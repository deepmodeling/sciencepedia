{"hands_on_practices": [{"introduction": "Understanding how a system evolves over time is the essence of studying dynamical systems. For linear systems, this evolution can be described by matrix-vector multiplication. This first exercise provides a concrete, geometric foundation by asking you to model a simple discrete-time system that rotates and scales vectors in a plane, demonstrating how abstract matrix operations directly correspond to intuitive physical actions [@problem_id:1690221].", "problem": "Consider a two-dimensional discrete-time linear dynamical system whose state at time step $k$ is described by a vector $\\mathbf{v}_k = \\begin{pmatrix} x_k \\\\ y_k \\end{pmatrix}$. The evolution of the system from one step to the next is governed by a linear transformation $L$ such that $\\mathbf{v}_{k+1} = L(\\mathbf{v}_k)$. The transformation $L$ applied to any vector consists of two operations performed in sequence: first, a counter-clockwise rotation about the origin by an angle of 45 degrees, and second, a uniform expansion by a factor of $s = \\sqrt{2}$.\n\nIf the initial state of the system at $k=0$ is $\\mathbf{v}_0 = \\begin{pmatrix} 2 \\\\ 0 \\end{pmatrix}$, determine the components of the state vector $\\mathbf{v}_4$ after 4 iterations of the transformation. Present your answer as a row matrix containing the two components $(x_4, y_4)$.", "solution": "The problem asks for the state of a system, $\\mathbf{v}_4$, after four applications of a linear transformation $L$ on an initial state $\\mathbf{v}_0$. The relationship is given by $\\mathbf{v}_{k+1} = L(\\mathbf{v}_k)$, which can be represented by a matrix multiplication $\\mathbf{v}_{k+1} = M \\mathbf{v}_k$, where $M$ is the matrix corresponding to the transformation $L$.\n\nFirst, we must find the matrix $M$. The transformation $L$ is a composition of two operations: a rotation followed by a scaling. Let's find the matrix for each operation.\n\nThe first operation is a counter-clockwise rotation about the origin by an angle $\\theta = 45^\\circ$. The standard matrix for a counter-clockwise rotation by an angle $\\theta$ in a 2D plane is:\n$$\nR(\\theta) = \\begin{pmatrix} \\cos\\theta  -\\sin\\theta \\\\ \\sin\\theta  \\cos\\theta \\end{pmatrix}\n$$\nFor $\\theta = 45^\\circ$, we have $\\cos(45^\\circ) = \\frac{\\sqrt{2}}{2} = \\frac{1}{\\sqrt{2}}$ and $\\sin(45^\\circ) = \\frac{\\sqrt{2}}{2} = \\frac{1}{\\sqrt{2}}$. Substituting these values gives the rotation matrix $R_{45}$:\n$$\nR_{45} = \\begin{pmatrix} \\frac{1}{\\sqrt{2}}  -\\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}}  \\frac{1}{\\sqrt{2}} \\end{pmatrix}\n$$\n\nThe second operation is a uniform scaling by a factor of $s = \\sqrt{2}$. The matrix for such a scaling is $S_s = sI$, where $I$ is the identity matrix:\n$$\nS_{\\sqrt{2}} = \\begin{pmatrix} \\sqrt{2}  0 \\\\ 0  \\sqrt{2} \\end{pmatrix}\n$$\n\nThe total transformation $L$ is a composition of the rotation followed by the scaling. If $\\mathbf{v}$ is a vector, applying the rotation first gives $R_{45} \\mathbf{v}$. Applying the scaling to this result gives $S_{\\sqrt{2}} (R_{45} \\mathbf{v})$. Therefore, the matrix $M$ for the full transformation $L$ is the product of the individual matrices, with the matrix for the first operation on the right:\n$$\nM = S_{\\sqrt{2}} R_{45} = \\begin{pmatrix} \\sqrt{2}  0 \\\\ 0  \\sqrt{2} \\end{pmatrix} \\begin{pmatrix} \\frac{1}{\\sqrt{2}}  -\\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}}  \\frac{1}{\\sqrt{2}} \\end{pmatrix}\n$$\nPerforming the matrix multiplication:\n$$\nM = \\begin{pmatrix} \\sqrt{2} \\cdot \\frac{1}{\\sqrt{2}} + 0 \\cdot \\frac{1}{\\sqrt{2}}  \\sqrt{2} \\cdot (-\\frac{1}{\\sqrt{2}}) + 0 \\cdot \\frac{1}{\\sqrt{2}} \\\\ 0 \\cdot \\frac{1}{\\sqrt{2}} + \\sqrt{2} \\cdot \\frac{1}{\\sqrt{2}}  0 \\cdot (-\\frac{1}{\\sqrt{2}}) + \\sqrt{2} \\cdot \\frac{1}{\\sqrt{2}} \\end{pmatrix} = \\begin{pmatrix} 1  -1 \\\\ 1  1 \\end{pmatrix}\n$$\n\nWe need to find the state vector $\\mathbf{v}_4$. Since $\\mathbf{v}_{k+1} = M \\mathbf{v}_k$, we have $\\mathbf{v}_1 = M \\mathbf{v}_0$, $\\mathbf{v}_2 = M \\mathbf{v}_1 = M(M \\mathbf{v}_0) = M^2 \\mathbf{v}_0$, and in general, $\\mathbf{v}_k = M^k \\mathbf{v}_0$. Thus, we need to compute $\\mathbf{v}_4 = M^4 \\mathbf{v}_0$.\n\nWe can calculate $M^4$ by repeated squaring:\n$$\nM^2 = M \\cdot M = \\begin{pmatrix} 1  -1 \\\\ 1  1 \\end{pmatrix} \\begin{pmatrix} 1  -1 \\\\ 1  1 \\end{pmatrix} = \\begin{pmatrix} 1(1) + (-1)(1)  1(-1) + (-1)(1) \\\\ 1(1) + 1(1)  1(-1) + 1(1) \\end{pmatrix} = \\begin{pmatrix} 0  -2 \\\\ 2  0 \\end{pmatrix}\n$$\n$$\nM^4 = M^2 \\cdot M^2 = \\begin{pmatrix} 0  -2 \\\\ 2  0 \\end{pmatrix} \\begin{pmatrix} 0  -2 \\\\ 2  0 \\end{pmatrix} = \\begin{pmatrix} 0(0) + (-2)(2)  0(-2) + (-2)(0) \\\\ 2(0) + 0(2)  2(-2) + 0(0) \\end{pmatrix} = \\begin{pmatrix} -4  0 \\\\ 0  -4 \\end{pmatrix}\n$$\nAlternatively, one can recognize that $M = s R(\\theta)$ and use the property that $(R(\\theta))^n = R(n\\theta)$.\n$M^4 = (S_{\\sqrt{2}} R_{45})^4 = (\\sqrt{2} I \\cdot R_{45})^4 = (\\sqrt{2})^4 (R_{45})^4$.\n$(\\sqrt{2})^4 = 4$.\n$(R_{45})^4 = R(4 \\times 45^\\circ) = R(180^\\circ)$.\nThe matrix for a $180^\\circ$ rotation is:\n$$\nR(180^\\circ) = \\begin{pmatrix} \\cos(180^\\circ)  -\\sin(180^\\circ) \\\\ \\sin(180^\\circ)  \\cos(180^\\circ) \\end{pmatrix} = \\begin{pmatrix} -1  0 \\\\ 0  -1 \\end{pmatrix} = -I\n$$\nSo, $M^4 = 4 \\cdot (-I) = -4I = \\begin{pmatrix} -4  0 \\\\ 0  -4 \\end{pmatrix}$. This confirms the previous calculation.\n\nNow we can find $\\mathbf{v}_4$ by applying $M^4$ to the initial vector $\\mathbf{v}_0 = \\begin{pmatrix} 2 \\\\ 0 \\end{pmatrix}$:\n$$\n\\mathbf{v}_4 = M^4 \\mathbf{v}_0 = \\begin{pmatrix} -4  0 \\\\ 0  -4 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} -4(2) + 0(0) \\\\ 0(2) + (-4)(0) \\end{pmatrix} = \\begin{pmatrix} -8 \\\\ 0 \\end{pmatrix}\n$$\nThe components of the state vector $\\mathbf{v}_4$ are $x_4 = -8$ and $y_4 = 0$. The problem asks for the answer as a row matrix.", "answer": "$$\\boxed{\\begin{pmatrix} -8  0 \\end{pmatrix}}$$", "id": "1690221"}, {"introduction": "Beyond simply calculating a system's future state, it is crucial to understand the qualitative properties of its evolution matrix. A fundamental question is whether the system's evolution is reversibleâ€”can we uniquely determine its past from its present? This practice problem explores the condition under which a system loses information, linking the abstract algebraic concept of a matrix determinant to the tangible idea of multiple distinct pasts converging to a single present [@problem_id:1690194].", "problem": "A team of ecologists is studying a simplified model of population dynamics for three interacting species in a closed environment. The state of the system at any given month $k$ is described by a state vector $\\mathbf{x}_k = \\begin{pmatrix} P_k \\\\ M_k \\\\ C_k \\end{pmatrix}$, where $P_k$, $M_k$, and $C_k$ represent the populations of a prey species, a predator species, and a competing species, respectively. The evolution of the population from one month to the next is governed by the linear discrete-time system $\\mathbf{x}_{k+1} = A \\mathbf{x}_k$.\n\nThe evolution matrix $A$ has been partially determined from field data and is given by:\n$$ A = \\begin{pmatrix} 1.1  -0.4  -0.1 \\\\ 0.3  0.8  0 \\\\ \\alpha  0  0.9 \\end{pmatrix} $$\nThe parameter $\\alpha$ represents a hypothesized interaction effect where the growth of the competing species is influenced by the prey population. Its value is currently unknown.\n\nA key theoretical question arises: under what condition could two different initial population states, say $\\mathbf{x}_0$ and $\\mathbf{x}'_0$, evolve into the exact same population state $\\mathbf{x}_1$ after just one month? Such a scenario would mean that observing the state at $k=1$ is not enough to uniquely determine the state at $k=0$, implying a loss of information in the system's evolution. For this phenomenon to be possible, the parameter $\\alpha$ must take a specific value.\n\nDetermine this specific numerical value of $\\alpha$.", "solution": "We seek a condition under which there exist two distinct initial states $\\mathbf{x}_{0}$ and $\\mathbf{x}'_{0}$ such that $A \\mathbf{x}_{0} = A \\mathbf{x}'_{0}$. This is equivalent to $A(\\mathbf{x}_{0} - \\mathbf{x}'_{0}) = \\mathbf{0}$ with $\\mathbf{x}_{0} - \\mathbf{x}'_{0} \\neq \\mathbf{0}$. Therefore, a necessary and sufficient condition is that the linear map $A$ is not injective, which holds if and only if the nullspace of $A$ is nontrivial, i.e., $\\det(A) = 0$.\n\nWith\n$$\nA = \\begin{pmatrix}\n1.1  -0.4  -0.1 \\\\\n0.3  0.8  0 \\\\\n\\alpha  0  0.9\n\\end{pmatrix},\n$$\ncompute $\\det(A)$ by expansion along the third column:\n- The cofactor from $(1,3)$ is $a_{13} \\cdot \\det\\begin{pmatrix} 0.3  0.8 \\\\ \\alpha  0 \\end{pmatrix} = (-0.1)\\left(0.3\\cdot 0 - 0.8 \\alpha\\right) = 0.08\\alpha$.\n- The cofactor from $(2,3)$ is zero because $a_{23} = 0$.\n- The cofactor from $(3,3)$ is $a_{33} \\cdot \\det\\begin{pmatrix} 1.1  -0.4 \\\\ 0.3  0.8 \\end{pmatrix} = 0.9\\left(1.1\\cdot 0.8 - (-0.4)\\cdot 0.3\\right) = 0.9\\left(0.88 + 0.12\\right) = 0.9$.\n\nThus,\n$$\n\\det(A) = 0.08\\alpha + 0.9.\n$$\nFor non-injectivity, set $\\det(A) = 0$:\n$$\n0.08\\alpha + 0.9 = 0 \\quad \\Longrightarrow \\quad \\alpha = -\\frac{0.9}{0.08}.\n$$\nExpressing in exact fractional form, $0.9 = \\frac{9}{10}$ and $0.08 = \\frac{2}{25}$, so\n$$\n\\alpha = -\\frac{\\frac{9}{10}}{\\frac{2}{25}} = -\\frac{9}{10}\\cdot\\frac{25}{2} = -\\frac{225}{20} = -\\frac{45}{4}.\n$$\nTherefore, the unique value of $\\alpha$ that makes two different initial states map to the same next state after one step is $\\alpha = -\\frac{45}{4}$.", "answer": "$$\\boxed{-\\frac{45}{4}}$$", "id": "1690194"}, {"introduction": "Linear algebra offers powerful theorems that provide deep insights and computational shortcuts for analyzing dynamical systems. The Cayley-Hamilton theorem, which relates a matrix to its own characteristic equation, is a prime example. This problem challenges you to apply this theorem to find the inverse of a system matrix, thereby deriving the exact mathematical description of the system's time-reversed dynamics without resorting to standard matrix inversion algorithms [@problem_id:1690201].", "problem": "Consider a discrete-time linear dynamical system whose state vector $\\mathbf{x}_k \\in \\mathbb{R}^3$ at integer time step $k$ evolves according to the equation $\\mathbf{x}_{k+1} = A\\mathbf{x}_k$. The system is governed by the constant matrix $A$ given by:\n$$A = \\begin{pmatrix} 1  2  0 \\\\ 0  1  2 \\\\ 1  1  1 \\end{pmatrix}$$\nThe time-reversed dynamics of this system, which describe how to determine the past state $\\mathbf{x}_k$ from a future state $\\mathbf{x}_{k+1}$, are given by an equation of the form $\\mathbf{x}_k = B\\mathbf{x}_{k+1}$. It can be shown that the matrix $B$ for the time-reversed system is expressible as a quadratic polynomial in the matrix $A$:\n$$B = c_2 A^2 + c_1 A + c_0 I$$\nwhere $I$ is the $3 \\times 3$ identity matrix and $c_2, c_1, c_0$ are scalar coefficients.\n\nDetermine the values of the coefficients $(c_2, c_1, c_0)$. Present your answer as a single row matrix $\\begin{pmatrix} c_2  c_1  c_0 \\end{pmatrix}$ using exact fractions.", "solution": "We seek the time-reversal matrix $B$ such that $\\mathbf{x}_{k} = B \\mathbf{x}_{k+1}$ for the system $\\mathbf{x}_{k+1} = A \\mathbf{x}_{k}$, hence $B = A^{-1}$. For a $3 \\times 3$ matrix $A$ with characteristic polynomial\n$$\np(\\lambda) = \\lambda^{3} - s_{1} \\lambda^{2} + s_{2} \\lambda - s_{3},\n$$\nthe Cayley-Hamilton theorem gives\n$$\nA^{3} - s_{1} A^{2} + s_{2} A - s_{3} I = 0.\n$$\nAssuming $A$ is invertible (verified below), we multiply by $A^{-1}$ to obtain\n$$\nA^{2} - s_{1} A + s_{2} I - s_{3} A^{-1} = 0,\n$$\nhence\n$$\nA^{-1} = \\frac{1}{s_{3}} \\left( A^{2} - s_{1} A + s_{2} I \\right).\n$$\nTherefore, the coefficients in $B = c_{2} A^{2} + c_{1} A + c_{0} I$ are $c_{2} = \\frac{1}{s_{3}}$, $c_{1} = -\\frac{s_{1}}{s_{3}}$, $c_{0} = \\frac{s_{2}}{s_{3}}$, where $s_{1} = \\operatorname{tr}(A)$, $s_{2} = \\frac{1}{2}\\left((\\operatorname{tr} A)^{2} - \\operatorname{tr}(A^{2})\\right)$, and $s_{3} = \\det(A)$.\n\nWe now compute $s_{1}$, $s_{2}$, and $s_{3}$ for\n$$\nA = \\begin{pmatrix} 1  2  0 \\\\ 0  1  2 \\\\ 1  1  1 \\end{pmatrix}.\n$$\nFirst, the trace is\n$$\ns_{1} = \\operatorname{tr}(A) = 1 + 1 + 1 = 3.\n$$\nNext, compute $A^{2}$ to obtain $\\operatorname{tr}(A^{2})$:\n$$\nA^{2} = \\begin{pmatrix} 1  2  0 \\\\ 0  1  2 \\\\ 1  1  1 \\end{pmatrix}\n\\begin{pmatrix} 1  2  0 \\\\ 0  1  2 \\\\ 1  1  1 \\end{pmatrix}\n= \\begin{pmatrix} 1  4  4 \\\\ 2  3  4 \\\\ 2  4  3 \\end{pmatrix},\n$$\nso\n$$\n\\operatorname{tr}(A^{2}) = 1 + 3 + 3 = 7.\n$$\nThus\n$$\ns_{2} = \\frac{1}{2}\\left((\\operatorname{tr} A)^{2} - \\operatorname{tr}(A^{2})\\right) = \\frac{1}{2}\\left(9 - 7\\right) = 1.\n$$\nFinally, compute the determinant:\n$$\ns_{3} = \\det(A) = \\det \\begin{pmatrix} 1  2  0 \\\\ 0  1  2 \\\\ 1  1  1 \\end{pmatrix}\n= 1\\cdot \\det \\begin{pmatrix} 1  2 \\\\ 1  1 \\end{pmatrix} - 2 \\cdot \\det \\begin{pmatrix} 0  2 \\\\ 1  1 \\end{pmatrix}\n= 1\\cdot (-1) - 2 \\cdot (-2) = 3.\n$$\nTherefore,\n$$\nB = A^{-1} = \\frac{1}{3} A^{2} - A + \\frac{1}{3} I,\n$$\nwhich identifies the coefficients\n$$\nc_{2} = \\frac{1}{3}, \\quad c_{1} = -1, \\quad c_{0} = \\frac{1}{3}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{1}{3}  -1  \\frac{1}{3} \\end{pmatrix}}$$", "id": "1690201"}]}