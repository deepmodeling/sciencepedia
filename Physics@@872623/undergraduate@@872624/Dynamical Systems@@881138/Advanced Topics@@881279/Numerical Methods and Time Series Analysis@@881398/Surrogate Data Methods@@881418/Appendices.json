{"hands_on_practices": [{"introduction": "To effectively use surrogate data methods, we must first understand the null hypothesis, which represents the absence of the structure we are testing for. This first exercise grounds our understanding by having you calculate the theoretical expectation for a simple test statistic under the assumption of complete randomness. By working through the combinatorics of all possible permutations of a sequence, you will derive the baseline value against which a real-world observation would be compared. [@problem_id:1712308]", "problem": "In the analysis of time series data, surrogate data methods are often used to test for non-random structure. The core idea is to generate a large number of \"surrogate\" datasets that share some statistical properties of the original data (like the mean or distribution of values) but are otherwise random. By comparing a test statistic computed from the original data to the distribution of the same statistic from the surrogates, one can assess the statistical significance of any observed patterns.\n\nConsider a simple binary time series, $S$, representing the outcomes of ten sequential trials (where 1 could be 'success' and 0 'failure'):\n$$ S = \\{1, 0, 0, 1, 1, 0, 1, 0, 0, 0\\} $$\nTo test for temporal ordering, we define a test statistic, $T$, as the total number of times an element in the sequence differs from the element immediately following it. For a sequence $\\{s_1, s_2, \\dots, s_N\\}$, this is the number of \"transitions\" (from 0 to 1 or 1 to 0) between adjacent elements.\n\nYour task is to determine the theoretical expected value of this test statistic, $\\langle T_{surr} \\rangle$, under the null hypothesis that there is no temporal order. This expected value is equivalent to the average value of $T$ computed over the ensemble of all possible unique permutations of the sequence $S$.\n\nCalculate the value of $\\langle T_{surr} \\rangle$ for the given sequence $S$. Round your final answer to two significant figures.", "solution": "Let the length be $N$, the number of ones be $n_{1}$, and the number of zeros be $n_{0}$, with $N=n_{1}+n_{0}$. Define the test statistic as\n$$\nT=\\sum_{i=1}^{N-1} I_{i},\n$$\nwhere $I_{i}$ is the indicator that $s_{i}\\neq s_{i+1}$. By linearity of expectation,\n$$\n\\langle T_{surr} \\rangle=\\sum_{i=1}^{N-1} \\Pr(s_{i}\\neq s_{i+1})=(N-1)\\,p,\n$$\nwhere $p=\\Pr(s_{i}\\neq s_{i+1})$ is the probability that two adjacent elements differ in a uniformly random permutation of the multiset with $n_{1}$ ones and $n_{0}$ zeros.\n\nBy exchangeability, the ordered adjacent pair has the same distribution as two draws without replacement from the population, hence\n$$\np=\\Pr(1\\text{ then }0)+\\Pr(0\\text{ then }1)=\\frac{n_{1}}{N}\\cdot\\frac{n_{0}}{N-1}+\\frac{n_{0}}{N}\\cdot\\frac{n_{1}}{N-1}=\\frac{2 n_{1} n_{0}}{N(N-1)}.\n$$\nTherefore,\n$$\n\\langle T_{surr} \\rangle=(N-1)\\cdot \\frac{2 n_{1} n_{0}}{N(N-1)}=\\frac{2 n_{1} n_{0}}{N}.\n$$\n\nFor the given sequence $S$, we have $N=10$, $n_{1}=4$, and $n_{0}=6$, so\n$$\n\\langle T_{surr} \\rangle=\\frac{2\\cdot 4\\cdot 6}{10}=\\frac{48}{10}=4.8,\n$$\nwhich rounded to two significant figures is $4.8$.", "answer": "$$\\boxed{4.8}$$", "id": "1712308"}, {"introduction": "Moving from theory to a concrete application, this practice simulates a complete surrogate data test from start to finish. You are given a time series from a hypothetical experiment and a small set of \"shuffled\" surrogates, which are consistent with the null hypothesis of no temporal correlations. Your task is to apply a standard test statistic, the lag-1 autocorrelation, to both the original data and the surrogates to calculate a p-value and draw a statistical conclusion. [@problem_id:1712276]", "problem": "A physicist is investigating a system where a small, highly elastic ball bounces on a specialized surface whose temperature is actively, but imperfectly, controlled. The hypothesis is that the sequence of peak bounce heights is an Independent and Identically Distributed (IID) process, meaning there is no \"memory\" or correlation between consecutive bounces. To test this null hypothesis, a surrogate data method is employed.\n\nThe recorded time series of five consecutive peak bounce heights, in meters, is given by:\n$$ H_{data} = \\{0.80, 0.60, 0.65, 0.45, 0.50\\} $$\n\nTo create a reference distribution under the null hypothesis, four surrogate time series were generated by shuffling the original data:\n- $S_1 = \\{0.45, 0.50, 0.60, 0.65, 0.80\\}$\n- $S_2 = \\{0.60, 0.80, 0.45, 0.50, 0.65\\}$\n- $S_3 = \\{0.80, 0.45, 0.65, 0.50, 0.60\\}$\n- $S_4 = \\{0.50, 0.80, 0.60, 0.45, 0.65\\}$\n\nThe test statistic used to quantify temporal correlation is the lag-1 autocorrelation coefficient, $r_1$. For a time series $x = \\{x_1, x_2, \\dots, x_N\\}$ with mean $\\bar{x}$, the lag-1 autocorrelation is defined as:\n$$ r_1 = \\frac{\\sum_{i=1}^{N-1} (x_i - \\bar{x})(x_{i+1} - \\bar{x})}{\\sum_{i=1}^{N} (x_i - \\bar{x})^2} $$\n\nYour task is to perform the significance test. Calculate the p-value, defined as the proportion of the provided surrogate datasets whose lag-1 autocorrelation is greater than or equal to the lag-1 autocorrelation of the original data, $H_{data}$. Express your answer as a decimal rounded to two significant figures.", "solution": "We use the lag-1 autocorrelation definition\n$$\nr_{1}=\\frac{\\sum_{i=1}^{N-1}(x_{i}-\\bar{x})(x_{i+1}-\\bar{x})}{\\sum_{i=1}^{N}(x_{i}-\\bar{x})^{2}},\n$$\nwith $N=5$ for each series. Since all surrogates are permutations of the same values, each has the same mean and the same denominator as the original.\n\nFor $H_{data}=\\{0.80,0.60,0.65,0.45,0.50\\}$, the mean is\n$$\n\\bar{x}=\\frac{0.80+0.60+0.65+0.45+0.50}{5}=\\frac{3.00}{5}=0.60.\n$$\nDeviations are $d=\\{0.20,0.00,0.05,-0.15,-0.10\\}$. The denominator is\n$$\n\\sum_{i=1}^{5}d_{i}^{2}=0.20^{2}+0.00^{2}+0.05^{2}+(-0.15)^{2}+(-0.10)^{2}=0.0750.\n$$\nThe numerator is\n$$\n\\sum_{i=1}^{4}d_{i}d_{i+1}=(0.20)(0.00)+(0.00)(0.05)+(0.05)(-0.15)+(-0.15)(-0.10)=0.0075,\n$$\nso\n$$\nr_{1}(H_{data})=\\frac{0.0075}{0.0750}=0.10.\n$$\n\nFor each surrogate, $\\bar{x}=0.60$ and the denominator is $0.0750$. Compute numerators and $r_{1}$:\n\n- $S_{1}=\\{0.45,0.50,0.60,0.65,0.80\\}$ has deviations $\\{-0.15,-0.10,0.00,0.05,0.20\\}$, numerator $0.015+0+0+0.010=0.025$, so\n$$\nr_{1}(S_{1})=\\frac{0.025}{0.075}=\\frac{1}{3}\\approx 0.333\\dots\n$$\n- $S_{2}=\\{0.60,0.80,0.45,0.50,0.65\\}$ has deviations $\\{0.00,0.20,-0.15,-0.10,0.05\\}$, numerator $0-0.030+0.015-0.005=-0.020$, so\n$$\nr_{1}(S_{2})=\\frac{-0.020}{0.075}=-0.266\\dots\n$$\n- $S_{3}=\\{0.80,0.45,0.65,0.50,0.60\\}$ has deviations $\\{0.20,-0.15,0.05,-0.10,0.00\\}$, numerator $-0.030-0.0075-0.005+0=-0.0425$, so\n$$\nr_{1}(S_{3})=\\frac{-0.0425}{0.075}=-0.566\\dots\n$$\n- $S_{4}=\\{0.50,0.80,0.60,0.45,0.65\\}$ has deviations $\\{-0.10,0.20,0.00,-0.15,0.05\\}$, numerator $-0.020+0+0-0.0075=-0.0275$, so\n$$\nr_{1}(S_{4})=\\frac{-0.0275}{0.075}=-0.366\\dots\n$$\n\nWe compare with $r_{1}(H_{data})=0.10$. Among the surrogates, only $S_{1}$ has $r_{1}\\geq 0.10$, giving $1$ out of $4$. Therefore, the p-value is\n$$\np=\\frac{1}{4}=0.25,\n$$\nwhich rounded to two significant figures is $0.25$.", "answer": "$$\\boxed{0.25}$$", "id": "1712276"}, {"introduction": "Real-world data analysis rarely yields perfectly clear-cut answers, and surrogate testing is no exception. This final practice explores the crucial skill of interpreting marginal or inconclusive results, where the test statistic from the original data falls at the very edge of the surrogate distribution. This scenario forces us to consider the nuances of statistical significance, the resolving power of the test given a finite number of surrogates, and the possibility that our test is underpowered, providing a lesson in careful scientific judgment. [@problem_id:1712258]", "problem": "An astrophysicist is analyzing the time series of brightness fluctuations, $x(t)$, from a distant star to determine if the underlying dynamics are purely linear or exhibit nonlinear behavior. The null hypothesis, $H_0$, is that the time series is generated by a stationary, linear, Gaussian stochastic process. The alternative hypothesis, $H_a$, is that the dynamics contain a nonlinear component.\n\nTo test this, the astrophysicist employs a surrogate data test. They choose a test statistic sensitive to time-reversal asymmetry, a common signature of nonlinearity. For the time series of length $N$ with a chosen time lag $\\tau$, the statistic is calculated as:\n$$ T = \\frac{1}{N-2\\tau} \\sum_{k=\\tau+1}^{N-\\tau} (x_k - x_{k-\\tau})^3 $$\nFor a process obeying the null hypothesis, the expected value of $T$ is zero. Many nonlinear processes are expected to yield a non-zero value for $T$.\n\nThe astrophysicist first calculates the statistic for the original data, obtaining $T_{orig}$. Then, they generate $M=199$ surrogate datasets. Each surrogate is generated using a phase-randomization algorithm that precisely preserves the power spectrum and the distribution of values (the histogram) of the original time series, consistent with the properties of $H_0$. They calculate the test statistic $T_i$ for each surrogate series $i=1, \\dots, 199$.\n\nFor a one-sided test, where the specific alternative hypothesis predicts $T > 0$, the value $T_{orig}$ is compared to the distribution of the surrogate values $\\{T_i\\}$. The analysis reveals that $T_{orig}$ is larger than 189 of the surrogate values, but smaller than the other 10 surrogate values.\n\nGiven a standard significance level of $\\alpha = 0.05$, which of the following statements provides the most accurate and complete interpretation of this finding?\n\nA. The null hypothesis is rejected at the $\\alpha = 0.05$ significance level, which provides strong evidence that the stellar dynamics are nonlinear.\nB. The null hypothesis is not rejected. This confirms that the underlying stellar dynamics can be fully described by a linear stochastic process.\nC. The result is inconclusive. Although the null hypothesis is not formally rejected, the test statistic is on the margin of the significance threshold, suggesting the test might be underpowered and a more definitive conclusion could potentially be reached with a larger number of surrogates.\nD. The surrogate generation method must be flawed. If the method were correct and the null hypothesis true, the original statistic $T_{orig}$ should be located near the median of the surrogate distribution.\nE. A Type I error (false positive) has likely occurred, as the test statistic is unusually high, but not high enough to formally reject the null hypothesis.", "solution": "Under the null hypothesis $H_{0}$, the time series is a stationary, linear, Gaussian process. The chosen statistic is\n$$\nT=\\frac{1}{N-2\\tau}\\sum_{k=\\tau+1}^{N-\\tau}(x_{k}-x_{k-\\tau})^{3},\n$$\nwhich has $\\mathbb{E}[T]=0$ when $H_{0}$ holds. For a one-sided test with alternative $H_{a}:T>0$, the empirical $p$-value is computed using surrogate data consistent with $H_{0}$.\n\nGiven $M=199$ surrogates, let $k$ denote the number of surrogates whose statistic is at least as large as the observed value $T_{orig}$. The recommended unbiased estimate of the one-sided $p$-value is\n$$\np=\\frac{k+1}{M+1}.\n$$\nThe data indicate that $T_{orig}$ is larger than $189$ surrogate values and smaller than $10$ surrogate values. Assuming no ties, the number of surrogates with statistic at least $T_{orig}$ is\n$$\nk=10.\n$$\nTherefore,\n$$\np=\\frac{k+1}{M+1}=\\frac{10+1}{199+1}=\\frac{11}{200}=0.055.\n$$\nWith a significance level $\\alpha=0.05$, we compare $p$ to $\\alpha$ and find $p>\\alpha$. Thus, we do not reject $H_{0}$ at the $\\alpha=0.05$ level. However, the result is marginal because the discrete resolution of the surrogate test is $\\frac{1}{M+1}=\\frac{1}{200}=0.005$, and the critical boundary for rejection corresponds to $k\\leq 9$. The observed $k=10$ is one count above this boundary, indicating that the test is close to, but does not reach, significance. This does not confirm that the process is linear; rather, it suggests an inconclusive outcome that could potentially be clarified with more surrogates (increasing $M$ reduces the $p$-value resolution).\nThe most accurate and complete interpretation among the options is that the null is not rejected, the result is borderline, and additional surrogates could provide a more definitive conclusion.", "answer": "$$\\boxed{C}$$", "id": "1712258"}]}