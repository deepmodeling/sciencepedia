{"hands_on_practices": [{"introduction": "To begin our exploration of cumulants, we start with a familiar and fundamental model from probability: the coin toss. This exercise grounds the abstract definition of the Cumulant Generating Function (CGF) in a concrete scenario. By analyzing a system composed of many identical, independent parts—a common theme in statistical mechanics—you will see how the CGF provides a powerful tool for describing the system's overall behavior, demonstrating the important property of additivity for cumulants. [@problem_id:1958739]", "problem": "Consider a sequence of $N$ independent tosses of a fair coin, where the probability of observing heads on any single toss is exactly $1/2$. Let the discrete random variable $X$ represent the total number of heads observed in these $N$ tosses.\n\nIn statistical mechanics, the properties of a random variable are often analyzed using generating functions. The Moment Generating Function (MGF) for a discrete random variable $Y$ with possible outcomes $y_i$ is defined as $M_Y(t) = \\mathbb{E}[\\exp(tY)] = \\sum_i \\exp(ty_i) P(Y=y_i)$, where $\\mathbb{E}[...]$ denotes the expectation value and $P(Y=y_i)$ is the probability of outcome $y_i$. The Cumulant Generating Function (CGF), denoted as $K_Y(t)$, is defined as the natural logarithm of the MGF: $K_Y(t) = \\ln(M_Y(t))$.\n\nDetermine the Cumulant Generating Function, $K_X(t)$, for the random variable $X$. Express your answer as a function of $N$ and $t$.", "solution": "Let $X$ be the total number of heads in $N$ independent tosses of a fair coin. Write $X$ as a sum of $N$ independent and identically distributed Bernoulli random variables: $X=\\sum_{i=1}^{N} Y_{i}$, where $P(Y_{i}=1)=\\frac{1}{2}$ and $P(Y_{i}=0)=\\frac{1}{2}$.\n\nBy definition, the Moment Generating Function (MGF) of $Y_{i}$ is\n$$\nM_{Y_{i}}(t)=\\mathbb{E}[\\exp(tY_{i})]=\\exp(t)\\cdot P(Y_{i}=1)+\\exp(0)\\cdot P(Y_{i}=0)=\\frac{1}{2}\\exp(t)+\\frac{1}{2}.\n$$\nSince the $Y_{i}$ are independent, the MGF of $X$ is the product of the individual MGFs:\n$$\nM_{X}(t)=\\prod_{i=1}^{N}M_{Y_{i}}(t)=\\left(\\frac{1}{2}\\exp(t)+\\frac{1}{2}\\right)^{N}=\\left(\\frac{1+\\exp(t)}{2}\\right)^{N}.\n$$\nThe Cumulant Generating Function (CGF) is the natural logarithm of the MGF:\n$$\nK_{X}(t)=\\ln\\left(M_{X}(t)\\right)=N\\,\\ln\\left(\\frac{1+\\exp(t)}{2}\\right).\n$$\nThis gives $K_{X}(t)$ explicitly in terms of $N$ and $t$.", "answer": "$$\\boxed{N\\,\\ln\\!\\left(\\frac{1+\\exp(t)}{2}\\right)}$$", "id": "1958739"}, {"introduction": "We now turn to the Poisson distribution, which is indispensable for modeling discrete, random events in physics, from radioactive decays to photon arrivals in a detector. This practice challenges you to derive all the cumulants, $\\kappa_n$, for a Poisson process. The strikingly simple result you will find is not just a mathematical curiosity; it reveals a defining characteristic of Poisson statistics and provides a key signature for identifying such processes in experimental data. [@problem_id:1958741]", "problem": "In a quantum optics experiment, a highly sensitive detector is used to count photons arriving from a coherent source of light, such as a highly attenuated laser. The number of photons, $k$, detected in a fixed time interval is a discrete random variable. It is found that the probability of detecting exactly $k$ photons follows the Poisson distribution, given by:\n$$P(k; \\lambda) = \\frac{\\lambda^k \\exp(-\\lambda)}{k!}$$\nwhere $k$ can be any non-negative integer ($k=0, 1, 2, \\dots$) and $\\lambda$ is a positive real parameter representing the average number of detected photons in the interval.\n\nTo analyze the statistical fluctuations of the photon counts, physicists use cumulants. The cumulants, $\\kappa_n$ (for $n=1, 2, 3, \\dots$), are derived from the cumulant-generating function (CGF), $K(t)$, which is defined as the natural logarithm of the moment-generating function (MGF), $M(t)$. The MGF is defined as the expectation value $M(t) = \\langle \\exp(tk) \\rangle$. The $n$-th cumulant is then found by taking the $n$-th derivative of the CGF with respect to $t$ and evaluating it at $t=0$:\n$$\\kappa_n = \\left. \\frac{d^n K(t)}{dt^n} \\right|_{t=0}$$\nFor the given Poisson distribution of photon counts, determine a general expression for the $n$-th cumulant, $\\kappa_n$, for any positive integer $n$. Your answer should be an analytic expression in terms of the parameter $\\lambda$.", "solution": "We are given a Poisson distribution with parameter $\\lambda$ for the photon count $k$. The moment-generating function is defined by $M(t)=\\langle \\exp(tk)\\rangle$. Using the definition of expectation with the Poisson probability mass function,\n$$\nM(t)=\\sum_{k=0}^{\\infty}P(k;\\lambda)\\exp(tk)=\\sum_{k=0}^{\\infty}\\frac{\\lambda^{k}\\exp(-\\lambda)}{k!}\\exp(tk).\n$$\nFactor out the constant $\\exp(-\\lambda)$ and combine the terms inside the sum:\n$$\nM(t)=\\exp(-\\lambda)\\sum_{k=0}^{\\infty}\\frac{\\left(\\lambda\\exp(t)\\right)^{k}}{k!}.\n$$\nRecognizing the exponential series $\\sum_{k=0}^{\\infty}a^{k}/k!=\\exp(a)$ with $a=\\lambda\\exp(t)$, we obtain\n$$\nM(t)=\\exp(-\\lambda)\\exp\\!\\left(\\lambda\\exp(t)\\right)=\\exp\\!\\left(\\lambda\\left(\\exp(t)-1\\right)\\right).\n$$\nThe cumulant-generating function is $K(t)=\\ln M(t)$, hence\n$$\nK(t)=\\ln\\!\\left(\\exp\\!\\left(\\lambda\\left(\\exp(t)-1\\right)\\right)\\right)=\\lambda\\left(\\exp(t)-1\\right).\n$$\nThe $n$-th cumulant is $\\kappa_{n}=\\left.\\frac{d^{n}K(t)}{dt^{n}}\\right|_{t=0}$. For $n\\geq 1$, differentiating $K(t)=\\lambda(\\exp(t)-1)$ yields\n$$\n\\frac{d^{n}K(t)}{dt^{n}}=\\lambda\\exp(t),\n$$\nsince each derivative of $\\exp(t)$ is $\\exp(t)$ and the derivative of the constant $-\\lambda$ is zero for $n\\geq 1$. Evaluating at $t=0$ gives\n$$\n\\kappa_{n}=\\left.\\lambda\\exp(t)\\right|_{t=0}=\\lambda.\n$$\nTherefore, for every positive integer $n$, the $n$-th cumulant equals $\\lambda$.", "answer": "$$\\boxed{\\lambda}$$", "id": "1958741"}, {"introduction": "This final exercise serves as a conceptual capstone, connecting cumulants directly to the physical principles of statistical mechanics. Instead of a random variable, we consider a quantity that is precisely fixed: the energy $E_0$ of an isolated system in the microcanonical ensemble. By analyzing this limiting case, you will gain a profound intuition for the physical meaning of cumulants. The problem demonstrates that cumulants are the natural language for describing fluctuations; where there are no fluctuations, all higher-order cumulants vanish, leaving only the mean. [@problem_id:1958779]", "problem": "In statistical mechanics, an isolated thermodynamic system is described by the microcanonical ensemble. A defining characteristic of this ensemble is that the total energy of the system is a precisely known and fixed constant, which we will denote as $E_0$. Consequently, the probability distribution function, $P(E)$, for observing the system to have a particular energy $E$ is described by the Dirac delta function: $P(E) = \\delta(E - E_0)$.\n\nThe statistical properties of this energy distribution can be characterized by its cumulants, $\\kappa_n$. The cumulants are derived from the cumulant generating function, $K(k)$, which is itself defined in terms of the characteristic function, $\\Phi(k)$. The definitions are as follows:\n\n1.  **Characteristic Function:** $\\Phi(k) = \\langle \\exp(ikE) \\rangle = \\int_{-\\infty}^{\\infty} P(E) \\exp(ikE) \\, dE$\n2.  **Cumulant Generating Function:** $K(k) = \\ln(\\Phi(k))$\n3.  **n-th Cumulant:** $\\kappa_n = \\frac{1}{i^n} \\left. \\frac{d^n K(k)}{dk^n} \\right|_{k=0}$ for any integer $n \\ge 1$.\n\nBased on these definitions, which of the following statements correctly describes the n-th cumulant, $\\kappa_n$, of the energy distribution for this system?\n\nA. $\\kappa_n = (i E_0)^n$\n\nB. $\\kappa_n = E_0$ for all $n \\geq 1$.\n\nC. $\\kappa_n = E_0$ for $n=1$, and $\\kappa_n = 0$ for $n \\geq 2$.\n\nD. $\\kappa_n = \\frac{E_0^n}{n!}$\n\nE. All cumulants are zero, i.e., $\\kappa_n = 0$ for all $n \\geq 1$.", "solution": "To determine the correct expression for the $n$-th cumulant, $\\kappa_n$, we must follow the specified procedure, starting with the calculation of the characteristic function.\n\nFirst, we calculate the characteristic function $\\Phi(k)$ using its definition and the given probability distribution $P(E) = \\delta(E - E_0)$.\n$$\n\\Phi(k) = \\int_{-\\infty}^{\\infty} P(E) \\exp(ikE) \\, dE = \\int_{-\\infty}^{\\infty} \\delta(E - E_0) \\exp(ikE) \\, dE\n$$\nUsing the sifting property of the Dirac delta function, which states that $\\int_{-\\infty}^{\\infty} f(x)\\delta(x-a) \\, dx = f(a)$, we can evaluate the integral. In our case, the function is $f(E) = \\exp(ikE)$ and the point of evaluation is $a = E_0$.\n$$\n\\Phi(k) = \\exp(ikE_0)\n$$\n\nNext, we find the cumulant generating function, $K(k)$, by taking the natural logarithm of the characteristic function.\n$$\nK(k) = \\ln(\\Phi(k)) = \\ln(\\exp(ikE_0))\n$$\nThe natural logarithm and the exponential function are inverses, so they cancel each other out.\n$$\nK(k) = ikE_0\n$$\n\nFinally, we calculate the $n$-th cumulant, $\\kappa_n$, by taking the $n$-th derivative of $K(k)$ with respect to $k$, evaluating it at $k=0$, and multiplying by $\\frac{1}{i^n}$.\nThe expression for $K(k)$ is a linear function of $k$. Let's examine its derivatives.\n\nFor $n=1$, we calculate the first cumulant, $\\kappa_1$:\n$$\n\\frac{dK}{dk} = \\frac{d}{dk}(ikE_0) = iE_0\n$$\nThis derivative is a constant, so its value at $k=0$ is also $iE_0$.\n$$\n\\kappa_1 = \\frac{1}{i^1} \\left. \\frac{dK}{dk} \\right|_{k=0} = \\frac{1}{i} (iE_0) = E_0\n$$\nThe first cumulant, which represents the mean of the distribution, is $E_0$. This is physically consistent, as the energy is fixed at $E_0$.\n\nFor $n \\ge 2$, we need to calculate higher-order derivatives of $K(k)$. Let's find the second derivative:\n$$\n\\frac{d^2K}{dk^2} = \\frac{d}{dk}\\left(\\frac{dK}{dk}\\right) = \\frac{d}{dk}(iE_0) = 0\n$$\nSince the first derivative is a constant, the second derivative is zero. Consequently, all higher-order derivatives will also be zero.\n$$\n\\frac{d^n K}{dk^n} = 0 \\quad \\text{for all } n \\geq 2\n$$\nNow we can find the cumulants for $n \\ge 2$:\n$$\n\\kappa_n = \\frac{1}{i^n} \\left. \\frac{d^n K}{dk^n} \\right|_{k=0} = \\frac{1}{i^n} (0) = 0 \\quad \\text{for all } n \\geq 2\n$$\nThis result is also physically intuitive. The second cumulant, $\\kappa_2$, is the variance of the distribution. Since the energy is fixed at $E_0$, there is no spread or fluctuation, so the variance must be zero. Similarly, all higher cumulants, which describe other aspects of the distribution's shape (like skewness and kurtosis), must also be zero for a distribution concentrated at a single point.\n\nCombining our results, we find that $\\kappa_1 = E_0$ and $\\kappa_n = 0$ for all $n \\geq 2$. This corresponds exactly to option C.", "answer": "$$\\boxed{C}$$", "id": "1958779"}]}