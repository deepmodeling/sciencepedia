{"hands_on_practices": [{"introduction": "The bridge between a microscopic random walk and macroscopic diffusion is a crucial scaling relationship. When we model diffusion numerically, we must choose a discrete step size $\\Delta x$ and time step $\\Delta t$. This exercise [@problem_id:1895732] explores how these choices determine the physical diffusion coefficient $D$, and how they must be adjusted in tandem to ensure the simulation accurately represents the same physical system at different resolutions.", "problem": "A computational physicist is developing a one-dimensional numerical model to simulate the diffusion of a cloud of inert tracer particles suspended in a quiescent fluid. The model is based on a discrete random walk, where each particle, at every time step $\\Delta t$, moves a fixed distance $\\Delta x$ to either the left or the right with equal probability. In the limit of small step sizes and time steps, this random walk process can be described by a continuum diffusion equation. The effective diffusion coefficient, $D$, which characterizes the macroscopic spreading rate, is given by the relation:\n$$D = \\frac{(\\Delta x)^2}{2\\Delta t}$$\nSuppose the physicist decides to refine the spatial resolution of the simulation by using a new, smaller step size, $\\Delta x'$, such that $\\Delta x' = \\frac{1}{2}\\Delta x$. To ensure that the model continues to describe the same physical system, the diffusion coefficient $D$ must remain constant. How must the time step, $\\Delta t$, be adjusted to a new value, $\\Delta t'$, to maintain the same value of $D$?\n\nChoose the correct relationship between the new time step $\\Delta t'$ and the original time step $\\Delta t$.\n\nA. $\\Delta t' = \\frac{1}{4}\\Delta t$\n\nB. $\\Delta t' = \\frac{1}{2}\\Delta t$\n\nC. $\\Delta t' = \\Delta t$\n\nD. $\\Delta t' = 2\\Delta t$\n\nE. $\\Delta t' = 4\\Delta t$", "solution": "The macroscopic diffusion coefficient for a symmetric one-dimensional random walk is given by the continuum limit relation\n$$D = \\frac{(\\Delta x)^{2}}{2 \\Delta t}.$$\nTo keep the same physical diffusion when the step size is changed to $\\Delta x'$, the diffusion coefficient must remain constant, so\n$$\\frac{(\\Delta x)^{2}}{2 \\Delta t} = \\frac{(\\Delta x')^{2}}{2 \\Delta t'}.$$\nThis simplifies to\n$$\\frac{(\\Delta x)^{2}}{\\Delta t} = \\frac{(\\Delta x')^{2}}{\\Delta t'}.$$\nGiven $\\Delta x' = \\frac{1}{2} \\Delta x$, substitute to obtain\n$$\\frac{(\\Delta x)^{2}}{\\Delta t} = \\frac{\\left(\\frac{1}{2} \\Delta x\\right)^{2}}{\\Delta t'} = \\frac{\\frac{1}{4} (\\Delta x)^{2}}{\\Delta t'}.$$\nCancel $(\\Delta x)^{2}$ on both sides:\n$$\\frac{1}{\\Delta t} = \\frac{1}{4} \\frac{1}{\\Delta t'}.$$\nMultiplying both sides by $\\Delta t \\Delta t'$ gives\n$$\\Delta t' = \\frac{1}{4} \\Delta t.$$\nTherefore, the correct choice is A.", "answer": "$$\\boxed{A}$$", "id": "1895732"}, {"introduction": "Beyond setting up simulations, a key skill for a physicist is to analyze data to extract fundamental parameters. In this problem [@problem_id:1895725], we move from theory to practice by analyzing simulated data from a biased random walk, a common model for processes like molecular motor movement. You will learn how to use statistical moments of the particle's position—the mean and the mean square displacement—to determine the underlying diffusion coefficient, distinguishing random motion from directed drift.", "problem": "A researcher is analyzing computer simulation data for the one-dimensional movement of a molecular motor. The motor's position, $x$, is tracked over time, $t$. The theoretical model for this motion suggests it is a biased random walk, equivalent to a diffusion process with a constant drift velocity. The simulation starts with a large number of motors at the origin ($x=0$) at time $t=0$. The researcher has calculated the ensemble average of the position, $\\langle x(t) \\rangle$, and the ensemble average of the squared position, $\\langle x^2(t) \\rangle$, at two different times.\n\nThe collected data are as follows:\nAt time $T_1 = 2.0$ s:\n$\\langle x(T_1) \\rangle = 1.0$ μm\n$\\langle x^2(T_1) \\rangle = 7.0$ μm²\n\nAt time $T_2 = 5.0$ s:\n$\\langle x(T_2) \\rangle = 2.5$ μm\n$\\langle x^2(T_2) \\rangle = 21.25$ μm²\n\nFrom this simulation data, determine the effective diffusion coefficient $D$ of the molecular motor. Express your answer in units of μm²/s, rounded to two significant figures.", "solution": "We model the one-dimensional biased diffusion as the Langevin process\n$$\ndx = v\\,dt + \\sqrt{2D}\\,dW_{t},\n$$\nwith drift velocity $v$ and diffusion coefficient $D$, starting from $x(0)=0$. The ensemble moments for this process are\n$$\n\\langle x(t)\\rangle = v t,\n$$\nand, since the noise has variance $2Dt$, the variance is\n$$\n\\operatorname{Var}(x(t))=\\langle x^{2}(t)\\rangle - \\langle x(t)\\rangle^{2} = 2 D t.\n$$\nTherefore,\n$$\nD = \\frac{\\langle x^{2}(t)\\rangle - \\langle x(t)\\rangle^{2}}{2 t}.\n$$\n\nUsing the data at $T_{1}=2.0\\,\\text{s}$:\n$$\n\\langle x(T_{1})\\rangle = 1.0\\,\\mu\\text{m},\\quad \\langle x^{2}(T_{1})\\rangle = 7.0\\,\\mu\\text{m}^{2},\n$$\nso\n$$\nD = \\frac{7.0\\,\\mu\\text{m}^{2} - \\left(1.0\\,\\mu\\text{m}\\right)^{2}}{2\\cdot 2.0\\,\\text{s}} = \\frac{6.0\\,\\mu\\text{m}^{2}}{4.0\\,\\text{s}} = 1.5\\,\\mu\\text{m}^{2}\\!/\\text{s}.\n$$\n\nUsing the data at $T_{2}=5.0\\,\\text{s}$:\n$$\n\\langle x(T_{2})\\rangle = 2.5\\,\\mu\\text{m},\\quad \\langle x^{2}(T_{2})\\rangle = 21.25\\,\\mu\\text{m}^{2},\n$$\nso\n$$\nD = \\frac{21.25\\,\\mu\\text{m}^{2} - \\left(2.5\\,\\mu\\text{m}\\right)^{2}}{2\\cdot 5.0\\,\\text{s}} = \\frac{15.0\\,\\mu\\text{m}^{2}}{10.0\\,\\text{s}} = 1.5\\,\\mu\\text{m}^{2}\\!/\\text{s}.\n$$\n\nBoth times yield the same diffusion coefficient. Rounded to two significant figures in units of $\\mu\\text{m}^{2}\\!/\\text{s}$, the result is $1.5$.", "answer": "$$\\boxed{1.5}$$", "id": "1895725"}, {"introduction": "Random walks exhibit fascinating and universal properties that depend strongly on the dimensionality of the space they explore. This practice [@problem_id:1895712] challenges you to move beyond one dimension and investigate one of the most classic questions in probability theory: what is the likelihood that a random walker will ever return to its starting point? By analyzing the return probability for a 2D random walk, you will uncover a fundamental scaling law that distinguishes diffusion on a plane from diffusion on a line.", "problem": "A simplified model for the motion of a protein motor on a microtubule filament treats its movement as a random walk on a one-dimensional lattice. Let's extend this idea to a two-dimensional surface. Consider a molecule adsorbed on a large, flat crystalline surface, which we model as a 2D square lattice. The molecule starts at the origin, a designated lattice site. Due to thermal energy, it hops to an adjacent lattice site at regular time intervals. Specifically, from any given site, the molecule has an equal probability of moving to one of its four nearest neighbors (up, down, left, or right) in a single step.\n\nAfter a total of $N$ steps, we are interested in the probability, $P_{N}(\\text{origin})$, that the molecule is found back at the origin. For a very large number of steps ($N \\to \\infty$), this probability is known to follow a power-law scaling relationship:\n$$P_{N}(\\text{origin}) \\propto N^{-\\alpha}$$\nwhere $\\alpha$ is a constant scaling exponent.\n\nAssuming $N$ is a large even integer, determine the value of the exponent $\\alpha$.", "solution": "Let the random walk take place on a 2D Cartesian lattice. A step consists of a displacement by one of the four vectors: $(\\pm 1, 0)$ or $(0, \\pm 1)$. Let $n_R, n_L, n_U, n_D$ be the number of steps taken to the right, left, up, and down, respectively. The total number of steps is $N = n_R + n_L + n_U + n_D$.\n\nFor the molecule to return to the origin after $N$ steps, the net displacement in both the x and y directions must be zero. This imposes two conditions:\n1.  Number of steps right equals the number of steps left: $n_R = n_L$.\n2.  Number of steps up equals the number of steps down: $n_U = n_D$.\n\nLet's define $n_x = n_R = n_L$ and $n_y = n_U = n_D$. The total number of steps can then be written as $N = n_R + n_L + n_U + n_D = 2n_x + 2n_y = 2(n_x + n_y)$. This immediately shows that the particle can only return to the origin if the total number of steps $N$ is even. Let's set $N = 2m$, where $m = n_x + n_y$ is an integer.\n\nThe total number of possible paths of length $N$ is $4^N$, since there are 4 choices at each of the $N$ steps.\n\nNow, we must count the number of specific paths that return to the origin. This is a combinatorial problem. For a fixed partition of steps into x-moves ($2n_x$) and y-moves ($2n_y$), the number of ways to arrange these moves is given by:\n-   First, choose which of the $N=2m$ steps are in the x-direction: $\\binom{N}{2n_x} = \\binom{2m}{2n_x}$. The remaining $2n_y = 2(m-n_x)$ steps are in the y-direction.\n-   Within the $2n_x$ steps in the x-direction, we need $n_x$ steps to the right and $n_x$ steps to the left. The number of ways to arrange these is $\\binom{2n_x}{n_x}$.\n-   Similarly, within the $2n_y$ steps in the y-direction, the number of ways to arrange the $n_y$ up and $n_y$ down steps is $\\binom{2n_y}{n_y}$.\n\nThus, for a given $n_x$ (which also fixes $n_y=m-n_x$), the number of paths is the product: $\\binom{2m}{2n_x} \\binom{2n_x}{n_x} \\binom{2(m-n_x)}{m-n_x}$.\n\nTo get the total number of return paths, we must sum over all possible values of $n_x$, which can range from $0$ to $m$. Let $\\mathcal{N}_{\\text{return}}$ be the total number of return paths.\n$$ \\mathcal{N}_{\\text{return}} = \\sum_{n_x=0}^{m} \\binom{2m}{2n_x} \\binom{2n_x}{n_x} \\binom{2(m-n_x)}{m-n_x} $$\nLet's simplify the term inside the sum by expanding the binomial coefficients:\n$$ \\frac{(2m)!}{(2n_x)!(2(m-n_x))!} \\times \\frac{(2n_x)!}{(n_x!)^2} \\times \\frac{(2(m-n_x))!}{((m-n_x)!)^2} = \\frac{(2m)!}{(n_x!)^2 ((m-n_x)!)^2} $$\nWe can re-arrange this expression by multiplying and dividing by $(m!)^2$:\n$$ \\frac{(2m)!}{m! m!} \\frac{m! m!}{(n_x!)^2((m-n_x)!)^2} = \\binom{2m}{m} \\left( \\frac{m!}{n_x!(m-n_x)!} \\right)^2 = \\binom{2m}{m} \\left( \\binom{m}{n_x} \\right)^2 $$\nSo, the total number of returning paths is:\n$$ \\mathcal{N}_{\\text{return}} = \\sum_{n_x=0}^{m} \\binom{2m}{m} \\left( \\binom{m}{n_x} \\right)^2 = \\binom{2m}{m} \\sum_{n_x=0}^{m} \\left( \\binom{m}{n_x} \\right)^2 $$\nWe use the well-known combinatorial identity $\\sum_{k=0}^{n} \\binom{n}{k}^2 = \\binom{2n}{n}$. This identity can be proven by considering the coefficient of $x^n$ in the expansion of $(1+x)^n (1+x^{-1})^n$.\nApplying this identity with $n=m$ and $k=n_x$, we get $\\sum_{n_x=0}^{m} \\binom{m}{n_x}^2 = \\binom{2m}{m}$.\nTherefore, the total number of paths that return to the origin is:\n$$ \\mathcal{N}_{\\text{return}} = \\binom{2m}{m} \\binom{2m}{m} = \\left( \\binom{2m}{m} \\right)^2 $$\nThe probability of returning to the origin after $N=2m$ steps is:\n$$ P_{N}(\\text{origin}) = P_{2m}(\\text{origin}) = \\frac{\\mathcal{N}_{\\text{return}}}{4^N} = \\frac{\\left( \\binom{2m}{m} \\right)^2}{4^{2m}} $$\nNow, we need to find the asymptotic behavior for large $N$ (and thus large $m$). We use Stirling's approximation for the factorial, $k! \\approx \\sqrt{2\\pi k} (\\frac{k}{e})^k$.\nLet's approximate the central binomial coefficient $\\binom{2m}{m}$:\n$$ \\binom{2m}{m} = \\frac{(2m)!}{(m!)^2} \\approx \\frac{\\sqrt{2\\pi(2m)}(\\frac{2m}{e})^{2m}}{ \\left( \\sqrt{2\\pi m} (\\frac{m}{e})^{m} \\right)^2} = \\frac{\\sqrt{4\\pi m} (2m)^{2m} e^{-2m}}{2\\pi m (m^m)^2 e^{-2m}} = \\frac{2\\sqrt{\\pi m} 2^{2m} m^{2m}}{2\\pi m m^{2m}} = \\frac{4^m}{\\sqrt{\\pi m}} $$\nSubstituting this asymptotic form back into the probability expression:\n$$ P_{2m}(\\text{origin}) \\approx \\frac{1}{4^{2m}} \\left( \\frac{4^m}{\\sqrt{\\pi m}} \\right)^2 = \\frac{1}{4^{2m}} \\frac{(4^m)^2}{\\pi m} = \\frac{1}{4^{2m}} \\frac{4^{2m}}{\\pi m} = \\frac{1}{\\pi m} $$\nFinally, we substitute back $m = N/2$:\n$$ P_{N}(\\text{origin}) \\approx \\frac{1}{\\pi (N/2)} = \\frac{2}{\\pi N} $$\nThe problem states that for large $N$, the probability scales as $P_{N}(\\text{origin}) \\propto N^{-\\alpha}$.\nOur derivation gives $P_N(\\text{origin}) \\propto N^{-1}$.\nBy comparing the two expressions, we can identify the scaling exponent $\\alpha = 1$.", "answer": "$$\\boxed{1}$$", "id": "1895712"}]}