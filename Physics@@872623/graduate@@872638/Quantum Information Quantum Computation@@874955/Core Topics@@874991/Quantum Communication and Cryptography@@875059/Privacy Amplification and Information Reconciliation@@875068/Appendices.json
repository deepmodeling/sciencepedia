{"hands_on_practices": [{"introduction": "Low-Density Parity-Check (LDPC) codes are a cornerstone of modern, high-efficiency information reconciliation. Their performance is fundamentally tied to iterative decoding algorithms, like Belief Propagation, which can be visualized as passing messages on the code's Tanner graph. This exercise provides a concrete opportunity to analyze the performance of this decoding process, calculating the probability of failure for a single bit in a specific LDPC code over a Binary Erasure Channel (BEC). Mastering this type of analysis is a key step toward understanding the limits and capabilities of practical reconciliation schemes. [@problem_id:110643]", "problem": "In quantum key distribution (QKD), information reconciliation is a crucial step where two parties, Alice and Bob, correct errors in their shared, sifted key. This is often accomplished using classical error-correcting codes, such as Low-Density Parity-Check (LDPC) codes. The performance of these codes is typically analyzed over a simplified channel model relevant to the errors observed in the sifted key.\n\nAn LDPC code is a linear block code defined by a sparse binary parity-check matrix $H$. Its structure is conveniently represented by a Tanner graph, a bipartite graph with variable nodes representing the codeword bits and check nodes representing the parity-check equations. An edge connects a variable node $v_i$ to a check node $c_j$ if bit $i$ participates in check equation $j$.\n\nConsider a scenario where the shared key is modeled as a codeword transmitted over a Binary Erasure Channel (BEC), which erases each bit with a probability $p$ and transmits it correctly with probability $1-p$. To recover the erased bits (i.e., decode the codeword), an iterative message-passing algorithm called Belief Propagation (BP) is used. In the context of a BEC, the BP algorithm works as follows:\n- An erased variable node is recovered if at least one of its adjacent check nodes provides its correct value.\n- A check node can determine the value of an adjacent erased variable node if and only if all other variable nodes participating in that same check equation are known (i.e., not erased).\n\nConsider a specific regular (2,4) LDPC code, meaning every variable node has degree 2 and every check node has degree 4. The code has $N=8$ variable nodes, denoted $\\{v_1, \\dots, v_8\\}$, and $M=4$ check nodes, denoted $\\{c_1, \\dots, c_4\\}$. The Tanner graph of the code is defined by the following connectivity:\n- $c_1$ is connected to $\\{v_1, v_2, v_3, v_4\\}$.\n- $c_2$ is connected to $\\{v_5, v_6, v_7, v_8\\}$.\n- $c_3$ is connected to $\\{v_1, v_2, v_5, v_6\\}$.\n- $c_4$ is connected to $\\{v_3, v_4, v_7, v_8\\}$.\n\nA codeword generated from this code is sent over a BEC with erasure probability $p$. Your task is to calculate the probability that a randomly chosen variable node, given that it was initially erased, remains unrecovered after a single iteration of the belief propagation algorithm. Provide the answer as a closed-form analytical expression in terms of $p$.", "solution": "The problem involves a (2,4) regular LDPC code with $N=8$ variable nodes and $M=4$ check nodes. The Tanner graph is defined by:\n- $c_1$ connected to $\\{v_1, v_2, v_3, v_4\\}$\n- $c_2$ connected to $\\{v_5, v_6, v_7, v_8\\}$\n- $c_3$ connected to $\\{v_1, v_2, v_5, v_6\\}$\n- $c_4$ connected to $\\{v_3, v_4, v_7, v_8\\}$\n\nEach variable node has degree 2. The goal is to find the probability that a randomly chosen variable node, given it was initially erased on a BEC with erasure probability $p$, remains unrecovered after one iteration of the belief propagation algorithm.\n\nFor a variable node $v_i$ that is erased, it can be recovered if at least one of its adjacent check nodes provides its value. A check node $c_j$ adjacent to $v_i$ can recover $v_i$ only if all other variable nodes connected to $c_j$ are known (not erased).\n\nConsider an erased variable node $v_i$. Let $c_A$ and $c_B$ be its two adjacent check nodes. Define:\n- Event $A$: The three other variable nodes in $c_A$ are known.\n- Event $B$: The three other variable nodes in $c_B$ are known.\n\n$v_i$ is recovered if at least one of $A$ or $B$ occurs. The probability that $v_i$ remains unrecovered is:\n$$\nP(\\text{unrecovered} \\mid \\text{erased}) = 1 - P(A \\cup B \\mid \\text{erased})\n$$\nBy inclusion-exclusion:\n$$\nP(A \\cup B \\mid \\text{erased}) = P(A \\mid \\text{erased}) + P(B \\mid \\text{erased}) - P(A \\cap B \\mid \\text{erased})\n$$\n\nThe erasures are independent, and conditioning on $v_i$ being erased does not affect other nodes. Thus:\n$$\nP(A \\mid \\text{erased}) = P(\\text{three specific nodes known}) = (1-p)^3\n$$\nSimilarly, $P(B \\mid \\text{erased}) = (1-p)^3$.\n\nThe sets for $A$ and $B$ share exactly one common variable node. For example:\n- For $v_1$: $c_A = c_1$ (others: $\\{v_2, v_3, v_4\\}$), $c_B = c_3$ (others: $\\{v_2, v_5, v_6\\}$), sharing $v_2$.\n- Similarly, every $v_i$ has two sets of three other nodes sharing one node, so $A \\cap B$ requires five distinct nodes to be known.\n\nThus:\n$$\nP(A \\cap B \\mid \\text{erased}) = (1-p)^5\n$$\n\nSubstituting:\n$$\nP(A \\cup B \\mid \\text{erased}) = (1-p)^3 + (1-p)^3 - (1-p)^5 = 2(1-p)^3 - (1-p)^5\n$$\n\nTherefore:\n$$\nP(\\text{unrecovered} \\mid \\text{erased}) = 1 - \\left[ 2(1-p)^3 - (1-p)^5 \\right] = 1 - 2(1-p)^3 + (1-p)^5\n$$\n\nThis expression holds for any variable node due to symmetry.", "answer": "$$ \\boxed{1 - 2(1-p)^3 + (1-p)^5} $$", "id": "110643"}, {"introduction": "While modern systems often rely on LDPC codes, the Cascade protocol remains a classic and highly intuitive method for information reconciliation. A crucial part of implementing any such protocol is to precisely quantify the information that is inevitably leaked to an eavesdropper through public communication. This practice problem tasks you with calculating the total expected information leakage for a two-pass Cascade protocol, providing essential experience in the careful accounting required to guarantee the security of the final key after privacy amplification. [@problem_id:110716]", "problem": "In quantum key distribution (QKD), two parties, Alice and Bob, generate a shared secret key. Due to imperfections in the quantum channel or the presence of an eavesdropper, Bob's key is often a noisy version of Alice's. To establish an identical key, they perform a classical post-processing procedure consisting of information reconciliation and privacy amplification.\n\nInformation reconciliation aims to identify and correct the errors in their keys. A common protocol for this is the Cascade protocol. This protocol, however, leaks some information to a potential eavesdropper, Eve, as it involves public communication of parity bits. The amount of leaked information must be quantified to perform privacy amplification, a step where the key is shortened to remove any partial information Eve might have gained.\n\nConsider a simplified scenario where Alice and Bob share an $N$-bit sifted key. Bob's key contains exactly two bit-flip errors at random positions compared to Alice's key. They use a two-pass Cascade protocol for error correction. The protocol proceeds as follows:\n\n1.  **Pass 1:** The $N$-bit key is divided into $N/k_1$ blocks of size $k_1$. Alice and Bob exchange the parity of each block.\n    *   If a block's parity differs, it contains an odd number of errors. A binary search is performed on this block to locate and correct one error. This search reveals $\\log_2(k_1)$ additional parity bits.\n    *   If the two errors are located and corrected in this pass, the protocol terminates.\n    *   If the two errors are in the same block, their parities match the no-error case, so no errors are found in this pass. The protocol proceeds to Pass 2.\n\n2.  **Pass 2:** Before this pass, the entire $N$-bit key is randomly permuted in a way known to both Alice and Bob. This re-randomizes the positions of the two remaining errors. The key is then divided into $N/k_2$ blocks of size $k_2$, and the error correction procedure from Pass 1 is repeated with the new block size.\n    *   Binary search on a block of size $k_2$ in this pass reveals $\\log_2(k_2)$ additional parity bits.\n    *   If the errors are found, the protocol terminates. If not, the protocol terminates in failure, and the key is discarded.\n\nFor this problem, assume that the key length $N$ is a multiple of both block sizes $k_1$ and $k_2$, and that $k_1$ and $k_2$ are powers of 2. The initial positions of the two errors are chosen uniformly at random from all possible pairs of positions.\n\nThe total information leakage is defined as the total number of parity bits revealed over the public channel throughout the protocol's execution. Calculate the expected total information leakage, expressing your answer in terms of $N$, $k_1$, and $k_2$.", "solution": "The expected total information leakage in the two-pass Cascade protocol is derived by considering the different scenarios based on the initial positions of the two errors and the permutation in Pass 2. The leakage consists of initial block parity bits and additional parity bits from binary searches.\n\n**Step 1: Define probabilities and leakage components**\n- Let $q_1$ be the probability that the two errors are in the same block in Pass 1. The number of ways to choose two positions in the same block is $\\frac{N}{k_1} \\binom{k_1}{2}$, and the total number of ways to choose any two positions is $\\binom{N}{2}$. Thus,\n  \n$$\n  q_1 = \\frac{\\frac{N}{k_1} \\cdot \\frac{k_1(k_1-1)}{2}}{\\frac{N(N-1)}{2}} = \\frac{k_1-1}{N-1}.\n  $$\n\n  The probability that the errors are in different blocks in Pass 1 is $p_1 = 1 - q_1 = \\frac{N - k_1}{N-1}$.\n\n- If Pass 2 is reached (which happens with probability $q_1$), a random permutation is applied. The probability that the two errors are in the same block in Pass 2 is\n  \n$$\n  q_2 = \\frac{k_2-1}{N-1},\n  $$\n\n  and the probability they are in different blocks is $p_2 = 1 - q_2 = \\frac{N - k_2}{N-1}$.\n\n**Step 2: Leakage in Pass 1**\n- The initial block parities in Pass 1 always leak $\\frac{N}{k_1}$ bits.\n- If the errors are in different blocks (probability $p_1$), two binary searches are performed, each revealing $\\log_2 k_1$ bits, so an additional $2 \\log_2 k_1$ bits are leaked.\n- If the errors are in the same block (probability $q_1$), no binary search is performed, so no additional bits are leaked.\n- Thus, the leakage in Pass 1 is:\n  \n$$\n  L_1 = \\begin{cases}\n    \\frac{N}{k_1} + 2 \\log_2 k_1 & \\text{with probability } p_1, \\\\\n    \\frac{N}{k_1} & \\text{with probability } q_1.\n  \\end{cases}\n  $$\n\n\n**Step 3: Leakage in Pass 2 (only if Pass 1 fails)**\n- Pass 2 occurs with probability $q_1$. The initial block parities leak $\\frac{N}{k_2}$ bits.\n- If the errors are in different blocks in Pass 2 (probability $p_2$), two binary searches are performed, leaking an additional $2 \\log_2 k_2$ bits.\n- If they are in the same block (probability $q_2$), no binary search is performed.\n- Thus, the leakage in Pass 2 is:\n  \n$$\n  L_2 = \\begin{cases}\n    \\frac{N}{k_2} + 2 \\log_2 k_2 & \\text{with probability } p_2, \\\\\n    \\frac{N}{k_2} & \\text{with probability } q_2.\n  \\end{cases}\n  $$\n\n\n**Step 4: Expected total leakage**\nThe expected leakage is:\n\n$$\n\\mathbb{E}[L] = \\mathbb{E}[L_1] + q_1 \\cdot \\mathbb{E}[L_2],\n$$\n\nsince $L_2$ is leaked only if Pass 2 occurs (probability $q_1$).\n\n- Compute $\\mathbb{E}[L_1]$:\n  \n$$\n  \\mathbb{E}[L_1] = p_1 \\left( \\frac{N}{k_1} + 2 \\log_2 k_1 \\right) + q_1 \\left( \\frac{N}{k_1} \\right) = \\frac{N}{k_1} + 2 p_1 \\log_2 k_1.\n  $$\n\n\n- Compute $\\mathbb{E}[L_2]$:\n  \n$$\n  \\mathbb{E}[L_2] = p_2 \\left( \\frac{N}{k_2} + 2 \\log_2 k_2 \\right) + q_2 \\left( \\frac{N}{k_2} \\right) = \\frac{N}{k_2} + 2 p_2 \\log_2 k_2.\n  $$\n\n\n- Substitute:\n  \n$$\n  \\mathbb{E}[L] = \\left( \\frac{N}{k_1} + 2 p_1 \\log_2 k_1 \\right) + q_1 \\left( \\frac{N}{k_2} + 2 p_2 \\log_2 k_2 \\right).\n  $$\n\n\n**Step 5: Substitute probabilities**\n- $p_1 = \\frac{N - k_1}{N-1}$, $q_1 = \\frac{k_1 - 1}{N-1}$, $p_2 = \\frac{N - k_2}{N-1}$.\n- Thus,\n  \n$$\n  \\mathbb{E}[L] = \\frac{N}{k_1} + 2 \\cdot \\frac{N - k_1}{N-1} \\log_2 k_1 + \\frac{k_1 - 1}{N-1} \\left( \\frac{N}{k_2} + 2 \\cdot \\frac{N - k_2}{N-1} \\log_2 k_2 \\right).\n  $$\n\n\n**Step 6: Simplify the expression**\nExpand the terms:\n\n$$\n\\mathbb{E}[L] = \\frac{N}{k_1} + \\frac{2(N - k_1)}{N-1} \\log_2 k_1 + \\frac{k_1 - 1}{N-1} \\cdot \\frac{N}{k_2} + \\frac{k_1 - 1}{N-1} \\cdot 2 \\cdot \\frac{N - k_2}{N-1} \\log_2 k_2.\n$$\n\nSimplify the third term:\n\n$$\n\\frac{k_1 - 1}{N-1} \\cdot \\frac{N}{k_2} = \\frac{N(k_1 - 1)}{k_2(N-1)},\n$$\n\nand the fourth term:\n\n$$\n\\frac{k_1 - 1}{N-1} \\cdot 2 \\cdot \\frac{N - k_2}{N-1} \\log_2 k_2 = \\frac{2(k_1 - 1)(N - k_2)}{(N-1)^2} \\log_2 k_2.\n$$\n\nThe final expression is:\n\n$$\n\\mathbb{E}[L] = \\frac{N}{k_1} + \\frac{N(k_1 - 1)}{k_2(N-1)} + \\frac{2(N - k_1)}{N-1} \\log_2 k_1 + \\frac{2(k_1 - 1)(N - k_2)}{(N-1)^2} \\log_2 k_2.\n$$", "answer": "$$\\boxed{\\dfrac{N}{k_1} + \\dfrac{N(k_1 - 1)}{k_2(N-1)} + \\dfrac{2(N - k_1)}{N-1} \\log_2 k_1 + \\dfrac{2(k_1 - 1)(N - k_2)}{(N-1)^2} \\log_2 k_2}$$", "id": "110716"}, {"introduction": "Secure protocols are built by composing different cryptographic building blocks, and the security of the final system depends on how these components interact. This advanced exercise models a realistic protocol chain, including an imperfect error verification step followed by privacy amplification using a strong randomness extractor. By deriving the overall security of the final key, you will practice combining the probabilistic failure of one stage with the formal security guarantee of the next, a vital skill in the rigorous analysis of real-world cryptographic systems. [@problem_id:110609]", "problem": "In the post-processing stage of a Quantum Key Distribution (QKD) protocol, two parties, Alice and Bob, perform information reconciliation and privacy amplification to distill a secret key from their correlated raw data. This problem concerns the security analysis of this process.\n\nAfter an initial error correction step, Alice and Bob hold $n$-bit strings, $K_A$ and $K_B$. The a priori probability that their strings are not identical ($K_A \\neq K_B$) is $P_{err,0}$. To detect any discrepancy, they perform an error verification step. They publicly agree on a random matrix $H$ from a 2-universal family of hash functions mapping $\\{0,1\\}^n \\to \\{0,1\\}^c$. They then publicly compare the syndromes $H K_A$ and $H K_B$. If the syndromes are identical, the verification passes. This hash-based check has the property that if $K_A \\neq K_B$, the probability of the check passing is exactly $2^{-c}$. If $K_A=K_B$, the check always passes.\n\nConditioned on the verification passing, they proceed to privacy amplification.\nLet the quantum state of the system held by Alice, Bob, and an eavesdropper Eve, conditioned on the check passing, be $\\rho_{K_A K_B E}$. This state is a mixture of two scenarios:\n1.  The strings are identical, $K_A = K_B = K_{raw}$. In this case, the maximum probability for Eve to guess the raw key, given her quantum side information $E$, is $P_{guess}(K_{raw}|E) = P_g$.\n2.  The strings are different, $K_A \\neq K_B$. This corresponds to a failure of the verification step. In this worst-case scenario, the final key is considered completely insecure.\n\nFor privacy amplification, Alice and Bob use a non-malleable extractor, which we model as a strong randomness extractor secure against quantum side-information. They apply the same extractor function $Ext: \\{0,1\\}^n \\to \\{0,1\\}^m$ with a public seed to their respective keys to obtain final keys $S_A$ and $S_B$ of length $m$. The security of this extractor is given by the Quantum Leftover Hash Lemma: for a key $K_{raw}$ with conditional min-entropy $H_{min}(K_{raw}|E) = -\\log_2 P_{guess}(K_{raw}|E)$, the resulting state $\\rho_{S_A E}$ after extraction is $\\epsilon_{ext}$-close in trace distance to a state where the key is uniformly random and independent of Eve, i.e., $\\frac{1}{2} || \\rho_{S_A E} - U_m \\otimes \\rho_E ||_1 \\leq \\epsilon_{ext}$, with $\\epsilon_{ext} = \\frac{1}{2} \\sqrt{2^m P_g}$.\n\nThe overall security of the final key is quantified by the trace distance $\\epsilon_{sec} = \\frac{1}{2} || \\rho_{S_A S_B E} - \\rho_{ideal} ||_1$, where $\\rho_{S_A S_B E}$ is the final state of the system and $\\rho_{ideal} = U_m^{AB} \\otimes \\rho_E'$ is an ideal state where Alice and Bob share a perfect, uniform $m$-bit key ($U_m^{AB} = \\frac{1}{2^m} \\sum_s |s\\rangle\\langle s|_A \\otimes |s\\rangle\\langle s|_B$) that is completely uncorrelated with Eve's system $E'$.\n\nDerive a tight upper bound on the final security parameter $\\epsilon_{sec}$ for the entire protocol chain, expressed in terms of the initial error probability $P_{err,0}$, the verification hash length $c$, the final key length $m$, and the guessing probability $P_g$.", "solution": "1. Error verification passes with probability \n$$P_{\\mathrm{pass}}=(1-P_{err,0})+P_{err,0}\\,2^{-c}.$$\nConditioned on passing, the probability that $K_A\\neq K_B$ is \n$$p=\\Pr[K_A\\neq K_B\\mid\\text{pass}]\n=\\frac{P_{err,0}\\,2^{-c}}{P_{\\mathrm{pass}}},$$\nand $\\Pr[K_A=K_B\\mid\\text{pass}]=1-p$.\n\n2. By the Quantum Leftover Hash Lemma, on the “good’’ branch ($K_A=K_B$) the extractor yields \n$$\\frac12\\bigl\\|\\rho_{S_AE}-U_m\\otimes\\rho_E\\bigr\\|_1\\le\\epsilon_{\\mathrm{ext}}, \n\\quad\\epsilon_{\\mathrm{ext}}=\\tfrac12\\sqrt{2^mP_g}.$$\nOn the “bad’’ branch ($K_A\\neq K_B$) the key may be fully insecure (trace‐distance up to 1).\n\n3. Writing the post‐verification state as the mixture \n$$\\rho=\\!(1-p)\\,\\rho_{\\mathrm{good}}+p\\,\\rho_{\\mathrm{bad}}$$\nand the ideal state as \n$$\\rho_{\\mathrm{ideal}}=U_m^{AB}\\otimes\\rho_E',$$\nthe trace‐distance bound follows by convexity and the triangle inequality:\n$$\\tfrac12\\|\\rho-\\rho_{\\mathrm{ideal}}\\|_1\n\\le (1-p)\\,\\epsilon_{\\mathrm{ext}}+p\\cdot1\n=\\;p+(1-p)\\,\\epsilon_{\\mathrm{ext}}.$$\n\n4. Substituting $p=\\frac{P_{err,0}2^{-c}}{(1-P_{err,0})+P_{err,0}2^{-c}}$ and $\\epsilon_{\\mathrm{ext}}=\\tfrac12\\sqrt{2^mP_g}$ yields the tight bound.", "answer": "$$\\boxed{\\frac{P_{err,0}2^{-c}}{1-P_{err,0}+P_{err,0}2^{-c}}\n\\;+\\;\\frac{1-P_{err,0}}{1-P_{err,0}+P_{err,0}2^{-c}}\\;\\frac12\\sqrt{2^mP_g}}$$", "id": "110609"}]}