{"hands_on_practices": [{"introduction": "The subadditivity of von Neumann entropy, $S(\\rho_{AB}) \\le S(\\rho_A) + S(\\rho_B)$, is a cornerstone of quantum information theory, establishing that the uncertainty of a whole system is no more than the sum of the uncertainties of its parts. This exercise [@problem_id:85502] provides hands-on practice in verifying this principle by calculating the \"subadditivity slack\"—the quantum mutual information $I(A:B)$—for the canonical family of two-qubit Werner states. Mastering this calculation is key to understanding how correlations reduce the total entropy of a composite system.", "problem": "Consider a bipartite quantum system composed of two qubits, A and B. The state of the system is described by a two-qubit Werner state, which is a mixture of a pure entangled state and a maximally mixed state. The density matrix is given by\n$$\n\\rho_{AB}(p) = p |\\Psi^-\\rangle\\langle\\Psi^-| + \\frac{1-p}{4} I_{AB}\n$$\nwhere $p$ is a real parameter such that $0 \\le p \\le 1$. Here, $|\\Psi^-\\rangle$ is the singlet Bell state, $|\\Psi^-\\rangle = \\frac{1}{\\sqrt{2}}(|01\\rangle - |10\\rangle)$, and $I_{AB}$ is the identity operator on the four-dimensional Hilbert space $\\mathcal{H}_A \\otimes \\mathcal{H}_B$.\n\nThe von Neumann entropy of a quantum state $\\rho$ is defined as $S(\\rho) = -\\mathrm{Tr}(\\rho \\log_2 \\rho)$, where $\\log_2$ is the base-2 logarithm. The entropy of the subsystems A and B is calculated from their reduced density matrices, $\\rho_A = \\mathrm{Tr}_B(\\rho_{AB})$ and $\\rho_B = \\mathrm{Tr}_A(\\rho_{AB})$.\n\nThe subadditivity inequality for von Neumann entropy states that $S(\\rho_{AB}) \\le S(\\rho_A) + S(\\rho_B)$. The \"subadditivity slack\" is defined as the difference $\\Delta S(A,B) = S(\\rho_A) + S(\\rho_B) - S(\\rho_{AB})$, which is also known as the quantum mutual information $I(A:B)$.\n\nYour task is to calculate the subadditivity slack $\\Delta S(A,B)$ for the Werner state $\\rho_{AB}(p)$ as a function of the parameter $p$.", "solution": "The problem asks for the calculation of the subadditivity slack $\\Delta S(A,B) = S(\\rho_A) + S(\\rho_B) - S(\\rho_{AB})$ for the Werner state $\\rho_{AB}(p) = p |\\Psi^-\\rangle\\langle\\Psi^-| + \\frac{1-p}{4} I_{AB}$.\n\n**Step 1: Calculate the entropy of the composite system, $S(\\rho_{AB})$.**\n\nTo compute the von Neumann entropy $S(\\rho_{AB}) = -\\sum_i \\lambda_i \\log_2 \\lambda_i$, we first need the eigenvalues $\\lambda_i$ of the density matrix $\\rho_{AB}(p)$. Let's write $\\rho_{AB}(p)$ in the standard computational basis $\\{|00\\rangle, |01\\rangle, |10\\rangle, |11\\rangle\\}$.\n\nThe singlet state projector is:\n$|\\Psi^-\\rangle\\langle\\Psi^-| = \\frac{1}{2}(|01\\rangle - |10\\rangle)(\\langle01| - \\langle10|) = \\frac{1}{2}(|01\\rangle\\langle01| - |01\\rangle\\langle10| - |10\\rangle\\langle01| + |10\\rangle\\langle10|)$.\nIn matrix form, this is:\n$$\nP_{\\Psi^-} = \\begin{pmatrix} 0 & 0 & 0 & 0 \\\\ 0 & 1/2 & -1/2 & 0 \\\\ 0 & -1/2 & 1/2 & 0 \\\\ 0 & 0 & 0 & 0 \\end{pmatrix}\n$$\nThe identity matrix is $I_{AB} = \\mathrm{diag}(1,1,1,1)$. So, the Werner state is:\n$$\n\\rho_{AB}(p) = p P_{\\Psi^-} + \\frac{1-p}{4} I_{AB} = \\begin{pmatrix}\n\\frac{1-p}{4} & 0 & 0 & 0 \\\\\n0 & \\frac{p}{2} + \\frac{1-p}{4} & -\\frac{p}{2} & 0 \\\\\n0 & -\\frac{p}{2} & \\frac{p}{2} + \\frac{1-p}{4} & 0 \\\\\n0 & 0 & 0 & \\frac{1-p}{4}\n\\end{pmatrix}\n= \\begin{pmatrix}\n\\frac{1-p}{4} & 0 & 0 & 0 \\\\\n0 & \\frac{1+p}{4} & -\\frac{p}{2} & 0 \\\\\n0 & -\\frac{p}{2} & \\frac{1+p}{4} & 0 \\\\\n0 & 0 & 0 & \\frac{1-p}{4}\n\\end{pmatrix}\n$$\nThis matrix is block-diagonal. Two eigenvalues are immediately apparent: $\\lambda_1 = \\lambda_2 = \\frac{1-p}{4}$.\nThe other two eigenvalues come from the central 2x2 block:\n$$ M = \\begin{pmatrix} \\frac{1+p}{4} & -\\frac{p}{2} \\\\ -\\frac{p}{2} & \\frac{1+p}{4} \\end{pmatrix} $$\nThe characteristic equation is $\\det(M - \\lambda I) = 0$:\n$$ \\left(\\frac{1+p}{4} - \\lambda\\right)^2 - \\left(-\\frac{p}{2}\\right)^2 = 0 \\implies \\left(\\frac{1+p}{4} - \\lambda\\right)^2 = \\frac{p^2}{4} $$\nTaking the square root gives $\\frac{1+p}{4} - \\lambda = \\pm \\frac{p}{2}$.\nThe solutions for $\\lambda$ are:\n$$ \\lambda = \\frac{1+p}{4} \\mp \\frac{p}{2} = \\frac{1+p \\mp 2p}{4} $$\nThis gives the remaining two eigenvalues: $\\lambda_3 = \\frac{1+3p}{4}$ and $\\lambda_4 = \\frac{1-p}{4}$.\nSo, the set of four eigenvalues of $\\rho_{AB}(p)$ is $\\left\\{ \\frac{1+3p}{4}, \\frac{1-p}{4}, \\frac{1-p}{4}, \\frac{1-p}{4} \\right\\}$.\n\nThe von Neumann entropy is:\n$$ S(\\rho_{AB}) = -\\left[ \\frac{1+3p}{4} \\log_2\\left(\\frac{1+3p}{4}\\right) + 3 \\cdot \\frac{1-p}{4} \\log_2\\left(\\frac{1-p}{4}\\right) \\right] $$\nUsing $\\log_2(x/y) = \\log_2(x) - \\log_2(y)$ and $\\log_2(4)=2$:\n$$ S(\\rho_{AB}) = -\\frac{1+3p}{4}(\\log_2(1+3p)-2) - \\frac{3(1-p)}{4}(\\log_2(1-p)-2) $$\n$$ S(\\rho_{AB}) = 2\\frac{1+3p}{4} + 2\\frac{3(1-p)}{4} - \\frac{1+3p}{4}\\log_2(1+3p) - \\frac{3(1-p)}{4}\\log_2(1-p) $$\n$$ S(\\rho_{AB}) = \\frac{2(1+3p) + 6(1-p)}{4} - \\frac{1}{4}\\left[(1+3p)\\log_2(1+3p) + 3(1-p)\\log_2(1-p)\\right] $$\n$$ S(\\rho_{AB}) = \\frac{2+6p+6-6p}{4} - \\frac{1}{4}\\left[(1+3p)\\log_2(1+3p) + 3(1-p)\\log_2(1-p)\\right] $$\n$$ S(\\rho_{AB}) = 2 - \\frac{1}{4}\\left[(1+3p)\\log_2(1+3p) + 3(1-p)\\log_2(1-p)\\right] $$\n\n**Step 2: Calculate the entropies of the reduced systems, $S(\\rho_A)$ and $S(\\rho_B)$.**\n\nWe need to compute the reduced density matrix $\\rho_A = \\mathrm{Tr}_B(\\rho_{AB})$.\n$$ \\rho_A = \\mathrm{Tr}_B\\left( p |\\Psi^-\\rangle\\langle\\Psi^-| + \\frac{1-p}{4} I_{AB} \\right) = p \\mathrm{Tr}_B(|\\Psi^-\\rangle\\langle\\Psi^-|) + \\frac{1-p}{4} \\mathrm{Tr}_B(I_A \\otimes I_B) $$\nLet's compute the two terms separately.\nThe second term: $\\mathrm{Tr}_B(I_A \\otimes I_B) = I_A \\cdot \\mathrm{Tr}(I_B) = I_A \\cdot 2 = 2 I_A$.\nThe first term:\n$|\\Psi^-\\rangle\\langle\\Psi^-| = \\frac{1}{2} ( |0\\rangle\\langle0|_A \\otimes |1\\rangle\\langle1|_B - |0\\rangle\\langle1|_A \\otimes |1\\rangle\\langle0|_B - |1\\rangle\\langle0|_A \\otimes |0\\rangle\\langle1|_B + |1\\rangle\\langle1|_A \\otimes |0\\rangle\\langle0|_B )$\nTaking the partial trace over B (using $\\mathrm{Tr}(|i\\rangle_B\\langle j|_B) = \\delta_{ij}$):\n$$ \\mathrm{Tr}_B(|\\Psi^-\\rangle\\langle\\Psi^-|) = \\frac{1}{2}(|0\\rangle\\langle0|_A \\cdot 1 - |0\\rangle\\langle1|_A \\cdot 0 - |1\\rangle\\langle0|_A \\cdot 0 + |1\\rangle\\langle1|_A \\cdot 1) = \\frac{1}{2}(|0\\rangle\\langle0|_A + |1\\rangle\\langle1|_A) = \\frac{1}{2}I_A $$\nCombining the terms:\n$$ \\rho_A = p \\left(\\frac{1}{2}I_A\\right) + \\frac{1-p}{4} (2I_A) = \\left(\\frac{p}{2} + \\frac{1-p}{2}\\right)I_A = \\frac{1}{2}I_A $$\nSo, the reduced state for qubit A is the maximally mixed state. Its matrix form is $\\rho_A = \\begin{pmatrix} 1/2 & 0 \\\\ 0 & 1/2 \\end{pmatrix}$.\nThe eigenvalues of $\\rho_A$ are $1/2$ and $1/2$. The entropy is:\n$$ S(\\rho_A) = - \\left(\\frac{1}{2}\\log_2\\frac{1}{2} + \\frac{1}{2}\\log_2\\frac{1}{2}\\right) = -2\\left(\\frac{1}{2}(-1)\\right) = 1 $$\nDue to the symmetry of the Werner state $\\rho_{AB}(p)$ under particle exchange, $\\rho_B = \\mathrm{Tr}_A(\\rho_{AB})$ is also the maximally mixed state, so $S(\\rho_B)=1$.\n\n**Step 3: Calculate the subadditivity slack.**\n\nThe subadditivity slack is $\\Delta S(A,B) = S(\\rho_A) + S(\\rho_B) - S(\\rho_{AB})$.\n$$ \\Delta S(p) = 1 + 1 - S(\\rho_{AB}) = 2 - S(\\rho_{AB}) $$\nSubstituting the expression for $S(\\rho_{AB})$ from Step 1:\n$$ \\Delta S(p) = 2 - \\left( 2 - \\frac{1}{4}\\left[(1+3p)\\log_2(1+3p) + 3(1-p)\\log_2(1-p)\\right] \\right) $$\n$$ \\Delta S(p) = \\frac{1}{4}\\left[(1+3p)\\log_2(1+3p) + 3(1-p)\\log_2(1-p)\\right] $$\nThis is the final expression for the subadditivity slack as a function of $p$.", "answer": "$$ \\boxed{\\frac{1}{4}\\left[ (1+3p)\\log_2(1+3p) + 3(1-p)\\log_2(1-p) \\right]} $$", "id": "85502"}, {"introduction": "Beyond static properties of states, entropy inequalities also govern the flow of information through quantum processes. The Data Processing Inequality (DPI), $S(\\rho||\\sigma) \\ge S(\\mathcal{E}(\\rho)||\\mathcal{E}(\\sigma))$, is a fundamental statement that distinguishability between quantum states, as measured by relative entropy, cannot increase under any quantum channel. This practice [@problem_id:85361] invites you to quantify this irreversible loss of information by calculating the slack in the DPI for two initial states passing through an amplitude damping channel, a key model for energy dissipation.", "problem": "The quantum relative entropy between two density matrices $\\rho$ and $\\sigma$ is given by $S(\\rho||\\sigma) = \\mathrm{Tr}(\\rho(\\ln\\rho - \\ln\\sigma))$, where $\\ln$ denotes the natural logarithm. A fundamental property of the relative entropy is the Data Processing Inequality (DPI), which states that for any quantum channel (a completely positive trace-preserving map) $\\mathcal{E}$, the relative entropy between two states cannot increase after they pass through the channel:\n$$ S(\\rho||\\sigma) \\ge S(\\mathcal{E}(\\rho)||\\mathcal{E}(\\sigma)) $$\nThis inequality implies that physical processes, modeled by quantum channels, lead to a loss of distinguishability between quantum states. The slack in the DPI, defined as $\\Delta S = S(\\rho||\\sigma) - S(\\mathcal{E}(\\rho)||\\mathcal{E}(\\sigma))$, quantifies this loss.\n\nConsider a single-qubit system undergoing amplitude damping. The amplitude damping channel $\\mathcal{E}$ with decay probability $\\gamma \\in [0, 1]$ is described by the Kraus operators:\n$$ E_0 = \\begin{pmatrix} 1 & 0 \\\\ 0 & \\sqrt{1-\\gamma} \\end{pmatrix}, \\quad E_1 = \\begin{pmatrix} 0 & \\sqrt{\\gamma} \\\\ 0 & 0 \\end{pmatrix} $$\nacting on the standard computational basis $\\{|0\\rangle, |1\\rangle\\}$. The action of the channel on a state $\\rho$ is $\\mathcal{E}(\\rho) = E_0 \\rho E_0^\\dagger + E_1 \\rho E_1^\\dagger$.\n\nLet the initial states be the pure excited state $\\rho = |1\\rangle\\langle1|$ and the maximally mixed state $\\sigma = I/2$, where $I$ is the $2\\times2$ identity matrix.\n\nCompute the slack in the data processing inequality, $\\Delta S$, for this channel and these initial states as a function of the decay probability $\\gamma$.", "solution": "1. Given states \n$$\\rho=|1\\rangle\\langle1|,\\quad \\sigma=\\frac I2,$$ \nthe relative entropy is \n$$S(\\rho\\|\\sigma)=\\mathrm{Tr}\\bigl(\\rho(\\ln\\rho-\\ln\\sigma)\\bigr).$$ \nSince $\\rho$ is pure, $S(\\rho)=-\\mathrm{Tr}(\\rho\\ln\\rho)=0$, and \n$$\\ln\\sigma=\\ln\\Bigl(\\tfrac12I\\Bigr)=-\\ln2\\;I,$$ \nso \n$$S(\\rho\\|\\sigma)=-\\mathrm{Tr}\\bigl(\\rho\\ln\\sigma\\bigr)\n=-\\bigl(-\\ln2\\bigr)\\mathrm{Tr}\\rho=\\ln2.$$\n\n2. The amplitude-damping channel acts as\n$$\\mathcal{E}(\\rho)=E_0\\rho E_0^\\dagger+E_1\\rho E_1^\\dagger\n=\\gamma\\,|0\\rangle\\langle0|+(1-\\gamma)\\,|1\\rangle\\langle1|,$$\n$$\\mathcal{E}(\\sigma)=\\frac12\\bigl(E_0E_0^\\dagger+E_1E_1^\\dagger\\bigr)\n=\\begin{pmatrix}\\frac{1+\\gamma}2&0\\\\0&\\frac{1-\\gamma}2\\end{pmatrix}.$$\n\n3. Writing $q=\\gamma$, $p=1-\\gamma$, and \n$$\\mathcal{E}(\\rho)=\\mathrm{diag}(q,p),\\quad \\mathcal{E}(\\sigma)=\\mathrm{diag}\\Bigl(\\tfrac{1+q}2,\\tfrac p2\\Bigr),$$ \nthe relative entropy is\n\n$$\nS\\bigl(\\mathcal{E}(\\rho)\\|\\mathcal{E}(\\sigma)\\bigr)\n=q\\ln\\frac{q}{(1+q)/2}+p\\ln\\frac{p}{p/2}\n=q\\ln\\frac{2q}{1+q}+p\\ln2\n=\\ln2+q\\ln\\frac{q}{1+q}.\n$$\n\n\n4. Therefore the slack is\n\n$$\n\\Delta S\n=S(\\rho\\|\\sigma)-S\\bigl(\\mathcal{E}(\\rho)\\|\\mathcal{E}(\\sigma)\\bigr)\n=\\ln2-\\Bigl(\\ln2+q\\ln\\frac{q}{1+q}\\Bigr)\n=-q\\ln\\frac{q}{1+q}\n=\\gamma\\ln\\frac{1+\\gamma}{\\gamma}.\n$$", "answer": "$$\\boxed{\\gamma\\ln\\frac{1+\\gamma}{\\gamma}}$$", "id": "85361"}, {"introduction": "Modern entropy inequalities have profoundly reshaped our understanding of the uncertainty principle, particularly in the presence of entanglement. The Berta-Christandl-Renner inequality, $S(X|B) + S(Z|B) \\ge 1 + S(A|B)$, reveals that an observer holding a quantum memory entangled with a measured system can predict measurement outcomes with much lower uncertainty. This problem [@problem_id:85395] explores this landmark result by having you compute how the uncertainty bound changes when the quantum memory is degraded by a depolarizing channel, providing a quantitative look at the interplay between entanglement, uncertainty, and decoherence.", "problem": "The entropic uncertainty principle in the presence of quantum memory, as formulated by Berta, Christandl, and Renner, provides a lower bound on the uncertainty of the outcomes of two incompatible measurements performed by Alice on a qubit A, conditioned on the information held by Bob in a quantum memory B. For measurements in the Pauli-X ($X$-eigenbasis $\\{|+\\rangle, |-\\rangle\\}$) and Pauli-Z ($Z$-eigenbasis $\\{|0\\rangle, |1\\rangle\\}$) bases, the relation is given by:\n$$S(X|B) + S(Z|B) \\ge 1 + S(A|B)$$\nHere, $S(K|B) = S(KB) - S(B)$ represents the conditional von Neumann entropy of the classical measurement outcome $K \\in \\{X, Z\\}$ given the quantum system B. The total state of the measurement outcome and system B is denoted by $\\rho_{KB}$. The term $S(A|B) = S(AB) - S(B)$ is the conditional von Neumann entropy of Alice's qubit A given Bob's system B, derived from their joint state $\\rho_{AB}$. All logarithms are base 2.\n\nLet's define the uncertainty quantity $L_B = S(X|B) + S(Z|B) - S(A|B)$, which according to the inequality must satisfy $L_B \\ge 1$.\n\nConsider an initial scenario where Alice and Bob share a maximally entangled Bell state:\n$$|\\Phi^+\\rangle_{AB} = \\frac{1}{\\sqrt{2}}(|00\\rangle_{AB} + |11\\rangle_{AB})$$\nThe initial state is $\\rho_{AB} = |\\Phi^+\\rangle\\langle\\Phi^+\\!|_{AB}$.\n\nNow, Bob sends his qubit (system B) through a depolarizing channel $\\mathcal{E}$ to a third party, Charlie, who receives system C. The action of the depolarizing channel on a single-qubit state $\\sigma$ is given by:\n$$\\mathcal{E}(\\sigma) = (1-p)\\sigma + p\\frac{\\mathbb{I}}{2}$$\nwhere $p$ is the depolarizing probability and $\\mathbb{I}$ is the $2 \\times 2$ identity matrix. The state shared by Alice and Charlie after the channel is $\\rho_{AC} = (\\mathcal{I}_A \\otimes \\mathcal{E}_B)(\\rho_{AB})$.\n\nThe uncertainty quantity for the final configuration is $L_C = S(X|C) + S(Z|C) - S(A|C)$.\n\nFor a depolarizing probability of $p = 2/3$, calculate the change in the uncertainty quantity, $\\Delta L = L_C - L_B$.", "solution": "1. **Initial State Calculation ($L_B$)**\nFor the initial Bell state $\\rho_{AB}=|\\Phi^+\\rangle\\langle\\Phi^+|$, we have $S(AB)=0$ and the reduced state $\\rho_B = \\mathbb{I}/2$ with $S(B)=1$. Thus, $S(A|B)=S(AB)-S(B)=-1$.\nWhen Alice measures, her outcome is random, but Bob's state collapses to a pure state correlated with hers. The entropy of the joint classical-quantum state is $S(ZB) = H_2(1/2) + \\sum p_z S(\\rho_{B|z}) = 1+0=1$. So, $S(Z|B)=S(ZB)-S(B)=1-1=0$. Similarly, $S(X|B)=0$.\nThe initial uncertainty quantity is $L_B = S(X|B) + S(Z|B) - S(A|B) = 0+0-(-1)=1$.\n\n2. **Final State Calculation ($\\rho_{AC}$)**\nApplying the depolarizing channel with $p=2/3$ to qubit B results in the Werner state $\\rho_{AC}=(1-p)|\\Phi^+\\rangle\\langle\\Phi^+|+\\frac{p}{4}I_{AC}$.\nFor $p=2/3$, this is $\\rho_{AC} = \\frac{1}{3}|\\Phi^+\\rangle\\langle\\Phi^+| + \\frac{1}{6}I_{AC}$.\nThe eigenvalues of this state are $\\{1/2, 1/6, 1/6, 1/6\\}$.\nThe entropy is $S(AC)=-\\frac{1}{2}\\log_2\\frac{1}{2}-3\\cdot\\frac{1}{6}\\log_2\\frac{1}{6} = \\frac{1}{2} + \\frac{1}{2}\\log_2 6 = \\frac{1+\\log_2 6}{2}$.\nThe marginal state $\\rho_C=\\mathrm{Tr}_A(\\rho_{AC})=\\mathbb{I}/2$, so $S(C)=1$.\n\n3. **Final Uncertainty Calculation ($L_C$)**\nWe use the relation $L_C=S(XC)+S(ZC)-S(AC)-S(C)$.\nWhen Alice measures in the Z-basis, the outcomes $z \\in \\{0,1\\}$ occur with probability $1/2$. The post-measurement state on C is $\\rho_{C|z}=(1-p)|z\\rangle\\langle z|+ \\frac{p}{2}\\mathbb{I}$.\nFor $p=2/3$, $\\rho_{C|z} = \\frac{1}{3}|z\\rangle\\langle z| + \\frac{1}{3}\\mathbb{I}$. The matrix is $\\mathrm{diag}(2/3, 1/3)$, with entropy $S(\\rho_{C|z}) = H_2(1/3)$.\nThe entropy of the joint state $\\rho_{ZC}$ is $S(ZC) = H_2(1/2) + S(\\rho_{C|z}) = 1+H_2(1/3)$.\nBy symmetry, $S(XC)=1+H_2(1/3)$ as well.\nNow we can assemble $L_C$:\n$$ L_C = S(XC) + S(ZC) - S(AC) - S(C) $$\n$$ L_C = (1+H_2(1/3)) + (1+H_2(1/3)) - \\frac{1+\\log_2 6}{2} - 1 = 1+2H_2(1/3)-\\frac{1+\\log_2 6}{2} $$\n\n4. **Change in Uncertainty ($\\Delta L$)**\nThe change is $\\Delta L = L_C - L_B$:\n$$ \\Delta L = \\left(1+2H_2(1/3)-\\frac{1+\\log_2 6}{2}\\right) - 1 = 2H_2(1/3)-\\frac{1+\\log_2 6}{2} $$\nTo get a numerical value, we expand the terms:\n- The binary entropy is $H_2(1/3) = -\\frac{1}{3}\\log_2\\frac{1}{3} - \\frac{2}{3}\\log_2\\frac{2}{3} = \\frac{1}{3}\\log_2 3 - \\frac{2}{3}(\\log_2 2 - \\log_2 3) = \\log_2 3 - \\frac{2}{3}$.\n- The logarithm is $\\log_2 6 = \\log_2(2 \\cdot 3) = 1 + \\log_2 3$.\nSubstituting these into the expression for $\\Delta L$:\n$$ \\Delta L = 2\\left(\\log_2 3 - \\frac{2}{3}\\right) - \\frac{1+(1+\\log_2 3)}{2} $$\n$$ \\Delta L = 2\\log_2 3 - \\frac{4}{3} - \\frac{2+\\log_2 3}{2} = 2\\log_2 3 - \\frac{4}{3} - 1 - \\frac{1}{2}\\log_2 3 $$\n$$ \\Delta L = \\frac{3}{2}\\log_2 3 - \\frac{7}{3} $$\nFinding a common denominator of 6 gives the final answer:\n$$ \\Delta L = \\frac{9}{6}\\log_2 3 - \\frac{14}{6} = \\frac{9\\log_2 3 - 14}{6} $$", "answer": "$$\\boxed{\\frac{9\\log_2 3 - 14}{6}}$$", "id": "85395"}]}