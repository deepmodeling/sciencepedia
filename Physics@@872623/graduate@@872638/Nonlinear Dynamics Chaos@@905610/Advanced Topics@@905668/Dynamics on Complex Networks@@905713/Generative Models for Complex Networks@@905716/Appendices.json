{"hands_on_practices": [{"introduction": "The configuration model is a cornerstone for generating random networks with a predetermined degree sequence. This exercise provides a concrete, hands-on calculation to demystify the model's \"stub-matching\" mechanism [@problem_id:876883]. By calculating the probability of forming a specific small graph, you will gain a deeper intuition for the combinatorial nature of this model and understand how it can produce both desired structures and artifacts like multi-edges or self-loops.", "problem": "In the study of complex networks, the configuration model is a generative algorithm for constructing a random graph with a specified degree sequence. Consider a set of $N$ nodes, where each node $i$ is assigned a degree $k_i$. To generate a graph, each node $i$ is given $k_i$ \"stubs\" or \"half-edges\". The total number of stubs in the network is $L = \\sum_{i=1}^N k_i$, which must be even. A random graph is then formed by choosing a perfect matching on the set of $L$ stubs, where each possible perfect matching is equally likely. This process can produce graphs with multi-edges (multiple edges between the same two nodes) and self-loops (edges connecting a node to itself).\n\nA \"paw graph\" is a simple graph with four vertices and four edges, consisting of a triangle with a pendant node attached to one of the triangle's vertices. The degree sequence of a paw graph is $\\{3, 2, 2, 1\\}$.\n\nConsider a configuration model with $N=4$ labeled nodes $\\{v_1, v_2, v_3, v_4\\}$ and a prescribed degree sequence $\\{k_1, k_2, k_3, k_4\\} = \\{3, 2, 2, 1\\}$. Any simple graph generated from this model must be isomorphic to a paw graph, with $v_1$ being the degree-3 center, $v_4$ the degree-1 pendant node, and $v_2, v_3$ the other two degree-2 nodes of the triangle.\n\nCalculate the exact probability that the stub-matching procedure for this degree sequence results in a simple graph (i.e., the paw graph).", "solution": "We label the stubs of each node $i$ by $s_{i,1},\\dots,s_{i,k_i}$.  The total number of stubs is\n$$\nL=\\sum_{i=1}^4k_i=3+2+2+1=8.\n$$\n1. Total number of perfect matchings on $L$ labeled stubs is\n$$\n(8-1)!!=7\\cdot5\\cdot3\\cdot1=105.\n$$\n2. We count favorable matchings that yield the paw graph on $\\{v_1,v_2,v_3,v_4\\}$ with edges\n$$\n\\{v_1v_2,\\;v_1v_3,\\;v_1v_4,\\;v_2v_3\\}.\n$$\n(a) Pair one of the $3$ stubs of $v_1$ with the unique stub of $v_4$: $3$ choices.  \n(b) Of the remaining $2$ stubs of $v_1$, choose one to pair with $v_2$: $2$ choices; then choose which of the $2$ stubs of $v_2$ to use: $2$ choices.  \n(c) The last stub of $v_1$ pairs with one of the $2$ stubs of $v_3$: $2$ choices.  \n(d) Finally, the remaining single stub of $v_2$ pairs with the remaining single stub of $v_3$: $1$ way.  \nHence the total number of favorable matchings is\n$$\n3\\times2\\times2\\times2\\times1=24.\n$$\n3. Therefore the probability of obtaining the simple paw graph is\n$$\n\\frac{24}{105}=\\frac{8}{35}.\n$$", "answer": "$$\\boxed{\\frac{8}{35}}$$", "id": "876883"}, {"introduction": "Shifting from algorithmic construction to a statistical physics perspective, Exponential Random Graph Models (ERGMs) define a probability distribution over an entire ensemble of graphs. This practice problem illustrates the core idea of ERGMs: a network's probability is a function of its structural features, such as edges and star-shaped motifs [@problem_id:876917]. By comparing the relative probabilities of two different network structures, you will learn how model parameters ($\\theta$) assign weight to these features, a technique that cleverly avoids the notoriously difficult calculation of the partition function.", "problem": "Exponential Random Graph Models (ERGMs) provide a statistical framework for modeling the structure of complex networks. In an ERGM, a probability distribution is defined over the set of all possible graphs $\\mathcal{G}_N$ on a fixed number of $N$ vertices. The probability of observing a particular graph $G$ from this ensemble is given by:\n$$\nP(G) = \\frac{1}{Z} \\exp\\left(H(G)\\right)\n$$\nwhere $H(G)$ is the graph Hamiltonian, and $Z = \\sum_{G' \\in \\mathcal{G}_N} \\exp\\left(H(G')\\right)$ is the partition function that normalizes the distribution.\n\nThe Hamiltonian is a linear combination of various graph statistics (also called network observables), $s_k(G)$:\n$$\nH(G) = \\sum_k \\theta_k s_k(G)\n$$\nwhere $\\theta_k$ are the model parameters that determine the importance of each statistic.\n\nConsider an ERGM for undirected graphs on $N=5$ vertices, defined by two statistics: the number of edges, $L(G)$, and the number of 2-stars, $S_2(G)$. The Hamiltonian is given by:\n$$\nH(G) = \\theta_L L(G) + \\theta_S S_2(G)\n$$\nA 2-star is a subgraph consisting of three vertices $\\{i,j,k\\}$ where vertex $j$ is connected to both $i$ and $k$, but there is no edge between $i$ and $k$. The total number of 2-stars in a graph $G$ with vertex set $V$ can be calculated as $S_2(G) = \\sum_{j \\in V} \\binom{d_j}{2}$, where $d_j$ is the degree of vertex $j$.\n\nYour task is to compute the probability ratio $\\frac{P(C_5)}{P(P_5)}$, where $C_5$ is the cycle graph on 5 vertices and $P_5$ is the path graph on 5 vertices. Express your answer as an analytic function of the parameters $\\theta_L$ and $\\theta_S$.", "solution": "1. The probability ratio is\n$$\n\\frac{P(C_5)}{P(P_5)}\n=\\frac{\\exp\\bigl(H(C_5)\\bigr)}{\\exp\\bigl(H(P_5)\\bigr)}\n=\\exp\\bigl(H(C_5)-H(P_5)\\bigr).\n$$\n2. Compute edge counts:\n$$\nL(C_5)=5,\\quad L(P_5)=4.\n$$\n3. Compute 2-star counts using $S_2(G)=\\sum_{j}\\binom{d_j}{2}$.\n- For $C_5$, each vertex has $d_j=2$, so\n$$\nS_2(C_5)=5\\binom{2}{2}=5.\n$$\n- For $P_5$, two endpoints have $d_j=1$ and three internal vertices have $d_j=2$, so\n$$\nS_2(P_5)=2\\binom{1}{2}+3\\binom{2}{2}=0+3=3.\n$$\n4. The Hamiltonian difference is\n$$\nH(C_5)-H(P_5)\n=\\theta_L\\bigl(5-4\\bigr)+\\theta_S\\bigl(5-3\\bigr)\n=\\theta_L+2\\theta_S.\n$$\n5. Therefore,\n$$\n\\frac{P(C_5)}{P(P_5)}=\\exp\\bigl(\\theta_L+2\\theta_S\\bigr).\n$$", "answer": "$$\\boxed{\\exp\\bigl(\\theta_L+2\\theta_S\\bigr)}$$", "id": "876917"}, {"introduction": "Many real-world networks are not static but grow and evolve over time. This exercise explores a dynamic generative model that combines preferential attachment with geometric factors, mimicking processes seen in social or information networks [@problem_id:876879]. You will apply the powerful rate equation method, a key analytical tool in network science, to derive a macroscopic property—the power-law exponent of the degree distribution—directly from the microscopic rules governing the network's growth.", "problem": "Consider a growing network constructed according to the following rules. The network starts with a small number of nodes. At each discrete time step, a new node is introduced and forms $m$ links to $m$ distinct existing nodes. The connections are established based on a combination of preferential attachment and geometric preference.\n\nThe probability $\\Pi_i$ that the new node connects to an existing node $i$ (with degree $k_i$) is a weighted sum of two terms:\n$$\n\\Pi_i = (1-\\alpha) \\Pi_i^{\\text{BA}} + \\alpha \\Pi_i^{\\text{GEO}}\n$$\nwhere $\\alpha \\in [0,1)$ is a mixing parameter.\n\n1.  The preferential attachment term, $\\Pi_i^{\\text{BA}}$, is given by the standard Barabási-Albert rule:\n    $$\n    \\Pi_i^{\\text{BA}} = \\frac{k_i}{\\sum_j k_j}\n    $$\n    where the sum is over all existing nodes $j$.\n\n2.  The geometric attachment term, $\\Pi_i^{\\text{GEO}}$, depends on the positions of nodes in a latent space. Each node $i$ is assigned a fixed, random position $x_i$ on a one-dimensional circle of circumference $L$. The new node at each time step is also assigned a random position $x_{new}$ uniformly on this circle. The geometric attachment probability to node $i$ for a new node at $x_{new}$ is:\n    $$\n    \\Pi_i^{\\text{GEO}}(x_{new}) = \\frac{e^{-d(x_{new}, x_i)/R_0}}{\\sum_j e^{-d(x_{new}, x_j)/R_0}}\n    $$\n    where $d(x,y)$ is the shortest distance between $x$ and $y$ on the circle, and $R_0$ is a characteristic length scale.\n\nTo analyze the large-time behavior of the network, we adopt a continuum-time approximation and a mean-field treatment. The rate of change of the degree of a node $i$ is given by $\\frac{dk_i}{dt} = m \\langle \\Pi_i \\rangle$, where $\\langle \\Pi_i \\rangle$ is the attachment probability averaged over the random position $x_{new}$ of the incoming node.\n\nYou are to make the following mean-field approximation for the geometric term:\n$$\n\\left\\langle \\Pi_i^{\\text{GEO}} \\right\\rangle = \\mathbb{E}_{x_{new}}\\left[ \\frac{e^{-d(x_{new}, x_i)/R_0}}{\\sum_j e^{-d(x_{new}, x_j)/R_0}} \\right] \\approx \\frac{\\mathbb{E}_{x_{new}}\\left[e^{-d(x_{new}, x_i)/R_0}\\right]}{\\mathbb{E}_{x_{new}}\\left[\\sum_j e^{-d(x_{new}, x_j)/R_0}\\right]}\n$$\n\nAssume that the network grows for a long time $t$, so the number of nodes is $N(t) \\approx t$ and the total degree is $\\sum_j k_j \\approx 2mt$.\nUnder these assumptions, the network develops a stationary degree distribution $P(k)$ that for large $k$ follows a power law, $P(k) \\sim k^{-\\gamma}$. Determine the scaling exponent $\\gamma$ as a function of the parameter $\\alpha$.", "solution": "1. Degree growth equation under mean-field and continuum approximation:\n   $$\\frac{dk_i}{dt} = m \\langle \\Pi_i\\rangle\n     = m\\Big[(1-\\alpha)\\,\\Pi_i^{\\rm BA} + \\alpha\\,\\langle\\Pi_i^{\\rm GEO}\\rangle\\Big].$$\n\n2. Preferential‐attachment term:\n   $$\\Pi_i^{\\rm BA}=\\frac{k_i}{\\sum_j k_j}\\approx\\frac{k_i}{2mt}.$$\n\n3. Geometric term mean-field approximation:\n   $$\\langle\\Pi_i^{\\rm GEO}\\rangle \\approx\\frac{\\mathbb{E}_{x_{new}}[e^{-d(x_{new},x_i)/R_0}]}{\\mathbb{E}_{x_{new}}\\Big[\\sum_j e^{-d(x_{new},x_j)/R_0}\\Big]}\n     \\sim\\frac{\\text{const}}{N(t)}\\approx\\frac{1}{t}.$$\n\n4. Combined rate equation:\n   $$\\frac{dk_i}{dt}\n     = m\\Big[(1-\\alpha)\\frac{k_i}{2mt} + \\alpha\\frac{1}{t}\\Big]\n     =\\frac{1-\\alpha}{2}\\,\\frac{k_i}{t}+\\frac{m\\alpha}{t}.$$\n\n5. For large $k_i$ the inhomogeneous term $m\\alpha/t$ is subleading.  Thus asymptotically\n   $$\\frac{dk_i}{dt}\\approx\\frac{1-\\alpha}{2}\\,\\frac{k_i}{t},$$\n   whose solution is\n   $$k_i(t)\\propto t^{\\tfrac{1-\\alpha}{2}}.$$\n\n6.  A node introduced at time $t_i$ has $k\\sim (t/t_i)^{(1-\\alpha)/2}$, so its birth‐time distribution yields\n   $$P(k)\\sim k^{-1-\\tfrac{2}{1-\\alpha}}.$$\n   Hence the tail exponent is\n   $$\\gamma=1+\\frac{2}{1-\\alpha}.$$", "answer": "$$\\boxed{1+\\frac{2}{1-\\alpha}}$$", "id": "876879"}]}