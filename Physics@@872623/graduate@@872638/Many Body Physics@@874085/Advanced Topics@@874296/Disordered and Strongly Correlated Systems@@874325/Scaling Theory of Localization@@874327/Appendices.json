{"hands_on_practices": [{"introduction": "The scaling theory of localization is built on the idea that conductance itself scales with system size in a dimension-dependent way. This first practice takes you back to fundamentals, guiding you to derive the famous $L^{d-2}$ scaling of the Thouless conductance, $g_T$, from the basic principles of diffusion and quantum level spacing [@problem_id:3014241]. Mastering this derivation provides a clear physical intuition for the pivotal role of dimensionality in the metal-insulator transition.", "problem": "Consider a $d$-dimensional hypercubic sample of side length $L$ containing non-interacting electrons subject to weak, quenched disorder that places the dynamics in the diffusive regime, with elastic mean free path $\\ell$ satisfying $\\ell \\ll L$ and negligible inelastic dephasing on the scale $L$. Let $D$ denote the diffusion constant and let $\\nu$ denote the single-particle density of states per unit volume at the Fermi energy. In the scaling theory of localization, the Thouless conductance (also called the Thouless number) $g_T$ is defined as the ratio of the characteristic energy scale associated with diffusion across the sample to the mean single-particle level spacing of the finite system.\n\nStarting only from foundational definitions that relate (i) the diffusive traversal of a length scale to a characteristic time, (ii) the connection between an energy scale and a characteristic time, and (iii) the relation between the density of states and the mean level spacing in a finite volume, derive an explicit expression for $g_T$ in terms of $L$, $D$, $\\nu$, and $d$. Then, extract its scaling with $L$ and confirm the power-law behavior in $L$ expected in $d$ spatial dimensions. Express your final answer as a single closed-form analytic expression for $g_T(L,D,\\nu,d)$, with no numerical evaluation required.", "solution": "The problem requires the derivation of an expression for the Thouless conductance, $g_T$, for a $d$-dimensional disordered system, based on its definition and a set of foundational physical relationships.\n\nFirst, we state the definition of the Thouless conductance $g_T$ as provided in the problem statement. It is the ratio of the Thouless energy, $E_T$, to the mean single-particle level spacing, $\\Delta E$:\n$$\ng_T = \\frac{E_T}{\\Delta E}\n$$\nWe proceed by deriving expressions for the numerator, $E_T$, and the denominator, $\\Delta E$, independently.\n\nThe Thouless energy, $E_T$, is the characteristic energy scale associated with the diffusion of an electron across the entire sample. This process is governed by a characteristic time, the Thouless time $\\tau_D$.\n(i) The first foundational principle relates the diffusive traversal of a length scale to a characteristic time. For a diffusive process characterized by a diffusion constant $D$, the mean-square displacement $\\langle r^2 \\rangle$ after a time $t$ is given by a relation of the form $\\langle r^2 \\rangle \\propto D t$. The characteristic time for an electron to diffuse across a hypercubic sample of side length $L$ is therefore obtained by setting the characteristic displacement to $L$. This gives the Thouless time $\\tau_D$ as:\n$$\n\\tau_D = \\frac{L^2}{D}\n$$\nThis relation captures the scaling of diffusion time with system size and is fundamental to the study of transport in disordered media.\n\n(ii) The second foundational principle connects this characteristic time to an energy scale. The finite time $\\tau_D$ that a particle spends within the sample volume leads to a broadening of its energy levels. This energy broadening is the Thouless energy $E_T$. The relationship between a characteristic time scale and its associated energy scale is given by the principles of quantum mechanics, akin to the energy-time uncertainty principle. The precise relation is:\n$$\nE_T = \\frac{\\hbar}{\\tau_D}\n$$\nwhere $\\hbar$ is the reduced Planck constant. The inclusion of $\\hbar$ is essential on both physical and dimensional grounds. Substituting our expression for $\\tau_D$ into this equation, we find the Thouless energy:\n$$\nE_T = \\frac{\\hbar D}{L^2}\n$$\n\nNext, we derive the expression for the mean single-particle level spacing, $\\Delta E$.\n(iii) The third foundational principle relates the density of states to the mean level spacing in a finite volume. The problem provides $\\nu$ as the single-particle density of states per unit volume at the Fermi energy. For a sample with a finite volume $V$, the total density of states, denoted $N(E_F)$, is the product of $\\nu$ and $V$. The sample is a $d$-dimensional hypercube of side length $L$, so its volume is:\n$$\nV = L^d\n$$\nThe total density of states at the Fermi energy is therefore:\n$$\nN(E_F) = \\nu V = \\nu L^d\n$$\nThis quantity has units of states per unit energy. The mean spacing between adjacent energy levels, $\\Delta E$, is the inverse of the total density of states:\n$$\n\\Delta E = \\frac{1}{N(E_F)} = \\frac{1}{\\nu L^d}\n$$\n\nWith expressions for both $E_T$ and $\\Delta E$, we can now assemble the expression for the Thouless conductance $g_T$:\n$$\ng_T = \\frac{E_T}{\\Delta E} = \\frac{\\frac{\\hbar D}{L^2}}{\\frac{1}{\\nu L^d}}\n$$\nBy simplifying this fraction, we arrive at the final expression for $g_T$:\n$$\ng_T = \\hbar D \\nu L^{d-2}\n$$\n\nThe problem also requires confirmation of the power-law scaling behavior. Our derived expression shows that, for fixed material parameters ($D$, $\\nu$) and dimensionality ($d$), the Thouless conductance scales with the system size $L$ as:\n$$\ng_T \\propto L^{d-2}\n$$\nThis power-law dependence is a central result of the scaling theory of localization. It implies that the conductivity of the material depends on its size in a manner dictated by its dimensionality. For dimensions $d>2$, $g_T$ increases with $L$, indicating metallic behavior. For dimensions $d2$, $g_T$ decreases with $L$, indicating insulating behavior where wavefunctions are localized. The case $d=2$ is a marginal case where this simple scaling suggests $g_T$ is constant, although more advanced theories predict a slow, logarithmic decrease, leading to weak localization. The derived result successfully captures the fundamental power-law behavior.", "answer": "$$\\boxed{\\hbar D \\nu L^{d-2}}$$", "id": "3014241"}, {"introduction": "The scaling hypothesis predicts that near a localization transition, physical quantities depend on system size $L$ and disorder $W$ only through a universal function of a single scaled variable. This hands-on exercise demonstrates how this powerful idea is used in practice to analyze numerical simulation data and extract universal critical exponents [@problem_id:3014276]. By working with mock data for the localization length, you will perform a finite-size scaling analysis to determine the critical exponent $\\nu$.", "problem": "Consider a disordered tight-binding model in three spatial dimensions in a quasi-one-dimensional geometry of transverse width $M$ and longitudinal length $L \\gg M$. Let the onsite disorder strength be $W$, with a continuous metal-insulator transition at a critical disorder $W_c$. The quasi-one-dimensional localization length $\\lambda_M(W)$ is defined via the largest Lyapunov exponent of the transfer matrix for a strip of width $M$. Define the dimensionless normalized localization length $\\Lambda_M(W) = \\lambda_M(W)/M$. \n\nStarting from the single-parameter scaling hypothesis of the scaling theory of localization (Abrahams-Anderson-Licciardello-Ramakrishnan (AALR)), and the existence of a diverging correlation length $\\xi(W)$ at the transition obeying $\\xi(W) \\sim |W - W_c|^{-\\nu}$, derive the finite-size scaling form for $\\Lambda_M(W)$ near criticality using only the dimensionless combinations constructed from $M$ and $\\xi(W)$. Justify why, at $W = W_c$, curves of $\\Lambda_M(W)$ for different $M$ intersect at a common value, and determine how the slope $\\partial \\Lambda_M/\\partial W$ at the crossing scales with $M$.\n\nIn a numerical experiment consistent with negligible corrections to scaling, the crossings of $\\Lambda_M(W)$ for widths $M_1 = 16$ and $M_2 = 64$ occur at the same value of $W$ (denote this crossing $W^{\\times}$), and the measured derivatives of $\\Lambda_M(W)$ with respect to $W$ evaluated at the crossing are $s_{16} = \\partial \\Lambda_{16}/\\partial W \\big|_{W^{\\times}} = 0.200$ and $s_{64} = \\partial \\Lambda_{64}/\\partial W \\big|_{W^{\\times}} = 0.400$. Under the single-parameter scaling assumptions above, compute the correlation-length critical exponent $\\nu$. Express your final answer exactly; no rounding is required. No physical units are required for your answer.", "solution": "The problem requires us to first derive the finite-size scaling form for the dimensionless normalized localization length $\\Lambda_M(W) = \\lambda_M(W)/M$ near a metal-insulator transition, and then use this form to calculate the correlation-length critical exponent $\\nu$ from provided numerical data.\n\nThe cornerstone of the theory is the single-parameter scaling hypothesis. This hypothesis posits that for a system of characteristic size $M$, its transport properties near a critical point are not determined by the microscopic details (like the disorder strength $W$ and system size $M$ independently), but rather by a single dimensionless parameter. In the vicinity of the critical point $W_c$, the only relevant length scale that diverges is the correlation length $\\xi(W)$. The scaling hypothesis then states that any dimensionless physical quantity must be a universal function of the ratio of the system size $M$ to this correlation length $\\xi(W)$.\n\nThe dimensionless normalized localization length $\\Lambda_M(W)$ is precisely such a quantity. Therefore, its scaling form is given by:\n$$\n\\Lambda_M(W) = F\\left(\\frac{M}{\\xi(W)}\\right)\n$$\nwhere $F(x)$ is a universal scaling function, independent of microscopic details.\n\nNext, we justify why curves of $\\Lambda_M(W)$ for different system widths $M$ intersect at a common value. At the critical disorder strength $W = W_c$, the correlation length diverges, $\\xi(W_c) \\to \\infty$. Consequently, the argument of the scaling function $F$ goes to zero, irrespective of the system size $M$:\n$$\n\\lim_{W \\to W_c} \\frac{M}{\\xi(W)} = 0\n$$\nThus, at the critical point, the normalized localization length assumes a value that is independent of $M$:\n$$\n\\Lambda_M(W_c) = F(0)\n$$\nThe value $F(0)$ is a universal constant. This means that if we plot $\\Lambda_M(W)$ as a function of $W$ for various values of $M$, all curves must intersect at the single point $(W_c, \\Lambda_c)$, where $\\Lambda_c = F(0)$. In a numerical simulation, the crossing point $W^{\\times}$ provides a precise estimate for the critical disorder $W_c$.\n\nNow, we determine how the slope $s_M = \\partial \\Lambda_M / \\partial W$ at the crossing point scales with $M$. The problem states that the correlation length diverges as $\\xi(W) \\sim |W - W_c|^{-\\nu}$. We can write this as $\\xi(W) = \\xi_0 |W - W_c|^{-\\nu}$ for some non-universal constant $\\xi_0$.\n\nTo find the scaling of the slope, it is convenient to rewrite the argument of the scaling function. Let's define a new variable $y = (W - W_c)M^{1/\\nu}$. This variable is dimensionless if we assume appropriate units for the disorder parameter $W$. The argument of the original scaling function $F$ can be expressed in terms of $y$:\n$$\n\\frac{M}{\\xi(W)} = \\frac{M}{\\xi_0 |W - W_c|^{-\\nu}} = \\frac{M}{\\xi_0} |W - W_c|^{\\nu} = \\frac{1}{\\xi_0} \\left( |W - W_c| M^{1/\\nu} \\right)^{\\nu} = \\frac{1}{\\xi_0} |y|^{\\nu}\n$$\nSince $\\Lambda_M(W)$ is a universal function of $M/\\xi$, it must also be a universal function of $y$. We can define a new universal scaling function $\\mathcal{G}$ such that:\n$$\n\\Lambda_M(W) = \\mathcal{G}(y) = \\mathcal{G}\\left( (W - W_c)M^{1/\\nu} \\right)\n$$\nClose to the critical point, where $W \\approx W_c$, the argument $y$ is small, and we can approximate $\\mathcal{G}(y)$ by its first-order Taylor expansion around $y=0$:\n$$\n\\mathcal{G}(y) \\approx \\mathcal{G}(0) + \\mathcal{G}'(0) y\n$$\nSubstituting this back, we get a linearized scaling form for $\\Lambda_M(W)$:\n$$\n\\Lambda_M(W) \\approx \\mathcal{G}(0) + \\mathcal{G}'(0)(W - W_c)M^{1/\\nu}\n$$\nWe can now calculate the slope $s_M$ by differentiating with respect to $W$ and evaluating at the critical point $W_c$:\n$$\ns_M = \\left. \\frac{\\partial \\Lambda_M}{\\partial W} \\right|_{W=W_c} = \\frac{\\partial}{\\partial W} \\left[ \\mathcal{G}(0) + \\mathcal{G}'(0)(W - W_c)M^{1/\\nu} \\right]_{W=W_c} = \\mathcal{G}'(0)M^{1/\\nu}\n$$\nThis derivation shows that the slope of $\\Lambda_M(W)$ at the critical point scales with the system size $M$ as:\n$$\ns_M \\propto M^{1/\\nu}\n$$\nThe problem provides numerical data for two system sizes, $M_1 = 16$ and $M_2 = 64$, and their corresponding slopes at the crossing point $W^{\\times}$, $s_{16} = 0.200$ and $s_{64} = 0.400$. We can use these data to find $\\nu$.\nLet $s_M = C \\cdot M^{1/\\nu}$, where $C = \\mathcal{G}'(0)$ is a constant. We can write this relation for our two data points:\n$$\ns_{16} = C \\cdot (16)^{1/\\nu}\n$$\n$$\ns_{64} = C \\cdot (64)^{1/\\nu}\n$$\nTo eliminate the unknown constant $C$, we take the ratio of these two equations:\n$$\n\\frac{s_{64}}{s_{16}} = \\frac{C \\cdot (64)^{1/\\nu}}{C \\cdot (16)^{1/\\nu}} = \\left(\\frac{64}{16}\\right)^{1/\\nu}\n$$\nSubstituting the given numerical values:\n$$\n\\frac{0.400}{0.200} = \\left(\\frac{64}{16}\\right)^{1/\\nu}\n$$\n$$\n2 = 4^{1/\\nu}\n$$\nTo solve for $\\nu$, we can express both sides of the equation with the same base, which is $2$:\n$$\n2^1 = (2^2)^{1/\\nu}\n$$\n$$\n2^1 = 2^{2/\\nu}\n$$\nEquating the exponents yields:\n$$\n1 = \\frac{2}{\\nu}\n$$\nSolving for $\\nu$, we find:\n$$\n\\nu = 2\n$$", "answer": "$$\\boxed{2}$$", "id": "3014276"}, {"introduction": "The one-parameter scaling hypothesis makes a remarkably strong claim: not just the average conductance, but its entire probability distribution, is governed by a single scaling variable. This practice challenges you to implement a direct numerical test of this profound idea using synthetic data for the logarithm of conductance, $\\ln g$ [@problem_id:3014270]. You will verify that different distributions can be collapsed onto a universal form, providing a concrete demonstration of one-parameter scaling at its deepest level.", "problem": "Consider a one-dimensional, single-channel disordered conductor described by a tight-binding chain with uncorrelated on-site disorder. In the localized regime, the Landauer picture connects the two-terminal conductance to transmission through the sample, and the transfer-matrix formulation expresses the evolution of the wavefunction amplitudes as a product of random matrices. By the Central Limit Theorem applied to this multiplicative process, the logarithm of the dimensionless conductance, denoted by $y = \\ln g$, is the sum of many weakly dependent increments and is expected to be approximately normally distributed. The scaling theory of localization posits one-parameter scaling: the full distribution $P(g;L)$ should depend on the system size $L$ only through a single scaling variable, such as $s = L/\\xi$, where $\\xi$ is the localization length, or equivalently through a single cumulant like the mean of $\\ln g$.\n\nYour task is to implement a numerical test of one-parameter scaling at the level of distributions using a synthetic but physically motivated model for $P(g;L)$. Work in the following idealized setting, which captures the localized regime in a single channel under general conditions:\n\n- Hypothesis H (Gaussian log-conductance model, justified by the Central Limit Theorem): The variable $y = \\ln g$ is Gaussian with a mean $m(s)$ and variance $v(s)$ that are both proportional to the single scaling variable $s = L/\\xi$. Without loss of generality, choose units such that $m(s) = -2 s$ and $v(s) = 4 s$. This normalization corresponds to an idealized regime where the Dorokhov–Mello–Pereyra–Kumar (DMPK) picture holds in one dimension and the first two cumulants of $y$ are linear in $s$.\n\n- Equivalence of distribution-level tests: Since the mapping $g \\mapsto \\ln g$ is strictly monotone on $(0,\\infty)$, any test of one-parameter scaling formulated in terms of $y = \\ln g$ is equivalent to a test on $g$ at the level of cumulative distribution ordering.\n\nImplement a program that generates independent ensembles of samples of $y = \\ln g$ using the Gaussian model above for a specified set of $(L,\\xi)$ or specified values of $s = L/\\xi$. Using these ensembles, perform the following two numerical tests:\n\n1. Same-scaling-variable collapse test: For different pairs $(L,\\xi)$ that share the same $s=L/\\xi$, the raw distributions of $y$ should be statistically indistinguishable. Quantify this by the two-sample Kolmogorov–Smirnov statistic on the raw $y$ samples. The test passes if all pairwise distances among the ensembles at the same $s$ are below a threshold $\\tau_{2s}$.\n\n2. Mean-only distribution collapse test: If one-parameter scaling holds at the level of distributions, then using only the sample mean of $y$ to fix the scaling variable should collapse distributions across different $s$. Define a rescaled variable for each ensemble by\n$$\nz = \\frac{y - \\overline{y}}{\\sqrt{-2\\,\\overline{y}}},\n$$\nwhere $\\overline{y}$ is the sample mean of that ensemble. Under the hypothesis above and for sufficiently large samples, $z$ should be close to a standard normal variable, and the rescaled distributions for different $s$ should coincide. Quantify this by the one-sample Kolmogorov–Smirnov statistic of $z$ against the standard normal distribution. The test passes if all distances are below a threshold $\\tau_{1s}$.\n\nDesign choices:\n- Use a fixed random seed for reproducibility.\n- Use the Gaussian model for $y$ with mean $m(s) = -2 s$ and variance $v(s) = 4 s$ to synthesize the data, consistent with Hypothesis H.\n- Use sufficiently large ensemble sizes so that sampling error does not dominate the outcome.\n\nTest suite:\n- Test 1 (same $s$ across different $(L,\\xi)$): Use three pairs with equal $s=2$,\n    - $(L,\\xi) = (200,100)$,\n    - $(L,\\xi) = (100,50)$,\n    - $(L,\\xi) = (50,25)$.\n  Evaluate the maximum pairwise two-sample Kolmogorov–Smirnov distance among these three ensembles of $y$ and compare it to $\\tau_{2s} = 0.06$. Output a boolean indicating whether all pairwise distances are less than or equal to $0.06$.\n\n- Test 2 (mean-only collapse across well-localized ensembles): Use $s \\in \\{0.5, 1.5, 3.0\\}$. For each $s$, compute the one-sample Kolmogorov–Smirnov distance of $z$ against the standard normal. The test passes if the maximum distance over these three ensembles is less than or equal to $\\tau_{1s} = 0.07$. Output a boolean for this test.\n\n- Test 3 (edge case, near-ballistic to weakly localized): Use $s \\in \\{0.05, 0.10, 0.20\\}$. Perform the same mean-only collapse test as in Test 2 with the same threshold $\\tau_{1s} = 0.07$. Output a boolean for this test.\n\nImplementation details:\n- Sample size: For each ensemble, draw exactly $N = 5000$ independent samples of $y$.\n- Use a fixed seed for the random number generator so that results are deterministic.\n- Numerical thresholds: Use the thresholds specified above: $\\tau_{2s} = 0.06$ for the two-sample collapse test and $\\tau_{1s} = 0.07$ for the one-sample collapse tests.\n- Angle units are not applicable. No physical units are required, as $g$ and $s$ are dimensionless.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3]\"), where each entry is a boolean corresponding to Tests 1, 2, and 3 in that order.", "solution": "We base the derivation on two fundamental and widely accepted pillars: the Landauer–Büttiker picture of quantum transport and the transfer-matrix description of wave propagation in disordered media.\n\n1. Landauer conductance and multiplicative random processes:\n   - In coherent two-terminal transport, the dimensionless conductance $g$ (in units of $2 e^2/h$) equals the transmission probability through the sample. In a single-channel one-dimensional disordered system, the wavefunction amplitudes evolve along the sample as $\\Psi_{n+1} = T_n \\Psi_n$, where $T_n$ is a random $2 \\times 2$ transfer matrix determined by the disordered potential at site $n$ and energy. The total evolution over length $L$ is the product $M_L = T_L T_{L-1} \\cdots T_1$, a multiplicative stochastic process.\n   - The transmission and reflection are expressible in terms of $M_L$; equivalently, $-\\ln g$ is proportional to twice the positive Lyapunov exponent times the length for large $L$.\n\n2. Central Limit Theorem and Gaussian fluctuations of $\\ln g$:\n   - The logarithm of the transmission (or conductance) is a sum of many weakly dependent increments arising from the local random transfer matrices. For a single channel with short-range-correlated disorder, a version of the Central Limit Theorem applies to the additive quantity $y = \\ln g$. Thus, $y$ approaches a normal distribution with a mean and variance both proportional to the system size $L$. Writing $s = L/\\xi$, where $\\xi$ is the localization length that sets the exponential decay scale of typical wavefunctions, we expect\n     $$\n     y \\sim \\mathcal{N}\\big(m(s), v(s)\\big), \\quad m(s) \\propto s, \\quad v(s) \\propto s.\n     $$\n   - In one-parameter scaling, all cumulants of $y$ are functions of a single parameter (for instance $s$ or the mean $m$). In the deep localized regime, the Dorokhov–Mello–Pereyra–Kumar (DMPK) approach and similar transfer-matrix analyses yield the specific relations\n     $$\n     \\langle \\ln g \\rangle = -2 s, \\qquad \\operatorname{Var}(\\ln g) = 4 s,\n     $$\n     implying $\\operatorname{Var}(\\ln g) = -2 \\langle \\ln g \\rangle$. These relations consistently realize one-parameter scaling, because the variance is determined by the mean.\n\n3. Distribution-level test for one-parameter scaling:\n   - Because $g \\mapsto \\ln g$ is monotone, testing one-parameter scaling for the distribution of $y = \\ln g$ is equivalent to testing it for $g$; any collapse of cumulative distributions in $y$ implies the same ordering in $g$.\n   - Same-scaling-variable collapse: If we pick different $(L,\\xi)$ with the same $s = L/\\xi$, then the underlying Gaussian distributions for $y$ share the same mean and variance, so they should be statistically indistinguishable. A two-sample Kolmogorov–Smirnov statistic on the raw $y$ samples then quantifies the collapse; small distances confirm consistency.\n   - Mean-only collapse across different $s$: One-parameter scaling at the distribution level implies the possibility of collapsing distributions using only a single parameter. Using the relationship $\\operatorname{Var}(\\ln g) = -2 \\langle \\ln g \\rangle$, one can define the rescaled variable\n     $$\n     z = \\frac{y - \\overline{y}}{\\sqrt{-2\\,\\overline{y}}},\n     $$\n     where $\\overline{y}$ is the sample mean serving as the estimator of the single scaling parameter. If the hypothesis holds and sample sizes are large, $z$ should follow a standard normal distribution independent of $s$, hence all rescaled ensembles should coincide. A one-sample Kolmogorov–Smirnov test against the standard normal quantifies the collapse quality.\n\n4. Algorithmic design:\n   - Set a fixed random seed to ensure reproducibility.\n   - For any specified $s$, synthesize $N$ independent samples of $y$ from a Gaussian with mean $m(s) = -2 s$ and variance $v(s) = 4 s$. This concretely instantiates the Central Limit Theorem-based model and fixes the otherwise arbitrary proportionality constants using a normalization convention.\n   - Test 1: Generate three ensembles with $(L,\\xi) = (200,100)$, $(100,50)$, $(50,25)$, all at $s=2$. Compute the three pairwise two-sample Kolmogorov–Smirnov distances on the raw samples of $y$; declare success if the maximum distance is less than or equal to $\\tau_{2s} = 0.06$.\n   - Test 2: Generate three ensembles at $s \\in \\{0.5, 1.5, 3.0\\}$. For each ensemble, compute $z$ using the sample mean $\\overline{y}$ and the mapping above. Compute the one-sample Kolmogorov–Smirnov distance of $z$ to the standard normal; declare success if the maximum over these three distances is less than or equal to $\\tau_{1s} = 0.07$.\n   - Test 3: Edge case with small $s \\in \\{0.05, 0.10, 0.20\\}$; repeat the mean-only collapse test with the same threshold $\\tau_{1s} = 0.07$.\n   - Use $N = 5000$ samples per ensemble to suppress statistical fluctuations so that the tests are stringent yet pass given the model.\n\n5. Output:\n   - Produce a single line with a Python list literal containing three booleans in order: Test 1, Test 2, Test 3.\n\nThis approach adheres to the principle-based derivation: starting from Landauer transport and transfer matrices, invoking the Central Limit Theorem for multiplicative processes, and operationalizing the one-parameter scaling hypothesis via a Gaussian model whose cumulants are linear in $s$. The numerical tests then directly quantify the claim that the full distribution depends on $L$ only via the single parameter $s$ or equivalently only via the mean of $\\ln g$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import kstest, ks_2samp\n\ndef generate_ln_g_samples(s: float, n: int, rng: np.random.Generator) - np.ndarray:\n    \"\"\"\n    Generate n samples of y = ln g for given scaling variable s = L/xi,\n    using the Gaussian log-conductance model:\n        y ~ Normal(mean = -2*s, variance = 4*s).\n    \"\"\"\n    mean = -2.0 * s\n    var = 4.0 * s\n    std = np.sqrt(var)\n    return rng.normal(loc=mean, scale=std, size=n)\n\ndef ks_pairwise_max(samples_list):\n    \"\"\"\n    Compute the maximum two-sample KS statistic over all unordered pairs\n    from a list of 1D sample arrays.\n    \"\"\"\n    m = len(samples_list)\n    max_stat = 0.0\n    for i in range(m):\n        for j in range(i+1, m):\n            stat = ks_2samp(samples_list[i], samples_list[j], alternative='two-sided', mode='auto').statistic\n            if stat  max_stat:\n                max_stat = stat\n    return max_stat\n\ndef mean_only_rescale_and_ks_to_norm(samples_list):\n    \"\"\"\n    For each sample array y, compute z = (y - mean(y)) / sqrt(-2*mean(y)),\n    then compute KS distance against standard normal.\n    Return the maximum KS statistic over the list.\n    \"\"\"\n    max_stat = 0.0\n    for y in samples_list:\n        y_mean = float(np.mean(y))\n        # Use only the sample mean to set the scale per one-parameter scaling.\n        scale = np.sqrt(-2.0 * y_mean)\n        # To avoid division by zero or NaNs in pathological cases, enforce positivity.\n        # Given our synthetic model, y_mean  0 with overwhelming probability.\n        z = (y - y_mean) / scale\n        stat = kstest(z, 'norm').statistic\n        if stat  max_stat:\n            max_stat = stat\n    return max_stat\n\ndef solve():\n    rng = np.random.default_rng(20230921)\n    N = 5000\n\n    # Thresholds\n    tau_2s = 0.06  # for two-sample KS among same-s ensembles\n    tau_1s = 0.07  # for one-sample KS to N(0,1) after mean-only rescaling\n\n    # Test 1: Same s across different (L, xi)\n    # (200,100), (100,50), (50,25) all have s = 2\n    s_same = 2.0\n    samples_test1 = [\n        generate_ln_g_samples(s_same, N, rng),\n        generate_ln_g_samples(s_same, N, rng),\n        generate_ln_g_samples(s_same, N, rng),\n    ]\n    max_ks_t1 = ks_pairwise_max(samples_test1)\n    result1 = (max_ks_t1 = tau_2s)\n\n    # Test 2: Mean-only collapse across different s in localized regime\n    s_list_t2 = [0.5, 1.5, 3.0]\n    samples_test2 = [generate_ln_g_samples(s, N, rng) for s in s_list_t2]\n    max_ks_t2 = mean_only_rescale_and_ks_to_norm(samples_test2)\n    result2 = (max_ks_t2 = tau_1s)\n\n    # Test 3: Edge case near ballistic to weakly localized (small s)\n    s_list_t3 = [0.05, 0.10, 0.20]\n    samples_test3 = [generate_ln_g_samples(s, N, rng) for s in s_list_t3]\n    max_ks_t3 = mean_only_rescale_and_ks_to_norm(samples_test3)\n    result3 = (max_ks_t3 = tau_1s)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, [result1, result2, result3]))}]\")\n\nsolve()\n```", "id": "3014270"}]}