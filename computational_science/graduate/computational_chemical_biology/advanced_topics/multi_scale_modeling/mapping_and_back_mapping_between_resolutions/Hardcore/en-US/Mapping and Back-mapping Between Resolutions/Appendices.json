{
    "hands_on_practices": [
        {
            "introduction": "The challenge of back-mapping stems from its ill-posed nature: a single coarse-grained configuration can correspond to a vast ensemble of different all-atom structures. This exercise provides a concrete, computational approach to understanding this ambiguity by modeling the coarse-graining map as a linear operator $M$. You will explore how the null space of this operator, $\\mathrm{Null}(M)$, precisely characterizes all the atomistic perturbations that are 'invisible' to the coarse-grained representation, thereby defining the full space of possible back-mapped solutions. ",
            "id": "3852043",
            "problem": "You are given a coarse-grained bead mapping for a tripeptide that maps all-atom Cartesian coordinates to bead coordinates via a linear operator. Let $N$ denote the number of atoms and $B$ denote the number of beads. The all-atom coordinate vector is $x \\in \\mathbb{R}^{3N}$ and the bead coordinate vector is $y \\in \\mathbb{R}^{3B}$. The mapping is linear, $y = M x$, where $M \\in \\mathbb{R}^{3B \\times 3N}$ is constructed from per-bead convex combinations of atomic coordinates replicated across the three Cartesian components. Specifically, bead $b$ is defined by a set of atom indices $S_b \\subset \\{0,1,\\dots,N-1\\}$ and nonnegative weights $\\{w_i\\}_{i \\in S_b}$ with $\\sum_{i \\in S_b} w_i  0$. The mapping matrix $M$ is defined by, for each bead $b \\in \\{0,1,\\dots,B-1\\}$ and each atom $i \\in S_b$, the block\n$$\nM[3b:3b+3,\\,3i:3i+3] \\;=\\; \\left(\\frac{w_i}{\\sum_{j \\in S_b} w_j}\\right) I_3 \\,,\n$$\nwhere $I_3$ denotes the $3 \\times 3$ identity matrix, and zero otherwise. This realizes the bead coordinate as a mass- or weight-weighted average of the assigned atomic positions. A back-mapping perturbation $\\delta x \\in \\mathbb{R}^{3N}$ preserves the coarse-grained coordinate $y$ if and only if $M \\,\\delta x = 0$, i.e., $\\delta x$ lies in the null space of $M$.\n\nYour task is to write a complete, runnable program that:\n- Constructs $M$ from given bead definitions.\n- Computes an orthonormal basis for $\\mathrm{Null}(M)$.\n- Generates random back-mapping perturbations by sampling coefficients $\\alpha$ and forming $\\delta x = N_{\\mathrm{basis}} \\,\\alpha$, where the columns of $N_{\\mathrm{basis}}$ form an orthonormal basis of $\\mathrm{Null}(M)$.\n- Verifies numerically that these perturbations preserve $y$ by reporting, for each test case, the maximum Euclidean norm $\\lVert M \\,\\delta x \\rVert_2$ over a fixed set of random perturbations.\n\nFundamental base for the derivation:\n- Coarse-grained mapping in computational chemical biology is commonly modeled as a linear operator from all-atom coordinates to bead coordinates via weighted averages based on physical masses or other coarse-graining weights. This is captured by $y = M x$ with $M$ constructed as above.\n- The set of all all-atom perturbations that leave $y$ invariant is precisely the null space of $M$, i.e., $\\{\\delta x \\in \\mathbb{R}^{3N} \\mid M \\,\\delta x = 0\\}$.\n- An orthonormal basis for the null space provides a convenient parameterization of all such perturbations via coefficients in $\\mathbb{R}^k$, where $k = \\dim \\mathrm{Null}(M)$.\n\nNumerical protocol to standardize outputs:\n- Use a fixed Gaussian sampling for the coefficients: for each test case, draw $K$ independent samples $\\alpha^{(j)} \\sim \\mathcal{N}(0, \\sigma^2 I_k)$ with $K = 10$ and $\\sigma = 0.05$, and construct $\\delta x^{(j)} = N_{\\mathrm{basis}} \\,\\alpha^{(j)}$.\n- For each test case, report the single scalar\n$$\n\\max_{1 \\le j \\le K} \\; \\lVert M \\,\\delta x^{(j)} \\rVert_2 \\,.\n$$\n- Use a fixed random seed $s = 42$ so that the results are reproducible.\n- No physical units are required; all quantities are treated as dimensionless.\n\nTest suite:\n- All test cases consider a tripeptide with $B = 3$ beads and $N = 12$ atoms, with indices $0,1,\\dots,11$. Each case specifies the bead index sets $(S_0,S_1,S_2)$ and corresponding unnormalized weights.\n\n$1.$ Case A (uniform weights, equal group sizes):\n$$\nS_0 = \\{0,1,2,3\\}, \\quad S_1 = \\{4,5,6,7\\}, \\quad S_2 = \\{8,9,10,11\\}.\n$$\nWeights:\n$$\nw^{(0)} = [1,1,1,1], \\quad w^{(1)} = [1,1,1,1], \\quad w^{(2)} = [1,1,1,1].\n$$\n\n$2.$ Case B (mass-weighted, equal group sizes). Approximate atomic masses for heavy atoms:\n$$\nw^{(b)} = [14.007,\\,12.011,\\,12.011,\\,15.999] \\quad \\text{for each} \\quad b \\in \\{0,1,2\\},\n$$\nwith the same index sets as Case A.\n\n$3.$ Case C (uniform weights, unequal group sizes):\n$$\nS_0 = \\{0,1,2,3,4\\}, \\quad S_1 = \\{5,6,7,8\\}, \\quad S_2 = \\{9,10,11\\},\n$$\nwith\n$$\nw^{(0)} = [1,1,1,1,1], \\quad w^{(1)} = [1,1,1,1], \\quad w^{(2)} = [1,1,1].\n$$\n\n$4.$ Case D (uniform weights, boundary with a single-atom bead):\n$$\nS_0 = \\{0\\}, \\quad S_1 = \\{1,2,3,4,5\\}, \\quad S_2 = \\{6,7,8,9,10,11\\},\n$$\nwith\n$$\nw^{(0)} = [1], \\quad w^{(1)} = [1,1,1,1,1], \\quad w^{(2)} = [1,1,1,1,1,1].\n$$\n\nProgram requirements:\n- Implement the construction of $M$ from the provided $(S_b, w^{(b)})$ definitions using the block-identity scheme above.\n- Compute an orthonormal basis of $\\mathrm{Null}(M)$.\n- For each test case, sample $K = 10$ independent Gaussian coefficient vectors with variance $\\sigma^2$ and form $\\delta x^{(j)}$. Compute the Euclidean norms $\\lVert M \\,\\delta x^{(j)} \\rVert_2$ and take the maximum over the $K$ samples as the test case’s reported value.\n- Use the specified random seed $s = 42$ for reproducibility.\n- Final output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the four test cases, for example, $[r_1,r_2,r_3,r_4]$, where each $r_i$ is a floating-point number.\n\nNote: Angles are not involved and no physical units are required. The only outputs are real-valued floats as defined above, one per test case.",
            "solution": "The problem requires us to validate a back-mapping procedure for a coarse-grained molecular model. The core principle is that any atomic perturbation $\\delta x$ that does not alter the coarse-grained representation $y$ must belong to the null space of the linear mapping operator $M$, which is defined by the relation $y = M x$. We must verify this by constructing such perturbations and measuring the norm of their projection by $M$, which should be close to zero due to numerical precision limits. The procedure involves four main steps: constructing the matrix $M$, computing a basis for its null space, generating random perturbations from this basis, and quantifying the numerical error.\n\nFirst, we construct the coarse-graining matrix $M \\in \\mathbb{R}^{3B \\times 3N}$. Here, $N=12$ is the number of atoms and $B=3$ is the number of coarse-grained beads. The matrix $M$ maps the all-atom coordinate vector $x \\in \\mathbb{R}^{3N}$ to the bead coordinate vector $y \\in \\mathbb{R}^{3B}$. For each bead $b \\in \\{0, 1, \\dots, B-1\\}$, its position is a weighted average of the positions of atoms in a set $S_b \\subset \\{0, 1, \\dots, N-1\\}$. The weights are given as $\\{w_i\\}_{i \\in S_b}$. The mapping is structured as a series of $3 \\times 3$ blocks. Specifically, for each atom $i \\in S_b$, the block of $M$ that maps the coordinates of atom $i$ to bead $b$ is given by:\n$$\nM[3b:3b+3, 3i:3i+3] = c_i I_3\n$$\nwhere $I_3$ is the $3 \\times 3$ identity matrix and $c_i$ is the normalized weight:\n$$\nc_i = \\frac{w_i}{\\sum_{j \\in S_b} w_j}\n$$\nAll other blocks of $M$ are zero matrices. This construction is implemented by initializing a $3B \\times 3N$ (i.e., $9 \\times 36$) zero matrix and populating the specified blocks for each bead definition provided in the test cases.\n\nSecond, we determine the space of perturbations $\\delta x$ that preserve the coarse-grained coordinates. A perturbation $\\delta x$ is considered valid for back-mapping if it does not change the bead coordinates, which means the change in $y$ is zero: $\\delta y = M \\delta x = 0$. The set of all such vectors $\\delta x$ constitutes the null space of the matrix $M$, denoted $\\mathrm{Null}(M)$. The dimension of this space, $k$, is given by the rank-nullity theorem: $k = \\dim(\\mathrm{Null}(M)) = 3N - \\mathrm{rank}(M)$. For the test cases provided, the atom sets $S_b$ for the beads are disjoint, which ensures that the rows of $M$ corresponding to different beads are linearly independent. Thus, the rank of $M$ is $3B = 9$. The dimension of the null space is therefore $k = 3 \\times 12 - 9 = 27$. We compute an orthonormal basis for this $27$-dimensional null space using a standard numerical linear algebra routine. Specifically, we use Singular Value Decomposition (SVD), as implemented in the `scipy.linalg.null_space` function, which returns a matrix $N_{\\mathrm{basis}} \\in \\mathbb{R}^{3N \\times k}$ whose columns form the orthonormal basis vectors $\\{v_1, v_2, \\dots, v_k\\}$ for $\\mathrm{Null}(M)$.\n\nThird, we generate random perturbations that lie within this null space. Any vector in $\\mathrm{Null}(M)$ can be expressed as a linear combination of its basis vectors. A random perturbation $\\delta x$ is constructed as:\n$$\n\\delta x = \\sum_{j=1}^{k} \\alpha_j v_j = N_{\\mathrm{basis}} \\alpha\n$$\nwhere $\\alpha = [\\alpha_1, \\alpha_2, \\dots, \\alpha_k]^T$ is a vector of coefficients. According to the problem specification, these coefficients are sampled independently from a Gaussian distribution with mean $0$ and variance $\\sigma^2$, i.e., $\\alpha_j \\sim \\mathcal{N}(0, \\sigma^2)$. The standard deviation is specified as $\\sigma = 0.05$. For each test case, we generate $K=10$ such random coefficient vectors $\\alpha^{(j)}$ and construct the corresponding perturbations $\\delta x^{(j)}$. The fixed random seed $s=42$ ensures the reproducibility of these samples.\n\nFourth, we perform the numerical verification. In exact arithmetic, since each column of $N_{\\mathrm{basis}}$ is in $\\mathrm{Null}(M)$, it holds that $M N_{\\mathrm{basis}} = \\boldsymbol{0}$, where $\\boldsymbol{0}$ is a zero matrix. Consequently, $M \\delta x = M (N_{\\mathrm{basis}} \\alpha) = (M N_{\\mathrm{basis}}) \\alpha = \\boldsymbol{0} \\alpha = 0$. However, due to finite floating-point precision in the computation of the null space and subsequent matrix multiplications, we expect the computed result $M \\delta x$ to be a vector with very small, non-zero components. We quantify this numerical error by computing the Euclidean norm $\\lVert M \\delta x^{(j)} \\rVert_2$ for each of the $K=10$ generated perturbations. The final reported value for each test case is the maximum of these norms, $\\max_{1 \\le j \\le K} \\lVert M \\delta x^{(j)} \\rVert_2$. This value serves as a measure of the numerical stability and correctness of the entire procedure.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import null_space\n\ndef solve():\n    \"\"\"\n    Constructs a coarse-graining matrix M, finds its null space, generates\n    random perturbations within this space, and verifies that they preserve\n    the coarse-grained representation by checking if M * delta_x is close to zero.\n    \"\"\"\n\n    # Define constants from the problem statement.\n    N_ATOMS = 12\n    N_BEADS = 3\n    K_SAMPLES = 10\n    SIGMA = 0.05\n    RANDOM_SEED = 42\n\n    # Define the test cases.\n    # Each case is a tuple: (name, bead_definitions)\n    # bead_definitions is a list of tuples: (atom_indices, weights)\n    test_cases = [\n        # 1. Case A (uniform weights, equal group sizes)\n        (\n            [\n                (list(range(0, 4)), [1.0] * 4),\n                (list(range(4, 8)), [1.0] * 4),\n                (list(range(8, 12)), [1.0] * 4)\n            ]\n        ),\n        # 2. Case B (mass-weighted, equal group sizes)\n        (\n            [\n                (list(range(0, 4)), [14.007, 12.011, 12.011, 15.999]),\n                (list(range(4, 8)), [14.007, 12.011, 12.011, 15.999]),\n                (list(range(8, 12)), [14.007, 12.011, 12.011, 15.999])\n            ]\n        ),\n        # 3. Case C (uniform weights, unequal group sizes)\n        (\n            [\n                (list(range(0, 5)), [1.0] * 5),\n                (list(range(5, 9)), [1.0] * 4),\n                (list(range(9, 12)), [1.0] * 3)\n            ]\n        ),\n        # 4. Case D (uniform weights, boundary with a single-atom bead)\n        (\n            [\n                ([0], [1.0]),\n                (list(range(1, 6)), [1.0] * 5),\n                (list(range(6, 12)), [1.0] * 6)\n            ]\n        )\n    ]\n\n    results = []\n    \n    # Set the random seed for reproducibility across all test cases.\n    np.random.seed(RANDOM_SEED)\n\n    for bead_defs in test_cases:\n        # 1. Construct the mapping matrix M\n        dim_M_rows = 3 * N_BEADS\n        dim_M_cols = 3 * N_ATOMS\n        M = np.zeros((dim_M_rows, dim_M_cols))\n        \n        for b, (atom_indices, weights) in enumerate(bead_defs):\n            sum_weights = sum(weights)\n            if sum_weights = 0:\n                # This case is disallowed by the problem statement.\n                # It would lead to division by zero.\n                raise ValueError(\"Sum of weights for a bead cannot be zero or negative.\")\n\n            for local_idx, atom_idx in enumerate(atom_indices):\n                weight = weights[local_idx]\n                normalized_weight = weight / sum_weights\n                \n                # The block M[3b:3b+3, 3i:3i+3] is a scaled identity matrix.\n                row_start = 3 * b\n                col_start = 3 * atom_idx\n                M[row_start:row_start+3, col_start:col_start+3] = normalized_weight * np.identity(3)\n\n        # 2. Compute an orthonormal basis for the null space of M.\n        # The columns of N_basis form the basis vectors.\n        N_basis = null_space(M)\n        \n        # Dimension of the null space, k.\n        k = N_basis.shape[1]\n        \n        max_norm = 0.0\n\n        for _ in range(K_SAMPLES):\n            # 3. Generate random coefficients alpha.\n            # np.random.normal's 'scale' parameter is the standard deviation sigma.\n            alpha = np.random.normal(loc=0.0, scale=SIGMA, size=k)\n            \n            # Construct the perturbation delta_x in the null space.\n            delta_x = N_basis @ alpha\n            \n            # 4. Verify by projecting delta_x back with M and computing the norm.\n            # In theory, M @ delta_x should be a zero vector.\n            y_pert = M @ delta_x\n            \n            # Compute the Euclidean norm of the resulting vector.\n            # This norm quantifies the numerical error.\n            norm = np.linalg.norm(y_pert, ord=2)\n            \n            # Keep track of the maximum norm found over K samples.\n            if norm  max_norm:\n                max_norm = norm\n                \n        results.append(max_norm)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.15e}' for r in results)}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "Given that a multitude of atomistic structures can match a single coarse-grained state, we need a robust method to select the most physically plausible one. This practice introduces optimization as a powerful framework for solving the back-mapping problem. You will construct and analyze a penalty function $\\Phi(x)$ that seeks a compromise between matching the target coarse-grained observables and satisfying known chemical constraints, such as ideal bond lengths and angles. ",
            "id": "3852006",
            "problem": "A coarse-to-atomistic back-mapping in computational chemical biology seeks atomistic coordinates $x \\in \\mathbb{R}^{3N}$ whose mapped coarse observables match a target $y \\in \\mathbb{R}^{m}$, where $m$ is the coarse dimensionality (for example, bead positions or other low-dimensional descriptors). Let $M:\\mathbb{R}^{3N} \\to \\mathbb{R}^{m}$ denote a differentiable mapping from atomistic coordinates to coarse observables. Consider the penalty function\n$$\n\\Phi(x) \\;=\\; \\| y - M(x) \\|^{2} \\;+\\; \\lambda \\, C(x),\n$$\nwhere $C:\\mathbb{R}^{3N} \\to \\mathbb{R}$ is a differentiable constraints functional that penalizes deviations from chemically meaningful structure (for example, sums of squared deviations of bond lengths, angles, or dihedrals from reference values), and $\\lambda  0$ is a scalar regularization weight. Define the residual vector $r(x) = y - M(x)$, the Jacobian $J_{M}(x) = \\frac{\\partial M(x)}{\\partial x} \\in \\mathbb{R}^{m \\times 3N}$, and for each component $M_{i}(x)$, let $\\nabla M_{i}(x) \\in \\mathbb{R}^{3N}$ and $\\nabla^{2} M_{i}(x) \\in \\mathbb{R}^{3N \\times 3N}$ be its gradient and Hessian. Assume $C(x)$ is twice continuously differentiable with gradient $\\nabla C(x)$ and Hessian $\\nabla^{2} C(x)$.\n\nUsing only fundamental multivariate calculus (chain rule for vector-valued functions and product rule) and standard linear algebra definitions (Jacobian, gradient, and Hessian), derive the expressions for the gradient $\\nabla \\Phi(x)$ and Hessian $\\nabla^{2} \\Phi(x)$ in terms of $r(x)$, $J_{M}(x)$, $\\nabla^{2} M_{i}(x)$, $\\nabla C(x)$, and $\\nabla^{2} C(x)$. Then, define the Gauss–Newton approximate Hessian as $H_{\\mathrm{GN}}(x) = 2 J_{M}(x)^{\\top} J_{M}(x) + \\lambda \\nabla^{2} C(x)$ (obtained by neglecting the second-derivative terms of $M$ in the data-fit part), and analyze conditions for numerical stability of a Newton or Gauss–Newton step applied to minimize $\\Phi(x)$.\n\nIn particular, assume there exists $\\mu > 0$ such that $\\nabla^{2} C(x) \\succeq \\mu I$ (that is, the Hessian of the constraints is bounded below by $\\mu I$ in the Loewner partial order), and let $\\sigma_{\\min}(x)$ denote the smallest singular value of $J_{M}(x)$. For a prescribed curvature floor $\\alpha > 0$ to ensure the smallest eigenvalue of $H_{\\mathrm{GN}}(x)$ is at least $\\alpha$, determine the smallest $\\lambda$ that guarantees $H_{\\mathrm{GN}}(x) \\succeq \\alpha I$.\n\nYour final answer must be a single composite analytical expression containing the gradient, the Hessian, and the minimal $\\lambda$ as derived above, written as a row matrix. No numerical evaluation is required.",
            "solution": "The problem requires the derivation of the gradient and Hessian of a penalty function $\\Phi(x)$, and an analysis of the conditions for numerical stability of an optimization step based on the Gauss-Newton approximation of the Hessian. The penalty function is given by:\n$$\n\\Phi(x) = \\| y - M(x) \\|^{2} + \\lambda \\, C(x)\n$$\nwhere $x \\in \\mathbb{R}^{3N}$ are the atomistic coordinates, $y \\in \\mathbb{R}^{m}$ are target coarse observables, $M: \\mathbb{R}^{3N} \\to \\mathbb{R}^{m}$ is a differentiable mapping, $C(x)$ is a differentiable constraints functional, and $\\lambda > 0$ is a scalar weight. We define the residual vector $r(x) = y - M(x)$. The function $\\Phi(x)$ can be written as:\n$$\n\\Phi(x) = r(x)^{\\top}r(x) + \\lambda \\, C(x)\n$$\n\nFirst, we derive the gradient of $\\Phi(x)$, denoted by $\\nabla \\Phi(x) \\in \\mathbb{R}^{3N}$. The gradient is the vector of partial derivatives, $[\\nabla \\Phi(x)]_k = \\frac{\\partial \\Phi}{\\partial x_k}$. We apply the sum rule for differentiation:\n$$\n\\nabla \\Phi(x) = \\nabla(r(x)^{\\top}r(x)) + \\nabla(\\lambda C(x))\n$$\nThe gradient of the second term is straightforward:\n$$\n\\nabla(\\lambda C(x)) = \\lambda \\nabla C(x)\n$$\nFor the first term, we use the chain rule for vector-valued functions. Let $f(u) = u^{\\top}u$. The gradient of $f$ is $\\nabla f(u) = 2u$. Here, $u = r(x)$. The Jacobian of $r(x) = y - M(x)$ with respect to $x$ is $J_r(x) = \\frac{\\partial r(x)}{\\partial x} = -\\frac{\\partial M(x)}{\\partial x} = -J_M(x)$. The chain rule states that $\\nabla(f(r(x))) = J_r(x)^{\\top} (\\nabla f)(r(x))$. Applying this, we get:\n$$\n\\nabla(r(x)^{\\top}r(x)) = (-J_M(x))^{\\top} (2r(x)) = -2 J_M(x)^{\\top} r(x)\n$$\nCombining the two parts, the gradient of $\\Phi(x)$ is:\n$$\n\\nabla \\Phi(x) = -2 J_M(x)^{\\top} r(x) + \\lambda \\nabla C(x)\n$$\n\nSecond, we derive the Hessian of $\\Phi(x)$, denoted by $\\nabla^2 \\Phi(x) \\in \\mathbb{R}^{3N \\times 3N}$. The Hessian is the matrix of second partial derivatives, $[\\nabla^2 \\Phi(x)]_{jk} = \\frac{\\partial^2 \\Phi}{\\partial x_j \\partial x_k}$. We differentiate the expression for the gradient's components. The $k$-th component of the gradient is:\n$$\n[\\nabla \\Phi(x)]_k = -2 \\sum_{i=1}^{m} [J_M(x)^{\\top}]_{ki} r_i(x) + \\lambda \\frac{\\partial C}{\\partial x_k} = -2 \\sum_{i=1}^{m} \\frac{\\partial M_i}{\\partial x_k} r_i(x) + \\lambda \\frac{\\partial C}{\\partial x_k}\n$$\nNow, we differentiate with respect to $x_j$ using the product rule on the first term:\n$$\n\\frac{\\partial^2 \\Phi}{\\partial x_j \\partial x_k} = \\frac{\\partial}{\\partial x_j} \\left( -2 \\sum_{i=1}^{m} \\frac{\\partial M_i}{\\partial x_k} r_i(x) + \\lambda \\frac{\\partial C}{\\partial x_k} \\right)\n$$\n$$\n= -2 \\sum_{i=1}^{m} \\left( \\frac{\\partial^2 M_i}{\\partial x_j \\partial x_k} r_i(x) + \\frac{\\partial M_i}{\\partial x_k} \\frac{\\partial r_i}{\\partial x_j} \\right) + \\lambda \\frac{\\partial^2 C}{\\partial x_j \\partial x_k}\n$$\nSince $r_i(x) = y_i - M_i(x)$, we have $\\frac{\\partial r_i}{\\partial x_j} = -\\frac{\\partial M_i}{\\partial x_j}$. Substituting this into the expression:\n$$\n\\frac{\\partial^2 \\Phi}{\\partial x_j \\partial x_k} = -2 \\sum_{i=1}^{m} \\left( \\frac{\\partial^2 M_i}{\\partial x_j \\partial x_k} r_i(x) - \\frac{\\partial M_i}{\\partial x_k} \\frac{\\partial M_i}{\\partial x_j} \\right) + \\lambda \\frac{\\partial^2 C}{\\partial x_j \\partial x_k}\n$$\n$$\n= 2 \\sum_{i=1}^{m} \\frac{\\partial M_i}{\\partial x_j} \\frac{\\partial M_i}{\\partial x_k} - 2 \\sum_{i=1}^{m} r_i(x) \\frac{\\partial^2 M_i}{\\partial x_j \\partial x_k} + \\lambda \\frac{\\partial^2 C}{\\partial x_j \\partial x_k}\n$$\nWe recognize the terms as elements of matrices. The first term is the $(j,k)$-th element of $2 J_M(x)^{\\top} J_M(x)$. The second term is the $(j,k)$-th element of $-2 \\sum_{i=1}^{m} r_i(x) \\nabla^2 M_i(x)$, where $\\nabla^2 M_i(x)$ is the Hessian of the $i$-th component of $M(x)$. The third term is the $(j,k)$-th element of $\\lambda \\nabla^2 C(x)$.\nAssembling these into matrix form gives the full Hessian:\n$$\n\\nabla^2 \\Phi(x) = 2 J_M(x)^{\\top} J_M(x) - 2 \\sum_{i=1}^{m} r_i(x) \\nabla^2 M_i(x) + \\lambda \\nabla^2 C(x)\n$$\n\nThird, we analyze the conditions for the stability of a Gauss-Newton optimization step. The Gauss-Newton approximate Hessian $H_{\\mathrm{GN}}(x)$ is formed by neglecting the second-derivative terms involving $M_i(x)$ (the term with $\\sum r_i \\nabla^2 M_i$), which is justified when the residuals $r_i(x)$ are small or when $M(x)$ is nearly linear. The problem defines:\n$$\nH_{\\mathrm{GN}}(x) = 2 J_{M}(x)^{\\top} J_{M}(x) + \\lambda \\nabla^{2} C(x)\n$$\nFor a stable descent step, $H_{\\mathrm{GN}}(x)$ must be positive definite. The problem requires a stronger condition: to find the smallest $\\lambda > 0$ such that the smallest eigenvalue of $H_{\\mathrm{GN}}(x)$ is at least $\\alpha > 0$, i.e., $H_{\\mathrm{GN}}(x) \\succeq \\alpha I$. This ensures the matrix is well-conditioned and the search direction is a strong descent direction.\n\nLet $\\lambda_{\\min}(A)$ denote the smallest eigenvalue of a symmetric matrix $A$. We want to find the smallest $\\lambda > 0$ such that $\\lambda_{\\min}(H_{\\mathrm{GN}}(x)) \\ge \\alpha$.\nUsing Weyl's inequality for the eigenvalues of a sum of symmetric matrices, $\\lambda_{\\min}(A+B) \\ge \\lambda_{\\min}(A) + \\lambda_{\\min}(B)$, we can establish a lower bound on the smallest eigenvalue of $H_{\\mathrm{GN}}(x)$:\n$$\n\\lambda_{\\min}(H_{\\mathrm{GN}}(x)) \\ge \\lambda_{\\min}(2 J_{M}(x)^{\\top} J_{M}(x)) + \\lambda_{\\min}(\\lambda \\nabla^{2} C(x))\n$$\nWe analyze each term on the right-hand side. The eigenvalues of $J_{M}(x)^{\\top} J_{M}(x)$ are the squares of the singular values of $J_{M}(x)$. Thus, its smallest eigenvalue is $\\sigma_{\\min}(x)^2$, where $\\sigma_{\\min}(x)$ is the smallest singular value of $J_{M}(x)$.\n$$\n\\lambda_{\\min}(2 J_{M}(x)^{\\top} J_{M}(x)) = 2 \\sigma_{\\min}(x)^2\n$$\nFor the second term, we are given $\\nabla^{2} C(x) \\succeq \\mu I$ for some $\\mu > 0$. This means $\\lambda_{\\min}(\\nabla^{2} C(x)) \\ge \\mu$. Since $\\lambda > 0$:\n$$\n\\lambda_{\\min}(\\lambda \\nabla^{2} C(x)) = \\lambda \\, \\lambda_{\\min}(\\nabla^{2} C(x)) \\ge \\lambda \\mu\n$$\nCombining these bounds, we get a sufficient condition for our requirement:\n$$\n\\lambda_{\\min}(H_{\\mathrm{GN}}(x)) \\ge 2 \\sigma_{\\min}(x)^2 + \\lambda \\mu\n$$\nTo guarantee that $\\lambda_{\\min}(H_{\\mathrm{GN}}(x)) \\ge \\alpha$, it is sufficient to require that this lower bound is at least $\\alpha$:\n$$\n2 \\sigma_{\\min}(x)^2 + \\lambda \\mu \\ge \\alpha\n$$\nSolving for $\\lambda$:\n$$\n\\lambda \\mu \\ge \\alpha - 2 \\sigma_{\\min}(x)^2 \\quad \\implies \\quad \\lambda \\ge \\frac{\\alpha - 2 \\sigma_{\\min}(x)^2}{\\mu}\n$$\nThis inequality provides a value for $\\lambda$ that is sufficient to guarantee the desired curvature, for any matrices satisfying the premises. It represents the requirement in the worst-case scenario (where the eigenvectors corresponding to the minimal eigenvalues of both matrices align).\nThe problem also specifies that $\\lambda > 0$. If the right-hand side, $\\frac{\\alpha - 2 \\sigma_{\\min}(x)^2}{\\mu}$, is non-positive, any $\\lambda > 0$ fulfills the derived inequality. To provide a single expression for the smallest value of $\\lambda$ (or, more precisely, the infimum of the set of valid $\\lambda$), we must take the maximum of $0$ and the derived lower bound. Therefore, the infimum for $\\lambda$ is:\n$$\n\\max\\left(0, \\frac{\\alpha - 2 \\sigma_{\\min}(x)^2}{\\mu}\\right)\n$$\n\nThe final answer requires the three derived expressions in a single row matrix.\n1.  Gradient: $\\nabla \\Phi(x) = -2J_M(x)^\\top r(x) + \\lambda \\nabla C(x)$\n2.  Hessian: $\\nabla^2 \\Phi(x) = 2 J_M(x)^\\top J_M(x) - 2 \\sum_{i=1}^m r_i(x) \\nabla^2 M_i(x) + \\lambda \\nabla^2 C(x)$\n3.  Smallest $\\lambda$ (infimum): $\\max \\left( 0, \\frac{\\alpha - 2 \\sigma_{\\min}(x)^2}{\\mu} \\right)$",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n-2J_M(x)^\\top r(x) + \\lambda \\nabla C(x)  2 J_M(x)^\\top J_M(x) - 2 \\sum_{i=1}^m r_i(x) \\nabla^2 M_i(x) + \\lambda \\nabla^2 C(x)  \\max \\left( 0, \\frac{\\alpha - 2 \\sigma_{\\min}(x)^2}{\\mu} \\right)\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Applying back-mapping algorithms to data from molecular simulations requires careful handling of technical details like Periodic Boundary Conditions (PBC). Naively calculating a coarse-grained bead's center of mass from atomic coordinates wrapped into the primary simulation cell can lead to significant errors if the underlying molecule is split across a boundary. This exercise will guide you through deriving the correct, robust procedure for making a molecule 'whole' before coarse-graining, ensuring that the resulting bead positions are physically meaningful. ",
            "id": "3852041",
            "problem": "Consider a coarse-graining map in Molecular Dynamics (MD) under Periodic Boundary Conditions (PBC) for a molecule whose atoms may cross simulation cell boundaries. Let the triclinic periodic cell be represented by the box matrix $H \\in \\mathbb{R}^{3 \\times 3}$ with columns equal to the three lattice vectors. Wrapped atomic coordinates are denoted by $r_i \\in \\mathbb{R}^3$ in the primary image, and unwrapped coordinates by $x_i \\in \\mathbb{R}^3$, related by $x_i = r_i + H n_i$ with $n_i \\in \\mathbb{Z}^3$ the integer lattice offset. A coarse-grained (CG) bead position $R_b \\in \\mathbb{R}^3$ is defined as the mass-weighted center of mass (COM) of its constituent atoms in unwrapped space: $R_b = \\left(\\sum_{i \\in b} m_i x_i\\right)\\big/\\left(\\sum_{i \\in b} m_i\\right)$, where $m_i$ is the atomic mass. For back-mapping from a bead to atoms, local internal coordinates (bond lengths, angles, dihedrals) and a bead-centered local frame are used to reconstruct atom positions relative to $R_b$.\n\nStarting from the core definitions of PBC and COM, derive how using wrapped coordinates $r_i$ instead of unwrapped $x_i$ affects the computed $R_b$ for molecules crossing boundaries, and explain why a consistent choice of lattice offsets $n_i$ is required to avoid artificial fragmentation or erroneous bead placement. Use the minimum-image principle formulated with fractional coordinates $s = H^{-1}(r)$: for any bonded pair $(j,k)$, the nearest-image displacement is $d_{jk} = r_k - r_j - H\\,\\mathrm{round}\\!\\left(H^{-1}(r_k - r_j)\\right)$, where $\\mathrm{round}(\\cdot)$ applies component-wise to yield the closest integer vector.\n\nThen, apply your derivation to the following orthorhombic example with $H = \\mathrm{diag}(L_x, L_y, L_z)$, $L_x = L_y = L_z = 1\\,\\mathrm{nm}$, a diatomic bead with equal masses $m_1 = m_2 = m$, and wrapped positions $r_1 = (0.98, 0.50, 0.50)\\,\\mathrm{nm}$ and $r_2 = (0.02, 0.50, 0.50)\\,\\mathrm{nm}$ connected by a single covalent bond. Compute the unwrapped positions $x_1$, $x_2$ consistent with the bond under PBC and the bead COM $R_b$ in unwrapped space, and state its value after rewrapping into the primary cell.\n\nFinally, select the option that correctly proposes a robust unwrapping and back-mapping strategy that is consistent with your derivation and yields the correct $R_b$ for the example.\n\nA. Perform graph-based unwrapping along molecular bonds using the nearest-image displacement $d_{jk} = r_k - r_j - H\\,\\mathrm{round}\\!\\left(H^{-1}(r_k - r_j)\\right)$ on a breadth-first traversal. Set $x_{j_0} = r_{j_0}$ for a reference atom $j_0$, then $x_k = x_j + d_{jk}$ for each visited bond $(j,k)$. Compute $R_b = \\left(\\sum_i m_i x_i\\right)\\big/\\left(\\sum_i m_i\\right)$ in unwrapped space and, for storage, rewrap $R_b$ by mapping to fractional coordinates and subtracting $\\mathrm{round}(\\cdot)$. For back-mapping, place atoms using internal coordinates in the bead’s local frame centered at the unwrapped $R_b$, then wrap all positions to the primary cell. For the example, $x_1 = (0.98, 0.50, 0.50)\\,\\mathrm{nm}$, $x_2 = (1.02, 0.50, 0.50)\\,\\mathrm{nm}$, $R_b = (1.00, 0.50, 0.50)\\,\\mathrm{nm}$, which rewraps to $(0.00, 0.50, 0.50)\\,\\mathrm{nm}$.\n\nB. Compute $R_b$ directly from wrapped coordinates $r_i$ in the primary cell without unwrapping, i.e., $R_b = \\left(\\sum_i m_i r_i\\right)\\big/\\left(\\sum_i m_i\\right)$. For back-mapping, place atoms so that each lies within $\\pm L_\\alpha/2$ of $R_b$ along axis $\\alpha \\in \\{x,y,z\\}$, ensuring proximity to the bead. For the example, $R_b = (0.50, 0.50, 0.50)\\,\\mathrm{nm}$.\n\nC. Estimate $R_b$ from wrapped coordinates $r_i$, then iteratively unwrap each atom by enforcing $|x_{i,\\alpha} - R_{b,\\alpha}| \\le L_\\alpha/2$ for each axis $\\alpha$; repeat until convergence. Use the final $R_b$ computed from the iteratively adjusted $x_i$. For the example, this procedure yields $R_b \\approx (0.50, 0.50, 0.50)\\,\\mathrm{nm}$.\n\nD. Choose integer lattice offsets $n_i \\in \\mathbb{Z}^3$ for all atoms by minimizing the sum of squared distances to the origin, $\\sum_i \\|r_i + H n_i\\|^2$, to unwrap the molecule; then compute $R_b$ from the resulting $x_i$. For back-mapping, place atoms by minimizing their distances to $R_b$ after wrapping. For the example, one possible choice gives $x_1 = (-0.02, 0.50, 0.50)\\,\\mathrm{nm}$, $x_2 = (0.02, 0.50, 0.50)\\,\\mathrm{nm}$, with $R_b = (0.00, 0.50, 0.50)\\,\\mathrm{nm}$, but this approach may distort bonded geometry in branched or cyclic molecules.",
            "solution": "The problem statement is first subjected to a rigorous validation process.\n\n**Step 1: Extract Givens**\n- Periodic cell representation: Triclinic box matrix $H \\in \\mathbb{R}^{3 \\times 3}$, with columns as lattice vectors.\n- Atomic coordinates: Wrapped coordinates $r_i \\in \\mathbb{R}^3$, unwrapped coordinates $x_i \\in \\mathbb{R}^3$.\n- Coordinate relation: $x_i = r_i + H n_i$, where $n_i \\in \\mathbb{Z}^3$ is the integer lattice offset.\n- Coarse-grained (CG) bead position: $R_b = \\left(\\sum_{i \\in b} m_i x_i\\right)\\big/\\left(\\sum_{i \\in b} m_i\\right)$, defined using unwrapped coordinates $x_i$. $m_i$ is the atomic mass.\n- Back-mapping: Reconstructs atom positions from $R_b$ using internal coordinates and a local frame.\n- Minimum-image displacement for a bonded pair $(j,k)$: $d_{jk} = r_k - r_j - H\\,\\mathrm{round}\\!\\left(H^{-1}(r_k - r_j)\\right)$. The $\\mathrm{round}(\\cdot)$ function is applied component-wise.\n- Fractional coordinates: $s = H^{-1}(r)$.\n- Example system specifications:\n    - Box matrix: Orthorhombic, $H = \\mathrm{diag}(L_x, L_y, L_z)$.\n    - Box dimensions: $L_x = L_y = L_z = 1\\,\\mathrm{nm}$.\n    - Bead composition: Diatomic, atoms $1$ and $2$ are bonded.\n    - Atomic masses: $m_1 = m_2 = m$.\n    - Wrapped positions: $r_1 = (0.98, 0.50, 0.50)\\,\\mathrm{nm}$ and $r_2 = (0.02, 0.50, 0.50)\\,\\mathrm{nm}$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientific Grounding**: The problem is firmly grounded in the standard principles of molecular dynamics (MD) simulations, including periodic boundary conditions (PBC), coarse-graining, center of mass calculations, and the minimum image convention. The provided equations are standard definitions used in the field.\n- **Well-Posedness**: The problem is well-posed. It provides all necessary definitions and data to perform the required derivation and calculations. The objective is clear: to derive the correct procedure for handling PBC in coarse-graining and apply it to a specific example, then identify the correct strategy among the options.\n- **Objectivity**: The problem statement is expressed in precise, technical language, free from subjectivity or ambiguity.\n\n**Flaw Checklist**:\n1.  **Scientific/Factual Unsoundness**: None. The physics and mathematics are standard and correct.\n2.  **Non-Formalizable/Irrelevant**: None. The problem is a formal and relevant challenge in computational chemical biology.\n3.  **Incomplete/Contradictory Setup**: None. The information is self-contained and sufficient.\n4.  **Unrealistic/Infeasible**: None. The parameters are typical for atomistic simulations.\n5.  **Ill-Posed/Poorly Structured**: None. The terms are well-defined and the question is structured to have a unique, correct answer.\n6.  **Trivial/Tautological**: None. The problem addresses a non-trivial and common issue in MD simulation analysis, often referred to as the \"center of mass of a wrapped cluster\" problem, which requires careful reasoning.\n7.  **Outside Scientific Verifiability**: None. The derivation and calculations are verifiable.\n\n**Step 3: Verdict and Action**\nThe problem statement is **VALID**. Proceeding to solution derivation.\n\n**Theoretical Derivation and Analysis**\n\nThe position of a coarse-grained bead, $R_b$, is defined as the center of mass (COM) of its constituent atoms in a physically contiguous, unwrapped coordinate system. The definition is:\n$$R_b = \\frac{\\sum_{i \\in b} m_i x_i}{\\sum_{i \\in b} m_i}$$\nwhere $x_i$ are the unwrapped coordinates. Using the relation $x_i = r_i + H n_i$, we can express $R_b$ in terms of the wrapped coordinates $r_i$ and the integer lattice offsets $n_i$:\n$$R_b = \\frac{\\sum_{i \\in b} m_i (r_i + H n_i)}{\\sum_{i \\in b} m_i} = \\frac{\\sum_{i \\in b} m_i r_i}{\\sum_{i \\in b} m_i} + H \\left( \\frac{\\sum_{i \\in b} m_i n_i}{\\sum_{i \\in b} m_i} \\right)$$\nLet $R_b^{\\text{wrapped}} = \\left(\\sum_{i \\in b} m_i r_i\\right) / \\left(\\sum_{i \\in b} m_i\\right)$ be the COM naively computed from the wrapped coordinates. The equation becomes:\n$$R_b = R_b^{\\text{wrapped}} + H \\cdot \\bar{n}_b$$\nwhere $\\bar{n}_b = \\left(\\sum_{i \\in b} m_i n_i\\right) / \\left(\\sum_{i \\in b} m_i\\right)$ is the mass-weighted average of the integer lattice offset vectors.\n\nIf a molecule is split across a periodic boundary, its constituent atoms will have different integer offset vectors $n_i$. For instance, for a diatomic molecule crossing the $x$-boundary, we might have $n_1 = (0,0,0)^T$ and $n_2 = (1,0,0)^T$. In this case, $\\bar{n}_b$ is not an integer vector, and $R_b^{\\text{wrapped}}$ does not represent the COM of any physical object. It becomes a meaningless average of two distant points, resulting in an erroneous placement of the CG bead (e.g., in the middle of the box, far from the actual molecule).\n\nTo compute the correct $R_b$, one must first determine a consistent set of $n_i$ vectors that reconstruct the molecule as a single, contiguous entity in unwrapped space. This is equivalent to making the molecule \"whole\". The covalent bond structure provides the necessary information to achieve this. The minimum-image displacement vector, $d_{jk} = x_k - x_j$, gives the true vector between two bonded atoms, $j$ and $k$. The formula provided, $d_{jk} = r_k - r_j - H\\,\\mathrm{round}\\!\\left(H^{-1}(r_k - r_j)\\right)$, is the standard way to compute this from wrapped coordinates.\n\nA robust algorithm is therefore to traverse the molecular graph (e.g., via breadth-first search). We can anchor the molecule by choosing a reference atom $j_0$ and setting its unwrapped position to its wrapped one, $x_{j_0} = r_{j_0}$ (effectively choosing $n_{j_0} = (0,0,0)^T$). Then, for each bonded neighbor $k$ of a visited atom $j$, its unwrapped position is determined as $x_k = x_j + d_{jk}$. This process iteratively reconstructs the entire molecule in unwrapped space, ensuring all bond vectors are correct. Once all consistent $x_i$ are found, the true COM, $R_b$, can be computed. This procedure ensures the internal geometry and the resulting $R_b$ are correct, regardless of where the molecule lies with respect to the imaging cell boundaries. For back-mapping, the atomistic structure should be rebuilt around this correct, unwrapped $R_b$ before any final wrapping of the entire molecule is performed.\n\n**Application to the Example**\n\n- Box: $H = \\mathrm{diag}(1, 1, 1)\\,\\mathrm{nm}$, so $H^{-1} = \\mathrm{diag}(1, 1, 1)\\,\\mathrm{nm}^{-1}$.\n- Masses: $m_1 = m_2 = m$.\n- Wrapped positions: $r_1 = (0.98, 0.50, 0.50)\\,\\mathrm{nm}$, $r_2 = (0.02, 0.50, 0.50)\\,\\mathrm{nm}$.\n\nWe follow the robust unwrapping procedure:\n1.  Choose atom $1$ as the reference. Set its unwrapped position to its wrapped one:\n    $$x_1 = r_1 = (0.98, 0.50, 0.50)\\,\\mathrm{nm}$$\n    This sets $n_1 = (0,0,0)^T$.\n\n2.  Compute the minimum-image displacement vector $d_{12}$ to find the position of atom $2$ relative to atom $1$.\n    $$r_2 - r_1 = (0.02 - 0.98, 0.50 - 0.50, 0.50 - 0.50)\\,\\mathrm{nm} = (-0.96, 0.00, 0.00)\\,\\mathrm{nm}$$\n    In fractional coordinates, this displacement is $H^{-1}(r_2 - r_1) = (-0.96, 0.00, 0.00)$.\n    The nearest integer vector is $\\mathrm{round}(H^{-1}(r_2 - r_1)) = (\\mathrm{round}(-0.96), \\mathrm{round}(0.00), \\mathrm{round}(0.00)) = (-1, 0, 0)^T$.\n    The minimum-image displacement is:\n    $$d_{12} = (r_2 - r_1) - H \\cdot (-1, 0, 0)^T = (-0.96, 0.00, 0.00)\\,\\mathrm{nm} - (-1, 0, 0)\\,\\mathrm{nm} = (0.04, 0.00, 0.00)\\,\\mathrm{nm}$$\n\n3.  Compute the unwrapped position of atom $2$:\n    $$x_2 = x_1 + d_{12} = (0.98, 0.50, 0.50)\\,\\mathrm{nm} + (0.04, 0.00, 0.00)\\,\\mathrm{nm} = (1.02, 0.50, 0.50)\\,\\mathrm{nm}$$\n    The consistent unwrapped coordinates are $x_1 = (0.98, 0.50, 0.50)\\,\\mathrm{nm}$ and $x_2 = (1.02, 0.50, 0.50)\\,\\mathrm{nm}$.\n\n4.  Compute the bead COM, $R_b$, from the unwrapped coordinates. Since masses are equal, it's the geometric mean:\n    $$R_b = \\frac{x_1 + x_2}{2} = \\frac{(0.98, 0.50, 0.50) + (1.02, 0.50, 0.50)}{2}\\,\\mathrm{nm} = \\frac{(2.00, 1.00, 1.00)}{2}\\,\\mathrm{nm} = (1.00, 0.50, 0.50)\\,\\mathrm{nm}$$\n\n5.  Rewrap $R_b$ into the primary cell $[0, 1) \\times [0, 1) \\times [0, 1)\\,\\mathrm{nm}$. We map to fractional coordinates $s_b = H^{-1}R_b = (1.00, 0.50, 0.50)$, find the integer image vector $n = \\mathrm{floor}(s_b) = (1, 0, 0)^T$, and subtract the lattice vector:\n    $$R_{b, \\text{wrapped}} = R_b - Hn = (1.00, 0.50, 0.50)\\,\\mathrm{nm} - (1, 0, 0)\\,\\mathrm{nm} = (0.00, 0.50, 0.50)\\,\\mathrm{nm}$$\n\n**Option-by-Option Analysis**\n\n**A. Perform graph-based unwrapping...**\nThis option describes the exact robust procedure derived above: unwrapping the molecule based on connectivity using the minimum-image displacement, computing the COM in this unwrapped space, and then handling back-mapping relative to the unwrapped COM. The calculations provided in the option, $x_1 = (0.98, 0.50, 0.50)\\,\\mathrm{nm}$, $x_2 = (1.02, 0.50, 0.50)\\,\\mathrm{nm}$, $R_b = (1.00, 0.50, 0.50)\\,\\mathrm{nm}$, and the rewrapped $R_b = (0.00, 0.50, 0.50)\\,\\mathrm{nm}$, perfectly match our derivation.\n**Verdict: Correct.**\n\n**B. Compute $R_b$ directly from wrapped coordinates...**\nThis proposes the naive, flawed approach. The calculation is $R_b = (r_1+r_2)/2 = ((0.98, 0.5, 0.5) + (0.02, 0.5, 0.5))/2\\,\\mathrm{nm} = (0.50, 0.50, 0.50)\\,\\mathrm{nm}$. As derived, this method produces a physically meaningless COM in the center of the box, far from the bonded atoms which are clustered near the $x=0/x=1$ boundary. The method is fundamentally incorrect for molecules crossing periodic boundaries.\n**Verdict: Incorrect.**\n\n**C. Estimate $R_b$ from wrapped coordinates, then iteratively unwrap each atom...**\nThis describes an iterative clustering algorithm. It starts with the incorrect naive COM from option B, $R_{b, \\text{init}} = (0.50, 0.50, 0.50)\\,\\mathrm{nm}$. It then checks if any atom should be unwrapped to be closer to this COM. For atom $1$, $|x_{1,x} - R_{b,x}| = |0.98 - 0.50| = 0.48$, which is less than $L_x/2 = 0.5$. For atom $2$, $|x_{2,x} - R_{b,x}| = |0.02 - 0.50| = 0.48$, also less than $L_x/2$. Since no atom is moved, the procedure converges immediately to the wrong result, $R_b=(0.50, 0.50, 0.50)\\,\\mathrm{nm}$. This method fails because it does not use the crucial information about molecular connectivity.\n**Verdict: Incorrect.**\n\n**D. Choose integer lattice offsets $n_i$ ... by minimizing the sum of squared distances to the origin...**\nThis strategy unwraps each atom independently to place it as close to the origin as possible, ignoring molecular connectivity. For $r_1 = (0.98, \\dots)$, the unwrapped position closest to the origin is $x_1 = (-0.02, \\dots)$. For $r_2 = (0.02, \\dots)$, the unwrapped position closest to the origin is $x_2 = (0.02, \\dots)$. This yields $x_1 = (-0.02, 0.50, 0.50)\\,\\mathrm{nm}$ and $x_2 = (0.02, 0.50, 0.50)\\,\\mathrm{nm}$. The resulting COM is $R_b = (x_1+x_2)/2 = (0.00, 0.50, 0.50)\\,\\mathrm{nm}$. While this numerically matches the correct wrapped COM for this simple, symmetric example, the underlying principle is flawed. As the option itself notes, this method can distort the geometry of more complex molecules (e.g., by breaking a long molecule that spans the origin) because it does not enforce contiguity. A robust method must be based on preserving the internal molecular structure, not on moving the molecule to an arbitrary location like the origin.\n**Verdict: Incorrect.**",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}