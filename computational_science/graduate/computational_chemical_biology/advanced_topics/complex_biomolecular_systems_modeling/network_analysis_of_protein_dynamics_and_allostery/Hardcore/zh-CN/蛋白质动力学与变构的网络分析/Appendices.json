{
    "hands_on_practices": [
        {
            "introduction": "在蛋白质网络分析中，首要步骤是定义网络的节点和边，这直接决定了我们如何表征一个复杂的生物分子。一个关键的决定是在何种分辨率水平上构建网络：是使用高分辨率的原子水平，还是采用更粗粒度的残基水平？这个练习将通过构建和比较这两种网络，揭示模型表示的选择如何深刻地影响网络的拓扑特性和我们的最终分析结论。通过这个实践，你将亲手量化不同表示方法对度分布、聚类系数和路径长度等关键网络指标的影响。",
            "id": "3855794",
            "problem": "给定一个近似于理想α螺旋的短多肽片段的单一三维结构模型。基于此结构，构建两个无向简单图：一个原子水平图和一个残基水平图。原子水平图中的每个节点代表一个重原子，残基水平图中的每个节点代表一个氨基酸残基。对于这两个图，边表示从欧几里得距离推断出的空间接触。您的程序必须根据一组指定的距离截断值，计算两个图在度分布、聚类和路径长度方面的定量差异。所有距离都必须以埃（Å）为单位处理，图论量是无量纲的。\n\n使用的基本依据和定义：\n- 两点笛卡尔坐标之间的欧几里得距离定义为 $d(\\mathbf{x},\\mathbf{y}) = \\sqrt{(x_1 - y_1)^2 + (x_2 - y_2)^2 + (x_3 - y_3)^2}$。\n- 一个简单无向图 $G = (V,E)$ 有一个节点集 $V$ 和一个边集 $E$，没有自环或多重边。\n- 图 $G$ 的邻接矩阵 $A \\in \\{0,1\\}^{n \\times n}$ 定义为：如果节点 $i$ 和 $j$ 之间有边，则 $A_{ij} = 1$，否则 $A_{ij} = 0$，且 $A_{ii} = 0$。\n- 节点 $i$ 的度 $k_i$ 定义为 $k_i = \\sum_{j=1}^{n} A_{ij}$。\n- 对于度 $k_i \\ge 2$ 的节点 $i$，其局部聚类系数 $C_i$ 为 $C_i = \\dfrac{2 \\, m_i}{k_i (k_i - 1)}$，其中 $m_i$ 是节点 $i$ 的邻居之间的边数。对于 $k_i < 2$，定义 $C_i = 0$。\n- 平均聚类系数 $\\bar{C}$ 定义为 $\\bar{C} = \\dfrac{1}{n} \\sum_{i=1}^{n} C_i$。\n- 两节点间的最短路径长度是连接它们所需的最少边数，在图的最大连通分量上计算。如果最大连通分量的大小 $s < 2$，则定义平均最短路径长度为 $0$。\n- 经验度分布 $P(k)$ 定义为 $P(k) = \\dfrac{1}{n} \\sum_{i=1}^{n} \\mathbf{1}_{\\{k_i = k\\}}$，其中整数 $k \\ge 0$。两个离散分布 $P$ 和 $Q$（支撑集为 $\\{0,1,\\dots,K_{\\max}\\}$）之间的总变差距离是 $D_{\\mathrm{TV}}(P,Q) = \\dfrac{1}{2} \\sum_{k=0}^{K_{\\max}} |P(k) - Q(k)|$。\n\n结构生成：\n- 考虑$N_{\\mathrm{res}} = 12$个排列成理想α螺旋的残基。残基$i$的α-碳（CA）的位置由每个残基的轴向升高量$h = 1.5$ Å、螺旋半径$R = 2.3$ Å和每个残基的旋转角度$\\Delta\\theta = 100^\\circ$（以弧度为单位）参数化，使得$\\theta_i = i \\times \\Delta\\theta$且$z_i = i \\times h$，其中$i = 0,1,\\dots,N_{\\mathrm{res}}-1$。CA的笛卡尔坐标定义为$x_i = R \\cos(\\theta_i)$、$y_i = R \\sin(\\theta_i)$和如上所述的$z_i$。\n- 对于每个残基，定义酰胺氮（N）、α-碳（CA）、羰基碳（C）和羰基氧（O）的重原子位置。设$\\mathbf{r}_{\\mathrm{CA},i}$表示CA的位置。使用CA位置的有限差分定义局部切向单位向量$\\mathbf{t}_i$：对于内部残基，$\\mathbf{t}_i$是归一化向量$\\mathbf{r}_{\\mathrm{CA},i+1} - \\mathbf{r}_{\\mathrm{CA},i-1}$；对于端点，分别使用前向或后向差分。然后按如下方式放置原子：\n    - $\\mathbf{r}_{\\mathrm{N},i} = \\mathbf{r}_{\\mathrm{CA},i} - \\ell_{\\mathrm{N-CA}} \\, \\mathbf{t}_i$，其中 $\\ell_{\\mathrm{N-CA}} = 1.47$ Å，\n    - $\\mathbf{r}_{\\mathrm{C},i} = \\mathbf{r}_{\\mathrm{CA},i} + \\ell_{\\mathrm{CA-C}} \\, \\mathbf{t}_i$，其中 $\\ell_{\\mathrm{CA-C}} = 1.53$ Å，\n    - $\\mathbf{r}_{\\mathrm{O},i} = \\mathbf{r}_{\\mathrm{C},i} + \\ell_{\\mathrm{C-O}} \\, \\mathbf{n}_i$，其中 $\\ell_{\\mathrm{C-O}} = 1.24$ Å，\n其中$\\mathbf{n}_i$是一个同时垂直于$\\mathbf{t}_i$和螺旋轴$\\mathbf{z} = (0,0,1)$的单位向量，定义为$\\mathbf{n}_i = \\dfrac{\\mathbf{t}_i \\times \\mathbf{z}}{\\|\\mathbf{t}_i \\times \\mathbf{z}\\|}$（如果$\\|\\mathbf{t}_i \\times \\mathbf{z}\\| > 0$），否则$\\mathbf{n}_i = (1,0,0)$。\n\n图构建规则：\n- 原子水平图$G_{\\mathrm{atom}}$：节点对应于每个残基的所有重原子$\\{\\mathrm{N}, \\mathrm{CA}, \\mathrm{C}, \\mathrm{O}\\}$。如果在两个原子$a$和$b$之间的距离$d(\\mathbf{r}_a,\\mathbf{r}_b) \\le d_{\\mathrm{atom}}$，则在它们之间放置一条无向边，其中$d_{\\mathrm{atom}}$是原子水平的距离截断值，单位为Å。\n- 残基水平图$G_{\\mathrm{res}}$：节点对应于残基$i=0,\\dots,N_{\\mathrm{res}}-1$。如果在残基$i$的任何重原子与残基$j$的任何重原子之间的最小原子间距离小于或等于$d_{\\mathrm{res}}$，则在残基$i$和$j$之间放置一条无向边，其中$d_{\\mathrm{res}}$是残基水平的距离截断值，单位为Å。\n\n每个测试用例需要计算的量：\n- 分别计算$G_{\\mathrm{atom}}$和$G_{\\mathrm{res}}$的平均度$\\bar{k}_{\\mathrm{atom}}$和$\\bar{k}_{\\mathrm{res}}$。\n- 计算经验度分布$P_{\\mathrm{atom}}(k)$和$P_{\\mathrm{res}}(k)$，其中$k \\in \\{0,1,\\dots,K_{\\max}\\}$且$K_{\\max} = \\max\\{\\max_i k^{\\mathrm{atom}}_i, \\max_j k^{\\mathrm{res}}_j\\}$，以及总变差距离$D_{\\mathrm{TV}}(P_{\\mathrm{atom}}, P_{\\mathrm{res}})$。\n- 计算两个图的平均聚类系数$\\bar{C}_{\\mathrm{atom}}$和$\\bar{C}_{\\mathrm{res}}$。\n- 计算每个图的最大连通分量上的平均最短路径长度$\\bar{L}_{\\mathrm{atom}}$和$\\bar{L}_{\\mathrm{res}}$。将平均最短路径长度$\\bar{L}$定义为最大连通分量内所有不同节点对之间最短路径长度的平均值；如果最大连通分量的节点数小于2，则设$\\bar{L} = 0$。\n\n每个测试用例的最终输出：\n- 对于每个测试用例，按以下顺序返回包含9个浮点数的列表：\n    1. $\\bar{k}_{\\mathrm{atom}}$，\n    2. $\\bar{k}_{\\mathrm{res}}$，\n    3. $D_{\\mathrm{TV}}(P_{\\mathrm{atom}}, P_{\\mathrm{res}})$，\n    4. $\\bar{C}_{\\mathrm{atom}}$，\n    5. $\\bar{C}_{\\mathrm{res}}$，\n    6. $\\Delta \\bar{C} = \\bar{C}_{\\mathrm{atom}} - \\bar{C}_{\\mathrm{res}}$，\n    7. $\\bar{L}_{\\mathrm{atom}}$，\n    8. $\\bar{L}_{\\mathrm{res}}$，\n    9. $\\Delta \\bar{L} = \\bar{L}_{\\mathrm{atom}} - \\bar{L}_{\\mathrm{res}}$。\n\n测试套件：\n- 对$(d_{\\mathrm{atom}}, d_{\\mathrm{res}})$（单位Å）使用以下测试用例：\n    1. $(4.5, 7.0)$，\n    2. $(3.0, 5.0)$，\n    3. $(6.0, 10.0)$，\n    4. $(4.0, 4.0)$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个元素对应一个测试用例，其本身是按上述顺序排列的九个浮点数的列表（例如，$[\\,[r_{1,1},\\dots,r_{1,9}],\\,[r_{2,1},\\dots,r_{2,9}],\\,[r_{3,1},\\dots,r_{3,9}],\\,[r_{4,1},\\dots,r_{4,9}]\\,]$）。除了在定义输入截断值时使用Å（这属于内部计算，不予打印）外，输出是无量纲的。输出中不使用角度；任何内部使用的角度都以弧度为单位。",
            "solution": "用户提供的问题是有效的，因为它具有科学依据、问题明确，并包含确定性解决方案所需的所有必要信息。它涉及生物分子网络表示的构建和分析，这是计算化学生物学中一个标准且重要的任务。我们将逐步进行求解。\n\n总体方法包括四个主要阶段：(1) 算法化生成理想α螺旋的原子坐标；(2) 基于距离截断值构建两种不同的图表示——原子水平图$G_{\\mathrm{atom}}$和残基水平图$G_{\\mathrm{res}}$；(3) 为两个图计算一套定量的图论度量指标；(4) 比较这些度量指标以评估两种表示水平之间的差异。\n\n### 第1部分：原子结构的生成\n\n分析的基础是多肽的三维模型。我们的任务是为处于理想α螺旋构象中的$N_{\\mathrm{res}} = 12$个残基片段生成所有重原子的坐标。\n\n首先，我们生成α-碳原子（$\\mathrm{CA}$）的位置，这些位置定义了螺旋主链的轨迹。残基$i$（对于$i = 0, 1, \\dots, N_{\\mathrm{res}}-1$）的$\\mathrm{CA}$原子的位置由笛卡尔坐标$(x_i, y_i, z_i)$中的参数化表示给出。参数包括螺旋半径$R = 2.3$ Å，每个残基的轴向升高量$h = 1.5$ Å，以及每个残基的旋转角度$\\Delta\\theta = 100^\\circ$。计算时必须将角度转换为弧度：$\\Delta\\theta_{\\mathrm{rad}} = 100 \\cdot (\\pi/180)$。第$i$个$\\mathrm{CA}$原子的坐标$\\mathbf{r}_{\\mathrm{CA},i}$则为：\n$$\n\\begin{cases}\nx_i = R \\cos(i \\cdot \\Delta\\theta_{\\mathrm{rad}}) \\\\\ny_i = R \\sin(i \\cdot \\Delta\\theta_{\\mathrm{rad}}) \\\\\nz_i = i \\cdot h\n\\end{cases}\n$$\n\n在确定了$\\mathrm{CA}$的位置后，我们放置其他主链重原子：酰胺氮（$\\mathrm{N}$）、羰基碳（$\\mathrm{C}$）和羰基氧（$\\mathrm{O}$）。它们的位置是相对于$\\mathrm{CA}$原子使用局部坐标系定义的。这需要沿着主链的局部切向向量$\\mathbf{t}_i$。我们使用$\\mathrm{CA}$位置的有限差分来近似这个向量：\n- 对于内部残基（$1 < i < N_{\\mathrm{res}}-1$）：$\\mathbf{t}_i = \\frac{\\mathbf{r}_{\\mathrm{CA},i+1} - \\mathbf{r}_{\\mathrm{CA},i-1}}{\\|\\mathbf{r}_{\\mathrm{CA},i+1} - \\mathbf{r}_{\\mathrm{CA},i-1}\\|}$（中心差分）。\n- 对于N-末端（$i=0$）：$\\mathbf{t}_0 = \\frac{\\mathbf{r}_{\\mathrm{CA},1} - \\mathbf{r}_{\\mathrm{CA},0}}{\\|\\mathbf{r}_{\\mathrm{CA},1} - \\mathbf{r}_{\\mathrm{CA},0}\\|}$（前向差分）。\n- 对于C-末端（$i=N_{\\mathrm{res}}-1$）：$\\mathbf{t}_{N_{\\mathrm{res}}-1} = \\frac{\\mathbf{r}_{\\mathrm{CA},N_{\\mathrm{res}}-1} - \\mathbf{r}_{\\mathrm{CA},N_{\\mathrm{res}}-2}}{\\|\\mathbf{r}_{\\mathrm{CA},N_{\\mathrm{res}}-1} - \\mathbf{r}_{\\mathrm{CA},N_{\\mathrm{res}}-2}\\|}$（后向差分）。\n\n$\\mathrm{N}$和$\\mathrm{C}$原子沿着这个切向向量放置：\n$$\n\\mathbf{r}_{\\mathrm{N},i} = \\mathbf{r}_{\\mathrm{CA},i} - \\ell_{\\mathrm{N-CA}} \\, \\mathbf{t}_i, \\quad \\text{其中} \\quad \\ell_{\\mathrm{N-CA}} = 1.47 \\, \\text{Å}\n$$\n$$\n\\mathbf{r}_{\\mathrm{C},i} = \\mathbf{r}_{\\mathrm{CA},i} + \\ell_{\\mathrm{CA-C}} \\, \\mathbf{t}_i, \\quad \\text{其中} \\quad \\ell_{\\mathrm{CA-C}} = 1.53 \\, \\text{Å}\n$$\n\n羰基氧（$\\mathrm{O}$）的放置需要一个额外的方向向量$\\mathbf{n}_i$，该向量应同时垂直于局部切线$\\mathbf{t}_i$和主螺旋轴$\\mathbf{z} = (0,0,1)$。该向量由归一化的叉积定义：\n$$\n\\mathbf{n}_i = \\frac{\\mathbf{t}_i \\times \\mathbf{z}}{\\|\\mathbf{t}_i \\times \\mathbf{z}\\|}\n$$\n问题指定了一个备用方案$\\mathbf{n}_i = (1,0,0)$，用于$\\|\\mathbf{t}_i \\times \\mathbf{z}\\| = 0$的情况，这种情况发生在$\\mathbf{t}_i$与$\\mathbf{z}$轴平行时（对于螺旋来说，这在物理上是不现实的）。然后氧原子的放置如下：\n$$\n\\mathbf{r}_{\\mathrm{O},i} = \\mathbf{r}_{\\mathrm{C},i} + \\ell_{\\mathrm{C-O}} \\, \\mathbf{n}_i, \\quad \\text{其中} \\quad \\ell_{\\mathrm{C-O}} = 1.24 \\, \\text{Å}\n$$\n这个过程得出了所有$N_{\\mathrm{atom}} = N_{\\mathrm{res}} \\times 4 = 12 \\times 4 = 48$个重原子的坐标。\n\n### 第2部分：图的构建\n\n根据原子坐标，我们构建两个无向简单图。\n\n**原子水平图 ($G_{\\mathrm{atom}}$)**：该图提供了原子接触的高分辨率视图。节点集$V_{\\mathrm{atom}}$由所有$N_{\\mathrm{atom}}=48$个重原子组成。如果在两个不同原子$a$和$b$之间的欧几里得距离$d(\\mathbf{r}_a, \\mathbf{r}_b)$小于或等于指定的截断值$d_{\\mathrm{atom}}$，则它们之间存在一条边。邻接矩阵$A^{\\mathrm{atom}}$定义为：\n$$\nA^{\\mathrm{atom}}_{ab} = \\begin{cases} 1 & \\text{如果 } 0 < d(\\mathbf{r}_a, \\mathbf{r}_b) \\le d_{\\mathrm{atom}} \\\\ 0 & \\text{否则} \\end{cases}\n$$\n\n**残基水平图 ($G_{\\mathrm{res}}$)**：这是一个粗粒化表示，其中每个节点对应一个完整的氨基酸残基。节点集$V_{\\mathrm{res}}$由$N_{\\mathrm{res}}=12$个残基组成。如果在两个不同残基$i$和$j$之间，残基$i$的任何重原子与残基$j$的任何重原子之间的最小欧几里得距离小于或等于指定的截断值$d_{\\mathrm{res}}$，则它们之间存在一条边。设$\\mathcal{H}_i$为残基$i$中的重原子集合。邻接矩阵$A^{\\mathrm{res}}$定义为：\n$$\nA^{\\mathrm{res}}_{ij} = \\begin{cases} 1 & \\text{如果 } i \\ne j \\text{ 且 } \\min_{a \\in \\mathcal{H}_i, b \\in \\mathcal{H}_j} d(\\mathbf{r}_a, \\mathbf{r}_b) \\le d_{\\mathrm{res}} \\\\ 0 & \\text{否则} \\end{cases}\n$$\n\n### 第3部分：图论度量的计算\n\n对于每个图，我们计算一组标准的网络度量来表征其拓扑结构。对于一个具有$n$个节点和邻接矩阵$A$的通用图$G$：\n\n- **平均度（$\\bar{k}$）**：节点$i$的度是$k_i = \\sum_{j=1}^{n} A_{ij}$。平均度是所有节点度的平均值：$\\bar{k} = \\frac{1}{n} \\sum_{i=1}^{n} k_i$。\n\n- **度分布（$P(k)$）和总变差距离（$D_{\\mathrm{TV}}$）**：经验度分布$P(k)$测量图中度为$k$的节点所占的比例。原子水平图和残基水平图的分布$P_{\\mathrm{atom}}$和$P_{\\mathrm{res}}$之间的总变差距离提供了一个量化它们差异的单一值。其计算公式为 $D_{\\mathrm{TV}}(P_{\\mathrm{atom}}, P_{\\mathrm{res}}) = \\frac{1}{2} \\sum_{k=0}^{K_{\\max}} |P_{\\mathrm{atom}}(k) - P_{\\mathrm{res}}(k)|$，其中$K_{\\max}$是在两个图中观察到的最大度。\n\n- **平均聚类系数（$\\bar{C}$）**：节点$i$的局部聚类系数$C_i$量化了其邻居之间相互连接的紧密程度。对于一个度为$k_i \\ge 2$的节点$i$，它是其邻居之间的边数（$m_i$）与可能的最大边数$\\binom{k_i}{2}$之比。\n$$\nC_i = \\frac{2 m_i}{k_i (k_i - 1)}\n$$\n对于$k_i < 2$，$C_i = 0$。通过节点$i$的三角形数量是$\\frac{1}{2}(A^3)_{ii}$。因此，计算$C_i$的一种有效方法是$C_i = \\frac{(A^3)_{ii}}{k_i(k_i - 1)}$。平均聚类系数$\\bar{C}$是所有节点局部系数的平均值：$\\bar{C} = \\frac{1}{n} \\sum_{i=1}^{n} C_i$。\n\n- **平均最短路径长度（$\\bar{L}$）**：该度量衡量图中节点之间的典型分离程度。首先，我们识别图的最大连通分量（LCC）。如果LCC的大小$s < 2$，则定义$\\bar{L}$为$0$。否则，我们计算LCC内所有$\\frac{s(s-1)}{2}$对不同节点的最短路径长度（最短路径中的边数）。平均最短路径长度$\\bar{L}$是这些路径长度的平均值。这可以通过从LCC中的每个节点运行广度优先搜索（BFS）或在LCC的邻接矩阵上使用Floyd-Warshall算法来计算。\n\n### 第4部分：综合与比较\n\n最后一步是为每个测试用例（即一对距离截断值$(d_{\\mathrm{atom}}, d_{\\mathrm{res}})$）应用这些计算。对于每种情况，我们计算$G_{\\mathrm{atom}}$和$G_{\\mathrm{res}}$的度量指标，然后计算它们的差异。九个输出值是：\n1.  $\\bar{k}_{\\mathrm{atom}}$：原子水平图的平均度。\n2.  $\\bar{k}_{\\mathrm{res}}$：残基水平图的平均度。\n3.  $D_{\\mathrm{TV}}(P_{\\mathrm{atom}}, P_{\\mathrm{res}})$：度分布之间的总变差距离。\n4.  $\\bar{C}_{\\mathrm{atom}}$：原子水平图的平均聚类系数。\n5.  $\\bar{C}_{\\mathrm{res}}$：残基水平图的平均聚类系数。\n6.  $\\Delta \\bar{C} = \\bar{C}_{\\mathrm{atom}} - \\bar{C}_{\\mathrm{res}}$：平均聚类系数的差异。\n7.  $\\bar{L}_{\\mathrm{atom}}$：原子水平图的平均最短路径长度。\n8.  $\\bar{L}_{\\mathrm{res}}$：残基水平图的平均最短路径长度。\n9.  $\\Delta \\bar{L} = \\bar{L}_{\\mathrm{atom}} - \\bar{L}_{\\mathrm{res}}$：平均路径长度的差异。\n\n这项全面的分析将揭示表示选择（原子水平 vs. 基于残基）如何影响蛋白质接触网络关键的拓扑特性。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.sparse.csgraph import connected_components, shortest_path\n\ndef generate_helix_structure(n_res, h, R, d_theta_deg):\n    \"\"\"\n    Generates atomic coordinates for an ideal alpha helix.\n    Returns a numpy array of shape (n_res, 4, 3) for N, CA, C, O atoms.\n    \"\"\"\n    d_theta_rad = np.deg2rad(d_theta_deg)\n    \n    # Bond lengths\n    l_n_ca = 1.47\n    l_ca_c = 1.53\n    l_c_o = 1.24\n\n    # Atom types map: 0:N, 1:CA, 2:C, 3:O\n    coords = np.zeros((n_res, 4, 3))\n    \n    # 1. Generate CA coordinates\n    ca_coords = np.zeros((n_res, 3))\n    for i in range(n_res):\n        theta_i = i * d_theta_rad\n        ca_coords[i, 0] = R * np.cos(theta_i)\n        ca_coords[i, 1] = R * np.sin(theta_i)\n        ca_coords[i, 2] = i * h\n    coords[:, 1, :] = ca_coords\n\n    # 2. Generate other heavy atoms\n    z_axis = np.array([0., 0., 1.])\n    \n    for i in range(n_res):\n        # Calculate tangent vector t_i\n        if i == 0:\n            t_i = ca_coords[1] - ca_coords[0]\n        elif i == n_res - 1:\n            t_i = ca_coords[i] - ca_coords[i-1]\n        else:\n            t_i = ca_coords[i+1] - ca_coords[i-1]\n        t_i /= np.linalg.norm(t_i)\n\n        # Place N and C atoms\n        coords[i, 0, :] = ca_coords[i] - l_n_ca * t_i\n        coords[i, 2, :] = ca_coords[i] + l_ca_c * t_i\n\n        # Calculate normal vector n_i and place O atom\n        t_cross_z = np.cross(t_i, z_axis)\n        norm_t_cross_z = np.linalg.norm(t_cross_z)\n        if norm_t_cross_z > 1e-9:\n            n_i = t_cross_z / norm_t_cross_z\n        else:\n            n_i = np.array([1., 0., 0.])\n        \n        coords[i, 3, :] = coords[i, 2, :] + l_c_o * n_i\n        \n    return coords\n\ndef analyze_graph(A):\n    \"\"\"\n    Analyzes a graph given its adjacency matrix A.\n    Returns avg_degree, degree_dist, avg_clustering, avg_path_length.\n    \"\"\"\n    n = A.shape[0]\n    if n == 0:\n        return 0.0, np.array([1.0]), 0.0, 0.0\n        \n    # Degrees and average degree\n    degrees = A.sum(axis=1)\n    avg_degree = np.mean(degrees)\n    \n    # Degree distribution\n    max_k = int(np.max(degrees)) if degrees.size > 0 else 0\n    k_counts = np.zeros(max_k + 1)\n    for k in degrees:\n        k_counts[int(k)] += 1\n    degree_dist = k_counts / n\n\n    # Average clustering coefficient\n    A3 = np.linalg.matrix_power(A, 3)\n    diagonals = np.diag(A3)\n    c_i = np.zeros(n)\n    for i in range(n):\n        ki = degrees[i]\n        if ki >= 2:\n            c_i[i] = diagonals[i] / (ki * (ki - 1))\n    avg_clustering = np.mean(c_i)\n\n    # Average shortest path length\n    n_components, labels = connected_components(A, directed=False)\n    if n_components > 0:\n        component_sizes = np.bincount(labels)\n        largest_comp_label = np.argmax(component_sizes)\n        lcc_nodes = np.where(labels == largest_comp_label)[0]\n        s = len(lcc_nodes)\n    else:\n        s = 0\n\n    if s < 2:\n        avg_path_length = 0.0\n    else:\n        lcc_A = A[np.ix_(lcc_nodes, lcc_nodes)]\n        path_matrix = shortest_path(lcc_A, directed=False, unweighted=True)\n        # Sum of upper triangle (excluding diagonal)\n        total_path_length = np.sum(np.triu(path_matrix, k=1))\n        num_pairs = s * (s - 1) / 2\n        avg_path_length = total_path_length / num_pairs\n        \n    return avg_degree, degree_dist, avg_clustering, avg_path_length\n\ndef solve():\n    # Define constants from the problem\n    N_RES = 12\n    H = 1.5\n    R = 2.3\n    D_THETA = 100.0\n    \n    test_cases = [\n        (4.5, 7.0),\n        (3.0, 5.0),\n        (6.0, 10.0),\n        (4.0, 4.0),\n    ]\n\n    # Generate structure once\n    structure_coords = generate_helix_structure(N_RES, H, R, D_THETA)\n    \n    all_results = []\n\n    for d_atom, d_res in test_cases:\n        # 1. Build atom-level graph\n        n_atoms = N_RES * 4\n        atom_coords_flat = structure_coords.reshape(n_atoms, 3)\n        diffs = atom_coords_flat[:, np.newaxis, :] - atom_coords_flat[np.newaxis, :, :]\n        dist_matrix_atom = np.sqrt(np.sum(diffs**2, axis=-1))\n        A_atom = (dist_matrix_atom <= d_atom).astype(int)\n        np.fill_diagonal(A_atom, 0)\n\n        # 2. Build residue-level graph\n        dist_matrix_res_min = np.full((N_RES, N_RES), np.inf)\n        for i in range(N_RES):\n            for j in range(i + 1, N_RES):\n                res_i_coords = structure_coords[i, :, :]\n                res_j_coords = structure_coords[j, :, :]\n                \n                # Pairwise distances between all atoms of residue i and j\n                res_diffs = res_i_coords[:, np.newaxis, :] - res_j_coords[np.newaxis, :, :]\n                res_dists = np.sqrt(np.sum(res_diffs**2, axis=-1))\n                min_dist = np.min(res_dists)\n                dist_matrix_res_min[i, j] = min_dist\n                dist_matrix_res_min[j, i] = min_dist\n        \n        A_res = (dist_matrix_res_min <= d_res).astype(int)\n        np.fill_diagonal(A_res, 0)\n        \n        # 3. Analyze graphs\n        k_atom, p_atom, c_atom, l_atom = analyze_graph(A_atom)\n        k_res, p_res, c_res, l_res = analyze_graph(A_res)\n\n        # 4. Compute TV distance and deltas\n        len_p_atom = len(p_atom)\n        len_p_res = len(p_res)\n        k_max = max(len_p_atom, len_p_res)\n        \n        p_atom_padded = np.pad(p_atom, (0, k_max - len_p_atom), 'constant')\n        p_res_padded = np.pad(p_res, (0, k_max - len_p_res), 'constant')\n        \n        d_tv = 0.5 * np.sum(np.abs(p_atom_padded - p_res_padded))\n        delta_c = c_atom - c_res\n        delta_l = l_atom - l_res\n        \n        case_results = [\n            k_atom, k_res, d_tv, c_atom, c_res, delta_c, l_atom, l_res, delta_l\n        ]\n        all_results.append(case_results)\n\n    # Format the final output string without extra spaces\n    outer_parts = []\n    for inner_list in all_results:\n        inner_parts_str = [f\"{val:.10f}\" for val in inner_list]\n        outer_parts.append(f\"[{','.join(inner_parts_str)}]\")\n    final_output_str = f\"[{','.join(outer_parts)}]\"\n    print(final_output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "蛋白质中残基间的相互作用强度各不相同，并非简单的“开”或“关”。一个完整的网络模型会使用权重来表示这些相互作用的强度，但在分析中，为了简化，研究人员常常会设定一个阈值将加权网络二值化。这个练习旨在探讨这种简化所带来的信息损失，让你在加权网络和通过阈值处理得到的无权网络之间进行直接比较。通过计算和对比平均最短路径长度、全局效率和聚类系数等指标在二值化前后的变化，你将学会批判性地评估这一常用分析步骤的后果，并理解保留权重信息的价值。",
            "id": "3855812",
            "problem": "考虑一种用于蛋白质动力学和变构的残基-残基相互作用网络表示，其中残基是节点，成对动力学耦合（例如，原子涨落的皮尔逊相关系数绝对值）被编码为非负对称权重。令 $n$ 表示残基（节点）的数量，并令 $W \\in \\mathbb{R}^{n \\times n}$ 为加权邻接矩阵，其中 $W_{ij} \\in [0,1]$，$W_{ii} = 0$，且 $W_{ij} = W_{ji}$。定义一个由阈值 $\\tau \\in [0,1]$ 参数化的二值化算子，该算子生成一个无权邻接矩阵 $A \\in \\{0,1\\}^{n \\times n}$，其规则为：当且仅当 $W_{ij} \\ge \\tau$ 且 $i \\ne j$ 时，$A_{ij} = 1$，否则 $A_{ij} = 0$。将 $W$ 和 $A$ 均视为无自环的无向图。\n\n为评估二值化所导致的信息损失，请在加权图和经过阈值处理的无权图上计算并比较以下网络度量指标：\n\n- 平均最短路径长度：对于加权图，通过 $C_{ij} = 1/W_{ij}$（如果 $W_{ij} > 0$）和 $C_{ij} = +\\infty$（否则）定义边成本矩阵 $C$，并令 $d^{w}_{ij}$ 表示使用 $C$ 时节点 $i$ 和 $j$ 之间的最短路径距离。对于无权图，令 $d^{u}_{ij}$ 表示使用 $A$ 的以边数计算的最短路径距离（每条边的成本为 $1$）。图的平均最短路径长度定义为所有 $i < j$ 的无序对 $(i,j)$ 的有限 $d_{ij}$ 的算术平均值。\n- 全局效率：对于给定的距离矩阵 $D$，定义为 $E = \\frac{1}{n(n-1)} \\sum_{i \\ne j} \\frac{1}{D_{ij}}$，约定 $\\frac{1}{+\\infty} = 0$，且不包括 $\\frac{1}{0}$，因为 $D_{ii} = 0$ 不在求和范围内。\n- 平均聚类系数：对于无权图，将节点 $i$ 的聚类系数定义为 $C^{u}_i = \\frac{\\text{与 } i \\text{ 相关联的三角形数量}}{\\text{以 } i \\text{ 为中心的连通三元组数量}}$，其中分母等于 $\\frac{k_i(k_i-1)}{2}$（$k_i$ 为节点 $i$ 的度），分子可从 $A$ 的立方获得，因为对于无向简单图，$A^3$ 的对角线满足 $(A^3)_{ii} = 2 T_i$，其中 $T_i$ 是与节点 $i$ 相关联的三角形数量。如果 $k_i < 2$，则设置 $C^{u}_i = 0$。平均聚类系数为 $\\bar{C}^u = \\frac{1}{n} \\sum_{i=1}^n C^{u}_i$。对于加权图，使用 Onnela 公式：首先通过 $\\tilde{W}_{ij} = W_{ij}/\\max_{p,q} W_{pq}$ 归一化权重，然后将 $C^{w}_i$ 定义为 $\\frac{1}{k_i(k_i - 1)} \\sum_{j,k} \\left( \\tilde{W}_{ij} \\tilde{W}_{ik} \\tilde{W}_{jk} \\right)^{1/3}$，求和遍历满足 $\\tilde{W}_{jk} > 0$ 的 $i$ 的无序邻居对 $(j,k)$（其中 $j < k$），并在 $k_i < 2$ 时设置 $C^{w}_i = 0$。平均加权聚类系数为 $\\bar{C}^w = \\frac{1}{n} \\sum_{i=1}^n C^{w}_i$。\n- 谱半径：对于每个邻接矩阵 $M$（$W$ 或 $A$），将谱半径 $\\lambda_{\\max}(M)$ 定义为 $M$ 的最大特征值。\n\n对于每个度量指标 $M \\in \\{\\text{ASPL}, \\text{Eff}, \\text{Clust}, \\text{Spec}\\}$，将由二值化引起的相对损失定义为 $L_M = \\frac{|M_{\\text{weighted}} - M_{\\text{binary}}|}{|M_{\\text{weighted}}| + \\varepsilon}$，其中 $\\varepsilon = 10^{-12}$ 是一个为避免除以零而设的小常数。所有量均为无量纲。\n\n你的任务是编写一个程序，对每个提供的测试用例，使用上述定义计算四个损失值 $[L_{\\text{ASPL}}, L_{\\text{Eff}}, L_{\\text{Clust}}, L_{\\text{Spec}}]$ 并输出它们，每个值四舍五入到 $6$ 位小数。\n\n使用以下参数值测试套件（每个测试用例是一对 $(W,\\tau)$）：\n\n- 测试用例 1 ($n = 6$):\n  $$\n  W = \\begin{pmatrix}\n  0  0.82  0.15  0.00  0.38  0.41 \\\\\n  0.82  0  0.22  0.30  0.27  0.58 \\\\\n  0.15  0.22  0  0.74  0.12  0.00 \\\\\n  0.00  0.30  0.74  0  0.33  0.26 \\\\\n  0.38  0.27  0.12  0.33  0  0.69 \\\\\n  0.41  0.58  0.00  0.26  0.69  0\n  \\end{pmatrix}, \\quad \\tau = 0.30.\n  $$\n- 测试用例 2 ($n = 6$):\n  $$\n  W = \\begin{pmatrix}\n  0  0.70  0.05  0.00  0.00  0.72 \\\\\n  0.70  0  0.00  0.00  0.68  0.00 \\\\\n  0.05  0.00  0  0.71  0.00  0.00 \\\\\n  0.00  0.00  0.71  0  0.00  0.70 \\\\\n  0.00  0.68  0.00  0.00  0  0.00 \\\\\n  0.72  0.00  0.00  0.70  0.00  0\n  \\end{pmatrix}, \\quad \\tau = 0.70.\n  $$\n- 测试用例 3 ($n = 5$):\n  $$\n  W = \\begin{pmatrix}\n  0  0.23  0.18  0.14  0.19 \\\\\n  0.23  0  0.17  0.21  0.16 \\\\\n  0.18  0.17  0  0.20  0.22 \\\\\n  0.14  0.21  0.20  0  0.15 \\\\\n  0.19  0.16  0.22  0.15  0\n  \\end{pmatrix}, \\quad \\tau = 0.10.\n  $$\n\n实现要求：\n\n- 在加权和无权情况下均使用 Dijkstra 算法计算最短路径（无权情况下的边成本为 1），将不存在的边视为成本为 $+\\infty$。\n- 对于平均最短路径长度，仅对 $i < j$ 的无序节点对的有限距离进行平均。\n- 对于全局效率，使用包含全部 $n(n-1)$ 个有向对计数的定义，并将 $\\frac{1}{+\\infty}$ 视为 $0$。\n- 对于无权聚类系数，通过 $T_i = \\frac{(A^3)_{ii}}{2}$ 使用 $A^3$ 的对角线计算 $T_i$，并在 $k_i \\ge 2$ 时使用 $C^{u}_i = \\frac{2 T_i}{k_i(k_i-1)}$，否则 $C^{u}_i = 0$。\n- 对于加权聚类系数，使用如上所述的 Onnela 定义和 $\\tilde{W}$，并在 $k_i < 2$ 时设置 $C^{w}_i = 0$。\n\n最终输出格式：\n\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，每个测试用例的结果是按 $[L_{\\text{ASPL}}, L_{\\text{Eff}}, L_{\\text{Clust}}, L_{\\text{Spec}}]$ 顺序排列的四个损失值的子列表，每个浮点数值四舍五入到 $6$ 位小数。输出中不得包含任何空格。例如，结构必须类似于 $[[x_1,x_2,x_3,x_4],[y_1,y_2,y_3,y_4],[z_1,z_2,z_3,z_4]]$，所有条目均为十进制数。",
            "solution": "该问题是有效的，因为它在科学上基于网络理论，通过具体的数学定义和测试用例进行了明确的阐述，并且其表述是客观的。所有必要的信息都已提供，所需的计算在计算上是可行的。我现在将着手提供一个完整的解决方案。\n\n任务是量化当一个加权蛋白质相互作用网络根据权重阈值 $\\tau$ 转换为一个无权（二值）网络时所产生的信息损失。该损失针对四个标准的网络度量指标进行衡量：平均最短路径长度（ASPL）、全局效率、平均聚类系数和谱半径。对于每个度量指标 $M$，相对损失 $L_M$ 计算为 $L_M = \\frac{|M_{\\text{weighted}} - M_{\\text{binary}}|}{|M_{\\text{weighted}}| + \\varepsilon}$，其中 $\\varepsilon = 10^{-12}$ 是一个用于保证数值稳定性的小常数。\n\n令加权邻接矩阵为 $W \\in \\mathbb{R}^{n \\times n}$，二值化阈值为 $\\tau$。生成的无权邻接矩阵 $A$ 定义为：当 $W_{ij} \\ge \\tau$ 且 $i \\ne j$ 时，$A_{ij} = 1$，否则 $A_{ij} = 0$。\n\n对于每个测试用例 $(W, \\tau)$，总体算法如下：\n1.  计算由 $W$ 表示的加权图的四个度量指标。记为 $M_{\\text{ASPL,w}}$、$M_{\\text{Eff,w}}$、$M_{\\text{Clust,w}}$ 和 $M_{\\text{Spec,w}}$。\n2.  从 $W$ 和 $\\tau$ 生成二值邻接矩阵 $A$。\n3.  计算由 $A$ 表示的无权图的相同四个度量指标。记为 $M_{\\text{ASPL,b}}$、$M_{\\text{Eff,b}}$、$M_{\\text{Clust,b}}$ 和 $M_{\\text{Spec,b}}$。\n4.  对每个度量指标，使用给定公式计算相对损失 $L_M$。\n\n每个度量指标的计算详述如下。\n\n**1. 基于最短路径的度量指标（ASPL 和效率）**\n\nASPL 和效率的计算基础是所有节点对之间的最短路径距离矩阵 $D$。其计算方法对加权图和无权图有所不同。\n\n-   **加权图 ($W$)**：边 $(i,j)$ 的成本定义为其权重的倒数，$c_{ij} = 1/W_{ij}$（对于 $W_{ij} > 0$）。不存在的边具有无穷大成本。我们构建成本矩阵 $C$，并从每个节点开始运行 Dijkstra 算法，以找到所有节点对 $(i,j)$ 之间的最短路径距离 $d^w_{ij}$。这将生成距离矩阵 $D^w$。使用 `method='D'` 的 `scipy.sparse.csgraph.shortest_path` 函数适用于此任务。\n\n-   **无权图 ($A$)**：每条边具有统一的成本 $1$。最短路径距离 $d^u_{ij}$ 就是连接节点 $i$ 和 $j$ 的路径中的最小边数。这可以通过对邻接矩阵 $A$ 应用相同的最短路径算法来计算，从而生成距离矩阵 $D^u$。\n\n一旦计算出 $D^w$ 和 $D^u$，就可以计算 ASPL 和效率：\n\n-   **平均最短路径长度 (ASPL)**：ASPL 是不同无序节点对之间所有有限最短路径距离的平均值。对于一个 $n$ 节点图的距离矩阵 $D$，其计算公式为：\n    $$\n    \\text{ASPL} = \\frac{1}{N_{\\text{finite}}} \\sum_{i < j, D_{ij} < \\infty} D_{ij}\n    $$\n    其中 $N_{\\text{finite}}$ 是存在有限路径的对 $(i,j)$（其中 $i<j$）的数量。\n\n-   **全局效率**：全局效率量化了网络中信息或物质流动的整体效率。对于一个距离矩阵 $D$，其计算公式为：\n    $$\n    E = \\frac{1}{n(n-1)} \\sum_{i \\ne j} \\frac{1}{D_{ij}}\n    $$\n    按照约定，当 $D_{ij} = \\infty$ 时，$\\frac{1}{D_{ij}} = 0$。\n\n**2. 聚类系数**\n\n聚类系数衡量了网络中的“小世界”特性或节点的邻居相互连接的趋势。计算方法对加权图和无权图也有所不同。\n\n-   **无权图 ($A$)**：节点 $i$ 的局部聚类系数 $C_i^u$ 是其邻居之间实际存在的边数与可能的最大边数之比。如果一个节点的度 $k_i < 2$，则其局部聚类系数为 $0$。对于 $k_i \\ge 2$：\n    $$\n    C_i^u = \\frac{2 T_i}{k_i (k_i - 1)}\n    $$\n    其中 $T_i$ 是包含节点 $i$ 的三角形数量，可以通过计算邻接矩阵的立方 $A^3$ 的对角元素 $(A^3)_{ii} = 2T_i$ 来找到。平均聚类系数 $\\bar{C}^u$ 是所有局部系数的平均值。\n\n-   **加权图 ($W$)**：我们使用 Onnela 等人提出的加权聚类系数的定义。首先，通过最大权重对权重矩阵进行归一化：$\\tilde{W}_{ij} = W_{ij}/\\max_{p,q} W_{pq}$。然后，节点 $i$ 的局部加权聚类系数 $C_i^w$ 定义为：\n    $$\n    C_i^w = \\frac{1}{k_i(k_i-1)} \\sum_{j,k} (\\tilde{W}_{ij} \\tilde{W}_{ik} \\tilde{W}_{jk})^{1/3}\n    $$\n    该求和遍历所有 $j$ 和 $k$ 对，它们都是节点 $i$ 的邻居。问题陈述中的求和约定（遍历无序对 $j<k$ 且 $\\tilde{W}_{jk}>0$）本质上等同于此，因为它将总和限制在封闭的三角形上，并将每对计数一次。对于 $k_i < 2$ 的情况，定义 $C^w_i=0$。平均加权聚类系数 $\\bar{C}^w$ 是所有 $C_i^w$ 的平均值。\n\n**3. 谱半径**\n\n谱半径 $\\lambda_{\\max}(M)$ 是矩阵 $M$ 特征值的最大绝对值。然而，对于对称非负矩阵（如 $W$ 和 $A$），所有特征值都是实数，并且根据 Perron-Frobenius 定理，谱半径等于最大特征值。我们可以使用 `numpy.linalg.eigvalsh` 来高效地计算实对称矩阵的特征值。\n\n-   $M_{\\text{Spec,w}} = \\max(\\text{eig}(W))$\n-   $M_{\\text{Spec,b}} = \\max(\\text{eig}(A))$\n\n将这些计算步骤应用于每个测试用例，我们就能得到所需的四个损失值。",
            "answer": "```python\nimport numpy as np\nfrom scipy.sparse.csgraph import shortest_path\nfrom itertools import combinations\n\ndef get_aspl(dist_matrix):\n    \"\"\"Computes the average shortest path length.\"\"\"\n    n = dist_matrix.shape[0]\n    if n <= 1:\n        return 0.0\n    \n    # Get upper triangle for unordered pairs (i < j)\n    paths = dist_matrix[np.triu_indices(n, k=1)]\n    \n    # Filter for finite paths\n    finite_paths = paths[np.isfinite(paths)]\n    \n    if len(finite_paths) == 0:\n        return 0.0\n    else:\n        return np.mean(finite_paths)\n\ndef get_efficiency(dist_matrix):\n    \"\"\"Computes the global efficiency.\"\"\"\n    n = dist_matrix.shape[0]\n    if n <= 1:\n        return 0.0\n        \n    # np.seterr is used to handle 1/0, which we correct later.\n    # 1/inf is correctly handled as 0 by numpy.\n    with np.errstate(divide='ignore'):\n        inv_dist = 1.0 / dist_matrix\n    \n    # Paths to self are not included in the sum\n    np.fill_diagonal(inv_dist, 0)\n\n    return np.sum(inv_dist) / (n * (n - 1))\n\ndef get_avg_clust_unweighted(A):\n    \"\"\"Computes the average unweighted clustering coefficient.\"\"\"\n    n = A.shape[0]\n    if n == 0:\n        return 0.0\n        \n    A_cubed = np.linalg.matrix_power(A, 3)\n    diag_A3 = np.diag(A_cubed)\n    degrees = np.sum(A, axis=1)\n    \n    coeffs = np.zeros(n)\n    for i in range(n):\n        k_i = degrees[i]\n        if k_i >= 2:\n            denominator = k_i * (k_i - 1)\n            coeffs[i] = diag_A3[i] / denominator\n            \n    return np.mean(coeffs)\n\ndef get_avg_clust_weighted(W):\n    \"\"\"Computes the average weighted clustering coefficient (Onnela formulation).\"\"\"\n    n = W.shape[0]\n    if n == 0:\n        return 0.0\n\n    max_weight = np.max(W)\n    if max_weight == 0:\n        return 0.0\n    W_tilde = W / max_weight\n    \n    # Get degrees from unweighted equivalent for neighbor iteration\n    A_equiv = (W > 0).astype(float)\n    degrees = np.sum(A_equiv, axis=1)\n    \n    coeffs = np.zeros(n)\n    for i in range(n):\n        k_i = degrees[i]\n        \n        if k_i >= 2:\n            neighbors = np.where(W[i, :] > 0)[0]\n            triangle_sum = 0.0\n            # Problem statement: sum over unordered pairs of neighbors (j < k)\n            for j, k in combinations(neighbors, 2):\n                # The term is only non-zero if a triangle exists (W[j,k] > 0)\n                term = (W_tilde[i, j] * W_tilde[i, k] * W_tilde[j, k])**(1/3.0)\n                triangle_sum += term\n            \n            # The definition implicitly uses 2*sum over combinations, so we need to multiply by 2\n            # Or just sum over all ordered pairs (j,k) and divide by 2, but the problem statement implies unordered pairs.\n            # Onnela's original formula sums over j,k and does not divide by 2 for the numerator.\n            # sum_{j,k} (...) = 2 * sum_{j<k} (...). So we multiply our sum by 2.\n            denominator = k_i * (k_i - 1)\n            coeffs[i] = (2 * triangle_sum) / denominator\n\n    return np.mean(coeffs)\n\ndef get_spectral_radius(matrix):\n    \"\"\"Computes the spectral radius of a symmetric matrix.\"\"\"\n    if matrix.shape[0] == 0:\n        return 0.0\n    # For real symmetric matrices, eigenvalues are real.\n    # For non-negative matrices, spectral radius is the largest eigenvalue.\n    eigvals = np.linalg.eigvalsh(matrix)\n    return np.max(eigvals)\n\ndef calculate_metrics(M, is_weighted):\n    \"\"\"Dispatcher to calculate all four metrics for a given matrix.\"\"\"\n    n = M.shape[0]\n\n    if is_weighted:\n        # Weighted graph calculations\n        with np.errstate(divide='ignore'):\n            cost_matrix = 1.0 / M\n        cost_matrix[M == 0] = np.inf\n        np.fill_diagonal(cost_matrix, 0)\n        dist_matrix = shortest_path(csgraph=cost_matrix, directed=False, method='D')\n        \n        aspl = get_aspl(dist_matrix)\n        eff = get_efficiency(dist_matrix)\n        clust = get_avg_clust_weighted(M)\n        spec = get_spectral_radius(M)\n    else:\n        # Unweighted graph calculations\n        dist_matrix = shortest_path(csgraph=M, directed=False, method='D')\n\n        aspl = get_aspl(dist_matrix)\n        eff = get_efficiency(dist_matrix)\n        clust = get_avg_clust_unweighted(M)\n        spec = get_spectral_radius(M)\n        \n    return aspl, eff, clust, spec\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    \"\"\"\n    test_cases = [\n        (np.array([\n            [0, 0.82, 0.15, 0.00, 0.38, 0.41],\n            [0.82, 0, 0.22, 0.30, 0.27, 0.58],\n            [0.15, 0.22, 0, 0.74, 0.12, 0.00],\n            [0.00, 0.30, 0.74, 0, 0.33, 0.26],\n            [0.38, 0.27, 0.12, 0.33, 0, 0.69],\n            [0.41, 0.58, 0.00, 0.26, 0.69, 0]\n        ]), 0.30),\n        (np.array([\n            [0, 0.70, 0.05, 0.00, 0.00, 0.72],\n            [0.70, 0, 0.00, 0.00, 0.68, 0.00],\n            [0.05, 0.00, 0, 0.71, 0.00, 0.00],\n            [0.00, 0.00, 0.71, 0, 0.00, 0.70],\n            [0.00, 0.68, 0.00, 0.00, 0, 0.00],\n            [0.72, 0.00, 0.00, 0.70, 0.00, 0]\n        ]), 0.70),\n        (np.array([\n            [0, 0.23, 0.18, 0.14, 0.19],\n            [0.23, 0, 0.17, 0.21, 0.16],\n            [0.18, 0.17, 0, 0.20, 0.22],\n            [0.14, 0.21, 0.20, 0, 0.15],\n            [0.19, 0.16, 0.22, 0.15, 0]\n        ]), 0.10)\n    ]\n    \n    epsilon = 1e-12\n    all_results = []\n\n    for W, tau in test_cases:\n        # Binarize W to get A\n        A = (W >= tau).astype(float)\n        np.fill_diagonal(A, 0)\n        \n        # Calculate metrics for both graphs\n        metrics_w = calculate_metrics(W, is_weighted=True)\n        metrics_b = calculate_metrics(A, is_weighted=False)\n        \n        # Compute relative losses\n        losses = []\n        for M_w, M_b in zip(metrics_w, metrics_b):\n            loss = np.abs(M_w - M_b) / (np.abs(M_w) + epsilon)\n            losses.append(loss)\n            \n        all_results.append(losses)\n\n    # Format output string\n    rounded_results = []\n    for result_list in all_results:\n        rounded_results.append([f\"{x:.6f}\" for x in result_list])\n\n    outer_list_str = []\n    for res in rounded_results:\n        inner_list_str = f\"[{','.join(res)}]\"\n        outer_list_str.append(inner_list_str)\n\n    print(f\"[{','.join(outer_list_str)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "蛋白质网络分析的一个核心应用是识别变构信号的通讯路径。这些关键路径可以被看作是网络中的“脆弱桥梁”，它们的断裂会对整个网络的连通性造成不成比例的巨大影响。本练习将介绍一种强大的网络分析技术——脆弱性分析，它利用边的介数中心性（edge betweenness centrality）来识别这些关键的通讯桥梁。通过比较靶向移除高介数边与随机移除边的效果，你将学习如何定位蛋白质结构中对维持通讯至关重要的边，从而深入理解变构调控的结构基础。",
            "id": "3855936",
            "problem": "您的任务是通过比较随机移除边与基于边介数中心性的目标性移除边的影响，来评估一个变构残基-残基相互作用网络是否包含脆弱的通信桥。将蛋白质网络建模为一个无向简单图 $G = (V,E)$，其中节点代表残基，边代表有效的动态耦合。根据图论的基本定义，一条边 $e \\in E$ 的边介数中心性 $B_e$ 是对所有有序的源-目标对，遍历 $e$ 的测地线（最短）路径所占比例的总和：$$B_e \\equiv \\sum_{s \\in V}\\sum_{\\substack{t \\in V\\\\ t \\neq s}} \\frac{\\sigma_{s t}(e)}{\\sigma_{s t}},$$ 其中 $\\sigma_{s t}$ 是 $s$ 和 $t$ 之间最短路径的数量，而 $\\sigma_{s t}(e)$ 是这些路径中包含边 $e$ 的数量。考虑两种移除边的策略：(i) 移除 $k$ 条具有最高 $B_e$ 的边（目标性移除），或 (ii) 从图中不放回地均匀随机抽样移除 $k$ 条边（随机移除）。在移除一组边 $R \\subseteq E$ 后，将最大连通分量（Largest Connected Component (LCC)）中的节点比例定义为 $$f_{\\mathrm{LCC}}(G\\setminus R) \\equiv \\frac{\\lvert C_{\\max}(G\\setminus R)\\rvert}{\\lvert V\\rvert},$$ 其中 $C_{\\max}(G\\setminus R)$ 表示剩余图的最大连通分量。对于随机策略，通过对 $k$ 条边的 $S$ 次独立随机抽取得到的 $f_{\\mathrm{LCC}}$ 进行平均，来估计平均 LCC 比例。定义脆弱性得分 $$V \\equiv \\overline{f}_{\\mathrm{rand}} - f_{\\mathrm{target}},$$ 其中 $\\overline{f}_{\\mathrm{rand}}$ 是随机移除下的 $f_{\\mathrm{LCC}}$ 样本均值，而 $f_{\\mathrm{target}}$ 是目标性移除下的 LCC 比例。较大的正值 $V$ 表示网络中存在作为脆弱桥梁的边，这些边不成比例地支撑了网络中的测地线通信。\n\n您的程序必须：\n- 构建指定的无向图，并直接根据无权图的路径计数定义，使用第一性原理算法（例如，使用广度优先搜索（BFS）来枚举距离和路径计数）计算边介数中心性 $B_e$。\n- 对于每个测试用例，计算 $f_{\\mathrm{target}}$，使用 $S$ 次随机试验计算 $\\overline{f}_{\\mathrm{rand}}$，并返回该测试用例的 $V$ 值（浮点数）。\n- 使用固定的伪随机数生成器种子，以使 $\\overline{f}_{\\mathrm{rand}}$ 是确定性的。\n- 最终输出表示为单行，包含所有测试用例的脆弱性得分 $V$，形式为用方括号括起来的逗号分隔列表，每个浮点数四舍五入到 $3$ 位小数，例如 $[0.123,0.000,0.456]$。\n\n测试套件规范（所有图均为无权无向图）：\n- 测试用例 $1$（两个密集模块，由一个单一的模块间桥连接）：$V$ 有 $10$ 个节点，边是节点 $\\{0,1,2,3,4\\}$ 和 $\\{5,6,7,8,9\\}$ 上的两个团，外加一条桥接边 $(4,5)$ 的并集。具体来说，边是 $$\\{(0,1),(0,2),(0,3),(0,4),(1,2),(1,3),(1,4),(2,3),(2,4),(3,4),(5,6),(5,7),(5,8),(5,9),(6,7),(6,8),(6,9),(7,8),(7,9),(8,9),(4,5)\\}.$$ 使用 $k=1$ 和 $S=200$。\n- 测试用例 $2$（完全图）：$V$ 有 $6$ 个节点，所有节点间都有边，即边为 $$\\{(0,1),(0,2),(0,3),(0,4),(0,5),(1,2),(1,3),(1,4),(1,5),(2,3),(2,4),(2,5),(3,4),(3,5),(4,5)\\}.$$ 使用 $k=1$ 和 $S=200$。\n- 测试用例 $3$（线性链）：$V$ 有 $6$ 个节点，边为 $$\\{(0,1),(1,2),(2,3),(3,4),(4,5)\\}.$$ 使用 $k=1$ 和 $S=200$。\n- 测试用例 $4$（冗余的模块间连接）：$V$ 有 $8$ 个节点；两个在 $\\{0,1,2,3\\}$ 和 $\\{4,5,6,7\\}$ 上的团，外加 $3$ 条模块间边 $(0,4),(1,5),(2,6)$。具体来说，边是 $$\\{(0,1),(0,2),(0,3),(1,2),(1,3),(2,3),(4,5),(4,6),(4,7),(5,6),(5,7),(6,7),(0,4),(1,5),(2,6)\\}.$$ 使用 $k=2$ 和 $S=200$。\n- 测试用例 $5$（边界情况 $k=0$）：重用测试用例 $1$ 的图。使用 $k=0$ 和 $S=50$。\n\n最终输出格式：\n- 您的程序应产生单行输出，包含结果，形式为用方括号括起来的逗号分隔列表，即 $[V_1,V_2,V_3,V_4,V_5]$，其中每个 $V_i$ 四舍五入到 $3$ 位小数。",
            "solution": "用户的请求是验证并解决一个关于网络脆弱性的问题，该网络被建模为图，并受到不同边移除策略的影响。\n\n### 问题验证\n首先评估问题的有效性。\n\n**步骤 1：提取已知条件**\n- **图模型**：一个无向简单图 $G = (V,E)$，其中 $V$ 是残基（节点），$E$ 是动态耦合（边）。\n- **边介数中心性 ($B_e$)**：$B_e \\equiv \\sum_{s \\in V}\\sum_{\\substack{t \\in V\\\\ t \\neq s}} \\frac{\\sigma_{s t}(e)}{\\sigma_{s t}}$，其中 $\\sigma_{st}$ 是节点 $s$ 和 $t$ 之间的最短路径数量，而 $\\sigma_{st}(e)$ 是通过边 $e$ 的此类路径的数量。\n- **边移除策略**：\n    1.  **目标性**：移除 $k$ 条具有最高 $B_e$ 的边。\n    2.  **随机性**：移除 $k$ 条通过不放回均匀随机抽样选出的边。\n- **评估指标（LCC 比例）**：$f_{\\mathrm{LCC}}(G\\setminus R) \\equiv \\frac{\\lvert C_{\\max}(G\\setminus R)\\rvert}{\\lvert V\\rvert}$，其中 $C_{\\max}$ 是移除边集 $R$ 后图的最大连通分量。\n- **脆弱性得分 ($V$)**：$V \\equiv \\overline{f}_{\\mathrm{rand}} - f_{\\mathrm{target}}$，其中 $\\overline{f}_{\\mathrm{rand}}$ 是 $S$ 次随机试验中 $f_{\\mathrm{LCC}}$ 的平均值，而 $f_{\\mathrm{target}}$ 是单次目标性试验的 $f_{\\mathrm{LCC}}$。\n- **程序要求**：\n    - $B_e$ 必须根据其第一性原理定义计算。\n    - 必须使用固定的伪随机数生成器种子。\n- **测试套件**：\n    - **案例 1**：由两个 5 节点团通过一条边连接的图；$k=1$, $S=200$。\n    - **案例 2**：6 个节点上的完全图；$k=1$, $S=200$。\n    - **案例 3**：6 个节点的线性链；$k=1$, $S=200$。\n    - **案例 4**：由两个 4 节点团通过三条边连接的图；$k=2$, $S=200$。\n    - **案例 5**：使用案例 1 的图；$k=0$, $S=50$。\n\n**步骤 2：使用提取的已知条件进行验证**\n根据验证标准分析问题陈述。\n- **科学/事实合理性**：该问题在网络科学和图论中有坚实的基础。介数中心性、连通分量和网络鲁棒性分析等概念是物理学、计算机科学和计算生物学中的标准内容。将其应用于蛋白质相互作用网络是一个成熟的研究领域。\n- **适定性**：该问题在数学上是适定的。对于简单无权图，定义是精确且无歧义的。输入被明确指定，所需的输出——脆弱性得分 $V$——是一个唯一定义的量（由于固定的随机种子而具有确定性）。\n- **客观性**：问题以客观、正式的语言陈述，没有主观或非科学的主张。\n- **完整性与一致性**：问题提供了所有必要的信息，包括每个测试用例的图的确切结构和参数（$k$, $S$）。没有内部矛盾。要求从“第一性原理”实现是关于方法的具体指令，而非缺陷。\n- **可行性**：指定的图规模很小，使得边介数中心性的计算和边移除的模拟在合理的时间内是可行的。\n\n**步骤 3：结论与行动**\n此问题是**有效的**。它是一个基于已确立科学原理的、定义明确的计算任务。可以继续进行求解过程。\n\n### 解法\n\n解法涉及开发一套算法来为每个测试用例计算脆弱性得分 $V$。每个案例的总体流程是 (1) 计算所有边的边介数中心性，(2) 模拟目标性移除并计算 $f_{\\mathrm{target}}$，(3) 模拟随机移除并计算 $\\overline{f}_{\\mathrm{rand}}$，以及 (4) 计算 $V$。\n\n**1. 算法核心：边介数中心性 ($B_e$)**\n\n核心算法挑战是在不依赖预构建库函数的情况下，从其基本定义计算边介数中心性 $B_e$。给定的定义是 $B_e \\equiv \\sum_{s \\in V}\\sum_{t \\in V, t \\neq s} \\frac{\\sigma_{s t}(e)}{\\sigma_{s t}}$。直接枚举所有节点对的所有路径在计算上是不可行的。采用了一种更高效的方法，基于 Ulrik Brandes 的算法。该方法计算所有源节点的依赖关系总和。\n\n算法流程如下：\n将所有边 $e \\in E$ 的介数得分 $B_e$ 初始化为 $0$。然后，对于每个节点 $s \\in V$ 作为潜在的源点：\n\n- **阶段 1：最短路径计数**\n  从 $s$ 开始执行广度优先搜索 (BFS)。在遍历过程中，我们为每个其他节点 $v \\in V$ 计算两个量：\n  1. 从 $s$ 到 $v$ 的最短路径长度，记为 $d(s,v)$。\n  2. 此类最短路径的数量，记为 $\\sigma_{sv}$。\n  BFS 自然地按离 $s$ 距离递增的层次探索图。当从节点 $u$ 移动到邻居 $v$ 时，如果 $v$ 位于从 $s$ 出发的最短路径上（即 $d(s,v) = d(s,u) + 1$），则路径数量更新为：$\\sigma_{sv} = \\sigma_{sv} + \\sigma_{su}$。算法还记录每个节点 $v$ 的前驱节点集合 $P_s(v)$，这些是 $v$ 的邻居且位于从 $s$ 出发的最短路径上。从 $s$ 出发的最短路径中涉及的节点和边构成一个有向无环图 (DAG)。\n\n- **阶段 2：依赖累积**\n  BFS 完成后，按节点离 $s$ 的距离的逆序处理节点。这可以通过在 BFS 期间填充一个栈来实现。对于每个节点 $w$，计算一个依赖得分 $\\delta_s(w)$。该得分表示从 $s$ 到更远节点的、经过 $w$ 的最短路径所占的比例。更新规则源于 DAG 结构。对于每个前驱节点 $v \\in P_s(w)$，对边 $(v,w)$ 介数性的贡献由 $\\frac{\\sigma_{sv}}{\\sigma_{sw}}(1+\\delta_s(w))$ 给出。此值被加到 $B_{(v,w)}$ 上，并更新前驱节点的依赖性：$\\delta_s(v) \\leftarrow \\delta_s(v) + \\frac{\\sigma_{sv}}{\\sigma_{sw}}(1+\\delta_s(w))$。\n\n通过遍历所有节点 $s \\in V$ 作为源点并累积这些贡献，我们计算出每条边的最终介数得分。由于给定的公式是 sobre 有序对 $(s,t)$ 的和，并且 Brandes 算法分别（当对源 $s$ 和 $t$ 运行时）正确地累积了路径 $s \\to t$ 和 $t \\to s$ 的贡献，因此最终不需要除以 $2$。\n\n**2. 网络分析与脆弱性计算**\n\n有了计算 $B_e$ 的能力，通过以下程序为每个测试用例 $(G, k, S)$ 确定脆弱性得分 $V$：\n\n- **步骤 A：计算 LCC 比例**\n  需要一个辅助函数来确定给定图 $G' = (V, E')$ 的最大连通分量 (LCC) 的大小。这可以使用标准的图遍历算法（如 BFS 或 DFS）来实现。该函数遍历所有节点。如果发现一个未访问的节点，则启动一次遍历以找到其所在分量的所有节点，将它们标记为已访问并计数。在所有此类遍历中找到的最大分量大小即为 LCC 大小 $\\lvert C_{\\max}(G')\\rvert$。然后比例为 $\\lvert C_{\\max}(G')\\rvert / \\lvert V\\rvert$。\n\n- **步骤 B：目标性移除**\n  1. 使用上述算法计算原始图 $G$ 中所有边的 $B_e$。\n  2. 按 $B_e$ 值降序对边进行排序。\n  3. 选择前 $k$ 条边进行移除，形成集合 $R_{\\mathrm{target}}$。\n  4. 构建剩余图 $G_{\\mathrm{target}} = G \\setminus R_{\\mathrm{target}}$。\n  5. 计算 $f_{\\mathrm{target}} = f_{\\mathrm{LCC}}(G_{\\mathrm{target}})$。\n\n- **步骤 C：随机移除**\n  1. 初始化总 LCC 比例的累加器，$\\Sigma f = 0$。\n  2. 对于 $i=1, \\dots, S$：\n     a. 从原始边集 $E$ 中，不放回地均匀随机抽样一个包含 $k$ 条边的集合 $R_{\\mathrm{rand}, i}$。使用固定种子的伪随机数生成器确保可复现性。\n     b. 构建剩余图 $G_{\\mathrm{rand},i} = G \\setminus R_{\\mathrm{rand}, i}$。\n     c. 计算 $f_i = f_{\\mathrm{LCC}}(G_{\\mathrm{rand},i})$ 并将其加到累加器中：$\\Sigma f \\leftarrow \\Sigma f + f_i$。\n  3. 计算平均 LCC 比例：$\\overline{f}_{\\mathrm{rand}} = \\frac{1}{S} \\Sigma f$。\n\n- **步骤 D：脆弱性得分**\n  最终的脆弱性得分是随机影响的平均值与目标性影响之间的差值：$V = \\overline{f}_{\\mathrm{rand}} - f_{\\mathrm{target}}$。对于 $k=0$ 的特殊情况进行了处理，此时没有边被移除，导致 $V = 1.0 - 1.0 = 0.0$。\n\n将此综合程序应用于问题陈述中指定的五个测试用例中的每一个。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom collections import deque\n\ndef get_lcc_size(num_nodes, adj):\n    \"\"\"Calculates the size of the largest connected component using BFS.\"\"\"\n    if num_nodes == 0:\n        return 0\n    \n    visited = [False] * num_nodes\n    max_size = 0\n    for i in range(num_nodes):\n        if not visited[i]:\n            current_size = 0\n            q = deque([i])\n            visited[i] = True\n            while q:\n                u = q.popleft()\n                current_size += 1\n                if u in adj:\n                    for v in adj[u]:\n                        if not visited[v]:\n                            visited[v] = True\n                            q.append(v)\n            max_size = max(max_size, current_size)\n    return max_size\n\ndef calculate_edge_betweenness(num_nodes, edges):\n    \"\"\"\n    Computes edge betweenness centrality from first principles (Brandes' algorithm).\n    The graph is unweighted and undirected.\n    \"\"\"\n    adj = {i: [] for i in range(num_nodes)}\n    for u, v in edges:\n        adj[u].append(v)\n        adj[v].append(u)\n    \n    # Use canonical representation for undirected edges\n    edge_betweenness = {tuple(sorted(e)): 0.0 for e in edges}\n    \n    for s in range(num_nodes):\n        # Phase 1: Shortest path counting (BFS)\n        stack = []\n        predecessors = {i: [] for i in range(num_nodes)}\n        sigma = np.zeros(num_nodes)\n        distance = np.full(num_nodes, -1, dtype=int)\n        \n        sigma[s] = 1.0\n        distance[s] = 0\n        q = deque([s])\n        \n        while q:\n            v = q.popleft()\n            stack.append(v)\n            for w in adj[v]:\n                if distance[w] < 0:\n                    q.append(w)\n                    distance[w] = distance[v] + 1\n                if distance[w] == distance[v] + 1:\n                    sigma[w] += sigma[v]\n                    predecessors[w].append(v)\n\n        # Phase 2: Dependency accumulation\n        delta = np.zeros(num_nodes)\n        while stack:\n            w = stack.pop()\n            for v in predecessors[w]:\n                # The division sigma[v] / sigma[w] can be zero if sigma[w] is zero, but\n                # in a connected component, sigma[w] > 0\n                if sigma[w] > 0:\n                    c = (sigma[v] / sigma[w]) * (1.0 + delta[w])\n                    edge = tuple(sorted((v, w)))\n                    edge_betweenness[edge] += c\n                    delta[v] += c\n                \n    return edge_betweenness\n\ndef solve_case(nodes, edges, k, S, rng):\n    \"\"\"\n    Solves a single test case for the vulnerability score V.\n    \"\"\"\n    num_nodes = len(nodes)\n    \n    if k == 0:\n        return 0.0\n\n    # Step 1: Compute edge betweenness centrality for the original graph\n    edge_betweenness = calculate_edge_betweenness(num_nodes, edges)\n    \n    # Step 2: Targeted removal\n    # Sort edges by betweenness centrality in descending order\n    sorted_edges_by_b = sorted(edge_betweenness.items(), key=lambda item: item[1], reverse=True)\n    \n    # Identify k edges with highest betweenness\n    edges_to_remove_target = {e[0] for e in sorted_edges_by_b[:k]}\n    \n    # Build adjacency list for the targeted residual graph\n    adj_target = {i: [] for i in range(num_nodes)}\n    for u, v in edges:\n        if tuple(sorted((u, v))) not in edges_to_remove_target:\n            adj_target[u].append(v)\n            adj_target[v].append(u)\n            \n    # Compute LCC fraction for the targeted case\n    lcc_target_size = get_lcc_size(num_nodes, adj_target)\n    f_target = lcc_target_size / num_nodes\n    \n    # Step 3: Random removal\n    total_f_rand = 0.0\n    canonical_edges = list(edge_betweenness.keys())\n    edge_indices = np.arange(len(canonical_edges))\n\n    for _ in range(S):\n        # Choose k distinct edges to remove at random\n        indices_to_remove = rng.choice(edge_indices, size=k, replace=False)\n        edges_to_remove_rand = {canonical_edges[i] for i in indices_to_remove}\n        \n        # Build adjacency list for the random residual graph\n        adj_rand = {i: [] for i in range(num_nodes)}\n        for u, v in edges:\n            if tuple(sorted((u, v))) not in edges_to_remove_rand:\n                adj_rand[u].append(v)\n                adj_rand[v].append(u)\n\n        # Compute LCC fraction and add to sum\n        lcc_rand_size = get_lcc_size(num_nodes, adj_rand)\n        total_f_rand += lcc_rand_size / num_nodes\n        \n    f_rand_avg = total_f_rand / S\n    \n    # Step 4: Compute vulnerability score\n    vulnerability = f_rand_avg - f_target\n    return vulnerability\n\ndef solve():\n    \"\"\"\n    Main function to define test cases, run simulations, and print results.\n    \"\"\"\n    # Test cases specification\n    case1_edges = [(0,1),(0,2),(0,3),(0,4),(1,2),(1,3),(1,4),(2,3),(2,4),(3,4),(5,6),(5,7),(5,8),(5,9),(6,7),(6,8),(6,9),(7,8),(7,9),(8,9),(4,5)]\n    case2_edges = [(i,j) for i in range(6) for j in range(i+1, 6)]\n    case3_edges = [(i, i+1) for i in range(5)]\n    case4_edges = [(0,1),(0,2),(0,3),(1,2),(1,3),(2,3),(4,5),(4,6),(4,7),(5,6),(5,7),(6,7),(0,4),(1,5),(2,6)]\n    \n    test_cases = [\n        (list(range(10)), case1_edges, 1, 200),\n        (list(range(6)), case2_edges, 1, 200),\n        (list(range(6)), case3_edges, 1, 200),\n        (list(range(8)), case4_edges, 2, 200),\n        (list(range(10)), case1_edges, 0, 50),\n    ]\n\n    # Use a fixed seed for the random number generator for reproducibility\n    rng = np.random.default_rng(seed=42)\n    \n    results = []\n    for nodes, edges, k, S in test_cases:\n        v_score = solve_case(nodes, edges, k, S, rng)\n        results.append(v_score)\n\n    # Format the final output string as specified\n    output_str = f\"[{','.join([f'{v:.3f}' for v in results])}]\"\n    print(output_str)\n\n# Execute the solver\nsolve()\n```"
        }
    ]
}