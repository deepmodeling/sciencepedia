{
    "hands_on_practices": [
        {
            "introduction": "网络分析的第一步通常是将来自模拟的连续数据（如残基间的相关运动）转化为一个离散的图。本练习将指导你使用阈值法完成这一基本过程，并探索网络拓扑结构如何随阈值的变化而改变。通过这个练习，你将学会识别网络中的“逾渗转变”——一个标志着从局部连接到全局连通的突变点，这对于理解蛋白质中长程通讯的出现至关重要。",
            "id": "3855795",
            "problem": "考虑一个通过对残基间相关性矩阵进行阈值化处理，由蛋白质分子动力学模拟构建的残基相互作用网络。设 $N$ 表示残基的数量。对于每一对 $i \\neq j$ 的残基 $i$ 和 $j$，假设一个实值相关性 $C_{ij}$ 被定义为均值中心化的位移时间序列 $x_i(t)$ 和 $x_j(t)$ 之间的皮尔逊相关系数，其中一对 $(i,j)$ 的皮尔逊相关系数 (PCC) 定义为\n$$\nC_{ij} \\equiv \\frac{\\sum_{t=1}^{T} \\left(x_i(t) - \\bar{x}_i\\right)\\left(x_j(t) - \\bar{x}_j\\right)}{\\sqrt{\\sum_{t=1}^{T}\\left(x_i(t) - \\bar{x}_i\\right)^2}\\sqrt{\\sum_{t=1}^{T}\\left(x_j(t) - \\bar{x}_j\\right)^2}},\n$$\n其中 $\\bar{x}_i$ 表示 $x_i(t)$ 的时间平均值。定义一个无向、无权图 $G(\\theta)$，其节点集为 $\\{1,\\dots,N\\}$，邻接规则为\n$$\nA_{ij}(\\theta) = \\begin{cases}\n1  \\text{若 } i \\neq j \\text{ 且 } |C_{ij}| \\ge \\theta,\\\\\n0  \\text{否则。}\n\\end{cases}\n$$\n边代表动态相关性高于阈值 $\\theta$ 的残基对。设 $E(\\theta)$ 表示 $G(\\theta)$ 中的无向边集合，并设 $M \\equiv \\frac{N(N-1)}{2}$ 表示 $N$ 个节点上最大可能的无向边数。边密度定义为\n$$\np(\\theta) \\equiv \\frac{|E(\\theta)|}{M}.\n$$\n设 $G(\\theta)$ 的最大连通分量（巨分量）的大小为 $S_{\\max}(\\theta)$，并将其相对大小定义为\n$$\ng(\\theta) \\equiv \\frac{S_{\\max}(\\theta)}{N}.\n$$\n定义巨分量上的平均最短路径长度 $\\ell(\\theta)$ 为属于 $G(\\theta)$ 巨分量的所有无序节点对之间的测地距离的均值，其中每条边的长度为单位长度。如果 $S_{\\max}(\\theta) < 2$，则定义 $\\ell(\\theta) \\equiv 0$。\n\n当 $\\theta$ 变化时，通过观察连通性度量的突变可以检测到类逾渗转变。给定一个非递增的阈值序列 $\\{\\theta_k\\}_{k=1}^{K}$，定义相邻阈值之间巨分量相对大小的离散变化为\n$$\n\\Delta g_k \\equiv g(\\theta_{k+1}) - g(\\theta_k), \\quad \\text{对于 } k \\in \\{1,\\dots,K-1\\}。\n$$\n通过对应于最大正向离散变化的阈值 $\\theta^\\star$ 来定义一个类逾渗转变点，即\n$$\n\\theta^\\star \\equiv \\theta_{k^\\star}, \\quad \\text{其中 } k^\\star = \\arg\\max_{k \\in \\{1,\\dots,K-1\\}} \\Delta g_k。\n$$\n如果多个 $k$ 达到最大值，则选择其中最小的 $k$。此外，定义一个连通性翻转阈值 $\\theta^{\\mathrm{conn}}$，作为序列中整个图变为连通（即 $g(\\theta) = 1$）的最早阈值。如果在此序列中图从未完全连通，则设 $\\theta^{\\mathrm{conn}} \\equiv -1$。同时定义一个半分数起始阈值 $\\theta^{1/2}$，作为 $g(\\theta) \\ge 0.5$ 出现的最早阈值，如果这种情况从未发生，则设 $\\theta^{1/2} \\equiv -1$。\n\n你的任务是实现一个程序，对于每个指定的测试用例，在序列中的每个阈值处构建 $G(\\theta)$，计算 $p(\\theta)$、$g(\\theta)$、$\\ell(\\theta)$，并确定 $\\theta^\\star$、$\\theta^{\\mathrm{conn}}$ 和 $\\theta^{1/2}$。\n\n你的推理应基于以下经过充分检验的定义和事实：\n- 如上所述的皮尔逊相关系数。\n- 通过无向图中的路径定义的图连通性和连通分量。\n- 无权图中的最短路径长度，即节点之间的最小边数。\n- 边密度，即实际边数占所有可能无向边数的比例。\n\n使用绝对相关性 $|C_{ij}|$ 进行阈值化处理，其中对于所有 $i$，$C_{ii} = 1$。所有图都是无向简单图。\n\n测试套件：\n- 案例 1 (带桥的模块化结构)：\n  - $N = 10$ 个残基，标记为 $0$ 到 $9$。\n  - 将残基划分为两个模块 $\\{0,1,2,3,4\\}$ 和 $\\{5,6,7,8,9\\}$。\n  - 定义 $i \\neq j$ 时的 $C_{ij}$ 如下：在第一个模块内部，设 $C_{ij} = 0.80$；在第二个模块内部，设 $C_{ij} = 0.85$；模块之间，设 $C_{ij} = 0.20$，但单个桥接对 $(4,5)$ 除外，其 $C_{45} = C_{54} = 0.60$；设 $C_{ii} = 1.00$。\n  - 阈值 $\\{\\theta_k\\}$ 为 $\\left[0.90, 0.85, 0.80, 0.60, 0.40, 0.20, 0.10, 0.00\\right]$。\n- 案例 2 (环状晶格衰减)：\n  - $N = 12$ 个残基，标记为 $0$ 到 $11$，排列在一个环上。设环上距离 $d(i,j)$ 为 $|i-j|$ 和 $N - |i-j|$ 中的最小值。\n  - 定义 $C_{ij} = \\exp\\left(-\\frac{d(i,j)}{2}\\right)$（当 $i \\neq j$ 时），以及 $C_{ii} = 1.00$。\n  - 阈值 $\\{\\theta_k\\}$ 为 $\\left[0.70, 0.61, 0.6065, 0.50, 0.37, 0.20, 0.10\\right]$。\n- 案例 3 (均匀弱相关)：\n  - $N = 8$ 个残基，标记为 $0$ 到 $7$。\n  - 定义 $C_{ij} = 0.05$（当 $i \\neq j$ 时），以及 $C_{ii} = 1.00$。\n  - 阈值 $\\{\\theta_k\\}$ 为 $\\left[0.50, 0.10, 0.05, 0.00\\right]$。\n\n对于每个测试用例，计算：\n- 边密度列表 $\\left[p(\\theta_1), p(\\theta_2), \\dots, p(\\theta_K)\\right]$。\n- 巨分量相对大小列表 $\\left[g(\\theta_1), g(\\theta_2), \\dots, g(\\theta_K)\\right]$。\n- 巨分量上的平均最短路径长度列表 $\\left[\\ell(\\theta_1), \\ell(\\theta_2), \\dots, \\ell(\\theta_K)\\right]$。\n- 类逾渗转变阈值 $\\theta^\\star$。\n- 连通性翻转阈值 $\\theta^{\\mathrm{conn}}$。\n- 半分数起始阈值 $\\theta^{1/2}$。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含一个结果列表，每个测试用例一个结果，而每个测试用例的结果本身又是按以下顺序排列的列表：\n$\\left[\\left[p(\\theta_k)\\right]_{k=1}^{K}, \\left[g(\\theta_k)\\right]_{k=1}^{K}, \\left[\\ell(\\theta_k)\\right]_{k=1}^{K}, \\theta^\\star, \\theta^{\\mathrm{conn}}, \\theta^{1/2}\\right]$。\n全部输出应在一行上打印为一个 Python 风格的列表，例如：$\\left[\\text{case1\\_result}, \\text{case2\\_result}, \\text{case3\\_result}\\right]$。所有数值均为无单位的实数。当某个阈值根据上述规则未定义时，按规定返回 $-1.0$。",
            "solution": "问题陈述已经过严格审查，并被确定为有效。该问题在应用于计算生物学的网络科学既定领域，特别是在蛋白质动力学分析方面，具有科学依据。所有术语在数学上都有明确定义，测试用例是自洽且无歧义的。该问题是良置的、客观的，并提供了一个清晰的计算任务，该任务允许一个唯一的、可验证的解。\n\n解决此问题需要实现一个计算流程，该流程为每个给定的测试用例系统地分析在不同相关性阈值下生成的一系列图。整体算法流程如下：\n\n首先，对于每个测试用例，根据指定规则构建大小为 $N \\times N$ 的相关性矩阵 $C$。然后，顺序处理所提供的 $K$ 个非递增阈值序列 $\\{\\theta_k\\}_{k=1}^{K}$。对于每个阈值 $\\theta_k$，构建一个无权、无向图 $G(\\theta_k)$ 并计算其属性。\n\n在单个阈值 $\\theta$ 下分析图的核心步骤是：\n\n1.  **图的构建**：图 $G(\\theta)$ 的邻接矩阵 $A(\\theta)$ 是根据 $N \\times N$ 的相关性矩阵 $C$ 构建的。如果两个不同残基（节点）$i$ 和 $j$ 之间相关性的绝对值 $|C_{ij}|$ 达到或超过阈值 $\\theta$，则它们之间存在一条边。因此，邻接矩阵的元素由下式给出：\n    $$\n    A_{ij}(\\theta) = \\begin{cases}\n    1  \\text{若 } i \\neq j \\text{ 且 } |C_{ij}| \\ge \\theta, \\\\\n    0  \\text{否则。}\n    \\end{cases}\n    $$\n    注意，对于所有 $i$，$A_{ii}(\\theta) = 0$，因为没有自环。\n\n2.  **边密度 $p(\\theta)$**：图中的边数 $|E(\\theta)|$ 是邻接矩阵中所有元素总和的一半，即 $|E(\\theta)| = \\frac{1}{2}\\sum_{i,j} A_{ij}(\\theta)$。边密度 $p(\\theta)$ 是实际边数与最大可能边数 $M = \\frac{N(N-1)}{2}$ 的比率。$$ p(\\theta) = \\frac{|E(\\theta)|}{M} = \\frac{\\frac{1}{2}\\sum_{i,j} A_{ij}(\\theta)}{N(N-1)/2} $$",
            "answer": "```python\nimport numpy as np\nfrom scipy.sparse import csgraph\n\ndef get_case1_C():\n    \"\"\"Generates the correlation matrix for Case 1.\"\"\"\n    N = 10\n    C = np.full((N, N), 0.20)\n    module1 = np.arange(5)\n    module2 = np.arange(5, 10)\n    \n    # Within-module correlations\n    C[np.ix_(module1, module1)] = 0.80\n    C[np.ix_(module2, module2)] = 0.85\n    \n    # Bridge correlation\n    C[4, 5] = C[5, 4] = 0.60\n    \n    np.fill_diagonal(C, 1.0)\n    return C\n\ndef get_case2_C():\n    \"\"\"Generates the correlation matrix for Case 2.\"\"\"\n    N = 12\n    C = np.zeros((N, N))\n    for i in range(N):\n        for j in range(i, N):\n            if i == j:\n                C[i, j] = 1.0\n            else:\n                dist = min(abs(i - j), N - abs(i - j))\n                val = np.exp(-dist / 2.0)\n                C[i, j] = C[j, i] = val\n    return C\n\ndef get_case3_C():\n    \"\"\"Generates the correlation matrix for Case 3.\"\"\"\n    N = 8\n    C = np.full((N, N), 0.05)\n    np.fill_diagonal(C, 1.0)\n    return C\n\ndef analyze_network(C, thresholds):\n    \"\"\"\n    Analyzes the network properties for a given correlation matrix C\n    across a sequence of thresholds.\n    \"\"\"\n    N = C.shape[0]\n    M = N * (N - 1) / 2 if N > 1 else 0\n\n    p_list, g_list, l_list = [], [], []\n\n    for theta in thresholds:\n        # 1. Graph Construction\n        adj = (np.abs(C) >= theta).astype(int)\n        np.fill_diagonal(adj, 0)\n\n        # 2. Edge Density p(theta)\n        num_edges = np.sum(adj) / 2\n        p = num_edges / M if M > 0 else 0.0\n        p_list.append(p)\n\n        # 3. Connected Components and g(theta)\n        if N == 0:\n            s_max = 0\n        elif num_edges == 0:\n            s_max = 1\n        else:\n            _, labels = csgraph.connected_components(adj, directed=False, return_labels=True)\n            if labels.size > 0:\n                component_sizes = np.bincount(labels)\n                s_max = np.max(component_sizes)\n            else: # Should not happen for N > 0\n                s_max = 0\n        g = s_max / N if N > 0 else 0.0\n        g_list.append(g)\n\n        # 4. Average Shortest Path Length l(theta)\n        if s_max  2:\n            l_list.append(0.0)\n        else:\n            _, labels = csgraph.connected_components(adj, directed=False, return_labels=True)\n            giant_comp_idx = np.argmax(np.bincount(labels))\n            giant_comp_nodes = np.where(labels == giant_comp_idx)[0]\n            \n            giant_adj = adj[np.ix_(giant_comp_nodes, giant_comp_nodes)]\n            \n            dist_matrix = csgraph.shortest_path(giant_adj, directed=False, unweighted=True)\n            \n            num_pairs = s_max * (s_max - 1) / 2\n            total_dist = np.sum(dist_matrix) / 2\n            \n            l = total_dist / num_pairs if num_pairs > 0 else 0.0\n            l_list.append(l)\n\n    # 5. Percolation Threshold theta_star\n    g_array = np.array(g_list)\n    delta_g = g_array[1:] - g_array[:-1]\n    \n    theta_star = -1.0\n    if len(delta_g) > 0:\n        max_delta = np.max(delta_g)\n        if max_delta > 0:\n            k_star_idx = np.argmax(delta_g)\n            theta_star = thresholds[k_star_idx]\n\n    # 6. Connectivity Flip Threshold theta_conn\n    theta_conn = -1.0\n    for i, g_val in enumerate(g_list):\n        if g_val == 1.0:\n            theta_conn = thresholds[i]\n            break\n\n    # 7. Half-Fraction Onset Threshold theta_half\n    theta_half = -1.0\n    for i, g_val in enumerate(g_list):\n        if g_val >= 0.5:\n            theta_half = thresholds[i]\n            break\n            \n    return [p_list, g_list, l_list, theta_star, theta_conn, theta_half]\n    \n\ndef solve():\n    test_cases = [\n        {\n            \"C_func\": get_case1_C,\n            \"thresholds\": [0.90, 0.85, 0.80, 0.60, 0.40, 0.20, 0.10, 0.00]\n        },\n        {\n            \"C_func\": get_case2_C,\n            \"thresholds\": [0.70, 0.61, 0.6065, 0.50, 0.37, 0.20, 0.10]\n        },\n        {\n            \"C_func\": get_case3_C,\n            \"thresholds\": [0.50, 0.10, 0.05, 0.00]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        C = case[\"C_func\"]()\n        thresholds = case[\"thresholds\"]\n        result = analyze_network(C, thresholds)\n        results.append(result)\n\n    # Format numbers for consistent output representation\n    # This part is for display only, to match a typical float representation.\n    # The computation is done with full precision.\n    formatted_results = []\n    for res_case in results:\n        p, g, l, ts, tc, th = res_case\n        # The problem doesn't specify precision, so we will not artificially round.\n        # The conversion to string will handle standard representation.\n        formatted_results.append([p, g, l, ts, tc, th])\n        \n    # The required output is a string representation of the list of lists.\n    # Python's `str()` on a list already provides the desired `[...]` format.\n    print(f\"[{','.join(map(str, formatted_results))}]\")\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "在前面的练习中，我们通过设定阈值将加权网络简化为了无权网络，但这会丢弃原始相互作用强度中包含的丰富信息。本练习旨在量化这种“信息损失”，通过直接比较完整加权网络与其简化无权网络在几个关键拓扑指标上的差异。这项实践将帮助你深入理解在网络建模中不同表示方法之间的权衡，并做出更明智的选择。",
            "id": "3855812",
            "problem": "考虑一个用于蛋白质动力学和变构的残基-残基相互作用网络表示，其中残基是节点，成对动态耦合（例如，原子涨落的绝对皮尔逊相关性）被编码为非负对称权重。令 $n$ 表示残基（节点）的数量，并令 $W \\in \\mathbb{R}^{n \\times n}$ 为加权邻接矩阵，其中 $W_{ij} \\in [0,1]$，$W_{ii} = 0$，且 $W_{ij} = W_{ji}$。定义一个由阈值 $\\tau \\in [0,1]$ 参数化的二值化算子，该算子生成一个无权邻接矩阵 $A \\in \\{0,1\\}^{n \\times n}$，规则为：当且仅当 $W_{ij} \\ge \\tau$ 且 $i \\ne j$ 时，$A_{ij} = 1$，否则 $A_{ij} = 0$。将 $W$ 和 $A$ 都视为无自环的无向图。\n\n为评估二值化导致的信息损失，请计算并比较加权图和阈值化无权图上的以下网络度量：\n\n- 平均最短路径长度：对于加权图，定义边成本矩阵 $C$ 为：如果 $W_{ij}  0$，则 $C_{ij} = 1/W_{ij}$，否则 $C_{ij} = +\\infty$。令 $d^{w}_{ij}$ 表示使用 $C$ 时节点 $i$ 和 $j$ 之间的最短路径距离。对于无权图，令 $d^{u}_{ij}$ 表示使用 $A$ 时的边数最短路径距离（每条边的成本为 $1$）。一个图的平均最短路径长度定义为所有 $i  j$ 的无序对 $(i,j)$ 上的有限 $d_{ij}$ 的算术平均值。\n- 全局效率：对于给定的距离矩阵 $D$，定义为 $E = \\frac{1}{n(n-1)} \\sum_{i \\ne j} \\frac{1}{D_{ij}}$，并约定 $\\frac{1}{+\\infty} = 0$，且 $\\frac{1}{0}$ 被排除，因为 $D_{ii} = 0$ 不包含在求和中。\n- 平均聚类系数：对于无权图，节点 $i$ 的聚类系数定义为 $C^{u}_i = \\frac{\\text{与 } i \\text{ 相关联的三角形数量}}{\\text{以 } i \\text{ 为中心的连通三元组数量}}$，其中分母等于 $\\frac{k_i(k_i-1)}{2}$（$k_i$ 是节点 $i$ 的度），分子可以从 $A$ 的三次方获得，因为对于无向简单图，$A^3$ 的对角线满足 $(A^3)_{ii} = 2 T_i$，其中 $T_i$ 是与节点 $i$ 相关联的三角形数量。如果 $k_i  2$，则设置 $C^{u}_i = 0$。平均聚类系数为 $\\bar{C}^u = \\frac{1}{n} \\sum_{i=1}^n C^{u}_i$。对于加权图，使用 Onnela 公式：首先通过 $\\tilde{W}_{ij} = W_{ij}/\\max_{p,q} W_{pq}$ 归一化权重，然后对 $i$ 的满足 $j  k$ 且 $\\tilde{W}_{jk}  0$ 的无序邻居对 $(j,k)$ 定义 $C^{w}_i = \\frac{1}{k_i(k_i - 1)} \\sum_{j,k} \\left( \\tilde{W}_{ij} \\tilde{W}_{ik} \\tilde{W}_{jk} \\right)^{1/3}$，如果 $k_i  2$，则设置 $C^{w}_i = 0$。平均加权聚类系数为 $\\bar{C}^w = \\frac{1}{n} \\sum_{i=1}^n C^{w}_i$。\n- 谱半径：对于每个邻接矩阵 $M$（$W$ 或 $A$），定义谱半径 $\\lambda_{\\max}(M)$ 为 $M$ 的最大特征值。\n\n对于每个度量 $M \\in \\{\\text{ASPL}, \\text{Eff}, \\text{Clust}, \\text{Spec}\\}$，定义由二值化引起的相对损失为 $L_M = \\frac{|M_{\\text{weighted}} - M_{\\text{binary}}|}{|M_{\\text{weighted}}| + \\varepsilon}$，其中 $\\varepsilon = 10^{-12}$ 是一个用于避免除以零的小常数。所有量都是无量纲的。\n\n您的任务是编写一个程序，为每个提供的测试用例，使用上述定义计算四个损失值 $[L_{\\text{ASPL}}, L_{\\text{Eff}}, L_{\\text{Clust}}, L_{\\text{Spec}}]$，并输出它们，每个值四舍五入到 $6$ 位小数。\n\n使用以下参数值测试套件（每个测试用例是一对 $(W,\\tau)$）：\n\n- 测试用例 1 ($n = 6$):\n  $$\n  W = \\begin{pmatrix}\n  0   0.82  0.15  0.00  0.38  0.41 \\\\\n  0.82  0  0.22  0.30  0.27  0.58 \\\\\n  0.15  0.22  0  0.74  0.12  0.00 \\\\\n  0.00  0.30  0.74  0  0.33  0.26 \\\\\n  0.38  0.27  0.12  0.33  0  0.69 \\\\\n  0.41  0.58  0.00  0.26  0.69  0\n  \\end{pmatrix}, \\quad \\tau = 0.30.\n  $$\n- 测试用例 2 ($n = 6$):\n  $$\n  W = \\begin{pmatrix}\n  0  0.70  0.05  0.00  0.00  0.72 \\\\\n  0.70  0  0.00  0.00  0.68  0.00 \\\\\n  0.05  0.00  0  0.71  0.00  0.00 \\\\\n  0.00  0.00  0.71  0  0.00  0.70 \\\\\n  0.00  0.68  0.00  0.00  0  0.00 \\\\\n  0.72  0.00  0.00  0.70  0.00  0\n  \\end{pmatrix}, \\quad \\tau = 0.70.\n  $$\n- 测试用例 3 ($n = 5$):\n  $$\n  W = \\begin{pmatrix}\n  0  0.23  0.18  0.14  0.19 \\\\\n  0.23  0  0.17  0.21  0.16 \\\\\n  0.18  0.17  0  0.20  0.22 \\\\\n  0.14  0.21  0.20  0  0.15 \\\\\n  0.19  0.16  0.22  0.15  0\n  \\end{pmatrix}, \\quad \\tau = 0.10.\n  $$\n\n实现要求：\n\n- 在加权和无权情况下，均使用 Dijkstra 算法计算最短路径（无权情况使用单位边成本），将缺失的边视为成本为 $+\\infty$。\n- 对于平均最短路径长度，仅对 $i  j$ 的无序节点对的有限距离进行平均。\n- 对于全局效率，使用包含全部 $n(n-1)$ 个有向对计数的定义，并将 $\\frac{1}{+\\infty}$ 视为 $0$。\n- 对于无权聚类系数，通过 $T_i = \\frac{(A^3)_{ii}}{2}$ 使用 $A^3$ 的对角线计算 $T_i$，并对 $k_i \\ge 2$ 使用 $C^{u}_i = \\frac{2 T_i}{k_i(k_i-1)}$，否则 $C^{u}_i = 0$。\n- 对于加权聚类系数，使用如上指定的 Onnela 定义和 $\\tilde{W}$，并在 $k_i  2$ 时设置 $C^{w}_i = 0$。\n\n最终输出格式：\n\n您的程序应生成单行输出，其中包含一个方括号括起来的逗号分隔列表。每个测试用例的结果是按 $[L_{\\text{ASPL}}, L_{\\text{Eff}}, L_{\\text{Clust}}, L_{\\text{Spec}}]$ 顺序排列的四个损失值的子列表，每个浮点数四舍五入到 $6$ 位小数。输出中不得有任何空格。例如，结构必须类似于 $[[x_1,x_2,x_3,x_4],[y_1,y_2,y_3,y_4],[z_1,z_2,z_3,z_4]]$，所有条目均为十进制数。",
            "solution": "该问题是有效的，因为它在网络理论中有科学依据，定义明确，包含具体的数学定义和测试用例，且其表述是客观的。所有必要信息都已提供，所需的计算在计算上是可行的。我现在将提供一个完整的解决方案。\n\n任务是量化当一个加权蛋白质相互作用网络基于权重阈值 $\\tau$ 转换为一个无权（二值）网络时的信息损失。该损失针对四个标准网络度量进行测量：平均最短路径长度（ASPL）、全局效率、平均聚类系数和谱半径。对于每个度量 $M$，相对损失 $L_M$ 计算为 $L_M = \\frac{|M_{\\text{weighted}} - M_{\\text{binary}}|}{|M_{\\text{weighted}}| + \\varepsilon}$，其中 $\\varepsilon = 10^{-12}$ 是一个用于保证数值稳定性的小常数。\n\n设加权邻接矩阵为 $W \\in \\mathbb{R}^{n \\times n}$，二值化阈值为 $\\tau$。生成的无权邻接矩阵 $A$ 定义为：如果 $W_{ij} \\ge \\tau$ 且 $i \\ne j$，则 $A_{ij} = 1$，否则 $A_{ij} = 0$。\n\n每个测试用例 $(W, \\tau)$ 的总体算法如下：\n1.  计算由 $W$ 表示的加权图的四个度量。令它们为 $M_{\\text{ASPL,w}}$、$M_{\\text{Eff,w}}$、$M_{\\text{Clust,w}}$ 和 $M_{\\text{Spec,w}}$。\n2.  根据 $W$ 和 $\\tau$ 生成二值邻接矩阵 $A$。\n3.  计算由 $A$ 表示的无权图的相同四个度量。令它们为 $M_{\\text{ASPL,b}}$、$M_{\\text{Clust,b}}$ 和 $M_{\\text{Spec,b}}$。\n4.  对每个度量，使用给定公式计算相对损失 $L_M$。\n\n每个度量的计算详述如下。\n\n**1. 基于最短路径的度量（ASPL 和效率）**\n\nASPL 和效率的基础是所有节点对的最短路径距离矩阵 $D$。加权图和无权图的计算方式不同。\n\n-   **加权图 ($W$)**：边 $(i,j)$ 的成本定义为其权重的倒数，$c_{ij} = 1/W_{ij}$（对于 $W_{ij}  0$）。不存在的边具有无限成本。我们构建成本矩阵 $C$，并从每个节点开始运行 Dijkstra 算法，以找到所有节点对 $(i,j)$ 之间的最短路径距离 $d^w_{ij}$。这将生成距离矩阵 $D^w$。使用 `method='D'` 的 `scipy.sparse.csgraph.shortest_path` 函数适用于此任务。\n\n-   **无权图 ($A$)**：每条边的成本统一为 $1$。最短路径距离 $d^u_{ij}$ 就是连接节点 $i$ 和 $j$ 的路径中的最小边数。这可以通过对邻接矩阵 $A$ 应用相同的最短路径算法来计算，从而生成距离矩阵 $D^u$。\n\n一旦计算出 $D^w$ 和 $D^u$，就可以计算 ASPL 和效率：\n\n-   **平均最短路径长度 (ASPL)**：ASPL 是不同节点无序对之间所有有限最短路径距离的平均值。对于一个 $n$ 节点图的距离矩阵 $D$，其计算公式为：\n    $$\n    \\text{ASPL} = \\frac{1}{N_{\\text{finite}}} \\sum_{i  j, D_{ij}  \\infty} D_{ij}\n    $$\n    其中 $N_{\\text{finite}}$ 是存在有限路径的 $ij$ 对的数量。",
            "answer": "```python\nimport numpy as np\nfrom scipy.sparse.csgraph import shortest_path\nfrom itertools import combinations\n\ndef get_aspl(dist_matrix):\n    \"\"\"Computes the average shortest path length.\"\"\"\n    n = dist_matrix.shape[0]\n    if n = 1:\n        return 0.0\n    \n    # Get upper triangle for unordered pairs (i  j)\n    paths = dist_matrix[np.triu_indices(n, k=1)]\n    \n    # Filter for finite paths\n    finite_paths = paths[np.isfinite(paths)]\n    \n    if len(finite_paths) == 0:\n        return 0.0\n    else:\n        return np.mean(finite_paths)\n\ndef get_efficiency(dist_matrix):\n    \"\"\"Computes the global efficiency.\"\"\"\n    n = dist_matrix.shape[0]\n    if n = 1:\n        return 0.0\n        \n    # np.seterr is used to handle 1/0, which we correct later.\n    # 1/inf is correctly handled as 0 by numpy.\n    with np.errstate(divide='ignore'):\n        inv_dist = 1.0 / dist_matrix\n    \n    # Paths to self are not included in the sum\n    np.fill_diagonal(inv_dist, 0)\n\n    return np.sum(inv_dist) / (n * (n - 1))\n\ndef get_avg_clust_unweighted(A):\n    \"\"\"Computes the average unweighted clustering coefficient.\"\"\"\n    n = A.shape[0]\n    if n == 0:\n        return 0.0\n        \n    A_cubed = np.linalg.matrix_power(A, 3)\n    diag_A3 = np.diag(A_cubed)\n    degrees = np.sum(A, axis=1)\n    \n    coeffs = np.zeros(n)\n    for i in range(n):\n        k_i = degrees[i]\n        if k_i >= 2:\n            denominator = k_i * (k_i - 1)\n            coeffs[i] = diag_A3[i] / denominator\n            \n    return np.mean(coeffs)\n\ndef get_avg_clust_weighted(W):\n    \"\"\"Computes the average weighted clustering coefficient (Onnela formulation).\"\"\"\n    n = W.shape[0]\n    if n == 0:\n        return 0.0\n\n    max_weight = np.max(W)\n    if max_weight == 0:\n        return 0.0\n    W_tilde = W / max_weight\n\n    coeffs = np.zeros(n)\n    for i in range(n):\n        neighbors = np.where(W[i, :] > 0)[0]\n        k_i = len(neighbors)\n        \n        if k_i >= 2:\n            triangle_sum = 0.0\n            for j, k in combinations(neighbors, 2):\n                if W[j, k] > 0: # Check if the triangle is closed\n                    term = (W_tilde[i, j] * W_tilde[i, k] * W_tilde[j, k])**(1/3)\n                    triangle_sum += 2*term # Onnela's original formula has a factor of 2 for undirected graphs\n            \n            denominator = k_i * (k_i - 1)\n            coeffs[i] = triangle_sum / denominator\n\n    return np.mean(coeffs)\n\ndef get_spectral_radius(matrix):\n    \"\"\"Computes the spectral radius of a symmetric matrix.\"\"\"\n    if matrix.shape[0] == 0:\n        return 0.0\n    # For real symmetric matrices, eigenvalues are real.\n    # For non-negative matrices, spectral radius is the largest eigenvalue.\n    eigvals = np.linalg.eigvalsh(matrix)\n    return np.max(eigvals)\n\ndef calculate_metrics(M, is_weighted):\n    \"\"\"Dispatcher to calculate all four metrics for a given matrix.\"\"\"\n    n = M.shape[0]\n\n    if is_weighted:\n        # Weighted graph calculations\n        with np.errstate(divide='ignore'):\n            cost_matrix = 1.0 / M\n        cost_matrix[M == 0] = np.inf\n        np.fill_diagonal(cost_matrix, 0)\n        dist_matrix = shortest_path(csgraph=cost_matrix, directed=False, method='D')\n        \n        aspl = get_aspl(dist_matrix)\n        eff = get_efficiency(dist_matrix)\n        clust = get_avg_clust_weighted(M)\n        spec = get_spectral_radius(M)\n    else:\n        # Unweighted graph calculations\n        dist_matrix = shortest_path(csgraph=M, directed=False, method='D')\n\n        aspl = get_aspl(dist_matrix)\n        eff = get_efficiency(dist_matrix)\n        clust = get_avg_clust_unweighted(M)\n        spec = get_spectral_radius(M)\n        \n    return aspl, eff, clust, spec\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    \"\"\"\n    test_cases = [\n        (np.array([\n            [0, 0.82, 0.15, 0.00, 0.38, 0.41],\n            [0.82, 0, 0.22, 0.30, 0.27, 0.58],\n            [0.15, 0.22, 0, 0.74, 0.12, 0.00],\n            [0.00, 0.30, 0.74, 0, 0.33, 0.26],\n            [0.38, 0.27, 0.12, 0.33, 0, 0.69],\n            [0.41, 0.58, 0.00, 0.26, 0.69, 0]\n        ]), 0.30),\n        (np.array([\n            [0, 0.70, 0.05, 0.00, 0.00, 0.72],\n            [0.70, 0, 0.00, 0.00, 0.68, 0.00],\n            [0.05, 0.00, 0, 0.71, 0.00, 0.00],\n            [0.00, 0.00, 0.71, 0, 0.00, 0.70],\n            [0.00, 0.68, 0.00, 0.00, 0, 0.00],\n            [0.72, 0.00, 0.00, 0.70, 0.00, 0]\n        ]), 0.70),\n        (np.array([\n            [0, 0.23, 0.18, 0.14, 0.19],\n            [0.23, 0, 0.17, 0.21, 0.16],\n            [0.18, 0.17, 0, 0.20, 0.22],\n            [0.14, 0.21, 0.20, 0, 0.15],\n            [0.19, 0.16, 0.22, 0.15, 0]\n        ]), 0.10)\n    ]\n    \n    epsilon = 1e-12\n    all_results = []\n\n    for W, tau in test_cases:\n        # Binarize W to get A\n        A = (W >= tau).astype(float)\n        np.fill_diagonal(A, 0)\n        \n        # Calculate metrics for both graphs\n        metrics_w = calculate_metrics(W, is_weighted=True)\n        metrics_b = calculate_metrics(A, is_weighted=False)\n        \n        # Compute relative losses\n        losses = []\n        for M_w, M_b in zip(metrics_w, metrics_b):\n            loss = np.abs(M_w - M_b) / (np.abs(M_w) + epsilon)\n            losses.append(loss)\n            \n        all_results.append(losses)\n\n    # Format output string\n    rounded_results = []\n    for result_list in all_results:\n        rounded_results.append([f\"{x:.6f}\" for x in result_list])\n\n    outer_list_str = []\n    for res in rounded_results:\n        inner_list_str = f\"[{','.join(res)}]\"\n        outer_list_str.append(inner_list_str)\n\n    print(f\"[{','.join(outer_list_str)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "掌握了网络构建和评估的基础后，我们可以应用这些工具来探索其生物学功能。本练习通过模拟“网络攻击”来检验网络的稳健性，并识别对于维持其整体连通性至关重要的边。通过比较移除高边介数中心性 ($B_e$) 的边与随机移除边的效果差异 ，你将能够发现网络中的“脆弱桥梁”，这些桥梁在蛋白质的变构通讯中可能扮演着关键角色。",
            "id": "3855936",
            "problem": "您的任务是评估一个变构残基-残基相互作用网络是否包含脆弱的通信桥，方法是比较随机移除边与基于边介数中心性的目标性移除边的影响。将蛋白质网络建模为一个无向简单图 $G = (V,E)$，其中节点代表残基，边代表有效的动力学耦合。根据基本的图论定义，一条边 $e \\in E$ 的边介数中心性 $B_e$ 是对所有有序的源-目标对，遍历该边 $e$ 的测地（最短）路径所占比例的总和：$$B_e \\equiv \\sum_{s \\in V}\\sum_{\\substack{t \\in V\\\\ t \\neq s}} \\frac{\\sigma_{s t}(e)}{\\sigma_{s t}},$$ 其中 $\\sigma_{s t}$ 是 $s$ 和 $t$ 之间的最短路径数量，而 $\\sigma_{s t}(e)$ 是这些路径中包含边 $e$ 的数量。考虑两种移除边的策略：(i) 移除 $k$ 条具有最高 $B_e$ 的边（目标性移除），或 (ii) 无放回地均匀随机抽样移除 $k$ 条边（随机移除）。在移除一组边 $R \\subseteq E$ 后，将最大连通分量（Largest Connected Component (LCC)）中的节点比例定义为 $$f_{\\mathrm{LCC}}(G\\setminus R) \\equiv \\frac{\\lvert C_{\\max}(G\\setminus R)\\rvert}{\\lvert V\\rvert},$$ 其中 $C_{\\max}(G\\setminus R)$ 表示残留图的最大连通分量。对于随机策略，通过对 $S$ 次独立的 $k$ 条边的随机抽取得到的 $f_{\\mathrm{LCC}}$ 进行平均，来估计平均 LCC 比例。定义脆弱性得分 $V \\equiv \\overline{f}_{\\mathrm{rand}} - f_{\\mathrm{target}}$，其中 $\\overline{f}_{\\mathrm{rand}}$ 是随机移除下 $f_{\\mathrm{LCC}}$ 的样本均值，而 $f_{\\mathrm{target}}$ 是目标性移除下的 LCC 比例。较大的正值 $V$ 表示网络中存在作为脆弱桥梁的边，这些边不成比例地支持了网络中的测地通信。\n\n您的程序必须：\n- 构建指定的无向图，并使用第一性原理算法（例如，使用广度优先搜索（BFS）来枚举距离和路径计数），直接根据无权图的路径计数定义计算边介数中心性 $B_e$。\n- 对于每个测试用例，计算 $f_{\\mathrm{target}}$，使用 $S$ 次随机试验计算 $\\overline{f}_{\\mathrm{rand}}$，并返回该测试用例的 $V$ 值（浮点数）。\n- 使用固定的伪随机数生成器种子，以使 $\\overline{f}_{\\mathrm{rand}}$ 是确定性的。\n- 最终输出表示为一行，其中包含所有测试用例的脆弱性得分 $V$，格式为方括号内的逗号分隔列表，每个浮点数四舍五入到 $3$ 位小数，例如 $[0.123,0.000,0.456]$。\n\n测试套件规范（所有图均为无权无向图）：\n- 测试用例 $1$（两个密集模块，由一个模块间桥连接）：$V$ 有 $10$ 个节点，边是节点 $\\{0,1,2,3,4\\}$ 和 $\\{5,6,7,8,9\\}$ 上两个团的并集，外加一条桥接边 $(4,5)$。明确地说，边是 $$\\{(0,1),(0,2),(0,3),(0,4),(1,2),(1,3),(1,4),(2,3),(2,4),(3,4),(5,6),(5,7),(5,8),(5,9),(6,7),(6,8),(6,9),(7,8),(7,9),(8,9),(4,5)\\}.$$ 使用 $k=1$ 和 $S=200$。\n- 测试用例 $2$（完全图）：$V$ 有 $6$ 个节点，包含所有成对的边，即边为 $$\\{(0,1),(0,2),(0,3),(0,4),(0,5),(1,2),(1,3),(1,4),(1,5),(2,3),(2,4),(2,5),(3,4),(3,5),(4,5)\\}.$$ 使用 $k=1$ 和 $S=200$。\n- 测试用例 $3$（线性链）：$V$ 有 $6$ 个节点，边为 $$\\{(0,1),(1,2),(2,3),(3,4),(4,5)\\}.$$ 使用 $k=1$ 和 $S=200$。\n- 测试用例 $4$（冗余的模块间连接）：$V$ 有 $8$ 个节点；两个在 $\\{0,1,2,3\\}$ 和 $\\{4,5,6,7\\}$ 上的团，外加 $3$ 条模块间边 $(0,4),(1,5),(2,6)$。明确地说，边是 $$\\{(0,1),(0,2),(0,3),(1,2),(1,3),(2,3),(4,5),(4,6),(4,7),(5,6),(5,7),(6,7),(0,4),(1,5),(2,6)\\}.$$ 使用 $k=2$ 和 $S=200$。\n- 测试用例 $5$（边界情况 $k=0$）：重用测试用例 $1$ 的图。使用 $k=0$ 和 $S=50$。\n\n最终输出格式：\n- 您的程序应产生一行输出，其中包含结果，格式为方括号内的逗号分隔列表，即 $[V_1,V_2,V_3,V_4,V_5]$，其中每个 $V_i$ 四舍五入到 $3$ 位小数。",
            "solution": "用户的请求是验证并解决一个关于网络脆弱性的问题，该网络被建模为图，并研究其对不同边移除策略的响应。\n\n### 问题验证\n首先对问题的有效性进行评估。\n\n**步骤1：提取已知条件**\n- **图模型**：一个无向简单图 $G = (V,E)$，其中 $V$ 是残基（节点），$E$ 是动力学耦合（边）。\n- **边介数中心性 ($B_e$)**：$B_e \\equiv \\sum_{s \\in V}\\sum_{\\substack{t \\in V\\\\ t \\neq s}} \\frac{\\sigma_{s t}(e)}{\\sigma_{s t}}$，其中 $\\sigma_{st}$ 是节点 $s$ 和 $t$ 之间的最短路径数量，$\\sigma_{st}(e)$ 是这些路径中通过边 $e$ 的数量。\n- **边移除策略**：\n    1.  **目标性**：移除 $k$ 条具有最高 $B_e$ 的边。\n    2.  **随机性**：无放回地均匀随机抽样移除 $k$ 条边。\n- **评估指标（LCC比例）**：$f_{\\mathrm{LCC}}(G\\setminus R) \\equiv \\frac{\\lvert C_{\\max}(G\\setminus R)\\rvert}{\\lvert V\\rvert}$，其中 $C_{\\max}$ 是移除边集 $R$ 后图的最大连通分量。\n- **脆弱性得分 ($V$)**：$V \\equiv \\overline{f}_{\\mathrm{rand}} - f_{\\mathrm{target}}$，其中 $\\overline{f}_{\\mathrm{rand}}$ 是 $S$ 次随机试验中 $f_{\\mathrm{LCC}}$ 的均值，而 $f_{\\mathrm{target}}$ 是单次目标性试验的 $f_{\\mathrm{LCC}}$。\n- **程序要求**：\n    - $B_e$ 必须根据其第一性原理定义计算。\n    - 必须使用固定的伪随机数生成器种子。\n- **测试套件**：\n    - **案例1**：由一条边连接的两个5节点团组成的图；$k=1$，$S=200$。\n    - **案例2**：6个节点上的完全图；$k=1$，$S=200$。\n    - **案例3**：6个节点的线性链；$k=1$，$S=200$。\n    - **案例4**：由三条边连接的两个4节点团组成的图；$k=2$，$S=200$。\n    - **案例5**：来自案例1的图；$k=0$，$S=50$。\n\n**步骤2：使用提取的已知条件进行验证**\n根据验证标准对问题陈述进行分析。\n- **科学性/事实性**：该问题在网络科学和图论中有充分的依据。介数中心性、连通分量和网络鲁棒性分析等概念在物理学、计算机科学和计算生物学中是标准内容。其在蛋白质相互作用网络中的应用是一个成熟的研究领域。\n- **适定性**：该问题在数学上是适定的。对于简单无权图，定义是精确且无歧义的。输入被明确指定，所需的输出——脆弱性得分 $V$——是一个唯一定义的量（由于固定的随机种子而具有确定性）。\n- **客观性**：问题以客观、正式的语言陈述，没有主观或非科学的主张。\n- **完整性与一致性**：问题提供了所有必要的信息，包括每个测试用例的图的确切结构和参数（$k$, $S$）。没有内部矛盾。要求从“第一性原理”实现是关于方法论的具体指令，而不是缺陷。\n- **可行性**：指定的图规模较小，使得边介数中心性的计算和边移除的模拟在合理的时间范围内是计算可行的。\n\n**步骤3：结论与行动**\n该问题是**有效的**。它是一个基于已建立的科学原理的、定义明确的计算任务。可以开始求解过程。\n\n### 解决方案\n\n解决方案涉及开发一套算法，为每个测试用例计算脆弱性得分 $V$。每个案例的总体流程是 (1) 计算所有边的边介数中心性，(2) 模拟目标性移除并计算 $f_{\\mathrm{target}}$，(3) 模拟随机移除并计算 $\\overline{f}_{\\mathrm{rand}}$，以及 (4) 计算 $V$。\n\n**1. 算法核心：边介数中心性 ($B_e$)**\n\n核心的算法挑战是根据其基本定义计算边介数中心性 $B_e$，而不依赖于预构建的库函数。给定的定义是 $B_e \\equiv \\sum_{s \\in V}\\sum_{t \\in V, t \\neq s} \\frac{\\sigma_{s t}(e)}{\\sigma_{s t}}$。直接枚举所有节点对的所有路径在计算上是不可行的。采用了一种更高效的方法，该方法基于 Ulrik Brandes 的算法。此方法计算所有源节点的依赖性总和。\n\n算法流程如下：\n将所有边 $e \\in E$ 的介数得分 $B_e$ 初始化为 $0$。然后，对于每个节点 $s \\in V$ 作为潜在的源点：\n\n- **阶段1：最短路径计数**\n  从 $s$ 开始执行广度优先搜索（BFS）。在遍历过程中，我们为每个其他节点 $v \\in V$ 计算两个量：\n  1.  从 $s$到 $v$ 的最短路径长度，记为 $d(s,v)$。\n  2.  此类最短路径的数量，记为 $\\sigma_{sv}$。\n  BFS 自然地按离 $s$ 距离递增的层次探索图。当从节点 $u$ 移动到邻居 $v$ 时，如果 $v$ 位于从 $s$ 出发的最短路径上（即 $d(s,v) = d(s,u) + 1$），则路径数量更新为：$\\sigma_{sv} = \\sigma_{sv} + \\sigma_{su}$。算法还记录每个节点 $v$ 的前驱节点集合 $P_s(v)$，这些是 $v$ 的邻居中位于从 $s$ 出发的最短路径上的节点。从 $s$ 出发的最短路径所涉及的节点和边的集合形成一个有向无环图（DAG）。\n\n- **阶段2：依赖性累积**\n  BFS完成后，按节点离 $s$ 距离的倒序处理节点。这可以通过使用在 BFS 期间填充的堆栈来实现。对每个节点 $w$，计算一个依赖性得分 $\\delta_s(w)$。该得分表示从 $s$ 到更远节点的、经过 $w$ 的最短路径的比例。更新规则从DAG结构中导出。对于每个前驱节点 $v \\in P_s(w)$，对边 $(v,w)$ 介数中心性的贡献由 $\\frac{\\sigma_{sv}}{\\sigma_{sw}}(1+\\delta_s(w))$ 给出。此值被加到 $B_{(v,w)}$ 上，并且前驱节点的依赖性被更新：$\\delta_s(v) \\leftarrow \\delta_s(v) + \\frac{\\sigma_{sv}}{\\sigma_{sw}}(1+\\delta_s(w))$。\n\n通过遍历所有节点 $s \\in V$ 作为源点并累积这些贡献，我们计算出每条边的最终介数得分。由于给定的公式是对有序对 $(s,t)$ 的求和，而 Brandes 算法分别（当对源 $s$ 和 $t$ 运行时）正确地累积了路径 $s \\to t$ 和 $t \\to s$ 的贡献，因此最终不需要除以 $2$。\n\n**2. 网络分析与脆弱性计算**\n\n在具备计算 $B_e$ 的能力后，通过以下流程为每个测试用例 $(G, k, S)$ 确定脆弱性得分 $V$：\n\n- **步骤A：计算LCC比例**\n  需要一个辅助函数来确定给定图 $G' = (V, E')$ 的最大连通分量（LCC）的大小。这可以使用标准的图遍历算法（如BFS或DFS）来实现。该函数遍历所有节点。如果找到一个未访问的节点，则启动一次遍历以找到其所在分量的所有节点，将它们标记为已访问并计数。在所有此类遍历中找到的最大分量大小即为 LCC 大小 $\\lvert C_{\\max}(G')\\rvert$。然后比例为 $\\lvert C_{\\max}(G')\\rvert / \\lvert V\\rvert$。\n\n- **步骤B：目标性移除**\n  1. 使用上述算法计算原始图 $G$ 中所有边的 $B_e$。\n  2. 按 $B_e$ 值降序对边进行排序。\n  3. 选择前 $k$ 条边进行移除，形成集合 $R_{\\mathrm{target}}$。\n  4. 构建残余图 $G_{\\mathrm{target}} = G \\setminus R_{\\mathrm{target}}$。\n  5. 计算 $f_{\\mathrm{target}} = f_{\\mathrm{LCC}}(G_{\\mathrm{target}})$。\n\n- **步骤C：随机移除**\n  1. 初始化总 LCC 比例的累加器，$\\Sigma f = 0$。\n  2. 对于 $i=1, \\dots, S$：\n     a. 从原始边集 $E$ 中，无放回地均匀随机抽样一个包含 $k$ 条边的集合 $R_{\\mathrm{rand}, i}$。固定的伪随机数生成器种子确保可复现性。\n     b. 构建残余图 $G_{\\mathrm{rand},i} = G \\setminus R_{\\mathrm{rand}, i}$。\n     c. 计算 $f_i = f_{\\mathrm{LCC}}(G_{\\mathrm{rand},i})$ 并将其加到累加器中：$\\Sigma f \\leftarrow \\Sigma f + f_i$。\n  3. 计算平均 LCC 比例：$\\overline{f}_{\\mathrm{rand}} = \\frac{1}{S} \\Sigma f$。\n\n- **步骤D：脆弱性得分**\n  最终的脆弱性得分是随机影响的平均值与目标性影响之间的差值：$V = \\overline{f}_{\\mathrm{rand}} - f_{\\mathrm{target}}$。对于 $k=0$ 的特殊情况，不移除任何边，导致 $V = 1.0 - 1.0 = 0.0$。\n\n将此综合流程应用于问题陈述中指定的五个测试用例中的每一个。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom collections import deque\n\ndef get_lcc_size(num_nodes, adj):\n    \"\"\"Calculates the size of the largest connected component using BFS.\"\"\"\n    if num_nodes == 0:\n        return 0\n    \n    visited = [False] * num_nodes\n    max_size = 0\n    for i in range(num_nodes):\n        if not visited[i]:\n            current_size = 0\n            q = deque([i])\n            visited[i] = True\n            while q:\n                u = q.popleft()\n                current_size += 1\n                if u in adj:\n                    for v in adj[u]:\n                        if not visited[v]:\n                            visited[v] = True\n                            q.append(v)\n            max_size = max(max_size, current_size)\n    return max_size\n\ndef calculate_edge_betweenness(num_nodes, edges):\n    \"\"\"\n    Computes edge betweenness centrality from first principles (Brandes' algorithm).\n    The graph is unweighted and undirected.\n    \"\"\"\n    adj = {i: [] for i in range(num_nodes)}\n    for u, v in edges:\n        adj[u].append(v)\n        adj[v].append(u)\n    \n    # Use canonical representation for undirected edges\n    edge_betweenness = {tuple(sorted(e)): 0.0 for e in edges}\n    \n    for s in range(num_nodes):\n        # Phase 1: Shortest path counting (BFS)\n        stack = []\n        predecessors = {i: [] for i in range(num_nodes)}\n        sigma = np.zeros(num_nodes)\n        distance = np.full(num_nodes, -1, dtype=int)\n        \n        sigma[s] = 1.0\n        distance[s] = 0\n        q = deque([s])\n        \n        while q:\n            v = q.popleft()\n            stack.append(v)\n            for w in adj[v]:\n                if distance[w]  0:\n                    q.append(w)\n                    distance[w] = distance[v] + 1\n                if distance[w] == distance[v] + 1:\n                    sigma[w] += sigma[v]\n                    predecessors[w].append(v)\n\n        # Phase 2: Dependency accumulation\n        delta = np.zeros(num_nodes)\n        while stack:\n            w = stack.pop()\n            for v in predecessors[w]:\n                if sigma[w] > 0:\n                    c = (sigma[v] / sigma[w]) * (1.0 + delta[w])\n                    edge = tuple(sorted((v, w)))\n                    edge_betweenness[edge] += c\n                    delta[v] += c\n                \n    return edge_betweenness\n\ndef solve_case(nodes, edges, k, S, rng):\n    \"\"\"\n    Solves a single test case for the vulnerability score V.\n    \"\"\"\n    num_nodes = len(nodes)\n    \n    if k == 0:\n        return 0.0\n\n    # Step 1: Compute edge betweenness centrality for the original graph\n    edge_betweenness = calculate_edge_betweenness(num_nodes, edges)\n    \n    # Step 2: Targeted removal\n    # Sort edges by betweenness centrality in descending order\n    sorted_edges_by_b = sorted(edge_betweenness.items(), key=lambda item: item[1], reverse=True)\n    \n    # Identify k edges with highest betweenness\n    edges_to_remove_target = {e[0] for e in sorted_edges_by_b[:k]}\n    \n    # Build adjacency list for the targeted residual graph\n    adj_target = {i: [] for i in range(num_nodes)}\n    for u, v in edges:\n        if tuple(sorted((u, v))) not in edges_to_remove_target:\n            adj_target[u].append(v)\n            adj_target[v].append(u)\n            \n    # Compute LCC fraction for the targeted case\n    lcc_target_size = get_lcc_size(num_nodes, adj_target)\n    f_target = lcc_target_size / num_nodes\n    \n    # Step 3: Random removal\n    total_f_rand = 0.0\n    canonical_edges = list(edge_betweenness.keys())\n    edge_indices = np.arange(len(canonical_edges))\n\n    for _ in range(S):\n        # Choose k distinct edges to remove at random\n        indices_to_remove = rng.choice(edge_indices, size=k, replace=False)\n        edges_to_remove_rand = {canonical_edges[i] for i in indices_to_remove}\n        \n        # Build adjacency list for the random residual graph\n        adj_rand = {i: [] for i in range(num_nodes)}\n        for u, v in edges:\n            if tuple(sorted((u, v))) not in edges_to_remove_rand:\n                adj_rand[u].append(v)\n                adj_rand[v].append(u)\n\n        # Compute LCC fraction and add to sum\n        lcc_rand_size = get_lcc_size(num_nodes, adj_rand)\n        total_f_rand += lcc_rand_size / num_nodes\n        \n    f_rand_avg = total_f_rand / S\n    \n    # Step 4: Compute vulnerability score\n    vulnerability = f_rand_avg - f_target\n    return vulnerability\n\ndef solve():\n    \"\"\"\n    Main function to define test cases, run simulations, and print results.\n    \"\"\"\n    # Test cases specification\n    case1_edges = [(0,1),(0,2),(0,3),(0,4),(1,2),(1,3),(1,4),(2,3),(2,4),(3,4),(5,6),(5,7),(5,8),(5,9),(6,7),(6,8),(6,9),(7,8),(7,9),(8,9),(4,5)]\n    case2_edges = [(i,j) for i in range(6) for j in range(i+1, 6)]\n    case3_edges = [(i, i+1) for i in range(5)]\n    case4_edges = [(0,1),(0,2),(0,3),(1,2),(1,3),(2,3),(4,5),(4,6),(4,7),(5,6),(5,7),(6,7),(0,4),(1,5),(2,6)]\n    \n    test_cases = [\n        (list(range(10)), case1_edges, 1, 200),\n        (list(range(6)), case2_edges, 1, 200),\n        (list(range(6)), case3_edges, 1, 200),\n        (list(range(8)), case4_edges, 2, 200),\n        (list(range(10)), case1_edges, 0, 50),\n    ]\n\n    # Use a fixed seed for the random number generator for reproducibility\n    rng = np.random.default_rng(seed=42)\n    \n    results = []\n    for nodes, edges, k, S in test_cases:\n        v_score = solve_case(nodes, edges, k, S, rng)\n        results.append(v_score)\n\n    # Format the final output string as specified\n    output_str = f\"[{','.join([f'{v:.3f}' for v in results])}]\"\n    print(output_str)\n\n# Execute the solver\nsolve()\n```"
        }
    ]
}