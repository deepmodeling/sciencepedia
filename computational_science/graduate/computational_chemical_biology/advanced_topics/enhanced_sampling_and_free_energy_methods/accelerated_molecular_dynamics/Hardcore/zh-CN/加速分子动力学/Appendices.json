{
    "hands_on_practices": [
        {
            "introduction": "在加速分子动力学中，从偏置系综恢复自由能的关键在于计算校正项 $\\ln \\langle \\exp(\\beta \\Delta V) \\rangle$。本练习将引导你通过累积量展开来探索这一校正项与增强势 $\\Delta V$ 统计分布之间的深刻联系。通过推导并应用这一展开，你将理解为何在 $\\Delta V$ 近似服从高斯分布的常见情况下，可以将其截断至二阶，从而为分析和理解重加权过程提供一个强大的理论工具 。",
            "id": "3834957",
            "problem": "在加速分子动力学 (aMD) 中，从修正系综重加权到正则系综时，会引入因子 $\\langle \\exp(\\beta \\Delta V) \\rangle$，其中 $\\Delta V$ 是加到物理势上的偏置势，$\\beta$ 是逆热能。考虑一个生物分子系统的 aMD 模拟，其中能量以每摩尔为单位报告。在此约定下，相应的逆热能为 $\\beta = 1/(R T)$，其中 $R$ 是摩尔气体常数，$T$ 是绝对温度。设 $\\Delta V$ 为一个标量随机变量，表示从稳态 aMD 系综中采样的偏置势。\n\n(a) 从矩生成函数 $M_{X}(t) = \\langle \\exp(t X) \\rangle$ 和累积量生成函数 $K_{X}(t) = \\ln M_{X}(t)$ 的定义出发，其中累积量 $\\kappa_{n}$ 定义为 $\\kappa_{n} = K_{X}^{(n)}(0)$，推导 $\\ln \\langle \\exp(\\beta \\Delta V) \\rangle$ 关于 $\\beta$ 的幂级数表示，并以 $\\Delta V$ 的累积量来表示。你的推导应从这些定义和一个光滑函数在 $t=0$ 附近的泰勒级数开始，然后得到一个系数为 $\\Delta V$ 的累积量的显式级数。\n\n(b) 在许多实际的 aMD 应用中，$\\Delta V$ 的分布根据经验接近高斯分布。仅使用高斯随机变量的定义性质，证明在 $m=2$ 阶截断该级数的合理性，并精确说明哪些项被忽略，以及在近似高斯性的条件下，为什么它们会消失或预期会很小。\n\n(c) 在温度 $T = 300 \\ \\mathrm{K}$ 下的一条特定 aMD 轨迹产生的偏置势 $\\Delta V$ 的样本均值为 $\\mu_{\\Delta V} = 3.0 \\ \\mathrm{kJ} \\ \\mathrm{mol}^{-1}$，样本方差为 $\\sigma_{\\Delta V}^{2} = 9.0 \\ \\mathrm{(kJ \\ mol^{-1})^{2}}$。取摩尔气体常数 $R = 8.314462618 \\times 10^{-3} \\ \\mathrm{kJ} \\ \\mathrm{mol}^{-1} \\ \\mathrm{K}^{-1}$。使用 (a) 部分的结果，并根据 (b) 部分的理由在 $m=2$ 阶进行截斷，计算 $\\ln \\langle \\exp(\\beta \\Delta V) \\rangle$ 的数值（到 $\\beta$ 的二阶）。将你的最终答案表示为一个无量纲数，并四舍五入到四位有效数字。",
            "solution": "该问题是有效的，因为它在科学上基于统计力学和计算化学，提法恰当并提供了所有必要信息，且其表述是客观的。\n\n(a) $\\ln \\langle \\exp(\\beta \\Delta V) \\rangle$ 的幂级数表示的推导。\n\n我们被要求推导 $\\ln \\langle \\exp(\\beta \\Delta V) \\rangle$ 关于随机变量 $\\Delta V$ 的累积量的幂级数表示。出发点是矩生成函数 (MGF)、累积量生成函数 (CGF) 和累积量的定义。\n\n设 $X$ 为一个随机变量。MGF 定义为 $M_{X}(t) = \\langle \\exp(t X) \\rangle$，CGF 定义为 $K_{X}(t) = \\ln M_{X}(t)$。累积量 $\\kappa_n$ 定义为 CGF 在 $t=0$ 处的导数：\n$$\n\\kappa_n = \\frac{d^n K_X(t)}{dt^n} \\bigg|_{t=0} = K_{X}^{(n)}(0)\n$$\n我们感兴趣的量是 $\\ln \\langle \\exp(\\beta \\Delta V) \\rangle$。与定义进行比较，我们可以确定随机变量为 $X = \\Delta V$，参数为 $t = \\beta$。因此，我们寻求的量正是 $\\Delta V$ 的 CGF 在 $\\beta$ 处的值：\n$$\n\\ln \\langle \\exp(\\beta \\Delta V) \\rangle = K_{\\Delta V}(\\beta)\n$$\n为了找到一个幂级数表示，我们可以将 $K_{\\Delta V}(t)$ 表示为麦克劳林级数（在 $t=0$ 附近的泰勒级数展开）。对于一个光滑函数 $f(t)$，其级数由下式给出：\n$$\nf(t) = \\sum_{n=0}^{\\infty} \\frac{f^{(n)}(0)}{n!} t^n\n$$\n将此应用于 CGF, $K_{\\Delta V}(t)$，我们有：\n$$\nK_{\\Delta V}(t) = \\sum_{n=0}^{\\infty} \\frac{K_{\\Delta V}^{(n)}(0)}{n!} t^n\n$$\n根据累积量的定义，$\\kappa_n = K_{\\Delta V}^{(n)}(0)$，我们可以将其代入级数中：\n$$\nK_{\\Delta V}(t) = \\sum_{n=0}^{\\infty} \\frac{\\kappa_n}{n!} t^n\n$$\n让我们检查级数的第一项，即 $n=0$ 的情况：\n$$\n\\kappa_0 = K_{\\Delta V}^{(0)}(0) = K_{\\Delta V}(0) = \\ln M_{\\Delta V}(0) = \\ln \\langle \\exp(0 \\cdot \\Delta V) \\rangle = \\ln \\langle 1 \\rangle = \\ln(1) = 0\n$$\n由于 $\\kappa_0 = 0$，求和可以从 $n=1$ 开始：\n$$\nK_{\\Delta V}(t) = \\sum_{n=1}^{\\infty} \\frac{\\kappa_n}{n!} t^n = \\frac{\\kappa_1}{1!} t + \\frac{\\kappa_2}{2!} t^2 + \\frac{\\kappa_3}{3!} t^3 + \\dots\n$$\n最后，为了得到所需的表达式，我们代入 $t=\\beta$：\n$$\n\\ln \\langle \\exp(\\beta \\Delta V) \\rangle = K_{\\Delta V}(\\beta) = \\sum_{n=1}^{\\infty} \\frac{\\kappa_n}{n!} \\beta^n\n$$\n这就是 $\\ln \\langle \\exp(\\beta \\Delta V) \\rangle$ 关于 $\\beta$ 的幂的幂级数表示，其系数由偏置势 $\\Delta V$ 的累积量 $\\kappa_n$ 给出。\n\n(b) 对于近似高斯分布，在 $m=2$ 阶截断级数的合理性。\n\n(a) 部分推导出的级数对于一般分布是精确且无限的。我们被要求在 $\\Delta V$ 的分布为高斯分布的近似下，证明在二阶项 ($n=2$)后截断级数的合理性。\n\n一个均值为 $\\mu$、方差为 $\\sigma^2$ 的高斯（或正态）随机变量 $X$ 的矩生成函数由下式给出：\n$$\nM_X(t) = \\exp\\left(\\mu t + \\frac{1}{2} \\sigma^2 t^2\\right)\n$$\n相应的累积量生成函数是：\n$$\nK_X(t) = \\ln(M_X(t)) = \\ln\\left(\\exp\\left(\\mu t + \\frac{1}{2} \\sigma^2 t^2\\right)\\right) = \\mu t + \\frac{1}{2} \\sigma^2 t^2\n$$\n累积量 $\\kappa_n$ 是通过对 $K_X(t)$ 关于 $t$ 求导并在 $t=0$ 处求值得到的。\n一阶累积量是：\n$$\n\\kappa_1 = K_X'(0) = \\left. \\frac{d}{dt}\\left(\\mu t + \\frac{1}{2} \\sigma^2 t^2\\right) \\right|_{t=0} = \\left. (\\mu + \\sigma^2 t) \\right|_{t=0} = \\mu\n$$\n二阶累积量是：\n$$\n\\kappa_2 = K_X''(0) = \\left. \\frac{d^2}{dt^2}\\left(\\mu t + \\frac{1}{2} \\sigma^2 t^2\\right) \\right|_{t=0} = \\left. \\sigma^2 \\right|_{t=0} = \\sigma^2\n$$\n三阶及所有更高阶的导数是：\n$$\nK_X^{(n)}(t) = 0 \\quad \\text{for } n \\ge 3\n$$\n因此，对于 $n \\ge 3$，高阶累积量恒等于零：\n$$\n\\kappa_n = K_X^{(n)}(0) = 0 \\quad \\text{for } n \\ge 3\n$$\n这是高斯分布的一个定义性质：所有高于2阶的累积量都为零。\n\n如果 $\\Delta V$ 的分布是严格的高斯分布，那么 (a) 部分的累积量展开将精确终止：\n$$\n\\ln \\langle \\exp(\\beta \\Delta V) \\rangle = \\frac{\\kappa_1}{1!} \\beta + \\frac{\\kappa_2}{2!} \\beta^2 + \\sum_{n=3}^{\\infty} \\frac{0}{n!} \\beta^n = \\kappa_1 \\beta + \\frac{1}{2} \\kappa_2 \\beta^2\n$$\n问题陈述指出 $\\Delta V$ 的分布*经验上接近高斯分布*。这意味着对于 $n \\ge 3$ 的高阶累积量 $\\kappa_n$ 不完全为零，但与 $\\kappa_1$ 和 $\\kappa_2$ 相比，预计是可忽略不计的。因此，在 $m=2$ 阶截断级数是一个很合理的近似。被忽略的项是级数中所有 $n \\ge 3$ 的项：\n$$\n\\text{被忽略的项} = \\sum_{n=3}^{\\infty} \\frac{\\kappa_n}{n!} \\beta^n = \\frac{\\kappa_3}{6} \\beta^3 + \\frac{\\kappa_4}{24} \\beta^4 + \\dots\n$$\n这些项被忽略是因为 $\\Delta V$ 的近高斯性质意味着对于 $n \\ge 3$，有 $\\kappa_n \\approx 0$。\n\n(c) 二阶近似的数值计算。\n\n我们使用 (b) 部分的截断级数，并用给定的样本统计量作为前两个累积量的估计量：\n$$\n\\ln \\langle \\exp(\\beta \\Delta V) \\rangle \\approx \\kappa_1 \\beta + \\frac{1}{2} \\kappa_2 \\beta^2\n$$\n给定值为：\n$\\kappa_1 = \\mu_{\\Delta V} = 3.0 \\ \\mathrm{kJ} \\ \\mathrm{mol}^{-1}$\n$\\kappa_2 = \\sigma_{\\Delta V}^{2} = 9.0 \\ \\mathrm{(kJ \\ mol^{-1})^{2}}$\n$T = 300 \\ \\mathrm{K}$\n$R = 8.314462618 \\times 10^{-3} \\ \\mathrm{kJ} \\ \\mathrm{mol}^{-1} \\ \\mathrm{K}^{-1}$\n\n首先，我们计算逆热能 $\\beta = 1/(RT)$：\n$$\n\\beta = \\frac{1}{R T} = \\frac{1}{(8.314462618 \\times 10^{-3} \\ \\mathrm{kJ} \\ \\mathrm{mol}^{-1} \\ \\mathrm{K}^{-1}) \\times (300 \\ \\mathrm{K})}\n$$\n$$\n\\beta = \\frac{1}{2.4943387854 \\ \\mathrm{kJ} \\ \\mathrm{mol}^{-1}} \\approx 0.400907834 \\ (\\mathrm{kJ} \\ \\mathrm{mol}^{-1})^{-1}\n$$\n现在，我们将 $\\kappa_1$、$\\kappa_2$ 和 $\\beta$ 的值代入二阶近似中：\n$$\n\\ln \\langle \\exp(\\beta \\Delta V) \\rangle \\approx (3.0 \\ \\mathrm{kJ} \\ \\mathrm{mol}^{-1}) \\beta + \\frac{1}{2} (9.0 \\ \\mathrm{(kJ \\ mol^{-1})^{2}}) \\beta^2\n$$\n$$\n\\ln \\langle \\exp(\\beta \\Delta V) \\rangle \\approx 3.0 \\beta + 4.5 \\beta^2\n$$\n代入 $\\beta$ 的值：\n$$\n\\ln \\langle \\exp(\\beta \\Delta V) \\rangle \\approx (3.0)(0.400907834) + (4.5)(0.400907834)^2\n$$\n$$\n\\ln \\langle \\exp(\\beta \\Delta V) \\rangle \\approx 1.202723502 + (4.5)(0.160727092)\n$$\n$$\n\\ln \\langle \\exp(\\beta \\Delta V) \\rangle \\approx 1.202723502 + 0.723271914\n$$\n$$\n\\ln \\langle \\exp(\\beta \\Delta V) \\rangle \\approx 1.925995416\n$$\n问题要求答案四舍五入到四位有效数字。结果是一个无量纲数，符合要求。\n$$\n\\ln \\langle \\exp(\\beta \\Delta V) \\rangle \\approx 1.926\n$$",
            "answer": "$$\n\\boxed{1.926}\n$$"
        },
        {
            "introduction": "理论推导是基础，但将理论应用于实际数据分析才是最终目标。本练习将带你从理论走向实践，处理从aMD模拟中获得的原始数据 。你将学习如何实现数值稳定的重加权算法来计算物理观测量在正则系综下的期望值，并掌握如何运用自举法（bootstrap）这一强大的统计工具来估计计算结果的不确定性，这对于任何严谨的科学研究都至关重要。",
            "id": "3834993",
            "problem": "您正在研究加速分子动力学 (aMD)，该方法通过修改势能面来增强对稀有事件的采样。aMD 中的采样分布与真实正则分布不同，因此需要通过重加权来恢复无偏的系综平均值。从分子动力学 (MD) 的正则系综出发，其中概率密度与真实势能的玻尔兹曼因子成正比，请从第一性原理推导，在 aMD 中使用修正势进行采样时为何必须进行重加权，以及重要性权重是如何产生的。然后，给定采样得到的偏置势移和可观测值，实现一个算法来计算重加权平均值，并使用一种通过重采样权重来处理重尾重要性权重的自助法来估计其不确定性。\n\n使用以下背景和要求：\n\n- 从平衡统计力学的正则系综开始。真实势能记为 $U(\\mathbf{r})$，加速分子动力学下的修正势为 $U^{\\ast}(\\mathbf{r})$，偏置势为 $\\Delta V(\\mathbf{r})$，使得 $U^{\\ast}(\\mathbf{r}) = U(\\mathbf{r}) + \\Delta V(\\mathbf{r})$。\n- 在绝对温度 $T$ 下，正则系综的概率密度与 $\\exp\\left(-\\beta U(\\mathbf{r})\\right)$ 成正比，其中逆热能为 $\\beta = 1/(k_{\\mathrm{B}} T)$，$k_{\\mathrm{B}}$ 是玻尔兹曼常数。\n- 根据上述正则系综的事实和修正势的定义，推导出将从修正分布计算出的期望值重加权回真实分布所需的重要性采样权重。\n\n程序要求：\n\n- 输入参数在程序中硬编码。没有用户输入。\n- 物理单位：$\\Delta V$ 使用千卡/摩尔 (kcal/mol)，温度使用开尔文 (K)，并设置 $k_{\\mathrm{B}} = 0.0019872041$，单位为千卡/摩尔/开尔文 (kcal/mol/K)。以 (千卡/摩尔) 的倒数作为单位计算 $\\beta = 1/(k_{\\mathrm{B}} T)$。\n- 对于每个测试用例，您将获得：\n  - 温度 $T$（单位：开尔文）。\n  - 采样得到的偏置势值列表 $\\{\\Delta V_i\\}$（单位：千卡/摩尔）。\n  - 可观测值列表 $\\{A_i\\}$（无量纲）。\n- 使用从第一性原理推导出的权重，计算可观测值的重加权平均值，记为 $\\hat{A}$。实现数值稳定的计算来处理重尾权重。然后，通过用独立的正常数因子对权重进行乘法重采样来估计不确定性，将其作为自助法标准差，以捕捉由重尾重要性权重引起的变化性。使用 $5000$ 次自助法重复和固定的随机种子以确保确定性。\n- 您的算法必须能稳健地处理边界和边缘情况，包括所有 $\\Delta V_i$ 相等的情况以及只有一个样本的情况。\n- 每个测试用例的最终输出是两个实数：重加权平均值 $\\hat{A}$ 和自助法不确定度 $\\sigma_{\\hat{A}}$。两者都表示为十进制浮点数。\n- 测试套件：\n  1. $T = 300$, $\\Delta V = [-0.4, 0.1, 0.0, 1.2, -0.8, 0.5, 0.3]$, $A = [1.25, 0.72, 0.95, 1.85, 1.05, 1.42, 0.88]$.\n  2. $T = 310$, $\\Delta V = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]$, $A = [1.10, 0.90, 1.00, 1.20, 0.80, 1.05]$.\n  3. $T = 300$, $\\Delta V = [0.0, 8.0, -2.0, 6.0, 0.5, -0.3, 4.0]$, $A = [0.90, 2.50, 0.70, 1.80, 1.20, 1.00, 2.00]$.\n  4. $T = 298$, $\\Delta V = [0.7]$, $A = [1.33]$.\n- 最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。该列表必须按 $[\\hat{A}_1, \\sigma_{\\hat{A},1}, \\hat{A}_2, \\sigma_{\\hat{A},2}, \\hat{A}_3, \\sigma_{\\hat{A},3}, \\hat{A}_4, \\sigma_{\\hat{A},4}]$ 的顺序进行扁平化，其中下标表示测试用例索引。将每个浮点数四舍五入到 $6$ 位小数。\n\n您的实现必须是一个完整的、可运行的程序，该程序为提供的测试套件计算所需的输出，并以确切指定的格式打印它们。",
            "solution": "该问题要求从第一性原理推导加速分子动力学 (aMD) 中使用的重加权方案，并实现一个算法来计算重加权的可观测值及其不确定性。\n\n### 原理与推导\n\n该问题的基础在于平衡统计力学和重要性采样理论。在一个与恒定体积 $V$ 和温度 $T$ 的热浴处于热平衡的经典系统中，发现系统处于具有构型 $\\mathbf{r}$ 和势能 $U(\\mathbf{r})$ 的特定微观态的概率由正则系综的玻尔兹曼分布给出。\n\n概率密度函数 $p_U(\\mathbf{r})$ 与玻尔兹曼因子成正比：\n$$ p_U(\\mathbf{r}) = \\frac{e^{-\\beta U(\\mathbf{r})}}{Z_U} $$\n其中 $\\beta = 1/(k_{\\mathrm{B}} T)$ 是逆热能，$k_{\\mathrm{B}}$ 是玻尔兹曼常数，$Z_U$ 是正则配分函数，它作为一个归一化常数：\n$$ Z_U = \\int e^{-\\beta U(\\mathbf{r})} \\, d\\mathbf{r} $$\n积分遍及所有可能的构型 $\\mathbf{r}$。\n\n一个物理可观测值 $A(\\mathbf{r})$ 的系综平均是其在该概率分布上的期望值：\n$$ \\langle A \\rangle_U = \\int A(\\mathbf{r}) p_U(\\mathbf{r}) \\, d\\mathbf{r} = \\frac{\\int A(\\mathbf{r}) e^{-\\beta U(\\mathbf{r})} \\, d\\mathbf{r}}{\\int e^{-\\beta U(\\mathbf{r})} \\, d\\mathbf{r}} $$\n\n在加速分子动力学 (aMD) 中，当原始势低于某个阈值时，通过添加一个非负的偏置势 $\\Delta V(\\mathbf{r})$ 来修改势能面 $U(\\mathbf{r})$，否则偏置势为零。为了一般性，我们将修正势表示为 $U^{\\ast}(\\mathbf{r}) = U(\\mathbf{r}) + \\Delta V(\\mathbf{r})$。在此修正势下运行的模拟会从一个不同的概率分布 $p_{U^{\\ast}}(\\mathbf{r})$ 中采样构型：\n$$ p_{U^{\\ast}}(\\mathbf{r}) = \\frac{e^{-\\beta U^{\\ast}(\\mathbf{r})}}{Z_{U^{\\ast}}} $$\n其中 $Z_{U^{\\ast}} = \\int e^{-\\beta U^{\\ast}(\\mathbf{r})} \\, d\\mathbf{r}$。\n\n对 aMD 轨迹上的可观测值 $A$ 进行直接平均会得到一个不正确的、有偏的估计 $\\langle A \\rangle_{U^{\\ast}}$。为了恢复正确的正则平均 $\\langle A \\rangle_U$，我们必须对样本进行重加权。这是重要性采样的一个应用。\n\n我们可以通过用修正系综来重写积分，从而表达 $\\langle A \\rangle_U$。我们在 $\\langle A \\rangle_U$ 的表达式中，对被积函数同乘和同除以 $e^{-\\beta U^{\\ast}(\\mathbf{r})}$：\n$$ \\langle A \\rangle_U = \\frac{\\int A(\\mathbf{r}) \\frac{e^{-\\beta U(\\mathbf{r})}}{e^{-\\beta U^{\\ast}(\\mathbf{r})}} e^{-\\beta U^{\\ast}(\\mathbf{r})} \\, d\\mathbf{r}}{\\int \\frac{e^{-\\beta U(\\mathbf{r})}}{e^{-\\beta U^{\\ast}(\\mathbf{r})}} e^{-\\beta U^{\\ast}(\\mathbf{r})} \\, d\\mathbf{r}} $$\n积分内的比率充当重加权因子，或称为重要性权重。我们定义这个权重为 $w(\\mathbf{r})$：\n$$ w(\\mathbf{r}) = \\frac{e^{-\\beta U(\\mathbf{r})}}{e^{-\\beta U^{\\ast}(\\mathbf{r})}} = \\frac{e^{-\\beta U(\\mathbf{r})}}{e^{-\\beta (U(\\mathbf{r}) + \\Delta V(\\mathbf{r}))}} = \\frac{e^{-\\beta U(\\mathbf{r})}}{e^{-\\beta U(\\mathbf{r})} e^{-\\beta \\Delta V(\\mathbf{r})}} = e^{\\beta \\Delta V(\\mathbf{r})} $$\n每个构型的权重是在该构型上施加的偏置势经 $\\beta$ 缩放后的指数。\n\n将 $w(\\mathbf{r})$ 代回到 $\\langle A \\rangle_U$ 的表达式中：\n$$ \\langle A \\rangle_U = \\frac{\\int A(\\mathbf{r}) w(\\mathbf{r}) e^{-\\beta U^{\\ast}(\\mathbf{r})} \\, d\\mathbf{r}}{\\int w(\\mathbf{r}) e^{-\\beta U^{\\ast}(\\mathbf{r})} \\, d\\mathbf{r}} $$\n通过将分子和分母同除以修正配分函数 $Z_{U^{\\ast}}$，我们可以将其表示为在修正 ($U^{\\ast}$) 系综中计算的期望值：\n$$ \\langle A \\rangle_U = \\frac{\\langle A \\cdot w \\rangle_{U^{\\ast}}}{\\langle w \\rangle_{U^{\\ast}}} $$\n这就是基本的重加权方程。\n\n在模拟中，我们生成一个包含 $N$ 个快照的离散轨迹 $\\{\\mathbf{r}_1, \\mathbf{r}_2, \\dots, \\mathbf{r}_N\\}$，这些快照是从 $p_{U^{\\ast}}$ 中采样的。系综平均值通过对这些快照的算术平均来估计。真实正则平均的估计量，记为 $\\hat{A}$，是：\n$$ \\hat{A} = \\frac{\\frac{1}{N} \\sum_{i=1}^{N} A(\\mathbf{r}_i) w(\\mathbf{r}_i)}{\\frac{1}{N} \\sum_{i=1}^{N} w(\\mathbf{r}_i)} = \\frac{\\sum_{i=1}^{N} A_i w_i}{\\sum_{i=1}^{N} w_i} $$\n其中 $A_i = A(\\mathbf{r}_i)$ 且 $w_i = e^{\\beta \\Delta V_i}$，而 $\\Delta V_i = \\Delta V(\\mathbf{r}_i)$。\n\n### 算法设计\n\n**1. 重加权平均计算：**\n给定一组采样得到的偏置势 $\\{\\Delta V_i\\}$ 和相应的可观测值 $\\{A_i\\}$，计算过程如下。\n首先，计算 $\\beta = 1/(k_{\\mathrm{B}} T)$。\n然后，计算权重 $w_i = e^{\\beta \\Delta V_i}$。$\\beta \\Delta V_i$ 的值可能很大，导致数值溢出。为确保稳定性，我们使用标准的“log-sum-exp”技巧。设 $c = \\max_i(\\beta \\Delta V_i)$。我们计算缩放后的权重 $w'_i = e^{\\beta \\Delta V_i - c}$。重加权平均则为：\n$$ \\hat{A} = \\frac{\\sum_{i=1}^{N} A_i e^{\\beta \\Delta V_i}}{\\sum_{i=1}^{N} e^{\\beta \\Delta V_i}} = \\frac{\\sum_{i=1}^{N} A_i e^{\\beta \\Delta V_i - c}}{\\sum_{i=1}^{N} e^{\\beta \\Delta V_i - c}} = \\frac{\\sum_{i=1}^{N} A_i w'_i}{\\sum_{i=1}^{N} w'_i} $$\n该公式在数值上是稳健的，因为现在的最大指数为 $0$。\n\n**2. 不确定性估计：**\n权重 $w_i$ 通常具有重尾分布，这意味着少数几个快照就可能主导总和。标准误差公式在这种情况下是不可靠的。该问题指定了一种适用于这种情况的自助法程序。它涉及使用独立的正常数因子对权重进行乘法重采样。这是贝叶斯自助法的一种变体，其中新权重是通过将原始权重乘以从均值为 $1$ 的指数分布中抽取的随机数来生成的。\n\n算法如下：\n1. 为保证可复现性，设置一个固定的随机种子。\n2. 对于固定数量的自助法重复，即 $B = 5000$：\n   a. 对于 $N$ 个原始样本中的每一个，从指数分布中抽取一个随机数 $g_i$，即 $g_i \\sim \\text{Exponential}(1)$。\n   b. 为第 $b$ 次重复创建一个新的自助法权重集：$w''_{i,b} = w'_i \\cdot g_i$。\n   c. 计算平均值的自助法估计：$\\hat{A}_b = \\frac{\\sum_{i=1}^{N} A_i w''_{i,b}}{\\sum_{i=1}^{N} w''_{i,b}}$。\n3. 集合 $\\{\\hat{A}_1, \\hat{A}_2, \\dots, \\hat{A}_B\\}$ 构成了均值的自助法分布。\n4. 不确定度 $\\sigma_{\\hat{A}}$ 被估计为该自助法分布的样本标准差：\n$$ \\sigma_{\\hat{A}} = \\sqrt{\\frac{1}{B-1} \\sum_{b=1}^{B} (\\hat{A}_b - \\bar{A}_{\\text{boot}})^2} $$\n其中 $\\bar{A}_{\\text{boot}}$ 是自助法估计的均值。\n\n**处理边缘情况：**\n- 如果所有的 $\\Delta V_i$ 都相同，则所有的权重 $w_i$ 都相等。$\\hat{A}$ 的公式正确地简化为 $\\{A_i\\}$ 的简单算术平均值。\n- 如果只给定一个样本 ($N=1$)，重加权平均就是其自身的值，即 $\\hat{A} = A_1$。自助法程序将对所有重复都产生 $\\hat{A}_b = A_1$，导致不确定度 $\\sigma_{\\hat{A}} = 0$，这对于单样本估计是一个合理的结果。\n这种基于原理的方法既提供了正则平均的稳健估计，也提供了其统计不确定性的可靠度量。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_reweighted_stats(T, dV, A, k_B, n_bootstrap, rng):\n    \"\"\"\n    Computes the reweighted average and its uncertainty for aMD data.\n\n    Args:\n        T (float): Temperature in Kelvin.\n        dV (list or np.ndarray): List of sampled boost potential values in kcal/mol.\n        A (list or np.ndarray): List of corresponding observable values.\n        k_B (float): Boltzmann constant in kcal/mol/K.\n        n_bootstrap (int): Number of bootstrap replicates.\n        rng (np.random.Generator): NumPy random number generator for reproducibility.\n\n    Returns:\n        tuple: A tuple containing the reweighted mean and its bootstrap uncertainty.\n    \"\"\"\n    dV = np.asarray(dV, dtype=np.float64)\n    A = np.asarray(A, dtype=np.float64)\n    N = len(A)\n\n    # Handle edge case: no samples\n    if N == 0:\n        return np.nan, np.nan\n\n    # Handle edge case: single sample\n    if N == 1:\n        return A[0], 0.0\n\n    # Calculate inverse thermal energy\n    beta = 1.0 / (k_B * T)\n\n    # Calculate log-weights for numerical stability\n    beta_dV = beta * dV\n    # The max subtraction ensures the largest weight is exp(0)=1, preventing overflow.\n    log_weights = beta_dV - np.max(beta_dV)\n    weights = np.exp(log_weights)\n\n    # Calculate the reweighted average\n    sum_weights = np.sum(weights)\n    if sum_weights > 0:\n        reweighted_mean = np.sum(A * weights) / sum_weights\n    else:\n        # This case is highly unlikely with the stable weight calculation unless N=0\n        reweighted_mean = np.mean(A)\n\n    # Estimate uncertainty using a multiplicative (Bayesian-like) bootstrap\n    bootstrap_means = np.empty(n_bootstrap)\n    for i in range(n_bootstrap):\n        # Generate positive random factors from an Exponential(1) distribution\n        g = rng.exponential(scale=1.0, size=N)\n        \n        # Create bootstrap weights by re-scaling original weights\n        bootstrap_weights = weights * g\n        \n        sum_bootstrap_weights = np.sum(bootstrap_weights)\n        if sum_bootstrap_weights > 0:\n            bootstrap_means[i] = np.sum(A * bootstrap_weights) / sum_bootstrap_weights\n        else:\n            # This case is also extremely unlikely\n            bootstrap_means[i] = np.nan\n\n    # Compute bootstrap standard deviation (ddof=1 for sample standard deviation)\n    uncertainty = np.nanstd(bootstrap_means, ddof=1)\n    \n    return reweighted_mean, uncertainty\n\ndef solve():\n    \"\"\"\n    Main function to run the test cases and print the final results.\n    \"\"\"\n    # Define physical constants and algorithm parameters\n    k_B = 0.0019872041  # Boltzmann constant in kcal/mol/K\n    N_BOOTSTRAP = 5000\n    SEED = 42  # Fixed seed for deterministic results\n\n    # Initialize a random number generator\n    rng = np.random.default_rng(SEED)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'T': 300, 'dV': [-0.4, 0.1, 0.0, 1.2, -0.8, 0.5, 0.3], 'A': [1.25, 0.72, 0.95, 1.85, 1.05, 1.42, 0.88]},\n        {'T': 310, 'dV': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'A': [1.10, 0.90, 1.00, 1.20, 0.80, 1.05]},\n        {'T': 300, 'dV': [0.0, 8.0, -2.0, 6.0, 0.5, -0.3, 4.0], 'A': [0.90, 2.50, 0.70, 1.80, 1.20, 1.00, 2.00]},\n        {'T': 298, 'dV': [0.7], 'A': [1.33]}\n    ]\n\n    results = []\n    for case in test_cases:\n        mean, uncertainty = compute_reweighted_stats(\n            case['T'], case['dV'], case['A'], k_B, N_BOOTSTRAP, rng\n        )\n        results.extend([mean, uncertainty])\n\n    # Final print statement in the exact required format.\n    # Each value is formatted to 6 decimal places.\n    formatted_results = [f'{x:.6f}' for x in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "尽管重加权能够从偏置轨迹中恢复无偏的统计平均，但这一过程往往伴随着统计效率的损失，其根源在于重要性权重的高度不均匀。本练习将向你介绍“有效样本量”（Effective Sample Size, ESS）这一关键诊断指标 。通过推导并计算ESS，你将能够量化重加权对数据统计能力的实际影响，从而评估aMD模拟的效率，并为优化模拟参数提供依据。",
            "id": "3835021",
            "problem": "您正在研究加速分子动力学（aMD），在该方法中，通过在一个偏置势下采样轨迹来改善探索，然后将可观测值重新加权以回到正则系综。令 $w_i$ 表示在 aMD 偏置引起的采样分布下抽取的 $N$ 个样本的非负重要性权重，其中 $i \\in \\{1,\\dots,N\\}$，并令归一化权重为 $\\tilde{w}_i = w_i \\big/ \\sum_{j=1}^{N} w_j$。从统计力学和计算化学生物学中的重要性采样原理出发，仅用未归一化的权重 $w_i$ 推导有效样本量 $N_{\\mathrm{eff}}$ 的通用表达式。您的推导必须从以下基本基础开始：\n- 正则系综的概率密度为 $\\pi(x) \\propto \\exp(-\\beta U(x))$，其中构象为 $x$，势能为 $U(x)$，逆温为 $\\beta = 1/(k_{\\mathrm{B}} T)$，$k_{\\mathrm{B}}$ 是玻尔兹曼常数，$T$ 是绝对温度。\n- 在加速分子动力学（aMD）中，模拟在修正势 $U'(x) = U(x) + \\Delta U(x)$ 下进行，并使用重要性权重 $w(x) \\propto \\pi(x)/q(x)$ 重新加权至 $\\pi(x)$，其中 $q(x) \\propto \\exp(-\\beta U'(x))$ 是采样密度。因此，$w(x)$ 是非负的，并允许归一化为 $\\tilde{w}_i$，使得 $\\sum_{i=1}^{N} \\tilde{w}_i = 1$。\n- 自归一化重要性采样估计量的方差取决于归一化权重 $\\tilde{w}_i$ 的离散程度。在权重相等的情况下，有效独立样本数等于总数 $N$。\n\n基于此，推导出一个 $N_{\\mathrm{eff}}$ 的表达式，该表达式在所有权重相等时恢复为 $N$，并在权重分布变得更加异构时减小。然后，实现一个程序，为以下每个权重测试用例计算此 $N_{\\mathrm{eff}}$。所有权重都是无量纲的。每个测试用例所需的输出是一个小数点后保留六位的小数。\n\n测试套件：\n- 用例 1：$[1,1,1,1,1]$。\n- 用例 2：$[10,0,0,0,0]$。\n- 用例 3：$[0.1,0.2,0.3,0.4]$。\n- 用例 4：$[100,200,300,400]$。\n- 用例 5：$[0.5,0.5,0.5,0.5,0.5,0.5]$。\n- 用例 6：$[2,1,1,1,1]$。\n- 用例 7：$[10^{-100}, 1, 10^{-50}, 10^{-25}]$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表内无空格，结果按上述用例的顺序排列（例如，$[r_1,r_2,\\dots,r_7]$）。每个 $r_i$ 必须是对应案例计算出的 $N_{\\mathrm{eff}}$，并四舍五入到小数点后六位。",
            "solution": "所述问题是有效的。它在科学上基于统计力学和重要性采样应用于计算化学生物学（特别是加速分子动力学，aMD）的原理。该问题提法恰当、客观，并包含足够的信息来推导有效样本量 $N_{\\mathrm{eff}}$ 的所需表达式。前提条件一致且符合事实。因此，我们可以进行形式推导。\n\n目标是为一个通过偏置模拟获得的包含 $N$ 个样本的集合，根据它们的未归一化重要性权重 $w_i \\ge 0$ 推导有效样本量 $N_{\\mathrm{eff}}$ 的通用表达式。推导必须满足两个关键性质：（1）当所有权重相等时，$N_{\\mathrm{eff}} = N$；（2）随着权重异构性的增加，$N_{\\mathrm{eff}}$ 减小。\n\n我们的出发点是可观测值 $A(x)$ 的正则期望值（记作 $\\langle A \\rangle_{\\pi}$）的自归一化重要性采样估计量。给定从偏置概率密度 $q(x)$ 中抽取的 $N$ 个构象 $\\{x_i\\}$，该估计量为：\n$$\n\\hat{A}_N = \\frac{\\sum_{i=1}^{N} A(x_i) w_i}{\\sum_{j=1}^{N} w_j} = \\sum_{i=1}^{N} A(x_i) \\tilde{w}_i\n$$\n在此，$w_i = \\pi(x_i)/q(x_i)$ 是未归一化的重要性权重，而 $\\tilde{w}_i = w_i / \\sum_{j=1}^{N} w_j$ 是相应的归一化权重，满足 $\\sum_{i=1}^{N} \\tilde{w}_i = 1$。在 aMD 的背景下，$w_i = \\exp(\\beta \\Delta U(x_i))$，其中 $\\Delta U(x_i)$ 是施加于构象 $x_i$ 的偏置势。\n\n有效样本量 $N_{\\mathrm{eff}}$ 的概念为重要性样本的质量提供了一个直观的度量。它的定义是通过将重要性采样估计量的方差与从目标分布 $\\pi(x)$ 直接抽取的 $N_{\\mathrm{eff}}$ 个独立样本所获得的理想估计量的方差相关联。\n\n从 $\\pi(x)$ 中抽取的 $N_{\\mathrm{ideal}}$ 个独立样本的估计量方差为 $\\mathrm{Var}_{\\pi}(A) / N_{\\mathrm{ideal}}$。我们旨在找到一个值 $N_{\\mathrm{eff}}$，使其在我们的重要性采样估计量中扮演 $N_{\\mathrm{ideal}}$ 的角色。\n\n重要性采样理论中的一个标准结果将自归一化估计量 $\\hat{A}_N$ 的方差近似为与归一化权重平方和成正比：\n$$\n\\mathrm{Var}(\\hat{A}_N) \\approx \\mathrm{Var}_{\\pi}(A) \\left( \\sum_{i=1}^{N} \\tilde{w}_i^2 \\right)\n$$\n这个近似抓住了估计方差因权重不均匀而增大的本质事实。当一个或少数几个权重占主导地位时，总和 $\\sum \\tilde{w}_i^2$ 接近 1，导致高方差。相反，当所有权重都相等时（$\\tilde{w}_i = 1/N$），该总和在 $N(1/N)^2 = 1/N$ 处达到最小值，从而为大小为 $N$ 的样本带来最低的可能方差。\n\n通过将我们的估计量的方差与大小为 $N_{\\mathrm{eff}}$ 的理想估计量的方差相等，我们得到：\n$$\n\\frac{\\mathrm{Var}_{\\pi}(A)}{N_{\\mathrm{eff}}} \\approx \\mathrm{Var}_{\\pi}(A) \\left( \\sum_{i=1}^{N} \\tilde{w}_i^2 \\right)\n$$\n消去公因子 $\\mathrm{Var}_{\\pi}(A)$，我们得到用归一化权重表示的 $N_{\\mathrm{eff}}$ 定义：\n$$\nN_{\\mathrm{eff}} = \\frac{1}{\\sum_{i=1}^{N} \\tilde{w}_i^2}\n$$\n问题要求用未归一化的权重 $w_i$ 表示此表达式。我们代入 $\\tilde{w}_i$ 的定义：\n$$\nN_{\\mathrm{eff}} = \\frac{1}{\\sum_{i=1}^{N} \\left( \\frac{w_i}{\\sum_{j=1}^{N} w_j} \\right)^2} = \\frac{1}{\\frac{\\sum_{i=1}^{N} w_i^2}{\\left(\\sum_{j=1}^{N} w_j\\right)^2}}\n$$\n这简化为最终所需的表达式：\n$$\nN_{\\mathrm{eff}} = \\frac{\\left(\\sum_{i=1}^{N} w_i\\right)^2}{\\sum_{i=1}^{N} w_i^2}\n$$\n该公式仅依赖于未归一化的权重 $w_i$，符合要求。\n\n现在我们根据指定条件验证此结果。\n\n1.  **权重相等：** 设对于所有 $i \\in \\{1, \\dots, N\\}$，$w_i = c$，其中 $c > 0$ 是一个常数。\n    总和为 $\\sum_{i=1}^{N} w_i = Nc$。\n    平方和为 $\\sum_{i=1}^{N} w_i^2 = Nc^2$。\n    $$\n    N_{\\mathrm{eff}} = \\frac{(Nc)^2}{Nc^2} = \\frac{N^2 c^2}{N c^2} = N\n    $$\n    条件得到满足。\n\n2.  **权重异构：** 该表达式可以根据权重的变异系数 $CV_w = \\sigma_w / \\bar{w}$ 重写，其中 $\\bar{w}$ 是权重的平均值，$\\sigma_w$ 是权重的标准差。该公式等价于 $N_{\\mathrm{eff}} = N / (1 + CV_w^2)$。随着权重异构性的增加，$CV_w$ 增大，因此 $N_{\\mathrm{eff}}$ 从其最大值 $N$（当 $CV_w = 0$ 时）向其最小值 1（在一个权重远超其他所有权重的极限情况下）减小。条件得到满足。\n\n推导至此结束。所推导的公式是稳健、通用的，并符合问题陈述中概述的基本原则。我们现在将此公式应用于所提供的测试用例。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Calculates the effective sample size for a series of weight sets\n    and prints the results in the specified format.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        [1.0, 1.0, 1.0, 1.0, 1.0],\n        [10.0, 0.0, 0.0, 0.0, 0.0],\n        [0.1, 0.2, 0.3, 0.4],\n        [100.0, 200.0, 300.0, 400.0],\n        [0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n        [2.0, 1.0, 1.0, 1.0, 1.0],\n        [1.0e-100, 1.0, 1.0e-50, 1.0e-25]\n    ]\n\n    results = []\n    for case in test_cases:\n        # Main logic to calculate the result for one case goes here.\n        # Convert the list of weights to a NumPy array for efficient computation.\n        # Using float64 for standard double-precision floating-point arithmetic.\n        weights = np.array(case, dtype=np.float64)\n        \n        # Calculate the sum of the squares of the weights.\n        sum_of_squares = np.sum(weights**2)\n        \n        # The formula for effective sample size is (sum(w))^2 / sum(w^2).\n        # We must handle the edge case where all weights are zero to avoid division by zero.\n        if sum_of_squares == 0.0:\n            result = 0.0\n        else:\n            # Calculate the sum of the weights.\n            sum_of_weights = np.sum(weights)\n            # Apply the derived formula.\n            result = sum_of_weights**2 / sum_of_squares\n            \n        # Format the result to six decimal places and add to the list.\n        results.append(f\"{result:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}