{
    "hands_on_practices": [
        {
            "introduction": "To truly master metadynamics, it's essential to understand how the abstract bias potential, defined on a low-dimensional collective variable (CV), translates into concrete forces acting on individual atoms in a simulation. This foundational exercise guides you through this crucial connection. By applying the chain rule from multivariable calculus, you will derive the analytical expression for the bias force, bridging the gap between the conceptual framework of metadynamics and its practical implementation within a molecular dynamics engine .",
            "id": "3852294",
            "problem": "Consider a pair of atoms indexed by $i$ and $j$ in a biomolecular system, with Cartesian position vectors $\\mathbf{r}_i$ and $\\mathbf{r}_j$. In metadynamics, a Collective Variable (CV) is a low-dimensional descriptor of the system’s state; here, the CV is the interatomic distance $s = |\\mathbf{r}_i - \\mathbf{r}_j|$. A metadynamics bias potential $V_{\\mathrm{b}}(s,t)$ is constructed as a sum of $M$ Gaussian hills (each deposited at an earlier time and centered at $s_n$ with height $w_n$ and width $\\sigma_n$), that is,\n$$\nV_{\\mathrm{b}}(s,t) = \\sum_{n=1}^{M} w_n \\exp\\!\\left( - \\frac{(s - s_n)^{2}}{2 \\sigma_n^{2}} \\right).\n$$\nStarting from the definition of force in classical mechanics ($\\mathbf{F} = - \\nabla_{\\mathbf{r}} U$ for a potential energy $U$), the definition of the CV $s$ in terms of the atom positions, and the chain rule from multivariable calculus, derive the gradient $\\frac{\\partial s}{\\partial \\mathbf{r}_i}$ and then use it to obtain the explicit expression for the bias force vector acting on atom $i$, $\\mathbf{F}_{i}^{(\\mathrm{b})}(t)$, in terms of $\\mathbf{r}_i$, $\\mathbf{r}_j$, $s$, and the Gaussian parameters $\\{w_n, s_n, \\sigma_n\\}_{n=1}^{M}$. Provide the symbolic expression only; if numerically evaluated, express the force in kilojoules per mole per nanometer (kJ mol$^{-1}$ nm$^{-1}$). The final answer must be a single closed-form analytic expression.",
            "solution": "The fundamental base consists of: (i) the definition of the force from classical mechanics, namely $\\mathbf{F} = - \\nabla_{\\mathbf{r}} U$, where $U$ is the potential energy as a function of coordinates; (ii) the definition of the collective variable $s = |\\mathbf{r}_i - \\mathbf{r}_j|$; and (iii) the chain rule for differentiation in multivariable calculus, which connects derivatives through intermediate variables.\n\nFirst, we derive $\\frac{\\partial s}{\\partial \\mathbf{r}_i}$. Write the distance in terms of a dot product:\n$$\ns = |\\mathbf{r}_i - \\mathbf{r}_j| = \\sqrt{ (\\mathbf{r}_i - \\mathbf{r}_j) \\cdot (\\mathbf{r}_i - \\mathbf{r}_j) }.\n$$\nDefine $\\mathbf{d} \\equiv \\mathbf{r}_i - \\mathbf{r}_j$. Then $s = \\sqrt{\\mathbf{d} \\cdot \\mathbf{d}}$. For $\\mathbf{d} \\neq \\mathbf{0}$, differentiate $s$ with respect to $\\mathbf{r}_i$ using the chain rule and properties of gradients:\n$$\n\\frac{\\partial s}{\\partial \\mathbf{r}_i} = \\frac{\\partial}{\\partial \\mathbf{r}_i} \\left( (\\mathbf{d} \\cdot \\mathbf{d})^{1/2} \\right) = \\frac{1}{2} (\\mathbf{d} \\cdot \\mathbf{d})^{-1/2} \\cdot 2 \\mathbf{d} = \\frac{\\mathbf{d}}{|\\mathbf{d}|} = \\frac{\\mathbf{r}_i - \\mathbf{r}_j}{|\\mathbf{r}_i - \\mathbf{r}_j|}.\n$$\nNote that this gradient is undefined at $\\mathbf{r}_i = \\mathbf{r}_j$ (i.e., $s = 0$) due to the absolute value singularity, but in molecular simulations atoms do not occupy exactly the same position, and regularization is typically unnecessary.\n\nSecond, we obtain the bias force on atom $i$. The bias potential depends only on $s$, which in turn depends on the atomic coordinates. Therefore, the force on atom $i$ due to the bias is given by\n$$\n\\mathbf{F}_{i}^{(\\mathrm{b})}(t) = - \\frac{\\partial V_{\\mathrm{b}}(s,t)}{\\partial \\mathbf{r}_i} = - \\frac{\\mathrm{d} V_{\\mathrm{b}}(s,t)}{\\mathrm{d} s} \\cdot \\frac{\\partial s}{\\partial \\mathbf{r}_i},\n$$\nwhere we have used the chain rule to factor the derivative into a derivative with respect to the scalar argument $s$ and the gradient of $s$ with respect to $\\mathbf{r}_i$.\n\nWe now compute $\\frac{\\mathrm{d} V_{\\mathrm{b}}(s,t)}{\\mathrm{d} s}$. For the given sum of Gaussian hills,\n$$\nV_{\\mathrm{b}}(s,t) = \\sum_{n=1}^{M} w_n \\exp\\!\\left( - \\frac{(s - s_n)^{2}}{2 \\sigma_n^{2}} \\right),\n$$\nthe derivative with respect to $s$ is the sum of derivatives term-wise:\n$$\n\\frac{\\mathrm{d} V_{\\mathrm{b}}(s,t)}{\\mathrm{d} s} = \\sum_{n=1}^{M} w_n \\exp\\!\\left( - \\frac{(s - s_n)^{2}}{2 \\sigma_n^{2}} \\right) \\cdot \\frac{\\mathrm{d}}{\\mathrm{d} s} \\left( - \\frac{(s - s_n)^{2}}{2 \\sigma_n^{2}} \\right).\n$$\nCompute the inner derivative:\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d} s} \\left( - \\frac{(s - s_n)^{2}}{2 \\sigma_n^{2}} \\right) = - \\frac{1}{\\sigma_n^{2}} (s - s_n).\n$$\nThus,\n$$\n\\frac{\\mathrm{d} V_{\\mathrm{b}}(s,t)}{\\mathrm{d} s} = - \\sum_{n=1}^{M} w_n \\exp\\!\\left( - \\frac{(s - s_n)^{2}}{2 \\sigma_n^{2}} \\right) \\frac{s - s_n}{\\sigma_n^{2}}.\n$$\nCombining this with $\\frac{\\partial s}{\\partial \\mathbf{r}_i} = \\frac{\\mathbf{r}_i - \\mathbf{r}_j}{|\\mathbf{r}_i - \\mathbf{r}_j|}$ yields\n$$\n\\mathbf{F}_{i}^{(\\mathrm{b})}(t) = - \\left( - \\sum_{n=1}^{M} w_n \\exp\\!\\left( - \\frac{(s - s_n)^{2}}{2 \\sigma_n^{2}} \\right) \\frac{s - s_n}{\\sigma_n^{2}} \\right) \\cdot \\frac{\\mathbf{r}_i - \\mathbf{r}_j}{|\\mathbf{r}_i - \\mathbf{r}_j|}.\n$$\nTherefore, the bias force acting on atom $i$ is\n$$\n\\mathbf{F}_{i}^{(\\mathrm{b})}(t) = \\left( \\sum_{n=1}^{M} w_n \\exp\\!\\left( - \\frac{(s - s_n)^{2}}{2 \\sigma_n^{2}} \\right) \\frac{s - s_n}{\\sigma_n^{2}} \\right) \\frac{\\mathbf{r}_i - \\mathbf{r}_j}{|\\mathbf{r}_i - \\mathbf{r}_j|},\n$$\nwith $s = |\\mathbf{r}_i - \\mathbf{r}_j|$. This expression is a symbolic vector result consistent with the fundamental definitions and the chain rule, and if numerically evaluated, the force would be reported in kilojoules per mole per nanometer (kJ mol$^{-1}$ nm$^{-1}$).",
            "answer": "$$\\boxed{\\left( \\sum_{n=1}^{M} w_n \\exp\\!\\left( - \\frac{(s - s_n)^{2}}{2 \\sigma_n^{2}} \\right) \\frac{s - s_n}{\\sigma_n^{2}} \\right) \\frac{\\mathbf{r}_i - \\mathbf{r}_j}{|\\mathbf{r}_i - \\mathbf{r}_j|}}$$"
        },
        {
            "introduction": "A perfectly executed metadynamics simulation can still produce misleading results if the chosen collective variable is inadequate. This common challenge is at the heart of the following thought experiment, which presents a frequent and often puzzling scenario: a deep free energy minimum found via metadynamics appears to be kinetically unstable in a standard, unbiased simulation. This practice challenges you to diagnose this discrepancy, revealing the critical concept of \"hidden\" degrees of freedom and the pitfalls of projecting a high-dimensional energy landscape onto a low-dimensional, incomplete coordinate .",
            "id": "2455465",
            "problem": "A student uses metadynamics to explore the free energy surface (FES) of a molecular system. They choose a single collective variable (CV) $s(\\mathbf{x})$, add a history-dependent bias $V_{\\mathrm{bias}}(s,t)$ during the metadynamics run, and after sufficient time reconstruct a free energy profile $F(s)$ from the bias. In the reconstructed $F(s)$, the student identifies a seemingly deep minimum at $s=s^{\\ast}$. They then extract a configuration $\\mathbf{x}^{\\ast}$ from the metadynamics trajectory with $s(\\mathbf{x}^{\\ast}) \\approx s^{\\ast}$ and run an unbiased Molecular Dynamics (MD) simulation at the same temperature $T$ and with the same Hamiltonian (no bias, identical thermostat and integrator settings). In this unbiased MD, the system rapidly leaves the vicinity of $s^{\\ast}$ and transitions to another state and does not return on the simulated timescale.\n\nAssume the thermodynamic definition $F(s)=-k_{\\mathrm{B}}T\\ln P(s)+C$, where $k_{\\mathrm{B}}$ is the Boltzmann constant, $P(s)$ is the equilibrium probability density of the CV, and $C$ is an irrelevant constant. Also recall that, along a truly relevant reaction coordinate $q$, a transition rate $k$ typically scales as $k\\propto \\exp(-\\beta \\Delta F^{\\ddagger})$ with $\\beta=1/(k_{\\mathrm{B}}T)$ and $\\Delta F^{\\ddagger}$ the free energy barrier along $q$.\n\nWhich of the following is the most justified implication of the student’s observation about the metadynamics run?\n\nA. The deep minimum in $F(s)$ necessarily implies a large exit barrier, so the rapid escape in unbiased MD must be due to numerical integration errors; the metadynamics free energy is otherwise correct.\n\nB. The chosen CV $s(\\mathbf{x})$ is insufficient to parameterize the slow dynamics; the apparent deep minimum in $F(s)$ is an artifact of projecting onto $s$, and the configuration at $s^{\\ast}$ is unstable along orthogonal degrees of freedom not captured by $s$.\n\nC. The discrepancy arises because the unbiased MD temperature $T$ differs from that used in metadynamics; therefore no inference about the metadynamics quality can be made.\n\nD. The Gaussian hills in metadynamics were too small, so the minimum at $s^{\\ast}$ is even deeper in reality; the fast escape in unbiased MD is a rare fluctuation and supports convergence of the metadynamics run.",
            "solution": "The problem statement must first be validated for scientific and logical integrity.\n\n### Step 1: Extract Givens\n- A metadynamics simulation is performed on a molecular system using a single collective variable (CV) $s(\\mathbf{x})$.\n- A history-dependent bias $V_{\\mathrm{bias}}(s,t)$ is added during the simulation.\n- A free energy profile $F(s)$ is reconstructed from the bias.\n- This reconstructed $F(s)$ has a deep minimum at $s=s^{\\ast}$.\n- A configuration $\\mathbf{x}^{\\ast}$ is extracted from the metadynamics trajectory, where $s(\\mathbf{x}^{\\ast}) \\approx s^{\\ast}$.\n- An unbiased Molecular Dynamics (MD) simulation is started from $\\mathbf{x}^{\\ast}$ under the same conditions (temperature $T$, Hamiltonian, thermostat, integrator).\n- In the unbiased MD, the system rapidly leaves the region near $s^{\\ast}$ and does not return.\n- The thermodynamic definition of the free energy profile is $F(s)=-k_{\\mathrm{B}}T\\ln P(s)+C$.\n- The scaling of a transition rate $k$ along a relevant reaction coordinate is given as $k\\propto \\exp(-\\beta \\Delta F^{\\ddagger})$, where $\\beta=1/(k_{\\mathrm{B}}T)$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem describes a common and realistic scenario encountered in computational studies employing enhanced sampling techniques like metadynamics.\n\n- **Scientifically Grounded:** The concepts presented—metadynamics, collective variables, free energy surface, unbiased MD, and transition rates—are standard and fundamental in computational chemistry and statistical mechanics. The scenario described is not only plausible but serves as a textbook example of a major pitfall in applying such methods. The principles are correctly stated.\n- **Well-Posed:** The problem is structured as a thought experiment or an interpretation of computational results. It asks for the most justified implication among a set of choices, which requires reasoning based on the provided information. A logical conclusion can be drawn.\n- **Objective:** The language is technical and objective. The description of the simulation results (\"deep minimum,\" \"rapidly leaves\") is clear in its intended physical meaning within the context of molecular simulation.\n\n### Step 3: Verdict and Action\nThe problem statement is valid. It is scientifically sound, well-posed, and objective. It poses a standard question about the interpretation of metadynamics results. I will proceed with the full analysis and solution.\n\n***\n\nThe core of the problem lies in the apparent contradiction between the results of two simulations:\n1.  **Metadynamics:** The reconstructed free energy surface, $F(s)$, shows a deep minimum at $s = s^{\\ast}$. According to the relation $F(s) = -k_{\\mathrm{B}}T\\ln P(s) + C$, a deep minimum in free energy corresponds to a high equilibrium probability density $P(s^{\\ast})$. This suggests that the state corresponding to $s=s^{\\ast}$ is thermodynamically stable. Furthermore, if $s$ were the true reaction coordinate, a deep well would imply high barriers separating it from other states, leading to a long lifetime for the state at $s^{\\ast}$.\n2.  **Unbiased MD:** A simulation started at a configuration $\\mathbf{x}^{\\ast}$ (where $s(\\mathbf{x}^{\\ast}) \\approx s^{\\ast}$) shows the system is kinetically unstable. It \"rapidly leaves\" the vicinity of $s^{\\ast}$, indicating a short lifetime for this state. This contradicts the conclusion of stability inferred from $F(s)$.\n\nThe task is to find the most justified reason for this discrepancy.\n\n### Option-by-Option Analysis\n\n**A. The deep minimum in $F(s)$ necessarily implies a large exit barrier, so the rapid escape in unbiased MD must be due to numerical integration errors; the metadynamics free energy is otherwise correct.**\n\nThis statement is flawed. The free energy profile $F(s)$ is a projection of the full-dimensional potential energy surface onto the one-dimensional coordinate $s$. A deep minimum in $F(s)$ implies a large exit barrier *only along the coordinate $s$*. It provides no information about the stability of the system with respect to motions in degrees of freedom orthogonal to $s$. The configuration $\\mathbf{x}^{\\ast}$ can be located in a deep well with respect to $s$ while simultaneously being on a maximum or a steep downhill slope with respect to other, \"hidden\" coordinates not captured by $s$. The observation of a rapid escape in an unbiased simulation, which propagates the system in the full-dimensional space, is strong physical evidence of kinetic instability. Attributing this to \"numerical integration errors\" without any basis is poor scientific reasoning. The unbiased MD result is a crucial piece of data that invalidates the naive interpretation of $F(s)$, it is not an error.\n\nVerdict: **Incorrect**.\n\n**B. The chosen CV $s(\\mathbf{x})$ is insufficient to parameterize the slow dynamics; the apparent deep minimum in $F(s)$ is an artifact of projecting onto $s$, and the configuration at $s^{\\ast}$ is unstable along orthogonal degrees of freedom not captured by $s$.**\n\nThis is the most accurate and fundamental explanation. The free energy $F(s)$ is obtained by integrating over all degrees of freedom $\\mathbf{x}$ compatible with a given value of $s$:\n$$ P(s) = \\int d\\mathbf{x} \\, \\delta(s(\\mathbf{x}) - s) P(\\mathbf{x}) \\propto \\int d\\mathbf{x} \\, \\delta(s(\\mathbf{x}) - s) e^{-\\beta U(\\mathbf{x})} $$\nA low value of $F(s)$ means that the ensemble of configurations with $s(\\mathbf{x})=s$ has a high total statistical weight. However, this ensemble may contain sub-regions of high energy (unstable configurations) and low energy (stable configurations). If the metadynamics simulation pushes the system into a high-energy region that happens to project onto $s=s^{\\ast}$, the reconstructed $F(s)$ might still show a minimum there due to entropic effects or averaging over other, more stable regions that were also sampled at $s=s^{\\ast}$. When a specific configuration $\\mathbf{x}^{\\ast}$ is extracted from this high-energy region and used to start an unbiased MD, the system will naturally and rapidly evolve \"downhill\" along the unstable degrees of freedom orthogonal to $s$. This is a classic symptom of a poorly chosen collective variable that does not capture all relevant slow motions of the system. The apparent stability in the $1$D projection is an artifact.\n\nVerdict: **Correct**.\n\n**C. The discrepancy arises because the unbiased MD temperature $T$ differs from that used in metadynamics; therefore no inference about the metadynamics quality can be made.**\n\nThe problem statement explicitly specifies that the unbiased MD was run \"at the **same temperature T** and with the **same Hamiltonian**\". This option introduces a premise that is directly contradicted by the given information. Therefore, it cannot be the correct explanation.\n\nVerdict: **Incorrect**.\n\n**D. The Gaussian hills in metadynamics were too small, so the minimum at $s^{\\ast}$ is even deeper in reality; the fast escape in unbiased MD is a rare fluctuation and supports convergence of the metadynamics run.**\n\nThis statement contains multiple logical errors. First, the size of the Gaussian hills affects the convergence rate and can introduce errors, but it does not have a simple, direct relationship where small hills guarantee the true minimum is deeper. Incompletely filled wells can appear artificially deep. Second, and more critically, a \"rapid\" escape is, by definition, not a \"rare fluctuation\". A rare event, such as crossing a high energy barrier, would be observed only after a long simulation time. A rapid event implies a low or non-existent barrier, indicating kinetic instability. Therefore, the fast escape directly contradicts the notion that the system is in a stable, deep minimum and thus fundamentally challenges the convergence and utility of the metadynamics run with this CV.\n\nVerdict: **Incorrect**.",
            "answer": "$$\\boxed{B}$$"
        },
        {
            "introduction": "After designing a metadynamics simulation and obtaining a free energy surface, a critical question remains: was the chosen CV a good reaction coordinate? This advanced practice introduces the theoretical \"gold standard\" for answering this question: committor analysis. You will implement a quantitative test to validate a CV by examining the distribution of committor probabilities, $p_B$, on the putative transition state surface defined by the CV . This procedure operationalizes a key theoretical concept, providing a rigorous method to assess whether the CV successfully captures the essential dynamics of the transition.",
            "id": "3852371",
            "problem": "You are given the task of assessing whether a path collective variable $s_{\\text{path}}$ used in metadynamics provides an adequate reaction coordinate for a biomolecular transition from a reactant basin $\\mathcal{A}$ to a product basin $\\mathcal{B}$. The assessment must be done by analyzing the committor probability distribution at fixed $s_{\\text{path}}$ in the transition region. The committor probability $p_{\\mathcal{B}}$ for a configuration $x$ is defined as the probability that a trajectory initiated from $x$ reaches $\\mathcal{B}$ before reaching $\\mathcal{A}$, under the underlying stochastic dynamics or deterministic dynamics with randomized momenta. You must test for near-uniformity in the local neighborhood around $p_{\\mathcal{B}} \\approx 0.5$ at the transition region to check whether $s_{\\text{path}}$ is free of spurious bias, with the specific procedure and criteria defined below.\n\nFundamental definitions:\n- The committor probability $p_{\\mathcal{B}}(x)$ is the hitting probability of $\\mathcal{B}$ before $\\mathcal{A}$ when starting at $x$, and satisfies $p_{\\mathcal{B}}(x) \\in [0,1]$.\n- A collective variable (CV) $s_{\\text{path}}$ is a scalar mapping $s_{\\text{path}}: \\Omega \\rightarrow \\mathbb{R}$ from configuration space $\\Omega$ to a progress parameter along a predefined path that connects $\\mathcal{A}$ and $\\mathcal{B}$.\n- At the transition region corresponding to the putative dividing surface in $s_{\\text{path}}$, a theoretically adequate reaction coordinate should ensure $p_{\\mathcal{B}} \\approx 0.5$ with no systematic skew. We operationalize this by testing local uniformity of the $p_{\\mathcal{B}}$ histogram within a small window around $0.5$ and checking the mean proximity to $0.5$.\n\nAlgorithmic specification:\n- For a given set of committor samples $\\{p_i\\}_{i=1}^n$ collected at fixed $s_{\\text{path}}$ in the transition region, define a window $[w_\\ell,w_u]$ intended to capture the local neighborhood of $p_{\\mathcal{B}} \\approx 0.5$. Only samples satisfying $w_\\ell \\le p_i \\le w_u$ are analyzed.\n- Partition $[w_\\ell,w_u]$ into $k$ equal-width bins, and compute observed counts $\\{O_j\\}_{j=1}^k$ in each bin.\n- Under the null hypothesis of local uniformity, the expected counts are $E_j = n_w/k$, where $n_w$ is the number of samples in the window.\n- Compute the Pearson chi-square statistic\n$$\n\\chi^2 = \\sum_{j=1}^k \\frac{(O_j - E_j)^2}{E_j}\n$$\nand the corresponding $p$-value from the chi-square distribution with $k-1$ degrees of freedom. Uniformity is not rejected if the $p$-value is greater than or equal to a significance level $\\alpha$.\n- Compute the sample mean in the window,\n$$\n\\bar{p} = \\frac{1}{n_w}\\sum_{i=1}^{n_w} p_i,\n$$\nand check the mean proximity criterion $\\lvert \\bar{p} - 0.5\\rvert \\le \\varepsilon$.\n\nDecision rule:\n- The reaction coordinate based on $s_{\\text{path}}$ passes the validation for the given sample set if and only if both conditions hold: the chi-square test does not reject local uniformity in $[w_\\ell,w_u]$ at level $\\alpha$, and the mean proximity criterion $\\lvert \\bar{p} - 0.5\\rvert \\le \\varepsilon$ is satisfied.\n\nYour program must implement the above procedure for the following test suite. For each test case, generate $\\{p_i\\}_{i=1}^n$ deterministically as specified. Use angle-free and unit-free numbers as dimensionless probabilities $p_i \\in [0,1]$. No external inputs are permitted. The parameters are:\n\n- Test case $1$ (happy path, locally uniform with mean near $0.5$):\n    - $n = 100$, $[w_\\ell,w_u] = [0.4, 0.6]$, $k = 10$, $\\alpha = 0.05$, $\\varepsilon = 0.02$.\n    - Define the bin width $\\Delta = (w_u - w_\\ell)/k$ and the bin centers $c_j = w_\\ell + (j + 0.5)\\Delta$ for $j \\in \\{0,\\dots,k-1\\}$.\n    - Construct $\\{p_i\\}$ by repeating each center $c_j$ exactly $m = 10$ times so that $n = k \\times m$ and each bin contains $m$ samples.\n\n- Test case $2$ (narrow peak near $0.5$, violating local uniformity but mean near $0.5$):\n    - $n = 100$, $[w_\\ell,w_u] = [0.4, 0.6]$, $k = 10$, $\\alpha = 0.05$, $\\varepsilon = 0.02$.\n    - Define $p_i = 0.5 + 0.01 \\cos\\!\\left(\\frac{2\\pi i}{n}\\right)$ for $i \\in \\{0,\\dots,n-1\\}$.\n\n- Test case $3$ (skewed distribution with mean offset from $0.5$):\n    - $n = 100$, $[w_\\ell,w_u] = [0.4, 0.6]$, $k = 10$, $\\alpha = 0.05$, $\\varepsilon = 0.02$.\n    - Define $p_i = w_\\ell + \\left(\\frac{i}{n-1}\\right)^2 (w_u - w_\\ell)$ for $i \\in \\{0,\\dots,n-1\\}$.\n\n- Test case $4$ (boundary condition with small sample size, locally uniform by construction):\n    - $n = 20$, $[w_\\ell,w_u] = [0.4, 0.6]$, $k = 5$, $\\alpha = 0.05$, $\\varepsilon = 0.02$.\n    - Define the bin width $\\Delta = (w_u - w_\\ell)/k$ and the bin centers $c_j = w_\\ell + (j + 0.5)\\Delta$ for $j \\in \\{0,\\dots,k-1\\}$.\n    - Construct $\\{p_i\\}$ by repeating each center $c_j$ exactly $m = 4$ times so that $n = k \\times m$ and each bin contains $m$ samples.\n\nOutput format:\n- For each test case, output a boolean indicating whether $s_{\\text{path}}$ passes the validation according to the decision rule defined above.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example, $\\texttt{[result1,result2,result3,result4]}$, where each $\\texttt{result}$ is either $\\texttt{True}$ or $\\texttt{False}$.\n\nAll computations must be performed exactly as specified, with no randomness. The final output must be deterministic.",
            "solution": "The problem statement has been evaluated and is determined to be valid. It is scientifically grounded in the principles of computational chemical biology, specifically in the use of committor probabilities for the validation of reaction coordinates. The problem is well-posed, with all parameters, data generation procedures, and assessment criteria specified unambiguously, ensuring a unique and deterministic solution. It is free of contradictions, vagueness, and factual errors.\n\nThe central task is to develop a computational procedure to assess whether a path collective variable, $s_{\\text{path}}$, serves as an adequate reaction coordinate for a transition between two states, $\\mathcal{A}$ and $\\mathcal{B}$. The theoretical foundation for this assessment lies in committor probability analysis. The committor probability, $p_{\\mathcal{B}}(x)$, is defined as the probability that a trajectory initiated from a configuration $x$ in the system's state space will commit to the product basin $\\mathcal{B}$ before the reactant basin $\\mathcal{A}$. The committor $p_{\\mathcal{B}}$ is, by definition, the ideal reaction coordinate. A value of $p_{\\mathcal{B}}(x) = 0$ signifies that configuration $x$ is in basin $\\mathcal{A}$, $p_{\\mathcal{B}}(x) = 1$ signifies it is in basin $\\mathcal{B}$, and $p_{\\mathcalB}(x) = 0.5$ defines the transition state surface, a dividing surface that perfectly separates reactants from products.\n\nA good, albeit approximate, collective variable $s_{\\text{path}}$ should be monotonically related to the true committor $p_{\\mathcal{B}}$. Consequently, a surface of constant $s_{\\text{path}}$ in the transition region should approximate the true transition state surface where $p_{\\mathcal{B}} \\approx 0.5$. The problem mandates a two-part test on a set of committor samples $\\{p_i\\}_{i=1}^n$ collected at a fixed value of $s_{\\text{path}}$ corresponding to the putative transition region.\n\nThe validation procedure is as follows:\n\n1.  **Data Filtering**: From the initial sample set $\\{p_i\\}_{i=1}^n$, we consider only the subset of $n_w$ samples that fall within a specified window $[w_\\ell, w_u]$ centered around $0.5$. This focuses the analysis on the local behavior at the transition state.\n\n2.  **Uniformity Test**: The first criterion assesses whether the committor probabilities are uniformly distributed within this window. A non-uniform distribution, such as one sharply peaked at $p_{\\mathcal{B}}=0.5$, would indicate that $s_{\\text{path}}$ is correlated with other, unobserved degrees of freedom that also influence the committor. This implies $s_{\\text{path}}$ alone is insufficient to describe the transition. We employ a Pearson's chi-square ($\\chi^2$) goodness-of-fit test.\n    - The window $[w_\\ell, w_u]$ is partitioned into $k$ equal-width bins.\n    - The number of observed samples, $O_j$, is counted for each bin $j \\in \\{1, \\dots, k\\}$.\n    - Under the null hypothesis $H_0$ of a uniform distribution, the expected count in each bin is $E_j = n_w/k$.\n    - The chi-square statistic is calculated as:\n    $$\n    \\chi^2 = \\sum_{j=1}^k \\frac{(O_j - E_j)^2}{E_j}\n    $$\n    - This statistic is compared to a $\\chi^2$ distribution with $\\nu = k-1$ degrees of freedom to obtain a $p$-value. A $p$-value less than a chosen significance level $\\alpha$ leads to the rejection of $H_0$. The validation condition is $p\\text{-value} \\ge \\alpha$. It is noteworthy that the validity of the $\\chi^2$ test is generally predicated on the condition that expected counts $E_j$ are not too small (e.g., $E_j \\ge 5$). While this may not hold for all test cases, the problem mandates the execution of the test regardless, and we shall comply.\n\n3.  **Mean Proximity Test**: The second criterion ensures that the average value of the committor on the tested surface is indeed close to the ideal transition state value of $0.5$. A significant deviation would indicate a systematic bias, meaning the chosen $s_{\\textpath}$ value does not correspond to the true $50/50$ dividing surface.\n    -   The sample mean of the windowed data, $\\bar{p}$, is calculated:\n    $$\n    \\bar{p} = \\frac{1}{n_w}\\sum_{i=1}^{n_w} p_i\n    $$\n    -   This mean must satisfy the proximity criterion $|\\bar{p} - 0.5| \\le \\varepsilon$ for a given tolerance $\\varepsilon$.\n\n4.  **Decision**: The collective variable $s_{\\text{path}}$ is deemed to pass the validation for the given sample set if and only if both the uniformity test and the mean proximity test are passed.\n\nThis combined procedure provides a rigorous, quantitative framework for evaluating the quality of a proposed reaction coordinate, which will be implemented for the four specified test cases.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef validate_rc(p_samples, wl, wu, k, alpha, epsilon):\n    \"\"\"\n    Assesses a reaction coordinate based on a set of committor samples.\n\n    This function performs a two-part test: a chi-square test for local\n    uniformity of committor probabilities and a check for mean proximity to 0.5.\n\n    Args:\n        p_samples (np.ndarray): The array of committor probability samples.\n        wl (float): The lower bound of the analysis window.\n        wu (float): The upper bound of the analysis window.\n        k (int): The number of bins for the uniformity test.\n        alpha (float): The significance level for the chi-square test.\n        epsilon (float): The tolerance for the mean proximity test.\n\n    Returns:\n        bool: True if the reaction coordinate passes validation, False otherwise.\n    \"\"\"\n    # Step 1: Filter samples to lie within the window [wl, wu].\n    p_in_window = p_samples[(p_samples >= wl) & (p_samples <= wu)]\n    n_w = len(p_in_window)\n\n    # If no samples are in the window, the tests cannot be performed.\n    # The problem specification guarantees n_w > 0 for all test cases.\n    if n_w == 0:\n        return False\n\n    # Condition 1: Chi-square test for local uniformity.\n    uniformity_passes = False\n    \n    # The chi-square test is not well-defined for k <= 1. The problem uses k > 1.\n    if k > 1:\n        # Bin the data within the window. `np.histogram` handles edges appropriately\n        # for this problem, including the right aclosed last bin.\n        bin_edges = np.linspace(wl, wu, k + 1)\n        observed_counts, _ = np.histogram(p_in_window, bins=bin_edges)\n        \n        # Calculate expected counts under the null hypothesis of uniformity.\n        expected_counts = n_w / k\n\n        # The chi-square test is ill-defined if expected_counts is zero.\n        # This only happens if n_w is zero, which is handled above.\n        if expected_counts > 0:\n            chi_sq_statistic = np.sum((observed_counts - expected_counts)**2 / expected_counts)\n            \n            # Degrees of freedom for the chi-square distribution.\n            df = k - 1\n            \n            # The p-value is the probability of observing a test statistic at least\n            # as extreme as the one computed, assuming the null hypothesis is true.\n            # We use the survival function (1 - CDF) for this right-tailed test.\n            p_value = chi2.sf(chi_sq_statistic, df)\n            \n            if p_value >= alpha:\n                uniformity_passes = True\n\n    # Condition 2: Mean proximity to 0.5.\n    mean_p = np.mean(p_in_window)\n    mean_proximity_passes = np.abs(mean_p - 0.5) <= epsilon\n\n    # Final decision: both conditions must be met.\n    return uniformity_passes and mean_proximity_passes\n\ndef solve():\n    \"\"\"\n    Generates data for the four test cases as specified in the problem\n    and runs the validation procedure for each.\n    \"\"\"\n    test_cases_params = [\n        {'n': 100, 'wl': 0.4, 'wu': 0.6, 'k': 10, 'alpha': 0.05, 'epsilon': 0.02, 'id': 1},\n        {'n': 100, 'wl': 0.4, 'wu': 0.6, 'k': 10, 'alpha': 0.05, 'epsilon': 0.02, 'id': 2},\n        {'n': 100, 'wl': 0.4, 'wu': 0.6, 'k': 10, 'alpha': 0.05, 'epsilon': 0.02, 'id': 3},\n        {'n': 20, 'wl': 0.4, 'wu': 0.6, 'k': 5, 'alpha': 0.05, 'epsilon': 0.02, 'id': 4},\n    ]\n    \n    results = []\n    \n    for params in test_cases_params:\n        n, wl, wu, k = params['n'], params['wl'], params['wu'], params['k']\n        \n        p_samples = np.array([])\n        if params['id'] == 1:\n            m = 10\n            delta = (wu - wl) / k\n            centers = wl + (np.arange(k) + 0.5) * delta\n            p_samples = np.repeat(centers, m)\n        elif params['id'] == 2:\n            i_vals = np.arange(n)\n            p_samples = 0.5 + 0.01 * np.cos(2 * np.pi * i_vals / n)\n        elif params['id'] == 3:\n            i_vals = np.arange(n)\n            p_samples = wl + (i_vals / (n - 1))**2 * (wu - wl)\n        elif params['id'] == 4:\n            m = 4\n            delta = (wu - wl) / k\n            centers = wl + (np.arange(k) + 0.5) * delta\n            p_samples = np.repeat(centers, m)\n\n        result = validate_rc(p_samples, wl, wu, k, params['alpha'], params['epsilon'])\n        results.append(result)\n\n    # The final print statement must match the required format exactly.\n    print(f\"[{','.join(map(str, results))}]\")\n\n# To be run as a self-contained script.\nsolve()\n```"
        }
    ]
}