{
    "hands_on_practices": [
        {
            "introduction": "The Ewald summation method is built upon a mathematical partition of the Coulomb potential using a splitting parameter, $\\alpha$, which has no direct physical meaning. A fundamental requirement for the method's validity is that the final calculated energy must be independent of this arbitrary choice. This practice guides you through a formal proof of this invariance, a classic exercise that solidifies one's understanding of the Ewald framework . By differentiating each component of the Ewald energy, you will see precisely how the dependencies on $\\alpha$ in the real-space, reciprocal-space, and self-energy terms are constructed to cancel one another perfectly.",
            "id": "3851277",
            "problem": "Consider a system of $N$ point charges $\\{q_{i}\\}_{i=1}^{N}$ at positions $\\{\\mathbf{r}_{i}\\}_{i=1}^{N}$ in a cubic periodic box of side length $L$ and volume $V=L^{3}$, with overall charge neutrality $\\sum_{i=1}^{N} q_{i} = 0$. The electrostatic interaction is evaluated under periodic boundary conditions using the Ewald splitting with a Gaussian screening parameter $\\alpha>0$. The total electrostatic energy $U(\\alpha)$ is composed of a real-space term $U_{\\mathrm{r}}(\\alpha)$, a reciprocal-space term $U_{\\mathrm{k}}(\\alpha)$, a self-energy term $U_{\\mathrm{self}}(\\alpha)$, and, depending on the boundary condition at infinity, a surface term $U_{\\mathrm{surf}}$. For a conducting (tin-foil) boundary condition, $U_{\\mathrm{surf}}$ is zero and has no dependence on $\\alpha$. Assume the Coulomb prefactor is unity to focus on the $\\alpha$-scaling. Define the real-space contribution using the Ewald-split pair potential\n$$\n\\phi_{\\mathrm{r}}(r;\\alpha) = \\frac{\\operatorname{erfc}(\\alpha r)}{r},\n$$\nwhere $\\operatorname{erfc}$ is the complementary error function, and let the reciprocal-space contribution be defined through the Fourier-space representation with reciprocal lattice vectors $\\mathbf{k} = \\frac{2\\pi}{L} \\mathbf{m}$, $\\mathbf{m}\\in\\mathbb{Z}^{3}$, and the structure factor $S(\\mathbf{k}) = \\sum_{j=1}^{N} q_{j} \\exp(-i \\mathbf{k}\\cdot \\mathbf{r}_{j})$. The Particle Mesh Ewald (PME) method evaluates $U_{\\mathrm{k}}(\\alpha)$ numerically through charge assignment and a mesh-based Fast Fourier Transform, but the exact Ewald sum corresponds to the formal reciprocal-space series over nonzero $\\mathbf{k}$.\n\nStarting from the above definitions and using only fundamental properties of Gaussians and the Poisson summation formula, analyze the $\\alpha$-scaling of each contribution and compute the exact derivative $\\frac{\\partial U(\\alpha)}{\\partial \\alpha}$ for the neutral system under conducting boundary conditions. You must explicitly account for the self-energy and surface terms in your analysis and justify any cancellation of $\\alpha$-dependences that you claim. Express your final answer as a single real number. No units are required. No rounding is required.",
            "solution": "The task is to compute the derivative of the total Ewald electrostatic energy $U(\\alpha)$ with respect to the Gaussian screening parameter $\\alpha$. The total energy in Ewald summation is constructed to be independent of $\\alpha$. Therefore, its derivative with respect to $\\alpha$ must be zero. The problem requires a formal proof of this result by analyzing the $\\alpha$-dependence of each term in the Ewald energy expression for a specific case.\n\nThe total electrostatic energy $U(\\alpha)$ for a system of $N$ point charges $\\{q_i\\}$ at positions $\\{\\mathbf{r}_i\\}$ in a cubic box of volume $V=L^3$ under periodic boundary conditions, with overall charge neutrality ($\\sum_i q_i = 0$) and conducting boundary conditions at infinity, is given by the sum of four terms:\n$$\nU(\\alpha) = U_{\\mathrm{r}}(\\alpha) + U_{\\mathrm{k}}(\\alpha) + U_{\\mathrm{self}}(\\alpha) + U_{\\mathrm{surf}}\n$$\n\nThe problem specifies that the Coulomb prefactor is unity (i.e., $1/(4\\pi\\epsilon_0) = 1$) and that for conducting boundary conditions, $U_{\\mathrm{surf}} = 0$. The other three terms are given by the standard Ewald formulas, consistent with the provided real-space potential.\n\n1.  **Real-space term ($U_{\\mathrm{r}}$):** This term sums the short-range screened interactions between all pairs of charges and their periodic images. The prime on the summation indicates exclusion of the $i=j$ self-interaction term within the primary cell ($\\mathbf{n}=0$).\n    $$\n    U_{\\mathrm{r}}(\\alpha) = \\frac{1}{2} \\sum_{i,j=1}^{N} \\sum_{\\mathbf{n}\\in\\mathbb{Z}^3}{'} q_i q_j \\frac{\\operatorname{erfc}(\\alpha |\\mathbf{r}_{ij} + L\\mathbf{n}|)}{|\\mathbf{r}_{ij} + L\\mathbf{n}|}\n    $$\n    where $\\mathbf{r}_{ij} = \\mathbf{r}_i - \\mathbf{r}_j$ and $\\operatorname{erfc}(x)$ is the complementary error function.\n\n2.  **Reciprocal-space term ($U_{\\mathrm{k}}$):** This term accounts for the long-range part of the interaction via a sum in Fourier space over reciprocal lattice vectors $\\mathbf{k} = \\frac{2\\pi}{L}\\mathbf{m}$ with $\\mathbf{m} \\in \\mathbb{Z}^3$. The $\\mathbf{k}=\\mathbf{0}$ term is excluded.\n    $$\n    U_{\\mathrm{k}}(\\alpha) = \\frac{2\\pi}{V} \\sum_{\\mathbf{k}\\neq \\mathbf{0}} \\frac{|S(\\mathbf{k})|^2}{k^2} \\exp\\left(-\\frac{k^2}{4\\alpha^2}\\right)\n    $$\n    where $S(\\mathbf{k}) = \\sum_{j=1}^{N} q_j \\exp(-i\\mathbf{k}\\cdot\\mathbf{r}_j)$ is the structure factor. The prefactor $2\\pi/V$ is consistent with setting $1/(4\\pi\\epsilon_0)=1$.\n\n3.  **Self-energy term ($U_{\\mathrm{self}}$):** This term subtracts the artificial interaction of each charge with its own screening Gaussian charge cloud.\n    $$\n    U_{\\mathrm{self}}(\\alpha) = -\\frac{\\alpha}{\\sqrt{\\pi}} \\sum_{i=1}^{N} q_i^2\n    $$\n\nWe will now compute the derivative of each term with respect to $\\alpha$.\n\n**Derivative of the real-space term $\\frac{\\partial U_{\\mathrm{r}}}{\\partial \\alpha}$:**\nWe first need the derivative of the screening function. Using the chain rule and the identity $\\frac{d}{dx}\\operatorname{erfc}(x) = -\\frac{2}{\\sqrt{\\pi}}\\exp(-x^2)$, we have:\n$$\n\\frac{\\partial}{\\partial \\alpha} \\left( \\frac{\\operatorname{erfc}(\\alpha r)}{r} \\right) = \\frac{1}{r} \\left( \\frac{\\partial}{\\partial \\alpha} \\operatorname{erfc}(\\alpha r) \\right) = \\frac{1}{r} \\left( -\\frac{2}{\\sqrt{\\pi}}\\exp(-(\\alpha r)^2) \\cdot r \\right) = -\\frac{2}{\\sqrt{\\pi}}\\exp(-\\alpha^2 r^2)\n$$\nApplying this to $U_{\\mathrm{r}}(\\alpha)$, we get:\n$$\n\\frac{\\partial U_{\\mathrm{r}}}{\\partial \\alpha} = \\frac{1}{2} \\sum_{i,j,\\mathbf{n}}{'} q_i q_j \\left( -\\frac{2}{\\sqrt{\\pi}}\\exp(-\\alpha^2 |\\mathbf{r}_{ij} + L\\mathbf{n}|^2) \\right) = -\\frac{1}{\\sqrt{\\pi}} \\sum_{i,j,\\mathbf{n}}{'} q_i q_j \\exp(-\\alpha^2 |\\mathbf{r}_{ij} + L\\mathbf{n}|^2)\n$$\nThe primed sum $\\sum'$ is over all pairs $(i,j)$ and lattice vectors $\\mathbf{n}$, excluding the case where $i=j$ and $\\mathbf{n}=\\mathbf{0}$ simultaneously. We can rewrite this by taking the full sum and subtracting the excluded term:\n$$\n\\sum_{i,j,\\mathbf{n}}{'} (\\dots) = \\sum_{i,j,\\mathbf{n}} (\\dots) - \\sum_{i=1}^N \\left( q_i^2 \\exp(-\\alpha^2 |\\mathbf{r}_{ii} + L\\mathbf{0}|^2) \\right) = \\sum_{i,j,\\mathbf{n}} (\\dots) - \\sum_{i=1}^N q_i^2\n$$\nSo, the derivative of the real-space term is:\n$$\n\\frac{\\partial U_{\\mathrm{r}}}{\\partial \\alpha} = -\\frac{1}{\\sqrt{\\pi}} \\left( \\sum_{i,j,\\mathbf{n}} q_i q_j \\exp(-\\alpha^2 |\\mathbf{r}_{ij} + L\\mathbf{n}|^2) \\right) + \\frac{1}{\\sqrt{\\pi}} \\sum_{i=1}^{N} q_i^2\n$$\n\n**Derivative of the reciprocal-space term $\\frac{\\partial U_{\\mathrm{k}}}{\\partial \\alpha}$:**\nWe differentiate the exponential term with respect to $\\alpha$:\n$$\n\\frac{\\partial}{\\partial \\alpha} \\exp\\left(-\\frac{k^2}{4\\alpha^2}\\right) = \\exp\\left(-\\frac{k^2}{4\\alpha^2}\\right) \\cdot \\left( -\\frac{k^2}{4} \\right) \\cdot \\left( -2\\alpha^{-3} \\right) = \\frac{k^2}{2\\alpha^3} \\exp\\left(-\\frac{k^2}{4\\alpha^2}\\right)\n$$\nSubstituting this into the expression for $U_{\\mathrm{k}}(\\alpha)$:\n$$\n\\frac{\\partial U_{\\mathrm{k}}}{\\partial \\alpha} = \\frac{2\\pi}{V} \\sum_{\\mathbf{k}\\neq \\mathbf{0}} \\frac{|S(\\mathbf{k})|^2}{k^2} \\left[ \\frac{k^2}{2\\alpha^3} \\exp\\left(-\\frac{k^2}{4\\alpha^2}\\right) \\right] = \\frac{\\pi}{V\\alpha^3} \\sum_{\\mathbf{k}\\neq \\mathbf{0}} |S(\\mathbf{k})|^2 \\exp\\left(-\\frac{k^2}{4\\alpha^2}\\right)\n$$\n\n**Derivative of the self-energy term $\\frac{\\partial U_{\\mathrm{self}}}{\\partial \\alpha}$:**\nThis derivative is straightforward:\n$$\n\\frac{\\partial U_{\\mathrm{self}}}{\\partial \\alpha} = \\frac{\\partial}{\\partial \\alpha} \\left( -\\frac{\\alpha}{\\sqrt{\\pi}} \\sum_{i=1}^{N} q_i^2 \\right) = -\\frac{1}{\\sqrt{\\pi}} \\sum_{i=1}^{N} q_i^2\n$$\n\n**Total Derivative $\\frac{\\partial U}{\\partial \\alpha}$:**\nNow, we sum the derivatives of all components. The derivative of $U_{\\mathrm{surf}}$ is $0$.\n$$\n\\frac{\\partial U}{\\partial \\alpha} = \\frac{\\partial U_{\\mathrm{r}}}{\\partial \\alpha} + \\frac{\\partial U_{\\mathrm{k}}}{\\partial \\alpha} + \\frac{\\partial U_{\\mathrm{self}}}{\\partial \\alpha}\n$$\n$$\n\\frac{\\partial U}{\\partial \\alpha} = \\left[ -\\frac{1}{\\sqrt{\\pi}} \\sum_{i,j,\\mathbf{n}} q_i q_j e^{-\\alpha^2 |\\mathbf{r}_{ij} + L\\mathbf{n}|^2} + \\frac{1}{\\sqrt{\\pi}} \\sum_i q_i^2 \\right] + \\left[ \\frac{\\pi}{V\\alpha^3} \\sum_{\\mathbf{k}\\neq\\mathbf{0}} |S(\\mathbf{k})|^2 e^{-\\frac{k^2}{4\\alpha^2}} \\right] + \\left[ -\\frac{1}{\\sqrt{\\pi}} \\sum_i q_i^2 \\right]\n$$\nThe self-energy derivative cancels exactly with the second part of the real-space derivative:\n$$\n\\frac{\\partial U}{\\partial \\alpha} = -\\frac{1}{\\sqrt{\\pi}} \\sum_{i,j,\\mathbf{n}} q_i q_j e^{-\\alpha^2 |\\mathbf{r}_{ij} + L\\mathbf{n}|^2} + \\frac{\\pi}{V\\alpha^3} \\sum_{\\mathbf{k}\\neq\\mathbf{0}} |S(\\mathbf{k})|^2 e^{-\\frac{k^2}{4\\alpha^2}}\n$$\nTo show that the remaining sum is zero, we use the Poisson summation formula, which connects a sum over a real-space lattice to a sum over the corresponding reciprocal-space lattice. The relevant identity for a Gaussian function is:\n$$\n\\sum_{\\mathbf{n}\\in\\mathbb{Z}^3} \\exp(-a |\\mathbf{x} + L\\mathbf{n}|^2) = \\frac{1}{L^3} \\left(\\frac{\\pi}{a}\\right)^{3/2} \\sum_{\\mathbf{k}} \\exp\\left(-\\frac{k^2}{4a}\\right) \\exp(i\\mathbf{k}\\cdot\\mathbf{x})\n$$\nWe apply this to the first term, letting $a = \\alpha^2$, $\\mathbf{x} = \\mathbf{r}_{ij} = \\mathbf{r}_i - \\mathbf{r}_j$, and $V=L^3$:\n$$\n\\sum_{\\mathbf{n}} \\exp(-\\alpha^2 |\\mathbf{r}_{ij} + L\\mathbf{n}|^2) = \\frac{\\pi^{3/2}}{V\\alpha^3} \\sum_{\\mathbf{k}} \\exp\\left(-\\frac{k^2}{4\\alpha^2}\\right) \\exp(i\\mathbf{k}\\cdot\\mathbf{r}_{ij})\n$$\nSubstituting this back into the first term of $\\frac{\\partial U}{\\partial \\alpha}$:\n$$\n-\\frac{1}{\\sqrt{\\pi}} \\sum_{i,j} q_i q_j \\left[ \\frac{\\pi^{3/2}}{V\\alpha^3} \\sum_{\\mathbf{k}} e^{-\\frac{k^2}{4\\alpha^2}} e^{i\\mathbf{k}\\cdot(\\mathbf{r}_i - \\mathbf{r}_j)} \\right] = -\\frac{\\pi}{V\\alpha^3} \\sum_{\\mathbf{k}} e^{-\\frac{k^2}{4\\alpha^2}} \\sum_{i,j} q_i q_j e^{i\\mathbf{k}\\cdot\\mathbf{r}_i} e^{-i\\mathbf{k}\\cdot\\mathbf{r}_j}\n$$\nThe double sum over $i,j$ can be factorized:\n$$\n\\sum_{i,j} q_i q_j e^{i\\mathbf{k}\\cdot\\mathbf{r}_i} e^{-i\\mathbf{k}\\cdot\\mathbf{r}_j} = \\left(\\sum_i q_i e^{i\\mathbf{k}\\cdot\\mathbf{r}_i}\\right) \\left(\\sum_j q_j e^{-i\\mathbf{k}\\cdot\\mathbf{r}_j}\\right) = S(\\mathbf{k})^* S(\\mathbf{k}) = |S(\\mathbf{k})|^2\n$$\nHere we used $S(\\mathbf{k})^* = \\sum_j q_j^* e^{i\\mathbf{k}\\cdot\\mathbf{r}_j} = S(-\\mathbf{k})$ for real charges $q_j$. The product in the sum is $S(-\\mathbf{k})S(\\mathbf{k})$.\n\nSo the first term becomes:\n$$\n-\\frac{\\pi}{V\\alpha^3} \\sum_{\\mathbf{k}} |S(\\mathbf{k})|^2 \\exp\\left(-\\frac{k^2}{4\\alpha^2}\\right)\n$$\nNow, substitute this back into the expression for the total derivative:\n$$\n\\frac{\\partial U}{\\partial \\alpha} = -\\frac{\\pi}{V\\alpha^3} \\sum_{\\mathbf{k}} |S(\\mathbf{k})|^2 e^{-\\frac{k^2}{4\\alpha^2}} + \\frac{\\pi}{V\\alpha^3} \\sum_{\\mathbf{k}\\neq\\mathbf{0}} |S(\\mathbf{k})|^2 e^{-\\frac{k^2}{4\\alpha^2}}\n$$\nThe two sums are identical except that the first sum includes the $\\mathbf{k}=\\mathbf{0}$ term, while the second does not. Their difference is the negative of the $\\mathbf{k}=\\mathbf{0}$ term from the first sum:\n$$\n\\frac{\\partial U}{\\partial \\alpha} = -\\frac{\\pi}{V\\alpha^3} |S(\\mathbf{0})|^2 \\exp(0) = -\\frac{\\pi}{V\\alpha^3} |S(\\mathbf{0})|^2\n$$\nThe structure factor at $\\mathbf{k}=\\mathbf{0}$ is defined as $S(\\mathbf{0}) = \\sum_{j=1}^{N} q_j \\exp(-i\\mathbf{0}\\cdot\\mathbf{r}_j) = \\sum_{j=1}^{N} q_j$.\nThe problem states that the system has overall charge neutrality, so $\\sum_{j=1}^{N} q_j = 0$.\nThis implies that $S(\\mathbf{0}) = 0$.\nTherefore, the total derivative is:\n$$\n\\frac{\\partial U(\\alpha)}{\\partial \\alpha} = 0\n$$\nThis demonstrates that the total Ewald energy is independent of the arbitrary splitting parameter $\\alpha$, which is a fundamental property of the method. The final answer is the numerical value of this derivative.",
            "answer": "$$\n\\boxed{0}\n$$"
        },
        {
            "introduction": "While the total energy is independent of the Ewald splitting parameter $\\alpha$, the computational cost is highly sensitive to its value. Choosing $\\alpha$ wisely is therefore critical for efficient simulations, as it dictates the balance of work between the short-range real-space sum and the long-range reciprocal-space sum. This exercise challenges you to explore this fundamental trade-off from first principles, establishing the scaling relationships that connect $\\alpha$, the real- and reciprocal-space cutoffs, and the overall computational cost for a fixed accuracy target .",
            "id": "3851319",
            "problem": "Consider a cubic periodic simulation cell of side length $L$ containing $N$ point charges with number density $\\rho = N/L^3$. In Ewald summation, the Coulomb kernel is split by a Gaussian screening of width parameter $\\alpha$ into a short-range real-space term and a long-range reciprocal-space term. The real-space sum is truncated at a cutoff $r_c$, and the reciprocal-space sum is truncated at a maximum wavevector magnitude $k_{\\max}$ or evaluated via Particle Mesh Ewald (PME) on a mesh whose effective resolution corresponds to $k_{\\max}$. Assume a homogeneous distribution for error estimates and consider a target root-mean-square (RMS) force error tolerance $\\varepsilon$.\n\nStarting from the facts that (i) the complementary error function $\\operatorname{erfc}(x)$ decays like a Gaussian for large $x$, and (ii) the reciprocal-space Ewald kernel is damped by a Gaussian factor in $k$-space, reason from first principles to establish how $\\alpha$ controls the spatial decay of the real-space kernel and the spectral decay of the reciprocal-space kernel. Use these decays to bound the truncation errors and to deduce how $r_c$ and $k_{\\max}$ must scale with $\\alpha$ in order to maintain a fixed tolerance $\\varepsilon$. Then use these relationships to infer the qualitative scaling of computational cost with $\\alpha$ for the two parts, under the following standard cost models: real-space cost per particle scales as $\\mathcal{O}(\\rho r_c^3)$ due to neighbor counts within $r_c$, and reciprocal-space cost scales as the number of $k$-modes with $|{\\bf k}| \\le k_{\\max}$, i.e., $\\mathcal{O}(k_{\\max}^3)$ for classical Ewald or monotonically with that count for PME.\n\nWhich of the following statements are correct in light of your derivation? Select all that apply.\n\nA. For a fixed error tolerance $\\varepsilon$ and fixed density $\\rho$, decreasing $\\alpha$ forces $r_c$ to grow roughly like $\\alpha^{-1}$ to keep the real-space truncation error small, so the real-space computational cost scales up as $\\alpha^{-3}$, while the reciprocal-space mode count needed scales down as $\\alpha^{3}$ because the Gaussian damping in $k$-space becomes stronger.\n\nB. For fixed $r_c$, the real-space computational cost is independent of $\\alpha$, but the real-space truncation error increases as $\\alpha$ decreases, with a leading dependence that is approximately $\\propto \\exp(-\\alpha^2 r_c^2)$, implying that choosing $\\alpha$ too small is inadmissible for a given tolerance even if the reciprocal-space grid is refined arbitrarily.\n\nC. For fixed $r_c$, decreasing $\\alpha$ increases the reciprocal-space workload because the Gaussian damping factor in $k$-space decays more slowly, so more $k$-modes are required.\n\nD. At a fixed accuracy target $\\varepsilon$, there exists an optimal $\\alpha$ that balances real-space and reciprocal-space costs, and as $r_c$ is decreased (e.g., due to memory or neighbor-list constraints), the optimal $\\alpha$ shifts to larger values, shifting more work to reciprocal space.",
            "solution": "The problem asks for an analysis of the Ewald summation method, specifically focusing on how the Ewald parameter $\\alpha$ influences the computational cost of the real-space and reciprocal-space parts of the calculation for a fixed error tolerance $\\varepsilon$.\n\nFirst, we validate the problem statement.\n**Step 1: Extract Givens**\n- System: A cubic periodic simulation cell of side length $L$.\n- Contents: $N$ point charges with number density $\\rho = N/L^3$.\n- Method: Ewald summation, where the Coulomb kernel is split using a Gaussian screening of width parameter $\\alpha$.\n- Real-space part: Truncated at a cutoff radius $r_c$.\n- Reciprocal-space part: Truncated at a maximum wavevector magnitude $k_{\\max}$.\n- Error tolerance: A target root-mean-square (RMS) force error $\\varepsilon$.\n- Fact (i): The complementary error function $\\operatorname{erfc}(x)$ decays like a Gaussian for large $x$.\n- Fact (ii): The reciprocal-space Ewald kernel is damped by a Gaussian factor in $k$-space.\n- Cost Model (real-space): Cost per particle is $\\mathcal{O}(\\rho r_c^3)$.\n- Cost Model (reciprocal-space): Cost is $\\mathcal{O}(k_{\\max}^3)$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem statement is scientifically grounded, describing the standard Ewald summation technique used in computational chemical biology. The physical and mathematical premises are correct: the splitting of the Coulomb potential, the use of cutoffs, the asymptotic behavior of the error function, and the Gaussian damping in reciprocal space are all standard textbook concepts. The cost models are reasonable approximations for pair-list based short-range calculations and Fourier-based long-range calculations. The problem is well-posed, objective, and contains sufficient information to deduce the qualitative scaling relationships requested. It is not trivial or ill-posed.\n\n**Step 3: Verdict and Action**\nThe problem is valid. We may proceed to the solution.\n\n**Derivation from First Principles**\n\nThe Ewald summation method splits the Coulomb potential $V(r) = 1/r$ for each pair of charges into a short-range and a long-range component using the identity $1 = \\operatorname{erfc}(\\alpha r) + \\operatorname{erf}(\\alpha r)$. The parameter $\\alpha$ controls the width of the screening Gaussian charge distribution used for this split.\n\nThe potential energy is split into:\n$$ V(r) = \\underbrace{\\frac{\\operatorname{erfc}(\\alpha r)}{r}}_{\\text{Real space}} + \\underbrace{\\frac{\\operatorname{erf}(\\alpha r)}{r}}_{\\text{Reciprocal space}} $$\n\n**1. Real-Space Analysis**\nThe real-space term is $\\phi_{rs}(r) = q_i q_j \\frac{\\operatorname{erfc}(\\alpha r)}{r}$. This term decays rapidly due to the complementary error function. The force is the negative gradient of the potential. The magnitude of the force contribution is $|F_{rs}(r)| = | - \\frac{d\\phi_{rs}}{dr} | = |q_i q_j| \\left| \\frac{\\operatorname{erfc}(\\alpha r)}{r^2} + \\frac{2\\alpha}{\\sqrt{\\pi}} \\frac{e^{-\\alpha^2 r^2}}{r} \\right|$.\n\nThe real-space sum is truncated at a cutoff $r_c$. The error introduced by this truncation is dominated by the magnitude of the force term at $r=r_c$. For a sufficiently large product $\\alpha r_c$, the term involving the Gaussian $e^{-\\alpha^2 r_c^2}$ dominates the decay. A standard result for the RMS force error, $\\varepsilon_{rs}$, is that it scales approximately as:\n$$ \\varepsilon_{rs} \\propto \\frac{e^{-\\alpha^2 r_c^2}}{r_c} $$\nMore detailed analysis shows a dependence like $\\varepsilon_{rs} \\propto (\\alpha r_c + 1) e^{-\\alpha^2 r_c^2}/r_c^2$. In any case, to maintain a constant error $\\varepsilon$, the exponential term must be kept roughly constant. This means we must have $\\alpha^2 r_c^2 \\approx C_1$, where $C_1$ is a constant determined by the target tolerance $\\varepsilon$. This leads to the scaling relationship:\n$$ r_c \\propto \\frac{1}{\\alpha} $$\nThe real-space computational cost is given as $\\mathcal{O}(\\rho r_c^3)$. Substituting the scaling for $r_c$:\n$$ \\text{Cost}_{rs} \\propto \\rho r_c^3 \\propto \\rho \\left(\\frac{1}{\\alpha}\\right)^3 = \\rho \\alpha^{-3} $$\nThus, as $\\alpha$ decreases, $r_c$ must increase, and the real-space cost grows as $\\alpha^{-3}$.\n\n**2. Reciprocal-Space Analysis**\nThe long-range term, $\\frac{\\operatorname{erf}(\\alpha r)}{r}$, is slowly varying and is handled by Fourier transformation. The Fourier transform of the associated screening charge distribution (a Gaussian of width controlled by $\\alpha$) is also a Gaussian. The coefficients of the reciprocal-space sum are modulated by a factor of $\\exp(-k^2 / (4\\alpha^2))$, where $k$ is the magnitude of the wavevector $\\mathbf{k}$.\n\nThe truncation of the reciprocal-space sum at $k_{\\max}$ introduces an error, $\\varepsilon_{recip}$, dominated by the first neglected terms. The error in the force scales approximately as:\n$$ \\varepsilon_{recip} \\propto k_{\\max}^c \\exp\\left(-\\frac{k_{\\max}^2}{4\\alpha^2}\\right) $$\nwhere $c$ is a small positive power. To maintain a constant error, the exponential term must again be kept roughly constant. This requires $k_{\\max}^2 / (4\\alpha^2) \\approx C_2$, leading to the scaling relationship:\n$$ k_{\\max} \\propto \\alpha $$\nThe reciprocal-space cost is given as $\\mathcal{O}(k_{\\max}^3)$, representing the number of wavevectors to sum over. Substituting the scaling for $k_{\\max}$:\n$$ \\text{Cost}_{recip} \\propto k_{\\max}^3 \\propto \\alpha^3 $$\nThus, as $\\alpha$ decreases, $k_{\\max}$ can be decreased, and the reciprocal-space cost shrinks as $\\alpha^3$.\n\n**3. Total Cost and Optimization**\nThe total computational cost is the sum of the real-space and reciprocal-space costs:\n$$ \\text{Cost}_{total} \\approx C_{rs} \\alpha^{-3} + C_{recip} \\alpha^3 $$\nThis function has a minimum with respect to $\\alpha$, which occurs when the two terms are of comparable magnitude, i.e., when the computational load is balanced between real and reciprocal space. This defines an optimal $\\alpha$ for a given problem and desired accuracy.\n\n**Evaluation of Options**\n\n**A. For a fixed error tolerance $\\varepsilon$ and fixed density $\\rho$, decreasing $\\alpha$ forces $r_c$ to grow roughly like $\\alpha^{-1}$ to keep the real-space truncation error small, so the real-space computational cost scales up as $\\alpha^{-3}$, while the reciprocal-space mode count needed scales down as $\\alpha^{3}$ because the Gaussian damping in $k$-space becomes stronger.**\n- \"decreasing $\\alpha$ forces $r_c$ to grow roughly like $\\alpha^{-1}$\": Our derivation shows $r_c \\propto 1/\\alpha$. This is correct.\n- \"so the real-space computational cost scales up as $\\alpha^{-3}$\": Our derivation shows $\\text{Cost}_{rs} \\propto \\alpha^{-3}$. This is correct.\n- \"the reciprocal-space mode count needed scales down as $\\alpha^{3}$\": The mode count is proportional to $k_{\\max}^3$. Our derivation shows $k_{\\max} \\propto \\alpha$, so the mode count scales as $\\alpha^3$. As $\\alpha$ decreases, this count decreases. This is correct.\n- \"because the Gaussian damping in $k$-space becomes stronger\": The damping factor is $\\exp(-k^2/(4\\alpha^2))$. As $\\alpha$ decreases, the denominator $4\\alpha^2$ becomes smaller, so the negative exponent grows more rapidly in magnitude with $k$. This corresponds to a stronger (faster) decay. This reasoning is correct.\nThe statement is entirely accurate.\n**Verdict: Correct**\n\n**B. For fixed $r_c$, the real-space computational cost is independent of $\\alpha$, but the real-space truncation error increases as $\\alpha$ decreases, with a leading dependence that is approximately $\\propto \\exp(-\\alpha^2 r_c^2)$, implying that choosing $\\alpha$ too small is inadmissible for a given tolerance even if the reciprocal-space grid is refined arbitrarily.**\n- \"For fixed $r_c$, the real-space computational cost is independent of $\\alpha$\": The cost model is $\\mathcal{O}(\\rho r_c^3)$. If $r_c$ is fixed, the cost is constant. This is correct.\n- \"the real-space truncation error increases as $\\alpha$ decreases\": The error scales with terms like $\\exp(-\\alpha^2 r_c^2)$. For fixed $r_c$, as $\\alpha$ decreases, $\\alpha^2 r_c^2$ decreases, so $-\\alpha^2 r_c^2$ increases, and the exponential term grows. The error increases. This is correct.\n- \"with a leading dependence that is approximately $\\propto \\exp(-\\alpha^2 r_c^2)$\": This is the dominant factor in the error formula, as established in our initial analysis. Correct.\n- \"implying that choosing $\\alpha$ too small is inadmissible for a given tolerance even if the reciprocal-space grid is refined arbitrarily\": If $\\alpha$ is too small for a given $r_c$, the real-space error $\\varepsilon_{rs}$ may exceed the total allowed error $\\varepsilon$. Refining the reciprocal-space calculation only reduces $\\varepsilon_{recip}$; it cannot compensate for an already too-large $\\varepsilon_{rs}$. Thus, the choice of $\\alpha$ is constrained by $r_c$ and $\\varepsilon$. This is a key practical consideration in using Ewald methods. Correct.\nThe statement is entirely accurate.\n**Verdict: Correct**\n\n**C. For fixed $r_c$, decreasing $\\alpha$ increases the reciprocal-space workload because the Gaussian damping factor in $k$-space decays more slowly, so more $k$-modes are required.**\n- This statement analyzes the consequence of decreasing $\\alpha$. As established in our reciprocal-space analysis, decreasing $\\alpha$ leads to a faster decay of the reciprocal-space terms (the damping factor $\\exp(-k^2 / (4\\alpha^2))$ decays more rapidly).\n- This means fewer $k$-modes are required to achieve a given accuracy, so $k_{\\max}$ can be smaller. A smaller $k_{\\max}$ leads to a a *decreased*, not increased, reciprocal-space workload.\n- The statement claims the workload increases because the damping factor \"decays more slowly\", which is also factually incorrect. Decreasing $\\alpha$ makes the decay faster.\nThe statement is incorrect in both its conclusion and its reasoning.\n**Verdict: Incorrect**\n\n**D. At a fixed accuracy target $\\varepsilon$, there exists an optimal $\\alpha$ that balances real-space and reciprocal-space costs, and as $r_c$ is decreased (e.g., due to memory or neighbor-list constraints), the optimal $\\alpha$ shifts to larger values, shifting more work to reciprocal space.**\n- \"there exists an optimal $\\alpha$ that balances real-space and reciprocal-space costs\": Our analysis of the total cost function $\\text{Cost}_{total} \\approx C_{rs} \\alpha^{-3} + C_{recip} \\alpha^3$ shows that a minimum exists, typically where the two costs are balanced. Correct.\n- \"as $r_c$ is decreased ... the optimal $\\alpha$ shifts to larger values\": If $r_c$ is constrained to be smaller, we must ensure the real-space error $\\varepsilon_{rs} \\propto \\exp(-\\alpha^2 r_c^2)$ remains small. With a smaller $r_c$, the only way to keep the argument $\\alpha^2 r_c^2$ large is to increase $\\alpha$. So, a smaller $r_c$ forces a larger $\\alpha$. Correct.\n- \"shifting more work to reciprocal space\": A larger $\\alpha$ makes the real-space interaction $\\operatorname{erfc}(\\alpha r)/r$ more short-ranged, justifying the smaller $r_c$ and reducing the real-space cost. Conversely, a larger $\\alpha$ makes the reciprocal-space components decay more slowly in $k$-space (since $\\exp(-k^2/(4\\alpha^2))$ decays more slowly as $\\alpha$ increases), requiring a larger $k_{\\max}$ and thus a higher reciprocal-space cost ($\\propto \\alpha^3$). The balance of work is shifted from real space to reciprocal space. Correct.\nThe statement is entirely accurate.\n**Verdict: Correct**",
            "answer": "$$\\boxed{ABD}$$"
        },
        {
            "introduction": "The Particle-Mesh Ewald (PME) method, the workhorse for long-range electrostatics, introduces a grid to efficiently compute the reciprocal-space sum, but this discretization can lead to numerical artifacts. This problem presents a practical diagnostic challenge: identifying and remedying aliasing errors, where unresolved high-frequency force components contaminate the calculation. By analyzing a hypothetical force power spectrum, you will learn to spot the tell-tale signs of aliasing and select the appropriate corrective actions, a crucial skill for ensuring the accuracy of modern molecular simulations .",
            "id": "3851262",
            "problem": "A biomolecular simulation uses the Particle-Mesh Ewald (PME) method to compute long-range electrostatic forces. In PME, point charges are assigned to a uniform mesh using a cardinal B-spline of order $p$, a discrete Fourier transform is applied to obtain reciprocal-space fields on the mesh, and forces are recovered through inverse transforms and interpolation. Consider the following setting: a cubic simulation cell of side length $L$ is discretized with $N_g$ mesh points per Cartesian direction, giving a mesh spacing $\\Delta = L/N_g$. The discrete sampling in real space implies a periodic replication of the continuous reciprocal-space spectrum with sampling wavevector $k_s = 2\\pi/\\Delta$, and thus a maximum resolvable wavevector (the Nyquist limit) $k_N = \\pi/\\Delta$. The force power spectrum $P_F(\\mathbf{k}) = \\lvert \\mathbf{F}(\\mathbf{k}) \\rvert^2$ is obtained by Fourier transforming the reciprocal-space force field and then radially averaging over shells of constant $\\lvert \\mathbf{k} \\rvert$. For a well-resolved PME calculation with a smooth charge structure factor $S(\\mathbf{k})$ and appropriate Gaussian screening parameter (Ewald splitting parameter) $\\alpha$, the physical $P_F(k)$ should follow the smooth decay dictated by the reciprocal-space kernel and the charge-assignment window, with no artificial peaks at the high-$k$ end of the spectrum.\n\nYou examine $P_F(k)$ for a system with $L = 3.2\\,\\mathrm{nm}$, $N_g = 32$, yielding $\\Delta = 0.1\\,\\mathrm{nm}$ and therefore $k_s = 2\\pi/\\Delta \\approx 62.83\\,\\mathrm{nm}^{-1}$ and $k_N \\approx 31.42\\,\\mathrm{nm}^{-1}$. The observed $P_F(k)$ shows pronounced shoulders and anisotropic spikes in the Cartesian components at $k$ values clustered near $k \\approx k_N$, despite a smooth $S(\\mathbf{k})$ and no obvious physical source of high-frequency power. You suspect aliasing due to undersampling and/or insufficient charge-assignment filtering.\n\nBased on first principles of sampling and the PME formulation, which of the following statements correctly describe a diagnostic of aliasing via force power spectra and appropriate remedies?\n\nA. The presence of excess power localized near the maximum resolved wavevector $k_N = \\pi/\\Delta$ and anisotropic spikes aligned with the mesh axes is indicative of aliasing due to undersampling; increasing the B-spline order $p$ reduces high-$k$ leakage of the assignment window, and refining the mesh (decreasing $\\Delta$) raises $k_N$, both of which mitigate aliasing.\n\nB. Aliasing in PME is caused by periodic boundary conditions; it is detected as a uniform elevation of $P_F(k)$ across all $k$, and the proper remedy is to increase the simulation box length $L$ while keeping $\\Delta$ fixed.\n\nC. If aliasing is present, the correct diagnostic is to inspect the time-autocorrelation of forces rather than their spectrum; increasing the order $p$ of the cardinal B-spline worsens aliasing because it broadens the real-space spreading kernel.\n\nD. True aliasing yields peaks in $P_F(k)$ at $k \\ll k_N$ due to the Gaussian screening factor; therefore, increasing the Ewald splitting parameter $\\alpha$ will suppress aliasing by attenuating high-$k$ modes.\n\nSelect all correct statements.",
            "solution": "The problem asks to identify correct statements regarding the diagnosis and remedy of aliasing artifacts in Particle-Mesh Ewald (PME) calculations, as observed in the force power spectrum.\n\nFirst, let us validate the problem statement. The problem provides a standard description of the PME method, including charge assignment via B-splines of order $p$, discretization on a grid with spacing $\\Delta$, and the use of Fast Fourier Transforms (FFTs) to solve for the long-range potential in reciprocal space. The provided parameters ($L = 3.2\\,\\mathrm{nm}$, $N_g=32$, leading to $\\Delta = 0.1\\,\\mathrm{nm}$) are physically realistic. The definitions of the sampling wavevector $k_s = 2\\pi/\\Delta$ and the Nyquist limit wavevector $k_N = \\pi/\\Delta$ are correct from sampling theory. The observed phenomenon—excess power and anisotropic spikes near $k_N$ in the force power spectrum—is a classic signature of aliasing in grid-based methods. The problem statement is scientifically sound, well-posed, and internally consistent.\n\nNow, we proceed to analyze the physics and numerics of aliasing in PME.\nThe PME method calculates the long-range electrostatic interaction in reciprocal space. This involves representing the charge density, $\\rho(\\mathbf{r})$, on a discrete grid. This discretization, or sampling, with a grid spacing $\\Delta$, is the origin of aliasing errors. According to the Nyquist-Shannon sampling theorem, a continuous signal can be perfectly reconstructed from its samples only if its frequency spectrum contains no components at frequencies higher than the Nyquist frequency, which in this spatial context corresponds to the Nyquist wavevector $k_N = \\pi/\\Delta$.\n\nThe true charge density of point particles has power at all wavevectors. In PME, two measures are taken to make the gridded function smoother (i.e., to reduce its high-frequency content) before sampling:\n1.  The Ewald splitting with parameter $\\alpha$ makes the long-range part of the potential (which is calculated in reciprocal space) a smooth function.\n2.  The charge assignment scheme, using, for instance, B-splines of order $p$, acts as a low-pass filter. A higher spline order $p$ corresponds to a smoother assignment function in real space and a faster decaying window function in Fourier space, which more effectively suppresses high-$k$ components.\n\nDespite these measures, the gridded charge density may still possess significant power at wavevectors $\\lvert\\mathbf{k}\\rvert > k_N$. Due to the discrete sampling, this high-frequency power is \"aliased\" or \"folded\" back into the principal Brillouin zone $[-\\pi/\\Delta, \\pi/\\Delta]$ for each Cartesian component of $\\mathbf{k}$. A component with wavevector $\\mathbf{k}'$ is aliased to $\\mathbf{k} = \\mathbf{k}' - \\mathbf{m} (2\\pi/\\Delta)$, where $\\mathbf{m}$ is a vector of integers chosen to bring $\\mathbf{k}$ into the principal zone. This aliased power contaminates the calculated reciprocal-space field. The effect is most pronounced near the boundary of the zone, i.e., for $k \\approx k_N$, because the power spectrum of the physical signal generally decays with $k$, so the strongest aliased contributions come from wavevectors just above $k_N$. Because the grid is Cartesian, these artifacts can exhibit anisotropy reflecting the grid geometry, leading to spikes along the reciprocal lattice axes.\n\nTo mitigate aliasing, one must either:\n1.  Increase the smoothness of the function being sampled, reducing its power content above $k_N$. This can be done by increasing the B-spline order $p$ or by increasing the Ewald splitting parameter $\\alpha$.\n2.  Increase the Nyquist frequency $k_N$ itself, so that the region of aliased power is pushed out to where the signal is weaker. This is achieved by decreasing the mesh spacing $\\Delta$, which for a fixed box size $L$, means increasing the number of grid points $N_g$.\n\nWith these principles established, we can evaluate each option.\n\n**A. The presence of excess power localized near the maximum resolved wavevector $k_N = \\pi/\\Delta$ and anisotropic spikes aligned with the mesh axes is indicative of aliasing due to undersampling; increasing the B-spline order $p$ reduces high-$k$ leakage of the assignment window, and refining the mesh (decreasing $\\Delta$) raises $k_N$, both of which mitigate aliasing.**\nThis statement is entirely correct.\n- **Diagnosis:** It correctly identifies the primary signature of aliasing in the power spectrum: an accumulation of spectral power near the Nyquist limit $k_N$. It also correctly notes the potential for anisotropic artifacts related to the grid structure.\n- **Remedies:** It correctly states that increasing the spline order $p$ provides better filtering of high-frequency components. It also correctly states that refining the mesh (decreasing $\\Delta$) increases the Nyquist frequency $k_N$. Both are standard and effective methods for reducing aliasing error.\n**Verdict: Correct.**\n\n**B. Aliasing in PME is caused by periodic boundary conditions; it is detected as a uniform elevation of $P_F(k)$ across all $k$, and the proper remedy is to increase the simulation box length $L$ while keeping $\\Delta$ fixed.**\nThis statement is incorrect.\n- **Cause:** Aliasing is caused by spatial discretization (sampling on a grid), not by periodic boundary conditions (PBCs). The Ewald method is specifically designed to handle PBCs correctly.\n- **Detection:** Aliasing manifests at high wavevectors near $k_N$, not as a uniform elevation across the entire spectrum.\n- **Remedy:** Increasing $L$ while keeping $\\Delta$ fixed does not change the Nyquist frequency $k_N=\\pi/\\Delta$ and thus does not address the fundamental undersampling problem. The primary remedy is to decrease $\\Delta$.\n**Verdict: Incorrect.**\n\n**C. If aliasing is present, the correct diagnostic is to inspect the time-autocorrelation of forces rather than their spectrum; increasing the order $p$ of the cardinal B-spline worsens aliasing because it broadens the real-space spreading kernel.**\nThis statement is incorrect.\n- **Diagnosis:** While force errors can affect time correlation functions, the force power spectrum $P_F(k)$ is a far more direct and powerful diagnostic for aliasing, as it resolves errors as a function of wavevector, pinpointing the problem in the frequency domain where it originates.\n- **Remedy/Effect of $p$:** The statement that increasing $p$ *worsens* aliasing is false. Although a higher-order B-spline is broader in real space, this greater smoothness is precisely what improves its filtering properties in Fourier space. A broader, smoother kernel corresponds to a Fourier transform that decays more rapidly at high $k$, thus *reducing* the high-frequency components that cause aliasing.\n**Verdict: Incorrect.**\n\n**D. True aliasing yields peaks in $P_F(k)$ at $k \\ll k_N$ due to the Gaussian screening factor; therefore, increasing the Ewald splitting parameter $\\alpha$ will suppress aliasing by attenuating high-$k$ modes.**\nThis statement is incorrect.\n- **Diagnosis:** The premise that aliasing produces peaks at low wavevectors ($k \\ll k_N$) is false. As explained, aliasing errors manifest primarily near the Nyquist frequency, $k \\approx k_N$.\n- **Remedy and Logic:** While the conclusion that increasing $\\alpha$ suppresses aliasing is correct (as it smooths the reciprocal-space charge density), the reasoning provided is flawed. The \"therefore\" connects a correct conclusion to a false premise, making the entire statement logically unsound.\n**Verdict: Incorrect.**\n\nBased on the analysis, only statement A is correct.",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}