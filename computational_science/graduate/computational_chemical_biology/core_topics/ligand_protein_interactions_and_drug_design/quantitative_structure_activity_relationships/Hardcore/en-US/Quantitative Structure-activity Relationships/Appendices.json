{
    "hands_on_practices": [
        {
            "introduction": "The foundation of any QSAR model lies in translating a molecule's structure into a set of quantitative numerical values, known as molecular descriptors. This practice introduces one of the most widely used descriptors, the Topological Polar Surface Area (TPSA), which is crucial for predicting properties like cell permeability and oral bioavailability. By calculating TPSA from its constituent fragments , you will gain direct experience with the principle of property additivity and be prompted to consider the critical differences between a simplified 2D topological representation and a molecule's complex 3D reality.",
            "id": "3860360",
            "problem": "A widely used descriptor in quantitative structure-activity relationships (QSAR) is the topological polar surface area (TPSA), which approximates the polar component of the solvent-accessible surface area using the molecular graph (atoms and bonds) and polar fragment types. The conceptual base is that many additive physicochemical properties can be represented by sums of local contributions defined on a molecular graph, consistent with linear free-energy relationships and fragment additivity in cheminformatics. In TPSA, the polar surface area is approximated as a sum over predefined fragment contributions associated with heteroatom environments. This approach assumes strict additivity of fragment contributions and neglects three-dimensional conformation, intramolecular hydrogen bonding, and dynamic occlusion of polar atoms.\n\nConsider the following macrocyclic scaffold, which contains the polar fragments listed below. You are told the counts of each fragment and their fragment contributions to TPSA, defined on the molecular graph without reference to three-dimensional conformation. The compound is conformationally constrained and is known to form intramolecular hydrogen bonds, but for TPSA these do not alter the fragment definitions because TPSA is purely topological.\n\nFragments and their counts with contributions:\n- Carbonyl oxygen in amide or lactam: count $=2$, contribution per fragment $=17.07\\,\\mathrm{\\AA^2}$.\n- Secondary amide nitrogen (hydrogen-bond donor): count $=1$, contribution per fragment $=12.03\\,\\mathrm{\\AA^2}$.\n- Aromatic ring nitrogen (pyridine-like, hydrogen-bond acceptor): count $=1$, contribution per fragment $=25.78\\,\\mathrm{\\AA^2}$.\n- Imidazole pyrroline-like nitrogen (hydrogen-bond donor): count $=1$, contribution per fragment $=12.03\\,\\mathrm{\\AA^2}$.\n- Tertiary hydroxyl oxygen (hydrogen-bond acceptor): count $=1$, contribution per fragment $=12.53\\,\\mathrm{\\AA^2}$.\n\nUsing only the additivity assumption on the molecular graph, compute the TPSA of this macrocycle from the given fragment contributions. Discuss the assumptions underlying fragment additivity and the limitations of TPSA for conformationally constrained molecules, but do not introduce any empirical occlusion or correction factors into the calculation. Round your final numerical answer to four significant figures. Express the final TPSA in $\\mathrm{\\AA^2}$.",
            "solution": "The problem statement is scientifically grounded, well-posed, objective, and contains all necessary information for a solution. It correctly describes the concept of Topological Polar Surface Area (TPSA) as a fragment-based additive property used in quantitative structure-activity relationships (QSAR). The provided data are complete and consistent with the task. Therefore, the problem is valid.\n\nThe central task is to calculate the TPSA of a macrocyclic scaffold using the principle of fragment additivity. The problem explicitly states that TPSA is approximated as a sum over predefined fragment contributions, a method grounded in the assumption that molecular properties can be deconstructed into the sum of contributions from their constituent parts. This approach is purely topological and does not account for the molecule's three-dimensional conformation.\n\nThe total TPSA is the sum of the contributions from all identified polar fragments. Let $C_i$ be the contribution of fragment type $i$, and let $n_i$ be the count of that fragment in the molecule. The total TPSA is given by the formula:\n$$\n\\text{TPSA} = \\sum_{i} n_i C_i\n$$\n\nThe problem provides the following fragment counts ($n_i$) and their respective contributions ($C_i$):\n1.  Carbonyl oxygen in amide or lactam: $n_1 = 2$, $C_1 = 17.07\\,\\mathrm{\\AA^2}$\n2.  Secondary amide nitrogen (hydrogen-bond donor): $n_2 = 1$, $C_2 = 12.03\\,\\mathrm{\\AA^2}$\n3.  Aromatic ring nitrogen (pyridine-like): $n_3 = 1$, $C_3 = 25.78\\,\\mathrm{\\AA^2}$\n4.  Imidazole pyrroline-like nitrogen (hydrogen-bond donor): $n_4 = 1$, $C_4 = 12.03\\,\\mathrm{\\AA^2}$\n5.  Tertiary hydroxyl oxygen: $n_5 = 1$, $C_5 = 12.53\\,\\mathrm{\\AA^2}$\n\nWe can now calculate the total TPSA by summing the products of the counts and their respective contributions:\n$$\n\\text{TPSA} = (n_1 \\times C_1) + (n_2 \\times C_2) + (n_3 \\times C_3) + (n_4 \\times C_4) + (n_5 \\times C_5)\n$$\nSubstituting the given values:\n$$\n\\text{TPSA} = (2 \\times 17.07\\,\\mathrm{\\AA^2}) + (1 \\times 12.03\\,\\mathrm{\\AA^2}) + (1 \\times 25.78\\,\\mathrm{\\AA^2}) + (1 \\times 12.03\\,\\mathrm{\\AA^2}) + (1 \\times 12.53\\,\\mathrm{\\AA^2})\n$$\n$$\n\\text{TPSA} = 34.14\\,\\mathrm{\\AA^2} + 12.03\\,\\mathrm{\\AA^2} + 25.78\\,\\mathrm{\\AA^2} + 12.03\\,\\mathrm{\\AA^2} + 12.53\\,\\mathrm{\\AA^2}\n$$\n$$\n\\text{TPSA} = 96.51\\,\\mathrm{\\AA^2}\n$$\nThe problem requires the final answer to be rounded to four significant figures. The calculated value of $96.51$ already has four significant figures, so no further rounding is necessary.\n\nA critical part of the analysis, as requested, is to discuss the assumptions and limitations of this method, especially for the specified molecular context.\n\n**Assumptions Underlying Fragment Additivity:**\nThe fundamental assumption of any fragment additivity scheme, including TPSA, is that a global molecular property can be represented as a simple sum of pre-calculated, constant contributions from its fragments. This implies that the contribution of any single fragment is independent of its context within the broader molecular structure. For TPSA, this means the polar surface area contribution of, for example, a carbonyl group is assumed to be the same regardless of what other functional groups are nearby, what conformation the molecule adopts, or whether the group is sterically hindered. This is a powerful simplification that enables rapid calculation but ignores the complexities of intramolecular electronic and steric interactions.\n\n**Limitations of TPSA for Conformationally Constrained Molecules:**\nThe problem specifies a conformationally constrained macrocycle known to form intramolecular hydrogen bonds (IMHBs). This context starkly exposes the limitations of the topological TPSA method.\n1.  **Neglect of 3D Conformation and Steric Occlusion:** TPSA is calculated from the molecular graph (2D connectivity). It inherently assumes all polar fragments are fully exposed to the solvent. In a real, folded 3D structure like a macrocycle, many polar atoms may be buried in the molecule's interior, making them inaccessible to solvent. The actual, physically relevant solvent-accessible surface area (SASA) of these polar atoms would be significantly lower, or even zero. The TPSA value of $96.51\\,\\mathrm{\\AA^2}$ represents a theoretical maximum that is physically unattainable for a constrained scaffold where polar groups are occluded.\n2.  **Neglect of Intramolecular Hydrogen Bonding (IMHB):** The problem states that the molecule forms IMHBs. An IMHB occurs when a hydrogen bond donor (like the secondary amide N-H or the imidazole N-H) interacts with an acceptor within the same molecule (like a carbonyl oxygen). When this happens, the involved atoms are \"internally satisfied\" and are no longer available to interact with external water molecules. TPSA, by its definition, ignores this. It adds the full fragment contribution for both the donor and the acceptor, as if they were both fully available for intermolecular interactions. This leads to a systematic overestimation of the surface area relevant for properties like solvation and membrane permeation. For the given molecule, it is highly probable that one or more of the hydrogen-bond donors ($n_2$, $n_4$) are bonded to an acceptor (e.g., $n_1$), yet the calculation includes their full contributions.\n\nIn summary, while TPSA is a valuable and rapid computational filter in drug discovery, its value for a conformationally rigid and internally hydrogen-bonded molecule like the one described is best interpreted as a crude upper bound on the true polar surface area. Its deviation from the physical reality for such molecules can be substantial. The calculation itself, however, must strictly follow the additive, topological definition as performed.",
            "answer": "$$\n\\boxed{96.51}\n$$"
        },
        {
            "introduction": "Once molecular properties are quantified, the next step is to build a mathematical model that relates them to biological activity. This exercise walks you through a complete, classic Hansch analysis, a cornerstone of QSAR that linearly combines hydrophobic ($\\pi$) and electronic ($\\sigma$) effects to rationalize activity trends in a chemical series. By first calculating these fundamental substituent constants and then using them in a multiple linear regression , you will practice the core workflow of building and assessing a simple, interpretable QSAR model from the ground up.",
            "id": "3860378",
            "problem": "You are given a scenario in quantitative structure–activity relationships (QSAR) where substituent hydrophobicity and electronic effects are hypothesized to jointly influence a biological activity measured on a logarithmic scale. The fundamental bases are: the definition of the octanol–water partition coefficient $P$ and its logarithm $\\log_{10} P$ (hydrophobicity), and the Hammett equation relating substituent electronic effects to reaction or equilibrium constants. The substituent hydrophobicity constant $\\pi_i$ for substituent $i$ is defined as the change in $\\log_{10} P$ relative to the parent (hydrogen) substituent on the same aromatic scaffold, and the electronic constant $\\sigma_i$ is defined using the Hammett relation with a reaction constant $\\rho$ and the acid dissociation constant $K_a$ expressed via $pK_a$.\n\nStarting from these bases:\n- Octanol–water partition coefficient $P_i$ is the ratio of equilibrium concentrations in octanol and water phases, and hydrophobicity is quantified by $x_i = \\log_{10} P_i$ (dimensionless).\n- Substituent hydrophobicity constant is $ \\pi_i = x_i - x_H $, where $x_H = \\log_{10} P_H$ is the parent hydrophobicity (dimensionless).\n- The Hammett relation is $ \\log_{10}(K_i / K_0) = \\rho \\sigma_i $, where $K_i = 10^{-pK_{a,i}}$ and $K_0 = 10^{-pK_{a,0}}$. This implies $ \\sigma_i = -\\dfrac{pK_{a,i} - pK_{a,0}}{\\rho} $ (dimensionless).\n\nYou must:\n1. For each test case, compute $ \\pi_i $ and $ \\sigma_i $ for each substituent in the series from the provided $\\log_{10} P_i$, $\\log_{10} P_H$, $pK_{a,i}$, $pK_{a,0}$, and $\\rho$.\n2. Fit a multiple linear regression model to the provided activity values $A_i$ (dimensionless, log scale) of the form\n$$\nA_i = \\beta_0 + \\beta_{\\pi} \\pi_i + \\beta_{\\sigma} \\sigma_i + \\varepsilon_i,\n$$\nwhere $ \\beta_0 $, $ \\beta_{\\pi} $, and $ \\beta_{\\sigma} $ are regression coefficients and $ \\varepsilon_i $ is the residual. Use ordinary least squares to estimate $ \\beta_0 $, $ \\beta_{\\pi} $, and $ \\beta_{\\sigma} $. Compute the coefficient of determination\n$$\nR^2 = 1 - \\frac{\\sum_i (A_i - \\hat{A}_i)^2}{\\sum_i (A_i - \\bar{A})^2},\n$$\nwhere $ \\hat{A}_i $ are fitted values and $ \\bar{A} $ is the mean of the $A_i$.\n\n3. For each test case, output the list $[\\beta_0, \\beta_{\\pi}, \\beta_{\\sigma}, R^2]$ with each value rounded to six decimal places.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes a bracketed four-element list in order. For example, the output should look like:\n[[_case1_b0_,_case1_bpi_,_case1_bsigma_,_case1_R2_],[_case2_b0_,_case2_bpi_,_case2_bsigma_,_case2_R2_],[_case3_b0_,_case3_bpi_,_case3_bsigma_,_case3_R2_]]\nwith numerical values substituted and no spaces.\n\nUse the following test suite. All quantities are dimensionless.\n\nTest Case 1 (general case):\n- Parent hydrophobicity $ x_H = \\log_{10} P_H = 2.13 $.\n- Parent acidity $ pK_{a,0} = 4.20 $.\n- Reaction constant $ \\rho = 1.00 $.\n- Substituent data arrays:\n    - $ x_i = [2.73, 2.18, 2.84, 2.11, 0.90, 3.00, 1.46] $.\n    - $ pK_{a,i} = [4.34, 3.45, 3.98, 4.47, 4.80, 3.60, 4.54] $.\n    - $ A_i = [0.812, 1.44, 1.332, 0.16, -1.204, 1.916, -0.444] $.\n\nTest Case 2 (boundary condition includes a case with $ \\pi_i = 0 $):\n- Parent hydrophobicity $ x_H = \\log_{10} P_H = 2.13 $.\n- Parent acidity $ pK_{a,0} = 4.20 $.\n- Reaction constant $ \\rho = 0.90 $.\n- Substituent data arrays:\n    - $ x_i = [2.73, 2.13, 2.84, 2.11, 0.90, 2.95, 1.46] $.\n    - $ pK_{a,i} = [4.30, 3.50, 4.00, 4.50, 4.85, 3.70, 4.52] $.\n    - $ A_i = [0.8288888889, 1.1777777778, 1.2612222222, 0.0486666667, -1.4292222222, 1.6935555556, -0.5585555556] $.\n\nTest Case 3 (edge case with stronger electronic weighting and mixed hydrophobicity extremes):\n- Parent hydrophobicity $ x_H = \\log_{10} P_H = 2.13 $.\n- Parent acidity $ pK_{a,0} = 4.20 $.\n- Reaction constant $ \\rho = 1.20 $.\n- Substituent data arrays:\n    - $ x_i = [2.73, 2.13, 3.05, 0.90, 1.46, 2.70] $.\n    - $ pK_{a,i} = [4.36, 3.40, 3.60, 4.86, 4.60, 3.95] $.\n    - $ A_i = [0.84, 0.9, 1.762, -1.548, -0.737, 1.1145] $.\n\nFinal Output Format Requirement:\n- Your program must print exactly one line: a single bracketed list of three bracketed lists, one per test case, each containing $[\\beta_0, \\beta_{\\pi}, \\beta_{\\sigma}, R^2]$ rounded to six decimal places, with commas and no spaces.",
            "solution": "The problem is valid as it is scientifically grounded in the principles of quantitative structure-activity relationships (QSAR), specifically the Hansch analysis. It is well-posed, objective, and provides all necessary information to compute a unique solution.\n\nThe problem requires a multiple linear regression analysis for three distinct test cases. For each case, we are to determine the coefficients of a linear model and its coefficient of determination, $R^2$. The model relates biological activity, $A_i$, to two physicochemical properties of molecular substituents: the hydrophobicity constant, $\\pi_i$, and the electronic constant, $\\sigma_i$.\n\nThe procedure is as follows:\nFirst, for each substituent $i$ in a given test series, we must calculate the independent variables (descriptors) $\\pi_i$ and $\\sigma_i$ from the provided data.\n\nThe substituent hydrophobicity constant, $\\pi_i$, is defined as the difference between the logarithm of the octanol-water partition coefficient of the substituted molecule, $x_i = \\log_{10} P_i$, and that of the parent compound, $x_H = \\log_{10} P_H$. The formula is:\n$$\n\\pi_i = x_i - x_H\n$$\n\nThe substituent electronic constant, $\\sigma_i$, is derived from the Hammett equation, which relates reaction rates and equilibrium constants of substituted aromatic compounds. The definition provided is:\n$$\n\\sigma_i = -\\frac{pK_{a,i} - pK_{a,0}}{\\rho}\n$$\nwhere $pK_{a,i}$ is the negative base-$10$ logarithm of the acid dissociation constant for the substituted compound, $pK_{a,0}$ is that for the parent compound, and $\\rho$ is the reaction constant that characterizes the sensitivity of the reaction to electronic effects.\n\nSecond, with the descriptors $\\pi_i$ and $\\sigma_i$ calculated for each substituent, we fit the specified linear model:\n$$\nA_i = \\beta_0 + \\beta_{\\pi} \\pi_i + \\beta_{\\sigma} \\sigma_i + \\varepsilon_i\n$$\nHere, $A_i$ is the measured biological activity, $\\beta_0$ is the intercept, $\\beta_{\\pi}$ and $\\beta_{\\sigma}$ are the regression coefficients for the hydrophobicity and electronic effects respectively, and $\\varepsilon_i$ is the residual error.\n\nTo find the coefficients, we use the method of ordinary least squares (OLS). The problem can be expressed in matrix form as $\\mathbf{y} = \\mathbf{X}\\mathbf{\\beta} + \\mathbf{\\varepsilon}$, where:\n- $\\mathbf{y}$ is an $n \\times 1$ column vector of the observed activities $A_i$.\n- $\\mathbf{X}$ is the $n \\times 3$ design matrix, where each row $i$ is $[1, \\pi_i, \\sigma_i]$. The first column of ones corresponds to the intercept term $\\beta_0$.\n- $\\mathbf{\\beta}$ is the $3 \\times 1$ column vector of coefficients to be estimated: $[\\beta_0, \\beta_{\\pi}, \\beta_{\\sigma}]^T$.\n- $\\mathbf{\\varepsilon}$ is an $n \\times 1$ column vector of the residuals.\n\nThe OLS estimate for $\\mathbf{\\beta}$ that minimizes the sum of squared residuals, $\\sum_i \\varepsilon_i^2$, is given by the normal equations:\n$$\n\\mathbf{\\hat{\\beta}} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y}\n$$\nwhere $\\mathbf{\\hat{\\beta}}$ is the vector of estimated coefficients. This system is solved numerically for each test case.\n\nThird, after estimating the coefficients, we evaluate the goodness of fit of the model using the coefficient of determination, $R^2$. First, we calculate the predicted activities, $\\hat{A}_i$, for each substituent using the fitted model:\n$$\n\\hat{A}_i = \\hat{\\beta}_0 + \\hat{\\beta}_{\\pi} \\pi_i + \\hat{\\beta}_{\\sigma} \\sigma_i\n$$\nThis can be written in matrix form as $\\mathbf{\\hat{y}} = \\mathbf{X}\\mathbf{\\hat{\\beta}}$.\n\n$R^2$ is then computed as:\n$$\nR^2 = 1 - \\frac{\\text{SSR}}{\\text{SST}}\n$$\nwhere:\n- The Residual Sum of Squares (SSR) is the sum of the squared differences between the observed and predicted activities: $\\text{SSR} = \\sum_{i=1}^{n} (A_i - \\hat{A}_i)^2$.\n- The Total Sum of Squares (SST) is the sum of the squared differences between the observed activities and their mean, $\\bar{A} = \\frac{1}{n}\\sum_{i=1}^{n} A_i$: $\\text{SST} = \\sum_{i=1}^{n} (A_i - \\bar{A})^2$.\n\nFinally, for each test case, the resulting values $[\\hat{\\beta}_0, \\hat{\\beta}_{\\pi}, \\hat{\\beta}_{\\sigma}, R^2]$ are rounded to six decimal places and formatted as specified.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the QSAR problem for all test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test Case 1\n        {\n            \"x_H\": 2.13,\n            \"pKa_0\": 4.20,\n            \"rho\": 1.00,\n            \"x_i\": np.array([2.73, 2.18, 2.84, 2.11, 0.90, 3.00, 1.46]),\n            \"pKa_i\": np.array([4.34, 3.45, 3.98, 4.47, 4.80, 3.60, 4.54]),\n            \"A_i\": np.array([0.812, 1.44, 1.332, 0.16, -1.204, 1.916, -0.444]),\n        },\n        # Test Case 2\n        {\n            \"x_H\": 2.13,\n            \"pKa_0\": 4.20,\n            \"rho\": 0.90,\n            \"x_i\": np.array([2.73, 2.13, 2.84, 2.11, 0.90, 2.95, 1.46]),\n            \"pKa_i\": np.array([4.30, 3.50, 4.00, 4.50, 4.85, 3.70, 4.52]),\n            \"A_i\": np.array([0.8288888889, 1.1777777778, 1.2612222222, 0.0486666667, -1.4292222222, 1.6935555556, -0.5585555556]),\n        },\n        # Test Case 3\n        {\n            \"x_H\": 2.13,\n            \"pKa_0\": 4.20,\n            \"rho\": 1.20,\n            \"x_i\": np.array([2.73, 2.13, 3.05, 0.90, 1.46, 2.70]),\n            \"pKa_i\": np.array([4.36, 3.40, 3.60, 4.86, 4.60, 3.95]),\n            \"A_i\": np.array([0.84, 0.9, 1.762, -1.548, -0.737, 1.1145]),\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        # Extract data for the current case\n        x_H = case[\"x_H\"]\n        pKa_0 = case[\"pKa_0\"]\n        rho = case[\"rho\"]\n        x_i = case[\"x_i\"]\n        pKa_i = case[\"pKa_i\"]\n        A_i = case[\"A_i\"]\n\n        # 1. Compute pi and sigma descriptors\n        pi_vals = x_i - x_H\n        sigma_vals = -(pKa_i - pKa_0) / rho\n\n        # 2. Fit a multiple linear regression model\n        # Construct the design matrix X\n        n_obs = len(A_i)\n        X = np.c_[np.ones(n_obs), pi_vals, sigma_vals]\n        \n        # Use ordinary least squares to estimate beta coefficients\n        # lstsq solves X * beta = A_i\n        beta, residuals, rank, s = np.linalg.lstsq(X, A_i, rcond=None)\n        beta_0, beta_pi, beta_sigma = beta[0], beta[1], beta[2]\n\n        # 3. Compute the coefficient of determination R^2\n        # Calculate predicted activities A_hat\n        A_hat = X @ beta\n        \n        # Calculate Total Sum of Squares (SST)\n        A_mean = np.mean(A_i)\n        sst = np.sum((A_i - A_mean)**2)\n        \n        # The 'residuals' output from lstsq is the Residual Sum of Squares (SSR)\n        # It's a 1-element array, so we access it with [0]\n        # This is valid only if sst > 0, which is true for non-constant A_i\n        ssr = residuals[0]\n        \n        # Handle the case where sst is zero (all A_i values are the same)\n        if sst == 0:\n            # If ssr is also zero, the fit is perfect. If ssr>0, the fit is meaningless.\n            # Conventionally, R^2 is set to 1.0 if SSR is also 0, otherwise undefined or 0.\n            R2 = 1.0 if ssr  1e-9 else 0.0\n        else:\n            R2 = 1 - (ssr / sst)\n\n        # Format results for the current case\n        case_result_str = f\"[{beta_0:.6f},{beta_pi:.6f},{beta_sigma:.6f},{R2:.6f}]\"\n        all_results.append(case_result_str)\n\n    # Final print statement in the exact required format.\n    print(f\"[[{case_result_str} for case_result_str in all_results]]\".replace(\"'\",\"\"))\n\nsolve()\n```"
        },
        {
            "introduction": "Building a predictive model is only half the battle; rigorously evaluating its performance is equally critical for its reliable application. This practice delves into the nuances of model validation by asking you to calculate and compare three different error metrics: the Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and Median Absolute Error. By analyzing a set of residuals that includes a realistic outlier , you will develop a practical understanding of how each metric responds differently to large errors and learn to choose the most appropriate statistic to reflect your model's predictive power fairly.",
            "id": "3860364",
            "problem": "A Quantitative Structure–Activity Relationships (QSAR) model is trained to predict inhibitory potency reported as $ \\mathrm{pIC}_{50} $ for a chemical series. The experimental endpoint $ \\mathrm{pIC}_{50} $ is dimensionless. For a held-out test set of $ n = 20 $ compounds, the model produces predicted values $ \\hat{y}_i $ and corresponding residuals $ r_i = y_i - \\hat{y}_i $ given by\n$$\n\\{0.07,\\,-0.12,\\,0.09,\\,-0.05,\\,0.11,\\,-0.08,\\,0.10,\\,0.06,\\,-0.07,\\,0.13,\\,-0.04,\\,0.15,\\,0.14,\\,-0.06,\\,0.05,\\,-0.09,\\,0.08,\\,-0.03,\\,0.12,\\,-1.50\\}.\n$$\nAssume residuals are independent and identically distributed across compounds, and that the measurement noise in $ \\mathrm{pIC}_{50} $ is bounded for the majority of compounds but occasional annotation errors may induce rare large-magnitude residuals. Using foundational definitions of error aggregation in predictive modeling, compute the root mean squared error (RMSE), the mean absolute error (MAE), and the median absolute error for this test set. Then, justify from first principles when each metric is robust to outliers or skewed residuals in QSAR datasets, identifying the error distributional assumptions under which each metric is preferable. Round all three numerical answers to four significant figures. Express each metric in the same units as $ \\mathrm{pIC}_{50} $ (dimensionless).",
            "solution": "The problem statement is evaluated as scientifically grounded, well-posed, and objective. All necessary data and definitions for the computation of standard statistical error metrics are provided. The context is a valid application of predictive modeling in computational chemical biology. The problem is therefore deemed valid and a solution will be provided.\n\nThe task is to compute three error metrics for a given set of residuals from a Quantitative Structure–Activity Relationships (QSAR) model and to provide a justification for the use of each metric based on its statistical properties. The endpoint, $ \\mathrm{pIC}_{50} $, is dimensionless, and therefore the residuals and all calculated error metrics will also be dimensionless.\n\nThe set of $ n = 20 $ residuals is given by $ R = \\{r_i\\}_{i=1}^{20} $:\n$$\n\\{0.07,\\,-0.12,\\,0.09,\\,-0.05,\\,0.11,\\,-0.08,\\,0.10,\\,0.06,\\,-0.07,\\,0.13,\\,-0.04,\\,0.15,\\,0.14,\\,-0.06,\\,0.05,\\,-0.09,\\,0.08,\\,-0.03,\\,0.12,\\,-1.50\\}\n$$\nThe outlier is the residual $r_{20} = -1.50$.\n\nFirst, we define and compute the requested metrics.\n\n**1. Root Mean Squared Error (RMSE)**\n\nThe RMSE is the square root of the mean of the squared errors. It is defined as:\n$$\n\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} r_i^2}\n$$\nWe first compute the sum of the squares of the residuals:\n\\begin{align*}\n\\sum_{i=1}^{20} r_i^2 = (0.07)^2 + (-0.12)^2 + (0.09)^2 + (-0.05)^2 + (0.11)^2 + (-0.08)^2 + (0.10)^2 + (0.06)^2 + (-0.07)^2 \\\\\n\\quad + (0.13)^2 + (-0.04)^2 + (0.15)^2 + (0.14)^2 + (-0.06)^2 + (0.05)^2 + (-0.09)^2 + (0.08)^2 + (-0.03)^2 \\\\\n\\quad + (0.12)^2 + (-1.50)^2 \\\\\n= 0.0049 + 0.0144 + 0.0081 + 0.0025 + 0.0121 + 0.0064 + 0.0100 + 0.0036 + 0.0049 + 0.0169 \\\\\n\\quad + 0.0016 + 0.0225 + 0.0196 + 0.0036 + 0.0025 + 0.0081 + 0.0064 + 0.0009 + 0.0144 + 2.25 \\\\\n= 0.1634 + 2.25 = 2.4134\n\\end{align*}\nThe mean squared error (MSE) is:\n$$\n\\text{MSE} = \\frac{2.4134}{20} = 0.12067\n$$\nThe RMSE is the square root of the MSE:\n$$\n\\text{RMSE} = \\sqrt{0.12067} \\approx 0.347375876...\n$$\nRounding to four significant figures, we get $\\text{RMSE} = 0.3474$.\n\n**2. Mean Absolute Error (MAE)**\n\nThe MAE is the mean of the absolute values of the errors. It is defined as:\n$$\n\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |r_i|\n$$\nWe first compute the sum of the absolute values of the residuals:\n\\begin{align*}\n\\sum_{i=1}^{20} |r_i| = |0.07| + |-0.12| + |0.09| + |-0.05| + |0.11| + |-0.08| + |0.10| + |0.06| + |-0.07| + |0.13| \\\\\n\\quad + |-0.04| + |0.15| + |0.14| + |-0.06| + |0.05| + |-0.09| + |0.08| + |-0.03| + |0.12| + |-1.50| \\\\\n= 0.07 + 0.12 + 0.09 + 0.05 + 0.11 + 0.08 + 0.10 + 0.06 + 0.07 + 0.13 + 0.04 + 0.15 + 0.14 \\\\\n\\quad + 0.06 + 0.05 + 0.09 + 0.08 + 0.03 + 0.12 + 1.50 \\\\\n= 1.64 + 1.50 = 3.14\n\\end{align*}\nThe MAE is:\n$$\n\\text{MAE} = \\frac{3.14}{20} = 0.157\n$$\nRounding to four significant figures, we get $\\text{MAE} = 0.1570$.\n\n**3. Median Absolute Error**\n\nThe Median Absolute Error is the median of the absolute values of the errors. It is defined as:\n$$\n\\text{MedianAE} = \\text{median}(\\{|r_i|\\}_{i=1}^n)\n$$\nFirst, we list the absolute values of the residuals:\n$$\n\\{0.07,\\,0.12,\\,0.09,\\,0.05,\\,0.11,\\,0.08,\\,0.10,\\,0.06,\\,0.07,\\,0.13,\\,0.04,\\,0.15,\\,0.14,\\,0.06,\\,0.05,\\,0.09,\\,0.08,\\,0.03,\\,0.12,\\,1.50\\}\n$$\nNext, we sort this list in ascending order:\n$$\n\\{0.03,\\,0.04,\\,0.05,\\,0.05,\\,0.06,\\,0.06,\\,0.07,\\,0.07,\\,0.08,\\,{\\bf 0.08},\\,{\\bf 0.09},\\,0.09,\\,0.10,\\,0.11,\\,0.12,\\,0.12,\\,0.13,\\,0.14,\\,0.15,\\,1.50\\}\n$$\nSince there are $n=20$ values (an even number), the median is the average of the two middle values, which are the 10th and 11th values in the sorted list.\n$$\n\\text{MedianAE} = \\frac{0.08 + 0.09}{2} = \\frac{0.17}{2} = 0.085\n$$\nRounding to four significant figures, we get $\\text{MedianAE} = 0.08500$.\n\n**Justification of Metric Choice**\n\nThe choice of an error metric depends on the assumed distribution of the errors and the desired properties of the assessment, particularly robustness to outliers.\n\n**Root Mean Squared Error (RMSE)** is associated with the $L_2$ norm. Minimizing the sum of squared errors is equivalent to finding the maximum likelihood estimate for a model assuming the errors are independent and identically distributed (i.i.d.) according to a Gaussian (normal) distribution, $r_i \\sim \\mathcal{N}(0, \\sigma^2)$. The squaring operation gives disproportionately high weight to large errors. In this dataset, the residual $-1.50$ contributes $(-1.50)^2 = 2.25$ to the sum of squares, which is $2.25 / 0.1634 \\approx 13.8$ times the sum of all other $19$ squared residuals. This extreme sensitivity makes RMSE a non-robust metric. It is preferable only when large errors are considered exceptionally detrimental and must be heavily penalized, and when the underlying error distribution is believed to be Gaussian, without heavy tails or outliers. In the context of QSAR, if an outlier is a genuine, albeit rare, instance of poor model performance, RMSE would rightly flag it. However, if outliers stem from data annotation or experimental errors, as suggested in the problem, RMSE provides a distorted and pessimistic view of the model's typical performance.\n\n**Mean Absolute Error (MAE)** is associated with the $L_1$ norm. Minimizing the sum of absolute errors is equivalent to finding the maximum likelihood estimate assuming the errors are i.i.d. according to a Laplace distribution, $r_i \\sim \\text{Laplace}(0, b)$. This distribution has heavier tails than the Gaussian distribution. MAE gives a linear penalty to errors, meaning its value scales directly with the magnitude of the error. The contribution of the outlier $-1.50$ to the sum of absolute errors is $|-1.50|=1.50$, which is less dominant than in the RMSE case. MAE is therefore considered more robust to outliers than RMSE. It is preferable when the error distribution is suspected to be heavy-tailed or when the dataset contains outliers that should not disproportionately influence the overall error measure. This aligns well with the problem description where occasional large-magnitude residuals due to annotation errors are expected.\n\n**Median Absolute Error**, as a non-parametric statistic, does not rely on a specific parametric error distribution assumption. The median is a robust measure of central tendency, as it is defined by the rank order of the data, not the magnitude of extreme values. In our dataset, the median of the absolute errors is determined by the 10th and 11th values in the sorted list, and the extreme value of $1.50$ has no more influence on the result than if it had been, for example, $0.16$. This makes the Median Absolute Error exceptionally robust to outliers. It is the most suitable metric when the primary goal is to understand the typical performance of the model on the majority of the compounds, while intentionally ignoring the influence of rare, large errors that may be artifacts of the data collection process. Given the problem states that \"occasional annotation errors may induce rare large-magnitude residuals\", the Median Absolute Error provides the most faithful assessment of the model's predictive power for the bulk of the chemical series.\n\nIn summary, for this specific QSAR problem, the high value of RMSE ($0.3474$) compared to MAE ($0.1570$) is driven almost entirely by the single outlier. The Median Absolute Error ($0.08500$) is much smaller still, indicating that for at least half of the compounds, the model's prediction error is less than $0.085$ $\\mathrm{pIC}_{50}$ units. This suggests the model performs well on typical compounds, a fact obscured by RMSE.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 0.3474  0.1570  0.08500 \\end{pmatrix}}\n$$"
        }
    ]
}