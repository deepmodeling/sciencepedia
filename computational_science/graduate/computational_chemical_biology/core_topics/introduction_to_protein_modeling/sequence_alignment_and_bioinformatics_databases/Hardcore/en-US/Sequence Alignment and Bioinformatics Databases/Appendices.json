{
    "hands_on_practices": [
        {
            "introduction": "To truly master sequence analysis, one must begin with its foundational algorithm. This first practice challenges you to manually compute a local alignment using the Smith-Waterman dynamic programming method . By populating the scoring matrix and tracing back the optimal path, you will gain a concrete understanding of how scoring schemes work and why the algorithm's signature zero-reset is critical for identifying conserved regions within larger, divergent sequences.",
            "id": "3863057",
            "problem": "In computational chemical biology, local sequence alignment underpins search and retrieval tasks in bioinformatics databases such as the National Center for Biotechnology Information (NCBI) and the Universal Protein Resource (UniProt). Local alignment identifies the highest-scoring subsequences between two biological polymers based on a biologically informed scoring scheme, and its dynamic programming implementation uses a zero-reset to prevent low-scoring regions from degrading otherwise meaningful local matches.\n\nConsider two short Deoxyribonucleic Acid (DNA) sequences encoded as nucleotides:\n$$\nX = (\\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T}, \\mathrm{A}, \\mathrm{G}, \\mathrm{T}),\n\\quad\nY = (\\mathrm{G}, \\mathrm{A}, \\mathrm{G}, \\mathrm{T}, \\mathrm{A}, \\mathrm{C}, \\mathrm{T}).\n$$\nUse a biologically motivated scoring function based on chemical classes of nucleotides: adenine and guanine are purines, cytosine and thymine are pyrimidines. Define a substitution score $s(\\alpha,\\beta)$ for any $\\alpha,\\beta \\in \\{\\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T}\\}$ by\n- identical nucleotides: $s(\\alpha,\\alpha) = +3$,\n- transitions (purine $\\leftrightarrow$ purine, $\\mathrm{A} \\leftrightarrow \\mathrm{G}$; pyrimidine $\\leftrightarrow$ pyrimidine, $\\mathrm{C} \\leftrightarrow \\mathrm{T}$): $s(\\alpha,\\beta) = -1$ for $\\alpha \\neq \\beta$,\n- transversions (purine $\\leftrightarrow$ pyrimidine, all other mismatches): $s(\\alpha,\\beta) = -3$,\nand use a linear gap penalty $d = -2$ for insertions or deletions.\n\nApply the principles of local alignment with dynamic programming and zero-reset to compute an explicit example of a high-scoring local alignment between $X$ and $Y$, and explain where and why a zero-reset occurs in the computation to enable detection of high-scoring subsequences that would otherwise be obscured by low-scoring flanking regions. Report, as your final answer, the maximal local alignment score under this scoring scheme. No rounding is required. Express the final answer as a real number without units.",
            "solution": "The problem requires the computation of the maximal local alignment score between two Deoxyribonucleic Acid (DNA) sequences, $X$ and $Y$, using the Smith-Waterman dynamic programming algorithm. This algorithm is fundamental to bioinformatics for finding regions of similarity between sequences.\n\nFirst, we establish the given parameters. The two sequences are:\n$$\nX = (\\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T}, \\mathrm{A}, \\mathrm{G}, \\mathrm{T}) \\quad \\text{of length } m=7\n$$\n$$\nY = (\\mathrm{G}, \\mathrm{A}, \\mathrm{G}, \\mathrm{T}, \\mathrm{A}, \\mathrm{C}, \\mathrm{T}) \\quad \\text{of length } n=7\n$$\nThe scoring scheme is based on the chemical classes of nucleotides. Adenine (A) and Guanine (G) are purines. Cytosine (C) and Thymine (T) are pyrimidines. The substitution score $s(\\alpha, \\beta)$ is defined as:\n- $s(\\alpha, \\alpha) = +3$ for identical nucleotides.\n- $s(\\alpha, \\beta) = -1$ for transitions (purine $\\leftrightarrow$ purine, pyrimidine $\\leftrightarrow$ pyrimidine), where $\\alpha \\neq \\beta$.\n- $s(\\alpha, \\beta) = -3$ for transversions (purine $\\leftrightarrow$ pyrimidine).\nThe linear gap penalty is $d = -2$.\n\nBased on these rules, we can construct the substitution scoring matrix, which we will denote as $S$:\n$$\nS =\n\\bordermatrix{  \\mathrm{A}  \\mathrm{C}  \\mathrm{G}  \\mathrm{T} \\cr\n\\mathrm{A}  +3  -3  -1  -3 \\cr\n\\mathrm{C}  -3  +3  -3  -1 \\cr\n\\mathrm{G}  -1  -3  +3  -3 \\cr\n\\mathrm{T}  -3  -1  -3  +3 \\cr\n}\n$$\n\nThe Smith-Waterman algorithm uses a dynamic programming matrix, let's call it $H$, of size $(n+1) \\times (m+1)$, which is $8 \\times 8$ in this case. The entry $H_{i,j}$ stores the maximum score of any alignment ending at position $i$ of sequence $Y$ and position $j$ of sequence $X$. The matrix is initialized with $H_{i,0} = 0$ for $i \\in [0, n]$ and $H_{0,j} = 0$ for $j \\in [0, m]$.\n\nEach cell $H_{i,j}$ for $i > 0$ and $j > 0$ is computed using the following recurrence relation, which includes the crucial zero-reset:\n$$\nH_{i,j} = \\max\n\\begin{cases}\n    0  \\text{(start of a new alignment)} \\\\\n    H_{i-1, j-1} + s(Y_i, X_j)  \\text{(match/mismatch)} \\\\\n    H_{i-1, j} + d  \\text{(deletion in } X, \\text{ gap in } X) \\\\\n    H_{i, j-1} + d  \\text{(insertion in } X, \\text{ gap in } Y)\n\\end{cases}\n$$\nwhere $X_j$ is the $j$-th nucleotide of $X$ and $Y_i$ is the $i$-th nucleotide of $Y$.\n\nWe now populate the matrix $H$. The columns correspond to sequence $X$ and the rows to sequence $Y$.\n\n$$\nH =\n\\bordermatrix{\n \\emptyset  \\mathrm{A}_{1}  \\mathrm{C}_{2}  \\mathrm{G}_{3}  \\mathrm{T}_{4}  \\mathrm{A}_{5}  \\mathrm{G}_{6}  \\mathrm{T}_{7} \\cr\n\\emptyset  0  0  0  0  0  0  0  0 \\cr\n\\mathrm{G}_{1}  0  0  0  3  1  0  3  1 \\cr\n\\mathrm{A}_{2}  0  3  1  1  0  4  2  0 \\cr\n\\mathrm{G}_{3}  0  1  0  4  2  2  7  5 \\cr\n\\mathrm{T}_{4}  0  0  0  2  7  5  5  10 \\cr\n\\mathrm{A}_{5}  0  3  1  0  5  10  8  8 \\cr\n\\mathrm{C}_{6}  0  1  6  4  3  8  7  7 \\cr\n\\mathrm{T}_{7}  0  0  4  3  7  6  5  10 \\cr\n}\n$$\n\nThe maximal score in the matrix $H$ is the maximal local alignment score. Inspecting the matrix, we find the maximum value is $10$. This score appears at three locations: $H_{4,7}$, $H_{5,5}$, and $H_{7,7}$. This indicates that there are at least three distinct local alignments that achieve this maximal score.\n\nThe problem requires an explicit example of a high-scoring local alignment. We can find one by performing a traceback from one of the maximal score cells, for instance $H_{5,5} = 10$.\n1.  Start at $H_{5,5} = 10$. This score was obtained from $H_{4,4} + s(Y_5, X_5) = H_{4,4} + s(\\mathrm{A}, \\mathrm{A}) = 7 + 3 = 10$. This corresponds to a diagonal move, aligning $Y_5=\\mathrm{A}$ with $X_5=\\mathrm{A}$. We move to $H_{4,4}$.\n2.  From $H_{4,4} = 7$. This score came from $H_{3,3} + s(Y_4, X_4) = H_{3,3} + s(\\mathrm{T}, \\mathrm{T}) = 4 + 3 = 7$. This is a diagonal move, aligning $Y_4=\\mathrm{T}$ with $X_4=\\mathrm{T}$. We move to $H_{3,3}$.\n3.  From $H_{3,3} = 4$. This score came from $H_{2,2} + s(Y_3, X_3) = H_{2,2} + s(\\mathrm{G}, \\mathrm{G}) = 1 + 3 = 4$. This is a diagonal move, aligning $Y_3=\\mathrm{G}$ with $X_3=\\mathrm{G}$. We move to $H_{2,2}$.\n4.  From $H_{2,2} = 1$. This score was from $H_{2,1} + d = 3 - 2 = 1$. This is a left move, which corresponds to aligning $X_2=\\mathrm{C}$ with a gap in sequence $Y$. We move to $H_{2,1}$.\n5.  From $H_{2,1} = 3$. This score came from $H_{1,0} + s(Y_2, X_1) = H_{1,0} + s(\\mathrm{A}, \\mathrm{A}) = 0 + 3 = 3$. This is a diagonal move, aligning $Y_2=\\mathrm{A}$ with $X_1=\\mathrm{A}$. We move to $H_{1,0}$.\n6.  The traceback terminates at $H_{1,0} = 0$.\n\nReconstructing the alignment from the traceback (in reverse order):\n$$\n\\begin{array}{cccccc}\n\\text{X:}  \\mathrm{A}  \\mathrm{C}  \\mathrm{G}  \\mathrm{T}  \\mathrm{A} \\\\\n\\text{Y:}  \\mathrm{A}  -  \\mathrm{G}  \\mathrm{T}  \\mathrm{A}\n\\end{array}\n$$\nThe score of this alignment is $s(\\mathrm{A},\\mathrm{A}) + d + s(\\mathrm{G},\\mathrm{G}) + s(\\mathrm{T},\\mathrm{T}) + s(\\mathrm{A},\\mathrm{A}) = 3 + (-2) + 3 + 3 + 3 = 10$, which confirms our calculation. This alignment involves the subsequences $X[1..5] = (\\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T}, \\mathrm{A})$ and $Y[2..5] = (\\mathrm{A}, \\mathrm{G}, \\mathrm{T}, \\mathrm{A})$.\n\nThe zero-reset is the key feature that distinguishes local from global alignment. A zero-reset occurs whenever the scores from extending a previous alignment (diagonally, from above, or from the left) are all negative. In such a case, the algorithm \"forgets\" the low-scoring extensions and starts a new potential local alignment from that point with a score of $0$.\n\nAn example of a zero-reset can be observed at cell $H_{1,1}$.\n$$\nH_{1,1} = \\max \\begin{cases}\n    0 \\\\\n    H_{0,0} + s(Y_1, X_1) = 0 + s(\\mathrm{G}, \\mathrm{A}) = -1 \\\\\n    H_{0,1} + d = 0 - 2 = -2 \\\\\n    H_{1,0} + d = 0 - 2 = -2\n\\end{cases}\n= \\max\\{0, -1, -2, -2\\} = 0\n$$\nHere, aligning the prefixes $X[1]=\\mathrm{A}$ and $Y[1]=\\mathrm{G}$ results in a negative score ($s(\\mathrm{A},\\mathrm{G}) = -1$), as does starting with a gap ($d=-2$). Because all possibilities for extending an alignment into this cell result in a negative cumulative score, the algorithm resets the score to $0$. This mechanism prevents low-scoring initial regions (like the A/G mismatch at the start of the sequences) from penalizing and thus obscuring a high-scoring local alignment that might occur later in the sequences, which is precisely the alignment we found starting at $X_1$ and $Y_2$.\n\nThe maximal local alignment score is the highest value found in the matrix $H$.\n$$\nS_{\\text{max}} = \\max_{i,j} H_{i,j} = 10\n$$",
            "answer": "$$\n\\boxed{10}\n$$"
        },
        {
            "introduction": "Effective sequence alignment depends not only on a robust algorithm but also on high-quality input data. This exercise shifts our focus to the probabilistic nature of modern sequencing by exploring Phred quality scores, the industry standard for quantifying base-calling uncertainty . You will first derive the core logarithmic relationship between error probability $p$ and quality score $Q$, and then apply this knowledge to quantify the improvement in data reliability gained from a common preprocessing step: quality trimming.",
            "id": "3863083",
            "problem": "A Next-Generation Sequencing (NGS) instrument outputs base calls with associated Phred quality scores, intended to quantify the probability of an incorrect base call. Consider a single-end DNA read destined for alignment to a reference genome retrieved from a curated bioinformatics database. You will derive the mapping from the error probability to the quality score from first principles and then use this mapping to compute the expected number of base-calling errors before and after suffix quality trimming.\n\nStart from the following foundational premises:\n- The Phred quality score $Q$ is a monotonic transformation of the base-calling error probability $p \\in (0,1]$, chosen to reflect the empirical observation that multiplicative changes in $p$ correspond to additive changes in $Q$ on a base-$10$ logarithmic scale. Specifically, decreasing $p$ by a factor of $10$ increases $Q$ by $10$.\n- The mapping is continuous, strictly decreasing in $p$, and normalized such that a base-call that is certain to be wrong has $p=1$ and maps to $Q=0$.\n- Individual base-call errors along a read can be modeled as independent Bernoulli trials with position-specific error probabilities $\\{p_i\\}$, and the expected total number of errors is the sum $\\sum_i p_i$ by linearity of expectation.\n\nTasks:\n1. Derive the functional relation between the Phred quality score $Q$ and the error probability $p$ consistent with the premises above.\n2. Consider a read of length $20$ bases whose Phred quality scores along the read (from $5'$ to $3'$) are given by the vector \n$$\n(35,\\,35,\\,30,\\,30,\\,28,\\,28,\\,25,\\,25,\\,22,\\,22,\\,20,\\,18,\\,18,\\,15,\\,15,\\,12,\\,12,\\,10,\\,10,\\,8).\n$$\nUsing your derived relation, compute the expected number of base-calling errors for the full read, denoted $E_{\\mathrm{full}}$.\n3. Define suffix quality trimming at threshold $Q_{\\mathrm{thr}}$ as removing bases from the $3'$ end until the last retained base satisfies $Q \\ge Q_{\\mathrm{thr}}$. For threshold $Q_{\\mathrm{thr}}=20$, compute the expected number of base-calling errors for the trimmed read, denoted $E_{\\mathrm{trim}}$.\n4. Report the reduction in expected errors due to trimming, $\\Delta E = E_{\\mathrm{full}} - E_{\\mathrm{trim}}$. Round your answer to four significant figures. Express the final value of $\\Delta E$ as a decimal.",
            "solution": "The problem is validated as scientifically grounded, well-posed, and objective. It is based on standard principles of bioinformatics (Phred quality scores) and probability theory. All necessary information is provided, and the questions are unambiguous.\n\nThe solution proceeds in four parts as requested by the problem statement.\n\n**1. Derivation of the Phred Quality Score Relation**\n\nThe Phred quality score, $Q$, is defined as a function of the base-calling error probability, $p \\in (0,1]$. Let this function be $Q(p)$. The problem specifies three properties for this function:\n- A. A multiplicative change in $p$ corresponds to an additive change in $Q$. Specifically, $Q(p/10) = Q(p) + 10$.\n- B. The function is normalized such that $Q(1) = 0$.\n- C. The function is continuous and strictly decreasing for $p \\in (0,1]$.\n\nProperty A suggests a logarithmic relationship. Let us propose a general form based on the base-10 logarithm, $Q(p) = A \\log_{10}(p) + B$, where $A$ and $B$ are constants to be determined.\n\nUsing property A:\n$$\nQ(p/10) = A \\log_{10}(p/10) + B\n$$\nUsing the properties of logarithms, $\\log_{10}(p/10) = \\log_{10}(p) - \\log_{10}(10) = \\log_{10}(p) - 1$.\n$$\nQ(p/10) = A (\\log_{10}(p) - 1) + B = A \\log_{10}(p) - A + B\n$$\nWe are given that $Q(p/10) = Q(p) + 10$. Substituting the proposed functional form:\n$$\nA \\log_{10}(p) - A + B = (A \\log_{10}(p) + B) + 10\n$$\n$$\n-A = 10 \\implies A = -10\n$$\nSo, the function has the form $Q(p) = -10 \\log_{10}(p) + B$.\n\nNext, we use the normalization condition (Property B), $Q(1) = 0$.\n$$\nQ(1) = -10 \\log_{10}(1) + B = 0\n$$\nSince $\\log_{10}(1) = 0$, this simplifies to $B = 0$.\n\nThus, the functional relation between $Q$ and $p$ is:\n$$\nQ(p) = -10 \\log_{10}(p)\n$$\nThis relation also satisfies Property C. The function is continuous for $p \\in (0,1]$. Its derivative, $\\frac{dQ}{dp} = \\frac{-10}{p \\ln(10)}$, is negative for all $p > 0$, confirming that $Q(p)$ is a strictly decreasing function of $p$.\n\nFor the subsequent calculations, it is necessary to express the error probability $p$ as a function of the quality score $Q$. Rearranging the equation:\n$$\n-\\frac{Q}{10} = \\log_{10}(p)\n$$\n$$\np(Q) = 10^{-Q/10}\n$$\n\n**2. Expected Errors in the Full Read ($E_{\\mathrm{full}}$)**\n\nThe expected number of errors in a read is the sum of the individual error probabilities for each base, $E = \\sum_i p_i$. The read has a length of $L=20$ bases, with quality scores given by the vector:\n$$\n\\mathbf{Q} = (35, 35, 30, 30, 28, 28, 25, 25, 22, 22, 20, 18, 18, 15, 15, 12, 12, 10, 10, 8)\n$$\nThe expected number of errors for the full read, $E_{\\mathrm{full}}$, is the sum of the error probabilities corresponding to each quality score:\n$$\nE_{\\mathrm{full}} = \\sum_{i=1}^{20} p_i = \\sum_{i=1}^{20} 10^{-Q_i/10}\n$$\nThe sum can be computed by grouping identical quality scores:\n$$\nE_{\\mathrm{full}} = 2 \\times 10^{-35/10} + 2 \\times 10^{-30/10} + 2 \\times 10^{-28/10} + 2 \\times 10^{-25/10} + 2 \\times 10^{-22/10} + 1 \\times 10^{-20/10} + 2 \\times 10^{-18/10} + 2 \\times 10^{-15/10} + 2 \\times 10^{-12/10} + 2 \\times 10^{-10/10} + 1 \\times 10^{-8/10}\n$$\n$$\nE_{\\mathrm{full}} = 2 \\times 10^{-3.5} + 2 \\times 10^{-3.0} + 2 \\times 10^{-2.8} + 2 \\times 10^{-2.5} + 2 \\times 10^{-2.2} + 10^{-2.0} + 2 \\times 10^{-1.8} + 2 \\times 10^{-1.5} + 2 \\times 10^{-1.2} + 2 \\times 10^{-1.0} + 10^{-0.8}\n$$\nCalculating the terms and summing them gives:\n$$\nE_{\\mathrm{full}} \\approx 0.00063246 + 0.002 + 0.00316979 + 0.00632456 + 0.01261915 + 0.01 + 0.03169786 + 0.06324555 + 0.12619147 + 0.2 + 0.15848932 \\approx 0.61437015\n$$\n\n**3. Expected Errors in the Trimmed Read ($E_{\\mathrm{trim}}$)**\n\nSuffix quality trimming is performed with a threshold $Q_{\\mathrm{thr}} = 20$. The procedure is to remove bases from the $3'$ end until the last retained base has a quality score $Q \\ge Q_{\\mathrm{thr}}$.\nWe inspect the quality score vector $\\mathbf{Q}$ from right to left (from index $20$ down to $1$).\n- $Q_{20}=8  20$\n- $Q_{19}=10  20$\n- $Q_{18}=10  20$\n- ...\n- $Q_{12}=18  20$\n- $Q_{11}=20 \\ge 20$\n\nThe last base that satisfies the condition is at index $11$. Therefore, all bases from index $12$ to $20$ are trimmed off. The trimmed read consists of the first $11$ bases, with quality scores:\n$$\n\\mathbf{Q}_{\\mathrm{trim}} = (35, 35, 30, 30, 28, 28, 25, 25, 22, 22, 20)\n$$\nThe expected number of errors for the trimmed read, $E_{\\mathrm{trim}}$, is the sum of the error probabilities for these $11$ bases:\n$$\nE_{\\mathrm{trim}} = \\sum_{i=1}^{11} 10^{-Q_i/10}\n$$\n$$\nE_{\\mathrm{trim}} = 2 \\times 10^{-3.5} + 2 \\times 10^{-3.0} + 2 \\times 10^{-2.8} + 2 \\times 10^{-2.5} + 2 \\times 10^{-2.2} + 10^{-2.0}\n$$\nCalculating this sum:\n$$\nE_{\\mathrm{trim}} \\approx 0.00063246 + 0.002 + 0.00316979 + 0.00632456 + 0.01261915 + 0.01 \\approx 0.03474594\n$$\n\n**4. Reduction in Expected Errors ($\\Delta E$)**\n\nThe reduction in expected errors due to trimming is the difference between the expected errors of the full read and the trimmed read:\n$$\n\\Delta E = E_{\\mathrm{full}} - E_{\\mathrm{trim}}\n$$\nThis value is equivalent to the sum of the error probabilities of the bases that were trimmed. The trimmed bases are those from index $12$ to $20$, with quality scores $(18, 18, 15, 15, 12, 12, 10, 10, 8)$.\n$$\n\\Delta E = \\sum_{i=12}^{20} 10^{-Q_i/10} = 2 \\times 10^{-1.8} + 2 \\times 10^{-1.5} + 2 \\times 10^{-1.2} + 2 \\times 10^{-1.0} + 10^{-0.8}\n$$\nUsing the values from the previous calculations:\n$$\n\\Delta E = E_{\\mathrm{full}} - E_{\\mathrm{trim}} \\approx 0.61437015 - 0.03474594 \\approx 0.57962421\n$$\nThe problem requires this value to be rounded to four significant figures. The first four significant figures are $5, 7, 9, 6$. The fifth digit is $2$, so we round down.\n$$\n\\Delta E \\approx 0.5796\n$$\nThis is the reduction in the expected number of sequencing errors achieved by trimming the low-quality tail of the read.",
            "answer": "$$\n\\boxed{0.5796}\n$$"
        },
        {
            "introduction": "While dynamic programming is foundational, its quadratic complexity is prohibitive for searching today's massive genomic databases. This advanced exercise introduces the principles behind modern, high-speed alignment tools by focusing on the Ferragina-Manzini (FM) index, a compressed data structure that enables rapid string matching . You will reason through the logic of a backtracking search for approximate matches that uses the FM-index's `backward_search` operation and employs branch-and-bound pruning to remain efficient, mirroring the core strategy of aligners like Bowtie and BWA.",
            "id": "3863004",
            "problem": "You are to implement an approximate substring search over a DNA-like string using the Ferragina–Manzini (FM) index, a compressed full-text index widely used for large-scale sequence alignment in bioinformatics databases such as curated genomic repositories. The goal is to search a query string against a reference string allowing up to $k$ mismatches (Hamming distance only; no insertions or deletions), with branch-and-bound pruning guided by a cumulative alignment score threshold.\n\nFoundational base and constraints:\n- Consider a finite alphabet $\\Sigma$ with a special terminal sentinel character $\"\\$\"$ that is lexicographically smaller than any symbol in $\\Sigma$. The reference string is augmented as $S = R \\, \\Vert \\, \"\\$\", where $R$ is the original reference and $\\Vert$ denotes concatenation.\n- Use the suffix array and the Burrows–Wheeler transform as the basis to construct the Ferragina–Manzini (FM) index. The FM index supports backward search by mapping a current suffix interval to the next interval given a prepended character, without storing the entire set of substrings explicitly.\n- Define a per-position alignment scoring function such that a match contributes $m$ and a mismatch contributes $-p$, where $m  0$ and $p  0$. The cumulative score over the query must meet or exceed a threshold $\\tau$ to be reported.\n- Implement pruning via branch-and-bound using the following logic: suppose the search has consumed $d$ symbols of a query of length $L$, and currently has cumulative score $s$. Even if all remaining $L - d$ symbols match, the maximum achievable final score is $s + (L - d) \\cdot m$. If $s + (L - d) \\cdot m  \\tau$, prune the branch (do not continue the search along that path). Also prune if the number of mismatches used exceeds $k$, or if the FM-index backward step yields an empty interval.\n- Report only 0-based starting positions in the original reference $R$, not in the augmented string $S$. Positions that would overrun the end of $R$ are invalid and should be excluded.\n- All searches are mismatches-only (Hamming distance); do not consider insertions or deletions.\n\nProgram requirements:\n- Construct the FM index of the augmented reference $S$ and use it to implement a depth-first backtracking search over the query from right to left. At each depth, branch on all characters in $\\Sigma \\setminus \\{\"\\$\"\\}$, counting mismatches and updating the cumulative score accordingly, and use the FM index to update the suffix interval via backward search.\n- Use branch-and-bound pruning based on the cumulative score threshold $\\tau$ as described above, together with the mismatch budget $k$ and empty-interval pruning.\n- For each test case, return the sorted list of distinct 0-based starting positions in $R$ where the query can align with at most $k$ mismatches and with cumulative score at least $\\tau$.\n\nTest suite:\nImplement your program to process the following fixed test cases, each specified as a tuple $(R, Q, k, m, p, \\tau)$ where $R$ is the reference string over $\\{A, C, G, T\\}$, $Q$ is the query string over the same alphabet, $k$ is the mismatch budget, $m$ is the match reward, $p$ is the mismatch penalty, and $\\tau$ is the cumulative score threshold. For this problem, angles and physical units are not applicable. All numeric answers must be represented as integers or floats.\n\nUse the following test cases:\n1. $(R, Q, k, m, p, \\tau) = (\\text{\"ACGTCGACGTTACG\"}, \\text{\"CGACG\"}, 1, 1.0, 1.0, 4.0)$\n2. $(R, Q, k, m, p, \\tau) = (\\text{\"ACGACGACG\"}, \\text{\"ACG\"}, 0, 1.0, 1.0, 3.0)$\n3. $(R, Q, k, m, p, \\tau) = (\\text{\"ACGTACGT\"}, \\text{\"ACGT\"}, 2, 1.0, 1.0, 5.0)$\n4. $(R, Q, k, m, p, \\tau) = (\\text{\"GGGGACGTAC\"}, \\text{\"ACGT\"}, 2, 1.0, 2.0, 3.0)$\n5. $(R, Q, k, m, p, \\tau) = (\\text{\"AAAAAA\"}, \\text{\"AAA\"}, 10, 1.0, 1.0, 2.5)$\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets with no spaces, where each element corresponds to one test case and is itself a bracketed comma-separated list of 0-based integer positions. For example, a valid output looks like $[[x_1,x_2],[y_1],[],[z_1,z_2],[w_1,w_2,w_3]]$.\n\nThe output values for each test case must be lists of integers. The program must be completely self-contained, require no input, and must not access external files or networks.",
            "solution": "The problem requires the implementation of an approximate substring search algorithm over a DNA sequence. The search must identify occurrences of a query string $Q$ within a reference string $R$ that satisfy two conditions: the Hamming distance is at most $k$, and the cumulative alignment score is at least $\\tau$. The search is to be implemented using the Ferragina–Manzini (FM) index, a compressed full-text data structure, combined with a branch-and-bound pruning strategy.\n\nThe solution is developed in three main stages:\n1.  Construction of the FM-index for the reference string.\n2.  Implementation of a recursive, depth-first backtracking search algorithm that uses the FM-index.\n3.  Integration of a branch-and-bound pruning mechanism based on mismatch counts and the score threshold.\n\n### 1. FM-Index Construction\n\nThe FM-index is built upon the Burrows-Wheeler Transform (BWT) and associated data structures. The construction process begins with the reference string $R$.\n\n**String Augmentation**: First, the reference string $R$ is augmented with a special sentinel character `\"$\"` that is lexicographically smaller than any other character in the alphabet $\\Sigma = \\{A, C, G, T\\}$. The augmented string is $S = R \\Vert \"\\$\"$, where $\\Vert$ denotes concatenation. Let $n = |S|$.\n\n**Suffix Array ($SA$)**: The suffix array, $SA$, is an array of integers of length $n$. It stores the starting positions of all suffixes of $S$ after they have been sorted lexicographically. That is, the suffix $S[SA[0]..]$ is the lexicographically smallest suffix, $S[SA[1]..]$ is the second smallest, and so on.\n\n**Burrows-Wheeler Transform ($L$)**: The BWT of $S$ is a string $L$ of length $n$. For each $i \\in [0, n-1]$, the character $L[i]$ is the one that precedes the suffix starting at $SA[i]$ in the original string $S$. Specifically, $L[i] = S[SA[i] - 1]$. If $SA[i] = 0$, the preceding character is taken to be the last character of $S$, which is the sentinel `\"$\"` (i.e., $L[i] = S[n-1]$). The string $L$ has the crucial property that all occurrences of a given character $c \\in \\Sigma \\cup \\{\"\\$\"\\}$ in $L$ maintain their relative order from the original string $S$. This is known as the Last-to-First (LF) mapping property.\n\n**Auxiliary Data Structures (`C` and `Occ`)**: To enable efficient searching, two more structures are required:\n-   **$C$-table**: The $C$ table is an array or map that, for each character $c \\in \\Sigma \\cup \\{\"\\$\"\\}$, stores the total count of characters in $S$ that are lexicographically smaller than $c$.\n-   **Occurrence table ($Occ$)**: The $Occ(c, i)$ function returns the number of occurrences of character $c$ in the prefix of the BWT string, $L[0..i-1]$. This is precomputed and stored in a 2D array for $O(1)$ lookup time, where one dimension corresponds to characters and the other to positions in $L$.\n\nThe combination of $L$, $C$, and $Occ$ forms the core of the FM-index. It supports a highly efficient `backward_search` operation. Given a character $c$ and a suffix array interval $[sp, ep)$ that corresponds to all suffixes beginning with some string $\\alpha$, this operation finds the new interval corresponding to all suffixes beginning with $c\\alpha$. The new interval $[sp', ep')$ is calculated as:\n$$sp' = C[c] + Occ(c, sp)$$\n$$ep' = C[c] + Occ(c, ep)$$\n\n### 2. Backtracking Search Algorithm\n\nThe search for approximate matches is performed using a recursive, depth-first backtracking algorithm. The search proceeds backward, from the last character of the query $Q$ to the first.\n\nThe state of the recursion is defined by the tuple $(q_{idx}, sp, ep, \\text{mismatches}, s)$, where:\n-   $q_{idx}$: The current index in the query $Q$ being processed (from $|Q|-1$ down to $0$).\n-   $[sp, ep)$: The current suffix array interval in the FM-index.\n-   $\\text{mismatches}$: The number of mismatches accumulated so far.\n-   $s$: The cumulative alignment score.\n\n**Recursive Step**: At each index $q_{idx}$ of the query, the algorithm branches, exploring all possible characters $c \\in \\Sigma \\setminus \\{\"\\$\"\\}$ that could align with the query character $Q[q_{idx}]$. For each choice of $c$:\n1.  The mismatch count and score are updated. If $c = Q[q_{idx}]$, it's a match (score increases by $m$); otherwise, it's a mismatch (score decreases by $p$, mismatch count increments).\n2.  The algorithm checks if the new mismatch count exceeds the budget $k$. If so, this path is pruned.\n3.  The FM-index `backward_search` operation is used to compute the next suffix array interval $[sp', ep')$ based on character $c$.\n4.  If the new interval is empty ($sp' \\ge ep'$), this path is pruned.\n5.  If not pruned, the algorithm recurses with the new state: $(q_{idx}-1, sp', ep', \\text{new\\_mismatches}, \\text{new\\_score})$.\n\n**Base Case**: The recursion terminates when $q_{idx}  0$, signifying that the entire query string has been processed. At this point, the final suffix array interval $[sp, ep)$ contains pointers to the starting positions of all alignments found along this path. For each $i \\in [sp, ep)$, the position $pos = SA[i]$ is a valid match if it does not cause the alignment to overrun the original reference string $R$ (i.e., $pos + |Q| \\le |R|$). All such valid positions are collected.\n\n### 3. Branch-and-Bound Pruning\n\nTo make the search feasible, a branch-and-bound strategy is employed to prune unproductive search paths early. In addition to pruning on the mismatch limit $k$ and empty SA intervals, a powerful score-based pruning rule is applied.\n\nLet the query have length $L = |Q|$. Suppose the search has processed $d$ characters (from right to left) and is currently at query index $q_{idx} = L - 1 - d$. The number of remaining characters to process is $q_{idx} + 1$. If the current cumulative score is $s$, the maximum possible final score $s_{max}$ is achieved if all remaining characters are perfect matches.\n$$s_{max} = s + (q_{idx} + 1) \\cdot m$$\nIf this maximum possible score is less than the required threshold $\\tau$ (i.e., $s_{max}  \\tau$), then it is impossible for this path to ever yield a valid alignment. Therefore, the entire branch is pruned. This check is performed at the beginning of each recursive call.\n\nThis combination of the FM-index for fast interval updates and aggressive branch-and-bound pruning allows the algorithm to efficiently search for approximate matches satisfying both Hamming distance and scoring constraints. The final set of unique, sorted, 0-based starting positions in $R$ constitutes the result for each test case.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for approximate string matching\n    using an FM-index with branch-and-bound search.\n    \"\"\"\n\n    class FMIndex:\n        \"\"\"\n        Represents a Ferragina-Manzini (FM) index for a given reference string.\n        \"\"\"\n        def __init__(self, R: str):\n            \"\"\"\n            Constructs the FM-index from the reference string R.\n            This includes the Suffix Array (SA), Burrows-Wheeler Transform (BWT),\n            C-table, and Occ-table.\n            \"\"\"\n            self.S = R + '$'\n            self.n = len(self.S)\n            self.alphabet = sorted(list(set(self.S)))\n            self.alphabet_map = {c: i for i, c in enumerate(self.alphabet)}\n\n            # 1. Suffix Array (SA)\n            # A simple suffix sort, sufficient for small strings.\n            suffixes = sorted([(self.S[i:], i) for i in range(self.n)])\n            self.SA = [s[1] for s in suffixes]\n\n            # 2. Burrows-Wheeler Transform (BWT / L)\n            self.L = \"\".join([self.S[self.SA[i] - 1] for i in range(self.n)])\n\n            # 3. C-table\n            counts = {c: self.S.count(c) for c in self.alphabet}\n            self.C = {}\n            cum_count = 0\n            for char in self.alphabet:\n                self.C[char] = cum_count\n                cum_count += counts[char]\n\n            # 4. Occ-table\n            self.Occ = np.zeros((len(self.alphabet), self.n + 1), dtype=int)\n            for i, char in enumerate(self.L):\n                self.Occ[:, i + 1] = self.Occ[:, i]\n                self.Occ[self.alphabet_map[char], i + 1] += 1\n        \n        def get_occ(self, char: str, index: int) - int:\n            \"\"\"\n            Returns the number of occurrences of 'char' in the BWT prefix L[0..index-1].\n            \"\"\"\n            return self.Occ[self.alphabet_map[char], index]\n\n    def solve_case(R: str, Q: str, k: int, m: float, p: float, tau: float) - list[int]:\n        \"\"\"\n        Solves a single test case for approximate matching.\n        \"\"\"\n        len_R = len(R)\n        len_Q = len(Q)\n\n        # Initial pruning: if the maximum possible score is less than the threshold,\n        # no match is possible.\n        if len_Q * m  tau:\n            return []\n\n        fm_index = FMIndex(R)\n        search_alphabet = [c for c in fm_index.alphabet if c != '$']\n        found_positions = set()\n\n        def search_recursive(q_idx: int, sa_start: int, sa_end: int, mismatches: int, score: float):\n            \"\"\"\n            Recursive backtracking search function with branch-and-bound pruning.\n            \"\"\"\n            # Score-based pruning\n            remaining_chars = q_idx + 1\n            if score + remaining_chars * m  tau:\n                return\n\n            # Base case: entire query has been processed\n            if q_idx  0:\n                for i in range(sa_start, sa_end):\n                    pos = fm_index.SA[i]\n                    # A match is valid if it doesn't overrun the original reference string R.\n                    if pos + len_Q = len_R:\n                        found_positions.add(pos)\n                return\n\n            q_char = Q[q_idx]\n\n            # Branch on all possible characters in the alphabet\n            for c in search_alphabet:\n                is_match = (c == q_char)\n                new_mismatches = mismatches + (0 if is_match else 1)\n                \n                # Mismatch-based pruning\n                if new_mismatches  k:\n                    continue\n                \n                new_score = score + (m if is_match else -p)\n                \n                # FM-index backward step\n                new_sa_start = fm_index.C[c] + fm_index.get_occ(c, sa_start)\n                new_sa_end = fm_index.C[c] + fm_index.get_occ(c, sa_end)\n\n                # Empty-interval pruning\n                if new_sa_start  new_sa_end:\n                    search_recursive(q_idx - 1, new_sa_start, new_sa_end, new_mismatches, new_score)\n\n        # Start the recursive search from the end of the query\n        search_recursive(len_Q - 1, 0, fm_index.n, 0, 0.0)\n        \n        return sorted(list(found_positions))\n\n\n    test_cases = [\n        (\"ACGTCGACGTTACG\", \"CGACG\", 1, 1.0, 1.0, 4.0),\n        (\"ACGACGACG\", \"ACG\", 0, 1.0, 1.0, 3.0),\n        (\"ACGTACGT\", \"ACGT\", 2, 1.0, 1.0, 5.0),\n        (\"GGGGACGTAC\", \"ACGT\", 2, 1.0, 2.0, 3.0),\n        (\"AAAAAA\", \"AAA\", 10, 1.0, 1.0, 2.5),\n    ]\n\n    results = []\n    for R, Q, k, m, p, tau in test_cases:\n        result = solve_case(R, Q, k, m, p, tau)\n        results.append(result)\n    \n    # Format the final output string exactly as required, with no spaces.\n    # e.g., [[5],[0,3,6],[],[4],[0,1,2,3]]\n    output_str = f\"[{','.join([str(res).replace(' ', '') for res in results])}]\"\n    print(output_str)\n\nsolve()\n```"
        }
    ]
}