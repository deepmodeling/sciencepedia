{
    "hands_on_practices": [
        {
            "introduction": "The heart of any Metropolis Monte Carlo simulation is the evaluation of the energy change, $\\Delta U$, that results from a proposed move. This energy difference is determined by the system's potential energy function, which in the field of molecular modeling is typically described by a detailed force field. This exercise  provides direct, hands-on practice in calculating $\\Delta U$ for a torsional rotation, a common type of move in biomolecular simulations, using a standard potential energy term. Mastering this calculation is the first step toward understanding how conformational changes are energetically scored and selected.",
            "id": "3866303",
            "problem": "A peptide backbone dihedral angle rotation in a molecular mechanics model is proposed within a Metropolis Monte Carlo (MMC) simulation. The torsional contribution to the potential energy for a single dihedral angle is modeled by the function\n$$\nU_{\\text{dihedral}}(\\phi) \\;=\\; \\sum_{k=1}^{3} K_{k}\\left[1+\\cos\\!\\left(n_{k}\\,\\phi-\\delta_{k}\\right)\\right],\n$$\nwhere $\\phi$ is the dihedral angle in radians, $K_{k}$ are torsional amplitudes in $\\mathrm{kJ\\,mol^{-1}}$, $n_{k}$ are periodicities, and $\\delta_{k}$ are phase offsets in radians. In the canonical ensemble at temperature $T$, the MMC method applies the Boltzmann distribution to potential energy differences, but here you must compute the energy change itself arising from the proposed dihedral rotation.\n\nConsider a peptide dihedral initially at $\\phi_{\\mathrm{i}} = -0.8$ radians. A trial move proposes a rotation by $\\Delta\\phi = 0.6$ radians, giving a candidate angle $\\phi_{\\mathrm{f}} = \\phi_{\\mathrm{i}} + \\Delta\\phi$. The torsional parameters are:\n- $K_{1} = 2.3$ $\\mathrm{kJ\\,mol^{-1}}$, $n_{1} = 1$, $\\delta_{1} = 0.4$ radians;\n- $K_{2} = 1.7$ $\\mathrm{kJ\\,mol^{-1}}$, $n_{2} = 3$, $\\delta_{2} = -1.1$ radians;\n- $K_{3} = 0.9$ $\\mathrm{kJ\\,mol^{-1}}$, $n_{3} = 2$, $\\delta_{3} = 2.2$ radians.\n\nUsing only the provided torsional potential and definitions from statistical mechanics, calculate the energy change\n$$\n\\Delta U \\;=\\; U_{\\text{dihedral}}(\\phi_{\\mathrm{f}}) \\;-\\; U_{\\text{dihedral}}(\\phi_{\\mathrm{i}})\n$$\nfor this proposed rotation. Use radians for all trigonometric functions. Express the final energy change in $\\mathrm{kJ\\,mol^{-1}}$ and round your answer to four significant figures.",
            "solution": "The problem requires the calculation of the change in torsional potential energy, $\\Delta U$, for a proposed rotation of a peptide backbone dihedral angle. The problem is scientifically grounded, well-posed, and provides all necessary information for a direct calculation. Therefore, the problem is deemed valid.\n\nThe change in potential energy, $\\Delta U$, is defined as the difference between the final potential energy, $U_{\\text{dihedral}}(\\phi_{\\mathrm{f}})$, and the initial potential energy, $U_{\\text{dihedral}}(\\phi_{\\mathrm{i}})$:\n$$\n\\Delta U = U_{\\text{dihedral}}(\\phi_{\\mathrm{f}}) - U_{\\text{dihedral}}(\\phi_{\\mathrm{i}})\n$$\nFirst, we determine the initial and final dihedral angles. The initial angle is given as $\\phi_{\\mathrm{i}} = -0.8$ radians. A trial move proposes a rotation by $\\Delta\\phi = 0.6$ radians. The final angle, $\\phi_{\\mathrm{f}}$, is therefore:\n$$\n\\phi_{\\mathrm{f}} = \\phi_{\\mathrm{i}} + \\Delta\\phi = -0.8 + 0.6 = -0.2 \\text{ radians}\n$$\nThe torsional potential energy, $U_{\\text{dihedral}}(\\phi)$, is given by the function:\n$$\nU_{\\text{dihedral}}(\\phi) = \\sum_{k=1}^{3} K_{k}\\left[1+\\cos(n_{k}\\,\\phi-\\delta_{k})\\right]\n$$\nWe can express the change in energy, $\\Delta U$, by substituting this function into the definition of $\\Delta U$:\n$$\n\\Delta U = \\sum_{k=1}^{3} K_{k}\\left[1+\\cos(n_{k}\\,\\phi_{\\mathrm{f}}-\\delta_{k})\\right] - \\sum_{k=1}^{3} K_{k}\\left[1+\\cos(n_{k}\\,\\phi_{\\mathrm{i}}-\\delta_{k})\\right]\n$$\nBy combining the summations and simplifying, the constant $1$ within the brackets cancels out:\n$$\n\\Delta U = \\sum_{k=1}^{3} K_{k} \\left( [1+\\cos(n_{k}\\,\\phi_{\\mathrm{f}}-\\delta_{k})] - [1+\\cos(n_{k}\\,\\phi_{\\mathrm{i}}-\\delta_{k})] \\right)\n$$\n$$\n\\Delta U = \\sum_{k=1}^{3} K_{k} \\left[ \\cos(n_{k}\\,\\phi_{\\mathrm{f}}-\\delta_{k}) - \\cos(n_{k}\\,\\phi_{\\mathrm{i}}-\\delta_{k}) \\right]\n$$\nThis expression allows for a direct calculation of the energy change. We now calculate the contribution from each of the three terms in the summation, denoted as $\\Delta U_k$.\n\nFor the term $k=1$:\nThe parameters are $K_{1} = 2.3$ $\\mathrm{kJ\\,mol^{-1}}$, $n_{1} = 1$, and $\\delta_{1} = 0.4$ radians.\nThe argument of the cosine for the initial angle is $n_{1}\\phi_{\\mathrm{i}}-\\delta_{1} = (1)(-0.8) - 0.4 = -1.2$ radians.\nThe argument of the cosine for the final angle is $n_{1}\\phi_{\\mathrm{f}}-\\delta_{1} = (1)(-0.2) - 0.4 = -0.6$ radians.\nThe energy change for this term is:\n$$\n\\Delta U_1 = K_{1} \\left[ \\cos(-0.6) - \\cos(-1.2) \\right] = 2.3 \\left[ \\cos(0.6) - \\cos(1.2) \\right]\n$$\n$$\n\\Delta U_1 \\approx 2.3 \\times (0.8253356 - 0.3623577) = 2.3 \\times (0.4629779) \\approx 1.064849 \\text{ kJ mol}^{-1}\n$$\n\nFor the term $k=2$:\nThe parameters are $K_{2} = 1.7$ $\\mathrm{kJ\\,mol^{-1}}$, $n_{2} = 3$, and $\\delta_{2} = -1.1$ radians.\nThe argument for the initial angle is $n_{2}\\phi_{\\mathrm{i}}-\\delta_{2} = (3)(-0.8) - (-1.1) = -2.4 + 1.1 = -1.3$ radians.\nThe argument for the final angle is $n_{2}\\phi_{\\mathrm{f}}-\\delta_{2} = (3)(-0.2) - (-1.1) = -0.6 + 1.1 = 0.5$ radians.\nThe energy change for this term is:\n$$\n\\Delta U_2 = K_{2} \\left[ \\cos(0.5) - \\cos(-1.3) \\right] = 1.7 \\left[ \\cos(0.5) - \\cos(1.3) \\right]\n$$\n$$\n\\Delta U_2 \\approx 1.7 \\times (0.8775826 - 0.2674988) = 1.7 \\times (0.6100838) \\approx 1.037142 \\text{ kJ mol}^{-1}\n$$\n\nFor the term $k=3$:\nThe parameters are $K_{3} = 0.9$ $\\mathrm{kJ\\,mol^{-1}}$, $n_{3} = 2$, and $\\delta_{3} = 2.2$ radians.\nThe argument for the initial angle is $n_{3}\\phi_{\\mathrm{i}}-\\delta_{3} = (2)(-0.8) - 2.2 = -1.6 - 2.2 = -3.8$ radians.\nThe argument for the final angle is $n_{3}\\phi_{\\mathrm{f}}-\\delta_{3} = (2)(-0.2) - 2.2 = -0.4 - 2.2 = -2.6$ radians.\nThe energy change for this term is:\n$$\n\\Delta U_3 = K_{3} \\left[ \\cos(-2.6) - \\cos(-3.8) \\right] = 0.9 \\left[ \\cos(2.6) - \\cos(3.8) \\right]\n$$\n$$\n\\Delta U_3 \\approx 0.9 \\times (-0.8560751 - (-0.7909677)) = 0.9 \\times (-0.0651074) \\approx -0.058597 \\text{ kJ mol}^{-1}\n$$\n\nThe total change in potential energy is the sum of these individual contributions:\n$$\n\\Delta U = \\Delta U_1 + \\Delta U_2 + \\Delta U_3\n$$\n$$\n\\Delta U \\approx 1.064849 + 1.037142 - 0.058597 \\approx 2.043394 \\text{ kJ mol}^{-1}\n$$\nThe problem requires the final answer to be rounded to four significant figures.\n$$\n\\Delta U \\approx 2.043 \\text{ kJ mol}^{-1}\n$$",
            "answer": "$$\\boxed{2.043}$$"
        },
        {
            "introduction": "Once the energy change $\\Delta U$ for a proposed move is known, the algorithm must decide whether to accept or reject the new configuration. This decision is not deterministic but probabilistic, forming the core of the Metropolis criterion and ensuring that the simulation correctly samples states according to the Boltzmann distribution. This practice  takes you through a complete Metropolis step, from calculating a more complex energy change involving non-bonded interactions to applying the final acceptance rule, solidifying your understanding of how the algorithm balances energetic favorability with thermal fluctuations to explore the system's configuration space.",
            "id": "3866338",
            "problem": "A small-molecule ligand with two interaction sites is bound near a charged receptor pocket in an aqueous environment. Consider a proposed rigid-body rotation of the ligand about the $z$-axis by an angle of $\\theta = \\pi/2$ (right-handed, active rotation of the ligand coordinates), while the receptor remains fixed. The potential energy is modeled by the sum of a Lennard–Jones (LJ) $12$–$6$ term and a screened electrostatic term. Starting from the definitions of the canonical ensemble and the Metropolis Monte Carlo (MMC) algorithm, compute the energy change $\\Delta U$ for this proposed move under the specified force field and then evaluate the MMC acceptance probability at temperature $T$.\n\nUse the following scientifically consistent setup and constants:\n- Geometry (all positions in nanometers): receptor atoms at $\\mathbf{R}_1 = (0, 0, 0)$ and $\\mathbf{R}_2 = (1.0, 0, 0)$; ligand atoms initially at $\\mathbf{L}_1 = (0.5, 0.5, 0)$ and $\\mathbf{L}_2 = (0.5, -0.5, 0)$. The proposed rotation about the $z$-axis by $\\theta = \\pi/2$ maps $(x, y, z) \\mapsto (-y, x, z)$, giving $\\mathbf{L}_1' = (-0.5, 0.5, 0)$ and $\\mathbf{L}_2' = (0.5, 0.5, 0)$.\n- Partial charges (in elementary charge units $e$): $q_{\\mathrm{L}_1} = +0.20$, $q_{\\mathrm{L}_2} = -0.20$, $Q_{\\mathrm{R}_1} = -0.50$, $Q_{\\mathrm{R}_2} = -0.50$.\n- Nonbonded parameters: Lorentz–Berthelot mixing for LJ, with site parameters $\\sigma_{\\mathrm{L}} = 0.50$ and $\\epsilon_{\\mathrm{L}} = 0.25$ (for ligand atoms), $\\sigma_{\\mathrm{R}} = 0.50$ and $\\epsilon_{\\mathrm{R}} = 0.25$ (for receptor atoms), all in nanometers and kilojoules per mole, respectively. Thus for any ligand–receptor pair, $\\sigma_{ij} = (\\sigma_{\\mathrm{L}} + \\sigma_{\\mathrm{R}})/2$ and $\\epsilon_{ij} = \\sqrt{\\epsilon_{\\mathrm{L}} \\epsilon_{\\mathrm{R}}}$.\n- Force-field energy terms for a ligand–receptor pair at separation $r$: LJ energy $U_{\\mathrm{LJ}}(r) = 4 \\epsilon_{ij} \\left[ \\left( \\frac{\\sigma_{ij}}{r} \\right)^{12} - \\left( \\frac{\\sigma_{ij}}{r} \\right)^6 \\right]$; screened Coulomb energy $U_{\\mathrm{coul}}(r) = \\frac{k_e}{\\varepsilon_r} \\frac{q_i q_j}{r}$, with $k_e = 138.935456$ $\\mathrm{kJ}\\,\\mathrm{mol}^{-1}\\,\\mathrm{nm}\\,e^{-2}$ and relative permittivity $\\varepsilon_r = 80$ (aqueous environment).\n- Temperature: $T = 300$ $\\mathrm{K}$; Boltzmann constant $k_B = 8.314462618 \\times 10^{-3}$ $\\mathrm{kJ}\\,\\mathrm{mol}^{-1}\\,\\mathrm{K}^{-1}$.\n\nAssume that only ligand–receptor nonbonded interactions contribute to the energy change for this move. Compute the total energy change $\\Delta U$ upon rotation and, using first principles consistent with the canonical ensemble and detailed balance, evaluate the Metropolis acceptance probability for this move. Report only the acceptance probability as a decimal number, rounded to four significant figures, with no units.",
            "solution": "The problem requires the calculation of the Metropolis Monte Carlo (MMC) acceptance probability for a proposed rigid-body rotation of a ligand molecule near a receptor. The solution must be derived from first principles, beginning with the tenets of the canonical ensemble and the MMC algorithm, and utilizing the provided force-field model.\n\nThe Metropolis Monte Carlo algorithm is a method for sampling configurations from a probability distribution. In the canonical ($NVT$) ensemble, the equilibrium probability $\\pi_i$ of a system being in a microstate $i$ with potential energy $U_i$ is given by the Boltzmann distribution:\n$$ \\pi_i = \\frac{1}{Z} \\exp\\left(-\\frac{U_i}{k_B T}\\right) $$\nwhere $Z$ is the canonical partition function, $k_B$ is the Boltzmann constant, and $T$ is the absolute temperature. The MMC algorithm generates a sequence of states (a Markov chain) whose limiting distribution is this Boltzmann distribution. A move from an old state $o$ to a new state $n$ is accepted with a probability $P_{acc}$ that satisfies the detailed balance condition, $\\pi_o P(o \\to n) = \\pi_n P(n \\to o)$. The standard choice for the acceptance probability is the Metropolis criterion:\n$$ P_{acc} = \\min\\left(1, \\frac{\\pi_n}{\\pi_o}\\right) = \\min\\left(1, \\exp\\left(-\\frac{U_n - U_o}{k_B T}\\right)\\right) = \\min\\left(1, \\exp\\left(-\\frac{\\Delta U}{k_B T}\\right)\\right) $$\nHere, $\\Delta U = U_n - U_o$ is the change in potential energy for the proposed move. Our task is to calculate this $\\Delta U$ and subsequently the acceptance probability $P_{acc}$.\n\nThe total potential energy $U$ of the system is the sum of Lennard–Jones ($U_{\\mathrm{LJ}}$) and screened electrostatic ($U_{\\mathrm{coul}}$) interactions between the ligand and receptor atoms. We consider only these inter-molecular interactions, as specified. There are a total of four such interaction pairs: $(\\mathbf{R}_1, \\mathbf{L}_1)$, $(\\mathbf{R}_1, \\mathbf{L}_2)$, $(\\mathbf{R}_2, \\mathbf{L}_1)$, and $(\\mathbf{R}_2, \\mathbf{L}_2)$.\nThe total energy for a given configuration is $U = \\sum_{i=1}^2 \\sum_{j=1}^2 U(\\mathbf{R}_i, \\mathbf{L}_j)$, where $U(\\mathbf{A}, \\mathbf{B}) = U_{\\mathrm{LJ}}(r_{AB}) + U_{\\mathrm{coul}}(r_{AB})$ and $r_{AB} = \\|\\mathbf{A} - \\mathbf{B}\\|$.\n\nFirst, we determine the mixed nonbonded parameters using the Lorentz–Berthelot combination rules:\nLigand parameters: $\\sigma_{\\mathrm{L}} = 0.50\\,\\mathrm{nm}$, $\\epsilon_{\\mathrm{L}} = 0.25\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1}$.\nReceptor parameters: $\\sigma_{\\mathrm{R}} = 0.50\\,\\mathrm{nm}$, $\\epsilon_{\\mathrm{R}} = 0.25\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1}$.\nFor any ligand-receptor pair $(ij)$:\n$$ \\sigma_{ij} = \\frac{\\sigma_{\\mathrm{L}} + \\sigma_{\\mathrm{R}}}{2} = \\frac{0.50\\,\\mathrm{nm} + 0.50\\,\\mathrm{nm}}{2} = 0.50\\,\\mathrm{nm} $$\n$$ \\epsilon_{ij} = \\sqrt{\\epsilon_{\\mathrm{L}} \\epsilon_{\\mathrm{R}}} = \\sqrt{(0.25\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1}) \\times (0.25\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1})} = 0.25\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1} $$\nThus, all ligand-receptor pairs share the same Lennard-Jones parameters $\\sigma_{ij} = 0.50\\,\\mathrm{nm}$ and $\\epsilon_{ij} = 0.25\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1}$.\n\nNext, we calculate the energy of the initial state, $U_o$. The initial coordinates are: $\\mathbf{R}_1=(0,0,0)$, $\\mathbf{R}_2=(1.0,0,0)$, $\\mathbf{L}_1=(0.5,0.5,0)$, and $\\mathbf{L}_2=(0.5,-0.5,0)$. The distances are:\n$$ r_{R_1 L_1} = \\|(0.5, 0.5, 0) - (0, 0, 0)\\| = \\sqrt{0.5^2 + 0.5^2} = \\sqrt{0.5}\\,\\mathrm{nm} $$\n$$ r_{R_1 L_2} = \\|(0.5, -0.5, 0) - (0, 0, 0)\\| = \\sqrt{0.5^2 + (-0.5)^2} = \\sqrt{0.5}\\,\\mathrm{nm} $$\n$$ r_{R_2 L_1} = \\|(0.5, 0.5, 0) - (1.0, 0, 0)\\| = \\sqrt{(-0.5)^2 + 0.5^2} = \\sqrt{0.5}\\,\\mathrm{nm} $$\n$$ r_{R_2 L_2} = \\|(0.5, -0.5, 0) - (1.0, 0, 0)\\| = \\sqrt{(-0.5)^2 + (-0.5)^2} = \\sqrt{0.5}\\,\\mathrm{nm} $$\nAll initial distances are identical, $r_o = \\sqrt{0.5}\\,\\mathrm{nm}$.\nThe Lennard-Jones energy for one pair at distance $r_o$ is:\n$$ U_{\\mathrm{LJ}}(r_o) = 4 \\epsilon_{ij} \\left[ \\left(\\frac{\\sigma_{ij}}{r_o}\\right)^{12} - \\left(\\frac{\\sigma_{ij}}{r_o}\\right)^6 \\right] = 4(0.25) \\left[ \\left(\\frac{0.50}{\\sqrt{0.5}}\\right)^{12} - \\left(\\frac{0.50}{\\sqrt{0.5}}\\right)^6 \\right] $$\n$$ U_{\\mathrm{LJ}}(r_o) = 1.0 \\left[ \\left(\\frac{1}{\\sqrt{2}}\\right)^{12} - \\left(\\frac{1}{\\sqrt{2}}\\right)^6 \\right] = \\left(\\frac{1}{2^6} - \\frac{1}{2^3}\\right) = \\frac{1}{64} - \\frac{8}{64} = -\\frac{7}{64}\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1} $$\nThe total initial LJ energy is $U_{\\mathrm{LJ}, o} = 4 \\times U_{\\mathrm{LJ}}(r_o) = 4 \\times (-\\frac{7}{64}) = -\\frac{7}{16}\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1}$.\nThe total initial Coulomb energy is:\n$$ U_{\\mathrm{coul}, o} = \\frac{k_e}{\\varepsilon_r r_o} \\sum_{i,j} q_{\\mathrm{L}_j} Q_{\\mathrm{R}_i} = \\frac{k_e}{\\varepsilon_r \\sqrt{0.5}} \\left[ (+0.2)(-0.5) + (-0.2)(-0.5) + (+0.2)(-0.5) + (-0.2)(-0.5) \\right] $$\n$$ U_{\\mathrm{coul}, o} = \\frac{k_e}{\\varepsilon_r \\sqrt{0.5}} \\left[ -0.10 + 0.10 - 0.10 + 0.10 \\right] = 0 $$\nThus, the total initial energy is $U_o = U_{\\mathrm{LJ}, o} + U_{\\mathrm{coul}, o} = -\\frac{7}{16}\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1}$.\n\nNow, we calculate the energy of the final state, $U_n$. The proposed move is a rotation by $\\theta=\\pi/2$ about the $z$-axis, mapping $(x,y,z) \\to (-y,x,z)$. The new ligand coordinates are $\\mathbf{L}_1' = (-0.5, 0.5, 0)$ and $\\mathbf{L}_2' = (0.5, 0.5, 0)$. The new distances are:\n$$ r'_{R_1 L_1} = \\|(-0.5, 0.5, 0) - (0, 0, 0)\\| = \\sqrt{(-0.5)^2 + 0.5^2} = \\sqrt{0.5}\\,\\mathrm{nm} $$\n$$ r'_{R_1 L_2} = \\|(0.5, 0.5, 0) - (0, 0, 0)\\| = \\sqrt{0.5^2 + 0.5^2} = \\sqrt{0.5}\\,\\mathrm{nm} $$\n$$ r'_{R_2 L_1} = \\|(-0.5, 0.5, 0) - (1.0, 0, 0)\\| = \\sqrt{(-1.5)^2 + 0.5^2} = \\sqrt{2.25 + 0.25} = \\sqrt{2.5}\\,\\mathrm{nm} $$\n$$ r'_{R_2 L_2} = \\|(0.5, 0.5, 0) - (1.0, 0, 0)\\| = \\sqrt{(-0.5)^2 + 0.5^2} = \\sqrt{0.5}\\,\\mathrm{nm} $$\nThree pairs are at distance $r_1' = \\sqrt{0.5}\\,\\mathrm{nm}$ and one pair (R2-L1) is at $r_2' = \\sqrt{2.5}\\,\\mathrm{nm}$.\nThe total final LJ energy $U_{\\mathrm{LJ}, n}$ is the sum of contributions from these pairs. For the pair at $r_2'=\\sqrt{2.5}$:\n$$ U_{\\mathrm{LJ}}(r_2') = 1.0 \\left[ \\left(\\frac{0.50}{\\sqrt{2.5}}\\right)^{12} - \\left(\\frac{0.50}{\\sqrt{2.5}}\\right)^6 \\right] = \\left(\\frac{1}{\\sqrt{10}}\\right)^{12} - \\left(\\frac{1}{\\sqrt{10}}\\right)^6 = \\frac{1}{10^6} - \\frac{1}{10^3} = -\\frac{999}{10^6}\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1} $$\nThe total final LJ energy is:\n$$ U_{\\mathrm{LJ}, n} = 3 \\times U_{\\mathrm{LJ}}(r_1') + 1 \\times U_{\\mathrm{LJ}}(r_2') = 3 \\times \\left(-\\frac{7}{64}\\right) - \\frac{999}{10^6} = -\\frac{21}{64} - 0.000999\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1} $$\nThe total final Coulomb energy is:\n$$ U_{\\mathrm{coul}, n} = \\frac{k_e}{\\varepsilon_r} \\left[ \\frac{q_{L_1}Q_{R_1}}{r'_{R_1 L_1}} + \\frac{q_{L_2}Q_{R_1}}{r'_{R_1 L_2}} + \\frac{q_{L_1}Q_{R_2}}{r'_{R_2 L_1}} + \\frac{q_{L_2}Q_{R_2}}{r'_{R_2 L_2}} \\right] $$\n$$ U_{\\mathrm{coul}, n} = \\frac{k_e}{\\varepsilon_r} \\left[ \\frac{(-0.10)}{\\sqrt{0.5}} + \\frac{(+0.10)}{\\sqrt{0.5}} + \\frac{(-0.10)}{\\sqrt{2.5}} + \\frac{(+0.10)}{\\sqrt{0.5}} \\right] = \\frac{k_e}{\\varepsilon_r} \\left[ \\frac{0.10}{\\sqrt{0.5}} - \\frac{0.10}{\\sqrt{2.5}} \\right] $$\nThe total final energy is $U_n = U_{\\mathrm{LJ}, n} + U_{\\mathrm{coul}, n}$.\n\nThe change in energy is $\\Delta U = U_n - U_o = (U_{\\mathrm{LJ}, n} - U_{\\mathrm{LJ}, o}) + (U_{\\mathrm{coul}, n} - U_{\\mathrm{coul}, o})$.\n$$ \\Delta U_{\\mathrm{LJ}} = \\left(-\\frac{21}{64} - 0.000999\\right) - \\left(-\\frac{7}{16}\\right) = -\\frac{21}{64} + \\frac{28}{64} - 0.000999 = \\frac{7}{64} - 0.000999\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1} $$\n$$ \\Delta U_{\\mathrm{coul}} = U_{\\mathrm{coul}, n} - 0 = 0.10 \\frac{k_e}{\\varepsilon_r} \\left( \\frac{1}{\\sqrt{0.5}} - \\frac{1}{\\sqrt{2.5}} \\right)\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1} $$\nNow we substitute the numerical values:\n$$ \\Delta U_{\\mathrm{LJ}} = 0.109375 - 0.000999 = 0.108376\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1} $$\n$$ \\Delta U_{\\mathrm{coul}} = 0.10 \\times \\frac{138.935456}{80} \\left( \\frac{1}{\\sqrt{0.5}} - \\frac{1}{\\sqrt{2.5}} \\right) \\approx 0.173669 \\times (1.414214 - 0.632456) \\approx 0.135753\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1} $$\nTotal energy change:\n$$ \\Delta U = \\Delta U_{\\mathrm{LJ}} + \\Delta U_{\\mathrm{coul}} \\approx 0.108376 + 0.135753 = 0.244129\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1} $$\nThe energy change is positive, indicating the new state is energetically unfavorable.\n\nFinally, we compute the acceptance probability. The thermal energy is:\n$$ k_B T = (8.314462618 \\times 10^{-3}\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1}\\,\\mathrm{K}^{-1}) \\times (300\\,\\mathrm{K}) \\approx 2.494339\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1} $$\nSince $\\Delta U  0$, the acceptance probability is:\n$$ P_{acc} = \\exp\\left(-\\frac{\\Delta U}{k_B T}\\right) = \\exp\\left(-\\frac{0.244129}{2.494339}\\right) \\approx \\exp(-0.097873) \\approx 0.90676 $$\nRounding to four significant figures, the acceptance probability is $0.9068$.",
            "answer": "$$\\boxed{0.9068}$$"
        },
        {
            "introduction": "A single Metropolis step is simple, but a full simulation involves generating millions or billions of such configurations. A critical question then arises: when has the simulation run long enough to produce reliable, converged statistics? This exercise  introduces a powerful statistical tool for answering this question, the Gelman-Rubin potential scale reduction factor, $\\hat{R}$. By working through its derivation and calculating it from hypothetical simulation data, you will learn how to diagnose MCMC convergence, a crucial and non-negotiable skill for ensuring the scientific validity of simulation results in computational biology and other fields.",
            "id": "3866365",
            "problem": "A small-molecule ligand bound in an enzyme active site is simulated using the Metropolis algorithm at fixed temperature $T$, targeting the Boltzmann distribution with probability density proportional to $\\exp(-\\beta E(\\mathbf{x}))$, where $\\beta = 1/(k_B T)$, $k_B$ is the Boltzmann constant, $E(\\mathbf{x})$ is the potential energy of configuration $\\mathbf{x}$, and moves are proposed from a symmetric proposal distribution. Consider the scalar observable $h(\\mathbf{x})$ that reports the instantaneous number of protein–ligand hydrogen bonds in a snapshot. Four independent Metropolis trajectories are run, each initialized from overdispersed conformations, and from each trajectory $n = 50$ post–burn-in samples are collected. The per–trajectory sample means of $h$ are\n$$\\bar{h}_1 = 2.90,\\quad \\bar{h}_2 = 3.10,\\quad \\bar{h}_3 = 3.35,\\quad \\bar{h}_4 = 3.65,$$\nand the corresponding per–trajectory sample variances are\n$$s_1^2 = 0.50,\\quad s_2^2 = 0.55,\\quad s_3^2 = 0.65,\\quad s_4^2 = 0.70.$$\nStarting from the fundamental definitions of the Boltzmann target for Metropolis Monte Carlo, the Markov Chain Monte Carlo (MCMC) convergence idea of stationarity, and the law of total variance, derive the Gelman–Rubin potential scale reduction factor $\\hat{R}$ for a scalar observable from $m$ independent Metropolis trajectories, and then compute $\\hat{R}$ for the given data. Explain the interpretation of the computed value in terms of convergence assessment in computational chemical biology. Round your final numerical answer to four significant figures and express it as a dimensionless number.",
            "solution": "The problem requires the derivation of the Gelman-Rubin potential scale reduction factor, $\\hat{R}$, its calculation for given simulation data, and an interpretation of the result. The problem is scientifically grounded, well-posed, and objective, and all necessary data are provided. Thus, we proceed with the solution.\n\nThe Gelman-Rubin diagnostic is a convergence diagnostic for Markov Chain Monte Carlo (MCMC) simulations. It assesses convergence by comparing the variance within multiple parallel chains to the variance between those chains. The fundamental premise is that if all chains have converged to the target stationary distribution (here, the Boltzmann distribution), then their individual statistical properties should be indistinguishable from each other and from the properties of their mixture. The derivation of $\\hat{R}$ is rooted in this comparison, drawing conceptually from the law of total variance.\n\nLet $h$ be the scalar observable of interest, which is the number of protein-ligand hydrogen bonds. We have $m$ independent MCMC trajectories (chains), and from each chain $i$ (where $i=1, \\dots, m$), we collect $n$ post-burn-in samples, denoted $h_{ij}$ for $j=1, \\dots, n$.\n\nThe goal is to estimate the true variance of the observable under the stationary distribution, $\\sigma^2 = \\text{Var}(h)$. The Gelman-Rubin method constructs two estimators for $\\sigma^2$.\n\nFirst, we estimate the variance *within* each chain. The sample mean for chain $i$ is:\n$$ \\bar{h}_i = \\frac{1}{n} \\sum_{j=1}^{n} h_{ij} $$\nThe sample variance for chain $i$ is:\n$$ s_i^2 = \\frac{1}{n-1} \\sum_{j=1}^{n} (h_{ij} - \\bar{h}_i)^2 $$\nThe pooled within-chain variance, $W$, is the average of these individual sample variances:\n$$ W = \\frac{1}{m} \\sum_{i=1}^{m} s_i^2 $$\nIf the chains have not yet explored the full state space (i.e., they are not fully converged), each $s_i^2$ is an estimate of the variance within a restricted portion of the stationary distribution. Consequently, $W$ will likely be an *underestimate* of the true total variance, $\\sigma^2$.\n\nSecond, we estimate the variance *between* the chains. This is captured by the variance of the sample means of the chains. The grand mean over all samples from all chains is:\n$$ \\bar{h} = \\frac{1}{m} \\sum_{i=1}^{m} \\bar{h}_i = \\frac{1}{mn} \\sum_{i=1}^{m} \\sum_{j=1}^{n} h_{ij} $$\nThe between-chain variance, $B$, is defined as the scaled sample variance of the chain means:\n$$ B = \\frac{n}{m-1} \\sum_{i=1}^{m} (\\bar{h}_i - \\bar{h})^2 $$\nThe scaling factor $n$ ensures that $B$ is an estimator of $\\sigma^2$, not $\\sigma^2/n$. If the chains are started from overdispersed locations, the chain means $\\bar{h}_i$ will be spread out more than would be expected from pure sampling error from a single distribution. This means $B$ provides information about the part of the state space that has been explored between the chains.\n\nThe law of total variance provides a conceptual basis for combining these variance components. For a random variable $Y$ and a grouping variable $X$, $\\text{Var}(Y) = E[\\text{Var}(Y|X)] + \\text{Var}(E[Y|X])$. In our context, $Y$ is the observable $h$ and $X$ is the chain index $i$. $W$ is a sample-based estimator of the first term, $E_i[\\text{Var}(h|\\text{chain } i)]$. $B/n$ is a sample-based estimator related to the second term, $\\text{Var}_i(E[h|\\text{chain } i])$.\n\nGelman and Rubin proposed a pooled estimator for the target variance, $\\hat{\\sigma}^2_+$, which is a weighted average of $W$ and $B$:\n$$ \\hat{\\sigma}^2_+ = \\frac{n-1}{n} W + \\frac{1}{n} B $$\nThis quantity represents an estimate of the variance of the observable in a mixture distribution formed by pooling all $m$ chains. If the chains were initiated from overdispersed starting points relative to the target distribution, this mixture distribution is wider than the target distribution itself, at least until the chains fully converge. Therefore, $\\hat{\\sigma}^2_+$ is expected to be an *overestimate* of the true variance $\\sigma^2$.\n\nThe potential scale reduction factor, $\\hat{R}$, is defined as the ratio of the overestimated variance to the underestimated variance. It quantifies the potential for the scale of the current distribution (estimated by $\\sqrt{\\hat{\\sigma}^2_+}$) to be reduced if the simulations were run longer.\n$$ \\hat{R} = \\sqrt{\\frac{\\hat{\\sigma}^2_+}{W}} $$\nSubstituting the expression for $\\hat{\\sigma}^2_+$:\n$$ \\hat{R} = \\sqrt{\\frac{\\frac{n-1}{n} W + \\frac{1}{n} B}{W}} = \\sqrt{\\frac{n-1}{n} + \\frac{B}{nW}} $$\nAs the chains converge, the chain means $\\bar{h}_i$ all approach the true mean $\\mu_h$, so $B$ approaches $W$. In the limit, $B \\to W$, and $\\hat{R} \\to \\sqrt{\\frac{n-1}{n} + \\frac{W}{nW}} = \\sqrt{\\frac{n-1}{n} + \\frac{1}{n}} = \\sqrt{1} = 1$. Thus, an $\\hat{R}$ value close to $1$ indicates convergence.\n\nNow, we compute $\\hat{R}$ for the given data.\nGiven:\nNumber of trajectories, $m = 4$.\nNumber of samples per trajectory, $n = 50$.\nPer-trajectory means: $\\bar{h}_1 = 2.90$, $\\bar{h}_2 = 3.10$, $\\bar{h}_3 = 3.35$, $\\bar{h}_4 = 3.65$.\nPer-trajectory variances: $s_1^2 = 0.50$, $s_2^2 = 0.55$, $s_3^2 = 0.65$, $s_4^2 = 0.70$.\n\nFirst, calculate the pooled within-chain variance, $W$:\n$$ W = \\frac{1}{m} \\sum_{i=1}^{m} s_i^2 = \\frac{1}{4} (0.50 + 0.55 + 0.65 + 0.70) = \\frac{2.40}{4} = 0.60 $$\n\nNext, calculate the between-chain variance, $B$. We first need the grand mean, $\\bar{h}$:\n$$ \\bar{h} = \\frac{1}{m} \\sum_{i=1}^{m} \\bar{h}_i = \\frac{1}{4} (2.90 + 3.10 + 3.35 + 3.65) = \\frac{13.00}{4} = 3.25 $$\nNow, we compute $B$:\n$$ B = \\frac{n}{m-1} \\sum_{i=1}^{m} (\\bar{h}_i - \\bar{h})^2 $$\n$$ B = \\frac{50}{4-1} \\left[ (2.90 - 3.25)^2 + (3.10 - 3.25)^2 + (0.35 - 3.25)^2 + (3.65 - 3.25)^2 \\right] $$\n$$ B = \\frac{50}{3} \\left[ (-0.35)^2 + (-0.15)^2 + (0.10)^2 + (0.40)^2 \\right] $$\n$$ B = \\frac{50}{3} \\left[ 0.1225 + 0.0225 + 0.0100 + 0.1600 \\right] $$\n$$ B = \\frac{50}{3} (0.3150) = 50 \\times 0.1050 = 5.25 $$\n\nFinally, we compute $\\hat{R}$:\n$$ \\hat{R} = \\sqrt{\\frac{n-1}{n} + \\frac{B}{nW}} = \\sqrt{\\frac{50-1}{50} + \\frac{5.25}{50 \\times 0.60}} $$\n$$ \\hat{R} = \\sqrt{\\frac{49}{50} + \\frac{5.25}{30}} = \\sqrt{0.98 + 0.175} = \\sqrt{1.155} $$\n$$ \\hat{R} \\approx 1.07470926 \\dots $$\nRounding to four significant figures, we get $\\hat{R} = 1.075$.\n\nInterpretation of the result:\nThe value $\\hat{R} \\approx 1.075$ is a measure of convergence for the observable $h(\\mathbf{x})$, the number of hydrogen bonds. An ideal value is $\\hat{R}=1.0$, which would indicate that the between-chain variance is consistent with the within-chain variance, suggesting all chains are sampling from the same distribution. In practice, a threshold (e.g., $\\hat{R}  1.1$) is often used to declare convergence.\nThe calculated value of $1.075$ is close to this common threshold but still signifies a noticeable difference between the chains. Specifically, it implies that the variance of the mixture of all chains is about $1.155$ times ($=\\hat{R}^2$) larger than the average variance within the chains. This indicates that the chains have not yet fully mixed and forgotten their overdispersed starting points. The variation in the mean number of hydrogen bonds across the four trajectories (from $2.90$ to $3.65$) is larger than what would be expected if all chains were drawing from a single, converged stationary distribution. For a rigorous analysis in computational chemical biology, this value would suggest that the simulations need to be extended (i.e., more samples need to be collected) to improve confidence in the computed average of $\\bar{h}=3.25$ and other associated statistics. The sampling is likely incomplete, and quantitative conclusions about the hydrogen bonding pattern should be drawn with caution until $\\hat{R}$ is closer to $1.0$.",
            "answer": "$$\\boxed{1.075}$$"
        }
    ]
}