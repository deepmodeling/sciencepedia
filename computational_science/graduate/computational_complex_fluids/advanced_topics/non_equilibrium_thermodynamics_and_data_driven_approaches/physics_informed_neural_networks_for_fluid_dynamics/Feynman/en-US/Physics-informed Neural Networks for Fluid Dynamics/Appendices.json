{
    "hands_on_practices": [
        {
            "introduction": "When constructing a PINN for fluid dynamics, a primary challenge is balancing the contributions of different physical principles within the loss function. Without proper scaling, the optimizer might prioritize satisfying one equation (e.g., momentum) while neglecting another (e.g., mass conservation), leading to poor convergence. This first exercise guides you through a foundational practice: using dimensional analysis to derive a static scaling factor that harmonizes the magnitudes of the momentum and continuity residuals, ensuring a more balanced training process from the very start. ",
            "id": "4099871",
            "problem": "Consider a two-dimensional, incompressible, Newtonian fluid with density $\\rho$ and dynamic viscosity $\\mu$, evolving on a bounded spatial domain $\\Omega \\subset \\mathbb{R}^{2}$ over a time interval $[0,T]$. The primary fields are velocity $\\mathbf{u}(\\mathbf{x},t)$ and pressure $p(\\mathbf{x},t)$. The governing equations are the incompressible Navier–Stokes equations,\n$$\n\\rho\\left(\\frac{\\partial \\mathbf{u}}{\\partial t} + \\mathbf{u}\\cdot\\nabla \\mathbf{u}\\right) = -\\nabla p + \\mu \\nabla^{2}\\mathbf{u} + \\mathbf{f}, \\qquad \\nabla\\cdot\\mathbf{u} = 0,\n$$\nwhere $\\mathbf{f}$ is a known body force density. A Physics-Informed Neural Network (PINN) is trained to approximate $(\\mathbf{u},p)$ by minimizing a physics loss that consists of two contributions: a momentum residual penalty and a mass-conservation (divergence) penalty. Define the pointwise momentum residual $\\mathbf{r}_{m}(\\mathbf{x},t)$ and continuity residual $r_{c}(\\mathbf{x},t)$ by\n$$\n\\mathbf{r}_{m} := \\rho\\left(\\frac{\\partial \\mathbf{u}}{\\partial t} + \\mathbf{u}\\cdot\\nabla \\mathbf{u}\\right) + \\nabla p - \\mu \\nabla^{2}\\mathbf{u} - \\mathbf{f}, \\qquad r_{c} := \\nabla\\cdot\\mathbf{u}.\n$$\nThe physics loss takes the form\n$$\n\\mathcal{L}_{\\text{phys}} = \\lambda_{m}\\,\\mathbb{E}\\!\\left[\\,\\|\\mathbf{r}_{m}\\|^{2}\\,\\right] + \\lambda_{c}\\,\\mathbb{E}\\!\\left[\\,|r_{c}|^{2}\\,\\right],\n$$\nwhere $\\mathbb{E}[\\cdot]$ denotes an average over collocation points in $\\Omega\\times[0,T]$, and $\\lambda_{m}>0$ and $\\lambda_{c}>0$ are weights. The divergence penalty is thereby constructed as the squared $L^{2}$-norm of $r_{c}$ over the training distribution.\n\nTo avoid over-suppressing velocity dynamics during training, one seeks a scaling of the divergence penalty relative to the momentum residual that balances their contributions at the level of characteristic magnitudes. Let $U$ and $L$ be characteristic velocity and length scales for the flow, respectively. Using only the fundamental equations above and standard dimensional analysis, derive a closed-form expression for the relative scaling\n$$\ns_{\\mathrm{rel}} \\equiv \\frac{\\lambda_{c}}{\\lambda_{m}}\n$$\nthat equalizes the characteristic magnitudes of the two squared residual terms, evaluated on fields with characteristic scales $U$ and $L$. Express your final answer for $s_{\\mathrm{rel}}$ in terms of $\\rho$ and $U$, using the International System of Units (SI). Provide the final expression only; do not substitute numerical values.",
            "solution": "The objective is to determine the relative scaling factor $s_{\\mathrm{rel}} \\equiv \\frac{\\lambda_{c}}{\\lambda_{m}}$ such that the two weighted penalty terms in the physics loss function, $\\lambda_{m}\\,\\mathbb{E}\\!\\left[\\,\\|\\mathbf{r}_{m}\\|^{2}\\,\\right]$ and $\\lambda_{c}\\,\\mathbb{E}\\!\\left[\\,|r_{c}|^{2}\\,\\right]$, have the same characteristic magnitude. This condition can be expressed as:\n$$\n\\lambda_{m} [\\|\\mathbf{r}_{m}\\|^{2}] \\sim \\lambda_{c} [|r_{c}|^{2}]\n$$\nwhere $[\\cdot]$ denotes the characteristic magnitude of a quantity. The problem is thus to find the scaling that balances the contributions of the momentum and continuity residuals based on the characteristic scales of the flow.\n\nRearranging the equivalence, we obtain an expression for the desired ratio:\n$$\ns_{\\mathrm{rel}} = \\frac{\\lambda_{c}}{\\lambda_{m}} \\sim \\frac{[\\|\\mathbf{r}_{m}\\|^{2}]}{[|r_{c}|^{2}]} = \\frac{[\\mathbf{r}_{m}]^{2}}{[r_{c}]^{2}}\n$$\nTo evaluate this ratio, we must perform a dimensional analysis of the pointwise residuals $\\mathbf{r}_{m}$ and $r_{c}$ using the provided characteristic velocity scale $U$ and length scale $L$.\n\nFirst, we analyze the continuity residual, $r_{c}$. It is defined as the divergence of the velocity field:\n$$\nr_{c} := \\nabla\\cdot\\mathbf{u}\n$$\nThe gradient operator $\\nabla$ involves spatial derivatives, so its characteristic scale is the inverse of the characteristic length scale, $[ \\nabla ] \\sim L^{-1}$. The velocity field $\\mathbf{u}$ has a characteristic magnitude of $U$. Therefore, the characteristic magnitude of the continuity residual is:\n$$\n[r_{c}] \\sim [ \\nabla ] \\cdot [\\mathbf{u}] \\sim \\frac{1}{L} \\cdot U = \\frac{U}{L}\n$$\n\nNext, we analyze the momentum residual, $\\mathbf{r}_{m}$, defined as:\n$$\n\\mathbf{r}_{m} := \\rho\\left(\\frac{\\partial \\mathbf{u}}{\\partial t} + \\mathbf{u}\\cdot\\nabla \\mathbf{u}\\right) + \\nabla p - \\mu \\nabla^{2}\\mathbf{u} - \\mathbf{f}\n$$\nThe magnitude of $\\mathbf{r}_{m}$ is determined by the magnitudes of the terms in the momentum equation. In a well-posed physical problem, all terms must have the same physical units (force per unit volume). The characteristic magnitude of the residual is set by the dominant physical effects. For many fluid flows, particularly at moderate to high Reynolds numbers, the inertial terms are dominant or are used as the reference scale. Let us analyze the inertial terms: the local acceleration term $\\rho \\frac{\\partial \\mathbf{u}}{\\partial t}$ and the convective (advective) acceleration term $\\rho(\\mathbf{u}\\cdot\\nabla \\mathbf{u})$.\n\nThe characteristic time scale, $t_{char}$, can be related to the length and velocity scales. The advective time scale, which is the time it takes for a fluid particle to travel a characteristic distance $L$ at a characteristic velocity $U$, is $t_{char} \\sim L/U$.\n\nUsing this, the magnitude of the local acceleration term is:\n$$\n\\left[\\rho \\frac{\\partial \\mathbf{u}}{\\partial t}\\right] \\sim \\frac{[\\rho][\\mathbf{u}]}{[t]} \\sim \\frac{\\rho U}{L/U} = \\rho \\frac{U^{2}}{L}\n$$\nThe magnitude of the convective acceleration term is:\n$$\n[\\rho(\\mathbf{u}\\cdot\\nabla \\mathbf{u})] \\sim [\\rho][\\mathbf{u}][\\nabla][\\mathbf{u}] \\sim \\rho \\cdot U \\cdot \\frac{1}{L} \\cdot U = \\rho \\frac{U^{2}}{L}\n$$\nBoth inertial terms have the same characteristic magnitude, $\\rho U^{2}/L$. This magnitude represents the inertial force per unit volume. The pressure gradient term, $[\\nabla p]$, and the viscous term, $[\\mu \\nabla^2 \\mathbf{u}]$, are expected to scale in a way that balances the inertial terms. Specifically, the dynamic pressure scales as $p \\sim \\rho U^2$, leading to $[\\nabla p] \\sim \\rho U^2/L$. Thus, it is appropriate to set the characteristic magnitude of the entire momentum residual to that of the inertial terms:\n$$\n[\\mathbf{r}_{m}] \\sim \\rho \\frac{U^{2}}{L}\n$$\n\nNow we can substitute the characteristic magnitudes of $[r_{c}]$ and $[\\mathbf{r}_{m}]$ into the expression for $s_{\\mathrm{rel}}$:\n$$\ns_{\\mathrm{rel}} \\sim \\frac{[\\mathbf{r}_{m}]^{2}}{[r_{c}]^{2}} \\sim \\frac{\\left(\\rho \\frac{U^{2}}{L}\\right)^{2}}{\\left(\\frac{U}{L}\\right)^{2}}\n$$\nSimplifying this expression yields:\n$$\ns_{\\mathrm{rel}} \\sim \\frac{\\rho^{2} \\frac{U^{4}}{L^{2}}}{\\frac{U^{2}}{L^{2}}} = \\rho^{2} U^{2}\n$$\nThe derived scaling factor $s_{\\mathrm{rel}}$ is expressed solely in terms of the fluid density $\\rho$ and the characteristic velocity $U$, as required. A dimensional check confirms consistency. The units of $\\lambda_c/\\lambda_m$ must be the units of $\\|\\mathbf{r}_m\\|^2 / |r_c|^2$. In SI units, this is $(\\text{kg} \\cdot \\text{m}^{-2} \\cdot \\text{s}^{-2})^2 / (\\text{s}^{-1})^2 = \\text{kg}^2 \\cdot \\text{m}^{-4} \\cdot \\text{s}^{-2}$. The units of $\\rho^2 U^2$ are $(\\text{kg} \\cdot \\text{m}^{-3})^2 \\cdot (\\text{m} \\cdot \\text{s}^{-1})^2 = (\\text{kg}^2 \\cdot \\text{m}^{-6}) \\cdot (\\text{m}^2 \\cdot \\text{s}^{-2}) = \\text{kg}^2 \\cdot \\text{m}^{-4} \\cdot \\text{s}^{-2}$. The units match, confirming the correctness of the derivation.",
            "answer": "$$\\boxed{\\rho^{2} U^{2}}$$"
        },
        {
            "introduction": "Beyond simply penalizing residuals, a more elegant approach in physics-informed modeling is to design network architectures that satisfy certain physical laws by construction. This practice explores such a method for 2D incompressible flows by employing the classical streamfunction formulation. By structuring the network to output a scalar streamfunction $\\psi$, from which the velocity field is derived, the divergence-free constraint is satisfied identically, simplifying the loss landscape and improving pressure identifiability. ",
            "id": "4099876",
            "problem": "Consider a two-dimensional incompressible Newtonian fluid in a connected domain $\\Omega \\subset \\mathbb{R}^2$ with unknown velocity field $\\boldsymbol{u}(x,y,t)$ and pressure field $p(x,y,t)$, subject to a body force $\\boldsymbol{f}(x,y,t)$. In a Physics-Informed Neural Network (PINN), one proposes to represent the velocity via a streamfunction ansatz $\\psi(x,y,t)$, namely\n$$\n\\boldsymbol{u} = \\begin{pmatrix} u_x \\\\ u_y \\end{pmatrix} = \\begin{pmatrix} \\partial_y \\psi \\\\ -\\partial_x \\psi \\end{pmatrix}.\n$$\nThe governing equations for an incompressible Newtonian fluid are the incompressibility constraint and the momentum balance,\n$$\n\\nabla \\cdot \\boldsymbol{u} = 0,\n$$\n$$\n\\rho\\left(\\partial_t \\boldsymbol{u} + (\\boldsymbol{u}\\cdot\\nabla)\\boldsymbol{u}\\right) = -\\nabla p + \\mu \\nabla^2 \\boldsymbol{u} + \\boldsymbol{f},\n$$\nwhere $\\rho$ is the constant density and $\\mu$ is the dynamic viscosity. No explicit pressure boundary condition is provided; velocity boundary conditions are imposed on $\\partial\\Omega$.\n\nFrom first principles and core definitions, reason about the implications of the streamfunction ansatz for the continuity residual and for the identifiability of the pressure field within the PINN framework that enforces the momentum balance at collocation points. In particular, start from the above governing laws and:\n\n- Establish whether the continuity residual is identically zero when $\\boldsymbol{u}$ is constructed from $\\psi$ as above.\n- By taking appropriate operators of the momentum balance and using incompressibility, derive the condition that determines the pressure in terms of $\\psi$ and $\\boldsymbol{f}$, and state what aspects of $p$ are or are not uniquely identified by enforcing momentum alone in the absence of pressure data.\n- Discuss how boundary conditions and gauge choices affect the recovery of $p$ and whether nontrivial null-spaces can lead to ambiguity beyond an additive constant.\n\nSelect the statement that is most correct in light of this analysis:\n\nA. In two-dimensional incompressible flow, defining $\\boldsymbol{u}=(\\partial_y \\psi,-\\partial_x \\psi)$ guarantees $\\nabla\\cdot\\boldsymbol{u}=0$ identically, so the continuity residual in a Physics-Informed Neural Network (PINN) is identically zero for any $\\psi$; pressure is then recovered by enforcing the momentum equations, which determine $\\nabla p$ uniquely (up to a gauge constant) given $\\boldsymbol{f}$ and boundary traction.\n\nB. Using a streamfunction ansatz removes both continuity and momentum residuals automatically, so pressure cannot be identified and must be set to zero in training.\n\nC. The streamfunction ansatz enforces $\\nabla\\times \\boldsymbol{u}=0$, which eliminates vorticity and hence removes the need for pressure; learned pressure becomes arbitrary and unobservable.\n\nD. With a streamfunction ansatz, the divergence of the momentum equation yields a Poisson equation for pressure whose source depends only on $\\psi$ through velocity gradients and $\\boldsymbol{f}$; however, in the PINN that enforces only momentum balance, pressure is uniquely determined without any boundary or gauge condition.\n\nE. When using a streamfunction ansatz, pressure is determined only up to an additive constant and, in the absence of traction or pressure boundary conditions, the PINN may learn a pressure that differs by a spatially harmonic function, because harmonic functions have zero gradient.",
            "solution": "### Derivation and Analysis\n\nThe problem requires an analysis of the streamfunction ansatz within the PINN framework for solving the 2D incompressible Navier-Stokes equations.\n\n**1. Consequence for the Continuity Residual**\nThe velocity field $\\boldsymbol{u}$ is defined via the streamfunction $\\psi(x,y,t)$ as:\n$$\n\\boldsymbol{u} = \\begin{pmatrix} u_x \\\\ u_y \\end{pmatrix} = \\begin{pmatrix} \\partial_y \\psi \\\\ -\\partial_x \\psi \\end{pmatrix}\n$$\nThe incompressibility condition, or continuity equation, is $\\nabla \\cdot \\boldsymbol{u} = 0$. Let us compute the divergence of the proposed velocity field:\n$$\n\\nabla \\cdot \\boldsymbol{u} = \\frac{\\partial u_x}{\\partial x} + \\frac{\\partial u_y}{\\partial y} = \\frac{\\partial}{\\partial x}\\left(\\frac{\\partial \\psi}{\\partial y}\\right) + \\frac{\\partial}{\\partial y}\\left(-\\frac{\\partial \\psi}{\\partial x}\\right) = \\frac{\\partial^2 \\psi}{\\partial x \\partial y} - \\frac{\\partial^2 \\psi}{\\partial y \\partial x}\n$$\nAssuming the neural network representing $\\psi$ is sufficiently smooth (at least $C^2$), Schwartz's or Clairaut's theorem on the equality of mixed partial derivatives applies, such that $\\frac{\\partial^2 \\psi}{\\partial x \\partial y} = \\frac{\\partial^2 \\psi}{\\partial y \\partial x}$. Therefore:\n$$\n\\nabla \\cdot \\boldsymbol{u} = 0\n$$\nThis condition is satisfied identically for any choice of a sufficiently smooth function $\\psi$. In the context of a PINN, where the continuity equation would typically be enforced as a residual in the loss function, this ansatz structurally enforces the constraint. The continuity residual is identically zero and does not need to be included in the PINN loss function.\n\n**2. Determination of the Pressure Field**\nWith the velocity field determined by $\\psi$, the remaining governing equation to be satisfied is the momentum balance. We can rearrange it to isolate the pressure gradient:\n$$\n\\nabla p = -\\rho\\left(\\partial_t \\boldsymbol{u} + (\\boldsymbol{u}\\cdot\\nabla)\\boldsymbol{u}\\right) + \\mu \\nabla^2 \\boldsymbol{u} + \\boldsymbol{f}\n$$\nLet's denote the right-hand side, which is a vector field fully determined by $\\psi$ and $\\boldsymbol{f}$, as $\\boldsymbol{G}(\\psi, \\boldsymbol{f})$:\n$$\n\\nabla p = \\boldsymbol{G}(\\psi, \\boldsymbol{f})\n$$\nA PINN that \"enforces the momentum balance\" aims to find neural networks for $\\psi$ and $p$ such that this vector equation is satisfied at a set of collocation points. This means the network for $p$ is trained so that its gradient matches the field $\\boldsymbol{G}$.\n\nThis equation only determines the gradient of the pressure, $\\nabla p$. By the fundamental theorem of calculus for line integrals, this determines $p$ only up to a value that is constant in space. This constant, however, can be a function of time, $p_0(t)$, since $\\nabla p_0(t) = 0$. So, enforcing the momentum equation alone determines pressure up to a function $p(x,y,t) \\rightarrow p(x,y,t) + p_0(t)$.\n\nTo obtain an equation for $p$ itself, we can take the divergence of the expression for $\\nabla p$:\n$$\n\\nabla \\cdot (\\nabla p) = \\nabla^2 p = \\nabla \\cdot \\boldsymbol{G}\n$$\nThis is a Poisson equation for the pressure. The source term $\\nabla \\cdot \\boldsymbol{G}$ is:\n$$\n\\nabla \\cdot \\boldsymbol{G} = \\nabla \\cdot \\left( -\\rho\\left(\\partial_t \\boldsymbol{u} + (\\boldsymbol{u}\\cdot\\nabla)\\boldsymbol{u}\\right) + \\mu \\nabla^2 \\boldsymbol{u} + \\boldsymbol{f} \\right)\n$$\nUsing the fact that $\\nabla \\cdot \\boldsymbol{u} = 0$, we have $\\nabla \\cdot (\\partial_t \\boldsymbol{u}) = \\partial_t (\\nabla \\cdot \\boldsymbol{u}) = 0$ and $\\nabla \\cdot (\\mu \\nabla^2 \\boldsymbol{u}) = \\mu \\nabla^2 (\\nabla \\cdot \\boldsymbol{u}) = 0$. The equation simplifies to:\n$$\n\\nabla^2 p = \\nabla \\cdot \\boldsymbol{f} - \\rho \\nabla \\cdot ((\\boldsymbol{u}\\cdot\\nabla)\\boldsymbol{u})\n$$\nThe source term depends on the velocity field (via $\\boldsymbol{u}$ and its gradients, which are derived from $\\psi$) and the body force $\\boldsymbol{f}$.\n\n**3. Uniqueness, Boundary Conditions, and Gauge Choices**\nThe solution to the Poisson equation $\\nabla^2 p = S$ is unique only if appropriate boundary conditions are supplied.\n- If Dirichlet conditions (values of $p$ on $\\partial\\Omega$) are given, the solution is unique.\n- If Neumann conditions (values of the normal derivative $\\partial_n p$ on $\\partial\\Omega$) are given, the solution is unique up to an additive constant.\n\nThe problem states that no explicit pressure boundary condition is provided. However, a Neumann condition is implicitly contained within the momentum equation itself. Evaluating the component of the momentum equation normal to the boundary $\\partial\\Omega$ yields:\n$$\n\\frac{\\partial p}{\\partial n} = \\boldsymbol{n} \\cdot \\nabla p = \\boldsymbol{n} \\cdot \\left( -\\rho\\left(\\partial_t \\boldsymbol{u} + (\\boldsymbol{u}\\cdot\\nabla)\\boldsymbol{u}\\right) + \\mu \\nabla^2 \\boldsymbol{u} + \\boldsymbol{f} \\right)\n$$\nwhere $\\boldsymbol{n}$ is the outward unit normal vector. Since velocity boundary conditions are specified for $\\boldsymbol{u}$ on $\\partial\\Omega$, the right-hand side is, in principle, known once $\\psi$ is determined. A PINN that enforces the momentum residual over the domain is effectively solving the Poisson equation with this natural Neumann boundary condition. Consequently, the pressure field $p$ is determined only up to a single additive constant (which can be a function of time, $p_0(t)$). To fix this constant, one must impose an additional condition, such as specifying the value of $p$ at a single point in the domain (a gauge choice) or providing a pressure or boundary traction condition ($\\boldsymbol{t} = \\boldsymbol{\\sigma} \\cdot \\boldsymbol{n} = [-p\\boldsymbol{I} + \\mu(\\nabla \\boldsymbol{u} + (\\nabla \\boldsymbol{u})^T)] \\cdot \\boldsymbol{n}$) somewhere on the boundary.\n\nA nontrivial null-space beyond an additive constant (e.g., a harmonic function) is not possible. If a non-constant harmonic function $h$ were added to the pressure, $p' = p + h$, then $\\nabla p' = \\nabla p + \\nabla h$. Since $\\nabla h \\neq 0$, this would alter the momentum equation residual, and a correctly trained PINN would penalize this deviation.\n\n### Option-by-Option Analysis\n\n**A. In two-dimensional incompressible flow, defining $\\boldsymbol{u}=(\\partial_y \\psi,-\\partial_x \\psi)$ guarantees $\\nabla\\cdot\\boldsymbol{u}=0$ identically, so the continuity residual in a Physics-Informed Neural Network (PINN) is identically zero for any $\\psi$; pressure is then recovered by enforcing the momentum equations, which determine $\\nabla p$ uniquely (up to a gauge constant) given $\\boldsymbol{f}$ and boundary traction.**\n- The first part regarding the streamfunction ansatz and the zero continuity residual is entirely correct.\n- The second part states that the momentum equations determine $\\nabla p$. This is correct, as $\\nabla p = \\boldsymbol{G}(\\psi, \\boldsymbol{f})$.\n- The phrasing \"determine $\\nabla p$ uniquely (up to a gauge constant)\" is awkward. $\\nabla p$ is determined uniquely once $\\psi$ and $\\boldsymbol{f}$ are known. It is $p$ that is determined up to a gauge constant. However, understanding this as \"determines $\\nabla p$ uniquely, which in turn determines $p$ up to a gauge constant\" makes the statement correct.\n- The final clause \"given $\\boldsymbol{f}$ and boundary traction\" correctly identifies that additional information, such as boundary traction, is needed to fix the gauge and determine $p$ uniquely. While the phrasing is slightly convoluted, all constituent claims are physically and mathematically correct in the context of the problem.\n**Verdict: Correct**\n\n**B. Using a streamfunction ansatz removes both continuity and momentum residuals automatically, so pressure cannot be identified and must be set to zero in training.**\n- The claim that the streamfunction ansatz removes the momentum residual is false. The momentum residual is precisely what must be minimized by the PINN to learn the correct $\\psi$ and $p$.\n- The claim that pressure cannot be identified is false; its gradient is determined by the momentum equation.\n**Verdict: Incorrect**\n\n**C. The streamfunction ansatz enforces $\\nabla\\times \\boldsymbol{u}=0$, which eliminates vorticity and hence removes the need for pressure; learned pressure becomes arbitrary and unobservable.**\n- The streamfunction ansatz enforces $\\nabla \\cdot \\boldsymbol{u} = 0$ (incompressibility), not $\\nabla \\times \\boldsymbol{u} = 0$ (irrotationality). Vorticity, $\\boldsymbol{\\omega} = \\nabla \\times \\boldsymbol{u}$, is generally non-zero and is given by $\\boldsymbol{\\omega} = (0, 0, -\\nabla^2 \\psi)$. This statement confuses the streamfunction with a velocity potential.\n- Pressure is essential for momentum balance even in irrotational flows.\n**Verdict: Incorrect**\n\n**D. With a streamfunction ansatz, the divergence of the momentum equation yields a Poisson equation for pressure whose source depends only on $\\psi$ through velocity gradients and $\\boldsymbol{f}$; however, in the PINN that enforces only momentum balance, pressure is uniquely determined without any boundary or gauge condition.**\n- The first part, describing the Poisson equation for pressure, is correct.\n- The second part, claiming pressure is uniquely determined without any boundary or gauge condition, is false. As shown, enforcing the momentum balance only determines pressure up to an additive constant $p_0(t)$.\n**Verdict: Incorrect**\n\n**E. When using a streamfunction ansatz, pressure is determined only up to an additive constant and, in the absence of traction or pressure boundary conditions, the PINN may learn a pressure that differs by a spatially harmonic function, because harmonic functions have zero gradient.**\n- The claim that pressure is determined up to an additive constant is correct.\n- The claim that the ambiguity could be a spatially harmonic function is incorrect. The enforcement of the momentum equation, $\\nabla p = \\boldsymbol{G}$, would be violated by adding a non-constant harmonic function $h(x,y)$, as this would add a non-zero term $\\nabla h$ to the residual.\n- The justification \"because harmonic functions have zero gradient\" is factually false. A function $h$ is harmonic if $\\nabla^2 h = 0$. Only constant functions have zero gradient. For example, $h(x,y)=x$ is harmonic, but its gradient is $(1,0)$.\n**Verdict: Incorrect**\n\n### Conclusion\n\nOption A is the only statement that, despite some awkward phrasing, is composed of entirely correct physical and mathematical facts relevant to the problem. All other options contain fundamental errors.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Training a PINN effectively requires a thoughtful distribution of collocation points where the governing equations are enforced. Uniform sampling is simple but inefficient, often wasting computation in regions where the solution is already accurate. This final exercise introduces a sophisticated and practical solution: residual-based adaptive refinement, which dynamically focuses computational effort where it is most needed. You will formulate a statistically sound strategy that concentrates new collocation points in high-error regions while using importance sampling to maintain an unbiased loss estimator, a key for robust and efficient training. ",
            "id": "4100006",
            "problem": "Consider an incompressible Newtonian fluid in a bounded spatial domain $\\Omega \\subset \\mathbb{R}^d$ ($d \\in \\{2,3\\}$) over a time interval $[0,T]$. The primary fields are the velocity $\\mathbf{u}(\\mathbf{x},t)$ and the pressure $p(\\mathbf{x},t)$. The governing equations are the incompressible Navier–Stokes momentum balance and the continuity constraint, which (for density $\\rho>0$, dynamic viscosity $\\mu>0$, and body force $\\mathbf{f}$) read\n$$\n\\rho\\left(\\partial_t \\mathbf{u} + (\\mathbf{u}\\cdot\\nabla)\\mathbf{u}\\right) + \\nabla p - \\mu \\nabla^2 \\mathbf{u} - \\mathbf{f} = \\mathbf{0},\\quad \\nabla\\cdot\\mathbf{u}=\\;0.\n$$\nA Physics-Informed Neural Network (PINN) with parameters $\\boldsymbol{\\theta}$ approximates $(\\mathbf{u},p)$ and is trained by minimizing a continuous objective that penalizes the squared residuals of the momentum and continuity equations in the space-time domain, together with boundary and initial condition violations. Let the interior residuals be\n$$\nr_{\\text{mom}}(\\mathbf{x},t;\\boldsymbol{\\theta}) \\equiv \\rho\\left(\\partial_t \\mathbf{u}_\\boldsymbol{\\theta} + (\\mathbf{u}_\\boldsymbol{\\theta}\\cdot\\nabla)\\mathbf{u}_\\boldsymbol{\\theta}\\right) + \\nabla p_\\boldsymbol{\\theta} - \\mu \\nabla^2 \\mathbf{u}_\\boldsymbol{\\theta} - \\mathbf{f},\\quad r_{\\text{cont}}(\\mathbf{x},t;\\boldsymbol{\\theta}) \\equiv \\nabla\\cdot\\mathbf{u}_\\boldsymbol{\\theta},\n$$\nand denote by $\\|\\cdot\\|$ the Euclidean norm. The interior contribution to the training objective is the domain-time integral of a positive combination of $\\|r_{\\text{mom}}\\|^2$ and $|r_{\\text{cont}}|^2$. In practice, this integral is approximated by a Monte Carlo (MC) sum over a set of interior collocation points sampled from a distribution on $\\Omega\\times[0,T]$.\n\nYou are asked to design a residual-based adaptive refinement strategy that, during training, adds collocation points in space-time regions where the scalar indicator $s(\\mathbf{x},t;\\boldsymbol{\\theta})\\equiv \\|r_{\\text{mom}}(\\mathbf{x},t;\\boldsymbol{\\theta})\\| + |r_{\\text{cont}}(\\mathbf{x},t;\\boldsymbol{\\theta})|$ exceeds a user-specified threshold $\\tau>0$. The strategy must satisfy two requirements: \n($i$) it should update the sampling distribution over interior points in a way that concentrates new samples in high-residual regions but still allows exploration of the entire domain, and \n($ii$) it should update the loss evaluation so that the estimator remains consistent with the original continuous objective defined under a baseline distribution (for example, uniform over $\\Omega\\times[0,T]$), avoiding bias introduced by nonuniform adaptive sampling. You may assume separate handling for boundary and initial condition points.\n\nWhich option most correctly formulates such a strategy, starting from the above governing equations and residual definitions, and explicitly states how both the loss and the sampling distribution are updated under residual-thresholded adaptive refinement?\n\nA. After each training epoch $k$, compute $s(\\mathbf{x},t;\\boldsymbol{\\theta}_k)$ on a candidate set in $\\Omega\\times[0,T]$ and define the exceedance region $\\mathcal{A}_k=\\{(\\mathbf{x},t): s(\\mathbf{x},t;\\boldsymbol{\\theta}_k)>\\tau\\}$. Update the interior sampling distribution by a mixture\n$$\nq_{k+1}(\\mathbf{x},t) = (1-\\beta)\\,p(\\mathbf{x},t) + \\beta\\,g_k(\\mathbf{x},t),\\quad \\beta\\in(0,1),\n$$\nwhere $p$ is the baseline (for example, uniform) distribution over $\\Omega\\times[0,T]$, and $g_k$ is supported on $\\mathcal{A}_k$ and proportional to $s(\\mathbf{x},t;\\boldsymbol{\\theta}_k)^\\gamma$ with $\\gamma\\geq 1$, i.e., $g_k(\\mathbf{x},t)=\\frac{s(\\mathbf{x},t;\\boldsymbol{\\theta}_k)^\\gamma\\,\\mathbf{1}_{\\mathcal{A}_k}(\\mathbf{x},t)}{Z_k}$ for normalizer $Z_k>0$. Evaluate the interior loss by importance weighting to preserve the original objective under $p$:\n$$\n\\mathcal{L}_{\\text{int}}(\\boldsymbol{\\theta}_{k+1}) \\approx \\frac{1}{N}\\sum_{i=1}^{N}\\frac{p(\\mathbf{x}_i,t_i)}{q_{k+1}(\\mathbf{x}_i,t_i)}\\left(\\lambda_{\\text{mom},k}\\,\\|r_{\\text{mom}}(\\mathbf{x}_i,t_i;\\boldsymbol{\\theta}_{k+1})\\|^2+\\lambda_{\\text{cont},k}\\,|r_{\\text{cont}}(\\mathbf{x}_i,t_i;\\boldsymbol{\\theta}_{k+1})|^2\\right),\n$$\nwith $(\\mathbf{x}_i,t_i)\\sim q_{k+1}$, and where $\\lambda_{\\text{mom},k},\\lambda_{\\text{cont},k}>0$ are updated (for example, via running normalization of residual scales) to balance the contributions of momentum and continuity terms. Continue to sample a fraction $(1-\\beta)$ from $p$ to maintain exploration.\n\nB. After each training epoch, identify the set $\\mathcal{B}_k=\\{(\\mathbf{x},t): s(\\mathbf{x},t;\\boldsymbol{\\theta}_k)<\\tau\\}$ and add new collocation points only from $\\mathcal{B}_k$ to stabilize training in already accurate regions. Update the sampling distribution by removing mass from $\\{s>\\tau\\}$ so that $q_{k+1}\\propto \\mathbf{1}_{\\mathcal{B}_k}$, and continue to evaluate the interior loss by the unweighted mean of $\\|r_{\\text{mom}}\\|^2$ and $|r_{\\text{cont}}|^2$ under $q_{k+1}$.\n\nC. At each epoch, set the sampling distribution $q_{k+1}(\\mathbf{x},t)\\propto \\exp\\left(s(\\mathbf{x},t;\\boldsymbol{\\theta}_k)\\right)$ over all of $\\Omega\\times[0,T]$ and draw all interior collocation points from $q_{k+1}$, with no baseline component. Clip the residuals above $\\tau$ by replacing $s$ with $\\min\\{s,\\tau\\}$ in the loss to avoid domination, and evaluate the interior loss as the simple average of $\\|r_{\\text{mom}}\\|^2$ and $|r_{\\text{cont}}|^2$ under $q_{k+1}$, without importance weights.\n\nD. After each epoch, deterministically select new interior points at the $M$ locations of maximum $s(\\mathbf{x},t;\\boldsymbol{\\theta}_k)$ for some fixed $M\\in\\mathbb{N}$, and keep the original uniform sampling distribution for all other points. Update the loss by multiplying the momentum and continuity residuals at those $M$ selected points by $s(\\mathbf{x},t;\\boldsymbol{\\theta}_k)$ in order to emphasize high-residual regions, while keeping the rest unweighted. No change to the overall sampling distribution is needed since uniform sampling is retained.",
            "solution": "The problem asks for an adaptive sampling strategy for training a PINN that satisfies two key requirements. Let's analyze these requirements formally.\n\nLet the baseline sampling distribution be $p(\\mathbf{x},t)$, which is typically uniform over the spatio-temporal domain $\\Omega \\times [0,T]$. The original, continuous interior loss objective is an expectation with respect to this distribution:\n$$\n\\mathcal{L}_{\\text{int}}(\\boldsymbol{\\theta}) = \\mathbb{E}_{(\\mathbf{x},t)\\sim p}\\left[ L(\\mathbf{x},t;\\boldsymbol{\\theta}) \\right] = \\int_{\\Omega \\times [0,T]} L(\\mathbf{x},t;\\boldsymbol{\\theta}) \\, p(\\mathbf{x},t) \\, d\\mathbf{x} dt\n$$\nwhere $L(\\mathbf{x},t;\\boldsymbol{\\theta})$ is the weighted sum of squared residuals, for instance, $L(\\mathbf{x},t;\\boldsymbol{\\theta}) = \\lambda_{\\text{mom}}\\|r_{\\text{mom}}\\|^2 + \\lambda_{\\text{cont}}|r_{\\text{cont}}|^2$.\n\nThe adaptive strategy must modify the sampling distribution, let's call the new distribution $q(\\mathbf{x},t)$, while respecting two constraints:\n\n**Requirement (i): Concentrate sampling in high-residual regions but maintain exploration.**\nA strategy that focuses sampling only where the residual indicator $s(\\mathbf{x},t;\\boldsymbol{\\theta})$ is high would be an \"exploitation\" strategy. To maintain \"exploration,\" the new distribution $q(\\mathbf{x},t)$ must retain non-zero probability mass over the entire domain (or at least, wherever $p(\\mathbf{x},t)$ is non-zero). A standard and robust method to achieve this is to define $q$ as a mixture model:\n$$\nq(\\mathbf{x},t) = (1-\\beta)p(\\mathbf{x},t) + \\beta g(\\mathbf{x},t)\n$$\nwhere $\\beta \\in (0,1)$ is a mixing coefficient, $p(\\mathbf{x},t)$ is the baseline (exploration) distribution, and $g(\\mathbf{x},t)$ is an \"exploitation\" distribution that concentrates probability mass in regions of interest, i.e., where $s > \\tau$. This structure explicitly allocates a fraction $(1-\\beta)$ of the sampling budget to global exploration and a fraction $\\beta$ to targeted refinement.\n\n**Requirement (ii): Ensure the loss estimator remains consistent with the original objective.**\nWhen we sample points $(\\mathbf{x}_i, t_i)$ from the new distribution $q(\\mathbf{x},t)$ instead of the baseline $p(\\mathbf{x},t)$, the simple Monte Carlo average $\\frac{1}{N}\\sum_i L(\\mathbf{x}_i,t_i;\\boldsymbol{\\theta})$ would be an estimator for $\\mathbb{E}_{(\\mathbf{x},t)\\sim q}[L]$, not $\\mathbb{E}_{(\\mathbf{x},t)\\sim p}[L]$. This introduces bias. To obtain an unbiased estimator for the original objective, one must use importance sampling. The fundamental identity of importance sampling is:\n$$\n\\mathcal{L}_{\\text{int}}(\\boldsymbol{\\theta}) = \\mathbb{E}_{p}[L] = \\int L \\cdot p \\, d\\mathbf{z} = \\int \\left(L \\cdot \\frac{p}{q}\\right) q \\, d\\mathbf{z} = \\mathbb{E}_{q}\\left[ L \\cdot \\frac{p}{q} \\right]\n$$\nwhere $\\mathbf{z} = (\\mathbf{x},t)$. The corresponding unbiased Monte Carlo estimator for $N$ samples drawn from $q$ is:\n$$\n\\hat{\\mathcal{L}}_{\\text{int}}(\\boldsymbol{\\theta}) \\approx \\frac{1}{N} \\sum_{i=1}^{N} \\frac{p(\\mathbf{x}_i,t_i)}{q(\\mathbf{x}_i,t_i)} L(\\mathbf{x}_i, t_i; \\boldsymbol{\\theta})\n$$\nThe term $w_i = p(\\mathbf{x}_i,t_i) / q(\\mathbf{x}_i,t_i)$ is the importance weight. Any correct strategy must incorporate these weights into the loss evaluation to satisfy requirement (ii).\n\nWe will now evaluate each option against these two established principles.\n\n### Option-by-Option Analysis\n\n**A. After each training epoch $k$, compute $s(\\mathbf{x},t;\\boldsymbol{\\theta}_k)$ on a candidate set in $\\Omega\\times[0,T]$ and define the exceedance region $\\mathcal{A}_k=\\{(\\mathbf{x},t): s(\\mathbf{x},t;\\boldsymbol{\\theta}_k)>\\tau\\}$. Update the interior sampling distribution by a mixture $q_{k+1}(\\mathbf{x},t) = (1-\\beta)\\,p(\\mathbf{x},t) + \\beta\\,g_k(\\mathbf{x},t),\\quad \\beta\\in(0,1),$ where $p$ is the baseline (for example, uniform) distribution over $\\Omega\\times[0,T]$, and $g_k$ is supported on $\\mathcal{A}_k$ and proportional to $s(\\mathbf{x},t;\\boldsymbol{\\theta}_k)^\\gamma$ with $\\gamma\\geq 1$, i.e., $g_k(\\mathbf{x},t)=\\frac{s(\\mathbf{x},t;\\boldsymbol{\\theta}_k)^\\gamma\\,\\mathbf{1}_{\\mathcal{A}_k}(\\mathbf{x},t)}{Z_k}$ for normalizer $Z_k>0$. Evaluate the interior loss by importance weighting to preserve the original objective under $p$: $\\mathcal{L}_{\\text{int}}(\\boldsymbol{\\theta}_{k+1}) \\approx \\frac{1}{N}\\sum_{i=1}^{N}\\frac{p(\\mathbf{x}_i,t_i)}{q_{k+1}(\\mathbf{x}_i,t_i)}\\left(\\lambda_{\\text{mom},k}\\,\\|r_{\\text{mom}}(\\mathbf{x}_i,t_i;\\boldsymbol{\\theta}_{k+1})\\|^2+\\lambda_{\\text{cont},k}\\,|r_{\\text{cont}}(\\mathbf{x}_i,t_i;\\boldsymbol{\\theta}_{k+1})|^2\\right),$ with $(\\mathbf{x}_i,t_i)\\sim q_{k+1}$, and where $\\lambda_{\\text{mom},k},\\lambda_{\\text{cont},k}>0$ are updated (for example, via running normalization of residual scales) to balance the contributions of momentum and continuity terms. Continue to sample a fraction $(1-\\beta)$ from $p$ to maintain exploration.**\n\n*   **Analysis**:\n    *   **Sampling Strategy**: The proposed usage of a mixture distribution $q_{k+1} = (1-\\beta)p + \\beta g_k$ directly and correctly implements the balance between exploration (via the baseline component $p$) and exploitation (via the refinement component $g_k$ concentrated on the high-residual region $\\mathcal{A}_k$). This perfectly satisfies **Requirement (i)**.\n    *   **Loss Evaluation**: The loss is calculated using the importance weights $w_i = p(\\mathbf{x}_i,t_i)/q_{k+1}(\\mathbf{x}_i,t_i)$. This is the mathematically correct procedure to ensure the Monte Carlo estimator remains unbiased with respect to the original continuous objective defined with the baseline distribution $p$. This perfectly satisfies **Requirement (ii)**.\n    *   The additional details, such as defining $g_k$ to be proportional to a power of the residual indicator and updating the loss term weights $\\lambda$, are reasonable and common heuristics that supplement the core correct strategy.\n\n*   **Verdict**: **Correct**. This option provides a statistically sound and complete formulation that satisfies both stated requirements.\n\n**B. After each training epoch, identify the set $\\mathcal{B}_k=\\{(\\mathbf{x},t): s(\\mathbf{x},t;\\boldsymbol{\\theta}_k)<\\tau\\}$ and add new collocation points only from $\\mathcal{B}_k$ to stabilize training in already accurate regions. Update the sampling distribution by removing mass from $\\{s>\\tau\\}$ so that $q_{k+1}\\propto \\mathbf{1}_{\\mathcal{B}_k}$, and continue to evaluate the interior loss by the unweighted mean of $\\|r_{\\text{mom}}\\|^2$ and $|r_{\\text{cont}}|^2$ under $q_{k+1}$.**\n\n*   **Analysis**:\n    *   **Sampling Strategy**: This strategy proposes sampling from low-residual regions ($\\mathcal{B}_k = \\{s < \\tau\\}$). This is the opposite of the stated goal, which is to add points in *high-residual* regions. It fails to concentrate sampling where the error is large. This violates the premise of the task. Furthermore, by sampling *only* from $\\mathcal{B}_k$, it fails to explore high-residual regions, thus violating **Requirement (i)**.\n    *   **Loss Evaluation**: The loss is an \"unweighted mean,\" which means importance weights are not used. Since the sampling distribution $q_{k+1}$ is drastically different from the baseline $p$, this introduces significant bias and violates **Requirement (ii)**.\n\n*   **Verdict**: **Incorrect**. This option is flawed in its fundamental logic.\n\n**C. At each epoch, set the sampling distribution $q_{k+1}(\\mathbf{x},t)\\propto \\exp\\left(s(\\mathbf{x},t;\\boldsymbol{\\theta}_k)\\right)$ over all of $\\Omega\\times[0,T]$ and draw all interior collocation points from $q_{k+1}$, with no baseline component. Clip the residuals above $\\tau$ by replacing $s$ with $\\min\\{s,\\tau\\}$ in the loss to avoid domination, and evaluate the interior loss as the simple average of $\\|r_{\\text{mom}}\\|^2$ and $|r_{\\text{cont}}|^2$ under $q_{k+1}$, without importance weights.**\n\n*   **Analysis**:\n    *   **Sampling Strategy**: The distribution $q_{k+1} \\propto \\exp(s)$ does concentrate sampling in high-residual regions. However, it does not explicitly include a baseline component. While technically non-zero everywhere, this formulation risks \"mode collapse,\" where the distribution becomes extremely peaked, starving low-residual regions of samples and thus failing the exploration aspect of **Requirement (i)** in a practical sense. The mixture model in A is a more robust guarantee of exploration.\n    *   **Loss Evaluation**: The most critical flaw is the use of a \"simple average ... without importance weights.\" This creates a biased estimator for the original loss objective, directly violating **Requirement (ii)**. The proposed \"clipping\" of residuals is an ad-hoc heuristic that does not correct this fundamental statistical error.\n\n*   **Verdict**: **Incorrect**. This option fails to provide a consistent loss estimator.\n\n**D. After each epoch, deterministically select new interior points at the $M$ locations of maximum $s(\\mathbf{x},t;\\boldsymbol{\\theta}_k)$ for some fixed $M\\in\\mathbb{N}$, and keep the original uniform sampling distribution for all other points. Update the loss by multiplying the momentum and continuity residuals at those $M$ selected points by $s(\\mathbf{x},t;\\boldsymbol{\\theta}_k)$ in order to emphasize high-residual regions, while keeping the rest unweighted. No change to the overall sampling distribution is needed since uniform sampling is retained.**\n\n*   **Analysis**:\n    *   **Sampling Strategy**: The statement that \"no change to the overall sampling distribution is needed\" is false. If one combines points sampled uniformly with points selected deterministically at maxima, the resulting collection of points is no longer a sample from a uniform distribution. The effective sampling distribution is altered. This approach is also a very greedy strategy that may not satisfy the exploration requirement of **Requirement (i)** well.\n    *   **Loss Evaluation**: The proposed loss update is to multiply the residuals by the indicator value $s$. This is an arbitrary, heuristic re-weighting. It does not correspond to the correct importance weights $p/q$ and fundamentally changes the objective function rather than providing a consistent estimator for the original one. It therefore violates **Requirement (ii)**.\n\n*   **Verdict**: **Incorrect**. The reasoning about the sampling distribution is flawed, and the loss update is statistically unfounded.",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}