## Introduction
The realization of fusion energy hinges on the ability to maintain stable, long-pulse plasma discharges in tokamaks. A primary obstacle to this goal is the phenomenon of [plasma disruption](@entry_id:753494)—a catastrophic loss of confinement that can damage the device and halt operations. To ensure the viability of future reactors like ITER, a robust system for predicting and actively controlling these events is not just desirable, but essential. While vast amounts of data from decades of tokamak experiments provide a fertile ground for machine learning, tackling this challenge requires more than a simple pattern-recognition approach. It demands a deep, interdisciplinary synthesis of plasma physics, advanced algorithms, and real-time control engineering.

This article provides a comprehensive guide to this synthesis. First, the **Principles and Mechanisms** section will establish the physical foundations of disruptions and formalize the machine learning problem, from [data labeling](@entry_id:635459) to [model evaluation](@entry_id:164873) in rare-event scenarios. Following this, the **Applications and Interdisciplinary Connections** section will explore how these principles are put into practice, covering advanced model architectures, the integration of physics, and the transition from passive prediction to [active control](@entry_id:924699). Finally, the **Hands-On Practices** section will offer concrete exercises to solidify understanding of key validation and decision-making concepts, translating theory into practical skill.

## Principles and Mechanisms

This section delineates the fundamental physical principles and machine learning mechanisms that underpin the prediction and control of [tokamak disruptions](@entry_id:756034). We begin by defining the disruption phenomenon from a first-principles physics perspective, identifying its precursors and observational signatures. Subsequently, we formalize the machine learning task, addressing the critical challenges of [data labeling](@entry_id:635459), evaluation in rare-event scenarios, and robust model training. Finally, we explore advanced topics concerning the reliability of predictions and their generalization across different experimental devices.

### The Physics of a Tokamak Disruption

A **[tokamak disruption](@entry_id:756033)** is a catastrophic event characterized by a rapid, global loss of [plasma confinement](@entry_id:203546), which abruptly terminates the discharge. Understanding the physics of this process is paramount for constructing predictive models, as the features and constraints of such models must be grounded in the conservation laws that govern magnetically [confined plasmas](@entry_id:1122875). A disruption typically unfolds in two distinct, sequential phases: a [thermal quench](@entry_id:755893) followed by a current quench.

The **thermal quench (TQ)** is an extremely rapid event, often occurring on a sub-millisecond timescale, where the plasma's stored thermal energy, $W_{\mathrm{th}}$, collapses. This is typically triggered by a fast-growing magnetohydrodynamic (MHD) instability that destroys the nested [magnetic flux surfaces](@entry_id:751623), leading to a massive release of thermal energy to the plasma-facing components. During this phase, the [plasma temperature](@entry_id:184751) plummets from several kilo-electronvolts (keV) to a few electronvolts (eV). A crucial aspect of the thermal quench is that it occurs on a timescale much shorter than the [magnetic diffusion](@entry_id:187718) time of the hot, pre-disruptive plasma. Consequently, the total [toroidal plasma](@entry_id:202484) current, $I_p$, remains approximately constant during the thermal quench. From the perspective of the plasma's energy budget, the TQ is dominated by a large negative time-derivative of thermal energy, $dW_{\mathrm{th}}/dt \ll 0$, while the magnetic energy, $W_{\mathrm{mag}} = \frac{1}{2} L I_p^2$ (where $L$ is the plasma inductance), changes only weakly .

The **current quench (CQ)** is the subsequent phase, occurring over a longer timescale of tens to hundreds of milliseconds. Following the TQ, the plasma is cold and therefore highly resistive. According to the circuit equation for the plasma, this dramatic increase in resistance causes the [plasma current](@entry_id:182365) $I_p$ to decay rapidly ($dI_p/dt \ll 0$). This rapid change in current induces a large toroidal electric field, observed as a large positive [loop voltage](@entry_id:1127453), $V_{\mathrm{loop}}$. During the CQ, the stored magnetic energy, $W_{\mathrm{mag}}$, is converted into other forms. This energy is dissipated primarily as heat in the cold, resistive plasma (which is then radiated away) and through induced currents in the surrounding conducting structures of the tokamak, such as the vacuum vessel and blankets. This transfer of energy to the walls is described by the **Poynting theorem**, and the resulting heat loads and large [electromagnetic forces](@entry_id:196024) on the vessel are major engineering concerns.

From the perspective of [momentum conservation](@entry_id:149964), the plasma is subject to the MHD momentum equation, $\rho (\partial \mathbf{v}/\partial t + (\mathbf{v} \cdot \nabla) \mathbf{v}) = \mathbf{j} \times \mathbf{B} - \nabla p + \mathbf{F}_{\mathrm{visc}}$. In a [stable equilibrium](@entry_id:269479), the [electromagnetic force density](@entry_id:1124311) $\mathbf{j} \times \mathbf{B}$ balances the pressure gradient $\nabla p$. During a disruption, this balance is lost, leading to large net forces that accelerate the plasma. This can cause rapid vertical or radial motion, culminating in a **Vertical Displacement Event (VDE)**. When the plasma comes into contact with the vessel wall, large **[halo currents](@entry_id:750136)** can flow from the plasma into the conducting wall and back, closing a circuit. The resulting $\mathbf{j}_{\mathrm{halo}} \times \mathbf{B}$ forces on the mechanical structure can be on the order of mega-Newtons and represent a significant structural threat to the device .

### Physical Precursors to Disruption

The goal of [disruption prediction](@entry_id:748575) is to identify signatures of an impending disruption with sufficient warning time to initiate mitigation actions. These signatures are rooted in the physics of plasma instabilities and the approach to operational limits.

#### Macroscopic Stability and Operational Limits

The state of a tokamak plasma can be characterized by a set of dimensionless parameters that measure its proximity to known stability boundaries. A machine learning model informed by physics must use features that represent these parameters. Three of the most important are the [normalized beta](@entry_id:1128891), the edge safety factor, and the Greenwald density fraction .

1.  **Normalized Beta ($\beta_N$)**: The plasma beta, $\beta$, is the ratio of plasma kinetic pressure to magnetic pressure. The **[normalized beta](@entry_id:1128891)**, $\beta_N$, is defined as $\beta_N \equiv \beta_T (a B_T / I_p)$, where $\beta_T$ is the toroidal beta, $a$ is the plasma minor radius, $B_T$ is the toroidal magnetic field, and $I_p$ is the plasma current. This normalization accounts for the fact that the maximum achievable beta, as determined by ideal MHD stability limits (the "Troyon limit"), scales with $I_p/(aB_T)$. Therefore, a high value of $\beta_N$ is a direct, causal indicator of proximity to pressure-driven instabilities like external [kink modes](@entry_id:182102) or Resistive Wall Modes (RWMs), which are common [disruption precursors](@entry_id:748574).

2.  **Edge Safety Factor ($q_{95}$)**: The **safety factor**, $q$, measures the pitch of the magnetic field lines. The **edge safety factor**, $q_{95}$, is the value of $q$ evaluated on the [magnetic flux surface](@entry_id:751622) that encloses 95% of the [poloidal magnetic flux](@entry_id:1129914). It is a proxy for the total [plasma current](@entry_id:182365) relative to the magnetic field and machine size. Low integer values of $q_{95}$ (e.g., approaching 3 or 2) are strongly associated with the onset of large-scale, current-driven instabilities, such as external [kink modes](@entry_id:182102) or [tearing modes](@entry_id:194294), which can lock to the vessel wall and trigger a disruption.

3.  **Greenwald Density Fraction ($f_G$)**: The **Greenwald limit** is an empirical boundary on the maximum achievable line-averaged electron density, $n_G$, which scales linearly with the average current density, $n_G \propto I_p/a^2$. The **Greenwald fraction**, $f_G$, is the ratio of the measured line-averaged density to this limit. As $f_G$ approaches unity, the plasma edge tends to cool and become highly radiative, leading to a contraction of the current profile. This profile contraction can destabilize [tearing modes](@entry_id:194294), leading to a radiative collapse and subsequent disruption.

These three parameters, $\beta_N$, $q_{95}$, and $f_G$, form the cornerstone of physics-informed [feature engineering](@entry_id:174925) for [disruption prediction](@entry_id:748575), as they are interpretable, can be calculated in real-time from standard diagnostics, and directly map to the primary causes of disruptions.

#### Magnetohydrodynamic (MHD) Instabilities

While operational limit parameters provide a global view of stability, machine learning models must also be sensitive to the direct signatures of specific growing instabilities.

A common disruption pathway is **radiative collapse**, which is a form of [thermal instability](@entry_id:151762). This can be analyzed with a zero-dimensional power balance model where the rate of change of temperature is governed by the competition between heating and cooling sources: $C dT/dt = p_{\mathrm{ohm}} - p_{\mathrm{rad}}$. Here, $p_{\mathrm{ohm}} = J^2 \eta(T)$ is the ohmic heating power from the [plasma current](@entry_id:182365), with Spitzer resistivity $\eta \propto T^{-3/2}$, and $p_{\mathrm{rad}} = n_e n_Z L_Z(T)$ is the power radiated by impurities, where $L_Z(T)$ is a complex function of temperature. A [stable equilibrium](@entry_id:269479) exists at a temperature $T_*$ where heating balances radiation, $p_{\mathrm{ohm}}(T_*) = p_{\mathrm{rad}}(T_*)$. However, this equilibrium can become unstable. A runaway cooling process, or radiative collapse, occurs if a small [negative temperature](@entry_id:140023) perturbation leads to a further decrease in temperature. This happens if the net power derivative is positive, $dp_{\mathrm{net}}/dT > 0$, where $p_{\mathrm{net}} = p_{\mathrm{ohm}} - p_{\mathrm{rad}}$. At the [equilibrium point](@entry_id:272705), this instability condition simplifies to $\frac{d\ln L_Z}{dT}  -\frac{3}{2T_*}$ . An ML classifier can be trained to detect imminent collapse by using features that represent the power balance, such as the ratio $p_{\mathrm{rad}}/p_{\mathrm{ohm}}$, and the stability condition, such as the term $S(T) = \frac{3}{2T} + \frac{d\ln L_Z}{dT}$.

Another critical class of precursors are **tearing modes**, which are [resistive instabilities](@entry_id:186275) that lead to the formation of magnetic islands at rational magnetic surfaces (where $q=m/n$ for integers $m, n$). A particularly dangerous mode is the $m=2, n=1$ [tearing mode](@entry_id:182276). In high-pressure plasmas, these can manifest as **Neoclassical Tearing Modes (NTMs)**. The drive for NTMs comes from a deficit in the self-generated **bootstrap current**. The bootstrap current, $j_{\mathrm{bs}}$, is a pressure-gradient-driven current, $j_{\mathrm{bs}} \propto -dp/dr$. When a seed [magnetic island](@entry_id:1127585) forms, the high [parallel thermal conductivity](@entry_id:1129319), $\chi_{\parallel}$, flattens the pressure profile across the island, causing the local pressure gradient to vanish. This eliminates the local bootstrap current, creating a "hole" in the current profile. This negative current perturbation provides a strong destabilizing drive that causes the island to grow, even in a plasma that would otherwise be stable to classical [tearing modes](@entry_id:194294). This mechanism only becomes effective once the seed island exceeds a **critical island width**, $W_{\mathrm{crit}}$, which is determined by the competition between parallel transport (which flattens the profile) and [perpendicular transport](@entry_id:1129533) (which restores it). The scaling can be estimated by balancing transport timescales, yielding $W_{\mathrm{crit}} \propto (\chi_{\perp}/\chi_{\parallel})^{1/2}$ or similar forms . This physics directly informs both prediction and control. For prediction, ML models should use features that track the local pressure gradient, [poloidal beta](@entry_id:1129912), and direct measurements of the [magnetic island](@entry_id:1127585) amplitude. For control, the goal is to "fill in" the current hole using precisely aimed, externally driven current, such as from Electron Cyclotron Current Drive (ECCD), synchronized with the island's rotation.

### Observing Precursors: The Role of Diagnostics

The ability of any predictive model is ultimately limited by the quality and speed of the diagnostic data it receives. A variety of diagnostics are employed to measure the physical quantities associated with [disruption precursors](@entry_id:748574).
- **Magnetic pickup coils** measure the time-rate-of-change of the magnetic field, $\partial \mathbf{B}/\partial t$, and are essential for detecting MHD fluctuations like [tearing modes](@entry_id:194294).
- **Electron Cyclotron Emission (ECE) radiometers** measure the electron temperature, $T_e$, and are crucial for detecting temperature profile flattening associated with NTMs.
- **Soft X-Ray (SXR) arrays** measure core emissivity, which is sensitive to temperature, density, and impurities.
- **Interferometry** measures the line-integrated electron density, $n_e$.
- **Bolometry** measures the [total radiated power](@entry_id:756065), $P_{\mathrm{rad}}$, which is critical for identifying radiative collapse.
- **D-alpha ($\mathrm{D}\alpha$) emission** monitors edge recycling and dynamics.
- **Loop voltage sensors** measure the global toroidal electric field.

A practical constraint in real-time prediction is the bandwidth of these systems. To capture precursors with frequency content up to $f_{\mathrm{prec}}$, the system's sampling frequency, $f_s$, must satisfy the Nyquist criterion, $f_s > 2 f_{\mathrm{prec}}$, to avoid aliasing. Furthermore, the analog front-end of each diagnostic has a characteristic time constant, $\tau$, which limits its [frequency response](@entry_id:183149). If $\tau$ is too large, the amplitude of high-frequency signals will be attenuated, corrupting the features fed to the ML model. For example, to resolve a $5\,\mathrm{kHz}$ precursor with less than $1\,\mathrm{dB}$ of attenuation, the diagnostic time constant must be shorter than approximately $16\,\mu\mathrm{s}$. Diagnostics like magnetic probes and ECE radiometers typically meet this requirement, whereas slower systems like foil bolometers ($\tau \sim \mathrm{ms}$) cannot resolve such fast dynamics and are better suited for tracking slower thermal evolution .

### Framing the Machine Learning Task

Translating the continuous, complex physics of disruptions into a tractable machine learning problem requires careful formalization of the prediction target, evaluation metrics, and training objectives.

#### From Physics to Labels: Defining the Prediction Target

The standard approach for [disruption prediction](@entry_id:748575) is to frame it as a [binary classification](@entry_id:142257) problem over time. For each time slice in a discharge, we assign a label: $y=1$ (positive) if a disruption is imminent, and $y=0$ (negative) otherwise. The definition of "imminent" is formalized using two key parameters relative to the [thermal quench](@entry_id:755893) onset time, $T_q$.

- A **warning horizon**, $H$, specifies the period before the disruption during which we wish to raise an alarm. All time points $t$ such that $T_q - t \le H$ are candidates for a positive label.
- An **exclusion window**, $E$ (with $E  H$), defines a period immediately preceding the quench that is excluded from the positive class.

The positive label is thus assigned to time points $t$ such that $E  T_q - t \le H$. The exclusion window is crucial because the [plasma dynamics](@entry_id:185550) become chaotic and irreversible very close to the quench, making this region less useful for training a model intended for timely mitigation. All other times, including the entirety of non-disruptive shots, are labeled as negative .

A fundamental challenge arises because the true quench time $T_q$ is never known with perfect precision; it is estimated from experimental data as $\hat{T}_q$ with some timing error, $\epsilon$, where $T_q = \hat{T}_q + \epsilon$. If this error is modeled as a random variable, for instance, $\epsilon \sim \mathcal{N}(0, \sigma^2)$, then the "true" label for any given time point becomes a random variable. The machine learning model, which only has access to measured quantities, should ideally predict the probability that a given time point falls within the positive window. This probability, or **noisy positive rate**, can be calculated as $r(t) = \mathbb{P}(E  T_q - t \le H)$. For a Gaussian error model, this yields $r(t) = \Phi(\frac{H - \Delta}{\sigma}) - \Phi(\frac{E - \Delta}{\sigma})$, where $\Delta = \hat{T}_q - t$ and $\Phi$ is the standard normal CDF. This has a profound implication for training: for a model trained with **[binary cross-entropy](@entry_id:636868) loss**, the **Bayes-optimal predictor**—the function that minimizes the expected loss—is precisely this noisy positive rate, $s^*(t) = r(t)$. This means the ideal model should output "soft" probabilistic targets that are smooth functions of time, rather than hard binary labels .

#### Evaluation Metrics for a Rare-Event Problem

Disruptions are, by design, rare events in tokamak operation. This leads to a severe **[class imbalance](@entry_id:636658)** in any representative dataset, where the number of negative examples ($n_-$) vastly exceeds the number of positive examples ($n_+$). For instance, a dataset with $n_+ = 800$ and $N = 10^5$ total examples has a positive rate of only $p = 0.008$ .

In such a scenario, standard **accuracy** is a deeply misleading metric. A trivial classifier that always predicts the negative class ("no disruption") would achieve an accuracy of $(1-p) = 0.992$ on this dataset. While numerically impressive, this model is completely useless as it fails to predict a single disruption.

Therefore, metrics that are sensitive to performance on the rare positive class must be used. The two most common tools are the Receiver Operating Characteristic (ROC) curve and the Precision-Recall (PR) curve.
- The **ROC curve** plots the True Positive Rate ($TPR = TP/(TP+FN)$) against the False Positive Rate ($FPR = FP/(FP+TN)$).
- The **PR curve** plots Precision ($\mathrm{Prec} = TP/(TP+FP)$) against Recall ($TPR$).

While the ROC curve is invariant to [class imbalance](@entry_id:636658) (since both axes are normalized by class counts), this invariance hides the true performance cost of false alarms. Using Bayes' rule, we can relate precision to the ROC curve's components and the positive class prevalence, $\pi$: $\mathrm{Prec} = \frac{\pi \cdot TPR}{\pi \cdot TPR + (1-\pi) \cdot FPR}$. When $\pi$ is very small, the denominator is dominated by the term $(1-\pi) \cdot FPR$. Consequently, even a very low FPR can lead to an overwhelming number of false alarms and thus a very poor precision. The PR curve makes this trade-off explicit and is therefore a much more informative evaluation tool for rare-event problems like [disruption prediction](@entry_id:748575) . The area under the PR curve (Average Precision) is a standard summary statistic.

#### Loss Functions for Imbalanced Learning

The [class imbalance](@entry_id:636658) also poses a major challenge during model training. A standard loss function like Binary Cross-Entropy (BCE) will be dominated by the contribution from the abundant negative class, leading the model to learn the trivial "always negative" solution. To counteract this, the loss function must be modified.

One common approach is **class-weighted BCE**, where the loss for each class is weighted inversely to its frequency. For a sample with label $y$, the loss is $-w_+ y \log(s) - w_- (1-y) \log(1-s)$, where $s$ is the model's score. To balance the total contribution from each class, the weights are typically set such that $w_+ n_+ \approx w_- n_-$, implying a weight ratio of $w_+/w_- \approx n_-/n_+ = (1-p)/p$.

A more advanced technique is the **Focal Loss**. It modifies the BCE loss by adding a modulating factor that down-weights the loss contribution from well-classified ("easy") examples. For a positive example, the loss is $-\alpha (1-s)^\gamma \log(s)$, where $\gamma > 0$ is a focusing parameter and $\alpha$ is a class-balancing weight. The $(1-s)^\gamma$ term ensures that as the model becomes confident in its prediction ($s \to 1$), the loss for that example is suppressed. This forces the training to focus on "hard" examples, which in an imbalanced setting often include the rare positive class and difficult-to-classify negatives .

### Advanced Topics in Reliability and Generalization

Beyond basic classification, a trustworthy [disruption prediction](@entry_id:748575) system must provide a measure of its own confidence and be able to generalize its knowledge to new situations or even different machines.

#### Quantifying Predictive Uncertainty

A simple point prediction of disruption risk is insufficient for high-stakes decisions. We must also quantify the model's uncertainty, which can be decomposed into two types:

1.  **Aleatoric Uncertainty** reflects the inherent, irreducible randomness or noise in the data-generating process. In the context of disruptions, this could arise from stochastic plasma processes or diagnostic measurement noise. In a probabilistic model that outputs a distribution (e.g., a Gaussian with mean $\mu(x)$ and variance $\sigma^2(x)$), the predicted variance $\sigma^2(x)$ captures this data-dependent noise.

2.  **Epistemic Uncertainty** reflects the model's own uncertainty about its parameters due to limited training data. This uncertainty is reducible with more data and is especially high for inputs that are far from the training distribution (out-of-distribution data).

In a Bayesian deep learning framework, these uncertainties can be estimated by approximating the predictive distribution $p(y \mid x, \mathcal{D}) = \int p(y \mid x, w) p(w \mid \mathcal{D}) dw$. This can be done using techniques like **[deep ensembles](@entry_id:636362)** (training multiple models independently) and **Monte Carlo (MC) dropout** (performing multiple stochastic forward passes at prediction time). By the law of total variance, the total predictive variance can be decomposed as $\mathrm{Var}(y) = \mathbb{E}[\sigma^2(x)] + \mathrm{Var}[\mu(x)]$. The first term, the average of the predicted variances, is the **aleatoric uncertainty**. The second term, the variance of the predicted means across the ensemble or dropout samples, is the **epistemic uncertainty**. This decomposition is invaluable: high aleatoric uncertainty indicates a fundamentally noisy regime, while high epistemic uncertainty signals that the model is extrapolating and its prediction should not be trusted .

#### Generalization Across Devices: The Challenge of Domain Shift

A key goal in fusion research is to develop predictive models that are applicable across multiple tokamaks. This is a **[domain adaptation](@entry_id:637871)** problem, as data from different devices (domains) will exhibit distributional shifts due to differences in hardware, operating regimes, and disruption frequencies. These shifts can be categorized as follows:

- **Covariate Shift**: The [marginal distribution](@entry_id:264862) of input features differs ($p_S(x) \neq p_T(x)$), but the underlying physical relationship is the same ($p_S(y \mid x) = p_T(y \mid x)$). For example, two tokamaks may operate in different parameter ranges but share the same disruption physics.
- **Prior Shift**: The class priors differ ($p_S(y) \neq p_T(y)$), meaning one device has disruptions more frequently than the other.
- **Concept Shift**: The relationship between features and labels itself changes ($p_S(y \mid x) \neq p_T(y \mid x)$). This is the most challenging shift, implying that the underlying physics or their diagnostic signatures are different.

**Adversarial [domain adaptation](@entry_id:637871)** is a powerful technique to address these shifts. In a Domain-Adversarial Neural Network (DANN), a [feature extractor](@entry_id:637338) is trained not only to predict the label but also to "fool" a domain discriminator that tries to identify the data's origin (source or target device). This encourages the extractor to learn features that are both predictive and domain-invariant, thereby mitigating representation-level covariate shift. To handle prior shift, this basic approach can be augmented by reweighting the source data or by using a conditional discriminator to align the class-conditional feature distributions. However, unsupervised [domain adaptation](@entry_id:637871) inherently assumes no concept shift. If concept shift is present, the decision boundary itself must be adapted, which requires some labeled data from the target domain for fine-tuning or [semi-supervised learning](@entry_id:636420) .