## Introduction
Controlling a fusion plasma within a tokamak is a grand challenge, demanding precise manipulation of temperature, density, and current profiles in a highly complex and nonlinear environment. To achieve stable, high-performance operation, controllers must not only guide the plasma to a desired state but also proactively respect a web of stringent operational constraints to prevent instabilities and protect the device. Traditional feedback control methods often fall short in this predictive, constraint-handling capacity. Model Predictive Control (MPC) emerges as a powerful solution, addressing this gap by leveraging a dynamic model of the plasma to forecast its future evolution and compute an optimal sequence of control actions in real-time. This article provides a comprehensive overview of MPC for [plasma profile control](@entry_id:1129800). The first chapter, **Principles and Mechanisms**, delves into the foundational pillars of the method, from deriving control-oriented physical models to formulating the constrained optimization problem and guaranteeing stability. Building on this, the second chapter, **Applications and Interdisciplinary Connections**, explores how MPC is deployed to solve critical challenges in fusion science, such as performance optimization, [disturbance rejection](@entry_id:262021), and the active suppression of magnetohydrodynamic (MHD) instabilities. Finally, the **Hands-On Practices** chapter provides concrete exercises to translate theory into practice. We begin by examining the core principles that enable MPC to transform a complex physical system into a tractable, real-time control problem.

## Principles and Mechanisms

The successful application of Model Predictive Control (MPC) to shape plasma profiles in fusion devices rests on a tripartite foundation: first, the development of a control-oriented physical model that is both sufficiently accurate and computationally tractable; second, the formulation of an optimization problem that encodes the desired performance objectives and respects stringent operational constraints; and third, the implementation of a robust, real-time algorithm that provides guarantees of stability and feasibility. This chapter elucidates the core principles and mechanisms underlying each of these pillars.

### Control-Oriented Modeling of Plasma Profiles

The dynamics of a tokamak plasma are governed by a complex, nonlinear system of coupled partial differential equations (PDEs). For real-time control, it is imperative to derive reduced models that capture the essential physics on the transport timescale, which is the characteristic timescale for the evolution of temperature, density, and current profiles.

#### Reduced Transport Models for Core Profiles

A standard approach to modeling for control involves deriving a set of one-dimensional (in the minor radius, $r$) transport equations for the key plasma profiles. These equations represent flux-surface-averaged conservation laws. For controlling the core profiles of electron temperature ($T_e$), [ion temperature](@entry_id:191275) ($T_i$), electron density ($n_e$), and safety factor ($q$), a minimal yet physically consistent model can be constructed . This model typically consists of four coupled parabolic PDEs.

The evolution of electron and ion temperatures is governed by energy [conservation equations](@entry_id:1122898) that balance transport, heating, and collisional energy exchange. The dominant transport mechanism across magnetic field lines in the core is diffusive, described by a Fourier-like heat law. The equations take the form:

$$
\frac{\partial}{\partial t}\left(\frac{3}{2} n_e T_e\right) = \frac{1}{r}\frac{\partial}{\partial r}\left(r n_e \chi_e \frac{\partial T_e}{\partial r}\right) + P_{e,\mathrm{aux}}(r,t) + P_{\Omega}(r,t) - Q_{ei}(r,t)
$$
$$
\frac{\partial}{\partial t}\left(\frac{3}{2} n_i T_i\right) = \frac{1}{r}\frac{\partial}{\partial r}\left(r n_i \chi_i \frac{\partial T_i}{\partial r}\right) + P_{i,\mathrm{aux}}(r,t) + Q_{ei}(r,t)
$$

Here, $\chi_e$ and $\chi_i$ are the effective electron and ion thermal diffusivities, respectively. The terms $P_{e,\mathrm{aux}}$ and $P_{i,\mathrm{aux}}$ represent power deposited by external heating systems (the control actuators). $P_{\Omega} = \eta j^2$ is the **Ohmic heating** generated by the [plasma current](@entry_id:182365) density $j$, where $\eta$ is the [plasma resistivity](@entry_id:196902). $Q_{ei}$ is the power transferred from electrons to ions through collisions, typically modeled as $Q_{ei} \propto n_e^2 (T_e - T_i) / T_e^{3/2}$.

Particle conservation for electrons (and ions, by [quasi-neutrality](@entry_id:197419) $n_i \approx n_e$) is described by a similar diffusion equation, based on Fick's law:
$$
\frac{\partial n_e}{\partial t} = \frac{1}{r}\frac{\partial}{\partial r}\left(r D \frac{\partial n_e}{\partial r}\right) + S_n(r,t)
$$
where $D$ is the particle diffusivity and $S_n$ is the particle source from actuators like [gas puffing](@entry_id:749726) or neutral beams.

Finally, the evolution of the current profile, and thus the safety factor $q$, is governed by [magnetic diffusion](@entry_id:187718). Combining Ohm's law with Maxwell's equations yields a diffusion equation for the toroidal current density $j$. A crucial coupling arises from the temperature dependence of the **Spitzer resistivity**, $\eta(T_e) \propto T_e^{-3/2}$. This means that heating the plasma (increasing $T_e$) reduces its resistivity, allowing current to diffuse faster. The current diffusion equation is:
$$
\frac{\partial j}{\partial t} \approx \frac{1}{\mu_0 r}\frac{\partial}{\partial r}\left(r \eta(T_e) \frac{\partial j}{\partial r}\right) + S_{cd}(r,t) + S_{bs}(r,t)
$$
Here, $\mu_0$ is the [vacuum permeability](@entry_id:186031), $S_{cd}$ is the externally driven non-inductive current source, and $S_{bs}$ is the **bootstrap current**, a self-generated current driven by pressure gradients. The safety factor $q(r,t)$ is then determined algebraically from the current profile $j(r,t)$.

This system of coupled PDEs forms the physical basis for a control-oriented model. It captures the essential dynamics: diffusive transport of heat and particles, and the critical nonlinear coupling between the temperature and current profiles through the temperature-dependent resistivity .

#### Semi-Discretization for State-Space Representation

To be used in a digital controller, the continuous PDE model must be converted into a discrete-time [state-space representation](@entry_id:147149), $x_{k+1} = f(x_k, u_k)$. This is typically a two-step process: [spatial discretization](@entry_id:172158) ([semi-discretization](@entry_id:163562)) followed by [temporal discretization](@entry_id:755844).

##### Finite-Volume and Finite-Difference Methods
A common approach is to discretize the radial domain into $N$ grid points or control volumes. Applying finite-volume or [finite-difference schemes](@entry_id:749361) to the spatial derivatives in the transport PDEs transforms the system of PDEs into a large system of coupled ordinary differential equations (ODEs) of the form $\dot{x}(t) = f(x(t), u(t))$. The state vector $x(t) \in \mathbb{R}^{n_x}$ is formed by stacking the values of each profile ($T_e, T_i, n_e, q$) at all $N$ grid points, so $n_x$ can be several hundred.

The structure of the linearized system, $\dot{x} = Ax + Bu$, reveals important properties . The [system matrix](@entry_id:172230) $A$, which represents the transport physics and internal couplings, is typically **block-tridiagonal**. This sparsity arises because local [discretization schemes](@entry_id:153074) (like central differences for diffusion) only couple a grid point to its immediate neighbors. The diagonal blocks are small, dense matrices (e.g., $4 \times 4$ if there are four coupled profiles) that represent the local physics at a single radial location, such as collisional energy exchange. The off-diagonal blocks represent the spatial transport between adjacent grid points. The input matrix $B$ maps the actuator commands to the state dynamics. Since heating and current-drive systems usually have localized deposition profiles, the columns of $B$ are also sparse, with non-zero entries only in the rows corresponding to the affected profile and spatial locations.

##### Basis Function Expansion and Galerkin Methods
An alternative to grid-based methods is to represent each profile as a linear combination of pre-defined basis functions, such as B-[splines](@entry_id:143749). For example, the electron temperature profile can be approximated as:
$$
T_e(\rho, t) \approx \sum_{i=1}^{m} x_i(t) N_i(\rho)
$$
where $\{N_i(\rho)\}$ are the B-[spline](@entry_id:636691) basis functions and $x_i(t)$ are the time-varying coefficients. The state vector $x(t) \in \mathbb{R}^m$ now consists of these coefficients. The dimension $m$ can be chosen significantly smaller than the number of grid points in a finite-difference model, achieving [model order reduction](@entry_id:167302) while retaining a smooth, physically plausible profile shape .

A **Galerkin projection** is used to derive the ODEs for the coefficients $x_i(t)$. This involves substituting the expansion into the [weak form](@entry_id:137295) of the PDE and integrating against each basis function. This procedure results in a semi-discrete system of the form:
$$
M \dot{x}(t) = -K x(t) + B U(t) + d(t)
$$
The **[mass matrix](@entry_id:177093)** $M$ arises from the time-derivative term and represents the inertia of the system. The **[stiffness matrix](@entry_id:178659)** $K$ arises from the spatial [diffusion operator](@entry_id:136699) and represents the rate of energy transport. For a diffusion problem, both $M$ and $K$ are symmetric and [positive definite](@entry_id:149459). The input vector $B$ projects the actuator deposition profile onto the basis functions. This method naturally incorporates boundary conditions and provides a low-order, structured model ideal for MPC.

#### Time Discretization and the Challenge of Stiffness

A critical challenge in discretizing the semi-discrete ODE model is **stiffness**. Plasma transport models are inherently stiff because they involve phenomena occurring on widely disparate timescales . For instance, [heat transport](@entry_id:199637) driven by electron [thermal diffusivity](@entry_id:144337) ($\chi_e \sim 1-10 \, \mathrm{m}^2/\mathrm{s}$) is much faster than the resistive diffusion of the magnetic field that governs the $q$ profile ($D_q \sim 0.01-0.1 \, \mathrm{m}^2/\mathrm{s}$).

The eigenvalues of the system matrix $A$ correspond to the negative inverse of the system's time constants. A fine spatial grid, needed to resolve sharp profile features, leads to very large-magnitude eigenvalues, scaling as $\lambda_{\max} \propto D / (\Delta r)^2$. For an **[explicit time integration](@entry_id:165797) scheme**, such as forward Euler, [numerical stability](@entry_id:146550) requires the time step $\Delta t$ to be on the order of the fastest timescale, i.e., $\Delta t \lt 2/|\lambda_{\max}|$. For typical plasma parameters and grid resolutions, this stability limit can be on the order of microseconds.

However, the control actions and desired profile evolution occur on much slower timescales, on the order of tens to hundreds of milliseconds. Using a time step of microseconds would make the MPC prediction horizon computationally intractable. Therefore, **[implicit time integration](@entry_id:171761) methods**, such as backward Euler or the Crank-Nicolson scheme, are essential. These methods are A-stable, meaning they are numerically stable for any choice of time step $\Delta t$ when applied to a stable linear system. This allows the use of a computationally feasible time step consistent with the control cycle rate (e.g., $10-50 \, \mathrm{ms}$), while still capturing the evolution of the stiff system accurately.

### The MPC Optimization Problem

With a discrete-time model $x_{k+1} = A x_k + B u_k$, MPC works by solving an open-loop [optimal control](@entry_id:138479) problem at each time step $k$ over a finite prediction horizon $N$. This optimization problem consists of a cost function to be minimized and a set of constraints to be satisfied.

#### The Predictive Control Objective

The cost function mathematically expresses the control goals. For profile tracking, a standard quadratic cost function is used :
$$
J = \sum_{i=0}^{N-1} \left( \| x_{k+i} - x^\star_{k+i} \|^2_{W_x} + \| u_{k+i} - u^\star_{k+i} \|^2_{W_u} + \| \Delta u_{k+i} \|^2_{W_{\Delta u}} \right) + \| x_{k+N} - x^\star_{k+N} \|^2_{W_f}
$$
where $\|z\|^2_W \equiv z^\top W z$. Each term serves a distinct purpose:

1.  **State Tracking Cost**: The term $\| x_{k+i} - x^\star_{k+i} \|^2_{W_x}$ penalizes deviations of the predicted state profile $x_{k+i}$ from the desired reference profile $x^\star_{k+i}$. The weighting matrix $W_x$ is crucial. It is typically diagonal and serves two roles: (i) **Normalization**, to make the errors of different physical quantities (e.g., temperature in keV, density in $10^{19} \, \mathrm{m}^{-3}$) dimensionless and comparable, and (ii) **Prioritization**, to place more importance on controlling certain profile features, such as maintaining $q>1$ in the core.

2.  **Input Cost**: The term $\| u_{k+i} - u^\star_{k+i} \|^2_{W_u}$ penalizes the deviation of the control inputs $u_{k+i}$ from a reference input trajectory $u^\star_{k+i}$ (which often corresponds to the steady-state input required for $x^\star$). The weight $W_u$ regularizes the control effort, reflecting operational costs and actuator preferences.

3.  **Input Rate-of-Change Cost**: The term $\| \Delta u_{k+i} \|^2_{W_{\Delta u}}$, where $\Delta u_{k+i} = u_{k+i} - u_{k+i-1}$, penalizes rapid changes in actuator commands. This is vital for two reasons. Physically, it respects the finite slew rates of hardware. From a control perspective, it promotes smooth actuator trajectories, which is essential for preventing oscillations in diffusive systems like plasma transport.

4.  **Terminal Cost**: The final term $\| x_{k+N} - x^\star_{k+N} \|^2_{W_f}$ penalizes the deviation from the reference at the end of the horizon. As will be discussed, a properly designed terminal cost is key to guaranteeing [closed-loop stability](@entry_id:265949).

#### Incorporating Operational Constraints

A primary advantage of MPC is its ability to handle constraints explicitly. For tokamak operation, this is not just beneficial but essential for safety and performance.

##### Actuator Limitations
Actuators have hard physical limits. For example, a heating system has a maximum power, and a [current drive](@entry_id:186346) system has limits on the current it can generate. These are translated into **[box constraints](@entry_id:746959)** on the input variables :
$$
u_{\min} \le u_k \le u_{\max}
$$
Furthermore, actuators cannot change their output instantaneously. These **slew rate limits** are translated into constraints on the change in input between consecutive time steps:
$$
|\Delta u_k| = |u_k - u_{k-1}| \le \Delta u_{\max} \quad \implies \quad -T_s \cdot r_{\max} \le u_k - u_{k-1} \le T_s \cdot r_{\max}
$$
where $r_{\max}$ is the maximum slew rate in physical units per second and $T_s$ is the controller sampling time.

##### Plasma Safety and Performance Constraints
To prevent plasma disruptions and maintain performance, several [state constraints](@entry_id:271616) must be respected. These are translated into inequalities involving the predicted [state variables](@entry_id:138790) $x_{k+i}$ . Key examples include:

-   **MHD Stability**: To prevent [sawtooth oscillations](@entry_id:754514), a major magnetohydrodynamic (MHD) instability, the on-axis safety factor must be kept above unity: $q(r=0, t) > 1$. This becomes a [linear inequality](@entry_id:174297) on the state variable for the on-axis safety factor, often with a small safety margin: $q_0[k] \ge 1 + \delta$.

-   **Density Limit**: To avoid disruptive density limits, the line-averaged plasma density $\bar{n}_e$ must remain below a fraction of the empirical **Greenwald limit** $n_G$: $\bar{n}_e(t) \le f_G n_G$. The line-averaged density is a linear combination of the nodal density values, so this also becomes a [linear inequality](@entry_id:174297) on the state vector.

-   **Gradient Limits**: To avoid triggering certain micro-instabilities or violating transport model assumptions, limits may be placed on the magnitude of profile gradients, such as $|\partial T_e / \partial r| \le G_{\max}$. Using finite differences, this becomes a set of linear inequalities on the nodal values of the temperature profile.

### Computational Formulation and Performance Guarantees

The MPC problem, comprising a quadratic objective and [linear constraints](@entry_id:636966), is a **Quadratic Program (QP)**, which can be solved efficiently. However, guaranteeing that the repeated solution of this problem leads to a stable and safe closed-loop system requires careful theoretical considerations.

#### The Sparse Quadratic Programming Formulation

The full MPC optimization problem can be formulated as a single, large QP by stacking all decision variables (states and inputs over the horizon) into one vector, $z = [x_0^\top, u_0^\top, x_1^\top, u_1^\top, \dots, x_N^\top]^\top$. The cost function becomes $\frac{1}{2} z^\top H z + f^\top z$, and the [linear dynamics](@entry_id:177848) and constraints are written as $A_{eq} z = b_{eq}$ and $C z \le d$ .

This "full-space" or "simultaneous" formulation reveals a critical structure. The Hessian matrix $H$ of the cost function is block-diagonal, as the cost at each time step depends only on variables at that step. The equality constraint matrix $A_{eq}$, which encodes the dynamics $x_{k+1} = A_k x_k + B_k u_k$, is highly sparse and has a banded or block-bidiagonal structure, coupling only adjacent time steps. The Karush-Kuhn-Tucker (KKT) system, which expresses the [optimality conditions](@entry_id:634091) for this QP, inherits this sparsity. The KKT matrix has a **block-tridiagonal-in-time** structure. This is immensely important because it allows the use of specialized solvers, such as banded [matrix factorization](@entry_id:139760) or Riccati-based methods, which can solve the QP with computational complexity that scales linearly with the horizon length $N$, rather than cubically as for a dense problem. This efficiency is what makes real-time MPC feasible.

#### Ensuring Stability and Recursive Feasibility

Simply solving the constrained optimization problem at each step does not automatically guarantee that the closed-loop system will be stable or that a [feasible solution](@entry_id:634783) will exist at the next time step (**[recursive feasibility](@entry_id:167169)**). To provide these guarantees, the MPC formulation is augmented with a **[terminal constraint](@entry_id:176488)** and a corresponding **terminal cost** .

The core idea is to define a **[terminal set](@entry_id:163892)** $\mathcal{X}_f$ around the target equilibrium state $x^\star$. This set has the property that it is **positively invariant** under a pre-designed, simple, stabilizing feedback law, $u = Kx$. This means that if the state enters $\mathcal{X}_f$, the local controller $K$ can keep it inside $\mathcal{X}_f$ forever while satisfying all constraints.

The MPC optimization then includes the additional constraint that the final state of the [prediction horizon](@entry_id:261473) must lie within this set: $x_{k+N} \in \mathcal{X}_f$. The terminal cost, $\| x_{k+N} - x^\star \|^2_{W_f}$, is chosen to be a **Lyapunov function** for the closed-loop system under the local controller $K$. A standard choice is to obtain the feedback gain $K$ and the terminal [cost matrix](@entry_id:634848) $W_f=P$ from the solution of the unconstrained infinite-horizon **Linear Quadratic Regulator (LQR)** problem. The matrix $P$ is found by solving the associated **Discrete Algebraic Riccati Equation (DARE)**.

This construction provides rigorous guarantees. At each time step, a [feasible solution](@entry_id:634783) is guaranteed to exist because the solution from the previous time step can be extended into a valid candidate solution. Stability is guaranteed because the optimal cost function $J^*$ serves as a Lyapunov function for the entire closed-loop system, decreasing at every time step.

### Robustness to Model Uncertainty

The models used for control are inherently uncertain; for instance, transport coefficients like $\chi_e$ are not known precisely. Robust MPC techniques are designed to guarantee stability and [constraint satisfaction](@entry_id:275212) despite this uncertainty.

#### Tube-Based Model Predictive Control

**Tube MPC** is a powerful framework for handling [model uncertainty](@entry_id:265539) . The strategy is to steer a *nominal* [system trajectory](@entry_id:1132840), $z_k$, which is surrounded by a "tube" that contains the true state of the plant, $x_k$. The true state is decomposed as $x_k = z_k + e_k$, where $e_k$ is the error between the true and nominal states. The control input is similarly decomposed: $u_k = v_k + K e_k$, where $v_k$ is the nominal input computed by the MPC optimizer, and $K e_k$ is an ancillary feedback action from a robustly stabilizing gain $K$ that aims to keep the error $e_k$ small.

The error $e_k$ evolves according to its own dynamics, which are driven by the difference between the true, uncertain plant ($A(\theta), B(\theta)$) and the nominal model ($A(\hat{\theta}), B(\hat{\theta})$), as well as any additive disturbances $w_k$:
$$
e_{k+1} = (A(\hat{\theta}) + B(\hat{\theta})K) e_k + \left[ (A(\theta) - A(\hat{\theta})) x_k + (B(\theta) - B(\hat{\theta})) u_k + w_k \right]
$$
The term in brackets acts as an effective disturbance to the error dynamics. By bounding this disturbance over all possible parameter uncertainties and all valid states and inputs, we can define an aggregate disturbance set $\mathcal{W}$.

#### Robust Constraint Satisfaction through Tightening

With the ancillary controller $K$ stabilizing the error dynamics, the set of all possible errors $e_k$ is guaranteed to remain within a **Robust Positive Invariant (RPI)** set, denoted $\Omega$. This set can be computed as the infinite Minkowski sum of the propagated disturbance set: $\Omega = \bigoplus_{i=0}^{\infty} A_K^i \mathcal{W}$.

To ensure that the true state $x_k = z_k + e_k$ and true input $u_k = v_k + Ke_k$ satisfy the original constraints $\mathcal{X}$ and $\mathcal{U}$ for *any* possible error $e_k \in \Omega$, the constraints on the nominal trajectory $(z_k, v_k)$ must be "tightened." This is achieved using the **Pontryagin difference** (Minkowski subtraction) :

-   The nominal state must lie within a tightened set: $z_k \in \mathcal{X} \ominus \Omega$.
-   The nominal input must lie within a tightened set: $v_k \in \mathcal{U} \ominus K\Omega$.

The MPC optimizer then computes the nominal trajectory $(z_k, v_k)$ subject to these more conservative, tightened constraints. This elegant mechanism ensures that even in the worst-case scenario of uncertainty, the true plasma state will evolve safely within its operational limits.