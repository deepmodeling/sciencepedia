{
    "hands_on_practices": [
        {
            "introduction": "The foundation of any digital twin is a predictive model that captures the essential dynamics of the physical system. This exercise guides you through the process of deriving such a model from first principles. By translating the physics of plasma vertical motion and actuator dynamics into a discrete-time state-space representation , you will develop a core skill in real-time modeling: creating a computationally tractable model ready for control design and state estimation.",
            "id": "3965909",
            "problem": "A Digital Twin (DT) of a tokamak’s vertical position control loop is to be deployed for real-time state prediction and estimation. The DT must use a discrete-time model that is obtained by linearizing the continuous-time physics around a nominal operating point and then discretizing under a Zero-Order Hold (ZOH) assumption. The continuous-time physics are as follows.\n\nThe plasma column’s vertical position is modeled as a rigid-body degree of freedom governed by Newton’s second law. Let the vertical displacement be denoted by $z$, with effective inertial parameter $m$, viscous damping coefficient $c$, and passive vertical restoring stiffness $k$. The net vertical force includes a contribution proportional to the coil current $i$ via a constant $\\alpha$, so that the vertical equation of motion is\n$$\nm\\,\\ddot{z} + c\\,\\dot{z} + k\\,z = \\alpha\\,i.\n$$\nThe vertical control actuator is an effective vertical field coil driven by a power supply with gain $K_{a}$ and coil parameters inductance $L$ and resistance $R$ described by the circuit equation implied by Kirchhoff’s voltage law,\n$$\nL\\,\\dot{i} + R\\,i = K_{a}\\,u,\n$$\nwhere $u$ is the commanded control input. A first-order anti-aliasing filter in the vertical position measurement provides the measured output $y$ with time constant $\\tau_{s}$ according to\n$$\n\\tau_{s}\\,\\dot{y} + y = z.\n$$\n\nConsider the operating point $(z_{0}, \\dot{z}_{0}, i_{0}, y_{0}, u_{0}) = (0, 0, 0, 0, 0)$. Define the state vector\n$$\nx = \\begin{pmatrix} z \\\\ \\dot{z} \\\\ i \\\\ y \\end{pmatrix},\n$$\nand assume the model parameters $m, c, k, \\alpha, L, R, K_{a}, \\tau_{s}$ are strictly positive and constant in time. The digital twin employs a discrete-time model with sampling period $T_{s}$ under Zero-Order Hold (ZOH) on the input $u$.\n\nTasks:\n1. Starting from the governing laws stated above and the operating point, perform a first-principles linearization to obtain the continuous-time Linear Time-Invariant (LTI) state-space model $\\dot{x} = A_{c}\\,x + B_{c}\\,u$, $y = C_{c}\\,x$ in terms of the physical parameters.\n2. From this model, derive the exact discrete-time state-space model under ZOH with sampling period $T_{s}$, namely $x_{k+1} = A_{d}\\,x_{k} + B_{d}\\,u_{k}$, $y_{k} = C_{d}\\,x_{k}$, where $A_{d}$, $B_{d}$, and $C_{d}$ are obtained from $A_{c}$, $B_{c}$, and $C_{c}$ using exact sampling.\n3. Using your discrete-time model, determine a closed-form analytic expression for the determinant of the discrete-time state transition matrix, $\\det(A_{d})$, expressed in terms of $m$, $c$, $L$, $R$, $\\tau_{s}$, and $T_{s}$ only. Your final answer must be a single closed-form expression. Do not round. No units are to be reported with the final answer.\n\nNote: You may assume the standard mathematical properties of Linear Time-Invariant (LTI) systems and matrix functions. All modeling assumptions and parameters are to be interpreted within the context of computational fusion science and engineering for real-time digital twin architectures.",
            "solution": "The problem statement will first be validated for scientific soundness, consistency, and completeness.\n\n### Step 1: Extract Givens\nThe problem provides the following information:\n- **Governing Equations**:\n  - Vertical motion: $m\\,\\ddot{z} + c\\,\\dot{z} + k\\,z = \\alpha\\,i$\n  - Coil circuit: $L\\,\\dot{i} + R\\,i = K_{a}\\,u$\n  - Measurement filter: $\\tau_{s}\\,\\dot{y} + y = z$\n- **Parameters**: The parameters $m, c, k, \\alpha, L, R, K_{a}, \\tau_{s}$ are strictly positive and constant.\n- **State Vector Definition**: $x = \\begin{pmatrix} z \\\\ \\dot{z} \\\\ i \\\\ y \\end{pmatrix}$\n- **Input and Output**: The control input is $u$, and the measured output is $y$.\n- **Operating Point**: The system is linearized around the equilibrium point $(z_{0}, \\dot{z}_{0}, i_{0}, y_{0}, u_{0}) = (0, 0, 0, 0, 0)$.\n- **Discretization Method**: Zero-Order Hold (ZOH) on the input $u$ with a sampling period of $T_{s}$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed against the validation criteria:\n- **Scientifically Grounded**: The provided equations represent standard, physically-based models. The vertical motion is a damped second-order system (Newton's second law), a common simplification for plasma vertical dynamics. The coil circuit is a first-order RL circuit (Kirchhoff's voltage law). The measurement model is a first-order low-pass filter. These are all well-established models in physics and control engineering. The problem is scientifically grounded.\n- **Well-Posed**: The problem is structured as a standard exercise in linear systems theory. It requests the derivation of state-space matrices from governing differential equations, a standard discretization procedure, and the calculation of a matrix determinant. The tasks are mathematically well-defined and lead to a unique solution.\n- **Objective**: The problem is stated in precise, technical language, free of any subjective or ambiguous terminology.\n- **Completeness and Consistency**: All necessary variables, parameters, and conditions are explicitly defined. The equations and definitions are internally consistent. The operating point at the origin simplifies the linearization, as the given equations are already linear and homogeneous (except for the input term).\n- **Other Flaws**: The problem does not exhibit any other flaws. It is not trivial, as it requires knowledge of the relationship between matrix exponentiation, determinants, and traces. It is formalizable, realistic within its modeling context, and verifiable.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\n### Solution Derivation\n\n**Task 1: Continuous-Time LTI State-Space Model**\n\nThe system is to be represented in the form $\\dot{x} = A_{c}\\,x + B_{c}\\,u$ and $y = C_{c}\\,x$. The state vector is $x = \\begin{pmatrix} x_{1} & x_{2} & x_{3} & x_{4} \\end{pmatrix}^{T} = \\begin{pmatrix} z & \\dot{z} & i & y \\end{pmatrix}^{T}$. We derive the state equations by expressing the first time derivative of each state variable in terms of the state variables themselves and the input $u$.\n\nFrom the definition of the state variables, we have:\n$$\n\\dot{x}_{1} = \\dot{z} = x_{2}\n$$\n\nFrom the vertical motion equation, $m\\,\\ddot{z} + c\\,\\dot{z} + k\\,z = \\alpha\\,i$, we solve for $\\ddot{z} = \\dot{x}_{2}$:\n$$\nm\\,\\dot{x}_{2} + c\\,x_{2} + k\\,x_{1} = \\alpha\\,x_{3}\n$$\n$$\n\\dot{x}_{2} = -\\frac{k}{m}x_{1} - \\frac{c}{m}x_{2} + \\frac{\\alpha}{m}x_{3}\n$$\n\nFrom the coil circuit equation, $L\\,\\dot{i} + R\\,i = K_{a}\\,u$, we solve for $\\dot{i} = \\dot{x}_{3}$:\n$$\nL\\,\\dot{x}_{3} + R\\,x_{3} = K_{a}\\,u\n$$\n$$\n\\dot{x}_{3} = -\\frac{R}{L}x_{3} + \\frac{K_{a}}{L}u\n$$\n\nFrom the measurement filter equation, $\\tau_{s}\\,\\dot{y} + y = z$, we solve for $\\dot{y} = \\dot{x}_{4}$:\n$$\n\\tau_{s}\\,\\dot{x}_{4} + x_{4} = x_{1}\n$$\n$$\n\\dot{x}_{4} = \\frac{1}{\\tau_{s}}x_{1} - \\frac{1}{\\tau_{s}}x_{4}\n$$\n\nSince the governing equations are already linear, linearization around the origin $(0,0,0,0,0)$ results in the same set of equations. We can now assemble the matrices $A_{c}$ and $B_{c}$:\n$$\n\\begin{pmatrix} \\dot{x}_{1} \\\\ \\dot{x}_{2} \\\\ \\dot{x}_{3} \\\\ \\dot{x}_{4} \\end{pmatrix} =\n\\begin{pmatrix}\n0 & 1 & 0 & 0 \\\\\n-\\frac{k}{m} & -\\frac{c}{m} & \\frac{\\alpha}{m} & 0 \\\\\n0 & 0 & -\\frac{R}{L} & 0 \\\\\n\\frac{1}{\\tau_{s}} & 0 & 0 & -\\frac{1}{\\tau_{s}}\n\\end{pmatrix}\n\\begin{pmatrix} x_{1} \\\\ x_{2} \\\\ x_{3} \\\\ x_{4} \\end{pmatrix}\n+\n\\begin{pmatrix} 0 \\\\ 0 \\\\ \\frac{K_{a}}{L} \\\\ 0 \\end{pmatrix}\nu\n$$\nThus, the continuous-time system matrix $A_{c}$ and input matrix $B_{c}$ are:\n$$\nA_{c} = \\begin{pmatrix}\n0 & 1 & 0 & 0 \\\\\n-\\frac{k}{m} & -\\frac{c}{m} & \\frac{\\alpha}{m} & 0 \\\\\n0 & 0 & -\\frac{R}{L} & 0 \\\\\n\\frac{1}{\\tau_{s}} & 0 & 0 & -\\frac{1}{\\tau_{s}}\n\\end{pmatrix}, \\quad\nB_{c} = \\begin{pmatrix} 0 \\\\ 0 \\\\ \\frac{K_{a}}{L} \\\\ 0 \\end{pmatrix}\n$$\nThe output is $y = x_{4}$. The output equation is $y = C_{c}\\,x$, so the output matrix $C_{c}$ is:\n$$\nC_{c} = \\begin{pmatrix} 0 & 0 & 0 & 1 \\end{pmatrix}\n$$\n\n**Task 2: Discrete-Time State-Space Model**\n\nFor a continuous-time LTI system $\\dot{x} = A_{c}\\,x + B_{c}\\,u$, the exact discrete-time equivalent model $x_{k+1} = A_{d}\\,x_{k} + B_{d}\\,u_{k}$ under a Zero-Order Hold (ZOH) on the input $u$ with sampling period $T_{s}$ is given by:\n$$\nA_{d} = \\exp(A_{c}T_{s})\n$$\n$$\nB_{d} = \\left( \\int_{0}^{T_{s}} \\exp(A_{c}\\tau) \\,d\\tau \\right) B_{c} = A_{c}^{-1} (A_{d} - I) B_{c} \\quad (\\text{if } A_c \\text{ is invertible})\n$$\nwhere $I$ is the identity matrix. The discrete-time output equation is $y_{k} = C_{d}\\,x_{k}$, where the output matrix is unchanged:\n$$\nC_{d} = C_{c} = \\begin{pmatrix} 0 & 0 & 0 & 1 \\end{pmatrix}\n$$\nThe problem does not require computing the explicit entries of $A_{d}$ and $B_{d}$, only their definitions via exact sampling, which are provided above.\n\n**Task 3: Determinant of the Discrete-Time State Transition Matrix**\n\nWe need to find a closed-form expression for $\\det(A_{d})$. The state transition matrix is $A_{d} = \\exp(A_{c}T_{s})$.\nA fundamental property of the matrix exponential, known as Jacobi's formula, relates the determinant of the exponential of a matrix to the trace of the matrix:\n$$\n\\det(\\exp(M)) = \\exp(\\mathrm{tr}(M))\n$$\nfor any square matrix $M$. In our case, $M = A_{c}T_{s}$. Applying this formula:\n$$\n\\det(A_{d}) = \\det(\\exp(A_{c}T_{s})) = \\exp(\\mathrm{tr}(A_{c}T_{s}))\n$$\nThe trace is a linear operator, so $\\mathrm{tr}(A_{c}T_{s}) = T_{s}\\,\\mathrm{tr}(A_{c})$. Therefore:\n$$\n\\det(A_{d}) = \\exp(T_{s}\\,\\mathrm{tr}(A_{c}))\n$$\nThe trace of a square matrix is the sum of its diagonal elements. From the matrix $A_{c}$ derived in Task 1:\n$$\nA_{c} = \\begin{pmatrix}\n0 & 1 & 0 & 0 \\\\\n-\\frac{k}{m} & -\\frac{c}{m} & \\frac{\\alpha}{m} & 0 \\\\\n0 & 0 & -\\frac{R}{L} & 0 \\\\\n\\frac{1}{\\tau_{s}} & 0 & 0 & -\\frac{1}{\\tau_{s}}\n\\end{pmatrix}\n$$\nThe trace of $A_{c}$ is:\n$$\n\\mathrm{tr}(A_{c}) = 0 + \\left(-\\frac{c}{m}\\right) + \\left(-\\frac{R}{L}\\right) + \\left(-\\frac{1}{\\tau_{s}}\\right) = -\\frac{c}{m} - \\frac{R}{L} - \\frac{1}{\\tau_{s}}\n$$\nSubstituting this into the expression for the determinant:\n$$\n\\det(A_{d}) = \\exp\\left(T_{s}\\left(-\\frac{c}{m} - \\frac{R}{L} - \\frac{1}{\\tau_{s}}\\right)\\right) = \\exp\\left(-T_{s}\\left(\\frac{c}{m} + \\frac{R}{L} + \\frac{1}{\\tau_{s}}\\right)\\right)\n$$\nThis expression depends only on the parameters $m$, $c$, $L$, $R$, $\\tau_{s}$, and $T_{s}$, as required. This result is physically significant, as it shows that the volume of the state-space parallelepiped contracts at each time step, which is expected for a stable physical system where energy dissipates (due to the damping $c$ and resistance $R$) and measurements lag. The eigenvalues of $A_d$ are related to the eigenvalues of $A_c$ by $\\lambda_{d,i} = \\exp(\\lambda_{c,i} T_s)$, and the determinant is the product of the eigenvalues, so $\\det(A_d) = \\prod_i \\exp(\\lambda_{c,i} T_s) = \\exp(\\sum_i \\lambda_{c,i} T_s) = \\exp(\\mathrm{tr}(A_c) T_s)$. This confirms the result.",
            "answer": "$$\n\\boxed{\\exp\\left(-T_{s}\\left(\\frac{c}{m} + \\frac{R}{L} + \\frac{1}{\\tau_{s}}\\right)\\right)}\n$$"
        },
        {
            "introduction": "A digital twin's true power lies in its ability to fuse model predictions with live sensor data, creating a state estimate that is more accurate than either source alone. This practice delves into the heart of this process: the Kalman filter update step. By deriving the optimal Kalman gain from fundamental principles of Bayesian estimation and applying it to a practical scenario , you will master the technique for optimally correcting a digital twin's state using noisy measurements.",
            "id": "3965967",
            "problem": "A core-coupled digital twin for a tokamak’s vertical plasma motion operates in real time at sampling period $\\Delta t$ and uses an Extended Kalman Filter (EKF) to fuse a predictive reduced-order model with magnetic diagnostics. At time step $k$, the twin linearizes the diagnostic model about the predicted state, yielding a locally linear measurement model of the form $y_{k} = H_{k} x_{k} + v_{k}$, where $x_{k} \\in \\mathbb{R}^{2}$ collects the normalized vertical position and vertical velocity, $H_{k} \\in \\mathbb{R}^{1 \\times 2}$ is the linearized measurement Jacobian, and $v_{k}$ is zero-mean Gaussian noise with covariance $R_{k} \\in \\mathbb{R}$. The EKF uses the innovation $y_{k} - H_{k} \\hat{x}_{k}^{-}$ to correct the prior estimate $\\hat{x}_{k}^{-}$, with a gain that must be chosen to minimize the posterior mean-squared error under standard linear-Gaussian assumptions.\n\nStarting from first principles, namely Bayes’ rule for linear Gaussian systems and the definition of the minimum mean-squared error estimator for jointly Gaussian random variables, derive the expression for the optimal linear innovation gain used in the EKF update at time $k$ in terms of the prior error covariance $P_{k}$, the measurement Jacobian $H_{k}$, and the measurement noise covariance $R_{k}$. Then evaluate this gain for the following real-time twin data at a particular time step:\n- Prior covariance $P_{k} = \\begin{pmatrix} 2.5 \\times 10^{-3} & 4.0 \\times 10^{-4} \\\\ 4.0 \\times 10^{-4} & 1.0 \\times 10^{-2} \\end{pmatrix}$,\n- Measurement Jacobian $H_{k} = \\begin{pmatrix} 0.75 & 0 \\end{pmatrix}$,\n- Measurement noise covariance $R_{k} = 1.6 \\times 10^{-3}$.\n\nAll quantities are expressed in normalized units (dimensionless). Report the gain as a $1 \\times 2$ row vector. Round your numerical entries to four significant figures.",
            "solution": "The problem requires the derivation of the optimal linear innovation gain for an Extended Kalman Filter (EKF) update step, followed by its numerical evaluation for a given set of parameters. The derivation must start from first principles, specifically the minimization of the posterior mean-squared error.\n\nFirst, let us establish the necessary definitions and notation. The state vector at time step $k$ is $x_k \\in \\mathbb{R}^2$, and the measurement is $y_k \\in \\mathbb{R}^1$. The linearized measurement model is given as:\n$$y_k = H_k x_k + v_k$$\nwhere $H_k \\in \\mathbb{R}^{1 \\times 2}$ is the measurement Jacobian, and $v_k$ is the measurement noise. The noise $v_k$ is assumed to be a zero-mean Gaussian random variable with covariance $R_k = E[v_k v_k^T] \\in \\mathbb{R}$.\n\nThe EKF propagates a state estimate and its error covariance. At the measurement update step, we have a prior state estimate $\\hat{x}_k^{-}$ and a prior error covariance $P_k = E[(x_k - \\hat{x}_k^{-})(x_k - \\hat{x}_k^{-})^T]$. It is noted that the problem statement uses the symbol $P_k$ for the prior error covariance, a notation more commonly reserved for the posterior covariance (with $P_k^{-}$ being the prior). We shall adhere to the problem's specified notation for consistency.\n\nThe posterior state estimate, $\\hat{x}_k$, is formed by correcting the prior estimate with the innovation, $y_k - H_k \\hat{x}_k^{-}$, scaled by a gain matrix $K_k$:\n$$\\hat{x}_k = \\hat{x}_k^{-} + K_k (y_k - H_k \\hat{x}_k^{-})$$\nThe objective is to find the gain $K_k$ that minimizes the posterior mean-squared error. This is equivalent to minimizing the trace of the posterior error covariance matrix, $P_k^{\\text{post}} = E[(x_k - \\hat{x}_k)(x_k - \\hat{x}_k)^T]$.\n\nLet us derive an expression for the posterior error, $e_k = x_k - \\hat{x}_k$.\n$$e_k = x_k - \\left( \\hat{x}_k^{-} + K_k (y_k - H_k \\hat{x}_k^{-}) \\right)$$\nSubstitute the measurement model $y_k = H_k x_k + v_k$:\n$$e_k = x_k - \\hat{x}_k^{-} - K_k (H_k x_k + v_k - H_k \\hat{x}_k^{-})$$\n$$e_k = (x_k - \\hat{x}_k^{-}) - K_k H_k (x_k - \\hat{x}_k^{-}) - K_k v_k$$\nLet the prior error be $e_k^{-} = x_k - \\hat{x}_k^{-}$. The expression simplifies to:\n$$e_k = (I - K_k H_k) e_k^{-} - K_k v_k$$\nNow, we compute the posterior error covariance $P_k^{\\text{post}} = E[e_k e_k^T]$.\n$$P_k^{\\text{post}} = E\\left[ \\left( (I - K_k H_k) e_k^{-} - K_k v_k \\right) \\left( (I - K_k H_k) e_k^{-} - K_k v_k \\right)^T \\right]$$\nThe prior state error $e_k^{-}$ is uncorrelated with the measurement noise $v_k$, meaning $E[e_k^{-} v_k^T] = 0$ and $E[v_k (e_k^{-})^T] = 0$. Expanding the expression gives:\n$$P_k^{\\text{post}} = (I - K_k H_k) E[e_k^{-} (e_k^{-})^T] (I - K_k H_k)^T + K_k E[v_k v_k^T] K_k^T$$\nSubstituting the definitions of the prior error covariance, $P_k$, and the measurement noise covariance, $R_k$:\n$$P_k^{\\text{post}} = (I - K_k H_k) P_k (I - K_k H_k)^T + K_k R_k K_k^T$$\nThis is the Joseph form of the covariance update. To find the optimal $K_k$, we expand this expression:\n$$P_k^{\\text{post}} = P_k - K_k H_k P_k - P_k (K_k H_k)^T + K_k H_k P_k (K_k H_k)^T + K_k R_k K_k^T$$\nSince $P_k$ is a covariance matrix, it is symmetric ($P_k = P_k^T$).\n$$P_k^{\\text{post}} = P_k - K_k H_k P_k - P_k H_k^T K_k^T + K_k H_k P_k H_k^T K_k^T + K_k R_k K_k^T$$\n$$P_k^{\\text{post}} = P_k - K_k H_k P_k - P_k H_k^T K_k^T + K_k (H_k P_k H_k^T + R_k) K_k^T$$\nThe cost function to minimize is the trace of this matrix, $J(K_k) = \\text{tr}(P_k^{\\text{post}})$. We differentiate $J(K_k)$ with respect to $K_k$ and set the result to zero.\n$$J(K_k) = \\text{tr}(P_k) - \\text{tr}(K_k H_k P_k) - \\text{tr}(P_k H_k^T K_k^T) + \\text{tr}(K_k (H_k P_k H_k^T + R_k) K_k^T)$$\nUsing the cyclic property of the trace, $\\text{tr}(AB) = \\text{tr}(BA)$, we have $\\text{tr}(P_k H_k^T K_k^T) = \\text{tr}(K_k^T P_k H_k^T) = \\text{tr}((H_k P_k K_k)^T) = \\text{tr}(K_k H_k P_k)$.\nLet $S_k = H_k P_k H_k^T + R_k$ be the innovation covariance. The cost function becomes:\n$$J(K_k) = \\text{tr}(P_k) - 2\\text{tr}(K_k H_k P_k) + \\text{tr}(K_k S_k K_k^T)$$\nUsing the standard matrix calculus identities $\\frac{\\partial \\text{tr}(AX)}{\\partial X} = A^T$ and $\\frac{\\partial \\text{tr}(XBX^T)}{\\partial X} = 2XB$ (for symmetric $B$), we differentiate $J(K_k)$:\n$$\\frac{\\partial J(K_k)}{\\partial K_k} = 0 - 2\\frac{\\partial}{\\partial K_k}\\text{tr}(K_k (H_k P_k)) + \\frac{\\partial}{\\partial K_k}\\text{tr}(K_k S_k K_k^T)$$\n$$\\frac{\\partial J(K_k)}{\\partial K_k} = -2(H_k P_k)^T + 2K_k S_k$$\nSince $P_k$ is symmetric, $(H_k P_k)^T = P_k^T H_k^T = P_k H_k^T$.\n$$\\frac{\\partial J(K_k)}{\\partial K_k} = -2 P_k H_k^T + 2K_k S_k$$\nSetting the derivative to zero to find the minimum:\n$$-2 P_k H_k^T + 2K_k S_k = 0$$\n$$K_k S_k = P_k H_k^T$$\n$$K_k (H_k P_k H_k^T + R_k) = P_k H_k^T$$\nSolving for $K_k$ yields the optimal linear innovation gain, also known as the Kalman gain:\n$$K_k = P_k H_k^T (H_k P_k H_k^T + R_k)^{-1}$$\nThis completes the derivation.\n\nNext, we evaluate this expression using the provided data:\n- Prior covariance $P_{k} = \\begin{pmatrix} 2.5 \\times 10^{-3} & 4.0 \\times 10^{-4} \\\\ 4.0 \\times 10^{-4} & 1.0 \\times 10^{-2} \\end{pmatrix}$\n- Measurement Jacobian $H_{k} = \\begin{pmatrix} 0.75 & 0 \\end{pmatrix}$\n- Measurement noise covariance $R_{k} = 1.6 \\times 10^{-3}$\n\nFirst, we compute the term $P_k H_k^T$:\n$$H_k^T = \\begin{pmatrix} 0.75 \\\\ 0 \\end{pmatrix}$$\n$$P_k H_k^T = \\begin{pmatrix} 2.5 \\times 10^{-3} & 4.0 \\times 10^{-4} \\\\ 4.0 \\times 10^{-4} & 1.0 \\times 10^{-2} \\end{pmatrix} \\begin{pmatrix} 0.75 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} (2.5 \\times 10^{-3})(0.75) \\\\ (4.0 \\times 10^{-4})(0.75) \\end{pmatrix} = \\begin{pmatrix} 1.875 \\times 10^{-3} \\\\ 3.0 \\times 10^{-4} \\end{pmatrix}$$\nNext, we compute the innovation covariance $S_k = H_k P_k H_k^T + R_k$. Since $H_k$ is a row vector and $P_k H_k^T$ is a column vector, their product is a scalar.\n$$H_k P_k H_k^T = \\begin{pmatrix} 0.75 & 0 \\end{pmatrix} \\begin{pmatrix} 1.875 \\times 10^{-3} \\\\ 3.0 \\times 10^{-4} \\end{pmatrix} = (0.75)(1.875 \\times 10^{-3}) = 1.40625 \\times 10^{-3}$$\n$$S_k = 1.40625 \\times 10^{-3} + 1.6 \\times 10^{-3} = 3.00625 \\times 10^{-3}$$\nThe inverse $S_k^{-1}$ is the reciprocal of this scalar value.\nNow we compute the gain $K_k$:\n$$K_k = P_k H_k^T S_k^{-1} = \\begin{pmatrix} 1.875 \\times 10^{-3} \\\\ 3.0 \\times 10^{-4} \\end{pmatrix} (3.00625 \\times 10^{-3})^{-1}$$\n$$K_k = \\begin{pmatrix} \\frac{1.875 \\times 10^{-3}}{3.00625 \\times 10^{-3}} \\\\ \\frac{3.0 \\times 10^{-4}}{3.00625 \\times 10^{-3}} \\end{pmatrix} = \\begin{pmatrix} \\frac{1.875}{3.00625} \\\\ \\frac{0.3}{3.00625} \\end{pmatrix}$$\n$$K_k \\approx \\begin{pmatrix} 0.6237005 \\\\ 0.0997920 \\end{pmatrix}$$\nThe dimension of the state is $n=2$ and the dimension of the measurement is $m=1$. Thus, the Kalman gain $K_k$ must be a $2 \\times 1$ matrix (a column vector) to ensure dimensional consistency in the update equation $\\hat{x}_k = \\hat{x}_k^{-} + K_k (y_k - H_k \\hat{x}_k^{-})$. However, the problem explicitly requests the answer as a $1 \\times 2$ row vector. We will therefore provide the transpose of the gain, $K_k^T$.\n\nRounding the components to four significant figures:\n$$K_{k,1} \\approx 0.6237$$\n$$K_{k,2} \\approx 0.09979$$\nThe final result as a $1 \\times 2$ row vector is:\n$$K_k^T \\approx \\begin{pmatrix} 0.6237 & 0.09979 \\end{pmatrix}$$",
            "answer": "$$\\boxed{\\begin{pmatrix} 0.6237 & 0.09979 \\end{pmatrix}}$$"
        },
        {
            "introduction": "Real-world digital twins must operate reliably despite imperfections like communication latency, which can destabilize a control system. This advanced practice explores how to guarantee stability in the presence of unknown, time-varying measurement delays using robust control theory. By applying the small-gain theorem to a discrete-time system , you will learn to derive delay-independent stability conditions, a critical step in building resilient and trustworthy real-time control architectures.",
            "id": "3965973",
            "problem": "A digital twin for a tokamak plasma vertical position coordinate uses a discrete-time model to synthesize real-time control in the presence of diagnostic latency. The plasma coordinate deviation about a nominal equilibrium, denoted by $x_k \\in \\mathbb{R}$ at discrete time index $k \\in \\mathbb{Z}_{\\ge 0}$, is described by the one-step linearized digital twin model\n$$\nx_{k+1} \\;=\\; a\\,x_k \\;+\\; b\\,u_k,\n$$\nwith output $y_k = x_k$, where $a \\in \\mathbb{R}$ and $b \\in \\mathbb{R}$ are constant digital twin parameters and $u_k \\in \\mathbb{R}$ is the control input. The real measurement available to the controller is delayed by an unknown, time-varying but bounded integer $d_k \\in \\{0,1,\\dots,d_{\\max}\\}$ arising from the diagnostic-acquisition and streaming pipeline. The controller applies delayed output feedback\n$$\nu_k \\;=\\; -\\,k\\,y_{k-d_k} \\;=\\; -\\,k\\,x_{k-d_k},\n$$\nwith scalar gain $k \\in \\mathbb{R}_{>0}$. Assume that $|a|<1$ and $b \\neq 0$.\n\nYou are asked to analyze the stability impact of the delayed measurement using discrete-time system theory and derive a robust, delay-independent sufficient condition guaranteeing asymptotic stability of the closed-loop for all admissible delay sequences $\\{d_k\\}$ with $0 \\le d_k \\le d_{\\max}$. Base your derivation only on fundamental input-output notions for discrete-time Linear Time-Invariant (LTI) systems, the Discrete-Time Fourier Transform (DTFT) on the unit circle, and the small-gain theorem for the induced $\\ell_2$-gain. In particular, you may model the unknown bounded delay as a causal operator with unit induced $\\ell_2$-gain.\n\n(a) Starting from the interconnection viewpoint of the LTI plant from $u$ to $x$ and the delayed feedback path, derive a sufficient inequality on $k$, $a$, and $b$ that guarantees robust closed-loop stability for all bounded integer delays $d_k \\in \\{0,1,\\dots,d_{\\max}\\}$. Your derivation must explicitly show the frequency-domain bound of the plant factor that appears in the small-gain condition.\n\n(b) For parameters $a=0.86$, $b=0.42$, and any integer bound $d_{\\max} \\ge 0$, compute the supremum $k_{\\max}>0$ of all controller gains $k$ that satisfy your sufficient condition in part (a), thereby ensuring robust stability for every admissible delay sequence. Provide your final result for $k_{\\max}$ as a reduced fraction. No rounding is required. The final answer must be a single real number.",
            "solution": "We begin with the discrete-time digital twin plant\n$$\nx_{k+1} \\;=\\; a\\,x_k \\;+\\; b\\,u_k,\\qquad y_k \\;=\\; x_k,\n$$\nand the delayed-output feedback law\n$$\nu_k \\;=\\; -\\,k\\,y_{k-d_k} \\;=\\; -\\,k\\,x_{k-d_k},\\qquad d_k \\in \\{0,1,\\dots,d_{\\max}\\}.\n$$\nWe analyze robustness with respect to the unknown, time-varying bounded delay using an input-output interconnection and the small-gain theorem for induced $\\ell_2$-gains.\n\nFirst, consider the LTI map from input $u$ to state $x$. Taking the $z$-transform under zero initial conditions, the transfer function from $U(z)$ to $X(z)$ is\n$$\nG(z) \\;=\\; \\frac{X(z)}{U(z)} \\;=\\; \\frac{b}{z - a}.\n$$\nThe delayed measurement in the feedback path can be represented as a causal operator $\\Delta$ acting on the signal $x$, where at constant delay $d$ the operator is the pure shift by $d$ samples, which in the frequency domain corresponds to multiplication by $z^{-d}$. For time-varying integer delay $d_k \\in \\{0,1,\\dots,d_{\\max}\\}$, the operator $\\Delta$ remains causal, bounded, and has induced $\\ell_2$-gain equal to $1$, since shifts on $\\ell_2$ preserve signal energy. Thus, we model the uncertainty as a causal operator $\\Delta$ with induced $\\ell_2$-gain\n$$\n\\|\\Delta\\| \\;=\\; 1.\n$$\n\nThe feedback interconnection can then be expressed as\n$$\nx \\;=\\; G \\bigl( -k\\, \\Delta\\, x \\bigr).\n$$\nThis is the standard feedback of a stable LTI $G$ with a bounded causal operator $\\Delta$ scaled by the real gain $k$. The small-gain theorem for induced $\\ell_2$-gains states that the feedback interconnection is well-posed and Lur’e-stable if\n$$\n\\| -k\\, G \\|_{\\infty} \\cdot \\|\\Delta\\| \\;<\\; 1,\n$$\nwhere $\\|G\\|_{\\infty}$ denotes the $\\mathcal{H}_{\\infty}$-norm of the stable LTI map $G$, i.e., the supremum of the magnitude of $G(e^{\\mathrm{j}\\omega})$ over $\\omega \\in [-\\pi,\\pi]$. Since $|a|<1$, the plant $G$ is stable, and since $\\|\\Delta\\|=1$, the sufficient robust stability condition reduces to\n$$\n|k| \\cdot \\|G\\|_{\\infty} \\;<\\; 1.\n$$\nWe next compute $\\|G\\|_{\\infty}$. For real $a$ and $b$, we have on the unit circle $z = \\exp(\\mathrm{j}\\omega)$\n$$\nG\\bigl(e^{\\mathrm{j}\\omega}\\bigr) \\;=\\; \\frac{b}{e^{\\mathrm{j}\\omega} - a},\n$$\nhence\n$$\n\\bigl|G\\bigl(e^{\\mathrm{j}\\omega}\\bigr)\\bigr| \\;=\\; \\frac{|b|}{\\left|e^{\\mathrm{j}\\omega} - a\\right|}.\n$$\nTherefore,\n$$\n\\|G\\|_{\\infty} \\;=\\; |b| \\cdot \\sup_{\\omega \\in [-\\pi,\\pi]} \\frac{1}{\\left|e^{\\mathrm{j}\\omega} - a\\right|}.\n$$\nTo evaluate the supremum, observe that\n$$\n\\left|e^{\\mathrm{j}\\omega} - a\\right|^{2} \\;=\\; \\left(\\cos\\omega - a\\right)^{2} + \\left(\\sin\\omega\\right)^{2} \\;=\\; \\cos^2\\omega - 2a\\cos\\omega + a^2 + \\sin^2\\omega = 1 + a^{2} - 2 a \\cos\\omega.\n$$\nFor fixed real $a$, the minimum of $1 + a^{2} - 2 a \\cos\\omega$ over $\\omega$ occurs at $\\cos\\omega = \\operatorname{sign}(a)$, yielding\n$$\n\\min_{\\omega} \\left|e^{\\mathrm{j}\\omega} - a\\right| \\;=\\; \\sqrt{1 + a^2 - 2a \\operatorname{sign}(a)} = \\sqrt{1 + a^2 - 2|a|} = \\sqrt{(1-|a|)^2} = 1 - |a|.\n$$\nThus,\n$$\n\\sup_{\\omega} \\frac{1}{\\left|e^{\\mathrm{j}\\omega} - a\\right|} \\;=\\; \\frac{1}{1 - |a|},\n$$\nand consequently\n$$\n\\|G\\|_{\\infty} \\;=\\; \\frac{|b|}{1 - |a|}.\n$$\nThe small-gain sufficient condition becomes\n$$\n|k| \\cdot \\frac{|b|}{1 - |a|} \\;<\\; 1 \\quad \\Longleftrightarrow \\quad |k b| \\;<\\; 1 - |a|.\n$$\nSince we consider $k>0$, this yields the delay-independent robust stability condition\n$$\nk \\;<\\; \\frac{1 - |a|}{|b|}.\n$$\nThis condition guarantees robust asymptotic stability of the closed-loop for any bounded integer delay sequence $d_k \\in \\{0,1,\\dots,d_{\\max}\\}$, because the uncertain delay operator $\\Delta$ has induced $\\ell_2$-gain equal to $1$ independently of $d_{\\max}$, and the plant factor is bounded by $\\|G\\|_{\\infty}$.\n\nFor part (b), substitute $a = 0.86$ and $b = 0.42$. Then\n$$\n1 - |a| \\;=\\; 1 - 0.86 \\;=\\; 0.14,\\qquad |b| \\;=\\; 0.42,\n$$\nso the supremum of admissible gains is\n$$\nk_{\\max} \\;=\\; \\frac{1 - |a|}{|b|} \\;=\\; \\frac{0.14}{0.42} \\;=\\; \\frac{14}{42} \\;=\\; \\frac{1}{3}.\n$$\nThis value is the supremum; any $k$ strictly less than $\\frac{1}{3}$ satisfies the sufficient small-gain inequality and thus guarantees robust stability for all integer delays $d_k$ with $0 \\le d_k \\le d_{\\max}$, for any $d_{\\max} \\ge 0$.",
            "answer": "$$\\boxed{\\frac{1}{3}}$$"
        }
    ]
}