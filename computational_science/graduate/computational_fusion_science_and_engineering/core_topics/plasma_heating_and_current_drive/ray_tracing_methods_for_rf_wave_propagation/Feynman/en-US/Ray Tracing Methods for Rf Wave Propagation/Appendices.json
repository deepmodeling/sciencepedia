{
    "hands_on_practices": [
        {
            "introduction": "Ray tracing simulates wave propagation in a continuous medium, but plasma equilibrium data is typically available only on a discrete grid. To solve the ray equations, which are continuous Ordinary Differential Equations (ODEs), we must be able to evaluate plasma parameters and their gradients *anywhere* in the domain. This exercise  explores how the choice of interpolation method directly impacts the physical realism and numerical stability of the simulation, challenging you to select a scheme that provides the required smoothness while preserving known physical constraints like monotonicity.",
            "id": "4038226",
            "problem": "In a tokamak equilibrium specified in straight-field-line flux coordinates with poloidal flux label $\\psi \\in [0,\\psi_{\\text{edge}}]$ and poloidal angle $\\theta \\in [-\\pi,\\pi]$ (periodic in $\\theta$), you are given tabulated plasma profiles on a tensor-product grid $\\{\\psi_i\\}_{i=0}^{N_\\psi}$ and $\\{\\theta_j\\}_{j=0}^{N_\\theta-1}$:\n- Electron density $n_e(\\psi)$ defined on $\\{\\psi_i\\}$ and known to be monotone decreasing with $\\psi$.\n- Electron temperature $T_e(\\psi)$ defined on $\\{\\psi_i\\}$ and known to be monotone decreasing with $\\psi$.\n- Magnetic field vector $\\mathbf{B}(\\psi,\\theta)$ defined on $\\{(\\psi_i,\\theta_j)\\}$ and periodic in $\\theta$ with period $2\\pi$.\n\nYou intend to perform high-accuracy Radio Frequency (RF) wave ray tracing in the eikonal or geometric optics limit. The ray path $\\mathbf{x}(s)$ and wavevector $\\mathbf{k}(s)$ follow a Hamiltonian system derived from the dispersion function $D(\\mathbf{x},\\mathbf{k},\\omega)=0$, with $\\omega$ fixed, where $D$ depends smoothly on $n_e$, $T_e$ (through collisionality and dielectric response), and $\\mathbf{B}$ (through cyclotron terms). The governing equations for rays may be written schematically as\n$$\n\\frac{d\\mathbf{x}}{ds} \\propto \\frac{\\partial D}{\\partial \\mathbf{k}}, \\qquad \\frac{d\\mathbf{k}}{ds} \\propto -\\frac{\\partial D}{\\partial \\mathbf{x}},\n$$\nwith proportionality constants involving $\\partial D/\\partial \\omega$. To ensure well-posedness and stability of the numerical integration of these ordinary differential equations (ODEs), $\\nabla_{\\mathbf{x}} D$ and $\\nabla_{\\mathbf{k}} D$ must be continuous and at least locally Lipschitz in $\\mathbf{x}$ and $\\mathbf{k}$. In addition, avoiding spurious turning points or artificial cutoffs requires that the interpolants for flux functions $n_e(\\psi)$ and $T_e(\\psi)$ preserve monotonicity in $\\psi$, while the interpolant for $\\mathbf{B}(\\psi,\\theta)$ must respect $2\\pi$-periodicity in $\\theta$ and provide smooth $\\theta$-derivatives.\n\nYou will construct continuous interpolants over the domain for evaluating $D$ and its gradients at off-grid ray locations. Which of the following strategies is the most appropriate choice to simultaneously satisfy:\n(i) monotonicity preservation for $n_e(\\psi)$ and $T_e(\\psi)$,\n(ii) periodicity and smoothness in $\\theta$ for $\\mathbf{B}(\\psi,\\theta)$,\n(iii) at least $C^1$ continuity in space so that $\\nabla_{\\mathbf{x}} D$ exists and is continuous,\n(iv) avoidance of spurious oscillations or overshoot that could create non-physical extrema, and\n(v) computational efficiency suitable for repeated evaluation during ray tracing?\n\nA. Use unconstrained natural cubic splines in $\\psi$ for $n_e(\\psi)$ and $T_e(\\psi)$, and standard bicubic splines in $(\\psi,\\theta)$ for each component of $\\mathbf{B}(\\psi,\\theta)$ without enforcing periodicity in $\\theta$.\n\nB. Use piecewise linear interpolation in $\\psi$ for $n_e(\\psi)$ and $T_e(\\psi)$, and bilinear interpolation in $(\\psi,\\theta)$ for $\\mathbf{B}(\\psi,\\theta)$; compute gradients of $D$ by differentiating the piecewise linear/bilinear interpolants where defined.\n\nC. For $n_e(\\psi)$ and $T_e(\\psi)$, use a shape-preserving Piecewise Cubic Hermite Interpolating Polynomial (PCHIP) in $\\psi$ to enforce monotonicity with $C^1$ continuity. For $\\mathbf{B}(\\psi,\\theta)$, use a tensor-product interpolant that is PCHIP in $\\psi$ and a periodic cubic spline in $\\theta$ with $2\\pi$-periodic boundary conditions; compute spatial derivatives analytically from the interpolants.\n\nD. For $n_e(\\psi)$ and $T_e(\\psi)$, use an order-$5$ Weighted Essentially Non-Oscillatory (WENO) reconstruction in $\\psi$; for $\\mathbf{B}(\\psi,\\theta)$, use a truncated Fourier series of order $N$ in $\\theta$ combined with polynomial interpolation in $\\psi$; compute $\\nabla_{\\mathbf{x}} D$ using finite differences applied to the reconstructed fields.\n\nE. Fit global Chebyshev polynomials in $\\psi$ to $n_e(\\psi)$ and $T_e(\\psi)$ using least squares, and use non-periodic bicubic interpolation in $(\\psi,\\theta)$ for $\\mathbf{B}(\\psi,\\theta)$; compute derivatives from the fitted polynomials and bicubic surfaces.\n\nChoose the best option and justify your choice by reasoning from the eikonal Hamiltonian formulation, the required continuity of $D$ and its gradients, the known monotonic and periodic structure of the profiles, and the numerical properties of the listed interpolation schemes.",
            "solution": "The problem asks for the most appropriate interpolation strategy for plasma profiles ($n_e$, $T_e$) and the magnetic field ($\\mathbf{B}$) to be used in a high-accuracy RF wave ray tracing code. The ray tracing equations form a Hamiltonian system, which imposes strict requirements on the continuity and differentiability of the underlying fields used to construct the dispersion function $D(\\mathbf{x}, \\mathbf{k}, \\omega)$.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n*   **Coordinates:** Straight-field-line flux coordinates $(\\psi, \\theta)$, where $\\psi \\in [0, \\psi_{\\text{edge}}]$ is the poloidal flux label and $\\theta \\in [-\\pi, \\pi]$ is the poloidal angle.\n*   **Data:**\n    *   Electron density $n_e(\\psi)$ given on a grid $\\{\\psi_i\\}$, known to be monotone decreasing.\n    *   Electron temperature $T_e(\\psi)$ given on a grid $\\{\\psi_i\\}$, known to be monotone decreasing.\n    *   Magnetic field vector $\\mathbf{B}(\\psi, \\theta)$ given on a tensor-product grid $\\{(\\psi_i, \\theta_j)\\}$, known to be periodic in $\\theta$ with period $2\\pi$.\n*   **Physics Model:** Ray tracing in the eikonal (geometric optics) limit.\n*   **Governing Equations:** Hamiltonian ODEs for ray position $\\mathbf{x}(s)$ and wavevector $\\mathbf{k}(s)$:\n    $$ \\frac{d\\mathbf{x}}{ds} \\propto \\frac{\\partial D}{\\partial \\mathbf{k}}, \\qquad \\frac{d\\mathbf{k}}{ds} \\propto -\\frac{\\partial D}{\\partial \\mathbf{x}} $$\n    where $D(\\mathbf{x}, \\mathbf{k}, \\omega) = 0$ is the dispersion relation.\n*   **Requirements on Interpolants:** The problem states five explicit criteria the chosen interpolation strategy must satisfy:\n    1.  (i) Monotonicity preservation for $n_e(\\psi)$ and $T_e(\\psi)$.\n    2.  (ii) Periodicity and smoothness in $\\theta$ for $\\mathbf{B}(\\psi, \\theta)$.\n    3.  (iii) At least $C^1$ continuity in space to ensure $\\nabla_{\\mathbf{x}} D$ is continuous.\n    4.  (iv) Avoidance of spurious oscillations or overshoot.\n    5.  (v) Computational efficiency.\n\n**Step 2: Validate Using Extracted Givens**\n\nThe problem statement is scientifically sound, well-posed, and objective.\n*   **Scientific Grounding:** The use of Hamiltonian mechanics to describe ray propagation (an application of the eikonal approximation) in a plasma medium described by a dispersion relation is a standard and fundamental technique in plasma physics. The specification of plasma profiles in flux coordinates is standard practice in fusion research.\n*   **Well-Posedness:** The problem sets forth a clear set of well-defined mathematical and numerical constraints (monotonicity, periodicity, $C^1$ continuity, efficiency) and asks for the evaluation of different numerical schemes against these constraints. This is a standard problem in scientific computing.\n*   **Objectivity & Completeness:** The problem is stated in precise, technical language. All necessary information regarding the physical context and numerical requirements is provided. The constraints are not contradictory, although they are challenging to satisfy simultaneously with simple methods. The question seeks the \"most appropriate\" option, which is a reasonable objective in comparing numerical methods.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is valid. I will proceed with the analysis of the options.\n\n### Solution Derivation and Option Analysis\n\nThe core of the problem lies in the properties of the right-hand side of the ray equations. For the numerical integration of the ODE system to be stable and accurate, the vector field defining the dynamics, which involves $\\nabla_{\\mathbf{x}} D$ and $\\nabla_{\\mathbf{k}} D$, must be at least continuous. The dispersion function $D$ depends on $n_e$, $T_e$, and $\\mathbf{B}$. By the chain rule, $\\nabla_{\\mathbf{x}} D$ involves the spatial gradients of these plasma quantities. Therefore, the interpolants for $n_e$, $T_e$, and $\\mathbf{B}$ must be at least $C^1$ (continuously differentiable) in the spatial coordinates. This is the origin of requirement (iii). The other requirements stem from the known physical properties of the profiles and the need to avoid numerical artifacts.\n\n**A. Use unconstrained natural cubic splines in $\\psi$ for $n_e(\\psi)$ and $T_e(\\psi)$, and standard bicubic splines in $(\\psi,\\theta)$ for each component of $\\mathbf{B}(\\psi,\\theta)$ without enforcing periodicity in $\\theta$.**\n\n*   **Analysis:** Natural cubic splines provide $C^2$ continuity, satisfying requirement (iii). However, they are not guaranteed to preserve the monotonicity of the original discrete data. They can introduce spurious oscillations and overshoots, especially in regions of changing curvature, which violates requirements (i) and (iv) and can lead to non-physical results like negative density or artificial turning points for the wave. Standard bicubic splines with default boundary conditions (e.g., `not-a-knot`) are not periodic. This means the interpolated value of $\\mathbf{B}$ and, more critically, its derivatives will have a jump discontinuity at the $\\theta=-\\pi$ and $\\theta=\\pi$ boundary, violating requirement (ii).\n*   **Verdict:** **Incorrect**. This option fails on the critical requirements of monotonicity and periodicity.\n\n**B. Use piecewise linear interpolation in $\\psi$ for $n_e(\\psi)$ and $T_e(\\psi)$, and bilinear interpolation in $(\\psi,\\theta)$ for $\\mathbf{B}(\\psi,\\theta)$; compute gradients of $D$ by differentiating the piecewise linear/bilinear interpolants where defined.**\n\n*   **Analysis:** Piecewise linear interpolation preserves monotonicity (i) and avoids overshoots (iv). However, it is only a $C^0$ continuous function. Its first derivative is piecewise constant and has jump discontinuities at the grid points. Similarly, bilinear interpolation for $\\mathbf{B}$ is $C^0$, but its gradients are discontinuous at the boundaries of each grid cell. This means that the crucial term $\\nabla_{\\mathbf{x}} D$ will be discontinuous throughout the domain. Integrating an ODE with a discontinuous right-hand side is problematic; it requires special handling, and standard high-order solvers will fail to converge properly, leading to large errors and instability. This violates the central requirement (iii) of $C^1$ continuity.\n*   **Verdict:** **Incorrect**. This option fails to provide the necessary smoothness for the Hamiltonian system of ODEs.\n\n**C. For $n_e(\\psi)$ and $T_e(\\psi)$, use a shape-preserving Piecewise Cubic Hermite Interpolating Polynomial (PCHIP) in $\\psi$ to enforce monotonicity with $C^1$ continuity. For $\\mathbf{B}(\\psi,\\theta)$, use a tensor-product interpolant that is PCHIP in $\\psi$ and a periodic cubic spline in $\\theta$ with $2\\pi$-periodic boundary conditions; compute spatial derivatives analytically from the interpolants.**\n\n*   **Analysis:** This option provides a comprehensive and correct solution.\n    *   **For $n_e(\\psi)$ and $T_e(\\psi)$:** PCHIP is a piecewise cubic interpolant specifically designed to be shape-preserving. If the input data is monotonic, the resulting interpolant is guaranteed to be monotonic. It is also, by construction, $C^1$ continuous. This simultaneously satisfies requirements (i), (iii), and (iv).\n    *   **For $\\mathbf{B}(\\psi,\\theta)$:** A tensor-product construction is appropriate for the grid. Using PCHIP in the $\\psi$ direction provides $C^1$ smoothness and good shape-preserving behavior. Using periodic cubic splines in the $\\theta$ direction provides $C^2$ smoothness and correctly enforces the $2\\pi$-periodicity of the function and its first two derivatives at the boundary. This satisfies requirement (ii). The resulting tensor-product surface is $C^1$ in both variables, thus satisfying the global requirement (iii).\n    *   **Efficiency and Gradients:** Both PCHIP and cubic splines are local schemes, meaning evaluation at a point $(\\psi, \\theta)$ only depends on data in the immediate neighborhood. This makes them computationally efficient for repeated evaluations inside an ODE solver, satisfying (v). The piecewise polynomial nature of these splines means their derivatives can be computed analytically and exactly, which is the most accurate and robust way to evaluate $\\nabla_{\\mathbf{x}} D$.\n*   **Verdict:** **Correct**. This strategy systematically addresses and satisfies all five requirements using well-established, appropriate numerical methods.\n\n**D. For $n_e(\\psi)$ and $T_e(\\psi)$, use an order-$5$ Weighted Essentially Non-Oscillatory (WENO) reconstruction in $\\psi$; for $\\mathbf{B}(\\psi,\\theta)$, use a truncated Fourier series of order $N$ in $\\theta$ combined with polynomial interpolation in $\\psi$; compute $\\nabla_{\\mathbf{x}} D$ using finite differences applied to the reconstructed fields.**\n\n*   **Analysis:** WENO schemes are high-order, non-oscillatory methods, often used in solving hyperbolic PDEs with shocks. While they can preserve monotonicity, they are significantly more complex and computationally expensive for simple function interpolation than PCHIP. A truncated Fourier series is an excellent choice for representing a smooth periodic function in $\\theta$. However, the suggestion to use finite differences to compute gradients is a significant drawback. Given that an analytical interpolant is constructed, one should use its analytical derivative. Using finite differences introduces an additional source of truncation error and can be less stable than using analytical derivatives, especially near boundaries or regions of high curvature. This approach is suboptimal for a \"high-accuracy\" ray tracing code compared to analytic differentiation of the interpolant.\n*   **Verdict:** **Incorrect**. While containing valid elements (Fourier series), this option proposes an overly complex scheme for the 1D profiles (WENO) and a suboptimal method for computing gradients (finite differences), making it less \"appropriate\" than option C.\n\n**E. Fit global Chebyshev polynomials in $\\psi$ to $n_e(\\psi)$ and $T_e(\\psi)$ using least squares, and use non-periodic bicubic interpolation in $(\\psi,\\theta)$ for $\\mathbf{B}(\\psi,\\theta)$; compute derivatives from the fitted polynomials and bicubic surfaces.**\n\n*   **Analysis:** Global polynomial fits, including Chebyshev polynomials, are not guaranteed to be monotonic, even if the data is. A least-squares fit will provide a smooth approximation, but it can exhibit oscillations (a distributed version of Gibbs phenomenon) that violate the monotonicity of the physical profiles, thus failing requirement (i). The use of \"non-periodic bicubic interpolation\" for $\\mathbf{B}(\\psi, \\theta)$ is the same fundamental flaw as in option A: it fails to respect the domain's periodicity, violating requirement (ii).\n*   **Verdict:** **Incorrect**. This option fails on the same two fundamental requirements as option A: monotonicity and periodicity.",
            "answer": "$$\\boxed{C}$$"
        },
        {
            "introduction": "Once the plasma medium is represented by smooth, continuous functions, the ray's path is found by integrating Hamilton's equations. These equations form a Hamiltonian system, which possesses special geometric properties, such as the conservation of energy in a static medium and the preservation of phase-space volume. This practice  delves into the crucial difference between standard and 'geometric' numerical integrators, demonstrating why methods that respect the underlying Hamiltonian structure are essential for ensuring the long-term physical fidelity of simulations.",
            "id": "4038257",
            "problem": "A high-frequency Radio Frequency (RF) wave is launched into a static, axisymmetric tokamak equilibrium with electron density $n_{e}(\\mathbf{x})$ and magnetic field $\\mathbf{B}(\\mathbf{x})$ that are independent of laboratory time. In the geometric optics limit, the wave phase is represented by an eikonal $S(\\mathbf{x})$ with local wavevector $\\mathbf{k}(\\mathbf{x}) = \\nabla S(\\mathbf{x})$, and the cold plasma dispersion relation defines a dispersion function $D(\\mathbf{x},\\mathbf{k},\\omega)=0$ at fixed angular frequency $\\omega$. Rays are integrated over a ray parameter $\\tau$ via a Hamiltonian system\n$$\n\\frac{d\\mathbf{x}}{d\\tau} = \\frac{\\partial H}{\\partial \\mathbf{k}}, \\qquad \\frac{d\\mathbf{k}}{d\\tau} = -\\frac{\\partial H}{\\partial \\mathbf{x}},\n$$\nwhere $H(\\mathbf{x},\\mathbf{k})$ is a Hamiltonian chosen so that the ray trajectories lie on the dispersion surface $D(\\mathbf{x},\\mathbf{k},\\omega)=0$; for example, one may use $H(\\mathbf{x},\\mathbf{k}) = \\tfrac{1}{2} D(\\mathbf{x},\\mathbf{k},\\omega)$, which is independent of $\\tau$ when the medium is stationary.\n\nFrom first principles of Hamiltonian dynamics, if $H$ has no explicit $\\tau$ dependence, then $dH/d\\tau = 0$ for the exact flow and the symplectic two-form in phase space, $d\\mathbf{k} \\wedge d\\mathbf{x}$, is exactly preserved along the flow (Liouville volume conservation). However, numerical integration introduces truncation error and possibly breaks these invariants unless the method respects the symplectic structure. In practice, RF ray trajectories in a tokamak may traverse large distances, pass near refraction layers and cutoffs where $\\lVert \\nabla n_{e}(\\mathbf{x}) \\rVert$ and $\\lVert \\nabla \\mathbf{B}(\\mathbf{x}) \\rVert$ are large, and can be stiff due to rapid variation of $\\partial H/\\partial \\mathbf{x}$ and $\\partial H/\\partial \\mathbf{k}$.\n\nSelect the most appropriate numerical integrator for this Hamiltonian ray system with the dual goals of (i) controlling local error in regions of strong gradients and (ii) preserving the long-time conservation properties associated with Hamiltonian flow (bounded energy error and phase-space volume preservation). Justify the choice based on conservation properties and error control trade-offs.\n\nWhich option best satisfies these goals?\n\nA. Use an embedded adaptive explicit Runge–Kutta method (such as Dormand–Prince $5(4)$) with state-dependent step size control to enforce a tight local error tolerance everywhere.\n\nB. Use a fixed-step, fourth-order symplectic composition integrator (for example, a Yoshida composition of the leapfrog scheme) applied after a Sundman reparameterization of the ray parameter, introducing a new parameter $s$ defined by $ds/d\\tau = g(\\mathbf{x},\\mathbf{k})$ that clusters steps near refraction layers, while integrating with a constant step $\\Delta s$.\n\nC. Use an implicit Gauss–Legendre Runge–Kutta method of order $2s$ with adaptive, state-dependent step size control, relying on its symplecticity to conserve the Hamiltonian $H$ exactly and preserve phase-space volume, even with varying steps.\n\nD. Use a variable-order linear multistep predictor–corrector scheme (Adams–Bashforth–Moulton) with aggressive adaptivity to minimize computational cost while maintaining acceptable accuracy.\n\nChoose the best option and provide a concise justification tied to the conservation of $H$ and phase-space volume and to the need for reliable error control in stiff regions. Assume computational resources permit implicit solves when needed but prioritize physical fidelity of long integrations across many characteristic times of the ray dynamics.",
            "solution": "The user wants me to select the most appropriate numerical integrator for Hamiltonian ray tracing in a tokamak plasma, with the dual goals of accurate local error control in regions of strong gradients and preservation of long-term conservation properties.\n\n### Step 1: Extract Givens\n- **System:** High-frequency Radio Frequency (RF) wave in a static, axisymmetric tokamak.\n- **Medium Description:** Electron density $n_{e}(\\mathbf{x})$ and magnetic field $\\mathbf{B}(\\mathbf{x})$ are independent of laboratory time.\n- **Ray Dynamics:** Geometric optics limit with eikonal $S(\\mathbf{x})$ and wavevector $\\mathbf{k}(\\mathbf{x}) = \\nabla S(\\mathbf{x})$.\n- **Dispersion Relation:** $D(\\mathbf{x},\\mathbf{k},\\omega)=0$ at a fixed angular frequency $\\omega$.\n- **Governing Equations:** A Hamiltonian system integrated over a ray parameter $\\tau$:\n$$\n\\frac{d\\mathbf{x}}{d\\tau} = \\frac{\\partial H}{\\partial \\mathbf{k}}, \\qquad \\frac{d\\mathbf{k}}{d\\tau} = -\\frac{\\partial H}{\\partial \\mathbf{x}}\n$$\n- **Hamiltonian:** $H(\\mathbf{x},\\mathbf{k})$ is chosen such that the ray path lies on the dispersion surface. One example is $H(\\mathbf{x},\\mathbf{k}) = \\tfrac{1}{2} D(\\mathbf{x},\\mathbf{k},\\omega)$. The Hamiltonian $H$ has no explicit dependence on $\\tau$.\n- **Exact Invariants:** Since $H$ is time-independent, $dH/d\\tau = 0$. The symplectic two-form $d\\mathbf{k} \\wedge d\\mathbf{x}$ is preserved, implying conservation of phase-space volume.\n- **Numerical Challenges:**\n    1.  Long integration paths.\n    2.  Regions of strong gradients near refraction layers and cutoffs, where $\\lVert \\nabla n_{e}(\\mathbf{x}) \\rVert$ and $\\lVert \\nabla \\mathbf{B}(\\mathbf{x}) \\rVert$ are large.\n    3.  Potential for stiffness due to rapid variation of the right-hand side functions ($\\partial H/\\partial \\mathbf{x}$ and $\\partial H/\\partial \\mathbf{k}$).\n- **Required Integrator Properties:**\n    1.  Control of local error in regions with strong gradients (adaptivity).\n    2.  Preservation of long-time conservation properties: bounded error in the Hamiltonian $H$ and preservation of phase-space volume.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is scientifically sound, well-posed, and objective.\n- **Scientific Grounding:** The description of RF ray tracing in a plasma using Hamiltonian mechanics is a standard and fundamental technique in computational fusion science. The governing equations, the concept of a dispersion relation, and the properties of Hamiltonian systems are all correctly stated and conform to established physical and mathematical principles.\n- **Well-Posedness:** The problem asks to identify the most suitable numerical integrator for a system with specific, well-defined characteristics (Hamiltonian structure) and challenges (stiffness, long-time integration). Comparing different families of numerical methods against these requirements is a standard task in computational science, and a meaningful conclusion can be reached.\n- **Objectivity and Completeness:** The problem is described using precise, technical language. The challenges and goals are objective criteria against which the options can be evaluated. Sufficient information is provided to make a reasoned choice based on the known theoretical properties of the numerical methods listed in the options.\n- **Consistency and Realism:** The problem is internally consistent. The mentioned numerical challenges are exactly those encountered in real-world simulations of this type. The trade-offs between local accuracy, computational cost, and long-term fidelity are central to the field.\n\n### Step 3: Verdict and Action\nThe problem is valid. I will proceed with the detailed derivation and evaluation of the options.\n\n### Principle-Based Derivation\nThe core of the problem lies in the properties of Hamiltonian systems and how numerical integrators interact with them. The system is described by Hamilton's equations for a phase-space coordinate $\\mathbf{z} = (\\mathbf{x}, \\mathbf{k})$.\n$$\n\\frac{d\\mathbf{z}}{d\\tau} = J \\nabla_{\\mathbf{z}} H(\\mathbf{z}), \\quad \\text{where} \\quad J = \\begin{pmatrix} 0 & I \\\\ -I & 0 \\end{pmatrix}\n$$\nis the standard symplectic matrix. The flow of this system, $\\phi_{\\tau}$, is a *symplectomorphism* or *canonical transformation*, meaning it preserves the symplectic two-form $\\omega = d\\mathbf{k} \\wedge d\\mathbf{x}$. This leads to the conservation of phase-space volume (Liouville's theorem). Since the Hamiltonian $H$ does not explicitly depend on the integration parameter $\\tau$, it is a conserved quantity (an integral of motion) along the exact trajectory:\n$$\n\\frac{dH}{d\\tau} = \\frac{\\partial H}{\\partial \\mathbf{z}} \\cdot \\frac{d\\mathbf{z}}{d\\tau} = (\\nabla_{\\mathbf{z}} H)^T J (\\nabla_{\\mathbf{z}} H) = 0\n$$\nThe two primary goals for the numerical method are (i) adaptivity for local accuracy and (ii) preservation of these geometric/conservation properties for long-time fidelity.\n\nA numerical integrator is called *symplectic* if its one-step map is a canonical transformation. Symplectic integrators do not conserve the original Hamiltonian $H$ exactly. Instead, they exactly conserve a nearby \"shadow\" Hamiltonian, $H_{shadow} = H + \\mathcal{O}((\\Delta \\tau)^p)$, where $p$ is the order of the method and $\\Delta \\tau$ is the step size. This property guarantees that the numerical error in $H$ remains bounded over exponentially long integration times, preventing the secular drift seen with non-symplectic methods. They also exactly preserve phase-space volume.\n\nA key difficulty arises when combining symplecticity with adaptive step sizes. A standard symplectic integrator is only symplectic for a *fixed* step size $\\Delta \\tau$. Applying it with a naively varying step size, $\\Delta \\tau_i$, breaks the property of conserving a shadow Hamiltonian, thereby destroying the favorable long-time energy conservation behavior.\n\nThe problem requires adaptivity to handle regions of strong gradients (refraction/cutoffs). This is where step sizes should be small. A robust solution must therefore reconcile the need for variable effective steps with the requirement of a fixed-step symplectic algorithm. The Sundman transformation, or reparameterization, is the canonical way to achieve this. One introduces a new monotonic integration parameter $s$ (\"fictitious time\") related to the original parameter $\\tau$ by $d\\tau = ds / g(\\mathbf{x}, \\mathbf{k})$, where $g(\\mathbf{x}, \\mathbf{k})$ is a positive-definite \"monitor function\". The new equations of motion become:\n$$\n\\frac{d\\mathbf{x}}{ds} = \\frac{1}{g(\\mathbf{x},\\mathbf{k})} \\frac{\\partial H}{\\partial \\mathbf{k}}, \\quad \\frac{d\\mathbf{k}}{ds} = -\\frac{1}{g(\\mathbf{x},\\mathbf{k})} \\frac{\\partial H}{\\partial \\mathbf{x}}\n$$\nThis new system is also Hamiltonian, with a new Hamiltonian $K(\\mathbf{x}, \\mathbf{k}) = H(\\mathbf{x}, \\mathbf{k}) / g(\\mathbf{x}, \\mathbf{k})$. One can now integrate this new Hamiltonian system using a *fixed-step* ($\\Delta s$) symplectic integrator. By choosing $g(\\mathbf{x}, \\mathbf{k})$ to be large in regions where small steps in $\\tau$ are needed (e.g., where $\\lVert \\nabla_{\\mathbf{z}} H \\rVert$ is large), one achieves adaptive resolution in the physical variables while maintaining the geometric properties of the integrator.\n\n### Option-by-Option Analysis\n\n**A. Use an embedded adaptive explicit Runge–Kutta method (such as Dormand–Prince $5(4)$) with state-dependent step size control to enforce a tight local error tolerance everywhere.**\nThis method is excellent for goal (i), providing robust local error control through adaptivity. However, it is fundamentally a non-symplectic method. When applied to a Hamiltonian system, it will not conserve phase-space volume nor will it exhibit bounded energy error. The value of the Hamiltonian $H$ will typically show a secular drift over long integrations, even with a very tight error tolerance. The cost of reducing this drift by tightening the tolerance is often prohibitive and does not change the qualitative nature of the error growth. This method fails to satisfy goal (ii).\n**Verdict: Incorrect.**\n\n**B. Use a fixed-step, fourth-order symplectic composition integrator (for example, a Yoshida composition of the leapfrog scheme) applied after a Sundman reparameterization of the ray parameter, introducing a new parameter $s$ defined by $ds/d\\tau = g(\\mathbf{x},\\mathbf{k})$ that clusters steps near refraction layers, while integrating with a constant step $\\Delta s$.**\nThis option presents a complete and theoretically sound solution. The Sundman reparameterization ($ds/d\\tau = g(\\mathbf{x},\\mathbf{k})$) provides adaptivity, satisfying goal (i). By choosing a suitable monitor function $g(\\mathbf{x},\\mathbf{k})$, the step size in the physical parameter $\\tau$ becomes small precisely where gradients are large. The integration of the transformed (but still Hamiltonian) system is then performed with a fixed-step symplectic integrator (a Yoshida composition method is a standard high-order choice). This satisfies goal (ii) by preserving the symplectic structure, thus guaranteeing bounded error in the transformed Hamiltonian $K$ and exact phase-space volume preservation. This is the state-of-the-art technique for this class of problems.\n**Verdict: Correct.**\n\n**C. Use an implicit Gauss–Legendre Runge–Kutta method of order $2s$ with adaptive, state-dependent step size control, relying on its symplecticity to conserve the Hamiltonian $H$ exactly and preserve phase-space volume, even with varying steps.**\nThis option contains several inaccuracies. First, while Gauss–Legendre methods are indeed symplectic, they do not \"conserve the Hamiltonian $H$ exactly\" in general. They conserve a shadow Hamiltonian. Second, and more critically, it suggests using standard adaptive step-size control. As explained, naively varying the step size of a symplectic method breaks the long-term conservation of a shadow Hamiltonian, which is the primary reason for using such a method. While the method would preserve phase-space volume at each step, the benefit of bounded energy error would be lost. The approach described in Option B is the correct way to incorporate adaptivity without sacrificing the benefits of symplecticity. Therefore, this option proposes a flawed implementation strategy.\n**Verdict: Incorrect.**\n\n**D. Use a variable-order linear multistep predictor–corrector scheme (Adams–Bashforth–Moulton) with aggressive adaptivity to minimize computational cost while maintaining acceptable accuracy.**\nThis option proposes using a non-geometric integrator. Linear multistep methods, like the explicit Runge-Kutta methods in Option A, are not symplectic. They are designed for general-purpose ODE solving and do not respect the geometric structure of Hamiltonian systems. For long-term integrations, they will suffer from secular drift in the Hamiltonian $H$ and will not conserve phase-space volume. They are unsuitable for problems where long-term fidelity and conservation of physical invariants are a primary concern. This method fails to satisfy goal (ii).\n**Verdict: Incorrect.**",
            "answer": "$$\\boxed{B}$$"
        },
        {
            "introduction": "The geometric optics approximation assumes that different wave modes propagate independently, but in a magnetized plasma, their dispersion relations can become nearly degenerate. Near these 'mode conversion' regions, energy can be transferred from one wave branch to another, a process modeled by a system of coupled equations. This final exercise  challenges you to implement a numerical model for this critical wave-plasma interaction and validate it against the famous Landau-Zener analytical formula, providing insight into phenomena that go beyond the simplest ray tracing picture.",
            "id": "4038264",
            "problem": "Consider the propagation of radio frequency (RF) waves in a cold, magnetized plasma described by geometric optics. Let the dispersion function be denoted by $D(\\omega,\\mathbf{x},\\mathbf{k})$, and suppose a single-frequency wave with fixed angular frequency $\\omega$ propagates along a spatial coordinate $s$ (the ray coordinate) through a quasi-one-dimensional slab where the background plasma parameters vary primarily along $s$. Assume that two distinct wave branches (modes) become nearly degenerate near a surface where their corresponding dispersion surfaces approach, which we idealize locally by a single “$D$-surface” proximity parameter crossing zero. In this neighborhood, the full vector wave equation reduces to coupled mode evolution for complex amplitudes of two interacting modes. Model the interaction by a canonical two-level avoided-crossing system with a slowly varying mismatch and a constant coupling, namely the coupled-mode envelope system\n$$\ni\\,\\frac{d}{ds}\\begin{bmatrix}a(s)\\\\ b(s)\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\frac{\\Delta(s)}{2} & \\kappa \\\\\n\\kappa & -\\frac{\\Delta(s)}{2}\n\\end{bmatrix}\n\\begin{bmatrix}a(s)\\\\ b(s)\\end{bmatrix},\n$$\nwhere $a(s)$ and $b(s)$ are the diabatic mode amplitudes along the ray coordinate $s$, the off-diagonal constant $\\kappa$ represents the strength of polarization-mediated coupling between the two modes, and the detuning $\\Delta(s)$ represents the difference in uncoupled dispersion relations projected along the ray. In a slab with a locally linear gradient at the interaction layer, it is reasonable to take $\\Delta(s)=\\alpha\\,(s-s_0)$, with $\\alpha$ a constant gradient parameter and $s_0$ the location of the closest approach (the “$D$-surface”). You may assume that far from the interaction region, $|\\Delta(s)|\\gg \\kappa$, so that diabatic and adiabatic states are distinguishable.\n\nStarting from a core geometric-optics base and the above coupled-mode reduction, your tasks are:\n- Derive a principled numerical algorithm to compute the mode-conversion efficiency by integrating the coupled-mode system along the ray, including:\n  1) tracking the instantaneous adiabatic polarization vectors (the eigenvectors of the $2\\times 2$ Hermitian matrix) along the trajectory, and\n  2) tracking the proximity to the $D$-surface via the minimum value of $|\\Delta(s)|$ encountered on the path.\n- Initialize the system at $s=s_{\\min}$ with $a(s_{\\min})=1$ and $b(s_{\\min})=0$, and integrate to $s=s_{\\max}$ such that $|\\Delta(s_{\\min})|,|\\Delta(s_{\\max})|\\gg \\kappa$. Define the numerical conversion efficiency as $P_{\\mathrm{num}}=|b(s_{\\max})|^2$.\n- Validate the numerical result against the analytic slab mode-conversion efficiency that applies to a linear crossing with constant coupling. Use the standard closed-form expression from the two-level avoided crossing theory for this efficiency, denoting it by $P_{\\mathrm{ana}}(\\alpha,\\kappa)$. Do not assume any specific simplifications beyond the linear-detuning, constant-coupling model stated above.\n- For each case, report the absolute error $|P_{\\mathrm{num}}-P_{\\mathrm{ana}}|$.\n\nAll quantities are dimensionless except $s$, which is in meters, and the parameters $\\alpha$ and $\\kappa$, which have units of $\\mathrm{m}^{-2}$ and $\\mathrm{m}^{-1}$ respectively such that the matrix entries have units of $\\mathrm{m}^{-1}$. Express the final numerical results as dimensionless floats.\n\nTest suite:\n- Use the following test cases, each specified by $(\\alpha,\\kappa,s_0,s_{\\min},s_{\\max})$:\n  1) $(\\alpha=0.8,\\ \\kappa=0.15,\\ s_0=0.0,\\ s_{\\min}=-50.0,\\ s_{\\max}=+50.0)$\n  2) $(\\alpha=1.2,\\ \\kappa=0.05,\\ s_0=0.0,\\ s_{\\min}=-50.0,\\ s_{\\max}=+50.0)$\n  3) $(\\alpha=0.5,\\ \\kappa=0.4,\\ s_0=0.0,\\ s_{\\min}=-50.0,\\ s_{\\max}=+50.0)$\n  4) $(\\alpha=-0.8,\\ \\kappa=0.15,\\ s_0=0.0,\\ s_{\\min}=-50.0,\\ s_{\\max}=+50.0)$\n  5) $(\\alpha=2.0,\\ \\kappa=0.01,\\ s_0=0.0,\\ s_{\\min}=-50.0,\\ s_{\\max}=+50.0)$\n\nFinal output format:\n- Your program should produce a single line of output containing the absolute errors for the five test cases as a comma-separated list enclosed in square brackets (for example, \"[e1,e2,e3,e4,e5]\"). Each entry must be a float. Angles are not used; no angle units are required. No physical unit symbols should appear in the output line. Round each error to at most six decimal places in the printed output to ensure stable comparison across platforms.",
            "solution": "The problem requires the calculation of mode-conversion efficiency for a two-level system described by a set of coupled ordinary differential equations and its comparison with a well-known analytical formula. The problem is scientifically grounded, well-posed, and its parameters are consistent. We can therefore proceed with a solution.\n\nThe governing equations for the complex amplitudes of the two coupled modes, $a(s)$ and $b(s)$, are given by:\n$$\ni\\,\\frac{d}{ds}\\begin{bmatrix}a(s)\\\\ b(s)\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\frac{\\Delta(s)}{2} & \\kappa\\\\\n\\kappa & -\\frac{\\Delta(s)}{2}\n\\end{bmatrix}\n\\begin{bmatrix}a(s)\\\\ b(s)\\end{bmatrix}\n$$\nThis can be written in a compact form as $i\\,\\frac{d\\mathbf{y}}{ds} = \\mathbf{H}(s)\\mathbf{y}(s)$, where the state vector is $\\mathbf{y}(s) = [a(s), b(s)]^T$ and the Hermitian matrix $\\mathbf{H}(s)$ is the effective Hamiltonian of the system. The detuning is given a linear dependence on the spatial coordinate $s$, $\\Delta(s) = \\alpha(s-s_0)$.\n\nThe problem will be solved by two methods: a direct numerical integration of the governing equations and an application of the analytical Landau-Zener formula.\n\nFirst, we design a principled numerical algorithm to compute the conversion efficiency, $P_{\\mathrm{num}}$. The system of equations is a first-order, linear, initial value problem (IVP). We can rewrite the equation in the standard form for numerical solvers, $\\frac{d\\mathbf{y}}{ds} = \\mathbf{f}(s, \\mathbf{y})$:\n$$\n\\frac{d\\mathbf{y}}{ds} = -i\\,\\mathbf{H}(s)\\mathbf{y}(s) = -i\n\\begin{bmatrix}\n\\frac{\\alpha(s-s_0)}{2} & \\kappa\\\\\n\\kappa & -\\frac{\\alpha(s-s_0)}{2}\n\\end{bmatrix}\n\\begin{bmatrix}a(s)\\\\ b(s)\\end{bmatrix}\n$$\nThe problem specifies the initial condition at $s=s_{\\min}$ as $a(s_{\\min})=1$ and $b(s_{\\min})=0$, which corresponds to the initial state vector $\\mathbf{y}(s_{\\min}) = [1, 0]^T$. Starting from this state, we integrate the system up to $s=s_{\\max}$. This integration can be efficiently performed using a standard adaptive step-size numerical method, such as a Runge-Kutta algorithm. The solution of this IVP yields the state vector $\\mathbf{y}(s_{\\max}) = [a(s_{\\max}), b(s_{\\max})]^T$. The numerical conversion efficiency, defined as the probability of finding the system in the second mode `b` at the end of the path, is then given by:\n$$\nP_{\\mathrm{num}} = |b(s_{\\max})|^2\n$$\nThe problem mentions tracking the adiabatic polarization vectors. These are the eigenvectors of the Hamiltonian matrix $\\mathbf{H}(s)$. Their eigenvalues are $\\lambda_{\\pm}(s) = \\pm\\sqrt{(\\Delta(s)/2)^2 + \\kappa^2}$. Far from the crossing point $s_0$ (where $\\Delta(s)=0$), i.e., where $|\\Delta(s)| \\gg \\kappa$, the eigenvectors of $\\mathbf{H}(s)$ (the adiabatic states) are nearly identical to the diabatic basis states $[1, 0]^T$ and $[0, 1]^T$. The initial state $[1, 0]^T$ thus corresponds to one of the adiabatic states. The minimum value of $|\\Delta(s)|$ encountered is $|\\Delta(s_0)| = 0$, confirming that the system passes through the degeneracy point where interaction is strongest.\n\nSecond, we state the analytical formula for the conversion efficiency, $P_{\\mathrm{ana}}$. The model is a classic example of a Landau-Zener-Stückelberg-Majorana problem. The Landau-Zener formula gives the probability of a non-adiabatic transition between the two energy levels (eigenvalues of $\\mathbf{H}(s)$) during the passage through the avoided crossing. This corresponds to the system staying in the same diabatic state. The probability of such a transition is:\n$$\nP_{\\text{diabatic}} = \\exp\\left(-\\frac{2\\pi \\kappa^2}{|\\frac{d\\Delta}{ds}|}\\right)\n$$\nIn our case, $\\frac{d\\Delta}{ds} = \\alpha$, so the probability of remaining in the initial diabatic state `a` throughout the evolution is $P_{a \\to a} = \\exp\\left(-\\frac{2\\pi \\kappa^2}{|\\alpha|}\\right)$.\nThe conversion efficiency is the probability of the system transitioning from the initial diabatic state `a` to the other diabatic state `b`. By the conservation of total probability, $|a(s_{\\max})|^2 + |b(s_{\\max})|^2 = 1$ for unitary evolution. Thus, the probability of conversion is:\n$$\nP_{\\mathrm{ana}} = P_{a \\to b} = 1 - P_{a \\to a} = 1 - \\exp\\left(-\\frac{2\\pi \\kappa^2}{|\\alpha|}\\right)\n$$\nThis formula is strictly valid for an infinite integration interval $s \\in (-\\infty, \\infty)$. However, it serves as an excellent approximation provided the integration limits $s_{\\min}$ and $s_{\\max}$ are chosen such that $|\\Delta(s_{\\min})|$ and $|\\Delta(s_{\\max})|$ are both much larger than the coupling strength $\\kappa$, a condition satisfied by the provided test cases.\n\nFinally, for each test case, we compute both $P_{\\mathrm{num}}$ and $P_{\\mathrm{ana}}$ and report the absolute error, $|P_{\\mathrm{num}} - P_{\\mathrm{ana}}|$. The numerical implementation will utilize the `solve_ivp` function from the SciPy library to solve the complex-valued ODE system with high precision.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import solve_ivp\n\ndef solve():\n    \"\"\"\n    Solves the coupled-mode evolution problem for a series of test cases.\n\n    For each case, it computes the mode-conversion efficiency numerically by integrating\n    the governing ODEs and analytically using the Landau-Zener formula. It then\n    calculates the absolute error between these two results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (alpha, kappa, s0, s_min, s_max)\n        (0.8, 0.15, 0.0, -50.0, 50.0),\n        (1.2, 0.05, 0.0, -50.0, 50.0),\n        (0.5, 0.4, 0.0, -50.0, 50.0),\n        (-0.8, 0.15, 0.0, -50.0, 50.0),\n        (2.0, 0.01, 0.0, -50.0, 50.0),\n    ]\n\n    results = []\n    for case in test_cases:\n        alpha, kappa, s0, s_min, s_max = case\n\n        # 1. Analytical solution (Landau-Zener formula)\n        # The conversion efficiency is the probability of an adiabatic transition,\n        # P_ana = 1 - P_diabatic, where P_diabatic is the probability of staying\n        # in the same diabatic state.\n        # P_diabatic = exp(-2 * pi * kappa^2 / |d(Delta)/ds|)\n        # The rate of change of the detuning is d(Delta)/ds = alpha.\n        P_ana = 1.0 - np.exp(-2.0 * np.pi * kappa**2 / np.abs(alpha))\n\n        # 2. Numerical solution via ODE integration\n        def ode_system(s, y, alpha_p, kappa_p, s0_p):\n            \"\"\"\n            Defines the system of coupled ODEs: dy/ds = -i * H(s) * y.\n            y is a complex vector [a(s), b(s)].\n            \"\"\"\n            delta_s = alpha_p * (s - s0_p)\n            \n            # The Hamiltonian matrix H(s)\n            H_matrix = np.array([\n                [delta_s / 2.0, kappa_p],\n                [kappa_p, -delta_s / 2.0]\n            ], dtype=np.complex128)\n            \n            # The ODE system dy/ds = -i * H(s) * y\n            dyds = -1j * (H_matrix @ y)\n            return dyds\n\n        y0 = np.array([1.0 + 0j, 0.0 + 0j])\n        s_span = [s_min, s_max]\n\n        # Use solve_ivp for numerical integration.\n        # A lambda function is used to pass parameters to the ODE system.\n        # High-precision tolerances are used to minimize numerical error.\n        sol = solve_ivp(\n            lambda s, y: ode_system(s, y, alpha, kappa, s0),\n            s_span,\n            y0,\n            method='RK45',\n            rtol=1e-9,\n            atol=1e-12\n        )\n\n        # Extract the final state vector to calculate numerical conversion efficiency.\n        y_final = sol.y[:, -1]\n        b_final = y_final[1]\n        P_num = np.abs(b_final)**2\n\n        # 3. Calculate absolute error\n        error = np.abs(P_num - P_ana)\n        results.append(error)\n\n    # 4. Format and print the output as specified.\n    # The errors are rounded to 6 decimal places as per the instruction\n    # \"Round each error to at most six decimal places in the printed output\".\n    # Using round() before map(str,...) ensures the output conforms to this.\n    rounded_results = [round(r, 6) for r in results]\n    print(f\"[{','.join(map(str, rounded_results))}]\")\n\nsolve()\n```"
        }
    ]
}