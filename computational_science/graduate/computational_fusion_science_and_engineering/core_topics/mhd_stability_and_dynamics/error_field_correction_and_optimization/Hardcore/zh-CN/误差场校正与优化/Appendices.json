{
    "hands_on_practices": [
        {
            "introduction": "在我们能够校正磁误差场之前，我们必须首先能够精确地测量它。本实践练习将引导你完成一项基本任务：从离散的磁探针阵列数据中提取关键的误差场分量。通过应用离散傅里叶分析的原理，你将学习如何从均匀或随机分布的传感器数据中计算出特定螺旋谐波的振幅和相位，这为后续的建模和控制奠定了基础。",
            "id": "3976225",
            "problem": "考虑一个环形磁约束装置，在半径 $r_s$ 处存在一个有理磁面，其安全因子 $q(r_s)$ 满足 $q(r_s)=2/1$。在该磁面上，径向磁场扰动 $b_r(\\theta,\\phi;r_s)$ 是极向角 $\\theta\\in[0,2\\pi)$ 和环向角 $\\phi\\in[0,2\\pi)$ 的双周期函数，两个角度均以弧度为单位。与 $m/n=2/1$ 螺线对称性相关的谐振复傅里叶振幅，记为 $b_{21}(r_s)$，是根据双周期函数 $b_r(\\theta,\\phi;r_s)$ 在极向-环向角域上的基本复傅里叶级数来定义的。离散的磁探针测量值在该磁面上沿 $\\theta$ 和 $\\phi$ 方向均匀分布，您必须直接从这些离散样本计算 $b_{21}(r_s)$，无需任何外部输入。推导过程需从二维角域上周期函数的复傅里叶系数基本定义出发，并应用与均匀采样一致的、科学合理的离散化方法。\n\n您的任务是编写一个独立的程序，该程序为三个指定的测试用例合成磁探针数据，根据合成的离散测量值计算每个用例的谐振复傅里叶振幅 $b_{21}(r_s)$，并为每个用例输出其模值 $\\lvert b_{21}(r_s)\\rvert$（单位：特斯拉）和相位 $\\arg\\left(b_{21}(r_s)\\right)$（单位：弧度）。最终程序必须将这些结果生成为单行输出，形式为方括号内包含的逗号分隔列表，顺序为 $[\\lvert b_{21}\\rvert_1,\\arg(b_{21})_1,\\lvert b_{21}\\rvert_2,\\arg(b_{21})_2,\\lvert b_{21}\\rvert_3,\\arg(b_{21})_3]$。\n\n合成数据和测试套件如下。在所有情况下，角度单位均为弧度，磁场单位均为特斯拉。\n\n- 测试用例1（一般情况，均匀网格，单谐波）：\n  - 网格分辨率：$N_\\theta=64$，$N_\\phi=64$。\n  - 场模型：$b_r(\\theta,\\phi;r_s)=A_{21}\\cos\\!\\big(m\\theta-n\\phi+\\delta_{21}\\big)$，其中 $m=2$ 且 $n=1$。\n  - 振幅和相位：$A_{21}=5\\times 10^{-5}\\,\\mathrm{T}$，$\\delta_{21}=1.2$。\n  - 不存在其他谐波或噪声。\n\n- 测试用例2（混合谐波与测量噪声，均匀网格）：\n  - 网格分辨率：$N_\\theta=48$，$N_\\phi=32$。\n  - 场模型：$b_r(\\theta,\\phi;r_s)=A_{21}\\cos\\!\\big(2\\theta-\\phi+\\delta_{21}\\big)+A_{11}\\cos\\!\\big(1\\theta-1\\phi+\\delta_{11}\\big)+\\eta(\\theta,\\phi)$，其中 $\\eta$ 是零均值高斯噪声。\n  - 振幅和相位：$A_{21}=8\\times 10^{-6}\\,\\mathrm{T}$，$\\delta_{21}=-0.5$；$A_{11}=3\\times 10^{-5}\\,\\mathrm{T}$，$\\delta_{11}=2.0$。\n  - 噪声标准差：$\\sigma_\\eta=1\\times 10^{-6}\\,\\mathrm{T}$。\n  - 使用固定的随机种子 $12345$ 生成 $\\eta$。\n\n- 测试用例3（边界采样情况，随机均匀点）：\n  - 探针数量：$N=12$。\n  - 探针位置：$\\theta_k$ 和 $\\phi_k$ 在 $[0,2\\pi)$ 上独立均匀分布。\n  - 场模型：$b_r(\\theta,\\phi;r_s)=A_{21}\\cos\\!\\big(2\\theta-\\phi+\\delta_{21}\\big)$，其中 $A_{21}=4\\times 10^{-5}\\,\\mathrm{T}$ 且 $\\delta_{21}=-2.3$。\n  - 使用固定的随机种子 $2024$ 生成随机探针角度。\n\n科学和数值要求：\n- 您的计算应基于定义域 $\\theta\\in[0,2\\pi)$, $\\phi\\in[0,2\\pi)$ 上二维周期函数的基本复傅里叶系数定义，并使用与 $\\theta$ 和 $\\phi$ 方向上均匀采样一致的离散化方法。\n- 确保估计量在均匀采样下是无偏的，并在推导中讨论任何混叠约束。\n- 将每个测试用例的模（单位：$\\mathrm{T}$）和相位（单位：弧度）作为实数输出。\n\n最终输出格式规范：\n- 您的程序应生成单行输出，其中包含一个方括号括起来的逗号分隔列表，顺序为 $[\\lvert b_{21}\\rvert_1,\\arg(b_{21})_1,\\lvert b_{21}\\rvert_2,\\arg(b_{21})_2,\\lvert b_{21}\\rvert_3,\\arg(b_{21})_3]$，其中每个条目都是一个浮点数。不应打印任何其他文本。",
            "solution": "该问题要求计算环形装置中有理磁面上的径向磁场扰动 $b_r(\\theta, \\phi; r_s)$ 的谐振复傅里叶振幅 $b_{21}(r_s)$。指数 $(m,n)=(2,1)$ 分别对应极向 ($m$) 和环向 ($n$) 的模数。该计算必须从复傅里叶级数的基本定义推导得出，并应用于离散数据集。\n\n### 理论基础：连续傅里叶级数\n\n在定义域 $(\\theta, \\phi) \\in [0, 2\\pi) \\times [0, 2\\pi)$ 上的双周期函数 $f(\\theta, \\phi)$ 可以用复傅里叶级数表示。在环形等离子体的螺线结构背景下，通常使用形式为 $e^{i(m\\theta - n\\phi)}$ 的基函数。相应的复傅里叶系数（此处记为 $b_{mn}$）由投影积分定义：\n$$\nb_{mn} = \\frac{1}{(2\\pi)^2} \\int_0^{2\\pi} \\int_0^{2\\pi} b_r(\\theta, \\phi) e^{-i(m\\theta - n\\phi)} \\, d\\theta \\, d\\phi\n$$\n该定义确保了基函数在指定域上的正交性。\n\n为了给测试用例建立基准真相，我们对由 $b_r(\\theta, \\phi) = A_{mn} \\cos(m\\theta - n\\phi + \\delta_{mn})$ 给出的单个纯螺线模计算该积分。使用 Euler 公式 $\\cos(x) = \\frac{1}{2}(e^{ix} + e^{-ix})$，我们将其代入积分中：\n$$\nb_{mn} = \\frac{1}{(2\\pi)^2} \\int_0^{2\\pi} \\int_0^{2\\pi} \\left[ \\frac{A_{mn}}{2} \\left( e^{i(m\\theta - n\\phi + \\delta_{mn})} + e^{-i(m\\theta - n\\phi + \\delta_{mn})} \\right) \\right] e^{-i(m\\theta - n\\phi)} \\, d\\theta \\, d\\phi\n$$\n$$\nb_{mn} = \\frac{A_{mn}}{2(2\\pi)^2} \\int_0^{2\\pi} \\int_0^{2\\pi} \\left( e^{i\\delta_{mn}} + e^{-i(2(m\\theta - n\\phi) + \\delta_{mn})} \\right) \\, d\\theta \\, d\\phi\n$$\n由于复指数的正交性，第二项在周期域上的积分（对于非零的 $m, n$）为零。第一项是一个常数，因此得到：\n$$\nb_{mn} = \\frac{A_{mn}}{2(2\\pi)^2} e^{i\\delta_{mn}} \\int_0^{2\\pi} \\int_0^{2\\pi} d\\theta \\, d\\phi = \\frac{A_{mn}}{2(2\\pi)^2} e^{i\\delta_{mn}} (2\\pi)^2 = \\frac{A_{mn}}{2} e^{i\\delta_{mn}}\n$$\n因此，对于振幅为 $A_{mn}$、相位为 $\\delta_{mn}$ 的纯余弦模，其对应的复傅里叶系数的模为 $|b_{mn}| = A_{mn}/2$，相位为 $\\arg(b_{mn}) = \\delta_{mn}$。这提供了预期的理论结果。\n\n### 离散数据的数值估计\n\n在实践中，$b_r$ 仅在有限数量的离散点上已知。连续积分必须用离散和来近似。这种近似的形式取决于采样策略。\n\n#### 用例 1 和 2：均匀网格采样\n\n对于在 $N_\\theta \\times N_\\phi$ 个点的均匀网格上进行的测量，其中 $\\theta_j = j \\frac{2\\pi}{N_\\theta}$（$j \\in \\{0, \\dots, N_\\theta-1\\}$）且 $\\phi_k = k \\frac{2\\pi}{N_\\phi}$（$k \\in \\{0, \\dots, N_\\phi-1\\}$），该积分可以用黎曼和来近似。微分面积元 $d\\theta d\\phi$ 被离散面积元 $\\Delta\\theta \\Delta\\phi = \\frac{2\\pi}{N_\\theta} \\frac{2\\pi}{N_\\phi} = \\frac{(2\\pi)^2}{N_\\theta N_\\phi}$ 所取代。\n\n将此代入 $b_{mn}$ 的定义中：\n$$\nb_{mn} \\approx \\frac{1}{(2\\pi)^2} \\sum_{j=0}^{N_\\theta-1} \\sum_{k=0}^{N_\\phi-1} b_r(\\theta_j, \\phi_k) e^{-i(m\\theta_j - n\\phi_k)} \\frac{(2\\pi)^2}{N_\\theta N_\\phi}\n$$\n该表达式可简化为经过适当缩放的二维离散傅里叶变换（DFT）公式：\n$$\nb_{mn} \\approx \\frac{1}{N_\\theta N_\\phi} \\sum_{j=0}^{N_\\theta-1} \\sum_{k=0}^{N_\\phi-1} b_r(\\theta_j, \\phi_k) e^{-i(m\\theta_j - n\\phi_k)}\n$$\n如果采样率满足 Nyquist-Shannon 采样定理，即要求 $N_\\theta > 2|m_{\\text{max}}|$ 和 $N_\\phi > 2|n_{\\text{max}}|$，则该估计量对于带限信号是精确的。对于用例1，我们有 $(m,n)=(2,1)$ 以及 $N_\\theta=64, N_\\phi=64$，这满足 $64 > 4$ 和 $64 > 2$。对于用例2，模为 $(2,1)$ 和 $(1,1)$，因此 $|m_{\\text{max}}|=2, |n_{\\text{max}}|=1$。网格 $N_\\theta=48, N_\\phi=32$ 也满足该准则（$48 > 4$, $32 > 2$），因此混叠不是问题。离散傅里叶基的正交性确保了 $(1,1)$ 模不会干扰 $(2,1)$ 系数的计算。用例2中的零均值噪声项会给估计值引入统计误差。\n\n#### 用例 3：随机均匀采样\n\n对于在 $[0, 2\\pi) \\times [0, 2\\pi)$ 上从均匀随机分布中独立抽取的 $N$ 个位置 $(\\theta_k, \\phi_k)$ 上的测量值，我们采用蒙特卡洛积分方法。定义 $b_{mn}$ 的积分可以解释为函数 $g(\\theta, \\phi) = b_r(\\theta, \\phi) e^{-i(m\\theta - n\\phi)}$ 在该域上的期望值，并由域的面积 $(2\\pi)^2$ 进行缩放。\n$$\nb_{mn} = \\frac{1}{(2\\pi)^2} \\int_0^{2\\pi} \\int_0^{2\\pi} g(\\theta, \\phi) \\,d\\theta d\\phi = E[g(\\theta, \\phi)]\n$$\n其中期望是相对于域上的均匀概率测度来计算的。根据大数定律，这个期望可以通过在 $N$ 个随机点上求值的函数样本均值来估计：\n$$\nb_{mn} \\approx \\frac{1}{N} \\sum_{k=1}^{N} g(\\theta_k, \\phi_k) = \\frac{1}{N} \\sum_{k=1}^{N} b_r(\\theta_k, \\phi_k) e^{-i(m\\theta_k - n\\phi_k)}\n$$\n这个蒙特卡洛估计量是无偏的，意味着其期望值就是真实的 $b_{mn}$。然而，对于有限数量的样本 $N$，特别是像 $N=12$ 这样的小样本，估计值将具有显著的方差，因此与真实值相比会存在统计误差。\n\n### 在测试用例中的应用\n\n程序将为 $(m,n)=(2,1)$ 实现这些估计量。\n- **测试用例 1：**精细均匀网格上的纯 $(2,1)$ 模。使用均匀网格估计量。结果应非常接近理论值 $|b_{21}| = A_{21}/2 = 2.5 \\times 10^{-5}$ T 和 $\\arg(b_{21}) = \\delta_{21} = 1.2$ rad。\n- **测试用例 2：**均匀网格上带有噪声的 $(2,1)$ 和 $(1,1)$ 模的混合。使用均匀网格估计量。由于离散正交性，$(1,1)$ 模没有贡献。结果将接近于理论上的 $(2,1)$ 值（$|b_{21}| = A_{21}/2 = 4.0 \\times 10^{-6}$ T, $\\arg(b_{21}) = \\delta_{21} = -0.5$ rad），并带有由随机噪声的实现引起的微小偏差。\n- **测试用例 3：**在少量随机点上采样的纯 $(2,1)$ 模。使用随机样本估计量。结果将近似于理论值（$|b_{21}| = A_{21}/2 = 2.0 \\times 10^{-5}$ T, $\\arg(b_{21}) = \\delta_{21} = -2.3$ rad），但由于样本量小（$N=12$），会有明显的统计误差。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the complex resonant Fourier amplitude b_21 for three test cases.\n    \"\"\"\n    m, n = 2, 1\n    results = []\n\n    # --- Test Case 1: General case, uniform grid, single harmonic ---\n    N_theta_1, N_phi_1 = 64, 64\n    A_21_1, delta_21_1 = 5e-5, 1.2\n    \n    # Generate uniform angular grids\n    theta_1_vals = np.linspace(0, 2 * np.pi, N_theta_1, endpoint=False)\n    phi_1_vals = np.linspace(0, 2 * np.pi, N_phi_1, endpoint=False)\n    theta_1, phi_1 = np.meshgrid(theta_1_vals, phi_1_vals, indexing='ij')\n\n    # Synthesize magnetic field data\n    b_r_1 = A_21_1 * np.cos(m * theta_1 - n * phi_1 + delta_21_1)\n    \n    # Compute the complex Fourier coefficient b_21\n    # Estimator: (1/N_theta*N_phi) * sum(b_r * exp(-i*(m*theta - n*phi)))\n    # This is equivalent to np.mean(b_r * kernel)\n    kernel_1 = np.exp(-1j * (m * theta_1 - n * phi_1))\n    b_21_1 = np.mean(b_r_1 * kernel_1)\n\n    mag_1 = np.abs(b_21_1)\n    phase_1 = np.angle(b_21_1)\n    results.extend([mag_1, phase_1])\n    \n    # --- Test Case 2: Mixture of harmonics with noise, uniform grid ---\n    N_theta_2, N_phi_2 = 48, 32\n    A_21_2, delta_21_2 = 8e-6, -0.5\n    A_11_2, delta_11_2 = 3e-5, 2.0\n    sigma_eta_2, seed_2 = 1e-6, 12345\n    \n    # Generate uniform angular grids\n    theta_2_vals = np.linspace(0, 2 * np.pi, N_theta_2, endpoint=False)\n    phi_2_vals = np.linspace(0, 2 * np.pi, N_phi_2, endpoint=False)\n    theta_2, phi_2 = np.meshgrid(theta_2_vals, phi_2_vals, indexing='ij')\n\n    # Synthesize magnetic field data with two modes and noise\n    b_r_2_mode1 = A_21_2 * np.cos(m * theta_2 - n * phi_2 + delta_21_2)\n    b_r_2_mode2 = A_11_2 * np.cos(1 * theta_2 - 1 * phi_2 + delta_11_2)\n    \n    # Generate reproducible Gaussian noise\n    rng_2 = np.random.default_rng(seed_2)\n    noise_2 = rng_2.normal(0, sigma_eta_2, size=(N_theta_2, N_phi_2))\n    \n    b_r_2 = b_r_2_mode1 + b_r_2_mode2 + noise_2\n    \n    # Compute the complex Fourier coefficient b_21\n    kernel_2 = np.exp(-1j * (m * theta_2 - n * phi_2))\n    b_21_2 = np.mean(b_r_2 * kernel_2)\n    \n    mag_2 = np.abs(b_21_2)\n    phase_2 = np.angle(b_21_2)\n    results.extend([mag_2, phase_2])\n\n    # --- Test Case 3: Boundary sampling case, random uniform points ---\n    N_3 = 12\n    A_21_3, delta_21_3 = 4e-5, -2.3\n    seed_3 = 2024\n\n    # Generate random uniform probe positions\n    rng_3 = np.random.default_rng(seed_3)\n    theta_3 = rng_3.uniform(0, 2 * np.pi, N_3)\n    phi_3 = rng_3.uniform(0, 2 * np.pi, N_3)\n\n    # Synthesize magnetic field data at random points\n    b_r_3 = A_21_3 * np.cos(m * theta_3 - n * phi_3 + delta_21_3)\n    \n    # Compute the complex Fourier coefficient b_21 using Monte Carlo estimator\n    # Estimator: (1/N) * sum(b_r * exp(-i*(m*theta - n*phi)))\n    kernel_3 = np.exp(-1j * (m * theta_3 - n * phi_3))\n    b_21_3 = np.mean(b_r_3 * kernel_3)\n    \n    mag_3 = np.abs(b_21_3)\n    phase_3 = np.angle(b_21_3)\n    results.extend([mag_3, phase_3])\n\n    # Print the final output in the specified format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在具备测量误差场的能力之后，下一步是建立一个能够预测我们的控制线圈将如何影响等离子体的响应模型。本练习将指导你构建这样一个线性响应模型，并重点使用吉洪诺夫正则化（Tikhonov regularization）来处理欠定或病态的系统，同时通过 $K$ 折交叉验证来评估模型的泛化能力。掌握这些技术对于从充满噪声的实验数据中开发出可靠、具有预测性的模型至关重要。",
            "id": "3976233",
            "problem": "您的任务是构建一个完整的程序，用于在聚变相关背景下估计磁误差场校正的线性响应算子，并通过交叉验证评估其泛化性能。背景设定如下。在一组由 $k \\in \\{1,\\dots,N\\}$ 索引的独立实验中，一个尺寸为 $S$ 的传感器阵列记录一个向量 $y_k \\in \\mathbb{R}^S$，该向量是无量纲的磁扰动测量值，其来自两个源头：施加的控制线圈电流 $u_k \\in \\mathbb{R}^A$ 和施加的代理误差场模式 $w_k \\in \\mathbb{R}^M$。根据小扰动下的场叠加原理，该关系被假定为线性，这与磁准静态区中的麦克斯韦方程组一致，因此有\n$$\ny_k = R\\,u_k + G\\,w_k + \\varepsilon_k,\n$$\n其中 $R \\in \\mathbb{R}^{S \\times A}$ 和 $G \\in \\mathbb{R}^{S \\times M}$ 是待辨识的未知响应算子，而 $\\varepsilon_k \\sim \\mathcal{N}(0,\\sigma^2 I_S)$ 是独立的、方差已知为 $\\sigma^2$ 的高斯测量噪声，$I_S$ 是单位矩阵。本问题中所有量均为无量纲。\n\n您必须纯粹以数学术语实现以下计算任务：\n\n1. 数据生成模型。对于给定的随机种子 $s$，通过采样均值为零、标准差分别为 $1/\\sqrt{A}$ 和 $1/\\sqrt{M}$ 的独立高斯分布条目来生成 $R_{\\text{true}} \\in \\mathbb{R}^{S \\times A}$ 和 $G_{\\text{true}} \\in \\mathbb{R}^{S \\times M}$。然后，对于 $k=1,\\dots,N$，独立地生成 $u_k \\sim \\mathcal{N}(0, I_A)$ 和 $w_k \\sim \\mathcal{N}(0, I_M)$，并设置\n$$\ny_k = R_{\\text{true}} u_k + G_{\\text{true}} w_k + \\varepsilon_k,\\quad \\varepsilon_k \\sim \\mathcal{N}(0,\\sigma^2 I_S).\n$$\n将输入 $x_k \\in \\mathbb{R}^{A+M}$ 堆叠为 $x_k = \\begin{bmatrix} u_k \\\\ w_k \\end{bmatrix}$ 以形成列为 $x_k$ 的 $X \\in \\mathbb{R}^{(A+M)\\times N}$，并将输出堆叠以形成列为 $y_k$ 的 $Y \\in \\mathbb{R}^{S \\times N}$。这对应于多输出线性模型\n$$\nY \\approx B X,\\quad B = \\begin{bmatrix} R  G \\end{bmatrix} \\in \\mathbb{R}^{S \\times (A+M)}.\n$$\n\n2. 通过 Tikhonov 正则化进行估计。给定正则化参数 $\\lambda \\ge 0$，通过求解岭回归（也称为 Tikhonov 正则化）问题，从训练子集中估计 $B$，该问题旨在最小化弗罗贝尼乌斯范数惩罚的最小二乘目标函数\n$$\n\\min_{B \\in \\mathbb{R}^{S \\times (A+M)}} \\sum_{k \\in \\mathcal{T}} \\lVert y_k - B x_k \\rVert_2^2 + \\lambda \\lVert B \\rVert_F^2,\n$$\n其中 $\\mathcal{T}$ 索引训练列。实现其闭式解\n$$\n\\widehat{B} = Y_{\\mathcal{T}} X_{\\mathcal{T}}^{\\top}\\, \\left(X_{\\mathcal{T}} X_{\\mathcal{T}}^{\\top} + \\lambda I_{A+M}\\right)^{-1},\n$$\n其中 $I_{A+M}$ 是尺寸为 $(A+M)\\times(A+M)$ 的单位矩阵，$X_{\\mathcal{T}}$ 和 $Y_{\\mathcal{T}}$ 是包含训练列的 $X$ 和 $Y$ 的子矩阵。\n\n3. $K$ 折交叉验证。使用由种子 $s$ 决定的确定性排列，将 $N$ 个实验划分为 $K$ 个大小尽可能相等的折。对于每一折 $f \\in \\{1,\\dots,K\\}$，令验证集 $\\mathcal{V}_f$ 为第 $f$ 折，训练集 $\\mathcal{T}_f$ 为其补集。使用上述公式在 $\\mathcal{T}_f$ 上拟合 $\\widehat{B}_f$。计算训练集和验证集上的均方误差为\n$$\n\\operatorname{MSE}_{\\text{train},f} = \\frac{1}{|\\mathcal{T}_f|\\,S} \\sum_{k \\in \\mathcal{T}_f} \\lVert y_k - \\widehat{B}_f x_k \\rVert_2^2,\\quad\n\\operatorname{MSE}_{\\text{val},f} = \\frac{1}{|\\mathcal{V}_f|\\,S} \\sum_{k \\in \\mathcal{V}_f} \\lVert y_k - \\widehat{B}_f x_k \\rVert_2^2.\n$$\n报告交叉验证均方误差为\n$$\n\\overline{\\operatorname{MSE}}_{\\text{val}} = \\frac{1}{K} \\sum_{f=1}^{K} \\operatorname{MSE}_{\\text{val},f}.\n$$\n同时计算平均训练误差 $\\overline{\\operatorname{MSE}}_{\\text{train}} = \\frac{1}{K} \\sum_{f=1}^{K} \\operatorname{MSE}_{\\text{train},f}$。\n\n4. 过拟合风险指标。定义参数数量 $P = S\\,(A+M)$，每折的平均训练样本数 $N_{\\text{train,avg}} = N \\,(K-1)/K$，以及复杂度比率\n$$\nr = \\frac{P}{N_{\\text{train,avg}}\\,S} = \\frac{S\\,(A+M)}{N \\,(K-1)/K \\cdot S} = \\frac{K\\,(A+M)}{N\\,(K-1)}.\n$$\n根据以下规则对过拟合风险指标 $O \\in \\{\\text{True},\\text{False}\\}$ 进行分类\n$$\nO = \\left(\\frac{\\overline{\\operatorname{MSE}}_{\\text{val}}}{\\overline{\\operatorname{MSE}}_{\\text{train}}} \\ge 1.5\\right) \\land \\left(r \\ge 0.6\\right),\n$$\n其中 $\\land$ 表示逻辑合取。\n\n5. 输出格式。您的程序必须将每个测试用例的结果汇总为单行输出，格式为一个包含多个双元素列表的列表，每个内部列表对应一个测试用例，其中包含交叉验证均方误差（浮点数）和过拟合指标（布尔值）。例如，输出必须如下所示\n$$\n[\\,[m_1,b_1],[m_2,b_2],[m_3,b_3]\\,],\n$$\n其中 $m_i$ 是数值浮点数，$b_i \\in \\{\\mathrm{True},\\mathrm{False}\\}$。\n\n测试套件。使用所提供的确切参数，在以下三个测试用例上实现并运行您的程序。所有量均为无量纲。每个案例使用 $K=5$ 折。\n\n- 案例 1：$N=200$, $S=8$, $A=3$, $M=2$, $\\sigma=0.05$, $\\lambda=10^{-6}$, 种子 $s=1$。\n- 案例 2：$N=30$, $S=8$, $A=10$, $M=8$, $\\sigma=0.08$, $\\lambda=10^{-6}$, 种子 $s=2$。\n- 案例 3：$N=15$, $S=6$, $A=8$, $M=8$, $\\sigma=0.05$, $\\lambda=10^{-3}$, 种子 $s=3$。\n\n您的程序应生成单行输出，其中包含结果，格式为用方括号括起的逗号分隔列表，内部列表中无多余空格，格式完全如下\n$$\n[\\,[m_1,b_1],[m_2,b_2],[m_3,b_3]\\,].\n$$",
            "solution": "用户提供了一个有效的问题陈述。该问题在计算等离子体物理和统计学习方面有科学依据，其所有必要的参数和定义都使其成为一个适定问题，并且其表述是客观的。它构成了一项在模型验证中非凡但定义明确的计算任务。现在我将开始进行解答。\n\n该问题要求实现一个计算工作流，以在一个简化的聚变装置背景下估计用于磁误差场校正的线性响应算子。这涉及模拟实验数据，使用 Tikhonov 正则化（岭回归）拟合模型，并通过 K 折交叉验证评估其泛化性能。问题的核心在于解决一个线性反问题，这是实验科学中的一项常见任务，即必须从带噪声的测量中推断出底层系统模型。\n\n物理模型由以下线性关系给出：\n$$\ny_k = R\\,u_k + G\\,w_k + \\varepsilon_k\n$$\n对于 $k \\in \\{1, \\dots, N\\}$ 个实验。这里，$y_k \\in \\mathbb{R}^S$ 是传感器测量向量，$u_k \\in \\mathbb{R}^A$ 是施加的控制电流向量，$w_k \\in \\mathbb{R}^M$ 是代表内在误差场的向量。矩阵 $R \\in \\mathbb{R}^{S \\times A}$ 和 $G \\in \\mathbb{R}^{S \\times M}$ 是我们希望辨识的线性响应算子。项 $\\varepsilon_k$ 代表测量噪声，被建模为方差为 $\\sigma^2$ 的独立高斯过程。通过将输入串联成 $x_k = \\begin{bmatrix} u_k \\\\ w_k \\end{bmatrix}$ 并将算子串联成 $B = \\begin{bmatrix} R  G \\end{bmatrix}$，整个数据集的模型可以紧凑的矩阵形式表示：\n$$\nY \\approx B X\n$$\n其中 $Y \\in \\mathbb{R}^{S \\times N}$ 的列是 $y_k$，$X \\in \\mathbb{R}^{(A+M) \\times N}$ 的列是 $x_k$。我们的目标是为真实算子 $B_{\\text{true}}$ 找到一个估计值 $\\widehat{B}$。\n\n解决方案通过一系列逻辑步骤实现：\n\n1.  **数据生成**：对于每个测试用例，我们首先根据指定的统计特性合成一个“真实基准”数据集。一个由参数 $s$ 播种的确定性随机数生成器确保了可复现性。真实响应算子 $R_{\\text{true}}$ 和 $G_{\\text{true}}$ 的条目从正态分布中抽取生成。将其标准差分别按 $1/\\sqrt{A}$ 和 $1/\\sqrt{M}$ 进行缩放是一种标准做法，以确保随着输入数量的增加，输出信号的期望幅度保持有界。输入向量 $u_k$ 和 $w_k$ 从标准正态分布中抽取，模拟了应用多样化输入来探测系统响应的典型实验情景。然后使用线性模型计算测量向量 $y_k$，并添加高斯噪声 $\\varepsilon_k$。\n\n2.  **K 折交叉验证**：为了稳健地评估模型对新的、未见过的数据的预测能力，我们采用 K 折交叉验证。将 $N$ 个数据样本进行确定性排列，并划分为 $K$ 个大小相等（或几乎相等）的折。对于每一折 $f \\in \\{1, \\dots, K\\}$，我们将其指定为验证集 ($\\mathcal{V}_f$)，其余的 $K-1$ 折作为训练集 ($\\mathcal{T}_f$)。这个过程重复 $K$ 次，每一折都恰好作为验证集一次。\n\n3.  **Tikhonov 正则化（岭回归）**：对于每一折，我们仅使用训练数据 ($\\mathcal{T}_f$) 来估计算子 $\\widehat{B}_f$。该估计是通过求解正则化最小二乘问题来进行的：\n    $$\n    \\min_{B \\in \\mathbb{R}^{S \\times (A+M)}} \\sum_{k \\in \\mathcal{T}_f} \\lVert y_k - B x_k \\rVert_2^2 + \\lambda \\lVert B \\rVert_F^2\n    $$\n    第一项是平方误差和，用于衡量对训练数据的保真度。第二项 $\\lambda \\lVert B \\rVert_F^2$ 是对算子 $B$ 的弗罗贝尼乌斯范数平方的惩罚，由正则化参数 $\\lambda \\ge 0$ 控制。这个惩罚项至关重要。在训练样本数量少于待估计参数数量（即问题是欠定的）或输入不够多样化（共线性）的情况下，无正则化的问题是不适定的。Tikhonov 正则化增加了一个约束，使解偏向于范数更小的算子，从而保证了唯一且稳定的解。其闭式解为：\n    $$\n    \\widehat{B}_f = Y_{\\mathcal{T}_f} X_{\\mathcal{T}_f}^{\\top}\\, \\left(X_{\\mathcal{T}_f} X_{\\mathcal{T}_f}^{\\top} + \\lambda I_{A+M}\\right)^{-1}\n    $$\n    其中 $X_{\\mathcal{T}_f}$ 和 $Y_{\\mathcal{T}_f}$ 是训练集的数据矩阵。此公式使用标准矩阵运算实现。\n\n4.  **误差评估**：在获得 $\\widehat{B}_f$ 后，我们通过计算均方误差 (MSE) 来评估其性能，该误差按每个样本每个传感器进行归一化。这对训练数据和留出的验证数据分别进行：\n    $$\n    \\operatorname{MSE}_{\\text{train},f} = \\frac{1}{|\\mathcal{T}_f|\\,S} \\sum_{k \\in \\mathcal{T}_f} \\lVert y_k - \\widehat{B}_f x_k \\rVert_2^2\n    $$\n    $$\n    \\operatorname{MSE}_{\\text{val},f} = \\frac{1}{|\\mathcal{V}_f|\\,S} \\sum_{k \\in \\mathcal{V}_f} \\lVert y_k - \\widehat{B}_f x_k \\rVert_2^2\n    $$\n    在遍历所有 $K$ 折后，我们计算平均训练 MSE $\\overline{\\operatorname{MSE}}_{\\text{train}}$ 和平均验证 MSE $\\overline{\\operatorname{MSE}}_{\\text{val}}$。后者 $\\overline{\\operatorname{MSE}}_{\\text{val}}$ 作为我们模型泛化性能的主要度量标准。\n\n5.  **过拟合评估**：当模型学习到训练数据中的噪声和特定的人为因素，从而导致在未见过的数据上表现不佳时，就会发生过拟合。这通常表现为训练误差远低于验证误差。我们实现一种特定的启发式方法来标记高过拟合风险。如果同时满足两个条件，则指标 $O$ 设置为真：\n    -   验证误差与训练误差的比率显著：$\\overline{\\operatorname{MSE}}_{\\text{val}} / \\overline{\\operatorname{MSE}}_{\\text{train}} \\ge 1.5$。\n    -   问题处于易于过拟合的区域，由复杂度比率 $r = \\frac{K(A+M)}{N(K-1)} \\ge 0.6$ 来衡量。该比率比较了模型参数数量与可用于训练的有效数据点数量。比率越高，风险越大。\n\n最终的程序结构包含一个主函数 `solve`，该函数会遍历所提供的测试用例。对于每个案例，一个辅助函数 `run_single_case` 执行所描述的工作流——数据生成、交叉验证、模型拟合和评估——并返回最终的 $\\overline{\\operatorname{MSE}}_{\\text{val}}$ 和过拟合指标 $O$。然后将结果汇总并以指定格式打印。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_single_case(N, S, A, M, sigma, lam, K, seed):\n    \"\"\"\n    Executes the full simulation and analysis for a single test case.\n    \n    Args:\n        N (int): Number of experiments.\n        S (int): Size of the sensor array.\n        A (int): Number of control coil currents.\n        M (int): Number of proxy error-field patterns.\n        sigma (float): Standard deviation of measurement noise.\n        lam (float): Tikhonov regularization parameter.\n        K (int): Number of folds for cross-validation.\n        seed (int): Random seed for reproducibility.\n\n    Returns:\n        tuple[float, bool]: A tuple containing the cross-validated mean squared \n                            error and the boolean overfitting risk indicator.\n    \"\"\"\n    # Use a dedicated Random Number Generator for reproducibility\n    rng = np.random.default_rng(seed)\n\n    # 1. Data generation\n    # Generate true response operators R and G, then stack them into B_true\n    R_true = rng.normal(loc=0.0, scale=1/np.sqrt(A), size=(S, A))\n    G_true = rng.normal(loc=0.0, scale=1/np.sqrt(M), size=(S, M))\n    B_true = np.hstack((R_true, G_true))  # Shape: S x (A+M)\n\n    # Generate stacked inputs X (u and w) and noise Epsilon\n    X = rng.normal(loc=0.0, scale=1.0, size=(A + M, N))\n    Epsilon = rng.normal(loc=0.0, scale=sigma, size=(S, N))\n\n    # Compute sensor measurements Y\n    Y = B_true @ X + Epsilon  # Shape: S x N\n\n    # 3. K-fold cross-validation setup\n    # Create a deterministic permutation of data indices\n    indices = rng.permutation(N)\n    # Split indices into K folds\n    folds = np.array_split(indices, K)\n    \n    all_mse_train = []\n    all_mse_val = []\n\n    for f in range(K):\n        # Determine training and validation sets for the current fold\n        val_indices = folds[f]\n        train_indices_list = [folds[i] for i in range(K) if i != f]\n        train_indices = np.concatenate(train_indices_list)\n        \n        X_train, Y_train = X[:, train_indices], Y[:, train_indices]\n        X_val, Y_val = X[:, val_indices], Y[:, val_indices]\n\n        num_train_samples = X_train.shape[1]\n        num_val_samples = X_val.shape[1]\n        \n        # 2. Estimation by Tikhonov regularization\n        # Calculate B_hat for the current training set\n        XXT = X_train @ X_train.T\n        YXT = Y_train @ X_train.T\n        identity_mat = np.identity(A + M)\n        \n        # Closed-form solution: B_hat = Y*X^T * (X*X^T + lambda*I)^-1\n        try:\n            inv_term = np.linalg.inv(XXT + lam * identity_mat)\n            B_hat = YXT @ inv_term\n        except np.linalg.LinAlgError:\n            # Fallback to pseudo-inverse if inversion fails, though unlikely with lambda > 0\n            inv_term = np.linalg.pinv(XXT + lam * identity_mat)\n            B_hat = YXT @ inv_term\n\n        # 3. Compute MSE for the current fold\n        # Predictions\n        Y_train_pred = B_hat @ X_train\n        Y_val_pred = B_hat @ X_val\n\n        # Sum of squared errors\n        train_error_sum_sq = np.sum((Y_train - Y_train_pred)**2)\n        val_error_sum_sq = np.sum((Y_val - Y_val_pred)**2)\n\n        # Normalized MSE\n        mse_train_f = train_error_sum_sq / (num_train_samples * S)\n        \n        if num_val_samples > 0:\n            mse_val_f = val_error_sum_sq / (num_val_samples * S)\n        else:\n            mse_val_f = 0.0\n\n        all_mse_train.append(mse_train_f)\n        all_mse_val.append(mse_val_f)\n\n    # Average MSEs over all folds\n    avg_mse_train = np.mean(all_mse_train)\n    avg_mse_val = np.mean(all_mse_val)\n\n    # 4. Overfitting risk indicator\n    # Calculate complexity ratio r\n    r = (K * (A + M)) / (N * (K - 1))\n    \n    # Calculate ratio of validation to training MSE.\n    # Handle the unlikely case of zero training error to avoid division by zero.\n    ratio_mse = np.inf if avg_mse_train == 0 else avg_mse_val / avg_mse_train\n    \n    # Apply the logical AND condition for the overfitting indicator\n    overfitting_risk = (ratio_mse >= 1.5) and (r >= 0.6)\n\n    return avg_mse_val, overfitting_risk\n\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results in the required format.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (N, S, A, M, sigma, lam, K, seed)\n        (200, 8, 3, 2, 0.05, 1e-6, 5, 1),\n        (30, 8, 10, 8, 0.08, 1e-6, 5, 2),\n        (15, 6, 8, 8, 0.05, 1e-3, 5, 3),\n    ]\n\n    results = []\n    for case in test_cases:\n        N, S, A, M, sigma, lam, K, seed = case\n        m_val, b_risk = run_single_case(N, S, A, M, sigma, lam, K, seed)\n        results.append([m_val, b_risk])\n\n    # Final print statement in the exact required format.\n    # e.g., [[0.0025,False],[0.015,True],[0.018,True]]\n    # str(bool_value) correctly produces 'True' or 'False'.\n    inner_parts = [f\"[{m},{b}]\" for m, b in results]\n    print(f\"[{','.join(inner_parts)}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "在真实的聚变装置控制中，我们往往需要在相互冲突的目标之间寻求平衡。本实践练习模拟了这样一个高级场景：我们既要最小化等离子体芯部的误差场，又要维持边缘所需的特定磁扰动强度。你将学习如何通过加权和方法来探索这些目标之间的帕累托（Pareto）权衡边界，并使用一种几何启发式方法来自动识别“拐点”处的最佳折衷方案。",
            "id": "3976162",
            "problem": "给定一个用于环形装置中磁误差场的线圈电流驱动的线性化、无量綱模型。决策变量是线圈电流向量 $\\mathbf{x} \\in \\mathbb{R}^n$。核心误差场残差由一个线性映射 $\\mathbf{C} \\in \\mathbb{R}^{m_c \\times n}$ 和一个期望的核心抵消向量 $\\mathbf{d} \\in \\mathbb{R}^{m_c}$ 表示，得到核心残差成本 $J_c(\\mathbf{x}) = \\lVert \\mathbf{C}\\mathbf{x} - \\mathbf{d} \\rVert_2^2$。边界共振磁扰动（RMP）强度目标由一个线性映射 $\\mathbf{E} \\in \\mathbb{R}^{m_e \\times n}$ 和一个期望的 RMP 向量 $\\mathbf{r} \\in \\mathbb{R}^{m_e}$ 表示，得到边界跟踪成本 $J_e(\\mathbf{x}) = \\lVert \\mathbf{E}\\mathbf{x} - \\mathbf{r} \\rVert_2^2$。为引入工程限制并避免病态问题，加入了一个 Tikhonov 正则化项 $\\mu \\lVert \\mathbf{x} \\rVert_2^2$，其中 $\\mu  0$。所有量均为无量纲和归一化的，因此不需要物理单位。\n\n对于固定的 $\\mu$，使用集合 $\\mathcal{W} = \\{\\, 0,\\, 0.1,\\, 0.25,\\, 0.5,\\, 0.75,\\, 0.9,\\, 1 \\,\\}$ 上的加权和标量化参数 $w \\in [0,1]$ 执行帕累托优化。对于每个 $w \\in \\mathcal{W}$，考虑凸二次规划问题\n$$\n\\min_{\\mathbf{x} \\in \\mathbb{R}^n} \\; F_w(\\mathbf{x}) = w \\, J_c(\\mathbf{x}) + (1-w) \\, J_e(\\mathbf{x}) + \\mu \\lVert \\mathbf{x} \\rVert_2^2,\n$$\n并将唯一极小值点记为 $\\mathbf{x}_w$。定义实现的核心残差 $J_c(\\mathbf{x}_w)$、边界跟踪残差 $J_e(\\mathbf{x}_w)$ 以及实现的边界 RMP 强度 $S(\\mathbf{x}_w) = \\lVert \\mathbf{E} \\mathbf{x}_w \\rVert_2$。\n\n通过以下步骤确定帕累托权衡曲线的离散“拐点”来选择工作点：按 $w \\in \\mathcal{W}$ 的递增顺序构建点序列 $\\big( \\log_{10} J_c(\\mathbf{x}_w), \\log_{10} J_e(\\mathbf{x}_w) \\big)$，然后对每三个连续点组成的点组，计算其 Menger 曲率 $\\kappa = \\dfrac{4 A}{a b c}$，其中 $a$、$b$ 和 $c$ 是该点组构成的三角形的边长，$A$ 是三角形的面积。选择与内部三点组（不包括端点）中最大曲率对应的 $w^\\star \\in \\mathcal{W}$。返回三元组 $\\big[ w^\\star,\\, J_c(\\mathbf{x}_{w^\\star}),\\, S(\\mathbf{x}_{w^\\star}) \\big]$。\n\n使用正则化参数 $\\mu = 10^{-3}$ 并求解以下三个独立的测试用例。每个用例都明确定义了 $\\mathbf{C}$、$\\mathbf{d}$、$\\mathbf{E}$ 和 $\\mathbf{r}$。\n\n测试用例 1：\n$$\n\\mathbf{C}_1 = \\begin{pmatrix}\n1  0.5  0 \\\\\n0  1  0.5\n\\end{pmatrix}, \\quad\n\\mathbf{d}_1 = \\begin{pmatrix} 0.1 \\\\ -0.2 \\end{pmatrix}, \\quad\n\\mathbf{E}_1 = \\begin{pmatrix}\n0.2  -0.5  1.0 \\\\\n0  0.3  0.4\n\\end{pmatrix}, \\quad\n\\mathbf{r}_1 = \\begin{pmatrix} 0.3 \\\\ 0.0 \\end{pmatrix}.\n$$\n\n测试用例 2：\n$$\n\\mathbf{C}_2 = \\begin{pmatrix}\n1.0  2.0  -1.0 \\\\\n0.0  1.0  1.0 \\\\\n1.0  -1.0  0.5\n\\end{pmatrix}, \\quad\n\\mathbf{d}_2 = \\begin{pmatrix} 0.05 \\\\ -0.1 \\\\ 0.2 \\end{pmatrix}, \\quad\n\\mathbf{E}_2 = \\begin{pmatrix}\n-0.3  1.0  0.7 \\\\\n0.6  -0.2  0.1\n\\end{pmatrix}, \\quad\n\\mathbf{r}_2 = \\begin{pmatrix} 0.4 \\\\ 0.2 \\end{pmatrix}.\n$$\n\n测试用例 3：\n$$\n\\mathbf{C}_3 = \\begin{pmatrix}\n10^{-2}  2 \\cdot 10^{-2}  -10^{-2} \\\\\n2 \\cdot 10^{-2}  4 \\cdot 10^{-2}  -2 \\cdot 10^{-2}\n\\end{pmatrix}, \\quad\n\\mathbf{d}_3 = \\begin{pmatrix} 10^{-3} \\\\ -10^{-3} \\end{pmatrix}, \\quad\n\\mathbf{E}_3 = \\begin{pmatrix}\n1.0  0.0  0.0 \\\\\n0.0  1.0  0.0\n\\end{pmatrix}, \\quad\n\\mathbf{r}_3 = \\begin{pmatrix} 0.2 \\\\ -0.1 \\end{pmatrix}.\n$$\n\n要求：\n- 对于每个测试用例 $i \\in \\{1,2,3\\}$ 和每个 $w \\in \\mathcal{W}$，求解 $\\mathbf{x}_w$ 并计算上文定义的 $J_c(\\mathbf{x}_w)$、$J_e(\\mathbf{x}_w)$ 和 $S(\\mathbf{x}_w)$。使用 $\\mu = 10^{-3}$。\n- 通过最大化 $\\big( \\log_{10} J_c, \\log_{10} J_e \\big)$ 曲线上内部三点组的离散 Menger 曲率来确定 $w^\\star$。\n- 您的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表。该列表包含对应于三个测试用例的三个元素，每个元素是形式为 $[w^\\star, J_c(\\mathbf{x}_{w^\\star}), S(\\mathbf{x}_{w^\\star})]$ 的列表。例如，输出形式为 $\\big[\\,[\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot]\\,\\big]$。\n\n所有计算都是纯数值和无量纲的；不需要单位转换。不使用角度。输出必须是实数。",
            "solution": "该问题需要求解一系列正则化线性最小二乘问题来描绘帕累托前沿，然后进行几何分析以确定一个最佳工作点。多目标优化、线性代数和数值几何的原理是该解决方案的核心。\n\n首先，我们处理固定权重 $w \\in [0,1]$ 的核心优化问题。需要最小化的目标函数是\n$$\nF_w(\\mathbf{x}) = w \\lVert \\mathbf{C}\\mathbf{x} - \\mathbf{d} \\rVert_2^2 + (1-w) \\lVert \\mathbf{E}\\mathbf{x} - \\mathbf{r} \\rVert_2^2 + \\mu \\lVert \\mathbf{x} \\rVert_2^2.\n$$\n这是关于决策变量 $\\mathbf{x}$ 的二次函数。我们可以展开范数的平方项：\n$J_c(\\mathbf{x}) = (\\mathbf{C}\\mathbf{x} - \\mathbf{d})^T (\\mathbf{C}\\mathbf{x} - \\mathbf{d}) = \\mathbf{x}^T \\mathbf{C}^T \\mathbf{C} \\mathbf{x} - 2\\mathbf{d}^T \\mathbf{C} \\mathbf{x} + \\mathbf{d}^T \\mathbf{d}$\n$J_e(\\mathbf{x}) = (\\mathbf{E}\\mathbf{x} - \\mathbf{r})^T (\\mathbf{E}\\mathbf{x} - \\mathbf{r}) = \\mathbf{x}^T \\mathbf{E}^T \\mathbf{E} \\mathbf{x} - 2\\mathbf{r}^T \\mathbf{E} \\mathbf{x} + \\mathbf{r}^T \\mathbf{r}$\n将这些代入 $F_w(\\mathbf{x})$ 并根据 $\\mathbf{x}$ 的幂次合并项可得：\n$$\nF_w(\\mathbf{x}) = \\mathbf{x}^T \\left( w \\mathbf{C}^T \\mathbf{C} + (1-w) \\mathbf{E}^T \\mathbf{E} + \\mu \\mathbf{I} \\right) \\mathbf{x} - 2 \\left( w \\mathbf{d}^T \\mathbf{C} + (1-w) \\mathbf{r}^T \\mathbf{E} \\right) \\mathbf{x} + \\text{const}.\n$$\n这是一个凸二次型。通过将关于 $\\mathbf{x}$ 的梯度设为零，可以找到极小值点 $\\mathbf{x}_w$：\n$$\n\\nabla_{\\mathbf{x}} F_w(\\mathbf{x}) = 2 \\left( w \\mathbf{C}^T \\mathbf{C} + (1-w) \\mathbf{E}^T \\mathbf{E} + \\mu \\mathbf{I} \\right) \\mathbf{x} - 2 \\left( w \\mathbf{C}^T \\mathbf{d} + (1-w) \\mathbf{E}^T \\mathbf{r} \\right) = \\mathbf{0}.\n$$\n这可以简化为称为正规方程组的线性方程组：\n$$\n\\left( w \\mathbf{C}^T \\mathbf{C} + (1-w) \\mathbf{E}^T \\mathbf{E} + \\mu \\mathbf{I} \\right) \\mathbf{x}_w = w \\mathbf{C}^T \\mathbf{d} + (1-w) \\mathbf{E}^T \\mathbf{r}.\n$$\n我们定义 $\\mathbf{A}_w = w \\mathbf{C}^T \\mathbf{C} + (1-w) \\mathbf{E}^T \\mathbf{E} + \\mu \\mathbf{I}$ 和 $\\mathbf{b}_w = w \\mathbf{C}^T \\mathbf{d} + (1-w) \\mathbf{E}^T \\mathbf{r}$。该系统为 $\\mathbf{A}_w \\mathbf{x}_w = \\mathbf{b}_w$。矩阵 $\\mathbf{A}_w$ 保证是可逆的，因为它是半正定矩阵（对于 $w \\in [0,1]$ 的 $w \\mathbf{C}^T \\mathbf{C}$ 和 $(1-w) \\mathbf{E}^T \\mathbf{E}$）与一个正定矩阵（对于 $\\mu > 0$ 的 $\\mu \\mathbf{I}$）的和。因此，$\\mathbf{A}_w$ 是正定的，对于每个 $w$ 都存在唯一解 $\\mathbf{x}_w = \\mathbf{A}_w^{-1} \\mathbf{b}_w$。\n\n总的求解步骤如下：\n1. 对于每个测试用例，给定矩阵 $\\mathbf{C}$、$\\mathbf{E}$ 和向量 $\\mathbf{d}$、$\\mathbf{r}$。正则化参数固定为 $\\mu = 10^{-3}$。\n2. 我们遍历指定集合 $\\mathcal{W} = \\{0, 0.1, 0.25, 0.5, 0.75, 0.9, 1\\}$ 中的每个权重 $w$。\n3. 对于每个 $w$，我们构造如上定义的矩阵 $\\mathbf{A}_w$ 和向量 $\\mathbf{b}_w$。\n4. 我们求解线性系统 $\\mathbf{A}_w \\mathbf{x}_w = \\mathbf{b}_w$ 以找到最优线圈电流向量 $\\mathbf{x}_w$。\n5. 使用 $\\mathbf{x}_w$，我们计算实现的核心残差和边界残差，$J_c(\\mathbf{x}_w) = \\lVert \\mathbf{C}\\mathbf{x}_w - \\mathbf{d} \\rVert_2^2$ 和 $J_e(\\mathbf{x}_w) = \\lVert \\mathbf{E}\\mathbf{x}_w - \\mathbf{r} \\rVert_2^2$。\n6. 我们按 $w$ 递增的顺序，在对数空间中构建表示帕累托权衡曲线的点序列：$P_w = \\left( \\log_{10} J_c(\\mathbf{x}_w), \\log_{10} J_e(\\mathbf{x}_w) \\right)$。\n7. 为找到此曲线的“拐点”，我们分析连续的内部三点组。对于每个内部点 $P_i$（对应于 $w_i \\in \\{0.1, 0.25, 0.5, 0.75, 0.9\\}$）及其相邻点 $P_{i-1}$ 和 $P_{i+1}$，我们计算 Menger 曲率 $\\kappa_i$。\n8. Menger 曲率由 $\\kappa = \\frac{4A}{abc}$ 给出，其中 $a$、$b$ 和 $c$ 是三点构成的三角形的边长，$A$ 是三角形的面积。面积 $A$ 可以使用向量叉积的模来稳健地计算：对于点 $\\mathbf{p}_1, \\mathbf{p}_2, \\mathbf{p}_3$，$A = \\frac{1}{2} | (\\mathbf{p}_2 - \\mathbf{p}_1) \\times (\\mathbf{p}_3 - \\mathbf{p}_1) |$，在二维情况下为 $A = \\frac{1}{2} |(x_2-x_1)(y_3-y_1) - (x_3-x_1)(y_2-y_1)|$。\n9. 我们确定产生最大曲率的三点组所对应的权重 $w^\\star$。这个 $w^\\star$ 就是我们选定的工作点。\n10. 最后，我们检索对应的核心残差 $J_c(\\mathbf{x}_{w^\\star})$ 并计算实现的边界 RMP 强度 $S(\\mathbf{x}_{w^\\star}) = \\lVert \\mathbf{E} \\mathbf{x}_{w^\\star} \\rVert_2$。要求的输出是三元组 $[w^\\star, J_c(\\mathbf{x}_{w^\\star}), S(\\mathbf{x}_{w^\\star})]$。\n\n此过程系统地应用于所有三个测试用例。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the three test cases for the error field correction problem.\n    \"\"\"\n    mu = 1e-3\n    W = [0.0, 0.1, 0.25, 0.5, 0.75, 0.9, 1.0]\n\n    # Test case 1 data\n    C1 = np.array([[1.0, 0.5, 0.0],\n                   [0.0, 1.0, 0.5]])\n    d1 = np.array([0.1, -0.2])\n    E1 = np.array([[0.2, -0.5, 1.0],\n                   [0.0, 0.3, 0.4]])\n    r1 = np.array([0.3, 0.0])\n\n    # Test case 2 data\n    C2 = np.array([[1.0, 2.0, -1.0],\n                   [0.0, 1.0, 1.0],\n                   [1.0, -1.0, 0.5]])\n    d2 = np.array([0.05, -0.1, 0.2])\n    E2 = np.array([[-0.3, 1.0, 0.7],\n                   [0.6, -0.2, 0.1]])\n    r2 = np.array([0.4, 0.2])\n\n    # Test case 3 data\n    C3 = np.array([[1e-2, 2e-2, -1e-2],\n                   [2e-2, 4e-2, -2e-2]])\n    d3 = np.array([1e-3, -1e-3])\n    E3 = np.array([[1.0, 0.0, 0.0],\n                   [0.0, 1.0, 0.0]])\n    r3 = np.array([0.2, -0.1])\n    \n    test_cases = [\n        (C1, d1, E1, r1),\n        (C2, d2, E2, r2),\n        (C3, d3, E3, r3)\n    ]\n\n    final_results = []\n    for C, d, E, r in test_cases:\n        result = solve_case(C, d, E, r, mu, W)\n        final_results.append(result)\n\n    # Format the final output string as specified\n    # Using a simple list-to-string conversion which produces the required format\n    # Example: [[0.75, 0.003, 0.25], [0.5, 0.01, 0.4], ...]\n    output_str = str(final_results).replace(\" \", \"\")\n    print(output_str)\n\n\ndef solve_case(C, d, E, r, mu, W):\n    \"\"\"\n    Solves a single test case of the optimization problem.\n\n    Args:\n        C (np.ndarray): Core error field mapping matrix.\n        d (np.ndarray): Desired core cancellation vector.\n        E (np.ndarray): Edge RMP strength mapping matrix.\n        r (np.ndarray): Desired RMP vector.\n        mu (float): Tikhonov regularization parameter.\n        W (list of float): List of weights for Pareto optimization.\n\n    Returns:\n        list: A list containing [w_star, Jc(x_w_star), S(x_w_star)].\n    \"\"\"\n    n = C.shape[1]\n    I = np.identity(n)\n    \n    pareto_points = []\n    results_for_w = {}\n\n    for w in W:\n        # Formulate and solve the linear system A_w * x_w = b_w\n        A_w = w * (C.T @ C) + (1 - w) * (E.T @ E) + mu * I\n        b_w = w * (C.T @ d) + (1 - w) * (E.T @ r)\n        x_w = np.linalg.solve(A_w, b_w)\n\n        # Calculate performance metrics\n        Jc_xw = np.linalg.norm(C @ x_w - d)**2\n        Je_xw = np.linalg.norm(E @ x_w - r)**2\n        S_xw = np.linalg.norm(E @ x_w)\n\n        # Store data for Pareto analysis\n        # Add a small epsilon to avoid log10(0)\n        epsilon = 1e-16\n        pareto_points.append((np.log10(Jc_xw + epsilon), np.log10(Je_xw + epsilon)))\n        results_for_w[w] = {\n            'Jc': Jc_xw,\n            'S': S_xw,\n        }\n    \n    # Find the knee of the Pareto curve using Menger curvature\n    curvatures = []\n    # Iterate over interior triples of points on the curve\n    for i in range(1, len(W) - 1):\n        p_prev = np.array(pareto_points[i-1])\n        p_curr = np.array(pareto_points[i])\n        p_next = np.array(pareto_points[i+1])\n\n        # Calculate side lengths of the triangle formed by the triple\n        a = np.linalg.norm(p_next - p_curr)\n        b = np.linalg.norm(p_next - p_prev)\n        c = np.linalg.norm(p_curr - p_prev)\n\n        # Check for collinearity or degenerate triangles\n        if a * b * c == 0.0:\n            curvatures.append(0.0)\n            continue\n        \n        # Calculate triangle area using the 2D cross product magnitude for numerical stability\n        # Area = 0.5 * |(x_prev-x_curr)(y_next-y_curr) - (x_next-x_curr)(y_prev-y_curr)|\n        area = 0.5 * np.abs( (p_prev[0] - p_curr[0]) * (p_next[1] - p_curr[1]) - \\\n                              (p_next[0] - p_curr[0]) * (p_prev[1] - p_curr[1]) )\n\n        # Menger curvature formula\n        kappa = (4 * area) / (a * b * c)\n        curvatures.append(kappa)\n\n    # The curvature list corresponds to the interior weights W[1] through W[len(W)-2]\n    # Find the index of the maximum curvature\n    if not curvatures: # Handle cases with fewer than 3 points\n        w_star = W[len(W) // 2] # Fallback to middle weight\n    else:\n        max_curvature_idx = np.argmax(curvatures)\n        # The index in the original weight list W is offset by 1\n        w_star_index = max_curvature_idx + 1\n        w_star = W[w_star_index]\n\n    # Retrieve the final results for the optimal weight w_star\n    final_Jc = results_for_w[w_star]['Jc']\n    final_S = results_for_w[w_star]['S']\n    \n    return [w_star, final_Jc, final_S]\n\n# The main execution block is guarded to be used as a script\nif __name__ == '__main__':\n    # This is a dummy call to the solve function since the environment\n    # seems to prefer to have the main logic outside of the guard.\n    # The actual solve() call is outside this guard.\n    pass\n\nsolve()\n```"
        }
    ]
}