{
    "hands_on_practices": [
        {
            "introduction": "Choosing an appropriate k-point mesh is a critical first step in any periodic electronic structure calculation. The density of the k-point grid in reciprocal space is inversely related to the dimensions of the real-space unit cell, meaning a larger cell requires a less dense sampling to achieve a comparable level of accuracy. This exercise  provides a hands-on procedure to translate a desired reciprocal-space resolution, $\\Delta k$, into a concrete Monkhorst-Pack grid size for any given crystal structure. Mastering this protocol ensures that simulations are set up with a rational and reproducible basis for k-point convergence.",
            "id": "3870659",
            "problem": "In periodic electronic-structure modeling for catalytic materials within computational catalysis and chemical engineering, Brillouin Zone (BZ) sampling is performed on a grid of wave vectors, often using a Gamma-centered Monkhorst-Pack (MP) mesh. Consider a crystalline slab used to model a close-packed catalytic surface, described by three direct lattice vectors $\\mathbf{a}$, $\\mathbf{b}$, and $\\mathbf{c}$ with lengths $a$, $b$, and $c$ and interaxial angles $\\alpha$ (between $\\mathbf{b}$ and $\\mathbf{c}$), $\\beta$ (between $\\mathbf{a}$ and $\\mathbf{c}$), and $\\gamma$ (between $\\mathbf{a}$ and $\\mathbf{b}$). The reciprocal lattice vectors are defined by the standard crystallographic convention $\\mathbf{b}_1 = 2\\pi \\, \\frac{\\mathbf{b} \\times \\mathbf{c}}{V}$, $\\mathbf{b}_2 = 2\\pi \\, \\frac{\\mathbf{c} \\times \\mathbf{a}}{V}$, and $\\mathbf{b}_3 = 2\\pi \\, \\frac{\\mathbf{a} \\times \\mathbf{b}}{V}$, where $V$ is the volume of the direct lattice unit cell.\n\nStarting from these definitions and the geometry of the direct lattice, propose a logically justified protocol to choose the integer grid sizes $(N_x, N_y, N_z)$ for a Gamma-centered Monkhorst-Pack mesh to achieve a target maximum reciprocal-space resolution $\\Delta k$ along each reciprocal primitive direction. Derive a general mapping from a given target $\\Delta k$ to the integers $(N_x, N_y, N_z)$ that guarantees the spacing between adjacent sampled $\\mathbf{k}$-points along each reciprocal basis direction is less than or equal to $\\Delta k$, while preserving Gamma centering. Your protocol must enforce the smallest odd integers that satisfy the resolution target and must guarantee at least one division along each direction.\n\nThen apply your derived mapping to the following hexagonal slab geometry that is commonly used to represent a close-packed catalyst surface:\n- $a = 2.500$ $\\mathrm{\\AA}$, $b = 2.500$ $\\mathrm{\\AA}$, $c = 15.000$ $\\mathrm{\\AA}$.\n- $\\alpha = 90^\\circ$, $\\beta = 90^\\circ$, $\\gamma = 120^\\circ$.\n- Target resolution $\\Delta k = 0.200$ $\\mathrm{\\AA}^{-1}$.\nAngles are given in degrees. Express the final grid sizes $(N_x, N_y, N_z)$ as integers, using the minimal odd-integer choice consistent with your protocol. The final answer must be a single row matrix containing the three integers, with no units in the final boxed expression.",
            "solution": "The problem is first validated against the principles of scientific correctness, logical consistency, and completeness.\n\n### Problem Validation\n**Step 1: Extract Givens**\n- **Direct Lattice:** Vectors $\\mathbf{a}$, $\\mathbf{b}$, $\\mathbf{c}$ with lengths $a$, $b$, $c$ and interaxial angles $\\alpha$, $\\beta$, $\\gamma$.\n- **Reciprocal Lattice Vectors:** $\\mathbf{b}_1 = 2\\pi \\, \\frac{\\mathbf{b} \\times \\mathbf{c}}{V}$, $\\mathbf{b}_2 = 2\\pi \\, \\frac{\\mathbf{c} \\times \\mathbf{a}}{V}$, and $\\mathbf{b}_3 = 2\\pi \\, \\frac{\\mathbf{a} \\times \\mathbf{b}}{V}$, where $V = \\mathbf{a} \\cdot (\\mathbf{b} \\times \\mathbf{c})$ is the direct cell volume.\n- **Sampling Scheme:** Gamma-centered Monkhorst-Pack (MP) mesh with integer grid sizes $(N_x, N_y, N_z)$.\n- **Resolution Constraint:** The spacing between adjacent sampled $\\mathbf{k}$-points along each reciprocal basis direction must be less than or equal to a target resolution $\\Delta k$.\n- **Integer Choice Protocol:** The integers $(N_x, N_y, N_z)$ must be the smallest odd integers that satisfy the resolution target and must be at least $1$.\n- **Specific Geometry:** A hexagonal slab with $a = 2.500$ $\\mathrm{\\AA}$, $b = 2.500$ $\\mathrm{\\AA}$, $c = 15.000$ $\\mathrm{\\AA}$, $\\alpha = 90^\\circ$, $\\beta = 90^\\circ$, and $\\gamma = 120^\\circ$.\n- **Specific Target Resolution:** $\\Delta k = 0.200$ $\\mathrm{\\AA}^{-1}$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is well-defined and scientifically sound.\n- **Scientifically Grounded:** The definitions of direct and reciprocal lattices, unit cell volume, and the concept of Brillouin zone sampling with a Monkhorst-Pack mesh are fundamental principles in solid-state physics and computational materials science. The provided numerical values for the lattice are physically plausible for a surface slab model.\n- **Well-Posed:** The problem provides all necessary definitions, constraints, and data to derive a unique solution. The requirements for the grid sizes $(N_x, N_y, N_z)$ are specified unambiguously (smallest odd integers satisfying a clear inequality).\n- **Objective:** The language is precise and quantitative. There are no subjective or opinion-based statements.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. A complete, reasoned solution will be provided.\n\n### Solution\nThe solution is developed in two parts. First, a general protocol for determining the Monkhorst-Pack grid dimensions is derived. Second, this protocol is applied to the specific hexagonal slab geometry provided.\n\n**Part 1: Derivation of the General Protocol**\nA Monkhorst-Pack grid is a uniform mesh of $\\mathbf{k}$-points sampling the Brillouin zone. For a grid with $N_x$, $N_y$, and $N_z$ divisions along the reciprocal lattice vector directions $\\mathbf{b}_1$, $\\mathbf{b}_2$, and $\\mathbf{b}_3$, respectively, the set of sampled $\\mathbf{k}$-points is generated by linear combinations of fractional coordinates along these vectors.\n\nThe spacing between adjacent $\\mathbf{k}$-points along the direction of the reciprocal vector $\\mathbf{b}_1$ is the magnitude of the vector $\\frac{1}{N_x}\\mathbf{b}_1$, which is $\\frac{|\\mathbf{b}_1|}{N_x}$. Let the magnitudes of the reciprocal lattice vectors be $b_1 = |\\mathbf{b}_1|$, $b_2 = |\\mathbf{b}_2|$, and $b_3 = |\\mathbf{b}_3|$. The spacings are thus $\\frac{b_1}{N_x}$, $\\frac{b_2}{N_y}$, and $\\frac{b_3}{N_z}$.\n\nThe problem requires that this spacing be no greater than a target resolution, $\\Delta k$. This gives rise to a set of inequalities for the integer grid sizes $N_x, N_y, N_z$:\n$$\n\\frac{b_1}{N_x} \\le \\Delta k \\implies N_x \\ge \\frac{b_1}{\\Delta k}\n$$\n$$\n\\frac{b_2}{N_y} \\le \\Delta k \\implies N_y \\ge \\frac{b_2}{\\Delta k}\n$$\n$$\n\\frac{b_3}{N_z} \\le \\Delta k \\implies N_z \\ge \\frac{b_3}{\\Delta k}\n$$\nThe problem further mandates that $N_x$, $N_y$, and $N_z$ must be the smallest positive odd integers that satisfy these conditions. The condition of being a positive integer guarantees at least one division.\n\nThe protocol to determine each integer $N_i$ (for $i \\in \\{x,y,z\\}$) is as follows:\n1.  Calculate the minimum required value, $R_i = \\frac{b_i}{\\Delta k}$.\n2.  Find the smallest integer that is greater than or equal to $R_i$. This is calculated using the ceiling function, $M_i = \\lceil R_i \\rceil$.\n3.  If $M_i$ is an odd number, then $N_i = M_i$.\n4.  If $M_i$ is an even number, the next odd integer must be chosen, so $N_i = M_i + 1$.\n\nThis protocol ensures all constraints are met.\n\n**Part 2: Application to the Hexagonal Slab Geometry**\nFirst, we must calculate the magnitudes of the reciprocal lattice vectors ($b_1, b_2, b_3$) from the given direct lattice parameters: $a = 2.500$ $\\mathrm{\\AA}$, $b = 2.500$ $\\mathrm{\\AA}$, $c = 15.000$ $\\mathrm{\\AA}$, $\\alpha = 90^\\circ$, $\\beta = 90^\\circ$, and $\\gamma = 120^\\circ$.\n\nThe volume of the direct lattice unit cell, $V$, is given by the formula:\n$$\nV = abc \\sqrt{1 - \\cos^2\\alpha - \\cos^2\\beta - \\cos^2\\gamma + 2\\cos\\alpha\\cos\\beta\\cos\\gamma}\n$$\nSubstituting the given angles, $\\cos(90^\\circ) = 0$ and $\\cos(120^\\circ) = -1/2$:\n$$\nV = (2.5)(2.5)(15.0) \\sqrt{1 - 0 - 0 - \\left(-\\frac{1}{2}\\right)^2 + 2(0)(0)\\left(-\\frac{1}{2}\\right)} = 93.75 \\sqrt{1 - \\frac{1}{4}} = 93.75 \\frac{\\sqrt{3}}{2} \\text{ } \\mathrm{\\AA}^3\n$$\nFor these specific angles where $\\alpha=\\beta=90^\\circ$, the volume formula simplifies to $V = abc\\sin\\gamma$.\n\nThe magnitudes of the reciprocal lattice vectors are given by:\n$$\nb_1 = |\\mathbf{b}_1| = \\frac{2\\pi}{V} |\\mathbf{b} \\times \\mathbf{c}| = \\frac{2\\pi bc \\sin\\alpha}{V}\n$$\n$$\nb_2 = |\\mathbf{b}_2| = \\frac{2\\pi}{V} |\\mathbf{c} \\times \\mathbf{a}| = \\frac{2\\pi ca \\sin\\beta}{V}\n$$\n$$\nb_3 = |\\mathbf{b}_3| = \\frac{2\\pi}{V} |\\mathbf{a} \\times \\mathbf{b}| = \\frac{2\\pi ab \\sin\\gamma}{V}\n$$\nSubstituting $V = abc\\sin\\gamma$ and the given angles:\n$$\nb_1 = \\frac{2\\pi bc \\sin(90^\\circ)}{abc\\sin(120^\\circ)} = \\frac{2\\pi (1)}{a\\sin(120^\\circ)} = \\frac{2\\pi}{(2.5)(\\sqrt{3}/2)} = \\frac{4\\pi}{2.5\\sqrt{3}} = \\frac{8\\pi}{5\\sqrt{3}} = \\frac{8\\pi\\sqrt{3}}{15} \\text{ } \\mathrm{\\AA}^{-1}\n$$\nSince $a=b$ and $\\alpha=\\beta$, the magnitude $b_2$ is identical to $b_1$:\n$$\nb_2 = \\frac{2\\pi ca \\sin(90^\\circ)}{abc\\sin(120^\\circ)} = \\frac{2\\pi (1)}{b\\sin(120^\\circ)} = \\frac{8\\pi\\sqrt{3}}{15} \\text{ } \\mathrm{\\AA}^{-1}\n$$\nFor $b_3$:\n$$\nb_3 = \\frac{2\\pi ab \\sin(120^\\circ)}{abc\\sin(120^\\circ)} = \\frac{2\\pi}{c} = \\frac{2\\pi}{15} \\text{ } \\mathrm{\\AA}^{-1}\n$$\nNow we apply the derived protocol with the target resolution $\\Delta k = 0.200 = 1/5$ $\\mathrm{\\AA}^{-1}$.\n\nFor $N_x$:\n$$\nR_x = \\frac{b_1}{\\Delta k} = \\frac{8\\pi\\sqrt{3}/15}{1/5} = \\frac{8\\pi\\sqrt{3}}{3} \\approx 14.518\n$$\nThe smallest integer greater than or equal to $14.518$ is $M_x = \\lceil 14.518 \\rceil = 15$. Since $15$ is an odd number, we set $N_x = 15$.\n\nFor $N_y$:\n$$\nR_y = \\frac{b_2}{\\Delta k} = \\frac{8\\pi\\sqrt{3}/15}{1/5} = \\frac{8\\pi\\sqrt{3}}{3} \\approx 14.518\n$$\nThe smallest integer greater than or equal to $14.518$ is $M_y = \\lceil 14.518 \\rceil = 15$. Since $15$ is an odd number, we set $N_y = 15$.\n\nFor $N_z$:\n$$\nR_z = \\frac{b_3}{\\Delta k} = \\frac{2\\pi/15}{1/5} = \\frac{2\\pi}{3} \\approx 2.094\n$$\nThe smallest integer greater than or equal to $2.094$ is $M_z = \\lceil 2.094 \\rceil = 3$. Since $3$ is an odd number, we set $N_z = 3$.\n\nThe resulting Monkhorst-Pack grid size is $(N_x, N_y, N_z) = (15, 15, 3)$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n15 & 15 & 3\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Achieving a target accuracy in a DFT calculation is not about converging a single parameter in isolation, but about balancing multiple numerical settings against the total computational cost. The total energy error is a composite of errors from different approximations, primarily the plane-wave basis set cutoff $E_{\\text{cut}}$ and the Brillouin zone sampling density, represented by the number of k-points $N_k$. This practice  frames the task as a multi-objective optimization problem, challenging you to find the most computationally efficient pair of $(E_{\\text{cut}}, N_k)$ that satisfies a given accuracy threshold, a crucial skill for managing resources in large-scale computational projects.",
            "id": "3870671",
            "problem": "Consider a periodic metallic system commonly used in computational catalysis and chemical engineering, where the total energy per unit cell is computed using a plane-wave basis and Brillouin zone integration. The following well-tested base facts and definitions apply:\n\n- Under periodic boundary conditions, electronic states are described by Bloch functions, and the total energy per unit cell is a Brillouin zone integral over crystal momentum $k$. Numerical evaluation replaces the integral by a sum over $N_k$ discrete $k$-points, for example via Monkhorst-Pack grids. For metals with finite-temperature smearing, the quadrature error of the Brillouin zone sampling decreases algebraically with the number of points, and is represented as $e_k(N_k) = B N_k^{-q}$ for some positive constants $B$ and $q$ that depend on the material and smearing details.\n\n- In a plane-wave method, the basis is truncated by an energy cutoff $E_{\\text{cut}}$ (in $\\mathrm{eV}$), which limits the maximum kinetic energy of included plane waves. The incompleteness error of a smooth observable such as the total energy typically decreases with increasing $E_{\\text{cut}}$ as a power law $e_{\\text{pw}}(E_{\\text{cut}}) = A E_{\\text{cut}}^{-p}$ for positive constants $A$ and $p$, reflecting the convergence properties of Fourier expansions of smooth functions.\n\n- The total energy error is modeled as the sum of the independent contributions $e_{\\text{tot}}(E_{\\text{cut}}, N_k) = e_{\\text{pw}}(E_{\\text{cut}}) + e_k(N_k) = A E_{\\text{cut}}^{-p} + B N_k^{-q}$.\n\n- Computational cost is dominated by operations that scale with the number of plane waves and the number of $k$-points. The number of plane waves scales as $N_{\\text{pw}} \\propto E_{\\text{cut}}^{3/2}$ because the count of reciprocal lattice vectors inside a sphere of radius set by $E_{\\text{cut}}$ grows as the volume in reciprocal space. Neglecting weak logarithmic factors, a simple and widely used cost model is $C(E_{\\text{cut}}, N_k) = \\gamma N_k E_{\\text{cut}}^{s}$ where $s \\approx 3/2$ and $\\gamma$ is a proportionality constant converting operation counts into wall-clock time (in seconds).\n\nYou are to compute, for given parameters $(A, p, B, q, s, \\gamma)$, a tolerance $\\tau$ (in $\\mathrm{eV}$), and bounded discrete search ranges for $E_{\\text{cut}}$ and $N_k$, the joint parameter choice $(E_{\\text{cut}}, N_k)$ that minimizes the computational cost $C(E_{\\text{cut}}, N_k)$ while satisfying the energy error constraint $e_{\\text{tot}}(E_{\\text{cut}}, N_k) \\le \\tau$. If no pair in the bounded search space satisfies the tolerance, return the pair that minimizes $e_{\\text{tot}}(E_{\\text{cut}}, N_k)$ (i.e., the closest achievable within bounds) and mark the case as not achievable.\n\nAlgorithmic requirements:\n\n- Use the error model $e_{\\text{tot}}(E_{\\text{cut}}, N_k) = A E_{\\text{cut}}^{-p} + B N_k^{-q}$.\n\n- Use the cost model $C(E_{\\text{cut}}, N_k) = \\gamma N_k E_{\\text{cut}}^{s}$.\n\n- Search $E_{\\text{cut}}$ on an integer grid in $\\mathrm{eV}$ with step $\\Delta E_{\\text{cut}}$ between bounds $E_{\\min}$ and $E_{\\max}$ inclusive.\n\n- Search $N_k$ over integers between $N_{k,\\min}$ and $N_{k,\\max}$ inclusive.\n\n- If multiple pairs achieve the same minimal cost (to within numerical tolerance), choose the one with the smallest $N_k$, and if still tied, the smallest $E_{\\text{cut}}$.\n\nUnits and output requirements:\n\n- All energies must be treated and reported in $\\mathrm{eV}$.\n\n- Computational cost must be reported in seconds.\n\n- For each test case, output a list $[\\text{achievable}, E_{\\text{cut}}^{\\star}, N_k^{\\star}, C^{\\star}]$ where $\\text{achievable}$ is a boolean indicating whether the tolerance $\\tau$ was met, $E_{\\text{cut}}^{\\star}$ is the chosen cutoff in $\\mathrm{eV}$ (integer), $N_k^{\\star}$ is the chosen number of $k$-points (integer), and $C^{\\star}$ is the computational cost in seconds (rounded to six decimal places). Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[ [\\text{True}, 500, 31, 1.733000], [\\text{False}, 900, 128, 4.321000] ]$).\n\nTest suite:\n\nUse the following four cases to exercise the algorithm:\n\n- Case $1$ (balanced, moderate tolerance):\n  - $A = 0.5$, $p = 1.5$, $B = 0.3$, $q = 1.0$, $s = 1.5$, $\\gamma = 5 \\times 10^{-6}$, $\\tau = 0.01$.\n  - $E_{\\min} = 200$, $E_{\\max} = 800$, $\\Delta E_{\\text{cut}} = 10$.\n  - $N_{k,\\min} = 6$, $N_{k,\\max} = 60$.\n\n- Case $2$ (tight tolerance, likely infeasible within bounds):\n  - $A = 0.8$, $p = 1.5$, $B = 0.5$, $q = 1.0$, $s = 1.5$, $\\gamma = 7 \\times 10^{-6}$, $\\tau = 0.001$.\n  - $E_{\\min} = 300$, $E_{\\max} = 900$, $\\Delta E_{\\text{cut}} = 10$.\n  - $N_{k,\\min} = 8$, $N_{k,\\max} = 128$.\n\n- Case $3$ (loose tolerance, basis error small relative to $k$-sampling):\n  - $A = 1.0$, $p = 1.2$, $B = 0.2$, $q = 1.0$, $s = 1.5$, $\\gamma = 4 \\times 10^{-6}$, $\\tau = 0.05$.\n  - $E_{\\min} = 200$, $E_{\\max} = 600$, $\\Delta E_{\\text{cut}} = 10$.\n  - $N_{k,\\min} = 4$, $N_{k,\\max} = 20$.\n\n- Case $4$ (dominant $k$-point error with slightly higher smoothness exponent):\n  - $A = 0.1$, $p = 1.5$, $B = 1.0$, $q = 1.2$, $s = 1.5$, $\\gamma = 6 \\times 10^{-6}$, $\\tau = 0.02$.\n  - $E_{\\min} = 300$, $E_{\\max} = 800$, $\\Delta E_{\\text{cut}} = 10$.\n  - $N_{k,\\min} = 10$, $N_{k,\\max} = 100$.\n\nYour program must implement the search and selection strategy described above for each case and produce the single-line aggregated output of four lists as specified. All numeric reporting must adhere to the units specified and $C^{\\star}$ must be rounded to six decimal places.",
            "solution": "The problem has been validated and is determined to be a well-posed, scientifically grounded, and objective optimization task within the domain of computational materials science. It is free of any invalidating flaws.\n\nThe task is to find the optimal computational parameters—the plane-wave energy cutoff, $E_{\\text{cut}}$, and the number of $k$-points, $N_k$—that minimize computational cost, $C$, while ensuring the total energy error, $e_{\\text{tot}}$, remains below a specified tolerance, $\\tau$. The problem provides physically motivated, algebraic models for both the error and the cost as functions of $E_{\\text{cut}}$ and $N_k$.\n\nThe total error is modeled as the sum of two independent contributions:\n$$ e_{\\text{tot}}(E_{\\text{cut}}, N_k) = e_{\\text{pw}}(E_{\\text{cut}}) + e_k(N_k) = A E_{\\text{cut}}^{-p} + B N_k^{-q} $$\nwhere $e_{\\text{pw}}$ is the basis set incompleteness error and $e_k$ is the Brillouin zone sampling error. The parameters $A, p, B, q$ are positive constants specific to the material system.\n\nThe computational cost is modeled as:\n$$ C(E_{\\text{cut}}, N_k) = \\gamma N_k E_{\\text{cut}}^{s} $$\nwhere $s \\approx 3/2$ and $\\gamma$ is a proportionality constant.\n\nThe search for the optimal pair $(E_{\\text{cut}}, N_k)$ is to be performed over a finite, discrete grid. $E_{\\text{cut}}$ is searched on an integer grid from $E_{\\min}$ to $E_{\\max}$ with a step of $\\Delta E_{\\text{cut}}$. $N_k$ is searched over integers from $N_{k,\\min}$ to $N_{k,\\max}$. Given that the search space is finite and not excessively large for the provided test cases, a comprehensive brute-force grid search is the most direct and robust algorithm. This approach guarantees that the true optimum within the discrete space is found, avoiding potential pitfalls of more complex optimization schemes that might be affected by the non-smooth or non-monotonic nature of the objective function when discretization effects are considered.\n\nThe algorithm proceeds as follows for each test case:\n1.  Generate all possible pairs $(E_{\\text{cut}}, N_k)$ within the specified discrete ranges.\n2.  For each pair, calculate the total error $e_{\\text{tot}}$ and the computational cost $C$.\n3.  Partition the resulting solutions into two groups:\n    a. `valid_solutions`: Pairs where the error constraint $e_{\\text{tot}} \\le \\tau$ is satisfied.\n    b. `all_solutions`: All pairs, stored with their calculated error and cost. This set is used for the fallback scenario.\n4.  Determine the final choice based on whether any valid solutions were found:\n    a. If `valid_solutions` is not empty, the tolerance is achievable. The optimal pair is found by sorting this list to find the one with the minimum cost. The problem specifies a clear tie-breaking rule: if costs are equal, the pair with the smaller $N_k$ is preferred; if that is also a tie, the smaller $E_{\\text{cut}}$ is chosen. This is implemented by sorting the valid solutions lexicographically using the tuple $(C, N_k, E_{\\text{cut}})$ as the key.\n    b. If `valid_solutions` is empty, the tolerance is not achievable. In this case, the requirement is to return the pair that minimizes the total error $e_{\\text{tot}}$. A reasonable and consistent tie-breaking scheme for this scenario, though not explicitly stated for this case, is to select from the minimum-error pairs the one with the lowest cost, followed by the lowest $N_k$, then the lowest $E_{\\text{cut}}$. This is implemented by sorting `all_solutions` lexicographically using the key $(e_{\\text{tot}}, C, N_k, E_{\\text{cut}})$.\n5.  The final result for the case, $[\\text{achievable}, E_{\\text{cut}}^{\\star}, N_k^{\\star}, C^{\\star}]$, is then constructed, with the cost $C^{\\star}$ rounded to six decimal places as required. The boolean `achievable` is set to `True` in the first scenario and `False` in the second.\nThis procedure is applied to each test case, and the results are aggregated into a single list of lists for the final output.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the optimal (E_cut, N_k) pair for a series of test cases based on\n    minimizing computational cost under an energy error constraint.\n    \"\"\"\n\n    test_cases = [\n        # Case 1 (balanced, moderate tolerance)\n        {\n            \"params\": (0.5, 1.5, 0.3, 1.0, 1.5, 5e-6, 0.01),\n            \"E_range\": (200, 800, 10),\n            \"Nk_range\": (6, 60)\n        },\n        # Case 2 (tight tolerance, likely infeasible)\n        {\n            \"params\": (0.8, 1.5, 0.5, 1.0, 1.5, 7e-6, 0.001),\n            \"E_range\": (300, 900, 10),\n            \"Nk_range\": (8, 128)\n        },\n        # Case 3 (loose tolerance, basis error small)\n        {\n            \"params\": (1.0, 1.2, 0.2, 1.0, 1.5, 4e-6, 0.05),\n            \"E_range\": (200, 600, 10),\n            \"Nk_range\": (4, 20)\n        },\n        # Case 4 (dominant k-point error)\n        {\n            \"params\": (0.1, 1.5, 1.0, 1.2, 1.5, 6e-6, 0.02),\n            \"E_range\": (300, 800, 10),\n            \"Nk_range\": (10, 100)\n        },\n    ]\n\n    results = []\n\n    for case in test_cases:\n        A, p, B, q, s, gamma, tau = case[\"params\"]\n        E_min, E_max, dE = case[\"E_range\"]\n        Nk_min, Nk_max = case[\"Nk_range\"]\n\n        E_cut_values = np.arange(E_min, E_max + 1, dE)\n        Nk_values = range(Nk_min, Nk_max + 1)\n\n        valid_solutions = []\n        all_solutions = []\n\n        for E_cut in E_cut_values:\n            # Pre-calculate E_cut dependent parts\n            e_pw = A * E_cut**(-p)\n            cost_factor_E = gamma * E_cut**s\n\n            for N_k in Nk_values:\n                # Calculate total error\n                e_k = B * N_k**(-q)\n                e_tot = e_pw + e_k\n\n                # Calculate computational cost\n                cost = cost_factor_E * N_k\n\n                # Store all solutions for fallback scenario\n                all_solutions.append((e_tot, cost, N_k, E_cut))\n                \n                # Check constraint and store valid solutions\n                if e_tot <= tau:\n                    valid_solutions.append((cost, N_k, E_cut))\n\n        if valid_solutions:\n            achievable = True\n            # Sort by cost, then N_k, then E_cut\n            valid_solutions.sort()\n            C_star, Nk_star, E_cut_star = valid_solutions[0]\n        else:\n            achievable = False\n            # Sort by error, then cost, then N_k, then E_cut\n            all_solutions.sort()\n            e_min, C_star, Nk_star, E_cut_star = all_solutions[0]\n        \n        results.append([achievable, E_cut_star, Nk_star, C_star])\n\n    def format_result(res):\n        ach, E, N, C = res\n        # Format with capital True/False and 6 decimal places for cost\n        return f\"[{str(ach)}, {E}, {N}, {C:.6f}]\"\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(format_result, results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "In simulations of metallic systems, particularly during geometry optimizations, numerical instabilities can arise that prevent the calculation from converging smoothly. A coarse sampling of the Brillouin zone can lead to abrupt, unphysical changes in the calculated forces as atoms move, which occurs when discrete k-points cross the Fermi level. This problem  tests your diagnostic skills by presenting a realistic case of \"force noise\" during an adsorption simulation, helping you learn to distinguish the symptoms of poor k-point sampling from other numerical artifacts and to select the most appropriate remedies.",
            "id": "3870674",
            "problem": "In a periodic Density Functional Theory (DFT) simulation of carbon monoxide adsorption on a platinum (111) slab, you optimize the geometry of a $3 \\times 3$ surface supercell with a vacuum region. You use a Monkhorst–Pack $\\mathbf{k}$-point grid of $3 \\times 3 \\times 1$ and a metallic smearing width of $\\sigma = 0.05\\ \\mathrm{eV}$. During a quasi-Newton ionic relaxation, the normal force on the adsorbate alternates sign between successive ionic steps while the total energy decreases nearly monotonically. When you refine the in-plane $\\mathbf{k}$-mesh to $5 \\times 5 \\times 1$, the force oscillations are reduced but not eliminated. Alternatively, when you keep the coarse $\\mathbf{k}$-mesh and increase smearing to $\\sigma = 0.20\\ \\mathrm{eV}$, the oscillations largely disappear, but the relaxed adsorption height increases by $0.10\\ \\mathrm{\\AA}$ relative to the result at $\\sigma = 0.05\\ \\mathrm{eV}$. You also observe that the relaxed adsorption height shows an odd–even dependence on the number of in-plane $\\mathbf{k}$-points along the $\\Gamma \\rightarrow M$ direction.\n\nConsider the following candidate statements about diagnostics and remedies for under-sampled Fermi surfaces in metallic slab calculations during adsorption relaxations. Which statements are correct?\n\nA. Alternating sign and magnitude of the adsorbate normal force between ionic steps, correlating with small changes in electronic occupations near the Fermi level at coarse $\\mathbf{k}$-point sampling, is a signature of an under-sampled Fermi surface. Increasing the in-plane $\\mathbf{k}$-point density and employing moderate finite-temperature smearing $\\sigma \\approx 0.10\\text{–}0.20\\ \\mathrm{eV}$ during relaxation are appropriate remedies to reduce such force oscillations.\n\nB. If the total energy varies smoothly with ionic steps but forces oscillate and this behavior disappears when the plane-wave cutoff is increased while being insensitive to $\\mathbf{k}$-mesh refinement and smearing changes, then the origin is an under-sampled Fermi surface; the remedy is to reduce the plane-wave cutoff to suppress basis-set Pulay forces.\n\nC. An odd–even dependence of the optimized adsorption height on the number of $\\mathbf{k}$-points along a direction intersecting the Fermi surface is consistent with poor Fermi surface integration; replacing finite-temperature smearing by the zero-temperature tetrahedron method with Blöchl corrections during relaxation is the recommended way to cure metallic force oscillations in slab relaxations.\n\nD. A strong dependence of relaxed geometry on the smearing width $\\sigma$ at fixed coarse $\\mathbf{k}$-mesh that vanishes upon simultaneous increase of $N_k$ and decrease of $\\sigma$ while approximately maintaining $N_k \\sigma$ constant indicates Fermi-surface under-sampling. A sound protocol is to converge forces with respect to both $N_k$ and $\\sigma$, minimize the finite-temperature Mermin free energy at nonzero $\\sigma$ during relaxation, and then extrapolate $\\sigma \\rightarrow 0$ at fixed dense $\\mathbf{k}$-mesh for final energetics.\n\nE. Switching from a $\\Gamma$-centered $3 \\times 3 \\times 1$ mesh to a Monkhorst–Pack $4 \\times 4 \\times 1$ mesh for a $3 \\times 3$ surface cell and observing a $0.20\\ \\mathrm{eV}$ change in adsorption energy while surface stress remains nearly unchanged is most likely caused by Pulay stress; the correct remedy is to decrease the electronic mixing parameter without changing $\\mathbf{k}$-points.\n\nF. During adsorption, the largest force oscillations coincide with small rigid shifts of the Fermi surface relative to the discrete $\\mathbf{k}$-points as the potential changes with ionic steps. Using denser in-plane $\\mathbf{k}$-meshes that target approximately uniform absolute $\\Delta k$ spacing across different supercell sizes, and employing Marzari–Vanderbilt cold smearing at moderate $\\sigma$, are effective mitigations for metallic slabs.\n\nSelect all statements that are correct.",
            "solution": "The supplied problem statement describes a common numerical issue encountered in periodic Density Functional Theory (DFT) calculations of metallic systems, specifically the phenomenon of force oscillations during ionic relaxations. The problem is well-posed and scientifically grounded, detailing a realistic scenario of carbon monoxide (CO) adsorption on a platinum (Pt)(111) surface. We will validate the provided observations and then evaluate each candidate statement.\n\nThe key physical and numerical principles are as follows:\n1.  In metallic systems, electronic states are continuously filled up to the Fermi energy, $E_F$. The boundary in reciprocal space between occupied and unoccupied states is the Fermi surface.\n2.  Periodic DFT calculations approximate the continuous Brillouin Zone (BZ) integral for properties like total energy by a discrete sum over a finite set of $ \\mathbf{k} $-points.\n3.  Forces on atoms are calculated as the derivative of the total energy with respect to atomic positions, $ \\mathbf{F}_I = - \\frac{dE_{tot}}{d\\mathbf{R}_I} $. For metals, the calculation of forces is complicated by the presence of the Fermi surface.\n4.  During a geometry optimization, small atomic displacements cause small changes in the effective potential, which in turn shift the electronic band energies $ \\epsilon_{n\\mathbf{k}} $.\n5.  If the $ \\mathbf{k} $-point mesh is too coarse, a band may cross the Fermi level, causing an abrupt change in the occupation number of that state (from $1$ to $0$ or vice versa). This leads to a discontinuity in the total energy surface and large fluctuations or 'noise' in the forces, which are its derivatives. This is the hallmark of an under-sampled Fermi surface.\n6.  This force noise can cause an optimization algorithm (like a quasi-Newton method) to overshoot, leading to oscillations in atomic positions and forces, hindering convergence.\n7.  To mitigate this, smearing techniques are employed. They replace the sharp step function for occupations at $E_F$ with a smooth function (e.g., a Fermi-Dirac distribution, $f(\\frac{\\epsilon - E_F}{\\sigma})$, where $ \\sigma $ is the smearing width). This makes the energy and forces continuous functions of atomic positions, even for a coarse $ \\mathbf{k} $-mesh. The calculated energy is a free energy corresponding to a finite electronic temperature $T_e$ (where $ \\sigma \\approx k_B T_e $).\n8.  A large $ \\sigma $ can stabilize forces but may introduce significant errors, as the system is relaxed at a high fictitious temperature. The optimized geometry and energy may differ significantly from the true $T=0\\ \\mathrm{K}$ result. The correct physical result is found in the dual limit of infinite $ \\mathbf{k} $-points ($N_k \\rightarrow \\infty$) and zero smearing ($ \\sigma \\rightarrow 0 $).\n\nThe observations in the problem statement are classic symptoms of this issue:\n-   Force oscillations that diminish with a denser $ \\mathbf{k} $-mesh ($3 \\times 3 \\times 1$ to $5 \\times 5 \\times 1$).\n-   Force oscillations that disappear with increased smearing ($\\sigma$ from $ 0.05\\ \\mathrm{eV} $ to $ 0.20\\ \\mathrm{eV} $).\n-   A significant change in relaxed geometry ($ 0.10\\ \\mathrm{\\AA} $ in height) with increased smearing, indicating a large smearing-induced error.\n-   An odd–even dependence on $ N_k $, a known artifact related to the inclusion/exclusion of high-symmetry points with special states near $ E_F $.\n\nNow we evaluate each statement.\n\n**A. Alternating sign and magnitude of the adsorbate normal force between ionic steps, correlating with small changes in electronic occupations near the Fermi level at coarse $\\mathbf{k}$-point sampling, is a signature of an under-sampled Fermi surface. Increasing the in-plane $\\mathbf{k}$-point density and employing moderate finite-temperature smearing $\\sigma \\approx 0.10\\text{–}0.20\\ \\mathrm{eV}$ during relaxation are appropriate remedies to reduce such force oscillations.**\nThis statement is a textbook definition of the problem and its standard solution. The alternating force sign is a direct consequence of abrupt occupation changes at a coarse $ \\mathbf{k} $-mesh as atomic positions are updated, which is the definition of an under-sampled Fermi surface. The proposed remedies—increasing the $ \\mathbf{k} $-point density to improve BZ integration and using a moderate smearing width to ensure force continuity—are precisely the correct first steps to address this issue. The range $ \\sigma \\approx 0.10\\text{–}0.20\\ \\mathrm{eV} $ is a typical choice for ensuring smooth convergence during relaxations, although one must be aware of the resulting artifacts in the final structure and energy.\n**Verdict: Correct.**\n\n**B. If the total energy varies smoothly with ionic steps but forces oscillate and this behavior disappears when the plane-wave cutoff is increased while being insensitive to $\\mathbf{k}$-mesh refinement and smearing changes, then the origin is an under-sampled Fermi surface; the remedy is to reduce the plane-wave cutoff to suppress basis-set Pulay forces.**\nThis statement is incorrect on multiple grounds. First, the scenario described (insensitivity to $ \\mathbf{k} $-mesh and smearing, sensitivity to plane-wave cutoff) points to basis-set incompleteness, not Fermi-surface sampling issues. These forces arising from an incomplete basis set are known as Pulay forces. Second, the diagnosis is wrong; it misidentifies the problem as Fermi-surface under-sampling. Third, the proposed remedy is counterproductive. To mitigate Pulay forces, one must *increase* the plane-wave cutoff energy until the basis set is converged, not reduce it.\n**Verdict: Incorrect.**\n\n**C. An odd–even dependence of the optimized adsorption height on the number of $\\mathbf{k}$-points along a direction intersecting the Fermi surface is consistent with poor Fermi surface integration; replacing finite-temperature smearing by the zero-temperature tetrahedron method with Blöchl corrections during relaxation is the recommended way to cure metallic force oscillations in slab relaxations.**\nThe first part of the statement is correct: the odd–even dependence is indeed a known artifact of poor BZ integration. However, the second part about the remedy is incorrect. While the tetrahedron method (with Blöchl corrections) is highly accurate for total energy calculations on a fixed geometry, it is generally ill-suited for geometry relaxations. The method provides a piecewise-linear interpolation of bands, and while the integrated energy is continuous, its derivatives (the forces) can be discontinuous and noisy when an energy level at a $ \\mathbf{k} $-point vertex crosses the Fermi level. Smearing methods are specifically designed to provide smooth, continuous forces and are therefore the standard choice for ionic relaxations in metals.\n**Verdict: Incorrect.**\n\n**D. A strong dependence of relaxed geometry on the smearing width $\\sigma$ at fixed coarse $\\mathbf{k}$-mesh that vanishes upon simultaneous increase of $N_k$ and decrease of $\\sigma$ while approximately maintaining $N_k \\sigma$ constant indicates Fermi-surface under-sampling. A sound protocol is to converge forces with respect to both $N_k$ and $\\sigma$, minimize the finite-temperature Mermin free energy at nonzero $\\sigma$ during relaxation, and then extrapolate $\\sigma \\rightarrow 0$ at fixed dense $\\mathbf{k}$-mesh for final energetics.**\nThis statement accurately describes both a diagnostic test and a robust, state-of-the-art computational protocol. The dependence of results on $ \\sigma $ for a coarse $ \\mathbf{k} $-mesh is a clear sign of sampling issues. A sound procedure involves using a sufficiently dense $ \\mathbf{k} $-mesh and a suitable smearing $ \\sigma $ to obtain a smoothly converged geometry by minimizing the corresponding free energy (e.g., Mermin free energy for Fermi-Dirac smearing). After the relaxation, for accurate final energetics, one must remove the smearing-induced error. This is typically done by performing a static calculation on the relaxed geometry with a very dense $ \\mathbf{k} $-mesh and extrapolating the energy to the $ \\sigma \\rightarrow 0 $ limit. This entire protocol ensures both efficient relaxation and accurate final results.\n**Verdict: Correct.**\n\n**E. Switching from a $\\Gamma$-centered $3 \\times 3 \\times 1$ mesh to a Monkhorst–Pack $4 \\times 4 \\times 1$ mesh for a $3 \\times 3$ surface cell and observing a $0.20\\ \\mathrm{eV}$ change in adsorption energy while surface stress remains nearly unchanged is most likely caused by Pulay stress; the correct remedy is to decrease the electronic mixing parameter without changing $\\mathbf{k}$-points.**\nThis statement is fundamentally flawed. A large change in energy ($ 0.20\\ \\mathrm{eV} $) upon changing the $ \\mathbf{k} $-mesh is a clear indicator of poor $ \\mathbf{k} $-point convergence, a manifestation of Fermi-surface under-sampling, not Pulay stress. Pulay stress is related to the plane-wave basis set cutoff, not the $ \\mathbf{k} $-point mesh. The proposed remedy, changing the electronic mixing parameter, is also incorrect. The mixing parameter affects the convergence rate of the self-consistent field (SCF) cycle, not the converged total energy. It is a numerical parameter for the algorithm, not a physical parameter to correct a sampling error.\n**Verdict: Incorrect.**\n\n**F. During adsorption, the largest force oscillations coincide with small rigid shifts of the Fermi surface relative to the discrete $\\mathbf{k}$-points as the potential changes with ionic steps. Using denser in-plane $\\mathbf{k}$-meshes that target approximately uniform absolute $\\Delta k$ spacing across different supercell sizes, and employing Marzari–Vanderbilt cold smearing at moderate $\\sigma$, are effective mitigations for metallic slabs.**\nThis statement provides a physically insightful description of the problem and recommends advanced, effective solutions. The characterization of force oscillations originating from the relative shift between the Fermi surface and the fixed $ \\mathbf{k} $-grid is precise. The recommendations constitute best practices. Maintaining a constant $ \\mathbf{k} $-point spacing $ \\Delta k $ ensures consistent accuracy when comparing calculations with different supercell sizes. Marzari–Vanderbilt cold smearing is a sophisticated method designed to minimize the error between the free energy at finite $ \\sigma $ and the true $T=0\\ \\mathrm{K}$ total energy, making it an excellent choice for accurate and stable relaxations in metals.\n**Verdict: Correct.**",
            "answer": "$$\\boxed{ADF}$$"
        }
    ]
}