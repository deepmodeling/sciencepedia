{
    "hands_on_practices": [
        {
            "introduction": "Linear free energy scaling relationships (LFERs) are a cornerstone of modern catalysis research, allowing us to predict the properties of many reaction intermediates from a single descriptor. This first exercise is a foundational practice in identifying and quantifying such a relationship from computed adsorption energies . You will learn to construct an LFER by correlating the Gibbs free energies of two structurally similar species, atomic oxygen ($O^*$) and hydroxyl ($OH^*$), and interpret the physical meaning of the resulting linear model.",
            "id": "3885848",
            "problem": "You are given the task of constructing a linear free energy scaling relationship between the Gibbs free energy of adsorption of hydroxyl on a surface, denoted by $G_{\\mathrm{ads}}(\\mathrm{OH}^*)$, and the Gibbs free energy of adsorption of atomic oxygen on the same surface, denoted by $G_{\\mathrm{ads}}(\\mathrm{O}^*)$, across a series of metal oxides. Starting from the definition of Gibbs free energy $G = H - TS$ and the thermodynamic definition of adsorption free energy $G_{\\mathrm{ads}}$, assume that the Gibbs free energy of adsorption can be approximated from electronic structure calculations as $G_{\\mathrm{ads}} \\approx E_{\\mathrm{ads}} + \\Delta \\mathrm{ZPE} - T \\Delta S$, where $E_{\\mathrm{ads}}$ is the electronic adsorption energy from density functional theory, $\\Delta \\mathrm{ZPE}$ is the zero-point energy correction, $T$ is the absolute temperature, and $\\Delta S$ is the entropy change upon adsorption. Derive, justify, and estimate a linear model of the form $G_{\\mathrm{ads}}(\\mathrm{OH}^*) = a \\, G_{\\mathrm{ads}}(\\mathrm{O}^*) + b$ by fitting $(a,b)$ to data from multiple surfaces, and explain in physical terms what the slope $a$ and intercept $b$ represent.\n\nYour program must implement the following steps:\n- Compute $G_{\\mathrm{ads}}(\\mathrm{O}^*)$ and $G_{\\mathrm{ads}}(\\mathrm{OH}^*)$ from provided $E_{\\mathrm{ads}}$ values using $G_{\\mathrm{ads}} = E_{\\mathrm{ads}} + \\Delta \\mathrm{ZPE} - T \\Delta S$.\n- Estimate $(a,b)$ by minimizing the sum of squared residuals between observed $G_{\\mathrm{ads}}(\\mathrm{OH}^*)$ and predicted $a \\, G_{\\mathrm{ads}}(\\mathrm{O}^*) + b$ across each dataset.\n- Report the fitted $a$, $b$, and the Root Mean Square Error (RMSE), where $\\mathrm{RMSE} = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N} \\left(G_{\\mathrm{ads}}^{(i)}(\\mathrm{OH}^*) - \\left(a \\, G_{\\mathrm{ads}}^{(i)}(\\mathrm{O}^*) + b\\right)\\right)^2}$, with $N$ the number of data points.\n\nUse electronvolts as the energy unit and kelvin for temperature. All output energies should be computed in $\\mathrm{eV}$ at $T = 298\\,\\mathrm{K}$. Your results must be expressed as floating-point numbers. The final output format must be a single line containing a comma-separated list enclosed in square brackets with the sequence $[a_1,b_1,\\mathrm{RMSE}_1,a_2,b_2,\\mathrm{RMSE}_2,a_3,b_3,\\mathrm{RMSE}_3]$ for the three test cases described below.\n\nTest Suite:\n- Common constants for all cases:\n  - Temperature: $T = 298\\,\\mathrm{K}$.\n  - Zero-point energy corrections: $\\Delta \\mathrm{ZPE}(\\mathrm{O}^*) = 0.05\\,\\mathrm{eV}$, $\\Delta \\mathrm{ZPE}(\\mathrm{OH}^*) = 0.35\\,\\mathrm{eV}$.\n  - Entropy changes (expressed so that $T \\Delta S$ is in $\\mathrm{eV}$ when multiplied by $T$ in $\\mathrm{K}$): $\\Delta S(\\mathrm{O}^*) = 1.0 \\times 10^{-4}\\,\\mathrm{eV}/\\mathrm{K}$ and $\\Delta S(\\mathrm{OH}^*) = 2.0 \\times 10^{-4}\\,\\mathrm{eV}/\\mathrm{K}$.\n\n- Case $1$ (general case with modest noise):\n  - Raw electronic adsorption energies for atomic oxygen: $E_{\\mathrm{ads}}^{(i)}(\\mathrm{O}^*) = [1.25, 1.60, 1.85, 2.10, 2.35, 2.55, 2.80, 3.05]\\,\\mathrm{eV}$.\n  - Raw electronic adsorption energies for hydroxyl: $E_{\\mathrm{ads}}^{(i)}(\\mathrm{OH}^*) = [1.455, 1.72, 2.015, 2.15, 2.425, 2.595, 2.79, 3.085]\\,\\mathrm{eV}$.\n\n- Case $2$ (boundary condition with exact linear scaling in free energies):\n  - Target exact parameters in Gibbs free energies: $a_{\\mathrm{target}} = 1.0$ and $b_{\\mathrm{target}} = 0.2\\,\\mathrm{eV}$.\n  - Choose oxygen adsorption energies: $E_{\\mathrm{ads}}^{(i)}(\\mathrm{O}^*) = [1.10, 1.80, 2.50]\\,\\mathrm{eV}$.\n  - Construct hydroxyl adsorption energies so that, after thermochemical corrections, the relation $G_{\\mathrm{ads}}(\\mathrm{OH}^*) = a_{\\mathrm{target}} \\, G_{\\mathrm{ads}}(\\mathrm{O}^*) + b_{\\mathrm{target}}$ holds exactly. This implies $E_{\\mathrm{ads}}^{(i)}(\\mathrm{OH}^*) = a_{\\mathrm{target}} \\, E_{\\mathrm{ads}}^{(i)}(\\mathrm{O}^*) + \\left(b_{\\mathrm{target}} + a_{\\mathrm{target}} \\left(\\Delta \\mathrm{ZPE}(\\mathrm{O}^*) - T \\Delta S(\\mathrm{O}^*)\\right) - \\left(\\Delta \\mathrm{ZPE}(\\mathrm{OH}^*) - T \\Delta S(\\mathrm{OH}^*)\\right)\\right)$.\n\n- Case $3$ (edge case with an outlier):\n  - Raw electronic adsorption energies for atomic oxygen: $E_{\\mathrm{ads}}^{(i)}(\\mathrm{O}^*) = [1.4, 1.9, 2.4, 2.9, 3.4, 2.2]\\,\\mathrm{eV}$.\n  - Raw electronic adsorption energies for hydroxyl: $E_{\\mathrm{ads}}^{(i)}(\\mathrm{OH}^*) = [1.56, 1.935, 2.40, 2.795, 3.24, 1.72]\\,\\mathrm{eV}$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[a_1,b_1,\\mathrm{RMSE}_1,a_2,b_2,\\mathrm{RMSE}_2,a_3,b_3,\\mathrm{RMSE}_3]$). All energies must be in $\\mathrm{eV}$ and the three $\\mathrm{RMSE}$ values must also be in $\\mathrm{eV}$.",
            "solution": "The objective is to justify and estimate a linear free energy scaling relationship between $G_{\\mathrm{ads}}(\\mathrm{OH}^*)$ and $G_{\\mathrm{ads}}(\\mathrm{O}^*)$ across a series of metal oxides. The derivation begins from thermodynamics. Gibbs free energy is defined as $G = H - TS$, where $H$ is the enthalpy, $T$ is the absolute temperature, and $S$ is the entropy. The adsorption free energy of a species on a surface can be expressed as the change in Gibbs free energy between the adsorbed and reference states. Under the harmonic and ideal-gas approximations used in density functional theory based thermochemistry, it is common to estimate adsorption free energies as $G_{\\mathrm{ads}} \\approx E_{\\mathrm{ads}} + \\Delta \\mathrm{ZPE} - T \\Delta S$, where $E_{\\mathrm{ads}}$ is the electronic energy difference, $\\Delta \\mathrm{ZPE}$ is the zero-point energy correction, and $\\Delta S$ is the entropy change upon adsorption. The pressure-volume term is negligible for condensed phases at ambient conditions, making $pV$ contributions small compared to electronic and vibrational terms in electronvolts.\n\nLinear free energy scaling relationships arise because different adsorbates that share similar bonding motifs to the surface often exhibit correlated changes in binding strengths across materials. For $\\mathrm{O}^*$ and $\\mathrm{OH}^*$, both species form a metal–oxygen bond, and variations in the metal–oxygen bond strength across oxides predominantly control both $G_{\\mathrm{ads}}(\\mathrm{O}^*)$ and $G_{\\mathrm{ads}}(\\mathrm{OH}^*)$. The addition of hydrogen to $\\mathrm{O}^*$ to form $\\mathrm{OH}^*$ contributes approximately a constant thermochemical offset across similar surfaces, due to similar vibrational spectra and entropy losses, together with an adsorbate–surface rehybridization that does not drastically vary when the coordination and local geometry are comparable. Therefore, a linear relationship $G_{\\mathrm{ads}}(\\mathrm{OH}^*) \\approx a \\, G_{\\mathrm{ads}}(\\mathrm{O}^*) + b$ can be justified: the slope $a$ captures how changes in the metal–oxygen bonding free energy propagate to the hydroxyl adsorption free energy, while the intercept $b$ captures the incremental free energy of hydrogenation (including zero-point energy and entropy changes specific to $\\mathrm{OH}^*$ relative to $\\mathrm{O}^*$), referenced to the computational reservoirs.\n\nTo estimate $(a,b)$ from data, define the list $\\{ G_{\\mathrm{ads}}^{(i)}(\\mathrm{O}^*) \\}_{i=1}^{N}$ and $\\{ G_{\\mathrm{ads}}^{(i)}(\\mathrm{OH}^*) \\}_{i=1}^{N}$ for a given dataset. The estimation problem is to minimize the sum of squared residuals:\n$$\n\\min_{a,b} \\sum_{i=1}^{N} \\left( G_{\\mathrm{ads}}^{(i)}(\\mathrm{OH}^*) - \\left(a \\, G_{\\mathrm{ads}}^{(i)}(\\mathrm{O}^*) + b\\right) \\right)^2.\n$$\nThis is Ordinary Least Squares (OLS). The unique minimizer yields\n$$\na = \\frac{\\sum_{i=1}^{N} \\left( x_i - \\bar{x} \\right)\\left( y_i - \\bar{y} \\right)}{\\sum_{i=1}^{N} \\left( x_i - \\bar{x} \\right)^2}, \\quad b = \\bar{y} - a \\bar{x},\n$$\nwhere $x_i = G_{\\mathrm{ads}}^{(i)}(\\mathrm{O}^*)$, $y_i = G_{\\mathrm{ads}}^{(i)}(\\mathrm{OH}^*)$, $\\bar{x} = \\frac{1}{N}\\sum_{i=1}^{N} x_i$, and $\\bar{y} = \\frac{1}{N}\\sum_{i=1}^{N} y_i$. The Root Mean Square Error (RMSE) quantifies the typical deviation:\n$$\n\\mathrm{RMSE} = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N} \\left( y_i - \\left(a x_i + b\\right)\\right)^2}.\n$$\n\nFor each test case, compute\n$$\nG_{\\mathrm{ads}}^{(i)}(\\mathrm{O}^*) = E_{\\mathrm{ads}}^{(i)}(\\mathrm{O}^*) + \\Delta \\mathrm{ZPE}(\\mathrm{O}^*) - T \\Delta S(\\mathrm{O}^*),\n$$\n$$\nG_{\\mathrm{ads}}^{(i)}(\\mathrm{OH}^*) = E_{\\mathrm{ads}}^{(i)}(\\mathrm{OH}^*) + \\Delta \\mathrm{ZPE}(\\mathrm{OH}^*) - T \\Delta S(\\mathrm{OH}^*).\n$$\nWith $T = 298\\,\\mathrm{K}$, $\\Delta \\mathrm{ZPE}(\\mathrm{O}^*) = 0.05\\,\\mathrm{eV}$, $\\Delta \\mathrm{ZPE}(\\mathrm{OH}^*) = 0.35\\,\\mathrm{eV}$, $\\Delta S(\\mathrm{O}^*) = 1.0 \\times 10^{-4}\\,\\mathrm{eV}/\\mathrm{K}$, $\\Delta S(\\mathrm{OH}^*) = 2.0 \\times 10^{-4}\\,\\mathrm{eV}/\\mathrm{K}$, the corrections become $\\Delta \\mathrm{ZPE}(\\mathrm{O}^*) - T \\Delta S(\\mathrm{O}^*) = 0.05\\,\\mathrm{eV} - 298\\,\\mathrm{K} \\times 1.0 \\times 10^{-4}\\,\\mathrm{eV}/\\mathrm{K} = 0.0202\\,\\mathrm{eV}$ and $\\Delta \\mathrm{ZPE}(\\mathrm{OH}^*) - T \\Delta S(\\mathrm{OH}^*) = 0.35\\,\\mathrm{eV} - 298\\,\\mathrm{K} \\times 2.0 \\times 10^{-4}\\,\\mathrm{eV}/\\mathrm{K} = 0.2904\\,\\mathrm{eV}$.\n\nCase $1$ uses eight points with modest noise relative to an underlying linear trend; the fit should yield a slope $a$ close to unity but may be slightly less than $1$ due to hydrogenation effects, and an intercept $b$ that captures the approximate incremental hydrogenation free energy. Case $2$ is constructed to satisfy the exact linear relationship in free energies with $a_{\\mathrm{target}} = 1.0$ and $b_{\\mathrm{target}} = 0.2\\,\\mathrm{eV}$; therefore, the fitted parameters should return values extremely close to these targets with $\\mathrm{RMSE}$ near $0$. Case $3$ introduces an outlier that perturbs the fit; the OLS estimate will reflect the influence of the outlier, typically changing both slope and intercept and increasing $\\mathrm{RMSE}$.\n\nPhysical interpretation:\n- The slope $a$ is dimensionless and measures how sensitivities in $G_{\\mathrm{ads}}(\\mathrm{O}^*)$ translate to $G_{\\mathrm{ads}}(\\mathrm{OH}^*)$ across materials. Because both $\\mathrm{O}^*$ and $\\mathrm{OH}^*$ share a metal–oxygen bond, $a$ is expected to be close to unity when the local bonding environment is similar; deviations of $a$ from $1$ reflect differences in rehybridization and bond-order redistribution upon hydrogenation.\n- The intercept $b$ has units of $\\mathrm{eV}$ and represents the baseline free energy offset associated with adding hydrogen to $\\mathrm{O}^*$ to form $\\mathrm{OH}^*$, including vibrational (zero-point energy) and entropic contributions and the chemical potential of hydrogen supplied by the chosen reference (for example, the Computational Hydrogen Electrode (CHE) framework). A positive $b$ indicates that, at fixed $G_{\\mathrm{ads}}(\\mathrm{O}^*)$, $\\mathrm{OH}^*$ is less strongly bound by approximately $b$ due to the thermochemistry of hydrogenation and vibrational stabilization.\n\nAlgorithmic design:\n- For each case, compute $G_{\\mathrm{ads}}(\\mathrm{O}^*)$ and $G_{\\mathrm{ads}}(\\mathrm{OH}^*)$ using the stated corrections.\n- Fit $(a,b)$ via OLS using the mean-centered covariance and variance formulas stated above, ensuring numerical stability by checking the variance of $G_{\\mathrm{ads}}(\\mathrm{O}^*)$ is nonzero.\n- Compute $\\mathrm{RMSE}$ as the square root of the mean squared residuals.\n- Aggregate the results for the three cases into a single list and print them in the specified format.\n\nAll reported energies and errors must be in $\\mathrm{eV}$ at $T = 298\\,\\mathrm{K}$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef fit_linear(x, y):\n    \"\"\"\n    Fit y ~ a*x + b via Ordinary Least Squares (OLS).\n    Returns (a, b, rmse).\n    \"\"\"\n    x = np.asarray(x, dtype=float)\n    y = np.asarray(y, dtype=float)\n    x_mean = np.mean(x)\n    y_mean = np.mean(y)\n    var_x = np.sum((x - x_mean) ** 2)\n    if var_x == 0.0:\n        # Degenerate case: all x are equal; cannot fit slope.\n        # Set slope to 0, intercept to mean(y), RMSE accordingly.\n        a = 0.0\n        b = y_mean\n        rmse = float(np.sqrt(np.mean((y - b) ** 2)))\n        return a, b, rmse\n    cov_xy = np.sum((x - x_mean) * (y - y_mean))\n    a = cov_xy / var_x\n    b = y_mean - a * x_mean\n    residuals = y - (a * x + b)\n    rmse = float(np.sqrt(np.mean(residuals ** 2)))\n    return float(a), float(b), rmse\n\ndef compute_g_ads(E_ads, zpe, T, S):\n    \"\"\"\n    Compute Gibbs free energy of adsorption:\n    G_ads = E_ads + zpe - T*S\n    Inputs:\n        E_ads: array-like of electronic adsorption energies (eV)\n        zpe: float, zero-point energy correction (eV)\n        T: float, temperature (K)\n        S: float, entropy change (eV/K)\n    Returns:\n        numpy array of G_ads in eV\n    \"\"\"\n    E_ads = np.asarray(E_ads, dtype=float)\n    return E_ads + zpe - T * S\n\ndef solve():\n    # Constants common to all cases\n    T = 298.0  # K\n    zpe_O = 0.05  # eV\n    zpe_OH = 0.35  # eV\n    S_O = 1.0e-4  # eV/K\n    S_OH = 2.0e-4  # eV/K\n\n    # Precompute corrections for clarity\n    corr_O = zpe_O - T * S_O      # should be 0.0202 eV\n    corr_OH = zpe_OH - T * S_OH   # should be 0.2904 eV\n\n    results = []\n\n    # Case 1: general case with modest noise\n    E_O_case1 = [1.25, 1.60, 1.85, 2.10, 2.35, 2.55, 2.80, 3.05]\n    E_OH_case1 = [1.455, 1.72, 2.015, 2.15, 2.425, 2.595, 2.79, 3.085]\n    G_O_case1 = compute_g_ads(E_O_case1, zpe_O, T, S_O)\n    G_OH_case1 = compute_g_ads(E_OH_case1, zpe_OH, T, S_OH)\n    a1, b1, rmse1 = fit_linear(G_O_case1, G_OH_case1)\n    results.extend([round(a1, 6), round(b1, 6), round(rmse1, 6)])\n\n    # Case 2: boundary condition with exact linear scaling in free energies\n    a_target = 1.0\n    b_target = 0.2  # eV\n    E_O_case2 = [1.10, 1.80, 2.50]\n    # Construct E_OH to enforce exact relation in G:\n    # G_OH = a_target * G_O + b_target\n    # = E_OH + corr_OH = a_target * (E_O + corr_O) + b_target\n    # = E_OH = a_target * E_O + (b_target + a_target * corr_O - corr_OH)\n    offset_case2 = (b_target + a_target * corr_O - corr_OH)\n    E_OH_case2 = [a_target * e + offset_case2 for e in E_O_case2]\n    G_O_case2 = compute_g_ads(E_O_case2, zpe_O, T, S_O)\n    G_OH_case2 = compute_g_ads(E_OH_case2, zpe_OH, T, S_OH)\n    a2, b2, rmse2 = fit_linear(G_O_case2, G_OH_case2)\n    results.extend([round(a2, 6), round(b2, 6), round(rmse2, 6)])\n\n    # Case 3: edge case with an outlier\n    E_O_case3 = [1.4, 1.9, 2.4, 2.9, 3.4, 2.2]\n    E_OH_case3 = [1.56, 1.935, 2.40, 2.795, 3.24, 1.72]  # includes an outlier at the last point\n    G_O_case3 = compute_g_ads(E_O_case3, zpe_O, T, S_O)\n    G_OH_case3 = compute_g_ads(E_OH_case3, zpe_OH, T, S_OH)\n    a3, b3, rmse3 = fit_linear(G_O_case3, G_OH_case3)\n    results.extend([round(a3, 6), round(b3, 6), round(rmse3, 6)])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "After establishing an empirical scaling law, the next logical step is to seek a more fundamental explanation rooted in the catalyst's intrinsic properties. This practice moves beyond correlating adsorbates with each other to modeling adsorption energy as a function of electronic structure descriptors . By building a multivariate linear model using the $d$-band center ($\\varepsilon_d$) and width ($W_d$) as descriptors, you will gain deeper physical insight and develop more powerful predictive tools for catalyst design.",
            "id": "3885786",
            "problem": "You are tasked with formulating and estimating an affine linear relationship between adsorption energies and electronic structure descriptors within the framework of linear free energy scaling relationships in computational catalysis and chemical engineering. Begin from a valid physical and mathematical base: chemisorption theory (e.g., the Newns–Anderson description) connects the adsorption energy to hybridization, filling of bonding and antibonding states, and the metal density of states near the Fermi level. In a regime where descriptor variations are small around a reference metal and site at fixed adsorbate coverage and surface geometry, first-order multivariate Taylor expansion and linear response imply that the change in adsorption energy can be approximated as an affine linear mapping of descriptor changes. Under these conditions, it is appropriate to model adsorption energy as an affine linear function of two descriptors: the $d$-band center relative to the Fermi level, denoted $\\varepsilon_d$ (in $\\mathrm{eV}$), and the $d$-band width, denoted $W_d$ (in $\\mathrm{eV}$). The coefficients represent sensitivities, and the intercept represents the baseline adsorption energy.\n\nYour program must estimate the coefficient vector $\\mathbf{m}$ and the intercept $b$ using ordinary least squares formulated as a minimization of the sum of squared residuals, solved stably via Singular Value Decomposition (SVD). To mitigate numerical instability in the presence of collinearity or rank deficiency, use the Moore–Penrose pseudoinverse with an SVD tolerance threshold $r_\\mathrm{tol}$ based on the largest singular value, such that singular values $\\sigma$ smaller than $r_\\mathrm{tol} \\times \\sigma_{\\max}$ are treated as zero. The design matrix must include a column of ones to estimate $b$ jointly with the descriptor sensitivities.\n\nScientific realism constraints:\n- Treat all adsorption energies as exothermic values in $\\mathrm{eV}$, and all descriptor values in $\\mathrm{eV}$.\n- Assume a constant adsorbate coverage and a single site type across each dataset.\n- Interpret the sign and magnitude of each coefficient by connecting it to the sensitivity of adsorption energy to the corresponding descriptor, consistent with linear response.\n\nImplement the following three test datasets, each representing a different facet of model behavior. For each dataset, you are given a set of descriptor pairs $(\\varepsilon_d, W_d)$ and measured adsorption energies $E_\\mathrm{ads}$ in $\\mathrm{eV}$:\n\nDataset A (general case with variability in both descriptors):\n- $\\varepsilon_d$ sequence: $[-2.1, -1.8, -1.2, -0.9, -2.5, -1.5, -0.7, -1.0]$ $\\mathrm{eV}$.\n- $W_d$ sequence: $[2.6, 2.3, 1.8, 1.7, 2.9, 2.0, 1.6, 1.7]$ $\\mathrm{eV}$.\n- $E_\\mathrm{ads}$ sequence: $[-1.845, -1.755, -1.35, -1.27, -2.09, -1.545, -1.145, -1.245]$ $\\mathrm{eV}$.\n\nDataset B (boundary case with zero variance in one descriptor):\n- $\\varepsilon_d$ sequence: $[-2.4, -2.0, -1.6, -1.2, -0.8]$ $\\mathrm{eV}$.\n- $W_d$ sequence: $[2.0, 2.0, 2.0, 2.0, 2.0]$ $\\mathrm{eV}$.\n- $E_\\mathrm{ads}$ sequence: $[-1.84, -1.68, -1.59, -1.41, -1.30]$ $\\mathrm{eV}$.\n\nDataset C (edge case with exact linear dependence between descriptors):\n- $\\varepsilon_d$ sequence: $[-2.0, -1.0, 0.0, 1.0]$ $\\mathrm{eV}$.\n- $W_d$ sequence: $[2.2, 2.7, 3.2, 3.7]$ $\\mathrm{eV}$.\n- $E_\\mathrm{ads}$ sequence: $[-1.75, -1.525, -1.30, -1.075]$ $\\mathrm{eV}$.\n\nUsing these datasets:\n- Construct the augmented design matrix with columns $[\\varepsilon_d, W_d, 1]$ for each dataset.\n- Solve for $\\mathbf{c} = [m_{\\varepsilon_d}, m_{W_d}, b]^\\top$ that minimizes the squared residual norm using SVD with a relative tolerance $r_\\mathrm{tol} = 10^{-12}$ applied to singular values, resulting in the Moore–Penrose pseudoinverse solution. Compute the fitted adsorption energies and the coefficient of determination $R^2 = 1 - \\frac{\\sum_i (E_{\\mathrm{ads},i} - \\hat{E}_{\\mathrm{ads},i})^2}{\\sum_i (E_{\\mathrm{ads},i} - \\bar{E}_\\mathrm{ads})^2}$ expressed as a decimal number.\n- Interpret the physical meaning of $m_{\\varepsilon_d}$ and $m_{W_d}$ as sensitivities (in units of $\\mathrm{eV}/\\mathrm{eV}$) and $b$ as the baseline energy (in $\\mathrm{eV}$). No textual interpretation needs to be printed by the program, but your solution must explain this interpretation.\n\nRequired output:\n- For each dataset in the order A, B, C, produce the list $[b, m_{\\varepsilon_d}, m_{W_d}, R^2]$.\n- Your program should produce a single line of output containing the results as a comma-separated list of these three lists, enclosed in square brackets, with no spaces. For example, the outer list should look like $[[b_A, m_{\\varepsilon_d,A}, m_{W_d,A}, R^2_A],[b_B, m_{\\varepsilon_d,B}, m_{W_d,B}, R^2_B],[b_C, m_{\\varepsilon_d,C}, m_{W_d,C}, R^2_C]]$ where each quantity is a float. All energies must be in $\\mathrm{eV}$ and all sensitivities must be in $\\mathrm{eV}/\\mathrm{eV}$.",
            "solution": "The objective is to estimate an affine linear mapping between adsorption energy and two electronic descriptors under the regime of linear response. The underlying physical base is chemisorption theory, in which the adsorption energy is determined by the interaction between adsorbate frontier orbitals and metal states near the Fermi level. The Newns–Anderson framework decomposes the adsorption energy into contributions from hybridization (bond formation) and occupation of antibonding states, both of which depend on features of the metal $d$-band such as the $d$-band center $\\varepsilon_d$ and the $d$-band width $W_d$. When descriptor changes are sufficiently small around a reference state and all other conditions are held fixed (coverage, site type, geometry), linear response theory and first-order multivariate Taylor expansion imply that the variation in adsorption energy can be described by an affine linear function of the descriptors. In this representation, the coefficients are the first-order sensitivities: $m_{\\varepsilon_d}$ represents the change in adsorption energy per unit change in $\\varepsilon_d$, and $m_{W_d}$ represents the change per unit change in $W_d$. The intercept $b$ represents the baseline adsorption energy when descriptors take the reference values.\n\nAlgorithmic formulation:\n- Given $N$ data points $\\{(\\varepsilon_{d,i}, W_{d,i}, E_{\\mathrm{ads},i})\\}_{i=1}^N$, assemble the augmented design matrix $X \\in \\mathbb{R}^{N \\times 3}$ with columns $[\\varepsilon_d, W_d, 1]$, and the response vector $\\mathbf{y} \\in \\mathbb{R}^N$ containing $E_{\\mathrm{ads}}$.\n- Estimate the coefficient vector $\\mathbf{c} = [m_{\\varepsilon_d}, m_{W_d}, b]^\\top$ by minimizing the sum of squared residuals $\\|\\mathbf{y} - X \\mathbf{c}\\|_2^2$. To obtain a numerically stable solution in the presence of collinearity or rank deficiency, compute the Singular Value Decomposition (SVD) $X = U \\Sigma V^\\top$, where $\\Sigma$ is diagonal with singular values $\\{\\sigma_j\\}$. Form the Moore–Penrose pseudoinverse $X^+ = V \\Sigma^+ U^\\top$, where $\\Sigma^+$ contains reciprocals of singular values larger than the threshold $r_\\mathrm{tol} \\times \\sigma_{\\max}$ and zeros otherwise. The solution is $\\mathbf{c} = X^+ \\mathbf{y}$.\n- Compute predictions $\\hat{\\mathbf{y}} = X \\mathbf{c}$ and the coefficient of determination $R^2 = 1 - \\frac{\\sum_i (y_i - \\hat{y}_i)^2}{\\sum_i (y_i - \\bar{y})^2}$, where $\\bar{y}$ is the mean of $y_i$. The $R^2$ measures how much variance in the response is explained by the model and is expressed as a decimal number.\n\nPhysical interpretation:\n- The coefficient $m_{\\varepsilon_d}$ (in $\\mathrm{eV}/\\mathrm{eV}$) quantifies how sensitive the adsorption energy is to shifts in the $d$-band center. In many chemisorption scenarios, increasing $\\varepsilon_d$ (moving the $d$-band center closer to the Fermi level) strengthens hybridization and can make adsorption more exothermic; this is reflected by the sign of $m_{\\varepsilon_d}$.\n- The coefficient $m_{W_d}$ (in $\\mathrm{eV}/\\mathrm{eV}$) captures sensitivity to changes in $d$-band width. A broader $d$-band modifies the density of available states and hybridization strength; the sign indicates whether widening the band strengthens or weakens adsorption in the studied regime.\n- The intercept $b$ (in $\\mathrm{eV}$) represents the baseline adsorption energy for the reference configuration at zeroed descriptors in the chosen coordinate representation.\n\nTest suite coverage:\n- Dataset A exercises the general case with variability in both descriptors, yielding a well-conditioned design matrix and a high $R^2$ if the linear model is appropriate.\n- Dataset B tests the boundary case where one descriptor ($W_d$) is constant; the regression can still uniquely estimate the intercept and the sensitivity to $\\varepsilon_d$, while the sensitivity to $W_d$ is inferred from the constant column and correlations captured by the intercept.\n- Dataset C constructs an edge case with exact linear dependence $W_d = a + c \\, \\varepsilon_d$; the design matrix is rank deficient. The SVD-based pseudoinverse returns the minimum-norm solution that best fits the data. The $R^2$ remains meaningful as long as the response varies.\n\nImplementation details:\n- Use $r_\\mathrm{tol} = 10^{-12}$ to determine which singular values to invert.\n- Assemble the outputs for each dataset as $[b, m_{\\varepsilon_d}, m_{W_d}, R^2]$.\n- Produce a single line containing a comma-separated outer list of the three inner lists, enclosed in square brackets, with no spaces, and ensure all energies are in $\\mathrm{eV}$ and sensitivities in $\\mathrm{eV}/\\mathrm{eV}$.\n\nThis procedure estimates the coefficients from first principles of linear response and stable numerical linear algebra and provides interpretable physical sensitivities consistent with linear free energy scaling relationships.",
            "answer": "```python\nimport numpy as np\n\ndef svd_pseudoinverse(X, rtol=1e-12):\n    \"\"\"\n    Compute the Moore-Penrose pseudoinverse of X using SVD with relative tolerance.\n    Singular values smaller than rtol * max_sigma are set to zero (not inverted).\n    \"\"\"\n    U, s, VT = np.linalg.svd(X, full_matrices=False)\n    max_sigma = s[0] if s.size  0 else 0.0\n    # Invert singular values with thresholding\n    s_inv = np.array([1/si if si = rtol * max_sigma and si  0 else 0.0 for si in s])\n    # Construct pseudoinverse\n    X_plus = (VT.T * s_inv) @ U.T\n    return X_plus\n\ndef fit_affine_linear(eps_d, W_d, E_ads, rtol=1e-12):\n    \"\"\"\n    Fit E_ads ~ m_eps * eps_d + m_W * W_d + b using SVD-based pseudoinverse.\n    Returns (b, m_eps, m_W, R2).\n    \"\"\"\n    eps_d = np.asarray(eps_d, dtype=float)\n    W_d = np.asarray(W_d, dtype=float)\n    y = np.asarray(E_ads, dtype=float)\n\n    # Design matrix with columns [eps_d, W_d, 1] to include intercept\n    X = np.column_stack([eps_d, W_d, np.ones_like(eps_d)])\n\n    # Solve via pseudoinverse\n    X_plus = svd_pseudoinverse(X, rtol=rtol)\n    coeffs = X_plus @ y  # [m_eps, m_W, b]\n    m_eps, m_W, b = coeffs[0], coeffs[1], coeffs[2]\n\n    # Predictions and R2\n    y_pred = X @ coeffs\n    y_mean = np.mean(y)\n    ss_res = float(np.sum((y - y_pred) ** 2))\n    ss_tot = float(np.sum((y - y_mean) ** 2))\n    R2 = 1.0 - ss_res / ss_tot if ss_tot  0 else float('nan')\n\n    return b, m_eps, m_W, R2\n\ndef format_results_no_spaces(results):\n    \"\"\"\n    Format a list of lists of floats as a single string with no spaces.\n    Each inner list is formatted with values as plain floats (Python default),\n    separated by commas and enclosed in square brackets. The outer list\n    concatenates the inner lists similarly, with no spaces anywhere.\n    \"\"\"\n    def fmt_inner(inner):\n        return \"[\" + \",\".join(f\"{x:.12g}\" if isinstance(x, float) else str(x) for x in inner) + \"]\"\n    return \"[\" + \",\".join(fmt_inner(inner) for inner in results) + \"]\"\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Dataset A\n    eps_A = [-2.1, -1.8, -1.2, -0.9, -2.5, -1.5, -0.7, -1.0]\n    W_A   = [ 2.6,  2.3,  1.8,  1.7,  2.9,  2.0,  1.6,  1.7]\n    E_A   = [-1.845, -1.755, -1.35, -1.27, -2.09, -1.545, -1.145, -1.245]\n\n    # Dataset B\n    eps_B = [-2.4, -2.0, -1.6, -1.2, -0.8]\n    W_B   = [ 2.0,  2.0,  2.0,  2.0,  2.0]\n    E_B   = [-1.84, -1.68, -1.59, -1.41, -1.30]\n\n    # Dataset C (Wd linearly dependent on eps_d)\n    eps_C = [-2.0, -1.0, 0.0, 1.0]\n    W_C   = [ 2.2,  2.7, 3.2, 3.7]\n    E_C   = [-1.75, -1.525, -1.30, -1.075]\n\n    test_cases = [\n        (eps_A, W_A, E_A),\n        (eps_B, W_B, E_B),\n        (eps_C, W_C, E_C),\n    ]\n\n    results = []\n    for eps_d, W_d, E_ads in test_cases:\n        b, m_eps, m_W, R2 = fit_affine_linear(eps_d, W_d, E_ads, rtol=1e-12)\n        results.append([b, m_eps, m_W, R2])\n\n    # Final print statement in the exact required format: no spaces.\n    print(format_results_no_spaces(results))\n\nsolve()\n```"
        },
        {
            "introduction": "Computational and experimental data are inherently imperfect and carry associated uncertainties. This final practice introduces the critical skill of building statistically robust models that properly account for this heterogeneous data quality . By implementing Weighted Least Squares (WLS), you will learn to weight data points according to their known variance, ensuring that more precise data has a greater influence on the resulting fit and leading to more reliable model parameters and predictions.",
            "id": "3885858",
            "problem": "Consider the task of fitting a Linear Free Energy Relationship (LFER) between a descriptor energy and a target free energy in computational catalysis, where Density Functional Theory (DFT) predictions carry heterogeneous and known uncertainties across data points. Assume a linear model $y_i = \\alpha + \\beta x_i + \\varepsilon_i$ with independent Gaussian errors $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma_i^2)$ and known standard deviations $\\sigma_i$ from DFT uncertainty quantification. The goal is to estimate the slope $\\beta$ (dimensionless) and intercept $\\alpha$ (in electron volts (eV)) using Weighted Least Squares (WLS), and to quantify the effect of weights on parameter estimates and prediction uncertainty. Adopt the following as the fundamental base: the Gaussian likelihood for independent observations, the Gauss–Markov theorem for linear estimators, and the well-tested formula for the WLS estimator derived from minimizing the weighted sum of squared residuals.\n\nYour program must implement the following protocol:\n- Use weights $w_i = 1/\\sigma_i^2$.\n- Construct the design matrix $X$ with rows $[1, x_i]$ and the diagonal weight matrix $W = \\mathrm{diag}(w_i)$.\n- Compute the WLS estimator $\\hat{\\boldsymbol{\\theta}} = [\\hat{\\alpha}, \\hat{\\beta}]^\\top$ by solving $$(X^\\top W X)\\hat{\\boldsymbol{\\theta}} = X^\\top W \\mathbf{y},$$ where $\\mathbf{y}$ is the vector of $y_i$.\n- Compute the parameter covariance matrix $$\\mathrm{Cov}(\\hat{\\boldsymbol{\\theta}}) = (X^\\top W X)^{-1},$$ which is valid under the assumption $w_i=1/\\sigma_i^2$ and independent Gaussian errors with variance $\\sigma_i^2$.\n- Extract the standard errors $\\mathrm{SE}(\\hat{\\alpha})$ and $\\mathrm{SE}(\\hat{\\beta})$ as the square roots of the diagonal of $\\mathrm{Cov}(\\hat{\\boldsymbol{\\theta}})$.\n- For a specified descriptor $x_0$, compute the predicted free energy $\\hat{y}_0 = \\hat{\\alpha} + \\hat{\\beta} x_0$ and its standard error $$\\mathrm{SE}(\\hat{y}_0) = \\sqrt{[1, x_0]\\ \\mathrm{Cov}(\\hat{\\boldsymbol{\\theta}})\\ [1, x_0]^\\top},$$ which captures the uncertainty from parameter estimation only. Report $\\hat{y}_0$ in electron volts (eV) and its standard error in electron volts (eV).\n\nAll energies must be treated in electron volts (eV). Report $\\hat{\\alpha}$ and $\\hat{y}_0$ in eV; $\\hat{\\beta}$ is dimensionless; $\\mathrm{SE}(\\hat{\\alpha})$ and $\\mathrm{SE}(\\hat{y}_0)$ in eV; $\\mathrm{SE}(\\hat{\\beta})$ is dimensionless. The answer values are floats.\n\nImplement the above for the following test suite. Each case provides arrays of descriptor energies $\\{x_i\\}$ (in eV), target free energies $\\{y_i\\}$ (in eV), and DFT uncertainty standard deviations $\\{\\sigma_i\\}$ (in eV). Use the same prediction point $x_0 = 0.60$ eV for all cases.\n\nTest Suite:\n- Case A (inverse-variance weights from DFT uncertainties; heterogeneous noise): \n  - $x = [-0.20, 0.00, 0.25, 0.50, 0.80, 1.10]$\n  - $y = [0.2 + 0.8(-0.20) + 0.01,\\ 0.2 + 0.8(0.00) - 0.02,\\ 0.2 + 0.8(0.25) + 0.03,\\ 0.2 + 0.8(0.50) - 0.04,\\ 0.2 + 0.8(0.80) + 0.02,\\ 0.2 + 0.8(1.10) - 0.06]$\n  - $\\sigma = [0.05, 0.05, 0.08, 0.10, 0.04, 0.12]$\n- Case B (equal uncertainties; reduces to Ordinary Least Squares (OLS) under WLS weighting):\n  - $x$ and $y$ as in Case A\n  - $\\sigma = [0.06, 0.06, 0.06, 0.06, 0.06, 0.06]$\n- Case C (one high-uncertainty outlier; inverse-variance weights downweight its influence):\n  - $x = [-0.20, 0.00, 0.25, 0.50, 0.80, 1.10, 1.50]$\n  - $y$ equals Case A values for the first six points and $y_7 = 0.2 + 0.8(1.50) + 0.50$\n  - $\\sigma = [0.05, 0.05, 0.08, 0.10, 0.04, 0.12, 0.50]$\n- Case D (one extremely precise point dominates; illustrates leverage under extreme weight):\n  - $x$ and $y$ as in Case A\n  - $\\sigma = [0.10, 0.10, 0.10, 0.10, 0.001, 0.10]$\n\nFor each case, compute and return the list $[\\hat{\\beta}, \\hat{\\alpha}, \\mathrm{SE}(\\hat{\\beta}), \\mathrm{SE}(\\hat{\\alpha}), \\hat{y}_0, \\mathrm{SE}(\\hat{y}_0)]$. Your program should produce a single line of output containing the results as a comma-separated list of these case-wise lists, with no spaces, enclosed in square brackets, for example: \n\"[[b1,a1,se_b1,se_a1,y1,se_y1],[b2,a2,se_b2,se_a2,y2,se_y2],[b3,a3,se_b3,se_a3,y3,se_y3],[b4,a4,se_b4,se_a4,y4,se_y4]]\".",
            "solution": "The problem requires the implementation of a Weighted Least Squares (WLS) regression to fit a linear model to data with known, heterogeneous uncertainties. This is a standard and fundamental technique in the analysis of experimental and computational data across STEM fields, particularly in physics, chemistry, and engineering, where measurement or calculation uncertainties are often quantifiable. The problem is scientifically valid, well-posed, and provides all necessary information for a deterministic solution.\n\nThe core of the problem lies in estimating the parameters of the linear model $y_i = \\alpha + \\beta x_i + \\varepsilon_i$, where the errors $\\boldsymbol{\\varepsilon}_i$ are independent and normally distributed, $\\boldsymbol{\\varepsilon}_i \\sim \\mathcal{N}(0, \\sigma_i^2)$, with known standard deviations $\\sigma_i$.\n\nIn matrix form, the model for a set of $n$ data points is written as:\n$$\n\\mathbf{y} = X\\boldsymbol{\\theta} + \\boldsymbol{\\varepsilon}\n$$\nwhere $\\mathbf{y} = [y_1, y_2, \\dots, y_n]^\\top$ is the vector of target free energies, $X$ is the $n \\times 2$ design matrix, $\\boldsymbol{\\theta} = [\\alpha, \\beta]^\\top$ is the vector of parameters to be estimated, and $\\boldsymbol{\\varepsilon} = [\\varepsilon_1, \\varepsilon_2, \\dots, \\varepsilon_n]^\\top$ is the vector of errors. The $i$-th row of the design matrix $X$ is $[1, x_i]$, corresponding to the intercept $\\alpha$ and the slope $\\beta$.\n\nThe errors are heteroscedastic, meaning they have non-uniform variance. The covariance matrix of the error vector $\\boldsymbol{\\varepsilon}$ is a diagonal matrix $\\Sigma = \\mathrm{diag}(\\sigma_1^2, \\sigma_2^2, \\dots, \\sigma_n^2)$. The WLS method addresses this by minimizing the weighted sum of squared residuals, where each residual is weighted by the inverse of its variance. The objective function to minimize is:\n$$\nS(\\boldsymbol{\\theta}) = \\sum_{i=1}^{n} w_i(y_i - (\\alpha + \\beta x_i))^2 = (\\mathbf{y} - X\\boldsymbol{\\theta})^\\top W (\\mathbf{y} - X\\boldsymbol{\\theta})\n$$\nThe optimal weights are the inverse variances, $w_i = 1/\\sigma_i^2$. The weight matrix $W$ is the inverse of the error covariance matrix, $W = \\Sigma^{-1} = \\mathrm{diag}(1/\\sigma_1^2, 1/\\sigma_2^2, \\dots, 1/\\sigma_n^2)$.\n\nTo find the parameter vector $\\hat{\\boldsymbol{\\theta}}$ that minimizes $S(\\boldsymbol{\\theta})$, we take the derivative of $S(\\boldsymbol{\\theta})$ with respect to $\\boldsymbol{\\theta}$ and set it to zero. This yields the WLS normal equations:\n$$\n(X^\\top W X) \\hat{\\boldsymbol{\\theta}} = X^\\top W \\mathbf{y}\n$$\nThis is a linear system of equations for the estimator $\\hat{\\boldsymbol{\\theta}} = [\\hat{\\alpha}, \\hat{\\beta}]^\\top$. The solution is given by:\n$$\n\\hat{\\boldsymbol{\\theta}} = (X^\\top W X)^{-1} X^\\top W \\mathbf{y}\n$$\n\nThe covariance matrix of the estimator $\\hat{\\boldsymbol{\\theta}}$ is a key quantity for assessing the uncertainty in the estimated parameters. Under the specified model assumptions where the weights are the true inverse variances, the covariance matrix is given by:\n$$\n\\mathrm{Cov}(\\hat{\\boldsymbol{\\theta}}) = (X^\\top W X)^{-1}\n$$\nThe diagonal elements of this $2 \\times 2$ matrix are the variances of the estimators for the intercept and slope: $\\mathrm{Var}(\\hat{\\alpha}) = \\mathrm{Cov}(\\hat{\\boldsymbol{\\theta}})_{11}$ and $\\mathrm{Var}(\\hat{\\beta}) = \\mathrm{Cov}(\\hat{\\boldsymbol{\\theta}})_{22}$. The standard errors are the square roots of these variances:\n$$\n\\mathrm{SE}(\\hat{\\alpha}) = \\sqrt{\\mathrm{Cov}(\\hat{\\boldsymbol{\\theta}})_{11}} \\quad \\text{and} \\quad \\mathrm{SE}(\\hat{\\beta}) = \\sqrt{\\mathrm{Cov}(\\hat{\\boldsymbol{\\theta}})_{22}}\n$$\nNote the indexing convention depends on the column order in $X$; here, the first column corresponds to $\\alpha$ and the second to $\\beta$.\n\nFinally, we need to make a prediction for a new descriptor value $x_0$ and quantify its uncertainty. The predicted value $\\hat{y}_0$ is:\n$$\n\\hat{y}_0 = \\hat{\\alpha} + \\hat{\\beta} x_0 = \\mathbf{x}_0^\\top \\hat{\\boldsymbol{\\theta}}\n$$\nwhere $\\mathbf{x}_0 = [1, x_0]^\\top$. The uncertainty in this prediction arises from the uncertainty in the estimated parameters $\\hat{\\boldsymbol{\\theta}}$. The variance of the prediction is calculated using the law of propagation of uncertainty for linear transformations:\n$$\n\\mathrm{Var}(\\hat{y}_0) = \\mathrm{Var}(\\mathbf{x}_0^\\top \\hat{\\boldsymbol{\\theta}}) = \\mathbf{x}_0^\\top \\mathrm{Cov}(\\hat{\\boldsymbol{\\theta}}) \\mathbf{x}_0\n$$\nThe standard error of the prediction is the square root of this variance:\n$$\n\\mathrm{SE}(\\hat{y}_0) = \\sqrt{\\mathbf{x}_0^\\top \\mathrm{Cov}(\\hat{\\boldsymbol{\\theta}}) \\mathbf{x}_0}\n$$\n\nThe implementation will proceed by first defining the data for each test case. Then, for each case, we will:\n1.  Construct the design matrix $X$ and the vectors $\\mathbf{y}$ and $\\boldsymbol{\\sigma}$.\n2.  Calculate the weights $w_i = 1/\\sigma_i^2$.\n3.  Form the matrices $A = X^\\top W X$ and the vector $\\mathbf{b} = X^\\top W \\mathbf{y}$. For computational efficiency, this is performed using array broadcasting rather than explicitly constructing the large diagonal matrix $W$.\n4.  Solve the linear system $A\\hat{\\boldsymbol{\\theta}} = \\mathbf{b}$ to obtain $\\hat{\\boldsymbol{\\theta}} = [\\hat{\\alpha}, \\hat{\\beta}]^\\top$.\n5.  Compute the covariance matrix $\\mathrm{Cov}(\\hat{\\boldsymbol{\\theta}}) = A^{-1}$.\n6.  Extract the parameter estimates and their standard errors from $\\hat{\\boldsymbol{\\theta}}$ and the diagonal of $\\mathrm{Cov}(\\hat{\\boldsymbol{\\theta}})$.\n7.  Calculate the predicted value $\\hat{y}_0$ and its standard error $\\mathrm{SE}(\\hat{y}_0)$ for $x_0 = 0.60$ eV.\n8.  Assemble the six required values in the specified order: $[\\hat{\\beta}, \\hat{\\alpha}, \\mathrm{SE}(\\hat{\\beta}), \\mathrm{SE}(\\hat{\\alpha}), \\hat{y}_0, \\mathrm{SE}(\\hat{y}_0)]$.\nThe results from all cases will be collected and formatted into a single output string.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Weighted Least Squares problem for the given test cases.\n    \"\"\"\n\n    def calculate_wls(x: np.ndarray, y: np.ndarray, sigma: np.ndarray, x0: float) - list[float]:\n        \"\"\"\n        Performs Weighted Least Squares (WLS) regression.\n\n        Args:\n            x: 1D array of descriptor energies.\n            y: 1D array of target free energies.\n            sigma: 1D array of DFT uncertainty standard deviations.\n            x0: The descriptor value for which to make a prediction.\n\n        Returns:\n            A list containing [beta_hat, alpha_hat, se_beta, se_alpha, y0_hat, se_y0].\n        \"\"\"\n        # Ensure inputs are numpy arrays\n        x = np.array(x, dtype=float)\n        y = np.array(y, dtype=float)\n        sigma = np.array(sigma, dtype=float)\n\n        # 1. Construct the design matrix X\n        n = len(x)\n        # First column is for the intercept (alpha), second is for the slope (beta)\n        X = np.vstack([np.ones(n), x]).T\n\n        # 2. Calculate weights w_i = 1/sigma_i^2\n        w = 1.0 / (sigma**2)\n\n        # 3. Compute X^T W X and X^T W y efficiently\n        # X.T * w broadcasts the weights to the rows of X.T\n        # (X^T W) = X.T @ diag(w) which is equivalent to X.T * w\n        X_T_W = X.T * w\n        A = X_T_W @ X  # This is the matrix (X^T W X)\n        b = X_T_W @ y  # This is the vector (X^T W y)\n\n        # 4. Solve the normal equations (X^T W X) * theta_hat = (X^T W y)\n        # theta_hat will be [alpha_hat, beta_hat]\n        try:\n            theta_hat = np.linalg.solve(A, b)\n        except np.linalg.LinAlgError:\n            # Handle cases where the matrix is singular, returning NaNs\n            return [np.nan] * 6\n        \n        alpha_hat = theta_hat[0]\n        beta_hat = theta_hat[1]\n\n        # 5. Compute the parameter covariance matrix Cov(theta_hat) = (X^T W X)^-1\n        try:\n            cov_theta = np.linalg.inv(A)\n        except np.linalg.LinAlgError:\n            # Handle cases where the matrix is singular after passing the solve step\n            return [beta_hat, alpha_hat, np.nan, np.nan, np.nan, np.nan]\n\n\n        # 6. Extract standard errors for alpha and beta\n        # The square roots of the diagonal elements of the covariance matrix\n        se_alpha = np.sqrt(cov_theta[0, 0])\n        se_beta = np.sqrt(cov_theta[1, 1])\n\n        # 7. Predict y0_hat for a new point x0\n        x0_vec = np.array([1.0, x0])\n        y0_hat = x0_vec @ theta_hat\n\n        # 8. Compute the standard error of the prediction\n        # SE(y0_hat) = sqrt(x0_vec^T * Cov(theta_hat) * x0_vec)\n        se_y0 = np.sqrt(x0_vec.T @ cov_theta @ x0_vec)\n\n        # 9. Return results in the specified order\n        return [beta_hat, alpha_hat, se_beta, se_alpha, y0_hat, se_y0]\n\n    # Define the test cases from the problem statement.\n    x0_pred = 0.60\n\n    # Common x and y components\n    x_base = [-0.20, 0.00, 0.25, 0.50, 0.80, 1.10]\n    y_base = [\n        0.2 + 0.8 * (-0.20) + 0.01,\n        0.2 + 0.8 * (0.00) - 0.02,\n        0.2 + 0.8 * (0.25) + 0.03,\n        0.2 + 0.8 * (0.50) - 0.04,\n        0.2 + 0.8 * (0.80) + 0.02,\n        0.2 + 0.8 * (1.10) - 0.06\n    ]\n\n    test_cases = [\n        # Case A\n        {'x': x_base, 'y': y_base, 'sigma': [0.05, 0.05, 0.08, 0.10, 0.04, 0.12]},\n        # Case B\n        {'x': x_base, 'y': y_base, 'sigma': [0.06] * 6},\n        # Case C\n        {\n            'x': x_base + [1.50],\n            'y': y_base + [0.2 + 0.8 * 1.50 + 0.50],\n            'sigma': [0.05, 0.05, 0.08, 0.10, 0.04, 0.12, 0.50]\n        },\n        # Case D\n        {'x': x_base, 'y': y_base, 'sigma': [0.10, 0.10, 0.10, 0.10, 0.001, 0.10]}\n    ]\n\n    results = []\n    for case in test_cases:\n        res = calculate_wls(case['x'], case['y'], case['sigma'], x0_pred)\n        results.append(f\"[{','.join(f'{v:.10f}' for v in res)}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}