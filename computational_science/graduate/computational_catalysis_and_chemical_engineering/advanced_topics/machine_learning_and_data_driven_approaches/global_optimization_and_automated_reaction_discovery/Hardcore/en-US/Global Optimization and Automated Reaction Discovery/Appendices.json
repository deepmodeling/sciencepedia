{
    "hands_on_practices": [
        {
            "introduction": "Automated search algorithms locate stationary points on a potential energy surface, but do not inherently know their nature. This exercise provides practice in the essential follow-up step of analyzing the Hessian matrix to classify a point as a stable minimum or a transition state, which is determined by the local curvature. Mastering this analysis is the first step toward interpreting the output of any optimization workflow .",
            "id": "3881319",
            "problem": "In automated reaction discovery for heterogeneous catalysis, the potential energy surface is represented by a scalar field $U(\\mathbf{q})$ over nuclear coordinates $\\mathbf{q}$. For a stationary point $\\mathbf{q}^{\\ast}$ found by a global optimization search, local characterization is performed by analyzing the second-order term of the Taylor expansion, which is governed by the Hessian matrix. Consider an adsorbate reacting on a metal cluster surface where translations and rotations have been removed and the motion is expressed in mass-weighted orthogonal coordinates. Let the computed Hessian at the stationary point, obtained from Density Functional Theory (DFT) and used within a quasi-Newton trust-region step, be\n$$\nH \\;=\\;\n\\begin{pmatrix}\n-2.0 & -3.0 & 0.0 & 0.0 & 0.0 \\\\\n-3.0 & -2.0 & 0.0 & 0.0 & 0.0 \\\\\n0.0 & 0.0 & 4.0 & 1.0 & 0.0 \\\\\n0.0 & 0.0 & 1.0 & 3.0 & 0.0 \\\\\n0.0 & 0.0 & 0.0 & 0.0 & 2.0\n\\end{pmatrix},\n$$\nwith entries in electronvolt per square ångström, $\\mathrm{eV}\\,\\mathrm{\\AA}^{-2}$. Using the fundamental characterization of stationary points via the signature of the Hessian, determine the Morse index (the number of negative eigenvalues of $H$) and classify the stationary point as a local minimum, a first-order saddle, or a higher-order saddle.\n\nFor the final reported classification code, use the following mapping:\n- $0$ denotes a local minimum,\n- $1$ denotes a first-order saddle,\n- $2$ denotes a higher-order saddle (index strictly greater than one).\n\nProvide your answer as a row matrix containing two numbers in the order: Morse index and classification code. Express the final answer with no units. No rounding is required.",
            "solution": "The task is to characterize a stationary point on a potential energy surface by analyzing its Hessian matrix. In computational chemistry and physics, the nature of a stationary point $\\mathbf{q}^{\\ast}$ on a potential energy surface $U(\\mathbf{q})$ is determined by the signature of the Hessian matrix, $H$, which contains the second partial derivatives of the energy with respect to the coordinates, $H_{ij} = \\frac{\\partial^2 U}{\\partial q_i \\partial q_j}$, evaluated at $\\mathbf{q}^{\\ast}$. The eigenvalues of the Hessian matrix correspond to the curvatures of the potential energy surface along the normal-mode directions.\n\nThe characterization is as follows:\n- If all eigenvalues are positive, the stationary point is a local minimum, corresponding to a stable structure. The Morse index (the number of negative eigenvalues) is $0$.\n- If there is exactly one negative eigenvalue, the stationary point is a first-order saddle point, typically representing a transition state for a reaction. The Morse index is $1$.\n- If there is more than one negative eigenvalue, the stationary point is a higher-order saddle point. The Morse index is greater than $1$.\n\nThe given Hessian matrix is:\n$$\nH \\;=\\;\n\\begin{pmatrix}\n-2.0 & -3.0 & 0.0 & 0.0 & 0.0 \\\\\n-3.0 & -2.0 & 0.0 & 0.0 & 0.0 \\\\\n0.0 & 0.0 & 4.0 & 1.0 & 0.0 \\\\\n0.0 & 0.0 & 1.0 & 3.0 & 0.0 \\\\\n0.0 & 0.0 & 0.0 & 0.0 & 2.0\n\\end{pmatrix}\n$$\nTo determine the Morse index, we must find the eigenvalues of $H$. We observe that $H$ is a block-diagonal matrix, which simplifies the eigenvalue problem. The matrix can be written as:\n$$\nH = \\begin{pmatrix} H_1 & \\mathbf{0} & \\mathbf{0} \\\\ \\mathbf{0} & H_2 & \\mathbf{0} \\\\ \\mathbf{0} & \\mathbf{0} & H_3 \\end{pmatrix}\n$$\nwhere the blocks are:\n$$\nH_1 = \\begin{pmatrix} -2 & -3 \\\\ -3 & -2 \\end{pmatrix}, \\quad\nH_2 = \\begin{pmatrix} 4 & 1 \\\\ 1 & 3 \\end{pmatrix}, \\quad\nH_3 = \\begin{pmatrix} 2 \\end{pmatrix}\n$$\nThe eigenvalues of a block-diagonal matrix are the union of the eigenvalues of its constituent blocks.\n\nFirst, we find the eigenvalues of the submatrix $H_1$ by solving the characteristic equation $\\det(H_1 - \\lambda I) = 0$:\n$$\n\\det \\begin{pmatrix} -2 - \\lambda & -3 \\\\ -3 & -2 - \\lambda \\end{pmatrix} = 0\n$$\n$$\n(-2 - \\lambda)^2 - (-3)^2 = 0\n$$\n$$\n(\\lambda + 2)^2 - 9 = 0\n$$\n$$\n\\lambda + 2 = \\pm \\sqrt{9} = \\pm 3\n$$\nThis yields two eigenvalues for $H_1$:\n$\\lambda_1 = 3 - 2 = 1$\n$\\lambda_2 = -3 - 2 = -5$\n\nNext, we find the eigenvalues of the submatrix $H_2$:\n$$\n\\det(H_2 - \\lambda I) = \\det \\begin{pmatrix} 4 - \\lambda & 1 \\\\ 1 & 3 - \\lambda \\end{pmatrix} = 0\n$$\n$$\n(4 - \\lambda)(3 - \\lambda) - (1)(1) = 0\n$$\n$$\n\\lambda^2 - 7\\lambda + 12 - 1 = 0\n$$\n$$\n\\lambda^2 - 7\\lambda + 11 = 0\n$$\nUsing the quadratic formula, $\\lambda = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$:\n$$\n\\lambda = \\frac{7 \\pm \\sqrt{(-7)^2 - 4(1)(11)}}{2 \\cdot 1} = \\frac{7 \\pm \\sqrt{49 - 44}}{2} = \\frac{7 \\pm \\sqrt{5}}{2}\n$$\nThis yields two eigenvalues for $H_2$:\n$\\lambda_3 = \\frac{7 + \\sqrt{5}}{2}$\n$\\lambda_4 = \\frac{7 - \\sqrt{5}}{2}$\nSince $\\sqrt{5} \\approx 2.236$, we have $\\lambda_3 \\approx 4.618$ and $\\lambda_4 \\approx 2.382$. Both eigenvalues are positive.\n\nFinally, the submatrix $H_3$ is a $1 \\times 1$ matrix. Its eigenvalue is the element itself:\n$\\lambda_5 = 2$\n\nThe complete set of eigenvalues for the Hessian matrix $H$ is $\\left\\{ 1, -5, \\frac{7+\\sqrt{5}}{2}, \\frac{7-\\sqrt{5}}{2}, 2 \\right\\}$.\n\nThe Morse index is the number of negative eigenvalues. In this set, only one eigenvalue, $\\lambda_2 = -5$, is negative. Therefore, the Morse index is $1$.\n\nBased on the problem's classification scheme:\n- A Morse index of $0$ corresponds to a classification code of $0$ (local minimum).\n- A Morse index of $1$ corresponds to a classification code of $1$ (first-order saddle).\n- A Morse index strictly greater than $1$ corresponds to a classification code of $2$ (higher-order saddle).\n\nSince the Morse index is $1$, the stationary point is a first-order saddle point, and its classification code is $1$. The final answer is the row matrix containing the Morse index followed by the classification code.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1 & 1\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "A central goal in catalysis is to predict reaction rates from fundamental material properties, often called descriptors. This practice bridges the gap between microscopic energies and macroscopic activity by guiding you through the derivation of a classic volcano plot, which embodies Sabatier's principle . By finding the optimal balance between reactant binding and product formation, you will uncover the core principles of rational catalyst design.",
            "id": "3881327",
            "problem": "Consider a single-site catalyst that converts a gas-phase reactant $A$ to a gas-phase product $P$ via an adsorbed intermediate $A^*$ on a vacant site $*$. The elementary steps are $A(\\mathrm{g}) + * \\rightleftharpoons A^*$ and $A^* \\rightarrow P(\\mathrm{g}) + *$. Assume an isothermal, isobaric, well-mixed reactor with no transport limitations, negligible product adsorption, and no lateral interactions between adsorbates. Let the catalyst be characterized by a scalar descriptor $D$ defined as the positive magnitude of the adsorption Gibbs free energy, so that the adsorption free energy change is $-\\!D$.\n\nUse the following foundational relations from chemical kinetics and thermodynamics:\n- The Arrhenius/Transition State Theory expression for an elementary rate constant is $k = \\nu \\exp(-E_{a}/(R T))$, where $E_{a}$ is the activation energy barrier, $R$ is the molar gas constant, $T$ is temperature, and $\\nu$ is a pre-exponential factor.\n- The Brønsted–Evans–Polanyi (BEP) relation states that the activation energy for the surface reaction $A^* \\rightarrow P(\\mathrm{g}) + *$ scales linearly with its reaction energy: $E_{a}(D) = E_{0} + \\alpha E_{\\mathrm{rxn}}(D)$, with $0 < \\alpha < 1$ and $E_{0} > 0$ independent of $D$.\n- Under quasi-equilibrium for adsorption and the Langmuir adsorption model, the coverage of $A^*$ is $\\theta_{A}(D) = \\dfrac{K(D) p_{A}}{1 + K(D) p_{A}}$, where $p_{A}$ is the partial pressure of $A$, and $K(D)$ is the adsorption equilibrium constant given by $K(D) = K^{\\circ} \\exp\\!\\left(\\dfrac{D}{R T}\\right)$ with $K^{\\circ} > 0$ a constant (units of inverse pressure) capturing standard-state and entropic contributions.\n\nAssume that the reaction energy for $A^* \\rightarrow P(\\mathrm{g}) + *$ equals $E_{\\mathrm{rxn}}(D) = D$, consistent with $D$ being the positive magnitude of the adsorption free energy. Define $k_{2,0} \\equiv \\nu \\exp(-E_{0}/(R T))$ so that the surface reaction rate constant is $k_{2}(D) = k_{2,0} \\exp\\!\\left(-\\dfrac{\\alpha D}{R T}\\right)$. The turnover frequency (TOF) per site is $r(D) = k_{2}(D)\\,\\theta_{A}(D)$.\n\nTask: Derive an analytic volcano-shaped expression for $r(D)$ and compute the globally optimal descriptor $D^{\\star}$ that maximizes $r(D)$ over $D > 0$, expressed in closed form as a function of $R$, $T$, $\\alpha$, $p_{A}$, and $K^{\\circ}$. Provide the final answer as a single closed-form analytic expression for $D^{\\star}$. Do not evaluate numerically.",
            "solution": "The problem has been validated and is determined to be a well-posed, scientifically grounded problem in chemical kinetics and catalysis theory.\n\nThe objective is to derive an expression for the turnover frequency, $r$, as a function of the catalyst descriptor, $D$, and to find the optimal value of the descriptor, $D^{\\star}$, that maximizes this rate. The descriptor $D > 0$ is defined as the positive magnitude of the adsorption Gibbs free energy.\n\nThe turnover frequency (TOF) per site, $r(D)$, is given by the product of the surface reaction rate constant, $k_{2}(D)$, and the coverage of the adsorbed intermediate, $\\theta_{A}(D)$.\n$$\nr(D) = k_{2}(D) \\theta_{A}(D)\n$$\nThe expressions for $k_{2}(D)$ and $\\theta_{A}(D)$ are provided in the problem statement.\nThe surface reaction rate constant is given as:\n$$\nk_{2}(D) = k_{2,0} \\exp\\left(-\\frac{\\alpha D}{R T}\\right)\n$$\nwhere $k_{2,0}$, $\\alpha$, $R$, and $T$ are constants. This expression shows that the rate of the surface reaction decreases as the binding strength $D$ increases, because a more stable intermediate $A^*$ faces a higher activation barrier to desorb as product $P$, according to the Brønsted–Evans–Polanyi (BEP) relation with a positive slope $\\alpha$.\n\nThe surface coverage of the intermediate, $\\theta_{A}(D)$, is given by the Langmuir isotherm under quasi-equilibrium for adsorption:\n$$\n\\theta_{A}(D) = \\frac{K(D) p_{A}}{1 + K(D) p_{A}}\n$$\nwhere the adsorption equilibrium constant $K(D)$ is:\n$$\nK(D) = K^{\\circ} \\exp\\left(\\frac{D}{R T}\\right)\n$$\nHere, $p_{A}$ and $K^{\\circ}$ are constants. This expression shows that the surface coverage $\\theta_{A}(D)$ increases as the binding strength $D$ increases, asymptotically approaching a full monolayer ($\\theta_{A} \\to 1$).\n\nCombining these expressions, the full equation for the turnover frequency is:\n$$\nr(D) = k_{2,0} \\exp\\left(-\\frac{\\alpha D}{R T}\\right) \\frac{K^{\\circ} \\exp\\left(\\frac{D}{R T}\\right) p_{A}}{1 + K^{\\circ} \\exp\\left(\\frac{D}{R T}\\right) p_{A}}\n$$\nThis expression demonstrates the classic volcano-shaped relationship central to Sabatier's principle.\nFor small values of $D$ (weak adsorption), the term $K^{\\circ} p_{A} \\exp(D/(R T))$ is small. The denominator approaches $1$, and $\\theta_{A}(D) \\approx K^{\\circ} p_{A} \\exp(D/(R T))$. The rate is thus:\n$$\nr(D) \\approx k_{2,0} \\exp\\left(-\\frac{\\alpha D}{R T}\\right) \\left[ K^{\\circ} p_{A} \\exp\\left(\\frac{D}{R T}\\right) \\right] = k_{2,0} K^{\\circ} p_{A} \\exp\\left(\\frac{(1-\\alpha)D}{R T}\\right)\n$$\nSince $0 < \\alpha < 1$, the exponent $(1-\\alpha)$ is positive, so the rate exponentially increases with $D$. The overall process is limited by the availability of the adsorbed intermediate $A^*$.\n\nFor large values of $D$ (strong adsorption), the term $K^{\\circ} p_{A} \\exp(D/(R T))$ is large. The surface becomes saturated, so $\\theta_{A}(D) \\to 1$. The rate is thus:\n$$\nr(D) \\approx k_{2,0} \\exp\\left(-\\frac{\\alpha D}{R T}\\right) \\times 1 = k_{2,0} \\exp\\left(-\\frac{\\alpha D}{R T}\\right)\n$$\nThe rate exponentially decreases with $D$. The overall process is limited by the slow surface reaction of the very stable intermediate $A^*$.\n\nThe competition between these two opposing trends gives rise to a maximum rate at an intermediate optimal descriptor value, $D^{\\star}$. To find this maximum, we can set the derivative of $r(D)$ with respect to $D$ equal to zero. It is often mathematically simpler to work with the natural logarithm of the rate, $\\ln(r(D))$, since $\\ln(x)$ is a monotonically increasing function and its maximum will occur at the same value of $D$ as the maximum of $r(D)$.\n\nThe natural logarithm of the rate is:\n$$\n\\ln(r(D)) = \\ln\\left(k_{2,0}\\right) + \\ln\\left(\\exp\\left(-\\frac{\\alpha D}{R T}\\right)\\right) + \\ln\\left(\\frac{K(D) p_{A}}{1 + K(D) p_{A}}\\right)\n$$\n$$\n\\ln(r(D)) = \\ln(k_{2,0}) - \\frac{\\alpha D}{R T} + \\ln(K(D) p_{A}) - \\ln(1 + K(D) p_{A})\n$$\nSubstituting $K(D) = K^{\\circ} \\exp(D/(R T))$:\n$$\n\\ln(r(D)) = \\ln(k_{2,0}) - \\frac{\\alpha D}{R T} + \\ln\\left(K^{\\circ}p_{A}\\right) + \\frac{D}{R T} - \\ln\\left(1 + K^{\\circ} p_{A} \\exp\\left(\\frac{D}{R T}\\right)\\right)\n$$\n$$\n\\ln(r(D)) = C + \\frac{(1-\\alpha)D}{R T} - \\ln\\left(1 + K^{\\circ} p_{A} \\exp\\left(\\frac{D}{R T}\\right)\\right)\n$$\nwhere $C = \\ln(k_{2,0}) + \\ln(K^{\\circ}p_{A})$ is a constant with respect to $D$.\n\nNow, we differentiate $\\ln(r(D))$ with respect to $D$:\n$$\n\\frac{d}{dD} \\ln(r(D)) = \\frac{1-\\alpha}{R T} - \\frac{1}{1 + K^{\\circ} p_{A} \\exp\\left(\\frac{D}{R T}\\right)} \\cdot \\left(K^{\\circ} p_{A} \\exp\\left(\\frac{D}{R T}\\right) \\cdot \\frac{1}{R T}\\right)\n$$\nTo find the optimal descriptor $D^{\\star}$, we set this derivative to zero:\n$$\n\\frac{1-\\alpha}{R T} = \\frac{K^{\\circ} p_{A} \\exp\\left(\\frac{D^{\\star}}{R T}\\right)}{1 + K^{\\circ} p_{A} \\exp\\left(\\frac{D^{\\star}}{R T}\\right)} \\cdot \\frac{1}{R T}\n$$\nThe term $1/(R T)$ cancels from both sides:\n$$\n1-\\alpha = \\frac{K^{\\circ} p_{A} \\exp\\left(\\frac{D^{\\star}}{R T}\\right)}{1 + K^{\\circ} p_{A} \\exp\\left(\\frac{D^{\\star}}{R T}\\right)}\n$$\nWe solve this equation for $D^{\\star}$. Let $X = K^{\\circ} p_{A} \\exp(D^{\\star}/(R T))$. The equation becomes:\n$$\n1-\\alpha = \\frac{X}{1+X}\n$$\n$$\n(1-\\alpha)(1+X) = X\n$$\n$$\n1-\\alpha + (1-\\alpha)X = X\n$$\n$$\n1-\\alpha = X - (1-\\alpha)X = X(1 - (1-\\alpha)) = X\\alpha\n$$\nSolving for $X$:\n$$\nX = \\frac{1-\\alpha}{\\alpha}\n$$\nNow, we substitute back the expression for $X$:\n$$\nK^{\\circ} p_{A} \\exp\\left(\\frac{D^{\\star}}{R T}\\right) = \\frac{1-\\alpha}{\\alpha}\n$$\nFinally, we solve for $D^{\\star}$ by taking the natural logarithm of both sides:\n$$\n\\exp\\left(\\frac{D^{\\star}}{R T}\\right) = \\frac{1-\\alpha}{\\alpha K^{\\circ} p_{A}}\n$$\n$$\n\\frac{D^{\\star}}{R T} = \\ln\\left(\\frac{1-\\alpha}{\\alpha K^{\\circ} p_{A}}\\right)\n$$\n$$\nD^{\\star} = R T \\ln\\left(\\frac{1-\\alpha}{\\alpha K^{\\circ} p_{A}}\\right)\n$$\nThis is the closed-form analytical expression for the optimal descriptor $D^{\\star}$ that maximizes the turnover frequency. The existence of a maximum for $D > 0$ requires the argument of the logarithm to be greater than $1$. The problem's premise of a \"volcano-shaped expression\" implies such a maximum exists within the domain.",
            "answer": "$$\n\\boxed{R T \\ln\\left(\\frac{1-\\alpha}{\\alpha K^{\\circ} p_{A}}\\right)}\n$$"
        },
        {
            "introduction": "Finding transition states is a cornerstone of mapping reaction networks, but it requires specialized algorithms that can navigate complex potential energy surfaces. This exercise moves from theory to practice by tasking you with building a Newton-based eigenvector-following algorithm from first principles . By implementing this powerful search method, you will gain a deep, practical understanding of how computational tools locate the saddle points that govern chemical reactivity.",
            "id": "3881308",
            "problem": "You are tasked with constructing and implementing a mathematically principled, Newton-based eigenvector-following algorithm to converge to a transition state on a potential energy surface, starting from nearby initial guesses. The problem is set within computational catalysis and chemical engineering, specifically in the domain of global optimization and automated reaction discovery. The goal is to reach a first-order saddle point, which corresponds to a transition state, by adjusting the Newton step so that the algorithm ascends along the reaction coordinate while descending along all orthogonal modes. Your derivation and implementation must be grounded in first principles, starting from the second-order Taylor expansion of the potential energy surface and making judicious use of the gradient and Hessian.\n\nA transition state is defined here as a stationary point for which the gradient vanishes and the Hessian has exactly one negative eigenvalue. The algorithm must systematically handle negative eigenvalues of the Hessian and near-zero curvature directions, ensure numerical stability, and employ a trust region strategy to regulate step sizes.\n\nStarting point for the derivation:\n- Use the second-order Taylor expansion of a twice continuously differentiable scalar potential energy surface $V(\\mathbf{x})$ around a point $\\mathbf{x}$: $V(\\mathbf{x} + \\mathbf{p}) \\approx V(\\mathbf{x}) + \\nabla V(\\mathbf{x})^{\\top} \\mathbf{p} + \\frac{1}{2} \\mathbf{p}^{\\top} \\nabla^{2} V(\\mathbf{x}) \\mathbf{p}$.\n- Use the definition of the Newton direction in terms of the gradient $\\nabla V(\\mathbf{x})$ and Hessian $\\nabla^{2} V(\\mathbf{x})$.\n- Use the spectral decomposition of the Hessian to reason about mode-specific curvature and how to systematically ascend along the reaction coordinate while descending along orthogonal modes.\n\nYou must not directly state or use any ready-made formulas for transition state algorithms. The problem must be solved from first principles by deriving the required steps.\n\nYour implementation target is the following two-dimensional, twice continuously differentiable potential energy surface (dimensionless units):\n$$\nV(x,y) = a(x^2 - b)^2 + c y^2 + d x y,\n$$\nwith parameters $a = 1.0$, $b = 1.0$, $c = 0.5$, and $d = 0.3$. This surface has two minima and one central saddle point that acts as a transition state between the wells. All quantities are dimensionless; express any numerical outputs as plain numbers without units.\n\nRequirements for your algorithm and program:\n- Derive and implement a step-by-step Newton-based eigenvector-following scheme that:\n  1. Computes the gradient and Hessian of $V(x,y)$ at the current iterate $\\mathbf{x} = (x,y)$.\n  2. Performs an eigen-decomposition of the Hessian to identify curvature modes.\n  3. Chooses the transition-state mode as the eigenvector associated with the smallest eigenvalue. If all eigenvalues are positive, still choose the mode associated with the smallest eigenvalue as the provisional reaction coordinate.\n  4. Constructs a modified Newton step in modal coordinates that ascends along the chosen transition-state mode while descending along the remaining modes.\n  5. Stabilizes the computation in the presence of negative or near-zero eigenvalues using a damping strategy grounded in your derivation.\n  6. Enforces a trust region on the step to avoid divergence and introduces an acceptance criterion based on the reduction of the gradient norm to decide whether to accept or shrink the trust region.\n  7. Terminates when the gradient norm and step size fall below specified tolerances, and then classifies the stationary point as a transition state if the Hessian has exactly one negative eigenvalue.\n- Your program must be completely deterministic and must not require any user input.\n\nTest suite:\nRun your algorithm on the following three initial guesses, using the fixed parameters given above. Each case must be independently processed by the program.\n1. Happy path: $(x_0, y_0) = (0.2, 0.1)$.\n2. Near a minimum: $(x_0, y_0) = (1.1, -0.3)$.\n3. Near an inflection-like region with soft curvature: $(x_0, y_0) = \\left(\\sqrt{\\frac{b}{3}}, 0.0\\right)$, which numerically is approximately $(0.5773502691896258, 0.0)$.\n\nConvergence and classification criteria:\n- Converge when the gradient norm $\\lVert \\nabla V\\rVert$ is below $10^{-8}$ and the step norm $\\lVert \\mathbf{p} \\rVert$ is below $10^{-10}$, or when a maximum of $200$ iterations is reached.\n- After termination, classify the final point as a transition state if and only if the Hessian has exactly one negative eigenvalue.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each test case, return a list of four elements: the final $x$ coordinate, the final $y$ coordinate, the final energy $V(x,y)$, and a boolean indicating whether the point is classified as a transition state. Therefore, the final output line must look like:\n[[x1,y1,E1,TS1],[x2,y2,E2,TS2],[x3,y3,E3,TS3]]\nAll numbers must be expressed as plain decimals, and booleans as True or False. No additional text should be printed.",
            "solution": "The objective is to derive and implement a Newton-based eigenvector-following algorithm to locate a first-order saddle point, representing a transition state (TS), on a given potential energy surface $V(\\mathbf{x})$. A transition state is a stationary point where the gradient of the potential energy, $\\nabla V$, is zero, and the Hessian matrix, $\\nabla^2 V$, possesses exactly one negative eigenvalue.\n\nThe algorithm will be developed from first principles, starting with the second-order Taylor expansion of the potential energy surface $V(\\mathbf{x})$ around a point $\\mathbf{x}_k$:\n$$\nV(\\mathbf{x}_k + \\mathbf{p}) \\approx V(\\mathbf{x}_k) + \\mathbf{g}_k^\\top \\mathbf{p} + \\frac{1}{2}\\mathbf{p}_k^\\top \\mathbf{H}_k \\mathbf{p}\n$$\nwhere $\\mathbf{p}$ is the step vector, $\\mathbf{g}_k = \\nabla V(\\mathbf{x}_k)$ is the gradient, and $\\mathbf{H}_k = \\nabla^2 V(\\mathbf{x}_k)$ is the Hessian matrix at the current iterate $\\mathbf{x}_k$.\n\nFirst, we define the potential energy surface and its derivatives. The given surface is:\n$$\nV(x,y) = a(x^2 - b)^2 + c y^2 + d x y\n$$\nwith parameters $a = 1.0$, $b = 1.0$, $c = 0.5$, and $d = 0.3$.\nThe position vector is $\\mathbf{x} = \\begin{pmatrix} x \\\\ y \\end{pmatrix}$.\n\nThe gradient, $\\nabla V(\\mathbf{x})$, is a vector of first partial derivatives:\n$$\n\\nabla V(\\mathbf{x}) = \\begin{pmatrix} \\frac{\\partial V}{\\partial x} \\\\ \\frac{\\partial V}{\\partial y} \\end{pmatrix} = \\begin{pmatrix} 2a(x^2 - b)(2x) + dy \\\\ 2cy + dx \\end{pmatrix} = \\begin{pmatrix} 4a(x^3 - bx) + dy \\\\ dx + 2cy \\end{pmatrix}\n$$\nThe Hessian, $\\nabla^2 V(\\mathbf{x})$, is a matrix of second partial derivatives:\n$$\n\\mathbf{H}(\\mathbf{x}) = \\begin{pmatrix} \\frac{\\partial^2 V}{\\partial x^2} & \\frac{\\partial^2 V}{\\partial x \\partial y} \\\\ \\frac{\\partial^2 V}{\\partial y \\partial x} & \\frac{\\partial^2 V}{\\partial y^2} \\end{pmatrix} = \\begin{pmatrix} 4a(3x^2 - b) & d \\\\ d & 2c \\end{pmatrix}\n$$\nSubstituting the given parameters:\n$$\n\\nabla V(x,y) = \\begin{pmatrix} 4(x^3 - x) + 0.3y \\\\ 0.3x + y \\end{pmatrix}\n$$\n$$\n\\mathbf{H}(x,y) = \\begin{pmatrix} 4(3x^2 - 1) & 0.3 \\\\ 0.3 & 1.0 \\end{pmatrix}\n$$\n\nThe standard Newton-Raphson step for finding a stationary point is derived by minimizing the quadratic model of $V$, leading to $\\mathbf{p} = -\\mathbf{H}^{-1}\\mathbf{g}$. This step is designed to converge to a minimum, where $\\mathbf{H}$ is positive definite. For a saddle point search, $\\mathbf{H}$ is indefinite (having both positive and negative eigenvalues), and the standard Newton step would lead away from the saddle point along the direction of negative curvature.\n\nThe core of the eigenvector-following method is to modify the step based on the local topology encoded in the Hessian's eigensystem. We perform a spectral decomposition of the symmetric Hessian matrix:\n$$\n\\mathbf{H} = \\mathbf{U} \\mathbf{\\Lambda} \\mathbf{U}^\\top\n$$\nwhere $\\mathbf{U}$ is an orthogonal matrix whose columns are the eigenvectors $\\mathbf{u}_i$, and $\\mathbf{\\Lambda}$ is a diagonal matrix of the corresponding eigenvalues $\\lambda_i$. We can express the step $\\mathbf{p}$ and gradient $\\mathbf{g}$ in the basis of eigenvectors:\n$$\n\\mathbf{p} = \\sum_{i=1}^n p'_i \\mathbf{u}_i \\quad \\text{and} \\quad \\mathbf{g} = \\sum_{i=1}^n g'_i \\mathbf{u}_i\n$$\nwhere $p'_i$ and $g'_i = \\mathbf{g}^\\top \\mathbf{u}_i$ are the components of the step and gradient along the eigenvector $\\mathbf{u}_i$. The quadratic energy model in this modal basis becomes:\n$$\nV(\\mathbf{x}_k + \\mathbf{p}) - V(\\mathbf{x}_k) \\approx \\sum_{i=1}^n \\left( g'_i p'_i + \\frac{1}{2} \\lambda_i (p'_i)^2 \\right)\n$$\nTo find a first-order saddle point, we must ascend along the mode with negative curvature (the reaction coordinate) and descend along all other modes with positive curvature. The problem specifies that the mode to be ascended corresponds to the eigenvector with the smallest eigenvalue, which we denote as $\\mathbf{u}_1$ with eigenvalue $\\lambda_1$.\n\nFor the descent modes ($i > 1$), we seek to minimize the energy contribution. The step component that minimizes $g'_i p'_i + \\frac{1}{2} \\lambda_i (p'_i)^2$ is the standard Newton step component:\n$$\np'_i = -\\frac{g'_i}{\\lambda_i} \\quad \\text{for } i=2, \\dots, n\n$$\nThis requires $\\lambda_i > 0$. If we are not in a region where this holds (e.g., at a higher-order saddle point or far from any stationary point), we must stabilize the step. A robust approach is to use a damped step, ensuring the effective curvature is positive:\n$$\np'_i = -\\frac{g'_i}{\\max(\\lambda_i, \\delta_d)} \\quad \\text{for } i=2, \\dots, n\n$$\nwhere $\\delta_d$ is a small positive damping constant. This ensures a descent step along these modes, even if their true curvature is negative or zero.\n\nFor the ascent mode ($i=1$), we seek to maximize the energy contribution $g'_1 p'_1 + \\frac{1}{2} \\lambda_1 (p'_1)^2$. A step in the direction of the gradient component, $g'_1$, will be uphill. To incorporate curvature information and maintain a structure similar to the Newton step, we can formulate an \"uphill\" Newton step. The step should be in the direction of $g'_1$ with a magnitude related to the curvature $|\\lambda_1|$. We define the ascent step component as:\n$$\np'_1 = +\\frac{g'_1}{\\max(|\\lambda_1|, \\delta_a)}\n$$\nwhere $\\delta_a$ is another positive damping constant. The positive sign ensures ascent along the gradient component for this mode, and using $|\\lambda_1|$ provides a stable step magnitude regardless of whether the curvature is currently negative (near a TS) or positive (near a minimum).\n\nCombining these components, the full raw step vector is constructed:\n$$\n\\mathbf{p}_{\\text{raw}} = p'_1 \\mathbf{u}_1 + \\sum_{i=2}^n p'_i \\mathbf{u}_i = \\left(\\frac{g'_1}{\\max(|\\lambda_1|, \\delta_a)}\\right)\\mathbf{u}_1 - \\sum_{i=2}^n \\left(\\frac{g'_i}{\\max(\\lambda_i, \\delta_d)}\\right)\\mathbf{u}_i\n$$\n\nTo prevent divergence when the quadratic approximation is poor, we introduce a trust region. The step $\\mathbf{p}$ is constrained to have a norm no larger than a trust radius $\\Delta$: $\\lVert\\mathbf{p}\\rVert \\le \\Delta$. If the raw step $\\mathbf{p}_{\\text{raw}}$ exceeds this radius, it is scaled down:\n$$\n\\mathbf{p}_k = \\begin{cases} \\mathbf{p}_{\\text{raw}} & \\text{if } \\lVert\\mathbf{p}_{\\text{raw}}\\rVert \\le \\Delta_k \\\\ \\mathbf{p}_{\\text{raw}} \\frac{\\Delta_k}{\\lVert\\mathbf{p}_{\\text{raw}}\\rVert} & \\text{if } \\lVert\\mathbf{p}_{\\text{raw}}\\rVert > \\Delta_k \\end{cases}\n$$\nThe new position is proposed as $\\mathbf{x}_{\\text{trial}} = \\mathbf{x}_k + \\mathbf{p}_k$. According to the problem specification, the step is accepted if the norm of the gradient at the trial point is smaller than at the current point, i.e., $\\lVert \\nabla V(\\mathbf{x}_{\\text{trial}}) \\rVert < \\lVert \\nabla V(\\mathbf{x}_k) \\rVert$. If the step is accepted, the trust radius for the next iteration may be increased. If rejected, the trust radius is decreased, and the step is re-evaluated from the same point $\\mathbf{x}_k$ with a smaller step size constraint.\n\nThe algorithm terminates when the norm of the gradient, $\\lVert \\mathbf{g} \\rVert$, and the norm of the last accepted step, $\\lVert \\mathbf{p} \\rVert$, fall below predefined tolerances, or a maximum number of iterations is reached.\n\nFinally, upon convergence to a stationary point $\\mathbf{x}^*$, we classify it. We compute the Hessian $\\mathbf{H}(\\mathbf{x}^*)$ and its eigenvalues. If there is exactly one negative eigenvalue, the point is classified as a transition state.\n\nThe complete algorithm is as follows:\n1.  Initialize with $\\mathbf{x}_0$ and an initial trust radius $\\Delta_0$.\n2.  For $k=0, 1, 2, \\dots$ up to a maximum number of iterations:\n    a.  Compute the gradient $\\mathbf{g}_k$ and Hessian $\\mathbf{H}_k$ at $\\mathbf{x}_k$.\n    b.  Check for convergence: if $\\lVert \\mathbf{g}_k \\rVert < \\epsilon_g$ and $\\lVert \\mathbf{p}_{k-1} \\rVert < \\epsilon_p$, terminate.\n    c.  Perform eigen-decomposition of $\\mathbf{H}_k$ to get eigenvalues $\\{\\lambda_i\\}$ and eigenvectors $\\{\\mathbf{u}_i\\}$, sorted by eigenvalue.\n    d.  Compute the raw step $\\mathbf{p}_{\\text{raw}}$ using the derived modal step equations.\n    e.  Constrain the step to the trust radius: $\\mathbf{p}_k = \\text{scale}(\\mathbf{p}_{\\text{raw}}, \\Delta_k)$.\n    f.  Propose a trial point $\\mathbf{x}_{\\text{trial}} = \\mathbf{x}_k + \\mathbf{p}_k$.\n    g.  Evaluate the gradient $\\mathbf{g}_{\\text{trial}} = \\nabla V(\\mathbf{x}_{\\text{trial}})$.\n    h.  If $\\lVert \\mathbf{g}_{\\text{trial}} \\rVert < \\lVert \\mathbf{g}_k \\rVert$ (step accepted):\n        i.  Update position: $\\mathbf{x}_{k+1} = \\mathbf{x}_{\\text{trial}}$.\n        ii. Increase trust radius: $\\Delta_{k+1} = \\min(\\Delta_{\\text{max}}, \\Delta_k \\cdot f_{\\text{grow}})$.\n    i.  Else (step rejected):\n        i.  Do not update position: $\\mathbf{x}_{k+1} = \\mathbf{x}_k$.\n        ii. Decrease trust radius: $\\Delta_{k+1} = \\Delta_k \\cdot f_{\\text{shrink}}$.\n3.  Once terminated, classify the final point $\\mathbf{x}_{\\text{final}}$ by analyzing the eigenvalues of $\\mathbf{H}(\\mathbf{x}_{\\text{final}})$.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the transition state search for all test cases.\n    \"\"\"\n    test_cases = [\n        (0.2, 0.1),\n        (1.1, -0.3),\n        (np.sqrt(1.0/3.0), 0.0),\n    ]\n\n    results = []\n    for x0, y0 in test_cases:\n        x_final, y_final, E_final, is_ts = find_transition_state(x0, y0)\n        results.append([x_final, y_final, E_final, is_ts])\n\n    # Format the final output string exactly as required\n    result_str = \"[\" + \",\".join([\n        f\"[{r[0]},{r[1]},{r[2]},{'True' if r[3] else 'False'}]\"\n        for r in results\n    ]) + \"]\"\n\n    print(result_str)\n\ndef find_transition_state(x0, y0):\n    \"\"\"\n    Implements the derived Newton-based eigenvector-following algorithm.\n    \"\"\"\n    # PES parameters\n    a = 1.0\n    b = 1.0\n    c = 0.5\n    d = 0.3\n\n    def V(pos):\n        x, y = pos\n        return a * (x**2 - b)**2 + c * y**2 + d * x * y\n\n    def grad_V(pos):\n        x, y = pos\n        gx = 4.0 * a * (x**3 - b * x) + d * y\n        gy = 2.0 * c * y + d * x\n        return np.array([gx, gy])\n\n    def hess_V(pos):\n        x, y = pos\n        h_xx = 4.0 * a * (3.0 * x**2 - b)\n        h_xy = d\n        h_yy = 2.0 * c\n        return np.array([[h_xx, h_xy], [h_xy, h_yy]])\n\n    # Algorithm hyperparameters\n    max_iter = 200\n    tol_g = 1e-8\n    tol_p = 1e-10\n    \n    trust_radius = 0.1\n    max_trust_radius = 0.3\n    grow_factor = 1.1\n    shrink_factor = 0.5\n    \n    damping_const = 0.05\n\n    x_current = np.array([x0, y0])\n    p_prev_norm = np.inf\n\n    for _ in range(max_iter):\n        g = grad_V(x_current)\n        g_norm = np.linalg.norm(g)\n        \n        if g_norm < tol_g and p_prev_norm < tol_p:\n            break\n\n        H = hess_V(x_current)\n        \n        # Eigen-decomposition. eigh returns eigenvalues in ascending order.\n        e_vals, e_vecs = np.linalg.eigh(H)\n        \n        # Project gradient onto eigenvector basis\n        g_prime = e_vecs.T @ g\n        \n        # Construct step in modal basis\n        p_prime = np.zeros_like(g_prime)\n        \n        # Ascent mode (mode 1, lowest eigenvalue)\n        p_prime[0] = g_prime[0] / max(abs(e_vals[0]), damping_const)\n        \n        # Descent modes (all others)\n        for i in range(1, len(e_vals)):\n            p_prime[i] = -g_prime[i] / max(e_vals[i], damping_const)\n        \n        # Reconstruct step in Cartesian coordinates\n        p_raw = e_vecs @ p_prime\n        \n        # Apply trust region constraint\n        p_raw_norm = np.linalg.norm(p_raw)\n        if p_raw_norm > trust_radius:\n            p = p_raw * (trust_radius / p_raw_norm)\n        else:\n            p = p_raw\n        \n        # Acceptance criterion\n        x_trial = x_current + p\n        g_trial = grad_V(x_trial)\n        \n        if np.linalg.norm(g_trial) < g_norm:  # Accept step\n            x_current = x_trial\n            p_prev_norm = np.linalg.norm(p)\n            trust_radius = min(max_trust_radius, trust_radius * grow_factor)\n        else:  # Reject step\n            p_prev_norm = 0.0 # Step was rejected, so its effective norm is 0\n            trust_radius *= shrink_factor\n\n            # If trust radius becomes too small, break to avoid infinite loop\n            if trust_radius < 1e-12:\n                break\n    \n    x_final = x_current\n    \n    # Final analysis\n    V_final = V(x_final)\n    H_final = hess_V(x_final)\n    final_evals, _ = np.linalg.eigh(H_final)\n    \n    # Classify as transition state if exactly one eigenvalue is negative\n    num_negative_evals = np.sum(final_evals < -1e-6) # Use a small tolerance\n    is_ts = (num_negative_evals == 1)\n\n    return x_final[0], x_final[1], V_final, is_ts\n\n# Run the solver\nsolve()\n```"
        }
    ]
}