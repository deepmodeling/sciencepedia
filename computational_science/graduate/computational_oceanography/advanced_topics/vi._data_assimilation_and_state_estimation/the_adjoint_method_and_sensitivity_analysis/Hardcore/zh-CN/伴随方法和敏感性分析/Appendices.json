{
    "hands_on_practices": [
        {
            "introduction": "要真正掌握伴随方法，必须理解其数学基础。本练习将引导您从第一性原理出发，通过变分法推导一个典型的海洋示踪剂输运方程的连续伴随方程。通过亲手执行时空域上的分部积分，您将清晰地看到伴随算子如何作为前向算子的“转置”而自然出现，以及为何伴随方程需要逆时积分 。这个基本功训练对于理解更复杂模型中伴随方程的结构至关重要。",
            "id": "3813441",
            "problem": "考虑一个有界单连通的海洋区域 $\\Omega \\subset \\mathbb{R}^{3}$，其边界 $\\partial \\Omega$ 光滑，单位外法向量为 $\\mathbf{n}$。设示踪剂浓度 $T(\\mathbf{x},t)$ 在时间区间 $t \\in [0,t_{f}]$ 上根据线性平流-扩散偏微分方程（PDE）演化\n$$\nT_{t} + \\mathbf{u}(\\mathbf{x},t) \\cdot \\nabla T - \\nabla \\cdot \\big( \\mathbf{K}(\\mathbf{x},t) \\nabla T \\big) = 0,\n$$\n其中 $\\mathbf{u}(\\mathbf{x},t)$ 是一个给定的无散速度场，满足 $\\nabla \\cdot \\mathbf{u} = 0$ 且在 $\\partial \\Omega$ 上 $\\mathbf{u} \\cdot \\mathbf{n} = 0$，$\\mathbf{K}(\\mathbf{x},t)$ 是一个对称、一致正定的扩散张量。在 $\\partial \\Omega$ 上施加齐次无通量边界条件 $(\\mathbf{K} \\nabla T) \\cdot \\mathbf{n} = 0$，并给定初始条件 $T(\\mathbf{x},0) = T_{0}(\\mathbf{x})$。\n\n定义终端数据失配代价泛函\n$$\n\\mathcal{J}(T) = \\frac{1}{2} \\int_{\\Omega} \\big( T(\\mathbf{x},t_{f}) - T_{d}(\\mathbf{x}) \\big)^{2} \\, d\\mathbf{x},\n$$\n其中 $T_{d}(\\mathbf{x})$ 是在时间 $t_{f}$ 给定的目标示踪剂场。使用 $L^{2}(\\Omega)$ 内积作为基本配对，并仅使用散度定理和分部积分作为核心工具，推导与正向PDE约束相关的Lagrange乘子场 $\\psi(\\mathbf{x},t)$ 的连续伴随公式，其边界条件与正向模型相同，即在 $\\partial \\Omega$ 上满足齐次边界条件 $(\\mathbf{K} \\nabla \\psi) \\cdot \\mathbf{n} = 0$ 和 $\\mathbf{u} \\cdot \\mathbf{n} = 0$。\n\n你的推导必须：\n- 从由 $\\mathcal{J}(T)$ 和带有乘子 $\\psi(\\mathbf{x},t)$ 的正向PDE约束所构造的增广Lagrangian函数开始。\n- 系统地应用时间和空间上的分部积分，将所有导数从 $\\delta T$ 转移到 $\\psi$ 上，清晰地识别出内部伴随算子和所有边界贡献项。\n- 仅使用所述性质（$\\mathbf{u}$ 的无散性、$\\mathbf{K}$ 的对称性和正定性，以及齐次边界条件）来消除边界项。\n- 证明伴随场随时间向后演化，其在 $t_{f}$ 的终端条件源于 $\\mathcal{J}$ 的变分。\n\n作为最终答案，报告作用于 $\\psi$ 的连续伴随算子的解析表达式（即在所有分部积分后，体积分中乘以 $\\delta T$ 的内部算子）。仅提供算子表达式，而非方程，且不包含任何单位。如果得到多种等价形式，请选择以散度符号表示的形式，而不是展开的乘积法则形式。无需四舍五入。",
            "solution": "该问题已经过验证，是一个适定的、具有科学依据的连续伴随模型推导练习。推导过程采用Lagrange乘子法。\n\n首先，我们将正向模型约束定义为PDE等于零：\n$$\nG(T) = T_{t} + \\mathbf{u}(\\mathbf{x},t) \\cdot \\nabla T - \\nabla \\cdot \\big( \\mathbf{K}(\\mathbf{x},t) \\nabla T \\big) = 0\n$$\n增广Lagrangian函数 $\\mathcal{L}$ 的构造方法是，将代价泛函 $\\mathcal{J}$ 与约束 $G(T)$ 和Lagrange乘子场 $\\psi(\\mathbf{x}, t)$ 的内积相加。该内积是在时空域 $\\Omega \\times [0,t_f]$ 上计算的。\n$$\n\\mathcal{L}(T, \\psi) = \\mathcal{J}(T) + \\int_{0}^{t_f} \\int_{\\Omega} \\psi G(T) \\, d\\mathbf{x} \\, dt\n$$\n代入 $\\mathcal{J}(T)$ 和 $G(T)$ 的表达式：\n$$\n\\mathcal{L}(T, \\psi) = \\frac{1}{2} \\int_{\\Omega} \\big( T(\\mathbf{x},t_{f}) - T_{d}(\\mathbf{x}) \\big)^{2} \\, d\\mathbf{x} + \\int_{0}^{t_f} \\int_{\\Omega} \\psi \\left( T_{t} + \\mathbf{u} \\cdot \\nabla T - \\nabla \\cdot (\\mathbf{K} \\nabla T) \\right) \\, d\\mathbf{x} \\, dt\n$$\n为求得伴随方程，我们通过考虑一个小的扰动 $\\delta T$ 来计算 $\\mathcal{L}$ 关于 $T$ 的一阶变分，记为 $\\delta \\mathcal{L}$。通过要求对于所有容许的扰动 $\\delta T$ 都有 $\\delta \\mathcal{L} = 0$，即可找到伴随方程。\n变分为：\n$$\n\\delta \\mathcal{L} = \\int_{\\Omega} \\big( T(\\mathbf{x},t_{f}) - T_{d}(\\mathbf{x}) \\big) \\delta T(\\mathbf{x},t_{f}) \\, d\\mathbf{x} + \\int_{0}^{t_f} \\int_{\\Omega} \\psi \\left( \\delta T_{t} + \\mathbf{u} \\cdot \\nabla(\\delta T) - \\nabla \\cdot (\\mathbf{K} \\nabla(\\delta T)) \\right) \\, d\\mathbf{x} \\, dt\n$$\n该方法的核心是使用分部积分将所有微分算子从扰动 $\\delta T$ 转移到乘子场 $\\psi$ 上。我们分析时空积分内的每一项。\n\n1.  时间导数项： $\\int_{0}^{t_f} \\int_{\\Omega} \\psi \\delta T_{t} \\, d\\mathbf{x} \\, dt$。\n    对时间 $t$ 进行分部积分：\n    $$\n    \\int_{0}^{t_f} \\psi \\delta T_{t} \\, dt = [\\psi \\delta T]_{0}^{t_f} - \\int_{0}^{t_f} \\psi_t \\delta T \\, dt = \\psi(t_f) \\delta T(t_f) - \\psi(0) \\delta T(0) - \\int_{0}^{t_f} \\psi_t \\delta T \\, dt\n    $$\n    由于初始条件 $T(\\mathbf{x},0) = T_0(\\mathbf{x})$ 是固定的，任何容许的扰动都必须满足 $\\delta T(\\mathbf{x},0) = 0$。因此，该项变为：\n    $$\n    \\int_{0}^{t_f} \\int_{\\Omega} \\psi \\delta T_{t} \\, d\\mathbf{x} \\, dt = \\int_{\\Omega} \\psi(t_f) \\delta T(t_f) \\, d\\mathbf{x} - \\int_{0}^{t_f} \\int_{\\Omega} \\psi_t \\delta T \\, d\\mathbf{x} \\, dt\n    $$\n\n2.  平流项： $\\int_{0}^{t_f} \\int_{\\Omega} \\psi (\\mathbf{u} \\cdot \\nabla(\\delta T)) \\, d\\mathbf{x} \\, dt$。\n    我们使用向量恒等式 $\\nabla \\cdot (a \\mathbf{V}) = (\\nabla a) \\cdot \\mathbf{V} + a (\\nabla \\cdot \\mathbf{V})$。将其应用于 $a = \\psi \\delta T$ 和 $\\mathbf{V} = \\mathbf{u}$，并考虑到 $\\nabla \\cdot \\mathbf{u} = 0$，我们有 $\\nabla \\cdot ((\\psi \\delta T)\\mathbf{u}) = \\nabla(\\psi \\delta T) \\cdot \\mathbf{u} = (\\psi \\nabla(\\delta T) + \\delta T \\nabla \\psi) \\cdot \\mathbf{u}$。整理后得到：\n    $$\n    \\psi (\\mathbf{u} \\cdot \\nabla(\\delta T)) = \\nabla \\cdot((\\psi \\delta T)\\mathbf{u}) - \\delta T(\\mathbf{u} \\cdot \\nabla \\psi)\n    $$\n    在 $\\Omega$ 上积分并应用散度定理：\n    $$\n    \\int_{\\Omega} \\psi (\\mathbf{u} \\cdot \\nabla(\\delta T)) \\, d\\mathbf{x} = \\int_{\\partial \\Omega} (\\psi \\delta T) \\mathbf{u} \\cdot \\mathbf{n} \\, dS - \\int_{\\Omega} \\delta T(\\mathbf{u} \\cdot \\nabla \\psi) \\, d\\mathbf{x}\n    $$\n    由于给定的边界条件 $\\mathbf{u} \\cdot \\mathbf{n} = 0$ 在 $\\partial \\Omega$ 上成立，边界积分为零。因此，我们有：\n    $$\n    \\int_{0}^{t_f} \\int_{\\Omega} \\psi (\\mathbf{u} \\cdot \\nabla(\\delta T)) \\, d\\mathbf{x} \\, dt = - \\int_{0}^{t_f} \\int_{\\Omega} (\\mathbf{u} \\cdot \\nabla \\psi) \\delta T \\, d\\mathbf{x} \\, dt\n    $$\n\n3.  扩散项： $\\int_{0}^{t_f} \\int_{\\Omega} \\psi \\left( - \\nabla \\cdot (\\mathbf{K} \\nabla(\\delta T)) \\right) \\, d\\mathbf{x} \\, dt$。\n    我们进行两次分部积分。首先，对空间积分使用格林第一恒等式：\n    $$\n    - \\int_{\\Omega} \\psi \\nabla \\cdot (\\mathbf{K} \\nabla(\\delta T)) \\, d\\mathbf{x} = - \\int_{\\partial \\Omega} \\psi (\\mathbf{K} \\nabla(\\delta T)) \\cdot \\mathbf{n} \\, dS + \\int_{\\Omega} \\nabla \\psi \\cdot (\\mathbf{K} \\nabla(\\delta T)) \\, d\\mathbf{x}\n    $$\n    边界项为零，因为扰动必须满足与正向变量相同的齐次无通量条件，即在 $\\partial \\Omega$ 上 $(\\mathbf{K} \\nabla(\\delta T)) \\cdot \\mathbf{n} = 0$。剩余项为 $\\int_{\\Omega} \\nabla \\psi \\cdot (\\mathbf{K} \\nabla(\\delta T)) \\, d\\mathbf{x}$。由于 $\\mathbf{K}$ 是对称的，这等于 $\\int_{\\Omega} (\\mathbf{K} \\nabla \\psi) \\cdot \\nabla(\\delta T) \\, d\\mathbf{x}$。我们再次应用分部积分：\n    $$\n    \\int_{\\Omega} (\\mathbf{K} \\nabla \\psi) \\cdot \\nabla(\\delta T) \\, d\\mathbf{x} = \\int_{\\partial \\Omega} \\delta T (\\mathbf{K} \\nabla \\psi) \\cdot \\mathbf{n} \\, dS - \\int_{\\Omega} \\delta T \\nabla \\cdot (\\mathbf{K} \\nabla \\psi) \\, d\\mathbf{x}\n    $$\n    由于为伴随场规定的边界条件 $(\\mathbf{K} \\nabla \\psi) \\cdot \\mathbf{n} = 0$ 在 $\\partial \\Omega$ 上成立，边界积分为零。综合这些步骤，扩散项变为：\n    $$\n    - \\int_{0}^{t_f} \\int_{\\Omega} \\psi \\nabla \\cdot (\\mathbf{K} \\nabla(\\delta T)) \\, d\\mathbf{x} \\, dt = - \\int_{0}^{t_f} \\int_{\\Omega} \\nabla \\cdot (\\mathbf{K} \\nabla \\psi) \\delta T \\, d\\mathbf{x} \\, dt\n    $$\n\n现在，我们将这些变换后的项代回到 $\\delta \\mathcal{L}$ 的表达式中：\n$$\n\\delta \\mathcal{L} = \\int_{\\Omega} \\big( T(t_{f}) - T_{d} \\big) \\delta T(t_{f}) \\, d\\mathbf{x} + \\int_{\\Omega} \\psi(t_f) \\delta T(t_f) \\, d\\mathbf{x} - \\int_{0}^{t_f} \\int_{\\Omega} \\psi_t \\delta T \\, d\\mathbf{x} \\, dt - \\int_{0}^{t_f} \\int_{\\Omega} (\\mathbf{u} \\cdot \\nabla \\psi) \\delta T \\, d\\mathbf{x} \\, dt - \\int_{0}^{t_f} \\int_{\\Omega} \\nabla \\cdot (\\mathbf{K} \\nabla \\psi) \\delta T \\, d\\mathbf{x} \\, dt\n$$\n按积分类型对各项进行分组：\n$$\n\\delta \\mathcal{L} = \\int_{\\Omega} \\left[ T(t_{f}) - T_{d} + \\psi(t_f) \\right] \\delta T(t_f) \\, d\\mathbf{x} + \\int_{0}^{t_f} \\int_{\\Omega} \\left[ - \\psi_t - \\mathbf{u} \\cdot \\nabla \\psi - \\nabla \\cdot (\\mathbf{K} \\nabla \\psi) \\right] \\delta T \\, d\\mathbf{x} \\, dt\n$$\n为了使 $\\delta \\mathcal{L}$ 对于任何任意的容许扰动 $\\delta T$ 都为零，方括号中的表达式必须为零。这就得出了伴随系统。$\\psi$ 在 $t=t_f$ 时的终端条件是：\n$$\n\\psi(\\mathbf{x}, t_f) = T_d(\\mathbf{x}) - T(\\mathbf{x}, t_f)\n$$\n通过将时空积分的被积函数设为零，可以得到在 $t \\in [0, t_f)$ 上必须成立的伴随PDE：\n$$\n- \\psi_t - \\mathbf{u} \\cdot \\nabla \\psi - \\nabla \\cdot (\\mathbf{K} \\nabla \\psi) = 0\n$$\n该方程描述了伴随场 $\\psi$ 的时间反向演化。问题要求的是作用于 $\\psi$ 的连续伴随算子的解析表达式，这恰好是该方程的左边部分。这也是在所有操作之后，在体积分中乘以 $\\delta T$ 的内部算子。",
            "answer": "$$\n\\boxed{- \\psi_{t} - \\mathbf{u} \\cdot \\nabla \\psi - \\nabla \\cdot (\\mathbf{K} \\nabla \\psi)}\n$$"
        },
        {
            "introduction": "从连续理论到离散的数值实现是应用伴随方法的关键一步，但这一过程极易出错。因此，验证伴随代码的正确性是不可或缺的实践环节。本练习  将指导您为一个离散的伴随模型实施“梯度检验”，这是一种通过将伴随方法计算出的梯度与有限差分逼近的梯度进行比较的黄金标准。您不仅将学习如何实现这一检验，还将深入探讨有限差分步长 $\\epsilon$ 选择中的权衡——即截断误差与舍入误差之间的平衡，这是所有数值分析中的一个核心问题。",
            "id": "3813416",
            "problem": "考虑一个代表深度平均海岸通道的一维、周期性、线性示踪剂演化模型。示踪剂浓度场 $c(x,t)$ 由具有恒定速度和扩散系数的平流-扩散方程控制，表示为 $$\\frac{\\partial c}{\\partial t} = -u \\frac{\\partial c}{\\partial x} + \\kappa \\frac{\\partial^2 c}{\\partial x^2},$$ 其中 $u$ 是深度平均的沿通道速度，单位为 $\\mathrm{m/s}$，$\\kappa$ 是涡动扩散系数，单位为 $\\mathrm{m^2/s}$。参数向量定义为 $p = (p_1, p_2)$，其中 $p_1 = u$，$p_2 = \\beta$，且 $\\kappa = \\exp(\\beta)$ 以强制扩散系数为严格正值。\n\n将长度为 $L$ 的空间域离散为 $N_x$ 个均匀间隔的网格点，间距为 $\\Delta x = L/N_x$，并施加周期性边界条件。假设 $u > 0$，对流项使用一阶迎风有限差分算子，扩散项使用二阶中心有限差分算子：\n- 迎风差分算子 $D_u$ 满足 $$(D_u c)_i = \\frac{c_i - c_{i-1}}{\\Delta x},$$ 其中索引进行周期性卷绕。\n- 扩散算子 $D_2$ 满足 $$(D_2 c)_i = \\frac{c_{i-1} - 2 c_i + c_{i+1}}{\\Delta x^2},$$ 同样进行周期性卷绕。\n\n时间上使用显式欧拉法推进，固定时间步长为 $\\Delta t$，总时间为 $T$。在步骤 $k$ 时，状态 $c^k \\in \\mathbb{R}^{N_x}$ 的离散前向更新为\n$$c^{k+1} = M(p) \\, c^k,\\quad M(p) = I + \\Delta t\\left(-u D_u + \\kappa D_2\\right),$$\n其中 $I$ 是 $N_x \\times N_x$ 的单位矩阵。初始条件 $c^0$ 指定为\n$$c^0_i = \\sin\\left(\\frac{2\\pi x_i}{L}\\right) + \\frac{1}{2}\\sin\\left(\\frac{4\\pi x_i}{L}\\right),\\quad x_i = i \\Delta x,$$\n目标终端剖面为 $c^\\star = 0$（零向量）。定义可微的标量目标函数\n$$J(p) = \\frac{1}{2} \\Delta x \\sum_{i=0}^{N_x-1} \\left(c^N_i - c^\\star_i\\right)^2 = \\frac{1}{2} \\Delta x \\left\\|c^N\\right\\|_2^2,$$\n其中 $N$ 是总时间步数，$N = \\lfloor T/\\Delta t \\rfloor$。\n\n使用离散伴随法，在名义参数 $p$ 处推导并实现梯度 $\\nabla_p J(p) = \\left(\\frac{\\partial J}{\\partial p_1}, \\frac{\\partial J}{\\partial p_2}\\right)$。对于上述显式欧拉格式，伴随变量 $\\lambda^k \\in \\mathbb{R}^{N_x}$ 的伴随递归关系为\n$$\\lambda^N = \\Delta x \\left(c^N - c^\\star\\right),\\quad \\lambda^k = M(p)^\\top \\lambda^{k+1},\\quad k = N-1,\\dots,0,$$\n参数梯度的分量为\n$$\\frac{\\partial J}{\\partial u} = \\sum_{k=0}^{N-1} \\left(\\lambda^{k+1}\\right)^\\top \\left(\\frac{\\partial M}{\\partial u}\\right) c^k,\\quad \\frac{\\partial M}{\\partial u} = -\\Delta t \\, D_u,$$\n$$\\frac{\\partial J}{\\partial \\beta} = \\sum_{k=0}^{N-1} \\left(\\lambda^{k+1}\\right)^\\top \\left(\\frac{\\partial M}{\\partial \\beta}\\right) c^k,\\quad \\frac{\\partial M}{\\partial \\beta} = \\Delta t \\, \\kappa \\, D_2.$$\n\n为每个分量 $i \\in \\{1,2\\}$ 设计并实现一个使用中心差分近似的有限差分梯度检验：\n$$\\mathrm{FD}_i(\\epsilon) = \\frac{J\\left(p + \\epsilon e_i\\right) - J\\left(p - \\epsilon e_i\\right)}{2\\epsilon},$$\n其中 $e_i$ 是 $\\mathbb{R}^2$ 中的第 $i$ 个标准基向量，$\\epsilon$ 是一个标量步长。通过计算相对误差，比较 $\\mathrm{FD}_i(\\epsilon)$ 与伴随梯度 $\\frac{\\partial J}{\\partial p_i}$\n$$E_i(\\epsilon) = \\frac{\\left|\\mathrm{FD}_i(\\epsilon) - \\frac{\\partial J}{\\partial p_i}\\right|}{\\left|\\frac{\\partial J}{\\partial p_i}\\right| + 10^{-14}}.$$\n\n在讨论中，阐述影响 $E_i(\\epsilon)$ 的步长选择权衡，包括中心差分公式中与 $\\epsilon^2$ 成比例的截断误差，以及与 $\\epsilon$ 成反比的浮点舍入效应，还有机器精度的作用。通过 Courant-Friedrichs-Lewy (CFL) 条件将 $\\Delta t$ 的选择与稳定性和准确性联系起来，以确保在不同扰动参数下的比较是有意义的。\n\n使用以下科学上一致的配置：\n- 域长度 $L = 1000$ $\\mathrm{m}$。\n- 网格点数 $N_x = 128$。\n- 名义参数 $u = 0.12$ $\\mathrm{m/s}$ 和 $\\kappa = 5\\times 10^{-3}$ $\\mathrm{m^2/s}$，其中 $\\beta = \\log(\\kappa)$。\n- 根据名义参数计算一次的固定时间步长为 $$\\Delta t = 0.4 \\times \\min\\left(\\frac{\\Delta x}{u}, \\frac{\\Delta x^2}{2\\kappa}\\right),$$ 总时间 $T = 2048$ $\\mathrm{s}$，得到 $N = \\lfloor T/\\Delta t \\rfloor$。\n- 假设 $u$ 严格为正，因此上述迎风格式定义无需切换。\n\n实现一个程序，该程序：\n1. 构建离散算子并执行前向模拟以计算 $J(p)$。\n2. 计算离散伴随以评估 $\\nabla_p J(p)$。\n3. 对于下面测试套件中的每个测试步长 $\\epsilon$，为 $i=1,2$ 评估 $\\mathrm{FD}_i(\\epsilon)$，计算相对误差 $E_i(\\epsilon)$，并返回各分量中的最大值 $E_{\\max}(\\epsilon) = \\max\\left(E_1(\\epsilon), E_2(\\epsilon)\\right)$。\n\n步长测试套件（分别加到 $u$ 和 $\\beta$ 上的无量纲标量）：\n- $\\epsilon = 10^{-1}$ （粗略，截断误差主导区），\n- $\\epsilon = 10^{-3}$ （中等），\n- $\\epsilon = 10^{-5}$ （精细），\n- $\\epsilon = 10^{-7}$ （非常精细），\n- $\\epsilon = 10^{-9}$ （接近舍入影响区），\n- $\\epsilon = 10^{-11}$ （极端，舍入误差主导区）。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果，顺序与上面列出的步长顺序相同，每个条目是作为浮点数的 $E_{\\max}(\\epsilon)$（例如，“[r1,r2,r3,r4,r5,r6]”）。内部使用的所有物理量必须与指定的单位保持一致。未使用角度；如果出现任何角度，默认必须解释为弧度。最终输出是定义的无单位相对误差。",
            "solution": "该问题被评估为**有效**。它提出了计算科学中一个适定、有科学依据的任务，具体是离散伴随法在一维平流-扩散模型灵敏度分析中的应用。所有参数、方程和数值方法都得到了明确和一致的定义，构成了一个自洽且可验证的问题。\n\n解决方案首先对控制偏微分方程进行离散化，然后按规定实现前向和伴随模型，最后执行有限差分梯度检验以验证伴随法的实现。\n\n### 1. 控制方程的离散化\n\n控制方程为一维平流-扩散方程：\n$$\n\\frac{\\partial c}{\\partial t} = -u \\frac{\\partial c}{\\partial x} + \\kappa \\frac{\\partial^2 c}{\\partial x^2}\n$$\n长度为 $L$ 的空间域被离散为 $N_x$ 个网格点 $x_i = i \\Delta x$，其中 $i=0, \\dots, N_x-1$，网格间距为 $\\Delta x = L/N_x$。示踪剂浓度 $c(x,t)$ 由状态向量 $c(t) \\in \\mathbb{R}^{N_x}$ 表示，其中 $(c(t))_i = c(x_i, t)$。\n\n空间导数算子使用带周期性边界条件的有限差分法进行离散化。\n对于 $u>0$，一阶迎风平流算子由 $(D_u c)_i = (c_i - c_{i-1}) / \\Delta x$ 给出。这可以由一个循环矩阵 $D_u$ 表示。\n二阶中心差分扩散算子为 $(D_2 c)_i = (c_{i-1} - 2c_i + c_{i+1}) / \\Delta x^2$，它也由一个循环矩阵 $D_2$ 表示。\n\n### 2. 前向模型\n\n时间积分使用显式欧拉法，并采用固定的时间步长 $\\Delta t$。离散状态向量 $c^k$ 在时间步 $k$ 按以下线性映射演化：\n$$\nc^{k+1} = M(p) \\, c^k\n$$\n其中 $p = (u, \\beta)$ 是参数向量，且 $\\kappa = \\exp(\\beta)$。传播矩阵 $M(p)$ 定义为：\n$$\nM(p) = I + \\Delta t \\left(-u D_u + \\kappa D_2\\right)\n$$\n其中 $I$ 是 $N_x \\times N_x$ 的单位矩阵。\n\n模拟从指定的初始条件 $c^0_i = \\sin(2\\pi x_i/L) + \\frac{1}{2}\\sin(4\\pi x_i/L)$ 开始，运行 $N = \\lfloor T/\\Delta t \\rfloor$ 步，以获得最终状态 $c^N$。时间步长 $\\Delta t$ 根据名义参数固定，通过 Courant-Friedrichs-Lewy (CFL) 条件确保显式格式的稳定性：\n$$\n\\Delta t = 0.4 \\times \\min\\left(\\frac{\\Delta x}{u_{\\text{nom}}}, \\frac{\\Delta x^2}{2\\kappa_{\\text{nom}}}\\right)\n$$\n\n待最小化的目标函数是衡量最终状态 $c^N$ 与目标状态 $c^\\star = 0$ 之间差异的度量：\n$$\nJ(p) = \\frac{1}{2} \\Delta x \\sum_{i=0}^{N_x-1} (c^N_i - c^\\star_i)^2 = \\frac{1}{2} \\Delta x \\|c^N\\|_2^2\n$$\n\n### 3. 离散伴随模型\n\n目标是计算目标函数关于参数的梯度 $\\nabla_p J$。离散伴随法为此提供了一种有效的方法。我们引入一个离散拉格朗日量：\n$$\n\\mathcal{L}(c^{0..N}, \\lambda^{1..N}, p) = J(c^N) - \\sum_{k=0}^{N-1} (\\lambda^{k+1})^\\top \\left( c^{k+1} - M(p) c^k \\right)\n$$\n其中 $\\lambda^k \\in \\mathbb{R}^{N_x}$ 是伴随变量（拉格朗日乘子）。通过要求 $\\mathcal{L}$ 对每个状态变量 $c^k$ 的梯度为零，我们推导出伴随方程。\n对于最终状态 $c^N$：\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial c^N} = \\nabla_{c^N} J - \\lambda^N = 0 \\implies \\lambda^N = \\nabla_{c^N} J = \\Delta x \\, c^N\n$$\n对于中间状态 $c^k$，其中 $k=1, \\dots, N-1$：\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial c^k} = (\\lambda^{k+1})^\\top M(p) - \\lambda^k = 0 \\implies \\lambda^k = M(p)^\\top \\lambda^{k+1}\n$$\n这些方程定义了伴随变量的递推关系，通过从 $\\lambda^N$ 开始向后推进时间来计算。\n\n一旦前向历史 $c^k$ 和伴随历史 $\\lambda^k$ 已知，目标函数的梯度可以通过对拉格朗日量关于参数 $p$ 求导得到：\n$$\n\\nabla_p J = \\frac{d\\mathcal{L}}{dp} = \\frac{\\partial \\mathcal{L}}{\\partial p} = \\sum_{k=0}^{N-1} (\\lambda^{k+1})^\\top \\frac{\\partial M(p)}{\\partial p} c^k\n$$\n对于 $p_1=u$ 和 $p_2=\\beta$ 的具体分量为：\n$$\n\\frac{\\partial J}{\\partial u} = \\sum_{k=0}^{N-1} (\\lambda^{k+1})^\\top \\left(\\frac{\\partial M}{\\partial u}\\right) c^k, \\quad \\text{其中} \\quad \\frac{\\partial M}{\\partial u} = -\\Delta t \\, D_u\n$$\n$$\n\\frac{\\partial J}{\\partial \\beta} = \\sum_{k=0}^{N-1} (\\lambda^{k+1})^\\top \\left(\\frac{\\partial M}{\\partial \\beta}\\right) c^k, \\quad \\text{其中} \\quad \\frac{\\partial M}{\\partial \\beta} = \\Delta t \\frac{\\partial \\kappa}{\\partial \\beta} D_2 = \\Delta t \\, e^\\beta D_2 = \\Delta t \\, \\kappa \\, D_2\n$$\n因此，该算法包括：\n1. 从 $k=0$ 到 $N$ 运行前向模型，存储整个状态历史 $\\{c^k\\}_{k=0}^N$。\n2. 初始化伴随变量 $\\lambda^N$。\n3. 从 $k=N-1$ 到 $0$ 向后运行伴随模型，在每一步使用存储的前向状态 $c^k$ 和计算出的伴随变量 $\\lambda^{k+1}$ 累积梯度贡献。\n\n### 4. 梯度验证和步长选择\n\n伴随梯度实现的正确性通过与有限差分近似进行比较来验证。为获得更高的精度，使用中心差分格式：\n$$\n\\mathrm{FD}_i(\\epsilon) = \\frac{J(p + \\epsilon e_i) - J(p - \\epsilon e_i)}{2\\epsilon}\n$$\n其中 $e_i$ 是一个标准基向量。相对误差 $E_i(\\epsilon)$ 衡量其差异：\n$$\nE_i(\\epsilon) = \\frac{\\left| \\mathrm{FD}_i(\\epsilon) - \\frac{\\partial J}{\\partial p_i} \\right|}{\\left| \\frac{\\partial J}{\\partial p_i} \\right| + \\delta}\n$$\n其中 $\\delta=10^{-14}$ 是一个小的正则化项，以防止除以零。\n\n步长 $\\epsilon$ 的选择至关重要。中心差分近似的误差主要有两个来源：\n1.  **截断误差**：$J$ 的泰勒展开表明，中心差分公式的主导误差项与 $\\epsilon^2$ 成正比。当 $\\epsilon$ 变小时，此误差减小。\n2.  **舍入误差**：当 $\\epsilon$ 变得非常小时，计算 $J(p + \\epsilon e_i) - J(p - \\epsilon e_i)$ 会遭受灾难性抵消（减法抵消），因为两项变得几乎相同。这种精度的损失，再加上除以一个非常小的 $2\\epsilon$，导致舍入误差增长，通常与 $1/\\epsilon$ 成比例。\n\n总误差是这两种效应之和。因此，在对数-对数坐标图上，$E_i(\\epsilon)$ 与 $\\epsilon$ 的关系图通常呈现“V”形。对于大的 $\\epsilon$，误差由截断误差主导，并随 $\\epsilon$ 减小。对于非常小的 $\\epsilon$，误差由舍入误差主导，并随 $\\epsilon$ 减小而增大。使总误差最小的最优 $\\epsilon$ 位于此“V”形的底部，平衡了这两种误差源。问题中提供的 $\\epsilon$ 值测试套件旨在跨越这些区域对误差进行采样，从截断误差主导区（$\\epsilon=10^{-1}$）到舍入误差主导区（$\\epsilon=10^{-11}$）。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of computing and verifying the adjoint gradient for a 1D\n    advection-diffusion model.\n    \"\"\"\n    # ------------------\n    # 1. Configuration and Setup\n    # ------------------\n    # Physical and numerical constants\n    L = 1000.0          # Domain length [m]\n    Nx = 128            # Number of grid points\n    u_nom = 0.12        # Nominal velocity [m/s]\n    kappa_nom = 5e-3    # Nominal diffusivity [m^2/s]\n    T = 2048.0          # Total time [s]\n    \n    # Test suite for finite difference step size\n    eps_test_suite = [1e-1, 1e-3, 1e-5, 1e-7, 1e-9, 1e-11]\n\n    # Derived parameters\n    dx = L / Nx\n    x_grid = np.arange(Nx) * dx\n    beta_nom = np.log(kappa_nom)\n    p_nom = np.array([u_nom, beta_nom])\n\n    # Construct discrete operators using dense matrices as Nx is small\n    def get_operators(Nx_in, dx_in):\n        # First-order upwind advection operator D_u for u > 0\n        # (D_u c)_i = (c_i - c_{i-1}) / dx\n        Du = (np.diag(np.ones(Nx_in)) - np.diag(np.ones(Nx_in - 1), k=-1)) / dx_in\n        Du[0, -1] = -1.0 / dx_in  # Periodic boundary condition\n        \n        # Second-order central difference diffusion operator D_2\n        # (D_2 c)_i = (c_{i-1} - 2c_i + c_{i+1}) / dx^2\n        D2 = (np.diag(np.ones(Nx_in - 1), k=-1) - 2 * np.diag(np.ones(Nx_in)) + \n              np.diag(np.ones(Nx_in - 1), k=1)) / dx_in**2\n        D2[0, -1] = 1.0 / dx_in**2  # Periodic BC\n        D2[-1, 0] = 1.0 / dx_in**2  # Periodic BC\n        return Du, D2\n\n    Du, D2 = get_operators(Nx, dx)\n\n    # Calculate fixed time step based on nominal CFL condition\n    cfl_adv_nom = dx / u_nom\n    cfl_diff_nom = dx**2 / (2 * kappa_nom)\n    dt = 0.4 * min(cfl_adv_nom, cfl_diff_nom)\n    N = int(np.floor(T / dt))\n\n    # Initial condition\n    c0 = np.sin(2 * np.pi * x_grid / L) + 0.5 * np.sin(4 * np.pi * x_grid / L)\n\n    # ------------------\n    # 2. Forward and Adjoint Solvers\n    # ------------------\n    # Function to run the forward model and compute objective J\n    def compute_j(p_vec):\n        u_p, beta_p = p_vec\n        kappa_p = np.exp(beta_p)\n        \n        # Forward model propagator matrix M(p)\n        M_p = np.eye(Nx) + dt * (-u_p * Du + kappa_p * D2)\n        \n        # Time-stepping loop\n        c_k = c0.copy()\n        for _ in range(N):\n            c_k = M_p @ c_k\n        c_N = c_k\n        \n        # Objective function J\n        J = 0.5 * dx * np.sum(c_N**2)\n        return J\n\n    # Function to compute the adjoint gradient\n    def compute_adjoint_gradient(p_vec):\n        u_p, beta_p = p_vec\n        kappa_p = np.exp(beta_p)\n        \n        # Propagator matrix M(p) and its transpose\n        M_p = np.eye(Nx) + dt * (-u_p * Du + kappa_p * D2)\n        MT_p = M_p.T\n        \n        # Run forward model and store state history\n        c_hist = np.zeros((N + 1, Nx))\n        c_hist[0] = c0\n        for k in range(N):\n            c_hist[k+1] = M_p @ c_hist[k]\n        c_N = c_hist[-1]\n        \n        # Derivatives of M with respect to parameters\n        dM_du = -dt * Du\n        dM_dbeta = dt * kappa_p * D2\n        \n        # Initialize adjoint variable and gradients\n        lambda_next_k = dx * c_N  # This is lambda^N\n        grad_u = 0.0\n        grad_beta = 0.0\n        \n        # Backward time-stepping for adjoint variable and gradient accumulation\n        for k in range(N - 1, -1, -1):\n            # At step k, lambda_next_k holds lambda^{k+1}\n            c_k = c_hist[k]\n            \n            # Accumulate gradient contributions\n            grad_u += lambda_next_k.T @ dM_du @ c_k\n            grad_beta += lambda_next_k.T @ dM_dbeta @ c_k\n            \n            # Update adjoint variable: lambda^k = M^T lambda^{k+1}\n            lambda_next_k = MT_p @ lambda_next_k\n        \n        return np.array([grad_u, grad_beta])\n\n    # ------------------\n    # 3. Gradient Calculation and Verification\n    # ------------------\n    # Compute adjoint gradient at the nominal parameter values\n    adj_grad = compute_adjoint_gradient(p_nom)\n\n    results = []\n    # Loop through the test suite of epsilons for the finite-difference check\n    for eps in eps_test_suite:\n        # Finite difference for p1 = u\n        p_plus_u = np.array([p_nom[0] + eps, p_nom[1]])\n        p_minus_u = np.array([p_nom[0] - eps, p_nom[1]])\n        J_plus_u = compute_j(p_plus_u)\n        J_minus_u = compute_j(p_minus_u)\n        fd_grad_u = (J_plus_u - J_minus_u) / (2 * eps)\n        \n        # Finite difference for p2 = beta\n        p_plus_beta = np.array([p_nom[0], p_nom[1] + eps])\n        p_minus_beta = np.array([p_nom[0], p_nom[1] - eps])\n        J_plus_beta = compute_j(p_plus_beta)\n        J_minus_beta = compute_j(p_minus_beta)\n        fd_grad_beta = (J_plus_beta - J_minus_beta) / (2 * eps)\n        \n        # Compute relative errors\n        err_u = np.abs(fd_grad_u - adj_grad[0]) / (np.abs(adj_grad[0]) + 1e-14)\n        err_beta = np.abs(fd_grad_beta - adj_grad[1]) / (np.abs(adj_grad[1]) + 1e-14)\n        \n        # Store the maximum relative error for this epsilon\n        E_max = max(err_u, err_beta)\n        results.append(E_max)\n\n    # ------------------\n    # 4. Final Output\n    # ------------------\n    # Format results into a single string as specified.\n    print(f\"[{','.join(f'{r:.8e}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "复杂的海洋模型通常由多个模块化组件构成，例如动力核心、压力求解器等。点积测试是验证模型中单个线性算子及其伴随算子实现是否正确的强大工具。它直接检验了伴随的代数定义：对于一个线性算子 $J$、其伴随算子 $J^{\\dagger}$ 以及任意向量 $v$ 和 $w$，必须满足关系 $\\langle J v, w \\rangle_W = \\langle v, J^{\\dagger} w \\rangle_W$。本练习  以一个典型的压力求解器为例，不仅演示了如何执行点积测试，还强调了在非均匀网格上正确定义加权内积 $\\langle \\cdot, \\cdot \\rangle_W$ 的重要性，这是真实世界模型开发中的常见情况。",
            "id": "3813446",
            "problem": "考虑一个计算海洋学中简化的静压-修正模块。不可压缩 Boussinesq 流的连续性约束是质量守恒方程 $\\,\\nabla \\cdot \\mathbf{u} = 0\\,$。在压力-修正方案中，压力增量 $\\,p\\,$ 是通过求解一个线性椭圆偏微分方程 (PDE) 得到的，该方程可以写成如下的典范形式\n$$\n-\\nabla \\cdot \\left( K \\nabla p \\right) + \\alpha p = b,\n$$\n其中 $\\,K \\ge 0\\,$ 表示一个空间变化的对称正标量场（例如，一个结合了物理权重和数值权重的有效类电导系数），$\\,\\alpha \\ge 0\\,$ 是边界附近的海绵层或惩罚项，$\\,b\\,$ 是由中间速度场的散度产生的已知源项。我们考虑一个二维、直线、单元中心网格，其网格间距 $\\,\\Delta x_i\\,$ 和 $\\,\\Delta y_j\\,$ （单位为米）可能不均匀。离散算子 $\\,J\\,$ 将一个单元中心的向量 $\\,p \\in \\mathbb{R}^{N}\\,$, 其中 $\\,N = n_x n_y\\,$, 映射到残差 $\\,r = J p\\,$，该残差通过穿过单元面的相容通量构建。对于每个宽度为 $\\,\\Delta x_i\\,$ 和 $\\,\\Delta y_j\\,$ 的单元 $\\,\\{i,j\\}\\,$，定义面间距\n$$\n\\delta x_{i\\pm\\frac{1}{2}}=\n\\begin{cases}\n\\frac{1}{2}\\left(\\Delta x_i + \\Delta x_{i\\pm 1}\\right)  \\text{如果邻居存在},\\\\\n\\frac{1}{2}\\Delta x_i  \\text{在狄利克雷边界处},\n\\end{cases}\n\\qquad\n\\delta y_{j\\pm\\frac{1}{2}}=\n\\begin{cases}\n\\frac{1}{2}\\left(\\Delta y_j + \\Delta y_{j\\pm 1}\\right)  \\text{如果邻居存在},\\\\\n\\frac{1}{2}\\Delta y_j  \\text{在狄利克雷边界处}。\n\\end{cases}\n$$\n设算术平均的面值\n$$\nK_{i\\pm\\frac{1}{2},j}=\n\\begin{cases}\n\\frac{1}{2}\\left(K_{i,j}+K_{i\\pm 1,j}\\right)  \\text{如果邻居存在},\\\\\nK_{i,j}  \\text{在狄利克雷边界处},\n\\end{cases}\n\\qquad\nK_{i,j\\pm\\frac{1}{2}}=\n\\begin{cases}\n\\frac{1}{2}\\left(K_{i,j}+K_{i,j\\pm 1}\\right)  \\text{如果邻居存在},\\\\\nK_{i,j}  \\text{在狄利克雷边界处}。\n\\end{cases}\n$$\n那么，单元 $\\{i,j\\}$ 上的离散残差 $r_{i,j}$ 由通量差除以单元尺寸构建，形成一个五点格式。其对角系数为：\n$$\nd_{i,j} = \\frac{K_{i+\\frac{1}{2},j}}{\\delta x_{i+\\frac{1}{2}}\\Delta x_i} + \\frac{K_{i-\\frac{1}{2},j}}{\\delta x_{i-\\frac{1}{2}}\\Delta x_i} + \\frac{K_{i,j+\\frac{1}{2}}}{\\delta y_{j+\\frac{1}{2}}\\Delta y_j} + \\frac{K_{i,j-\\frac{1}{2}}}{\\delta y_{j-\\frac{1}{2}}\\Delta y_j} + \\alpha_{i,j},\n$$\n与邻居 $\\{i\\pm 1,j\\}$ 和 $\\{i,j\\pm 1\\}$ 相关的非对角系数分别为：\n$$\n-\\frac{K_{i+\\frac{1}{2},j}}{\\delta x_{i+\\frac{1}{2}}\\Delta x_i},\\quad -\\frac{K_{i-\\frac{1}{2},j}}{\\delta x_{i-\\frac{1}{2}}\\Delta x_i},\\quad -\\frac{K_{i,j+\\frac{1}{2}}}{\\delta y_{j+\\frac{1}{2}}\\Delta y_j},\\quad -\\frac{K_{i,j-\\frac{1}{2}}}{\\delta y_{j-\\frac{1}{2}}\\Delta y_j}.\n$$\n狄利克雷边界通过将外部值置零来实施，这仅通过边界面项对对角线产生贡献。这样就得到了一个稀疏矩阵 $J \\in \\mathbb{R}^{N\\times N}$，其关于下面定义的加权内积是自伴随的（self-adjoint）。\n\n在 $\\,\\mathbb{R}^{N}\\,$ 上定义离散加权内积为\n$$\n\\langle x,y \\rangle_W = x^\\top W y,\n$$\n其中对角正权重 $\\,W = \\operatorname{diag}(A_{i,j})\\,$，$\\,A_{i,j} = \\Delta x_i \\Delta y_j\\,$ 是单元面积，单位为平方米。$\\,J\\,$ 关于此加权内积的伴随是 $\\,W$-伴随\n$$\nJ^{\\dagger} = W^{-1} J^\\top W.\n$$\n点积测试断言，对于任意向量 $\\,v,w \\in \\mathbb{R}^{N}\\,$,\n$$\n\\langle J v, w \\rangle_W = \\langle v, J^{\\dagger} w \\rangle_W.\n$$\n\n您的任务是为上述离散算子 $\\,J\\,$ 和内积 $\\,\\langle \\cdot,\\cdot \\rangle_W\\,$ 实现点积测试。对于每个测试用例，构建 $\\,J\\,$、$\\,W\\,$ 以及随机向量 $\\,v\\,$ 和 $\\,w\\,$（使用固定的随机种子以确保可复现性），计算两个内积，并评估相对误差\n$$\n\\mathrm{err} = \\frac{\\left|\\langle J v, w \\rangle_W - \\langle v, J^{\\dagger} w \\rangle_W\\right|}{\\max\\left(1,\\left|\\langle J v, w \\rangle_W\\right|,\\left|\\langle v, J^{\\dagger} w \\rangle_W\\right|\\right)}.\n$$\n如果一个测试用例的 $\\,\\mathrm{err} \\le \\tau\\,$，其中 $\\,\\tau\\,$ 是其指定的阈值，则认为该测试用例通过。\n\n实现程序以运行以下测试套件，该套件涵盖了一般情况、非均匀网格和系数、小网格边界情况以及海绵区域情况。在所有情况下，均不涉及角度。网格间距 $\\,\\Delta x_i\\,$ 和 $\\,\\Delta y_j\\,$ 的单位为米。\n\n- 测试用例 $\\,1\\,$（均匀网格，均匀系数）：$\\,n_x = 5\\,$，$\\,n_y = 4\\,$，对所有 $\\,i\\,$ 有 $\\,\\Delta x_i = 1000\\,$，对所有 $\\,j\\,$ 有 $\\,\\Delta y_j = 1000\\,$，对所有单元有 $\\,K_{i,j} = 1\\,$，对所有单元有 $\\,\\alpha_{i,j} = 0\\,$，阈值 $\\,\\tau = 10^{-12}\\,$。\n\n- 测试用例 $\\,2\\,$（非均匀网格，平滑变化系数）：$\\,n_x = 7\\,$，$\\,n_y = 6\\,$，\n$$\n\\Delta x_i = 1000 \\left(1 + 0.2 \\sin\\left(\\frac{\\pi i}{n_x-1}\\right)\\right),\\quad i=0,\\ldots,n_x-1,\n$$\n$$\n\\Delta y_j = 900 \\left(1 + 0.3 \\cos\\left(\\frac{\\pi j}{n_y-1}\\right)\\right),\\quad j=0,\\ldots,n_y-1,\n$$\n$$\nK_{i,j} = 0.7 + 0.3 \\sin\\left(\\frac{2\\pi i}{n_x}\\right)\\cos\\left(\\frac{2\\pi j}{n_y}\\right),\n$$\n对所有单元有 $\\,\\alpha_{i,j} = 0\\,$，阈值 $\\,\\tau = 10^{-12}\\,$。\n\n- 测试用例 $\\,3\\,$（小网格，边界惩罚）：$\\,n_x = 2\\,$，$\\,n_y = 2\\,$，$\\,\\Delta x_0 = 500\\,$，$\\,\\Delta x_1 = 1500\\,$，$\\,\\Delta y_0 = 800\\,$，$\\,\\Delta y_1 = 1200\\,$，\n$$\nK_{i,j} = 1 + 0.2 i + 0.1 j,\n$$\n$$\n\\alpha_{i,j} =\n\\begin{cases}\n10^{-3}  \\text{如果 } i\\in\\{0,n_x-1\\} \\text{ 或 } j\\in\\{0,n_y-1\\},\\\\\n0  \\text{否则},\n\\end{cases}\n$$\n阈值 $\\,\\tau = 10^{-12}\\,$。\n\n- 测试用例 $\\,4\\,$（沿一个边界的海绵区域）：$\\,n_x = 8\\,$，$\\,n_y = 3\\,$，\n$$\n\\Delta x_i = 1000 \\left(1 + 0.1 \\sin\\left(\\frac{2\\pi i}{n_x}\\right)\\right),\\quad \\Delta y_j = 1200 \\left(1 + 0.2 \\cos\\left(\\frac{2\\pi j}{n_y}\\right)\\right),\n$$\n$$\nK_{i,j} = 1 + 0.5 \\left(\\frac{i}{n_x-1}\\right)^2 + 0.25 \\left(\\frac{j}{n_y-1}\\right),\n$$\n$$\n\\alpha_{i,j} =\n\\begin{cases}\n10^{-2}  \\text{如果 } i = 0,\\\\\n0  \\text{否则},\n\\end{cases}\n$$\n阈值 $\\,\\tau = 10^{-12}\\,$。\n\n每个测试的随机向量 $\\,v\\,$ 和 $\\,w\\,$ 应使用固定种子 $\\,s = 12345\\,$ 从标准正态分布中独立抽取，并重塑为适当的大小 $\\,N = n_x n_y\\,$。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$\\,[$result1,result2,result3,result4$]\\,$），其中每个 $\\,\\text{result}_k\\,$ 是一个布尔值，表示测试用例 $\\,k\\,$ 是否通过了其指定阈值的点积测试。",
            "solution": "问题陈述提出了一个在偏微分方程数值求解器开发中标准的验证任务，具体来说是针对一个离散椭圆算子的点积测试。其目标是验证算子及其关于加权内积的伴随算子的实现是否正确。\n\n首先，需要对问题的设定进行细致的验证。问题描述了一个椭圆偏微分方程 $-\\nabla \\cdot (K \\nabla p) + \\alpha p = b$ 在二维、单元中心、直线网格上的有限体积离散化。所提供的离散算子（我们用矩阵 $J$ 表示）的格式系数公式与标准的单元中心有限体积法一致。\n\n一个关键的审查点是这句话：“这样就得到了一个稀疏、对称正定矩阵 $J \\in \\mathbb{R}^{N\\times N}$”。让我们来验证其对称性，即 $J = J^\\top$。$J$ 中将变量 $p_{i,j}$（在扁平化索引 $k$ 处）耦合到其邻居 $p_{i+1,j}$（在扁平化索引 $l$ 处）的元素由第 $k$ 行对应于第 $l$ 列的系数给出：\n$$\nJ_{k,l} = -\\frac{K_{i+\\frac{1}{2},j}}{\\delta x_{i+\\frac{1}{2}}\\Delta x_i}\n$$\n反之，将 $p_{i+1,j}$ 耦合到 $p_{i,j}$ 的元素出现在第 $l$ 行和第 $k$ 列：\n$$\nJ_{l,k} = -\\frac{K_{i+1-\\frac{1}{2},j}}{\\delta x_{i+1-\\frac{1}{2}}\\Delta x_{i+1}} = -\\frac{K_{i+\\frac{1}{2},j}}{\\delta x_{i+\\frac{1}{2}}\\Delta x_{i+1}}\n$$\n对于一个普遍的非均匀网格，其中 $\\Delta x_i \\neq \\Delta x_{i+1}$，很明显 $J_{k,l} \\neq J_{l,k}$。因此，矩阵 $J$ 通常是**不**对称的。\n\n然而，这并不会使问题无效。当方程按单元体积（在二维中是面积）进行归一化时，这种非对称矩阵是非均匀网格上有限体积离散化的特征。物理上重要的性质是连续算子 $-\\nabla \\cdot (K \\nabla \\cdot)$ 相对于标准的 $L^2$ 内积是自伴的。它的离散对应物 $J$ 应该相对于一个离散加权内积是自伴的，其中权重是单元体积（面积）。\n\n问题将此加权内积定义为 $\\langle x, y \\rangle_W = x^\\top W y$，其中 $W$ 是由单元面积 $A_{i,j} = \\Delta x_i \\Delta y_j$ 构成的对角矩阵。如果对于所有 $x,y$，都有 $\\langle Jx, y \\rangle_W = \\langle x, Jy \\rangle_W$，则算子 $J$ 关于此内积是自伴的。这等价于矩阵乘积 $WJ$ 是对称的，即 $(WJ)^\\top = WJ$。让我们对对应于单元 $(i,j)$ 和 $(i+1,j)$ 之间耦合的非对角元素来验证这一点：\n$$\n(WJ)_{k,l} = W_{k,k} J_{k,l} = (\\Delta x_i \\Delta y_j) \\left( -\\frac{K_{i+\\frac{1}{2},j}}{\\delta x_{i+\\frac{1}{2}}\\Delta x_i} \\right) = - \\frac{K_{i+\\frac{1}{2},j} \\Delta y_j}{\\delta x_{i+\\frac{1}{2}}}\n$$\n$$\n(WJ)_{l,k} = W_{l,l} J_{l,k} = (\\Delta x_{i+1} \\Delta y_j) \\left( -\\frac{K_{i+\\frac{1}{2},j}}{\\delta x_{i+\\frac{1}{2}}\\Delta x_{i+1}} \\right) = - \\frac{K_{i+\\frac{1}{2},j} \\Delta y_j}{\\delta x_{i+\\frac{1}{2}}}\n$$\n它们确实相等。对于 $y$ 方向的耦合，也存在类似的论证。因此，矩阵 $WJ$ 是对称的。这个性质 $(WJ)^\\top = WJ$ 意味着 $J^\\top W = WJ$。左乘 $W^{-1}$，我们得到 $W^{-1} J^\\top W = J$。问题将 $W$-伴随定义为 $J^{\\dagger} = W^{-1} J^\\top W$。因此，我们已经证明了 $J = J^{\\dagger}$，这意味着算子关于加权内积是自伴的。问题描述中的微小术语不准确（称 $J$ 为对称而非 $W$-对称或自伴）已被注意到，但其底层的数学结构是健全和一致的。\n\n点积测试验证恒等式 $\\langle J v, w \\rangle_W = \\langle v, J^{\\dagger} w \\rangle_W$，是代码验证的一个基本工具。给定定义 $J^{\\dagger} = W^{-1} J^\\top W$，该恒等式是一个数学上的重言式：\n$$\n\\langle v, J^{\\dagger} w \\rangle_W = v^\\top W (J^{\\dagger} w) = v^\\top W (W^{-1} J^\\top W) w = v^\\top (W W^{-1}) J^\\top (W w) = v^\\top J^\\top W w = (Jv)^\\top W w = \\langle J v, w \\rangle_W\n$$\n因此，测试的目的不是证明这个恒等式，而是确保矩阵 $J$、权重矩阵 $W$、矩阵-向量乘积以及伴随计算 $J^\\dagger = W^{-1}J^\\top W$ 的数值实现都是正确的。测试应该在机器浮点精度范围内通过。\n\n解决此问题的步骤如下：\n1.  对于每个测试用例，定义网格维度 ($n_x, n_y$)、网格间距 ($\\Delta x, \\Delta y$) 和系数场 ($K, \\alpha$)。\n2.  根据提供的五点格式公式构建 $N \\times N$ 矩阵 $J$（其中 $N=n_x n_y$），并仔细处理边界条件。\n3.  构建 $N \\times N$ 对角权重矩阵 $W$，其对角线元素是单元面积 $A_{i,j} = \\Delta x_i \\Delta y_j$。\n4.  使用指定的种子初始化一个随机数生成器，并生成两个随机向量 $v, w \\in \\mathbb{R}^N$。\n5.  计算伴随矩阵 $J^\\dagger = W^{-1} J^\\top W$。由于 $W$ 是对角矩阵， $W^{-1}$ 就是单元面积倒数的对角矩阵。\n6.  计算点积测试的左侧 (LHS)：$\\text{LHS} = (Jv)^\\top Ww$。\n7.  计算点积测试的右侧 (RHS)：$\\text{RHS} = v^\\top W(J^\\dagger w)$。\n8.  计算相对误差：$\\text{err} = |\\text{LHS} - \\text{RHS}| / \\max(1, |\\text{LHS}|, |\\text{RHS}|)$。\n9.  如果 $\\text{err} \\le \\tau$，则测试用例通过，其中 $\\tau$ 是指定的阈值。\n\n将对所有四个测试用例实施此程序，以确定它们的通过/失败状态。考虑到网格维度较小，使用密集的 NumPy 数组足以表示这些矩阵。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef build_J_matrix(nx, ny, dx, dy, K, alpha):\n    \"\"\"\n    Constructs the discrete operator matrix J based on the problem specification.\n    \n    Args:\n        nx (int): Number of cells in the x-direction.\n        ny (int): Number of cells in the y-direction.\n        dx (np.ndarray): Array of cell widths, shape (nx,).\n        dy (np.ndarray): Array of cell heights, shape (ny,).\n        K (np.ndarray): Spatially varying coefficient, shape (nx, ny).\n        alpha (np.ndarray): Sponge/penalty term, shape (nx, ny).\n\n    Returns:\n        np.ndarray: The (N, N) operator matrix J, where N = nx * ny.\n    \"\"\"\n    N = nx * ny\n    J = np.zeros((N, N))\n\n    for i in range(nx):\n        for j in range(ny):\n            k = i * ny + j  # Row-major linear index for cell (i, j)\n\n            # ----- Diagonal term -----\n            d_ij = 0.0\n\n            # Right face (i + 1/2)\n            if i  nx - 1:\n                delta_x_ip12 = 0.5 * (dx[i] + dx[i+1])\n                K_ip12_j = 0.5 * (K[i, j] + K[i+1, j])\n            else: # Boundary face\n                delta_x_ip12 = 0.5 * dx[i]\n                K_ip12_j = K[i, j]\n            d_ij += K_ip12_j / (delta_x_ip12 * dx[i])\n\n            # Left face (i - 1/2)\n            if i > 0:\n                delta_x_im12 = 0.5 * (dx[i] + dx[i-1])\n                K_im12_j = 0.5 * (K[i, j] + K[i-1, j])\n            else: # Boundary face\n                delta_x_im12 = 0.5 * dx[i]\n                K_im12_j = K[i, j]\n            d_ij += K_im12_j / (delta_x_im12 * dx[i])\n\n            # Top face (j + 1/2)\n            if j  ny - 1:\n                delta_y_jp12 = 0.5 * (dy[j] + dy[j+1])\n                K_i_jp12 = 0.5 * (K[i, j] + K[i, j+1])\n            else: # Boundary face\n                delta_y_jp12 = 0.5 * dy[j]\n                K_i_jp12 = K[i, j]\n            d_ij += K_i_jp12 / (delta_y_jp12 * dy[j])\n\n            # Bottom face (j - 1/2)\n            if j > 0:\n                delta_y_jm12 = 0.5 * (dy[j] + dy[j-1])\n                K_i_jm12 = 0.5 * (K[i, j] + K[i, j-1])\n            else: # Boundary face\n                delta_y_jm12 = 0.5 * dy[j]\n                K_i_jm12 = K[i, j]\n            d_ij += K_i_jm12 / (delta_y_jm12 * dy[j])\n\n            # Add alpha term\n            d_ij += alpha[i, j]\n            J[k, k] = d_ij\n\n            # ----- Off-diagonal terms -----\n            # Right neighbor (i+1, j)\n            if i  nx - 1:\n                l = (i + 1) * ny + j\n                delta_x_ip12 = 0.5 * (dx[i] + dx[i+1])\n                K_ip12_j = 0.5 * (K[i, j] + K[i+1, j])\n                J[k, l] = -K_ip12_j / (delta_x_ip12 * dx[i])\n            \n            # Left neighbor (i-1, j)\n            if i > 0:\n                l = (i - 1) * ny + j\n                delta_x_im12 = 0.5 * (dx[i] + dx[i-1])\n                K_im12_j = 0.5 * (K[i, j] + K[i-1, j])\n                J[k, l] = -K_im12_j / (delta_x_im12 * dx[i])\n            \n            # Top neighbor (i, j+1)\n            if j  ny - 1:\n                l = i * ny + (j + 1)\n                delta_y_jp12 = 0.5 * (dy[j] + dy[j+1])\n                K_i_jp12 = 0.5 * (K[i, j] + K[i, j+1])\n                J[k, l] = -K_i_jp12 / (delta_y_jp12 * dy[j])\n            \n            # Bottom neighbor (i, j-1)\n            if j > 0:\n                l = i * ny + (j - 1)\n                delta_y_jm12 = 0.5 * (dy[j] + dy[j-1])\n                K_i_jm12 = 0.5 * (K[i, j] + K[i, j-1])\n                J[k, l] = -K_i_jm12 / (delta_y_jm12 * dy[j])\n    \n    return J\n\ndef run_dot_product_test(nx, ny, dx_func, dy_func, K_func, alpha_func, tau, seed):\n    \"\"\"\n    Runs a single dot-product test case.\n    \"\"\"\n    # 1. Setup grid and parameters\n    N = nx * ny\n    i_indices = np.arange(nx)\n    j_indices = np.arange(ny)\n\n    dx = dx_func(nx, i_indices)\n    dy = dy_func(ny, j_indices)\n    \n    K = np.zeros((nx, ny))\n    alpha = np.zeros((nx, ny))\n    for i in range(nx):\n        for j in range(ny):\n            K[i, j] = K_func(nx, ny, i, j)\n            alpha[i, j] = alpha_func(nx, ny, i, j)\n\n    # 2. Construct J matrix\n    J = build_J_matrix(nx, ny, dx, dy, K, alpha)\n\n    # 3. Construct W matrix\n    cell_areas = np.outer(dx, dy).flatten()\n    W = np.diag(cell_areas)\n    W_inv = np.diag(1.0 / cell_areas)\n\n    # 4. Generate random vectors\n    rng = np.random.default_rng(seed)\n    v = rng.standard_normal(N)\n    w = rng.standard_normal(N)\n\n    # 5. Compute adjoint J_dagger\n    J_dagger = W_inv @ J.T @ W\n\n    # 6. Calculate LHS and RHS\n    lhs = (J @ v).T @ W @ w\n    rhs = v.T @ W @ (J_dagger @ w)\n    \n    # 7. Calculate relative error\n    denominator = max(1.0, abs(lhs), abs(rhs))\n    err = abs(lhs - rhs) / denominator\n    \n    # 8. Compare with threshold\n    return err = tau\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = [\n        {\n            \"nx\": 5, \"ny\": 4, \"tau\": 1e-12,\n            \"dx_func\": lambda nx, i: np.full(nx, 1000.0),\n            \"dy_func\": lambda ny, j: np.full(ny, 1000.0),\n            \"K_func\": lambda nx, ny, i, j: 1.0,\n            \"alpha_func\": lambda nx, ny, i, j: 0.0,\n        },\n        {\n            \"nx\": 7, \"ny\": 6, \"tau\": 1e-12,\n            \"dx_func\": lambda nx, i: 1000 * (1 + 0.2 * np.sin(np.pi * i / (nx - 1) if nx > 1 else 0)),\n            \"dy_func\": lambda ny, j: 900 * (1 + 0.3 * np.cos(np.pi * j / (ny - 1) if ny > 1 else 0)),\n            \"K_func\": lambda nx, ny, i, j: 0.7 + 0.3 * np.sin(2*np.pi*i/nx) * np.cos(2*np.pi*j/ny),\n            \"alpha_func\": lambda nx, ny, i, j: 0.0,\n        },\n        {\n            \"nx\": 2, \"ny\": 2, \"tau\": 1e-12,\n            \"dx_func\": lambda nx, i: np.array([500.0, 1500.0]),\n            \"dy_func\": lambda ny, j: np.array([800.0, 1200.0]),\n            \"K_func\": lambda nx, ny, i, j: 1.0 + 0.2 * i + 0.1 * j,\n            \"alpha_func\": lambda nx, ny, i, j: 1e-3 if i in {0, nx-1} or j in {0, ny-1} else 0.0,\n        },\n        {\n            \"nx\": 8, \"ny\": 3, \"tau\": 1e-12,\n            \"dx_func\": lambda nx, i: 1000 * (1 + 0.1 * np.sin(2 * np.pi * i / nx)),\n            \"dy_func\": lambda ny, j: 1200 * (1 + 0.2 * np.cos(2 * np.pi * j / ny)),\n            \"K_func\": lambda nx, ny, i, j: 1.0 + 0.5 * (i / (nx-1 if nx > 1 else 1))**2 + 0.25 * (j / (ny-1 if ny > 1 else 1)),\n            \"alpha_func\": lambda nx, ny, i, j: 1e-2 if i == 0 else 0.0,\n        },\n    ]\n\n    results = []\n    seed = 12345\n    for case in test_cases:\n        passed = run_dot_product_test(\n            case[\"nx\"], case[\"ny\"], case[\"dx_func\"], case[\"dy_func\"], \n            case[\"K_func\"], case[\"alpha_func\"], case[\"tau\"], seed\n        )\n        results.append(passed)\n    \n    print(f\"[{','.join(str(r).lower() for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}