{
    "hands_on_practices": [
        {
            "introduction": "本章提供了一系列动手实践，旨在巩固您对变分资料同化方法的理解，从其贝叶斯根基到处理非线性问题的挑战。第一个练习将问题简化到最基本的形式：一个单一状态变量和一个单一观测。其目标是通过直接应用贝叶斯定理来推导最优估计（即分析场），从而揭示变分代价函数是如何作为高斯误差假设的直接结果而产生的。这项实践旨在建立关于如何融合先验知识（背景场）和新观测的基本直觉。",
            "id": "3864732",
            "problem": "考虑一个单网格单元的环境状态变量 $x$，它表示在遥感与环境建模系统中分析时刻的柱平均示踪剂浓度。您正在使用一次卫星观测执行三维变分(3D-Var)数据同化，它是四维变分(4D-Var)数据同化的时间无关极限。假设一个线性观测算子 $H=1$，因此观测模型为 $y=Hx+\\epsilon$，其中 $\\epsilon$ 是附加的零均值高斯仪器噪声。先验（背景）状态被建模为一个均值为 $x_b$、方差为 $B$ 的高斯随机变量。观测误差服从方差为 $R$ 的高斯分布。在这些假设下，最大后验(MAP)估计等于从线性高斯模型的贝叶斯定理推导出的二次 3D-Var 代价函数的最小值点。\n\n从高斯先验 $p(x)$ 和高斯似然 $p(y\\mid x)$ 的定义出发，使用贝叶斯定理构建后验 $p(x\\mid y)$，推导当 $H=1$ 时的标量 MAP 估计量 $x_a$ 和相关的分析方差 $\\sigma_a^2$。然后，对于 $x_b=2$，$B=4$，$y=5$，$H=1$ 和 $R=1$ 的情况，计算您的表达式。\n\n将最终答案以单行矩阵 $\\begin{pmatrix}x_a & \\sigma_a^2\\end{pmatrix}$ 的形式报告。数值需精确表示，无需四舍五入。",
            "solution": "该问题是有效的，因为它具有科学依据、是适定的、客观的，并包含了获得唯一解所需的所有信息。它代表了贝叶斯推断在数据同化背景下的一个标准应用。\n\n目标是推导最大后验(MAP)估计，记为分析状态 $x_a$，以及相应的分析方差 $\\sigma_a^2$。推导从贝叶斯定理开始，该定理将给定观测值 $y$ 时状态 $x$ 的后验概率与状态的先验概率以及给定状态时观测值的似然联系起来：\n\n$$p(x \\mid y) = \\frac{p(y \\mid x) p(x)}{p(y)}$$\n\n项 $p(y)$ 是一个归一化常数，与 $x$ 无关。因此，为了找到使后验概率最大化的 $x$ 值，我们可以写成：\n\n$$p(x \\mid y) \\propto p(y \\mid x) p(x)$$\n\n问题指定状态变量 $x$ 的高斯先验分布，其均值为 $x_b$（背景状态），方差为 $B$。其概率密度函数(PDF)为：\n\n$$p(x) = \\frac{1}{\\sqrt{2\\pi B}} \\exp\\left(-\\frac{1}{2} \\frac{(x - x_b)^2}{B}\\right)$$\n\n观测模型为 $y = Hx + \\epsilon$，其中 $H=1$，观测误差 $\\epsilon$ 服从零均值、方差为 $R$ 的高斯分布。这定义了似然函数 $p(y \\mid x)$，它是一个以 $Hx=x$ 为中心、方差为 $R$ 的关于 $y$ 的高斯分布：\n\n$$p(y \\mid x) = \\frac{1}{\\sqrt{2\\pi R}} \\exp\\left(-\\frac{1}{2} \\frac{(y - x)^2}{R}\\right)$$\n\n将先验和似然的PDF代入后验概率的正比关系式中，得到：\n\n$$p(x \\mid y) \\propto \\left[ \\frac{1}{\\sqrt{2\\pi R}} \\exp\\left(-\\frac{1}{2} \\frac{(y - x)^2}{R}\\right) \\right] \\left[ \\frac{1}{\\sqrt{2\\pi B}} \\exp\\left(-\\frac{1}{2} \\frac{(x - x_b)^2}{B}\\right) \\right]$$\n\n合并指数项并忽略常数系数，我们得到：\n\n$$p(x \\mid y) \\propto \\exp\\left(-\\frac{1}{2} \\left[ \\frac{(x - x_b)^2}{B} + \\frac{(y - x)^2}{R} \\right]\\right)$$\n\nMAP 估计 $x_a$ 是使这个后验概率最大化的 $x$ 值。最大化 $p(x \\mid y)$ 等价于最小化其自然对数的负值。这定义了 3D-Var 代价函数 $J(x)$：\n\n$$J(x) = \\frac{1}{2} \\left[ \\frac{(x - x_b)^2}{B} + \\frac{(y - x)^2}{R} \\right]$$\n\n为了找到 $J(x)$ 的最小值，我们计算它关于 $x$ 的一阶导数，并令其为零：\n\n$$\\frac{dJ}{dx} = \\frac{1}{2} \\left[ \\frac{2(x - x_b)}{B} + \\frac{2(y - x)(-1)}{R} \\right] = \\frac{x - x_b}{B} - \\frac{y - x}{R}$$\n\n在 $x = x_a$ 处令导数为零：\n\n$$\\frac{x_a - x_b}{B} - \\frac{y - x_a}{R} = 0$$\n\n$$\\frac{x_a - x_b}{B} = \\frac{y - x_a}{R}$$\n\n解出 $x_a$：\n\n$$R(x_a - x_b) = B(y - x_a)$$\n$$Rx_a - Rx_b = By - Bx_a$$\n$$Rx_a + Bx_a = By + Rx_b$$\n$$x_a(R + B) = By + Rx_b$$\n\n这就得出了分析状态 $x_a$ 的 MAP 估计量：\n\n$$x_a = \\frac{By + Rx_b}{B+R}$$\n\n后验分布 $p(x \\mid y)$ 本身也是高斯分布，因为它与两个高斯函数的乘积成正比。该后验分布的方差就是分析方差 $\\sigma_a^2$。在变分数据同化中，分析（后验）协方差是代价函数在最小值点处的海森矩阵的逆。对于这个标量问题，分析方差是 $J(x)$ 二阶导数的倒数。\n\n代价函数的二阶导数是：\n\n$$\\frac{d^2 J}{dx^2} = \\frac{d}{dx} \\left( \\frac{x - x_b}{B} - \\frac{y - x}{R} \\right) = \\frac{1}{B} + \\frac{1}{R}$$\n\n分析方差 $\\sigma_a^2$ 是该表达式的倒数：\n\n$$\\sigma_a^2 = \\left(\\frac{d^2 J}{dx^2}\\right)^{-1} = \\left(\\frac{1}{B} + \\frac{1}{R}\\right)^{-1} = \\left(\\frac{R + B}{BR}\\right)^{-1} = \\frac{BR}{B+R}$$\n\n现在我们使用给定的数值计算这些表达式：$x_b=2$，$B=4$，$y=5$ 和 $R=1$。\n\n分析状态 $x_a$ 是：\n\n$$x_a = \\frac{(4)(5) + (1)(2)}{4+1} = \\frac{20 + 2}{5} = \\frac{22}{5}$$\n\n分析方差 $\\sigma_a^2$ 是：\n\n$$\\sigma_a^2 = \\frac{(4)(1)}{4+1} = \\frac{4}{5}$$\n\n最终答案是数对 $(x_a, \\sigma_a^2)$，以行矩阵的形式表示。",
            "answer": "$$\\boxed{\\begin{pmatrix} \\frac{22}{5} & \\frac{4}{5} \\end{pmatrix}}$$"
        },
        {
            "introduction": "现实世界系统包含许多相互作用的变量。这个练习将标量情况下的原理扩展到一个简单的多维系统。您将看到背景误差协方差矩阵（$\\mathbf{B}$）如何在将单个观测信息分配到多个状态分量中扮演关键角色，这是三维变分（3D-Var）的核心机制。通过求解这个问题，您可以深入理解多维状态下信息是如何依据先验不确定性进行传播和加权的。",
            "id": "3864622",
            "problem": "考虑一个双分量环境状态向量 $\\mathbf{x} \\in \\mathbb{R}^{2}$，它代表了在线性设定下，通过单次卫星观测进行分析的空间聚合量。假设一个基于高斯误差统计和线性观测算子的三维变分（3D-Var）数据同化框架，其中分析场 $\\mathbf{x}^{a}$ 是使由背景场和观测场误差构建的二次代价函数最小化的状态。设背景误差协方差为 $\\mathbf{B}=\\begin{bmatrix}1 & 0 \\\\ 0 & 4\\end{bmatrix}$，观测算子为 $\\mathbf{H}=\\begin{bmatrix}1 & 1\\end{bmatrix}$，观测误差协方差为 $R=1$，背景场（也称先验）为 $\\mathbf{x}_{b}=\\begin{bmatrix}0 \\\\ 0\\end{bmatrix}$，观测值为 $y=3$。\n\n从结合了线性高斯假设下的背景场和观测场误差的3D-Var代价函数的定义出发，推导出表征最小值的的一阶最优性条件（正规方程）。然后，使用给定的数值，计算分析增量 $\\delta \\mathbf{x}^{a}=\\mathbf{x}^{a}-\\mathbf{x}_{b}$ 和分析状态 $\\mathbf{x}^{a}$。以 $\\big[\\delta x^{a}_{1},\\,\\delta x^{a}_{2},\\,x^{a}_{1},\\,x^{a}_{2}\\big]$ 的顺序，将最终结果表示为单个行矩阵。\n\n无需单位。请提供精确值，无需四舍五入。",
            "solution": "首先对问题陈述进行严格的验证过程。\n\n### 第一步：提取已知条件\n-   状态向量：$\\mathbf{x} \\in \\mathbb{R}^{2}$\n-   背景误差协方差：$\\mathbf{B}=\\begin{bmatrix}1 & 0 \\\\ 0 & 4\\end{bmatrix}$\n-   观测算子：$\\mathbf{H}=\\begin{bmatrix}1 & 1\\end{bmatrix}$\n-   观测误差协方差：$R=1$\n-   背景状态：$\\mathbf{x}_{b}=\\begin{bmatrix}0 \\\\ 0\\end{bmatrix}$\n-   观测值：$y=3$\n-   任务：推导正规方程，然后计算分析增量 $\\delta \\mathbf{x}^{a}=\\mathbf{x}^{a}-\\mathbf{x}_{b}$ 和分析状态 $\\mathbf{x}^{a}$。\n-   最终输出格式：单个行矩阵 $\\big[\\delta x^{a}_{1},\\,\\delta x^{a}_{2},\\,x^{a}_{1},\\,x^{a}_{2}\\big]$。\n\n### 第二步：使用提取的已知条件进行验证\n根据验证标准对问题进行评估。\n-   **科学上成立：**该问题描述了一个标准的三维变分（3D-Var）数据同化情景。二次代价函数、背景/观测误差协方差以及线性观测算子的使用是遥感和环境建模中这一既定科学方法的典型要素。该框架是在线性高斯假设下从 Bayes 定理推导出来的。该问题在科学上是合理的。\n-   **适定性：**问题是求解一个二次代价函数的最小值。背景误差协方差矩阵 $\\mathbf{B}$ 的特征值为1和4，均为正数，因此 $\\mathbf{B}$ 是正定的，从而可逆。观测误差协方差 $R=1$ 是一个正标量。代价函数的Hessian矩阵 $(\\mathbf{B}^{-1} + \\mathbf{H}^T R^{-1} \\mathbf{H})$ 将被证明是正定的，这保证了唯一稳定最小值的存在。所有必要信息均已提供，且无矛盾之处。该问题是适定的。\n-   **客观性：**问题使用了精确的数学语言和定义（$\\mathbf{x}_b, \\mathbf{B}, \\mathbf{H}, R, y$）来陈述。没有主观或含糊不清的术语。该问题是客观的。\n-   **其他缺陷：**该问题并非微不足道，因为它需要推导和矩阵代数运算。对于一个教科书式的例子来说，它不是隐喻性的、不完整的或不切实际的。\n\n### 第三步：结论与行动\n问题有效。将提供解答。\n\n3D-Var分析状态 $\\mathbf{x}^a$ 是使代价函数 $J(\\mathbf{x})$ 最小化的状态向量 $\\mathbf{x}$。代价函数衡量了与背景状态和观测值的拟合误差，并由它们各自的误差协方差加权。对于线性高斯系统，其表达式为：\n$$J(\\mathbf{x}) = \\frac{1}{2}(\\mathbf{x} - \\mathbf{x}_b)^T \\mathbf{B}^{-1} (\\mathbf{x} - \\mathbf{x}_b) + \\frac{1}{2}(y - \\mathbf{H}\\mathbf{x})^T R^{-1} (y - \\mathbf{H}\\mathbf{x})$$\n为了找到最小值，我们计算 $J(\\mathbf{x})$ 相对于 $\\mathbf{x}$ 的梯度并将其设为零。梯度 $\\nabla_\\mathbf{x} J(\\mathbf{x})$ 为：\n$$\\nabla_\\mathbf{x} J(\\mathbf{x}) = \\mathbf{B}^{-1}(\\mathbf{x} - \\mathbf{x}_b) - \\mathbf{H}^T R^{-1} (y - \\mathbf{H}\\mathbf{x})$$\n在 $\\mathbf{x}=\\mathbf{x}^a$ 处将梯度设为零，得到一阶最优性条件，也称为正规方程：\n$$\\mathbf{B}^{-1}(\\mathbf{x}^a - \\mathbf{x}_b) - \\mathbf{H}^T R^{-1} (y - \\mathbf{H}\\mathbf{x}^a) = 0$$\n这就是所要求的正规方程的推导过程。\n\n我们需要求解分析增量，定义为 $\\delta \\mathbf{x}^a = \\mathbf{x}^a - \\mathbf{x}_b$。我们将 $\\mathbf{x}^a = \\mathbf{x}_b + \\delta \\mathbf{x}^a$ 代入正规方程：\n$$\\mathbf{B}^{-1}(\\delta \\mathbf{x}^a) - \\mathbf{H}^T R^{-1} (y - \\mathbf{H}(\\mathbf{x}_b + \\delta \\mathbf{x}^a)) = 0$$\n$$\\mathbf{B}^{-1}(\\delta \\mathbf{x}^a) - \\mathbf{H}^T R^{-1} (y - \\mathbf{H}\\mathbf{x}_b - \\mathbf{H}\\delta \\mathbf{x}^a) = 0$$\n整理各项以求解 $\\delta \\mathbf{x}^a$：\n$$\\mathbf{B}^{-1}(\\delta \\mathbf{x}^a) + \\mathbf{H}^T R^{-1} \\mathbf{H}\\delta \\mathbf{x}^a = \\mathbf{H}^T R^{-1} (y - \\mathbf{H}\\mathbf{x}_b)$$\n$$(\\mathbf{B}^{-1} + \\mathbf{H}^T R^{-1} \\mathbf{H}) \\delta \\mathbf{x}^a = \\mathbf{H}^T R^{-1} (y - \\mathbf{H}\\mathbf{x}_b)$$\n这个方程可以用来求解分析增量 $\\delta \\mathbf{x}^a$。\n\n现在，我们代入给定的数值：\n-   $\\mathbf{x}_b = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$\n-   $\\mathbf{B} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 4 \\end{bmatrix} \\implies \\mathbf{B}^{-1} = \\begin{bmatrix} 1 & 0 \\\\ 0 & \\frac{1}{4} \\end{bmatrix}$\n-   $\\mathbf{H} = \\begin{bmatrix} 1 & 1 \\end{bmatrix} \\implies \\mathbf{H}^T = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$\n-   $R = 1 \\implies R^{-1} = 1$\n-   $y = 3$\n\n首先，我们计算 $\\delta \\mathbf{x}^a$ 方程的各个组成部分。\n项 $(y - \\mathbf{H}\\mathbf{x}_b)$ 是新息 (innovation)：\n$$y - \\mathbf{H}\\mathbf{x}_b = 3 - \\begin{bmatrix} 1 & 1 \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} = 3 - 0 = 3$$\n方程的右侧是：\n$$\\mathbf{H}^T R^{-1} (y - \\mathbf{H}\\mathbf{x}_b) = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} (1) (3) = \\begin{bmatrix} 3 \\\\ 3 \\end{bmatrix}$$\n方程左侧的矩阵是代价函数的Hessian矩阵：\n$$\\mathbf{B}^{-1} + \\mathbf{H}^T R^{-1} \\mathbf{H} = \\begin{bmatrix} 1 & 0 \\\\ 0 & \\frac{1}{4} \\end{bmatrix} + \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} (1) \\begin{bmatrix} 1 & 1 \\end{bmatrix}$$\n$$= \\begin{bmatrix} 1 & 0 \\\\ 0 & \\frac{1}{4} \\end{bmatrix} + \\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix} = \\begin{bmatrix} 2 & 1 \\\\ 1 & 1 + \\frac{1}{4} \\end{bmatrix} = \\begin{bmatrix} 2 & 1 \\\\ 1 & \\frac{5}{4} \\end{bmatrix}$$\n为了求解 $\\delta \\mathbf{x}^a$，我们需要对该矩阵求逆。其行列式为：\n$$\\det\\left(\\begin{bmatrix} 2 & 1 \\\\ 1 & \\frac{5}{4} \\end{bmatrix}\\right) = (2)\\left(\\frac{5}{4}\\right) - (1)(1) = \\frac{5}{2} - 1 = \\frac{3}{2}$$\n逆矩阵为：\n$$\\begin{bmatrix} 2 & 1 \\\\ 1 & \\frac{5}{4} \\end{bmatrix}^{-1} = \\frac{1}{\\frac{3}{2}} \\begin{bmatrix} \\frac{5}{4} & -1 \\\\ -1 & 2 \\end{bmatrix} = \\frac{2}{3} \\begin{bmatrix} \\frac{5}{4} & -1 \\\\ -1 & 2 \\end{bmatrix} = \\begin{bmatrix} \\frac{10}{12} & -\\frac{2}{3} \\\\ -\\frac{2}{3} & \\frac{4}{3} \\end{bmatrix} = \\begin{bmatrix} \\frac{5}{6} & -\\frac{2}{3} \\\\ -\\frac{2}{3} & \\frac{4}{3} \\end{bmatrix}$$\n现在我们可以求解 $\\delta \\mathbf{x}^a$：\n$$\\delta \\mathbf{x}^a = \\begin{bmatrix} \\frac{5}{6} & -\\frac{2}{3} \\\\ -\\frac{2}{3} & \\frac{4}{3} \\end{bmatrix} \\begin{bmatrix} 3 \\\\ 3 \\end{bmatrix} = \\begin{bmatrix} \\frac{5}{6}(3) - \\frac{2}{3}(3) \\\\ -\\frac{2}{3}(3) + \\frac{4}{3}(3) \\end{bmatrix} = \\begin{bmatrix} \\frac{5}{2} - 2 \\\\ -2 + 4 \\end{bmatrix} = \\begin{bmatrix} \\frac{1}{2} \\\\ 2 \\end{bmatrix}$$\n因此，分析增量的分量为 $\\delta x^a_1 = \\frac{1}{2}$ 和 $\\delta x^a_2 = 2$。\n\n最后，我们计算分析状态 $\\mathbf{x}^a$：\n$$\\mathbf{x}^a = \\mathbf{x}_b + \\delta \\mathbf{x}^a = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} + \\begin{bmatrix} \\frac{1}{2} \\\\ 2 \\end{bmatrix} = \\begin{bmatrix} \\frac{1}{2} \\\\ 2 \\end{bmatrix}$$\n分析状态的分量为 $x^a_1 = \\frac{1}{2}$ 和 $x^a_2 = 2$。\n\n最终结果要求以 $\\big[\\delta x^{a}_{1},\\,\\delta x^{a}_{2},\\,x^{a}_{1},\\,x^{a}_{2}\\big]$ 的顺序表示为单个行矩阵。这得到：\n$$\\begin{pmatrix} \\frac{1}{2} & 2 & \\frac{1}{2} & 2 \\end{pmatrix}$$",
            "answer": "$$\\boxed{\\begin{pmatrix} \\frac{1}{2} & 2 & \\frac{1}{2} & 2 \\end{pmatrix}}$$"
        },
        {
            "introduction": "大多数真实的海洋学模型都是非线性的，这使得直接最小化代价函数变得困难，因此催生了对模型进行线性化的“增量”方法。这项练习探讨了这种线性化（即切线性模型）的有效性，这是理解四维变分（4D-Var）实际应用和潜在问题的关键一步。通过量化线性化误差并将其与观测误差进行比较，您可以评估在特定条件下切线性假设是否成立，这是保证增量4D-Var算法稳定性和准确性的前提。",
            "id": "3864651",
            "problem": "在增量三维变分同化 (3D-Var) 和四维变分同化 (4D-Var) 中，观测算子围绕当前迭代值进行线性化，以构建内循环的二次子问题。考虑一个标量状态变量 $x$（无量纲）和一个标量观测算子 $\\mathcal{H}(x)$，它代表一种简化的非线性，类似于遥感辐射模型中的饱和效应。令 $\\mathcal{H}(x) = \\sin(x)$，其中角度以弧度为单位。在当前迭代值 $x^{i} = 0.2$ 处，假设真实状态与当前迭代值相差一个已知增量 $\\delta x = 0.5$，因此真实状态为 $x^{i} + \\delta x$。使用基本原理（泰勒定理和变分资料同化中使用的切线性近似的定义），计算观测算子在 $x^{i}$ 附近对增量 $\\delta x$ 的绝对线性化误差。假设观测误差标准差为 $\\sigma_{o} = 0.05$（无量纲），并使用“如果绝对线性化误差小于 $\\sigma_{o}$，则切线性假设是可接受的”这一标准来评估其可接受性。将您的最终答案（绝对线性化误差）四舍五入到四位有效数字，并以无量纲单位表示。",
            "solution": "分析问题陈述的有效性。\n\n**步骤 1：提取已知条件**\n- 标量状态变量：$x$（无量纲）\n- 标量观测算子：$\\mathcal{H}(x) = \\sin(x)$\n- 状态变量的当前迭代值：$x^{i} = 0.2$\n- 状态变量的增量：$\\delta x = 0.5$\n- 真实状态：$x^{i} + \\delta x$\n- 观测误差标准差：$\\sigma_{o} = 0.05$\n- 切线性假设可接受的标准：绝对线性化误差 $ \\sigma_{o}$\n- 要求计算：计算绝对线性化误差并四舍五入到四位有效数字。\n\n**步骤 2：使用提取的已知条件进行验证**\n- **科学依据**：该问题基于变分资料同化的基本原理，特别是非线性算子使用泰勒级数展开进行线性化，这构成了增量 3D-Var 和 4D-Var 中切线性模型的基础。算子 $\\mathcal{H}(x) = \\sin(x)$ 是一个用于教学目的的简单、光滑、非线性函数的标准示例。\n- **适定性**：该问题是适定的。它提供了计算唯一数值答案所需的所有数据和定义。目标陈述清晰。\n- **客观性**：该问题以精确、客观和定量的术语表述。\n\n**步骤 3：结论与行动**\n该问题被认为是有效的，因为它在科学上是合理的、自洽的且适定的。下面将推导求解过程。\n\n核心任务是计算绝对线性化误差。线性化误差定义为在真实状态下计算的完整非线性观测算子的值与其围绕当前迭代值展开的切线性近似值之间的差。\n\n令真实状态为 $x_{t} = x^{i} + \\delta x$。真实的观测值为 $\\mathcal{H}(x_{t}) = \\mathcal{H}(x^{i} + \\delta x)$。\n\n$\\mathcal{H}(x)$ 在点 $x^{i}$ 附近的切线性近似由一阶泰勒展开给出：\n$$ \\mathcal{H}(x^{i} + \\delta x) \\approx \\mathcal{H}(x^{i}) + H \\delta x $$\n其中 $H$ 是切线性算子，定义为 $\\mathcal{H}$ 关于 $x$ 的导数在线性化点 $x^{i}$ 处的值：\n$$ H = \\frac{d\\mathcal{H}}{dx}\\bigg|_{x=x^{i}} $$\n线性化误差（我们记为 $\\epsilon_{L}$）是真实值与近似值之间的差：\n$$ \\epsilon_{L} = \\mathcal{H}(x^{i} + \\delta x) - \\left( \\mathcal{H}(x^{i}) + H \\delta x \\right) $$\n问题要求计算绝对线性化误差 $|\\epsilon_{L}|$。\n\n我们已知具体的观测算子为 $\\mathcal{H}(x) = \\sin(x)$。\n首先，我们计算切线性算子 $H$：\n$$ H = \\frac{d}{dx}(\\sin(x))\\bigg|_{x=x^{i}} = \\cos(x^{i}) $$\n代入给定值 $x^{i} = 0.2$：\n$$ H = \\cos(0.2) $$\n现在，我们可以使用给定的算子和值写出线性化误差 $\\epsilon_{L}$ 的表达式：\n$$ \\epsilon_{L} = \\sin(x^{i} + \\delta x) - \\left( \\sin(x^{i}) + \\cos(x^{i}) \\delta x \\right) $$\n代入数值 $x^{i} = 0.2$ 和 $\\delta x = 0.5$：\n$$ \\epsilon_{L} = \\sin(0.2 + 0.5) - \\left( \\sin(0.2) + \\cos(0.2) \\times 0.5 \\right) $$\n$$ \\epsilon_{L} = \\sin(0.7) - \\sin(0.2) - 0.5 \\cos(0.2) $$\n现在我们计算该表达式的数值，确保计算器处于弧度模式：\n$$ \\sin(0.7) \\approx 0.6442176872 $$\n$$ \\sin(0.2) \\approx 0.1986693308 $$\n$$ \\cos(0.2) \\approx 0.9800665778 $$\n将这些值代入 $\\epsilon_{L}$ 的表达式中：\n$$ \\epsilon_{L} \\approx 0.6442176872 - (0.1986693308 + 0.5 \\times 0.9800665778) $$\n$$ \\epsilon_{L} \\approx 0.6442176872 - (0.1986693308 + 0.4900332889) $$\n$$ \\epsilon_{L} \\approx 0.6442176872 - 0.6887026197 $$\n$$ \\epsilon_{L} \\approx -0.0444849325 $$\n绝对线性化误差是 $\\epsilon_{L}$ 的绝对值：\n$$ |\\epsilon_{L}| = |-0.0444849325| = 0.0444849325 $$\n问题要求将此值四舍五入到四位有效数字。\n$$ |\\epsilon_{L}| \\approx 0.04448 $$\n最后，我们使用给定标准评估切线性假设的可接受性：绝对线性化误差 $ \\sigma_{o}$。\n我们已知 $\\sigma_{o} = 0.05$。\n我们检查 $0.04448  0.05$ 是否成立。该不等式成立。因此，根据所提供的标准，对于此增量和状态，切线性假设是可接受的。\n\n最终答案是按要求四舍五入的计算出的绝对线性化误差。",
            "answer": "$$\\boxed{0.04448}$$"
        }
    ]
}