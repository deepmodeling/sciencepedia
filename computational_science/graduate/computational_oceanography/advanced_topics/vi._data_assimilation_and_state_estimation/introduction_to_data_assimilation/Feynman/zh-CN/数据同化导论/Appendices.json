{
    "hands_on_practices": [
        {
            "introduction": "数据同化的核心在于如何根据各自的不确定性来最优地融合预测（先验）和观测。这个练习将这一过程简化到最基本的形式：一个标量状态变量，例如单个点的海面温度异常。通过从贝叶斯定理出发并使用配方法，您将亲自推导出卡尔曼滤波更新方程的关键组成部分，从而牢固掌握分析均值、分析方差和卡尔曼增益的基本概念。",
            "id": "3795500",
            "problem": "在一个单网格点设置中，该设置代表了单步持续性模型数据同化循环中的无量纲化海表温度异常，假设预报状态是标量，并且在该循环中动力学是线性和确定性的。状态的先验（也称为预报或背景）分布是高斯分布，其均值为 $x^{f}$，方差为 $P^{f}$。获取一个与状态线性相关的单一并置观测，其观测算子为 $H$，独立的观测误差为高斯分布，方差为 $R$。假设所有变量都是无量纲的，并且先验和似然是独立且联合高斯的。使用适用于线性高斯模型的贝叶斯定理和配方法，推导后验（也称为分析）高斯分布，并用 $x^{f}$、$P^{f}$、$H$、$R$ 和观测值 $y$ 明确表示卡尔曼增益、分析均值和分析方差。\n\n然后，针对特定情况 $F=\\begin{bmatrix}1\\end{bmatrix}$、$H=\\begin{bmatrix}1\\end{bmatrix}$、$P^{f}=2$、$R=1$、$x^{f}=0$ 和 $y=1$ 计算您推导出的表达式的值。以精确有理数的形式提供最终的数值。\n\n将您的最终答案表示为包含三个条目的一行，顺序为：卡尔曼增益、分析均值、分析方差。无需单位。不要四舍五入；提供精确值。",
            "solution": "问题要求在线性高斯数据同化设置中，推导标量状态的后验（分析）分布，然后针对特定情况计算关键量的值。将按要求应用贝叶斯定理和配方法进行分析。\n\n### 第 1 步：问题验证\n\n首先根据所需标准对问题进行验证。\n\n**1.1. 提取的已知条件：**\n- 预报状态 $x$ 是一个标量。\n- 状态的先验分布是高斯分布，均值为 $x^f$，方差为 $P^f$。\n- 观测值 $y$ 是一个单一的并置测量。\n- 观测算子 $H$ 是线性的。\n- 观测误差来自一个独立的、均值为零、方差为 $R$ 的高斯分布。\n- 先验和似然是独立且联合高斯的。\n- 任务是使用贝叶斯定理和配方法推导后验（分析）分布。\n- 确定卡尔曼增益 ($K$)、分析均值 ($x^a$) 和分析方差 ($P^a$)。\n- 针对以下情况计算这些量的值：$F=\\begin{bmatrix}1\\end{bmatrix}$、$H=\\begin{bmatrix}1\\end{bmatrix}$、$P^{f}=2$、$R=1$、$x^{f}=0$ 和 $y=1$。\n\n**1.2. 验证：**\n- **科学依据：** 该问题是数据同化理论中的一个标准基础练习，特别是卡尔曼滤波分析步骤的推导。它基于贝叶斯统计和概率论的既定原理。该问题在科学上是合理的。\n- **适定性：** 问题提供了推导通用表达式和计算具体数值结果所需的所有信息。状态和观测模型定义清晰。提及模型算子 $F$ 提供了关于数据同化循环（持续性预报）的背景信息，但对于分析计算本身而言并非必需，因为预报状态 $x^f$ 是给定的。这不构成矛盾或不明确的设置。\n- **客观性：** 问题以精确、客观的数学语言陈述。\n\n**1.3. 结论：**\n该问题是有效的，因为它具有科学依据、适定且客观。不存在妨碍严谨求解的缺陷。我们可以继续。\n\n### 第 2 步：分析分布的推导\n\n根据贝叶斯定理，后验概率密度函数 (PDF) $p(x|y)$ 与似然概率密度函数 $p(y|x)$ 和先验概率密度函数 $p(x)$ 的乘积成正比。\n$$p(x|y) \\propto p(y|x) p(x)$$\n根据问题陈述，先验和似然都是高斯分布。对于标量状态 $x$，其概率密度函数为：\n\n先验分布为 $x \\sim \\mathcal{N}(x^f, P^f)$：\n$$p(x) \\propto \\exp\\left( -\\frac{1}{2} \\frac{(x - x^f)^2}{P^f} \\right)$$\n基于观测模型 $y = Hx + \\epsilon$（其中 $\\epsilon \\sim \\mathcal{N}(0, R)$），似然函数为：\n$$p(y|x) \\propto \\exp\\left( -\\frac{1}{2} \\frac{(y - Hx)^2}{R} \\right)$$\n\n后验概率密度函数是这两者的乘积：\n$$p(x|y) \\propto \\exp\\left( -\\frac{1}{2} \\frac{(x - x^f)^2}{P^f} \\right) \\exp\\left( -\\frac{1}{2} \\frac{(y - Hx)^2}{R} \\right)$$\n$$p(x|y) \\propto \\exp\\left( -\\frac{1}{2} \\left[ \\frac{(x - x^f)^2}{P^f} + \\frac{(y - Hx)^2}{R} \\right] \\right)$$\n两个高斯分布的乘积是另一个高斯分布。因此，$x$ 的后验分布也将是高斯分布，记为 $x \\sim \\mathcal{N}(x^a, P^a)$，其概率密度函数形式为：\n$$p(x|y) \\propto \\exp\\left( -\\frac{1}{2} \\frac{(x - x^a)^2}{P^a} \\right)$$\n为了找到分析均值 $x^a$ 和方差 $P^a$，我们令指数函数的参数相等。设 $J(x)$ 为后验概率密度函数指数中的代价函数：\n$$J(x) = \\frac{(x - x^a)^2}{P^a} + \\text{const.} = \\frac{(x - x^f)^2}{P^f} + \\frac{(y - Hx)^2}{R}$$\n我们现在展开右侧的各项，并根据 $x$ 的幂次合并同类项：\n$$J(x) = \\frac{1}{P^f}(x^2 - 2xx^f + (x^f)^2) + \\frac{1}{R}(y^2 - 2yHx + H^2x^2)$$\n$$J(x) = x^2 \\left(\\frac{1}{P^f} + \\frac{H^2}{R}\\right) - 2x \\left(\\frac{x^f}{P^f} + \\frac{yH}{R}\\right) + \\left(\\frac{(x^f)^2}{P^f} + \\frac{y^2}{R}\\right)$$\n这个关于 $x$ 的二次式必须等价于 $\\frac{1}{P^a}(x^2 - 2xx^a + (x^a)^2) + \\text{const.}$ 的形式。通过比较 $x^2$ 和 $x$ 项的系数（即“配方法”），我们可以确定 $P^a$ 和 $x^a$。\n\n比较 $x^2$ 项的系数：\n$$\\frac{1}{P^a} = \\frac{1}{P^f} + \\frac{H^2}{R}$$\n该方程表明，分析的精度（方差的倒数）是预报精度和观测精度的总和。求解分析方差 $P^a$：\n$$P^a = \\left( \\frac{R + H^2 P^f}{P^f R} \\right)^{-1} = \\frac{P^f R}{R + H^2 P^f}$$\n\n比较 $-2x$ 项的系数：\n$$\\frac{x^a}{P^a} = \\frac{x^f}{P^f} + \\frac{yH}{R}$$\n求解分析均值 $x^a$：\n$$x^a = P^a \\left( \\frac{x^f}{P^f} + \\frac{yH}{R} \\right) = \\frac{P^f R}{R + H^2 P^f} \\left( \\frac{x^f R + yH P^f}{P^f R} \\right) = \\frac{x^f R + yH P^f}{R + H^2 P^f}$$\n为了将其表示为包含卡尔曼增益的标准形式，我们对 $x^a$ 的表达式进行变换：\n$$x^a = \\frac{x^f(R + H^2 P^f) - x^f H^2 P^f + yH P^f}{R + H^2 P^f}$$\n$$x^a = x^f + \\frac{yH P^f - x^f H^2 P^f}{R + H^2 P^f} = x^f + \\left( \\frac{P^f H}{R + H^2 P^f} \\right) (y - Hx^f)$$\n这就是经典的卡尔曼更新方程 $x^a = x^f + K(y - Hx^f)$。由此，我们确定卡尔曼增益 $K$：\n$$K = \\frac{P^f H}{H^2 P^f + R}$$\n分析方差 $P^a$ 也可以用 $K$ 来表示。从我们对 $P^a$ 的表达式出发：\n$$P^a = \\frac{P^f R}{R + H^2 P^f} = P^f \\frac{R + H^2 P^f - H^2 P^f}{R + H^2 P^f} = P^f \\left( 1 - \\frac{H^2 P^f}{R + H^2 P^f} \\right)$$\n$$P^a = P^f \\left( 1 - H \\cdot \\frac{H P^f}{R + H^2 P^f} \\right) = P^f(1 - HK)$$\n由于所有量都是标量，这等价于 $P^a = (1-KH)P^f$。\n\n### 第 3 步：针对特定情况的求值\n\n给定以下值：\n- 预报均值：$x^f = 0$\n- 预报方差：$P^f = 2$\n- 观测算子：$H = 1$（来自 $H=\\begin{bmatrix}1\\end{bmatrix}$）\n- 观测误差方差：$R = 1$\n- 观测值：$y = 1$\n\n现在我们将这些值代入推导出的表达式中。\n\n**1. 卡尔曼增益 ($K$):**\n$$K = \\frac{P^f H}{H^2 P^f + R} = \\frac{2 \\cdot 1}{1^2 \\cdot 2 + 1} = \\frac{2}{2 + 1} = \\frac{2}{3}$$\n\n**2. 分析均值 ($x^a$):**\n$$x^a = x^f + K(y - Hx^f) = 0 + \\frac{2}{3}(1 - 1 \\cdot 0) = \\frac{2}{3}(1) = \\frac{2}{3}$$\n\n**3. 分析方差 ($P^a$):**\n使用形式 $P^a = (1 - KH)P^f$：\n$$P^a = \\left( 1 - \\frac{2}{3} \\cdot 1 \\right) \\cdot 2 = \\left( 1 - \\frac{2}{3} \\right) \\cdot 2 = \\frac{1}{3} \\cdot 2 = \\frac{2}{3}$$\n或者，使用直接公式：\n$$P^a = \\frac{P^f R}{R + H^2 P^f} = \\frac{2 \\cdot 1}{1 + 1^2 \\cdot 2} = \\frac{2}{1 + 2} = \\frac{2}{3}$$\n结果是一致的。\n\n最终值以精确有理数表示为：卡尔曼增益 $K = \\frac{2}{3}$，分析均值 $x^a = \\frac{2}{3}$，分析方差 $P^a = \\frac{2}{3}$。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{2}{3}  \\frac{2}{3}  \\frac{2}{3} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "真实世界的海洋系统是多维的，不同位置的状态变量（如海温）通常是相关的。本练习将上一节的标量概念扩展到二维状态向量，引入了协方差矩阵来描述变量之间的误差相关性。通过处理这个更实际的场景，您将学习如何使用矩阵形式的卡尔曼滤波方程来更新整个状态，并理解观测一个变量如何能够利用协方差信息改进对另一个未观测变量的估计。",
            "id": "3795551",
            "problem": "在计算海洋学中，考虑一个区域海洋模型中两个相邻网格点的海面温度异常所代表的二维状态的线性高斯单次同化步骤。设该状态由随机向量 $x \\in \\mathbb{R}^{2}$ 表示，其预报（先验）均值为 $x^{f}$，预报协方差为 $P^{f} \\in \\mathbb{R}^{2 \\times 2}$。单个原位观测值 $y \\in \\mathbb{R}$ 通过线性观测算子 $H \\in \\mathbb{R}^{1 \\times 2}$ 测量第一个状态分量，其中包含加性测量噪声 $\\varepsilon$，该噪声与 $x$ 独立且满足 $\\varepsilon \\sim \\mathcal{N}(0, R)$，其中 $R \\in \\mathbb{R}$ 是观测误差方差。观测模型为 $y = H x + \\varepsilon$。假设 $(x, y)$ 的联合分布为高斯分布，并考虑最佳线性无偏估计（BLUE），也称为卡尔曼滤波器（KF）分析更新，它产生分析状态 $x^{a}$ 和分析协方差 $P^{a}$。\n\n从高斯设定下线性估计的定义以及估计器在无偏性约束下最小化分析误差方差的要求出发，推导卡尔曼增益 $K \\in \\mathbb{R}^{2 \\times 1}$ 和分析协方差 $P^{a} \\in \\mathbb{R}^{2 \\times 2}$ 关于 $P^{f}$、$H$ 和 $R$ 的表达式。然后，对于特定情况\n$$\nP^{f} = \\begin{bmatrix} 1  0.5 \\\\ 0.5  1 \\end{bmatrix}, \\quad\nH = \\begin{bmatrix} 1  0 \\end{bmatrix}, \\quad\nR = 0.25,\n$$\n精确计算 $K$ 和 $P^{a}$ 的数值。\n\n使用以下顺序将最终答案表示为单个行矩阵：列出 $K$ 的两个元素（从上到下），然后是 $P^{a}$ 的四个元素（按行主序，即先第一行从左到右，再第二行从左到右）。无需四舍五入，也不涉及物理单位。最终答案必须是一个计算。",
            "solution": "该问题要求推导线性高斯估计问题中的卡尔曼增益 $K$ 和分析协方差 $P^{a}$，然后对一个特定情况进行数值计算。\n\n分析状态 $x^{a}$ 是一个线性估计器，它结合了预报（先验）状态 $x^{f}$ 和新的观测值 $y$。线性估计器的一般形式是：\n$$\nx^{a} = A x^{f} + B y\n$$\n其中 $A$ 和 $B$ 是矩阵。对于标准卡尔曼滤波器，我们寻求基于观测的新信息对预报进行更新。这表示为用增益矩阵 $K$ 加权的“新息”或“失配” $(y - Hx^{f})$ 来修正预报。\n$$\nx^{a} = x^{f} + K(y - Hx^{f})\n$$\n这种形式可以重写为 $x^{a} = (I - KH)x^{f} + Ky$，它对应于 $A=I-KH$ 和 $B=K$ 的一般线性形式。\n\n该估计器必须是无偏的，并且最小化分析误差方差。\n\n**1. 无偏性条件**\n分析误差定义为 $e^{a} = x - x^{a}$。无偏估计器要求分析误差的期望值为零，即 $E[e^{a}] = 0$。\n代入 $x^{a}$ 的表达式和观测模型 $y = Hx + \\varepsilon$：\n$$\ne^{a} = x - [x^{f} + K(y - Hx^{f})]\n$$\n$$\ne^{a} = x - x^{f} - K(Hx + \\varepsilon - Hx^{f})\n$$\n设预报误差为 $e^{f} = x - x^{f}$。那么：\n$$\ne^{a} = e^{f} - K(H(x-x^{f}) + \\varepsilon)\n$$\n$$\ne^{a} = e^{f} - K(He^{f} + \\varepsilon)\n$$\n$$\ne^{a} = (I - KH)e^{f} - K\\varepsilon\n$$\n分析误差的期望值为：\n$$\nE[e^{a}] = E[(I - KH)e^{f} - K\\varepsilon] = (I - KH)E[e^{f}] - KE[\\varepsilon]\n$$\n假设预报是无偏的，因此 $E[x^{f}] = E[x]$，这意味着 $E[e^{f}] = E[x - x^{f}] = 0$。测量噪声也假设为零均值，$E[\\varepsilon] = 0$。因此：\n$$\nE[e^{a}] = (I - KH)(0) - K(0) = 0\n$$\n所选的估计器形式是内在地无偏的，无论 $K$ 的选择如何。\n\n**2. 最小化分析误差方差**\n分析误差协方差矩阵定义为 $P^{a} = E[e^{a}(e^{a})^T]$。我们的目标是找到卡尔曼增益 $K$，以最小化该矩阵的标量度量，通常是其迹，它代表状态估计的总方差。\n$$\nP^{a} = E[((I - KH)e^{f} - K\\varepsilon)((I - KH)e^{f} - K\\varepsilon)^T]\n$$\n展开转置：\n$$\nP^{a} = E[((I - KH)e^{f} - K\\varepsilon)((e^{f})^T(I - KH)^T - \\varepsilon^T K^T)]\n$$\n$$\nP^{a} = E[(I - KH)e^{f}(e^{f})^T(I - KH)^T - (I - KH)e^{f}\\varepsilon^T K^T - K\\varepsilon(e^{f})^T(I - KH)^T + K\\varepsilon\\varepsilon^T K^T]\n$$\n逐项取期望，并利用预报误差 $e^f$ 和观测噪声 $\\varepsilon$ 不相关的事实，即 $E[e^{f}\\varepsilon^T] = 0$ 和 $E[\\varepsilon(e^{f})^T] = 0$：\n$$\nP^{a} = (I - KH)E[e^{f}(e^{f})^T](I - KH)^T + K E[\\varepsilon\\varepsilon^T] K^T\n$$\n根据定义，预报误差协方差为 $P^{f} = E[e^{f}(e^{f})^T]$，观测误差协方差为 $R = E[\\varepsilon\\varepsilon^T]$（由于 $y$ 是标量，$R$ 是标量方差）。\n$$\nP^{a} = (I - KH)P^{f}(I - KH)^T + KRK^T\n$$\n为了最小化分析误差方差，我们最小化 $P^{a}$ 的迹，$J(K) = \\text{tr}(P^{a})$。\n$$\nJ(K) = \\text{tr}((I - KH)P^{f}(I - KH)^T + KRK^T)\n$$\n展开第一项：\n$$\n(I - KH)P^{f}(I - KH)^T = (P^{f} - KHP^{f})(I - H^T K^T) = P^{f} - P^{f}H^T K^T - KHP^{f} + KHP^{f}H^T K^T\n$$\n所以，\n$$\nJ(K) = \\text{tr}(P^{f}) - \\text{tr}(P^{f}H^T K^T) - \\text{tr}(KHP^{f}) + \\text{tr}(KHP^{f}H^T K^T) + \\text{tr}(KRK^T)\n$$\n使用迹的循环性质 $\\text{tr}(ABC) = \\text{tr}(CAB)$，我们有 $\\text{tr}(P^{f}H^T K^T) = \\text{tr}(K^T P^{f}H^T)$。由于矩阵的迹等于其转置的迹，$\\text{tr}(K^T P^{f}H^T) = \\text{tr}((P^{f}H^T)^T K) = \\text{tr}(HP^{f}K)$。但 $P^f$ 是对称的（$P^f = (P^f)^T$），所以这是 $\\text{tr}(HP^f K)$。另外，$\\text{tr}(KHP^f)$ 是一个标量，所以它等于其转置 $\\text{tr}((KHP^f)^T) = \\text{tr}((P^f)^T H^T K^T) = \\text{tr}(P^f H^T K^T)$。一个更直接的方法是注意到对于实数矩阵，$\\text{tr}(KHP^f) = \\text{tr}(P^f H^T K^T)$。\n因此，$\\text{tr}(P^{f}H^T K^T) = \\text{tr}(KHP^{f})$。\n$$\nJ(K) = \\text{tr}(P^{f}) - 2 \\text{tr}(KHP^{f}) + \\text{tr}(K(HP^{f}H^T + R)K^T)\n$$\n为了找到最小值，我们将 $J(K)$ 对 $K$ 求导并令结果为零。使用标准矩阵导数恒等式 $\\frac{d}{dX}\\text{tr}(AXB) = A^T B^T$ 和 $\\frac{d}{dX}\\text{tr}(AXA^T) = 2AX$：\n$$\n\\frac{d J(K)}{dK} = -2\\frac{d}{dK}\\text{tr}(KHP^{f}) + \\frac{d}{dK}\\text{tr}(K(HP^{f}H^T + R)K^T) = 0\n$$\n$$\n-2(HP^{f})^T + 2K(HP^{f}H^T + R) = 0\n$$\n$$\n-2 P^{f}H^T + 2K(HP^{f}H^T + R) = 0\n$$\n$$\nK(HP^{f}H^T + R) = P^{f}H^T\n$$\n解出 $K$，我们得到最优卡尔曼增益的表达式：\n$$\nK = P^{f}H^T(HP^{f}H^T + R)^{-1}\n$$\n现在我们推导分析协方差 $P^{a}$ 的简化表达式。从 $P^{a} = (I - KH)P^{f} - (I - KH)P^{f}H^T K^T + KRK^T$ 开始：\n$$\nP^{a} = P^{f} - KHP^{f} - P^{f}H^T K^T + KHP^{f}H^T K^T + KRK^T\n$$\n$$\nP^{a} = P^{f} - KHP^{f} - P^{f}H^T K^T + K(HP^{f}H^T + R)K^T\n$$\n从 $K$ 的推导中，我们有 $K(HP^{f}H^T + R) = P^{f}H^T$。将此代入最后一项：\n$$\nP^{a} = P^{f} - KHP^{f} - P^{f}H^T K^T + (P^{f}H^T)K^T\n$$\n最后两项相消，剩下：\n$$\nP^{a} = P^{f} - KHP^{f}\n$$\n由于 $KHP^f$ 不一定是对称的，一个更稳健的形式是 $P^a = (I - KH)P^f$。如果 $P^f$ 是对称的，这种形式能保持 $P^a$ 的对称性，我们将在计算中看到这一点。\n\n**3. 数值计算**\n给定：\n$$\nP^{f} = \\begin{bmatrix} 1  0.5 \\\\ 0.5  1 \\end{bmatrix}, \\quad\nH = \\begin{bmatrix} 1  0 \\end{bmatrix}, \\quad\nR = 0.25 = \\frac{1}{4}\n$$\n首先，计算卡尔曼增益 $K$ 所需的项。\n$H$ 的转置是 $H^T = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$。\n项 $P^{f}H^T$ 是：\n$$\nP^{f}H^T = \\begin{bmatrix} 1  0.5 \\\\ 0.5  1 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 1 \\cdot 1 + 0.5 \\cdot 0 \\\\ 0.5 \\cdot 1 + 1 \\cdot 0 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 0.5 \\end{bmatrix}\n$$\n项 $HP^{f}H^T$ 是：\n$$\nHP^{f}H^T = \\begin{bmatrix} 1  0 \\end{bmatrix} \\left( \\begin{bmatrix} 1  0.5 \\\\ 0.5  1 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\right) = \\begin{bmatrix} 1  0 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0.5 \\end{bmatrix} = 1 \\cdot 1 + 0 \\cdot 0.5 = 1\n$$\n新息协方差是 $S = HP^{f}H^T + R$：\n$$\nS = 1 + 0.25 = 1.25 = \\frac{5}{4}\n$$\n由于这是一个标量，其逆为 $S^{-1} = \\frac{1}{1.25} = \\frac{4}{5} = 0.8$。\n现在，计算卡尔曼增益 $K = P^{f}H^T S^{-1}$：\n$$\nK = \\begin{bmatrix} 1 \\\\ 0.5 \\end{bmatrix} \\cdot 0.8 = \\begin{bmatrix} 0.8 \\\\ 0.4 \\end{bmatrix} = \\begin{bmatrix} \\frac{4}{5} \\\\ \\frac{2}{5} \\end{bmatrix}\n$$\n接下来，使用 $P^{a} = (I-KH)P^{f}$ 计算分析协方差 $P^{a}$。\n首先，计算矩阵 $KH$：\n$$\nKH = \\begin{bmatrix} 0.8 \\\\ 0.4 \\end{bmatrix} \\begin{bmatrix} 1  0 \\end{bmatrix} = \\begin{bmatrix} 0.8 \\cdot 1  0.8 \\cdot 0 \\\\ 0.4 \\cdot 1  0.4 \\cdot 0 \\end{bmatrix} = \\begin{bmatrix} 0.8  0 \\\\ 0.4  0 \\end{bmatrix}\n$$\n然后，计算 $I - KH$：\n$$\nI - KH = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix} - \\begin{bmatrix} 0.8  0 \\\\ 0.4  0 \\end{bmatrix} = \\begin{bmatrix} 1 - 0.8  0 - 0 \\\\ 0 - 0.4  1 - 0 \\end{bmatrix} = \\begin{bmatrix} 0.2  0 \\\\ -0.4  1 \\end{bmatrix}\n$$\n最后，计算 $P^{a} = (I - KH)P^{f}$：\n$$\nP^{a} = \\begin{bmatrix} 0.2  0 \\\\ -0.4  1 \\end{bmatrix} \\begin{bmatrix} 1  0.5 \\\\ 0.5  1 \\end{bmatrix}\n$$\n$$\nP^{a} = \\begin{bmatrix} (0.2)(1) + (0)(0.5)  (0.2)(0.5) + (0)(1) \\\\ (-0.4)(1) + (1)(0.5)  (-0.4)(0.5) + (1)(1) \\end{bmatrix}\n$$\n$$\nP^{a} = \\begin{bmatrix} 0.2  0.1 \\\\ 0.1  -0.2 + 1 \\end{bmatrix} = \\begin{bmatrix} 0.2  0.1 \\\\ 0.1  0.8 \\end{bmatrix}\n$$\n让我们将这些结果表示为精确分数：\n$K = \\begin{bmatrix} 4/5 \\\\ 2/5 \\end{bmatrix}$\n$P^{a} = \\begin{bmatrix} 1/5  1/10 \\\\ 1/10  4/5 \\end{bmatrix}$\n\n问题要求将 $K$ 的元素（从上到下）和 $P^{a}$ 的元素（按行主序）排列成一个单行矩阵。\n这些元素是：$K_1 = \\frac{4}{5}$，$K_2 = \\frac{2}{5}$，$P^{a}_{11} = \\frac{1}{5}$，$P^{a}_{12} = \\frac{1}{10}$，$P^{a}_{21} = \\frac{1}{10}$，$P^{a}_{22} = \\frac{4}{5}$。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{4}{5}  \\frac{2}{5}  \\frac{1}{5}  \\frac{1}{10}  \\frac{1}{10}  \\frac{4}{5} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "数据同化领域存在两种看似不同的主流方法：序贯的卡尔曼滤波（KF）和整体优化的三维变分（3D-Var）方法。这个练习旨在揭示两者之间深刻的内在联系。您将分别推导这两种方法的分析解，并证明在线性高斯假设下，它们在数学上是等价的。完成这项实践将使您对数据同化问题的贝叶斯基础有一个更统一和深入的理解，认识到不同的方法只是同一基本原理的不同表现形式。",
            "id": "3795564",
            "problem": "考虑计算海洋学中的一个分析步骤，其对象是一个二维线性状态，其分量代表单个水平网格点上的两个预报变量。设未知真实状态为 $x \\in \\mathbb{R}^{2}$，背景（先验）状态 $x_b \\in \\mathbb{R}^{2}$ 及其误差协方差 $B \\in \\mathbb{R}^{2 \\times 2}$ 已知，观测值 $y \\in \\mathbb{R}$ 通过一个已知的线性算子 $H \\in \\mathbb{R}^{1 \\times 2}$ 与状态相关，观测误差协方差为 $R \\in \\mathbb{R}^{1 \\times 1}$。假设先验误差和观测误差是独立的、无偏的且服从高斯分布。\n\n仅从贝叶斯定理以及线性和高斯误差统计的假设出发，推导使后验密度负对数最小化的分析状态，这等价于三维变分数据同化（3D-Var）分析。独立地，从高斯误差下最优线性估计器的定义出发，为同样设置推导单步卡尔曼滤波器（KF）分析。然后，对于特定情况\n$$\nx_b = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}, \\quad\nB = \\begin{pmatrix} 2  0 \\\\ 0  1 \\end{pmatrix}, \\quad\nH = \\begin{pmatrix} 1  1 \\end{pmatrix}, \\quad\nR = \\begin{pmatrix} 1 \\end{pmatrix}, \\quad\ny = 0.5,\n$$\n显式计算 3D-Var 分析和单步 KF 分析，并报告这两个分析状态之间差值的欧几里得范数。\n\n将最终答案表示为一个无单位的实数。无需四舍五入。",
            "solution": "该问题是有效的，因为它科学地基于数据同化原理，问题提法良好，具有唯一且有意义的解，并以客观、正式的语言表述。这是计算海洋学和统计估计中的一个标准问题。\n\n该问题要求对分析状态 $x_a \\in \\mathbb{R}^2$ 进行两次独立的推导，并进行最终的数值计算。首先，我们推导三维变分（3D-Var）分析。其次，我们推导单步卡尔曼滤波器（KF）分析。最后，我们证明在线性和高斯情况下，这两种方法是等价的，这直接导出了最终答案。\n\n**第一部分：3D-Var 分析的推导**\n\n3D-Var 分析旨在寻找使后验概率密度函数（PDF）$p(x|y)$ 最大化的状态 $x$。根据贝叶斯定理，后验概率与似然概率和先验概率的乘积成正比：\n$$p(x|y) \\propto p(y|x) p(x)$$\n问题陈述先验误差和观测误差是无偏的且服从高斯分布。\n\n先验信息是背景状态 $x_b$ 及其误差协方差 $B$。因此，先验概率密度函数 $p(x)$ 是一个以 $x_b$ 为中心、协方差为 $B$ 的高斯分布：\n$$p(x) = \\mathcal{N}(x_b, B) \\propto \\exp\\left(-\\frac{1}{2}(x - x_b)^T B^{-1} (x - x_b)\\right)$$\n观测值 $y$ 通过线性算子 $H$ 与真实状态 $x$ 相关，观测误差 $\\epsilon_o$ 的均值为零，协方差为 $R$。因此，$y = Hx + \\epsilon_o$。在给定状态 $x$ 的条件下观测到 $y$ 的似然概率 $p(y|x)$ 也是一个以 $Hx$ 为中心、协方差为 $R$ 的高斯分布：\n$$p(y|x) = \\mathcal{N}(Hx, R) \\propto \\exp\\left(-\\frac{1}{2}(y - Hx)^T R^{-1} (y - Hx)\\right)$$\n结合这些，后验概率密度函数为：\n$$p(x|y) \\propto \\exp\\left(-\\frac{1}{2}\\left[ (x - x_b)^T B^{-1} (x - x_b) + (y - Hx)^T R^{-1} (y - Hx) \\right]\\right)$$\n最大化后验概率密度函数 $p(x|y)$ 等价于最小化其负对数。我们将 3D-Var 代价函数 $J(x)$ 定义为负指数部分的两倍：\n$$J(x) = (x - x_b)^T B^{-1} (x - x_b) + (y - Hx)^T R^{-1} (y - Hx)$$\n为了找到使 $J(x)$ 最小化的状态 $x_a$，我们计算 $J(x)$ 对 $x$ 的梯度并令其为零。使用矩阵微积分恒等式，梯度为：\n$$\\nabla_x J(x) = 2B^{-1}(x - x_b) - 2H^T R^{-1}(y - Hx)$$\n令 $x = x_a$ 处的 $\\nabla_x J(x) = 0$：\n$$B^{-1}(x_a - x_b) - H^T R^{-1}(y - Hx_a) = 0$$\n整理各项以求解 $x_a$：\n$$B^{-1}x_a - B^{-1}x_b - H^T R^{-1}y + H^T R^{-1}Hx_a = 0$$\n$$(B^{-1} + H^T R^{-1}H)x_a = B^{-1}x_b + H^T R^{-1}y$$\n因此，3D-Var 分析状态为：\n$$x_{a, \\text{3DVar}} = (B^{-1} + H^T R^{-1}H)^{-1} (B^{-1}x_b + H^T R^{-1}y)$$\n\n**第二部分：卡尔曼滤波器分析的推导**\n\n卡尔曼滤波器分析更新提供了状态的最优线性无偏估计。分析状态 $x_a$ 表示为基于新息（即观测值 $y$ 与其背景估计 $Hx_b$ 之间的差值）对背景状态 $x_b$ 的线性修正：\n$$x_a = x_b + K(y - Hx_b)$$\n这里，$K$ 是卡尔曼增益矩阵，其选择旨在最小化分析误差的方差，即最小化分析误差协方差矩阵 $P_a = E[(x_a-x)(x_a-x)^T]$ 的迹。\n\n分析误差 $x_a-x$ 可以写为：\n$$x_a - x = x_b + K(y - Hx_b) - x = x_b + K(Hx + \\epsilon_o - Hx_b) - x$$\n其中 $\\epsilon_o$ 是观测误差。令 $\\epsilon_b = x_b - x$ 为背景误差。\n$$x_a - x = (x_b - x) + K(H(x-x_b) + \\epsilon_o) = \\epsilon_b - KH\\epsilon_b + K\\epsilon_o = (I - KH)\\epsilon_b + K\\epsilon_o$$\n现在，我们计算分析误差协方差 $P_a$。由于背景误差 $\\epsilon_b$ 和观测误差 $\\epsilon_o$ 是独立的，所以 $E[\\epsilon_b \\epsilon_o^T] = 0$ 且 $E[\\epsilon_o \\epsilon_b^T] = 0$。\n$$P_a = E[((I - KH)\\epsilon_b + K\\epsilon_o)((I - KH)\\epsilon_b + K\\epsilon_o)^T]$$\n$$P_a = (I - KH) E[\\epsilon_b\\epsilon_b^T] (I - KH)^T + K E[\\epsilon_o\\epsilon_o^T] K^T$$\n使用 $E[\\epsilon_b\\epsilon_b^T] = B$ 和 $E[\\epsilon_o\\epsilon_o^T] = R$：\n$$P_a = (I - KH)B(I - KH)^T + KRK^T$$\n$$P_a = B - KHB - BH^T K^T + KHBH^TK^T + KRK^T$$\n为了最小化 $P_a$ 的迹（相对于 $K$），我们将其导数设为零：\n$$\\frac{\\partial}{\\partial K} \\mathrm{tr}(P_a) = -2BH^T + 2K(HBH^T + R) = 0$$\n求解 $K$ 得到最优卡尔曼增益：\n$$K = BH^T(HBH^T + R)^{-1}$$\n因此，卡尔曼滤波器分析状态为：\n$$x_{a, \\text{KF}} = x_b + BH^T(HBH^T + R)^{-1}(y - Hx_b)$$\n\n**等价性与最终计算**\n\n对于具有高斯误差的线性系统，3D-Var 分析和卡尔曼滤波器分析是等价的。这可以通过将 Woodbury 矩阵恒等式应用于 3D-Var 分析表达式来证明。该恒等式为 $(A+UCV)^{-1} = A^{-1} - A^{-1}U(C^{-1}+VA^{-1}U)^{-1}VA^{-1}$。令 $A = B^{-1}$，$U=H^T$，$C=R^{-1}$，$V=H$。\n$$(B^{-1} + H^T R^{-1}H)^{-1} = B - BH^T(R + HBH^T)^{-1}HB$$\n将此代入 $x_a$ 的 3D-Var 公式中：\n$$x_{a, \\text{3DVar}} = (B - BH^T(HBH^T + R)^{-1}HB)(B^{-1}x_b + H^T R^{-1}y)$$\n$$x_{a, \\text{3DVar}} = x_b + BH^T R^{-1}y - BH^T(HBH^T + R)^{-1}HB B^{-1}x_b - BH^T(HBH^T + R)^{-1}HBH^TR^{-1}y$$\n$$x_{a, \\text{3DVar}} = x_b - BH^T(HBH^T + R)^{-1}Hx_b + BH^T[I - (HBH^T + R)^{-1}HBH^T]R^{-1}y$$\n方括号中的项可以简化：$I - (HBH^T+R)^{-1}HBH^T = (HBH^T+R)^{-1}[(HBH^T+R) - HBH^T] = (HBH^T+R)^{-1}R$。\n$$x_{a, \\text{3DVar}} = x_b - BH^T(HBH^T + R)^{-1}Hx_b + BH^T(HBH^T + R)^{-1}R R^{-1}y$$\n$$x_{a, \\text{3DVar}} = x_b + BH^T(HBH^T + R)^{-1}(y - Hx_b) = x_{a, \\text{KF}}$$\n由于这两种方法在解析上产生相同的结果，它们数值输出之间的差值必须是一个零向量，并且这个差值的欧几里得范数必须为零。\n\n为了完整起见，我们使用卡尔曼滤波器公式计算给定数值的分析状态。\n给定：\n$$\nx_b = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}, \\quad\nB = \\begin{pmatrix} 2  0 \\\\ 0  1 \\end{pmatrix}, \\quad\nH = \\begin{pmatrix} 1  1 \\end{pmatrix}, \\quad\nR = 1, \\quad\ny = 0.5\n$$\n首先，计算卡尔曼增益 $K = BH^T(HBH^T + R)^{-1}$ 的分量：\n$$H^T = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$$\n$$BH^T = \\begin{pmatrix} 2  0 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}$$\n$$HBH^T = \\begin{pmatrix} 1  1 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = 1(2)+1(1) = 3$$\n项 $(HBH^T + R)^{-1}$ 是一个标量：\n$$(3 + 1)^{-1} = 4^{-1} = \\frac{1}{4}$$\n卡尔曼增益为：\n$$K = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} \\frac{1}{4} = \\begin{pmatrix} 1/2 \\\\ 1/4 \\end{pmatrix}$$\n接下来，计算新息项 $y - Hx_b$：\n$$Hx_b = \\begin{pmatrix} 1  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} = 1(1) + 1(-1) = 0$$\n$$y - Hx_b = 0.5 - 0 = 0.5 = \\frac{1}{2}$$\n最后，计算分析状态 $x_a$：\n$$x_a = x_b + K(y - Hx_b) = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} + \\begin{pmatrix} 1/2 \\\\ 1/4 \\end{pmatrix} \\left(\\frac{1}{2}\\right) = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} + \\begin{pmatrix} 1/4 \\\\ 1/8 \\end{pmatrix} = \\begin{pmatrix} 5/4 \\\\ -7/8 \\end{pmatrix}$$\n$x_{a, \\text{3DVar}}$ 和 $x_{a, \\text{KF}}$ 都等于 $\\begin{pmatrix} 5/4 \\\\ -7/8 \\end{pmatrix}$。\n差值为 $x_{a, \\text{3DVar}} - x_{a, \\text{KF}} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$。\n差值的欧几里得范数为：\n$$\\left\\| \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} \\right\\|_2 = \\sqrt{0^2 + 0^2} = 0$$",
            "answer": "$$\\boxed{0}$$"
        }
    ]
}