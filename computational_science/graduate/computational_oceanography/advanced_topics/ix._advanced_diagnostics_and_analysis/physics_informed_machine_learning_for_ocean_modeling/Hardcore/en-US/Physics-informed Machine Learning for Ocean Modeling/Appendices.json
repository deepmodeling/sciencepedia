{
    "hands_on_practices": [
        {
            "introduction": "The 'physics' in Physics-Informed Machine Learning (PIML) extends beyond just embedding governing equations; it also demands respect for fundamental symmetries. Galilean invariance, the principle that the laws of physics are the same in all inertial frames, is a cornerstone of fluid dynamics. This exercise  provides a hands-on investigation into the critical importance of this symmetry, demonstrating how learned closures that inadvertently violate it can produce non-physical artifacts, such as spurious energy generation when the frame of reference is changed. By quantifying this effect, you will gain a deeper appreciation for why enforcing such fundamental principles is essential for building robust and reliable PIML models.",
            "id": "3807972",
            "problem": "Consider a one-dimensional, periodic, incompressible flow used as a reduced model for horizontally homogeneous ocean currents. The kinetic energy in nondimensional units is defined as $E(t) = \\frac{1}{2} \\int_0^L u(x,t)^2 \\, dx$ over a domain of length $L$, with periodic boundary conditions. Starting from Newton's second law and the incompressible Navier–Stokes momentum equation in one spatial dimension, the kinetic energy budget for a periodic domain implies that the rate of change of kinetic energy due to any added body force or closure term equals the spatial integral of the product of velocity and that forcing. In Physics-Informed Machine Learning (PIML), learned closures may introduce explicit dependence on the absolute velocity that is not Galilean invariant. A Galilean translation corresponds to $u'(x,t) = u(x,t) + U$, where $U$ is a constant uniform background velocity. For a closure functional $C(u,\\partial_x u)$, the energy input by the closure is defined as $I(u; C) = \\int_0^L u(x) \\, C(u(x), \\partial_x u(x)) \\, dx$. Under a uniform frame translation $U$, define the spurious energy input as $\\Delta I = I(u+U; C) - I(u; C)$, which should be zero for a Galilean-invariant closure. In this problem, you will compute $\\Delta I$ for a family of learned closures that may violate Galilean invariance.\n\nUse the following closure family, parameterized by coefficients $\\alpha$, $\\beta$, and $\\gamma$:\n$$\nC(u,\\partial_x u) = \\alpha \\, u + \\beta \\, u^3 + \\gamma \\, \\partial_x u.\n$$\nThis choice deliberately mixes potentially non-invariant terms ($\\alpha u$ and $\\beta u^3$) with an invariant gradient-dependent term ($\\gamma \\, \\partial_x u$). The uniform translation affects only the absolute velocity, not spatial gradients, so $\\partial_x (u+U) = \\partial_x u$.\n\nImplement a program that, given a domain length $L$, a grid size $N$, a uniform translation $U$, closure parameters $(\\alpha, \\beta, \\gamma)$, and a prescribed stationary velocity field $u(x)$, numerically computes the spurious energy input $\\Delta I$ using discrete approximations:\n- Represent the domain as $N$ grid points with spacing $\\Delta x = L/N$, with coordinates $x_j = j \\Delta x$ for $j = 0, 1, \\dots, N-1$ and periodic boundary conditions.\n- Approximate $\\partial_x u$ using the second-order central difference with periodic wrap:\n$$\n(\\partial_x u)_j \\approx \\frac{u_{j+1} - u_{j-1}}{2 \\, \\Delta x},\n$$\nwhere $u_{-1} \\equiv u_{N-1}$ and $u_N \\equiv u_0$.\n- Approximate the spatial integrals by the rectangle rule (equivalently a Riemann sum):\n$$\nI(u; C) \\approx \\sum_{j=0}^{N-1} u_j \\, C(u_j, (\\partial_x u)_j) \\, \\Delta x.\n$$\n- Compute $\\Delta I$ in nondimensional units as a floating-point number.\n\nUse nondimensional units throughout; no physical units are required. Angles, when present in trigonometric functions, should be evaluated in radians.\n\nYour program must run all of the following test cases and print the results in the specified format. For each case, define $u(x)$ as specified and evaluate $\\Delta I$.\n\nTest Suite:\n- Case $1$ (general mixed closure, sinusoidal field, moderate translation):\n  - $L = 2\\pi$, $N = 1024$, $U = 0.5$, $(\\alpha,\\beta,\\gamma) = (0.1, 0.02, -0.05)$,\n  - $u(x) = \\sin(x) + 0.3 \\, \\sin(2x)$.\n- Case $2$ (gradient-only closure that should be Galilean invariant):\n  - $L = 2\\pi$, $N = 1024$, $U = 0.75$, $(\\alpha,\\beta,\\gamma) = (0, 0, -0.1)$,\n  - $u(x) = \\cos(3x)$.\n- Case $3$ (zero translation baseline):\n  - $L = 2\\pi$, $N = 1024$, $U = 0.0$, $(\\alpha,\\beta,\\gamma) = (0.2, -0.03, 0.0)$,\n  - $u(x) = \\sin(x)$.\n- Case $4$ (constant field, purely non-invariant linear closure, nonzero translation):\n  - $L = 1.0$, $N = 256$, $U = -1.2$, $(\\alpha,\\beta,\\gamma) = (0.5, 0.0, 0.0)$,\n  - $u(x) = 0.2$ for all $x$.\n- Case $5$ (coarse grid edge case, mixed closure):\n  - $L = 2\\pi$, $N = 4$, $U = 0.3$, $(\\alpha,\\beta,\\gamma) = (0.0, 0.05, -0.02)$,\n  - $u(x) = \\sin(x)$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[r_1,r_2,r_3,r_4,r_5]$), where each $r_i$ is the computed $\\Delta I$ for Case $i$ as a floating-point number in nondimensional units.",
            "solution": "The problem requires the computation of the spurious energy input, denoted as $\\Delta I$, for a specific family of learned closure terms in a one-dimensional fluid dynamics model. This spurious energy arises from a violation of Galilean invariance when a uniform velocity translation $U$ is applied to the system. The analysis will proceed by first defining the relevant quantities, then establishing the numerical methods for their approximation, and finally outlining the algorithm to compute $\\Delta I$ for the specified test cases.\n\nThe spurious energy input is defined as the difference between the energy input by the closure term for a translated velocity field and the original velocity field:\n$$\n\\Delta I = I(u+U; C) - I(u; C)\n$$\nwhere $u(x,t)$ is the velocity field, $U$ is a constant uniform translation, and $I(v; C)$ is the energy input functional for a generic velocity field $v$. This functional is given by the integral over the periodic domain of length $L$:\n$$\nI(v; C) = \\int_0^L v(x) \\, C(v(x), \\partial_x v(x)) \\, dx\n$$\nThe closure functional, $C(v, \\partial_x v)$, is given by a specific parametric form:\n$$\nC(v, \\partial_x v) = \\alpha \\, v + \\beta \\, v^3 + \\gamma \\, \\partial_x v\n$$\nwhere $\\alpha$, $\\beta$, and $\\gamma$ are constant coefficients. A key property of the uniform translation is that it does not affect spatial gradients: $\\partial_x (u+U) = \\partial_x u$.\n\nTo compute $\\Delta I$ numerically, we must discretize the domain and the differential and integral operators. The domain $[0, L]$ is represented by $N$ grid points $x_j = j \\Delta x$ for $j = 0, 1, \\dots, N-1$, where the grid spacing is $\\Delta x = L/N$. The continuous velocity field $u(x)$ is represented by its values at these grid points, $u_j = u(x_j)$.\n\nThe spatial derivative $\\partial_x u$ at each grid point $j$ is approximated using a second-order central difference scheme with periodic boundary conditions. The formula is:\n$$\n(\\partial_x u)_j \\approx \\frac{u_{j+1} - u_{j-1}}{2 \\, \\Delta x}\n$$\nPeriodicity implies that indices are handled modulo $N$, such that $u_{N} \\equiv u_0$ and $u_{-1} \\equiv u_{N-1}$.\n\nThe integral $\\int_0^L f(x) \\, dx$ is approximated by a Riemann sum (specifically, the rectangle rule with left-hand points on each subinterval):\n$$\n\\int_0^L f(x) \\, dx \\approx \\sum_{j=0}^{N-1} f(x_j) \\, \\Delta x\n$$\n\nThe computational procedure to find $\\Delta I$ is as follows:\n\n1.  **Compute $I(u; C)$**:\n    a.  First, generate the discrete velocity field $u_j = u(x_j)$ for $j=0, \\dots, N-1$.\n    b.  Next, compute the discrete derivative $(\\partial_x u)_j$ for all $j$ using the central difference formula.\n    c.  At each grid point, evaluate the discrete closure term: $C_j = \\alpha u_j + \\beta u_j^3 + \\gamma (\\partial_x u)_j$.\n    d.  Compute the discrete integrand, which is the product $(u \\cdot C)_j = u_j C_j$.\n    e.  Finally, approximate the integral $I(u; C)$ using the Riemann sum:\n        $$\n        I(u; C) \\approx \\left( \\sum_{j=0}^{N-1} u_j C_j \\right) \\Delta x\n        $$\n\n2.  **Compute $I(u+U; C)$**:\n    a.  Define the translated velocity field as $u'_j = u_j + U$.\n    b.  The derivative of the translated field, $\\partial_x(u+U)$, is the same as the derivative of the original field, $\\partial_x u$, since $U$ is a constant. Thus, the discrete derivative vector $(\\partial_x u')_j$ is identical to $(\\partial_x u)_j$ computed in the previous step.\n    c.  Evaluate the closure term for the translated field at each grid point: $C'_j = C(u'_j, (\\partial_x u)_j) = \\alpha u'_j + \\beta (u'_j)^3 + \\gamma (\\partial_x u)_j$.\n    d.  Compute the discrete integrand for the translated case: $(u' \\cdot C')_j = u'_j C'_j$.\n    e.  Approximate the integral $I(u+U; C)$ using the Riemann sum:\n        $$\n        I(u+U; C) \\approx \\left( \\sum_{j=0}^{N-1} u'_j C'_j \\right) \\Delta x\n        $$\n\n3.  **Compute $\\Delta I$**:\n    The final result is the difference between the two numerically computed integrals:\n    $$\n    \\Delta I = I_\\text{approx}(u+U; C) - I_\\text{approx}(u; C)\n    $$\nThis procedure is applied to each test case with its specific set of parameters ($L, N, U, \\alpha, \\beta, \\gamma$) and velocity field $u(x)$. For test cases where the closure should be Galilean invariant (e.g., when $\\alpha=0$ and $\\beta=0$) or when the translation is zero ($U=0$), we expect $\\Delta I$ to be zero, or a value on the order of floating-point precision due to numerical artifacts.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by computing the spurious energy input for a series of test cases.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: general mixed closure, sinusoidal field, moderate translation\n        {\n            \"L\": 2 * np.pi, \"N\": 1024, \"U\": 0.5,\n            \"params\": (0.1, 0.02, -0.05), # (alpha, beta, gamma)\n            \"u_func\": lambda x: np.sin(x) + 0.3 * np.sin(2 * x),\n        },\n        # Case 2: gradient-only closure that should be Galilean invariant\n        {\n            \"L\": 2 * np.pi, \"N\": 1024, \"U\": 0.75,\n            \"params\": (0.0, 0.0, -0.1),\n            \"u_func\": lambda x: np.cos(3 * x),\n        },\n        # Case 3: zero translation baseline\n        {\n            \"L\": 2 * np.pi, \"N\": 1024, \"U\": 0.0,\n            \"params\": (0.2, -0.03, 0.0),\n            \"u_func\": lambda x: np.sin(x),\n        },\n        # Case 4: constant field, purely non-invariant linear closure, nonzero translation\n        {\n            \"L\": 1.0, \"N\": 256, \"U\": -1.2,\n            \"params\": (0.5, 0.0, 0.0),\n            \"u_func\": lambda x: 0.2 * np.ones_like(x),\n        },\n        # Case 5: coarse grid edge case, mixed closure\n        {\n            \"L\": 2 * np.pi, \"N\": 4, \"U\": 0.3,\n            \"params\": (0.0, 0.05, -0.02),\n            \"u_func\": lambda x: np.sin(x),\n        },\n    ]\n\n    def compute_energy_input(v, dv_dx, dx, alpha, beta, gamma):\n        \"\"\"\n        Computes the discrete energy input I(v; C).\n        \n        Args:\n            v (np.ndarray): Discrete velocity field.\n            dv_dx (np.ndarray): Discrete spatial derivative of the velocity field.\n            dx (float): Grid spacing.\n            alpha (float): Closure parameter.\n            beta (float): Closure parameter.\n            gamma (float): Closure parameter.\n        \n        Returns:\n            float: The numerically computed energy input.\n        \"\"\"\n        # Closure term C(v, dv/dx) = alpha*v + beta*v^3 + gamma*dv/dx\n        closure_term = alpha * v + beta * v**3 + gamma * dv_dx\n        \n        # Integrand v * C(v, dv/dx)\n        integrand = v * closure_term\n        \n        # Integral via Riemann sum\n        integral = np.sum(integrand) * dx\n        return integral\n\n    results = []\n    for case in test_cases:\n        L, N, U = case[\"L\"], case[\"N\"], case[\"U\"]\n        alpha, beta, gamma = case[\"params\"]\n        u_func = case[\"u_func\"]\n\n        # 1. Set up the discrete domain and initial velocity field\n        dx = L / N\n        x = np.linspace(0, L, N, endpoint=False)\n        u = u_func(x)\n\n        # 2. Compute the derivative of the original velocity field u\n        # np.roll(u, -1) provides u_{j+1}\n        # np.roll(u, 1) provides u_{j-1}\n        du_dx = (np.roll(u, -1) - np.roll(u, 1)) / (2 * dx)\n\n        # 3. Compute I(u; C) for the original field\n        I_u = compute_energy_input(u, du_dx, dx, alpha, beta, gamma)\n\n        # 4. Define the translated field u' = u + U\n        u_prime = u + U\n        # The derivative of u' is the same as u, since d(u+U)/dx = du/dx\n        du_prime_dx = du_dx\n        \n        # 5. Compute I(u+U; C) for the translated field\n        I_u_prime = compute_energy_input(u_prime, du_prime_dx, dx, alpha, beta, gamma)\n        \n        # 6. Calculate the spurious energy input ΔI\n        delta_I = I_u_prime - I_u\n        results.append(delta_I)\n    \n    # Format and print the final output\n    print(f\"[{','.join(f'{r:.12f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Having established the importance of physical principles, we now turn to the practical challenge of implementing them. A powerful PIML strategy involves embedding a numerical solver for the governing equations directly into the model's computational graph, making the physics fully differentiable. This practice  guides you through building a key component of this approach: a spectral Poisson solver for the pressure projection step, which is fundamental to enforcing incompressibility in ocean models. You will not only implement the solver but also perform the crucial step of verifying its analytic gradient, a cornerstone skill for developing and debugging complex, physics-informed deep learning architectures.",
            "id": "3807941",
            "problem": "Implement a differentiable spectral Poisson solver for pressure projection under periodic boundary conditions and verify the correctness of the gradient of a physics-informed loss with respect to a scalar parameter by comparing an analytic gradient to a finite-difference approximation.\n\nYou are modeling the incompressible pressure projection step used in ocean modeling on a two-dimensional periodic domain of size $L_x \\times L_y$ with $N_x \\times N_y$ grid points. Let the collocated velocity field be $(u, v)$, and let the projection operator $P$ enforce incompressibility by removing the irrotational component via the Helmholtz–Hodge decomposition under periodic boundaries. Specifically, given a tentative velocity $(u^\\ast, v^\\ast)$, compute the divergence $g = \\nabla \\cdot (u^\\ast, v^\\ast)$, solve the Poisson problem\n$$\n\\Delta p = g\n$$\nwith periodic boundary conditions and zero-mean constraint for $p$, and return the projected velocity\n$$\n(u, v) = (u^\\ast, v^\\ast) - \\nabla p.\n$$\nAll differential operators are to be implemented spectrally: the two-dimensional Fast Fourier Transform (FFT) maps a field $f(x,y)$ to $\\hat{f}(k_x, k_y)$, where the spectral derivatives are defined by $\\widehat{\\partial_x f} = i k_x \\hat{f}$, $\\widehat{\\partial_y f} = i k_y \\hat{f}$, and the Laplacian satisfies $\\widehat{\\Delta f} = - (k_x^2 + k_y^2) \\hat{f}$. The zero-wavenumber mode $\\hat{p}(0,0)$ must be set to zero to enforce zero mean.\n\nConsider a parametric family of tentative velocities\n$$\n(u^\\ast(\\alpha), v^\\ast(\\alpha)) = (u_0, v_0) + \\alpha \\, (u_b, v_b),\n$$\nwhere $(u_0, v_0)$ and $(u_b, v_b)$ are fixed, smooth, periodic velocity fields and $\\alpha \\in \\mathbb{R}$ is a scalar parameter. Let the projected velocity be\n$$\n(u(\\alpha), v(\\alpha)) = P\\big(u^\\ast(\\alpha), v^\\ast(\\alpha)\\big).\n$$\nDefine a physics-informed quadratic loss that measures deviation from a target divergence-free field $(u_T, v_T)$:\n$$\n\\mathcal{L}(\\alpha) = \\frac{1}{2} \\int_0^{L_x} \\int_0^{L_y} \\left( \\left[u(\\alpha) - u_T\\right]^2 + \\left[v(\\alpha) - v_T\\right]^2 \\right) \\, \\mathrm{d}y \\, \\mathrm{d}x.\n$$\nOn the discrete grid, approximate the integral by a Riemann sum with cell area $\\Delta A = \\Delta x \\, \\Delta y$, where $\\Delta x = L_x/N_x$ and $\\Delta y = L_y/N_y$.\n\nTask requirements:\n1. Implement the spectral pressure projection operator $P$ described above using the two-dimensional Fast Fourier Transform (FFT) and its inverse (Inverse Fast Fourier Transform (IFFT)) under periodic boundary conditions.\n2. Implement the loss $\\mathcal{L}(\\alpha)$ as a function of $\\alpha$ using the projected velocity $P\\big((u_0, v_0) + \\alpha (u_b, v_b)\\big)$.\n3. Derive and implement the analytic gradient $\\mathrm{d}\\mathcal{L}/\\mathrm{d}\\alpha$ using first principles. Your derivation must start from the definition of $\\mathcal{L}(\\alpha)$ and the linearity of $P$, and must not assume any pre-packaged automatic differentiation. Use that the projection is linear so that\n$$\nP\\big((u_0, v_0) + \\alpha (u_b, v_b)\\big) = P(u_0, v_0) + \\alpha \\, P(u_b, v_b),\n$$\nand thus\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}\\alpha} (u(\\alpha), v(\\alpha)) = P(u_b, v_b).\n$$\nCombine this with the chain rule applied to $\\mathcal{L}(\\alpha)$ to obtain an explicit expression for $\\mathrm{d}\\mathcal{L}/\\mathrm{d}\\alpha$ in terms of $(u(\\alpha)-u_T, v(\\alpha)-v_T)$ and $P(u_b, v_b)$.\n4. Verify the correctness of your analytic gradient by comparing it to a central finite-difference approximation:\n$$\n\\frac{\\mathrm{d}\\mathcal{L}}{\\mathrm{d}\\alpha} \\approx \\frac{\\mathcal{L}(\\alpha + \\varepsilon) - \\mathcal{L}(\\alpha - \\varepsilon)}{2 \\varepsilon},\n$$\nfor a small step $\\varepsilon$.\n5. All velocity fields must be constructed from smooth trigonometric modes that are periodic on $[0,L_x] \\times [0,L_y]$. The target field must be set to the projection of the base field: $(u_T, v_T) = P(u_0, v_0)$, to ensure physical consistency.\n\nPhysical units: $x$ and $y$ in meters, $u$ and $v$ in meters per second, $\\mathcal{L}$ in $\\mathrm{m}^4/\\mathrm{s}^2$, and $\\mathrm{d}\\mathcal{L}/\\mathrm{d}\\alpha$ in $\\mathrm{m}^4/\\mathrm{s}^2$ since $\\alpha$ is dimensionless. Report the final numerical errors as dimensionless quantities as specified below.\n\nProvide a program that evaluates the relative discrepancy between the analytic gradient and the finite-difference approximation for each of the following test cases. For each case, compute the error metric\n$$\nE = \\frac{\\left| \\left(\\mathrm{d}\\mathcal{L}/\\mathrm{d}\\alpha\\right)_{\\mathrm{analytic}} - \\left(\\mathrm{d}\\mathcal{L}/\\mathrm{d}\\alpha\\right)_{\\mathrm{FD}} \\right|}{\\max\\left(1, \\left| \\left(\\mathrm{d}\\mathcal{L}/\\mathrm{d}\\alpha\\right)_{\\mathrm{analytic}} \\right|\\right)}.\n$$\n\nTest suite:\n- Case A (general mixed basis, happy path): $N_x = 32$, $N_y = 32$, $L_x = 10^6$ meters, $L_y = 10^6$ meters, $\\alpha = 0.3$, $\\varepsilon = 10^{-6}$. Construct\n  - $u_0(x,y) = 0.08 \\, \\sin\\left(2\\pi x/L_x\\right) \\cos\\left(2\\pi y/L_y\\right)$,\n  - $v_0(x,y) = -0.05 \\, \\cos\\left(2\\pi x/L_x\\right) \\sin\\left(2\\pi y/L_y\\right)$,\n  - $(u_b, v_b)$ as the mixed field\n    $u_b(x,y) = 0.06 \\, \\sin\\left(4\\pi x/L_x\\right) \\cos\\left(2\\pi y/L_y\\right) + 0.03 \\, \\cos\\left(2\\pi x/L_x\\right) \\sin\\left(6\\pi y/L_y\\right)$,\n    $v_b(x,y) = 0.02 \\, \\cos\\left(4\\pi x/L_x\\right) \\sin\\left(2\\pi y/L_y\\right) + 0.07 \\, \\sin\\left(2\\pi x/L_x\\right) \\cos\\left(6\\pi y/L_y\\right)$.\n- Case B (divergence-free basis): $N_x = 32$, $N_y = 32$, $L_x = 10^6$ meters, $L_y = 10^6$ meters, $\\alpha = -0.7$, $\\varepsilon = 10^{-6}$. Construct $(u_b, v_b)$ from a streamfunction $\\psi(x,y) = \\Psi_0 \\sin\\left(2\\pi x/L_x\\right) \\sin\\left(4\\pi y/L_y\\right)$ with $\\Psi_0 = 5\\times 10^3 \\, \\mathrm{m}^2/\\mathrm{s}$ via $u_b = \\partial_y \\psi$, $v_b = -\\partial_x \\psi$. Use the same $(u_0,v_0)$ as in Case A.\n- Case C (pure gradient basis, edge case): $N_x = 32$, $N_y = 32$, $L_x = 10^6$ meters, $L_y = 10^6$ meters, $\\alpha = 0.5$, $\\varepsilon = 10^{-6}$. Construct $(u_b, v_b)$ from a potential $\\phi(x,y) = \\Phi_0 \\sin\\left(2\\pi x/L_x\\right) \\cos\\left(2\\pi y/L_y\\right)$ with $\\Phi_0 = 5\\times 10^3 \\, \\mathrm{m}^2/\\mathrm{s}$ via $u_b = \\partial_x \\phi$, $v_b = \\partial_y \\phi$. Use the same $(u_0,v_0)$ as in Case A.\n- Case D (small grid resolution, boundary condition stress test): $N_x = 8$, $N_y = 8$, $L_x = 10^6$ meters, $L_y = 10^6$ meters, $\\alpha = 10^{-3}$, $\\varepsilon = 10^{-7}$. Use $(u_0,v_0)$ as in Case A and the mixed $(u_b, v_b)$ from Case A.\n\nFor all cases, set the target field $(u_T, v_T)$ to the projected base field $P(u_0, v_0)$. The analytic gradient must be computed from first principles, not by automatic differentiation. Angles for trigonometric functions are in radians.\n\nYour program should produce a single line of output containing the errors for Cases A, B, C, and D as a comma-separated list enclosed in square brackets (e.g., \"[e_A,e_B,e_C,e_D]\"), where each $e$ is a floating-point number representing $E$ for that case, dimensionless, printed with full machine precision available by the default string conversion in the specified environment.",
            "solution": "The user-provided problem statement has been meticulously validated and is determined to be scientifically sound, well-posed, and complete. All necessary data, physical principles, and mathematical formulations are provided and are consistent with established practices in computational fluid dynamics and numerical analysis. The task requires the implementation and verification of a differentiable spectral Poisson solver, which is a standard and non-trivial problem in physics-informed machine learning for ocean modeling. I will now proceed with a complete solution.\n\nThe solution is structured as follows:\n1.  Establishment of the discrete domain and spectral representation.\n2.  Implementation of the spectral pressure projection operator $P$.\n3.  Derivation of the analytic gradient $\\mathrm{d}\\mathcal{L}/\\mathrm{d}\\alpha$.\n4.  Description of the verification process using a finite-difference approximation.\n\n**1. Discrete Domain and Spectral Representation**\n\nWe consider a two-dimensional periodic domain $[0, L_x] \\times [0, L_y]$ discretized by a uniform grid with $N_x \\times N_y$ points. The grid spacings are $\\Delta x = L_x/N_x$ and $\\Delta y = L_y/N_y$. A physical field $f(x,y)$ is represented by its values $f_{j,k} = f(j\\Delta x, k\\Delta y)$ on this grid.\n\nThe core of the spectral method is the two-dimensional Discrete Fourier Transform (DFT), realized via the Fast Fourier Transform (FFT) algorithm. The transform of a field $f$ is denoted $\\hat{f}$. The corresponding angular wavenumbers for a grid of size $N$ and length $L$ are given by $k_n = 2\\pi n / L$ for an integer mode number $n$. For a discrete grid, the wavenumbers are calculated as $k_m = 2\\pi f_m$, where $f_m$ are the frequencies returned by standard FFT libraries. For a grid of size $N$ with spacing $d$, these are $f_m = m/(N d)$ for $m \\in \\{-N/2, \\dots, N/2-1\\}$ (or a similar range).\n\nWe define the two-dimensional wavenumber grids $k_x$ and $k_y$ corresponding to the dimensions of our domain. Let $\\boldsymbol{k} = (k_x, k_y)$. Using these, we can define spectral differential operators. The Fourier transform of a partial derivative is given by:\n$$\n\\widehat{\\frac{\\partial f}{\\partial x}}(\\boldsymbol{k}) = i k_x \\hat{f}(\\boldsymbol{k}) \\quad \\text{and} \\quad \\widehat{\\frac{\\partial f}{\\partial y}}(\\boldsymbol{k}) = i k_y \\hat{f}(\\boldsymbol{k})\n$$\nwhere $i = \\sqrt{-1}$. Consequently, the divergence of a vector field $(u, v)$ and the Laplacian of a scalar field $p$ are expressed in Fourier space as:\n$$\n\\widehat{\\nabla \\cdot (u,v)}(\\boldsymbol{k}) = i k_x \\hat{u}(\\boldsymbol{k}) + i k_y \\hat{v}(\\boldsymbol{k})\n$$\n$$\n\\widehat{\\Delta p}(\\boldsymbol{k}) = \\widehat{\\nabla \\cdot \\nabla p}(\\boldsymbol{k}) = (i k_x)(i k_x) \\hat{p}(\\boldsymbol{k}) + (i k_y)(i k_y) \\hat{p}(\\boldsymbol{k}) = -(k_x^2 + k_y^2)\\hat{p}(\\boldsymbol{k}) = -|\\boldsymbol{k}|^2 \\hat{p}(\\boldsymbol{k})\n$$\n\n**2. Spectral Pressure Projection Operator**\n\nThe pressure projection operator $P$ maps a tentative velocity field $(u^\\ast, v^\\ast)$ to a divergence-free field $(u, v)$. This involves three steps, which can be efficiently combined in Fourier space.\n\nFirst, we compute the divergence of the tentative field, $g = \\nabla \\cdot (u^\\ast, v^\\ast)$. In Fourier space, this is:\n$$\n\\hat{g}(\\boldsymbol{k}) = i k_x \\hat{u}^\\ast(\\boldsymbol{k}) + i k_y \\hat{v}^\\ast(\\boldsymbol{k})\n$$\nSecond, a Poisson problem $\\Delta p = g$ is solved for the pressure field $p$. In Fourier space, this algebraic equation becomes:\n$$\n-|\\boldsymbol{k}|^2 \\hat{p}(\\boldsymbol{k}) = \\hat{g}(\\boldsymbol{k})\n$$\nThe solution for $\\hat{p}$ is thus $\\hat{p}(\\boldsymbol{k}) = -\\hat{g}(\\boldsymbol{k}) / |\\boldsymbol{k}|^2$. For the zero-wavenumber mode $\\boldsymbol{k}=(0,0)$, the denominator $|\\boldsymbol{k}|^2$ is zero. However, for a periodic field $(u^\\ast, v^\\ast)$, the divergence theorem ensures that the mean of $g$ is zero, i.e., $\\hat{g}(0,0)=0$. The problem is made well-posed by enforcing a zero-mean constraint on the pressure, $\\hat{p}(0,0)=0$. We therefore define the inverse Laplacian operator kernel as:\n$$\n\\widehat{\\Delta^{-1}}(\\boldsymbol{k}) = \\begin{cases} -1/|\\boldsymbol{k}|^2 & \\text{if } \\boldsymbol{k} \\neq (0,0) \\\\ 0 & \\text{if } \\boldsymbol{k} = (0,0) \\end{cases}\n$$\nSo, $\\hat{p}(\\boldsymbol{k}) = \\widehat{\\Delta^{-1}}(\\boldsymbol{k}) \\hat{g}(\\boldsymbol{k})$.\n\nThird, the final projected velocity is obtained by subtracting the pressure gradient, $(u, v) = (u^\\ast, v^\\ast) - \\nabla p$. In Fourier space:\n$$\n\\hat{u}(\\boldsymbol{k}) = \\hat{u}^\\ast(\\boldsymbol{k}) - i k_x \\hat{p}(\\boldsymbol{k})\n$$\n$$\n\\hat{v}(\\boldsymbol{k}) = \\hat{v}^\\ast(\\boldsymbol{k}) - i k_y \\hat{p}(\\boldsymbol{k})\n$$\nSubstituting the expressions for $\\hat{p}$ and $\\hat{g}$, we can express the entire projection operator $P$ in Fourier space. Let $(u,v) = P(u^\\ast, v^\\ast)$, then:\n$$\n\\hat{u}(\\boldsymbol{k}) = \\hat{u}^\\ast(\\boldsymbol{k}) - i k_x \\widehat{\\Delta^{-1}}(\\boldsymbol{k}) \\left( i k_x \\hat{u}^\\ast(\\boldsymbol{k}) + i k_y \\hat{v}^\\ast(\\boldsymbol{k}) \\right) = \\left( 1 - \\frac{k_x^2}{|\\boldsymbol{k}|^2} \\right) \\hat{u}^\\ast(\\boldsymbol{k}) - \\frac{k_x k_y}{|\\boldsymbol{k}|^2} \\hat{v}^\\ast(\\boldsymbol{k})\n$$\n$$\n\\hat{v}(\\boldsymbol{k}) = \\hat{v}^\\ast(\\boldsymbol{k}) - i k_y \\widehat{\\Delta^{-1}}(\\boldsymbol{k}) \\left( i k_x \\hat{u}^\\ast(\\boldsymbol{k}) + i k_y \\hat{v}^\\ast(\\boldsymbol{k}) \\right) = -\\frac{k_x k_y}{|\\boldsymbol{k}|^2} \\hat{u}^\\ast(\\boldsymbol{k}) + \\left( 1 - \\frac{k_y^2}{|\\boldsymbol{k}|^2} \\right) \\hat{v}^\\ast(\\boldsymbol{k})\n$$\nThese expressions are valid for $\\boldsymbol{k} \\neq (0,0)$. For $\\boldsymbol{k}=(0,0)$, $\\hat{u}(0,0)=\\hat{u}^\\ast(0,0)$ and $\\hat{v}(0,0)=\\hat{v}^\\ast(0,0)$. The implementation will follow this formulation by transforming the input fields $(u^\\ast, v^\\ast)$ to Fourier space, applying the projection tensor, and transforming back.\n\n**3. Loss Function and Analytic Gradient**\n\nThe loss function is defined as a discrete sum approximating the integral of the squared error:\n$$\n\\mathcal{L}(\\alpha) = \\frac{1}{2} \\Delta A \\sum_{j,k} \\left( \\left[u_{j,k}(\\alpha) - u_{T,j,k}\\right]^2 + \\left[v_{j,k}(\\alpha) - v_{T,j,k}\\right]^2 \\right)\n$$\nwhere $\\Delta A = \\Delta x \\Delta y$ is the area of a grid cell.\n\nTo find the analytic gradient $\\mathrm{d}\\mathcal{L}/\\mathrm{d}\\alpha$, we apply the chain rule:\n$$\n\\frac{\\mathrm{d}\\mathcal{L}}{\\mathrm{d}\\alpha} = \\Delta A \\sum_{j,k} \\left( \\left[u_{j,k}(\\alpha) - u_{T,j,k}\\right] \\frac{\\mathrm{d}u_{j,k}}{\\mathrm{d}\\alpha} + \\left[v_{j,k}(\\alpha) - v_{T,j,k}\\right] \\frac{\\mathrm{d}v_{j,k}}{\\mathrm{d}\\alpha} \\right)\n$$\nThe problem states that the projection operator $P$ is linear. The parametric velocity is $(u^\\ast(\\alpha), v^\\ast(\\alpha)) = (u_0, v_0) + \\alpha \\, (u_b, v_b)$. Applying the linear operator $P$ gives:\n$$\n(u(\\alpha), v(\\alpha)) = P\\big( (u_0, v_0) + \\alpha(u_b, v_b) \\big) = P(u_0, v_0) + \\alpha P(u_b, v_b)\n$$\nLet $(u_p, v_p) = P(u_0, v_0)$ and $(u_{bp}, v_{bp}) = P(u_b, v_b)$. Then $(u(\\alpha), v(\\alpha)) = (u_p, v_p) + \\alpha(u_{bp}, v_{bp})$. The derivatives with respect to $\\alpha$ are simply:\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}\\alpha} (u(\\alpha), v(\\alpha)) = (u_{bp}, v_{bp}) = P(u_b, v_b)\n$$\nThe target velocity field is set to $(u_T, v_T) = P(u_0, v_0) = (u_p, v_p)$. The error term in the gradient expression becomes:\n$$\n(u(\\alpha) - u_T, v(\\alpha) - v_T) = \\left( (u_p + \\alpha u_{bp}) - u_p, (v_p + \\alpha v_{bp}) - v_p \\right) = (\\alpha u_{bp}, \\alpha v_{bp})\n$$\nSubstituting these results back into the expression for $\\mathrm{d}\\mathcal{L}/\\mathrm{d}\\alpha$:\n$$\n\\frac{\\mathrm{d}\\mathcal{L}}{\\mathrm{d}\\alpha} = \\Delta A \\sum_{j,k} \\left( (\\alpha u_{bp,j,k}) (u_{bp,j,k}) + (\\alpha v_{bp,j,k}) (v_{bp,j,k}) \\right)\n$$\nFactoring out the scalar $\\alpha$ yields the final analytic expression for the gradient:\n$$\n\\frac{\\mathrm{d}\\mathcal{L}}{\\mathrm{d}\\alpha} = \\alpha \\left( \\Delta A \\sum_{j,k} \\left( u_{bp,j,k}^2 + v_{bp,j,k}^2 \\right) \\right)\n$$\nThis expression is implemented by first computing the projected field $(u_{bp}, v_{bp}) = P(u_b, v_b)$, then calculating the sum of its squared magnitude over the grid, scaling by $\\Delta A$ and $\\alpha$.\n\n**4. Verification via Finite Differences**\n\nTo verify the correctness of the analytic gradient implementation, we compare its output against a second-order accurate central finite-difference (FD) approximation. For a small step size $\\varepsilon$, the FD gradient is:\n$$\n\\left(\\frac{\\mathrm{d}\\mathcal{L}}{\\mathrm{d}\\alpha}\\right)_{\\mathrm{FD}} = \\frac{\\mathcal{L}(\\alpha + \\varepsilon) - \\mathcal{L}(\\alpha - \\varepsilon)}{2 \\varepsilon}\n$$\nThis requires evaluating the full loss function twice. The discrepancy between the analytic and FD gradients is quantified by the normalized error metric $E$:\n$$\nE = \\frac{\\left| \\left(\\mathrm{d}\\mathcal{L}/\\mathrm{d}\\alpha\\right)_{\\mathrm{analytic}} - \\left(\\mathrm{d}\\mathcal{L}/\\mathrm{d}\\alpha\\right)_{\\mathrm{FD}} \\right|}{\\max\\left(1, \\left| \\left(\\mathrm{d}\\mathcal{L}/\\mathrm{d}\\alpha\\right)_{\\mathrm{analytic}} \\right|\\right)}\n$$\nThe denominator $\\max(1, |\\cdot|)$ provides robustness by preventing division by zero when the analytic gradient is zero or near-zero, transitioning from a relative to an absolute error measure. For a correct implementation and a sufficiently small $\\varepsilon$, this error $E$ is expected to be very small, approaching machine precision limited by the truncation error of the FD formula (proportional to $\\varepsilon^2$) and floating-point round-off error.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import fft\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n\n    def create_spectral_ops(Nx, Ny, Lx, Ly):\n        \"\"\"\n        Creates wavenumber grids and the inverse Laplacian operator kernel.\n        \"\"\"\n        kx_vec = 2 * np.pi * fft.fftfreq(Nx, d=Lx / Nx)\n        ky_vec = 2 * np.pi * fft.fftfreq(Ny, d=Ly / Ny)\n        kxx, kyy = np.meshgrid(kx_vec, ky_vec)\n        ksq = kxx**2 + kyy**2\n        \n        # Regularize inverse Laplacian for the zero-wavenumber mode\n        inv_ksq = np.zeros_like(ksq)\n        non_zero_k = ksq != 0\n        inv_ksq[non_zero_k] = 1.0 / ksq[non_zero_k]\n        \n        return kxx, kyy, inv_ksq\n\n    def project(u_star, v_star, kxx, kyy, inv_ksq):\n        \"\"\"\n        Applies the spectral pressure projection operator.\n        \"\"\"\n        # Using ortho norm, no need to scale FFTs\n        u_star_hat = fft.fft2(u_star, norm='ortho')\n        v_star_hat = fft.fft2(v_star, norm='ortho')\n        \n        # Divergence in Fourier space\n        g_hat = 1j * kxx * u_star_hat + 1j * kyy * v_star_hat\n        \n        # Pressure in Fourier space (p_hat = -g_hat * inv_ksq)\n        p_hat = -g_hat * inv_ksq\n        \n        # Subtract pressure gradient in Fourier space\n        u_hat = u_star_hat - 1j * kxx * p_hat\n        v_hat = v_star_hat - 1j * kyy * p_hat\n        \n        # Transform back to physical space\n        u = fft.ifft2(u_hat, norm='ortho').real\n        v = fft.ifft2(v_hat, norm='ortho').real\n        \n        return u, v\n\n    def calculate_loss(alpha, u0, v0, ub, vb, uT, vT, Nx, Ny, Lx, Ly, kxx, kyy, inv_ksq):\n        \"\"\"\n        Computes the loss L(alpha).\n        \"\"\"\n        u_star_alpha = u0 + alpha * ub\n        v_star_alpha = v0 + alpha * vb\n        \n        u_alpha, v_alpha = project(u_star_alpha, v_star_alpha, kxx, kyy, inv_ksq)\n        \n        dA = (Lx / Nx) * (Ly / Ny)\n        loss = 0.5 * np.sum((u_alpha - uT)**2 + (v_alpha - vT)**2) * dA\n        return loss\n\n    def calculate_analytic_gradient(alpha, ub, vb, Nx, Ny, Lx, Ly, kxx, kyy, inv_ksq):\n        \"\"\"\n        Computes the analytic gradient dL/dalpha.\n        \"\"\"\n        ubp, vbp = project(ub, vb, kxx, kyy, inv_ksq)\n        \n        dA = (Lx / Nx) * (Ly / Ny)\n        integral_term = np.sum(ubp**2 + vbp**2) * dA\n        \n        grad_analytic = alpha * integral_term\n        return grad_analytic\n\n    def calculate_fd_gradient(alpha, eps, u0, v0, ub, vb, uT, vT, Nx, Ny, Lx, Ly, kxx, kyy, inv_ksq):\n        \"\"\"\n        Computes the finite-difference gradient.\n        \"\"\"\n        loss_plus = calculate_loss(alpha + eps, u0, v0, ub, vb, uT, vT, Nx, Ny, Lx, Ly, kxx, kyy, inv_ksq)\n        loss_minus = calculate_loss(alpha - eps, u0, v0, ub, vb, uT, vT, Nx, Ny, Lx, Ly, kxx, kyy, inv_ksq)\n        \n        grad_fd = (loss_plus - loss_minus) / (2 * eps)\n        return grad_fd\n\n    test_cases = [\n        # Case A\n        {'Nx': 32, 'Ny': 32, 'Lx': 1e6, 'Ly': 1e6, 'alpha': 0.3, 'eps': 1e-6, 'case_id': 'A'},\n        # Case B\n        {'Nx': 32, 'Ny': 32, 'Lx': 1e6, 'Ly': 1e6, 'alpha': -0.7, 'eps': 1e-6, 'case_id': 'B'},\n        # Case C\n        {'Nx': 32, 'Ny': 32, 'Lx': 1e6, 'Ly': 1e6, 'alpha': 0.5, 'eps': 1e-6, 'case_id': 'C'},\n        # Case D\n        {'Nx': 8, 'Ny': 8, 'Lx': 1e6, 'Ly': 1e6, 'alpha': 1e-3, 'eps': 1e-7, 'case_id': 'D'}\n    ]\n\n    results = []\n\n    for case in test_cases:\n        Nx, Ny, Lx, Ly, alpha, eps = case['Nx'], case['Ny'], case['Lx'], case['Ly'], case['alpha'], case['eps']\n        \n        # Create grid\n        x = np.arange(Nx) * (Lx / Nx)\n        y = np.arange(Ny) * (Ly / Ny)\n        xx, yy = np.meshgrid(x, y)\n\n        # Create spectral operators\n        kxx, kyy, inv_ksq = create_spectral_ops(Nx, Ny, Lx, Ly)\n\n        # Define base velocity field (u0, v0) - common for all cases\n        u0 = 0.08 * np.sin(2 * np.pi * xx / Lx) * np.cos(2 * np.pi * yy / Ly)\n        v0 = -0.05 * np.cos(2 * np.pi * xx / Lx) * np.sin(2 * np.pi * yy / Ly)\n        \n        # Define perturbation velocity field (ub, vb) based on case\n        if case['case_id'] in ['A', 'D']:\n            ub = 0.06 * np.sin(4 * np.pi * xx / Lx) * np.cos(2 * np.pi * yy / Ly) + \\\n                 0.03 * np.cos(2 * np.pi * xx / Lx) * np.sin(6 * np.pi * yy / Ly)\n            vb = 0.02 * np.cos(4 * np.pi * xx / Lx) * np.sin(2 * np.pi * yy / Ly) + \\\n                 0.07 * np.sin(2 * np.pi * xx / Lx) * np.cos(6 * np.pi * yy / Ly)\n        elif case['case_id'] == 'B':\n            Psi0 = 5e3\n            ub = Psi0 * (4 * np.pi / Ly) * np.sin(2 * np.pi * xx / Lx) * np.cos(4 * np.pi * yy / Ly)\n            vb = -Psi0 * (2 * np.pi / Lx) * np.cos(2 * np.pi * xx / Lx) * np.sin(4 * np.pi * yy / Ly)\n        elif case['case_id'] == 'C':\n            Phi0 = 5e3\n            ub = Phi0 * (2 * np.pi / Lx) * np.cos(2 * np.pi * xx / Lx) * np.cos(2 * np.pi * yy / Ly)\n            vb = -Phi0 * (2 * np.pi / Ly) * np.sin(2 * np.pi * xx / Lx) * np.sin(2 * np.pi * yy / Ly)\n\n        # Compute target field\n        uT, vT = project(u0, v0, kxx, kyy, inv_ksq)\n        \n        # Calculate gradients\n        grad_analytic = calculate_analytic_gradient(alpha, ub, vb, Nx, Ny, Lx, Ly, kxx, kyy, inv_ksq)\n        grad_fd = calculate_fd_gradient(alpha, eps, u0, v0, ub, vb, uT, vT, Nx, Ny, Lx, Ly, kxx, kyy, inv_ksq)\n        \n        # Calculate error metric\n        error = np.abs(grad_analytic - grad_fd) / np.maximum(1.0, np.abs(grad_analytic))\n        results.append(error)\n        \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "This final practice integrates the preceding concepts into a complete scientific workflow for model discovery. You will conduct a 'twin experiment,' a standard validation technique in geosciences, to assess a PIML model's ability to learn an unknown physical closure from data . By first generating a synthetic 'ground truth' and then attempting to recover the underlying physical parameters from noisy observations, you will experience the end-to-end process of PIML-based system identification. This exercise highlights how PIML can be used not just to simulate known physics, but to discover new physical laws, and it underscores the importance of rigorously testing model performance against noise and uncertainty.",
            "id": "3807973",
            "problem": "Consider a one-dimensional tracer transport model used in computational oceanography that represents the evolution of tracer concentration by a conservation law. Starting from the conservation of mass for a passive tracer, the governing equation on a periodic domain of length $L$ is\n$$\n\\frac{\\partial C}{\\partial t} + u \\frac{\\partial C}{\\partial x} = \\frac{\\partial}{\\partial x}\\left( K(C_x) \\, \\frac{\\partial C}{\\partial x} \\right),\n$$\nwhere $C(x,t)$ is the tracer concentration in $\\mathrm{kg}\\,\\mathrm{m}^{-3}$, $u$ is the constant advection velocity in $\\mathrm{m}\\,\\mathrm{s}^{-1}$, $K$ is the (unknown) subgrid-scale diffusivity in $\\mathrm{m}^2\\,\\mathrm{s}^{-1}$, and $C_x \\equiv \\frac{\\partial C}{\\partial x}$. The boundary condition is periodic in $x \\in [0,L]$. Assume that the true subgrid-scale closure is of the form\n$$\nK_{\\mathrm{true}}(C_x) = k_0^{\\mathrm{(true)}} + a^{\\mathrm{(true)}} \\left( \\frac{|C_x|}{G_0} \\right),\n$$\nwhere $k_0^{\\mathrm{(true)}}$ has units $\\mathrm{m}^2\\,\\mathrm{s}^{-1}$, $a^{\\mathrm{(true)}}$ has units $\\mathrm{m}^2\\,\\mathrm{s}^{-1}$, and $G_0$ is a fixed gradient scale with units $\\mathrm{kg}\\,\\mathrm{m}^{-4}$ to nondimensionalize $|C_x|$. You will construct twin experiments by generating a synthetic truth using this closure, produce noisy observations, and estimate the closure parameters using Physics-Informed Machine Learning (PIML), where Physics-Informed Machine Learning (PIML) is defined as a learning paradigm that constrains model training with physical laws such as partial differential equations (PDEs). The unknown parameters are $\\theta = (k_0, a)$ and the PIML estimation should be obtained by minimizing the squared residual of the governing equation evaluated on the noisy observations.\n\nFundamental base for derivation and algorithm design:\n- Conservation of mass for a passive tracer in one space dimension: \n$$\n\\frac{\\partial C}{\\partial t} + \\frac{\\partial}{\\partial x}\\left( u C - K(C_x) \\frac{\\partial C}{\\partial x} \\right) = 0.\n$$\n- Constant advection velocity $u$ and periodic boundary conditions on a uniform grid.\n- Finite difference approximations of spatial and temporal derivatives on a uniform grid with spacing $\\Delta x$ and time step $\\Delta t$.\n\nYou must implement the following steps in a complete, runnable program:\n1. Define the computational domain and initial condition. Use $L = 1000\\,\\mathrm{m}$, $u = 0.1\\,\\mathrm{m}\\,\\mathrm{s}^{-1}$, $N_x = 64$ spatial points, and $\\Delta t = 0.5\\,\\mathrm{s}$ for $N_t = 400$ time steps (total assimilation window $T = N_t \\Delta t = 200\\,\\mathrm{s}$). Use a periodic initial condition\n$$\nC(x,0) = A_1 \\sin\\left( \\frac{2\\pi x}{L} \\right) + \\frac{A_1}{2} \\sin\\left( \\frac{4\\pi x}{L} \\right),\n$$\nwith $A_1 = 1.0\\,\\mathrm{kg}\\,\\mathrm{m}^{-3}$. Compute $G_0$ as the root-mean-square of $|C_x(x,0)|$ over the domain (i.e., $G_0 = \\sqrt{\\frac{1}{L}\\int_0^L |C_x(x,0)|^2 \\, \\mathrm{d}x}$), using the discrete approximation consistent with your grid.\n2. Generate the synthetic truth $C^{\\mathrm{true}}(x,t)$ by time stepping the governing equation with the true closure parameters $k_0^{\\mathrm{(true)}} = 10^{-5}\\,\\mathrm{m}^2\\,\\mathrm{s}^{-1}$ and $a^{\\mathrm{(true)}} = 5\\times 10^{-6}\\,\\mathrm{m}^2\\,\\mathrm{s}^{-1}$, using explicit time stepping:\n$$\nC^{n+1} = C^n + \\Delta t \\left( - u \\, \\partial_x C^n + \\partial_x\\left( K_{\\mathrm{true}}(C_x^n) \\, \\partial_x C^n \\right) \\right),\n$$\nwith second-order centered differences for spatial derivatives and periodic boundary conditions. Here $C^n$ denotes $C(x,t_n)$.\n3. Generate noisy observations $C^{\\mathrm{obs}}(x,t)$ by adding zero-mean Gaussian noise with standard deviation $\\sigma = \\eta \\, \\mathrm{RMS}(C^{\\mathrm{true}})$, where $\\eta$ is a dimensionless noise level and $\\mathrm{RMS}(C^{\\mathrm{true}})$ is the root-mean-square of $C^{\\mathrm{true}}$ over space and time. You must use the same random seed for all test cases to ensure reproducibility.\n4. Estimate the parameters $\\theta = (k_0, a)$ using PIML by minimizing the mean squared residual of the governing equation evaluated on $C^{\\mathrm{obs}}$:\n$$\nJ(\\theta) = \\left\\langle \\left( \\frac{\\partial C^{\\mathrm{obs}}}{\\partial t} + u \\frac{\\partial C^{\\mathrm{obs}}}{\\partial x} - \\frac{\\partial}{\\partial x}\\left( K_\\theta(C_x^{\\mathrm{obs}}) \\, \\frac{\\partial C^{\\mathrm{obs}}}{\\partial x} \\right) \\right)^2 \\right\\rangle,\n$$\nwhere $K_\\theta(C_x) = k_0 + a \\left( \\frac{|C_x|}{G_0} \\right)$ and $\\langle \\cdot \\rangle$ denotes the average over the spatiotemporal assimilation window. Use centered finite differences for $\\frac{\\partial C^{\\mathrm{obs}}}{\\partial t}$ on interior time levels and second-order centered differences for spatial derivatives. Constrain $k_0 \\ge 0$ and $a \\ge 0$ during optimization. Initialize the optimization at $k_0^{(0)} = 5\\times 10^{-6}\\,\\mathrm{m}^2\\,\\mathrm{s}^{-1}$ and $a^{(0)} = 7.5\\times 10^{-6}\\,\\mathrm{m}^2\\,\\mathrm{s}^{-1}$.\n5. After estimating $\\hat{\\theta} = (\\hat{k}_0, \\hat{a})$, re-simulate the model using the same numerical method and initial condition to obtain $C^{\\mathrm{est}}(x,t)$ with $K_{\\hat{\\theta}}$, and compute the normalized root-mean-square error (RMSE) over space and time:\n$$\n\\mathrm{NRMSE} = \\frac{\\sqrt{\\left\\langle \\left( C^{\\mathrm{est}} - C^{\\mathrm{true}} \\right)^2 \\right\\rangle}}{\\mathrm{RMS}(C^{\\mathrm{true}})}.\n$$\nAlso compute the relative parameter errors\n$$\ne_{k_0} = \\frac{|\\hat{k}_0 - k_0^{\\mathrm{(true)}}|}{k_0^{\\mathrm{(true)}}}, \\quad\ne_a = \\frac{|\\hat{a} - a^{\\mathrm{(true)}}|}{a^{\\mathrm{(true)}}}.\n$$\nAll reported metrics must be dimensionless.\nTest suite:\nRun the full twin-experiment and PIML estimation pipeline for the following three cases, which test different aspects of recovery performance:\n- Case $1$ (happy path): $\\eta = 0.00$.\n- Case $2$ (moderate noise): $\\eta = 0.02$.\n- Case $3$ (significant noise edge case): $\\eta = 0.08$.\nFinal output specification:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with one sublist per test case and no spaces. Each sublist must contain the three floats $[e_{k_0}, e_a, \\mathrm{NRMSE}]$ in that order, for the corresponding case. For example, the output format must be\n$$\n[\\,[e_{k_0}^{(1)},e_a^{(1)},\\mathrm{NRMSE}^{(1)}],[e_{k_0}^{(2)},e_a^{(2)},\\mathrm{NRMSE}^{(2)}],[e_{k_0}^{(3)},e_a^{(3)},\\mathrm{NRMSE}^{(3)}]\\,].\n$$\nAll numerical results must be printed as decimal floats. No physical units should be printed in the output because the metrics are dimensionless by construction.",
            "solution": "The problem statement is valid. It is a well-posed, scientifically grounded, and computationally feasible problem in the field of computational oceanography, specifically focusing on parameter estimation using a Physics-Informed Machine Learning (PIML) approach. The premises are consistent with fundamental principles of fluid dynamics and standard numerical methods. All necessary parameters, equations, and procedures are provided to construct a unique and verifiable solution.\n\nThe solution proceeds by first implementing the numerical framework for the one-dimensional tracer transport model, followed by the execution of a twin experiment to test the PIML parameter recovery algorithm.\n\n### 1. Model Discretization and Numerical Methods\n\nThe governing advection-diffusion equation for the tracer concentration $C(x, t)$ is given on a periodic domain of length $L$:\n$$\n\\frac{\\partial C}{\\partial t} + u \\frac{\\partial C}{\\partial x} = \\frac{\\partial}{\\partial x}\\left( K(C_x) \\, \\frac{\\partial C}{\\partial x} \\right)\n$$\nThe domain $x \\in [0, L]$ is discretized into a uniform grid of $N_x$ points with spacing $\\Delta x = L/N_x$, such that $x_i = i \\Delta x$ for $i = 0, 1, \\dots, N_x-1$. Time is discretized with a constant step $\\Delta t$.\n\nSpatial derivatives are approximated using second-order centered finite differences, which respect the periodicity of the domain. For a grid function $f(x_i) = f_i$, the first and second derivatives are:\n$$\n\\left(\\frac{\\partial f}{\\partial x}\\right)_i \\approx \\frac{f_{i+1} - f_{i-1}}{2 \\Delta x}\n$$\n$$\n\\left(\\frac{\\partial^2 f}{\\partial x^2}\\right)_i \\approx \\frac{f_{i+1} - 2f_i + f_{i-1}}{(\\Delta x)^2}\n$$\nThe term involving the nonlinear diffusivity, $\\frac{\\partial}{\\partial x}\\left( K(C_x) \\frac{\\partial C}{\\partial x} \\right)$, is handled by first computing the flux term $F = K(C_x) \\frac{\\partial C}{\\partial x}$ at the grid points, and then applying the centered difference operator for the outer derivative $\\frac{\\partial F}{\\partial x}$.\n\nTime integration is performed using the explicit forward Euler method, consistent with the specified time-stepping formula:\n$$\nC_i^{n+1} = C_i^n + \\Delta t \\cdot \\mathcal{R}(C^n)_i\n$$\nwhere $\\mathcal{R}(C^n)_i$ represents the discretized right-hand side of the PDE evaluated at time level $n$ and spatial point $i$. The stability of this explicit scheme is ensured as the Courant-Friedrichs-Lewy (CFL) conditions for both advection and diffusion are satisfied by the provided parameters.\n\n### 2. Synthetic Data Generation\n\nA twin experiment requires a \"ground truth\" dataset. This is generated by solving the governing PDE with a known set of true parameters.\n\n**Initial Condition and Gradient Scale $G_0$**:\nThe simulation starts from the specified periodic initial condition:\n$$\nC(x,0) = A_1 \\sin\\left( \\frac{2\\pi x}{L} \\right) + \\frac{A_1}{2} \\sin\\left( \\frac{4\\pi x}{L} \\right)\n$$\nThe diffusivity model $K(C_x) = k_0 + a (|C_x|/G_0)$ requires a characteristic gradient scale $G_0$ for non-dimensionalization. This is calculated as the root-mean-square of the initial concentration gradient, $|C_x(x,0)|$, over the domain. The discrete approximation consistent with our grid is:\n$$\nG_0 = \\sqrt{\\frac{1}{N_x} \\sum_{i=0}^{N_x-1} \\left| \\left(\\frac{\\partial C}{\\partial x}\\right)_{i, t=0} \\right|^2}\n$$\n\n**Truth Simulation**:\nUsing the initial condition $C(x,0)$, the true parameters $k_0^{\\mathrm{(true)}} = 10^{-5}\\,\\mathrm{m}^2\\,\\mathrm{s}^{-1}$ and $a^{\\mathrm{(true)}} = 5\\times 10^{-6}\\,\\mathrm{m}^2\\,\\mathrm{s}^{-1}$, and the calculated $G_0$, the model is integrated forward in time for $N_t$ steps to produce the true spatiotemporal field $C^{\\mathrm{true}}(x,t)$.\n\n**Noisy Observations**:\nObservations $C^{\\mathrm{obs}}(x,t)$ are simulated by corrupting the true field with additive zero-mean Gaussian noise. The noise standard deviation $\\sigma$ is proportional to the overall magnitude of the true signal, i.e., $\\sigma = \\eta \\, \\mathrm{RMS}(C^{\\mathrm{true}})$, where $\\eta$ is the noise level and $\\mathrm{RMS}(C^{\\mathrm{true}})$ is the root-mean-square of $C^{\\mathrm{true}}$ over the entire spatiotemporal domain. A fixed random seed ensures reproducibility across test cases.\n\n### 3. PIML-Based Parameter Estimation\n\nThe core of the task is to estimate the parameters $\\theta = (k_0, a)$ from the noisy observations $C^{\\mathrm{obs}}$. The PIML approach does this by minimizing the discrepancy between the observations and the governing physical law. The cost function $J(\\theta)$ is the mean squared residual of the PDE:\n$$\nJ(\\theta) = \\left\\langle \\left( \\frac{\\partial C^{\\mathrm{obs}}}{\\partial t} + u \\frac{\\partial C^{\\mathrm{obs}}}{\\partial x} - \\frac{\\partial}{\\partial x}\\left( K_\\theta(C_x^{\\mathrm{obs}}) \\, \\frac{\\partial C^{\\mathrm{obs}}}{\\partial x} \\right) \\right)^2 \\right\\rangle\n$$\nBy expanding the diffusivity term $K_\\theta$, the expression inside the square becomes linear in the parameters $k_0$ and $a$:\n$$\n\\text{Residual}(\\theta) = \\left(\\frac{\\partial C^{\\mathrm{obs}}}{\\partial t} + u \\frac{\\partial C^{\\mathrm{obs}}}{\\partial x}\\right) - k_0 \\left(\\frac{\\partial^2 C^{\\mathrm{obs}}}{\\partial x^2}\\right) - a \\left(\\frac{1}{G_0} \\frac{\\partial}{\\partial x}\\left(\\left|\\frac{\\partial C^{\\mathrm{obs}}}{\\partial x}\\right| \\frac{\\partial C^{\\mathrm{obs}}}{\\partial x}\\right)\\right)\n$$\nThis can be formulated as a linear least-squares problem, $y \\approx k_0 X_1 + a X_2$.\n- The target vector $y$ is computed from the terms without unknown parameters: $y = \\frac{\\partial C^{\\mathrm{obs}}}{\\partial t} + u \\frac{\\partial C^{\\mathrm{obs}}}{\\partial x}$.\n- The feature vectors (or regression coefficients) $X_1$ and $X_2$ are the terms multiplying $k_0$ and $a$: $X_1 = \\frac{\\partial^2 C^{\\mathrm{obs}}}{\\partial x^2}$ and $X_2 = \\frac{1}{G_0} \\frac{\\partial}{\\partial x}\\left(\\left|\\frac{\\partial C^{\\mathrm{obs}}}{\\partial x}\\right| \\frac{\\partial C^{\\mathrm{obs}}}{\\partial x}\\right)$.\n\nAll derivatives of $C^{\\mathrm{obs}}$ are computed using the same finite difference schemes. The time derivative is computed using a centered difference on interior time points ($t=1, \\dots, N_t-1$), and all spatial derivatives are evaluated on this same interior spatiotemporal grid.\n\nThe optimization problem is to find $(\\hat{k}_0, \\hat{a}) = \\arg\\min_{k_0, a \\ge 0} J(k_0, a)$. This is a non-negative least-squares problem, which is solved using `scipy.optimize.minimize` with the `L-BFGS-B` method, incorporating the bounds $k_0 \\ge 0$, $a \\ge 0$ and the specified initial guess.\n\n### 4. Evaluation of Results\n\nThe performance of the PIML estimation is assessed using three metrics. First, the estimated parameters $(\\hat{k}_0, \\hat{a})$ are used to run a new forward simulation, starting from the original $C(x,0)$, to produce an estimated field $C^{\\mathrm{est}}(x,t)$. Then, the following are computed:\n1.  **Relative Error in $k_0$**: $e_{k_0} = |\\hat{k}_0 - k_0^{\\mathrm{(true)}}| / k_0^{\\mathrm{(true)}}$\n2.  **Relative Error in $a$**: $e_a = |\\hat{a} - a^{\\mathrm{(true)}}| / a^{\\mathrm{(true)}}$\n3.  **Normalized RMSE**: $\\mathrm{NRMSE} = \\sqrt{\\langle(C^{\\mathrm{est}} - C^{\\mathrm{true}})^2\\rangle} / \\mathrm{RMS}(C^{\\mathrm{true}})$\n\nThese dimensionless metrics quantify the accuracy of parameter recovery and the predictive skill of the identified model, respectively. The entire pipeline is executed for each specified noise level $\\eta$.",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Main function to run the twin experiment for PIML parameter estimation.\n    \"\"\"\n    # 1. Define computational domain, constants, and parameters\n    L = 1000.0  # Domain length [m]\n    u = 0.1     # Advection velocity [m/s]\n    Nx = 64     # Number of spatial points\n    dt = 0.5    # Time step [s]\n    Nt = 400    # Number of time steps\n    A1 = 1.0    # Initial condition amplitude [kg/m^3]\n    \n    k0_true = 1.0e-5  # True background diffusivity [m^2/s]\n    a_true = 5.0e-6   # True gradient-dependent diffusivity parameter [m^2/s]\n    \n    k0_init = 5.0e-6  # Initial guess for k0 [m^2/s]\n    a_init = 7.5e-6   # Initial guess for a [m^2/s]\n    \n    test_cases_eta = [0.00, 0.02, 0.08] # Noise levels\n    \n    SEED = 42 # Random seed for reproducibility\n\n    # Discretization parameters\n    dx = L / Nx\n    x = np.linspace(0, L, Nx, endpoint=False)\n    \n    # --- Helper functions for numerical derivatives ---\n    def ddx(f):\n        \"\"\"Computes 1st spatial derivative using centered differences.\"\"\"\n        f_plus_1 = np.roll(f, -1, axis=-1)\n        f_minus_1 = np.roll(f, 1, axis=-1)\n        return (f_plus_1 - f_minus_1) / (2 * dx)\n\n    def d2dx2(f):\n        \"\"\"Computes 2nd spatial derivative using centered differences.\"\"\"\n        f_plus_1 = np.roll(f, -1, axis=-1)\n        f_minus_1 = np.roll(f, 1, axis=-1)\n        return (f_plus_1 - 2 * f + f_minus_1) / (dx**2)\n\n    # --- Forward model simulation ---\n    def run_forward_model(C0, k0, a, G0, time_steps):\n        \"\"\"Integrates the advection-diffusion equation forward in time.\"\"\"\n        C_history = [C0.copy()]\n        C = C0.copy()\n        for _ in range(time_steps):\n            Cx = ddx(C)\n            K = k0 + a * np.abs(Cx) / G0\n            \n            advection_term = -u * ddx(C)\n            diffusion_flux = K * Cx\n            diffusion_term = ddx(diffusion_flux)\n            \n            C = C + dt * (advection_term + diffusion_term)\n            C_history.append(C.copy())\n        return np.array(C_history)\n\n    # --- Step 1: Initial condition and G0 calculation ---\n    C0 = A1 * np.sin(2 * np.pi * x / L) + (A1 / 2) * np.sin(4 * np.pi * x / L)\n    Cx0 = ddx(C0)\n    G0 = np.sqrt(np.mean(Cx0**2))\n\n    # --- Step 2: Generate synthetic truth ---\n    C_true = run_forward_model(C0, k0_true, a_true, G0, Nt)\n\n    # --- Step 3: Generate noisy observations for each test case ---\n    rms_C_true = np.sqrt(np.mean(C_true**2))\n    rng = np.random.default_rng(SEED)\n\n    results = []\n\n    for eta in test_cases_eta:\n        noise = rng.normal(0, eta * rms_C_true, size=C_true.shape)\n        C_obs = C_true + noise\n\n        # --- Step 4: Estimate parameters using PIML ---\n        # The cost function is evaluated on interior time steps (1 to Nt-1)\n        # to allow for centered time derivatives.\n        C_obs_interior = C_obs[1:-1, :]  # Shape: (Nt-1, Nx)\n        \n        # Temporal derivative\n        dCdt_obs = (C_obs[2:, :] - C_obs[:-2, :]) / (2 * dt)\n        \n        # Spatial derivatives on the interior time grid\n        dCdx_obs = ddx(C_obs_interior)\n        \n        # Formulate the linear regression problem: y = k0*X1 + a*X2\n        # y = dC/dt + u*dC/dx\n        y_target = (dCdt_obs + u * dCdx_obs).flatten()\n        \n        # X1 = d^2C/dx^2\n        X1_feature = d2dx2(C_obs_interior).flatten()\n        \n        # X2 = (1/G0) * d/dx(|dC/dx|*dC/dx)\n        flux_term_for_X2 = np.abs(dCdx_obs) * dCdx_obs\n        X2_feature = (1 / G0) * ddx(flux_term_for_X2).flatten()\n        \n        # Define the cost function for optimization (mean squared residual)\n        def cost_function(params):\n            k0, a = params\n            residual = y_target - (k0 * X1_feature + a * X2_feature)\n            return np.mean(residual**2)\n\n        # Perform constrained optimization\n        opt_result = minimize(\n            cost_function,\n            x0=[k0_init, a_init],\n            bounds=[(0, None), (0, None)],\n            method='L-BFGS-B'\n        )\n        k0_hat, a_hat = opt_result.x\n        \n        # --- Step 5: Re-simulate with estimated parameters and compute metrics ---\n        C_est = run_forward_model(C0, k0_hat, a_hat, G0, Nt)\n        \n        e_k0 = np.abs(k0_hat - k0_true) / k0_true\n        if a_true == 0:\n            e_a = np.abs(a_hat - a_true) if a_hat==0 else np.inf\n        else:\n            e_a = np.abs(a_hat - a_true) / a_true\n        \n        mse = np.mean((C_est - C_true)**2)\n        nrmse = np.sqrt(mse) / rms_C_true\n        \n        results.append([e_k0, e_a, nrmse])\n\n    # Format the final output string as specified\n    sublist_strs = [f\"[{item[0]},{item[1]},{item[2]}]\" for item in results]\n    final_output = f\"[{','.join(sublist_strs)}]\"\n    \n    print(final_output)\n\nsolve()\n```"
        }
    ]
}