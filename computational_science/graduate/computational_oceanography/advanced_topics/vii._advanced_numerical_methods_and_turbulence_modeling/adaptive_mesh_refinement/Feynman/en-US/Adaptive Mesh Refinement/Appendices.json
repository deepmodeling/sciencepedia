{
    "hands_on_practices": [
        {
            "introduction": "The principle of conservation is the bedrock of computational physics, stating that quantities like mass or energy cannot be arbitrarily created or destroyed. In Adaptive Mesh Refinement, maintaining this principle across interfaces between coarse and fine grids presents a unique challenge. This exercise will guide you through the cornerstone of conservative AMR: the flux correction algorithm. By quantifying and correcting the mismatch between fluxes calculated on different grid levels, you will gain a practical understanding of how AMR ensures global conservation, a non-negotiable property for physically meaningful simulations. ",
            "id": "3785227",
            "problem": "Consider a two-dimensional finite-volume discretization of a passive scalar tracer in a coastal ocean model using Adaptive Mesh Refinement (AMR), where a coarse grid cell of width $\\Delta x_{\\mathrm{c}}$ abuts a refined patch on its eastern face. The tracer mass in the coarse cell, denoted by $M$, obeys conservation under advective fluxes across cell faces: the time rate of change of $M$ equals the net outward mass flux rate integrated over time. In AMR with refinement ratio $r=2$, the fine level advances with two substeps over one coarse time step, and the coarse east face is covered by two fine faces of equal length. Assume that the vertical is already integrated and the flux rates provided are total mass flux rates integrated over the face length and depth.\n\nLet the coarse time step be $\\Delta t_{\\mathrm{c}} = 60$ seconds and the fine time step be $\\Delta t_{\\mathrm{f}} = \\Delta t_{\\mathrm{c}}/r = 30$ seconds. Assume that positive flux is oriented outward from the coarse cell into the fine patch across the shared east interface. Over the single coarse time step, the coarse-level discretization produced a constant east-face mass flux rate $F_{\\mathrm{c}} = 1.00 \\times 10^{6}$ kilograms per second. On the fine level, the two fine faces that cover the coarse east face have the following mass flux rates during the two fine substeps:\n- For substep $m=1$, the fine flux rates are $F_{\\mathrm{f},1}^{(1)} = 5.8 \\times 10^{5}$ kilograms per second and $F_{\\mathrm{f},2}^{(1)} = 6.0 \\times 10^{5}$ kilograms per second.\n- For substep $m=2$, the fine flux rates are $F_{\\mathrm{f},1}^{(2)} = 6.2 \\times 10^{5}$ kilograms per second and $F_{\\mathrm{f},2}^{(2)} = 5.9 \\times 10^{5}$ kilograms per second.\n\nAssume that there is no flux across the coarse cell’s western face during this coarse step. The coarse cell’s initial tracer mass is $M^{n} = 2.00 \\times 10^{8}$ kilograms.\n\nStarting from the finite-volume conservation principle and the definition of flux integrals over time and faces, derive the coarse-fine flux mismatch accumulated over the single coarse time step and explain how it is applied as a correction to the coarse cell to enforce conservation across the coarse-fine interface. Compute the corrected coarse-cell tracer mass at the end of the coarse time step. Round your final answer to four significant figures and express it in kilograms.",
            "solution": "The problem is valid as it describes a standard, well-posed scenario in computational fluid dynamics, specifically the flux-correction step in Adaptive Mesh Refinement (AMR) to ensure mass conservation across a coarse-fine grid interface. All necessary data are provided, and the requested calculation is based on fundamental principles of finite-volume methods.\n\nThe core principle governing the evolution of the tracer mass $M$ in the coarse finite-volume cell is the conservation law, which states that the change in mass over a time interval is equal to the negative of the total mass that has fluxed out of the cell's boundaries. In discretized form, for a single coarse time step $\\Delta t_{\\mathrm{c}}$, the mass at time $n+1$, denoted $M^{n+1}$, is related to the mass at time $n$, $M^n$, by:\n$$\nM^{n+1} = M^n - \\Delta M_{\\text{flux}}\n$$\nwhere $\\Delta M_{\\text{flux}}$ is the total net mass that exited the cell during the time step $\\Delta t_{\\mathrm{c}}$. The problem specifies no flux on the western face, so we only need to consider the flux across the eastern face.\n\nIn an AMR context, there are two different calculations for the total mass flux across the coarse-fine interface over the time interval from $t^n$ to $t^{n+1} = t^n + \\Delta t_{\\mathrm{c}}$.\n\nFirst, the coarse grid computes a total mass outflow, $\\Delta M_{\\mathrm{c}}$, based on its own flux estimate. The coarse-level flux rate, $F_{\\mathrm{c}}$, is given as constant over the coarse time step $\\Delta t_{\\mathrm{c}}$.\n$$\n\\Delta M_{\\mathrm{c}} = F_{\\mathrm{c}} \\cdot \\Delta t_{\\mathrm{c}}\n$$\nUsing the provided values:\n$$\n\\Delta M_{\\mathrm{c}} = (1.00 \\times 10^{6} \\, \\text{kg/s}) \\cdot (60 \\, \\text{s}) = 6.00 \\times 10^{7} \\, \\text{kg}\n$$\n\nSecond, the fine grid provides a more accurate calculation of the mass outflow, $\\Delta M_{\\mathrm{f}}$, by resolving the interface with higher spatial and temporal fidelity. The single coarse-face flux is resolved by two fine-face fluxes, and the single coarse time step is resolved by $r=2$ fine substeps of duration $\\Delta t_{\\mathrm{f}} = \\Delta t_{\\mathrm{c}} / r$. The total mass outflow as computed on the fine level is the sum of fluxes over all fine faces and all fine substeps.\n\nFor the first fine substep ($m=1$, time interval $\\Delta t_{\\mathrm{f}}$), the total mass outflow is:\n$$\n\\Delta M_{\\mathrm{f}}^{(1)} = \\left( F_{\\mathrm{f},1}^{(1)} + F_{\\mathrm{f},2}^{(1)} \\right) \\cdot \\Delta t_{\\mathrm{f}}\n$$\nFor the second fine substep ($m=2$, time interval $\\Delta t_{\\mathrm{f}}$), the total mass outflow is:\n$$\n\\Delta M_{\\mathrm{f}}^{(2)} = \\left( F_{\\mathrm{f},1}^{(2)} + F_{\\mathrm{f},2}^{(2)} \\right) \\cdot \\Delta t_{\\mathrm{f}}\n$$\nThe total mass outflow across the interface over the full coarse time step $\\Delta t_{\\mathrm{c}}$, according to the fine grid, is the sum of these:\n$$\n\\Delta M_{\\mathrm{f}} = \\Delta M_{\\mathrm{f}}^{(1)} + \\Delta M_{\\mathrm{f}}^{(2)} = \\left[ \\left( F_{\\mathrm{f},1}^{(1)} + F_{\\mathrm{f},2}^{(1)} \\right) + \\left( F_{\\mathrm{f},1}^{(2)} + F_{\\mathrm{f},2}^{(2)} \\right) \\right] \\cdot \\Delta t_{\\mathrm{f}}\n$$\nSubstituting the given values:\n$F_{\\mathrm{f},1}^{(1)} = 5.8 \\times 10^{5}$ kg/s, $F_{\\mathrm{f},2}^{(1)} = 6.0 \\times 10^{5}$ kg/s\n$F_{\\mathrm{f},1}^{(2)} = 6.2 \\times 10^{5}$ kg/s, $F_{\\mathrm{f},2}^{(2)} = 5.9 \\times 10^{5}$ kg/s\n$\\Delta t_{\\mathrm{f}} = 30$ s\n\n$$\n\\Delta M_{\\mathrm{f}} = \\left[ (5.8 \\times 10^{5} + 6.0 \\times 10^{5}) + (6.2 \\times 10^{5} + 5.9 \\times 10^{5}) \\right] \\frac{\\text{kg}}{\\text{s}} \\cdot (30 \\, \\text{s})\n$$\n$$\n\\Delta M_{\\mathrm{f}} = \\left[ (1.18 \\times 10^{6}) + (1.21 \\times 10^{6}) \\right] \\frac{\\text{kg}}{\\text{s}} \\cdot (30 \\, \\text{s})\n$$\n$$\n\\Delta M_{\\mathrm{f}} = (2.39 \\times 10^{6} \\, \\text{kg/s}) \\cdot (30 \\, \\text{s}) = 7.17 \\times 10^{7} \\, \\text{kg}\n$$\n\nThe coarse-fine flux mismatch, which we denote as $\\delta M_{\\text{flux}}$, is the difference between the total mass transfer computed by the fine grid and that computed by the coarse grid.\n$$\n\\delta M_{\\text{flux}} = \\Delta M_{\\mathrm{f}} - \\Delta M_{\\mathrm{c}}\n$$\n$$\n\\delta M_{\\text{flux}} = 7.17 \\times 10^{7} \\, \\text{kg} - 6.00 \\times 10^{7} \\, \\text{kg} = 1.17 \\times 10^{7} \\, \\text{kg}\n$$\nThis mismatch represents the error in the coarse grid's flux calculation. A positive value means that the more accurate fine grid calculated a greater mass outflow from the coarse cell than the coarse grid itself did.\n\nTo enforce global conservation, this mismatch must be corrected. The coarse cell's mass, which was updated using the less accurate flux $\\Delta M_{\\mathrm{c}}$ during the coarse time step, must be adjusted. The correction is applied by subtracting the flux mismatch from the coarse cell's mass. The change to the coarse cell's mass is $-\\delta M_{\\text{flux}}$.\nThe logic is as follows: A provisional update of the coarse cell mass is $M^{n+1, \\text{uncorrected}} = M^{n} - \\Delta M_{\\mathrm{c}}$. The correction is then applied to this value:\n$$\nM^{n+1, \\text{corrected}} = M^{n+1, \\text{uncorrected}} - \\delta M_{\\text{flux}} = (M^{n} - \\Delta M_{\\mathrm{c}}) - (\\Delta M_{\\mathrm{f}} - \\Delta M_{\\mathrm{c}})\n$$\nThis simplifies to:\n$$\nM^{n+1, \\text{corrected}} = M^{n} - \\Delta M_{\\mathrm{f}}\n$$\nThis result demonstrates that the flux-correction procedure ensures that the coarse cell's mass budget is consistent with the more accurate flux calculated on the fine grid, thereby maintaining conservation.\n\nWe can now compute the corrected final mass of the coarse cell using the initial mass $M^n$ and the total flux from the fine grid $\\Delta M_{\\mathrm{f}}$.\nGiven $M^n = 2.00 \\times 10^{8}$ kg:\n$$\nM^{n+1, \\text{corrected}} = 2.00 \\times 10^{8} \\, \\text{kg} - 7.17 \\times 10^{7} \\, \\text{kg}\n$$\n$$\nM^{n+1, \\text{corrected}} = 2.00 \\times 10^{8} \\, \\text{kg} - 0.717 \\times 10^{8} \\, \\text{kg}\n$$\n$$\nM^{n+1, \\text{corrected}} = (2.00 - 0.717) \\times 10^{8} \\, \\text{kg} = 1.283 \\times 10^{8} \\, \\text{kg}\n$$\nThis value is already expressed to four significant figures as requested.",
            "answer": "$$\\boxed{1.283 \\times 10^{8}}$$"
        },
        {
            "introduction": "When the AMR algorithm decides to refine a region, it must populate the newly created fine cells with data interpolated from the parent coarse cell. A naive interpolation can degrade the simulation's accuracy or, worse, violate conservation. This practice delves into the design of a high-quality \"prolongation\" operator. You will derive a second-order accurate, conservative stencil that demonstrates how to properly initialize a refined patch, ensuring that the new grid is not only a more detailed view but also a consistent representation of the underlying physical state. ",
            "id": "4009052",
            "problem": "Adaptive Mesh Refinement (AMR) in Numerical Weather Prediction (NWP) and climate modeling requires prolongation operators that are both conservative and at least second-order accurate to prevent spurious creation or loss of scalar quantities such as tracer mass. Consider a finite-volume coarse cell centered at the origin, with uniform spacings $\\Delta x_c$ and $\\Delta y_c$ in the $x$- and $y$-directions, respectively. Let a dimensionless conserved scalar field be represented on the coarse level by the coarse cell average $\\bar{q}_c$. Assume a bilinear reconstruction within the coarse cell of the form\n$$\np(x,y) \\equiv \\bar{q}_c + S_x\\,x + S_y\\,y + S_{xy}\\,x\\,y,\n$$\nwhere $S_x$, $S_y$, and $S_{xy}$ are second-order accurate, coarse-level estimates of the local first derivatives and the mixed term coefficient, and $(x,y)$ are local coordinates measured from the coarse cell center with $x \\in [-\\Delta x_c/2,\\,\\Delta x_c/2]$ and $y \\in [-\\Delta y_c/2,\\,\\Delta y_c/2]$. The fine level is a factor-of-$2$ refinement in each spatial direction, producing four fine subcells by splitting at $x=0$ and $y=0$: the northeast (NE) subcell with $x \\in [0,\\,\\Delta x_c/2]$, $y \\in [0,\\,\\Delta y_c/2]$; the northwest (NW) subcell with $x \\in [-\\Delta x_c/2,\\,0]$, $y \\in [0,\\,\\Delta y_c/2]$; the southwest (SW) subcell with $x \\in [-\\Delta x_c/2,\\,0]$, $y \\in [-\\Delta y_c/2,\\,0]$; and the southeast (SE) subcell with $x \\in [0,\\,\\Delta x_c/2]$, $y \\in [-\\Delta y_c/2,\\,0]$.\n\nUsing only the finite-volume definition of a cell average and conservation principles, derive the second-order conservative prolongation stencil that maps the coarse cell average and bilinear coefficients to the four fine cell averages, defined as\n$$\n\\bar{q}_{R} \\equiv \\frac{1}{A_R} \\int_{R} p(x,y)\\, \\mathrm{d}A,\n$$\nfor each region $R \\in \\{\\mathrm{NE},\\mathrm{NW},\\mathrm{SW},\\mathrm{SE}\\}$ with area $A_R = (\\Delta x_c/2)(\\Delta y_c/2)$, and $\\mathrm{d}A = \\mathrm{d}x\\,\\mathrm{d}y$. Your final answers must be explicit analytic expressions for $\\bar{q}_{\\mathrm{NE}}$, $\\bar{q}_{\\mathrm{NW}}$, $\\bar{q}_{\\mathrm{SW}}$, and $\\bar{q}_{\\mathrm{SE}}$ in terms of $\\bar{q}_c$, $\\Delta x_c$, $\\Delta y_c$, $S_x$, $S_y$, and $S_{xy}$. Present your final answer as a single row matrix in the order $(\\bar{q}_{\\mathrm{NE}}, \\bar{q}_{\\mathrm{NW}}, \\bar{q}_{\\mathrm{SW}}, \\bar{q}_{\\mathrm{SE}})$. Express your answer exactly; no rounding or units are required.",
            "solution": "The problem statement has been validated and is deemed scientifically grounded, self-contained, consistent, and well-posed. The task is to derive the second-order conservative prolongation stencil for a finite-volume method, which maps a coarse-cell average and its reconstructed distribution to four fine-cell averages.\n\nThe fundamental principle to be used is the definition of a cell average for a conserved scalar field $q$. For any region $R$ with area $A_R$, the cell average $\\bar{q}_R$ is defined as the integral of the scalar field over the region, divided by the area of the region:\n$$\n\\bar{q}_{R} \\equiv \\frac{1}{A_R} \\int_{R} q(x,y)\\, \\mathrm{d}A\n$$\nIn this problem, the scalar field distribution within the coarse cell is given by a bilinear reconstruction polynomial $p(x,y)$:\n$$\np(x,y) = \\bar{q}_c + S_x\\,x + S_y\\,y + S_{xy}\\,x\\,y\n$$\nThe coarse cell is centered at the origin, with domain $x \\in [-\\Delta x_c/2, \\Delta x_c/2]$ and $y \\in [-\\Delta y_c/2, \\Delta y_c/2]$. The fine grid is a factor-of-$2$ refinement, resulting in four subcells (NE, NW, SW, SE) each with area $A_R = (\\Delta x_c/2)(\\Delta y_c/2) = \\frac{\\Delta x_c \\Delta y_c}{4}$.\n\nOur objective is to compute the average of $p(x,y)$ over each of these four subcells. Let's denote a generic subcell region as $R$. The average is:\n$$\n\\bar{q}_{R} = \\frac{1}{A_R} \\int_{R} (\\bar{q}_c + S_x\\,x + S_y\\,y + S_{xy}\\,x\\,y)\\, \\mathrm{d}x\\,\\mathrm{d}y\n$$\nBy linearity of integration, we can separate the terms:\n$$\n\\bar{q}_{R} = \\frac{1}{A_R} \\left( \\bar{q}_c \\int_{R} 1\\, \\mathrm{d}x\\,\\mathrm{d}y + S_x \\int_{R} x\\, \\mathrm{d}x\\,\\mathrm{d}y + S_y \\int_{R} y\\, \\mathrm{d}x\\,\\mathrm{d}y + S_{xy} \\int_{R} xy\\, \\mathrm{d}x\\,\\mathrm{d}y \\right)\n$$\nThe first integral $\\int_{R} 1\\, \\mathrm{d}x\\,\\mathrm{d}y$ is simply the area of the region, $A_R$. This simplifies the expression to:\n$$\n\\bar{q}_{R} = \\bar{q}_c + \\frac{S_x}{A_R} \\int_{R} x\\, \\mathrm{d}x\\,\\mathrm{d}y + \\frac{S_y}{A_R} \\int_{R} y\\, \\mathrm{d}x\\,\\mathrm{d}y + \\frac{S_{xy}}{A_R} \\int_{R} xy\\, \\mathrm{d}x\\,\\mathrm{d}y\n$$\nThe remaining integrals can be evaluated for a general rectangular region $[x_1, x_2] \\times [y_1, y_2]$ with area $A_R = (x_2 - x_1)(y_2 - y_1)$. The centroid of this rectangle is $(\\bar{x}_R, \\bar{y}_R) = (\\frac{x_1+x_2}{2}, \\frac{y_1+y_2}{2})$.\nThe integrals are:\n$$\n\\int_{R} x\\, \\mathrm{d}A = \\int_{y_1}^{y_2} \\int_{x_1}^{x_2} x\\, \\mathrm{d}x\\,\\mathrm{d}y = \\left[\\frac{x^2}{2}\\right]_{x_1}^{x_2} \\left[y\\right]_{y_1}^{y_2} = \\frac{x_2^2-x_1^2}{2}(y_2-y_1) = \\frac{(x_2-x_1)(x_2+x_1)}{2}(y_2-y_1) = A_R \\bar{x}_R\n$$\n$$\n\\int_{R} y\\, \\mathrm{d}A = \\int_{y_1}^{y_2} \\int_{x_1}^{x_2} y\\, \\mathrm{d}x\\,\\mathrm{d}y = (x_2-x_1)\\frac{y_2^2-y_1^2}{2} = A_R \\bar{y}_R\n$$\n$$\n\\int_{R} xy\\, \\mathrm{d}A = \\int_{y_1}^{y_2} \\int_{x_1}^{x_2} xy\\, \\mathrm{d}x\\,\\mathrm{d}y = \\left[\\frac{x^2}{2}\\right]_{x_1}^{x_2} \\left[\\frac{y^2}{2}\\right]_{y_1}^{y_2} = \\frac{x_2^2-x_1^2}{2} \\frac{y_2^2-y_1^2}{2} = (A_R \\bar{x}_R) \\bar{y}_R = A_R \\bar{x}_R \\bar{y}_R\n$$\nSubstituting these results back into the expression for $\\bar{q}_R$, we obtain a general formula for the average of the bilinear polynomial over any rectangular sub-region $R$:\n$$\n\\bar{q}_R = \\bar{q}_c + S_x \\bar{x}_R + S_y \\bar{y}_R + S_{xy} \\bar{x}_R \\bar{y}_R\n$$\nThis elegant result shows that the fine-cell average is determined by evaluating the contributions from the derivative terms at the centroid of the fine cell. Now we apply this formula to each of the four subcells by finding their centroids.\n\n1.  **Northeast (NE) subcell**: $x \\in [0, \\Delta x_c/2]$, $y \\in [0, \\Delta y_c/2]$.\n    The centroid is $(\\bar{x}_{\\mathrm{NE}}, \\bar{y}_{\\mathrm{NE}}) = (\\frac{0+\\Delta x_c/2}{2}, \\frac{0+\\Delta y_c/2}{2}) = (\\frac{\\Delta x_c}{4}, \\frac{\\Delta y_c}{4})$.\n    $$\n    \\bar{q}_{\\mathrm{NE}} = \\bar{q}_c + S_x \\left(\\frac{\\Delta x_c}{4}\\right) + S_y \\left(\\frac{\\Delta y_c}{4}\\right) + S_{xy} \\left(\\frac{\\Delta x_c}{4}\\right)\\left(\\frac{\\Delta y_c}{4}\\right) = \\bar{q}_c + \\frac{S_x \\Delta x_c}{4} + \\frac{S_y \\Delta y_c}{4} + \\frac{S_{xy} \\Delta x_c \\Delta y_c}{16}\n    $$\n\n2.  **Northwest (NW) subcell**: $x \\in [-\\Delta x_c/2, 0]$, $y \\in [0, \\Delta y_c/2]$.\n    The centroid is $(\\bar{x}_{\\mathrm{NW}}, \\bar{y}_{\\mathrm{NW}}) = (\\frac{-\\Delta x_c/2+0}{2}, \\frac{0+\\Delta y_c/2}{2}) = (-\\frac{\\Delta x_c}{4}, \\frac{\\Delta y_c}{4})$.\n    $$\n    \\bar{q}_{\\mathrm{NW}} = \\bar{q}_c + S_x \\left(-\\frac{\\Delta x_c}{4}\\right) + S_y \\left(\\frac{\\Delta y_c}{4}\\right) + S_{xy} \\left(-\\frac{\\Delta x_c}{4}\\right)\\left(\\frac{\\Delta y_c}{4}\\right) = \\bar{q}_c - \\frac{S_x \\Delta x_c}{4} + \\frac{S_y \\Delta y_c}{4} - \\frac{S_{xy} \\Delta x_c \\Delta y_c}{16}\n    $$\n\n3.  **Southwest (SW) subcell**: $x \\in [-\\Delta x_c/2, 0]$, $y \\in [-\\Delta y_c/2, 0]$.\n    The centroid is $(\\bar{x}_{\\mathrm{SW}}, \\bar{y}_{\\mathrm{SW}}) = (\\frac{-\\Delta x_c/2+0}{2}, \\frac{-\\Delta y_c/2+0}{2}) = (-\\frac{\\Delta x_c}{4}, -\\frac{\\Delta y_c}{4})$.\n    $$\n    \\bar{q}_{\\mathrm{SW}} = \\bar{q}_c + S_x \\left(-\\frac{\\Delta x_c}{4}\\right) + S_y \\left(-\\frac{\\Delta y_c}{4}\\right) + S_{xy} \\left(-\\frac{\\Delta x_c}{4}\\right)\\left(-\\frac{\\Delta y_c}{4}\\right) = \\bar{q}_c - \\frac{S_x \\Delta x_c}{4} - \\frac{S_y \\Delta y_c}{4} + \\frac{S_{xy} \\Delta x_c \\Delta y_c}{16}\n    $$\n\n4.  **Southeast (SE) subcell**: $x \\in [0, \\Delta x_c/2]$, $y \\in [-\\Delta y_c/2, 0]$.\n    The centroid is $(\\bar{x}_{\\mathrm{SE}}, \\bar{y}_{\\mathrm{SE}}) = (\\frac{0+\\Delta x_c/2}{2}, \\frac{-\\Delta y_c/2+0}{2}) = (\\frac{\\Delta x_c}{4}, -\\frac{\\Delta y_c}{4})$.\n    $$\n    \\bar{q}_{\\mathrm{SE}} = \\bar{q}_c + S_x \\left(\\frac{\\Delta x_c}{4}\\right) + S_y \\left(-\\frac{\\Delta y_c}{4}\\right) + S_{xy} \\left(\\frac{\\Delta x_c}{4}\\right)\\left(-\\frac{\\Delta y_c}{4}\\right) = \\bar{q}_c + \\frac{S_x \\Delta x_c}{4} - \\frac{S_y \\Delta y_c}{4} - \\frac{S_{xy} \\Delta x_c \\Delta y_c}{16}\n    $$\n\nTo verify the conservation property of this prolongation stencil, we check if the average of the fine-cell averages equals the coarse-cell average.\n$$\n\\frac{1}{4}(\\bar{q}_{\\mathrm{NE}} + \\bar{q}_{\\mathrm{NW}} + \\bar{q}_{\\mathrm{SW}} + \\bar{q}_{\\mathrm{SE}}) = \\frac{1}{4} \\left( 4\\bar{q}_c \\right)\n+ \\frac{1}{4}\\frac{S_x \\Delta x_c}{4}(1 - 1 - 1 + 1)\n+ \\frac{1}{4}\\frac{S_y \\Delta y_c}{4}(1 + 1 - 1 - 1)\n+ \\frac{1}{4}\\frac{S_{xy} \\Delta x_c \\Delta y_c}{16}(1 - 1 + 1 - 1)\n$$\n$$\n= \\bar{q}_c + 0 + 0 + 0 = \\bar{q}_c\n$$\nSince the sum of the fine-cell values (weighted by area) equals the coarse-cell value, the procedure is conservative. The derived expressions constitute the desired prolongation stencil.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\bar{q}_c + \\frac{S_x \\Delta x_c}{4} + \\frac{S_y \\Delta y_c}{4} + \\frac{S_{xy} \\Delta x_c \\Delta y_c}{16} & \\bar{q}_c - \\frac{S_x \\Delta x_c}{4} + \\frac{S_y \\Delta y_c}{4} - \\frac{S_{xy} \\Delta x_c \\Delta y_c}{16} & \\bar{q}_c - \\frac{S_x \\Delta x_c}{4} - \\frac{S_y \\Delta y_c}{4} + \\frac{S_{xy} \\Delta x_c \\Delta y_c}{16} & \\bar{q}_c + \\frac{S_x \\Delta x_c}{4} - \\frac{S_y \\Delta y_c}{4} - \\frac{S_{xy} \\Delta x_c \\Delta y_c}{16}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "An effective AMR strategy relies on a robust logic for deciding where and when to refine or derefine the mesh. However, in the presence of noise or features that hover near the decision threshold, a simple criterion can lead to \"thrashing\"—a computationally wasteful cycle of rapid refinement and derefinement. This hands-on exercise introduces a powerful stabilization technique using hysteresis. By implementing and testing a refinement strategy with separate thresholds and a temporal hold, you will learn how to build a more efficient and stable AMR controller that is resilient to fluctuations. ",
            "id": "3094967",
            "problem": "You are tasked with designing and implementing a hysteresis-based adaptive mesh refinement decision scheme to avoid repeated refine/derefine toggling when a moving shock passes across cell boundaries in a one-dimensional simulation reminiscent of the Sod shock tube. The computational objective is purely algorithmic: do not solve the governing partial differential equations. Instead, derive, implement, and compare decision logic based on an error indicator derived from a continuous surrogate density profile with a moving discontinuity-like feature.\n\nFundamental base and core definitions: Adaptive mesh refinement (AMR) refines the computational mesh where an error indicator is high and derefines where it is low. A moving shock in the Sod tube creates a large gradient in the density field. Let the domain be the interval $[0,1]$. Let there be $N_{\\text{cells}}$ uniform coarse cells with cell width $\\Delta x = \\frac{1}{N_{\\text{cells}}}$ and centers $x_i = \\left(i + \\frac{1}{2}\\right)\\Delta x$ for integer $i \\in \\{0,1,\\dots,N_{\\text{cells}}-1\\}$. Define a smooth surrogate density field with a moving jump:\n$$\n\\rho(x,t) = \\rho_R + \\left(\\rho_L - \\rho_R\\right) S(x,t), \\quad S(x,t) = \\frac{1}{2}\\left(1 - \\tanh\\left(\\frac{x - x_s(t)}{w}\\right)\\right),\n$$\nwhere $x_s(t) = x_0 + v t$ is the shock location, $w > 0$ is the smoothing width, $\\rho_L$ is the left density state, and $\\rho_R$ is the right density state. This surrogate captures a moving steep gradient as in the Sod tube context but remains continuous to permit stable finite differences. The cellwise error indicator is defined from the discrete spatial gradient of $\\rho$:\n$$\nI_i(t) = \\frac{\\left|\\rho(x_{i+1}, t) - \\rho(x_i, t)\\right|}{\\Delta x},\n$$\nwith $I_{N_{\\text{cells}}-1}(t)$ set equal to $I_{N_{\\text{cells}}-2}(t)$ to avoid boundary indexing. To emulate sensor uncertainty and model discretization noise, a zero-mean additive Gaussian noise term with standard deviation $\\sigma$ may be added to $I_i(t)$; negative indicators after noise must be clipped to $0$.\n\nDecision schemes to implement and compare:\n- Naive scheme (single threshold): Given a threshold $T$, define the refine flag $R_i(t)$ by $R_i(t) = \\text{true}$ if $I_i(t) \\ge T$ and $R_i(t) = \\text{false}$ otherwise.\n- Hysteresis scheme (two thresholds plus hold time): Given a refine threshold `T_r`, a derefine threshold `T_d` with $T_d  T_r$, and a hold time $H$ in integer time steps, implement $R_i(t)$ as follows. If $R_i(t-1) = \\text{false}$, then refine only if $I_i(t)  T_r$; if refinement occurs at time $t$, set a hold counter $h_i(t) = H$. If $R_i(t-1) = \\text{true}$, then continue to hold refinement while $h_i(t-1)  0$ by setting $R_i(t) = \\text{true}$ and $h_i(t) = h_i(t-1) - 1$ regardless of $I_i(t)$. After the hold counter reaches $0$, derefine only if $I_i(t)  T_d$; otherwise keep $R_i(t) = \\text{true}$. If $I_i(t)$ satisfies neither strict inequality (equalities), keep the current state. This creates a deadband and a temporal persistence to avoid thrashing.\n\nPerformance metric and thrashing definition: Define the total number of state toggles over a simulation as\n$$\nN_{\\text{toggles}} = \\sum_{t=1}^{N_{\\text{steps}}-1} \\sum_{i=0}^{N_{\\text{cells}}-1} \\mathbf{1}\\left[R_i(t) \\ne R_i(t-1)\\right],\n$$\nwhere $N_{\\text{steps}}$ is the number of discrete time steps and $\\mathbf{1}[\\cdot]$ is the indicator function that equals $1$ for true and $0$ for false. Compute $N_{\\text{toggles}}^{\\text{naive}}$ for the naive scheme and $N_{\\text{toggles}}^{\\text{hyst}}$ for the hysteresis scheme, then report the difference $D = N_{\\text{toggles}}^{\\text{naive}} - N_{\\text{toggles}}^{\\text{hyst}}$ for each test case.\n\nStarting point from fundamental principles: The scheme must be derived from the definitions of conservation-law-driven refinement (large gradients imply regions of interest), the definition of a discrete gradient as a well-tested numerical approximation, and the concept of hysteresis as a double-threshold deadband with temporal persistence to suppress rapid switching caused by small fluctuations.\n\nAlgorithmic requirements:\n1. Use the surrogate density with parameters specified in each test case.\n2. At each time $t_k = k\\,\\Delta t$ for integer $k \\in \\{0,1,\\dots,N_{\\text{steps}}-1\\}$, compute $\\rho(x_i, t_k)$ and the indicators $I_i(t_k)$, then apply the decision logic for both schemes independently.\n3. Count the toggles for each scheme over the full simulation and return the difference $D$ for each test case.\n\nAngle units are not applicable, and there are no physical units required in the final answer; all quantities are dimensionless by construction.\n\nTest suite and parameters:\nProvide three test cases to probe different facets:\n- Case $1$ (general moving shock with mild noise):\n  - $N_{\\text{cells}} = 64$, $N_{\\text{steps}} = 120$, $\\Delta t = 0.005$, $x_0 = 0.20$, $v = 0.25$, $w = 0.020$, $\\rho_L = 1.00$, $\\rho_R = 0.125$, $\\sigma = 0.5$, random seed $s = 42$,\n  - Naive threshold $T = 14$,\n  - Hysteresis thresholds and hold $T_r = 16$, $T_d = 12$, $H = 3$.\n- Case $2$ (boundary condition with near-equality and no noise):\n  - $N_{\\text{cells}} = 64$, $N_{\\text{steps}} = 120$, $\\Delta t = 0.005$, $x_0 = 0.25$, $v = 0.30$, $w = 0.040$, $\\rho_L = 1.00$, $\\rho_R = 0.125$, $\\sigma = 0.0$, random seed $s = 7$,\n  - Naive threshold $T = 11$,\n  - Hysteresis thresholds and hold $T_r = 12$, $T_d = 10$, $H = 2$.\n- Case $3$ (edge case with strong noise to induce oscillations):\n  - $N_{\\text{cells}} = 64$, $N_{\\text{steps}} = 120$, $\\Delta t = 0.005$, $x_0 = 0.20$, $v = 0.25$, $w = 0.020$, $\\rho_L = 1.00$, $\\rho_R = 0.125$, $\\sigma = 3.0$, random seed $s = 123$,\n  - Naive threshold $T = 14$,\n  - Hysteresis thresholds and hold $T_r = 16$, $T_d = 12$, $H = 4$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, specifically the three differences $D$ for the three cases in order:\n`print [D_1, D_2, D_3]`.",
            "solution": "The problem requires the design, implementation, and comparison of two decision schemes for adaptive mesh refinement (AMR) in the context of a one-dimensional moving shock profile. The objective is to quantify the reduction in refinement state \"toggling\" or \"thrashing\" achieved by a hysteresis-based scheme compared to a naive single-threshold scheme.\n\n### Principle-Based Design and Model Formulation\n\nThe foundation of this problem lies in the principles of numerical methods for conservation laws and control theory. In fluid dynamics simulations, features like shock waves exhibit large gradients in physical quantities (e.g., density, pressure). To accurately resolve these features without excessive computational cost across the entire domain, AMR techniques refine the mesh locally. The decision to refine or derefine is based on an error indicator, which is typically a measure of the local solution gradient.\n\n1.  **Surrogate Physical Model**: We model a moving shock-like feature using a continuous surrogate density profile $\\rho(x,t)$. This avoids the complexities of solving hyperbolic partial differential equations while preserving the essential feature of a steep, moving gradient. The function is defined as:\n    $$\n    \\rho(x,t) = \\rho_R + \\left(\\rho_L - \\rho_R\\right) S(x,t)\n    $$\n    where $\\rho_L$ and $\\rho_R$ are the densities on the left and right of the shock, respectively. The transition is governed by a smoothed step function:\n    $$\n    S(x,t) = \\frac{1}{2}\\left(1 - \\tanh\\left(\\frac{x - x_s(t)}{w}\\right)\\right)\n    $$\n    Here, $x_s(t) = x_0 + v t$ is the time-dependent position of the shock center, moving with velocity $v$, and $w$ is a parameter controlling the width or steepness of the gradient. The hyperbolic tangent function, $\\tanh$, provides a smooth but sharp transition, mimicking a shock profile resolved on a numerical grid.\n\n2.  **Error Indicator**: The core of any AMR strategy is the error indicator. A fundamental principle in numerical analysis is that the local truncation error is related to higher-order derivatives of the solution. A simple and effective proxy for this error is the magnitude of the solution's first derivative, or its discrete approximation, the gradient. We define the cell-wise error indicator $I_i(t)$ for cell $i$ at time $t$ based on a finite difference approximation of the density gradient:\n    $$\n    I_i(t) = \\frac{\\left|\\rho(x_{i+1}, t) - \\rho(x_i, t)\\right|}{\\Delta x}\n    $$\n    where $x_i$ is the center of cell $i$ and $\\Delta x$ is the uniform cell width. This indicator will be large in regions where the density changes rapidly (i.e., near the shock) and small in regions where the solution is smooth. To simulate measurement noise and discretization effects inherent in real simulations, a zero-mean Gaussian noise with standard deviation $\\sigma$ is added to $I_i(t)$.\n\n3.  **AMR Decision Schemes**:\n    -   **Naive Scheme**: The simplest approach is to refine a cell if its error indicator exceeds a single, predetermined threshold, $T$. The refinement flag $R_i(t)$ is determined by:\n        $$\n        R_i(t) = \\begin{cases} \\text{true}  \\text{if } I_i(t) \\geq T \\\\ \\text{false}  \\text{if } I_i(t)  T \\end{cases}\n        $$\n        While simple, this scheme is highly susceptible to \"thrashing\"—rapid, repeated refinement and derefinement—if the noisy indicator $I_i(t)$ fluctuates around the threshold $T$.\n\n    -   **Hysteresis Scheme**: To combat thrashing, we employ hysteresis, a concept from control engineering that introduces memory into the system. This is achieved through two mechanisms: a spatial deadband and a temporal hold.\n        -   **Spatial Hysteresis (Deadband)**: Instead of one threshold, we use two: a refine threshold $T_r$ and a derefine threshold $T_d$, with $T_d  T_r$. A cell is marked for refinement only if its indicator *strictly exceeds* $T_r$. It is marked for derefinement only if its indicator *drops below* $T_d$. For any value of the indicator $I_i(t)$ in the \"deadband\" $[T_d, T_r]$, the cell's refinement state does not change. This prevents toggling due to minor fluctuations of the indicator within this band.\n        -   **Temporal Hysteresis (Hold Time)**: A hold time $H$ (an integer number of time steps) is introduced. Once a cell is refined, it is forced to remain in the refined state for at least $H$ time steps, regardless of the indicator's value. This enforces temporal stability and prevents the system from immediately undoing a refinement decision due to a transient dip in the indicator.\n\n4.  **Algorithmic Implementation and Evaluation**:\n    The simulation proceeds through discrete time steps $t_k = k\\,\\Delta t$. At each step, the algorithm performs the following:\n    -   Computes the shock position $x_s(t_k)$ and the density values $\\rho(x_i, t_k)$ for all cell centers $x_i$.\n    -   Calculates the error indicators $I_i(t_k)$ for all cells, adds the specified noise, and clips negative values to zero.\n    -   Applies the logic for both the naive and hysteresis schemes independently to determine the refinement state $R_i(t_k)$ for each cell. For the hysteresis scheme, this involves updating the state and the hold-down counters based on the previous state, the current indicator value, and the defined thresholds ($T_r, T_d, H$).\n    -   The performance of each scheme is measured by the total number of state toggles, $N_{\\text{toggles}}$, over the entire simulation. A toggle is counted for a cell $i$ at time $t_k$ if $R_i(t_k) \\ne R_i(t_{k-1})$. The final metric, $D = N_{\\text{toggles}}^{\\text{naive}} - N_{\\text{toggles}}^{\\text{hyst}}$, directly quantifies the improvement offered by the hysteresis scheme. A positive value of $D$ indicates that hysteresis successfully reduced the number of state changes.\n\nThe implementation will be vectorized using NumPy for efficiency, performing calculations for all cells simultaneously at each time step.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print the results.\n    \"\"\"\n\n    test_cases = [\n        # Case 1: General moving shock with mild noise\n        {\n            \"N_cells\": 64, \"N_steps\": 120, \"dt\": 0.005, \"x0\": 0.20, \"v\": 0.25,\n            \"w\": 0.020, \"rho_L\": 1.00, \"rho_R\": 0.125, \"sigma\": 0.5,\n            \"seed\": 42, \"T\": 14, \"Tr\": 16, \"Td\": 12, \"H\": 3\n        },\n        # Case 2: Boundary condition with near-equality and no noise\n        {\n            \"N_cells\": 64, \"N_steps\": 120, \"dt\": 0.005, \"x0\": 0.25, \"v\": 0.30,\n            \"w\": 0.040, \"rho_L\": 1.00, \"rho_R\": 0.125, \"sigma\": 0.0,\n            \"seed\": 7, \"T\": 11, \"Tr\": 12, \"Td\": 10, \"H\": 2\n        },\n        # Case 3: Edge case with strong noise to induce oscillations\n        {\n            \"N_cells\": 64, \"N_steps\": 120, \"dt\": 0.005, \"x0\": 0.20, \"v\": 0.25,\n            \"w\": 0.020, \"rho_L\": 1.00, \"rho_R\": 0.125, \"sigma\": 3.0,\n            \"seed\": 123, \"T\": 14, \"Tr\": 16, \"Td\": 12, \"H\": 4\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        diff = run_simulation_case(case)\n        results.append(diff)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\n\ndef run_simulation_case(params):\n    \"\"\"\n    Runs the simulation for a single test case and returns the toggle difference D.\n    \"\"\"\n    # Unpack parameters\n    N_cells = params[\"N_cells\"]\n    N_steps = params[\"N_steps\"]\n    dt = params[\"dt\"]\n    x0 = params[\"x0\"]\n    v = params[\"v\"]\n    w = params[\"w\"]\n    rho_L = params[\"rho_L\"]\n    rho_R = params[\"rho_R\"]\n    sigma = params[\"sigma\"]\n    seed = params[\"seed\"]\n    T = params[\"T\"]\n    Tr = params[\"Tr\"]\n    Td = params[\"Td\"]\n    H = params[\"H\"]\n\n    # Setup grid and time\n    dx = 1.0 / N_cells\n    x_centers = (np.arange(N_cells) + 0.5) * dx\n    times = np.arange(N_steps) * dt\n\n    # Initialize random number generator for reproducibility\n    rng = np.random.default_rng(seed)\n\n    # State history arrays\n    R_naive_hist = np.zeros((N_steps, N_cells), dtype=bool)\n    R_hyst_hist = np.zeros((N_steps, N_cells), dtype=bool)\n    h_hyst_hist = np.zeros((N_steps, N_cells), dtype=int)\n\n    # Time-stepping loop\n    for k, t in enumerate(times):\n        # 1. Compute surrogate density and error indicator\n        x_s = x0 + v * t\n        arg = (x_centers - x_s) / w\n        S_xt = 0.5 * (1 - np.tanh(arg))\n        rho_xt = rho_R + (rho_L - rho_R) * S_xt\n        \n        # Calculate indicators I_i for i = 0 to N_cells-2\n        indicators_part = np.abs(rho_xt[1:] - rho_xt[:-1]) / dx\n        \n        # Assemble N_cells indicators, setting I_{N-1} = I_{N-2}\n        indicators = np.append(indicators_part, indicators_part[-1])\n        \n        # Add noise and clip at 0\n        noise = rng.normal(loc=0.0, scale=sigma, size=N_cells)\n        indicators_noisy = np.maximum(0, indicators + noise)\n\n        # 2. Update Naive Scheme State\n        R_naive_hist[k, :] = (indicators_noisy = T)\n\n        # 3. Update Hysteresis Scheme State\n        if k == 0:\n            R_hyst_prev = np.zeros(N_cells, dtype=bool)\n            h_hyst_prev = np.zeros(N_cells, dtype=int)\n        else:\n            R_hyst_prev = R_hyst_hist[k - 1, :]\n            h_hyst_prev = h_hyst_hist[k - 1, :]\n\n        R_hyst_curr = np.copy(R_hyst_prev)\n        h_hyst_curr = np.copy(h_hyst_prev)\n        \n        # Logic for cells that were previously NOT refined\n        was_false_mask = ~R_hyst_prev\n        to_refine_mask = was_false_mask  (indicators_noisy  Tr)\n        R_hyst_curr[to_refine_mask] = True\n        h_hyst_curr[to_refine_mask] = H\n\n        # Logic for cells that were previously refined\n        was_true_mask = R_hyst_prev\n        \n        # Decrement hold counter if it's positive\n        holding_mask = was_true_mask  (h_hyst_prev  0)\n        h_hyst_curr[holding_mask] = h_hyst_prev[holding_mask] - 1\n        \n        # Check for derefinement if hold counter is zero\n        hold_expired_mask = was_true_mask  (h_hyst_prev == 0)\n        to_derefine_mask = hold_expired_mask  (indicators_noisy  Td)\n        R_hyst_curr[to_derefine_mask] = False\n        \n        R_hyst_hist[k, :] = R_hyst_curr\n        h_hyst_hist[k, :] = h_hyst_curr\n\n    # 4. Calculate Toggles\n    # Sum over all cells and time steps from k=1 to N_steps-1\n    toggles_naive = np.sum(R_naive_hist[1:, :] != R_naive_hist[:-1, :])\n    toggles_hyst = np.sum(R_hyst_hist[1:, :] != R_hyst_hist[:-1, :])\n\n    # 5. Return difference\n    return toggles_naive - toggles_hyst\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}