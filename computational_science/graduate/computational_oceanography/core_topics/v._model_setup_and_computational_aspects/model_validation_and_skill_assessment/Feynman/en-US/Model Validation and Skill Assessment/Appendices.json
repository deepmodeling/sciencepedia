{
    "hands_on_practices": [
        {
            "introduction": "Evaluating a model's ability to predict discrete events, such as whether a significant wave height will exceed a critical threshold, requires moving beyond simple accuracy. This practice  introduces the Equitable Threat Score (ETS), a fundamental metric that quantifies skill by explicitly correcting for successful predictions that could occur purely by random chance. By working through its derivation from a contingency table, you will gain a deep understanding of how to construct and interpret skill scores, a cornerstone of rigorous model assessment.",
            "id": "3799780",
            "problem": "A numerical wave model is validated against buoy observations for significant wave height exceedances above a fixed threshold of $6 \\ \\mathrm{m}$ across $N = 5000$ independent forecast–observation collocations. Each collocation is categorized in a $2 \\times 2$ contingency table as follows: a hit ($H$) if both forecast and observation exceed the threshold, a miss ($M$) if the observation exceeds but the forecast does not, a false alarm ($F$) if the forecast exceeds but the observation does not, and a correct rejection ($C$) otherwise. For this verification experiment, the counts are $H = 150$, $M = 90$, and $F = 150$, with $C$ implied by $C = N - H - M - F$.\n\nTasks:\n1. Starting from the definitions of joint and marginal probabilities and assuming statistical independence between forecasts and observations under a no-skill (random) forecast, derive an expression for the expected number of random hits $H_{r}$ in terms of $H$, $M$, $F$, and $N$. Then use this to derive the Equitable Threat Score (ETS) that corrects the threat score for random hits.\n2. In the context of thresholded exceedance detection, define the hit rate and the false alarm rate in terms of $H$, $M$, $F$, and $C$, making clear which event base each rate conditions on.\n3. Using the counts above, compute the Equitable Threat Score (ETS). Express your final ETS as a decimal fraction and round your answer to four significant figures. Do not include a percent sign or any units in your final answer.",
            "solution": "The problem statement has been validated and is deemed to be scientifically grounded, well-posed, objective, and complete. We may proceed with a solution. The problem is addressed in three parts as requested.\n\nThe contingency table for a dichotomous (yes/no) forecast verification is defined by the following counts:\n- $H$: Hits (forecast = yes, observation = yes)\n- $M$: Misses (forecast = no, observation = yes)\n- $F$: False Alarms (forecast = yes, observation = no)\n- $C$: Correct Rejections (forecast = no, observation = no)\nThe total number of samples is $N = H + M + F + C$.\n\n**1. Derivation of Random Hits ($H_r$) and Equitable Threat Score (ETS)**\n\nLet $O$ be the event that the observation exceeds the threshold, and let $F_c$ be the event that the forecast exceeds the threshold. From the $N$ samples, we can estimate the marginal probabilities of these events occurring. The empirical probability of an observed exceedance is the total number of observed exceedances, $H+M$, divided by the total sample size $N$:\n$$P(O) = \\frac{H + M}{N}$$\nSimilarly, the empirical probability of a forecast exceedance (the forecast's climatological frequency or bias) is the total number of forecast exceedances, $H+F$, divided by $N$:\n$$P(F_c) = \\frac{H + F}{N}$$\nA \"no-skill\" or purely random forecast is one where the forecast events are statistically independent of the observed events. Under this assumption of independence, the joint probability of a hit (an event being both forecast and observed) is the product of the marginal probabilities:\n$$P(\\text{random hit}) = P(O \\cap F_c) = P(O) \\times P(F_c)$$\nThe expected number of random hits, $H_r$, in a sample of size $N$ is then $N$ times this joint probability:\n$$H_r = N \\times P(\\text{random hit}) = N \\times \\left(\\frac{H + M}{N}\\right) \\times \\left(\\frac{H + F}{N}\\right)$$\n$$H_r = \\frac{(H + M)(H + F)}{N}$$\nThis is the expression for the expected number of hits due to random chance, given the observed and forecast event frequencies.\n\nThe Threat Score (TS), also known as the Critical Success Index (CSI), measures the accuracy of the forecast with respect to the set of cases where the event was either forecast or observed. It is defined as:\n$$TS = \\frac{H}{H + M + F}$$\nThe Equitable Threat Score (ETS), also known as the Gilbert Skill Score (GSS), improves upon the TS by correcting for hits that would be expected to occur purely by chance. A skill score measures the improvement of the forecast over a reference forecast, which in this case is a random forecast. The general formula for a skill score is:\n$$\\text{Skill Score} = \\frac{\\text{Score}_{\\text{forecast}} - \\text{Score}_{\\text{random}}}{\\text{Score}_{\\text{perfect}} - \\text{Score}_{\\text{random}}}$$\nIn the context of hits, the \"score\" is simply the count of hits.\n- The number of hits from the forecast is $H$.\n- The number of hits expected from a random forecast is $H_r$.\n- For a perfect forecast, all events would be hits, and there would be no misses ($M=0$) or false alarms ($F=0$). The total number of events is $H+M+F$. So, a perfect forecast would achieve all these as hits. The denominator of TS is the union of observed and forecast events. So the potential number of hits for perfect score is $H+M+F$.\nThe number of hits attributable to forecast skill is the number of actual hits minus those expected by chance: $H - H_r$. This forms the numerator of the ETS.\nThe denominator represents the total number of events where skill could have been demonstrated. This is the total set of forecast or observed events, $H+M+F$, less the hits that were expected by chance, $H_r$. By removing $H_r$ from the denominator, we are assessing skill on the set of events not accounted for by random chance.\nThus, the expression for the Equitable Threat Score is:\n$$ETS = \\frac{H - H_r}{H + M + F - H_r}$$\n\n**2. Definition of Hit Rate and False Alarm Rate**\n\nThe Hit Rate (HR), also known as the Probability of Detection (POD) or recall, is the fraction of observed events that were correctly forecast. It is defined as the number of hits divided by the total number of observed events.\n$$HR = \\frac{H}{H+M}$$\nThe conditioning event base for the Hit Rate is the set of all cases where the observation exceeded the threshold.\n\nThe False Alarm Rate (FARate), also known as the Probability of False Detection (POFD), is the fraction of non-observed events that were incorrectly forecast as events. It is defined as the number of false alarms divided by the total number of cases where the event was not observed.\n$$FARate = \\frac{F}{F+C}$$\nThe conditioning event base for the False Alarm Rate is the set of all cases where the observation did not exceed the threshold. It should not be confused with the False Alarm *Ratio*, which is $F/(H+F)$ and is conditioned on the event being forecast.\n\n**3. Computation of the Equitable Threat Score (ETS)**\n\nWe are given the following counts from the verification experiment:\n- $H = 150$\n- $M = 90$\n- $F = 150$\n- $N = 5000$\n\nFirst, we calculate the number of correct rejections, $C$:\n$$C = N - H - M - F = 5000 - 150 - 90 - 150 = 5000 - 390 = 4610$$\nNext, we calculate the expected number of random hits, $H_r$, using the formula derived in Part 1. We require the marginal totals:\n- Total observed events: $H + M = 150 + 90 = 240$\n- Total forecast events: $H + F = 150 + 150 = 300$\nNow, we compute $H_r$:\n$$H_r = \\frac{(H + M)(H + F)}{N} = \\frac{240 \\times 300}{5000} = \\frac{72000}{5000} = 14.4$$\nFinally, we compute the ETS using the derived formula:\n$$ETS = \\frac{H - H_r}{H + M + F - H_r}$$\nThe total number of events (forecast or observed) is $H + M + F = 150 + 90 + 150 = 390$.\nSubstituting the values into the ETS formula:\n$$ETS = \\frac{150 - 14.4}{390 - 14.4} = \\frac{135.6}{375.6}$$\nPerforming the division and rounding to four significant figures:\n$$ETS \\approx 0.36102236...$$\n$$ETS \\approx 0.3610$$",
            "answer": "$$\\boxed{0.3610}$$"
        },
        {
            "introduction": "A low average model error, or 'global bias,' can be deceptive, potentially masking large, offsetting errors that occur under different conditions. This hands-on coding exercise  guides you through diagnosing these hidden, state-dependent biases by examining the model error conditioned on the observed state. You will implement techniques like quantile binning and use a nested-model $F$-test to statistically identify nonlinear bias structures, a critical skill for targeted model improvement.",
            "id": "3799836",
            "problem": "You are given paired series of model outputs and observations of Sea Surface Temperature (SST), denoted by $M_i$ and $O_i$ respectively, for $i=1,\\dots,N$. The error at time index $i$ is defined by $e_i = M_i - O_i$, expressed in degrees Celsius (°C). The goal is to validate the model by computing the global bias and the conditional bias as a function of the observed state, and to diagnose nonlinear bias structures that are obscured when considering only the global bias.\n\nStarting from the foundational definition of conditional expectation, the conditional bias function $b(o)$ is defined as $b(o) = \\mathbb{E}[e \\mid O = o]$. Since direct evaluation of $\\mathbb{E}[e \\mid O = o]$ is not practical with finite samples, you must estimate $b(o)$ using bins over the observed state $O$. To do this:\n- Partition the observed values $\\{O_i\\}$ into $K$ quantile bins (equal-frequency bins) with $K=6$. Let these bins be defined by edges $q_0 < q_1 < \\dots < q_6$, where $q_j$ is the empirical quantile of order $j/6$ of $\\{O_i\\}$. For each bin $j$, compute the conditional bias estimate $b_j$ as the sample mean of $\\{e_i: O_i \\in [q_{j-1}, q_j)\\}$, treating the last bin as $[q_5, q_6]$ to include the maximum. Let the conditional bias range be $R = \\max_j b_j - \\min_j b_j$, expressed in degrees Celsius (°C).\n- Compute the global bias $B = \\frac{1}{N}\\sum_{i=1}^N e_i$, also in degrees Celsius (°C).\n\nTo diagnose nonlinear bias structures, model the error as a polynomial function of the observed state,\n$$\ne_i = a_0 + a_1 O_i + a_2 O_i^2 + \\varepsilon_i,\n$$\nand estimate the coefficients $\\hat{a}_0, \\hat{a}_1, \\hat{a}_2$ via least squares. Compare the quadratic model to the nested linear model\n$$\ne_i = c_0 + c_1 O_i + \\eta_i\n$$\nusing the classical nested-model $F$-test. Let $\\mathrm{SSE}_1$ and $\\mathrm{SSE}_2$ be the sum of squared residuals for the linear and quadratic models respectively, with $p_1=2$ parameters for the linear model and $p_2=3$ parameters for the quadratic model. With $N$ samples, compute the test statistic\n$$\nF = \\frac{\\left(\\mathrm{SSE}_1 - \\mathrm{SSE}_2\\right)/(p_2 - p_1)}{\\mathrm{SSE}_2/(N - p_2)},\n$$\nand its $p$-value under the Fisher-Snedecor distribution (F-distribution) with $(p_2 - p_1, N - p_2)$ degrees of freedom. A small $p$-value indicates that including the quadratic term significantly improves the fit, diagnosing nonlinear bias. Report $\\hat{a}_2$ in units of degrees Celsius per degrees Celsius squared (°C/°C²), and the $p$-value as a decimal within $[0,1]$.\n\nYour program must implement the above procedure and apply it to the following test suite. In each test case, the observations and model outputs should be generated synthetically according to the specified rules. All SST values are in degrees Celsius (°C), and noise is Gaussian with zero mean.\n\nTest suite (four cases):\n1. Nonlinear bias with near-zero global bias:\n   - Sample size $N = 2000$.\n   - Observations $O_i$ drawn independently from a uniform distribution on $[10, 30]$.\n   - Deterministic bias term $d(O_i) = 0.02\\,(O_i - 20)^2 - c$, where $c$ is the analytic mean of $0.02\\,(O - 20)^2$ under $O \\sim \\mathrm{Uniform}(10, 30)$, i.e., $c = 0.02 \\times \\mathrm{Var}(O) = 0.02 \\times \\frac{(30-10)^2}{12}$.\n   - Noise standard deviation $\\sigma = 0.1$. Model outputs $M_i = O_i + d(O_i) + \\epsilon_i$ with $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$.\n\n2. Pure linear bias:\n   - Sample size $N = 2000$.\n   - Observations $O_i \\sim \\mathrm{Uniform}(5, 30)$.\n   - Deterministic bias term $d(O_i) = 0.5 + 0.03\\,(O_i - 17.5)$.\n   - Noise standard deviation $\\sigma = 0.15$. Model outputs $M_i = O_i + d(O_i) + \\epsilon_i$.\n\n3. Unbiased model with random noise:\n   - Sample size $N = 2000$.\n   - Observations $O_i \\sim \\mathrm{Uniform}(5, 30)$.\n   - Deterministic bias term $d(O_i) = 0$.\n   - Noise standard deviation $\\sigma = 0.2$. Model outputs $M_i = O_i + \\epsilon_i$.\n\n4. Heteroscedastic noise and subtle quadratic bias centered to zero mean:\n   - Sample size $N = 80$.\n   - Observations $O_i$ drawn by first sampling $X_i \\sim \\mathrm{Beta}(\\alpha=2,\\beta=5)$, then setting $O_i = 5 + 25 X_i$ to map to $[5, 30]$.\n   - Deterministic bias term $d(O_i) = 0.015\\,(O_i - 15)^2 - c$, where $c$ is chosen numerically as the sample mean of $0.015\\,(O_i - 15)^2$ over the realized $\\{O_i\\}$ for this case, to center the deterministic bias to near zero global mean.\n   - Noise standard deviation depends on $O_i$ as $\\sigma_i = 0.05 + 0.01\\,(O_i - 5)$.\n   - Model outputs $M_i = O_i + d(O_i) + \\epsilon_i$, with $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma_i^2)$.\n\nFor each test case, compute:\n- The global bias $B$ in degrees Celsius (°C).\n- The conditional bias range $R$ in degrees Celsius (°C).\n- The estimated quadratic coefficient $\\hat{a}_2$ in degrees Celsius per degrees Celsius squared (°C/°C²).\n- The $p$-value for the nested-model $F$-test as a decimal.\n\nAngle units do not apply in this problem. All physical quantities must be treated in the specified units. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets in the following format:\n- For each test case output the list $[B, R, \\hat{a}_2, p]$.\n- Aggregate the four test case results into a single list, yielding an output like $[[B_1,R_1,\\hat{a}_{2,1},p_1],[B_2,R_2,\\hat{a}_{2,2},p_2],[B_3,R_3,\\hat{a}_{2,3},p_3],[B_4,R_4,\\hat{a}_{2,4},p_4]]$.",
            "solution": "The problem statement has been analyzed and is determined to be valid. It is scientifically grounded in standard statistical and numerical methods used for model validation, it is well-posed with clear and unambiguous instructions, and it is expressed in objective, formal language. All necessary data, parameters, and procedures are provided to construct a unique and verifiable solution.\n\nThe problem requires the implementation of a statistical validation procedure for a Sea Surface Temperature (SST) model against observational data. This procedure involves quantifying different aspects of model error, or bias, defined as $e_i = M_i - O_i$, where $M_i$ are model outputs and $O_i$ are observations. The analysis comprises three main components for each test case: calculation of the global bias, estimation of the conditional bias, and a regression-based diagnosis of nonlinear bias structures.\n\nFirst, we generate the synthetic data series $\\{O_i\\}_{i=1}^N$ and $\\{M_i\\}_{i=1}^N$ for each of the four test cases according to the specified stochastic models. The error series $\\{e_i\\}_{i=1}^N$ is then calculated as their difference.\n\nThe global bias, $B$, is the simplest metric of model performance, defined as the mean of all errors:\n$$\nB = \\frac{1}{N}\\sum_{i=1}^N e_i\n$$\nA value of $B$ close to zero suggests that, on average, the model does not systematically overestimate or underestimate the observations. However, a zero global bias can mask significant state-dependent errors.\n\nTo uncover such structures, we estimate the conditional bias, $b(o) = \\mathbb{E}[e \\mid O = o]$, which is the expected error given a specific observed value $o$. Since the exact conditional expectation is intractable with finite data, we approximate it by binning the data. The range of observed SST values is partitioned into $K=6$ equal-frequency (quantile) bins. The bin edges are determined by the empirical quantiles of the observation series $\\{O_i\\}$. Let the quantile-based edges be $q_0, q_1, \\dots, q_K$, where $q_j$ is the empirical quantile of order $j/K$. The conditional bias for the $j$-th bin ($j=1, \\dots, K$) is estimated as the sample mean of errors whose corresponding observations fall within that bin:\n$$\nb_j = \\text{mean}\\{e_i \\mid O_i \\in [q_{j-1}, q_j') \\}\n$$\nwhere the interval is $[q_{j-1}, q_j)$ for $j < K$ and $[q_{K-1}, q_K]$ for $j=K$ to ensure the maximum observation is included. The conditional bias range, $R = \\max_j b_j - \\min_j b_j$, quantifies the magnitude of the variation in bias across different states of the system. A large $R$ relative to the global bias $B$ indicates a significant state-dependent bias structure.\n\nFinally, to formally diagnose and quantify nonlinear bias, we model the error $e_i$ as a polynomial function of the observation $O_i$. We fit a quadratic model via ordinary least squares (OLS):\n$$\ne_i = a_0 + a_1 O_i + a_2 O_i^2 + \\varepsilon_i\n$$\nThe estimated coefficient $\\hat{a}_2$ provides a direct measure of the concavity of the bias. A non-zero $\\hat{a}_2$ suggests the model error changes quadratically with the observed SST. To assess the statistical significance of this quadratic term, we perform a nested-model $F$-test, comparing the full quadratic model (with $p_2=3$ parameters: $a_0, a_1, a_2$) against a simpler, nested linear model (with $p_1=2$ parameters: $c_0, c_1$):\n$$\ne_i = c_0 + c_1 O_i + \\eta_i\n$$\nThe $F$-statistic is calculated from the sum of squared residuals (SSE) of the linear model ($\\mathrm{SSE}_1$) and the quadratic model ($\\mathrm{SSE}_2$):\n$$\nF = \\frac{(\\mathrm{SSE}_1 - \\mathrm{SSE}_2)/(p_2 - p_1)}{\\mathrm{SSE}_2/(N - p_2)}\n$$\nThis statistic follows an $F$-distribution with $(p_2 - p_1, N - p_2)$ degrees of freedom under the null hypothesis that the quadratic term is zero ($H_0: a_2 = 0$). The $p$-value associated with this $F$-statistic indicates the probability of observing such an improvement in fit (from linear to quadratic) by chance if the true relationship were linear. A small $p$-value (e.g., $< 0.05$) provides strong evidence against the null hypothesis, confirming the presence of a significant nonlinear bias structure.\n\nThis full procedure is applied to each of the four specified test cases. The required outputs—global bias $B$, conditional bias range $R$, quadratic coefficient $\\hat{a}_2$, and the $F$-test $p$-value—are calculated and aggregated. It is noted that for Case 4, the OLS assumption of homoscedasticity is violated by design ($\\sigma_i$ depends on $O_i$). While OLS coefficient estimates remain unbiased, the resulting $p$-value from the standard $F$-test should be interpreted with caution. However, the calculation is performed as specified.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import f as f_dist\n\ndef solve():\n    \"\"\"\n    Main function to run the validation procedure for all test cases.\n    \"\"\"\n\n    # Using a fixed seed for reproducibility of the random process.\n    rng = np.random.default_rng(seed=42)\n\n    test_cases = [\n        # Case 1: Nonlinear bias with near-zero global bias\n        {\n            \"N\": 2000,\n            \"O_dist\": lambda n: rng.uniform(10, 30, size=n),\n            \"d_func\": lambda O: 0.02 * (O - 20)**2 - (0.02 * (30 - 10)**2 / 12),\n            \"sigma\": 0.1,\n            \"heteroscedastic\": False\n        },\n        # Case 2: Pure linear bias\n        {\n            \"N\": 2000,\n            \"O_dist\": lambda n: rng.uniform(5, 30, size=n),\n            \"d_func\": lambda O: 0.5 + 0.03 * (O - 17.5),\n            \"sigma\": 0.15,\n            \"heteroscedastic\": False\n        },\n        # Case 3: Unbiased model with random noise\n        {\n            \"N\": 2000,\n            \"O_dist\": lambda n: rng.uniform(5, 30, size=n),\n            \"d_func\": lambda O: 0.0,\n            \"sigma\": 0.2,\n            \"heteroscedastic\": False\n        },\n        # Case 4: Heteroscedastic noise and subtle quadratic bias\n        {\n            \"N\": 80,\n            \"O_dist\": lambda n: 5 + 25 * rng.beta(2, 5, size=n),\n            \"d_func\": \"special\", # Handle this case inside the loop\n            \"sigma_func\": lambda O: 0.05 + 0.01 * (O - 5),\n            \"heteroscedastic\": True\n        }\n    ]\n\n    results = []\n\n    for case in test_cases:\n        N = case[\"N\"]\n        K = 6\n\n        # 1. Generate synthetic data\n        O = case[\"O_dist\"](N)\n        \n        if case[\"heteroscedastic\"]:\n            if case[\"d_func\"] == \"special\":\n                # As per problem, c is sample mean for this case\n                T = 0.015 * (O - 15)**2\n                c = np.mean(T)\n                d = T - c\n            sigma_i = case[\"sigma_func\"](O)\n            epsilon = rng.normal(0, sigma_i, size=N)\n        else:\n            d = case[\"d_func\"](O)\n            sigma = case[\"sigma\"]\n            epsilon = rng.normal(0, sigma, size=N)\n        \n        # Error is the deterministic bias plus random noise\n        e = d + epsilon\n\n        # 2. Calculate global bias B\n        B = np.mean(e)\n\n        # 3. Calculate conditional bias range R\n        q_edges = np.quantile(O, np.linspace(0, 1, K + 1))\n        \n        b_means = []\n        for j in range(1, K + 1):\n            if j < K:\n                # Interval [q_{j-1}, q_j)\n                indices = (O >= q_edges[j-1]) & (O < q_edges[j])\n            else:\n                # Last bin [q_{K-1}, q_K] inclusive\n                indices = (O >= q_edges[j-1]) & (O <= q_edges[j])\n            \n            # Handle potentially empty bins if quantiles are not unique\n            if np.any(indices):\n                b_means.append(np.mean(e[indices]))\n            else:\n                # Append nan for empty bin, will be ignored by max/min\n                b_means.append(np.nan)\n        \n        b_means = np.array(b_means)\n        R = np.nanmax(b_means) - np.nanmin(b_means)\n        \n        # 4. Polynomial regression and F-test\n        p1, p2 = 2, 3\n\n        # Linear model: e = c0 + c1*O\n        X1 = np.vstack([O, np.ones(N)]).T\n        _, sse1_list, _, _ = np.linalg.lstsq(X1, e, rcond=None)\n        sse1 = sse1_list[0] if len(sse1_list) > 0 else 0.0\n\n        # Quadratic model: e = a0 + a1*O + a2*O^2\n        X2 = np.vstack([O**2, O, np.ones(N)]).T\n        coeffs2, sse2_list, _, _ = np.linalg.lstsq(X2, e, rcond=None)\n        a2_hat = coeffs2[0]\n        sse2 = sse2_list[0] if len(sse2_list) > 0 else 0.0\n        \n        # F-test\n        df1 = p2 - p1\n        df2 = N - p2\n        \n        if df2 > 0 and sse2 > 1e-12: # Check forvalid degrees of freedom and non-zero denominator\n            f_stat = ((sse1 - sse2) / df1) / (sse2 / df2)\n            p_value = f_dist.sf(f_stat, df1, df2)\n        else: # Handle degenerate cases\n            f_stat = np.nan\n            p_value = np.nan\n\n        results.append([B, R, a2_hat, p_value])\n    \n    # Format the final output precisely as requested\n    formatted_results = ','.join([str(res) for res in results])\n    print(f\"[{formatted_results}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Geophysical time series are rarely composed of independent data points; they typically exhibit serial correlation that violates the assumptions of many standard statistical tests. This practice  addresses this critical issue by guiding you through the derivation of the 'effective sample size,' $N_{\\text{eff}}$, which quantifies the reduced informational content in an autocorrelated dataset. By applying this concept to adjust the confidence interval of a correlation skill score, you will learn a fundamental method for producing statistically robust and credible validation results from time-dependent data.",
            "id": "3799822",
            "problem": "A regional ocean circulation model is validated against satellite-derived Sea Surface Temperature (SST) anomalies over a western boundary current region. Let $M_t$ denote the monthly model anomaly and $O_t$ denote the monthly observational anomaly, both sampled at regular monthly intervals for $N=120$ months. The anomalies are approximately mean-zero, weakly stationary, and jointly Gaussian. The sample Pearson correlation between $M_t$ and $O_t$ is $r=0.65$. Both series exhibit serial correlation consistent with Autoregressive of order one (AR(1)) processes, with lag-$1$ autocorrelations $\\phi_M=0.6$ for $M_t$ and $\\phi_O=0.8$ for $O_t$. \n\nYou will derive an effective sample size that accounts for serial correlation and use it to adjust the confidence interval of the correlation skill metric. Proceed as follows:\n\n1. Starting from a valid base for time series with dependence, use the definition of the autocorrelation function and the variance of sums of dependent random variables to justify the construction of an effective sample size $N_{\\text{eff}}$ for the Fisher $z$-transformed correlation. In particular, recall that for independent samples the Fisher transform $z=\\operatorname{arctanh}(r)$ is approximately normal with variance $1/(N-3)$. For dependent samples, define $N_{\\text{eff}}$ by matching the variance of $z$ under dependence to the independent-sample form.\n\n2. Under the AR(1) assumptions above, derive a closed-form analytic expression for $N_{\\text{eff}}$ in terms of $N$, $\\phi_M$, and $\\phi_O$.\n\n3. Using your derived $N_{\\text{eff}}$, construct the lower bound of the $95\\%$ confidence interval for the true correlation by applying the Fisher $z$ transformation and the normal quantile. Express the final lower bound in decimal form. Round your final numeric answer to four significant figures.\n\nNo physical units are required in your final answer.",
            "solution": "The problem requires the derivation of an effective sample size, $N_{\\text{eff}}$, for calculating the confidence interval of a correlation coefficient between two autocorrelated time series. This will be done in three steps: justifying the form of $N_{\\text{eff}}$, deriving a specific formula for Autoregressive of order one (AR(1)) processes, and finally calculating the lower bound of a $95\\%$ confidence interval for the specified data.\n\n**Step 1: Justification of the Effective Sample Size $N_{\\text{eff}}$**\n\nThe starting point is the Fisher $z$-transformation for a sample Pearson correlation coefficient $r$:\n$$ z = \\operatorname{arctanh}(r) = \\frac{1}{2} \\ln\\left(\\frac{1+r}{1-r}\\right) $$\nFor two jointly Gaussian random variables with $N$ independent paired samples, the sampling distribution of $z$ is approximately normal with a mean of $\\operatorname{arctanh}(\\rho)$, where $\\rho$ is the true population correlation, and a variance given by:\n$$ \\operatorname{Var}(z) \\approx \\frac{1}{N-3} $$\nWhen the time series $M_t$ and $O_t$ are not independent in time (i.e., they exhibit serial correlation), the samples are not independent, and the variance of $z$ is larger than that given by the independent-sample formula. The concept of an effective sample size, $N_{\\text{eff}}$, is introduced to account for this inflation of variance. We define $N_{\\text{eff}}$ such that the variance of $z$ for dependent samples can be expressed in a form analogous to the independent case:\n$$ \\operatorname{Var}_{\\text{dep}}(z) \\approx \\frac{1}{N_{\\text{eff}}-3} $$\nFor large sample sizes, the variance of $z$ for two autocorrelated time series is well-approximated by scaling the independent variance by a factor that depends on the autocorrelation functions, $\\rho_M(k)$ and $\\rho_O(k)$, of the two series. This leads to the relationship:\n$$ \\operatorname{Var}_{\\text{dep}}(z) \\approx \\frac{1}{N} \\sum_{k=-\\infty}^{\\infty} \\rho_M(k) \\rho_O(k) $$\nComparing this large-$N$ approximation to the standard form $\\operatorname{Var}(z) \\approx 1/N_{\\text{eff}}$, motivates the following definition for $N_{\\text{eff}}$:\n$$ \\frac{1}{N_{\\text{eff}}} \\approx \\frac{1}{N} \\sum_{k=-(N-1)}^{N-1} \\rho_M(k) \\rho_O(k) $$\nwhere the sum is truncated for a finite sample size $N$. Noting that $\\rho(k) = \\rho(-k)$ and $\\rho(0)=1$, this can be rewritten as:\n$$ \\frac{N}{N_{\\text{eff}}} \\approx 1 + 2 \\sum_{k=1}^{N-1} \\rho_M(k) \\rho_O(k) $$\nThis expression provides the justification for the construction of $N_{\\text{eff}}$. It effectively represents the factor by which the number of samples must be reduced to yield the correct variance for the statistic of interest (here, the Fisher-transformed correlation). For large $N$, the approximation $\\frac{N-3}{N_{\\text{eff}}-3} \\approx \\frac{N}{N_{\\text{eff}}}$ holds, validating this approach.\n\n**Step 2: Derivation of $N_{\\text{eff}}$ for AR(1) Processes**\n\nThe problem states that both time series, $M_t$ and $O_t$, follow AR(1) processes. The autocorrelation function for a stationary AR(1) process with lag-$1$ autocorrelation $\\phi$ is given by $\\rho(k) = \\phi^{|k|}$ for an integer lag $k$.\nWe are given $\\rho_M(1) = \\phi_M = 0.6$ and $\\rho_O(1) = \\phi_O = 0.8$. Therefore, the autocorrelation functions are $\\rho_M(k) = \\phi_M^k$ and $\\rho_O(k) = \\phi_O^k$ for $k \\ge 0$.\n\nWe substitute these into the summation from Step 1. For a large sample size $N$ (here $N=120$ is sufficiently large), we can approximate the finite sum with an infinite one:\n$$ \\sum_{k=1}^{N-1} \\rho_M(k) \\rho_O(k) = \\sum_{k=1}^{N-1} (\\phi_M \\phi_O)^k \\approx \\sum_{k=1}^{\\infty} (\\phi_M \\phi_O)^k $$\nThis is an infinite geometric series with first term and ratio equal to $\\phi_M \\phi_O$. Since $|\\phi_M| < 1$ and $|\\phi_O| < 1$, we have $|\\phi_M \\phi_O| < 1$, so the series converges to:\n$$ \\sum_{k=1}^{\\infty} (\\phi_M \\phi_O)^k = \\frac{\\phi_M \\phi_O}{1 - \\phi_M \\phi_O} $$\nSubstituting this result back into the expression for $N_{\\text{eff}}$:\n$$ \\frac{N}{N_{\\text{eff}}} \\approx 1 + 2 \\left( \\frac{\\phi_M \\phi_O}{1 - \\phi_M \\phi_O} \\right) = \\frac{(1 - \\phi_M \\phi_O) + 2 \\phi_M \\phi_O}{1 - \\phi_M \\phi_O} = \\frac{1 + \\phi_M \\phi_O}{1 - \\phi_M \\phi_O} $$\nInverting this expression gives the closed-form analytic formula for the effective sample size:\n$$ N_{\\text{eff}} \\approx N \\frac{1 - \\phi_M \\phi_O}{1 + \\phi_M \\phi_O} $$\n\n**Step 3: Calculation of the 95% Confidence Interval Lower Bound**\n\nWe are given the following values:\n-   Sample size: $N = 120$\n-   Sample correlation: $r = 0.65$\n-   AR(1) coefficients: $\\phi_M = 0.6$ and $\\phi_O = 0.8$\n\nFirst, we calculate the product of the AR(1) coefficients:\n$$ \\phi_M \\phi_O = 0.6 \\times 0.8 = 0.48 $$\nNext, we compute the effective sample size $N_{\\text{eff}}$ using the derived formula:\n$$ N_{\\text{eff}} = 120 \\frac{1 - 0.48}{1 + 0.48} = 120 \\frac{0.52}{1.48} = 120 \\frac{13}{37} = \\frac{1560}{37} \\approx 42.16216 $$\nNow, we perform the Fisher $z$-transformation on the sample correlation $r=0.65$:\n$$ z = \\operatorname{arctanh}(0.65) = \\frac{1}{2}\\ln\\left(\\frac{1+0.65}{1-0.65}\\right) = \\frac{1}{2}\\ln\\left(\\frac{1.65}{0.35}\\right) = \\frac{1}{2}\\ln\\left(\\frac{33}{7}\\right) \\approx 0.77530 $$\nThe standard error of $z$, $\\sigma_z$, is calculated using $N_{\\text{eff}}$:\n$$ \\sigma_z = \\sqrt{\\frac{1}{N_{\\text{eff}}-3}} = \\sqrt{\\frac{1}{\\frac{1560}{37}-3}} = \\sqrt{\\frac{1}{\\frac{1560-111}{37}}} = \\sqrt{\\frac{37}{1449}} \\approx 0.15980 $$\nFor a $95\\%$ confidence interval, the critical value from the standard normal distribution is $z_{\\alpha/2} = z_{0.025}$, which is approximately $1.96$. More precisely, $z_{0.025} \\approx 1.95996$.\nThe lower bound of the confidence interval for the true Fisher-transformed correlation, $\\zeta = \\operatorname{arctanh}(\\rho)$, is:\n$$ \\zeta_{\\text{lower}} = z - z_{0.025} \\sigma_z \\approx 0.77530 - 1.95996 \\times 0.15980 \\approx 0.77530 - 0.31320 \\approx 0.46210 $$\nFinally, to find the lower bound for the true correlation coefficient $\\rho$, we apply the inverse Fisher transformation (hyperbolic tangent) to $\\zeta_{\\text{lower}}$:\n$$ \\rho_{\\text{lower}} = \\tanh(\\zeta_{\\text{lower}}) \\approx \\tanh(0.46210) $$\n$$ \\rho_{\\text{lower}} \\approx 0.43178 $$\nRounding the final result to four significant figures gives $0.4318$.",
            "answer": "$$\\boxed{0.4318}$$"
        }
    ]
}