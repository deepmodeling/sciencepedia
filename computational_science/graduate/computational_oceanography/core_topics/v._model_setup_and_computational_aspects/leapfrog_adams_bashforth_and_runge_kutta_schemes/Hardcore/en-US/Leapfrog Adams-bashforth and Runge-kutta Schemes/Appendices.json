{
    "hands_on_practices": [
        {
            "introduction": "A fundamental task in computational modeling is ensuring the numerical stability of the chosen time integration scheme. This practice guides you through a complete stability analysis for a canonical problem in oceanography: the propagation of gravity waves. By applying Fourier (von Neumann) analysis to the semi-discretized shallow-water equations integrated with the fourth-order Runge-Kutta (RK4) method, you will derive the maximum allowable time step, known as the Courant-Friedrichs-Lewy (CFL) condition, from first principles .",
            "id": "3798698",
            "problem": "Consider the one-dimensional linearized shallow-water equations for depth-averaged flow on an $f$-plane with constant mean depth $H$ and gravitational acceleration $g$, neglecting rotation to isolate free surface gravity waves:\n$$\n\\frac{\\partial \\eta}{\\partial t} + H \\frac{\\partial u}{\\partial x} = 0, \\qquad \\frac{\\partial u}{\\partial t} + g \\frac{\\partial \\eta}{\\partial x} = 0,\n$$\nwhere $\\eta(x,t)$ is the free surface displacement and $u(x,t)$ is the depth-averaged velocity. These equations imply a gravity wave phase speed $c=\\sqrt{gH}$. Discretize space on a uniform periodic grid with spacing $\\Delta x$ using the standard second-order centered finite difference for $\\partial/\\partial x$, and leave time continuous (a method-of-lines semi-discretization). Then integrate in time with the classical explicit four-stage Runge-Kutta method (Runge-Kutta fourth order (RK4)) with time step $\\Delta t$.\n\nUsing Fourier (von Neumann) stability analysis applied to the semi-discrete system, and imposing the absolute stability requirement for RK4 on all resolvable discrete wavenumbers, derive the maximum allowable time step $\\Delta t_{\\max}$ as a closed-form analytic expression in terms of $g$, $H$, and $\\Delta x$. Your derivation must start from the conservation laws above, the centered-difference symbol for the first derivative, and the RK4 scalar stability function, and must ensure stability for all discrete Fourier modes supported on the grid.\n\nExpress your final result for $\\Delta t_{\\max}$ as a single simplified analytic expression. No numerical evaluation is required. Its physical unit is seconds.",
            "solution": "The problem is valid as it is scientifically grounded, well-posed, and objective. It poses a standard question in numerical analysis for partial differential equations, a core topic in computational science. All necessary information is provided.\n\nThe solution proceeds in several steps:\n1.  Semi-discretization of the governing equations in space.\n2.  Application of Fourier analysis to the semi-discrete system to find its eigenvalues.\n3.  Determination of the stability boundary for the RK4 method on the imaginary axis.\n4.  Combination of these results to derive the stability constraint on the time step $\\Delta t$.\n\n**Step 1: Semi-discretization**\nThe given one-dimensional linearized shallow-water equations are:\n$$\n\\frac{\\partial \\eta}{\\partial t} + H \\frac{\\partial u}{\\partial x} = 0\n$$\n$$\n\\frac{\\partial u}{\\partial t} + g \\frac{\\partial \\eta}{\\partial x} = 0\n$$\nWe discretize the spatial domain into points $x_j = j \\Delta x$ for integer $j$. The continuous variables $\\eta(x,t)$ and $u(x,t)$ are approximated by grid-point values $\\eta_j(t) = \\eta(x_j, t)$ and $u_j(t) = u(x_j, t)$. The spatial derivative $\\partial/\\partial x$ is approximated using a second-order centered finite difference operator:\n$$\n\\left. \\frac{\\partial f}{\\partial x} \\right|_{x=x_j} \\approx \\frac{f_{j+1} - f_{j-1}}{2 \\Delta x}\n$$\nApplying this to the system of equations yields a set of ordinary differential equations (ODEs) in time, a technique known as the method of lines:\n$$\n\\frac{d \\eta_j}{dt} = -H \\left( \\frac{u_{j+1} - u_{j-1}}{2 \\Delta x} \\right)\n$$\n$$\n\\frac{d u_j}{dt} = -g \\left( \\frac{\\eta_{j+1} - \\eta_{j-1}}{2 \\Delta x} \\right)\n$$\n\n**Step 2: Fourier (von Neumann) Analysis**\nTo analyze the stability, we consider a single Fourier mode solution on the periodic grid:\n$$\n\\eta_j(t) = \\hat{\\eta}(k, t) e^{i k x_j} = \\hat{\\eta}(k, t) e^{i k j \\Delta x}\n$$\n$$\nu_j(t) = \\hat{u}(k, t) e^{i k x_j} = \\hat{u}(k, t) e^{i k j \\Delta x}\n$$\nwhere $k$ is the wavenumber and $\\hat{\\eta}$ and $\\hat{u}$ are the complex Fourier amplitudes, which depend on time. Substituting these forms into the semi-discrete equations:\nFor the first equation:\n$$\n\\frac{d}{dt} \\left(\\hat{\\eta} e^{i k j \\Delta x}\\right) = -H \\left( \\frac{\\hat{u} e^{i k (j+1) \\Delta x} - \\hat{u} e^{i k (j-1) \\Delta x}}{2 \\Delta x} \\right)\n$$\nDividing by $e^{i k j \\Delta x}$:\n$$\n\\frac{d \\hat{\\eta}}{dt} = -\\frac{H \\hat{u}}{2 \\Delta x} \\left( e^{i k \\Delta x} - e^{-i k \\Delta x} \\right) = -\\frac{H \\hat{u}}{2 \\Delta x} (2i \\sin(k \\Delta x)) = -i \\frac{H \\sin(k \\Delta x)}{\\Delta x} \\hat{u}\n$$\nSimilarly, for the second equation:\n$$\n\\frac{d \\hat{u}}{dt} = -g \\left( \\frac{\\hat{\\eta}_{j+1} - \\hat{\\eta}_{j-1}}{2 \\Delta x} \\right) \\implies \\frac{d \\hat{u}}{dt} = -i \\frac{g \\sin(k \\Delta x)}{\\Delta x} \\hat{\\eta}\n$$\nThis forms a linear system of ODEs for the Fourier amplitudes:\n$$\n\\frac{d}{dt} \\begin{pmatrix} \\hat{\\eta} \\\\ \\hat{u} \\end{pmatrix} = \\begin{pmatrix} 0  -i \\frac{H \\sin(k \\Delta x)}{\\Delta x} \\\\ -i \\frac{g \\sin(k \\Delta x)}{\\Delta x}  0 \\end{pmatrix} \\begin{pmatrix} \\hat{\\eta} \\\\ \\hat{u} \\end{pmatrix}\n$$\nThis is of the form $\\frac{d\\mathbf{v}}{dt} = \\mathbf{A} \\mathbf{v}$. The stability of the time integration scheme will depend on the eigenvalues $\\lambda$ of the matrix $\\mathbf{A}$. The eigenvalues are found by solving the characteristic equation $\\det(\\mathbf{A} - \\lambda \\mathbf{I}) = 0$:\n$$\n\\det \\begin{pmatrix} -\\lambda  -i \\frac{H \\sin(k \\Delta x)}{\\Delta x} \\\\ -i \\frac{g \\sin(k \\Delta x)}{\\Delta x}  -\\lambda \\end{pmatrix} = (-\\lambda)^2 - \\left(-i \\frac{H \\sin(k \\Delta x)}{\\Delta x}\\right)\\left(-i \\frac{g \\sin(k \\Delta x)}{\\Delta x}\\right) = 0\n$$\n$$\n\\lambda^2 - i^2 \\frac{gH \\sin^2(k \\Delta x)}{(\\Delta x)^2} = 0\n$$\n$$\n\\lambda^2 + \\frac{gH \\sin^2(k \\Delta x)}{(\\Delta x)^2} = 0\n$$\nLet $c = \\sqrt{gH}$ be the gravity wave phase speed.\n$$\n\\lambda^2 = - \\frac{c^2 \\sin^2(k \\Delta x)}{(\\Delta x)^2}\n$$\nThe eigenvalues are purely imaginary:\n$$\n\\lambda(k) = \\pm i \\frac{c |\\sin(k \\Delta x)|}{\\Delta x}\n$$\nThese eigenvalues represent the frequencies of the discrete wave modes.\n\n**Step 3: RK4 Stability**\nThe classical fourth-order Runge-Kutta (RK4) method, when applied to the scalar test equation $y' = \\lambda y$, yields the update rule $y_{n+1} = R(\\lambda \\Delta t) y_n$, where $R(z)$ is the stability polynomial:\n$$\nR(z) = 1 + z + \\frac{z^2}{2!} + \\frac{z^3}{3!} + \\frac{z^4}{4!}\n$$\nThe scheme is stable if $|R(z)| \\le 1$ for $z = \\lambda \\Delta t$. Since our eigenvalues $\\lambda$ are purely imaginary, we must determine the stability interval of RK4 on the imaginary axis. Let $z = i\\beta$ for a real number $\\beta$.\n$$\nR(i\\beta) = 1 + i\\beta + \\frac{(i\\beta)^2}{2} + \\frac{(i\\beta)^3}{6} + \\frac{(i\\beta)^4}{24} = \\left(1 - \\frac{\\beta^2}{2} + \\frac{\\beta^4}{24}\\right) + i\\left(\\beta - \\frac{\\beta^3}{6}\\right)\n$$\nThe stability condition is $|R(i\\beta)|^2 \\le 1$:\n$$\n|R(i\\beta)|^2 = \\left(1 - \\frac{\\beta^2}{2} + \\frac{\\beta^4}{24}\\right)^2 + \\left(\\beta - \\frac{\\beta^3}{6}\\right)^2 \\le 1\n$$\nExpanding the terms:\n$$\n\\left(1 - \\frac{\\beta^2}{2} + \\frac{\\beta^4}{24}\\right)^2 = 1 - \\beta^2 + \\frac{\\beta^4}{3} - \\frac{\\beta^6}{24} + \\frac{\\beta^8}{576}\n$$\n$$\n\\left(\\beta - \\frac{\\beta^3}{6}\\right)^2 = \\beta^2 - \\frac{\\beta^4}{3} + \\frac{\\beta^6}{36}\n$$\nSumming these gives:\n$$\n|R(i\\beta)|^2 = 1 - \\frac{\\beta^6}{24} + \\frac{\\beta^6}{36} + \\frac{\\beta^8}{576} = 1 - \\beta^6 \\left(\\frac{1}{24} - \\frac{1}{36}\\right) + \\frac{\\beta^8}{576} = 1 - \\frac{\\beta^6}{72} + \\frac{\\beta^8}{576}\n$$\nThe stability condition becomes:\n$$\n1 - \\frac{\\beta^6}{72} + \\frac{\\beta^8}{576} \\le 1 \\implies \\frac{\\beta^8}{576} - \\frac{\\beta^6}{72} \\le 0\n$$\n$$\n\\beta^6 \\left( \\frac{\\beta^2}{576} - \\frac{1}{72} \\right) \\le 0\n$$\nSince $\\beta^6 \\ge 0$ for real $\\beta$, we require the term in parentheses to be non-positive:\n$$\n\\frac{\\beta^2}{576} \\le \\frac{1}{72} \\implies \\beta^2 \\le \\frac{576}{72} = 8\n$$\nThis gives the stability limit for $\\beta$:\n$$\n|\\beta| \\le \\sqrt{8} = 2\\sqrt{2}\n$$\nSo, for purely imaginary $z = i\\beta$, the RK4 method is stable if and only if $z$ lies on the imaginary axis in the interval $[-2i\\sqrt{2}, 2i\\sqrt{2}]$.\n\n**Step 4: Derivation of the Maximum Time Step**\nThe stability condition must hold for all eigenvalues $\\lambda(k)$ of the semi-discrete system. This means for all $k$, we must satisfy:\n$$\n|\\lambda(k) \\Delta t| \\le 2\\sqrt{2}\n$$\nThis must hold for the eigenvalue with the largest magnitude. Let's find $\\max_k |\\lambda(k)|$:\n$$\n\\max_k |\\lambda(k)| = \\max_k \\left| \\pm i \\frac{c |\\sin(k \\Delta x)|}{\\Delta x} \\right| = \\frac{c}{\\Delta x} \\max_k |\\sin(k \\Delta x)|\n$$\nThe range of wavenumbers $k$ resolved by a grid of spacing $\\Delta x$ spans up to the Nyquist wavenumber, $k_{Ny} = \\pi/\\Delta x$. The product $k \\Delta x$ thus ranges from $-\\pi$ to $\\pi$. Over this interval, the maximum value of $|\\sin(k \\Delta x)|$ is $1$, which occurs at $k \\Delta x = \\pm \\pi/2$.\nTherefore, the maximum magnitude of the eigenvalues is:\n$$\n\\max_k |\\lambda(k)| = \\frac{c}{\\Delta x} \\cdot 1 = \\frac{c}{\\Delta x}\n$$\nThe stability constraint for the time step $\\Delta t$ is then:\n$$\n\\left(\\frac{c}{\\Delta x}\\right) \\Delta t \\le 2\\sqrt{2}\n$$\nThis gives the maximum allowable time step $\\Delta t_{\\max}$:\n$$\n\\Delta t_{\\max} = \\frac{2\\sqrt{2} \\Delta x}{c}\n$$\nSubstituting back the expression for the phase speed, $c=\\sqrt{gH}$:\n$$\n\\Delta t_{\\max} = \\frac{2\\sqrt{2} \\Delta x}{\\sqrt{gH}}\n$$\nThis is the final analytical expression for the maximum time step that ensures stability for all Fourier modes supported on the grid when using centered differences for space and RK4 for time. The expression represents a Courant-Friedrichs-Lewy (CFL) condition, where the CFL number is $\\frac{c \\Delta t}{\\Delta x} \\le 2\\sqrt{2}$.",
            "answer": "$$\\boxed{\\frac{2\\sqrt{2} \\Delta x}{\\sqrt{gH}}}$$"
        },
        {
            "introduction": "While multi-step methods like the Adams-Bashforth (AB) family offer high efficiency, they require multiple previous time-steps to compute the next, posing a challenge for starting a simulation. This exercise addresses this crucial \"start-up problem\" directly. You will explore why the starting procedure must match the order of the main integrator and construct a third-order Runge-Kutta scheme to generate the necessary initial values for an AB3 method, a common task in practical code development .",
            "id": "3798641",
            "problem": "A common explicit multistep integrator in computational oceanography is the Adams–Bashforth method of order $k$ (Adams–Bashforth (AB$k$)). Because AB$k$ requires $k$ past solution values $\\{y^{n}, y^{n-1}, \\ldots, y^{n-k+1}\\}$ to advance from time $t^{n}$ to $t^{n+1}$, an accurate start-up procedure is needed to construct these initial values from a given initial condition. Consider the mixed-layer zonal current modeled as a scalar initial value problem\n$$\n\\frac{du}{dt} \\;=\\; -\\alpha\\,u \\;+\\; F_0\\,\\cos(\\omega t),\n$$\nwith $u(0)=0$, where $\\alpha0$ is a linear damping rate, $F_00$ is a constant wind-forcing amplitude, and $\\omega0$ is a characteristic near-inertial frequency. This scalar model is widely used as a reduced description of wind-forced near-inertial currents in the surface mixed layer.\n\nYou will use a fixed time step $\\Delta t$ to construct $u^1 \\approx u(\\Delta t)$ and $u^2 \\approx u(2\\Delta t)$ for initializing Adams–Bashforth of order three (AB3). Begin from the fundamental definition of a one-step Runge–Kutta method as a quadrature of the right-hand side applied along trial stage trajectories, and use Taylor-series order conditions to derive a three-stage explicit Runge–Kutta (Runge–Kutta (RK)) scheme of order three. Then apply it to compute $u^1$ and $u^2$. In your derivation, clearly state why AB2 requires only one start-up value $y^1$ of second-order accuracy while AB3 requires two start-up values $\\{y^1,y^2\\}$ of third-order accuracy to preserve the global order of the multistep method.\n\nUse the following physically consistent parameter values, which are representative of mid-latitude near-inertial forcing:\n- $\\alpha = \\frac{1}{86400}\\ \\mathrm{s}^{-1}$,\n- $F_0 = 1 \\times 10^{-4}\\ \\mathrm{m}\\ \\mathrm{s}^{-2}$,\n- $\\omega = 1 \\times 10^{-4}\\ \\mathrm{rad}\\ \\mathrm{s}^{-1}$,\n- $\\Delta t = 3600\\ \\mathrm{s}$.\n\nCompute $u^2$ using the derived third-order RK start-up, and report the value of $u^2$ in $\\mathrm{m}\\ \\mathrm{s}^{-1}$. Round your answer to four significant figures.",
            "solution": "The problem is well-posed, scientifically grounded, and provides all necessary information for a unique solution. It is a standard application of numerical methods to a simplified but physically relevant model in oceanography. Therefore, the problem is deemed valid.\n\nThe solution process involves three main parts:\n1.  Derivation of a three-stage, third-order explicit Runge-Kutta (RK3) scheme.\n2.  Explanation of the start-up accuracy requirements for Adams-Bashforth (AB) methods.\n3.  Application of the derived RK3 scheme to compute the requested values for the given initial value problem.\n\n**Part 1: Derivation of a Third-Order, Three-Stage Explicit Runge-Kutta Scheme**\n\nAn $s$-stage explicit Runge-Kutta (RK) method for the initial value problem $\\frac{dy}{dt} = f(t, y)$ is given by\n$$\ny^{n+1} = y^n + \\Delta t \\sum_{i=1}^{s} b_i k_i\n$$\nwhere the stages $k_i$ are\n$$\nk_i = f\\left(t^n + c_i \\Delta t, y^n + \\Delta t \\sum_{j=1}^{i-1} a_{ij} k_j\\right).\n$$\nFor an explicit method, we impose the condition $c_i = \\sum_{j=1}^{i-1} a_{ij}$. For a method to be of order $p=3$, the coefficients $\\{a_{ij}, b_i, c_i\\}$ must satisfy a set of order conditions derived from matching the Taylor series expansion of the numerical solution to that of the true solution up to terms of order $(\\Delta t)^3$. For $s=3$ stages, the order conditions up to order $3$ are:\n1.  Order $1$: $\\sum_{i=1}^3 b_i = 1$\n2.  Order $2$: $\\sum_{i=1}^3 b_i c_i = \\frac{1}{2}$\n3.  Order $3$:\n    a) $\\sum_{i=1}^3 b_i c_i^2 = \\frac{1}{3}$\n    b) $\\sum_{i,j=1}^3 b_i a_{ij} c_j = \\frac{1}{6}$\n\nSince the method is explicit, $a_{ij}=0$ for $j \\ge i$, $c_1=0$, $c_2 = a_{21}$, and $c_3 = a_{31} + a_{32}$. The order conditions simplify to:\n1.  $b_1 + b_2 + b_3 = 1$\n2.  $b_2 c_2 + b_3 c_3 = \\frac{1}{2}$\n3.  $b_2 c_2^2 + b_3 c_3^2 = \\frac{1}{3}$\n4.  $b_3 a_{32} c_2 = \\frac{1}{6}$\n\nThis is a system of $4$ equations in $6$ unknowns ($b_1, b_2, b_3, c_2, c_3, a_{32}$), leaving us with two free parameters. A common and canonical choice is to set $c_2 = \\frac{1}{2}$ and $c_3 = 1$. Substituting these into equations (2) and (3):\n$$\n\\frac{1}{2} b_2 + b_3 = \\frac{1}{2}\n$$\n$$\n\\frac{1}{4} b_2 + b_3 = \\frac{1}{3}\n$$\nSubtracting the second equation from the first yields $\\frac{1}{4} b_2 = \\frac{1}{2} - \\frac{1}{3} = \\frac{1}{6}$, which gives $b_2 = \\frac{4}{6} = \\frac{2}{3}$.\nSubstituting $b_2$ back, we find $b_3 = \\frac{1}{3} - \\frac{1}{4} b_2 = \\frac{1}{3} - \\frac{1}{4} \\left(\\frac{2}{3}\\right) = \\frac{1}{3} - \\frac{1}{6} = \\frac{1}{6}$.\nFrom equation (1), $b_1 = 1 - b_2 - b_3 = 1 - \\frac{2}{3} - \\frac{1}{6} = \\frac{6-4-1}{6} = \\frac{1}{6}$.\nNow, we use equation (4) and the known values of $b_3$ and $c_2$ to find $a_{32}$:\n$$\n\\frac{1}{6} a_{32} \\left(\\frac{1}{2}\\right) = \\frac{1}{6} \\implies \\frac{a_{32}}{12} = \\frac{1}{6} \\implies a_{32} = 2.\n$$\nFinally, we use the explicit method conditions to find the remaining coefficients:\n$a_{21} = c_2 = \\frac{1}{2}$.\n$a_{31} = c_3 - a_{32} = 1 - 2 = -1$.\nThe resulting scheme, known as Kutta's third-order method, is defined by:\n$$\nk_1 = f(t^n, y^n)\n$$\n$$\nk_2 = f\\left(t^n + \\frac{1}{2}\\Delta t, y^n + \\frac{1}{2}\\Delta t k_1\\right)\n$$\n$$\nk_3 = f\\left(t^n + \\Delta t, y^n - \\Delta t k_1 + 2\\Delta t k_2\\right)\n$$\n$$\ny^{n+1} = y^n + \\frac{\\Delta t}{6}(k_1 + 4 k_2 + k_3)\n$$\nThis is a valid three-stage, third-order explicit RK scheme.\n\n**Part 2: Start-Up Accuracy for Adams-Bashforth Methods**\n\nAn Adams-Bashforth method of order $p$ (AB$p$) is a $p$-step linear multistep method. Its global error is of order $O(\\Delta t^p)$, provided it is stable and its local truncation error (LTE) is $O(\\Delta t^{p+1})$. The global error $e^n = y(t^n) - y^n$ depends on two sources: the accumulation of LTE at each step, and the propagation of errors from the initial starting values $\\{y^1, \\dots, y^{p-1}\\}$.\n\nFor a stable $p$-step method, the global error at time $t^n$ is bounded by a quantity proportional to the sum of the initial errors and the accumulated LTEs. To achieve an overall global accuracy of $O(\\Delta t^p)$, the error contribution from the starting values must not be of a lower order. That is, the errors in the starting values, $e^i = y(t^i) - y^i$ for $i=1, \\dots, p-1$, must themselves be at least $O(\\Delta t^p)$.\n\nTo generate these starting values, a one-step method is typically used. A one-step method of order $p$, such as an RK$p$ scheme, has a global error of $O(\\Delta t^p)$. Therefore, to compute a value $y^i = y(i\\Delta t)$ with an error $e^i = O(\\Delta t^p)$, one must use a starter method of at least order $p$.\n\n-   **For AB2 ($p=2$):** This is a 2-step method with global order $O(\\Delta t^2)$. It requires one start-up value, $y^1$, in addition to the initial condition $y^0=y(0)$. To preserve the $O(\\Delta t^2)$ global accuracy, the error in the start-up value, $|y(\\Delta t) - y^1|$, must be $O(\\Delta t^2)$. This requires a start-up procedure of at least second-order accuracy.\n\n-   **For AB3 ($p=3$):** This is a 3-step method with global order $O(\\Delta t^3)$. It requires two start-up values, $\\{y^1, y^2\\}$. To preserve the $O(\\Delta t^3)$ global accuracy, the errors $|y(\\Delta t) - y^1|$ and $|y(2\\Delta t) - y^2|$ must both be $O(\\Delta t^3)$. This requires a start-up procedure of at least third-order accuracy, such as the RK3 scheme derived above.\n\n**Part 3: Application to the Mixed-Layer Zonal Current Model**\n\nThe initial value problem is given by\n$$\n\\frac{du}{dt} = -\\alpha u + F_0 \\cos(\\omega t), \\quad u(0) = 0.\n$$\nWe define the function $f(t,u) = -\\alpha u + F_0 \\cos(\\omega t)$. The given parameters are:\n- $\\alpha = \\frac{1}{86400}\\ \\mathrm{s}^{-1}$\n- $F_0 = 1 \\times 10^{-4}\\ \\mathrm{m}\\ \\mathrm{s}^{-2}$\n- $\\omega = 1 \\times 10^{-4}\\ \\mathrm{rad}\\ \\mathrm{s}^{-1}$\n- $\\Delta t = 3600\\ \\mathrm{s}$\n- $u^0 = u(0) = 0$\n\nWe will use the derived RK3 scheme to compute $u^1 \\approx u(\\Delta t)$ and then $u^2 \\approx u(2\\Delta t)$.\n\n**Step 1: Compute $u^1$**\nWe advance from $t^0=0$ to $t^1 = \\Delta t = 3600$. The initial condition is $u^0=0$.\n\n1.  Compute $k_1$:\n    $k_1 = f(t^0, u^0) = f(0, 0) = -\\alpha(0) + F_0 \\cos(0) = F_0 = 10^{-4}$.\n\n2.  Compute $k_2$:\n    The arguments are $t^0 + \\frac{1}{2}\\Delta t = 1800$ and $u^0 + \\frac{1}{2}\\Delta t k_1 = 0 + \\frac{3600}{2}(10^{-4}) = 0.18$.\n    $k_2 = f(1800, 0.18) = -\\alpha(0.18) + F_0 \\cos(\\omega \\cdot 1800) = -\\frac{0.18}{86400} + 10^{-4}\\cos(0.18) \\approx 9.6303354 \\times 10^{-5}$.\n\n3.  Compute $k_3$:\n    The arguments are $t^0 + \\Delta t = 3600$ and $u_k = u^0 + \\Delta t(-k_1 + 2k_2) = 0 + 3600(-10^{-4} + 2(9.6303354 \\times 10^{-5})) \\approx 0.33338415$.\n    $k_3 = f(3600, 0.33338415) = -\\alpha(0.33338415) + F_0 \\cos(\\omega \\cdot 3600) = -\\frac{0.33338415}{86400} + 10^{-4}\\cos(0.36) \\approx 8.9690330 \\times 10^{-5}$.\n\n4.  Compute $u^1$:\n    $u^1 = u^0 + \\frac{\\Delta t}{6}(k_1 + 4k_2 + k_3) = 0 + \\frac{3600}{6}(10^{-4} + 4(9.6303354 \\times 10^{-5}) + 8.9690330 \\times 10^{-5})$.\n    $u^1 \\approx 600(10^{-4} + 3.8521342 \\times 10^{-4} + 8.9690330 \\times 10^{-5}) = 600(5.7490375 \\times 10^{-4}) \\approx 0.34494225$.\n\n**Step 2: Compute $u^2$**\nWe advance from $t^1=3600$ to $t^2 = 2\\Delta t = 7200$. The initial condition is $(t^1, u^1) = (3600, 0.34494225)$. Let's denote the new stages as $k'_i$.\n\n1.  Compute $k'_1$:\n    $k'_1 = f(t^1, u^1) = f(3600, 0.34494225) = -\\alpha(0.34494225) + F_0 \\cos(\\omega \\cdot 3600) = -\\frac{0.34494225}{86400} + 10^{-4}\\cos(0.36) \\approx 8.9556555 \\times 10^{-5}$.\n\n2.  Compute $k'_2$:\n    The arguments are $t^1 + \\frac{1}{2}\\Delta t = 5400$ and $u^1 + \\frac{1}{2}\\Delta t k'_1 \\approx 0.34494225 + \\frac{3600}{2}(8.9556555 \\times 10^{-5}) \\approx 0.50614405$.\n    $k'_2 = f(5400, 0.50614405) = -\\alpha(0.50614405) + F_0 \\cos(\\omega \\cdot 5400) = -\\frac{0.50614405}{86400} + 10^{-4}\\cos(0.54) \\approx 7.9912733 \\times 10^{-5}$.\n\n3.  Compute $k'_3$:\n    The arguments are $t^1 + \\Delta t = 7200$ and $u_k = u^1 + \\Delta t(-k'_1 + 2k'_2) \\approx 0.34494225 + 3600(-8.9556555 \\times 10^{-5} + 2(7.9912733 \\times 10^{-5})) \\approx 0.59791032$.\n    $k'_3 = f(7200, 0.59791032) = -\\alpha(0.59791032) + F_0 \\cos(\\omega \\cdot 7200) = -\\frac{0.59791032}{86400} + 10^{-4}\\cos(0.72) \\approx 6.8266206 \\times 10^{-5}$.\n\n4.  Compute $u^2$:\n    $u^2 = u^1 + \\frac{\\Delta t}{6}(k'_1 + 4k'_2 + k'_3)$.\n    $u^2 \\approx 0.34494225 + \\frac{3600}{6}(8.9556555 \\times 10^{-5} + 4(7.9912733 \\times 10^{-5}) + 6.8266206 \\times 10^{-5})$.\n    $u^2 \\approx 0.34494225 + 600(8.9556555 \\times 10^{-5} + 3.1965093 \\times 10^{-4} + 6.8266206 \\times 10^{-5})$.\n    $u^2 \\approx 0.34494225 + 600(4.7747369 \\times 10^{-4}) \\approx 0.34494225 + 0.28648421$.\n    $u^2 \\approx 0.63142646$.\n\nRounding to four significant figures, we get $u^2 \\approx 0.6314$.",
            "answer": "$$\n\\boxed{0.6314}\n$$"
        },
        {
            "introduction": "Predictor-corrector methods offer a powerful blend of efficiency and stability, forming the basis of many advanced time-stepping algorithms. This practice delves into the construction and analysis of a classic predictor-corrector pair: the second-order Adams-Bashforth (AB2) predictor and the second-order Adams-Moulton (AM2) corrector. By deriving each component from the principles of numerical quadrature and then analyzing the linear stability of the combined scheme, you will gain a deep understanding of how these methods work and what determines their performance .",
            "id": "3798652",
            "problem": "Consider a semi-discrete ocean model time tendency written as an ordinary differential equation initial value problem $y^{\\prime}(t)=f(t,y(t))$ with a smooth right-hand side $f$. Starting from the integral form $y(t_{n+1})=y(t_{n})+\\int_{t_{n}}^{t_{n+1}} f(s,y(s))\\,\\mathrm{d}s$ and using only principles of numerical quadrature and polynomial interpolation of $f$ on past time levels, do the following:\n\n1) Derive the two-step Adams–Moulton corrector of order two (trapezoidal rule), expressed in one-step form as an implicit update for $y_{n+1}$ in terms of $f_{n+1}$ and $f_{n}$, where $f_{k}=f(t_{k},y_{k})$ and $t_{k}=t_{0}+k h$ with fixed step size $h0$.\n\n2) Derive the two-step Adams–Bashforth predictor of order two by approximating $f$ over $[t_{n-1},t_{n}]$ by a degree-one interpolant through $\\{(t_{n-1},f_{n-1}),(t_{n},f_{n})\\}$, and use it to form a predictor $y_{n+1}^{p}$ at $t_{n+1}$.\n\n3) Combine your results into a single predictor–evaluate–correct–evaluate (PECE) scheme, where the first evaluation computes $f_{n+1}^{p}=f(t_{n+1},y_{n+1}^{p})$ and the second evaluation computes $f_{n+1}=f(t_{n+1},y_{n+1})$. State, with justification based on Taylor expansions about $t_{n}$, the global order $p$ of accuracy of this PECE method.\n\n4) Analyze the linear stability of the PECE method by applying it to the Dahlquist test equation $y^{\\prime}=\\lambda y$ with $\\lambda\\in\\mathbb{C}$, and defining $z=h\\lambda$. Derive the two-step scalar recurrence that $y_{n}$ satisfies as a function of $z$, and then determine the largest negative real number $z^{\\star}0$ such that, for all real $z$ with $z\\in[z^{\\star},0]$, every root of the method’s characteristic polynomial has magnitude less than or equal to $1$. Your final reported answer should be the exact value of $z^{\\star}$ with no rounding required and no units.\n\nThe final answer must be a single real number.",
            "solution": "The problem asks for the derivation and analysis of a predictor-corrector numerical scheme for an ordinary differential equation of the form $y^{\\prime}(t) = f(t, y(t))$. We will address the four parts of the problem in sequence.\n\n1) Derivation of the two-step Adams-Moulton corrector (Trapezoidal Rule)\nWe begin with the integral form of the differential equation over the interval $[t_n, t_{n+1}]$:\n$$y(t_{n+1}) = y(t_n) + \\int_{t_n}^{t_{n+1}} f(s, y(s)) \\, \\mathrm{d}s$$\nThe trapezoidal rule for numerical integration approximates the integral of a function $g(s)$ over $[a, b]$ as $\\frac{b-a}{2}(g(a)+g(b))$. Applying this to our integral, with a step size $h = t_{n+1} - t_n$, we approximate the integrand $f(s, y(s))$ using its values at the endpoints $s=t_n$ and $s=t_{n+1}$. This gives:\n$$\\int_{t_n}^{t_{n+1}} f(s, y(s)) \\, \\mathrm{d}s \\approx \\frac{h}{2} \\left[ f(t_n, y(t_n)) + f(t_{n+1}, y(t_{n+1})) \\right]$$\nReplacing the exact solution $y(t_k)$ with its numerical approximation $y_k$, and defining $f_k = f(t_k, y_k)$, we obtain the numerical scheme:\n$$y_{n+1} = y_n + \\frac{h}{2} (f_n + f_{n+1})$$\nThis is the one-step implicit formula for the trapezoidal rule, also known as the two-step Adams-Moulton method of order two. The term \"two-step\" refers to the two points, $(t_n, f_n)$ and $(t_{n+1}, f_{n+1})$, used to construct the underlying degree-one interpolating polynomial for $f$.\n\n2) Derivation of the two-step Adams-Bashforth predictor\nTo derive the predictor, we again start from the integral form. For an explicit predictor, we must approximate the integral using only information from times $t_n$ and earlier. The problem specifies using a degree-one polynomial, $P(s)$, that interpolates $f$ at the points $(t_{n-1}, f_{n-1})$ and $(t_n, f_n)$. Using the Lagrange form for this polynomial:\n$$P(s) = f_{n-1} \\frac{s - t_n}{t_{n-1} - t_n} + f_n \\frac{s - t_{n-1}}{t_n - t_{n-1}}$$\nSince $t_k = t_0 + kh$, we have $t_n - t_{n-1} = h$. The polynomial becomes:\n$$P(s) = f_{n-1} \\frac{s - t_n}{-h} + f_n \\frac{s - t_{n-1}}{h} = \\frac{1}{h} \\left[ f_n(s - t_{n-1}) - f_{n-1}(s - t_n) \\right]$$\nWe now approximate the integral by integrating this polynomial from $s=t_n$ to $s=t_{n+1}$:\n$$\\int_{t_n}^{t_{n+1}} f(s, y(s)) \\, \\mathrm{d}s \\approx \\int_{t_n}^{t_{n+1}} P(s) \\, \\mathrm{d}s$$\nTo simplify the integration, let's use the substitution $u = s - t_n$, so $\\mathrm{d}u = \\mathrm{d}s$. The limits of integration become $u=0$ to $u=h$. Also, $s - t_{n-1} = (s - t_n) + (t_n - t_{n-1}) = u + h$.\n\\begin{align*} \\int_0^h \\frac{1}{h} \\left[ f_n(u+h) - f_{n-1}(u) \\right] \\, \\mathrm{d}u = \\frac{1}{h} \\left[ f_n\\left(\\frac{u^2}{2} + hu\\right) - f_{n-1}\\left(\\frac{u^2}{2}\\right) \\right]_0^h \\\\ = \\frac{1}{h} \\left[ f_n\\left(\\frac{h^2}{2} + h^2\\right) - f_{n-1}\\left(\\frac{h^2}{2}\\right) \\right] \\\\ = \\frac{1}{h} \\left[ \\frac{3}{2}h^2 f_n - \\frac{1}{2}h^2 f_{n-1} \\right] \\\\ = h \\left( \\frac{3}{2} f_n - \\frac{1}{2} f_{n-1} \\right)\\end{align*}\nThe predictor for $y_{n+1}$, denoted $y_{n+1}^p$, is therefore:\n$$y_{n+1}^p = y_n + \\frac{h}{2} (3 f_n - f_{n-1})$$\nThis is the formula for the two-step Adams-Bashforth method of order two.\n\n3) PECE scheme and order of accuracy\nThe Predictor-Evaluate-Correct-Evaluate (PECE) scheme combines the previous results as follows for each time step:\n(P) Predict: Calculate a first estimate $y_{n+1}^p$ using the Adams-Bashforth predictor.\n$$y_{n+1}^p = y_n + \\frac{h}{2} (3 f_n - f_{n-1})$$\n(E) Evaluate: Compute the derivative at the predicted solution.\n$$f_{n+1}^p = f(t_{n+1}, y_{n+1}^p)$$\n(C) Correct: Use this derivative estimate in the Adams-Moulton corrector to obtain the final value for the step, $y_{n+1}$.\n$$y_{n+1} = y_n + \\frac{h}{2} (f_n + f_{n+1}^p)$$\n(E) Evaluate: Compute the derivative at the corrected solution, to be used in the next time step.\n$$f_{n+1} = f(t_{n+1}, y_{n+1})$$\n\nTo determine the order of accuracy, we analyze the local truncation error (LTE), which is the error made in a single step assuming the solution is exact at the start of the step. The LTE for the AB2 predictor is $\\tau_p = y(t_{n+1}) - y_{n+1}^p = \\frac{5}{12}h^3 y'''(t_n) + O(h^4)$. The LTE for the AM2 corrector is $\\tau_c = y(t_{n+1}) - (y_n + \\frac{h}{2}(f_n + f(t_{n+1}, y(t_{n+1})))) = -\\frac{1}{12}h^3 y'''(t_n) + O(h^4)$. Both underlying methods are order $2$.\nFor the PECE scheme, starting with exact values $y_n = y(t_n)$ and $f_{n-1} = f(t_{n-1}, y(t_{n-1}))$, the predicted value has an error:\n$$y_{n+1}^p = y(t_{n+1}) - \\frac{5}{12}h^3 y'''(t_n) + O(h^4)$$\nThe argument of $f$ in the corrector step is $f(t_{n+1}, y_{n+1}^p)$. By Taylor's theorem:\n$$f_{n+1}^p = f(t_{n+1}, y(t_{n+1}) - \\frac{5}{12}h^3 y'''(t_n) + O(h^4)) = f(t_{n+1}, y(t_{n+1})) - \\frac{\\partial f}{\\partial y} \\frac{5}{12}h^3 y'''(t_n) + O(h^4)$$\nThe corrected value is $y_{n+1} = y_n + \\frac{h}{2}(f_n + f_{n+1}^p)$. Substituting the expansion for $f_{n+1}^p$:\n$$y_{n+1} = \\left(y_n + \\frac{h}{2}(f_n + f(t_{n+1}, y(t_{n+1})))\\right) - \\frac{h}{2}\\left(\\frac{5}{12}h^3 \\frac{\\partial f}{\\partial y} y'''(t_n)\\right) + O(h^5)$$\nThe term in parentheses is the result of the implicit AM2 method applied to exact data. Its value is $y(t_{n+1}) - \\tau_c = y(t_{n+1}) + \\frac{1}{12}h^3 y'''(t_n) + O(h^4)$.\nThus,\n$$y_{n+1} = y(t_{n+1}) + \\frac{1}{12}h^3 y'''(t_n) + O(h^4)$$\nThe term involving $\\frac{\\partial f}{\\partial y}$ is absorbed into the $O(h^4)$ term. The LTE of the full PECE step is:\n$$\\tau_{\\text{PECE}} = y(t_{n+1}) - y_{n+1} = -\\frac{1}{12}h^3 y'''(t_n) + O(h^4)$$\nSince the LTE is of order $O(h^3)$, the global error, which accumulates over approximately $T/h$ steps, is of order $O(h^2)$. Therefore, the global order of accuracy is $p=2$.\n\n4) Linear stability analysis\nWe apply the PECE scheme to the Dahlquist test equation $y' = \\lambda y$, where $\\lambda \\in \\mathbb{C}$. For this equation, $f_k = f(t_k, y_k) = \\lambda y_k$. Let $z = h\\lambda$.\nThe PECE steps become:\n(P) $y_{n+1}^p = y_n + \\frac{h}{2}(3\\lambda y_n - \\lambda y_{n-1}) = y_n + \\frac{z}{2}(3y_n - y_{n-1}) = (1+\\frac{3z}{2})y_n - \\frac{z}{2}y_{n-1}$.\n(E) $f_{n+1}^p = \\lambda y_{n+1}^p$.\n(C) $y_{n+1} = y_n + \\frac{h}{2}(f_n + f_{n+1}^p) = y_n + \\frac{h}{2}(\\lambda y_n + \\lambda y_{n+1}^p) = (1+\\frac{z}{2})y_n + \\frac{z}{2}y_{n+1}^p$.\n\nNow, we substitute the expression for $y_{n+1}^p$ into the corrector equation to get a single recurrence relation for the sequence $\\{y_k\\}$:\n$$y_{n+1} = \\left(1+\\frac{z}{2}\\right)y_n + \\frac{z}{2}\\left[ \\left(1+\\frac{3z}{2}\\right)y_n - \\frac{z}{2}y_{n-1} \\right]$$\n$$y_{n+1} = \\left(1+\\frac{z}{2} + \\frac{z}{2} + \\frac{3z^2}{4}\\right)y_n - \\frac{z^2}{4}y_{n-1}$$\n$$y_{n+1} = \\left(1+z+\\frac{3z^2}{4}\\right)y_n - \\frac{z^2}{4}y_{n-1}$$\nThis gives the two-step scalar recurrence:\n$$y_{n+1} - \\left(1+z+\\frac{3z^2}{4}\\right)y_n + \\frac{z^2}{4}y_{n-1} = 0$$\nTo find the stability region, we examine the roots of the characteristic polynomial, obtained by substituting $y_n = \\xi^n$:\n$$\\xi^2 - \\left(1+z+\\frac{3z^2}{4}\\right)\\xi + \\frac{z^2}{4} = 0$$\nFor stability, all roots $\\xi$ must satisfy $|\\xi|\\le 1$. We use the Jury stability criterion for a second-degree polynomial $P(\\xi) = \\xi^2+a_1\\xi+a_0=0$. The conditions for all roots to be inside or on the unit circle ($|\\xi| \\le 1$) are:\n1) $|a_0| \\le 1$\n2) $|a_1| \\le 1+a_0$\n\nHere, $a_0 = \\frac{z^2}{4}$ and $a_1 = -(1+z+\\frac{3z^2}{4})$. We analyze these for real $z  0$.\n\nCondition 1: $|a_0| \\le 1$ gives $|\\frac{z^2}{4}| \\le 1$, which implies $z^2 \\le 4$, or $|z| \\le 2$. For negative $z$, this is $-2 \\le z \\le 0$.\n\nCondition 2: $|a_1| \\le 1+a_0$ is equivalent to $- (1+a_0) \\le a_1 \\le 1+a_0$.\nFirst inequality: $a_1 \\le 1+a_0$\n$$-(1+z+\\frac{3z^2}{4}) \\le 1+\\frac{z^2}{4} \\implies 0 \\le 2+z+z^2$$\nThe quadratic $z^2+z+2$ has discriminant $\\Delta = 1^2 - 4(1)(2) = -7  0$. Since the leading coefficient is positive, the quadratic is always positive. This inequality holds for all real $z$.\n\nSecond inequality: $a_1 \\ge -(1+a_0)$\n$$-(1+z+\\frac{3z^2}{4}) \\ge -(1+\\frac{z^2}{4}) \\implies 1+z+\\frac{3z^2}{4} \\le 1+\\frac{z^2}{4}$$\n$$z + \\frac{2z^2}{4} \\le 0 \\implies z + \\frac{z^2}{2} \\le 0 \\implies z(1+\\frac{z}{2}) \\le 0$$\nThe roots of $z(1+z/2)=0$ are $z=0$ and $z=-2$. The parabola $z(1+z/2)$ opens upwards, so it is non-positive between its roots. This inequality holds for $z \\in [-2, 0]$.\n\nCombining all conditions for real $z$, the stability region is the intersection of $[-2, 0]$, $\\mathbb{R}$, and $[-2, 0]$, which is $[-2, 0]$.\nThe problem asks for the largest negative real number $z^{\\star}$ such that stability holds for all $z \\in [z^{\\star}, 0]$. This corresponds to the left endpoint of the derived stability interval. Thus, $z^{\\star} = -2$.",
            "answer": "$$\\boxed{-2}$$"
        }
    ]
}