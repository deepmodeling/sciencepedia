{
    "hands_on_practices": [
        {
            "introduction": "While it may seem intuitive that a smaller grid spacing $h$ always leads to a more accurate derivative, this is not the case in practice. This exercise explores the fundamental trade-off between truncation error, which decreases as $h$ shrinks, and floating-point roundoff error, which grows. By analyzing these competing error sources using Taylor series, you will derive the optimal step size $h^*$ that minimizes the total error, providing a crucial insight into the practical limits of numerical differentiation .",
            "id": "3813087",
            "problem": "An oceanographic transect through a mid-latitude region exhibits variability dominated by mesoscale eddies. Along a straight zonal path, idealize the sea surface height anomaly as $f(x) = \\sin(k x)$, where $k$ is the wavenumber associated with the eddy field. Let the dominant eddy wavelength be $\\lambda = 100\\,\\mathrm{km}$, so $k = 2\\pi/\\lambda$. You wish to compute the horizontal derivative $\\partial f/\\partial x$ at the point $x$ where $k x = \\pi/4$ using a symmetric two-point central difference based on samples at $x \\pm h$. Assume arithmetic follows the Institute of Electrical and Electronics Engineers (IEEE) 754 double precision model with unit roundoff $u = 2^{-53}$, and assume angles are measured in radians.\n\nStarting from Taylor series and a standard floating-point rounding model, derive the leading-order total error as a function of the step size $h$ by balancing truncation error and rounding error for the central difference derivative, and use this to obtain the optimal step size $h^{*}$. Then evaluate $h^{*}$ numerically for the given $k$ and the specified evaluation point. Round your final numerical answer to three significant figures and express the optimal step size in meters.\n\nFinally, based on your derivation, briefly assess whether practical horizontal grid spacings of $1\\,\\mathrm{km}$, $5\\,\\mathrm{km}$, and $10\\,\\mathrm{km}$ are close to the optimal $h^{*}$ for differentiating $f(x)$ via central differencing in this setting, and identify which error source (truncation or rounding) dominates at those spacings. Your assessment should be qualitative; the single final answer must be your computed $h^{*}$.",
            "solution": "The problem statement is evaluated for validity before proceeding to a solution.\n\n### Step 1: Extract Givens\n-   Sea surface height anomaly function: $f(x) = \\sin(k x)$\n-   Wavenumber definition: $k = \\frac{2\\pi}{\\lambda}$\n-   Dominant eddy wavelength: $\\lambda = 100\\,\\mathrm{km}$\n-   Derivative to be computed: $\\frac{\\partial f}{\\partial x}$\n-   Evaluation point: A point $x$ such that $k x = \\frac{\\pi}{4}$\n-   Numerical approximation method: Symmetric two-point central difference, $\\frac{f(x+h) - f(x-h)}{2h}$\n-   Step size: $h$\n-   Computational arithmetic model: IEEE 754 double precision\n-   Unit roundoff: $u = 2^{-53}$\n-   Angle units: Radians\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed against the validation criteria.\n-   **Scientifically Grounded:** The problem is firmly grounded in the principles of numerical analysis and its application to physical oceanography. The use of a sinusoidal function to model mesoscale eddy fields is a standard simplification, and the analysis of truncation and rounding errors in finite difference schemes is a fundamental topic in scientific computing. The specified wavelength of $100\\,\\mathrm{km}$ is physically realistic for mid-latitude mesoscale eddies.\n-   **Well-Posed:** The problem is well-posed. It requests the derivation of an optimal step size for a clearly defined function and numerical method, which is a standard problem with a unique, expected solution. All necessary parameters ($f(x)$, $k$, $\\lambda$, $u$, the evaluation point) are provided.\n-   **Objective:** The problem statement is objective, using precise mathematical and technical language. It is free of subjective or opinion-based claims.\n-   **Completeness and Consistency:** The problem is self-contained and internally consistent. It provides all the necessary information to derive the optimal step size $h^*$ and evaluate it numerically.\n-   **Realism:** The parameters and context are realistic. The use of double precision arithmetic, the physical scale of the eddies, and the consideration of practical grid spacings are all authentic to the field of computational oceanography.\n\n### Step 3: Verdict and Action\nThe problem is valid. It is a standard and well-defined problem in numerical analysis applied to a geophysical context. A full solution will be derived.\n\n### Derivation of the Optimal Step Size\n\nThe task is to find the optimal step size $h^*$ that minimizes the total error in computing the derivative of $f(x)$ using a central difference formula. The total error is a combination of truncation error and rounding error.\n\n**1. Truncation Error**\n\nThe central difference approximation for the first derivative, $f'(x)$, is given by:\n$$\nD_h f(x) = \\frac{f(x+h) - f(x-h)}{2h}\n$$\nTo analyze the truncation error, we use Taylor series expansions of $f(x+h)$ and $f(x-h)$ around the point $x$:\n$$\nf(x+h) = f(x) + h f'(x) + \\frac{h^2}{2!} f''(x) + \\frac{h^3}{3!} f'''(x) + \\frac{h^4}{4!} f^{(4)}(x) + O(h^5)\n$$\n$$\nf(x-h) = f(x) - h f'(x) + \\frac{h^2}{2!} f''(x) - \\frac{h^3}{3!} f'''(x) + \\frac{h^4}{4!} f^{(4)}(x) - O(h^5)\n$$\nSubtracting the second expansion from the first yields:\n$$\nf(x+h) - f(x-h) = 2h f'(x) + \\frac{2h^3}{3!} f'''(x) + O(h^5)\n$$\n$$\nf(x+h) - f(x-h) = 2h f'(x) + \\frac{h^3}{3} f'''(x) + O(h^5)\n$$\nRearranging to solve for $f'(x)$, we see how the central difference formula relates to the true derivative:\n$$\nf'(x) = \\frac{f(x+h) - f(x-h)}{2h} - \\frac{h^2}{6} f'''(x) - O(h^4)\n$$\nThe truncation error, $E_T$, is the difference between the true derivative and its finite difference approximation. The leading-order term of this error is:\n$$\nE_T(h) = |D_h f(x) - f'(x)| \\approx \\frac{h^2}{6} |f'''(x)|\n$$\n\n**2. Rounding Error**\n\nIn floating-point arithmetic, the evaluation of the function $f(z)$ is not exact. We denote the floating-point representation as $\\text{fl}(\\cdot)$. According to the standard model of floating-point arithmetic, for some small $\\epsilon$ with $|\\epsilon| \\le u$ (the unit roundoff), we have:\n$$\n\\text{fl}(f(z)) = f(z)(1 + \\epsilon)\n$$\nThe computed central difference, $\\hat{D}_h f(x)$, uses these inexact function values:\n$$\n\\hat{D}_h f(x) = \\frac{\\text{fl}(f(x+h)) - \\text{fl}(f(x-h))}{2h} = \\frac{f(x+h)(1+\\epsilon_1) - f(x-h)(1+\\epsilon_2)}{2h}\n$$\nwhere $|\\epsilon_1|, |\\epsilon_2| \\le u$. The primary source of rounding error in this expression is the subtraction of two nearly equal numbers, $f(x+h)$ and $f(x-h)$, when $h$ is small. The absolute error in the numerator is bounded by:\n$$\n|\\left(f(x+h)(1+\\epsilon_1) - f(x-h)(1+\\epsilon_2)\\right) - \\left(f(x+h) - f(x-h)\\right)| = |f(x+h)\\epsilon_1 - f(x-h)\\epsilon_2|\n$$\nUsing the triangle inequality, this is bounded by $|f(x+h)||\\epsilon_1| + |f(x-h)||\\epsilon_2| \\le u(|f(x+h)|+|f(x-h)|)$. For a small step size $h$, $f(x \\pm h) \\approx f(x)$, so this error is approximately $2u|f(x)|$. The rounding error in the final computation of the derivative, $E_R(h)$, is this numerator error divided by the denominator $2h$:\n$$\nE_R(h) \\approx \\frac{2u|f(x)|}{2h} = \\frac{u|f(x)|}{h}\n$$\n\n**3. Total Error and Optimal Step Size**\n\nThe total error, $E(h)$, is the sum of the magnitudes of the truncation and rounding errors:\n$$\nE(h) \\approx E_T(h) + E_R(h) = \\frac{h^2}{6} |f'''(x)| + \\frac{u|f(x)|}{h}\n$$\nTo find the optimal step size $h^*$ that minimizes this total error, we differentiate $E(h)$ with respect to $h$ and set the result to zero:\n$$\n\\frac{dE}{dh} = \\frac{2h}{6} |f'''(x)| - \\frac{u|f(x)|}{h^2} = 0\n$$\n$$\n\\frac{h}{3} |f'''(x)| = \\frac{u|f(x)|}{h^2}\n$$\nSolving for $h$, which we denote $h^*$:\n$$\nh^{*3} = \\frac{3u|f(x)|}{|f'''(x)|} \\implies h^* = \\left( \\frac{3u|f(x)|}{|f'''(x)|} \\right)^{1/3}\n$$\n\n**4. Numerical Evaluation for the Specific Problem**\n\nWe are given the function $f(x) = \\sin(kx)$. We need its third derivative:\n- $f(x) = \\sin(kx)$\n- $f'(x) = k \\cos(kx)$\n- $f''(x) = -k^2 \\sin(kx)$\n- $f'''(x) = -k^3 \\cos(kx)$\n\nThe derivative is evaluated at a point $x$ where $kx = \\frac{\\pi}{4}$. At this point:\n$$\n|f(x)| = |\\sin(kx)| = \\left|\\sin\\left(\\frac{\\pi}{4}\\right)\\right| = \\frac{\\sqrt{2}}{2}\n$$\n$$\n|f'''(x)| = |-k^3 \\cos(kx)| = k^3 \\left|\\cos\\left(\\frac{\\pi}{4}\\right)\\right| = k^3 \\frac{\\sqrt{2}}{2}\n$$\nSubstituting these into the expression for $h^*$:\n$$\nh^* = \\left( \\frac{3u \\left(\\frac{\\sqrt{2}}{2}\\right)}{k^3 \\left(\\frac{\\sqrt{2}}{2}\\right)} \\right)^{1/3} = \\left( \\frac{3u}{k^3} \\right)^{1/3} = \\frac{(3u)^{1/3}}{k}\n$$\nNow, we substitute the given numerical values:\n- Unit roundoff for double precision: $u = 2^{-53}$\n- Wavelength: $\\lambda = 100\\,\\mathrm{km} = 100 \\times 10^3\\,\\mathrm{m} = 10^5\\,\\mathrm{m}$\n- Wavenumber: $k = \\frac{2\\pi}{\\lambda} = \\frac{2\\pi}{10^5}\\,\\mathrm{m}^{-1}$\n\nPlugging these into the formula for $h^*$:\n$$\nh^* = \\frac{(3 \\times 2^{-53})^{1/3}}{\\frac{2\\pi}{10^5}} = \\frac{10^5}{2\\pi} (3 \\times 2^{-53})^{1/3}\n$$\nNow, we calculate the numerical value:\n$$\nh^* = \\frac{10^5}{2\\pi} \\cdot 3^{1/3} \\cdot 2^{-53/3} \\approx \\frac{100000}{6.283185} \\cdot (1.44225) \\cdot (4.78216 \\times 10^{-6})\n$$\n$$\nh^* \\approx (15915.49) \\cdot (6.8988 \\times 10^{-6}) \\approx 0.110\\,\\mathrm{m}\n$$\nRounding to three significant figures, the optimal step size is $0.110$ meters.\n\n**5. Assessment of Practical Grid Spacings**\n\nThe derived optimal step size is $h^* \\approx 0.110\\,\\mathrm{m}$.\nThe practical grid spacings are given as $h_1 = 1\\,\\mathrm{km} = 1000\\,\\mathrm{m}$, $h_2 = 5\\,\\mathrm{km} = 5000\\,\\mathrm{m}$, and $h_3 = 10\\,\\mathrm{km} = 10000\\,\\mathrm{m}$.\n\nAll of these practical grid spacings are vastly larger than the optimal step size: $h_i \\gg h^*$.\n\nThe total error is $E(h) \\approx \\frac{h^2}{6} |f'''(x)| + \\frac{u|f(x)|}{h}$. The first term is the truncation error ($E_T \\propto h^2$) and the second is the rounding error ($E_R \\propto h^{-1}$). The optimal step size $h^*$ is the point where these two error contributions are of comparable magnitude.\n\n- For $h < h^*$, the rounding error term ($h^{-1}$) dominates.\n- For $h > h^*$, the truncation error term ($h^2$) dominates.\n\nSince the practical grid spacings ($1\\,\\mathrm{km}$ to $10\\,\\mathrm{km}$) are all much greater than $h^* \\approx 0.110\\,\\mathrm{m}$, the error in calculating the derivative at these spacings is overwhelmingly dominated by **truncation error**. The rounding error is negligible by comparison. This indicates that at the typical scales of ocean models, the limitation on the accuracy of finite difference derivatives is the discretization of the Taylor series, not the precision of the floating-point arithmetic.",
            "answer": "$$\\boxed{1.10 \\times 10^{-1}}$$"
        },
        {
            "introduction": "In the design of computational models, a key task is to select a grid that is both efficient and sufficiently accurate for the problem at hand. This practice shifts our perspective from analyzing existing errors to proactively designing a grid that meets a predefined error tolerance $\\varepsilon$. You will use the Lagrange form of the Taylor series remainder to derive rigorous error bounds for common finite difference schemes, translating these theoretical bounds into practical grid spacing requirements .",
            "id": "3813084",
            "problem": "Consider a one-dimensional horizontal transect in computational oceanography where a smooth scalar field $f(x)$ represents a seawater property along distance $x$ (for example, temperature or salinity measured along a ship track). You aim to approximate spatial derivatives of $f(x)$ on a uniform grid with spacing $h$ and to guarantee that the absolute derivative approximation error is bounded by a user-chosen tolerance $\\varepsilon$. You are given a uniform bound $M_k$ on the $k$-th derivative, meaning $|f^{(k)}(x)| \\le M_k$ for all $x$ in the interval of interest. You must use the Taylor series expansion with the Lagrange form of the remainder as the fundamental base for your derivations.\n\nYour tasks are:\n- Starting only from the Taylor series definition with the Lagrange remainder and standard smoothness assumptions on $f(x)$, derive a rigorous bound on the pointwise truncation error for each of the following finite difference derivative approximations:\n  1. A forward difference approximation for the first derivative $f'(x)$.\n  2. A centered difference approximation for the first derivative $f'(x)$.\n  3. A centered difference approximation for the second derivative $f''(x)$.\n- From each bound, derive a sufficient grid refinement criterion, expressed as an upper limit on the grid spacing $h$, to ensure that the absolute error is everywhere less than or equal to the tolerance $\\varepsilon$ on the interior of the domain. Express the resulting constraints in terms of $M_k$ and $\\varepsilon$, with clear identification of which $k$ applies for each scheme.\n- Translate the spacing constraint into a minimum number of grid points $N_{\\text{points}}$ required to cover a finite domain of length $L$ with a uniform grid. Use $N_{\\text{segments}} = \\lceil L / h \\rceil$ and $N_{\\text{points}} = N_{\\text{segments}} + 1$, and enforce the minimum number of points needed by each scheme to be valid on interior points:\n  - For the forward difference of $f'(x)$, require at least $2$ grid points.\n  - For the centered difference of $f'(x)$, require at least $3$ grid points.\n  - For the centered difference of $f''(x)$, require at least $3$ grid points.\n- Specify and correctly handle the special case $M_k = 0$. Explain its meaning and specify what $N_{\\text{points}}$ should be chosen in that case for each scheme.\n\nAll quantities are purely mathematical and should be treated symbolically, except for the domain length $L$ which is a physical length. The domain length $L$ must be interpreted in meters and is provided numerically in meters ($\\mathrm{m}$). The tolerance $\\varepsilon$ is a bound on the absolute error in the derivative approximation and is specified as a pure number in the appropriate units implied by the derivative (for example, $\\mathrm{(property)}/\\mathrm{m}$ for a first spatial derivative, or $\\mathrm{(property)}/\\mathrm{m}^2$ for a second spatial derivative). Your program must only output integers (the required number of grid points), which are dimensionless counts, so no unit conversion is required in the final outputs.\n\nImplement your derivation algorithm in a complete, runnable program. Use the following test suite of cases, each given as a tuple describing the scheme, the domain length $L$, the error tolerance $\\varepsilon$, and the derivative bound $M_k$:\n\n- Case A (happy path): scheme is centered first derivative, $L = 10^3$ $\\mathrm{m}$, $\\varepsilon = 10^{-5}$, $M_3 = 10^{-8}$.\n- Case B (large refinement demand): scheme is forward first derivative, $L = 5 \\times 10^2$ $\\mathrm{m}$, $\\varepsilon = 10^{-6}$, $M_2 = 10^{-3}$.\n- Case C (second derivative centered): scheme is centered second derivative, $L = 2 \\times 10^3$ $\\mathrm{m}$, $\\varepsilon = 10^{-4}$, $M_4 = 10^{-6}$.\n- Case D (degenerate bound): scheme is centered first derivative, $L = 3 \\times 10^2$ $\\mathrm{m}$, $\\varepsilon = 10^{-5}$, $M_3 = 0$.\n\nYour program should compute, for each case, the minimum integer $N_{\\text{points}}$ that ensures the corresponding error bound is less than or equal to $\\varepsilon$ across the domain. When $M_k = 0$, choose the minimum number of points required by the scheme. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[n_A,n_B,n_C,n_D]$), where each entry is the computed $N_{\\text{points}}$ for the corresponding case in the order A, B, C, D. All input values should be treated as positive real numbers, with the exception that $M_k$ may be zero.",
            "solution": "The objective is to derive the minimum number of grid points $N_{\\text{points}}$ required to discretize a one-dimensional domain of length $L$ such that the truncation error of a finite difference approximation is bounded by a given tolerance $\\varepsilon$. The derivation will be founded upon the Taylor series expansion with the Lagrange form of the remainder. We are given a bound $M_k$ on the $k$-th derivative of the function $f(x)$, i.e., $|f^{(k)}(x)| \\le M_k$.\n\nThe fundamental tool is Taylor's theorem. For a sufficiently smooth function $f(x)$, its expansion around a point $x_0$ is given by:\n$$f(x) = \\sum_{n=0}^{p} \\frac{f^{(n)}(x_0)}{n!}(x-x_0)^n + R_{p+1}(x)$$\nThe Lagrange form of the remainder term $R_{p+1}(x)$ is:\n$$R_{p+1}(x) = \\frac{f^{(p+1)}(\\xi)}{(p+1)!}(x-x_0)^{p+1}$$\nfor some $\\xi$ between $x_0$ and $x$. We will use this theorem to analyze the truncation error of three common finite difference schemes.\n\n**1. Forward Difference Approximation for the First Derivative $f'(x)$**\n\nThe forward difference formula approximates the first derivative $f'(x)$ using values at $x$ and $x+h$:\n$$f'(x) \\approx \\frac{f(x+h) - f(x)}{h}$$\nTo find the truncation error, we expand $f(x+h)$ around $x$ using Taylor's theorem up to the term with the second derivative:\n$$f(x+h) = f(x) + f'(x)h + \\frac{f''(\\xi)}{2!}h^2$$\nfor some $\\xi \\in (x, x+h)$. Rearranging this equation to solve for $f'(x)$ yields:\n$$f'(x) = \\frac{f(x+h) - f(x)}{h} - \\frac{f''(\\xi)}{2}h$$\nThe truncation error $E_{\\text{FD}}$ is the difference between the true derivative and its approximation:\n$$E_{\\text{FD}} = f'(x) - \\left( \\frac{f(x+h) - f(x)}{h} \\right) = - \\frac{f''(\\xi)}{2}h$$\nThe absolute error is therefore bounded using the provided constant $M_2$:\n$$|E_{\\text{FD}}| = \\left| - \\frac{f''(\\xi)}{2}h \\right| = \\frac{|f''(\\xi)|}{2}h \\le \\frac{M_2}{2}h$$\nTo ensure this error does not exceed the tolerance $\\varepsilon$, we impose the condition:\n$$\\frac{M_2}{2}h \\le \\varepsilon$$\nThis yields the constraint on the grid spacing $h$ for $M_2 > 0$:\n$$h \\le \\frac{2\\varepsilon}{M_2}$$\n\n**2. Centered Difference Approximation for the First Derivative $f'(x)$**\n\nThe centered difference formula for $f'(x)$ uses values at $x-h$ and $x+h$:\n$$f'(x) \\approx \\frac{f(x+h) - f(x-h)}{2h}$$\nTo analyze this scheme's error, we expand $f(x+h)$ and $f(x-h)$ around $x$ up to the third derivative term:\n$$f(x+h) = f(x) + f'(x)h + \\frac{f''(x)}{2}h^2 + \\frac{f'''(\\xi_1)}{6}h^3, \\quad \\text{for } \\xi_1 \\in (x, x+h)$$\n$$f(x-h) = f(x) - f'(x)h + \\frac{f''(x)}{2}h^2 - \\frac{f'''(\\xi_2)}{6}h^3, \\quad \\text{for } \\xi_2 \\in (x-h, x)$$\nSubtracting the second expansion from the first cancels the even-powered terms in $h$:\n$$f(x+h) - f(x-h) = 2f'(x)h + \\frac{h^3}{6}(f'''(\\xi_1) + f'''(\\xi_2))$$\nSolving for $f'(x)$:\n$$f'(x) = \\frac{f(x+h) - f(x-h)}{2h} - \\frac{h^2}{12}(f'''(\\xi_1) + f'''(\\xi_2))$$\nIf $f'''(x)$ is continuous, the Intermediate Value Theorem guarantees there exists a point $\\xi \\in (x-h, x+h)$ such that $\\frac{f'''(\\xi_1) + f'''(\\xi_2)}{2} = f'''(\\xi)$. The truncation error $E_{\\text{CD1}}$ becomes:\n$$E_{\\text{CD1}} = -\\frac{f'''(\\xi)}{6}h^2$$\nThe absolute error is bounded using $M_3$:\n$$|E_{\\text{CD1}}| = \\frac{|f'''(\\xi)|}{6}h^2 \\le \\frac{M_3}{6}h^2$$\nWe require $|E_{\\text{CD1}}| \\le \\varepsilon$, which leads to the constraint for $M_3 > 0$:\n$$\\frac{M_3}{6}h^2 \\le \\varepsilon \\implies h \\le \\sqrt{\\frac{6\\varepsilon}{M_3}}$$\n\n**3. Centered Difference Approximation for the Second Derivative $f''(x)$**\n\nThe centered difference approximation for $f''(x)$ is:\n$$f''(x) \\approx \\frac{f(x+h) - 2f(x) + f(x-h)}{h^2}$$\nWe use Taylor expansions to the fourth derivative terms:\n$$f(x+h) = f(x) + f'(x)h + \\frac{f''(x)}{2}h^2 + \\frac{f'''(x)}{6}h^3 + \\frac{f^{(4)}(\\xi_1)}{24}h^4$$\n$$f(x-h) = f(x) - f'(x)h + \\frac{f''(x)}{2}h^2 - \\frac{f'''(x)}{6}h^3 + \\frac{f^{(4)}(\\xi_2)}{24}h^4$$\nAdding these two expansions cancels the odd-powered terms in $h$:\n$$f(x+h) + f(x-h) = 2f(x) + f''(x)h^2 + \\frac{h^4}{24}(f^{(4)}(\\xi_1) + f^{(4)}(\\xi_2))$$\nSolving for $f''(x)$:\n$$f''(x) = \\frac{f(x+h) - 2f(x) + f(x-h)}{h^2} - \\frac{h^2}{24}(f^{(4)}(\\xi_1) + f^{(4)}(\\xi_2))$$\nUsing the Intermediate Value Theorem again for a continuous $f^{(4)}(x)$, there exists a $\\xi \\in (x-h, x+h)$ such that the truncation error $E_{\\text{CD2}}$ is:\n$$E_{\\text{CD2}} = -\\frac{f^{(4)}(\\xi)}{12}h^2$$\nThe absolute error is bounded using $M_4$:\n$$|E_{\\text{CD2}}| = \\frac{|f^{(4)}(\\xi)|}{12}h^2 \\le \\frac{M_4}{12}h^2$$\nWe require $|E_{\\text{CD2}}| \\le \\varepsilon$, which gives the constraint for $M_4 > 0$:\n$$\\frac{M_4}{12}h^2 \\le \\varepsilon \\implies h \\le \\sqrt{\\frac{12\\varepsilon}{M_4}}$$\n\n**The Special Case $M_k = 0$**\n\nIf the relevant derivative bound $M_k$ is zero, then $|f^{(k)}(x)| \\le 0$, which implies $f^{(k)}(x) = 0$ for all $x$. This means $f(x)$ is a polynomial of degree at most $k-1$.\n-   For the forward difference ($k=2$), $M_2=0$ implies $f''(x)=0$, so $f(x)$ is linear. The formula is exact.\n-   For the centered first derivative ($k=3$), $M_3=0$ implies $f'''(x)=0$, so $f(x)$ is quadratic. The formula is exact.\n-   For the centered second derivative ($k=4$), $M_4=0$ implies $f^{(4)}(x)=0$, so $f(x)$ is cubic. The formula is exact.\nIn all these cases, the truncation error is identically zero for any grid spacing $h > 0$. The constraint on $h$ is therefore trivially satisfied. To obtain a definite number of points, we select the minimum number of grid points required to define the stencil for each scheme. The problem states these minimums: $2$ for forward difference, and $3$ for centered difference schemes.\n\n**Calculating the Number of Grid Points $N_{\\text{points}}$**\n\nTo ensure the error condition is met, the grid spacing $h$ must be less than or equal to a maximum value, $h_{\\max}$, which we derived for each scheme. To minimize the number of grid points, we must choose the largest possible spacing, so we select $h = h_{\\max}$.\nA domain of length $L$ must be covered by an integer number of segments, $N_{\\text{segments}}$. For a chosen spacing $h$, the number of segments must be at least $L/h$. Since $N_{\\text{segments}}$ must be an integer, we have $N_{\\text{segments}} = \\lceil L/h \\rceil$. A grid with $N_{\\text{segments}}$ segments has $N_{\\text{points}} = N_{\\text{segments}} + 1$ points.\nSubstituting $h = h_{\\max}$, the required number of points is:\n$$N_{\\text{points\\_calc}} = \\left\\lceil \\frac{L}{h_{\\max}} \\right\\rceil + 1$$\nThis calculated value must be at least the minimum number of points required for the scheme itself to be valid. Therefore, the final number of points is:\n$$N_{\\text{points}} = \\max(\\text{min\\_points\\_for\\_scheme}, N_{\\text{points\\_calc}})$$\nIf $M_k=0$, $h_{\\max} \\to \\infty$, causing $N_{\\text{points\\_calc}}$ to be $1$. The $\\max$ function then correctly selects the required minimum number of points for the scheme.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the minimum number of grid points for several finite difference\n    approximation scenarios based on Taylor series error bounds.\n    \"\"\"\n    \n    # Each tuple contains: (scheme_name, L, epsilon, M_k)\n    # L: domain length in meters\n    # epsilon: absolute error tolerance\n    # M_k: bound on the k-th derivative\n    test_cases = [\n        ('centered_first', 1e3, 1e-5, 1e-8),      # Case A\n        ('forward_first', 5e2, 1e-6, 1e-3),       # Case B\n        ('centered_second', 2e3, 1e-4, 1e-6),     # Case C\n        ('centered_first', 3e2, 1e-5, 0),          # Case D\n    ]\n\n    results = []\n    \n    # Scheme parameters: (minimum points, relevant derivative order k)\n    scheme_params = {\n        'forward_first': {'min_points': 2},\n        'centered_first': {'min_points': 3},\n        'centered_second': {'min_points': 3},\n    }\n\n    for scheme, L, eps, Mk in test_cases:\n        \n        min_points = scheme_params[scheme]['min_points']\n\n        # Handle the special case where the derivative bound Mk is zero.\n        # This implies the finite difference formula is exact for any h > 0.\n        # Thus, we only need the minimum number of points to define the stencil.\n        if Mk == 0:\n            results.append(min_points)\n            continue\n\n        # Calculate the maximum allowed grid spacing h_max based on the scheme.\n        if scheme == 'forward_first':\n            # h_max = 2 * epsilon / M2\n            h_max = 2.0 * eps / Mk\n        elif scheme == 'centered_first':\n            # h_max = sqrt(6 * epsilon / M3)\n            h_max = np.sqrt(6.0 * eps / Mk)\n        elif scheme == 'centered_second':\n            # h_max = sqrt(12 * epsilon / M4)\n            h_max = np.sqrt(12.0 * eps / Mk)\n        else:\n            # This case should not be reached with the given test_cases.\n            raise ValueError(f\"Unknown scheme: {scheme}\")\n\n        # The number of segments must be an integer, and cover the whole domain L.\n        # To achieve a grid spacing of h <= h_max, we need at least L/h_max segments.\n        # We use ceiling to get the smallest integer number of segments.\n        num_segments = np.ceil(L / h_max)\n        \n        # The number of points is one more than the number of segments.\n        num_points_calculated = int(num_segments) + 1\n        \n        # The final number of points must also satisfy the minimum requirement for the scheme.\n        final_num_points = max(min_points, num_points_calculated)\n        \n        results.append(final_num_points)\n\n    # Print the results in the specified format: [n_A,n_B,n_C,n_D]\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Achieving higher accuracy often comes at the steep computational cost of grid refinement. This practice introduces Richardson extrapolation, an elegant and powerful technique to boost the accuracy of a numerical approximation without needing an excessively fine grid. By cleverly combining approximations computed at different step sizes, you will see how the known structure of the Taylor series truncation error can be exploited to systematically eliminate the leading error term, yielding a higher-order estimate .",
            "id": "3813062",
            "problem": "A computational oceanography task considers vertical shear $u_z$ of a horizontal current $u(z)$ from discrete vertical profiles. Starting from the Taylor series expansion of a sufficiently smooth function $u(z)$ about a target depth $z_0$, construct two distinct finite-difference approximations to $u_z(z_0)$ using uniform spacings $h$ and $h/2$, respectively. Combine these approximations to eliminate the dominant truncation error term by Richardson extrapolation, based only on the Taylor series structure and the requirement that the leading error term be canceled. Implement this Richardson-extrapolated estimate and, using Taylor series, determine the residual leading error constant multiplying $h^4$ in the extrapolated derivative approximation.\n\nYou must apply this approach to discrete profiles that are generated synthetically from physically plausible analytic current profiles, so that exact derivatives are available for quantitative verification. For the two oscillatory-decaying profiles, angles must be treated in radians. Report all shear quantities in $\\mathrm{s}^{-1}$ as pure decimal numbers without units embedded in the output.\n\nFor each test case listed below, compute:\n1. The Richardson-extrapolated estimate of $u_z(z_0)$ from discrete samples taken at $z_0 \\pm h$ and $z_0 \\pm h/2$.\n2. The absolute error of this estimate with respect to the exact $u_z(z_0)$ computed analytically.\n3. The residual leading error constant from the Taylor series after extrapolation, expressed as the coefficient $C$ such that the leading truncation error behaves like $C h^4$ for small $h$ at fixed $z_0$. Provide both the analytically derived constant $C_{\\mathrm{theory}}$ and an empirical estimate $C_{\\mathrm{numeric}} = \\left(u_z^{\\mathrm{extrap}}(z_0) - u_z^{\\mathrm{exact}}(z_0)\\right)/h^4$ for the chosen $h$.\n\nAll angles are in radians. All shear quantities must be expressed in $\\mathrm{s}^{-1}$ as decimal numbers. Do not round; output raw floating-point numbers. The discrete sampling is to be performed directly at the specified offsets from $z_0$, without any interpolation.\n\nTest suite:\n- Case A (oscillatory-decaying, moderate resolution): $u(z) = U_0 \\exp(-z/D)\\cos(b z)$ with $U_0 = 0.5\\,\\mathrm{m}\\,\\mathrm{s}^{-1}$, $D = 50\\,\\mathrm{m}$, $b = \\pi/100\\,\\mathrm{rad}\\,\\mathrm{m}^{-1}$, $z_0 = 100\\,\\mathrm{m}$, coarse spacing $h = 20\\,\\mathrm{m}$.\n- Case B (oscillatory-decaying, coarse resolution): $u(z) = U_0 \\exp(-z/D)\\cos(b z)$ with $U_0 = 0.3\\,\\mathrm{m}\\,\\mathrm{s}^{-1}$, $D = 30\\,\\mathrm{m}$, $b = \\pi/50\\,\\mathrm{rad}\\,\\mathrm{m}^{-1}$, $z_0 = 200\\,\\mathrm{m}$, coarse spacing $h = 100\\,\\mathrm{m}$.\n- Case C (quartic polynomial profile, error edge case): $u(z) = \\alpha z^4 + \\beta z^3 + \\gamma$ with $\\alpha = 2.0\\times 10^{-12}\\,\\mathrm{s}^{-1}\\,\\mathrm{m}^{-3}$, $\\beta = -1.0\\times 10^{-9}\\,\\mathrm{s}^{-1}\\,\\mathrm{m}^{-2}$, $\\gamma = 0.1\\,\\mathrm{m}\\,\\mathrm{s}^{-1}$, $z_0 = 50\\,\\mathrm{m}$, coarse spacing $h = 10\\,\\mathrm{m}$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes a sub-list of four decimal numbers $[u_z^{\\mathrm{extrap}}, \\lvert \\mathrm{error} \\rvert, C_{\\mathrm{theory}}, C_{\\mathrm{numeric}}]$. For example, the overall output format must be of the form $[[a_1,b_1,c_1,d_1],[a_2,b_2,c_2,d_2],[a_3,b_3,c_3,d_3]]$ with all entries being floats.",
            "solution": "The problem requires the construction and application of a high-order finite-difference scheme for the vertical shear, $u_z(z_0) = \\frac{du}{dz}\\rvert_{z=z_0}$, of a horizontal current profile $u(z)$. The method specified is Richardson extrapolation based on two central difference approximations. We must also derive the leading-order truncation error of the resulting extrapolated formula.\n\nFirst, we establish the central difference approximation and its error structure using Taylor series expansions of a sufficiently smooth function $u(z)$ around a point $z_0$. The expansions for $u(z_0+h)$ and $u(z_0-h)$ are:\n$$u(z_0+h) = u(z_0) + h u'(z_0) + \\frac{h^2}{2!}u''(z_0) + \\frac{h^3}{3!}u'''(z_0) + \\frac{h^4}{4!}u''''(z_0) + \\frac{h^5}{5!}u'''''(z_0) + O(h^6)$$\n$$u(z_0-h) = u(z_0) - h u'(z_0) + \\frac{h^2}{2!}u''(z_0) - \\frac{h^3}{3!}u'''(z_0) + \\frac{h^4}{4!}u''''(z_0) - \\frac{h^5}{5!}u'''''(z_0) + O(h^6)$$\nSubtracting the second equation from the first eliminates the even-powered derivative terms:\n$$u(z_0+h) - u(z_0-h) = 2h u'(z_0) + \\frac{2h^3}{3!}u'''(z_0) + \\frac{2h^5}{5!}u'''''(z_0) + O(h^7)$$\nSolving for $u'(z_0)$ gives:\n$$u'(z_0) = \\frac{u(z_0+h) - u(z_0-h)}{2h} - \\frac{h^2}{6}u'''(z_0) - \\frac{h^4}{120}u'''''(z_0) - O(h^6)$$\nLet $F(h)$ denote the second-order central difference approximation for $u'(z_0)$ with step size $h$:\n$$F(h) = \\frac{u(z_0+h) - u(z_0-h)}{2h}$$\nThe true derivative $u'(z_0)$ can be expressed in terms of this approximation as an error series:\n$$u'(z_0) = F(h) - C_1 h^2 - C_2 h^4 - O(h^6)$$\nwhere the error coefficients are $C_1 = \\frac{u'''(z_0)}{6}$ and $C_2 = \\frac{u'''''(z_0)}{120}$.\n\nThe problem requires constructing two such approximations, one with a coarse spacing $h$, denoted $F_h$, and one with a finer spacing $h/2$, denoted $F_{h/2}$. Their relationships to the exact derivative $u'(z_0)$ are:\n$$F_h = u'(z_0) + C_1 h^2 + C_2 h^4 + O(h^6) \\quad (1)$$\n$$F_{h/2} = u'(z_0) + C_1 \\left(\\frac{h}{2}\\right)^2 + C_2 \\left(\\frac{h}{2}\\right)^4 + O(h^6) = u'(z_0) + \\frac{1}{4}C_1 h^2 + \\frac{1}{16}C_2 h^4 + O(h^6) \\quad (2)$$\nTo eliminate the dominant error term, $C_1 h^2$, we seek a linear combination of $F_h$ and $F_{h/2}$. Multiplying equation $(2)$ by $4$ and subtracting equation $(1)$ yields:\n$$4F_{h/2} - F_h = \\left(4u'(z_0) + C_1 h^2 + \\frac{1}{4}C_2 h^4 \\right) - \\left(u'(z_0) + C_1 h^2 + C_2 h^4 \\right) + O(h^6)$$\n$$4F_{h/2} - F_h = 3u'(z_0) - \\frac{3}{4}C_2 h^4 + O(h^6)$$\nSolving for $u'(z_0)$ gives the Richardson-extrapolated estimate, $u_z^{\\mathrm{extrap}}(z_0)$:\n$$u_z^{\\mathrm{extrap}}(z_0) = \\frac{4F_{h/2} - F_h}{3}$$\nThe truncation error of this new estimate is:\n$$u_z^{\\mathrm{extrap}}(z_0) - u'(z_0) = -\\frac{1}{4}C_2 h^4 + O(h^6)$$\nSubstituting the expression for $C_2 = \\frac{u'''''(z_0)}{120}$, we find the leading error term:\n$$\\text{Error} = -\\frac{1}{4} \\left(\\frac{u'''''(z_0)}{120}\\right) h^4 + O(h^6) = -\\frac{u'''''(z_0)}{480} h^4 + O(h^6)$$\nThus, the analytically derived leading error constant is $C_{\\mathrm{theory}} = -\\frac{u'''''(z_0)}{480}$.\n\nTo perform the calculations for the given test cases, the following steps are executed:\n1.  For each profile $u(z)$, determine the analytical expressions for its first derivative, $u'(z)$, and fifth derivative, $u'''''(z)$.\n    - For the oscillatory-decaying profile, $u(z) = U_0 e^{-z/D}\\cos(bz)$, derivatives are efficiently found by considering the real part of the complex function $w(z) = U_0 e^{(a+ib)z}$ where $a = -1/D$. The $n$-th derivative is $u^{(n)}(z) = \\text{Re}\\left(U_0(a+ib)^n e^{(a+ib)z}\\right)$.\n    - For the polynomial profile, $u(z) = \\alpha z^4 + \\beta z^3 + \\gamma$, the derivatives are found by standard differentiation. Notably, for this profile, $u'''''(z) = 0$, which implies the theoretical error is zero.\n2.  Compute the exact shear $u_z^{\\mathrm{exact}}(z_0) = u'(z_0)$.\n3.  Compute the two central difference approximations: $F_h = \\frac{u(z_0+h) - u(z_0-h)}{2h}$ and $F_{h/2} = \\frac{u(z_0+h/2) - u(z_0-h/2)}{h}$.\n4.  Calculate the Richardson-extrapolated estimate $u_z^{\\mathrm{extrap}} = \\frac{4F_{h/2} - F_h}{3}$.\n5.  Calculate the absolute error of the estimate: $|\\mathrm{error}| = |u_z^{\\mathrm{extrap}} - u_z^{\\mathrm{exact}}|$.\n6.  Calculate the theoretical error constant: $C_{\\mathrm{theory}} = -u'''''(z_0)/480$.\n7.  Calculate the empirical error constant: $C_{\\mathrm{numeric}} = (u_z^{\\mathrm{extrap}} - u_z^{\\mathrm{exact}})/h^4$. For the polynomial case, since the error is exactly zero, $C_{\\mathrm{numeric}}$ is also zero.\n\nThese steps are implemented for each test case to produce the required set of four values: $[u_z^{\\mathrm{extrap}}, |\\mathrm{error}|, C_{\\mathrm{theory}}, C_{\\mathrm{numeric}}]$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# No other libraries outside the Python standard library are permitted.\n\ndef u_osc(z, U0, D, b):\n    \"\"\"Computes the oscillatory-decaying profile u(z).\"\"\"\n    return U0 * np.exp(-z/D) * np.cos(b*z)\n\ndef du_osc_dz(z, U0, D, b):\n    \"\"\"Computes the exact first derivative of the oscillatory profile.\"\"\"\n    a = -1.0/D\n    return U0 * np.exp(a*z) * (a * np.cos(b*z) - b * np.sin(b*z))\n\ndef d5u_osc_dz5(z, U0, D, b):\n    \"\"\"Computes the exact fifth derivative of the oscillatory profile.\"\"\"\n    a = -1.0/D\n    # (a+ib)^5 = c_re + i * c_im\n    c_re = a**5 - 10*a**3*b**2 + 5*a*b**4\n    c_im = 5*a**4*b - 10*a**2*b**3 + b**5\n    # d5u/dz5 = Re( U0 * (c_re + i*c_im) * exp(az) * (cos(bz) + i*sin(bz)) )\n    return U0 * np.exp(a*z) * (c_re * np.cos(b*z) - c_im * np.sin(b*z))\n\ndef u_poly(z, alpha, beta, gamma):\n    \"\"\"Computes the quartic polynomial profile u(z).\"\"\"\n    return alpha * z**4 + beta * z**3 + gamma\n\ndef du_poly_dz(z, alpha, beta, gamma):\n    \"\"\"Computes the exact first derivative of the polynomial profile.\"\"\"\n    return 4 * alpha * z**3 + 3 * beta * z**2\n\ndef d5u_poly_dz5(z, alpha, beta, gamma):\n    \"\"\"Computes the exact fifth derivative of the polynomial profile.\"\"\"\n    return 0.0\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A (oscillatory-decaying, moderate resolution)\n        {'type': 'osc', 'params': {'U0': 0.5, 'D': 50, 'b': np.pi/100}, 'z0': 100, 'h': 20},\n        # Case B (oscillatory-decaying, coarse resolution)\n        {'type': 'osc', 'params': {'U0': 0.3, 'D': 30, 'b': np.pi/50}, 'z0': 200, 'h': 100},\n        # Case C (quartic polynomial profile, error edge case)\n        {'type': 'poly', 'params': {'alpha': 2.0e-12, 'beta': -1.0e-9, 'gamma': 0.1}, 'z0': 50, 'h': 10},\n    ]\n\n    results = []\n    for case in test_cases:\n        # Main logic to calculate the result for one case goes here.\n        z0, h = case['z0'], case['h']\n        params = case['params']\n        \n        if case['type'] == 'osc':\n            u_func = u_osc\n            du_func = du_osc_dz\n            d5u_func = d5u_osc_dz5\n        else: # 'poly'\n            u_func = u_poly\n            du_func = du_poly_dz\n            d5u_func = d5u_poly_dz5\n\n        # 1. Compute exact shear at z0\n        uz_exact = du_func(z0, **params)\n\n        # 2. Compute two central difference approximations\n        F_h = (u_func(z0 + h, **params) - u_func(z0 - h, **params)) / (2*h)\n        h_half = h / 2.0\n        F_h_half = (u_func(z0 + h_half, **params) - u_func(z0 - h_half, **params)) / (h)\n\n        # 3. Compute Richardson-extrapolated estimate\n        uz_extrap = (4.0 * F_h_half - F_h) / 3.0\n\n        # 4. Compute absolute error\n        abs_error = np.abs(uz_extrap - uz_exact)\n        \n        # 5. Compute theoretical leading error constant\n        d5u_at_z0 = d5u_func(z0, **params)\n        C_theory = -d5u_at_z0 / 480.0\n\n        # 6. Compute empirical estimate of the error constant\n        error_val = uz_extrap - uz_exact\n        if h == 0:\n            C_numeric = 0.0 if error_val == 0.0 else np.inf\n        else:\n            C_numeric = error_val / (h**4)\n\n        results.append([uz_extrap, abs_error, C_theory, C_numeric])\n\n    # Final print statement in the exact required format.\n    # We construct the string manually to avoid spaces introduced by str(list).\n    print(\"[\" + \",\".join([f\"[{','.join(map(str, sublist))}]\" for sublist in results]) + \"]\")\n\nsolve()\n```"
        }
    ]
}