{
    "hands_on_practices": [
        {
            "introduction": "While the basic Random-Walk Metropolis algorithm is simple to implement, its performance can be inefficient in high-dimensional or poorly scaled problems. A more powerful approach is to use gradient information from the target distribution to guide proposals towards regions of high probability. This exercise  walks you through the derivation of the Metropolis-Adjusted Langevin Algorithm (MALA), starting from its theoretical foundation in stochastic differential equations, and culminates in a practical calculation of an acceptance probability.",
            "id": "3289331",
            "problem": "A central task in computational systems biology is parameter inference for stochastic models of gene regulation from noisy observations. Consider a two-parameter transcription-degradation model whose Bayesian posterior over a parameter vector $\\theta \\in \\mathbb{R}^{2}$ is smooth and strictly positive. Suppose we wish to construct a Markov chain Monte Carlo (MCMC) method that targets this posterior using dynamics inspired by the overdamped Langevin Stochastic Differential Equation (SDE). The overdamped Langevin SDE for a target density $\\pi(\\theta)$ is given by\n$$\nd\\theta_{t} \\;=\\; \\frac{1}{2}\\,\\nabla \\log \\pi(\\theta_{t})\\,dt \\;+\\; dW_{t},\n$$\nwhere $W_{t}$ is a standard $2$-dimensional Wiener process and $\\nabla \\log \\pi(\\theta)$ denotes the gradient with respect to $\\theta$.\n\nTask:\n- Starting only from the SDE above and fundamental definitions of the Metropolis-Hastings (MH) algorithm, derive a proposal mechanism of the form $\\theta' = \\theta + \\frac{\\delta^{2}}{2}\\,\\nabla \\log \\pi(\\theta) + \\delta\\,\\eta$ with $\\eta \\sim \\mathcal{N}(0, I)$, and derive the corresponding MH acceptance probability in terms of $\\pi$, the current state $\\theta$, the proposed state $\\theta'$, and the Gaussian proposal densities. Define any acronyms you introduce on their first appearance.\n\nThen, specialize to the following scientifically realistic posterior arising from a linear-Gaussian approximation to a stochastic gene expression model. The posterior $\\pi(\\theta)$ is proportional to a Gaussian density with mean $\\mu$ and covariance $\\Sigma$:\n$$\n\\pi(\\theta) \\;\\propto\\; \\exp\\!\\left(-\\frac{1}{2}(\\theta - \\mu)^{\\top}\\Sigma^{-1}(\\theta - \\mu)\\right),\n$$\nwith\n$$\n\\mu \\;=\\; \\begin{pmatrix}0.5 \\\\ -0.3\\end{pmatrix}, \n\\qquad \n\\Sigma \\;=\\; \\begin{pmatrix}0.5  0.1 \\\\ 0.1  0.4\\end{pmatrix}.\n$$\nAssume the current state is\n$$\n\\theta \\;=\\; \\begin{pmatrix}0.6 \\\\ -0.2\\end{pmatrix},\n$$\nthe step size parameter is $\\delta = 0.2$, and the realized Gaussian noise draw is\n$$\n\\eta \\;=\\; \\begin{pmatrix}0.5 \\\\ -1.2\\end{pmatrix}.\n$$\nUsing the proposal you derived and the general MH acceptance probability expression, compute the Metropolis-Adjusted Langevin Algorithm (MALA) acceptance probability for moving from $\\theta$ to the proposed $\\theta'$. Express your final answer as a decimal and round your answer to four significant figures.",
            "solution": "The problem is evaluated to be scientifically grounded, well-posed, objective, and internally consistent. It provides a standard exercise in the application of Markov chain Monte Carlo methods to a Bayesian inference problem, a core task in computational systems biology. All necessary definitions, data, and parameters are provided to derive the requested expressions and compute the final numerical answer. The problem is valid.\n\nThe task is to derive a proposal mechanism and acceptance probability for a specific Markov chain Monte Carlo (MCMC) method and then apply it to a given Bayesian posterior.\n\nFirst, we derive the proposal mechanism. The problem specifies dynamics inspired by the overdamped Langevin Stochastic Differential Equation (SDE):\n$$d\\theta_{t} = \\frac{1}{2}\\nabla \\log \\pi(\\theta_{t})\\,dt + dW_{t}$$\nwhere $\\theta_t \\in \\mathbb{R}^2$ is the parameter vector, $\\pi(\\theta)$ is the target posterior density, and $W_t$ is a standard $2$-dimensional Wiener process.\n\nA discrete-time approximation of this SDE can be obtained using the Euler-Maruyama method. We discretize time with a step size $\\Delta t > 0$. The update from a state $\\theta$ at time $t$ to a state $\\theta'$ at time $t+\\Delta t$ is:\n$$\\theta' \\approx \\theta + \\frac{1}{2}\\nabla \\log \\pi(\\theta) \\Delta t + \\Delta W_t$$\nThe increment of the Wiener process, $\\Delta W_t = W_{t+\\Delta t} - W_t$, is a Gaussian random variable with mean $0$ and covariance matrix $(\\Delta t)I$, where $I$ is the $2 \\times 2$ identity matrix.\nWe can write $\\Delta W_t = \\sqrt{\\Delta t}\\,\\eta$, where $\\eta \\sim \\mathcal{N}(0, I)$. Let the step size parameter be $\\delta = \\sqrt{\\Delta t}$, so $\\Delta t = \\delta^2$. Substituting this into the discretized equation yields the proposal mechanism:\n$$\\theta' = \\theta + \\frac{\\delta^2}{2}\\nabla \\log \\pi(\\theta) + \\delta\\eta, \\quad \\eta \\sim \\mathcal{N}(0, I)$$\nThis is a draw from a Gaussian proposal density, $q(\\theta'|\\theta)$, centered at $\\theta + \\frac{\\delta^2}{2}\\nabla \\log \\pi(\\theta)$ with covariance $\\delta^2 I$. The proposal density function is:\n$$q(\\theta'|\\theta) = \\frac{1}{(2\\pi\\delta^2)^{2/2}} \\exp\\left( -\\frac{1}{2\\delta^2} \\left\\| \\theta' - \\left( \\theta + \\frac{\\delta^2}{2}\\nabla \\log \\pi(\\theta) \\right) \\right\\|^2 \\right)$$\nwhere $\\|\\cdot\\|$ denotes the Euclidean norm.\n\nNext, we derive the Metropolis-Hastings (MH) acceptance probability. The MH algorithm ensures that the resulting Markov chain has $\\pi(\\theta)$ as its stationary distribution. The acceptance probability $\\alpha(\\theta', \\theta)$ for a move from state $\\theta$ to a proposed state $\\theta'$ is given by:\n$$\\alpha(\\theta', \\theta) = \\min\\left(1, \\frac{\\pi(\\theta')q(\\theta|\\theta')}{\\pi(\\theta)q(\\theta'|\\theta)}\\right)$$\nThe term $q(\\theta|\\theta')$ is the density of proposing $\\theta$ starting from $\\theta'$. Based on our proposal mechanism, this is:\n$$q(\\theta|\\theta') = \\frac{1}{(2\\pi\\delta^2)^{2/2}} \\exp\\left( -\\frac{1}{2\\delta^2} \\left\\| \\theta - \\left( \\theta' + \\frac{\\delta^2}{2}\\nabla \\log \\pi(\\theta') \\right) \\right\\|^2 \\right)$$\nSubstituting the expressions for $q(\\theta'|\\theta)$ and $q(\\theta|\\theta')$ into the acceptance probability formula, the normalization constants cancel, leading to:\n$$\\alpha(\\theta', \\theta) = \\min\\left(1, \\frac{\\pi(\\theta')}{\\pi(\\theta)} \\frac{\\exp\\left( -\\frac{1}{2\\delta^2} \\left\\| \\theta - \\theta' - \\frac{\\delta^2}{2}\\nabla \\log \\pi(\\theta') \\right\\|^2 \\right)}{\\exp\\left( -\\frac{1}{2\\delta^2} \\left\\| \\theta' - \\theta - \\frac{\\delta^2}{2}\\nabla \\log \\pi(\\theta) \\right\\|^2 \\right)}\\right)$$\nThis algorithm, which uses a Langevin-based proposal with an MH correction step, is known as the Metropolis-Adjusted Langevin Algorithm (MALA).\n\nNow, we specialize to the given posterior, which is proportional to a multivariate Gaussian density:\n$$\\pi(\\theta) \\propto \\exp\\left(-\\frac{1}{2}(\\theta - \\mu)^{\\top}\\Sigma^{-1}(\\theta - \\mu)\\right)$$\nThe log-posterior is $\\log\\pi(\\theta) = C - \\frac{1}{2}(\\theta - \\mu)^{\\top}\\Sigma^{-1}(\\theta - \\mu)$ for some constant $C$. The gradient of the log-posterior with respect to $\\theta$, which we denote as $g(\\theta)$, is:\n$$g(\\theta) = \\nabla \\log \\pi(\\theta) = \\nabla_\\theta \\left( -\\frac{1}{2}(\\theta - \\mu)^{\\top}\\Sigma^{-1}(\\theta - \\mu) \\right) = -\\Sigma^{-1}(\\theta - \\mu)$$\nThe given values are:\n$$\\mu = \\begin{pmatrix}0.5 \\\\ -0.3\\end{pmatrix}, \\quad \\Sigma = \\begin{pmatrix}0.5  0.1 \\\\ 0.1  0.4\\end{pmatrix}, \\quad \\theta = \\begin{pmatrix}0.6 \\\\ -0.2\\end{pmatrix}, \\quad \\delta = 0.2, \\quad \\eta = \\begin{pmatrix}0.5 \\\\ -1.2\\end{pmatrix}$$\nFirst, we compute the inverse of the covariance matrix $\\Sigma$:\n$$\\det(\\Sigma) = (0.5)(0.4) - (0.1)(0.1) = 0.2 - 0.01 = 0.19$$\n$$\\Sigma^{-1} = \\frac{1}{0.19} \\begin{pmatrix}0.4  -0.1 \\\\ -0.1  0.5\\end{pmatrix}$$\nNext, we compute the proposed state $\\theta'$ using $\\theta' = \\theta + \\frac{\\delta^2}{2}g(\\theta) + \\delta\\eta$. We calculate each term:\n$$\\theta - \\mu = \\begin{pmatrix}0.6 \\\\ -0.2\\end{pmatrix} - \\begin{pmatrix}0.5 \\\\ -0.3\\end{pmatrix} = \\begin{pmatrix}0.1 \\\\ 0.1\\end{pmatrix}$$\n$$g(\\theta) = -\\Sigma^{-1}(\\theta - \\mu) = -\\frac{1}{0.19} \\begin{pmatrix}0.4  -0.1 \\\\ -0.1  0.5\\end{pmatrix} \\begin{pmatrix}0.1 \\\\ 0.1\\end{pmatrix} = -\\frac{1}{0.19} \\begin{pmatrix}0.03 \\\\ 0.04\\end{pmatrix}$$\nThe drift term is, with $\\delta^2 = (0.2)^2 = 0.04$:\n$$\\frac{\\delta^2}{2}g(\\theta) = \\frac{0.04}{2} \\left( -\\frac{1}{0.19} \\begin{pmatrix}0.03 \\\\ 0.04\\end{pmatrix} \\right) = -\\frac{0.02}{0.19} \\begin{pmatrix}0.03 \\\\ 0.04\\end{pmatrix} = -\\begin{pmatrix} 0.0006/0.19 \\\\ 0.0008/0.19 \\end{pmatrix} \\approx \\begin{pmatrix} -0.003158 \\\\ -0.004211 \\end{pmatrix}$$\nThe diffusion term is:\n$$\\delta\\eta = 0.2 \\begin{pmatrix}0.5 \\\\ -1.2\\end{pmatrix} = \\begin{pmatrix}0.1 \\\\ -0.24\\end{pmatrix}$$\nSo, the proposed state is:\n$$\\theta' = \\theta + \\frac{\\delta^2}{2}g(\\theta) + \\delta\\eta \\approx \\begin{pmatrix}0.6 \\\\ -0.2\\end{pmatrix} + \\begin{pmatrix} -0.003158 \\\\ -0.004211 \\end{pmatrix} + \\begin{pmatrix}0.1 \\\\ -0.24\\end{pmatrix} = \\begin{pmatrix} 0.696842 \\\\ -0.444211 \\end{pmatrix}$$\nFor a Gaussian target, the log of the acceptance ratio simplifies significantly to:\n$$\\log R = \\log \\left(\\frac{\\pi(\\theta')q(\\theta|\\theta')}{\\pi(\\theta)q(\\theta'|\\theta)}\\right) = - \\frac{\\delta^2}{8} \\left( \\|g(\\theta')\\|^2 - \\|g(\\theta)\\|^2 \\right)$$\nWe need to compute the squared norms of the gradients at $\\theta$ and $\\theta'$.\n$$g(\\theta) = -\\frac{1}{0.19} \\begin{pmatrix}0.03 \\\\ 0.04\\end{pmatrix} = -\\frac{1}{19} \\begin{pmatrix}3 \\\\ 4\\end{pmatrix}$$\n$$\\|g(\\theta)\\|^2 = \\left(\\frac{1}{19}\\right)^2 (3^2 + 4^2) = \\frac{25}{361} \\approx 0.06925208$$\nNext, we compute $g(\\theta')$:\n$$\\theta'-\\mu \\approx \\begin{pmatrix} 0.696842 \\\\ -0.444211 \\end{pmatrix} - \\begin{pmatrix}0.5 \\\\ -0.3\\end{pmatrix} = \\begin{pmatrix}0.196842 \\\\ -0.144211\\end{pmatrix}$$\n$$g(\\theta') = -\\Sigma^{-1}(\\theta'-\\mu) \\approx -\\frac{1}{0.19} \\begin{pmatrix}0.4  -0.1 \\\\ -0.1  0.5\\end{pmatrix} \\begin{pmatrix}0.196842 \\\\ -0.144211\\end{pmatrix}$$\n$$g(\\theta') \\approx -\\frac{1}{0.19} \\begin{pmatrix}0.4(0.196842) - 0.1(-0.144211) \\\\ -0.1(0.196842) + 0.5(-0.144211)\\end{pmatrix} = -\\frac{1}{0.19} \\begin{pmatrix}0.0787368 + 0.0144211 \\\\ -0.0196842 - 0.0721055\\end{pmatrix}$$\n$$g(\\theta') \\approx -\\frac{1}{0.19} \\begin{pmatrix}0.0931579 \\\\ -0.0917897\\end{pmatrix} \\approx \\begin{pmatrix}-0.490305 \\\\ 0.483104\\end{pmatrix}$$\n$$\\|g(\\theta')\\|^2 \\approx (-0.490305)^2 + (0.483104)^2 \\approx 0.240399 + 0.233390 = 0.473789$$\nWith $\\delta^2/8 = 0.04/8 = 0.005$, we find $\\log R$:\n$$\\log R \\approx -0.005 \\times (0.473789 - 0.069252) = -0.005 \\times (0.404537) = -0.002022685$$\nThe acceptance probability is $\\alpha = \\min(1, \\exp(\\log R))$. Since $\\log R  0$, we have:\n$$\\alpha = \\exp(-0.002022685) \\approx 0.99797934$$\nRounding to four significant figures, the result is $0.9980$.",
            "answer": "$$\\boxed{0.9980}$$"
        },
        {
            "introduction": "After running an MCMC simulation, it is crucial to assess the quality of the resulting chain. Since MCMC samples are generated sequentially, they are typically correlated, meaning they are not independent draws from the posterior. This practice  provides a concrete exercise in quantifying this inefficiency by calculating the integrated autocorrelation time ($IACT$) and the effective sample size ($ESS$), two fundamental metrics for understanding how many \"useful\" independent samples your chain represents.",
            "id": "4318054",
            "problem": "In a Bayesian network model for cytokine signaling, a scalar edge weight parameter $\\,\\theta\\,$ (for example, a log-effect size for a regulatory edge) is inferred by Markov chain Monte Carlo (MCMC). After burn-in, the chain for $\\,\\theta\\,$ is stationary and mean-square ergodic. Suppose that the lag-$k$ autocorrelation function $\\,\\rho_k\\,$ of the chain is well-approximated by an exponential form $\\,\\rho_k = 0.8^{k}\\,$ for all integers $\\,k \\geq 1\\,$, with $\\,\\rho_0 = 1\\,$. Using only the definition of the integrated autocorrelation time (IACT) for a stationary scalar chain and standard properties of absolutely convergent series, derive the IACT in closed form for this autocorrelation structure. Then use the standard definition of effective sample size (ESS) for a univariate MCMC output to estimate the number of effectively independent draws when $\\,T = 5000\\,$ post-burn-in iterations are retained.\n\nState any intermediate assumptions you use explicitly, justify convergence of any infinite series invoked, and express your final answer as two exact values, without rounding. The two outputs should be, in order: the integrated autocorrelation time and the effective sample size. Do not include units. If you choose to approximate, you must round to four significant figures; otherwise provide exact values.",
            "solution": "The problem statement is critically validated before proceeding to a solution.\n\n### Step 1: Extract Givens\nThe verbatim data provided in the problem statement are:\n- A Markov chain Monte Carlo (MCMC) chain for a scalar parameter $\\theta$ is stationary and mean-square ergodic.\n- The lag-$k$ autocorrelation function is given by $\\rho_k = 0.8^k$ for all integers $k \\geq 1$.\n- The lag-$0$ autocorrelation is $\\rho_0 = 1$.\n- The number of post-burn-in iterations (samples) is $T = 5000$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed against the required criteria:\n- **Scientifically Grounded**: The problem is well-grounded in the statistical theory of MCMC methods, which are foundational to Bayesian inference in systems biology and other fields. The concepts of autocorrelation, integrated autocorrelation time (IACT), and effective sample size (ESS) are standard for assessing MCMC sampler efficiency. The exponential decay model for autocorrelation is a common and tractable approximation.\n- **Well-Posed**: The problem is well-posed. It provides an explicit functional form for the autocorrelation function and asks for derived quantities (IACT and ESS) based on their standard definitions. All necessary information ($T$, $\\rho_k$) is provided to find a unique, meaningful solution.\n- **Objective**: The language is precise and uses standard, unambiguous terminology from statistics.\n- **Completeness/Consistency**: The problem is self-contained. The given autocorrelation structure is consistent with the properties of a stationary process (e.g., $|\\rho_k| \\leq 1$). The condition of being mean-square ergodic is consistent with the fact that the given autocorrelation function leads to a convergent series, as will be shown.\n- **Other Flaws**: The problem does not exhibit any other flaws such as being unrealistic, ill-posed, pseudo-profound, or unverifiable.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. A full, reasoned solution is provided below.\n\nThe solution proceeds in two parts as requested: first, the derivation of the integrated autocorrelation time (IACT), and second, the calculation of the effective sample size (ESS).\n\n**Part 1: Derivation of the Integrated Autocorrelation Time (IACT)**\n\nThe integrated autocorrelation time, denoted by $\\tau$, for a stationary scalar time series is defined as the sum of all auto-correlations from lag $k = -\\infty$ to $k = \\infty$.\n$$ \\tau = \\sum_{k=-\\infty}^{\\infty} \\rho_k $$\nFor a stationary process, the autocorrelation function is symmetric, i.e., $\\rho_k = \\rho_{-k}$. Also, by definition, $\\rho_0 = 1$. The definition can thus be rewritten as:\n$$ \\tau = \\rho_0 + \\sum_{k=1}^{\\infty} \\rho_k + \\sum_{k=-\\infty}^{-1} \\rho_k = 1 + 2 \\sum_{k=1}^{\\infty} \\rho_k $$\nThis is the standard definition we will use, as suggested by the problem statement's reference to properties of convergent series.\n\nThe problem provides the autocorrelation structure as $\\rho_k = 0.8^k$ for $k \\geq 1$. Substituting this into the definition of $\\tau$:\n$$ \\tau = 1 + 2 \\sum_{k=1}^{\\infty} (0.8)^k $$\nThe sum $\\sum_{k=1}^{\\infty} (0.8)^k$ is a geometric series with first term $a = 0.8$ and common ratio $r = 0.8$.\nThe sum of an infinite geometric series $\\sum_{n=1}^{\\infty} ar^{n-1}$ converges if and only if the absolute value of the common ratio is less than $1$, i.e., $|r|  1$. In this case, $r = 0.8$, and since $|0.8|  1$, the series converges absolutely.\n\nThe formula for the sum of an infinite geometric series starting from the $k=1$ term is:\n$$ \\sum_{k=1}^{\\infty} r^k = \\frac{r}{1-r} $$\nApplying this formula with $r=0.8$:\n$$ \\sum_{k=1}^{\\infty} (0.8)^k = \\frac{0.8}{1 - 0.8} = \\frac{0.8}{0.2} = 4 $$\nThe convergence of this sum confirms that the IACT is finite, which is consistent with the given information that the chain is mean-square ergodic.\n\nNow, we substitute this sum back into the expression for $\\tau$:\n$$ \\tau = 1 + 2 \\times 4 = 1 + 8 = 9 $$\nThus, the integrated autocorrelation time is exactly $9$.\n\n**Part 2: Estimation of the Effective Sample Size (ESS)**\n\nThe effective sample size (ESS) is a metric that quantifies the number of independent samples that would yield the same variance in the sample mean as the $T$ autocorrelated samples from the MCMC chain. The standard definition for ESS, given a chain of length $T$ and an integrated autocorrelation time $\\tau$, is:\n$$ \\text{ESS} = \\frac{T}{\\tau} $$\nWe are given the total number of post-burn-in iterations, $T = 5000$. From Part 1, we derived the IACT as $\\tau = 9$.\n\nSubstituting these values into the ESS formula:\n$$ \\text{ESS} = \\frac{5000}{9} $$\nThe problem requests the exact value. The fraction $\\frac{5000}{9}$ is an exact representation of this value. This corresponds to the recurring decimal $555.\\overline{5}$. Per the instructions, we provide the exact fractional form.\n\nThe final answers are the IACT, $\\tau = 9$, and the ESS, $\\text{ESS} = \\frac{5000}{9}$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n9  \\frac{5000}{9}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "A key goal in Bayesian inference is to compute posterior expectations with the lowest possible variance for a given computational effort. The standard approach averages a function over the MCMC chain, but this ignores information contained in the proposals that were rejected. This exercise  introduces the powerful concept of Rao-Blackwellization, demonstrating how you can derive a more statistically efficient estimator by conditioning on the proposed state and averaging out the randomness of the accept/reject step.",
            "id": "1343414",
            "problem": "In statistical physics and Bayesian inference, the Metropolis-Hastings algorithm is a widely used Markov chain Monte Carlo method for obtaining a sequence of random samples from a probability distribution for which direct sampling is difficult. These samples are then used to approximate expectations of functions with respect to this target distribution.\n\nConsider a target probability density function $\\pi(x)$ defined on a state space $\\mathcal{X}$. We wish to estimate the expectation $I = \\mathbb{E}_{\\pi}[f(X)]$, where $f(x)$ is a given real-valued function. The Metropolis-Hastings algorithm generates a Markov chain $\\{X_t\\}_{t=0,1,2,...}$ whose stationary distribution is $\\pi(x)$.\n\nThe generation of the chain proceeds as follows. Given the current state $X_t = x$, a candidate state $Y_t = y$ is proposed from a proposal distribution with density $q(y|x)$. This proposal is then accepted or rejected based on the acceptance probability,\n$$\n\\alpha(x, y) = \\min\\left(1, \\frac{\\pi(y)q(x|y)}{\\pi(x)q(y|x)}\\right)\n$$\nThe next state of the chain, $X_{t+1}$, is set to the proposed state $y$ with probability $\\alpha(x,y)$, and remains at the current state $x$ with probability $1 - \\alpha(x,y)$.\n\nThe standard Monte Carlo estimator for $I$ is the sample mean of the function evaluated at the states of the chain, $\\hat{I}_{S} = \\frac{1}{N} \\sum_{t=1}^{N} f(X_t)$, assuming the chain has reached its stationary distribution.\n\nA more sophisticated estimator can be constructed by applying the Rao-Blackwell theorem. The key idea is to replace the random term $f(X_{t+1})$ in the summation with its conditional expectation, given the information available at the time of the proposal. At step $t$, after observing the current state $X_t$ and generating the proposal $Y_t$, the next state $X_{t+1}$ is the only remaining random element in the transition.\n\nYour task is to derive an expression for the term $g(X_t, Y_t)$ that would be used in such a Rao-Blackwellized estimator, $\\hat{I}_{RB} = \\frac{1}{N} \\sum_{t=1}^{N} g(X_t, Y_t)$. This term is defined by the conditional expectation $g(x,y) = \\mathbb{E}[f(X_{t+1}) | X_t=x, Y_t=y]$. Express your result in terms of the function $f$ evaluated at $x$ and $y$, and the acceptance probability $\\alpha(x,y)$.",
            "solution": "We seek $g(x,y) = \\mathbb{E}[f(X_{t+1}) \\mid X_{t}=x, Y_{t}=y]$. Under the Metropolis-Hastings transition, once $X_{t}=x$ and the proposal $Y_{t}=y$ are fixed, the only randomness is whether the proposal is accepted. Let $A$ be the acceptance indicator with\n$$\n\\mathbb{P}(A=1 \\mid X_{t}=x, Y_{t}=y) = \\alpha(x,y), \\quad \\mathbb{P}(A=0 \\mid X_{t}=x, Y_{t}=y) = 1-\\alpha(x,y).\n$$\nThe next state is $X_{t+1}=y$ if $A=1$ and $X_{t+1}=x$ if $A=0$. Therefore,\n$$\nf(X_{t+1}) = f(y)\\,A + f(x)\\,(1-A).\n$$\nTaking the conditional expectation given $X_{t}=x$ and $Y_{t}=y$ and using linearity of expectation,\n$$\n\\mathbb{E}[f(X_{t+1}) \\mid X_{t}=x, Y_{t}=y] = f(y)\\,\\mathbb{E}[A \\mid x,y] + f(x)\\,\\bigl(1-\\mathbb{E}[A \\mid x,y]\\bigr).\n$$\nSince $\\mathbb{E}[A \\mid x,y] = \\alpha(x,y)$, we obtain\n$$\ng(x,y) = \\alpha(x,y)\\,f(y) + \\bigl(1-\\alpha(x,y)\\bigr)\\,f(x) = f(x) + \\alpha(x,y)\\,\\bigl(f(y)-f(x)\\bigr).\n$$\nEither form is acceptable; both express the conditional expectation in terms of $f(x)$, $f(y)$, and $\\alpha(x,y)$.",
            "answer": "$$\\boxed{\\alpha(x,y)\\,f(y)+\\bigl(1-\\alpha(x,y)\\bigr)\\,f(x)}$$"
        }
    ]
}