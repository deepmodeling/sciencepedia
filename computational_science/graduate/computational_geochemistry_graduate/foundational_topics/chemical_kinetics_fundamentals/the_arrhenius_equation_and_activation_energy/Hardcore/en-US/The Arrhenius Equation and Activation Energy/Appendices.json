{
    "hands_on_practices": [
        {
            "introduction": "A cornerstone of computational geochemistry is the ability to translate raw experimental measurements into robust kinetic models. This practice focuses on a common scenario where reaction rates depend on both temperature and chemical affinity, such as mineral precipitation. By linearizing a rate law that combines the Arrhenius equation with a power-law dependence on supersaturation, we can employ multiple linear regression to simultaneously estimate the activation energy $E_a$ and other key kinetic parameters from a single dataset .",
            "id": "4103248",
            "problem": "A computational geochemistry laboratory has measured surface-normalized calcite precipitation rates under controlled aqueous conditions at multiple temperatures and saturation states. The precipitation rate depends on temperature $T$ (in $\\mathrm{K}$) through an activated process with an energy barrier, and on the saturation state $\\Omega$ through a nonlinear supersaturation response. The saturation state $\\Omega$ is defined as the ratio of the ion activity product to the solubility product of calcite, and thus $\\Omega  1$ denotes supersaturation. The objective is to estimate the activation energy $E_a$ while explicitly accounting for the nonlinearity in $\\Omega$.\n\nStarting from fundamental statistical mechanics, use the Boltzmann distribution to model the fraction of configurations that can cross an energy barrier. Justify a separability assumption in which the temperature dependence and the supersaturation dependence factorize into a product of two functions. Adopt a monotone response function of supersaturation that can be modeled by a power of the supersaturation distance from equilibrium, and justify the use of a logarithmic transformation to linearize the estimation problem. Your program must:\n\n- Derive a regression model from first principles that isolates $E_a$ using the fraction of configurations above an energy threshold and a parametric nonlinear function of $\\Omega$.\n- Implement an estimation routine that, given arrays of $(T_i, \\Omega_i)$ and measured rates $r_i$ (in $\\mathrm{mol\\,m^{-2}\\,s^{-1}}$), returns estimates of three parameters:\n  - the activation energy $E_a$ (expressed in $\\mathrm{kJ\\,mol^{-1}}$),\n  - the supersaturation nonlinearity exponent $n$ (dimensionless),\n  - a pre-exponential coefficient $A$ (with units $\\mathrm{mol\\,m^{-2}\\,s^{-1}}$).\n- Use the Ideal Gas Constant, $R = 8.314462618\\ \\mathrm{J\\,mol^{-1}\\,K^{-1}}$. Angles are not involved in this problem.\n\nDesign the estimation so that it is testable and reproducible. To this end, use the following four test cases. Each test case provides triplets $(T_i, \\Omega_i, r_i)$; assemble them into vectors and fit the model. The test suite spans a general case, low-supersaturation boundary behavior, a high activation energy case at elevated temperatures, and a simple nonlinearity case.\n\nTest case 1 (general “happy path”):\n- $T$ in $\\mathrm{K}$: $[298.15, 298.15, 298.15, 308.15, 308.15, 308.15, 318.15, 318.15, 318.15, 328.15, 328.15, 328.15]$\n- $\\Omega$: $[1.2, 1.5, 2.0, 1.2, 1.5, 2.0, 1.2, 1.5, 2.0, 1.2, 1.5, 2.0]$\n- $r$ in $\\mathrm{mol\\,m^{-2}\\,s^{-1}}$: $[3.92\\times 10^{-10}, 2.45\\times 10^{-9}, 9.80\\times 10^{-9}, 6.64\\times 10^{-10}, 4.15\\times 10^{-9}, 1.66\\times 10^{-8}, 1.09\\times 10^{-9}, 6.83\\times 10^{-9}, 2.73\\times 10^{-8}, 1.75\\times 10^{-9}, 1.10\\times 10^{-8}, 4.39\\times 10^{-8}]$\n\nTest case 2 (boundary, low supersaturation):\n- $T$ in $\\mathrm{K}$: $[298.15, 298.15, 298.15, 308.15, 308.15, 308.15]$\n- $\\Omega$: $[1.05, 1.10, 1.20, 1.05, 1.10, 1.20]$\n- $r$ in $\\mathrm{mol\\,m^{-2}\\,s^{-1}}$: $[5.48\\times 10^{-12}, 3.10\\times 10^{-11}, 1.75\\times 10^{-10}, 9.27\\times 10^{-12}, 5.25\\times 10^{-11}, 2.97\\times 10^{-10}]$\n\nTest case 3 (high activation energy, elevated temperatures):\n- $T$ in $\\mathrm{K}$: $[328.15, 328.15, 328.15, 338.15, 338.15, 338.15, 348.15, 348.15, 348.15]$\n- $\\Omega$: $[1.20, 2.00, 3.00, 1.20, 2.00, 3.00, 1.20, 2.00, 3.00]$\n- $r$ in $\\mathrm{mol\\,m^{-2}\\,s^{-1}}$: $[3.22\\times 10^{-11}, 3.60\\times 10^{-10}, 1.02\\times 10^{-9}, 7.34\\times 10^{-11}, 8.20\\times 10^{-10}, 2.32\\times 10^{-9}, 1.79\\times 10^{-10}, 2.00\\times 10^{-9}, 5.66\\times 10^{-9}]$\n\nTest case 4 (simple nonlinearity):\n- $T$ in $\\mathrm{K}$: $[293.15, 293.15, 293.15, 303.15, 303.15, 303.15, 313.15, 313.15, 313.15]$\n- $\\Omega$: $[1.10, 1.30, 2.00, 1.10, 1.30, 2.00, 1.10, 1.30, 2.00]$\n- $r$ in $\\mathrm{mol\\,m^{-2}\\,s^{-1}}$: $[1.00\\times 10^{-13}, 3.00\\times 10^{-13}, 1.00\\times 10^{-12}, 2.25\\times 10^{-13}, 6.75\\times 10^{-13}, 2.25\\times 10^{-12}, 4.85\\times 10^{-13}, 1.455\\times 10^{-12}, 4.85\\times 10^{-12}]$\n\nYour program must output one single line that aggregates the estimates for all four test cases into a single list. For each test case, output a list of three numbers $[E_a, n, A]$ where:\n- $E_a$ is in $\\mathrm{kJ\\,mol^{-1}}$, rounded to three significant figures,\n- $n$ is dimensionless, rounded to three significant figures,\n- $A$ is in $\\mathrm{mol\\,m^{-2}\\,s^{-1}}$, rounded to three significant figures.\n\nFinal output format: a single line containing the outer list of the four inner lists, with comma-separated entries enclosed in square brackets, for example $[[E_{a,1}, n_1, A_1],[E_{a,2}, n_2, A_2],[E_{a,3}, n_3, A_3],[E_{a,4}, n_4, A_4]]$.",
            "solution": "The problem statement has been analyzed and is determined to be valid. It is scientifically grounded in the principles of chemical kinetics and statistical mechanics, well-posed as a parameter estimation problem, and specified with all necessary data and constraints for a unique solution. We may therefore proceed with the derivation and implementation.\n\nThe objective is to determine the activation energy $E_a$, a pre-exponential factor $A$, and a nonlinearity exponent $n$ from experimental rate data. The precipitation rate, $r$, is a function of absolute temperature, $T$, and the calcite saturation state, $\\Omega$. The problem suggests a model where the dependencies on temperature and saturation are separable. This is a common and physically reasonable assumption, leading to a rate law of the form:\n$$\nr(T, \\Omega) = f(T) \\cdot g(\\Omega)\n$$\nwhere $f(T)$ captures the temperature dependence and $g(\\Omega)$ captures the dependence on supersaturation.\n\n**1. Temperature Dependence, $f(T)$**\n\nThe temperature dependence is stated to arise from an activated process. According to statistical mechanics and the Boltzmann distribution, the fraction of molecules in a system possessing at least a minimum molar energy $E_a$ (the activation energy) at a given temperature $T$ is proportional to the Boltzmann factor, $e^{-E_a / (RT)}$. Here, $R$ is the ideal gas constant. This is the cornerstone of the Arrhenius equation. We thus model the temperature-dependent part of the rate constant as:\n$$\nf(T) \\propto e^{-E_a / (RT)}\n$$\n\n**2. Supersaturation Dependence, $g(\\Omega)$**\n\nThe problem specifies that the supersaturation dependence, $g(\\Omega)$, should be modeled as a power of the supersaturation distance from equilibrium. The saturation state $\\Omega$ is defined as the ratio of the ion activity product to the solubility product. Equilibrium corresponds to $\\Omega=1$. For precipitation to occur, the system must be supersaturated, i.e., $\\Omega > 1$. The \"distance from equilibrium\" can be quantified as $(\\Omega - 1)$. A general nonlinear response can then be modeled as a power law:\n$$\ng(\\Omega) \\propto (\\Omega - 1)^n\n$$\nwhere $n$ is a dimensionless exponent that describes the order of the reaction with respect to the supersaturation driving force.\n\n**3. Combined Rate Law**\n\nCombining these two dependencies and introducing a single pre-exponential factor, $A$, which consolidates all proportionality constants, we obtain the complete rate law:\n$$\nr(T, \\Omega) = A \\cdot e^{-E_a / (RT)} \\cdot (\\Omega - 1)^n\n$$\nThe parameters to be estimated from the experimental data $(T_i, \\Omega_i, r_i)$ are $A$, $E_a$, and $n$.\n\n**4. Linearization for Parameter Estimation**\n\nThis model is nonlinear in its parameters $E_a$ and $n$, which complicates direct fitting. As suggested, we can linearize the equation by taking the natural logarithm of both sides:\n$$\n\\ln(r) = \\ln\\left(A \\cdot e^{-E_a / (RT)} \\cdot (\\Omega - 1)^n\\right)\n$$\nUsing the properties of logarithms, $\\ln(xy) = \\ln(x) + \\ln(y)$ and $\\ln(x^p) = p\\ln(x)$, we expand the expression:\n$$\n\\ln(r) = \\ln(A) + \\ln\\left(e^{-E_a / (RT)}\\right) + \\ln\\left((\\Omega - 1)^n\\right)\n$$\n$$\n\\ln(r) = \\ln(A) - \\frac{E_a}{RT} + n \\ln(\\Omega - 1)\n$$\nThis equation can be rearranged into the form of a multiple linear regression model, $Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2$. We make the following identifications for a given data point $i$:\n- The response variable: $Y_i = \\ln(r_i)$\n- The predictor variables: $X_{i,1} = \\frac{1}{T_i}$ and $X_{i,2} = \\ln(\\Omega_i - 1)$\n- The regression coefficients: $\\beta_0 = \\ln(A)$, $\\beta_1 = -\\frac{E_a}{R}$, and $\\beta_2 = n$.\n\nThe linearized model is:\n$$\nY_i = \\beta_0 + \\beta_1 X_{i,1} + \\beta_2 X_{i,2} + \\epsilon_i\n$$\nwhere $\\epsilon_i$ represents the residual error for the $i$-th measurement.\n\n**5. Solving via Ordinary Least Squares (OLS)**\n\nThe vector of coefficients $\\boldsymbol{\\beta} = [\\beta_0, \\beta_1, \\beta_2]^T$ can be estimated by minimizing the sum of squared residuals. This is the method of Ordinary Least Squares (OLS). The OLS solution is given by the normal equations:\n$$\n\\boldsymbol{\\beta} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{Y}\n$$\nwhere $\\mathbf{Y}$ is the vector of observed responses $[Y_1, Y_2, \\dots, Y_m]^T$ and $\\mathbf{X}$ is the $m \\times 3$ design matrix. Each row of $\\mathbf{X}$ corresponds to an experimental data point and has the form $[1, X_{i,1}, X_{i,2}]$, where the initial $1$ accounts for the intercept term $\\beta_0$:\n$$\n\\mathbf{X} = \\begin{pmatrix}\n1  1/T_1  \\ln(\\Omega_1 - 1) \\\\\n1  1/T_2  \\ln(\\Omega_2 - 1) \\\\\n\\vdots  \\vdots  \\vdots \\\\\n1  1/T_m  \\ln(\\Omega_m - 1)\n\\end{pmatrix}\n, \\quad\n\\mathbf{Y} = \\begin{pmatrix}\n\\ln(r_1) \\\\\n\\ln(r_2) \\\\\n\\vdots \\\\\n\\ln(r_m)\n\\end{pmatrix}\n$$\nThis system will be solved numerically using standard linear algebra routines, such as those provided in `numpy.linalg`.\n\n**6. Recovering Physical Parameters**\n\nOnce the regression coefficients $\\beta_0$, $\\beta_1$, and $\\beta_2$ are determined, the physical parameters of the model are recovered as follows:\n- Pre-exponential factor: $A = e^{\\beta_0}$\n- Activation energy: $E_a = -\\beta_1 \\cdot R$. Given $R$ in $\\mathrm{J\\,mol^{-1}\\,K^{-1}}$, $E_a$ will be in $\\mathrm{J\\,mol^{-1}}$. To express it in $\\mathrm{kJ\\,mol^{-1}}$, we divide by $1000$: $E_a\\ [\\mathrm{kJ\\,mol^{-1}}] = \\frac{-\\beta_1 \\cdot R}{1000}$.\n- Nonlinearity exponent: $n = \\beta_2$\n\nThe implementation will process each of the four test cases by constructing the respective $\\mathbf{X}$ and $\\mathbf{Y}$ matrices, solving for $\\boldsymbol{\\beta}$, and then calculating and rounding the physical parameters $E_a$, $n$, and $A$ to three significant figures.",
            "answer": "```python\nimport numpy as np\nimport math\n\ndef round_to_significant_figures(x, n):\n    \"\"\"\n    Rounds a number to a specified number of significant figures.\n\n    Args:\n        x (float): The number to round.\n        n (int): The number of significant figures.\n\n    Returns:\n        float: The rounded number.\n    \"\"\"\n    if x == 0:\n        return 0.0\n    if np.isnan(x) or np.isinf(x):\n        return x\n    # Calculate the power of 10 to shift the decimal point\n    power = n - int(math.floor(math.log10(abs(x)))) - 1\n    # Round the number and then shift the decimal point back\n    return round(x * (10**power)) / (10**power)\n\ndef estimate_parameters(T, Omega, r):\n    \"\"\"\n    Estimates kinetic parameters Ea, n, and A from experimental data.\n\n    The function fits the model r = A * exp(-Ea/(R*T)) * (Omega - 1)^n\n    by linearizing it to ln(r) = ln(A) - Ea/R * (1/T) + n * ln(Omega - 1)\n    and performing a multiple linear regression.\n\n    Args:\n        T (np.ndarray): Array of temperatures in Kelvin.\n        Omega (np.ndarray): Array of saturation states (dimensionless).\n        r (np.ndarray): Array of measured rates in mol m^-2 s^-1.\n\n    Returns:\n        list: A list containing [Ea, n, A] with values rounded to\n              three significant figures. Ea is in kJ/mol.\n    \"\"\"\n    R = 8.314462618  # Ideal Gas Constant in J mol^-1 K^-1\n\n    # 1. Prepare data for linear regression\n    # Y = ln(r)\n    y_vec = np.log(r)\n\n    # Design matrix X with columns for intercept, 1/T, and ln(Omega - 1)\n    # X_0 = 1 (for intercept)\n    # X_1 = 1/T\n    # X_2 = ln(Omega - 1)\n    ones_col = np.ones_like(T)\n    x1_col = 1.0 / T\n    x2_col = np.log(Omega - 1)\n    X_matrix = np.vstack([ones_col, x1_col, x2_col]).T\n\n    # 2. Perform Ordinary Least Squares (OLS) regression\n    # Solves for beta in X @ beta = y\n    beta, _, _, _ = np.linalg.lstsq(X_matrix, y_vec, rcond=None)\n    beta0, beta1, beta2 = beta\n\n    # 3. Recover physical parameters from regression coefficients\n    # beta0 = ln(A)\n    A = np.exp(beta0)\n\n    # beta1 = -Ea / R\n    Ea_J_per_mol = -beta1 * R\n    Ea_kJ_per_mol = Ea_J_per_mol / 1000.0\n\n    # beta2 = n\n    n = beta2\n\n    # 4. Round results to three significant figures\n    Ea_rounded = round_to_significant_figures(Ea_kJ_per_mol, 3)\n    n_rounded = round_to_significant_figures(n, 3)\n    A_rounded = round_to_significant_figures(A, 3)\n\n    return [Ea_rounded, n_rounded, A_rounded]\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = [\n        # Test case 1 (general “happy path”)\n        {\n            'T': np.array([298.15, 298.15, 298.15, 308.15, 308.15, 308.15, 318.15, 318.15, 318.15, 328.15, 328.15, 328.15]),\n            'Omega': np.array([1.2, 1.5, 2.0, 1.2, 1.5, 2.0, 1.2, 1.5, 2.0, 1.2, 1.5, 2.0]),\n            'r': np.array([3.92e-10, 2.45e-9, 9.80e-9, 6.64e-10, 4.15e-9, 1.66e-8, 1.09e-9, 6.83e-9, 2.73e-8, 1.75e-9, 1.10e-8, 4.39e-8])\n        },\n        # Test case 2 (boundary, low supersaturation)\n        {\n            'T': np.array([298.15, 298.15, 298.15, 308.15, 308.15, 308.15]),\n            'Omega': np.array([1.05, 1.10, 1.20, 1.05, 1.10, 1.20]),\n            'r': np.array([5.48e-12, 3.10e-11, 1.75e-10, 9.27e-12, 5.25e-11, 2.97e-10])\n        },\n        # Test case 3 (high activation energy, elevated temperatures)\n        {\n            'T': np.array([328.15, 328.15, 328.15, 338.15, 338.15, 338.15, 348.15, 348.15, 348.15]),\n            'Omega': np.array([1.20, 2.00, 3.00, 1.20, 2.00, 3.00, 1.20, 2.00, 3.00]),\n            'r': np.array([3.22e-11, 3.60e-10, 1.02e-9, 7.34e-11, 8.20e-10, 2.32e-9, 1.79e-10, 2.00e-9, 5.66e-9])\n        },\n        # Test case 4 (simple nonlinearity)\n        {\n            'T': np.array([293.15, 293.15, 293.15, 303.15, 303.15, 303.15, 313.15, 313.15, 313.15]),\n            'Omega': np.array([1.10, 1.30, 2.00, 1.10, 1.30, 2.00, 1.10, 1.30, 2.00]),\n            'r': np.array([1.00e-13, 3.00e-13, 1.00e-12, 2.25e-13, 6.75e-13, 2.25e-12, 4.85e-13, 1.455e-12, 4.85e-12])\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        params = estimate_parameters(case['T'], case['Omega'], case['r'])\n        results.append(params)\n\n    # Format the final output string exactly as specified.\n    # The `map(str, results)` will convert each inner list to its string representation.\n    # e.g., '[40.0, 2.5, 1.0e-05]'\n    # `','.join(...)` joins these strings with commas.\n    # The outer `f\"[{...}]\"` adds the outer brackets.\n    output_string = f\"[{','.join(map(str, results))}]\"\n    print(output_string)\n\nsolve()\n```"
        },
        {
            "introduction": "Obtaining a best-fit value for activation energy is only the first step; a crucial subsequent task is to understand how uncertainty in this parameter impacts the model's predictive power. This exercise explores the propagation of uncertainty, treating the activation energy $E_a$ as a statistical distribution rather than a single number. You will see how the exponential nature of the Arrhenius equation transforms a simple Gaussian uncertainty in $E_a$ into a skewed log-normal distribution for the predicted rate constant, revealing the significant risks associated with extrapolating beyond the calibration temperature range .",
            "id": "4103296",
            "problem": "You are studying a geochemical reaction system where the temperature dependence of the reaction rate constant arises from a barrier-crossing process. Based on equilibrium statistical mechanics and kinetic theory, the fraction of molecules with energy at least equal to a barrier can be derived from the Boltzmann factor, which implies that the number of successful barrier crossings per unit time depends exponentially on the barrier energy and inversely on the absolute temperature. Consider a calibration measurement of the reaction rate constant at an absolute temperature $T_{\\text{cal}}$, with a measured calibration rate constant $k_{\\text{cal}}$ that is treated as exact for the purposes of this analysis. The barrier height is the activation energy $E_a$, which is uncertain due to experimental fitting and is modeled as a normal random variable with mean $\\mu_{E_a}$ and standard deviation $\\sigma_{E_a}$. The activation energy $E_a$ is given per mole, and the relevant thermal energy scale is determined by the universal gas constant $R$. Starting from the Boltzmann population and collision-frequency picture, derive the dependence of the rate constant on activation energy and temperature, and use the calibration measurement at $T_{\\text{cal}}$ to eliminate any unknown frequency factor so that the predicted rate at another temperature $T_{\\text{out}}$ depends only on $k_{\\text{cal}}$, $E_a$, $T_{\\text{cal}}$, and $T_{\\text{out}}$. Then, assuming $E_a \\sim \\mathcal{N}(\\mu_{E_a},\\sigma_{E_a}^2)$, analytically propagate the uncertainty to the predicted rate constant at $T_{\\text{out}}$ and compute the distribution’s mean, median, and central $95$ percent interval.\n\nUse the following constants and units:\n- Use the universal gas constant $R = 8.31446261815324\\,\\mathrm{J\\,mol^{-1}\\,K^{-1}}$.\n- All absolute temperatures must be specified and used in $\\mathrm{K}$.\n- All activation energies must be specified in $\\mathrm{kJ\\,mol^{-1}}$ but converted internally to $\\mathrm{J\\,mol^{-1}}$ for computation.\n- All rate constants must be computed and reported in $\\mathrm{s^{-1}}$.\n- Express interval bounds and summary statistics as decimal numbers; do not use a percent sign.\n\nAssumptions:\n- The calibration rate constant $k_{\\text{cal}}$ at $T_{\\text{cal}}$ is treated as exact.\n- The only source of uncertainty is the activation energy $E_a$, modeled as $E_a \\sim \\mathcal{N}(\\mu_{E_a},\\sigma_{E_a}^2)$.\n\nRequired outputs for each test case:\n- Compute the predicted rate constant distribution at $T_{\\text{out}}$, and return a list of four numbers: the distribution mean, the distribution median, the lower bound of the central $95$ percent interval, and the upper bound of the central $95$ percent interval. All four numbers must be in $\\mathrm{s^{-1}}$ and rounded to eight significant digits.\n\nTest suite:\n- Case $1$ (happy path): $T_{\\text{cal}} = 298.15\\,\\mathrm{K}$, $k_{\\text{cal}} = 1.0\\times10^{-10}\\,\\mathrm{s^{-1}}$, $\\mu_{E_a} = 60\\,\\mathrm{kJ\\,mol^{-1}}$, $\\sigma_{E_a} = 5\\,\\mathrm{kJ\\,mol^{-1}}$, $T_{\\text{out}} = 373.15\\,\\mathrm{K}$.\n- Case $2$ (boundary, no extrapolation): $T_{\\text{cal}} = 298.15\\,\\mathrm{K}$, $k_{\\text{cal}} = 3.2\\times10^{-9}\\,\\mathrm{s^{-1}}$, $\\mu_{E_a} = 80\\,\\mathrm{kJ\\,mol^{-1}}$, $\\sigma_{E_a} = 10\\,\\mathrm{kJ\\,mol^{-1}}$, $T_{\\text{out}} = 298.15\\,\\mathrm{K}$.\n- Case $3$ (higher-temperature extrapolation with larger uncertainty): $T_{\\text{cal}} = 323.15\\,\\mathrm{K}$, $k_{\\text{cal}} = 5.0\\times10^{-12}\\,\\mathrm{s^{-1}}$, $\\mu_{E_a} = 100\\,\\mathrm{kJ\\,mol^{-1}}$, $\\sigma_{E_a} = 15\\,\\mathrm{kJ\\,mol^{-1}}$, $T_{\\text{out}} = 573.15\\,\\mathrm{K}$.\n- Case $4$ (lower-temperature extrapolation): $T_{\\text{cal}} = 333.15\\,\\mathrm{K}$, $k_{\\text{cal}} = 2.0\\times10^{-9}\\,\\mathrm{s^{-1}}$, $\\mu_{E_a} = 75\\,\\mathrm{kJ\\,mol^{-1}}$, $\\sigma_{E_a} = 8\\,\\mathrm{kJ\\,mol^{-1}}$, $T_{\\text{out}} = 263.15\\,\\mathrm{K}$.\n- Case $5$ (zero uncertainty in activation energy): $T_{\\text{cal}} = 298.15\\,\\mathrm{K}$, $k_{\\text{cal}} = 3.0\\times10^{-11}\\,\\mathrm{s^{-1}}$, $\\mu_{E_a} = 50\\,\\mathrm{kJ\\,mol^{-1}}$, $\\sigma_{E_a} = 0\\,\\mathrm{kJ\\,mol^{-1}}$, $T_{\\text{out}} = 423.15\\,\\mathrm{K}$.\n\nFinal output format:\n- Your program should produce a single line of output containing a comma-separated list enclosed in square brackets, where each element corresponds to one test case and is itself a list of the four requested numbers in $\\mathrm{s^{-1}}$, rounded to eight significant digits. For example, the output format should look like $[[m_1,\\tilde{m}_1,\\ell_1,u_1],[m_2,\\tilde{m}_2,\\ell_2,u_2],\\dots]$ where $m_i$ denotes the mean, $\\tilde{m}_i$ the median, $\\ell_i$ the lower bound, and $u_i$ the upper bound for case $i$.",
            "solution": "The user provides a problem in computational geochemistry that requires deriving and applying a form of the Arrhenius equation to propagate uncertainty. The problem is scientifically grounded, well-posed, and contains all necessary information for a unique solution.\n\n### Step 1: Derivation of the Rate Constant Relationship\nThe problem is based on the Arrhenius equation, which describes the temperature dependence of a reaction rate constant, $k$:\n$$\nk(T) = A \\exp\\left(-\\frac{E_a}{RT}\\right)\n$$\nHere, $A$ is the pre-exponential factor, $E_a$ is the activation energy, $R$ is the universal gas constant, and $T$ is the absolute temperature.\n\nA calibration measurement provides the rate constant $k_{\\text{cal}}$ at a specific temperature $T_{\\text{cal}}$. This measurement is treated as exact.\n$$\nk_{\\text{cal}} = A \\exp\\left(-\\frac{E_a}{RT_{\\text{cal}}}\\right)\n$$\nWe can solve this equation for the unknown pre-exponential factor $A$:\n$$\nA = k_{\\text{cal}} \\exp\\left(\\frac{E_a}{RT_{\\text{cal}}}\\right)\n$$\nTo predict the rate constant $k_{\\text{out}}$ at a different temperature $T_{\\text{out}}$, we substitute this expression for $A$ back into the general Arrhenius equation:\n$$\nk_{\\text{out}} = k(T_{\\text{out}}) = \\left( k_{\\text{cal}} \\exp\\left(\\frac{E_a}{RT_{\\text{cal}}}\\right) \\right) \\exp\\left(-\\frac{E_a}{RT_{\\text{out}}}\\right)\n$$\nCombining the exponential terms yields the desired relationship, which eliminates the pre-exponential factor:\n$$\nk_{\\text{out}} = k_{\\text{cal}} \\exp\\left(\\frac{E_a}{RT_{\\text{cal}}} - \\frac{E_a}{RT_{\\text{out}}}\\right) = k_{\\text{cal}} \\exp\\left(\\frac{E_a}{R} \\left(\\frac{1}{T_{\\text{cal}}} - \\frac{1}{T_{\\text{out}}}\\right)\\right)\n$$\n\n### Step 2: Uncertainty Propagation\nThe activation energy $E_a$ is the sole source of uncertainty and is modeled as a normal random variable: $E_a \\sim \\mathcal{N}(\\mu_{E_a}, \\sigma_{E_a}^2)$. Our goal is to determine the distribution of $k_{\\text{out}}$ that results from this uncertainty.\n\nLet us define a constant $b$ that encapsulates the temperature dependence:\n$$\nb = \\frac{1}{R} \\left(\\frac{1}{T_{\\text{cal}}} - \\frac{1}{T_{\\text{out}}}\\right)\n$$\nThe expression for $k_{\\text{out}}$ becomes:\n$$\nk_{\\text{out}} = k_{\\text{cal}} \\exp(b E_a)\n$$\nSince $E_a$ is a normal random variable, the exponent $b E_a$ is also a normal random variable. Let $X = E_a$. The random variable $Y = k_{\\text{out}}$ is of the form $c \\exp(\\text{Normal variable})$, which defines a log-normal distribution.\n\nTo find the parameters of this distribution, we take the natural logarithm of $k_{\\text{out}}$:\n$$\n\\ln(k_{\\text{out}}) = \\ln(k_{\\text{cal}}) + b E_a\n$$\nSince $\\ln(k_{\\text{cal}})$ is a constant (as $k_{\\text{cal}}$ is exact) and $E_a$ is a normal random variable, $\\ln(k_{\\text{out}})$ is also normally distributed. Let's find its mean and variance.\nThe mean of $\\ln(k_{\\text{out}})$ is:\n$$\n\\mu_{\\ln k} = E[\\ln(k_{\\text{out}})] = E[\\ln(k_{\\text{cal}}) + b E_a] = \\ln(k_{\\text{cal}}) + b E[E_a] = \\ln(k_{\\text{cal}}) + b \\mu_{E_a}\n$$\nThe variance of $\\ln(k_{\\text{out}})$ is:\n$$\n\\sigma_{\\ln k}^2 = \\text{Var}[\\ln(k_{\\text{out}})] = \\text{Var}[\\ln(k_{\\text{cal}}) + b E_a] = b^2 \\text{Var}[E_a] = b^2 \\sigma_{E_a}^2\n$$\nThus, $\\ln(k_{\\text{out}}) \\sim \\mathcal{N}(\\mu_{\\ln k}, \\sigma_{\\ln k}^2)$, which means $k_{\\text{out}}$ follows a log-normal distribution, $k_{\\text{out}} \\sim \\text{LogNormal}(\\mu_{\\ln k}, \\sigma_{\\ln k}^2)$.\n\n### Step 3: Computation of Statistical Properties\nFor a random variable $Y \\sim \\text{LogNormal}(\\mu, \\sigma^2)$, where $\\mu$ and $\\sigma^2$ are the mean and variance of $\\ln(Y)$, the mean, median, and quantiles are given by standard formulas.\n\n1.  **Mean**: The mean of $k_{\\text{out}}$ is given by:\n    $$\n    E[k_{\\text{out}}] = \\exp\\left(\\mu_{\\ln k} + \\frac{\\sigma_{\\ln k}^2}{2}\\right) = \\exp\\left( \\ln(k_{\\text{cal}}) + b\\mu_{E_a} + \\frac{(b\\sigma_{E_a})^2}{2} \\right)\n    $$\n    $$\n    E[k_{\\text{out}}] = k_{\\text{cal}} \\exp\\left(b\\mu_{E_a} + \\frac{b^2\\sigma_{E_a}^2}{2}\\right)\n    $$\n\n2.  **Median**: The median of $k_{\\text{out}}$ is:\n    $$\n    \\text{Median}[k_{\\text{out}}] = \\exp(\\mu_{\\ln k}) = \\exp(\\ln(k_{\\text{cal}}) + b\\mu_{E_a}) = k_{\\text{cal}} \\exp(b\\mu_{E_a})\n    $$\n    This is the deterministic value of $k_{\\text{out}}$ evaluated at the mean activation energy, $\\mu_{E_a}$.\n\n3.  **Central 95% Interval**: The interval is found by transforming the corresponding interval for the underlying normal distribution, $\\ln(k_{\\text{out}})$. For a central $95\\%$ interval, we need the $2.5$-th and $97.5$-th percentiles. Let $z_p$ be the $p$-th quantile of the standard normal distribution $\\mathcal{N}(0, 1)$. The bounds are:\n    $$\n    \\text{Lower Bound, } \\ell = \\exp(\\mu_{\\ln k} + z_{0.025} \\sigma_{\\ln k})\n    $$\n    $$\n    \\text{Upper Bound, } u = \\exp(\\mu_{\\ln k} + z_{0.975} \\sigma_{\\ln k})\n    $$\n    where $z_{0.025} = -z_{0.975} \\approx -1.959964$, and $\\sigma_{\\ln k} = |b|\\sigma_{E_a}$.\n\n### Special Cases\n-   If $T_{\\text{cal}} = T_{\\text{out}}$, then $b=0$. The predicted rate $k_{\\text{out}} = k_{\\text{cal}}$ is a deterministic constant. Consequently, the mean, median, and interval bounds are all equal to $k_{\\text{cal}}$.\n-   If $\\sigma_{E_a} = 0$, the activation energy is the deterministic value $\\mu_{E_a}$. Then $\\sigma_{\\ln k} = 0$, and the distribution collapses to a single point. The mean, median, and interval bounds are all equal to the deterministic prediction $k_{\\text{cal}} \\exp(b\\mu_{E_a})$.\n\nThe algorithm involves converting input energies from $\\mathrm{kJ\\,mol^{-1}}$ to $\\mathrm{J\\,mol^{-1}}$, calculating the constant $b$, determining the parameters $\\mu_{\\ln k}$ and $\\sigma_{\\ln k}$, and then applying the above formulas to find the mean, median, and interval bounds. All results are reported in $\\mathrm{s^{-1}}$ rounded to eight significant digits.",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Solves the geochemical uncertainty propagation problem for a suite of test cases.\n\n    The solution involves deriving the relationship for an extrapolated rate constant\n    based on the Arrhenius equation and a calibration point. It then propagates the\n    uncertainty from a normally distributed activation energy (Ea) to the predicted\n    rate constant (k_out). The resulting k_out follows a log-normal distribution.\n    The function calculates the mean, median, and central 95% confidence interval\n    for this log-normal distribution for each test case.\n    \"\"\"\n    # Universal gas constant in J mol^-1 K^-1\n    R = 8.31446261815324\n\n    # Test cases parameters:\n    # (T_cal (K), k_cal (s^-1), mu_Ea (kJ/mol), sigma_Ea (kJ/mol), T_out (K))\n    test_cases = [\n        (298.15, 1.0e-10, 60.0, 5.0, 373.15),\n        (298.15, 3.2e-9, 80.0, 10.0, 298.15),\n        (323.15, 5.0e-12, 100.0, 15.0, 573.15),\n        (333.15, 2.0e-9, 75.0, 8.0, 263.15),\n        (298.15, 3.0e-11, 50.0, 0.0, 423.15),\n    ]\n\n    results = []\n\n    for t_cal, k_cal, mu_ea_kj, sigma_ea_kj, t_out in test_cases:\n        # Convert activation energy from kJ/mol to J/mol\n        mu_ea = mu_ea_kj * 1000.0\n        sigma_ea = sigma_ea_kj * 1000.0\n\n        # Handle special cases where uncertainty collapses to zero\n        if t_cal == t_out or sigma_ea == 0:\n            if t_cal == t_out:\n                # If temperatures are the same, k_out = k_cal deterministically.\n                result_val = k_cal\n            else: # sigma_ea == 0 case\n                # If there's no uncertainty in Ea, the result is deterministic.\n                b = (1.0 / t_cal - 1.0 / t_out) / R\n                result_val = k_cal * np.exp(b * mu_ea)\n            \n            # For deterministic cases, mean, median, and bounds are all the same.\n            case_results = [result_val, result_val, result_val, result_val]\n\n        else: # General case with uncertainty\n            # Calculate the temperature-dependent constant 'b'\n            b = (1.0 / t_cal - 1.0 / t_out) / R\n\n            # Parameters of the underlying normal distribution for ln(k_out)\n            mu_ln_k = np.log(k_cal) + b * mu_ea\n            sigma_ln_k = abs(b) * sigma_ea\n\n            # Calculate statistics for the log-normal distribution of k_out\n            \n            # Mean\n            mean_k = np.exp(mu_ln_k + (sigma_ln_k**2) / 2.0)\n            \n            # Median\n            median_k = np.exp(mu_ln_k)\n\n            # Central 95% interval\n            # Find z-scores for 2.5th and 97.5th percentiles\n            z_lower = norm.ppf(0.025)  # approx -1.96\n            z_upper = norm.ppf(0.975)  # approx +1.96\n            \n            lower_bound = np.exp(mu_ln_k + z_lower * sigma_ln_k)\n            upper_bound = np.exp(mu_ln_k + z_upper * sigma_ln_k)\n            \n            case_results = [mean_k, median_k, lower_bound, upper_bound]\n\n        results.append(case_results)\n\n    # Format the final output string according to the problem specification.\n    # Each number is rounded to 8 significant digits.\n    # The final string is a list of lists of numbers, with no spaces.\n    formatted_cases = []\n    for res_list in results:\n        # Use '.8g' format specifier for 8 significant digits.\n        inner_list_str = \",\".join(f\"{num:.8g}\" for num in res_list)\n        formatted_cases.append(f\"[{inner_list_str}]\")\n    \n    final_output_str = f\"[{','.join(formatted_cases)}]\"\n\n    print(final_output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "Geochemical data, often visualized in an Arrhenius plot, can sometimes suggest a change in reaction mechanism across different temperatures, appearing as a \"break\" in the linear trend. This practice introduces a principled statistical approach to determine if such a feature is a true reflection of underlying physics or merely an artifact of measurement noise. By applying information criteria like AIC and BIC, you will learn to quantitatively compare a simple single-regime model against a more complex two-regime model, mastering the art of balancing goodness-of-fit with the penalty for added complexity .",
            "id": "4103254",
            "problem": "Consider geochemical reaction rates for a thermally activated process where molecules must cross an energy barrier before transforming, grounded in the Boltzmann distribution and barrier crossing in statistical mechanics. From these principles, the rate constant depends on temperature in a way that, when expressed in logarithmic form, becomes a linear function of inverse temperature. In natural geological systems, distinct mechanistic regimes may operate across different temperature ranges, leading to a potential piecewise-linear dependence, with a single change-point where the mechanism shifts. Your task is to design a program that performs principled model selection between a single-regime and a two-regime representation of this dependence by using information criteria.\n\nBegin from the following fundamental base and core definitions only: the Boltzmann factor, barrier crossing in statistical mechanics, and the definition of the rate constant as proportional to the probability of surmounting a barrier. Assume a Gaussian error model in the logarithm of the rate constant, with independent and identically distributed residuals. Employ maximum likelihood estimation for the parameters, including an unknown variance, and use the Akaike Information Criterion (AIC) and the Bayesian Information Criterion (BIC) to compare the models. Do not employ any shortcut formulas beyond what follows from the base principles enumerated. Count the free parameters explicitly: for a single-regime representation, the slope and intercept plus the variance; for a two-regime representation, the two slopes, two intercepts, the variance, and one discrete change-point location.\n\nYou will fit two candidate models to each dataset:\n- A single-regime model: one linear relationship in logarithmic rate constant versus inverse temperature.\n- A two-regime model: two linear relationships joined at an unknown change-point in temperature, with the change-point chosen from among the observed temperatures, and each regime having its own slope and intercept.\n\nAssume temperatures are given in kelvin and rate constants in per second. The molar gas constant must be used in joules per mole per kelvin. All energies must be in joules per mole. Your algorithms must compute the maximum likelihood under the Gaussian assumption in the space of the natural logarithm of the rate constant.\n\nFor model comparison, compute the Akaike Information Criterion (AIC) and the Bayesian Information Criterion (BIC) using the maximum likelihood under the Gaussian error model with unknown variance. The parameter count for AIC and BIC must include the variance and the change-point for the two-regime model as described above. Select the preferred model under each criterion by choosing the one with the lower value of the corresponding criterion. Also report the differences between the two-regime and the single-regime criteria (two-regime minus single-regime) to quantify the net penalty of added complexity.\n\nPhysical and numerical units and conventions:\n- Temperature $T$ in $\\mathrm{K}$.\n- Rate constant $k$ in $\\mathrm{s^{-1}}$.\n- Molar gas constant $R$ in $\\mathrm{J\\,mol^{-1}\\,K^{-1}}$.\n- Activation energy $E_{\\mathrm{a}}$ in $\\mathrm{J\\,mol^{-1}}$.\n- Natural logarithms only.\n\nTest suite:\nProvide results for the following three datasets. In each case, construct the natural logarithm of the rate constants from the regime definition and add the deterministic perturbation to obtain the observed logarithms. The deterministic perturbations must be added to the logarithm of the rate constant, not to the rate constant itself.\n\nDataset $\\#1$ (single-regime, broad temperature span):\n- Temperatures $T$: $[300,350,400,450,500,600,700,800,900]$ $\\mathrm{K}$.\n- Parameters: pre-exponential factor $A = 1.0\\times 10^{13}$ $\\mathrm{s^{-1}}$, activation energy $E_{\\mathrm{a}} = 75\\,000$ $\\mathrm{J\\,mol^{-1}}$.\n- Deterministic perturbation added to the logarithm: $\\epsilon(T) = 0.15\\cdot \\sin(T/80)$.\n\nDataset $\\#2$ (two-regime, mechanism change near mid-range temperatures):\n- Temperatures $T$: $[300,350,400,450,500,550,600,650,700,750,800]$ $\\mathrm{K}$.\n- Regime change at $T^{\\star} = 650$ $\\mathrm{K}$.\n- Low-temperature regime parameters: $A_{1} = 1.0\\times 10^{12}$ $\\mathrm{s^{-1}}$, $E_{\\mathrm{a},1} = 80\\,000$ $\\mathrm{J\\,mol^{-1}}$.\n- High-temperature regime parameters: $A_{2} = 5.0\\times 10^{11}$ $\\mathrm{s^{-1}}$, $E_{\\mathrm{a},2} = 60\\,000$ $\\mathrm{J\\,mol^{-1}}$.\n- Deterministic perturbation added to the logarithm: $\\epsilon(T) = 0.12\\cdot \\cos(T/70)$.\n\nDataset $\\#3$ (edge case: small sample and subtle mechanism change):\n- Temperatures $T$: $[500,550,600,650,700,750]$ $\\mathrm{K}$.\n- Regime change at $T^{\\star} = 650$ $\\mathrm{K}$.\n- Low-temperature regime parameters: $A_{1} = 1.0\\times 10^{12}$ $\\mathrm{s^{-1}}$, $E_{\\mathrm{a},1} = 70\\,000$ $\\mathrm{J\\,mol^{-1}}$.\n- High-temperature regime parameters: $A_{2} = 1.0\\times 10^{12}$ $\\mathrm{s^{-1}}$, $E_{\\mathrm{a},2} = 68\\,000$ $\\mathrm{J\\,mol^{-1}}$.\n- Deterministic perturbation added to the logarithm: $\\epsilon(T) = 0.10\\cdot \\sin(T/90)$.\n\nFor each dataset, implement the following steps:\n- Compute the natural logarithm of the rate constants from the regime definition and add the deterministic perturbation to obtain the observed logarithms.\n- Fit the single-regime model using ordinary least squares in logarithm versus inverse temperature.\n- Fit the two-regime model by evaluating all admissible change-points among the observed temperatures subject to at least $2$ points per regime, fitting each regime by ordinary least squares, and selecting the change-point that maximizes the likelihood (equivalently minimizes the residual sum of squares) under the Gaussian assumption.\n- Compute the maximum log-likelihood for each model using the Gaussian log-likelihood with variance given by its maximum likelihood estimate.\n- Compute the Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC) for each model, using the parameter counts specified above.\n- Decide the preferred model under AIC and under BIC.\n- Report the differences $\\Delta \\mathrm{AIC} = \\mathrm{AIC}_{\\text{two}} - \\mathrm{AIC}_{\\text{single}}$ and $\\Delta \\mathrm{BIC} = \\mathrm{BIC}_{\\text{two}} - \\mathrm{BIC}_{\\text{single}}$ so that negative values indicate the two-regime model is favored.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each dataset, append four values in order: the AIC-selected model encoded as $1$ for single-regime or $2$ for two-regime, the BIC-selected model encoded in the same way, the float value of $\\Delta \\mathrm{AIC}$, and the float value of $\\Delta \\mathrm{BIC}$. Concatenate these quadruplets for the three datasets into a single flat list. For example, the output should look like $[\\text{d1\\_AIC\\_choice},\\text{d1\\_BIC\\_choice},\\text{d1\\_DeltaAIC},\\text{d1\\_DeltaBIC},\\text{d2\\_AIC\\_choice},\\ldots,\\text{d3\\_DeltaBIC}]$ with all numbers given in their natural numeric forms, expressed without any units.",
            "solution": "The user has provided a problem in computational geochemistry requiring a quantitative comparison between two models for the temperature dependence of a reaction rate constant, $k$. The problem is grounded in the Arrhenius equation, derived from first principles of statistical mechanics. The task is to implement a model selection procedure based on the Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC).\n\n### Theoretical Foundation and Model Specification\n\nThe foundation of this problem is the Arrhenius equation, which describes the temperature dependence of reaction rate constants:\n$$\nk = A e^{-E_{\\mathrm{a}} / (RT)}\n$$\nwhere $k$ is the rate constant, $A$ is the pre-exponential factor, $E_{\\mathrm{a}}$ is the activation energy, $R$ is the molar gas constant, and $T$ is the absolute temperature.\n\nTo analyze this relationship with linear models, we take the natural logarithm of the equation:\n$$\n\\ln(k) = \\ln(A) - \\frac{E_{\\mathrm{a}}}{R} \\left(\\frac{1}{T}\\right)\n$$\nThis equation is in the form of a straight line, $y = \\beta_0 + \\beta_1 x$, where:\n- The dependent variable is $y = \\ln(k)$.\n- The independent variable is $x = 1/T$.\n- The intercept is $\\beta_0 = \\ln(A)$.\n- The slope is $\\beta_1 = -E_{\\mathrm{a}}/R$.\n\nThe problem requires comparing two models for the relationship between $y$ and $x$:\n\n1.  **Single-Regime Model**: A single linear relationship holds across the entire temperature range. The model is $y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i$.\n2.  **Two-Regime Model**: The temperature range is split into two distinct regimes at a change-point temperature. Each regime has its own linear relationship, implying different pre-exponential factors and activation energies. The model is piecewise linear.\n\nWe assume the errors, $\\epsilon_i$, are independent and identically distributed (i.i.d.) following a normal distribution with mean $0$ and unknown variance $\\sigma^2$, i.e., $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$.\n\n### Maximum Likelihood Estimation\n\nUnder the Gaussian error assumption, the log-likelihood function for a given model with parameters $\\boldsymbol{\\theta}$ and variance $\\sigma^2$ for a dataset of $n$ points $(x_i, y_i)$ is:\n$$\n\\mathcal{L}(\\boldsymbol{\\theta}, \\sigma^2 | \\mathbf{y}) = -\\frac{n}{2}\\ln(2\\pi) - \\frac{n}{2}\\ln(\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - f(x_i; \\boldsymbol{\\theta}))^2\n$$\nwhere $f(x_i; \\boldsymbol{\\theta})$ is the prediction from the model. The term $\\sum_{i=1}^n (y_i - f(x_i; \\boldsymbol{\\theta}))^2$ is the Residual Sum of Squares (RSS).\n\nTo find the maximum likelihood estimates (MLEs), we first find the parameters $\\boldsymbol{\\theta}$ that minimize the RSS. For linear and piecewise-linear models, this is achieved through Ordinary Least Squares (OLS). Let the minimum RSS for a model be $\\mathrm{RSS}_{\\text{min}}$.\n\nNext, we find the MLE for the variance $\\sigma^2$ by differentiating the log-likelihood with respect to $\\sigma^2$ and setting it to zero. This gives:\n$$\n\\hat{\\sigma}^2_{\\text{ML}} = \\frac{\\mathrm{RSS}_{\\text{min}}}{n}\n$$\nSubstituting this back into the log-likelihood function gives the maximum log-likelihood, $\\mathcal{L}_{\\text{max}}$:\n$$\n\\mathcal{L}_{\\text{max}} = -\\frac{n}{2} \\left[ \\ln(2\\pi) + \\ln\\left(\\frac{\\mathrm{RSS}_{\\text{min}}}{n}\\right) + 1 \\right]\n$$\n\n### Model Fitting Procedure\n\n**Single-Regime Model:**\nThe model has two parameters, $\\beta_0$ and $\\beta_1$. We fit a single line to all $n$ data points $(\\frac{1}{T_i}, \\ln k_i)$ using OLS. This procedure yields the coefficients that minimize the RSS, which we denote as $\\mathrm{RSS}_1$.\n\n**Two-Regime Model:**\nThis model involves two sets of linear parameters $(\\beta_{0,1}, \\beta_{1,1})$ and $(\\beta_{0,2}, \\beta_{1,2})$ and a change-point. The change-point is found by an exhaustive search. We consider all possible splits of the temperature-sorted data into two contiguous segments, with the constraint that each segment must contain at least two data points.\nFor each potential split, we perform two independent OLS fits, one for each data segment. The total RSS for that split is the sum of the RSS from the two fits. The optimal change-point is the one that minimizes this total RSS. Let this minimum total RSS be $\\mathrm{RSS}_2$. This approach ensures we find the maximum likelihood estimate for the piecewise model parameters and the change-point location simultaneously. The common variance for the entire model is estimated using this total RSS: $\\hat{\\sigma}^2_{\\text{ML},2} = \\mathrm{RSS}_2 / n$.\n\n### Model Selection using Information Criteria\n\nWe use AIC and BIC to compare the two models. These criteria balance model fit (measured by $\\mathcal{L}_{\\text{max}}$) with model complexity (measured by the number of parameters, $p$).\n\n- **Akaike Information Criterion (AIC):**\n  $$\n  \\mathrm{AIC} = 2p - 2\\mathcal{L}_{\\text{max}}\n  $$\n- **Bayesian Information Criterion (BIC):**\n  $$\n  \\mathrm{BIC} = p \\ln(n) - 2\\mathcal{L}_{\\text{max}}\n  $$\n\nThe model with the lower AIC or BIC value is preferred. The number of parameters, $p$, is defined by the problem statement:\n- For the single-regime model ($p_1$): intercept, slope, and variance. Total $p_1 = 3$.\n- For the two-regime model ($p_2$): two intercepts, two slopes, one shared variance, and one discrete change-point location. Total $p_2 = 6$.\n\nWe compute $\\mathrm{AIC}_1, \\mathrm{BIC}_1$ for the single-regime model and $\\mathrm{AIC}_2, \\mathrm{BIC}_2$ for the two-regime model. The final outputs include the preferred model under each criterion and the differences $\\Delta \\mathrm{AIC} = \\mathrm{AIC}_2 - \\mathrm{AIC}_1$ and $\\Delta \\mathrm{BIC} = \\mathrm{BIC}_2 - \\mathrm{BIC}_1$. A negative delta indicates that the more complex two-regime model is favored.\n\n### Algorithm and Implementation\n\nThe overall algorithm proceeds as follows for each dataset:\n1.  **Data Generation**: Construct the vectors of temperatures $T$, inverse temperatures $x=1/T$, and observed log-rate constants $y = \\ln(k)_{\\text{true}} + \\epsilon(T)$.\n2.  **Single-Regime Fit**: Perform an OLS fit of $y$ on $x$ for all data points to find $\\mathrm{RSS}_1$. Calculate $\\mathcal{L}_{\\text{max},1}$, $\\mathrm{AIC}_1$, and $\\mathrm{BIC}_1$ using $p_1=3$.\n3.  **Two-Regime Fit**: Iterate through all valid change-point indices $j \\in [2, n-2]$. For each $j$, split the data, perform two OLS fits, and calculate the total $\\mathrm{RSS}_{\\text{total}}(j)$. The minimum of these values is $\\mathrm{RSS}_2$. Calculate $\\mathcal{L}_{\\text{max},2}$, $\\mathrm{AIC}_2$, and $\\mathrm{BIC}_2$ using $p_2=6$.\n4.  **Comparison**: Determine the preferred model for AIC and BIC by comparing their values. Calculate $\\Delta \\mathrm{AIC}$ and $\\Delta \\mathrm{BIC}$.\n5.  **Output**: Collect and format the results as specified. A Python script using the `numpy` library is sufficient for all numerical computations, including the OLS fits via `numpy.linalg.lstsq`.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the model selection analysis for all datasets.\n    \"\"\"\n    R = 8.314462618  # Molar gas constant in J/(mol*K)\n\n    # Define test cases\n    test_cases = [\n        {\n            \"name\": \"Dataset 1\",\n            \"T\": np.array([300, 350, 400, 450, 500, 600, 700, 800, 900]),\n            \"params\": {\"A\": 1.0e13, \"Ea\": 75000},\n            \"perturbation_func\": lambda T: 0.15 * np.sin(T / 80),\n        },\n        {\n            \"name\": \"Dataset 2\",\n            \"T\": np.array([300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800]),\n            \"params\": {\n                \"T_star\": 650,\n                \"A1\": 1.0e12, \"Ea1\": 80000,\n                \"A2\": 5.0e11, \"Ea2\": 60000,\n            },\n            \"perturbation_func\": lambda T: 0.12 * np.cos(T / 70),\n        },\n        {\n            \"name\": \"Dataset 3\",\n            \"T\": np.array([500, 550, 600, 650, 700, 750]),\n            \"params\": {\n                \"T_star\": 650,\n                \"A1\": 1.0e12, \"Ea1\": 70000,\n                \"A2\": 1.0e12, \"Ea2\": 68000,\n            },\n            \"perturbation_func\": lambda T: 0.10 * np.sin(T / 90),\n        },\n    ]\n\n    final_results = []\n    for case in test_cases:\n        T_arr = case[\"T\"]\n        params = case[\"params\"]\n        perturbation_func = case[\"perturbation_func\"]\n        \n        # --- Data Generation ---\n        x_inv_T = 1.0 / T_arr\n        ln_k = np.zeros_like(T_arr, dtype=float)\n\n        if \"A1\" in params:  # Two-regime data generation\n            T_star, A1, Ea1, A2, Ea2 = params[\"T_star\"], params[\"A1\"], params[\"Ea1\"], params[\"A2\"], params[\"Ea2\"]\n            low_T_mask = T_arr = T_star\n            high_T_mask = T_arr  T_star\n            ln_k[low_T_mask] = np.log(A1) - Ea1 / (R * T_arr[low_T_mask])\n            ln_k[high_T_mask] = np.log(A2) - Ea2 / (R * T_arr[high_T_mask])\n        else:  # Single-regime data generation\n            A, Ea = params[\"A\"], params[\"Ea\"]\n            ln_k = np.log(A) - Ea / (R * T_arr)\n        \n        perturbation = perturbation_func(T_arr)\n        y_obs = ln_k + perturbation\n        n = len(T_arr)\n\n        # --- Model Fitting and Evaluation ---\n        # Single-regime model\n        p1 = 3\n        rss1 = fit_ols(x_inv_T, y_obs)\n        logL1 = calculate_log_likelihood(rss1, n)\n        aic1 = 2 * p1 - 2 * logL1\n        bic1 = p1 * np.log(n) - 2 * logL1\n\n        # Two-regime model\n        p2 = 6\n        best_rss2 = np.inf\n        # Iterate through possible change points. The split is after j points.\n        # j must be at least 2, and the second partition (n-j) must be at least 2.\n        # So j can range from 2 to n-2.\n        for j in range(2, n - 1): \n            x1, y1 = x_inv_T[:j], y_obs[:j]\n            x2, y2 = x_inv_T[j:], y_obs[j:]\n            \n            rss_p1 = fit_ols(x1, y1)\n            rss_p2 = fit_ols(x2, y2)\n            current_rss2_total = rss_p1 + rss_p2\n            \n            if current_rss2_total  best_rss2:\n                best_rss2 = current_rss2_total\n        \n        rss2 = best_rss2\n        logL2 = calculate_log_likelihood(rss2, n)\n        aic2 = 2 * p2 - 2 * logL2\n        bic2 = p2 * np.log(n) - 2 * logL2\n\n        # --- Model Comparison ---\n        aic_choice = 2 if aic2  aic1 else 1\n        bic_choice = 2 if bic2  bic1 else 1\n        delta_aic = aic2 - aic1\n        delta_bic = bic2 - bic1\n        \n        final_results.extend([aic_choice, bic_choice, delta_aic, delta_bic])\n    \n    # Format and print the final output\n    print(f\"[{','.join(map(str, final_results))}]\")\n\n\ndef fit_ols(x, y):\n    \"\"\"\n    Performs Ordinary Least Squares fit for y = b0 + b1*x and returns the RSS.\n    \"\"\"\n    A = np.vstack([np.ones_like(x), x]).T\n    n_pts, n_params = A.shape\n    _, rss_tuple, _, _ = np.linalg.lstsq(A, y, rcond=None)\n    \n    # lstsq returns an empty array for RSS if n_pts = n_params\n    if len(rss_tuple) == 0:\n        return 0.0\n    return rss_tuple[0]\n\n\ndef calculate_log_likelihood(rss, n):\n    \"\"\"\n    Calculates the maximum log-likelihood for a Gaussian model.\n    \"\"\"\n    if rss = 1e-15:  # Handle perfect or near-perfect fits to avoid log(0)\n        return np.inf  # A perfect fit implies infinite likelihood\n    \n    sigma2_ml = rss / n\n    log_likelihood = -(n / 2.0) * (np.log(2 * np.pi) + np.log(sigma2_ml) + 1.0)\n    return log_likelihood\n\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}