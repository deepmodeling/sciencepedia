{
    "hands_on_practices": [
        {
            "introduction": "The hallmark of Fourier pseudo-spectral methods is their exceptional accuracy for smooth, periodic functions. This exercise provides a direct, hands-on opportunity to witness this 'spectral accuracy' by implementing the fundamental algorithm for spectral differentiation. By transforming a function to Fourier space, performing differentiation via simple multiplication, and transforming back, you will verify that the numerical derivative can match the analytical result to machine precision for resolved wavenumbers .",
            "id": "4066305",
            "problem": "Consider a periodic, one-dimensional domain $[0,2\\pi)$ that models a uniform direction in a Direct Numerical Simulation of reacting flows in computational combustion where high-fidelity gradients are required for species and temperature fields. Let $N$ denote the number of grid points, and let the uniform grid be defined by $x_j = \\frac{2\\pi}{N} j$ for $j \\in \\{0,1,\\dots,N-1\\}$, with angles in radians. Let $f(x)$ be a scalar field sampled on this grid. The pseudo-spectral first derivative on the periodic domain uses the Discrete Fourier Transform (DFT) and the Fast Fourier Transform (FFT) computational algorithm, which are well-tested numerical tools for periodic problems.\n\nStarting from the Fourier series representation of a sufficiently smooth periodic function and the associated Discrete Fourier Transform (DFT) pair on the grid $x_j$, derive the pseudo-spectral first derivative operator for the function $f(x) = \\sin(kx)$, and implement it to compute the pointwise derivative on the grid for the case $N=32$ and $k=7$. The derivation must begin from the standard DFT definitions and the property that differentiation in the physical space corresponds to multiplication by the wavenumber in the spectral space, without presupposing the final algorithm.\n\nYou must verify that the maximum pointwise absolute error between the pseudo-spectral derivative and the exact analytical derivative is machine zero, quantified by a threshold $T$ appropriate for double-precision floating-point arithmetic. For this problem, define machine zero as $\\lvert \\text{error} \\rvert \\le T$ with $T = 10^{-12}$.\n\nYour program must:\n- Use angles in radians.\n- Use $N=32$ for all tests.\n- Construct the periodic grid $x_j$ on $[0,2\\pi)$.\n- For each test case, define $f_j = f(x_j)$ with $f(x) = \\sin(kx)$ for the given integer $k$.\n- Compute the pseudo-spectral first derivative using a DFT/FFT-based approach on the periodic grid.\n- Compute the exact analytical derivative for $f(x)=\\sin(kx)$, which is $f'(x)=k\\cos(kx)$, and evaluate it at the grid points.\n- Compute the maximum pointwise absolute error over the grid and return a boolean indicating whether it is less than or equal to $T$.\n\nTest Suite:\n- General resolvable mode: $N=32$, $k=7$.\n- High but resolvable mode: $N=32$, $k=15$.\n- Nyquist mode edge case: $N=32$, $k=16$.\n- Aliasing beyond Nyquist: $N=32$, $k=17$.\n- Trivial constant derivative case: $N=32$, $k=0$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3]\"), where each entry is a boolean indicating whether the maximum pointwise absolute error is less than or equal to $T$ for the corresponding test case, in the order listed above. No other output is permitted.",
            "solution": "The problem is valid as it is scientifically grounded in the principles of Fourier analysis and numerical methods, is well-posed with a clear objective and all necessary data, and is expressed in objective, formal language. The test cases are standard in the analysis of spectral methods, designed to probe the behavior of the algorithm for resolved modes, at the Nyquist limit, and under aliasing.\n\nWe are tasked with deriving and implementing the pseudo-spectral first derivative operator for a periodic function $f(x)$ on the domain $[0, 2\\pi)$. The derivation will begin from the principles of Fourier series and the Discrete Fourier Transform (DFT).\n\nLet a sufficiently smooth, $2\\pi$-periodic function $f(x)$ be represented by its complex Fourier series:\n$$\nf(x) = \\sum_{m=-\\infty}^{\\infty} \\hat{f}_m e^{imx}\n$$\nwhere $\\hat{f}_m$ are the complex Fourier coefficients and $m$ is the integer wavenumber. Differentiating with respect to $x$ yields:\n$$\nf'(x) = \\frac{d}{dx} \\sum_{m=-\\infty}^{\\infty} \\hat{f}_m e^{imx} = \\sum_{m=-\\infty}^{\\infty} (im) \\hat{f}_m e^{imx}\n$$\nThis demonstrates the fundamental principle of spectral methods: differentiation in physical space is equivalent to multiplication by $im$ in the spectral (Fourier) space, where $i = \\sqrt{-1}$.\n\nIn a computational setting, the continuous function $f(x)$ is sampled on a discrete grid. The problem defines a uniform grid of $N$ points $x_j = \\frac{2\\pi}{N} j$ for $j \\in \\{0, 1, \\dots, N-1\\}$. The function values on this grid are denoted by $f_j = f(x_j)$. The continuous Fourier series is replaced by the Discrete Fourier Transform (DFT) pair. The forward DFT (analysis transform) and inverse DFT (synthesis transform) are defined as:\n$$\n\\hat{f}_m^{\\text{DFT}} = \\sum_{j=0}^{N-1} f_j e^{-imx_j} = \\sum_{j=0}^{N-1} f_j e^{-i \\frac{2\\pi mj}{N}}, \\quad m \\in \\{0, 1, \\dots, N-1\\}\n$$\n$$\nf_j = \\frac{1}{N} \\sum_{m=0}^{N-1} \\hat{f}_m^{\\text{DFT}} e^{imx_j} = \\frac{1}{N} \\sum_{m=0}^{N-1} \\hat{f}_m^{\\text{DFT}} e^{i \\frac{2\\pi mj}{N}}, \\quad j \\in \\{0, 1, \\dots, N-1\\}\n$$\nThe pseudo-spectral differentiation algorithm leverages this discrete framework to approximate the derivative $f'(x_j)$:\n\n1.  **Transform to Spectral Space**: Compute the DFT of the discrete function values $f_j$ to obtain the spectral coefficients $\\hat{f}_m^{\\text{DFT}}$. This is typically done efficiently using the Fast Fourier Transform (FFT) algorithm.\n    $$\n    \\{\\hat{f}_0^{\\text{DFT}}, \\hat{f}_1^{\\text{DFT}}, \\dots, \\hat{f}_{N-1}^{\\text{DFT}}\\} = \\text{FFT}(\\{f_0, f_1, \\dots, f_{N-1}\\})\n    $$\n\n2.  **Differentiate in Spectral Space**: Multiply each spectral coefficient $\\hat{f}_m^{\\text{DFT}}$ by its corresponding effective wavenumber, scaled by $i$. The DFT indices $m \\in \\{0, 1, \\dots, N-1\\}$ must be mapped to the physical wavenumbers they represent. For a real-valued signal, the wavenumbers are symmetric about zero. For an even number of points $N$, the DFT indices are mapped to an effective wavenumber vector $m'_{\\text{eff}}$ as follows:\n    -   For $0 \\le m  N/2$, the index $m$ corresponds to the physical wavenumber $m' = m$.\n    -   For $N/2  m  N$, the index $m$ corresponds to a negative (aliased) wavenumber. The mapping is $m' = m - N$. For example, $m=N-1$ corresponds to $m'=-1$.\n    -   The index $m=N/2$ is special and corresponds to the Nyquist wavenumber. For a real-valued input function $f_j$, its derivative $f'_j$ must also be real. The inverse DFT of a sequence $\\hat{g}_m$ produces a real-valued result if and only if the sequence has Hermitian symmetry, i.e., $\\hat{g}_m = \\overline{\\hat{g}_{N-m}}$ (where the bar denotes complex conjugation). Let's denote the DFT of the derivative as $\\hat{g}_m = i m'_{\\text{eff}}(m) \\hat{f}_m^{\\text{DFT}}$. For a real input $f_j$, $\\hat{f}_m^{\\text{DFT}} = \\overline{\\hat{f}_{N-m}^{\\text{DFT}}}$. For $m \\ne 0, N/2$, we have $m'_{\\text{eff}}(N-m) = (N-m)-N = -m = -m'_{\\text{eff}}(m)$. Then $\\hat{g}_{N-m} = i m'_{\\text{eff}}(N-m) \\hat{f}_{N-m}^{\\text{DFT}} = -im'_{\\text{eff}}(m) \\overline{\\hat{f}_m^{\\text{DFT}}} = \\overline{i m'_{\\text{eff}}(m) \\hat{f}_m^{\\text{DFT}}} = \\overline{\\hat{g}_m}$. The symmetry holds. However, at the Nyquist frequency $m=N/2$, $m' = N/2$. For a real signal, $\\hat{f}_{N/2}^{\\text{DFT}}$ must be a real number. Differentiating would yield $\\hat{g}_{N/2} = i(N/2)\\hat{f}_{N/2}^{\\text{DFT}}$, which is purely imaginary. This breaks the Hermitian symmetry, as $\\hat{g}_{N/2} \\ne \\overline{\\hat{g}_{N/2}}$ unless it is zero. To ensure the derivative of a real function remains real, a common convention is to set the derivative of the Nyquist mode to zero.\n\n    Therefore, the effective wavenumber vector $m'_{\\text{eff}}$ applied to the DFT indices $m \\in \\{0, 1, \\dots, N-1\\}$ is:\n    $$\n    m'_{\\text{eff}}(m) = \\begin{cases} m  \\text{if } 0 \\le m  N/2 \\\\ 0  \\text{if } m = N/2 \\\\ m-N  \\text{if } N/2  m  N \\end{cases}\n    $$\n    The spectral coefficients of the derivative, $\\hat{g}_m^{\\text{DFT}}$, are then computed as:\n    $$\n    \\hat{g}_m^{\\text{DFT}} = i m'_{\\text{eff}}(m) \\hat{f}_m^{\\text{DFT}}\n    $$\n\n3.  **Transform back to Physical Space**: Compute the inverse DFT of the modified spectral coefficients $\\hat{g}_m^{\\text{DFT}}$ to obtain the derivative values $f'_j$ on the grid.\n    $$\n    \\{f'_0, f'_1, \\dots, f'_{N-1}\\} = \\text{IFFT}(\\{\\hat{g}_0^{\\text{DFT}}, \\hat{g}_1^{\\text{DFT}}, \\dots, \\hat{g}_{N-1}^{\\text{DFT}}\\})\n    $$\n\nFor the function $f(x) = \\sin(kx) = \\frac{e^{ikx} - e^{-ikx}}{2i}$, the analytical derivative is $f'(x) = k\\cos(kx)$.\n-   **Cases $k=7$ and $k=15$ ($N=32$):** Since $0  k  N/2 = 16$, the wavenumber is well-resolved by the grid. The DFT can exactly represent the two sinusoidal components $e^{ikx}$ and $e^{-ikx}$. The pseudo-spectral derivative will be numerically exact, and the error will be on the order of machine precision. The boolean check against $T=10^{-12}$ should be true.\n-   **Case $k=16$ ($N=32$):** This is the Nyquist wavenumber, $k=N/2$. The function values on the grid are $f_j = \\sin(16 \\cdot \\frac{2\\pi j}{32}) = \\sin(\\pi j) = 0$ for all $j$. The DFT of an all-zero vector is an all-zero vector. The numerical derivative is therefore zero. The analytical derivative is $f'(x_j) = 16\\cos(16x_j) = 16\\cos(\\pi j) = 16(-1)^j$. The numerical and analytical results differ significantly, so the error will be large. The boolean check will be false.\n-   **Case $k=17$ ($N=32$):** This wavenumber is beyond the Nyquist limit, $|k| > N/2$. The signal is aliased. On the grid, the frequency $k=17$ is indistinguishable from the frequency $k' = k-N = 17-32 = -15$. That is, $\\sin(17x_j) = \\sin((32-15)x_j) = \\sin(2\\pi j - 15x_j) = \\sin(-15x_j) = -\\sin(15x_j)$. The numerical method will compute the derivative of $-\\sin(15x)$, which is $-15\\cos(15x)$. This is not equal to the true derivative, $17\\cos(17x)$. The error will be large, and the boolean check will be false.\n-   **Case $k=0$ ($N=32$):** The function is $f(x) = \\sin(0) = 0$ for all $x$. The numerical derivative is zero. The analytical derivative is $f'(x) = 0 \\cdot \\cos(0) = 0$. The error is identically zero. The boolean check will be true.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the pseudo-spectral derivative for f(x) = sin(kx) on a periodic grid\n    and verifies its accuracy against the analytical derivative for several test cases.\n    \"\"\"\n    # Define problem constants\n    N = 32\n    T = 1e-12\n\n    # Define the test suite of wavenumbers k\n    test_cases = [\n        7,  # General resolvable mode\n        15, # High but resolvable mode\n        16, # Nyquist mode edge case\n        17, # Aliasing beyond Nyquist\n        0,  # Trivial constant derivative case\n    ]\n\n    results = []\n    \n    # Construct the periodic grid\n    # x_j = (2*pi/N) * j for j in {0, ..., N-1}\n    x_grid = (2 * np.pi / N) * np.arange(N)\n\n    # Define the effective wavenumbers for differentiation\n    # For a real signal, the derivative of the Nyquist component is set to 0\n    # to ensure the resulting derivative is also real.\n    # np.fft.fftfreq(N) * N gives [0, 1, ..., N/2-1, -N/2, -N/2+1, ..., -1]\n    m_eff = np.fft.fftfreq(N) * N\n    # Set the derivative of the Nyquist mode to zero\n    if N % 2 == 0:\n        m_eff[N // 2] = 0.0\n\n    for k in test_cases:\n        # 1. Define the function f(x) = sin(kx) on the grid\n        f_vals = np.sin(k * x_grid)\n\n        # 2. Compute the pseudo-spectral first derivative\n        # a. Forward FFT to get spectral coefficients\n        f_hat = np.fft.fft(f_vals)\n\n        # b. Multiply by i*m_eff in spectral space\n        df_hat = 1j * m_eff * f_hat\n\n        # c. Inverse FFT to get derivative in physical space\n        # Result should be real; take the real part to discard negligible\n        # imaginary components from floating-point inaccuracies.\n        df_dx_spectral = np.real(np.fft.ifft(df_hat))\n\n        # 3. Compute the exact analytical derivative f'(x) = k*cos(kx) on the grid\n        df_dx_analytical = k * np.cos(k * x_grid)\n\n        # 4. Compute the maximum pointwise absolute error\n        max_abs_error = np.max(np.abs(df_dx_spectral - df_dx_analytical))\n\n        # 5. Verify if the error is within the specified tolerance T\n        results.append(max_abs_error = T)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While spectral methods are globally accurate, compact finite difference schemes offer an alternative path to high-order accuracy using local stencils. This approach leads to implicit formulations that require solving a banded matrix system but confines data dependencies, which is advantageous in many parallel computing architectures. This practice will guide you through the foundational process of using Taylor series expansions to derive the coefficients of a fourth-order accurate compact scheme for the second derivative and determine its leading-order error .",
            "id": "4066280",
            "problem": "Consider a one-dimensional reacting mixture with constant molecular diffusivity on a uniform grid used in Computational Fluid Dynamics (CFD) for Computational Combustion. Let $u(x)$ be a smooth scalar field (e.g., a species mass fraction) sampled at nodes $x_i = x_0 + i h$ with uniform spacing $h$. You aim to construct a compact, centered, fourth-order accurate finite difference scheme to approximate the second derivative $u''(x_i)$ that yields a pentadiagonal left-hand side matrix when assembled over all grid points.\n\nAssume periodic boundary conditions so that interior formulas apply at all nodes. Seek a symmetric compact relation of the form\n$$\na\\,u''_{i-2} + b\\,u''_{i-1} + c\\,u''_{i} + b\\,u''_{i+1} + a\\,u''_{i+2}\n= \\frac{1}{h^{2}}\\left[ A\\left(u_{i-2} - 2 u_{i} + u_{i+2}\\right) + B\\left(u_{i-1} - 2 u_{i} + u_{i+1}\\right) \\right],\n$$\nwhere $a$, $b$, $c$, $A$, and $B$ are constants independent of $i$, and the stencil is centered and symmetric. For uniqueness and to minimize computational bandwidth of the explicit operator, impose the normalization and bandwidth constraints $c = 1$, $A = 0$, and $B = 1$.\n\nUsing Taylor series expansions about $x_i$, enforce fourth-order consistency of the scheme by matching terms through $\\mathcal{O}(h^{2})$ and then determine the leading-order local truncation error. Specifically:\n\n- Determine $a$ and $b$ such that the scheme is consistent and achieves fourth-order accuracy for $u''(x_i)$.\n- Verify the order of accuracy by performing a Taylor expansion and identify the leading nonzero truncation term.\n- Report the leading local truncation error in the form $C_{\\mathrm{TE}}\\,h^{4}\\,u^{(6)}(x_i)$, giving the exact rational value of the constant $C_{\\mathrm{TE}}$.\n\nExpress your final answer as the row matrix containing the five scheme coefficients and the truncation error constant, in the order $\\left(a,\\,b,\\,c,\\,A,\\,B,\\,C_{\\mathrm{TE}}\\right)$. Provide exact rational values (no rounding).",
            "solution": "The user wants me to act as a meticulous STEM professor and solve the given problem.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\nThe problem provides a general form for a compact finite difference scheme:\n$$\na\\,u''_{i-2} + b\\,u''_{i-1} + c\\,u''_{i} + b\\,u''_{i+1} + a\\,u''_{i+2}\n= \\frac{1}{h^{2}}\\left[ A\\left(u_{i-2} - 2 u_{i} + u_{i+2}\\right) + B\\left(u_{i-1} - 2 u_{i} + u_{i+1}\\right) \\right]\n$$\nwhere $u_i = u(x_i)$ and $u''_i = u''(x_i)$ on a uniform grid with spacing $h$.\n\nThe following constraints are imposed:\n1.  The scheme is centered and symmetric. This is already reflected in the form of the equation with coefficients $a$ and $b$.\n2.  Normalization and bandwidth constraints: $c = 1$, $A = 0$, and $B = 1$.\n3.  The task is to determine the coefficients $a$ and $b$ to achieve fourth-order accuracy.\n4.  The task is to find the leading-order local truncation error in the form $C_{\\mathrm{TE}}\\,h^{4}\\,u^{(6)}(x_i)$.\n5.  The final answer must be the set of values $(a, b, c, A, B, C_{\\mathrm{TE}})$.\n\n**Step 2: Validate Using Extracted Givens**\n\n- **Scientifically Grounded:** The problem is a standard exercise in the field of numerical analysis, specifically in the derivation of high-order finite difference schemes for solving differential equations. This topic is fundamental to computational fluid dynamics and computational combustion. The problem is scientifically and mathematically sound.\n- **Well-Posed:** The problem is well-posed. It provides a clear objective (find coefficients and error term), a set of constraints (symmetry, normalization), and a standard method of solution (Taylor series expansion). These conditions lead to a unique and meaningful solution.\n- **Objective:** The problem is stated in precise, objective mathematical language, free from ambiguity or subjective claims.\n- **Completeness and Consistency:** The problem provides all necessary information. The constraints are consistent and sufficient to determine the unknown coefficients.\n\n**Step 3: Verdict and Action**\n\nThe problem is deemed **valid**. I will proceed with the solution.\n\n### Solution\n\nThe objective is to determine the coefficients $a$ and $b$ for the given compact finite difference scheme to achieve fourth-order accuracy and to find the corresponding leading truncation error.\n\nFirst, we apply the given constraints $c=1$, $A=0$, and $B=1$ to the general form of the scheme. This simplifies the equation to:\n$$\na\\,u''_{i-2} + b\\,u''_{i-1} + u''_{i} + b\\,u''_{i+1} + a\\,u''_{i+2}\n= \\frac{1}{h^{2}}\\left(u_{i-1} - 2 u_{i} + u_{i+1}\\right)\n$$\nThe local truncation error, $T_i$, is defined by substituting the exact solution $u(x)$ into the scheme. The terms are rearranged so that $T_i=0$ for an exact solution if the scheme were perfect.\n$$\nT_i = \\left( a u''_{i-2} + b u''_{i-1} + u''_{i} + b u''_{i+1} + a u''_{i+2} \\right) - \\frac{1}{h^2} \\left( u_{i-1} - 2u_i + u_{i+1} \\right)\n$$\nTo determine the coefficients and the order of accuracy, we expand each term in a Taylor series about the point $x_i$, assuming $u(x)$ is sufficiently smooth. Let $u_i^{(n)}$ denote the $n$-th derivative of $u$ at $x_i$.\n\nThe expansions for the function values are:\n$$\nu_{i \\pm k} = u(x_i \\pm kh) = u_i \\pm (kh)u_i' + \\frac{(kh)^2}{2!}u_i'' \\pm \\frac{(kh)^3}{3!}u_i''' + \\frac{(kh)^4}{4!}u_i^{(4)} \\pm \\frac{(kh)^5}{5!}u_i^{(5)} + \\frac{(kh)^6}{6!}u_i^{(6)} + \\mathcal{O}(h^7)\n$$\nThe right-hand side (RHS) operator involves the standard second-order central difference stencil:\n$$\nu_{i-1} - 2u_i + u_{i+1} = \\left(u_i - hu_i' + \\frac{h^2}{2}u_i'' - \\dots\\right) - 2u_i + \\left(u_i + hu_i' + \\frac{h^2}{2}u_i'' + \\dots\\right)\n$$\nBy summing the series for $u_{i+1}$ and $u_{i-1}$, the odd-powered terms in $h$ cancel out:\n$$\nu_{i-1} - 2u_i + u_{i+1} = 2\\left(\\frac{h^2}{2}u_i'' + \\frac{h^4}{24}u_i^{(4)} + \\frac{h^6}{720}u_i^{(6)}\\right) + \\mathcal{O}(h^8) = h^2 u_i'' + \\frac{h^4}{12}u_i^{(4)} + \\frac{h^6}{360}u_i^{(6)} + \\mathcal{O}(h^8)\n$$\nThus, the RHS of the truncation error expression is:\n$$\n\\frac{1}{h^2}\\left(u_{i-1} - 2u_i + u_{i+1}\\right) = u_i'' + \\frac{h^2}{12}u_i^{(4)} + \\frac{h^4}{360}u_i^{(6)} + \\mathcal{O}(h^6)\n$$\nNext, we expand the terms on the left-hand side (LHS) of the truncation error expression. The expansions for the second derivative values are:\n$$\nu''_{i \\pm k} = u''(x_i \\pm kh) = u_i'' \\pm (kh)u_i''' + \\frac{(kh)^2}{2!}u_i^{(4)} \\pm \\frac{(kh)^3}{3!}u_i^{(5)} + \\frac{(kh)^4}{4!}u_i^{(6)} + \\mathcal{O}(h^5)\n$$\nDue to symmetry, we combine terms:\n$$\nu''_{i-k} + u''_{i+k} = 2u_i'' + (kh)^2 u_i^{(4)} + \\frac{(kh)^4}{12}u_i^{(6)} + \\mathcal{O}(h^6)\n$$\nFor $k=1$:\n$$u''_{i-1} + u''_{i+1} = 2u_i'' + h^2 u_i^{(4)} + \\frac{h^4}{12}u_i^{(6)} + \\mathcal{O}(h^6)$$\nFor $k=2$:\n$$u''_{i-2} + u''_{i+2} = 2u_i'' + (2h)^2 u_i^{(4)} + \\frac{(2h)^4}{12}u_i^{(6)} + \\mathcal{O}(h^6) = 2u_i'' + 4h^2 u_i^{(4)} + \\frac{4}{3}h^4 u_i^{(6)} + \\mathcal{O}(h^6)$$\nSubstituting these into the LHS of the truncation error expression:\n$$\n\\text{LHS} = a(2u_i'' + 4h^2 u_i^{(4)} + \\frac{4}{3}h^4 u_i^{(6)}) + b(2u_i'' + h^2 u_i^{(4)} + \\frac{h^4}{12}u_i^{(6)}) + u_i'' + \\mathcal{O}(h^6)\n$$\nGrouping terms by derivative order:\n$$\n\\text{LHS} = (1+2a+2b)u_i'' + (4a+b)h^2 u_i^{(4)} + \\left(\\frac{4a}{3} + \\frac{b}{12}\\right)h^4 u_i^{(6)} + \\mathcal{O}(h^6)\n$$\nNow we assemble the full expression for the truncation error $T_i = \\text{LHS} - \\text{RHS}$:\n$$\nT_i = \\left[(1+2a+2b)u_i'' + \\dots\\right] - \\left[u_i'' + \\frac{h^2}{12}u_i^{(4)} + \\dots\\right]\n$$\n$$\nT_i = (2a+2b)u_i'' + \\left(4a+b - \\frac{1}{12}\\right)h^2 u_i^{(4)} + \\left(\\frac{4a}{3} + \\frac{b}{12} - \\frac{1}{360}\\right)h^4 u_i^{(6)} + \\mathcal{O}(h^6)\n$$\nFor the scheme to be fourth-order accurate, the truncation error must be $\\mathcal{O}(h^4)$. This requires the coefficients of $u_i''$ and $h^2 u_i^{(4)}$ to be zero.\n1. Coefficient of $u_i''$:\n$$2a+2b=0 \\implies a = -b$$\n2. Coefficient of $h^2 u_i^{(4)}$:\n$$4a+b - \\frac{1}{12} = 0$$\nSubstitute $a=-b$ into the second equation:\n$$4(-b) + b - \\frac{1}{12} = 0 \\implies -3b = \\frac{1}{12} \\implies b = -\\frac{1}{36}$$\nFrom $a=-b$, we find:\n$$a = \\frac{1}{36}$$\nThe imposed constraints from the problem statement are $c=1$, $A=0$, and $B=1$.\n\nWith $a = 1/36$ and $b = -1/36$, the terms up to $\\mathcal{O}(h^2)$ in the truncation error vanish. The leading term is the one proportional to $h^4$:\n$$\nT_i = \\left(\\frac{4a}{3} + \\frac{b}{12} - \\frac{1}{360}\\right)h^4 u_i^{(6)} + \\mathcal{O}(h^6)\n$$\nThis is the leading local truncation error, which is of the form $C_{\\mathrm{TE}} h^4 u_i^{(6)}$. The constant $C_{\\mathrm{TE}}$ is:\n$$\nC_{\\mathrm{TE}} = \\frac{4a}{3} + \\frac{b}{12} - \\frac{1}{360}\n$$\nSubstitute the values of $a$ and $b$:\n$$\nC_{\\mathrm{TE}} = \\frac{4}{3}\\left(\\frac{1}{36}\\right) + \\frac{1}{12}\\left(-\\frac{1}{36}\\right) - \\frac{1}{360} = \\frac{1}{27} - \\frac{1}{432} - \\frac{1}{360}\n$$\nTo sum these fractions, we find a common denominator. The prime factorizations are $27=3^3$, $432 = 2^4 \\cdot 3^3$, and $360 = 2^3 \\cdot 3^2 \\cdot 5$. The least common multiple is $2^4 \\cdot 3^3 \\cdot 5 = 16 \\cdot 27 \\cdot 5 = 2160$.\n$$\nC_{\\mathrm{TE}} = \\frac{1 \\cdot 80}{27 \\cdot 80} - \\frac{1 \\cdot 5}{432 \\cdot 5} - \\frac{1 \\cdot 6}{360 \\cdot 6} = \\frac{80}{2160} - \\frac{5}{2160} - \\frac{6}{2160} = \\frac{80 - 11}{2160} = \\frac{69}{2160}\n$$\nThis fraction can be simplified by dividing the numerator and denominator by their greatest common divisor, which is $3$:\n$$\nC_{\\mathrm{TE}} = \\frac{69 \\div 3}{2160 \\div 3} = \\frac{23}{720}\n$$\nSo the leading local truncation error is $\\frac{23}{720}h^4 u^{(6)}_i$.\n\nThe requested values are:\n- $a = \\frac{1}{36}$\n- $b = -\\frac{1}{36}$\n- $c = 1$ (given)\n- $A = 0$ (given)\n- $B = 1$ (given)\n- $C_{\\mathrm{TE}} = \\frac{23}{720}$",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{1}{36}  -\\frac{1}{36}  1  0  1  \\frac{23}{720} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "A central challenge in simulating fluid dynamics and combustion is the accurate treatment of nonlinear convective terms, which can generate spurious energy and lead to instability. The pseudo-spectral evaluation of these terms introduces aliasing errors, where unresolved high-wavenumber interactions corrupt the resolved scales. This advanced practice explores a practical solution by comparing a naive evaluation with a mathematically equivalent, but numerically superior, skew-symmetric form, allowing you to quantify the significant reduction in aliasing error this technique provides .",
            "id": "4066241",
            "problem": "Consider the inviscid form of Burgersâ€™ equation on the periodic domain $[0,2\\pi]$,\n$$\\partial_t u + \\partial_x \\left(\\tfrac{1}{2} u^2\\right) = 0,$$\nas a canonical model for nonlinear convective transport in computational combustion. In pseudo-spectral discretizations, the nonlinear term is typically evaluated in physical space and transformed back to spectral space, which induces aliasing due to the discrete convolution truncation of unresolved high-wavenumber interactions. A commonly used remedy in high-order schemes for reacting flows is to employ skew-symmetric split forms to mitigate aliasing-driven energy transfer toward unresolved modes.\n\nYour task is to quantitatively compare the aliasing error incurred by two pseudo-spectral evaluations of the nonlinear term at a finite resolution $N$:\n\n- The naive evaluation, defined by pointwise multiplication of $u$ and its spectral derivative $u_x$:\n$$\\mathcal{N}_{\\mathrm{naive}}(x) := u(x) \\, \\partial_x u(x).$$\n\n- The skew-symmetric split form, defined as the arithmetic mean between the advective and flux forms:\n$$\\mathcal{N}_{\\mathrm{skew}}(x) := \\tfrac{1}{2}\\left(u(x)\\,\\partial_x u(x) + \\partial_x\\left(\\tfrac{1}{2}u(x)^2\\right)\\right).$$\n\nTo define a reference (aliasing-free) nonlinear term at resolution $N$, use the $3/2$ de-aliasing rule. Specifically:\n1. Upsample $u(x)$ analytically to a fine grid of size $N_p = \\lfloor \\tfrac{3}{2}N \\rfloor$, over the same periodic domain $[0,2\\pi]$.\n2. Compute $u(x)^2$ on the fine grid.\n3. Compute the spectral derivative of $\\tfrac{1}{2}u(x)^2$ on the fine grid.\n4. Truncate the fine-grid spectrum back to the coarse resolution $N$ (retain the low wavenumber content only) and invert to obtain a coarse-grid physical-space field, denoted $\\mathcal{N}^\\star(x)$.\n\nDefine the relative aliasing error of an approximation $\\mathcal{N}(x)$ at resolution $N$ by the dimensionless root-mean-square norm\n$$E(\\mathcal{N}) := \\frac{\\left\\|\\mathcal{N}(x) - \\mathcal{N}^\\star(x)\\right\\|_2}{\\left\\|\\mathcal{N}^\\star(x)\\right\\|_2},$$\nwhere the $L^2$ norm is computed on the coarse grid of size $N$ over $[0,2\\pi]$. Quantify the aliasing error reduction achieved by the skew-symmetric form relative to the naive form by the reduction factor\n$$R := \\frac{E(\\mathcal{N}_{\\mathrm{naive}})}{E(\\mathcal{N}_{\\mathrm{skew}})}.$$\n\nAngles must be interpreted in radians. No physical units are involved. Your program must compute $R$ for each of the following test cases, each specified by $(N,\\text{components})$, where\n$$u(x) = \\sum_{j=1}^{J_s} A_j \\sin(k_j x + \\phi_j) + \\sum_{\\ell=1}^{J_c} B_\\ell \\cos(m_\\ell x + \\psi_\\ell),$$\nwith integer wavenumbers and real amplitudes and phases:\n\n- Test case $1$: $N=64$, components $\\left[(\\sin, A=1.0, k=3, \\phi=0), (\\sin, A=0.5, k=7, \\phi=0), (\\cos, B=0.25, m=5, \\psi=0)\\right]$.\n- Test case $2$: $N=32$, components $\\left[(\\sin, A=1.0, k=15, \\phi=0), (\\sin, A=0.7, k=16, \\phi=0)\\right]$.\n- Test case $3$: $N=128$, components $\\left[(\\sin, A=1.0, k=20, \\phi=0), (\\sin, A=0.8, k=27, \\phi=0), (\\cos, B=0.6, m=9, \\psi=0), (\\cos, B=0.4, m=13, \\psi=0)\\right]$.\n- Test case $4$: $N=128$, components $\\left[(\\sin, A=1.0, k=2, \\phi=0)\\right]$.\n\nYour program should produce a single line of output containing the four reduction factors $R$ for the above test cases, as a comma-separated list enclosed in square brackets (for example, $[r_1,r_2,r_3,r_4]$). The results must be floats.",
            "solution": "The problem requires a quantitative comparison of aliasing errors between two different pseudo-spectral evaluations of the nonlinear convective term in the inviscid Burgers' equation, $\\partial_t u + \\partial_x \\left(\\tfrac{1}{2} u^2\\right) = 0$. The two forms are the naive product, $\\mathcal{N}_{\\mathrm{naive}}(x)$, and a skew-symmetric formulation, $\\mathcal{N}_{\\mathrm{skew}}(x)$. The comparison is based on a reduction factor, $R$, which measures the improvement of the skew-symmetric form over the naive form in mitigating aliasing error. The aliasing error itself is quantified by comparing each approximation against a high-fidelity reference term, $\\mathcal{N}^\\star(x)$, computed using the $3/2$ de-aliasing rule.\n\nThe entire procedure is performed numerically on a periodic domain $[0, 2\\pi]$ discretized by a uniform grid. The core numerical tools are the Fast Fourier Transform (FFT) for moving between physical and spectral (wavenumber) space, and spectral differentiation.\n\n**1. Pseudo-Spectral Discretization**\n\nA function $f(x)$ on the periodic domain $[0, 2\\pi]$ is represented by its values on a discrete grid of $N$ points, $x_j = j \\frac{2\\pi}{N}$ for $j=0, 1, \\dots, N-1$. The Discrete Fourier Transform (DFT), efficiently computed via FFT, maps this physical-space representation $f(x_j)$ to a spectral-space representation $\\hat{f}_k$, which are the coefficients of the finite Fourier series expansion.\n\nThe spatial derivative $\\partial_x f(x)$ is computed in spectral space. The Fourier transform of the derivative, $\\widehat{\\partial_x f}_k$, is obtained by multiplying each Fourier coefficient $\\hat{f}_k$ by $ik$, where $i = \\sqrt{-1}$ and $k$ is the integer wavenumber. The wavenumbers represented on an $N$-point grid are typically $k \\in \\{0, \\pm 1, \\dots, \\pm(N/2-1), N/2\\}$ for even $N$ (with the highest positive and negative wavenumbers aliased at the Nyquist frequency $N/2$). The derivative is then found by applying the inverse FFT to the resulting spectrum $\\widehat{\\partial_x f}_k$. For real-valued functions, this process can be optimized using the real-to-complex FFT (`rfft`) and its inverse. The derivative of the Nyquist mode, $k=N/2$, is set to zero as it is not well-defined on the grid.\n\n**2. Evaluation of Approximate Nonlinear Terms**\n\nBoth $\\mathcal{N}_{\\mathrm{naive}}(x)$ and $\\mathcal{N}_{\\mathrm{skew}}(x)$ are computed on the coarse grid of size $N$. Let $D_N$ denote the spectral differentiation operator on this grid.\n\n- **Naive Form**: $\\mathcal{N}_{\\mathrm{naive}}(x) := u(x) \\, \\partial_x u(x)$.\nThe algorithm is:\n1.  Start with the function $u(x)$ evaluated on the $N$-point grid, yielding the vector $u$.\n2.  Compute its spectral derivative, $u_x = D_N(u)$.\n3.  Compute the pointwise product $\\mathcal{N}_{\\mathrm{naive}} = u \\odot u_x$, where $\\odot$ denotes element-wise multiplication.\n\nThis evaluation is called 'naive' because the pointwise product of two functions represented by $N$ Fourier modes can generate higher-wavenumber modes that are not representable on the $N$-point grid. These unresolvable modes are aliased, i.e., they are incorrectly projected onto the resolved wavenumbers, introducing error.\n\n- **Skew-Symmetric Form**: $\\mathcal{N}_{\\mathrm{skew}}(x) := \\tfrac{1}{2}\\left(u(x)\\,\\partial_x u(x) + \\partial_x\\left(\\tfrac{1}{2}u(x)^2\\right)\\right)$.\nThis is the arithmetic mean of the advective form, $u u_x$, and the flux divergence form, $\\partial_x(\\frac{1}{2}u^2)$.\nThe algorithm is:\n1.  Compute the naive term, $\\mathcal{N}_{\\mathrm{naive}} = u \\odot D_N(u)$.\n2.  Compute the flux divergence term:\n    a. Calculate $u^2$ pointwise on the grid.\n    b. Apply the spectral derivative operator: $\\mathcal{N}_{\\mathrm{flux}} = D_N(\\tfrac{1}{2}u^2)$.\n3.  Average the two forms: $\\mathcal{N}_{\\mathrm{skew}} = \\tfrac{1}{2}(\\mathcal{N}_{\\mathrm{naive}} + \\mathcal{N}_{\\mathrm{flux}})$.\n\nWhile continuously equivalent, the two forms are not discretely identical. The skew-symmetric form is known to have better conservation properties and can mitigate aliasing-induced instability.\n\n**3. Reference 'Aliasing-Free' Term ($\\mathcal{N}^\\star$)**\n\nThe reference term $\\mathcal{N}^\\star(x)$ is computed using the $3/2$ de-aliasing rule, which provides a result free from the aliasing errors that affect the coarse-grid computations.\nThe procedure is:\n1.  Define a fine grid of size $N_p = \\lfloor \\tfrac{3}{2}N \\rfloor$.\n2.  Evaluate the analytical function $u(x)$ on this fine grid to obtain $u_{pad}$.\n3.  Compute the flux $\\tfrac{1}{2}u^2$ pointwise on the fine grid: $(\\tfrac{1}{2}u^2)_{pad}$.\n4.  Compute the spectral derivative on the fine grid using the operator $D_{N_p}$: $\\mathcal{N}_{pad} = D_{N_p}((\\tfrac{1}{2}u^2)_{pad})$. This result is considered aliasing-free because the fine grid is large enough to represent all wavenumber interactions generated by the quadratic nonlinearity of $u(x)$ (whose modes are resolved on the coarse grid).\n5.  Transform $\\mathcal{N}_{pad}$ to the spectral domain via FFT: $\\hat{\\mathcal{N}}_{pad} = \\text{FFT}(\\mathcal{N}_{pad})$.\n6.  Truncate the spectrum $\\hat{\\mathcal{N}}_{pad}$ by retaining only the modes that are resolvable on the coarse $N$-point grid. This involves keeping the first $N/2+1$ coefficients of the real FFT spectrum.\n7.  Apply the inverse FFT of size $N$ to the truncated spectrum to obtain the reference term $\\mathcal{N}^\\star(x)$ on the coarse grid.\n\n**4. Error Quantification**\n\nThe accuracy of the approximations is measured by the relative aliasing error, defined as the discrete $L^2$-norm of the difference from the reference, normalized by the $L^2$-norm of the reference itself. For a vector $f$ on the $N$-point grid, the norm is $\\|f\\|_2 = \\sqrt{\\sum_{j=0}^{N-1} |f_j|^2}$.\n$$E(\\mathcal{N}) := \\frac{\\|\\mathcal{N} - \\mathcal{N}^\\star\\|_2}{\\|\\mathcal{N}^\\star\\|_2}$$\nThe two errors, $E(\\mathcal{N}_{\\mathrm{naive}})$ and $E(\\mathcal{N}_{\\mathrm{skew}})$, are calculated.\n\nThe final metric is the reduction factor $R$, which compares these two errors:\n$$R := \\frac{E(\\mathcal{N}_{\\mathrm{naive}})}{E(\\mathcal{N}_{\\mathrm{skew}})}$$\nA value of $R  1$ indicates that the skew-symmetric form is more accurate than the naive form.\n\nThe overall algorithm proceeds by implementing these steps for each test case specified. The function $u(x)$ is constructed from the given sine and cosine components. All spectral operations (differentiation, truncation) are implemented using `numpy.fft.rfft` and `numpy.fft.irfft` for efficiency and correct handling of real-valued data.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the aliasing error reduction factor for pseudo-spectral evaluations\n    of the nonlinear term in Burgers' equation.\n    \"\"\"\n\n    test_cases = [\n        (64, [('sin', 1.0, 3, 0), ('sin', 0.5, 7, 0), ('cos', 0.25, 5, 0)]),\n        (32, [('sin', 1.0, 15, 0), ('sin', 0.7, 16, 0)]),\n        (128, [('sin', 1.0, 20, 0), ('sin', 0.8, 27, 0), ('cos', 0.6, 9, 0), ('cos', 0.4, 13, 0)]),\n        (128, [('sin', 1.0, 2, 0)])\n    ]\n\n    results = []\n\n    for N, components in test_cases:\n        # Step 0: Define a factory for the analytical function u(x)\n        def get_u_func(comps):\n            def u_func(x):\n                val = np.zeros_like(x)\n                for comp in comps:\n                    form, amp, k, phase = comp\n                    if form == 'sin':\n                        val += amp * np.sin(k * x + phase)\n                    elif form == 'cos':\n                        val += amp * np.cos(k * x + phase)\n                return val\n            return u_func\n\n        # Step 1: Define grids and evaluate analytical solution u(x)\n        Np = int(1.5 * N)\n        x_coarse = np.linspace(0, 2 * np.pi, N, endpoint=False)\n        x_pad = np.linspace(0, 2 * np.pi, Np, endpoint=False)\n\n        u_func = get_u_func(components)\n        u_coarse = u_func(x_coarse)\n        u_pad = u_func(x_pad)\n\n        # Helper function for spectral derivative using real FFTs\n        def rspectral_derivative(f, n_grid):\n            # The length of the rfft output is n_grid//2 + 1\n            k_vec = np.arange(n_grid // 2 + 1)\n            f_hat = np.fft.rfft(f)\n            \n            # Derivative in spectral space is multiplication by ik\n            df_hat = 1j * k_vec * f_hat\n            \n            # The derivative of the Nyquist mode is zero on the grid\n            if n_grid % 2 == 0:\n                df_hat[-1] = 0.0\n            \n            # Inverse FFT to get derivative in physical space\n            return np.fft.irfft(df_hat, n=n_grid)\n\n        # Step 2: Compute the naive term N_naive on the coarse grid\n        du_dx_coarse = rspectral_derivative(u_coarse, N)\n        N_naive = u_coarse * du_dx_coarse\n\n        # Step 3: Compute the skew-symmetric term N_skew on the coarse grid\n        u2_coarse = 0.5 * u_coarse**2\n        flux_form = rspectral_derivative(u2_coarse, N)\n        N_skew = 0.5 * (N_naive + flux_form)\n\n        # Step 4: Compute the reference term N_star using 3/2 de-aliasing rule\n        u2_pad = 0.5 * u_pad**2\n        N_pad = rspectral_derivative(u2_pad, Np)\n\n        # Truncate the fine-grid spectrum to the coarse grid resolution\n        hat_N_pad = np.fft.rfft(N_pad)\n        k_max_coarse_len = N // 2 + 1\n        hat_N_star = np.zeros(k_max_coarse_len, dtype=complex)\n        \n        # Copy the low-wavenumber content from the padded spectrum\n        hat_N_star[:k_max_coarse_len] = hat_N_pad[:k_max_coarse_len]\n        \n        # Invert the truncated spectrum to get the coarse-grid reference field\n        N_star = np.fft.irfft(hat_N_star, n=N)\n\n        # Step 5: Compute errors and the reduction factor R\n        norm_N_star = np.linalg.norm(N_star)\n\n        if norm_N_star  1e-15:\n            # If reference is zero, any non-zero approximation gives infinite error.\n            # If both approx are also zero, errors are 0, ratio is undefined (treat as 1).\n            if np.linalg.norm(N_naive)  1e-15 and np.linalg.norm(N_skew)  1e-15:\n                R = 1.0\n            else:\n                R = np.nan\n        else:\n            E_naive = np.linalg.norm(N_naive - N_star) / norm_N_star\n            E_skew = np.linalg.norm(N_skew - N_star) / norm_N_star\n\n            if E_skew  1e-15:\n                # If skew-symmetric form is (nearly) perfect\n                if E_naive  1e-15:\n                    # and naive form is also perfect, the ratio is 1.\n                    R = 1.0\n                else:\n                    # but naive form has error, the reduction is infinite.\n                    R = np.inf\n            else:\n                R = E_naive / E_skew\n        \n        results.append(R)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}