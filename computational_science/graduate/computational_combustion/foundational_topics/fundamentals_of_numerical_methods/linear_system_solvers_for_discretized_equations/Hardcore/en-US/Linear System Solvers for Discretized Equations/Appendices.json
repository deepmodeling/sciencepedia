{
    "hands_on_practices": [
        {
            "introduction": "Before choosing a linear solver, it's crucial to understand the properties of the matrix being solved. This exercise demonstrates how to use fundamental analytical tools to probe the structure of a matrix that arises from a typical advection-diffusion discretization . By applying the Gershgorin Circle Theorem, you will connect the physical and numerical parameters of the problem to key matrix properties like diagonal dominance and its eigenvalue spectrum, which in turn govern the convergence behavior of stationary iterative solvers.",
            "id": "4036826",
            "problem": "Consider one-dimensional species transport in a premixed gaseous mixture with constant properties, modeled by the Partial Differential Equation (PDE)\n$$\n\\frac{\\partial Y}{\\partial t} + u \\frac{\\partial Y}{\\partial x} = D \\frac{\\partial^{2} Y}{\\partial x^{2}},\n$$\nwhere $Y(x,t)$ is a species mass fraction, $u>0$ is a constant advection speed, and $D>0$ is a constant molecular diffusivity. Assume Dirichlet boundary conditions on a finite interval. Discretize space on a uniform grid with spacing $\\Delta x$ and time with backward Euler time step $\\Delta t$, using first-order upwind for advection and second-order centered differences for diffusion, all evaluated at the new time level. This yields a linear system\n$$\nA \\mathbf{y}^{n+1} = \\mathbf{y}^{n},\n$$\nwhere $A$ is tridiagonal with interior-row coefficients\n$$\na_{i,i} = \\frac{1}{\\Delta t} + \\frac{u}{\\Delta x} + \\frac{2D}{\\Delta x^{2}}, \\quad a_{i,i-1} = -\\left(\\frac{u}{\\Delta x} + \\frac{D}{\\Delta x^{2}}\\right), \\quad a_{i,i+1} = -\\frac{D}{\\Delta x^{2}}.\n$$\nDefine the nondimensional advection and diffusion measures\n$$\nC = \\frac{u \\Delta t}{\\Delta x}, \\qquad S = \\frac{D \\Delta t}{\\Delta x^{2}}.\n$$\nUsing the Gershgorin Circle Theorem and the structure of $A$, derive bounds on the eigenvalues of $A$ for interior rows and explain how these bounds embody diagonal dominance and relate to the stability of stationary linear solvers. Then, consider the Jacobi iteration applied to $A \\mathbf{y} = \\mathbf{b}$, whose iteration matrix is $T_{J} = D^{-1}(L+U)$, where $D$ is the diagonal of $A$, and $L$ and $U$ are its strict lower and upper triangular parts. Using Gershgorinâ€™s theorem and norm bounds, obtain a closed-form upper bound on the spectral radius of $T_{J}$ expressed solely in terms of $C$ and $S$. Provide this upper bound as your final answer. No numerical evaluation is required. If you introduce any angle, express it in radians. There is no rounding requirement because the final answer is symbolic.",
            "solution": "The problem statement is evaluated to be valid. It is scientifically grounded, well-posed, objective, and internally consistent for the purposes of the question asked. The problem concerns the numerical analysis of a standard finite difference discretization of the one-dimensional advection-diffusion equation. Although there is a minor inconsistency in the stated linear system (the right-hand side should be scaled by $1/\\Delta t$), this does not affect the properties of the matrix $A$ or its associated Jacobi iteration matrix $T_J$, which are the subjects of the analysis. Thus, the questions posed can be answered rigorously.\n\nLet us begin the analysis of the matrix $A$. The problem asks to apply the Gershgorin Circle Theorem to the matrix $A$ resulting from the discretization. The theorem states that every eigenvalue $\\lambda$ of a square matrix $M$ lies within at least one of the Gershgorin discs $G_i$ in the complex plane, where $G_i = \\{ z \\in \\mathbb{C} : |z - m_{i,i}| \\le R_i \\}$, with $m_{i,i}$ being the diagonal entry of row $i$ and $R_i = \\sum_{j \\neq i} |m_{i,j}|$ being the sum of the absolute values of the off-diagonal entries in that row.\n\nFor an interior row $i$ of the matrix $A$, the coefficients are given as:\n$$\na_{i,i} = \\frac{1}{\\Delta t} + \\frac{u}{\\Delta x} + \\frac{2D}{\\Delta x^{2}}\n$$\n$$\na_{i,i-1} = -\\left(\\frac{u}{\\Delta x} + \\frac{D}{\\Delta x^{2}}\\right)\n$$\n$$\na_{i,i+1} = -\\frac{D}{\\Delta x^{2}}\n$$\nThe center of the Gershgorin disc $G_i$ is the diagonal entry $a_{i,i}$. The radius $R_i$ is the sum of the absolute values of the off-diagonal entries in row $i$:\n$$\nR_i = |a_{i,i-1}| + |a_{i,i+1}| = \\left|-\\left(\\frac{u}{\\Delta x} + \\frac{D}{\\Delta x^{2}}\\right)\\right| + \\left|-\\frac{D}{\\Delta x^{2}}\\right|\n$$\nSince $u > 0$, $D > 0$, and $\\Delta x > 0$, the terms inside the absolute values are positive, so:\n$$\nR_i = \\left(\\frac{u}{\\Delta x} + \\frac{D}{\\Delta x^{2}}\\right) + \\frac{D}{\\Delta x^{2}} = \\frac{u}{\\Delta x} + \\frac{2D}{\\Delta x^{2}}\n$$\nA matrix is strictly diagonally dominant by rows if $|a_{i,i}| > \\sum_{j \\neq i} |a_{i,j}|$ for all rows $i$. Let's check this condition for the interior rows of $A$. Since $u$, $D$, $\\Delta t$, $\\Delta x$ are all positive, $a_{i,i}$ is positive, so $|a_{i,i}| = a_{i,i}$.\n$$\n|a_{i,i}| - R_i = \\left(\\frac{1}{\\Delta t} + \\frac{u}{\\Delta x} + \\frac{2D}{\\Delta x^{2}}\\right) - \\left(\\frac{u}{\\Delta x} + \\frac{2D}{\\Delta x^{2}}\\right) = \\frac{1}{\\Delta t}\n$$\nSince $\\Delta t > 0$, we have $|a_{i,i}| - R_i = \\frac{1}{\\Delta t} > 0$, which implies $|a_{i,i}| > R_i$. Thus, the matrix $A$ is strictly diagonally dominant for its interior rows. This property, if it holds for all rows (which is typical for such discretizations with Dirichlet boundary conditions), guarantees that $A$ is invertible. Furthermore, it guarantees that stationary iterative methods like the Jacobi and Gauss-Seidel methods will converge when applied to a system $A\\mathbf{x} = \\mathbf{b}$. The \"degree\" of diagonal dominance, quantified by the ratio $R_i/|a_{i,i}|$, influences the convergence rate of these solvers.\n\nThe Gershgorin Circle Theorem provides bounds on the eigenvalues $\\lambda$ of $A$. For any eigenvalue $\\lambda$, there exists a row $i$ such that $|\\lambda - a_{i,i}| \\le R_i$. This implies that the real part of $\\lambda$ is bounded by $a_{i,i} - R_i \\le \\text{Re}(\\lambda) \\le a_{i,i} + R_i$. Using the results from the interior rows, we find:\n$$\n\\lambda_{\\text{min, bound}} = a_{i,i} - R_i = \\frac{1}{\\Delta t}\n$$\n$$\n\\lambda_{\\text{max, bound}} = a_{i,i} + R_i = \\frac{1}{\\Delta t} + \\frac{2u}{\\Delta x} + \\frac{4D}{\\Delta x^{2}}\n$$\nSince all discs are centered on the positive real axis and their radii are smaller than the center's value, all eigenvalues must have positive real parts. In fact, since $A$ is a real matrix with non-positive off-diagonal entries and is strictly diagonally dominant with positive diagonal entries, it is an M-matrix, and all its eigenvalues are real and positive. The smallest eigenvalue is bounded below by $\\lambda_{min} \\ge \\frac{1}{\\Delta t} > 0$.\n\nNext, we analyze the Jacobi iteration for solving $A\\mathbf{y} = \\mathbf{b}$. The matrix $A$ is split into its diagonal part $D_{A}$, strict lower triangular part $L_{A}$, and strict upper triangular part $U_{A}$ such that $A = D_{A} - L_{A} - U_{A}$. The problem uses the notation $D$, $L$, $U$, but to avoid confusion with the diffusivity $D$, we use subscripts. The problem states $T_J = D^{-1}(L+U)$, which corresponds to $A = D-(L+U)$, so $L_{A}$ and $U_{A}$ are defined with positive entries (the negatives of the off-diagonal entries of $A$).\nThe Jacobi iteration matrix is $T_J = D_{A}^{-1}(L_{A} + U_{A})$. The convergence of the Jacobi method is guaranteed if the spectral radius of $T_J$, denoted $\\rho(T_J)$, is less than $1$. We can find an upper bound on $\\rho(T_J)$ using matrix norms, as $\\rho(T_J) \\le \\|T_J\\|$ for any consistent matrix norm. We use the infinity norm, $\\|T_J\\|_{\\infty}$, which is the maximum absolute row sum.\nThe entries of $T_J$ are given by $(T_J)_{ij} = -a_{ij}/a_{ii}$ for $i \\neq j$ and $(T_J)_{ii} = 0$.\nFor an interior row $i$, the non-zero entries are:\n$$\n(T_J)_{i, i-1} = \\frac{-a_{i,i-1}}{a_{i,i}} = \\frac{\\frac{u}{\\Delta x} + \\frac{D}{\\Delta x^{2}}}{\\frac{1}{\\Delta t} + \\frac{u}{\\Delta x} + \\frac{2D}{\\Delta x^{2}}}\n$$\n$$\n(T_J)_{i, i+1} = \\frac{-a_{i,i+1}}{a_{i,i}} = \\frac{\\frac{D}{\\Delta x^{2}}}{\\frac{1}{\\Delta t} + \\frac{u}{\\Delta x} + \\frac{2D}{\\Delta x^{2}}}\n$$\nThe absolute row sum for an interior row $i$ is:\n$$\n\\sum_{j}|(T_J)_{ij}| = |(T_J)_{i, i-1}| + |(T_J)_{i, i+1}| = \\frac{\\frac{u}{\\Delta x} + \\frac{D}{\\Delta x^{2}}}{\\frac{1}{\\Delta t} + \\frac{u}{\\Delta x} + \\frac{2D}{\\Delta x^{2}}} + \\frac{\\frac{D}{\\Delta x^{2}}}{\\frac{1}{\\Delta t} + \\frac{u}{\\Delta x} + \\frac{2D}{\\Delta x^{2}}} = \\frac{\\frac{u}{\\Delta x} + \\frac{2D}{\\Delta x^{2}}}{\\frac{1}{\\Delta t} + \\frac{u}{\\Delta x} + \\frac{2D}{\\Delta x^{2}}}\n$$\nThis is also the radius of the Gershgorin disc for row $i$ of $T_J$, which is centered at $0$.\n\nThe problem requires this bound to be expressed in terms of the non-dimensional Courant number $C = \\frac{u \\Delta t}{\\Delta x}$ and diffusion number $S = \\frac{D \\Delta t}{\\Delta x^{2}}$. We can rewrite the row sum by multiplying the numerator and denominator by $\\Delta t$:\n$$\n\\frac{\\Delta t \\left(\\frac{u}{\\Delta x} + \\frac{2D}{\\Delta x^{2}}\\right)}{\\Delta t \\left(\\frac{1}{\\Delta t} + \\frac{u}{\\Delta x} + \\frac{2D}{\\Delta x^{2}}\\right)} = \\frac{\\frac{u \\Delta t}{\\Delta x} + \\frac{2D \\Delta t}{\\Delta x^{2}}}{1 + \\frac{u \\Delta t}{\\Delta x} + \\frac{2D \\Delta t}{\\Delta x^{2}}} = \\frac{C + 2S}{1 + C + 2S}\n$$\nThe row sums for the first and last interior rows of the system (rows $i=1$ and $i=N-1$) will be smaller than this value, thus this expression for the interior row sum represents the maximum absolute row sum for the entire matrix $T_J$.\nTherefore, $\\|T_J\\|_{\\infty} = \\frac{C + 2S}{1 + C + 2S}$.\nThis provides an upper bound for the spectral radius:\n$$\n\\rho(T_J) \\le \\|T_J\\|_{\\infty} = \\frac{C + 2S}{1 + C + 2S}\n$$\nSince $C > 0$ and $S > 0$, the numerator $C+2S$ is strictly less than the denominator $1+C+2S$. This means $\\rho(T_J) < 1$ for any choice of physical and numerical parameters, which guarantees that the Jacobi iteration will always converge for this problem. This unconditional convergence is a direct consequence of the strict diagonal dominance established by the implicit time discretization scheme. The final requested answer is this upper bound on the spectral radius.",
            "answer": "$$\n\\boxed{\\frac{C + 2S}{1 + C + 2S}}\n$$"
        },
        {
            "introduction": "Many physical laws, when discretized, do not yield straightforward invertible matrices. A classic case in computational combustion is the pressure Poisson equation, which is singular when pure Neumann boundary conditions are applied, reflecting that pressure is only defined up to an additive constant . This practice explores the origin of this singularity, identifies the compatibility condition required for a solution to exist, and demonstrates the standard technique of augmenting the system with a constraint to enforce a unique solution.",
            "id": "4036855",
            "problem": "In low-Mach-number reacting flows typical of computational combustion, the velocity field is advanced by a projection method that enforces mass conservation through a pressure correction. Consider the velocity update written schematically as $\\,\\boldsymbol{u}^{n+1}=\\boldsymbol{u}^{\\star}-\\Delta t\\,\\nabla p\\,$, where $\\,\\boldsymbol{u}^{\\star}\\,$ is a provisional velocity obtained from advection, diffusion, and volumetric source terms. Enforcing the discrete form of mass conservation for a low-Mach formulation leads to a Poisson equation for the pressure of the form $\\,\\nabla^{2}p=g\\,$ with homogeneous Neumann boundary conditions $\\,\\partial p/\\partial n=0\\,$ on all impermeable boundaries. In this setting:\n- Starting from the mass conservation requirement $\\,\\nabla\\cdot\\boldsymbol{u}^{n+1}=0\\,$ and the velocity update, derive the pressure Poisson equation and show that pure Neumann boundary conditions imply non-uniqueness of $\\,p\\,$. Identify the nullspace at the continuous level and derive the associated compatibility condition on the source $\\,g\\,$.\n- Discretize the one-dimensional problem on the interval $[0,1]$ using a uniform, cell-centered finite-volume grid with $\\,N=3\\,$ control volumes and homogeneous Neumann boundary conditions at both ends. Let $\\,\\boldsymbol{p}=(p_{1},p_{2},p_{3})^{T}\\,$ denote the cell-centered pressure unknowns, and let the discrete operator be written (after absorbing the grid-spacing scaling into the right-hand side) as\n$$\nA=\\begin{pmatrix}\n-1 & 1 & 0\\\\\n1 & -2 & 1\\\\\n0 & 1 & -1\n\\end{pmatrix},\\qquad \\text{so that}\\qquad A\\,\\boldsymbol{p}=\\boldsymbol{b}.\n$$\nShow that $\\,A\\,$ is rank-deficient and identify its nullspace and the discrete compatibility condition on $\\,\\boldsymbol{b}\\,$.\n- Explain how to restore solvability and uniqueness by imposing a mean-zero constraint on $\\,\\boldsymbol{p}\\,$ consistent with uniform cell volumes, and write the corresponding augmented saddle-point system that enforces $\\,\\sum_{i=1}^{3}p_{i}=0\\,$.\n- Finally, for the specific right-hand side $\\,\\boldsymbol{b}=(2,-1,-1)^{T}\\,$, solve the augmented system and report the central cell pressure $\\,p_{2}\\,$. Give the exact value as a pure number (nondimensional), with no units and no rounding.",
            "solution": "The problem is divided into four parts. We will address them sequentially.\n\nFirst, we derive the pressure Poisson equation and analyze its properties at the continuous level.\nThe velocity field at the new time step, $\\boldsymbol{u}^{n+1}$, is given by the update formula:\n$$\n\\boldsymbol{u}^{n+1} = \\boldsymbol{u}^{\\star} - \\Delta t \\, \\nabla p\n$$\nwhere $\\boldsymbol{u}^{\\star}$ is a provisional velocity and $p$ is the pressure correction. This new velocity field must satisfy the mass conservation requirement for a low-Mach-number flow, which is expressed as the divergence-free condition:\n$$\n\\nabla \\cdot \\boldsymbol{u}^{n+1} = 0\n$$\nTo derive the equation for $p$, we take the divergence of the velocity update equation:\n$$\n\\nabla \\cdot \\boldsymbol{u}^{n+1} = \\nabla \\cdot (\\boldsymbol{u}^{\\star} - \\Delta t \\, \\nabla p)\n$$\n$$\n\\nabla \\cdot \\boldsymbol{u}^{n+1} = \\nabla \\cdot \\boldsymbol{u}^{\\star} - \\Delta t \\, \\nabla \\cdot (\\nabla p)\n$$\nUsing the identity $\\nabla \\cdot (\\nabla p) = \\nabla^2 p$ (the Laplacian of $p$), and enforcing the mass conservation condition $\\nabla \\cdot \\boldsymbol{u}^{n+1} = 0$, we get:\n$$\n0 = \\nabla \\cdot \\boldsymbol{u}^{\\star} - \\Delta t \\, \\nabla^2 p\n$$\nRearranging this equation gives the pressure Poisson equation:\n$$\n\\nabla^2 p = \\frac{1}{\\Delta t} \\nabla \\cdot \\boldsymbol{u}^{\\star}\n$$\nThis is of the form $\\nabla^2 p = g$, with the source term $g$ identified as $g = \\frac{1}{\\Delta t} \\nabla \\cdot \\boldsymbol{u}^{\\star}$.\n\nNext, we demonstrate the non-uniqueness of the solution $p$ under pure homogeneous Neumann boundary conditions, $\\frac{\\partial p}{\\partial n} = 0$. Let $p(\\boldsymbol{x})$ be a solution to the problem. Consider a new function $\\tilde{p}(\\boldsymbol{x}) = p(\\boldsymbol{x}) + C$, where $C$ is an arbitrary constant.\n1.  The Poisson equation for $\\tilde{p}$ is $\\nabla^2 \\tilde{p} = \\nabla^2(p + C) = \\nabla^2 p + \\nabla^2 C = \\nabla^2 p + 0 = g$. So, $\\tilde{p}$ satisfies the Poisson equation.\n2.  The boundary condition for $\\tilde{p}$ is $\\frac{\\partial \\tilde{p}}{\\partial n} = \\frac{\\partial (p+C)}{\\partial n} = \\frac{\\partial p}{\\partial n} + \\frac{\\partial C}{\\partial n} = 0 + 0 = 0$. So, $\\tilde{p}$ satisfies the homogeneous Neumann boundary conditions.\nSince $\\tilde{p} = p+C$ is also a solution for any constant $C$, the solution is not unique; it is determined only up to an additive constant. The nullspace of the Laplacian operator with these boundary conditions is the set of functions whose Laplacian is zero, which are the harmonic functions. With the additional constraint that the normal derivative is zero on the boundary, the only possible functions are constants. Thus, the nullspace is the set of all constant functions.\n\nTo derive the compatibility condition, we integrate the Poisson equation over the entire domain $\\Omega$:\n$$\n\\int_{\\Omega} \\nabla^2 p \\, dV = \\int_{\\Omega} g \\, dV\n$$\nApplying the divergence theorem to the left-hand side, we convert the volume integral of the Laplacian (the divergence of the gradient) into a surface integral of the flux of the gradient:\n$$\n\\int_{\\Omega} \\nabla \\cdot (\\nabla p) \\, dV = \\oint_{\\partial\\Omega} (\\nabla p) \\cdot \\boldsymbol{n} \\, dS\n$$\nwhere $\\partial\\Omega$ is the boundary of the domain and $\\boldsymbol{n}$ is the outward-pointing unit normal vector. The term $(\\nabla p) \\cdot \\boldsymbol{n}$ is the directional derivative in the normal direction, $\\frac{\\partial p}{\\partial n}$. The problem specifies homogeneous Neumann boundary conditions, $\\frac{\\partial p}{\\partial n} = 0$, on all boundaries. Therefore, the surface integral is zero:\n$$\n\\oint_{\\partial\\Omega} \\frac{\\partial p}{\\partial n} \\, dS = \\oint_{\\partial\\Omega} 0 \\, dS = 0\n$$\nThis implies that the right-hand side of the integrated Poisson equation must also be zero. This gives the compatibility condition:\n$$\n\\int_{\\Omega} g \\, dV = 0\n$$\nFor a solution to exist, the integral of the source term over the domain must be zero.\n\nSecond, we analyze the discrete one-dimensional problem. The system is $A\\boldsymbol{p} = \\boldsymbol{b}$, with the matrix $A$ given as:\n$$\nA = \\begin{pmatrix} -1 & 1 & 0 \\\\ 1 & -2 & 1 \\\\ 0 & 1 & -1 \\end{pmatrix}\n$$\nTo show that $A$ is rank-deficient, we can compute its determinant:\n$$\n\\det(A) = -1 \\cdot ((-2)(-1) - (1)(1)) - 1 \\cdot ((1)(-1) - (1)(0)) + 0 = -1(1) - 1(-1) = -1 + 1 = 0\n$$\nSince the determinant is zero, the matrix is singular and thus rank-deficient. The rank of $A$ is less than $3$.\nTo identify the nullspace, we seek a non-zero vector $\\boldsymbol{v}=(v_1, v_2, v_3)^T$ such that $A\\boldsymbol{v} = \\boldsymbol{0}$:\n$$\n\\begin{pmatrix} -1 & 1 & 0 \\\\ 1 & -2 & 1 \\\\ 0 & 1 & -1 \\end{pmatrix} \\begin{pmatrix} v_1 \\\\ v_2 \\\\ v_3 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\nThis gives the system of equations:\n1. $-v_1 + v_2 = 0 \\implies v_1 = v_2$\n2. $v_1 - 2v_2 + v_3 = 0$\n3. $v_2 - v_3 = 0 \\implies v_2 = v_3$\nFrom these equations, we have $v_1 = v_2 = v_3$. Thus, any vector in the nullspace is a scalar multiple of the vector $\\boldsymbol{1}=(1, 1, 1)^T$. The nullspace is $\\text{span}(\\{(1, 1, 1)^T\\})$, which is the discrete analog of the space of constant functions.\n\nFor a solution to the singular system $A\\boldsymbol{p} = \\boldsymbol{b}$ to exist, the right-hand side vector $\\boldsymbol{b}$ must be orthogonal to the nullspace of $A^T$. Since $A$ is symmetric ($A=A^T$), its nullspace and left nullspace are identical. The compatibility condition is that $\\boldsymbol{b}$ must be orthogonal to the nullspace of $A$. Let $\\boldsymbol{v}_{\\text{null}} = (1, 1, 1)^T$ be the basis vector for the nullspace. The condition is:\n$$\n\\boldsymbol{v}_{\\text{null}}^T \\boldsymbol{b} = 0 \\implies (1, 1, 1) \\begin{pmatrix} b_1 \\\\ b_2 \\\\ b_3 \\end{pmatrix} = 0 \\implies b_1 + b_2 + b_3 = 0\n$$\nThis is the discrete compatibility condition, analogous to $\\int g \\, dV = 0$.\n\nThird, we explain how to restore solvability and uniqueness. The singularity of $A$ leads to no unique solution. We can obtain a unique solution by imposing an additional constraint on $\\boldsymbol{p}$. The problem suggests a mean-zero constraint, $\\sum_{i=1}^3 p_i = 0$. This condition removes the arbitrary additive constant from the solution. The combined problem is to solve $A\\boldsymbol{p} = \\boldsymbol{b}$ subject to $\\boldsymbol{1}^T \\boldsymbol{p} = 0$. This can be formulated as an augmented saddle-point system by introducing a Lagrange multiplier, $\\lambda$. The system is:\n$$\n\\begin{pmatrix} A & \\boldsymbol{1} \\\\ \\boldsymbol{1}^T & 0 \\end{pmatrix} \\begin{pmatrix} \\boldsymbol{p} \\\\ \\lambda \\end{pmatrix} = \\begin{pmatrix} \\boldsymbol{b} \\\\ 0 \\end{pmatrix}\n$$\nSubstituting the given matrix $A$ and the vector $\\boldsymbol{1}=(1, 1, 1)^T$, the augmented system is:\n$$\n\\begin{pmatrix}\n-1 & 1 & 0 & 1 \\\\\n1 & -2 & 1 & 1 \\\\\n0 & 1 & -1 & 1 \\\\\n1 & 1 & 1 & 0\n\\end{pmatrix}\n\\begin{pmatrix}\np_1 \\\\ p_2 \\\\ p_3 \\\\ \\lambda\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nb_1 \\\\ b_2 \\\\ b_3 \\\\ 0\n\\end{pmatrix}\n$$\nThis augmented matrix is non-singular, and the system has a unique solution for $(\\boldsymbol{p}, \\lambda)$.\n\nFinally, we solve this augmented system for the specific right-hand side $\\boldsymbol{b} = (2, -1, -1)^T$. First, we check the compatibility condition: $b_1+b_2+b_3 = 2 + (-1) + (-1) = 0$. The condition is satisfied, so a solution exists. The system of equations is:\n$$\n\\begin{pmatrix}\n-1 & 1 & 0 & 1 \\\\\n1 & -2 & 1 & 1 \\\\\n0 & 1 & -1 & 1 \\\\\n1 & 1 & 1 & 0\n\\end{pmatrix}\n\\begin{pmatrix}\np_1 \\\\ p_2 \\\\ p_3 \\\\ \\lambda\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n2 \\\\ -1 \\\\ -1 \\\\ 0\n\\end{pmatrix}\n$$\nThis represents four linear equations:\n1. $-p_1 + p_2 + \\lambda = 2$\n2. $p_1 - 2p_2 + p_3 + \\lambda = -1$\n3. $p_2 - p_3 + \\lambda = -1$\n4. $p_1 + p_2 + p_3 = 0$\n\nSumming the first three equations gives:\n$(-p_1+p_1) + (p_2-2p_2+p_2) + (p_3-p_3) + 3\\lambda = 2-1-1$\n$0 + 0 + 0 + 3\\lambda = 0 \\implies \\lambda=0$.\nThis simplification occurs because the compatibility condition on $\\boldsymbol{b}$ is met. With $\\lambda = 0$, the system reduces to:\n1. $-p_1 + p_2 = 2$\n2. $p_1 - 2p_2 + p_3 = -1$\n3. $p_2 - p_3 = -1$\n4. $p_1 + p_2 + p_3 = 0$\n\nFrom equation (4), we express $p_3$ as $p_3 = -p_1 - p_2$.\nSubstitute this into equation (2):\n$p_1 - 2p_2 + (-p_1 - p_2) = -1$\n$-3p_2 = -1 \\implies p_2 = \\frac{1}{3}$.\nWe can also substitute $p_3$ into equation (3):\n$p_2 - (-p_1 - p_2) = -1$\n$p_1 + 2p_2 = -1$.\nNow, substitute the value of $p_2 = 1/3$ into this equation:\n$p_1 + 2(\\frac{1}{3}) = -1 \\implies p_1 = -1 - \\frac{2}{3} = -\\frac{5}{3}$.\nWe can also verify using equation (1):\n$-p_1 + p_2 = -(-\\frac{5}{3}) + \\frac{1}{3} = \\frac{5}{3} + \\frac{1}{3} = \\frac{6}{3} = 2$. This is consistent.\nFinally, we find $p_3$:\n$p_3 = -p_1 - p_2 = -(-\\frac{5}{3}) - (\\frac{1}{3}) = \\frac{5}{3} - \\frac{1}{3} = \\frac{4}{3}$.\nThe full solution for the pressure is $\\boldsymbol{p} = (-\\frac{5}{3}, \\frac{1}{3}, \\frac{4}{3})^T$.\nThe problem asks for the central cell pressure, which is $p_2$.\n$$\np_2 = \\frac{1}{3}\n$$",
            "answer": "$$\n\\boxed{\\frac{1}{3}}\n$$"
        },
        {
            "introduction": "In large-scale simulations, explicitly forming and storing the system matrix $A$ is often impractical due to its enormous size. Fortunately, powerful iterative solvers like GMRES only require the ability to compute the matrix-vector product $A\\mathbf{x}$ for a given vector $\\mathbf{x}$ . This hands-on coding exercise guides you through implementing such a \"matrix-free\" operator, where the action of the matrix is computed directly from local flux evaluations, a cornerstone technique in modern computational science.",
            "id": "4036875",
            "problem": "Consider the one-dimensional, nondimensional advection-diffusion-reaction balance for a reactive scalar in computational combustion. Let the unknown increment field be $x_i$ defined at cell centers $i \\in \\{0,1,\\dots,N-1\\}$ on a uniform periodic mesh with spacing $\\Delta x$. The fluxes are defined on faces $i+\\tfrac{1}{2}$ between cells $i$ and $i+1$ with periodic wrap-around indexing. The discrete residual of a conservative finite-volume discretization is constructed from face fluxes and a local reaction term. The goal is to implement a matrix-free application of the linearized discrete operator $A$ such that $y = A x$ is computed via flux differences and reaction contributions without ever assembling $A$ explicitly.\n\nStarting from the conservation of species mass fraction in a one-dimensional control volume, the canonical finite-volume residual at cell $i$ is defined by the divergence of the total flux plus a reaction source,\n$$\n\\mathcal{R}_i(Y) \\equiv \\frac{F_{i+\\tfrac{1}{2}}(Y) - F_{i-\\tfrac{1}{2}}(Y)}{\\Delta x} + \\omega(Y_i),\n$$\nwhere $F_{i+\\tfrac{1}{2}}(Y)$ is the total flux at face $i+\\tfrac{1}{2}$, composed of an advective contribution and a diffusive contribution,\n$$\nF_{i+\\tfrac{1}{2}}(Y) = F^{\\mathrm{adv}}_{i+\\tfrac{1}{2}}(Y) + F^{\\mathrm{diff}}_{i+\\tfrac{1}{2}}(Y).\n$$\nAssume an upwind advective flux based on the sign of the face-normal velocity $u_{i+\\tfrac{1}{2}}$ and a central diffusive flux based on Fickian diffusion with face diffusivity $D_{i+\\tfrac{1}{2}}$,\n$$\nF^{\\mathrm{adv}}_{i+\\tfrac{1}{2}}(Y) =\n\\begin{cases}\nu_{i+\\tfrac{1}{2}}\\, Y_i, & \\text{if } u_{i+\\tfrac{1}{2}} > 0, \\\\\nu_{i+\\tfrac{1}{2}}\\, Y_{i+1}, & \\text{if } u_{i+\\tfrac{1}{2}} \\le 0,\n\\end{cases}\n\\qquad\nF^{\\mathrm{diff}}_{i+\\tfrac{1}{2}}(Y) = - D_{i+\\tfrac{1}{2}}\\, \\frac{Y_{i+1} - Y_i}{\\Delta x}.\n$$\nWe consider a matrix-free linearization suitable for Krylov subspace methods such as the Generalized Minimal Residual (GMRES) method. Let the reaction term be linearized about a given base state $Y^{\\star}$, yielding a local Jacobian $k_i = \\left.\\dfrac{d\\omega}{dY}\\right|_{Y^{\\star}_i}$, so that for a perturbation $x$ the linearized reaction contribution is $k_i\\, x_i$. Then, the matrix-free application of the discrete operator $A$ to $x$ is given by computing fluxes with $x$ substituted for $Y$ in the above linear flux formulas:\n$$\nF^{\\mathrm{adv}}_{i+\\tfrac{1}{2}}(x) =\n\\begin{cases}\nu_{i+\\tfrac{1}{2}}\\, x_i, & \\text{if } u_{i+\\tfrac{1}{2}} > 0, \\\\\nu_{i+\\tfrac{1}{2}}\\, x_{i+1}, & \\text{if } u_{i+\\tfrac{1}{2}} \\le 0,\n\\end{cases}\n\\qquad\nF^{\\mathrm{diff}}_{i+\\tfrac{1}{2}}(x) = - D_{i+\\tfrac{1}{2}}\\, \\frac{x_{i+1} - x_i}{\\Delta x},\n$$\nand then\n$$\ny_i \\equiv (A x)_i = \\frac{F_{i+\\tfrac{1}{2}}(x) - F_{i-\\tfrac{1}{2}}(x)}{\\Delta x} + k_i\\, x_i,\n\\quad \\text{with } F_{i+\\tfrac{1}{2}}(x) = F^{\\mathrm{adv}}_{i+\\tfrac{1}{2}}(x) + F^{\\mathrm{diff}}_{i+\\tfrac{1}{2}}(x).\n$$\nAll quantities are nondimensional. Periodic boundary conditions are imposed by interpreting indices modulo $N$, i.e., $x_{-1} \\equiv x_{N-1}$ and $x_{N} \\equiv x_{0}$.\n\nYour task is to implement the matrix-free operation $y = A x$ using the flux computations above without assembling $A$. Then, for the test suite below, compute and report the resulting $y$ vectors.\n\nTest suite (each case specifies $N$, $\\Delta x$, face velocities $u_{i+\\tfrac{1}{2}}$, face diffusivities $D_{i+\\tfrac{1}{2}}$, cell reaction coefficients $k_i$, and the input vector $x$):\n\n- Case $1$ (pure advection, uniform positive velocity):\n  - $N = 6$, $\\Delta x = 1.0$,\n  - $u_{i+\\tfrac{1}{2}} = 2.0$ for all faces $i$,\n  - $D_{i+\\tfrac{1}{2}} = 0.0$ for all faces $i$,\n  - $k_i = 0.0$ for all cells $i$,\n  - $x = [1.0, 0.0, -1.0, 2.0, -2.0, 0.5]$.\n\n- Case $2$ (mixed advection, diffusion, and reaction with sign-changing velocity):\n  - $N = 6$, $\\Delta x = 1.0$,\n  - $u_{i+\\tfrac{1}{2}} = [1.0, -1.0, 1.0, -1.0, 1.0, -1.0]$,\n  - $D_{i+\\tfrac{1}{2}} = 0.5$ for all faces $i$,\n  - $k = [0.2, 0.0, 0.4, 0.0, 0.6, 0.0]$,\n  - $x = [0.3, -0.1, 0.5, -0.2, 0.0, 0.4]$.\n\n- Case $3$ (pure diffusion, no advection, no reaction):\n  - $N = 5$, $\\Delta x = 0.5$,\n  - $u_{i+\\tfrac{1}{2}} = 0.0$ for all faces $i$,\n  - $D_{i+\\tfrac{1}{2}} = 1.0$ for all faces $i$,\n  - $k_i = 0.0$ for all cells $i$,\n  - $x = [1.0, -1.0, 2.0, -2.0, 0.5]$.\n\n- Case $4$ (reaction only, spatially varying linearized reaction):\n  - $N = 4$, $\\Delta x = 1.0$,\n  - $u_{i+\\tfrac{1}{2}} = 0.0$ for all faces $i$,\n  - $D_{i+\\tfrac{1}{2}} = 0.0$ for all faces $i$,\n  - $k = [10.0, 1.0, 5.0, 0.1]$,\n  - $x = [0.01, 1.0, -0.2, 0.5]$.\n\nFinal output format: Your program should produce a single line of output containing the four resulting vectors $y$ for the cases above, as a comma-separated list of lists enclosed in square brackets, with no spaces, for example, $[[y^{(1)}],[y^{(2)}],[y^{(3)}],[y^{(4)}]]$, where $[y^{(c)}]$ denotes the list representation of the vector $y$ for case $c$.",
            "solution": "The problem is valid as it is scientifically grounded in the principles of computational fluid dynamics, well-posed with all necessary information provided, and objective in its formulation. It describes a standard matrix-free implementation of a discretized linear operator derived from an advection-diffusion-reaction equation, a common task in scientific computing.\n\nThe objective is to compute the result of a matrix-vector product, $y = A x$, without explicitly forming the matrix $A$. The vector $y$ is defined component-wise for each cell $i$ on a one-dimensional periodic grid:\n$$\ny_i \\equiv (A x)_i = \\frac{F_{i+\\tfrac{1}{2}}(x) - F_{i-\\tfrac{1}{2}}(x)}{\\Delta x} + k_i\\, x_i\n$$\nwhere $i \\in \\{0, 1, \\dots, N-1\\}$. All indices are treated modulo $N$ to enforce periodic boundary conditions. The term $k_i x_i$ is the contribution from a linearized reaction source. The term involving $F$ represents the net flux into cell $i$.\n\nThe total flux at a cell face, $F_{i+\\tfrac{1}{2}}(x)$, is the sum of an advective flux, $F^{\\mathrm{adv}}_{i+\\tfrac{1}{2}}(x)$, and a diffusive flux, $F^{\\mathrm{diff}}_{i+\\tfrac{1}{2}}(x)$.\n\nThe advective flux is given by a first-order upwind scheme, which selects the value of $x$ from the \"upwind\" cell based on the sign of the face velocity $u_{i+\\tfrac{1}{2}}$:\n$$\nF^{\\mathrm{adv}}_{i+\\tfrac{1}{2}}(x) =\n\\begin{cases}\nu_{i+\\tfrac{1}{2}}\\, x_i, & \\text{if } u_{i+\\tfrac{1}{2}} > 0, \\\\\nu_{i+\\tfrac{1}{2}}\\, x_{i+1}, & \\text{if } u_{i+\\tfrac{1}{2}} \\le 0.\n\\end{cases}\n$$\n\nThe diffusive flux is given by a central difference approximation to Fick's law:\n$$\nF^{\\mathrm{diff}}_{i+\\tfrac{1}{2}}(x) = - D_{i+\\tfrac{1}{2}}\\, \\frac{x_{i+1} - x_i}{\\Delta x}\n$$\nwhere $D_{i+\\tfrac{1}{2}}$ is the face diffusivity.\n\nTo implement the operation $y = A x$ efficiently, we can use a vectorized approach, which avoids explicit loops over the grid cells and is well-suited for libraries like NumPy. The strategy involves the following steps:\n\n1.  **Represent Fields as Arrays**: The grid variables $x$, $k$, and the face-based quantities $u$, $D$ are represented as one-dimensional NumPy arrays of length $N$.\n\n2.  **Handle Periodicity**: The periodic nature of the grid means that cell $i+1$ is the right neighbor of cell $i$, and for $i=N-1$, the right neighbor is cell $0$. Similarly, the left neighbor of cell $0$ is cell $N-1$. This \"wrapping\" of indices can be efficiently implemented using `np.roll()`.\n    - `np.roll(x, -1)` creates an array where the $i$-th element is $x_{i+1}$.\n    - `np.roll(x, 1)` creates an array where the $i$-th element is $x_{i-1}$.\n\n3.  **Compute Face Fluxes Vectorially**: We can compute all $N$ face fluxes, $F_{i+\\tfrac{1}{2}}$, simultaneously.\n    - Let `x_p1 = np.roll(x, -1)`. This array contains the values $\\{x_1, x_2, \\dots, x_{N-1}, x_0\\}$.\n    - The advective flux for all faces can be computed in a single line using `np.where()`:\n      `F_adv = u * np.where(u > 0, x, x_p1)`\n    - The diffusive flux for all faces is also a simple vectorized operation:\n      `F_diff = -D / dx * (x_p1 - x)`\n    - The total flux vector `F_total` is the sum of `F_adv` and `F_diff`. The $i$-th element of `F_total` corresponds to the flux $F_{i+\\tfrac{1}{2}}$.\n\n4.  **Compute Flux Divergence**: The flux divergence for cell $i$ is $\\frac{F_{i+\\tfrac{1}{2}} - F_{i-\\tfrac{1}{2}}}{\\Delta x}$. We already have the vector of fluxes $F_{i+\\tfrac{1}{2}}$. To get the vector of fluxes $F_{i-\\tfrac{1}{2}}$, we can simply roll the `F_total` array:\n    - Let `F_total_m1 = np.roll(F_total, 1)`. The $i$-th element of this array is $F_{(i-1)+\\tfrac{1}{2}} = F_{i-\\tfrac{1}{2}}$.\n    - The divergence for all cells becomes:\n      `div_F = (F_total - F_total_m1) / dx`\n\n5.  **Assemble the Final Vector**: Finally, the resulting vector $y$ is obtained by adding the reaction term contribution:\n      `y = div_F + k * x`\n\nThis vectorized procedure computes the entire vector $y$ without any explicit loops, leveraging the optimized performance of NumPy for array operations. This is the core of the matrix-free methodology for this operator. The provided Python code implements this exact algorithm to solve the test cases.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef matrix_vector_product(N: int, dx: float, u: list, D: list, k: list, x: list) -> list:\n    \"\"\"\n    Computes the matrix-free application y = Ax for a 1D advection-diffusion-reaction operator.\n\n    Args:\n        N: Number of cells.\n        dx: Grid spacing.\n        u: List of face velocities u_{i+1/2}.\n        D: List of face diffusivities D_{i+1/2}.\n        k: List of cell-centered linearized reaction coefficients k_i.\n        x: Input vector x.\n\n    Returns:\n        The resulting vector y as a list of floats.\n    \"\"\"\n    # Ensure inputs are NumPy arrays for vectorized operations.\n    u_arr = np.asarray(u)\n    D_arr = np.asarray(D)\n    k_arr = np.asarray(k)\n    x_arr = np.asarray(x)\n\n    # Create periodic-shifted versions of the vector x.\n    # x_p1[i] corresponds to x_{i+1} (value from the right neighbor).\n    x_p1 = np.roll(x_arr, -1)\n\n    # 1. Compute advective fluxes at all faces i + 1/2.\n    # The upwind value of x is chosen based on the sign of the velocity u.\n    upwind_x = np.where(u_arr > 0, x_arr, x_p1)\n    F_adv_face = u_arr * upwind_x\n\n    # 2. Compute diffusive fluxes at all faces i + 1/2.\n    F_diff_face = -D_arr / dx * (x_p1 - x_arr)\n\n    # 3. Sum fluxes to get the total flux at faces i + 1/2.\n    # F_total_face[i] corresponds to F_{i+1/2}(x).\n    F_total_face = F_adv_face + F_diff_face\n\n    # 4. Get fluxes at faces i - 1/2 by rolling the total flux array.\n    # F_total_face_m1[i] corresponds to F_{i-1/2}(x).\n    F_total_face_m1 = np.roll(F_total_face, 1)\n\n    # 5. Compute the flux divergence term for each cell i.\n    div_F = (F_total_face - F_total_face_m1) / dx\n\n    # 6. Add the local reaction term to get the final result y = Ax.\n    y = div_F + k_arr * x_arr\n\n    return y.tolist()\n\ndef solve():\n    \"\"\"\n    Defines and runs the test suite for the matrix-vector product,\n    then prints the results in the specified format.\n    \"\"\"\n    test_cases = [\n        # Case 1 (pure advection, uniform positive velocity)\n        {\n            \"N\": 6, \"dx\": 1.0, \"u\": [2.0] * 6, \"D\": [0.0] * 6, \"k\": [0.0] * 6,\n            \"x\": [1.0, 0.0, -1.0, 2.0, -2.0, 0.5]\n        },\n        # Case 2 (mixed advection, diffusion, and reaction with sign-changing velocity)\n        {\n            \"N\": 6, \"dx\": 1.0, \"u\": [1.0, -1.0, 1.0, -1.0, 1.0, -1.0],\n            \"D\": [0.5] * 6, \"k\": [0.2, 0.0, 0.4, 0.0, 0.6, 0.0],\n            \"x\": [0.3, -0.1, 0.5, -0.2, 0.0, 0.4]\n        },\n        # Case 3 (pure diffusion, no advection, no reaction)\n        {\n            \"N\": 5, \"dx\": 0.5, \"u\": [0.0] * 5, \"D\": [1.0] * 5, \"k\": [0.0] * 5,\n            \"x\": [1.0, -1.0, 2.0, -2.0, 0.5]\n        },\n        # Case 4 (reaction only, spatially varying linearized reaction)\n        {\n            \"N\": 4, \"dx\": 1.0, \"u\": [0.0] * 4, \"D\": [0.0] * 4,\n            \"k\": [10.0, 1.0, 5.0, 0.1], \"x\": [0.01, 1.0, -0.2, 0.5]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        y_vector = matrix_vector_product(\n            case[\"N\"], case[\"dx\"], case[\"u\"], case[\"D\"], case[\"k\"], case[\"x\"]\n        )\n        results.append(y_vector)\n\n    # Format the final output string as a list of lists with no spaces.\n    # e.g., [[val1,val2],[val3,val4]] -> \"[[val1,val2],[val3,val4]]\"\n    output_str = str(results).replace(\" \", \"\")\n    print(output_str)\n\nsolve()\n```"
        }
    ]
}