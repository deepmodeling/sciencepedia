{
    "hands_on_practices": [
        {
            "introduction": "To optimize code effectively, we must first understand its performance limitations. The Roofline model is an essential tool for this analysis, providing a visual and intuitive way to understand the interplay between a kernel's computational intensity and the hardware's peak throughput and memory bandwidth. This exercise will guide you through applying the Roofline model to a realistic combustion chemistry kernel, a common component in reacting flow simulations . By calculating the arithmetic intensity and comparing it to the GPU's capabilities, you will learn to identify whether a kernel's performance is limited by memory bandwidth or computational throughput, a crucial first step in any optimization effort.",
            "id": "4028784",
            "problem": "A finite-volume reacting-flow solver evaluates species source terms in a per-cell kernel on a Graphics Processing Unit (GPU). Each cell update carries out a floating-point workload of $F$ floating-point operations (flops) and transfers $B$ bytes through high-bandwidth device memory. Assume double precision (binary64) arithmetic. The kernel performs only streaming, perfectly coalesced global memory accesses for the per-cell state and writes back updated fields, with no reuse across cells, so that the total data traffic per cell equals $B$. The GPU has a sustained peak double-precision compute throughput of $P_{\\text{peak}}$ flops per second and a sustained device-memory bandwidth of $\\beta$ bytes per second. Use fundamental definitions of arithmetic intensity and the roofline performance model to derive an expression for the arithmetic intensity and to determine how the kernel’s performance is bounded relative to the bandwidth and peak-compute roofs.\n\nNow specialize to the following scientifically realistic parameters for a detailed-chemistry species source term kernel:\n- Per-cell floating-point work: $F = 6.0 \\times 10^{4}$ flops.\n- Per-cell data movement: $B = 8.0 \\times 10^{3}$ bytes.\n- GPU sustained peak double-precision throughput: $P_{\\text{peak}} = 9.7 \\times 10^{12}$ flops per second.\n- GPU sustained device-memory bandwidth: $\\beta = 1.6 \\times 10^{12}$ bytes per second.\n\nUsing only fundamental definitions, compute the arithmetic intensity and place the kernel relative to the bandwidth and compute roofs to obtain the roofline-predicted sustained performance. Express your final numerical answer as the predicted sustained performance in giga floating-point operations per second (GFLOP/s), and round your answer to four significant figures.",
            "solution": "The problem will be validated according to the specified criteria.\n\n### Step 1: Extract Givens\n- Per-cell floating-point workload: $F = 6.0 \\times 10^{4}$ flops\n- Per-cell data movement: $B = 8.0 \\times 10^{3}$ bytes\n- Arithmetic precision: double precision (binary64)\n- Memory access pattern: streaming, perfectly coalesced global memory accesses, no reuse across cells.\n- GPU sustained peak double-precision throughput: $P_{\\text{peak}} = 9.7 \\times 10^{12}$ flops per second.\n- GPU sustained device-memory bandwidth: $\\beta = 1.6 \\times 10^{12}$ bytes per second.\n- Final answer requirement: express the predicted sustained performance in giga floating-point operations per second (GFLOP/s), rounded to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, well-posed, and objective.\n- **Scientifically Grounded:** The problem uses the roofline performance model, a fundamental and widely accepted tool in high-performance computing for analyzing the performance of computational kernels. The scenario of a reacting-flow solver on a GPU is a standard application in computational science. The provided parameters for floating-point operations, data movement, peak throughput, and memory bandwidth are realistic for a modern GPU executing a complex chemical kinetics calculation.\n- **Well-Posed:** All necessary data ($F$, $B$, $P_{\\text{peak}}$, $\\beta$) and definitions are provided to compute the arithmetic intensity and the predicted performance using the roofline model. The problem is self-contained and leads to a unique, meaningful solution.\n- **Objective:** The problem is stated using precise, technical terminology (\"finite-volume\", \"coalesced global memory accesses\", \"arithmetic intensity\") and is free from subjective or ambiguous language.\n\nThe problem does not exhibit any of the flaws listed in the instructions (e.g., scientific unsoundness, incompleteness, contradiction, etc.).\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\n### Solution Derivation\nThe performance of a computational kernel on a processor like a GPU is typically limited by either its peak computational ability or the rate at which it can be supplied with data from memory. The roofline model formalizes this concept.\n\nFirst, we define the arithmetic intensity, $I$, of the kernel. This is the ratio of the total floating-point operations ($F$) performed to the total data volume ($B$) moved to and from main memory.\n$$I = \\frac{F}{B}$$\nThe units of $I$ are flops per byte.\n\nThe roofline model states that the attainable performance, $P_{\\text{attainable}}$, measured in flops per second, is limited by two factors: the peak compute throughput of the hardware, $P_{\\text{peak}}$, and the performance achievable given the memory bandwidth, $\\beta$.\n\nThe maximum performance is inherently capped by the processor's peak throughput:\n$$P_{\\text{attainable}} \\le P_{\\text{peak}}$$\nThe performance is also limited by the memory subsystem. The time required to execute the kernel, $t$, must be at least as long as the time it takes to transfer the necessary data, $t_{\\text{memory}} = B / \\beta$. The performance, which is $F/t$, is thus bounded by:\n$$P_{\\text{attainable}} = \\frac{F}{t} \\le \\frac{F}{t_{\\text{memory}}} = \\frac{F}{B/\\beta} = \\left(\\frac{F}{B}\\right) \\beta = I \\cdot \\beta$$\nCombining these two limits, the roofline-predicted performance is the minimum of the two ceilings:\n$$P_{\\text{attainable}} = \\min(P_{\\text{peak}}, I \\cdot \\beta)$$\nThe kernel is considered **compute-bound** if its performance is limited by $P_{\\text{peak}}$, and **memory-bound** (or bandwidth-bound) if it is limited by $I \\cdot \\beta$. The transition between these two regimes occurs at a specific arithmetic intensity known as the machine's ridge point, $I_{\\text{ridge}}$. This point is found by setting the two performance limits equal:\n$$P_{\\text{peak}} = I_{\\text{ridge}} \\cdot \\beta \\implies I_{\\text{ridge}} = \\frac{P_{\\text{peak}}}{\\beta}$$\nIf the kernel's arithmetic intensity $I > I_{\\text{ridge}}$, it is compute-bound. If $I  I_{\\text{ridge}}$, it is memory-bound.\n\nNow, we specialize to the given parameters.\n- Per-cell floating-point work: $F = 6.0 \\times 10^{4}$ flops.\n- Per-cell data movement: $B = 8.0 \\times 10^{3}$ bytes.\n\nThe arithmetic intensity of the kernel is:\n$$I = \\frac{6.0 \\times 10^{4} \\text{ flops}}{8.0 \\times 10^{3} \\text{ bytes}} = \\frac{60}{8} \\text{ flops/byte} = 7.5 \\text{ flops/byte}$$\nThe GPU hardware parameters are:\n- Peak double-precision throughput: $P_{\\text{peak}} = 9.7 \\times 10^{12}$ flops/s.\n- Memory bandwidth: $\\beta = 1.6 \\times 10^{12}$ bytes/s.\n\nNext, we compute the ridge point of the GPU:\n$$I_{\\text{ridge}} = \\frac{P_{\\text{peak}}}{\\beta} = \\frac{9.7 \\times 10^{12} \\text{ flops/s}}{1.6 \\times 10^{12} \\text{ bytes/s}} = \\frac{9.7}{1.6} \\text{ flops/byte} = 6.0625 \\text{ flops/byte}$$\nWe compare the kernel's arithmetic intensity $I$ to the machine's ridge point $I_{\\text{ridge}}$:\n$$I = 7.5 \\text{ flops/byte} > I_{\\text{ridge}} = 6.0625 \\text{ flops/byte}$$\nSince the kernel's arithmetic intensity is greater than the ridge point, the kernel's performance is compute-bound.\n\nTherefore, the roofline-predicted performance is determined by the peak compute throughput of the GPU:\n$$P_{\\text{attainable}} = \\min(P_{\\text{peak}}, I \\cdot \\beta) = P_{\\text{peak}}$$\n$$P_{\\text{attainable}} = 9.7 \\times 10^{12} \\text{ flops/s}$$\nThe problem asks for the answer to be expressed in giga floating-point operations per second (GFLOP/s). We know that $1 \\text{ GFLOP/s} = 10^9 \\text{ flops/s}$. Converting the result:\n$$P_{\\text{attainable}} = \\frac{9.7 \\times 10^{12} \\text{ flops/s}}{10^9 \\text{ flops/s per GFLOP/s}} = 9.7 \\times 10^3 \\text{ GFLOP/s} = 9700 \\text{ GFLOP/s}$$\nThe problem requires the final answer to be rounded to four significant figures. The calculated value is exactly $9700$, which can be expressed with four significant figures. Thus, no further rounding is necessary.",
            "answer": "$$\\boxed{9700}$$"
        },
        {
            "introduction": "The Roofline model is not just for post-mortem analysis; it is a powerful predictive tool for making strategic design decisions. A frequent choice in GPU programming is whether to fuse multiple, smaller kernels into a single, larger one to improve data locality and reduce off-chip memory traffic. This practice challenges you to use Roofline analysis to quantitatively evaluate the performance trade-offs of kernel fusion . You will see how splitting a kernel, which can sometimes be necessary to manage resource constraints like register pressure, may increase memory traffic and shift the performance bottleneck, directly impacting overall execution time.",
            "id": "4028809",
            "problem": "A reacting-flow time advancement for a premixed methane–air flame is implemented on a Graphics Processing Unit (GPU). The chemistry update per cell evaluates thermodynamic properties, chemical source terms, and updates species mass fractions and temperature. For a mechanism with $50$ species, detailed profiling of the fused implementation (single kernel that performs all stages without intermediate global-memory writes) reports the following per-cell metrics: total floating-point operation count $F_{\\mathrm{fused}} = 1.2 \\times 10^{4}$ and total global-memory traffic $M_{\\mathrm{fused}} = 6.0 \\times 10^{2}$ bytes (sum of global loads and stores). When the kernel is split into two kernels (first kernel evaluates properties and source terms, second kernel updates the state, with intermediate reaction-rate vectors materialized in global memory), the total floating-point operation count remains approximately the same, $F_{\\mathrm{split}} \\approx 1.2 \\times 10^{4}$, but the total global-memory traffic increases to $M_{\\mathrm{split}} = 1.4 \\times 10^{3}$ bytes per cell due to intermediate writes and reads and additional spill/reload.\n\nThe GPU has a peak single-precision compute throughput $P_{\\max} = 1.4 \\times 10^{13}$ floating-point operations per second and a sustained global-memory bandwidth $B_{\\max} = 9.0 \\times 10^{11}$ bytes per second. The grid has $N_{c} = 5.0 \\times 10^{7}$ cells, and the chemistry update is applied once per time step. Assume ideal scaling across Streaming Multiprocessors (no contention effects or kernel launch overheads), and neglect latency hiding imperfections.\n\nStarting from first principles, use roofline analysis to determine the bound on the achievable performance for each strategy and predict the execution time for one chemistry-update time step for both the fused and split implementations. Decide which strategy is optimal under these assumptions. Report the predicted runtime of the optimal strategy for one time step in milliseconds. Round your answer to three significant figures and express the time in milliseconds.",
            "solution": "The roofline model constrains the attainable performance of a computation by two fundamental machine limits and the algorithm’s arithmetic intensity. The fundamental limits are the peak floating-point throughput $P_{\\max}$ of the processor and the sustained global-memory bandwidth $B_{\\max}$ of the memory subsystem. The arithmetic intensity $R$ of an algorithm is defined as the number of floating-point operations performed per byte of data moved to and from global memory, namely\n$$\nR \\equiv \\frac{F}{M}\n$$\nwhere $F$ is the total floating-point operation count for the workload and $M$ is the corresponding global-memory traffic. The performance bound implied by the roofline model is that the achievable throughput $P_{\\mathrm{achieved}}$ cannot exceed either the compute peak or the bandwidth-limited ceiling, which is the product of bandwidth and arithmetic intensity:\n$$\nP_{\\mathrm{achieved}} \\leq \\min\\!\\big( P_{\\max},\\ B_{\\max} \\, R \\big).\n$$\nThis statement is derived from first principles: if the computation requires $R$ floating-point operations per byte moved, and the memory subsystem can deliver at most $B_{\\max}$ bytes per second, then the computation cannot sustain more than $B_{\\max} R$ floating-point operations per second from the memory side; simultaneously, no computation can exceed the processor peak $P_{\\max}$.\n\nGiven $N_{c}$ cells, each cell carries the same workload, so the total work per time step is $F_{\\mathrm{total}} = F \\, N_{c}$. The execution time $T$ under the roofline bound is then\n$$\nT = \\frac{F_{\\mathrm{total}}}{P_{\\mathrm{achieved}}} = \\frac{F \\, N_{c}}{\\min\\!\\big(P_{\\max},\\ B_{\\max} R\\big)}.\n$$\n\nWe now compute the arithmetic intensities for the two strategies.\n\nFor the fused kernel,\n$$\nF_{\\mathrm{fused}} = 1.2 \\times 10^{4}, \\quad M_{\\mathrm{fused}} = 6.0 \\times 10^{2},\n$$\nso\n$$\nR_{\\mathrm{fused}} = \\frac{F_{\\mathrm{fused}}}{M_{\\mathrm{fused}}} = \\frac{1.2 \\times 10^{4}}{6.0 \\times 10^{2}} = 2.0 \\times 10^{1}.\n$$\nThe bandwidth-limited ceiling for the fused kernel is\n$$\nB_{\\max} R_{\\mathrm{fused}} = \\left(9.0 \\times 10^{11}\\right) \\times \\left(2.0 \\times 10^{1}\\right) = 1.8 \\times 10^{13}.\n$$\nComparing with the compute peak,\n$$\nP_{\\max} = 1.4 \\times 10^{13}, \\quad B_{\\max} R_{\\mathrm{fused}} = 1.8 \\times 10^{13},\n$$\nthe fused kernel is compute-bound, because $P_{\\max}  B_{\\max} R_{\\mathrm{fused}}$. Therefore\n$$\nP_{\\mathrm{achieved,fused}} = P_{\\max} = 1.4 \\times 10^{13}.\n$$\nThe total work per time step is\n$$\nF_{\\mathrm{total}} = F_{\\mathrm{fused}} N_{c} = \\left(1.2 \\times 10^{4}\\right)\\left(5.0 \\times 10^{7}\\right) = 6.0 \\times 10^{11}.\n$$\nHence the fused time is\n$$\nT_{\\mathrm{fused}} = \\frac{6.0 \\times 10^{11}}{1.4 \\times 10^{13}} = 4.2857142857 \\times 10^{-2}\\ \\mathrm{s}.\n$$\nExpressed in milliseconds,\n$$\nT_{\\mathrm{fused,ms}} = \\left(4.2857142857 \\times 10^{-2}\\right)\\times \\left(1.0 \\times 10^{3}\\right) = 4.2857142857 \\times 10^{1}\\ \\mathrm{ms} = 42.857142857\\ \\mathrm{ms}.\n$$\n\nFor the split kernels,\n$$\nF_{\\mathrm{split}} \\approx 1.2 \\times 10^{4}, \\quad M_{\\mathrm{split}} = 1.4 \\times 10^{3},\n$$\nso\n$$\nR_{\\mathrm{split}} = \\frac{F_{\\mathrm{split}}}{M_{\\mathrm{split}}} = \\frac{1.2 \\times 10^{4}}{1.4 \\times 10^{3}} = 8.571428571.\n$$\nThe bandwidth-limited ceiling for the split implementation is\n$$\nB_{\\max} R_{\\mathrm{split}} = \\left(9.0 \\times 10^{11}\\right) \\times \\left(8.571428571\\right) = 7.714285714 \\times 10^{12}.\n$$\nComparing with the compute peak,\n$$\nP_{\\max} = 1.4 \\times 10^{13}, \\quad B_{\\max} R_{\\mathrm{split}} = 7.714285714 \\times 10^{12},\n$$\nthe split implementation is memory-bound, because $B_{\\max} R_{\\mathrm{split}}  P_{\\max}$. Therefore\n$$\nP_{\\mathrm{achieved,split}} = 7.714285714 \\times 10^{12}.\n$$\nWith the same total work $F_{\\mathrm{total}} = 6.0 \\times 10^{11}$, the split time is\n$$\nT_{\\mathrm{split}} = \\frac{6.0 \\times 10^{11}}{7.714285714 \\times 10^{12}} = 7.777777778 \\times 10^{-2}\\ \\mathrm{s},\n$$\nand in milliseconds,\n$$\nT_{\\mathrm{split,ms}} = \\left(7.777777778 \\times 10^{-2}\\right)\\times \\left(1.0 \\times 10^{3}\\right) = 7.777777778 \\times 10^{1}\\ \\mathrm{ms} = 77.77777778\\ \\mathrm{ms}.\n$$\n\nDecision: Since $T_{\\mathrm{fused,ms}} \\approx 42.857142857\\ \\mathrm{ms}$ and $T_{\\mathrm{split,ms}} \\approx 77.77777778\\ \\mathrm{ms}$, the fused strategy is optimal under the stated assumptions. Rounding the optimal runtime to three significant figures and expressing the answer in milliseconds yields\n$$\nT_{\\mathrm{optimal,ms}} = 42.9\\ \\mathrm{ms}.\n$$",
            "answer": "$$\\boxed{42.9}$$"
        },
        {
            "introduction": "After high-level analysis identifies a kernel as memory-bound, the focus shifts to optimizing its data access patterns. For the stencil-based computations that dominate the transport solvers in computational combustion, efficient use of the GPU's on-chip shared memory is paramount for achieving high performance. This exercise tackles a critical low-level optimization: avoiding shared memory bank conflicts by strategically padding data arrays . You will derive and implement a padding scheme, gaining hands-on experience with the GPU memory architecture and learning a fundamental technique to ensure that a full warp of threads can access data in parallel without serialization.",
            "id": "4028757",
            "problem": "You are given a three-dimensional tile with halo regions to be staged in Graphics Processing Unit (GPU) shared memory for finite-volume or finite-difference stencil operations in computational combustion. Assume the following architecture and layout: shared memory has $32$ banks, the warp size is $32$ threads, and the bank index for a $4$-byte word at word address $a$ is $a \\bmod 32$. Use row-major layout where $x$ varies fastest, followed by $y$, followed by $z$. The tile includes halo cells of width $h_x$, $h_y$, and $h_z$ on the $x$, $y$, and $z$ faces, respectively. The unpadded tile extents including halos are $s_x = n_x + 2 h_x$, $s_y = n_y + 2 h_y$, and $s_z = n_z + 2 h_z$. You will introduce padding in the $x$ and $y$ dimensions, denoted $p_x$ and $p_y$, so that the padded pitches are $\\pi_x = s_x + p_x$ and $\\pi_y = s_y + p_y$, and $\\pi_z = s_z$ (no padding in $z$). Let the shared-memory address in $4$-byte words for an element at indices $(x,y,z)$ be:\n$$\nA(x,y,z) = (z \\cdot \\pi_x \\pi_y) + (y \\cdot \\pi_x) + x\n$$\nA warp performs three access patterns commonly encountered in stencil updates:\n1. $x$-line access: threads access $(x_0 + t, y_0, z_0)$ for $t \\in \\{0,1,\\ldots,31\\}$.\n2. $y$-line access: threads access $(x_0, y_0 + t, z_0)$ for $t \\in \\{0,1,\\ldots,31\\}$.\n3. $z$-line access: threads access $(x_0, y_0, z_0 + t)$ for $t \\in \\{0,1,\\ldots,31\\}$.\n\nStarting from the fundamental base that a shared-memory bank conflict occurs when two or more threads in a warp access different addresses mapping to the same bank and that conflict-free access requires that all $32$ threads map to distinct banks, derive an indexing and padding scheme that ensures conflict-free bank access for all three patterns. Your derivation should begin from the bank-index formula $b = A \\bmod 32$ and the row-major address arithmetic, and reason about the stride in $4$-byte words for each pattern. You must explicitly define the conditions on $\\pi_x$ and $\\pi_y$ under which a warp experiences no bank conflicts for $y$-line and $z$-line access. Then, derive the minimal padding values $p_x$ and $p_y$ that satisfy these conditions and quantify the padding overhead, defined as the fractional increase in allocated shared-memory elements:\n$$\n\\text{overhead} = \\frac{(\\pi_x \\pi_y \\pi_z) - (s_x s_y s_z)}{s_x s_y s_z}\n$$\nYou must implement a program that, for each test case below, computes the minimal nonnegative padding $(p_x, p_y)$ that guarantees conflict-free access for all three patterns, verifies conflict-freedom by explicitly computing bank indices for $t \\in \\{0,\\ldots,31\\}$, and outputs the padding and overhead along with three booleans indicating conflict-freedom for $x$-, $y$-, and $z$-line accesses, respectively. Assume $4$-byte elements throughout. The base indices $(x_0,y_0,z_0)$ may be taken as $(0,0,0)$ without loss of generality.\n\nTest suite (each test case is a tuple $(n_x,n_y,n_z,h_x,h_y,h_z)$):\n- Case 1: $(30,2,1,1,0,0)$\n- Case 2: $(32,8,4,1,1,1)$\n- Case 3: $(14,2,3,1,0,0)$\n- Case 4: $(1,1,1,0,0,0)$\n- Case 5: $(31,32,1,0,0,0)$\n\nYour program should produce a single line of output containing the results for the five cases as a comma-separated list enclosed in square brackets, where each case’s result is a list in the form $[p_x,p_y,\\text{overhead},\\text{ok\\_x},\\text{ok\\_y},\\text{ok\\_z}]$. Use a decimal number for $\\text{overhead}$ and booleans for $\\text{ok\\_x}$, $\\text{ok\\_y}$, and $\\text{ok\\_z}$. For example, your output should look like\n$$\n[[p_x,p_y,\\text{overhead},\\text{ok\\_x},\\text{ok\\_y},\\text{ok\\_z}],\\ldots]\n$$\nwith no spaces in the printed line.",
            "solution": "The problem requires the derivation of a memory padding scheme for a three-dimensional tile stored in a Graphics Processing Unit's (GPU) shared memory to ensure conflict-free access for a warp of threads performing stencil-like operations. We begin by formalizing the conditions for bank conflicts and then derive the minimal padding required to prevent them.\n\nThe GPU architecture specifies $N_B = 32$ shared memory banks and a warp size of $W = 32$ threads. The bank index $b$ for a $4$-byte word at address $a$ is given by the formula $b = a \\pmod{32}$. A bank conflict occurs if two or more threads within the same warp access distinct memory addresses that map to the same bank index. For an access pattern to be conflict-free, all $32$ threads in the warp must access addresses that map to $32$ distinct bank indices.\n\nThe data is stored in a 3D array using a row-major layout with padding in the $x$ and $y$ dimensions. The address $A$ of an element at logical coordinates $(x,y,z)$ is given by:\n$$\nA(x,y,z) = (z \\cdot \\pi_x \\cdot \\pi_y) + (y \\cdot \\pi_x) + x\n$$\nwhere $\\pi_x = s_x + p_x$ and $\\pi_y = s_y + p_y$ are the padded pitches (strides) in the $x$ and $y$ dimensions, respectively. The unpadded dimensions are $s_x = n_x + 2h_x$, $s_y = n_y + 2h_y$, and $s_z = n_z + 2h_z$. Note that $\\pi_z = s_z$. We analyze the three specified access patterns for a warp, where the $k$-th thread (for $k \\in \\{0, 1, \\dots, 31\\}$) accesses a specific address. For simplicity and without loss of generality as stated, we assume the base indices are $(x_0, y_0, z_0) = (0,0,0)$.\n\nLet the address accessed by thread $k$ be $A_k$. The corresponding bank index is $b_k = A_k \\pmod{32}$. An access pattern is conflict-free if and only if the set of bank indices $\\{b_0, b_1, \\dots, b_{31}\\}$ contains $32$ distinct values. This is equivalent to the addresses of the $32$ threads having distinct values modulo $32$. If the addresses accessed by threads $k=0, \\dots, 31$ are of the form $A_0 + k \\cdot S$, where $S$ is a constant stride, the condition for conflict-free access simplifies. The bank indices are $(A_0 + k \\cdot S) \\pmod{32}$. This set of bank indices will be a permutation of $\\{0, 1, \\dots, 31\\}$ if and only if the stride $S$ is coprime to the number of banks, $N_B = 32$. That is, $\\gcd(S, 32) = 1$.\n\nNow, we derive the stride $S$ for each access pattern.\n\n**1. x-line access:**\nThreads access coordinates $(k, 0, 0)$ for $k \\in \\{0, \\dots, 31\\}$.\nThe address for thread $k$ is $A_k = A(k, 0, 0) = (0 \\cdot \\pi_x \\pi_y) + (0 \\cdot \\pi_x) + k = k$.\nThe stride between addresses accessed by consecutive threads is $S_x = A_{k+1} - A_k = (k+1) - k = 1$.\nWe check the condition for conflict-free access: $\\gcd(S_x, 32) = \\gcd(1, 32) = 1$.\nThis condition is always met. Therefore, x-line access is inherently conflict-free, irrespective of any padding. No conditions are imposed on $\\pi_x$ or $\\pi_y$.\n\n**2. y-line access:**\nThreads access coordinates $(0, k, 0)$ for $k \\in \\{0, \\dots, 31\\}$.\nThe address for thread $k$ is $A_k = A(0, k, 0) = (0 \\cdot \\pi_x \\pi_y) + (k \\cdot \\pi_x) + 0 = k \\cdot \\pi_x$.\nThe stride between addresses accessed by consecutive threads is $S_y = A_{k+1} - A_k = (k+1)\\pi_x - k\\pi_x = \\pi_x$.\nFor conflict-free access, we must have $\\gcd(S_y, 32) = \\gcd(\\pi_x, 32) = 1$.\nSince $32 = 2^5$, any number coprime to $32$ must not have $2$ as a prime factor, meaning it must be an odd number.\nThus, the condition for conflict-free y-line access is that the padded pitch $\\pi_x$ must be an odd number.\nCondition: $\\pi_x = s_x + p_x$ must be odd.\n\n**3. z-line access:**\nThreads access coordinates $(0, 0, k)$ for $k \\in \\{0, \\dots, 31\\}$.\nThe address for thread $k$ is $A_k = A(0, 0, k) = (k \\cdot \\pi_x \\pi_y) + (0 \\cdot \\pi_x) + 0 = k \\cdot \\pi_x \\pi_y$.\nThe stride between addresses accessed by consecutive threads is $S_z = A_{k+1} - A_k = (k+1)\\pi_x\\pi_y - k\\pi_x\\pi_y = \\pi_x\\pi_y$.\nFor conflict-free access, we must have $\\gcd(S_z, 32) = \\gcd(\\pi_x \\pi_y, 32) = 1$.\nThis requires the product $\\pi_x \\pi_y$ to be an odd number. A product of two integers is odd if and only if both integers are odd.\nThus, the conditions for conflict-free z-line access are that both $\\pi_x$ and $\\pi_y$ must be odd numbers.\nCondition: $\\pi_x = s_x + p_x$ must be odd AND $\\pi_y = s_y + p_y$ must be odd.\n\n**Derivation of Minimal Padding:**\nTo satisfy the conditions for all three access patterns simultaneously, both $\\pi_x$ and $\\pi_y$ must be odd. We need to find the minimal non-negative padding values, $p_x$ and $p_y$, to achieve this.\n\nFor $\\pi_x = s_x + p_x$ to be odd:\n- If $s_x$ is odd, we can choose $p_x=0$ (since odd + even = odd, and $0$ is even). This is the minimal non-negative choice.\n- If $s_x$ is even, we must choose an odd $p_x$. The minimal non-negative odd value is $p_x=1$.\nThis can be summarized as: $p_x = 1$ if $s_x$ is even, and $p_x = 0$ if $s_x$ is odd. This is equivalent to $p_x = (s_x+1) \\pmod 2$.\n\nFor $\\pi_y = s_y + p_y$ to be odd:\n- Similarly, if $s_y$ is odd, we choose $p_y=0$.\n- If $s_y$ is even, we choose $p_y=1$.\nThis is equivalent to $p_y = (s_y+1) \\pmod 2$.\n\nThese minimal, non-negative choices for $p_x$ and $p_y$ constitute the derived padding scheme.\n\n**Padding Overhead Calculation:**\nThe padding overhead is the fractional increase in the total number of allocated shared memory elements.\nThe original volume is $V_{orig} = s_x s_y s_z$.\nThe padded volume is $V_{pad} = \\pi_x \\pi_y \\pi_z = (s_x + p_x)(s_y + p_y)s_z$.\nThe overhead is defined as:\n$$\n\\text{overhead} = \\frac{V_{pad} - V_{orig}}{V_{orig}} = \\frac{(s_x+p_x)(s_y+p_y)s_z - s_x s_y s_z}{s_x s_y s_z}\n$$\nThis formula is used to compute the quantitative impact of the padding.\nThe algorithm for the solution is thus:\n1. For a given test case $(n_x, n_y, n_z, h_x, h_y, h_z)$, compute the unpadded dimensions $s_x, s_y, s_z$.\n2. Determine the minimal non-negative padding $p_x, p_y$ based on the parity of $s_x$ and $s_y$.\n3. Compute the padded pitches $\\pi_x, \\pi_y, \\pi_z$.\n4. Calculate the padding overhead.\n5. Verify conflict-freedom for all three access patterns using the derived $\\pi_x$ and $\\pi_y$ to confirm the theoretical derivation.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# No other libraries are imported, as per the rules.\n\ndef solve():\n    \"\"\"\n    Calculates the minimal padding for conflict-free shared memory access\n    and the associated overhead for a series of tile configurations.\n    \"\"\"\n    # Define the test cases from the problem statement:\n    # (n_x, n_y, n_z, h_x, h_y, h_z)\n    test_cases = [\n        (30, 2, 1, 1, 0, 0),\n        (32, 8, 4, 1, 1, 1),\n        (14, 2, 3, 1, 0, 0),\n        (1, 1, 1, 0, 0, 0),\n        (31, 32, 1, 0, 0, 0),\n    ]\n\n    results = []\n    \n    # Constants from the problem\n    warp_size = 32\n    num_banks = 32\n\n    def check_conflict_free(stride, size):\n        \"\"\"\n        Checks if an access pattern with a given stride is conflict-free.\n        An access is conflict-free if gcd(stride, size) == 1.\n        This is equivalent to checking if all threads map to a unique bank.\n        \"\"\"\n        banks = set()\n        for t in range(size):\n            bank_index = (t * stride) % size\n            banks.add(bank_index)\n        return len(banks) == size\n\n    for case in test_cases:\n        nx, ny, nz, hx, hy, hz = case\n\n        # Calculate unpadded tile extents including halos\n        sx = nx + 2 * hx\n        sy = ny + 2 * hy\n        sz = nz + 2 * hz\n\n        # Derive minimal padding px and py\n        # The padded pitch (e.g., pi_x = sx + px) must be odd to be coprime with 32.\n        # If sx is even, we need to add 1 to make it odd. p_x = 1.\n        # If sx is odd, we can add 0 to keep it odd. p_x = 0.\n        px = 1 if sx % 2 == 0 else 0\n        py = 1 if sy % 2 == 0 else 0\n\n        # Calculate padded pitches\n        pi_x = sx + px\n        pi_y = sy + py\n        pi_z = sz  # No padding in z\n\n        # Calculate padding overhead\n        vol_unpadded = sx * sy * sz\n        vol_padded = pi_x * pi_y * pi_z\n        \n        # Overhead is 0 if unpadded volume is 0 to avoid division by zero,\n        # though problem constraints ensure it's positive.\n        if vol_unpadded  0:\n            overhead = (vol_padded - vol_unpadded) / vol_unpadded\n        else:\n            overhead = 0.0\n\n        # Verify conflict-freedom for the three access patterns\n        \n        # 1. x-line access: stride is 1\n        stride_x = 1\n        ok_x = check_conflict_free(stride_x, warp_size)\n\n        # 2. y-line access: stride is pi_x\n        stride_y = pi_x\n        ok_y = check_conflict_free(stride_y, warp_size)\n\n        # 3. z-line access: stride is pi_x * pi_y\n        stride_z = pi_x * pi_y\n        ok_z = check_conflict_free(stride_z, warp_size)\n\n        # Store the results for this case\n        results.append([px, py, overhead, ok_x, ok_y, ok_z])\n\n    # Format the final output string exactly as required, with no spaces.\n    results_str_list = []\n    for res in results:\n        # Format: [px,py,overhead,ok_x,ok_y,ok_z]\n        # Python's str() for bools gives 'True'/'False', which is acceptable.\n        res_str = f\"[{res[0]},{res[1]},{res[2]},{str(res[3]).lower()},{str(res[4]).lower()},{str(res[5]).lower()}]\"\n        results_str_list.append(res_str)\n        \n    final_output = f\"[{','.join(results_str_list)}]\"\n    print(final_output)\n\nsolve()\n```"
        }
    ]
}