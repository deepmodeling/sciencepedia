{
    "hands_on_practices": [
        {
            "introduction": "This practice goes to the heart of the closure problem in turbulent combustion, where chemical source terms are highly nonlinear functions of temperature and species concentrations. This exercise demonstrates why simply using the filtered (mean) values in the original chemical rate expressions leads to significant errors. By performing a second-order expansion, you will quantify the correction needed to account for sub-filter fluctuations, gaining a concrete understanding of the challenge that machine learning models aim to solve .",
            "id": "4037717",
            "problem": "You are given a micro-kinetics mechanism for a reacting mixture that defines a progress-variable source rate as the sum of two elementary reaction rates. Consider the Large-Eddy Simulation (LES) filtered progress-variable source term denoted by $\\tilde{\\dot{\\omega}}_c$. The closure problem arises because the filtered source $\\tilde{\\dot{\\omega}}_c$ is, in general, not equal to the source evaluated at filtered means due to nonlinearity and subfilter covariance. Your task is to compute the modeled filtered source by evaluating the source at filtered means, and to quantify the modeling error attributable to nonlinearity and covariance via a second-order moment expansion.\n\nFundamental base to use:\n- The filtered transport equation in Large-Eddy Simulation (LES) includes a source term $\\tilde{\\dot{\\omega}}_c$ that is the filter of the microscopic source $\\dot{\\omega}_c(\\mathbf{Y},T)$, where $\\mathbf{Y}$ denotes species mass fractions and $T$ denotes temperature.\n- The expectation of a nonlinear function under small fluctuations admits a second-order Taylor expansion: for a sufficiently smooth function $f$, random vector $\\mathbf{X}$ with mean $\\boldsymbol{\\mu}$ and covariance $\\boldsymbol{\\Sigma}$, $\\mathbb{E}[f(\\mathbf{X})] \\approx f(\\boldsymbol{\\mu}) + \\frac{1}{2}\\,\\mathrm{tr}\\left(\\mathbf{H}_f(\\boldsymbol{\\mu})\\,\\boldsymbol{\\Sigma}\\right)$, where $\\mathbf{H}_f$ is the Hessian matrix of second derivatives of $f$ with respect to its inputs.\n\nMechanism definition:\n- Let the reacting system involve species with mass fractions $\\mathbf{Y} = (Y_F, Y_{O_2}, Y_R)$ for fuel, oxidizer, and an intermediate radical, respectively, and temperature $T$ in Kelvin.\n- Two elementary reactions contribute to the progress variable source:\n  1. Reaction $1$: $F + O_2 \\rightarrow P + R$ with rate\n     $$r_1(Y_F, Y_{O_2}, T) = A_1\\,Y_F^{a_1}\\,Y_{O_2}^{b_1}\\,\\exp\\!\\left(-\\frac{E_1}{R_u\\,T}\\right),$$\n  2. Reaction $2$: $R + O_2 \\rightarrow P$ with rate\n     $$r_2(Y_R, Y_{O_2}, T) = A_2\\,Y_R^{a_2}\\,Y_{O_2}^{b_2}\\,\\exp\\!\\left(-\\frac{E_2}{R_u\\,T}\\right),$$\n  where $A_1$ and $A_2$ are pre-exponential factors in $\\mathrm{s}^{-1}$, $a_1$, $a_2$, $b_1$, $b_2$ are reaction orders (dimensionless), $E_1$ and $E_2$ are activation energies in $\\mathrm{J/mol}$, and $R_u$ is the Universal Gas Constant with $R_u = 8.314\\,\\mathrm{J/(mol\\,K)}$.\n- Define the microscopic progress-variable source rate as\n  $$\\dot{\\omega}_c(\\mathbf{Y},T) = r_1(Y_F, Y_{O_2}, T) + r_2(Y_R, Y_{O_2}, T).$$\n\nClosure definitions to evaluate:\n- Modeled filtered source (naive closure using means):\n  $$\\tilde{\\dot{\\omega}}_c^{\\,\\mathrm{model}} = \\dot{\\omega}_c\\!\\left(\\tilde{\\mathbf{Y}}, \\tilde{T}\\right) = \\dot{\\omega}_c\\!\\left(\\boldsymbol{\\mu}_{\\mathbf{Y}}, \\mu_T\\right),$$\n  where $(\\boldsymbol{\\mu}_{\\mathbf{Y}}, \\mu_T)$ are the filtered means of $(\\mathbf{Y},T)$.\n- Second-order approximation of the true filtered source:\n  $$\\tilde{\\dot{\\omega}}_c^{\\,\\mathrm{approx}} \\approx \\dot{\\omega}_c(\\boldsymbol{\\mu}_{\\mathbf{Y}}, \\mu_T) + \\frac{1}{2}\\,\\mathrm{tr}\\!\\left(\\mathbf{H}_{\\dot{\\omega}_c}(\\boldsymbol{\\mu}_{\\mathbf{Y}},\\mu_T)\\,\\boldsymbol{\\Sigma}\\right),$$\n  where $\\boldsymbol{\\Sigma}$ is the covariance matrix of $(Y_F, Y_{O_2}, Y_R, T)$, and $\\mathbf{H}_{\\dot{\\omega}_c}$ is the Hessian of $\\dot{\\omega}_c$ with respect to $(Y_F, Y_{O_2}, Y_R, T)$.\n\nOutputs to compute for each test case:\n- The modeled filtered source $\\tilde{\\dot{\\omega}}_c^{\\,\\mathrm{model}}$ in $\\mathrm{s}^{-1}$.\n- The second-order approximation $\\tilde{\\dot{\\omega}}_c^{\\,\\mathrm{approx}}$ in $\\mathrm{s}^{-1}$.\n- The relative modeling bias due to nonlinearity and covariance defined as\n  $$b_{\\mathrm{rel}} = \\frac{\\tilde{\\dot{\\omega}}_c^{\\,\\mathrm{approx}} - \\tilde{\\dot{\\omega}}_c^{\\,\\mathrm{model}}}{\\tilde{\\dot{\\omega}}_c^{\\,\\mathrm{approx}}},$$\n  expressed as a decimal (unitless).\n\nPhysical units:\n- Temperature $T$ must be used in Kelvin.\n- Source rates must be expressed in $\\mathrm{s}^{-1}$.\n\nAngle units:\n- No angles appear in this problem.\n\nTest suite:\nFor each test case $i \\in \\{1,2,3,4\\}$, you are provided $(A_1, E_1, a_1, b_1, A_2, E_2, a_2, b_2)$, the filtered means $(\\mu_{Y_F}, \\mu_{Y_{O_2}}, \\mu_{Y_R}, \\mu_T)$, and the covariance matrix $\\boldsymbol{\\Sigma}$ with variable ordering $(Y_F, Y_{O_2}, Y_R, T)$.\n\n- Test case $1$:\n  - Mechanism parameters: $A_1 = 5.0\\times 10^{6}\\,\\mathrm{s}^{-1}$, $E_1 = 1.2\\times 10^{5}\\,\\mathrm{J/mol}$, $a_1 = 1.0$, $b_1 = 1.0$; $A_2 = 2.5\\times 10^{7}\\,\\mathrm{s}^{-1}$, $E_2 = 1.8\\times 10^{5}\\,\\mathrm{J/mol}$, $a_2 = 1.0$, $b_2 = 0.5$.\n  - Means: $\\mu_{Y_F} = 0.02$, $\\mu_{Y_{O_2}} = 0.21$, $\\mu_{Y_R} = 0.001$, $\\mu_T = 1500$.\n  - Covariance matrix:\n    $$\\boldsymbol{\\Sigma} = \\begin{bmatrix}\n    1.0\\times 10^{-6}  -5.0\\times 10^{-7}  1.0\\times 10^{-8}  5.0\\times 10^{-2} \\\\\n    -5.0\\times 10^{-7}  2.0\\times 10^{-6}  -3.0\\times 10^{-8}  -1.0\\times 10^{-1} \\\\\n    1.0\\times 10^{-8}  -3.0\\times 10^{-8}  5.0\\times 10^{-8}  0.0 \\\\\n    5.0\\times 10^{-2}  -1.0\\times 10^{-1}  0.0  4.0\\times 10^{2}\n    \\end{bmatrix}.$$\n\n- Test case $2$:\n  - Mechanism parameters: $A_1 = 4.0\\times 10^{6}\\,\\mathrm{s}^{-1}$, $E_1 = 1.0\\times 10^{5}\\,\\mathrm{J/mol}$, $a_1 = 1.0$, $b_1 = 1.0$; $A_2 = 1.5\\times 10^{7}\\,\\mathrm{s}^{-1}$, $E_2 = 1.6\\times 10^{5}\\,\\mathrm{J/mol}$, $a_2 = 1.0$, $b_2 = 0.7$.\n  - Means: $\\mu_{Y_F} = 0.001$, $\\mu_{Y_{O_2}} = 0.23$, $\\mu_{Y_R} = 0.0005$, $\\mu_T = 1200$.\n  - Covariance matrix:\n    $$\\boldsymbol{\\Sigma} = \\begin{bmatrix}\n    1.0\\times 10^{-8}  -2.0\\times 10^{-8}  0.0  1.0\\times 10^{-2} \\\\\n    -2.0\\times 10^{-8}  1.5\\times 10^{-6}  -1.0\\times 10^{-8}  -2.0\\times 10^{-2} \\\\\n    0.0  -1.0\\times 10^{-8}  1.0\\times 10^{-8}  0.0 \\\\\n    1.0\\times 10^{-2}  -2.0\\times 10^{-2}  0.0  2.25\\times 10^{2}\n    \\end{bmatrix}.$$\n\n- Test case $3$:\n  - Mechanism parameters: $A_1 = 6.0\\times 10^{6}\\,\\mathrm{s}^{-1}$, $E_1 = 1.4\\times 10^{5}\\,\\mathrm{J/mol}$, $a_1 = 1.0$, $b_1 = 1.2$; $A_2 = 3.0\\times 10^{7}\\,\\mathrm{s}^{-1}$, $E_2 = 2.0\\times 10^{5}\\,\\mathrm{J/mol}$, $a_2 = 1.0$, $b_2 = 0.6$.\n  - Means: $\\mu_{Y_F} = 0.015$, $\\mu_{Y_{O_2}} = 0.20$, $\\mu_{Y_R} = 0.002$, $\\mu_T = 2000$.\n  - Covariance matrix:\n    $$\\boldsymbol{\\Sigma} = \\begin{bmatrix}\n    5.0\\times 10^{-7}  -3.0\\times 10^{-7}  3.0\\times 10^{-8}  1.0\\times 10^{-1} \\\\\n    -3.0\\times 10^{-7}  2.0\\times 10^{-6}  -1.0\\times 10^{-7}  -1.5\\times 10^{-1} \\\\\n    3.0\\times 10^{-8}  -1.0\\times 10^{-7}  2.0\\times 10^{-7}  2.0\\times 10^{-1} \\\\\n    1.0\\times 10^{-1}  -1.5\\times 10^{-1}  2.0\\times 10^{-1}  9.0\\times 10^{2}\n    \\end{bmatrix}.$$\n\n- Test case $4$:\n  - Mechanism parameters: $A_1 = 3.0\\times 10^{6}\\,\\mathrm{s}^{-1}$, $E_1 = 0.9\\times 10^{5}\\,\\mathrm{J/mol}$, $a_1 = 1.0$, $b_1 = 1.0$; $A_2 = 2.2\\times 10^{7}\\,\\mathrm{s}^{-1}$, $E_2 = 1.7\\times 10^{5}\\,\\mathrm{J/mol}$, $a_2 = 1.0$, $b_2 = 0.5$.\n  - Means: $\\mu_{Y_F} = 1.0\\times 10^{-5}$, $\\mu_{Y_{O_2}} = 0.25$, $\\mu_{Y_R} = 1.0\\times 10^{-6}$, $\\mu_T = 1400$.\n  - Covariance matrix:\n    $$\\boldsymbol{\\Sigma} = \\begin{bmatrix}\n    1.0\\times 10^{-7}  -1.0\\times 10^{-7}  5.0\\times 10^{-9}  2.0\\times 10^{-2} \\\\\n    -1.0\\times 10^{-7}  1.0\\times 10^{-6}  -2.0\\times 10^{-8}  -3.0\\times 10^{-2} \\\\\n    5.0\\times 10^{-9}  -2.0\\times 10^{-8}  1.0\\times 10^{-8}  0.0 \\\\\n    2.0\\times 10^{-2}  -3.0\\times 10^{-2}  0.0  4.0\\times 10^{2}\n    \\end{bmatrix}.$$\n\nRequired final output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets.\n- For the four test cases, output the twelve values in the following order:\n  $$[\\tilde{\\dot{\\omega}}_c^{\\,\\mathrm{model}}(1),\\,\\tilde{\\dot{\\omega}}_c^{\\,\\mathrm{approx}}(1),\\,b_{\\mathrm{rel}}(1),\\,\\tilde{\\dot{\\omega}}_c^{\\,\\mathrm{model}}(2),\\,\\tilde{\\dot{\\omega}}_c^{\\,\\mathrm{approx}}(2),\\,b_{\\mathrm{rel}}(2),\\,\\tilde{\\dot{\\omega}}_c^{\\,\\mathrm{model}}(3),\\,\\tilde{\\dot{\\omega}}_c^{\\,\\mathrm{approx}}(3),\\,b_{\\mathrm{rel}}(3),\\,\\tilde{\\dot{\\omega}}_c^{\\,\\mathrm{model}}(4),\\,\\tilde{\\dot{\\omega}}_c^{\\,\\mathrm{approx}}(4),\\,b_{\\mathrm{rel}}(4)],$$\n  where each $\\tilde{\\dot{\\omega}}_c$ is in $\\mathrm{s}^{-1}$ and each $b_{\\mathrm{rel}}$ is a decimal (unitless).",
            "solution": "The task is to evaluate a simple closure model for the filtered progress-variable source term in a Large-Eddy Simulation (LES) of a reacting flow and to quantify its error using a second-order moment expansion. The problem is well-defined, scientifically grounded in the principles of chemical kinetics and turbulence modeling, and all necessary parameters and data for its resolution are provided. I will proceed with a step-by-step derivation and computation.\n\nThe state of the system is described by a vector of variables $\\mathbf{x}$ and their corresponding filtered mean values $\\boldsymbol{\\mu}$. The variables are the mass fractions of fuel ($Y_F$), oxidizer ($Y_{O_2}$), a radical species ($Y_R$), and the temperature ($T$). We define the state vector as $\\mathbf{x} = (x_1, x_2, x_3, x_4)^T = (Y_F, Y_{O_2}, Y_R, T)^T$ and its mean as $\\boldsymbol{\\mu} = (\\mu_1, \\mu_2, \\mu_3, \\mu_4)^T = (\\tilde{Y}_F, \\tilde{Y}_{O_2}, \\tilde{Y}_R, \\tilde{T})^T$.\n\nThe microscopic source rate for the progress variable, $\\dot{\\omega}_c$, is given as the sum of two Arrhenius-type reaction rates, $r_1$ and $r_2$:\n$$\n\\dot{\\omega}_c(\\mathbf{x}) = r_1(x_1, x_2, x_4) + r_2(x_3, x_2, x_4)\n$$\nwhere\n$$\nr_1(x_1, x_2, x_4) = A_1\\,x_1^{a_1}\\,x_2^{b_1}\\,\\exp\\!\\left(-\\frac{E_1}{R_u\\,x_4}\\right)\n$$\n$$\nr_2(x_3, x_2, x_4) = A_2\\,x_3^{a_2}\\,x_2^{b_2}\\,\\exp\\!\\left(-\\frac{E_2}{R_u\\,x_4}\\right)\n$$\nThe universal gas constant is $R_u = 8.314\\,\\mathrm{J/(mol\\,K)}$.\n\nFirst, we compute the modeled filtered source, $\\tilde{\\dot{\\omega}}_c^{\\,\\mathrm{model}}$, which is the source rate evaluated at the filtered mean values of the state variables:\n$$\n\\tilde{\\dot{\\omega}}_c^{\\,\\mathrm{model}} = \\dot{\\omega}_c(\\boldsymbol{\\mu}) = r_1(\\mu_1, \\mu_2, \\mu_4) + r_2(\\mu_3, \\mu_2, \\mu_4)\n$$\n\nNext, we seek a more accurate approximation of the true filtered source, $\\tilde{\\dot{\\omega}}_c = \\widetilde{\\dot{\\omega}_c(\\mathbf{x})}$, using a second-order Taylor expansion around the mean values. This accounts for the effects of subfilter fluctuations (covariance) and the nonlinearity of the source term function:\n$$\n\\tilde{\\dot{\\omega}}_c^{\\,\\mathrm{approx}} = \\dot{\\omega}_c(\\boldsymbol{\\mu}) + \\frac{1}{2}\\,\\mathrm{tr}\\!\\left(\\mathbf{H}_{\\dot{\\omega}_c}(\\boldsymbol{\\mu})\\,\\boldsymbol{\\Sigma}\\right)\n$$\nHere, $\\boldsymbol{\\Sigma}$ is the $4 \\times 4$ covariance matrix of the state variables, provided for each test case. $\\mathbf{H}_{\\dot{\\omega}_c}(\\boldsymbol{\\mu})$ is the Hessian matrix of the source function $\\dot{\\omega}_c$, evaluated at the mean values $\\boldsymbol{\\mu}$. The Hessian is a symmetric matrix of second partial derivatives, $H_{ij} = \\frac{\\partial^2 \\dot{\\omega}_c}{\\partial x_i \\partial x_j}$.\n\nThe correction term due to nonlinearity and covariance is $\\Delta = \\frac{1}{2}\\,\\mathrm{tr}(\\mathbf{H}_{\\dot{\\omega}_c}\\,\\boldsymbol{\\Sigma})$. The trace operation is given by $\\mathrm{tr}(\\mathbf{A}\\mathbf{B}) = \\sum_i \\sum_j A_{ij} B_{ji}$. Since the covariance matrix $\\boldsymbol{\\Sigma}$ is symmetric ($\\Sigma_{ji} = \\Sigma_{ij}$), this simplifies to the sum of the element-wise product: $\\mathrm{tr}(\\mathbf{H}_{\\dot{\\omega}_c}\\,\\boldsymbol{\\Sigma}) = \\sum_{i,j} H_{ij} \\Sigma_{ij}$.\n\nTo compute the correction, we must first derive the components of the Hessian matrix $\\mathbf{H}_{\\dot{\\omega}_c} = \\mathbf{H}_{r_1} + \\mathbf{H}_{r_2}$. The following derivations assume positive values for all mean mass-fractions and temperature, which is physically consistent and holds for all test-cases. Let all functions and derivatives be evaluated at $\\boldsymbol{\\mu}$.\n\nThe second partial derivatives of $r_1$ are:\n$$ \\frac{\\partial^2 r_1}{\\partial x_1^2} = r_1 \\frac{a_1(a_1-1)}{x_1^2} \\quad , \\quad \\frac{\\partial^2 r_1}{\\partial x_2^2} = r_1 \\frac{b_1(b_1-1)}{x_2^2} \\quad , \\quad \\frac{\\partial^2 r_1}{\\partial x_4^2} = r_1 \\frac{E_1}{R_u x_4^3} \\left(\\frac{E_1}{R_u x_4} - 2\\right) $$\n$$ \\frac{\\partial^2 r_1}{\\partial x_1 \\partial x_2} = r_1 \\frac{a_1 b_1}{x_1 x_2} \\quad , \\quad \\frac{\\partial^2 r_1}{\\partial x_1 \\partial x_4} = r_1 \\frac{a_1 E_1}{x_1 R_u x_4^2} \\quad , \\quad \\frac{\\partial^2 r_1}{\\partial x_2 \\partial x_4} = r_1 \\frac{b_1 E_1}{x_2 R_u x_4^2} $$\nAll derivatives of $r_1$ with respect to $x_3$ (i.e., $Y_R$) are zero.\n\nThe second partial derivatives of $r_2$ are analogous:\n$$ \\frac{\\partial^2 r_2}{\\partial x_3^2} = r_2 \\frac{a_2(a_2-1)}{x_3^2} \\quad , \\quad \\frac{\\partial^2 r_2}{\\partial x_2^2} = r_2 \\frac{b_2(b_2-1)}{x_2^2} \\quad , \\quad \\frac{\\partial^2 r_2}{\\partial x_4^2} = r_2 \\frac{E_2}{R_u x_4^3} \\left(\\frac{E_2}{R_u x_4} - 2\\right) $$\n$$ \\frac{\\partial^2 r_2}{\\partial x_2 \\partial x_3} = r_2 \\frac{a_2 b_2}{x_2 x_3} \\quad , \\quad \\frac{\\partial^2 r_2}{\\partial x_3 \\partial x_4} = r_2 \\frac{a_2 E_2}{x_3 R_u x_4^2} \\quad , \\quad \\frac{\\partial^2 r_2}{\\partial x_2 \\partial x_4} = r_2 \\frac{b_2 E_2}{x_2 R_u x_4^2} $$\nAll derivatives of $r_2$ with respect to $x_1$ (i.e., $Y_F$) are zero.\n\nThe components of the total Hessian $\\mathbf{H}_{\\dot{\\omega}_c}$ are the sums of the corresponding components from $\\mathbf{H}_{r_1}$ and $\\mathbf{H}_{r_2}$. For example, $H_{22} = \\frac{\\partial^2 r_1}{\\partial x_2^2} + \\frac{\\partial^2 r_2}{\\partial x_2^2}$, while $H_{11} = \\frac{\\partial^2 r_1}{\\partial x_1^2}$ since $r_2$ does not depend on $x_1$.\n\nThe non-zero components of the Hessian matrix $H_{ij}$ are:\n- $H_{11} = r_1 \\frac{a_1(a_1-1)}{x_1^2}$\n- $H_{22} = r_1 \\frac{b_1(b_1-1)}{x_2^2} + r_2 \\frac{b_2(b_2-1)}{x_2^2}$\n- $H_{33} = r_2 \\frac{a_2(a_2-1)}{x_3^2}$\n- $H_{44} = r_1 \\frac{E_1}{R_u x_4^3}\\left(\\frac{E_1}{R_u x_4}-2\\right) + r_2 \\frac{E_2}{R_u x_4^3}\\left(\\frac{E_2}{R_u x_4}-2\\right)$\n- $H_{12} = r_1 \\frac{a_1 b_1}{x_1 x_2}$\n- $H_{13} = 0$\n- $H_{14} = r_1 \\frac{a_1 E_1}{x_1 R_u x_4^2}$\n- $H_{23} = r_2 \\frac{a_2 b_2}{x_2 x_3}$\n- $H_{24} = r_1 \\frac{b_1 E_1}{x_2 R_u x_4^2} + r_2 \\frac{b_2 E_2}{x_2 R_u x_4^2}$\n- $H_{34} = r_2 \\frac{a_2 E_2}{x_3 R_u x_4^2}$\n\nWith the Hessian matrix computed, we find the second-order approximation:\n$$\n\\tilde{\\dot{\\omega}}_c^{\\,\\mathrm{approx}} = \\tilde{\\dot{\\omega}}_c^{\\,\\mathrm{model}} + \\frac{1}{2}\\sum_{i=1}^4 \\sum_{j=1}^4 H_{ij} \\Sigma_{ij}\n$$\n\nFinally, the relative modeling bias, $b_{\\mathrm{rel}}$, quantifies the error of the naive closure model relative to the second-order approximation. It is defined as:\n$$\nb_{\\mathrm{rel}} = \\frac{\\tilde{\\dot{\\omega}}_c^{\\,\\mathrm{approx}} - \\tilde{\\dot{\\omega}}_c^{\\,\\mathrm{model}}}{\\tilde{\\dot{\\omega}}_c^{\\,\\mathrm{approx}}} = \\frac{\\Delta}{\\tilde{\\dot{\\omega}}_c^{\\,\\mathrm{approx}}}\n$$\nThis procedure is applied to each test case to compute the required triplet of values: $(\\tilde{\\dot{\\omega}}_c^{\\,\\mathrm{model}}, \\tilde{\\dot{\\omega}}_c^{\\,\\mathrm{approx}}, b_{\\mathrm{rel}})$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Solves the problem for all test cases and prints the final result.\n    \"\"\"\n    # Universal Gas Constant in J/(mol K)\n    Ru = 8.314\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"mech_params\": (5.0e6, 1.2e5, 1.0, 1.0, 2.5e7, 1.8e5, 1.0, 0.5), # A1, E1, a1, b1, A2, E2, a2, b2\n            \"means\": (0.02, 0.21, 0.001, 1500), # mu_YF, mu_YO2, mu_YR, mu_T\n            \"Sigma\": np.array([\n                [1.0e-6, -5.0e-7, 1.0e-8, 5.0e-2],\n                [-5.0e-7, 2.0e-6, -3.0e-8, -1.0e-1],\n                [1.0e-8, -3.0e-8, 5.0e-8, 0.0],\n                [5.0e-2, -1.0e-1, 0.0, 4.0e2]\n            ])\n        },\n        {\n            \"mech_params\": (4.0e6, 1.0e5, 1.0, 1.0, 1.5e7, 1.6e5, 1.0, 0.7),\n            \"means\": (0.001, 0.23, 0.0005, 1200),\n            \"Sigma\": np.array([\n                [1.0e-8, -2.0e-8, 0.0, 1.0e-2],\n                [-2.0e-8, 1.5e-6, -1.0e-8, -2.0e-2],\n                [0.0, -1.0e-8, 1.0e-8, 0.0],\n                [1.0e-2, -2.0e-2, 0.0, 2.25e2]\n            ])\n        },\n        {\n            \"mech_params\": (6.0e6, 1.4e5, 1.0, 1.2, 3.0e7, 2.0e5, 1.0, 0.6),\n            \"means\": (0.015, 0.20, 0.002, 2000),\n            \"Sigma\": np.array([\n                [5.0e-7, -3.0e-7, 3.0e-8, 1.0e-1],\n                [-3.0e-7, 2.0e-6, -1.0e-7, -1.5e-1],\n                [3.0e-8, -1.0e-7, 2.0e-7, 2.0e-1],\n                [1.0e-1, -1.5e-1, 2.0e-1, 9.0e2]\n            ])\n        },\n        {\n            \"mech_params\": (3.0e6, 0.9e5, 1.0, 1.0, 2.2e7, 1.7e5, 1.0, 0.5),\n            \"means\": (1.0e-5, 0.25, 1.0e-6, 1400),\n            \"Sigma\": np.array([\n                [1.0e-7, -1.0e-7, 5.0e-9, 2.0e-2],\n                [-1.0e-7, 1.0e-6, -2.0e-8, -3.0e-2],\n                [5.0e-9, -2.0e-8, 1.0e-8, 0.0],\n                [2.0e-2, -3.0e-2, 0.0, 4.0e2]\n            ])\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        # Unpack data for the current case\n        A1, E1, a1, b1, A2, E2, a2, b2 = case[\"mech_params\"]\n        mu_YF, mu_YO2, mu_YR, mu_T = case[\"means\"]\n        Sigma = case[\"Sigma\"]\n        \n        # State vector of means: YF, YO2, YR, T\n        x = np.array([mu_YF, mu_YO2, mu_YR, mu_T])\n\n        # Step 1: Compute modeled source rate at mean values\n        exp_term1 = np.exp(-E1 / (Ru * x[3]))\n        r1_mean = A1 * (x[0]**a1) * (x[1]**b1) * exp_term1\n        \n        exp_term2 = np.exp(-E2 / (Ru * x[3]))\n        r2_mean = A2 * (x[2]**a2) * (x[1]**b2) * exp_term2\n\n        omega_model = r1_mean + r2_mean\n\n        # Step 2: Compute the Hessian matrix H\n        H = np.zeros((4, 4))\n        \n        # Diagonal components\n        H[0, 0] = r1_mean * a1 * (a1 - 1) / x[0]**2 if x[0]  0 else 0\n        H[1, 1] = r1_mean * b1 * (b1 - 1) / x[1]**2 + r2_mean * b2 * (b2 - 1) / x[1]**2\n        H[2, 2] = r2_mean * a2 * (a2 - 1) / x[2]**2 if x[2]  0 else 0\n        \n        term_T_r1 = r1_mean * (E1 / (Ru * x[3]**2))**2 - r1_mean * 2 * E1 / (Ru * x[3]**3)\n        term_T_r2 = r2_mean * (E2 / (Ru * x[3]**2))**2 - r2_mean * 2 * E2 / (Ru * x[3]**3)\n        H[3, 3] = term_T_r1 + term_T_r2\n\n        # Off-diagonal components\n        H[0, 1] = r1_mean * a1 * b1 / (x[0] * x[1]) if x[0]  0 else 0\n        # H[0, 2] is 0\n        H[0, 3] = r1_mean * a1 * E1 / (x[0] * Ru * x[3]**2) if x[0]  0 else 0\n        \n        H[1, 2] = r2_mean * a2 * b2 / (x[1] * x[2]) if x[2]  0 else 0\n        H[1, 3] = r1_mean * b1 * E1 / (x[1] * Ru * x[3]**2) + r2_mean * b2 * E2 / (x[1] * Ru * x[3]**2)\n        \n        H[2, 3] = r2_mean * a2 * E2 / (x[2] * Ru * x[3]**2) if x[2]  0 else 0\n\n        # Symmetrize the Hessian\n        H[1, 0] = H[0, 1]\n        H[2, 0] = H[0, 2]\n        H[3, 0] = H[0, 3]\n        H[2, 1] = H[1, 2]\n        H[3, 1] = H[1, 3]\n        H[3, 2] = H[2, 3]\n        \n        # Step 3: Compute the correction term and the approximate source rate\n        # tr(H * Sigma) simplifies to sum of element-wise product because Sigma is symmetric\n        correction = 0.5 * np.sum(H * Sigma)\n        omega_approx = omega_model + correction\n        \n        # Step 4: Compute the relative modeling bias\n        if omega_approx == 0:\n            # This case is unlikely; the bias would be undefined or infinite.\n            # For this problem, assume omega_approx is non-zero.\n            b_rel = 0.0 if correction == 0 else np.nan\n        else:\n            b_rel = correction / omega_approx\n            \n        results.extend([omega_model, omega_approx, b_rel])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.7g}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A powerful approach in developing robust machine learning closures is to embed known physical laws directly into the training process. This practice, often called physics-informed machine learning, ensures that the model's predictions do not violate fundamental principles like conservation laws. This exercise  challenges you to think like a model developer by selecting the most appropriate loss function term to enforce element conservation, balancing mathematical rigor with practical considerations like differentiability and numerical stability.",
            "id": "4037701",
            "problem": "Consider the training of a neural-network closure for filtered chemical reaction rates in Large Eddy Simulation (LES). Let there be $N_s$ chemical species and $N_e$ conserved elements (for example, carbon, hydrogen, oxygen), and let the element-to-species composition matrix be $\\mathbf{A} \\in \\mathbb{R}^{N_e \\times N_s}$ with entries $a_{\\kappa\\alpha}$ equal to the number of atoms of element $\\kappa$ in species $\\alpha$. The network outputs, for each training sample $i$ in a mini-batch of size $N_b$, a vector of filtered molar production rates $\\tilde{\\boldsymbol{\\dot{\\omega}}}^{(i)} \\in \\mathbb{R}^{N_s}$, where each component $\\tilde{\\dot{\\omega}}_\\alpha^{(i)}$ has units of $\\mathrm{mol\\,m^{-3}\\,s^{-1}}$. In chemically reacting systems, element conservation imposes the constraint that for each element $\\kappa$,\n$$\n\\sum_{\\alpha=1}^{N_s} a_{\\kappa\\alpha} \\,\\dot{\\omega}_\\alpha = 0,\n$$\nand under linear filtering this implies the filtered constraint\n$$\n\\sum_{\\alpha=1}^{N_s} a_{\\kappa\\alpha} \\,\\tilde{\\dot{\\omega}}_\\alpha = 0.\n$$\nIn practice, a learned closure may violate this constraint, so the training objective must include a penalty that enforces element-wise conservation of the filtered reaction rates. The penalty should be twice continuously differentiable to support gradient-based optimization and should be element-balanced and dimensionless to avoid biasing the optimization toward elements with larger typical magnitudes.\n\nWhich of the following loss terms best enforces element-wise species conservation in the filtered reaction rates by penalizing deviations from $\\sum_{\\alpha=1}^{N_s} a_{\\kappa\\alpha} \\,\\tilde{\\dot{\\omega}}_\\alpha = 0$ for each conserved element $\\kappa$, in a way that is twice continuously differentiable, element-balanced, and dimensionless?\n\nA. $L_{\\mathrm{elem}} = \\dfrac{1}{N_b} \\displaystyle\\sum_{i=1}^{N_b} \\sum_{\\kappa=1}^{N_e} \\left( \\dfrac{\\sum_{\\alpha=1}^{N_s} a_{\\kappa\\alpha} \\,\\tilde{\\dot{\\omega}}_\\alpha^{(i)}}{s_\\kappa} \\right)^2$, where $s_\\kappa  0$ are fixed normalization constants representative of the typical magnitude of the $\\kappa$-th element violation over the dataset.\n\nB. $L_{\\mathrm{elem}} = \\dfrac{1}{N_b} \\displaystyle\\sum_{i=1}^{N_b} \\left( \\sum_{\\alpha=1}^{N_s} \\tilde{\\dot{\\omega}}_\\alpha^{(i)} \\right)^2$.\n\nC. $L_{\\mathrm{elem}} = \\dfrac{1}{N_b} \\displaystyle\\sum_{i=1}^{N_b} \\left\\| \\mathbf{A}^\\top \\,\\tilde{\\boldsymbol{\\dot{\\omega}}}^{(i)} \\right\\|_2^2$.\n\nD. $L_{\\mathrm{elem}} = \\dfrac{1}{N_b} \\displaystyle\\sum_{i=1}^{N_b} \\sum_{\\kappa=1}^{N_e} \\left| \\sum_{\\alpha=1}^{N_s} a_{\\kappa\\alpha} \\,\\tilde{\\dot{\\omega}}_\\alpha^{(i)} \\right|$.\n\nE. $L_{\\mathrm{elem}} = \\dfrac{1}{N_b} \\displaystyle\\sum_{i=1}^{N_b} \\sum_{\\kappa=1}^{N_e} \\left( \\sum_{\\alpha=1}^{N_s} W_\\alpha \\,a_{\\kappa\\alpha} \\,\\tilde{\\dot{\\omega}}_\\alpha^{(i)} \\right)^2$, where $W_\\alpha$ is the molar mass of species $\\alpha$ in $\\mathrm{kg\\,mol^{-1}}$.\n\nSelect the single best choice.",
            "solution": "The goal is to find a loss function term, $L_{\\mathrm{elem}}$, that effectively penalizes violations of the element conservation law, $\\sum_{\\alpha=1}^{N_s} a_{\\kappa\\alpha} \\,\\tilde{\\dot{\\omega}}_\\alpha = 0$, for each element $\\kappa$. A suitable loss term must meet three criteria:\n1.  **Twice continuously differentiable ($C^2$)**: This is crucial for stable and efficient training using second-order or quasi-Newton optimization methods, and it avoids issues with gradient-based methods near zero-violation points. Squaring the violation, $(v_\\kappa)^2$, satisfies this, whereas the absolute value, $|v_\\kappa|$, does not (it is not differentiable at $v_\\kappa=0$).\n2.  **Element-balanced**: The magnitude of violation for different elements (e.g., carbon vs. hydrogen) can vary significantly. To prevent the optimization from being dominated by the element with the largest violation, each element's penalty term must be normalized by a characteristic scale, $s_\\kappa$.\n3.  **Dimensionless**: The loss function should be a pure scalar. The violation term, $\\sum a_{\\kappa\\alpha} \\tilde{\\dot{\\omega}}_\\alpha$, has units of $\\mathrm{mol\\,m^{-3}\\,s^{-1}}$. Normalizing by $s_\\kappa$, which represents a typical violation magnitude and thus has the same units, makes the term dimensionless.\n\nCombining these requirements, the ideal penalty for a single training sample $i$ is a sum of squared, normalized violations: $\\sum_{\\kappa=1}^{N_e} \\left( \\frac{\\sum_{\\alpha=1}^{N_s} a_{\\kappa\\alpha} \\,\\tilde{\\dot{\\omega}}_\\alpha^{(i)}}{s_\\kappa} \\right)^2$. Averaging this over the mini-batch gives the final loss term.\n\nLet's evaluate the options based on these criteria:\n\n-   **A.** This option, $L_{\\mathrm{elem}} = \\frac{1}{N_b} \\sum_{i} \\sum_{\\kappa} \\left( \\frac{\\sum_{\\alpha} a_{\\kappa\\alpha} \\,\\tilde{\\dot{\\omega}}_\\alpha^{(i)}}{s_\\kappa} \\right)^2$, perfectly matches our derived ideal form. It is a squared term (hence $C^2$), normalized by $s_\\kappa$ for balance, and rendered dimensionless by the same normalization.\n\n-   **B.** This term, involving $(\\sum_{\\alpha} \\tilde{\\dot{\\omega}}_\\alpha^{(i)})^2$, attempts to enforce conservation of total moles, which is not a general physical law in chemical reactions. It incorrectly ignores the elemental composition matrix $\\mathbf{A}$.\n\n-   **C.** This term, $\\|\\mathbf{A}^\\top \\tilde{\\boldsymbol{\\dot{\\omega}}}^{(i)}\\|_2^2$, involves an incorrect matrix product. The correct constraint is $\\mathbf{A}\\tilde{\\boldsymbol{\\dot{\\omega}}}^{(i)} = \\mathbf{0}$. Even if corrected to $\\|\\mathbf{A}\\tilde{\\boldsymbol{\\dot{\\omega}}}^{(i)}\\|_2^2$, it would lack element-balancing and would not be dimensionless.\n\n-   **D.** This term uses the absolute value, which is not twice continuously differentiable, failing a key requirement for many optimization algorithms. It also lacks balancing and is not dimensionless.\n\n-   **E.** This term incorrectly weights the molar rates by molar masses $W_\\alpha$ *inside* the summation over species. This does not represent the conservation of elemental mass and is physically incorrect.\n\nTherefore, option A is the only choice that correctly formulates the physical constraint into a mathematically and numerically sound loss function.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Beyond matching reference data, a successful turbulence model must produce outputs that are physically realizable. For the Reynolds-stress tensor, this means its predictions must satisfy certain mathematical properties, such as being positive semidefinite, which ensures positive turbulent kinetic energy. This exercise  provides a practical application of this concept by asking you to verify the realizability of an anisotropy tensor predicted by a Tensor Basis Neural Network (TBNN), connecting the model's output to the fundamental geometric constraints of turbulent stresses.",
            "id": "4037715",
            "problem": "Consider a reacting shear layer in a computational combustion simulation where the Reynolds-stress anisotropy tensor $b_{ij}$ is modeled using a Tensor Basis Neural Network (TBNN). The TBNN constructs $b_{ij}$ from the mean velocity gradient $A_{ij}$ through invariant scalar functions and a tensor basis built from the mean strain-rate tensor $S_{ij}$ and rotation-rate tensor $R_{ij}$. The foundational definitions are:\n- The strain-rate tensor $S_{ij}$ and the rotation-rate tensor $R_{ij}$ are defined by $S_{ij} = \\tfrac{1}{2}\\left(A_{ij} + A_{ji}\\right)$ and $R_{ij} = \\tfrac{1}{2}\\left(A_{ij} - A_{ji}\\right)$.\n- The anisotropy tensor $b_{ij}$ is symmetric and traceless by construction in the TBNN framework and is modeled as a linear combination of basis tensors $T^{(m)}_{ij}$ with scalar coefficient functions $g_{m}$ that depend on invariants of $S_{ij}$ and $R_{ij}$.\n\nFor an incompressible, planar, nonpremixed flame segment, suppose the local mean velocity gradient is\n$$\nA_{ij} = \\begin{pmatrix}\n0  2  0 \\\\\n0  0  0 \\\\\n0  0  0\n\\end{pmatrix}.\n$$\nThe TBNN uses the following three basis tensors constructed from $S_{ij}$ and $R_{ij}$:\n$$\nT^{(1)}_{ij} = S_{ij}, \\quad T^{(2)}_{ij} = S_{ik}R_{kj} - R_{ik}S_{kj}, \\quad T^{(3)}_{ij} = S_{ik}S_{kj} - \\tfrac{1}{3}\\,\\mathrm{tr}\\!\\left(S^{2}\\right)\\delta_{ij}.\n$$\nThe scalar invariants used by the network are $I_{1} = \\mathrm{tr}\\!\\left(S^{2}\\right)$ and $I_{2} = \\mathrm{tr}\\!\\left(R^{2}\\right)$. For this flow, the trained network prescribes the coefficient functions\n$$\ng_{1} = \\alpha_{1}\\,\\frac{I_{1}}{1 + |I_{2}|}, \\quad g_{2} = \\frac{\\alpha_{2}}{1 + I_{1}}, \\quad g_{3} = \\frac{\\alpha_{3}}{1 - I_{2}},\n$$\nwith constants $\\alpha_{1} = \\tfrac{3}{40}$, $\\alpha_{2} = \\tfrac{3}{10}$, and $\\alpha_{3} = \\tfrac{3}{4}$. The predicted anisotropy is\n$$\nb_{ij} = \\sum_{m=1}^{3} g_{m}\\,T^{(m)}_{ij}.\n$$\n\nTasks:\n1. Using the definitions above, compute $S_{ij}$, $R_{ij}$, and the invariants $I_{1}$ and $I_{2}$ for the given $A_{ij}$.\n2. Compute $g_{1}$, $g_{2}$, and $g_{3}$, then assemble $b_{ij}$ from the specified basis tensors.\n3. Compute the ordered eigenvalues $\\lambda_{1} \\ge \\lambda_{2} \\ge \\lambda_{3}$ of $b_{ij}$ and the barycentric coordinates\n$$\nC_{1\\mathrm{C}} = \\lambda_{1} - \\lambda_{2}, \\quad C_{2\\mathrm{C}} = 2\\left(\\lambda_{2} - \\lambda_{3}\\right), \\quad C_{3\\mathrm{C}} = 3\\lambda_{3} + 1.\n$$\nVerify that $C_{1\\mathrm{C}}$, $C_{2\\mathrm{C}}$, and $C_{3\\mathrm{C}}$ are all nonnegative and sum to $1$, ensuring realizability.\n\nReport as your final answer the realizability margin defined by\n$$\n\\Delta = \\min\\!\\left(C_{1\\mathrm{C}},\\,C_{2\\mathrm{C}},\\,C_{3\\mathrm{C}}\\right),\n$$\nexpressed as a single simplified closed-form analytic expression with no units. No rounding is required; provide the exact expression.",
            "solution": "The problem requires a sequence of calculations to determine the realizability of a predicted Reynolds-stress anisotropy tensor, $b_{ij}$. The solution proceeds by executing these steps directly.\n\nFirst, we compute the mean strain-rate tensor $S_{ij}$ and the mean rotation-rate tensor $R_{ij}$ from the given mean velocity gradient tensor $A_{ij}$.\nThe mean velocity gradient is given by\n$$\nA_{ij} = \\begin{pmatrix}\n0  2  0 \\\\\n0  0  0 \\\\\n0  0  0\n\\end{pmatrix}\n$$\nIts transpose is\n$$\nA_{ji} = \\begin{pmatrix}\n0  0  0 \\\\\n2  0  0 \\\\\n0  0  0\n\\end{pmatrix}\n$$\nThe strain-rate tensor $S_{ij}$ is the symmetric part of $A_{ij}$:\n$$\nS_{ij} = \\frac{1}{2}\\left(A_{ij} + A_{ji}\\right) = \\frac{1}{2}\\left( \\begin{pmatrix}\n0  2  0 \\\\\n0  0  0 \\\\\n0  0  0\n\\end{pmatrix} + \\begin{pmatrix}\n0  0  0 \\\\\n2  0  0 \\\\\n0  0  0\n\\end{pmatrix} \\right) = \\frac{1}{2}\\begin{pmatrix}\n0  2  0 \\\\\n2  0  0 \\\\\n0  0  0\n\\end{pmatrix} = \\begin{pmatrix}\n0  1  0 \\\\\n1  0  0 \\\\\n0  0  0\n\\end{pmatrix}\n$$\nThe rotation-rate tensor $R_{ij}$ is the anti-symmetric part of $A_{ij}$:\n$$\nR_{ij} = \\frac{1}{2}\\left(A_{ij} - A_{ji}\\right) = \\frac{1}{2}\\left( \\begin{pmatrix}\n0  2  0 \\\\\n0  0  0 \\\\\n0  0  0\n\\end{pmatrix} - \\begin{pmatrix}\n0  0  0 \\\\\n2  0  0 \\\\\n0  0  0\n\\end{pmatrix} \\right) = \\frac{1}{2}\\begin{pmatrix}\n0  2  0 \\\\\n-2  0  0 \\\\\n0  0  0\n\\end{pmatrix} = \\begin{pmatrix}\n0  1  0 \\\\\n-1  0  0 \\\\\n0  0  0\n\\end{pmatrix}\n$$\nNext, we compute the scalar invariants $I_{1} = \\mathrm{tr}(S^{2})$ and $I_{2} = \\mathrm{tr}(R^{2})$.\n$$\nS^{2} = S_{ik}S_{kj} = \\begin{pmatrix}\n0  1  0 \\\\\n1  0  0 \\\\\n0  0  0\n\\end{pmatrix} \\begin{pmatrix}\n0  1  0 \\\\\n1  0  0 \\\\\n0  0  0\n\\end{pmatrix} = \\begin{pmatrix}\n1  0  0 \\\\\n0  1  0 \\\\\n0  0  0\n\\end{pmatrix}\n$$\n$$\nI_{1} = \\mathrm{tr}(S^{2}) = 1 + 1 + 0 = 2\n$$\n$$\nR^{2} = R_{ik}R_{kj} = \\begin{pmatrix}\n0  1  0 \\\\\n-1  0  0 \\\\\n0  0  0\n\\end{pmatrix} \\begin{pmatrix}\n0  1  0 \\\\\n-1  0  0 \\\\\n0  0  0\n\\end{pmatrix} = \\begin{pmatrix}\n-1  0  0 \\\\\n0  -1  0 \\\\\n0  0  0\n\\end{pmatrix}\n$$\n$$\nI_{2} = \\mathrm{tr}(R^{2}) = -1 + (-1) + 0 = -2\n$$\nNow, we compute the scalar coefficient functions $g_{1}$, $g_{2}$, and $g_{3}$ using the given constants $\\alpha_{1} = \\frac{3}{40}$, $\\alpha_{2} = \\frac{3}{10}$, and $\\alpha_{3} = \\frac{3}{4}$.\n$$\ng_{1} = \\alpha_{1}\\frac{I_{1}}{1 + |I_{2}|} = \\frac{3}{40} \\frac{2}{1 + |-2|} = \\frac{3}{40} \\frac{2}{3} = \\frac{1}{20}\n$$\n$$\ng_{2} = \\frac{\\alpha_{2}}{1 + I_{1}} = \\frac{3/10}{1 + 2} = \\frac{3/10}{3} = \\frac{1}{10}\n$$\n$$\ng_{3} = \\frac{\\alpha_{3}}{1 - I_{2}} = \\frac{3/4}{1 - (-2)} = \\frac{3/4}{3} = \\frac{1}{4}\n$$\nWe then compute the basis tensors $T^{(1)}_{ij}$, $T^{(2)}_{ij}$, and $T^{(3)}_{ij}$.\n$T^{(1)}_{ij} = S_{ij} = \\begin{pmatrix}\n0  1  0 \\\\\n1  0  0 \\\\\n0  0  0\n\\end{pmatrix}$.\nFor $T^{(2)}_{ij} = S_{ik}R_{kj} - R_{ik}S_{kj}$:\n$$\nS R = \\begin{pmatrix}\n0  1  0 \\\\\n1  0  0 \\\\\n0  0  0\n\\end{pmatrix} \\begin{pmatrix}\n0  1  0 \\\\\n-1  0  0 \\\\\n0  0  0\n\\end{pmatrix} = \\begin{pmatrix}\n-1  0  0 \\\\\n0  1  0 \\\\\n0  0  0\n\\end{pmatrix}\n$$\n$$\nR S = \\begin{pmatrix}\n0  1  0 \\\\\n-1  0  0 \\\\\n0  0  0\n\\end{pmatrix} \\begin{pmatrix}\n0  1  0 \\\\\n1  0  0 \\\\\n0  0  0\n\\end{pmatrix} = \\begin{pmatrix}\n1  0  0 \\\\\n0  -1  0 \\\\\n0  0  0\n\\end{pmatrix}\n$$\n$$\nT^{(2)}_{ij} = SR - RS = \\begin{pmatrix}\n-2  0  0 \\\\\n0  2  0 \\\\\n0  0  0\n\\end{pmatrix}\n$$\nFor $T^{(3)}_{ij} = S_{ik}S_{kj} - \\frac{1}{3}\\mathrm{tr}(S^{2})\\delta_{ij}$:\n$$\nT^{(3)}_{ij} = S^{2} - \\frac{1}{3}I_{1}\\delta_{ij} = \\begin{pmatrix}\n1  0  0 \\\\\n0  1  0 \\\\\n0  0  0\n\\end{pmatrix} - \\frac{2}{3}\\begin{pmatrix}\n1  0  0 \\\\\n0  1  0 \\\\\n0  0  1\n\\end{pmatrix} = \\begin{pmatrix}\n1/3  0  0 \\\\\n0  1/3  0 \\\\\n0  0  -2/3\n\\end{pmatrix}\n$$\nWe assemble the anisotropy tensor $b_{ij} = \\sum_{m=1}^{3} g_{m}T^{(m)}_{ij}$:\n$$\nb_{ij} = \\frac{1}{20}\\begin{pmatrix}\n0  1  0 \\\\\n1  0  0 \\\\\n0  0  0\n\\end{pmatrix} + \\frac{1}{10}\\begin{pmatrix}\n-2  0  0 \\\\\n0  2  0 \\\\\n0  0  0\n\\end{pmatrix} + \\frac{1}{4}\\begin{pmatrix}\n1/3  0  0 \\\\\n0  1/3  0 \\\\\n0  0  -2/3\n\\end{pmatrix}\n$$\n$$\nb_{ij} = \\begin{pmatrix}\n0 - \\frac{2}{10} + \\frac{1}{12}  \\frac{1}{20}  0 \\\\\n\\frac{1}{20}  0 + \\frac{2}{10} + \\frac{1}{12}  0 \\\\\n0  0  0 + 0 - \\frac{2}{12}\n\\end{pmatrix} = \\begin{pmatrix}\n-\\frac{1}{5} + \\frac{1}{12}  \\frac{1}{20}  0 \\\\\n\\frac{1}{20}  \\frac{1}{5} + \\frac{1}{12}  0 \\\\\n0  0  -\\frac{1}{6}\n\\end{pmatrix}\n$$\n$$\nb_{ij} = \\begin{pmatrix}\n\\frac{-12+5}{60}  \\frac{3}{60}  0 \\\\\n\\frac{3}{60}  \\frac{12+5}{60}  0 \\\\\n0  0  -\\frac{10}{60}\n\\end{pmatrix} = \\frac{1}{60}\\begin{pmatrix}\n-7  3  0 \\\\\n3  17  0 \\\\\n0  0  -10\n\\end{pmatrix}\n$$\nTo find the eigenvalues, we observe the matrix is block-diagonal. One eigenvalue is immediately $\\lambda = -\\frac{10}{60} = -\\frac{1}{6}$. The other two are the eigenvalues of the submatrix $M = \\frac{1}{60}\\begin{pmatrix} -7  3 \\\\ 3  17 \\end{pmatrix}$. Let the eigenvalues of $\\begin{pmatrix} -7  3 \\\\ 3  17 \\end{pmatrix}$ be $\\mu$. The characteristic equation is $(-7-\\mu)(17-\\mu) - (3)(3) = 0$, which simplifies to $\\mu^2 - 10\\mu - 119 - 9 = 0$, or $\\mu^2 - 10\\mu - 128 = 0$.\nUsing the quadratic formula:\n$$\n\\mu = \\frac{10 \\pm \\sqrt{(-10)^2 - 4(1)(-128)}}{2} = \\frac{10 \\pm \\sqrt{100 + 512}}{2} = \\frac{10 \\pm \\sqrt{612}}{2}\n$$\nSince $612 = 36 \\times 17$, $\\sqrt{612} = 6\\sqrt{17}$.\n$$\n\\mu = \\frac{10 \\pm 6\\sqrt{17}}{2} = 5 \\pm 3\\sqrt{17}\n$$\nThe eigenvalues of $b_{ij}$ are $\\lambda = \\mu/60$, so we have the set of eigenvalues $\\left\\{ \\frac{5+3\\sqrt{17}}{60}, \\frac{5-3\\sqrt{17}}{60}, -\\frac{10}{60} \\right\\}$.\nWe order them as $\\lambda_{1} \\ge \\lambda_{2} \\ge \\lambda_{3}$.\nSince $\\sqrt{17}  \\sqrt{25/9} = 5/3$, $3\\sqrt{17}  5$, so $\\frac{5-3\\sqrt{17}}{60}$ is negative.\nTo compare $\\frac{5-3\\sqrt{17}}{60}$ and $-\\frac{10}{60}$, we compare $5-3\\sqrt{17}$ and $-10$. This is equivalent to comparing $15$ and $3\\sqrt{17}$, or $5$ and $\\sqrt{17}$. Since $5^2 = 25  17$, we have $5  \\sqrt{17}$, which means $15  3\\sqrt{17}$, and thus $5-3\\sqrt{17}  -10$.\nThe ordered eigenvalues are:\n$$\n\\lambda_{1} = \\frac{5 + 3\\sqrt{17}}{60}, \\quad \\lambda_{2} = \\frac{5 - 3\\sqrt{17}}{60}, \\quad \\lambda_{3} = -\\frac{10}{60} = -\\frac{1}{6}\n$$\nNext, we compute the barycentric coordinates and verify realizability.\n$$\nC_{1\\mathrm{C}} = \\lambda_{1} - \\lambda_{2} = \\frac{5 + 3\\sqrt{17}}{60} - \\frac{5 - 3\\sqrt{17}}{60} = \\frac{6\\sqrt{17}}{60} = \\frac{\\sqrt{17}}{10}\n$$\n$$\nC_{2\\mathrm{C}} = 2\\left(\\lambda_{2} - \\lambda_{3}\\right) = 2\\left(\\frac{5 - 3\\sqrt{17}}{60} - \\frac{-10}{60}\\right) = 2\\left(\\frac{15 - 3\\sqrt{17}}{60}\\right) = \\frac{15 - 3\\sqrt{17}}{30} = \\frac{5 - \\sqrt{17}}{10}\n$$\n$$\nC_{3\\mathrm{C}} = 3\\lambda_{3} + 1 = 3\\left(-\\frac{1}{6}\\right) + 1 = -\\frac{1}{2} + 1 = \\frac{1}{2} = \\frac{5}{10}\n$$\nAll coordinates are non-negative: $C_{1\\mathrm{C}}  0$; $C_{2\\mathrm{C}}  0$ because $5  \\sqrt{17}$; $C_{3\\mathrm{C}}  0$.\nTheir sum is $C_{1\\mathrm{C}} + C_{2\\mathrm{C}} + C_{3\\mathrm{C}} = \\frac{\\sqrt{17}}{10} + \\frac{5 - \\sqrt{17}}{10} + \\frac{5}{10} = \\frac{\\sqrt{17} + 5 - \\sqrt{17} + 5}{10} = \\frac{10}{10} = 1$. The realizability conditions are satisfied.\n\nFinally, we find the realizability margin $\\Delta = \\min(C_{1\\mathrm{C}}, C_{2\\mathrm{C}}, C_{3\\mathrm{C}})$. We must compare $\\frac{\\sqrt{17}}{10}$, $\\frac{5 - \\sqrt{17}}{10}$, and $\\frac{5}{10}$.\nComparing $C_{1\\mathrm{C}}$ and $C_{2\\mathrm{C}}$: $\\sqrt{17}$ vs $5 - \\sqrt{17} \\implies 2\\sqrt{17}$ vs $5 \\implies \\sqrt{68}$ vs $\\sqrt{25}$. Thus $C_{1\\mathrm{C}}  C_{2\\mathrm{C}}$.\nComparing $C_{2\\mathrm{C}}$ and $C_{3\\mathrm{C}}$: $5 - \\sqrt{17}$ vs $5 \\implies -\\sqrt{17}$ vs $0$. Thus $C_{3\\mathrm{C}}  C_{2\\mathrm{C}}$.\nThe minimum value is $C_{2\\mathrm{C}}$.\n$$\n\\Delta = \\frac{5 - \\sqrt{17}}{10}\n$$",
            "answer": "$$\n\\boxed{\\frac{5 - \\sqrt{17}}{10}}\n$$"
        }
    ]
}