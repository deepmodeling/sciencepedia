{
    "hands_on_practices": [
        {
            "introduction": "Mastering the analysis of numerical methods begins with quantifying local errors. This foundational practice  walks you through using Taylor series expansions to derive the truncation error for the ubiquitous central difference approximation to the second derivative. Completing this exercise solidifies your understanding of how a discrete operator approximates a continuous one and reveals its order of accuracy, a cornerstone concept in computational science.",
            "id": "4149992",
            "problem": "In one-dimensional, lossless linear acoustics, the acoustic pressure field $p(x,t)$ satisfies the acoustic wave equation. In a Finite Difference Time Domain (FDTD) spatial discretization, the Laplacian term $p_{xx}(x,t)$ is commonly approximated by a symmetric $3$-point central difference on a uniform grid of spacing $h>0$. At a fixed time $t^{\\ast}$, treat $p(\\cdot,t^{\\ast})$ as a scalar function $p(x)$ that is at least six times continuously differentiable in a neighborhood of a point $x$. Define the discrete operator\n$$\nD_{xx}p(x) \\equiv \\frac{p(x+h)-2\\,p(x)+p(x-h)}{h^{2}}.\n$$\nUsing Taylor’s theorem about $x$ for $p(x\\pm h)$ with a remainder expressed in Big-$O$ notation, derive the local truncation error, defined as $D_{xx}p(x)-p_{xx}(x)$, to its leading nonzero order in $h$. Identify the constant $C$ such that\n$$\nD_{xx}p(x)-p_{xx}(x)=C\\,h^{2}\\,p^{(4)}(x)+\\mathcal{O}(h^{4}),\n$$\nwhere $p^{(4)}(x)$ denotes the fourth spatial derivative of $p$ at $x$. Provide only the value of $C$ as your final answer. The final answer is dimensionless and should be given exactly, without rounding.",
            "solution": "The problem is valid as it represents a standard, well-posed exercise in numerical analysis, specifically the derivation of the local truncation error for a finite difference scheme. It is scientifically grounded, objective, and contains all necessary information for a unique solution.\n\nThe objective is to determine the constant $C$ in the expression for the local truncation error of the discrete Laplacian operator $D_{xx}p(x)$. The truncation error is defined as the difference between the discrete operator and the continuous operator it approximates, $D_{xx}p(x) - p_{xx}(x)$, where $p_{xx}(x)$ denotes the second spatial derivative of the pressure field $p(x)$.\n\nThe discrete operator is given by:\n$$\nD_{xx}p(x) = \\frac{p(x+h) - 2\\,p(x) + p(x-h)}{h^{2}}\n$$\nTo analyze the error, we employ Taylor's theorem to expand the terms $p(x+h)$ and $p(x-h)$ around the point $x$. The problem states that the function $p(x)$ is at least six times continuously differentiable, which allows us to write the Taylor series expansions with sufficient precision to determine the leading order error term and the subsequent term.\n\nThe Taylor series expansion for $p(x+h)$ about $x$ is:\n$$\np(x+h) = p(x) + h\\,p^{(1)}(x) + \\frac{h^{2}}{2!}\\,p^{(2)}(x) + \\frac{h^{3}}{3!}\\,p^{(3)}(x) + \\frac{h^{4}}{4!}\\,p^{(4)}(x) + \\frac{h^{5}}{5!}\\,p^{(5)}(x) + \\frac{h^{6}}{6!}\\,p^{(6)}(x) + \\mathcal{O}(h^{7})\n$$\nSimilarly, the expansion for $p(x-h)$ about $x$ is:\n$$\np(x-h) = p(x) - h\\,p^{(1)}(x) + \\frac{h^{2}}{2!}\\,p^{(2)}(x) - \\frac{h^{3}}{3!}\\,p^{(3)}(x) + \\frac{h^{4}}{4!}\\,p^{(4)}(x) - \\frac{h^{5}}{5!}\\,p^{(5)}(x) + \\frac{h^{6}}{6!}\\,p^{(6)}(x) + \\mathcal{O}(h^{7})\n$$\nwhere $p^{(n)}(x)$ denotes the $n$-th derivative of $p$ with respect to $x$, evaluated at $x$.\n\nWe now substitute these expansions into the numerator of the expression for $D_{xx}p(x)$. Let's first sum $p(x+h)$ and $p(x-h)$:\n$$\np(x+h) + p(x-h) = 2\\,p(x) + 2\\frac{h^{2}}{2!}\\,p^{(2)}(x) + 2\\frac{h^{4}}{4!}\\,p^{(4)}(x) + 2\\frac{h^{6}}{6!}\\,p^{(6)}(x) + \\mathcal{O}(h^{8})\n$$\nNotice that all terms with odd powers of $h$ cancel out due to the symmetry of the expansions. Simplifying the factorials ($2! = 2$, $4! = 24$, $6! = 720$), we get:\n$$\np(x+h) + p(x-h) = 2\\,p(x) + h^{2}\\,p^{(2)}(x) + \\frac{h^{4}}{12}\\,p^{(4)}(x) + \\frac{h^{6}}{360}\\,p^{(6)}(x) + \\mathcal{O}(h^{8})\n$$\nNow, we form the full numerator $p(x+h) - 2\\,p(x) + p(x-h)$:\n$$\np(x+h) - 2\\,p(x) + p(x-h) = \\left(2\\,p(x) + h^{2}\\,p^{(2)}(x) + \\frac{h^{4}}{12}\\,p^{(4)}(x) + \\frac{h^{6}}{360}\\,p^{(6)}(x) + \\mathcal{O}(h^{8})\\right) - 2\\,p(x)\n$$\n$$\np(x+h) - 2\\,p(x) + p(x-h) = h^{2}\\,p^{(2)}(x) + \\frac{h^{4}}{12}\\,p^{(4)}(x) + \\frac{h^{6}}{360}\\,p^{(6)}(x) + \\mathcal{O}(h^{8})\n$$\nTo find the expression for $D_{xx}p(x)$, we divide this result by $h^{2}$:\n$$\nD_{xx}p(x) = \\frac{1}{h^{2}}\\left(h^{2}\\,p^{(2)}(x) + \\frac{h^{4}}{12}\\,p^{(4)}(x) + \\frac{h^{6}}{360}\\,p^{(6)}(x) + \\mathcal{O}(h^{8})\\right)\n$$\n$$\nD_{xx}p(x) = p^{(2)}(x) + \\frac{h^{2}}{12}\\,p^{(4)}(x) + \\frac{h^{4}}{360}\\,p^{(6)}(x) + \\mathcal{O}(h^{6})\n$$\nThe local truncation error, which we denote by $T(h)$, is the difference between this discrete approximation and the exact second derivative, $p_{xx}(x) = p^{(2)}(x)$:\n$$\nT(h) = D_{xx}p(x) - p_{xx}(x) = \\left(p^{(2)}(x) + \\frac{h^{2}}{12}\\,p^{(4)}(x) + \\frac{h^{4}}{360}\\,p^{(6)}(x) + \\mathcal{O}(h^{6})\\right) - p^{(2)}(x)\n$$\n$$\nT(h) = \\frac{h^{2}}{12}\\,p^{(4)}(x) + \\frac{h^{4}}{360}\\,p^{(6)}(x) + \\mathcal{O}(h^{6})\n$$\nThis expression gives the local truncation error. The leading non-zero term is $\\frac{h^{2}}{12}\\,p^{(4)}(x)$. The order of accuracy of the scheme is the power of $h$ in this leading term, which is $2$.\n\nThe problem requires us to write the error in the form $C\\,h^{2}\\,p^{(4)}(x)+\\mathcal{O}(h^{4})$. From our derived expression, we can write:\n$$\nD_{xx}p(x) - p_{xx}(x) = \\frac{1}{12}\\,h^{2}\\,p^{(4)}(x) + \\mathcal{O}(h^{4})\n$$\nThe term $\\frac{h^{4}}{360}\\,p^{(6)}(x)$ and all higher-order terms are absorbed into the $\\mathcal{O}(h^{4})$ notation.\n\nBy comparing our result with the specified form $C\\,h^{2}\\,p^{(4)}(x)+\\mathcal{O}(h^{4})$, we can directly identify the constant $C$:\n$$\nC = \\frac{1}{12}\n$$",
            "answer": "$$\\boxed{\\frac{1}{12}}$$"
        },
        {
            "introduction": "A small truncation error suggests local accuracy, but does it guarantee a valid global solution over time? This computational exercise  tackles this critical question by demonstrating the profound difference between local accuracy and numerical stability. You will implement a simulation of the wave equation and observe how a numerically unstable scheme can produce divergent results, even when the grid is fine enough to make the truncation error very small.",
            "id": "4149952",
            "problem": "Consider the one-dimensional linear acoustic wave equation for small-amplitude pressure perturbations in a homogeneous medium, expressed as the second-order partial differential equation $p_{tt} = c^2 p_{xx}$, where $p(x,t)$ is the nondimensional acoustic pressure, $t$ is nondimensional time, $x$ is nondimensional space, and $c$ is the nondimensional speed of sound (set to $c=1$ by nondimensionalization). On a periodic domain of length $L = 2\\pi$, an exact solution is $p(x,t) = \\sin(\\kappa x)\\cos(\\omega t)$ with $\\kappa = 1$ and $\\omega = c\\kappa = 1$.\n\nA standard explicit second-order finite-difference scheme for $p_{tt} = c^2 p_{xx}$ on a uniform grid $x_j = j\\Delta x$ with time step $\\Delta t$ updates nodal values via\n$$\np_j^{n+1} = 2p_j^n - p_j^{n-1} + \\lambda^2\\left(p_{j+1}^n - 2p_j^n + p_{j-1}^n\\right),\n$$\nwhere $\\lambda = c\\,\\Delta t/\\Delta x$ is the Courant number associated with the Courant–Friedrichs–Lewy (CFL) condition. This scheme is second-order accurate in both time and space: its local truncation error is expected to scale as $\\mathcal{O}(\\Delta t^2) + \\mathcal{O}(\\Delta x^2)$. However, the CFL requirement imposes a stability restriction that is not implied by truncation error alone; for this scheme, violating stability (e.g., by choosing $\\lambda > 1$) may lead to divergent numerical solutions even when the truncation error is small.\n\nYour task is to implement a program that, for several test cases, demonstrates the separation between truncation error and stability. For each test case, you must:\n\n1. Compute the maximum-norm local truncation residual at time $t=0$ by substituting the exact solution into the finite-difference update and evaluating\n$$\nR_j = p(x_j,\\Delta t) - 2p(x_j,0) + p(x_j,-\\Delta t) - \\lambda^2\\left[p(x_{j+1},0) - 2p(x_j,0) + p(x_{j-1},0)\\right],\n$$\nthen report $\\max_j |R_j|$. This quantity is dimensionless.\n\n2. Evolve the finite-difference scheme from $t=0$ to a final time $T$ with periodic boundary conditions, using $p_j^0 = p(x_j,0)$ and $p_j^1 = p(x_j,\\Delta t)$ obtained from the exact solution to avoid startup inconsistencies. At the end of the evolution, report the growth factor defined by\n$$\nG = \\frac{\\max_j |p_j^N|}{\\max_j |p_j^0|},\n$$\nwhere $N$ is the total number of time steps taken to reach $T$ (rounded to the nearest integer), and $p_j^N$ is the numerical solution after $N$ steps. This quantity is dimensionless.\n\n3. Report a boolean boundedness indicator defined as true if $G \\leq 1.2$ and false otherwise.\n\nYou must use the following test suite, where each tuple specifies $(N_x, \\lambda, T)$ with $N_x$ the number of spatial grid points, $\\lambda$ the Courant number, and $T$ the nondimensional final time:\n\n- $(100, 0.9, 10)$: a case expected to satisfy the CFL stability condition.\n- $(100, 1.0, 10)$: a boundary case for the CFL condition.\n- $(200, 1.05, 30)$: a case that violates the CFL stability condition while having fine spatial and temporal resolution (small $\\Delta x$ and $\\Delta t$), hence small truncation residual but unstable.\n\nAll quantities in this problem are nondimensional; no physical units are required in the output. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with entries ordered sequentially per test case as\n$[\\text{residual}_1,\\text{growth}_1,\\text{bounded}_1,\\text{residual}_2,\\text{growth}_2,\\text{bounded}_2,\\text{residual}_3,\\text{growth}_3,\\text{bounded}_3]$,\nwhere each $\\text{residual}_i$ and $\\text{growth}_i$ is a float, and each $\\text{bounded}_i$ is a boolean.",
            "solution": "The problem statement has been analyzed and is determined to be valid. It is a well-posed, scientifically grounded problem in the field of computational acoustics and numerical analysis of partial differential equations. All required data, definitions, and conditions are provided, and there are no internal contradictions or ambiguities.\n\nThe problem requires the calculation of three quantities for three distinct test cases to illustrate the difference between local truncation error and numerical stability for a finite-difference scheme applied to the one-dimensional acoustic wave equation. The quantities are the maximum local truncation residual, the solution growth factor over a fixed time interval, and a boundedness indicator.\n\nThe governing partial differential equation (PDE) is the linear wave equation in one spatial dimension, $p_{tt} = c^2 p_{xx}$, where $p(x,t)$ is the acoustic pressure, and the wave speed is specified as $c=1$. The problem is posed on a periodic domain of length $L=2\\pi$. An exact solution is given by $p(x,t) = \\sin(\\kappa x)\\cos(\\omega t)$ with $\\kappa = 1$ and $\\omega = c\\kappa = 1$.\n\nThe numerical method is the explicit second-order central difference scheme:\n$$\np_j^{n+1} = 2p_j^n - p_j^{n-1} + \\lambda^2\\left(p_{j+1}^n - 2p_j^n + p_{j-1}^n\\right)\n$$\nwhere $p_j^n \\approx p(x_j, t_n)$, $x_j=j\\Delta x$, $t_n=n\\Delta t$, and $\\lambda = c\\Delta t/\\Delta x = \\Delta t/\\Delta x$ is the Courant number.\n\n### Step 1: Calculation of the Local Truncation Residual\n\nThe local truncation residual, $R_j$, is a measure of how well the exact solution satisfies the finite-difference equation at a single point. It is defined as:\n$$\nR_j = p(x_j,\\Delta t) - 2p(x_j,0) + p(x_j,-\\Delta t) - \\lambda^2\\left[p(x_{j+1},0) - 2p(x_j,0) + p(x_{j-1},0)\\right]\n$$\nThis quantity is directly related to the local truncation error, $\\tau$, by $R_j = \\Delta t^2 \\tau_j^{n=0}$. To compute $\\max_j |R_j|$, we first establish a uniform spatial grid with $N_x$ points, $x_j = j \\Delta x$ for $j=0, 1, \\dots, N_x-1$, where $\\Delta x = L/N_x = 2\\pi/N_x$. The time step $\\Delta t$ is determined by the given Courant number $\\lambda$ and $\\Delta x$ as $\\Delta t = \\lambda \\Delta x$.\n\nWe then evaluate the terms in the expression for $R_j$ using the exact solution $p(x,t) = \\sin(x)\\cos(t)$:\n-   $p(x_j, \\Delta t) = \\sin(x_j)\\cos(\\Delta t)$\n-   $p(x_j, 0) = \\sin(x_j)$\n-   $p(x_j, -\\Delta t) = \\sin(x_j)\\cos(-\\Delta t) = \\sin(x_j)\\cos(\\Delta t)$\n-   The spatial difference term requires values at neighboring points $x_{j+1}$ and $x_{j-1}$. For a vectorized computation on the grid, these are obtained by shifting the array representing $p(x_j, 0)$.\n\nThe maximum absolute value of the resulting vector $R_j$ is then computed. As the scheme is second-order accurate in space and time, the local truncation error is $\\mathcal{O}(\\Delta x^2, \\Delta t^2)$. The residual $R_j$ is thus expected to scale as $\\mathcal{O}(\\Delta x^4, \\Delta t^4, \\Delta x^2 \\Delta t^2)$. For smaller grid spacings, the residual should decrease, indicating higher local accuracy.\n\n### Step 2: Time Evolution and Growth Factor\n\nThe second task is to simulate the evolution of the solution using the finite-difference scheme and measure its growth. The simulation is initialized using the exact solution to maintain second-order accuracy from the start:\n-   $p_j^0 = p(x_j, 0) = \\sin(x_j)$\n-   $p_j^1 = p(x_j, \\Delta t) = \\sin(x_j)\\cos(\\Delta t)$\n\nThe simulation runs for a total number of time steps $N = \\text{round}(T/\\Delta t)$, where $T$ is the specified final time. The update rule is applied iteratively for $N-1$ steps to find the solution $p_j^N$ at time $t_N = N \\Delta t$. Periodic boundary conditions are enforced by ensuring that grid indices are treated modulo $N_x$. For example, the neighbor of point $j=N_x-1$ is $j=0$, and the neighbor of $j=0$ is $j=N_x-1$.\n\nThe growth factor $G$ is then computed as the ratio of the maximum amplitude at the final time to the maximum initial amplitude:\n$$\nG = \\frac{\\max_j |p_j^N|}{\\max_j |p_j^0|}\n$$\nThe stability of this scheme is governed by the Courant-Friedrichs-Lewy (CFL) condition, which for this scheme is $\\lambda \\le 1$.\n-   If $\\lambda \\le 1$, the scheme is stable, and the numerical amplitude should remain bounded. We expect $G \\approx 1$.\n-   If $\\lambda > 1$, the scheme is unstable. Numerical errors are amplified at each time step, leading to exponential growth of the solution. We expect $G \\gg 1$, potentially becoming infinite if overflow occurs.\n\n### Step 3: Boundedness Indicator\n\nFinally, a boolean indicator is determined based on the computed growth factor: it is `True` if $G \\le 1.2$ and `False` otherwise. This provides a simple binary classification of the simulation's outcome as either bounded (stable) or unbounded (unstable).\n\nThe three test cases are designed to highlight the following:\n1.  **Case 1: $(N_x=100, \\lambda=0.9, T=10)$**: This is a stable case ($\\lambda < 1$). We expect a small residual and a growth factor close to $1$.\n2.  **Case 2: $(N_x=100, \\lambda=1.0, T=10)$**: This is the marginally stable case ($\\lambda = 1$). The scheme has special properties at this limit (zero numerical dispersion for this specific problem), so we expect an even smaller residual and a growth factor very close to $1$.\n3.  **Case 3: $(N_x=200, \\lambda=1.05, T=30)$**: This is an unstable case ($\\lambda > 1$). Because $N_x$ is larger, $\\Delta x$ is smaller, leading to a smaller truncation residual than in Case 1. However, since the CFL condition is violated, the solution is expected to grow unboundedly, demonstrating that low truncation error does not imply stability.\n\nThe implementation will follow these steps for each test case provided.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n\n    def run_case(Nx, lambda_val, T_final):\n        \"\"\"\n        Solves one test case for the acoustic wave equation problem.\n\n        Args:\n            Nx (int): Number of spatial grid points.\n            lambda_val (float): Courant number.\n            T_final (float): Final simulation time.\n\n        Returns:\n            tuple: A tuple containing (max_residual, growth_factor, is_bounded).\n        \"\"\"\n        # --- Constants and Grid Setup ---\n        L = 2.0 * np.pi\n        c = 1.0\n        kappa = 1.0\n        omega = 1.0\n\n        dx = L / Nx\n        # Grid points x_j = j*dx for j = 0, ..., Nx-1\n        x = np.arange(Nx) * dx\n        dt = lambda_val * dx / c\n\n        # Exact solution p(x,t) = sin(kappa*x) * cos(omega*t)\n        def p_exact(x_coords, t):\n            return np.sin(kappa * x_coords) * np.cos(omega * t)\n\n        # --- Part 1: Calculation of the Local Truncation Residual ---\n        # The residual is defined as:\n        # R_j = p(x_j,Δt) - 2p(x_j,0) + p(x_j,-Δt) - λ^2[p(x_{j+1},0) - 2p_j^0 + p(x_{j-1},0)]\n        p_t0 = p_exact(x, 0.0)\n        p_tdt = p_exact(x, dt)\n        p_t_neg_dt = p_exact(x, -dt)\n\n        # Spatial finite difference operator applied to p(x,0)\n        # np.roll implements periodic boundary conditions\n        D2x_p_t0 = np.roll(p_t0, -1) - 2 * p_t0 + np.roll(p_t0, 1)\n\n        # Temporal difference and spatial difference terms of the residual\n        term_time = p_tdt - 2 * p_t0 + p_t_neg_dt\n        term_space = (lambda_val**2) * D2x_p_t0\n\n        residual_vector = term_time - term_space\n        max_residual = np.max(np.abs(residual_vector))\n\n        # --- Part 2: Time Evolution and Growth Factor ---\n        N_steps = int(round(T_final / dt))\n\n        # Initialize numerical solution at two time levels from exact solution\n        p_prev = p_exact(x, 0.0)      # p^0\n        p_curr = p_exact(x, dt)       # p^1\n\n        max_p0 = np.max(np.abs(p_prev))\n        # Avoid division by zero, although not expected for this problem's initial condition\n        if max_p0 == 0:\n            max_p0 = 1.0\n\n        # Time-stepping loop to evolve the solution to t = N_steps * dt\n        for _ in range(1, N_steps):\n            D2x_p_curr = np.roll(p_curr, -1) - 2 * p_curr + np.roll(p_curr, 1)\n\n            # Leapfrog update rule\n            p_next = 2 * p_curr - p_prev + (lambda_val**2) * D2x_p_curr\n\n            # Update time levels\n            p_prev = p_curr\n            p_curr = p_next\n\n        max_pN = np.max(np.abs(p_curr))\n        growth_factor = max_pN / max_p0\n\n        # --- Part 3: Boundedness Indicator ---\n        is_bounded = growth_factor <= 1.2\n\n        return max_residual, growth_factor, is_bounded\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (Nx, lambda, T)\n        (100, 0.9, 10),\n        (100, 1.0, 10),\n        (200, 1.05, 30),\n    ]\n\n    results = []\n    for case in test_cases:\n        res, growth, bounded = run_case(*case)\n        results.extend([res, growth, bounded])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "In professional practice, verifying that a newly written solver performs as theoretically designed is a crucial, non-negotiable step. This hands-on practice  introduces the grid refinement study, a powerful and standard technique for code verification. You will derive the formulas for estimating the observed order of accuracy and for performing Richardson extrapolation, then implement them to confirm that a synthetic solver behaves as expected, a skill essential for developing reliable computational tools.",
            "id": "4149943",
            "problem": "You are tasked with designing a mathematically rigorous grid refinement study to estimate the observed order of accuracy for an acoustic solver, using three solutions computed on successively refined spatial grids with spacings $h$, $h/2$, and $h/4$. Your goal is to derive the estimator for the observed order of accuracy and a consistent Richardson extrapolation formula for the underlying acoustic observable, and to implement these in a program that evaluates a set of test cases.\n\nThe fundamental base for this problem is the definition of truncation error and order of accuracy. For a consistent numerical method approximating a smooth acoustic observable (for example, a sample of acoustic pressure or a spatial norm) on a grid with spacing $h$, the discrete approximation $S_h$ satisfies, for sufficiently small $h$, the asymptotic error model\n$$\nS_h = S + C h^p + \\mathcal{O}\\left(h^{p+1}\\right),\n$$\nwhere $S$ is the exact observable, $C$ is a constant independent of $h$, and $p$ is the (unknown) order of accuracy. The purpose of the grid refinement study is to estimate $p$ and to compute an extrapolated approximation of $S$ using only $S_h$, $S_{h/2}$, and $S_{h/4}$.\n\nDesign requirements:\n- Starting from the asymptotic error model above, derive a formula to estimate the observed order $p$ using the three approximations $S_h$, $S_{h/2}$, and $S_{h/4}$ at refinement ratio $r = 2$.\n- Derive a Richardson extrapolation formula for $S$ using the two finest-grid approximations and your estimated order $p$.\n- The derivations must be performed without invoking any pre-derived “shortcut” formulas. You must start from the error model and reason to the final formulas.\n\nImplementation requirements:\n- Implement a program that constructs synthetic “acoustic solver” outputs consistent with the asymptotic model. For each test case, you will be given parameters $(S_\\star, p_{\\text{true}}, C, D, h)$, and you must define synthetic approximations by\n$$\nS_h = S_\\star + C h^{p_{\\text{true}}} + D h^{p_{\\text{true}} + 1}, \\quad\nS_{h/2} = S_\\star + C \\left(\\frac{h}{2}\\right)^{p_{\\text{true}}} + D \\left(\\frac{h}{2}\\right)^{p_{\\text{true}} + 1}, \\quad\nS_{h/4} = S_\\star + C \\left(\\frac{h}{4}\\right)^{p_{\\text{true}}} + D \\left(\\frac{h}{4}\\right)^{p_{\\text{true}} + 1}.\n$$\nHere $S_\\star$ represents an exact acoustic observable (dimensionless), $p_{\\text{true}}$ is the true order of the synthetic model, $C$ is the leading-order error coefficient, and $D$ is a subleading error coefficient representing higher-order contamination.\n- From these three values, compute the observed order $p_{\\text{obs}}$ and an extrapolated solution $S_{\\text{ext}}$ using your derived formulas. Use the finest pair $(h/2,h/4)$ for extrapolation to reduce higher-order contamination.\n- For numerical robustness, take absolute values inside the logarithm when estimating the order to avoid issues with sign changes in $C$; you must still ensure the ratio is positive and finite.\n\nTest suite:\nUse the following four test cases, each defined by $(S_\\star, p_{\\text{true}}, C, D, h)$.\n- Case $1$: $(0.75321, 2, 0.5, 0, 0.1)$\n- Case $2$: $(-0.132, 3, -0.3, 0, 0.12)$\n- Case $3$: $(2.5, 4, 1.0, 5.0, 0.08)$\n- Case $4$: $(0.0, 2, 1.0 \\times 10^{-4}, 0, 0.5)$\n\nProgram output specification:\n- For each test case, output two floats: the observed order $p_{\\text{obs}}$ and the extrapolated solution $S_{\\text{ext}}$, both rounded to $6$ decimal places.\n- Aggregate the results for all four test cases into a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order\n$$\n[p_{\\text{obs}}^{(1)}, S_{\\text{ext}}^{(1)}, p_{\\text{obs}}^{(2)}, S_{\\text{ext}}^{(2)}, p_{\\text{obs}}^{(3)}, S_{\\text{ext}}^{(3)}, p_{\\text{obs}}^{(4)}, S_{\\text{ext}}^{(4)}].\n$$\nNo physical units are required because all quantities are dimensionless by construction. Do not include any additional text in the output.",
            "solution": "The problem requires the derivation of an estimator for the observed order of accuracy, $p_{\\text{obs}}$, and a corresponding Richardson extrapolation formula, $S_{\\text{ext}}$, based on three numerical solutions from a grid refinement study. Following this, an implementation is required to apply these formulas to a set of synthetic test cases.\n\nThe foundation for this analysis is the asymptotic error model for a numerical approximation $S_h$ of an exact quantity $S$ on a grid with characteristic spacing $h$:\n$$\nS_h = S + C h^p + \\mathcal{O}\\left(h^{p+1}\\right)\n$$\nHere, $p$ is the formal order of accuracy of the numerical method and $C$ is the leading-order error coefficient, assumed to be constant for sufficiently small $h$.\n\nWe are provided with three solutions, $S_h$, $S_{h/2}$, and $S_{h/4}$, computed on successively refined grids with a constant refinement ratio $r=2$. To simplify the derivation, we will denote these solutions as $S_1 = S_h$, $S_2 = S_{h/2}$, and $S_3 = S_{h/4}$. By truncating the asymptotic error model and neglecting the higher-order terms $\\mathcal{O}(h^{p+1})$, we obtain a system of approximate equations. This truncation is valid in the asymptotic limit where $h \\to 0$.\n\n$$\nS_1 \\approx S + C h^p \\\\\nS_2 \\approx S + C \\left(\\frac{h}{2}\\right)^p = S + C \\frac{h^p}{2^p} \\\\\nS_3 \\approx S + C \\left(\\frac{h}{4}\\right)^p = S + C \\frac{h^p}{4^p}\n$$\n\n**Derivation of the Observed Order of Accuracy ($p_{\\text{obs}}$)**\n\nOur first goal is to estimate the order of accuracy $p$ using the three available solutions. The strategy is to eliminate the unknown quantities $S$ and $C$ from the system of equations. We can eliminate $S$ by considering the differences between successive approximations:\n\n$$\nS_1 - S_2 \\approx \\left(S + C h^p\\right) - \\left(S + C \\frac{h^p}{2^p}\\right) = C h^p \\left(1 - \\frac{1}{2^p}\\right)\n$$\n\n$$\nS_2 - S_3 \\approx \\left(S + C \\frac{h^p}{2^p}\\right) - \\left(S + C \\frac{h^p}{4^p}\\right) = C \\frac{h^p}{2^p} \\left(1 - \\frac{1}{2^p}\\right)\n$$\n\nNow, we can eliminate the term $C h^p \\left(1 - \\frac{1}{2^p}\\right)$ by taking the ratio of these two differences. This is permissible as long as the denominator is non-zero, which is generally true for a converging solution where the error does not vanish prematurely.\n\n$$\n\\frac{S_1 - S_2}{S_2 - S_3} \\approx \\frac{C h^p \\left(1 - \\frac{1}{2^p}\\right)}{C \\frac{h^p}{2^p} \\left(1 - \\frac{1}{2^p}\\right)} = 2^p\n$$\nThis relationship provides a direct way to solve for $p$. By taking the natural logarithm of both sides, we can isolate $p$:\n\n$$\n\\ln\\left(\\frac{S_1 - S_2}{S_2 - S_3}\\right) \\approx \\ln(2^p) = p \\ln(2)\n$$\n\nSolving for $p$ gives the estimator for the observed order of accuracy, which we denote $p_{\\text{obs}}$:\n\n$$\np_{\\text{obs}} = \\frac{\\ln\\left(\\frac{S_h - S_{h/2}}{S_{h/2} - S_{h/4}}\\right)}{\\ln(2)}\n$$\n\nFor numerical robustness, particularly when dealing with real solver output that may include floating-point noise or non-monotonically convergent behavior, it is prudent to take the absolute value of the ratio before applying the logarithm, as specified in the problem.\n\n$$\np_{\\text{obs}} = \\frac{\\ln\\left(\\left| \\frac{S_h - S_{h/2}}{S_{h/2} - S_{h/4}} \\right|\\right)}{\\ln(2)}\n$$\n\n**Derivation of the Richardson Extrapolation Formula ($S_{\\text{ext}}$)**\n\nOur second goal is to derive a more accurate estimate of the exact solution $S$ using the available approximations. This procedure is known as Richardson extrapolation. The problem specifies using the two finest-grid solutions, $S_2 = S_{h/2}$ and $S_3 = S_{h/4}$, along with our estimated order of accuracy, $p_{\\text{obs}}$.\n\nWe return to the truncated error equations for these two solutions, now using $p_{\\text{obs}}$ as our estimate for $p$:\n\n$$\nS_2 \\approx S + C \\left(\\frac{h}{2}\\right)^{p_{\\text{obs}}} \\\\\nS_3 \\approx S + C \\left(\\frac{h}{4}\\right)^{p_{\\text{obs}}} = S + C \\frac{(h/2)^{p_{\\text{obs}}}}{2^{p_{\\text{obs}}}}\n$$\n\nThis is a system of two linear equations in the two unknowns $S$ and the error term $E_2 = C (h/2)^{p_{\\text{obs}}}$. Our objective is to solve for $S$. Let's rewrite the system:\n\n$$\nS_2 \\approx S + E_2 \\\\\nS_3 \\approx S + \\frac{E_2}{2^{p_{\\text{obs}}}}\n$$\n\nFrom the first equation, we can express the error term $E_2$ as $E_2 \\approx S_2 - S$. Substituting this into the second equation yields:\n\n$$\nS_3 \\approx S + \\frac{S_2 - S}{2^{p_{\\text{obs}}}}\n$$\n\nWe now solve this equation for $S$. Multiply both sides by $2^{p_{\\text{obs}}}$ to clear the denominator:\n\n$$\nS_3 \\cdot 2^{p_{\\text{obs}}} \\approx S \\cdot 2^{p_{\\text{obs}}} + S_2 - S\n$$\n\nGroup the terms involving $S$:\n\n$$\nS_3 \\cdot 2^{p_{\\text{obs}}} - S_2 \\approx S \\left(2^{p_{\\text{obs}}} - 1\\right)\n$$\n\nFinally, dividing by $(2^{p_{\\text{obs}}} - 1)$ gives the formula for the Richardson-extrapolated solution, $S_{\\text{ext}}$. This formula is valid provided that $p_{\\text{obs}} \\neq 0$.\n\n$$\nS_{\\text{ext}} = \\frac{S_3 \\cdot 2^{p_{\\text{obs}}} - S_2}{2^{p_{\\text{obs}}} - 1} = \\frac{S_{h/4} \\cdot 2^{p_{\\text{obs}}} - S_{h/2}}{2^{p_{\\text{obs}}} - 1}\n$$\n\nThis extrapolated value, $S_{\\text{ext}}$, has an error that is of a higher order than the original approximations, typically $\\mathcal{O}(h^{p+1})$, assuming the asymptotic error model accurately describes the solver's behavior on the grids used.\n\nThe implementation will proceed by first generating the synthetic data points $S_h$, $S_{h/2}$, and $S_{h/4}$ for each test case. Then, it will apply the derived formula for $p_{\\text{obs}}$, followed by the formula for $S_{\\text{ext}}$, and format the results as specified.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the grid refinement study problem by deriving estimators for the\n    order of accuracy and performing Richardson extrapolation.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (S_star, p_true, C, D, h)\n    test_cases = [\n        (0.75321, 2, 0.5, 0, 0.1),\n        (-0.132, 3, -0.3, 0, 0.12),\n        (2.5, 4, 1.0, 5.0, 0.08),\n        (0.0, 2, 1.0e-4, 0, 0.5),\n    ]\n\n    results = []\n    for case in test_cases:\n        S_star, p_true, C, D, h = case\n\n        # 1. Generate synthetic \"acoustic solver\" outputs\n        # S_h = S_star + C*h^p + D*h^(p+1)\n        s_h = S_star + C * h**p_true + D * h**(p_true + 1)\n        # S_h/2\n        s_h_2 = S_star + C * (h / 2)**p_true + D * (h / 2)**(p_true + 1)\n        # S_h/4\n        s_h_4 = S_star + C * (h / 4)**p_true + D * (h / 4)**(p_true + 1)\n\n        # 2. Compute the observed order of accuracy (p_obs)\n        # p_obs = ln(|(S_h - S_h/2) / (S_h/2 - S_h/4)|) / ln(2)\n        numerator = s_h - s_h_2\n        denominator = s_h_2 - s_h_4\n\n        # The problem cases are well-behaved, so denominator won't be zero.\n        ratio = numerator / denominator\n        \n        # Taking the absolute value as per the problem's robustness requirement.\n        p_obs = np.log(np.abs(ratio)) / np.log(2)\n\n        # 3. Compute the extrapolated solution (S_ext)\n        # S_ext = (S_h/4 * 2^p_obs - S_h/2) / (2^p_obs - 1)\n        # This formula is valid for p_obs != 0.\n        power_of_2 = 2**p_obs\n        S_ext = (s_h_4 * power_of_2 - s_h_2) / (power_of_2 - 1)\n\n        # 4. Round results to 6 decimal places and append to the list\n        results.append(round(p_obs, 6))\n        results.append(round(S_ext, 6))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}