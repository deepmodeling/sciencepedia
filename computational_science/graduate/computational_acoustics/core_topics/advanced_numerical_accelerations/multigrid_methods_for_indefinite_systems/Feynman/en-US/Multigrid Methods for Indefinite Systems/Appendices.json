{
    "hands_on_practices": [
        {
            "introduction": "Before building complex solvers, it is crucial to understand why simple ones fail. This first practice uses Local Fourier Analysis (LFA), a cornerstone of multigrid theory, to quantitatively diagnose the performance of a standard weighted Jacobi smoother on the Helmholtz equation. By calculating the two-grid convergence factor, you will directly observe that the smoother fails to attenuate high-frequency errors, providing the fundamental motivation for developing the specialized methods discussed in this article .",
            "id": "4130263",
            "problem": "Consider one-dimensional, time-harmonic linear acoustics in free space, for which the frequency-domain pressure satisfies the Helmholtz equation derived from conservation of mass and momentum in the linear regime: $-\\frac{\\mathrm{d}^{2}u}{\\mathrm{d}x^{2}} - k^{2} u = f$, where $u$ is the acoustic pressure amplitude, $k$ is the wavenumber, and $f$ is a source term. Discretize the operator on an infinite, uniform grid with spacing $h$ using the second-order centered difference for the second derivative. Denote the resulting discrete operator by $A_{h}$ acting on grid functions $\\{u_{i}\\}_{i \\in \\mathbb{Z}}$. Assume the two-grid method uses one pre-smoothing and one post-smoothing step of weighted Jacobi with weight $\\omega = \\frac{2}{3}$, and ideal coarse-grid correction that exactly removes the low-frequency error components residing in the subspace spanned by Fourier modes with fine-grid angles $|\\theta| \\leq \\frac{\\pi}{2}$. Under the Local Fourier Analysis (LFA) framework (Local Fourier Analysis (LFA) uses plane-wave error modes and operator symbols to predict multigrid performance), the worst-case two-grid convergence factor is defined as the supremum, over the high-frequency set $\\frac{\\pi}{2} \\leq \\theta \\leq \\pi$, of the squared magnitude of the one-step weighted-Jacobi smoothing symbol.\n\nStarting from these bases:\n- The second-order centered finite-difference approximation of the second derivative.\n- The definition of the Helmholtz operator and its discretization symbol on an infinite uniform grid.\n- The form of weighted Jacobi smoothing derived from diagonal splitting $A_{h} = D - (L + U)$ and the smoothing operator $S = I - \\omega D^{-1} A_{h}$.\n\nDerive the discrete Helmholtz symbol $a(\\theta)$, the diagonal symbol $d$, and the weighted Jacobi smoothing symbol $s(\\theta)$ in terms of the dimensionless parameter $q = kh$. Then, using the idealized two-grid LFA assumption stated above, express the worst-case two-grid convergence factor as $\\sup_{\\theta \\in [\\pi/2,\\pi]} |s(\\theta)|^{2}$. Evaluate this supremum exactly for the specified parameter $q = 1.6$ and $\\omega = \\frac{2}{3}$.\n\nYour final answer must be the single worst-case two-grid convergence factor, expressed as an exact rational number. No rounding is required and no units are needed.",
            "solution": "The problem is subjected to validation before proceeding to a solution.\n\n### Step 1: Extract Givens\n-   **Governing Equation**: The one-dimensional, time-harmonic linear acoustics pressure $u$ satisfies the Helmholtz equation: $-\\frac{\\mathrm{d}^{2}u}{\\mathrm{d}x^{2}} - k^{2} u = f$.\n-   **Discretization**: The operator is discretized on an infinite, uniform grid with spacing $h$ using a second-order centered difference for the second derivative.\n-   **Discrete Operator**: The discrete operator is denoted by $A_h$.\n-   **Two-Grid Method**: The method employs one pre-smoothing and one post-smoothing step.\n-   **Smoother**: The smoother is weighted Jacobi with weight $\\omega = \\frac{2}{3}$.\n-   **Smoothing Operator**: The smoothing operator is defined as $S = I - \\omega D^{-1} A_{h}$, derived from the splitting $A_h = D - (L+U)$.\n-   **Coarse-Grid Correction**: The correction is assumed to be ideal, exactly removing error components for Fourier modes with fine-grid angles $|\\theta| \\leq \\frac{\\pi}{2}$.\n-   **Analysis Framework**: Local Fourier Analysis (LFA) is used.\n-   **Quantity to Calculate**: The worst-case two-grid convergence factor is defined as $\\sup_{\\theta \\in [\\pi/2,\\pi]} |s(\\theta)|^{2}$, where $s(\\theta)$ is the one-step weighted-Jacobi smoothing symbol.\n-   **Parameters**: The dimensionless parameter is $q = kh$, its value is specified as $q=1.6$.\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientifically Grounded**: The problem is based on the Helmholtz equation, a cornerstone of wave physics, and employs standard numerical methods (finite differences, multigrid, weighted Jacobi) and analysis tools (Local Fourier Analysis). The entire framework is scientifically and mathematically sound.\n-   **Well-Posed**: The problem is well-posed. It requests the calculation of a specific, well-defined quantity (the worst-case smoothing factor) based on a complete set of initial data, parameters, and definitions.\n-   **Objective**: The problem is stated in precise, objective, and formal mathematical language, free of any subjectivity or ambiguity.\n-   **Completeness and Consistency**: The problem provides all necessary information: the differential equation, the discretization scheme, the multigrid components (smoother, weight, ideal correction), the analysis method (LFA), and all required numerical parameters ($\\omega$, $q$). There are no contradictions.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete, reasoned solution will be provided.\n\n### Solution Derivation\nThe solution proceeds by first deriving the symbol of the discrete Helmholtz operator, then the symbol of the weighted Jacobi smoother, and finally evaluating the supremum of its squared magnitude over the specified frequency range.\n\nThe one-dimensional Helmholtz operator is given by $A = -\\frac{\\mathrm{d}^2}{\\mathrm{d}x^2} - k^2$.\nUsing a second-order centered finite difference for the second derivative on a uniform grid with spacing $h$, the discrete operator $A_h$ acting on a grid function $\\{u_i\\}_{i \\in \\mathbb{Z}}$ at grid point $i$ is:\n$$ (A_h u)_i = -\\frac{u_{i+1} - 2u_i + u_{i-1}}{h^2} - k^2 u_i $$\nWe can rewrite this as a stencil applied at point $i$:\n$$ (A_h u)_i = \\frac{1}{h^2} \\left( -u_{i+1} + (2 - k^2 h^2)u_i - u_{i-1} \\right) $$\n\nTo perform Local Fourier Analysis (LFA), we analyze the action of the operator $A_h$ on a Fourier mode $u_j = \\exp(ij\\theta)$, where $\\theta \\in [-\\pi, \\pi]$ is the Fourier angle. The symbol $a(\\theta)$ of the operator $A_h$ is defined by the relation $(A_h \\exp(ij\\theta))_j = a(\\theta) \\exp(ij\\theta)$.\n$$ a(\\theta) = \\frac{1}{h^2} \\left( -e^{i\\theta} + (2 - k^2 h^2) - e^{-i\\theta} \\right) $$\nUsing Euler's formula $e^{i\\theta} + e^{-i\\theta} = 2\\cos(\\theta)$, the symbol becomes:\n$$ a(\\theta) = \\frac{1}{h^2} \\left( 2 - 2\\cos(\\theta) - k^2 h^2 \\right) $$\nUsing the half-angle identity $1 - \\cos(\\theta) = 2\\sin^2(\\frac{\\theta}{2})$ and the given dimensionless parameter $q=kh$:\n$$ a(\\theta) = \\frac{1}{h^2} \\left( 4\\sin^2\\left(\\frac{\\theta}{2}\\right) - q^2 \\right) $$\nThis is the symbol of the discrete Helmholtz operator $A_h$.\n\nThe weighted Jacobi method is based on the splitting $A_h = D - (L+U)$, where $D$ is the diagonal part of $A_h$. From the stencil, the diagonal operator $D$ is given by $(Du)_i = \\frac{1}{h^2}(2 - q^2)u_i$. The symbol of $D$, denoted by $d$, is the constant coefficient:\n$$ d = \\frac{1}{h^2}(2 - q^2) $$\n\nThe weighted Jacobi smoothing operator is $S = I - \\omega D^{-1} A_h$. Its symbol, $s(\\theta)$, is given by:\n$$ s(\\theta) = 1 - \\omega \\frac{a(\\theta)}{d} $$\nSubstituting the expressions for $a(\\theta)$ and $d$:\n$$ s(\\theta) = 1 - \\omega \\frac{\\frac{1}{h^2} \\left( 4\\sin^2\\left(\\frac{\\theta}{2}\\right) - q^2 \\right)}{\\frac{1}{h^2}(2 - q^2)} = 1 - \\omega \\frac{4\\sin^2\\left(\\frac{\\theta}{2}\\right) - q^2}{2 - q^2} $$\nThis is the general expression for the smoothing symbol.\n\nWe are given the specific parameters $\\omega = \\frac{2}{3}$ and $q = 1.6$. We will use exact rational arithmetic.\n$q = 1.6 = \\frac{16}{10} = \\frac{8}{5}$.\n$q^2 = \\left(\\frac{8}{5}\\right)^2 = \\frac{64}{25}$.\nThe denominator in the fraction is $2 - q^2 = 2 - \\frac{64}{25} = \\frac{50 - 64}{25} = -\\frac{14}{25}$.\nSubstituting these values into the expression for $s(\\theta)$:\n$$ s(\\theta) = 1 - \\frac{2}{3} \\frac{4\\sin^2\\left(\\frac{\\theta}{2}\\right) - \\frac{64}{25}}{-\\frac{14}{25}} $$\n$$ s(\\theta) = 1 + \\left(\\frac{2}{3}\\right) \\left(\\frac{25}{14}\\right) \\left(4\\sin^2\\left(\\frac{\\theta}{2}\\right) - \\frac{64}{25}\\right) $$\n$$ s(\\theta) = 1 + \\frac{25}{21} \\left(4\\sin^2\\left(\\frac{\\theta}{2}\\right) - \\frac{64}{25}\\right) $$\n$$ s(\\theta) = 1 + \\frac{100}{21}\\sin^2\\left(\\frac{\\theta}{2}\\right) - \\frac{25}{21}\\frac{64}{25} $$\n$$ s(\\theta) = 1 + \\frac{100}{21}\\sin^2\\left(\\frac{\\theta}{2}\\right) - \\frac{64}{21} $$\n$$ s(\\theta) = \\frac{21 - 64}{21} + \\frac{100}{21}\\sin^2\\left(\\frac{\\theta}{2}\\right) = \\frac{1}{21}\\left(100\\sin^2\\left(\\frac{\\theta}{2}\\right) - 43\\right) $$\n\nThe problem asks for the worst-case two-grid convergence factor, defined as the supremum of $|s(\\theta)|^2$ over the high-frequency range $\\theta \\in [\\frac{\\pi}{2}, \\pi]$.\nLet $x = \\sin^2(\\frac{\\theta}{2})$. As $\\theta$ varies in the interval $[\\frac{\\pi}{2}, \\pi]$, the argument $\\frac{\\theta}{2}$ varies in $[\\frac{\\pi}{4}, \\frac{\\pi}{2}]$.\nOn this interval, $\\sin(\\frac{\\theta}{2})$ is a monotonically increasing function.\nThe minimum value is $\\sin(\\frac{\\pi}{4}) = \\frac{\\sqrt{2}}{2}$, and the maximum value is $\\sin(\\frac{\\pi}{2}) = 1$.\nTherefore, the variable $x = \\sin^2(\\frac{\\theta}{2})$ varies in the interval $[(\\frac{\\sqrt{2}}{2})^2, 1^2] = [\\frac{2}{4}, 1] = [\\frac{1}{2}, 1]$.\n\nWe need to find the supremum of $|f(x)|^2$ for $x \\in [\\frac{1}{2}, 1]$, where $f(x) = \\frac{1}{21}(100x - 43)$.\nThe function $f(x)$ is a linear function of $x$ with a positive slope ($m = \\frac{100}{21}$). It is therefore monotonically increasing on its domain. The extreme values of $f(x)$ on the interval $[\\frac{1}{2}, 1]$ must occur at the endpoints.\nAt $x = \\frac{1}{2}$ (corresponding to $\\theta = \\frac{\\pi}{2}$):\n$$ f\\left(\\frac{1}{2}\\right) = \\frac{1}{21}\\left(100 \\cdot \\frac{1}{2} - 43\\right) = \\frac{1}{21}(50 - 43) = \\frac{7}{21} = \\frac{1}{3} $$\nAt $x = 1$ (corresponding to $\\theta = \\pi$):\n$$ f(1) = \\frac{1}{21}(100 \\cdot 1 - 43) = \\frac{57}{21} = \\frac{19 \\times 3}{7 \\times 3} = \\frac{19}{7} $$\nSince $f(x)$ is monotonically increasing from $\\frac{1}{3}$ to $\\frac{19}{7}$ on the interval $x \\in [\\frac{1}{2}, 1]$, the function is always positive. Thus, $|f(x)| = f(x)$.\nThe maximum value of $|f(x)|$ on the interval is at $x=1$, which is $\\frac{19}{7}$.\nThe required quantity is the supremum of $|s(\\theta)|^2 = |f(x)|^2$, which is the square of the maximum value of $|f(x)|$.\n$$ \\sup_{\\theta \\in [\\pi/2, \\pi]} |s(\\theta)|^2 = \\left(\\frac{19}{7}\\right)^2 = \\frac{19^2}{7^2} = \\frac{361}{49} $$\nThe worst-case two-grid convergence factor is $\\frac{361}{49}$.",
            "answer": "$$\\boxed{\\frac{361}{49}}$$"
        },
        {
            "introduction": "Moving from 1D theory to a more realistic 2D setting, we now investigate the algebraic properties that make the discretized Helmholtz operator so challenging. This exercise guides you in constructing the system matrix for an acoustic problem with impedance boundary conditions, which are common in practical applications . By computing metrics for non-normality and indefiniteness, you will gain a concrete understanding of how physical boundary conditions directly contribute to the difficult spectral properties of the problem.",
            "id": "4130286",
            "problem": "Consider the time-harmonic acoustic wave governed by the Helmholtz equation on a square domain, where the acoustic pressure field satisfies the partial differential equation $\\nabla^2 u + k^2 u = 0$ in the interior and impedance (Robin) boundary conditions $\\partial u / \\partial n + i \\beta k u = 0$ on the boundary, with $u$ denoting the complex-valued acoustic pressure, $k$ denoting a non-dimensional wave number, and $\\beta$ denoting a non-dimensional impedance factor. Starting from the second-order central finite-difference approximation of the Laplacian on a uniform grid, construct a square sparse matrix $A$ acting on the unknowns associated with interior grid points only. Use the following elimination of boundary values at grid points adjacent to the boundary derived from the impedance boundary condition: at a boundary, the outward normal derivative is approximated by a one-sided finite difference that relates the boundary value $u_b$ and the adjacent interior value $u_a$ through $u_a = (1 + i \\beta k h) u_b$, which implies $u_b = u_a / (1 + i \\beta k h)$, where $h$ is the grid spacing. In the discrete Helmholtz operator at an interior point, replace each missing neighbor outside the domain by this boundary value to obtain the matrix row. For an interior grid point with $m$ missing neighbors due to the boundary, this adds $m \\alpha / h^2$ to the diagonal with $\\alpha = 1 / (1 + i \\beta k h)$, while keeping standard $1 / h^2$ couplings to interior neighbors; the baseline interior stencil is $(-4 / h^2 + k^2)$ on the diagonal and $1 / h^2$ to each of the four axial neighbors.\n\nYou must:\n- Assemble the matrix $A \\in \\mathbb{C}^{n \\times n}$ for a given number of interior grid points per dimension $N$ (so the unknown vector has $n = N^2$ entries), grid spacing $h = 1/(N+1)$, wave number $k$, and impedance factor $\\beta$.\n- Compute all eigenvalues of $A$.\n- Quantify the departure from normality of $A$ using the normalized Frobenius measure $\\delta(A) = \\lVert A^* A - A A^* \\rVert_F / \\lVert A \\rVert_F^2$, where $A^*$ denotes the conjugate transpose and $\\lVert \\cdot \\rVert_F$ denotes the Frobenius norm.\n- Quantify indefiniteness by computing the fraction of eigenvalues with negative real part, defined as $f_- = (\\#\\{\\lambda : \\mathrm{Re}(\\lambda) < 0\\})/n$.\n- Compute the spectral radius of the weighted Jacobi iteration matrix $M = I - \\omega D^{-1} A$ for a fixed weight $\\omega$, where $I$ is the identity matrix and $D$ is the diagonal of $A$. Use $\\omega = 0.6$. Report $\\rho(M)$, the maximum modulus of eigenvalues of $M$.\n\nYour program must compute the above quantities for the following test suite of parameter sets $(N, k, \\beta)$:\n- Case $1$: $(N, k, \\beta) = (8, 15.0, 1.0)$.\n- Case $2$: $(N, k, \\beta) = (8, 6.0, 0.5)$.\n- Case $3$: $(N, k, \\beta) = (6, 10.0, 2.0)$.\n- Case $4$: $(N, k, \\beta) = (4, 20.0, 1.0)$.\n\nAll quantities are dimensionless. For each case, produce a list of three values $[\\delta(A), f_-, \\rho(M)]$ with each value rounded to six decimal places. Your program should produce a single line of output containing the results as a comma-separated list of lists enclosed in square brackets (e.g., $[[x_1,y_1,z_1],[x_2,y_2,z_2],\\ldots]$), where each inner list corresponds to one case in the order given above.\n\nThe problem requires careful construction and analysis to expose the effect of impedance boundary conditions on the non-normality of the discrete Helmholtz operator, and to connect this phenomenon to the behavior of simple smoothers relevant to multigrid methods for indefinite systems.",
            "solution": "The problem requires the construction and analysis of a matrix representing the discretized Helmholtz operator with impedance boundary conditions. The analysis involves quantifying the matrix's non-normality, indefiniteness, and the convergence properties of a related iterative solver.\n\n### 1. Discretization of the Helmholtz Equation\n\nThe governing partial differential equation is the Helmholtz equation on a square domain:\n$$ \\nabla^2 u + k^2 u = 0 $$\nwhere $u$ is the complex-valued acoustic pressure and $k$ is the wave number. The boundary condition is the impedance (or Robin) condition:\n$$ \\frac{\\partial u}{\\partial n} + i \\beta k u = 0 $$\nwhere $\\partial/\\partial n$ is the outward normal derivative, $\\beta$ is the impedance factor, and $i$ is the imaginary unit.\n\nWe discretize this system on a uniform grid with $N$ interior points in each dimension. The grid spacing is $h = 1/(N+1)$. The unknowns are the values of $u$ at the $n = N^2$ interior grid points. We use a second-order central difference scheme for the Laplacian $\\nabla^2$. For an interior point $(i,j)$ far from boundaries, this yields:\n$$ \\frac{u_{i-1,j} + u_{i+1,j} + u_{i,j-1} + u_{i,j+1} - 4u_{i,j}}{h^2} + k^2 u_{i,j} = 0 $$\nThis equation defines the entries of the matrix $A$ for a row corresponding to a point not adjacent to any boundary. The diagonal entry is $k^2 - 4/h^2$, and the off-diagonal entries corresponding to its four neighbors are $1/h^2$.\n\n### 2. Elimination of Boundary Conditions\n\nFor an interior point adjacent to a boundary, one or more of its neighbors lie on the boundary or outside the domain. The problem specifies a method to eliminate these boundary values. The outward normal derivative is approximated by a first-order one-sided difference. For an interior point $u_a$ adjacent to a boundary point $u_b$, this leads to the relation:\n$$ u_b = \\frac{u_a}{1 + i \\beta k h} = \\alpha u_a $$\nwhere $\\alpha = 1 / (1 + i \\beta k h)$.\n\nConsider an interior point $u_{i,j}$ that has a neighbor, say $u_{i-1,j}$, on the boundary. We replace $u_{i-1,j}$ in the central difference formula with $\\alpha u_{i,j}$. The aformentioned discrete equation becomes:\n$$ \\frac{\\alpha u_{i,j} + u_{i+1,j} + u_{i,j-1} + u_{i,j+1} - 4u_{i,j}}{h^2} + k^2 u_{i,j} = 0 $$\nRearranging the terms for $u_{i,j}$, we get:\n$$ \\left( k^2 - \\frac{4}{h^2} + \\frac{\\alpha}{h^2} \\right) u_{i,j} + \\frac{1}{h^2} (u_{i+1,j} + u_{i,j-1} + u_{i,j+1}) = 0 $$\nAs stipulated, the effect of one boundary neighbor is to add a term $\\alpha/h^2$ to the diagonal element of the matrix row. If an interior point has $m$ neighbors on the boundary (e.g., $m=1$ for an edge point, $m=2$ for a corner point), the diagonal entry for that point's row in matrix $A$ will be:\n$$ A_{p,p} = k^2 - \\frac{4}{h^2} + \\frac{m \\alpha}{h^2} $$\nwhere $p$ is the 1D index corresponding to the 2D grid point. The off-diagonal entries corresponding to interior neighbors remain $1/h^2$. The presence of the complex term $\\alpha$ makes the matrix $A$ non-Hermitian.\n\n### 3. Analysis of Matrix Properties\n\nThe constructed matrix $A \\in \\mathbb{C}^{n \\times n}$ is analyzed using three metrics:\n\n1.  **Departure from Normality ($\\delta(A)$)**: A matrix $A$ is normal if it commutes with its conjugate transpose $A^*$, i.e., $A A^* = A^* A$. The departure from normality is quantified by the normalized Frobenius norm of the commutator:\n    $$ \\delta(A) = \\frac{\\lVert A^* A - A A^* \\rVert_F}{\\lVert A \\rVert_F^2} $$\n    where $\\lVert M \\rVert_F = \\sqrt{\\sum_{i,j} |M_{ij}|^2}$ is the Frobenius norm. For a normal matrix, $\\delta(A) = 0$. The complex impedance term is expected to make $A$ non-normal, resulting in $\\delta(A) > 0$.\n\n2.  **Indefiniteness ($f_-$)**: The Helmholtz operator is indefinite, meaning its eigenvalues can have both positive and negative real parts. This property poses a challenge for many iterative solvers. We quantify indefiniteness by the fraction of eigenvalues with a negative real part:\n    $$ f_- = \\frac{|\\{\\lambda_j : \\mathrm{Re}(\\lambda_j) < 0\\}|}{n} $$\n    where $\\lambda_j$ are the eigenvalues of $A$.\n\n3.  **Spectral Radius of Weighted Jacobi Smoother ($\\rho(M)$)**: The weighted Jacobi method is a simple iterative scheme (often used as a smoother in multigrid methods) for solving $A\\mathbf{x}=\\mathbf{b}$. The iteration is given by $\\mathbf{x}^{(k+1)} = (I - \\omega D^{-1} A)\\mathbf{x}^{(k)} + \\omega D^{-1}\\mathbf{b}$, where $D$ is the diagonal of $A$ and $\\omega$ is a relaxation weight. The convergence of this method is determined by the spectral radius of the iteration matrix $M = I - \\omega D^{-1} A$:\n    $$ \\rho(M) = \\max_j |\\lambda_j(M)| $$\n    The iteration converges if and only if $\\rho(M) < 1$. We compute this value for a fixed weight $\\omega = 0.6$ to assess the performance of this basic smoother.\n\n### 4. Computational Procedure\n\nFor each parameter set $(N, k, \\beta)$, the following steps are performed:\n1.  Compute constants: $n=N^2$, $h=1/(N+1)$, and $\\alpha = 1/(1+i\\beta k h)$.\n2.  Assemble the $n \\times n$ complex matrix $A$ by iterating through each of the $N^2$ interior grid points. For each point, determine its neighbors and the number of boundary adjacencies $m$ to construct the corresponding row of $A$.\n3.  Compute the eigenvalues of $A$ using a standard numerical library function.\n4.  Calculate $\\delta(A)$, $f_-$, and $\\rho(M)$ according to their definitions.\n5.  Store the three resulting values, rounded to six decimal places, for final output formatting.\nThis process is repeated for all test cases provided in the problem statement.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test cases.\n    It assembles the discrete Helmholtz operator matrix, then computes\n    its non-normality, indefiniteness, and the spectral radius of the\n    weighted Jacobi iteration matrix.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (N, k, beta)\n        (8, 15.0, 1.0),\n        (8, 6.0, 0.5),\n        (6, 10.0, 2.0),\n        (4, 20.0, 1.0),\n    ]\n\n    results = []\n    for N, k, beta in test_cases:\n        # Step 1: Initialize parameters\n        n = N * N\n        h = 1.0 / (N + 1)\n        k_sq = k * k\n        h_sq = h * h\n        omega = 0.6\n        alpha = 1.0 / (1.0 + 1j * beta * k * h)\n\n        # Step 2: Assemble the matrix A\n        A = np.zeros((n, n), dtype=np.complex128)\n        \n        # Base values for diagonal and off-diagonal elements from FD stencil\n        diag_base = k_sq - 4.0 / h_sq\n        off_diag = 1.0 / h_sq\n\n        # Iterate over each interior grid point (i,j)\n        # i, j are 1-based grid indices from 1 to N\n        for i in range(1, N + 1):\n            for j in range(1, N + 1):\n                # Map 2D grid index (i,j) to 1D matrix index p (0-based)\n                p = (i - 1) * N + (j - 1)\n\n                # Set the base diagonal value\n                A[p, p] = diag_base\n                \n                # m counts the number of \"missing\" neighbors (on the boundary)\n                m = 0\n\n                # Check neighbor (i, j-1) - left\n                if j > 1:\n                    q = p - 1\n                    A[p, q] = off_diag\n                else:\n                    m += 1\n\n                # Check neighbor (i, j+1) - right\n                if j  N:\n                    q = p + 1\n                    A[p, q] = off_diag\n                else:\n                    m += 1\n\n                # Check neighbor (i-1, j) - up\n                if i > 1:\n                    q = p - N\n                    A[p, q] = off_diag\n                else:\n                    m += 1\n\n                # Check neighbor (i+1, j) - down\n                if i  N:\n                    q = p + N\n                    A[p, q] = off_diag\n                else:\n                    m += 1\n                \n                # Add the boundary condition contribution to the diagonal\n                if m > 0:\n                    A[p, p] += m * alpha / h_sq\n\n        # Step 3: Compute the required quantities\n        \n        # Eigenvalues of A\n        eig_A = np.linalg.eigvals(A)\n\n        # Departure from normality, delta(A)\n        A_H = A.conj().T\n        commutator = A_H @ A - A @ A_H\n        norm_commutator_F = np.linalg.norm(commutator, 'fro')\n        norm_A_F_sq = np.linalg.norm(A, 'fro')**2\n        delta_A = 0.0 if norm_A_F_sq == 0 else norm_commutator_F / norm_A_F_sq\n\n        # Indefiniteness fraction, f_minus\n        num_neg_real = np.sum(np.real(eig_A)  0)\n        f_minus = num_neg_real / n\n\n        # Spectral radius of weighted Jacobi iteration matrix, rho(M)\n        D_diag = np.diag(A)\n        # M = I - omega * D_inv * A\n        # To avoid creating full D_inv matrix, use broadcasting with its diagonal\n        M = np.identity(n, dtype=np.complex128) - omega * (A / D_diag[:, np.newaxis])\n        eig_M = np.linalg.eigvals(M)\n        rho_M = np.max(np.abs(eig_M))\n\n        # Step 4: Collect and round the results for the current case\n        case_results = [\n            round(delta_A, 6),\n            round(f_minus, 6),\n            round(rho_M, 6)\n        ]\n        results.append(case_results)\n\n    # Final print statement in the exact required format.\n    # e.g., [[val1,val2,val3],[val4,val5,val6]]\n    list_of_strings = [f\"[{','.join(map(str, res))}]\" for res in results]\n    final_output_str = f\"[{','.join(list_of_strings)}]\"\n    print(final_output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "Having diagnosed the failure of simple smoothers and analyzed the challenging properties of the system matrix, we now turn to constructing a viable solution. This advanced practice introduces a powerful technique for designing a custom smoother using Chebyshev polynomials, which is particularly effective for operators with spectra contained within a known region, such as an annulus . You will implement the logic to determine the optimal polynomial degree and coefficients needed to achieve a target error reduction, showcasing a key building block of robust multigrid solvers for indefinite systems.",
            "id": "4130235",
            "problem": "Consider time-harmonic linear acoustics where the acoustic pressure field satisfies the Helmholtz equation derived from the acoustic wave equation. Starting from the acoustic wave equation $\\partial_t^2 p - c^2 \\Delta p = s$ and assuming time-harmonic fields of the form $p(\\mathbf{x},t) = \\Re\\{u(\\mathbf{x}) e^{-i \\omega t}\\}$, the governing equation reduces to the Helmholtz equation $(-\\Delta - k^2) u = f$, where $k = \\omega/c$ is the wavenumber, $\\Delta$ is the Laplacian, and $f$ is a source term. After discretization on a grid with suitable boundary conditions (e.g., absorbing layers), the resulting linear system for the solution $\\mathbf{u}$ is $A \\mathbf{u} = \\mathbf{f}$, where $A \\in \\mathbb{C}^{N \\times N}$ is indefinite and may be non-normal. In many practical configurations in computational acoustics, the spectrum of $A$ is well-approximated by an annulus in the complex plane, $\\mathcal{A} = \\{\\lambda \\in \\mathbb{C} : r_{\\min} \\le |\\lambda| \\le r_{\\max}\\}$, where $r_{\\min}  0$ and $r_{\\max}  r_{\\min}$.\n\nTo build a robust multigrid smoother for such indefinite systems, one may act on the normal equations $H = A^* A$, which are Hermitian positive semi-definite under the assumption that $A$ is full rank on the relevant subspace. If the spectrum of $A$ lies in the annulus $\\mathcal{A}$, then the spectrum of $H$ lies in the real interval $[\\alpha,\\beta]$ with $\\alpha = r_{\\min}^2$ and $\\beta = r_{\\max}^2$. A polynomial smoother can then be designed as $p_n(H)$, where $p_n$ is a polynomial of degree $n$ chosen to reduce error components associated with eigenvalues $\\mu \\in [\\alpha,\\beta]$.\n\nYour task is to construct a complex-valued Chebyshev polynomial smoother $p_n(H)$ that provides a guaranteed attenuation over the spectral interval $\\mu \\in [\\alpha,\\beta]$. Specifically, you must:\n\n1. Start from the well-tested properties of the Chebyshev polynomials of the first kind $T_n(x)$, which minimize the maximum deviation on the interval $[-1,1]$, and from the spectral mapping of $H$ to a real interval $[\\alpha,\\beta]$ arising from the annular spectral model of $A$. Using only these fundamental bases, derive a polynomial $p_n(\\mu)$ in the scalar variable $\\mu$ such that $\\max_{\\mu \\in [\\alpha,\\beta]} |p_n(\\mu)|$ is minimized subject to the normalization $p_n(0) = 1$. Express $p_n(\\mu)$ explicitly as a polynomial in powers of $\\mu$, i.e., $p_n(\\mu) = \\sum_{j=0}^{n} c_j \\mu^j$, and make clear the normalization needed to enforce $p_n(0) = 1$.\n\n2. Based on the minimax property of Chebyshev polynomials and a suitable affine mapping that transports the spectral interval $\\mu \\in [\\alpha,\\beta]$ to $x \\in [-1,1]$, derive an explicit criterion on the minimal degree $n$ that guarantees a target attenuation factor $\\delta \\in (0,1)$, namely $\\max_{\\mu \\in [\\alpha,\\beta]} |p_n(\\mu)| \\le \\delta$. Your derivation must be grounded in first principles and well-tested facts about $T_n(x)$ for arguments $x  1$.\n\n3. Implement a complete, runnable program that:\n   - For each test case below, computes the minimal polynomial degree $n$ that guarantees the target attenuation $\\delta$.\n   - Constructs the normalized polynomial coefficients $\\{c_j\\}_{j=0}^n$ for $p_n(\\mu)$ in powers of $\\mu$.\n   - Returns the results for all test cases as a single line, formatted exactly as a comma-separated list enclosed in square brackets, where each test caseâ€™s result is of the form $[n,[c_0,c_1,\\dots,c_n]]$.\n\nYou must implement the polynomial construction using expansion in powers of $\\mu$ and the affine mapping from $\\mu$ to the Chebyshev argument, and you must enforce $p_n(0) = 1$ via appropriate normalization.\n\nTest Suite:\n- Case 1 (happy path): $r_{\\min} = 10.0$, $r_{\\max} = 40.0$, $\\delta = 0.1$.\n- Case 2 (thin annulus): $r_{\\min} = 20.0$, $r_{\\max} = 21.0$, $\\delta = 10^{-3}$.\n- Case 3 (wide annulus): $r_{\\min} = 5.0$, $r_{\\max} = 100.0$, $\\delta = 0.2$.\n- Case 4 (near the origin but excluding zero): $r_{\\min} = 0.5$, $r_{\\max} = 2.0$, $\\delta = 10^{-2}$.\n- Case 5 (strict attenuation): $r_{\\min} = 15.0$, $r_{\\max} = 25.0$, $\\delta = 10^{-4}$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to one test case and is of the form $[n,[c_0,c_1,\\dots,c_n]]$. For example:\n$[[n_1,[c_{0,1},\\dots,c_{n_1,1}]],[n_2,[c_{0,2},\\dots,c_{n_2,2}]],\\dots]$.\nAll numbers must be represented in standard decimal notation. No physical units or angles are required in this problem, and all numerical outputs must be real numbers without percentage signs.",
            "solution": "The problem requires the design of a polynomial smoother for indefinite linear systems arising from the discretization of the time-harmonic acoustic wave equation. The smoother is based on Chebyshev polynomials and is optimized for systems where the spectrum of the matrix $A$ lies in an annulus in the complex plane, $\\mathcal{A} = \\{\\lambda \\in \\mathbb{C} : r_{\\min} \\le |\\lambda| \\le r_{\\max}\\}$. The smoother acts on the normal equations matrix $H = A^* A$, whose spectrum is contained in the real interval $[\\alpha, \\beta]$ where $\\alpha = r_{\\min}^2$ and $\\beta = r_{\\max}^2$.\n\nOur task is to derive and implement a polynomial $p_n(\\mu)$ of degree $n$ that satisfies the normalization condition $p_n(0) = 1$ and minimizes the maximum absolute value on the spectral interval $[\\alpha, \\beta]$. This is a classic minimax approximation problem. The solution is based on the properties of Chebyshev polynomials of the first kind, $T_n(x)$.\n\n### Part 1: Derivation of the Optimal Polynomial\n\nThe objective is to find a polynomial $p_n(\\mu)$ of degree $n$ that minimizes $\\max_{\\mu \\in [\\alpha, \\beta]} |p_n(\\mu)|$ subject to the constraint $p_n(0) = 1$.\n\nThe Chebyshev polynomials $T_n(x)$ are known to be the unique solution to a related minimax problem: of all monic polynomials of degree $n$, $2^{1-n} T_n(x)$ has the minimal maximum absolute value on the interval $[-1, 1]$. A more general property is that for any point $x_0$ outside $[-1, 1]$, the polynomial $q_n(x) = T_n(x) / T_n(x_0)$ minimizes $\\max_{x \\in [-1, 1]} |q_n(x)|$ among all polynomials $q_n$ of degree $n$ satisfying $q_n(x_0) = 1$.\n\nTo leverage this property, we first apply an affine transformation that maps the spectral interval $[\\alpha, \\beta]$ to the canonical Chebyshev interval $[-1, 1]$:\n$$x(\\mu) = m\\mu + b$$\nWe require $x(\\alpha) = -1$ and $x(\\beta) = 1$. Solving the system of linear equations:\n$$\n\\begin{cases}\n-1 = m\\alpha + b \\\\\n1 = m\\beta + b\n\\end{cases}\n$$\nyields the mapping parameters:\n$$m = \\frac{2}{\\beta - \\alpha} \\quad \\text{and} \\quad b = -\\frac{\\beta + \\alpha}{\\beta - \\alpha}$$\nThe normalization constraint is imposed at $\\mu = 0$. We map this point to the $x$ coordinate:\n$$x_0 = x(0) = b = -\\frac{\\beta + \\alpha}{\\beta - \\alpha}$$\nSince the problem states $r_{\\min}  0$, we have $\\alpha = r_{\\min}^2  0$. Consequently, $\\beta  \\alpha  0$, which implies $\\beta + \\alpha  \\beta - \\alpha  0$. Thus, $x_0  -1$, so the normalization point lies outside the interval $[-1, 1]$.\n\nThe optimal polynomial in the transformed coordinate is $q_n(x) = T_n(x) / T_n(x_0)$. In terms of the original variable $\\mu$, the solution is:\n$$p_n(\\mu) = \\frac{T_n(x(\\mu))}{T_n(x_0)} = \\frac{T_n\\left(\\frac{2\\mu - (\\alpha + \\beta)}{\\beta - \\alpha}\\right)}{T_n\\left(-\\frac{\\beta + \\alpha}{\\beta - \\alpha}\\right)}$$\nThis polynomial satisfies $p_n(0) = T_n(x(0))/T_n(x_0) = 1$. The constant term of the polynomial $p_n(\\mu) = \\sum_{j=0}^n c_j \\mu^j$ is therefore $c_0 = 1$.\n\n### Part 2: Minimal Degree for Target Attenuation\n\nWe need to find the minimal degree $n$ that guarantees an attenuation factor of $\\delta \\in (0, 1)$. This means we require:\n$$\\max_{\\mu \\in [\\alpha, \\beta]} |p_n(\\mu)| \\le \\delta$$\nFor $\\mu \\in [\\alpha, \\beta]$, the variable $x(\\mu)$ is in $[-1, 1]$. In this interval, the maximum absolute value of $T_n(x)$ is $1$. Therefore, the maximum of $|p_n(\\mu)|$ on $[\\alpha, \\beta]$ is:\n$$\\max_{\\mu \\in [\\alpha, \\beta]} |p_n(\\mu)| = \\frac{\\max_{x \\in [-1, 1]} |T_n(x)|}{|T_n(x_0)|} = \\frac{1}{|T_n(x_0)|}$$\nThe condition becomes $1 / |T_n(x_0)| \\le \\delta$, or $|T_n(x_0)| \\ge 1/\\delta$.\n\nLet $\\kappa = -x_0 = \\frac{\\beta + \\alpha}{\\beta - \\alpha}$. Since $\\kappa  1$, we use the identity $T_n(x) = \\cosh(n \\operatorname{arccosh}(x))$ for $x  1$. Also, $T_n(-x) = (-1)^n T_n(x)$, so $|T_n(x_0)| = |T_n(-\\kappa)| = T_n(\\kappa)$. The inequality is:\n$$T_n(\\kappa) \\ge 1/\\delta$$\nSubstituting the identity for $T_n(\\kappa)$:\n$$\\cosh(n \\operatorname{arccosh}(\\kappa)) \\ge 1/\\delta$$\nSince $\\operatorname{arccosh}(y)$ is an increasing function for $y \\ge 1$, we can apply it to both sides (noting $1/\\delta  1$):\n$$n \\operatorname{arccosh}(\\kappa) \\ge \\operatorname{arccosh}(1/\\delta)$$\nThis yields the criterion for the degree $n$:\n$$n \\ge \\frac{\\operatorname{arccosh}(1/\\delta)}{\\operatorname{arccosh}(\\kappa)}$$\nAs the degree must be an integer, the minimal degree required is:\n$$n = \\left\\lceil \\frac{\\operatorname{arccosh}(1/\\delta)}{\\operatorname{arccosh}(\\kappa)} \\right\\rceil \\quad \\text{where} \\quad \\kappa = \\frac{r_{\\max}^2 + r_{\\min}^2}{r_{\\max}^2 - r_{\\min}^2}$$\n\n### Part 3: Polynomial Coefficient Construction\n\nTo find the coefficients $\\{c_j\\}$ of $p_n(\\mu) = \\sum_{j=0}^{n} c_j \\mu^j$, we first construct the coefficients of the unnormalized polynomial $P_n(\\mu) = T_n(m\\mu + b)$ where $m = \\frac{2}{\\beta-\\alpha}$ and $b = -\\kappa$. We use the three-term recurrence relation for Chebyshev polynomials:\n$$T_{k+1}(x) = 2x T_k(x) - T_{k-1}(x), \\quad \\text{with } T_0(x)=1, T_1(x)=x$$\nSubstituting $x = m\\mu+b$, we obtain a recurrence for the polynomials $P_k(\\mu) = T_k(m\\mu+b)$:\n$$P_{k+1}(\\mu) = 2(m\\mu+b)P_k(\\mu) - P_{k-1}(\\mu)$$\nThis relation translates to a recurrence for the polynomial coefficients. Let $P_k(\\mu) = \\sum_{j=0}^{k} d_j^{(k)} \\mu^j$. The coefficients $\\{d_j^{(k+1)}\\}$ of $P_{k+1}(\\mu)$ can be computed from the coefficients of $P_k(\\mu)$ and $P_{k-1}(\\mu)$. Specifically, we start with the coefficient vectors for $P_0(\\mu) = 1$ (coeffs: $[1]$) and $P_1(\\mu) = m\\mu+b$ (coeffs: $[b, m]$) and iteratively compute the coefficient vectors up to $P_n(\\mu)$.\n\nThe final coefficients $\\{c_j\\}$ are obtained by normalizing the coefficients of $P_n(\\mu)$ by the value of the normalization constant $C_n = T_n(b)$:\n$$c_j = \\frac{d_j^{(n)}}{T_n(b)}$$\nThe constant $T_n(b)$ is computed efficiently using the scalar version of the recurrence: $T_{k+1}(b) = 2b T_k(b) - T_{k-1}(b)$. Since $d_0^{(n)} = P_n(0) = T_n(b)$, the constant term of the final polynomial is $c_0 = d_0^{(n)}/T_n(b) = 1$, as required by the normalization condition.\nThe implementation will follow this procedure algorithmically.",
            "answer": "```python\nimport numpy as np\n\ndef format_num(x):\n    \"\"\"Formats a number into a standard decimal string, trimming trailing zeros.\"\"\"\n    if x == 0.0:\n        return '0.0'\n    s = \"{:.16f}\".format(x)\n    s = s.rstrip('0')\n    if s.endswith('.'):\n        s = s[:-1]\n    if s == '-0':\n        s = '0'\n    return s\n\ndef compute_chebyshev_smoother(r_min, r_max, delta):\n    \"\"\"\n    Computes the minimal degree and coefficients of the Chebyshev polynomial smoother.\n\n    Args:\n        r_min (float): The minimum radius of the spectral annulus.\n        r_max (float): The maximum radius of the spectral annulus.\n        delta (float): The target attenuation factor.\n\n    Returns:\n        tuple: A tuple containing:\n            - n (int): The minimal polynomial degree.\n            - coeffs (list): The list of polynomial coefficients [c_0, c_1, ..., c_n].\n    \"\"\"\n    alpha = r_min**2\n    beta = r_max**2\n\n    # Handle the case where the annulus is degenerate\n    if np.isclose(alpha, beta):\n        # A degree 0 polynomial p_0(mu) = 1 is sufficient.\n        # It has value 1 everywhere, attenuation is not possible unless delta >= 1.\n        # Assuming delta  1 implies this case won't be a primary concern,\n        # but for robustness, return degree 0.\n        return 0, [1.0]\n\n    # Calculate kappa for the mapped interval\n    kappa = (beta + alpha) / (beta - alpha)\n\n    # Calculate the minimal degree n\n    # n >= arccosh(1/delta) / arccosh(kappa)\n    # Use the identity arccosh(x) = log(x + sqrt(x^2 - 1))\n    n_float = np.arccosh(1.0 / delta) / np.arccosh(kappa)\n    n = int(np.ceil(n_float))\n\n    if n == 0:\n        return 0, [1.0]\n\n    # Parameters for the affine map x(mu) = m*mu + b\n    m = 2.0 / (beta - alpha)\n    b = -kappa\n\n    # Calculate the normalization constant C_n = T_n(b) using the recurrence\n    T_km1 = 1.0  # T_0(b)\n    T_k = b      # T_1(b)\n    for _ in range(1, n):\n        T_kp1 = 2.0 * b * T_k - T_km1\n        T_km1 = T_k\n        T_k = T_kp1\n    C_n = T_k\n\n    # Compute coefficients of the unnormalized polynomial P_n(mu) = T_n(m*mu + b)\n    # using a recurrence on the coefficient vectors.\n    P_km1_coeffs = np.array([1.0])                   # Coeffs for P_0\n    if n == 1:\n        P_n_coeffs = np.array([b, m])\n    else:\n        P_k_coeffs = np.array([b, m])                # Coeffs for P_1\n        for k in range(1, n):\n            # Recurrence: P_{k+1} = 2*(m*mu+b)*P_k - P_{k-1}\n            # Term 1: 2*b*P_k\n            term1 = 2.0 * b * P_k_coeffs\n            # Term 2: 2*m*mu*P_k (multiplication by mu is a right shift of coeffs)\n            term2 = 2.0 * m * P_k_coeffs\n\n            # Combine terms to get P_{k+1}\n            P_kp1_coeffs = np.zeros(k + 2)\n            P_kp1_coeffs[:k + 1] += term1\n            P_kp1_coeffs[1:] += term2\n            P_kp1_coeffs[:k] -= P_km1_coeffs\n\n            P_km1_coeffs = P_k_coeffs\n            P_k_coeffs = P_kp1_coeffs\n        P_n_coeffs = P_k_coeffs\n\n    # Normalize coefficients to get the final polynomial p_n(mu)\n    coeffs = P_n_coeffs / C_n\n\n    return n, coeffs.tolist()\n\ndef solve():\n    \"\"\"\n    Main function to process test cases and print results.\n    \"\"\"\n    test_cases = [\n        (10.0, 40.0, 0.1),\n        (20.0, 21.0, 1e-3),\n        (5.0, 100.0, 0.2),\n        (0.5, 2.0, 1e-2),\n        (15.0, 25.0, 1e-4),\n    ]\n\n    results = []\n    for r_min, r_max, delta in test_cases:\n        n, coeffs = compute_chebyshev_smoother(r_min, r_max, delta)\n        \n        # Format the coefficients to strings\n        coeffs_str = '[' + ','.join(map(format_num, coeffs)) + ']'\n        \n        # Format the result for this case\n        case_result_str = f\"[{n},{coeffs_str}]\"\n        results.append(case_result_str)\n\n    # Final print statement must be a single line with the exact format\n    final_output = '[' + ','.join(results) + ']'\n    print(final_output)\n\nsolve()\n```"
        }
    ]
}