{
    "hands_on_practices": [
        {
            "introduction": "在我们为声学模型构建可靠的代理模型之前，我们必须首先理解那些用于生成训练数据的数值求解器的局限性。本练习将引导你对数值色散进行基础分析，这是一种在离散化介质中不同频率的波以错误速度传播的现象。通过推导一种常见的有限差分格式的相速度误差，你将具体理解数值误差是如何产生的，以及它们如何依赖于仿真参数。",
            "id": "4128308",
            "problem": "考虑质点位移 $u(x,t)$ 的一维（$1$-D）线性声波方程，\n$$\n\\frac{\\partial^{2} u}{\\partial t^{2}} = c^{2} \\frac{\\partial^{2} u}{\\partial x^{2}},\n$$\n其中 $c$ 是恒定声速。在一个间距为 $h$ 的均匀空间网格和一个均匀时间步长 $\\Delta t$ 上，使用空间和时间上的中心二阶有限差分对该方程在网格点 $x_{j} = j h$ 和时间层 $t^{n} = n \\Delta t$ 上进行离散化，更新格式如下\n$$\n\\frac{u_{j}^{n+1} - 2 u_{j}^{n} + u_{j}^{n-1}}{\\Delta t^{2}} = c^{2} \\frac{u_{j+1}^{n} - 2 u_{j}^{n} + u_{j-1}^{n}}{h^{2}}.\n$$\n假设一个形式为 $u_{j}^{n} = A \\exp\\!\\big( \\mathrm{i} (k j h - \\omega n \\Delta t) \\big)$ 的平面波解，其中 $A$ 是复振幅，$k$ 是连续波数，$\\omega$ 是角频率。从该离散格式和平面波拟设出发，推导连接 $\\omega$ 和 $k$ 的数值色散关系。然后定义数值相速度 $c_{p}^{\\text{num}}(k) = \\omega / k$ 和相对相速度误差\n$$\n\\varepsilon(k h; r) = \\frac{c_{p}^{\\text{num}}(k)}{c} - 1,\n$$\n其中库朗数 $r = c \\Delta t / h$，无量纲波数 $\\xi = k h$。假设角频率取主支，使得 $0 \\le \\omega \\Delta t \\le \\pi$ 且 $0 \\le \\xi \\le \\pi$。将最终答案表示为关于 $k h$ 和 $r$ 的 $\\varepsilon(k h; r)$ 的单个闭式解析表达式。无需进行数值计算，最终答案中不报告单位。",
            "solution": "用户想要为一维波动方程的有限差分离散格式推导相对相速度误差。\n\n### 问题验证\n\n**第一步：提取已知条件**\n\n- **控制方程：** 质点位移 $u(x,t)$ 的一维（$1$-D）线性声波方程为\n$$\n\\frac{\\partial^{2} u}{\\partial t^{2}} = c^{2} \\frac{\\partial^{2} u}{\\partial x^{2}}\n$$\n其中 $c$ 是恒定声速。\n- **离散格式：** 使用中心二阶有限差分格式：\n$$\n\\frac{u_{j}^{n+1} - 2 u_{j}^{n} + u_{j}^{n-1}}{\\Delta t^{2}} = c^{2} \\frac{u_{j+1}^{n} - 2 u_{j}^{n} + u_{j-1}^{n}}{h^{2}}\n$$\n其中 $x_j = j h$, $t^n = n \\Delta t$, $h$ 是空间网格间距，$\\Delta t$ 是时间步长。\n- **平面波拟设：** 假设解的形式为：\n$$\nu_{j}^{n} = A \\exp\\!\\big( \\mathrm{i} (k j h - \\omega n \\Delta t) \\big)\n$$\n其中 $A$ 是复振幅，$k$ 是连续波数，$\\omega$ 是角频率。\n- **定义：**\n    - 数值相速度：$c_{p}^{\\text{num}}(k) = \\omega / k$。\n    - 相对相速度误差：$\\varepsilon(k h; r) = \\frac{c_{p}^{\\text{num}}(k)}{c} - 1$。\n    - 库朗数：$r = c \\Delta t / h$。\n    - 无量纲波数：$\\xi = k h$。\n- **约束条件：**\n    - 角频率的主支：$0 \\le \\omega \\Delta t \\le \\pi$。\n    - 无量纲波数范围：$0 \\le k h \\le \\pi$。\n\n**第二步：使用提取的已知条件进行验证**\n\n- **科学基础：** 该问题坚实地植根于计算声学和偏微分方程数值分析领域。一维波动方程、其有限差分离散化，以及用于推导数值色散关系的冯·诺依曼分析（使用平面波拟设）都是标准的、成熟的方法。\n- **适定性：** 该问题提供了推导相对相速度误差的唯一解析表达式所需的所有方程、定义和约束。目标陈述清晰。\n- **客观性：** 该问题以精确、客观的数学语言表述，没有任何主观性或模糊性。\n- **完整性与一致性：** 该问题是自洽的。最终表达式所需的所有变量（$r$, $kh$）都已定义。对 $\\omega \\Delta t$ 和 $kh$ 的约束是一致的，用于选择解的主支，确保答案唯一。\n- **其他缺陷：** 该问题未违反任何无效性标准。它是一个标准的、可形式化的、非平凡的数值方法学术练习。\n\n**第三步：结论与行动**\n\n问题有效。将提供完整解答。\n\n### 解的推导\n\n目标是找到相对相速度误差 $\\varepsilon(k h; r)$ 的表达式。这需要首先推导数值色散关系，该关系将数值频率 $\\omega$ 与波数 $k$ 联系起来。\n\n我们首先将平面波拟设 $u_{j}^{n} = A \\exp(\\mathrm{i}(k j h - \\omega n \\Delta t))$ 代入离散化的波动方程。为此，我们将 $u_{j}^{n+1}$、$u_{j}^{n-1}$、$u_{j+1}^{n}$ 和 $u_{j-1}^{n}$各项用 $u_{j}^{n}$ 表示：\n$$\nu_{j}^{n+1} = A \\exp(\\mathrm{i}(k j h - \\omega (n+1) \\Delta t)) = A \\exp(\\mathrm{i}(k j h - \\omega n \\Delta t)) \\exp(-\\mathrm{i} \\omega \\Delta t) = u_{j}^{n} \\exp(-\\mathrm{i} \\omega \\Delta t)\n$$\n$$\nu_{j}^{n-1} = A \\exp(\\mathrm{i}(k j h - \\omega (n-1) \\Delta t)) = u_{j}^{n} \\exp(\\mathrm{i} \\omega \\Delta t)\n$$\n$$\nu_{j+1}^{n} = A \\exp(\\mathrm{i}(k (j+1) h - \\omega n \\Delta t)) = u_{j}^{n} \\exp(\\mathrm{i} k h)\n$$\n$$\nu_{j-1}^{n} = A \\exp(\\mathrm{i}(k (j-1) h - \\omega n \\Delta t)) = u_{j}^{n} \\exp(-\\mathrm{i} k h)\n$$\n\n将这些表达式代入有限差分方程得到：\n$$\n\\frac{u_{j}^{n} \\exp(-\\mathrm{i} \\omega \\Delta t) - 2 u_{j}^{n} + u_{j}^{n} \\exp(\\mathrm{i} \\omega \\Delta t)}{\\Delta t^{2}} = c^{2} \\frac{u_{j}^{n} \\exp(\\mathrm{i} k h) - 2 u_{j}^{n} + u_{j}^{n} \\exp(-\\mathrm{i} k h)}{h^{2}}\n$$\n假设存在非平凡解（$A \\neq 0$，因此 $u_{j}^{n} \\neq 0$），我们可以将整个方程除以 $u_{j}^{n}$：\n$$\n\\frac{\\exp(-\\mathrm{i} \\omega \\Delta t) - 2 + \\exp(\\mathrm{i} \\omega \\Delta t)}{\\Delta t^{2}} = c^{2} \\frac{\\exp(\\mathrm{i} k h) - 2 + \\exp(-\\mathrm{i} k h)}{h^{2}}\n$$\n使用欧拉公式 $\\exp(\\mathrm{i}\\theta) + \\exp(-\\mathrm{i}\\theta) = 2 \\cos(\\theta)$，我们可以简化方程两边：\n$$\n\\frac{2 \\cos(\\omega \\Delta t) - 2}{\\Delta t^{2}} = c^{2} \\frac{2 \\cos(k h) - 2}{h^{2}}\n$$\n接下来，我们应用半角三角恒等式 $\\cos(\\theta) - 1 = -2 \\sin^{2}(\\theta/2)$：\n$$\n\\frac{-4 \\sin^{2}(\\omega \\Delta t / 2)}{\\Delta t^{2}} = c^{2} \\frac{-4 \\sin^{2}(k h / 2)}{h^{2}}\n$$\n两边同除以 $-4$ 进行简化：\n$$\n\\frac{\\sin^{2}(\\omega \\Delta t / 2)}{\\Delta t^{2}} = c^{2} \\frac{\\sin^{2}(k h / 2)}{h^{2}}\n$$\n整理各项得到：\n$$\n\\sin^{2}\\left(\\frac{\\omega \\Delta t}{2}\\right) = \\left(\\frac{c \\Delta t}{h}\\right)^{2} \\sin^{2}\\left(\\frac{k h}{2}\\right)\n$$\n根据定义，库朗数 $r = c \\Delta t / h$。将其代入方程：\n$$\n\\sin^{2}\\left(\\frac{\\omega \\Delta t}{2}\\right) = r^{2} \\sin^{2}\\left(\\frac{k h}{2}\\right)\n$$\n我们对两边取平方根。根据问题约束，$0 \\le \\omega \\Delta t \\le \\pi$ 且 $0 \\le k h \\le \\pi$。这意味着 $0 \\le \\omega \\Delta t / 2 \\le \\pi/2$ 且 $0 \\le k h / 2 \\le \\pi/2$。在区间 $[0, \\pi/2]$ 内，正弦函数是非负的。因此，我们可以无歧义地取正平方根：\n$$\n\\sin\\left(\\frac{\\omega \\Delta t}{2}\\right) = r \\sin\\left(\\frac{k h}{2}\\right)\n$$\n该方程是隐式形式的数值色散关系。为了求出 $\\omega$，我们对其求解：\n$$\n\\frac{\\omega \\Delta t}{2} = \\arcsin\\left(r \\sin\\left(\\frac{k h}{2}\\right)\\right)\n$$\n$$\n\\omega = \\frac{2}{\\Delta t} \\arcsin\\left(r \\sin\\left(\\frac{k h}{2}\\right)\\right)\n$$\n现在，我们可以求出数值相速度 $c_{p}^{\\text{num}} = \\omega / k$：\n$$\nc_{p}^{\\text{num}}(k) = \\frac{1}{k} \\left[ \\frac{2}{\\Delta t} \\arcsin\\left(r \\sin\\left(\\frac{k h}{2}\\right)\\right) \\right] = \\frac{2}{k \\Delta t} \\arcsin\\left(r \\sin\\left(\\frac{k h}{2}\\right)\\right)\n$$\n最后一步是计算相对相速度误差 $\\varepsilon(k h; r) = c_{p}^{\\text{num}}(k)/c - 1$：\n$$\n\\varepsilon(k h; r) = \\frac{1}{c} \\left[ \\frac{2}{k \\Delta t} \\arcsin\\left(r \\sin\\left(\\frac{k h}{2}\\right)\\right) \\right] - 1\n$$\n为了用 $r$ 和 $kh$ 表示，我们使用库朗数的定义 $r = c \\Delta t / h$，可以重排为 $c = r h / \\Delta t$。用此式代换 $c$：\n$$\n\\varepsilon(k h; r) = \\frac{\\Delta t}{r h} \\left[ \\frac{2}{k \\Delta t} \\arcsin\\left(r \\sin\\left(\\frac{k h}{2}\\right)\\right) \\right] - 1\n$$\n$\\Delta t$ 项消去：\n$$\n\\varepsilon(k h; r) = \\frac{2}{r k h} \\arcsin\\left(r \\sin\\left(\\frac{k h}{2}\\right)\\right) - 1\n$$\n这就是相对相速度误差关于无量纲波数 $kh$ 和库朗数 $r$ 的最终闭式表达式。",
            "answer": "$$\n\\boxed{\\frac{2}{r k h} \\arcsin\\left(r \\sin\\left(\\frac{k h}{2}\\right)\\right) - 1}\n$$"
        },
        {
            "introduction": "基于我们对数值误差的理解，本实践将解决一个关键问题：我们如何高效地生成高质量的训练数据？本练习模拟了一个真实场景，你必须通过智能地结合廉价的低保真度仿真和昂贵的高保真度仿真，来减轻高频数值污染的影响。通过这个编码任务，你将实现并评估一种数据策展策略，这是开发兼具成本效益和准确性的代理模型的一项至关重要的技能。",
            "id": "4128285",
            "problem": "您的任务是构建并评估一个机器学习代理模型，该模型用于预测由亥姆霍兹方程控制的一维腔体的声学可观测量，同时通过选择性地应用高阶和网格加密有限元（hp-FEM）来减轻训练数据中的高频数值污染。域为区间 $[0,L]$，声压场 $p(x)$ 满足齐次狄利克雷边界条件，时谐源产生稳态亥姆霍兹模型。问题的基础是一维时谐声学的亥姆霍兹方程：$$\\frac{d^2 p}{dx^2} + k^2 p = f(x),$$ 边界条件为 $$p(0) = 0,\\quad p(L) = 0,$$ 其中 $k$ 是以 $\\mathrm{rad/m}$ 为单位的声波数，$L$ 是以 $\\mathrm{m}$ 为单位的腔体长度，$f(x)$ 是源分布。假设一个单位振幅的模态源 $$f(x) = \\sin\\left(\\frac{\\pi x}{L}\\right),$$ 并考虑定义为域中点 $x_0 = L/2$ 处压力振幅的可观测量，该值可以从系统的精确模态响应中获得。在这些假设下，并且与狄利克雷问题的模态展开的线性性和正交性一致，该可观测量是精确的传递函数值 $$A_{\\mathrm{true}}(k,L) = \\frac{\\sin\\left(\\frac{\\pi x_0}{L}\\right)}{k^2 - \\left(\\frac{\\pi}{L}\\right)^2},$$ 在 $x_0 = L/2$ 处求值，注意到 $\\sin\\left(\\frac{\\pi}{2}\\right)=1$。\n\n您必须构建一个合成标签生成器，该生成器代表在均匀网格上使用低阶有限元法（FEM）获得的数值解，这些解会遭受高频色散误差，从而污染训练数据。使用经过充分检验的特性，即亥姆霍兹方程的有限元法中的色散误差随无量纲参数 $k h$（其中 $h$ 是单元尺寸）的增加而增长，并随有限元基函数的多项式阶数 $p$ 的增加而减少。具体来说，令粗略求解器标签为 $$A_{\\mathrm{coarse}}(k,L) = A_{\\mathrm{true}}(k,L) + \\Delta_{\\mathrm{coarse}}(k,h,p),$$ 其中 $$h = \\frac{L}{N_e},$$ $N_e$ 是单元数量，$\\Delta_{\\mathrm{coarse}}$ 是由确定性函数定义的色散引起的偏差 $$\\Delta_{\\mathrm{coarse}}(k,h,p) = \\gamma_{\\mathrm{c}} \\frac{(k h)^{2p+1}}{1 + (k h)^{2p+1}},$$ 这是 $k h$ 的一个光滑增函数，与渐近增长率 $O\\!\\left((k h)^{2p+1}\\right)$ 一致。为减轻这种污染，对于选定比例的训练样本，用更高保真度的 hp-FEM 标签替换粗略标签：$$A_{\\mathrm{hp}}(k,L) = A_{\\mathrm{true}}(k,L) + \\Delta_{\\mathrm{hp}}(k,h_{\\mathrm{hp}},p_{\\mathrm{hp}}),$$ 其中 $$h_{\\mathrm{hp}} = \\frac{L}{N_e^{\\mathrm{hp}}},\\quad \\Delta_{\\mathrm{hp}}(k,h_{\\mathrm{hp}},p_{\\mathrm{hp}}) = \\gamma_{\\mathrm{hp}} \\frac{(k h_{\\mathrm{hp}})^{2p_{\\mathrm{hp}}+1}}{1 + (k h_{\\mathrm{hp}})^{2p_{\\mathrm{hp}}+1}},$$ 且 $p_{\\mathrm{hp}} > p$，$N_e^{\\mathrm{hp}} > N_e$，以及 $\\gamma_{\\mathrm{hp}} \\ll \\gamma_{\\mathrm{c}}$。\n\n您必须创建一个训练数据集，其中包含输入参数对 $(k,L)$ 和根据下述选择策略生成的标签。然后，拟合一个使用高斯核的核岭回归代理模型，以将 $(k,L)$ 映射到该可观测量。通过计算相对于 $A_{\\mathrm{true}}(k,L)$ 的平均绝对误差（MAE），在一个未见过的测试集上评估其泛化性能。\n\n实施以下要求：\n- 使用 $N_{\\mathrm{train}} = 200$ 个训练样本，其中 $k$ 在 $[5,150]$（单位 $\\mathrm{rad/m}$）内均匀采样，$L$ 在 $[0.8,1.2]$（单位 $\\mathrm{m}$）内均匀采样。\n- 使用 $N_{\\mathrm{test}} = 200$ 个独立采样的测试样本，采样方式同上。\n- 对于粗略求解器，使用 $N_e = 20$，$p = 1$ 和 $\\gamma_{\\mathrm{c}} = 0.08$。\n- 对于 hp-FEM 求解器，使用 $N_e^{\\mathrm{hp}} = 80$，$p_{\\mathrm{hp}} = 4$ 和 $\\gamma_{\\mathrm{hp}} = 0.005$。\n- 拟合使用高斯核 $$K(\\mathbf{x},\\mathbf{z}) = \\exp\\left(-\\frac{\\|\\mathbf{x}-\\mathbf{z}\\|^2}{2\\sigma^2}\\right)$$ 的核岭回归，正则化参数为 $\\lambda$，核宽度为 $\\sigma$，其中 $\\mathbf{x} = [k,L]$。使用 $\\sigma = 25$ 和 $\\lambda = 10^{-6}$。对于训练和测试，使用训练集的统计数据将每个特征 $k$ 和 $L$ 标准化为零均值和单位方差。\n- hp-FEM 标签的选择策略：给定一个精化比例 $r \\in [0,1]$，根据以下两种策略之一选择 $\\lfloor r N_{\\mathrm{train}}\\rfloor$ 个训练样本：\n    - \"high-k\"：选择具有最大 $k$ 值的样本。\n    - \"random\"：均匀随机选择样本。为保证可复现性，使用种子为 $123$ 的伪随机数生成器。\n- 对于所有未被选中的样本，使用粗略求解器标签 $A_{\\mathrm{coarse}}(k,L)$；对于选中的样本，使用 hp-FEM 标签 $A_{\\mathrm{hp}}(k,L)$。\n- 计算平均绝对误差 $$\\mathrm{MAE} = \\frac{1}{N_{\\mathrm{test}}} \\sum_{i=1}^{N_{\\mathrm{test}}} \\left| \\widehat{A}(k_i,L_i) - A_{\\mathrm{true}}(k_i,L_i) \\right|,$$ 其中 $\\widehat{A}$ 是代理模型的预测值。\n\n设计一个包含五种参数情况的测试套件，以量化对代理模型泛化能力的影响：\n1. 情况 1：$r = 0.0$，策略 \"none\"（即不使用 hp-FEM；所有标签均为粗略解）。\n2. 情况 2：$r = 0.1$，策略 \"high-k\"。\n3. 情况 3：$r = 0.5$，策略 \"high-k\"。\n4. 情况 4：$r = 0.1$，策略 \"random\"。\n5. 情况 5：$r = 1.0$，策略 \"high-k\"（即所有标签均使用 hp-FEM）。\n\n您的程序必须生成单行输出，其中包含一个方括号内的逗号分隔列表，按情况 1 到 5 的顺序排列结果，每个条目是对应情况的 MAE，表示为浮点数。最终输出是无量纲的，并且必须不带单位打印。例如，格式必须完全像 $[x_1,x_2,x_3,x_4,x_5]$，其中 $x_i$ 是情况 $i=1,\\dots,5$ 计算出的 MAE 值。",
            "solution": "该问题要求构建并评估一个机器学习代理模型，该模型用于一个源自一维亥姆霍兹方程的声学可观测量。任务的核心是研究如何通过选择性地提高训练数据质量（这一过程称为数据筛选）来影响代理模型的泛化性能。具体来说，我们将使用一个在混合保真度数据集上训练的核岭回归（KRR）模型，其中一些标签由低阶数值求解器生成，另一些由高阶求解器生成，并根据精确的解析解来评估其准确性。\n\n物理系统是一个长度为 $L$ 的一维声学腔体，由声压场 $p(x)$ 的稳态亥姆霍兹方程控制：\n$$\n\\frac{d^2 p}{dx^2} + k^2 p = f(x)\n$$\n其中 $k$ 是声波数，$f(x)$ 是时谐源分布。域为 $x \\in [0, L]$，具有齐次狄利克雷边界条件 $p(0) = 0$ 和 $p(L) = 0$。源被指定为对应于腔体第一本征模的单位振幅模态源，$f(x) = \\sin\\left(\\frac{\\pi x}{L}\\right)$。\n\n对于这种特定的源和边界条件，该问题有精确的解析解。压力场的解为 $p(x) = \\frac{\\sin(\\pi x/L)}{k^2 - (\\pi/L)^2}$，只要波数 $k$ 不与共振波数 $k_1 = \\pi/L$ 重合，该解就有效。我们感兴趣的可观测量是域中点 $x_0 = L/2$ 处的压力振幅。这个可观量的精确值，作为我们的真实值，是：\n$$\nA_{\\mathrm{true}}(k,L) = \\frac{\\sin\\left(\\frac{\\pi (L/2)}{L}\\right)}{k^2 - \\left(\\frac{\\pi}{L}\\right)^2} = \\frac{1}{k^2 - \\left(\\frac{\\pi}{L}\\right)^2}\n$$\n\n代理模型的训练数据是综合生成的，以模拟有限元法（FEM）求解器的数值解。亥姆霍兹方程的有限元法的一个关键方面是数值污染或色散误差现象，这种现象在较高波数（高频）下变得更加严重。已知此误差的大小取决于无量纲参数 $kh$（波数乘以单元尺寸）和基函数的多项式阶数 $p$。我们用两个合成求解器来模拟这种行为。\n\n“粗略”求解器产生带有显著误差的标签：\n$$\nA_{\\mathrm{coarse}}(k,L) = A_{\\mathrm{true}}(k,L) + \\Delta_{\\mathrm{coarse}}(k,h,p)\n$$\n其中色散引起的偏差 $\\Delta_{\\mathrm{coarse}}$ 被建模为 $k$、单元尺寸 $h = L/N_e$ 和多项式阶数 $p$ 的函数。我们使用具体形式：\n$$\n\\Delta_{\\mathrm{coarse}}(k,h,p) = \\gamma_{\\mathrm{c}} \\frac{(k h)^{2p+1}}{1 + (k h)^{2p+1}}\n$$\n参数为 $N_e = 20$，$p = 1$ 和 $\\gamma_{\\mathrm{c}} = 0.08$。\n\n“高保真度”或 hp-FEM 求解器产生更准确的标签，误差项要小得多：\n$$\nA_{\\mathrm{hp}}(k,L) = A_{\\mathrm{true}}(k,L) + \\Delta_{\\mathrm{hp}}(k,h_{\\mathrm{hp}},p_{\\mathrm{hp}})\n$$\n其中偏差 $\\Delta_{\\mathrm{hp}}$ 由以下公式给出：\n$$\n\\Delta_{\\mathrm{hp}}(k,h_{\\mathrm{hp}},p_{\\mathrm{hp}}) = \\gamma_{\\mathrm{hp}} \\frac{(k h_{\\mathrm{hp}})^{2p_{\\mathrm{hp}}+1}}{1 + (k h_{\\mathrm{hp}})^{2p_{\\mathrm{hp}}+1}}\n$$\n该求解器使用加密的网格（$h_{\\mathrm{hp}} = L/N_e^{\\mathrm{hp}}$）和更高阶的多项式，参数为 $N_e^{\\mathrm{hp}} = 80$，$p_{\\mathrm{hp}} = 4$ 和 $\\gamma_{\\mathrm{hp}} = 0.005$。\n\n代理模型是一个核岭回归（KRR）模型，它将输入特征 $\\mathbf{x} = [k, L]$ 映射到声学可观测量。在训练之前，输入特征会根据训练集的统计数据进行标准化，使其均值为零，方差为一。这对于基于距离的核方法至关重要。对于新输入 $\\mathbf{x}_*$ 的 KRR 预测由下式给出：\n$$\n\\widehat{A}(\\mathbf{x}_*) = \\sum_{i=1}^{N_{\\mathrm{train}}} \\alpha_i K(\\mathbf{x}_*, \\mathbf{x}_i) = \\mathbf{k}_*^T \\boldsymbol{\\alpha}\n$$\n其中 $\\mathbf{x}_i$ 是 $N_{\\mathrm{train}}=200$ 个训练特征向量，$K(\\cdot, \\cdot)$ 是核函数，$\\mathbf{k}_*$ 是一个元素为 $K(\\mathbf{x}_*, \\mathbf{x}_i)$ 的向量。权重向量 $\\boldsymbol{\\alpha}$ 通过求解正则化的线性系统来确定：\n$$\n(\\mathbf{K} + \\lambda I) \\boldsymbol{\\alpha} = \\mathbf{y}_{\\mathrm{train}}\n$$\n这里，$\\mathbf{K}$ 是 $N_{\\mathrm{train}} \\times N_{\\mathrm{train}}$ 的格拉姆矩阵 (Gram matrix)，其中 $K_{ij} = K(\\mathbf{x}_i, \\mathbf{x}_j)$，$\\lambda = 10^{-6}$ 是正则化参数，$I$ 是单位矩阵，$\\mathbf{y}_{\\mathrm{train}}$ 是训练标签的向量。我们使用高斯核：\n$$\nK(\\mathbf{x}, \\mathbf{z}) = \\exp\\left(-\\frac{\\|\\mathbf{x}-\\mathbf{z}\\|^2}{2\\sigma^2}\\right)\n$$\n核宽度为 $\\sigma = 25$。\n\n训练标签 $\\mathbf{y}_{\\mathrm{train}}$ 是使用混合保真度方法生成的。给定一个精化比例 $r \\in [0,1]$，从训练集中总共选择 $\\lfloor r N_{\\mathrm{train}}\\rfloor$ 个样本，使其标签由高保真度求解器 $A_{\\mathrm{hp}}$ 计算。剩余的样本由粗略求解器 $A_{\\mathrm{coarse}}$ 标记。研究了两种选择样本进行精化的策略：\n1.  **\"high-k\"**：选择波数 $k$ 值最大的样本，预计粗略求解器的误差在这些样本上最大。\n2.  **\"random\"**：均匀随机选择样本，使用固定的种子以保证可复现性。\n\n训练后的代理模型的泛化性能在一个包含 $N_{\\mathrm{test}}=200$ 个样本的独立测试集上进行评估。性能通过代理模型预测值 $\\widehat{A}$ 与精确解析解 $A_{\\mathrm{true}}$ 的真实值之间的平均绝对误差（MAE）来量化：\n$$\n\\mathrm{MAE} = \\frac{1}{N_{\\mathrm{test}}} \\sum_{i=1}^{N_{\\mathrm{test}}} \\left| \\widehat{A}(k_i,L_i) - A_{\\mathrm{true}}(k_i,L_i) \\right|\n$$\n\n该过程将针对五个不同的情况执行，以分析数据筛选策略对代理模型准确性的影响：\n1.  情况 1：$r = 0.0$（所有标签均为粗略解）。这建立了一个基线性能。\n2.  情况 2：$r = 0.1$，采用 \"high-k\" 策略。这测试了目标性精化。\n3.  情况 3：$r = 0.5$，采用 \"high-k\" 策略。这测试了更广泛的目标性精化。\n4.  情况 4：$r = 0.1$，采用 \"random\" 策略。这比较了随机精化与目标性精化。\n5.  情况 5：$r = 1.0$（所有标签均为 hp-FEM 解）。这确立了使用高质量数据所能达到的性能上限。",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import solve as sp_solve\n\ndef solve():\n    \"\"\"\n    Constructs and evaluates a machine learning surrogate for an acoustic observable,\n    investigating the impact of training data curation on model performance.\n    \"\"\"\n    # --- Problem Constants ---\n    N_TRAIN = 200\n    N_TEST = 200\n    K_RANGE = (5, 150)\n    L_RANGE = (0.8, 1.2)\n    \n    # Coarse solver parameters\n    NE_COARSE = 20\n    P_COARSE = 1\n    GAMMA_C = 0.08\n    \n    # hp-FEM solver parameters\n    NE_HP = 80\n    P_HP = 4\n    GAMMA_HP = 0.005\n    \n    # KRR hyperparameters\n    SIGMA = 25.0\n    LAMBDA = 1e-6\n    \n    # Random seeds for reproducibility\n    DATA_GENERATION_SEED = 42\n    RANDOM_SELECTION_SEED = 123\n\n    # --- Test Cases ---\n    test_cases = [\n        (0.0, \"none\"),    # Case 1\n        (0.1, \"high-k\"),  # Case 2\n        (0.5, \"high-k\"),  # Case 3\n        (0.1, \"random\"),  # Case 4\n        (1.0, \"high-k\")   # Case 5\n    ]\n\n    # --- Helper Functions ---\n\n    def A_true(k, L):\n        \"\"\"Computes the exact analytical observable.\"\"\"\n        return 1.0 / (k**2 - (np.pi / L)**2)\n\n    def delta_error(k, L, Ne, p, gamma):\n        \"\"\"Computes the phenomenological dispersion error term.\"\"\"\n        h = L / Ne\n        kh = k * h\n        kh_pow = kh**(2 * p + 1)\n        return gamma * (kh_pow / (1.0 + kh_pow))\n\n    def A_coarse(k, L):\n        \"\"\"Computes the coarse solver labels.\"\"\"\n        error = delta_error(k, L, NE_COARSE, P_COARSE, GAMMA_C)\n        return A_true(k, L) + error\n\n    def A_hp(k, L):\n        \"\"\"Computes the high-fidelity hp-FEM solver labels.\"\"\"\n        error = delta_error(k, L, NE_HP, P_HP, GAMMA_HP)\n        return A_true(k, L) + error\n\n    def get_sq_dist_matrix(X, Z):\n        \"\"\"Computes the matrix of squared Euclidean distances between two sets of vectors.\"\"\"\n        X_sq = np.sum(X**2, axis=1, keepdims=True)\n        Z_sq = np.sum(Z**2, axis=1, keepdims=True)\n        return X_sq + Z_sq.T - 2 * (X @ Z.T)\n\n    def gaussian_kernel(X, Z, sigma):\n        \"\"\"Computes the Gaussian kernel matrix.\"\"\"\n        sq_dists = get_sq_dist_matrix(X, Z)\n        return np.exp(-sq_dists / (2 * sigma**2))\n\n    def train_krr(X_train, y_train, sigma, lam):\n        \"\"\"Trains the Kernel Ridge Regression model.\"\"\"\n        K = gaussian_kernel(X_train, X_train, sigma)\n        alpha = sp_solve(K + lam * np.eye(len(K)), y_train, assume_a='pos')\n        return alpha\n\n    def predict_krr(X_test, X_train, alpha, sigma):\n        \"\"\"Makes predictions with a trained KRR model.\"\"\"\n        K_test = gaussian_kernel(X_test, X_train, sigma)\n        return K_test @ alpha\n\n    # --- Main Logic ---\n\n    # 1. Generate Training and Test Data\n    data_rng = np.random.default_rng(seed=DATA_GENERATION_SEED)\n    k_train = data_rng.uniform(K_RANGE[0], K_RANGE[1], N_TRAIN)\n    L_train = data_rng.uniform(L_RANGE[0], L_RANGE[1], N_TRAIN)\n    X_train = np.vstack((k_train, L_train)).T\n\n    k_test = data_rng.uniform(K_RANGE[0], K_RANGE[1], N_TEST)\n    L_test = data_rng.uniform(L_RANGE[0], L_RANGE[1], N_TEST)\n    X_test = np.vstack((k_test, L_test)).T\n\n    # 2. Compute Ground Truth for Test Set\n    y_true_test = A_true(k_test, L_test)\n\n    # 3. Standardize Features\n    mean_train = X_train.mean(axis=0)\n    std_train = X_train.std(axis=0)\n    X_train_std = (X_train - mean_train) / std_train\n    X_test_std = (X_test - mean_train) / std_train\n    \n    # 4. Pre-compute solver labels for the entire training set\n    y_coarse_train = A_coarse(k_train, L_train)\n    y_hp_train = A_hp(k_train, L_train)\n\n    results = []\n    for r, strategy in test_cases:\n        # 5. Generate Mixed-Fidelity Training Labels for the current case\n        y_train = y_coarse_train.copy()\n        \n        num_refined = int(np.floor(r * N_TRAIN))\n        \n        if num_refined > 0:\n            if strategy == \"high-k\":\n                indices_to_refine = np.argsort(k_train)[-num_refined:]\n            elif strategy == \"random\":\n                selection_rng = np.random.default_rng(seed=RANDOM_SELECTION_SEED)\n                indices_to_refine = selection_rng.choice(N_TRAIN, size=num_refined, replace=False)\n            \n            y_train[indices_to_refine] = y_hp_train[indices_to_refine]\n        \n        # 6. Train KRR Model\n        alpha = train_krr(X_train_std, y_train, SIGMA, LAMBDA)\n        \n        # 7. Make Predictions on Test Set\n        y_pred = predict_krr(X_test_std, X_train_std, alpha, SIGMA)\n        \n        # 8. Calculate and store MAE\n        mae = np.mean(np.abs(y_pred - y_true_test))\n        results.append(mae)\n\n    # 9. Print Final Output\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "有了精心策展的数据集后，最后一步是训练代理模型，这需要一个精心选择的损失函数。在声学中，我们经常预测复数值，如声压，其振幅和相位都具有物理意义。这个动手实践问题要求你实现一个基于物理动机的自定义损失函数，该函数能恰当地平衡振幅和相位的误差，从而训练出更准确、更有意义的声学代理模型。",
            "id": "4128310",
            "problem": "您正在训练一个机器学习代理模型，用于预测在固定角频率下的频域复声压，该声压被建模为一个复相量。设某一空间位置的真实复声压表示为 $p \\in \\mathbb{C}$，其笛卡尔分量为 $p = x + \\mathrm{i} y$，幅值为 $A = \\sqrt{x^2 + y^2}$（单位：帕斯卡，Pa），相位为 $\\phi = \\mathrm{atan2}(y, x)$（单位：弧度）。设代理模型的预测值为 $\\hat{p} = \\hat{x} + \\mathrm{i} \\hat{y}$，其幅值为 $\\hat{A}$，相位为 $\\hat{\\phi}$。您需要一个用于训练的损失函数，该函数能以一种具有物理意义的方式平衡幅值和相位误差，并且单位为平方帕斯卡。该代理模型在 $N$ 个样本上进行训练，样本索引为 $k \\in \\{1,\\dots,N\\}$。\n\n从第一性原理出发，将幅值和相位视为实部和虚部的函数，并回想一下，在复平面中，一个大小为 $\\Delta \\phi$ 的小相位误差，在幅值为 $A$ 时，会产生一个大小约为 $A \\Delta \\phi$ 的正交扰动。基于此，构建一个标量单样本损失，该损失是加权幅值差异平方与由幅值平方缩放的加权相位差异平方之和：\n$$\n\\ell(p, \\hat{p}; w_A, w_\\phi) \\equiv w_A \\left(\\hat{A} - A\\right)^2 + w_\\phi \\, A^2 \\, \\Delta \\phi^2,\n$$\n其中 $w_A > 0$ 和 $w_\\phi > 0$ 是用户指定的权重，$\\Delta \\phi$ 是包裹在主值区间 $(-\\pi, \\pi]$（单位：弧度）内的相位差。数据集平均损失为\n$$\n\\mathcal{L} \\equiv \\frac{1}{N} \\sum_{k=1}^{N} \\ell\\!\\left(p_k, \\hat{p}_k; w_A, w_\\phi\\right).\n$$\n此 $\\mathcal{L}$ 必须以平方帕斯卡（Pa$^2$）为单位报告，且角度以弧度计算。\n\n使用变量替换 $(x, y) \\mapsto (A, \\phi)$，其中 $A = \\sqrt{x^2 + y^2}$ 且 $\\phi = \\mathrm{atan2}(y, x)$，在 $p$ 点的雅可比矩阵为\n$$\nJ(p) \\equiv\n\\begin{bmatrix}\n\\frac{\\partial A}{\\partial x}  \\frac{\\partial A}{\\partial y} \\\\\nA \\frac{\\partial \\phi}{\\partial x}  A \\frac{\\partial \\phi}{\\partial y}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\frac{x}{A}  \\frac{y}{A} \\\\\n-\\frac{y}{A}  \\frac{x}{A}\n\\end{bmatrix},\n$$\n对于 $A > 0$。对于小误差 $\\Delta x = \\hat{x} - x$ 和 $\\Delta y = \\hat{y} - y$，线性化可得 $[\\Delta A, \\; A \\Delta \\phi]^\\top \\approx J(p) [\\Delta x, \\; \\Delta y]^\\top$。因此，损失 $\\ell$ 的二次近似可以写成关于实部和虚部的加权形式，\n$$\n\\ell(p, \\hat{p}; w_A, w_\\phi) \\approx\n\\begin{bmatrix} \\Delta x  \\Delta y \\end{bmatrix}\n\\left(J(p)^\\top \\, \\mathrm{diag}(w_A, w_\\phi) \\, J(p)\\right)\n\\begin{bmatrix} \\Delta x \\\\ \\Delta y \\end{bmatrix},\n$$\n这定义了对实部和虚部残差的一种感知幅值和相位的加权。然而，当 $A=0$ 时，相位未定义，相位项不应产生贡献；在这种情况下，精确损失简化为 $w_A \\hat{A}^2$。\n\n您的任务是实现精确的幅值-相位平衡损失 $\\mathcal{L}$，其中使用以弧度为单位的包裹相位差，并以 Pa$^2$ 为单位报告损失。您还应通过上述精确表达式稳健地处理 $A = 0$ 的边界情况，而不依赖于雅可比矩阵。\n\n实现一个程序，针对下面的测试套件，计算每种情况下的标量损失 $\\mathcal{L}$，并将结果打印在单一行上，形式为用方括号括起来的逗号分隔列表。\n\n角度单位要求：所有角度必须以弧度为单位。物理单位要求：最终损失必须以平方帕斯卡（Pa$^2$）报告。数值输出：打印浮点值。\n\n测试套件：\n- 情况1（仅幅值误差）：$N = 1$，$p_1 = 1 + \\mathrm{i}\\,0$ Pa, $\\hat{p}_1 = 1.1 + \\mathrm{i}\\,0$ Pa, $w_A = 1$, $w_\\phi = 1$。\n- 情况2（仅相位误差，小角度）：$N = 1$，$p_1 = 1 + \\mathrm{i}\\,0$ Pa, $\\hat{p}_1 = \\exp(\\mathrm{i}\\,0.1)$ Pa, $w_A = 1$, $w_\\phi = 1$。\n- 情况3（近零幅值，未定义相位）：$N = 1$，$p_1 = 0 + \\mathrm{i}\\,0$ Pa, $\\hat{p}_1 = 0.001 + \\mathrm{i}\\,0$ Pa, $w_A = 2$, $w_\\phi = 3$。\n- 情况4（混合幅值和相位误差）：$N = 1$，$p_1 = 2 \\exp(\\mathrm{i}\\,\\pi/4)$ Pa, $\\hat{p}_1 = 1.8 \\exp(\\mathrm{i}\\,(\\pi/4 + 0.2))$ Pa, $w_A = 0.5$, $w_\\phi = 2$。\n- 情况5（批量平均）：$N = 2$，$p_1 = 1 \\exp(\\mathrm{i}\\,0)$ Pa, $\\hat{p}_1 = 1.05 \\exp(\\mathrm{i}\\,0)$ Pa; $p_2 = 3 \\exp(\\mathrm{i}\\,\\pi/3)$ Pa, $\\hat{p}_2 = 3 \\exp(\\mathrm{i}\\,(\\pi/3 + 0.2))$ Pa; $w_A = 1.5$, $w_\\phi = 0.5$。\n\n最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，“[result1,result2,result3]”）。每个结果对应相应情况的标量损失 $\\mathcal{L}$，顺序与测试套件中的顺序相同。",
            "solution": "用户已提供有效的问题陈述。任务是为一系列涉及复声压预测的测试用例计算一个幅值-相位平衡损失函数。\n\n问题将真实复声压定义为 $p = x + \\mathrm{i} y$，代理模型的预测值定义为 $\\hat{p} = \\hat{x} + \\mathrm{i} \\hat{y}$。在极坐标下，它们分别由幅值和相位对 $(A, \\phi)$ 和 $(\\hat{A}, \\hat{\\phi})$ 表示，其中 $A = |p|$，$\\phi = \\mathrm{arg}(p)$，$\\hat{A} = |\\hat{p}|$，且 $\\hat{\\phi} = \\mathrm{arg}(\\hat{p})$。所有角度均以弧度为单位。\n\n单样本损失函数 $\\ell$ 由下式给出：\n$$ \\ell(p, \\hat{p}; w_A, w_\\phi) = w_A (\\hat{A} - A)^2 + w_\\phi A^2 (\\Delta \\phi)^2 $$\n其中 $w_A > 0$ 和 $w_\\phi > 0$ 是无量纲权重。项 $\\Delta \\phi$ 表示相位差 $\\hat{\\phi} - \\phi$，并被包裹到主值区间 $(-\\pi, \\pi]$ 内。问题指明，对于 $A=0$（此时相位 $\\phi$ 未定义）的情况，损失简化为 $\\ell = w_A \\hat{A}^2$。所提供的公式与此要求一致，因为当 $A=0$ 时，无论 $\\Delta \\phi$ 的值如何，项 $w_\\phi A^2 (\\Delta \\phi)^2$ 都会变为零。\n\n在 $N$ 个样本上的数据集平均损失 $\\mathcal{L}$ 为：\n$$ \\mathcal{L} = \\frac{1}{N} \\sum_{k=1}^{N} \\ell(p_k, \\hat{p}_k; w_A, w_\\phi) $$\n最终结果 $\\mathcal{L}$ 的单位必须是平方帕斯卡（Pa$^2$）。\n\n我们现在将为所提供的每个测试用例计算 $\\mathcal{L}$。计算过程包括将给定的复声压转换为其极坐标分量（幅值和相位），计算包裹后的相位差，并应用损失公式。\n\n**情况1：** 仅幅值误差。\n- 已知条件：$N=1$，$p_1 = 1 + \\mathrm{i}\\,0$ Pa, $\\hat{p}_1 = 1.1 + \\mathrm{i}\\,0$ Pa, $w_A = 1$, $w_\\phi = 1$。\n- 真实值：$A_1 = |1 + \\mathrm{i}\\,0| = 1$ Pa, $\\phi_1 = \\mathrm{arg}(1 + \\mathrm{i}\\,0) = 0$ rad。\n- 预测值：$\\hat{A}_1 = |1.1 + \\mathrm{i}\\,0| = 1.1$ Pa, $\\hat{\\phi}_1 = \\mathrm{arg}(1.1 + \\mathrm{i}\\,0) = 0$ rad。\n- 差异：$\\hat{A}_1 - A_1 = 1.1 - 1 = 0.1$ Pa. $\\Delta\\phi_1 = \\hat{\\phi}_1 - \\phi_1 = 0 - 0 = 0$ rad。\n- 单样本损失：$\\ell_1 = w_A (\\hat{A}_1 - A_1)^2 + w_\\phi A_1^2 (\\Delta\\phi_1)^2 = 1 \\cdot (0.1)^2 + 1 \\cdot (1)^2 \\cdot (0)^2 = 0.01$ Pa$^2$。\n- 平均损失：$\\mathcal{L} = \\ell_1 / 1 = 0.01$ Pa$^2$。\n\n**情况2：** 仅相位误差。\n- 已知条件：$N=1$，$p_1 = 1 + \\mathrm{i}\\,0$ Pa, $\\hat{p}_1 = \\exp(\\mathrm{i}\\,0.1)$ Pa, $w_A = 1$, $w_\\phi = 1$。\n- 真实值：$A_1 = 1$ Pa, $\\phi_1 = 0$ rad。\n- 预测值：$\\hat{A}_1 = |\\exp(\\mathrm{i}\\,0.1)| = 1$ Pa, $\\hat{\\phi}_1 = \\mathrm{arg}(\\exp(\\mathrm{i}\\,0.1)) = 0.1$ rad。\n- 差异：$\\hat{A}_1 - A_1 = 1 - 1 = 0$ Pa. $\\Delta\\phi_1 = 0.1 - 0 = 0.1$ rad。该值在 $(-\\pi, \\pi]$ 区间内。\n- 单样本损失：$\\ell_1 = w_A (\\hat{A}_1 - A_1)^2 + w_\\phi A_1^2 (\\Delta\\phi_1)^2 = 1 \\cdot (0)^2 + 1 \\cdot (1)^2 \\cdot (0.1)^2 = 0.01$ Pa$^2$。\n- 平均损失：$\\mathcal{L} = \\ell_1 / 1 = 0.01$ Pa$^2$。\n\n**情况3：** 近零幅值。\n- 已知条件：$N=1$，$p_1 = 0 + \\mathrm{i}\\,0$ Pa, $\\hat{p}_1 = 0.001 + \\mathrm{i}\\,0$ Pa, $w_A = 2$, $w_\\phi = 3$。\n- 真实值：$A_1 = |0 + \\mathrm{i}\\,0| = 0$ Pa。相位 $\\phi_1$ 未定义。\n- 预测值：$\\hat{A}_1 = |0.001| = 0.001$ Pa。\n- 单样本损失：由于第二项变为零，公式简化。$\\ell_1 = w_A (\\hat{A}_1 - A_1)^2 + w_\\phi A_1^2 (\\Delta\\phi_1)^2 = 2 \\cdot (0.001 - 0)^2 + 3 \\cdot (0)^2 \\cdot (\\Delta\\phi_1)^2 = 2 \\cdot (0.001)^2 = 2 \\times 10^{-6}$ Pa$^2$。\n- 平均损失：$\\mathcal{L} = \\ell_1 / 1 = 2 \\times 10^{-6}$ Pa$^2$。\n\n**情况4：** 混合幅值和相位误差。\n- 已知条件：$N=1$，$p_1 = 2 \\exp(\\mathrm{i}\\,\\pi/4)$ Pa, $\\hat{p}_1 = 1.8 \\exp(\\mathrm{i}\\,(\\pi/4 + 0.2))$ Pa, $w_A = 0.5$, $w_\\phi = 2$。\n- 真实值：$A_1 = 2$ Pa, $\\phi_1 = \\pi/4$ rad。\n- 预测值：$\\hat{A}_1 = 1.8$ Pa, $\\hat{\\phi}_1 = \\pi/4 + 0.2$ rad。\n- 差异：$\\hat{A}_1 - A_1 = 1.8 - 2 = -0.2$ Pa. $\\Delta\\phi_1 = (\\pi/4 + 0.2) - (\\pi/4) = 0.2$ rad。该值在 $(-\\pi, \\pi]$ 区间内。\n- 单样本损失：$\\ell_1 = w_A (\\hat{A}_1 - A_1)^2 + w_\\phi A_1^2 (\\Delta\\phi_1)^2 = 0.5 \\cdot (-0.2)^2 + 2 \\cdot (2)^2 \\cdot (0.2)^2 = 0.5 \\cdot 0.04 + 2 \\cdot 4 \\cdot 0.04 = 0.02 + 0.32 = 0.34$ Pa$^2$。\n- 平均损失：$\\mathcal{L} = \\ell_1 / 1 = 0.34$ Pa$^2$。\n\n**情况5：** 批量平均。\n- 已知条件：$N=2$, $w_A = 1.5$, $w_\\phi = 0.5$。\n- 样本1：$p_1 = 1 \\exp(\\mathrm{i}\\,0)$ Pa, $\\hat{p}_1 = 1.05 \\exp(\\mathrm{i}\\,0)$ Pa。\n    - $A_1 = 1$ Pa, $\\phi_1 = 0$ rad。\n    - $\\hat{A}_1 = 1.05$ Pa, $\\hat{\\phi}_1 = 0$ rad。\n    - $\\Delta A_1 = 0.05$ Pa, $\\Delta \\phi_1 = 0$ rad。\n    - $\\ell_1 = 1.5 \\cdot (0.05)^2 + 0.5 \\cdot (1)^2 \\cdot (0)^2 = 1.5 \\cdot 0.0025 = 0.00375$ Pa$^2$。\n- 样本2：$p_2 = 3 \\exp(\\mathrm{i}\\,\\pi/3)$ Pa, $\\hat{p}_2 = 3 \\exp(\\mathrm{i}\\,(\\pi/3 + 0.2))$ Pa。\n    - $A_2 = 3$ Pa, $\\phi_2 = \\pi/3$ rad。\n    - $\\hat{A}_2 = 3$ Pa, $\\hat{\\phi}_2 = \\pi/3 + 0.2$ rad。\n    - $\\Delta A_2 = 0$ Pa, $\\Delta \\phi_2 = 0.2$ rad。\n    - $\\ell_2 = 1.5 \\cdot (0)^2 + 0.5 \\cdot (3)^2 \\cdot (0.2)^2 = 0.5 \\cdot 9 \\cdot 0.04 = 0.18$ Pa$^2$。\n- 平均损失：$\\mathcal{L} = \\frac{1}{2}(\\ell_1 + \\ell_2) = \\frac{1}{2}(0.00375 + 0.18) = \\frac{0.18375}{2} = 0.091875$ Pa$^2$。\n\n实现将遵循以上对各情况的计算过程。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the amplitude-phase balanced loss for a suite of test cases.\n    \"\"\"\n\n    test_cases = [\n        # Case 1: amplitude error only\n        {\n            \"samples\": [(1.0 + 0.0j, 1.1 + 0.0j)],\n            \"w_A\": 1.0,\n            \"w_phi\": 1.0,\n        },\n        # Case 2: phase error only, small angle\n        {\n            \"samples\": [(1.0 + 0.0j, np.exp(0.1j))],\n            \"w_A\": 1.0,\n            \"w_phi\": 1.0,\n        },\n        # Case 3: near-zero amplitude, undefined phase\n        {\n            \"samples\": [(0.0 + 0.0j, 0.001 + 0.0j)],\n            \"w_A\": 2.0,\n            \"w_phi\": 3.0,\n        },\n        # Case 4: mixed amplitude and phase\n        {\n            \"samples\": [(2 * np.exp(1j * np.pi / 4), 1.8 * np.exp(1j * (np.pi / 4 + 0.2)))],\n            \"w_A\": 0.5,\n            \"w_phi\": 2.0,\n        },\n        # Case 5: batch averaging\n        {\n            \"samples\": [\n                (1.0 * np.exp(1j * 0), 1.05 * np.exp(1j * 0)),\n                (3.0 * np.exp(1j * np.pi / 3), 3.0 * np.exp(1j * (np.pi / 3 + 0.2)))\n            ],\n            \"w_A\": 1.5,\n            \"w_phi\": 0.5,\n        },\n    ]\n\n    def compute_loss(samples, w_A, w_phi):\n        \"\"\"\n        Calculates the average loss L for a given batch of samples.\n        \"\"\"\n        N = len(samples)\n        if N == 0:\n            return 0.0\n        \n        total_sample_loss = 0.0\n        \n        for p_true, p_hat in samples:\n            # Calculate amplitude and phase for true and predicted values\n            A_true = np.abs(p_true)\n            phi_true = np.angle(p_true)\n            \n            A_hat = np.abs(p_hat)\n            phi_hat = np.angle(p_hat)\n            \n            # Calculate amplitude difference\n            amp_diff = A_hat - A_true\n            \n            # Calculate raw phase difference\n            phase_diff_raw = phi_hat - phi_true\n            \n            # Wrap phase difference to the interval (-pi, pi]\n            phase_diff_wrapped = np.arctan2(np.sin(phase_diff_raw), np.cos(phase_diff_raw))\n            \n            # Calculate per-sample loss l(p, p_hat)\n            # The A_true**2 term naturally handles the case where A_true is 0.\n            sample_loss = w_A * (amp_diff**2) + w_phi * (A_true**2) * (phase_diff_wrapped**2)\n            \n            total_sample_loss += sample_loss\n            \n        # Return the dataset-averaged loss L\n        return total_sample_loss / N\n\n    results = []\n    for case in test_cases:\n        loss = compute_loss(case[\"samples\"], case[\"w_A\"], case[\"w_phi\"])\n        results.append(loss)\n\n    # Format the final output string as specified\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}