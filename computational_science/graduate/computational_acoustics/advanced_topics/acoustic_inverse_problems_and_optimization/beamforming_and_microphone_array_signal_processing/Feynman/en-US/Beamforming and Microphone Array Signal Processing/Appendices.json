{
    "hands_on_practices": [
        {
            "introduction": "Before designing any signal processing algorithm, a firm grasp of the array's physical limitations is essential. This first practice explores the fundamental concept of spatial aliasing in a Uniform Linear Array (ULA), which manifests as undesired sensitivity in directions other than the intended look direction. By deriving the conditions under which these artifacts, known as grating lobes, appear in the visible region, you will gain crucial insight into how array geometry and signal frequency dictate the unambiguous field of view of your sensor system .",
            "id": "4117593",
            "problem": "A Uniform Linear Array (ULA) of $N \\ge 2$ omnidirectional microphones is placed along the $x$-axis with fixed inter-element spacing $d  0$. Assume far-field plane-wave propagation in a homogeneous medium with sound speed $c  0$. The beamformer uses phase-shift steering to a look direction specified by an angle $\\theta_{0}$ relative to broadside, and all angles are measured in radians. Let $f$ denote the acoustic frequency and $\\lambda = c / f$ the wavelength.\n\nUsing only first principles of plane-wave propagation and the definition of phase alignment across array elements, derive the angle-dependent aliasing condition for a steered ULA and determine the minimal positive frequency at which the first grating lobe enters the visible region. The visible region is defined by physically realizable arrival angles satisfying $|\\sin \\theta| \\le 1$. Your derivation must explicitly capture how increasing $f$ (equivalently decreasing $\\lambda$) brings grating lobes into the visible region in a way that depends on $\\theta_{0}$.\n\nProvide a single closed-form analytic expression for the transition frequency $f_{\\mathrm{gl}}(\\theta_{0})$ as a function of $d$, $c$, and $\\theta_{0}$, corresponding to the smallest $f  0$ for which any grating lobe is visible. Do not compute any numerical values. The final answer must be a single analytic expression with no units inside the final box. Angles are in radians.",
            "solution": "The problem requires the derivation of the angle-dependent aliasing condition for a Uniform Linear Array (ULA) and the subsequent determination of the minimal positive frequency at which a grating lobe becomes visible.\n\nWe begin by establishing the signal model based on first principles. Consider a ULA with $N$ microphones located along the $x$-axis. The position of the $n$-th microphone, indexed from $n=0$ to $N-1$, is given by the vector $\\vec{p}_n = (nd, 0, 0)$, where $d$ is the inter-element spacing. A planar acoustic wave with frequency $f$ and speed $c$ propagates from the far-field, arriving from an angle $\\theta$ measured with respect to the array's broadside (the $y$-axis).\n\nThe path length difference for the wave arriving at microphone $n$ relative to the reference microphone at $n=0$ (the origin) is $\\Delta L_n = nd \\sin\\theta$. This corresponds to a time delay of arrival:\n$$\n\\tau_n(\\theta) = \\frac{\\Delta L_n}{c} = \\frac{nd \\sin\\theta}{c}\n$$\nIn the frequency domain, this time delay manifests as a phase shift. For a monochromatic wave with angular frequency $\\omega = 2\\pi f$, the signal at microphone $n$ is related to the signal at the reference microphone $S_0(\\omega)$ by:\n$$\nS_n(\\omega, \\theta) = S_0(\\omega) \\exp(-\\mathrm{j}\\omega\\tau_n(\\theta)) = S_0(\\omega) \\exp\\left(-\\mathrm{j} 2\\pi f \\frac{nd \\sin\\theta}{c}\\right)\n$$\nUsing the relationship $\\lambda = c/f$, where $\\lambda$ is the wavelength, the phase term can be written as:\n$$\nS_n(\\omega, \\theta) = S_0(\\omega) \\exp\\left(-\\mathrm{j} 2\\pi n \\frac{d}{\\lambda} \\sin\\theta\\right)\n$$\nThe beamformer steers the array to a look direction $\\theta_0$ by applying a set of complex weights, $w_n$, to each microphone signal. For phase-shift steering, these weights are designed to precisely cancel the phase delays for a wave arriving from $\\theta_0$, causing signals from that direction to add coherently. The weight for the $n$-th microphone is:\n$$\nw_n(\\theta_0) = \\exp(+\\mathrm{j}\\omega\\tau_n(\\theta_0)) = \\exp\\left(+\\mathrm{j} 2\\pi n \\frac{d}{\\lambda} \\sin\\theta_0\\right)\n$$\nThe output of the beamformer, $Y(\\omega, \\theta, \\theta_0)$, is the weighted sum of the signals from all microphones for an incoming wave from direction $\\theta$:\n$$\nY(\\omega, \\theta, \\theta_0) = \\sum_{n=0}^{N-1} w_n(\\theta_0) S_n(\\omega, \\theta) = S_0(\\omega) \\sum_{n=0}^{N-1} \\exp\\left(\\mathrm{j} 2\\pi n \\frac{d}{\\lambda} \\sin\\theta_0\\right) \\exp\\left(-\\mathrm{j} 2\\pi n \\frac{d}{\\lambda} \\sin\\theta\\right)\n$$\nCombining the exponential terms, we get:\n$$\nY(\\omega, \\theta, \\theta_0) = S_0(\\omega) \\sum_{n=0}^{N-1} \\exp\\left(\\mathrm{j} 2\\pi n \\frac{d}{\\lambda} (\\sin\\theta_0 - \\sin\\theta)\\right)\n$$\nThe sum term is known as the Array Factor, $AF(\\theta, \\theta_0)$. The magnitude of the beamformer's response is maximized when all terms in the summation are in phase, i.e., equal to $1$. This occurs when the argument of the exponential is an integer multiple of $2\\pi$. Let $\\theta_g$ be an angle corresponding to a maximum response. The condition for maximum constructive interference is:\n$$\n2\\pi \\frac{d}{\\lambda} (\\sin\\theta_0 - \\sin\\theta_g) = 2\\pi m, \\quad \\text{for } m \\in \\mathbb{Z}\n$$\nwhere $m$ is an integer. Simplifying this equation gives the locations of the response maxima (lobes) in terms of $\\sin\\theta$:\n$$\n\\sin\\theta_g = \\sin\\theta_0 - m \\frac{\\lambda}{d}\n$$\nThe case $m=0$ results in $\\sin\\theta_g = \\sin\\theta_0$, which corresponds to the main lobe correctly pointed at the desired look direction $\\theta_0$.\nThe cases where $m \\neq 0$ correspond to grating lobes, which are undesired maxima in the beam pattern.\n\nA grating lobe becomes physically meaningful, or \"visible,\" if its corresponding angle $\\theta_g$ is real. This is equivalent to the condition $|\\sin\\theta_g| \\le 1$. Therefore, a visible grating lobe exists if there is a non-zero integer $m$ such that:\n$$\n-1 \\le \\sin\\theta_0 - m \\frac{\\lambda}{d} \\le 1\n$$\nThis inequality is the angle-dependent aliasing condition.\n\nTo avoid any visible grating lobes, we must ensure that for all non-zero integers $m$, the condition $|\\sin\\theta_g| > 1$ is met.\n$$\n\\left| \\sin\\theta_0 - m \\frac{\\lambda}{d} \\right| > 1, \\quad \\forall m \\in \\mathbb{Z} \\setminus \\{0\\}\n$$\nThis is equivalent to requiring that for every non-zero integer $m$, either $\\sin\\theta_0 - m \\frac{\\lambda}{d} > 1$ or $\\sin\\theta_0 - m \\frac{\\lambda}{d}  -1$.\n\nLet's analyze these two possibilities:\n1. For positive integers $m = 1, 2, 3, \\ldots$: The condition $\\sin\\theta_0 - m \\frac{\\lambda}{d} > 1$ is impossible since $\\sin\\theta_0 \\le 1$ and $m \\frac{\\lambda}{d} > 0$. So we must satisfy $\\sin\\theta_0 - m \\frac{\\lambda}{d}  -1$. Rearranging gives $m \\frac{\\lambda}{d} > 1 + \\sin\\theta_0$, or $\\frac{\\lambda}{d} > \\frac{1 + \\sin\\theta_0}{m}$. To satisfy this for all $m \\ge 1$, we must satisfy it for the most restrictive case, which is $m=1$. Thus, we need $\\frac{\\lambda}{d} > 1 + \\sin\\theta_0$.\n\n2. For negative integers $m = -1, -2, -3, \\ldots$: Let $m = -k$ where $k = 1, 2, 3, \\ldots$. The condition becomes $|\\sin\\theta_0 + k \\frac{\\lambda}{d}| > 1$. The possibility $\\sin\\theta_0 + k \\frac{\\lambda}{d}  -1$ is impossible since $\\sin\\theta_0 \\ge -1$ and $k\\frac{\\lambda}{d} > 0$. So we must satisfy $\\sin\\theta_0 + k \\frac{\\lambda}{d} > 1$. Rearranging gives $k \\frac{\\lambda}{d} > 1 - \\sin\\theta_0$, or $\\frac{\\lambda}{d} > \\frac{1 - \\sin\\theta_0}{k}$. To satisfy this for all $k \\ge 1$, we must satisfy it for the most restrictive case, $k=1$. Thus, we need $\\frac{\\lambda}{d} > 1 - \\sin\\theta_0$.\n\nTo be free of any visible grating lobes, both conditions must hold simultaneously:\n$$\n\\frac{\\lambda}{d} > 1 + \\sin\\theta_0 \\quad \\text{and} \\quad \\frac{\\lambda}{d} > 1 - \\sin\\theta_0\n$$\nThis is equivalent to requiring that $\\frac{\\lambda}{d}$ be greater than the maximum of the two right-hand side values:\n$$\n\\frac{\\lambda}{d} > \\max(1 + \\sin\\theta_0, 1 - \\sin\\theta_0)\n$$\nThe maximum of these two terms can be expressed in a more compact form. Since $\\sin\\theta_0$ is a real number between $-1$ and $1$, we have:\n$$\n\\max(1 + \\sin\\theta_0, 1 - \\sin\\theta_0) = 1 + |\\sin\\theta_0|\n$$\nTherefore, the condition for a grating-lobe-free visible region is:\n$$\n\\frac{\\lambda}{d} > 1 + |\\sin\\theta_0|\n$$\nThe problem asks for the minimal positive frequency, $f_{\\mathrm{gl}}(\\theta_0)$, at which the first grating lobe enters the visible region. This frequency corresponds to the boundary of the above condition. As frequency $f$ increases from zero, the wavelength $\\lambda = c/f$ decreases from infinity. The first grating lobe appears at the edge of the visible region when $\\lambda/d$ first violates the inequality, which happens at the point of equality. Let this transition wavelength be $\\lambda_{\\mathrm{gl}}$.\n$$\n\\frac{\\lambda_{\\mathrm{gl}}}{d} = 1 + |\\sin\\theta_0|\n$$\nSubstituting $\\lambda_{\\mathrm{gl}} = c / f_{\\mathrm{gl}}(\\theta_0)$, we have:\n$$\n\\frac{c}{f_{\\mathrm{gl}}(\\theta_0) d} = 1 + |\\sin\\theta_0|\n$$\nSolving for the transition frequency $f_{\\mathrm{gl}}(\\theta_0)$ yields the desired expression:\n$$\nf_{\\mathrm{gl}}(\\theta_0) = \\frac{c}{d(1 + |\\sin\\theta_0|)}\n$$\nThis expression gives the lowest frequency at which a grating lobe will appear at the boundary of the visible region ($\\sin\\theta_g = \\pm 1$), dependent on the steering angle $\\theta_0$. For any frequency $f > f_{\\mathrm{gl}}(\\theta_0)$, at least one grating lobe will be present in the visible region.",
            "answer": "$$\n\\boxed{\\frac{c}{d(1 + |\\sin\\theta_0|)}}\n$$"
        },
        {
            "introduction": "With an understanding of the array's physical properties, we now turn to the processing itself. This exercise delves into the celebrated Minimum Variance Distortionless Response (MVDR) beamformer, a cornerstone of adaptive array processing designed to maximize interference rejection. You will investigate the critical trade-off between resolution and robustness by implementing diagonal loading, a technique vital for stabilizing the beamformer in the presence of noise and model mismatch .",
            "id": "4117576",
            "problem": "Consider a narrowband plane-wave impinging on a two-sensor linear microphone array. Let the steering vector in the look direction be $a \\in \\mathbb{C}^{2}$, and assume a distortionless response beamformer, that is, $w^{H} a = 1$. The array is operated with Minimum Variance Distortionless Response (MVDR) beamforming and diagonal loading, which replaces the sample covariance $R \\in \\mathbb{C}^{2 \\times 2}$ by $R_{\\lambda} = R + \\lambda I$, where $\\lambda \\ge 0$ is the diagonal loading parameter and $I$ is the identity matrix. The White-Noise Gain (WNG) is defined as the ratio of the squared distortionless response to the output power under spatially white noise with unit power spectral density. Under the distortionless constraint $w^{H} a = 1$, this equals the reciprocal of the squared Euclidean norm of the beamforming weights.\n\nStart from first principles: the narrowband array data model, the definition of the MVDR criterion as a constrained quadratic program, and the definition of WNG under spatially white noise. Show how diagonal loading trades robustness against resolution by deriving how the WNG depends on $\\lambda$ and how it behaves as $\\lambda$ varies.\n\nThen, for the specific, physically consistent case below, derive a closed-form expression for $\\lambda$ that meets a White-Noise Gain constraint, and compute its value.\n\nData and requirement:\n- Two sensors with a look-direction steering vector $a = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$.\n- Sample covariance is diagonal and unequal across sensors due to distinct microphone self-noise powers: $R = \\begin{pmatrix} r_{1}  0 \\\\ 0  r_{2} \\end{pmatrix}$ with $r_{1} = 5.0 \\times 10^{-6}$ and $r_{2} = 1.0 \\times 10^{-6}$ (units: $\\mathrm{Pa}^{2}$).\n- White-Noise Gain target (constraint): $\\mathrm{WNG} = \\Gamma = 1.6$.\n- Find the physically valid diagonal loading parameter $\\lambda$ that satisfies the WNG constraint for the diagonally loaded MVDR beamformer.\n\nTasks:\n1) Starting from the constrained minimization definition of the diagonally loaded MVDR beamformer, derive an explicit expression for the beamformer weights in terms of $R$, $a$, and $\\lambda$, and then derive the WNG as an explicit function of $\\lambda$.\n2) Specialize your WNG expression to the two-sensor diagonal $R$ specified above and $a = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$, reduce the WNG-constraint equation $\\mathrm{WNG}(\\lambda) = \\Gamma$ to a univariate polynomial in $\\lambda$, and solve for the physically valid $\\lambda$ that keeps $R_{\\lambda}$ positive definite.\n3) Show analytically why increasing $\\lambda$ increases robustness (as measured by WNG) but decreases resolution (interpreted as the ability to adaptively suppress out-of-look-direction components), by relating the limiting behavior of the weights as $\\lambda \\to \\infty$ to a non-adaptive matched-filter form.\n\nRound your final numerical value of $\\lambda$ to four significant figures. Express $\\lambda$ in $\\mathrm{Pa}^{2}$.",
            "solution": "The solution is organized into three parts as requested by the problem statement.\n\nTask 1: Derivation of the beamformer weights and White-Noise Gain (WNG).\n\nThe Minimum Variance Distortionless Response (MVDR) beamformer with diagonal loading seeks to find the weight vector $w \\in \\mathbb{C}^{2}$ that solves the following constrained optimization problem:\n$$\n\\underset{w}{\\text{minimize}} \\quad w^{H} R_{\\lambda} w \\quad \\text{subject to} \\quad w^{H} a = 1\n$$\nwhere $R_{\\lambda} = R + \\lambda I$, $R$ is the sample covariance matrix, $\\lambda \\ge 0$ is the diagonal loading parameter, $I$ is the identity matrix, and $a$ is the steering vector for the look direction.\n\nWe solve this using the method of Lagrange multipliers. The Lagrangian $\\mathcal{L}$ is:\n$$\n\\mathcal{L}(w, \\mu) = w^{H} R_{\\lambda} w + \\mu (1 - w^{H} a) + \\mu^{*} (1 - a^{H} w)\n$$\nwhere $\\mu$ is a complex Lagrange multiplier. To find the minimum, we take the complex gradient of $\\mathcal{L}$ with respect to $w^{*}$ and set it to zero:\n$$\n\\nabla_{w^{*}} \\mathcal{L} = R_{\\lambda} w - \\mu a = 0\n$$\nThis gives $R_{\\lambda} w = \\mu a$. Since $R$ is a covariance matrix, it is positive semidefinite. For $\\lambda  0$, $R_{\\lambda}$ is strictly positive definite and thus invertible. For $\\lambda=0$, we assume $R$ to be invertible. Therefore, we can write:\n$$\nw = \\mu R_{\\lambda}^{-1} a\n$$\nTo find the value of $\\mu$, we substitute this expression for $w$ into the distortionless constraint $w^{H} a = 1$:\n$$\n(\\mu R_{\\lambda}^{-1} a)^{H} a = 1 \\implies \\mu^{*} a^{H} (R_{\\lambda}^{-1})^{H} a = 1\n$$\nSince $R_{\\lambda}$ is a Hermitian matrix ($R_{\\lambda}^{H} = R_{\\lambda}$), its inverse is also Hermitian ($(R_{\\lambda}^{-1})^{H} = R_{\\lambda}^{-1}$). The expression $a^{H} R_{\\lambda}^{-1} a$ is a positive real scalar. Thus, $\\mu^{*}$ must be a positive real scalar, which implies $\\mu$ is also a positive real scalar.\n$$\n\\mu (a^{H} R_{\\lambda}^{-1} a) = 1 \\implies \\mu = \\frac{1}{a^{H} R_{\\lambda}^{-1} a}\n$$\nSubstituting this back into the expression for $w$, we obtain the optimal weights for the diagonally loaded MVDR beamformer:\n$$\nw = \\frac{R_{\\lambda}^{-1} a}{a^{H} R_{\\lambda}^{-1} a}\n$$\nThe White-Noise Gain (WNG) is defined as the reciprocal of the squared Euclidean norm of the beamforming weights, given the distortionless constraint.\n$$\n\\mathrm{WNG} = \\frac{1}{\\|w\\|_{2}^{2}} = \\frac{1}{w^{H} w}\n$$\nWe compute $w^{H}w$:\n$$\nw^{H} w = \\left( \\frac{R_{\\lambda}^{-1} a}{a^{H} R_{\\lambda}^{-1} a} \\right)^{H} \\left( \\frac{R_{\\lambda}^{-1} a}{a^{H} R_{\\lambda}^{-1} a} \\right) = \\frac{a^{H} (R_{\\lambda}^{-1})^{H} R_{\\lambda}^{-1} a}{(a^{H} R_{\\lambda}^{-1} a)^{H} (a^{H} R_{\\lambda}^{-1} a)}\n$$\nAgain, since $a^{H} R_{\\lambda}^{-1} a$ is a real scalar and $R_{\\lambda}^{-1}$ is Hermitian, this simplifies to:\n$$\nw^{H} w = \\frac{a^{H} R_{\\lambda}^{-2} a}{(a^{H} R_{\\lambda}^{-1} a)^{2}}\n$$\nTherefore, the WNG as an explicit function of $\\lambda$ is:\n$$\n\\mathrm{WNG}(\\lambda) = \\frac{(a^{H} R_{\\lambda}^{-1} a)^{2}}{a^{H} R_{\\lambda}^{-2} a}\n$$\n\nTask 2: Solving for $\\lambda$ given specific data.\n\nWe are given:\n$a = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$, $R = \\begin{pmatrix} r_{1}  0 \\\\ 0  r_{2} \\end{pmatrix}$ with $r_{1} = 5.0 \\times 10^{-6}$ and $r_{2} = 1.0 \\times 10^{-6}$, and the target $\\mathrm{WNG} = \\Gamma = 1.6$.\n\nFirst, we find the required matrices:\n$$\nR_{\\lambda} = R + \\lambda I = \\begin{pmatrix} r_{1} + \\lambda  0 \\\\ 0  r_{2} + \\lambda \\end{pmatrix}\n$$\n$$\nR_{\\lambda}^{-1} = \\begin{pmatrix} \\frac{1}{r_{1} + \\lambda}  0 \\\\ 0  \\frac{1}{r_{2} + \\lambda} \\end{pmatrix}\n$$\n$$\nR_{\\lambda}^{-2} = (R_{\\lambda}^{-1})^{2} = \\begin{pmatrix} \\frac{1}{(r_{1} + \\lambda)^{2}}  0 \\\\ 0  \\frac{1}{(r_{2} + \\lambda)^{2}} \\end{pmatrix}\n$$\nNext, we compute the quadratic forms in the WNG expression:\n$$\na^{H} R_{\\lambda}^{-1} a = \\begin{pmatrix} 1  1 \\end{pmatrix} R_{\\lambda}^{-1} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\frac{1}{r_{1} + \\lambda} + \\frac{1}{r_{2} + \\lambda}\n$$\n$$\na^{H} R_{\\lambda}^{-2} a = \\begin{pmatrix} 1  1 \\end{pmatrix} R_{\\lambda}^{-2} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\frac{1}{(r_{1} + \\lambda)^{2}} + \\frac{1}{(r_{2} + \\lambda)^{2}}\n$$\nSubstituting these into the WNG expression and setting it to $\\Gamma$:\n$$\n\\Gamma = \\frac{\\left( \\frac{1}{r_{1} + \\lambda} + \\frac{1}{r_{2} + \\lambda} \\right)^{2}}{\\frac{1}{(r_{1} + \\lambda)^{2}} + \\frac{1}{(r_{2} + \\lambda)^{2}}} = \\frac{\\left( \\frac{(r_{2} + \\lambda) + (r_{1} + \\lambda)}{(r_{1} + \\lambda)(r_{2} + \\lambda)} \\right)^{2}}{\\frac{(r_{2} + \\lambda)^{2} + (r_{1} + \\lambda)^{2}}{((r_{1} + \\lambda)(r_{2} + \\lambda))^{2}}} = \\frac{((r_{1} + r_{2}) + 2\\lambda)^{2}}{(r_{1} + \\lambda)^{2} + (r_{2} + \\lambda)^{2}}\n$$\nWe expand and rearrange this equation to form a univariate polynomial in $\\lambda$:\n$$\n\\Gamma \\left( (r_{1} + \\lambda)^{2} + (r_{2} + \\lambda)^{2} \\right) = ((r_{1} + r_{2}) + 2\\lambda)^{2}\n$$\n$$\n\\Gamma \\left( r_{1}^{2} + 2r_{1}\\lambda + \\lambda^{2} + r_{2}^{2} + 2r_{2}\\lambda + \\lambda^{2} \\right) = (r_{1} + r_{2})^{2} + 4(r_{1} + r_{2})\\lambda + 4\\lambda^{2}\n$$\n$$\n\\Gamma \\left( 2\\lambda^{2} + 2(r_{1} + r_{2})\\lambda + (r_{1}^{2} + r_{2}^{2}) \\right) = 4\\lambda^{2} + 4(r_{1} + r_{2})\\lambda + (r_{1} + r_{2})^{2}\n$$\nCollecting terms by powers of $\\lambda$:\n$$\n(2\\Gamma - 4)\\lambda^{2} + (2\\Gamma(r_{1} + r_{2}) - 4(r_{1} + r_{2}))\\lambda + (\\Gamma(r_{1}^{2} + r_{2}^{2}) - (r_{1} + r_{2})^{2}) = 0\n$$\nThis is a quadratic equation $A\\lambda^{2} + B\\lambda + C = 0$ with coefficients:\n$A = 2\\Gamma - 4$\n$B = 2(\\Gamma - 2)(r_{1} + r_{2})$\n$C = \\Gamma(r_{1}^{2} + r_{2}^{2}) - (r_{1} + r_{2})^{2}$\n\nNow, we substitute the given numerical values: $\\Gamma = 1.6$, $r_{1} = 5.0 \\times 10^{-6}$, $r_{2} = 1.0 \\times 10^{-6}$.\n$r_{1} + r_{2} = 6.0 \\times 10^{-6}$\n$r_{1}^{2} + r_{2}^{2} = (5.0 \\times 10^{-6})^{2} + (1.0 \\times 10^{-6})^{2} = (25.0 + 1.0) \\times 10^{-12} = 26.0 \\times 10^{-12}$\n$(r_{1} + r_{2})^{2} = (6.0 \\times 10^{-6})^{2} = 36.0 \\times 10^{-12}$\n\n$A = 2(1.6) - 4 = 3.2 - 4 = -0.8$\n$B = 2(1.6 - 2)(6.0 \\times 10^{-6}) = 2(-0.4)(6.0 \\times 10^{-6}) = -4.8 \\times 10^{-6}$\n$C = 1.6(26.0 \\times 10^{-12}) - 36.0 \\times 10^{-12} = 41.6 \\times 10^{-12} - 36.0 \\times 10^{-12} = 5.6 \\times 10^{-12}$\n\nThe quadratic equation for $\\lambda$ is:\n$$\n-0.8\\lambda^{2} - 4.8 \\times 10^{-6}\\lambda + 5.6 \\times 10^{-12} = 0\n$$\nMultiplying by $-1$ gives:\n$$\n0.8\\lambda^{2} + 4.8 \\times 10^{-6}\\lambda - 5.6 \\times 10^{-12} = 0\n$$\nUsing the quadratic formula $\\lambda = \\frac{-b \\pm \\sqrt{b^{2}-4ac}}{2a}$:\n$$\n\\lambda = \\frac{-(4.8 \\times 10^{-6}) \\pm \\sqrt{(4.8 \\times 10^{-6})^{2} - 4(0.8)(-5.6 \\times 10^{-12})}}{2(0.8)}\n$$\n$$\n\\lambda = \\frac{-4.8 \\times 10^{-6} \\pm \\sqrt{23.04 \\times 10^{-12} + 17.92 \\times 10^{-12}}}{1.6}\n$$\n$$\n\\lambda = \\frac{-4.8 \\times 10^{-6} \\pm \\sqrt{40.96 \\times 10^{-12}}}{1.6} = \\frac{-4.8 \\times 10^{-6} \\pm 6.4 \\times 10^{-6}}{1.6}\n$$\nThis yields two solutions:\n$$\n\\lambda_{1} = \\frac{-4.8 \\times 10^{-6} + 6.4 \\times 10^{-6}}{1.6} = \\frac{1.6 \\times 10^{-6}}{1.6} = 1.0 \\times 10^{-6}\n$$\n$$\n\\lambda_{2} = \\frac{-4.8 \\times 10^{-6} - 6.4 \\times 10^{-6}}{1.6} = \\frac{-11.2 \\times 10^{-6}}{1.6} = -7.0 \\times 10^{-6}\n$$\nThe diagonal loading parameter $\\lambda$ must be non-negative, $\\lambda \\ge 0$. This condition also guarantees that $R_{\\lambda} = R + \\lambda I$ remains positive definite since $R$ is positive definite ($r_1, r_2 > 0$). Thus, the only physically valid solution is $\\lambda = \\lambda_{1} = 1.0 \\times 10^{-6}$. The units of $\\lambda$ are the same as the elements of $R$, which are $\\mathrm{Pa}^{2}$.\n\nTask 3: Analysis of robustness-resolution trade-off.\n\nIncreasing $\\lambda$ increases robustness, measured by WNG. We examine the limit of $\\mathrm{WNG}(\\lambda)$ as $\\lambda \\to \\infty$:\n$$\n\\lim_{\\lambda \\to \\infty} \\mathrm{WNG}(\\lambda) = \\lim_{\\lambda \\to \\infty} \\frac{((r_{1} + r_{2}) + 2\\lambda)^{2}}{(r_{1} + \\lambda)^{2} + (r_{2} + \\lambda)^{2}} = \\lim_{\\lambda \\to \\infty} \\frac{4\\lambda^{2} + O(\\lambda)}{\\lambda^{2} + \\lambda^{2} + O(\\lambda)} = \\frac{4\\lambda^{2}}{2\\lambda^{2}} = 2\n$$\nThe maximum possible WNG for a $2$-sensor array is $2$. As $\\lambda$ increases, $\\mathrm{WNG}(\\lambda)$ monotonically approaches this maximum value, indicating increased robustness against spatially white noise.\n\nIncreasing $\\lambda$ decreases resolution, interpreted as the ability to adaptively suppress interference. To show this, we analyze the behavior of the weights $w$ as $\\lambda \\to \\infty$:\n$$\nw = \\frac{R_{\\lambda}^{-1} a}{a^{H} R_{\\lambda}^{-1} a} = \\frac{(R + \\lambda I)^{-1} a}{a^{H} (R + \\lambda I)^{-1} a}\n$$\nFor large $\\lambda$, we can approximate the inverse matrix. Factor out $\\lambda$:\n$$\n(R + \\lambda I)^{-1} = (\\lambda(\\frac{1}{\\lambda}R + I))^{-1} = \\frac{1}{\\lambda}(I + \\frac{1}{\\lambda}R)^{-1}\n$$\nUsing the first-order Taylor expansion $(I + X)^{-1} \\approx I - X$ for small $X$:\n$$\n(R + \\lambda I)^{-1} \\approx \\frac{1}{\\lambda}(I - \\frac{1}{\\lambda}R) = \\frac{1}{\\lambda}I - \\frac{1}{\\lambda^{2}}R\n$$\nSubstituting this into the expression for $w$:\n$$\nw \\approx \\frac{(\\frac{1}{\\lambda}I - \\frac{1}{\\lambda^{2}}R)a}{a^{H}(\\frac{1}{\\lambda}I - \\frac{1}{\\lambda^{2}}R)a} = \\frac{\\frac{1}{\\lambda}a - \\frac{1}{\\lambda^{2}}Ra}{\\frac{1}{\\lambda}a^{H}a - \\frac{1}{\\lambda^{2}}a^{H}Ra} = \\frac{a - \\frac{1}{\\lambda}Ra}{a^{H}a - \\frac{1}{\\lambda}a^{H}Ra}\n$$\nTaking the limit as $\\lambda \\to \\infty$:\n$$\n\\lim_{\\lambda \\to \\infty} w = \\frac{a}{a^{H}a}\n$$\nThis limiting weight vector corresponds to a conventional, non-adaptive beamformer (or matched filter). Its beam pattern is fixed and determined solely by the look direction $a$, independent of the covariance matrix $R$. Because the beamformer no longer adapts to the noise and interference field described by $R$, it loses its ability to form nulls in the direction of interfering sources. This loss of adaptivity corresponds to a decrease in resolution.\nTherefore, increasing $\\lambda$ transitions the beamformer from an adaptive MVDR type to a non-adaptive conventional type, thereby trading higher resolution (adaptive nulling) for higher robustness (WNG).\n\nRounding the final numerical value for $\\lambda$ to four significant figures as requested:\n$\\lambda = 1.0 \\times 10^{-6} \\, \\mathrm{Pa}^{2}$ becomes $1.000 \\times 10^{-6} \\, \\mathrm{Pa}^{2}$.",
            "answer": "$$\n\\boxed{1.000 \\times 10^{-6}}\n$$"
        },
        {
            "introduction": "Real-world acoustic scenes are rarely static; sources move, and environments change. This final practice elevates our analysis to a dynamic scenario, challenging you to analyze an adaptive MVDR beamformer that must track a moving source amidst interference. By simulating this system and exploring the role of the recursive covariance estimator's 'forgetting factor', you will confront the fundamental tension between rapid adaptation to change and the stability of the weight estimates .",
            "id": "4117613",
            "problem": "An array processing system observes a narrowband acoustic field with a time-varying desired source and a fixed interferer. Consider a Uniform Linear Array (ULA) of $M$ microphones, equally spaced by distance $d$ along the $x$-axis, immersed in a homogeneous medium with sound speed $c$. A time-harmonic plane wave at acoustic frequency $f_0$ propagates to the array. Under the narrowband assumption, the complex baseband snapshot at discrete time index $t$ is modeled as\n$$\n\\mathbf{x}[t] = s[t]\\,\\mathbf{a}(\\theta_s[t]) + i[t]\\,\\mathbf{a}(\\theta_i) + \\mathbf{n}[t],\n$$\nwhere $s[t]$ and $i[t]$ are zero-mean circularly symmetric complex Gaussian source amplitudes with variances $\\sigma_s^2$ and $\\sigma_i^2$, respectively, and $\\mathbf{n}[t]\\sim\\mathcal{CN}(\\mathbf{0},\\sigma_n^2\\mathbf{I}_M)$ is spatially white noise. The steering vector $\\mathbf{a}(\\theta)$ is defined by\n$$\n\\mathbf{a}(\\theta) = \\left[ e^{\\mathrm{j} k x_0 \\sin(\\theta)}, e^{\\mathrm{j} k x_1 \\sin(\\theta)}, \\dots, e^{\\mathrm{j} k x_{M-1} \\sin(\\theta)} \\right]^{\\top},\n$$\nwith $k = \\frac{2\\pi f_0}{c}$ the acoustic wavenumber and $x_m = m d$ the position of the $m$-th sensor $(m = 0,1,\\dots,M-1)$. The direction-of-arrival (DOA) of the desired source varies in time as $\\theta_s[t]$, while the interferer DOA $\\theta_i$ is constant. Angles must be interpreted in degrees for specification and converted to radians when used in $\\sin(\\cdot)$.\n\nThe Minimum Variance Distortionless Response (MVDR) beamformer at time $t$ solves\n$$\n\\min_{\\mathbf{w}\\in\\mathbb{C}^M} \\ \\mathbf{w}^{\\mathrm{H}} \\mathbf{R}[t] \\mathbf{w} \\quad \\text{subject to} \\quad \\mathbf{w}^{\\mathrm{H}}\\mathbf{a}(\\theta_s[t]) = 1,\n$$\nwhere $\\mathbf{R}[t]$ is the array covariance matrix at time $t$. The exact (oracle) covariance for the stated stochastic model is\n$$\n\\mathbf{R}_{\\mathrm{true}}[t] = \\sigma_s^2 \\mathbf{a}(\\theta_s[t])\\mathbf{a}^{\\mathrm{H}}(\\theta_s[t]) + \\sigma_i^2 \\mathbf{a}(\\theta_i)\\mathbf{a}^{\\mathrm{H}}(\\theta_i) + \\sigma_n^2 \\mathbf{I}_M.\n$$\nThe MVDR solution is the unique vector\n$$\n\\mathbf{w}_{\\mathrm{MVDR}}[t] = \\frac{\\mathbf{R}^{-1}[t]\\,\\mathbf{a}(\\theta_s[t])}{\\mathbf{a}^{\\mathrm{H}}(\\theta_s[t])\\,\\mathbf{R}^{-1}[t]\\,\\mathbf{a}(\\theta_s[t])}.\n$$\nIn practice, an exponentially weighted recursive covariance estimator is used:\n$$\n\\widehat{\\mathbf{R}}[t] = \\lambda\\,\\widehat{\\mathbf{R}}[t-1] + (1-\\lambda)\\,\\mathbf{x}[t]\\mathbf{x}^{\\mathrm{H}}[t],\n$$\nwith $0\\lambda1$ the forgetting factor and an initial positive semidefinite $\\widehat{\\mathbf{R}}[0]$. The adaptive MVDR uses $\\widehat{\\mathbf{R}}[t]$ in place of $\\mathbf{R}[t]$.\n\nStarting from first principles in computational acoustics and statistical signal processing, derive conditions on the forgetting factor $\\lambda$ that ensure the adaptive MVDR tracks the time variation of $\\mathbf{R}_{\\mathrm{true}}[t]$ induced by $\\theta_s[t]$ with bounded error. Your derivation must begin with the plane-wave array model and the MVDR optimization definition, then show how the exponentially weighted recursion acts as a discrete-time linear time-invariant low-pass filter on the covariance trajectory. Establish a relationship between $\\lambda$ and the variation frequency of $\\theta_s[t]$ (consider a sinusoidal DOA variation $\\theta_s[t] = \\Theta \\sin(2\\pi f_v t)$ with $\\Theta$ in degrees and $f_v$ in cycles per frame), and derive an inequality on $\\lambda$ to guarantee a specified tracking fidelity level in terms of the filter magnitude response at angular frequency $\\omega_v = 2\\pi f_v$. Also derive a variance-limiting condition on $\\lambda$ to keep the estimator variance below a prescribed bound when the input snapshots are contaminated by additive white noise. Clearly state any approximations required to connect the covariance tracking to MVDR weight tracking.\n\nYou must then implement a program that simulates this scenario and evaluates the tracking behavior empirically by comparing the adaptive MVDR weights $\\widehat{\\mathbf{w}}[t]$ (obtained using $\\widehat{\\mathbf{R}}[t]$) to the oracle MVDR weights $\\mathbf{w}_{\\mathrm{MVDR}}[t]$ (obtained using $\\mathbf{R}_{\\mathrm{true}}[t]$). Use the following scientifically plausible parameters and ensure angles are specified in degrees in the problem statement and converted to radians in computations:\n- Number of microphones: $M = 8$.\n- Sensor spacing: $d = 0.035\\,\\mathrm{m}$.\n- Sound speed: $c = 343\\,\\mathrm{m/s}$.\n- Narrowband frequency: $f_0 = 3000\\,\\mathrm{Hz}$.\n- Desired source DOA variation: $\\theta_s[t] = \\Theta \\sin(2\\pi f_v t)$, with amplitude $\\Theta = 30\\,\\mathrm{deg}$.\n- Interferer DOA: $\\theta_i = -20\\,\\mathrm{deg}$.\n- Source, interferer, and noise variances: $\\sigma_s^2 = 1.0$, $\\sigma_i^2 = 5.0$, $\\sigma_n^2 = 0.1$ (dimensionless complex baseband power units).\n- Number of frames: $T = 4000$.\n- Diagonal loading added to each covariance inversion: a small constant $\\gamma = 10^{-3}$ to ensure numerical stability (dimensionless).\n\nDefine the tracking error at time $t$ as\n$$\ne[t] = \\left\\|\\widehat{\\mathbf{w}}[t] - \\mathbf{w}_{\\mathrm{MVDR}}[t]\\right\\|_2,\n$$\nand the overall tracking error metric as the root-mean-square error\n$$\nE = \\sqrt{\\frac{1}{T}\\sum_{t=1}^{T} e[t]^2}.\n$$\n\nYour program must run four test cases that probe different tracking regimes by varying the forgetting factor $\\lambda$ and the DOA variation frequency $f_v$ (in cycles per frame). For each case, compute $E$ and compare it to a specified threshold $\\tau$ to produce a boolean result indicating tracking success. Use the following test suite:\n- Case $1$: $\\lambda = 0.98$, $f_v = \\frac{1}{500}$, threshold $\\tau = 0.20$.\n- Case $2$: $\\lambda = 0.98$, $f_v = \\frac{1}{50}$, threshold $\\tau = 0.20$.\n- Case $3$: $\\lambda = 0.90$, $f_v = \\frac{1}{20}$, threshold $\\tau = 0.25$.\n- Case $4$: $\\lambda = 0.60$, $f_v = \\frac{1}{20}$, threshold $\\tau = 0.25$.\n\nFor each test case, output a boolean indicating whether $E \\le \\tau$. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test cases above.\n\nAll angles in the simulation must be specified in degrees in the parameters and then converted internally to radians when used in trigonometric functions. Physical units for $d$, $c$, and $f_0$ must be used exactly as specified: meters for $d$, meters per second for $c$, and Hertz for $f_0$. The output boolean list has no physical units.",
            "solution": "We begin with the acoustic plane wave model and the array response. A time-harmonic plane wave of angular frequency $\\omega_0 = 2\\pi f_0$ propagating in a homogeneous medium of sound speed $c$ has wavenumber $k = \\frac{\\omega_0}{c} = \\frac{2\\pi f_0}{c}$. For a Uniform Linear Array (ULA) with sensor positions $x_m = m d$ along the $x$-axis, the narrowband complex baseband steering vector $\\mathbf{a}(\\theta)$ for a plane wave impinging from direction $\\theta$ (measured from broadside in degrees, converted to radians in trigonometric use) is\n$$\n\\mathbf{a}(\\theta) = \\left[e^{\\mathrm{j} k x_0 \\sin(\\theta)}, e^{\\mathrm{j} k x_1 \\sin(\\theta)}, \\dots, e^{\\mathrm{j} k x_{M-1} \\sin(\\theta)}\\right]^{\\top},\n$$\nwhich follows from the phase accumulation $k\\mathbf{r}\\cdot\\hat{\\mathbf{s}}$ where $\\hat{\\mathbf{s}}$ is the unit propagation direction.\n\nThe observed snapshot at discrete time $t$ under the narrowband superposition model is\n$$\n\\mathbf{x}[t] = s[t]\\mathbf{a}(\\theta_s[t]) + i[t]\\mathbf{a}(\\theta_i) + \\mathbf{n}[t],\n$$\nwith $s[t]\\sim\\mathcal{CN}(0,\\sigma_s^2)$, $i[t]\\sim\\mathcal{CN}(0,\\sigma_i^2)$, and $\\mathbf{n}[t]\\sim\\mathcal{CN}(\\mathbf{0},\\sigma_n^2\\mathbf{I}_M)$ mutually independent. The exact covariance matrix is then the sum of the individual covariances:\n$$\n\\mathbf{R}_{\\mathrm{true}}[t] = \\mathbb{E}\\left[\\mathbf{x}[t]\\mathbf{x}^{\\mathrm{H}}[t]\\right] = \\sigma_s^2 \\mathbf{a}(\\theta_s[t])\\mathbf{a}^{\\mathrm{H}}(\\theta_s[t]) + \\sigma_i^2 \\mathbf{a}(\\theta_i)\\mathbf{a}^{\\mathrm{H}}(\\theta_i) + \\sigma_n^2 \\mathbf{I}_M.\n$$\n\nThe Minimum Variance Distortionless Response (MVDR) beamformer is defined by\n$$\n\\mathbf{w}_{\\mathrm{MVDR}}[t] = \\arg\\min_{\\mathbf{w}} \\ \\mathbf{w}^{\\mathrm{H}}\\mathbf{R}[t]\\mathbf{w} \\quad \\text{subject to} \\quad \\mathbf{w}^{\\mathrm{H}}\\mathbf{a}(\\theta_s[t]) = 1.\n$$\nUsing Lagrange multipliers, the solution is well known:\n$$\n\\mathbf{w}_{\\mathrm{MVDR}}[t] = \\frac{\\mathbf{R}^{-1}[t]\\mathbf{a}(\\theta_s[t])}{\\mathbf{a}^{\\mathrm{H}}(\\theta_s[t])\\mathbf{R}^{-1}[t]\\mathbf{a}(\\theta_s[t])}.\n$$\nWe use diagonal loading to ensure numerical stability: replace $\\mathbf{R}[t]$ with $\\mathbf{R}[t]+\\gamma\\mathbf{I}_M$ for a small $\\gamma0$.\n\nIn adaptive operation, the covariance is estimated recursively via Exponentially Weighted Moving Average (EWMA):\n$$\n\\widehat{\\mathbf{R}}[t] = \\lambda \\widehat{\\mathbf{R}}[t-1] + (1-\\lambda)\\mathbf{x}[t]\\mathbf{x}^{\\mathrm{H}}[t], \\quad 0\\lambda1,\n$$\ninitialized with a positive semidefinite $\\widehat{\\mathbf{R}}[0]$. This recursion is linear in $\\mathbf{x}[t]\\mathbf{x}^{\\mathrm{H}}[t]$ and defines a discrete-time Linear Time-Invariant (LTI) filter on the trajectory of the covariance samples $\\mathbf{S}[t] \\triangleq \\mathbf{x}[t]\\mathbf{x}^{\\mathrm{H}}[t]$. Writing the recursion componentwise for any scalar entry $\\widehat{R}_{mn}[t] = \\lambda \\widehat{R}_{mn}[t-1] + (1-\\lambda) S_{mn}[t]$, the $z$-transform yields\n$$\n\\widehat{R}_{mn}(z) = \\frac{(1-\\lambda)}{1 - \\lambda z^{-1}} S_{mn}(z),\n$$\nso the filter transfer function is\n$$\nH(z) = \\frac{(1-\\lambda)}{1 - \\lambda z^{-1}},\n$$\nwith pole at $z=\\lambda$. Evaluated on the unit circle $z=e^{\\mathrm{j}\\omega}$, the magnitude response is\n$$\n|H(e^{\\mathrm{j}\\omega})| = \\frac{(1-\\lambda)}{\\sqrt{1 + \\lambda^2 - 2\\lambda\\cos\\omega}}.\n$$\nInterpreting $\\mathbf{R}_{\\mathrm{true}}[t]$ as a slowly time-varying signal driven by the DOA variation, and $\\mathbf{S}[t]$ as a noisy sample of that signal, the EWMA acts as a first-order low-pass smoother on each covariance entry. The effective time constant in samples is approximately\n$$\nN_{\\mathrm{eff}} = \\frac{1}{1-\\lambda},\n$$\nsince the impulse response is $h[t] = (1-\\lambda)\\lambda^{t} u[t]$, whose mean index is $\\frac{\\lambda}{1-\\lambda}$ and whose $e^{-1}$ decay time is on the order of $\\frac{1}{1-\\lambda}$.\n\nTracking fidelity requirement: suppose the desired covariance varies approximately sinusoidally at angular frequency $\\omega_v = 2\\pi f_v$ due to the sinusoidal DOA $\\theta_s[t] = \\Theta\\sin(2\\pi f_v t)$. To ensure the EWMA does not attenuate the covariance variation amplitude beyond a specified fraction $\\alpha\\in(0,1]$, impose\n$$\n|H(e^{\\mathrm{j}\\omega_v})| \\ge \\alpha.\n$$\nSubstituting the magnitude response and squaring both sides, we obtain\n$$\n\\frac{(1-\\lambda)^2}{1 + \\lambda^2 - 2\\lambda\\cos\\omega_v} \\ge \\alpha^2,\n$$\nwhich rearranges to an inequality in $\\lambda$:\n$$\n(1-\\lambda)^2 \\ge \\alpha^2\\left(1 + \\lambda^2 - 2\\lambda\\cos\\omega_v\\right).\n$$\nExpanding and collecting terms yields\n$$\n1 - 2\\lambda + \\lambda^2 \\ge \\alpha^2 + \\alpha^2\\lambda^2 - 2\\alpha^2\\lambda\\cos\\omega_v.\n$$\nBringing all terms to one side gives a quadratic inequality in $\\lambda$:\n$$\n(1-\\alpha^2)\\lambda^2 + \\left(-2 + 2\\alpha^2\\cos\\omega_v\\right)\\lambda + (1 - \\alpha^2) \\ge 0.\n$$\nFor a chosen $\\alpha$ and $\\omega_v$, this inequality defines an interval of $\\lambda$ values that achieve at least the desired passband gain at $\\omega_v$. In the common case $\\alpha$ near $1$, the intuitive condition $N_{\\mathrm{eff}} \\ll \\frac{2\\pi}{\\omega_v}$ emerges, i.e., the filter memory should be much shorter than the variation period: $\\frac{1}{1-\\lambda} \\ll \\frac{2\\pi}{\\omega_v}$, or equivalently\n$$\n\\lambda \\ll 1 - \\frac{\\omega_v}{2\\pi}\\cdot c_\\alpha,\n$$\nfor a constant $c_\\alpha$ determined by the desired fidelity (the exact bound follows from the quadratic inequality).\n\nVariance-limiting requirement: the EWMA reduces variance of a white-noise-driven input. If $S_{mn}[t]$ contains additive white noise with variance $\\sigma_{S}^2$, the output variance at $\\widehat{R}_{mn}[t]$ is\n$$\n\\mathrm{Var}\\{\\widehat{R}_{mn}[t]\\} = \\sigma_{S}^2 \\sum_{k=0}^{\\infty} (1-\\lambda)^2 \\lambda^{2k} = \\sigma_{S}^2 \\frac{(1-\\lambda)^2}{1 - \\lambda^2}.\n$$\nTo bound the estimator variance by $\\beta^2$, impose\n$$\n\\sigma_{S}^2 \\frac{(1-\\lambda)^2}{1 - \\lambda^2} \\le \\beta^2.\n$$\nSolving for $\\lambda$ gives\n$$\n\\frac{(1-\\lambda)^2}{1 - \\lambda^2} \\le \\frac{\\beta^2}{\\sigma_{S}^2} \\quad \\Rightarrow \\quad \\frac{1-\\lambda}{1+\\lambda} \\le \\frac{\\beta}{\\sigma_{S}},\n$$\nwhich yields\n$$\n\\lambda \\ge \\frac{1 - \\frac{\\beta}{\\sigma_{S}}}{1 + \\frac{\\beta}{\\sigma_{S}}}.\n$$\nThus $\\lambda$ must be sufficiently close to $1$ to suppress variance, but not so close that the tracking fidelity at $\\omega_v$ is violated. Combining the fidelity and variance bounds yields an admissible interval for $\\lambda$.\n\nConnecting covariance tracking to MVDR weight tracking: the MVDR weights depend smoothly on $\\mathbf{R}^{-1}[t]$ via\n$$\n\\mathbf{w}[t] = \\frac{\\mathbf{R}^{-1}[t]\\mathbf{a}(\\theta_s[t])}{\\mathbf{a}^{\\mathrm{H}}(\\theta_s[t])\\mathbf{R}^{-1}[t]\\mathbf{a}(\\theta_s[t])}.\n$$\nIf $\\widehat{\\mathbf{R}}[t]$ tracks $\\mathbf{R}_{\\mathrm{true}}[t]$ with bounded error in operator norm and remains positive definite (e.g., via diagonal loading $\\gamma\\mathbf{I}_M$), then by continuity of matrix inversion on the cone of positive definite matrices and the smoothness of the steering vector map $\\theta\\mapsto\\mathbf{a}(\\theta)$, the induced error in $\\mathbf{w}[t]$ is bounded. Therefore, the EWMA fidelity constraint $|H(e^{\\mathrm{j}\\omega_v})|\\ge\\alpha$ and noise variance bound translate into bounded MVDR weight tracking error $E$.\n\nAlgorithmic implementation for simulation:\n- Fix $M$, $d$, $c$, and $f_0$, compute $k = \\frac{2\\pi f_0}{c}$.\n- Define $\\mathbf{a}(\\theta)$ using $\\sin(\\theta)$ with $\\theta$ in radians.\n- For each test case, set $\\lambda$, $f_v$, and threshold $\\tau$; define $\\theta_s[t] = \\Theta\\sin(2\\pi f_v t)$ with $\\Theta$ in degrees, convert $\\theta_s[t]$ and $\\theta_i$ to radians for steering vector evaluation.\n- Initialize $\\widehat{\\mathbf{R}}[0] = \\sigma_n^2 \\mathbf{I}_M$.\n- For $t=1,\\dots,T$:\n  - Draw $s[t]\\sim\\mathcal{CN}(0,\\sigma_s^2)$, $i[t]\\sim\\mathcal{CN}(0,\\sigma_i^2)$, and $\\mathbf{n}[t]\\sim\\mathcal{CN}(\\mathbf{0},\\sigma_n^2\\mathbf{I}_M)$.\n  - Form $\\mathbf{x}[t] = s[t]\\mathbf{a}(\\theta_s[t]) + i[t]\\mathbf{a}(\\theta_i) + \\mathbf{n}[t]$.\n  - Update $\\widehat{\\mathbf{R}}[t] = \\lambda\\widehat{\\mathbf{R}}[t-1] + (1-\\lambda)\\mathbf{x}[t]\\mathbf{x}^{\\mathrm{H}}[t]$.\n  - Compute $\\mathbf{R}_{\\mathrm{true}}[t]$ using $\\sigma_s^2$, $\\sigma_i^2$, $\\sigma_n^2$, $\\mathbf{a}(\\theta_s[t])$, and $\\mathbf{a}(\\theta_i)$.\n  - With diagonal loading $\\gamma\\mathbf{I}_M$, compute $\\widehat{\\mathbf{w}}[t]$ and $\\mathbf{w}_{\\mathrm{MVDR}}[t]$ by solving linear systems rather than explicitly inverting matrices: let $\\mathbf{v}_{\\mathrm{hat}}[t]$ solve $(\\widehat{\\mathbf{R}}[t]+\\gamma\\mathbf{I}_M)\\mathbf{v}=\\mathbf{a}(\\theta_s[t])$ and set $\\widehat{\\mathbf{w}}[t] = \\mathbf{v}_{\\mathrm{hat}}[t]/\\left(\\mathbf{a}^{\\mathrm{H}}(\\theta_s[t])\\mathbf{v}_{\\mathrm{hat}}[t]\\right)$; likewise for the oracle using $\\mathbf{R}_{\\mathrm{true}}[t]$.\n  - Compute $e[t] = \\left\\|\\widehat{\\mathbf{w}}[t] - \\mathbf{w}_{\\mathrm{MVDR}}[t]\\right\\|_2$.\n- Compute $E = \\sqrt{\\frac{1}{T}\\sum_{t=1}^{T} e[t]^2}$ and compare to $\\tau$ to yield a boolean result for the test case.\n\nScientific realism and edge cases:\n- The recursion with $0\\lambda1$ and initial $\\widehat{\\mathbf{R}}[0]\\succeq \\mathbf{0}$ maintains positive semidefiniteness since each update is a positive convex combination of $\\widehat{\\mathbf{R}}[t-1]$ and $\\mathbf{x}[t]\\mathbf{x}^{\\mathrm{H}}[t]$. Diagonal loading ensures invertibility.\n- The sinusoidal DOA variation introduces a single variation frequency $\\omega_v$, making the fidelity analysis via $|H(e^{\\mathrm{j}\\omega_v})|$ appropriate.\n- The variance bound connects $\\lambda$ to robustness against snapshot noise.\n\nTest suite coverage:\n- Case $1$ (slow variation, large $\\lambda$): $f_v=\\frac{1}{500}$, $\\lambda=0.98$, expected good tracking ($E\\le\\tau$).\n- Case $2$ (faster variation, same $\\lambda$): $f_v=\\frac{1}{50}$, $\\lambda=0.98$, expected degraded tracking ($E\\tau$).\n- Case $3$ (moderate variation, smaller $\\lambda$): $f_v=\\frac{1}{20}$, $\\lambda=0.90$, expected acceptable tradeoff ($E\\le\\tau$).\n- Case $4$ (moderate variation, small $\\lambda$): $f_v=\\frac{1}{20}$, $\\lambda=0.60$, expected noisy estimate ($E\\tau$).\n\nThe program implements these cases and prints a single line with the four booleans, in order.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef steering_vector(theta_deg, k, d, M):\n    \"\"\"\n    Construct ULA steering vector for angle theta_deg (degrees).\n    Uses radians internally for sin.\n    \"\"\"\n    theta_rad = np.deg2rad(theta_deg)\n    # Sensor positions x_m = m*d, m=0..M-1\n    m_idx = np.arange(M)\n    x = m_idx * d\n    return np.exp(1j * k * x * np.sin(theta_rad))\n\ndef mvdr_weights(R, a, gamma=1e-3):\n    \"\"\"\n    MVDR weights with diagonal loading gamma. Avoid explicit inverse by solving.\n    w = R^{-1} a / (a^H R^{-1} a)\n    \"\"\"\n    M = R.shape[0]\n    R_loaded = R + gamma * np.eye(M, dtype=R.dtype)\n    # Solve R_loaded v = a\n    v = np.linalg.solve(R_loaded, a)\n    denom = np.vdot(a, v)  # a^H v\n    # Protect against numerical issues\n    if np.abs(denom)  1e-12:\n        return np.zeros_like(a)\n    return v / denom\n\ndef simulate_case(M, d, c, f0, Theta_deg, theta_i_deg,\n                  sigma_s2, sigma_i2, sigma_n2,\n                  T, lam, f_v, gamma, rng):\n    \"\"\"\n    Simulate adaptive MVDR tracking for a single test case.\n    Returns RMS weight error E.\n    \"\"\"\n    # Wavenumber\n    k = 2.0 * np.pi * f0 / c\n    # Fixed interferer steering\n    a_i = steering_vector(theta_i_deg, k, d, M)\n    # Initialize covariance estimate\n    R_hat = sigma_n2 * np.eye(M, dtype=np.complex128)\n    # Accumulate squared errors\n    err_sq_sum = 0.0\n\n    for t in range(1, T + 1):\n        # Desired DOA varies sinusoidally: theta_s[t] = Theta * sin(2*pi*f_v*t)\n        theta_s_deg = Theta_deg * np.sin(2.0 * np.pi * f_v * t)\n        a_s = steering_vector(theta_s_deg, k, d, M)\n\n        # Draw complex Gaussian amplitudes and noise\n        # Complex CN(0, sigma^2): real and imag ~ N(0, sigma^2/2)\n        s = (np.sqrt(sigma_s2 / 2.0) *\n             (rng.standard_normal() + 1j * rng.standard_normal()))\n        i = (np.sqrt(sigma_i2 / 2.0) *\n             (rng.standard_normal() + 1j * rng.standard_normal()))\n        n = (np.sqrt(sigma_n2 / 2.0) *\n             (rng.standard_normal(M) + 1j * rng.standard_normal(M)))\n\n        # Snapshot\n        x = s * a_s + i * a_i + n\n\n        # Recursive covariance update\n        R_hat = lam * R_hat + (1.0 - lam) * np.outer(x, np.conj(x))\n\n        # Oracle covariance\n        R_true = (sigma_s2 * np.outer(a_s, np.conj(a_s)) +\n                  sigma_i2 * np.outer(a_i, np.conj(a_i)) +\n                  sigma_n2 * np.eye(M, dtype=np.complex128))\n\n        # Weights\n        w_hat = mvdr_weights(R_hat, a_s, gamma=gamma)\n        w_oracle = mvdr_weights(R_true, a_s, gamma=gamma)\n\n        # Error\n        e = np.linalg.norm(w_hat - w_oracle)\n        err_sq_sum += (e * e)\n\n    E = np.sqrt(err_sq_sum / T)\n    return E\n\ndef solve():\n    # Fixed parameters from the problem statement\n    M = 8\n    d = 0.035  # meters\n    c = 343.0  # m/s\n    f0 = 3000.0  # Hz\n    Theta_deg = 30.0  # degrees\n    theta_i_deg = -20.0  # degrees\n    sigma_s2 = 1.0\n    sigma_i2 = 5.0\n    sigma_n2 = 0.1\n    T = 4000\n    gamma = 1e-3\n\n    # Test cases: (lambda, f_v, threshold tau)\n    test_cases = [\n        (0.98, 1.0/500.0, 0.20),  # Case 1\n        (0.98, 1.0/50.0, 0.20),   # Case 2\n        (0.90, 1.0/20.0, 0.25),   # Case 3\n        (0.60, 1.0/20.0, 0.25),   # Case 4\n    ]\n\n    # Seed for reproducibility\n    rng = np.random.default_rng(123456)\n\n    results = []\n    for lam, f_v, tau in test_cases:\n        E = simulate_case(M, d, c, f0, Theta_deg, theta_i_deg,\n                          sigma_s2, sigma_i2, sigma_n2,\n                          T, lam, f_v, gamma, rng)\n        results.append(E = tau)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}