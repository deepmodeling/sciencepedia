{
    "hands_on_practices": [
        {
            "introduction": "在深入研究复杂的抽样方法之前，我们首先探讨一种强大的分析技术：拉普拉斯近似。这种方法旨在用一个更简单的分布（通常是高斯分布）来逼近后验分布，为快速获取不确定性估计提供了一种有效途径。本练习将指导您推导围绕后验最大值（MAP）的拉普拉斯近似，并学习如何评估其在非线性模型中的准确性，这对于理解后验分布的局部几何特性至关重要。",
            "id": "3938004",
            "problem": "考虑一个稳态对流传热中的校准问题。一个表面温度恒定的平板经历对流热通量，其模型为 $q = h(\\theta)\\,\\Delta T$，其中 $\\Delta T$ 是已知的温差，$h(\\theta)$ 是由单个标量参数 $\\theta$ 参数化的对流传热系数。受某些对流关系式对类指数参数的近指数敏感性的启发，假设 $h(\\theta) = h_{\\mathrm{ref}} \\exp(\\theta)$，其中 $h_{\\mathrm{ref}}$ 已知。在已知温差 $\\{\\Delta T_i\\}_{i=1}^N$ 下，热通量的带噪声测量值 $\\{y_i\\}_{i=1}^N$ 满足\n$$\ny_i \\;=\\; h(\\theta)\\,\\Delta T_i \\;+\\; \\varepsilon_i,\\quad \\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2),\\quad i=1,\\dots,N,\n$$\n其中 $\\sigma^2$ 已知，且 $\\varepsilon_i$ 在统计上是独立的。为 $\\theta$ 设置一个高斯先验：$\\theta \\sim \\mathcal{N}(\\mu_0,\\sigma_0^2)$，其中 $\\mu_0$ 和 $\\sigma_0^2$ 已知。\n\n给定 $N=3$ 次实验，其中 $h_{\\mathrm{ref}}=100\\,\\mathrm{W\\,m^{-2}\\,K^{-1}}$，$\\mu_0=0$，$\\sigma_0=0.5$，$\\sigma=100\\,\\mathrm{W\\,m^{-2}}$，且\n$$\n\\Delta T_1=10\\,\\mathrm{K},\\quad \\Delta T_2=20\\,\\mathrm{K},\\quad \\Delta T_3=30\\,\\mathrm{K},\n$$\n测得的通量为\n$$\ny_1=1000\\,\\mathrm{W\\,m^{-2}},\\quad y_2=2000\\,\\mathrm{W\\,m^{-2}},\\quad y_3=3000\\,\\mathrm{W\\,m^{-2}}.\n$$\n\n使用贝叶斯定理以及高斯噪声和先验模型：\n\n1) 推导以 $\\{y_i\\}$、$\\{\\Delta T_i\\}$、$h_{\\mathrm{ref}}$、$\\sigma^2$、$\\mu_0$ 和 $\\sigma_0^2$ 表示的负对数后验 $U(\\theta)$，结果可相差一个加性常数。\n\n2) 通过求解驻点条件 $U'(\\hat{\\theta})=0$ 来确定最大后验估计 $\\hat{\\theta}$。\n\n3) 推导负对数后验的海森矩阵 $U''(\\theta)$，以及后验在 $\\hat{\\theta}$ 附近的拉普拉斯（二阶）高斯近似，即均值为 $\\hat{\\theta}$、方差为 $[U''(\\hat{\\theta})]^{-1}$ 的高斯分布。\n\n4) 为评估一个弱非线性模型的准确性，计算标准化的非高斯性指标\n$$\n\\eta \\;=\\; \\frac{|U^{(3)}(\\hat{\\theta})|}{\\big(U''(\\hat{\\theta})\\big)^{3/2}},\n$$\n其中 $U^{(3)}(\\theta)$ 是 $U(\\theta)$ 的三阶导数。对给定数据，计算 $\\eta$ 的数值。\n\n将 $\\eta$ 的最终结果表示为单个实数，四舍五入到四位有效数字。$\\eta$ 是无量纲的，因此不需要单位。",
            "solution": "用户提供了一个应用于传热模型的贝叶斯推断中的适定问题。所有必要的数据和模型形式都已指定，问题在数学上是精确的。该问题具有科学依据且内部一致。\n\n该问题需要一个分四部分的解答，涉及推导后验分布、寻找最大后验（MAP）估计、描述后验的二阶高斯近似以及计算非高斯性指标。\n\n热通量的物理模型是 $q_i = h(\\theta) \\Delta T_i$，其参数化为 $h(\\theta) = h_{\\mathrm{ref}} \\exp(\\theta)$。测量模型是 $y_i = h(\\theta) \\Delta T_i + \\varepsilon_i$，其中噪声项 $\\varepsilon_i$ 是独立同分布（i.i.d.）的，即 $\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$。为参数 $\\theta$ 指定了高斯先验，$\\theta \\sim \\mathcal{N}(\\mu_0, \\sigma_0^2)$。\n\n**第1部分：负对数后验 $U(\\theta)$ 的推导**\n\n根据贝叶斯定理，后验概率密度函数（PDF）$p(\\theta|\\{y_i\\}_{i=1}^N)$ 正比于似然函数 $p(\\{y_i\\}_{i=1}^N|\\theta)$ 和先验概率密度函数 $p(\\theta)$ 的乘积。\n$$\np(\\theta|\\{y_i\\}) \\propto p(\\{y_i\\}|\\theta) p(\\theta)\n$$\n单个测量值 $y_i$ 的似然由高斯噪声模型给出：\n$$\np(y_i|\\theta) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_i - h(\\theta)\\Delta T_i)^2}{2\\sigma^2}\\right)\n$$\n由于测量值在统计上是独立的，联合似然是各个似然的乘积：\n$$\np(\\{y_i\\}|\\theta) = \\prod_{i=1}^{N} p(y_i|\\theta) = \\left(2\\pi\\sigma^2\\right)^{-N/2} \\exp\\left(-\\frac{1}{2\\sigma^2} \\sum_{i=1}^{N} (y_i - h(\\theta)\\Delta T_i)^2\\right)\n$$\n$\\theta$ 的先验概率密度函数给出如下：\n$$\np(\\theta) = \\frac{1}{\\sqrt{2\\pi\\sigma_0^2}} \\exp\\left(-\\frac{(\\theta - \\mu_0)^2}{2\\sigma_0^2}\\right)\n$$\n因此，后验概率密度函数正比于：\n$$\np(\\theta|\\{y_i\\}) \\propto \\exp\\left(-\\frac{1}{2\\sigma^2} \\sum_{i=1}^{N} (y_i - h_{\\mathrm{ref}}\\exp(\\theta)\\Delta T_i)^2 - \\frac{(\\theta - \\mu_0)^2}{2\\sigma_0^2}\\right)\n$$\n负对数后验 $U(\\theta) = -\\ln(p(\\theta|\\{y_i\\}))$，忽略一个加性常数后为：\n$$\nU(\\theta) = \\frac{1}{2\\sigma^2} \\sum_{i=1}^{N} (y_i - h_{\\mathrm{ref}}\\exp(\\theta)\\Delta T_i)^2 + \\frac{(\\theta - \\mu_0)^2}{2\\sigma_0^2}\n$$\n\n**第2部分：最大后验（MAP）估计 $\\hat{\\theta}$**\n\nMAP估计 $\\hat{\\theta}$ 是使 $U(\\theta)$ 最小化的 $\\theta$ 值。我们通过求解驻点条件 $U'(\\hat{\\theta}) = \\frac{dU}{d\\theta}\\big|_{\\theta=\\hat{\\theta}} = 0$ 来找到它。\n$U(\\theta)$ 的一阶导数是：\n$$\nU'(\\theta) = \\frac{d}{d\\theta} \\left[ \\frac{1}{2\\sigma^2} \\sum_{i=1}^{N} (y_i - h_{\\mathrm{ref}}\\exp(\\theta)\\Delta T_i)^2 + \\frac{(\\theta - \\mu_0)^2}{2\\sigma_0^2} \\right]\n$$\n$$\nU'(\\theta) = \\frac{1}{2\\sigma^2} \\sum_{i=1}^{N} 2(y_i - h_{\\mathrm{ref}}\\exp(\\theta)\\Delta T_i)(-h_{\\mathrm{ref}}\\exp(\\theta)\\Delta T_i) + \\frac{2(\\theta - \\mu_0)}{2\\sigma_0^2}\n$$\n$$\nU'(\\theta) = -\\frac{h_{\\mathrm{ref}}\\exp(\\theta)}{\\sigma^2} \\sum_{i=1}^{N} (y_i - h_{\\mathrm{ref}}\\exp(\\theta)\\Delta T_i)\\Delta T_i + \\frac{\\theta - \\mu_0}{\\sigma_0^2}\n$$\n提供的数据为 $h_{\\mathrm{ref}}=100\\,\\mathrm{W\\,m^{-2}\\,K^{-1}}$，$\\Delta T_1=10\\,\\mathrm{K}$，$\\Delta T_2=20\\,\\mathrm{K}$，$\\Delta T_3=30\\,\\mathrm{K}$，以及 $y_1=1000\\,\\mathrm{W\\,m^{-2}}$，$y_2=2000\\,\\mathrm{W\\,m^{-2}}$，$y_3=3000\\,\\mathrm{W\\,m^{-2}}$。我们观察到，对于所有 $i$，$y_i = 100 \\Delta T_i = h_{\\mathrm{ref}} \\Delta T_i$。\n将 $y_i = h_{\\mathrm{ref}} \\Delta T_i$ 代入 $U'(\\theta)$ 的表达式中：\n$$\nU'(\\theta) = -\\frac{h_{\\mathrm{ref}}\\exp(\\theta)}{\\sigma^2} \\sum_{i=1}^{N} (h_{\\mathrm{ref}}\\Delta T_i - h_{\\mathrm{ref}}\\exp(\\theta)\\Delta T_i)\\Delta T_i + \\frac{\\theta - \\mu_0}{\\sigma_0^2}\n$$\n$$\nU'(\\theta) = -\\frac{h_{\\mathrm{ref}}^2\\exp(\\theta)(1 - \\exp(\\theta))}{\\sigma^2} \\sum_{i=1}^{N} (\\Delta T_i)^2 + \\frac{\\theta - \\mu_0}{\\sigma_0^2}\n$$\n我们需要求解 $U'(\\hat{\\theta})=0$。先验参数为 $\\mu_0=0$ 和 $\\sigma_0=0.5$。我们来检验解 $\\hat{\\theta}=0$。当 $\\theta=0$ 时，$\\exp(\\theta)=1$，这使得项 $(1 - \\exp(\\theta))$ 等于 $0$。$U'(\\theta)$ 的第一项消失。第二项变为 $(\\hat{\\theta} - \\mu_0)/\\sigma_0^2 = (0 - 0)/\\sigma_0^2 = 0$。因此，$U'(0) = 0$。\nMAP估计为 $\\hat{\\theta} = 0$。这个结果的出现是因为数据在先验分布的峰值处与模型预测完全匹配。\n\n**第3部分：海森矩阵 $U''(\\theta)$ 和拉普拉斯近似**\n\n我们通过对 $U'(\\theta)$ 求导来计算 $U(\\theta)$ 的二阶导数，即海森矩阵 $U''(\\theta)$：\n$$\nU'(\\theta) = -\\frac{h_{\\mathrm{ref}}^2}{\\sigma^2}(\\exp(\\theta) - \\exp(2\\theta)) \\sum_{i=1}^{N} (\\Delta T_i)^2 + \\frac{\\theta - \\mu_0}{\\sigma_0^2}\n$$\n对 $\\theta$ 求导：\n$$\nU''(\\theta) = -\\frac{h_{\\mathrm{ref}}^2}{\\sigma^2}(\\exp(\\theta) - 2\\exp(2\\theta)) \\sum_{i=1}^{N} (\\Delta T_i)^2 + \\frac{1}{\\sigma_0^2}\n$$\n拉普拉斯近似是一个以 $\\hat{\\theta}$ 为中心、方差为 $[U''(\\hat{\\theta})]^{-1}$ 的高斯分布。我们在 $\\hat{\\theta}=0$ 处计算 $U''(\\theta)$ 的值：\n$$\nU''(\\hat{\\theta}) = U''(0) = -\\frac{h_{\\mathrm{ref}}^2}{\\sigma^2}(\\exp(0) - 2\\exp(0)) \\sum_{i=1}^{N} (\\Delta T_i)^2 + \\frac{1}{\\sigma_0^2}\n$$\n$$\nU''(\\hat{\\theta}) = -\\frac{h_{\\mathrm{ref}}^2}{\\sigma^2}(1 - 2) \\sum_{i=1}^{N} (\\Delta T_i)^2 + \\frac{1}{\\sigma_0^2}\n$$\n$$\nU''(\\hat{\\theta}) = \\frac{h_{\\mathrm{ref}}^2}{\\sigma^2} \\sum_{i=1}^{N} (\\Delta T_i)^2 + \\frac{1}{\\sigma_0^2}\n$$\n拉普拉斯近似是高斯概率密度函数 $p_{L}(\\theta) = \\mathcal{N}(\\hat{\\theta}, [U''(\\hat{\\theta})]^{-1})$，其中 $\\hat{\\theta}=0$，方差由上述表达式的倒数给出。\n\n**第4部分：非高斯性指标 $\\eta$**\n\n非高斯性指标定义为 $\\eta = |U^{(3)}(\\hat{\\theta})| / (U''(\\hat{\\theta}))^{3/2}$。我们首先通过对 $U''(\\theta)$ 求导来计算三阶导数 $U^{(3)}(\\theta)$：\n$$\nU''(\\theta) = -\\frac{h_{\\mathrm{ref}}^2}{\\sigma^2}(\\exp(\\theta) - 2\\exp(2\\theta)) \\sum_{i=1}^{N} (\\Delta T_i)^2 + \\frac{1}{\\sigma_0^2}\n$$\n$$\nU^{(3)}(\\theta) = -\\frac{h_{\\mathrm{ref}}^2}{\\sigma^2}(\\exp(\\theta) - 4\\exp(2\\theta)) \\sum_{i=1}^{N} (\\Delta T_i)^2\n$$\n在 $\\hat{\\theta}=0$ 处求值：\n$$\nU^{(3)}(\\hat{\\theta}) = U^{(3)}(0) = -\\frac{h_{\\mathrm{ref}}^2}{\\sigma^2}(\\exp(0) - 4\\exp(0)) \\sum_{i=1}^{N} (\\Delta T_i)^2\n$$\n$$\nU^{(3)}(\\hat{\\theta}) = -\\frac{h_{\\mathrm{ref}}^2}{\\sigma^2}(1 - 4) \\sum_{i=1}^{N} (\\Delta T_i)^2\n$$\n$$\nU^{(3)}(\\hat{\\theta}) = \\frac{3h_{\\mathrm{ref}}^2}{\\sigma^2} \\sum_{i=1}^{N} (\\Delta T_i)^2\n$$\n现在我们计算数值。\n温差的平方和是：\n$$\n\\sum_{i=1}^{3} (\\Delta T_i)^2 = (10\\,\\mathrm{K})^2 + (20\\,\\mathrm{K})^2 + (30\\,\\mathrm{K})^2 = 100 + 400 + 900 = 1400\\,\\mathrm{K}^2\n$$\n给定的参数是 $h_{\\mathrm{ref}}=100\\,\\mathrm{W\\,m^{-2}\\,K^{-1}}$，$\\sigma=100\\,\\mathrm{W\\,m^{-2}}$，以及 $\\sigma_0=0.5$。\n因此，$\\frac{h_{\\mathrm{ref}}^2}{\\sigma^2} = \\frac{100^2}{100^2} = 1\\,\\mathrm{K^{-2}}$ 且 $\\sigma_0^2 = 0.5^2 = 0.25$。\n\n让我们来数值计算 $U''(\\hat{\\theta})$ 和 $U^{(3)}(\\hat{\\theta})$：\n$$\nU''(\\hat{\\theta}) = \\frac{h_{\\mathrm{ref}}^2}{\\sigma^2} \\sum_{i=1}^{N} (\\Delta T_i)^2 + \\frac{1}{\\sigma_0^2} = (1) \\cdot (1400) + \\frac{1}{0.25} = 1400 + 4 = 1404\n$$\n$$\nU^{(3)}(\\hat{\\theta}) = \\frac{3h_{\\mathrm{ref}}^2}{\\sigma^2} \\sum_{i=1}^{N} (\\Delta T_i)^2 = 3 \\cdot (1) \\cdot (1400) = 4200\n$$\n非高斯性指标 $\\eta$ 是：\n$$\n\\eta = \\frac{|U^{(3)}(\\hat{\\theta})|}{(U''(\\hat{\\theta}))^{3/2}} = \\frac{|4200|}{(1404)^{3/2}} = \\frac{4200}{1404\\sqrt{1404}}\n$$\n计算数值：\n$$\n\\eta = \\frac{4200}{52607.889...} \\approx 0.0798364...\n$$\n四舍五入到四位有效数字，我们得到 $\\eta \\approx 0.07984$。",
            "answer": "$$\\boxed{0.07984}$$"
        },
        {
            "introduction": "虽然分析近似法很有用，但马尔可夫链蒙特卡洛（MCMC）等抽样方法是探索复杂高维后验分布的主力。然而，MCMC并非“即插即用”的工具；我们必须仔细诊断其输出，以确保生成的样本能真实地代表后验分布。本练习模拟了一个常见挑战——参数高度相关——并要求您解读关键的MCMC诊断指标，以识别混合不良等问题，并提出有效的改进策略。",
            "id": "3938052",
            "problem": "一个一维稳态热传导问题用于校准厚度为 $L$ 的均质平板的热导率 $k$（单位 $\\mathrm{W\\,m^{-1}\\,K^{-1}}$）和对流换热系数 $h$（单位 $\\mathrm{W\\,m^{-2}\\,K^{-1}}$）。该平板在 $x=0$ 处施加已知的均匀热通量 $q_{\\mathrm{in}}$，并在 $x=L$ 处对流冷却至环境温度 $T_{\\infty}$。在位置 $\\{x_i\\}_{i=1}^{m}$ 处采集温度场 $T(x)$ 的测量值，这些测量值带有独立的、方差未知但受工程规范限制的高斯传感器噪声（假设该方差已知且等于一个常数，记为 $\\sigma^2$）。使用三个等长的独立马尔可夫链蒙特卡洛 (MCMC) 链来探索 $(k,h)$ 的后验分布，在预热后的平稳段上产生了以下合并诊断结果：\n\n- 共有 $3$ 条链，每条链的预热后长度为 $n=3000$。一阶滞后自相关的合并估计值为 $\\rho_1(k)=0.95$ 和 $\\rho_1(h)=0.93$。估计的积分自相关时间为 $\\hat{\\tau}_{\\mathrm{int}}(k)=120$ 和 $\\hat{\\tau}_{\\mathrm{int}}(h)=90$。\n- 在对数参数化下的估计相关性为 $\\operatorname{corr}(\\log k,\\log h)=-0.98$。\n- 参数 $k$ 的链均值为 $(170,200,185)$，相应的链内样本方差为 $(1200,1500,1100)$；参数 $h$ 的链均值为 $(70,85,75)$，相应的链内样本方差为 $(400,500,350)$。\n- 估计的 Gelman–Rubin 潜在尺度缩减因子 $\\hat{R}$（以经典的未分割形式计算）报告为 $\\hat{R}(k)\\approx 1.11$ 和 $\\hat{R}(h)\\approx 1.09$。\n\n假设确定性正向模型遵循具有恒定物性和稳态条件的热传导和对流物理定律，并且在给定 $(k,h)$ 的情况下，数据的似然是高斯分布，其均值由每个 $x_i$ 处的模型预测给出，方差为 $\\sigma^2$。基于热传导和对流的基本物理关系，以及有效样本量、自相关和 $\\hat{R}$ 的核心定义，以下哪个选项最恰当地诊断了链的混合和收敛行为，并提出了针对根本原因的有效补救措施？\n\nA. 后验分布在 $(k,h)$ 上呈现出一个由可加的热阻 $L/k$ 和 $1/h$ 引起的狭窄、强相关的脊，这与 $\\operatorname{corr}(\\log k,\\log h)=-0.98$、小的有效样本量以及 $\\hat{R}>1.05$ 一致。补救措施：使用与后验协方差对齐的协方差自适应分块提议对 $(k,h)$ 进行联合采样，或者重新参数化为 $(r_{\\mathrm{tot}},\\mathrm{Bi})$，其中 $r_{\\mathrm{tot}}=L/k+1/h$ 和 $\\mathrm{Bi}=hL/k$，并使用对数变换以强制正性；或者，使用几何感知 MCMC，例如带质量矩阵自适应的哈密顿蒙特卡洛。这些操作应能增加有效样本量并将 $\\hat{R}$ 降低至趋近于 $1$。\n\nB. 高自相关最好通过将每条链稀疏化 $10$ 倍来解决，这将使有效样本量大约增加 $10\\times$，并将 $\\hat{R}$ 降低到 $1.05$ 以下，而无需任何重新参数化或分块。\n\nC. 在保持相同采样器和每条链长度的情况下，将链的数量从 $3$ 增加到 $10$，即使自相关和参数相关性仍然很高，也将使 $\\hat{R}$ 趋向于 $1$ 并解决混合病态问题。\n\nD. 减小随机游走提议的步长将降低自相关并增加有效样本量；保持对 $k$ 和 $h$ 的单参数更新是足够的，因此不需要分块或重新参数化。\n\n选择唯一的最佳选项。",
            "solution": "用户要求对问题陈述进行批判性验证，然后是详细的解答和对所提供选项的评估。\n\n### 问题验证\n\n**第 1 步：提取已知条件**\n\n-   **物理系统：** 一维稳态热传导，均质平板。\n-   **厚度：** $L$。\n-   **用于校准的参数：** 热导率 $k$ ($\\mathrm{W\\,m^{-1}\\,K^{-1}}$) 和对流换热系数 $h$ ($\\mathrm{W\\,m^{-2}\\,K^{-1}}$)。\n-   **$x=0$ 处的边界条件：** 均匀施加的热通量，$q_{\\mathrm{in}}$。\n-   **$x=L$ 处的边界条件：** 对流冷却至环境温度 $T_{\\infty}$。\n-   **测量数据：** 在位置 $\\{x_i\\}_{i=1}^{m}$ 处的温度测量值 $T(x_i)$。\n-   **误差模型：** 独立的、具有已知恒定方差 $\\sigma^2$ 的高斯传感器噪声。\n-   **推断方法：** 马尔可夫链蒙特卡洛 (MCMC)。\n-   **MCMC 诊断：**\n    -   链的数量：$3$。\n    -   每条链的预热后样本数：$n=3000$。\n    -   一阶滞后自相关：$\\rho_1(k)=0.95$，$\\rho_1(h)=0.93$。\n    -   估计的积分自相关时间 (IAT)：$\\hat{\\tau}_{\\mathrm{int}}(k)=120$，$\\hat{\\tau}_{\\mathrm{int}}(h)=90$。\n    -   对数参数相关性：$\\operatorname{corr}(\\log k,\\log h)=-0.98$。\n    -   $k$ 的链均值：$(170, 200, 185)$。\n    -   $k$ 的链内样本方差：$(1200, 1500, 1100)$。\n    -   $h$ 的链均值：$(70, 85, 75)$。\n    -   $h$ 的链内样本方差：$(400, 500, 350)$。\n    -   Gelman–Rubin 潜在尺度缩减因子：$\\hat{R}(k)\\approx 1.11$，$\\hat{R}(h)\\approx 1.09$。\n\n**第 2 步：使用提取的已知条件进行验证**\n\n1.  **科学依据：** 该问题基于热传导的基本定律。对于具有恒定物性的一维稳态热传导，其控制方程为 $\\frac{d^2T}{dx^2}=0$。边界条件是在 $x=0$ 处的诺伊曼条件（$-k\\frac{dT}{dx} = q_{\\mathrm{in}}$）和在 $x=L$ 处的罗宾条件（$-k\\frac{dT}{dx} = h(T(L)-T_{\\infty})$）。这个边值问题的解是：\n    $$T(x) = q_{\\mathrm{in}} \\left( \\frac{L-x}{k} + \\frac{1}{h} \\right) + T_{\\infty}$$\n    该模型提供了参数 $(k,h)$ 与可观测温度 $T(x)$ 之间的确定性联系。使用 MCMC 和高斯似然从含噪声数据中推断参数是贝叶斯统计推断和不确定性量化 (UQ) 中的标准且成熟的方法。所有缩写和诊断工具（$\\rho_1$、$\\hat{\\tau}_{\\mathrm{int}}$、$\\hat{R}$、$\\operatorname{corr}$）都是计算统计学领域的标准工具。该问题在科学上是合理的。\n\n2.  **适定性与一致性：** 正向模型 $T(x) \\propto \\frac{L-x}{k} + \\frac{1}{h}$ 的结构揭示了参数 $k$ 和 $h$ 之间的强耦合。具体来说，对于 $x=0$ 处的温度，传导热阻项 $L/k$ 和对流热阻项 $1/h$ 是可加的。任何能为形如 $(A/k + B/h)$ 的表达式提供相似值的 $(k,h)$ 对都会产生相似的模型预测，从而导致似然函数具有一个长而窄的弯曲脊或谷。这表明 $k$ 和 $h$ 之间存在强负相关（或其倒数之间存在强正相关），这使得参数估计具有挑战性。所提供的诊断结果 $\\operatorname{corr}(\\log k,\\log h)=-0.98$ 是这种物理模型结构的直接且预期的结果。高自相关（$\\rho_1 > 0.9$）、高积分自相关时间（$\\hat{\\tau}_{\\mathrm{int}} \\ge 90$）和大的 Gelman-Rubin 因子（$\\hat{R} > 1.05$）都是 MCMC 采样器在处理高度相关的后验分布时遇到困难的典型症状。快速检查给定的链统计数据可以证实报告的 $\\hat{R}$ 值是合理的，表明问题数据是内部一致的。该问题是适定的。\n\n3.  **客观性与清晰度：** 问题陈述使用了精确、客观和定量的语言。没有歧义或主观性陈述。\n\n**第 3 步：结论与行动**\n问题陈述是有效的。它有科学依据，内部一致，且表述清晰。所提供的数据代表了由于强参数相关性而导致 MCMC 混合不良的典型案例，而这种相关性是由物理原因驱动的。任务是诊断这种情况并确定最合适的补救措施。\n\n### 解答推导与选项分析\n\n问题的核心在于解释 MCMC 诊断结果，以理解采样器的性能及其根本原因。\n\n1.  **MCMC 性能诊断：**\n    -   **收敛性：** Gelman-Rubin 诊断值 $\\hat{R}(k)\\approx 1.11$ 和 $\\hat{R}(h)\\approx 1.09$ 显著大于 $1$。通常，该值应接近 $1.0$（例如 $1.05$）才能宣告收敛。这表明多个链未能成功探索相同的分布；链间方差与链内方差相比是显著的。\n    -   **混合与效率：** 一阶滞后自相关 $\\rho_1(k)=0.95$ 和 $\\rho_1(h)=0.93$ 极高。这意味着连续的样本几乎相同，链在参数空间中的探索非常缓慢（混合不良）。这由积分自相关时间（IAT）$\\hat{\\tau}_{\\mathrm{int}}$ 来量化。一个理想的采样器应该有 $\\tau_{\\mathrm{int}} \\approx 1$。在这里，$\\hat{\\tau}_{\\mathrm{int}}(k)=120$ 和 $\\hat{\\tau}_{\\mathrm{int}}(h)=90$ 的值非常高。\n    -   **有效样本量 (ESS)：** ESS 是指与自相关样本携带相同信息量的独立样本数量。它的计算公式为 $ESS = N_{total} / \\hat{\\tau}_{\\mathrm{int}}$。总样本量为 $N_{total} = 3 \\times 3000 = 9000$，我们得到 $ESS(k) = 9000/120 = 75$ 和 $ESS(h) = 9000/90 = 100$。这些值非常低，不足以进行可靠的后验推断。\n\n2.  **根本原因分析：**\n    极高的负相关性 $\\operatorname{corr}(\\log k,\\log h)=-0.98$ 是解释上述所有病态问题的关键变量。这种相关性不是数值假象，而是由正向模型的物理特性引起的，如验证步骤所示。似然函数仅在 $(k,h)$ 参数空间的一个非常狭窄的区域内很高。一个沿着坐标轴进行提议的标准 MCMC 算法（例如，固定 $h$ 更新 $k$，然后再反过来）将非常低效。任何沿一个轴的合理大小的步长都可能使提议的状态远离高概率脊，导致高拒绝率并迫使采样器采取微小的步长，从而导致高自相关。\n\n3.  **评估建议的补救措施：**\n    一个有效的补救措施必须直接解决强参数相关性问题。\n\n**A. 后验分布在 $(k,h)$ 上呈现出一个由可加的热阻 $L/k$ 和 $1/h$ 引起的狭窄、强相关的脊，这与 $\\operatorname{corr}(\\log k,\\log h)=-0.98$、小的有效样本量以及 $\\hat{R}>1.05$ 一致。补救措施：使用与后验协方差对齐的协方差自适应分块提议对 $(k,h)$ 进行联合采样，或者重新参数化为 $(r_{\\mathrm{tot}},\\mathrm{Bi})$，其中 $r_{\\mathrm{tot}}=L/k+1/h$ 和 $\\mathrm{Bi}=hL/k$，并使用对数变换以强制正性；或者，使用几何感知 MCMC，例如带质量矩阵自适应的哈密顿蒙特卡洛。这些操作应能增加有效样本量并将 $\\hat{R}$ 降低至趋近于 $1$。**\n\n-   **分析：** 该选项提供了完美的诊断，将物理模型（$L/k$ 和 $1/h$）与统计问题（相关的脊）联系起来，并正确地将其与所有观察到的诊断值联系起来。然后它提出了三种强大且先进的补救措施，这些措施直接针对相关的根本原因：\n    1.  **协方差自适应分块：** 使用形状类似于后验分布（即沿脊部拉长）的提议分布对 $(k,h)$ 进行联合提议，可以在高概率区域内进行大步移动，从而极大地改善混合。\n    2.  **重新参数化：** 将变量更改为相关性较低的集合，例如基于总电阻（$r_{\\mathrm{tot}}$）和毕渥数（$\\mathrm{Bi}$）的集合，可以将困难的后验几何形状转换为一个简单得多的形状，从而易于被标准采样器探索。\n    3.  **几何感知 MCMC (HMC)：** 这些方法使用梯度信息来智能地导航复杂的后验几何形状，对于高度相关的参数尤其有效。\n-   **结论：** 该选项在科学和统计上都是完美的。它正确地诊断了问题，并提出了最合适和最有效的解决方案。**正确**。\n\n**B. 高自相关最好通过将每条链稀疏化 $10$ 倍来解决，这将使有效样本量大约增加 $10\\times$，并将 $\\hat{R}$ 降低到 $1.05$ 以下，而无需任何重新参数化或分块。**\n\n-   **分析：** 该选项做出了一个根本上不正确的论断。稀疏化是丢弃样本以减少存储链中的自相关并节省内存的过程。它**不会**产生新信息或提高底层采样器的效率。有效样本量（$ESS$）是*稀疏化前*整个链信息含量的度量。$ESS$ 不会因为稀疏化而增加；充其量保持不变。声称 $ESS$ 将“大约增加 $10\\times$”是错误的。稀疏化不能修复混合不良或缺乏收敛的问题，因此它不会解决高 $\\hat{R}$ 值的问题。\n-   **结论：** 建议的补救措施基于对 MCMC 理论的严重误解。**不正确**。\n\n**C. 在保持相同采样器和每条链长度的情况下，将链的数量从 $3$ 增加到 $10$，即使自相关和参数相关性仍然很高，也将使 $\\hat{R}$ 趋向于 $1$ 并解决混合病态问题。**\n\n-   **分析：** 运行更多的并行链对于更稳健地诊断不收敛很有用，但它并不能解决问题。如果采样器效率低下，那么这 $10$ 条链中的每一条都会像原来的 $3$ 条链一样卡住和缓慢混合。$\\hat{R}$ 是链间方差与链内方差的比值；如果链仍然卡在不同的位置，这个比率将保持很大。增加更多的链不会“解决混合病态问题”。问题在于采样器无法在参数空间中导航，而不是尝试的次数不够。\n-   **结论：** 这将诊断工具与治疗工具混淆了，并且未能解决根本原因。**不正确**。\n\n**D. 减小随机游走提议的步长将降低自相关并增加有效样本量；保持对 $k$ 和 $h$ 的单参数更新是足够的，因此不需要分块或重新参数化。**\n\n-   **分析：** 该选项显示了对采样器调优和核心问题的双重误解。首先，对于随机游走采样器，减小提议步长通常会*增加*接受率，但也会*增加*自相关，因为链采取微小的步长，探索空间更慢。其次，更重要的是，它断言单参数更新是足够的。这与事实恰恰相反。采样器的失败是由于强相关性使得单参数（分量式）更新无效，无论步长如何调整。任何简单的步长调整都无法克服相关后验脊的几何挑战。\n-   **结论：** 建议的补救措施适得其反，并且忽略了问题的真正原因。**不正确**。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "在掌握了单个模型内的参数推断后，我们将更进一步，学习如何利用贝叶斯方法在多个竞争性物理模型之间进行选择。贝叶斯因子是实现这一目标的核心工具，它量化了数据支持不同模型的相对证据强度。在这个实践编码练习中，您将通过蒙特卡洛积分来计算模型证据，并进行先验敏感性分析，从而亲身体验贝叶斯模型比较的完整流程。",
            "id": "3938066",
            "problem": "考虑一个厚度为 $L$ 的均匀平板上的一维稳态热传导问题，其边界受到相互作用。该平板具有未知的导热系数 $k$（单位为 $\\mathrm{W\\,m^{-1}\\,K^{-1}}$）。位于位置 $x = 0$ 的左侧面通过一个未知的传热系数 $h$（单位为 $\\mathrm{W\\,m^{-2}\\,K^{-1}}$）与温度为 $T_{\\infty}$ 的周围流体进行对流换热。对于位于位置 $x = L$ 的右侧面，考虑了两个相互竞争的边界模型，并使用贝叶斯推断进行边界模型比较，以支持不确定性量化 (UQ)。\n\n控制方程基于傅里叶热传导定律和能量平衡。对于一维、稳态、无内部热源的情况，温度场 $T(x)$ 满足\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}x}\\left(k\\,\\frac{\\mathrm{d}T}{\\mathrm{d}x}\\right) = 0,\n$$\n且在 $x = 0$ 处的对流边界条件为\n$$\n-k\\,\\left.\\frac{\\mathrm{d}T}{\\mathrm{d}x}\\right|_{x=0} = h\\,\\left(T(0) - T_{\\infty}\\right).\n$$\n在 $x = L$ 处的两个竞争性边界模型是：\n- 模型 $\\mathcal{M}_1$（右边界等温）：$T(L) = T_L$，其中 $T_L$ 已知。\n- 模型 $\\mathcal{M}_2$（右边界绝热）：$\\left.\\frac{\\mathrm{d}T}{\\mathrm{d}x}\\right|_{x=L} = 0$。\n\n假设在位置 $x_i$ 处测量的温度受到标准差已知的独立高斯测量噪声的干扰。给定在位置 $\\{x_i\\}$ 处的温度测量向量 $\\mathbf{y} = \\{y_i\\}$，每个模型的似然函数是以模型预测温度为中心的高斯密度函数的乘积。\n\n从控制方程和边界条件出发，推导每个模型所对应的温度场 $T(x)$ 以及相应的似然 $p(\\mathbf{y}\\mid h,k,\\mathcal{M}_i)$。使用贝叶斯因子，模型比较由以下公式量化\n$$\nB_{12} = \\frac{p(\\mathbf{y} \\mid \\mathcal{M}_1)}{p(\\mathbf{y} \\mid \\mathcal{M}_2)}, \\quad \\text{其中} \\quad p(\\mathbf{y} \\mid \\mathcal{M}_i) = \\int_0^{\\infty}\\int_0^{\\infty} p(\\mathbf{y}\\mid h,k,\\mathcal{M}_i)\\,p(h)\\,p(k)\\,\\mathrm{d}h\\,\\mathrm{d}k,\n$$\n其中 $p(h)$ 和 $p(k)$ 是关于 $h$ 和 $k$ 的独立先验。通过改变 $h$ 和 $k$ 的先验来进行先验敏感性分析，并量化 $B_{12}$ 如何变化。\n\n为确保科学真实性和数值鲁棒性，排除那些使模型 $\\mathcal{M}_1$ 下的温度解在数学上奇异的参数组合。具体来说，如果 $\\left|L - \\frac{k}{h}\\right|  \\varepsilon$，则对于一个小的正常数阈值 $\\varepsilon$，将 $p(\\mathbf{y}\\mid h,k,\\mathcal{M}_1)$ 视为零。\n\n使用以下物理上和数值上一致的常数和数据：\n- 平板厚度：$L = 0.02$ $\\mathrm{m}$。\n- 环境流体温度：$T_{\\infty} = 293.0$ $\\mathrm{K}$。\n- 模型 $\\mathcal{M}_1$ 的右边界温度：$T_L = 313.0$ $\\mathrm{K}$。\n- 测量噪声标准差：$\\sigma = 0.5$ $\\mathrm{K}$。\n- 测量位置：$\\{x_i\\} = \\{0.0,\\,0.005,\\,0.010,\\,0.015,\\,0.020\\}$ $\\mathrm{m}$。\n- 温度测量值：$\\mathbf{y} = \\{313.133000,\\,313.399445,\\,312.965890,\\,313.232335,\\,312.948780\\}$ $\\mathrm{K}$。\n\n为敏感性分析定义以下四种先验情景：\n- 测试用例 $1$（均匀先验，中等支撑集）：$h \\sim \\mathrm{Uniform}(40,\\,120)$，$k \\sim \\mathrm{Uniform}(120,\\,240)$。\n- 测试用例 $2$（信息性对数正态先验）：$h \\sim \\mathrm{Lognormal}(\\mu_h,\\,\\sigma_h)$，其中 $\\mu_h = \\ln(60)$ 和 $\\sigma_h = 0.2$；$k \\sim \\mathrm{Lognormal}(\\mu_k,\\,\\sigma_k)$，其中 $\\mu_k = \\ln(180)$ 和 $\\sigma_k = 0.15$。\n- 测试用例 $3$（弥散对数正态先验）：$h \\sim \\mathrm{Lognormal}(\\mu_h,\\,\\sigma_h)$，其中 $\\mu_h = \\ln(60)$ 和 $\\sigma_h = 0.8$；$k \\sim \\mathrm{Lognormal}(\\mu_k,\\,\\sigma_k)$，其中 $\\mu_k = \\ln(180)$ 和 $\\sigma_k = 0.8$。\n- 测试用例 $4$（奇异边界比率附近的均匀先验）：$h \\sim \\mathrm{Uniform}(800,\\,1200)$，$k \\sim \\mathrm{Uniform}(10,\\,30)$。\n\n上述对数正态分布的参数化方式为：如果 $Z \\sim \\mathcal{N}(\\mu, \\sigma^2)$，则随机变量 $X = \\exp(Z)$ 服从 Lognormal$(\\mu,\\sigma)$ 分布。\n\n通过数值估计每个模型的证据，实现对每个测试用例的贝叶斯因子 $B_{12}$ 的计算。对于 $\\mathcal{M}_1$，使用蒙特卡洛积分，通过在指定先验下计算似然的期望来估计 $p(\\mathbf{y}\\mid \\mathcal{M}_1)$，为保证可复现性，使用足够大的固定数量的样本。对于 $\\mathcal{M}_2$，使用绝热边界所蕴含的精确模型预测，并直接计算似然。使用奇异点排除阈值 $\\varepsilon = 10^{-6}$ $\\mathrm{m}$。\n\n您的程序应生成单行输出，其中包含四个测试用例的贝叶斯因子，形式为用方括号括起来的逗号分隔列表（例如，$\\left[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4\\right]$）。每个贝叶斯因子必须是无量纲浮点数。最终的数值输出不应包含任何物理单位。\n\n测试套件覆盖要求：\n- 包括上述四个测试用例。\n- 程序必须能处理一般情况（测试用例 $1$）、信息性先验（测试用例 $2$）、弥散先验（测试用例 $3$）以及先验质量集中在奇异比率 $L \\approx \\frac{k}{h}$ 附近的边界情况（测试用例 $4$）。\n- 在指定的奇异点排除条件下，输出必须是可复现的且数值稳定的。",
            "solution": "该问题要求对一维稳态热传导的两个竞争性边界条件模型进行贝叶斯模型比较。该比较通过贝叶斯因子 $B_{12}$ 来量化，这需要计算每个模型的边际似然（或称模型证据）。通过在四个不同的未知模型参数（导热系数 $k$ 和对流传热系数 $h$）的先验情景下评估 $B_{12}$，来进行敏感性分析。\n\n均匀材料中无内部热源的一维稳态热传导的基本控制方程源于傅里叶定律和能量守恒原理。其形式如下：\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}x}\\left(k\\,\\frac{\\mathrm{d}T}{\\mathrm{d}x}\\right) = 0\n$$\n由于导热系数 $k$ 被假定为常数且非零，该方程简化为一维拉普拉斯方程：\n$$\n\\frac{\\mathrm{d}^2T}{\\mathrm{d}x^2} = 0\n$$\n此常微分方程的通解是一个线性温度分布：\n$$\nT(x) = C_1 x + C_2\n$$\n其中 $C_1$ 和 $C_2$ 是由边界条件决定的积分常数。\n\n左侧面（$x=0$）的边界条件是对流，由下式给出：\n$$\n-k\\,\\left.\\frac{\\mathrm{d}T}{\\mathrm{d}x}\\right|_{x=0} = h\\,\\left(T(0) - T_{\\infty}\\right)\n$$\n\n我们现在为两个竞争模型 $\\mathcal{M}_1$ 和 $\\mathcal{M}_2$ 分别推导具体的温度分布 $T(x)$。\n\n**模型 $\\mathcal{M}_1$：右边界等温**\n该模型假设右侧面（$x=L$）的温度为固定值 $T_L$。两个边界条件是：\n1. $T(L) = T_L$\n2. $-k\\,\\left.\\frac{\\mathrm{d}T}{\\mathrm{d}x}\\right|_{x=0} = h\\,\\left(T(0) - T_{\\infty}\\right)$\n\n从通解可知，$\\frac{\\mathrm{d}T}{\\mathrm{d}x} = C_1$。应用第一个边界条件：\n$$\nT(L) = C_1 L + C_2 = T_L \\implies C_2 = T_L - C_1 L\n$$\n将 $C_2$ 代入通解，得到用 $C_1$ 表示的温度场：\n$$\nT(x) = C_1 x + T_L - C_1 L = C_1(x-L) + T_L\n$$\n现在，我们使用在 $x=0$ 处的第二个边界条件。首先，我们求得 $T(0) = C_1(0-L) + T_L = -C_1 L + T_L$。该条件变为：\n$$\n-k C_1 = h \\left( (-C_1 L + T_L) - T_{\\infty} \\right)\n$$\n求解 $C_1$：\n$$\n-k C_1 = -h L C_1 + h(T_L - T_{\\infty})\n$$\n$$\nC_1(hL - k) = h(T_L - T_{\\infty})\n$$\n$$\nC_1 = \\frac{h(T_L - T_{\\infty})}{hL - k}\n$$\n将这个 $C_1$ 的表达式代回 $T(x)$ 的方程，我们得到模型 $\\mathcal{M}_1$ 的温度分布，它依赖于参数 $h$ 和 $k$：\n$$\nT_1(x; h, k) = \\frac{h(T_L - T_{\\infty})}{hL - k}(x-L) + T_L\n$$\n当分母为零，即 $hL - k = 0$ 或 $k/h = L$ 时，该解表现出奇异性。按照要求，我们必须通过排除满足 $| L - k/h |  \\varepsilon$（对于一个小的阈值 $\\varepsilon$）的参数组合来处理此问题。\n\n**模型 $\\mathcal{M}_2$：右边界绝热**\n该模型假设右侧面（$x=L$）没有热通量。两个边界条件是：\n1. $\\left.\\frac{\\mathrm{d}T}{\\mathrm{d}x}\\right|_{x=L} = 0$\n2. $-k\\,\\left.\\frac{\\mathrm{d}T}{\\mathrm{d}x}\\right|_{x=0} = h\\,\\left(T(0) - T_{\\infty}\\right)$\n\n从通解可知，$\\frac{\\mathrm{d}T}{\\mathrm{d}x} = C_1$。第一个边界条件直接意味着：\n$$\nC_1 = 0\n$$\n这使得通解简化为 $T(x) = C_2$，意味着整个平板的温度是均匀的。应用第二个边界条件：\n$$\n-k \\cdot (0) = h(T(0) - T_{\\infty}) \\implies 0 = h(C_2 - T_{\\infty})\n$$\n由于 $h$ 是一个物理参数并且必须为正（$h>0$），这要求 $C_2 - T_{\\infty} = 0$，即 $C_2 = T_{\\infty}$。\n因此，模型 $\\mathcal{M}_2$ 的温度分布是恒定的，且与参数 $h$ 和 $k$ 无关：\n$$\nT_2(x) = T_{\\infty}\n$$\n\n**贝叶斯模型比较**\n目标是计算贝叶斯因子 $B_{12} = p(\\mathbf{y} \\mid \\mathcal{M}_1) / p(\\mathbf{y} \\mid \\mathcal{M}_2)$，其中 $\\mathbf{y} = \\{y_i\\}$ 是测量温度的向量。项 $p(\\mathbf{y} \\mid \\mathcal{M}_i)$ 是模型 $\\mathcal{M}_i$ 的模型证据。它是通过对未知参数 $h$ 和 $k$ 的先验分布进行边缘化似然函数得到的：\n$$\np(\\mathbf{y} \\mid \\mathcal{M}_i) = \\int_0^{\\infty}\\int_0^{\\infty} p(\\mathbf{y}\\mid h,k,\\mathcal{M}_i)\\,p(h)\\,p(k)\\,\\mathrm{d}h\\,\\mathrm{d}k\n$$\n问题陈述中指出，测量误差是独立的、服从高斯分布且具有已知的标准差 $\\sigma$。对于给定的模型 $\\mathcal{M}_i$ 和参数集 $\\{h, k\\}$，其似然函数是高斯概率密度函数的乘积：\n$$\np(\\mathbf{y}\\mid h,k,\\mathcal{M}_i) = \\prod_{j=1}^{N_m} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_j - T_i(x_j; h, k))^2}{2\\sigma^2}\\right)\n$$\n其中 $N_m$ 是测量次数。为保证数值稳定性，最好使用对数似然：\n$$\n\\ln p(\\mathbf{y}\\mid h,k,\\mathcal{M}_i) = \\sum_{j=1}^{N_m} \\left( -\\frac{1}{2}\\ln(2\\pi\\sigma^2) - \\frac{(y_j - T_i(x_j; h, k))^2}{2\\sigma^2} \\right)\n$$\n\n**$\\mathcal{M}_2$ 的证据计算**\n对于模型 $\\mathcal{M}_2$，温度预测 $T_2(x) = T_{\\infty}$ 与 $h$ 和 $k$ 无关。因此，似然 $p(\\mathbf{y}\\mid h,k,\\mathcal{M}_2)$ 也与 $h$ 和 $k$ 无关。我们将这个常数似然表示为 $L_2$。证据的积分简化如下：\n$$\np(\\mathbf{y} \\mid \\mathcal{M}_2) = \\int_0^{\\infty}\\int_0^{\\infty} L_2\\,p(h)\\,p(k)\\,\\mathrm{d}h\\,\\mathrm{d}k = L_2 \\int_0^{\\infty} p(h)\\,\\mathrm{d}h \\int_0^{\\infty} p(k)\\,\\mathrm{d}k\n$$\n由于 $p(h)$ 和 $p(k)$ 是概率密度函数，它们在其支撑集上的积分等于 $1$。因此，$\\mathcal{M}_2$ 的证据就是似然本身，可以直接从数据和常数预测 $T_{\\infty}$ 计算得出：\n$$\np(\\mathbf{y} \\mid \\mathcal{M}_2) = L_2 = \\prod_{j=1}^{N_m} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_j - T_{\\infty})^2}{2\\sigma^2}\\right)\n$$\n\n**$\\mathcal{M}_1$ 的证据计算**\n对于模型 $\\mathcal{M}_1$，温度预测 $T_1(x; h, k)$ 依赖于 $h$ 和 $k$，所以证据积分不能简化。我们必须对其进行数值评估。按照指示，我们使用蒙特卡洛积分。证据近似为在从先验分布 $p(h)$ 和 $p(k)$ 中抽取的大量样本 $N_s$ 上，似然函数的平均值：\n$$\np(\\mathbf{y} \\mid \\mathcal{M}_1) \\approx \\frac{1}{N_s} \\sum_{s=1}^{N_s} p(\\mathbf{y}\\mid h_s, k_s, \\mathcal{M}_1), \\quad \\text{其中 } (h_s, k_s) \\sim p(h)p(k)\n$$\n在计算此和时，落入奇异区域 $|L-k_s/h_s|  \\varepsilon$ 的样本 $(h_s, k_s)$ 的似然被赋值为 $0$。一种从对数似然计算此均值的数值稳健方法是使用 log-sum-exp 技巧：\n$$\n\\ln p(\\mathbf{y} \\mid \\mathcal{M}_1) \\approx \\mathrm{logsumexp}_{s=1}^{N_s} \\left( \\ln p(\\mathbf{y}\\mid h_s, k_s, \\mathcal{M}_1) \\right) - \\ln(N_s)\n$$\n其中，奇异样本的对数似然被设置为 $-\\infty$。\n\n最后一步是为四种指定的先验情景中的每一种计算贝叶斯因子 $B_{12}$。$B_{12} \\gg 1$ 的值表示支持模型 $\\mathcal{M}_1$ 相对于 $\\mathcal{M}_2$ 的证据很强。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import logsumexp\n\ndef solve():\n    \"\"\"\n    Computes the Bayes factor B12 for four prior scenarios to compare\n    two heat conduction models.\n    \"\"\"\n    # Set a random seed for reproducibility of Monte Carlo integration\n    np.random.seed(0)\n\n    # --- Problem Constants and Data ---\n    L = 0.02  # Slab thickness, m\n    T_inf = 293.0  # Ambient fluid temperature, K\n    T_L = 313.0  # Right boundary temperature for M1, K\n    sigma = 0.5  # Measurement noise standard deviation, K\n    epsilon = 1e-6  # Singularity exclusion threshold, m\n    \n    # Measurement locations and data\n    x_obs = np.array([0.0, 0.005, 0.010, 0.015, 0.020])  # m\n    y_obs = np.array([313.133000, 313.399445, 312.965890, 313.232335, 312.948780])  # K\n    N_m = len(x_obs)\n    \n    # Monte Carlo simulation parameters\n    N_s = 2_000_000  # Number of samples for Monte Carlo integration\n\n    # --- Define Prior Scenarios ---\n    # Each test case is a tuple of two dicts: (h_prior_def, k_prior_def)\n    test_cases = [\n        # Case 1: Uniform priors, moderate support\n        ({'dist': 'uniform', 'low': 40.0, 'high': 120.0}, \n         {'dist': 'uniform', 'low': 120.0, 'high': 240.0}),\n        # Case 2: Informative Lognormal priors\n        ({'dist': 'lognormal', 'mu': np.log(60.0), 'sigma': 0.2}, \n         {'dist': 'lognormal', 'mu': np.log(180.0), 'sigma': 0.15}),\n        # Case 3: Diffuse Lognormal priors\n        ({'dist': 'lognormal', 'mu': np.log(60.0), 'sigma': 0.8}, \n         {'dist': 'lognormal', 'mu': np.log(180.0), 'sigma': 0.8}),\n        # Case 4: Uniform priors near singular boundary ratio\n        ({'dist': 'uniform', 'low': 800.0, 'high': 1200.0}, \n         {'dist': 'uniform', 'low': 10.0, 'high': 30.0}),\n    ]\n\n    # --- Helper Functions ---\n    def generate_samples(prior_def, num_samples):\n        \"\"\"Generates samples from a specified prior distribution.\"\"\"\n        if prior_def['dist'] == 'uniform':\n            return np.random.uniform(prior_def['low'], prior_def['high'], num_samples)\n        elif prior_def['dist'] == 'lognormal':\n            return np.random.lognormal(mean=prior_def['mu'], sigma=prior_def['sigma'], size=num_samples)\n        else:\n            raise ValueError(f\"Unknown distribution: {prior_def['dist']}\")\n\n    # --- Evidence Calculation for Model 2 (M2) ---\n    # For M2, T_pred is constant T_inf, independent of h and k.\n    # The evidence is just the likelihood, as it's constant over the prior space.\n    T_pred_M2 = np.full_like(y_obs, T_inf)\n    sum_sq_err_M2 = np.sum((y_obs - T_pred_M2)**2)\n    log_evidence_M2 = -0.5 * N_m * np.log(2 * np.pi * sigma**2) - sum_sq_err_M2 / (2 * sigma**2)\n\n    results = []\n    for h_prior, k_prior in test_cases:\n        # --- Evidence Calculation for Model 1 (M1) via Monte Carlo ---\n        \n        # 1. Draw samples from prior distributions\n        h_samples = generate_samples(h_prior, N_s)\n        k_samples = generate_samples(k_prior, N_s)\n\n        # 2. Handle singularity\n        # We use a mask to identify non-singular samples\n        # Singular if |L - k/h|  epsilon\n        # We work with log-likelihoods, so singular samples get -inf\n        is_singular = np.abs(L - k_samples / h_samples)  epsilon\n        \n        # 3. Calculate predicted temperatures for M1 for all samples (vectorized)\n        # Denominator in the C1 expression\n        denominator = h_samples * L - k_samples\n        \n        # A second singularity case is when denominator is exactly zero.\n        # This will produce `inf` or `nan` in C1, which leads to `inf` in log_likelihoods\n        # We need to filter these out as well.\n        # We can add this to the singular mask.\n        is_singular |= (denominator == 0)\n        \n        # To avoid division by zero, we can replace zero denominators with a non-zero value\n        # This is safe because we will set the log-likelihood for these to -inf anyway.\n        denominator[is_singular] = 1.0\n\n        C1 = h_samples * (T_L - T_inf) / denominator\n        \n        # Broadcasting C1 (N_s,) and x_obs (N_m,) to get T_pred (N_s, N_m)\n        T_pred_M1 = C1[:, np.newaxis] * (x_obs[np.newaxis, :] - L) + T_L\n\n        # 4. Calculate log-likelihood for each sample\n        # Broadcasting y_obs (N_m,) with T_pred_M1 (N_s, N_m)\n        sum_sq_err_M1 = np.sum((y_obs[np.newaxis, :] - T_pred_M1)**2, axis=1)\n        log_likelihoods = -0.5 * N_m * np.log(2 * np.pi * sigma**2) - sum_sq_err_M1 / (2 * sigma**2)\n\n        # 5. Apply singularity exclusion\n        log_likelihoods[is_singular] = -np.inf\n\n        # 6. Compute log evidence using log-sum-exp for numerical stability\n        # Find the number of valid (non-singular) samples for averaging\n        num_valid_samples = N_s - np.sum(is_singular)\n        if num_valid_samples == 0:\n            log_evidence_M1 = -np.inf\n        else:\n            # We average over the total number of samples N_s as per Monte Carlo definition\n            # The -inf values for singular samples correctly make their likelihood contribution zero.\n            log_evidence_M1 = logsumexp(log_likelihoods) - np.log(N_s)\n\n        # --- Compute Bayes Factor ---\n        log_B12 = log_evidence_M1 - log_evidence_M2\n        B12 = np.exp(log_B12)\n        \n        # In case evidence for M1 is zero, B12 would be 0.\n        if np.isinf(log_evidence_M1) and log_evidence_M1  0:\n            B12 = 0.0\n\n        results.append(B12)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}