{
    "hands_on_practices": [
        {
            "introduction": "Before building algorithms to solve optimization problems, we must first understand the mathematical conditions that define an optimal solution. This foundational exercise () guides you through the derivation of the Karush-Kuhn-Tucker (KKT) conditions for a general thermal topology optimization problem. Mastering this derivation solidifies your understanding of how constraints are handled in optimization and reveals the origin of the update schemes used in practice.",
            "id": "3998279",
            "problem": "Consider a thermal topology optimization problem over a bounded open domain $\\Omega \\subset \\mathbb{R}^{d}$ with Lipschitz boundary, where the design variable is a material density field $\\rho:\\Omega \\to [0,1]$. Let the objective functional $J(\\rho)$ be the reduced cost obtained by solving the steady-state heat conduction for each admissible $\\rho$ and then evaluating a differentiable performance functional; assume $J:L^{\\infty}(\\Omega)\\to\\mathbb{R}$ is Fréchet differentiable with derivative denoted by the variational sensitivity $\\frac{\\delta J}{\\delta \\rho}(x)$. The design is subject to a global volume constraint and bound constraints,\n$$\n\\int_{\\Omega} \\rho(x)\\, dx \\le V^{*}, \\quad 0 \\le \\rho(x) \\le 1 \\quad \\text{for almost every } x \\in \\Omega.\n$$\nStarting from the Lagrangian of the constrained problem, derive the necessary Karush–Kuhn–Tucker (KKT) optimality conditions in terms of stationarity, primal feasibility, dual feasibility, and complementary slackness. Use the following structure of the Lagrangian with multipliers $\\lambda \\in \\mathbb{R}$ for the volume constraint and $\\alpha(x),\\beta(x)$ for the pointwise lower and upper bound constraints, respectively:\n$$\n\\mathcal{L}(\\rho,\\lambda,\\alpha,\\beta) = J(\\rho) + \\lambda\\!\\left(\\int_{\\Omega} \\rho(x)\\, dx - V^{*}\\right) + \\int_{\\Omega} \\alpha(x)\\,(-\\rho(x))\\, dx + \\int_{\\Omega} \\beta(x)\\,(\\rho(x)-1)\\, dx,\n$$\nwhere $\\alpha,\\beta \\in L^{2}(\\Omega)$ represent the distributed multipliers. Clearly state the sign conditions on the multipliers, and the complementary slackness relations associated with the active and inactive constraints. Your derivation should start from the calculus of variations and constrained optimization first principles, including the fundamental lemma of the calculus of variations and the inequality-constraint optimality framework.\n\nAs your final answer, report the pointwise stationarity condition for the KKT system in the form of a single analytic expression involving $\\frac{\\delta J}{\\delta \\rho}(x)$, $\\lambda$, $\\alpha(x)$, and $\\beta(x)$, valid almost everywhere in $\\Omega$. No numerical evaluation is required. Do not include any units in your final answer.",
            "solution": "The problem of finding an optimal material density distribution $\\rho(x)$ is a constrained optimization problem in an infinite-dimensional function space. The necessary conditions for an optimal solution are given by the Karush–Kuhn–Tucker (KKT) conditions, which generalize the method of Lagrange multipliers to handle inequality constraints. We will derive these conditions systematically based on the provided Lagrangian.\n\nThe optimization problem can be stated as:\nMinimize $J(\\rho)$\nSubject to:\n$g_1(\\rho) = \\int_{\\Omega} \\rho(x)\\, dx - V^{*} \\le 0$\n$g_{2,x}(\\rho) = -\\rho(x) \\le 0 \\quad$ for a.e. $x \\in \\Omega$\n$g_{3,x}(\\rho) = \\rho(x) - 1 \\le 0 \\quad$ for a.e. $x \\in \\Omega$\n\nThe Lagrangian for this problem is given as:\n$$\n\\mathcal{L}(\\rho,\\lambda,\\alpha,\\beta) = J(\\rho) + \\lambda g_1(\\rho) + \\int_{\\Omega} \\alpha(x) g_{2,x}(\\rho) \\, dx + \\int_{\\Omega} \\beta(x) g_{3,x}(\\rho) \\, dx\n$$\nSubstituting the specific forms of the constraints, we have:\n$$\n\\mathcal{L}(\\rho,\\lambda,\\alpha,\\beta) = J(\\rho) + \\lambda\\left(\\int_{\\Omega} \\rho(x)\\, dx - V^{*}\\right) + \\int_{\\Omega} \\alpha(x)\\,(-\\rho(x))\\, dx + \\int_{\\Omega} \\beta(x)\\,(\\rho(x)-1)\\, dx\n$$\nThis can be rewritten by grouping terms involving $\\rho(x)$:\n$$\n\\mathcal{L}(\\rho,\\lambda,\\alpha,\\beta) = J(\\rho) + \\int_{\\Omega} \\left[ \\lambda \\rho(x) - \\alpha(x) \\rho(x) + \\beta(x) \\rho(x) \\right]\\, dx - \\lambda V^{*} - \\int_{\\Omega} \\beta(x) \\, dx\n$$\n\nThe KKT conditions are a set of four conditions that must be satisfied at a regular point that is a local minimum: stationarity, primal feasibility, dual feasibility, and complementary slackness.\n\n1.  **Stationarity Condition**\nThe stationarity condition requires that the first variation (or Gâteaux derivative) of the Lagrangian with respect to the primal variable $\\rho$ vanishes for all admissible variations $\\delta \\rho$. Let $\\rho^*$ be an optimal density field. Then for any admissible variation $\\delta \\rho$, we must have:\n$$\n\\delta_{\\rho} \\mathcal{L}(\\rho^*, \\lambda, \\alpha, \\beta; \\delta\\rho) = \\left. \\frac{d}{d\\epsilon} \\mathcal{L}(\\rho^* + \\epsilon \\delta\\rho, \\dots) \\right|_{\\epsilon=0} = 0\n$$\nWe compute the variation of each term in the Lagrangian:\n-   The variation of the objective functional $J(\\rho)$ is, by definition of the variational sensitivity $\\frac{\\delta J}{\\delta \\rho}$, given by:\n    $$\n    \\delta_{\\rho} J(\\rho; \\delta\\rho) = \\int_{\\Omega} \\frac{\\delta J}{\\delta \\rho}(x) \\delta\\rho(x) \\, dx\n    $$\n-   The variations of the constraint terms are calculated as follows. Since they are linear in $\\rho$, their variations are straightforward:\n    $$\n    \\delta_{\\rho} \\left[ \\lambda\\left(\\int_{\\Omega} \\rho(x)\\, dx - V^{*}\\right) \\right] = \\lambda \\int_{\\Omega} \\delta\\rho(x) \\, dx\n    $$\n    $$\n    \\delta_{\\rho} \\left[ \\int_{\\Omega} \\alpha(x)\\,(-\\rho(x))\\, dx \\right] = -\\int_{\\Omega} \\alpha(x) \\delta\\rho(x) \\, dx\n    $$\n    $$\n    \\delta_{\\rho} \\left[ \\int_{\\Omega} \\beta(x)\\,(\\rho(x)-1)\\, dx \\right] = \\int_{\\Omega} \\beta(x) \\delta\\rho(x) \\, dx\n    $$\nCombining these results, the first variation of the Lagrangian is:\n$$\n\\delta_{\\rho} \\mathcal{L} = \\int_{\\Omega} \\frac{\\delta J}{\\delta \\rho}(x) \\delta\\rho(x) \\, dx + \\lambda \\int_{\\Omega} \\delta\\rho(x) \\, dx - \\int_{\\Omega} \\alpha(x) \\delta\\rho(x) \\, dx + \\int_{\\Omega} \\beta(x) \\delta\\rho(x) \\, dx = 0\n$$\nFactoring out the arbitrary variation $\\delta\\rho(x)$:\n$$\n\\int_{\\Omega} \\left( \\frac{\\delta J}{\\delta \\rho}(x) + \\lambda - \\alpha(x) + \\beta(x) \\right) \\delta\\rho(x) \\, dx = 0\n$$\nAccording to the fundamental lemma of the calculus of variations, if this integral identity holds for all admissible variations $\\delta\\rho(x)$ (e.g., all $\\delta \\rho \\in L^2(\\Omega)$), then the term in the parentheses must be zero almost everywhere in $\\Omega$. This yields the pointwise stationarity condition:\n$$\n\\frac{\\delta J}{\\delta \\rho}(x) + \\lambda - \\alpha(x) + \\beta(x) = 0 \\quad \\text{for a.e. } x \\in \\Omega\n$$\n\n2.  **Primal Feasibility**\nThe optimal solution $\\rho(x)$ must satisfy the original problem constraints:\n$$\n\\int_{\\Omega} \\rho(x)\\, dx - V^{*} \\le 0\n$$\n$$\n-\\rho(x) \\le 0 \\implies \\rho(x) \\ge 0 \\quad \\text{for a.e. } x \\in \\Omega\n$$\n$$\n\\rho(x) - 1 \\le 0 \\implies \\rho(x) \\le 1 \\quad \\text{for a.e. } x \\in \\Omega\n$$\n\n3.  **Dual Feasibility**\nFor a minimization problem with inequality constraints of the form $g_i(\\rho) \\le 0$, the corresponding Lagrange multipliers must be non-negative.\n-   For the volume constraint $\\int_{\\Omega} \\rho(x)\\, dx - V^{*} \\le 0$, the multiplier $\\lambda$ must satisfy:\n    $$\n    \\lambda \\ge 0\n    $$\n-   For the pointwise lower bound constraint $-\\rho(x) \\le 0$, the multiplier field $\\alpha(x)$ must satisfy:\n    $$\n    \\alpha(x) \\ge 0 \\quad \\text{for a.e. } x \\in \\Omega\n    $$\n-   For the pointwise upper bound constraint $\\rho(x) - 1 \\le 0$, the multiplier field $\\beta(x)$ must satisfy:\n    $$\n    \\beta(x) \\ge 0 \\quad \\text{for a.e. } x \\in \\Omega\n    $$\n\n4.  **Complementary Slackness**\nThis condition states that for each inequality constraint, the product of the multiplier and the constraint function must be zero. This means that a multiplier can be strictly positive only if the corresponding constraint is active (i.e., holds with equality).\n-   For the volume constraint:\n    $$\n    \\lambda \\left( \\int_{\\Omega} \\rho(x)\\, dx - V^{*} \\right) = 0\n    $$\n-   For the pointwise lower bound constraint:\n    $$\n    \\alpha(x) (-\\rho(x)) = 0 \\implies \\alpha(x) \\rho(x) = 0 \\quad \\text{for a.e. } x \\in \\Omega\n    $$\n    This implies that if $\\rho(x)  0$ (i.e., the lower bound is inactive), then $\\alpha(x)$ must be $0$.\n-   For the pointwise upper bound constraint:\n    $$\n    \\beta(x) (\\rho(x) - 1) = 0 \\quad \\text{for a.e. } x \\in \\Omega\n    $$\n    This implies that if $\\rho(x)  1$ (i.e., the upper bound is inactive), then $\\beta(x)$ must be $0$.\n\nThese four sets of conditions collectively form the KKT optimality conditions for the given topology optimization problem. The problem specifically asks for the pointwise stationarity condition, which we derived as the first result.",
            "answer": "$$\n\\boxed{\\frac{\\delta J}{\\delta \\rho}(x) + \\lambda - \\alpha(x) + \\beta(x) = 0}\n$$"
        },
        {
            "introduction": "An optimization process is only as reliable as the physical simulation it is built upon. This practice () focuses on the core of thermal design: building a robust \"forward solver\" that calculates the temperature field for a given design. By implementing a conservative finite volume scheme and verifying it with a global energy balance check, you will gain hands-on experience in ensuring your numerical model respects the fundamental laws of physics.",
            "id": "3998265",
            "problem": "Consider a two-dimensional rectangular design domain for thermal topology optimization with conjugate heat transfer at steady state. The domain has width $L$ in meters, height $H$ in meters, and a uniform out-of-plane thickness $t$ in meters. The interior is a heterogeneous solid whose effective thermal conductivity is governed by the Solid Isotropic Material with Penalization (SIMP) model: $k(\\rho) = k_{\\min} + \\rho^p (k_{\\max} - k_{\\min})$, where $\\rho \\in [0,1]$ is the element-wise design density, $p$ is the penalization exponent, $k_{\\min}$ is the residual conductivity of void-like regions, and $k_{\\max}$ is the conductivity of solid-like material.\n\nThe governing steady-state heat equation is the energy conservation statement for a control volume, with volumetric heat generation $q(\\mathbf{x})$ inside the domain $\\Omega$:\n$$\n-\\nabla \\cdot \\left( k(\\rho) \\nabla T(\\mathbf{x}) \\right) = q(\\mathbf{x}) \\quad \\text{in } \\Omega,\n$$\nsubject to boundary conditions on disjoint boundary portions $\\Gamma_{\\text{sink}}$ (isothermal heat sink), $\\Gamma_{\\text{conv}}$ (convective exchange with ambient), $\\Gamma_{\\text{rad}}$ (radiative exchange), and remaining boundaries being adiabatic. The boundary conditions are:\n$$\nT = T_{\\text{sink}} \\quad \\text{on } \\Gamma_{\\text{sink}},\n$$\n$$\n- \\mathbf{n} \\cdot k(\\rho) \\nabla T = h \\left( T - T_{\\infty} \\right) \\quad \\text{on } \\Gamma_{\\text{conv}},\n$$\n$$\n- \\mathbf{n} \\cdot k(\\rho) \\nabla T = \\varepsilon \\sigma \\left( T^4 - T_{\\text{sur}}^4 \\right) \\quad \\text{on } \\Gamma_{\\text{rad}},\n$$\nwhere $\\mathbf{n}$ is the outward unit normal, $h$ is the convective heat transfer coefficient, $T_{\\infty}$ is the ambient temperature, $\\varepsilon$ is the surface emissivity, and $\\sigma$ is the Stefan–Boltzmann constant.\n\nStarting from the first law of thermodynamics and applying the divergence theorem, derive the global energy balance that the total input thermal power equals the sum of heat removed through the sink by conduction, convective removal, and radiative removal:\n$$\n\\underbrace{\\int_{\\Omega} q \\, d\\Omega}_{\\text{total input}} = \\underbrace{\\int_{\\Gamma_{\\text{sink}}} \\left( -\\mathbf{n} \\cdot k(\\rho) \\nabla T \\right) d\\Gamma}_{\\text{conduction to sink}} + \\underbrace{\\int_{\\Gamma_{\\text{conv}}} h (T - T_{\\infty}) \\, d\\Gamma}_{\\text{convective removal}} + \\underbrace{\\int_{\\Gamma_{\\text{rad}}} \\varepsilon \\sigma \\left( T^4 - T_{\\text{sur}}^4 \\right) d\\Gamma}_{\\text{radiative removal}}.\n$$\nDefine the energy balance residual as\n$$\nr = \\left| \\int_{\\Omega} q \\, d\\Omega - \\int_{\\Gamma_{\\text{sink}}} \\left( -\\mathbf{n} \\cdot k(\\rho) \\nabla T \\right) d\\Gamma - \\int_{\\Gamma_{\\text{conv}}} h (T - T_{\\infty}) \\, d\\Gamma - \\int_{\\Gamma_{\\text{rad}}} \\varepsilon \\sigma \\left( T^4 - T_{\\text{sur}}^4 \\right) d\\Gamma \\right|.\n$$\nImplement a numerical scheme based on a conservative cell-centered finite volume discretization on a uniform grid with $N_x$ cells in the $x$-direction and $N_y$ cells in the $y$-direction. Use harmonic averaging for face conductivities. Impose the Dirichlet sink boundary condition via a half-cell diffusive conductance to the boundary with distance $d = \\Delta x/2$. Impose convective and radiative boundary conditions as linear Robin-type contributions to the discrete equations. To handle the nonlinearity of radiation, employ a fixed-point iteration for bottom boundary nodes. At each step, use the temperature from the previous iteration, $T^{\\text{old}}$, to define an effective radiative conductance $h_{\\text{rad}} = 4\\varepsilon\\sigma(T^{\\text{old}})^3$ and an effective ambient temperature $T_{\\text{rad,eff}} = T^{\\text{old}} - \\frac{\\varepsilon\\sigma((T^{\\text{old}})^4 - T_{\\text{sur}}^4)}{h_{\\text{rad}}}$. Iterate until convergence of the temperature field.\n\nFor the numerical implementation, use the following parameters with units explicitly respected:\n- Domain: $L = 0.10$ meters, $H = 0.10$ meters, thickness $t = 0.010$ meters. Uniform grid of $N_x = 10$, $N_y = 10$ cells so that $\\Delta x = L/N_x$ and $\\Delta y = H/N_y$.\n- Material model: $k_{\\min} = 0.2$ watts per meter-kelvin, $k_{\\max} = 200$ watts per meter-kelvin, penalization exponent $p = 3$.\n- Heat sink: $\\Gamma_{\\text{sink}}$ is the entire left boundary; $T_{\\text{sink}} = 300$ kelvin.\n- Convection: $\\Gamma_{\\text{conv}}$ is the entire top and right boundaries; $T_{\\infty} = 300$ kelvin. The convective coefficient $h$ varies per test case (see below).\n- Radiation: $\\Gamma_{\\text{rad}}$ is the entire bottom boundary; $\\varepsilon$ varies per test case (see below). The surrounding temperature $T_{\\text{sur}} = 300$ kelvin, and $\\sigma = 5.670374419 \\times 10^{-8}$ watts per meter squared-kelvin to the fourth power.\n- Internal heat generation: $q(\\mathbf{x}) = Q = 1.0 \\times 10^7$ watts per cubic meter in the central $4 \\times 4$ block of cells and $q(\\mathbf{x}) = 0$ elsewhere. The central block indices are $i \\in \\{3,4,5,6\\}$, $j \\in \\{3,4,5,6\\}$ using zero-based indexing with $i$ along $x$ and $j$ along $y$.\n- Topology (design density field $\\rho$) varies per test case (see below) and affects $k(\\rho)$ via the SIMP model.\n\nProgram requirements:\n- Construct the discrete linear system and solve for the temperature field $T_{i,j}$ in kelvin.\n- Evaluate the energy balance residual $r$ in watts using the exact radiation flux $\\varepsilon \\sigma (T^4 - T_{\\text{sur}}^4)$ for the post-processed bottom boundary integral, the convective flux $h (T - T_{\\infty})$ on top and right boundaries, and the conductive flux to the sink on the left boundary as the diffusive boundary flux consistent with the half-cell conductance model.\n- Use a fixed-point iteration to incorporate radiation into the linear system until the maximum change in temperature between successive iterations is less than $10^{-8}$ kelvin or until a maximum of $50$ iterations is reached.\n\nTest suite:\nProvide three test cases to validate the implementation with different topology and boundary parameter combinations:\n1. Test Case A (baseline heterogeneous conduction with convection and radiation):\n   - $\\rho_{i,j} = 1$ for all cells,\n   - $h = 1000$ watts per meter squared-kelvin,\n   - $\\varepsilon = 0.8$.\n2. Test Case B (sparse diagonal conductive path with convection and radiation):\n   - $\\rho_{i,j} = 0.05$ for all cells except those with $i = j$ or $i = j \\pm 1$ (clipped to valid indices), where $\\rho_{i,j} = 1$,\n   - $h = 1000$ watts per meter squared-kelvin,\n   - $\\varepsilon = 0.8$.\n3. Test Case C (pure conduction to sink, no convection or radiation):\n   - $\\rho_{i,j} = 1$ for all cells,\n   - $h = 0$ watts per meter squared-kelvin,\n   - $\\varepsilon = 0$.\n\nFinal output specification:\nYour program should produce a single line of output containing the energy balance residuals $r$ in watts for the three test cases as a comma-separated list enclosed in square brackets, with each value rounded to six significant figures (for example, $\\left[0.123456,0.000321,1.23457\\right]$). The values must be expressed in watts and printed exactly in this format.",
            "solution": "The problem poses a task in computational heat transfer, requiring the derivation of the global energy balance, the design and implementation of a numerical solver for the steady-state heat equation with nonlinear boundary conditions, and the evaluation of this solver on a set of specific test cases. The problem is scientifically sound, well-posed, and provides all necessary information for a complete solution.\n\n### Part 1: Derivation of the Global Energy Balance\n\nThe derivation begins with the governing partial differential equation for steady-state heat conduction with an internal heat source $q(\\mathbf{x})$ within a domain $\\Omega$:\n$$\n-\\nabla \\cdot \\left( k(\\rho) \\nabla T(\\mathbf{x}) \\right) = q(\\mathbf{x})\n$$\nThis equation is a statement of the first law of thermodynamics applied to an infinitesimal control volume, where the divergence of the heat flux vector, $\\mathbf{q}'' = -k(\\rho)\\nabla T$, is balanced by the local heat generation rate per unit volume, $q$.\n\nTo obtain the global energy balance for the entire domain $\\Omega$, we integrate the governing equation over the volume of the domain (for a $2$D problem with thickness $t$, this corresponds to an integral over area $d\\Omega$ and multiplication by $t$, but for simplicity, we use $d\\Omega$ to denote the volumetric element $dxdydz$):\n$$\n\\int_{\\Omega} -\\nabla \\cdot \\left( k(\\rho) \\nabla T(\\mathbf{x}) \\right) d\\Omega = \\int_{\\Omega} q(\\mathbf{x}) d\\Omega\n$$\nThe term on the right-hand side, $\\int_{\\Omega} q \\, d\\Omega$, represents the total power generated within the domain.\n\nWe apply the divergence theorem to the left-hand side. The theorem states that for a continuously differentiable vector field $\\mathbf{F}$, the integral of its divergence over a volume $\\Omega$ equals the flux of the field through the closed surface $\\partial\\Omega$ that bounds the volume: $\\int_{\\Omega} (\\nabla \\cdot \\mathbf{F}) \\, d\\Omega = \\oint_{\\partial\\Omega} \\mathbf{n} \\cdot \\mathbf{F} \\, d\\Gamma$. Here, our vector field is the heat flux $\\mathbf{q}'' = -k(\\rho)\\nabla T$.\n$$\n\\int_{\\Omega} \\nabla \\cdot \\left( -k(\\rho) \\nabla T \\right) d\\Omega = \\oint_{\\partial\\Omega} \\mathbf{n} \\cdot \\left( -k(\\rho) \\nabla T \\right) d\\Gamma\n$$\nThus, the integrated governing equation becomes:\n$$\n\\int_{\\Omega} q(\\mathbf{x}) \\, d\\Omega = \\oint_{\\partial\\Omega} \\left( -\\mathbf{n} \\cdot k(\\rho) \\nabla T \\right) d\\Gamma\n$$\nThis equation states that the total heat generated within the domain must equal the total heat exiting the domain through its boundaries at steady state.\n\nThe total boundary $\\partial\\Omega$ is composed of four disjoint segments: the sink boundary $\\Gamma_{\\text{sink}}$, the convective boundary $\\Gamma_{\\text{conv}}$, the radiative boundary $\\Gamma_{\\text{rad}}$, and any remaining adiabatic boundaries where the flux is zero. We can split the boundary integral into contributions from each segment:\n$$\n\\oint_{\\partial\\Omega} \\left( -\\mathbf{n} \\cdot k \\nabla T \\right) d\\Gamma = \\int_{\\Gamma_{\\text{sink}}} \\left( -\\mathbf{n} \\cdot k \\nabla T \\right) d\\Gamma + \\int_{\\Gamma_{\\text{conv}}} \\left( -\\mathbf{n} \\cdot k \\nabla T \\right) d\\Gamma + \\int_{\\Gamma_{\\text{rad}}} \\left( -\\mathbf{n} \\cdot k \\nabla T \\right) d\\Gamma\n$$\nNow, we substitute the given boundary conditions for the flux term $-\\mathbf{n} \\cdot k \\nabla T$:\n1.  On $\\Gamma_{\\text{conv}}$: The flux is given by Newton's law of cooling, $-\\mathbf{n} \\cdot k \\nabla T = h(T - T_{\\infty})$.\n2.  On $\\Gamma_{\\text{rad}}$: The flux is given by the Stefan-Boltzmann law for radiation to a large surrounding, $-\\mathbf{n} \\cdot k \\nabla T = \\varepsilon \\sigma (T^4 - T_{\\text{sur}}^4)$.\n3.  On $\\Gamma_{\\text{sink}}$: The boundary condition is Dirichlet, $T = T_{\\text{sink}}$. The integrand $-\\mathbf{n} \\cdot k \\nabla T$ itself represents the conductive heat flux from the domain into the sink.\n\nSubstituting these expressions yields the final global energy balance equation:\n$$\n\\underbrace{\\int_{\\Omega} q \\, d\\Omega}_{\\text{total input}} = \\underbrace{\\int_{\\Gamma_{\\text{sink}}} \\left( -\\mathbf{n} \\cdot k(\\rho) \\nabla T \\right) d\\Gamma}_{\\text{conduction to sink}} + \\underbrace{\\int_{\\Gamma_{\\text{conv}}} h (T - T_{\\infty}) \\, d\\Gamma}_{\\text{convective removal}} + \\underbrace{\\int_{\\Gamma_{\\text{rad}}} \\varepsilon \\sigma \\left( T^4 - T_{\\text{sur}}^4 \\right) d\\Gamma}_{\\text{radiative removal}}\n$$\nThis completes the derivation. The energy balance residual $r$ is the absolute difference between the total input power and the sum of all power removal terms, which serves as a metric for the conservation of energy in the numerical solution.\n\n### Part 2: Numerical Scheme Design\n\nA conservative cell-centered finite volume method (FVM) is employed to solve the governing equation on a uniform grid of $N_x \\times N_y$ cells. The temperature $T_{i,j}$ is located at the center of the cell $(i,j)$.\n\n**Discretization of the Governing Equation:**\nIntegrating the PDE over the volume of a single cell $V_{i,j} = \\Delta x \\Delta y t$ and applying the divergence theorem yields:\n$$\n-\\sum_{f \\in \\{\\text{e,w,n,s}\\}} \\left( \\int_{A_f} (k \\nabla T) \\cdot \\mathbf{n}_f dA \\right) = q_{i,j} V_{i,j}\n$$\nwhere the sum is over the east, west, north, and south faces of the cell. The integral over a face $A_f$ is the heat flux across that face. For an interior face between cell $(i,j)$ and $(i+1,j)$, the flux is approximated as:\n$$\nQ_{i,j \\to i+1,j} = k_e \\frac{T_{i,j} - T_{i+1,j}}{\\Delta x} (\\Delta y t) = G_{e} (T_{i,j} - T_{i+1,j})\n$$\nwhere $G_e$ is the thermal conductance between the cell centers. The interface conductivity $k_e$ is computed using the harmonic mean to properly handle large contrasts in conductivity:\n$$\nk_e = \\frac{2 k_{i,j} k_{i+1,j}}{k_{i,j} + k_{i+1,j}} \\quad \\text{where} \\quad k_{i,j} = k(\\rho_{i,j})\n$$\nSimilar expressions hold for the other three faces. The energy balance for an interior cell $(i,j)$ forms a linear algebraic equation relating $T_{i,j}$ to its four neighbors:\n$$\nG_e(T_{i,j}-T_{i+1,j}) + G_w(T_{i,j}-T_{i-1,j}) + G_n(T_{i,j}-T_{i,j+1}) + G_s(T_{i,j}-T_{i,j-1}) = q_{i,j} V_{i,j}\n$$\n\n**Boundary Conditions Implementation:**\nFor cells adjacent to the domain boundaries, one or more flux terms are replaced by boundary condition expressions.\n1.  **Sink (Left, $i=0$):** The Dirichlet condition $T=T_{\\text{sink}}$ is imposed via a half-cell conductance model. The flux from cell $(0,j)$ to the sink is modeled as conduction over a distance of $\\Delta x/2$:\n    $$ Q_{\\text{sink}} = G_{\\text{sink}} (T_{0,j} - T_{\\text{sink}}), \\quad \\text{where} \\quad G_{\\text{sink}} = \\frac{k_{0,j} (\\Delta y t)}{\\Delta x / 2} $$\n    This adds a term $G_{\\text{sink}}T_{0,j}$ to the left-hand side (LHS) of the matrix equation and $G_{\\text{sink}}T_{\\text{sink}}$ to the right-hand side (RHS) vector.\n\n2.  **Convection (Top, $j=N_y-1$; Right, $i=N_x-1$):** This Robin-type condition is implemented directly. For a top-boundary cell $(i,N_y-1)$, the northward flux is:\n    $$ Q_{\\text{conv}} = h (T_{i,N_y-1} - T_{\\infty}) (\\Delta x t) $$\n    This is equivalent to a conductance $G_{\\text{conv}}=h(\\Delta x t)$ to an ambient temperature $T_{\\infty}$, adding $G_{\\text{conv}}T_{i,N_y-1}$ to the LHS and $G_{\\text{conv}}T_{\\infty}$ to the RHS. A similar treatment applies to the right boundary.\n\n3.  **Radiation (Bottom, $j=0$):** The nonlinear radiative flux is linearized for inclusion in the linear system. The flux is $Q_{\\text{rad}} = \\varepsilon \\sigma (T^4 - T_{\\text{sur}}^4) A_{\\text{face}}$. We use a Newton-Raphson linearization around the temperature from the previous iteration, $T^{\\text{old}}$:\n    $$ Q_{\\text{rad}}(T) \\approx Q_{\\text{rad}}(T^{\\text{old}}) + \\frac{dQ_{\\text{rad}}}{dT}\\bigg|_{T^{\\text{old}}} (T - T^{\\text{old}}) $$\n    This can be expressed as an effective Robin condition $Q_{\\text{rad}} \\approx h_{\\text{rad}}(T - T_{\\text{rad,eff}}) A_{\\text{face}}$, with:\n    $$ h_{\\text{rad}} = 4\\varepsilon\\sigma (T^{\\text{old}})^3, \\quad T_{\\text{rad,eff}} = T^{\\text{old}} - \\frac{\\varepsilon\\sigma((T^{\\text{old}})^4 - T_{\\text{sur}}^4)}{h_{\\text{rad}}} = \\frac{3(T^{\\text{old}})^4 + T_{\\text{sur}}^4}{4(T^{\\text{old}})^3} $$\n    For each bottom-boundary cell $(i,0)$, this contributes a term $h_{\\text{rad},i,0}(\\Delta x t) T_{i,0}$ to the LHS and $h_{\\text{rad},i,0}(\\Delta x t) T_{\\text{rad,eff},i,0}$ to the RHS.\n\n**Solution Algorithm:**\nThe nonlinearity of the radiation boundary condition necessitates an iterative solution:\n1.  Initialize the temperature field, e.g., $T^{(0)}_{i,j} = T_{\\text{sink}}$ for all $(i,j)$.\n2.  Begin a fixed-point iteration loop (for $k = 0, 1, 2, ...$):\n    a.  For each bottom-boundary cell, calculate $h_{\\text{rad}}$ and $T_{\\text{rad,eff}}$ using the current temperature field $T^{(k)}$.\n    b.  Assemble the global linear system of equations $A(T^{(k)}) \\mathbf{T} = \\mathbf{b}(T^{(k)})$, where the vector $\\mathbf{T}$ contains the unknown cell temperatures $T_{i,j}$.\n    c.  Solve the sparse linear system for the new temperature field, $\\mathbf{T}^{(k+1)}$.\n    d.  Check for convergence by comparing the maximum absolute temperature change between iterations: $\\max_{i,j} |T^{(k+1)}_{i,j} - T^{(k)}_{i,j}|  \\delta_{tol}$. If converged, or if the maximum number of iterations is reached, terminate.\n    e.  Set $T^{(k)} \\leftarrow T^{(k+1)}$ and continue to the next iteration.\n\n### Part 3: Energy Balance Residual Calculation\n\nAfter the temperature field has converged, the energy balance residual $r$ is calculated to verify the global energy conservation of the solution.\n1.  **Total Input Power ($P_{\\text{in}}$):** This is the sum of heat generation over all source cells.\n    $$ P_{\\text{in}} = \\sum_{i,j \\in \\text{source}} Q \\cdot V_{i,j} = (1.0 \\times 10^7 \\text{ W/m}^3) \\cdot (16 \\text{ cells}) \\cdot (\\Delta x \\Delta y t) = 160 \\text{ W} $$\n2.  **Sink Removal ($P_{\\text{sink}}$):** Sum of fluxes from all left-boundary cells into the sink.\n    $$ P_{\\text{sink}} = \\sum_{j=0}^{N_y-1} \\frac{2 k_{0,j} \\Delta y t}{\\Delta x} (T_{0,j} - T_{\\text{sink}}) $$\n3.  **Convective Removal ($P_{\\text{conv}}$):** Sum of convective fluxes from all top and right boundary cells.\n    $$ P_{\\text{conv}} = \\sum_{i=0}^{N_x-1} h(T_{i,N_y-1} - T_{\\infty})(\\Delta x t) + \\sum_{j=0}^{N_y-1} h(T_{N_x-1,j} - T_{\\infty})(\\Delta y t) $$\n4.  **Radiative Removal ($P_{\\text{rad}}$):** Sum of radiative fluxes from all bottom boundary cells, using the original nonlinear Stefan-Boltzmann law as specified.\n    $$ P_{\\text{rad}} = \\sum_{i=0}^{N_x-1} \\varepsilon \\sigma (T_{i,0}^4 - T_{\\text{sur}}^4)(\\Delta x t) $$\nThe residual is then computed as the absolute difference:\n$$\nr = \\left| P_{\\text{in}} - (P_{\\text{sink}} + P_{\\text{conv}} + P_{\\text{rad}}) \\right|\n$$\nThis residual quantifies the extent to which the converged solution satisfies the original nonlinear energy balance equation. Its smallness is an indicator of the accuracy of the linearization and the convergence of the fixed-point scheme.",
            "answer": "```python\nimport numpy as np\nfrom scipy.sparse import lil_matrix, csc_matrix\nfrom scipy.sparse.linalg import spsolve\n\ndef solve():\n    \"\"\"\n    Main function to run the specified test cases for the thermal topology optimization problem.\n    \"\"\"\n    \n    # --------------------------------------------------------------------------\n    # 1. Define Physical and Numerical Parameters\n    # --------------------------------------------------------------------------\n    L, H, t = 0.10, 0.10, 0.010  # Domain dimensions [m]\n    Nx, Ny = 10, 10                # Number of cells\n    dx, dy = L / Nx, H / Ny          # Cell dimensions [m]\n    \n    k_min, k_max = 0.2, 200.0      # Material thermal conductivities [W/(m.K)]\n    p = 3.0                          # SIMP penalization exponent\n    \n    T_sink = 300.0                   # Sink temperature [K]\n    T_inf = 300.0                    # Ambient fluid temperature [K]\n    T_sur = 300.0                    # Surrounding surface temperature for radiation [K]\n    \n    Q = 1.0e7                        # Volumetric heat generation [W/m^3]\n    sigma = 5.670374419e-8           # Stefan-Boltzmann constant [W/(m^2.K^4)]\n\n    # Convergence parameters\n    max_iter = 50\n    tol = 1e-8\n\n    # Define heat source location (central 4x4 block)\n    q_source = np.zeros((Ny, Nx))\n    for j in range(3, 7):\n        for i in range(3, 7):\n            q_source[j, i] = Q\n            \n    # --------------------------------------------------------------------------\n    # 2. Define Test Cases\n    # --------------------------------------------------------------------------\n    \n    # Test Case A: Uniform solid material, convection, and radiation\n    rho_A = np.ones((Ny, Nx))\n    case_A = {'rho': rho_A, 'h': 1000.0, 'eps': 0.8}\n\n    # Test Case B: Sparse diagonal path, convection, and radiation\n    rho_B = np.full((Ny, Nx), 0.05)\n    for j in range(Ny):\n        for i in range(Nx):\n            if abs(i - j) = 1:\n                rho_B[j, i] = 1.0\n    case_B = {'rho': rho_B, 'h': 1000.0, 'eps': 0.8}\n\n    # Test Case C: Uniform solid material, pure conduction to sink\n    rho_C = np.ones((Ny, Nx))\n    case_C = {'rho': rho_C, 'h': 0.0, 'eps': 0.0}\n\n    test_cases = [case_A, case_B, case_C]\n    results = []\n\n    # --------------------------------------------------------------------------\n    # 3. Main Loop over Test Cases\n    # --------------------------------------------------------------------------\n    for case in test_cases:\n        h = case['h']\n        eps = case['eps']\n        rho = case['rho']\n\n        # Calculate cell-wise thermal conductivity\n        k_field = k_min + rho**p * (k_max - k_min)\n        \n        # Initialize temperature field\n        T = np.full((Ny, Nx), T_sink)\n        \n        for iter_count in range(max_iter):\n            T_old = T.copy()\n            \n            # Assemble the linear system A*T = b\n            A = lil_matrix((Nx * Ny, Nx * Ny))\n            b = np.zeros(Nx * Ny)\n            \n            for j in range(Ny):       # y-direction, rows\n                for i in range(Nx):   # x-direction, columns\n                    k_idx = j * Nx + i\n                    k_cell = k_field[j, i]\n                    \n                    # Volumetric heat source term\n                    b[k_idx] += q_source[j, i] * dx * dy * t\n                    \n                    # West face\n                    if i == 0:  # Left boundary (sink)\n                        G_sink = 2.0 * k_cell * dy * t / dx\n                        A[k_idx, k_idx] += G_sink\n                        b[k_idx] += G_sink * T_sink\n                    else: # Internal face\n                        k_neighbor = k_field[j, i - 1]\n                        k_w = 2.0 * k_cell * k_neighbor / (k_cell + k_neighbor)\n                        G_w = k_w * dy * t / dx\n                        A[k_idx, k_idx] += G_w\n                        A[k_idx, k_idx - 1] -= G_w\n                        \n                    # East face\n                    if i == Nx - 1: # Right boundary (convection)\n                        G_conv = h * dy * t\n                        A[k_idx, k_idx] += G_conv\n                        b[k_idx] += G_conv * T_inf\n                    else: # Internal face\n                        k_neighbor = k_field[j, i + 1]\n                        k_e = 2.0 * k_cell * k_neighbor / (k_cell + k_neighbor)\n                        G_e = k_e * dy * t / dx\n                        A[k_idx, k_idx] += G_e\n                        A[k_idx, k_idx + 1] -= G_e\n\n                    # South face\n                    if j == 0: # Bottom boundary (radiation)\n                        if eps  0:\n                            T_old_cell = T_old[j, i]\n                            # Avoid division by zero if T_old is close to 0\n                            if T_old_cell  1e-6: T_old_cell = 1e-6\n                            \n                            h_rad = 4.0 * eps * sigma * (T_old_cell**3)\n                            T_rad_eff = (3.0 * T_old_cell**4 + T_sur**4) / (4.0 * T_old_cell**3)\n                            G_rad = h_rad * dx * t\n                            A[k_idx, k_idx] += G_rad\n                            b[k_idx] += G_rad * T_rad_eff\n                        # if eps=0, it's adiabatic (no flux), do nothing\n                    else: # Internal face\n                        k_neighbor = k_field[j - 1, i]\n                        k_s = 2.0 * k_cell * k_neighbor / (k_cell + k_neighbor)\n                        G_s = k_s * dx * t / dy\n                        A[k_idx, k_idx] += G_s\n                        A[k_idx, k_idx - Nx] -= G_s\n                        \n                    # North face\n                    if j == Ny - 1: # Top boundary (convection)\n                        G_conv = h * dx * t\n                        A[k_idx, k_idx] += G_conv\n                        b[k_idx] += G_conv * T_inf\n                    else: # Internal face\n                        k_neighbor = k_field[j + 1, i]\n                        k_n = 2.0 * k_cell * k_neighbor / (k_cell + k_neighbor)\n                        G_n = k_n * dx * t / dy\n                        A[k_idx, k_idx] += G_n\n                        A[k_idx, k_idx + Nx] -= G_n\n            \n            # Solve the linear system\n            A_csc = csc_matrix(A)\n            T_flat = spsolve(A_csc, b)\n            T = T_flat.reshape((Ny, Nx))\n            \n            # Check for convergence\n            max_diff = np.max(np.abs(T - T_old))\n            if max_diff  tol:\n                break\n        \n        # ----------------------------------------------------------------------\n        # 4. Calculate Energy Balance Residual\n        # ----------------------------------------------------------------------\n        \n        # Total power input from volumetric generation\n        P_in = np.sum(q_source) * dx * dy * t\n        \n        # Power removal at the sink (left boundary)\n        P_sink = 0.0\n        for j in range(Ny):\n            k_cell = k_field[j, 0]\n            G_sink = 2.0 * k_cell * dy * t / dx\n            P_sink += G_sink * (T[j, 0] - T_sink)\n            \n        # Power removal by convection (top and right boundaries)\n        P_conv = 0.0\n        # a) Top boundary\n        for i in range(Nx):\n            P_conv += h * (T[Ny - 1, i] - T_inf) * dx * t\n        # b) Right boundary\n        for j in range(Ny):\n            P_conv += h * (T[j, Nx - 1] - T_inf) * dy * t\n            \n        # Power removal by radiation (bottom boundary)\n        P_rad = 0.0\n        if eps  0:\n            for i in range(Nx):\n                P_rad += eps * sigma * (T[0, i]**4 - T_sur**4) * dx * t\n        \n        # Total power output\n        P_out = P_sink + P_conv + P_rad\n        \n        # Energy balance residual\n        residual = abs(P_in - P_out)\n        results.append(f\"{residual:.6g}\")\n\n    # Final print statement\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Gradient-based optimization requires the efficient and accurate computation of sensitivities, which describe how the objective function changes with respect to the design variables. This advanced practice () tackles the implementation of the adjoint method, the workhorse for sensitivity analysis in large-scale problems. You will not only derive and code the adjoint solution but also validate its correctness against the highly accurate complex-step method, a vital skill for developing reliable optimization tools.",
            "id": "3998277",
            "problem": "Consider a one-dimensional, steady-state heat conduction problem on the domain $[0,L]$ with prescribed temperature at both ends. The state variable $T(x)$ satisfies the energy balance law and Fourier’s law of heat conduction, resulting in the nonlinear boundary value problem\n$$\n\\frac{d}{dx}\\left(k(T,\\theta)\\frac{dT}{dx}\\right) + q(x) = 0,\\quad x\\in(0,L),\n$$\nsubject to Dirichlet boundary conditions\n$$\nT(0)=T_{\\mathrm{left}},\\quad T(L)=T_{\\mathrm{right}}.\n$$\nThe thermal conductivity is temperature and parameter dependent,\n$$\nk(T,\\theta) = k_0 + \\theta\\,\\exp\\left(\\beta\\,T\\right),\n$$\nwhere $k_00$ is the baseline conductivity, $\\beta0$ is a temperature sensitivity coefficient, and $\\theta$ is a design parameter entering the conductivity. The objective functional, known as thermal compliance in topology optimization, is\n$$\nJ(T) = \\int_0^L q(x)\\,T(x)\\,dx,\n$$\nwhere $q(x)$ is a given volumetric heat source distribution.\n\nYour tasks are:\n1. Starting from the energy balance and Fourier’s law, derive the discrete residual for a uniform grid of $N$ intervals (grid spacing $h=L/N$) using second-order central differences with interface conductivities evaluated at arithmetic averages. For interior nodes $i=1,\\dots,N-1$, define the discrete residual $F_i(T,\\theta)$ that enforces the discretized energy balance.\n2. Derive the discrete Jacobian matrix $\\partial F/\\partial T$ for the interior nodes by differentiating the residual with respect to the temperatures at interior nodes, fully accounting for the dependence of $k$ on $T$. Also derive the vector $\\partial F/\\partial\\theta$ for the interior nodes by differentiating the residual with respect to $\\theta$.\n3. Using the discrete trapezoidal rule, define the discrete objective $J_h(T)$ and derive the discrete sensitivity $\\frac{dJ_h}{d\\theta}$ via the adjoint method. Introduce the adjoint vector $\\lambda$ solving the linear system\n$$\n\\left(\\frac{\\partial F}{\\partial T}\\right)^{\\!\\top} \\lambda = \\frac{\\partial J_h}{\\partial T},\n$$\nand show that\n$$\n\\frac{dJ_h}{d\\theta} = -\\,\\lambda^{\\top}\\,\\frac{\\partial F}{\\partial \\theta}.\n$$\nExplain the boundary conditions for the adjoint consistent with fixed temperature boundaries.\n4. Implement a Newton method to solve the nonlinear forward problem for $T(x)$ on the grid. Use the derived discrete residual and Jacobian. Then implement the adjoint sensitivity computation.\n5. Validate the adjoint sensitivity against a complex-step differentiation estimate. Specifically, compute $J_h$ at $\\theta + \\mathrm{i}\\,\\varepsilon$ (with $\\varepsilon$ a small positive real number) using complex arithmetic and report the estimate\n$$\n\\left.\\frac{dJ_h}{d\\theta}\\right|_{\\mathrm{csd}} \\approx \\frac{\\operatorname{Im}\\,J_h\\!\\left(T(\\theta+\\mathrm{i}\\,\\varepsilon)\\right)}{\\varepsilon}.\n$$\n\nUse the following scientifically consistent and self-contained parameter sets as a test suite. For each test case, you must:\n- Solve the forward problem to obtain $T(x)$.\n- Compute the adjoint sensitivity $\\frac{dJ_h}{d\\theta}$.\n- Compute the complex-step sensitivity estimate using $\\varepsilon=10^{-30}$.\n- Output the absolute difference between the adjoint sensitivity and the complex-step sensitivity estimate as a floating-point number.\n\nAll physical quantities use the International System of Units. The program’s final output should be unitless absolute differences. The heat source is defined by\n$$\nq(x) = q_0\\left(1 + \\sin\\left(\\pi x/L\\right)\\right),\n$$\nwhere $q_0\\ge 0$.\n\nTest suite parameter sets:\n- Case A (general nonlinear conduction): $L=0.1\\,\\mathrm{m}$, $N=200$, $k_0=10\\,\\mathrm{W}/(\\mathrm{m}\\cdot\\mathrm{K})$, $\\beta=10^{-2}\\,\\mathrm{K}^{-1}$, $\\theta=5\\,\\mathrm{W}/(\\mathrm{m}\\cdot\\mathrm{K})$, $q_0=10^6\\,\\mathrm{W}/\\mathrm{m}^3$, $T_{\\mathrm{left}}=300\\,\\mathrm{K}$, $T_{\\mathrm{right}}=310\\,\\mathrm{K}$.\n- Case B (zero source edge case): $L=0.1\\,\\mathrm{m}$, $N=200$, $k_0=10\\,\\mathrm{W}/(\\mathrm{m}\\cdot\\mathrm{K})$, $\\beta=10^{-2}\\,\\mathrm{K}^{-1}$, $\\theta=3\\,\\mathrm{W}/(\\mathrm{m}\\cdot\\mathrm{K})$, $q_0=0\\,\\mathrm{W}/\\mathrm{m}^3$, $T_{\\mathrm{left}}=300\\,\\mathrm{K}$, $T_{\\mathrm{right}}=300\\,\\mathrm{K}$.\n- Case C (stronger nonlinearity): $L=0.1\\,\\mathrm{m}$, $N=200$, $k_0=10\\,\\mathrm{W}/(\\mathrm{m}\\cdot\\mathrm{K})$, $\\beta=5\\times10^{-2}\\,\\mathrm{K}^{-1}$, $\\theta=8\\,\\mathrm{W}/(\\mathrm{m}\\cdot\\mathrm{K})$, $q_0=5\\times10^5\\,\\mathrm{W}/\\mathrm{m}^3$, $T_{\\mathrm{left}}=280\\,\\mathrm{K}$, $T_{\\mathrm{right}}=320\\,\\mathrm{K}$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[resultA,resultB,resultC]\"), where each result is the absolute difference between the adjoint sensitivity and the complex-step sensitivity for the corresponding test case, represented as a floating-point number.",
            "solution": "The problem is subjected to validation and is found to be scientifically grounded, well-posed, and self-contained. We may therefore proceed with a complete solution.\n\nThe solution is structured into five parts:\n1.  Derivation of the discrete residual for the governing nonlinear boundary value problem using a finite difference method.\n2.  Derivation of the Jacobian matrix and parameter-derivative vector required for the Newton-Raphson solution method.\n3.  Derivation of the adjoint sensitivity formula for the thermal compliance objective functional.\n4.  Description of the numerical implementation using a Newton solver for the forward problem and the adjoint method for sensitivity.\n5.  Explanation of the complex-step method used for validating the adjoint sensitivity results.\n\n### 1. Discretization and Discrete Residual\n\nThe one-dimensional domain $[0, L]$ is discretized into a uniform grid with $N$ intervals, resulting in $N+1$ grid points $x_i = i \\cdot h$ for $i=0, 1, \\dots, N$, where $h=L/N$ is the grid spacing. The temperatures at the interior nodes, $T_1, \\dots, T_{N-1}$, are the unknowns, while the boundary temperatures $T_0 = T_{\\mathrm{left}}$ and $T_N = T_{\\mathrm{right}}$ are prescribed.\n\nThe governing equation is:\n$$\n\\frac{d}{dx}\\left(k(T,\\theta)\\frac{dT}{dx}\\right) + q(x) = 0\n$$\nWe apply a finite volume / finite difference method by integrating this equation over a control volume $[x_{i-1/2}, x_{i+1/2}]$ centered around each interior node $x_i$:\n$$\n\\int_{x_{i-1/2}}^{x_{i+1/2}} \\left(\\frac{d}{dx}\\left(k\\frac{dT}{dx}\\right) + q(x)\\right) dx = 0\n$$\nThis yields:\n$$\n\\left. \\left(k\\frac{dT}{dx}\\right) \\right|_{x_{i+1/2}} - \\left. \\left(k\\frac{dT}{dx}\\right) \\right|_{x_{i-1/2}} + \\int_{x_{i-1/2}}^{x_{i+1/2}} q(x) dx \\approx 0\n$$\nUsing second-order central differences for the derivatives and a midpoint rule for the integral, we obtain the discrete equation at node $i$:\n$$\nk_{i+1/2} \\frac{T_{i+1} - T_i}{h} - k_{i-1/2} \\frac{T_i - T_{i-1}}{h} + q_i h = 0\n$$\nwhere $T_i = T(x_i)$, $q_i = q(x_i)$, and $k_{i\\pm1/2}$ is the thermal conductivity at the control volume interface. As specified, the interface conductivity is evaluated as the arithmetic mean of the conductivities at the adjacent nodes:\n$$\nk_{i+1/2} = \\frac{k(T_i, \\theta) + k(T_{i+1}, \\theta)}{2} \\equiv \\frac{k_i + k_{i+1}}{2}\n$$\nSubstituting this into the balance equation and dividing by $h$ gives:\n$$\n\\frac{1}{2h^2} \\left[ (k_i + k_{i+1}) (T_{i+1} - T_i) - (k_{i-1} + k_i) (T_i - T_{i-1}) \\right] + q_i = 0\n$$\nThe discrete residual for each interior node $i \\in \\{1, \\dots, N-1\\}$ is defined as the left-hand side of this equation. Let $\\mathbf{T}$ be the vector of interior temperatures $[T_1, \\dots, T_{N-1}]^T$. The residual for node $i$, $F_i(\\mathbf{T}, \\theta)$, is:\n$$\nF_i(\\mathbf{T}, \\theta) = \\frac{1}{2h^2} \\left[ (k_i + k_{i+1}) (T_{i+1} - T_i) - (k_{i-1} + k_i) (T_i - T_{i-1}) \\right] + q_i\n$$\nFor $i=1$, $T_{i-1}$ is the fixed boundary value $T_0 = T_{\\mathrm{left}}$. For $i=N-1$, $T_{i+1}$ is the fixed boundary value $T_N = T_{\\mathrm{right}}$.\n\n### 2. Jacobian Matrix and Parameter Derivative\n\nTo solve the nonlinear system $\\mathbf{F}(\\mathbf{T}, \\theta) = \\mathbf{0}$ using Newton's method, we need the Jacobian matrix $\\mathcal{J} = \\frac{\\partial \\mathbf{F}}{\\partial \\mathbf{T}}$ and the parameter derivative vector $\\frac{\\partial \\mathbf{F}}{\\partial \\theta}$.\n\nThe thermal conductivity function is $k(T, \\theta) = k_0 + \\theta \\exp(\\beta T)$. Its partial derivatives are:\n$$\n\\frac{\\partial k}{\\partial T}(T, \\theta) = \\theta \\beta \\exp(\\beta T) \\equiv k'(T)\n$$\n$$\n\\frac{\\partial k}{\\partial \\theta}(T, \\theta) = \\exp(\\beta T)\n$$\nThe Jacobian matrix $\\mathcal{J}$ is an $(N-1) \\times (N-1)$ matrix with entries $\\mathcal{J}_{ij} = \\frac{\\partial F_i}{\\partial T_j}$. Since $F_i$ depends only on $T_{i-1}, T_i, T_{i+1}$, the Jacobian is tridiagonal. The non-zero entries for row $i$ (corresponding to $F_i$) are:\n\n- **Diagonal term ($j=i$):**\n$$\n\\frac{\\partial F_i}{\\partial T_i} = \\frac{1}{2h^2} \\frac{\\partial}{\\partial T_i} \\left[ (k_i + k_{i+1}) (T_{i+1} - T_i) - (k_{i-1} + k_i) (T_i - T_{i-1}) \\right]\n$$\n$$\n\\frac{\\partial F_i}{\\partial T_i} = \\frac{1}{2h^2} \\left[ k'_i (T_{i+1} - T_i) - (k_i + k_{i+1}) - k'_i (T_i - T_{i-1}) - (k_{i-1} + k_i) \\right]\n$$\n\n- **Super-diagonal term ($j=i+1$):** (for $i  N-1$)\n$$\n\\frac{\\partial F_i}{\\partial T_{i+1}} = \\frac{1}{2h^2} \\frac{\\partial}{\\partial T_{i+1}} \\left[ (k_i + k_{i+1}) (T_{i+1} - T_i) \\right] = \\frac{1}{2h^2} \\left[ k'_{i+1} (T_{i+1} - T_i) + (k_i + k_{i+1}) \\right]\n$$\n\n- **Sub-diagonal term ($j=i-1$):** (for $i  1$)\n$$\n\\frac{\\partial F_i}{\\partial T_{i-1}} = \\frac{1}{2h^2} \\frac{\\partial}{\\partial T_{i-1}} \\left[ -(k_{i-1} + k_i) (T_i - T_{i-1}) \\right] = \\frac{1}{2h^2} \\left[ -k'_{i-1} (T_i - T_{i-1}) + (k_{i-1} + k_i) \\right]\n$$\n\nThe derivative of the residual vector with respect to the design parameter $\\theta$ is a vector with components:\n$$\n\\frac{\\partial F_i}{\\partial \\theta} = \\frac{1}{2h^2} \\left[ \\left(\\frac{\\partial k_i}{\\partial \\theta} + \\frac{\\partial k_{i+1}}{\\partial \\theta}\\right) (T_{i+1} - T_i) - \\left(\\frac{\\partial k_{i-1}}{\\partial \\theta} + \\frac{\\partial k_i}{\\partial \\theta}\\right) (T_i - T_{i-1}) \\right]\n$$\n$$\n\\frac{\\partial F_i}{\\partial \\theta} = \\frac{1}{2h^2} \\left[ (\\exp(\\beta T_i) + \\exp(\\beta T_{i+1})) (T_{i+1} - T_i) - (\\exp(\\beta T_{i-1}) + \\exp(\\beta T_i)) (T_i - T_{i-1}) \\right]\n$$\n\n### 3. Adjoint Sensitivity Analysis\n\nThe objective functional $J(T) = \\int_0^L q(x) T(x) dx$ is discretized using the trapezoidal rule on the grid $x_0, \\dots, x_N$:\n$$\nJ_h(\\mathbf{T}) = h \\left( \\frac{q_0 T_0 + q_N T_N}{2} + \\sum_{i=1}^{N-1} q_i T_i \\right)\n$$\nThe state equation dictates that $\\mathbf{T}$ is an implicit function of $\\theta$, i.e., $\\mathbf{T} = \\mathbf{T}(\\theta)$, satisfying $\\mathbf{F}(\\mathbf{T}(\\theta), \\theta) = \\mathbf{0}$. We seek the total derivative $\\frac{dJ_h}{d\\theta}$. Applying the chain rule:\n$$\n\\frac{dJ_h}{d\\theta} = \\frac{\\partial J_h}{\\partial \\theta} + \\frac{\\partial J_h}{\\partial \\mathbf{T}} \\frac{d\\mathbf{T}}{d\\theta}\n$$\nSince $J_h$ has no explicit dependence on $\\theta$, $\\frac{\\partial J_h}{\\partial \\theta}=0$. The derivative of the state equation with respect to $\\theta$ gives:\n$$\n\\frac{d\\mathbf{F}}{d\\theta} = \\frac{\\partial \\mathbf{F}}{\\partial \\theta} + \\frac{\\partial \\mathbf{F}}{\\partial \\mathbf{T}} \\frac{d\\mathbf{T}}{d\\theta} = \\mathbf{0} \\implies \\frac{d\\mathbf{T}}{d\\theta} = - \\left( \\frac{\\partial \\mathbf{F}}{\\partial \\mathbf{T}} \\right)^{-1} \\frac{\\partial \\mathbf{F}}{\\partial \\theta}\n$$\nSubstituting this into the sensitivity expression yields the direct method:\n$$\n\\frac{dJ_h}{d\\theta} = - \\frac{\\partial J_h}{\\partial \\mathbf{T}} \\left( \\frac{\\partial \\mathbf{F}}{\\partial \\mathbf{T}} \\right)^{-1} \\frac{\\partial \\mathbf{F}}{\\partial \\theta}\n$$\nThe adjoint method avoids the explicit matrix inversion by defining an adjoint vector $\\boldsymbol{\\lambda}$ as the solution to the linear system:\n$$\n\\left( \\frac{\\partial \\mathbf{F}}{\\partial \\mathbf{T}} \\right)^\\top \\boldsymbol{\\lambda} = \\left( \\frac{\\partial J_h}{\\partial \\mathbf{T}} \\right)^\\top\n$$\nThe right-hand side is the transpose of the objective gradient, whose components are $\\frac{\\partial J_h}{\\partial T_j} = h q_j$ for $j=1, \\dots, N-1$.\nWith $\\boldsymbol{\\lambda}$ defined as such, we can write $\\boldsymbol{\\lambda}^\\top = \\frac{\\partial J_h}{\\partial \\mathbf{T}} \\left( \\frac{\\partial \\mathbf{F}}{\\partial \\mathbf{T}} \\right)^{-1}$. Substituting this into the direct sensitivity formula gives the adjoint sensitivity expression:\n$$\n\\frac{dJ_h}{d\\theta} = - \\boldsymbol{\\lambda}^\\top \\frac{\\partial \\mathbf{F}}{\\partial \\theta}\n$$\nThis method is computationally efficient, requiring the solution of only one linear system (the adjoint equation) regardless of the number of design parameters.\n\nThe boundary conditions for the adjoint problem are implicitly handled by the formulation. The primal variables are the $N-1$ interior temperatures, so the Jacobian $\\frac{\\partial \\mathbf{F}}{\\partial \\mathbf{T}}$ is an $(N-1) \\times (N-1)$ matrix. The adjoint vector $\\boldsymbol{\\lambda}$ thus also has $N-1$ components, corresponding to the interior nodes. This is the discrete analog of imposing homogeneous Dirichlet boundary conditions on the continuous adjoint problem (i.e., $\\lambda(0)=0, \\lambda(L)=0$), which is the correct condition when the primal problem has fixed (Dirichlet) boundary conditions.\n\n### 4. Numerical Implementation\nThe forward nonlinear problem $\\mathbf{F}(\\mathbf{T}, \\theta) = \\mathbf{0}$ is solved using Newton's method. Starting with an initial guess $\\mathbf{T}^{(0)}$ (e.g., a linear profile), we iteratively compute updates $\\Delta \\mathbf{T}^{(k)}$ by solving the linear system:\n$$\n\\mathcal{J}(\\mathbf{T}^{(k)}) \\Delta \\mathbf{T}^{(k)} = - \\mathbf{F}(\\mathbf{T}^{(k)})\n$$\nand updating the solution $\\mathbf{T}^{(k+1)} = \\mathbf{T}^{(k)} + \\Delta \\mathbf{T}^{(k)}$ until the norm of the residual $\\mathbf{F}$ is below a specified tolerance. As the Jacobian $\\mathcal{J}$ is tridiagonal, the linear system at each iteration is efficiently solved using a banded matrix solver.\n\nOnce the forward problem has converged to a solution $\\mathbf{T}$, the adjoint sensitivity is computed by:\n1.  Assembling the Jacobian $\\mathcal{J}$ at the converged temperature $\\mathbf{T}$.\n2.  Assembling the objective gradient vector $\\left( \\frac{\\partial J_h}{\\partial \\mathbf{T}} \\right)^\\top$.\n3.  Solving the linear adjoint system $\\mathcal{J}^\\top \\boldsymbol{\\lambda} = \\left( \\frac{\\partial J_h}{\\partial \\mathbf{T}} \\right)^\\top$ for the adjoint vector $\\boldsymbol{\\lambda}$. The transpose of a tridiagonal matrix is also tridiagonal, so this system is also solved efficiently.\n4.  Assembling the parameter derivative vector $\\frac{\\partial \\mathbf{F}}{\\partial \\theta}$.\n5.  Calculating the final sensitivity as the dot product $\\frac{dJ_h}{d\\theta} = - \\boldsymbol{\\lambda} \\cdot \\frac{\\partial \\mathbf{F}}{\\partial \\theta}$.\n\n### 5. Complex-Step Validation\nThe adjoint sensitivity is validated against the complex-step differentiation (CSD) method, which provides a highly accurate numerical derivative estimate, free from the subtractive cancellation errors of finite differences. The procedure is:\n1.  Perturb the design parameter $\\theta$ by a small imaginary step: $\\theta_c = \\theta + i \\varepsilon$, where $\\varepsilon$ is a very small real number (e.g., $10^{-30}$).\n2.  Solve the forward problem $\\mathbf{F}(\\mathbf{T}_c, \\theta_c) = \\mathbf{0}$ for the complex-valued temperature field $\\mathbf{T}_c$. This is done using the same Newton solver, but with all variables and operations defined over the complex field. The real-valued boundary conditions are treated as complex numbers with a zero imaginary part.\n3.  Compute the complex-valued objective function $J_h(\\mathbf{T}_c)$.\n4.  The sensitivity is estimated using the imaginary part of the result:\n$$\n\\left.\\frac{dJ_h}{d\\theta}\\right|_{\\mathrm{csd}} = \\frac{\\operatorname{Im}[J_h(\\mathbf{T}(\\theta + i\\varepsilon))]}{\\varepsilon}\n$$\nThis result is based on the Taylor series expansion of a complex analytic function and is accurate to machine precision. The absolute difference between the adjoint and CSD results serves as a robust verification of the correctness of the derived and implemented adjoint sensitivity expressions.",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import solve_banded\n\n# Use complex numbers for CSD validation\nnp.complex = np.complex128 if hasattr(np, 'complex') else complex\n\ndef get_k(T, theta, beta, k0):\n    \"\"\"Computes thermal conductivity k(T, theta).\"\"\"\n    return k0 + theta * np.exp(beta * T)\n\ndef get_k_prime_T(T, theta, beta):\n    \"\"\"Computes derivative of k w.r.t. T.\"\"\"\n    return theta * beta * np.exp(beta * T)\n\ndef get_dk_dtheta(T, beta):\n    \"\"\"Computes derivative of k w.r.t. theta.\"\"\"\n    return np.exp(beta * T)\n\ndef assemble_system(T_full, params, dtype=np.float64):\n    \"\"\"\n    Assembles the residual F and the Jacobian J for the interior nodes.\n    T_full is the temperature vector of size N+1 including boundaries.\n    \"\"\"\n    N, h, k0, beta, theta, q_vec = params['N'], params['h'], params['k0'], params['beta'], params['theta'], params['q_vec']\n    \n    num_unknowns = N - 1\n    F = np.zeros(num_unknowns, dtype=dtype)\n    # Banded Jacobian: J_banded[0,:]=upper, J_banded[1,:]=main, J_banded[2,:]=lower\n    J_banded = np.zeros((3, num_unknowns), dtype=dtype)\n    \n    # Pre-compute k and its derivatives for all nodes\n    k = get_k(T_full, theta, beta, k0)\n    k_prime_T = get_k_prime_T(T_full, theta, beta)\n    \n    c = 1.0 / (2.0 * h**2)\n\n    for i in range(1, N): # Loop over interior nodes\n        idx = i - 1 # 0-based index for F and J\n        \n        # Temperatures\n        T_im1, T_i, T_ip1 = T_full[i-1], T_full[i], T_full[i+1]\n        \n        # Conductivities\n        k_im1, k_i, k_ip1 = k[i-1], k[i], k[i+1]\n        \n        # Residual F_i\n        term1 = (k_i + k_ip1) * (T_ip1 - T_i)\n        term2 = (k_im1 + k_i) * (T_i - T_im1)\n        F[idx] = c * (term1 - term2) + q_vec[i]\n        \n        # Jacobian entries for F_i\n        \n        # Main diagonal: dF_i/dT_i\n        dkp_dT_i = k_prime_T[i]\n        J_banded[1, idx] = c * (dkp_dT_i * (T_ip1 - T_i) - (k_i + k_ip1) - dkp_dT_i * (T_i - T_im1) - (k_im1 + k_i))\n\n        # Upper diagonal: dF_i/dT_{i+1}\n        if i  N - 1:\n            dkp_dT_ip1 = k_prime_T[i+1]\n            J_banded[0, idx + 1] = c * (dkp_dT_ip1 * (T_ip1 - T_i) + (k_i + k_ip1))\n\n        # Lower diagonal: dF_i/dT_{i-1}\n        if i  1:\n            dkp_dT_im1 = k_prime_T[i-1]\n            J_banded[2, idx - 1] = c * (-dkp_dT_im1 * (T_i - T_im1) + (k_im1 + k_i))\n\n    return F, J_banded\n\ndef solve_forward(params, dtype=np.float64):\n    \"\"\"\n    Solves the nonlinear forward problem T(x) using Newton's method.\n    \"\"\"\n    N, L, T_left, T_right = params['N'], params['L'], params['T_left'], params['T_right']\n    \n    # Initial guess: linear temperature profile\n    T_full = np.linspace(T_left, T_right, N + 1, dtype=dtype)\n    \n    # Newton's method\n    max_iter = 50\n    tol = 1e-10\n    for it in range(max_iter):\n        T_interior = T_full[1:-1]\n        F, J_banded = assemble_system(T_full, params, dtype)\n        \n        res_norm = np.linalg.norm(F)\n        if res_norm  tol:\n            break\n        \n        # Solve J * delta_T = -F\n        delta_T = solve_banded((1, 1), J_banded, -F)\n        T_interior += delta_T\n        T_full[1:-1] = T_interior\n    \n    return T_full\n\ndef compute_adjoint_sensitivity(T_full, params):\n    \"\"\"\n    Computes dJ/dtheta using the adjoint method.\n    \"\"\"\n    N, h, k0, beta, theta, q_vec = params['N'], params['h'], params['k0'], params['beta'], params['theta'], params['q_vec']\n    num_unknowns = N - 1\n    \n    # 1. Get Jacobian at converged T\n    _, J_banded = assemble_system(T_full, params, dtype=np.float64)\n    \n    # 2. Compute dJ/dT (RHS of adjoint equation)\n    dJ_dT = h * q_vec[1:-1]\n    \n    # 3. Solve adjoint system J^T * lambda = dJ/dT\n    # For J^T, the upper and lower diagonals are swapped.\n    J_T_banded = np.zeros_like(J_banded)\n    J_T_banded[1, :] = J_banded[1, :]\n    J_T_banded[0, 1:] = J_banded[2, :-1]\n    J_T_banded[2, :-1] = J_banded[0, 1:]\n    \n    adjoint_lambda = solve_banded((1, 1), J_T_banded, dJ_dT)\n    \n    # 4. Compute dF/dtheta\n    dF_dtheta = np.zeros(num_unknowns, dtype=np.float64)\n    exp_beta_T = get_dk_dtheta(T_full, beta)\n    \n    c = 1.0 / (2.0 * h**2)\n    for i in range(1, N):\n        idx = i - 1\n        T_im1, T_i, T_ip1 = T_full[i-1], T_full[i], T_full[i+1]\n        exp_im1, exp_i, exp_ip1 = exp_beta_T[i-1], exp_beta_T[i], exp_beta_T[i+1]\n        \n        term1 = (exp_i + exp_ip1) * (T_ip1 - T_i)\n        term2 = (exp_im1 + exp_i) * (T_i - T_im1)\n        dF_dtheta[idx] = c * (term1 - term2)\n        \n    # 5. Compute sensitivity\n    sensitivity = -np.dot(adjoint_lambda, dF_dtheta)\n    \n    return sensitivity\n\ndef compute_cs_sensitivity(params, epsilon=1e-30):\n    \"\"\"\n    Computes dJ/dtheta using the complex-step method.\n    \"\"\"\n    # Create a complex copy of params\n    params_cs = params.copy()\n    params_cs['theta'] = params['theta'] + 1j * epsilon\n    params_cs['T_left'] = complex(params['T_left'])\n    params_cs['T_right'] = complex(params['T_right'])\n\n    # Solve forward problem with complex arithmetic\n    T_full_cs = solve_forward(params_cs, dtype=np.complex128)\n    \n    # Compute complex objective function J_h\n    h, N, q_vec = params_cs['h'], params_cs['N'], params_cs['q_vec']\n    J_h_cs = h * ( (q_vec[0] * T_full_cs[0] + q_vec[N] * T_full_cs[N]) / 2.0 + np.sum(q_vec[1:-1] * T_full_cs[1:-1]) )\n\n    # Estimate derivative\n    sensitivity = np.imag(J_h_cs) / epsilon\n    \n    return sensitivity\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and print results.\n    \"\"\"\n    test_cases = [\n        # Case A\n        {'L': 0.1, 'N': 200, 'k0': 10.0, 'beta': 1e-2, 'theta': 5.0, 'q0': 1e6, 'T_left': 300.0, 'T_right': 310.0},\n        # Case B\n        {'L': 0.1, 'N': 200, 'k0': 10.0, 'beta': 1e-2, 'theta': 3.0, 'q0': 0.0, 'T_left': 300.0, 'T_right': 300.0},\n        # Case C\n        {'L': 0.1, 'N': 200, 'k0': 10.0, 'beta': 5e-2, 'theta': 8.0, 'q0': 5e5, 'T_left': 280.0, 'T_right': 320.0},\n    ]\n\n    results = []\n    \n    for case_params in test_cases:\n        N = case_params['N']\n        L = case_params['L']\n        q0 = case_params['q0']\n        h = L / N\n        case_params['h'] = h\n        \n        x_vec = np.linspace(0, L, N + 1)\n        q_vec = q0 * (1 + np.sin(np.pi * x_vec / L))\n        case_params['q_vec'] = q_vec\n        \n        # 1. Solve real forward problem\n        T_real = solve_forward(case_params, dtype=np.float64)\n        \n        # 2. Compute adjoint sensitivity\n        adj_sens = compute_adjoint_sensitivity(T_real, case_params)\n        \n        # 3. Compute complex-step sensitivity for validation\n        cs_sens = compute_cs_sensitivity(case_params)\n        \n        # 4. Calculate absolute difference and store\n        abs_diff = np.abs(adj_sens - cs_sens)\n        results.append(abs_diff)\n        \n    print(f\"[{','.join(f'{r:.15e}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}