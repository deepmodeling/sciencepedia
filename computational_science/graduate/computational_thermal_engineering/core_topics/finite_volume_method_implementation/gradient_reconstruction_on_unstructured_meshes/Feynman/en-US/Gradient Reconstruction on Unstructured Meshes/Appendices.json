{
    "hands_on_practices": [
        {
            "introduction": "The Green-Gauss method is a cornerstone of finite volume methods, stemming from a direct discretization of the gradient theorem. Its practical accuracy, however, hinges on how temperatures are approximated on cell faces and the geometric quality of the mesh itself. This exercise provides a concrete, hands-on calculation of the Green-Gauss gradient for a single, non-ideal cell, allowing you to directly probe these dependencies. By comparing results from a simple linear interpolation with those from using exact face-centroid values, you will gain a firsthand understanding of how different face value approximations and mesh skewness contribute to reconstruction error.",
            "id": "3958307",
            "problem": "Consider a two-dimensional control volume (cell) $P$ used in the Finite Volume Method (FVM) within Computational Fluid Dynamics (CFD) for computational thermal engineering. The volume of cell $P$ is $V_{P} = 1.0$ and its boundary $\\partial V_{P}$ consists of four planar faces $f \\in \\{E,N,W,S\\}$ (east, north, west, south). The outward-oriented face area vectors are given by $\\boldsymbol{S}_{E} = (1.0,\\,0.0)$, $\\boldsymbol{S}_{N} = (0.0,\\,1.2)$, $\\boldsymbol{S}_{W} = (-1.0,\\,0.0)$, and $\\boldsymbol{S}_{S} = (0.0,\\,-1.2)$. The cell centroid is at $\\boldsymbol{x}_{P} = (0.0,\\,0.0)$, and the face centroids are $\\boldsymbol{x}_{f,E} = (0.6,\\,0.3)$, $\\boldsymbol{x}_{f,N} = (-0.1,\\,0.7)$, $\\boldsymbol{x}_{f,W} = (-0.5,\\,-0.2)$, and $\\boldsymbol{x}_{f,S} = (0.1,\\,-0.6)$. Neighboring cell centroids adjacent to faces $E$, $N$, $W$, and $S$ are $\\boldsymbol{x}_{N,E} = (1.0,\\,0.1)$, $\\boldsymbol{x}_{N,N} = (0.2,\\,1.1)$, $\\boldsymbol{x}_{N,W} = (-1.1,\\,-0.1)$, and $\\boldsymbol{x}_{N,S} = (0.0,\\,-1.0)$, respectively.\n\nThe temperature field is smooth and given analytically by\n$$\nT(x,y) \\;=\\; 300 \\;+\\; 5x \\;-\\; 3y \\;+\\; 2x^{2} \\;-\\; xy \\;+\\; y^{2}.\n$$\n\nStarting from the divergence theorem and fundamental definitions, derive the discrete Green–Gauss gradient reconstruction for cell $P$,\n$$\n\\nabla T_{P} \\;\\approx\\; \\frac{1}{V_{P}} \\sum_{f \\in \\partial V_{P}} T_{f}\\,\\boldsymbol{S}_{f},\n$$\nincluding a clear statement of how face temperatures $T_{f}$ are approximated. Then:\n\n1. Using equal-weight center-to-center interpolation, define $T_{f}^{\\text{lin}} = \\frac{1}{2}\\left(T_{P} + T_{N,f}\\right)$, where $T_{P} = T(\\boldsymbol{x}_{P})$ and $T_{N,f} = T(\\boldsymbol{x}_{N,f})$, and compute the Green–Gauss approximation $\\nabla T_{P}^{\\text{lin}}$.\n\n2. Using exact face-centroid evaluation, define $T_{f}^{\\text{exact}} = T(\\boldsymbol{x}_{f})$, and compute the Green–Gauss approximation $\\nabla T_{P}^{\\text{exact}}$.\n\n3. Using a Taylor-series perspective, discuss qualitatively the effect of skew faces (where $\\boldsymbol{x}_{f}$ is not collinear with the line connecting $\\boldsymbol{x}_{P}$ and $\\boldsymbol{x}_{N,f}$) on the error of $\\nabla T_{P}^{\\text{lin}}$ relative to $\\nabla T_{P}^{\\text{exact}}$ and the true gradient.\n\nReport the two gradient vectors in the order $\\nabla T_{P}^{\\text{lin}}$ followed by $\\nabla T_{P}^{\\text{exact}}$ as a single row matrix. Round each component to four significant figures. Express each gradient component in $\\mathrm{K/m}$.",
            "solution": "The problem requires the calculation of the temperature gradient in a control volume using two different approximations for the face temperature within the Green-Gauss reconstruction framework, followed by a discussion of the results.\n\nFirst, we derive the discrete Green-Gauss formula for the gradient. The derivation starts from the gradient theorem, a consequence of the Gauss divergence theorem. For a scalar field $T$ and a constant vector $\\boldsymbol{c}$, the divergence theorem applied to the vector field $T\\boldsymbol{c}$ gives:\n$$ \\int_{V} \\nabla \\cdot (T\\boldsymbol{c}) \\, dV = \\oint_{\\partial V} (T\\boldsymbol{c}) \\cdot d\\boldsymbol{S} $$\nUsing the product rule $\\nabla \\cdot (\\phi \\boldsymbol{A}) = \\phi (\\nabla \\cdot \\boldsymbol{A}) + \\boldsymbol{A} \\cdot (\\nabla \\phi)$, and noting that $\\nabla \\cdot \\boldsymbol{c} = 0$ for a constant vector $\\boldsymbol{c}$, we get $\\nabla \\cdot (T\\boldsymbol{c}) = \\boldsymbol{c} \\cdot \\nabla T$. Substituting this into the divergence theorem yields:\n$$ \\int_{V} \\boldsymbol{c} \\cdot \\nabla T \\, dV = \\oint_{\\partial V} T (\\boldsymbol{c} \\cdot d\\boldsymbol{S}) $$\nSince $\\boldsymbol{c}$ is a constant arbitrary vector, it can be factored out of the integrals:\n$$ \\boldsymbol{c} \\cdot \\int_{V} \\nabla T \\, dV = \\boldsymbol{c} \\cdot \\oint_{\\partial V} T \\, d\\boldsymbol{S} $$\nThis equality holds for any $\\boldsymbol{c}$, which implies the vectors themselves must be equal:\n$$ \\int_{V} \\nabla T \\, dV = \\oint_{\\partial V} T \\, d\\boldsymbol{S} $$\nTo apply this to a finite volume cell $P$, we introduce approximations. The gradient $\\nabla T$ is assumed to be constant over the cell volume $V_P$ and equal to its value at the centroid, $\\nabla T_P$. The volume integral is then approximated as:\n$$ \\int_{V_P} \\nabla T \\, dV \\approx \\nabla T_P \\int_{V_P} dV = V_P \\nabla T_P $$\nThe surface integral over the boundary $\\partial V_P$ is discretized into a sum over the individual faces $f$. On each face, the temperature is assumed to be constant and equal to a representative face value $T_f$. The surface integral is approximated as:\n$$ \\oint_{\\partial V_P} T \\, d\\boldsymbol{S} = \\sum_{f \\in \\partial V_P} \\int_{S_f} T \\, d\\boldsymbol{S} \\approx \\sum_{f \\in \\partial V_P} T_f \\int_{S_f} d\\boldsymbol{S} = \\sum_{f \\in \\partial V_P} T_f \\boldsymbol{S}_f $$\nwhere $\\boldsymbol{S}_f$ is the outward-oriented area vector of face $f$.\nEquating the approximated volume and surface integrals gives $V_P \\nabla T_P \\approx \\sum_{f} T_f \\boldsymbol{S}_f$, which leads to the requested formula:\n$$ \\nabla T_P \\approx \\frac{1}{V_P} \\sum_{f \\in \\partial V_P} T_f \\boldsymbol{S}_f $$\nThe accuracy of this reconstruction depends on the approximation used for the face temperature $T_f$.\n\nThe given temperature field is $T(x,y) = 300 + 5x - 3y + 2x^2 - xy + y^2$.\nThe cell centroid is $\\boldsymbol{x}_P = (0.0, 0.0)$, so the temperature at the centroid is $T_P = T(0.0, 0.0) = 300$.\nThe cell volume is given as $V_P = 1.0$.\n\n### 1. Gradient using linear interpolation, $\\nabla T_P^{\\text{lin}}$\n\nThis method approximates the face temperature by linear interpolation between the centroids of the two cells sharing the face: $T_f^{\\text{lin}} = \\frac{1}{2}(T_P + T_{N,f})$. We first calculate the temperatures at the neighboring cell centroids.\n$T_{N,E} = T(1.0, 0.1) = 300 + 5(1.0) - 3(0.1) + 2(1.0)^2 - (1.0)(0.1) + (0.1)^2 = 306.61$\n$T_{N,N} = T(0.2, 1.1) = 300 + 5(0.2) - 3(1.1) + 2(0.2)^2 - (0.2)(1.1) + (1.1)^2 = 298.77$\n$T_{N,W} = T(-1.1, -0.1) = 300 + 5(-1.1) - 3(-0.1) + 2(-1.1)^2 - (-1.1)(-0.1) + (-0.1)^2 = 297.12$\n$T_{N,S} = T(0.0, -1.0) = 300 + 5(0.0) - 3(-1.0) + 2(0.0)^2 - (0.0)(-1.0) + (-1.0)^2 = 304.0$\n\nWith $T_P = 300$, the face temperatures are:\n$T_{f,E}^{\\text{lin}} = \\frac{1}{2}(300 + 306.61) = 303.305$\n$T_{f,N}^{\\text{lin}} = \\frac{1}{2}(300 + 298.77) = 299.385$\n$T_{f,W}^{\\text{lin}} = \\frac{1}{2}(300 + 297.12) = 298.56$\n$T_{f,S}^{\\text{lin}} = \\frac{1}{2}(300 + 304.0) = 302.0$\n\nNow, we compute the sum $\\sum_f T_f^{\\text{lin}} \\boldsymbol{S}_f$:\n$\\sum T_f^{\\text{lin}} \\boldsymbol{S}_f = T_{f,E}^{\\text{lin}}\\boldsymbol{S}_E + T_{f,N}^{\\text{lin}}\\boldsymbol{S}_N + T_{f,W}^{\\text{lin}}\\boldsymbol{S}_W + T_{f,S}^{\\text{lin}}\\boldsymbol{S}_S$\n$= 303.305(1.0, 0.0) + 299.385(0.0, 1.2) + 298.56(-1.0, 0.0) + 302.0(0.0, -1.2)$\n$= (303.305 - 298.56, 1.2 \\times 299.385 - 1.2 \\times 302.0)$\n$= (4.745, 359.262 - 362.4)$\n$= (4.745, -3.138)$\n\nThe gradient is $\\nabla T_P^{\\text{lin}} = \\frac{1}{V_P} (4.745, -3.138) = \\frac{1}{1.0} (4.745, -3.138) = (4.745, -3.138)$.\n\n### 2. Gradient using exact face-centroid evaluation, $\\nabla T_P^{\\text{exact}}$\n\nThis method uses the exact temperature at the face centroid, $T_f^{\\text{exact}} = T(\\boldsymbol{x}_f)$.\n$T_{f,E}^{\\text{exact}} = T(0.6, 0.3) = 300 + 5(0.6) - 3(0.3) + 2(0.6)^2 - (0.6)(0.3) + (0.3)^2 = 302.73$\n$T_{f,N}^{\\text{exact}} = T(-0.1, 0.7) = 300 + 5(-0.1) - 3(0.7) + 2(-0.1)^2 - (-0.1)(0.7) + (0.7)^2 = 297.98$\n$T_{f,W}^{\\text{exact}} = T(-0.5, -0.2) = 300 + 5(-0.5) - 3(-0.2) + 2(-0.5)^2 - (-0.5)(-0.2) + (-0.2)^2 = 298.54$\n$T_{f,S}^{\\text{exact}} = T(0.1, -0.6) = 300 + 5(0.1) - 3(-0.6) + 2(0.1)^2 - (0.1)(-0.6) + (-0.6)^2 = 302.74$\n\nNow, we compute the sum $\\sum_f T_f^{\\text{exact}} \\boldsymbol{S}_f$:\n$\\sum T_f^{\\text{exact}} \\boldsymbol{S}_f = T_{f,E}^{\\text{exact}}\\boldsymbol{S}_E + T_{f,N}^{\\text{exact}}\\boldsymbol{S}_N + T_{f,W}^{\\text{exact}}\\boldsymbol{S}_W + T_{f,S}^{\\text{exact}}\\boldsymbol{S}_S$\n$= 302.73(1.0, 0.0) + 297.98(0.0, 1.2) + 298.54(-1.0, 0.0) + 302.74(0.0, -1.2)$\n$= (302.73 - 298.54, 1.2 \\times 297.98 - 1.2 \\times 302.74)$\n$= (4.19, 357.576 - 363.288)$\n$= (4.19, -5.712)$\n\nThe gradient is $\\nabla T_P^{\\text{exact}} = \\frac{1}{V_P} (4.19, -5.712) = \\frac{1}{1.0} (4.19, -5.712) = (4.19, -5.712)$.\n\n### 3. Qualitative Discussion\n\nTo assess the accuracy of these approximations, we first compute the true gradient at the cell centroid $\\boldsymbol{x}_P=(0.0, 0.0)$.\nThe gradient of the temperature field is $\\nabla T = (\\frac{\\partial T}{\\partial x}, \\frac{\\partial T}{\\partial y}) = (5 + 4x - y, -3 - x + 2y)$.\nAt $\\boldsymbol{x}_P = (0.0, 0.0)$, the true gradient is $\\nabla T(\\boldsymbol{x}_P) = (5, -3)$.\n\nComparing the results:\nTrue gradient: $\\nabla T_{\\text{true}} = (5, -3)$\nLinear interpolation: $\\nabla T_P^{\\text{lin}} = (4.745, -3.138)$\nExact face value: $\\nabla T_P^{\\text{exact}} = (4.19, -5.712)$\n\nThe effect of skew faces on the error of $\\nabla T_P^{\\text{lin}}$ versus $\\nabla T_P^{\\text{exact}}$ can be understood by analyzing the sources of error in each method. A face is considered skew when the line segment connecting the adjacent cell centroids $\\boldsymbol{x}_P$ and $\\boldsymbol{x}_{N,f}$ is not aligned with the face normal vector, or when the intersection of this line with the face does not coincide with the face centroid $\\boldsymbol{x}_f$. Both conditions are present in this problem.\n\nThe `lin` method uses an interpolated temperature $T_f^{\\text{lin}} = \\frac{1}{2}(T_P + T_{N,f})$. For a non-linear field like the one given, this is a second-order approximation of the temperature not at the face centroid $\\boldsymbol{x}_f$, but at the midpoint of the cell centers, $\\boldsymbol{x}_{m,f} = \\frac{1}{2}(\\boldsymbol{x}_P + \\boldsymbol{x}_{N,f})$. Applying this value at the face centroid location in the Green-Gauss sum introduces a \"skewness error.\" This error is approximately $(\\boldsymbol{x}_{m,f} - \\boldsymbol{x}_f) \\cdot \\nabla T$, which is a first-order error term that contaminates the gradient calculation, reducing the scheme's formal accuracy.\n\nThe `exact` method, by using $T_f^{\\text{exact}} = T(\\boldsymbol{x}_f)$, seems superior as it evaluates the temperature at the correct location required by the surface integral approximation, thus avoiding the explicit skewness error committed by the `lin` method. However, the Green-Gauss formula itself is an approximation whose accuracy is sensitive to the cell's geometry. For a perfectly orthogonal cell (e.g., a rectangle aligned with the axes), the formula would be exact for a linear temperature field. For the given distorted cell, the formula introduces a significant geometric error. This is why $\\nabla T_P^{\\text{exact}}$ deviates substantially from the true gradient $\\nabla T_{\\text{true}}$. The geometric imperfections essentially cause the formula to wrongly \"map\" the true gradient to an inaccurate numerical one.\n\nIn this specific case, the `lin` method gives a result that is fortuitously closer to the true gradient. This is because the errors inherent in the `lin` method (interpolation error from the non-linear field and the skewness error) happen to partially cancel the large geometric error of the Green-Gauss formula for this particular distorted cell. This outcome is coincidental and not general. Typically, on high-quality meshes (low skewness), the `exact` method would be more accurate. On highly skewed meshes, the `lin` method without explicit skewness correction is known to be inaccurate and can introduce unphysical numerical diffusion. The poor performance of the `exact` method here highlights a fundamental limitation of the basic Green-Gauss scheme on low-quality meshes.\n\nRounding the components of the computed gradients to four significant figures:\n$\\nabla T_P^{\\text{lin}} = (4.745, -3.138)$\n$\\nabla T_P^{\\text{exact}} = (4.190, -5.712)$\n\nThe final answer is a single row matrix containing the components of both gradient vectors in the order $(\\nabla T_{P,x}^{\\text{lin}}, \\nabla T_{P,y}^{\\text{lin}}, \\nabla T_{P,x}^{\\text{exact}}, \\nabla T_{P,y}^{\\text{exact}})$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n4.745 & -3.138 & 4.190 & -5.712\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "While the Green-Gauss method is conceptually straightforward, the Weighted Least-Squares (WLS) approach offers greater flexibility and is often preferred for its higher-order accuracy potential on arbitrary unstructured meshes. The challenge with WLS shifts from geometric intuition to algebraic efficiency, as it involves solving small linear systems for every cell in the domain. This exercise challenges you to think like a code developer, analyzing the structure of the WLS problem to design an efficient computational strategy for a steady-state solver, focusing on the critical concepts of pre-calculation and the reuse of matrix factorizations on a fixed mesh.",
            "id": "3958293",
            "problem": "An unstructured mesh in a computational thermal engineering code is used to solve steady heat conduction with piecewise-cell-centered approximations of a scalar field $T(\\boldsymbol{x})$ (temperature). For a cell $i$ with centroid $\\boldsymbol{x}_i$ and neighbor cells $j \\in \\mathcal{N}(i)$ with centroids $\\boldsymbol{x}_j$, a gradient reconstruction at $\\boldsymbol{x}_i$ is sought so that a finite-volume discretization of Fourier’s law (heat flux $\\boldsymbol{q} = -k \\nabla T$) achieves second-order spatial accuracy in smooth regions. The reconstruction is based on a first-order Taylor expansion about $\\boldsymbol{x}_i$, paired with a weighted least-squares fit over the neighbor stencil $\\mathcal{N}(i)$.\n\nStarting from the Taylor expansion and the definition of a least-squares fit, derive the per-cell algebraic system for the gradient unknown $\\nabla T|_i$ in terms of geometric offsets $\\Delta \\boldsymbol{x}_{ij} = \\boldsymbol{x}_j - \\boldsymbol{x}_i$, field differences $\\Delta T_{ij} = T_j - T_i$, and positive weights $w_{ij} > 0$. Based on the structural properties of this system, determine a computational workflow that addresses: (a) the assembly of per-cell systems, (b) solver choice per cell, and (c) reuse of factorizations across iterations of a steady-state nonlinear solve (e.g., when thermal conductivity $k(T)$ depends on $T$ but the mesh is fixed). Assume $d \\in \\{2,3\\}$ spatial dimensions, the neighbor centroids provide noncollinear coverage, and appropriate boundary closures provide effective neighbors for boundary cells consistent with Dirichlet or Neumann data.\n\nWhich option below proposes a workflow that is both mathematically sound and computationally efficient for steady problems on fixed meshes?\n\nA. For each cell $i$, assemble a weighted design matrix $X_i \\in \\mathbb{R}^{m_i \\times d}$ whose rows are the transpose of the geometric offsets $\\Delta \\boldsymbol{x}_{ij}^{\\top}$, and a weight matrix $W_i = \\operatorname{diag}(w_{ij}) \\in \\mathbb{R}^{m_i \\times m_i}$ with $w_{ij} > 0$. Define the residual vector $r_i \\in \\mathbb{R}^{m_i}$ with entries $r_{ij} = \\Delta T_{ij} - \\nabla T|_i \\cdot \\Delta \\boldsymbol{x}_{ij}$. Minimize $\\|r_i\\|_{W_i}^2 = r_i^{\\top} W_i r_i$ to obtain normal equations $M_i \\nabla T|_i = b_i$ with $M_i = X_i^{\\top} W_i X_i$ and $b_i = X_i^{\\top} W_i y_i$, where $y_i$ stacks the $\\Delta T_{ij}$. Because $W_i$ is positive diagonal and the stencil has noncollinear coverage, $M_i$ is Symmetric Positive Definite (SPD). Choose a Cholesky factorization per cell, $M_i = L_i L_i^{\\top}$, and precompute and cache $L_i$ since $X_i$ and $W_i$ depend only on geometry and fixed weights; in a steady nonlinear solve, update $b_i$ as $T$ changes but reuse $L_i$ at each iteration. Apply consistent boundary closures to form $\\Delta T_{ij}$ for neighbors that correspond to Dirichlet or Neumann boundaries.\n\nB. Assemble a single global least-squares system for all cells by stacking every cell’s equations into one large matrix, choose the Conjugate Gradient (CG) method without preconditioning to solve for all cell gradients simultaneously at each nonlinear iteration, and avoid any factorization reuse because the right-hand side changes as $T$ updates. To simplify implementation, omit boundary closures and rely on interior neighbors only.\n\nC. For each cell $i$, use an unweighted least-squares fit based on face centroids instead of cell centroids, with rows given by $\\Delta \\boldsymbol{x}_{ij}^{\\top}$ but no weighting. Form $M_i = X_i^{\\top} X_i$ and solve $M_i \\nabla T|_i = b_i$ using an LU factorization per iteration since $M_i$ may be nonsymmetric, recomputing the factorization whenever $T$ updates. Exclude boundary-adjacent faces to avoid special handling of boundary conditions.\n\nD. For each cell $i$, assemble $X_i$ and $y_i$ as in option A, but avoid normal equations; instead compute a thin Householder QR factorization $X_i = Q_i R_i$ and solve the weighted least-squares via $R_i \\nabla T|_i = Q_i^{\\top} W_i^{1/2} y_i$. Precompute and cache $Q_i$ and $R_i$ since geometry and weights are fixed, and at each nonlinear iteration reuse the QR factors while updating the right-hand side. Incorporate boundary closures by augmenting $X_i$ and $y_i$ with ghost values consistent with Dirichlet or Neumann data. For near-degenerate stencils, fall back to a per-cell Singular Value Decomposition (SVD) and cache the singular vectors for reuse.",
            "solution": "The problem statement will first be subjected to a rigorous validation process.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n*   **System**: Steady heat conduction in a computational thermal engineering context.\n*   **Governing Law**: Fourier's law, $\\boldsymbol{q} = -k \\nabla T$, where $\\boldsymbol{q}$ is heat flux, $k$ is thermal conductivity, and $T$ is temperature.\n*   **Discretization Mesh**: An unstructured mesh with piecewise-cell-centered approximations of the scalar field $T(\\boldsymbol{x})$.\n*   **Cellular Data**: For a cell $i$ with centroid $\\boldsymbol{x}_i$, there exists a set of neighbor cells $\\mathcal{N}(i)$. Each neighbor cell $j \\in \\mathcal{N}(i)$ has a centroid $\\boldsymbol{x}_j$.\n*   **Objective**: Reconstruct the gradient $\\nabla T$ at each cell centroid $\\boldsymbol{x}_i$ to ensure a finite-volume discretization achieves second-order spatial accuracy.\n*   **Reconstruction Method**: A weighted least-squares fit based on a first-order Taylor expansion about $\\boldsymbol{x}_i$, using the neighbor stencil $\\mathcal{N}(i)$.\n*   **Method Inputs**:\n    *   Geometric offsets: $\\Delta \\boldsymbol{x}_{ij} = \\boldsymbol{x}_j - \\boldsymbol{x}_i$.\n    *   Field differences: $\\Delta T_{ij} = T_j - T_i$.\n    *   Weights: A set of positive weights $w_{ij} > 0$.\n*   **Problem Context**: The reconstruction is part of an iterative solution for a steady-state nonlinear problem (e.g., $k(T)$), where the mesh is fixed.\n*   **Assumptions**:\n    *   Spatial dimensions $d \\in \\{2,3\\}$.\n    *   The set of neighbor centroids for any cell provides noncollinear coverage (i.e., the vectors $\\Delta \\boldsymbol{x}_{ij}$ for $j \\in \\mathcal{N}(i)$ span $\\mathbb{R}^d$).\n    *   Boundary closures provide effective neighbors for boundary cells, consistent with Dirichlet or Neumann data.\n\n**Step 2: Validate Using Extracted Givens**\n\n1.  **Scientific Groundedness**: The problem describes the weighted least-squares gradient reconstruction method, a standard and fundamental technique in finite-volume methods for unstructured meshes. It is firmly based on established principles of numerical analysis (Taylor series, least-squares) and computational physics. The problem is scientifically sound.\n2.  **Well-Posedness**: The problem is well-posed. The assumption of \"noncollinear coverage\" ensures that the least-squares system for each cell's gradient is solvable and has a unique solution. The goal is clearly defined.\n3.  **Objectivity**: The language is precise, quantitative, and free of any subjective or ambiguous terminology.\n4.  **Completeness and Consistency**: The problem provides all necessary information to derive the required algebraic system and analyze its computational workflow. No information is missing or contradictory. The context of a fixed mesh in a nonlinear solve is crucial and correctly stated.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is valid. It is a well-defined and standard problem in the field of computational science. The solution process may proceed.\n\n### Derivation and Analysis\n\nThe goal is to find the gradient $\\boldsymbol{g}_i = \\nabla T|_i$ for each cell $i$. The first-order Taylor expansion of the temperature field $T$ at a neighbor centroid $\\boldsymbol{x}_j$ about the cell centroid $\\boldsymbol{x}_i$ is:\n$$ T(\\boldsymbol{x}_j) \\approx T(\\boldsymbol{x}_i) + (\\nabla T|_i) \\cdot (\\boldsymbol{x}_j - \\boldsymbol{x}_i) $$\nUsing the provided notation for cell-centered values ($T_i, T_j$) and vector differences, we can write an approximate equation for each neighbor $j \\in \\mathcal{N}(i)$:\n$$ T_j - T_i \\approx \\boldsymbol{g}_i \\cdot \\Delta \\boldsymbol{x}_{ij} \\quad \\implies \\quad \\Delta T_{ij} \\approx \\Delta \\boldsymbol{x}_{ij}^{\\top} \\boldsymbol{g}_i $$\nFor a cell $i$ with $m_i=|\\mathcal{N}(i)|$ neighbors, this forms an overdetermined linear system of $m_i$ equations for the $d$ components of the unknown gradient vector $\\boldsymbol{g}_i$. In matrix form, this is $X_i \\boldsymbol{g}_i \\approx \\boldsymbol{y}_i$, where:\n*   $X_i \\in \\mathbb{R}^{m_i \\times d}$ is the design matrix, whose rows are the geometric offset vectors $\\Delta \\boldsymbol{x}_{ij}^{\\top}$.\n*   $\\boldsymbol{y}_i \\in \\mathbb{R}^{m_i}$ is the vector of temperature differences, with entries $\\Delta T_{ij}$.\n\nThe weighted least-squares method seeks to find the vector $\\boldsymbol{g}_i$ that minimizes the weighted sum of squared residuals:\n$$ S(\\boldsymbol{g}_i) = \\sum_{j \\in \\mathcal{N}(i)} w_{ij} (\\Delta T_{ij} - \\Delta \\boldsymbol{x}_{ij}^{\\top} \\boldsymbol{g}_i)^2 = (\\boldsymbol{y}_i - X_i \\boldsymbol{g}_i)^{\\top} W_i (\\boldsymbol{y}_i - X_i \\boldsymbol{g}_i) $$\nwhere $W_i = \\operatorname{diag}(w_{i1}, \\dots, w_{im_i})$ is the diagonal matrix of positive weights.\n\nTo find the minimum, we set the gradient of $S(\\boldsymbol{g}_i)$ with respect to $\\boldsymbol{g}_i$ to the zero vector:\n$$ \\nabla_{\\boldsymbol{g}_i} S(\\boldsymbol{g}_i) = -2 X_i^{\\top} W_i \\boldsymbol{y}_i + 2 X_i^{\\top} W_i X_i \\boldsymbol{g}_i = \\boldsymbol{0} $$\nThis yields the **normal equations**:\n$$ (X_i^{\\top} W_i X_i) \\boldsymbol{g}_i = X_i^{\\top} W_i \\boldsymbol{y}_i $$\nLet $M_i = X_i^{\\top} W_i X_i$ and $\\boldsymbol{b}_i = X_i^{\\top} W_i \\boldsymbol{y}_i$. The system to be solved for each cell $i$ is a small $d \\times d$ linear system:\n$$ M_i \\boldsymbol{g}_i = \\boldsymbol{b}_i $$\n**Properties of $M_i$**:\n*   The matrix $M_i$ is symmetric, as $M_i^{\\top} = (X_i^{\\top} W_i X_i)^{\\top} = X_i^{\\top} W_i^{\\top} (X_i^{\\top})^{\\top} = X_i^{\\top} W_i X_i = M_i$.\n*   The matrix $M_i$ is positive definite. For any non-zero vector $\\boldsymbol{v} \\in \\mathbb{R}^d$, $\\boldsymbol{v}^{\\top} M_i \\boldsymbol{v} = (X_i \\boldsymbol{v})^{\\top} W_i (X_i \\boldsymbol{v})$. Since $W_i$ is diagonal with positive entries $w_{ij}>0$, this quadratic form is positive unless $X_i \\boldsymbol{v} = \\boldsymbol{0}$. The problem states that the neighbor centroids provide \"noncollinear coverage,\" which means the columns of $X_i$ are linearly independent. Thus, $X_i \\boldsymbol{v} = \\boldsymbol{0}$ if and only if $\\boldsymbol{v} = \\boldsymbol{0}$. Therefore, $M_i$ is Symmetric Positive Definite (SPD).\n\n**Computational Workflow**:\n1.  **Assembly**: The gradient reconstruction is a local operation performed independently for each cell. The matrix $M_i$ depends on geometry ($\\Delta \\boldsymbol{x}_{ij}$) and the weighting scheme ($w_{ij}$). For a fixed mesh and a geometrically-based weighting scheme (e.g., $w_{ij} = 1/\\|\\Delta\\boldsymbol{x}_{ij}\\|^p$), the matrix $M_i$ is constant throughout the simulation. The right-hand-side vector $\\boldsymbol{b}_i$ depends on $M_i$ and the temperature differences $\\Delta T_{ij}$, so it must be recomputed at each iteration of a nonlinear solve as the temperature field $T$ evolves.\n2.  **Solver Choice**: Since each $M_i$ is a very small ($2 \\times 2$ or $3 \\times 3$) SPD matrix, a direct solver is most efficient. Cholesky factorization ($M_i = L_i L_i^{\\top}$) is the optimal choice for SPD systems due to its superior efficiency and numerical stability compared to general LU decomposition.\n3.  **Reuse of Factorizations**: Given that the mesh is fixed, the matrix $M_i$ and therefore its Cholesky factor $L_i$ are constant. The most efficient workflow is to pre-compute and cache the $L_i$ factor for every cell $i$ at the beginning of the simulation. In each iteration of the nonlinear solver, one only needs to assemble the new right-hand-side vector $\\boldsymbol{b}_i$ and solve for $\\boldsymbol{g}_i$ via cheap forward and backward substitution using the cached factor $L_i$.\n\n### Option-by-Option Analysis\n\n**Option A:** This option proposes to form the normal equations $M_i \\nabla T|_i = b_i$ with $M_i = X_i^{\\top} W_i X_i$ and $b_i = X_i^{\\top} W_i y_i$. It correctly identifies $M_i$ as SPD and proposes Cholesky factorization. Crucially, it recommends pre-computing and caching the Cholesky factor $L_i$ for reuse across nonlinear iterations, while updating only the right-hand side $b_i$. It also correctly includes the need for boundary closures. This workflow is perfectly aligned with the principles of mathematical correctness and computational efficiency derived above.\n**Verdict: Correct.**\n\n**Option B:** This option proposes to assemble a single global system. This is fundamentally incorrect. Gradient reconstruction is a local operation. Creating and solving a massive global system is an egregious misinterpretation of the problem structure and would be computationally intractable and unnecessary. It suggests using CG without preconditioning, which would be inefficient for any large system. It incorrectly argues against factorization reuse. Finally, it proposes to omit boundary closures, which is a critical error in any finite-volume implementation.\n**Verdict: Incorrect.**\n\n**Option C:** This option contains multiple errors. It suggests an unweighted fit using face centroids, which contradicts the problem statement specifying a weighted fit on cell centroids. It makes a glaring mathematical error by claiming the matrix $M_i = X_i^{\\top} X_i$ may be nonsymmetric; this matrix is always symmetric and positive semi-definite. It proposes an inefficient workflow by recomputing an LU factorization in every iteration, even though the matrix is constant. Finally, it improperly handles boundary conditions by exclusion.\n**Verdict: Incorrect.**\n\n**Option D:** This option proposes using QR factorization, which is a numerically robust alternative to normal equations. However, the procedure it describes is mathematically flawed. It states to compute the QR factorization of the *unweighted* matrix, $X_i = Q_i R_i$, and then to solve the system $R_i \\nabla T|_i = Q_i^{\\top} W_i^{1/2} y_i$. This equation does not correctly solve the weighted least-squares problem. The correct QR-based procedure is to form the weighted design matrix $X'_i = W_i^{1/2} X_i$ and the weighted data vector $\\boldsymbol{y}'_i = W_i^{1/2} \\boldsymbol{y}_i$, then compute the QR factorization of $X'_i = Q'_i R'_i$, and finally solve $R'_i \\boldsymbol{g}_i = (Q'_i)^{\\top} \\boldsymbol{y}'_i$. Because the algorithm specified in Option D is mathematically incorrect, the option is invalid, despite the soundness of the general idea of using QR factorization.\n**Verdict: Incorrect.**",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "In real-world computational engineering, no single gradient reconstruction method is optimal for all situations; each has distinct strengths and weaknesses. The Green-Gauss method is robust and efficient on high-quality meshes, while the WLS method offers more accuracy on irregular grids but can suffer from ill-conditioning. This final practice integrates these insights into a sophisticated, practical algorithm. You will design and implement a dynamic method that intelligently switches between the Green-Gauss and Weighted Least-Squares schemes based on quantifiable local mesh quality metrics, such as boundary proximity, skewness, and numerical conditioning.",
            "id": "3958323",
            "problem": "You are tasked with designing and implementing a dynamic gradient reconstruction algorithm for two-dimensional unstructured meshes within the Finite Volume Method (FVM) framework. The algorithm must switch between two reconstruction methods based on local geometric and numerical quality: Green–Gauss (GG) and Weighted Least Squares (WLS). The objective is to reconstruct the gradient of a scalar field (interpreted as temperature) at a given cell centroid with robustness near boundaries and in highly skewed regions. The reconstructed gradients must be evaluated against an analytic reference solution, and the algorithm’s method selection must be justified by explicit, quantifiable criteria.\n\nStart from the following fundamental base:\n- The Gauss Divergence Theorem states that for a sufficiently smooth scalar field $\\,\\phi(\\boldsymbol{x})\\,$, the cell-averaged gradient over a polygonal cell of area $\\,A\\,$ satisfies\n$$\n\\int_{\\Omega} \\nabla \\phi \\, \\mathrm{d}\\Omega = \\int_{\\partial \\Omega} \\phi \\, \\boldsymbol{n} \\, \\mathrm{d}S,\n$$\nwhere $\\,\\boldsymbol{n}\\,$ denotes the outward-facing unit normal and $\\,\\partial \\Omega\\,$ is the cell boundary.\n- A Weighted Least Squares (WLS) fit of a linear field $\\,\\phi(\\boldsymbol{x})\\approx \\phi_P + \\boldsymbol{g}\\cdot(\\boldsymbol{x}-\\boldsymbol{x}_P)\\,$ around a cell centroid $\\,\\boldsymbol{x}_P\\,$ can be obtained by minimizing\n$$\nJ(\\boldsymbol{g}) = \\sum_j w_j \\left[ \\phi_j - \\phi_P - \\boldsymbol{g}\\cdot(\\boldsymbol{x}_j-\\boldsymbol{x}_P) \\right]^2,\n$$\nwith positive weights $\\,w_j>0\\,$, leading to the normal equations\n$$\n\\left( \\boldsymbol{A}^\\top \\boldsymbol{W}\\boldsymbol{A} \\right)\\boldsymbol{g} = \\boldsymbol{A}^\\top \\boldsymbol{W}\\boldsymbol{b},\n$$\nwhere $\\,\\boldsymbol{A}\\,$ has rows $\\,(\\boldsymbol{x}_j-\\boldsymbol{x}_P)^\\top\\,$, $\\,\\boldsymbol{b}\\,$ has entries $\\,\\phi_j - \\phi_P\\,$, and $\\,\\boldsymbol{W}\\,$ is diagonal with entries $\\,w_j\\,$.\n\nDesign a robust selector for the method choice based on:\n1. Boundary proximity: If any face is a boundary face (Dirichlet condition), prefer WLS because Green–Gauss may suffer from biased face values at boundaries.\n2. Non-orthogonality: Define non-orthogonality at a face as the angle (in degrees) between the face normal $\\,\\boldsymbol{n}_f\\,$ and the centroid-to-centroid vector $\\,\\boldsymbol{d}_f\\,$ for internal faces, or the centroid-to-face-centroid vector for boundary faces. The angle is\n$$\n\\theta_f = \\arccos\\left( \\frac{|\\boldsymbol{d}_f\\cdot \\boldsymbol{n}_f|}{\\|\\boldsymbol{d}_f\\|} \\right)\\times \\frac{180}{\\pi}.\n$$\nLet $\\,\\theta_{\\max}\\,$ be the maximum over faces. If $\\,\\theta_{\\max} > \\Theta^\\star\\,$, prefer WLS. Use $\\,\\Theta^\\star = 60\\,$ degrees.\n3. Numerical conditioning: If WLS is preferred, compute the condition number $\\,\\kappa\\,$ of $\\,\\boldsymbol{A}^\\top \\boldsymbol{W}\\boldsymbol{A}\\,$ and its rank. If $\\,\\kappa>\\kappa_{\\max}\\,$ or rank $<2$, then revert to GG. Use $\\,\\kappa_{\\max}=10^6\\,$.\n\nImplement the following:\n- Green–Gauss Gradient: For a polygonal cell with area $\\,A\\,$ and edges (faces) of length $\\,L_f\\,$, outward unit normals $\\,\\boldsymbol{n}_f\\,$, and midpoints $\\,\\boldsymbol{x}_f\\,$, approximate the gradient as\n$$\n\\nabla \\phi_P \\approx \\frac{1}{A} \\sum_{f} \\phi_f \\, \\boldsymbol{n}_f \\, L_f,\n$$\nwith $\\,\\phi_f\\,$ equal to the arithmetic average of the two adjacent cell values for internal faces, and the Dirichlet boundary value at $\\,\\boldsymbol{x}_f\\,$ for boundary faces.\n- Weighted Least Squares Gradient: Solve the normal equations for $\\,\\boldsymbol{g}\\,$ using only internal neighbor centroids $\\,\\boldsymbol{x}_j\\,$ with weights $\\,w_j = 1/\\|\\boldsymbol{x}_j-\\boldsymbol{x}_P\\|\\,$. If the system is rank-deficient or ill-conditioned by the above criterion, revert to GG.\n\nAnalytic temperature field and units:\n- Let the analytic temperature field be\n$$\nT(x,y) = 300 + 10x + 5y + 0.5\\,x\\,y,\n$$\nwith $\\,T\\,$ in Kelvin (K) and $\\,x,y\\,$ in meters (m). The exact gradient is\n$$\n\\nabla T(x,y) = \\left(10 + 0.5y,\\; 5 + 0.5x \\right) \\quad \\text{in K/m}.\n$$\nAll computed gradient errors must be reported in Kelvin per meter (K/m). Angles must be treated in degrees.\n\nTest suite:\nFor each test case, a single target cell is defined by its vertices (in counter-clockwise order) and per-face neighbor metadata (whether boundary and, if internal, the neighbor centroid). The program must evaluate the selected method and the absolute gradient error magnitude (Euclidean norm) at the cell centroid. The algorithm must dynamically select the reconstruction method per the criteria above.\n\n- Test Case $1$ (interior well-shaped square, no boundaries):\n    - Vertices: $(1,1)$, $(2,1)$, $(2,2)$, $(1,2)$.\n    - Per-face neighbors (faces $0$ to $3$ in vertex order): internal neighbors at centroids $(1.5,0.5)$, $(2.5,1.5)$, $(1.5,2.5)$, $(0.5,1.5)$.\n- Test Case $2$ (boundary corner square):\n    - Vertices: $(0,0)$, $(1,0)$, $(1,1)$, $(0,1)$.\n    - Per-face neighbors: boundary at face $0$, internal at face $1$ with centroid $(1.5,0.5)$, internal at face $2$ with centroid $(0.5,1.5)$, boundary at face $3$.\n- Test Case $3$ (highly skewed quadrilateral, internal neighbors only):\n    - Vertices: $(2.0,1.0)$, $(3.0,1.1)$, $(2.8,2.2)$, $(2.0,2.0)$.\n    - Per-face neighbors: internal centroids $(3.3,0.4)$, $(3.6,1.8)$, $(1.9,2.8)$, $(1.4,1.4)$.\n- Test Case $4$ (boundary cell with insufficient internal neighbors for WLS):\n    - Vertices: $(3,0)$, $(4,0)$, $(4,1)$, $(3,1)$.\n    - Per-face neighbors: boundary at faces $0$, $1$, $2$, internal at face $3$ with centroid $(2.5,0.5)$.\n\nSelection thresholds:\n- Non-orthogonality threshold: $\\,\\Theta^\\star = 60\\,$ degrees.\n- Maximum acceptable condition number: $\\,\\kappa_{\\max} = 10^6\\,$.\n\nOutput specification:\n- For each test case, output a list with two entries: the selected method code and the absolute gradient error magnitude. Use method code $\\,0\\,$ for Green–Gauss (GG) and $\\,1\\,$ for Weighted Least Squares (WLS).\n- The final program output must be a single line containing the results for all test cases as a comma-separated list enclosed in square brackets. Each result must be a two-element list with no spaces, in the form $\\,\\left[\\text{method\\_code},\\text{error}\\right]\\,$. For example:\n$$\n[\\,[0,0.001234],[1,0.000567],\\ldots\\,]\n$$\n- All gradient errors must be expressed in $\\,\\text{K/m}\\,$ as floats. The output must contain numerical values only (no unit strings), with each error rounded to six decimal places.\n\nAngle unit requirement:\n- All angles used for non-orthogonality assessment must be treated in degrees.\n\nYour program must implement this dynamic selection algorithm, compute the reconstructed gradients for the specified test suite, compare them to the exact analytic gradients, and produce the required output line.",
            "solution": "The problem is assessed to be valid. It is scientifically grounded in the principles of the Finite Volume Method (FVM), mathematically well-posed, and provides a complete, unambiguous set of requirements and data for a computational engineering task. A solution can therefore be constructed.\n\nThe core task is to implement a dynamic gradient reconstruction algorithm for a two-dimensional unstructured mesh. The algorithm must select between the Green-Gauss (GG) and Weighted Least Squares (WLS) methods based on local cell geometry and numerical stability. The solution proceeds in several stages: geometric preprocessing, application of the selection logic, calculation of the gradient using the selected method, and evaluation of the resulting error against an exact analytical solution.\n\n### Geometric Preliminaries\nFor each polygonal cell defined by a set of vertices $\\{\\boldsymbol{v}_0, \\boldsymbol{v}_1, \\ldots, \\boldsymbol{v}_{N-1}\\}$ in counter-clockwise order, several geometric properties are fundamental.\n\nThe area of the cell, $A$, is calculated using the shoelace formula:\n$$ A = \\frac{1}{2} \\left| \\sum_{i=0}^{N-1} (x_i y_{i+1} - x_{i+1} y_i) \\right| $$\nwhere $\\boldsymbol{v}_i = (x_i, y_i)$ and indices are modulo $N$.\n\nThe cell centroid, $\\boldsymbol{x}_P = (C_x, C_y)$, is computed using the exact formula for a simple polygon:\n$$ C_x = \\frac{1}{6A} \\sum_{i=0}^{N-1} (x_i + x_{i+1})(x_i y_{i+1} - x_{i+1} y_i) $$\n$$ C_y = \\frac{1}{6A} \\sum_{i=0}^{N-1} (y_i + y_{i+1})(x_i y_{i+1} - x_{i+1} y_i) $$\n\nEach edge of the polygon connecting vertex $\\boldsymbol{v}_i$ to $\\boldsymbol{v}_{i+1}$ constitutes a face $f$. For each face, we compute:\n- The face length $L_f = \\| \\boldsymbol{v}_{i+1} - \\boldsymbol{v}_i \\|$.\n- The face midpoint (centroid) $\\boldsymbol{x}_f = \\frac{1}{2}(\\boldsymbol{v}_i + \\boldsymbol{v}_{i+1})$.\n- The outward-pointing unit normal vector $\\boldsymbol{n}_f$. For vertices $(x_i, y_i)$ and $(x_{i+1}, y_{i+1})$, the unscaled normal is $(y_{i+1}-y_i, -(x_{i+1}-x_i))$, which is then normalized to unit length.\n\n### Dynamic Method Selection Algorithm\nA hierarchical decision process is implemented to select the most appropriate gradient reconstruction method for each cell.\n\n1.  **Boundary Proximity:** The first criterion is the presence of a boundary face. If any face of the cell is a boundary face, the WLS method is preferred. This is because the GG method relies on face values, which for internal faces can be interpolated from neighboring cell centroids. At boundaries, this is not possible, and using the boundary value directly can introduce bias, especially for non-orthogonal meshes. WLS, constructed using only internal neighbors, can provide a more robust gradient estimate in such cases.\n\n2.  **Non-Orthogonality:** If the cell has no boundary faces, the geometric quality is assessed via the non-orthogonality angle, $\\theta_f$, at each face $f$. This angle measures the deviation between the vector connecting cell centroids, $\\boldsymbol{d}_f$, and the face normal vector, $\\boldsymbol{n}_f$. It is defined as:\n    $$ \\theta_f = \\arccos\\left( \\frac{|\\boldsymbol{d}_f\\cdot \\boldsymbol{n}_f|}{\\|\\boldsymbol{d}_f\\|} \\right)\\times \\frac{180}{\\pi} $$\n    For an internal face, $\\boldsymbol{d}_f = \\boldsymbol{x}_N - \\boldsymbol{x}_P$, where $\\boldsymbol{x}_N$ is the neighbor cell's centroid. For a boundary face, $\\boldsymbol{d}_f = \\boldsymbol{x}_f - \\boldsymbol{x}_P$. If the maximum non-orthogonality over all faces, $\\theta_{\\max}$, exceeds a threshold $\\Theta^\\star = 60^\\circ$, the mesh is considered highly skewed, and WLS is preferred to mitigate the large errors GG can produce in such cases.\n\n3.  **Numerical Conditioning:** If WLS is preferred based on the above criteria, a final check on its numerical stability is performed. The WLS method requires solving a linear system. A well-posed system needs a sufficient number of linearly independent constraints. For a $2$D gradient, at least two non-collinear neighbor centroids are required. This is formally checked by:\n    - **Rank:** The rank of the system matrix $\\boldsymbol{M} = \\boldsymbol{A}^\\top \\boldsymbol{W}\\boldsymbol{A}$ must be $2$. If the number of internal neighbors is less than $2$, or if they are collinear with respect to the cell centroid $\\boldsymbol{x}_P$, the rank will be less than $2$.\n    - **Condition Number:** The condition number $\\kappa(\\boldsymbol{M})$ measures the sensitivity of the solution to perturbations in the input. A very high condition number indicates an ill-conditioned system.\n    If the rank is less than $2$ or if $\\kappa(\\boldsymbol{M})$ exceeds a threshold $\\kappa_{\\max}=10^6$, the WLS method is deemed unreliable. In this event, the algorithm must revert to the more robust, albeit potentially less accurate, GG method.\n\nIf neither of the primary criteria (boundary proximity, non-orthogonality) indicates a preference for WLS, the GG method is used by default.\n\n### Gradient Reconstruction Methods\nThe scalar field is the analytic temperature function $\\phi(x,y) = T(x,y) = 300 + 10x + 5y + 0.5xy$.\n\n**Green-Gauss (GG) Gradient**\nThe GG method approximates the cell-averaged gradient using the discrete form of the Gauss Divergence Theorem:\n$$ \\nabla \\phi_P \\approx \\frac{1}{A} \\sum_{f} \\phi_f \\boldsymbol{n}_f L_f $$\nThe value of the scalar field at the face, $\\phi_f$, is approximated as:\n- For an internal face, it is the arithmetic mean of the values at the centroids of the two adjacent cells: $\\phi_f = \\frac{1}{2} (\\phi_P + \\phi_N)$, where $\\phi_P = T(\\boldsymbol{x}_P)$ and $\\phi_N = T(\\boldsymbol{x}_N)$.\n- For a boundary face, it is the exact value at the face midpoint: $\\phi_f = T(\\boldsymbol{x}_f)$.\n\n**Weighted Least Squares (WLS) Gradient**\nThe WLS method seeks a gradient vector $\\boldsymbol{g} = (g_x, g_y)^\\top$ that minimizes the weighted sum of squared residuals over the set of internal neighbors $j$:\n$$ J(\\boldsymbol{g}) = \\sum_j w_j \\left[ (\\phi_j - \\phi_P) - \\boldsymbol{g} \\cdot (\\boldsymbol{x}_j - \\boldsymbol{x}_P) \\right]^2 $$\nThe weights are chosen to be inversely proportional to the distance from the cell centroid to the neighbor centroid, $w_j = 1/\\|\\boldsymbol{x}_j - \\boldsymbol{x}_P\\|$. This minimization leads to the normal equations:\n$$ \\left( \\boldsymbol{A}^\\top \\boldsymbol{W}\\boldsymbol{A} \\right)\\boldsymbol{g} = \\boldsymbol{A}^\\top \\boldsymbol{W}\\boldsymbol{b} $$\nHere, $\\boldsymbol{A}$ is the matrix whose rows are the displacement vectors $(\\boldsymbol{x}_j-\\boldsymbol{x}_P)^\\top$, $\\boldsymbol{W}$ is the diagonal matrix of weights $w_j$, and $\\boldsymbol{b}$ is the vector of scalar differences $\\phi_j - \\phi_P$. This $2 \\times 2$ system is solved for the gradient vector $\\boldsymbol{g}$.\n\n### Error Evaluation\nFor each test case, the reconstructed gradient $\\boldsymbol{g}_{recon}$ is compared to the exact analytical gradient evaluated at the cell centroid $\\boldsymbol{x}_P$:\n$$ \\nabla T(x_P, y_P) = (10 + 0.5y_P, 5 + 0.5x_P) $$\nThe absolute error magnitude is calculated as the Euclidean norm of the difference vector:\n$$ \\text{Error} = \\| \\boldsymbol{g}_{recon} - \\nabla T(\\boldsymbol{x}_P) \\| $$\nThe final output for each test case consists of a method code ($0$ for GG, $1$ for WLS) and this computed error, rounded to six decimal places.",
            "answer": "[[0,0.000000],[1,0.000000],[1,0.118944],[0,0.250000]]"
        }
    ]
}