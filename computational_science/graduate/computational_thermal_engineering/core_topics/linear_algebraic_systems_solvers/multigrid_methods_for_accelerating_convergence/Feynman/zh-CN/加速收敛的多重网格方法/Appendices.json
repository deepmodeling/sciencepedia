{
    "hands_on_practices": [
        {
            "introduction": "多重网格方法的核心思想是在不同尺度的网格上处理误差的不同频率分量。其中，“松弛”（smoothing）步骤是关键，它负责高效地衰减高频误差分量。本练习将引导您使用局部傅里叶分析（Local Fourier Analysis, LFA）——一种用于分析网格上线性算子行为的强大工具——来量化加权雅可比（weighted Jacobi）松弛器的性能，并为其找到最优的松弛参数。通过这个实践，您将深入理解“松弛特性”的数学本质，并掌握优化多重网格方法基本组件的分析技术。",
            "id": "3974232",
            "problem": "考虑一个无穷二维均匀笛卡尔网格（网格间距为 $h$）上的均匀各向同性介质中的稳态热传导，该过程由泊松方程 $-\\nabla^{2} T = f$ 描述。使用拉普拉斯算子的标准二阶五点有限差分近似，离散算子 $A$ 的模板为 $\\frac{1}{h^{2}}\\begin{pmatrix}  -1  \\\\ -1  4  -1 \\\\  -1  \\end{pmatrix}$，且 $A$ 的对角部分 $D$ 为 $D = \\frac{4}{h^{2}} I$。在一个采用 $2 \\times 2$ 粗化、全加权限制和双线性插值的双网格方法中，一种常见的光滑子是加权雅可比方法，其对迭代量 $u^{(k)}$ 的定义为 $u^{(k+1)} = u^{(k)} + \\omega D^{-1}\\left(b - A u^{(k)}\\right)$，其中 $\\omega \\in (0,1)$ 是松弛参数。\n\n使用局部傅里叶分析（LFA; Local Fourier Analysis），分析此无穷网格上算子的加权雅可比光滑子的误差传播符号。定义高频集为两个分量都在粗网格可表示频带之外的傅里叶模式，具体来说是 $|\\theta_{x}| \\in [\\pi/2,\\pi]$ 和 $|\\theta_{y}| \\in [\\pi/2,\\pi]$。确定松弛参数 $\\omega$ 的值，该值使得光滑子符号在此高频集上的最坏情况（最大）幅值最小。将最终答案表示为精确数，无需四舍五入。",
            "solution": "该问题要求确定用于二维泊松方程多重网格方法中加权雅可比光滑子的最优松弛参数 $\\omega$。该优化需使用局部傅里叶分析 (LFA) 在指定的高频模式集上进行。\n\n首先，我们建立 LFA 的分析框架。在一个网格间距为 $h$ 的无穷均匀笛卡尔网格上，一个离散函数由其傅里叶分量表示。一个傅里叶模式是任何线性移不变算子（如有限差分算子 $A$）的特征函数。一个具有无量纲波向量 $\\theta = (\\theta_x, \\theta_y) \\in [-\\pi, \\pi]^2$ 的模式由 $\\phi_{\\theta}(j) = \\exp(i j \\cdot \\theta)$ 给出，其中 $j = (j_x, j_y)$ 是网格索引。一个算子对应于此模式的特征值被称为该算子的符号。\n\n离散算子 $A$ 由负拉普拉斯算子的五点模板给出：\n$$\n(A u)_j = \\frac{1}{h^2} \\left( 4u_j - u_{j+(1,0)} - u_{j-(1,0)} - u_{j+(0,1)} - u_{j-(0,1)} \\right)\n$$\n为了求得符号 $\\hat{A}(\\theta)$，我们将 $A$ 应用于傅里叶模式 $\\phi_{\\theta}(j)$：\n$$\n(A \\phi_{\\theta})_j = \\frac{1}{h^2} \\left( 4e^{i j \\cdot \\theta} - e^{i (j_x+1)\\theta_x}e^{i j_y\\theta_y} - e^{i (j_x-1)\\theta_x}e^{i j_y\\theta_y} - e^{i j_x\\theta_x}e^{i (j_y+1)\\theta_y} - e^{i j_x\\theta_x}e^{i (j_y-1)\\theta_y} \\right)\n$$\n提出公因子 $\\phi_{\\theta}(j) = e^{i j \\cdot \\theta}$：\n$$\n(A \\phi_{\\theta})_j = \\frac{1}{h^2} \\phi_{\\theta}(j) \\left( 4 - e^{i\\theta_x} - e^{-i\\theta_x} - e^{i\\theta_y} - e^{-i\\theta_y} \\right)\n$$\n使用恒等式 $2\\cos(x) = e^{ix} + e^{-ix}$，$A$ 的符号为：\n$$\n\\hat{A}(\\theta) = \\frac{1}{h^2} \\left( 4 - 2\\cos(\\theta_x) - 2\\cos(\\theta_y) \\right) = \\frac{2}{h^2} \\left( 2 - \\cos(\\theta_x) - \\cos(\\theta_y) \\right)\n$$\n使用半角恒等式 $1 - \\cos(x) = 2\\sin^2(x/2)$，这可以重写为：\n$$\n\\hat{A}(\\theta) = \\frac{4}{h^2} \\left( \\sin^2\\left(\\frac{\\theta_x}{2}\\right) + \\sin^2\\left(\\frac{\\theta_y}{2}\\right) \\right)\n$$\n加权雅可比迭代由 $u^{(k+1)} = u^{(k)} + \\omega D^{-1}(b - A u^{(k)})$ 给出。误差 $e^{(k)} = u^{(k)} - u$（其中 $Au=b$）根据光滑算子 $S = I - \\omega D^{-1} A$ 进行传播。我们需要 $S$ 的符号，记为 $\\hat{S}(\\theta)$。\n算子 $D$ 是 $A$ 的对角部分，即 $D = \\frac{4}{h^2}I$。其逆为 $D^{-1} = \\frac{h^2}{4}I$。$D$ 和 $D^{-1}$ 的符号分别是标量 $\\hat{D} = \\frac{4}{h^2}$ 和 $\\hat{D}^{-1} = \\frac{h^2}{4}$。\n\n那么光滑算子 $S$ 的符号是：\n$$\n\\hat{S}(\\theta) = 1 - \\omega \\hat{D}^{-1} \\hat{A}(\\theta) = 1 - \\omega \\left(\\frac{h^2}{4}\\right) \\left[ \\frac{4}{h^2} \\left( \\sin^2\\left(\\frac{\\theta_x}{2}\\right) + \\sin^2\\left(\\frac{\\theta_y}{2}\\right) \\right) \\right]\n$$\n$$\n\\hat{S}(\\theta) = 1 - \\omega \\left( \\sin^2\\left(\\frac{\\theta_x}{2}\\right) + \\sin^2\\left(\\frac{\\theta_y}{2}\\right) \\right)\n$$\n这就是误差传播符号，也称为模式 $\\theta$ 的光滑因子。我们将其记为 $\\mu(\\theta, \\omega)$。\n\n问题将高频集定义为 $HF = \\{ (\\theta_x, \\theta_y) : |\\theta_x| \\in [\\pi/2, \\pi] \\text{ and } |\\theta_y| \\in [\\pi/2, \\pi] \\}$。我们需要找到 $\\omega \\in (0,1)$ 的值，使得 $\\mu(\\theta, \\omega)$ 在此集合上的最坏情况（最大）幅值最小。\n$$\n\\min_{\\omega \\in (0,1)} \\max_{\\theta \\in HF} |\\mu(\\theta, \\omega)|\n$$\n设依赖于频率的项为 $C(\\theta) = \\sin^2(\\frac{\\theta_x}{2}) + \\sin^2(\\frac{\\theta_y}{2})$。则符号为 $\\mu(\\theta, \\omega) = 1 - \\omega C(\\theta)$。\n我们首先确定当 $\\theta \\in HF$ 时 $C(\\theta)$ 的范围。函数 $\\sin^2(x/2)$ 在 $x \\in [0, \\pi]$ 上是单调递增的。由于 $\\sin^2(x/2)$ 是 $x$ 的偶函数，我们只需要考虑 $\\theta_x, \\theta_y \\in [\\pi/2, \\pi]$。\n当 $\\alpha \\in [\\pi/2, \\pi]$ 时，$\\sin^2(\\alpha/2)$ 的最小值在 $\\alpha = \\pi/2$ 处取得：$\\sin^2(\\frac{\\pi/2}{2}) = \\sin^2(\\pi/4) = (\\frac{1}{\\sqrt{2}})^2 = \\frac{1}{2}$。\n最大值在 $\\alpha = \\pi$ 处取得：$\\sin^2(\\pi/2) = 1^2 = 1$。\n因此，对于 $\\theta \\in HF$，项 $\\sin^2(\\theta_x/2)$ 的范围是 $[1/2, 1]$，$\\sin^2(\\theta_y/2)$ 的范围也是如此。\n因此，它们的和 $C(\\theta)$ 的范围是：\n$$\nC_{min} = \\frac{1}{2} + \\frac{1}{2} = 1 \\quad (\\text{在 } |\\theta_x|=|\\theta_y|=\\pi/2 \\text{ 处})\n$$\n$$\nC_{max} = 1 + 1 = 2 \\quad (\\text{在 } |\\theta_x|=|\\theta_y|=\\pi \\text{ 处})\n$$\n所以，对于 $\\theta \\in HF$，$C(\\theta)$ 的取值范围是区间 $[1, 2]$。\n\n我们的问题简化为求解以下极小化极大问题中的 $\\omega$：\n$$\n\\min_{\\omega \\in (0,1)} \\max_{C \\in [1, 2]} |1 - \\omega C|\n$$\n函数 $g(C) = 1 - \\omega C$ 是关于 $C$ 的线性函数。对于固定的 $\\omega  0$，线性函数在一个区间 $[C_{min}, C_{max}]$ 上的最大绝对值必然在端点 $C=1$ 或 $C=2$ 处取得。\n所以，我们需要最小化：\n$$\n\\max(|1 - \\omega \\cdot 1|, |1 - \\omega \\cdot 2|) = \\max(|1 - \\omega|, |1 - 2\\omega|)\n$$\n最优的 $\\omega$ 值在两个边界点的幅值相等时取得，因为这平衡了极端频率分量的放大。对于最小化两个关于参数一个递减、一个递增的函数的最大值问题，这是一个标准结果。\n我们令 $|1 - \\omega| = |1 - 2\\omega|$。\n由于问题指定 $\\omega \\in (0,1)$，项 $1-\\omega$ 总是正的，所以 $|1-\\omega| = 1-\\omega$。\n对于项 $|1-2\\omega|$，我们考虑关于 $\\omega$ 的两种情况：\n1. 如果 $\\omega \\in (0, 1/2]$，那么 $1-2\\omega \\ge 0$，所以 $|1-2\\omega| = 1-2\\omega$。方程变为 $1-\\omega = 1-2\\omega$，这意味着 $\\omega=0$，这个值在指定的区间 $(0,1)$ 之外。\n2. 如果 $\\omega \\in (1/2, 1)$，那么 $1-2\\omega  0$，所以 $|1-2\\omega| = -(1-2\\omega) = 2\\omega - 1$。方程变为：\n$$\n1 - \\omega = 2\\omega - 1\n$$\n$$\n2 = 3\\omega\n$$\n$$\n\\omega = \\frac{2}{3}\n$$\n这个值 $\\omega = 2/3$ 位于区间 $(1/2, 1)$ 内，因此它是一个有效的候选值。在此值下，最大幅值为 $|1 - 2/3| = |1 - 2(2/3)| = |1 - 4/3| = 1/3$。\n为了确认这是最小值，我们可以分析函数 $f(\\omega) = \\max(1-\\omega, |1-2\\omega|)$ 在 $\\omega \\in (0,1)$ 上的行为。\n对于 $\\omega \\in (0, 1/2)$，$f(\\omega) = \\max(1-\\omega, 1-2\\omega) = 1-\\omega$。这是一个递减函数，所以它在这个开区间上的最小值在 $\\omega=1/2$ 处逼近，值为 $1/2$。\n对于 $\\omega \\in [1/2, 1)$，$f(\\omega) = \\max(1-\\omega, 2\\omega-1)$。在这里，$1-\\omega$ 是递减的，$2\\omega-1$ 是递增的。它们最大值的最小值出现在它们的交点处，我们已经求得该交点为 $\\omega=2/3$，此时的值为 $1/3$。\n比较这两个区间的结果，$\\omega \\in (0,1)$ 上的全局最小值是 $1/3$，在 $\\omega = 2/3$ 处取得。\n\n因此，使得光滑子符号在指定高频集上的最坏情况幅值最小的松弛参数 $\\omega$ 的值为 $2/3$。",
            "answer": "$$\\boxed{\\frac{2}{3}}$$"
        },
        {
            "introduction": "在松弛步骤处理完高频误差后，剩下的误差分量变得平滑，适合在更粗的网格上进行求解。为了在粗网格上建立有效的误差修正方程，我们需要一个“粗网格算子”。本练习将聚焦于伽辽金（Galerkin）构造法，这是一种从细网格算子和网格间转移算子出发，系统地构建粗网格算子的稳健方法。您将为一个可变系数的一维热传导问题推导出伽辽金粗网格算子的具体形式，并证明它继承了细网格算子的对称正定性（Symmetric Positive Definite, SPD），从而确保了整个多重网格层次的数学适定性（well-posedness）。",
            "id": "3974226",
            "problem": "考虑一维稳态热传导问题，研究对象为一根非均匀杆，其导热系数随空间变化，并遵循傅里叶定律。其控制方程是具有可变系数的二阶扩散算子，\n$$\n-\\frac{d}{dx}\\!\\left(k(x)\\,\\frac{du}{dx}\\right)=f(x),\n$$\n该方程定义在区间上的均匀网格上，两端施加齐次狄利克雷边界条件 $u=0$。可变导热系数 $k(x)$ 是严格为正且光滑的。在间距为 $h$ 的细网格上，使用中边电导率 $\\{k_{i+1/2}\\}_{i}$，通过标准的三点守恒通量平衡法对该算子进行离散化。离散线性算子 $\\mathbf{A}$ 作用于细网格向量 $\\mathbf{u}$，在内部索引 $i$ 处由下式给出：\n$$\n(\\mathbf{A}\\mathbf{u})_{i}=\\frac{1}{h^{2}}\\!\\left(-k_{i-1/2}\\,\\mathbf{u}_{i-1}+(k_{i-1/2}+k_{i+1/2})\\,\\mathbf{u}_{i}-k_{i+1/2}\\,\\mathbf{u}_{i+1}\\right).\n$$\n设粗网格间距为 $H=2h$。定义从粗网格到细网格的线性插值延长算子 $\\mathbf{P}$ 如下：\n$$\n(\\mathbf{P}\\mathbf{v})_{2j}=\\mathbf{v}_{j},\\quad (\\mathbf{P}\\mathbf{v})_{2j+1}=\\frac{\\mathbf{v}_{j}+\\mathbf{v}_{j+1}}{2},\n$$\n其中 $j$ 为内部粗网格索引。定义从细网格到粗网格的全加权限制算子 $\\mathbf{R}$ 如下：\n$$\n(\\mathbf{R}\\mathbf{r})_{j}=\\frac{1}{4}\\,\\mathbf{r}_{2j-1}+\\frac{1}{2}\\,\\mathbf{r}_{2j}+\\frac{1}{4}\\,\\mathbf{r}_{2j+1}.\n$$\n使用伽辽金构造 $\\mathbf{A}_{c}=\\mathbf{R}\\mathbf{A}\\mathbf{P}$，显式计算 $\\mathbf{A}_{c}$ 在内部粗网格索引 $j$ 处的三点粗网格模板，用四个细网格中边电导率 $k_{2j-3/2}$、$k_{2j-1/2}$、$k_{2j+1/2}$ 和 $k_{2j+3/2}$ 以及粗网格间距 $H$ 表示。然后，使用第一性原理和线性代数能量论证，验证在所有细网格中边电导率均为严格正且边界条件为齐次狄利克雷的情况下，$\\mathbf{A}_{c}$ 是对称正定 (SPD) 的。\n\n将粗网格节点 $j$ 处的最终三点模板系数，即 $\\left(a^{c}_{j,j-1},\\,a^{c}_{j,j},\\,a^{c}_{j,j+1}\\right)$，使用 LaTeX 的 $\\texttt{pmatrix}$ 环境表示为一个单行矩阵。无需四舍五入。最终答案中无需单位。",
            "solution": "**第 1 部分：粗网格算子模板的推导**\n\n目标是计算粗网格算子 $\\mathbf{A}_c$ 对任意粗网格向量 $\\mathbf{v}$ 的作用。我们将计算结果向量的第 $j$ 个分量 $(\\mathbf{A}_{c}\\mathbf{v})_{j}$，其定义为 $(\\mathbf{R}(\\mathbf{A}(\\mathbf{P}\\mathbf{v})))_j$。我们从最内层的运算开始向外计算。\n\n**步骤 1：延长算子 $\\mathbf{P}$ 的作用**\n设 $\\mathbf{v}$ 为一个粗网格向量。延长算子 $\\mathbf{P}$ 将 $\\mathbf{v}$ 映射到一个细网格向量 $\\mathbf{u} = \\mathbf{P}\\mathbf{v}$。在细网格点 $2j$ 附近的 $\\mathbf{u}$ 的分量由插值规则给出：\n$$\n\\mathbf{u}_{2j-2} = \\mathbf{v}_{j-1}\n$$\n$$\n\\mathbf{u}_{2j-1} = \\frac{1}{2}(\\mathbf{v}_{j-1} + \\mathbf{v}_{j})\n$$\n$$\n\\mathbf{u}_{2j} = \\mathbf{v}_{j}\n$$\n$$\n\\mathbf{u}_{2j+1} = \\frac{1}{2}(\\mathbf{v}_{j} + \\mathbf{v}_{j+1})\n$$\n$$\n\\mathbf{u}_{2j+2} = \\mathbf{v}_{j+1}\n$$\n\n**步骤 2：细网格算子 $\\mathbf{A}$ 的作用**\n接下来，我们计算细网格向量 $\\mathbf{r} = \\mathbf{A}\\mathbf{u}$ 的分量。粗网格索引 $j$ 处的限制算子 $\\mathbf{R}$ 需要分量 $\\mathbf{r}_{2j-1}$、$\\mathbf{r}_{2j}$ 和 $\\mathbf{r}_{2j+1}$。我们使用 $\\mathbf{A}$ 的定义来计算这些分量：\n$$\n(\\mathbf{A}\\mathbf{u})_{i}=\\frac{1}{h^{2}}\\!\\left(-k_{i-1/2}\\,\\mathbf{u}_{i-1}+(k_{i-1/2}+k_{i+1/2})\\,\\mathbf{u}_{i}-k_{i+1/2}\\,\\mathbf{u}_{i+1}\\right)\n$$\n为清晰起见，我们计算 $h^2 \\mathbf{r}_i$：\n\n索引 $2j-1$ 处的分量：\n$$\nh^2 \\mathbf{r}_{2j-1} = -k_{2j-3/2}\\mathbf{u}_{2j-2} + (k_{2j-3/2}+k_{2j-1/2})\\mathbf{u}_{2j-1} - k_{2j-1/2}\\mathbf{u}_{2j}\n$$\n代入步骤 1 中 $\\mathbf{u}_{i}$ 的表达式：\n$$\nh^2 \\mathbf{r}_{2j-1} = -k_{2j-3/2}\\mathbf{v}_{j-1} + (k_{2j-3/2}+k_{2j-1/2})\\frac{1}{2}(\\mathbf{v}_{j-1} + \\mathbf{v}_{j}) - k_{2j-1/2}\\mathbf{v}_{j}\n$$\n合并 $\\mathbf{v}_{j-1}$ 和 $\\mathbf{v}_{j}$ 的项：\n$$\nh^2 \\mathbf{r}_{2j-1} = \\left(-\\frac{1}{2}k_{2j-3/2} + \\frac{1}{2}k_{2j-1/2}\\right)\\mathbf{v}_{j-1} + \\left(\\frac{1}{2}k_{2j-3/2} - \\frac{1}{2}k_{2j-1/2}\\right)\\mathbf{v}_{j}\n$$\n\n索引 $2j$ 处的分量：\n$$\nh^2 \\mathbf{r}_{2j} = -k_{2j-1/2}\\mathbf{u}_{2j-1} + (k_{2j-1/2}+k_{2j+1/2})\\mathbf{u}_{2j} - k_{2j+1/2}\\mathbf{u}_{2j+1}\n$$\n代入：\n$$\nh^2 \\mathbf{r}_{2j} = -k_{2j-1/2}\\frac{1}{2}(\\mathbf{v}_{j-1} + \\mathbf{v}_{j}) + (k_{2j-1/2}+k_{2j+1/2})\\mathbf{v}_{j} - k_{2j+1/2}\\frac{1}{2}(\\mathbf{v}_{j} + \\mathbf{v}_{j+1})\n$$\n合并 $\\mathbf{v}_{j-1}$、$\\mathbf{v}_{j}$ 和 $\\mathbf{v}_{j+1}$ 的项：\n$$\nh^2 \\mathbf{r}_{2j} = \\left(-\\frac{1}{2}k_{2j-1/2}\\right)\\mathbf{v}_{j-1} + \\left(\\frac{1}{2}k_{2j-1/2} + \\frac{1}{2}k_{2j+1/2}\\right)\\mathbf{v}_{j} + \\left(-\\frac{1}{2}k_{2j+1/2}\\right)\\mathbf{v}_{j+1}\n$$\n\n索引 $2j+1$ 处的分量：\n$$\nh^2 \\mathbf{r}_{2j+1} = -k_{2j+1/2}\\mathbf{u}_{2j} + (k_{2j+1/2}+k_{2j+3/2})\\mathbf{u}_{2j+1} - k_{2j+3/2}\\mathbf{u}_{2j+2}\n$$\n代入：\n$$\nh^2 \\mathbf{r}_{2j+1} = -k_{2j+1/2}\\mathbf{v}_{j} + (k_{2j+1/2}+k_{2j+3/2})\\frac{1}{2}(\\mathbf{v}_{j} + \\mathbf{v}_{j+1}) - k_{2j+3/2}\\mathbf{v}_{j+1}\n$$\n合并 $\\mathbf{v}_{j}$ 和 $\\mathbf{v}_{j+1}$ 的项：\n$$\nh^2 \\mathbf{r}_{2j+1} = \\left(-\\frac{1}{2}k_{2j+1/2} + \\frac{1}{2}k_{2j+3/2}\\right)\\mathbf{v}_{j} + \\left(\\frac{1}{2}k_{2j+1/2} - \\frac{1}{2}k_{2j+3/2}\\right)\\mathbf{v}_{j+1}\n$$\n\n**步骤 3：限制算子 $\\mathbf{R}$ 的作用**\n最后，我们将全加权限制算子应用于向量 $\\mathbf{r}$：\n$$\n(\\mathbf{A}_{c}\\mathbf{v})_{j} = (\\mathbf{R}\\mathbf{r})_j = \\frac{1}{4}\\mathbf{r}_{2j-1} + \\frac{1}{2}\\mathbf{r}_{2j} + \\frac{1}{4}\\mathbf{r}_{2j+1}\n$$\n我们代入 $\\mathbf{r}_i$ 的表达式，并合并 $\\mathbf{v}_{j-1}$、$\\mathbf{v}_{j}$ 和 $\\mathbf{v}_{j+1}$ 的系数，这些系数即为模板系数 $a^c_{j,j-1}$、$a^c_{j,j}$ 和 $a^c_{j,j+1}$。\n$$\nh^2(\\mathbf{A}_{c}\\mathbf{v})_{j} = \\frac{1}{4}(h^2\\mathbf{r}_{2j-1}) + \\frac{1}{2}(h^2\\mathbf{r}_{2j}) + \\frac{1}{4}(h^2\\mathbf{r}_{2j+1})\n$$\n\n$\\mathbf{v}_{j-1}$ 的系数：\n$$\nh^2 a^c_{j,j-1} = \\frac{1}{4}\\left(-\\frac{1}{2}k_{2j-3/2} + \\frac{1}{2}k_{2j-1/2}\\right) + \\frac{1}{2}\\left(-\\frac{1}{2}k_{2j-1/2}\\right) = -\\frac{1}{8}k_{2j-3/2} - \\frac{1}{8}k_{2j-1/2} = -\\frac{1}{8}(k_{2j-3/2} + k_{2j-1/2})\n$$\n\n$\\mathbf{v}_{j+1}$ 的系数：\n根据对称性，我们可以通过将所有索引移动 $+2$ 从 $\\mathbf{v}_{j-1}$ 的系数推断出此结果：\n$$\nh^2 a^c_{j,j+1} = -\\frac{1}{8}(k_{2(j+1)-3/2} + k_{2(j+1)-1/2}) = -\\frac{1}{8}(k_{2j+1/2} + k_{2j+3/2})\n$$\n让我们直接验证一下：\n$$\nh^2 a^c_{j,j+1} = \\frac{1}{2}\\left(-\\frac{1}{2}k_{2j+1/2}\\right) + \\frac{1}{4}\\left(\\frac{1}{2}k_{2j+1/2} - \\frac{1}{2}k_{2j+3/2}\\right) = -\\frac{1}{4}k_{2j+1/2} + \\frac{1}{8}k_{2j+1/2} - \\frac{1}{8}k_{2j+3/2} = -\\frac{1}{8}(k_{2j+1/2} + k_{2j+3/2})\n$$\n结果得到证实。\n\n$\\mathbf{v}_{j}$ 的系数：\n$$\nh^2 a^c_{j,j} = \\frac{1}{4}\\left(\\frac{1}{2}k_{2j-3/2} - \\frac{1}{2}k_{2j-1/2}\\right) + \\frac{1}{2}\\left(\\frac{1}{2}k_{2j-1/2} + \\frac{1}{2}k_{2j+1/2}\\right) + \\frac{1}{4}\\left(-\\frac{1}{2}k_{2j+1/2} + \\frac{1}{2}k_{2j+3/2}\\right)\n$$\n$$\nh^2 a^c_{j,j} = \\frac{1}{8}k_{2j-3/2} - \\frac{1}{8}k_{2j-1/2} + \\frac{1}{4}k_{2j-1/2} + \\frac{1}{4}k_{2j+1/2} - \\frac{1}{8}k_{2j+1/2} + \\frac{1}{8}k_{2j+3/2}\n$$\n$$\nh^2 a^c_{j,j} = \\frac{1}{8}k_{2j-3/2} + \\frac{1}{8}k_{2j-1/2} + \\frac{1}{8}k_{2j+1/2} + \\frac{1}{8}k_{2j+3/2} = \\frac{1}{8}(k_{2j-3/2} + k_{2j-1/2} + k_{2j+1/2} + k_{2j+3/2})\n$$\n注意 $a^c_{j,j-1} + a^c_{j,j} + a^c_{j,j+1} = 0$，这对于守恒格式是预期的。\n\n**步骤 4：用粗网格间距 $H$ 表示**\n问题使用粗网格间距 $H=2h$，因此 $h^2 = H^2/4$。为了求得最终系数，我们除以 $h^2$：\n$$\na^c_{j,j-1} = \\frac{1}{h^2}\\left[-\\frac{1}{8}(k_{2j-3/2} + k_{2j-1/2})\\right] = \\frac{4}{H^2}\\left[-\\frac{1}{8}(k_{2j-3/2} + k_{2j-1/2})\\right] = -\\frac{k_{2j-3/2} + k_{2j-1/2}}{2H^2}\n$$\n$$\na^c_{j,j} = \\frac{1}{h^2}\\left[\\frac{1}{8}(k_{2j-3/2} + k_{2j-1/2} + k_{2j+1/2} + k_{2j+3/2})\\right] = \\frac{k_{2j-3/2} + k_{2j-1/2} + k_{2j+1/2} + k_{2j+3/2}}{2H^2}\n$$\n$$\na^c_{j,j+1} = \\frac{1}{h^2}\\left[-\\frac{1}{8}(k_{2j+1/2} + k_{2j+3/2})\\right] = -\\frac{k_{2j+1/2} + k_{2j+3/2}}{2H^2}\n$$\n\n**第 2 部分：对称正定 (SPD) 性质的验证**\n\n**对称性：**\n伽辽金粗网格算子为 $\\mathbf{A}_{c} = \\mathbf{R}\\mathbf{A}\\mathbf{P}$。如果一个算子等于其转置，即 $\\mathbf{A}_{c} = \\mathbf{A}_{c}^T$，则该算子是对称的。\n其转置为 $\\mathbf{A}_{c}^T = (\\mathbf{R}\\mathbf{A}\\mathbf{P})^T = \\mathbf{P}^T \\mathbf{A}^T \\mathbf{R}^T$。\n细网格算子 $\\mathbf{A}$ 是一个对称矩阵，因此 $\\mathbf{A}^T = \\mathbf{A}$。\n对于所定义的线性插值延长算子 $\\mathbf{P}$ 和全加权限制算子 $\\mathbf{R}$，可以证明它们满足关系 $\\mathbf{R}=\\frac{1}{2}\\mathbf{P}^T$。\n将此代入 $\\mathbf{A}_c$ 的定义，得到 $\\mathbf{A}_{c} = \\frac{1}{2}\\mathbf{P}^T \\mathbf{A} \\mathbf{P}$。\n现在我们检查 $\\mathbf{A}_{c}$ 的转置：\n$$\n\\mathbf{A}_{c}^T = \\left(\\frac{1}{2}\\mathbf{P}^T \\mathbf{A} \\mathbf{P}\\right)^T = \\frac{1}{2} \\mathbf{P}^T \\mathbf{A}^T (\\mathbf{P}^T)^T = \\frac{1}{2} \\mathbf{P}^T \\mathbf{A} \\mathbf{P} = \\mathbf{A}_{c}\n$$\n因此，$\\mathbf{A}_{c}$ 是对称的。\n\n**正定性：**\n我们必须证明，对于任何非零的粗网格向量 $\\mathbf{v}$（满足齐次边界条件），二次型 $\\mathbf{v}^T \\mathbf{A}_{c} \\mathbf{v}$ 是严格为正的。\n$$\n\\mathbf{v}^T \\mathbf{A}_{c} \\mathbf{v} = \\mathbf{v}^T \\left(\\frac{1}{2}\\mathbf{P}^T \\mathbf{A} \\mathbf{P}\\right) \\mathbf{v} = \\frac{1}{2} (\\mathbf{P}\\mathbf{v})^T \\mathbf{A} (\\mathbf{P}\\mathbf{v})\n$$\n令 $\\mathbf{u} = \\mathbf{P}\\mathbf{v}$。表达式变为 $\\frac{1}{2}\\mathbf{u}^T \\mathbf{A} \\mathbf{u}$。\n\n首先，我们确定 $\\mathbf{A}$ 是正定的。$\\mathbf{A}$ 的二次型可以通过分部求和表示为离散能量范数：\n$$\n\\mathbf{u}^T \\mathbf{A} \\mathbf{u} = \\frac{1}{h^2} \\sum_{i=0}^{N-1} k_{i+1/2}(\\mathbf{u}_{i+1} - \\mathbf{u}_i)^2\n$$\n鉴于导热系数 $k_{i+1/2}$ 严格为正，这个平方和总是非负的。它为零当且仅当对于所有 $i=0, \\dots, N-1$，都有 $\\mathbf{u}_{i+1} - \\mathbf{u}_i = 0$。这意味着 $\\mathbf{u}$ 必须是一个常数向量。由于齐次狄利克雷边界条件，$\\mathbf{u}_0 = \\mathbf{u}_N = 0$，这迫使该常数为零。因此，$\\mathbf{u}^T \\mathbf{A} \\mathbf{u} = 0$ 当且仅当 $\\mathbf{u} = \\mathbf{0}$。所以，$\\mathbf{A}$ 是正定的。\n\n其次，我们需要确保如果 $\\mathbf{v} \\neq \\mathbf{0}$，则 $\\mathbf{u} = \\mathbf{P}\\mathbf{v} \\neq \\mathbf{0}$。算子 $\\mathbf{P}$ 是单射的（其零空间是平凡的）。如果 $\\mathbf{v}$ 是一个非零的粗网格向量，则至少存在一个内部索引 $j$ 使得 $\\mathbf{v}_j \\neq 0$。根据 $\\mathbf{P}$ 的定义，相应的细网格分量是 $(\\mathbf{P}\\mathbf{v})_{2j} = \\mathbf{v}_j \\neq 0$。这意味着 $\\mathbf{P}\\mathbf{v}$不可能是零向量。\n\n结合这两个事实：对于任何非零的粗网格向量 $\\mathbf{v}$，延长后的向量 $\\mathbf{u} = \\mathbf{P}\\mathbf{v}$ 是一个非零的细网格向量。由于 $\\mathbf{A}$ 是正定的，所以 $\\mathbf{u}^T\\mathbf{A}\\mathbf{u} > 0$。因此：\n$$\n\\mathbf{v}^T \\mathbf{A}_{c} \\mathbf{v} = \\frac{1}{2}\\mathbf{u}^T \\mathbf{A} \\mathbf{u}  0\n$$\n这证明了 $\\mathbf{A}_{c}$ 是正定的。由于它也是对称的，所以 $\\mathbf{A}_{c}$ 是 SPD。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} -\\frac{k_{2j-3/2} + k_{2j-1/2}}{2H^2}  \\frac{k_{2j-3/2} + k_{2j-1/2} + k_{2j+1/2} + k_{2j+3/2}}{2H^2}  -\\frac{k_{2j+1/2} + k_{2j+3/2}}{2H^2} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "在分别探究了松弛器和粗网格修正这两个多重网格的关键组成部分后，我们现在可以将它们结合起来，评估整个方法的综合效能。本练习通过一个具体的三维热传导问题，量化展示了多重网格方法作为预条件子（preconditioner）所带来的惊人加速效果。您将通过计算和对比，直观地感受到标准共轭梯度法（CG）在网格加密时收敛速度的急剧恶化，以及多重网格预处理共轭梯度法（PCG）如何实现近乎独立于网格规模的高效收敛。这个实践将理论与性能联系起来，揭示了多重网格方法为何是求解大型科学与工程问题的首选迭代策略之一。",
            "id": "3974261",
            "problem": "考虑一个单位立方体上的三维稳态热传导方程，当热导率恒定时，该方程简化为拉普拉斯方程 $-\\nabla^2 T = 0$，并带有齐次狄利克雷边界条件。使用二阶中心差分方法，在每个坐标方向有 $n$ 个内部点的均匀网格上对该方程进行离散化，得到一个线性系统 $\\mathbf{A}\\mathbf{u}=\\mathbf{b}$，其中 $\\mathbf{A}$ 是对称正定矩阵。该离散算子对应于标准的七点模板，并按 $1/h^2$ 进行缩放，其中网格间距为 $h=1/(n+1)$。假设使用共轭梯度法 (CG) 求解该线性系统，并可在每次 CG 迭代中应用一次多重网格 (MG) 预条件子（即预条件共轭梯度法，PCG）。\n\n从具有齐次狄利克雷边界条件的离散拉普拉斯算子的基本性质出发，推导适用于此场景的矩阵 $\\mathbf{A}$ 的极端特征值，然后求出条件数 $\\kappa(\\mathbf{A})$，并使用共轭梯度法的标准能量范数收敛界来估计将误差的能量范数减小一个指定因子所需的迭代次数。对于 MG 预处理的情况，假设每次 PCG 迭代都能实现一个估计的单周期几何收敛因子 $\\rho \\in (0,1)$，并计算将误差减小相同因子所需的最小迭代次数。\n\n对于所有计算，设置 $n=128$（即问题规模为 $128^3$ 个内部未知数）。对于未使用预条件子的共轭梯度法，收敛性估计应基于从矩阵 $\\mathbf{A}$ 的条件数推导出的能量范数误差界。对于多重网格预处理的情况，使用一个简化假设，即每次 PCG 迭代都将误差减小因子 $\\rho$，且该因子与 $n$ 无关。\n\n你的程序必须为每个测试用例计算一对整数 $[k_{\\mathrm{CG}},k_{\\mathrm{PCG}}]$，其中 $k_{\\mathrm{CG}}$ 是将误差的能量范数减小因子 $\\tau$ 所需的共轭梯度法最小迭代次数（使用从第一性原理推导出的界），而 $k_{\\mathrm{PCG}}$ 是在因子为 $\\rho$ 的几何缩减模型下所需的预条件共轭梯度法最小迭代次数。整数 $k_{\\mathrm{CG}}$ 必须是满足标准界保证误差减小程度至少为 $\\tau$ 的最小整数 $k$，而 $k_{\\mathrm{PCG}}$ 必须是满足 $\\rho^k \\le \\tau$ 的最小整数 $k$。\n\n使用以下测试套件，其中每个案例提供了目标缩减因子 $\\tau$ 和估计的 MG 单周期因子 $\\rho$：\n- 案例 1：$\\tau=10^{-6}$，$\\rho=0.1$。\n- 案例 2：$\\tau=10^{-8}$，$\\rho=0.3$。\n- 案例 3：$\\tau=10^{-10}$，$\\rho=0.8$。\n- 案例 4：$\\tau=10^{-4}$，$\\rho=0.99$。\n- 案例 5：$\\tau=10^{-12}$，$\\rho=0.05$。\n\n所有量均为无量纲。你的程序应生成单行输出，包含五个案例的结果，格式为由方括号括起来的、用逗号分隔的括号对列表，不得包含任何额外文本。例如，输出格式必须为 $[[k_{\\mathrm{CG},1},k_{\\mathrm{PCG},1}],[k_{\\mathrm{CG},2},k_{\\mathrm{PCG},2}],\\dots,[k_{\\mathrm{CG},5},k_{\\mathrm{PCG},5}]]$ 的形式。",
            "solution": "问题核心是在单位立方体上的三维稳态热传导方程，当热导率恒定时，该方程即为拉普拉斯方程：\n$$\n-\\nabla^2 T = - \\left( \\frac{\\partial^2 T}{\\partial x^2} + \\frac{\\partial^2 T}{\\partial y^2} + \\frac{\\partial^2 T}{\\partial z^2} \\right) = 0\n$$\n在定义域 $\\Omega = [0,1]^3$ 的边界上具有齐次狄利克雷边界条件 $T=0$。\n\n我们在每个坐标方向有 $n$ 个内部点的均匀网格上离散化该方程。网格间距为 $h = 1/(n+1)$。在内部网格点 $(x_i, y_j, z_k)$ 处，对二阶导数使用二阶中心差分近似，我们得到：\n$$\n-\\frac{\\partial^2 T}{\\partial x^2}\\bigg|_{(i,j,k)} \\approx -\\frac{T_{i-1,j,k} - 2T_{i,j,k} + T_{i+1,j,k}}{h^2}\n$$\n对于 $y$ 和 $z$ 方向的导数也是如此。将这些项相加，得到每个内部点处负拉普拉斯算子的离散方程：\n$$\n(-\\nabla^2_h T)_{i,j,k} = \\frac{1}{h^2} \\left( 6T_{i,j,k} - T_{i-1,j,k} - T_{i+1,j,k} - T_{i,j-1,k} - T_{i,j+1,k} - T_{i,j,k-1} - T_{i,j,k+1} \\right) = 0\n$$\n这构成了一个线性系统 $\\mathbf{A}\\mathbf{u}=\\mathbf{b}$，其中 $\\mathbf{u}$ 是 $n^3$ 个内部点上未知温度组成的向量。矩阵 $\\mathbf{A}$ 代表标准的 7 点离散拉普拉斯算子，并按 $1/h^2$ 进行了缩放。由于齐次边界条件，右侧向量 $\\mathbf{b}$ 为零。矩阵 $\\mathbf{A}$ 是对称且正定的。\n\n为了分析共轭梯度 (CG) 法的收敛性，我们必须确定条件数 $\\kappa(\\mathbf{A})$，即其最大特征值与最小特征值之比，$\\kappa(\\mathbf{A}) = \\lambda_{\\max} / \\lambda_{\\min}$。\n\n三维离散拉普拉斯算子的特征值可以通过变量分离法，从一维情况推广得到。在 $n$ 个内部点上的一维离散拉普拉斯矩阵是 $L_{1D} = \\frac{1}{h^2} \\text{tridiag}(-1, 2, -1)$。其特征值已知为：\n$$\n\\lambda_p = \\frac{2}{h^2}\\left(1 - \\cos\\left(\\frac{p\\pi}{n+1}\\right)\\right) = \\frac{4}{h^2}\\sin^2\\left(\\frac{p\\pi}{2(n+1)}\\right), \\quad p = 1, 2, \\dots, n\n$$\n三维矩阵 $\\mathbf{A}$ 可以表示为一维矩阵的克罗内克和：$\\mathbf{A} = L_{1D} \\otimes I \\otimes I + I \\otimes L_{1D} \\otimes I + I \\otimes I \\otimes L_{1D}$。因此，$\\mathbf{A}$ 的特征值是各维度特征值之和：\n$$\n\\lambda_{p,q,r} = \\lambda_p + \\lambda_q + \\lambda_r = \\frac{4}{h^2} \\left[ \\sin^2\\left(\\frac{p\\pi}{2(n+1)}\\right) + \\sin^2\\left(\\frac{q\\pi}{2(n+1)}\\right) + \\sin^2\\left(\\frac{r\\pi}{2(n+1)}\\right) \\right]\n$$\n其中 $p, q, r \\in \\{1, 2, \\dots, n\\}$。\n\n最小特征值 $\\lambda_{\\min}$ 对应于最低频率模式，即 $p=q=r=1$ 时：\n$$\n\\lambda_{\\min} = \\lambda_{1,1,1} = \\frac{4}{h^2} \\left[ 3 \\sin^2\\left(\\frac{\\pi}{2(n+1)}\\right) \\right] = \\frac{12}{h^2} \\sin^2\\left(\\frac{\\pi}{2(n+1)}\\right)\n$$\n最大特征值 $\\lambda_{\\max}$ 对应于最高频率模式，即 $p=q=r=n$ 时：\n$$\n\\lambda_{\\max} = \\lambda_{n,n,n} = \\frac{4}{h^2} \\left[ 3 \\sin^2\\left(\\frac{n\\pi}{2(n+1)}\\right) \\right]\n$$\n使用恒等式 $\\sin\\left(\\frac{n\\pi}{2(n+1)}\\right) = \\sin\\left(\\frac{\\pi}{2} - \\frac{\\pi}{2(n+1)}\\right) = \\cos\\left(\\frac{\\pi}{2(n+1)}\\right)$，我们得到：\n$$\n\\lambda_{\\max} = \\frac{12}{h^2} \\cos^2\\left(\\frac{\\pi}{2(n+1)}\\right)\n$$\n那么矩阵 $\\mathbf{A}$ 的条件数就是：\n$$\n\\kappa(\\mathbf{A}) = \\frac{\\lambda_{\\max}}{\\lambda_{\\min}} = \\frac{\\frac{12}{h^2} \\cos^2\\left(\\frac{\\pi}{2(n+1)}\\right)}{\\frac{12}{h^2} \\sin^2\\left(\\frac{\\pi}{2(n+1)}\\right)} = \\cot^2\\left(\\frac{\\pi}{2(n+1)}\\right)\n$$\nCG 方法的收敛性由条件数决定。经过 $k$ 次迭代后的误差 $e_k = u - u_k$，在能量范数 $\\|e_k\\|_{\\mathbf{A}} = \\sqrt{e_k^T \\mathbf{A} e_k}$ 下度量，满足标准界：\n$$\n\\|e_k\\|_{\\mathbf{A}} \\le 2 \\left( \\frac{\\sqrt{\\kappa(\\mathbf{A})} - 1}{\\sqrt{\\kappa(\\mathbf{A})} + 1} \\right)^k \\|e_0\\|_{\\mathbf{A}}\n$$\n我们需要找到最小整数 $k$（记为 $k_{\\mathrm{CG}}$），使得误差减小一个因子 $\\tau$，即 $\\|e_k\\|_{\\mathbf{A}} / \\|e_0\\|_{\\mathbf{A}} \\le \\tau$。这需要解出不等式中的 $k$：\n$$\n2 \\left( \\frac{\\sqrt{\\kappa(\\mathbf{A})} - 1}{\\sqrt{\\kappa(\\mathbf{A})} + 1} \\right)^k \\le \\tau\n$$\n对两边取自然对数：\n$$\n\\ln(2) + k \\ln\\left(\\frac{\\sqrt{\\kappa(\\mathbf{A})} - 1}{\\sqrt{\\kappa(\\mathbf{A})} + 1}\\right) \\le \\ln(\\tau)\n$$\n由于 $\\sqrt{\\kappa(\\mathbf{A})}  1$，对数内的项小于 1，因此其对数值为负。因此，求解 $k$ 时，不等号反向：\n$$\nk \\ge \\frac{\\ln(\\tau) - \\ln(2)}{\\ln\\left(\\frac{\\sqrt{\\kappa(\\mathbf{A})} - 1}{\\sqrt{\\kappa(\\mathbf{A})} + 1}\\right)} = \\frac{\\ln(\\tau/2)}{\\ln\\left(\\frac{\\sqrt{\\kappa(\\mathbf{A})} - 1}{\\sqrt{\\kappa(\\mathbf{A})} + 1}\\right)}\n$$\n最小整数迭代次数是此表达式的向上取整：\n$$\nk_{\\mathrm{CG}} = \\left\\lceil \\frac{\\ln(\\tau/2)}{\\ln\\left(\\frac{\\cot(\\frac{\\pi}{2(n+1)}) - 1}{\\cot(\\frac{\\pi}{2(n+1)}) + 1}\\right)} \\right\\rceil\n$$\n对于多重网格预条件共轭梯度 (PCG) 的情况，问题提供了一个简化模型，其中每次迭代将误差减小一个常数因子 $\\rho$。我们寻求达到 $\\tau$ 的缩减所需的最小迭代次数 $k$（记为 $k_{\\mathrm{PCG}}$）。控制不等式为：\n$$\n\\rho^k \\le \\tau\n$$\n取自然对数：\n$$\nk \\ln(\\rho) \\le \\ln(\\tau)\n$$\n由于 $\\rho \\in (0,1)$，$\\ln(\\rho)$ 为负。求解 $k$ 会使不等号反向：\n$$\nk \\ge \\frac{\\ln(\\tau)}{\\ln(\\rho)}\n$$\n因此，最小整数迭代次数为：\n$$\nk_{\\mathrm{PCG}} = \\left\\lceil \\frac{\\ln(\\tau)}{\\ln(\\rho)} \\right\\rceil\n$$\n对于所有计算，问题指定 $n=128$。我们将使用这个值以及测试用例参数 $(\\tau, \\rho)$来计算数组 $[k_{\\mathrm{CG}}, k_{\\mathrm{PCG}}]$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\n\ndef solve():\n    \"\"\"\n    Computes the estimated number of iterations for Conjugate Gradient (CG)\n    and Preconditioned Conjugate Gradient (PCG) methods for solving the\n    3D discretized Laplace equation based on provided theoretical models.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # Each tuple contains: (error reduction factor tau, MG convergence factor rho)\n    test_cases = [\n        (1e-6, 0.1),\n        (1e-8, 0.3),\n        (1e-10, 0.8),\n        (1e-4, 0.99),\n        (1e-12, 0.05),\n    ]\n\n    # Number of interior grid points per dimension\n    n = 128\n\n    # --- CG Iteration Count Calculation ---\n\n    # Derivation steps for k_CG:\n    # 1. Condition number kappa = cot(pi / (2*(n+1)))^2\n    # 2. sqrt(kappa) = cot(pi / (2*(n+1)))\n    # 3. CG convergence factor gamma = (sqrt(kappa) - 1) / (sqrt(kappa) + 1)\n    # 4. Error bound: 2 * gamma^k = tau\n    # 5. k = log(tau / 2) / log(gamma)\n    \n    n_plus_1 = n + 1\n    # Argument for the cotangent function\n    angle = np.pi / (2.0 * n_plus_1)\n    # The square root of the condition number\n    sqrt_kappa = 1.0 / np.tan(angle)\n    \n    # The convergence factor in the CG error bound\n    cg_conv_factor = (sqrt_kappa - 1.0) / (sqrt_kappa + 1.0)\n    log_cg_conv_factor = np.log(cg_conv_factor)\n\n    results = []\n    for tau, rho in test_cases:\n        # --- Calculate k_CG for the current test case ---\n        log_tau_div_2 = np.log(tau / 2.0)\n        # k_CG is the smallest integer k satisfying the bound\n        k_cg = int(math.ceil(log_tau_div_2 / log_cg_conv_factor))\n\n        # --- PCG Iteration Count Calculation ---\n\n        # Derivation steps for k_PCG:\n        # 1. Error model: rho^k = tau\n        # 2. k = log(tau) / log(rho)\n        log_tau = np.log(tau)\n        log_rho = np.log(rho)\n        # k_PCG is the smallest integer k satisfying the model\n        k_pcg = int(math.ceil(log_tau / log_rho))\n\n        results.append([k_cg, k_pcg])\n\n    # Final print statement in the exact required format.\n    # e.g., [[k_CG,1,k_PCG,1],[k_CG,2,k_PCG,2],...,[k_CG,5,k_PCG,5]]\n    formatted_results = [f\"[{r[0]},{r[1]}]\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}