{
    "hands_on_practices": [
        {
            "introduction": "A central challenge in computational catalysis is to move beyond simply predicting properties and toward rational design. This often involves finding ways to break the so-called \"scaling relations\" that constrain the adsorption energies of related intermediates, limiting the performance of many catalyst families. This first exercise provides a hands-on exploration of one physical mechanism for decoupling these energies: the interaction between an adsorbate's dipole moment and the interfacial electric field . By constructing a targeted counterfactual scenario, you will gain insight into how specific descriptors can serve as \"design levers\" to selectively tune the binding strength of one species without affecting another.",
            "id": "4241578",
            "problem": "You are tasked with constructing and evaluating a mathematically explicit, descriptor-based counterfactual in computational electrochemistry that isolates how a single interfacial descriptor can shift the hydroxyl adsorption energy while leaving the oxygen adsorption energy essentially unchanged. Your derivation and program must be grounded in first principles and yield numerically testable outcomes.\n\nConsider the descriptor-based decomposition of the adsorption energy on a transition-metal surface site for an adsorbate species $X \\in \\{\\mathrm{OH}, \\mathrm{O}\\}$ in terms of a chemisorption component that depends on the metal electronic structure descriptor (for instance, the $d$-band center $\\varepsilon_d$) and an interfacial electrostatic component that depends on the interfacial electric field $F$ and the adsorbate-specific surface-normal dipole moment $\\mu_X$. We assume the chemisorption energy depends only on $\\varepsilon_d$ (which you will hold constant in the counterfactual), and the field-dependent energy depends only on $F$ and $\\mu_X$. The physical premise is that the oxygen adatom has a negligible surface-normal dipole moment, while the hydroxyl has a finite surface-normal dipole moment due to its polar $\\mathrm{O}-\\mathrm{H}$ bond and interfacial orientation. This premise is widely supported by adsorption studies and is consistent with electrostatic interactions in an external field.\n\nYour tasks are:\n\n- Derive from first principles the change in adsorption energy $\\Delta E_{\\mathrm{ads}}(X)$ between two field values $F_0$ and $F_1$, holding $\\varepsilon_d$ fixed, using only the electrostatic interaction of a dipole with an external electric field and a descriptor-based decomposition of adsorption energy. Do not use or assume any shortcut or target formula beyond these fundamental bases. Express all energies in electronvolts ($\\mathrm{eV}$), all fields in volts per angstrom ($\\mathrm{V/\\AA}$), and all dipole moments either in Debye or converted to units of elementary charge times angstrom ($\\mathrm{e\\AA}$); if given in Debye, you must internally convert using $1\\,\\mathrm{Debye} = 0.20819434\\,\\mathrm{e\\AA}$.\n- Design the counterfactual modification in which only the interfacial field descriptor $F$ is changed from $F_0$ to $F_1$, while keeping the chemisorption descriptor $\\varepsilon_d$ fixed (hence the chemisorption contribution cancels in the difference). Use the physical mechanism that the field couples to the surface-normal dipole of $\\mathrm{OH}$ but not to $\\mathrm{O}$ to enable decoupling.\n- Implement a complete, runnable program that, for each test case in the suite below, computes the changes $\\Delta E_{\\mathrm{ads}}(\\mathrm{OH})$ and $\\Delta E_{\\mathrm{ads}}(\\mathrm{O})$ in $\\mathrm{eV}$ resulting from changing $F$ from $F_0$ to $F_1$, and evaluates whether the decoupling criterion is satisfied. The decoupling criterion for a case is the logical condition $\\left|\\Delta E_{\\mathrm{ads}}(\\mathrm{O})\\right| \\le \\tau$ and $\\left|\\Delta E_{\\mathrm{ads}}(\\mathrm{OH})\\right| \\ge \\sigma$, where $\\tau$ is a tolerance threshold in $\\mathrm{eV}$ representing “no change” for $\\mathrm{O}$, and $\\sigma$ is a significance threshold in $\\mathrm{eV}$ representing a “meaningful change” for $\\mathrm{OH}$. Output the results in the exact final output format described below.\n\nFundamental bases you must use:\n\n- Electrostatic interaction energy of a dipole in a uniform external field along the surface normal, together with the descriptor-based split of adsorption energy into a chemisorption part (held constant here) and a field-coupled part.\n- Widely accepted physical observation that a hydroxyl adsorbate possesses a finite surface-normal dipole moment, while an oxygen adatom has negligible surface-normal dipole moment in typical high-symmetry adsorption configurations.\n\nTest suite (each case provides $(\\mu_{\\mathrm{OH}}, \\mu_{\\mathrm{O}}, F_0, F_1, \\tau, \\sigma)$; dipoles in Debye, fields in $\\mathrm{V/\\AA}$, thresholds in $\\mathrm{eV}$):\n\n- Case $1$: $\\mu_{\\mathrm{OH}} = 1.60$, $\\mu_{\\mathrm{O}} = 0.00$, $F_0 = 0.00$, $F_1 = 0.50$, $\\tau = 1\\times 10^{-6}$, $\\sigma = 0.05$.\n- Case $2$ (edge case, no dipoles): $\\mu_{\\mathrm{OH}} = 0.00$, $\\mu_{\\mathrm{O}} = 0.00$, $F_0 = 0.00$, $F_1 = 1.00$, $\\tau = 1\\times 10^{-6}$, $\\sigma = 0.05$.\n- Case $3$ (small nonzero $\\mu_{\\mathrm{O}}$ within tolerance): $\\mu_{\\mathrm{OH}} = 1.60$, $\\mu_{\\mathrm{O}} = 0.05$, $F_0 = 0.00$, $F_1 = 1.00$, $\\tau = 0.02$, $\\sigma = 0.05$.\n- Case $4$ (negative field change): $\\mu_{\\mathrm{OH}} = 1.60$, $\\mu_{\\mathrm{O}} = 0.00$, $F_0 = 1.00$, $F_1 = 0.00$, $\\tau = 1\\times 10^{-6}$, $\\sigma = 0.05$.\n- Case $5$ (decoupling fails due to large $\\mu_{\\mathrm{O}}$): $\\mu_{\\mathrm{OH}} = 1.60$, $\\mu_{\\mathrm{O}} = 0.50$, $F_0 = 0.00$, $F_1 = 0.50$, $\\tau = 0.05$, $\\sigma = 0.05$.\n\nFinal output format:\n\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to one test case and is itself a list of three elements $[\\Delta E_{\\mathrm{ads}}(\\mathrm{OH}), \\Delta E_{\\mathrm{ads}}(\\mathrm{O}), \\text{decoupled}]$. Here $\\Delta E_{\\mathrm{ads}}(\\mathrm{OH})$ and $\\Delta E_{\\mathrm{ads}}(\\mathrm{O})$ are floats in $\\mathrm{eV}$ and $\\text{decoupled}$ is a boolean. For example: $[[x_1,y_1,\\mathrm{True}],[x_2,y_2,\\mathrm{False}],\\ldots]$.",
            "solution": "The problem has been validated and is deemed scientifically sound, well-posed, and objective. It presents a formalizable task directly relevant to the field of computational electrochemistry and descriptor-based materials design. All necessary data, physical premises, and constraints are provided without contradiction or ambiguity.\n\nThe solution proceeds by first deriving the change in adsorption energy from fundamental principles, then applying this derivation to implement the specified counterfactual analysis.\n\nThe adsorption energy, $E_{\\mathrm{ads}}$, for an adsorbate species $X$ on a metal surface is modeled as a sum of a chemisorption component, $E_{\\mathrm{chem}}$, and an electrostatic component, $E_{\\mathrm{elec}}$. The chemisorption component is a function of an electronic structure descriptor, such as the $d$-band center $\\varepsilon_d$, while the electrostatic component depends on the interfacial electric field, $F$, and the adsorbate's surface-normal dipole moment, $\\mu_X$. The total adsorption energy is:\n$$E_{\\mathrm{ads}}(X, \\varepsilon_d, F) = E_{\\mathrm{chem}}(X, \\varepsilon_d) + E_{\\mathrm{elec}}(X, F, \\mu_X)$$\nThe problem defines a counterfactual scenario where only the interfacial field descriptor $F$ is varied from an initial value $F_0$ to a final value $F_1$, while the chemisorption descriptor $\\varepsilon_d$ is held constant. We are tasked with deriving the resulting change in adsorption energy, $\\Delta E_{\\mathrm{ads}}(X)$.\n\nFrom first principles of electrostatics, the interaction energy of a static electric dipole moment $\\vec{\\mu}$ with a uniform external electric field $\\vec{F}$ is given by $U = -\\vec{\\mu} \\cdot \\vec{F}$. For the purpose of this model, we consider only the components normal to the surface. Thus, the electrostatic contribution to the adsorption energy is:\n$$E_{\\mathrm{elec}}(X, F, \\mu_X) = -\\mu_X F$$\nFor this equation to be dimensionally consistent and yield energy in electronvolts ($\\mathrm{eV}$), the units must be managed correctly. If the field $F$ is in volts per angstrom ($\\mathrm{V/\\AA}$) and the dipole moment $\\mu_X$ is in units of elementary charge times angstrom ($\\mathrm{e\\AA}$), their product directly gives energy in $\\mathrm{eV}$:\n$$[\\mathrm{e\\AA}] \\times [\\mathrm{V/\\AA}] = [\\mathrm{e}] \\times [\\mathrm{V}] = [\\mathrm{eV}]$$\nThe problem provides dipole moments in units of Debye ($\\mathrm{D}$). We must use the specified conversion factor, $k_{\\mathrm{conv}} = 0.20819434\\,\\mathrm{e\\AA}/\\mathrm{D}$, to convert the dipole moment $\\mu_X[\\mathrm{D}]$ into the required units:\n$$\\mu_X[\\mathrm{e\\AA}] = \\mu_X[\\mathrm{D}] \\times k_{\\mathrm{conv}}$$\n\nThe change in adsorption energy, $\\Delta E_{\\mathrm{ads}}(X)$, is the difference between the final and initial states:\n$$\\Delta E_{\\mathrm{ads}}(X) = E_{\\mathrm{ads}}(X, \\varepsilon_d, F_1) - E_{\\mathrm{ads}}(X, \\varepsilon_d, F_0)$$\nSubstituting the decomposed expression for $E_{\\mathrm{ads}}$:\n$$\\Delta E_{\\mathrm{ads}}(X) = [E_{\\mathrm{chem}}(X, \\varepsilon_d) + E_{\\mathrm{elec}}(X, F_1, \\mu_X)] - [E_{\\mathrm{chem}}(X, \\varepsilon_d) + E_{\\mathrm{elec}}(X, F_0, \\mu_X)]$$\nSince $\\varepsilon_d$ is held constant, the chemisorption term $E_{\\mathrm{chem}}(X, \\varepsilon_d)$ cancels out:\n$$\\Delta E_{\\mathrm{ads}}(X) = E_{\\mathrm{elec}}(X, F_1, \\mu_X) - E_{\\mathrm{elec}}(X, F_0, \\mu_X)$$\nNow, substituting the electrostatic energy expression $E_{\\mathrm{elec}} = -\\mu_X F$:\n$$\\Delta E_{\\mathrm{ads}}(X) = (-\\mu_X F_1) - (-\\mu_X F_0)$$\n$$\\Delta E_{\\mathrm{ads}}(X) = -\\mu_X (F_1 - F_0) = -\\mu_X \\Delta F$$\nThis is the final derived equation. To use it computationally with the given units, we write it as:\n$$\\Delta E_{\\mathrm{ads}}(X)[\\mathrm{eV}] = - (\\mu_X[\\mathrm{D}] \\times k_{\\mathrm{conv}}) \\times (F_1[\\mathrm{V/\\AA}] - F_0[\\mathrm{V/\\AA}])$$\nThis formula embodies the counterfactual: it isolates the effect of changing the field descriptor $F$ on the adsorption energy. The effect is linearly proportional to the adsorbate's intrinsic dipole moment, $\\mu_X$.\n\nThe physical premise of the problem is that for oxygen, $\\mu_{\\mathrm{O}} \\approx 0$, while for hydroxyl, $\\mu_{\\mathrm{OH}}$ is finite. Applying our derived formula:\n- For oxygen ($\\mathrm{O}$): $\\Delta E_{\\mathrm{ads}}(\\mathrm{O}) = -\\mu_{\\mathrm{O}} \\Delta F$. If $\\mu_{\\mathrm{O}} \\approx 0$, then $\\Delta E_{\\mathrm{ads}}(\\mathrm{O}) \\approx 0$.\n- For hydroxyl ($\\mathrm{OH}$): $\\Delta E_{\\mathrm{ads}}(\\mathrm{OH}) = -\\mu_{\\mathrm{OH}} \\Delta F$. Since $\\mu_{\\mathrm{OH}}$ is finite, any change in field ($\\Delta F \\neq 0$) will induce a change in its adsorption energy.\n\nThis demonstrates the selective decoupling: varying the field $F$ primarily influences the adsorption energy of $\\mathrm{OH}$ while leaving that of $\\mathrm{O}$ largely unchanged. The program will implement this formula for the species $\\mathrm{OH}$ and $\\mathrm{O}$ for each test case. It will then evaluate the decoupling criterion, which is the logical condition:\n$$(\\left|\\Delta E_{\\mathrm{ads}}(\\mathrm{O})\\right| \\le \\tau) \\land (\\left|\\Delta E_{\\mathrm{ads}}(\\mathrm{OH})\\right| \\ge \\sigma)$$\nwhere $\\tau$ and $\\sigma$ are the given tolerance and significance thresholds, respectively. The program will compute the two energy changes and the boolean result of this criterion for each test case.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Constructs and evaluates a descriptor-based counterfactual in computational\n    electrochemistry to isolate the effect of the interfacial electric field\n    on OH and O adsorption energies.\n    \"\"\"\n    # Conversion factor from Debye to elementary charge * angstrom.\n    # 1 Debye = 0.20819434 eÅ\n    DEBYE_TO_EAA = 0.20819434\n\n    # Test suite: (mu_OH[D], mu_O[D], F0[V/Å], F1[V/Å], tau[eV], sigma[eV])\n    test_cases = [\n        # Case 1: Standard decoupling\n        (1.60, 0.00, 0.00, 0.50, 1e-6, 0.05),\n        # Case 2: Edge case with no dipoles, decoupling should fail significance test\n        (0.00, 0.00, 0.00, 1.00, 1e-6, 0.05),\n        # Case 3: Small nonzero mu_O, but within tolerance\n        (1.60, 0.05, 0.00, 1.00, 0.02, 0.05),\n        # Case 4: Negative field change\n        (1.60, 0.00, 1.00, 0.00, 1e-6, 0.05),\n        # Case 5: Decoupling fails due to large mu_O violating tolerance\n        (1.60, 0.50, 0.00, 0.50, 0.05, 0.05),\n    ]\n\n    results = []\n    for case in test_cases:\n        mu_OH_D, mu_O_D, F0, F1, tau, sigma = case\n\n        # Convert dipole moments from Debye to eÅ\n        mu_OH_eA = mu_OH_D * DEBYE_TO_EAA\n        mu_O_eA = mu_O_D * DEBYE_TO_EAA\n\n        # Calculate the change in electric field\n        delta_F = F1 - F0\n\n        # Calculate the change in adsorption energy for OH and O in eV.\n        # The formula is ΔE_ads = -μ * ΔF, where μ is in eÅ and F is in V/Å.\n        # The product (eÅ) * (V/Å) results in eV.\n        delta_E_ads_OH = -mu_OH_eA * delta_F\n        delta_E_ads_O = -mu_O_eA * delta_F\n\n        # Evaluate the decoupling criterion:\n        # |ΔE_ads(O)| <= τ AND |ΔE_ads(OH)| >= σ\n        is_decoupled = (abs(delta_E_ads_O) <= tau) and (abs(delta_E_ads_OH) >= sigma)\n\n        results.append([delta_E_ads_OH, delta_E_ads_O, is_decoupled])\n\n    # Final print statement in the exact required format.\n    # str() on a list of lists will produce the desired format.\n    # e.g., str([[1.0, 2.0, True]]) -> '[[1.0, 2.0, True]]'\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Building on the concept of scaling relations, a crucial practical skill is the ability to quantitatively assess their validity and strength. A \"tight\" scaling relation is a powerful predictive tool, while a \"loose\" one may be unreliable or, more interestingly, hint at opportunities for design. This practice guides you through the process of creating a robust, quantitative metric for the tightness of a scaling relation using fundamental statistical concepts . You will combine measures of linearity, monotonicity, and residual error to formulate a single score that provides a more nuanced assessment than simple correlation coefficients alone.",
            "id": "4241585",
            "problem": "You are given the task of formalizing the notion of a scaling relation between adsorption energies of oxygen reduction reaction intermediates in computational electrochemistry and of constructing a quantitative, dimensionless scalar that measures the tightness of such a relation. Work within the descriptor-based design paradigm where adsorption energies serve as descriptors to forecast catalytic behavior. Proceed from fundamental, widely accepted definitions in statistics and linear regression to formulate a mathematically rigorous tightness measure based on correlation and residual analysis. Then implement the measure as a program and apply it to the provided datasets.\n\nConstruct a scalar tightness score for a bivariate scaling relation between two adsorption energies, where one is treated as the descriptor and the other as the target. The score must be derived from the following fundamental bases:\n\n- The definition of Pearson product-moment correlation, which for two random variables with realizations $x_i$ and $y_i$ and finite nonzero standard deviations $\\sigma_x$ and $\\sigma_y$, is given by the correlation between centered variables divided by the product of their standard deviations.\n- The definition of Spearman rank correlation as the Pearson correlation of the rank-transformed variables.\n- Ordinary least squares linear regression of $y$ onto $x$ with an intercept, yielding a line $y = a x + b$ minimizing the sum of squared residuals $\\sum_i \\varepsilon_i^2$, where $\\varepsilon_i = y_i - (a x_i + b)$.\n- Root-mean-square error computed from residuals and an appropriate normalization using the standard deviation of $y$ so that the residual contribution becomes unitless and affine-invariant under rescaling of $y$.\n\nYour score must satisfy all of the following properties, which you must justify from first principles in your derivation:\n\n- It aggregates three contributions: one that increases monotonically with the magnitude of the Pearson correlation, one that increases monotonically with the magnitude of the Spearman correlation, and one that increases as the residual dispersion decreases, using a normalization by a dispersion of $y$ so that it is invariant to affine rescaling of $y$.\n- It is bounded in the closed interval $[0,1]$.\n- It attains the value $1$ for perfectly linear, strictly monotonic relations with zero residuals.\n- It does not increase when a single outlier is introduced that increases the residual dispersion while preserving the overall monotonic trend.\n- It is symmetric under exchanging $x$ and $y$ only in the two correlation contributions, but not necessarily in the residual contribution because the regression is $y$ on $x$.\n\nYou must construct a concrete score that satisfies these properties and implement it algorithmically. Adopt a nonnegative, convex aggregation across the three contributions with equal emphasis on correlation monotonicity and residual compactness. If needed to maintain the $[0,1]$ bound, apply a rectification to the residual-based term to avoid negative contributions.\n\nData are adsorption energies of oxygen intermediates in electronvolts (eV), sampled across distinct catalyst surfaces. Each dataset contains triplets $(E_{\\mathrm{OH}}, E_{\\mathrm{O}}, E_{\\mathrm{OOH}})$ for multiple catalysts. For each dataset, evaluate three scaling relations, treating the first argument as $x$ and the second as $y$:\n\n- $E_{\\mathrm{OOH}}$ versus $E_{\\mathrm{OH}}$,\n- $E_{\\mathrm{O}}$ versus $E_{\\mathrm{OH}}$,\n- $E_{\\mathrm{OOH}}$ versus $E_{\\mathrm{O}}$.\n\nAll adsorption energies are in $\\mathrm{eV}$. Your scalar tightness score is dimensionless and must be reported as a real number rounded to $6$ decimal places.\n\nUse the following three datasets (each list corresponds to the same ordered set of distinct catalyst surfaces):\n\n- Dataset $A$ (near-perfect linear scaling):\n  - $E_{\\mathrm{OH}}$ in $\\mathrm{eV}$: $[0.8, 1.0, 1.2, 1.4, 1.6]$,\n  - $E_{\\mathrm{OOH}}$ in $\\mathrm{eV}$: $E_{\\mathrm{OH}} + 3.2$,\n  - $E_{\\mathrm{O}}$ in $\\mathrm{eV}$: $2 \\, E_{\\mathrm{OH}} + 0.5$.\n- Dataset $B$ (monotonic but mildly nonlinear scaling):\n  - $E_{\\mathrm{OH}}$ in $\\mathrm{eV}$: $[0.7, 0.9, 1.1, 1.3, 1.5]$,\n  - $E_{\\mathrm{OOH}}$ in $\\mathrm{eV}$: $3.1 + E_{\\mathrm{OH}} + 0.1 \\, E_{\\mathrm{OH}}^2$,\n  - $E_{\\mathrm{O}}$ in $\\mathrm{eV}$: $0.5 + 2 \\, E_{\\mathrm{OH}} + 0.2 \\, E_{\\mathrm{OH}}^2$.\n- Dataset $C$ (linear relation with an outlier):\n  - $E_{\\mathrm{OH}}$ in $\\mathrm{eV}$: $[0.8, 1.0, 1.2, 1.4, 1.6]$,\n  - $E_{\\mathrm{OOH}}$ in $\\mathrm{eV}$: $E_{\\mathrm{OH}} + 3.2$ except the third entry increased by $0.6 \\, \\mathrm{eV}$,\n  - $E_{\\mathrm{O}}$ in $\\mathrm{eV}$: $2 \\, E_{\\mathrm{OH}} + 0.5$ except the second entry decreased by $0.8 \\, \\mathrm{eV}$.\n\nTest suite and required output:\n\n- For each of the three datasets $A$, $B$, and $C$, compute the tightness score for the three ordered relations: $E_{\\mathrm{OOH}}$ versus $E_{\\mathrm{OH}}$, $E_{\\mathrm{O}}$ versus $E_{\\mathrm{OH}}$, and $E_{\\mathrm{OOH}}$ versus $E_{\\mathrm{O}}$.\n- This yields $9$ scores in total. Your program should produce a single line of output containing these $9$ results as a comma-separated list enclosed in square brackets, in the following fixed order: $\\left[ S_{A, \\mathrm{OOH|OH}}, S_{A, \\mathrm{O|OH}}, S_{A, \\mathrm{OOH|O}}, S_{B, \\mathrm{OOH|OH}}, S_{B, \\mathrm{O|OH}}, S_{B, \\mathrm{OOH|O}}, S_{C, \\mathrm{OOH|OH}}, S_{C, \\mathrm{O|OH}}, S_{C, \\mathrm{OOH|O}} \\right]$, with each entry rounded to exactly $6$ decimal places. The score is dimensionless.\n\nAngle units do not appear in this problem. Do not express any result using the percentage sign; all values must be real numbers.\n\nYour final program must be self-contained and produce the exact output format described here without requiring user input or external resources.",
            "solution": "The problem as stated is valid. It presents a well-posed task within the established scientific framework of computational materials science and descriptor-based design, specifically in the context of electrocatalysis. The problem is scientifically grounded, relying on fundamental, universally accepted principles of linear algebra and statistics (Pearson and Spearman correlations, Ordinary Least Squares regression). It is objective, complete, and contains no contradictions or ambiguities. It requires the construction of a mathematical object (a scalar score) based on a clear set of axiomatic properties and its application to well-defined synthetic datasets. This constitutes a standard and meaningful exercise in quantitative scientific modeling. We may, therefore, proceed with the derivation and solution.\n\nThe task is to formalize a quantitative, dimensionless scalar, which we shall denote $S$, to measure the \"tightness\" of a bivariate scaling relation between two sets of adsorption energies, treated as a descriptor variable $x$ and a target variable $y$. The score $S$ must be constructed from first principles, satisfying a set of specified properties.\n\nLet the two sets of observations be given by the vectors $\\mathbf{x} = \\{x_1, x_2, \\ldots, x_n\\}$ and $\\mathbf{y} = \\{y_1, y_2, \\ldots, y_n\\}$. The tightness score $S$ is formulated as a convex combination of three distinct, normalized contributions, each lying in the interval $[0, 1]$: a Pearson correlation term $C_P$, a Spearman rank correlation term $C_S$, and a normalized residual error term $C_R$. The problem specifies equal emphasis on each contribution, leading to the following form for the score $S$:\n$$S = \\frac{1}{3} (C_P + C_S + C_R)$$\nWe will now derive each component based on the provided requirements.\n\n**1. Pearson Correlation Contribution, $C_P$**\n\nThe Pearson product-moment correlation coefficient, $\\rho_{xy}$, measures the degree of linear association between two variables. For samples $\\mathbf{x}$ and $\\mathbf{y}$ with means $\\bar{x}$ and $\\bar{y}$, and standard deviations $\\sigma_x$ and $\\sigma_y$, it is defined as:\n$$\\rho_{xy} = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n} (x_i - \\bar{x})^2 \\sum_{i=1}^{n} (y_i - \\bar{y})^2}}$$\nThe value of $\\rho_{xy}$ lies in the interval $[-1, 1]$. The problem requires a contribution that increases monotonically with the magnitude of the correlation. The most direct choice that is bounded in $[0, 1]$ is the absolute value of the Pearson coefficient.\n$$C_P = |\\rho_{xy}|$$\nThis component is $1$ for a perfect linear relationship (either positive or negative) and $0$ for no linear correlation. It is symmetric upon exchange of $x$ and $y$.\n\n**2. Spearman Rank Correlation Contribution, $C_S$**\n\nThe Spearman rank correlation coefficient, $\\rho_S$, measures the strength and direction of the monotonic relationship between two variables. It is defined as the Pearson correlation coefficient of the rank-transformed variables. Let $R_x(i)$ and $R_y(i)$ be the ranks of $x_i$ and $y_i$ within their respective datasets. Then:\n$$\\rho_S = \\rho_{R_x R_y} = \\frac{\\text{cov}(R_x, R_y)}{\\sigma_{R_x} \\sigma_{R_y}}$$\nLike the Pearson coefficient, $\\rho_S$ lies in $[-1, 1]$. It is less sensitive to outliers than $\\rho_{xy}$ and captures non-linear monotonic trends. To meet the requirement of a score contribution that increases with the magnitude of monotonic correlation, we again use the absolute value:\n$$C_S = |\\rho_S|$$\nThis component is $1$ for any perfect monotonic relationship (linear or not) and $0$ for no monotonic trend. It is also symmetric upon exchange of $x$ and $y$.\n\n**3. Normalized Residual Error Contribution, $C_R$**\n\nThis component quantifies the compactness of the data around a best-fit line, independent of any inherent monotonic trend. It is based on the residuals of an Ordinary Least Squares (OLS) linear regression of $y$ onto $x$. The OLS procedure finds the parameters $a$ (slope) and $b$ (intercept) for the line $y_{pred} = ax + b$ that minimize the sum of squared residuals, $\\sum_{i=1}^{n} \\varepsilon_i^2$, where the residual for each point is $\\varepsilon_i = y_i - y_{pred,i} = y_i - (ax_i + b)$.\n\nThe dispersion of these residuals is measured by the Root Mean Square Error (RMSE):\n$$\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} \\varepsilon_i^2}$$\nTo make this measure dimensionless and invariant to affine transformations of $y$ (i.e., $y' = cy+d$ for $c \\neq 0$), the problem requires normalization by a measure of the dispersion of $y$. The standard deviation of $y$, $\\sigma_y = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\bar{y})^2}$, is the appropriate choice. An affine transformation on $y$ transforms $\\text{RMSE}$ to $|c|\\text{RMSE}$ and $\\sigma_y$ to $|c|\\sigma_y$, leaving their ratio, the Normalized RMSE (NRMSE), invariant.\n$$\\text{NRMSE} = \\frac{\\text{RMSE}}{\\sigma_y}$$\nThe contribution $C_R$ must increase as the residual dispersion decreases. A simple form is $1 - \\text{NRMSE}$. For an OLS regression model that includes an intercept term, the sum of squared residuals is always less than or equal to the total sum of squares, i.e., $\\sum \\varepsilon_i^2 \\le \\sum (y_i - \\bar{y})^2$. Dividing by $n$ and taking the square root gives $\\text{RMSE} \\le \\sigma_y$. This ensures that $\\text{NRMSE} \\in [0, 1]$ (assuming $\\sigma_y > 0$), and consequently, the contribution term is also bounded in $[0, 1]$. We define it as:\n$$C_R = 1 - \\frac{\\text{RMSE}}{\\sigma_y}$$\nTo be robust, should any numerical instability or edge case lead to $\\text{RMSE} > \\sigma_y$, we can apply the specified rectification: $C_R = \\max(0, 1 - \\text{NRMSE})$. This component reaches its maximum of $1$ when all residuals are zero (perfect fit, $\\text{RMSE}=0$). Unlike $C_P$ and $C_S$, $C_R$ is asymmetric with respect to the exchange of $x$ and $y$, as the regression of $y$ on $x$ is not identical to the regression of $x$ on $y$.\n\n**4. Final Aggregated Score, $S$**\n\nCombining the three components with equal weighting yields the final expression for the tightness score:\n$$S(\\mathbf{x}, \\mathbf{y}) = \\frac{1}{3} \\left( |\\rho_{xy}| + |\\rho_S| + \\left(1 - \\frac{\\text{RMSE}_y}{\\sigma_y}\\right) \\right)$$\nThis score satisfies all the required properties:\n- It aggregates the three specified contributions with equal emphasis via a convex combination.\n- It is bounded in $[0, 1]$ as it is an average of three terms, each in $[0, 1]$.\n- It equals $1$ only when $|\\rho_{xy}|=1$, $|\\rho_S|=1$, and $\\text{RMSE}=0$, which corresponds to a perfect, strictly monotonic linear relationship with zero error.\n- The introduction of an outlier typically increases $\\text{RMSE}$ and decreases $|\\rho_{xy}|$, thus decreasing $C_R$ and $C_P$, which leads to a lower score $S$. The inclusion of the robust Spearman term $C_S$ prevents the score from collapsing if the outlier does not disrupt the overall rank-ordering.\n- The score is asymmetric because the term $C_R$ depends on the choice of $y$ as the dependent variable.\n\nThe following algorithm will be used to compute the score for each dataset and relation.\n1.  For a given pair of vectors $(\\mathbf{x}, \\mathbf{y})$:\n2.  Compute the Pearson correlation coefficient $\\rho_{xy}$ and set $C_P = |\\rho_{xy}|$.\n3.  Compute the Spearman rank correlation coefficient $\\rho_S$ and set $C_S = |\\rho_S|$.\n4.  Perform an OLS linear regression of $\\mathbf{y}$ on $\\mathbf{x}$ to obtain the predicted values $\\mathbf{y}_{pred}$.\n5.  Calculate the residuals $\\boldsymbol{\\varepsilon} = \\mathbf{y} - \\mathbf{y}_{pred}$.\n6.  Compute the RMSE from the residuals.\n7.  Compute the standard deviation $\\sigma_y$ of the target variable $\\mathbf{y}$.\n8.  If $\\sigma_y > 0$, calculate $C_R = 1 - \\text{RMSE}/\\sigma_y$. If $\\sigma_y=0$, the relation is perfectly flat; both $\\mathrm{RMSE}$ and $\\sigma_y$ are $0$. In this degenerate case, $C_R$ is taken to be $1$ as prediction error is zero.\n9.  Calculate the final score $S = (C_P + C_S + C_R) / 3$.\nThis procedure is applied to the nine specified relations across the three datasets.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\n\ndef solve():\n    \"\"\"\n    Main function to define datasets, compute tightness scores, and print results.\n    \"\"\"\n\n    def calculate_tightness_score(x_data, y_data):\n        \"\"\"\n        Calculates the tightness score S for a bivariate scaling relation.\n\n        The score S is a convex combination of three terms:\n        1. C_P: Absolute Pearson correlation coefficient.\n        2. C_S: Absolute Spearman rank correlation coefficient.\n        3. C_R: Normalized residual error from an OLS regression.\n\n        S = (C_P + C_S + C_R) / 3\n\n        Args:\n            x_data (list or np.ndarray): The independent variable (descriptor).\n            y_data (list or np.ndarray): The dependent variable (target).\n\n        Returns:\n            float: The calculated tightness score, a value between 0 and 1.\n        \"\"\"\n        x = np.array(x_data, dtype=float)\n        y = np.array(y_data, dtype=float)\n\n        if len(x) != len(y) or len(x) < 2:\n            raise ValueError(\"Input arrays must have the same length of at least 2.\")\n\n        # Component 1: Pearson Correlation\n        # scipy.stats.pearsonr returns (correlation, p-value)\n        # We handle the case of constant input, which would give nan.\n        if np.std(x) == 0 or np.std(y) == 0:\n            rho_xy = 0.0\n        else:\n            rho_xy, _ = stats.pearsonr(x, y)\n        \n        c_p = np.abs(rho_xy)\n\n        # Component 2: Spearman Rank Correlation\n        # scipy.stats.spearmanr returns (correlation, p-value)\n        rho_s, _ = stats.spearmanr(x, y)\n        c_s = np.abs(rho_s)\n\n        # Component 3: Normalized Residual Error\n        # Perform OLS regression of y on x\n        slope, intercept, _, _, _ = stats.linregress(x, y)\n        \n        y_pred = slope * x + intercept\n        residuals = y - y_pred\n        \n        rmse = np.sqrt(np.mean(residuals**2))\n        \n        sigma_y = np.std(y)\n        \n        # If sigma_y is 0, y is constant. The best prediction is the mean,\n        # so residuals are 0, RMSE = 0. C_R should be 1.\n        if sigma_y < 1e-12: # Use a small tolerance for floating point\n            c_r = 1.0\n        else:\n            nrmse = rmse / sigma_y\n            # The value is guaranteed to be in [0, 1] for OLS with intercept.\n            # max(0, ..) is for robustness.\n            c_r = max(0.0, 1.0 - nrmse)\n\n        # Final Score: Convex combination with equal weights\n        score = (c_p + c_s + c_r) / 3.0\n        \n        return score\n\n    # --- Data Generation ---\n\n    # Dataset A (perfect linear scaling)\n    E_OH_A = np.array([0.8, 1.0, 1.2, 1.4, 1.6])\n    E_OOH_A = E_OH_A + 3.2\n    E_O_A = 2 * E_OH_A + 0.5\n    \n    # Dataset B (monotonic but mildly nonlinear scaling)\n    E_OH_B = np.array([0.7, 0.9, 1.1, 1.3, 1.5])\n    E_OOH_B = 3.1 + E_OH_B + 0.1 * E_OH_B**2\n    E_O_B = 0.5 + 2 * E_OH_B + 0.2 * E_OH_B**2\n\n    # Dataset C (linear relation with an outlier)\n    E_OH_C = np.array([0.8, 1.0, 1.2, 1.4, 1.6])\n    E_OOH_C = E_OH_C + 3.2\n    E_OOH_C[2] += 0.6  # Outlier for OOH at E_OH=1.2\n    E_O_C = 2 * E_OH_C + 0.5\n    E_O_C[1] -= 0.8    # Outlier for O at E_OH=1.0\n\n    # Define the 9 relations to test in the required order\n    # Format: (x_data, y_data)\n    # Order: E_OOH vs E_OH, E_O vs E_OH, E_OOH vs E_O\n    test_cases = [\n        # Dataset A\n        (E_OH_A, E_OOH_A),\n        (E_OH_A, E_O_A),\n        (E_O_A, E_OOH_A),\n        # Dataset B\n        (E_OH_B, E_OOH_B),\n        (E_OH_B, E_O_B),\n        (E_O_B, E_OOH_B),\n        # Dataset C\n        (E_OH_C, E_OOH_C),\n        (E_OH_C, E_O_C),\n        (E_O_C, E_OOH_C),\n    ]\n\n    results = []\n    for x_data, y_data in test_cases:\n        score = calculate_tightness_score(x_data, y_data)\n        results.append(score)\n\n    # Format the final output string as per requirements\n    # Each value rounded to 6 decimal places.\n    output_str = f\"[{','.join([f'{s:.6f}' for s in results])}]\"\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "Descriptor-based models are powerful, but their predictions are only as reliable as their inputs. In real-world computational and experimental science, all data carries some degree of uncertainty. This final practice bridges the gap between deterministic models and robust, real-world predictions by introducing uncertainty quantification . You will learn how to propagate the uncertainty from your input descriptors through a catalyst performance model to determine a confidence interval for a key metric, the limiting potential ($U_L$). This essential skill allows for a more honest and scientifically rigorous assessment of a material's predicted catalytic activity.",
            "id": "4241567",
            "problem": "In descriptor-based design of electrocatalysts under the Computational Hydrogen Electrode (CHE) framework, the free energy of an elementary electrochemical step $i$ at electrode potential $U$ satisfies a linear shift with $U$ due to electron transfer. The limiting potential $U_{\\mathrm{L}}$ is defined as the smallest $U$ for which all elementary steps are thermodynamically downhill. Consider a reaction mechanism with two potentially rate-determining steps, indexed by $i \\in \\{1,2\\}$, each involving a single electron transfer. A descriptor vector $\\mathbf{x} \\in \\mathbb{R}^{2}$ encodes two adsorption free energies (in electronvolts), and the standard free energy for step $i$ at $U=0$ is modeled as an affine function of the descriptors:\n$$\n\\Delta G_{i}^{0} = A_{i} + \\mathbf{w}_{i}^{\\top}\\mathbf{x},\n$$\nwith $A_{i} \\in \\mathbb{R}$ and $\\mathbf{w}_{i} \\in \\mathbb{R}^{2}$. Assume the descriptor vector is Gaussian due to model and electronic-structure uncertainty,\n$$\n\\mathbf{x} \\sim \\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma}),\n$$\nwith mean\n$$\n\\boldsymbol{\\mu} = \\begin{pmatrix} 0.95 \\\\ 1.65 \\end{pmatrix},\n$$\nand covariance\n$$\n\\boldsymbol{\\Sigma} = \\begin{pmatrix} 0.04^{2} & 0.6 \\times 0.04 \\times 0.05 \\\\ 0.6 \\times 0.04 \\times 0.05 & 0.05^{2} \\end{pmatrix}.\n$$\nThe two steps are parameterized by\n$$\nA_{1} = 0.28,\\quad \\mathbf{w}_{1} = \\begin{pmatrix} 0.85 \\\\ -0.15 \\end{pmatrix},\\qquad\nA_{2} = 0.12,\\quad \\mathbf{w}_{2} = \\begin{pmatrix} 0.10 \\\\ 0.90 \\end{pmatrix}.\n$$\nAll energies are in electronvolts, and each step transfers $n_{i} = 1$ electron. The elementary charge is $e$.\n\nTasks:\n1. Starting from the CHE potential dependence of step free energies and the definition of the limiting potential, derive an analytic expression for $U_{\\mathrm{L}}$ in terms of $\\Delta G_{i}^{0}$ and $e$ for the two-step mechanism. Then, express $U_{\\mathrm{L}}$ as a function of $\\mathbf{x}$.\n2. Using first-order error propagation (the delta method) for a piecewise-smooth function, derive the mean and variance of $U_{\\mathrm{L}}$ in terms of $\\boldsymbol{\\mu}$, $\\boldsymbol{\\Sigma}$, and the appropriate gradient with respect to $\\mathbf{x}$, under the assumption that a single step dominates the limiting potential in the neighborhood of $\\boldsymbol{\\mu}$.\n3. Compute the two-sided $95\\%$ confidence interval for $U_{\\mathrm{L}}$ in volts, using the Gaussian approximation and the parameters provided. State which step dominates at $\\boldsymbol{\\mu}$ and justify the local linearization. Express the final interval endpoints in volts, rounded to four significant figures.",
            "solution": "The user-provided problem statement has been validated and is deemed scientifically grounded, well-posed, objective, complete, and non-trivial. The problem is solvable.\n\n### Task 1: Derivation of the Limiting Potential $U_{\\mathrm{L}}$\n\nThe problem is framed within the Computational Hydrogen Electrode (CHE) model. The free energy of an elementary electrochemical step $i$ involving the transfer of $n_i$ electrons at an electrode potential $U$ is given by $\\Delta G_i(U)$. The sign of the potential-dependent term depends on whether the electron is a reactant or a product. For a general oxidative step $A \\rightarrow B + n_i e^{-}$, the free energy change is $\\Delta G_i(U) = \\Delta G_i^0 - n_i e U$, where $\\Delta G_i^0$ is the standard free energy change at $U=0$, and $e$ is the elementary charge. A step is considered thermodynamically downhill if its free energy change is non-positive, i.e., $\\Delta G_i(U) \\le 0$.\n\nThis condition translates to:\n$$\n\\Delta G_i^0 - n_i e U \\le 0 \\implies n_i e U \\ge \\Delta G_i^0 \\implies U \\ge \\frac{\\Delta G_i^0}{n_i e}\n$$\nThe limiting potential, $U_{\\mathrm{L}}$, is defined as the smallest potential $U$ for which *all* elementary steps are thermodynamically downhill. This means we must satisfy the condition $U \\ge \\frac{\\Delta G_i^0}{n_i e}$ for all steps $i$ in the mechanism. For the given two-step mechanism ($i \\in \\{1, 2\\}$), this requires:\n$$\nU \\ge \\frac{\\Delta G_1^0}{n_1 e} \\quad \\text{and} \\quad U \\ge \\frac{\\Delta G_2^0}{n_2 e}\n$$\nTo satisfy both inequalities simultaneously, $U$ must be greater than or equal to the maximum of the two lower bounds. The smallest such $U$ is therefore the maximum itself:\n$$\nU_{\\mathrm{L}} = \\max\\left(\\frac{\\Delta G_1^0}{n_1 e}, \\frac{\\Delta G_2^0}{n_2 e}\\right)\n$$\nThis expression is consistent with the problem's definition of $U_{\\mathrm{L}}$ as the *smallest* potential satisfying the downhill condition for an oxidative process.\n\nThe problem states that energies are given in electronvolts (eV) and the potential $U$ is in volts (V). Let $g_i^0$ be the numerical value of the free energy $\\Delta G_i^0$ in units of eV. Then $\\Delta G_i^0 = g_i^0 \\cdot e$. Substituting this into the expression for $U_{\\mathrm{L}}$:\n$$\nU_{\\mathrm{L}} = \\max\\left(\\frac{g_1^0 \\cdot e}{n_1 e}, \\frac{g_2^0 \\cdot e}{n_2 e}\\right) = \\max\\left(\\frac{g_1^0}{n_1}, \\frac{g_2^0}{n_2}\\right)\n$$\nIn this equation, the numerical value of $U_{\\mathrm{L}}$ in volts is determined by the numerical values of the free energies in electronvolts. The problem provides that $n_1=1$ and $n_2=1$, and gives the standard free energies (in eV) as $g_i^0(\\mathbf{x}) = A_i + \\mathbf{w}_i^{\\top} \\mathbf{x}$. Therefore, the limiting potential in volts as a function of the descriptor vector $\\mathbf{x}$ is:\n$$\nU_{\\mathrm{L}}(\\mathbf{x}) = \\max\\left(A_1 + \\mathbf{w}_1^{\\top}\\mathbf{x}, A_2 + \\mathbf{w}_2^{\\top}\\mathbf{x}\\right)\n$$\n\n### Task 2: Mean and Variance of $U_{\\mathrm{L}}$\n\nTo find the mean and variance of $U_{\\mathrm{L}}$, we use the first-order error propagation (delta method). The problem assumes that a single step dominates in the neighborhood of the mean descriptor value $\\boldsymbol{\\mu}$, which linearizes the piecewise function $U_{\\mathrm{L}}(\\mathbf{x})$ around $\\boldsymbol{\\mu}$.\n\nFirst, we must determine which step dominates at $\\mathbf{x} = \\boldsymbol{\\mu}$. Let $g_i(\\mathbf{x}) = A_i + \\mathbf{w}_i^{\\top}\\mathbf{x}$. We evaluate $g_1(\\boldsymbol{\\mu})$ and $g_2(\\boldsymbol{\\mu})$.\n$$\n\\boldsymbol{\\mu} = \\begin{pmatrix} 0.95 \\\\ 1.65 \\end{pmatrix}\n$$\n$$\ng_1(\\boldsymbol{\\mu}) = A_1 + \\mathbf{w}_1^{\\top}\\boldsymbol{\\mu} = 0.28 + \\begin{pmatrix} 0.85 & -0.15 \\end{pmatrix} \\begin{pmatrix} 0.95 \\\\ 1.65 \\end{pmatrix} = 0.28 + (0.85)(0.95) - (0.15)(1.65) = 0.28 + 0.8075 - 0.2475 = 0.84\n$$\n$$\ng_2(\\boldsymbol{\\mu}) = A_2 + \\mathbf{w}_2^{\\top}\\boldsymbol{\\mu} = 0.12 + \\begin{pmatrix} 0.10 & 0.90 \\end{pmatrix} \\begin{pmatrix} 0.95 \\\\ 1.65 \\end{pmatrix} = 0.12 + (0.10)(0.95) + (0.90)(1.65) = 0.12 + 0.095 + 1.485 = 1.70\n$$\nSince $g_2(\\boldsymbol{\\mu}) = 1.70 > g_1(\\boldsymbol{\\mu}) = 0.84$, step $2$ dominates the limiting potential at the mean descriptor value. The assumption of local linearity is justified by the large difference between $g_2(\\boldsymbol{\\mu})$ and $g_1(\\boldsymbol{\\mu})$.\n\nIn the neighborhood of $\\boldsymbol{\\mu}$, $U_{\\mathrm{L}}(\\mathbf{x}) \\approx g_2(\\mathbf{x}) = A_2 + \\mathbf{w}_2^{\\top}\\mathbf{x}$. The gradient of $U_{\\mathrm{L}}$ with respect to $\\mathbf{x}$ at $\\boldsymbol{\\mu}$ is therefore:\n$$\n\\nabla_{\\mathbf{x}} U_{\\mathrm{L}}(\\boldsymbol{\\mu}) \\approx \\nabla_{\\mathbf{x}} g_2(\\boldsymbol{\\mu}) = \\mathbf{w}_2\n$$\nAccording to the delta method, the expectation of $U_{\\mathrm{L}}$ is approximated by:\n$$\nE[U_{\\mathrm{L}}] \\approx U_{\\mathrm{L}}(\\boldsymbol{\\mu}) = g_2(\\boldsymbol{\\mu})\n$$\nThe variance of $U_{\\mathrm{L}}$ is approximated by:\n$$\n\\mathrm{Var}[U_{\\mathrm{L}}] \\approx (\\nabla_{\\mathbf{x}} U_{\\mathrm{L}}(\\boldsymbol{\\mu}))^{\\top} \\boldsymbol{\\Sigma} (\\nabla_{\\mathbf{x}} U_{\\mathrm{L}}(\\boldsymbol{\\mu})) = \\mathbf{w}_2^{\\top} \\boldsymbol{\\Sigma} \\mathbf{w}_2\n$$\nSince $U_{\\mathrm{L}}(\\mathbf{x})$ is locally a linear function of the normally distributed vector $\\mathbf{x}$, the resulting distribution for $U_{\\mathrm{L}}$ is also approximately Gaussian, and these expressions for the mean and variance are exact for the linearized model.\n\n### Task 3: Calculation of the 95% Confidence Interval\n\nWe now compute the numerical values for the mean and variance of $U_{\\mathrm{L}}$.\nThe mean is:\n$$\n\\mu_{U_{\\mathrm{L}}} = E[U_{\\mathrm{L}}] \\approx g_2(\\boldsymbol{\\mu}) = 1.70 \\, \\mathrm{V}\n$$\nThe covariance matrix is:\n$$\n\\boldsymbol{\\Sigma} = \\begin{pmatrix} 0.04^{2} & 0.6 \\times 0.04 \\times 0.05 \\\\ 0.6 \\times 0.04 \\times 0.05 & 0.05^{2} \\end{pmatrix} = \\begin{pmatrix} 0.0016 & 0.0012 \\\\ 0.0012 & 0.0025 \\end{pmatrix} \\, \\mathrm{eV}^2\n$$\nThe variance of $U_{\\mathrm{L}}$ (in $\\mathrm{V}^2$) is:\n$$\n\\sigma_{U_{\\mathrm{L}}}^2 = \\mathrm{Var}[U_{\\mathrm{L}}] \\approx \\mathbf{w}_2^{\\top} \\boldsymbol{\\Sigma} \\mathbf{w}_2 = \\begin{pmatrix} 0.10 & 0.90 \\end{pmatrix} \\begin{pmatrix} 0.0016 & 0.0012 \\\\ 0.0012 & 0.0025 \\end{pmatrix} \\begin{pmatrix} 0.10 \\\\ 0.90 \\end{pmatrix}\n$$\n$$\n\\sigma_{U_{\\mathrm{L}}}^2 \\approx \\begin{pmatrix} 0.10(0.0016) + 0.90(0.0012) & 0.10(0.0012) + 0.90(0.0025) \\end{pmatrix} \\begin{pmatrix} 0.10 \\\\ 0.90 \\end{pmatrix}\n$$\n$$\n\\sigma_{U_{\\mathrm{L}}}^2 \\approx \\begin{pmatrix} 0.00016 + 0.00108 & 0.00012 + 0.00225 \\end{pmatrix} \\begin{pmatrix} 0.10 \\\\ 0.90 \\end{pmatrix}\n$$\n$$\n\\sigma_{U_{\\mathrm{L}}}^2 \\approx \\begin{pmatrix} 0.00124 & 0.00237 \\end{pmatrix} \\begin{pmatrix} 0.10 \\\\ 0.90 \\end{pmatrix}\n$$\n$$\n\\sigma_{U_{\\mathrm{L}}}^2 \\approx 0.00124(0.10) + 0.00237(0.90) = 0.000124 + 0.002133 = 0.002257 \\, \\mathrm{V}^2\n$$\nThe standard deviation is:\n$$\n\\sigma_{U_{\\mathrm{L}}} \\approx \\sqrt{0.002257} \\approx 0.0475079 \\, \\mathrm{V}\n$$\nFor a $95\\%$ confidence interval, we use the z-score $z_{\\alpha/2}$ corresponding to a cumulative probability of $1 - (1-0.95)/2 = 0.975$. This value is $z_{0.025} \\approx 1.96$. The interval is given by $\\mu_{U_{\\mathrm{L}}} \\pm z_{0.025} \\sigma_{U_{\\mathrm{L}}}$.\nMargin of error:\n$$\n\\Delta = z_{0.025} \\sigma_{U_{\\mathrm{L}}} \\approx 1.959964 \\times 0.0475079 \\approx 0.093114 \\, \\mathrm{V}\n$$\nLower bound:\n$$\nU_{\\mathrm{L, lower}} = 1.70 - 0.093114 = 1.606886 \\, \\mathrm{V}\n$$\nUpper bound:\n$$\nU_{\\mathrm{L, upper}} = 1.70 + 0.093114 = 1.793114 \\, \\mathrm{V}\n$$\nRounding the endpoints to four significant figures gives $1.607 \\, \\mathrm{V}$ and $1.793 \\, \\mathrm{V}$.\n\nThe justification for linearization is robust. The difference in free energies at the mean, $g_2(\\boldsymbol{\\mu}) - g_1(\\boldsymbol{\\mu}) = 0.86$, is substantial. The standard deviation of this difference is $\\sigma_{g_2-g_1} = \\sqrt{(\\mathbf{w}_2-\\mathbf{w}_1)^{\\top}\\boldsymbol{\\Sigma}(\\mathbf{w}_2-\\mathbf{w}_1)} \\approx 0.042$. The mean difference is $0.86/0.042 \\approx 20.5$ standard deviations away from zero, meaning the probability of step $1$ becoming dominant is negligible. Thus, the linearization is well-justified.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 1.607 & 1.793 \\end{pmatrix}}\n$$"
        }
    ]
}