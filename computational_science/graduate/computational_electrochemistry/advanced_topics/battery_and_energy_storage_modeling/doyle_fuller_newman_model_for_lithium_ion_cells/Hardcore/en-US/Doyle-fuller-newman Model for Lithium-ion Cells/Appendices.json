{
    "hands_on_practices": [
        {
            "introduction": "A robust computational model is one whose numerical implementation can be trusted. This practice lays the groundwork for building a reliable Doyle-Fuller-Newman model by focusing on a core component: the diffusion equation. You will implement a numerical solution for Fickian diffusion and verify its correctness by performing a convergence analysis, a fundamental skill for any computational scientist to quantify and ensure the accuracy of their simulations. ",
            "id": "4242995",
            "problem": "Consider the electrolyte mass balance within the Doyle-Fuller-Newman model for lithium-ion cells under the condition of zero interfacial reaction current and constant temperature. In this limit, the governing equation for the electrolyte salt concentration reduces to Fickian diffusion. Let $c(x,t)$ denote the electrolyte salt concentration in $\\mathrm{mol/m^3}$, $D$ denote the salt diffusivity in the electrolyte in $\\mathrm{m^2/s}$, $x \\in [0,L]$ denote the through-cell coordinate in $\\mathrm{m}$, and $t \\ge 0$ denote the time in $\\mathrm{s}$. The governing equation and boundary conditions are\n$$\n\\frac{\\partial c}{\\partial t} = D \\frac{\\partial^2 c}{\\partial x^2}, \\quad \\frac{\\partial c}{\\partial x}(0,t) = 0, \\quad \\frac{\\partial c}{\\partial x}(L,t) = 0,\n$$\nwith an initial condition specified by a single cosine mode:\n$$\nc(x,0) = c_{\\mathrm{ref}} + a \\cos\\left(\\frac{\\pi x}{L}\\right),\n$$\nwhere $c_{\\mathrm{ref}}$ is a constant reference concentration in $\\mathrm{mol/m^3}$ and $a$ is an amplitude in $\\mathrm{mol/m^3}$.\n\nStarting only from conservation of mass and Fick’s law of diffusion, discretize the spatial operator using a second-order, uniform-grid, central-difference scheme with no-flux (Neumann) boundary conditions, and discretize time using a second-order implicit Crank–Nicolson method. Implement the resulting scheme in a computer program and quantify the discretization error at a final time by comparison with the exact solution derived from first principles. Then, for a sequence of grid refinements, estimate the observed spatial order of convergence $p$ by fitting a line to the data $\\log(e(\\Delta x))$ versus $\\log(\\Delta x)$, where $e(\\Delta x)$ is the numerical error measured in the continuous $\\mathrm{L^2}$ norm at the final time.\n\nYou must adhere to the following requirements:\n- Spatial domain is $[0,L]$ with a uniform grid of $M$ intervals, so that $\\Delta x = L/M$, where $M \\in \\{20, 40, 80, 160\\}$ for each test case.\n- Enforce the Neumann boundaries with second-order accuracy by appropriate treatment of boundary nodes in the discrete Laplacian, consistent with the physical no-flux condition.\n- Use the Crank–Nicolson method with a time step $\\Delta t$ chosen according to $\\Delta t = \\beta \\, \\Delta x^2 / D$, with a fixed $\\beta = 2.0$ for all tests. Advance to $t_{\\mathrm{final}} = N_t \\Delta t$, where $N_t$ is the nearest integer to $T/\\Delta t$.\n- The exact solution should be derived from separation of variables and used to compute the error at $t_{\\mathrm{final}}$. Measure the error $e(\\Delta x)$ using the continuous $\\mathrm{L^2}$ norm approximated by the rectangle rule:\n$$\ne(\\Delta x) = \\left( \\Delta x \\sum_{i=0}^{M} \\left[c_i^{\\mathrm{num}}(t_{\\mathrm{final}}) - c^{\\mathrm{exact}}(x_i,t_{\\mathrm{final}})\\right]^2 \\right)^{1/2},\n$$\nwhere $x_i = i \\Delta x$ and $c_i^{\\mathrm{num}}(t_{\\mathrm{final}})$ is the numerical solution at the grid points.\n- For each test case, estimate $p$ by fitting a line to $\\log(e(\\Delta x))$ versus $\\log(\\Delta x)$ across the grid sequence $\\{20, 40, 80, 160\\}$, and report $p$ rounded to three decimal places.\n\nPhysical units and constants:\n- Report all quantities with physical units as follows: $D$ in $\\mathrm{m^2/s}$, $L$ in $\\mathrm{m}$, $T$ in $\\mathrm{s}$, $c_{\\mathrm{ref}}$ and $a$ in $\\mathrm{mol/m^3}$.\n- Angles do not appear; no angle unit is needed.\n- Do not use percentages; all ratios must be decimals or fractions.\n\nTest suite:\n- Case A (happy path): $D = 1.0 \\times 10^{-10}\\ \\mathrm{m^2/s}$, $L = 100 \\times 10^{-6}\\ \\mathrm{m}$, $T = 10\\ \\mathrm{s}$, $c_{\\mathrm{ref}} = 1000\\ \\mathrm{mol/m^3}$, $a = 100\\ \\mathrm{mol/m^3}$.\n- Case B (rapid diffusion): $D = 5.0 \\times 10^{-10}\\ \\mathrm{m^2/s}$, $L = 50 \\times 10^{-6}\\ \\mathrm{m}$, $T = 2\\ \\mathrm{s}$, $c_{\\mathrm{ref}} = 1200\\ \\mathrm{mol/m^3}$, $a = 50\\ \\mathrm{mol/m^3}$.\n- Case C (slow diffusion, longer horizon): $D = 1.0 \\times 10^{-11}\\ \\mathrm{m^2/s}$, $L = 200 \\times 10^{-6}\\ \\mathrm{m}$, $T = 50\\ \\mathrm{s}$, $c_{\\mathrm{ref}} = 1000\\ \\mathrm{mol/m^3}$, $a = 200\\ \\mathrm{mol/m^3}$.\n- Case D (small domain, stiff): $D = 2.0 \\times 10^{-9}\\ \\mathrm{m^2/s}$, $L = 20 \\times 10^{-6}\\ \\mathrm{m}$, $T = 0.02\\ \\mathrm{s}$, $c_{\\mathrm{ref}} = 1000\\ \\mathrm{mol/m^3}$, $a = 150\\ \\mathrm{mol/m^3}$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[p_A,p_B,p_C,p_D]$), where each $p$ is the observed order of convergence for the corresponding test case, rounded to three decimal places.",
            "solution": "The user has provided a well-posed problem in computational science, asking for the numerical solution of a one-dimensional diffusion equation and an analysis of the numerical scheme's convergence.\n\n### **Problem Validation**\n\n**Step 1: Extract Givens**\n\n*   **Governing Equation**: $\\frac{\\partial c}{\\partial t} = D \\frac{\\partial^2 c}{\\partial x^2}$\n*   **Domain**: $x \\in [0,L]$, $t \\ge 0$.\n*   **Boundary Conditions (BCs)**: No-flux (Neumann) at both ends: $\\frac{\\partial c}{\\partial x}(0,t) = 0$ and $\\frac{\\partial c}{\\partial x}(L,t) = 0$.\n*   **Initial Condition (IC)**: $c(x,0) = c_{\\mathrm{ref}} + a \\cos\\left(\\frac{\\pi x}{L}\\right)$.\n*   **Numerical Method**: A uniform grid with $M$ intervals ($\\Delta x = L/M$), second-order central-difference for spatial discretization, and second-order implicit Crank–Nicolson for time stepping.\n*   **Time Step**: $\\Delta t = \\beta \\, \\Delta x^2 / D$ with a fixed constant $\\beta = 2.0$.\n*   **Final Time**: Calculations are performed up to $t_{\\mathrm{final}} = N_t \\Delta t$, where $N_t$ is the nearest integer to $T/\\Delta t$.\n*   **Grid Refinements**: The simulation is repeated for $M \\in \\{20, 40, 80, 160\\}$.\n*   **Error Metric**: The continuous $\\mathrm{L^2}$ norm, approximated by a specific quadrature rule: $e(\\Delta x) = \\left( \\Delta x \\sum_{i=0}^{M} \\left[c_i^{\\mathrm{num}}(t_{\\mathrm{final}}) - c^{\\mathrm{exact}}(x_i,t_{\\mathrm{final}})\\right]^2 \\right)^{1/2}$.\n*   **Convergence Order Estimation**: The order $p$ is the slope of a linear fit to $\\log(e(\\Delta x))$ versus $\\log(\\Delta x)$ over the sequence of grid refinements.\n*   **Physical Parameters**: Four distinct test cases (A, B, C, D) are provided, each with values for $D, L, T, c_{\\mathrm{ref}}, a$.\n\n**Step 2: Validate Using Extracted Givens**\n\nThe problem is assessed against the validation criteria:\n\n*   **Scientifically Grounded**: The problem is based on Fick's second law of diffusion, a fundamental principle of mass transport. The context, a simplified electrolyte model, is scientifically valid. All parameters are physically meaningful.\n*   **Well-Posed**: The diffusion equation with the given initial and Neumann boundary conditions is a classic, well-posed initial-boundary value problem.\n*   **Objective**: The problem is stated in precise, mathematical language, with all requirements, methods, and parameters explicitly defined.\n*   **Completeness and Consistency**: The problem is self-contained and provides all necessary information. The requested numerical methods, error metrics, and analysis procedures are consistent and standard in the field of numerical analysis.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is **valid**. It is a standard, non-trivial problem in numerical methods for partial differential equations that is scientifically sound, well-posed, and complete. A full solution will be provided.\n\n### **Principle-Based Solution Design**\n\n#### **1. Analytical Solution**\nThe problem can be solved analytically using the method of separation of variables. The governing equation is a linear partial differential equation (PDE), and the initial condition is expressed as a sum of eigenfunctions of the spatial operator with the given Neumann boundary conditions.\nThe general solution for the eigenfunctions $\\cos(n \\pi x / L)$ is:\n$$\nc(x,t) = \\sum_{n=0}^{\\infty} A_n \\cos\\left(\\frac{n \\pi x}{L}\\right) \\exp\\left(-D \\left(\\frac{n \\pi}{L}\\right)^2 t\\right)\n$$\nThe coefficients $A_n$ are determined by the initial condition, $c(x,0)$. By inspection, the given initial condition $c(x,0) = c_{\\mathrm{ref}} + a \\cos\\left(\\frac{\\pi x}{L}\\right)$ corresponds to a Fourier cosine series with only two non-zero terms:\n*   $A_0 = c_{\\mathrm{ref}}$ (for $n=0$)\n*   $A_1 = a$ (for $n=1$)\n*   $A_n = 0$ for $n  1$.\n\nSubstituting these coefficients, the exact analytical solution is:\n$$\nc^{\\mathrm{exact}}(x,t) = c_{\\mathrm{ref}} + a \\cos\\left(\\frac{\\pi x}{L}\\right) \\exp\\left(-D \\left(\\frac{\\pi}{L}\\right)^2 t\\right)\n$$\nThis solution will serve as the benchmark against which the numerical scheme's accuracy is measured.\n\n#### **2. Numerical Discretization**\nWe discretize the domain into $M+1$ grid points $x_i = i \\Delta x$ for $i = 0, 1, \\dots, M$, where $\\Delta x = L/M$. Let $c_i(t)$ be the numerical approximation of $c(x_i, t)$.\n\n**2.1. Spatial Discretization (Second-Order)**\nThe second spatial derivative is approximated using a second-order central difference:\n$$\n\\frac{\\partial^2 c}{\\partial x^2}\\bigg|_{x_i} \\approx \\frac{c_{i-1}(t) - 2c_i(t) + c_{i+1}(t)}{\\Delta x^2} \\quad \\text{for } i = 1, \\dots, M-1\n$$\nTo maintain second-order accuracy at the boundaries, we introduce \"ghost points\" $c_{-1}$ and $c_{M+1}$. The no-flux boundary conditions $\\frac{\\partial c}{\\partial x}=0$ are approximated by a second-order central difference:\n$$\n\\frac{c_1 - c_{-1}}{2\\Delta x} = 0 \\implies c_{-1} = c_1\n\\qquad \\text{and} \\qquad\n\\frac{c_{M+1} - c_{M-1}}{2\\Delta x} = 0 \\implies c_{M+1} = c_{M-1}\n$$\nApplying the spatial stencil at the boundaries and substituting the ghost point relations yields:\n$$\n\\frac{d c_0}{dt} = D \\frac{c_{-1} - 2c_0 + c_1}{\\Delta x^2} = D \\frac{2c_1 - 2c_0}{\\Delta x^2}\n$$\n$$\n\\frac{d c_M}{dt} = D \\frac{c_{M-1} - 2c_M + c_{M+1}}{\\Delta x^2} = D \\frac{2c_{M-1} - 2c_M}{\\Delta x^2}\n$$\n\n**2.2. Temporal Discretization (Crank–Nicolson)**\nThe Crank–Nicolson method approximates the time derivative at the midpoint of a time interval $[t_j, t_{j+1}]$ and averages the spatial derivative over the two time levels:\n$$\n\\frac{c_i^{j+1} - c_i^j}{\\Delta t} = \\frac{D}{2} \\left( \\left(\\frac{\\partial^2 c}{\\partial x^2}\\right)_i^{j+1} + \\left(\\frac{\\partial^2 c}{\\partial x^2}\\right)_i^{j} \\right)\n$$\nLetting $\\vec{c}^j$ be the vector of concentrations at time $t_j$, and $\\mathbf{L}$ be the discrete Laplacian matrix operator, the scheme is:\n$$\n\\frac{\\vec{c}^{j+1} - \\vec{c}^j}{\\Delta t} = \\frac{D}{2} \\left( \\mathbf{L} \\vec{c}^{j+1} + \\mathbf{L} \\vec{c}^{j} \\right)\n$$\nRearranging terms to group knowns (at time $j$) and unknowns (at time $j+1$) gives a linear system to be solved at each time step:\n$$\n\\left(\\mathbf{I} - \\frac{D \\Delta t}{2} \\mathbf{L}\\right) \\vec{c}^{j+1} = \\left(\\mathbf{I} + \\frac{D \\Delta t}{2} \\mathbf{L}\\right) \\vec{c}^{j}\n$$\nLet $\\alpha = \\frac{D \\Delta t}{2 \\Delta x^2}$. The problem specifies $\\Delta t = \\beta \\frac{\\Delta x^2}{D}$ with $\\beta=2.0$, which conveniently fixes $\\alpha = \\frac{D}{2\\Delta x^2} \\left(2.0 \\frac{\\Delta x^2}{D}\\right) = 1.0$.\n\n#### **3. Matrix System Implementation**\nWith $\\alpha=1.0$, the system of equations for the grid points $i=0, \\dots, M$ is:\n$$\n\\mathbf{A} \\vec{c}^{j+1} = \\mathbf{B} \\vec{c}^{j}\n$$\nwhere $\\mathbf{A} = (\\mathbf{I} - \\mathbf{L})$ and $\\mathbf{B} = (\\mathbf{I} + \\mathbf{L})$ for $\\alpha=1.0$. The matrices $\\mathbf{A}$ and $\\mathbf{B}$ are tridiagonal and have the following structure:\n$$\n\\mathbf{A} = \\begin{pmatrix}\n3  -2    \\\\\n-1  3  -1   \\\\\n \\ddots  \\ddots  \\ddots  \\\\\n  -1  3  -1 \\\\\n   -2  3\n\\end{pmatrix}, \\quad\n\\mathbf{B} = \\begin{pmatrix}\n-1  2    \\\\\n1  -1  1   \\\\\n \\ddots  \\ddots  \\ddots  \\\\\n  1  -1  1 \\\\\n   2  -1\n\\end{pmatrix}\n$$\nThis tridiagonal system is solved at each time step. Since the matrices are constant, this is computationally efficient. We use `scipy.linalg.solve_banded` for this purpose.\n\n#### **4. Convergence Analysis**\nThe Crank–Nicolson scheme is second-order accurate in both time ($\\mathcal{O}(\\Delta t^2)$) and space ($\\mathcal{O}(\\Delta x^2)$). The total error is expected to scale as $e \\propto \\mathcal{O}(\\Delta t^2 + \\Delta x^2)$. Since $\\Delta t \\propto \\Delta x^2$, the truncation error is dominated by the spatial term:\n$$\ne(\\Delta x) \\propto \\mathcal{O}((\\Delta x^2)^2 + \\Delta x^2) = \\mathcal{O}(\\Delta x^4 + \\Delta x^2) \\approx C \\Delta x^2\n$$\nTaking the logarithm, we expect a linear relationship: $\\log(e) \\approx 2 \\log(\\Delta x) + \\log(C)$. The slope of the line fit to $\\log(e)$ vs. $\\log(\\Delta x)$ data should yield the observed order of convergence, $p \\approx 2$. The implementation will calculate this slope using `numpy.polyfit` on the errors computed for $M \\in \\{20, 40, 80, 160\\}$. The error $e(\\Delta x)$ is computed at the final time $t_{\\mathrm{final}}$ using the L2-norm definition provided.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import solve_banded\n\ndef solve_diffusion_case(D, L, T, c_ref, a):\n    \"\"\"\n    Solves the 1D diffusion equation for a given set of parameters and computes\n    the observed order of convergence.\n    \"\"\"\n    M_values = [20, 40, 80, 160]\n    beta = 2.0\n    \n    log_dx_list = []\n    log_err_list = []\n    \n    for M in M_values:\n        # 1. Grid and time step setup\n        dx = L / M\n        dt = beta * dx**2 / D\n        \n        # Determine number of time steps. Ensure Nt  0.\n        if dt  0:\n            Nt = int(round(T / dt))\n        else: # This case should not be reached with the given parameters\n            Nt = 0\n            \n        t_final = Nt * dt\n        \n        # 2. Grid and Initial Condition\n        x = np.linspace(0, L, M + 1)\n        c = c_ref + a * np.cos(np.pi * x / L)\n        \n        # 3. Crank-Nicolson matrices\n        # The choice beta=2.0 leads to a constant alpha = D*dt/(2*dx**2) = 1.0.\n        # The system is A * c_new = B * c_old.\n        \n        # Matrix A (LHS) in banded format for solve_banded.\n        # (l=1, u=1) - shape (3, M+1)\n        A_banded = np.zeros((3, M + 1))\n        # Diagonals for alpha = 1.0\n        A_banded[0, 1:] = -1.0      # Super-diagonal: -alpha\n        A_banded[1, :] = 3.0        # Main-diagonal: 1 + 2*alpha\n        A_banded[2, :-1] = -1.0     # Sub-diagonal: -alpha\n        # Boundary conditions (2nd order Neumann)\n        A_banded[0, 1] = -2.0       # Corresponds to A[0,1] = -2*alpha\n        A_banded[2, M - 1] = -2.0   # Corresponds to A[M,M-1] = -2*alpha\n        \n        # Matrix B (RHS)\n        B = np.zeros((M + 1, M + 1))\n        # Diagonals for alpha = 1.0\n        diag_main = -np.ones(M + 1)   # 1 - 2*alpha\n        diag_upper = np.ones(M)     # +alpha\n        diag_lower = np.ones(M)     # +alpha\n        \n        np.fill_diagonal(B, diag_main)\n        np.fill_diagonal(B[1:, :], diag_lower)\n        np.fill_diagonal(B[:, 1:], diag_upper)\n\n        # Boundary conditions (2nd order Neumann)\n        B[0, 1] = 2.0               # B[0,1] = 2*alpha\n        B[M, M - 1] = 2.0           # B[M,M-1] = 2*alpha\n        \n        # 4. Time stepping\n        for _ in range(Nt):\n            b_rhs = B @ c\n            c = solve_banded((1, 1), A_banded, b_rhs)\n            \n        c_numerical = c\n        \n        # 5. Exact solution at t_final\n        decay_term = np.exp(-D * (np.pi/L)**2 * t_final)\n        c_exact = c_ref + a * np.cos(np.pi * x / L) * decay_term\n        \n        # 6. Error calculation (L2 norm as specified)\n        err_vec = c_numerical - c_exact\n        error_L2 = np.sqrt(dx * np.sum(err_vec**2))\n        \n        # Store for regression\n        if error_L2  0: # Avoid log(0)\n            log_dx_list.append(np.log(dx))\n            log_err_list.append(np.log(error_L2))\n        \n    # 7. Linear regression to find order of convergence p\n    # log(error) = p * log(dx) + const\n    if len(log_dx_list)  1:\n        p, _ = np.polyfit(log_dx_list, log_err_list, 1)\n    else: # Should not happen with M_values sequence\n        p = np.nan\n\n    return p\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A (happy path)\n        (1.0e-10, 100e-6, 10.0, 1000.0, 100.0),\n        # Case B (rapid diffusion)\n        (5.0e-10, 50e-6, 2.0, 1200.0, 50.0),\n        # Case C (slow diffusion, longer horizon)\n        (1.0e-11, 200e-6, 50.0, 1000.0, 200.0),\n        # Case D (small domain, stiff)\n        (2.0e-9, 20e-6, 0.02, 1000.0, 150.0),\n    ]\n\n    results = []\n    for case in test_cases:\n        p = solve_diffusion_case(*case)\n        results.append(p)\n\n    # Final print statement in the exact required format.\n    # Format each result rounded to three decimal places.\n    print(f\"[{','.join(f'{r:.3f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "After verifying your ability to solve the diffusion partial differential equation, the next step is to use this tool to interpret experimental data. This exercise guides you through a classic inverse problem: estimating the solid-phase diffusion coefficient, $D_s$, from a transient voltage response. By building a numerical solver for spherical diffusion and coupling it with an optimization routine, you will learn how to extract key material properties that govern battery performance. ",
            "id": "4242979",
            "problem": "You are tasked with estimating solid-phase diffusion coefficients in the Doyle-Fuller-Newman (DFN) model context for lithium-ion cells by solving and inverting the spherical solid diffusion equation for an electrode particle. The estimation should be carried out by fitting transient voltage data generated under a small galvanostatic step, where the voltage response is dominated by solid diffusion. The derivation and computation must begin from first principles of mass conservation and Fick's laws of diffusion, without relying on pre-specified shortcut formulas.\n\nConsider a single spherical active material particle of radius $R$ undergoing lithium intercalation. The solid-phase concentration $c(r,t)$ is governed by Fick's second law in spherical coordinates, derived from mass conservation and the constitutive flux law. The governing balance for the local concentration is the partial differential equation\n$$\n\\frac{\\partial c}{\\partial t} = D \\left( \\frac{\\partial^2 c}{\\partial r^2} + \\frac{2}{r} \\frac{\\partial c}{\\partial r} \\right),\n$$\nwhere $D$ is the solid diffusion coefficient to be estimated. The initial condition is a uniform concentration\n$$\nc(r,0) = c_0,\n$$\nand the boundary conditions are symmetry at the center\n$$\n\\left. \\frac{\\partial c}{\\partial r} \\right|_{r=0} = 0,\n$$\nand a specified molar flux $J$ at the surface (inward insertion taken as positive) linked to intercalation by mass conservation,\n$$\n- D \\left. \\frac{\\partial c}{\\partial r} \\right|_{r=R} = J.\n$$\n\nAssume the terminal voltage is dominated by the open-circuit potential variation with surface concentration and linearize it around the initial state as\n$$\nU(t) = U_0 + k \\left( c(R,t) - c_0 \\right),\n$$\nwhere $k$ is the local slope of the open-circuit potential with respect to solid concentration in units of volts times cubic meters per mole, $U_0$ is the initial open-circuit voltage, and $c(R,t)$ is the surface concentration. This approximation is valid under small currents where kinetic and electrolyte contributions to voltage are negligible for the transient times considered.\n\nYour program must:\n- Implement a time-stepping solver for the spherical diffusion equation using a stable implicit discretization in space and time that enforces the symmetry and flux boundary conditions. Use a uniform radial grid. The solver must compute $c(R,t)$ for a given $D$, $R$, $J$, $c_0$, final time $T$, and time step $\\Delta t$.\n- Generate synthetic voltage time-series data $U_{\\text{meas}}(t)$ from the model using a known \"true\" diffusion coefficient $D_{\\text{true}}$ and add small, zero-mean Gaussian noise of a specified standard deviation.\n- Formulate and solve the inverse problem to estimate $D$ by minimizing the sum of squared differences between the measured and model-predicted voltages over the time grid,\n$$\n\\min_{D_{\\min} \\le D \\le D_{\\max}} \\sum_{n=1}^{N_t} \\left( U_{\\text{model}}(t_n; D) - U_{\\text{meas}}(t_n) \\right)^2,\n$$\nwhere $N_t$ is the number of time points, and $D_{\\min}$ and $D_{\\max}$ are physically plausible bounds on $D$. Use a robust bounded scalar minimization.\n\nAll physical quantities and constants must be used in International System of Units (SI). Express the final estimated diffusion coefficients in meters squared per second (m^2/s) as floating-point numbers.\n\nImplement the solver under the following discrete approximation requirements:\n- Use a backward Euler time discretization for stability.\n- Use a second-order finite-difference spatial discretization for the spherical Laplacian on a uniform grid with nodes $r_i = i \\Delta r$ for $i = 0, 1, \\dots, N$, where $N$ is the number of radial intervals. Enforce the center symmetry condition using an appropriate discrete approximation and treat the surface flux boundary condition by introducing a ghost point to convert the flux into a source term in the surface node equation.\n- Ensure numerical stability and accuracy sufficient to resolve the transient responses for the provided parameter sets.\n\nTest Suite:\nRun your program for the following three parameter sets. In each case, generate synthetic data using the specified $D_{\\text{true}}$, estimate $D$, and return the estimated value. The final output must be a single line containing the estimated $D$ values for the three cases in the specified format.\n\nCase $1$ (general case):\n- Particle radius $R = 5 \\times 10^{-6}$ meters.\n- True solid diffusion coefficient $D_{\\text{true}} = 2 \\times 10^{-13}$ meters squared per second.\n- Constant molar flux at surface $J = 1 \\times 10^{-6}$ moles per square meter per second.\n- Initial concentration $c_0 = 20000$ moles per cubic meter.\n- Open-circuit voltage parameters: $U_0 = 3.7$ volts, $k = -1 \\times 10^{-4}$ volts times cubic meters per mole.\n- Final time $T = 100$ seconds and time step $\\Delta t = 0.2$ seconds.\n- Number of radial intervals $N = 30$ (i.e., $31$ nodes).\n- Additive Gaussian voltage noise standard deviation $\\sigma = 5 \\times 10^{-4}$ volts.\n\nCase $2$ (slow diffusion, larger particle):\n- Particle radius $R = 1.0 \\times 10^{-5}$ meters.\n- True solid diffusion coefficient $D_{\\text{true}} = 1 \\times 10^{-14}$ meters squared per second.\n- Constant molar flux at surface $J = 5 \\times 10^{-7}$ moles per square meter per second.\n- Initial concentration $c_0 = 15000$ moles per cubic meter.\n- Open-circuit voltage parameters: $U_0 = 3.8$ volts, $k = -8 \\times 10^{-5}$ volts times cubic meters per mole.\n- Final time $T = 300$ seconds and time step $\\Delta t = 0.5$ seconds.\n- Number of radial intervals $N = 40$.\n- Additive Gaussian voltage noise standard deviation $\\sigma = 1 \\times 10^{-3}$ volts.\n\nCase $3$ (fast diffusion, smaller particle):\n- Particle radius $R = 2 \\times 10^{-6}$ meters.\n- True solid diffusion coefficient $D_{\\text{true}} = 5 \\times 10^{-11}$ meters squared per second.\n- Constant molar flux at surface $J = 2 \\times 10^{-6}$ moles per square meter per second.\n- Initial concentration $c_0 = 22000$ moles per cubic meter.\n- Open-circuit voltage parameters: $U_0 = 3.6$ volts, $k = -1.2 \\times 10^{-4}$ volts times cubic meters per mole.\n- Final time $T = 10$ seconds and time step $\\Delta t = 0.02$ seconds.\n- Number of radial intervals $N = 25$.\n- Additive Gaussian voltage noise standard deviation $\\sigma = 2 \\times 10^{-4}$ volts.\n\nBounds for the diffusion coefficient in the inverse problem for all cases must be $D_{\\min} = 1 \\times 10^{-15}$ meters squared per second and $D_{\\max} = 1 \\times 10^{-9}$ meters squared per second.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example, $[d_1,d_2,d_3]$, where $d_i$ are the estimated diffusion coefficients for Case $i$ expressed in meters squared per second (m^2/s) as floating-point numbers.",
            "solution": "The problem requires the estimation of the solid-phase diffusion coefficient, $D$, for a spherical electrode particle, a fundamental problem in the modeling of lithium-ion batteries using the Doyle-Fuller-Newman (DFN) framework. The approach involves two main parts: first, developing a numerical solver for the governing partial differential equation (PDE) of diffusion (the forward problem), and second, using this solver within an optimization routine to fit model predictions to synthetic, noisy voltage data (the inverse problem).\n\n### I. The Forward Problem: Solving the Spherical Diffusion Equation\n\nThe concentration of lithium, $c(r,t)$, within a spherical particle of radius $R$ is governed by Fick's second law in spherical coordinates:\n$$\n\\frac{\\partial c}{\\partial t} = \\frac{1}{r^2} \\frac{\\partial}{\\partial r} \\left( D r^2 \\frac{\\partial c}{\\partial r} \\right) = D \\left( \\frac{\\partial^2 c}{\\partial r^2} + \\frac{2}{r} \\frac{\\partial c}{\\partial r} \\right) \\quad \\text{for } 0  r  R, t  0\n$$\nwhere $D$ is the constant solid diffusion coefficient.\n\nThe initial and boundary conditions are:\n1.  **Initial Condition**: A uniform concentration $c_0$ at $t=0$.\n    $$ c(r,0) = c_0 $$\n2.  **Center Symmetry**: No flux at the center of the particle, due to symmetry.\n    $$ \\left. \\frac{\\partial c}{\\partial r} \\right|_{r=0} = 0 $$\n3.  **Surface Flux**: A constant molar flux $J$ at the surface, representing lithium intercalation/deintercalation.\n    $$ -D \\left. \\frac{\\partial c}{\\partial r} \\right|_{r=R} = J $$\n\nTo solve this PDE numerically, we employ the finite difference method. We discretize the spatial domain $r \\in [0, R]$ into $N$ intervals of width $\\Delta r = R/N$, with nodes $r_i = i \\Delta r$ for $i=0, 1, \\dots, N$. The time domain is discretized with a constant step $\\Delta t$, with time points $t_k = k \\Delta t$. Let $c_i^k \\approx c(r_i, t_k)$.\n\nWe use the backward Euler method for the time derivative, which is unconditionally stable:\n$$\n\\frac{\\partial c}{\\partial t} \\approx \\frac{c_i^{k+1} - c_i^k}{\\Delta t}\n$$\n\nFor spatial derivatives, we use second-order central differences:\n$$\n\\frac{\\partial c}{\\partial r} \\bigg|_{r_i} \\approx \\frac{c_{i+1}^{k+1} - c_{i-1}^{k+1}}{2 \\Delta r}\n$$\n$$\n\\frac{\\partial^2 c}{\\partial r^2} \\bigg|_{r_i} \\approx \\frac{c_{i+1}^{k+1} - 2c_i^{k+1} + c_{i-1}^{k+1}}{(\\Delta r)^2}\n$$\n\n#### Discretized Equations\n\n**For an interior node ($1 \\le i \\le N-1$):**\nSubstituting the finite difference approximations into the PDE yields:\n$$\n\\frac{c_i^{k+1} - c_i^k}{\\Delta t} = D \\left( \\frac{c_{i+1}^{k+1} - 2c_i^{k+1} + c_{i-1}^{k+1}}{(\\Delta r)^2} + \\frac{2}{i \\Delta r} \\frac{c_{i+1}^{k+1} - c_{i-1}^{k+1}}{2 \\Delta r} \\right)\n$$\nLetting $\\alpha = D \\Delta t / (\\Delta r)^2$, we can rearrange this into a linear equation relating the unknown concentrations at step $k+1$ to the known concentrations at step $k$:\n$$\n-\\alpha \\left(1 - \\frac{1}{i}\\right) c_{i-1}^{k+1} + (1+2\\alpha) c_i^{k+1} - \\alpha \\left(1 + \\frac{1}{i}\\right) c_{i+1}^{k+1} = c_i^k\n$$\n\n**For the center node ($r_0=0$, $i=0$):**\nThe term $2/r$ creates a singularity. We use L'Hôpital's rule to show that as $r \\to 0$, the spherical Laplacian simplifies to $3D \\frac{\\partial^2 c}{\\partial r^2}$. The symmetry condition implies $c_{-1}^{k+1} = c_{1}^{k+1}$. The discretized equation at the center is:\n$$\n\\frac{c_0^{k+1} - c_0^k}{\\Delta t} = 3D \\frac{c_1^{k+1} - 2c_0^{k+1} + c_{-1}^{k+1}}{(\\Delta r)^2} = 6D \\frac{c_1^{k+1} - c_0^{k+1}}{(\\Delta r)^2}\n$$\nRearranging gives:\n$$\n(1+6\\alpha) c_0^{k+1} - 6\\alpha c_1^{k+1} = c_0^k\n$$\n\n**For the surface node ($r_N=R$, $i=N$):**\nTo maintain second-order accuracy, we use a ghost point at $r_{N+1} = R + \\Delta r$. The flux boundary condition is discretized using a central difference at $r_N=R$:\n$$\n-D \\frac{c_{N+1}^{k+1} - c_{N-1}^{k+1}}{2 \\Delta r} = J  \\implies c_{N+1}^{k+1} = c_{N-1}^{k+1} - \\frac{2J\\Delta r}{D}\n$$\nSubstituting this into the discretized PDE at node $i=N$:\n$$\n\\frac{c_N^{k+1} - c_N^k}{\\Delta t} = D \\left( \\frac{c_{N+1}^{k+1} - 2c_N^{k+1} + c_{N-1}^{k+1}}{(\\Delta r)^2} + \\frac{2}{R} \\frac{c_{N+1}^{k+1} - c_{N-1}^{k+1}}{2 \\Delta r} \\right)\n$$\nUsing the flux condition, the second term on the RHS simplifies: $D(2/R)(-J/D) = -2J/R$. Substituting the ghost point into the first term on the RHS and combining yields:\n$$\n\\frac{c_N^{k+1} - c_N^k}{\\Delta t} = D \\frac{2c_{N-1}^{k+1} - 2c_N^{k+1}}{(\\Delta r)^2} - \\frac{2J}{\\Delta r} - \\frac{2J}{R}\n$$\nRearranging and using $R=N\\Delta r$ gives:\n$$\n-2\\alpha c_{N-1}^{k+1} + (1+2\\alpha) c_N^{k+1} = c_N^k - \\frac{2J\\Delta t}{\\Delta r} \\left(1 + \\frac{1}{N}\\right)\n$$\n\nThe set of $N+1$ linear equations for $c_i^{k+1}$ ($i=0, \\dots, N$) forms a tridiagonal matrix system $\\mathbf{M} \\mathbf{c}^{k+1} = \\mathbf{d}^k$, which can be solved efficiently at each time step. The matrix $\\mathbf{M}$ is constant in time, so it needs to be assembled only once. We use `scipy.linalg.solve_banded` for this purpose.\n\n### II. The Inverse Problem: Parameter Estimation\n\nThe goal is to estimate $D$. We first generate synthetic \"measured\" voltage data $U_{\\text{meas}}(t)$ using the forward model with a known true diffusion coefficient, $D_{\\text{true}}$, and add Gaussian noise:\n$$\nU_{\\text{meas}}(t_n) = U_{\\text{true}}(t_n) + \\mathcal{N}(0, \\sigma^2)\n$$\nwhere $U_{\\text{true}}(t_n) = U_0 + k(c(R, t_n; D_{\\text{true}}) - c_0)$, and $\\mathcal{N}(0, \\sigma^2)$ is a normally distributed random variable with mean $0$ and standard deviation $\\sigma$.\n\nThe estimation of $D$ is formulated as a least-squares minimization problem. We seek the value of $D$ within a plausible range $[D_{\\min}, D_{\\max}]$ that minimizes the sum of squared differences between the model-predicted voltage and the synthetic data:\n$$\n\\min_{D_{\\min} \\le D \\le D_{\\max}} \\mathcal{L}(D) = \\sum_{n=1}^{N_t} \\left( U_{\\text{model}}(t_n; D) - U_{\\text{meas}}(t_n) \\right)^2\n$$\nwhere $U_{\\text{model}}(t_n; D) = U_0 + k(c(R, t_n; D) - c_0)$ is the voltage predicted by the forward model for a trial coefficient $D$. This is a scalar-bounded optimization problem, which we solve using `scipy.optimize.minimize_scalar` with the 'bounded' method.\n\n### III. Implementation Details\n\nThe implementation consists of two main functions:\n1.  `solve_pde`: This function implements the forward model. It takes physical parameters including a trial $D$ and numerical parameters ($T$, $\\Delta t$, $N$) as input. It assembles the tridiagonal system matrix $\\mathbf{M}$ and iteratively solves for the concentration profile over time, returning the surface concentration time series $c(R,t)$.\n2.  `solve`: This main function iterates through the three test cases provided. For each case, it:\n    a. Generates the synthetic noisy voltage data $U_{\\text{meas}}(t)$ using `solve_pde` with $D_{\\text{true}}$. A fixed random seed is used for reproducibility.\n    b. Defines an objective function that takes a trial $D$, calls `solve_pde` to get the model-predicted voltage, and returns the sum of squared errors against $U_{\\text{meas}}(t)$.\n    c. Calls `scipy.optimize.minimize_scalar` to find the optimal $D$ that minimizes the objective function.\n    d. Collects the estimated $D$ values and formats them for the final output.\n\nThe choice of numerical parameters ($N$, $\\Delta t$) for each case ensures numerical stability and sufficient resolution of the diffusion dynamics across different timescales.",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize_scalar\nfrom scipy.linalg import solve_banded\n\ndef solve_pde(D, R, J, c0, T, dt, N):\n    \"\"\"\n    Solves the spherical diffusion PDE using an implicit finite difference method.\n\n    Args:\n        D (float): Solid diffusion coefficient (m^2/s).\n        R (float): Particle radius (m).\n        J (float): Molar flux at the surface (mol/m^2/s).\n        c0 (float): Initial uniform concentration (mol/m^3).\n        T (float): Final time (s).\n        dt (float): Time step (s).\n        N (int): Number of radial intervals.\n\n    Returns:\n        tuple: A tuple containing:\n            - time_points (np.ndarray): Array of time points.\n            - c_surface (np.ndarray): Array of surface concentrations over time.\n    \"\"\"\n    dr = R / N\n    alpha = D * dt / (dr**2)\n    num_nodes = N + 1\n    \n    # Set up the tridiagonal matrix M in banded form for solve_banded.\n    # The matrix ab has shape (3, num_nodes) for kl=1, ku=1.\n    # ab[0,:] = super-diagonal (A[i, i+1])\n    # ab[1,:] = main diagonal (A[i, i])\n    # ab[2,:] = sub-diagonal (A[i, i-1])\n    ab = np.zeros((3, num_nodes))\n    \n    # Main diagonal\n    ab[1, 0] = 1.0 + 6.0 * alpha\n    ab[1, 1:] = 1.0 + 2.0 * alpha\n    \n    # Upper diagonal\n    ab[0, 1] = -6.0 * alpha\n    i_upper = np.arange(1, N)\n    ab[0, i_upper + 1] = -alpha * (1.0 + 1.0 / i_upper)\n    \n    # Lower diagonal\n    i_lower = np.arange(1, N)\n    # The j-th element of the i-th sub-diagonal is ab[i+ku, j]\n    # For sub-diagonal 1 (i=1), A[j+1, j] is ab[1+1, j].\n    # solve_banded expects ab[ku + i - j, j] = A[i,j].\n    # Lower diag: j = i-1 = ab[1 + i - (i-1), i-1] = ab[2, i-1] = A[i, i-1]\n    ab[2, i_lower - 1] = -alpha * (1.0 - 1.0 / i_lower)\n    # Surface node term A[N, N-1]\n    ab[2, N-1] = -2.0 * alpha\n\n    # Constant part of the RHS from the flux boundary condition\n    b_const = np.zeros(num_nodes)\n    if N  0:\n        b_const[-1] = - (2.0 * J * dt / dr) * (1.0 + 1.0 / N)\n\n    # Time stepping\n    time_points = np.arange(0, T + dt, dt)\n    c = np.full(num_nodes, c0)\n    c_surface = np.zeros(len(time_points))\n    c_surface[0] = c0\n\n    for k in range(1, len(time_points)):\n        rhs = c + b_const\n        c = solve_banded((1, 1), ab, rhs, check_finite=False)\n        c_surface[k] = c[-1]\n    \n    return time_points, c_surface\n\ndef solve():\n    \"\"\"\n    Main function to run test cases for estimating the diffusion coefficient.\n    \"\"\"\n    # Use a fixed random seed for reproducible results\n    np.random.seed(0)\n\n    # Common parameters for optimization\n    D_min = 1e-15\n    D_max = 1e-9\n\n    test_cases = [\n        # Case 1 (general case)\n        {\n            \"R\": 5e-6, \"D_true\": 2e-13, \"J\": 1e-6, \"c0\": 20000,\n            \"U0\": 3.7, \"k\": -1e-4, \"T\": 100, \"dt\": 0.2, \"N\": 30,\n            \"sigma\": 5e-4\n        },\n        # Case 2 (slow diffusion, larger particle)\n        {\n            \"R\": 1.0e-5, \"D_true\": 1e-14, \"J\": 5e-7, \"c0\": 15000,\n            \"U0\": 3.8, \"k\": -8e-5, \"T\": 300, \"dt\": 0.5, \"N\": 40,\n            \"sigma\": 1e-3\n        },\n        # Case 3 (fast diffusion, smaller particle)\n        {\n            \"R\": 2e-6, \"D_true\": 5e-11, \"J\": 2e-6, \"c0\": 22000,\n            \"U0\": 3.6, \"k\": -1.2e-4, \"T\": 10, \"dt\": 0.02, \"N\": 25,\n            \"sigma\": 2e-4\n        }\n    ]\n\n    estimated_Ds = []\n\n    for params in test_cases:\n        # 1. Generate synthetic \"measured\" data\n        time_points, c_surf_true = solve_pde(\n            params[\"D_true\"], params[\"R\"], params[\"J\"], params[\"c0\"], \n            params[\"T\"], params[\"dt\"], params[\"N\"]\n        )\n        U_true = params[\"U0\"] + params[\"k\"] * (c_surf_true - params[\"c0\"])\n        noise = np.random.normal(0, params[\"sigma\"], len(U_true))\n        U_meas = U_true + noise\n\n        # 2. Define the objective function for minimization\n        def objective_func(D_trial):\n            _, c_surf_model = solve_pde(\n                D_trial, params[\"R\"], params[\"J\"], params[\"c0\"], \n                params[\"T\"], params[\"dt\"], params[\"N\"]\n            )\n            U_model = params[\"U0\"] + params[\"k\"] * (c_surf_model - params[\"c0\"])\n            return np.sum((U_model - U_meas)**2)\n\n        # 3. Perform bounded scalar minimization\n        result = minimize_scalar(\n            objective_func,\n            bounds=(D_min, D_max),\n            method='bounded'\n        )\n        estimated_Ds.append(result.x)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(f'{d:.6e}' for d in estimated_Ds)}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "Alongside mass transport, interfacial kinetics are a critical pillar of the Doyle-Fuller-Newman model. This practice focuses on determining the exchange current density, $j_0$, which governs the rate of lithium intercalation reactions at the electrode-electrolyte interface. Using synthetic cyclic voltammetry (CV) data, you will isolate the kinetic signature from capacitive effects and fit it to the Butler-Volmer equation, a fundamental technique in electrochemical parameterization. ",
            "id": "4242987",
            "problem": "You are tasked with calibrating the exchange current density parameter in the Doyle-Fuller-Newman model for lithium-ion cells from cyclic voltammetry (CV) data. The exchange current density plays a central role in the interfacial kinetics modeled by the Butler-Volmer equation. In the small-overpotential region typical of CV around equilibrium, the interface current is primarily governed by charge-transfer kinetics and the double-layer capacitance.\n\nStarting point, assumptions, and definitions:\n- The Doyle-Fuller-Newman model describes porous electrode behavior, where the interfacial reaction current density is given by the Butler-Volmer equation. For symmetric anodic and cathodic transfer coefficients with value $0.5$, the interfacial current density reduces to\n$$\nj_{n}(\\eta) = 2 j_{0} \\sinh\\left(\\frac{\\alpha F \\eta}{R T}\\right),\n$$\nwhere $j_{n}$ is the interfacial reaction current density in $\\mathrm{A}/\\mathrm{m}^2$, $j_{0}$ is the exchange current density in $\\mathrm{A}/\\mathrm{m}^2$, $\\eta$ is the interfacial overpotential in $\\mathrm{V}$, $F$ is the Faraday constant in $\\mathrm{C}/\\mathrm{mol}$, $R$ is the universal gas constant in $\\mathrm{J}/(\\mathrm{mol}\\cdot\\mathrm{K})$, $T$ is the absolute temperature in $\\mathrm{K}$, and $\\alpha$ is the charge-transfer coefficient (dimensionless).\n- In cyclic voltammetry, the applied potential $E(t)$ is swept linearly in time with scan rate $v$, so that $\\mathrm{d}E/\\mathrm{d}t = \\pm v$ depending on the scan direction, with $v$ in $\\mathrm{V}/\\mathrm{s}$.\n- The measured current density $i(t)$ is the sum of the faradaic current density $j_{n}(t)$ and the capacitive current density due to the double layer: $i(t) = j_{n}(t) + C_{\\mathrm{dl}} \\, \\mathrm{d}E/\\mathrm{d}t$, where $C_{\\mathrm{dl}}$ is the double-layer capacitance per unit area in $\\mathrm{F}/\\mathrm{m}^2$.\n- The overpotential is defined as $\\eta = E - U(x)$, where $U(x)$ is the equilibrium open-circuit potential for stoichiometry $x$ in the active material (dimensionless), and $E$ is the applied potential in $\\mathrm{V}$.\n- In the small-overpotential CV regime near a reference stoichiometry $x_{\\mathrm{ref}}$ (assumed constant over the small voltage window), we may treat $j_{0}$ as the exchange current density at that reference condition, denoted $j_{0,\\mathrm{ref}}$, with units $\\mathrm{A}/\\mathrm{m}^2$.\n\nYour goal is to recover $j_{0,\\mathrm{ref}}$ from given potential-current data produced under these assumptions. The small-voltage window ensures that solid stoichiometry remains approximately constant and that mass-transport limitations are negligible.\n\nUse the following open-circuit potential model:\n$$\nU(x) = U_{0} + A \\ln\\left(\\frac{x}{1-x}\\right),\n$$\nwhere $U_{0}$ is a constant in $\\mathrm{V}$, and $A$ is a constant in $\\mathrm{V}$. The reference stoichiometry is $x_{\\mathrm{ref}}$, so $E_{\\mathrm{eq}} = U(x_{\\mathrm{ref}})$.\n\nFor each test case, you are provided with the parameters necessary to synthesize the CV data over a discrete set of potentials $\\{E_{i}\\}$, and the CV current density is generated deterministically by\n$$\ni_{\\mathrm{meas}}(E_i) = 2 j_{0,\\mathrm{ref}} \\sinh\\left(\\frac{\\alpha F (E_i - E_{\\mathrm{eq}})}{R T}\\right) + C_{\\mathrm{dl}} \\, v,\n$$\nfor the forward scan with $\\mathrm{d}E/\\mathrm{d}t = +v$. Your task is to write a program that, given the test cases below, reconstructs $j_{0,\\mathrm{ref}}$ by fitting the faradaic component after subtracting the capacitive contribution. You must express the final calibrated $j_{0,\\mathrm{ref}}$ in $\\mathrm{A}/\\mathrm{m}^2$ for each test case, and produce the outputs as floats.\n\nConstants to use in all test cases:\n- $F = 96485$ $\\mathrm{C}/\\mathrm{mol}$,\n- $R = 8.314$ $\\mathrm{J}/(\\mathrm{mol}\\cdot\\mathrm{K})$,\n- $\\alpha = 0.5$.\n\nTest suite:\n- Case 1 (happy path):\n  - $T = 298$ $\\mathrm{K}$,\n  - $v = 5\\times 10^{-3}$ $\\mathrm{V}/\\mathrm{s}$,\n  - $C_{\\mathrm{dl}} = 0.2$ $\\mathrm{F}/\\mathrm{m}^2$,\n  - $U_{0} = 3.6$ $\\mathrm{V}$,\n  - $A = 0.01$ $\\mathrm{V}$,\n  - $x_{\\mathrm{ref}} = 0.5$,\n  - $E_{\\mathrm{eq}} = U(x_{\\mathrm{ref}})$,\n  - $j_{0,\\mathrm{ref}} = 2.0$ $\\mathrm{A}/\\mathrm{m}^2$,\n  - Potential samples: $E_{i} = E_{\\mathrm{eq}} + k \\Delta E$ for $k \\in \\{-3,-2,-1,0,1,2,3\\}$ with $\\Delta E = 10^{-3}$ $\\mathrm{V}$.\n- Case 2 (capacitive-dominant edge case):\n  - $T = 298$ $\\mathrm{K}$,\n  - $v = 5\\times 10^{-2}$ $\\mathrm{V}/\\mathrm{s}$,\n  - $C_{\\mathrm{dl}} = 0.8$ $\\mathrm{F}/\\mathrm{m}^2$,\n  - $U_{0} = 3.7$ $\\mathrm{V}$,\n  - $A = 0.02$ $\\mathrm{V}$,\n  - $x_{\\mathrm{ref}} = 0.5$,\n  - $E_{\\mathrm{eq}} = U(x_{\\mathrm{ref}})$,\n  - $j_{0,\\mathrm{ref}} = 2.0$ $\\mathrm{A}/\\mathrm{m}^2$,\n  - Potential samples: $E_{i} = E_{\\mathrm{eq}} + k \\Delta E$ for $k \\in \\{-3,-2,-1,0,1,2,3\\}$ with $\\Delta E = 10^{-3}$ $\\mathrm{V}$.\n- Case 3 (small-signal window boundary case):\n  - $T = 310$ $\\mathrm{K}$,\n  - $v = 2\\times 10^{-3}$ $\\mathrm{V}/\\mathrm{s}$,\n  - $C_{\\mathrm{dl}} = 0.2$ $\\mathrm{F}/\\mathrm{m}^2$,\n  - $U_{0} = 3.8$ $\\mathrm{V}$,\n  - $A = 0.02$ $\\mathrm{V}$,\n  - $x_{\\mathrm{ref}} = 0.6$,\n  - $E_{\\mathrm{eq}} = U(x_{\\mathrm{ref}})$,\n  - $j_{0,\\mathrm{ref}} = 0.5$ $\\mathrm{A}/\\mathrm{m}^2$,\n  - Potential samples: $E_{i} = E_{\\mathrm{eq}} + k \\Delta E$ for $k \\in \\{-1,0,1\\}$ with $\\Delta E = 10^{-3}$ $\\mathrm{V}$.\n\nProgram requirements:\n- For each test case, compute $E_{\\mathrm{eq}} = U(x_{\\mathrm{ref}})$.\n- Construct the list of potentials $\\{E_{i}\\}$ as specified. Synthesize the measured current density values $\\{i_{\\mathrm{meas}}(E_{i})\\}$ using the equation above and the provided parameters. These represent deterministic CV measurements in the small-overpotential region for the forward scan.\n- Subtract the capacitive offset $C_{\\mathrm{dl}} v$ to isolate the faradaic current density $j_{n}$.\n- Fit $j_{n}(\\eta)$, with $\\eta = E_{i} - E_{\\mathrm{eq}}$, to the Butler-Volmer form $2 j_{0} \\sinh\\left(\\frac{\\alpha F \\eta}{R T}\\right)$ to calibrate $j_{0,\\mathrm{ref}}$ for each test case. Use a principled initial guess based on the small-signal slope near $\\eta = 0$.\n- Express the final calibrated $j_{0,\\mathrm{ref}}$ in $\\mathrm{A}/\\mathrm{m}^2$ as floats.\n\nFinal output format:\nYour program should produce a single line of output containing the calibrated exchange current densities for all three test cases as a comma-separated list enclosed in square brackets, in the order Case 1, Case 2, Case 3, for example: \"[j0_case1,j0_case2,j0_case3]\". Each entry must be in $\\mathrm{A}/\\mathrm{m}^2$.",
            "solution": "The problem requires the calibration of the exchange current density, $j_{0,\\mathrm{ref}}$, a key parameter in the Doyle-Fuller-Newman (DFN) model for lithium-ion cells, using synthetic cyclic voltammetry (CV) data. The process involves three main steps: synthesizing the measurement data based on the provided physical model, isolating the faradaic current component, and fitting this component to the Butler-Volmer equation to extract $j_{0,\\mathrm{ref}}$.\n\nFirst, we establish the physical framework. The total measured current density, $i(t)$, in a CV experiment is the sum of two contributions: the faradaic current from the electrochemical reaction at the electrode-electrolyte interface, $j_{n}(t)$, and the non-faradaic current from charging/discharging the electrical double layer, $i_{\\mathrm{cap}}(t)$. This is expressed as:\n$$\ni(t) = j_{n}(t) + i_{\\mathrm{cap}}(t)\n$$\nThe faradaic component, $j_n$, is described by the Butler-Volmer equation. For symmetric charge-transfer coefficients, $\\alpha = 1-\\alpha = 0.5$, this equation simplifies to:\n$$\nj_{n}(\\eta) = 2 j_{0} \\sinh\\left(\\frac{\\alpha F \\eta}{R T}\\right)\n$$\nHere, $\\eta = E - E_{\\mathrm{eq}}$ is the surface overpotential, $j_{0}$ is the exchange current density, $F$ is the Faraday constant ($96485 \\text{ C/mol}$), $R$ is the universal gas constant ($8.314 \\text{ J/(mol}\\cdot\\text{K)}$), and $T$ is the temperature. The problem assumes a small potential window, so $j_{0}$ can be treated as a constant, $j_{0,\\mathrm{ref}}$.\n\nThe capacitive current, $i_{\\mathrm{cap}}$, is proportional to the rate of change of the potential, $\\mathrm{d}E/\\mathrm{d}t$, and the double-layer capacitance, $C_{\\mathrm{dl}}$:\n$$\ni_{\\mathrm{cap}}(t) = C_{\\mathrm{dl}} \\frac{\\mathrm{d}E}{\\mathrm{d}t}\n$$\nIn a CV experiment with a linear scan rate $v$, we have $\\mathrm{d}E/\\mathrm{d}t = v$ for the forward scan. Thus, the equation for the measured current at a given potential $E_i$ becomes:\n$$\ni_{\\mathrm{meas}}(E_i) = 2 j_{0,\\mathrm{ref}} \\sinh\\left(\\frac{\\alpha F (E_i - E_{\\mathrm{eq}})}{R T}\\right) + C_{\\mathrm{dl}} v\n$$\nThe equilibrium potential, $E_{\\mathrm{eq}}$, is determined by the reference stoichiometry, $x_{\\mathrm{ref}}$, through the given open-circuit potential model:\n$$\nE_{\\mathrm{eq}} = U(x_{\\mathrm{ref}}) = U_{0} + A \\ln\\left(\\frac{x_{\\mathrm{ref}}}{1-x_{\\mathrm{ref}}}\\right)\n$$\n\nThe overall algorithm for each test case is as follows:\n\n1.  **Data Synthesis**:\n    a.  Calculate the equilibrium potential, $E_{\\mathrm{eq}}$, using the provided case-specific parameters $U_0$, $A$, and $x_{\\mathrm{ref}}$.\n    b.  Construct the array of potential samples $\\{E_i\\}$ and the corresponding overpotentials $\\eta_i = E_i - E_{\\mathrm{eq}}$.\n    c.  Synthesize the measured current density values, $\\{i_{\\mathrm{meas}}(E_i)\\}$, using the given equation, the true value of $j_{0,\\mathrm{ref}}$, and the other parameters ($T$, $v$, $C_{\\mathrm{dl}}$).\n\n2.  **Data Processing**:\n    a.  Calculate the constant capacitive current offset, $i_{\\mathrm{cap}} = C_{\\mathrm{dl}} v$.\n    b.  Subtract this offset from the synthesized measured current data to isolate the faradaic component for each potential point: $j_{n,i} = i_{\\mathrm{meas}}(E_i) - i_{\\mathrm{cap}}$. As the data is generated deterministically, this step perfectly recovers the true faradaic current.\n\n3.  **Parameter Fitting**:\n    a.  The task is to find the value of $j_0$ that best fits the relationship $j_{n,i} = 2 j_0 \\sinh\\left(\\frac{\\alpha F \\eta_i}{R T}\\right)$. This is a non-linear least-squares problem. We employ the `scipy.optimize.curve_fit` function for this purpose.\n    b.  An essential part of robust fitting is providing a good initial guess for the parameter. The problem statement specifies using the small-signal slope. For small overpotentials ($|\\eta| \\ll RT/(\\alpha F)$), the Butler-Volmer equation can be linearized, as $\\sinh(z) \\approx z$ for small $z$.\n    $$\n    j_n(\\eta) \\approx 2 j_0 \\left(\\frac{\\alpha F \\eta}{R T}\\right)\n    $$\n    This shows a linear relationship between $j_n$ and $\\eta$ near equilibrium. The slope, or charge-transfer resistance inverse, is $\\frac{\\mathrm{d}j_n}{\\mathrm{d}\\eta}|_{\\eta=0} = \\frac{2 j_0 \\alpha F}{R T}$. We can rearrange this to estimate $j_0$:\n    $$\n    j_{0, \\text{guess}} = \\left(\\frac{\\mathrm{d}j_n}{\\mathrm{d}\\eta}\\right)_{\\eta=0} \\frac{R T}{2 \\alpha F}\n    $$\n    The slope is estimated from the data points closest to $\\eta=0$ using a finite difference, for example, using the points at $\\eta = \\pm \\Delta E$: $\\frac{j_n(\\Delta E) - j_n(-\\Delta E)}{2 \\Delta E}$.\n    c.  With the `x` data as the array of overpotentials $\\{\\eta_i\\}$, `y` data as the isolated faradaic currents $\\{j_{n,i}\\}$, the model function, and the initial guess, `curve_fit` is called to find the optimal value of $j_{0,\\mathrm{ref}}$.\n\nThis procedure is applied to each of the three test cases, and the resulting calibrated $j_{0,\\mathrm{ref}}$ values are collected. Since the input data is synthetically generated from the same model used for fitting and contains no noise, the fitting process is expected to recover the original $j_{0,\\mathrm{ref}}$ values with high precision.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import curve_fit\n\ndef solve():\n    \"\"\"\n    Solves the problem of calibrating the exchange current density (j0_ref)\n    from synthetic cyclic voltammetry (CV) data for three test cases.\n    \"\"\"\n    \n    # Global constants\n    F = 96485.0  # Faraday constant in C/mol\n    R = 8.314   # Universal gas constant in J/(mol*K)\n    ALPHA = 0.5   # Charge-transfer coefficient\n\n    # Test suite defined as a list of dictionaries\n    test_cases = [\n        {\n            \"T\": 298.0,\n            \"v\": 5e-3,\n            \"C_dl\": 0.2,\n            \"U0\": 3.6,\n            \"A\": 0.01,\n            \"x_ref\": 0.5,\n            \"j0_ref_true\": 2.0,\n            \"k_range\": range(-3, 4),\n            \"delta_E\": 1e-3,\n        },\n        {\n            \"T\": 298.0,\n            \"v\": 5e-2,\n            \"C_dl\": 0.8,\n            \"U0\": 3.7,\n            \"A\": 0.02,\n            \"x_ref\": 0.5,\n            \"j0_ref_true\": 2.0,\n            \"k_range\": range(-3, 4),\n            \"delta_E\": 1e-3,\n        },\n        {\n            \"T\": 310.0,\n            \"v\": 2e-3,\n            \"C_dl\": 0.2,\n            \"U0\": 3.8,\n            \"A\": 0.02,\n            \"x_ref\": 0.6,\n            \"j0_ref_true\": 0.5,\n            \"k_range\": range(-1, 2),\n            \"delta_E\": 1e-3,\n        },\n    ]\n\n    results = []\n\n    for case in test_cases:\n        # Unpack parameters for the current case\n        T = case[\"T\"]\n        v = case[\"v\"]\n        C_dl = case[\"C_dl\"]\n        U0 = case[\"U0\"]\n        A = case[\"A\"]\n        x_ref = case[\"x_ref\"]\n        j0_ref_true = case[\"j0_ref_true\"]\n        k_range = case[\"k_range\"]\n        delta_E = case[\"delta_E\"]\n\n        # 1. Data Synthesis\n        # Calculate equilibrium potential E_eq\n        # Note: np.log can handle x_ref=0.5 where arg is 1, but for x_ref near 0 or 1,\n        # we check for domain validity, though not required by the test cases.\n        if x_ref  0 and x_ref  1:\n            E_eq = U0 + A * np.log(x_ref / (1.0 - x_ref))\n        else: # Handles the x_ref = 0.5 case more efficiently\n            E_eq = U0\n\n        # Generate potential and overpotential arrays\n        k_values = np.array(list(k_range))\n        eta_values = k_values * delta_E\n        E_values = E_eq + eta_values\n\n        # Synthesize measured current density i_meas\n        exponent_arg = (ALPHA * F * eta_values) / (R * T)\n        j_n_true = 2.0 * j0_ref_true * np.sinh(exponent_arg)\n        i_cap = C_dl * v\n        i_meas = j_n_true + i_cap\n\n        # 2. Data Processing\n        # Isolate the faradaic current component for fitting\n        j_n_for_fitting = i_meas - i_cap\n\n        # 3. Parameter Fitting\n        # Define the model function for curve_fit. It captures T from the outer scope.\n        def butler_volmer_model(eta, j0):\n            return 2.0 * j0 * np.sinh((ALPHA * F * eta) / (R * T))\n\n        # Calculate a principled initial guess for j0\n        # Find indices for eta = +/- delta_E for slope calculation\n        eta_plus_idx = np.where(np.isclose(eta_values, delta_E))[0]\n        eta_minus_idx = np.where(np.isclose(eta_values, -delta_E))[0]\n\n        # Use linearization for small eta to estimate j0\n        if len(eta_plus_idx)  0 and len(eta_minus_idx)  0:\n            jn_plus = j_n_for_fitting[eta_plus_idx[0]]\n            jn_minus = j_n_for_fitting[eta_minus_idx[0]]\n            slope_at_zero = (jn_plus - jn_minus) / (2 * delta_E)\n            j0_guess = slope_at_zero * (R * T) / (2 * ALPHA * F)\n        else:\n            # Fallback guess if points are not available (not the case here)\n            j0_guess = 1.0\n        \n        # Perform non-linear least squares fitting\n        # We only fit j0, which is the first parameter.\n        popt, _ = curve_fit(\n            butler_volmer_model, \n            eta_values, \n            j_n_for_fitting, \n            p0=[j0_guess]\n        )\n        \n        calibrated_j0 = popt[0]\n        results.append(calibrated_j0)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}