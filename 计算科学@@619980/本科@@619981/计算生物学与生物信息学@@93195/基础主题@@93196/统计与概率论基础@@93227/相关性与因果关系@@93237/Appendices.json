{"hands_on_practices": [{"introduction": "我们对因果关系的探索始于一个经典的统计学警示故事：辛普森悖论。这个练习将通过一个假设的临床试验数据，让你亲手计算并体验这个悖论。通过这个过程，你将直观地理解，当一个未被观察到的变量（即混杂变量）存在时，简单地合并数据进行分析会如何得出与分组分析时完全相反的、具有误导性的结论 [@problem_id:2383010]。", "problem": "一位计算生物学家正在审核一个经过整理的临床数据集的结果，该数据集旨在评估一种新的抗菌药物。患者根据疾病严重程度被分为两个层次：轻度和重度。对于每个层次和治疗组（药物组对对照组），报告了康复患者人数和总患者人数如下：轻度层次，药物组：$20$人中有$18$人康复；轻度层次，对照组：$200$人中有$160$人康复；重度层次，药物组：$800$人中有$240$人康复；重度层次，对照组：$20$人中有$4$人康复。定义任何组的康复率为该组康复人数与总患者人数之比。定义一个治疗组的合并康复率为两个层次的总康复人数与两个层次的总患者人数之比。定义合并风险差为药物组的合并康复率减去对照组的合并康复率。当忽略层次标签并将各治疗组内的所有患者合并时，计算合并风险差。请用小数表示你的答案，并四舍五入到四位有效数字。", "solution": "所述问题是有效的。它具有科学依据，问题提出得当，并包含得出唯一解所需的所有信息。我们将着手进行分析。\n\n目标是计算药物组和对照组之间的合并风险差，这需要将指定层次的数据进行汇总。我们获得了两个层次（轻度和重度）的数据，分别对应药物组和对照组。\n\n让我们系统地定义变量。设 $R$ 表示康复患者人数，$N$ 表示总患者人数。我们使用下标来表示治疗组（D代表药物组，C代表对照组）和层次（m代表轻度，s代表重度）。\n\n给定的数据是：\n-   轻度层次，药物组：$R_{D,m} = 18$， $N_{D,m} = 20$。\n-   轻度层次，对照组：$R_{C,m} = 160$， $N_{C,m} = 200$。\n-   重度层次，药物组：$R_{D,s} = 240$， $N_{D,s} = 800$。\n-   重度层次，对照组：$R_{C,s} = 4$， $N_{C,s} = 20$。\n\n任何特定组内的康复率 $r$ 定义为康复人数与总患者人数之比，$r = \\frac{R}{N}$。尽管问题要求的是合并结果，但我们首先作为初步分析，计算每个层次内的康复率。\n\n对于轻度层次：\n-   药物组康复率：$r_{D,m} = \\frac{R_{D,m}}{N_{D,m}} = \\frac{18}{20} = 0.9$。\n-   对照组康复率：$r_{C,m} = \\frac{R_{C,m}}{N_{C,m}} = \\frac{160}{200} = 0.8$。\n轻度层次的风险差为 $r_{D,m} - r_{C,m} = 0.9 - 0.8 = 0.1$。\n\n对于重度层次：\n-   药物组康复率：$r_{D,s} = \\frac{R_{D,s}}{N_{D,s}} = \\frac{240}{800} = 0.3$。\n-   对照组康复率：$r_{C,s} = \\frac{R_{C,s}}{N_{C,s}} = \\frac{4}{20} = 0.2$。\n重度层次的风险差为 $r_{D,s} - r_{C,s} = 0.3 - 0.2 = 0.1$。\n\n可以观察到，在两个层次中，药物组的康复率都高出 $0.1$ 或 $10$ 个百分点。一个简单的解释是药物是有益的。\n\n现在，我们进行主要任务：计算合并风险差。这涉及到忽略层次标签，并汇总每个治疗组的数据。\n\n首先，计算合并药物组的总康复人数和总患者人数。\n-   药物组的总康复人数：$R_D = R_{D,m} + R_{D,s} = 18 + 240 = 258$。\n-   药物组的总患者人数：$N_D = N_{D,m} + N_{D,s} = 20 + 800 = 820$。\n\n因此，药物组的合并康复率 $RR_D$ 为：\n$$RR_D = \\frac{R_D}{N_D} = \\frac{258}{820}$$\n\n接下来，计算合并对照组的总康复人数和总患者人数。\n-   对照组的总康复人数：$R_C = R_{C,m} + R_{C,s} = 160 + 4 = 164$。\n-   对照组的总患者人数：$N_C = N_{C,m} + N_{C,s} = 200 + 20 = 220$。\n\n对照组的合并康复率 $RR_C$ 为：\n$$RR_C = \\frac{R_C}{N_C} = \\frac{164}{220}$$\n\n合并风险差 $\\Delta_{RD}$ 定义为药物组的合并康复率与对照组的合并康复率之差。\n$$\\Delta_{RD} = RR_D - RR_C = \\frac{258}{820} - \\frac{164}{220}$$\n\n现在我们对该表达式进行数值计算。\n$$RR_D = \\frac{258}{820} \\approx 0.3146341...$$\n$$RR_C = \\frac{164}{220} = \\frac{41}{55} \\approx 0.7454545...$$\n\n将这些值代入合并风险差的表达式中：\n$$\\Delta_{RD} \\approx 0.3146341 - 0.7454545 = -0.4308204...$$\n\n问题要求答案四舍五入到四位有效数字。第一位有效数字是 $4$。我们必须保留接下来的三位数字：$3$、$0$ 和 $8$。第四位有效数字（$8$）后面的数字是 $2$。由于 $2  5$，我们不进位。\n因此，四舍五入到四位有效数字的合并风险差为 $-0.4308$。\n\n这个结果展示了一个辛普森悖论（Simpson's paradox）的经典案例。混淆变量是疾病的严重程度。在每个层次内部分析时，该药物似乎是有效的，但当数据合并后，结论却反转了，表明该药物是有害的。这是因为治疗分配严重不均衡：大多数使用药物的患者属于重度类别（无论治疗如何，康复率都较低），而大多数对照组的患者属于轻度类别（无论治疗如何，康复率都较高）。不加批判地合并数据会导致错误的结论。任何严谨的分析都必须考虑到这类混淆因素。", "answer": "$$\n\\boxed{-0.4308}\n$$", "id": "2383010"}, {"introduction": "为了系统性地解决辛普森悖论这类问题，我们需要一个能严格区分“观察到”（关联）和“干预后”（因果）的数学框架。本练习利用贝叶斯网络和 Judea Pearl 的“do算子”，让你在一个简化的基因-行为-疾病模型中，精确计算关联效应 $P(C=1 \\mid S=1)$ 与因果效应 $P(C=1 \\mid do(S=1))$ 之间的差异 [@problem_id:2382934]。这个差异，即混杂偏倚，正是我们在上一个练习中遇到的问题的核心，它量化了由共同原因（基因）引起的相关性。", "problem": "给定一个离散贝叶斯网络，其中有三个二元随机变量，用于模拟人群中遗传和行为对疾病风险的影响：烟碱型乙酰胆碱受体α5亚基基因（CHRNA5）上一个单核苷酸多态性的基因型、吸烟状况以及肺癌结果。设 $G \\in \\{0,1\\}$ 表示 CHRNA5 处风险等位基因的基因型指示符，其中 $G=1$ 表示存在至少一个风险等位基因。设 $S \\in \\{0,1\\}$ 表示吸烟状况，其中 $S=1$ 表示当前为吸烟者。设 $C \\in \\{0,1\\}$ 表示肺癌，其中 $C=1$ 表示患有该疾病。其有向无环图（DAG）结构为 $G \\to S$、$S \\to C$，以及可选的 $G \\to C$。联合分布可分解为 $P(G,S,C) = P(G) P(S \\mid G) P(C \\mid S,G)$。\n\n每个测试用例的参数化由以下概率给出：\n- $P(G=1) = p_g$，\n- $P(S=1 \\mid G=0) = s_0$, $P(S=1 \\mid G=1) = s_1$，\n- $P(C=1 \\mid S=s, G=g) = c_{sg}$ 对于 $(s,g) \\in \\{0,1\\} \\times \\{0,1\\}$。\n\n干预使用 do-算子定义。在干预 $do(S=1)$ 下，变量 $S$被外生地设置为 $1$，这会移除所有指向 $S$ 的箭头，并将 $S$ 的条件分布替换为在 $1$ 处的点质量（point mass），同时保持所有其他条件分布不变。\n\n对于下述每个测试用例，计算以下标量值：\n- 差值 $\\Delta = P(C=1 \\mid S=1) - P(C=1 \\mid do(S=1))$。\n\n您的程序必须根据上述定义和概率法则，从第一性原理出发为每个测试用例计算 $\\Delta$，不使用任何外部数据。将每个 $\\Delta$ 表示为四舍五入到六位小数的十进制数（不要使用百分号）。\n\n测试套件（每个用例由 $(p_g, s_0, s_1, c_{00}, c_{10}, c_{01}, c_{11})$ 指定）：\n1. 用例A（存在对吸烟的遗传效应和对肺癌的直接遗传效应，吸烟导致肺癌）： $(p_g, s_0, s_1, c_{00}, c_{10}, c_{01}, c_{11}) = (0.3, 0.2, 0.6, 0.01, 0.05, 0.02, 0.12)$。\n2. 用例B（存在对吸烟的遗传效应，但不存在对肺癌的直接遗传效应，吸烟导致肺癌）： $(p_g, s_0, s_1, c_{00}, c_{10}, c_{01}, c_{11}) = (0.3, 0.2, 0.6, 0.01, 0.05, 0.01, 0.05)$。\n3. 用例C（存在对吸烟的遗传效应和对肺癌的直接遗传效应，但吸烟对肺癌没有因果效应）： $(p_g, s_0, s_1, c_{00}, c_{10}, c_{01}, c_{11}) = (0.3, 0.2, 0.6, 0.01, 0.01, 0.05, 0.05)$。\n4. 用例D（不存在对吸烟的遗传效应，但存在对肺癌的遗传和吸烟效应）： $(p_g, s_0, s_1, c_{00}, c_{10}, c_{01}, c_{11}) = (0.3, 0.4, 0.4, 0.01, 0.05, 0.02, 0.12)$。\n\n最终输出格式：您的程序应生成单行输出，其中包含按上述测试用例顺序列出的结果，形式为逗号分隔的列表并用方括号括起，例如 $[\\Delta_A,\\Delta_B,\\Delta_C,\\Delta_D]$。", "solution": "问题要求针对给定的贝叶斯网络计算数量 $\\Delta = P(C=1 \\mid S=1) - P(C=1 \\mid do(S=1))$。这个数量表示在给定吸烟条件下的肺癌观测条件概率与在强制吸烟的干预下的肺癌因果概率之间的差异。这个差异正是由基因 $G$ 引入的混杂偏倚，该基因是吸烟 $S$ 和肺癌 $C$ 的一个潜在共同原因。\n\n分析过程分三步进行：首先，推导观测项 $P(C=1 \\mid S=1)$ 的表达式；其次，推导干预项 $P(C=1 \\mid do(S=1))$ 的表达式；第三，将这两项结合起来求出 $\\Delta$，并将其应用于给定的测试用例。\n\n联合概率分布由分解式 $P(G,S,C) = P(G) P(S \\mid G) P(C \\mid S,G)$ 给出。参数定义为 $P(G=1) = p_g$，$P(S=1 \\mid G=0) = s_0$，$P(S=1 \\mid G=1) = s_1$，以及 $P(C=1 \\mid S=s, G=g) = c_{sg}$。\n\n1.  观测项 $P(C=1 \\mid S=1)$ 的推导：\n    根据条件概率的定义，\n    $$ P(C=1 \\mid S=1) = \\frac{P(C=1, S=1)}{P(S=1)} $$\n    分母 $P(S=1)$ 通过使用全概率法则对变量 $G$ 进行边缘化得到：\n    $$ P(S=1) = \\sum_{g \\in \\{0,1\\}} P(S=1, G=g) = \\sum_{g \\in \\{0,1\\}} P(S=1 \\mid G=g) P(G=g) $$\n    $$ P(S=1) = P(S=1 \\mid G=0)P(G=0) + P(S=1 \\mid G=1)P(G=1) $$\n    代入给定参数，其中 $P(G=0) = 1 - p_g$：\n    $$ P(S=1) = s_0 (1 - p_g) + s_1 p_g $$\n    分子 $P(C=1, S=1)$ 同样通过对 $G$ 边缘化得到：\n    $$ P(C=1, S=1) = \\sum_{g \\in \\{0,1\\}} P(C=1, S=1, G=g) $$\n    根据网络结构使用链式法则：\n    $$ P(C=1, S=1) = P(C=1 \\mid S=1, G=0)P(S=1 \\mid G=0)P(G=0) + P(C=1 \\mid S=1, G=1)P(S=1 \\mid G=1)P(G=1) $$\n    代入给定参数：\n    $$ P(C=1, S=1) = c_{10} s_0 (1 - p_g) + c_{11} s_1 p_g $$\n    将分子和分母结合起来，得到观测概率：\n    $$ P(C=1 \\mid S=1) = \\frac{c_{10} s_0 (1 - p_g) + c_{11} s_1 p_g}{s_0 (1 - p_g) + s_1 p_g} $$\n\n2.  干预项 $P(C=1 \\mid do(S=1))$ 的推导：\n    干预 $do(S=1)$ 通过将整个群体的 $S$ 值设置为 $1$ 来修改系统。这对应于在图中移除所有指向节点 $S$ 的入边（在此例中为边 $G \\to S$），并设置 $S=1$。在这个修改后的图中，剩余变量 $G$ 和 $C$ 的联合分布，记为 $P_{do(S=1)}$，变为 $P_{do(S=1)}(G, C) = P(G) P(C \\mid S=1, G)$。\n    所求概率是这个新分布中 $C=1$ 的边缘概率：\n    $$ P(C=1 \\mid do(S=1)) = \\sum_{g \\in \\{0,1\\}} P_{do(S=1)}(C=1, G=g) $$\n    $$ P(C=1 \\mid do(S=1)) = \\sum_{g \\in \\{0,1\\}} P(C=1 \\mid S=1, G=g)P(G=g) $$\n    这是 $S$ 对 $C$ 的因果效应的后门调整公式，其中 $G$ 是混杂变量。\n    代入参数：\n    $$ P(C=1 \\mid do(S=1)) = P(C=1 \\mid S=1, G=0)P(G=0) + P(C=1 \\mid S=1, G=1)P(G=1) $$\n    $$ P(C=1 \\mid do(S=1)) = c_{10}(1 - p_g) + c_{11} p_g $$\n\n3.  $\\Delta$ 的计算：\n    $\\Delta$ 的最终表达式是两个推导项之差：\n    $$ \\Delta = \\frac{c_{10} s_0 (1 - p_g) + c_{11} s_1 p_g}{s_0 (1 - p_g) + s_1 p_g} - \\left( c_{10}(1 - p_g) + c_{11} p_g \\right) $$\n    该表达式可以通过代数运算进行简化。设分母为 $D = s_0 (1 - p_g) + s_1 p_g$。将两项通分到共同分母 $D$ 上并简化分子后，我们得到一个更具洞察力的形式：\n    $$ \\Delta = \\frac{p_g(1-p_g)(s_1 - s_0)(c_{11} - c_{10})}{s_0 (1 - p_g) + s_1 p_g} $$\n    这个简化公式表明，混杂偏倚 $\\Delta$ 非零，当且仅当：\n    a) 该基因具有多态性（$0  p_g  1$）。\n    b) 该基因影响吸烟行为（$s_1 \\neq s_0$），从而创建了路径 $G \\to S$。\n    c) 对于吸烟者，该基因对不同等位基因的肺癌风险影响不同（$c_{11} \\neq c_{10}$），这表明存在 $G \\to C$ 路径或交互作用。这意味着 $G$ 是 $S$ 和 $C$ 的共同原因。\n\n将此公式应用于每个测试用例：\n\n用例A：$(p_g, s_0, s_1, c_{10}, c_{11}) = (0.3, 0.2, 0.6, 0.05, 0.12)$\n$$ \\Delta_A = \\frac{0.3 \\times (1-0.3) \\times (0.6 - 0.2) \\times (0.12 - 0.05)}{(1-0.3) \\times 0.2 + 0.3 \\times 0.6} = \\frac{0.3 \\times 0.7 \\times 0.4 \\times 0.07}{0.7 \\times 0.2 + 0.3 \\times 0.6} = \\frac{0.00588}{0.32} = 0.018375 $$\n\n用例B：$(p_g, s_0, s_1, c_{10}, c_{11}) = (0.3, 0.2, 0.6, 0.05, 0.05)$\n此处，$c_{11} - c_{10} = 0.05 - 0.05 = 0$。分子变为 $0$。\n$$ \\Delta_B = 0 $$\n这是符合预期的。对于 $s=0$ 和 $s=1$，$c_{s0}=c_{s1}$ 的条件表示不存在从 $G$ 到 $C$ 的直接因果路径。因此，$G$ 不是 $S \\to C$ 关系的混杂因素。\n\n用例C：$(p_g, s_0, s_1, c_{10}, c_{11}) = (0.3, 0.2, 0.6, 0.01, 0.05)$\n$$ \\Delta_C = \\frac{0.3 \\times (1-0.3) \\times (0.6 - 0.2) \\times (0.05 - 0.01)}{(1-0.3) \\times 0.2 + 0.3 \\times 0.6} = \\frac{0.3 \\times 0.7 \\times 0.4 \\times 0.04}{0.32} = \\frac{0.00336}{0.32} = 0.0105 $$\n在这种情况下，由于 $G$ 的混杂作用，吸烟与癌症之间存在关联，尽管吸烟本身对癌症没有因果效应（因为 $c_{0g}=c_{1g}$）。\n\n用例D：$(p_g, s_0, s_1, c_{10}, c_{11}) = (0.3, 0.4, 0.4, 0.05, 0.12)$\n此处，$s_1 - s_0 = 0.4 - 0.4 = 0$。分子变为 $0$。\n$$ \\Delta_D = 0 $$\n这也是符合预期的。条件 $s_0 = s_1$ 表示基因 $G$ 对吸烟行为没有影响，切断了 $G \\to S$ 路径。没有这条路径，$G$ 不能成为共同原因，因此也不能成为混杂因素。\n\n结果四舍五入到六位小数后为：$\\Delta_A=0.018375$, $\\Delta_B=0.000000$, $\\Delta_C=0.010500$ 以及 $\\Delta_D=0.000000$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of calculating the difference between associational and\n    causal probabilities in a given Bayesian network.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (p_g, s_0, s_1, c_00, c_10, c_01, c_11)\n    test_cases = [\n        (0.3, 0.2, 0.6, 0.01, 0.05, 0.02, 0.12),  # Case A\n        (0.3, 0.2, 0.6, 0.01, 0.05, 0.01, 0.05),  # Case B\n        (0.3, 0.2, 0.6, 0.01, 0.01, 0.05, 0.05),  # Case C\n        (0.3, 0.4, 0.4, 0.01, 0.05, 0.02, 0.12),  # Case D\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        # Unpack parameters for the current test case.\n        # Notation from problem statement:\n        # pg: P(G=1)\n        # s0: P(S=1 | G=0)\n        # s1: P(S=1 | G=1)\n        # c10: P(C=1 | S=1, G=0)\n        # c11: P(C=1 | S=1, G=1)\n        # c00 and c01 are not needed for this specific calculation.\n        pg, s0, s1, c00, c10, c01, c11 = case\n\n        # The quantity to compute is Delta = P(C=1|S=1) - P(C=1|do(S=1)).\n        # This difference represents the confounding bias.\n        # A simplified formula derived from first principles is used:\n        # Delta = (pg * (1-pg) * (s1-s0) * (c11-c10)) / P(S=1)\n        # where P(S=1) = (1-pg)*s0 + pg*s1.\n        \n        # Calculate the denominator, P(S=1).\n        prob_s1 = (1.0 - pg) * s0 + pg * s1\n\n        # The problem statement implies P(S=1) will not be zero for any test case,\n        # which would make the observational probability P(C=1|S=1) undefined.\n        # For the given cases, P(S=1) is always positive.\n        if prob_s1 == 0.0:\n            # If P(S=1) is 0, the subpopulation of smokers is empty.\n            # The confounding bias is taken to be 0 in this edge case.\n            delta = 0.0\n        else:\n            # Calculate the numerator of the simplified formula.\n            # This represents the covariance between the genetic effect on smoking\n            # and the genetic effect on cancer risk among a population of smokers.\n            numerator = pg * (1.0 - pg) * (s1 - s0) * (c11 - c10)\n            \n            # Calculate Delta, the confounding bias.\n            delta = numerator / prob_s1\n        \n        # Format the result to six decimal places as required.\n        results.append(f\"{delta:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2382934"}, {"introduction": "掌握了混杂问题的本质以及区分关联与因果的理论基础后，我们转向一种在现代生物信息学和流行病学中广泛应用的强大计算策略：孟德尔随机化（Mendelian Randomization）。这个练习将指导你通过模拟，扮演一名计算生物学家的角色，使用遗传变异作为“工具变量”来估计转录因子对靶基因的真实因果效应 $\\beta$ [@problem_id:2382981]。你将通过编程实践，比较传统的普通最小二乘法（OLS）回归与工具变量法（IV）的结果，从而深刻理解如何利用自然界的随机分配来克服潜藏的混杂因素。", "problem": "给定一个数学上明确定义的线性结构因果模型，该模型用于描述一个简化的转录调控场景，其提出受到了孟德尔随机化（Mendelian Randomization, MR）的启发。涉及的变量有：一个遗传工具变量$Z$（处于哈代-温伯格平衡 (Hardy–Weinberg equilibrium) 状态的单核苷酸多态性的等位基因剂量）、一个转录因子表达量$X$、一个目标基因表达量$Y$，以及一个同时影响$X$和$Y$的未观测混杂因素$U$。对于个体 $i \\in \\{1,\\dots,n\\}$，数据生成过程如下：\n$$\nZ_i \\sim \\text{Binomial}(2,p), \\quad U_i \\sim \\mathcal{N}(0,1), \\quad \\varepsilon^X_i \\sim \\mathcal{N}(0,\\sigma_X^2), \\quad \\varepsilon^Y_i \\sim \\mathcal{N}(0,\\sigma_Y^2),\n$$\n在个体 $i$ 之间相互独立，并且\n$$\nX_i \\;=\\; \\alpha Z_i \\;+\\; \\delta U_i \\;+\\; \\varepsilon^X_i, \\qquad\nY_i \\;=\\; \\beta X_i \\;+\\; \\kappa U_i \\;+\\; \\gamma Z_i \\;+\\; \\varepsilon^Y_i.\n$$\n所有截距项均为零。我们感兴趣的因果假设是，$X$对$Y$存在因果效应，该效应由结构参数$\\beta$所表征。参数$\\gamma$表示$Z$可能对$Y$产生的、并非由$X$介导的直接效应（这违反了工具变量的排他性限制）。参数$\\delta$和$\\kappa$表示未观测到的混杂效应。\n\n您的任务是，针对下方测试套件中的每一组参数，从该模型中生成一个大小为$n$的样本，并根据该样本计算以下量值：\n- 在上述模型中，当$X$由$Z$作为工具变量时，$Y$的线性结构方程中$X$的已识别系数$\\widehat{\\beta}_{\\mathrm{IV}}$。该系数通过将$Y$的回归量投影到工具变量的列空间并求解相应的正规方程组获得。\n- 用于检验上述已识别系数的原假设$H_0:\\beta=0$的双侧$p$值。该$p$值使用同方差线性模型计算，该模型采用自由度为$n-k$的Student’s $t$分布，其中$k=2$是结构方程中系数的数量（截距和斜率）。\n- 用于检验在$X$对工具变量空间的线性投影中$Z$的系数为零的原假设的第一阶段$F$统计量。使用带有截距的单个工具变量的标准$F$统计量，自由度为$\\left(1, n-2\\right)$。\n- 带截距项的$Y$对$X$回归的普通最小二乘法（ordinary least squares）系数$\\widehat{\\beta}_{\\mathrm{OLS}}$。\n\n所有量值必须根据样本计算，并以实数形式表示。不涉及物理单位。当需要显著性水平时，请使用小数形式的$\\alpha=0.05$。随机抽样必须是可复现的：对每个测试用例，使用由所提供的整数种子$s$初始化的伪随机数生成器。\n\n测试套件（四个用例）：\n- 用例A（有效工具变量，非零因果效应）：$n=5000$, $p=0.3$, $\\alpha=0.8$, $\\beta=1.2$, $\\delta=1.0$, $\\kappa=1.0$, $\\gamma=0.0$, $\\sigma_X=1.0$, $\\sigma_Y=1.0$, $s=2021$。\n- 用例B（有效工具变量，零因果效应）：$n=5000$, $p=0.3$, $\\alpha=0.8$, $\\beta=0.0$, $\\delta=1.0$, $\\kappa=1.0$, $\\gamma=0.0$, $\\sigma_X=1.0$, $\\sigma_Y=1.0$, $s=2022$。\n- 用例C（因直接效应而无效的工具变量）：$n=5000$, $p=0.3$, $\\alpha=0.8$, $\\beta=1.0$, $\\delta=1.0$, $\\kappa=1.0$, $\\gamma=0.6$, $\\sigma_X=1.0$, $\\sigma_Y=1.0$, $s=2023$。\n- 用例D（弱工具变量）：$n=5000$, $p=0.3$, $\\alpha=0.05$, $\\beta=1.0$, $\\delta=1.0$, $\\kappa=1.0$, $\\gamma=0.0$, $\\sigma_X=1.0$, $\\sigma_Y=1.0$, $s=2024$。\n\n最终输出格式：\n- 对每个测试用例，返回列表$\\left[\\widehat{\\beta}_{\\mathrm{IV}},\\, p\\text{-value}_{\\mathrm{IV}},\\, F_{\\text{first-stage}},\\, \\widehat{\\beta}_{\\mathrm{OLS}}\\right]$，其中每个条目都四舍五入到恰好$4$位小数。\n- 您的程序应生成单行输出，其中包含四个用例的结果。结果以逗号分隔的列表形式呈现，并用方括号括起来（例如，$\\left[\\left[a,b,c,d\\right],\\left[\\dots\\right],\\left[\\dots\\right],\\left[\\dots\\right]\\right]$），所有数字均按指定要求四舍五入。", "solution": "该问题具有科学依据，提法明确，所有变量和步骤都得到了充分的数学精确定义。它描述了一项基于线性结构因果模型（一种因果推断中的标准工具）的模拟研究，旨在评估普通最小二乘法（Ordinary Least Squares, OLS）和工具变量（Instrumental Variable, IV）估计量在与孟德尔随机化相关的不同场景下的性能。该问题是有效的。\n\n任务是，针对四组不同的参数集，从指定的模型中生成数据，并为每组数据计算四个统计量：IV估计值$\\widehat{\\beta}_{\\mathrm{IV}}$、其对应的$p$值、第一阶段$F$统计量以及OLS估计值$\\widehat{\\beta}_{\\mathrm{OLS}}$。\n\n解决方案分为五个阶段进行：\n1. 数据生成：对于每个测试用例，我们根据指定的分布和结构方程生成一个大小为$n$的样本。\n2. OLS估计：我们通过将$Y$对$X$和一个截距项进行回归，来计算OLS估计值$\\widehat{\\beta}_{\\mathrm{OLS}}$。\n3. IV估计：我们使用两阶段最小二乘法（2SLS）程序计算IV估计值$\\widehat{\\beta}_{\\mathrm{IV}}$。\n4. IV推断：我们计算$\\widehat{\\beta}_{\\mathrm{IV}}$的标准误，以求得$t$统计量和用于检验原假设$H_0: \\beta=0$的对应$p$值。\n5. 第一阶段诊断：我们计算第一阶段回归的$F$统计量，以评估工具变量的强度。\n\n设长度为$n$的向量$\\mathbf{y}$、$\\mathbf{x}$、$\\mathbf{z}$分别代表抽样数据$\\{Y_i\\}_{i=1}^n$、$\\{X_i\\}_{i=1}^n$和$\\{Z_i\\}_{i=1}^n$。设$\\mathbf{1}$是长度为$n$的全1向量。\n\n**1. 数据生成**\n对于每个个体$i \\in \\{1, \\dots, n\\}$，我们按规定生成变量：\n- 遗传工具变量：$Z_i \\sim \\text{Binomial}(2,p)$\n- 未观测混杂因素：$U_i \\sim \\mathcal{N}(0,1)$\n- 误差项：$\\varepsilon^X_i \\sim \\mathcal{N}(0,\\sigma_X^2)$ 和 $\\varepsilon^Y_i \\sim \\mathcal{N}(0,\\sigma_Y^2)$\n利用这些变量，我们构建可观测变量$X_i$和$Y_i$：\n$$\nX_i \\;=\\; \\alpha Z_i \\;+\\; \\delta U_i \\;+\\; \\varepsilon^X_i\n$$\n$$\nY_i \\;=\\; \\beta X_i \\;+\\; \\kappa U_i \\;+\\; \\gamma Z_i \\;+\\; \\varepsilon^Y_i\n$$\n使用种子$s$初始化的伪随机数生成器确保每个用例的可复现性。\n\n**2. 普通最小二乘法（OLS）估计**\nOLS模型包含一个截距项：$Y_i = b_0 + b_1 X_i + e_i$。其矩阵形式为$\\mathbf{y} = \\mathbf{X}_{\\text{OLS}} \\mathbf{b} + \\mathbf{e}$，其中$\\mathbf{X}_{\\text{OLS}} = [\\mathbf{1}, \\mathbf{x}]$是$n \\times 2$的设计矩阵。\n$\\mathbf{b} = [b_0, b_1]'$的OLS估计量由正规方程组的解给出：\n$$\n\\widehat{\\mathbf{b}}_{\\mathrm{OLS}} = (\\mathbf{X}_{\\text{OLS}}' \\mathbf{X}_{\\text{OLS}})^{-1} \\mathbf{X}_{\\text{OLS}}' \\mathbf{y}\n$$\n所需的量是斜率系数$\\widehat{\\beta}_{\\mathrm{OLS}} = \\widehat{b}_1$。\n\n**3. 工具变量（IV）估计**\nIV估计使用两阶段最小二乘法（2SLS）进行。\n$Y$的结构方程为$Y_i = \\beta_0 + \\beta_1 X_i + \\eta_i$。内生回归量$X$的工具变量是$Z$。我们在所有回归中都包含截距项。\n回归量矩阵为$\\mathbf{X}_{\\text{reg}} = [\\mathbf{1}, \\mathbf{x}]$，工具变量矩阵为$\\mathbf{Z}_{\\text{inst}} = [\\mathbf{1}, \\mathbf{z}]$。\n\n第一阶段：将回归量投影到由工具变量张成的空间上。投影矩阵为$\\mathbf{P_Z} = \\mathbf{Z}_{\\text{inst}} (\\mathbf{Z}_{\\text{inst}}' \\mathbf{Z}_{\\text{inst}})^{-1} \\mathbf{Z}_{\\text{inst}}'$。投影后的回归量为$\\widehat{\\mathbf{X}}_{\\text{reg}} = \\mathbf{P_Z} \\mathbf{X}_{\\text{reg}}$。\n\n第二阶段：2SLS估计量$\\widehat{\\mathbf{\\beta}}_{\\mathrm{IV}} = [\\widehat{\\beta}_0, \\widehat{\\beta}_1]'$通过将$\\mathbf{y}$对$\\widehat{\\mathbf{X}}_{\\text{reg}}$回归得到。然而，一个更直接和标准的公式是：\n$$\n\\widehat{\\mathbf{\\beta}}_{\\mathrm{IV}} = (\\mathbf{X}_{\\text{reg}}' \\mathbf{P_Z} \\mathbf{X}_{\\text{reg}})^{-1} \\mathbf{X}_{\\text{reg}}' \\mathbf{P_Z} \\mathbf{y}\n$$\n因果效应的估计值是斜率系数，我们将其记为$\\widehat{\\beta}_{\\mathrm{IV}}$（这里略微滥用了符号，它实际上是向量中的$\\widehat{\\beta}_1$）。\n\n**4. $\\widehat{\\beta}_{\\mathrm{IV}}$的P值**\n为了检验原假设$H_0: \\beta=0$，我们计算一个$t$统计量。\n首先，我们使用估计出的系数和原始回归量计算残差：\n$$\n\\mathbf{e}_{\\mathrm{IV}} = \\mathbf{y} - \\mathbf{X}_{\\text{reg}} \\widehat{\\mathbf{\\beta}}_{\\mathrm{IV}}\n$$\n在同方差性的假设下，回归误差的估计方差为：\n$$\n\\widehat{\\sigma}^2_{\\mathrm{IV}} = \\frac{\\mathbf{e}_{\\mathrm{IV}}' \\mathbf{e}_{\\mathrm{IV}}}{n-k}\n$$\n其中$k=2$是参数的数量（截距和斜率）。估计量的方差-协方差矩阵为：\n$$\n\\widehat{\\text{Var}}(\\widehat{\\mathbf{\\beta}}_{\\mathrm{IV}}) = \\widehat{\\sigma}^2_{\\mathrm{IV}} (\\mathbf{X}_{\\text{reg}}' \\mathbf{P_Z} \\mathbf{X}_{\\text{reg}})^{-1}\n$$\n斜率系数的标准误$SE(\\widehat{\\beta}_{\\mathrm{IV}})$是该矩阵第二个对角元素的平方根。$t$统计量为：\n$$\nt = \\frac{\\widehat{\\beta}_{\\mathrm{IV}}}{SE(\\widehat{\\beta}_{\\mathrm{IV}})}\n$$\n双侧$p$值是使用自由度为$n-k=n-2$的Student's $t$-distribution计算的：\n$$\np\\text{-value}_{\\mathrm{IV}} = 2 \\cdot P(T_{n-2} > |t|)\n$$\n\n**5. 第一阶段F统计量**\n第一阶段回归是$X_i = \\pi_0 + \\pi_1 Z_i + \\nu_i$。我们需要检验原假设$H_0: \\pi_1 = 0$。\n$F$统计量将完整模型（包含$Z_i$）与受限模型（仅包含截距）进行比较。\n设$RSS_1$是完整第一阶段回归（$X$对$\\mathbf{1}$和$\\mathbf{z}$回归）的残差平方和。设$TSS$是$X$的总平方和，即$X$仅对截距回归的残差平方和。对于含有1个工具变量和1个截距项的情况，$F$统计量的公式为：\n$$\nF_{\\text{first-stage}} = \\frac{(TSS - RSS_1) / (2-1)}{RSS_1 / (n-2)} = \\frac{TSS - RSS_1}{RSS_1 / (n-2)}\n$$\n在原假设下，该统计量服从自由度为$(1, n-2)$的$F$分布。\n\n这五个步骤将针对四个测试用例中的每一个进行实施。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import t\n\ndef solve():\n    \"\"\"\n    Solves the problem by iterating through test cases, simulating data,\n    and calculating the required statistical quantities.\n    \"\"\"\n    test_cases = [\n        # Case A (valid instrument, nonzero causal effect)\n        {'n': 5000, 'p': 0.3, 'alpha': 0.8, 'beta': 1.2, 'delta': 1.0, 'kappa': 1.0, 'gamma': 0.0, 'sigma_X': 1.0, 'sigma_Y': 1.0, 's': 2021},\n        # Case B (valid instrument, null causal effect)\n        {'n': 5000, 'p': 0.3, 'alpha': 0.8, 'beta': 0.0, 'delta': 1.0, 'kappa': 1.0, 'gamma': 0.0, 'sigma_X': 1.0, 'sigma_Y': 1.0, 's': 2022},\n        # Case C (invalid instrument via direct effect)\n        {'n': 5000, 'p': 0.3, 'alpha': 0.8, 'beta': 1.0, 'delta': 1.0, 'kappa': 1.0, 'gamma': 0.6, 'sigma_X': 1.0, 'sigma_Y': 1.0, 's': 2023},\n        # Case D (weak instrument)\n        {'n': 5000, 'p': 0.3, 'alpha': 0.05, 'beta': 1.0, 'delta': 1.0, 'kappa': 1.0, 'gamma': 0.0, 'sigma_X': 1.0, 'sigma_Y': 1.0, 's': 2024},\n    ]\n\n    results = []\n    for params in test_cases:\n        n = params['n']\n        p = params['p']\n        alpha = params['alpha']\n        beta = params['beta']\n        delta = params['delta']\n        kappa = params['kappa']\n        gamma = params['gamma']\n        sigma_X = params['sigma_X']\n        sigma_Y = params['sigma_Y']\n        s = params['s']\n\n        # 1. Data Generation\n        rng = np.random.default_rng(s)\n        Z = rng.binomial(2, p, size=n)\n        U = rng.normal(0, 1, size=n)\n        eps_X = rng.normal(0, sigma_X, size=n)\n        eps_Y = rng.normal(0, sigma_Y, size=n)\n        \n        X = alpha * Z + delta * U + eps_X\n        Y = beta * X + kappa * U + gamma * Z + eps_Y\n\n        # Prepare matrices for regressions\n        ones = np.ones(n)\n        \n        # OLS matrices\n        X_ols_mat = np.vstack([ones, X]).T\n        \n        # IV/2SLS matrices\n        X_reg_mat = np.vstack([ones, X]).T  # Regressors for 2nd stage\n        Z_inst_mat = np.vstack([ones, Z]).T # Instruments for 1st stage\n\n        # 2. OLS Estimation\n        try:\n            b_ols_hat_vec = np.linalg.solve(X_ols_mat.T @ X_ols_mat, X_ols_mat.T @ Y)\n            beta_ols_hat = b_ols_hat_vec[1]\n        except np.linalg.LinAlgError:\n            beta_ols_hat = np.nan\n\n        # 3. IV Estimation (2SLS)\n        try:\n            # Projection matrix P_Z\n            ZtZ_inv = np.linalg.inv(Z_inst_mat.T @ Z_inst_mat)\n            P_Z = Z_inst_mat @ ZtZ_inv @ Z_inst_mat.T\n            \n            # 2SLS estimator\n            X_reg_T_P_Z = X_reg_mat.T @ P_Z\n            beta_iv_vec = np.linalg.solve(X_reg_T_P_Z @ X_reg_mat, X_reg_T_P_Z @ Y)\n            beta_iv_hat = beta_iv_vec[1]\n\n            # 4. IV p-value calculation\n            k = 2  # Number of parameters in 2nd stage (intercept, slope)\n            df = n - k\n            residuals_iv = Y - X_reg_mat @ beta_iv_vec\n            sigma2_hat_iv = np.sum(residuals_iv**2) / df\n            \n            var_cov_beta_iv = sigma2_hat_iv * np.linalg.inv(X_reg_T_P_Z @ X_reg_mat)\n            se_beta_iv_hat = np.sqrt(var_cov_beta_iv[1, 1])\n            \n            t_stat_iv = beta_iv_hat / se_beta_iv_hat\n            p_value_iv = 2 * t.sf(np.abs(t_stat_iv), df=df)\n\n        except np.linalg.LinAlgError:\n            beta_iv_hat = np.nan\n            p_value_iv = np.nan\n\n        # 5. First-stage F-statistic\n        try:\n            # Full model: X ~ 1 + Z\n            _, rss1, _, _ = np.linalg.lstsq(Z_inst_mat, X, rcond=None)\n            \n            # Restricted model: X ~ 1\n            X_mean = np.mean(X)\n            tss = np.sum((X - X_mean)**2)\n            \n            df_num = 1\n            df_den = n - 2\n            \n            f_stat = ((tss - rss1[0]) / df_num) / (rss1[0] / df_den)\n        except (np.linalg.LinAlgError, IndexError):\n            f_stat = np.nan\n\n        # Store results for the current case\n        results.append([beta_iv_hat, p_value_iv, f_stat, beta_ols_hat])\n\n    # Final print statement in the exact required format.\n    formatted_results = [\n        f\"[{r[0]:.4f},{r[1]:.4f},{r[2]:.4f},{r[3]:.4f}]\" for r in results\n    ]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2382981"}]}