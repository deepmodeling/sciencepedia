{"hands_on_practices": [{"introduction": "差异表达分析的一个关键产出是一份基因列表，其中每个基因都附有一个效应大小（如 $\\log_2(\\text{倍数变化})$）和一个 $p$ 值。本练习旨在挑战你解读一种常见但时而令人困惑的情景：观察到巨大的效应，却缺乏统计显著性。通过完成这项练习 [@problem_id:2281817]，你将巩固对“变化幅度”与“对该变化的统计置信度”之间关键区别的理解。", "problem": "一个计算生物学家团队正在使用核糖核酸（RNA）测序数据进行差异基因表达分析。他们的目标是确定在一个癌细胞系中，哪些基因的表达水平被一种新的实验性药物所改变。他们比较了药物处理过的细胞与未处理的对照组细胞中的基因表达。对于每个基因，他们的分析流程会计算两个关键指标：\n\n1.  **$\\log_2(\\text{倍数变化})$**：这个值量化了表达变化的幅度和方向。正值表示上调（表达增加），而负值表示下调。例如，$\\log_2(\\text{倍数变化})$ 为2.0对应于表达量增加了$2^{2} = 4$倍。\n2.  **p值**：这个值评估了观察到的倍数变化的统计显著性。它表示在假设药物没有实际效果（零假设）的情况下，观察到至少与测量值一样极端的倍数变化的概率。p值越小，表明反对零假设的证据越强。通常，小于0.05的p值被认为具有统计显著性。\n\n该团队对一个名为`REG-17`的特定基因的分析得出的 $\\log_2(\\text{倍数变化})$ 为4.5，p值为0.38。\n\n对于`REG-17`基因的这一结果，以下哪个陈述提供了最准确和合理的解释？\n\nA. 药物导致`REG-17`基因非常大幅度且统计上显著的上调，使其成为需要优先进一步研究的候选基因。\n\nB. 实验中观察到`REG-17`基因的大幅度上调，但由于数据的高度变异性或样本量不足，我们无法确信这种变化是药物的真实效果，而不是随机偶然的结果。\n\nC. 药物对`REG-17`基因没有有意义的影响，因为观察到的变化不具有统计显著性。\n\nD. 计算肯定有误，因为高达4.5的 $\\log_2(\\text{倍数变化})$ 不可能与高达0.38的p值相关联。\n\nE. `REG-17`是一个生物学上不重要的基因，这就是为什么其表达变化没有达到统计显著性。", "solution": "为了确定正确的解释，我们必须仔细考虑 $\\log_2(\\text{倍数变化})$ 和p值的含义。\n\n1.  **解释 $\\log_2(\\text{倍数变化})$**：$\\log_2(\\text{倍数变化})$ 是效应大小的度量。`REG-17`的值为4.5意味着药物处理组中该基因的平均表达量比对照组高约$2^{4.5} \\approx 22.6$倍。从生物学角度来看，这是一个非常大的变化幅度。它表明在收集到的数据中确实*观察*到了强烈的上调。\n\n2.  **解释p值**：p值评估了观察到的效应的统计可靠性。p值为0.38意味着，即使药物对该基因的表达没有真实效果（即，如果零假设为真），纯粹由于随机偶然，也有38%的概率观察到这种幅度（或更大）的倍数变化。在生物医学研究中，统计显著性的常规阈值是p值小于0.05。由于0.38远大于0.05，该结果被认为**不具有统计显著性**。这个高p值表明我们无法自信地排除随机变异是观察到变化的原因。缺乏统计显著性通常是由于组内重复样本之间的高度变异性（例如，一些处理过的细胞反应强烈，另一些则完全没有反应）或重复样本数量不足，这降低了实验检测真实效应的统计功效。\n\n3.  **综合两个指标**：我们面临着一个看似矛盾的情况：一个非常大的效应量 ($\\log_2(\\text{倍数变化}) = 4.5$) 伴随着缺乏统计显著性 (p值 = 0.38)。正确的解释综合了这两个事实。它承认在数据中看到的大变化，但同时也承认围绕这一观察结果的高度不确定性。我们观察到了戏剧性的变化，但我们不能确定这是否是药物真实、可重复的效果。\n\n现在，让我们基于这一理解来评估给出的选项：\n\n*   **A. 药物导致`REG-17`基因非常大幅度且统计上显著的上调，使其成为需要优先进一步研究的候选基因。** 这是不正确的。虽然上调幅度很大，但它明确地**不具有**统计显著性 (p值 = 0.38 > 0.05)。\n\n*   **B. 实验中观察到`REG-17`基因的大幅度上调，但由于数据的高度变异性或样本量不足，我们无法确信这种变化是药物的真实效果，而不是随机偶然的结果。** 这是正确的解释。它准确地报告了观察到的大效应（大幅度上调），同时正确地将高p值解释为对结果缺乏信心，并正确地指出了常见原因，如高变异性或小样本量。\n\n*   **C. 药物对`REG-17`基因没有有意义的影响，因为观察到的变化不具有统计显著性。** 这是一个不正确的结论。“没有证据不等于没有的证据。” 实验未能提供效应的*统计显著证据*，但这并不能证明*没有效应*。大的倍数变化表明可能存在效应，但实验缺乏证实它的统计功效。\n\n*   **D. 计算肯定有误，因为高达4.5的 $\\log_2(\\text{倍数变化})$ 不可能与高达0.38的p值相关联。** 这是不正确的。这在生物实验中是非常常见的情况，特别是在那些重复样本数量少或生物系统本身“噪音”大（即组内方差高）的实验中。\n\n*   **E. `REG-17`是一个生物学上不重要的基因，这就是为什么其表达变化没有达到统计显著性。** 这是一个没有依据的逻辑跳跃。单个实验中的统计显著性并不能说明一个基因的整体生物学重要性。一个基因可能至关重要，但药物可能不影响它，或者实验可能不够稳健以检测到这种变化。", "answer": "$$\\boxed{B}$$", "id": "2281817"}, {"introduction": "当同时分析成千上万个基因时，我们实际上执行了成千上万次统计检验，这会显著增加假阳性的风险。为了解决这个问题，我们必须使用例如 Benjamini-Hochberg (BH) 等方法来校正 $p$ 值，以控制假发现率 (False Discovery Rate, FDR)。在这个动手实践的编程挑战中 [@problem_id:2385494]，你将从零开始实现 BH 算法，将一系列原始 $p$ 值转换为校正后的值，从而深入且实用地掌握这一核心统计工具。", "problem": "给定一组原始 $p$ 值，这些 $p$ 值来源于一项比较两种条件的差异基因表达实验中的 $m$ 个独立的基因水平原假设。设原假设集合为 $\\{H_1,\\dots,H_m\\}$，其对应的原始 $p$ 值为 $p_1,\\dots,p_m \\in [0,1]$。对于一个目标水平 $q \\in (0,1)$，用于将错误发现率 (FDR) 控制在水平 $q$ 的 Benjamini–Hochberg (BH) 程序定义如下。将 $p$ 值按非递减顺序排列为 $p_{(1)} \\le \\dots \\le p_{(m)}$，其中下标表示顺序统计量。定义索引\n$$\nk \\;=\\; \\max\\left\\{ i \\in \\{1,\\dots,m\\} \\;:\\; p_{(i)} \\le \\frac{i}{m}\\,q \\right\\},\n$$\n并约定如果该集合为空，则不拒绝任何假设。那么，BH 拒绝集是所有原始 $p$ 值不超过阈值 $p_{(k)}$ 的假设，即：\n$$\n\\mathcal{R} \\;=\\; \\{ j \\in \\{1,\\dots,m\\} \\;:\\; p_j \\le p_{(k)} \\},\n$$\n当 $k$ 存在时，否则 $\\mathcal{R}=\\varnothing$。BH 校正 $p$ 值（在某些情况下也称为 BH $q$ 值）是为每个假设定义的，首先将以下值赋给第 $i$ 个顺序统计量\n$$\n\\tilde{p}_{(i)} \\;=\\; \\min_{j \\in \\{i,\\dots,m\\}} \\left( \\frac{m}{j}\\,p_{(j)} \\right),\n$$\n然后通过 $\\min\\{\\tilde{p}_{(i)},1\\}$ 将其截断至 $1$，最后映射回原始的假设顺序。为了在存在相等 $p$ 值的情况下使排序分配具有确定性，请使用稳定排序，即通过增加原始索引来打破平局。也就是说，如果 $p_a=p_b$ 且 $a<b$，那么在排序中 $p_a$ 在 $p_b$ 之前。使用从 0 开始的索引来为假设的原始位置建立索引。\n\n任务。对于下方的每个测试用例，给定一个原始 $p$ 值列表和一个目标 FDR 水平 $q$，计算：\n- 按原始假设顺序列出的 BH 校正 $p$ 值列表，每个值四舍五入到 $6$ 位小数（以小数形式表示，而非百分比），以及\n- 在水平 $q$ 下，根据 BH 程序得到的被拒绝假设的索引列表（使用从 0 开始的索引），按升序排列。\n\n测试套件。在以下四个案例上评估您的实现，这些案例共同涵盖了典型情况、边界值、平局情况以及无拒绝情况：\n- 案例 $1$：$p=(0.001,\\,0.04,\\,0.03,\\,0.2,\\,0.5,\\,0.0005,\\,0.07,\\,0.9)$, $q=0.1$。\n- 案例 $2$：$p=(0,\\,1,\\,0.5,\\,0.05,\\,0.2)$, $q=0.05$。\n- 案例 $3$：$p=(0.02,\\,0.02,\\,0.02,\\,0.5,\\,0.8,\\,0.9)$, $q=0.1$。\n- 案例 $4$：$p=(0.2,\\,0.3,\\,0.4,\\,0.6,\\,0.8)$, $q=0.01$。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个由方括号括起来的、以逗号分隔的列表形式的结果，每个测试用例对应一个元素。每个元素本身必须是一个双元素列表，其第一个元素是四舍五入后的 BH 校正 $p$ 值列表（按原始顺序），第二个元素是按升序排列的、从 0 开始的被拒绝假设的索引列表。不应打印其他任何文本。例如，整体结构必须是如下形式：\n[[adj_case1,rej_case1],[adj_case2,rej_case2],[adj_case3,rej_case3],[adj_case4,rej_case4]]\n其中 adj_case$k$ 和 rej_case$k$ 分别是按上述规定为案例 $k$ 生成的列表。", "solution": "问题陈述经评估有效。它基于标准且科学可靠的 Benjamini-Hochberg 程序提出了一个清晰、明确的计算任务，该程序是控制错误发现率 (False Discovery Rate) 的一种基本方法，在计算生物学和统计学中广泛应用。其定义、条件和测试用例是完整、一致且客观的，可以得出一个唯一且可验证的解。\n\n任务是实现 Benjamini-Hochberg (BH) 程序。给定来自多个假设检验的一组 $m$ 个原始 $p$ 值 $\\{p_1, \\dots, p_m\\}$ 和一个目标错误发现率 (FDR) 水平 $q$，我们必须计算 BH 校正 $p$ 值并确定被拒绝的假设集合。该程序是确定性的，将通过一系列直接源自所提供数学定义的、有原则的步骤来实现。\n\n设 $m$ 为假设总数。算法按以下步骤进行：\n\n1.  **数据结构化与排序**：每个原始 $p$ 值 $p_j$ 与其原始的、从 0 开始的索引 $j$ 相关联。然后将得到的配对 $(p_j, j)$ 按 $p_j$ 的非递减顺序排序。问题指定了一种稳定的排序机制来处理平局情况：如果对于原始索引 $a<b$ 有 $p_a=p_b$，则对应于 $a$ 的配对必须在对应于 $b$ 的配对之前。该步骤产生有序的 $p$ 值 $p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(m)}$ 及其原始索引。$p_{(i)}$ 的秩为 $i$。\n\n2.  **确定拒绝阈值**：BH 程序的核心是找到满足以下条件的最大秩 $k \\in \\{1,\\dots,m\\}$：\n    $$\n    p_{(k)} \\le \\frac{k}{m}q\n    $$\n    此条件将第 $k$ 小的 $p$ 值与一个随着秩 $k$ 增加而线性放宽的阈值进行比较。如果满足此不等式的秩集合为空，则结论是在指定的 FDR 水平 $q$ 下不能拒绝任何假设，并且拒绝集 $\\mathcal{R}$ 为空。否则，与最大秩 $k$ 对应的 $p_{(k)}$ 值成为显著性阈值。\n\n3.  **确定拒绝集**：被拒绝的假设集合 $\\mathcal{R}$ 包含所有其原始、未校正的 $p$ 值 $p_j$ 小于或等于上一步中找到的阈值 $p_{(k)}$ 的假设。即 $\\mathcal{R} = \\{ j \\in \\{1,\\dots,m\\} : p_j \\le p_{(k)} \\}$。最终输出要求提供这些假设的、从 0 开始的索引，并按升序排列。\n\n4.  **计算校正 $p$ 值**：对于对应于第 $i$ 个有序原始 $p$ 值 $p_{(i)}$ 的假设，其 BH 校正 $p$ 值定义为：\n    $$\n    \\tilde{p}_{(i)} = \\min_{j \\in \\{i,\\dots,m\\}} \\left( \\frac{m}{j}p_{(j)} \\right)\n    $$\n    如有必要，再将其截断至 $1$。此定义确保校正后的 $p$ 值相对于其秩是单调非递减的，即 $\\tilde{p}_{(1)} \\le \\tilde{p}_{(2)} \\le \\dots \\le \\tilde{p}_{(m)}$。该步骤的一个高效计算策略包括首先为所有秩 $j=1, \\dots, m$ 计算缩放值 $\\frac{m}{j}p_{(j)}$。然后，从秩 $m$ 向下迭代至 $1$，在每一步计算累积最小值。具体来说，秩 $i$ 的校正 $p$ 值是其自身的缩放值与秩为 $i+1$ 的校正 $p$ 值的最小值。最终的校正 $p$ 值随后被映射回其原始假设顺序，并按要求四舍五入到 6 位小数。\n\n实现将把此四步逻辑应用于每个提供的测试用例，以生成所需的输出。", "answer": "```python\nimport numpy as np\n\ndef _format_output(data):\n    \"\"\"\n    Custom recursive function to format the final list into a string\n    without spaces and with floats formatted to 6 decimal places.\n    \"\"\"\n    if isinstance(data, list):\n        return f\"[{','.join(_format_output(item) for item in data)}]\"\n    if isinstance(data, float):\n        return f\"{data:.6f}\"\n    return str(data)\n\ndef benjamini_hochberg(p_values: np.ndarray, q: float):\n    \"\"\"\n    Performs the Benjamini-Hochberg procedure for FDR control.\n\n    Args:\n        p_values: A numpy array of raw p-values.\n        q: The target False Discovery Rate level.\n\n    Returns:\n        A tuple containing:\n        - A list of BH adjusted p-values, rounded to 6 decimal places, in original order.\n        - A sorted list of 0-based indices of rejected hypotheses.\n    \"\"\"\n    m = len(p_values)\n    if m == 0:\n        return [], []\n        \n    original_indices = np.arange(m)\n    \n    # Sort p-values while keeping track of original indices.\n    # The 'stable' kind ensures that for equal p-values, the original order is preserved,\n    # satisfying the problem's tie-breaking rule.\n    sorted_order_indices = np.argsort(p_values, kind='stable')\n    sorted_p_values = p_values[sorted_order_indices]\n    \n    # --- Step 1: Find rejection threshold ---\n    ranks = np.arange(1, m + 1)\n    bh_thresholds = (ranks / m) * q\n    \n    significant_mask = sorted_p_values <= bh_thresholds\n    \n    rejected_indices = []\n    if np.any(significant_mask):\n        # Find the largest rank k satisfying the BH condition\n        k = np.max(ranks[significant_mask])\n        \n        # The rejection threshold is the p-value at this rank k\n        rejection_threshold = sorted_p_values[k - 1]\n        \n        # Identify all hypotheses with original p-values <= threshold\n        rejected_mask = p_values <= rejection_threshold\n        rejected_indices = original_indices[rejected_mask].tolist()\n\n    # --- Step 2: Calculate adjusted p-values ---\n    # Calculate raw scaled p-values: (m/i) * p_(i)\n    scaled_p_values = (m / ranks) * sorted_p_values\n    \n    # Enforce monotonicity by taking the cumulative minimum from the end (right-to-left)\n    adj_p_sorted = np.minimum.accumulate(scaled_p_values[::-1])[::-1]\n    \n    # Truncate values at 1.0\n    adj_p_sorted = np.minimum(adj_p_sorted, 1.0)\n    \n    # Unsort the adjusted p-values to match the original p-value order\n    adj_p_original = np.empty(m)\n    adj_p_original[sorted_order_indices] = adj_p_sorted\n    \n    # Round to 6 decimal places for final output\n    adj_p_rounded = [round(p, 6) for p in adj_p_original]\n\n    return adj_p_rounded, rejected_indices\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the final result.\n    \"\"\"\n    test_cases = [\n        ((0.001, 0.04, 0.03, 0.2, 0.5, 0.0005, 0.07, 0.9), 0.1),\n        ((0.0, 1.0, 0.5, 0.05, 0.2), 0.05),\n        ((0.02, 0.02, 0.02, 0.5, 0.8, 0.9), 0.1),\n        ((0.2, 0.3, 0.4, 0.6, 0.8), 0.01),\n    ]\n\n    results = []\n    for p_tuple, q_val in test_cases:\n        p_values_np = np.array(p_tuple)\n        adj_p, rej_idx = benjamini_hochberg(p_values_np, q_val)\n        results.append([adj_p, rej_idx])\n    \n    # Print the final result in the specified single-line format\n    print(_format_output(results))\n\nsolve()\n```", "id": "2385494"}, {"introduction": "当差异表达分析最终没有发现任何显著基因时，这意味着什么？虽然这可能真实反映了潜在的生物学现象，但它也常常指向实验设计或数据分析流程中存在的问题。本练习 [@problem_id:2385515] 将让你扮演一名数据侦探，任务是识别导致“无显著结果”这一情况的多种合理解释。培养这种诊断性思维模式，是每一位计算生物学家必备的关键技能。", "problem": "您正在进行一项双条件RNA测序差异基因表达分析，每组有 $n=3$ 个生物学重复。您使用一种标准的基于计数的方法，该方法利用负二项分布对计数进行建模，并将假发现率（FDR）控制在 $q=0.05$。分析结果显示，在 $q<0.05$ 的条件下，显著基因为 $0$ 个。在这种情况下，观察到 $0$ 个发现的可能原因有哪些？请选择所有适用项；恰好有 $5$ 个选项是正确的。\n\nA. 每组的样本量很小（例如，$n=3$），且基因层面的离散度很高，因此估计的标准误很大；在 $q=0.05$ 的水平上进行多重检验校正后，没有基因通过阈值。\n\nB. 样本的测序深度普遍较低，导致许多基因的计数较低且不确定性较高，从而降低了统计功效，并可能导致 $0$ 个发现。\n\nC. 设计矩阵中包含一个批次因子，该因子与条件完全混淆（例如，所有条件 $1$ 的样本都在批次 $A$ 中，所有条件 $2$ 的样本都在批次 $B$ 中），导致条件系数不可估计；因此，软件无法检验条件效应，并返回没有显著基因的结果。\n\nD. 样本元数据中的条件标签被意外地为所有样本设置了相同的值，因此该方法测试了一个空对比，并返回没有显著基因的结果。\n\nE. 主成分分析（PCA）的前两个主成分的散点图显示组间存在重叠；因此，不可能存在差异表达，所以预期会有零个发现。\n\nF. 真实的潜在生物学机制在条件之间几乎没有表达变化；也就是说，对于所有基因，原假设 $H_0$ 都为真，因此在 $q=0.05$ 的水平上进行FDR控制后，获得 $0$ 个拒绝是合理的。\n\nG. 当检验许多基因时，在 $q=0.05$ 水平上的 Benjamini–Hochberg FDR 程序总能产生至少一些发现；因此，零个显著基因意味着软件错误，而不是一个合理的结果。\n\nH. 在检验前移除了几乎所有基因的过度激进的独立过滤步骤不会降低发现的机会，因为它减轻了多重检验的负担，所以它不能解释零发现的结果。\n\nI. 当真实效应同时存在于两个方向时，使用双侧检验而不是单侧检验会保证得到零个显著基因，因此检验方向的选择解释了没有发现的原因。", "solution": "首先对问题陈述进行验证。\n\n**步骤1：提取已知条件**\n-   **实验：** 双条件RNA测序差异基因表达分析。\n-   **重复：** 每组 $n=3$ 个生物学重复。\n-   **统计模型：** 一种使用负二项分布的基于计数的方法。\n-   **多重检验控制：** 假发现率（FDR）控制在阈值 $q=0.05$。\n-   **结果：** 分析报告有 $0$ 个显著基因。\n-   **问题：** 找出观察到 $0$ 个发现的可能原因。\n\n**步骤2：使用提取的已知条件进行验证**\n-   **科学上成立：** 该问题描述了生物信息学和计算生物学中一个标准且常见的情景。RNA测序的使用、两组比较、小样本量（$n=3$）、使用负二项分布对计数进行建模（如DESeq2和edgeR等流行工具所做的那样），以及控制FDR，这些都是已确立且科学上合理的做法。\n-   **定义良好：** 问题定义良好。它要求对一个现实的实验结果进行解释，这需要理解影响差异表达分析功效和有效性的统计及实践因素。存在一组明确的合理解释。\n-   **客观性：** 问题使用了生物信息学领域常见的精确、客观和技术性语言来陈述。没有主观或含糊的术语。\n\n该问题没有科学上的不合理之处，是可形式化的，是完整的，并且结构符合实际。\n\n**步骤3：结论与行动**\n问题陈述有效。将推导出一个完整的解决方案。\n\n该问题要求解释为什么一个标准的RNA测序差异基因表达（DE）分析（每条件 $n=3$ 个重复）在FDR为 $q=0.05$ 的水平上没有发现任何显著基因。在此类分析中，对于每个基因 $g$，原始计数使用负二项（NB）分布进行建模，该分布由均值 $\\mu_g$ 和离散度参数 $\\phi_g$ 表征。方差由 $\\sigma_g^2 = \\mu_g + \\phi_g \\mu_g^2$ 给出。使用广义线性模型（GLM）来检验两个条件之间表达无差异的假设，从而为每个基因生成一个 $p$-值。然后，对这些 $p$-值进行多重检验校正以控制FDR。发现零个基因意味着对于所有被检验的基因，其校正后的 $p$-值（或 $q$-值）都大于或等于 $0.05$。这通常发生在原始 $p$-值不够小的情况下，可能由多种与统计功效、实验设计或潜在生物学机制相关的因素导致。下文对每个选项进行评估。\n\nA. 每组的样本量很小（例如，$n=3$），且基因层面的离散度很高，因此估计的标准误很大；在 $q=0.05$ 的水平上进行多重检验校正后，没有基因通过阈值。\n统计检验的功效取决于效应大小、样本量和数据的方差。对于DE分析，基因的检验统计量（例如，Wald统计量）是估计的log$_2$倍数变化（$\\hat{\\beta}$）除以其标准误（$SE(\\hat{\\beta})$）。像 $n=3$ 这样的小样本量只能提供非常有限的数据来估计组内方差，这在NB模型中由离散度参数 $\\phi$ 捕获。重复样本之间的高生物学变异性转化为高的基因层面离散度。高离散度导致大方差（$\\sigma^2 = \\mu + \\phi\\mu^2$），从而导致系数估计的标准误较大。大的 $SE(\\hat{\\beta})$ 会减小检验统计量的绝对值，导致更大（即不那么显著）的 $p$-值。当这种情况发生在大多数或所有基因上时，即使是最小的原始 $p$-值也可能不够小，无法在对数千个基因进行严格的多重检验校正后存留下来。这种因小样本量 $n$ 和高方差导致的低功效是导致零DE基因发现的典型且非常常见的原因。\n**结论：正确**\n\nB. 样本的测序深度普遍较低，导致许多基因的计数较低且不确定性较高，从而降低了统计功效，并可能导致 $0$ 个发现。\n测序深度指的是每个样本测序的平均读数（reads）数量。低测序深度导致大多数基因的读数计数较低。对于计数数据，方差与均值内在地关联。在低计数时，相对于测量的测量不确定性很高（例如，对于泊松分布的计数，变异系数为 $1/\\sqrt{\\text{count}}$）。这使得对每个组的平均表达水平进行精确估计变得困难。因此，检测组间统计显著差异的能力减弱。基因必须被足够深度地抽样才能克服这种抽样噪音。如果大多数基因的计数都很低，实验的统计功效将受到严重损害，这很容易导致FDR校正后没有发现。\n**结论：正确**\n\nC. 设计矩阵中包含一个批次因子，该因子与条件完全混淆（例如，所有条件 $1$ 的样本都在批次 $A$ 中，所有条件 $2$ 的样本都在批次 $B$ 中），导致条件系数不可估计；因此，软件无法检验条件效应，并返回没有显著基因的结果。\n正确的实验设计至关重要。如果一个实验变量（如“条件”）与一个技术变量（如“批次”）完全相关，那么这两个因子就是混淆的。在GLM框架中，这会导致设计矩阵不是满秩的（即它是奇异的）。因此，模型无法同时估计批次效应和条件效应，因为在数学上无法将它们分离开来。标准的统计软件（如DESeq2）会检测到这个问题，并报告“条件”系数不可估计。由于系数无法估计，因此无法对“条件”效应进行统计检验。软件将因此不返回该对比的结果（或返回 $p$-值为`NA`的结果），从而导致输出 $0$ 个显著基因。这是一个灾难性的设计缺陷，使得预期的分析无法进行。\n**结论：正确**\n\nD. 样本元数据中的条件标签被意外地为所有样本设置了相同的值，因此该方法测试了一个空对比，并返回没有显著基因的结果。\n这是一种常见的用户错误。统计软件依赖元数据表将样本与其各自的条件关联起来。如果错误地将所有样本都分配给了同一个条件（例如，“条件1”），那么软件实际上是在被要求将“条件1”与自身进行比较。这是一个空对比。根据定义，真实的生物学差异为 $0$。统计检验将正确地发现没有差异的证据。估计的倍数变化将围绕 $0$ 居中，由此产生的 $p$-值将会很高（在 $0$ 和 $1$ 之间均匀分布）。经过多重检验校正后，任何基因被宣布为显著的可能性都极低。\n**结论：正确**\n\nE. 主成分分析（PCA）的前两个主成分的散点图显示组间存在重叠；因此，不可能存在差异表达，所以预期会有零个发现。\nPCA是一种无监督方法，它总结数据中方差的主要轴。如果样本按条件清晰地聚类，这表明条件效应是方差的一个大来源。如果它们重叠，这表明其他因素（例如，重复间的变异性、批次效应）相对于条件效应来说很大。虽然这种重叠与弱生物信号从而导致的低功效是一致的（使得零发现成为一个可能的结果），但该选项中提出的推理是错误的。“因此，不可能存在差异表达”这一说法是一个无效的结论。PCA反映的是所有基因中最主要的方差来源。可能有一小部分基因存在强烈的差异表达，但它们的信号在被前几个主成分捕获的整体方差结构中被“淹没”了。PCA图上缺乏分离并不能排除DE基因的存在。它是一种症状，而不能保证结果为空。该解释在逻辑上有缺陷。\n**结论：不正确**\n\nF. 真实的潜在生物学机制在条件之间几乎没有表达变化；也就是说，对于所有基因，原假设 $H_0$ 都为真，因此在 $q=0.05$ 的水平上进行FDR控制后，获得 $0$ 个拒绝是合理的。\n这就是“全局原假设”。被比较的实验条件完全有可能在转录水平上不引起任何实质性的基因表达变化。在这种情况下，原假设（$H_0$：表达无差异）对所有或几乎所有基因都为真。统计检验和FDR控制的目的恰恰是为了在这种情况下避免做出错误的发现。当所有原假设都为真时，产生的原始 $p$-值预计将服从一个Uniform($0,1$)分布。像Benjamini-Hochberg这样的FDR程序被设计为在全局原假设下是保守的，最可能的结果是拒绝零个假设（即找到零个显著基因）。这不是一个错误，而是统计方法的正确运作。\n**结论：正确**\n\nG. 当检验许多基因时，在 $q=0.05$ 水平上的 Benjamini–Hochberg FDR 程序总能产生至少一些发现；因此，零个显著基因意味着软件错误，而不是一个合理的结果。\n这个陈述在事实上是不正确的。Benjamini-Hochberg（BH）程序不保证会有发现。它提供的是关于假发现比例的统计保证，*前提是做出了任何发现*。该程序首先对所有 $m$ 个原始 $p$-值进行排序：$p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(m)}$。然后找到满足 $p_{(k)} \\le \\frac{k}{m}q$ 的最大索引 $k$。如果连最小的 $p$-值 $p_{(1)}$ 都不满足此条件（即，如果 $p_{(1)} > q/m$），那么就不会有任何基因被宣布为显著。如在（A）、（B）和（F）中所讨论的，所有原始 $p$-值都不够小的情况非常常见，导致BH程序正确地报告零个发现。\n**结论：不正确**\n\nH. 在检验前移除了几乎所有基因的过度激进的独立过滤步骤不会降低发现的机会，因为它减轻了多重检验的负担，所以它不能解释零发现的结果。\n独立过滤旨在通过在检验前移除那些不大可能显示显著DE证据的基因（例如，表达计数非常低的基因）来提高统计功效。这减少了总检验数 $m$，使得多重检验校正不那么严格。然而，该选项描述的是“过度激进的”过滤。如果过滤标准过于严格，它们可能会错误地移除那些实际上是真正差异表达的基因。例如，基于高平均计数的过滤器可能会丢弃一个表达量低但具有很大且生物学上重要的倍数变化的基因。如果这些基因被移除，它们就永远不会被检验，因此也永远不会被发现。“过滤不会降低发现机会”这一前提是错误的；一个设计不当、过于激进的过滤器很容易成为发现零个显著基因的直接原因。\n**结论：不正确**\n\nI. 当真实效应同时存在于两个方向时，使用双侧检验而不是单侧检验会保证得到零个显著基因，因此检验方向的选择解释了没有发现的原因。\n这个陈述是不正确的。双侧检验（备择假设 $H_A: \\beta \\neq 0$）是DE分析的标准和适当选择，因为它旨在检测任何方向（上调或下调）的表达变化。真实效应存在于两个方向是典型的生物学情景。双侧检验并不会“保证”零发现；它完全有能力检测到它们。虽然单侧检验（$H_A: \\beta > 0$ 或 $H_A: \\beta < 0$）对于预先指定方向的效应更具功效，但它将没有能力检测相反方向的效应。使用双侧检验是一种标准、合理的做法，不能解释完全没有发现的情况。\n**结论：不正确**\n\n合理原因总结：A、B、C、D、F。", "answer": "$$\\boxed{ABCDF}$$", "id": "2385515"}]}