{"hands_on_practices": [{"introduction": "在构建复杂的基因预测模型之前，理解基线情况至关重要：仅凭偶然，基因样的特征（开放阅读框，Open Reading Frames, ORFs）出现的频率有多高？这个练习将利用概率论，从第一性原理出发计算随机基因组中假阳性开放阅读框的期望数量。通过这个实践，你将体会到为什么仅仅依赖开放阅读框的长度不足以作为基因预测的可靠标准。[@problem_id:2419180]", "problem": "给定一个应用于原核生物脱氧核糖核酸（DNA）序列的开放阅读框（ORF）预测的形式化模型。假设一个基因组是基于字母表 $\\{A,C,G,T\\}$ 生成的独立同分布序列，其碱基概率 $p_A$、$p_C$、$p_G$ 和 $p_T$ 的总和为 $1$。一个开放阅读框（ORF）在选定的链和阅读框上定义如下：从与该阅读框对齐的某个位置开始，如果其三联体密码子是规范起始密码子集合 $\\{ATG,TTG,GTG\\}$ 中的一个，则翻译过程在同一阅读框内逐个密码子进行，直到遇到第一个框内终止密码子（来自集合 $\\{TAA,TAG,TGA\\}$）为止。该 ORF 是指从起始密码子开始，到终止密码子之前（不包括终止密码子）的序列。ORF 长度（以密码子为单位）定义为从起始密码子（含）到终止密码子（不含）之间的密码子数量。\n\n一个预测的 ORF 是指任何长度至少为指定最小长度 $L_{\\min}$（单位为密码子，如上定义）的 ORF。一个标准的 ORF 查找器被假定在指定数量的阅读框 $F \\in \\{3,6\\}$ 中扫描所有密码子对齐的位置，其中 $F=3$ 表示三个正向阅读框，$F=6$ 表示三个正向阅读框和三个反向互补阅读框。在每个阅读框中，它会独立于其他阅读框，评估所有可能的密码子对齐的起始位置。\n\n在此设定下，将假阳性率（FPR）定义为在一个不包含任何真实基因的基因组中（因此每个报告的 ORF 都是伪 ORF），每兆碱基（即每 $1000000$ 个核苷酸）预测出的 ORF 的期望数量。在由 $(p_A,p_T,p_G,p_C)$ 指定的独立同分布碱基模型下，您必须从第一性原理出发，精确计算此期望值，并假设基因组非常长，以至于边界效应可以忽略不计。为了转换为每兆碱基的数量，使用 $N=1000000$ 个核苷酸的基因组长度，并且每帧只计算完整的密码子起始位点，即每帧使用 $\\left\\lfloor N/3 \\right\\rfloor$ 个密码子对齐的起始位置。\n\n您的任务是编写一个完整的程序，针对以下参数集测试套件，为每种情况返回每兆碱基中伪预测 ORF 的期望数量（实数）。每个测试用例指定为 $(p_A,p_T,p_G,p_C,L_{\\min},F)$：\n\n- 测试用例 1：$(0.45,\\,0.40,\\,0.10,\\,0.05,\\,100,\\,6)$。\n- 测试用例 2：$(0.49,\\,0.41,\\,0.06,\\,0.04,\\,50,\\,6)$。\n- 测试用例 3：$(0.40,\\,0.40,\\,0.10,\\,0.10,\\,75,\\,6)$。\n- 测试用例 4：$(0.25,\\,0.25,\\,0.25,\\,0.25,\\,50,\\,6)$。\n- 测试用例 5：$(0.50,\\,0.35,\\,0.10,\\,0.05,\\,30,\\,3)$。\n- 测试用例 6：$(0.50,\\,0.35,\\,0.10,\\,0.05,\\,300,\\,6)$。\n\n要求与约定：\n\n- 在每个测试用例中，碱基概率必须满足 $p_A+p_T+p_G+p_C=1$；所有给定的用例均已满足此条件。\n- 起始密码子集合恰好为 $\\{ATG,TTG,GTG\\}$，终止密码子集合恰好为 $\\{TAA,TAG,TGA\\}$。\n- 为每个测试用例报告每 $1000000$ 个核苷酸中伪预测 ORF 的期望数量，结果为实数。\n- 最终输出格式：您的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表（例如 $[x_1,x_2,\\dots,x_6]$），其结果顺序与上述测试用例相同。输出行中不允许有任何额外的文本或空白字符。", "solution": "问题陈述已经过验证，被认为是有效的。这是一个适定 (well-posed) 的、有科学依据的计算生物学问题，需要应用概率论的第一性原理来解决。\n\n目标是计算随机脱氧核糖核酸（DNA）每兆碱基中伪预测开放阅读框（ORF）的期望数量。这个量被定义为假阳性率（FPR）。基因组模型是一个由字母表 $\\{A, C, G, T\\}$ 中的核苷酸组成的独立同分布（IID）序列，其概率由给定的 $p_A$、$p_C$、$p_G$ 和 $p_T$ 决定。\n\n设 $E[N_{\\text{ORF}}]$ 为在长度为 $N = 1000000$ 个核苷酸的序列中预测 ORF 的期望数量。一个预测的 ORF 是指长度至少为 $L_{\\min}$ 个密码子的 ORF。对 ORF 的搜索在 $F$ 个阅读框上进行。\n\n根据期望的线性性，预测 ORF 的总期望数量是从每个可能位置开始找到一个预测 ORF 的期望之和。由于序列的独立同分布特性，在任何给定的密码子对齐位置上开始一个预测 ORF 的概率是恒定的。\n\n待测试的密码子对齐位置总数是阅读框数 $F$ 与每个阅读框起始位置数的乘积。对于长度为 $N$ 的序列，在单个阅读框中有 $\\lfloor N/3 \\rfloor$ 个不重叠的密码子位置。\n测试位点的数量为 $F \\times \\lfloor N/3 \\rfloor$。\n给定 $N = 1000000$，每个阅读框的位置数为 $\\lfloor 1000000/3 \\rfloor = 333333$。\n\n因此，总期望为：\n$$ E[N_{\\text{ORF}}] = F \\times \\left\\lfloor \\frac{N}{3} \\right\\rfloor \\times P(\\text{predicted ORF}) $$\n其中 $P(\\text{predicted ORF})$ 是在一个任意的密码子对齐位置上开始一个预测 ORF 的概率。\n\n要使一个预测的 ORF 在给定位置开始，必须独立满足两个条件：\n$1$. 该位置的密码子必须是一个起始密码子。\n$2$. 所得 ORF 的长度必须至少为 $L_{\\min}$ 个密码子。\n\n让我们来计算这些事件的概率。\n起始密码子的集合是 $\\mathcal{S} = \\{ATG, TTG, GTG\\}$。一个起始密码子的概率 $P(\\text{start})$ 是每个起始密码子概率的总和，根据碱基概率 $p_A, p_T, p_G, p_C$ 计算得出：\n$$ P(\\text{start}) = P(ATG) + P(TTG) + P(GTG) $$\n$$ P(\\text{start}) = (p_A \\cdot p_T \\cdot p_G) + (p_T \\cdot p_T \\cdot p_G) + (p_G \\cdot p_T \\cdot p_G) $$\n\n终止密码子的集合是 $\\mathcal{T} = \\{TAA, TAG, TGA\\}$。一个随机密码子是终止密码子的概率 $P(\\text{stop})$ 为：\n$$ P(\\text{stop}) = P(TAA) + P(TAG) + P(TGA) $$\n$$ P(\\text{stop}) = (p_T \\cdot p_A \\cdot p_A) + (p_T \\cdot p_A \\cdot p_G) + (p_T \\cdot p_G \\cdot p_A) $$\n一个随机密码子不是终止密码子的概率是 $P(\\text{non-stop}) = 1 - P(\\text{stop})$。\n\nORF 定义为从起始密码子开始，到第一个框内终止密码子之前（不包括终止密码子）的序列。ORF 的长度是它包含的密码子数量。要使一个 ORF 的长度至少为 $L_{\\min}$，起始密码子之后的第一个 $L_{\\min}-1$ 个密码子必须全部是非终止密码子。\n起始位置之后的一系列密码子是一连串的独立试验。一个 ORF 长度至少为 $L_{\\min}$ 的概率，等于一个长度为 $L_{\\min}-1$ 的密码子序列不包含任何终止密码子的概率。\n$$ P(\\text{length} \\ge L_{\\min}) = (P(\\text{non-stop}))^{L_{\\min}-1} = (1 - P(\\text{stop}))^{L_{\\min}-1} $$\n\n在一个特定位点上开始一个预测 ORF 的概率是起始密码子概率与后续 ORF 足够长的概率的乘积：\n$$ P(\\text{predicted ORF}) = P(\\text{start}) \\times P(\\text{length} \\ge L_{\\min}) $$\n$$ P(\\text{predicted ORF}) = P(\\text{start}) \\times (1 - P(\\text{stop}))^{L_{\\min}-1} $$\n\n最后，我们将此代入预测 ORF 总期望数量的表达式中：\n$$ E[N_{\\text{ORF}}] = F \\times \\left\\lfloor \\frac{N}{3} \\right\\rfloor \\times P(\\text{start}) \\times (1 - P(\\text{stop}))^{L_{\\min}-1} $$\n\n代入明确的概率公式和 $N=1000000$ 的值：\n$$ E[N_{\\text{ORF}}] = F \\times 333333 \\times (p_A p_T p_G + p_T^2 p_G + p_G p_T p_G) \\times (1 - (p_T p_A^2 + p_T p_A p_G + p_T p_G p_A))^{L_{\\min}-1} $$\n\n对每个给定的测试用例实施此公式，以计算所需的值。", "answer": "```python\nimport math\n\ndef solve():\n    \"\"\"\n    Computes the expected number of spurious predicted ORFs per megabase.\n    \"\"\"\n    test_cases = [\n        # (p_A, p_T, p_G, p_C, L_min, F)\n        (0.45, 0.40, 0.10, 0.05, 100, 6),\n        (0.49, 0.41, 0.06, 0.04, 50, 6),\n        (0.40, 0.40, 0.10, 0.10, 75, 6),\n        (0.25, 0.25, 0.25, 0.25, 50, 6),\n        (0.50, 0.35, 0.10, 0.05, 30, 3),\n        (0.50, 0.35, 0.10, 0.05, 300, 6),\n    ]\n\n    results = []\n    \n    # Genome length for calculation (per megabase)\n    N = 1000000\n    \n    # Number of codon-aligned start positions per frame\n    num_positions_per_frame = N // 3\n\n    for case in test_cases:\n        p_A, p_T, p_G, p_C, L_min, F = case\n\n        # Calculate the probability of encountering a start codon {ATG, TTG, GTG}\n        # P(start) = P(ATG) + P(TTG) + P(GTG) = pA*pT*pG + pT*pT*pG + pG*pT*pG\n        p_start = (p_A * p_T * p_G) + (p_T * p_T * p_G) + (p_G * p_T * p_G)\n\n        # Calculate the probability of encountering a stop codon {TAA, TAG, TGA}\n        # P(stop) = P(TAA) + P(TAG) + P(TGA) = pT*pA*pA + pT*pA*pG + pT*pG*pA\n        p_stop = (p_T * p_A * p_A) + (p_T * p_A * p_G) + (p_T * p_G * p_A)\n\n        # The probability of a codon not being a stop codon\n        p_non_stop = 1.0 - p_stop\n\n        # An ORF is predicted if its length is >= L_min. This means the first L_min-1\n        # codons after the start codon must be non-stop codons.\n        # The probability of this event for an ORF is P(non_stop)^(L_min - 1).\n        if L_min > 1:\n            prob_long_enough = p_non_stop ** (L_min - 1)\n        else: # L_min=1 means any start codon is a predicted ORF of sufficient length.\n            prob_long_enough = 1.0\n\n        # The probability of a predicted ORF at a single codon-aligned site\n        # is P(start) * P(length >= L_min).\n        prob_predicted_orf_at_site = p_start * prob_long_enough\n\n        # The total number of sites to check is F * num_positions_per_frame.\n        total_sites = F * num_positions_per_frame\n\n        # By linearity of expectation, the total expected number is num_sites * probability_per_site.\n        expected_orfs = total_sites * prob_predicted_orf_at_site\n        results.append(expected_orfs)\n\n    # Format the final output as a comma-separated list in brackets.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "2419180"}, {"introduction": "超越简单的开放阅读框扫描，本练习将探索两种识别基因边界的核心策略。你将实现一个基于特定基序（motif）的确定性扫描器和一个简单的概率模型（隐马尔可夫模型, Hidden Markov Model, HMM），并比较它们的性能。这项实践有助于深入理解生物信息学中不同建模哲学之间的权衡和考量。[@problem_id:2419168]", "problem": "您的任务是实现并评估两种不同的序列标注模型，用于在原核生物脱氧核糖核酸（DNA）序列中识别基因边界。每个序列是一个由字母表 $\\{A,C,G,T\\}$ 构成的字符串。在此，一个基因被定义为位于正向链上的一个连续编码区段，其起始于集合 $\\{ATG,GTG,TTG\\}$ 中的一个起始密码子，并终止于其后的第一个来自集合 $\\{TAA,TAG,TGA\\}$ 的终止密码子。起始边界索引定义为起始密码子第一个碱基的从零开始的索引，而终止边界索引定义为终止密码子最后一个碱基的从零开始的索引。本问题中的所有索引均为从零开始计数。\n\n将使用以下两种模型来预测基因边界。\n\n1) 模型 A (概率性双状态一阶模型):\n\n- 状态：基因间区 ($I$) 和编码区 ($C$)。\n- 初始状态概率: $\\pi_I = 0.8$, $\\pi_C = 0.2$。\n- 状态转移概率: $P(I \\to I) = 0.98$, $P(I \\to C) = 0.02$, $P(C \\to C) = 0.98$, $P(C \\to I) = 0.02$。\n- 字母表 $\\{A,C,G,T\\}$ 上的发射概率:\n  - 对于 $I$: $P(A|I) = 0.3$, $P(C|I) = 0.2$, $P(G|I) = 0.2$, $P(T|I) = 0.3$。\n  - 对于 $C$: $P(A|C) = 0.2$, $P(C|C) = 0.3$, $P(G|C) = 0.3$, $P(T|C) = 0.2$。\n- 给定一个长度为 $L$ 的序列 $s$，最可能的状态路径 $z_{1:L}$ 是指在上述参数下使联合概率最大化的路径。当路径在位置 $t$ 从 $I$ 转换到 $C$ 时，预测一个位于索引 $t$ 的起始边界；当路径在位置 $t$ 从 $C$ 转换到 $I$ 时，预测一个位于索引 $t-1$ 的终止边界。如果最可能的路径在位置 $L-1$ 处以 $C$ 结束，则预测在索引 $L-1$ 处有一个终止边界。如果路径在位置 $0$ 处以 $C$ 开始，则预测在索引 $0$ 处有一个起始边界。\n\n2) 模型 B (确定性递归基序驱动边界检测器):\n\n- 令 $S = \\{ATG,GTG,TTG\\}$ 为起始密码子集合，令 $P = \\{TAA,TAG,TGA\\}$ 为终止密码子集合。\n- 为序列 $s$ 定义指示函数：\n  - 如果 $s[t:t+3] \\in S$，则 $m_s(t) = 1$，否则 $m_s(t) = 0$。该函数在 $t \\in \\{0,1,\\ldots,L-3\\}$ 时有定义，对于 $t>L-3$，$m_s(t)=0$。\n  - 如果 $t \\ge 2$ 且 $s[t-2:t+1] \\in P$，则 $m_p(t) = 1$，否则 $m_p(t) = 0$。\n- 初始化一个二元基因内状态 $y_{-1} = 0$。对于从 $0$ 到 $L-1$ 的 $t$：\n  - 如果 $y_{t-1} = 0$ 且 $m_s(t) = 1$，则记录一个位于索引 $t$ 的起始边界，并设置 $y_t = 1$。\n  - 否则，如果 $y_{t-1} = 1$ 且 $m_p(t) = 1$，则记录一个位于索引 $t$ 的终止边界，并设置 $y_t = 0$。\n  - 否则，设置 $y_t = y_{t-1}$。\n- 模型 B 的预测边界集合是所有记录的起始和终止索引的集合。\n\n评估指标：\n\n- 对于一个给定的序列，令 $B_{\\text{true}}$ 为真实边界索引的集合，令 $B_{\\text{pred}}$ 为模型预测的边界索引的集合。定义真阳性 $TP = |B_{\\text{true}} \\cap B_{\\text{pred}}|$，假阳性 $FP = |B_{\\text{pred}} \\setminus B_{\\text{true}}|$，以及假阴性 $FN = |B_{\\text{true}} \\setminus B_{\\text{pred}}|$。当 $TP+FP > 0$ 时，定义精确率 $p = \\frac{TP}{TP+FP}$；当 $TP+FN > 0$ 时，定义召回率 $r = \\frac{TP}{TP+FN}$。当 $p+r>0$ 时，F1分数为 $F1 = \\frac{2pr}{p+r}$。特殊情况：如果 $|B_{\\text{true}}| = 0$ 且 $|B_{\\text{pred}}| = 0$，则定义 $F1 = 1$。\n- 对以下每个测试用例，计算模型 A 和模型 B 的 F1 分数。将每个 F1 分数表示为四舍五入到三位小数的小数。\n\n测试套件：\n\n- 测试用例 1：序列 $s_1 = $ \"AAAGGAGGCCATGAAACCCGGGTTTTAATTT\"。真实的起始边界索引是 $10$（位于索引 $10$–$12$ 的 \"ATG\" 中的 \"A\"），真实的终止边界索引是 $27$（位于索引 $25$–$27$ 的 \"TAA\" 中的最后一个 \"A\"）。因此，$B_{\\text{true},1} = \\{10, 27\\}$。\n- 测试用例 2：序列 $s_2 = $ \"ATGCCCGGGCCCTAGAAAA\"。真实的起始边界索引是 $0$（位于索引 $0$–$2$ 的 \"ATG\" 中的 \"A\"），真实的终止边界索引是 $14$（位于索引 $12$–$14$ 的 \"TAG\" 中的 \"G\"）。因此，$B_{\\text{true},2} = \\{0, 14\\}$。\n- 测试用例 3：序列 $s_3 = $ \"ACACACACACACACACGGCGGCCGCGGCCG\"。序列 $s_3$ 中不包含来自上述集合的起始或终止密码子，所以 $B_{\\text{true},3} = \\emptyset$。\n\n要求的最终输出格式：\n\n- 您的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表。按顺序为每个测试用例输出一个双元素列表 $[F1_{\\text{A}}, F1_{\\text{B}}]$，其中 $F1_{\\text{A}}$ 是模型 A 的 F1 分数，$F1_{\\text{B}}$ 是模型 B 的 F1 分数，两者均四舍五入到三位小数。例如，总输出必须采用 \"[[a1,b1],[a2,b2],[a3,b3]]\" 的形式，其中每个 $a_i$ 和 $b_i$ 都是四舍五入到三位小数的小数。", "solution": "该问题是计算生物学领域一个明确定义的练习，特别是在原核生物基因预测方面。它要求实现和评估两种不同的模型来识别基因边界。经过严格的验证过程，该问题被认为是具有科学依据、问题明确且客观的。所有必要的参数、定义和测试用例都已提供，并且没有内部矛盾或逻辑缺陷。评估指标 F1 分数是标准指标，其计算方法，包括指定的边界情况和未定义场景的标准解释，都是可行的。因此，该问题是有效的，并将提供一个完整的解决方案。\n\n解决方案包含两个主要部分：实现预测模型（模型 A 和模型 B），然后使用 F1 分数评估它们的预测结果与提供的真实标签。\n\n**模型 A：概率性双状态一阶模型**\n\n该模型是一个隐马尔可夫模型（HMM），具有两个状态：基因间区（$I$）和编码区（$C$）。目标是为给定的 DNA 序列找到最可能的状态序列，并从中推断出基因边界。维特比算法是完成此任务的标准方法。\n\n该 HMM 由以下参数定义：\n-   **状态：** $\\mathcal{S} = \\{I, C\\}$。为了计算方便，我们将它们映射到索引 $\\{0, 1\\}$。\n-   **观测（字母表）：** $\\mathcal{O} = \\{A, C, G, T\\}$，映射到索引 $\\{0, 1, 2, 3\\}$。\n-   **初始状态概率 ($\\boldsymbol{\\pi}$):** 模型以给定状态开始的概率。\n    $$ \\pi_I = P(z_0=I) = 0.8 $$\n    $$ \\pi_C = P(z_0=C) = 0.2 $$\n-   **转移概率 ($\\mathbf{A}$):** 从一个状态转移到另一个状态的概率。\n    $$ A = \\begin{pmatrix} P(I|I) & P(C|I) \\\\ P(I|C) & P(C|C) \\end{pmatrix} = \\begin{pmatrix} 0.98 & 0.02 \\\\ 0.02 & 0.98 \\end{pmatrix} $$\n-   **发射概率 ($\\mathbf{B}$):** 在给定状态下观测到特定核苷酸的概率。\n    $$ P(\\text{obs}|I) = \\{P(A|I)=0.3, P(C|I)=0.2, P(G|I)=0.2, P(T|I)=0.3\\} $$\n    $$ P(\\text{obs}|C) = \\{P(A|C)=0.2, P(C|C)=0.3, P(G|C)=0.3, P(T|C)=0.2\\} $$\n\n为避免长序列出现数值下溢，维特比算法在对数空间中实现。设输入序列为 $s$，长度为 $L$，索引为 $0, \\dots, L-1$。\n\n1.  **初始化 ($t=0$):** 对于每个状态 $k \\in \\{I, C\\}$，分数 $\\delta_0(k)$ 是以状态 $k$ 开始并发出第一个观测值 $s_0$ 的对数概率。\n    $$ \\delta_0(k) = \\log(\\pi_k) + \\log(B_k(s_0)) $$\n    初始化一个回溯指针表 $\\psi$: $\\psi_0(k) = 0$。\n\n2.  **递归 ($t=1, \\dots, L-1$):** 对于每个状态 $j \\in \\{I, C\\}$，我们找到在时间 $t$ 结束于状态 $j$ 的最可能路径。\n    $$ \\delta_t(j) = \\max_{i \\in \\{I, C\\}} (\\delta_{t-1}(i) + \\log(A_{ij})) + \\log(B_j(s_t)) $$\n    回溯指针存储使概率最大化的状态 $i$：\n    $$ \\psi_t(j) = \\arg\\max_{i \\in \\{I, C\\}} (\\delta_{t-1}(i) + \\log(A_{ij})) $$\n\n3.  **终止和回溯:** 最可能的最终状态是 $z_{L-1} = \\arg\\max_{k \\in \\{I, C\\}} (\\delta_{L-1}(k))$。路径的其余部分 $z_{L-2}, \\dots, z_0$ 通过跟随回溯指针找到：$z_{t-1} = \\psi_t(z_t)$。\n\n4.  **边界预测:** 扫描得到的维特比路径 $z_0, \\dots, z_{L-1}$，根据问题规则识别边界：\n    -   如果 $z_0 = C$，在索引 $0$ 处预测一个起始边界。\n    -   对于 $t \\in \\{1, \\dots, L-1\\}$，如果 $z_{t-1}=I$ 且 $z_t=C$，在索引 $t$ 处预测一个起始边界。\n    -   对于 $t \\in \\{1, \\dots, L-1\\}$，如果 $z_{t-1}=C$ 且 $z_t=I$，在索引 $t-1$ 处预测一个终止边界。\n    -   如果路径以 $z_{L-1}=C$ 结尾，在索引 $L-1$ 处预测一个终止边界。\n\n**模型 B：确定性递归基序驱动边界检测器**\n\n该模型是一个简单的有限状态自动机，它扫描序列以寻找起始和终止密码子。其行为是完全确定性的。\n\n-   **状态:** 一个二元变量 $y_t \\in \\{0, 1\\}$，其中 $y_t=0$ 表示在步骤 $t$ 处于基因间区，$y_t=1$ 表示处于基因内区域。初始状态为 $y_{-1}=0$。\n-   **密码子集合:** 起始密码子 $S = \\{ATG, GTG, TTG\\}$ 和终止密码子 $P = \\{TAA, TAG, TGA\\}$。\n-   **逻辑:** 模型从索引 $t=0$ 到 $L-1$ 遍历序列。在每个位置 $t$，它根据以下规则更新其状态：\n    1.  如果当前状态是基因间区 ($y_{t-1}=0$) 并且在索引 $t$ 处开始一个来自 $S$ 的起始密码子（即 $s[t:t+3] \\in S$），则在索引 $t$ 处记录一个起始边界，并将状态转换为基因内区 ($y_t=1$)。\n    2.  如果当前状态是基因内区 ($y_{t-1}=1$) 并且在索引 $t$ 处结束一个来自 $P$ 的终止密码子（即 $s[t-2:t+1] \\in P$），则在索引 $t$ 处记录一个终止边界，并将状态转换为基因间区 ($y_t=0$)。\n    3.  否则，状态保持不变 ($y_t = y_{t-1}$)。\n-   所有记录的起始和终止索引的集合构成了预测的边界 $B_{\\text{pred}}$。这种自动机结构确保它找到不重叠、交替出现的起始和终止位点。\n\n**评估指标：F1 分数**\n\n对于每个模型，预测的边界集合 $B_{\\text{pred}}$ 与真实边界集合 $B_{\\text{true}}$ 进行比较。性能由 F1 分数量化。\n\n-   **计数:**\n    -   真阳性 ($TP$): $|B_{\\text{true}} \\cap B_{\\text{pred}}|$\n    -   假阳性 ($FP$): $|B_{\\text{pred}} \\setminus B_{\\text{true}}|$\n    -   假阴性 ($FN$): $|B_{\\text{true}} \\setminus B_{\\text{pred}}|$\n-   **指标:**\n    -   精确率 ($p$): 如果 $TP+FP > 0$, 则 $p = \\frac{TP}{TP+FP}$，否则 $p=0$。\n    -   召回率 ($r$): 如果 $TP+FN > 0$, 则 $r = \\frac{TP}{TP+FN}$，否则 $r=0$。\n-   **F1 分数:**\n    -   主要公式为如果 $p+r > 0$, 则 $F1 = \\frac{2pr}{p+r}$，否则 $F1=0$。\n    -   定义了一个特殊情况：如果 $|B_{\\text{true}}| = 0$ 且 $|B_{\\text{pred}}| = 0$，则 $F1 = 1$。\n\n提供的 Python 代码实现了这些模型和评估指标，以解决给定的测试用例。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the gene prediction models on test cases and print the results.\n    \"\"\"\n\n    def model_a_predict(s: str) -> set:\n        \"\"\"\n        Predicts gene boundaries using the probabilistic two-state first-order model (Model A).\n        This is an HMM, and the most probable state path is found using the Viterbi algorithm.\n        \"\"\"\n        L = len(s)\n        if L == 0:\n            return set()\n\n        # Model Parameters\n        # States: 0=Intergenic (I), 1=Coding (C)\n        # Observations: 0=A, 1=C, 2=G, 3=T\n        char_to_int = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n        obs = np.array([char_to_int[c] for c in s], dtype=int)\n        \n        num_states = 2\n        pi = np.array([0.8, 0.2])\n        A = np.array([[0.98, 0.02], [0.02, 0.98]])\n        B = np.array([[0.3, 0.2, 0.2, 0.3], [0.2, 0.3, 0.3, 0.2]])\n\n        # Use log probabilities for numerical stability\n        log_pi = np.log(pi)\n        log_A = np.log(A)\n        log_B = np.log(B)\n\n        # Viterbi algorithm\n        delta = np.zeros((L, num_states))\n        psi = np.zeros((L, num_states), dtype=int)\n\n        # Initialization step\n        delta[0, :] = log_pi + log_B[:, obs[0]]\n\n        # Recursion step\n        for t in range(1, L):\n            for j in range(num_states):\n                trans_prob = delta[t - 1, :] + log_A[:, j]\n                max_prob_idx = np.argmax(trans_prob)\n                max_prob = trans_prob[max_prob_idx]\n                delta[t, j] = max_prob + log_B[j, obs[t]]\n                psi[t, j] = max_prob_idx\n\n        # Backtracking to find the most probable path\n        path = np.zeros(L, dtype=int)\n        path[L - 1] = np.argmax(delta[L - 1, :])\n        for t in range(L - 2, -1, -1):\n            path[t] = psi[t + 1, path[t + 1]]\n\n        # Boundary extraction from the path\n        B_pred = set()\n        # Rule: If path begins in C, start boundary at 0\n        if path[0] == 1:\n            B_pred.add(0)\n        \n        # Rule: Transitions between states\n        for t in range(1, L):\n            if path[t-1] == 0 and path[t] == 1:  # I -> C transition\n                B_pred.add(t)\n            elif path[t-1] == 1 and path[t] == 0:  # C -> I transition\n                B_pred.add(t-1)\n        \n        # Rule: If path ends in C, stop boundary at L-1\n        if path[L - 1] == 1:\n            B_pred.add(L - 1)\n            \n        return B_pred\n\n    def model_b_predict(s: str) -> set:\n        \"\"\"\n        Predicts gene boundaries using the deterministic recurrent motif-driven detector (Model B).\n        \"\"\"\n        L = len(s)\n        if L == 0:\n            return set()\n        \n        start_codons = {\"ATG\", \"GTG\", \"TTG\"}\n        stop_codons = {\"TAA\", \"TAG\", \"TGA\"}\n        \n        B_pred = set()\n        # y=0: intergenic state, y=1: coding state\n        y = 0 \n        \n        for t in range(L):\n            if y == 0:\n                # Look for a start codon\n                if t + 3 <= L and s[t:t+3] in start_codons:\n                    B_pred.add(t)\n                    y = 1\n            else: # y == 1\n                # Look for a stop codon\n                if t >= 2 and s[t-2:t+1] in stop_codons:\n                    B_pred.add(t)\n                    y = 0\n        return B_pred\n\n    def calculate_f1(B_true: set, B_pred: set) -> float:\n        \"\"\"\n        Calculates the F1-score given true and predicted boundary sets.\n        \"\"\"\n        if not B_true and not B_pred:\n            return 1.0\n\n        tp = len(B_true.intersection(B_pred))\n        fp = len(B_pred.difference(B_pred))\n        fn = len(B_true.difference(B_pred))\n\n        # Handle division by zero for precision and recall\n        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n        \n        # Handle division by zero for F1-score\n        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n        \n        return f1\n\n    # Test suite from the problem statement\n    test_cases = [\n        (\"AAAGGAGGCCATGAAACCCGGGTTTTAATTT\", {10, 27}),\n        (\"ATGCCCGGGCCCTAGAAAA\", {0, 14}),\n        (\"ACACACACACACACACGGCGGCCGCGGCCG\", set())\n    ]\n\n    results = []\n    for s, B_true in test_cases:\n        # Model A\n        B_pred_a = model_a_predict(s)\n        f1_a = calculate_f1(B_true, B_pred_a)\n        \n        # Model B\n        B_pred_b = model_b_predict(s)\n        f1_b = calculate_f1(B_true, B_pred_b)\n        \n        results.append([f\"{f1_a:.3f}\", f\"{f1_b:.3f}\"])\n\n    # Format the final output string as specified\n    final_output = \"[\" + \",\".join([f\"[{a},{b}]\" for a, b in results]) + \"]\"\n    print(final_output)\n\nsolve()\n```", "id": "2419168"}, {"introduction": "现代基因预测工具通过整合多种生物信号来实现高准确性。本练习将介绍一个朴素贝叶斯（Naive Bayes）框架，用于将多个特征——例如隐马尔可夫模型（HMM）得分、密码子使用统计和核糖体结合位点基序——组合成一个单一的后验概率或置信度得分。这项实践演示了如何将多源证据进行形式化整合，以便更可靠地区分真实基因和虚假预测。[@problem_id:2419184]", "problem": "给定一个概率模型，用于为一个由隐马尔可夫模型 (HMM) 预测的基因是原核生物基因组中真实蛋白质编码基因的事件分配后验概率。对于每个预测的基因，您会观察到一个由五个分量组成的特征向量：一个 HMM 对数优势比分数 $s$、一个编码六聚体对数似然比 $h$、一个核糖体结合位点基序分数 $r$、基因的鸟嘌呤-胞嘧啶 (GC) 含量 $x \\in (0,1)$，以及起始密码子类别 $c \\in \\{\\text{ATG},\\text{GTG},\\text{TTG},\\text{OTHER}\\}$。设潜类别变量为 $G \\in \\{T,F\\}$，其中 $T$ 表示一个真实的蛋白质编码基因，$F$ 表示一个假预测。假设在给定 $G$ 的条件下，这些特征是条件独立的。\n\n设先验概率为 $P(G=T) = p_0$ 和 $P(G=F) = 1 - p_0$，其中 $p_0 = 0.7$。给定 $G$ 的特征条件分布规定如下。\n\n- 对于 HMM 对数优势比分数 $s$：\n  - $s \\mid G=T \\sim \\mathcal{N}(\\mu_s^T,\\ (\\sigma_s^T)^2)$，其中 $\\mu_s^T = 5$ 且 $\\sigma_s^T = 2$。\n  - $s \\mid G=F \\sim \\mathcal{N}(\\mu_s^F,\\ (\\sigma_s^F)^2)$，其中 $\\mu_s^F = 0$ 且 $\\sigma_s^F = 2$。\n\n- 对于编码六聚体对数似然比 $h$：\n  - $h \\mid G=T \\sim \\mathcal{N}(\\mu_h^T,\\ (\\sigma_h^T)^2)$，其中 $\\mu_h^T = 2$ 且 $\\sigma_h^T = 1.5$。\n  - $h \\mid G=F \\sim \\mathcal{N}(\\mu_h^F,\\ (\\sigma_h^F)^2)$，其中 $\\mu_h^F = -1$ 且 $\\sigma_h^F = 1.5$。\n\n- 对于核糖体结合位点基序分数 $r$：\n  - $r \\mid G=T \\sim \\mathcal{N}(\\mu_r^T,\\ (\\sigma_r^T)^2)$，其中 $\\mu_r^T = 3$ 且 $\\sigma_r^T = 1$。\n  - $r \\mid G=F \\sim \\mathcal{N}(\\mu_r^F,\\ (\\sigma_r^F)^2)$，其中 $\\mu_r^F = 0$ 且 $\\sigma_r^F = 1.5$。\n\n- 对于 GC 含量 $x$：\n  - $x \\mid G=T \\sim \\mathrm{Beta}(\\alpha_T,\\ \\beta_T)$，其中 $\\alpha_T = 55$ 且 $\\beta_T = 45$。\n  - $x \\mid G=F \\sim \\mathrm{Beta}(\\alpha_F,\\ \\beta_F)$，其中 $\\alpha_F = 35$ 且 $\\beta_F = 65$。\n\n- 对于起始密码子类别 $c$（分类变量）：\n  - $P(c=\\text{ATG} \\mid G=T)=0.83$, $P(c=\\text{GTG} \\mid G=T)=0.12$, $P(c=\\text{TTG} \\mid G=T)=0.04$, $P(c=\\text{OTHER} \\mid G=T)=0.01$。\n  - $P(c=\\text{ATG} \\mid G=F)=0.25$, $P(c=\\text{GTG} \\mid G=F)=0.25$, $P(c=\\text{TTG} \\mid G=F)=0.25$, $P(c=\\text{OTHER} \\mid G=F)=0.25$。\n\n使用以下密度函数和质量函数。\n\n- 对于正态分布， $X \\sim \\mathcal{N}(\\mu,\\ \\sigma^2)$ 的概率密度函数是\n  $$ f_{\\mathcal{N}}(x \\mid \\mu,\\ \\sigma) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma}\\exp\\!\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right). $$\n\n- 对于贝塔分布， $X \\sim \\mathrm{Beta}(\\alpha,\\ \\beta)$ 的概率密度函数是\n  $$ f_{\\mathrm{Beta}}(x \\mid \\alpha,\\ \\beta) = \\frac{x^{\\alpha-1}(1-x)^{\\beta-1}}{B(\\alpha,\\ \\beta)}, \\quad \\text{for } x \\in (0,1), $$\n  其中 $B(\\alpha,\\ \\beta) = \\dfrac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha+\\beta)}$ 且 $\\Gamma(\\cdot)$ 是伽马函数。\n\n- 对于分类变量，其概率质量函数是 $P(c=k \\mid G)=q_k$，对于具有指定概率 $q_k$ 的类别 $k$。\n\n对于一个观察到的特征向量 $e=(s,h,r,x,c)$，定义类条件似然\n$$ \\ell_T(e) = f_{\\mathcal{N}}(s \\mid \\mu_s^T,\\ \\sigma_s^T) \\cdot f_{\\mathcal{N}}(h \\mid \\mu_h^T,\\ \\sigma_h^T) \\cdot f_{\\mathcal{N}}(r \\mid \\mu_r^T,\\ \\sigma_r^T) \\cdot f_{\\mathrm{Beta}}(x \\mid \\alpha_T,\\ \\beta_T) \\cdot P(c \\mid G=T), $$\n$$ \\ell_F(e) = f_{\\mathcal{N}}(s \\mid \\mu_s^F,\\ \\sigma_s^F) \\cdot f_{\\mathcal{N}}(h \\mid \\mu_h^F,\\ \\sigma_h^F) \\cdot f_{\\mathcal{N}}(r \\mid \\mu_r^F,\\ \\sigma_r^F) \\cdot f_{\\mathrm{Beta}}(x \\mid \\alpha_F,\\ \\beta_F) \\cdot P(c \\mid G=F). $$\n\n使用 Bayes 定理，给定 $e$ 的真实基因的后验概率为\n$$ P(G=T \\mid e) = \\frac{p_0 \\cdot \\ell_T(e)}{p_0 \\cdot \\ell_T(e) + (1-p_0) \\cdot \\ell_F(e)}. $$\n\n您的任务是编写一个程序，对下面列出的每个测试案例，使用上述模型和定义计算 $P(G=T \\mid e)$。\n\n按所述顺序评估的观察特征向量 $(s,h,r,x,c)$ 测试套件：\n- 案例 Alpha: $(6.0,\\,2.5,\\,3.2,\\,0.56,\\,\\text{ATG})$。\n- 案例 Beta: $(3.0,\\,1.0,\\,2.0,\\,0.50,\\,\\text{GTG})$。\n- 案例 Gamma: $(1.0,\\,0.0,\\,0.5,\\,0.45,\\,\\text{TTG})$。\n- 案例 Delta: $(-1.0,\\,-1.5,\\,-0.5,\\,0.20,\\,\\text{OTHER})$。\n- 案例 Epsilon: $(12.0,\\,6.0,\\,6.0,\\,0.58,\\,\\text{ATG})$。\n- 案例 Zeta: $(-5.0,\\,-4.0,\\,-3.0,\\,0.10,\\,\\text{OTHER})$。\n\n最终输出格式：您的程序应生成单行输出，其中包含按上述确切顺序排列的各案例的后验概率，形式为一个用方括号括起来的逗号分隔的十进制数列表，每个值四舍五入到六位小数（例如，[$0.123456$,$0.654321$,$0.500000$,$0.000001$,$0.999999$,$0.250000$])。不应打印任何额外文本。", "solution": "该问题要求在给定一组观测特征的情况下，计算一个预测基因为真实蛋白质编码基因的后验概率。这是贝叶斯推断的一个经典应用，具体来说是使用朴素贝叶斯分类器。该模型假设在给定类别标签 $G \\in \\{T, F\\}$（其中 $T$ 表示真实基因，$F$ 表示假预测）的条件下，特征是条件独立的。\n\n解决方案的核心是应用 Bayes 定理。在给定证据（特征向量 $e=(s,h,r,x,c)$）的情况下，一个基因为真实（$G=T$）的后验概率由下式给出：\n$$ P(G=T \\mid e) = \\frac{P(e \\mid G=T) P(G=T)}{P(e)} $$\n先验概率 $P(G=T)$ 给定为 $p_0 = 0.7$。项 $P(e \\mid G=T)$ 是在基因为真实的情况下观测到证据 $e$ 的类条件似然。分母 $P(e)$ 是证据的总概率，可以使用全概率定律展开：\n$$ P(e) = P(e \\mid G=T)P(G=T) + P(e \\mid G=F)P(G=F) $$\n将此代入 Bayes 公式，并使用问题陈述中的符号 $\\ell_G(e) = P(e \\mid G)$ 表示似然以及 $P(G=F) = 1-p_0$，我们得到问题陈述中提供的表达式：\n$$ P(G=T \\mid e) = \\frac{p_0 \\cdot \\ell_T(e)}{p_0 \\cdot \\ell_T(e) + (1-p_0) \\cdot \\ell_F(e)} $$\n由于条件独立性假设，类条件似然 $\\ell_G(e)$ 是每个特征的单个概率密度或质量函数的乘积：\n$$ \\ell_G(e) = P(s \\mid G) \\cdot P(h \\mid G) \\cdot P(r \\mid G) \\cdot P(x \\mid G) \\cdot P(c \\mid G) $$\n每个特征的分布都有指定：连续特征 $s, h, r$ 服从正态分布（$\\mathcal{N}$），特征 $x$ 服从贝塔分布（$\\mathrm{Beta}$），离散特征 $c$ 服从分类分布。\n\n通过乘以概率密度直接计算似然 $\\ell_T(e)$ 和 $\\ell_F(e)$ 可能会导致数值下溢，因为这些值可能非常小。一种标准且稳健的技术是在对数空间中执行计算。对数似然 $L_G(e) = \\ln(\\ell_G(e))$ 是各个对数概率的总和：\n$$ L_G(e) = \\ln(P(s \\mid G)) + \\ln(P(h \\mid G)) + \\ln(P(r \\mid G)) + \\ln(P(x \\mid G)) + \\ln(P(c \\mid G)) $$\n正态分布 $\\mathcal{N}(\\mu, \\sigma^2)$ 的对数概率密度为：\n$$ \\ln(f_{\\mathcal{N}}(z \\mid \\mu, \\sigma)) = -\\ln(\\sigma) - \\frac{1}{2}\\ln(2\\pi) - \\frac{(z-\\mu)^2}{2\\sigma^2} $$\n贝塔分布 $\\mathrm{Beta}(\\alpha, \\beta)$ 的对数概率密度为：\n$$ \\ln(f_{\\mathrm{Beta}}(z \\mid \\alpha, \\beta)) = (\\alpha-1)\\ln(z) + (\\beta-1)\\ln(1-z) - \\ln(B(\\alpha, \\beta)) $$\n其中 $\\ln(B(\\alpha, \\beta)) = \\ln(\\Gamma(\\alpha)) + \\ln(\\Gamma(\\beta)) - \\ln(\\Gamma(\\alpha+\\beta))$。这些计算最好使用专用函数如 `scipy.stats.norm.logpdf`、`scipy.stats.beta.logpdf` 和 `scipy.special.gammaln` 来执行，以保持数值精度。分类变量的对数概率就是其给定概率质量的对数。\n\n为了使用对数似然计算后验概率，我们可以对公式进行代数变换：\n$$ P(G=T \\mid e) = \\frac{p_0 \\ell_T(e)}{p_0 \\ell_T(e) + (1-p_0) \\ell_F(e)} = \\frac{1}{1 + \\frac{(1-p_0) \\ell_F(e)}{p_0 \\ell_T(e)}} $$\n分母中的比率项可以使用对数量之差的指数来表示：\n$$ \\frac{(1-p_0) \\ell_F(e)}{p_0 \\ell_T(e)} = \\exp\\left( \\ln\\left( \\frac{(1-p_0) \\ell_F(e)}{p_0 \\ell_T(e)} \\right) \\right) = \\exp\\left( (\\ln(1-p_0) + L_F(e)) - (\\ln(p_0) + L_T(e)) \\right) $$\n这个变换后的表达式涉及一个 logistic (sigmoid) 函数，它在数值上是稳定的，并减轻了上溢或下溢的风险。\n\n计算流程如下：\n对于每个测试案例向量 $e = (s, h, r, x, c)$：\n1.  使用“真”类（$G=T$）的一组参数，通过对每个观测特征值的对数概率求和来计算对数似然 $L_T(e)$。\n2.  类似地，使用“假”类（$G=F$）的参数计算对数似然 $L_F(e)$。\n3.  计算先验优势比的对数，$\\ln(1-p_0) - \\ln(p_0)$。\n4.  组合这些项以找到后验优势比的对数：$Z = (\\ln(1-p_0) + L_F(e)) - (\\ln(p_0) + L_T(e))$。\n5.  计算最终的后验概率为 $P(G=T \\mid e) = \\frac{1}{1 + \\exp(Z)}$。\n6.  所有测试案例的结果被收集并格式化为六位小数，以逗号分隔的列表形式呈现。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm, beta\n\ndef solve():\n    \"\"\"\n    Computes the posterior probability that a predicted gene is a true\n    protein-coding gene based on a Naive Bayes model.\n    \"\"\"\n    # Define the model parameters for true (T) and false (F) gene classes.\n    # The parameters are for features: s, h, r, x, c.\n    params = {\n        'T': {\n            's': {'mu': 5.0, 'sigma': 2.0},\n            'h': {'mu': 2.0, 'sigma': 1.5},\n            'r': {'mu': 3.0, 'sigma': 1.0},\n            'x': {'alpha': 55.0, 'beta': 45.0},\n            'c': {'ATG': 0.83, 'GTG': 0.12, 'TTG': 0.04, 'OTHER': 0.01}\n        },\n        'F': {\n            's': {'mu': 0.0, 'sigma': 2.0},\n            'h': {'mu': -1.0, 'sigma': 1.5},\n            'r': {'mu': 0.0, 'sigma': 1.5},\n            'x': {'alpha': 35.0, 'beta': 65.0},\n            'c': {'ATG': 0.25, 'GTG': 0.25, 'TTG': 0.25, 'OTHER': 0.25}\n        }\n    }\n    \n    # Prior probability of being a true gene.\n    prior_p0 = 0.7\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (s, h, r, x, c)\n        (6.0, 2.5, 3.2, 0.56, 'ATG'),     # Case Alpha\n        (3.0, 1.0, 2.0, 0.50, 'GTG'),     # Case Beta\n        (1.0, 0.0, 0.5, 0.45, 'TTG'),     # Case Gamma\n        (-1.0, -1.5, -0.5, 0.20, 'OTHER'), # Case Delta\n        (12.0, 6.0, 6.0, 0.58, 'ATG'),    # Case Epsilon\n        (-5.0, -4.0, -3.0, 0.10, 'OTHER')  # Case Zeta\n    ]\n\n    results = []\n    \n    # Pre-compute log of priors for efficiency.\n    log_p0 = np.log(prior_p0)\n    log_1_minus_p0 = np.log(1.0 - prior_p0)\n\n    for s_obs, h_obs, r_obs, x_obs, c_obs in test_cases:\n        # Calculate log-likelihood for the \"True\" class (G=T).\n        # This is the sum of the log-probabilities of each feature given G=T.\n        log_L_T = (\n            norm.logpdf(s_obs, loc=params['T']['s']['mu'], scale=params['T']['s']['sigma']) +\n            norm.logpdf(h_obs, loc=params['T']['h']['mu'], scale=params['T']['h']['sigma']) +\n            norm.logpdf(r_obs, loc=params['T']['r']['mu'], scale=params['T']['r']['sigma']) +\n            beta.logpdf(x_obs, a=params['T']['x']['alpha'], b=params['T']['x']['beta']) +\n            np.log(params['T']['c'][c_obs])\n        )\n\n        # Calculate log-likelihood for the \"False\" class (G=F).\n        # This is the sum of the log-probabilities of each feature given G=F.\n        log_L_F = (\n            norm.logpdf(s_obs, loc=params['F']['s']['mu'], scale=params['F']['s']['sigma']) +\n            norm.logpdf(h_obs, loc=params['F']['h']['mu'], scale=params['F']['h']['sigma']) +\n            norm.logpdf(r_obs, loc=params['F']['r']['mu'], scale=params['F']['r']['sigma']) +\n            beta.logpdf(x_obs, a=params['F']['x']['alpha'], b=params['F']['x']['beta']) +\n            np.log(params['F']['c'][c_obs])\n        )\n\n        # Calculate the posterior probability P(G=T|e) using a numerically stable\n        # formula based on log-likelihoods.\n        # P(T|e) = 1 / (1 + exp(log( (1-p0)l_F / (p0 * l_T) )))\n        # log_ratio = log(1-p0) + log_L_F - (log(p0) + log_L_T)\n        \n        log_joint_T = log_p0 + log_L_T\n        log_joint_F = log_1_minus_p0 + log_L_F\n        \n        # This term is log( P(e, F) / P(e, T) )\n        log_odds_ratio = log_joint_F - log_joint_T\n        \n        posterior_T = 1.0 / (1.0 + np.exp(log_odds_ratio))\n        \n        results.append(posterior_T)\n\n    # Format the final output as a comma-separated list of values rounded to\n    # six decimal places, enclosed in square brackets.\n    formatted_results = [f'{r:.6f}' for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2419184"}]}