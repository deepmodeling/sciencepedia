{"hands_on_practices": [{"introduction": "现代基因组组装不仅仅依赖于单一来源的数据，而是通过整合多种实验证据来构建更准确的支架。此练习模拟了这一过程，采用贝叶斯框架来量化地评估一个潜在的支架连接。你将学习如何结合来自不同技术（如配对末端、光学图谱和Hi-C）的证据，以更新我们对一个连接是否正确的置信度，这体现了在面对不确定性和噪声数据时进行科学推理的核心原则。[@problem_id:2427655]", "problem": "给定一个形式化概率模型，用于根据基因组组装中常用的多种独立实验证据类型来评估两个重叠群 (contig) 之间建议的支架连接 (scaffold link) 是否正确。这些证据类型包括：mate-pair 文库 (mate-pair libraries)、光学图谱 (optical mapping) 和高通量染色体构象捕获 (High-throughput Chromosome Conformation Capture, Hi-C)。令二元事件 $L \\in \\{0,1\\}$ 表示建议的连接是否正确（$L=1$ 为正确，$L=0$ 为不正确）。对于集合 $\\mathcal{D} = \\{\\text{MP}, \\text{OM}, \\text{HC}\\}$ 中的每种数据类型 $d$，会记录一个观测值 $x_d \\in \\{+1,-1,0\\}$，其中 $+1$ 表示支持性证据（与连接一致），$-1$ 表示矛盾性证据（与连接不一致），$0$ 表示缺失或无信息证据。假设在给定 $L$ 的条件下，各观测值是条件独立的。\n\n对于每种数据类型 $d \\in \\mathcal{D}$，给定条件概率 $P(x_d=+1 \\mid L=1)$ 和 $P(x_d=+1 \\mid L=0)$ 作为模型参数。当 $x_d=-1$ 时，使用 $P(x_d=-1 \\mid L=1)=1-P(x_d=+1 \\mid L=1)$ 和 $P(x_d=-1 \\mid L=0)=1-P(x_d=+1 \\mid L=0)$。当 $x_d=0$ 时，观测值不应改变后验概率。\n\n您的任务是，在给定先验概率 $P(L=1)=p_0$ 和观测向量 $\\mathbf{x}=(x_{\\text{MP}},x_{\\text{OM}},x_{\\text{HC}})$ 的情况下，从第一性原理出发计算后验概率 $P(L=1 \\mid \\mathbf{x})$。条件独立性意味着\n$$\nP(\\mathbf{x}\\mid L=\\ell) \\;=\\; \\prod_{d\\in\\mathcal{D}} P(x_d\\mid L=\\ell), \\quad \\ell\\in\\{0,1\\}.\n$$\n使用贝叶斯法则 (Bayes' rule)：\n$$\nP(L=1\\mid \\mathbf{x}) \\;=\\; \\frac{p_0 \\cdot \\prod_{d\\in\\mathcal{D}} P(x_d\\mid L=1)}{p_0 \\cdot \\prod_{d\\in\\mathcal{D}} P(x_d\\mid L=1) + (1-p_0) \\cdot \\prod_{d\\in\\mathcal{D}} P(x_d\\mid L=0)}.\n$$\n\n所有概率都必须视为 $[0,1]$ 范围内的小数。\n\n对所有测试用例使用以下固定模型参数：\n- Mate-pair (MP): $P(x_{\\text{MP}}=+1 \\mid L=1)=0.9$, $P(x_{\\text{MP}}=+1 \\mid L=0)=0.1$。\n- 光学图谱 (Optical map, OM): $P(x_{\\text{OM}}=+1 \\mid L=1)=0.95$, $P(x_{\\text{OM}}=+1 \\mid L=0)=0.05$。\n- 高通量染色体构象捕获 (Hi-C) (HC): $P(x_{\\text{HC}}=+1 \\mid L=1)=0.85$, $P(x_{\\text{HC}}=+1 \\mid L=0)=0.2$。\n\n实现一个程序，为下列每个测试用例计算 $P(L=1\\mid \\mathbf{x})$，并将每个结果四舍五入到 $6$ 位小数：\n- 用例 1：$p_0=0.5$, $x_{\\text{MP}}=+1$, $x_{\\text{OM}}=+1$, $x_{\\text{HC}}=+1$。\n- 用例 2：$p_0=0.5$, $x_{\\text{MP}}=+1$, $x_{\\text{OM}}=-1$, $x_{\\text{HC}}=+1$。\n- 用例 3：$p_0=0.01$, $x_{\\text{MP}}=+1$, $x_{\\text{OM}}=+1$, $x_{\\text{HC}}=+1$。\n- 用例 4：$p_0=0.9$, $x_{\\text{MP}}=-1$, $x_{\\text{OM}}=-1$, $x_{\\text{HC}}=-1$。\n- 用例 5：$p_0=0.2$, $x_{\\text{MP}}=+1$, $x_{\\text{OM}}=0$, $x_{\\text{HC}}=-1$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的、逗号分隔的结果列表，每个值都四舍五入到 $6$ 位小数（例如 $[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4,\\text{result}_5]$）。不涉及物理单位，也不涉及角度。", "solution": "所给出的问题在科学上是合理的，在计算上是适定的。它要求将概率论的基本原理，特别是贝叶斯法则 (Bayes' rule)，应用于一个生物信息学问题。我们将从第一性原理出发推导解答。\n\n目标是计算在给定观测向量 $\\mathbf{x} = (x_{\\text{MP}}, x_{\\text{OM}}, x_{\\text{HC}})$ 的情况下，一个支架连接是正确的 ($L=1$) 的后验概率 $P(L=1 \\mid \\mathbf{x})$。一个正确连接的先验概率给定为 $P(L=1) = p_0$。\n\n根据贝叶斯法则，后验概率由下式给出：\n$$\nP(L=1 \\mid \\mathbf{x}) = \\frac{P(\\mathbf{x} \\mid L=1) P(L=1)}{P(\\mathbf{x})}\n$$\n分母中的项 $P(\\mathbf{x})$ 是证据的边际概率，使用全概率定律计算得出：\n$$\nP(\\mathbf{x}) = P(\\mathbf{x} \\mid L=1) P(L=1) + P(\\mathbf{x} \\mid L=0) P(L=0)\n$$\n鉴于 $P(L=0) = 1 - P(L=1) = 1 - p_0$，我们得到问题描述中提供的公式：\n$$\nP(L=1\\mid \\mathbf{x}) = \\frac{p_0 \\cdot P(\\mathbf{x}\\mid L=1)}{p_0 \\cdot P(\\mathbf{x}\\mid L=1) + (1-p_0) \\cdot P(\\mathbf{x}\\mid L=0)}\n$$\n问题陈述说明，在给定连接的真实状态 $L$ 的条件下，观测值是条件独立的。因此，对于 $\\ell \\in \\{0, 1\\}$，似然函数 $P(\\mathbf{x}\\mid L=\\ell)$ 是各个独立条件概率的乘积：\n$$\nP(\\mathbf{x}\\mid L=\\ell) = \\prod_{d\\in\\mathcal{D}} P(x_d\\mid L=\\ell)\n$$\n其中 $\\mathcal{D} = \\{\\text{MP}, \\text{OM}, \\text{HC}\\}$。\n\n对于每种数据类型 $d \\in \\mathcal{D}$ 和观测值 $x_d \\in \\{+1, -1, 0\\}$，其条件概率定义如下。支持性证据 ($x_d=+1$) 的参数已给出：\n- Mate-pair (MP): $P(x_{\\text{MP}}=+1 \\mid L=1) = 0.9$, $P(x_{\\text{MP}}=+1 \\mid L=0) = 0.1$。\n- 光学图谱 (OM): $P(x_{\\text{OM}}=+1 \\mid L=1) = 0.95$, $P(x_{\\text{OM}}=+1 \\mid L=0) = 0.05$。\n- Hi-C (HC): $P(x_{\\text{HC}}=+1 \\mid L=1) = 0.85$, $P(x_{\\text{HC}}=+1 \\mid L=0) = 0.2$。\n\n对于矛盾性证据 ($x_d=-1$)，概率推导如下：\n$$\nP(x_d = -1 \\mid L=\\ell) = 1 - P(x_d = +1 \\mid L=\\ell)\n$$\n这得出：\n- MP: $P(x_{\\text{MP}}=-1 \\mid L=1) = 0.1$, $P(x_{\\text{MP}}=-1 \\mid L=0) = 0.9$。\n- OM: $P(x_{\\text{OM}}=-1 \\mid L=1) = 0.05$, $P(x_{\\text{OM}}=-1 \\mid L=0) = 0.95$。\n- HC: $P(x_{\\text{HC}}=-1 \\mid L=1) = 0.15$, $P(x_{\\text{HC}}=-1 \\mid L=0) = 0.8$。\n\n对于缺失证据 ($x_d=0$)，观测值不能改变后验分布。这通过将此观测的似然比设为 $1$ 来实现。在我们的计算中，这等同于对 $\\ell=1$ 和 $\\ell=0$ 都设置 $P(x_d=0 \\mid L=\\ell) = 1$，从而有效地从乘积中移除了该项。\n\n现在我们为每个测试用例计算后验概率。\n\n**用例 1：** $p_0=0.5$, $\\mathbf{x}=(x_{\\text{MP}}=+1, x_{\\text{OM}}=+1, x_{\\text{HC}}=+1)$。\n- $L=1$ 的似然：$P(\\mathbf{x} \\mid L=1) = 0.9 \\times 0.95 \\times 0.85 = 0.72675$。\n- $L=0$ 的似然：$P(\\mathbf{x} \\mid L=0) = 0.1 \\times 0.05 \\times 0.2 = 0.001$。\n- 后验概率：$P(L=1 \\mid \\mathbf{x}) = \\frac{0.5 \\times 0.72675}{0.5 \\times 0.72675 + (1-0.5) \\times 0.001} = \\frac{0.363375}{0.363375 + 0.0005} = \\frac{0.363375}{0.363875} \\approx 0.998626$。\n\n**用例 2：** $p_0=0.5$, $\\mathbf{x}=(x_{\\text{MP}}=+1, x_{\\text{OM}}=-1, x_{\\text{HC}}=+1)$。\n- $L=1$ 的似然：$P(\\mathbf{x} \\mid L=1) = 0.9 \\times (1-0.95) \\times 0.85 = 0.9 \\times 0.05 \\times 0.85 = 0.03825$。\n- $L=0$ 的似然：$P(\\mathbf{x} \\mid L=0) = 0.1 \\times (1-0.05) \\times 0.2 = 0.1 \\times 0.95 \\times 0.2 = 0.019$。\n- 后验概率：$P(L=1 \\mid \\mathbf{x}) = \\frac{0.5 \\times 0.03825}{0.5 \\times 0.03825 + (1-0.5) \\times 0.019} = \\frac{0.019125}{0.019125 + 0.0095} = \\frac{0.019125}{0.028625} \\approx 0.668122$。\n\n**用例 3：** $p_0=0.01$, $\\mathbf{x}=(x_{\\text{MP}}=+1, x_{\\text{OM}}=+1, x_{\\text{HC}}=+1)$。\n- 似然与用例 1 中相同：$P(\\mathbf{x} \\mid L=1) = 0.72675$, $P(\\mathbf{x} \\mid L=0) = 0.001$。\n- 后验概率：$P(L=1 \\mid \\mathbf{x}) = \\frac{0.01 \\times 0.72675}{0.01 \\times 0.72675 + (1-0.01) \\times 0.001} = \\frac{0.0072675}{0.0072675 + 0.00099} = \\frac{0.0072675}{0.0082575} \\approx 0.880115$。\n\n**用例 4：** $p_0=0.9$, $\\mathbf{x}=(x_{\\text{MP}}=-1, x_{\\text{OM}}=-1, x_{\\text{HC}}=-1)$。\n- $L=1$ 的似然：$P(\\mathbf{x} \\mid L=1) = (1-0.9) \\times (1-0.95) \\times (1-0.85) = 0.1 \\times 0.05 \\times 0.15 = 0.00075$。\n- $L=0$ 的似然：$P(\\mathbf{x} \\mid L=0) = (1-0.1) \\times (1-0.05) \\times (1-0.2) = 0.9 \\times 0.95 \\times 0.8 = 0.684$。\n- 后验概率：$P(L=1 \\mid \\mathbf{x}) = \\frac{0.9 \\times 0.00075}{0.9 \\times 0.00075 + (1-0.9) \\times 0.684} = \\frac{0.000675}{0.000675 + 0.0684} = \\frac{0.000675}{0.069075} \\approx 0.009772$。\n\n**用例 5：** $p_0=0.2$, $\\mathbf{x}=(x_{\\text{MP}}=+1, x_{\\text{OM}}=0, x_{\\text{HC}}=-1)$。\n- $L=1$ 的似然：$P(\\mathbf{x} \\mid L=1) = 0.9 \\times 1 \\times (1-0.85) = 0.9 \\times 0.15 = 0.135$。\n- $L=0$ 的似然：$P(\\mathbf{x} \\mid L=0) = 0.1 \\times 1 \\times (1-0.2) = 0.1 \\times 0.8 = 0.08$。\n- 后验概率：$P(L=1 \\mid \\mathbf{x}) = \\frac{0.2 \\times 0.135}{0.2 \\times 0.135 + (1-0.2) \\times 0.08} = \\frac{0.027}{0.027 + 0.064} = \\frac{0.027}{0.091} \\approx 0.296703$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the posterior probability for scaffold link correctness\n    based on a Bayesian model with multiple evidence types.\n    \"\"\"\n\n    # Fixed model parameters\n    # For each data type d, we store (P(x_d=+1|L=1), P(x_d=+1|L=0))\n    model_params = {\n        \"MP\": (0.9, 0.1),\n        \"OM\": (0.95, 0.05),\n        \"HC\": (0.85, 0.2)\n    }\n\n    # Test cases from the problem statement\n    # Each case is a tuple: (p0, (x_mp, x_om, x_hc))\n    test_cases = [\n        (0.5, (1, 1, 1)),   # Case 1\n        (0.5, (1, -1, 1)),  # Case 2\n        (0.01, (1, 1, 1)),  # Case 3\n        (0.9, (-1, -1, -1)),# Case 4\n        (0.2, (1, 0, -1))   # Case 5\n    ]\n    \n    data_types = [\"MP\", \"OM\", \"HC\"]\n    results = []\n\n    for case in test_cases:\n        p0, observations = case\n        \n        # Initialize likelihoods for L=1 and L=0\n        lik_L1 = 1.0\n        lik_L0 = 1.0\n\n        for i, obs in enumerate(observations):\n            data_type = data_types[i]\n            p_plus_1_given_L1, p_plus_1_given_L0 = model_params[data_type]\n            \n            if obs == 1:\n                # Supportive evidence\n                lik_L1 *= p_plus_1_given_L1\n                lik_L0 *= p_plus_1_given_L0\n            elif obs == -1:\n                # Contradictory evidence\n                # P(x_d=-1|L) = 1 - P(x_d=+1|L)\n                lik_L1 *= (1.0 - p_plus_1_given_L1)\n                lik_L0 *= (1.0 - p_plus_1_given_L0)\n            elif obs == 0:\n                # Missing or uninformative evidence\n                # Likelihood ratio is 1, so we multiply by 1 (i.e., do nothing)\n                pass\n\n        # Calculate numerator and denominator of Bayes' rule\n        numerator = p0 * lik_L1\n        denominator = numerator + (1.0 - p0) * lik_L0\n        \n        if denominator == 0:\n            # This case is not expected with the given parameters but is good practice\n            posterior = 0.0\n        else:\n            posterior = numerator / denominator\n        \n        results.append(posterior)\n\n    # Format the results as a comma-separated string, rounded to 6 decimal places\n    output_str = f\"[{','.join([f'{r:.6f}' for r in results])}]\"\n    print(output_str)\n\nsolve()\n```", "id": "2427655"}, {"introduction": "在通过支架构建确定了重叠群（contigs）的顺序和方向后，我们面临的下一个挑战是填补它们之间的序列空白。本练习将填补空白问题抽象为一个经典的计算问题：在德布鲁因图中寻找最佳路径。通过从未映射的读长构建图，并根据序列重叠的置信度为路径分配权重，你可以体验到如何将生物学问题转化为一个可解的算法挑战，并最终重建出缺失的DNA序列。[@problem_id:2427629]", "problem": "给定一组关于核苷酸字母表的有限的未映射测序读长，以及一个由德布鲁因图中阶为 $k$ 的起始节点和终止节点定义的目标缺口。将填补该缺口的路径的置信度建模为沿该路径的平滑转移概率的乘积。形式上，设 $\\Sigma=\\{A,C,G,T\\}$，并从给定的读长构建德布鲁因图 $G_k$ 如下。对于每个读长 $r$ 以及 $r$ 中每个长度为 $k$ 的连续子串（表示为 $x_1 x_2 \\dots x_k$），从节点 $u = x_1 x_2 \\dots x_{k-1}$ 到节点 $v = x_2 x_3 \\dots x_k$ 添加一条有向边。计数 $c(u \\to v)$ 是这个 $k$-mer 在所有读长中出现的次数。对于给定的平滑参数 $\\alpha > 0$，将出度 $d(u)$ 定义为从 $u$ 出发的不同出边的数量，并将从 $u$ 到 $v$ 的平滑转移概率定义为\n$$\nP(u \\to v) = \\frac{c(u \\to v) + \\alpha}{\\sum_{v'} c(u \\to v') + \\alpha \\cdot d(u)} \\quad \\text{对于观测到的所有出邻居 } v'.\n$$\n一条路径 $u_0 \\to u_1 \\to \\dots \\to u_m$ 的置信度为\n$$\n\\mathrm{Conf} = \\prod_{i=0}^{m-1} P(u_i \\to u_{i+1}).\n$$\n设起始节点为 $s$，终止节点为 $t$，两者都是长度为 $k-1$ 的字符串。设允许的最大边数为 $L \\in \\mathbb{N}$。将缺口填补的最优置信度定义为从 $s$ 到 $t$ 的所有最多使用 $L$ 条边的有向路径的 $\\mathrm{Conf}$ 的最大值；如果 $m=0$ 且 $s=t$，定义 $\\mathrm{Conf}=1$。如果不存在这样的路径（当 $s \\ne t$ 时 $m \\ge 1$），则定义最优置信度为 $0$。\n\n您的程序必须为每个指定的测试用例计算最优置信度的自然对数（以 $e$ 为底），即\n$$\n\\log \\mathrm{Conf}^* = \\max_{\\substack{s \\to t \\text{ 路径} \\\\ \\text{且 } m \\le L}} \\sum_{i=0}^{m-1} \\log P(u_i \\to u_{i+1}),\n$$\n并遵循以下约定：如果不存在路径且 $s \\ne t$，输出 $-\\infty$；如果 $s=t$ 且 $L \\ge 0$，则允许空路径，其 $\\log \\mathrm{Conf}^* = 0$。所有对数都必须是自然对数。要求的数值输出必须四舍五入到 $6$ 位小数（如果为有限值）。不涉及物理单位。不使用角度。不使用百分比。\n\n测试套件。对于每个测试用例，参数为 $(\\text{reads}, k, \\alpha, s, t, L)$，其中 reads 是 $\\Sigma$ 上的字符串的有限列表。\n\n- 测试用例 1（顺利路径，唯一链）：\n  - reads $= [\\text{ATG}, \\text{TGA}, \\text{TGA}, \\text{GAC}]$\n  - $k = 3$\n  - $\\alpha = 0.5$\n  - $s = \\text{AT}$\n  - $t = \\text{AC}$\n  - $L = 3$\n\n- 测试用例 2（具有不等支持度的分支）：\n  - reads $= [\\text{ATG}, \\text{ATG}, \\text{ATA}, \\text{TGA}, \\text{TGC}, \\text{GCA}]$\n  - $k = 3$\n  - $\\alpha = 0.5$\n  - $s = \\text{AT}$\n  - $t = \\text{GA}$\n  - $L = 2$\n\n- 测试用例 3（不存在路径）：\n  - reads $= [\\text{AAA}, \\text{AAT}, \\text{ATC}]$\n  - $k = 3$\n  - $\\alpha = 0.5$\n  - $s = \\text{GG}$\n  - $t = \\text{TT}$\n  - $L = 5$\n\n- 测试用例 4（边界条件 $L=0$ 且 $s=t$）：\n  - reads $= [\\text{AAA}, \\text{AAT}, \\text{ATC}]$\n  - $k = 3$\n  - $\\alpha = 0.5$\n  - $s = \\text{AT}$\n  - $t = \\text{AT}$\n  - $L = 0$\n\n最终输出格式。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔的结果列表，顺序与测试用例相同。每个条目必须是该测试用例的 $\\log \\mathrm{Conf}^*$ 的浮点数值，如果有限则四舍五入到 $6$ 位小数，如果不存在路径则为 $-\\infty$。例如，包含四个结果的输出必须看起来像 $[\\text{r}_1,\\text{r}_2,\\text{r}_3,\\text{r}_4]$。", "solution": "所提出的问题是一个在加权有向图上的定义明确的优化练习。它为一个计算基因组学中的常见问题——填补基因组草图组装中的缺口——建立了一个简化但概念上有效的模型。该置信度模型基于德布鲁因图内的平滑转移概率，在统计上是合理的。目标是在两个指定节点之间找到一条具有最大置信度的路径，并受路径长度的约束。这等价于寻找一条最长路径，其中边权重被定义为转移概率的对数。该问题不包含逻辑矛盾、科学谬误或歧义。因此，我们将着手进行其形式化求解。\n\n问题的核心是找到具有最大累积对数概率的路径。设图为 $G = (V, E)$，其中 $V$ 是从读长中派生出的 $(k-1)$-mer 的集合，如果对应于从 $u$ 到 $v$ 的转移的 $k$-mer 被观测到，则存在一条边 $(u, v) \\in E$。边 $(u, v)$ 的权重由 $w(u, v) = \\log P(u \\to v)$ 给出。问题就变成了寻找：\n$$\n\\log \\mathrm{Conf}^* = \\max_{\\substack{\\pi = u_0 \\to \\dots \\to u_m \\\\ u_0 = s, u_m = t \\\\ m \\le L}} \\sum_{i=0}^{m-1} w(u_i, u_{i+1})\n$$\n\n这是最长路径问题的一个变种，受边的数量约束。这类问题可以通过动态规划正确解决。一种类似于 Bellman-Ford 算法的方法是合适的。\n\n解决方案通过以下步骤构建：\n\n1.  **德布鲁因图的构建**\n    首先，我们必须从输入的读长中构建德布鲁因图。图的节点是长度为 $k-1$ 的唯一子串（称为 $(k-1)$-mer）。如果读长中存在一个 $k$-mer，其前 $k-1$ 个字符构成节点 $u$，后 $k-1$ 个字符构成节点 $v$，则存在从 $u$ 到 $v$ 的一条边。我们处理所有读长，以找出所有构成的 $k$-mer 及其频率。设 $c(u \\to v)$ 是对应于从节点 $u$ 到节点 $v$ 转移的 $k$-mer 的计数。这些计数可以存储在例如哈希映射数据结构中，该结构将节点对 $(u, v)$ 映射到其计数。\n\n2.  **边权重的计算**\n    在图结构和边计数确定后，我们计算每条边的权重。对于作为至少一条边起点的每个节点 $u$，我们计算两个量：\n    - 出度 $d(u)$，即从 $u$ 一步可达的不同节点 $v'$ 的数量。\n    - 总出向计数 $\\sum_{v'} c(u \\to v')$，对 $u$ 的所有观测到的邻居 $v'$求和。\n\n    然后根据所提供的公式为每条边 $(u, v)$ 计算平滑转移概率 $P(u \\to v)$：\n    $$\n    P(u \\to v) = \\frac{c(u \\to v) + \\alpha}{\\sum_{v'} c(u \\to v') + \\alpha \\cdot d(u)}\n    $$\n    边 $(u, v)$ 的权重是此概率的自然对数，即 $w(u, v) = \\log P(u \\to v)$。由于 $P(u \\to v)$ 可能小于 $1$，其对数将是非正的。这保证了没有正权重环路，从而简化了最长路径问题。\n\n3.  **用于最长路径的动态规划**\n    我们定义一个动态规划状态 $D(l, v)$，表示从起始节点 $s$ 到任意节点 $v$ 使用*恰好* $l$ 条边的路径的最大对数置信度。\n    状态空间由路径长度 $l \\in [0, L]$ 和节点 $v \\in V$ 索引。为了在基于数组的实现中高效访问，我们可以将每个节点的字符串表示映射到一个唯一的整数索引。\n\n    DP 公式如下：\n    - **基础情况：** 对于长度 $l=0$ 的路径，唯一能被“到达”的节点是起始节点 $s$ 本身（通过空路径）。\n      $$ D(0, v) = \\begin{cases} 0 & \\text{若 } v = s \\\\ -\\infty & \\text{若 } v \\neq s \\end{cases} $$\n    - **递推关系：** 对于从 $1$ 到 $L$ 的 $l$，我们通过考虑所有入边 $(u, v)$ 来更新到达每个节点 $v$ 的对数置信度。\n      $$\n      D(l, v) = \\max_{u \\text{ 使得 } (u,v) \\in E} \\{ D(l-1, u) + w(u, v) \\}\n      $$\n      如果没有长度为 $l-1$ 的路径到达 $v$ 的任何前驱节点 $u$，或者 $v$ 没有前驱节点，则 $D(l, v)$ 保持为 $-\\infty$。\n\n4.  **最终答案的提取**\n    在填充完直至 $l=L$ 的 DP 表之后，从 $s$ 到目标节点 $t$ 使用*最多* $L$ 条边的最优对数置信度是在所有可能的路径长度下，节点 $t$ 的条目中找到的最大值。\n    $$\n    \\max_{0 \\le l \\le L} D(l, t)\n    $$\n    我们必须遵守具体的问题约定：\n    - 如果 $s = t$，允许长度为零的路径，其对数置信度为 $0$。因此，答案必须至少为 $0$。最终结果是 $\\max(0, \\max_{1 \\le l \\le L} D(l, t))$。\n    - 如果在 $L$ 条边内不存在从 $s$ 到 $t$ 的路径（即，对于 $l \\geq 1$ 的所有 $D(l, t)$ 仍为 $-\\infty$），且 $s \\neq t$，则结果为 $-\\infty$。\n    - 如果 $s$ 或 $t$ 不存在于由读长构建的图中，则不可能存在路径。如果 $s=t$，结果为 $0$，否则为 $-\\infty$。\n\n这完成了算法的逻辑设计。实现将系统地遵循这些步骤。", "answer": "```python\nimport numpy as np\nfrom collections import defaultdict\n\ndef format_result(val):\n    \"\"\"Formats a number for the final output string.\"\"\"\n    if val == float('-inf'):\n        return '-inf'\n    return f\"{val:.6f}\"\n\ndef calculate_best_log_confidence(reads, k, alpha, s, t, L):\n    \"\"\"\n    Computes the optimal log confidence for a gap fill.\n    \"\"\"\n    # Step 1: Graph Construction\n    kmer_counts = defaultdict(int)\n    for read in reads:\n        if len(read) >= k:\n            for i in range(len(read) - k + 1):\n                kmer = read[i:i+k]\n                kmer_counts[kmer] += 1\n\n    # Adjacency list representation: graph[u] = {v1: count, v2: count}\n    graph = defaultdict(lambda: defaultdict(int))\n    nodes = set()\n    if k <= 1: # Nodes must have length k-1 >= 1\n        return 0.0 if s == t else float('-inf')\n\n    for kmer, count in kmer_counts.items():\n        u, v = kmer[:-1], kmer[1:]\n        graph[u][v] += count\n        nodes.add(u)\n        nodes.add(v)\n    \n    if not nodes:\n        return 0.0 if s == t else float('-inf')\n\n    node_list = sorted(list(nodes))\n    node_to_idx = {node: i for i, node in enumerate(node_list)}\n    num_nodes = len(node_list)\n\n    # Step 2: Edge Weight Calculation\n    weights = {}\n    for u, neighbors in graph.items():\n        if not neighbors:\n            continue\n        d_u = len(neighbors)\n        sum_c_u = sum(neighbors.values())\n        denominator = sum_c_u + alpha * d_u\n        for v, c_uv in neighbors.items():\n            numerator = c_uv + alpha\n            prob = numerator / denominator\n            weights[(u, v)] = np.log(prob)\n\n    # Step 3: Dynamic Programming\n    dp = np.full((L + 1, num_nodes), float('-inf'))\n\n    if s in node_to_idx:\n        s_idx = node_to_idx[s]\n        dp[0][s_idx] = 0.0\n\n    for l in range(1, L + 1):\n        for u_str, u_neighbors in graph.items():\n            u_idx = node_to_idx[u_str]\n            if dp[l-1][u_idx] == float('-inf'):\n                continue\n            for v_str in u_neighbors:\n                v_idx = node_to_idx[v_str]\n                weight = weights[(u_str, v_str)]\n                new_log_conf = dp[l-1][u_idx] + weight\n                dp[l][v_idx] = max(dp[l][v_idx], new_log_conf)\n\n    # Step 4: Final Answer Extraction\n    if t not in node_to_idx:\n        return 0.0 if s == t else float('-inf')\n        \n    t_idx = node_to_idx[t]\n    \n    # max log-confidence over paths of length 1 to L\n    max_log_conf = np.max(dp[1:, t_idx]) if L > 0 else float('-inf')\n\n    if s == t:\n        # A path of length 0 (log-conf 0) is also an option.\n        return max(0.0, max_log_conf)\n    else:\n        return max_log_conf\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and print results.\n    \"\"\"\n    test_cases = [\n        # Test case 1 (happy path, unique chain)\n        {'reads': ['ATG', 'TGA', 'TGA', 'GAC'], 'k': 3, 'alpha': 0.5, 's': 'AT', 't': 'AC', 'L': 3},\n        # Test case 2 (branching with unequal support)\n        {'reads': ['ATG', 'ATG', 'ATA', 'TGA', 'TGC', 'GCA'], 'k': 3, 'alpha': 0.5, 's': 'AT', 't': 'GA', 'L': 2},\n        # Test case 3 (no path exists)\n        {'reads': ['AAA', 'AAT', 'ATC'], 'k': 3, 'alpha': 0.5, 's': 'GG', 't': 'TT', 'L': 5},\n        # Test case 4 (boundary condition L=0 and s=t)\n        {'reads': ['AAA', 'AAT', 'ATC'], 'k': 3, 'alpha': 0.5, 's': 'AT', 't': 'AT', 'L': 0},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = calculate_best_log_confidence(\n            case['reads'], case['k'], case['alpha'], case['s'], case['t'], case['L']\n        )\n        results.append(result)\n\n    formatted_results = [format_result(r) for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2427629"}, {"introduction": "一个初步完成的基因组序列并非终点，还需要经过严格的质量控制和校正，即“精加工”阶段。此练习聚焦于一个关键的质量控制任务：利用序列比对的统计特征来检测结构性错误。你将学习如何通过分析软剪切（soft-clipped）读长的异常富集，应用二项分布检验来识别潜在的组装错误区域，这让你能够亲身体验基因组“警察”如何发现并标记组装中的可疑之处。[@problem_id:2427648]", "problem": "您将获得一个已完成基因组组装的、测序读段到组装结果比对的简化抽象模型。对于由整数 $i \\in \\{0,1,\\dots,L-1\\}$ 索引的每个组装位置，您会得到两个非负整数：$n_i$，即覆盖位置 $i$ 的总读段数；以及 $c_i$，即这些读段中为了比对而在位置 $i$ 需要进行软剪切 (soft-clip) 的读段数。假设在正确组装的区域中，单个读段在特定位置需要软剪切的概率为 $p_0$ 且相互独立，因此在正确性的零假设模型下，$C_i \\sim \\mathrm{Binomial}(n_i,p_0)$。对于显著性水平为 $\\alpha$ 的单边检验，如果零假设下的上尾概率\n$$\n\\mathbb{P}\\left(X \\ge c_i \\mid X \\sim \\mathrm{Binomial}(n_i,p_0)\\right),\n$$\n严格小于 $\\alpha$，则位置 $i$ 被称为异常。一个检测出的区域被定义为异常位置的最大连续区间 $[a,b]$（使用从0开始的、包含端点的索引），并且只报告长度至少为 $L_{\\min}$（即 $b-a+1 \\ge L_{\\min}$）的区间。\n\n您的任务是编写一个完整的程序，根据上述定义，为下面提供的每个测试用例确定并输出检测到的区间 $[a,b]$ 列表。程序必须独立处理每个测试用例。所有区间端点都应表示为整数，不带物理单位。不涉及角度。所有概率都必须视为 $[0,1]$ 范围内的实数。\n\n测试套件（每个测试用例由 $(\\{n_i\\},\\{c_i\\},p_0,\\alpha,L_{\\min})$ 组成）：\n- 测试用例 1：\n  - $\\{n_i\\}_{i=0}^{19} = [100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100]$\n  - $\\{c_i\\}_{i=0}^{19} = [2,2,2,2,2,2,2,2,15,15,15,2,2,2,2,2,2,2,2,2]$\n  - $p_0 = 0.02$, $\\alpha = 10^{-6}$, $L_{\\min} = 2$\n- 测试用例 2：\n  - $\\{n_i\\}_{i=0}^{6} = [20,20,100,100,100,100,100]$\n  - $\\{c_i\\}_{i=0}^{6} = [8,8,2,2,2,2,2]$\n  - $p_0 = 0.02$, $\\alpha = 10^{-6}$, $L_{\\min} = 2$\n- 测试用例 3：\n  - $\\{n_i\\}_{i=0}^{7} = [5,5,5,5,5,100,100,100]$\n  - $\\{c_i\\}_{i=0}^{7} = [2,0,2,0,2,4,4,4]$\n  - $p_0 = 0.02$, $\\alpha = 10^{-3}$, $L_{\\min} = 2$\n\n最终输出格式：您的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表。列表中的每个元素对应一个测试用例，每个测试用例表示为检测出的区间列表，每个区间写成一个双元素列表 $[a,b]$，使用从0开始的、包含端点的索引。例如，总体格式为 $[R_1,R_2,R_3]$，其中每个 $R_j$ 是一个列表，如 $[[a_1,b_1],[a_2,b_2],\\dots]$。举例来说，如果三个测试用例产生的结果分别是区间 $[[8,10]]$、 $[[0,1]]$ 和 $[]$，则程序必须打印单行输出 $[[[8,10]],[[0,1]],[]]$。", "solution": "在尝试任何解决方案之前，问题陈述会经过一个强制性验证过程。\n\n### 步骤 1：提取已知信息\n已知信息从问题陈述中逐字提取：\n- 组装由 $L$ 个位置组成，由 $i \\in \\{0, 1, \\dots, L-1\\}$ 索引。\n- 对于每个位置 $i$，给定两个非负整数：\n    - $n_i$：覆盖位置 $i$ 的总读段数。\n    - $c_i$：在位置 $i$ 被软剪切的读段数。\n- 一个正确组装区域的零假设模型假定，软剪切读段的计数 $C_i$ 服从二项分布：$C_i \\sim \\mathrm{Binomial}(n_i, p_0)$，其中 $p_0$ 是单个读段需要软剪切的概率。\n- 如果零假设模型下的上尾概率严格小于显著性水平 $\\alpha$，则位置 $i$ 被指定为“异常”：\n$$\n\\mathbb{P}\\left(X \\ge c_i \\mid X \\sim \\mathrm{Binomial}(n_i, p_0)\\right) < \\alpha\n$$\n- 一个“检测出的区域”是异常位置的最大连续区间 $[a, b]$，使用从0开始的、包含端点的索引。\n- 只报告长度至少为 $L_{\\min}$（即 $b - a + 1 \\ge L_{\\min}$）的检测区域。\n- 提供了三个测试用例，每个用例由元组 $(\\{n_i\\}, \\{c_i\\}, p_0, \\alpha, L_{\\min})$ 定义。\n\n### 步骤 2：使用提取的已知信息进行验证\n根据有效性标准对问题进行评估：\n\n- **科学依据：** 该问题牢固地植根于计算生物学和统计遗传学。使用二项分布在零假设下对读段计数数据进行建模，是识别序列比对中异常的标准且可靠的做法。此类统计检验是基因组组装质量控制和结构变异检测的基础。该问题在科学上是有效的。\n- **表述清晰：** 该问题是明确的，并提供了一个清晰的、确定性的算法。每个测试用例所需的所有参数（$n_i$、$c_i$、$p_0$、$\\alpha$、$L_{\\min}$）都已指定。“异常位置”和“检测出的区域”的定义是精确的数学和逻辑结构。每个测试用例都存在唯一的解。\n- **客观性：** 该问题使用客观、形式化的语言进行阐述，没有主观论断、观点或含糊之处。\n\n### 步骤 3：结论与行动\n该问题是**有效的**。它是一个定义明确的计算任务，基于可靠的科学和统计原理，可以构建严谨的解决方案。\n\n### 解决方案推导\n\n解决方案针对每个测试用例遵循一个多步骤程序，该程序基于统计假设检验。目标是识别出基因组中观测到的软剪切读段数异常高的区域，这表明其偏离了正确组装的零假设模型。\n\n对于由参数 $(\\{n_i\\}_{i=0}^{L-1}, \\{c_i\\}_{i=0}^{L-1}, p_0, \\alpha, L_{\\min})$ 表征的每个测试用例：\n\n**1. 识别异常位置**\n\n对于从 0 到 $L-1$ 的每个位置 $i$，我们进行一次单边假设检验。零假设 $H_0$ 是该位置已正确组装，软剪切读段的数量是一个随机变量 $X \\sim \\mathrm{Binomial}(n_i, p_0)$。备择假设 $H_1$ 是软剪切读段的数量显著高于在 $H_0$ 下的预期。\n\n我们计算p值 (p-value)，即假设 $H_0$ 为真时，观测到至少与观测计数 $c_i$ 一样极端的结果的概率。这对应于二项分布的上尾概率，或生存函数（SF）：\n$$\nP_i = \\mathbb{P}(X \\ge c_i) = \\sum_{k=c_i}^{n_i} \\binom{n_i}{k} p_0^k (1 - p_0)^{n_i-k}\n$$\n如果位置 $i$ 的p值 $P_i$ 严格小于预定的显著性水平 $\\alpha$，则该位置被分类为“异常”。此过程应用于所有位置，从而产生一个布尔向量，指示哪些位置是异常的。\n\n**2. 分组成连续区域**\n\n下一步是识别所有异常位置的最大连续区间。我们遍历异常位置的布尔向量，并将连续的 `True` 值分组。例如，如果位置 $i, i+1, \\dots, j$ 都是异常的，而 $i-1$ 和 $j+1$ 不是（或超出边界），则 $[i, j]$ 构成一个最大连续区域。\n\n**3. 按最小长度筛选**\n\n最后，对每个识别出的区域 $[a, b]$ 进行长度筛选。区间的长度计算为 $b - a + 1$。只有长度大于或等于指定的最小长度 $L_{\\min}$ 的区域才会被保留并报告为检测出的区域。\n\n这个完整的算法被独立地应用于问题陈述中提供的每个测试用例。使用具有统计函数稳健实现的计算库（如 `scipy.stats`）对于准确计算二项分布生存函数至关重要，特别是对于较大的 $n_i$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import binom\n\ndef solve():\n    \"\"\"\n    Solves the problem for all test cases as specified.\n    \"\"\"\n\n    test_cases = [\n        # Test Case 1:\n        (\n            np.array([100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], dtype=np.int64),\n            np.array([2, 2, 2, 2, 2, 2, 2, 2, 15, 15, 15, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=np.int64),\n            0.02,\n            1e-6,\n            2\n        ),\n        # Test Case 2:\n        (\n            np.array([20, 20, 100, 100, 100, 100, 100], dtype=np.int64),\n            np.array([8, 8, 2, 2, 2, 2, 2], dtype=np.int64),\n            0.02,\n            1e-6,\n            2\n        ),\n        # Test Case 3:\n        (\n            np.array([5, 5, 5, 5, 5, 100, 100, 100], dtype=np.int64),\n            np.array([2, 0, 2, 0, 2, 4, 4, 4], dtype=np.int64),\n            0.02,\n            1e-3,\n            2\n        ),\n    ]\n\n    all_results = []\n    for case in test_cases:\n        n_i, c_i, p_0, alpha, L_min = case\n        \n        # Step 1: Identify abnormal positions\n        # Calculate P(X >= c_i) for each position.\n        # This is the survival function P(X > k) where k = c_i - 1.\n        p_values = binom.sf(c_i - 1, n_i, p_0)\n        is_abnormal = p_values < alpha\n        \n        # Step 2: Group into contiguous regions\n        candidate_regions = []\n        in_region = False\n        start_index = -1\n        \n        for i, abnormal_flag in enumerate(is_abnormal):\n            if abnormal_flag and not in_region:\n                # Start of a new potential region\n                in_region = True\n                start_index = i\n            elif not abnormal_flag and in_region:\n                # End of the current region\n                in_region = False\n                end_index = i - 1\n                candidate_regions.append([start_index, end_index])\n        \n        # Handle the case where the sequence ends with an abnormal region\n        if in_region:\n            candidate_regions.append([start_index, len(is_abnormal) - 1])\n            \n        # Step 3: Filter regions by minimum length\n        detected_regions = []\n        for region in candidate_regions:\n            start, end = region\n            length = end - start + 1\n            if length >= L_min:\n                detected_regions.append(region)\n                \n        all_results.append(detected_regions)\n\n    # Convert results to the required string format\n    # Example: [[[8,10]],[[0,1]],[]]\n    result_str = str(all_results).replace(\" \", \"\")\n    print(result_str)\n\nsolve()\n```", "id": "2427648"}]}