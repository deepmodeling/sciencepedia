{"hands_on_practices": [{"introduction": "理论知识是基础，但真正的理解来自于实践。本节将通过一系列动手练习，带你将结构变异检测的核心概念转化为实际的计算技能。让我们从解读测序数据中蕴含的最基本信号开始。\n\n双末端测序（paired-end sequencing）数据为我们提供了揭示大型基因组重排的有力线索，例如缺失和插入。这个练习将指导你如何利用双末端测序读段的两个关键特征——作图插入片段大小（mapped insert size）和读段方向（read orientation）——来区分这两种结构变异。通过将这些信号背后的生物学直觉转化为一个明确的决策算法，你将掌握结构变异检测中最基本也是最重要的分析逻辑之一 [@problem_id:2431909]。", "problem": "您面临一个基于双端测序技术发现结构变异的决策问题。假设一个DNA测序文库，其中正确配对读段的物理片段长度（插入片段大小）分布近似于均值为 $\\mu$、标准差为 $\\sigma$（单位：碱基对 bp）的高斯分布。在某个基因组位点，您观察到双端测序的比对具有以下两个可观测量的特征：(i) 每个已比对读段对相对于参考基因组的方向（类别：FR、RF、FF、RR），以及 (ii) 对于那些方向为FR的配对，其两条读段在参考基因组上的比对距离（即比对比对插入片段大小）。您的任务是，仅使用这两类可观测量，为每个位点判断其证据更符合样本相对于参考基因组存在大片段缺失（输出整数 $0$），还是更符合样本相对于参考基因组存在新的逆转录转座子插入（输出整数 $1$）。\n\n定义与假设：\n- 双端（PE）测序产生读段对。FR方向表示一种朝内配置，这是标准Illumina方案下预期的正确配对方向；RF、FF和RR表示朝外或同向链的配置，被认为与文库的预期方向不一致。\n- 样本相对于参考基因组的大片段缺失倾向于产生FR配对的富集，这些配对在参考基因组上的比对插入片段大小随机地大于由 $\\mu$ 和 $\\sigma$ 表征的文库分布，同时FR仍然是局部的主要方向。\n- 样本相对于参考基因组的新的逆转录转座子插入倾向于产生非FR方向（RF、FF、RR）的富集，以及FR配对在参考基因组上的比对插入片段大小随机地小于由 $\\mu$ 和 $\\sigma$ 表征的文库分布。\n\n每个测试用例的输入规范：\n- 文库参数 $\\mu$ 和 $\\sigma$（单位均为 bp）。\n- 在位点周围固定窗口内测得的方向计数 $c_{\\mathrm{FR}}$、$c_{\\mathrm{RF}}$、$c_{\\mathrm{FF}}$、$c_{\\mathrm{RR}}$。\n- 在该位点观察到的、方向为FR的读段对子集的比对插入片段大小列表（单位为 bp）。\n\n输出规范：\n- 对每个测试用例，输出一个整数：如果位点被分类为缺失，则输出 $0$；如果被分类为新的逆转录转座子插入，则输出 $1$。\n- 您的程序应生成单行输出，其中包含所有测试用例的结果，形式为一个无空格、用逗号分隔的列表，并用方括号括起来，例如 `\"[0,1,1,0]\"`。\n\n测试套件：\n- 测试用例 $1$：\n  - $\\mu = 350$, $\\sigma = 50$。\n  - $c_{\\mathrm{FR}} = 40$, $c_{\\mathrm{RF}} = 1$, $c_{\\mathrm{FF}} = 0$, $c_{\\mathrm{RR}} = 0$。\n  - FR 插入片段大小：$\\{520,540,560,590,610\\}$。\n- 测试用例 $2$：\n  - $\\mu = 350$, $\\sigma = 50$。\n  - $c_{\\mathrm{FR}} = 10$, $c_{\\mathrm{RF}} = 25$, $c_{\\mathrm{FF}} = 5$, $c_{\\mathrm{RR}} = 3$。\n  - FR 插入片段大小：$\\{150,160,170,180,190,200,210\\}$。\n- 测试用例 $3$：\n  - $\\mu = 350$, $\\sigma = 50$。\n  - $c_{\\mathrm{FR}} = 22$, $c_{\\mathrm{RF}} = 2$, $c_{\\mathrm{FF}} = 1$, $c_{\\mathrm{RR}} = 1$。\n  - FR 插入片段大小：$\\{410,430,420,380,370\\}$。\n- 测试用例 $4$：\n  - $\\mu = 400$, $\\sigma = 40$。\n  - $c_{\\mathrm{FR}} = 8$, $c_{\\mathrm{RF}} = 30$, $c_{\\mathrm{FF}} = 4$, $c_{\\mathrm{RR}} = 2$。\n  - FR 插入片段大小：$\\{260,280,300,310\\}$。\n- 测试用例 $5$：\n  - $\\mu = 300$, $\\sigma = 30$。\n  - $c_{\\mathrm{FR}} = 15$, $c_{\\mathrm{RF}} = 14$, $c_{\\mathrm{FF}} = 3$, $c_{\\mathrm{RR}} = 3$。\n  - FR 插入片段大小：$\\{200,210,190,205,195\\}$。\n\n最终输出格式：\n- 您的程序必须为上述每个测试用例计算一个分类，并打印一行结果，该结果是一个由整数组成的逗号分隔列表，用方括号括起且无空格，例如 `\"[0,1,0,1,1]\"`。", "solution": "该问题已经过验证，被确定为具有科学依据、定义明确且客观。它提出了一个计算生物学领域的标准二元分类任务，具体涉及利用双端DNA测序数据分析结构变异。\n\n任务是：将一个基因组位点分类为包含相对于参考基因组的大片段缺失（输出 $0$）或新的逆转录转座子插入（输出 $1$）。我们获得两类证据用于此决策：\n$1$. 读段对相对于参考基因组的不同方向的计数：朝内方向（$c_{\\mathrm{FR}}$）和不一致方向（$c_{\\mathrm{RF}}$、$c_{\\mathrm{FF}}$、$c_{\\mathrm{RR}}$）。\n$2$. 在FR方向上观察到的 $n$ 个读段对子集的比对插入片段大小样本，记为 $\\{x_1, x_2, \\ldots, x_n\\}$。\n这些观察结果需要在一个特定的测序文库背景下进行解释，在该文库中，正确配对的读段呈现的物理片段长度分布是均值为 $\\mu$、标准差为 $\\sigma$ 的高斯分布。\n\n决策算法直接源自问题陈述中对两种相互排斥的基因组特征的形式化描述。\n\n**假设 $H_0$：大片段缺失**\n大片段缺失的特征由两种并发的现象描述：\n- **方向证据：** FR方向配对的富集，FR仍然是主要方向。这可形式化为 FR 配对的计数超过所有非 FR（不一致）配对的总计数。\n$$c_{\\mathrm{FR}} > c_{\\mathrm{RF}} + c_{\\mathrm{FF}} + c_{\\mathrm{RR}}$$\n- **插入片段大小证据：** FR配对的比对插入片段大小随机地大于文库的物理片段长度分布。这是因为跨越样本基因组中缺失区域的读段会比对到参考基因组上相距遥远的点，从而产生人为增大的比对插入片段大小。这可通过比较观察到的FR插入片段大小的样本均值 $\\bar{x}_{\\mathrm{FR}}$ 与文库均值 $\\mu$ 来形式化。\n$$ \\bar{x}_{\\mathrm{FR}} = \\frac{1}{n} \\sum_{i=1}^{n} x_i > \\mu $$\n\n**假设 $H_1$：新的逆转录转座子插入**\n新的逆转录转座子插入的特征在现象上与缺失有显著区别：\n- **方向证据：** 非FR方向的富集。发生这种情况是因为跨越插入位点的读段对中，一个读段比对到侧翼基因组序列，而另一个读段比对到基因组其他地方的逆转录转座子的另一个拷贝，从而导致不一致的方向。这可形式化为FR配对的计数不超过非FR配对的计数。\n$$c_{\\mathrm{FR}} \\le c_{\\mathrm{RF}} + c_{\\mathrm{FF}} + c_{\\mathrm{RR}}$$\n- **插入片段大小证据：** FR配对的比对插入片段大小随机地小于文库的分布。这适用于完全包含在新的插入片段内的片段对，当它们比对回单拷贝的参考序列时，看起来像是源于一个比实际更小的片段。这可形式化为：\n$$ \\bar{x}_{\\mathrm{FR}} < \\mu $$\n\n**决策规则**\n问题要求进行决定性的分类。对缺失特征的描述意味着其两个证据成分之间存在逻辑合取关系。一个位点当且仅当其方向证据和插入片段大小证据都与缺失一致时，才被分类为缺失。鉴于这是一个在两个明确定义的备选项之间的二元分类任务，任何不满足缺失严格标准的情况因此被分类为插入。这导出了以下稳健且完备的决策规则：\n\n一个位点被分类为**缺失（输出 $0$）**，如果同时满足以下两个条件：\n$1$. $c_{\\mathrm{FR}} > (c_{\\mathrm{RF}} + c_{\\mathrm{FF}} + c_{\\mathrm{RR}})$\n$2$. $\\bar{x}_{\\mathrm{FR}} > \\mu$\n\n否则，该位点被分类为**新的逆转录转座子插入（输出 $1$）**。\n\n这个逻辑框架足以处理所有提供的测试用例，因为没有一个用例表现出矛盾的证据（例如，FR占主导但插入片段大小小于平均值）。使用更复杂的模型，例如结合标准差 $\\sigma$ 来计算Z分数或似然值，将需要关于证据类型相对权重的额外假设，而问题陈述中并未提供这些假设。所选算法代表了对所述问题最直接且科学上最合理的解释。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the structural variant classification problem based on paired-end sequencing data.\n    \"\"\"\n    \n    # Test cases defined in the problem statement.\n    test_cases = [\n        # (mu, sigma, c_fr, c_rf, c_ff, c_rr, fr_sizes)\n        (350, 50, 40, 1, 0, 0, [520, 540, 560, 590, 610]),\n        (350, 50, 10, 25, 5, 3, [150, 160, 170, 180, 190, 200, 210]),\n        (350, 50, 22, 2, 1, 1, [410, 430, 420, 380, 370]),\n        (400, 40, 8, 30, 4, 2, [260, 280, 300, 310]),\n        (300, 30, 15, 14, 3, 3, [200, 210, 190, 205, 195]),\n    ]\n\n    results = []\n    for case in test_cases:\n        mu, _, c_fr, c_rf, c_ff, c_rr, fr_sizes = case\n        \n        # Calculate the total count of non-FR (discordant) read pairs.\n        c_non_fr = c_rf + c_ff + c_rr\n        \n        # Calculate the sample mean of the FR insert sizes.\n        # Handle the edge case of an empty list of FR sizes, though not present in tests.\n        if not fr_sizes:\n            # If no FR sizes are available, the insert size criterion cannot be tested.\n            # The decision rule defaults to 'insertion' as the strict 'deletion' criteria cannot be met.\n            x_bar_fr = -np.inf # Ensures the comparison 'x_bar_fr > mu' is false.\n        else:\n            x_bar_fr = np.mean(fr_sizes)\n        \n        # A deletion signature requires FR orientation to be predominant AND\n        # the mean FR insert size to be larger than the library mean.\n        is_deletion_signature = (c_fr > c_non_fr) and (x_bar_fr > mu)\n        \n        if is_deletion_signature:\n            # Output 0 for a deletion.\n            results.append(0)\n        else:\n            # Otherwise, classify as an insertion (output 1).\n            # This covers cases where orientation or insert size (or both)\n            # are consistent with an insertion signature.\n            results.append(1)\n\n    # Print the final results in the specified format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2431909"}, {"introduction": "识别潜在的结构变异信号只是第一步，更关键的挑战在于如何从大量背景噪音中筛选出真正的信号。本练习将引导你应对结构变异分析中的一个核心问题：假阳性（false positives），特别是那些由基因组重复序列引起的假阳性。\n\n我们将聚焦于裂读（split-read）比对，这是检测倒位（inversion）等复杂重排断点的直接证据。然而，并非所有裂读信号都可靠。这个练习要求你实现一个评分函数，它巧妙地结合了两个量化指标：用于衡量序列复杂性的香农熵（Shannon entropy），以及评估比对可信度的作图质量（mapping quality）。通过这个练习，你将学会如何量化信号的“质量”，从而更准确地区分真正的变异和比对伪影 [@problem_id:2431938]。", "problem": "给定一个评分的形式化定义，该评分利用两条比对读段的脱氧核糖核酸 (DNA) 序列复杂度和它们的比对质量，量化了据称支持基因组倒位的裂读比对的可靠性。DNA 碱基字母表仅限于符号集合 {A, C, G, T}。对于每个裂读比对，都有两个侧翼（左侧和右侧），各自具有相应的序列和 Phred 标度的比对质量。\n\n对于一个长度为 $n$ 的 DNA 序列 $s$，其单核苷酸计数为 $c_A$、$c_C$、$c_G$、$c_T$ 且满足 $c_A + c_C + c_G + c_T = n$，定义经验碱基频率为 $p_b = c_b / n$，其中 $b \\in \\{A,C,G,T\\}$。定义以比特为单位的 Shannon 熵为\n$$\nH(s) = - \\sum_{b \\in \\{A,C,G,T\\}} p_b \\log_2 p_b,\n$$\n约定当 $p_b = 0$ 时，该项贡献为 $0$。定义归一化熵\n$$\nh(s) = \\frac{H(s)}{\\log_2 4} = \\frac{H(s)}{2},\n$$\n使得 $h(s) \\in [0,1]$。\n\n设左侧和右侧侧翼的序列分别为 $s_L$ 和 $s_R$，Phred 标度的比对质量分别为 $Q_L$ 和 $Q_R$。使用以下公式将每个比对质量 $Q$ 转换为正确比对的概率\n$$\nP(Q) = 1 - 10^{-Q/10}.\n$$\n\n定义复合可靠性评分为\n$$\nS(s_L,s_R,Q_L,Q_R) = \\min\\{ h(s_L), h(s_R) \\} \\times \\min\\{ P(Q_L), P(Q_R) \\}.\n$$\n\n给定一个决策阈值 $\\tau$，当且仅当 $S \\ge \\tau$ 时，将一个裂读比对分类为真实的支持倒位的信号，否则分类为比对假象，从而产生一个布尔值结果。\n\n请实现一个程序，对以下测试套件，使用阈值 $\\tau = 0.7$ 计算每种情况下的布尔分类：\n\n- 情况 $1$：$s_L=$ \"ACGTACGTACGT\", $s_R=$ \"TGCATGCATGCA\", $Q_L = 40$, $Q_R = 42$。\n- 情况 $2$：$s_L=$ \"ATATATATATAT\", $s_R=$ \"ATATATATATAT\", $Q_L = 10$, $Q_R = 10$。\n- 情况 $3$：$s_L=$ \"GATTACAGATTACA\", $s_R=$ \"TCGATCGATCGA\", $Q_L = 35$, $Q_R = 5$。\n- 情况 $4$：$s_L=$ \"AAAAAAAAAAAA\", $s_R=$ \"ACGTACGTACGT\", $Q_L = 60$, $Q_R = 60$。\n- 情况 $5$：$s_L=$ \"CG\", $s_R=$ \"CG\", $Q_L = 20$, $Q_R = 20$。\n- 情况 $6$：$s_L=$ \"ACGTACGT\", $s_R=$ \"GTACGTAC\", $Q_L = 20$, $Q_R = 20$。\n\n您的程序应产生单行输出，其中包含一个用方括号括起来的逗号分隔列表，结果的顺序与上述情况相同。例如，一个有效的输出格式是“[True,False,True]”。输出必须精确包含与情况 $1$ 到 $6$ 对应的六个布尔值。", "solution": "首先对问题陈述进行严格验证。\n\n步骤 1：提取的已知条件\n问题提供了以下定义和数据：\n- DNA 碱基字母表：$\\Sigma = \\{A, C, G, T\\}$。\n- 对于一个长度为 $n$ 的序列 $s$，其单核苷酸计数为 $c_A, c_C, c_G, c_T$ 且满足 $\\sum_{b \\in \\Sigma} c_b = n$。\n- 经验碱基频率：对于 $b \\in \\Sigma$，$p_b = c_b / n$。\n- 以比特为单位的 Shannon 熵：$H(s) = - \\sum_{b \\in \\Sigma} p_b \\log_2 p_b$，其中 $0 \\log_2 0 = 0$。\n- 归一化熵：$h(s) = H(s) / \\log_2 4 = H(s) / 2$，其中 $h(s) \\in [0,1]$。\n- 左侧和右侧侧翼序列：$s_L, s_R$。\n- Phred 标度的比对质量：$Q_L, Q_R$。\n- 正确比对的概率：$P(Q) = 1 - 10^{-Q/10}$。\n- 复合可靠性评分：$S(s_L, s_R, Q_L, Q_R) = \\min\\{ h(s_L), h(s_R) \\} \\times \\min\\{ P(Q_L), P(Q_R) \\}$。\n- 决策阈值：$\\tau = 0.7$。\n- 分类规则：如果 $S \\ge \\tau$ 则为 True，否则为 False。\n- 测试用例：\n    1. $s_L=$ \"ACGTACGTACGT\", $s_R=$ \"TGCATGCATGCA\", $Q_L = 40$, $Q_R = 42$。\n    2. $s_L=$ \"ATATATATATAT\", $s_R=$ \"ATATATATATAT\", $Q_L = 10$, $Q_R = 10$。\n    3. $s_L=$ \"GATTACAGATTACA\", $s_R=$ \"TCGATCGATCGA\", $Q_L = 35$, $Q_R = 5$。\n    4. $s_L=$ \"AAAAAAAAAAAA\", $s_R=$ \"ACGTACGTACGT\", $Q_L = 60$, $Q_R = 60$。\n    5. $s_L=$ \"CG\", $s_R=$ \"CG\", $Q_L = 20$, $Q_R = 20$。\n    6. $s_L=$ \"ACGTACGT\", $s_R=$ \"GTACGTAC\", $Q_L = 20$, $Q_R = 20$。\n\n步骤 2：使用提取的已知条件进行验证\n根据指定标准对问题进行评估。\n- **有科学依据**：问题有充分的科学依据。它采用了信息论（Shannon 熵）和生物信息学（Phred 质量分数、序列复杂度）中的标准定义。所提出的可靠性评分是评估结构变异证据的一种合乎逻辑（尽管简化了）的启发式方法。它不含伪科学。\n- **良态的**：问题是良态的。所有数学关系都已明确定义。测试套件的所有常量和输入数据均已提供。每个案例都期望有唯一的布尔输出。\n- **客观的**：问题以客观、数学上精确的方式陈述。没有主观或模糊的术语。\n\n该问题没有表现出科学上不健全、不可形式化、不完整、矛盾、不可行或结构不良等缺陷。\n\n步骤 3：结论与行动\n问题被判定为**有效**。将提供解决方案。\n\n解决方案要求实现一个基于复合可靠性评分 $S$ 的分类过程。必须为六个测试用例中的每一个计算此分数，并与决策阈值 $\\tau=0.7$进行比较。\n\n分数 $S$ 的计算包含两个主要部分：由归一化熵 $h(s)$ 衡量的序列复杂度，以及由正确比对概率 $P(Q)$ 衡量的比对可靠性。\n\n首先，我们定义归一化熵 $h(s)$ 的计算。对于给定长度为 $n$ 的序列 $s$，我们计算每个碱基 $b \\in \\{A, C, G, T\\}$ 的出现次数 $c_b$。频率为 $p_b = c_b/n$。Shannon 熵则为 $H(s) = - \\sum p_b \\log_2 p_b$。当所有四种碱基出现的可能性均等时($p_b=0.25$)，DNA 序列的熵达到最大值，得到 $H_{max} = \\log_2 4 = 2$ 比特。通过这个最大值进行归一化，得到 $h(s) = H(s)/2$，这将复杂度映射到区间 $[0,1]$。$h(s)=0$ 的值对应于均聚物（例如，“AAAA”），表示最低复杂度。$h(s)=1$ 的值对应于具有均匀碱基分布的序列，表示最高复杂度。\n\n其次，我们定义比对概率 $P(Q)$ 的计算。Phred 标度的质量分数 $Q$ 与错误概率 $P_{error}$ 呈对数关系。具体来说，$Q = -10 \\log_{10} P_{error}$，这意味着 $P_{error} = 10^{-Q/10}$。因此，正确比对的概率为 $P(Q) = 1 - P_{error} = 1 - 10^{-Q/10}$。\n\n复合评分 $S$ 结合了这两个指标：$S = \\min\\{h(s_L), h(s_R)\\} \\times \\min\\{P(Q_L), P(Q_R)\\}$。这个公式是保守的；最终得分受序列复杂度较低的侧翼和比对质量较低的侧翼的限制。如果 $S \\ge \\tau$，则将比对分类为真实信号。\n\n现在我们将此过程应用于每个案例，其中 $\\tau = 0.7$。\n\n情况 1：$s_L=$ \"ACGTACGTACGT\", $s_R=$ \"TGCATGCATGCA\", $Q_L = 40, Q_R = 42$。\n- 对于 $s_L$ 和 $s_R$，$n=12$ 且 $c_A=c_C=c_G=c_T=3$。因此，对于所有碱基，$p_b = 3/12 = 0.25$。\n- $H(s_L) = H(s_R) = -4 \\times (0.25 \\log_2 0.25) = -4 \\times (0.25 \\times -2) = 2$。\n- $h(s_L) = h(s_R) = 2/2 = 1$。 $\\min\\{h\\} = 1$。\n- $P(Q_L) = 1 - 10^{-40/10} = 1 - 10^{-4} = 0.9999$。\n- $P(Q_R) = 1 - 10^{-42/10} = 1 - 10^{-4.2} \\approx 0.999937$。\n- $\\min\\{P\\} = 0.9999$。\n- $S = 1 \\times 0.9999 = 0.9999$。\n- $0.9999 \\ge 0.7$。分类：**True**。\n\n情况 2：$s_L=$ \"ATATATATATAT\", $s_R=$ \"ATATATATATAT\", $Q_L = 10, Q_R = 10$。\n- 对于两个序列，$n=12$，$c_A=6, c_T=6$。$p_A=p_T=0.5$。\n- $H(s_L) = H(s_R) = -2 \\times (0.5 \\log_2 0.5) = -2 \\times (0.5 \\times -1) = 1$。\n- $h(s_L) = h(s_R) = 1/2 = 0.5$。$\\min\\{h\\} = 0.5$。\n- $P(Q_L) = P(Q_R) = 1 - 10^{-10/10} = 1 - 0.1 = 0.9$。$\\min\\{P\\} = 0.9$。\n- $S = 0.5 \\times 0.9 = 0.45$。\n- $0.45 < 0.7$。 分类：**False**。\n\n情况 3：$s_L=$ \"GATTACAGATTACA\", $s_R=$ \"TCGATCGATCGA\", $Q_L = 35, Q_R = 5$。\n- 对于 $s_L$，$n=14$, $c_A=6, c_C=2, c_G=2, c_T=4$。频率：$p_A=6/14, p_C=2/14, p_G=2/14, p_T=4/14$。\n- $H(s_L) \\approx -(\\frac{6}{14}\\log_2\\frac{6}{14} + \\frac{2}{14}\\log_2\\frac{2}{14} + \\frac{2}{14}\\log_2\\frac{2}{14} + \\frac{4}{14}\\log_2\\frac{4}{14}) \\approx 1.8423$。\n- $h(s_L) \\approx 1.8423 / 2 \\approx 0.9212$。\n- 对于 $s_R$，$n=12$，所有碱基的 $p_b = 0.25$，所以 $h(s_R)=1$。\n- $\\min\\{h\\} \\approx 0.9212$。\n- $P(Q_L) = 1 - 10^{-35/10} = 1 - 10^{-3.5} \\approx 0.9997$。\n- $P(Q_R) = 1 - 10^{-5/10} = 1 - 10^{-0.5} \\approx 0.6838$。\n- $\\min\\{P\\} \\approx 0.6838$。\n- $S \\approx 0.9212 \\times 0.6838 \\approx 0.6299$。\n- $0.6299 < 0.7$。 分类：**False**。\n\n情况 4：$s_L=$ \"AAAAAAAAAAAA\", $s_R=$ \"ACGTACGTACGT\", $Q_L = 60, Q_R = 60$。\n- 对于 $s_L$，一个均聚物，$p_A=1$ 且其他 $p_b=0$。\n- $H(s_L) = -(1 \\log_2 1) = 0$。$h(s_L) = 0$。\n- 对于 $s_R$，$p_b=0.25$，所以 $h(s_R)=1$。\n- $\\min\\{h\\} = 0$。\n- $S = 0 \\times \\min\\{P(60), P(60)\\} = 0$。\n- $0 < 0.7$。 分类：**False**。\n\n情况 5：$s_L=$ \"CG\", $s_R=$ \"CG\", $Q_L = 20, Q_R = 20$。\n- 对于两个序列，$n=2$，$c_C=1, c_G=1$。$p_C=p_G=0.5$。\n- 在频率方面，这与情况 2 类似：$H(s_{L,R})=1$，$h(s_{L,R})=0.5$。\n- $\\min\\{h\\} = 0.5$。\n- $P(Q_{L,R}) = 1 - 10^{-20/10} = 1 - 10^{-2} = 0.99$。$\\min\\{P\\}=0.99$。\n- $S = 0.5 \\times 0.99 = 0.495$。\n- $0.495 < 0.7$。 分类：**False**。\n\n情况 6：$s_L=$ \"ACGTACGT\", $s_R=$ \"GTACGTAC\", $Q_L = 20, Q_R = 20$。\n- 对于两个序列，$n=8$，$c_A=c_C=c_G=c_T=2$。$p_b=2/8=0.25$。\n- 在频率方面，这与情况 1 类似：$H(s_{L,R})=2$，$h(s_{L,R})=1$。\n- $\\min\\{h\\} = 1$。\n- $P(Q_{L,R}) = 1 - 10^{-20/10} = 0.99$。$\\min\\{P\\}=0.99$。\n- $S = 1 \\times 0.99 = 0.99$。\n- $0.99 \\ge 0.7$。 分类：**True**。\n\n最终结果是：[True, False, False, False, False, True]。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom collections import Counter\n\ndef calculate_normalized_entropy(s: str) -> float:\n    \"\"\"\n    Calculates the normalized Shannon entropy for a DNA sequence.\n    The entropy is normalized by log2(4) = 2.\n    \"\"\"\n    n = len(s)\n    if n == 0:\n        return 0.0\n\n    counts = Counter(s)\n    dna_bases = {'A', 'C', 'G', 'T'}\n    entropy = 0.0\n    \n    for base in dna_bases:\n        count = counts.get(base, 0)\n        if count > 0:\n            p_b = count / n\n            entropy -= p_b * np.log2(p_b)\n    \n    # Normalize by log2(4), which is 2.\n    h_s = entropy / 2.0\n    return h_s\n\ndef calculate_mapping_probability(Q: int) -> float:\n    \"\"\"\n    Converts a Phred-scaled mapping quality score to a probability of correct mapping.\n    \"\"\"\n    # The problem specifies Q as an integer (from the test cases), so we can treat it as such.\n    return 1.0 - 10**(-float(Q) / 10.0)\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test suite and prints the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each tuple is (s_L, s_R, Q_L, Q_R).\n    test_cases = [\n        (\"ACGTACGTACGT\", \"TGCATGCATGCA\", 40, 42),\n        (\"ATATATATATAT\", \"ATATATATATAT\", 10, 10),\n        (\"GATTACAGATTACA\", \"TCGATCGATCGA\", 35, 5),\n        (\"AAAAAAAAAAAA\", \"ACGTACGTACGT\", 60, 60),\n        (\"CG\", \"CG\", 20, 20),\n        (\"ACGTACGT\", \"GTACGTAC\", 20, 20),\n    ]\n\n    # The decision threshold tau.\n    tau = 0.7\n    \n    results = []\n    \n    for s_L, s_R, Q_L, Q_R in test_cases:\n        # Calculate normalized entropies for left and right flanks.\n        h_L = calculate_normalized_entropy(s_L)\n        h_R = calculate_normalized_entropy(s_R)\n        \n        # Calculate mapping probabilities for left and right flanks.\n        P_L = calculate_mapping_probability(Q_L)\n        P_R = calculate_mapping_probability(Q_R)\n        \n        # Determine the minimum of each pair of metrics.\n        min_h = min(h_L, h_R)\n        min_P = min(P_L, P_R)\n        \n        # Calculate the composite reliability score S.\n        S = min_h * min_P\n        \n        # Classify the alignment based on the threshold tau.\n        classification = S >= tau\n        results.append(classification)\n\n    # Final print statement in the exact required format.\n    # The str() of a bool in Python is 'True' or 'False'.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "2431938"}, {"introduction": "在前两个练习中，我们处理了局部信号。现在，让我们将分析提升到一个新的层次，学习如何使用概率模型来整合跨越整个基因组区域的证据。我们将探讨一种重要的结构变异类型——拷贝数变异（Copy Number Variation, CNV），其主要检测信号是读段深度（read depth）。\n\n虽然读段深度与拷贝数成正比的直觉很简单，但真实数据充满噪音，信号往往模棱两可。本练习将介绍一种强大的统计工具——隐马尔可夫模型（Hidden Markov Model, $HMM$），用于从一系列嘈杂的读段深度“观测值”中推断出最可能的基础拷贝数“状态”序列。通过构建并求解一个 $HMM$，你将体验到从简单的启发式方法到稳健的、基于模型的结构变异发现方法的转变，这代表了生物信息学分析的一大进步 [@problem_id:2431910]。", "problem": "您将获得一个用于结构变异发现的测序深度信号生成模型，其中每个基因组窗口的隐藏状态是绝对拷贝数。该模型是一个隐马尔可夫模型 (HMM)，其隐藏状态空间是绝对拷贝数集合 $\\{0,1,2,\\ldots,8\\}$，发射值为固定大小的连续基因组窗口的归一化测序深度。您的任务是，对于每个给定的观测序列，确定在该模型下能使后验概率最大化的隐藏状态序列。\n\n模型规格：\n- 隐藏状态空间：$\\mathcal{C}=\\{0,1,2,\\ldots,8\\}$。\n- 窗口 $t$ 处的观测值：一个实数 $D_t \\in \\mathbb{R}$，代表归一化测序深度。\n- 在 $c \\in \\mathcal{C}$ 上的初始分布 $\\pi(c)$:\n  $$\\pi(c) \\propto \\exp\\!\\left(-\\beta\\,(c-c_0)^2\\right), \\quad \\text{with } \\beta=1.0 \\text{ and } c_0=2,$$\n  归一化以使 $\\sum_{c \\in \\mathcal{C}} \\pi(c) = 1$。\n- 从 $i \\in \\mathcal{C}$ 到 $j \\in \\mathcal{C}$ 的转移概率 $T(i,j)$ 由未归一化的权重定义\n  $$w(i,j)=\\begin{cases}\n  \\kappa & \\text{if } j=i,\\\\\n  \\exp\\!\\left(-\\gamma \\,\\lvert j-i \\rvert \\right) & \\text{if } j \\neq i,\n  \\end{cases}$$\n  参数为 $\\kappa=20.0$ 和 $\\gamma=\\ln 2$。那么，行随机转移概率为\n  $$T(i,j)=\\frac{w(i,j)}{\\sum\\limits_{j' \\in \\mathcal{C}} w(i,j')}.$$\n- 在给定状态 $c$ 时观测值 $d$ 的发射密度为高斯（正态）分布，其均值与拷贝数成正比：\n  $$f(d \\mid c) = \\frac{1}{\\sigma \\sqrt{2\\pi}}\\exp\\!\\left(-\\frac{(d-\\mu_c)^2}{2\\sigma^2}\\right), \\quad \\mu_c = \\frac{c}{2}, \\quad \\sigma = 0.15.$$\n\n对于一个观测序列 $D_{1:n}=(D_1,D_2,\\ldots,D_n)$ 和一个隐藏序列 $C_{1:n}=(C_1,C_2,\\ldots,C_n)$，其联合概率为\n$$P(C_{1:n},D_{1:n})=\\pi(C_1)\\left(\\prod_{t=2}^{n} T(C_{t-1},C_t)\\right)\\left(\\prod_{t=1}^{n} f(D_t \\mid C_t)\\right).$$\n您的任务是：对于下方的每个观测序列，确定一个序列 $C_{1:n} \\in \\mathcal{C}^n$，该序列能够最大化后验概率 $P(C_{1:n} \\mid D_{1:n}) \\propto P(C_{1:n},D_{1:n})$。如果存在多个最大化序列，请选择在 $\\mathbb{Z}^{n}$ 的常规顺序下字典序最小的序列（即，从左到右逐元素比较两个序列，并选择在第一个不同位置上值较小的那个）。\n\n测试套件：\n- 案例 A（平衡二倍体中含有一个单拷贝缺失片段）：$D_{1:8}=(0.98, 1.03, 1.01, 0.51, 0.48, 0.50, 0.99, 1.02)$。\n- 案例 B（纯合缺失片段）：$D_{1:4}=(0.08, 0.05, 0.04, 0.07)$。\n- 案例 C（二倍体背景下的局灶性高水平扩增）：$D_{1:5}=(1.01, 1.99, 2.49, 2.51, 1.02)$。\n- 案例 D（与奇数拷贝数一致的中间信号）：$D_{1:4}=(1.40, 1.60, 1.45, 1.55)$。\n- 案例 E（上边界高拷贝数）：$D_{1:2}=(3.95, 4.05)$。\n\n要求的最终输出格式：\n- 您的程序必须生成单行文本，其中包含所有案例的结果，以逗号分隔的列表形式呈现，并用方括号括起，不含任何空白字符。\n- 每个案例的结果必须是最大化的隐藏状态序列，表示为一个用方括号括起的整数列表，同样不含任何空白。例如，一个包含两个案例的有效整体输出结构将是 `[[0,1],[2,2,3]]`。\n- 本问题中没有物理单位。所有数值结果都是无量纲的。\n- 您的程序必须为每个测试案例计算出如上所述的最大化隐藏状态序列，并按 A、B、C、D、E 的顺序输出这五个序列，按要求将它们汇总到一行中。", "solution": "所提出的问题是计算生物学领域一个有效且定义明确的科学问题。它要求在隐马尔可夫模型 (HMM) 中寻找最可能的隐藏状态序列，这是一个存在标准算法的经典问题。所有模型参数和数据都已完整且一致地给出。我将开始进行求解。\n\n目标是针对给定的观测测序深度序列 $D_{1:n} = (D_1, D_2, \\ldots, D_n)$，找到能够最大化后验概率 $P(C_{1:n} \\mid D_{1:n})$ 的隐藏拷贝数状态序列 $C_{1:n} = (C_1, C_2, \\ldots, C_n)$。由于证据 $P(D_{1:n})$ 对于固定的观测序列是一个常数，因此最大化后验概率等价于最大化联合概率 $P(C_{1:n}, D_{1:n})$。联合概率由以下公式给出：\n$$P(C_{1:n},D_{1:n})=\\pi(C_1)\\left(\\prod_{t=2}^{n} T(C_{t-1},C_t)\\right)\\left(\\prod_{t=1}^{n} f(D_t \\mid C_t)\\right)$$\n直接评估所有可能的状态序列在计算上是不可行的，因为存在 $|\\mathcal{C}|^n$ 种这样的序列。维特比算法提供了一种高效的动态规划方法来找到这条最优路径。为了防止因多个小概率相乘而导致的数值下溢，所有计算都在对数空间中执行。目标变为最大化联合对数概率：\n$$\\log P(C_{1:n},D_{1:n}) = \\log\\pi(C_1) + \\sum_{t=2}^{n} \\log T(C_{t-1},C_t) + \\sum_{t=1}^{n} \\log f(D_t \\mid C_t)$$\n\n首先，我们预先计算所有模型参数的对数：\n1.  **对数初始概率**: 未归一化的初始概率为 $\\pi'(c) = \\exp(-\\beta(c-c_0)^2)$，其中 $c \\in \\mathcal{C}=\\{0,1,\\ldots,8\\}$，$\\beta=1.0$ 且 $c_0=2$。我们计算归一化常数 $Z_\\pi = \\sum_{c \\in \\mathcal{C}} \\pi'(c)$，然后计算对数概率 $\\log\\pi(c) = \\log(\\pi'(c)) - \\log(Z_\\pi)$。\n\n2.  **对数转移概率**: 未归一化的转移权重为：当 $i=j$ 时，$w(i,j) = \\kappa$；当 $i \\neq j$ 时，$w(i,j) = \\exp(-\\gamma|j-i|)$。其中 $\\kappa=20.0$ 且 $\\gamma=\\ln 2$。对于每个状态 $i$，我们计算归一化常数 $Z_T(i) = \\sum_{j \\in \\mathcal{C}} w(i,j)$。然后，对数转移概率为 $\\log T(i,j) = \\log w(i,j) - \\log Z_T(i)$。这将得到一个 $|\\mathcal{C}| \\times |\\mathcal{C}|$ 的对数概率矩阵。\n\n3.  **对数发射概率**: 发射密度是一个高斯分布 $f(d \\mid c) = \\mathcal{N}(d; \\mu_c, \\sigma^2)$，其均值为 $\\mu_c = c/2$，标准差为 $\\sigma = 0.15$。其对数密度为：\n    $$\\log f(d \\mid c) = -\\log(\\sigma\\sqrt{2\\pi}) - \\frac{(d - \\mu_c)^2}{2\\sigma^2}$$\n    对于每个观测序列 $D_{1:n}$，我们计算一个大小为 $n \\times |\\mathcal{C}|$ 的对数发射概率矩阵。\n\n维特比算法的执行过程如下：\n\n令 $\\delta_t(j)$ 为任何以状态 $j$ 结尾的长度为 $t$ 的路径的最大对数概率，$\\psi_t(j)$ 为该路径上的前驱状态。\n\n**1. 初始化 ($t=1$):**\n对于每个状态 $j \\in \\mathcal{C}$:\n$$\\delta_1(j) = \\log \\pi(j) + \\log f(D_1 \\mid j)$$\n\n**2. 递归 (对于 $t=2, \\ldots, n$):**\n对于每个状态 $j \\in \\mathcal{C}$:\n$$\\delta_t(j) = \\log f(D_t \\mid j) + \\max_{i \\in \\mathcal{C}} \\left( \\delta_{t-1}(i) + \\log T(i,j) \\right)$$\n$$\\psi_t(j) = \\arg\\max_{i \\in \\mathcal{C}} \\left( \\delta_{t-1}(i) + \\log T(i,j) \\right)$$\n如果 $\\arg\\max$ 存在平局，我们选择索引最小的前驱状态 $i$。\n\n**3. 终止:**\n任何完整路径的最大对数概率为 $P^* = \\max_{j \\in \\mathcal{C}} \\delta_n(j)$。\n\n**4. 路径回溯与平局打破:**\n如果多个序列产生相同的最大概率，问题要求选择字典序最小的序列。在递归过程中简单的平局打破规则不足以在全局上保证这一点。正确的步骤是：\na. 识别所有可以结束最大概率路径的最终状态 $J^* = \\{j \\in \\mathcal{C} \\mid \\delta_n(j) \\text{ 接近 } P^*\\}$。浮点数比较需要一个小的容差。\nb. 对于每个 $j \\in J^*$，通过从 $t=n$ 回溯到 $t=1$ 来重构整个路径：$C_n^* = j$，且对于 $t=n-1, \\ldots, 1$, $C_t^* = \\psi_{t+1}(C_{t+1}^*)$。\nc. 这将产生一组候选路径，它们都具有相同的最大概率。\nd. 对这些路径进行字典序比较，并选择最小的一个作为最终答案。\n\n该过程将为每个提供的测试案例实现，以确定唯一的最优隐藏状态序列。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the HMM decoding problem for structural variant discovery.\n    \"\"\"\n\n    # --- Model Specification ---\n    BETA = 1.0\n    C0 = 2.0\n    KAPPA = 20.0\n    GAMMA = np.log(2.0)\n    SIGMA = 0.15\n    STATES = np.arange(9)\n    NUM_STATES = len(STATES)\n\n    # --- Pre-compute HMM Parameters ---\n\n    # 1. Log Initial Probabilities\n    unnorm_pi = np.exp(-BETA * (STATES - C0)**2)\n    pi = unnorm_pi / np.sum(unnorm_pi)\n    log_pi = np.log(pi)\n\n    # 2. Log Transition Matrix\n    W = np.zeros((NUM_STATES, NUM_STATES))\n    for i in range(NUM_STATES):\n        for j in range(NUM_STATES):\n            if i == j:\n                W[i, j] = KAPPA\n            else:\n                W[i, j] = np.exp(-GAMMA * np.abs(i - j))\n    \n    T = W / W.sum(axis=1, keepdims=True)\n    # Avoid log(0) for impossible transitions, though not expected here\n    log_T = np.log(np.where(T > 0, T, 1e-300))\n\n    def viterbi_solver(D):\n        \"\"\"\n        Finds the most likely state sequence using the Viterbi algorithm.\n        Handles lexicographical tie-breaking.\n        \"\"\"\n        n = len(D)\n\n        # 3. Log Emission Probabilities for the given sequence D\n        mu = STATES / 2.0\n        log_em_prefactor = -np.log(SIGMA) - 0.5 * np.log(2 * np.pi)\n        inv_2_sig_sq = 1.0 / (2.0 * SIGMA**2)\n        log_E = np.zeros((n, NUM_STATES))\n        for t in range(n):\n            d_t = D[t]\n            log_E[t, :] = log_em_prefactor - ((d_t - mu)**2 * inv_2_sig_sq)\n\n        # --- Viterbi Algorithm ---\n        delta = np.zeros((n, NUM_STATES))\n        psi = np.zeros((n, NUM_STATES), dtype=int)\n\n        # Initialization (t=0)\n        delta[0, :] = log_pi + log_E[0, :]\n\n        # Recursion (t=1 to n-1)\n        for t in range(1, n):\n            for j in range(NUM_STATES):\n                scores = delta[t-1, :] + log_T[:, j]\n                # In numpy.argmax, ties are broken by returning the first index,\n                # which corresponds to the smallest state index.\n                best_prev_state = np.argmax(scores)\n                psi[t, j] = best_prev_state\n                delta[t, j] = scores[best_prev_state] + log_E[t, j]\n\n        # Termination & Tie-Breaking\n        max_logp = np.max(delta[n-1, :])\n        # Find all states that achieve the max probability within a tolerance\n        potential_last_states = np.where(np.isclose(delta[n-1, :], max_logp))[0]\n\n        optimal_paths = []\n        for last_state in potential_last_states:\n            path = [0] * n\n            path[n-1] = last_state\n            for t in range(n-2, -1, -1):\n                path[t] = psi[t+1, path[t+1]]\n            optimal_paths.append(path)\n\n        # Sort paths lexicographically and select the first one\n        optimal_paths.sort()\n        return optimal_paths[0]\n\n    # --- Test Suite ---\n    test_cases = [\n        (0.98, 1.03, 1.01, 0.51, 0.48, 0.50, 0.99, 1.02), # Case A\n        (0.08, 0.05, 0.04, 0.07),                         # Case B\n        (1.01, 1.99, 2.49, 2.51, 1.02),                   # Case C\n        (1.40, 1.60, 1.45, 1.55),                         # Case D\n        (3.95, 4.05),                                     # Case E\n    ]\n    \n    results = []\n    for D_tuple in test_cases:\n        D_array = np.array(D_tuple)\n        result_path = viterbi_solver(D_array)\n        results.append(result_path)\n\n    # --- Format Output ---\n    results_str = []\n    for path in results:\n        results_str.append(f\"[{','.join(map(str, path))}]\")\n    \n    print(f\"[{','.join(results_str)}]\")\n\nsolve()\n```", "id": "2431910"}]}