{"hands_on_practices": [{"introduction": "在我们能够信任任何共演化模型的预测之前，必须有一套严谨的方法来评估其准确性。本练习将引导你完成计算精确率（precision）这一基本任务，让你亲身体验评估指标的定义如何影响我们对模型性能的判断。你将探索改变物理接触的距离阈值 $d_c$ 如何直接影响最终的精确率得分，这对于批判性地解读研究结果至关重要。[@problem_id:2380714]", "problem": "您将使用一个综合基准测试设置，来研究三维空间中残基-残基接触的定义如何影响基于共进化的预测器所报告的精确率。在用于接触预测的共进化分析中，例如直接耦合分析 (DCA)，残基对根据反映其共进化耦合强度的分数进行排名。如果一对残基的β-碳 (C-beta) 位置之间的距离小于或等于指定的截止距离，则认为它们是一个接触。您将实现一个精确的评估，研究改变接触定义阈值如何影响在固定数量的排名靠前预测下的测量精确率。\n\n基本原理和定义：\n- 位于坐标 $\\left(x_{i}, y_{i}, z_{i}\\right)$ 和 $\\left(x_{j}, y_{j}, z_{j}\\right)$ 的残基之间的成对欧几里得距离为\n$$\nd_{ij} = \\sqrt{(x_{i}-x_{j})^{2} + (y_{i}-y_{j})^{2} + (z_{i}-z_{j})^{2}}.\n$$\n- 如果 $d_{ij} \\le d_{c}$，则一对 $\\left(i,j\\right)$ 被标记为正向接触，其中 $d_{c}$ 是以埃（Angstrom）为单位的接触截止距离。\n- 前k个预测的精确率定义为\n$$\n\\text{Precision}(k, d_{c}) = \\frac{\\text{在前k个符合条件的预测中真实接触的数量}}{\\text{被评估的预测数量}},\n$$\n其中“符合条件的”意味着序列间隔满足 $\\lvert i-j \\rvert \\ge g$，以排除平凡的局部邻居。如果符合条件的预测少于k个，则评估所有可用的符合条件的预测，并除以该数量。将精确率报告为保留小数点后三位的小数。\n\n本任务的数据：\n- 一条长度为 $L=10$ 个残基的单多肽链。每个残基索引 $i \\in \\{1,2,\\dots,10\\}$ 都有一个固定的 C-beta 坐标，如下所示（单位为埃）。所有 $z$ 坐标均为 $0$：\n  - 残基 $1$: $(0.0, 0.0, 0.0)$\n  - 残基 $2$: $(3.8, 0.0, 0.0)$\n  - 残基 $3$: $(7.6, 0.0, 0.0)$\n  - 残基 $4$: $(11.4, 0.0, 0.0)$\n  - 残基 $5$: $(15.2, 0.0, 0.0)$\n  - 残基 $6$: $(0.0, 6.0, 0.0)$\n  - 残基 $7$: $(3.8, 6.0, 0.0)$\n  - 残基 $8$: $(7.6, 6.0, 0.0)$\n  - 残基 $9$: $(11.4, 6.0, 0.0)$\n  - 残基 $10$: $(15.2, 6.0, 0.0)$\n- 一个DCA风格的预测残基对列表，附有相关分数，分数越高表示共进化耦合越强。每个元组为 $(i, j, s_{ij})$，其中 $i<j$，分数值 $s_{ij}$ 为实数。列表如下：\n  - $(2,7,0.95)$\n  - $(3,8,0.94)$\n  - $(1,6,0.93)$\n  - $(4,9,0.92)$\n  - $(5,10,0.91)$\n  - $(1,7,0.84)$\n  - $(2,8,0.83)$\n  - $(3,9,0.82)$\n  - $(4,10,0.81)$\n  - $(2,6,0.80)$\n  - $(3,7,0.79)$\n  - $(5,9,0.78)$\n  - $(1,8,0.77)$\n  - $(1,5,0.76)$\n  - $(6,10,0.75)$\n  - $(4,8,0.745)$\n  - $(2,9,0.74)$\n  - $(3,10,0.73)$\n- 使用序列间隔合格性阈值 $g=4$，即只有满足 $\\lvert i-j \\rvert \\ge 4$ 的对才有资格被评估。所有距离单位均为埃。所有精确率值必须报告为保留小数点后三位的小数。\n\n任务：\n- 编写一个完整的程序，针对下面测试套件中的每个测试用例 $(d_{c}, k)$，在接触定义截止距离 $d_{c}$ 下，使用上述坐标和预测计算前k个预测的精确率。您必须使用欧几里得距离从坐标中推导出接触标签，必须遵守合格性约束 $\\lvert i-j \\rvert \\ge g$，并且必须将 $d_{ij} \\le d_{c}$ 视为接触。\n\n待评估的测试套件：\n- 用例 A: $d_{c}=6.0$, $k=10$\n- 用例 B: $d_{c}=8.0$, $k=10$\n- 用例 C: $d_{c}=10.0$, $k=10$\n- 用例 D: $d_{c}=8.0$, $k=5$\n- 用例 E: $d_{c}=6.0$, $k=25$ (注意: $k$ 超过了符合条件的预测数量)\n- 用例 F: $d_{c}=8.0$, $k=13$\n- 用例 G: $d_{c}=10.0$, $k=13$\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含按顺序排列的用例 A 到 G 的精确率结果，形式为用逗号分隔并用方括号括起来的列表，例如，$\\left[\\dots\\right]$。每个值必须四舍五入到小数点后三位。", "solution": "所述问题是有效的。它在科学上基于计算蛋白质结构分析的原理，定义清晰，提供了所有必要的数据和定义，并且完全客观。没有逻辑矛盾、数据缺失或含糊不清之处。我们将进行系统性的解答。\n\n任务是为几个测试用例计算一个共进化接触预测器的精确率，每个用例由一对参数定义：接触距离截止值 $d_c$ 和要考虑的顶部预测数量 $k$。\n\n步骤如下：\n1.  筛选提供的预测对列表，仅保留那些基于序列间隔标准“符合条件的”对。\n2.  对于每个符合条件的对，使用其给定的 C-beta 坐标计算残基之间的真实欧几里得距离。\n3.  对于每个测试用例 $(d_c, k)$，确定要评估的预测集合并计算精确率。\n\n**步骤 1：数据表示和筛选**\n\n提供了 L=10 个残基的坐标。我们将其表示为从残基索引 i 到坐标 $(x_i, y_i, z_i)$ 的映射。设残基 i 的坐标为 $C_i$。\n坐标如下：\n$C_1=(0.0, 0.0, 0.0)$, $C_2=(3.8, 0.0, 0.0)$, $C_3=(7.6, 0.0, 0.0)$, $C_4=(11.4, 0.0, 0.0)$, $C_5=(15.2, 0.0, 0.0)$, $C_6=(0.0, 6.0, 0.0)$, $C_7=(3.8, 6.0, 0.0)$, $C_8=(7.6, 6.0, 0.0)$, $C_9=(11.4, 6.0, 0.0)$, $C_{10}=(15.2, 6.0, 0.0)$。\n\n问题提供了一个包含18个预测对 $(i, j, s_{ij})$ 的列表，已经按分数 $s_{ij}$ 的降序排列。这些预测必须通过合格性标准 $|i-j| \\ge g$（其中 $g=4$）进行筛选。\n\n我们检查每个预测：\n- $(2,7)$: $|7-2|=5 \\ge 4$。符合条件。\n- $(3,8)$: $|8-3|=5 \\ge 4$。符合条件。\n- $(1,6)$: $|6-1|=5 \\ge 4$。符合条件。\n- $(4,9)$: $|9-4|=5 \\ge 4$。符合条件。\n- $(5,10)$: $|10-5|=5 \\ge 4$。符合条件。\n- $(1,7)$: $|7-1|=6 \\ge 4$。符合条件。\n- $(2,8)$: $|8-2|=6 \\ge 4$。符合条件。\n- $(3,9)$: $|9-3|=6 \\ge 4$。符合条件。\n- $(4,10)$: $|10-4|=6 \\ge 4$。符合条件。\n- $(2,6)$: $|6-2|=4 \\ge 4$。符合条件。\n- $(3,7)$: $|7-3|=4 \\ge 4$。符合条件。\n- $(5,9)$: $|9-5|=4 \\ge 4$。符合条件。\n- $(1,8)$: $|8-1|=7 \\ge 4$。符合条件。\n- $(1,5)$: $|5-1|=4 \\ge 4$。符合条件。\n- $(6,10)$: $|10-6|=4 \\ge 4$。符合条件。\n- $(4,8)$: $|8-4|=4 \\ge 4$。符合条件。\n- $(2,9)$: $|9-2|=7 \\ge 4$。符合条件。\n- $(3,10)$: $|10-3|=7 \\ge 4$。符合条件。\n\n所有18个预测都满足合格性标准。因此，符合条件的预测列表就是完整的预测列表，其大小为 $N_{eligible} = 18$。\n\n**步骤 2：距离计算**\n\n对于18个符合条件的对 $(i,j)$ 中的每一个，我们计算欧几里得距离 $d_{ij} = \\sqrt{(x_i - x_j)^2 + (y_i - y_j)^2 + (z_i - z_j)^2}$。由于所有 z 坐标均为 0，公式简化为 $d_{ij} = \\sqrt{(x_i - x_j)^2 + (y_i - y_j)^2}$。\n\n排序后的符合条件的预测列表的计算距离如下：\n1.  对 $(2,7)$: $d_{2,7} = \\sqrt{(3.8-3.8)^2 + (0.0-6.0)^2} = 6.0$\n2.  对 $(3,8)$: $d_{3,8} = \\sqrt{(7.6-7.6)^2 + (0.0-6.0)^2} = 6.0$\n3.  对 $(1,6)$: $d_{1,6} = \\sqrt{(0.0-0.0)^2 + (0.0-6.0)^2} = 6.0$\n4.  对 $(4,9)$: $d_{4,9} = \\sqrt{(11.4-11.4)^2 + (0.0-6.0)^2} = 6.0$\n5.  对 $(5,10)$: $d_{5,10} = \\sqrt{(15.2-15.2)^2 + (0.0-6.0)^2} = 6.0$\n6.  对 $(1,7)$: $d_{1,7} = \\sqrt{(0.0-3.8)^2 + (0.0-6.0)^2} = \\sqrt{14.44 + 36} = \\sqrt{50.44} \\approx 7.102$\n7.  对 $(2,8)$: $d_{2,8} = \\sqrt{(3.8-7.6)^2 + (0.0-6.0)^2} = \\sqrt{14.44 + 36} = \\sqrt{50.44} \\approx 7.102$\n8.  对 $(3,9)$: $d_{3,9} = \\sqrt{(7.6-11.4)^2 + (0.0-6.0)^2} = \\sqrt{14.44 + 36} = \\sqrt{50.44} \\approx 7.102$\n9.  对 $(4,10)$: $d_{4,10} = \\sqrt{(11.4-15.2)^2 + (0.0-6.0)^2} = \\sqrt{14.44 + 36} = \\sqrt{50.44} \\approx 7.102$\n10. 对 $(2,6)$: $d_{2,6} = \\sqrt{(3.8-0.0)^2 + (0.0-6.0)^2} = \\sqrt{14.44 + 36} = \\sqrt{50.44} \\approx 7.102$\n11. 对 $(3,7)$: $d_{3,7} = \\sqrt{(7.6-3.8)^2 + (0.0-6.0)^2} = \\sqrt{14.44 + 36} = \\sqrt{50.44} \\approx 7.102$\n12. 对 $(5,9)$: $d_{5,9} = \\sqrt{(15.2-11.4)^2 + (0.0-6.0)^2} = \\sqrt{14.44 + 36} = \\sqrt{50.44} \\approx 7.102$\n13. 对 $(1,8)$: $d_{1,8} = \\sqrt{(0.0-7.6)^2 + (0.0-6.0)^2} = \\sqrt{57.76 + 36} = \\sqrt{93.76} \\approx 9.683$\n14. 对 $(1,5)$: $d_{1,5} = \\sqrt{(0.0-15.2)^2 + (0.0-0.0)^2} = 15.2$\n15. 对 $(6,10)$: $d_{6,10} = \\sqrt{(0.0-15.2)^2 + (6.0-6.0)^2} = 15.2$\n16. 对 $(4,8)$: $d_{4,8} = \\sqrt{(11.4-7.6)^2 + (0.0-6.0)^2} = \\sqrt{14.44 + 36} = \\sqrt{50.44} \\approx 7.102$\n17. 对 $(2,9)$: $d_{2,9} = \\sqrt{(3.8-11.4)^2 + (0.0-6.0)^2} = \\sqrt{57.76 + 36} = \\sqrt{93.76} \\approx 9.683$\n18. 对 $(3,10)$: $d_{3,10} = \\sqrt{(7.6-15.2)^2 + (0.0-6.0)^2} = \\sqrt{57.76 + 36} = \\sqrt{93.76} \\approx 9.683$\n\n如果 $d_{ij} \\le d_c$，则一对 $(i,j)$ 是一个真实接触。\n\n**步骤 3：各测试用例的精确率计算**\n\n我们现在评估每个用例。精确率为 $\\frac{TP}{N_{eval}}$，其中 TP 是真正例 (True Positives) 的数量，$N_{eval} = \\min(k, N_{eligible})$ 是被评估的预测数量。这里 $N_{eligible} = 18$。\n\n**用例 A: $d_{c}=6.0$, $k=10$**\n- $N_{eval} = \\min(10, 18) = 10$。\n- 我们考虑排名前10的预测。\n- 我们检查条件 $d_{ij} \\le 6.0$。第1到5对的距离 $d_{ij}=6.0$；第6到10对的距离 $d_{ij} \\approx 7.102 > 6.0$。\n- $TP = 5$。\n- 精确率 = $5/10 = 0.5$。结果：$0.500$。\n\n**用例 B: $d_{c}=8.0$, $k=10$**\n- $N_{eval} = \\min(10, 18) = 10$。\n- 我们考虑排名前10的预测。\n- 我们检查条件 $d_{ij} \\le 8.0$。第1到5对的距离 $d_{ij}=6.0$；第6到10对的距离 $d_{ij} \\approx 7.102$。两者都 $\\le 8.0$。\n- $TP = 10$。\n- 精确率 = $10/10 = 1.0$。结果：$1.000$。\n\n**用例 C: $d_{c}=10.0$, $k=10$**\n- $N_{eval} = \\min(10, 18) = 10$。\n- 我们考虑排名前10的预测。\n- 我们检查条件 $d_{ij} \\le 10.0$。排名前10对的所有距离都 $\\le 7.102$，因此 $\\le 10.0$。\n- $TP = 10$。\n- 精确率 = $10/10 = 1.0$。结果：$1.000$。\n\n**用例 D: $d_{c}=8.0$, $k=5$**\n- $N_{eval} = \\min(5, 18) = 5$。\n- 我们考虑排名前5的预测。\n- 我们检查条件 $d_{ij} \\le 8.0$。排名前5对的所有距离都是 $6.0$，小于等于 $8.0$。\n- $TP = 5$。\n- 精确率 = $5/5 = 1.0$。结果：$1.000$。\n\n**用例 E: $d_{c}=6.0$, $k=25$**\n- $N_{eval} = \\min(25, 18) = 18$。我们评估所有符合条件的预测。\n- 我们考虑所有18个预测。\n- 我们检查条件 $d_{ij} \\le 6.0$。只有第1到5对满足此条件。\n- $TP = 5$。\n- 精确率 = $5/18 \\approx 0.2777...$。四舍五入到3位小数：$0.278$。\n\n**用例 F: $d_{c}=8.0$, $k=13$**\n- $N_{eval} = \\min(13, 18) = 13$。\n- 我们考虑排名前13的预测。\n- 我们检查 $d_{ij} \\le 8.0$。第1-5对的距离 $d_{ij}=6.0$。第6-12对的距离 $d_{ij} \\approx 7.102$。第13对的距离 $d_{ij} \\approx 9.683 > 8.0$。\n- 排名前13的预测是第1到第13对。它们的距离分别为 $6.0$（5次）、$7.102$（7次）和 $9.683$（1次）。\n- 距离 $\\le 8.0$ 的是对前12对。\n- $TP = 12$。\n- 精确率 = $12/13 \\approx 0.92307...$。四舍五入到3位小数：$0.923$。\n\n**用例 G: $d_{c}=10.0$, $k=13$**\n- $N_{eval} = \\min(13, 18) = 13$。\n- 我们考虑排名前13的预测。\n- 我们检查 $d_{ij} \\le 10.0$。排名前13对的距离分别为 $6.0$（5次）、$7.102$（7次）和 $\\approx 9.683$（1次）。所有距离都 $\\le 10.0$。\n- $TP = 13$。\n- 精确率 = $13/13 = 1.0$。结果：$1.000$。\n\n因此，用例A到G的最终精确率向量为 $[0.500, 1.000, 1.000, 1.000, 0.278, 0.923, 1.000]$。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes precision for coevolutionary contact predictions based on specified parameters.\n    \"\"\"\n    # Define residue coordinates (1-based indexing for convenience)\n    coords = {\n        1: np.array([0.0, 0.0, 0.0]),\n        2: np.array([3.8, 0.0, 0.0]),\n        3: np.array([7.6, 0.0, 0.0]),\n        4: np.array([11.4, 0.0, 0.0]),\n        5: np.array([15.2, 0.0, 0.0]),\n        6: np.array([0.0, 6.0, 0.0]),\n        7: np.array([3.8, 6.0, 0.0]),\n        8: np.array([7.6, 6.0, 0.0]),\n        9: np.array([11.4, 6.0, 0.0]),\n        10: np.array([15.2, 6.0, 0.0]),\n    }\n\n    # List of predictions (i, j, score), already sorted by score\n    predictions = [\n        (2, 7, 0.95), (3, 8, 0.94), (1, 6, 0.93), (4, 9, 0.92), (5, 10, 0.91),\n        (1, 7, 0.84), (2, 8, 0.83), (3, 9, 0.82), (4, 10, 0.81), (2, 6, 0.80),\n        (3, 7, 0.79), (5, 9, 0.78), (1, 8, 0.77), (1, 5, 0.76), (6, 10, 0.75),\n        (4, 8, 0.745), (2, 9, 0.74), (3, 10, 0.73)\n    ]\n    \n    g = 4  # Sequence separation threshold\n\n    # Filter for eligible predictions and calculate distances\n    eligible_predictions = []\n    for i, j, score in predictions:\n        if abs(i - j) >= g:\n            dist = np.linalg.norm(coords[i] - coords[j])\n            eligible_predictions.append({'pair': (i, j), 'dist': dist})\n\n    # Test suite to evaluate\n    test_cases = [\n        {'d_c': 6.0, 'k': 10},   # Case A\n        {'d_c': 8.0, 'k': 10},   # Case B\n        {'d_c': 10.0, 'k': 10},  # Case C\n        {'d_c': 8.0, 'k': 5},    # Case D\n        {'d_c': 6.0, 'k': 25},   # Case E\n        {'d_c': 8.0, 'k': 13},   # Case F\n        {'d_c': 10.0, 'k': 13},  # Case G\n    ]\n\n    results = []\n    for case in test_cases:\n        d_c = case['d_c']\n        k = case['k']\n\n        # Determine the number of predictions to evaluate\n        num_eligible = len(eligible_predictions)\n        num_to_evaluate = min(k, num_eligible)\n\n        if num_to_evaluate == 0:\n            # Handle edge case of no predictions to evaluate\n            precision = 0.0\n        else:\n            # Get the top predictions to evaluate\n            top_predictions = eligible_predictions[:num_to_evaluate]\n            \n            # Count true positives (TPs)\n            true_positives = 0\n            for pred in top_predictions:\n                if pred['dist'] <= d_c:\n                    true_positives += 1\n            \n            # Calculate precision\n            precision = true_positives / num_to_evaluate\n        \n        # Format the result to exactly three decimal places\n        results.append(f\"{precision:.3f}\")\n\n    # Print the final output in the required format\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2380714"}, {"introduction": "共演化分析提供的不仅仅是一份残基对列表，它更揭示了一个支撑蛋白质折叠与功能的相互作用网络。在这个练习中，你将学习如何将高分共演化信号对构建成一个网络图，并应用社区发现算法来识别其中紧密耦合的残基集群。通过将这些数据驱动的“社区”与已知的结构特征（如二级结构或亚结构域）进行比较，你将亲身体验从微观的进化信号中提取宏观结构模块的强大能力。[@problem_id:2380694]", "problem": "您的任务是形式化分析共演化衍生的接触图。您需要通过对高分直接耦合分析 (DCA) 对构成的图进行聚类，并评估所产生的社群是否与已知的结构特征相对应。对于每个测试用例，您将获得序列长度 $L$，一个对称耦合矩阵 $S \\in \\mathbb{R}^{L \\times L}$（其中对于所有索引 $i,j$ 都有 $S_{ii} = 0$ 和 $S_{ij} = S_{ji}$），一个阈值 $\\tau \\in \\mathbb{R}$（用于定义一个无向简单图 $G = (V,E)$，其顶点集为 $V = \\{0,1,\\dots,L-1\\}$，当且仅当 $S_{ij} \\ge \\tau$ 且 $i \\ne j$ 时，边 $(i,j) \\in E$），以及两种类型的真实标签：二级结构标签和亚域标签。二级结构标签从集合 $\\{\\mathrm{H}, \\mathrm{E}, \\mathrm{C}\\}$ 中选取，分别对应 $\\alpha$-螺旋、$\\beta$-折叠和无规卷曲。亚域标签从 $\\{\\mathrm{A}, \\mathrm{B}\\}$ 中选取。目标是推导出顶点集的两种社群划分，并对每种划分量化其社群与二级结构和亚域的对齐程度，以及相对于图的社群结构质量。\n\n形式上，设 $A \\in \\{0,1\\}^{L \\times L}$ 是由 $S$ 和 $\\tau$ 导出的邻接矩阵，其中对所有 $i$ 都有 $A_{ii} = 0$。设 $k_i = \\sum_{j=0}^{L-1} A_{ij}$ 为顶点 $i$ 的度，设 $m = \\frac{1}{2}\\sum_{i=0}^{L-1}\\sum_{j=0}^{L-1} A_{ij}$ 为边的数量。社群划分是一个映射 $c: \\{0,1,\\dots,L-1\\} \\to \\mathbb{Z}$，它为每个顶点 $i$ 分配一个整数社群标签 $c(i)$。划分 $c$ 相对于 $A$ 的模块度 $Q$ 定义为\n$$\nQ(c;A) = \\begin{cases}\n\\frac{1}{2m} \\sum_{i=0}^{L-1}\\sum_{j=0}^{L-1} \\left( A_{ij} - \\frac{k_i k_j}{2m} \\right) \\mathbf{1}\\{c(i) = c(j)\\}, & \\text{if } m > 0, \\\\\\\\\n0, & \\text{if } m = 0,\n\\end{cases}\n$$\n其中 $\\mathbf{1}\\{\\cdot\\}$ 是指示函数。\n\n设 $y^{\\mathrm{sec}} \\in \\{\\mathrm{H},\\mathrm{E},\\mathrm{C}\\}^{L}$ 是二级结构标签，$y^{\\mathrm{dom}} \\in \\{\\mathrm{A},\\mathrm{B}\\}^{L}$ 是亚域标签。对于任何划分 $c$，其相对于真实标签 $y \\in \\mathcal{Y}^{L}$ 的纯度定义为\n$$\n\\mathrm{Purity}(c,y) = \\frac{1}{L} \\sum_{u \\in \\mathcal{C}} \\max_{t \\in \\mathcal{Y}} \\left| \\{ i \\in \\{0,1,\\dots,L-1\\} : c(i) = u \\text{ and } y_i = t \\} \\right|,\n$$\n其中 $\\mathcal{C}$ 是划分 $c$ 中的不同社群标签的集合，$\\mathcal{Y}$ 是 $y$ 中可能标签的集合。\n\n您的程序必须为每个测试用例计算两种确定性的社群划分：\n1. 划分 $\\mathcal{P}_1$：一个在以下单顶点社群重分配规则下的不动点。按索引递增顺序 $i = 0,1,\\dots,L-1$ 考虑顶点；对于每个顶点 $i$，在其闭邻域 $\\{i\\} \\cup \\{ j : A_{ij} = 1 \\}$ 中存在的社群集合中，将 $i$ 重新分配到能够使模块度 $Q$ 产生最大增益（严格为正）的社群，若增益相同，则选择数值最小的社群标签来打破平局。重复遍历所有顶点，直到某一次完整遍历中没有发生任何重分配。\n2. 划分 $\\mathcal{P}_2$：一个在以下标签多数动态规则下的不动点。首先将每个顶点初始化为其索引作为唯一标签。然后，迭代地对 $i = 0,1,\\dots,L-1$ 设置顶点 $i$ 的标签，使其等于其邻居 $\\{ j : A_{ij} = 1 \\}$ 中最频繁的标签；当多个标签出现频率并列最高时，选择数值最小的标签；如果 $i$ 没有邻居，则保持其当前标签。重复遍历所有顶点，直到某一次完整遍历中没有标签发生改变。\n\n对于每种划分 $\\mathcal{P}_1$ 和 $\\mathcal{P}_2$，计算：\n- 模块度 $Q$\n- 相对于二级结构标签的纯度 $\\mathrm{Purity}(\\cdot, y^{\\mathrm{sec}})$\n- 相对于亚域标签的纯度 $\\mathrm{Purity}(\\cdot, y^{\\mathrm{dom}})$\n\n您的程序必须将所有测试用例的结果汇总到单行中。对于每个测试用例，按顺序 $[Q(\\mathcal{P}_1), \\mathrm{Purity}(\\mathcal{P}_1,y^{\\mathrm{sec}}), \\mathrm{Purity}(\\mathcal{P}_1,y^{\\mathrm{dom}}), Q(\\mathcal{P}_2), \\mathrm{Purity}(\\mathcal{P}_2,y^{\\mathrm{sec}}), \\mathrm{Purity}(\\mathcal{P}_2,y^{\\mathrm{dom}})]$ 输出一个包含六个实数的列表。您的程序应生成一个单行，包含一个由这些按测试用例排列的列表组成的逗号分隔列表，该列表用方括号括起来，且不含空格。所有实数必须以小数形式打印，并四舍五入到小数点后六位。\n\n测试套件。使用以下三个测试用例。对于每个用例，矩阵 $S$ 要么被明确指定，要么通过一个规则为 $i \\ne j$ 的 $S_{ij}$ 赋值；始终取 $S_{ii} = 0$ 和 $S_{ij} = S_{ji}$。\n\n- 测试用例 1:\n  - $L = 10$。\n  - $y^{\\mathrm{sec}} = [\\mathrm{H}, \\mathrm{H}, \\mathrm{H}, \\mathrm{H}, \\mathrm{E}, \\mathrm{E}, \\mathrm{E}, \\mathrm{C}, \\mathrm{C}, \\mathrm{C}]$。\n  - $y^{\\mathrm{dom}} = [\\mathrm{A}, \\mathrm{A}, \\mathrm{A}, \\mathrm{A}, \\mathrm{A}, \\mathrm{B}, \\mathrm{B}, \\mathrm{B}, \\mathrm{B}, \\mathrm{B}]$。\n  - 对于 $i \\ne j$, 定义\n    $$\n    S_{ij} = \\begin{cases}\n    1.0, & \\text{if } y^{\\mathrm{sec}}_i = y^{\\mathrm{sec}}_j, \\\\\\\\\n    0.6, & \\text{if } y^{\\mathrm{sec}}_i \\ne y^{\\mathrm{sec}}_j \\text{ and } y^{\\mathrm{dom}}_i = y^{\\mathrm{dom}}_j, \\\\\\\\\n    0.2, & \\text{if } y^{\\mathrm{dom}}_i \\ne y^{\\mathrm{dom}}_j.\n    \\end{cases}\n    $$\n  - 阈值 $\\tau = 0.5$。\n\n- 测试用例 2:\n  - $L = 6$。\n  - $y^{\\mathrm{sec}} = [\\mathrm{H}, \\mathrm{E}, \\mathrm{C}, \\mathrm{H}, \\mathrm{E}, \\mathrm{C}]$。\n  - $y^{\\mathrm{dom}} = [\\mathrm{A}, \\mathrm{A}, \\mathrm{A}, \\mathrm{B}, \\mathrm{B}, \\mathrm{B}]$。\n  - 对于 $i \\ne j$, $S_{ij} = 0.1$。\n  - 阈值 $\\tau = 0.9$。\n\n- 测试用例 3:\n  - $L = 8$。\n  - $y^{\\mathrm{sec}} = [\\mathrm{H}, \\mathrm{H}, \\mathrm{E}, \\mathrm{E}, \\mathrm{C}, \\mathrm{C}, \\mathrm{H}, \\mathrm{E}]$。\n  - $y^{\\mathrm{dom}} = [\\mathrm{A}, \\mathrm{B}, \\mathrm{A}, \\mathrm{B}, \\mathrm{A}, \\mathrm{B}, \\mathrm{A}, \\mathrm{B}]$。\n  - 对于 $i \\ne j$, $S_{ij} = 1.0$。\n  - 阈值 $\\tau = 0.5$。\n\n最终输出格式。您的程序必须输出一个单行，该行是一个列表的字符串表示，其中包含恰好三个元素（每个测试用例一个），每个元素是一个包含六个小数的列表，小数四舍五入到小数点后六位，且不含任何空格。例如，一个带有占位符的输出看起来像 `[[x_{11},x_{12},x_{13},x_{14},x_{15},x_{16}],[x_{21},x_{22},x_{23},x_{24},x_{25},x_{26}],[x_{31},x_{32},x_{33},x_{34},x_{35},x_{36}]]`，其中每个 $x_{ab}$ 都是一个按规定格式化的小数。", "solution": "该问题要求在从共演化分析数据衍生的图上，实现并评估两种不同的社群检测算法。评估是通过测量模块度和两种真实标签下的纯度来执行的。该问题定义明确，在计算生物学领域有科学依据，并提供了明确的确定性算法，确保了唯一解。\n\n首先，让我们为每个测试用例形式化该过程。\n- 给定一个对称耦合矩阵 $S \\in \\mathbb{R}^{L \\times L}$ 和一个阈值 $\\tau$。由此构建一个无向简单图 $G=(V,E)$。顶点集为 $V = \\{0, 1, \\dots, L-1\\}$，当且仅当 $i \\ne j$ 且 $S_{ij} \\ge \\tau$ 时，存在一条边 $(i, j)$。这由一个邻接矩阵 $A$ 表示，其中如果 $(i,j)\\in E$ 则 $A_{ij} = 1$，否则 $A_{ij}=0$，且 $A_{ii}=0$。\n- 顶点 $i$ 的度为 $k_i = \\sum_{j=0}^{L-1} A_{ij}$。\n- 图中边的总数为 $m = \\frac{1}{2} \\sum_{i,j} A_{ij}$。\n\n两项主要任务是找到顶点集 $V$ 的两种划分 $\\mathcal{P}_1$ 和 $\\mathcal{P}_2$。\n\n**划分 $\\mathcal{P}_1$：模块度优化**\n该划分通过一种基于模块度最大化的贪婪迭代算法找到。\n1.  **初始化**：每个顶点 $i$ 被分配到其自己的唯一社群中，因此初始划分为对所有 $i \\in V$，有 $c(i) = i$。\n2.  **迭代**：算法按轮次进行。在每一轮中，按顺序从 $i = 0$ 到 $L-1$ 考虑顶点。对于每个顶点 $i$，我们评估将其从当前社群移动到不同社群所导致的模块度变化 $\\Delta Q$。为 $i$ 寻找新社群的搜索范围被限制在其闭邻域中存在的社群，即其邻居 $\\{j : A_{ij}=1\\}$ 和其自身所属的社群集合。\n3.  **模块度增益计算**：一个划分 $c$ 的模块度由以下公式给出\n    $$Q(c;A) = \\frac{1}{2m} \\sum_{i,j} \\left( A_{ij} - \\frac{k_i k_j}{2m} \\right) \\mathbf{1}\\{c(i) = c(j)\\}$$\n    对于 $m > 0$，而当 $m=0$ 时 $Q=0$。要找到将顶点 $i$ 从其当前社群 $C_{old}$ 移动到新社群 $C_{new}$ 的最佳移动，我们计算增益 $\\Delta Q$。将顶点 $i$ 移入社群 $C$ 的增益可以高效地计算为\n    $$ \\Delta Q_{i \\to C} = \\left[ \\frac{\\sum_{\\mathrm{in}}(C) + 2k_{i,C}}{2m} - \\left(\\frac{\\sum_{\\mathrm{tot}}(C)+k_i}{2m}\\right)^2 \\right] - \\left[ \\frac{\\sum_{\\mathrm{in}}(C)}{2m} - \\left(\\frac{\\sum_{\\mathrm{tot}}(C)}{2m}\\right)^2 \\right] $$\n    其中 $\\sum_{\\mathrm{in}}(C)$ 是社群 $C$ 内部边权重之和（对于无权图，这是内部边数的两倍），$\\sum_{\\mathrm{tot}}(C)$ 是 $C$ 中所有顶点的度之和，而 $k_{i,C}$ 是从顶点 $i$ 到社群 $C$ 中顶点的边权重之和。将 $i$ 从其原始社群移出时，会产生相应的模块度损失。总变化量是将 $i$ 加入新社群的增益减去将其从旧社群移除的损失。\n4.  **顶点重分配**：顶点 $i$ 被移动到能产生最大、严格为正的 $Q$ 增益的邻居社群。如果多个社群产生相同的最大增益，则选择数值最小的社群标签作为打破平局的规则。\n5.  **终止**：重复轮次，直到对所有顶点的完整一轮遍历不再发生重分配，这表示已达到模块度的局部最大值。得到的划分即为 $\\mathcal{P}_1$。\n\n**划分 $\\mathcal{P}_2$：标签传播**\n该划分使用标签传播算法找到，这是一种简单高效的社群检测方法。\n1.  **初始化**：每个顶点 $i$ 被分配一个唯一的标签，即其自身的索引，因此对所有 $i \\in V$ 有 $c(i) = i$。\n2.  **迭代**：算法按轮次进行。在每一轮中，按顺序从 $i = 0$ 到 $L-1$ 考虑顶点。\n3.  **标签更新**：对于每个顶点 $i$，其标签被更新为其邻居 $\\{j : A_{ij}=1\\}$ 中最频繁的标签。如果频率出现平局，则选择并列标签中数值最小的。如果一个顶点没有邻居，其标签保持不变。更新是异步的，意味着顶点 $i$ 的新标签可立即用于同一轮次中后续的顶点。\n4.  **终止**：重复轮次，直到在一轮完整的遍历中没有顶点的标签发生变化。得到的划分即为 $\\mathcal{P}_2$。\n\n**评估指标**\n对于每个划分 $\\mathcal{P}_k \\in \\{\\mathcal{P}_1, \\mathcal{P}_2\\}$，我们计算三个值：\n1.  **模块度 $Q(\\mathcal{P}_k; A)$**：使用上面提供的公式计算。\n2.  **相对于二级结构的纯度 ($y^{\\mathrm{sec}}$)**：这衡量了社群相对于真实标签的同质性。给定 $y^{\\mathrm{sec}} \\in \\{\\mathrm{H}, \\mathrm{E}, \\mathrm{C}\\}^L$，纯度为：\n    $$ \\mathrm{Purity}(c, y^{\\mathrm{sec}}) = \\frac{1}{L} \\sum_{u \\in \\mathcal{C}} \\max_{t \\in \\{\\mathrm{H,E,C}\\}} \\left| \\{ i : c(i) = u \\text{ and } y^{\\mathrm{sec}}_i = t \\} \\right| $$\n    其中 $\\mathcal{C}$ 是划分 $c$ 中的社群集合。\n3.  **相对于亚域的纯度 ($y^{\\mathrm{dom}}$)**：类似地，对于 $y^{\\mathrm{dom}} \\in \\{\\mathrm{A}, \\mathrm{B}\\}^L$，纯度为：\n    $$ \\mathrm{Purity}(c, y^{\\mathrm{dom}}) = \\frac{1}{L} \\sum_{u \\in \\mathcal{C}} \\max_{t \\in \\{\\mathrm{A,B}\\}} \\left| \\{ i : c(i) = u \\text{ and } y^{\\mathrm{dom}}_i = t \\} \\right| $$\n\n实现将处理每个测试用例，构建图，运行两种社群检测算法，计算六个指定的指标，并将它们格式化为指定的最终输出列表。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom collections import Counter\n\ndef build_graph(L, S_rule, y_sec, y_dom, tau):\n    \"\"\"Constructs the adjacency matrix from the coupling matrix rule.\"\"\"\n    S = np.zeros((L, L))\n    if S_rule == \"explicit_1\":\n        for i in range(L):\n            for j in range(i + 1, L):\n                val = 0.0\n                if y_sec[i] == y_sec[j]:\n                    val = 1.0\n                elif y_dom[i] == y_dom[j]:\n                    val = 0.6\n                else:\n                    val = 0.2\n                S[i, j] = S[j, i] = val\n    elif S_rule == \"explicit_2\":\n        S.fill(0.1)\n        np.fill_diagonal(S, 0)\n    elif S_rule == \"explicit_3\":\n        S.fill(1.0)\n        np.fill_diagonal(S, 0)\n    \n    A = (S >= tau).astype(int)\n    np.fill_diagonal(A, 0)\n    return A\n\ndef calculate_modularity(A, communities, m, k_degrees):\n    \"\"\"Calculates the modularity of a given partition.\"\"\"\n    if m == 0:\n        return 0.0\n    \n    L = A.shape[0]\n    Q = 0.0\n    \n    # Use numpy for efficiency\n    comms, comm_inv = np.unique(communities, return_inverse=True)\n    n_comms = len(comms)\n    \n    # Sum of degrees in each community\n    sigma_tot = np.zeros(n_comms)\n    np.add.at(sigma_tot, comm_inv, k_degrees)\n    \n    # Number of edges within each community\n    e_cc = np.zeros(n_comms)\n    for i in range(L):\n        for j in range(i + 1, L):\n            if A[i, j] == 1 and communities[i] == communities[j]:\n                comm_idx = np.where(comms == communities[i])[0][0]\n                e_cc[comm_idx] += 1\n                \n    Q = np.sum(e_cc / m - (sigma_tot / (2 * m))**2)\n    return Q\n\n\ndef calculate_purity(communities, labels, label_map):\n    \"\"\"Calculates the purity of a partition against ground-truth labels.\"\"\"\n    L = len(communities)\n    if L == 0:\n        return 0.0\n        \n    total_max_sum = 0\n    unique_comms = np.unique(communities)\n    \n    for comm_label in unique_comms:\n        member_indices = np.where(communities == comm_label)[0]\n        if len(member_indices) == 0:\n            continue\n            \n        gt_labels_in_comm = [labels[i] for i in member_indices]\n        if not gt_labels_in_comm:\n            continue\n        \n        counts = Counter(gt_labels_in_comm)\n        max_count = max(counts.values())\n        total_max_sum += max_count\n        \n    return total_max_sum / L\n\ndef run_p1(A, k_degrees, m, L):\n    \"\"\"Partition P1: Modularity-based community detection.\"\"\"\n    communities = np.arange(L)\n    if m == 0:\n        return communities\n    \n    inverse_m = 1.0 / m\n    inverse_2m = 1.0 / (2*m)\n\n    while True:\n        changed = False\n        for i in range(L):\n            current_comm = communities[i]\n            k_i = k_degrees[i]\n            \n            # Find communities of neighbors\n            neighbors = np.where(A[i, :] == 1)[0]\n            neighbor_comms = {communities[j] for j in neighbors}\n            neighbor_comms.add(current_comm)\n\n            best_comm = current_comm\n            max_delta_q = 0.0\n            \n            # Remove i from its community\n            nodes_in_current_comm = np.where(communities == current_comm)[0]\n            sigma_tot_D = np.sum(k_degrees[nodes_in_current_comm])\n            k_i_D = np.sum(A[i, nodes_in_current_comm])\n\n            for comm_label in neighbor_comms:\n                if comm_label == current_comm:\n                    continue\n\n                nodes_in_target_comm = np.where(communities == comm_label)[0]\n                sigma_tot_C = np.sum(k_degrees[nodes_in_target_comm])\n                k_i_C = np.sum(A[i, nodes_in_target_comm])\n                \n                delta_q = (k_i_C - k_i_D) * inverse_m - k_i * (sigma_tot_C - (sigma_tot_D - k_i)) * inverse_2m * inverse_m\n                \n                if delta_q > max_delta_q:\n                    max_delta_q = delta_q\n                    best_comm = comm_label\n                elif abs(delta_q - max_delta_q)  1e-12 and comm_label  best_comm:\n                    best_comm = comm_label\n            \n            if best_comm != current_comm and max_delta_q > 1e-12:\n                communities[i] = best_comm\n                changed = True\n        \n        if not changed:\n            break\n            \n    return communities\n\ndef run_p2(A, L):\n    \"\"\"Partition P2: Label propagation.\"\"\"\n    communities = np.arange(L)\n    \n    while True:\n        changed = False\n        for i in range(L):\n            current_label = communities[i]\n            neighbors = np.where(A[i, :] == 1)[0]\n            if len(neighbors) == 0:\n                continue\n\n            neighbor_labels = communities[neighbors]\n            counts = Counter(neighbor_labels)\n            \n            if not counts: continue\n            \n            max_freq = max(counts.values())\n            best_labels = sorted([label for label, freq in counts.items() if freq == max_freq])\n            new_label = best_labels[0]\n\n            if new_label != current_label:\n                communities[i] = new_label\n                changed = True\n\n        if not changed:\n            break\n            \n    return communities\n\ndef solve():\n    test_cases = [\n        {\n            \"L\": 10,\n            \"y_sec\": list(\"HHHHEEECCC\"),\n            \"y_dom\": list(\"AAAAABBBBB\"),\n            \"S_rule\": \"explicit_1\",\n            \"tau\": 0.5\n        },\n        {\n            \"L\": 6,\n            \"y_sec\": list(\"HECHEC\"),\n            \"y_dom\": list(\"AAABBB\"),\n            \"S_rule\": \"explicit_2\",\n            \"tau\": 0.9\n        },\n        {\n            \"L\": 8,\n            \"y_sec\": list(\"HHEECCHE\"),\n            \"y_dom\": list(\"ABABABAB\"),\n            \"S_rule\": \"explicit_3\",\n            \"tau\": 0.5\n        }\n    ]\n\n    sec_map = {'H': 0, 'E': 1, 'C': 2}\n    dom_map = {'A': 0, 'B': 1}\n\n    all_results = []\n\n    for case in test_cases:\n        L = case[\"L\"]\n        y_sec_str = case[\"y_sec\"]\n        y_dom_str = case[\"y_dom\"]\n        y_sec = [sec_map[s] for s in y_sec_str]\n        y_dom = [dom_map[d] for d in y_dom_str]\n        tau = case[\"tau\"]\n        S_rule = case[\"S_rule\"]\n\n        A = build_graph(L, S_rule, y_sec_str, y_dom_str, tau)\n        k_degrees = np.sum(A, axis=1)\n        m = np.sum(k_degrees) / 2.0\n\n        # Partition P1\n        communities1 = run_p1(A, k_degrees, m, L)\n        q1 = calculate_modularity(A, communities1, m, k_degrees)\n        purity1_sec = calculate_purity(communities1, y_sec, sec_map)\n        purity1_dom = calculate_purity(communities1, y_dom, dom_map)\n        \n        # Partition P2\n        communities2 = run_p2(A, L)\n        q2 = calculate_modularity(A, communities2, m, k_degrees)\n        purity2_sec = calculate_purity(communities2, y_sec, sec_map)\n        purity2_dom = calculate_purity(communities2, y_dom, dom_map)\n        \n        case_results = [\n            q1, purity1_sec, purity1_dom,\n            q2, purity2_sec, purity2_dom\n        ]\n        all_results.append(case_results)\n\n    list_of_strings = [f\"[{','.join([f'{x:.6f}' for x in r])}]\" for r in all_results]\n    final_string = f\"[{','.join(list_of_strings)}]\"\n    print(final_string)\n\nsolve()\n```", "id": "2380694"}]}