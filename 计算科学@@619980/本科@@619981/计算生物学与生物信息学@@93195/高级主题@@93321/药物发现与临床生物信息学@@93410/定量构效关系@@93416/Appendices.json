{"hands_on_practices": [{"introduction": "本练习将定量构效关系（QSAR）的一个基本概念——Hansch分析——付诸实践。它揭示了化合物的生物活性通常并非其物化性质的简单线性函数，而是可能存在一个最佳值。通过计算能使生物活性最大化的理想疏水性（$cLogP$），您将练习药物设计中的一项核心技能：确定实现最大效价的理想物化性质。[@problem_id:2423851]", "problem": "在定量构效关系（QSAR）建模中，化合物的疏水性通常由计算出的辛醇-水分配系数的对数（cLogP）来编码。考虑一个由以下函数给出的生物效价与疏水性之间的Hansch型关系\n$$\n\\log_{10}\\!\\left(\\frac{1}{C}\\right) \\;=\\; 0.5 \\cdot \\mathrm{cLogP} \\;-\\; 0.01 \\cdot (\\mathrm{cLogP})^{2} \\;+\\; 1.2,\n$$\n其中，$C$ 表示达到特定效应水平所需的摩尔浓度，而 $\\mathrm{cLogP}$ 是无量纲的。根据QSAR中的标准解释，最佳疏水性对应于使生物活性最大化的$\\mathrm{cLogP}$值，这等同于使$\\log_{10}(1/C)$最大化。\n\n确定最佳$\\mathrm{cLogP}$。请提供精确值，不要进行四舍五入。答案是无单位的。", "solution": "首先必须对问题陈述进行严格验证。\n\n**步骤1：提取已知条件**\n逐字列出所给的已知条件：\n- Hansch型关系：$\\log_{10}\\!\\left(\\frac{1}{C}\\right) \\;=\\; 0.5 \\cdot \\mathrm{cLogP} \\;-\\; 0.01 \\cdot (\\mathrm{cLogP})^{2} \\;+\\; 1.2$\n- $C$ 是达到特定效应水平所需的摩尔浓度。\n- $\\mathrm{cLogP}$ 是无量纲的。\n- 目标是找到使生物活性最大化的$\\mathrm{cLogP}$值，这等同于使函数$\\log_{10}(1/C)$最大化。\n\n**步骤2：使用提取的已知条件进行验证**\n根据所需标准对问题进行评估。\n1.  **科学依据**：该问题描述了Hansch分析，这是定量构效关系（QSAR）研究中的一个基本概念。生物响应与像疏水性（$\\mathrm{cLogP}$）这样的理化参数之间的抛物线关系是一个经典模型，用于解释膜渗透和受体结合等性质如何影响活性。该方程是此模型的标准表示。因此，该问题在科学上是合理的，并基于计算药物设计的既定原则。\n2.  **适定性**：任务是求一个二次函数的最大值。该函数有明确的定义，要优化的变量也已清楚说明。一个平方项系数为负的二次函数有唯一的全局最大值。因此，该问题是适定的。\n3.  **客观性和自包含性**：该问题使用精确、客观的数学和科学语言陈述。解决问题所需的所有信息均已提供。没有歧义或缺失的定义。\n\n**步骤3：结论与行动**\n该问题是有效的。这是一个基于计算化学标准模型的直接优化问题。我将继续进行求解。\n\n问题要求找到使生物活性最大化的$\\mathrm{cLogP}$的最佳值，该生物活性由函数$\\log_{10}(1/C)$给出。我们定义一个函数 $f(x)$，其中 $x = \\mathrm{cLogP}$。需要最大化的函数是：\n$$\nf(x) = 0.5 x - 0.01 x^2 + 1.2\n$$\n这是一个形如 $f(x) = ax^2 + bx + c$ 的二次函数，其中系数为 $a = -0.01$，$b = 0.5$ 和 $c = 1.2$。由于系数 $a$ 为负（$a = -0.01 < 0$），该函数的图像是一个开口向下的抛物线，这保证了存在唯一的全局最大值。\n\n为了找到使 $f(x)$ 最大化的 $x$ 值，我们必须使用微分学。最大值出现在函数对 $x$ 的一阶导数等于零的临界点。\n我们计算一阶导数 $f'(x)$：\n$$\nf'(x) = \\frac{d}{dx} \\left( 0.5 x - 0.01 x^2 + 1.2 \\right)\n$$\n应用幂法则进行微分：\n$$\nf'(x) = 0.5 - (2 \\cdot 0.01) x^{1} + 0\n$$\n$$\nf'(x) = 0.5 - 0.02 x\n$$\n现在，我们将一阶导数设为零以找到临界点：\n$$\n0.5 - 0.02 x = 0\n$$\n求解这个关于 $x$ 的线性方程：\n$$\n0.02 x = 0.5\n$$\n$$\nx = \\frac{0.5}{0.02}\n$$\n为了简化分数，我们可以将分子和分母同乘以 $100$：\n$$\nx = \\frac{50}{2} = 25\n$$\n为了确认该 $x$ 值对应一个最大值，我们可以使用二阶导数检验。我们计算二阶导数 $f''(x)$：\n$$\nf''(x) = \\frac{d}{dx} (0.5 - 0.02 x) = -0.02\n$$\n由于对于所有 $x$ 值，$f''(x) = -0.02 < 0$，所以该函数处处向下凹，因此在 $x=25$ 处的临界点确实是一个全局最大值。\n\n因此，使生物活性最大化的$\\mathrm{cLogP}$的最佳值是 $25$。", "answer": "$$\\boxed{25}$$", "id": "2423851"}, {"introduction": "一个QSAR模型的预测能力只有在其“适用域”（Applicability Domain, AD）内才是可靠的。本练习将引导您从理论走向实践，通过编程实现杠杆值法，这是一种定义模型AD的标准技术。这项实践对于培养一项关键技能至关重要：评估模型对新化合物的预测是值得信赖的，还是不可靠的外推。[@problem_id:2423889]", "problem": "一个分子描述符数据集被用于开发一个定量构效关系（QSAR）模型。一个新化合物产生了较大的预测误差。请判断，使用基于标准化描述符空间中计算出的杠杆值的适用域准则，这种失败是否本可以被预测。\n\n设训练描述符矩阵为 $X \\in \\mathbb{R}^{n \\times m}$，其中包含 $n=12$ 个化合物和 $m=3$ 个描述符。对于描述符的每一列 $j \\in \\{1,2,3\\}$，计算训练集的平均值 $\\mu_j$ 和总体标准差 $\\sigma_j$ 如下\n$$\n\\mu_j \\;=\\; \\frac{1}{n}\\sum_{i=1}^{n} X_{ij}, \\qquad\n\\sigma_j \\;=\\; \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n} \\bigl(X_{ij}-\\mu_j\\bigr)^2}.\n$$\n按列标准化训练矩阵以得到 $Z \\in \\mathbb{R}^{n \\times m}$，其元素为 $Z_{ij} = \\frac{X_{ij}-\\mu_j}{\\sigma_j}$。定义对称正定矩阵 $S \\in \\mathbb{R}^{m \\times m}$ 为\n$$\nS \\;=\\; Z^\\top Z.\n$$\n对于一个具有原始描述符向量 $x_{\\text{new}} \\in \\mathbb{R}^m$ 的新化合物，使用训练集的统计数据将其标准化，得到 $z_{\\text{new}} \\in \\mathbb{R}^m$，其元素为 $z_{\\text{new},j} = \\frac{x_{\\text{new},j}-\\mu_j}{\\sigma_j}$。将其杠杆值定义为\n$$\nh_{\\text{new}} \\;=\\; z_{\\text{new}}^\\top S^{-1} z_{\\text{new}}.\n$$\n使用常规的基于杠杆值的适用域阈值\n$$\nh^\\star \\;=\\; \\frac{3m}{n}.\n$$\n当且仅当 $h_{\\text{new}} > h^\\star$ 时，判定一个新化合物在适用域之外。对于本问题，将“失败是可预测的”解释为事件 $h_{\\text{new}} > h^\\star$。\n\n使用以下训练描述符矩阵 $X$（行代表化合物，列代表描述符），其中所有数值对于每个描述符都使用相同的任意单位：\n- 第 1 行：$\\bigl[\\,1.2,\\,35.0,\\,2.10\\,\\bigr]$\n- 第 2 行：$\\bigl[\\,1.5,\\,40.2,\\,2.30\\,\\bigr]$\n- 第 3 行：$\\bigl[\\,0.8,\\,28.7,\\,1.80\\,\\bigr]$\n- 第 4 行：$\\bigl[\\,1.1,\\,33.3,\\,2.00\\,\\bigr]$\n- 第 5 行：$\\bigl[\\,1.7,\\,45.1,\\,2.60\\,\\bigr]$\n- 第 6 行：$\\bigl[\\,1.3,\\,36.9,\\,2.20\\,\\bigr]$\n- 第 7 行：$\\bigl[\\,1.0,\\,31.5,\\,1.90\\,\\bigr]$\n- 第 8 行：$\\bigl[\\,1.4,\\,38.4,\\,2.40\\,\\bigr]$\n- 第 9 行：$\\bigl[\\,1.6,\\,43.0,\\,2.50\\,\\bigr]$\n- 第 10 行：$\\bigl[\\,0.9,\\,29.8,\\,1.70\\,\\bigr]$\n- 第 11 行：$\\bigl[\\,1.8,\\,47.5,\\,2.80\\,\\bigr]$\n- 第 12 行：$\\bigl[\\,1.2,\\,34.1,\\,2.05\\,\\bigr]$\n\n评估以下包含 $4$ 个新化合物的集合（测试套件），每个化合物以原始描述符向量 $x_{\\text{new}}$ 的形式给出：\n- 情况 A：$\\bigl[\\,1.3,\\,36.0,\\,2.10\\,\\bigr]$\n- 情况 B：$\\bigl[\\,2.5,\\,70.0,\\,4.5\\,\\bigr]$\n- 情况 C：$\\bigl[\\,0.7,\\,26.0,\\,1.5\\,\\bigr]$\n- 情况 D：$\\bigl[\\,1.5,\\,40.2,\\,2.30\\,\\bigr]$\n\n您的程序必须：\n- 使用 $n=12$ 和上述公式，从训练矩阵 $X$ 中计算 $\\mu_j$ 和 $\\sigma_j$。\n- 标准化 $X$ 以获得 $Z$，并计算 $S = Z^\\top Z$。\n- 对于每个新情况，将 $x_{\\text{new}}$ 标准化为 $z_{\\text{new}}$，计算 $h_{\\text{new}} = z_{\\text{new}}^\\top S^{-1} z_{\\text{new}}$，计算 $h^\\star = \\frac{3m}{n}$（其中 $m=3$，$n=12$），并判断是否 $h_{\\text{new}} > h^\\star$。\n- 生成一行输出，其中包含四个情况的结果，格式为一个由方括号括起来的逗号分隔的布尔值列表，顺序为 $\\bigl[\\text{A},\\text{B},\\text{C},\\text{D}\\bigr]$，例如 $\\bigl[\\text{True},\\text{False},\\text{True},\\text{False}\\bigr]$。\n\n输出中不需要物理单位。不使用角度。不使用百分比。输出必须严格按照上述格式，且只有一行。", "solution": "题目要求我们对每个新化合物进行判断：一个大的预测误差是否可以通过适用域分析来预测。该分析基于新数据点在由训练集张成的标准化描述符空间中的杠杆值。其基本构造是不含截距项的描述符空间中的帽子矩阵：对于一个标准化的训练矩阵 $Z \\in \\mathbb{R}^{n \\times m}$，定义矩阵 $H \\in \\mathbb{R}^{n \\times n}$ 为 $H = Z \\bigl(Z^\\top Z\\bigr)^{-1} Z^\\top$，其对角线元素度量了训练化合物的杠杆值。对于一个新的标准化描述符向量 $z_{\\text{new}} \\in \\mathbb{R}^m$，其相对于训练集的杠杆值为\n$$\nh_{\\text{new}} \\;=\\; z_{\\text{new}}^\\top \\bigl(Z^\\top Z\\bigr)^{-1} z_{\\text{new}}.\n$$\n此表达式直接源于 $Z$ 的列所张成的 $m$ 维描述符空间中最小二乘投影的几何解释。此处使用的适用域阈值为\n$$\nh^\\star \\;=\\; \\frac{3m}{n},\n$$\n该阈值与训练集大小 $n$ 成反比，与维度 $m$ 成正比。\n\n与这些原则一致的算法步骤如下：\n1. 给定 $X \\in \\mathbb{R}^{n \\times m}$，其中 $n=12$，$m=3$，计算列均值和总体标准差：\n   $$\n   \\mu_j = \\frac{1}{12}\\sum_{i=1}^{12} X_{ij}, \\quad \\sigma_j = \\sqrt{\\frac{1}{12}\\sum_{i=1}^{12} \\bigl(X_{ij}-\\mu_j\\bigr)^2}, \\quad j \\in \\{1,2,3\\}.\n   $$\n   这将得到具体的数值 $\\mu_1, \\mu_2, \\mu_3$ 和 $\\sigma_1, \\sigma_2, \\sigma_3$。\n2. 构建标准化训练矩阵 $Z$，其元素为 $Z_{ij} = \\frac{X_{ij}-\\mu_j}{\\sigma_j}$，确保每列的均值为零，总体方差为一。计算 $S = Z^\\top Z \\in \\mathbb{R}^{3 \\times 3}$ 并求其逆矩阵 $S^{-1}$（可逆性源于列的线性无关性）。\n3. 对于每个新的原始描述符向量 $x_{\\text{new}}$，使用相同的 $\\mu_j$ 和 $\\sigma_j$ 计算 $z_{\\text{new}}$，其元素为 $z_{\\text{new},j} = \\frac{x_{\\text{new},j}-\\mu_j}{\\sigma_j}$，然后计算杠杆值 $h_{\\text{new}} = z_{\\text{new}}^\\top S^{-1} z_{\\text{new}}$。\n4. 设定 $h^\\star = \\frac{3m}{n} = \\frac{3 \\cdot 3}{12}$。\n5. 如果 $h_{\\text{new}} > h^\\star$，则判定为“可预测的失败”；否则判定为“不可预测”。\n\n将这些步骤应用于所提供的数据：\n- 使用给定的 $X$，直接根据定义计算均值和总体标准差。标准化产生 $Z$，然后组装并求逆 $S = Z^\\top Z$。\n- 对于情况 A，$x_{\\text{new}} = \\bigl[\\,1.3,\\,36.0,\\,2.10\\,\\bigr]$，其标准化向量 $z_{\\text{new}}$ 靠近原点；得到的 $h_{\\text{new}}$ 远小于 $h^\\star$，因此判定为“不可预测”（布尔值 $\\text{False}$）。\n- 对于情况 B，$x_{\\text{new}} = \\bigl[\\,2.5,\\,70.0,\\,4.5\\,\\bigr]$，$z_{\\text{new}}$ 远离训练数据云；$h_{\\text{new}}$ 远大于 $h^\\star$，因此判定为“可预测”（布尔值 $\\text{True}$）。\n- 对于情况 C，$x_{\\text{new}} = \\bigl[\\,0.7,\\,26.0,\\,1.5\\,\\bigr]$，$z_{\\text{new}}$ 与中心的距离中等；$h_{\\text{new}}$ 超过 $h^\\star$，因此判定为“可预测”（布尔值 $\\text{True}$）。\n- 对于情况 D，$x_{\\text{new}} = \\bigl[\\,1.5,\\,40.2,\\,2.30\\,\\bigr]$，该点与一个训练点重合，$h_{\\text{new}}$ 与 $h^\\star$ 相比很小，因此判定为“不可预测”（布尔值 $\\text{False}$）。\n\n因此，按 $\\bigl[\\text{A},\\text{B},\\text{C},\\text{D}\\bigr]$ 的顺序，布尔结果为 $\\bigl[\\text{False},\\text{True},\\text{True},\\text{False}\\bigr]$。附带的程序遵循上述定义计算这些值，并以要求的单行格式打印它们。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef standardize_training(X):\n    \"\"\"\n    Compute column-wise means and population standard deviations (ddof=0),\n    then standardize X using these statistics.\n    Returns Z (standardized), means, stds.\n    \"\"\"\n    means = X.mean(axis=0)\n    # population std: sqrt(mean((x - mean)^2))\n    diffs = X - means\n    vars_pop = (diffs ** 2).mean(axis=0)\n    stds = np.sqrt(vars_pop)\n    # Guard against zero std (not expected here)\n    if np.any(stds == 0):\n        raise ValueError(\"Zero standard deviation encountered in a descriptor column.\")\n    Z = (X - means) / stds\n    return Z, means, stds\n\ndef leverage_new_point(z_new, S_inv):\n    \"\"\"\n    Compute leverage h_new = z_new^T S^{-1} z_new\n    where S = Z^T Z for training standardized matrix Z.\n    \"\"\"\n    return float(z_new @ S_inv @ z_new)\n\ndef solve():\n    # Training descriptor matrix X: n=12, m=3\n    X = np.array([\n        [1.2, 35.0, 2.10],\n        [1.5, 40.2, 2.30],\n        [0.8, 28.7, 1.80],\n        [1.1, 33.3, 2.00],\n        [1.7, 45.1, 2.60],\n        [1.3, 36.9, 2.20],\n        [1.0, 31.5, 1.90],\n        [1.4, 38.4, 2.40],\n        [1.6, 43.0, 2.50],\n        [0.9, 29.8, 1.70],\n        [1.8, 47.5, 2.80],\n        [1.2, 34.1, 2.05],\n    ], dtype=float)\n\n    # Test suite: new compounds (A, B, C, D)\n    new_compounds = [\n        np.array([1.3, 36.0, 2.10], dtype=float),  # A\n        np.array([2.5, 70.0, 4.50], dtype=float),  # B\n        np.array([0.7, 26.0, 1.50], dtype=float),  # C\n        np.array([1.5, 40.2, 2.30], dtype=float),  # D\n    ]\n\n    n, m = X.shape\n    # Standardize training data\n    Z, means, stds = standardize_training(X)\n    # Compute S and its inverse\n    S = Z.T @ Z\n    # Using a robust inverse in case of near-singularity; here it should be fine.\n    S_inv = np.linalg.inv(S)\n\n    # Applicability domain threshold h* = 3m/n\n    h_star = 3.0 * m / n\n\n    results = []\n    for x_new in new_compounds:\n        z_new = (x_new - means) / stds\n        h_new = leverage_new_point(z_new, S_inv)\n        predictable = h_new > h_star\n        results.append(predictable)\n\n    # Final print statement in the exact required format.\n    # Booleans will be printed as True/False without spaces as per join formatting.\n    print(f\"[{','.join('True' if r else 'False' for r in results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2423889"}, {"introduction": "这个练习将带您深入探索QSAR中的“可解释人工智能”（eXplainable AI, XAI）世界。虽然像神经网络这样的复杂模型功能强大，但它们通常被视为“黑箱”。本练习通过让您从第一性原理出发计算SHAP值，来揭开这些模型的神秘面纱，为每个分子特征如何对预测产生贡献提供清晰、定量的解释。这项实践将使您掌握一种现代化技术，以解释和建立对复杂QSAR模型的信任。[@problem_id:2423840]", "problem": "构建一个完整的程序，为指定的定量结构-活性关系（QSAR）预测任务计算精确的 SHapley 加性解释（SHAP）值。定量结构-活性关系（QSAR）将分子结构描述符与生物活性相关联。考虑一个神经网络（Neural Network (NN)）模型，该模型将一个维度为 $d=6$ 的二元分子指纹描述符向量映射到一个预测的活性值。该活性值采用负以10为底的对数浓度标度（通常称为 $p\\mathrm{IC}_{50}$，其中半数最大抑制浓度（IC50）是一个浓度；$p\\mathrm{IC}_{50}$ 是无量纲的）。\n\n该模型定义如下。设输入为 $x \\in \\{0,1\\}^{6}$，隐藏层大小为 $3$，激活函数为修正线性单元（ReLU），定义为 $\\mathrm{ReLU}(z)=\\max(0,z)$，并按元素应用。模型输出为\n$$\nf(x) = b_2 + W_2 \\cdot \\sigma(W_1 x + b_1),\n$$\n其中 $\\sigma$ 表示按元素应用的 $\\mathrm{ReLU}$，$W_1 \\in \\mathbb{R}^{3 \\times 6}$，$b_1 \\in \\mathbb{R}^{3}$，$W_2 \\in \\mathbb{R}^{1 \\times 3}$，$b_2 \\in \\mathbb{R}$。参数固定如下：\n$$\nW_1 =\n\\begin{bmatrix}\n1.0 & -0.5 & 0.0 & 0.5 & 1.0 & -1.0\\\\\n0.0 & 1.0 & 1.0 & -0.5 & 0.5 & 0.0\\\\\n0.5 & 0.5 & -1.0 & 1.0 & 0.0 & 1.0\n\\end{bmatrix},\n\\quad\nb_1 =\n\\begin{bmatrix}\n0.0\\\\\n0.0\\\\\n0.0\n\\end{bmatrix},\n\\quad\nW_2 =\n\\begin{bmatrix}\n1.0 & 0.5 & -0.5\n\\end{bmatrix},\n\\quad\nb_2 = 0.1.\n$$\n\n为了定义 SHapley 加性解释（SHAP）值，固定一个基线描述符向量 $b \\in \\{0,1\\}^{6}$，其值为全零向量：\n$$\nb = [0,0,0,0,0,0].\n$$\n对于任意子集 $S \\subseteq \\{1,2,3,4,5,6\\}$，定义联盟值为\n$$\nv(S) = f(x_S),\n$$\n其中 $x_S \\in \\{0,1\\}^{6}$ 的构造方式如下：\n$$\n(x_S)_j =\n\\begin{cases}\nx_j, & \\text{if } j \\in S,\\\\\nb_j, & \\text{if } j \\notin S.\n\\end{cases}\n$$\n对于每个特征索引 $i \\in \\{1,\\dots,6\\}$，SHAP 值 $\\phi_i(x)$ 是在特征函数为 $v$ 的合作博弈中，参与者 $i$ 的 Shapley 值，其定义为：\n$$\n\\phi_i(x) = \\sum_{S \\subseteq N \\setminus \\{i\\}} \\frac{|S|!\\,(|N|-|S|-1)!}{|N|!} \\left[ v(S \\cup \\{i\\}) - v(S) \\right],\n$$\n其中 $N=\\{1,2,3,4,5,6\\}$ 且 $|N|=6$。\n\n您的程序必须使用上面指定的模型 $f$ 和基线 $b$，为以下测试套件中的每个输入描述符向量 $x$ 计算精确的 SHAP 值向量：\n$$\n\\Phi(x) = [\\phi_1(x), \\phi_2(x), \\phi_3(x), \\phi_4(x), \\phi_5(x), \\phi_6(x)]\n$$\n\n- 测试用例 1（单个强效分子）：$x^{(1)} = [1,1,0,1,1,0]$。\n- 测试用例 2（边界基线）：$x^{(2)} = [0,0,0,0,0,0]$。\n- 测试用例 3（单个比特存在）：$x^{(3)} = [0,0,1,0,0,0]$。\n- 测试用例 4（饱和存在）：$x^{(4)} = [1,1,1,1,1,1]$。\n\n无需外部数据。所有计算都是无量纲的，不需要物理单位。不涉及角度。每个测试用例的最终结果必须是实数列表。\n\n您的程序应生成单行输出，其中包含所有测试用例的结果，形式为列表的列表，并严格按照 $\\{x^{(1)}, x^{(2)}, x^{(3)}, x^{(4)}\\}$ 的顺序。其中每个内部列表是对应测试用例 $k \\in \\{1,2,3,4\\}$ 的 SHAP 值向量 $\\Phi(x^{(k)})$。格式必须为单行：\n$$\n[\\Phi(x^{(1)}), \\Phi(x^{(2)}), \\Phi(x^{(3)}), \\Phi(x^{(4)})]\n$$\n例如，输出必须类似于\n$$\n[[a_1,a_2,a_3,a_4,a_5,a_6],[b_1,b_2,b_3,b_4,b_5,b_6],[c_1,c_2,c_3,c_4,c_5,c_6],[d_1,d_2,d_3,d_4,d_5,d_6]]\n$$\n其中每个 $a_i$、$b_i$、$c_i$ 和 $d_i$ 都是实数。如果您愿意，可以四舍五入到固定的小数位数，但必须在此结构中输出数值（而非符号）。", "solution": "任务是根据第一性原理，为一个指定的定量结构-活性关系（QSAR）神经网络计算 SHapley 加性解释（SHAP）值。通过固定模型 $f$、基线 $b$ 和输入 $x$ 来设定一个合作博弈。对于任意子集 $S \\subseteq N=\\{1,\\dots,6\\}$，联盟值为 $v(S)=f(x_S)$，其中 $x_S$ 在 $S$ 中的索引处等于 $x$，在 $S$ 之外的索引处等于 $b$。\n\n该模型是一个带修正线性单元（ReLU）非线性的单隐藏层神经网络：\n$$\nf(x) = b_2 + W_2 \\cdot \\sigma(W_1 x + b_1),\n$$\n其中 $\\sigma(z)=\\max(0,z)$ 按元素应用。矩阵和向量已明确给出：\n$$\nW_1 =\n\\begin{bmatrix}\n1.0 & -0.5 & 0.0 & 0.5 & 1.0 & -1.0\\\\\n0.0 & 1.0 & 1.0 & -0.5 & 0.5 & 0.0\\\\\n0.5 & 0.5 & -1.0 & 1.0 & 0.0 & 1.0\n\\end{bmatrix},\n\\quad\nb_1 =\n\\begin{bmatrix}\n0.0\\\\\n0.0\\\\\n0.0\n\\end{bmatrix},\n\\quad\nW_2 =\n\\begin{bmatrix}\n1.0 & 0.5 & -0.5\n\\end{bmatrix},\n\\quad\nb_2 = 0.1,\n\\quad\nb = [0,0,0,0,0,0].\n$$\n给定任意 $x \\in \\{0,1\\}^{6}$，前向评估计算 $z=W_1 x + b_1$，应用 $\\sigma$ 得到 $h=\\sigma(z)$，然后输出 $f(x)=b_2 + W_2 \\cdot h$。由于基线 $b$ 是全零向量，对于任意子集 $S$，向量 $x_S$ 可以通过将所有不在 $S$ 中的特征置零，并保持 $S$ 中的特征与 $x$ 的特征相等来获得。\n\n特征 $i$ 的 SHAP 值 $\\phi_i(x)$ 由合作博弈论中的 Shapley 值公式定义：\n$$\n\\phi_i(x) = \\sum_{S \\subseteq N \\setminus \\{i\\}} \\frac{|S|!\\,(|N|-|S|-1)!}{|N|!} \\left[ f(x_{S \\cup \\{i\\}}) - f(x_S) \\right],\n$$\n其中 $|N|=6$。基于阶乘的权重 $\\frac{|S|!\\,(|N|-|S|-1)!}{|N|!}$ 仅依赖于 $|S|$ 的大小，并确保了 Shapley 公理，包括对称性、虚拟性、可加性和有效性属性：\n$$\n\\sum_{i=1}^{6} \\phi_i(x) = f(x) - f(b).\n$$\n\n基于原理的计算过程如下：\n- 枚举所有子集 $S \\subseteq N$；由于 $|N|=6$，共有 $2^{6}=64$ 个子集。为了计算效率和精确性，对所有 $S$ 预计算 $f(x_S)$。\n- 对于每个特征 $i$，使用精确的 Shapley 权重，对所有 $S \\subseteq N \\setminus \\{i\\}$ 的加权边际贡献 $f(x_{S \\cup \\{i\\}}) - f(x_S)$ 求和。这仅使用 Shapley 值的基本定义，不需要近似或外部库。\n- 结果是 SHAP 向量 $\\Phi(x)=[\\phi_1(x),\\dots,\\phi_6(x)]$。\n\n为了验证，可以检查对于每个测试输入 $x$，有效性属性是否成立：\n$$\n\\sum_{i=1}^{6} \\phi_i(x) = f(x) - f(b),\n$$\n其中 $b=[0,0,0,0,0,0]$ 且 $f$ 已给定。由于 $\\sigma$ 是分段线性的，而 $f$ 是与 $\\sigma$ 复合的仿射形式之和，所有评估结果都是确定性的实数。该程序对四个指定的测试用例精确执行这些步骤：\n- $x^{(1)} = [1,1,0,1,1,0]$,\n- $x^{(2)} = [0,0,0,0,0,0]$,\n- $x^{(3)} = [0,0,1,0,0,0]$,\n- $x^{(4)} = [1,1,1,1,1,1]$.\n\n最终输出是包含按要求顺序排列的 SHAP 向量列表的单行文本：\n$$\n[\\Phi(x^{(1)}), \\Phi(x^{(2)}), \\Phi(x^{(3)}), \\Phi(x^{(4)})].\n$$\n每个内部向量由实数组成，可以为了可读性进行四舍五入而不改变数学正确性。此方法满足 SHAP 值的基本定义，并直接解释了每个二元指纹特征相对于基线对 QSAR 模型的 $p\\mathrm{IC}_{50}$ 预测的贡献。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\n\ndef relu(z: np.ndarray) -> np.ndarray:\n    return np.maximum(0.0, z)\n\ndef model_f(x: np.ndarray) -> float:\n    # Define the fixed NN parameters\n    W1 = np.array([\n        [1.0, -0.5, 0.0, 0.5, 1.0, -1.0],\n        [0.0,  1.0, 1.0, -0.5, 0.5,  0.0],\n        [0.5,  0.5, -1.0, 1.0, 0.0,  1.0]\n    ], dtype=float)\n    b1 = np.array([0.0, 0.0, 0.0], dtype=float)\n    W2 = np.array([1.0, 0.5, -0.5], dtype=float)\n    b2 = 0.1\n    h = relu(W1 @ x + b1)\n    return float(b2 + W2 @ h)\n\ndef shap_values_exact(x: np.ndarray, f, baseline: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Compute exact SHAP values by enumeration for input x given model f and baseline.\n    Uses interventional definition with baseline imputation (features not in S set to baseline).\n    \"\"\"\n    d = x.size\n    # Precompute factorials for weights\n    fact = [math.factorial(k) for k in range(d+1)]\n    d_fact = fact[d]\n\n    # Precompute f for all subset masks to avoid redundant evaluations.\n    # mask is an integer in [0, 2^d), where bit j indicates feature j included.\n    num_masks = 1 << d\n    f_cache = np.empty(num_masks, dtype=float)\n    for mask in range(num_masks):\n        x_S = baseline.copy()\n        # set features present in mask to those of x\n        for j in range(d):\n            if (mask >> j) & 1:\n                x_S[j] = x[j]\n        f_cache[mask] = f(x_S)\n\n    # Compute SHAP values\n    phi = np.zeros(d, dtype=float)\n    for i in range(d):\n        contrib = 0.0\n        for mask in range(num_masks):\n            if (mask >> i) & 1:\n                # skip masks that already include i; we only consider S ⊆ N \\ {i}\n                continue\n            s_size = mask.bit_count()\n            weight = (fact[s_size] * fact[d - s_size - 1]) / d_fact\n            with_i_mask = mask | (1 << i)\n            marginal = f_cache[with_i_mask] - f_cache[mask]\n            contrib += weight * marginal\n        phi[i] = contrib\n    return phi\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        np.array([1,1,0,1,1,0], dtype=float),  # Test case 1\n        np.array([0,0,0,0,0,0], dtype=float),  # Test case 2\n        np.array([0,0,1,0,0,0], dtype=float),  # Test case 3\n        np.array([1,1,1,1,1,1], dtype=float),  # Test case 4\n    ]\n    baseline = np.zeros(6, dtype=float)\n\n    # Compute SHAP values for each test case\n    results = []\n    for x in test_cases:\n        phi = shap_values_exact(x, model_f, baseline)\n        # Optional rounding for readability\n        phi = np.round(phi, 6)\n        results.append(phi.tolist())\n\n    # Final print statement in the exact required format: list of lists on a single line.\n    # Example: [[a1,a2,...,a6],[b1,b2,...,b6],...]\n    def format_list_of_lists(lol):\n        # Format without extra spaces to keep it compact and deterministic.\n        inner = []\n        for lst in lol:\n            inner.append(\"[\" + \",\".join(f\"{v:.6f}\".rstrip('0').rstrip('.') if '.' in f\"{v:.6f}\" else f\"{v:.6f}\" for v in lst) + \"]\")\n        return \"[\" + \",\".join(inner) + \"]\"\n\n    print(format_list_of_lists(results))\n\nsolve()\n```", "id": "2423840"}]}