{"hands_on_practices": [{"introduction": "确定生物过程的“起点”是轨迹推断中的一个关键且首要的步骤，这通常对应于干细胞或祖细胞。本练习提出了一个基于信息论的自动化方法来识别这些“根细胞”。其核心思想是，祖细胞的表达谱在多能性标记基因上更为集中，因此其基因表达分布的香农熵（Shannon entropy）较低 [@problem_id:2437518]。通过这个实践，你将学习如何将生物学假设（多能性）转化为可计算的策略，并解决一个实际的生物信息学问题。", "problem": "给定一个有限的单细胞集合，每个细胞都测量了多个基因的表达量，并指定了一个作为多能性标记的基因子集。对于每个细胞，通过对其非负的标记基因表达向量添加一个非负的伪计数并进行归一化，来定义一个在标记基因集合上的概率分布。该分布的香农熵（Shannon entropy）量化了该细胞内多能性标记基因表达的集中程度。将根细胞集合定义为最小化此香农熵的细胞子集，若熵值相同，则优先选择总标记基因表达量较大的细胞，若仍相同，则选择细胞索引较小的细胞。您的任务是编写一个完整程序，精确地实现这一定义，并为多个测试用例返回所选细胞的索引。\n\n形式上，假设有 $N$ 个细胞和 $G$ 个基因。设 $X \\in \\mathbb{R}_{\\ge 0}^{N \\times G}$ 为非负表达矩阵，其中条目 $x_{i,g}$ 表示基因 $g \\in \\{0,\\dots,G-1\\}$ 在细胞 $i \\in \\{0,\\dots,N-1\\}$ 中的表达量。设 $M \\subseteq \\{0,\\dots,G-1\\}$ 为多能性标记基因索引的非空集合，且 $|M| = K \\ge 1$。对于一个给定的非负伪计数 $\\alpha \\in \\mathbb{R}_{\\ge 0}$，为每个细胞 $i$ 定义标记基因向量 $v_i \\in \\mathbb{R}_{\\ge 0}^{K}$，其分量为 $v_{i,g} = x_{i,g}$（对于 $g \\in M$）；平滑后的标记基因向量 $w_i$，其分量为 $w_{i,g} = v_{i,g} + \\alpha$；以及归一化常数 $s_i = \\sum_{g \\in M} w_{i,g}$。如果 $s_i > 0$，则定义分布 $p_i$ 的分量为 $p_{i,g} = \\dfrac{w_{i,g}}{s_i}$。如果 $s_i = 0$，则将 $p_i$ 定义为在 $M$ 上的均匀分布，即对于所有 $g \\in M$，有 $p_{i,g} = \\dfrac{1}{K}$。将细胞 $i$ 的香农熵（使用自然对数）定义为\n$$\nH_i = - \\sum_{g \\in M} p_{i,g} \\log p_{i,g},\n$$\n并遵循通常的约定，即对于任何 $q \\in [0,1]$，当 $q = 0$ 时，$q \\log q = 0$。同时，将不含伪计数的总标记基因表达量定义为\n$$\nS_i = \\sum_{g \\in M} v_{i,g} = \\sum_{g \\in M} x_{i,g}.\n$$\n给定目标根细胞数量 $r \\in \\{1,2,\\dots,N\\}$，将所选根细胞集合 $R$ 定义为 $\\{0,\\dots,N-1\\}$ 中大小为 $r$ 的子集，该子集满足以下字典序最小化规则：将所有细胞按 $H_i$ 升序排列，若出现相同值，则按 $S_i$ 降序排列，若仍有相同值，则按细胞索引 $i$ 升序排列。取此排序下的前 $r$ 个细胞构成集合 $R$。对于一个给定的测试用例，当 $r=1$ 时，输出为 $\\{0,\\dots,N-1\\}$ 中的单个整数索引；当 $r>1$ 时，输出为一个严格按数值升序排列的索引列表。\n\n您的程序必须为以下测试套件精确实现这些定义。在所有情况下，索引都是从零开始的。\n\n- 测试用例 $1$（带平滑的通用情况）：\n  - $X = \\begin{bmatrix}\n  10 & 10 & 0 \\\\\n  20 & 0 & 0 \\\\\n  0 & 20 & 0 \\\\\n  5 & 5 & 10\n  \\end{bmatrix}$,\n  - $M = \\{0,1\\}$,\n  - $\\alpha = 1$,\n  - $r = 1$.\n- 测试用例 $2$（熵值明确相同，通过更大的总标记基因表达量解决）：\n  - $X = \\begin{bmatrix}\n  8 & 2 \\\\\n  16 & 4 \\\\\n  5 & 5\n  \\end{bmatrix}$,\n  - $M = \\{0,1\\}$,\n  - $\\alpha = 0$,\n  - $r = 1$.\n- 测试用例 $3$（细胞中标记基因向量全为零的边界情况，通过平滑处理）：\n  - $X = \\begin{bmatrix}\n  0 & 0 \\\\\n  0 & 10 \\\\\n  0 & 1\n  \\end{bmatrix}$,\n  - $M = \\{0,1\\}$,\n  - $\\alpha = 1$,\n  - $r = 1$.\n- 测试用例 $4$（请求多个根细胞）：\n  - $X = \\begin{bmatrix}\n  10 & 0 & 0 \\\\\n  0 & 10 & 0 \\\\\n  3 & 3 & 3 \\\\\n  6 & 4 & 0 \\\\\n  9 & 1 & 0\n  \\end{bmatrix}$,\n  - $M = \\{0,1,2\\}$,\n  - $\\alpha = 1$,\n  - $r = 2$.\n\n您的程序应生成单行输出，其中包含按顺序汇总的四个测试用例的结果，结果为逗号分隔的列表并用方括号括起。每个元素必须是整数（对于 $r=1$）或升序整数列表（对于 $r>1$）。例如，输出可能如下所示：\n$[a,b,c,[d,e]]$\n其中 $a$、$b$、$c$ 是整数，$[d,e]$ 是一个整数列表。不应打印任何额外文本。", "solution": "该问题提出了一个定义明确的计算任务，其背景是生物信息学领域，特别是用于在单细胞数据集中识别根细胞。定义在数学上是精确的，每个测试用例的参数都已完全指定，并且所需的选择标准是明确的。因此，该问题是有效的，并允许直接的算法解决方案。\n\n目标是从总共 $N$ 个细胞中识别出 $r$ 个根细胞的集合。选择基于字典序排序，其中在预定义的多能性标记基因集合上具有最集中表达谱的细胞被优先选择。这种集中程度由从细胞的标记基因表达水平导出的概率分布的香农熵 $H_i$ 来量化。\n\n执行过程如下：对于每个细胞 $i \\in \\{0, \\dots, N-1\\}$，我们计算两个作为排序基础的指标：香农熵 $H_i$ 和总标记基因表达量 $S_i$。\n\n首先，我们为每个细胞 $i$ 计算香农熵 $H_i$：\n1.  从表达矩阵 $X \\in \\mathbb{R}_{\\ge 0}^{N \\times G}$ 中，我们为细胞 $i$ 提取标记基因表达向量 $v_i \\in \\mathbb{R}_{\\ge 0}^{K}$。其分量为 $v_{i,g} = x_{i,g}$，适用于标记基因集合 $M$ 中的所有基因索引 $g$，其中 $K = |M|$。\n2.  将一个非负伪计数 $\\alpha \\ge 0$ 添加到 $v_i$ 的每个分量上，形成一个平滑向量 $w_i$，其分量为 $w_{i,g} = v_{i,g} + \\alpha$。当 $\\alpha > 0$ 时，此步骤可确保没有概率为零，从而避免对数计算的问题，并处理了细胞对所有标记基因表达量均为零的情况。\n3.  对向量 $w_i$ 进行归一化以创建一个概率分布 $p_i$。归一化常数为 $s_i = \\sum_{g \\in M} w_{i,g}$。\n4.  如果 $s_i > 0$，则概率分布 $p_i$ 的分量为 $p_{i,g} = \\dfrac{w_{i,g}}{s_i}$。在 $s_i = 0$ 的特殊情况下（这只可能在 $\\alpha=0$ 且对于 $g \\in M$ 的所有标记基因表达量 $x_{i,g}$ 均为零时发生），分布 $p_i$ 被定义为均匀分布，即对于所有 $g \\in M$，$p_{i,g} = \\dfrac{1}{K}$。\n5.  然后使用指定的自然对数计算此分布的香农熵：\n    $$\n    H_i = - \\sum_{g \\in M} p_{i,g} \\log p_{i,g}\n    $$\n    遵循 $q=0$ 时 $q \\log q = 0$ 的约定。较低的 $H_i$ 值表示在标记基因上的表达谱更集中、更不均匀。\n\n其次，我们为每个细胞 $i$ 计算总标记基因表达量 $S_i$。这是原始、未经平滑的标记基因表达值的简单总和：\n$$\nS_i = \\sum_{g \\in M} x_{i,g}\n$$\n该指标用作主要的平局决胜规则。\n\n在为所有细胞计算出 $H_i$ 和 $S_i$ 后，我们建立一个唯一的细胞排序。排序基于每个细胞 $i$ 的一组标准，按字典序进行：\n1.  主要标准：按香农熵 $H_i$ 升序排列。\n2.  次要标准（平局决胜）：按总标记基因表达量 $S_i$ 降序排列。\n3.  第三标准（最终平局决胜）：按细胞索引 $i$ 升序排列。\n\n这个排序过程可以通过对所有 $i \\in \\{0, \\dots, N-1\\}$ 的元组列表 $(H_i, -S_i, i)$ 进行排序来实现。\n\n最后，从这个唯一排序的列表中选择前 $r$ 个细胞，形成根细胞集合 $R$。对于给定的测试用例，输出是所选细胞的索引（当 $r=1$ 时）或索引列表（当 $r>1$ 时）。如果 $r>1$，最终输出中的索引必须以严格的数值升序呈现。\n\n该实现使用 Python 编写，利用 `numpy` 库进行高效的数组操作，并使用 `scipy.stats.entropy` 来稳健地计算香农熵。该算法为每个提供的测试用例精确地遵循了上述步骤。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import entropy\n\ndef find_roots(X_raw, M, alpha, r):\n    \"\"\"\n    Identifies root cells based on Shannon entropy and total marker expression.\n\n    Args:\n        X_raw (list of lists): The N x G gene expression matrix.\n        M (set): The set of marker gene indices.\n        alpha (float): The nonnegative pseudocount.\n        r (int): The number of root cells to select.\n\n    Returns:\n        int or list of int: The index or list of indices of the root cells.\n    \"\"\"\n    X = np.array(X_raw, dtype=float)\n    marker_indices = sorted(list(M))\n    num_cells = X.shape[0]\n    K = len(marker_indices)\n\n    cell_metrics = []\n\n    for i in range(num_cells):\n        # Extract marker vector v_i and calculate total marker expression S_i\n        v_i = X[i, marker_indices]\n        S_i = np.sum(v_i)\n\n        # Calculate smoothed marker vector w_i and normalization constant s_i\n        w_i = v_i + alpha\n        s_i = np.sum(w_i)\n\n        # Define probability distribution p_i\n        if s_i > 0:\n            p_i = w_i / s_i\n        else:\n            # This case occurs iff alpha=0 and all relevant x_i,g are 0.\n            # Define p_i as the uniform distribution on M.\n            p_i = np.full(K, 1.0 / K)\n\n        # Calculate Shannon entropy H_i using natural logarithm\n        H_i = entropy(p_i, base=np.e)\n\n        # Store metrics for lexicographical sorting: (H_i, -S_i, i)\n        # We use -S_i because the tie-breaker is in descending order of S_i.\n        cell_metrics.append((H_i, -S_i, i))\n\n    # Sort cells based on the specified criteria\n    cell_metrics.sort()\n\n    # Select the top r cell indices\n    root_indices = [metric[2] for metric in cell_metrics[:r]]\n\n    # Format the output as per the problem description\n    if r == 1:\n        return root_indices[0]\n    else:\n        # Return indices in strictly increasing numerical order\n        return sorted(root_indices)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"X\": [[10, 10, 0], [20, 0, 0], [0, 20, 0], [5, 5, 10]],\n            \"M\": {0, 1}, \"alpha\": 1, \"r\": 1\n        },\n        {\n            \"X\": [[8, 2], [16, 4], [5, 5]],\n            \"M\": {0, 1}, \"alpha\": 0, \"r\": 1\n        },\n        {\n            \"X\": [[0, 0], [0, 10], [0, 1]],\n            \"M\": {0, 1}, \"alpha\": 1, \"r\": 1\n        },\n        {\n            \"X\": [[10, 0, 0], [0, 10, 0], [3, 3, 3], [6, 4, 0], [9, 1, 0]],\n            \"M\": {0, 1, 2}, \"alpha\": 1, \"r\": 2\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = find_roots(case[\"X\"], case[\"M\"], case[\"alpha\"], case[\"r\"])\n        results.append(result)\n\n    # Helper function to format results into the required string format\n    def format_result(res):\n        if isinstance(res, list):\n            # Format list as '[d,e]' without spaces\n            return f\"[{','.join(map(str, res))}]\"\n        else:\n            return str(res)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(format_result, results))}]\")\n\nsolve()\n```", "id": "2437518"}, {"introduction": "将细胞沿伪时间轴排序后，我们能从这个序列中解读出关于生物过程动态的什么信息呢？本练习引导你探索细胞在伪时间上的分布密度如何反映生物过程的“速度”。一个关键的假设是，细胞分化较慢的阶段会聚集更多的细胞，而分化较快的阶段细胞则分布稀疏。通过将“分化速度”定义为单位伪时间内细胞计数的期望变化率，你将学习如何从静态的细胞分布快照中推断出动态信息 [@problem_id:2437529]。", "problem": "一项单细胞RNA测序 (scRNA-seq) 研究使用轨迹推断为$N$个细胞中的每一个分配一个伪时间 $\\tau \\in [0,1]$。在一个特定的细胞谱系中，伪时间分配的分布可以很好地用一个形状参数为 $\\alpha = 2$ 和 $\\beta = 3$ 的贝塔分布来近似，其在 $[0,1]$ 上的概率密度函数为 $f(\\tau) = 12\\,\\tau\\,(1-\\tau)^{2}$。总共有 $N=800$ 个细胞。将在伪时间 $\\tau$ 处的“分化速度”定义为期望累积细胞计数相对于伪时间的变化率，即 $\\frac{d}{d\\tau}\\big(\\text{expected number of cells with pseudotime} \\le \\tau\\big)$。计算在 $\\tau = 0.25$ 处的这个速度。将答案表示为单位伪时间的细胞数的精确值，无需四舍五入。", "solution": "在继续解题之前，对问题陈述进行验证。\n\n步骤1：提取已知条件。\n- 细胞总数：$N = 800$。\n- 伪时间变量：$\\tau \\in [0, 1]$。\n- 伪时间分配分布的概率密度函数 (PDF) 服从形状参数为 $\\alpha = 2$ 和 $\\beta = 3$ 的贝塔分布。\n- PDF 的具体形式为 $f(\\tau) = 12\\tau(1-\\tau)^{2}$，其中 $\\tau \\in [0, 1]$。\n- “分化速度”定义为期望累积细胞计数相对于伪时间的变化率：$\\frac{d}{d\\tau}\\big(\\text{expected number of cells with pseudotime} \\le \\tau\\big)$。\n- 任务是计算在特定伪时间 $\\tau = 0.25$ 处的这个速度。\n\n步骤2：使用提取的已知条件进行验证。\n该问题具有科学依据，提法恰当且客观。它涉及轨迹推断，这是计算生物学中的一个标准课题。使用贝塔分布来为区间 $[0, 1]$ 上的变量建模是恰当的。所提供的PDF $f(\\tau) = 12\\tau(1-\\tau)^{2}$ 对于参数为 $\\alpha=2$ 和 $\\beta=3$ 的贝塔分布是正确归一化的，因为贝塔函数 $B(\\alpha, \\beta)$ 是 $B(2, 3) = \\frac{\\Gamma(2)\\Gamma(3)}{\\Gamma(2+3)} = \\frac{1!2!}{4!} = \\frac{2}{24} = \\frac{1}{12}$，而贝塔PDF的一般形式是 $\\frac{\\tau^{\\alpha-1}(1-\\tau)^{\\beta-1}}{B(\\alpha, \\beta)}$。所有定义都清晰且可以进行数学形式化。不存在矛盾或缺失的信息。\n\n步骤3：结论与行动。\n该问题是有效的。将构建解答。\n\n解答过程如下。设 $T$ 为代表一个随机选择的细胞的伪时间的随机变量。$T$ 的概率密度函数由 $f(\\tau) = 12\\tau(1-\\tau)^{2}$ 给出，其中 $\\tau \\in [0, 1]$。\n\n累积分布函数 (CDF)，记为 $F(\\tau)$，给出一个细胞的伪时间小于或等于 $\\tau$ 的概率。它由PDF的积分定义：\n$$F(\\tau) = P(T \\le \\tau) = \\int_{0}^{\\tau} f(t) \\, dt$$\n对于总共 $N$ 个细胞，伪时间小于或等于 $\\tau$ 的细胞的期望数量，我们记为 $E(\\tau)$，是细胞总数乘以这个概率：\n$$E(\\tau) = N \\cdot F(\\tau) = N \\int_{0}^{\\tau} f(t) \\, dt$$\n问题将“分化速度”（我们称之为 $S(\\tau)$）定义为这个期望累积细胞计数相对于伪时间的变化率。这是 $E(\\tau)$ 相对于 $\\tau$ 的导数：\n$$S(\\tau) = \\frac{d}{d\\tau} E(\\tau) = \\frac{d}{d\\tau} \\left( N \\int_{0}^{\\tau} f(t) \\, dt \\right)$$\n由于 $N$ 是一个常数，它可以移到导数符号的外面：\n$$S(\\tau) = N \\frac{d}{d\\tau} \\left( \\int_{0}^{\\tau} f(t) \\, dt \\right)$$\n根据微积分基本定理，一个积分对其上限的导数等于在上限处取值的被积函数。因此：\n$$\\frac{d}{d\\tau} \\left( \\int_{0}^{\\tau} f(t) \\, dt \\right) = f(\\tau)$$\n将此结果代回到 $S(\\tau)$ 的表达式中，我们得到一个简单的关系：\n$$S(\\tau) = N f(\\tau)$$\n这个结果是合乎逻辑的：细胞在某个伪时间点累积的速率与该点的细胞密度成正比。\n\n我们被要求计算在 $\\tau = 0.25$ 处的这个速度。我们有 $N = 800$ 和 $f(\\tau) = 12\\tau(1-\\tau)^{2}$。我们代入 $\\tau = 0.25$，即 $\\frac{1}{4}$。\n\n首先，计算 PDF $f(\\tau)$ 在 $\\tau = \\frac{1}{4}$ 处的值：\n$$f\\left(\\frac{1}{4}\\right) = 12 \\left(\\frac{1}{4}\\right) \\left(1 - \\frac{1}{4}\\right)^{2}$$\n$$f\\left(\\frac{1}{4}\\right) = 12 \\left(\\frac{1}{4}\\right) \\left(\\frac{3}{4}\\right)^{2}$$\n$$f\\left(\\frac{1}{4}\\right) = 3 \\left(\\frac{9}{16}\\right)$$\n$$f\\left(\\frac{1}{4}\\right) = \\frac{27}{16}$$\n现在，我们使用 $S(\\frac{1}{4}) = N f(\\frac{1}{4})$ 计算在该点的速度 $S(\\tau)$：\n$$S\\left(\\frac{1}{4}\\right) = 800 \\times \\frac{27}{16}$$\n为了简化计算，我们将 $800$ 除以 $16$：\n$$\\frac{800}{16} = \\frac{100 \\times 8}{16} = \\frac{100}{2} = 50$$\n最后，我们将此结果乘以 $27$：\n$$S\\left(\\frac{1}{4}\\right) = 50 \\times 27 = 1350$$\n在 $\\tau = 0.25$ 处的分化速度是 $1350$ 细胞/单位伪时间。", "answer": "$$\\boxed{1350}$$", "id": "2437529"}, {"introduction": "生物过程并非总是线性的，细胞分化等过程常常包含关键的“分叉点”，细胞在此处走向不同的命运。因此，选择正确的轨迹拓扑结构（线性还是分枝）对于准确的生物学解读至关重要。本练习要求你实现一个模型选择框架，用以判断线性轨迹模型和分枝轨迹模型哪一个更适合给定的单细胞数据 [@problem_id:2437495]。你将应用赤池信息准则（$AIC$）或贝叶斯信息准则（$BIC$）等统计学原理，来平衡模型的拟合优度与复杂度，从而做出客观的决策。", "problem": "给定一个平面上的有限点集，这些点代表从单细胞数据中获得的、嵌入在低维空间中的细胞。您将比较两个嵌套的轨迹模型，这两个模型将每个细胞映射到一个一维的伪时间上，同时假设在垂直于轨迹的方向上存在各向同性的高斯噪声。两个候选模型是：一个线性轨迹模型和一个带有单分岔点（两条共享一个连接点的直线分支）的分支轨迹模型。您的任务是实现一个程序，该程序对测试套件中的每个数据集，根据赤池信息准则 (Akaike Information Criterion, AIC) 或贝叶斯信息准则 (Bayesian Information Criterion, BIC) 来判断哪个模型更优，并为每个数据集返回一个整型标志。最终输出必须是包含所有数据集对应结果的整数列表的单行文本。\n\n基本建模假设和定义：\n- 设数据集为点集 $\\{x_i\\}_{i=1}^n \\subset \\mathbb{R}^2$，其中 $x_i = (x_{i1}, x_{i2})^\\top$。假设每个细胞位于一条一维轨迹附近，且在垂直于轨迹的方向上存在各向同性的高斯噪声。\n- 对于线性模型 $\\mathcal{M}_{\\text{lin}}$，轨迹是一条直线：由一个点 $m \\in \\mathbb{R}^2$ 和一个单位方向向量 $d \\in \\mathbb{R}^2$ 定义，$\\|d\\|_2 = 1$。点 $x_i$ 的伪时间是标量 $t_i = d^\\top (x_i - m)$。正交残差为 $r_i = (x_i - m) - t_i d$，残差平方和为 $RSS_{\\text{lin}} = \\sum_{i=1}^n \\|r_i\\|_2^2$。\n- 对于分支模型 $\\mathcal{M}_{\\text{br}}$，轨迹是共享一个公共连接点 $m \\in \\mathbb{R}^2$ 的两条直线的并集，这两条直线有两个单位方向向量 $d_1, d_2 \\in \\mathbb{R}^2$，其中对 $j \\in \\{1,2\\}$ 有 $\\|d_j\\|_2 = 1$。每个细胞被分配到使其正交距离更小的分支。对于使垂直距离最小化的分配 $a_i \\in \\{1,2\\}$，伪时间为 $t_i^{(a_i)} = d_{a_i}^\\top (x_i - m)$，正交残差为 $r_i^{(a_i)} = (x_i - m) - t_i^{(a_i)} d_{a_i}$。残差平方和为 $RSS_{\\text{br}} = \\sum_{i=1}^n \\min\\{\\|(x_i - m) - (d_1^\\top (x_i - m)) d_1\\|_2^2,\\|(x_i - m) - (d_2^\\top (x_i - m)) d_2\\|_2^2\\}$。\n- 高斯噪声模型和对数似然：假设正交偏差是独立同分布的，服从一维高斯噪声 $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$，因此方差的最大似然估计量为 $\\widehat{\\sigma}^2 = RSS/n$。在任一模型下，最大化对数似然为\n$$\n\\log L_{\\max} = -\\frac{n}{2}\\left[ \\log(2\\pi \\widehat{\\sigma}^2) + 1 \\right].\n$$\n为避免当 $RSS = 0$ 时出现退化的似然，实现一个严格为正的下限 $\\epsilon$，并使用 $\\widehat{\\sigma}^2 = \\max\\{RSS/n, \\epsilon\\}$，其中 $\\epsilon = 10^{-12}$。\n- 模型选择准则定义为\n$$\n\\text{AIC} = 2k - 2 \\log L_{\\max}, \\quad \\text{BIC} = k \\log n - 2 \\log L_{\\max},\n$$\n其中 $k$ 是估计的自由参数数量。参数计数如下，包括方差参数：\n  - 对于 $\\mathcal{M}_{\\text{lin}}$: $k_{\\text{lin}} = 4$ 个参数，包括 $m$（2 个实数自由度）、直线方向 $d$（1 个角自由度，因为 $\\|d\\|_2=1$）和方差 $\\sigma^2$（1 个）。\n  - 对于 $\\mathcal{M}_{\\text{br}}$: $k_{\\text{br}} = 5$ 个参数，包括 $m$（2 个）、两个分支方向 $d_1, d_2$（每个贡献 1 个角自由度，共 2 个）和方差 $\\sigma^2$（1 个）。离散的分支分配不计为参数。\n\n算法要求：\n- 拟合 $\\mathcal{M}_{\\text{lin}}$：将 $m$ 估计为样本均值 $m = \\frac{1}{n}\\sum_{i=1}^n x_i$。将 $d$ 估计为中心化数据矩阵的第一个主成分方向。通过对到拟合直线的垂直距离的平方求和来计算 $RSS_{\\text{lin}}$。\n- 拟合 $\\mathcal{M}_{\\text{br}}$：将连接点固定为相同的样本均值 $m$。对于那些满足 $\\|x_i - m\\|_2 > 0$ 的点 $i$，通过对单位向量 $u_i = \\frac{x_i - m}{\\|x_i - m\\|_2}$ 执行迭代方向聚类过程来估计方向 $d_1, d_2$。\n  - 初始化：使用中心化数据的前两个主方向作为初始单位方向。\n  - 迭代：进行固定次数的少量迭代，在迭代中交替执行以下两个步骤：将每个 $u_i$ 分配给能最大化 $|u_i^\\top d_j|$（反映双向线）的方向 $d_j$；以及更新每个 $d_j$ 为其所分配的 $u_i$ 的归一化带符号总和，即 $d_j \\leftarrow \\frac{\\sum_{i \\in S_j} \\operatorname{sign}(u_i^\\top d_j) u_i}{\\left\\|\\sum_{i \\in S_j} \\operatorname{sign}(u_i^\\top d_j) u_i\\right\\|_2}$。如果在某次迭代中集合 $S_j$ 为空，则保留之前的 $d_j$。\n  - 通过对每个点到两条直线（穿过 $m$，方向为 $d_1$ 和 $d_2$）中较近一条的垂直距离的平方求和，来计算 $RSS_{\\text{br}}$。\n- 根据每个测试用例的指定，计算 $\\log L_{\\max}$, AIC 或 BIC，并选择准则值较小的模型。如果在数值容差 $10^{-9}$ 内相等，则选择更简单的线性模型 $\\mathcal{M}_{\\text{lin}}$。\n\n角度单位：所有角度必须以弧度为单位进行解释。\n\n测试套件（不允许随机性；按规定生成确切的点）：\n- 案例 1（线性，准则 BIC）：\n  - 单直线数据集：$m = (0,0)$，方向角度 $\\theta = \\pi/6$，伪时间 $t \\in \\{-2,-1,0,1,2\\}$。对于每个 $t$，点为 $x(t) = m + t(\\cos\\theta, \\sin\\theta)$。\n  - 使用 BIC 进行选择。\n- 案例 2（分支，准则 AIC）：\n  - 双分支数据集：$m = (0,0)$，分支方向角度为 $\\theta_1 = \\pi/6$ 和 $\\theta_2 = -\\pi/6$，每个分支上的伪时间 $t \\in \\{-1, 1\\}$。点集是 $\\{ m + t(\\cos\\theta_1, \\sin\\theta_1) : t \\in \\{-1,1\\} \\}$ 和 $\\{ m + t(\\cos\\theta_2, \\sin\\theta_2) : t \\in \\{-1,1\\} \\}$ 的并集。\n  - 使用 AIC 进行选择。\n- 案例 3（不平衡弱分支，准则 BIC）：\n  - 双分支数据集：真实连接点 $m_{\\text{true}} = (0,0)$，分支方向角度为 $\\theta_1 = 0$ 和 $\\theta_2 = \\pi/12$，分支 1 上的伪时间 $t_1 \\in \\{0,1,2,3\\}$，分支 2 上的伪时间 $t_2 \\in \\{0.5\\}$。点集是 $\\{ m_{\\text{true}} + t(\\cos\\theta_1, \\sin\\theta_1) : t \\in \\{0,1,2,3\\} \\}$ 和 $\\{ m_{\\text{true}} + t(\\cos\\theta_2, \\sin\\theta_2) : t \\in \\{0.5\\} \\}$ 的并集。\n  - 使用 BIC 进行选择。\n- 案例 4（微小边缘案例，准则 AIC）：\n  - 直线上的两个点：$x_1 = (0,0)$，$x_2 = (1,0)$。\n  - 使用 AIC 进行选择。\n\n答案规格和最终输出格式：\n- 对于每个案例，如果根据指定的信息准则，分支模型 $\\mathcal{M}_{\\text{br}}$ 更优，则输出整数 $1$；如果线性模型 $\\mathcal{M}_{\\text{lin}}$ 更优（包括相等情况），则输出 $0$。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果（例如，“[0,1,0,0]”）。", "solution": "该问题要求我们实现一个模型选择框架，用以比较线性轨迹模型（$\\mathcal{M}_{\\text{lin}}$）和分支轨迹模型（$\\mathcal{M}_{\\text{br}}$），并根据赤池信息准则（AIC）或贝叶斯信息准则（BIC）选择更优的模型。\n\n解题思路如下：\n1.  **实现模型拟合**：对于给定的点集 $\\{x_i\\}_{i=1}^n$，我们需要分别为线性和分支模型估计参数并计算残差平方和（RSS）。\n2.  **计算信息准则**：利用计算出的 RSS 和每个模型的参数数量（$k$），计算其最大化对数似然 $\\log L_{\\max}$，并进而得到 AIC 或 BIC 值。\n3.  **模型选择**：比较两个模型的准则值，选择值较小者作为更优模型。\n\n**步骤 1：模型拟合与 RSS 计算**\n\n对于一个给定的数据集 $X \\in \\mathbb{R}^{n \\times 2}$，两个模型的公共交汇点 $m$ 都估计为样本均值：\n$$m = \\frac{1}{n} \\sum_{i=1}^n x_i$$\n令 $B = X - m^\\top$ 为中心化后的数据矩阵。\n\n**线性模型 ($\\mathcal{M}_{\\text{lin}}$):**\n-   方向向量 $d$ 是中心化数据 $B$ 的第一个主成分方向。这可以通过对 $B$ 进行奇异值分解（SVD）得到。$d$ 对应于最大奇异值所对应的右奇异向量。\n-   残差平方和 $RSS_{\\text{lin}}$ 是每个点到拟合直线的正交距离的平方和。对于每个中心化点 $b_i = x_i - m$，其与直线间的正交距离平方为 $\\|b_i\\|^2 - (d^\\top b_i)^2$。因此：\n    $$RSS_{\\text{lin}} = \\sum_{i=1}^n \\left( \\|b_i\\|^2 - (d^\\top b_i)^2 \\right)$$\n\n**分支模型 ($\\mathcal{M}_{\\text{br}}$):**\n-   两个方向向量 $d_1$ 和 $d_2$ 通过一个迭代过程来估计。\n-   **初始化**：使用中心化数据 $B$ 的前两个主成分方向作为 $d_1$ 和 $d_2$ 的初始值。\n-   **迭代**：对于每个不等于均值的点 $x_i$，计算其单位方向向量 $u_i = \\frac{x_i - m}{\\|x_i - m\\|_2}$。然后交替执行以下步骤（例如，固定迭代10次）：\n    1.  **分配**：将每个 $u_i$ 分配给能使其投影绝对值 $|u_i^\\top d_j|$ 最大的方向 $d_j$。\n    2.  **更新**：对于每个分支 $j$，将其方向 $d_j$ 更新为分配给它的所有 $u_i$ 的带符号向量和的归一化结果，符号由 $u_i$ 与旧方向 $d_j$ 的内积决定。\n-   **RSS 计算**：迭代结束后，对于每个点，计算其到两条分支（由 $m, d_1$ 和 $m, d_2$ 定义）的正交距离，并取其较小者。$RSS_{\\text{br}}$ 是这些最小距离平方的总和：\n    $$RSS_{\\text{br}} = \\sum_{i=1}^n \\min\\left( \\|b_i\\|^2 - (d_1^\\top b_i)^2, \\quad \\|b_i\\|^2 - (d_2^\\top b_i)^2 \\right)$$\n\n**步骤 2：对数似然与信息准则计算**\n\n对于任一模型，首先估计噪声方差 $\\widehat{\\sigma}^2 = \\max(RSS/n, \\epsilon)$，其中 $\\epsilon = 10^{-12}$ 是为防止数值问题而设的下限。然后计算最大化对数似然：\n$$ \\log L_{\\max} = -\\frac{n}{2}\\left( \\log(2\\pi \\widehat{\\sigma}^2) + 1 \\right) $$\n最后，根据给定的参数数量 $k$（$k_{\\text{lin}}=4, k_{\\text{br}}=5$）和样本量 $n$，计算相应的信息准则：\n$$ \\text{AIC} = 2k - 2 \\log L_{\\max} $$\n$$ \\text{BIC} = k \\log n - 2 \\log L_{\\max} $$\n\n**步骤 3：决策**\n\n比较计算出的准则值 $\\text{Criterion}_{\\text{lin}}$ 和 $\\text{Criterion}_{\\text{br}}$。如果 $\\text{Criterion}_{\\text{br}} < \\text{Criterion}_{\\text{lin}}$（考虑到数值容差），则选择分支模型（输出1）；否则选择线性模型（输出0）。\n\n该方法论为比较嵌套的几何模型提供了一个严谨的统计框架，平衡了模型的拟合优度（由RSS反映）和模型的复杂度（由$k$反映）。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the model selection analysis on all test cases.\n    \"\"\"\n    epsilon = 1e-12\n    num_iterations_branching = 10\n    tie_tolerance = 1e-9\n    \n    # --- Helper Functions ---\n    \n    def fit_linear_model(X):\n        \"\"\"Fits the linear model M_lin.\"\"\"\n        n, _ = X.shape\n        if n == 0:\n            return np.zeros(2), np.array([1.0, 0.0]), 0.0\n\n        m = np.mean(X, axis=0)\n        B = X - m\n        \n        if n < 2:\n            return m, np.array([1.0, 0.0]), 0.0\n        \n        # SVD on centered data to get principal components\n        # Vh contains the principal directions as rows\n        try:\n            _, _, Vh = np.linalg.svd(B, full_matrices=False)\n            d = Vh[0, :]\n        except np.linalg.LinAlgError:\n            d = np.array([1.0, 0.0]) # Fallback for singular matrix\n            \n        # Calculate RSS using the efficient formula: sum(||b_i||^2 - (d.b_i)^2)\n        squared_norms = np.sum(B**2, axis=1)\n        projections_sq = (B @ d)**2\n        rss = np.sum(squared_norms - projections_sq)\n        \n        return m, d, rss\n\n    def fit_branching_model(X):\n        \"\"\"Fits the branching model M_br.\"\"\"\n        n, _ = X.shape\n        if n == 0:\n            return np.zeros(2), np.array([1., 0.]), np.array([0., 1.]), 0.0\n\n        m = np.mean(X, axis=0)\n        B = X - m\n        \n        if n < 2:\n            return m, np.array([1., 0.]), np.array([0., 1.]), 0.0\n\n        # Initialize directions with the first two PCs\n        try:\n            _, _, Vh = np.linalg.svd(B, full_matrices=False)\n            d1 = Vh[0, :]\n            d2 = Vh[1, :] if Vh.shape[0] > 1 else np.array([-d1[1], d1[0]])\n        except np.linalg.LinAlgError:\n            d1 = np.array([1.0, 0.0])\n            d2 = np.array([0.0, 1.0])\n\n        # Get unit vectors for points not at the mean\n        norms = np.linalg.norm(B, axis=1)\n        valid_indices = norms > epsilon\n        u_vectors = B[valid_indices] / norms[valid_indices, np.newaxis]\n\n        if u_vectors.shape[0] > 0:\n            # Iterative refinement of directions\n            for _ in range(num_iterations_branching):\n                d1_old, d2_old = d1, d2\n                \n                # Assignment step\n                proj1 = np.abs(u_vectors @ d1)\n                proj2 = np.abs(u_vectors @ d2)\n                \n                assign_to_1 = proj1 >= proj2\n                S1_vectors = u_vectors[assign_to_1]\n                S2_vectors = u_vectors[~assign_to_1]\n\n                # Update step for d1\n                if S1_vectors.shape[0] > 0:\n                    signs1 = np.sign(S1_vectors @ d1_old)\n                    sum_vec1 = np.sum(S1_vectors * signs1[:, np.newaxis], axis=0)\n                    norm1 = np.linalg.norm(sum_vec1)\n                    if norm1 > epsilon:\n                        d1 = sum_vec1 / norm1\n\n                # Update step for d2\n                if S2_vectors.shape[0] > 0:\n                    signs2 = np.sign(S2_vectors @ d2_old)\n                    sum_vec2 = np.sum(S2_vectors * signs2[:, np.newaxis], axis=0)\n                    norm2 = np.linalg.norm(sum_vec2)\n                    if norm2 > epsilon:\n                        d2 = sum_vec2 / norm2\n\n        # Calculate RSS for the branching model\n        squared_norms = np.sum(B**2, axis=1)\n        proj_d1_sq = (B @ d1)**2\n        proj_d2_sq = (B @ d2)**2\n        \n        rss_per_point_1 = squared_norms - proj_d1_sq\n        rss_per_point_2 = squared_norms - proj_d2_sq\n        \n        # Negative rss values can occur from float precision errors, clip at 0\n        rss_br = np.sum(np.minimum(rss_per_point_1, rss_per_point_2).clip(min=0))\n\n        return m, d1, d2, rss_br\n\n    def calculate_criterion(rss, k, n, criterion_type):\n        \"\"\"Calculates AIC or BIC.\"\"\"\n        if n == 0:\n            return float('inf')\n        \n        sigma_sq_hat = max(rss / n, epsilon)\n        log_L_max = - (n / 2) * (np.log(2 * np.pi * sigma_sq_hat) + 1)\n        \n        if criterion_type.upper() == 'AIC':\n            return 2 * k - 2 * log_L_max\n        elif criterion_type.upper() == 'BIC':\n            # log(n) can be problematic for n=1, k log(1) = 0\n            # Problem cases have n>=2.\n            return k * np.log(n) - 2 * log_L_max\n        else:\n            raise ValueError(\"Unknown criterion type\")\n\n    # --- Test Cases ---\n    \n    test_cases_defs = [\n        {\n            \"id\": 1,\n            \"criterion\": \"BIC\",\n            \"points_func\": lambda: np.array([t * np.array([np.cos(np.pi/6), np.sin(np.pi/6)]) for t in [-2, -1, 0, 1, 2]])\n        },\n        {\n            \"id\": 2,\n            \"criterion\": \"AIC\",\n            \"points_func\": lambda: np.vstack([\n                np.array([t * np.array([np.cos(np.pi/6), np.sin(np.pi/6)]) for t in [-1, 1]]),\n                np.array([t * np.array([np.cos(-np.pi/6), np.sin(-np.pi/6)]) for t in [-1, 1]])\n            ])\n        },\n        {\n            \"id\": 3,\n            \"criterion\": \"BIC\",\n            \"points_func\": lambda: np.vstack([\n                np.array([t * np.array([np.cos(0), np.sin(0)]) for t in [0, 1, 2, 3]]),\n                np.array([0.5 * np.array([np.cos(np.pi/12), np.sin(np.pi/12)])])\n            ])\n        },\n        {\n            \"id\": 4,\n            \"criterion\": \"AIC\",\n            \"points_func\": lambda: np.array([[0., 0.], [1., 0.]])\n        }\n    ]\n\n    results = []\n    for case_def in test_cases_defs:\n        X = case_def[\"points_func\"]()\n        criterion_type = case_def[\"criterion\"]\n        n = X.shape[0]\n\n        # Linear Model\n        k_lin = 4\n        _, _, rss_lin = fit_linear_model(X)\n        crit_lin = calculate_criterion(rss_lin, k_lin, n, criterion_type)\n\n        # Branching Model\n        k_br = 5\n        _, _, _, rss_br = fit_branching_model(X)\n        crit_br = calculate_criterion(rss_br, k_br, n, criterion_type)\n\n        # Decision\n        if crit_br < crit_lin - tie_tolerance:\n            results.append(1)\n        else:\n            results.append(0)\n            \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2437495"}]}