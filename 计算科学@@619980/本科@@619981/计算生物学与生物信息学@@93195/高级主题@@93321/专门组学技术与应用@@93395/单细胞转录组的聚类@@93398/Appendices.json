{"hands_on_practices": [{"introduction": "在对细胞进行聚类后，一个关键问题是评估每个细胞分配到其簇的确定性。本练习将指导您从基本原则出发，推导出一个量化这种确定性的置信度分数 [@problem_id:2379661]。通过计算一个细胞相对于其最近的两个簇中心的距离，这个实践可以帮助您直观地理解如何评估聚类结果的稳健性。", "problem": "您正在分析一个单细胞核糖核酸测序（single-cell ribonucleic acid sequencing）数据集，该数据集包含的单细胞转录组已通过主成分分析（Principal Component Analysis, PCA）嵌入到一个二维空间中。在此嵌入空间中进行了聚类，每个簇由一个质心表示。对于一个给定坐标为 $\\left(2,-1\\right)$ 的细胞和三个分别位于 $\\mu_{A}=\\left(1,0\\right)$、$\\mu_{B}=\\left(4,-2\\right)$ 和 $\\mu_{C}=\\left(-1,3\\right)$ 的簇质心，此空间中的距离由欧几里得范数（Euclidean norm）度量，即对于一个位于 $x \\in \\mathbb{R}^{2}$ 的细胞和一个位于 $\\mu \\in \\mathbb{R}^{2}$ 的质心，其距离为 $d\\left(x,\\mu\\right)=\\left\\|x-\\mu\\right\\|_{2}$。\n\n定义细胞的指定簇为其质心与该细胞的欧几里得距离最小的那个簇。令 $d_{1}$ 为细胞到其指定质心的距离，$d_{2}$ 为细胞到次近质心的距离。您的任务是为该细胞的簇分配开发一个无量纲置信度分数 $c\\left(d_{1},d_{2}\\right)$，该分数需满足以下所有原则：\n\n- 该分数在嵌入坐标的任何均匀缩放变换下保持不变，因此它仅通过比率 $r=d_{1}/d_{2}$ 依赖于 $\\left(d_{1},d_{2}\\right)$。\n- 在定义域 $r \\in \\left[0,1\\right]$（注意根据定义 $d_{1} \\leq d_{2}$）上，该分数是 $r$ 的连续、严格递减函数。\n- 当 $r=0$ 时，分数达到 $c=1$；当 $r=1$ 时，分数达到 $c=0$。\n- 对 $r$ 的依赖关系是仿射的。\n\n仅使用这些原则，首先推导出 $c\\left(d_{1},d_{2}\\right)$ 关于 $d_{1}$和$d_{2}$ 的封闭形式表达式。然后，使用所提供的坐标，计算给定细胞的置信度分数的数值。将您的答案四舍五入到四位有效数字。最终答案以不带单位的小数形式表示。", "solution": "首先对问题陈述进行验证。\n\n逐字提取给定条件：\n- 一个细胞位于坐标 $\\left(2,-1\\right)$。\n- 三个簇质心分别位于 $\\mu_{A}=\\left(1,0\\right)$、$\\mu_{B}=\\left(4,-2\\right)$ 和 $\\mu_{C}=\\left(-1,3\\right)$。\n- 空间是一个二维嵌入。\n- 距离是欧几里得范数：对于一个位于 $x \\in \\mathbb{R}^{2}$ 的细胞和一个位于 $\\mu \\in \\mathbb{R}^{2}$ 的质心，其距离为 $d\\left(x,\\mu\\right)=\\left\\|x-\\mu\\right\\|_{2}$。\n- 指定的簇是质心与之欧几里得距离最小的那个簇。\n- $d_{1}$ 是细胞到其指定质心的距离。\n- $d_{2}$ 是细胞到次近质心的距离。\n- 必须推导出一个无量纲置信度分数 $c\\left(d_{1},d_{2}\\right)$。\n- 分数的原则：\n  1. 在均匀缩放下保持不变，仅依赖于比率 $r=d_{1}/d_{2}$。\n  2. 在定义域 $r \\in \\left[0,1\\right]$ 上，分数是 $r$ 的连续、严格递减函数。\n  3. 当 $r=0$ 时，分数达到 $c=1$。\n  4. 当 $r=1$ 时，分数达到 $c=0$。\n  5. 对 $r$ 的依赖关系是仿射的。\n\n进行验证。\n- 科学基础：该问题是计算生物学中的一个标准练习，具体涉及单细胞转录组聚类分析。PCA嵌入、用于聚类的欧几里得距离以及为簇分配定义置信度分数等概念都是完善且科学合理的。\n- 适定性：该问题是适定的。它提供了所有必要的数据，并定义了一组一致的约束条件，这些条件唯一地确定了置信度分数的函数。\n- 客观性：该问题以精确的数学术语陈述，没有主观或含糊的语言。\n\n结论是该问题有效。我们现在可以开始求解。\n\n求解过程需要两个步骤：第一步，基于给定的原则推导置信度分数 $c\\left(d_{1},d_{2}\\right)$ 的一般形式；第二步，为指定的细胞和质心计算其数值。\n\n第1部分：推导置信度分数公式。\n问题陈述指出，分数 $c$ 对比率 $r = d_{1}/d_{2}$ 的依赖关系是仿射的。一个仿射函数是形如下式的线性函数：\n$$c(r) = m \\cdot r + b$$\n其中 $m$ 和 $b$ 是待定常数。\n\n问题为该函数提供了两个边界条件：\n1. 当 $r=0$ 时，$c=1$。\n2. 当 $r=1$ 时，$c=0$。\n\n我们将这些条件代入仿射方程。\n对于第一个条件（$r=0$）：\n$$c(0) = m \\cdot 0 + b = 1$$\n这立即得出 $b=1$。\n\n对于第二个条件（$r=1$）：\n$$c(1) = m \\cdot 1 + b = 0$$\n将 $b=1$ 的值代入此方程，得到：\n$$m + 1 = 0$$\n这意味着 $m=-1$。\n\n当 $m=-1$ 和 $b=1$ 时，置信度分数的仿射函数为：\n$$c(r) = 1 - r$$\n\n我们必须验证此函数是否满足其余的原则。\n- 该分数仅依赖于 $r$，因此在坐标的均匀缩放下保持不变。如果坐标按因子 $\\alpha > 0$ 缩放，距离也按 $\\alpha$ 缩放，因此 $d'_{1} = \\alpha d_{1}$ 且 $d'_{2} = \\alpha d_{2}$。新的比率为 $r' = d'_{1}/d'_{2} = (\\alpha d_{1})/(\\alpha d_{2}) = d_{1}/d_{2} = r$，分数保持不变。此项得到满足。\n- 函数 $c(r)=1-r$ 对所有 $r$ 都是连续的。它关于 $r$ 的导数为 $c'(r)=-1$，是严格为负的。因此，$c(r)$ 在其定义域 $r \\in \\left[0,1\\right]$ 上是 $r$ 的严格递减函数。此项得到满足。\n\n所有原则都由推导出的函数满足。代入 $r = d_{1}/d_{2}$，得到以 $d_1$ 和 $d_2$ 表示的置信度分数的最终表达式：\n$$c\\left(d_{1},d_{2}\\right) = 1 - \\frac{d_{1}}{d_{2}}$$\n\n第2部分：计算给定细胞的置信度分数。\n细胞位于点 $x = \\left(2,-1\\right)$。质心为 $\\mu_{A}=\\left(1,0\\right)$、$\\mu_{B}=\\left(4,-2\\right)$ 和 $\\mu_{C}=\\left(-1,3\\right)$。我们必须计算细胞到每个质心的欧几里得距离。为方便计算，我们首先计算距离的平方。\n\n到质心 A 的距离平方为：\n$$d(x, \\mu_{A})^{2} = (2-1)^{2} + (-1-0)^{2} = 1^{2} + (-1)^{2} = 1 + 1 = 2$$\n到质心 B 的距离平方为：\n$$d(x, \\mu_{B})^{2} = (2-4)^{2} + (-1 - (-2))^{2} = (-2)^{2} + (1)^{2} = 4 + 1 = 5$$\n到质心 C 的距离平方为：\n$$d(x, \\mu_{C})^{2} = (2 - (-1))^{2} + (-1-3)^{2} = 3^{2} + (-4)^{2} = 9 + 16 = 25$$\n\n距离是这些值的平方根：\n$$d_{A} = d(x, \\mu_{A}) = \\sqrt{2}$$\n$$d_{B} = d(x, \\mu_{B}) = \\sqrt{5}$$\n$$d_{C} = d(x, \\mu_{C}) = \\sqrt{25} = 5$$\n\n根据定义，指定的簇是对应于最小距离的簇。比较这些距离：$\\sqrt{2} \\approx 1.414$，$\\sqrt{5} \\approx 2.236$，以及 $5$。最小的距离是 $d_{A} = \\sqrt{2}$。因此，该细胞被分配到簇 A。\n这意味着 $d_{1} = d_{A} = \\sqrt{2}$。\n\n次近的质心是对应于第二小距离的质心。第二小的距离是 $d_{B} = \\sqrt{5}$。\n这意味着 $d_{2} = d_{B} = \\sqrt{5}$。\n\n现在我们可以使用推导出的公式计算置信度分数：\n$$c = 1 - \\frac{d_{1}}{d_{2}} = 1 - \\frac{\\sqrt{2}}{\\sqrt{5}} = 1 - \\sqrt{\\frac{2}{5}}$$\n\n为了提供数值答案，我们计算此值：\n$$c = 1 - \\sqrt{0.4} \\approx 1 - 0.632455532... \\approx 0.367544467...$$\n\n问题要求将答案四舍五入到四位有效数字。第一位有效数字是 $3$，所以我们需要在其后保留三位数字。第五位有效数字是 $4$，小于 $5$，因此向下取整。\n$$c \\approx 0.3675$$\n这是置信度分数的最终数值。", "answer": "$$\\boxed{0.3675}$$", "id": "2379661"}, {"introduction": "初始的计算聚类往往会产生比真实生物学状态更多的簇，即“过度聚类”。本高级练习模拟了一个真实的生物信息学任务：设计并实施一个有原则的方法，通过检验簇之间是否存在统计上显著的差异表达基因，来自动合并这些被过度分割的细胞群 [@problem_id:2379646]。这个练习将统计检验、多重测试校正和图论概念结合起来，以获得更具生物学意义的结论。", "problem": "给定一个基因-细胞计数矩阵和一组用于单细胞核糖核酸测序 (scRNA-seq) 转录组的初始聚类标签。目标是设计并实现一个有原则的程序，通过检验簇对之间是否缺乏统计上显著的分离标记基因，来自动合并过度聚类的细胞群。该方法必须基于单细胞转录组学中常用的核心定义和经过充分检验的统计程序。\n\n从以下基础出发：\n- 细胞-基因计数矩阵是一个形状为 $n \\times g$ 的非负整数数组，其中 $n$ 是细胞数量，$g$ 是基因数量。该矩阵表示为 $X \\in \\mathbb{N}_{0}^{n \\times g}$，其元素 $X_{i j}$ 代表细胞 $i$ 和基因 $j$ 的计数值。\n- 文库大小归一化会重缩放每个细胞，以使每个细胞的总计数具有可比性。一种标准方法是为每个细胞 $i$ 计算总计数 $s_{i} = \\sum_{j=1}^{g} X_{i j}$，然后将计数转换为每 $10^{4}$ 个计数的数值，再进行自然对数稳定化，即定义\n$$\n\\tilde{X}_{i j} = \\log\\left(1 + \\frac{X_{i j}}{s_{i}} \\cdot 10^{4}\\right),\n$$\n对于所有细胞 $i \\in \\{1,\\dots,n\\}$ 和基因 $j \\in \\{1,\\dots,g\\}$，其中 $\\log$ 表示自然对数。\n- 对于两个簇 $a$ 和 $b$，设 $A$ 是标签为 $a$ 的细胞索引集，$B$ 是标签为 $b$ 的细胞索引集。对每个基因 $j \\in \\{1,\\dots,g\\}$，考虑对样本 $\\{\\tilde{X}_{i j} : i \\in A\\}$ 和 $\\{\\tilde{X}_{i j} : i \\in B\\}$ 应用双边Mann–Whitney $U$检验（也称为Wilcoxon秩和检验），得到一个p值 $p_{j} \\in [0,1]$。设每个基因的绝对对数倍数变化为\n$$\nL_{j} = \\left|\\frac{1}{|A|} \\sum_{i \\in A} \\tilde{X}_{i j} - \\frac{1}{|B|} \\sum_{i \\in B} \\tilde{X}_{i j}\\right|.\n$$\n- 使用Benjamini–Hochberg错误发现率（FDR）升阶程序来控制对 $g$ 个基因的多重检验。给定向量 $(p_{1},\\dots,p_{g})$，将其按非递减顺序排序以获得 $p_{(1)} \\le \\cdots \\le p_{(g)}$，并计算\n$$\nq_{(k)} = \\min_{t \\in \\{k,\\dots,g\\}} \\left\\{ \\frac{g}{t} \\, p_{(t)} \\right\\},\n$$\n然后恢复原始顺序以获得校正后的q值 $(q_{1},\\dots,q_{g})$。\n- 在固定阈值 $\\alpha \\in (0,1)$、$\\tau > 0$ 和 $m_{\\min} \\in \\mathbb{N}$ 下定义决策规则：如果同时满足 $q_{j} \\le \\alpha$ 和 $L_{j} \\ge \\tau$ 的基因数量严格小于 $m_{\\min}$，则簇对 $(a,b)$ 被判定为不可区分。等价地，如果\n$$\nS(a,b) = \\left| \\left\\{ j \\in \\{1,\\dots,g\\} : q_{j} \\le \\alpha \\;\\wedge\\; L_{j} \\ge \\tau \\right\\} \\right| < m_{\\min},\n$$\n那么簇 $a$ 和 $b$ 将被合并。\n\n算法要求：\n- 构建一个无向图，其节点是当前的簇标识。当且仅当 $S(a,b) < m_{\\min}$ 时，在不同的簇 $a$ 和 $b$ 之间添加一条边。用该图的连通分量替换当前的簇集合（将每个连通分量合并为一个单一的簇）。迭代此过程，直到某次迭代中没有添加任何边为止（即达到不动点）。最后，在扫描细胞 $i=1$ 到 $n$ 时，根据首次出现的顺序将簇标签压缩为从0开始的连续整数。\n\n对所有测试用例使用以下固定的超参数：\n- 显著性水平 $\\alpha = 0.01$，\n- 对数倍数变化阈值 $\\tau = 0.25$，\n- 最小标记基因数 $m_{\\min} = 2$。\n\n程序输入规范：\n- 将下面的测试套件直接硬编码在程序中。不从标准输入或文件中读取任何输入。\n\n测试套件：\n- 测试用例1（带有过度聚类的理想路径）：$g = 5$ 个基因，$n = 12$ 个细胞。矩阵 $X \\in \\mathbb{N}_{0}^{12 \\times 5}$ 按行定义如下\n  - 第1至4行：$[50, 100, 80, 30, 20]$，\n  - 第5至7行：$[50, 100, 80, 30, 20]$，\n  - 第8至12行：$[50, 100, 80, 300, 200]$。\n  初始标签向量为 $L = [0,0,0,0,1,1,1,2,2,2,2,2]$。标签为 $0$ 和 $1$ 的簇在组成上是相同的，应该合并；簇 $2$ 是不同的。\n- 测试用例2（分离良好的簇）：$g = 5$，$n = 10$。矩阵 $X \\in \\mathbb{N}_{0}^{10 \\times 5}$ 为\n  - 第1至5行：$[5, 5, 5, 5, 30]$，\n  - 第6至10行：$[30, 5, 5, 5, 5]$。\n  初始标签 $L = [0,0,0,0,0,1,1,1,1,1]$。这两个簇在至少2个基因上存在差异，不应合并。\n- 测试用例3（含单例簇和有限标记基因的边界情况）：$g = 5$，$n = 5$。矩阵 $X \\in \\mathbb{N}_{0}^{5 \\times 5}$ 为\n  - 第1至4行：$[20, 20, 20, 20, 20]$，\n  - 第5行：$[20, 20, 50, 20, 20]$。\n  初始标签 $L = [0,0,0,0,1]$。这模拟了一个仅在1个基因上存在差异的、被过度分裂的小单例；由于 $m_{\\min} = 2$，它应该被合并回去。\n\n输出规范：\n- 对于每个测试用例，程序必须输出一个包含两个元素的列表：收敛后的最终簇数量，以及长度为 $n$ 的最终压缩标签向量。\n- 将所有三个测试用例的结果汇总到一行，形式为用方括号括起来的逗号分隔列表。具体而言，输出必须是表示以下内容的一行\n$$\n\\left[ [K_{1}, \\text{labels}_{1}], [K_{2}, \\text{labels}_{2}], [K_{3}, \\text{labels}_{3}] \\right],\n$$\n其中 $K_{t} \\in \\mathbb{N}$ 且 $\\text{labels}_{t}$ 是测试用例 $t \\in \\{1,2,3\\}$ 的一个包含 $n_{t}$ 个整数的列表。列表内的整数打印时不得有空格。例如，一个语法正确的输出可能看起来像 $[[2,[0,0,0]],[2,[0,1]],[1,[0]]]$（这只是一个格式示例，并非预期答案）。", "solution": "我们为过度聚类的单细胞核糖核酸测序（scRNA-seq）数据集设计了一个基于统计学原理的合并程序。该程序通过将在受控的错误发现率（FDR）下，簇间缺乏分离标记基因的情况形式化为一个无法被拒绝的零假设来实现。该推导始于转录组学中的核心定义和广泛使用的统计工具。\n\n预处理和归一化。每个观测到的计数值 $X_{i j}$ 都受到细胞基因表达程序和文库大小等技术因素的影响。一种广为接受的一阶校正方法是文库大小归一化与方差稳定化变换相结合。对每个细胞 $i$，计算其文库大小 $s_{i} = \\sum_{j=1}^{g} X_{i j}$。然后，连续尺度上的归一化表达量为\n$$\n\\tilde{X}_{i j} = \\log\\left(1 + \\frac{X_{i j}}{s_{i}} \\cdot 10^{4}\\right).\n$$\n该过程将所有细胞重缩放到一个共同的有效深度，即总计数值为 $10^{4}$，并应用自然对数来抑制均值-方差关系，这是单细胞分析中一种经过充分检验的实践。\n\n检验分离标记基因。考虑两个簇 $a$ 和 $b$，其索引集分别为 $A$ 和 $B$。对于每个基因 $j \\in \\{1,\\dots,g\\}$，我们需要一种检验来检测 $A$ 和 $B$ 之间 $\\tilde{X}_{i j}$ 集中趋势的差异。由于scRNA-seq归一化数据通常是非高斯的，并且可能存在相同值（结），我们采用双边Mann–Whitney $U$检验（Wilcoxon秩和检验），该检验测试\n$$\nH_{0}: \\text{the distributions of } \\{\\tilde{X}_{i j}\\}_{i \\in A} \\text{ and } \\{\\tilde{X}_{i j}\\}_{i \\in B} \\text{ are equal}\n$$\n对立于\n$$\nH_{1}: \\text{the distributions differ in location}.\n$$\n对每个基因 $j$，这将产生一个p值 $p_{j} \\in [0,1]$。\n\n多重检验校正。由于我们对 $g$ 个基因进行检验，我们使用Benjamini–Hochberg（BH）错误发现率升阶程序来控制预期的错误发现比例。给定p值 $(p_{1},\\dots,p_{g})$，将其排序得到 $p_{(1)} \\le \\cdots \\le p_{(g)}$。通过以下方式定义BH校正值\n$$\nq_{(k)} = \\min_{t \\in \\{k,\\dots,g\\}} \\left\\{ \\frac{g}{t} \\, p_{(t)} \\right\\},\n$$\n然后映射回原始基因顺序，以获得 $(q_{1},\\dots,q_{g})$。这会产生q值，在标准的独立性或正相关性假设下，这些q值可以控制发现中的预期假阳性比例。\n\n效应量阈值。为避免合并那些差异在统计上可检测但实际上可忽略不计的簇，我们通过绝对对数倍数变化引入一个效应量约束\n$$\nL_{j} = \\left|\\mu_{A j} - \\mu_{B j}\\right|, \\quad \\text{where } \\mu_{A j} = \\frac{1}{|A|} \\sum_{i \\in A} \\tilde{X}_{i j}, \\;\\; \\mu_{B j} = \\frac{1}{|B|} \\sum_{i \\in B} \\tilde{X}_{i j}.\n$$\n仅当对于固定的阈值 $\\alpha$ 和 $\\tau$，同时满足 $q_{j} \\le \\alpha$ 和 $L_{j} \\ge \\tau$ 时，一个基因才被视为分离标记基因。分离标记基因的数量是\n$$\nS(a,b) = \\left| \\left\\{ j \\in \\{1,\\dots,g\\} : q_{j} \\le \\alpha \\;\\wedge\\; L_{j} \\ge \\tau \\right\\} \\right|.\n$$\n\n合并规则与收敛。我们定义一个无向图，其节点等于当前的簇标识。对于每对不同的簇 $(a,b)$，如果 $S(a,b) < m_{\\min}$，我们就在 $a$ 和 $b$ 之间添加一条边，将其解释为这些簇不可区分的证据（在FDR和效应量阈值下，分离标记基因不足）。一个连通分量内的所有簇都被合并成一个单一的簇。我们进行迭代：在每一步，基于合并后的簇重新计算图，然后再次合并，直到没有新的边出现。这个过程必然在有限步内终止，因为每次合并都严格减少了簇的数量，而簇的数量是以1为下界的非负整数。\n\n在给定测试套件下的正确性论证。我们使用固定的超参数 $\\alpha = 0.01$，$\\tau = 0.25$ 和 $m_{\\min} = 2$。\n\n- 测试用例1。根据构造，初始标签为0和1的簇在所有 $g=5$ 个基因上具有完全相同的组成。归一化后，对于任何基因 $j$，簇0和簇1中细胞 $i$ 的 $\\tilde{X}_{i j}$ 分布是相等的，从而得到 $p_j = 1$，因此 $q_j = 1$。对所有 $j$， $q_j \\le \\alpha$ 和 $L_j \\ge \\tau$ 都不成立；因此 $S(0,1) = 0 < m_{\\min}$，所以它们会合并。对于合并后的簇与簇2，其组成在基因 $j=4$ 和 $j=5$（基因索引从1到5）上差异显著，这使得 $L_j$ 很大而 $q_j$ 很小，导致至少有2个基因通过了两个阈值。因此 $S(\\text{merged},2) \\ge 2 \\ge m_{\\min}$，所以它们不合并，我们最终得到 $K_{1} = 2$ 个簇。\n\n- 测试用例2。这两个簇在至少2个基因（基因1和基因5）上存在组成差异，这将使得这些基因的 $L_j$ 很大而 $q_j$ 很小，从而 $S(0,1) \\ge 2$。因此 $S(0,1) \\ge m_{\\min}$，没有边被添加，我们最终得到 $K_{2} = 2$ 个簇。\n\n- 测试用例3。单例簇相对于较大的簇仅在单个基因（基因3）上存在差异，所以 $S(0,1) = 1 < m_{\\min}$，该对簇被视为不可区分；它们合并成一个簇，最终得到 $K_{3} = 1$。\n\n标签压缩。收敛后，我们按照细胞 $i = 1$ 到 $n$ 的顺序，根据簇的首次出现顺序将簇重标记为从0开始的整数。这确保了输出是规范且可复现的。\n\n算法考量。Mann–Whitney U检验是针对每个基因，使用双边备择假设和渐近p值计算的，这适用于小到中等的样本量，并且可以处理结（相同值）。Benjamini–Hochberg程序完全按照规定实现。基于图的合并使用联合-查找（union-find）或通过标准的不相交集合逻辑来寻找连通分量。如上所述，算法的终止性得到保证。\n\n程序完全按照规定编码三个矩阵 $X$ 和标签向量 $L$，应用归一化，计算逐对统计量，执行迭代合并，并以指定格式在单行上输出所需的聚合列表。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import mannwhitneyu\n\ndef normalize_log1p_cpm(X, scale=1e4):\n    \"\"\"\n    Library-size normalize counts per cell to counts-per-scale and apply log1p (natural log).\n    X: (n_cells, n_genes) nonnegative counts\n    Returns: (n_cells, n_genes) normalized matrix\n    \"\"\"\n    X = np.asarray(X, dtype=float)\n    # Compute library sizes per cell; add small epsilon to avoid divide-by-zero if necessary\n    lib = X.sum(axis=1, keepdims=True)\n    # Assumes lib > 0 in our test suite; if zeros occur, leave as zeros.\n    with np.errstate(divide='ignore', invalid='ignore'):\n        norm = np.where(lib > 0, (X / lib) * scale, 0.0)\n    return np.log1p(norm)\n\ndef bh_fdr(pvals):\n    \"\"\"\n    Benjamini-Hochberg FDR adjustment.\n    pvals: array-like of length m\n    Returns: adjusted q-values array of length m\n    \"\"\"\n    p = np.asarray(pvals, dtype=float)\n    m = p.size\n    order = np.argsort(p)\n    p_sorted = p[order]\n    # Compute adjusted values\n    # q_(k) = min_{t >= k} (m/t * p_(t))\n    denom = np.arange(1, m + 1)\n    q_sorted = (m / denom) * p_sorted\n    # Enforce monotonicity\n    q_sorted = np.minimum.accumulate(q_sorted[::-1])[::-1]\n    # Cap at 1\n    q_sorted = np.minimum(q_sorted, 1.0)\n    # Unsort\n    q = np.empty_like(q_sorted)\n    q[order] = q_sorted\n    return q\n\ndef count_markers_between_clusters(Xnorm, labels, a, b, alpha, tau):\n    \"\"\"\n    For clusters a and b, compute the number of genes that satisfy q <= alpha and |logFC| >= tau.\n    Uses two-sided Mann-Whitney U test with asymptotic p-values.\n    \"\"\"\n    labels = np.asarray(labels)\n    idx_a = np.where(labels == a)[0]\n    idx_b = np.where(labels == b)[0]\n    Xa = Xnorm[idx_a, :]\n    Xb = Xnorm[idx_b, :]\n    # Compute per-gene means for effect size\n    mean_a = Xa.mean(axis=0)\n    mean_b = Xb.mean(axis=0)\n    logfc = np.abs(mean_a - mean_b)\n    # Compute per-gene p-values using Mann-Whitney U test\n    g = Xnorm.shape[1]\n    pvals = np.empty(g, dtype=float)\n    # Use asymptotic method to handle ties deterministically\n    for j in range(g):\n        # Handle degenerate case where both groups are constant and equal => p-value = 1.0\n        col_a = Xa[:, j]\n        col_b = Xb[:, j]\n        if np.all(col_a == col_a[0]) and np.all(col_b == col_b[0]) and (col_a[0] == col_b[0]):\n            pvals[j] = 1.0\n        else:\n            try:\n                res = mannwhitneyu(col_a, col_b, alternative='two-sided', method='asymptotic')\n                pvals[j] = res.pvalue\n            except Exception:\n                # Fallback: if test fails for any numerical reason, treat as non-significant\n                pvals[j] = 1.0\n    qvals = bh_fdr(pvals)\n    # Count markers satisfying both thresholds\n    markers = np.logical_and(qvals <= alpha, logfc >= tau)\n    return int(np.count_nonzero(markers))\n\ndef connected_components_merge(labels, indist_pairs):\n    \"\"\"\n    Merge clusters based on indistinguishable pairs using union-find.\n    labels: array of cluster ids\n    indist_pairs: list of tuples (a,b) that should be merged\n    Returns: new_labels with merged cluster ids (not yet compressed)\n    \"\"\"\n    labels = np.asarray(labels)\n    unique_clusters = np.unique(labels)\n    parent = {int(c): int(c) for c in unique_clusters}\n\n    def find(x):\n        # Path compression\n        if parent[x] != x:\n            parent[x] = find(parent[x])\n        return parent[x]\n\n    def union(x, y):\n        rx, ry = find(x), find(y)\n        if rx != ry:\n            parent[ry] = rx\n\n    # Union all indistinguishable pairs\n    for a, b in indist_pairs:\n        union(int(a), int(b))\n\n    # Map each original cluster to its root\n    root_map = {c: find(int(c)) for c in unique_clusters}\n    # Build new labels by replacing each label with its root\n    new_labels = np.array([root_map[int(c)] for c in labels], dtype=int)\n    return new_labels\n\ndef compress_labels_stable(labels):\n    \"\"\"\n    Compress labels to 0..K-1 in order of first appearance across the array.\n    \"\"\"\n    labels = np.asarray(labels, dtype=int)\n    mapping = {}\n    next_id = 0\n    compressed = np.empty_like(labels)\n    for i, c in enumerate(labels):\n        if int(c) not in mapping:\n            mapping[int(c)] = next_id\n            next_id += 1\n        compressed[i] = mapping[int(c)]\n    return compressed\n\ndef merge_overclustered(X, init_labels, alpha=0.01, tau=0.25, m_min=2):\n    \"\"\"\n    Main procedure:\n    - Normalize X with log1p CPM.\n    - Iteratively merge clusters with insufficient markers until convergence.\n    - Return final compressed labels and number of clusters.\n    \"\"\"\n    X = np.asarray(X, dtype=float)\n    labels = np.asarray(init_labels, dtype=int)\n    Xnorm = normalize_log1p_cpm(X)\n\n    changed = True\n    while changed:\n        changed = False\n        # Current distinct clusters\n        clusters = np.unique(labels)\n        # Compute indistinguishable pairs\n        indist_pairs = []\n        for i in range(len(clusters)):\n            for j in range(i + 1, len(clusters)):\n                a = clusters[i]\n                b = clusters[j]\n                S = count_markers_between_clusters(Xnorm, labels, a, b, alpha, tau)\n                if S < m_min:\n                    indist_pairs.append((int(a), int(b)))\n        if indist_pairs:\n            new_labels = connected_components_merge(labels, indist_pairs)\n            if not np.array_equal(new_labels, labels):\n                labels = new_labels\n                changed = True\n    # Compress to consecutive integers in order of first appearance\n    final_labels = compress_labels_stable(labels)\n    K = int(np.unique(final_labels).size)\n    return K, final_labels.tolist()\n\ndef fmt(obj):\n    \"\"\"\n    Format lists (possibly nested) and integers into a compact string without spaces.\n    \"\"\"\n    if isinstance(obj, list):\n        return \"[\" + \",\".join(fmt(x) for x in obj) + \"]\"\n    elif isinstance(obj, (tuple, np.ndarray)):\n        return \"[\" + \",\".join(fmt(x) for x in list(obj)) + \"]\"\n    else:\n        return str(int(obj)) if isinstance(obj, (np.integer,)) else str(obj)\n\ndef solve():\n    # Define the test cases from the problem statement.\n\n    # Test case 1\n    X1_top = [50, 100, 80, 30, 20]\n    X1_mid = [50, 100, 80, 30, 20]\n    X1_bot = [50, 100, 80, 300, 200]\n    X1 = np.array(\n        [X1_top] * 4 + [X1_mid] * 3 + [X1_bot] * 5,\n        dtype=float\n    )\n    L1 = [0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2]\n\n    # Test case 2\n    X2_a = [5, 5, 5, 5, 30]\n    X2_b = [30, 5, 5, 5, 5]\n    X2 = np.array([X2_a] * 5 + [X2_b] * 5, dtype=float)\n    L2 = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n\n    # Test case 3\n    X3_a = [20, 20, 20, 20, 20]\n    X3_b = [20, 20, 50, 20, 20]\n    X3 = np.array([X3_a] * 4 + [X3_b] * 1, dtype=float)\n    L3 = [0, 0, 0, 0, 1]\n\n    test_cases = [\n        (X1, L1),\n        (X2, L2),\n        (X3, L3),\n    ]\n\n    alpha = 0.01\n    tau = 0.25\n    m_min = 2\n\n    results = []\n    for X, L in test_cases:\n        K, labels = merge_overclustered(X, L, alpha=alpha, tau=tau, m_min=m_min)\n        results.append([K, labels])\n\n    # Final print statement in the exact required format: no spaces inside lists.\n    print(fmt(results))\n\nsolve()\n```", "id": "2379646"}]}