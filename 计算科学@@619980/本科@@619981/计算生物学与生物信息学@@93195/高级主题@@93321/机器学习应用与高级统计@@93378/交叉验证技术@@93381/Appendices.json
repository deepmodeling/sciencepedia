{"hands_on_practices": [{"introduction": "在生物信息学和临床研究中，我们经常会遇到来自同一个体（如患者）的多个数据点，例如在不同时间点测量的基因表达数据。这些数据点并非相互独立，若在交叉验证时将它们分散到不同的折（fold）中，会导致数据泄漏，从而过分乐观地评估模型性能。本练习将指导您实践一种至关重要的交叉验证方法——“分组 K 折交叉验证”（Group K-Fold CV），确保来自同一患者的所有数据始终位于同一个折中，从而获得对模型泛化能力更真实、更可靠的评估。[@problem_id:2383472]", "problem": "您将获得一个自包含的计算任务，以评估一个连续药物反应的预测模型。评估采用一种基于折的划分方法，该方法尊重患者身份，即同一患者的所有时间点测量值必须被分配到同一折中。该场景是一个药物基因组学研究中多名患者的时间基因表达测量的简化模型。\n\n现有 $6$ 名患者，由集合 $\\mathcal{P}=\\{1,2,3,4,5,6\\}$ 索引。对于每位患者 $p \\in \\mathcal{P}$，您将在以下集合给出的特定整数时间点 $t \\in \\mathbb{Z}_{\\ge 0}$ 观察到测量值：\n- 对于 $p=1$: $T(1)=\\{0,1,2\\}$。\n- 对于 $p=2$: $T(2)=\\{0,1\\}$。\n- 对于 $p=3$: $T(3)=\\{0,1,2,3\\}$。\n- 对于 $p=4$: $T(4)=\\{0\\}$。\n- 对于 $p=5$: $T(5)=\\{0,1\\}$。\n- 对于 $p=6$: $T(6)=\\{0,1,2\\}$。\n\n对于每个观测对 $(p,t)$，定义如下四个不含截距项的特征：\n- $g_1 = 1 + 0.1\\,p + 0.05\\,t$，\n- $g_2 = -2 + 0.2\\,p - 0.05\\,t^2$，\n- $g_3 = 0.5\\,p + 0.1\\,t$，\n- $u = t$。\n\n设设计向量为 $x = [1, g_1, g_2, g_3, u] \\in \\mathbb{R}^5$，其中第一个分量是常数截距项。每个 $(p,t)$ 的实值响应由以下公式确定性地生成：\n$$\ny = x^\\top b^\\star + \\varepsilon,\n$$\n其真实系数为\n$$\nb^\\star = \\begin{bmatrix} 0.3 \\\\ 1.2 \\\\ -0.8 \\\\ 0.5 \\\\ 0.7 \\end{bmatrix},\n$$\n以及一个确定性扰动\n$$\n\\varepsilon = 0.01\\,(p-3)\\,\\big(0.5 - 0.1\\,t\\big).\n$$\n\n对于给定的折数 $K \\in \\mathbb{N}$（$1 \\le K \\le |\\mathcal{P}|$）和给定的正则化参数 $\\lambda \\in \\mathbb{R}_{\\ge 0}$，按如下方式将患者集合划分为 $K$ 个不相交的折。将患者按其数字索引升序排序，得到序列 $(1,2,3,4,5,6)$。对于此顺序中秩为 $r \\in \\{0,1,2,3,4,5\\}$ 的每位患者，将其分配到折索引 $f = r \\bmod K$。设 $F_0,\\dots,F_{K-1}$ 为所得到的不相交的患者子集。对于每个折索引 $j \\in \\{0,\\dots,K-1\\}$，将所有 $p \\in F_j$ 的行 $(p,t)$ 设为测试集，其余所有行设为训练集。\n\n对于每个折，设训练设计矩阵为 $X \\in \\mathbb{R}^{n_{\\text{train}} \\times 5}$（其行如上文定义的 $x^\\top$），训练响应向量为 $y \\in \\mathbb{R}^{n_{\\text{train}}}$。将折 $j$ 的参数估计 $\\hat b^{(j)} \\in \\mathbb{R}^5$ 定义为以下目标的任意最小化子：\n$$\n\\frac{1}{n_{\\text{train}}}\\,\\|X\\,b - y\\|_2^2 + \\lambda\\,\\|R\\,b\\|_2^2,\n$$\n其中 $R \\in \\mathbb{R}^{5 \\times 5}$ 是一个对角矩阵，其对角元素满足 $R_{00}=0$（对截距项不施加惩罚）且对于所有 $i \\in \\{1,2,3,4\\}$ 满足 $R_{ii}=1$。对于每个折，使用 $\\hat b^{(j)}$ 对测试行形成预测 $\\hat y$，并计算平方误差。汇总所有折和所有留出行的平方误差，最终得分是这些平方误差在所有折的总留出行数上的均值。该均值是对于给定对 $(K,\\lambda)$ 的单个实值结果。\n\n定义以下测试套件，其中每个测试用例是一个对 $(K,\\lambda)$：\n- 测试 $1$: $(K,\\lambda) = (3, 0.1)$。\n- 测试 $2$: $(K,\\lambda) = (6, 0.0)$。\n- 测试 $3$: $(K,\\lambda) = (2, 1.0)$。\n- 测试 $4$: $(K,\\lambda) = (4, 0.5)$。\n\n您的程序必须严格按照规定构建数据集，严格按照定义执行基于折的评估，并为每个测试用例计算所有留出行的平方误差均值。您的程序应生成单行输出，其中包含测试$1$到$4$的结果，结果按顺序排列，格式为方括号内包含的逗号分隔列表，每个实数四舍五入到小数点后恰好$6$位（例如，$[0.123456,0.000000,1.500000,2.718282]$）。", "solution": "该问题经过严格验证，被认为是有效的。它是一项有科学依据、良定且客观的计算任务。它是自包含的，所有必要的数据和定义均已提供。该过程描述了正则化线性模型的标准患者级别（或留组）交叉验证，这是生物统计学和生物信息学中一种常用技术，用以防止来自同一受试者内相关测量的数据泄露。所有的数学和程序定义都非常精确，为一个唯一且可验证的解决方案奠定了坚实的基础。\n\n该任务是计算一个连续药物反应预测模型的交叉验证均方误差。解决方案分为两个主要阶段：首先，根据指定的确定性规则生成完整的数据集；其次，对每个给定的测试用例 $(K, \\lambda)$ 执行感知患者的 K 折交叉验证。\n\n首先，我们构建完整的数据集。患者集合为 $\\mathcal{P}=\\{1,2,3,4,5,6\\}$。对每位患者 $p \\in \\mathcal{P}$ 的测量时间点由集合 $T(p)$ 给出。观测总数为 $N = \\sum_{p \\in \\mathcal{P}} |T(p)| = 3+2+4+1+2+3 = 15$。对于每个对应于一对 $(p,t)$ 的数据点，我们生成一个 5 维特征向量和一个标量响应。特征如下：\n$$\n\\begin{aligned}\ng_1 &= 1 + 0.1\\,p + 0.05\\,t \\\\\ng_2 &= -2 + 0.2\\,p - 0.05\\,t^2 \\\\\ng_3 &= 0.5\\,p + 0.1\\,t \\\\\nu &= t\n\\end{aligned}\n$$\n每个观测的设计向量为 $x = [1, g_1, g_2, g_3, u]^\\top \\in \\mathbb{R}^5$，其中包括一个常数截距项。响应 $y$ 由一个带有确定性扰动项 $\\varepsilon$ 的线性模型生成：\n$$\ny = x^\\top b^\\star + \\varepsilon\n$$\n其中真实系数向量为 $b^\\star = [0.3, 1.2, -0.8, 0.5, 0.7]^\\top$，且扰动为 $\\varepsilon = 0.01\\,(p-3)\\,(0.5 - 0.1\\,t)$。我们将所有 $N=15$ 个观测值组装成一个完整的设计矩阵 $X_{\\text{full}} \\in \\mathbb{R}^{15 \\times 5}$ 和一个响应向量 $y_{\\text{full}} \\in \\mathbb{R}^{15}$。我们还维护一个与每行对应的患者标识符数组。\n\n其次，对于每个测试用例 $(K, \\lambda)$，我们执行交叉验证。患者集合被划分为 $K$ 个折。患者首先按其索引升序排序：$(1,2,3,4,5,6)$。此序列中秩为 $r \\in \\{0, 1, \\dots, 5\\}$ 的患者被分配到折 $f = r \\pmod K$。设所得的患者划分为 $F_0, \\dots, F_{K-1}$。\n\n交叉验证通过迭代每个折索引 $j \\in \\{0, \\dots, K-1\\}$ 来进行。在每次迭代中，与 $F_j$ 中患者对应的数据构成测试集，而所有剩余数据构成训练集。设折 $j$ 的训练数据为 $(X_{\\text{train}}, y_{\\text{train}})$，包含 $n_{\\text{train}}$ 个样本，测试数据为 $(X_{\\text{test}}, y_{\\text{test}})$。\n\n对于每个折，我们必须通过最小化指定的正则化最小二乘目标函数来估计模型参数 $\\hat{b}^{(j)}$：\n$$\nJ(b) = \\frac{1}{n_{\\text{train}}}\\,\\|X_{\\text{train}}\\,b - y_{\\text{train}}\\|_2^2 + \\lambda\\,\\|R\\,b\\|_2^2\n$$\n正则化矩阵 $R$ 是一个对角矩阵，其中 $R_{00}=0$ 且对于 $i>0$ 有 $R_{ii}=1$，这实现了对除截距项外的所有系数进行惩罚的岭回归。该目标函数是凸函数，其最小化子可以通过将其关于 $b$ 的梯度设为零来找到：\n$$\n\\nabla_b J(b) = \\frac{2}{n_{\\text{train}}} X_{\\text{train}}^\\top (X_{\\text{train}}b - y_{\\text{train}}) + 2\\lambda R^\\top R b = 0\n$$\n由于 $R$ 是对角矩阵，所以 $R^\\top R = R^2 = \\text{diag}(0,1,1,1,1)$。重新整理这些项，我们得到此正则化问题的正规方程：\n$$\n\\left(\\frac{1}{n_{\\text{train}}} X_{\\text{train}}^\\top X_{\\text{train}} + \\lambda R^2\\right) b = \\frac{1}{n_{\\text{train}}} X_{\\text{train}}^\\top y_{\\text{train}}\n$$\n两边乘以 $n_{\\text{train}}$ 将系统简化为岭回归的标准形式：\n$$\n(X_{\\text{train}}^\\top X_{\\text{train}} + n_{\\text{train}}\\lambda R^2) \\hat{b}^{(j)} = X_{\\text{train}}^\\top y_{\\text{train}}\n$$\n求解此线性系统以得到参数估计 $\\hat{b}^{(j)}$。当 $\\lambda > 0$ 时，矩阵 $(X_{\\text{train}}^\\top X_{\\text{train}} + n_{\\text{train}}\\lambda R^2)$ 保证是可逆的；当 $\\lambda=0$ 时，只要 $X_{\\text{train}}$ 具有满列秩，它也是可逆的，而在此问题中所有训练集都满足此条件。\n\n使用估计出的参数 $\\hat{b}^{(j)}$，对测试集进行预测：$\\hat{y}_{\\text{test}} = X_{\\text{test}}\\hat{b}^{(j)}$。测试集中所有数据点的平方误差计算为 $(y_{\\text{test}} - \\hat{y}_{\\text{test}})^2$。这些平方误差从所有 $K$ 个折中收集。由于在交叉验证过程中每个数据点恰好属于一个测试集，我们总共收集 $N=15$ 个平方误差值。对于给定的 $(K, \\lambda)$，最终得分是这 $N$ 个值的均值。对所有四个测试用例重复此过程。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_cv_score(K, lam, patient_ids, X_full, y_full):\n    \"\"\"\n    Computes the cross-validated mean squared error for a given K and lambda.\n    \n    Args:\n        K (int): The number of folds.\n        lam (float): The regularization parameter.\n        patient_ids (np.ndarray): Array of patient IDs for each row in X_full.\n        X_full (np.ndarray): The full design matrix.\n        y_full (np.ndarray): The full response vector.\n        \n    Returns:\n        float: The mean squared error across all folds.\n    \"\"\"\n    patients_sorted = sorted(list(set(patient_ids)))\n    patient_to_fold = {p: i % K for i, p in enumerate(patients_sorted)}\n    \n    all_squared_errors = []\n    \n    # Define the regularization matrix R^2\n    R_sq = np.diag([0.0, 1.0, 1.0, 1.0, 1.0])\n    \n    for j in range(K):\n        # Create boolean masks for train/test split based on patient IDs\n        test_mask = np.array([patient_to_fold[p_id] == j for p_id in patient_ids])\n        train_mask = ~test_mask\n        \n        # Split the data\n        X_train, y_train = X_full[train_mask], y_full[train_mask]\n        X_test, y_test = X_full[test_mask], y_full[test_mask]\n        \n        n_train = X_train.shape[0]\n        \n        # Solve the normal equations for Ridge regression\n        # (X_train.T @ X_train + n_train * lam * R^2) @ b = X_train.T @ y_train\n        A = X_train.T @ X_train + n_train * lam * R_sq\n        b_vec = X_train.T @ y_train\n        \n        try:\n            b_hat = np.linalg.solve(A, b_vec)\n        except np.linalg.LinAlgError:\n            # Fallback to pseudoinverse if solve fails, though not expected here\n            A_pinv = np.linalg.pinv(A)\n            b_hat = A_pinv @ b_vec\n\n        # Predict on the test set\n        y_pred = X_test @ b_hat\n        \n        # Calculate and store squared errors\n        squared_errors = (y_test - y_pred) ** 2\n        all_squared_errors.extend(squared_errors.tolist())\n        \n    # The final score is the mean of all collected squared errors\n    mean_squared_error = np.mean(all_squared_errors)\n    \n    return mean_squared_error\n\ndef solve():\n    \"\"\"\n    Main function to orchestrate dataset generation and cross-validation evaluation.\n    \"\"\"\n    # Define test cases: (K, lambda)\n    test_cases = [\n        (3, 0.1),\n        (6, 0.0),\n        (2, 1.0),\n        (4, 0.5),\n    ]\n\n    # Patient time points\n    T = {\n        1: [0, 1, 2],\n        2: [0, 1],\n        3: [0, 1, 2, 3],\n        4: [0],\n        5: [0, 1],\n        6: [0, 1, 2],\n    }\n\n    # True coefficients b_star\n    b_star = np.array([0.3, 1.2, -0.8, 0.5, 0.7])\n\n    # Generate the full dataset\n    data_points = []\n    for p in sorted(T.keys()):\n        for t in T[p]:\n            g1 = 1 + 0.1 * p + 0.05 * t\n            g2 = -2 + 0.2 * p - 0.05 * t**2\n            g3 = 0.5 * p + 0.1 * t\n            u = float(t)\n            \n            x = np.array([1.0, g1, g2, g3, u])\n            \n            eps = 0.01 * (p - 3) * (0.5 - 0.1 * t)\n            y = x @ b_star + eps\n            \n            data_points.append({'p': p, 'x': x, 'y': y})\n\n    patient_ids_full = np.array([dp['p'] for dp in data_points])\n    X_full = np.array([dp['x'] for dp in data_points])\n    y_full = np.array([dp['y'] for dp in data_points])\n\n    results = []\n    for K, lam in test_cases:\n        score = compute_cv_score(K, lam, patient_ids_full, X_full, y_full)\n        results.append(score)\n\n    # Format the output as specified\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```", "id": "2383472"}, {"introduction": "除了处理样本间的依赖关系，一个稳健的模型评估流程还需考虑潜在的混淆变量。在基因组学中，诸如 GC 含量之类的序列特征就可能影响模型的预测，若训练集和测试集的 GC 含量分布差异过大，评估结果便会产生偏差。本练习将带您实现一个基于连续特征（本例中为 GC 含量）的定制化分层交叉验证方案，通过确保每个折都含有具代表性的 GC 含量分布，您将学会如何构建能有效控制生物协变量、更具鲁棒性的评估流程。[@problem_id:2383457]", "problem": "我们将评估一个二元分类器，该分类器用于预测一个脱氧核糖核酸（DNA）序列是否为增强子（标签为$1$）或非增强子（标签为$0$）。评估采用一种按鸟嘌呤-胞嘧啶（GC）含量分层的交叉验证方案。提供了一个包含 $N=12$ 个DNA窗口的数据集。对于每个窗口 $i \\in \\{1,\\dots,12\\}$，其GC比例 $g_i \\in [0,1]$ 和增强子标签 $y_i \\in \\{0,1\\}$ 如下所示（索引已按 $g_i$ 递增排序）：\n- $i=1$: $g_1=0.30$, $y_1=0$\n- $i=2$: $g_2=0.34$, $y_2=0$\n- $i=3$: $g_3=0.36$, $y_3=0$\n- $i=4$: $g_4=0.40$, $y_4=0$\n- $i=5$: $g_5=0.45$, $y_5=0$\n- $i=6$: $g_6=0.48$, $y_6=1$\n- $i=7$: $g_7=0.52$, $y_7=1$\n- $i=8$: $g_8=0.55$, $y_8=1$\n- $i=9$: $g_9=0.60$, $y_9=1$\n- $i=10$: $g_{10}=0.62$, $y_{10}=1$\n- $i=11$: $g_{11}=0.66$, $y_{11}=1$\n- $i=12$: $g_{12}=0.70$, $y_{12}=1$\n\n分类器是仅基于GC比例的阈值规则 $f_{\\tau}$：\n- 对于阈值 $\\tau \\in [0,1]$，如果 $g_i \\ge \\tau$，则预测标签为 $\\hat{y}_i = 1$，否则 $\\hat{y}_i = 0$。\n\n交叉验证（CV）的划分定义如下。对于给定的GC含量箱数 $B \\in \\mathbb{N}$ 和折数 $K \\in \\mathbb{N}$：\n1. 按 $g_i$ 递增排序索引（上面的列表已经排序）。\n2. 将排序后的索引划分为 $B$ 个连续的箱，其大小相差最多为 $1$。形式上，设 $q = \\left\\lfloor \\frac{N}{B} \\right\\rfloor$ 且 $r = N \\bmod B$。前 $r$ 个箱的大小为 $q+1$，其余 $B-r$ 个箱的大小为 $q$，并保持排序顺序。\n3. 在每个箱内，按排序索引的顺序，以循环方式将样本分配到折 $0,1,\\dots,K-1$ 中：箱中的第 $t$ 个样本（$t$ 从 $0$ 开始）被分配到折 $t \\bmod K$。\n4. 对于折 $k \\in \\{0,\\dots,K-1\\}$，测试集是所有箱中分配给折 $k$ 的索引的并集。训练集是测试集的补集。如果某个折的测试集为空，则在下文所述的平均计算中将其排除。\n\n对测试集 $S$ 的评估使用平衡准确率。定义 $S$ 上的真阳性率（TPR）和真阴性率（TNR）为\n$$\n\\mathrm{TPR}(S) = \\begin{cases}\n\\frac{\\#\\{i \\in S : y_i = 1 \\text{ and } \\hat{y}_i = 1\\}}{\\#\\{i \\in S : y_i = 1\\}}, & \\text{如果 } \\#\\{i \\in S : y_i = 1\\} > 0, \\\\\n0, & \\text{否则},\n\\end{cases}\n$$\n$$\n\\mathrm{TNR}(S) = \\begin{cases}\n\\frac{\\#\\{i \\in S : y_i = 0 \\text{ and } \\hat{y}_i = 0\\}}{\\#\\{i \\in S : y_i = 0\\}}, & \\text{如果 } \\#\\{i \\in S : y_i = 0\\} > 0, \\\\\n0, & \\text{否则}.\n\\end{cases}\n$$\n$S$ 上的平衡准确率（BA）为\n$$\n\\mathrm{BA}(S) = \\frac{1}{2}\\left(\\mathrm{TPR}(S) + \\mathrm{TNR}(S)\\right).\n$$\n对于CV，计算每个非空折的测试集上的 $\\mathrm{BA}$，并报告这些折对应值的算术平均值。\n\n测试套件。对于上述固定数据，在以下三个参数集 $(K,B,\\tau)$ 下评估 $f_{\\tau}$：\n- 案例 1：$K=3$, $B=3$, $\\tau=0.50$。\n- 案例 2：$K=4$, $B=3$, $\\tau=0.55$。\n- 案例 3：$K=6$, $B=4$, $\\tau=0.48$。\n\n您的程序必须完全按照规定实现分箱和折分配，相应地评估分类器 $f_{\\tau}$，并计算每种情况下的交叉验证平衡准确率。最终输出格式：生成一行包含三个平衡准确率的逗号分隔列表，按上述案例的顺序排列，四舍五入到恰好四位小数，并用方括号括起来，例如 $[\\mathrm{result}_1,\\mathrm{result}_2,\\mathrm{result}_3]$，无空格。", "solution": "问题陈述经过严格验证，被认为是科学合理的、定义明确的、客观的和完整的。所有数据、参数和算法都以足够的精度进行了规定，以得出一个唯一且可验证的解。该问题描述了在生物信息学背景下进行交叉验证的一个标准（尽管具体）的程序，这是一项合法的科学任务。因此，我们着手求解。\n\n数据集包含 $N=12$ 个样本，每个样本都有一个鸟嘌呤-胞嘧啶（GC）比例 $g_i$ 和一个二元标签 $y_i$。按 $g_i$ 排序后的数据如下：\n$$\n\\begin{array}{r|*{12}{c}}\n\\text{索引 } i & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 \\\\\n\\hline\n\\text{GC 比例 } g_i & 0.30 & 0.34 & 0.36 & 0.40 & 0.45 & 0.48 & 0.52 & 0.55 & 0.60 & 0.62 & 0.66 & 0.70 \\\\\n\\text{标签 } y_i & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\\\\n\\end{array}\n$$\n分类器 $f_{\\tau}$ 在 $g_i \\ge \\tau$ 时预测标签 $\\hat{y}_i=1$，否则预测 $\\hat{y}_i=0$。评估基于交叉验证各折的平均平衡准确率（BA）。\n\n我们按规定分析每个测试案例。\n\n**案例 1：$K=3$, $B=3$, $\\tau=0.50$**\n\n1.  **分箱**：对于 $N=12$ 和 $B=3$，我们有 $q = \\lfloor 12/3 \\rfloor = 4$ 和 $r = 12 \\bmod 3 = 0$。3个箱中的每个箱包含4个样本。\n    - 箱 1：索引 $\\{1, 2, 3, 4\\}$\n    - 箱 2：索引 $\\{5, 6, 7, 8\\}$\n    - 箱 3：索引 $\\{9, 10, 11, 12\\}$\n\n2.  **折分配**：对于 $K=3$，在每个箱内以循环方式将样本分配到折 $0, 1, 2$。\n    - 折 $0$ 包含每个箱的第1个和第4个样本：$\\{1, 4, 5, 8, 9, 12\\}$。\n    - 折 $1$ 包含每个箱的第2个样本：$\\{2, 6, 10\\}$。\n    - 折 $2$ 包含每个箱的第3个样本：$\\{3, 7, 11\\}$。\n\n3.  **评估**：对于 $\\tau=0.50$，分类器在 $g_i \\ge 0.50$ 时预测 $\\hat{y}_i = 1$，这对应于索引 $i \\in \\{7, 8, \\dots, 12\\}$。\n\n    - **折 0 测试集 $S_0=\\{1, 4, 5, 8, 9, 12\\}$**：\n        - 真阴性 ($y_i=0$)：$\\{1, 4, 5\\}$；计数为3。预测为 $\\hat{y}_1=0, \\hat{y}_4=0, \\hat{y}_5=0$。全部正确(TN)。TN数量为3。\n        - 真阳性 ($y_i=1$)：$\\{8, 9, 12\\}$；计数为3。预测为 $\\hat{y}_8=1, \\hat{y}_9=1, \\hat{y}_{12}=1$。全部正确(TP)。TP数量为3。\n        - $\\mathrm{TNR}(S_0) = 3/3 = 1$。$\\mathrm{TPR}(S_0) = 3/3 = 1$。\n        - $\\mathrm{BA}(S_0) = \\frac{1}{2}(1 + 1) = 1$。\n\n    - **折 1 测试集 $S_1=\\{2, 6, 10\\}$**：\n        - 真阴性 ($y_i=0$)：$\\{2\\}$；计数为1。预测为 $\\hat{y}_2=0$。这是一个TN。\n        - 真阳性 ($y_i=1$)：$\\{6, 10\\}$；计数为2。预测为 $\\hat{y}_6=0$ ($g_6=0.48 < 0.50$，一个假阴性) 和 $\\hat{y}_{10}=1$ ($g_{10}=0.62 \\ge 0.50$，一个TP)。\n        - $\\mathrm{TNR}(S_1) = 1/1 = 1$。$\\mathrm{TPR}(S_1) = 1/2 = 0.5$。\n        - $\\mathrm{BA}(S_1) = \\frac{1}{2}(1 + 0.5) = 0.75$。\n\n    - **折 2 测试集 $S_2=\\{3, 7, 11\\}$**：\n        - 真阴性 ($y_i=0$)：$\\{3\\}$；计数为1。预测为 $\\hat{y}_3=0$。这是一个TN。\n        - 真阳性 ($y_i=1$)：$\\{7, 11\\}$；计数为2。预测为 $\\hat{y}_7=1, \\hat{y}_{11}=1$。两者都是TP。\n        - $\\mathrm{TNR}(S_2) = 1/1 = 1$。$\\mathrm{TPR}(S_2) = 2/2 = 1$。\n        - $\\mathrm{BA}(S_2) = \\frac{1}{2}(1 + 1) = 1$。\n\n4.  **平均BA**：平均BA为 $\\frac{1}{3}(1 + 0.75 + 1) = \\frac{2.75}{3} \\approx 0.9167$。\n\n**案例 2：$K=4$, $B=3$, $\\tau=0.55$**\n\n1.  **分箱**：与案例1相同。箱为 $\\{1,2,3,4\\}, \\{5,6,7,8\\}, \\{9,10,11,12\\}$。\n\n2.  **折分配**：对于 $K=4$，样本被分配到折 $0, 1, 2, 3$。\n    - 折 $0$: $\\{1, 5, 9\\}$。折 $1$: $\\{2, 6, 10\\}$。折 $2$: $\\{3, 7, 11\\}$。折 $3$: $\\{4, 8, 12\\}$。\n\n3.  **评估**：对于 $\\tau=0.55$，当 $g_i \\ge 0.55$ 时，$\\hat{y}_i = 1$，即 $i \\in \\{8, 9, \\dots, 12\\}$。\n\n    - **折 0 测试集 $S_0=\\{1, 5, 9\\}$**：\n        - P: $\\{9\\}$（1个样本），N: $\\{1, 5\\}$（2个样本）。\n        - 预测: $\\hat{y}_1=0$ (TN)，$\\hat{y}_5=0$ (TN)，$\\hat{y}_9=1$ (TP)。\n        - $\\mathrm{TNR}(S_0) = 2/2 = 1$。$\\mathrm{TPR}(S_0) = 1/1 = 1$。$\\mathrm{BA}(S_0) = 1$。\n\n    - **折 1 测试集 $S_1=\\{2, 6, 10\\}$**：\n        - P: $\\{6, 10\\}$（2个样本），N: $\\{2\\}$（1个样本）。\n        - 预测: $\\hat{y}_2=0$ (TN)，$\\hat{y}_6=0$ (FN)，$\\hat{y}_{10}=1$ (TP)。\n        - $\\mathrm{TNR}(S_1) = 1/1 = 1$。$\\mathrm{TPR}(S_1) = 1/2 = 0.5$。$\\mathrm{BA}(S_1) = 0.75$。\n\n    - **折 2 测试集 $S_2=\\{3, 7, 11\\}$**：\n        - P: $\\{7, 11\\}$（2个样本），N: $\\{3\\}$（1个样本）。\n        - 预测: $\\hat{y}_3=0$ (TN)，$\\hat{y}_7=0$ (FN，因为 $g_7=0.52 < 0.55$)，$\\hat{y}_{11}=1$ (TP)。\n        - $\\mathrm{TNR}(S_2) = 1/1 = 1$。$\\mathrm{TPR}(S_2) = 1/2 = 0.5$。$\\mathrm{BA}(S_2) = 0.75$。\n\n    - **折 3 测试集 $S_3=\\{4, 8, 12\\}$**：\n        - P: $\\{8, 12\\}$（2个样本），N: $\\{4\\}$（1个样本）。\n        - 预测: $\\hat{y}_4=0$ (TN)，$\\hat{y}_8=1$ (TP)，$\\hat{y}_{12}=1$ (TP)。\n        - $\\mathrm{TNR}(S_3) = 1/1 = 1$。$\\mathrm{TPR}(S_3) = 2/2 = 1$。$\\mathrm{BA}(S_3) = 1$。\n\n4.  **平均BA**：平均BA为 $\\frac{1}{4}(1 + 0.75 + 0.75 + 1) = \\frac{3.5}{4} = 0.8750$。\n\n**案例 3：$K=6$, $B=4$, $\\tau=0.48$**\n\n1.  **分箱**：对于 $N=12$ 和 $B=4$，我们有 $q = \\lfloor 12/4 \\rfloor = 3$ 和 $r = 12 \\bmod 4 = 0$。4个箱中的每个箱包含3个样本。\n    - 箱 1: $\\{1, 2, 3\\}$。箱 2: $\\{4, 5, 6\\}$。箱 3: $\\{7, 8, 9\\}$。箱 4: $\\{10, 11, 12\\}$。\n\n2.  **折分配**：对于 $K=6$，样本被分配到折 $0, \\dots, 5$。\n    - 折 $0$: $\\{1, 4, 7, 10\\}$。折 $1$: $\\{2, 5, 8, 11\\}$。折 $2$: $\\{3, 6, 9, 12\\}$。\n    - 折 $3, 4, 5$ 为空，不参与平均计算。\n\n3.  **评估**：对于 $\\tau=0.48$，当 $g_i \\ge 0.48$ 时，$\\hat{y}_i = 1$，即 $i \\in \\{6, 7, \\dots, 12\\}$。\n\n    - **折 0 测试集 $S_0=\\{1, 4, 7, 10\\}$**：\n        - P: $\\{7, 10\\}$（2个样本），N: $\\{1, 4\\}$（2个样本）。\n        - 预测: $\\hat{y}_1=0$ (TN)，$\\hat{y}_4=0$ (TN)，$\\hat{y}_7=1$ (TP)，$\\hat{y}_{10}=1$ (TP)。\n        - $\\mathrm{TNR}(S_0) = 2/2 = 1$。$\\mathrm{TPR}(S_0) = 2/2 = 1$。$\\mathrm{BA}(S_0) = 1$。\n\n    - **折 1 测试集 $S_1=\\{2, 5, 8, 11\\}$**：\n        - P: $\\{8, 11\\}$（2个样本），N: $\\{2, 5\\}$（2个样本）。\n        - 预测: $\\hat{y}_2=0$ (TN)，$\\hat{y}_5=0$ (TN)，$\\hat{y}_8=1$ (TP)，$\\hat{y}_{11}=1$ (TP)。\n        - $\\mathrm{TNR}(S_1) = 2/2 = 1$。$\\mathrm{TPR}(S_1) = 2/2 = 1$。$\\mathrm{BA}(S_1) = 1$。\n\n    - **折 2 测试集 $S_2=\\{3, 6, 9, 12\\}$**：\n        - P: $\\{6, 9, 12\\}$（3个样本），N: $\\{3\\}$（1个样本）。\n        - 预测: $\\hat{y}_3=0$ (TN)，$\\hat{y}_6=1$ (TP)，$\\hat{y}_9=1$ (TP)，$\\hat{y}_{12}=1$ (TP)。\n        - $\\mathrm{TNR}(S_2) = 1/1 = 1$。$\\mathrm{TPR}(S_2) = 3/3 = 1$。$\\mathrm{BA}(S_2) = 1$。\n\n4.  **平均BA**：平均BA为 $\\frac{1}{3}(1 + 1 + 1) = 1.0000$。\n\n最终结果是 $0.9167$、$0.8750$ 和 $1.0000$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the cross-validation problem for the three specified test cases.\n    \"\"\"\n    # Data as given in the problem statement.\n    # The data is 1-indexed in the problem; we use 0-indexed lists.\n    # The order is already sorted by GC content.\n    data = np.array([\n        (0.30, 0), (0.34, 0), (0.36, 0), (0.40, 0), (0.45, 0), (0.48, 1),\n        (0.52, 1), (0.55, 1), (0.60, 1), (0.62, 1), (0.66, 1), (0.70, 1)\n    ])\n    N = len(data)\n\n    test_cases = [\n        {'K': 3, 'B': 3, 'tau': 0.50},\n        {'K': 4, 'B': 3, 'tau': 0.55},\n        {'K': 6, 'B': 4, 'tau': 0.48},\n    ]\n\n    results = []\n    for params in test_cases:\n        K = params['K']\n        B = params['B']\n        tau = params['tau']\n\n        # Step 1 & 2: Binning\n        # Since data is already sorted, we just partition the indices.\n        q = N // B\n        r = N % B\n        \n        bins = []\n        current_idx = 0\n        for i in range(B):\n            bin_size = q + 1 if i < r else q\n            bins.append(list(range(current_idx, current_idx + bin_size)))\n            current_idx += bin_size\n            \n        # Step 3: Fold Assignment\n        folds = [[] for _ in range(K)]\n        for bin_indices in bins:\n            for t, sample_idx in enumerate(bin_indices):\n                fold_idx = t % K\n                folds[fold_idx].append(sample_idx)\n        \n        # Step 4: Evaluation\n        fold_accuracies = []\n        num_valid_folds = 0\n        \n        for k in range(K):\n            test_indices = folds[k]\n            if not test_indices:\n                continue\n            \n            num_valid_folds += 1\n            test_set = data[test_indices]\n            \n            # Get true labels and predicted labels for the test set\n            true_labels = test_set[:, 1]\n            gc_values = test_set[:, 0]\n            predicted_labels = (gc_values >= tau).astype(int)\n            \n            # Count positives and negatives in the test set\n            pos_mask = true_labels == 1\n            neg_mask = true_labels == 0\n            \n            num_pos = np.sum(pos_mask)\n            num_neg = np.sum(neg_mask)\n            \n            # Calculate True Positives (TP) and True Negatives (TN)\n            tp = np.sum((predicted_labels == 1) & pos_mask)\n            tn = np.sum((predicted_labels == 0) & neg_mask)\n            \n            # Calculate TPR and TNR with division-by-zero handling\n            tpr = tp / num_pos if num_pos > 0 else 0.0\n            tnr = tn / num_neg if num_neg > 0 else 0.0\n            \n            # Calculate Balanced Accuracy\n            ba = 0.5 * (tpr + tnr)\n            fold_accuracies.append(ba)\n            \n        # Compute mean balanced accuracy across non-empty folds\n        mean_ba = np.mean(fold_accuracies) if fold_accuracies else 0.0\n        results.append(mean_ba)\n\n    # Format the final output string as required\n    formatted_results = [f\"{res:.4f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2383457"}, {"introduction": "在交叉验证中，如何选择折数 $k$ 是一个涉及偏差（bias）与方差（variance）权衡的经典问题。理论上，留一法交叉验证（LOOCV，即 $k=N$）能提供近乎无偏的性能估计，但这种估计的稳定性（方差）如何呢？本模拟练习将让您亲手验证一个核心统计概念：通过编程模拟比较留一法交叉验证与 10 折交叉验证性能估计值的波动情况，您将直观地理解为何 LOOCV 虽然偏差小，但其估计结果的方差可能更高，以及为什么 K 折交叉验证在实践中通常是更稳健、更受青睐的选择。[@problem_id:2383426]", "problem": "您正在研究交叉验证（CV）对泛化误差估计的可靠性。该研究的背景源于计算生物学和生物信息学，其中基因表达值通过序列衍生特征进行预测。我们考虑一个纯粹的合成数据生成过程，其中特征与响应之间没有真实的预测信号，这反映了实践中常用作校准基线的零模型。\n\n数据生成过程。对于给定的样本量 $n$、特征维度 $p$ 和噪声尺度 $\\sigma > 0$，一个独立同分布的数据集 $S = \\{(x_i, y_i)\\}_{i=1}^n$ 按如下方式抽取：每个特征向量 $x_i \\in \\mathbb{R}^p$ 的坐标都独立地从标准正态分布中抽样，每个响应 $y_i \\in \\mathbb{R}$ 都独立地从均值为 $0$、方差为 $\\sigma^2$ 的正态分布中抽样，且与 $x_i$ 相互独立。在此合成设置中，特征可以解释为基于基序（motif）或k-mer的数值摘要，而响应代表基因表达测量值，所有这些都被形式化为独立的随机变量。\n\n模型类别与损失函数。对于任意训练子集 $T \\subset \\{1,\\dots,n\\}$，将带截距的普通最小二乘线性模型定义为函数 $f_{\\hat{\\beta}_T}(x) = \\hat{\\beta}_{0,T} + \\sum_{j=1}^p \\hat{\\beta}_{j,T} x_j$，其中参数向量 $\\hat{\\beta}_T$ 使得在训练子集 $T$ 上的平均平方误差最小。在目标值 $y$ 处，对预测值 $f_{\\hat{\\beta}_T}(x)$ 的损失为平方误差 $(y - f_{\\hat{\\beta}_T}(x))^2$。\n\n交叉验证的泛化误差估计。对于一个固定的数据集 $S$，定义：\n- 留一交叉验证（LOOCV）的均方误差估计值为：对每一个 $i \\in \\{1,\\dots,n\\}$，在集合 $\\{1,\\dots,n\\} \\setminus \\{i\\}$ 上训练模型并在索引 $i$ 上进行验证，得到平方误差，然后对所有这些平方误差求平均值。\n- $k=10$ 的 k 折交叉验证估计值如下计算。将 $\\{1,\\dots,n\\}$ 划分为 $k$ 个大小尽可能相等的折。具体方法是，为前 $n \\bmod k$ 个折分配一个额外元素，其余部分按顺序索引划分。对每个折，在其补集上训练模型，并在该留出的折上计算平方误差。10 折交叉验证的估计值是所有 $k$ 个折中所有平方误差的平均值。\n\n跨独立数据集的抽样方差。对于一个固定的参数元组 $(n,p,\\sigma)$，考虑从上述数据生成过程生成的 $R \\ge 2$ 个独立数据集 $S^{(1)},\\dots,S^{(R)}$。对每个数据集 $S^{(r)}$，计算 LOOCV 估计值和 10 折 CV 估计值。然后，对这 $R$ 个 LOOCV 估计值计算无偏样本方差，并对这 $R$ 个 10 折 CV 估计值计算无偏样本方差。\n\n任务。对于下面测试套件中的每个参数元组，生成 $R$ 个具有指定随机种子的独立数据集（为保证可复现性，请使用以给定种子初始化的伪随机数生成器），计算所定义的两种样本方差，并输出一个布尔值，该值表示 LOOCV 方差是否严格大于 10 折 CV 方差，且差值至少为 $10^{-12}$。形式上，如果 $\\mathrm{Var}_{\\text{LOOCV}} - \\mathrm{Var}_{10\\text{-fold}} > 10^{-12}$，则输出 $\\mathrm{True}$，否则输出 $\\mathrm{False}$。\n\n测试套件。使用以下三个参数元组，每个元组均以 $(\\text{seed}, n, p, \\sigma, R)$ 的形式给出：\n- $(1337, 60, 8, 1.0, 200)$，\n- $(20231102, 100, 12, 2.0, 150)$，\n- $(987654321, 20, 3, 1.5, 400)$。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表内容为按上述测试套件顺序列出的结果。每个条目必须是一个布尔值。例如，一个有效的输出形如 $[\\mathrm{True},\\mathrm{False},\\mathrm{True}]$。", "solution": "该问题要求对两种交叉验证泛化误差估计器——留一交叉验证（LOOCV）和10折交叉验证（10-fold CV）——的抽样方差进行比较分析。此分析将在合成生成的数据上进行，这些数据代表一个统计零模型，即特征对响应变量没有预测能力。该分析必须对几个指定的参数集执行。\n\n解决此问题的程序框架如下：\n\n1.  **模拟设置**：对于每个参数元组 $(\\text{seed}, n, p, \\sigma, R)$，其中 $\\text{seed}$ 是随机数生成器种子， $n$ 是样本量， $p$ 是特征维度， $\\sigma$ 是噪声标准差， $R$ 是独立模拟运行的次数，我们将执行 $R$ 次独立的试验。使用给定 $\\text{seed}$ 初始化的伪随机数生成器可确保整个实验的可复现性。\n\n2.  **数据生成**：在每次试验 $r \\in \\{1, \\dots, R\\}$ 中，我们生成一个数据集 $S^{(r)} = \\{(x_i, y_i)\\}_{i=1}^n$ 。每个特征向量 $x_i \\in \\mathbb{R}^p$ 的分量 $x_{ij}$ 都是从标准正态分布（$x_{ij} \\sim \\mathcal{N}(0, 1)$）中独立同分布（i.i.d.）抽取的。每个响应 $y_i \\in \\mathbb{R}$ 都是从均值为 $0$、方差为 $\\sigma^2$ 的正态分布（即 $y_i \\sim \\mathcal{N}(0, \\sigma^2)$）中独立同分布抽取的。特征和响应彼此独立。\n\n3.  **模型规格**：模型是带截距项的普通最小二乘（OLS）线性回归模型。对于给定的训练集，模型函数为 $f_{\\hat{\\beta}}(x) = \\hat{\\beta}_0 + \\sum_{j=1}^p \\hat{\\beta}_j x_j$ 。系数向量 $\\hat{\\beta} = (\\hat{\\beta}_0, \\hat{\\beta}_1, \\dots, \\hat{\\beta}_p)^T$ 通过最小化训练数据上的平方和误差来估计。这可以通过求解正规方程组来实现。对于增广设计矩阵 $X_{\\text{aug}}$（其前导列为全1列）和响应向量 $y$ ，解为 $\\hat{\\beta} = (X_{\\text{aug}}^T X_{\\text{aug}})^{-1} X_{\\text{aug}}^T y$ 。我们将使用数值稳定的求解器，例如基于QR分解的求解器，来进行此计算。\n\n4.  **留一交叉验证（LOOCV）误差**：对于每个数据集 $S^{(r)}$ ，我们计算均方误差（MSE）的 LOOCV 估计值。一个朴素的实现方法是拟合 OLS 模型 $n$ 次。然而，对于线性模型，存在一种高效的解析捷径。第 $i$ 个数据点的 LOOCV 预测值 $\\hat{y}_{(-i)}$ 可以通过在整个数据集上进行单次模型拟合的结果计算得出。设 $\\hat{y}_i$ 是完整模型对第 $i$ 个数据点的预测值， $h_{ii}$ 是帽子矩阵 $H = X_{\\text{aug}}(X_{\\text{aug}}^T X_{\\text{aug}})^{-1}X_{\\text{aug}}^T$ 的第 $i$ 个对角元素。LOOCV 残差由下式给出：\n    $$ y_i - \\hat{y}_{(-i)} = \\frac{y_i - \\hat{y}_i}{1 - h_{ii}} $$\n    对角元素 $h_{ii}$ ，也称为杠杆值，可以从 $X_{\\text{aug}}$ 的 QR 分解的 $Q$ 矩阵中高效计算。如果 $X_{\\text{aug}} = QR$ ，则 $H=QQ^T$ ，并且 $h_{ii}$ 是 $Q$ 的第 $i$ 行的欧几里得范数的平方。LOOCV MSE 估计值是这些平方残差的均值：\n    $$ \\text{LOOCV}(S^{(r)}) = \\frac{1}{n} \\sum_{i=1}^n \\left( \\frac{y_i - \\hat{y}_i}{1 - h_{ii}} \\right)^2 $$\n    对 $R$ 个数据集中的每一个都执行此计算，从而得到 $R$ 个估计值的序列。\n\n5.  **10折交叉验证误差**：对于同一个数据集 $S^{(r)}$ ，我们还计算 10 折 CV 估计值。将包含 $n$ 个样本的数据集划分为 $k=10$ 个折。问题指定了一种顺序划分方案，使得各折的大小尽可能相等。设这些折为 $F_1, \\dots, F_{10}$ 。对于每个折 $F_j$ ，使用其余 9 个折的数据（$S \\setminus F_j$）训练一个 OLS 模型。然后，该模型用于预测留出折 $F_j$ 中数据的响应。10 折 CV 估计值是所有 $n$ 个数据点上平方预测误差的平均值。\n    $$ 10\\text{-fold CV}(S^{(r)}) = \\frac{1}{n} \\sum_{j=1}^{10} \\sum_{(x_i, y_i) \\in F_j} (y_i - f_{\\hat{\\beta}_{S \\setminus F_j}}(x_i))^2 $$\n    对 $R$ 个数据集中的每一个重复此过程。\n\n6.  **抽样方差计算**：经过 $R$ 次试验后，我们得到两组估计值：$\\{\\text{LOOCV}(S^{(r)})\\}_{r=1}^R$ 和 $\\{10\\text{-fold CV}(S^{(r)})\\}_{r=1}^R$ 。我们为每组计算无偏样本方差。对于一组通用估计值 $\\{E_r\\}_{r=1}^R$ ，无偏样本方差为：\n    $$ \\text{Var} = \\frac{1}{R-1} \\sum_{r=1}^R (E_r - \\bar{E})^2, \\quad \\text{其中 } \\bar{E} = \\frac{1}{R} \\sum_{r=1}^R E_r $$\n    这将得到两个值：$\\mathrm{Var}_{\\text{LOOCV}}$ 和 $\\mathrm{Var}_{10\\text{-fold}}$ 。\n\n7.  **最终比较**：任务是确定 LOOCV 估计器的方差是否严格大于 10 折 CV 估计器的方差，且差值至少为一个很小的裕量 $10^{-12}$ 。对于每个参数集，我们评估布尔条件：\n    $$ \\mathrm{Var}_{\\text{LOOCV}} - \\mathrm{Var}_{10\\text{-fold}} > 10^{-12} $$\n    所有测试用例的结果被汇编成一个列表。\n\n理论上，LOOCV 的抽样方差预计会比 k 折 CV（对于较小的 $k$）更高，因为 LOOCV 中每个折的训练集几乎完全相同，仅相差一个样本。这种高度重叠导致模型之间高度相关，从而导致误差估计值也高度相关。相关随机变量的平均值的方差要高于相关性较低的随机变量的平均值的方差。10 折 CV 使用的训练集重叠较少，这通常会使得对不同初始数据抽样的泛化误差估计更稳定（方差更低）。我们的计算将验证这一启发式观点在给定场景下是否成立。", "answer": "```python\nimport numpy as np\n\ndef calculate_loocv_mse(X: np.ndarray, y: np.ndarray) -> float:\n    \"\"\"\n    Calculates the Leave-One-Out Cross-Validation Mean Squared Error for OLS\n    using the efficient analytical shortcut.\n    \"\"\"\n    n, p = X.shape\n    X_aug = np.hstack([np.ones((n, 1)), X])\n\n    # Fit OLS model on the full dataset\n    beta_hat, _, _, _ = np.linalg.lstsq(X_aug, y, rcond=None)\n    y_pred_full = X_aug @ beta_hat\n\n    # Calculate leverages (diagonal of the hat matrix) using QR decomposition\n    q, _ = np.linalg.qr(X_aug, mode='reduced')\n    leverages = np.sum(q * q, axis=1)\n\n    # Handle cases where leverage is close to 1\n    # This might happen with duplicate data points, though unlikely here.\n    # We clip to prevent division by zero or very small numbers.\n    leverages = np.clip(leverages, 0, 1 - 1e-9)\n\n    # Calculate LOOCV residuals and MSE\n    loocv_residuals = (y - y_pred_full) / (1 - leverages)\n    return np.mean(loocv_residuals**2)\n\ndef calculate_kfold_cv_mse(X: np.ndarray, y: np.ndarray, k: int) -> float:\n    \"\"\"\n    Calculates the k-fold Cross-Validation Mean Squared Error for OLS.\n    \"\"\"\n    n = X.shape[0]\n    indices = np.arange(n)\n    \n    # Define fold sizes as per the problem description\n    fold_sizes = np.full(k, n // k, dtype=int)\n    fold_sizes[:n % k] += 1\n    \n    current_idx = 0\n    all_squared_errors = []\n    \n    for fold_size in fold_sizes:\n        test_indices = indices[current_idx : current_idx + fold_size]\n        train_indices = np.setdiff1d(indices, test_indices, assume_unique=True)\n        \n        X_train, y_train = X[train_indices], y[train_indices]\n        X_test, y_test = X[test_indices], y[test_indices]\n        \n        # Augment data with intercept term\n        X_train_aug = np.hstack([np.ones((X_train.shape[0], 1)), X_train])\n        X_test_aug = np.hstack([np.ones((X_test.shape[0], 1)), X_test])\n        \n        # Fit OLS model on the training fold\n        beta_hat, _, _, _ = np.linalg.lstsq(X_train_aug, y_train, rcond=None)\n        \n        # Predict on the test fold\n        y_pred = X_test_aug @ beta_hat\n        \n        squared_errors = (y_test - y_pred)**2\n        all_squared_errors.extend(squared_errors.tolist())\n        \n        current_idx += fold_size\n        \n    return np.mean(all_squared_errors)\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        (1337, 60, 8, 1.0, 200),\n        (20231102, 100, 12, 2.0, 150),\n        (987654321, 20, 3, 1.5, 400),\n    ]\n\n    final_results = []\n\n    for seed, n, p, sigma, R in test_cases:\n        rng = np.random.default_rng(seed)\n        \n        loocv_estimates = np.zeros(R)\n        kfold_estimates = np.zeros(R)\n        \n        for r_idx in range(R):\n            # Generate dataset S = {(x_i, y_i)}\n            X = rng.normal(loc=0, scale=1, size=(n, p))\n            y = rng.normal(loc=0, scale=sigma, size=n)\n            \n            # Compute LOOCV estimate for this dataset\n            loocv_estimates[r_idx] = calculate_loocv_mse(X, y)\n            \n            # Compute 10-fold CV estimate for this dataset\n            kfold_estimates[r_idx] = calculate_kfold_cv_mse(X, y, k=10)\n            \n        # Compute unbiased sample variance over the R datasets\n        # ddof=1 for unbiased sample variance (division by R-1)\n        var_loocv = np.var(loocv_estimates, ddof=1)\n        var_kfold = np.var(kfold_estimates, ddof=1)\n        \n        # Perform the comparison and store the boolean result\n        is_larger = (var_loocv - var_kfold) > 1e-12\n        final_results.append(is_larger)\n\n    # Print the final results in the specified format\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```", "id": "2383426"}]}