{"hands_on_practices": [{"introduction": "本练习旨在通过手动计算，深入理解期望最大化（EM）算法的核心迭代过程。我们将探讨一个简化的序列基元（motif）发现问题，这是一个生物信息学中的基本任务。通过逐步完成两轮完整的 E-M 步骤，您可以清晰地看到算法如何处理隐藏变量并更新模型参数 [@problem_id:2388823]。", "problem": "观测到一条长度为 $4$ 的双链 DNA 序列：位置 $1$ 到 $4$ 依次包含碱基 A、C、G、T。一个概率性基序发现模型规定如下。\n\n- 一个长度为 $L=2$ 的基序（motif）在该序列中仅出现一次，且只有两个候选的基序位置：位置 $1$–$2$ 或位置 $3$–$4$。令潜变量 $Z \\in \\{1,2\\}$ 表示基序的起始位置，其中 $Z=1$ 表示位置 $1$–$2$ 是基序，$Z=2$ 表示位置 $3$–$4$ 是基序。\n- 非基序位置的背景是独立同分布的，其在脱氧核糖核酸（DNA）字母表 $\\{ \\text{A}, \\text{C}, \\text{G}, \\text{T} \\}$ 上的固定分布为 $b_{\\text{A}}=b_{\\text{C}}=b_{\\text{G}}=b_{\\text{T}}=\\frac{1}{4}$。\n- 该基序由一个大小为 $2 \\times 4$ 的位置权重矩阵（PWM）$\\theta$ 建模，其中 PWM 的每一行都是在 $\\{\\text{A},\\text{C},\\text{G},\\text{T}\\}$ 上的一个分类分布。初始时（$t=0$），PWM 为\n  - 基序位置 1：$[\\theta_{1,\\text{A}},\\theta_{1,\\text{C}},\\theta_{1,\\text{G}},\\theta_{1,\\text{T}}] = \\left[\\frac{3}{5},\\frac{1}{5},\\frac{1}{10},\\frac{1}{10}\\right]$，\n  - 基序位置 2：$[\\theta_{2,\\text{A}},\\theta_{2,\\text{C}},\\theta_{2,\\text{G}},\\theta_{2,\\text{T}}] = \\left[\\frac{1}{10},\\frac{1}{10},\\frac{3}{5},\\frac{1}{5}\\right]$。\n- 两种基序位置的先验混合权重初始为 $\\pi^{(0)}_1=\\pi^{(0)}_2=\\frac{1}{2}$。\n- 背景分布 $b$ 是固定的（不更新）。不使用伪计数或正则化。\n\n将该模型视为一个有限混合模型，其完整数据似然按常规方式定义，即基序位置上来自 PWM 的独立分类发射和非基序位置上来自背景的发射。从上述初始参数开始，手动执行期望最大化（EM）算法的两次完整迭代，即执行两次 E-步骤后跟 M-步骤。\n\n完成第二个 E-步骤后，基序起始于位置 $1$–$2$ 的后验概率是多少，即 $\\Pr(Z=1 \\mid \\text{A C G T}; \\text{第一个 M-步骤后的参数})$？请将您的答案表示为四舍五入到四位有效数字的小数。", "solution": "该问题定义明确，具有科学依据，并包含执行所需计算的所有必要组成部分。这是期望最大化（EM）算法在生物信息学基序发现问题上的一个标准应用。因此，该问题被认为是有效的，并将按所述进行求解。\n\n期望最大化（EM）算法是一种迭代方法，用于在统计模型中寻找参数的最大似然估计，其中模型依赖于未观测到的潜变量。每次迭代包括两个步骤：一个期望（E）步骤和一个最大化（M）步骤。\n\n设观测数据为 DNA 序列 $X = (X_1, X_2, X_3, X_4) = (\\text{A}, \\text{C}, \\text{G}, \\text{T})$。潜变量 $Z \\in \\{1, 2\\}$ 表示基序的起始位置。模型的参数为 $\\Theta = (\\pi, \\theta)$，其中 $\\pi = (\\pi_1, \\pi_2)$ 是混合权重，$\\theta$ 是长度为 $L=2$ 的基序的位置权重矩阵（PWM）。\n\n对于单个观测值 $X$ 和潜变量 $Z$ 的一个特定值 $z$，其完整数据似然为 $\\Pr(X, Z=z; \\Theta) = \\Pr(X \\mid Z=z; \\theta) \\Pr(Z=z; \\pi) = \\pi_z \\Pr(X \\mid Z=z; \\theta)$。\n\nEM 算法的流程如下：\n1.  **E-步骤**：给定数据 $X$ 和当前参数 $\\Theta^{(t)}$，计算每个混合成分 $z$ 的后验概率，或称响应度（responsibility）。\n    $$ \\gamma_z^{(t)} = \\Pr(Z=z \\mid X; \\Theta^{(t)}) = \\frac{\\pi_z^{(t)} \\Pr(X \\mid Z=z; \\theta^{(t)})}{\\sum_{z'} \\pi_{z'}^{(t)} \\Pr(X \\mid Z=z'; \\theta^{(t)})} $$\n2.  **M-步骤**：使用在 E-步骤中计算出的响应度，通过最大化完整数据对数似然的期望值来更新参数为 $\\Theta^{(t+1)}$。对于此特定问题：\n    $$ \\pi_z^{(t+1)} = \\gamma_z^{(t)} $$\n    $$ \\theta_{j,k}^{(t+1)} = \\frac{\\sum_{z} \\gamma_z^{(t)} I(X_{s_z + j - 1} = k)}{\\sum_{k' \\in \\{\\text{A},\\text{C},\\text{G},\\text{T}\\}} \\sum_z \\gamma_z^{(t)} I(X_{s_z + j - 1} = k')} $$\n    其中 $I(\\cdot)$ 是指示函数，$s_z$ 是成分 $z$ 的起始位置（$s_1=1, s_2=3$），$j \\in \\{1, 2\\}$ 是基序内的位置，$k \\in \\{\\text{A}, \\text{C}, \\text{G}, \\text{T}\\}$。\n\n我们从 $t=0$ 时的初始参数开始：\n- 序列：$X = (\\text{A}, \\text{C}, \\text{G}, \\text{T})$\n- 混合权重：$\\pi^{(0)}_1 = \\frac{1}{2}, \\pi^{(0)}_2 = \\frac{1}{2}$\n- 背景分布：$b_k = \\frac{1}{4}$ for $k \\in \\{\\text{A}, \\text{C}, \\text{G}, \\text{T}\\}$\n- PWM $\\theta^{(0)}$：\n  - $\\theta^{(0)}_{1,\\cdot} = [\\theta_{1,\\text{A}},\\theta_{1,\\text{C}},\\theta_{1,\\text{G}},\\theta_{1,\\text{T}}] = \\left[\\frac{3}{5},\\frac{1}{5},\\frac{1}{10},\\frac{1}{10}\\right]$\n  - $\\theta^{(0)}_{2,\\cdot} = [\\theta_{2,\\text{A}},\\theta_{2,\\text{C}},\\theta_{2,\\text{G}},\\theta_{2,\\text{T}}] = \\left[\\frac{1}{10},\\frac{1}{10},\\frac{3}{5},\\frac{1}{5}\\right]$\n\n**第 1 次迭代：E-步骤**\n\n首先，我们计算每种可能的基序位置下数据的似然。\n- 如果 $Z=1$，基序位于位置 $1-2$ (`AC`)，背景位于位置 $3-4$ (`GT`)。其似然为：\n  $$ \\Pr(X \\mid Z=1; \\theta^{(0)}) = (\\theta^{(0)}_{1,\\text{A}} \\cdot \\theta^{(0)}_{2,\\text{C}}) \\cdot (b_{\\text{G}} \\cdot b_{\\text{T}}) = \\left(\\frac{3}{5} \\cdot \\frac{1}{10}\\right) \\cdot \\left(\\frac{1}{4} \\cdot \\frac{1}{4}\\right) = \\frac{3}{50} \\cdot \\frac{1}{16} = \\frac{3}{800} $$\n- 如果 $Z=2$，基序位于位置 $3-4$ (`GT`)，背景位于位置 $1-2$ (`AC`)。其似然为：\n  $$ \\Pr(X \\mid Z=2; \\theta^{(0)}) = (\\theta^{(0)}_{1,\\text{G}} \\cdot \\theta^{(0)}_{2,\\text{T}}) \\cdot (b_{\\text{A}} \\cdot b_{\\text{C}}) = \\left(\\frac{1}{10} \\cdot \\frac{1}{5}\\right) \\cdot \\left(\\frac{1}{4} \\cdot \\frac{1}{4}\\right) = \\frac{1}{50} \\cdot \\frac{1}{16} = \\frac{1}{800} $$\n\n接下来，我们计算联合概率和边际似然：\n- $\\Pr(X, Z=1; \\Theta^{(0)}) = \\pi^{(0)}_1 \\Pr(X \\mid Z=1; \\theta^{(0)}) = \\frac{1}{2} \\cdot \\frac{3}{800} = \\frac{3}{1600}$\n- $\\Pr(X, Z=2; \\Theta^{(0)}) = \\pi^{(0)}_2 \\Pr(X \\mid Z=2; \\theta^{(0)}) = \\frac{1}{2} \\cdot \\frac{1}{800} = \\frac{1}{1600}$\n- $\\Pr(X; \\Theta^{(0)}) = \\frac{3}{1600} + \\frac{1}{1600} = \\frac{4}{1600} = \\frac{1}{400}$\n\n现在，我们计算响应度 $\\gamma_z^{(0)}$：\n- $\\gamma_1^{(0)} = \\Pr(Z=1 \\mid X; \\Theta^{(0)}) = \\frac{3/1600}{4/1600} = \\frac{3}{4}$\n- $\\gamma_2^{(0)} = \\Pr(Z=2 \\mid X; \\Theta^{(0)}) = \\frac{1/1600}{4/1600} = \\frac{1}{4}$\n\n**第 1 次迭代：M-步骤**\n\n我们使用响应度 $\\gamma_1^{(0)}$ 和 $\\gamma_2^{(0)}$ 来更新参数。\n- 更新混合权重：\n  $$ \\pi_1^{(1)} = \\gamma_1^{(0)} = \\frac{3}{4} $$\n  $$ \\pi_2^{(1)} = \\gamma_2^{(0)} = \\frac{1}{4} $$\n- 更新 PWM $\\theta^{(1)}$：\n  对于基序位置 $j=1$：\n  - $\\theta_{1,\\text{A}}^{(1)} = \\frac{\\frac{3}{4} \\cdot 1 + \\frac{1}{4} \\cdot 0}{1} = \\frac{3}{4}$\n  - $\\theta_{1,\\text{C}}^{(1)} = 0$\n  - $\\theta_{1,\\text{G}}^{(1)} = \\frac{\\frac{3}{4} \\cdot 0 + \\frac{1}{4} \\cdot 1}{1} = \\frac{1}{4}$\n  - $\\theta_{1,\\text{T}}^{(1)} = 0$\n  (在手动计算中，分母是所有碱基的期望计数之和：($\\frac{3}{4}$ for A) + 0 + ($\\frac{1}{4}$ for G) + 0 = 1)\n\n  对于基序位置 $j=2$：\n  - $\\theta_{2,\\text{A}}^{(1)} = 0$\n  - $\\theta_{2,\\text{C}}^{(1)} = \\frac{\\frac{3}{4} \\cdot 1 + \\frac{1}{4} \\cdot 0}{1} = \\frac{3}{4}$\n  - $\\theta_{2,\\text{G}}^{(1)} = 0$\n  - $\\theta_{2,\\text{T}}^{(1)} = \\frac{\\frac{3}{4} \\cdot 0 + \\frac{1}{4} \\cdot 1}{1} = \\frac{1}{4}$\n  (同样，分母为 1)\n\n一次完整迭代后的参数为 $\\Theta^{(1)} = (\\pi^{(1)}, \\theta^{(1)})$。\n\n**第 2 次迭代：E-步骤**\n\n问题要求的是后验概率 $\\Pr(Z=1 \\mid X; \\Theta^{(1)})$，这正是在第二个 E-步骤中计算的响应度 $\\gamma_1^{(1)}$。我们使用更新后的参数 $\\pi^{(1)}$ 和 $\\theta^{(1)}$。\n\n首先，我们用 $\\theta^{(1)}$ 重新计算似然：\n- 如果 $Z=1$：\n  $$ \\Pr(X \\mid Z=1; \\theta^{(1)}) = (\\theta^{(1)}_{1,\\text{A}} \\cdot \\theta^{(1)}_{2,\\text{C}}) \\cdot (b_{\\text{G}} \\cdot b_{\\text{T}}) = \\left(\\frac{3}{4} \\cdot \\frac{3}{4}\\right) \\cdot \\left(\\frac{1}{4} \\cdot \\frac{1}{4}\\right) = \\frac{9}{16} \\cdot \\frac{1}{16} = \\frac{9}{256} $$\n- 如果 $Z=2$：\n  $$ \\Pr(X \\mid Z=2; \\theta^{(1)}) = (\\theta^{(1)}_{1,\\text{G}} \\cdot \\theta^{(1)}_{2,\\text{T}}) \\cdot (b_{\\text{A}} \\cdot b_{\\text{C}}) = \\left(\\frac{1}{4} \\cdot \\frac{1}{4}\\right) \\cdot \\left(\\frac{1}{4} \\cdot \\frac{1}{4}\\right) = \\frac{1}{16} \\cdot \\frac{1}{16} = \\frac{1}{256} $$\n\n接下来，我们使用 $\\pi^{(1)}$ 计算联合概率：\n- $\\Pr(X, Z=1; \\Theta^{(1)}) = \\pi^{(1)}_1 \\Pr(X \\mid Z=1; \\theta^{(1)}) = \\frac{3}{4} \\cdot \\frac{9}{256} = \\frac{27}{1024}$\n- $\\Pr(X, Z=2; \\Theta^{(1)}) = \\pi^{(1)}_2 \\Pr(X \\mid Z=2; \\theta^{(1)}) = \\frac{1}{4} \\cdot \\frac{1}{256} = \\frac{1}{1024}$\n\n新的边际似然为：\n- $\\Pr(X; \\Theta^{(1)}) = \\frac{27}{1024} + \\frac{1}{1024} = \\frac{28}{1024}$\n\n最后，新的响应度 $\\gamma_z^{(1)}$ 为：\n- $\\gamma_1^{(1)} = \\Pr(Z=1 \\mid X; \\Theta^{(1)}) = \\frac{27/1024}{28/1024} = \\frac{27}{28}$\n- $\\gamma_2^{(1)} = \\Pr(Z=2 \\mid X; \\Theta^{(1)}) = \\frac{1/1024}{28/1024} = \\frac{1}{28}$\n\n基序起始于位置 $1–2$ 的后验概率是 $\\gamma_1^{(1)} = \\frac{27}{28}$。将其转换为小数并四舍五入到四位有效数字：\n$$ \\frac{27}{28} \\approx 0.9642857... \\approx 0.9643 $$", "answer": "$$\\boxed{0.9643}$$", "id": "2388823"}, {"introduction": "本练习将EM算法的应用范围扩展到一类不同的挑战：处理生存分析中的删失数据（censored data）。您将为一个假设的患者生存时间研究，推导并实现EM算法来估计事件发生率。这个实践不仅展示了EM框架的灵活性，也锻炼了您从第一性原理推导更新规则的能力，这对于将算法应用于新问题至关重要 [@problem_id:2388747]。", "problem": "考虑独立的患者生存时间，其模型如下。每个患者的生存时间是一个随机变量 $T_i$，独立地从具有恒定风险率 $\\lambda$（单位为天的倒数）的指数分布中抽取，其概率密度函数为 $f(t \\mid \\lambda) = \\lambda e^{-\\lambda t}$（当 $t \\ge 0$），生存函数为 $S(t \\mid \\lambda) = e^{-\\lambda t}$。右删失是无信息且独立的：对于某些患者，研究在事件发生前结束，因此我们只观察到一个删失时间 $c_i$，并且知道 $T_i \\ge c_i$。对于每个患者，我们观察到一个时间 $x_i$ 和一个事件指示符 $\\delta_i$，其中 $x_i = \\min(T_i, c_i)$，如果观察到事件则 $\\delta_i = 1$，如果观察值被右删失则 $\\delta_i = 0$。所有时间单位均为天，$\\lambda$ 必须以天的倒数表示。\n\n您的任务是设计并实现期望最大化（EM）算法，该算法将被删失患者的未观察到失效时间视为潜变量，并估计指数率参数 $\\lambda$。请仅从上述基本定义、独立性假设和条件期望的定义出发。不要调用直接给出 EM 算法更新步骤的现成公式。\n\n需要推导和实现的EM过程规范如下：\n- 期望最大化（EM）算法应在以下两者之间交替进行：计算在给定观测数据和当前参数的情况下，完全数据对数似然的条件期望；以及关于 $\\lambda$ 最大化该期望。\n- 从一个严格正值 $\\lambda^{(0)}$（单位为天的倒数）开始初始化。\n- 迭代直至 $\\lambda$ 的绝对变化小于容差 $\\varepsilon$ 或达到最大迭代次数 $K_{\\max}$。\n- 返回最终估计值 $\\widehat{\\lambda}$，单位为天的倒数。\n\n测试套件。您的程序必须对以下三个测试用例运行EM算法。对于每个用例，$x$ 是观测时间列表（单位为天），$\\delta$ 是事件指示符列表，$\\lambda^{(0)}$ 是初始值（单位为天的倒数），$\\varepsilon$ 是容差，$K_{\\max}$ 是最大迭代次数。\n\n- 用例 $1$（混合删失，一般情况）：\n  - $x^{(1)} = [\\,5,\\,12,\\,9,\\,3,\\,15,\\,7,\\,20,\\,4,\\,11,\\,8\\,]$\n  - $\\delta^{(1)} = [\\,1,\\,0,\\,1,\\,1,\\,0,\\,1,\\,0,\\,1,\\,1,\\,0\\,]$\n  - $\\lambda^{(0)}_{(1)} = 0.1$, $\\varepsilon_{(1)} = 10^{-12}$, $K_{\\max,(1)} = 100000$\n\n- 用例 $2$（无删失，边界条件）：\n  - $x^{(2)} = [\\,1,\\,2,\\,3,\\,4,\\,5\\,]$\n  - $\\delta^{(2)} = [\\,1,\\,1,\\,1,\\,1,\\,1\\,]$\n  - $\\lambda^{(0)}_{(2)} = 0.25$, $\\varepsilon_{(2)} = 10^{-12}$, $K_{\\max,(2)} = 100000$\n\n- 用例 $3$（重度删失，边缘情况）：\n  - $x^{(3)} = [\\,10,\\,10,\\,10,\\,2,\\,10,\\,10\\,]$\n  - $\\delta^{(3)} = [\\,0,\\,0,\\,0,\\,1,\\,0,\\,0\\,]$\n  - $\\lambda^{(0)}_{(3)} = 0.05$, $\\varepsilon_{(3)} = 10^{-12}$, $K_{\\max,(3)} = 100000$\n\n最终输出格式。您的程序应生成单行输出，其中包含三个最终估计值，以十进制浮点数形式表示（单位为天的倒数），每个值四舍五入到小数点后恰好六位，并聚合为一个包含在方括号中的逗号分隔列表。例如，输出必须类似于 $[a,b,c]$，其中 $a$、$b$ 和 $c$ 分别是用例 1、2 和 3 的三个四舍五入后的估计值（不含多余的空格、单位或附加文本）。", "solution": "所陈述的问题在科学上是合理的、内容是自包含的、并且是适定的。它描述了在带有右删失数据的生存模型中，使用期望最大化（EM）算法进行参数估计的一个标准应用，这是生物统计学中的一个常见任务。该问题是有效的，我将着手解决它。\n\n目标是推导并实现EM算法，以找到指数分布率参数 $\\lambda$ 的最大似然估计（MLE），其中一些生存时间观测值是右删失的。该算法必须从基本原理推导得出，将删失观测的未知真实生存时间视为潜变量。\n\n设完全数据为真实、独立同分布的生存时间集合 $\\mathbf{T} = \\{T_1, T_2, \\ldots, T_n\\}$，其中每个 $T_i \\sim \\text{Exponential}(\\lambda)$。其概率密度函数（PDF）为 $f(t | \\lambda) = \\lambda e^{-\\lambda t}$（当 $t \\ge 0$ 时）。完全数据对数似然函数 $\\ell_c(\\lambda; \\mathbf{T})$ 由下式给出：\n$$ \\ell_c(\\lambda; \\mathbf{T}) = \\log \\left( \\prod_{i=1}^{n} f(T_i | \\lambda) \\right) = \\log \\left( \\prod_{i=1}^{n} \\lambda e^{-\\lambda T_i} \\right) = \\sum_{i=1}^{n} (\\log \\lambda - \\lambda T_i) = n \\log \\lambda - \\lambda \\sum_{i=1}^{n} T_i $$\n观测数据由数据对 $\\mathbf{Y}_{\\text{obs}} = \\{(x_i, \\delta_i)\\}_{i=1}^n$ 组成，其中 $x_i$ 是观测时间，$\\delta_i$ 是事件指示符。如果 $\\delta_i=1$，则事件被观测到，真实生存时间 $T_i$ 已知为 $x_i$。如果 $\\delta_i=0$，则观测值被删失，真实生存时间 $T_i$ 仅可知大于 $x_i$。因此，未观测到的（潜）变量是所有被删失个体的确切生存时间 $T_i$。\n\nEM算法是一个迭代过程，包括两个步骤：期望（E）步骤和最大化（M）步骤。\n\n**E步：期望**\n在第 $(k+1)$ 次迭代中，E步计算在给定观测数据 $\\mathbf{Y}_{\\text{obs}}$ 和当前参数估计 $\\lambda^{(k)}$ 的条件下，完全数据对数似然的期望。这就是 $Q$ 函数。\n$$ Q(\\lambda | \\lambda^{(k)}) = E_{\\mathbf{T} | \\mathbf{Y}_{\\text{obs}}, \\lambda^{(k)}}[\\ell_c(\\lambda; \\mathbf{T})] $$\n代入 $\\ell_c(\\lambda; \\mathbf{T})$ 的表达式：\n$$ Q(\\lambda | \\lambda^{(k)}) = E_{\\mathbf{T} | \\mathbf{Y}_{\\text{obs}}, \\lambda^{(k)}} \\left[ n \\log \\lambda - \\lambda \\sum_{i=1}^{n} T_i \\right] $$\n根据期望的线性性质，这变为：\n$$ Q(\\lambda | \\lambda^{(k)}) = n \\log \\lambda - \\lambda \\, E \\left[ \\sum_{i=1}^{n} T_i \\mid \\mathbf{Y}_{\\text{obs}}, \\lambda^{(k)} \\right] = n \\log \\lambda - \\lambda \\sum_{i=1}^{n} E[T_i | (x_i, \\delta_i), \\lambda^{(k)}] $$\n我们必须根据每个观测的状态 $\\delta_i$ 来评估其条件期望 $E[T_i | (x_i, \\delta_i), \\lambda^{(k)}]$：\n\n1.  对于未删失的观测（$\\delta_i=1$），真实生存时间是已知的：$T_i = x_i$。因此，期望就是观测值本身：\n    $$ E[T_i | (x_i, \\delta_i=1), \\lambda^{(k)}] = x_i $$\n\n2.  对于删失的观测（$\\delta_i=0$），我们只知道 $T_i > x_i$。条件期望是 $E[T_i | T_i > x_i, \\lambda^{(k)}]$。我们从条件期望的定义推导这个值。在 $T_i > x_i$ 的条件下，$T_i$ 的条件概率密度函数是：\n    $$ f(t | T_i > x_i, \\lambda^{(k)}) = \\frac{f(t | \\lambda^{(k)})}{P(T_i > x_i | \\lambda^{(k)})} = \\frac{\\lambda^{(k)} e^{-\\lambda^{(k)} t}}{e^{-\\lambda^{(k)} x_i}} = \\lambda^{(k)} e^{-\\lambda^{(k)}(t - x_i)} \\quad \\text{for } t > x_i $$\n    那么条件期望是：\n    $$ E[T_i | T_i > x_i, \\lambda^{(k)}] = \\int_{x_i}^{\\infty} t \\cdot \\lambda^{(k)} e^{-\\lambda^{(k)}(t - x_i)} \\, dt $$\n    使用换元法，令 $u = t - x_i$（因此 $t = u + x_i$ 且 $dt = du$）：\n    $$ = \\int_{0}^{\\infty} (u + x_i) \\lambda^{(k)} e^{-\\lambda^{(k)} u} \\, du = \\int_{0}^{\\infty} u \\lambda^{(k)} e^{-\\lambda^{(k)} u} \\, du + x_i \\int_{0}^{\\infty} \\lambda^{(k)} e^{-\\lambda^{(k)} u} \\, du $$\n    第一个积分是速率为 $\\lambda^{(k)}$ 的指数随机变量的期望，即 $1/\\lambda^{(k)}$。第二个积分是 $x_i$ 乘以一个概率密度函数在其支撑集上的积分，结果为 $1$。这验证了由无记忆性得出的结果。\n    $$ E[T_i | T_i > x_i, \\lambda^{(k)}] = \\frac{1}{\\lambda^{(k)}} + x_i $$\n\n结合这两种情况，期望总和变为：\n$$ \\sum_{i=1}^{n} E[T_i | (x_i, \\delta_i), \\lambda^{(k)}] = \\sum_{i: \\delta_i=1} x_i + \\sum_{i: \\delta_i=0} \\left(x_i + \\frac{1}{\\lambda^{(k)}}\\right) $$\n令 $n_c = \\sum_{i=1}^n (1-\\delta_i)$ 为删失观测的数量。该表达式简化为：\n$$ \\sum_{i=1}^{n} E[T_i | \\dots] = \\sum_{i=1}^{n} x_i + \\frac{n_c}{\\lambda^{(k)}} $$\n因此，$Q$ 函数为：\n$$ Q(\\lambda | \\lambda^{(k)}) = n \\log \\lambda - \\lambda \\left( \\sum_{i=1}^{n} x_i + \\frac{n_c}{\\lambda^{(k)}} \\right) $$\n\n**M步：最大化**\nM步通过关于 $\\lambda$ 最大化函数 $Q(\\lambda | \\lambda^{(k)})$ 来找到更新后的参数估计 $\\lambda^{(k+1)}$。我们将 $Q$ 对 $\\lambda$ 求导，并令导数等于零：\n$$ \\frac{\\partial Q(\\lambda | \\lambda^{(k)})}{\\partial \\lambda} = \\frac{n}{\\lambda} - \\left( \\sum_{i=1}^{n} x_i + \\frac{n_c}{\\lambda^{(k)}} \\right) = 0 $$\n求解 $\\lambda$ 即可得到 $\\lambda^{(k+1)}$ 的更新规则：\n$$ \\frac{n}{\\lambda^{(k+1)}} = \\sum_{i=1}^{n} x_i + \\frac{n_c}{\\lambda^{(k)}} \\implies \\lambda^{(k+1)} = \\frac{n}{\\sum_{i=1}^{n} x_i + \\frac{n_c}{\\lambda^{(k)}}} $$\n\n**迭代算法**\nEM算法按以下步骤进行：\n1.  用一个起始值 $\\lambda^{(0)} > 0$ 进行初始化。\n2.  对于 $k = 0, 1, 2, \\ldots$：使用推导出的更新规则计算下一个估计值：\n    $$ \\lambda^{(k+1)} = \\frac{n}{\\sum_{i=1}^{n} x_i + \\frac{\\sum_{i=1}^n (1-\\delta_i)}{\\lambda^{(k)}}} $$\n3.  当绝对差 $|\\lambda^{(k+1)} - \\lambda^{(k)}|$ 小于指定的容差 $\\varepsilon$ 时，或在达到最大迭代次数 $K_{\\max}$ 后终止。最终的值即为最大似然估计 $\\widehat{\\lambda}$。\n可以验证，此迭代的不动点 $\\lambda^*$ 满足 $\\lambda^* = n / (\\sum x_i + n_c/\\lambda^*)$，这可以简化为 $\\lambda^* = (\\sum \\delta_i) / (\\sum x_i)$，即该问题的正确闭式最大似然估计。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef em_survival_exponential(x: list[float], \n                            delta: list[int], \n                            lambda0: float, \n                            epsilon: float, \n                            k_max: int) -> float:\n    \"\"\"\n    Estimates the rate parameter lambda of an exponential distribution with\n    right-censored data using the Expectation-Maximization (EM) algorithm.\n\n    Args:\n        x: A list of observed times (event or censoring times) in days.\n        delta: A list of event indicators (1 for event, 0 for censored).\n        lambda0: The initial guess for the rate parameter lambda (in reciprocal days).\n        epsilon: The tolerance for convergence.\n        k_max: The maximum number of iterations.\n\n    Returns:\n        The final estimate of the rate parameter lambda.\n    \"\"\"\n    x_np = np.array(x, dtype=float)\n    delta_np = np.array(delta, dtype=int)\n    \n    n = len(x_np)\n    if n == 0:\n        return np.nan\n\n    # Pre-compute fixed quantities\n    sum_x = np.sum(x_np)\n    # Number of censored observations\n    n_c = n - np.sum(delta_np)\n    \n    lambda_current = lambda0\n    \n    for _ in range(k_max):\n        # A check to prevent division by zero if lambda becomes non-positive,\n        # which can happen with pathological inputs, though not for these test cases.\n        if lambda_current <= 0:\n            # A strictly positive rate is required.\n            # Returning NaN indicates failure to converge to a valid estimate.\n            return np.nan\n        \n        # M-step: update lambda based on the Q-function maximization\n        # which involves the expected sum of true survival times from the E-step.\n        # Expected sum of T_i = sum(x_i) + n_c * (1 / lambda_current)\n        lambda_next = n / (sum_x + n_c / lambda_current)\n        \n        # Check for convergence\n        if np.abs(lambda_next - lambda_current) < epsilon:\n            return lambda_next\n        \n        lambda_current = lambda_next\n        \n    return lambda_current\n\ndef solve():\n    \"\"\"\n    Runs the EM algorithm on the specified test cases and prints the results.\n    \"\"\"\n    test_cases = [\n        {\n            \"x\": [5.0, 12.0, 9.0, 3.0, 15.0, 7.0, 20.0, 4.0, 11.0, 8.0],\n            \"delta\": [1, 0, 1, 1, 0, 1, 0, 1, 1, 0],\n            \"lambda0\": 0.1,\n            \"epsilon\": 1e-12,\n            \"k_max\": 100000\n        },\n        {\n            \"x\": [1.0, 2.0, 3.0, 4.0, 5.0],\n            \"delta\": [1, 1, 1, 1, 1],\n            \"lambda0\": 0.25,\n            \"epsilon\": 1e-12,\n            \"k_max\": 100000\n        },\n        {\n            \"x\": [10.0, 10.0, 10.0, 2.0, 10.0, 10.0],\n            \"delta\": [0, 0, 0, 1, 0, 0],\n            \"lambda0\": 0.05,\n            \"epsilon\": 1e-12,\n            \"k_max\": 100000\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        lambda_hat = em_survival_exponential(\n            case[\"x\"], case[\"delta\"], case[\"lambda0\"], case[\"epsilon\"], case[\"k_max\"]\n        )\n        results.append(f\"{lambda_hat:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2388747"}]}