{"hands_on_practices": [{"introduction": "理论与实践相结合的最佳方式莫过于亲手构建一个模型来解决经典问题。本练习将指导您使用图神经网络 (GNN) 的基本原理，为药物研发中的一个核心概念——“类药性”——创建一个评分函数。您将基于著名的里宾斯基“五规则” (Lipinski's rule of five) 来设计一个能够精确计算分子属性的 GNN，这个过程将揭示 GNN 架构如何与分子属性的内在可加性（additive properties）深刻关联。通过这个练习，您不仅将掌握 GNN 的基本操作，还将体会到如何根据第一性原理（first principles）来定制化模型，以满足特定的预测需求。", "problem": "要求您根据 Lipinski 五规则，仅使用第一性原理定义和广为接受的事实，将一个基于原则的、具有置换不变性的图神经网络（GNN）程序形式化，用于评估分子的“类药性”。您必须生成一个完整的程序来实现您的设计，并在提供的测试集上对其进行评估。\n\n从以下基本基础开始：\n- 一个分子可以被建模为一个无向图，其邻接矩阵为 $A \\in \\{0,1\\}^{n \\times n}$，节点特征为 $X \\in \\mathbb{R}^{n \\times d}$，其中 $n$ 是原子（节点）的数量， $d$ 是特征维度。\n- 一个带消息传递的图神经网络（GNN）使用置换不变的聚合来获得图级表示。求和聚合对节点排序具有不变性。\n- Lipinski 五规则指出，口服类药分子通常满足四个约束条件：分子量 $\\leq 500$（单位 $\\mathrm{g/mol}$）、辛醇-水分配系数 $\\log P \\leq 5$（无单位）、氢键供体数量 $\\leq 5$（无量纲计数）以及氢键受体数量 $\\leq 10$（无量纲计数）。这些是经验性启发规则，并为软满足度分数提供了一个合理的目标。\n\n您的任务：\n1. 将每个分子建模为一个具有邻接矩阵 $A$ 和节点特征 $X$ 的图，其中每个节点特征向量按顺序包含四个分量：\n   - 每个原子对分子量的贡献（单位 $\\mathrm{g/mol}$），\n   - 每个原子对 $\\log P$ 的贡献（无单位，遵循简化的片段加和近似法），\n   - 每个原子的氢键供体指示符（$0$ 或 $1$），\n   - 每个原子的氢键受体指示符（$0$ 或 $1$）。\n   四个全局分子属性是相应分量在所有节点上的总和。\n2. 设计一个单层消息传递图神经网络（GNN），该网络具有置换不变性，并通过求和池化生成图级嵌入。使用线性消息传递更新和求和池化，以便可以通过一个合适的线性读出层从节点级贡献中精确恢复可加和的图级属性。\n3. 根据预测的属性，使用按每个规则阈值归一化的铰链式惩罚，定义一个可微的软满足度分数 $s \\in [0,1]$。令 $\\phi(z) = \\max(0,z)$ 表示整流线性单元。定义四个归一化的违规值\n   $$v_{\\mathrm{MW}} = \\phi\\left(\\frac{\\mathrm{MW} - 500}{500}\\right), \\quad v_{\\log P} = \\phi\\left(\\frac{\\log P - 5}{5}\\right), \\quad v_{\\mathrm{HBD}} = \\phi\\left(\\frac{\\mathrm{HBD} - 5}{5}\\right), \\quad v_{\\mathrm{HBA}} = \\phi\\left(\\frac{\\mathrm{HBA} - 10}{10}\\right)。$$\n   然后定义\n   $$s = \\mathrm{clip}\\left(1 - \\frac{v_{\\mathrm{MW}} + v_{\\log P} + v_{\\mathrm{HBD}} + v_{\\mathrm{HBA}}}{4}, \\, 0, \\, 1\\right),$$\n   其中 $\\mathrm{MW}$ 的单位是 $\\mathrm{g/mol}$， $\\log P$ 无单位， $\\mathrm{HBD}$ 和 $\\mathrm{HBA}$ 是无量纲计数。最终分数 $s$ 无单位。clip 操作是逐元素裁剪到区间 $[0,1]$ 内。\n4. 将此过程实现为一个完整的、可运行的程序，并在下面的测试集上对其进行评估。最终程序必须打印每个测试用例的分数，四舍五入到三位小数。\n\n测试集：\n每个分子由 $(A, X)$ 表示，其中 $A$ 是邻接矩阵， $X$ 是节点特征矩阵，其列的顺序如上所述。\n\n- 案例 1（典型的类药分子，所有约束条件均远在限制范围内）：\n  $$A_1 = \\begin{bmatrix}\n  0 & 1 & 0 & 0 & 0 \\\\\n  1 & 0 & 1 & 0 & 0 \\\\\n  0 & 1 & 0 & 1 & 0 \\\\\n  0 & 0 & 1 & 0 & 1 \\\\\n  0 & 0 & 0 & 1 & 0\n  \\end{bmatrix}, \\quad\n  X_1 = \\begin{bmatrix}\n  60 & 0.4 & 0 & 1 \\\\\n  80 & 0.6 & 0 & 2 \\\\\n  100 & 0.8 & 1 & 1 \\\\\n  55 & 0.5 & 0 & 1 \\\\\n  55 & 0.5 & 0 & 1\n  \\end{bmatrix}。$$\n\n- 案例 2（边界情况：恰好在所有阈值上）：\n  $$A_2 = \\begin{bmatrix}\n  0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\\\\n  1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n  0 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n  0 & 0 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n  0 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n  0 & 0 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 0 \\\\\n  0 & 0 & 0 & 0 & 0 & 1 & 0 & 1 & 0 & 0 \\\\\n  0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 1 & 0 \\\\\n  0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 1 \\\\\n  1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0\n  \\end{bmatrix}, \\quad\n  X_2 = \\begin{bmatrix}\n  50 & 0.5 & 1 & 1 \\\\\n  50 & 0.5 & 1 & 1 \\\\\n  50 & 0.5 & 1 & 1 \\\\\n  50 & 0.5 & 1 & 1 \\\\\n  50 & 0.5 & 1 & 1 \\\\\n  50 & 0.5 & 0 & 1 \\\\\n  50 & 0.5 & 0 & 1 \\\\\n  50 & 0.5 & 0 & 1 \\\\\n  50 & 0.5 & 0 & 1 \\\\\n  50 & 0.5 & 0 & 1\n  \\end{bmatrix}。$$\n\n- 案例 3（中度违反两个规则：分子量和 $\\log P$）：\n  $$A_3 = \\begin{bmatrix}\n  0 & 1 & 0 & 0 & 0 & 0 \\\\\n  1 & 0 & 1 & 0 & 1 & 0 \\\\\n  0 & 1 & 0 & 1 & 0 & 0 \\\\\n  0 & 0 & 1 & 0 & 1 & 0 \\\\\n  0 & 1 & 0 & 1 & 0 & 1 \\\\\n  0 & 0 & 0 & 0 & 1 & 0\n  \\end{bmatrix}, \\quad\n  X_3 = \\begin{bmatrix}\n  100 & 0.9 & 0 & 1 \\\\\n  120 & 1.2 & 0 & 2 \\\\\n  130 & 1.4 & 1 & 2 \\\\\n  90 & 1.0 & 0 & 2 \\\\\n  80 & 0.8 & 1 & 1 \\\\\n  100 & 1.1 & 0 & 1\n  \\end{bmatrix}。$$\n\n- 案例 4（非常小的、类似水分子的分子，轻易满足所有规则）：\n  $$A_4 = \\begin{bmatrix} 0 \\end{bmatrix}, \\quad\n  X_4 = \\begin{bmatrix} 18 & -0.4 & 2 & 1 \\end{bmatrix}。$$\n\n您的程序应按规定实现基于 GNN 的计算，为每个 $(A, X)$ 评估软类药性分数 $s$，并生成单行输出，其中包含一个用方括号括起来的、以逗号分隔的分数列表，顺序为 $[ \\text{案例 }1, \\text{案例 }2, \\text{案例 }3, \\text{案例 }4 ]$，每个分数都四舍五入到三位小数（无单位），例如 `[0.123,0.456,0.789,1.000]`。", "solution": "问题陈述经验证。\n\n**步骤 1：提取已知条件**\n- **分子模型**：一个无向图，其邻接矩阵为 $A \\in \\{0,1\\}^{n \\times n}$，节点特征为 $X \\in \\mathbb{R}^{n \\times d}$。\n- **节点特征**：对于每个节点（原子），特征向量有 $d=4$ 个分量：（1）每个原子的分子量贡献（$\\mathrm{g/mol}$），（2）每个原子的 $\\log P$ 贡献（无单位），（3）每个原子的氢键供体（HBD）指示符（$0$ 或 $1$），以及（4）每个原子的氢键受体（HBA）指示符（$0$ 或 $1$）。\n- **全局属性**：四个全局分子属性（$\\mathrm{MW}$、$\\log P$、$\\mathrm{HBD}$、$\\mathrm{HBA}$）是所有节点上相应特征分量的总和。\n- **Lipinski 五规则阈值**：$\\mathrm{MW} \\leq 500$，$\\log P \\leq 5$，$\\mathrm{HBD} \\leq 5$，$\\mathrm{HBA} \\leq 10$。\n- **GNN 架构**：一个单层消息传递 GNN，具有置换不变性，使用求和池化，并通过线性读出层允许精确恢复可加和的全局属性。\n- **软分数定义**：\n    - 整流线性单元：$\\phi(z) = \\max(0,z)$。\n    - 归一化违规值：\n        - $v_{\\mathrm{MW}} = \\phi\\left(\\frac{\\mathrm{MW} - 500}{500}\\right)$\n        - $v_{\\log P} = \\phi\\left(\\frac{\\log P - 5}{5}\\right)$\n        - $v_{\\mathrm{HBD}} = \\phi\\left(\\frac{\\mathrm{HBD} - 5}{5}\\right)$\n        - $v_{\\mathrm{HBA}} = \\phi\\left(\\frac{\\mathrm{HBA} - 10}{10}\\right)$\n    - 最终分数：$s = \\mathrm{clip}\\left(1 - \\frac{v_{\\mathrm{MW}} + v_{\\log P} + v_{\\mathrm{HBD}} + v_{\\mathrm{HBA}}}{4}, \\, 0, \\, 1\\right)$。\n- **测试集**：由邻接矩阵 $A_k$ 和节点特征矩阵 $X_k$（$k \\in \\{1, 2, 3, 4\\}$）指定的四个测试用例。\n- **输出格式**：单行输出，包含一个用方括号括起来的、以逗号分隔的四个案例的分数列表，每个分数四舍五入到三位小数。\n\n**步骤 2：使用提取的已知条件进行验证**\n该问题具有科学依据、提法恰当且客观。它基于图神经网络的标准原理和化学信息学中的既定启发式方法（Lipinski 规则）。所有定义、数据和约束条件都已提供，使得问题自洽且无矛盾。整体设定是形式化且清晰明确的。\n\n**步骤 3：结论与行动**\n该问题被判定为**有效**。将提供解决方案。\n\n**原则性解决方案**\n\n任务是设计一个基于 GNN 的程序来计算类药性分数。让我们按照问题中概述的步骤逐一进行。\n\n**1. 分子属性计算**\n一个分子由一个有 $n$ 个节点和节点特征 $X \\in \\mathbb{R}^{n \\times 4}$ 的图表示。$X$ 的第 $i$ 行，表示为 $X_i$，是第 $i$ 个原子的特征向量：$X_i = [x_{i, \\mathrm{MW}}, x_{i, \\log P}, x_{i, \\mathrm{HBD}}, x_{i, \\mathrm{HBA}}]$。问题陈述指出全局分子属性是可加和的。这意味着它们是通过将所有原子的相应特征相加来计算的：\n$$ \\mathrm{MW} = \\sum_{i=1}^{n} x_{i, \\mathrm{MW}}, \\quad \\log P = \\sum_{i=1}^{n} x_{i, \\log P}, \\quad \\mathrm{HBD} = \\sum_{i=1}^{n} x_{i, \\mathrm{HBD}}, \\quad \\mathrm{HBA} = \\sum_{i=1}^{n} x_{i, \\mathrm{HBA}} $$\n令 $\\mathbf{p} \\in \\mathbb{R}^4$ 为这四个属性的向量。该向量可以通过对输入特征矩阵 $X$ 的各列求和来直接计算：\n$$ \\mathbf{p} = \\left[ \\sum_{i=1}^{n} X_{i,1}, \\sum_{i=1}^{n} X_{i,2}, \\sum_{i=1}^{n} X_{i,3}, \\sum_{i=1}^{n} X_{i,4} \\right]^T = \\sum_{i=1}^n X_i^T = X^T \\mathbf{1} $$\n其中 $\\mathbf{1}$ 是一个包含 $n$ 个 1 的列向量。\n\n**2. GNN 设计**\n我们必须设计一个单层消息传递 GNN，它能生成一个图级嵌入 $h_G$，并且可以从 $h_G$ 通过线性读出层精确恢复属性向量 $\\mathbf{p}$。令 $H^{(0)} = X$ 为初始节点特征。一个单一的线性消息传递层按如下方式更新节点 $i$ 的特征：\n$$ H_i^{(1)} = W_{self} H_i^{(0)} + W_{neigh} \\sum_{j \\in \\mathcal{N}(i)} H_j^{(0)} $$\n其中 $H_i^{(l)}$ 是第 $l$ 层节点 $i$ 的特征向量， $W_{self}, W_{neigh} \\in \\mathbb{R}^{d \\times d}$ 是可学习的权重矩阵。求和是对节点 $i$ 的邻居 $\\mathcal{N}(i)$ 进行的。\n\n图级嵌入 $h_G$ 是通过对最终的节点嵌入进行求和池化得到的：\n$$ h_G = \\sum_{i=1}^n H_i^{(1)} $$\n代入更新规则：\n$$ h_G = \\sum_{i=1}^n \\left( W_{self} H_i^{(0)} + W_{neigh} \\sum_{j \\in \\mathcal{N}(i)} H_j^{(0)} \\right) = W_{self} \\left(\\sum_{i=1}^n H_i^{(0)}\\right) + W_{neigh} \\left(\\sum_{i=1}^n \\sum_{j \\in \\mathcal{N}(i)} H_j^{(0)}\\right) $$\n第一项是 $W_{self} \\sum_i X_i$。第二项取决于图的连接结构（邻接矩阵 $A$）。令 $d_j = |\\mathcal{N}(j)|$ 为节点 $j$ 的度。第二项可以重写为 $\\sum_{j=1}^n d_j H_j^{(0)}$。因此：\n$$ h_G = W_{self} \\sum_{i=1}^n X_i + W_{neigh} \\sum_{j=1}^n d_j X_j $$\n问题要求属性向量 $\\mathbf{p} = \\sum_i X_i$ 能够对于任意图都通过一个线性读出层 $W_{readout} \\in \\mathbb{R}^{4 \\times d}$ 从 $h_G$ 中恢复出来。即，$W_{readout} h_G = \\sum_i X_i$。\n$$ W_{readout} \\left( W_{self} \\sum_{i=1}^n X_i + W_{neigh} \\sum_{j=1}^n d_j X_j \\right) = \\sum_{i=1}^n X_i $$\n为了使此等式对任意图（具有变化的度 $d_j$）和任意特征矩阵 $X$ 都成立，涉及度的项必须消失。这仅在 $W_{neigh} = 0$ 时才可能。这意味着来自邻居节点的信息（即消息传递）必须被置零，以保证纯粹可加和属性的精确恢复。对于这个特定任务，邻接矩阵 $A$ 变得无关紧要。\n\n当 $W_{neigh} = 0$ 时，方程简化为 $W_{readout} W_{self} \\sum_i X_i = \\sum_i X_i$。这要求 $W_{readout} W_{self} = I$，其中 $I$ 是单位矩阵。满足此条件的最简单选择是将 $W_{self}$ 和 $W_{readout}$ 都设置为 $4 \\times 4$ 的单位矩阵 $I_4$。\n\n因此，这个“GNN”程序简化为：\n1.  节点更新：$H^{(1)}_i = I_4 H^{(0)}_i = X_i$。（特征未经改变地传递）。\n2.  求和池化：$h_G = \\sum_i H^{(1)}_i = \\sum_i X_i$。\n3.  线性读出：$\\mathbf{p} = I_4 h_G = h_G$。\n\n得到的图级嵌入 $h_G$ 正是全局属性向量 $\\mathbf{p}$。这个形式满足了所有约束：它是一个单层 GNN（尽管是平凡的），由于求和池化而具有置换不变性，并且允许精确恢复可加和属性。\n\n**3. 软满足度分数计算**\n给定属性向量 $\\mathbf{p} = [\\mathrm{MW}, \\log P, \\mathrm{HBD}, \\mathrm{HBA}]^T$，我们计算类药性分数 $s$。阈值为 $\\mathbf{t} = [500, 5, 5, 10]^T$。\n归一化的违规值为：\n$v_{\\mathrm{MW}} = \\max\\left(0, \\frac{\\mathrm{MW} - 500}{500}\\right)$\n$v_{\\log P} = \\max\\left(0, \\frac{\\log P - 5}{5}\\right)$\n$v_{\\mathrm{HBD}} = \\max\\left(0, \\frac{\\mathrm{HBD} - 5}{5}\\right)$\n$v_{\\mathrm{HBA}} = \\max\\left(0, \\frac{\\mathrm{HBA} - 10}{10}\\right)$\n最终分数由以下公式给出：\n$s = \\max\\left(0, \\min\\left(1, 1 - \\frac{v_{\\mathrm{MW}} + v_{\\log P} + v_{\\mathrm{HBD}} + v_{\\mathrm{HBA}}}{4}\\right)\\right)$\n\n**4. 在测试集上评估**\n\n我们现在将此程序应用于提供的测试用例。\n\n- **案例 1**：\n  $X_1$ 有 5 行。$\\mathbf{p}_1 = \\sum_i X_{1,i}^T = [350, 2.8, 1, 6]^T$。\n  所有属性都在其阈值范围内。\n  $v_{\\mathrm{MW}}=v_{\\log P}=v_{\\mathrm{HBD}}=v_{\\mathrm{HBA}} = 0$。\n  $s_1 = \\mathrm{clip}(1 - 0/4, 0, 1) = 1.0$。\n\n- **案例 2**：\n  $X_2$ 有 10 行。$\\mathbf{p}_2 = \\sum_i X_{2,i}^T = [500, 5.0, 5, 10]^T$。\n  所有属性都恰好在其阈值上。\n  $v_{\\mathrm{MW}} = \\max(0, \\frac{500-500}{500})=0$。\n  $v_{\\log P} = \\max(0, \\frac{5-5}{5})=0$。\n  $v_{\\mathrm{HBD}} = \\max(0, \\frac{5-5}{5})=0$。\n  $v_{\\mathrm{HBA}} = \\max(0, \\frac{10-10}{10})=0$。\n  $s_2 = \\mathrm{clip}(1 - 0/4, 0, 1) = 1.0$。\n\n- **案例 3**：\n  $X_3$ 有 6 行。$\\mathbf{p}_3 = \\sum_i X_{3,i}^T = [620, 6.4, 2, 9]^T$。\n  $\\mathrm{MW}$ 和 $\\log P$ 违反了它们的规则。\n  $v_{\\mathrm{MW}} = \\max(0, \\frac{620-500}{500}) = 0.24$。\n  $v_{\\log P} = \\max(0, \\frac{6.4-5}{5}) = 0.28$。\n  $v_{\\mathrm{HBD}} = \\max(0, \\frac{2-5}{5}) = 0$。\n  $v_{\\mathrm{HBA}} = \\max(0, \\frac{9-10}{10}) = 0$。\n  总违规值：$0.24 + 0.28 = 0.52$。\n  $s_3 = \\mathrm{clip}(1 - 0.52/4, 0, 1) = \\mathrm{clip}(1 - 0.13, 0, 1) = 0.87$。\n\n- **案例 4**：\n  $X_4$ 有 1 行。$\\mathbf{p}_4 = [18, -0.4, 2, 1]^T$。\n  所有属性都远在其阈值范围内。\n  $v_{\\mathrm{MW}}=v_{\\log P}=v_{\\mathrm{HBD}}=v_{\\mathrm{HBA}} = 0$。\n  $s_4 = \\mathrm{clip}(1 - 0/4, 0, 1) = 1.0$。\n\n最终计算出的分数为 $[1.0, 1.0, 0.87, 1.0]$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the GNN-based drug-likeness scoring procedure and evaluates it on the test suite.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # The adjacency matrix A is not used in the final calculation, as derived in the solution,\n    # because recovering purely additive properties requires nullifying the message passing term.\n    # It is included here for completeness.\n    test_cases = [\n        # Case 1\n        (np.array([[0, 1, 0, 0, 0], [1, 0, 1, 0, 0], [0, 1, 0, 1, 0], [0, 0, 1, 0, 1], [0, 0, 0, 1, 0]]),\n         np.array([[60, 0.4, 0, 1], [80, 0.6, 0, 2], [100, 0.8, 1, 1], [55, 0.5, 0, 1], [55, 0.5, 0, 1]])),\n        # Case 2\n        (np.array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 1], [1, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 1, 0, 0, 0, 0, 0, 0], \n                   [0, 0, 1, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 1, 0, 0, 0], \n                   [0, 0, 0, 0, 0, 1, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 1], \n                   [1, 0, 0, 0, 0, 0, 0, 0, 1, 0]]),\n         np.array([[50, 0.5, 1, 1], [50, 0.5, 1, 1], [50, 0.5, 1, 1], [50, 0.5, 1, 1], [50, 0.5, 1, 1], \n                   [50, 0.5, 0, 1], [50, 0.5, 0, 1], [50, 0.5, 0, 1], [50, 0.5, 0, 1], [50, 0.5, 0, 1]])),\n        # Case 3\n        (np.array([[0, 1, 0, 0, 0, 0], [1, 0, 1, 0, 1, 0], [0, 1, 0, 1, 0, 0], [0, 0, 1, 0, 1, 0], \n                   [0, 1, 0, 1, 0, 1], [0, 0, 0, 0, 1, 0]]),\n         np.array([[100, 0.9, 0, 1], [120, 1.2, 0, 2], [130, 1.4, 1, 2], [90, 1.0, 0, 2], \n                   [80, 0.8, 1, 1], [100, 1.1, 0, 1]])),\n        # Case 4\n        (np.array([[0]]),\n         np.array([[18, -0.4, 2, 1]]))\n    ]\n\n    def calculate_drug_likeness_score(X: np.ndarray) -> float:\n        \"\"\"\n        Calculates the drug-likeness score based on Lipinski's rule of five.\n\n        Args:\n            X: Node feature matrix of shape (n_atoms, 4), where columns are\n               per-atom contributions to MW, logP, HBD, and HBA.\n\n        Returns:\n            The soft satisfaction score s, a float between 0 and 1.\n        \"\"\"\n        # The GNN-based procedure simplifies to summing the node features to get the graph-level properties.\n        # This corresponds to sum pooling of the initial node features.\n        properties = np.sum(X, axis=0)\n        mw, logp, hbd, hba = properties[0], properties[1], properties[2], properties[3]\n\n        # Lipinski's rule thresholds\n        thresholds = {'mw': 500, 'logp': 5, 'hbd': 5, 'hba': 10}\n\n        # Calculate normalized violations using a rectified linear unit (phi(z) = max(0, z))\n        v_mw = max(0, (mw - thresholds['mw']) / thresholds['mw'])\n        v_logp = max(0, (logp - thresholds['logp']) / thresholds['logp'])\n        v_hbd = max(0, (hbd - thresholds['hbd']) / thresholds['hbd'])\n        v_hba = max(0, (hba - thresholds['hba']) / thresholds['hba'])\n\n        # Calculate the total penalty\n        total_violation = v_mw + v_logp + v_hbd + v_hba\n        \n        # Calculate the final score, clipped to the [0, 1] range\n        score = 1.0 - (total_violation / 4.0)\n        final_score = np.clip(score, 0, 1)\n        \n        return final_score\n\n    results = []\n    for _, X_case in test_cases:\n        score = calculate_drug_likeness_score(X_case)\n        results.append(score)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.3f}' for r in results)}]\")\n\nsolve()\n```", "id": "2395422"}, {"introduction": "一个强大的模型不仅取决于其复杂的算法，更取决于我们为其提供的“信息养料”的质量。这个思想实验将挑战您对 GNN 能力边界的理解。我们将探讨一个关键问题：如果从分子图中移除诸如单键、双键等化学键类型的详细信息，仅保留原子间的连接性，GNN 的预测能力会发生什么变化？通过对比苯（benzene）和环己烷（cyclohexane）等经典案例，本练习旨在揭示 GNN 的“表达能力”（expressive power）极限，并强调特征工程（feature engineering）在分子建模中的核心地位。这有助于培养您在设计模型时对数据表征的批判性思维。", "problem": "您正在训练一个消息传递神经网络（Message Passing Neural Network, MPNN），用于计算生物学和生物信息学中的分子性质预测。每个分子被表示为一个重原子（不显式包含氢原子）的无向分子图 $G=(V,E)$，其中每个节点 $v\\in V$ 带有包含原子序数和形式电荷的初始特征向量 $x_v$，每条边 $\\{u,v\\}\\in E$ 带有编码化学键类型（单键、双键、三键、芳香键）的边特征 $e_{uv}$。MPNN 执行 $L$ 轮具有置换不变聚合的消息传递，然后应用一个置换不变读出层以获得对目标分子性质的预测值 $\\hat{y}$。所有训练条件（架构深度 $L$、优化方法、数据集大小以及训练/验证/测试集划分）都保持不变。目标性质依赖于电子结构特征，而已知这些特征受键级和芳香性影响（例如，紫外-可见（UV-Vis）吸收峰位置或共轭依赖的反应性）。\n\n您考虑修改分子表示方法，将多类别的边特征 $e_{uv}$ 替换为单个二元指示符，该指示符仅编码两个原子是否由化学键连接（$1$）或未连接（$0$），而流程中的所有其他方面保持不变。\n\n以下哪个陈述最能描述这一变化对 MPNN 预测能力的预期影响？\n\nA. 在深度 $L$ 足够大的情况下，预测能力将保持不变，因为深层消息传递仅从连接性中就能重构所有必要的化学信息，使得显式的化学键类型变得冗余。\n\nB. 对于依赖于键级、共振或芳香性的性质，预测能力通常会下降，因为模型失去了信息丰富的边标签信号，而这些信号无法从二元连接性中恢复。\n\nC. 在典型的小型数据集上，预测能力通常会提高，因为降低的输入维度起到了隐式正则化器的作用，其效果超过了任何化学细节损失带来的影响。\n\nD. 如果将 $L$ 增加到每个节点的感受野都覆盖整个图，则预测能力将保持不变，因为全局视图弥补了缺失的边标签信息。\n\nE. 当节点特征包含原子序数和形式电荷时，预测能力将保持不变，因为仅使用二元连接性和节点特征，就可以根据价键规则精确推断出键级。", "solution": "对问题陈述进行验证。\n\n### 步骤1：提取已知条件\n- **模型**：消息传递神经网络 (MPNN)。\n- **任务**：分子性质预测。\n- **输入**：表示重原子的无向分子图 $G=(V,E)$。\n- **节点特征**：每个节点 $v \\in V$ 的初始特征向量 $x_v$，包含原子序数和形式电荷。\n- **边特征（原始）**：每条边 $\\{u,v\\} \\in E$ 的特征向量 $e_{uv}$，编码化学键类型（单键、双键、三键、芳香键）。\n- **MPNN 流程**：进行 $L$ 轮具有置换不变聚合的消息传递，随后通过一个置换不变的读出层产生预测值 $\\hat{y}$。\n- **目标性质**：一种依赖于电子结构的分子性质，受键级和芳香性影响（例如，紫外-可见（UV-Vis）吸收）。\n- **固定条件**：架构深度 $L$、优化方法、数据集大小和数据划分均保持不变。\n- **修改**：将多类别边特征 $e_{uv}$ 替换为单个二元指示符：如果存在化学键则为 $1$，否则为 $0$。\n- **问题**：描述此修改对 MPNN 预测能力的预期影响。\n\n### 步骤2：使用提取的已知条件进行验证\n该问题陈述具有科学依据、问题明确且客观。\n\n1.  **科学或事实上的不健全性**：该问题在科学上是健全的。它描述了在化学信息学中使用图神经网络的标准方法。MPNN、分子图、原子特征、键特征以及它们与电子性质（如 UV-Vis 光谱）之间的关系等概念，在计算化学和生物学中都是成熟的。\n2.  **非形式化或不相关**：该问题是形式化的，并且直接关系到图神经网络在分子数据分析中的应用。\n3.  **设置不完整或矛盾**：设置是完整且自洽的。它清晰地定义了初始状态、修改内容、约束条件（固定条件）以及感兴趣的性质。\n4.  **不切实际或不可行**：所提出的修改是机器学习研究中为理解特征重要性而进行的一种常见的消融研究。这完全是现实的。\n5.  **问题提出不当或结构不良**：该问题提出得很好，要求定性分析对模型性能的影响，这可以从 GNN 和化学的第一性原理推断出来。\n6.  **超出科学可验证性范围**：这些论断可以基于已建立的 GNN 表达能力理论和基本化学原理进行评估。\n\n### 步骤3：结论与行动\n问题陈述有效。将推导出解决方案。\n\n### 推导\n问题的核心在于理解分子图表示的信息含量，以及其减少如何影响消息传递神经网络 (MPNN) 的学习能力。原始表示包含丰富的边特征 $e_{uv}$，用于指定键类型：单键、双键、三键或芳香键。修改后的表示丢弃了这些信息，只保留了图的邻接矩阵（即连接性）。\n\n目标性质被明确指出依赖于电子结构、键级和芳香性。这些化学特性与分子中电子的分布直接相关，尤其是共轭体系中的 $\\pi$ 电子。\n- **键级**（例如，单键 vs. 双键）决定了键长、键强和电子的局域化程度。\n- **芳香性**是环状、平面、共轭体系的一种特殊性质，导致其具有超常的热力学稳定性和独特的电子行为（例如，特定的反应性、独特的光谱信号）。\n\nMPNN 的工作原理是基于其邻居在上一层 $k-1$ 的表示，迭代更新第 $k$ 层节点表示 $h_v^{(k)}$：\n$$h_v^{(k)} = U^{(k)} \\left( h_v^{(k-1)}, \\bigoplus_{u \\in N(v)} M^{(k)}(h_v^{(k-1)}, h_u^{(k-1)}, e_{vu}) \\right)$$\n其中 $M^{(k)}$ 是消息函数，$\\bigoplus$ 是置换不变的聚合函数（例如，求和、求均值），而 $U^{(k)}$ 是更新函数。初始表示为 $h_v^{(0)} = x_v$。\n\n关键点在于，网络可用的所有信息都包含在初始节点特征 $x_v$ 和边特征 $e_{uv}$ 中。消息传递机制只能在图结构上传播和转换这些初始信息。它无法创造出未在输入中隐式或显式存在的新信息。\n\n通过将 $e_{uv}$ 中详细的键类型信息替换为二元指示符，我们造成了一个显著的信息瓶颈。问题就变成了，这些丢失的信息是否可以从剩余的数据中——即图的拓扑结构、原子序数和形式电荷——恢复出来。\n\n考虑两个截然不同的分子：苯 ($C_6H_6$) 和环己烷 ($C_6H_{12}$)。在重原子图表示中，两者都被表示为一个由 $6$ 个碳原子组成的环。\n- **节点特征**：对于两者，所有 $6$ 个节点都是碳原子（原子序数相同）。假设是中性分子，形式电荷均为 $0$。因此，两种图中所有节点的初始节点特征向量 $x_v$ 都是相同的。\n- **边特征（原始）**：对于苯，边将被标记为“芳香键”。对于环己烷，它们将是“单键”。\n- **边特征（修改后）**：对于这两种分子，$6$ 元环中的所有边现在都由数值 $1$ 表示。\n\n在使用修改后的表示时，苯和环己烷的输入图对于 MPNN 来说变得完全无法区分。它们具有相同的节点特征、相同的边特征（均为 $1$）以及相同的同构图结构（一个 6-环）。由于 MPNN 架构是其输入图的确定性函数，它将对这两个分子产生完全相同的最终图嵌入，从而产生完全相同的性质预测值 $\\hat{y}$。\n\n然而，它们真实的性质却大相径庭。苯是芳香性的、平面的，由于其离域的 $\\pi$ 电子体系而强烈吸收紫外光。环己烷是非芳香性的、非平面的，并且在同一紫外区域是透明的。在修改后的数据上训练的 MPNN 不可能学会区分它们，并且至少会对其中一个产生很大的误差。这并非个例；许多同分异构体和具有共振结构的分子（例如，羧酸根离子、酰胺）的性质都依赖于键级和离域，而如果没有显式的键类型特征，这些信息就会丢失。\n\n因此，移除编码键类型的边特征从根本上限制了模型在需要此类信息的任务上的表达能力。模型在对电子共轭和芳香性敏感的性质上的性能预计将大幅下降。\n\n### 逐项分析\n**A. 在深度 $L$ 足够大的情况下，预测能力将保持不变，因为深层消息传递仅从连接性中就能重构所有必要的化学信息，使得显式的化学键类型变得冗余。**\n这个陈述是错误的。正如苯/环己烷的例子所示，如果两个化学上不同的分子被表示为具有相同初始节点和边特征的同构图，那么无论消息传递的次数有多少（$L \\to \\infty$），都无法使它们变得可区分。消息传递是在现有图结构上传播信息，它不能“创造”信息，也不能在初始特征向量相同的情况下解决图同构问题。必要的化学信息并不仅仅包含在连接性中。\n\n**B. 对于依赖于键级、共振或芳香性的性质，预测能力通常会下降，因为模型失去了信息丰富的边标签信号，而这些信号无法从二元连接性中恢复。**\n这个陈述是正确的。它准确地指出了对于与电子结构相关的性质，键类型是一个信息量非常大的特征。它正确地说明了这些信息无法仅从图的拓扑结构和节点特征中完全恢复。失去这个关键信号会削弱模型区分具有根本不同电子性质（例如，芳香族 vs. 脂肪族）的分子能力，导致预测能力下降。\n\n**C. 在典型的小型数据集上，预测能力通常会提高，因为降低的输入维度起到了隐式正则化器的作用，其效果超过了任何化学细节损失带来的影响。**\n这个陈述是错误的。虽然降低特征维度可能具有正则化效应，但这仅在被移除的特征是噪声或预测价值较低时才是有益的。在这里，键类型特征对于指定的目标性质至关重要。移除如此关键的信号会引入强烈的系统性偏差，使模型从根本上无法捕捉底层的化学原理。由此导致的欠拟合（高偏差）将远超于因过拟合减少（低方差）而带来的任何潜在好处。化学细节的损失是灾难性的。\n\n**D. 如果将 $L$ 增加到每个节点的感受野都覆盖整个图，则预测能力将保持不变，因为全局视图弥补了缺失的边标签信息。**\n这个陈述是错误的。这是论点 A 的一个变体。全局感受野意味着每个节点的最终表示依赖于图中所有其他的节点和边。然而，如果两个不同分子的初始输入图是相同的（如修改特征后的苯/环己烷案例），那么全局聚合的结果也将是相同的。全局视图无法弥补基础特征层面信息的缺失。\n\n**E. 当节点特征包含原子序数和形式电荷时，预测能力将保持不变，因为仅使用二元连接性和节点特征，就可以根据价键规则精确推断出键级。**\n这个陈述是错误的。“可以根据价键规则…精确推断出键级”的说法是错误的。化学中充满了同分异构和共振的例子，其中一个单一的连接图对应于多个有效且不同的电子结构。虽然价键规则提供了约束，但它们并不能为许多复杂的有机分子（尤其是涉及共轭体系、芳香环或杂原子的分子）中的键级提供唯一解。例如，对于一个吡啶环（$C_5H_5N$），连接性和原子类型并不能毫无歧义地唯一确定其电子结构。模型无法“推断”出一个并未由输入唯一决定的唯一真理。", "answer": "$$\\boxed{B}$$", "id": "2395408"}, {"introduction": "在真实的生物信息学应用中，我们处理的分子系统远比单个连通的分子要复杂，例如离子盐（如 $\\text{Na}^+\\text{Cl}^-$）或混合物，它们在图表示中通常呈现为多个不相连的组件。本练习聚焦于这一实际挑战，要求您设计出能够处理这些断开图（disconnected graphs）的 GNN 策略。您将评估多种高级架构模式，如分层池化（hierarchical pooling）和引入“虚拟节点”（virtual node），学习如何在信息无法在各部分间直接传递的情况下，构建一个既能整合全局信息又满足排列不变性（permutation invariance）的统一表示。这个练习将您的 GNN 设计技能从单个分子提升到复杂化学系统，为您处理多样化的真实世界数据打下坚实基础。", "problem": "您正在构建一个图神经网络（GNN）来预测一个离子盐的标量属性 $y(G)$。该离子盐表示为一个分子图 $G=(V,E)$，其共价键拓扑结构产生了多个不连通的分量。考虑一个典型案例，如 $\\text{Na}^+\\text{Cl}^-$，其中 $G$ 分解为 $k\\ge 2$ 个连通分量 $G_i=(V_i,E_i)$，且满足 $\\bigsqcup_{i=1}^k V_i=V$ 和 $\\bigsqcup_{i=1}^k E_i=E$。节点特征 $x_v$ 包括原子类型和形式电荷；边特征 $e_{uv}$ 编码了 $(u,v)\\in E$ 的键类型。数据集中没有可靠的三维坐标或离子间距离，并且属性 $y(G)$ 是为化学式单元（例如，一个阳离子和一个阴离子）定义的。一个 $T$ 层的消息传递GNN通过函数 $\\psi$ 和 $\\phi$ 以及一个置换不变的多重集聚合器 $\\square$ 来更新节点状态：\n$$\nh_v^{(0)}=x_v,\\quad\nm_v^{(t)}=\\square_{u\\in \\mathcal{N}(v)} \\psi\\!\\left(h_v^{(t)},h_u^{(t)},e_{uv}\\right),\\quad\nh_v^{(t+1)}=\\phi\\!\\left(h_v^{(t)},m_v^{(t)}\\right),\\quad t=0,\\dots,T-1.\n$$\n图级别的预测器必须产生一个 $\\hat y(G)$，该预测结果对于每个分量内部的原子排序是不变的，对于分量集合 $\\{G_i\\}_{i=1}^k$ 的排列是不变的，并且必须能处理可变的 $k$。\n\n在当前设定下，以下哪些策略是处理不连通分量的有原则的方法，以获得一个定义良好、置换不变的、适合属性预测的图级别表示？\n\nA. 执行分层池化：首先用一个置换不变的读出函数 $\\rho$ 计算一个分量级别的嵌入 $r_i=\\rho\\!\\left(\\{h_v^{(T)}: v\\in V_i\\}\\right)$，然后用另一个置换不变的集合函数 $\\Gamma$（例如，对于广延性目标使用求和，对于强度性目标使用均值）计算一个分子级别的嵌入 $z=\\Gamma\\!\\left(\\{r_i\\}_{i=1}^k\\right)$，最后预测 $\\hat y=f(z)$。\n\nB. 引入一个单一的可学习的全局虚拟节点 $g$，通过特殊类型的边与每个原子相连；扩展消息传递以包含 $g$，使得 $h_g^{(T)}$ 能聚合来自所有分量的信息，并使用 $h_g^{(T)}$（可选择性地与池化的节点特征结合）作为图表示来预测 $\\hat y$。\n\nC. 在阳离子中的一个随机选择的原子和阴离子中的一个随机选择的原子之间人为地添加一条无向边，将此边与共价键同等对待，从而使 $G$ 变为连通图，然后应用一个标准的图级别读出。\n\nD. 除最大分量外，丢弃所有其他分量，仅对该分量应用GNN和读出函数，并将结果用作分子级别的表示。\n\nE. 通过用点分隔符连接离子的简化分子线性输入规范（SMILES）字符串，将该盐转化为一个序列，将此序列输入到一个循环神经网络（RNN）中，并使用最后一个隐藏状态来预测 $\\hat y$，从而绕过图的不连通性问题。", "solution": "问题陈述需要进行验证。\n\n**第1步：提取已知条件**\n- **模型类型**：用于预测分子图 $G$ 的标量属性 $y(G)$ 的图神经网络（GNN）。\n- **输入图**：$G=(V,E)$ 代表一个离子盐。\n- **图结构**：$G$ 由 $k\\ge 2$ 个不连通的分量 $G_i=(V_i,E_i)$ 组成，使得 $V=\\bigsqcup_{i=1}^k V_i$ 且 $E=\\bigsqcup_{i=1}^k E_i$。一个例子是 $\\text{Na}^+\\text{Cl}^-$。\n- **特征**：提供了节点特征 $x_v$（原子类型、形式电荷）和边特征 $e_{uv}$（键类型）。共价键构成了分量内部的边。\n- **缺失信息**：三维坐标和离子间距离不可用。\n- **目标属性**：$y(G)$ 是为化学式单元（例如，一个阳离子和一个阴离子）定义的。\n- **GNN架构**：使用一个 $T$ 层的消息传递GNN，其更新规则如下（对于 $t=0, \\dots, T-1$）：\n  - 节点初始化：$h_v^{(0)}=x_v$。\n  - 消息聚合：$m_v^{(t)}=\\square_{u\\in \\mathcal{N}(v)} \\psi(h_v^{(t)},h_u^{(t)},e_{uv})$，其中 $\\square$ 是一个置换不变的多重集聚合器。\n  - 节点更新：$h_v^{(t+1)}=\\phi(h_v^{(t)},m_v^{(t)})$。\n- **输出要求**：对于 $\\hat y(G)$ 的图级别预测器必须：\n  1. 对每个分量 $G_i$ 内部的原子排序不变。\n  2. 对分量本身 $\\{G_i\\}_{i=1}^k$ 的排列不变。\n  3. 能够处理可变数量的分量 $k$。\n\n**第2步：使用提取的已知条件进行验证**\n- **科学依据**：该问题在计算生物学和化学信息学领域有充分的科学依据。使用GNN预测分子属性是一个标准且高度活跃的研究领域。在缺少三维结构信息时，将离子盐表示为其共价拓扑结构的不连通图是一种常见且有效的方法。所描述的消息传递框架是一种通用且广泛使用的公式（例如，图同构网络或GIN是其一个特例）。对置换不变性的要求是创建有效化学系统模型的基础。该问题在科学上是合理的。\n- **适定性**：该问题是适定的。它清楚地定义了输入（一个具有特定特征的不连通图）、模型类别（一个消息传递GNN）以及对输出的约束（不变性属性）。问题要求找到满足这些约束的有原则的策略，这是一个明确的目标。虽然可能存在多种有效策略，因此不期望有唯一答案，但有效策略的集合是明确定义的。\n- **客观性**：问题陈述使用了机器学习和计算化学文献中常见的精确、技术性语言。它没有歧义、主观性或观点。\n\n**第3步：结论与行动**\n问题陈述是有效的。它在科学上是合理的、适定的、客观的且自洽的。因此，将推导其解答。\n\n**推导与选项分析**\n\n核心困难源于图 $G$ 的不连通性。在所描述的消息传递方案中，信息不会在不连通的分量之间流动。对于任何两个节点 $u \\in V_i$ 和 $v \\in V_j$（其中 $i \\neq j$），它们之间没有路径。因此，经过 $T$ 层消息传递后，节点 $v \\in V_i$ 的最终嵌入 $h_v^{(T)}$ 仅是其自身分量 $G_i$ 内部节点和边的初始特征的函数。因此，模型必须采用一种特定的策略来聚合这些独立分量的信息，以形成一个单一、连贯的、代表整个离子盐的表示，同时遵守所需的不变性。\n\n**选项 A：执行分层池化...**\n该策略提出了一个两步聚合过程。\n1.  **分量级别池化**：对于每个分量 $G_i$，通过对其最终节点嵌入集合 $\\{h_v^{(T)}: v\\in V_i\\}$ 应用一个置换不变的读出函数 $\\rho$ 来计算一个表示 $r_i$。GNN本身确保了节点嵌入集合对于分量内部节点索引的置换是不变的。应用一个置换不变的函数，如求和、均值或最大值池化（即 $\\rho$），确保了 $r_i$ 是分量 $G_i$ 的一个规范表示。\n2.  **分子级别池化**：然后，使用另一个置换不变的集合函数 $\\Gamma$ 来聚合分量表示的集合 $\\{r_i\\}_{i=1}^k$，以产生最终的图级别嵌入 $z = \\Gamma(\\{r_i\\}_{i=1}^k)$。这明确地解决了对分量排列不变性的要求。像求和或均值这样的聚合函数也自然地处理可变数量的分量 $k$。$\\Gamma$ 的选择（例如，对广延性属性使用求和，对强度性属性使用均值）为模型增加了另一层物理原则。\n\n这是一种逻辑上合理、有原则且广泛使用的处理输入集合的方法，而不连通图正是一个连通分量的集合。\n**结论：正确**\n\n**选项 B：引入一个单一的可学习的全局虚拟节点...**\n该策略涉及增强图结构。一个新的“虚拟”节点 $g$ 被添加到图中，并与每个现有节点 $v \\in V$ 相连。可以为这些新边分配一个特殊类型，以便消息函数 $\\psi$ 能够区分它们。\n在这个修改后的连通图中，消息传递的运作方式不同：\n- 在第一层，虚拟节点 $g$ 聚合来自所有分量中所有节点的消息。它的状态 $h_g^{(1)}$ 成为整个图的摘要。\n- 同时，所有节点 $v \\in V$ 都会收到来自 $g$ 的消息。\n- 在第二层，一个节点 $v \\in V_i$ 可以通过路径 $u \\to g \\to v$ 接收来自另一个节点 $u \\in V_j$（对于 $i \\neq j$）的消息。信息现在通过全局节点的中介在所有分量之间交换。\n经过 $T$ 层之后，虚拟节点的最终嵌入 $h_g^{(T)}$ 迭代地聚合了来自整个分子系统的信息。由于用于更新 $h_g^{(t)}$ 的聚合函数 $\\square$ 是置换不变的，因此 $h_g^{(T)}$ 对节点的排列是内在不变的，因此对分量的排列也是不变的。使用 $h_g^{(T)}$ 作为图级别表示是产生整个系统的置换不变嵌入的一种有效且强大的技术。这是一种标准的架构模式，称为“主节点”或“全局读出”。\n**结论：正确**\n\n**选项 C：在阳离子中的一个随机选择的原子和阴离子中的一个随机选择的原子之间人为地添加一条无向边...**\n该策略旨在通过添加一条边来使图连通。虽然这允许信息在整个结构中流动，但选择这条边端点的方法被指定为*随机*的。\nGNN通常对图的拓扑结构不是不变的。通过在不同节点对之间添加边来改变连通性，通常会导致不同的最终节点嵌入和不同的图级别预测。对于一个给定的输入图 $G$，预测 $\\hat y(G)$ 必须是确定性的。在模型的前向传播中引入随机选择会使对于一个固定输入的预测结果是随机的，这是不可接受的。可以对所有可能的连接进行平均，但这并非该选项所提议的，并且计算成本高昂。这种方法是一种任意的启发式方法，而不是有原则的方法。它引入了一个依赖于随机种子而非系统化学性质的人为结构特征。\n**结论：错误**\n\n**选项 D：除最大分量外，丢弃所有其他分量...**\n该策略提议通过丢弃数据来简化问题。问题陈述中指出，属性 $y(G)$ 是为化学式单元（例如，一个阳离子和一个阴离子）定义的。对于 $\\text{Na}^+\\text{Cl}^-$，分量是大小相等的单个原子，因此“最大”没有唯一定义。对于更复杂的盐，如硫酸镁 $(\\text{Mg}^{2+})(\\text{SO}_4^{2-})$，硫酸根离子（5个原子）是最大的分量。此策略将丢弃镁阳离子 $(\\text{Mg}^{2+})$。硫酸镁的性质关键性地依赖于镁阳离子和硫酸根阴离子。忽略其中任何一个都使得在物理和化学上不可能预测该盐的性质。这种方法从根本上说是不合理的，因为它丢弃了解决问题所必需的关键信息。\n**结论：错误**\n\n**选项 E：通过...将该盐转化为一个序列...并使用一个循环神经网络（RNN）...**\n该问题明确要求在应用于图表示的GNN模型的背景下提出一种策略。此选项提议完全放弃图表示和GNN架构。它用基于字符串的表示（SMILES）和序列模型（RNN）来替代它们。虽然将SMILES与RNN或Transformer一起使用是分子属性预测中一种有效的替代建模范式，但它不是一种*在指定的GNN框架内处理不连通分量*的策略。它完全偏离了问题的设定。问题是如何使给定的GNN架构工作，而不是如何替换它。因此，此选项没有回答所提出的问题。\n**结论：错误**", "answer": "$$\\boxed{AB}$$", "id": "2395424"}]}