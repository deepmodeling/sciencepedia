{"hands_on_practices": [{"introduction": "在生物学研究中，我们常常希望了解不同类型的分子数据（例如，$DNA$ 甲基化与组蛋白修饰）哪一种对基因表达等表型具有更强的预测能力。本练习将介绍一种基本而强大的方法，通过将模型的输出方差分解到不同的特征组，来量化它们各自的贡献。这项实践将帮助你掌握一种评估和比较特征组重要性的基础技术，这是理解模型预测驱动因素的第一步。[@problem_id:2400021]", "id": "2400021", "problem": "给定一个形式化框架，用于比较两种分子特征组，即脱氧核糖核酸（DNA）甲基化和组蛋白修饰，对细胞系中基因表达的预测贡献。考虑一个用于表达变量 $y$ 的生成线性模型，其定义为\n$$\ny \\;=\\; X^{(M)} w^{(M)} \\;+\\; X^{(H)} w^{(H)} \\;+\\; \\varepsilon,\n$$\n其中，$X^{(M)} \\in \\mathbb{R}^{n \\times m}$ 表示 DNA 甲基化特征，$X^{(H)} \\in \\mathbb{R}^{n \\times h}$ 表示组蛋白修饰特征，$w^{(M)} \\in \\mathbb{R}^{m}$ 和 $w^{(H)} \\in \\mathbb{R}^{h}$ 是固定系数向量，$\\varepsilon \\in \\mathbb{R}^{n}$ 是一个零均值噪声向量，每个样本的方差为 $\\sigma^2$。假设 $X^{(M)}$ 和 $X^{(H)}$ 的每一列都是方差为 $1$ 的独立标准化随机变量，并且 $X^{(M)}$、$X^{(H)}$ 和 $\\varepsilon$ 相互独立，且 $n$ 足够大以适用总体方差表达式。\n\n根据模型假设，将 DNA 甲基化的组特征重要性定义为 $y$ 中可归因于 DNA 甲基化的方差比例：\n$$\nI_M \\;=\\; \\frac{\\mathrm{Var}\\!\\left(X^{(M)} w^{(M)}\\right)}{\\mathrm{Var}(y)}.\n$$\n类似地，将组蛋白修饰的组特征重要性定义为\n$$\nI_H \\;=\\; \\frac{\\mathrm{Var}\\!\\left(X^{(H)} w^{(H)}\\right)}{\\mathrm{Var}(y)}.\n$$\n在所述假设下，这些量可以简化为以下关于系数向量和噪声方差的表达式：\n$$\n\\mathrm{Var}\\!\\left(X^{(M)} w^{(M)}\\right) \\;=\\; \\left\\| w^{(M)} \\right\\|_2^2,\\quad\n\\mathrm{Var}\\!\\left(X^{(H)} w^{(H)}\\right) \\;=\\; \\left\\| w^{(H)} \\right\\|_2^2,\\quad\n\\mathrm{Var}(y) \\;=\\; \\left\\| w^{(M)} \\right\\|_2^2 \\;+\\; \\left\\| w^{(H)} \\right\\|_2^2 \\;+\\; \\sigma^2.\n$$\n您的任务是编写一个程序，该程序针对下方测试套件中的每一组参数，使用上述定义计算 $I_M$ 和 $I_H$，并根据以下规则（容差 $\\delta = 10^{-9}$），为每种情况输出一个整数决策：\n- 如果 $I_M - I_H \\ge \\delta$，输出 $1$。\n- 如果 $I_H - I_M \\ge \\delta$，输出 $-1$。\n- 否则，输出 $0$。\n\n测试套件（每种情况均指定 $w^{(M)}$、$w^{(H)}$ 和 $\\sigma$）：\n- 情况 1：$w^{(M)} = (1.0,\\, 0.8,\\, 0.0,\\, 0.0,\\, 0.0)$，$w^{(H)} = (0.3,\\, 0.0,\\, 0.0,\\, 0.0)$，$\\sigma = 0.5$。\n- 情况 2：$w^{(M)} = (0.2,\\, 0.0,\\, 0.0)$，$w^{(H)} = (0.9,\\, 0.7,\\, 0.0,\\, 0.0)$，$\\sigma = 0.4$。\n- 情况 3：$w^{(M)} = (0.5,\\, 0.5)$，$w^{(H)} = (0.7071067811865476,\\, 0.0)$，$\\sigma = 0.0$。\n- 情况 4：$w^{(M)} = (0.0,\\, 0.0,\\, 0.0)$，$w^{(H)} = (0.2,\\, 0.2,\\, 0.2)$，$\\sigma = 1.0$。\n- 情况 5：$w^{(M)} = (0.0,\\, 0.0)$，$w^{(H)} = (0.0,\\, 0.0)$，$\\sigma = 0.3$。\n\n您的程序应生成单行输出，其中包含五个测试用例的结果，形式为一个用方括号括起来的逗号分隔的整数列表（例如，$[1,-1,0,-1,0]$）。不允许有任何额外的输出或空格。不涉及角度。不涉及物理单位。所有数值计算都必须使用标准实数算术执行。", "solution": "所提出的问题是有效的，因为它具有科学依据、问题明确且客观。它基于一个简化但合理的基因调控统计模型，提出了一个清晰的计算任务，这是计算生物学中的标准方法。定义、假设和测试用例是完整且内部一致的。我们将着手提供一个解决方案。\n\n目标是比较两个特征组——DNA甲基化（$M$）和组蛋白修饰（$H$）——对生物响应变量基因表达（$y$）的预测贡献。这通过量化每个特征组所能解释的 $y$ 的方差比例来实现。这是模型解释中的一种基本技术。\n\n问题将基因表达 $y$ 的线性模型定义为：\n$$\ny \\;=\\; X^{(M)} w^{(M)} \\;+\\; X^{(H)} w^{(H)} \\;+\\; \\varepsilon\n$$\n在此， $y$ 是中心化的响应向量。项 $X^{(M)} w^{(M)}$ 和 $X^{(H)} w^{(H)}$ 分别代表来自 DNA 甲基化和组蛋白修饰特征的贡献，由固定系数向量 $w^{(M)}$ 和 $w^{(H)}$ 加权。项 $\\varepsilon$ 代表随机噪声，假设其独立同分布，每个样本的均值为 $0$，方差为 $\\sigma^2$。\n\n一个关键假设是，特征矩阵 $X^{(M)}$ 和 $X^{(H)}$ 的列是独立的、标准化的随机变量（均值为 $0$，方差为 $1$）。此外，特征组和噪声是相互独立的。在这些条件下，响应 $y$ 的总方差可以进行加性分解，这是源于不相关随机变量和的方差的 Bienaymé 公式的一个性质。\n\n对于单个样本 $y_i$，其方差为：\n$$\n\\mathrm{Var}(y_i) \\;=\\; \\mathrm{Var}\\left(\\sum_{j} X_{ij}^{(M)} w_{j}^{(M)}\\right) \\;+\\; \\mathrm{Var}\\left(\\sum_{k} X_{ik}^{(H)} w_{k}^{(H)}\\right) \\;+\\; \\mathrm{Var}(\\varepsilon_i)\n$$\n由于特征 $X_{ij}$ 的独立性和单位方差：\n$$\n\\mathrm{Var}\\left(\\sum_{j} X_{ij}^{(M)} w_{j}^{(M)}\\right) \\;=\\; \\sum_{j} (w_{j}^{(M)})^2 \\mathrm{Var}(X_{ij}^{(M)}) \\;=\\; \\sum_{j} (w_{j}^{(M)})^2 \\cdot 1 \\;=\\; \\left\\| w^{(M)} \\right\\|_2^2\n$$\n类似地，$\\mathrm{Var}\\left(\\sum_k X_{ik}^{(H)} w_k^{(H)}\\right) = \\left\\| w^{(H)} \\right\\|_2^2$。噪声方差给定为 $\\mathrm{Var}(\\varepsilon_i) = \\sigma^2$。因此， $y$ 的总方差正确地表示为：\n$$\n\\mathrm{Var}(y) \\;=\\; \\left\\| w^{(M)} \\right\\|_2^2 \\;+\\; \\left\\| w^{(H)} \\right\\|_2^2 \\;+\\; \\sigma^2\n$$\nL$2$范数的平方 $\\left\\| w \\right\\|_2^2$ 计算为向量 $w$ 各元素平方的总和。\n\n然后计算组特征重要性，它被定义为总方差的比例。对于 DNA 甲基化：\n$$\nI_M \\;=\\; \\frac{\\mathrm{Var}(X^{(M)} w^{(M)})}{\\mathrm{Var}(y)} \\;=\\; \\frac{\\left\\| w^{(M)} \\right\\|_2^2}{\\left\\| w^{(M)} \\right\\|_2^2 \\;+\\; \\left\\| w^{(H)} \\right\\|_2^2 \\;+\\; \\sigma^2}\n$$\n对于组蛋白修饰：\n$$\nI_H \\;=\\; \\frac{\\mathrm{Var}(X^{(H)} w^{(H)})}{\\mathrm{Var}(y)} \\;=\\; \\frac{\\left\\| w^{(H)} \\right\\|_2^2}{\\left\\| w^{(M)} \\right\\|_2^2 \\;+\\; \\left\\| w^{(H)} \\right\\|_2^2 \\;+\\; \\sigma^2}\n$$\n计算任务是为每个提供的参数集评估这些量，并应用决策规则。对于每种情况，我们将计算 $\\left\\| w^{(M)} \\right\\|_2^2$、$\\left\\| w^{(H)} \\right\\|_2^2$ 和 $\\sigma^2$ 的值。让它们分别为 $V_M$、$V_H$ 和 $V_{\\text{noise}}$。总方差为 $V_{\\text{total}} = V_M + V_H + V_{\\text{noise}}$。然后，$I_M = V_M / V_{\\text{total}}$ 且 $I_H = V_H / V_{\\text{total}}$。请注意，如果 $V_{\\text{total}} = 0$（仅当所有权重和 $\\sigma$ 都为零时发生），则这些重要性是未定义的。这种情况在给定的测试套件中不会出现。\n\n最终决策基于差值 $D = I_M - I_H$，容差为 $\\delta = 10^{-9}$：\n1.  如果 $D \\ge \\delta$，则判定甲基化的贡献更大。输出为 $1$。\n2.  如果 $-D \\ge \\delta$（等价于 $D \\le -\\delta$），则判定组蛋白的贡献更大。输出为 $-1$。\n3.  否则，如果 $|D| < \\delta$，则认为在给定容差内它们的贡献无法区分。输出为 $0$。\n\n此过程将为每个测试用例实施，以生成最终的决策列表。例如，对于情况1：$w^{(M)} = (1.0, 0.8, \\dots)$，$w^{(H)} = (0.3, \\dots)$，$\\sigma = 0.5$。\n$V_M = 1.0^2 + 0.8^2 = 1.64$。\n$V_H = 0.3^2 = 0.09$。\n$V_{\\text{noise}} = 0.5^2 = 0.25$。\n$V_{\\text{total}} = 1.64 + 0.09 + 0.25 = 1.98$。\n$I_M = 1.64 / 1.98$，$I_H = 0.09 / 1.98$。\n$I_M - I_H = (1.64 - 0.09) / 1.98 = 1.55 / 1.98 \\approx 0.7828$。由于 $0.7828 \\ge 10^{-9}$，输出为 $1$。该算法对所有情况的处理方式完全相同。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes and compares group feature importances for DNA methylation and histone modifications\n    based on a generative linear model.\n    \"\"\"\n    # Test suite with parameter sets (w_M, w_H, sigma).\n    test_cases = [\n        # Case 1\n        (np.array([1.0, 0.8, 0.0, 0.0, 0.0]), np.array([0.3, 0.0, 0.0, 0.0]), 0.5),\n        # Case 2\n        (np.array([0.2, 0.0, 0.0]), np.array([0.9, 0.7, 0.0, 0.0]), 0.4),\n        # Case 3\n        (np.array([0.5, 0.5]), np.array([0.7071067811865476, 0.0]), 0.0),\n        # Case 4\n        (np.array([0.0, 0.0, 0.0]), np.array([0.2, 0.2, 0.2]), 1.0),\n        # Case 5\n        (np.array([0.0, 0.0]), np.array([0.0, 0.0]), 0.3),\n    ]\n\n    # Tolerance for comparison.\n    delta = 1e-9\n\n    results = []\n    \n    for w_M, w_H, sigma in test_cases:\n        # Calculate the variance component for DNA methylation: ||w^(M)||_2^2\n        v_M = np.dot(w_M, w_M)\n        \n        # Calculate the variance component for histone modifications: ||w^(H)||_2^2\n        v_H = np.dot(w_H, w_H)\n        \n        # Calculate the variance component for noise: sigma^2\n        v_noise = sigma**2\n        \n        # Calculate the total variance of y.\n        v_total = v_M + v_H + v_noise\n        \n        # Calculate group feature importances I_M and I_H.\n        # Handle the edge case where total variance is zero, though not in the test data.\n        if v_total == 0.0:\n            i_M = 0.0\n            i_H = 0.0\n        else:\n            i_M = v_M / v_total\n            i_H = v_H / v_total\n            \n        # Calculate the difference in importances.\n        diff = i_M - i_H\n        \n        # Apply the decision rule.\n        if diff >= delta:\n            # Importance of methylation is significantly greater.\n            decision = 1\n        elif diff <= -delta:\n            # Importance of histone modifications is significantly greater.\n            decision = -1\n        else:\n            # Importances are not significantly different.\n            decision = 0\n            \n        results.append(decision)\n\n    # Print the final results in the specified format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"}, {"introduction": "在生物机器学习中，一个常见的陷阱是模型学会了走“捷径”，即利用实验批次效应等虚假相关性而非真实的生物信号进行预测，这种现象被称为“聪明的汉斯”效应。本练习模拟了这一重要问题，并指导你运用排列特征重要性和分布外（deconfounded）测试等强大技术来诊断这种行为。掌握这种诊断能力对于确保你的模型具有科学有效性至关重要，是每位计算生物学家必备的技能。[@problem_id:2400032]", "id": "2400032", "problem": "您的任务是设计一个程序，用于揭示“聪明的汉斯”（Clever Hans）效应，即预测模型使用实验批次伪影而非生物信号进行预测。您的实现必须使用基于第一性原理的可解释性工具来检测此行为。目标是设计一个能够反映合理生物数据生成过程的合成场景，然后从第一性原理出发，检测一个在经验风险最小化下训练的线性分类器是否主要依赖批次伪影而非生物信号。\n\n从以下基础出发：\n- 经验风险最小化通过优化模型参数向量来最小化经验损失。对于二元分类，一个常见的选择是逻辑斯谛损失。对于样本 $\\{(x_i,y_i)\\}_{i=1}^n$，其中 $y_i \\in \\{0,1\\}$ 且特征 $x_i \\in \\mathbb{R}^d$，一个带有权重 $w \\in \\mathbb{R}^d$ 和偏置 $b \\in \\mathbb{R}$ 的逻辑斯谛回归旨在最小化\n$$\n\\mathcal{L}(w,b) \\;=\\; \\sum_{i=1}^n \\left[-y_i \\log \\sigma(w^\\top x_i + b) - (1-y_i)\\log\\left(1-\\sigma(w^\\top x_i + b)\\right)\\right] \\;+\\; \\frac{\\lambda}{2}\\|w\\|_2^2,\n$$\n其中 $\\sigma(z) = \\frac{1}{1+e^{-z}}$ 且 $\\lambda \\ge 0$ 是正则化强度。\n- 批次伪影是一种非生物来源的变异，此处建模为一个二元批次指示符，它可能与标签产生伪相关。设 $y \\in \\{0,1\\}$ 为生物表型。设 $b \\in \\{0,1\\}$ 为批次分配。定义一个混淆参数 $c \\in [0,1]$，使得\n$$\n\\mathbb{P}(b = y) = c, \\quad \\mathbb{P}(b \\ne y) = 1-c.\n$$\n因此，当 $c=1$ 时，批次与标签完全混淆；当 $c = \\tfrac{1}{2}$ 时，批次与标签无关。\n- 生物学特征和批次特征按如下方式生成。假设有 $p_b$ 个生物学特征和 $p_a$ 个批次特征。对每个样本 $i$：\n    - 抽取 $y_i \\sim \\mathrm{Bernoulli}(0.5)$。\n    - 抽取 $b_i$，使得 $b_i = y_i$ 的概率为 $c$，$b_i = 1-y_i$ 的概率为 $1-c$。\n    - 生物学特征向量 $x^{(bio)}_i \\in \\mathbb{R}^{p_b}$ 从一个类别依赖均值的分布中抽取，$x^{(bio)}_i \\sim \\mathcal{N}(\\mu^{(bio)}(y_i), \\sigma^2 I)$，其中 $\\mu^{(bio)}(1)=+\\mu_b \\cdot \\mathbf{1}$ 且 $\\mu^{(bio)}(0)=-\\mu_b \\cdot \\mathbf{1}$。\n    - 批次特征向量 $x^{(art)}_i \\in \\mathbb{R}^{p_a}$ 从一个批次依赖均值的分布中抽取，$x^{(art)}_i \\sim \\mathcal{N}(\\mu^{(art)}(b_i), \\sigma^2 I)$，其中 $\\mu^{(art)}(1)=+\\mu_a \\cdot \\mathbf{1}$ 且 $\\mu^{(art)}(0)=-\\mu_a \\cdot \\mathbf{1}$。\n    - 拼接形成 $x_i = [x^{(bio)}_i, x^{(art)}_i] \\in \\mathbb{R}^{p_b + p_a}$。\n- 对于验证集 $\\mathcal{D}_{val}$ 上的一个特征组 $G$，其置换特征重要性定义为：当组 $G$ 中的特征在样本间被置换（从而破坏其与目标的依赖结构）时，所选性能指标的下降值。使用准确率作为指标，该组的重要性为\n$$\nI(G) = \\mathrm{Acc}(\\mathcal{D}_{val}) - \\mathrm{Acc}(\\pi_G(\\mathcal{D}_{val})),\n$$\n其中 $\\pi_G(\\cdot)$ 表示对验证集中由 $G$ 索引的列在样本间进行独立的随机置换。\n\n您的程序必须：\n1. 根据上述过程，从一个参数为 $c_{train} \\in [0,1]$ 的混淆分布中生成用于训练和验证划分的数据，并为之生成一个 $c_{test} = \\tfrac{1}{2}$ 的独立去混淆测试集。\n2. 通过在训练集上最小化带有 $\\ell_2$ 惩罚强度 $\\lambda > 0$ 的正则化逻辑斯谛损失 $\\mathcal{L}(w,b)$，来训练一个正则化逻辑斯谛回归分类器。\n3. 计算模型在来自混淆分布的验证划分上的验证准确率，以及在去混淆测试集上的测试准确率。\n4. 在验证集上计算生物学特征组 $G_{bio}$ 和批次伪影特征组 $G_{art}$ 的组置换特征重要性 $I(G_{bio})$ 和 $I(G_{art})$。\n5. 如果以下两个条件同时成立，则检测到“Clever Hans”效应：\n   - 批次伪影组的重要性严格大于生物学组的重要性，且至少大出一个很小的边际 $\\epsilon > 0$，即 $I(G_{art}) \\ge I(G_{bio}) + \\epsilon$。\n   - 从混淆验证到去混淆测试的泛化差距超过一个阈值 $\\Delta > 0$，即 $\\mathrm{Acc}_{val} - \\mathrm{Acc}_{test} \\ge \\Delta$。\n\n使用固定值 $\\lambda = 1$、$\\epsilon = 0.01$、$\\Delta = 0.2$ 以及高斯噪声标准差 $\\sigma = 1$。使用确定性的划分，训练集比例为 $0.6$，验证集比例为 $0.4$。对于每个数据集，使用指定的整数随机种子来构造一个 NumPy 随机数生成器。\n\n用 Python 实现您的解决方案，并在以下测试套件上进行评估，其中每个元组编码为 $(N, p_b, p_a, \\mu_b, \\mu_a, c_{train}, seed)$：\n- 案例 A（强混淆，强伪影，弱生物信号）：$(4000, 50, 2, 0.3, 3.0, 0.95, 42)$。\n- 案例 B（无混淆，强生物信号）：$(4000, 50, 2, 1.5, 3.0, 0.5, 43)$。\n- 案例 C（部分混淆，生物信号主导）：$(4000, 50, 2, 1.5, 1.0, 0.7, 44)$。\n- 案例 D（完全混淆，无生物信号）：$(3000, 10, 10, 0.0, 2.0, 1.0, 45)$。\n- 案例 E（小样本，强混淆，强伪影）：$(800, 20, 1, 0.3, 2.5, 0.95, 46)$。\n\n您的程序必须产生单行输出，其中包含一个用方括号括起来的、逗号分隔的布尔值列表，表示每个案例是否检测到“Clever Hans”效应。例如，输出格式必须与以下完全一样：\n\"[True,False,True,False,True]\"\n\n不涉及物理单位。不涉及角度。当描述分数时，在代码中必须作为小数处理。\n\n约束条件：\n- 您必须通过对上述定义的正则化逻辑斯谛损失进行数值优化来实现训练。\n- 置换重要性必须通过在验证样本中联合置换组内所有特征来计算。\n- 去混淆测试集必须使用 $c_{test} = 0.5$，并且其大小必须与验证划分相同。\n- 仅可根据优化需要使用 Python 标准库、NumPy 和 SciPy。最终代码必须在没有用户输入的情况下运行，并且只打印所需的单行输出。", "solution": "该问题要求设计并实现一个程序，在一个模拟的生物学分类场景中检测“Clever Hans”效应。当预测模型利用了诸如实验批次伪影之类的伪相关性，而不是真实的生物信号来进行预测时，就会发生这种效应。解决方案包含三个阶段的过程：首先，生成模拟此现象的合成数据；其次，在此数据上训练一个分类器；第三，应用基于第一性原理的可解释性方法来诊断模型的行为。\n\n首先，我们形式化数据生成过程。我们考虑一个二元分类任务，其中每个样本 $i$ 都有一个真实的生物学标签 $y_i \\in \\{0, 1\\}$，该标签从参数为 0.5 的伯努利分布中抽取。每个样本还关联一个批次分配 $b_i \\in \\{0, 1\\}$。批次分配与生物学标签之间的相关性由一个混淆参数 $c \\in [0, 1]$ 控制，使得批次与标签匹配的概率为 $\\mathbb{P}(b_i = y_i) = c$。$c=0.5$ 的值表示无混淆（独立），而 $c=1.0$ 表示完全混淆。每个样本的特征向量 $x_i \\in \\mathbb{R}^{p_b + p_a}$ 由两部分组成：一个生物学特征向量 $x^{(bio)}_i \\in \\mathbb{R}^{p_b}$ 和一个批次伪影特征向量 $x^{(art)}_i \\in \\mathbb{R}^{p_a}$。生物学特征从一个类别条件高斯分布中抽取：$x^{(bio)}_i \\sim \\mathcal{N}(\\mu^{(bio)}(y_i), \\sigma^2 I)$，其中均值向量 $\\mu^{(bio)}(y_i)$ 取决于真实标签。具体来说，$\\mu^{(bio)}(1) = +\\mu_b \\cdot \\mathbf{1}$ 且 $\\mu^{(bio)}(0) = -\\mu_b \\cdot \\mathbf{1}$，其中 $\\mu_b$ 控制生物信号的强度。类似地，伪影特征从一个批次条件高斯分布中抽取：$x^{(art)}_i \\sim \\mathcal{N}(\\mu^{(art)}(b_i), \\sigma^2 I)$，其中均值 $\\mu^{(art)}(b_i)$ 取决于批次分配。此处，$\\mu^{(art)}(1) = +\\mu_a \\cdot \\mathbf{1}$ 且 $\\mu^{(art)}(0) = -\\mu_a \\cdot \\mathbf{1}$，其中 $\\mu_a$ 控制伪影信号的强度。最终的特征向量是拼接而成的 $x_i = [x^{(bio)}_i, x^{(art)}_i]$。\n\n其次，我们在生成的训练数据上训练一个逻辑斯谛回归分类器。模型通过最小化正则化的负对数似然（经验风险最小化的一种形式）来学习权重向量 $w \\in \\mathbb{R}^{p_b+p_a}$ 和偏置项 $b \\in \\mathbb{R}$。目标函数 $\\mathcal{L}(w, b)$，也称为带有 $\\ell_2$ 惩罚的逻辑斯谛损失或交叉熵损失，由下式给出：\n$$\n\\mathcal{L}(w,b) \\;=\\; \\sum_{i=1}^n \\left[-y_i \\log \\sigma(w^\\top x_i + b) - (1-y_i)\\log\\left(1-\\sigma(w^\\top x_i + b)\\right)\\right] \\;+\\; \\frac{\\lambda}{2}\\|w\\|_2^2\n$$\n此处，$\\sigma(z) = (1+e^{-z})^{-1}$ 是 sigmoid 函数，$\\lambda > 0$ 是正则化参数，用于惩罚较大的权重以防止过拟合。此优化问题是凸的，其最小值可以使用诸如 L-BFGS 的拟牛顿法高效地找到。为此，我们必须提供目标函数相对于参数的梯度。对于单个样本 $(x_i, y_i)$，损失项关于权重 $w$ 的梯度是 $(\\sigma(w^\\top x_i + b) - y_i)x_i$，关于偏置 $b$ 的梯度是 $(\\sigma(w^\\top x_i + b) - y_i)$。正则化项的梯度是 $\\lambda w$。对所有样本求和，即可得到优化中使用的完整梯度。\n\n第三，我们设计一个由两部分组成的准则来检测“Clever Hans”行为。\n第一部分衡量模型从混淆环境泛化到去混淆环境的失败程度。我们在两个集合上评估已训练模型的准确率：一个验证集，它与训练数据一样从相同的混淆分布（混淆度为 $c_{train}$）中抽取；以及一个测试集，它从批次伪影与标签独立的去混淆分布（$c_{test} = 0.5$）中抽取。准确率的显著下降，即 $\\mathrm{Acc}_{val} - \\mathrm{Acc}_{test} \\ge \\Delta$（其中 $\\Delta$ 是一个预定义阈值），表明模型学到了一个只在混淆环境中才有效的捷径。\n\n第二部分使用一种可解释性技术——置换特征重要性，来验证伪影特征确实是这种依赖性的来源。一个特征组 $G$ 的重要性，记为 $I(G)$，是指当这些特征与目标标签之间的关联被破坏时，模型在验证集上准确率的下降值。这是通过在验证集的所有样本中置换组 $G$ 内特征的值来实现的。其重要性即为 $I(G) = \\mathrm{Acc}_{val} - \\mathrm{Acc}_{\\pi_G(val)}$，其中 $\\mathrm{Acc}_{\\pi_G(val)}$ 是在特征被置换后的数据上的准确率。我们计算生物学特征组的重要性 $I(G_{bio})$ 和伪影特征组的重要性 $I(G_{art})$。如果模型是“Clever Hans”，它将更严重地依赖伪影特征。这种依赖性由条件 $I(G_{art}) \\ge I(G_{bio}) + \\epsilon$ 捕捉，其中 $\\epsilon > 0$ 是一个很小的边际，以确保差异是显著的。\n\n当且仅当两个条件都满足时，才正式检测到“Clever Hans”效应：模型表现出显著的泛化差距，并且其性能可证明地更依赖于伪影特征而非生物学特征。这种有原则的方法将性能评估与对模型内部逻辑的直接探查相结合，为诊断伪学习提供了一种稳健的方法。实现部分将系统地对每个指定的测试案例应用此程序，使用提供的参数和随机种子以确保可复现性。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Main function to run the \"Clever Hans\" detection analysis on a suite of test cases.\n    \"\"\"\n    test_cases = [\n        # (N, p_b, p_a, mu_b, mu_a, c_train, seed)\n        (4000, 50, 2, 0.3, 3.0, 0.95, 42),  # Case A\n        (4000, 50, 2, 1.5, 3.0, 0.5, 43),   # Case B\n        (4000, 50, 2, 1.5, 1.0, 0.7, 44),   # Case C\n        (3000, 10, 10, 0.0, 2.0, 1.0, 45),  # Case D\n        (800, 20, 1, 0.3, 2.5, 0.95, 46),    # Case E\n    ]\n\n    # Fixed parameters from the problem statement\n    LAMBDA = 1.0\n    EPSILON = 0.01\n    DELTA = 0.2\n    SIGMA = 1.0\n    TRAIN_FRAC = 0.6\n    C_TEST = 0.5\n\n    results = []\n    for params in test_cases:\n        result = _run_case(params, TRAIN_FRAC, C_TEST, SIGMA, LAMBDA, EPSILON, DELTA)\n        results.append(result)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef _generate_data(N, p_b, p_a, mu_b, mu_a, c, sigma, rng):\n    \"\"\"\n    Generates synthetic data according to the specified model.\n    \"\"\"\n    # 1. Draw biological labels\n    y = rng.binomial(1, 0.5, size=N)\n\n    # 2. Draw batch assignments based on confounding parameter c\n    u = rng.random(size=N)\n    b = np.where(u < c, y, 1 - y)\n\n    # 3. Generate biological features\n    mean_bio = np.where(y[:, np.newaxis] == 1, mu_b, -mu_b)\n    X_bio = mean_bio + rng.normal(0, sigma, size=(N, p_b))\n\n    # 4. Generate artifact features\n    mean_art = np.where(b[:, np.newaxis] == 1, mu_a, -mu_a)\n    X_art = mean_art + rng.normal(0, sigma, size=(N, p_a))\n    \n    # 5. Concatenate features\n    X = np.hstack([X_bio, X_art])\n    \n    return X, y\n\ndef _cost_function(theta, X, y, lambda_reg):\n    \"\"\"\n    Computes the regularized logistic loss.\n    \"\"\"\n    m = X.shape[0]\n    X_aug = np.hstack([X, np.ones((m, 1))])\n    z = X_aug @ theta\n    \n    # Sigmoid function, clipped for numerical stability\n    h = 1 / (1 + np.exp(-z))\n    h = np.clip(h, 1e-10, 1 - 1e-10)\n\n    log_loss = -np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n    reg_term = (lambda_reg / 2) * np.sum(theta[:-1]**2)\n\n    return log_loss + reg_term\n\ndef _gradient_function(theta, X, y, lambda_reg):\n    \"\"\"\n    Computes the gradient of the regularized logistic loss.\n    \"\"\"\n    m = X.shape[0]\n    X_aug = np.hstack([X, np.ones((m, 1))])\n    z = X_aug @ theta\n    h = 1 / (1 + np.exp(-z))\n    \n    error = h - y\n    grad = X_aug.T @ error\n    \n    # Add gradient of regularization term (bias is not regularized)\n    grad[:-1] += lambda_reg * theta[:-1]\n    \n    return grad\n\ndef _train_logistic_regression(X_train, y_train, lambda_reg):\n    \"\"\"\n    Trains a logistic regression model using L-BFGS optimization.\n    \"\"\"\n    d = X_train.shape[1]\n    theta_initial = np.zeros(d + 1)\n    \n    res = minimize(\n        _cost_function,\n        theta_initial,\n        args=(X_train, y_train, lambda_reg),\n        jac=_gradient_function,\n        method='L-BFGS-B'\n    )\n    return res.x\n\ndef _predict(X, theta):\n    \"\"\"\n    Makes predictions using the trained logistic regression model.\n    \"\"\"\n    m = X.shape[0]\n    X_aug = np.hstack([X, np.ones((m, 1))])\n    scores = X_aug @ theta\n    return (scores > 0).astype(int)\n\ndef _calculate_accuracy(y_true, y_pred):\n    \"\"\"\n    Calculates prediction accuracy.\n    \"\"\"\n    return np.mean(y_true == y_pred)\n\ndef _calculate_permutation_importance(X_val, y_val, theta, group_indices, rng):\n    \"\"\"\n    Calculates permutation importance for a given feature group.\n    \"\"\"\n    # Baseline accuracy\n    y_pred_val = _predict(X_val, theta)\n    acc_val = _calculate_accuracy(y_val, y_pred_val)\n\n    # Permuted accuracy\n    X_perm = X_val.copy()\n    n_val = X_val.shape[0]\n    \n    # Jointly permute the feature group columns across samples\n    perm_indices = rng.permutation(n_val)\n    X_perm[:, group_indices] = X_perm[perm_indices, :][:, group_indices]\n    \n    y_pred_perm = _predict(X_perm, theta)\n    acc_perm = _calculate_accuracy(y_val, y_pred_perm)\n    \n    return acc_val - acc_perm\n\ndef _run_case(params, train_frac, c_test, sigma, lambda_reg, epsilon, delta):\n    \"\"\"\n    Executes one full test case for \"Clever Hans\" detection.\n    \"\"\"\n    N, p_b, p_a, mu_b, mu_a, c_train, seed = params\n    rng = np.random.default_rng(seed)\n\n    # 1. Generate confounded data and split\n    X, y = _generate_data(N, p_b, p_a, mu_b, mu_a, c_train, sigma, rng)\n    n_train = int(N * train_frac)\n    X_train, y_train = X[:n_train], y[:n_train]\n    X_val, y_val = X[n_train:], y[n_train:]\n    n_val = X_val.shape[0]\n\n    # 2. Train the model\n    theta = _train_logistic_regression(X_train, y_train, lambda_reg)\n\n    # 3. Compute validation and test accuracies\n    y_pred_val = _predict(X_val, theta)\n    acc_val = _calculate_accuracy(y_val, y_pred_val)\n    \n    X_test, y_test = _generate_data(n_val, p_b, p_a, mu_b, mu_a, c_test, sigma, rng)\n    y_pred_test = _predict(X_test, theta)\n    acc_test = _calculate_accuracy(y_test, y_pred_test)\n\n    # 4. Compute permutation feature importances\n    bio_indices = list(range(p_b))\n    art_indices = list(range(p_b, p_b + p_a))\n    \n    imp_bio = _calculate_permutation_importance(X_val, y_val, theta, bio_indices, rng)\n    imp_art = _calculate_permutation_importance(X_val, y_val, theta, art_indices, rng)\n\n    # 5. Check for \"Clever Hans\" effect\n    cond1 = imp_art >= imp_bio + epsilon\n    cond2 = acc_val - acc_test >= delta\n    \n    is_clever_hans = cond1 and cond2\n    return is_clever_hans\n\nif __name__ == '__main__':\n    solve()\n```"}, {"introduction": "从理解模型的全局行为转向解释单个预测，“反事实解释”（counterfactual explanations）提出了一种有力的问题：“需要做出何种最小的改变，才能翻转模型的预测结果？” 本练习将这一概念应用于蛋白质工程的场景，挑战你找出一个能够将蛋白质功能从“活性”翻转为“非活性”的最小突变集合。这不仅是对模型进行深度质询，更是利用可解释机器学习来生成具体、可检验的生物学假设的直接实践。[@problem_id:2399979]", "id": "2399979", "problem": "给定一个用于蛋白质功能预测的离散、加性、基于序列的分类器，该分类器旨在为计算生物学和生物信息学领域中的可解释机器学习（ML）提供反事实解释支持。一个长度为 $L$、基于包含 $A$ 种氨基酸类别的字母表的蛋白质序列，由位置 $i \\in \\{0,1,\\dots,L-1\\}$ 上的索引 $x_i \\in \\{0,1,\\dots,A-1\\}$ 表示。序列 $x$ 的模型得分为\n$$\ns(x) \\;=\\; \\sum_{i=0}^{L-1} W_{i,\\,x_i} \\;+\\; b,\n$$\n其中 $W \\in \\mathbb{R}^{L \\times A}$ 是一个权重矩阵，$b \\in \\mathbb{R}$ 是一个标量偏置。如果 $s(x) \\ge 0$，则预测标签为“活性”，否则为“非活性”。单残基突变定义为在位置 $p$ 处，将 $x_p$ 替换为一个新的氨基酸索引 $a' \\in \\{0,1,\\dots,A-1\\}$，其中 $a' \\ne x_p$。一个突变集合必须作用于不同的位置。将一个突变集合应用于 $x$ 会产生一个突变后的序列 $x'$ 和一个新的得分 $s(x')$。\n\n您的任务是通过找到一个基数最小的突变集合，来计算一个最小反事实解释，该解释能将预测结果从“活性”翻转为“非活性”。如果原始序列已经是“非活性”，则最小集合为空集。如果没有任何突变集合能使序列变为“非活性”，则报告为不可能。\n\n为确保结果唯一的平局打破规则：\n- 在所有能达到“非活性”状态的突变集合中，选择突变数量最少的一个。\n- 在这些集合中，选择产生最小最终得分 $s(x')$（即最负的值）的一个。\n- 如果仍然存在平局，将突变集合表示为一个按 $p$ 升序排列的序对 $(p,a')$ 列表；在 $s(x')$ 相同的解中，通过比较 $(p,a')$ 序对（$p$ 升序，$a'$ 升序）来选择字典序最小的列表。\n\n所有索引（位置和氨基酸类别）必须使用从零开始的索引，并表示为整数。\n\n测试套件。对于下面的每个测试用例，$W$ 和 $b$ 指定了模型，并给出了序列 $x$。对于测试用例 $1$–$6$，使用相同的模型 $(W^{(1)}, b^{(1)})$，其长度 $L=5$，字母表大小 $A=4$：\n$$\nW^{(1)} \\;=\\;\n\\begin{bmatrix}\n2 & -1 & 0 & 1\\\\\n1 & 2 & -2 & 0\\\\\n0 & -1 & 3 & -2\\\\\n2 & 0 & -1 & -1\\\\\n-1 & 1 & 0 & 2\n\\end{bmatrix},\n\\qquad\nb^{(1)} \\;=\\; -1.\n$$\n对测试用例 $1$–$6$ 使用以下序列 $x$：\n- 测试用例 $1$：$x = [1,\\,1,\\,0,\\,0,\\,1]$。\n- 测试用例 $2$：$x = [1,\\,1,\\,0,\\,1,\\,2]$。\n- 测试用例 $3$：$x = [0,\\,0,\\,2,\\,0,\\,3]$。\n- 测试用例 $4$：$x = [0,\\,3,\\,0,\\,0,\\,0]$。\n- 测试用例 $5$：$x = [1,\\,0,\\,0,\\,1,\\,0]$。\n- 测试用例 $6$：$x = [2,\\,3,\\,0,\\,0,\\,1]$。\n\n对于测试用例 $7$，使用一个不同的模型 $(W^{(2)}, b^{(2)})$，其 $L=3$，$A=2$：\n$$\nW^{(2)} \\;=\\;\n\\begin{bmatrix}\n2 & 3\\\\\n1 & 4\\\\\n0 & 5\n\\end{bmatrix},\n\\qquad\nb^{(2)} \\;=\\; 0,\n$$\n及序列：\n- 测试用例 $7$：$x = [0,\\,0,\\,0]$。\n\n要求的最终输出格式。您的程序应生成单行输出，其中包含测试用例 $1$ 到 $7$ 的结果，形式为一个由方括号括起来的逗号分隔列表，每个测试用例的结果本身也是一个按如下方式编码的列表：\n- 如果无法翻转为“非活性”，则输出单元素列表 $[-1]$。\n- 如果原始序列已经是“非活性”，则输出单元素列表 $[0]$。\n- 否则，输出一个列表，以最小突变数 $m$ 开头，后跟 $2m$ 个整数，给出按 $p$ 升序排列的序对 $(p_1,a'_1),(p_2,a'_2),\\dots,(p_m,a'_m)$：即 $[m,\\,p_1,\\,a'_1,\\,p_2,\\,a'_2,\\,\\dots,\\,p_m,\\,a'_m]$。\n\n您的程序应生成单行输出，其中包含一个由七个测试用例列表组成的逗号分隔列表，并用方括号括起来（例如，$[[…],[…],…]$）。本问题无需外部输入，也不涉及物理单位或角度。每个测试用例的答案必须完全由上述定义确定。", "solution": "对问题陈述进行验证。\n\n### 第1步：提取已知信息\n- **模型：** 一个离散、加性、基于序列的分类器。\n- **序列表示：** 一个长度为 $L$、基于大小为 $A$ 的字母表的序列 $x$，由位置 $i \\in \\{0, 1, \\dots, L-1\\}$ 上的索引 $x_i \\in \\{0, 1, \\dots, A-1\\}$ 给出。\n- **得分函数：** $s(x) = \\sum_{i=0}^{L-1} W_{i, x_i} + b$，其中 $W \\in \\mathbb{R}^{L \\times A}$ 是一个权重矩阵，$b \\in \\mathbb{R}$ 是一个标量偏置。\n- **分类规则：** 如果 $s(x) \\ge 0$，序列为“活性”，否则为“非活性”。\n- **突变：** 在位置 $p$ 上的单残基突变，将 $x_p$ 替换为一个新索引 $a' \\in \\{0, 1, \\dots, A-1\\}$，其中 $a' \\ne x_p$。突变集合必须作用于不同的位置。\n- **目标：** 找到一个最小反事实解释，即一个基数最小的突变集合，它将“活性”序列转换为“非活性”序列。\n- **特殊情况：**\n    - 如果 $s(x) < 0$（已经是“非活性”），最小集合为空集。\n    - 如果没有任何突变集合能使 $s(x') < 0$，则任务不可能完成。\n- **平局打破规则：**\n    1.  选择基数（突变数量）最小的突变集合。\n    2.  在这些集合中，选择产生最小最终得分 $s(x')$ 的一个。\n    3.  如果仍然存在平局，将突变表示为序对 $(p, a')$，按位置 $p$ 排序，并选择此类序对列表的字典序最小者。\n- **提供的数据：**\n    - 测试用例 1-6：$L=5, A=4$。\n      $$W^{(1)} = \\begin{bmatrix} 2 & -1 & 0 & 1 \\\\ 1 & 2 & -2 & 0 \\\\ 0 & -1 & 3 & -2 \\\\ 2 & 0 & -1 & -1 \\\\ -1 & 1 & 0 & 2 \\end{bmatrix}, \\quad b^{(1)} = -1$$\n      序列：$x_1=[1,1,0,0,1]$, $x_2=[1,1,0,1,2]$, $x_3=[0,0,2,0,3]$, $x_4=[0,3,0,0,0]$, $x_5=[1,0,0,1,0]$, $x_6=[2,3,0,0,1]$。\n    - 测试用例 7：$L=3, A=2$。\n      $$W^{(2)} = \\begin{bmatrix} 2 & 3 \\\\ 1 & 4 \\\\ 0 & 5 \\end{bmatrix}, \\quad b^{(2)} = 0$$\n      序列：$x_7=[0,0,0]$。\n- **输出格式：**\n    - 一个单行的列表的列表，例如 `[[...],[...]]`。\n    - 对于不可能的情况，为 `[-1]`。\n    - 对于已经是“非活性”的序列，为 `[0]`。\n    - 对于成功的反事实解释，为 `[m, p_1, a'_1, ..., p_m, a'_m]`，按 $p_i$ 排序。\n\n### 第2步：使用提取的已知信息进行验证\n根据验证标准对问题进行评估：\n- **科学依据：** 所述模型为位置特异性评分矩阵（PSSM），是生物信息学中用于建模蛋白质域和DNA结合位点的标准和基础工具。反事实解释的概念是可解释机器学习的基石。因此，该问题在科学上是合理的，并与指定领域相关。\n- **适定性：** 该问题在一套清晰、分层的目标标准（基数、最终得分、字典序）下寻求一个最优解。这确保了唯一解的存在且定义明确。搜索空间是有限的，保证了可以通过算法找到解。\n- **客观性：** 该问题使用标准符号进行数学上的精确表述。所有术语都得到了明确的定义，并提供了测试用例所需的所有数据。语言是客观的，没有任何推测性或主观性陈述。\n\n该问题没有显示任何无效标志。它是自洽的、逻辑一致的，并且在计算上是可行的。\n\n### 第3步：结论与行动\n**结论：** 问题有效。\n**行动：** 继续提供解决方案。\n\n### 解决方案\n\n该问题要求找到一个基数最小的突变集合，以将蛋白质的分类从“活性”（$s(x) \\ge 0$）更改为“非活性”（$s(x') < 0$）。这是一个受一套严格的平局打破规则约束的优化问题。\n\n首先，我们分析单个突变的效果。序列 $x$ 的得分为 $s(x) = b + \\sum_{i=0}^{L-1} W_{i,x_i}$。在位置 $p$ 上进行一次突变，将氨基酸从 $x_p$ 变为 $a'$，会产生新序列 $x'$。$x'$ 的得分为 $s(x') = s(x) - W_{p,x_p} + W_{p,a'}$。因此，得分的变化量为 $\\Delta s = W_{p,a'} - W_{p,x_p}$。为了使序列变为非活性，我们必须使最终得分 $s(x') < 0$。这需要选择一个突变集合，其累积得分变化能将初始得分 $s(x)$ 降低到零以下。\n\n优化是分层的：\n1.  最小化突变数量 $|M|$。\n2.  最小化最终得分 $s(x')$。\n3.  最小化突变集合的字典序表示。\n\n这种结构允许采用贪心方法。为了最小化突变数量，我们应首先应用最有效的突变——即那些能提供最大得分降幅的突变。\n\n整体算法如下：\n\n1.  **计算初始得分：** 计算给定序列 $x$ 的初始得分 $s(x)$。如果 $s(x) < 0$，则序列已经是“非活性”，任务完成，结果为空突变集。\n\n2.  **识别最优单点突变：** 对于每个位置 $p \\in \\{0, 1, \\dots, L-1\\}$，我们确定最佳的单个突变。突变由新的氨基酸索引 $a' \\in \\{0, 1, \\dots, A-1\\}$ 定义，其中 $a' \\ne x_p$。“最佳”突变是能使得分最小化的突变，这对应于使权重 $W_{p,a'}$ 最小的 $a'$。\n    - 如果多个 $a'$ 选项产生相同的最小权重，平局打破规则要求选择字典序最小的突变列表，这意味着选择最小的索引 $a'$。\n    - 设该位置 $p$ 的最优新氨基酸为 $a'_p$，相应的得分变化为 $\\Delta_p = W_{p,a'_p} - W_{p,x_p}$。\n    - 我们只考虑能降低得分的突变，因此只考虑 $\\Delta_p < 0$ 的位置。这些是“有益”的突变。\n\n3.  **创建并排序潜在突变列表：** 我们编制一个包含所有此类有益的“各位置最佳”突变的列表。列表中的每个元素都是一个元组，包含得分变化、位置和新氨基酸：$(\\Delta_p, p, a'_p)$。如果不存在这样的有益突变，就无法降低得分，问题无解。\n\n4.  **贪心选择：** 为了满足优化标准，我们必须对该列表进行排序。要在固定突变数量下最小化最终得分，我们必须选择具有最大负值 $\\Delta_p$ 的突变。为了打破得分平局并满足字典序要求，我们应优先选择位置索引 $p$ 较小的突变。因此，我们按 $\\Delta_p$ 为主键、$p$ 为次键的升序对潜在突变列表进行排序。\n\n5.  **迭代应用突变：** 我们遍历排序后的列表，一次应用一个突变。我们将突变的得分变化 $\\Delta_p$ 加到当前总分上，并将突变 $(p, a'_p)$ 添加到我们的解集中。每次添加后，我们检查当前得分是否已降至 $0$ 以下。当此条件首次满足时，我们就找到了解。这种贪心策略保证能找到基数最小的解，因为我们总是在使用最有效的可用突变。它还能为该基数产生可能的最小得分。排序顺序确保了在得分平局时满足字典序要求。\n\n6.  **格式化输出：** 一旦找到最小突变集合，我们按位置 $p$ 对其进行排序，并根据问题规范进行格式化：$[m, p_1, a'_1, \\dots, p_m, a'_m]$，其中 $m$ 是突变数量。如果初始序列为非活性，输出为 `[0]`。如果找不到解，输出为 `[-1]`。\n\n这个系统性步骤正确地处理了问题的约束，并得出了唯一的、最优的反事实解释。", "answer": "```python\nimport numpy as np\n\ndef list_to_str(lst):\n    \"\"\"Converts a list of integers to a string format '[i1,i2,...]'.\"\"\"\n    return f\"[{','.join(map(str, lst))}]\"\n\ndef find_counterfactual(W, b, x):\n    \"\"\"\n    Finds the minimal counterfactual explanation for a given sequence.\n    \"\"\"\n    L, A = W.shape\n    \n    # Step 1: Calculate initial score\n    current_score = b + sum(W[i, x[i]] for i in range(L))\n    \n    if current_score < 0:\n        return [0]\n    \n    # Step 2 & 3: Identify and collect best beneficial mutations for each position\n    potential_mutations = []\n    for p in range(L):\n        original_aa = x[p]\n        original_weight = W[p, original_aa]\n        \n        best_mut_aa = -1\n        min_weight = float('inf')\n        \n        for a_prime in range(A):\n            if a_prime == original_aa:\n                continue\n            \n            if W[p, a_prime] < min_weight:\n                min_weight = W[p, a_prime]\n                best_mut_aa = a_prime\n            # Tie-breaking rule: choose smallest a' for same weight\n            elif W[p, a_prime] == min_weight:\n                if a_prime < best_mut_aa:\n                    best_mut_aa = a_prime\n                    \n        delta = min_weight - original_weight\n        \n        if delta < 0:\n            potential_mutations.append((delta, p, best_mut_aa))\n            \n    if not potential_mutations:\n        return [-1]\n\n    # Step 4: Sort potential mutations\n    # Primary key: delta (ascending), Secondary key: position p (ascending)\n    potential_mutations.sort(key=lambda item: (item[0], item[1]))\n    \n    # Step 5: Greedily apply mutations\n    mutations_applied = []\n    final_score = current_score\n    \n    for delta, p, a_prime in potential_mutations:\n        final_score += delta\n        mutations_applied.append((p, a_prime))\n        \n        if final_score < 0:\n            break\n    \n    # If loop finishes and score is still not negative, it's impossible\n    if final_score >= 0:\n        return [-1]\n        \n    # Step 6: Format the output\n    mutations_applied.sort(key=lambda item: item[0]) # Sort by position\n    \n    m = len(mutations_applied)\n    result = [m]\n    for p, a_prime in mutations_applied:\n        result.extend([p, a_prime])\n        \n    return result\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    # Test cases definition\n    W1 = np.array([\n        [2, -1, 0, 1],\n        [1, 2, -2, 0],\n        [0, -1, 3, -2],\n        [2, 0, -1, -1],\n        [-1, 1, 0, 2]\n    ])\n    b1 = -1.0\n    \n    x_sequences_1 = [\n        np.array([1, 1, 0, 0, 1]), # TC1\n        np.array([1, 1, 0, 1, 2]), # TC2\n        np.array([0, 0, 2, 0, 3]), # TC3\n        np.array([0, 3, 0, 0, 0]), # TC4\n        np.array([1, 0, 0, 1, 0]), # TC5\n        np.array([2, 3, 0, 0, 1]), # TC6\n    ]\n\n    W2 = np.array([\n        [2, 3],\n        [1, 4],\n        [0, 5]\n    ])\n    b2 = 0.0\n    x_sequence_2 = np.array([0, 0, 0]) # TC7\n    \n    test_cases = []\n    for x in x_sequences_1:\n        test_cases.append((W1, b1, x))\n    test_cases.append((W2, b2, x_sequence_2))\n    \n    results = []\n    for W, b, x in test_cases:\n        result = find_counterfactual(W, b, x)\n        results.append(result)\n    \n    # Format the final output string\n    all_results_str = [list_to_str(res) for res in results]\n    print(f\"[{','.join(all_results_str)}]\")\n\nsolve()\n```"}]}