{"hands_on_practices": [{"introduction": "第一个练习将带你深入了解循环神经网络（RNN）内部的“齿轮”是如何运转的。我们将构建一个参数被精确定义的极简 RNN，来完成寻找互补 DNA 链的任务。通过追踪计算过程，你将亲眼见证权重矩阵如何编码一个基本的生物学规则——沃森-克里克碱基配对，从而揭开这些网络一步步处理信息的神秘面纱 [@problem_id:2425719]。", "problem": "考虑使用循环神经网络 (RNN) 为给定的脱氧核糖核酸 (DNA) 单链预测其互补链的任务。DNA 字母表由核苷酸 $\\mathrm{A}$、$\\mathrm{C}$、$\\mathrm{G}$ 和 $\\mathrm{T}$ 组成。定义索引映射 $\\mathrm{A} \\mapsto 0$、$\\mathrm{C} \\mapsto 1$、$\\mathrm{G} \\mapsto 2$ 和 $\\mathrm{T} \\mapsto 3$。Watson–Crick 互补配对映射由函数 $\\mathrm{comp}:\\{0,1,2,3\\}\\to\\{0,1,2,3\\}$ 给出，定义为 $\\mathrm{comp}(0)=3$、$\\mathrm{comp}(1)=2$、$\\mathrm{comp}(2)=1$ 和 $\\mathrm{comp}(3)=0$。\n\n设模型为一个离散时间的 Elman RNN，其隐藏状态维度为 $4$，并在每个位置上对 $4$ 个符号进行分类输出。对于一个长度为 $T$ 的序列，设位置 $t$ 上的独热 (one-hot) 输入为 $x_t \\in \\mathbb{R}^4$，隐藏状态为 $h_t \\in \\mathbb{R}^4$，softmax 前的输出 (logits) 为 $o_t \\in \\mathbb{R}^4$，输出概率向量为 $p_t \\in \\mathbb{R}^4$。其循环和输出方程为\n$$\nh_t = \\tanh\\!\\left(W_{xh} x_t + W_{hh} h_{t-1} + b_h\\right), \\quad o_t = W_{hy} h_t + b_y, \\quad p_t = \\mathrm{softmax}(o_t),\n$$\n初始隐藏状态为 $h_0 = \\mathbf{0}_4$。双曲正切函数 $\\tanh(\\cdot)$ 逐元素作用，softmax 定义为\n$$\n\\mathrm{softmax}(o)_k = \\frac{e^{o_k}}{\\sum_{j=1}^{4} e^{o_j}},\n$$\n其中 $k \\in \\{1,2,3,4\\}$ 为输出分量的索引。\n\n所有模型参数都是固定的，如下所示：\n- 输入到隐藏层的权重 $W_{xh} \\in \\mathbb{R}^{4 \\times 4}$ 是单位矩阵：$W_{xh} = I_4$。\n- 隐藏层到隐藏层的权重 $W_{hh} \\in \\mathbb{R}^{4 \\times 4}$ 全为零：$W_{hh} = 0_{4 \\times 4}$。\n- 隐藏层偏置 $b_h \\in \\mathbb{R}^{4}$ 全为零：$b_h = \\mathbf{0}_4$。\n- 隐藏层到输出层的权重 $W_{hy} \\in \\mathbb{R}^{4 \\times 4}$ 由以下条目定义\n$$\n\\left(W_{hy}\\right)_{j,i} = \\begin{cases}\n2 & \\text{if } j = \\mathrm{comp}(i),\\\\\n0 & \\text{otherwise},\n\\end{cases}\n$$\n对于所有 $i \\in \\{0,1,2,3\\}$ 和 $j \\in \\{0,1,2,3\\}$，其中行和列分别由输出和输入核苷酸的整数编码索引。\n- 输出偏置 $b_y \\in \\mathbb{R}^{4}$ 全为零：$b_y = \\mathbf{0}_4$。\n\n对于任意输入序列 $(x_1,\\dots,x_T)$，在每个时间步 $t$，预测的符号索引 $\\hat{y}_t$ 定义为输出分布的最大化者，\n$$\n\\hat{y}_t = \\arg\\max_{k \\in \\{0,1,2,3\\}} \\, p_t[k].\n$$\n程序必须独立处理每个测试序列，对每个序列都将 $h_0$ 重置为 $\\mathbf{0}_4$。每个测试用例的最终答案必须是整数索引列表 $[\\hat{y}_1,\\ldots,\\hat{y}_T]$。\n\n使用以下输入序列测试套件，这些序列使用映射 $\\mathrm{A} \\mapsto 0$、$\\mathrm{C} \\mapsto 1$、$\\mathrm{G} \\mapsto 2$、$\\mathrm{T} \\mapsto 3$ 表示为索引编码列表：\n- 用例 $1$ (使用所有符号的一般情况)：$[0,1,2,3]$。\n- 用例 $2$ (边界情况：长度为 $1$)：$[0]$。\n- 用例 $3$ (边缘情况：均聚物)：$[2,2,2,2]$。\n- 用例 $4$ (交替模式)：$[0,3,0,3]$。\n- 用例 $5$ (互补下的回文模式)：$[1,2,1,2]$。\n\n您的程序应生成单行输出，其中包含结果，格式为方括号括起来的逗号分隔列表，其中每个元素对应于给定顺序的一个测试用例，并且本身是一个带方括号的、逗号分隔的整数列表。例如，整体结构必须为 `[[...],[...],[...],[...],[...]]` 形式。不涉及物理单位，也不需要角度或百分比。每个测试用例的输出必须是指定的整数列表。", "solution": "RNN 由给定的参数值完全确定。目标是对于给定输入序列中的每个位置 $t$，使用模型方程和 $\\arg\\max$ 决策规则来确定预测的类别索引 $\\hat{y}_t \\in \\{0,1,2,3\\}$。\n\n首先，根据给定的索引映射 $\\mathrm{A} \\mapsto 0$、$\\mathrm{C} \\mapsto 1$、$\\mathrm{G} \\mapsto 2$、$\\mathrm{T} \\mapsto 3$，将每个输入核苷酸编码为独热 (one-hot) 向量 $x_t \\in \\mathbb{R}^4$。因此，如果时间 $t$ 处的核苷酸索引为 $i \\in \\{0,1,2,3\\}$，则 $x_t$ 在第 $i$ 个位置为 $1$，其他位置为 $0$。\n\n隐藏状态的递推关系为\n$$\nh_t = \\tanh\\!\\left(W_{xh} x_t + W_{hh} h_{t-1} + b_h\\right),\n$$\n其中 $h_0 = \\mathbf{0}_4$。使用所提供的参数 $W_{xh} = I_4$、$W_{hh} = 0_{4\\times 4}$ 和 $b_h = \\mathbf{0}_4$，该式简化为\n$$\nh_t = \\tanh\\!\\left(I_4 \\, x_t\\right) = \\tanh(x_t).\n$$\n由于 $x_t$ 是独热向量，$\\tanh$ 逐元素作用，产生一个向量，其在活动索引处有一个等于 $\\tanh(1)$ 的非零项，其他位置均为零。记 $c \\triangleq \\tanh(1)$，其中 $c \\in (0,1)$，数值上 $c \\approx 0.76159$，不过决策规则的推导并不需要其精确值。\n\nlogits 为\n$$\no_t = W_{hy} h_t + b_y = W_{hy} h_t,\n$$\n因为 $b_y = \\mathbf{0}_4$。根据 $W_{hy}$ 的定义，对于时间 $t$ 的输入索引 $i$，隐藏状态 $h_t$ 满足 $h_t[i] = c$ 且当 $k \\neq i$ 时 $h_t[k] = 0$。因此，第 $j$ 个 logit 为\n$$\no_t[j] = \\sum_{k=0}^{3} (W_{hy})_{j,k} \\, h_t[k] = (W_{hy})_{j,i} \\, c = \\begin{cases}\n2c & \\text{if } j = \\mathrm{comp}(i),\\\\\n0 & \\text{otherwise}.\n\\end{cases}\n$$\n因此，softmax 概率满足\n$$\np_t[j] = \\frac{e^{o_t[j]}}{\\sum_{\\ell=0}^{3} e^{o_t[\\ell]}} = \\begin{cases}\n\\displaystyle \\frac{e^{2c}}{3 + e^{2c}} & \\text{if } j = \\mathrm{comp}(i),\\\\\n\\displaystyle \\frac{1}{3 + e^{2c}} & \\text{otherwise}.\n\\end{cases}\n$$\n因为 $c > 0$，所以 $2c > 0$，因此 $e^{2c} > 1$，这意味着对于任何 $j \\neq \\mathrm{comp}(i)$，$p_t[\\mathrm{comp}(i)]$ 都严格大于 $p_t[j]$。因此，$\\arg\\max$ 决策产生\n$$\n\\hat{y}_t = \\arg\\max_{j \\in \\{0,1,2,3\\}} p_t[j] = \\mathrm{comp}(i).\n$$\n\n这表明，对于位置 $t$ 的每个输入符号索引 $i$，预测的输出索引 $\\hat{y}_t$ 等于其 Watson–Crick 互补索引 $\\mathrm{comp}(i)$，并且与之前的位置无关，因为 $W_{hh} = 0_{4 \\times 4}$ 和 $b_h = \\mathbf{0}_4$ 消除了时间依赖性。\n\n将此规则应用于每个测试序列：\n\n- 用例 1：输入 $[0,1,2,3]$ 通过 $\\mathrm{comp}$ 逐元素映射到 $[3,2,1,0]$。\n- 用例 2：输入 $[0]$ 映射到 $[3]$。\n- 用例 3：输入 $[2,2,2,2]$ 映射到 $[1,1,1,1]$。\n- 用例 4：输入 $[0,3,0,3]$ 映射到 $[3,0,3,0]$。\n- 用例 5：输入 $[1,2,1,2]$ 映射到 $[2,1,2,1]$。\n\n程序必须用给定的参数实现所述的 RNN 方程，对每个测试序列独立处理（$h_0 = \\mathbf{0}_4$），通过在 softmax 输出上（等价地，由于单调性，在 logits 上）取 $\\arg\\max$ 来计算每个位置的 $\\hat{y}_t$，并按规定格式将预测的索引序列列表打印在单个方括号行中。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef rnn_predict(sequences):\n    # Define dimensions\n    num_symbols = 4  # A, C, G, T\n    hidden_size = 4\n\n    # Define parameter matrices and vectors as specified\n    W_xh = np.eye(num_symbols)  # 4x4 identity\n    W_hh = np.zeros((hidden_size, hidden_size))  # 4x4 zeros\n    b_h = np.zeros(hidden_size)  # 4 zeros\n\n    # Define complement mapping: A->T, C->G, G->C, T->A with indices 0,1,2,3\n    comp = {0: 3, 1: 2, 2: 1, 3: 0}\n\n    # Hidden-to-output weights: (W_hy)_{j,i} = 2 if j == comp(i) else 0\n    W_hy = np.zeros((num_symbols, hidden_size))\n    for i in range(num_symbols):\n        j = comp[i]\n        W_hy[j, i] = 2.0\n    b_y = np.zeros(num_symbols)  # 4 zeros\n\n    results = []\n    for seq in sequences:\n        # Reset hidden state for each sequence\n        h = np.zeros(hidden_size)\n        pred_seq = []\n        for idx in seq:\n            # One-hot encode input symbol\n            x = np.zeros(num_symbols)\n            x[idx] = 1.0\n\n            # RNN forward step\n            h = np.tanh(W_xh.dot(x) + W_hh.dot(h) + b_h)\n            o = W_hy.dot(h) + b_y  # logits\n            # Argmax over logits equals argmax over softmax\n            y_hat = int(np.argmax(o))\n            pred_seq.append(y_hat)\n        results.append(pred_seq)\n    return results\n\ndef format_list_no_spaces(obj):\n    if isinstance(obj, list):\n        return \"[\" + \",\".join(format_list_no_spaces(el) for el in obj) + \"]\"\n    else:\n        return str(obj)\n\ndef solve():\n    # Define the test cases from the problem statement (index-coded sequences)\n    test_cases = [\n        [0, 1, 2, 3],      # Case 1\n        [0],               # Case 2\n        [2, 2, 2, 2],      # Case 3\n        [0, 3, 0, 3],      # Case 4\n        [1, 2, 1, 2],      # Case 5\n    ]\n\n    results = rnn_predict(test_cases)\n\n    # Final print statement in the exact required format (single line, no spaces).\n    print(format_list_no_spaces(results))\n\nsolve()\n```", "id": "2425719"}, {"introduction": "在掌握基础之后，这个实践将探索“循环”的核心概念及其带来的特性：记忆。你将模拟移码突变对 DNA 序列的影响，并追踪这个单一的改变如何导致 RNN 的内部隐藏状态 $h_t$ 随时间推移而发散。这个练习提供了一个强有力的类比，展示了 RNN 如何对序列依赖性进行建模，以及它们对扰动的敏感性，这正如同此类突变在生物学上造成的重大影响 [@problem_id:2425716]。", "problem": "给定一个简化的循环神经网络（Recurrent Neural Network, RNN）模型，用于对基于字母表 $\\{\\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T}\\}$ 的脱氧核糖核酸（DNA）核苷酸序列进行序列分析。每个核苷酸通过标准基映射为 $\\mathbb{R}^{4}$ 中的一个独热向量：$\\mathrm{A}\\mapsto (1,0,0,0)^{\\top}$，$\\mathrm{C}\\mapsto (0,1,0,0)^{\\top}$，$\\mathrm{G}\\mapsto (0,0,1,0)^{\\top}$，$\\mathrm{T}\\mapsto (0,0,0,1)^{\\top}$。该 RNN 的隐藏维度为 $d_{h}=3$，输入维度为 $d_{x}=4$，并使用以下递推关系\n$$\nh_{0}=\\mathbf{0}\\in\\mathbb{R}^{3},\\quad h_{t}=\\tanh\\!\\left(W_{x}\\,x_{t}+W_{h}\\,h_{t-1}+b\\right)\\in\\mathbb{R}^{3}\\quad \\text{for } t=1,2,\\dots,T,\n$$\n其中 $x_{t}\\in\\mathbb{R}^{4}$ 是序列中第 $t$ 个核苷酸的独热编码，$W_{x}\\in\\mathbb{R}^{3\\times 4}$、$W_{h}\\in\\mathbb{R}^{3\\times 3}$ 和 $b\\in\\mathbb{R}^{3}$ 是固定参数，$\\tanh(\\cdot)$ 按元素作用。通过 logistic sigmoid 函数 $\\sigma(z)=\\frac{1}{1+e^{-z}}$，从最终的隐藏状态获得一个标量函数预测值：\n$$\n\\hat{y}=\\sigma\\!\\left(w^{\\top} h_{T}+b_{y}\\right),\\quad w\\in\\mathbb{R}^{3},\\ b_{y}\\in\\mathbb{R}.\n$$\n移码突变被建模为在原始序列的指定位置 $m$ 处的单核苷酸插入或删除。设原始序列长度为 $T$，突变序列长度为 $T'$。我们如下定义突变序列：\n- 对于在位置 $m$（位置从1开始索引）插入一个核苷酸 $u\\in\\{\\mathrm{A},\\mathrm{C},\\mathrm{G},\\mathrm{T}\\}$，新的核苷酸 $u$ 被立即插入到原始序列的位置 $m$ 之后，得到的长度为 $T'=T+1$。\n- 对于在位置 $m$ 的删除，原本在位置 $m$ 的核苷酸被移除，得到的长度为 $T'=T-1$。\n对原始序列和突变序列，使用相同的 RNN 参数和初始化 $h_{0}=\\mathbf{0}$，计算它们的隐藏状态序列 $\\{h_{t}^{\\text{orig}}\\}_{t=1}^{T}$ 和 $\\{h_{t}^{\\text{mut}}\\}_{t=1}^{T'}$。通过欧几里得距离定义突变点之后的隐藏状态差异\n$$\nd_{t}=\\left\\|h_{t}^{\\text{mut}}-h_{t}^{\\text{orig}}\\right\\|_{2}\\quad \\text{for } t=m,m+1,\\dots,\\min(T,T').\n$$\n如果 $m>\\min(T,T')$，则将下面的平均值定义为 $0$。设平均突变后隐藏状态差异为\n$$\n\\overline{D}=\\begin{cases}\n\\frac{1}{\\min(T,T')-m+1}\\displaystyle\\sum_{t=m}^{\\min(T,T')} d_{t}, & \\text{if } m \\le \\min(T,T') \\\\[2ex]\n0, & \\text{if } m > \\min(T,T')\n\\end{cases}\n$$\n设函数预测值为 $\\hat{y}^{\\text{orig}}=\\sigma\\!\\left(w^{\\top} h_{T}^{\\text{orig}}+b_{y}\\right)$ 和 $\\hat{y}^{\\text{mut}}=\\sigma\\!\\left(w^{\\top} h_{T'}^{\\text{mut}}+b_{y}\\right)$。对于给定的加权参数 $\\lambda>0$，定义功能扰动指数\n$$\nF=\\left|\\hat{y}^{\\text{mut}}-\\hat{y}^{\\text{orig}}\\right|+\\lambda\\,\\overline{D}.\n$$\n使用以下固定的 RNN 参数：\n$$\nW_{x}=\\begin{bmatrix}\n0.5 & -0.3 & 0.8 & -0.1\\\\\n-0.2 & 0.7 & -0.5 & 0.4\\\\\n0.3 & 0.1 & -0.4 & 0.6\n\\end{bmatrix},\\quad\nW_{h}=\\begin{bmatrix}\n0.2 & 0.1 & -0.3\\\\\n-0.4 & 0.5 & 0.2\\\\\n0.3 & -0.6 & 0.1\n\\end{bmatrix},\\quad\nb=\\begin{bmatrix}0.01\\\\ -0.02\\\\ 0.03\\end{bmatrix},\n$$\n$$\nw=\\begin{bmatrix}0.4\\\\ -0.7\\\\ 0.2\\end{bmatrix},\\quad b_{y}=-0.1,\\quad \\lambda=0.35.\n$$\n你的任务是为以下每个测试用例计算 $F$。在每个用例中，序列仅由 $\\{\\mathrm{A},\\mathrm{C},\\mathrm{G},\\mathrm{T}\\}$ 中的字符组成，位置 $m$ 从1开始索引，插入操作为“在位置 $m$ 后立即插入”。对于删除操作，移除位置 $m$ 处的字符。测试套件如下：\n- 用例 1（一般情况）：原始序列 $S=\\text{\"ATGGCCATTGTA\"}$，在 $m=5$ 处插入 $u=\\text{\"A\"}$。\n- 用例 2（起始边界）：原始序列 $S=\\text{\"ATGCGT\"}$，在 $m=1$ 处删除。\n- 用例 3（在末尾位置插入）：原始序列 $S=\\text{\"CCGTAACG\"}$，在 $m=8$ 处插入 $u=\\text{\"T\"}$。\n- 用例 4（在末尾位置删除，m 之后无重叠索引）：原始序列 $S=\\text{\"GATTACA\"}$，在 $m=7$ 处删除。\n所有计算必须严格遵循上述定义。不使用角度。没有物理单位。每个结果都必须是一个实数。你的程序应产生单行输出，其中包含四个 $F$ 值（按用例1到4的顺序）的逗号分隔列表，每个值都四舍五入到小数点后六位，并用方括号括起来；例如，$\\text{[}r_{1},r_{2},r_{3},r_{4}\\text{]}$，其中每个 $r_{i}$ 都格式化为六位小数。", "solution": "所提出的问题是有效的。这是一个定义明确的计算任务，基于循环神经网络（RNN）应用于计算生物学中序列分析的既定原则。模型、参数和分析指标都以数学精度指定，具有科学依据，并构成一个独立的、可解决的问题。我将开始进行解答。\n\n任务是计算一个简化的 RNN 在 DNA 序列中经受特定移码突变后的功能扰动指数 $F$。解决方案需要直接实现所提供的数学模型。该过程分为几个计算步骤，并为每个测试用例执行这些步骤。\n\n首先，我们定义网络的常量参数。独热编码将字母表 $\\{\\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T}\\}$ 中的每个核苷酸映射到 $\\mathbb{R}^{4}$ 中的一个标准基向量。\n- $\\mathrm{A} \\mapsto [1, 0, 0, 0]^{\\top}$\n- $\\mathrm{C} \\mapsto [0, 1, 0, 0]^{\\top}$\n- $\\mathrm{G} \\mapsto [0, 0, 1, 0]^{\\top}$\n- $\\mathrm{T} \\mapsto [0, 0, 0, 1]^{\\top}$\n\nRNN 的固定参数是权重矩阵 $W_{x}\\in\\mathbb{R}^{3\\times 4}$ 和 $W_{h}\\in\\mathbb{R}^{3\\times 3}$，以及偏置向量 $b\\in\\mathbb{R}^{3}$。输出层的参数是权重向量 $w\\in\\mathbb{R}^{3}$ 和标量偏置 $b_{y}\\in\\mathbb{R}$。隐藏状态差异的贡献由 $\\lambda = 0.35$ 加权。\n\n$W_{x}=\\begin{bmatrix} 0.5 & -0.3 & 0.8 & -0.1 \\\\ -0.2 & 0.7 & -0.5 & 0.4 \\\\ 0.3 & 0.1 & -0.4 & 0.6 \\end{bmatrix}$，$W_{h}=\\begin{bmatrix} 0.2 & 0.1 & -0.3 \\\\ -0.4 & 0.5 & 0.2 \\\\ 0.3 & -0.6 & 0.1 \\end{bmatrix}$，$b=\\begin{bmatrix} 0.01 \\\\ -0.02 \\\\ 0.03 \\end{bmatrix}$\n$w=\\begin{bmatrix} 0.4 \\\\ -0.7 \\\\ 0.2 \\end{bmatrix}$，$b_{y}=-0.1$\n\n模型的核心是隐藏状态 $h_t \\in \\mathbb{R}^3$ 的递推关系：\n$$h_{t}=\\tanh\\!\\left(W_{x}\\,x_{t}+W_{h}\\,h_{t-1}+b\\right)$$\n此计算以迭代方式执行，从初始隐藏状态 $h_0 = \\mathbf{0} \\in \\mathbb{R}^3$ 开始。对于一个长度为 $T$ 的给定输入序列，此过程会生成一个隐藏状态序列 $\\{h_t\\}_{t=1}^{T}$。$\\tanh$ 函数是按元素应用的。\n\n对于每个测试用例，我们必须首先确定原始序列 $S^{\\text{orig}}$ 和突变序列 $S^{\\text{mut}}$。突变是在一个从1开始索引的位置 $m$ 之后插入核苷酸 $u$，或删除位置 $m$ 处的核苷酸。\n\n随后，我们对 $S^{\\text{orig}}$ 和 $S^{\\text{mut}}$ 应用 RNN 前向传播，以获得它们各自的隐藏状态序列 $\\{h_{t}^{\\text{orig}}\\}_{t=1}^{T}$ 和 $\\{h_{t}^{\\text{mut}}\\}_{t=1}^{T'}$。\n\n下一步是计算平均突变后隐藏状态差异 $\\overline{D}$。该度量量化了突变如何导致 RNN 的内部表示偏离原始表示。其定义如下：\n$$\n\\overline{D}=\\begin{cases}\n\\frac{1}{\\min(T,T')-m+1}\\displaystyle\\sum_{t=m}^{\\min(T,T')} \\left\\|h_{t}^{\\text{mut}}-h_{t}^{\\text{orig}}\\right\\|_{2}, & \\text{if } m \\le \\min(T,T') \\\\[2ex]\n0, & \\text{if } m > \\min(T,T')\n\\end{cases}\n$$\n求和的范围是从突变点 $m$ 开始到较短序列末尾的索引。范数 $\\left\\|\\cdot\\right\\|_{2}$ 是标准欧几里得距离。注意，在实现中，问题中的序列索引（基于1）必须转换为数组索引（基于0），因此 $h_t$ 对应于状态列表中索引为 $t-1$ 的元素。\n\n然后，我们分别从最终的隐藏状态 $h_{T}^{\\text{orig}}$ 和 $h_{T'}^{\\text{mut}}$ 计算标量预测值 $\\hat{y}^{\\text{orig}}$ 和 $\\hat{y}^{\\text{mut}}$。该计算使用 logistic sigmoid 函数 $\\sigma(z) = (1+e^{-z})^{-1}$：\n$$\\hat{y}^{\\text{orig}}=\\sigma\\!\\left(w^{\\top} h_{T}^{\\text{orig}}+b_{y}\\right)$$\n$$\\hat{y}^{\\text{mut}}=\\sigma\\!\\left(w^{\\top} h_{T'}^{\\text{mut}}+b_{y}\\right)$$\n\n最后，功能扰动指数 $F$ 由预测值的绝对差和加权平均差异组合而成：\n$$F=\\left|\\hat{y}^{\\text{mut}}-\\hat{y}^{\\text{orig}}\\right|+\\lambda\\,\\overline{D}$$\n\n这整个过程被实现并应用于四个指定的测试用例。该逻辑正确处理了边界条件，例如序列开始或结束处的突变，以及在用例4中遇到的当 $m > \\min(T, T')$ 时 $\\overline{D}$ 的特殊情况。最终的数值结果按要求四舍五入到六位小数。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# No other libraries are permitted.\n\ndef solve():\n    \"\"\"\n    Main function to solve the RNN mutation analysis problem.\n    It sets up the model parameters, defines test cases, and computes\n    the functional perturbation index F for each case.\n    \"\"\"\n    \n    # ------------------ Fixed RNN Parameters ------------------ #\n    # Weight matrix for input-to-hidden connections\n    Wx = np.array([\n        [0.5, -0.3, 0.8, -0.1],\n        [-0.2, 0.7, -0.5, 0.4],\n        [0.3, 0.1, -0.4, 0.6]\n    ])\n    \n    # Weight matrix for hidden-to-hidden connections\n    Wh = np.array([\n        [0.2, 0.1, -0.3],\n        [-0.4, 0.5, 0.2],\n        [0.3, -0.6, 0.1]\n    ])\n    \n    # Bias vector for the hidden layer\n    b = np.array([0.01, -0.02, 0.03]).reshape(3, 1)\n    \n    # Weight vector for the output layer\n    w = np.array([0.4, -0.7, 0.2]).reshape(3, 1)\n    \n    # Bias for the output layer\n    by = -0.1\n    \n    # Weighting parameter for the divergence term\n    lambda_param = 0.35\n\n    # ------------------ Encoding and Helper Functions ------------------ #\n    # One-hot encoding map for DNA nucleotides\n    dna_map = {\n        'A': np.array([1, 0, 0, 0]).reshape(4, 1),\n        'C': np.array([0, 1, 0, 0]).reshape(4, 1),\n        'G': np.array([0, 0, 1, 0]).reshape(4, 1),\n        'T': np.array([0, 0, 0, 1]).reshape(4, 1),\n    }\n\n    def sigmoid(z):\n        \"\"\"Computes the logistic sigmoid function.\"\"\"\n        return 1.0 / (1.0 + np.exp(-z))\n\n    def rnn_forward(sequence_str):\n        \"\"\"\n        Performs the forward pass of the RNN for a given sequence.\n        Returns a list of all hidden states.\n        \"\"\"\n        T = len(sequence_str)\n        h_dim = Wh.shape[0]\n        \n        h_states = []\n        h_prev = np.zeros((h_dim, 1))\n\n        for t in range(T):\n            char = sequence_str[t]\n            x_t = dna_map[char]\n            \n            # Recurrence relation\n            h_t = np.tanh(Wx @ x_t + Wh @ h_prev + b)\n            h_states.append(h_t)\n            h_prev = h_t\n            \n        return h_states\n\n    def compute_f_for_case(S_orig, mutation_type, m, u=None):\n        \"\"\"\n        Computes the functional perturbation index F for a single test case.\n        \"\"\"\n        # 1. Generate mutated sequence based on problem rules\n        T_orig = len(S_orig)\n        if mutation_type == 'insertion':\n            # Insert nucleotide u immediately after 1-indexed position m\n            S_mut = S_orig[:m] + u + S_orig[m:]\n        elif mutation_type == 'deletion':\n            # Remove nucleotide at 1-indexed position m\n            S_mut = S_orig[:m-1] + S_orig[m:]\n        else:\n            raise ValueError(\"Invalid mutation type specified.\")\n        \n        T_mut = len(S_mut)\n\n        # 2. Compute hidden state sequences for original and mutated sequences\n        h_orig_states = rnn_forward(S_orig)\n        h_mut_states = rnn_forward(S_mut)\n\n        # 3. Compute average post-mutation hidden-state divergence D_bar\n        min_T = min(T_orig, T_mut)\n        D_bar = 0.0\n        \n        if m <= min_T:\n            sum_d_t = 0.0\n            # Summation is from t=m to min_T (1-based indices)\n            for t_idx in range(m, min_T + 1):\n                # Convert 1-based t to 0-based list index\n                h_t_orig = h_orig_states[t_idx-1]\n                h_t_mut = h_mut_states[t_idx-1]\n                # Euclidean distance\n                d_t = np.linalg.norm(h_t_mut - h_t_orig)\n                sum_d_t += d_t\n            \n            num_terms = min_T - m + 1\n            D_bar = sum_d_t / num_terms\n        # If m > min_T, D_bar is 0 by definition, which is the initial value.\n\n        # 4. Compute final predictions y_hat for both sequences\n        h_T_orig = h_orig_states[-1]\n        y_hat_orig = sigmoid((w.T @ h_T_orig + by).item())\n        \n        # Handle case where mutated sequence is empty\n        if not h_mut_states:\n            # Re-initialize h_0 for empty sequence prediction\n            h_final_mut = np.zeros((Wh.shape[0], 1))\n        else:\n            h_final_mut = h_mut_states[-1]\n        \n        y_hat_mut = sigmoid((w.T @ h_final_mut + by).item())\n\n        # 5. Compute the final Functional Perturbation Index F\n        F = np.abs(y_hat_mut - y_hat_orig) + lambda_param * D_bar\n\n        return F\n\n    # ------------------ Test Cases ------------------ #\n    test_cases = [\n        # (original_sequence, mutation_type, m, nucleotide_for_insertion)\n        (\"ATGGCCATTGTA\", 'insertion', 5, 'A'),\n        (\"ATGCGT\", 'deletion', 1, None),\n        (\"CCGTAACG\", 'insertion', 8, 'T'),\n        (\"GATTACA\", 'deletion', 7, None),\n    ]\n\n    results = []\n    for case in test_cases:\n        S_orig, mut_type, m, u = case\n        result = compute_f_for_case(S_orig, mut_type, m, u)\n        results.append(result)\n\n    # ------------------ Final Output ------------------ #\n    # Format results as a comma-separated list of numbers rounded to 6 decimal places,\n    # enclosed in square brackets.\n    print(f\"[{','.join([f'{r:.6f}' for r in results])}]\")\n\nsolve()\n```", "id": "2425716"}, {"introduction": "简单的 RNN 难以处理长序列，而像长短期记忆（LSTM）网络这样的高级架构解决了这个问题。最后的这个实践将深入探讨 LSTM 的核心：细胞状态及其保护性的“门”机制。你将通过数学计算，确定一个能让 LSTM 在数千个核苷酸的距离上“记住”一条信息的最小序列，从而具体理解 LSTM 是如何捕捉长程依赖关系的——这是分析复杂生物序列的关键特性 [@problem_id:2425681]。", "problem": "给定一个单单元长短期记忆（LSTM）单元，用于处理以独热（one-hot）向量表示的、基于字母表 $\\{\\mathrm{A},\\mathrm{C},\\mathrm{G},\\mathrm{T}\\}$ 的脱氧核糖核酸（DNA）序列。该 LSTM 包含一个输入门、一个遗忘门和候选细胞非线性环节。令 $\\sigma(z) = \\frac{1}{1+\\exp(-z)}$ 表示 logistic sigmoid 函数，$\\tanh(z)$ 表示双曲正切函数。对于一个独热输入序列 $\\{x_t\\}$，细胞状态 $\\{c_t\\}$ 的演化方式如下：\n$$\nc_t \\;=\\; f_t \\, c_{t-1} \\;+\\; i_t \\, g_t,\n$$\n其中\n$$\nf_t \\;=\\; \\sigma\\!\\left(z_f(x_t)\\right), \\quad\ni_t \\;=\\; \\sigma\\!\\left(z_i(x_t)\\right), \\quad\ng_t \\;=\\; \\tanh\\!\\left(z_g(x_t)\\right).\n$$\n初始状态为 $c_0 = 0$。对于每个核苷酸 $\\nu \\in \\{\\mathrm{A},\\mathrm{C},\\mathrm{G},\\mathrm{T}\\}$，预激活值 $z_f(\\nu)$、$z_i(\\nu)$ 和 $z_g(\\nu)$ 是给定的固定常数，具体如下：\n- 对于 $\\mathrm{A}$：$z_f(\\mathrm{A}) = 2.0$, $z_i(\\mathrm{A}) = 3.0$, $z_g(\\mathrm{A}) = 3.0$。\n- 对于 $\\mathrm{C}$：$z_f(\\mathrm{C}) = 3.0$, $z_i(\\mathrm{C}) = -4.0$, $z_g(\\mathrm{C}) = 0.0$。\n- 对于 $\\mathrm{G}$：$z_f(\\mathrm{G}) = 1.0$, $z_i(\\mathrm{G}) = -2.0$, $z_g(\\mathrm{G}) = -3.0$。\n- 对于 $\\mathrm{T}$：$z_f(\\mathrm{T}) = 7.600902$, $z_i(\\mathrm{T}) = -6.0$, $z_g(\\mathrm{T}) = 0.0$。\n\n考虑限制为以下两段式结构的序列：一个前缀，由单个核苷酸 $\\alpha \\in \\{\\mathrm{A},\\mathrm{C},\\mathrm{G},\\mathrm{T}\\}$ 重复 $m$ 次组成；随后是一个填充段，由单个核苷酸 $\\beta \\in \\{\\mathrm{A},\\mathrm{C},\\mathrm{G},\\mathrm{T}\\}$ 重复 $L$ 次组成。令 $\\theta > 0$ 为一个目标阈值。如果在处理完整个序列后，最终的细胞状态 $c_{m+L}$ 满足 $c_{m+L} \\ge \\theta$，则该设计是可行的。\n\n对于每个测试用例 $(L,\\theta)$，确定最小的非负整数 $m$，使得存在一种对 $\\alpha$ 和 $\\beta$ 的选择，能让该设计是可行的。如果对于任何 $\\alpha$ 和 $\\beta$ 的选择，都不存在有限的 $m$ 满足该不等式，则该测试用例返回 $-1$。所有计算必须严格遵循上述定义；不允许任何额外假设。计算不涉及角度；也不涉及任何物理单位。\n\n使用以下参数测试集 $(L,\\theta)$：\n- $(L,\\theta) = (10,\\,0.2)$\n- $(L,\\theta) = (1000,\\,0.2)$\n- $(L,\\theta) = (1500,\\,0.5)$\n- $(L,\\theta) = (5000,\\,1.0)$\n- $(L,\\theta) = (0,\\,0.1)$\n\n您的程序应产生单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如 $[m_1,m_2,m_3,m_4,m_5]$），其中每个 $m_k$ 是按上面所列顺序的相应测试用例所需的最小整数。", "solution": "该问题要求找到最小的非负整数 $m$，使得对于一个特殊结构的 DNA 序列，给定的可行性条件能够被满足。一个序列由一个前缀和一个填充段组成，前缀是核苷酸 $\\alpha \\in \\{\\mathrm{A},\\mathrm{C},\\mathrm{G},\\mathrm{T}\\}$ 重复 $m$ 次，填充段是核苷酸 $\\beta \\in \\{\\mathrm{A},\\mathrm{C},\\mathrm{G},\\mathrm{T}\\}$ 重复 $L$ 次。可行性条件是，一个简化的长短期记忆（LSTM）单元的最终细胞状态 $c_{m+L}$ 必须大于或等于一个阈值 $\\theta > 0$。\n\n首先，我们必须将最终细胞状态 $c_{m+L}$ 的计算过程形式化。状态更新方程以线性递推关系给出：\n$$c_t = f_t c_{t-1} + i_t g_t$$\n其中，门激活值 $f_t = \\sigma(z_f(x_t))$、$i_t = \\sigma(z_i(x_t))$ 和 $g_t = \\tanh(z_g(x_t))$ 取决于时间步 $t$ 的输入核苷酸 $x_t$。初始状态为 $c_0 = 0$。\n\n该序列由两个恒定段组成。对于由 $m$ 个相同核苷酸 $\\alpha$ 组成的第一个段，在 $t=1, \\dots, m$ 时，门激活值是恒定的：\n$f_\\alpha = \\sigma(z_f(\\alpha))$\n$i_\\alpha = \\sigma(z_i(\\alpha))$\n$g_\\alpha = \\tanh(z_g(\\alpha))$\n令 $K_\\alpha = i_\\alpha g_\\alpha$。递推关系变为 $c_t = f_\\alpha c_{t-1} + K_\\alpha$。在 $c_0=0$ 的条件下，将此递推关系从 $t=1$ 展开到 $m$ 会得到一个等比数列的和：\n$$c_m = K_\\alpha \\sum_{k=0}^{m-1} f_\\alpha^k$$\n由于对所有核苷酸 $\\nu$，预激活值 $z_f(\\nu)$ 是有限实数，因此遗忘门激活值 $f_\\nu = \\sigma(z_f(\\nu))$ 严格介于 0 和 1 之间。具体而言，$f_\\nu \\neq 1$。因此，该和可以用封闭形式表示：\n$$c_m = K_\\alpha \\frac{1 - f_\\alpha^m}{1 - f_\\alpha}$$\n这是处理完由 $m$ 个核苷酸 $\\alpha$ 组成的第一个段后的细胞状态。\n\n接下来，对于由 $L$ 个相同核苷酸 $\\beta$ 组成的第二个段，门激活值同样是恒定的：$f_\\beta$、$i_\\beta$、$g_\\beta$。令 $K_\\beta = i_\\beta g_\\beta$。对于 $t = m+1, \\dots, m+L$，递推关系为 $c_t = f_\\beta c_{t-1} + K_\\beta$，该段的初始条件是 $c_m$。通过对这个递推关系求解 $L$ 步，可以找到最终状态 $c_{m+L}$：\n$$c_{m+L} = f_\\beta^L c_m + K_\\beta \\sum_{k=0}^{L-1} f_\\beta^k = f_\\beta^L c_m + K_\\beta \\frac{1-f_\\beta^L}{1-f_\\beta}$$\n我们定义 $C_{\\beta,L} = K_\\beta \\frac{1-f_\\beta^L}{1-f_\\beta}$。此项代表从 $c_0=0$ 开始处理一个由 $L$ 个核苷酸 $\\beta$ 组成的序列后的细胞状态。\n\n代入 $c_m$ 的表达式，我们得到最终状态 $c_{m+L}$ 是一个关于 $m$、$L$、$\\alpha$ 和 $\\beta$ 的函数：\n$$c_{m+L}(m) = f_\\beta^L \\left( K_\\alpha \\frac{1 - f_\\alpha^m}{1 - f_\\alpha} \\right) + C_{\\beta,L}$$\n\n目标是找到最小的非负整数 $m$，使得对于某一对 $(\\alpha, \\beta)$ 的选择，$c_{m+L}(m) \\ge \\theta$。我们必须分析 $c_{m+L}(m)$ 作为 $m$ 的函数的行为。唯一与 $m$ 相关的项是 $f_\\alpha^m$。由于 $0 < f_\\alpha < 1$，$f_\\alpha^m$ 是一个关于 $m$ 的正的、单调递减的函数，当 $m \\to \\infty$ 时，该函数趋近于 0。\n\n让我们使用提供的 $z$ 值，为每个核苷酸 $\\nu \\in \\{\\mathrm{A},\\mathrm{C},\\mathrm{G},\\mathrm{T}\\}$ 计算常数 $f_\\nu$ 和 $K_\\nu = i_\\nu g_\\nu$。\n- $\\mathrm{A}$：$z_f=2.0, z_i=3.0, z_g=3.0 \\Rightarrow f_A \\approx 0.8808, K_A \\approx 0.9479 > 0$。\n- $\\mathrm{C}$：$z_f=3.0, z_i=-4.0, z_g=0.0 \\Rightarrow f_C \\approx 0.9526, K_C = 0$。\n- $\\mathrm{G}$：$z_f=1.0, z_i=-2.0, z_g=-3.0 \\Rightarrow f_G \\approx 0.7311, K_G \\approx -0.1186 < 0$。\n- $\\mathrm{T}$：$z_f=7.600902, z_i=-6.0, z_g=0.0 \\Rightarrow f_T \\approx 0.9995, K_T = 0$。\n\n对 $c_{m+L}(m)$ 的分析取决于 $K_\\alpha$ 的符号：\n1.  如果 $\\alpha \\in \\{\\mathrm{C}, \\mathrm{T}\\}$，则 $K_\\alpha = 0$。这使得对所有 $m$ 都有 $c_m=0$，并且 $c_{m+L}(m) = C_{\\beta,L}$。该表达式与 $m$ 无关。条件变为 $C_{\\beta,L} \\ge \\theta$。如果此条件成立，则所需的最小 $m$ 为 $0$。如果不成立，则对于这对 $(\\alpha, \\beta)$，没有任何 $m$ 值能满足条件。\n\n2.  如果 $\\alpha = \\mathrm{G}$，则 $K_G < 0$。项 $-K_G f_G^m$ 是正的且递减的，因此 $c_{m+L}(m)$ 是一个关于 $m$ 的单调递减函数。其最大值在 $m=0$ 时取到，即 $c_{m+L}(0) = C_{\\beta,L}$。因此，当且仅当 $C_{\\beta,L} \\ge \\theta$ 时存在解，此时答案为 $m=0$。\n\n3.  如果 $\\alpha = \\mathrm{A}$，则 $K_A > 0$。项 $-K_A f_A^m$ 是负的，且其绝对值随着 $m$ 增大而减小，因此 $c_{m+L}(m)$ 是一个关于 $m$ 的单调递增函数。\n    - 如果 $c_{m+L}(0) = C_{\\beta,L} \\ge \\theta$，则最小解为 $m=0$。\n    - 如果 $c_{m+L}(0) < \\theta$，我们必须检查该函数是否能达到 $\\theta$。我们考察当 $m \\to \\infty$ 时的极限：$c_{m+L}(\\infty) = f_\\beta^L \\frac{K_A}{1-f_A} + C_{\\beta,L}$。如果此极限小于 $\\theta$，则不存在有限的 $m$ 能满足条件。否则，解是存在的。我们通过求解 $c_{m+L}(m) \\ge \\theta$ 来找到 $m$：\n    $$f_A^m \\le 1 - \\frac{(\\theta - C_{\\beta,L})(1-f_A)}{f_\\beta^L K_A}$$\n    两边取对数得到 $$ m \\ln(f_A) \\le \\ln(Y) $$ 其中 $Y$ 是右侧的表达式。因为 $\\ln(f_A) < 0$，不等式变为 $$ m \\ge \\frac{\\ln(Y)}{\\ln(f_A)} $$ 最小整数解是 $$ m = \\lceil \\frac{\\ln(Y)}{\\ln(f_A)} \\rceil $$\n\n这导出了针对每个测试用例 $(L, \\theta)$ 的以下算法：\n1.  初始化一个变量 $\\min\\_m \\leftarrow \\infty$，用于记录目前找到的最小 $m$。\n2.  首先，检查是否存在 $m=0$ 的解。这可以简化为检查是否存在任何 $\\beta \\in \\{\\mathrm{A},\\mathrm{C},\\mathrm{G},\\mathrm{T}\\}$ 使得 $C_{\\beta,L} \\ge \\theta$。经检查，$K_C=K_T=0$ 且 $K_G<0$，因此对于 $\\beta \\in \\{\\mathrm{C},\\mathrm{G},\\mathrm{T}\\}$，$C_{\\beta,L} \\le 0$。所以，对于 $\\theta > 0$，$m=0$ 的解只有在 $C_{\\mathrm{A},L} \\ge \\theta$ 时才可能存在。如果该条件成立，答案就是 $0$。\n3.  如果不存在 $m=0$ 的解，我们必须寻找 $m > 0$ 的解。根据我们的分析，这只在 $\\alpha = \\mathrm{A}$ 时才可能。我们遍历每个可能的 $\\beta \\in \\{\\mathrm{A},\\mathrm{C},\\mathrm{G},\\mathrm{T}\\}$。对于每一对 $(\\mathrm{A}, \\beta)$，我们按照上面第 3 点中描述的方法计算所需的 $m$，并用找到的最小有效 $m$ 更新 $\\min\\_m$。\n4.  如果在检查完所有配对后，$\\min\\_m$ 仍然是 $\\infty$，则说明不存在解，答案为 $-1$。否则，答案就是 $\\min\\_m$ 的最终值。\n\n让我们将此算法应用于各个测试用例。\n- 对于 $(L,\\theta) = (10, 0.2)$、$(1000, 0.2)$、$(1500, 0.5)$ 和 $(5000, 1.0)$：我们检查是否存在以 $\\beta=\\mathrm{A}$ 构成的 $m=0$ 解。对于这些 $L$ 值，$f_A^L$ 很小，使得 $C_{A,L} = K_A \\frac{1-f_A^L}{1-f_A}$ 趋近其极限值 $\\frac{K_A}{1-f_A} \\approx 7.95$。在这四种情况下，$C_{A,L}$ 均大于各自对应的 $\\theta$。例如，当 $L=10$ 时，$C_{A,10} \\approx 5.70 > 0.2$。因此，对于这四种情况，选择 $\\beta=\\mathrm{A}$（以及任意 $\\alpha$）都能得到一个有效的 $m=0$ 设计。最小非负整数 $m$ 为 $0$。\n- 对于 $(L,\\theta) = (0, 0.1)$：$L=0$，因此对任意 $\\beta$，$C_{\\beta,0} = K_\\beta \\frac{1-f_\\beta^0}{1-f_\\beta} = 0$。条件 $0 \\ge 0.1$ 不成立。不存在 $m=0$ 的解。我们必须在 $\\alpha=\\mathrm{A}$ 且 $m>0$ 的情况下进行搜索。条件 $c_{m+0} \\ge 0.1$ 变为 $c_m \\ge 0.1$。\n$$K_A \\frac{1 - f_A^m}{1 - f_A} \\ge 0.1$$\n求解 $m$ 得出 $$ m \\ge \\frac{\\ln(1 - 0.1 \\frac{1-f_A}{K_A})}{\\ln(f_A)} \\approx 0.09968 $$ 最小的整数 $m$ 是 $$ m = \\lceil 0.09968 \\rceil = 1 $$ 因为 $L=0$，所以 $\\beta$ 的选择不影响结果。\n\n最终结果为 $[0, 0, 0, 0, 1]$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the LSTM design problem for a series of test cases.\n    \"\"\"\n\n    # --- Pre-computation of constants ---\n\n    def sigma(z):\n        return 1.0 / (1.0 + np.exp(-z))\n\n    # Given pre-activation values\n    z_f_vals = {'A': 2.0, 'C': 3.0, 'G': 1.0, 'T': 7.600902}\n    z_i_vals = {'A': 3.0, 'C': -4.0, 'G': -2.0, 'T': -6.0}\n    z_g_vals = {'A': 3.0, 'C': 0.0, 'G': -3.0, 'T': 0.0}\n    \n    nucleotides = ['A', 'C', 'G', 'T']\n    \n    # Gate parameters for each nucleotide\n    f_vals = {n: sigma(z_f_vals[n]) for n in nucleotides}\n    i_vals = {n: sigma(z_i_vals[n]) for n in nucleotides}\n    g_vals = {n: np.tanh(z_g_vals[n]) for n in nucleotides}\n    \n    # Combined term K = i*g\n    K_vals = {n: i_vals[n] * g_vals[n] for n in nucleotides}\n\n    # Test cases\n    test_cases = [\n        (10, 0.2),\n        (1000, 0.2),\n        (1500, 0.5),\n        (5000, 1.0),\n        (0, 0.1)\n    ]\n\n    results = []\n\n    for L, theta in test_cases:\n        min_m_for_case = float('inf')\n        \n        # --- Algorithm Implementation ---\n        \n        # 1. Check for m=0 solutions\n        # An m=0 solution exists if c_L >= theta for some beta.\n        # c_L = K_beta * (1 - f_beta^L) / (1 - f_beta)\n        # This is only positive for beta='A', since K_C=K_T=0 and K_G<0.\n        \n        m_0_is_solution = False\n        beta = 'A'\n        f_beta, K_beta = f_vals[beta], K_vals[beta]\n        \n        if L == 0:\n            C_beta_L = 0.0\n        else:\n            C_beta_L = K_beta * (1 - f_beta**L) / (1 - f_beta)\n\n        if C_beta_L >= theta:\n            min_m_for_case = 0\n            m_0_is_solution = True\n\n        # 2. If no m=0 solution, search for m > 0\n        # A solution with m > 0 is only possible with alpha='A'\n        if not m_0_is_solution:\n            alpha = 'A'\n            f_alpha, K_alpha = f_vals[alpha], K_vals[alpha]\n\n            for beta in nucleotides:\n                f_beta, K_beta = f_vals[beta], K_vals[beta]\n\n                if L == 0:\n                    C_beta_L = 0.0\n                else:\n                    C_beta_L = K_beta * (1 - f_beta**L) / (1 - f_beta)\n                \n                # We already know C_beta_L < theta\n                # Check limit as m -> infinity\n                limit_c = (f_beta**L) * K_alpha / (1 - f_alpha) + C_beta_L\n                \n                if limit_c >= theta:\n                    # Solve for m. Need to handle f_beta**L being near zero.\n                    denominator = (f_beta**L) * K_alpha\n                    if np.isclose(denominator, 0): # Avoid division by zero\n                        # This implies limit_c is basically C_beta_L, which is < theta.\n                        # This branch should not be taken if limit_c >= theta unless\n                        # there are floating point issues.\n                        continue\n\n                    # Y = 1 - (theta - C_beta_L)*(1-f_alpha) / (f_beta^L * K_alpha)\n                    Y = 1.0 - (theta - C_beta_L) * (1 - f_alpha) / denominator\n                    \n                    if 0.0 < Y < 1.0:\n                        m_val = np.log(Y) / np.log(f_alpha)\n                        current_m = np.ceil(m_val)\n                        if current_m >= 0:\n                            min_m_for_case = min(min_m_for_case, current_m)\n                    # If Y >= 1, log is non-negative, m would be <= 0.\n                    # Since m=0 already failed, this implies C_beta_L >= theta, a contradiction.\n                    # If Y <= 0, no real log, no solution for this beta.\n        \n        if min_m_for_case == float('inf'):\n            results.append(-1)\n        else:\n            results.append(int(min_m_for_case))\n            \n    # Final print statement\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2425681"}]}