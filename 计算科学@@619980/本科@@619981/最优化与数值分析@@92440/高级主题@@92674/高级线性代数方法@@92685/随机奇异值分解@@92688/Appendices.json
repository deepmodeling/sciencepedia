{"hands_on_practices": [{"introduction": "随机SVD算法的核心思想始于一个被称为“素描”(sketching)的过程，即通过乘以一个随机矩阵来捕捉原始大矩阵的主要特征。这个练习将带你亲手完成这个关键的第一步：计算素描矩阵 $Y = A\\Omega$。通过这个具体的计算，你将直观地理解算法是如何从一个高维空间投影到一个更易于管理的低维子空间中的 [@problem_id:2196192]。", "problem": "在许多现代数据分析应用中，我们会遇到非常大的矩阵，对于这些矩阵，标准计算技术，如完全奇异值分解 (SVD)，速度太慢。随机数值线性代数通过使用随机采样来创建原始矩阵的一个更小、更易于管理的“速写”(sketch)，从而提供了一种强大的替代方案。\n\n考虑一个表示某个数据集的矩阵 $A$。许多随机算法的第一步是通过将 $A$ 与一个随机测试矩阵 $\\Omega$ 相乘来探测 $A$ 的作用。该乘积形成一个新矩阵 $Y = A\\Omega$，通常称为速写矩阵，其列是 $A$ 的列的随机线性组合。矩阵 $Y$ 作为原始矩阵 $A$ 的值域（或列空间）的一个低维代理。\n\n给定以下矩阵：\n$$\nA = \\begin{pmatrix} 1 & 0 & -1 \\\\ 2 & 1 & 0 \\\\ 0 & -2 & 3 \\\\ 1 & 1 & 1 \\end{pmatrix}\n$$\n以及一个随机测试矩阵\n$$\n\\Omega = \\begin{pmatrix} 2 & -1 \\\\ 1 & 0 \\\\ 3 & 2 \\end{pmatrix}\n$$\n计算速写矩阵 $Y = A\\Omega$。", "solution": "我们通过矩阵乘法 $Y=A\\Omega$ 来构建速写矩阵。一个 $4\\times 3$ 矩阵与一个 $3\\times 2$ 矩阵的乘积结果是一个 $4\\times 2$ 矩阵，其元素由下式给出\n$$\nY_{ij}=\\sum_{k=1}^{3}A_{ik}\\Omega_{kj}.\n$$\n等价地，按列来看，\n$$\nY=[A\\omega_{1},A\\omega_{2}],\n$$\n其中 $\\omega_{1}$ 和 $\\omega_{2}$ 是 $\\Omega$ 的列。\n\n令 $\\omega_{1}=\\begin{pmatrix}2 \\\\ 1 \\\\ 3\\end{pmatrix}$ 且 $\\omega_{2}=\\begin{pmatrix}-1 \\\\ 0 \\\\ 2\\end{pmatrix}$。那么\n$$\nA\\omega_{1}\n=\n\\begin{pmatrix}\n1 & 0 & -1 \\\\\n2 & 1 & 0 \\\\\n0 & -2 & 3 \\\\\n1 & 1 & 1\n\\end{pmatrix}\n\\begin{pmatrix}\n2 \\\\ 1 \\\\ 3\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n1\\cdot 2+0\\cdot 1+(-1)\\cdot 3 \\\\\n2\\cdot 2+1\\cdot 1+0\\cdot 3 \\\\\n0\\cdot 2+(-2)\\cdot 1+3\\cdot 3 \\\\\n1\\cdot 2+1\\cdot 1+1\\cdot 3\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n-1 \\\\ 5 \\\\ 7 \\\\ 6\n\\end{pmatrix}.\n$$\n类似地，\n$$\nA\\omega_{2}\n=\n\\begin{pmatrix}\n1 & 0 & -1 \\\\\n2 & 1 & 0 \\\\\n0 & -2 & 3 \\\\\n1 & 1 & 1\n\\end{pmatrix}\n\\begin{pmatrix}\n-1 \\\\ 0 \\\\ 2\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n1\\cdot(-1)+0\\cdot 0+(-1)\\cdot 2 \\\\\n2\\cdot(-1)+1\\cdot 0+0\\cdot 2 \\\\\n0\\cdot(-1)+(-2)\\cdot 0+3\\cdot 2 \\\\\n1\\cdot(-1)+1\\cdot 0+1\\cdot 2\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n-3 \\\\ -2 \\\\ 6 \\\\ 1\n\\end{pmatrix}.\n$$\n因此，\n$$\nY=A\\Omega=\n\\begin{pmatrix}\n-1 & -3 \\\\\n5 & -2 \\\\\n7 & 6 \\\\\n6 & 1\n\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}-1 & -3 \\\\ 5 & -2 \\\\ 7 & 6 \\\\ 6 & 1\\end{pmatrix}}$$", "id": "2196192"}, {"introduction": "理解随机SVD算法的效率，关键在于追踪算法每一步中矩阵维度的变化。这个练习将引导你分析从初始的随机投影到最终生成低秩分量的整个流程中，各个关键矩阵的尺寸 [@problem_id:2196156]。这不仅有助于巩固你对算法流程的理解，还能让你清晰地看到计算量是如何被有效降低的。", "problem": "随机奇异值分解（rSVD）是一种功能强大的算法，用于计算大型矩阵的低秩近似。考虑一个矩阵 $A \\in \\mathbb{R}^{m \\times n}$，其中 $m=1000$ 且 $n=500$。我们希望使用 rSVD 找到 $A$ 的一个秩-$k$ 近似，目标秩为 $k=10$，过采样参数为 $p=5$。\n\n该 rSVD 变体算法的主要步骤如下：\n1. 生成一个随机高斯矩阵 $\\Omega$。\n2. 形成草图矩阵 $Y = A\\Omega$。\n3. 计算 $Y$ 的列空间的一组标准正交基 $Q$（例如，使用 QR 分解）。\n4. 形成一个更小的投影矩阵 $B = Q^T A$。\n5. 计算矩阵 $B$ 的经济型奇异值分解（SVD），其形式为 $B = \\tilde{U}\\Sigma V^T$。\n\n根据提供的参数，按所列顺序确定以下矩阵的维度：$\\Omega$、 $Y$、 $B$、 $\\tilde{U}$ 和 $V$。维度应表示为一对（行数，列数）。\n\n选择正确列出 $(\\Omega, Y, B, \\tilde{U}, V)$ 维度序列的选项。\n\nA. $(500, 15), (1000, 15), (15, 500), (15, 15), (500, 15)$\n\nB. $(500, 10), (1000, 10), (10, 500), (10, 10), (500, 10)$\n\nC. $(500, 15), (1000, 15), (15, 500), (15, 15), (500, 500)$\n\nD. $(500, 15), (1000, 15), (500, 15), (500, 15), (15, 15)$\n\nE. $(1000, 15), (500, 15), (15, 1000), (15, 15), (1000, 15)$", "solution": "设 $A \\in \\mathbb{R}^{m \\times n}$，其中 $m=1000$，$n=500$。目标秩为 $k=10$，过采样参数为 $p=5$。定义草图大小 $l$ 为 $l=k+p$，因此 $l=15$。\n\n步骤1（随机测试矩阵）：为了形成列草图 $Y=A\\Omega$，高斯矩阵 $\\Omega$ 的大小必须为 $\\Omega \\in \\mathbb{R}^{n \\times l}$，以使乘积有定义。因此，$\\Omega$ 的维度为 $(500, 15)$。\n\n步骤2（草图矩阵）：计算\n$$\nY = A \\Omega,\n$$\n其中 $A \\in \\mathbb{R}^{1000 \\times 500}$ 且 $\\Omega \\in \\mathbb{R}^{500 \\times 15}$。因此，$Y \\in \\mathbb{R}^{1000 \\times 15}$，即 $(1000, 15)$。\n\n步骤3（标准正交基）：$Y$ 的列的一组标准正交基 $Q$ 的行数与 $A$ 相同，并有 $l$ 列，所以 $Q \\in \\mathbb{R}^{1000 \\times 15}$。\n\n步骤4（投影矩阵）：形成\n$$\nB = Q^{T} A.\n$$\n此处，$Q^{T} \\in \\mathbb{R}^{15 \\times 1000}$，$A \\in \\mathbb{R}^{1000 \\times 500}$，所以 $B \\in \\mathbb{R}^{15 \\times 500}$，即 $(15, 500)$。\n\n步骤5（$B$的经济型SVD）：对于 $B \\in \\mathbb{R}^{l \\times n}$ 且 $l \\leq n$，其经济型SVD\n$$\nB = \\tilde{U} \\Sigma V^{T}\n$$\n具有 $\\tilde{U} \\in \\mathbb{R}^{l \\times l}$ 和 $V \\in \\mathbb{R}^{n \\times l}$。因此，$\\tilde{U}$ 的维度为 $(15, 15)$，$V$ 的维度为 $(500, 15)$。\n\n综上所述，序列 $(\\Omega, Y, B, \\tilde{U}, V)$ 为 $(500, 15), (1000, 15), (15, 500), (15, 15), (500, 15)$，这与选项 A 一致。", "answer": "$$\\boxed{A}$$", "id": "2196156"}, {"introduction": "在实际应用中，一个算法的效率不仅仅取决于其内在设计，还取决于我们如何策略性地使用它。对于一个形状为“高瘦”($m \\gg n$)或“矮胖”($n \\gg m$)的矩阵，直接应用rSVD或对其转置应用rSVD，其计算成本可能大不相同 [@problem_id:2196144]。通过分析这两种策略的计算成本，你将学会如何根据数据矩阵的几何特性做出最优选择，从而最大化计算效率。", "problem": "在数值线性代数中，随机奇异值分解（rSVD）为计算大型矩阵的低秩近似提供了一种有效的方法。许多 rSVD 算法的一个关键步骤是找到一个标准正交基 $Q$，该基能近似矩阵的值域（列空间）。\n\n考虑一个矩阵 $A \\in \\mathbb{R}^{m \\times n}$。我们希望找到一个秩为 $k$ 的近似，其中 $k$ 远小于 $m$ 和 $n$。我们可以通过两种方式来解决这个问题：\n\n**策略1：** 直接对矩阵 $A$ 应用随机化过程。\n**策略2：** 对转置矩阵 $A^T$ 应用相同的随机化过程，并利用 $A^T$ 的左奇异向量即为 $A$ 的右奇异向量这一事实。\n\n让我们来分析这两种策略中算法核心的“值域寻找”部分的计算成本。该过程如下：\n1. 给定一个输入矩阵 $M$，生成一个大小合适的高斯随机矩阵 $\\Omega$。构成“速写”矩阵 $Y = M \\Omega$。$\\Omega$ 的列数为 $k$。\n2. 通过对 $Y$ 进行 QR 分解，计算 $Y$ 的列的一个标准正交基 $Q$。\n\n在你的分析中，请使用以下关于浮点运算次数（flops）的标准估算：\n- 一个 $p \\times q$ 矩阵与一个 $q \\times r$ 矩阵的乘法大约需要 $2pqr$ 次浮点运算。\n- 一个 $p \\times q$ 矩阵（其中 $p \\ge q$）的 QR 分解大约需要 $2pq^2$ 次浮点运算。\n\n每种策略的总成本是步骤1和步骤2的成本之和。请比较这两种策略对于以下两种不同类型矩阵的主导阶成本：\n- “高瘦”矩阵，其中 $m \\gg n$。\n- “矮胖”矩阵，其中 $n \\gg m$。\n\n在两种情况下，都假设 $m \\gg k$ 且 $n \\gg k$。根据你对主导阶计算成本的比较，以下哪个陈述是正确的？\n\nA. 对于“高瘦”矩阵，策略1的计算成本更低；而对于“矮胖”矩阵，策略2的计算成本更低。\n\nB. 对于“高瘦”矩阵，策略2的计算成本更低；而对于“矮胖”矩阵，策略1的计算成本更低。\n\nC. 无论矩阵形状如何，策略1的计算成本总是更低。\n\nD. 无论矩阵形状如何，策略2的计算成本总是更低。\n\nE. 在两种情况下，两种策略的主导阶计算成本相同。", "solution": "我们用 $k$ 表示目标秩，其中 $m \\gg k$ 且 $n \\gg k$。核心的值域寻找过程包括：\n1) 将输入矩阵乘以一个具有 $k$ 列的高斯测试矩阵。\n2) 对所得的速写矩阵进行 QR 分解。\n\n浮点运算模型：\n- 尺寸为 $p \\times q$ 和 $q \\times r$ 的矩阵乘积：$2pqr$ 次浮点运算。\n- $p \\times q$ 矩阵（其中 $p \\ge q$）的 QR 分解：$2pq^{2}$ 次浮点运算。\n\n策略1（应用于 $A \\in \\mathbb{R}^{m \\times n}$）：\n- 步骤1：$\\Omega \\in \\mathbb{R}^{n \\times k}$，$Y = A\\Omega \\in \\mathbb{R}^{m \\times k}$。成本：$2mnk$。\n- 步骤2：对 $Y$（$m \\times k$ 矩阵，其中 $m \\ge k$）进行 QR 分解。成本：$2mk^{2}$。\n总计：\n$$\nC_{1}=2mnk+2mk^{2}.\n$$\n\n策略2（应用于 $A^{T} \\in \\mathbb{R}^{n \\times m}$）：\n- 步骤1：$\\Omega \\in \\mathbb{R}^{m \\times k}$，$Y' = A^{T}\\Omega \\in \\mathbb{R}^{n \\times k}$。成本：$2nmk=2mnk$。\n- 步骤2：对 $Y'$（$n \\times k$ 矩阵，其中 $n \\ge k$）进行 QR 分解。成本：$2nk^{2}$。\n总计：\n$$\nC_{2}=2mnk+2nk^{2}.\n$$\n\n按矩阵形状比较：\n- 高瘦矩阵（$m \\gg n$ 且 $n \\gg k$）：$C_{1}$ 和 $C_{2}$ 共享相同的主导项 $2mnk$。下一项不同：$2mk^{2}$ 与 $2nk^{2}$。由于 $m \\gg n$，我们有 $2nk^{2} \\ll 2mk^{2}$，因此 $C_{2}<C_{1}$；策略2的成本更低。\n- 矮胖矩阵（$n \\gg m$ 且 $m \\gg k$）：同样，主导项 $2mnk$ 是共享的。现在 $2mk^{2} \\ll 2nk^{2}$，因此 $C_{1}<C_{2}$；策略1的成本更低。\n\n因此，对于高瘦矩阵，策略2的成本更低；对于矮胖矩阵，策略1的成本更低。", "answer": "$$\\boxed{B}$$", "id": "2196144"}]}