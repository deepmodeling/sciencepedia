{"hands_on_practices": [{"introduction": "L-BFGS 算法的威力在于它仅使用最近几次迭代的信息就能近似黑塞矩阵。这是通过存储历史向量，特别是位移向量 $s_k$ 和梯度差向量 $y_k$ 来实现的。第一个练习 [@problem_id:2184596] 将引导您完成这些关键构件的基本计算，它们构成了算法的“记忆”。", "problem": "您正在分析有限内存Broyden–Fletcher–Goldfarb–Shanno (L-BFGS) 算法的行为，这是一种用于无约束优化的常用拟牛顿法。该算法通过存储最近的 $m$ 对向量 $(s_k, y_k)$ 来构建逆海森矩阵的近似。在这里，$x_k$ 是第 $k$ 步的迭代点，$s_k = x_{k+1} - x_k$ 是位移向量，而 $y_k = \\nabla f(x_{k+1}) - \\nabla f(x_k)$ 是某个目标函数 $f(x)$ 的梯度向量的变化量。\n\n考虑对二维凸二次函数 $f(x_1, x_2) = (x_1 - 2)^2 + 3(x_2 + 1)^2$ 进行优化。一个优化程序产生了以下三个迭代点（位置向量）的序列：\n$$\nx_0 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}, \\quad x_1 = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix}, \\quad x_2 = \\begin{pmatrix} 2 \\\\ -1.5 \\end{pmatrix}\n$$\n请根据这一迭代序列，计算 L-BFGS 算法将存储的两对历史向量 $(s_0, y_0)$ 和 $(s_1, y_1)$。\n\n请将您的答案表示为一个 $2 \\times 4$ 矩阵，其中各列按顺序分别代表向量 $s_0$、$y_0$、$s_1$ 和 $y_1$。对于任何非整数值，请使用分数表示。", "solution": "我们的目标是计算当 $k=0$ 和 $k=1$ 时的位移向量 $s_k = x_{k+1} - x_k$ 和梯度差向量 $y_k = \\nabla f(x_{k+1}) - \\nabla f(x_k)$。\n\n首先，我们需要求出目标函数 $f(x_1, x_2) = (x_1 - 2)^2 + 3(x_2 + 1)^2$ 的梯度。其偏导数如下：\n$$\n\\frac{\\partial f}{\\partial x_1} = 2(x_1 - 2)\n$$\n$$\n\\frac{\\partial f}{\\partial x_2} = 3 \\cdot 2(x_2 + 1) = 6(x_2 + 1)\n$$\n因此，梯度向量为：\n$$\n\\nabla f(x_1, x_2) = \\begin{pmatrix} 2(x_1 - 2) \\\\ 6(x_2 + 1) \\end{pmatrix}\n$$\n\n接下来，我们在给定的每个迭代点 $x_0$、$x_1$ 和 $x_2$ 处计算梯度。我们将这些梯度表示为 $g_0$、$g_1$ 和 $g_2$。\n\n对于 $x_0 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$：\n$$\ng_0 = \\nabla f(0, 0) = \\begin{pmatrix} 2(0 - 2) \\\\ 6(0 + 1) \\end{pmatrix} = \\begin{pmatrix} -4 \\\\ 6 \\end{pmatrix}\n$$\n\n对于 $x_1 = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix}$：\n$$\ng_1 = \\nabla f(1, -2) = \\begin{pmatrix} 2(1 - 2) \\\\ 6(-2 + 1) \\end{pmatrix} = \\begin{pmatrix} 2(-1) \\\\ 6(-1) \\end{pmatrix} = \\begin{pmatrix} -2 \\\\ -6 \\end{pmatrix}\n$$\n\n对于 $x_2 = \\begin{pmatrix} 2 \\\\ -1.5 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ -\\frac{3}{2} \\end{pmatrix}$：\n$$\ng_2 = \\nabla f(2, -1.5) = \\begin{pmatrix} 2(2 - 2) \\\\ 6(-1.5 + 1) \\end{pmatrix} = \\begin{pmatrix} 2(0) \\\\ 6(-0.5) \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ -3 \\end{pmatrix}\n$$\n\n现在我们可以计算位移向量 $s_0$ 和 $s_1$。\n\n对于 $k=0$：\n$$\ns_0 = x_1 - x_0 = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix} - \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix}\n$$\n\n对于 $k=1$：\n$$\ns_1 = x_2 - x_1 = \\begin{pmatrix} 2 \\\\ -1.5 \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix} = \\begin{pmatrix} 2 - 1 \\\\ -1.5 - (-2) \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0.5 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ \\frac{1}{2} \\end{pmatrix}\n$$\n\n接下来，我们计算梯度差向量 $y_0$ 和 $y_1$。\n\n对于 $k=0$：\n$$\ny_0 = g_1 - g_0 = \\begin{pmatrix} -2 \\\\ -6 \\end{pmatrix} - \\begin{pmatrix} -4 \\\\ 6 \\end{pmatrix} = \\begin{pmatrix} -2 - (-4) \\\\ -6 - 6 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ -12 \\end{pmatrix}\n$$\n\n对于 $k=1$：\n$$\ny_1 = g_2 - g_1 = \\begin{pmatrix} 0 \\\\ -3 \\end{pmatrix} - \\begin{pmatrix} -2 \\\\ -6 \\end{pmatrix} = \\begin{pmatrix} 0 - (-2) \\\\ -3 - (-6) \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 3 \\end{pmatrix}\n$$\n\n最后，我们将结果组合成一个 $2 \\times 4$ 的矩阵，其中各列分别为 $s_0, y_0, s_1, y_1$。\n$$\ns_0 = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix}, \\quad y_0 = \\begin{pmatrix} 2 \\\\ -12 \\end{pmatrix}, \\quad s_1 = \\begin{pmatrix} 1 \\\\ \\frac{1}{2} \\end{pmatrix}, \\quad y_1 = \\begin{pmatrix} 2 \\\\ 3 \\end{pmatrix}\n$$\n得到的矩阵是：\n$$\n\\begin{pmatrix} 1 & 2 & 1 & 2 \\\\ -2 & -12 & \\frac{1}{2} & 3 \\end{pmatrix}\n$$", "answer": "$$\n\\boxed{\\begin{pmatrix} 1 & 2 & 1 & 2 \\\\ -2 & -12 & \\frac{1}{2} & 3 \\end{pmatrix}}\n$$", "id": "2184596"}, {"introduction": "存储了历史向量之后，L-BFGS 如何利用它们来找到一个好的搜索方向呢？答案在于优雅而高效的双循环递归。这个实践 [@problem_id:2184578] 邀请您手动追踪这一核心计算过程，从而具体地理解算法是如何隐式地将近似的逆黑塞矩阵与梯度相乘的。", "problem": "有限内存Broyden–Fletcher–Goldfarb–Shanno (L-BFGS)算法是一种常用于无约束优化的拟牛顿法。在每次迭代 $k$ 中，该算法通过将逆Hessian矩阵的近似应用于当前梯度的负值 $g_k = \\nabla f(x_k)$，来计算搜索方向 $p_k$。这个近似是使用最近 $m$ 步的有限历史记录隐式构造的。\n\n历史记录以向量对 $(s_i, y_i)$ 的形式存储，其中 $i=k-m, \\dots, k-1$，$s_i = x_{i+1} - x_i$ 是位置的变化量，$y_i = g_{i+1} - g_i$ 是梯度的变化量。然后通过一个称为L-BFGS双循环递归的过程来找到搜索方向 $p_k$。\n\n考虑在步骤 $k$ 进行一次L-BFGS更新，内存大小为 $m=2$。从先前步骤中可用的相关数据如下：\n- 当前梯度: $g_k = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix}$\n- 来自步骤 $k-1$ 的历史记录: $s_{k-1} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$, $y_{k-1} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$\n- 来自步骤 $k-2$ 的历史记录: $s_{k-2} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$, $y_{k-2} = \\begin{pmatrix} -1 \\\\ 2 \\end{pmatrix}$\n\n您的任务是计算本次迭代的搜索方向向量 $p_k$。请将您的答案表示为一个具有精确有理数分量的 $2 \\times 1$ 列向量。", "solution": "L-BFGS搜索方向 $p_k$ 是通过近似计算乘积 $-H_k g_k$ 得出的，其中 $H_k$ 是逆Hessian矩阵的近似。这可以通过双循环递归算法高效地实现。我们已知 $m=2$、梯度 $g_k$ 以及历史向量 $(s_{k-1}, y_{k-1})$ 和 $(s_{k-2}, y_{k-2})$。\n\n该算法如下：\n\n1.  用当前梯度初始化向量 $q$：\n    $q = g_k = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix}$。\n\n2.  **第一个循环（向后传递）：**这个循环从 $i = k-1$ 向下迭代到 $i = k-m$。在我们的例子中，$i$ 从 $k-1$到 $k-2$。\n    我们首先预先计算标量 $\\rho_i = \\frac{1}{y_i^T s_i}$。\n    对于 $i = k-1$：\n    $y_{k-1}^T s_{k-1} = \\begin{pmatrix} 1 & 1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = (1)(1) + (1)(0) = 1$。\n    因此，$\\rho_{k-1} = \\frac{1}{1} = 1$。\n\n    对于 $i = k-2$：\n    $y_{k-2}^T s_{k-2} = \\begin{pmatrix} -1 & 2 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = (-1)(0) + (2)(1) = 2$。\n    因此，$\\rho_{k-2} = \\frac{1}{2}$。\n\n    现在，我们执行循环更新。我们还将存储计算出的 $\\alpha_i$ 值，因为第二个循环需要它们。\n    -   **对于 $i = k-1$**：\n        $\\alpha_{k-1} = \\rho_{k-1} s_{k-1}^T q = (1) \\begin{pmatrix} 1 & 0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix} = (1)((1)(1) + (0)(-2)) = 1$。\n        $q \\leftarrow q - \\alpha_{k-1} y_{k-1} = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix} - (1) \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1-1 \\\\ -2-1 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ -3 \\end{pmatrix}$。\n\n    -   **对于 $i = k-2$**：\n        $\\alpha_{k-2} = \\rho_{k-2} s_{k-2}^T q = \\left(\\frac{1}{2}\\right) \\begin{pmatrix} 0 & 1 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ -3 \\end{pmatrix} = \\left(\\frac{1}{2}\\right)((0)(0) + (1)(-3)) = -\\frac{3}{2}$。\n        $q \\leftarrow q - \\alpha_{k-2} y_{k-2} = \\begin{pmatrix} 0 \\\\ -3 \\end{pmatrix} - \\left(-\\frac{3}{2}\\right) \\begin{pmatrix} -1 \\\\ 2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ -3 \\end{pmatrix} + \\begin{pmatrix} -\\frac{3}{2} \\\\ 3 \\end{pmatrix} = \\begin{pmatrix} 0 - \\frac{3}{2} \\\\ -3 + 3 \\end{pmatrix} = \\begin{pmatrix} -\\frac{3}{2} \\\\ 0 \\end{pmatrix}$。\n\n3.  **初始Hessian缩放：** 初始逆Hessian近似 $H_k^0$ 是一个对角矩阵 $\\gamma_k I$，其中 $\\gamma_k = \\frac{s_{k-1}^T y_{k-1}}{y_{k-1}^T y_{k-1}}$。我们通过将这个缩放后的单位矩阵与当前的 $q$ 相乘来初始化结果向量 $r$。\n    $s_{k-1}^T y_{k-1} = (1)(1) + (0)(1) = 1$。\n    $y_{k-1}^T y_{k-1} = (1)^2 + (1)^2 = 2$。\n    $\\gamma_k = \\frac{1}{2}$。\n    $r = \\gamma_k q = \\frac{1}{2} \\begin{pmatrix} -\\frac{3}{2} \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} -\\frac{3}{4} \\\\ 0 \\end{pmatrix}$。\n\n4.  **第二个循环（向前传递）：** 这个循环从 $i = k-m$ 向上迭代到 $i = k-1$。在我们的例子中，$i$ 从 $k-2$ 到 $k-1$。\n    -   **对于 $i = k-2$**：\n        $\\beta = \\rho_{k-2} y_{k-2}^T r = \\left(\\frac{1}{2}\\right) \\begin{pmatrix} -1 & 2 \\end{pmatrix} \\begin{pmatrix} -\\frac{3}{4} \\\\ 0 \\end{pmatrix} = \\left(\\frac{1}{2}\\right)((-1)(-\\frac{3}{4}) + (2)(0)) = \\frac{3}{8}$。\n        $r \\leftarrow r + s_{k-2} (\\alpha_{k-2} - \\beta) = \\begin{pmatrix} -\\frac{3}{4} \\\\ 0 \\end{pmatrix} + \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} \\left(-\\frac{3}{2} - \\frac{3}{8}\\right) = \\begin{pmatrix} -\\frac{3}{4} \\\\ 0 \\end{pmatrix} + \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} \\left(-\\frac{12}{8} - \\frac{3}{8}\\right) = \\begin{pmatrix} -\\frac{3}{4} \\\\ 0 \\end{pmatrix} + \\begin{pmatrix} 0 \\\\ -\\frac{15}{8} \\end{pmatrix} = \\begin{pmatrix} -\\frac{6}{8} \\\\ -\\frac{15}{8} \\end{pmatrix}$。\n\n    -   **对于 $i = k-1$**：\n        $\\beta = \\rho_{k-1} y_{k-1}^T r = (1) \\begin{pmatrix} 1 & 1 \\end{pmatrix} \\begin{pmatrix} -\\frac{6}{8} \\\\ -\\frac{15}{8} \\end{pmatrix} = (1)(-\\frac{6}{8}) + (1)(-\\frac{15}{8}) = -\\frac{21}{8}$。\n        $r \\leftarrow r + s_{k-1} (\\alpha_{k-1} - \\beta) = \\begin{pmatrix} -\\frac{6}{8} \\\\ -\\frac{15}{8} \\end{pmatrix} + \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\left(1 - \\left(-\\frac{21}{8}\\right)\\right) = \\begin{pmatrix} -\\frac{6}{8} \\\\ -\\frac{15}{8} \\end{pmatrix} + \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\left(\\frac{8}{8} + \\frac{21}{8}\\right) = \\begin{pmatrix} -\\frac{6}{8} \\\\ -\\frac{15}{8} \\end{pmatrix} + \\begin{pmatrix} \\frac{29}{8} \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} \\frac{23}{8} \\\\ -\\frac{15}{8} \\end{pmatrix}$。\n\n5.  双循环递归的最终结果是向量 $r = H_k g_k$。搜索方向为 $p_k = -r$。\n    $p_k = - \\begin{pmatrix} \\frac{23}{8} \\\\ -\\frac{15}{8} \\end{pmatrix} = \\begin{pmatrix} -\\frac{23}{8} \\\\ \\frac{15}{8} \\end{pmatrix}$。", "answer": "$$\\boxed{\\begin{pmatrix} -\\frac{23}{8} \\\\ \\frac{15}{8} \\end{pmatrix}}$$", "id": "2184578"}, {"introduction": "与最速下降法等更简单的方法相比，复杂的 L-BFGS 机制真的值得吗？最后一个练习 [@problem_id:2184555] 让您通过一个具体的例子直接回答这个问题。通过计算同一点的 L-BFGS 和最速下降搜索方向，您可以对它们进行定量和概念上的比较，从而深入了解 L-BFGS 如何利用曲率信息找到通往最小值的更有效路径。", "problem": "在数值优化领域，拟牛顿法是求解函数最小值的常用方法。其中一种方法是限制内存的 Broyden-Fletcher-Goldfarb-Shanno (L-BFGS) 算法，该算法利用有限次数的先前迭代信息来近似逆 Hessian 矩阵。\n\n考虑最小化二次目标函数 $f: \\mathbb{R}^2 \\to \\mathbb{R}$，其定义为：\n$$f(x_1, x_2) = x_1^2 + 4x_2^2$$\n一个优化算法当前处于迭代点 $\\mathbf{x}_1 = (2, -0.5)^T$。前一个迭代点是 $\\mathbf{x}_0 = (4, 1)^T$。我们希望比较两种不同方法在点 $\\mathbf{x}_1$ 处提出的搜索方向。\n\n第一种方法是最速下降法，其搜索方向 $\\mathbf{p}_{\\text{SD}}$ 就是当前点梯度的负方向，即 $\\mathbf{p}_{\\text{SD}} = -\\nabla f(\\mathbf{x}_1)$。\n\n第二种方法是内存为 $m=1$ 的 L-BFGS 算法。在当前迭代点 $\\mathbf{x}_1$ 处的搜索方向 $\\mathbf{p}_{\\text{L-BFGS}}$ 计算为 $\\mathbf{p}_{\\text{L-BFGS}} = -\\mathbf{r}$，其中向量 $\\mathbf{r}$ 是通过以下步骤（称为双循环递归）得到的结果：\n令 $\\mathbf{g}_1 = \\nabla f(\\mathbf{x}_1)$ 为当前梯度。从上一步我们得到向量 $\\mathbf{s}_0 = \\mathbf{x}_1 - \\mathbf{x}_0$ 和 $\\mathbf{y}_0 = \\nabla f(\\mathbf{x}_1) - \\nabla f(\\mathbf{x}_0)$。\n1.  初始化临时向量 $\\mathbf{q} \\leftarrow \\mathbf{g}_1$。\n2.  计算标量 $\\rho_0 = \\frac{1}{\\mathbf{y}_0^T \\mathbf{s}_0}$。\n3.  计算标量 $\\alpha_0 = \\rho_0 (\\mathbf{s}_0^T \\mathbf{q})$。\n4.  更新临时向量：$\\mathbf{q} \\leftarrow \\mathbf{q} - \\alpha_0 \\mathbf{y}_0$。\n5.  计算初始 Hessian 缩放因子 $\\gamma_0 = \\frac{\\mathbf{s}_0^T \\mathbf{y}_0}{\\mathbf{y}_0^T \\mathbf{y}_0}$。\n6.  初始化结果向量 $\\mathbf{r} \\leftarrow \\gamma_0 \\mathbf{q}$。\n7.  计算标量 $\\beta_0 = \\rho_0 (\\mathbf{y}_0^T \\mathbf{r})$。\n8.  更新结果向量：$\\mathbf{r} \\leftarrow \\mathbf{r} + (\\alpha_0 - \\beta_0) \\mathbf{s}_0$。\n\n你的任务是计算在点 $\\mathbf{x}_1$ 处，最速下降搜索方向 $\\mathbf{p}_{\\text{SD}}$ 与 L-BFGS 搜索方向 $\\mathbf{p}_{\\text{L-BFGS}}$ 之间夹角 $\\theta$ 的余弦值。请将你的答案以数值形式报告，并四舍五入到四位有效数字。", "solution": "目标函数为 $f(x_1, x_2) = x_1^2 + 4x_2^2$，所以梯度为 $\\nabla f(x_1, x_2)=(2x_1, 8x_2)^T$。\n\n在 $\\mathbf{x}_0=(4,1)^T$ 处，梯度为 $\\mathbf{g}_0=\\nabla f(\\mathbf{x}_0)=(8,8)^T$。在 $\\mathbf{x}_1=(2,-0.5)^T$ 处，梯度为 $\\mathbf{g}_1=\\nabla f(\\mathbf{x}_1)=(4,-4)^T$。\n\n在 $\\mathbf{x}_1$ 处的最速下降方向是\n$$\n\\mathbf{p}_{\\text{SD}} = -\\mathbf{g}_1 = (-4, 4)^T.\n$$\n\n对于 $m=1$ 的 L-BFGS 算法，定义 $\\mathbf{s}_0 = \\mathbf{x}_1 - \\mathbf{x}_0 = (-2, -1.5)^T$ 和 $\\mathbf{y}_0 = \\mathbf{g}_1 - \\mathbf{g}_0 = (-4, -12)^T$。计算\n$$\n\\mathbf{y}_0^T\\mathbf{s}_0 = (-4)(-2)+(-12)(-1.5) = 8+18 = 26, \\qquad \\rho_0 = \\frac{1}{\\mathbf{y}_0^T\\mathbf{s}_0} = \\frac{1}{26}.\n$$\n初始化 $\\mathbf{q} \\leftarrow \\mathbf{g}_1 = (4, -4)^T$ 并计算\n$$\n\\alpha_0 = \\rho_0(\\mathbf{s}_0^T\\mathbf{q}) = \\frac{1}{26}[(-2)(4)+(-1.5)(-4)] = \\frac{1}{26}(-8+6) = -\\frac{2}{26} = -\\frac{1}{13}.\n$$\n更新\n$$\n\\mathbf{q} \\leftarrow \\mathbf{q} - \\alpha_0\\mathbf{y}_0 = (4, -4)^T - \\left(-\\frac{1}{13}\\right)(-4, -12)^T = (4, -4)^T - \\left(\\frac{4}{13}, \\frac{12}{13}\\right)^T = \\left(\\frac{48}{13}, -\\frac{64}{13}\\right)^T.\n$$\n计算缩放因子\n$$\n\\gamma_0 = \\frac{\\mathbf{s}_0^T\\mathbf{y}_0}{\\mathbf{y}_0^T\\mathbf{y}_0} = \\frac{26}{(-4)^2+(-12)^2} = \\frac{26}{16+144} = \\frac{26}{160} = \\frac{13}{80},\n$$\n并初始化\n$$\n\\mathbf{r} \\leftarrow \\gamma_0\\mathbf{q} = \\frac{13}{80}\\left(\\frac{48}{13}, -\\frac{64}{13}\\right)^T = \\left(\\frac{48}{80}, -\\frac{64}{80}\\right)^T = \\left(\\frac{3}{5}, -\\frac{4}{5}\\right)^T.\n$$\n然后\n$$\n\\beta_0 = \\rho_0(\\mathbf{y}_0^T\\mathbf{r}) = \\frac{1}{26}\\left[(-4)\\left(\\frac{3}{5}\\right)+(-12)\\left(-\\frac{4}{5}\\right)\\right] = \\frac{1}{26}\\left(\\frac{-12+48}{5}\\right) = \\frac{36}{130} = \\frac{18}{65}.\n$$\n更新\n$$\n\\mathbf{r} \\leftarrow \\mathbf{r} + (\\alpha_0-\\beta_0)\\mathbf{s}_0 = \\left(\\frac{3}{5}, -\\frac{4}{5}\\right)^T + \\left(-\\frac{1}{13}-\\frac{18}{65}\\right)\\left(-2, -1.5\\right)^T = \\left(\\frac{17}{13}, -\\frac{7}{26}\\right)^T.\n$$\n因此 L-BFGS 方向是\n$$\n\\mathbf{p}_{\\text{L-BFGS}} = -\\mathbf{r} = \\left(-\\frac{17}{13}, \\frac{7}{26}\\right)^T.\n$$\n\n$\\mathbf{p}_{\\text{SD}}$ 和 $\\mathbf{p}_{\\text{L-BFGS}}$ 之间夹角的余弦值为\n$$\n\\cos\\theta = \\frac{\\mathbf{p}_{\\text{SD}}^T\\mathbf{p}_{\\text{L-BFGS}}}{\\|\\mathbf{p}_{\\text{SD}}\\| \\|\\mathbf{p}_{\\text{L-BFGS}}\\|}.\n$$\n计算分子和范数：\n$$\n\\mathbf{p}_{\\text{SD}}^T\\mathbf{p}_{\\text{L-BFGS}} = (-4)\\left(-\\frac{17}{13}\\right) + (4)\\left(\\frac{7}{26}\\right) = \\frac{68}{13} + \\frac{14}{13} = \\frac{82}{13},\n$$\n$$\n\\|\\mathbf{p}_{\\text{SD}}\\| = \\sqrt{(-4)^2+4^2} = \\sqrt{32} = 4\\sqrt{2},\n$$\n$$\n\\|\\mathbf{p}_{\\text{L-BFGS}}\\| = \\sqrt{\\left(-\\frac{17}{13}\\right)^2+\\left(\\frac{7}{26}\\right)^2} = \\sqrt{\\frac{1156+49}{676}} = \\frac{\\sqrt{1205}}{26}.\n$$\n因此\n$$\n\\cos\\theta = \\frac{\\frac{82}{13}}{4\\sqrt{2} \\cdot \\frac{\\sqrt{1205}}{26}} = \\frac{82 \\cdot 2}{4\\sqrt{2}\\sqrt{1205}} = \\frac{41}{\\sqrt{2410}}.\n$$\n数值上，$\\cos\\theta = \\frac{41}{\\sqrt{2410}}\\approx 0.8352$（四舍五入到四位有效数字）。", "answer": "$$\\boxed{0.8352}$$", "id": "2184555"}]}