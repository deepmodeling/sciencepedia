{"hands_on_practices": [{"introduction": "掌握Hessian矩阵的第一步是能够熟练地计算它。这个练习将通过一个在机器学习和正则化中无处不在的基础函数——平方欧几里得范数，来引导你进行实践。通过完成这个基础计算，你将为分析更复杂函数打下坚实的基础 [@problem_id:2198466]。", "problem": "在数值优化和机器学习的背景下，分析函数的局部曲率对于设计如牛顿法等高效算法至关重要。这种曲率由 Hessian 矩阵来刻画。\n\n考虑一个函数 $f: \\mathbb{R}^n \\to \\mathbb{R}$，它代表模型中的一个简化正则化项。该函数定义为向量 $x \\in \\mathbb{R}^n$ 的欧几里得范数的平方，并乘以一个常数因子：\n$$f(x) = \\frac{1}{2}\\|x\\|^2_2$$\n其中 $\\|x\\|_2 = \\sqrt{x_1^2 + x_2^2 + \\dots + x_n^2}$ 是标准欧几里得范数。\n\n$f$ 的 Hessian 矩阵记作 $\\nabla^2 f(x)$，它是一个 $n \\times n$ 矩阵，其第 $j$ 行第 $k$ 列的元素由二阶偏导数 $\\frac{\\partial^2 f}{\\partial x_j \\partial x_k}$ 给出。\n\n计算函数 $f(x)$ 对于任意向量 $x \\in \\mathbb{R}^n$ 的 Hessian 矩阵。将最终答案用 $n \\times n$ 单位矩阵 $I_n$ 表示。", "solution": "我们从函数作为平方和的定义开始：\n$$\nf(x) = \\frac{1}{2}\\|x\\|_{2}^{2} = \\frac{1}{2}\\sum_{i=1}^{n} x_{i}^{2}.\n$$\n为了计算 Hessian 矩阵，我们首先求梯度。对于每个坐标 $x_{j}$，其偏导数为\n$$\n\\frac{\\partial f}{\\partial x_{j}} = \\frac{1}{2}\\cdot 2 x_{j} = x_{j}.\n$$\n将这些分量组合起来，梯度为\n$$\n\\nabla f(x) = \\begin{pmatrix} x_{1} \\\\ \\vdots \\\\ x_{n} \\end{pmatrix} = x.\n$$\n接下来，我们计算二阶偏导数。对于 Hessian 矩阵第 $j$ 行第 $k$ 列的元素，\n$$\n\\frac{\\partial^{2} f}{\\partial x_{j}\\,\\partial x_{k}} = \\frac{\\partial}{\\partial x_{k}}\\left(\\frac{\\partial f}{\\partial x_{j}}\\right) = \\frac{\\partial}{\\partial x_{k}}(x_{j}) = \n\\begin{cases}\n1, & \\text{若 } j = k, \\\\\n0, & \\text{若 } j \\neq k,\n\\end{cases}\n$$\n这可以写作 $\\delta_{jk}$，即克罗内克 delta (Kronecker delta)。因此，Hessian 矩阵的主对角线元素为 $1$，非对角线元素为 $0$，这正是 $n \\times n$ 单位矩阵。所以，\n$$\n\\nabla^{2} f(x) = I_{n}.\n$$\n该矩阵是常数矩阵，不依赖于 $x$。", "answer": "$$\\boxed{I_{n}}$$", "id": "2198466"}, {"introduction": "计算出Hessian矩阵后，下一步是解读它所包含的信息。这个练习探讨了Hessian矩阵与函数凸性之间的关键联系，而凸性是确保局部最优解即为全局最优解的重要属性。通过确定Hessian矩阵正定的条件，你将亲身体验如何判别目标函数的几何形状 [@problem_id:2198477]。", "problem": "在数值优化领域，一个常见的任务是寻找一个函数的最小值。对于一个多元二次函数 $f(\\mathbf{x}) = \\frac{1}{2}\\mathbf{x}^T H \\mathbf{x} + \\mathbf{c}^T \\mathbf{x} + d$，其中 $\\mathbf{x}$ 是一个变量列向量，该函数是严格凸函数的充要条件是其Hessian矩阵 $H$ 是正定的。这个性质非常理想，因为它保证了任何找到的局部最小值也是唯一的全局最小值。\n\n考虑一个二维二次代价函数 $f(x_1, x_2)$，其Hessian矩阵由下式给出：\n$$\nH = \\begin{pmatrix} 2 & k \\\\ k & 8 \\end{pmatrix}\n$$\n其中 $k$ 是一个实值参数，可以在设计代价函数时进行调整。\n\n确定参数 $k$ 的取值范围，使得函数 $f(x_1, x_2)$ 是严格凸函数。\n\nA. $k < 4$\nB. $k > -4$\nC. $-4 < k < 4$\nD. $-4 \\leq k \\leq 4$\nE. $k > 4$ 或 $k < -4$\nF. $k = \\pm 4$", "solution": "对于一个具有常数Hessian矩阵 $H$ 的二次函数 $f(\\mathbf{x})=\\frac{1}{2}\\mathbf{x}^{T}H\\mathbf{x}+\\mathbf{c}^{T}\\mathbf{x}+d$，其严格凸性等价于 $H$ 是正定的。由于 $H$ 是对称的，根据 Sylvester 判据，其为正定的充要条件是所有顺序主子式都为正。\n\n给定\n$$\nH=\\begin{pmatrix}2 & k \\\\ k & 8\\end{pmatrix},\n$$\n第一个顺序主子式是\n$$\n\\Delta_{1}=2>0,\n$$\n这对所有实数 $k$ 都成立。第二个顺序主子式是行列式\n$$\n\\Delta_{2}=\\det(H)=2\\cdot 8 - k^{2}=16 - k^{2}.\n$$\n正定性要求\n$$\n16 - k^{2} > 0 \\quad \\Longleftrightarrow \\quad k^{2} < 16 \\quad \\Longleftrightarrow \\quad -4 < k < 4.\n$$\n因此，当且仅当 $-4<k<4$ 时，$H$ 是正定的，从而 $f$ 是严格凸的。这对应于选项C。", "answer": "$$\\boxed{C}$$", "id": "2198477"}, {"introduction": "Hessian矩阵的作用远不止于对函数形状的静态分析，它对于理解优化算法的动态行为至关重要。这个高级练习揭示了Hessian矩阵的性质，特别是其条件数$ \\kappa $，如何直接决定梯度下降法的收敛速度。通过这个推导，你将发现函数曲率与寻找其最小值的算法效率之间的深刻联系 [@problem_id:2198464]。", "problem": "考虑最小化强凸二次函数 $f(x) = \\frac{1}{2}x^T Q x - b^T x$ 的问题，其中 $x, b \\in \\mathbb{R}^n$，$Q$ 是一个 $n \\times n$ 的对称正定矩阵。该函数的最小值在唯一的点 $x^*$ 处取得。\n\n我们应用梯度下降法来寻找这个最小值，使用迭代更新规则 $x_{k+1} = x_k - \\alpha \\nabla f(x_k)$，其中 $k$ 是迭代次数，$\\alpha$ 是一个常数步长。令 $\\lambda_{\\min}$ 和 $\\lambda_{\\max}$ 分别为矩阵 $Q$ 的最小和最大特征值。对于此问题，我们使用特定的固定步长 $\\alpha = \\frac{2}{\\lambda_{\\min} + \\lambda_{\\max}}$。\n\n已知误差的欧几里得范数 $\\|x_k - x^*\\|_2$ 在每一步都会减小。收敛是线性的，意味着存在一个常数 $\\rho \\in [0, 1)$ 使得对所有 $k \\ge 0$ 都有 $\\|x_{k+1} - x^*\\|_2 \\le \\rho \\|x_k - x^*\\|_2$。\n\n你的任务是确定这个收敛因子 $\\rho$ 的最紧确的值。将你的最终答案仅用矩阵 $Q$ 的条件数 $\\kappa = \\frac{\\lambda_{\\max}}{\\lambda_{\\min}}$ 来表示。", "solution": "目标函数为 $f(x) = \\frac{1}{2}x^T Q x - b^T x$。其梯度由 $\\nabla f(x) = Qx - b$ 给出。\n最优解 $x^*$ 通过将梯度设为零找到：$\\nabla f(x^*) = Qx^* - b = 0$，这意味着 $b = Qx^*$。\n\n梯度下降的更新规则是 $x_{k+1} = x_k - \\alpha \\nabla f(x_k)$。\n代入梯度的表达式，我们得到：\n$x_{k+1} = x_k - \\alpha (Qx_k - b)$。\n\n定义第 $k$ 次迭代的误差为 $e_k = x_k - x^*$。我们想要找到误差的递归关系。\n$e_{k+1} = x_{k+1} - x^* = (x_k - \\alpha (Qx_k - b)) - x^*$。\n代入 $b = Qx^*$：\n$e_{k+1} = x_k - \\alpha (Qx_k - Qx^*) - x^* = (x_k - x^*) - \\alpha Q(x_k - x^*)$。\n这给出了误差的更新规则：\n$e_{k+1} = (I - \\alpha Q)e_k$。\n\n为了分析在欧几里得范数下的收敛性，我们对两边取 2-范数：\n$\\|e_{k+1}\\|_2 = \\|(I - \\alpha Q)e_k\\|_2$。\n使用矩阵范数的性质 $\\|Ax\\|_2 \\le \\|A\\|_2 \\|x\\|_2$，其中 $\\|A\\|_2$ 是 $A$ 的谱范数，我们得到：\n$\\|e_{k+1}\\|_2 \\le \\|I - \\alpha Q\\|_2 \\|e_k\\|_2$。\n因此，收敛因子 $\\rho$ 是迭代矩阵 $G = I - \\alpha Q$ 的谱范数。\n$\\rho = \\|I - \\alpha Q\\|_2$。\n\n由于 $Q$ 是对称矩阵，矩阵 $G = I - \\alpha Q$ 也是对称的。对称矩阵的谱范数是其特征值绝对值的最大值。\n令 $\\lambda_i$ ($i=1, \\dots, n$) 为 $Q$ 的特征值。由于 $Q$ 是正定的，对所有 $i$ 都有 $0 < \\lambda_{\\min} \\le \\lambda_i \\le \\lambda_{\\max}$。\n$G = I - \\alpha Q$ 的特征值是 $\\mu_i = 1 - \\alpha \\lambda_i$。\n所以，收敛因子是：\n$\\rho = \\|G\\|_2 = \\max_{i} |\\mu_i| = \\max_{i} |1 - \\alpha \\lambda_i|$。\n\n函数 $g(\\lambda) = |1 - \\alpha \\lambda|$ 在区间 $[\\lambda_{\\min}, \\lambda_{\\max}]$ 上的最大值在某个端点处取得。因此，\n$\\rho = \\max(|1 - \\alpha \\lambda_{\\min}|, |1 - \\alpha \\lambda_{\\max}|)$。\n\n问题指定了步长 $\\alpha = \\frac{2}{\\lambda_{\\min} + \\lambda_{\\max}}$。我们将这个值代入 $\\rho$ 的表达式中。\n让我们计算最大值函数内部的两项。\n第一项：\n$1 - \\alpha \\lambda_{\\min} = 1 - \\frac{2\\lambda_{\\min}}{\\lambda_{\\min} + \\lambda_{\\max}} = \\frac{(\\lambda_{\\min} + \\lambda_{\\max}) - 2\\lambda_{\\min}}{\\lambda_{\\min} + \\lambda_{\\max}} = \\frac{\\lambda_{\\max} - \\lambda_{\\min}}{\\lambda_{\\max} + \\lambda_{\\min}}$。\n第二项：\n$1 - \\alpha \\lambda_{\\max} = 1 - \\frac{2\\lambda_{\\max}}{\\lambda_{\\min} + \\lambda_{\\max}} = \\frac{(\\lambda_{\\min} + \\lambda_{\\max}) - 2\\lambda_{\\max}}{\\lambda_{\\min} + \\lambda_{\\max}} = \\frac{\\lambda_{\\min} - \\lambda_{\\max}}{\\lambda_{\\min} + \\lambda_{\\max}} = - \\frac{\\lambda_{\\max} - \\lambda_{\\min}}{\\lambda_{\\max} + \\lambda_{\\min}}$。\n\n这两项的绝对值相等：\n$|1 - \\alpha \\lambda_{\\min}| = |1 - \\alpha \\lambda_{\\max}| = \\frac{\\lambda_{\\max} - \\lambda_{\\min}}{\\lambda_{\\max} + \\lambda_{\\min}}$。\n因此，收敛因子是：\n$\\rho = \\frac{\\lambda_{\\max} - \\lambda_{\\min}}{\\lambda_{\\max} + \\lambda_{\\min}}$。\n\n最后，我们需要用条件数 $\\kappa = \\frac{\\lambda_{\\max}}{\\lambda_{\\min}}$ 来表示这个结果。为此，我们将 $\\rho$ 表达式的分子和分母同时除以 $\\lambda_{\\min}$ (其为严格正数)：\n$\\rho = \\frac{\\frac{\\lambda_{\\max}}{\\lambda_{\\min}} - \\frac{\\lambda_{\\min}}{\\lambda_{\\min}}}{\\frac{\\lambda_{\\max}}{\\lambda_{\\min}} + \\frac{\\lambda_{\\min}}{\\lambda_{\\min}}} = \\frac{\\kappa - 1}{\\kappa + 1}$。\n\n这是在给定步长下，收敛因子 $\\rho$ 的最紧确的值。", "answer": "$$\\boxed{\\frac{\\kappa - 1}{\\kappa + 1}}$$", "id": "2198464"}]}