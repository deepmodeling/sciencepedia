{"hands_on_practices": [{"introduction": "本练习将引导你完成精确线搜索的基本流程。我们将从一个简单的二次函数入手，计算其在初始点的最速下降方向，然后通过求解一维优化问题来确定最佳步长。这个实践旨在帮助你掌握将多维搜索问题简化为一维问题的核心技巧，这是许多优化算法的基石。[@problem_id:2170891]", "problem": "考虑最小化二次目标函数 $f(x_1, x_2) = (x_1 + x_2 - 2)^2$ 的优化问题。我们将从初始点 $\\mathbf{x}_0 = (0, 0)$ 开始，执行一步最速下降算法。该步骤的搜索方向是最速下降方向，定义为 $\\mathbf{p}_0 = -\\nabla f(\\mathbf{x}_0)$，其中 $\\nabla f$ 是函数的梯度。\n\n为了找到沿此方向移动的最优距离，我们执行精确线搜索。此过程涉及求解一个一维最小化问题，以找到使函数 $g(\\alpha) = f(\\mathbf{x}_0 + \\alpha\\mathbf{p}_0)$ 最小化的步长 $\\alpha > 0$。\n\n确定此过程得到的精确最优步长 $\\alpha^*$。", "solution": "我们给定二次函数 $f(x_{1}, x_{2}) = (x_{1} + x_{2} - 2)^{2}$ 和初始点 $\\mathbf{x}_{0} = (0, 0)$。最速下降方向定义为 $\\mathbf{p}_{0} = -\\nabla f(\\mathbf{x}_{0})$，其中梯度通过微分计算：\n$$\n\\nabla f(x_{1}, x_{2}) = \\left(\\frac{\\partial f}{\\partial x_{1}}, \\frac{\\partial f}{\\partial x_{2}}\\right).\n$$\n由于 $f(x_{1}, x_{2}) = (x_{1} + x_{2} - 2)^{2}$，根据链式法则，\n$$\n\\frac{\\partial f}{\\partial x_{1}} = 2(x_{1} + x_{2} - 2)\\cdot \\frac{\\partial}{\\partial x_{1}}(x_{1} + x_{2} - 2) = 2(x_{1} + x_{2} - 2),\n$$\n类似地，\n$$\n\\frac{\\partial f}{\\partial x_{2}} = 2(x_{1} + x_{2} - 2).\n$$\n因此，\n$$\n\\nabla f(x_{1}, x_{2}) = 2(x_{1} + x_{2} - 2)\\,(1, 1).\n$$\n在 $\\mathbf{x}_{0} = (0, 0)$ 处求值得到\n$$\n\\nabla f(\\mathbf{x}_{0}) = 2(0 + 0 - 2)\\,(1, 1) = -4\\,(1, 1) = (-4, -4),\n$$\n所以最速下降方向是\n$$\n\\mathbf{p}_{0} = -\\nabla f(\\mathbf{x}_{0}) = (4, 4).\n$$\n对于精确线搜索，定义一元函数\n$$\ng(\\alpha) = f(\\mathbf{x}_{0} + \\alpha \\mathbf{p}_{0}) = f\\big((0, 0) + \\alpha(4, 4)\\big) = f(4\\alpha, 4\\alpha).\n$$\n代入 $f$ 中，\n$$\ng(\\alpha) = (4\\alpha + 4\\alpha - 2)^{2} = (8\\alpha - 2)^{2}.\n$$\n为了在 $\\alpha > 0$ 上最小化 $g(\\alpha)$，将其导数设为零：\n$$\ng'(\\alpha) = 2(8\\alpha - 2)\\cdot 8 = 16(8\\alpha - 2).\n$$\n求解 $g'(\\alpha) = 0$：\n$$\n16(8\\alpha - 2) = 0 \\;\\;\\Longrightarrow\\;\\; 8\\alpha - 2 = 0 \\;\\;\\Longrightarrow\\;\\; \\alpha^{*} = \\frac{1}{4}.\n$$\n这满足 $\\alpha^{*} > 0$，并给出了沿搜索方向的精确极小点。", "answer": "$$\\boxed{\\frac{1}{4}}$$", "id": "2170891"}, {"introduction": "在掌握了二次函数的基础之上，我们现在将精确线搜索方法应用到一个更复杂的场景：三角函数。这个练习将挑战你处理非多项式和周期性函数，其中可能存在多个局部最小值。通过解决这个问题，你将学会如何辨别并选择最合适的步长，从而加深对线搜索方法普适性的理解。[@problem_id:2170899]", "problem": "考虑使用迭代优化算法最小化单变量目标函数 $f(x)$ 的过程。此类算法中的一个关键步骤是线搜索，即从一个点 $x_k$ 开始，我们寻找一个步长 $\\alpha$ 来最小化函数在给定搜索方向 $p_k$ 上的值。序列中的下一个点则由 $x_{k+1} = x_k + \\alpha p_k$ 决定。\n\n设目标函数为 $f(x) = \\sin(x) + \\cos(x)$，其中参数 $x$ 的单位是弧度。假设我们处于初始点 $x_0 = 0$。搜索方向选择为最速下降方向，对于单变量函数，该方向由 $p_0 = -f'(x_0)$ 给出，其中 $f'(x_0)$ 是 $f(x)$ 在 $x_0$ 处的导数。\n\n确定最小的正步长 $\\alpha > 0$，使得函数在此方向上最小化。也就是说，找到最小的正 $\\alpha$，使得新函数 $\\phi(\\alpha) = f(x_0 + \\alpha p_0)$ 最小化。\n\n请以闭式解析表达式的形式给出 $\\alpha$ 的精确值。", "solution": "我们已知 $f(x) = \\sin(x) + \\cos(x)$ 且 $x_{0} = 0$。最速下降方向是 $p_{0} = -f'(x_{0})$。计算导数：\n$$\nf'(x) = \\cos(x) - \\sin(x).\n$$\n在 $x_{0} = 0$ 处求值：\n$$\nf'(0) = \\cos(0) - \\sin(0) = 1 - 0 = 1,\n$$\n所以\n$$\np_{0} = -f'(0) = -1.\n$$\n定义线搜索目标函数 $\\phi(\\alpha) = f(x_{0} + \\alpha p_{0})$：\n$$\n\\phi(\\alpha) = f(0 + \\alpha(-1)) = f(-\\alpha) = \\sin(-\\alpha) + \\cos(-\\alpha) = -\\sin(\\alpha) + \\cos(\\alpha).\n$$\n为了在 $\\alpha > 0$ 的范围内最小化 $\\phi(\\alpha)$，我们求导并令其为零：\n$$\n\\phi'(\\alpha) = -\\cos(\\alpha) - \\sin(\\alpha) = 0 \\quad \\Longleftrightarrow \\quad \\cos(\\alpha) + \\sin(\\alpha) = 0.\n$$\n这得到\n$$\n\\tan(\\alpha) = -1 \\quad \\text{其中} \\quad \\cos(\\alpha) \\neq 0 \\quad \\Longrightarrow \\quad \\alpha = -\\frac{\\pi}{4} + n\\pi, \\quad n \\in \\mathbb{Z}.\n$$\n在正数解中，当 $n=1$ 时得到最小解：\n$$\n\\alpha = -\\frac{\\pi}{4} + \\pi = \\frac{3\\pi}{4}.\n$$\n通过二阶导数验证它是一个最小值：\n$$\n\\phi''(\\alpha) = \\sin(\\alpha) - \\cos(\\alpha).\n$$\n在 $\\alpha = \\frac{3\\pi}{4}$ 处，$\\sin\\left(\\frac{3\\pi}{4}\\right) > 0$ 且 $\\cos\\left(\\frac{3\\pi}{4}\\right) < 0$，因此 $\\phi''\\left(\\frac{3\\pi}{4}\\right) > 0$，这证实了它是一个局部最小值。由于 $\\phi$ 是周期为 $2\\pi$ 的周期函数，且所有最小值都出现在 $\\alpha = \\frac{3\\pi}{4} + 2\\pi k$（其中 $k \\in \\mathbb{Z}$）处，因此最小的正数最小值点是 $\\alpha = \\frac{3\\pi}{4}$。", "answer": "$$\\boxed{\\frac{3\\pi}{4}}$$", "id": "2170899"}, {"introduction": "这个练习将你的技能从单纯的计算提升到分析和推理的层面。它不再是求解一个具体的步长，而是通过观察优化算法的特定行为——迭代点从一个坐标轴移动到另一个坐标轴——来反推目标函数的内在属性。这项实践旨在培养你深入理解函数几何形态（由其参数 $A$ 和 $B$ 决定）与算法迭代路径之间相互关系的分析能力。[@problem_id:2170940]", "problem": "考虑一个二次目标函数 $f(x_1, x_2) = \\frac{A}{2} x_1^2 + \\frac{B}{2} x_2^2 - C x_2$，其中 $A, B, C$ 是正实数常量。使用带有精确线搜索的最速下降法来求此函数的最小值。观测到对于任意起始点 $\\mathbf{x}_0 = (x_{0,1}, 0)$ 且 $x_{0,1} \\neq 0$，算法的第一次迭代结果 $\\mathbf{x}_1$ 总是落在 $x_2$ 轴上。根据此观测，确定比值 $B/A$ 的值。", "solution": "我们用带有精确线搜索的最速下降法来最小化二次函数 $f(x_{1},x_{2})=\\frac{A}{2}x_{1}^{2}+\\frac{B}{2}x_{2}^{2}-C x_{2}$，其中 $A>0$，$B>0$，$C>0$。其梯度和Hessian矩阵为\n$$\n\\nabla f(x_{1},x_{2})=\\begin{pmatrix}A x_{1}\\\\ B x_{2}-C\\end{pmatrix},\\qquad H=\\begin{pmatrix}A&0\\\\0&B\\end{pmatrix}.\n$$\n设起始点为 $\\mathbf{x}_{0}=(x_{0,1},0)$，其中 $x_{0,1}\\neq 0$。那么初始梯度为\n$$\ng_{0}=\\nabla f(\\mathbf{x}_{0})=\\begin{pmatrix}A x_{0,1}\\\\ -C\\end{pmatrix}.\n$$\n最速下降方向为 $d_{0}=-g_{0}$，并且在精确线搜索下，步长 $\\alpha_{0}$ 最小化 $\\phi(\\alpha)=f(\\mathbf{x}_{0}+\\alpha d_{0})$。对于二次函数，使用 $\\nabla f(\\mathbf{x}_{0}+\\alpha d_{0})=\\nabla f(\\mathbf{x}_{0})+\\alpha H d_{0}$，我们有\n$$\n\\phi'(\\alpha)=\\nabla f(\\mathbf{x}_{0}+\\alpha d_{0})^{\\top} d_{0}\n=\\left(g_{0}+\\alpha H d_{0}\\right)^{\\top} d_{0}\n=g_{0}^{\\top} d_{0}+\\alpha d_{0}^{\\top} H d_{0}.\n$$\n令 $\\phi'(\\alpha_{0})=0$ 可得\n$$\n\\alpha_{0}=\\frac{g_{0}^{\\top} g_{0}}{g_{0}^{\\top} H g_{0}}.\n$$\n计算所需的量：\n$$\ng_{0}^{\\top} g_{0}=(A x_{0,1})^{2}+C^{2}=A^{2}x_{0,1}^{2}+C^{2},\n$$\n$$\nH g_{0}=\\begin{pmatrix}A&0\\\\0&B\\end{pmatrix}\\begin{pmatrix}A x_{0,1}\\\\ -C\\end{pmatrix}\n=\\begin{pmatrix}A^{2} x_{0,1}\\\\ -B C\\end{pmatrix},\n$$\n$$\ng_{0}^{\\top} H g_{0}=(A x_{0,1})(A^{2} x_{0,1})+(-C)(-B C)=A^{3} x_{0,1}^{2}+B C^{2}.\n$$\n因此\n$$\n\\alpha_{0}=\\frac{A^{2} x_{0,1}^{2}+C^{2}}{A^{3} x_{0,1}^{2}+B C^{2}}.\n$$\n第一次迭代的结果是\n$$\n\\mathbf{x}_{1}=\\mathbf{x}_{0}-\\alpha_{0} g_{0}=\\begin{pmatrix}x_{0,1}-\\alpha_{0} A x_{0,1}\\\\ 0-\\alpha_{0}(-C)\\end{pmatrix},\n$$\n所以它的第一个分量是\n$$\nx_{1,1}=x_{0,1}\\left(1-\\alpha_{0} A\\right).\n$$\n观测表明，对于任意 $x_{0,1}\\neq 0$，$\\mathbf{x}_1$ 总是落在 $x_2$ 轴上，因此对于所有这样的 $x_{0,1}$ 都有 $x_{1,1}=0$。所以，$1-\\alpha_{0} A=0$ 必须对所有 $x_{0,1}$ 成立，即\n$$\n\\alpha_{0}=\\frac{1}{A}.\n$$\n将其与精确线搜索的表达式相等，可得\n$$\n\\frac{A^{2} x_{0,1}^{2}+C^{2}}{A^{3} x_{0,1}^{2}+B C^{2}}=\\frac{1}{A}.\n$$\n交叉相乘并化简，\n$$\nA\\left(A^{2} x_{0,1}^{2}+C^{2}\\right)=A^{3} x_{0,1}^{2}+B C^{2}\n\\;\\;\\Longrightarrow\\;\\;\nA^{3} x_{0,1}^{2}+A C^{2}=A^{3} x_{0,1}^{2}+B C^{2}\n\\;\\;\\Longrightarrow\\;\\;\n(A-B) C^{2}=0.\n$$\n因为 $C>0$，所以可得 $A=B$，因此\n$$\n\\frac{B}{A}=1.\n$$\n这个条件也是充分的，因为如果 $A=B$，那么对于任意 $x_{0,1}$，都有 $\\alpha_{0}=(A^{2} x_{0,1}^{2}+C^{2})/(A^{3} x_{0,1}^{2}+A C^{2})=1/A$，从而得到 $x_{1,1}=x_{0,1}(1-\\alpha_{0} A)=0$。", "answer": "$$\\boxed{1}$$", "id": "2170940"}]}