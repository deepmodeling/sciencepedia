{"hands_on_practices": [{"introduction": "在我们应用完整的 DFP 更新公式之前，我们必须首先理解其核心输入：步长向量 $s_k$ 和梯度变化向量 $y_k$。本练习将提供计算这两个基本量的实践机会，这些量是根据函数的迭代点和梯度计算得出的。掌握这一步对于正确实施任何拟牛顿法都至关重要。[@problem_id:2212535]", "problem": "在拟牛顿优化方法（例如 Davidon-Fletcher-Powell (DFP) 算法）的背景下，海森矩阵的近似在每次迭代中都会被更新。此更新依赖于两个关键向量，记为 $s_k$ 和 $y_k$。向量 $s_k$ 表示在变量空间中所走的步长，而向量 $y_k$ 表示梯度的相应变化。\n\n考虑函数 $f(x_1, x_2) = 2x_1^2 + x_2^2 + x_1 x_2$ 的无约束优化问题。\n假设我们处于第 $k$ 次迭代，当前点为 $x_k = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$。通过某个线搜索过程找到序列中的下一个点是 $x_{k+1} = \\begin{pmatrix} 0.5 \\\\ 1 \\end{pmatrix}$。\n\nDFP 更新所需的向量定义为 $s_k = x_{k+1} - x_k$ 和 $y_k = \\nabla f(x_{k+1}) - \\nabla f(x_k)$。\n\n下列哪个选项正确表示了本次迭代的向量 $s_k$ 和 $y_k$？\n\nA. $s_k = \\begin{pmatrix} -0.5 \\\\ 1 \\end{pmatrix}$, $y_k = \\begin{pmatrix} -1 \\\\ 1.5 \\end{pmatrix}$\n\nB. $s_k = \\begin{pmatrix} 0.5 \\\\ -1 \\end{pmatrix}$, $y_k = \\begin{pmatrix} 1 \\\\ -1.5 \\end{pmatrix}$\n\nC. $s_k = \\begin{pmatrix} 1.5 \\\\ 1 \\end{pmatrix}$, $y_k = \\begin{pmatrix} 7 \\\\ 3.5 \\end{pmatrix}$\n\nD. $s_k = \\begin{pmatrix} -1 \\\\ 1.5 \\end{pmatrix}$, $y_k = \\begin{pmatrix} -0.5 \\\\ 1 \\end{pmatrix}$\n\nE. $s_k = \\begin{pmatrix} -0.5 \\\\ 1 \\end{pmatrix}$, $y_k = \\begin{pmatrix} 7 \\\\ 3.5 \\end{pmatrix}$", "solution": "我们已知函数 $f(x_{1},x_{2})=2x_{1}^{2}+x_{2}^{2}+x_{1}x_{2}$。通过按分量求导得到梯度：\n$$\n\\nabla f(x_{1},x_{2})=\\begin{pmatrix}\\frac{\\partial f}{\\partial x_{1}}\\\\ \\frac{\\partial f}{\\partial x_{2}}\\end{pmatrix}\n=\\begin{pmatrix}4x_{1}+x_{2}\\\\ 2x_{2}+x_{1}\\end{pmatrix}.\n$$\n根据定义，位移向量为 $s_{k}=x_{k+1}-x_{k}$。已知 $x_{k}=\\begin{pmatrix}1\\\\ 0\\end{pmatrix}$ 和 $x_{k+1}=\\begin{pmatrix}\\tfrac{1}{2}\\\\ 1\\end{pmatrix}$，我们得到\n$$\ns_{k}=\\begin{pmatrix}\\tfrac{1}{2}-1\\\\ 1-0\\end{pmatrix}=\\begin{pmatrix}-\\tfrac{1}{2}\\\\ 1\\end{pmatrix}.\n$$\n接下来，梯度变化为 $y_{k}=\\nabla f(x_{k+1})-\\nabla f(x_{k})$。计算在每个点上的梯度：\n$$\n\\nabla f(x_{k})=\\nabla f(1,0)=\\begin{pmatrix}4\\cdot 1+0\\\\ 2\\cdot 0+1\\end{pmatrix}=\\begin{pmatrix}4\\\\ 1\\end{pmatrix},\n$$\n$$\n\\nabla f(x_{k+1})=\\nabla f\\!\\left(\\tfrac{1}{2},1\\right)=\\begin{pmatrix}4\\cdot \\tfrac{1}{2}+1\\\\ 2\\cdot 1+\\tfrac{1}{2}\\end{pmatrix}=\\begin{pmatrix}3\\\\ \\tfrac{5}{2}\\end{pmatrix}.\n$$\n因此，\n$$\ny_{k}=\\begin{pmatrix}3-4\\\\ \\tfrac{5}{2}-1\\end{pmatrix}=\\begin{pmatrix}-1\\\\ \\tfrac{3}{2}\\end{pmatrix}.\n$$\n与选项比较，这对应于 $s_{k}=\\begin{pmatrix}-\\tfrac{1}{2}\\\\ 1\\end{pmatrix}$ 和 $y_{k}=\\begin{pmatrix}-1\\\\ \\tfrac{3}{2}\\end{pmatrix}$，即选项 A。", "answer": "$$\\boxed{A}$$", "id": "2212535"}, {"introduction": "在理解了 $s_k$ 和 $y_k$ 的基础上，我们现在可以构建 DFP 对逆 Hessian 矩阵近似 $H_k$ 的更新。从标准初始猜测 $H_0 = I$（单位矩阵）开始，本练习将引导你完成单次更新所需的矩阵计算。这项实践将巩固你对 DFP 公式结构及其不同组成部分作用的理解。[@problem_id:2212500]", "problem": "在数值优化领域，拟牛顿法是用于寻找函数局部最小值或最大值的迭代算法。这些方法的一个关键特征是近似Hessian矩阵或其逆矩阵。最早且最著名的拟牛顿算法之一是 Davidon-Fletcher-Powell (DFP) 方法。\n\n用于近似Hessian矩阵的逆矩阵（记为 $H$）的DFP更新公式由下式给出：\n$$H_{k+1} = H_k + \\frac{s_k s_k^T}{s_k^T y_k} - \\frac{H_k y_k y_k^T H_k}{y_k^T H_k y_k}$$\n其中 $k$ 是迭代索引，$s_k = x_{k+1} - x_k$ 是在参数空间中移动的步长，$y_k = \\nabla f(x_{k+1}) - \\nabla f(x_k)$ 是目标函数 $f(x)$ 梯度的变化量。\n\n考虑一个优化过程的第一步（$k=0$）。逆Hessian矩阵的初始近似被设置为单位矩阵，$H_0 = I$。经过第一次线性搜索后，计算出步长向量 $s_0$ 和梯度变化向量 $y_0$ 为：\n$$s_0 = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix}, \\quad y_0 = \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix}$$\n\n你的任务是计算这第一步之后更新的逆Hessian近似矩阵 $H_1$。将你的答案表示为一个包含分数元素的矩阵。", "solution": "我们使用 DFP 更新公式来近似逆Hessian矩阵：\n$$H_{k+1} = H_{k} + \\frac{s_{k}s_{k}^{T}}{s_{k}^{T}y_{k}} - \\frac{H_{k}y_{k}y_{k}^{T}H_{k}}{y_{k}^{T}H_{k}y_{k}}.$$\n在第一步，$k=0$ 时，$H_{0}=I$，$s_{0}=\\begin{pmatrix}1 \\\\ -2\\end{pmatrix}$，以及 $y_{0}=\\begin{pmatrix}2 \\\\ -1\\end{pmatrix}$。因为 $H_{0}=I$，我们有 $H_{0}y_{0}=y_{0}$ 和 $y_{0}^{T}H_{0}y_{0}=y_{0}^{T}y_{0}$。因此，\n$$H_{1} = I + \\frac{s_{0}s_{0}^{T}}{s_{0}^{T}y_{0}} - \\frac{y_{0}y_{0}^{T}}{y_{0}^{T}y_{0}}.$$\n计算所需的内积：\n$$s_{0}^{T}y_{0} = 1\\cdot 2 + (-2)\\cdot(-1) = 4,$$\n$$y_{0}^{T}y_{0} = 2^{2} + (-1)^{2} = 5.$$\n计算外积：\n$$s_{0}s_{0}^{T} = \\begin{pmatrix}1 & -2 \\\\ -2 & 4\\end{pmatrix}, \\quad y_{0}y_{0}^{T} = \\begin{pmatrix}4 & -2 \\\\ -2 & 1\\end{pmatrix}.$$\n因此，\n$$\\frac{s_{0}s_{0}^{T}}{s_{0}^{T}y_{0}} = \\frac{1}{4}\\begin{pmatrix}1 & -2 \\\\ -2 & 4\\end{pmatrix} = \\begin{pmatrix}\\frac{1}{4} & -\\frac{1}{2} \\\\ -\\frac{1}{2} & 1\\end{pmatrix}, \\quad \\frac{y_{0}y_{0}^{T}}{y_{0}^{T}y_{0}} = \\frac{1}{5}\\begin{pmatrix}4 & -2 \\\\ -2 & 1\\end{pmatrix} = \\begin{pmatrix}\\frac{4}{5} & -\\frac{2}{5} \\\\ -\\frac{2}{5} & \\frac{1}{5}\\end{pmatrix}.$$\n合并各项：\n$$H_{1} = I + \\begin{pmatrix}\\frac{1}{4} & -\\frac{1}{2} \\\\ -\\frac{1}{2} & 1\\end{pmatrix} - \\begin{pmatrix}\\frac{4}{5} & -\\frac{2}{5} \\\\ -\\frac{2}{5} & \\frac{1}{5}\\end{pmatrix}.$$\n计算每个元素：\n$$(1,1): 1 + \\frac{1}{4} - \\frac{4}{5} = \\frac{5}{4} - \\frac{4}{5} = \\frac{25 - 16}{20} = \\frac{9}{20},$$\n$$(1,2) \\text{ and } (2,1): 0 - \\frac{1}{2} - \\left(-\\frac{2}{5}\\right) = -\\frac{1}{2} + \\frac{2}{5} = -\\frac{1}{10},$$\n$$(2,2): 1 + 1 - \\frac{1}{5} = 2 - \\frac{1}{5} = \\frac{9}{5}.$$\n因此，\n$$H_{1} = \\begin{pmatrix}\\frac{9}{20} & -\\frac{1}{10} \\\\ -\\frac{1}{10} & \\frac{9}{5}\\end{pmatrix}.$$\n作为检验，割线条件 $H_{1}y_{0}=s_{0}$ 成立：\n$$\\begin{pmatrix}\\frac{9}{20} & -\\frac{1}{10} \\\\ -\\frac{1}{10} & \\frac{9}{5}\\end{pmatrix}\\begin{pmatrix}2 \\\\ -1\\end{pmatrix} = \\begin{pmatrix}1 \\\\ -2\\end{pmatrix} = s_{0}.$$", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{9}{20} & -\\frac{1}{10} \\\\ -\\frac{1}{10} & \\frac{9}{5}\\end{pmatrix}}$$", "id": "2212500"}, {"introduction": "一个稳健的数值算法不仅要保证理论上的正确性，还必须在实践中保持数值稳定。本练习旨在探讨 DFP 更新公式的数值特性，特别是逆 Hessian 矩阵近似 $H_k$ 的条件数如何发生变化。通过分析一个步长方向 $s_k$ 与梯度变化 $y_k$ 近乎正交的特定场景，您将亲身体会到为何 DFP 更新可能导致矩阵的病态，这是理解该方法实际局限性的一个关键洞察。[@problem_id:2212484]", "problem": "在无约束最优化的拟牛顿法中，有一类算法用于寻找函数的局部极小值。其中一种方法使用Davidon-Fletcher-Powell (DFP) 公式在每次迭代中更新逆Hessian矩阵的近似。设在第 $k$ 步的这个近似矩阵记为 $H_k$。\n\nDFP更新公式如下：\n$$H_{k+1} = H_k + \\frac{s_k s_k^T}{s_k^T y_k} - \\frac{H_k y_k y_k^T H_k}{y_k^T H_k y_k}$$\n其中 $s_k = x_{k+1} - x_k$ 是从迭代点 $x_k$ 到 $x_{k+1}$ 的步长，而 $y_k = \\nabla f(x_{k+1}) - \\nabla f(x_k)$ 是目标函数 $f$ 梯度的相应变化。\n\n考虑在 $\\mathbb{R}^2$ 上的一个优化过程中的某一步，其中当前的逆Hessian近似是单位矩阵，$H_k = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}$。该次迭代的步长向量和梯度变化量分别为 $s_k = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ 和 $y_k = \\begin{pmatrix} 0.01 \\\\ 1 \\end{pmatrix}$。\n\n您的任务是计算更新后的逆Hessian近似矩阵 $H_{k+1}$ 的条件数。对称正定矩阵 $H$ 的条件数定义为其最大特征值与最小特征值之比，即 $\\kappa(H) = \\frac{\\lambda_{\\max}}{\\lambda_{\\min}}$。\n\n请将您的答案表示为一个实数，并四舍五入到三位有效数字。", "solution": "我们使用DFP逆Hessian更新公式\n$$H_{k+1} = H_k + \\frac{s_k s_k^{T}}{s_k^{T} y_k} - \\frac{H_k y_k y_k^{T} H_k}{y_k^{T} H_k y_k}.$$\n当 $H_k = I$ 时，公式简化为\n$$H_{k+1} = I + \\frac{s_k s_k^{T}}{s_k^{T} y_k} - \\frac{y_k y_k^{T}}{y_k^{T} y_k}.$$\n这里 $s_k = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix}$ 且 $y_k = \\begin{pmatrix}0.01 \\\\ 1\\end{pmatrix}$，因此\n$$s_k^{T} y_k = 0.01,\\qquad y_k^{T} y_k = 0.01^{2} + 1^{2} = 1.0001 = \\frac{10001}{10000}.$$\n并且，\n$$s_k s_k^{T} = \\begin{pmatrix}1 & 0 \\\\ 0 & 0\\end{pmatrix},\\qquad y_k y_k^{T} = \\begin{pmatrix}0.0001 & 0.01 \\\\ 0.01 & 1\\end{pmatrix}.$$\n因此\n$$\\frac{s_k s_k^{T}}{s_k^{T} y_k} = \\begin{pmatrix}100 & 0 \\\\ 0 & 0\\end{pmatrix},\\qquad\n\\frac{y_k y_k^{T}}{y_k^{T} y_k} = \\frac{10000}{10001}\\begin{pmatrix}0.0001 & 0.01 \\\\ 0.01 & 1\\end{pmatrix}\n= \\begin{pmatrix}\\frac{1}{10001} & \\frac{100}{10001} \\\\ \\frac{100}{10001} & \\frac{10000}{10001}\\end{pmatrix}.$$\n于是\n$$H_{k+1} = \\begin{pmatrix}1 & 0 \\\\ 0 & 1\\end{pmatrix} + \\begin{pmatrix}100 & 0 \\\\ 0 & 0\\end{pmatrix} - \\begin{pmatrix}\\frac{1}{10001} & \\frac{100}{10001} \\\\ \\frac{100}{10001} & \\frac{10000}{10001}\\end{pmatrix}\n= \\begin{pmatrix}101 - \\frac{1}{10001} & -\\frac{100}{10001} \\\\ -\\frac{100}{10001} & 1 - \\frac{10000}{10001}\\end{pmatrix}.$$\n等价地，\n$$H_{k+1} = \\frac{1}{10001}\\begin{pmatrix}1010100 & -100 \\\\ -100 & 1\\end{pmatrix}.$$\n由于条件数在正标量缩放变换下是不变的，我们可以计算下面矩阵的条件数\n$$M := \\begin{pmatrix}1010100 & -100 \\\\ -100 & 1\\end{pmatrix},$$\n且 $\\kappa(H_{k+1}) = \\kappa(M)$。\n\n对于一个 $2 \\times 2$ 对称矩阵 $M = \\begin{pmatrix}A & B \\\\ B & D\\end{pmatrix}$，其特征值为\n$$\\mu_{\\pm} = \\frac{\\operatorname{tr} M \\pm \\sqrt{(\\operatorname{tr} M)^{2} - 4 \\det M}}{2},$$\n所以条件数为\n$$\\kappa(M) = \\frac{\\mu_{+}}{\\mu_{-}} = \\frac{\\operatorname{tr} M + \\sqrt{(\\operatorname{tr} M)^{2} - 4 \\det M}}{\\operatorname{tr} M - \\sqrt{(\\operatorname{tr} M)^{2} - 4 \\det M}}.$$\n这里\n$$\\operatorname{tr} M = 1010100 + 1 = 1010101,\\qquad \\det M = 1010100 \\cdot 1 - (-100)^{2} = 1010100 - 10000 = 1000100.$$\n于是\n$$\\kappa(M) = \\frac{1010101 + \\sqrt{1010101^{2} - 4 \\cdot 1000100}}{1010101 - \\sqrt{1010101^{2} - 4 \\cdot 1000100}}.$$\n为了高精度地进行数值计算，可以写作\n$$\\sqrt{1010101^{2} - 4 \\cdot 1000100} = 1010101 \\sqrt{1 - \\frac{4 \\cdot 1000100}{1010101^{2}}}.$$\n令 $x = \\frac{4 \\cdot 1000100}{1010101^{2}} = \\frac{400}{10001 \\cdot 101^{2}}$。使用二项式展开 $\\sqrt{1 - x} = 1 - \\frac{x}{2} - \\frac{x^{2}}{8} + O(x^{3})$，其中 $x$ 的量级为 $10^{-6}$，\n$$\\sqrt{1010101^{2} - 4 \\cdot 1000100} = 1010101 \\left(1 - \\frac{x}{2} - \\frac{x^{2}}{8} + O(x^{3})\\right).$$\n因此，微小的差值\n$$\\Delta := 1010101 - \\sqrt{1010101^{2} - 4 \\cdot 1000100} = 1010101 \\left(\\frac{x}{2} + \\frac{x^{2}}{8} + O(x^{3})\\right)\n= \\frac{200}{101} + \\frac{20000}{10001 \\cdot 101^{3}} + O(10^{-11}),$$\n其数值计算结果为\n$$\\Delta \\approx 1.98019996.$$\n那么\n$$\\kappa(M) = \\frac{2 \\cdot 1010101 - \\Delta}{\\Delta} = \\frac{2020202 - \\Delta}{\\Delta} \\approx \\frac{2020202 - 1.98019996}{1.98019996} \\approx 1.02020001 \\times 10^{6}.$$\n四舍五入到三位有效数字，得到\n$$\\kappa(H_{k+1}) = \\kappa(M) \\approx 1.02 \\times 10^{6}.$$\n因为 $s_k^{T} y_k = 0.01 > 0$，DFP更新保持了正定性，因此条件数是良定义的。", "answer": "$$\\boxed{1.02 \\times 10^{6}}$$", "id": "2212484"}]}