{"hands_on_practices": [{"introduction": "任何优化过程的第一步都是量化模型与数据之间的“误差”。本练习通过一个将数据点拟合到圆的具体例子，指导您计算初始猜测下的残差向量。这项实践对于建立 Levenberg-Marquardt 算法旨在最小化的目标函数至关重要，是理解非线性最小二乘法的基础。[@problem_id:2217008]", "problem": "优化中的一个常见任务是将一个几何模型拟合到一组数据点上。考虑在二维平面上将一个圆拟合到一组点的问题。该圆由参数向量 $\\mathbf{p} = [x_c, y_c, R]^T$ 定义，其中 $(x_c, y_c)$ 是圆心，$R$ 是其半径。\n\n对于一组 $n$ 个数据点 $(x_i, y_i)$，非线性最小二乘拟合的目标是找到参数向量 $\\mathbf{p}$，以最小化残差平方和。第 $i$ 个数据点的残差 $r_i(\\mathbf{p})$ 定义为该点到所设圆心 $(x_c, y_c)$ 的距离与所设半径 $R$ 之间的差值。\n\n给定三个在笛卡尔坐标系中表示测量值的数据点，所有坐标单位均为米：\n$P_1 = (1.0, 7.0)$\n$P_2 = (6.0, 2.0)$\n$P_3 = (9.0, 8.0)$\n\n一个迭代优化算法，例如 Levenberg-Marquardt 算法，从参数的初始估计开始。圆的参数初始估计为 $\\mathbf{p}_0 = [x_{c,0}, y_{c,0}, R_0]^T = [5.0, 5.0, 4.0]^T$。\n\n计算此初始估计的残差向量 $\\mathbf{r}(\\mathbf{p}_0) = [r_1(\\mathbf{p}_0), r_2(\\mathbf{p}_0), r_3(\\mathbf{p}_0)]^T$。将所得向量的每个分量以米为单位表示，并四舍五入到四位有效数字。将您的最终答案以单个行矩阵的形式呈现。", "solution": "对于参数为 $\\mathbf{p} = [x_{c}, y_{c}, R]^{T}$ 的圆和一个数据点 $(x_{i}, y_{i})$，残差定义为该点到圆心的欧几里得距离与半径之间的差值：\n$$\nr_{i}(\\mathbf{p}) = \\sqrt{(x_{i} - x_{c})^{2} + (y_{i} - y_{c})^{2}} - R.\n$$\n使用初始估计 $\\mathbf{p}_{0} = [5.0, 5.0, 4.0]^{T}$，计算每个残差。\n\n对于 $P_{1} = (1.0, 7.0)$：\n$$\nd_{1} = \\sqrt{(1.0 - 5.0)^{2} + (7.0 - 5.0)^{2}} = \\sqrt{(-4.0)^{2} + (2.0)^{2}} = \\sqrt{16 + 4} = \\sqrt{20},\n$$\n$$\nr_{1}(\\mathbf{p}_{0}) = \\sqrt{20} - 4.0 \\approx 0.4721 \\text{ (保留四位有效数字)}.\n$$\n\n对于 $P_{2} = (6.0, 2.0)$：\n$$\nd_{2} = \\sqrt{(6.0 - 5.0)^{2} + (2.0 - 5.0)^{2}} = \\sqrt{(1.0)^{2} + (-3.0)^{2}} = \\sqrt{1 + 9} = \\sqrt{10},\n$$\n$$\nr_{2}(\\mathbf{p}_{0}) = \\sqrt{10} - 4.0 \\approx -0.8377 \\text{ (保留四位有效数字)}.\n$$\n\n对于 $P_{3} = (9.0, 8.0)$：\n$$\nd_{3} = \\sqrt{(9.0 - 5.0)^{2} + (8.0 - 5.0)^{2}} = \\sqrt{(4.0)^{2} + (3.0)^{2}} = \\sqrt{16 + 9} = \\sqrt{25} = 5.0,\n$$\n$$\nr_{3}(\\mathbf{p}_{0}) = 5.0 - 4.0 = 1.000 \\text{ (保留四位有效数字)}.\n$$\n\n因此，残差向量（作为行矩阵）为：\n$$\n\\begin{pmatrix}\n0.4721 & -0.8377 & 1.000\n\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix} 0.4721 & -0.8377 & 1.000 \\end{pmatrix}}$$", "id": "2217008"}, {"introduction": "Levenberg-Marquardt 算法利用模型的线性近似来寻找更新步骤，而雅可比矩阵正是此近似的基石，它包含了模型所有的一阶偏导数。本练习将引导您为一个常见的非线性模型计算雅可比矩阵。掌握这项技能对于实现或理解任何基于梯度的优化方法都至关重要。[@problem_id:2217052]", "problem": "在非线性优化领域，像 Levenberg-Marquardt 算法这样的算法通过最小化残差平方和，用于将模型函数拟合到一组数据点。此过程中的一个关键组成部分是模型函数的雅可比矩阵。\n\n考虑一个用于描述物质浓度随时间变化的模型，由以下双参数有理函数给出：\n$$f(t; a, b) = \\frac{a}{1 + bt}$$\n其中 $t$ 是自变量（例如，时间），而 $\\mathbf{p} = [a, b]^T$ 是待确定的参数向量。\n\n假设我们收集了以下三个数据点 $(t_i, y_i)$：\n- $(t_1, y_1) = (1.0, 2.5)$\n- $(t_2, y_2) = (2.0, 1.8)$\n- $(t_3, y_3) = (4.0, 1.1)$\n\n此拟合问题的雅可比矩阵 $\\mathbf{J}$ 是一个 $m \\times n$ 矩阵，其中 $m$ 是数据点的数量，$n$ 是参数的数量。其元素定义为 $J_{ij} = \\frac{\\partial f(t_i; \\mathbf{p})}{\\partial p_j}$。\n\n计算在初始参数猜测值 $\\mathbf{p}_0 = [a_0, b_0]^T = [3.0, 0.5]^T$ 处评估的雅可比矩阵 $\\mathbf{J}$ 的数值。所有给定的数值都是无量纲的。\n\n将你的最终答案表示为一个 $3 \\times 2$ 矩阵，每个元素四舍五入到三位有效数字。", "solution": "我们给定的模型函数为 $f(t; a, b) = \\dfrac{a}{1 + bt}$，参数向量为 $\\mathbf{p} = [a, b]^{T}$，雅可比矩阵定义为 $J_{ij} = \\dfrac{\\partial f(t_{i}; \\mathbf{p})}{\\partial p_{j}}$。因此，$\\mathbf{J}$ 的每一行对应一个数据点 $t_{i}$，两列分别对应关于 $a$ 和 $b$ 的导数。\n\n首先，计算偏导数的表达式。将 $f(t; a, b)$ 写为 $a(1 + bt)^{-1}$。然后，使用幂法则和链式法则：\n$$\n\\frac{\\partial f}{\\partial a} = (1 + bt)^{-1} = \\frac{1}{1 + bt},\n$$\n$$\n\\frac{\\partial f}{\\partial b} = a \\cdot \\frac{\\partial}{\\partial b}(1 + bt)^{-1} = a \\cdot \\left[-(1 + bt)^{-2} \\cdot t\\right] = -\\frac{a t}{(1 + bt)^{2}}.\n$$\n\n因此，对于每个数据点 $t_{i}$，雅可比矩阵的对应行为\n$$\n\\left[\\frac{1}{1 + b t_{i}},\\ -\\frac{a t_{i}}{(1 + b t_{i})^{2}}\\right].\n$$\n\n在初始猜测值 $\\mathbf{p}_{0} = [a_{0}, b_{0}]^{T} = [3.0, 0.5]^{T}$ 和给定的 $t$ 值处进行求值。\n\n对于 $t_{1} = 1$:\n$$\n1 + b_{0} t_{1} = 1 + 0.5 \\cdot 1 = \\frac{3}{2},\\quad \\frac{\\partial f}{\\partial a} = \\frac{2}{3},\\quad \\frac{\\partial f}{\\partial b} = -\\frac{3 \\cdot 1}{(3/2)^{2}} = -\\frac{12}{9} = -\\frac{4}{3}.\n$$\n\n对于 $t_{2} = 2$:\n$$\n1 + b_{0} t_{2} = 1 + 0.5 \\cdot 2 = 2,\\quad \\frac{\\partial f}{\\partial a} = \\frac{1}{2},\\quad \\frac{\\partial f}{\\partial b} = -\\frac{3 \\cdot 2}{2^{2}} = -\\frac{6}{4} = -\\frac{3}{2}.\n$$\n\n对于 $t_{3} = 4$:\n$$\n1 + b_{0} t_{3} = 1 + 0.5 \\cdot 4 = 3,\\quad \\frac{\\partial f}{\\partial a} = \\frac{1}{3},\\quad \\frac{\\partial f}{\\partial b} = -\\frac{3 \\cdot 4}{3^{2}} = -\\frac{12}{9} = -\\frac{4}{3}.\n$$\n\n组合成雅可比矩阵，并将每个元素四舍五入到三位有效数字：\n$$\n\\mathbf{J}(\\mathbf{p}_{0}) \\approx\n\\begin{pmatrix}\n0.667 & -1.33 \\\\\n0.500 & -1.50 \\\\\n0.333 & -1.33\n\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}0.667 & -1.33 \\\\ 0.500 & -1.50 \\\\ 0.333 & -1.33\\end{pmatrix}}$$", "id": "2217052"}, {"introduction": "在练习了构建模块（残差和雅可比矩阵）之后，本练习将深入探讨 Levenberg-Marquardt 算法的核心——更新步骤本身。通过研究线性最小二乘问题这一特殊情况，我们可以深刻理解阻尼参数 $\\lambda$ 如何影响解。这项实践揭示了 LM 步骤与通往精确解的直接路径之间的数学关系，阐明了该算法如何在速度与稳定性之间取得平衡。[@problem_id:2216994]", "problem": "考虑一个最小化平方和函数的一般性问题，$S(x) = \\frac{1}{2} \\sum_{i=1}^{m} [r_i(x)]^2 = \\frac{1}{2}\\|r(x)\\|_2^2$，其中 $x \\in \\mathbb{R}^n$ 是一个参数向量，$r(x) \\in \\mathbb{R}^m$ 是一个残差函数向量。\n\nLevenberg-Marquardt (LM) 算法是求解此类问题的一种迭代方法。从一个初始猜测值 $x_k$ 开始，下一个迭代点 $x_{k+1}$ 通过 $x_{k+1} = x_k + p_k$ 求得，其中更新步长 $p_k$ 是以下线性系统的解：\n$$(J_k^T J_k + \\lambda I) p_k = -J_k^T r_k$$\n此处，$J_k$ 是残差向量 $r(x)$ 在 $x_k$ 处的雅可比矩阵，$r_k = r(x_k)$，$I$ 是单位矩阵，$\\lambda > 0$ 是一个阻尼参数。\n\n现在，我们来分析一个特殊情况，即优化问题是一个线性最小二乘问题。残差向量由 $r(x) = Ax - b$ 给出，其中 $A$ 是一个满列秩（$n \\le m$）的实 $m \\times n$ 矩阵，$b$ 是 $\\mathbb{R}^m$ 中的一个向量。该问题有一个唯一的极小值点，我们将其记为 $x^*$。\n\n设 $x_0$ 为算法的任意起始点。在单次迭代中达到解所需的精确步长为 $p_{exact} = x^* - x_0$。设 $p_{LM}$ 为从 $x_0$ 开始、使用给定阻尼参数 $\\lambda$ 的 LM 算法计算出的第一步更新步长。\n\n你的任务是推导 LM 步长与精确步长之间的关系。请将向量 $p_{LM}$ 用矩阵 $A$、阻尼参数 $\\lambda$ 以及向量 $p_{exact}$ 表示。", "solution": "我们考虑残差为 $r(x) = Ax - b$ 的线性最小二乘问题，其中 $A \\in \\mathbb{R}^{m \\times n}$ 具有满列秩，因此 $A^{T}A$ 是对称正定且可逆的。唯一极小值点 $x^{*}$ 满足正规方程组：\n$$\nA^{T}(Ax^{*} - b) = 0 \\quad \\Longleftrightarrow \\quad A^{T}A\\,x^{*} = A^{T}b.\n$$\n从 $x_0$ 开始，Levenberg-Marquardt 步长 $p_{LM}$ 求解\n$$\n(A^{T}A + \\lambda I)\\,p_{LM} = -A^{T}r_{0} = -A^{T}(Ax_{0} - b) = -A^{T}A\\,x_{0} + A^{T}b.\n$$\n使用正规方程组 $A^{T}b = A^{T}A\\,x^{*}$，等式右侧变为\n$$\n-A^{T}A\\,x_{0} + A^{T}b = A^{T}A\\,x^{*} - A^{T}A\\,x_{0} = A^{T}A\\,(x^{*} - x_{0}) = A^{T}A\\,p_{exact}.\n$$\n因此，LM 步长满足\n$$\n(A^{T}A + \\lambda I)\\,p_{LM} = A^{T}A\\,p_{exact},\n$$\n并且，由于当 $\\lambda > 0$ 时 $A^{T}A + \\lambda I$ 是可逆的，我们得到\n$$\np_{LM} = (A^{T}A + \\lambda I)^{-1}A^{T}A\\,p_{exact}.\n$$\n这就将 $p_{LM}$ 用 $A$、$\\lambda$ 和 $p_{exact}$ 表示了出来，符合题目要求。", "answer": "$$\\boxed{p_{LM} = (A^{T}A+\\lambda I)^{-1}A^{T}A\\,p_{exact}}$$", "id": "2216994"}]}