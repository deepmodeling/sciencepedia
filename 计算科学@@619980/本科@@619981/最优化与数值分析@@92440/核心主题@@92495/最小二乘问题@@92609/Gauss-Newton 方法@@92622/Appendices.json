{"hands_on_practices": [{"introduction": "高斯-牛顿法等最小二乘方法的核心目标是最小化模型预测与实际观测数据之间的误差。这个误差由所谓的“残差”向量 $r(\\beta)$ 来量化。在着手优化参数之前，我们必须首先掌握如何根据给定的模型、数据和一组参数来计算这些残差。本练习将带你完成这个基础但至关重要的第一步，为后续的迭代优化奠定坚实的基础。[@problem_id:2214281]", "problem": "在非线性最小二乘拟合的背景下，一个常见的任务是最小化残差平方和。考虑一个描述某种物理现象的模型，由函数 $f(x, \\beta) = \\beta_1 \\sqrt{x} + \\beta_2$ 给出，其中 $\\beta = (\\beta_1, \\beta_2)^T$ 是待确定的参数向量。\n\n一次实验产生了两个数据点 $(x_i, y_i)$：第一个点是 $(4, 5)$，第二个点是 $(9, 7)$。\n\n第 $i$ 个数据点的残差定义为 $r_i(\\beta) = y_i - f(x_i, \\beta)$。残差向量 $r(\\beta)$ 是一个列向量，其分量是各个残差 $r_i(\\beta)$。\n\n给定参数的初始估计 $\\beta^{(0)} = (1, 3)^T$，计算相应的残差向量 $r(\\beta^{(0)})$。请将您的最终答案表示为一个包含两个元素的行矩阵，这两个元素对应于残差向量的分量。", "solution": "我们已知模型 $f(x,\\beta)=\\beta_{1}\\sqrt{x}+\\beta_{2}$，残差 $r_{i}(\\beta)=y_{i}-f(x_{i},\\beta)$，数据点 $(x_{1},y_{1})=(4,5)$ 和 $(x_{2},y_{2})=(9,7)$，以及初始估计 $\\beta^{(0)}=(\\beta_{1}^{(0)},\\beta_{2}^{(0)})^{T}=(1,3)^{T}$。\n\n使用 $\\beta^{(0)}$ 计算在给定 $x_{i}$ 处的模型预测值：\n$$\nf(x_{1},\\beta^{(0)})=\\beta_{1}^{(0)}\\sqrt{x_{1}}+\\beta_{2}^{(0)}=1\\cdot\\sqrt{4}+3=2+3=5,\n$$\n$$\nf(x_{2},\\beta^{(0)})=\\beta_{1}^{(0)}\\sqrt{x_{2}}+\\beta_{2}^{(0)}=1\\cdot\\sqrt{9}+3=3+3=6.\n$$\n\n计算残差：\n$$\nr_{1}(\\beta^{(0)})=y_{1}-f(x_{1},\\beta^{(0)})=5-5=0,\n$$\n$$\nr_{2}(\\beta^{(0)})=y_{2}-f(x_{2},\\beta^{(0)})=7-6=1.\n$$\n\n因此，残差向量的分量为 $0$ 和 $1$。表示为一个包含两个元素的行矩阵，即 $\\begin{pmatrix}0  1\\end{pmatrix}$。", "answer": "$$\\boxed{\\begin{pmatrix}0  1\\end{pmatrix}}$$", "id": "2214281"}, {"introduction": "理解了残差的概念后，我们就可以运用高斯-牛顿法来迭代地改进我们的参数估计，以期最小化这些残差的平方和。这个过程通过构建一个线性子问题来确定参数的更新方向和步长。本练习将引导你完整地执行一次高斯-牛顿迭代，包括计算雅可比矩阵、构建并求解正规方程，从而让你亲身体验该算法的核心运作机制。[@problem_id:2214282]", "problem": "在一项实验研究中，某个物理过程由函数 $y(x;a) = \\frac{x}{1+ax}$ 建模，其中 $a$ 是一个待确定的未知参数。一名研究人员收集了两个数据点 $(x_i, y_i)$：第一个点是 $(1, 0.5)$，第二个点是 $(2, 0.8)$。\n\n为了找到在最小二乘意义上最能拟合数据的参数 $a$ 的最优值，该研究人员决定使用高斯-牛顿方法。从初始猜测 $a_0 = 1$ 开始，执行恰好一次高斯-牛顿方法的迭代，以求得参数的更新估计值，记为 $a_1$。\n\n将 $a_1$ 的答案表示为最简精确分数。", "solution": "我们用模型 $y(x;a)=\\dfrac{x}{1+a x}$ 对数据进行建模。根据文章约定，残差为 $r_i(a) = y_i - y(x_i;a)$。单个参数 $a$ 的高斯-牛顿更新步长 $\\Delta a$ 可通过求解法向方程 $(J^{\\top}J)\\Delta a = -J^{\\top}r$ 得到。其中 $J$ 是雅可比矩阵，$r$ 是残差向量，均在当前猜测值 $a_0$ 处计算。更新后的估计值为 $a_1=a_0+\\Delta a$。\n\n首先，计算雅可比矩阵的元素 $J_i = \\dfrac{\\partial r_i}{\\partial a} = -\\dfrac{\\partial y(x_i;a)}{\\partial a}$。模型对 $a$ 的导数为：\n$$\n\\frac{\\partial y}{\\partial a} = -x^2(1+ax)^{-2}.\n$$\n\n对于数据点 $(x_1, y_1)=(1, \\tfrac{1}{2})$ 和 $(x_2, y_2)=(2, \\tfrac{4}{5})$，以及初始猜测 $a_0=1$，雅可比项为：\n$$\nJ_1 = - \\left( - \\frac{1^2}{(1+1\\cdot 1)^2} \\right) = \\frac{1}{4},\\quad J_2 = - \\left( - \\frac{2^2}{(1+1\\cdot 2)^2} \\right) = \\frac{4}{9}.\n$$\n\n在 $a_0=1$ 处的残差为：\n$$\nr_1=y(1;1)-\\frac{1}{2}=\\frac{1}{2}-\\frac{1}{2}=0,\\quad r_2 = \\frac{4}{5} - y(2;1) = \\frac{4}{5} - \\frac{2}{3} = \\frac{2}{15}.\n$$\n\n计算标量 $J^{\\top}r$ 和 $J^{\\top}J$：\n$$\nJ^{\\top}r=J_1r_1+J_2r_2 = \\left(\\frac{1}{4}\\right)(0) + \\left(\\frac{4}{9}\\right)\\left(\\frac{2}{15}\\right) = \\frac{8}{135},\n$$\n$$\nJ^{\\top}J=J_1^2+J_2^2=\\left(\\frac{1}{4}\\right)^2 + \\left(\\frac{4}{9}\\right)^2=\\frac{1}{16}+\\frac{16}{81}=\\frac{81+256}{1296}=\\frac{337}{1296}.\n$$\n\n因此，\n$$\n\\Delta a=-\\frac{J^{\\top}r}{J^{\\top}J}=-\\frac{\\frac{8}{135}}{\\frac{337}{1296}}=-\\frac{8}{135}\\cdot\\frac{1296}{337}=-\\frac{384}{1685}.\n$$\n\n因此，更新后的估计值为\n$$\na_1=a_0+\\Delta a=1-\\frac{384}{1685}=\\frac{1685-384}{1685}=\\frac{1301}{1685}.\n$$", "answer": "$$\\boxed{\\frac{1301}{1685}}$$", "id": "2214282"}, {"introduction": "虽然高斯-牛顿法非常强大，但它并非万无一失，其收敛性严重依赖于初始猜测的位置以及问题的非线性程度。本练习是一个精心设计的思想实验，旨在揭示该算法的一个典型失效模式：在某些情况下，算法的迭代过程可能不会收敛到最优解，反而陷入来回振荡的“稳定循环”中。通过分析这种现象，你将更深刻地理解高斯-牛顿法的局限性，并认识到在实际应用中引入阻尼策略（如Levenberg-Marquardt方法）的重要性。[@problem_id:2214263]", "problem": "一位工程师正在使用高斯-牛顿算法解决一个简单的非线性最小二乘问题。目标是使用模型 $g(t; x) = A \\arctan(x t)$ 拟合单个数据点 $(t_1, y_1) = (1, 0)$。待定参数为 $x$，常数 $A$ 固定为 $A=1$。目标是找到使残差平方和 $F(x) = \\frac{1}{2} [g(t_1; x) - y_1]^2$ 最小化的 $x$ 值。该问题的真正最小值显然在 $x = 0$ 处。\n\n然而，当工程师从一个特定的初始猜测值 $x_0  0$ 开始应用高斯-牛顿法时，他们观察到算法未能收敛到最小值。相反，迭代陷入了一个稳定的2-循环，在初始猜测值 $x_0$ 和其相反数 $-x_0$ 之间永久振荡。\n\n确定导致高斯-牛顿法立即进入此2-循环的特定初始猜测值 $x_0$。将您的答案表示为一个四舍五入到四位有效数字的数值。", "solution": "模型为 $g(t; x) = \\arctan(x t)$（其中 $A=1$），单个数据点为 $(t_{1}, y_{1}) = (1, 0)$。因此残差为\n$$\nr(x) = g(1; x) - y_{1} = \\arctan(x).\n$$\n最小化 $F(x) = \\frac{1}{2} r(x)^{2}$ 的标量高斯-牛顿步长通过求解线性化最小二乘问题 $r(x) + J(x) p \\approx 0$ 得到，其中 $J(x) = \\frac{dr}{dx}$。因此\n$$\np = -\\frac{r(x)}{J(x)}, \\quad x_{+} = x + p = x - \\frac{r(x)}{J(x)}.\n$$\n此处 $J(x) = \\frac{d}{dx}\\arctan(x) = \\frac{1}{1 + x^{2}}$，所以高斯-牛顿迭代映射为\n$$\nT(x) = x - \\frac{\\arctan(x)}{\\frac{1}{1 + x^{2}}} = x - (1 + x^{2}) \\arctan(x).\n$$\n当 $T(x_{0}) = -x_{0}$ 时，立即出现一个2-循环 $\\{x_{0}, -x_{0}\\}$，这给出\n$$\n-x_{0} = x_{0} - (1 + x_{0}^{2}) \\arctan(x_{0}) \\;\\;\\Longrightarrow\\;\\; (1 + x_{0}^{2}) \\arctan(x_{0}) = 2 x_{0}.\n$$\n令 $x_{0} = \\tan(\\theta)$，其中 $\\theta \\in (0, \\frac{\\pi}{2})$。使用 $1 + \\tan^{2}(\\theta) = \\sec^{2}(\\theta)$ 和 $\\arctan(\\tan(\\theta)) = \\theta$，该方程变为\n$$\n\\sec^{2}(\\theta)\\,\\theta = 2 \\tan(\\theta) \\;\\;\\Longrightarrow\\;\\; \\theta = 2 \\sin(\\theta)\\cos(\\theta) = \\sin(2\\theta).\n$$\n除了平凡解 $\\theta = 0$（对应于 $x=0$），在 $(0, \\frac{\\pi}{2})$ 区间内的唯一非零解满足 $\\theta = \\sin(2\\theta)$。数值求解得出\n$$\n\\theta \\approx 0.947745,\n$$\n所以\n$$\nx_{0} = \\tan(\\theta) \\approx 1.391740\\ldots\n$$\n四舍五入到四位有效数字，得到所需的初始猜测值。", "answer": "$$\\boxed{1.392}$$", "id": "2214263"}]}