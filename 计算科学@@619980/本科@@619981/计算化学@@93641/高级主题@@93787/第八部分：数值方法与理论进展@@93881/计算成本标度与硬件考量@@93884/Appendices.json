{"hands_on_practices": [{"introduction": "在开始任何大规模计算化学模拟之前，一个最基本的问题是：我的计算任务能否在可用的硬件内存中运行？这个练习将理论与实践联系起来，通过一个具体的例子，让你亲手计算在给定的内存限制下，传统 Hartree-Fock 计算所能处理的最大系统规模。这个估算过程对于规划计算资源和判断一个方法对于特定问题是否可行至关重要。[@problem_id:2452800]", "problem": "在一组空间基函数上的哈特里-福克（Hartree–Fock）计算中，四指标电子排斥积分张量可以表示为一个稠密的四阶数组，其条目由 $(\\mu,\\nu,\\lambda,\\sigma)$ 索引，每个索引的取值范围为 $1$ 到 $N$。假设没有利用对称性约化或稀疏性，因此存储的实数总数为 $N^{4}$。假设您有一个计算节点，其上分配了恰好 $128$ 吉比字节（gibibytes）的内存，专门用于在内存中存储此张量，并且每个张量元素都存储为 $64$ 位浮点数。使用以下单位转换定义：$1\\ \\mathrm{byte} = 8\\ \\mathrm{bits}$ 以及 $1\\ \\mathrm{GiB} = 2^{30}\\ \\mathrm{bytes}$。忽略任何额外的内存开销。能够使完整的 $N \\times N \\times N \\times N$ 张量完全容纳于内存中的最大整数 $N$ 是多少？请提供 $N$ 的精确整数值。", "solution": "对所述问题进行验证。\n\n步骤 1：提取已知条件。\n- 研究对象是四指标电子排斥积分张量。\n- 该张量表示为稠密的四阶数组，索引为 $(\\mu, \\nu, \\lambda, \\sigma)$。\n- 每个索引的取值范围为 $1$ 到 $N$，其中 $N$ 是空间基函数的数量。\n- 未利用对称性或稀疏性。\n- 张量中的元素总数为 $N^4$。\n- 每个元素存储为 $64$ 位浮点数。\n- 计算节点上的可用内存恰好为 $128$ 吉比字节 (GiB)。\n- 指定了单位转换：$1\\ \\mathrm{byte} = 8\\ \\mathrm{bits}$ 和 $1\\ \\mathrm{GiB} = 2^{30}\\ \\mathrm{bytes}$。\n- 来自操作系统或其他来源的内存开销将被忽略。\n- 目标是找到能使张量完全存储在指定内存中的最大整数 $N$。\n\n步骤 2：使用提取的已知条件进行验证。\n- **科学依据充分**：该问题是计算化学中关于硬件限制的一个完全标准和基础的练习。在基组表示中，双电子排斥积分张量的 $N^4$ 标度律是理解哈特里-福克（Hartree-Fock）理论计算成本的基石。数据类型和内存大小是符合实际的。该问题有效。\n- **问题定义明确**：该问题提供了得出唯一整数解 $N$ 所需的所有数值和定义。它没有歧义且是自洽的。该问题有效。\n- **客观性**：该问题以精确、定量的术语陈述。没有主观或基于意见的成分。该问题有效。\n\n步骤 3：结论与行动。\n问题有效。将构建解答。\n\n基本原理是，存储张量所需的总内存必须小于或等于可用内存。我们将把这个条件形式化，并求解 $N$ 的最大整数值。\n\n首先，我们确定存储张量单个元素所需的内存。问题指出，每个元素是一个 $64$ 位浮点数。使用提供的转换，我们得到以字节为单位的大小：\n$$\n\\text{Size per element} = 64\\ \\mathrm{bits} \\times \\frac{1\\ \\mathrm{byte}}{8\\ \\mathrm{bits}} = 8\\ \\mathrm{bytes}\n$$\n\n接下来，我们表示存储整个稠密张量所需的总内存。该张量是秩为 $4$ 的张量，每个维度的大小为 $N$。因此，元素总数为 $N^4$。我们记总内存需求为 $M_{\\text{req}}$，它是元素数量与每个元素大小的乘积：\n$$\nM_{\\text{req}} = N^4 \\times (8\\ \\mathrm{bytes})\n$$\n\n现在，我们以字节为单位计算总可用内存 $M_{\\text{avail}}$。可用内存为 $128$ GiB。使用指定的转换 $1\\ \\mathrm{GiB} = 2^{30}\\ \\mathrm{bytes}$，我们有：\n$$\nM_{\\text{avail}} = 128\\ \\mathrm{GiB} \\times \\frac{2^{30}\\ \\mathrm{bytes}}{1\\ \\mathrm{GiB}} = 128 \\times 2^{30}\\ \\mathrm{bytes}\n$$\n将系数 $128$ 表示为 $2$ 的幂会很有利：$128 = 2^7$。因此，\n$$\nM_{\\text{avail}} = 2^7 \\times 2^{30}\\ \\mathrm{bytes} = 2^{37}\\ \\mathrm{bytes}\n$$\n\n张量能够容纳于内存中的条件是 $M_{\\text{req}} \\le M_{\\text{avail}}$。我们代入这些量的表达式：\n$$\n8 \\times N^4 \\le 2^{37}\n$$\n我们将系数 $8$ 表示为 $2$ 的幂：$8 = 2^3$。\n$$\n2^3 \\times N^4 \\le 2^{37}\n$$\n为了求解 $N$，我们首先通过将两边除以 $2^3$ 来分离 $N^4$ 项：\n$$\nN^4 \\le \\frac{2^{37}}{2^3} = 2^{37-3} = 2^{34}\n$$\n现在，我们对不等式两边取四次方根。由于 $N$ 必须是正整数，此操作很简单：\n$$\nN \\le (2^{34})^{\\frac{1}{4}} = 2^{\\frac{34}{4}} = 2^{8.5}\n$$\n为了求出数值，我们可以将 $2^{8.5}$ 写成 $2^8 \\times 2^{0.5}$：\n$$\nN \\le 2^8 \\times \\sqrt{2}\n$$\n我们知道 $2^8 = 256$。$\\sqrt{2}$ 的值约为 $1.41421356...$。\n$$\nN \\le 256 \\times 1.41421356... \\approx 362.03867...\n$$\n问题要求满足此条件的最大整数 $N$。满足 $N \\le 362.03867...$ 的整数集合是 $\\{..., 360, 361, 362\\}$。此集合中的最大整数是 $362$。\n\n因此，能使完整的电子排斥积分（ERI）张量存储在给定内存中的最大基函数数目 $N$ 是 $362$。", "answer": "$$\n\\boxed{362}\n$$", "id": "2452800"}, {"introduction": "算法的计算标度（例如 $O(N^3)$）不仅仅是一个抽象的数学符号，它直接决定了计算时间如何随系统规模 $N$ 增长。这个实践旨在量化这种影响，通过对比一个理论上正确的算法和一个存在微小缺陷的算法，你将看到标度指数的微小差异如何导致计算成本的巨大变化。这个练习能加深你对算法复杂度重要性的理解。[@problem_id:2452785]", "problem": "在一个固定的硬件平台上，一个用于大小为 $N$（例如，基函数数量）的体系的密度泛函理论（DFT）代码的实际运行时间 $T(N)$，在 $N$ 足够大时，被观察到与 $N$ 的某个幂成正比。假设正确实现的标度行为为 $T_{\\text{corr}}(N) \\propto N^{3}$，但一个错误导致代码的标度行为变为 $T_{\\text{bug}}(N) \\propto N^{3.5}$。假设两个版本共享相同的比例前因子（即，它们仅在 $N$ 的指数上有所不同），在相同的硬件上运行，并且任何低阶项都可以忽略不计。\n\n对于同一体系，当 $N$ 取何值时，该错误导致的运行时间相比正确实现增加了 $100\\%$，即 $T_{\\text{bug}}(N)$ 恰好是 $T_{\\text{corr}}(N)$ 的两倍？请以纯数字形式提供 $N$，不带单位。无需进行四舍五入。", "solution": "在尝试求解之前，必须首先对问题陈述进行严格的验证。\n\n步骤 1：提取已知条件。\n提供的如下信息：\n- 一个密度泛函理论（DFT）代码的正确实现的实际运行时间为 $T_{\\text{corr}}(N)$。\n- 正确实现的标度行为为 $T_{\\text{corr}}(N) \\propto N^{3}$。\n- 同一代码的错误实现的实际运行时间为 $T_{\\text{bug}}(N)$。\n- 错误实现的标度行为为 $T_{\\text{bug}}(N) \\propto N^{3.5}$。\n- 比例前因子（我们将其表示为 $c$）对于两个实现是相同的。\n- 标度表达式中的低阶项被认为可以忽略不计。\n- 待求解的条件是，在某个体系大小 $N$ 下，错误实现的运行时间相对于正确实现的运行时间增加了 $100\\%$。这等价于条件 $T_{\\text{bug}}(N) = 2 T_{\\text{corr}}(N)$。\n\n步骤 2：使用提取的已知条件进行验证。\n根据所需标准对问题进行评估：\n- **科学上合理：** 其前提是合理的。标准的DFT计算通常表现出计算成本随体系大小的立方（$O(N^{3})$）而扩展的特性，这通常由矩阵对角化或交换相关势的构建所主导。一个算法上的低效或错误，有可能增加有效的标度指数。在此背景下，给出的指数 $3$ 和 $3.5$ 是符合实际的。\n- **适定性：** 这个问题是适定的。它提供了清晰的数学关系和一个待满足的特定条件，由此可以唯一地确定单个未知变量 $N$。\n- **客观性：** 其语言是定量的和精确的，没有任何主观或模糊的术语。\n\n该问题不违反任何指定的无效性标准。它在科学上是合理的、可形式化的、完整的且结构良好。\n\n步骤 3：结论与行动。\n问题被判定为有效。现在开始推导解答。\n\n标度关系明确定义如下：\n$$T_{\\text{corr}}(N) = c N^{3}$$\n$$T_{\\text{bug}}(N) = c N^{3.5}$$\n其中 $c$ 是一个代表共享比例前因子的正常数。可忽略低阶项的假设使我们能够为本次分析的目的，将这些简单的幂律用作精确等式。\n\n给定的条件是错误实现的运行时间相对于正确实现显示出 $100\\%$ 的增加。$100\\%$ 的增加相当于原始值的两倍。因此，数学条件是：\n$$T_{\\text{bug}}(N) = T_{\\text{corr}}(N) + (1.00) \\times T_{\\text{corr}}(N) = 2 T_{\\text{corr}}(N)$$\n\n将标度表达式代入此方程：\n$$c N^{3.5} = 2 (c N^{3})$$\n\n我们寻求 $N$ 的非平凡解，这意味着 $N > 0$。前因子 $c$ 必须为非零才能进行任何计算，因此 $c > 0$。所以我们可以将方程两边同时除以 $c$：\n$$N^{3.5} = 2 N^{3}$$\n\n假设 $N > 0$，我们可以将两边同时除以 $N^{3}$：\n$$\\frac{N^{3.5}}{N^{3}} = 2$$\n\n使用指数的性质 $x^{a}/x^{b} = x^{a-b}$：\n$$N^{3.5 - 3} = 2$$\n$$N^{0.5} = 2$$\n\n指数 $0.5$ 等价于平方根：\n$$N^{1/2} = \\sqrt{N} = 2$$\n\n为了解出 $N$，我们将方程两边平方：\n$$\\left(\\sqrt{N}\\right)^{2} = 2^{2}$$\n$$N = 4$$\n\n因此，对于体系大小 $N=4$，错误实现的运行时间将恰好是正确实现的两倍。此结果与前因子 $c$ 无关，这对于基于标度律的相对比较是符合预期的。", "answer": "$$\\boxed{4}$$", "id": "2452785"}, {"introduction": "在理想世界中，将计算核心数量加倍应该会使计算时间减半。然而，在真实的计算化学实践中，我们常常会遇到“性能负扩展”的现象，即使用更多核心反而导致程序运行变慢。这个练习挑战你跳出简单的标度定律，从现代计算机硬件架构的复杂性（如内存带宽、缓存争用、NUMA效应等）出发，诊断并行计算中可能出现的性能瓶颈。[@problem_id:2452799]", "problem": "一名学生在同一台工作站上运行了两次完全相同的密度泛函理论 (DFT) 几何结构优化：一次使用 $8$ 个线程，另一次使用 $16$ 个线程。使用 $16$ 个线程的运行比使用 $8$ 个线程的运行完成得更慢。除了线程数之外，没有更改任何输入文件或算法设置。以下哪几种硬件层面的效应可以合理地解释这一结果？选择所有适用项。\n\nA. 内存带宽是一种共享资源；当使用 $16$ 个线程时，内存子系统达到饱和，因此与 $8$ 个线程相比，每个线程的带宽下降，总时间增加。\n\nB. 随着活动核心数量的增加，中央处理器 (CPU) 因功率和散热限制（全核睿频）而降低了每个核心的频率，这使得 $16$ 个线程的运行速度慢于 $8$ 个线程。\n\nC. 非一致性内存访问 (NUMA) 效应：在使用 $16$ 个线程时，操作系统会将工作调度到不同的插槽上，从而导致远程内存访问，与 $8$ 个线程相比，其延迟更高、带宽更低。\n\nD. 使用 $16$ 个线程的运行采用了比 $8$ 个线程的运行更大的分子几何结构，因此自然耗时更长。\n\nE. 在使用 $16$ 个线程时，共享的末级缓存 (LLC) 中的竞争加剧，导致更高的缓存未命中率和更多的主内存流量，从而相对于 $8$ 个线程减慢了执行速度。\n\nF. DFT 使用的数学算法在更多线程上运行时，其渐近复杂性类别更差，因此在 $16$ 个线程时其大O成本增加。\n\nG. 同时多线程 (SMT) 已启用；$16$ 个线程分时共享 $8$ 个物理核心，对于此工作负载，额外的硬件线程几乎不提供好处，甚至因资源竞争而产生负面影响。", "solution": "问题描述的是一个并行计算中典型的负强扩展性案例。其目标是解决一个固定大小的问题，即一个密度泛函理论 (DFT) 几何结构优化问题，而将处理线程数从 $8$ 增加到 $16$ 导致了更长的执行时间。这表明增加更多线程所带来的开销超过了计算上的加速。我们必须验证所提出的针对此现象的硬件层面原因的合理性。\n\n问题陈述是合理的。它描述了在高性能计算中遇到的一个现实场景，其科学基础植根于计算机体系结构和计算化学的原理，并且问题提法得当，要求从给定列表中找出合理的解释。\n\n我们现在来逐一评估每个选项。\n\n**A. 内存带宽是一种共享资源；当使用 $16$ 个线程时，内存子系统达到饱和，因此与 $8$ 个线程相比，每个线程的带宽下降，总时间增加。**\nDFT 计算的许多阶段，例如构建 Fock 矩阵或 Kohn-Sham 矩阵以及用于对角化的数值线性代数例程，都受内存带宽的限制。从 DRAM 到 CPU 的总可用内存带宽是所有核心的有限共享资源。如果 $8$ 线程的执行已经利用了该带宽的很大一部分，那么将活动线程数加倍到 $16$ 个可能会使内存控制器过饱和。当饱和时，线程必须等待更长时间才能从主内存中获取数据，从而导致处理器停顿周期的增加。每个线程的有效内存带宽会降低，如果算法的进展受限于此数据访问速率，那么总的墙钟时间将会增加。这是多核系统中一个非常常见的性能瓶颈。\n结论：**正确**。\n\n**B. 随着活动核心数量的增加，中央处理器 (CPU) 因功率和散热限制（全核睿频）而降低了每个核心的频率，这使得 $16$ 个线程的运行速度慢于 $8$ 个线程。**\n现代 CPU 会根据工作负载、核心利用率、功耗和散热余量动态调整其时钟频率。这通常在市场上被宣传为“Turbo Boost”或“Precision Boost”。一个核心可达到的最高频率与并发活动的核心数量成反比。运行 $16$ 个线程会加载 $16$ 个核心（或逻辑处理器），这比在 $8$ 个核心上运行产生更多的热量和消耗更多的功率。为了保持在指定的热设计功耗 (TDP) 和温度限制之内，CPU 的电源管理单元将降低“全核”睿频频率。$16$ 个活动核心的频率显著低于 $8$ 个活动核心的频率是完全合理的。如果这种频率降低带来的性能损失大于将工作并行化到额外 $8$ 个线程上所获得的性能增益，那么最终结果就是执行时间变慢。\n结论：**正确**。\n\n**C. 非一致性内存访问 (NUMA) 效应：在使用 $16$ 个线程时，操作系统会将工作调度到不同的插槽上，从而导致远程内存访问，与 $8$ 个线程相比，其延迟更高、带宽更低。**\n拥有 $16$ 个或更多核心的工作站通常采用多插槽或多芯粒设计，这导致了非一致性内存访问 (NUMA) 架构。在这样的系统中，一个 CPU 由多个 NUMA 节点组成（例如，2 个节点，每个节点有 8 个核心）。每个节点都有自己的本地内存控制器和连接的 DRAM。访问本地内存速度很快，而访问连接到不同节点上的内存（远程内存）则因为需要通过插槽间的互连通道而产生更高的延迟和更低的带宽。一个 $8$ 线程的作业可能被操作系统调度器限制在单个 NUMA 节点内，从而专门受益于快速的本地内存访问。然而，一个 $16$ 线程的作业必然会跨越两个 NUMA 节点。这将为试图访问由另一个节点上的线程分配的数据的线程引入远程内存访问。对于像 DFT 这样的内存密集型应用，内存访问延迟的增加和互连通道上的竞争很容易导致显著的性能下降，从而造成净减速。\n结论：**正确**。\n\n**D. 使用 $16$ 个线程的运行采用了比 $8$ 个线程的运行更大的分子几何结构，因此自然耗时更长。**\n该陈述直接与问题的前提相矛盾。问题明确指出，学生运行的是“**完全相同的**密度泛函理论 (DFT) 几何结构优化”，并且“**没有更改任何输入文件或算法设置**”。分子几何结构是输入文件的主要组成部分。因此，该选项不符合问题的条件。\n结论：**错误**。\n\n**E. 在使用 $16$ 个线程时，共享的末级缓存 (LLC) 中的竞争加剧，导致更高的缓存未命中率和更多的主内存流量，从而相对于 $8$ 个线程减慢了执行速度。**\n末级缓存 (LLC)，通常是 $L3$ 缓存，是多个核心共享的一个关键性能组件。每个线程的性能都取决于能否将其工作数据集保留在缓存中，以避免缓慢的主内存访问。当线程数从 $8$ 增加到 $16$ 时，每个线程可用的 LLC 容量减半。这可能导致一种被称为“缓存颠簸”的情况，即线程之间相互竞争，将对方的数据从缓存中驱逐出去。由此导致的缓存未命中率增加，迫使 CPU 更频繁地从主内存获取数据，而这要慢上几个数量级。这种被称为缓存竞争的效应会增加内存流量和处理器停顿，从而导致性能减慢。\n结论：**正确**。\n\n**F. DFT 使用的数学算法在更多线程上运行时，其渐近复杂性类别更差，因此在 $16$ 个线程时其大O成本增加。**\n这一陈述反映了对计算复杂度的根本性误解。渐近复杂度，用像 $O(N^3)$ 这样的大O表示法来表示，描述的是一个算法的资源需求（如时间或内存）如何随输入规模 $N$（衡量系统大小的指标，如基函数的数量）而变化。它不依赖于用于执行的处理器数量。无论是否并行化，底层的数学算法都保持不变。并行化影响的是执行时间中的常数因子，即 $T(N, P) = c(P) \\cdot f(N)$，其中 $P$ 是处理器数量，$f(N)$ 代表渐近增长。函数 $f(N)$ 不会随 $P$ 的变化而改变。\n结论：**错误**。\n\n**G. 同时多线程 (SMT) 已启用；$16$ 个线程分时共享 $8$ 个物理核心，对于此工作负载，额外的硬件线程几乎不提供好处，甚至因资源竞争而产生负面影响。**\n同时多线程 (SMT)，在 Intel CPU 上被称为 Hyper-Threading，允许单个物理核心向操作系统呈现为两个（或更多）逻辑处理器。如果该工作站有一个启用了 SMT 的 $8$ 核 CPU，它将显示为拥有 $16$ 个逻辑核心。一次 $8$ 线程的运行会利用 $8$ 个物理核心，每个核心一个线程。而一次 $16$ 线程的运行会在每个物理核心上调度两个线程。这两个线程必须共享该核心的执行资源（例如，浮点单元、加载/存储单元、L1/L2 缓存）。对于许多已经为利用核心资源而高度优化的科学计算工作负载来说，这种共享会导致资源竞争，而不是对空闲周期的有效利用。这种竞争可能使一个核心上的两个线程的运行速度明显慢于单个线程速度的两倍，在某些情况下，甚至可能比每个核心单线程的情形还要慢，从而导致从 $8$ 个线程增加到 $16$ 个线程时出现净性能损失。\n结论：**正确**。", "answer": "$$\\boxed{ABCEG}$$", "id": "2452799"}]}