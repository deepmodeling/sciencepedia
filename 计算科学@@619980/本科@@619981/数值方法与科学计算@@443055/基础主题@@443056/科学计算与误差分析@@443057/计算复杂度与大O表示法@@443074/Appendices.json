{"hands_on_practices": [{"introduction": "这个练习是计算复杂性分析的绝佳切入点。我们将从一个常见的场景开始：遍历一个数据集，并对其中的每个项目执行固定量的工作。通过分析一个直接的算法，本练习将帮助您掌握将其转化为大O表示法的基本技能，教会您如何识别主导操作并忽略不影响算法可扩展性的常数因子 [@problem_id:1349082]。", "problem": "一位工程师正在为社交媒体平台开发一个系统，以验证其用户帐户的完整性。他们设计了一种名为 `verifyAllAccounts` 的算法，该算法接收一个包含 $n$ 个用户个人资料的列表作为输入。该算法会逐一迭代这 $n$ 个个人资料。对于每个个人资料，它都会调用一个名为 `runComplianceScan` 的子程序。这个 `runComplianceScan` 子程序被设计用来执行一组固定且恒定的1000个基本计算操作（例如数据字段比较和哈希检查），以确保帐户符合平台的服务条款。`runComplianceScan` 执行的操作数量始终为1000，与个人资料中的具体数据或用户总数 $n$ 无关。\n\n假设访问列表中的每个个人资料所需时间为常数，那么整个 `verifyAllAccounts` 算法关于用户数量 $n$ 的渐近时间复杂度（大O表示法）是多少？\n\nA. $O(\\log n)$\n\nB. $O(n)$\n\nC. $O(n \\log n)$\n\nD. $O(n^2)$\n\nE. $O(1000^n)$\n\nF. $O(1)$", "solution": "要确定 `verifyAllAccounts` 算法的时间复杂度，我们需要分析其作为输入大小 $n$ 的函数所执行的基本操作总数。设 $T(n)$ 代表这个操作总数。\n\n该算法包含一个主循环，遍历 $n$ 个用户个人资料中的每一个。这种结构可以建模为一个从 $i=1$ 到 $n$ 的 `for` 循环。\n\n对于主循环的每次迭代（即，对于每个用户个人资料），算法都会调用 `runComplianceScan` 子程序。问题陈述 `runComplianceScan` 执行恒定数量的操作，具体为1000次。\n\n因此，在第一次迭代中（针对第一个用户），执行1000次操作。\n在第二次迭代中（针对第二个用户），再执行1000次操作。\n这个过程对所有 $n$ 个用户都继续进行。\n\n为了求出总操作数 $T(n)$，我们将主循环的 $n$ 次迭代中每次执行的操作数相加。由于每次迭代都恰好贡献1000次操作，总数为：\n$$T(n) = \\sum_{i=1}^{n} 1000$$\n这等价于将1000自加 $n$ 次：\n$$T(n) = 1000 + 1000 + \\dots + 1000 \\quad (n \\text{ times})$$\n$$T(n) = 1000 \\cdot n$$\n\n现在，我们必须求出 $T(n)$ 的大O复杂度。根据大O表示法的定义，如果存在正常数 $c$ 和 $n_0$，使得对于所有 $n \\ge n_0$ 都有 $0 \\le T(n) \\le c \\cdot g(n)$，则函数 $T(n)$ 属于 $O(g(n))$。\n\n在我们的例子中，$T(n) = 1000n$。我们在寻找能够作为 $T(n)$ 上界的那个最简单的函数 $g(n)$。我们来测试函数 $g(n) = n$。\n我们需要检查是否存在某个常数 $c$ 使得对于所有 $n \\ge n_0$ 都有 $1000n \\le c \\cdot n$。\n如果我们选择常数 $c = 1000$，不等式变为 $1000n \\le 1000n$。这对所有 $n \\ge 1$ 都成立。所以，我们可以选择 $c=1000$ 和 $n_0=1$。\n既然我们找到了这样的常数，我们可以得出结论 $T(n)$ 属于 $O(n)$。\n\n在大O分析中，常数因子被忽略，因为我们关心的是当 $n$ 变得非常大时函数的增长率。函数 $1000n$ 随 $n$ 线性增长，就像函数 $n$ 一样。因此，渐近时间复杂度为 $O(n)$。\n\n将我们的结果与给定选项进行比较：\nA. $O(\\log n)$: 不正确。对数增长远慢于线性增长。\nB. $O(n)$: 正确。运行时间随用户数量线性增长。\nC. $O(n \\log n)$: 不正确。这是超线性增长，常见于高效的排序算法。\nD. $O(n^2)$: 不正确。这是平方增长，典型的例子是内循环的迭代次数也依赖于 $n$ 的嵌套循环。\nE. $O(1000^n)$: 不正确。这是指数增长，远大于实际的线性增长。\nF. $O(1)$: 不正确。常数时间复杂度意味着运行时间与 $n$ 无关。\n\n因此，正确的时间复杂度是 $O(n)$。", "answer": "$$\\boxed{B}$$", "id": "1349082"}, {"introduction": "科学计算中许多最高效的算法，从排序到快速傅里叶变换，都建立在“分而治之”的原则之上。分析这些递归算法的运行时间需要一种不同于简单计算循环迭代次数的方法。本练习将指导您使用递归树方法来解决一个经典的分治递推关系，揭示像 $\\Theta(N^{\\log_2(3)})$ 这样不那么直观的复杂性是如何产生的 [@problem_id:3215942]。", "problem": "一个用于处理大小为 $N$ 的输入的分治数值核心将问题分解为 $3$ 个大小为 $N/2$ 的子问题，并执行一个额外的线性时间复杂度的合并步骤。假设运行时间 $T(N)$ 满足以下递推关系：\n$$\nT(N)=3\\,T\\!\\left(\\frac{N}{2}\\right)+c\\,N \\quad \\text{for } N\\ge 2, \\quad T(1)=d,\n$$\n其中 $c0$ 和 $d0$ 是常数，且 $N$ 是 $2$ 的幂。请仅使用 $O(\\cdot)$ 记号的定义、用于分析分治递推式的递归树方法，以及对数和几何级数的标准性质，推导出 $T(N)$ 的渐近增长率，其形式为 $T(N)=\\Theta(N^{\\alpha})$，其中指数 $\\alpha0$。然后，通过定义指数差\n$$\n\\gamma \\equiv 2-\\alpha,\n$$\n将此增长率与一个复杂度为 $O(N^{2})$ 的标准平方时间数值方法的增长率进行比较。\n请给出 $\\gamma$ 的精确闭式表达式作为最终答案。不要进行近似或四舍五入；无需进行数值舍入。", "solution": "该问题给出了一个分治算法运行时间 $T(N)$ 的递推关系，并要求推导其渐近增长率。最终目标是计算指数差 $\\gamma$。\n\n### 步骤一：问题验证\n\n第一步是对问题陈述进行关键的验证。\n\n**逐字提取的已知条件：**\n*   递推关系：$T(N)=3\\,T\\!\\left(\\frac{N}{2}\\right)+c\\,N \\quad \\text{for } N\\ge 2$\n*   基础情况：$T(1)=d$\n*   常数：$c0$ 和 $d0$\n*   输入规模约束：$N$ 是 $2$ 的幂。\n*   任务：\n    1.  使用递归树方法推导渐近增长率 $T(N)=\\Theta(N^{\\alpha})$，其中指数 $\\alpha0$。\n    2.  将其与一个复杂度为 $O(N^{2})$ 的平方时间方法进行比较。\n    3.  定义指数差 $\\gamma \\equiv 2-\\alpha$。\n    4.  给出 $\\gamma$ 的精确闭式表达式。\n\n**验证分析：**\n*   **科学依据**：该问题是算法分析领域的经典范例，算法分析是计算机科学和数值方法的核心课题。该递推关系是用于建模分治算法的标准形式。所要求的方法，即递归树分析，是解决此类递推式的基本技巧。该问题在科学上和数学上都是合理的。\n*   **良定性**：该问题是良定的。递推式、基础情况以及对 $N$ 的约束（作为 $2$ 的幂）都已明确指定，确保了 $T(N)$ 存在唯一、精确的解，并且其渐近行为可以确定，而不会涉及向下取整或向上取整函数带来的模糊性。\n*   **客观性**：该问题以精确、客观的数学语言陈述。\n*   **完整性与一致性**：提供了所有必要的信息。常数 $c$ 和 $d$ 被定义为正数，这对于运行时间而言具有物理意义。约束条件是一致的。\n*   **其他缺陷**：该问题并非不切实际、病态、微不足道或无法验证。它是算法分析中一个标准的、非平凡的练习。\n\n**结论：** 该问题是 **有效的**。我们可以继续进行求解。\n\n### 步骤二：求解推导\n\n我们将按照要求使用递归树方法来确定 $T(N)$ 的渐近行为。给定的递推关系为 $T(N) = 3\\,T(N/2) + cN$。\n\n递归树将计算的成本可视化。在根节点（第 0 层），我们有 1 个大小为 $N$ 的问题。在这一层，递归调用之外完成的工作是合并步骤，其成本为 $cN$。这个单一问题产生 $3$ 个大小为 $N/2$ 的子问题。\n\n在树的第 1 层，我们有 $3$ 个节点，每个节点对应一个大小为 $N/2$ 的子问题。每个子问题的合并成本是 $c(N/2)$。因此，第 1 层的总成本是 $3 \\times c(N/2) = cN \\cdot (3/2)$。\n\n在第 2 层，第 1 层的 $3$ 个节点中的每一个都产生 $3$ 个新的子问题，从而得到 $3 \\times 3 = 3^2$ 个节点。这些节点中的每一个都对应一个大小为 $N/2^2 = N/4$ 的问题。每个问题的合并成本是 $c(N/4)$。第 2 层的总成本是 $3^2 \\times c(N/4) = cN \\cdot (3/2)^2$。\n\n我们可以将其推广到任意层 $k$。在第 $k$ 层，有 $3^k$ 个子问题，每个子问题的大小为 $N/2^k$。在第 $k$ 层产生的总成本是所有这些子问题的合并成本之和，即：\n$$\n\\text{Cost(level } k) = 3^k \\times c \\left(\\frac{N}{2^k}\\right) = cN \\left(\\frac{3}{2}\\right)^k\n$$\n递归一直持续到子问题的大小变为 $1$。设树的深度为 $h$。这在 $N/2^h = 1$ 时发生。由于 $N$ 是 $2$ 的幂，我们可以写出 $N = 2^h$，这意味着 $h = \\log_2(N)$。树的层级从 $k=0, 1, \\dots, h$ 索引。最后一层，即第 $h$ 层，由叶节点组成。\n\n总运行时间 $T(N)$ 是所有层级成本的总和。这包括从第 $k=0$ 层到第 $k=h-1$ 层的内部节点（合并步骤）的成本，以及叶节点（第 $h$ 层）的基础情况成本。\n\n在第 $h$ 层，叶节点的数量是 $3^h$。每个叶节点对应一个基础情况 $T(1)=d$。所以，第 $h$ 层的总成本是：\n$$\n\\text{Cost(level } h) = 3^h \\cdot T(1) = 3^h d\n$$\n总成本 $T(N)$ 是所有层级成本的总和：\n$$\nT(N) = \\left( \\sum_{k=0}^{h-1} cN \\left(\\frac{3}{2}\\right)^k \\right) + 3^h d\n$$\n我们可以从求和中提取出常数项：\n$$\nT(N) = cN \\left( \\sum_{k=0}^{h-1} \\left(\\frac{3}{2}\\right)^k \\right) + 3^h d\n$$\n该求和是一个首项为 $a=1$、公比为 $r=3/2$、共有 $h$ 项的有限几何级数。其和由公式 $\\sum_{k=0}^{m-1} r^k = \\frac{r^m - 1}{r - 1}$ 给出。在我们的例子中，$m=h$：\n$$\n\\sum_{k=0}^{h-1} \\left(\\frac{3}{2}\\right)^k = \\frac{(3/2)^h - 1}{(3/2) - 1} = \\frac{(3/2)^h - 1}{1/2} = 2\\left(\\left(\\frac{3}{2}\\right)^h - 1\\right)\n$$\n将此代回 $T(N)$ 的表达式中：\n$$\nT(N) = cN \\cdot 2\\left(\\left(\\frac{3}{2}\\right)^h - 1\\right) + 3^h d = 2cN\\left(\\frac{3^h}{2^h} - 1\\right) + 3^h d\n$$\n现在，我们代入 $h=\\log_2(N)$。这意味着 $2^h = N$。对于 $3^h$ 项，我们使用对数恒等式 $a^{\\log_b(c)} = c^{\\log_b(a)}$：\n$$\n3^h = 3^{\\log_2(N)} = N^{\\log_2(3)}\n$$\n将这些代入 $T(N)$ 的表达式中：\n$$\nT(N) = 2cN\\left(\\frac{N^{\\log_2(3)}}{N} - 1\\right) + d \\cdot N^{\\log_2(3)}\n$$\n$$\nT(N) = 2c\\left(N^{\\log_2(3)} - N\\right) + d \\cdot N^{\\log_2(3)}\n$$\n$$\nT(N) = 2c N^{\\log_2(3)} - 2cN + d N^{\\log_2(3)}\n$$\n$$\nT(N) = (2c+d)N^{\\log_2(3)} - 2cN\n$$\n对于渐近分析，我们观察到 $\\log_2(3) \\approx 1.585$，它大于 $1$。因此，$N^{\\log_2(3)}$ 项的渐近增长速度比 $N$ 项快。$T(N)$ 表达式中的主导项是 $(2c+d)N^{\\log_2(3)}$。\n因此，渐近增长率为：\n$$\nT(N) = \\Theta(N^{\\log_2(3)})\n$$\n问题陈述了 $T(N) = \\Theta(N^\\alpha)$。通过比较这两种形式，我们确定指数 $\\alpha$：\n$$\n\\alpha = \\log_2(3)\n$$\n问题将指数差 $\\gamma$ 定义为一个平方时间方法（指数为 $2$）的指数与 $\\alpha$ 之间的差：\n$$\n\\gamma \\equiv 2 - \\alpha\n$$\n代入我们求得的 $\\alpha$ 值：\n$$\n\\gamma = 2 - \\log_2(3)\n$$\n这就是 $\\gamma$ 的精确闭式表达式。", "answer": "$$\n\\boxed{2 - \\log_{2}(3)}\n$$", "id": "3215942"}, {"introduction": "虽然大O表示法是抽象比较算法的强大工具，但它有意忽略了计算机硬件的物理现实。这个高级练习通过矩阵乘法的例子，探讨了渐近分析的一个关键局限性。您将研究为什么具有相同 $O(N^3)$ 复杂度的不同循环顺序，在现实世界中会产生截然不同的运行时间，从而为理解内存访问模式和缓存性能的重要性提供一堂关键课程 [@problem_id:3215939]。", "problem": "考虑大小为 $N \\times N$ 的稠密实数矩阵 $A$、$B$ 和 $C$，它们以行主序存储，其中元素 $X[i,j]$ 位于与 $iN + j$ 成正比的内存地址处。乘积 $C = A \\cdot B$ 是通过一个三重嵌套循环算法计算的，无论循环顺序如何，该算法都执行 $N^3$ 次乘加运算。现代中央处理器 (CPU) 以包含 $L$ 个连续元素的缓存行（cache line）为单位获取内存，并受益于空间局部性（spatial locality）和时间局部性（temporal locality）。所有三种标记为 $\\text{ijk}$、$\\text{ikj}$ 和 $\\text{jik}$ 的循环顺序都实现了相同的算术序列，并且具有 $O(N^3)$ 的渐近时间复杂度。\n\n选择所有能正确解释为什么这些循环顺序在实际应用中通常表现出巨大性能差异，并指出在行主序数据上，是什么因素使得某一种顺序通常比其他顺序更快的陈述：\n- A. 渐近界 $O(N^3)$ 隐藏了由内存层次结构（memory hierarchy）引起的常数因子；改变循环顺序会改变空间和时间局部性，因此缓存未命中（cache miss）的次数可能会相差一个与 $L$ 成正比的因子，这在现代硬件上主导了运行时间。\n- B. $\\text{ikj}$ 顺序执行的浮点运算比 $\\text{ijk}$ 和 $\\text{jik}$ 顺序少，从而将算术计数降低到 $O(N^3)$ 以下。\n- C. 在行主序存储中，$\\text{ijk}$ 和 $\\text{jik}$ 顺序在最内层循环中按列访问 $B[k,j]$（步长为 $N$），每个缓存行大约只产生一个有用元素，并且导致较差的转译后备缓冲器（TLB）行为，而 $\\text{ikj}$ 顺序在最内层循环中按行访问 $B[k,j]$（步长为 $1$），这使得硬件预取（hardware prefetch）和单指令多数据（SIMD）向量化成为可能；这导致了显著不同的运行时间。\n- D. 所有三种顺序的性能相同，因为编译器总是在编译时将循环重排为最优布局，而不考虑数据布局和依赖关系。\n- E. 在一个具有单位成本内存访问和无限缓存的理想化随机存取存储器（RAM）模型下，所有三种顺序的性能将无法区分；大O表示法（Big-O notation）抽象掉了这些与机器相关的效应，这解释了为什么它不能预测这些性能差异。", "solution": "问题陈述是计算科学领域一个有效的练习，涉及算法设计在现代计算机体系结构上的实际性能影响。它具有科学依据、问题明确、客观，并且没有任何逻辑或事实上的缺陷。它正确地设置了一个经典场景，展示了在忽略内存层次结构时渐近分析（$O$表示法）的局限性。因此，我们可以进行全面分析。\n\n问题的核心在于计算矩阵乘积 $C = A \\cdot B$，其中 $A, B, C$ 是 $N \\times N$ 的矩阵。元素 $C[i,j]$ 的矩阵乘法定义为：\n$$C[i,j] = \\sum_{k=0}^{N-1} A[i,k] \\cdot B[k,j]$$\n对于所有 $i,j \\in \\{0, 1, \\dots, N-1\\}$，都必须执行此计算。一个朴素的实现使用三重嵌套循环来遍历索引 $i, j, k$。这些循环的顺序会显著影响性能，这是由于现代CPU处理内存访问的方式，特别是通过缓存。矩阵以行主序存储，意味着元素 $X[i,j]$ 的内存地址与 $iN+j$ 成正比。沿行顺序访问元素（例如，$X[i,j]$ 后面跟着 $X[i,j+1]$）是步长为1的访问，效率很高。沿列向下访问元素（例如，$X[i,j]$ 后面跟着 $X[i+1,j]$）是步长为N的访问，对于大的 $N$ 来说效率很低。\n\n让我们分析每种顺序在最内层循环中的内存访问模式，因为这个循环执行 $N^3$ 次并主导了运行时间。\n\n1.  **`ijk` 顺序：**\n    ```\n    for i = 0 to N-1\n      for j = 0 to N-1\n        // C[i,j] is accumulated in this loop\n        for k = 0 to N-1\n          C[i,j] += A[i,k] * B[k,j]\n    ```\n    在最内层循环（关于 $k$），索引 $i$ 和 $j$ 是固定的。\n    - **`A[i,k]`**: 顺序访问 $A$ 的第 $i$ 行元素。这是步长为1的访问，表现出良好的空间局部性。\n    - **`B[k,j]`**: 访问 $B$ 的第 $j$ 列元素。在行主序存储中，这是步长为 $N$ 的访问。这具有较差的空间局部性；如果 $N$ 大于一个缓存行中的元素数量，每次访问都可能导致缓存未命中。\n    - **`C[i,j]`**: 同一个元素被重复访问，用作累加器。这表现出极好的时间局部性，并且很可能被保存在CPU寄存器中。\n\n2.  **`ikj` 顺序：**\n    ```\n    for i = 0 to N-1\n      for k = 0 to N-1\n        // A[i,k] is a scalar for the inner loop\n        for j = 0 to N-1\n          C[i,j] += A[i,k] * B[k,j]\n    ```\n    在最内层循环（关于 $j$），索引 $i$ 和 $k$ 是固定的。\n    - **`A[i,k]`**: 在内层循环的所有 $N$ 次迭代中，同一个元素被重复访问。这具有极好的时间局部性。\n    - **`B[k,j]`**: 顺序访问 $B$ 的第 $k$ 行元素。这是步长为1的访问，表现出良好的空间局部性。\n    - **`C[i,j]`**: 顺序访问 $C$ 的第 $i$ 行元素。这也是步长为1的访问，具有良好的空间局部性。\n    这种顺序是最高效的，因为最内层循环中的所有内存访问都是局部的（无论是时间局部性还是步长为1的空间局部性）。\n\n3.  **`jik` 顺序：**\n    ```\n    for j = 0 to N-1\n      for i = 0 to N-1\n        // C[i,j] is accumulated in this loop\n        for k = 0 to N-1\n          C[i,j] += A[i,k] * B[k,j]\n    ```\n    在最内层循环（关于 $k$），索引 $j$ 和 $i$ 是固定的。\n    - **`A[i,k]`**: 顺序访问 $A$ 的第 $i$ 行元素。这是步长为1的访问（良好的空间局部性）。\n    - **`B[k,j]`**: 访问 $B$ 的第 $j$ 列元素。这是步长为 $N$ 的访问（较差的空间局部性），与 `ijk` 顺序中的情况相同。\n    - **`C[i,j]`**: 同一个元素被重复访问（极好的时间局部性）。\n    `jik` 顺序的最内层循环具有与 `ijk` 顺序相同的内存访问特性。两者都受限于对矩阵 $B$ 的非局部访问。\n\n基于此分析，在具有内存层次结构的系统上，`ikj` 顺序的性能将显著优于 `ijk` 和 `jik`。性能差异源于缓存未命中的次数。`ijk`/`jik` 的缓存未命中次数约为 $O(N^3)$，而 `ikj` 的缓存未命中次数约为 $O(N^3/L)$，其中 $L$ 是每个缓存行的数据元素数量。\n\n现在我们来评估每个选项。\n\n**A. 这个陈述是对情况的准确高层总结。$O(N^3)$ 的复杂度指的是算术运算的数量，假设每次运算的成本为单位成本。在实际硬件上，内存访问成本是非均匀的，这个假设不成立。大O表示法隐藏的“常数因子”实际上是缓存大小、延迟、带宽和缓存行大小 $L$ 的复杂函数。正如我们的分析所示，低效顺序（`ijk`、`jik`）的缓存未命中次数大约为 $N^3$，而高效顺序（`ikj`）的缓存未命中次数大约为 $N^3/L$。未命中次数的比率确实与 $L$ 成正比。由于内存访问远慢于算术运算，对于大矩阵而言，这种缓存性能的差异是影响总运行时间的主导因素。\n**结论：正确。**\n\n**B. 这个陈述是错误的。问题陈述本身正确地指出，所有三种顺序都执行 $N^3$ 次乘加运算。标准算法的浮点运算总数为 $2N^3 - N^2$，即 $O(N^3)$。交换循环顺序会改变加法和乘法的执行顺序（例如，`ijk` 计算点积，`ikj` 执行向量-标量乘积和加法），但这不会改变这些操作的总数。\n**结论：不正确。**\n\n**C. 这个陈述对性能差异给出了详细且技术上正确的解释。我们的分析证实了 `ijk` 和 `jik` 在最内层循环中涉及对矩阵 $B$ 的步长为 $N$ 的访问。这导致了较差的缓存利用率（“每个缓存行只有一个有用元素”）。如果矩阵足够大，以至于每一步长为 $N$ 的访问都落在新的内存页上，这种大步长也可能导致频繁的转译后备缓冲器（TLB）未命中。相比之下，`ikj` 顺序访问所有矩阵都具有良好的局部性（对 `B` 和 `C` 是步长为1，对 `A` 是时间局部性）。可预测的步长为1的访问模式对于硬件预取器在数据需要之前自动将其取入缓存，以及对于编译器生成 SIMD（向量）指令（同时对多个数据元素执行相同操作）来说是理想的。这些因素共同造成了巨大的性能差距。\n**结论：正确。**\n\n**D. 这个陈述是不正确的。尽管现代优化编译器可以并且确实会执行像循环交换这样的循环变换，但它们的能力是有限的。编译器必须能够证明变换是安全的，并且保留程序的语义。指针别名、循环内的函数调用，或者在编译时矩阵维度未知的情况下，都可能阻止此类优化。声称它们“总是”成功是极大的夸张，并且在经验上是错误的；如果这是真的，矩阵核心的性能调优就不会成为一个主要的研究领域。此外，优化严重依赖于数据布局，而非独立于它。\n**结论：不正确。**\n\n**E. 这个陈述正确地指出了标准渐近分析所依据的理论计算机科学模型。在RAM模型中，每次内存操作都具有统一的成本，通常认为是 $O(1)$。一个无限大的缓存有效地模拟了这个模型。在这个模型下，总运行时间与算术运算的数量成正比。由于所有三种循环顺序执行相同数量的操作（$O(N^3)$），它们的性能确实将无法区分。该陈述正确地得出结论，大O表示法基于这种理想化模型，抽象掉了内存层次结构的现实世界影响，因此它本身不足以预测观察到的性能差异。\n**结论：正确。**", "answer": "$$\\boxed{ACE}$$", "id": "3215939"}]}