{"hands_on_practices": [{"introduction": "这个首个练习清晰直观地介绍了数据误差的概念。通过分析截断常数 $\\pi$ 这一简单行为，我们可以推导出体积计算中由此产生的误差的精确公式。这项实践将帮助您理解初始的不精确性（即使很小）是如何通过数学公式传播，并可能根据输入数据而被放大 [@problem_id:3221388]。", "problem": "在数值方法和科学计算中，截断数学常数会引入数据误差，这些误差会在计算过程中传播。考虑一个半径为 $R$ 的球体，其中 $R$ 是一个精确已知的正实数。其真实体积由一个经过充分验证的几何公式确定。假设在实践中，常数 $\\pi$ 在计算球体体积前被截断为小数值 $3.14$。使用前向（输出）误差（即计算量与真实量之差）的基本定义，并仅利用已确立的几何事实，推导仅因将 $\\pi$ 截断为 $3.14$ 而导致的计算体积的有符号误差的精确闭式表达式。请将最终答案表示为关于 $R$ 的单个解析表达式。无需进行四舍五入。", "solution": "问题陈述已经过验证，被认为是自洽、一致且科学合理的。它提出了数值分析领域中的一个良定问题，具体涉及常数截断引起的数据误差。该问题是可形式化且客观的。\n\n目标是推导当常数 $\\pi$ 被截断时，计算出的球体体积的有符号误差的精确闭式表达式。问题明确将此误差定义为前向误差。\n\n设 $V_{\\text{true}}$ 为球体的真实体积，$V_{\\text{computed}}$ 为计算体积。球体半径为 $R$，它是一个精确已知的正实数。\n\n根据已确立的几何原理，球体的真实体积由以下公式给出：\n$$V_{\\text{true}} = \\frac{4}{3}\\pi R^3$$\n\n问题陈述指出，在计算中，常数 $\\pi$ 被截断为小数值 $3.14$。我们将此近似值记为 $\\pi_{\\text{approx}}$。\n$$\\pi_{\\text{approx}} = 3.14$$\n因此，计算体积是使用这个截断值计算的：\n$$V_{\\text{computed}} = \\frac{4}{3}\\pi_{\\text{approx}} R^3 = \\frac{4}{3}(3.14)R^3$$\n\n问题将有符号误差（我们记为 $E$）定义为前向（输出）误差。即计算量与真实量之差。\n$$E = V_{\\text{computed}} - V_{\\text{true}}$$\n\n将 $V_{\\text{computed}}$ 和 $V_{\\text{true}}$ 的表达式代入误差 $E$ 的定义中，我们得到：\n$$E = \\left(\\frac{4}{3}(3.14)R^3\\right) - \\left(\\frac{4}{3}\\pi R^3\\right)$$\n\n为简化此表达式，我们可以提出公因式 $\\frac{4}{3}R^3$：\n$$E = \\frac{4}{3}R^3 (3.14 - \\pi)$$\n\n该表达式即为体积的有符号误差的精确闭式表达式。它是一个关于 $R$ 的解析表达式，符合要求。项 $(3.14 - \\pi)$ 是一个负常数，这正确地表明将 $\\pi$ 截断为一个更小的值将导致计算体积小于真实体积。\n最终表达式为：\n$$E = \\frac{4}{3}(3.14 - \\pi)R^3$$", "answer": "$$\\boxed{\\frac{4}{3}(3.14 - \\pi)R^3}$$", "id": "3221388"}, {"introduction": "数值计算并非完美，每次浮点运算都可能引入微小的舍入误差。本练习将展示这些小误差如何累积成显著的差异，以及运算顺序如何出人意料地影响最终结果。通过实现并比较朴素求和与复杂的 Kahan 求和算法，您将对数值稳定性以及选择正确算法的重要性获得切实的理解 [@problem_id:3221372]。", "problem": "考虑双精度浮点求和。假设采用就近舍入，单位舍入为 $u$，其模型由标准浮点舍入关系式 $ \\operatorname{fl}(a \\circ b) = (a \\circ b)(1 + \\theta) $ 描述，适用于基本运算 $ \\circ \\in \\{ +, -, \\times, \\div \\} $，其中 $|\\theta| \\leq u$ 且对于 IEEE 754 双精度标准，$u = 2^{-53}$。令 $x_i = \\frac{1}{i} + \\delta_i$，其中 $i \\in \\{1,2,\\dots,n\\}$，$\\delta_i$ 是微小的加性数据噪声。目标是通过以 $i$ 的升序和降序计算 $ \\sum_{i=1}^{n} x_i $，来研究求和顺序对舍入误差的影响，并在存在加性数据噪声 $\\delta_i$ 的情况下，比较朴素顺序求和与补偿求和方法（Kahan 求和算法）。\n\n任务：\n- 对于每个测试用例，构造序列 $x_i = \\frac{1}{i} + \\delta_i$，$i = 1,\\dots,n$。使用固定的伪随机种子 $0$ 从均值为 $0$、标准差为 $\\sigma$ 的正态分布中生成独立样本 $\\delta_i$，以使噪声的实现是确定性的。整个过程使用双精度。\n- 为每个测试用例计算四个和：朴素升序、朴素降序、补偿升序、补偿降序。这里的“朴素”指没有任何补偿的直接从左到右累加，而“补偿”指为减少舍入误差而设计的数值稳定的求和技术。\n- 为每个测试用例报告以下四个浮点度量：\n    1. $d_{\\text{naive}} = \\left| S_{\\text{naive}}^{\\uparrow} - S_{\\text{naive}}^{\\downarrow} \\right|$，朴素升序和与朴素降序和之间的绝对差。\n    2. $d_{\\text{comp}} = \\left| S_{\\text{comp}}^{\\uparrow} - S_{\\text{comp}}^{\\downarrow} \\right|$，补偿升序和与补偿降序和之间的绝对差。\n    3. $I_{\\uparrow} = \\left| S_{\\text{naive}}^{\\uparrow} - S_{\\text{comp}}^{\\uparrow} \\right|$，升序求和中朴素方法与补偿方法结果的绝对差。\n    4. $I_{\\downarrow} = \\left| S_{\\text{naive}}^{\\downarrow} - S_{\\text{comp}}^{\\downarrow} \\right|$，降序求和中朴素方法与补偿方法结果的绝对差。\n\n测试套件：\n- 测试用例 A：$n = 1$，$\\sigma = 0$。\n- 测试用例 B：$n = 10^3$，$\\sigma = 0$。\n- 测试用例 C：$n = 10^5$，$\\sigma = 0$。\n- 测试用例 D：$n = 10^5$，$\\sigma = 10^{-12}$。\n\n实现细节：\n- 在每个测试用例中，使用固定的伪随机种子 $0$ 来生成长度为 $n$ 的整个向量 $\\delta_i$。噪声在不同 $i$ 之间是独立的。\n- 所有计算都必须以双精度进行。\n- 没有物理单位；所有量都是无量纲的。\n\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，每个测试用例的结果本身是按上述顺序排列的四个度量的逗号分隔列表。例如，输出格式应类似于 $[[d_{\\text{naive}},d_{\\text{comp}},I_{\\uparrow},I_{\\downarrow}],\\dots]$，不含空格。", "solution": "该问题是有效的。这是一个适定 (well-posed) 且具有科学依据的数值分析问题，旨在研究浮点舍入误差的累积以及不同求和策略的有效性。所有参数和过程都已明确定义。\n\n### 基于原理的解决方案设计\n\n此问题的核心在于理解浮点算术如何偏离精确的实数算术，特别是在对一长串数字求和的背景下。\n\n#### 1. 浮点求和与误差传播\n\n一个标准的浮点加法运算由 $\\operatorname{fl}(a + b) = (a + b)(1 + \\theta)$ 建模，其中 $|\\theta| \\leq u$。$u$ 是单位舍入，对于 IEEE 754 双精度标准，$u = 2^{-53}$。每次加法都可能引入一个小的相对误差。当对 $n$ 个数求和 $S_n = \\sum_{i=1}^n x_i$ 时，朴素顺序求和计算 $s_1 = x_1$，$s_2 = \\operatorname{fl}(s_1 + x_2)$，$s_3 = \\operatorname{fl}(s_2 + x_3)$，依此类推。每一步的误差都会累积。\n\n当对数量级差异巨大的数进行相加时，会出现一个众所周知的问题。如果我们将一个小数加到一个大数上，即 $|x_i| \\ll |s_{i-1}|$，那么这个较小的数可能会因舍入而部分或完全丢失。对于序列 $x_i = \\frac{1}{i}$，各项的量级是严格递减的：$x_1 > x_2 > \\dots > x_n$。\n\n- **朴素升序求和 ($S_{\\text{naive}}^{\\uparrow}$):** 这涉及从 $i=1$ 到 $n$ 求和。我们从最大的项 $x_1=1$ 开始，依次加上越来越小的项。随着部分和 $s_k = \\sum_{i=1}^k x_i$ 的增长，新加入的项 $x_{k+1}$ 相对于 $s_k$ 变得越来越小。这会导致严重的精度损失，这种现象广义上称为“灾难性抵消”，尽管在这里更像是一种渐进的吸收误差。\n\n- **朴素降序求和 ($S_{\\text{naive}}^{\\downarrow}$):** 这涉及从 $i=n$ 到 $1$ 求和。我们从最小的项开始，逐渐加上较大的项。部分和增长得更慢，连续相加的项的量级也更接近。这种策略通常能减少舍入误差的累积。因此，我们预期 $S_{\\text{naive}}^{\\downarrow}$ 会比 $S_{\\text{naive}}^{\\uparrow}$ 更精确。对于大的 $n$，差值 $d_{\\text{naive}} = |S_{\\text{naive}}^{\\uparrow} - S_{\\text{naive}}^{\\downarrow}|$ 预计会很显著。\n\n#### 2. 补偿求和（Kahan 算法）\n\n为了减轻舍入误差的累积，研究人员开发了多种数值稳定的算法。该问题指定使用一种补偿求和方法，其中 Kahan 求和算法是经典选择。该算法巧妙地追踪每次加法产生的舍入误差，并将其并入下一步的计算中。\n\n计算 $S = \\sum_{i=1}^n x_i$ 的算法如下：\n1. 初始化和 $s = 0.0$ 以及一个补偿变量 $c = 0.0$。\n2. 对于 $i=1$ 到 $n$：\n   a. $y = x_i - c$  （从当前项中减去上一步的误差）\n   b. $t = s + y$    （将修正后的项加到和上）\n   c. $c = (t - s) - y$  （新的误差是 $y$ 在与 $s$ 相加时丢失的部分）\n   d. $s = t$          （更新和）\n3. 最终结果是 $s$。\n\n关键在于步骤 2c。在精确算术中，$c$ 将为 $0$。在浮点算术中，$(t - s)$ 是 $y$ 中实际被吸收到 $s$ 中的部分。从此值中减去 $y$ 会得到 $y$ 丢失部分的相反数。这个“丢失的低位部分”随后会在下一次迭代的步骤 2a 中从下一个项 $x_{i+1}$ 中减去，从而有效地将其携带到后续的求和中。\n\nKahan 求和的误差界约为 $(2u + O(nu^2))\\sum_{i=1}^n |x_i|$。其一阶项与 $n$ 无关，这使得该算法即使对于非常大的求和也极其精确。因此，无论是升序 ($S_{\\text{comp}}^{\\uparrow}$) 还是降序 ($S_{\\text{comp}}^{\\downarrow}$) 的补偿求和结果，都应非常接近真实的数学和，因此彼此也非常接近。我们预期它们的差值 $d_{\\text{comp}} = |S_{\\text{comp}}^{\\uparrow} - S_{\\text{comp}}^{\\downarrow}|$ 将接近于零。\n\n补偿求和的结果可作为一个高精度的基准。因此，度量 $I_{\\uparrow} = |S_{\\text{naive}}^{\\uparrow} - S_{\\text{comp}}^{\\uparrow}|$ 和 $I_{\\downarrow} = |S_{\\text{naive}}^{\\downarrow} - S_{\\text{comp}}^{\\downarrow}|$ 分别有效地衡量了朴素升序和降序求和的绝对误差。我们预期对于大的 $n$，$I_{\\uparrow} > I_{\\downarrow}$。\n\n#### 3. 加性数据噪声的影响\n\n测试用例 D 引入了加性数据噪声 $\\delta_i$，这些噪声从均值为 $0$、标准差为 $\\sigma = 10^{-12}$ 的正态分布中采样。单位舍入 $u$ 约为 $2.22 \\times 10^{-16}$。由于 $\\sigma \\gg u$，数据噪声远大于单次运算的舍入误差。这些噪声项的和 $\\sum \\delta_i$ 将为总和带来一个误差。这个总噪声误差的标准差为 $\\sqrt{n}\\sigma$。对于 $n=10^5$，这个值约为 $\\sqrt{10^5} \\times 10^{-12} \\approx 3.16 \\times 10^{-10}$。\n\nKahan 求和能够精确地对给定的含噪数据 $x_i = 1/i + \\delta_i$ 进行求和。升序和降序 Kahan 求和之间的差值应该仍然可以忽略不计。然而，朴素求和将同时受到其固有的舍入误差累积和数据噪声的影响。度量 $I_{\\uparrow}$ 和 $I_{\\downarrow}$ 仍将主要反映朴素方法的大量舍入误差，因为对于 $n=10^5$，这些误差预计将远大于总的数据误差。\n\n### 算法实现\n\n- 对于每个测试用例 $(n, \\sigma)$：\n  1. 生成项向量 $x_i = \\frac{1}{i} + \\delta_i$，$i=1, \\dots, n$。每个用例都使用一个新的以 $0$ 为种子的伪随机数生成器来生成长度为 $n$ 的噪声向量 $\\delta$。对于 $\\sigma = 0$ 的情况，$\\delta_i = 0$。所有计算均使用双精度（`np.float64`）。\n  2. 创建数据向量的两个版本：一个按 $i$ 的升序排列，另一个按降序排列。\n  3. 实现两个求和函数：`naive_sum`（一个简单的循环累加器）和 `kahan_sum`（实现上述算法）。\n  4. 通过将适当的函数应用于适当的数据向量，计算四个和：$S_{\\text{naive}}^{\\uparrow}$、$S_{\\text{naive}}^{\\downarrow}$、$S_{\\text{comp}}^{\\uparrow}$ 和 $S_{\\text{comp}}^{\\downarrow}$。\n  5. 根据这些和计算所需的四个度量 ($d_{\\text{naive}}, d_{\\text{comp}}, I_{\\uparrow}, I_{\\downarrow}$)。\n  6. 按规定存储并格式化结果。", "answer": "```python\nimport numpy as np\n\ndef naive_sum(arr: np.ndarray) -> np.float64:\n    \"\"\"\n    Computes the sum of array elements using a naive, left-to-right\n    iterative approach.\n    \"\"\"\n    s = np.float64(0.0)\n    for x_i in arr:\n        s += x_i\n    return s\n\ndef kahan_sum(arr: np.ndarray) -> np.float64:\n    \"\"\"\n    Computes the sum of array elements using the Kahan summation algorithm\n    to minimize rounding error.\n    \"\"\"\n    s = np.float64(0.0)\n    c = np.float64(0.0)  # A running compensation for lost low-order bits.\n    for x_i in arr:\n        y = x_i - c\n        t = s + y\n        # (t - s) is the high-order part of y; ((t - s) - y) is the low-order part.\n        c = (t - s) - y\n        s = t\n    return s\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        (1, 0.0),            # Case A\n        (10**3, 0.0),        # Case B\n        (10**5, 0.0),        # Case C\n        (10**5, 10**-12)     # Case D\n    ]\n\n    all_results = []\n    for n, sigma in test_cases:\n        # 1. Construct the sequence x_i = 1/i + delta_i\n        # As per problem, re-seed for each test case for deterministic noise.\n        rng = np.random.default_rng(0)\n        \n        i_vals = np.arange(1, n + 1, dtype=np.float64)\n        x = 1.0 / i_vals\n        \n        if sigma > 0:\n            delta = rng.normal(loc=0.0, scale=sigma, size=n)\n            x += delta.astype(np.float64)\n\n        # Ensure final array is of the correct type\n        x = x.astype(np.float64)\n\n        # 2. Get ascending and descending views of the sequence\n        x_asc = x\n        x_desc = x[::-1].copy() # Use copy to ensure it's a new continuous array\n\n        # 3. Compute the four required sums\n        S_naive_up = naive_sum(x_asc)\n        S_naive_down = naive_sum(x_desc)\n        S_comp_up = kahan_sum(x_asc)\n        S_comp_down = kahan_sum(x_desc)\n\n        # 4. Compute the four metrics\n        d_naive = abs(S_naive_up - S_naive_down)\n        d_comp = abs(S_comp_up - S_comp_down)\n        I_up = abs(S_naive_up - S_comp_up)\n        I_down = abs(S_naive_down - S_comp_down)\n        \n        case_results = [d_naive, d_comp, I_up, I_down]\n        all_results.append(case_results)\n\n    # 5. Format the final output string as per requirements\n    # Format: [[d_naive_A,d_comp_A,I_up_A,I_down_A],[...]]\n    output_str = \",\".join([f\"[{','.join(map(str, res))}]\" for res in all_results])\n    print(f\"[{output_str}]\")\n\nsolve()\n```", "id": "3221372"}, {"introduction": "在现实世界的科学和工程中，数据几乎总是被噪声所污染，而且真实的误差分布通常是未知的。这个动手编程练习介绍了自助法（bootstrap），这是一种功能强大且广泛应用的计算技术，用于直接从数据本身量化统计估计的不确定性。通过对您自己的数据集进行重采样，您将学会如何稳健地估计标准误和置信区间，为您的计算结果加上可靠的误差棒 [@problem_id:3221310]。", "problem": "您会获得几个包含带噪声实值观测值的小数据集。您的任务是实现非参数自举法（nonparametric bootstrap），以量化样本均值和无偏样本标准差的不确定性。请使用以下核心定义和事实，从基本原理构建您的方法。\n\n基本原理：\n- 对于观测值 $x_{1}, x_{2}, \\dots, x_{n}$，样本均值定义为 $\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_{i}$。\n- 无偏样本标准差使用贝塞尔修正（Bessel’s correction），定义为 $s = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^{n} (x_{i} - \\bar{x})^{2}}$，其中 $n \\ge 2$。\n- 一个统计量的标准误（standard error）是其抽样分布的标准差。\n- 非参数自举法通过从经验分布中进行有放回重抽样来近似抽样分布，该经验分布在每个观测值 $x_{i}$ 处赋予 $1/n$ 的质量。通过从 $\\{x_{1}, \\dots, x_{n}\\}$ 中有放回地抽取 $n$ 个样本，并对该重抽样样本计算统计量，即可获得一个自举复制（bootstrap replicate）。\n- 覆盖率为 $0.95$ 的双侧置信区间可以通过百分位数法（percentile method）构建，即取自举复制样本在概率 $0.025$ 和 $0.975$ 处的经验分位数。\n\n要求：\n- 实现一个程序，对每个数据集执行以下操作。\n  1. 计算观测到的样本均值 $\\bar{x}$ 和无偏样本标准差 $s$。\n  2. 从观测数据中有放回地抽样，执行 $B$ 次自举重抽样，每次重抽样的样本量为 $n$。\n  3. 对于每个自举重抽样样本，计算其样本均值和无偏样本标准差（使用相同的 $n-1$ 自由度修正）。\n  4. 将自举均值分布的样本标准差作为均值的标准误估计值，将自举标准差分布的样本标准差作为标准差的标准误估计值。\n  5. 对均值和标准差，使用通过顺序统计量之间的线性插值计算出的 $0.025$ 和 $0.975$ 经验分位数，构建覆盖率为 $0.95$ 的双侧百分位置信区间。\n- 为确保确定性，在进行重抽样之前，为每个测试用例将随机数生成器设置为给定的整数种子。\n- 所有最终的数值输出必须四舍五入到 $6$ 位小数。\n- 最终输出必须是单行，包含所有测试用例的结果列表。对于每个测试用例，按以下顺序生成一个包含 $8$ 个浮点数的列表：$[\\bar{x}, \\text{SE}(\\bar{x}), \\text{CI}_{\\text{mean,lower}}, \\text{CI}_{\\text{mean,upper}}, s, \\text{SE}(s), \\text{CI}_{\\text{sd,lower}}, \\text{CI}_{\\text{sd,upper}}]$。整体输出必须是这些按用例排列的列表的列表，不含任何空格，例如：$[[a_{1},a_{2},\\dots,a_{8}],[b_{1},\\dots,b_{8}],\\dots]$。\n\n不涉及角度单位。不涉及物理单位。所有概率必须以小数表示，不得使用百分号。\n\n测试套件：\n- 用例 $1$（一般情况，中等噪声）：\n  - 数据 $x = (1.32, 0.98, 1.15, 0.87, 1.40, 1.05, 0.75, 1.22, 1.08, 0.91, 1.10, 1.27)$\n  - 自举复制次数 $B = 10000$\n  - 种子 $= 12345$\n- 用例 $2$（小样本，数值反映出重尾行为）：\n  - 数据 $x = (0.50, -0.20, 1.80, -3.50, 2.70)$\n  - 自举复制次数 $B = 20000$\n  - 种子 $= 24680$\n- 用例 $3$（退化方差边界情况）：\n  - 数据 $x = (2.00, 2.00, 2.00, 2.00, 2.00, 2.00)$\n  - 自举复制次数 $B = 5000$\n  - 种子 $= 42$\n- 用例 $4$（存在异常值）：\n  - 数据 $x = (9.80, 10.20, 9.90, 10.10, 9.70, 10.00, 10.30, 9.60, 9.95, 30.00)$\n  - 自举复制次数 $B = 15000$\n  - 种子 $= 13579$\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个由方括号括起来的、逗号分隔的列表的列表。例如：$[[r_{1,1},\\dots,r_{1,8}],[r_{2,1},\\dots,r_{2,8}],[r_{3,1},\\dots,r_{3,8}],[r_{4,1},\\dots,r_{4,8}]]$。打印行中任何地方都不能有空格。", "solution": "用户要求实现一个非参数自举程序，以估计多个数据集的样本均值和无偏样本标准差的不确定性。这需要一个基于统计学原理的、分步进行的过程。\n\n### 问题验证\n\n**第1步：提取已知信息**\n\n-   **统计量定义**：\n    -   样本均值：$\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_{i}$。\n    -   无偏样本标准差：$s = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^{n} (x_{i} - \\bar{x})^{2}}$，其中 $n \\ge 2$。\n-   **自举程序**：\n    -   一个统计量的标准误（SE）是其抽样分布的标准差。\n    -   非参数自举法通过从原始数据 $\\{x_1, \\dots, x_n\\}$ 中有放回地抽取创建 $B$ 个大小为 $n$ 的重抽样样本来近似抽样分布。\n    -   统计量的标准误被估计为该统计量的自举复制样本的样本标准差。\n    -   一个 $0.95$ 的置信区间（CI）是使用百分位数法构建的，取概率为 $0.025$ 和 $0.975$ 的经验分位数。\n    -   分位数的计算必须使用顺序统计量之间的线性插值。\n-   **执行要求**：\n    -   对于每个数据集，计算 $8$ 个值：$[\\bar{x}, \\text{SE}(\\bar{x}), \\text{CI}_{\\text{mean,lower}}, \\text{CI}_{\\text{mean,upper}}, s, \\text{SE}(s), \\text{CI}_{\\text{sd,lower}}, \\text{CI}_{\\text{sd,upper}}]$。\n    -   所有数值输出必须四舍五入到 $6$ 位小数。\n    -   每个用例都必须使用带有指定种子的确定性随机数生成器。\n-   **测试套件**：\n    -   用例 1：数据 $x = (1.32, 0.98, 1.15, 0.87, 1.40, 1.05, 0.75, 1.22, 1.08, 0.91, 1.10, 1.27)$， $B = 10000$，种子 $= 12345$。\n    -   用例 2：数据 $x = (0.50, -0.20, 1.80, -3.50, 2.70)$， $B = 20000$，种子 $= 24680$。\n    -   用例 3：数据 $x = (2.00, 2.00, 2.00, 2.00, 2.00, 2.00)$， $B = 5000$，种子 $= 42$。\n    -   用例 4：数据 $x = (9.80, 10.20, 9.90, 10.10, 9.70, 10.00, 10.30, 9.60, 9.95, 30.00)$， $B = 15000$，种子 $= 13579$。\n-   **输出格式**：代表列表的列表的单行，无空格，例如 $[[r_{1,1},\\dots,r_{1,8}],\\dots,[r_{4,1},\\dots,r_{4,8}]]$。\n\n**第2步：使用提取的已知信息进行验证**\n\n该问题具有科学依据、定义明确且客观。\n1.  **科学合理性**：样本均值、无偏样本标准差、标准误和非参数自举程序的定义在统计学领域是标准且正确的。\n2.  **定义明确性**：问题被完全指定。对于每个测试用例，都提供了数据、自举复制次数和随机种子。这确保了可以计算出唯一的、确定性的解。所需的输出也已明确定义。\n3.  **客观性**：问题以精确的数学语言表述，没有歧义或主观看法。测试用例，包括零方差和异常值等边界情况，适合用于验证一种统计方法。\n\n**第3步：结论与行动**\n\n该问题有效。将提供完整的解决方案。\n\n### 解决方案\n\n该解决方案实现了非参数自举法，以量化样本均值 $\\bar{x}$ 和无偏样本标准差 $s$ 的不确定性。自举法的核心原理是通过从观测数据的经验分布中反复抽样，来近似统计量的抽样分布。\n\n对于每个测试用例，总体算法流程如下：\n\n1.  **初始化**：给定一个大小为 $n$ 的数据集 $(x_1, x_2, \\dots, x_n)$、自举复制次数 $B$ 和一个随机种子，我们初始化一个伪随机数生成器（PRNG）以确保可复现性。\n\n2.  **从原始样本中计算点估计**：我们首先从原始数据中计算我们感兴趣的统计量。\n    -   样本均值计算为 $\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_{i}$。\n    -   无偏样本标准差使用贝塞尔修正计算：$s = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^{n} (x_{i} - \\bar{x})^{2}}$。这对应于 `numpy.std` 中设置 `ddof=1`（delta自由度）。\n\n3.  **自举重抽样与分布生成**：我们生成 $B$ 个自举重抽样样本。每个重抽样样本（表示为 $x^*$）是一个大小为 $n$ 的新数据集，通过从原始数据 $\\{x_1, \\dots, x_n\\}$ 中有放回地抽样形成。通过生成一个 $B \\times n$ 的随机索引矩阵，并使用这些索引用一次向量化操作构建所有 $B$ 个重抽样样本，可以高效地实现此过程。\n\n4.  **计算自举统计量**：对于 $B$ 个重抽样样本中的每一个，我们计算样本均值和无偏样本标准差。这将产生两个大小为 $B$ 的分布：\n    -   一个自举均值分布：$\\{\\bar{x}^{*}_1, \\bar{x}^{*}_2, \\dots, \\bar{x}^{*}_B\\}$。\n    -   一个自举标准差分布：$\\{s^{*}_1, s^{*}_2, \\dots, s^{*}_B\\}$，其中每个 $s^{*}_j$ 都是用 $n-1$ 作为分母计算的。\n\n5.  **估计标准误**：统计量的标准误是其抽样分布的标准差。我们从我们的自举分布中估计这个值。\n    -   均值的标准误 $\\text{SE}(\\bar{x})$ 通过自举均值分布的样本标准差来估计：$\\text{SE}(\\bar{x}) \\approx \\sqrt{\\frac{1}{B-1}\\sum_{j=1}^{B} (\\bar{x}^{*}_j - \\overline{\\bar{x}^{*}})^2}$，其中 $\\overline{\\bar{x}^{*}}$ 是自举均值的均值。\n    -   同样，标准差的标准误 $\\text{SE}(s)$ 通过自举标准差分布的样本标准差来估计。\n\n6.  **构建百分位置信区间**：使用百分位数法构建一个双侧 $95\\%$ 置信区间。这包括找到统计量的自举分布的经验分位数。\n    -   均值的置信区间为 $[\\text{quantile}(\\{\\bar{x}^{*}\\}, 0.025), \\text{quantile}(\\{\\bar{x}^{*}\\}, 0.975)]$。\n    -   标准差的置信区间为 $[\\text{quantile}(\\{s^{*}\\}, 0.025), \\text{quantile}(\\{s^{*}\\}, 0.975)]$。\n    问题指定分位数应使用线性插值计算，这是 `numpy.quantile` 中的默认方法。\n\n7.  **输出格式化**：将得到的八个值——$\\bar{x}$、$\\text{SE}(\\bar{x})$、其置信区间的下限和上限、$s$、$\\text{SE}(s)$、及其置信区间的下限和上限——收集起来，四舍五入到 $6$ 位小数，并格式化为所需的精确字符串格式。对所有测试用例重复此过程。", "answer": "```python\nimport numpy as np\n\ndef perform_bootstrap_analysis(data, B, seed):\n    \"\"\"\n    Performs a nonparametric bootstrap analysis for the mean and standard deviation.\n\n    Args:\n        data (tuple or list): The observed data points.\n        B (int): The number of bootstrap replicates.\n        seed (int): The seed for the random number generator.\n\n    Returns:\n        list: A list of 8 floats representing the computed statistics, rounded.\n    \"\"\"\n    x = np.array(data)\n    n = len(x)\n\n    # Initialize the random number generator for reproducibility.\n    rng = np.random.default_rng(seed)\n\n    # 1. Compute original sample statistics.\n    x_bar = np.mean(x)\n    # The problem defines s for n >= 2. All test cases satisfy this.\n    # ddof=1 ensures division by (n-1) for an unbiased estimator.\n    s = np.std(x, ddof=1) if n > 1 else 0.0\n\n    # Handle the degenerate variance case to avoid NaN issues.\n    if s == 0.0:\n        return [\n            x_bar, 0.0, x_bar, x_bar,\n            0.0, 0.0, 0.0, 0.0\n        ]\n\n    # 2. & 3. Generate B bootstrap resamples and compute their statistics.\n    # This is a vectorized approach for efficiency.\n    # First, generate all indices for all B resamples.\n    bootstrap_indices = rng.choice(n, size=(B, n), replace=True)\n    # Then create the resamples using advanced indexing.\n    bootstrap_samples = x[bootstrap_indices]\n    \n    # Compute statistics for each bootstrap sample along axis 1 (rows).\n    bootstrap_means = np.mean(bootstrap_samples, axis=1)\n    # Use ddof=1 for the standard deviation of each resample as required.\n    bootstrap_stds = np.std(bootstrap_samples, ddof=1, axis=1)\n\n    # 4. Estimate standard errors.\n    # The SE is the sample standard deviation (ddof=1) of the bootstrap distribution.\n    se_mean = np.std(bootstrap_means, ddof=1)\n    se_std = np.std(bootstrap_stds, ddof=1)\n\n    # 5. Construct 95% percentile confidence intervals.\n    # numpy.quantile uses linear interpolation by default.\n    ci_mean_lower, ci_mean_upper = np.quantile(bootstrap_means, [0.025, 0.975])\n    ci_std_lower, ci_std_upper = np.quantile(bootstrap_stds, [0.025, 0.975])\n    \n    # 6. Assemble the 8 required results.\n    results = [\n        x_bar, se_mean, ci_mean_lower, ci_mean_upper,\n        s, se_std, ci_std_lower, ci_std_upper\n    ]\n    \n    return results\n\ndef solve():\n    \"\"\"\n    Main function to run the analysis on all test cases and print the final output.\n    \"\"\"\n    test_cases = [\n        {\n            \"data\": (1.32, 0.98, 1.15, 0.87, 1.40, 1.05, 0.75, 1.22, 1.08, 0.91, 1.10, 1.27),\n            \"B\": 10000,\n            \"seed\": 12345\n        },\n        {\n            \"data\": (0.50, -0.20, 1.80, -3.50, 2.70),\n            \"B\": 20000,\n            \"seed\": 24680\n        },\n        {\n            \"data\": (2.00, 2.00, 2.00, 2.00, 2.00, 2.00),\n            \"B\": 5000,\n            \"seed\": 42\n        },\n        {\n            \"data\": (9.80, 10.20, 9.90, 10.10, 9.70, 10.00, 10.30, 9.60, 9.95, 30.00),\n            \"B\": 15000,\n            \"seed\": 13579\n        }\n    ]\n\n    all_results_formatted = []\n    for case in test_cases:\n        result_floats = perform_bootstrap_analysis(case[\"data\"], case[\"B\"], case[\"seed\"])\n        # Format each number to 6 decimal places and create the sublist string.\n        formatted_list = [f\"{x:.6f}\" for x in result_floats]\n        all_results_formatted.append(f\"[{','.join(formatted_list)}]\")\n    \n    # Join all sublist strings into the final required format.\n    final_output = f\"[{','.join(all_results_formatted)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "3221310"}]}