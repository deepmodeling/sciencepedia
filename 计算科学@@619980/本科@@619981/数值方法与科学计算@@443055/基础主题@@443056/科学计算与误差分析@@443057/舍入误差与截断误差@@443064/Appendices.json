{"hands_on_practices": [{"introduction": "我们从一个看似简单的任务开始：计算小$x$值下的双曲正弦函数$\\sinh(x)$。这个练习将揭示一个常见的数值计算陷阱，即“灾难性抵消”（catastrophic cancellation）。通过亲手实践，你将直观地比较直接套用定义公式所产生的舍入误差，与使用泰勒级数近似所引入的截断误差，从而深刻理解为何数学上等价的公式在计算机中的表现可能天差地别 [@problem_id:3268991]。", "problem": "考虑由恒等式 $\\,\\sinh(x) = \\dfrac{e^{x} - e^{-x}}{2}\\,$ 定义的双曲正弦函数，及其麦克劳林级数，后者是解析函数通用泰勒级数的一种特殊情况。麦克劳林级数是通过在原点求导并对所得各项求和来构建的。对于足够小的 $\\,x\\,$，通常使用一阶截断 $\\,\\sinh(x) \\approx x\\,$，这会因舍弃高阶项而引入截断误差。在采用电气和电子工程师协会（IEEE）754浮点数标准的有限精度算术的数字计算机中，计算 $\\,e^{x}\\,$ 和 $\\,e^{-x}\\,$ 的每一步操作都会进行舍入。当对较小的 $\\,x\\,$ 通过 $\\,\\dfrac{e^{x} - e^{-x}}{2}\\,$ 来计算 $\\,\\sinh(x)\\,$ 时，两个几乎相等的数相减可能会因灾难性抵消而放大舍入误差。您的任务是通过直接计算，对几个代表性输入量化截断误差和舍入误差之间的相互影响。\n\n实现一个程序，对下面指定的测试套件中的每个输入 $\\,x\\,$，计算 $\\,\\sinh(x)\\,$ 的三种数值近似，并报告它们与在浮点算术中计算的高质量参考值相比的相对误差：\n- 直接公式 $\\,\\dfrac{e^{x} - e^{-x}}{2}\\,$（该公式在 $\\,x\\,$ 较小时容易受到抵消效应的影响）。\n- 一种数值改进的公式，它通过使用函数 $\\,\\operatorname{expm1}(x) = e^{x} - 1\\,$ 来计算 $\\,\\dfrac{\\operatorname{expm1}(x) - \\operatorname{expm1}(-x)}{2}\\,$，从而减少抵消效应。\n- 一阶泰勒近似 $\\,x\\,$。\n\n使用 $\\,\\sinh(x)\\,$ 在浮点算术中的数值稳定实现作为参考值（例如，一个经过充分测试的库实现）。对于每种近似 $\\,y_{\\text{approx}}\\,$ 和参考值 $\\,y_{\\text{ref}}\\,$，计算相对误差 $\\,E = \\dfrac{|y_{\\text{approx}} - y_{\\text{ref}}|}{|y_{\\text{ref}}|}\\,$。如果 $\\,y_{\\text{ref}} = 0\\,$，则报告绝对误差 $\\,E = |y_{\\text{approx}} - 0|\\,$ 以避免除以零。\n\n测试套件：\n- $\\,x = 10^{-9}\\,$\n- $\\,x = 10^{-16}\\,$\n- $\\,x = 10^{-1}\\,$\n- $\\,x = 0\\,$\n- $\\,x = -10^{-9}\\,$\n- $\\,x = 20\\,$\n\n覆盖性设计：\n- 情况 $\\,x = 10^{-9}\\,$ 用于测试小参数，此时灾难性抵消会影响直接公式，而截断误差很小。\n- 情况 $\\,x = 10^{-16}\\,$ 用于探测双精度机器ε附近的数值行为，此时抵消效应会加剧。\n- 情况 $\\,x = 10^{-1}\\,$ 是一个中等大小的参数，此时截断误差和舍入误差都较小。\n- 情况 $\\,x = 0\\,$ 作为一个边界条件，此时 $\\,\\sinh(0) = 0\\,$。\n- 情况 $\\,x = -10^{-9}\\,$ 用于检查奇对称性和符号处理。\n- 情况 $\\,x = 20\\,$ 代表一个大参数，此时抵消效应可以忽略不计，指数增长占主导地位。\n\n最终输出格式：\n您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。对于测试套件中按给定顺序排列的每个 $\\,x\\,$，依次附加三个浮点数：用于直接公式的 $\\,E_{\\text{naive}}\\,$，用于改进的基于 $\\,\\operatorname{expm1}\\,$ 的公式的 $\\,E_{\\text{stable}}\\,$，以及用于一阶泰勒近似的 $\\,E_{\\text{taylor}}\\,$。最终输出是一个包含 $\\,18\\,$ 个条目的扁平列表，对应 $\\,6\\,$ 个测试输入，每个输入有 $\\,3\\,$ 个误差值，例如 $\\,\\big[ E_{\\text{naive}}(10^{-9}), E_{\\text{stable}}(10^{-9}), E_{\\text{taylor}}(10^{-9}), \\ldots \\big]\\,$。所有输出必须是无量纲的实数（浮点数）。", "solution": "该问题要求对双曲正弦函数 $\\sinh(x)$ 计算中的数值误差进行定量分析。该分析将三种不同方法与一个高精度参考值进行比较。所考虑的两个主要误差来源是舍入误差和截断误差，前者源于浮点运算的有限精度，后者源于用有限项近似无限级数。\n\n该函数定义为：\n$$\n\\sinh(x) = \\frac{e^x - e^{-x}}{2}\n$$\n其麦克劳林级数展开为：\n$$\n\\sinh(x) = x + \\frac{x^3}{3!} + \\frac{x^5}{5!} + \\frac{x^7}{7!} + \\dots = \\sum_{n=0}^{\\infty} \\frac{x^{2n+1}}{(2n+1)!}\n$$\n该级数对所有实数 $x$ 收敛。\n\n我们的方法论涉及使用三种不同的近似方法为一组给定的输入值 $x$ 计算 $\\sinh(x)$。然后，我们将计算每种近似相对于一个参考值 $y_{\\text{ref}}$ 的误差，该参考值从一个数值稳健的库实现（`numpy.sinh`）中获得。对于一个近似值 $y_{\\text{approx}}$，其相对误差 $E$ 定义为：\n$$\nE = \\frac{|y_{\\text{approx}} - y_{\\text{ref}}|}{|y_{\\text{ref}}|}\n$$\n在 $y_{\\text{ref}} = 0$ 的特殊情况下，除以零是未定义的。对于这种情况，我们将按规定计算绝对误差 $E = |y_{\\text{approx}} - y_{\\text{ref}}|$。\n\n待评估的三种近似方法是：\n\n$1$。**朴素直接公式 ($y_{\\text{naive}}$)**：\n该方法直接使用定义恒等式：\n$$\ny_{\\text{naive}} = \\frac{e^x - e^{-x}}{2}\n$$\n对于接近 $0$ 的 $x$ 值，$e^x \\approx 1 + x$ 且 $e^{-x} \\approx 1 - x$。因此，$e^x$ 和 $e^{-x}$ 成为两个几乎相等的数。在有限精度运算中，这两个数相减会导致一种称为灾难性抵消的现象。前导的有效数字相互抵消，留下的结果由原始数中较不重要的、被舍入的部分主导。这会有效地放大相对舍入误差，导致严重的精度损失。\n\n$2$。**数值稳定公式 ($y_{\\text{stable}}$)**：\n该方法重新构造表达式以避免灾难性抵消。它利用标准库函数 $\\operatorname{expm1}(x) = e^x - 1$，该函数即使在 $|x| \\ll 1$ 时也能精确计算其结果。$\\sinh(x)$ 的公式被重写为：\n$$\ny_{\\text{stable}} = \\frac{\\operatorname{expm1}(x) - \\operatorname{expm1}(-x)}{2}\n$$\n在数学上，这等同于朴素公式，因为 $(\\operatorname{expm1}(x) - \\operatorname{expm1}(-x)) / 2 = ((e^x-1) - (e^{-x}-1))/2 = (e^x - e^{-x})/2$。然而，在数值上，对于小的 $|x|$，它更优越。当 $x$ 很小时，$\\operatorname{expm1}(x) \\approx x$ 且 $\\operatorname{expm1}(-x) \\approx -x$。此时减法运算为 $\\operatorname{expm1}(x) - \\operatorname{expm1}(-x) \\approx x - (-x) = 2x$。该操作不涉及几乎相等的数相减，因此保留了数值精度。\n\n$3$。**一阶泰勒近似 ($y_{\\text{taylor}}$)**：\n该方法使用 $\\sinh(x)$ 的麦克劳林级数的第一项：\n$$\ny_{\\text{taylor}} = x\n$$\n该近似通过省略级数中从 $\\frac{x^3}{3!}$ 开始的所有高阶项来引入截断误差。截断误差约等于第一个被忽略的项，即 $\\frac{x^3}{6}$。因此，相对截断误差近似为：\n$$\n\\frac{|\\frac{x^3}{6}|}{|\\sinh(x)|} \\approx \\frac{|x^3/6|}{|x|} = \\frac{x^2}{6} \\quad \\text{对于小的 } x \\neq 0\n$$\n此误差是数学近似本身固有的，并且独立于浮点表示，尽管其最终计算值会受到舍入的影响。该近似仅对非常接近 $0$ 的 $x$ 值是准确的。\n\n提供的测试套件旨在展示这些误差在不同范围内的行为：\n- 对于小的 $|x|$（例如，$10^{-9}$ 和 $10^{-16}$），我们预计由于灾难性抵消，$y_{\\text{naive}}$ 会表现出较大误差，而 $y_{\\text{stable}}$ 应该非常精确。$y_{\\text{taylor}}$ 的截断误差将非常小，使其也成为一个很好的近似。\n- 对于像 $10^{-1}$ 这样的中等 $x$ 值，抵消问题不大，因此 $y_{\\text{naive}}$ 会更精确。然而，$y_{\\text{taylor}}$ 的截断误差（$x^2/6 \\approx (10^{-1})^2/6 \\approx 1.6 \\times 10^{-3}$）将变得显著。\n- 对于像 $20$ 这样的大 $x$ 值，$e^x$ 非常大而 $e^{-x}$ 非常小。不存在抵消问题，因此 $y_{\\text{naive}}$ 和 $y_{\\text{stable}}$ 预计表现同样出色。相比之下，$y_{\\text{taylor}} = 20$ 对于 $\\sinh(20) \\approx 2.4 \\times 10^8$ 是一个很差的近似，导致很大的误差。\n- 对于 $x=0$，所有三种方法都应得到精确结果 $0$，从而误差为零。\n\n程序将执行这些计算并报告误差，从而清晰、定量地阐释数值分析的这些基本原理。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes numerical errors for three different approximations of sinh(x)\n    for a given test suite of x values.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    # Use numpy.float64 for consistent high-precision floating-point arithmetic.\n    test_cases = [\n        np.float64(1e-9),\n        np.float64(1e-16),\n        np.float64(1e-1),\n        np.float64(0.0),\n        np.float64(-1e-9),\n        np.float64(20.0),\n    ]\n\n    results = []\n\n    def calculate_error(y_approx, y_ref):\n        \"\"\"\n        Calculates relative error, or absolute error if the reference is zero.\n        \"\"\"\n        if y_ref == 0.0:\n            # For y_ref = 0, use absolute error to avoid division by zero.\n            return np.abs(y_approx - y_ref)\n        else:\n            # Otherwise, use relative error.\n            return np.abs(y_approx - y_ref) / np.abs(y_ref)\n\n    for x in test_cases:\n        # 1. Compute the high-quality reference value using the library function.\n        y_ref = np.sinh(x)\n\n        # 2. Compute the three approximations.\n        \n        # Naive formula: susceptible to catastrophic cancellation for small x.\n        y_naive = (np.exp(x) - np.exp(-x)) / 2.0\n        \n        # Stable formula: uses expm1 to avoid cancellation for small x.\n        # np.expm1(x) computes exp(x) - 1 with high precision for small x.\n        y_stable = (np.expm1(x) - np.expm1(-x)) / 2.0\n        \n        # First-order Taylor approximation: introduces truncation error.\n        y_taylor = x\n        \n        # 3. Calculate and store the errors for each approximation.\n        e_naive = calculate_error(y_naive, y_ref)\n        e_stable = calculate_error(y_stable, y_ref)\n        e_taylor = calculate_error(y_taylor, y_ref)\n        \n        results.extend([e_naive, e_stable, e_taylor])\n\n    # Final print statement in the exact required format.\n    # map(str, results) converts all float results to their string representations.\n    # ','.join(...) joins them into a single comma-separated string.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3268991"}, {"introduction": "在理解了灾难性抵消的基本概念后，我们将探讨它在更复杂的算法——泰勒级数求和——中的影响。本练习以计算$e^{-x}$为例，要求你比较不同求和顺序（正向与反向）以及一种替代计算策略的数值稳定性。通过这个实践，你将深入了解算法结构如何能够放大或抑制舍入误差，尤其是在中间项远大于最终结果的情况下 [@problem_id:3268948]。", "problem": "开发一个程序，当计算指数函数在大的负自变量处的值时，数值上演示舍入误差和截断误差之间的相互作用。完全在双精度浮点运算（由语言运行时和标准库提供的 IEEE 754 binary64）中进行。使用以下基本依据：指数函数的泰勒级数定义、每次操作具有有界相对误差的标准浮点舍入模型，以及交错级数余项界。你的任务是研究近似计算 $e^{-x}$ 的不同计算策略的稳定性。\n\n从以下基本定义和事实开始：\n- 对于任意实数 $x$，指数函数在 0 点的泰勒级数展开为：\n$$e^{x} = \\sum_{k=0}^{\\infty} \\frac{x^{k}}{k!}.$$\n- 浮点舍入模型可以抽象为 $fl(a \\circ b) = (a \\circ b)(1 + \\delta)$，其中对于单个二元运算 $\\circ$（加、减、乘或除），$|\\delta| \\leq u$，而单位舍入 $u$ 是该算术的特征。\n- 对于一个交错级数 $\\sum_{k=0}^{\\infty} (-1)^{k} a_{k}$，其中 $a_{k} \\ge 0$ 且单调递减至 0，其前 $K$ 项之后的截断误差的绝对值由被舍去的第一项为界：\n$$\\left|\\sum_{k=0}^{\\infty} (-1)^{k} a_{k} - \\sum_{k=0}^{K} (-1)^{k} a_{k}\\right| \\le a_{K+1}.$$\n\n设计一个算法，通过对 $e^{-x}$ 的泰勒级数求和来近似计算 $e^{-x}$，\n$$e^{-x} = \\sum_{k=0}^{\\infty} \\frac{(-x)^{k}}{k!},$$\n使用项的递推关系\n$$t_{0} = 1,\\quad t_{k+1} = t_{k} \\cdot \\frac{-x}{k+1},\\quad k \\ge 0,$$\n以及一个截断规则，该规则在下一项的量值满足 $|t_{k}| \\le \\tau_{\\text{abs}}$ 时停止，其中 $\\tau_{\\text{abs}}$ 是一个预设的绝对容差。一旦各项进入递减阶段，该截断规则可由交错级数界来证明其合理性。使用两种累加顺序：\n- 正向求和：从 $k=0$ 开始，按 $k$ 递增的顺序加总各项。\n- 反向求和：首先生成所有满足停止准则的项，然后按 $k$ 递减的顺序将它们加总至 $k=0$。\n\n同时考虑通过计算 $e^x$ 的倒数来计算 $e^{-x}$ 的替代策略：\n$$e^{-x} = \\frac{1}{e^{x}},$$\n使用标准库函数计算 $e^x$，然后进行一次除法运算。\n\n为了进行数值评估，将参考值定义为运行时的库函数值 $e_{\\text{ref}} = \\exp(-x)$，并将近似值 $\\widehat{e^{-x}}$ 的相对误差报告为\n$$\\mathrm{rel\\_err} = \\frac{|\\widehat{e^{-x}} - e_{\\text{ref}}|}{|e_{\\text{ref}}|}.$$\n\n实现一个单一程序，执行以下测试套件，每个测试返回一个等于 $\\mathrm{rel\\_err}$ 的浮点值：\n- 测试 A (灾难性抵消目标)：$x = 25$，通过绝对容差为 $\\tau_{\\text{abs}} = 10^{-30}$ 的正向泰勒求和计算 $e^{-x}$。\n- 测试 B (稳定的倒数法)：$x = 25$，使用标准库将 $e^{-x}$ 计算为 $1/\\exp(x)$。\n- 测试 C (良性级数)：$x = 1$，通过绝对容差为 $\\tau_{\\text{abs}} = 10^{-30}$ 的正向泰勒求和计算 $e^{-x}$。\n- 测试 D (缓解的抵消)：$x = 25$，通过绝对容差为 $\\tau_{\\text{abs}} = 10^{-30}$ 的反向泰勒求和计算 $e^{-x}$。\n\n你的程序必须：\n- 使用上述项的递推关系以避免中间计算 $k!$ 或 $x^k$ 时发生溢出。\n- 通过使用 $\\tau_{\\text{abs}} = 10^{-30}$ 来确保截断误差相对于所研究的现象是可忽略的。\n- 对每个测试，使用来自标准库、相同浮点精度的参考值 $e_{\\text{ref}} = \\exp(-x)$ 来计算并返回相对误差。\n\n最终输出格式：\n- 你的程序应产生单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，“[resultA,resultB,resultC,resultD]”），结果的顺序必须与上面定义的 A、B、C、D 完全一致。结果必须是浮点数。\n\n科学真实性与适用性：\n- 此设置通过交错级数界分离了截断误差，并展示了由于灾难性抵消而产生的舍入效应。当 $x=25$ 时，对大的交错项求和时会发生这种情况，因为这些项的绝对值之和远大于微小的最终结果。相比之下，倒数策略避免了这种由减法引起的有效数字损失。", "solution": "该问题要求开发并分析三种不同的数值方法，用于对正自变量 $x$ 的指数函数 $e^{-x}$ 进行近似计算。问题的核心在于展示两种基本数值误差类型的实际后果：截断误差和舍入误差。我们将在标准的双精度浮点运算框架（IEEE 754）内操作。\n\n需要近似的函数是 $e^{-x}$，其在 0 点的泰勒级数展开为：\n$$e^{-x} = \\sum_{k=0}^{\\infty} \\frac{(-x)^{k}}{k!} = 1 - x + \\frac{x^2}{2!} - \\frac{x^3}{3!} + \\dots$$\n对于 $x>0$，这是一个交错级数。设 $t_k = \\frac{(-x)^k}{k!}$ 为第 $k$ 项。为避免计算可能导致溢出的大阶乘和幂，我们使用稳定的递推关系：\n$$t_0 = 1, \\quad t_{k+1} = t_k \\cdot \\frac{-x}{k+1} \\quad \\text{for } k \\ge 0.$$\n\n必须考虑两种主要的误差来源：\n1. **截断误差**：这种误差源于用有限和来近似无限级数。如果我们截断级数的前 $K$ 项，截断误差 $E_{\\text{trunc}}$ 为余项：\n$$E_{\\text{trunc}} = \\sum_{k=K+1}^{\\infty} \\frac{(-x)^{k}}{k!}.$$\n对于一个交错级数，如果其各项的量值 $|t_k| = \\frac{x^k}{k!}$ 最终单调递减至零，则截断误差的绝对值小于等于被舍去的第一项的绝对值。也就是说，对于足够大的 $K$，$|\\sum_{k=K+1}^{\\infty} t_k| \\le |t_{K+1}|$。问题指定了基于绝对容差 $\\tau_{\\text{abs}} = 10^{-30}$ 的停止准则：当 $|t_k|$ 小于此值时，我们停止求和。该容差远小于双精度的机器精度（$u \\approx 2.22 \\times 10^{-16}$），从而确保截断误差在设计上相对于我们希望研究的舍入误差是可以忽略的。\n\n2. **舍入误差**：这种误差是浮点运算所固有的。每次算术运算都受到舍入的影响，其模型为 $fl(a \\circ b) = (a \\circ b)(1 + \\delta)$，其中 $|\\delta| \\leq u$。在对级数求和时，这些小误差会累积。一种特别有害的舍入误差形式是**灾难性抵消**，它发生在两个几乎相等的数相减时。开头的有效数字相互抵消，结果由先前计算产生的噪声主导，导致相对精度的大量损失。\n\n我们将根据这些误差来源分析以下三种计算策略。计算相对误差的参考值将是 $e_{\\text{ref}} = \\exp(-x)$，由标准库中高度优化的函数计算得出。相对误差为 $\\mathrm{rel\\_err} = |\\widehat{e^{-x}} - e_{\\text{ref}}| / |e_{\\text{ref}}|$。\n\n**测试 A：对 $x=25$ 进行正向泰勒求和**\n该算法按自然顺序对各项求和：$S_N = \\sum_{k=0}^{N} t_k$。对于 $x=25$，项 $\\frac{(-25)^k}{k!}$ 的量值最初增长得非常大。最大量值出现在 $k \\approx x = 25$ 附近。例如，$|t_{24}| = \\frac{25^{24}}{24!} \\approx 1.00 \\times 10^{11}$ 且 $|t_{25}| = \\frac{25^{25}}{25!} \\approx 1.00 \\times 10^{11}$。我们将这些巨大的数字相加减，最终得到一个非常小的结果，$e^{-25} \\approx 1.39 \\times 10^{-11}$。在浮点运算中，和 $S_k = S_{k-1} + t_k$ 将涉及数量级差异巨大的数字。更关键的是，当 $k$ 足够大时，$S_k$ 是两个巨大且几乎相等的数之差，这是灾难性抵消的教科书式定义。双精度约 16 位十进制数字的有限精度意味着结果将几乎没有，甚至完全没有正确的有效数字。预计会产生非常大的相对误差。\n\n**测试 C：对 $x=1$ 进行正向泰勒求和**（为便于比较而打乱顺序分析）\n在这种情况下，项为 $t_k = \\frac{(-1)^k}{k!}$。量值 $|t_k|$ 从一开始就单调递减：$1, 1, 0.5, 0.166...$ 等。和收敛于 $e^{-1} \\approx 0.368$。在任何时候，我们都不会为了得到一个小结果而加减大数。部分和永远不会增长到比最终结果大很多。灾难性抵消不会发生。主要误差来源将是每次加法产生的标准舍入误差的平缓累积以及可忽略的截断误差。预计会得到一个非常低的、接近机器精度的相对误差。\n\n**测试 D：对 $x=25$ 进行反向泰勒求和**\n该策略首先计算并存储所有需要的项 $t_0, t_1, \\dots, t_K$ 以满足截断容差。然后以相反的顺序进行求和：$S = t_K + t_{K-1} + \\dots + t_0$。这是一种减小舍入误差累积的标准技术。求和从最小的项开始相加。这使得部分和在与较大量值的项相加之前能够累积精度。虽然该方法没有消除减去大数（$t_{24}$ 和 $t_{25}$ 仍然在列表中）的基本问题，但它以一种不易受到信息即时损失影响的方式组织了运算，而信息即时损失在正向求和中，当一个小项加到一个大的运行和上时会发生。结果应显著比正向求和更精确，但可能不如完全避免抵消的方法精确。\n\n**测试 B：对 $x=25$ 使用倒数法**\n该方法将 $e^{-x}$ 计算为 $1/e^x$。标准库中的 $e^x$ 函数是高度优化的。对于大的正自变量如 $x=25$，它不会遭受抵消问题，因为其级数展开中的所有项都是正的。库例程将以接近机器精度的水平计算 $e^{25}$。随后的单次除法运算最多引入一个额外的单位舍入。该方法完全回避了困扰直接泰勒级数求值的灾难性抵消问题。这是数值上稳定且首选的方法。预期相对误差应该非常小，在机器精度的量级上。\n\n程序将实现这四个测试并报告产生的相对误差，从而为这些原理提供一个清晰的数值演示。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef forward_taylor_sum(x, tol):\n    \"\"\"\n    Computes exp(-x) using forward summation of the Taylor series.\n    \n    Args:\n        x (float): The argument to the exponential function.\n        tol (float): The absolute tolerance for the stopping criterion.\n        \n    Returns:\n        float: The approximation of exp(-x).\n    \"\"\"\n    total_sum = 0.0\n    term = 1.0  # t_0\n    k = 0\n    while abs(term) > tol:\n        total_sum += term\n        k += 1\n        term = term * (-x) / k\n    # Add the last term that was computed but failed the while condition\n    total_sum += term\n    return total_sum\n\ndef backward_taylor_sum(x, tol):\n    \"\"\"\n    Computes exp(-x) using backward summation of the Taylor series.\n    \n    Args:\n        x (float): The argument to the exponential function.\n        tol (float): The absolute tolerance for the stopping criterion.\n        \n    Returns:\n        float: The approximation of exp(-x).\n    \"\"\"\n    terms = []\n    term = 1.0  # t_0\n    k = 0\n    while abs(term) > tol:\n        terms.append(term)\n        k += 1\n        term = term * (-x) / k\n    # Add the last term that was computed but failed the while condition\n    terms.append(term)\n    \n    # Sum in reverse order\n    total_sum = 0.0\n    for t in reversed(terms):\n        total_sum += t\n    return total_sum\n    \ndef reciprocal_method(x):\n    \"\"\"\n    Computes exp(-x) as 1.0 / exp(x) using the standard library function.\n    \n    Args:\n        x (float): The argument to the exponential function.\n        \n    Returns:\n        float: The approximation of exp(-x).\n    \"\"\"\n    return 1.0 / np.exp(x)\n\ndef solve():\n    \"\"\"\n    Runs the full test suite and prints the results.\n    \"\"\"\n    # Define the shared parameters\n    x_large = 25.0\n    x_small = 1.0\n    tolerance = 1e-30\n    \n    results = []\n\n    # Test A: Catastrophic cancellation target\n    ref_A = np.exp(-x_large)\n    approx_A = forward_taylor_sum(x_large, tolerance)\n    rel_err_A = abs(approx_A - ref_A) / abs(ref_A)\n    results.append(rel_err_A)\n\n    # Test B: Stable reciprocal\n    ref_B = np.exp(-x_large)\n    approx_B = reciprocal_method(x_large)\n    rel_err_B = abs(approx_B - ref_B) / abs(ref_B)\n    results.append(rel_err_B)\n    \n    # Test C: Benign series\n    ref_C = np.exp(-x_small)\n    approx_C = forward_taylor_sum(x_small, tolerance)\n    rel_err_C = abs(approx_C - ref_C) / abs(ref_C)\n    results.append(rel_err_C)\n\n    # Test D: Mitigated cancellation\n    ref_D = np.exp(-x_large)\n    approx_D = backward_taylor_sum(x_large, tolerance)\n    rel_err_D = abs(approx_D - ref_D) / abs(ref_D)\n    results.append(rel_err_D)\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3268948"}, {"introduction": "最后的实践环节将解决另一个普遍存在的问题：对大量数值求和时微小误差的累积。你将实现并测试一种巧妙的算法——Kahan补偿求和法，它能“记住”每一步加法中丢失的微小精度并进行补偿。这个练习展示了一种在有限精度算术中获得高精度求和结果的强大通用技术，是数值计算工具箱中的重要一员 [@problem_id:3268973]。", "problem": "你需要设计并实现一个实验，以量化并比较两种浮点数求和策略（朴素循环和补偿求和（Kahan 算法））所产生的舍入误差。你必须在与电气与电子工程师协会（IEEE）754 双精度标准一致的浮点数算术模型中工作，该标准由标准 Python 浮点数实现。请使用以下基本依据：\n- 浮点舍入模型：每个基本运算执行为 $fl(a \\circ b) = (a \\circ b)(1 + \\delta)$，其中 $|\\delta| \\leq u$，$u$ 是单位舍入误差。\n- 对于基数 $\\beta = 2$ 和精度 $p = 53$（IEEE 754 双精度），$u = \\tfrac{1}{2}\\beta^{1-p} = 2^{-53}$。\n- 绝对误差定义为 $| \\widehat{S} - S |$，其中 $S$ 是精确的实数结果，$\\widehat{S}$ 是计算出的浮点结果。\n\n你的程序必须：\n- 实现两个针对序列 $(x_i)$ 的求和例程：\n  1. 一个朴素循环，按给定顺序累加 $s \\leftarrow s + x_i$。\n  2. 一个补偿求和（Kahan）循环，使用一个补偿变量来捕获因舍入而丢失的低位比特，维护一个运行时对 $(s,c)$，其中 $s$ 是运行时和，$c$ 是补偿值。除了指定的环境外，不要使用任何外部库。\n- 对于下述每个测试用例，计算两种方法相对于精确实数和的绝对误差，使用高精度十进制算术来表示精确值 $S$ 并评估 $|\\widehat{S} - S|$。将输入中的数学常数视为精确的实数（例如，将字符串“0.1”解释为精确的有理数 $1/10$）。\n- 为每个测试报告补偿求和的绝对误差是否小于或等于朴素循环的绝对误差。因此，每个测试的结果必须是一个布尔值。\n\n重要说明：\n- 本任务只研究舍入误差。本问题中的级数是有限的，在精确算术中可以精确求和，因此所有测试用例中的截断误差均为 $0$。你的分析和实现应明确区分舍入误差（由于有限精度）和截断误差（由于近似无限或连续过程）。\n- 本问题不涉及角度和物理单位。\n- 使用编程语言的原生布尔字面量表示布尔输出。\n\n需要实现和评估的测试套件：\n- 情况 A（大相同加数的求和）：对级数 $\\sum_{i=1}^{10^7} 0.1$ 求和。精确值为 $10^6$。验证补偿求和的绝对误差是否小于或等于朴素循环的绝对误差。\n- 情况 B（短列表中的灾难性抵消）：按顺序对列表 $[10^{16}, 1, -10^{16}]$ 求和。精确值为 $1$。验证补偿求和的绝对误差是否小于或等于朴素循环的绝对误差。\n- 情况 C（零序列健全性检查）：对列表 $[0, 0, 0]$ 求和。精确值为 $0$。验证补偿求和的绝对误差是否小于或等于朴素循环的绝对误差。\n- 情况 D（许多微小相同加数的求和）：对级数 $\\sum_{i=1}^{10^6} 10^{-10}$ 求和。精确值为 $10^{-4}$。验证补偿求和的绝对误差是否小于或等于朴素循环的绝对误差。\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含四个布尔结果，按 [情况 A, 情况 B, 情况 C, 情况 D] 的顺序，以逗号分隔并用方括号括起来（例如，“[True,False,True,True]”）。", "solution": "用户要求分析和实现两种求和算法——朴素求和与补偿（Kahan）求和——以比较它们对舍入误差的敏感性。该问题是有效的，科学上基于数值分析原理，并且是适定 (well-posed) 的。它要求实现一个计算实验并报告结果。\n\n这个问题的核心在于浮点数算术的有限精度。实数的标准计算机表示法，例如 Python 的 `float` 类型所使用的 IEEE 754 双精度格式，其比特数是有限的。这种限制意味着大多数实数无法被精确表示，并且算术运算会引入微小的误差。\n\n**浮点数算术与舍入误差**\n\n我们在浮点数算术的标准模型内操作。对于任意实数 $a$ 和 $b$ 以及算术运算 $\\circ \\in \\{+, -, \\times, \\div\\}$，计算出的浮点结果（表示为 $fl(a \\circ b)$）由以下公式给出：\n$$\nfl(a \\circ b) = (a \\circ b)(1 + \\delta)\n$$\n其中 $|\\delta| \\leq u$。常数 $u$ 是单位舍入误差，或称为机器 epsilon。对于 IEEE 754 双精度，基数是 $\\beta=2$，精度（有效数位数，包括隐含的前导比特）是 $p=53$。单位舍入误差定义为 $u = \\frac{1}{2}\\beta^{1-p} = 2^{-53}$，约等于 $1.11 \\times 10^{-16}$。\n\n这个模型意味着每次基本运算都可能引入一个小的相对误差。在对一长串数字求和时，这些小误差会累积起来，导致计算出的和与真实的数学和之间产生显著差异。本问题要求我们通过比较两种算法来研究这一现象。请注意，由于所有求和都是针对有限数量的项，截断误差（由有限过程近似无限过程产生的误差）为零。我们只关心舍入误差。\n\n**算法1：朴素求和**\n\n这是最直接的求和方法。给定一个数字序列 $x_1, x_2, \\ldots, x_N$，和 $S_N = \\sum_{i=1}^N x_i$ 通过迭代计算得出。\n\n设 $\\widehat{S}_k$ 为 $k$ 项后的计算和。算法如下：\n1. 初始化运行时和：$\\widehat{S}_0 = 0$。\n2. 对于 $i = 1, \\ldots, N$，更新和：$\\widehat{S}_i = fl(\\widehat{S}_{i-1} + x_i)$。\n\n主要误差源发生在将一个数 $x_i$ 加到一个数量级大得多的运行时和 $\\widehat{S}_{i-1}$ 上时。为了执行加法，浮点单元必须通过将较小数的有效数向右移位来对齐两个数的二进制小数点。这可能导致较小数的低位比特完全移出表示范围，从而实际上丢失。这些丢失的信息就是该步骤的舍入误差，并且永远不会被恢复。经过多次加法，这种误差会累积起来，通常是以一种系统性的方式，最终导致较大的最终误差。\n\n**算法2：补偿求和（Kahan 算法）**\n\nKahan 算法是一种旨在减轻舍入误差累积的精巧技术。它维护第二个变量，即*补偿值* $c$，该变量追踪每次加法中“丢失”的低位部分。这个被捕获的误差随后在下一步中被重新纳入总和。\n\n算法如下，维护一个运行时和 $s$ 和一个补偿值 $c$：\n1. 初始化和与补偿值：$s \\leftarrow 0$, $c \\leftarrow 0$。\n2. 对于序列中的每一项 $x_i$：\n   a. 用先前的误差校正下一项：$y \\leftarrow x_i - c$。\n   b. 将校正后的项加到和中。这里会引入一个新的小误差：$t \\leftarrow s + y$。\n   c. 计算上一步的误差：$c \\leftarrow (t - s) - y$。在精确算术中，这个结果应为 $0$。在浮点数算术中，这个计算分离出了当 $y$ 加到 $s$ 时丢失的低位比特。\n   d. 更新和：$s \\leftarrow t$。\n\n最终结果是遍历所有项后 $s$ 的值。通过在 $c$ 中追踪误差并用它来校正下一项，该算法防止了舍入误差的系统性累积。Kahan 求和的误差界显著优于朴素求和，并且值得注意的是，它与项数 $N$ 无关。\n\n**测试用例分析**\n\n为了找到绝对误差 $|\\widehat{S} - S|$，我们需要精确的和 $S$。按照指示，我们使用高精度算术来计算，将输入视为精确的有理数（例如，将 $0.1$ 视为 $1/10$）。\n\n- **情况 A：对 $\\sum_{i=1}^{10^7} 0.1$ 求和。精确和 $S = 10^6$。**\n数字 $0.1$ 的二进制表示是无限循环的（$0.000110011..._2$），因此无法作为标准浮点数被精确存储。每次将不精确的 `float(0.1)` 加到不断增长的和中都会引入一个小的误差。经过 $10^7$ 次加法，朴素求和会累积显著的误差。Kahan 算法正是为这种情况设计的；补偿变量 $c$ 会捕获每一步中丢失的微小部分并将其重新引入，从而得到一个精确得多的最终结果。因此，Kahan 求和的误差将小于或等于朴素循环的误差。\n\n- **情况 B：对 $[10^{16}, 1, -10^{16}]$ 求和。精确和 $S = 1$。**\n这个例子展示了灾难性抵消。\n在朴素求和中，第一个操作是 $10^{16} + 1$。由于双精度浮点数的精度约为 16 个十进制位，而 $1$ 比 $10^{16}$ 小 16 个数量级，因此加法结果仍为 $10^{16}$。数字 $1$ 因舍入而完全丢失（这种现象被称为“淹没”(swamping)）。下一步操作是 $10^{16} - 10^{16} = 0$。朴素求和的结果是 $0.0$，误差为 $1$。\nKahan 算法能够检测并纠正这个问题。在计算 $t \\leftarrow s + y = 10^{16} + 1 \\approx 10^{16}$ 之后，补偿步骤为 $c \\leftarrow (t - s) - y = (10^{16} - 10^{16}) - 1 = -1$。算法“记住”了 $1$ 被丢失了。在下一步中，这个丢失的部分被用来校正项 $-10^{16}$，从而得到正确的最终答案 $1$。其误差将小于或等于朴素循环的误差。\n\n- **情况 C：对 $[0, 0, 0]$ 求和。精确和 $S = 0$。**\n这是一个简单的健全性检查。在浮点数算术中，加零是精确操作。朴素循环和 Kahan 算法都会产生精确为 $0$ 的结果，因此两者的绝对误差都将是 $0$。“小于或等于”的条件因相等而成立（$0 \\le 0$）。\n\n- **情况 D：对 $\\sum_{i=1}^{10^6} 10^{-10}$ 求和。精确和 $S = 10^{-4}$。**\n这个场景与情况 A 类似，但使用的是更小的数字。项 $10^{-10}$ 不是 $2$ 的精确幂，因此其浮点表示是不精确的。对 $10^6$ 个这样的不精确值求和会导致舍入误差在朴素求和中累积。虽然误差的量级可能不如情况 A 中严重（因为运行时和与待加项的比率增长得不那么极端），但 Kahan 算法通过在每一步补偿表示误差，仍然会提供一个更精确的结果。其误差将小于或等于朴素循环的误差。\n\n在所有四种情况下，理论分析表明，Kahan 的补偿求和算法的表现将至少与朴素求和循环一样好，并且在大多数情况下显著优于后者。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom decimal import Decimal, getcontext\n\ndef solve():\n    \"\"\"\n    Implements and compares naive and Kahan summation for four test cases,\n    reporting if Kahan summation provides an error less than or equal to\n    naive summation.\n    \"\"\"\n    \n    # Set precision for Decimal calculations to ensure it's high enough.\n    getcontext().prec = 50\n\n    def naive_sum(numbers):\n        \"\"\"Computes the sum of a sequence using a naive iterative loop.\"\"\"\n        s = 0.0\n        for x in numbers:\n            s += x\n        return s\n\n    def kahan_sum(numbers):\n        \"\"\"Computes the sum of a sequence using Kahan's compensated summation algorithm.\"\"\"\n        s = 0.0\n        c = 0.0  # A running compensation for lost low-order bits.\n        for x in numbers:\n            y = x - c             # So far, so good: c is zero.\n            t = s + y             # Alas, s is big, y small, so low-order bits of y are lost.\n            c = (t - s) - y       # (t - s) recovers the high-order part of y; subtracting y extracts the low part.\n            s = t                 # Algebraically, c should be zero. Beware eagerly optimizing compilers!\n        return s\n\n    def run_test(sequence_generator, exact_sum_decimal):\n        \"\"\"\n        Runs a single test case for both summation methods and compares their absolute errors.\n        \n        Args:\n            sequence_generator: A lambda function that generates the sequence of floats for summation.\n            exact_sum_decimal: The exact sum as a high-precision Decimal object.\n            \n        Returns:\n            A boolean indicating if the absolute error of Kahan summation is = the absolute error of naive summation.\n        \"\"\"\n        # Generate the sequence of floating point numbers\n        sequence = list(sequence_generator())\n        \n        # Compute sums using both methods\n        naive_result = naive_sum(sequence)\n        kahan_result = kahan_sum(sequence)\n        \n        # Calculate absolute errors using high-precision Decimal arithmetic\n        err_naive = abs(Decimal(naive_result) - exact_sum_decimal)\n        err_kahan = abs(Decimal(kahan_result) - exact_sum_decimal)\n        \n        return err_kahan = err_naive\n\n    # Define the test cases\n    test_cases = [\n        {\n            \"name\": \"Case A\",\n            \"generator\": lambda: (0.1 for _ in range(10**7)),\n            \"exact_sum\": Decimal(10**7) * Decimal('0.1')\n        },\n        {\n            \"name\": \"Case B\",\n            \"generator\": lambda: [1.0e16, 1.0, -1.0e16],\n            \"exact_sum\": Decimal('1')\n        },\n        {\n            \"name\": \"Case C\",\n            \"generator\": lambda: [0.0, 0.0, 0.0],\n            \"exact_sum\": Decimal('0')\n        },\n        {\n            \"name\": \"Case D\",\n            \"generator\": lambda: (1e-10 for _ in range(10**6)),\n            \"exact_sum\": Decimal(10**6) * Decimal('1e-10')\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_test(case[\"generator\"], case[\"exact_sum\"])\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3268973"}]}