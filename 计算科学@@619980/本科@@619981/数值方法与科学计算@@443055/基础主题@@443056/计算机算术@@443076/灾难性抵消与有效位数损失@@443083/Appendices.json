{"hands_on_practices": [{"introduction": "计算形如 $f(x) = \\sqrt{1+x}-1$ 的函数在 $x$ 值很小时的情况，是数值计算中一个经典问题。直接计算会涉及两个几乎相等的数（$\\sqrt{1+x}$ 和 $1$）相减，这会引发灾难性抵消，导致精度的严重损失。本练习旨在通过对比直接计算与代数等价的稳定形式，让您亲手验证这一现象，并掌握通过代数变换来提高算法稳定性的基本技巧。[@problem_id:3212218]", "problem": "你需要编写一个完整、可运行的程序来研究对于较小的 $x$ 值，计算函数 $f(x)=\\sqrt{1+x}-1$ 的数值稳定性，并比较在有限精度算术下两个代数上等价的公式：\n- 直接相减法：$f_{\\mathrm{dir}}(x) = \\sqrt{1+x} - 1$。\n- 有理化形式：$f_{\\mathrm{rat}}(x) = \\dfrac{x}{\\sqrt{1+x}+1}$。\n\n你的程序必须完成以下任务，仅使用标准的双精度浮点算術进行近似计算，并使用高精度参考值来量化误差。\n\n基本原理和背景：\n- 使用标准的浮点舍入模型：对于一个产生实数结果 $t$ 的实数运算，其计算出的浮点结果是 $\\operatorname{fl}(t)=t(1+\\delta)$，其中 $|\\delta|\\leq u$，$u$ 是单位舍入误差（对于二进制64位，通常称为双精度，大约为 $u\\approx 10^{-16}$）。\n- 认识到减去两个几乎相等的数会导致灾难性抵消（catastrophic cancellation），即许多有效数字会相互抵消，从而可能放大结果中的相对误差。\n- 代数恒等式 $f(x)=\\dfrac{x}{\\sqrt{1+x}+1}$ 在实数算术中对于所有 $x\\geq -1$ 精确成立，并且对于小的 $|x|$ 避免了直接减去两个几乎相等的量。\n\n你的程序必须执行的任务：\n1. 对于下面测试套件中的每个测试值 $x$，计算两个浮点近似值：\n   - $A_{\\mathrm{dir}}=\\operatorname{fl}\\left(\\sqrt{1+x}-1\\right)$，\n   - $A_{\\mathrm{rat}}=\\operatorname{fl}\\left(\\dfrac{x}{\\sqrt{1+x}+1}\\right)$。\n2. 使用至少80位精度的精确实数算术模拟，计算一个高精度参考值 $f_{\\ast}(x)=\\sqrt{1+x}-1$。你不能使用外部文件或网络。如果 $f_{\\ast}(x)=0$，按照惯例将其相对误差定义为 $0$。\n3. 对于每个近似值 $A\\in\\{A_{\\mathrm{dir}},A_{\\mathrm{rat}}\\}$，计算绝对误差 $E_{\\mathrm{abs}}=\\left|A-f_{\\ast}(x)\\right|$ 和相对误差 $E_{\\mathrm{rel}}=\\dfrac{\\left|A-f_{\\ast}(x)\\right|}{\\left|f_{\\ast}(x)\\right|}$（当分母为零时，使用所述的惯例）。\n4. 将每个 $x$ 的结果按此顺序聚合为一个列表 $[E_{\\mathrm{abs}}^{\\mathrm{dir}},E_{\\mathrm{rel}}^{\\mathrm{dir}},E_{\\mathrm{abs}}^{\\mathrm{rat}},E_{\\mathrm{rel}}^{\\mathrm{rat}}]$。\n\n测试套件：\n- 使用以下7个 $x$ 值来探测在不同区间的行为，包括小的正值、零和负值，以及接近双精度抵消阈值的值：\n  - $x\\in\\{10^{-1},\\,10^{-8},\\,10^{-12},\\,10^{-16},\\,0,\\,-10^{-16},\\,-10^{-12}\\}$。\n- 由于所有列出的情况都满足 $x\\geq -1$，所以所有的平方根运算都是对非负参数进行的。\n\n最终输出格式：\n- 你的程序应该生成单行输出，其中包含所有测试用例的结果，形式为以逗号分隔的列表的列表，采用标准编程语言的字面量表示法。第 $k$ 个内部列表必须对应于上面列出的第 $k$ 个测试值 $x$，并且必须按 $[E_{\\mathrm{abs}}^{\\mathrm{dir}},E_{\\mathrm{rel}}^{\\mathrm{dir}},E_{\\mathrm{abs}}^{\\mathrm{rat}},E_{\\mathrm{rel}}^{\\mathrm{rat}}]$ 的顺序排列。\n- 例如，格式应如下所示：$[[e_{11},e_{12},e_{13},e_{14}],[e_{21},e_{22},e_{23},e_{24}],\\dots]$，其中每个 $e_{ij}$ 是一个浮点数。\n- 不涉及物理单位。不要打印任何额外的文本。\n\n科学真实性和推导期望：\n- 需要揭示的现象是，尽管函数 $f(x)$ 在 $x=0$ 附近是良态的（其条件数趋近于 $1$），但由于灾难性抵消，直接相减法 $f_{\\mathrm{dir}}(x)$ 对于小的 $|x|$ 在算法上是不稳定的，而有理化形式 $f_{\\mathrm{rat}}(x)$ 则是数值稳定的。你的代码必须通过报告误差来从数值上证实这一点。", "solution": "该问题要求分析计算函数 $f(x) = \\sqrt{1+x} - 1$ 的两个代数等价公式的数值稳定性，特别是对于接近 $0$ 的 $x$ 值。这两个公式分别是直接求值法 $f_{\\mathrm{dir}}(x) = \\sqrt{1+x} - 1$ 和一个有理化形式 $f_{\\mathrm{rat}}(x) = \\frac{x}{\\sqrt{1+x}+1}$。这种等价性是通过代数变换建立的：\n$$\nf(x) = (\\sqrt{1+x} - 1) \\times \\frac{\\sqrt{1+x}+1}{\\sqrt{1+x}+1} = \\frac{(\\sqrt{1+x})^2 - 1^2}{\\sqrt{1+x}+1} = \\frac{(1+x)-1}{\\sqrt{1+x}+1} = \\frac{x}{\\sqrt{1+x}+1}.\n$$\n该恒等式对所有 $x \\ge -1$ 成立。虽然在数学上是相同的，但它们在有限精度浮点算術下的行为却大不相同，尤其对于小的 $|x|$。这个分析是灾难性抵消的一个经典例证。\n\n问题的核心在于直接计算的公式 $f_{\\mathrm{dir}}(x)$。当 $x$ 趋近于 $0$ 时，项 $\\sqrt{1+x}$ 趋近于 $1$。$\\sqrt{1+x}$ 在 $x=0$ 附近的泰勒级数展开为 $1 + \\frac{1}{2}x - \\frac{1}{8}x^2 + O(x^3)$。因此，对于小的 $|x|$，我们有 $\\sqrt{1+x} \\approx 1 + \\frac{1}{2}x$。因此，减法 $\\sqrt{1+x} - 1$ 变成了两个几乎相等的数相减。\n\n在标准浮点算術中，一个实数 $y$ 被表示为一个有限精度的近似值 $\\operatorname{fl}(y)$。计算过程会引入舍入误差。当我们计算两个几乎相等的数之差 $a-b$（其中 $a \\approx b$）时，其尾数的有效数字会相互抵消。如果原始数字 $a$ 和 $b$ 带有舍入误差，这些原先位于最低有效位的误差，现在会被提升到结果的最高有效位。这种现象被称为灾难性抵消，可能导致相对精度的急剧损失。\n\n让我们对计算 $f_{\\mathrm{dir}}(x)$ 的误差进行建模。首先，$1+x$ 被计算为 $\\operatorname{fl}(1+x) = (1+x)(1+\\delta_1)$。然后计算其平方根：$\\hat{y} = \\operatorname{fl}(\\sqrt{\\operatorname{fl}(1+x)}) \\approx \\sqrt{1+x}(1+\\delta_2)$。最后一步是减法：$A_{\\mathrm{dir}} = \\operatorname{fl}(\\hat{y}-1) \\approx (\\sqrt{1+x}(1+\\delta_2) - 1)(1+\\delta_3)$，其中 $|\\delta_i| \\le u$，$u$ 是单位舍入误差（对于64位双精度，$u \\approx 1.11 \\times 10^{-16}$）。结果的绝对误差大约为 $|A_{\\mathrm{dir}} - f(x)| \\approx |\\sqrt{1+x}\\delta_2| \\approx |\\delta_2|$，因为 $\\sqrt{1+x} \\approx 1$。真实值为 $f(x) \\approx \\frac{1}{2}x$。因此相对误差为\n$$\nE_{\\mathrm{rel}} = \\frac{|A_{\\mathrm{dir}} - f(x)|}{|f(x)|} \\approx \\frac{|\\delta_2|}{|\\frac{1}{2}x|} = \\frac{2|\\delta_2|}{|x|}.\n$$\n由于 $|\\delta_2|$ 可能与单位舍入误差 $u$ 一样大，相对误差可能被一个与 $1/|x|$ 成正比的因子放大。例如，如果 $|x| \\approx u$，相对误差可能接近 $2$，这意味着所有有效数字都已丢失。\n\n相比之下，有理化公式 $f_{\\mathrm{rat}}(x) = \\frac{x}{\\sqrt{1+x}+1}$ 是数值稳定的。对于小的 $|x|$，分母 $\\sqrt{1+x}+1$ 是两个正数相加，这是一个良性运算。分母接近 $2$，所以不会发生抵消。该计算涉及一次平方根、一次加法和一次除法。每个操作都会引入一个量级为单位舍入误差 $u$ 的小相对误差。最终计算出的结果 $A_{\\mathrm{rat}}$ 的相对误差也将是 $u$ 的一个小数倍，而与 $|x|$ 的大小无关。\n\n为了从数值上验证这一分析，我们将实现一个程序，对给定的测试套件中的 $x$ 值 $\\{10^{-1}, 10^{-8}, 10^{-12}, 10^{-16}, 0, -10^{-16}, -10^{-12}\\}$ 进行计算。\n1. 对于每个 $x$，将使用至少80位精度计算一个高精度参考值 $f_*(x)$。这通过使用Python的 `decimal` 模块实现，该模块模拟任意精度算术。这个参考值作为我们衡量误差的“真”值。\n2. 两个近似值 $A_{\\mathrm{dir}} = \\operatorname{fl}(\\sqrt{1+x}-1)$ 和 $A_{\\mathrm{rat}} = \\operatorname{fl}(\\frac{x}{\\sqrt{1+x}+1})$ 将使用标准的双精度浮点算術（对应于 `numpy.float64`）来计算。\n3. 对于每个近似值 $A$，我们将计算绝对误差 $E_{\\mathrm{abs}} = |A-f_*(x)|$ 和相对误差 $E_{\\mathrm{rel}} = E_{\\mathrm{abs}}/|f_*(x)|$。对于 $x=0$ 的情况，此时 $f_*(0)=0$，按照惯例，相对误差取为 $0$。\n4. 每个 $x$ 的结果将被聚合成一个包含四个值的列表：$[E_{\\mathrm{abs}}^{\\mathrm{dir}}, E_{\\mathrm{rel}}^{\\mathrm{dir}}, E_{\\mathrm{abs}}^{\\mathrm{rat}}, E_{\\mathrm{rel}}^{\\mathrm{rat}}]$。\n\n预期的结果是，对于小的 $|x|$（例如 $10^{-8}$ 及更小），直接计算公式的相对误差 $E_{\\mathrm{rel}}^{\\mathrm{dir}}$ 将显著增大，从而证实了灾难性抵消。相反，有理化公式的相对误差 $E_{\\mathrm{rel}}^{\\mathrm{rat}}$ 在所有测试用例中都应保持很小，在单位舍入误差 $u \\approx 10^{-16}$ 的数量级上，从而证明其数值稳定性。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport decimal\n\ndef solve():\n    \"\"\"\n    Analyzes the numerical stability of two formulas for f(x) = sqrt(1+x) - 1.\n    \"\"\"\n    # Set precision for the high-precision reference calculation (more than 80 digits).\n    decimal.getcontext().prec = 100\n\n    # Define the test cases from the problem statement.\n    # Each tuple contains the string representation for high-precision Decimal\n    # and the float representation for standard double-precision numpy calculation.\n    test_cases = [\n        ('1e-1', 1e-1),\n        ('1e-8', 1e-8),\n        ('1e-12', 1e-12),\n        ('1e-16', 1e-16),\n        ('0', 0.0),\n        ('-1e-16', -1e-16),\n        ('-1e-12', -1e-12),\n    ]\n\n    results = []\n    \n    # Pre-calculate Decimal(1) for efficiency.\n    one_dec = decimal.Decimal(1)\n\n    for x_str, x_float in test_cases:\n        # Task 2: Compute a high-precision reference value.\n        x_dec = decimal.Decimal(x_str)\n        f_star = (one_dec + x_dec).sqrt() - one_dec\n\n        # Task 1: Compute two floating-point approximations.\n        x_f64 = np.float64(x_float)\n        one_f64 = np.float64(1.0)\n        \n        # Direct subtraction formula\n        A_dir = np.sqrt(one_f64 + x_f64) - one_f64\n        \n        # Rationalized formula\n        A_rat = x_f64 / (np.sqrt(one_f64 + x_f64) + one_f64)\n\n        # Task 3: Compute absolute and relative errors.\n        # Convert double-precision results to Decimal for accurate error calculation.\n        A_dir_dec = decimal.Decimal(A_dir)\n        A_rat_dec = decimal.Decimal(A_rat)\n\n        # Absolute errors\n        e_abs_dir = abs(A_dir_dec - f_star)\n        e_abs_rat = abs(A_rat_dec - f_star)\n\n        # Relative errors, with special handling for f_star = 0.\n        if f_star == 0:\n            e_rel_dir = decimal.Decimal(0)\n            e_rel_rat = decimal.Decimal(0)\n        else:\n            e_rel_dir = e_abs_dir / abs(f_star)\n            e_rel_rat = e_abs_rat / abs(f_star)\n\n        # Task 4: Aggregate the results for the current x.\n        # Convert Decimal error values to float for the final output.\n        results.append([\n            float(e_abs_dir), float(e_rel_dir),\n            float(e_abs_rat), float(e_rel_rat)\n        ])\n\n    # Final print statement in the exact required format.\n    # Creates a string like '[[e1,e2,e3,e4],[...]]' without extra whitespace.\n    inner_lists = [f\"[{','.join(map(str, r))}]\" for r in results]\n    final_output = f\"[{','.join(inner_lists)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "3212218"}, {"introduction": "灾难性抵消不仅存在于简单的数学函数中，它同样会影响到数据分析等实际应用。一个典型的例子是方差计算，常用的“捷径”公式 $\\sigma^2 = E[X^2] - (E[X])^2$ 在数据均值远大于其标准差时，会因两个大而相近的数相减而变得极其不稳定。本练习将引导您实现并比较多种方差计算算法，包括不稳定的单遍算法和多种数值稳定的替代算法，从而深刻理解在实际数据处理中选择正确算法的重要性。[@problem_id:3212118]", "problem": "要求您研究在使用公式 $\\sigma^2 = E[X^2] - (E[X])^2$ 计算总体方差时出现的灾难性抵消和有效数字损失问题，并比较不同算法的数值稳定性。本研究的基础是总体均值和方差的定义，以及带舍入的有限精度算术模型。\n\n将使用的基本定义：\n- $n$ 个真实样本 $x_1, x_2, \\dots, x_n$ 的总体均值为 $\\mu = \\frac{1}{n}\\sum_{i=1}^{n} x_i$。\n- 总体方差为 $\\sigma^2 = \\frac{1}{n}\\sum_{i=1}^{n} (x_i - \\mu)^2$。\n- 方差的另一个等价恒等式是 $\\sigma^2 = E[X^2] - (E[X])^2$，其中 $E[X] = \\mu$ 且 $E[X^2] = \\frac{1}{n}\\sum_{i=1}^{n} x_i^2$。\n\n有限精度模型：\n- 实际计算在符合电气和电子工程师协会 (IEEE) $754$ 双精度格式的浮点算术中执行。设单位舍入误差为 $u \\approx 2^{-53}$，并假设每个基本运算引入一个小的相对误差，其上界为一个常数乘以 $u$。\n\n您的任务：\n1. 实现四种算法，为给定的实数列表计算总体方差 $\\sigma^2$：\n   - 算法 $A_1$ (朴素单遍法)：通过单遍累加 $\\sum x_i$ 和 $\\sum x_i^2$ 来计算 $E[X]$ 和 $E[X^2]$，然后返回 $E[X^2] - (E[X])^2$。\n   - 算法 $A_2$ (两遍法，无补偿)：第一遍使用 $\\mu = \\frac{1}{n}\\sum x_i$ 计算 $\\mu$，然后在第二遍计算 $\\sigma^2 = \\frac{1}{n}\\sum (x_i - \\mu)^2$。\n   - 算法 $A_3$ (两遍法，使用 Kahan 求和补偿)：使用 Kahan 补偿求和法计算第一遍的均值和第二遍的平方偏差和。\n   - 算法 $A_4$ (Welford 在线算法)：使用以下递推关系单遍计算 $\\sigma^2$\n     $$\\text{for } i = 1,2,\\dots,n: \\quad \\delta_i = x_i - \\mu_{i-1}, \\quad \\mu_i = \\mu_{i-1} + \\frac{\\delta_i}{i}, \\quad M2_i = M2_{i-1} + \\delta_i \\cdot (x_i - \\mu_i),$$\n     并返回 $\\sigma^2 = \\frac{M2_n}{n}$。\n\n2. 使用高精度基准来近似精确方差以供比较。使用精度为 $p = 100$ 位的十进制算术计算参考均值和方差，将数据集中的值视为所提供的精确小数或整数。\n\n3. 对于每种算法，测量其与高精度基准的差异：\n   - 如果参考方差非零，计算相对误差 $r = \\frac{|\\widehat{\\sigma^2} - \\sigma^2|}{|\\sigma^2|}$，其中 $\\widehat{\\sigma^2}$ 是算法的结果。\n   - 如果参考方差为零，计算绝对误差 $a = |\\widehat{\\sigma^2} - 0|$。\n\n测试套件：\n在以下数据集上提供结果，这些数据集旨在测试一般情况、易于出现抵消的情况以及边界情况。在每种情况下，将列表解释为实数：\n- 情况 1 (通用理想情况)：$[1,2,3,4,5]$。\n- 情况 2 (大偏移量，小方差，在 $E[X^2] - (E[X])^2$ 中导致灾难性抵消)：$[10^{8} + 0, 10^{8} + 1, 10^{8} + 2, 10^{8} + 3, 10^{8} + 4]$。\n- 情况 3 (常数序列，真实方差为零)：$[12345678, 12345678, 12345678, 12345678, 12345678]$。\n- 情况 4 (高动态范围且有符号变化)：$[10^{16}, 10^{16} + 1, -10^{16}, -10^{16} + 1]$。\n- 情况 5 (多点，大偏移量，小增量)：$[10^{12} + i \\text{ for } i = 0, 1, 2, \\dots, 999]$。\n- 情况 6 (单元素，真实方差为零)：$[42]$。\n\n实现约束：\n- 程序必须是一个完整、可运行的 Python 程序，仅使用 Python 标准库和版本为 $1.23.5$ 的 NumPy 库。\n- 程序不得读取任何输入，也不得访问文件或网络。\n- 对每种情况，使用精度为 $p = 100$ 的十进制算术计算参考均值和方差。\n\n要求的最终输出格式：\n- 您的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的列表的列表，且不含空格。每个内部列表按上述顺序对应一个测试用例，并包含四个数字 (浮点数)，分别代表算法 $A_1$、$A_2$、$A_3$ 和 $A_4$ 的误差度量。\n- 示例格式：$[[e_{1,1},e_{1,2},e_{1,3},e_{1,4}],[e_{2,1},e_{2,2},e_{2,3},e_{2,4}],\\dots]$，其中每个 $e_{i,j}$ 根据参考方差是否为零，分别为相对误差 (浮点数) 或绝对误差 (浮点数)。", "solution": "该问题陈述已经过验证，被认为是合理、有科学依据且可形式化的数值分析任务。所有定义、算法和测试用例均为标准且明确规定，可以直接、无歧义地进行实现和分析。该问题是统计计算中数值不稳定性及其缓解方法的经典演示。\n\n问题的核心在于计算总体方差 $\\sigma^2$ 的不同公式的数值特性。对于包含 $n$ 个样本 $\\{x_1, x_2, \\dots, x_n\\}$ 且均值为 $\\mu = \\frac{1}{n}\\sum_{i=1}^{n} x_i$ 的总体，其方差定义为与均值之差的平方的均值：\n$$\n\\sigma^2 = \\frac{1}{n}\\sum_{i=1}^{n} (x_i - \\mu)^2\n$$\n一个通过展开平方得到的数学上等价的公式是：\n$$\n\\sigma^2 = E[X^2] - (E[X])^2 = \\left(\\frac{1}{n}\\sum_{i=1}^{n} x_i^2\\right) - \\left(\\frac{1}{n}\\sum_{i=1}^{n} x_i\\right)^2\n$$\n虽然这些公式在精确算术中是等价的，但它们在有限精度浮点算术中的表现可能截然不同。我们将分析指定的四种算法。\n\n**高精度基准**\n\n为了量化浮点算法的误差，需要一个“基准真相”或参考值。由于输入值是作为精确数字（整数或简单小数）给出的，我们可以使用任意精度算术来计算一个高度精确的参考方差。Python 的 `decimal` 模块，配置为高精度（例如 $p=100$ 位），可以达到此目的。通过使用这种高精度执行所有计算（均值、减法、平方和求和），我们得到的结果相对于标准双精度浮点数的有限精度而言，实际上是精确的。\n\n**算法 $A_1$：朴素单遍算法**\n\n该算法直接实现公式 $\\sigma^2 = E[X^2] - (E[X])^2$。它在单遍处理中计算样本总和 $\\sum x_i$ 和平方和 $\\sum x_i^2$。此方法容易受到**灾难性抵消**的影响。当两个几乎相等的数相减时，会发生这种情况，导致结果的相对精度损失。如果数据由围绕一个大均值 $C$ 聚集的值组成（即 $x_i \\approx C$），那么 $E[X] \\approx C$，$E[X^2] \\approx C^2$。方差取决于 $x_i$ 与均值的微小偏差，它通过减去两个大而几乎相等的值 $E[X^2]$ 和 $(E[X])^2$ 来计算。在浮点算术中，这两个数的前导数字会相互抵消，结果将主要由舍入误差主导，常常产生一个非常不准确、甚至可能是负的方差。\n\n**算法 $A_2$：两遍算法**\n\n该算法遵循定义公式 $\\sigma^2 = \\frac{1}{n}\\sum (x_i - \\mu)^2$。它需要对数据进行两遍处理：\n1. 第一遍：计算均值 $\\mu = \\frac{1}{n}\\sum x_i$。\n2. 第二遍：计算平方偏差之和 $\\sum (x_i - \\mu)^2$ 并除以 $n$。\n\n该方法在数值上比 $A_1$ 稳定得多。通过先计算均值，然后从每个数据点中减去它，后续的求和是在以零为中心的值 $(x_i - \\mu)$ 上执行的。这避免了两个大数相减，从而防止了灾难性抵消。此方法的准确性主要取决于第一遍中计算出的均值的准确性。\n\n**算法 $A_3$：带 Kahan 补偿求和的两遍算法**\n\n这是 $A_2$ 的一个改进版本。浮点数的标准求和会累积显著的误差，特别是对于大型数据集。Kahan 求和是一种通过跟踪每次加法中丢失的低位比特的运行补偿来减轻这种误差的算法。对于一个和 $S = \\sum x_i$，Kahan 算法的流程如下：\n`sum = 0.0`，`c = 0.0`\n对于每个 `x`：\n  `y = x - c`\n  `t = sum + y`\n  `c = (t - sum) - y`\n  `sum = t`\n变量 `c` 累积了舍入误差。算法 $A_3$ 将此补偿求和应用于第一遍（计算 $\\mu$）和第二遍（计算 $\\sum(x_i-\\mu)^2$），从而产生比 $A_2$ 更准确的结果，尤其是在数据点数 $n$ 很大时。\n\n**算法 $A_4$：Welford 在线算法**\n\nWelford 算法是一种数值稳定的单遍方法。它避免了存储整个数据集，使其成为适合处理流式数据的“在线”算法。它迭代地更新均值 $\\mu$ 和与均值之差的平方和 $M_2$。对于一个新的数据点 $x_i$，更新公式为：\n$$\n\\delta_i = x_i - \\mu_{i-1} \\\\\n\\mu_i = \\mu_{i-1} + \\frac{\\delta_i}{i} \\\\\nM_{2,i} = M_{2,i-1} + \\delta_i(x_i - \\mu_i)\n$$\n初始条件为 $\\mu_0 = 0$ 和 $M_{2,0} = 0$。最终的总体方差为 $\\sigma^2 = M_{2,n}/n$。该算法通过基于微小差异 ($\\delta_i$) 的更新来整合新数据点，从而保持稳定性，其精神与两遍法相似，但在单遍中完成。其稳定性可与两遍算法相媲美。\n\n**测试用例的预期结果**\n\n- **情况 1 (通用)：** $[1, 2, 3, 4, 5]$。预计所有算法都会表现良好，因为数值很小，且方差相对于均值而言并不小。\n- **情况 2 (大偏移量，小方差)：** $[10^8, \\dots, 10^8+4]$。这是灾难性抵消的经典案例。预计 $A_1$ 会严重失败，可能产生接近零的结果，而 $A_2$、$A_3$ 和 $A_4$ 应该会很准确。\n- **情况 3 (零方差)：** $[12345678, \\dots]$。真实方差为 $0$。$A_1$ 可能会由于舍入误差而产生一个小的非零或负值结果。其他算法应该会产生非常接近 $0$ 的结果。\n- **情况 4 (高动态范围)：** $[10^{16}, 10^{16}+1, -10^{16}, -10^{16}+1]$。此案例测试对不同符号的大数求和的影响。数值的量级接近 `float64` 的精度极限，可能导致中间计算中有效数字的损失。所有算法都可能出现一些误差，但预计 $A_2$、$A_3$ 和 $A_4$ 会更稳健。\n- **情况 5 (多点，大偏移量)：** $[10^{12}, \\dots, 10^{12}+999]$。与情况 2 类似，但 $n=1000$。更大的数据集可能会放大求和误差。$A_1$ 将会失败。由于补偿求和，$A_3$ 可能会比 $A_2$ 略有优势。\n- **情况 6 (单点)：** $[42]$。真实方差为 $0$。所有算法都应能正确计算出方差为 $0$。\n\n该实现将计算每种算法和每种情况下相对于高精度基准的误差，从而在实践中展示这些数值特性。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport decimal\n\ndef solve():\n    \"\"\"\n    Main function to run the variance algorithm comparison.\n    \"\"\"\n    decimal.getcontext().prec = 100\n\n    def get_reference_variance(data_list):\n        \"\"\"\n        Computes the population variance using high-precision decimal arithmetic.\n        \"\"\"\n        if not data_list or len(data_list) == 0:\n            return decimal.Decimal(0)\n        \n        n = len(data_list)\n        data_dec = [decimal.Decimal(str(x)) for x in data_list]\n        \n        mean_dec = sum(data_dec) / decimal.Decimal(n)\n        \n        var_dec = sum((x - mean_dec)**2 for x in data_dec) / decimal.Decimal(n)\n        \n        return var_dec\n\n    def alg1_naive(data: np.ndarray) -> np.float64:\n        \"\"\"Algorithm A1: Naive one-pass E[X^2] - (E[X])^2.\"\"\"\n        n = data.size\n        if n == 0:\n            return np.float64(0.0)\n        \n        # In a single pass, one would loop. np.sum is equivalent and fast.\n        sum_x = np.sum(data)\n        sum_x_sq = np.sum(data**2)\n        \n        mean_x = sum_x / n\n        mean_x_sq = sum_x_sq / n\n        \n        return mean_x_sq - mean_x**2\n\n    def alg2_twopass(data: np.ndarray) -> np.float64:\n        \"\"\"Algorithm A2: Two-pass definitional formula.\"\"\"\n        n = data.size\n        if n == 0:\n            return np.float64(0.0)\n        \n        mean = np.sum(data) / n\n        sum_sq_dev = np.sum((data - mean)**2)\n        \n        return sum_sq_dev / n\n\n    def kahan_sum(arr):\n        \"\"\"Kahan compensated summation.\"\"\"\n        s = np.float64(0.0)\n        c = np.float64(0.0)\n        for x in arr:\n            y = np.float64(x - c)\n            t = s + y\n            c = (t - s) - y\n            s = t\n        return s\n\n    def alg3_kahan(data: np.ndarray) -> np.float64:\n        \"\"\"Algorithm A3: Two-pass with Kahan summation.\"\"\"\n        n = data.size\n        if n == 0:\n            return np.float64(0.0)\n            \n        mean = kahan_sum(data) / n\n        \n        # The terms (data - mean)**2 are computed in standard float arithmetic\n        # before being summed with Kahan.\n        sq_devs = (data - mean)**2\n        sum_sq_dev = kahan_sum(sq_devs)\n        \n        return sum_sq_dev / n\n        \n    def alg4_welford(data: np.ndarray) -> np.float64:\n        \"\"\"Algorithm A4: Welford's one-pass online algorithm.\"\"\"\n        n = data.size\n        if n == 0:\n            return np.float64(0.0)\n\n        mean = np.float64(0.0)\n        m2 = np.float64(0.0)\n        \n        for i, x in enumerate(data, 1):\n            delta = x - mean\n            mean += delta / i\n            delta2 = x - mean\n            m2 += delta * delta2\n            \n        return m2 / n\n\n    test_cases = [\n        # Case 1: general happy path\n        ([1.0, 2.0, 3.0, 4.0, 5.0]),\n        # Case 2: large offset, small variance\n        ([1e8 + 0.0, 1e8 + 1.0, 1e8 + 2.0, 1e8 + 3.0, 1e8 + 4.0]),\n        # Case 3: constant sequence, true variance zero\n        ([12345678.0] * 5),\n        # Case 4: high dynamic range\n        ([1e16, 1e16 + 1.0, -1e16, -1e16 + 1.0]),\n        # Case 5: many points, large offset\n        ([1e12 + float(i) for i in range(1000)]),\n        # Case 6: single element, true variance zero\n        ([42.0])\n    ]\n\n    results = []\n    algorithms = [alg1_naive, alg2_twopass, alg3_kahan, alg4_welford]\n\n    for data_list in test_cases:\n        case_errors = []\n        data_np = np.array(data_list, dtype=np.float64)\n        ref_var = get_reference_variance(data_list)\n\n        for alg in algorithms:\n            computed_var = alg(data_np)\n            \n            if ref_var == 0:\n                error = abs(computed_var)\n            else:\n                error = abs(computed_var - float(ref_var)) / float(ref_var)\n            case_errors.append(float(error))\n        results.append(case_errors)\n\n    # Final print statement in the exact required format.\n    print(str(results).replace(\" \", \"\"))\n\nsolve()\n```", "id": "3212118"}, {"introduction": "除了两个几乎相等的数直接相减，数值精度损失还可能在长序列求和的过程中逐渐累积。当一个数量级很小的数与一个很大的累加和相加时，其有效信息可能会被“舍入”掉。本练习通过计算交错调和级数的和来探究这一现象，您将比较不同求和顺序（正向与逆向）以及不同算法（朴素求和与 Kahan 补偿求和）下的结果差异。这有助于您理解浮点数加法的非结合性，并学习如何使用补偿算法来显著提高求和的精度。[@problem_id:3212279]", "problem": "考虑由有限级数 $$S_N = \\sum_{n=1}^{N} \\frac{(-1)^{n+1}}{n}$$ 定义的交错调和部分和。在精确算术中，$$S_N$$ 的值与各项求和的顺序无关。在由电气与电子工程师协会（IEEE）754二进制浮点标准管理的有限精度浮点算术中，舍入模型可理想化为 $$\\operatorname{fl}(a \\,\\oplus\\, b) = (a \\,\\oplus\\, b)(1 + \\delta), \\quad |\\delta| \\leq u,$$ 其中 $$\\operatorname{fl}(\\cdot)$$ 表示计算值，$$\\oplus$$ 表示算术运算，$$u$$ 是与浮点精度相关的单位舍入误差。当许多小量级的项被加到一个较大量级的累加和中时，可能会发生灾难性抵消和有效位损失，并且计算结果可能依赖于求和顺序。\n\n任务：编写一个完整、可运行的程序，对每个指定的 $$N$$ 执行以下操作：\n- 使用朴素求和，以正序（从 $$n=1$$ 到 $$n=N$$）计算 $$S_N$$，同时使用 binary32（单精度，视为 $$32$$ 位）和 binary64（双精度，视为 $$64$$ 位）两种精度。\n- 使用朴素求和，以逆序（从 $$n=N$$ 到 $$n=1$$）计算 $$S_N$$，同样使用两种精度。\n- 使用补偿求和（Kahan 求和），以正序和逆序计算 $$S_N$$，同样使用两种精度。\n\n利用这六次计算，为每个 $$N$$ 生成以下六个定量指标（均为实数）：\n1. $$d_{64} = \\left|S_N^{\\text{forward, naive, 64}} - S_N^{\\text{reverse, naive, 64}}\\right|$$\n2. $$d_{32} = \\left|S_N^{\\text{forward, naive, 32}} - S_N^{\\text{reverse, naive, 32}}\\right|$$\n3. $$\\Delta_{64}^{\\text{f}} = \\left|S_N^{\\text{forward, naive, 64}} - S_N^{\\text{forward, Kahan, 64}}\\right|$$\n4. $$\\Delta_{64}^{\\text{r}} = \\left|S_N^{\\text{reverse, naive, 64}} - S_N^{\\text{reverse, Kahan, 64}}\\right|$$\n5. $$\\Delta_{32}^{\\text{f}} = \\left|S_N^{\\text{forward, naive, 32}} - S_N^{\\text{forward, Kahan, 32}}\\right|$$\n6. $$\\Delta_{32}^{\\text{r}} = \\left|S_N^{\\text{reverse, naive, 32}} - S_N^{\\text{reverse, Kahan, 32}}\\right|$$\n\n这些指标旨在揭示顺序敏感性（项目 $$1$$ 和 $$2$$）以及通过补偿减轻的有效位损失程度（项目 $$3$$ 到 $$6$$）。\n\n使用的基本原理：\n- IEEE 754 的舍入行为可抽象为 $$\\operatorname{fl}(a \\,\\oplus\\, b) = (a \\,\\oplus\\, b)(1 + \\delta), \\ |\\delta| \\leq u.$$\n- 交错的符号在量级相似的项相加时可能产生抵消，以及求和顺序会影响舍入误差的累积方式，这一概念。\n\n您的程序必须明确地以两种精度和两种顺序实现计算。本问题不涉及物理单位。不涉及角度。不涉及百分比。\n\n测试套件：\n- $$N = 1$$ （边界情况；平凡的单项和），\n- $$N = 10^5$$ （中等规模；在 binary32 中可见的舍入效应），\n- $$N = 10^6$$ （大规模；更强的舍入效应累积）。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含结果，格式为一个逗号分隔的列表，列表中的每个元素是对应一个测试用例的子列表，子列表无空格，且均由方括号包围。例如，输出必须看起来像 $$\\texttt{[[d64\\_1,d32\\_1,Delta64f\\_1,Delta64r\\_1,Delta32f\\_1,Delta32r\\_1],[d64\\_2,\\dots],[d64\\_3,\\dots]]}$$ 其中下标表示测试用例索引。每个数字都应以标准十进制形式打印。", "solution": "该问题要求分析交错调和级数 $$S_N = \\sum_{n=1}^{N} \\frac{(-1)^{n+1}}{n}$$ 求和中的数值误差。完成此任务的方法是实现并比较不同的求和策略——具体来说，是正序和逆序的朴素求和，以及补偿求和（Kahan 求和）——并跨越两种不同的浮点精度：binary32（单精度）和 binary64（双精度）。目标是量化求和顺序带来的影响，以及更复杂算法在减轻舍入误差方面的优势。\n\n该问题的基础在于 IEEE 754 标准化的有限精度浮点算术的本质。浮点数使用有限位数的有效数（或尾数）来表示。因此，并非所有实数都能被精确表示。当执行算术运算时，结果会被舍入到最接近的可表示浮点数。这个过程可通过模型 $$\\operatorname{fl}(a \\,\\oplus\\, b) = (a \\,\\oplus\\, b)(1 + \\delta)$$ 来理想化，其中 $$|\\delta|$$ 受单位舍入误差 $$u$$ 的限制。对于 binary64，$$u \\approx 2^{-53}$$；对于 binary32，$$u \\approx 2^{-24}$$。\n\n求和中的一个关键误差来源是当一个小数加到一个大数上时发生的有效位损失。如果 $|x| \\ll |y|$，特别是如果 $|x|  u|y|$，那么浮点加法 $\\operatorname{fl}(y+x)$ 的计算结果可能就是 $y$，实际上忽略了 $x$ 的贡献。\n\n交错调和级数收敛于 $\\ln(2) \\approx 0.693$。随着 $N$ 的增加，项 $\\frac{(-1)^{n+1}}{n}$ 逐渐变小。\n\n1.  **正序朴素求和（$n=1 \\to N$）**：和按 $S = (\\dots((a_1 + a_2) + a_3) + \\dots + a_N)$ 计算。部分和迅速接近其极限。后续的项 $a_n$ 与累加和 $S_{n-1}$ 相比变得非常小。最终，对于足够大的 $n$， $|a_n|$ 会小于 $S_{n-1}$ 的最低有效位，导致加法 $\\operatorname{fl}(S_{n-1} + a_n)$ 的结果就是 $S_{n-1}$。所有后续项都将丢失，从而导致不准确的结果。\n\n2.  **逆序朴素求和（$n=N \\to 1$）**：和按 $S = (\\dots((a_N + a_{N-1}) + a_{N-2}) + \\dots + a_1)$ 计算。此方法首先对最小的项求和。累加的部分和增长缓慢，因此每个新加入的项与当前和的量级相当。这在每一步都最大限度地减少了有效位损失，从而产生比正序求和更准确的结果。\n\n3.  **Kahan 求和（补偿求和）**：该算法明确地跟踪并校正每次加法中的舍入误差。它由 William Kahan 发明，维持一个累加和 `sum` 和一个累积补偿项 `c`，后者保存了前一步的误差。对于级数中的每一项 `x`，算法执行四步操作：\n    *   `y = x - c`：首先通过减去先前加法的误差来校正下一项。\n    *   `t = sum + y`：将校正后的项加到主和上。此操作仍会产生舍入误差。\n    *   `c = (t - sum) - y`：这是关键步骤。在精确算术中，`c` 将为零。在浮点算術中，此计算分离出了在加法 `sum + y` 过程中丢失的 `y` 的低位比特。这个值就是新的舍入误差。\n    *   `sum = t`：更新主和。\n    \n    通过将误差 `c` 向前传递，Kahan 求和将每个项的“丢失”部分重新引入计算，从而显著提高准确性。它可以作为一个高质量的参考，用来与朴素方法进行比较。\n\n实现将按以下步骤进行：\n首先，对于测试套件中的每个 $N$（$1$，$10^5$，$10^6$），为 binary64（`numpy.float64`）和 binary32（`numpy.float32`）精度生成级数项 $\\frac{(-1)^{n+1}}{n}$ 的数组。\n\n然后，为每种精度和每个 $N$ 计算六个和：\n*   $S_N^{\\text{forward, naive, 64}}$: 对 binary64 项从 $n=1$到 $N$ 进行朴素求和。\n*   $S_N^{\\text{reverse, naive, 64}}$: 对 binary64 项从 $n=N$到 $1$ 进行朴素求和。\n*   $S_N^{\\text{forward, Kahan, 64}}$: 对 binary64 项从 $n=1$到 $N$ 进行 Kahan 求和。\n*   $S_N^{\\text{reverse, Kahan, 64}}$: 对 binary64 项从 $n=N$到 $1$ 进行 Kahan 求和。\n*   以及对应的四种 binary32 精度的求和。\n\n题目要求仅进行六次计算。重新阅读题目要求，它要求正序和逆序都使用 Kahan 求和。这是为了分析的完整性，尽管在实践中 Kahan 求和的顺序敏感性远低于朴素求和。我将实现所有八种计算来算出所需的六个指标。\n\n最后，根据这些和计算出六个指定的指标：\n*   $d_{64}$ 和 $d_{32}$ 衡量正序和逆序朴素求和之间的差异。这直接量化了求和顺序的影响。我们预计这个差异对于 binary32 会更大，并且会随着 $N$ 的增大而增大。\n*   $\\Delta$ 指标（$\\Delta_{64}^{\\text{f}}$、$\\Delta_{64}^{\\text{r}}$、$\\Delta_{32}^{\\text{f}}$、$\\Delta_{32}^{\\text{r}}$）衡量朴素求和相对于其 Kahan 求和对应项的误差。由于 Kahan 求和明显更准确，这些值可以作为朴素求和方法中误差的绝佳估计。我们预计误差在正序、单精度求和（$\\Delta_{32}^{\\text{f}}$）中最大，并且此误差会随着 $N$ 的增大而增大。\n对于边界情况 $N=1$，和就是 $1$。没有求和过程，因此没有舍入误差累积。所有六个指标预计都精确为 $0.0$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef naive_sum(terms_array):\n    \"\"\"\n    Performs naive summation over an array of terms.\n    The summation's precision is determined by the array's dtype.\n    \"\"\"\n    # Initialize sum to zero with the correct precision\n    s = terms_array.dtype.type(0.0)\n    for x in terms_array:\n        s += x\n    return s\n\ndef kahan_sum(terms_array):\n    \"\"\"\n    Performs Kahan compensated summation over an array of terms.\n    The summation's precision is determined by the array's dtype.\n    \"\"\"\n    # Initialize sum and compensation to zero with the correct precision\n    s = terms_array.dtype.type(0.0)\n    c = terms_array.dtype.type(0.0)\n    for x in terms_array:\n        y = x - c\n        t = s + y\n        c = (t - s) - y\n        s = t\n    return s\n\ndef solve():\n    \"\"\"\n    Main function to perform the computations and print the final results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [1, 10**5, 10**6]\n\n    results = []\n    for N in test_cases:\n        # Generate the terms of the series for n=1 to N\n        # Use float64 for initial generation for higher precision before casting\n        n_vals_64 = np.arange(1, N + 1, dtype=np.float64)\n        terms64 = ((-1.0)**(n_vals_64 + 1.0)) / n_vals_64\n        terms32 = terms64.astype(np.float32)\n\n        # Reverse the term arrays for reverse summation\n        terms64_rev = terms64[::-1].copy() # Use .copy() for contiguous memory layout\n        terms32_rev = terms32[::-1].copy()\n\n        # --- Perform all computations ---\n\n        # Binary64 (double precision) computations\n        s_fwd_naive_64 = naive_sum(terms64)\n        s_rev_naive_64 = naive_sum(terms64_rev)\n        s_fwd_kahan_64 = kahan_sum(terms64)\n        s_rev_kahan_64 = kahan_sum(terms64_rev)\n\n        # Binary32 (single precision) computations\n        s_fwd_naive_32 = naive_sum(terms32)\n        s_rev_naive_32 = naive_sum(terms32_rev)\n        s_fwd_kahan_32 = kahan_sum(terms32)\n        s_rev_kahan_32 = kahan_sum(terms32_rev)\n\n        # --- Calculate the six required metrics ---\n        \n        # 1. d_64: Sensitivity to order in naive 64-bit summation\n        d64 = abs(s_fwd_naive_64 - s_rev_naive_64)\n\n        # 2. d_32: Sensitivity to order in naive 32-bit summation\n        d32 = abs(s_fwd_naive_32 - s_rev_naive_32)\n\n        # 3. Delta_64^f: Error of forward naive 64-bit sum\n        delta64_f = abs(s_fwd_naive_64 - s_fwd_kahan_64)\n\n        # 4. Delta_64^r: Error of reverse naive 64-bit sum\n        delta64_r = abs(s_rev_naive_64 - s_rev_kahan_64)\n        \n        # 5. Delta_32^f: Error of forward naive 32-bit sum\n        delta32_f = abs(s_fwd_naive_32 - s_fwd_kahan_32)\n\n        # 6. Delta_32^r: Error of reverse naive 32-bit sum\n        delta32_r = abs(s_rev_naive_32 - s_rev_kahan_32)\n\n        # Store the metrics for this test case\n        case_results = [\n            d64,\n            d32,\n            delta64_f,\n            delta64_r,\n            delta32_f,\n            delta32_r\n        ]\n        results.append(case_results)\n\n    # Final print statement in the exact required format.\n    # Manually build the string to avoid spaces inserted by str() on lists.\n    output_str = f\"[{','.join([f'[{\",\".join(map(str, sublist))}]' for sublist in results])}]\"\n    print(output_str)\n\nsolve()\n```", "id": "3212279"}]}