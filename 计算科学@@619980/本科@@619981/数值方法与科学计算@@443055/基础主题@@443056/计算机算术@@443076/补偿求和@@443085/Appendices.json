{"hands_on_practices": [{"introduction": "我们的第一个练习是一个思想实验，它旨在揭示浮点数算术中的一个核心问题：“淹没”（swamping）或称“大数吃小数”。通过分析一个精心设计但极端的数列求和，我们将直观地理解为何简单的顺序求和会失败，以及补偿求和法是如何尝试解决这个问题的。这个练习将帮助我们在不编写代码的情况下，深化对浮点数舍入误差机制的理解[@problem_id:3214532]。", "problem": "考虑在电气和电子工程师协会（IEEE）浮点算术标准（IEEE 754）的 binary64 格式下，使用向最近偶数舍入（rounding to nearest, ties to even）的方式对三个实数求和。设序列为 $a_{1} = 1$，$a_{2} = 10^{100}$ 和 $a_{3} = -10^{100}$。在实数算术中，其精确和为 $a_{1} + a_{2} + a_{3}$。在浮点算术中，将朴素求和定义为通过递推式 $s \\leftarrow \\operatorname{fl}(s + a_{k})$ 对一个运行总和 $s$ 进行从左到右的累加，其中 $\\operatorname{fl}(\\cdot)$ 表示在 binary64 中的一次正确舍入的浮点运算。将 Kahan 补偿求和定义为其变体，该变体维持一个补偿变量 $c$，并根据以下方式更新：$y \\leftarrow a_{k} - c$，$t \\leftarrow \\operatorname{fl}(s + y)$，$c \\leftarrow \\operatorname{fl}(\\operatorname{fl}(t - s) - y)$，$s \\leftarrow t$。\n\n仅使用 binary64 中向最近值舍入的基本定义以及末位单位的概念，分析舍入对朴素累加在 $(a_{1}, a_{2}, a_{3})$ 和 $(a_{2}, a_{3}, a_{1})$ 顺序下的部分和的影响，以及对 Kahan 补偿求和在 $(a_{1}, a_{2}, a_{3})$ 顺序下的影响。然后，确定 Kahan 补偿求和对于顺序 $(a_{1}, a_{2}, a_{3})$ 返回的最终值。报告的答案无需舍入，也不适用任何物理单位。请以单个实数形式提供您的答案。", "solution": "用户希望在 IEEE $754$ binary64 算术中使用 Kahan 补偿求和算法，计算序列 $a_{1} = 1$，$a_{2} = 10^{100}$ 和 $a_{3} = -10^{100}$ 这三个数的和。\n\n**问题验证**\n\n**步骤 1：提取已知条件**\n- **数字：** $a_{1} = 1$，$a_{2} = 10^{100}$，$a_{3} = -10^{100}$。\n- **算术规则：** IEEE $754$ binary64 格式，向最近偶数舍入。\n- **浮点运算：** $\\operatorname{fl}(\\cdot)$ 表示一次正确舍入的浮点运算。\n- **朴素求和：** $s \\leftarrow \\operatorname{fl}(s + a_{k})$，其中 $s$ 初始化为 $0$。\n- **Kahan 补偿求和：** 初始化 $s=0, c=0$。对于每个 $a_k$：\n  $y \\leftarrow a_{k} - c$\n  $t \\leftarrow \\operatorname{fl}(s + y)$\n  $c \\leftarrow \\operatorname{fl}(\\operatorname{fl}(t - s) - y)$\n  $s \\leftarrow t$\n  问题描述中对 $y$ 的更新没有明确使用 $\\operatorname{fl}(\\cdot)$，但在实现数值算法的上下文中，此赋值意味着一次浮点运算。因此，我们将其解释为 $y \\leftarrow \\operatorname{fl}(a_k - c)$。\n- **任务：** 分析朴素求和在 $(a_1, a_2, a_3)$ 和 $(a_2, a_3, a_1)$ 顺序下的结果，并确定 Kahan 求和在 $(a_1, a_2, a_3)$ 顺序下的最终值。精确和为 $1 + 10^{100} + (-10^{100}) = 1$。\n\n**步骤 2：使用提取的已知条件进行验证**\n- **科学依据：** 该问题牢固地植根于数值分析以及 IEEE $754$ 标准所定义的浮点算术细节。这是一个用于说明求和算法属性的经典例子。\n- **适定性：** 问题是适定的。输入、算术规则和算法都已指定，从而导向一个唯一的、确定性的结果。\n- **客观性：** 问题以精确、正式的语言陈述，没有歧义或主观论断。\n\n该问题被认为是有效的，因为它符合所有标准。这是科学计算领域内一个合理且正式的问题。\n\n**解法**\n\n首先，我们确定输入数字在 binary64 格式下的浮点表示。binary64 格式具有 $53$ 位的有效数精度（包括隐含的前导位）。\n- $a_1 = 1$：这个数可以精确地表示为 binary64 中的 $1.0 \\times 2^0$。我们将其表示记为 $\\hat{a}_1 = 1$。\n- $a_2 = 10^{100}$：这个数不能精确表示。它必须被舍入到最接近的 binary64 数。我们将其表示记为 $\\hat{a}_2 = \\operatorname{fl}(10^{100})$。$\\hat{a}_2$ 的值非常大。我们可以估计其数量级：$\\log_2(10^{100}) = 100 \\log_2(10) \\approx 100 \\times 3.3219 \\approx 332.19$。所以，$\\hat{a}_2$ 大约为 $m \\times 2^{332}$，其中有效数 $m \\in [1, 2)$。\n- $a_3 = -10^{100}$：其表示为 $\\hat{a}_3 = \\operatorname{fl}(-10^{100})$。由于向最近值舍入的对称性，$\\hat{a}_3 = -\\operatorname{fl}(10^{100}) = -\\hat{a}_2$。\n\n此问题中的一个关键概念是**淹没** (swamping)，它发生在对两个数量级差异巨大的浮点数进行加减法时。如果 $|x| \\gg |y|$，则 $\\operatorname{fl}(x+y)$ 的结果可能等于 $x$，实际上“淹没”了 $y$。当 $y$ 小于 $x$ 周围可表示数之间的间距时，就会发生这种情况。对于 $x = m \\times 2^E$ ($1 \\le m  2$)，其末位单位（ulp）为 $\\text{ulp}(x) = 2^{E-52}$。对于 $\\hat{a}_2 \\approx 2^{332}$，ulp 大约为 $2^{332-52} = 2^{280}$，这是一个远大于 $1$ 的数。因此，将 $1$ 加到 $\\hat{a}_2$ 上对其浮点表示没有影响。\n\n**朴素求和分析**\n- **顺序 $(a_1, a_2, a_3)$：**\n  1. $s_0 = 0$。\n  2. $s_1 = \\operatorname{fl}(s_0 + a_1) = \\operatorname{fl}(0 + 1) = 1$。\n  3. $s_2 = \\operatorname{fl}(s_1 + a_2) = \\operatorname{fl}(1 + 10^{100}) = \\operatorname{fl}(1 + \\hat{a}_2) = \\hat{a}_2$（由于淹没）。\n  4. $s_3 = \\operatorname{fl}(s_2 + a_3) = \\operatorname{fl}(\\hat{a}_2 + (-\\hat{a}_2)) = 0$。\n  结果为 $0$。\n\n- **顺序 $(a_2, a_3, a_1)$：**\n  1. $s_0 = 0$。\n  2. $s_1 = \\operatorname{fl}(s_0 + a_2) = \\operatorname{fl}(0 + 10^{100}) = \\hat{a}_2$。\n  3. $s_2 = \\operatorname{fl}(s_1 + a_3) = \\operatorname{fl}(\\hat{a}_2 + (-\\hat{a}_2)) = 0$。\n  4. $s_3 = \\operatorname{fl}(s_2 + a_1) = \\operatorname{fl}(0 + 1) = 1$。\n  结果为 $1$，这是正确的和。这说明了求和顺序的重要性。\n\n**对顺序为 $(a_1, a_2, a_3)$ 的 Kahan 补偿求和的分析**\n我们将跟踪算法每一步的状态变量 $s$（和）和 $c$（补偿）。\n\n**初始化：**\n- $s = 0$\n- $c = 0$\n\n**步骤 1：加上 $a_1 = 1$**\n- $y \\leftarrow \\operatorname{fl}(a_1 - c) = \\operatorname{fl}(1 - 0) = 1$。\n- $t \\leftarrow \\operatorname{fl}(s + y) = \\operatorname{fl}(0 + 1) = 1$。\n- $c \\leftarrow \\operatorname{fl}(\\operatorname{fl}(t - s) - y) = \\operatorname{fl}(\\operatorname{fl}(1 - 0) - 1) = \\operatorname{fl}(1 - 1) = 0$。\n- $s \\leftarrow t = 1$。\n**步骤 1 后的状态：** $s = 1$，$c = 0$。和是正确的，不需要补偿。\n\n**步骤 2：加上 $a_2 = 10^{100}$**\n- $y \\leftarrow \\operatorname{fl}(a_2 - c) = \\operatorname{fl}(10^{100} - 0) = \\hat{a}_2$。\n- $t \\leftarrow \\operatorname{fl}(s + y) = \\operatorname{fl}(1 + \\hat{a}_2)$。如前所述，$\\hat{a}_2$ 的数量级非常大，以至于加上 $1$ 会因淹没而丢失。结果被舍入为 $\\hat{a}_2$。所以，$t = \\hat{a}_2$。\n- $c \\leftarrow \\operatorname{fl}(\\operatorname{fl}(t - s) - y)$。我们有 $t=\\hat{a}_2$，$s=1$ 和 $y=\\hat{a}_2$。\n  - 内层运算：$\\operatorname{fl}(t - s) = \\operatorname{fl}(\\hat{a}_2 - 1)$。同样，由于淹没，减去 $1$ 对浮点结果没有影响。所以，$\\operatorname{fl}(\\hat{a}_2 - 1) = \\hat{a}_2$。\n  - 外层运算：$c \\leftarrow \\operatorname{fl}(\\hat{a}_2 - y) = \\operatorname{fl}(\\hat{a}_2 - \\hat{a}_2) = 0$。\n- $s \\leftarrow t = \\hat{a}_2$。\n**步骤 2 后的状态：** $s = \\hat{a}_2$，$c = 0$。Kahan 算法未能将丢失的项 $1$ 捕获到补偿变量 $c$ 中。这种失败的发生是因为正确计算误差项的条件 $|s| \\ge |y|$ 被违反了。\n\n**步骤 3：加上 $a_3 = -10^{100}$**\n- $y \\leftarrow \\operatorname{fl}(a_3 - c) = \\operatorname{fl}(-10^{100} - 0) = \\hat{a}_3 = -\\hat{a}_2$。\n- $t \\leftarrow \\operatorname{fl}(s + y) = \\operatorname{fl}(\\hat{a}_2 + (-\\hat{a}_2)) = 0$。这个减法是精确的，因为浮点数有精确的负数。\n- $c \\leftarrow \\operatorname{fl}(\\operatorname{fl}(t - s) - y) = \\operatorname{fl}(\\operatorname{fl}(0 - \\hat{a}_2) - (-\\hat{a}_2))$。\n  - 内层运算：$\\operatorname{fl}(0 - \\hat{a}_2) = -\\hat{a}_2$（精确）。\n  - 外层运算：$c \\leftarrow \\operatorname{fl}((-\\hat{a}_2) - (-\\hat{a}_2)) = \\operatorname{fl}(-\\hat{a}_2 + \\hat{a}_2) = 0$。\n- $s \\leftarrow t = 0$。\n**最终状态：** $s = 0$，$c = 0$。\n\nKahan 求和算法返回的最终值，即 $s$ 的最终值，是 $0$。这个例子演示了一种情况，即当运行总和远小于要相加的项时，由于发生淹没，标准 Kahan 算法未能改进朴素求和的结果。", "answer": "$$\\boxed{0}$$", "id": "3214532"}, {"introduction": "现在，让我们从理论走向实践。在这个练习中，你将通过编程计算交错调和级数（其和收敛于 $\\ln(2)$）来亲手实现朴素求和与补偿求和。这个任务不仅可以让你量化累积的舍入误差，并直观地看到补偿算法带来的精度提升，还能让你探索求和顺序对结果的影响，这是编写稳健数值代码的另一个重要方面[@problem_id:3214610]。", "problem": "要求您研究条件收敛级数的数值求和，并量化补偿对浮点舍入误差的影响。考虑由下式定义的交错调和级数\n$$\nS = \\sum_{k=1}^{\\infty} (-1)^{k+1}\\frac{1}{k}.\n$$\n一个经过充分检验的事实是，自然对数的泰勒级数满足\n$$\n\\ln(1+x) = \\sum_{k=1}^{\\infty} (-1)^{k+1}\\frac{x^k}{k}\n$$\n对于 $|x| \\leq 1$ 且 $x \\neq -1$，这意味着\n$$\n\\sum_{k=1}^{\\infty} (-1)^{k+1}\\frac{1}{k} = \\ln(2).\n$$\n交错级数检验进一步保证，对于部分和\n$$\nS_N = \\sum_{k=1}^{N} (-1)^{k+1}\\frac{1}{k},\n$$\n截断误差 $|S - S_N|$ 的上界是下一项的绝对值：\n$$\n|S - S_N| \\leq \\frac{1}{N+1}.\n$$\n\n从数值计算的角度来看，假设浮点运算遵循电气与电子工程师协会 (IEEE) $754$ 双精度标准下的标准舍入模型：对于加法和减法，\n$$\n\\operatorname{fl}(a \\oplus b) = (a \\oplus b)(1 + \\delta), \\quad |\\delta| \\leq \\varepsilon_{\\text{mach}},\n$$\n其中 $\\varepsilon_{\\text{mach}}$ 是机器精度，$\\operatorname{fl}(\\cdot)$ 表示浮点运算结果。在长序列求和中，当相加的数数量级差异巨大或符号相反时，许多低位比特可能会丢失，导致累积的舍入误差。一种原则性的缓解方法是补偿求和，它为每一步因舍入而丢失的低位部分维护一个动态补偿，并在下一次加法中将其反馈回来。\n\n您的任务是：\n\n- 实现两种用于计算 $S_N$ 的数值求和程序：\n  1. 一种朴素前向求和，按指定顺序累加各项，不进行补偿。\n  2. 一种补偿求和，使用一个单项补偿变量，在每次加法时更新它，以捕捉并重新引入因舍入而丢失的低位部分。\n\n- 支持两种累加顺序：\n  - 前向顺序：迭代 $k = 1,2,\\dots,N$。\n  - 反向顺序：迭代 $k = N,N-1,\\dots,1$。\n\n- 对每个部分和，计算：\n  1. 绝对误差 $E_{\\text{naive}} = |\\operatorname{fl}(S_N^{\\text{naive}}) - \\ln(2)|$。\n  2. 绝对误差 $E_{\\text{comp}} = |\\operatorname{fl}(S_N^{\\text{comp}}) - \\ln(2)|$。\n  3. 归一化误差 $E_{\\text{naive}} / \\left(\\frac{1}{N+1}\\right)$。\n  4. 归一化误差 $E_{\\text{comp}} / \\left(\\frac{1}{N+1}\\right)$。\n  5. 一个布尔标志，指示补偿是否提高了准确性，即 $E_{\\text{comp}} \\leq E_{\\text{naive}}$。\n\n设计并实现您的程序，使其使用双精度 ($\\text{IEEE } 754$ double) 算术 (Python 内置的 $float$)，并为以下测试套件生成结果：\n- 情况 1：$N = 1$，前向顺序。\n- 情况 2：$N = 10$，前向顺序。\n- 情况 3：$N = 1000$，前向顺序。\n- 情况 4：$N = 200000$，前向顺序。\n- 情况 5：$N = 200000$，反向顺序。\n\n该测试套件涵盖：\n- 一个边界情况 ($N = 1$)，其中求和项很少。\n- 一个小规模情况 ($N = 10$)，说明早期收敛行为。\n- 一个中等规模情况 ($N = 1000$)，其中截断误差很小，但舍入误差开始变得重要。\n- 一个大规模情况 ($N = 200000$)，其中舍入误差可能累积。\n- 在大规模 $N$ 时对求和顺序的敏感性。\n\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表。对于每个测试用例，按以下顺序精确地输出五个项目：\n$$\n[E_{\\text{naive}}, E_{\\text{comp}}, \\; E_{\\text{naive}}/(1/(N+1)), \\; E_{\\text{comp}}/(1/(N+1)), \\; (E_{\\text{comp}} \\leq E_{\\text{naive}})]\n$$\n将所有五个测试用例的结果连接成一个单一的扁平列表。例如，输出格式必须是\n$$\n[\\text{case1\\_naive\\_err},\\text{case1\\_comp\\_err},\\text{case1\\_naive\\_norm},\\text{case1\\_comp\\_norm},\\text{case1\\_improved},\\dots,\\text{case5\\_improved}]\n$$\n不含任何多余的字符或行。此问题不涉及物理单位或角度，因此不需要进行单位转换。所有数值均应以标准十进制表示法打印。", "solution": "该问题要求对补偿求和在计算交错调和级数部分和 $S_N = \\sum_{k=1}^{N} (-1)^{k+1}\\frac{1}{k}$ 时的准确性影响进行数值研究。已知该无穷级数的精确值为 $S = \\ln(2)$。$S_N$ 的数值计算总误差，即 $|\\operatorname{fl}(S_N) - S|$，是两个分量的和：截断误差 $|S_N - S|$ 和舍入误差 $|\\operatorname{fl}(S_N) - S_N|$。问题给出了截断误差的一个上界，即 $|S - S_N| \\leq \\frac{1}{N+1}$。我们的目标是实现并比较两种求和算法（朴素算法和补偿算法），并评估它们在前向和反向求和顺序下的性能，从而量化舍入误差分量的影响。所有计算都使用 IEEE $754$ 双精度浮点算术进行。\n\n朴素求和算法通过按给定顺序依次相加各项来计算部分和 $S_N$。对于一个项序列 $\\{x_k\\}_{k=1}^N$，和 $S_N = \\sum_{k=1}^N x_k$ 通过递推关系 $s_k = s_{k-1} + x_k$ 计算，其中 $s_0=0$。在浮点算术中，这变为 $\\operatorname{fl}(s_k) = \\operatorname{fl}(\\operatorname{fl}(s_{k-1}) + x_k)$。根据标准模型，$\\operatorname{fl}(a+b) = (a+b)(1+\\delta)$，其中 $|\\delta| \\leq \\varepsilon_{\\text{mach}}$。每一步都会引入一个小的舍入误差。当将一个项 $x_k$ 加到一个当前和 $s_{k-1}$ 上时，如果 $|s_{k-1}| \\gg |x_k|$，$x_k$ 的低位比特会从尾数中移出并丢失。这种精度损失在多次运算后会累积，导致最终结果中可能出现显著的舍入误差。\n\n为了减轻这种舍入误差的累积，我们采用补偿求和，特别是 Kahan 求和算法。该方法引入一个补偿变量 $c$，用于跟踪每次加法引入的误差。设 $s$ 为当前和，$c$ 为补偿，两者都初始化为 $0$。要添加一个新项 $x$，算法按以下步骤进行：\n$1$. 通过从新项中减去前一个误差来计算修正项 $y$：$y = x - c$。\n$2$. 将修正项加到和上：$t = s + y$。由于精度有限，此操作可能不精确。\n$3$. 计算上一步中引入的新误差为 $c_{\\text{new}} = (t - s) - y$。在精确算术中，这个值应为零。然而，在浮点算术中，$(t - s)$ 恢复了成功加到 $s$ 上的 $y$ 的高位部分，因此从中减去 $y$ 得到的是 $y$ 中丢失的低位部分的相反数。\n$4$. 将和更新为 $s = t$，并将新的补偿项 $c$ 设置为 $c_{\\text{new}}$ 以供下一次迭代使用。\n这个过程有效地将从一步到下一步的精度损失“携带”过去，并将其重新引入求和中，从而显著减少最终的累积舍入误差。\n\n求和的顺序也会影响朴素方法的准确性。对于项的绝对值递减的级数，如交错调和级数，有两种自然的顺序：\n- **前向顺序**：从 $k=1$ 到 $N$ 求和。各项 $x_k = (-1)^{k+1}/k$ 的绝对值递减。当前和 $s_k$ 很快接近其最终值，而被加的项则变得越来越小。这导致了 $|s_k| \\gg |x_{k+1}|$ 的经典情况，从而引起显著的舍入误差。\n- **反向顺序**：从 $k=N$ 到 $1$ 求和。此策略首先加上绝对值最小的项。当前和初始时保持较小，这使得后续小项的加法能以更高的相对精度执行。这种启发式方法通常能提高朴素求和的准确性。\n\n对于指定的测试用例，我们预期以下行为。对于小的 $N$ (例如 $N=1, 10$)，截断误差占主导地位，不同求和方法之间的差异将微不足道。对于大的 $N$ (例如 $N=200000$)，舍入误差变得显著。我们预计朴素前向求和的误差 $E_{\\text{naive}}$ 将远大于截断误差界限。相比之下，补偿求和的误差 $E_{\\text{comp}}$ 应保持接近截断误差界限，这证明了该算法的有效性。我们还预计朴素反向求和会比朴素前向求和更准确。归一化误差 $E / (\\frac{1}{N+1})$ 提供了一个衡量总误差超出理论截断误差界限程度的指标；一个接近 $1$ 的值表示舍入误差得到了很好的控制。\n\n分析过程将通过实现这些算法并将其应用于给定的测试套件来进行。对于每种情况，我们计算相对于 $\\ln(2)$ 的高精度值的绝对误差 $E_{\\text{naive}}$ 和 $E_{\\text{comp}}$、归一化误差，以及一个指示补偿是否改善了结果的布尔标志。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef naive_sum(N, order):\n    \"\"\"\n    Computes the partial sum of the alternating harmonic series using naive summation.\n\n    Args:\n        N (int): The number of terms to sum.\n        order (str): The order of summation, 'forward' or 'reverse'.\n\n    Returns:\n        float: The computed sum.\n    \"\"\"\n    s = 0.0\n    k_range = range(1, N + 1) if order == 'forward' else range(N, 0, -1)\n    \n    for k in k_range:\n        term = ((-1.0)**(k + 1)) / k\n        s += term\n        \n    return s\n\ndef compensated_sum(N, order):\n    \"\"\"\n    Computes the partial sum of the alternating harmonic series using\n    Kahan compensated summation.\n\n    Args:\n        N (int): The number of terms to sum.\n        order (str): The order of summation, 'forward' or 'reverse'.\n\n    Returns:\n        float: The computed sum.\n    \"\"\"\n    s = 0.0  # The running sum\n    c = 0.0  # A running compensation for the lost low-order bits\n    k_range = range(1, N + 1) if order == 'forward' else range(N, 0, -1)\n    \n    for k in k_range:\n        term = ((-1.0)**(k + 1)) / k\n        y = term - c\n        t = s + y\n        # (t - s) is the high-order part of y that was successfully added.\n        # (t - s) - y isolates the low-order part of y that was lost.\n        # c stores the negative of this lost part.\n        c = (t - s) - y\n        s = t\n        \n    return s\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and produce the final output.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1, 'forward'),\n        (10, 'forward'),\n        (1000, 'forward'),\n        (200000, 'forward'),\n        (200000, 'reverse'),\n    ]\n\n    # Use numpy's high-precision value for ln(2) as the \"exact\" value.\n    ln2 = np.log(2.0)\n\n    # List to store all results in a flat structure.\n    all_results = []\n\n    for N, order in test_cases:\n        # 1. Compute sums\n        s_naive = naive_sum(N, order)\n        s_comp = compensated_sum(N, order)\n\n        # 2. Compute absolute errors\n        err_naive = abs(s_naive - ln2)\n        err_comp = abs(s_comp - ln2)\n\n        # 3. Compute truncation error bound\n        trunc_err_bound = 1.0 / (N + 1)\n\n        # 4. Compute normalized errors\n        norm_err_naive = err_naive / trunc_err_bound\n        norm_err_comp = err_comp / trunc_err_bound\n\n        # 5. Determine if compensation improved accuracy\n        improved = err_comp = err_naive\n\n        # Append the five required metrics for this test case\n        all_results.extend([\n            err_naive,\n            err_comp,\n            norm_err_naive,\n            norm_err_comp,\n            improved\n        ])\n\n    # Final print statement in the exact required format.\n    # The boolean `True`/`False` is converted to string 'True'/'False'.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\n# Execute the solver.\nsolve()\n```", "id": "3214610"}, {"introduction": "最后一个练习展示了补偿求和如何作为构建块，应用于更复杂的数值算法中。我们将挑战计算统计方差这一对数值误差非常敏感的任务。通过将补偿求和技术集成到经典的单遍 Welford 算法中，我们将构建一个高稳定性的方差计算方法，这充分体现了该技术在解决实际科学计算问题中的强大威力[@problem_id:3214603]。", "problem": "给定一个有限的实数序列，要求您使用三种方法以浮点运算计算总体方差：一种双遍法、一种通常归功于 Welford 的单遍在线更新法，以及一种在二阶中心矩累加过程中集成了补偿求和的改进单遍更新法。目标是通过量化相对于从精确浮点输入计算出的高精度参考值的绝对误差，来评估和比较这些方法的数值稳定性。总体方差根据基本原理定义如下：对于一个有限序列 $\\{x_i\\}_{i=1}^n$，其均值为 $\\mu = \\frac{1}{n}\\sum_{i=1}^n x_i$，总体方差为 $\\sigma^2 = \\frac{1}{n}\\sum_{i=1}^n (x_i - \\mu)^2$。\n\n请将您的推理建立在以下基本事实上：\n- 在浮点运算中，由于实数表示的有限精度模型，$n$ 项求和可能会产生舍入误差。在广泛使用的电气和电子工程师协会（IEEE）754 浮点算术标准中，加法和乘法等基本运算的结果会被舍入到最接近的可表示值。\n- 总体方差 $\\sigma^2$ 的定义需要均值 $\\mu$ 和离差平方和 $\\sum_{i=1}^n (x_i - \\mu)^2$。当 $x_i$ 和 $\\mu$ 的数值非常接近时，在减法 $x_i - \\mu$ 中可能会发生数值抵消。\n\n在单个程序中实现以下内容：\n- 一种双遍总体方差计算方法，该方法首先使用直接的从左到右求和来计算均值，然后在第二遍中使用直接的从左到右求和来计算离差平方和。在这两遍中，都使用机器的标准浮点算术，不采用任何特殊的稳定化技术。\n- 一种使用归功于 Welford 的经典递推关系的单遍在线总体方差计算方法，该方法在处理每个新样本时更新运行均值和二阶中心矩的运行累加器，不采用任何特殊的稳定化技术。\n- 一种单遍在线总体方差计算方法，该方法使用与 Welford 更新相同的结构，但在二阶中心矩分量的累加中集成了补偿求和（一个校正项），以减少运行总和中的舍入误差。\n\n对于所有这三种方法，计算相对于高精度参考方差的绝对误差。该参考方差的获取方式是：使用与二进制浮点表示完全相同的输入，但采用任意精度十进制算术来计算方差公式。为确保参考值与精确的浮点输入相对应，在计算方差之前，将每个浮点输入精确地转换为高精度十进制数；不要将这些数字重新解释为除其精确浮点表示之外的有理数或符号值。\n\n使用以下输入序列的测试套件，这些序列旨在检验抵消、尺度差异、对称性和边界行为：\n- 测试用例 1：$[10^{16}, 1.0, 1.0, 1.0, 10^{16} + 1.0]$。\n- 测试用例 2：$[1.0, 1.0, 1.0, 1.0, 1.0]$。\n- 测试用例 3：$[1.0 + 10^{-10}, 1.0 - 10^{-10}, 1.0 + 2 \\cdot 10^{-10}, 1.0 - 2 \\cdot 10^{-10}, 1.0, 1.0]$。\n- 测试用例 4：$[-10^{9}, 10^{9}, -3.0, 3.0, -2.0, 2.0, -1.0, 1.0]$。\n- 测试用例 5：$[123456789.0]$。\n\n对于每个测试用例，计算三个浮点结果：\n- 双遍总体方差的绝对误差。\n- 无补偿的 Welford 单遍总体方差的绝对误差。\n- 在二阶矩累加器中集成了补偿求和的 Welford 单遍总体方差的绝对误差。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，按测试用例和方法排序，即 $[e_{1, \\text{two-pass}}, e_{1, \\text{welford}}, e_{1, \\text{comp}}, e_{2, \\text{two-pass}}, e_{2, \\text{welford}}, e_{2, \\text{comp}}, \\ldots, e_{5, \\text{comp}}]$，其中每个 $e_{k, \\cdot}$ 是一个浮点绝对误差。不涉及物理单位。不涉及角度。所有答案均以浮点数表示。", "solution": "该问题要求实现并数值比较用于计算浮点数序列总体方差的三种不同算法。比较将基于每种方法相对于高精度参考计算的绝对误差。问题的核心在于理解和展示这些算法在有限精度算术中执行时固有的不同程度的数值稳定性。\n\n对于一个包含 $n$ 个数的有限序列 $\\{x_i\\}_{i=1}^n$，其均值为 $\\mu = \\frac{1}{n}\\sum_{i=1}^n x_i$，总体方差 $\\sigma^2$ 定义为与均值的离差平方的平均值：\n$$\n\\sigma^2 = \\frac{1}{n}\\sum_{i=1}^n (x_i - \\mu)^2\n$$\n在浮点运算中，直接计算此公式及其变体会因舍入误差和灾难性抵消而导致严重的精度损失。我们将分析三种数值稳健性递增的方法。\n\n**1. 双遍算法**\n\n这是对定义最直接的转写。它通过对数据进行两遍不同的处理来完成计算。\n\n- **第一遍：计算均值。** 通过对所有元素求和再除以计数 $n$ 来计算均值 $\\mu$：\n  $$\n  \\mu = \\frac{1}{n} \\sum_{i=1}^n x_i\n  $$\n- **第二遍：计算离差平方和。** 使用第一遍计算出的均值 $\\mu$，计算离差平方和 $S_2$：\n  $$\n  S_2 = \\sum_{i=1}^n (x_i - \\mu)^2\n  $$\n- **最终方差：** 方差即为 $\\sigma^2 = S_2 / n$。\n\n该方法主要的数值弱点是**灾难性抵消**。如果数据点 $x_i$ 紧密聚集，它们的值将非常接近均值 $\\mu$。此时，减法 $x_i - \\mu$ 将涉及两个几乎相等的数，导致结果带有巨大的相对误差和严重的精度损失。随后的平方和求和操作可能会加剧这个初始误差。此外，如果数据集中包含数量级差异巨大的数，第一遍的求和可能会遭受舍入误差的影响，导致均值 $\\mu$ 不准确，进而破坏整个第二遍的计算。\n\n**2. Welford 在线算法**\n\n该算法在单遍处理中计算方差，每当有新数据点到达时，就更新运行均值和离差平方和。这种“在线”特性对于处理流式数据非常有利。该算法基于以下递推关系。\n\n令 $M_k$ 为前 $k$ 个元素的运行均值，令 $S_k$ 为前 $k$ 个元素的运行离差平方和，即 $S_k = \\sum_{i=1}^k (x_i - M_k)^2$。对于第一个元素 $x_1$ 的初始条件是 $M_1 = x_1$ 和 $S_1 = 0$。对于后续元素 $k = 2, 3, \\ldots, n$，更新公式为：\n$$\nM_k = M_{k-1} + \\frac{x_k - M_{k-1}}{k}\n$$\n$$\nS_k = S_{k-1} + (x_k - M_{k-1})(x_k - M_k)\n$$\n在处理完所有 $n$ 个点后，总体方差为 $\\sigma^2 = S_n / n$。\n\nWelford 算法通常比双遍法具有更好的数值稳定性。它通过计算与*运行*均值（而非最终均值）的偏差来减轻灾难性抵消。与双遍法中的 $x_i - \\mu$ 相比，项 $x_k - M_{k-1}$ 成为两个几乎相等的大数相减的可能性较小，尤其是在数据存在漂移的情况下。然而，$S_k$ 的求和仍然可能受到累积舍入误差的影响，特别是当一个非常小的更新项被加到一个很大的运行总和 $S_{k-1}$ 上时。\n\n**3. 带补偿求和的 Welford 算法**\n\n为了进一步提高 Welford 算法中总和 $S_k$ 的准确性，我们可以采用一种补偿求和技术，例如 Kahan 求和算法。该方法会跟踪求和过程中每一步产生的舍入误差，并将其作为校正项并入下一步计算。\n\n对运行总和 $S_k$ 的更新修改如下，引入一个初始化为 $c_0 = 0$ 的校正项 $c_k$。对于每一步 $k$：\n1. 计算要加到平方和中的新项：\n   $$\n   \\text{term}_k = (x_k - M_{k-1})(x_k - M_k)\n   $$\n2. 并入上一步的校正项：\n   $$\n   y = \\text{term}_k - c_{k-1}\n   $$\n3. 将此校正后的项加到运行总和 $S_{k-1}$ 中。这个加法本身会引入新的误差：\n   $$\n   t = S_{k-1} + y\n   $$\n4. 计算新的校正项，它捕捉了上一次加法中丢失的低位比特：\n   $$\n   c_k = (t - S_{k-1}) - y\n   $$\n5. 更新总和：\n   $$\n   S_k = t\n   $$\n均值 $M_k$ 的更新保持不变。对 $S_k$ 的这种补偿求和有效地恢复了在浮点加法中本会丢失的精度，从而实现了离差平方和的高度精确累加。这种方法异常稳健，即使对于病态数据集也能提供准确的结果。\n\n**参考计算与误差度量**\n\n为了客观评估这三种方法的准确性，需要计算一个高精度的参考方差 $\\sigma^2_{\\text{reference}}$。实现方式如下：\n1. 获取输入的浮点数（例如 IEEE 754 `double` 精度）。\n2. 使用任意精度算术将每个数转换为其精确的十进制表示。Python 的 `decimal` 模块非常适合此任务。\n3. 使用这种高精度算术执行总体方差公式 $\\sigma^2 = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\mu)^2$ 的所有计算，并设置足够大的位数（例如 100 位），以使舍入误差可以忽略不计。\n\n然后，每个实现算法的性能通过与此参考值的绝对误差 $e$ 来量化：\n$$\ne = |\\sigma^2_{\\text{computed}} - \\sigma^2_{\\text{reference}}|\n$$\n这为每种计算方法在每个测试用例的特定条件下所造成的精度损失提供了一个直接的度量。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom decimal import Decimal, getcontext\n\ndef reference_variance(data: list[float]) -> float:\n    \"\"\"Computes population variance using high-precision decimal arithmetic.\"\"\"\n    n = len(data)\n    if n = 1:\n        return 0.0\n\n    getcontext().prec = 100  # Set high precision for reference calculation\n    d_data = [Decimal(str(x)) for x in data]\n    \n    mean = sum(d_data) / Decimal(n)\n    sum_sq_dev = sum((x - mean)**2 for x in d_data)\n    variance = sum_sq_dev / Decimal(n)\n    \n    return float(variance)\n\ndef two_pass_variance(x: np.ndarray) -> np.float64:\n    \"\"\"Computes population variance using a standard two-pass algorithm.\"\"\"\n    n = x.size\n    if n = 1:\n        return np.float64(0.0)\n    \n    # Pass 1: Compute mean\n    mean = np.sum(x) / n\n    \n    # Pass 2: Compute sum of squared deviations\n    sum_sq_dev = np.sum((x - mean)**2)\n    \n    return sum_sq_dev / n\n\ndef welford_variance(x: np.ndarray) -> np.float64:\n    \"\"\"Computes population variance using Welford's one-pass online algorithm.\"\"\"\n    n = x.size\n    if n = 1:\n        return np.float64(0.0)\n        \n    M = np.float64(0.0)  # Running mean\n    S = np.float64(0.0)  # Running sum of squared deviations\n    \n    for k, val in enumerate(x, 1):\n        M_old = M\n        M += (val - M_old) / k\n        S += (val - M_old) * (val - M)\n        \n    return S / n\n\ndef compensated_welford_variance(x: np.ndarray) -> np.float64:\n    \"\"\"\n    Computes population variance using Welford's algorithm with compensated summation\n    for the sum of squared deviations.\n    \"\"\"\n    n = x.size\n    if n = 1:\n        return np.float64(0.0)\n        \n    M = np.float64(0.0)  # Running mean\n    S = np.float64(0.0)  # Running sum of squared deviations\n    c = np.float64(0.0)  # Compensation for S\n    \n    for k, val in enumerate(x, 1):\n        # Update mean\n        M_old = M\n        M += (val - M) / k\n        \n        # Update sum of squares with compensation\n        term = (val - M_old) * (val - M)\n        y = term - c\n        t = S + y\n        c = (t - S) - y\n        S = t\n        \n    return S / n\n\ndef solve():\n    \"\"\"\n    Runs the variance comparison for the specified test cases and prints the\n    absolute errors in the required format.\n    \"\"\"\n    test_cases = [\n        [10**16, 1.0, 1.0, 1.0, 10**16 + 1.0],\n        [1.0, 1.0, 1.0, 1.0, 1.0],\n        [1.0 + 1e-10, 1.0 - 1e-10, 1.0 + 2e-10, 1.0 - 2e-10, 1.0, 1.0],\n        [-10**9, 10**9, -3.0, 3.0, -2.0, 2.0, -1.0, 1.0],\n        [123456789.0],\n    ]\n\n    results = []\n    for case in test_cases:\n        # It's crucial to first convert to np.float64 to simulate the\n        # exact inputs as they would be stored in standard double precision.\n        np_case = np.array(case, dtype=np.float64)\n        \n        # The reference must be computed from the list of python floats,\n        # which will be identical to np.float64 in value.\n        ref_var = reference_variance(case)\n\n        # Compute variance with each method\n        var_2pass = two_pass_variance(np_case)\n        var_welford = welford_variance(np_case)\n        var_comp = compensated_welford_variance(np_case)\n\n        # Calculate and store absolute errors\n        results.append(abs(var_2pass - ref_var))\n        results.append(abs(var_welford - ref_var))\n        results.append(abs(var_comp - ref_var))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3214603"}]}