{"hands_on_practices": [{"introduction": "Metropolis-Hastings算法的威力在于其简洁而优雅的接受准则，该准则保证了马尔可夫链能够收敛到目标分布。本练习将通过一个具体计算，让您深入理解接受概率这一驱动采样器决策的核心机制。通过完成这个基础步骤，您将亲身体会到算法如何评估并决定是接受还是拒绝新的提议状态 [@problem_id:1371728]。", "problem": "一位数据科学家正在实施马尔可夫链蒙特卡洛（MCMC）模拟，以从参数 $x$ 的后验概率分布中抽取样本。\n\n目标分布 $\\pi(x)$ 与参数负绝对值的指数成正比，即 $\\pi(x) \\propto \\exp(-|x|)$。\n\n该科学家使用 Metropolis 算法，其建议分布 $q(x'|x)$ 是对称的，即在给定当前状态 $x$ 的情况下建议新状态 $x'$ 的概率等于在给定 $x'$ 的情况下建议 $x$ 的概率（即 $q(x'|x) = q(x|x')$）。\n\n假设在模拟的某一步，马尔可夫链的当前状态是 $x = 1.5$。算法接着建议转移到一个新的候选状态 $x' = 2.0$。\n\n计算此特定转移的接受概率。你的答案应该是一个无量纲的实数。将最终答案四舍五入到四位有效数字。", "solution": "对于从 $x$ 到 $x'$ 的转移，当建议分布 $q(x'|x)=q(x|x')$ 对称时，Metropolis 接受概率为\n$$\n\\alpha(x \\to x')=\\min\\left(1,\\frac{\\pi(x')q(x|x')}{\\pi(x)q(x'|x)}\\right)=\\min\\left(1,\\frac{\\pi(x')}{\\pi(x)}\\right).\n$$\n给定目标分布 $\\pi(x)\\propto \\exp(-|x|)$，该比率可简化为\n$$\n\\frac{\\pi(x')}{\\pi(x)}=\\frac{\\exp(-|x'|)}{\\exp(-|x|)}=\\exp\\!\\left(-\\left(|x'|-|x|\\right)\\right).\n$$\n当 $x=1.5$ 且 $x'=2.0$ 时，我们有 $|x|=1.5$ 和 $|x'|=2.0$，所以\n$$\n\\frac{\\pi(x')}{\\pi(x)}=\\exp\\!\\left(-\\left(2.0-1.5\\right)\\right)=\\exp(-0.5).\n$$\n因此，\n$$\n\\alpha(x \\to x')=\\min\\left(1,\\exp(-0.5)\\right)=\\exp(-0.5).\n$$\n数值上，$\\exp(-0.5)\\approx 0.6065$（四舍五入到四位有效数字）。", "answer": "$$\\boxed{0.6065}$$", "id": "1371728"}, {"introduction": "一个有效的MCMC采样器不仅关乎最终的收敛性，更在于其对参数空间的探索效率。接受率是衡量此效率的关键诊断指标，但对其的解读可能与直觉相悖。这个练习 [@problem_id:2408757] 旨在探讨一个常见的悖论：为什么一个非常高的接受率通常标志着采样器性能不佳，以及在这种情况下应采取何种调整策略。", "problem": "考虑一个计算金融中的贝叶斯后验抽样问题，其中标量参数 $\\theta$ 表示在一个正态-正态共轭模型中某项资产的预期超额回报。为具体起见，假设后验密度是高斯分布，其密度正比于\n$$\n\\pi(\\theta) \\propto \\exp\\!\\left(-\\frac{(\\theta - \\mu)^2}{2\\sigma^2}\\right),\n$$\n其中 $\\mu$ 和 $\\sigma^2$ 已知。你实现了一个带有对称提议的随机游走 Metropolis–Hastings 算法\n$$\nq(\\theta' \\mid \\theta) = \\mathcal{N}(\\theta, \\tau^2),\n$$\n以及接受概率\n$$\n\\alpha(\\theta, \\theta') = \\min\\!\\left\\{1,\\ \\frac{\\pi(\\theta')}{\\pi(\\theta)}\\right\\}。\n$$\n在长时间运行后，你观察到平均接受率 $\\hat{a} \\approx 0.97$（即 $\\hat{a} \\approx 97\\%$）。关于这对状态空间探索的影响以及应采取的适当行动，以下哪些陈述是正确的？\n\nA. 非常高的接受率意味着低自相关性和良好的混合性，因此当前的提议尺度 $\\tau$ 应保持不变。\n\nB. 非常高的接受率通常表明 $\\tau$ 太小；尽管大多数提议都被接受，但每次迭代的预期跳跃平方非常小，这导致探索缓慢（高自相关性）。增加 $\\tau$ 以将接受率降低到中等水平（例如，在 1 维中约为 $0.44$），可以改善探索。\n\nC. 为了进一步改善探索并减少有限样本偏差，应该进一步减小 $\\tau$ 以将接受率推向接近 $1$。\n\nD. 对于一个平滑的、单峰的目标分布和一个对称的随机游走提议，当 $\\tau \\to 0$ 时，接受率趋于 $1$，但积分自相关时间趋于 $\\infty$，这意味着尽管几乎肯定会被接受，探索效果却很差。\n\nE. 链的平稳分布取决于 $\\tau$；当接受率非常高时，链的目标分布比 $\\pi(\\theta)$ 更集中，这解释了探索效果差的原因。", "solution": "必须首先验证问题陈述的科学性和逻辑完整性。\n\n### 第 1 步：提取已知信息\n问题提供了以下信息：\n-   **模型**：一个来自正态-正态共轭模型的贝叶斯后验抽样问题。\n-   **参数**：一个标量参数 $\\theta$。\n-   **目标后验密度**：$\\pi(\\theta) \\propto \\exp\\!\\left(-\\frac{(\\theta - \\mu)^2}{2\\sigma^2}\\right)$，其中 $\\mu$ 和 $\\sigma^2$ 是已知常数。这是一个高斯分布 $\\mathcal{N}(\\mu, \\sigma^2)$ 的密度。\n-   **算法**：随机游走 Metropolis-Hastings (RWMH)。\n-   **提议分布**：一个对称提议，$q(\\theta' \\mid \\theta) = \\mathcal{N}(\\theta, \\tau^2)$。参数 $\\tau$ 是提议尺度或步长。\n-   **接受概率**：$\\alpha(\\theta, \\theta') = \\min\\!\\left\\{1,\\ \\frac{\\pi(\\theta')}{\\pi(\\theta)}\\right\\}$。\n-   **经验观察**：长时间运行后的平均接受率是 $\\hat{a} \\approx 0.97$。\n\n### 第 2 步：使用提取的已知信息进行验证\n对问题进行严格验证。\n1.  **科学依据**：该问题描述了 Metropolis-Hastings 算法的一个典型应用，该算法是计算统计学和计量经济学中的一个基本工具。模型（高斯后验）和提议机制（高斯随机游走）构成了一个标准的教科书示例。该问题在科学上是合理的。\n2.  **良定性**：该问题要求对算法的一个特定的、明确定义的结果（$\\hat{a} \\approx 0.97$）进行解释。这引出了对采样器性能的诊断分析，这是 MCMC 实践中的一项标准任务。该问题是良定的。\n3.  **客观性**：该问题以精确的数学语言陈述，没有歧义或主观内容。\n4.  **完整性和一致性**：该问题提供了分析 MCMC 采样器性能所需的所有必要信息。没有矛盾之处。\n\n### 第 3 步：结论和行动\n问题陈述是有效的。这是一个计算统计学领域中良定的、有科学依据的问题。我将继续进行全面的推导和分析。\n\n### 求解推导\nMetropolis-Hastings 算法的目标是从一个难以直接抽样的概率分布 $\\pi(\\theta)$ 中生成一系列样本 $\\{\\theta_t\\}_{t=1}^N$。该算法构建了一个马尔可夫链，其平稳分布是目标分布 $\\pi(\\theta)$。对于任何有效的提议分布，包括指定的尺度 $\\tau > 0$ 的分布，该算法都保证以 $\\pi(\\theta)$ 为其平稳分布。然而，$\\tau$ 的选择会严重影响算法的效率，即链探索状态空间并收敛到此平稳分布的速率。\n\n效率取决于提议步长和接受概率之间的权衡。\n-   如果提议尺度 $\\tau$ 非常小，新的提议 $\\theta' = \\theta_t + \\epsilon$（其中 $\\epsilon \\sim \\mathcal{N}(0, \\tau^2)$）将非常接近当前状态 $\\theta_t$。因此，$\\pi(\\theta')$ 将非常接近 $\\pi(\\theta_t)$，比率 $\\frac{\\pi(\\theta')}{\\pi(\\theta_t)}$ 将接近 $1$，接受概率 $\\alpha(\\theta_t, \\theta')$ 也将接近 $1$。链几乎接受所有提议。然而，由于每一步都非常小，链移动得非常缓慢。这导致样本序列高度相关，从而对状态空间的探索效果很差。这被称为慢混合。\n-   如果提议尺度 $\\tau$ 非常大，新的提议 $\\theta'$ 很可能远离当前状态 $\\theta_t$。如果 $\\theta_t$ 位于高概率区域，$\\theta'$ 很可能落入概率低得多的区域（分布的尾部）。因此，比率 $\\frac{\\pi(\\theta')}{\\pi(\\theta_t)}$ 会非常小，导致接受概率很低。链会拒绝大多数提议，并在多次迭代中停留在同一状态 $\\theta_t$。这同样会导致高样本自相关和差的探索效果。\n\n观察到的平均接受率是 $\\hat{a} \\approx 0.97$。这个值非常高，表明算法正处于第一种情况：提议尺度 $\\tau$ 太小。虽然链在不断移动，但其步长太小以至于效率低下。\n\n最优调整旨在最大化采样器的效率，通常通过最小化样本的自相关性来实现。理论研究（例如 Roberts、Gelman 和 Gilks，1997）已经为 RWMH 算法确立了最优接受率。对于像本问题中的一维目标分布，最大化探索效率的最优接受率大约是 $0.44$。观察到的 $0.97$ 的接受率远非这个最优值，证实了采样器的调整很差。正确的做法是增加 $\\tau$ 以将接受率降低到最优范围。\n\n### 逐项分析\n\n**A. 非常高的接受率意味着低自相关性和良好的混合性，因此当前的提议尺度 $\\tau$ 应保持不变。**\n这个陈述有根本性的错误。非常高的接受率是提议步长过小的典型症状，这会导致微小、胆怯的移动。这使得链中连续的状态几乎相同，从而导致*高*自相关性和*差*的混合性。因此，保持 $\\tau$ 不变的建议是错误的。\n结论：**错误**。\n\n**B. 非常高的接受率通常表明 $\\tau$ 太小；尽管大多数提议都被接受，但每次迭代的预期跳跃平方非常小，这导致探索缓慢（高自相关性）。增加 $\\tau$ 以将接受率降低到中等水平（例如，在 1 维中约为 $0.44$），可以改善探索。**\n这个陈述完全正确。它准确地诊断了情况：$\\approx 0.97$ 的接受率表明 $\\tau$ 太小。它正确地指出了后果：链的跳跃非常小，导致探索缓慢，表现为高自相关性。它正确地给出了补救措施：增加 $\\tau$。最后，它正确地引用了 1 维问题中理论上的最优接受率 $\\approx 0.44$。这是标准的、教科书式的诊断和应对方法。\n结论：**正确**。\n\n**C. 为了进一步改善探索并减少有限样本偏差，应该进一步减小 $\\tau$ 以将接受率推向接近 $1$。**\n这个陈述建议的操作与正确的做法完全相反。如前所述，接近 $1$ 的接受率是效率低下的标志。进一步减小 $\\tau$ 只会加剧问题，使步长更小，探索更慢。这会增加而不是减少自相关性以及从链输出计算的任何统计估计量的方差。\n结论：**错误**。\n\n**D. 对于一个平滑的、单峰的目标分布和一个对称的随机游走提议，当 $\\tau \\to 0$ 时，接受率趋于 $1$，但积分自相关时间趋于 $\\infty$，这意味着尽管几乎肯定会被接受，探索效果却很差。**\n这是一个精确的理论陈述，它形式化了 $\\tau$ 非常小情况下的病态问题。当 $\\tau \\to 0$ 时，任何提议的步长 $\\theta' = \\theta + \\epsilon$ 都将无限接近于 $\\theta$。对于一个平滑的密度 $\\pi$，$\\pi(\\theta') \\approx \\pi(\\theta)$，所以接受率比值 $\\frac{\\pi(\\theta')}{\\pi(\\theta)} \\to 1$，因此接受率趋于 $1$。然而，此时链成为随机游走的离散近似。要探索一个固定大小的区域，所需的步数与 $1/\\tau^2$ 成比例。积分自相关时间（IACT），它衡量了与一个独立样本等价的相关样本数量，可以被证明与 $\\text{IACT} \\propto 1/\\tau^2$ 成比例。因此，当 $\\tau \\to 0$ 时，IACT $\\to \\infty$。这标志着高效探索的完全崩溃。这个陈述是 MCMC 最优缩放理论的基石。\n结论：**正确**。\n\n**E. 链的平稳分布取决于 $\\tau$；当接受率非常高时，链的目标分布比 $\\pi(\\theta)$ 更集中，这解释了探索效果差的原因。**\n这个陈述包含一个严重的概念性错误。Metropolis-Hastings 算法的构建是为了满足细致平衡条件 $\\pi(\\theta) K(\\theta'|\\theta) = \\pi(\\theta') K(\\theta|\\theta')$，其中 $K$ 是转移核。这个条件保证了马尔可夫链的平稳分布*恰好*是目标分布 $\\pi(\\theta)$。这个性质对任何有效的提议尺度 $\\tau > 0$ 都成立。参数 $\\tau$ 影响收敛到平稳分布的*速率*和采样器的*效率*，但它*不*改变目标分布本身。探索效果差是由于动力学缓慢，而不是因为目标分布错误。\n结论：**错误**。", "answer": "$$\\boxed{BD}$$", "id": "2408757"}, {"introduction": "在掌握了MCMC的核心机制和诊断原则之后，现在是时候为一个经典的统计任务构建一个完整的MCMC采样器了。本练习 [@problem_id:3250349] 将引导您实现一个Metropolis-Hastings算法，用以执行贝叶斯线性回归。您将需要从第一性原理出发，推导后验分布，并编写代码来估计模型参数，从而在一个实际的应用场景中综合运用提议、接受和采样器调优等关键概念。", "problem": "给定由独立同分布误差假设指定的线性观测模型：对于数据集中的每个索引 $i$，标量响应 $y_i$ 由以下方式生成\n$$\ny_i \\;=\\; m\\,x_i \\;+\\; b \\;+\\; \\epsilon_i,\n$$\n其中误差项 $\\epsilon_i$ 服从均值为零、方差为 $\\sigma^2$ 的高斯随机变量分布，即 $\\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$，并且不同 $i$ 之间的误差是独立的。参数 $m$ 和 $b$ 是未知的。假设独立的高斯先验 $m \\sim \\mathcal{N}(0,\\tau_m^2)$ 和 $b \\sim \\mathcal{N}(0,\\tau_b^2)$，其中先验标准差 $\\tau_m$ 和 $\\tau_b$ 是已知的。方差 $\\sigma^2$ 是已知的。\n\n从贝叶斯定理以及高斯似然和高斯先验密度的定义出发，推导出一个可实现的、关于给定观测数据 $(x_i,y_i)$ 和已知超参数 $(\\sigma,\\tau_m,\\tau_b)$ 的参数 $(m,b)$ 的未归一化后验密度对数的表达式。然后，为这两个参数实现一个带有对称高斯随机游走提议的 Metropolis–Hastings 马尔可夫链蒙特卡洛 (MCMC) 算法：\n- 提议 $m^\\star = m + \\eta_m$，其中 $\\eta_m \\sim \\mathcal{N}(0,s_m^2)$。\n- 提议 $b^\\star = b + \\eta_b$，其中 $\\eta_b \\sim \\mathcal{N}(0,s_b^2)$。\n- 根据基于未归一化后验密度之比的 Metropolis–Hastings 准则接受或拒绝 $(m^\\star,b^\\star)$。\n\n使用这些基础来为以下测试套件近似 $(m,b)$ 的后验分布。在每种情况下，观测响应 $y_i$ 必须在您的程序内部使用所提供的数据生成种子以及所述的真实参数和噪声水平来综合生成。然后，为马尔可夫链使用一个单独的种子，运行 MCMC 采样器，并在丢弃预烧期样本后报告 $m$ 和 $b$ 的后验均值。不需要进行抽样稀疏化。\n\n对于所有情况，假设初始状态 $(m_0,b_0)$ 为 $(0,0)$。对所有情况使用下面指定的相同的先验标准差 $\\tau_m=\\tau_b$。\n\n测试套件：\n- 情况 1 (理想路径)：\n  - 设计点：$x$ 是从 $-2.0$ 到 $2.0$ (含) 的 $n=20$ 个等距值。\n  - 真实值：$m_{\\text{true}}=2.0$, $b_{\\text{true}}=-1.0$。\n  - 噪声标准差：$\\sigma=0.5$。\n  - 先验标准差：$\\tau_m=\\tau_b=10.0$。\n  - 提议标准差：$s_m=0.02$, $s_b=0.05$。\n  - 数据生成种子：$11$。\n  - MCMC 种子：$101$。\n  - 总迭代次数：$20000$。\n  - 预烧期：$5000$。\n- 情况 2 (含两点的边界规模数据集和低噪声)：\n  - 设计点：$x=[-1.0,\\,1.0]$，其中 $n=2$。\n  - 真实值：$m_{\\text{true}}=-0.5$, $b_{\\text{true}}=2.0$。\n  - 噪声标准差：$\\sigma=0.1$。\n  - 先验标准差：$\\tau_m=\\tau_b=10.0$。\n  - 提议标准差：$s_m=0.005$, $s_b=0.01$。\n  - 数据生成种子：$22$。\n  - MCMC 种子：$202$。\n  - 总迭代次数：$30000$。\n  - 预烧期：$10000$。\n- 情况 3 (含噪观测)：\n  - 设计点：$x$ 是从 $0.0$ 到 $5.0$ (含) 的 $n=30$ 个等距值。\n  - 真实值：$m_{\\text{true}}=0.3$, $b_{\\text{true}}=4.0$。\n  - 噪声标准差：$\\sigma=5.0$。\n  - 先验标准差：$\\tau_m=\\tau_b=10.0$。\n  - 提议标准差：$s_m=0.05$, $s_b=0.20$。\n  - 数据生成种子：$33$。\n  - MCMC 种子：$303$。\n  - 总迭代次数：$25000$。\n  - 预烧期：$8000$。\n\n实现和输出要求：\n- 完全按照描述实现 Metropolis–Hastings 采样器，使用您推导出的未归一化后验密度的对数。\n- 对于每种情况，仅使用预烧期后的样本计算 $m$ 的后验均值和 $b$ 的后验均值。\n- 您的程序必须使用所述的真实参数和噪声水平以及给定的数据生成种子来生成综合的 $y$ 值，并且必须使用提供的 MCMC 种子进行采样。\n- 将每个后验均值四舍五入到恰好 $4$ 位小数。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，顺序为 $[m^{(1)}_{\\text{mean}},b^{(1)}_{\\text{mean}},m^{(2)}_{\\text{mean}},b^{(2)}_{\\text{mean}},m^{(3)}_{\\text{mean}},b^{(3)}_{\\text{mean}}]$，其中上标表示情况编号。例如，输出格式必须是带有方括号和逗号分隔小数的单行。\n\n注：\n- 如果存在任何角度，都将以弧度为单位；此处未使用角度。\n- 输出不需要物理单位。\n- 通过使用指定的伪随机数生成种子，确保所有计算都是确定性的。", "solution": "该问题要求实现一个 Metropolis-Hastings 马尔可夫链蒙特卡洛 (MCMC) 算法，以从简单线性回归模型的参数 $(m,b)$ 的后验分布中采样。该解决方案需要两个主要组成部分：目标概率密度函数的推导和 MCMC 采样器的实现。\n\n### 未归一化对数后验密度的推导\n\n该问题设定在贝叶斯框架内。根据贝叶斯定理，给定观测数据 $D = \\{(x_i, y_i)\\}_{i=1}^n$ 和已知超参数 $H = (\\sigma, \\tau_m, \\tau_b)$，参数 $(m,b)$ 的后验概率为：\n$$\np(m, b \\mid D, H) = \\frac{p(D \\mid m, b, \\sigma) p(m \\mid \\tau_m) p(b \\mid \\tau_b)}{p(D \\mid H)}\n$$\n其中 $p(D \\mid m, b, \\sigma)$ 是数据的似然， $p(m \\mid \\tau_m)$ 和 $p(b \\mid \\tau_b)$ 是参数的先验概率，而 $p(D \\mid H)$ 是边缘似然或证据，它充当归一化常数。对于像 Metropolis-Hastings 这样的 MCMC 方法，不需要归一化常数。我们可以使用与分子成比例的未归一化后验：\n$$\np(m, b \\mid D, H) \\propto p(D \\mid m, b, \\sigma) p(m \\mid \\tau_m) p(b \\mid \\tau_b)\n$$\n\n**1. 似然函数**\n线性观测模型为 $y_i = m x_i + b + \\epsilon_i$，其中误差项 $\\epsilon_i$ 从均值为零、方差为 $\\sigma^2$ 的正态分布中抽取，即 $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$。这意味着每个响应变量 $y_i$ 也服从正态分布：\n$$\ny_i \\mid m, b, x_i, \\sigma \\sim \\mathcal{N}(m x_i + b, \\sigma^2)\n$$\n单个观测 $(x_i, y_i)$ 的概率密度函数 (PDF) 为：\n$$\np(y_i \\mid m, b, x_i, \\sigma) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_i - (m x_i + b))^2}{2\\sigma^2}\\right)\n$$\n假设误差 $\\epsilon_i$ 是独立同分布 (i.i.d.) 的，整个数据集 $D$ 的似然是各个概率的乘积：\n$$\np(D \\mid m, b, \\sigma) = \\prod_{i=1}^n p(y_i \\mid m, b, x_i, \\sigma)\n$$\n\n**2. 先验分布**\n问题为参数 $m$ 和 $b$ 指定了独立的高斯先验：\n$$\nm \\sim \\mathcal{N}(0, \\tau_m^2) \\implies p(m \\mid \\tau_m) = \\frac{1}{\\sqrt{2\\pi\\tau_m^2}} \\exp\\left(-\\frac{m^2}{2\\tau_m^2}\\right)\n$$\n$$\nb \\sim \\mathcal{N}(0, \\tau_b^2) \\implies p(b \\mid \\tau_b) = \\frac{1}{\\sqrt{2\\pi\\tau_b^2}} \\exp\\left(-\\frac{b^2}{2\\tau_b^2}\\right)\n$$\n由于它们的独立性，联合先验是单个先验的乘积：$p(m, b \\mid \\tau_m, \\tau_b) = p(m \\mid \\tau_m) p(b \\mid \\tau_b)$。\n\n**3. 未归一化对数后验**\n为了数值稳定性和计算方便，通常使用后验密度的对数。未归一化后验的对数，我们表示为 $\\mathcal{L}_{un}(m,b)$，是：\n$$\n\\mathcal{L}_{un}(m,b) = \\log\\left[ p(D \\mid m, b, \\sigma) p(m \\mid \\tau_m) p(b \\mid \\tau_b) \\right] = \\log p(D \\mid m, b, \\sigma) + \\log p(m \\mid \\tau_m) + \\log p(b \\mid \\tau_b)\n$$\n让我们展开每一项，去掉任何不依赖于 $m$ 或 $b$ 的加法常数：\n对数似然项是：\n$$\n\\log p(D \\mid m, b, \\sigma) = \\sum_{i=1}^n \\log p(y_i \\mid m, b, x_i, \\sigma) = \\sum_{i=1}^n \\left( \\log\\left(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\right) - \\frac{(y_i - (m x_i + b))^2}{2\\sigma^2} \\right)\n$$\n忽略常数项 $\\sum_{i=1}^n \\log(1/\\sqrt{2\\pi\\sigma^2})$，我们得到：\n$$\n\\log p(D \\mid m, b, \\sigma) \\propto -\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - m x_i - b)^2\n$$\n对数先验项是：\n$$\n\\log p(m \\mid \\tau_m) \\propto -\\frac{m^2}{2\\tau_m^2} \\quad \\text{和} \\quad \\log p(b \\mid \\tau_b) \\propto -\\frac{b^2}{2\\tau_b^2}\n$$\n结合这些项，得到未归一化对数后验密度的最终表达式：\n$$\n\\mathcal{L}_{un}(m,b) = -\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - m x_i - b)^2 - \\frac{m^2}{2\\tau_m^2} - \\frac{b^2}{2\\tau_b^2}\n$$\n这个表达式是我们需要在 MCMC 算法中求值的函数。第一项与负的残差平方和成正比，第二和第三项是源于高斯先验的正则化项 (L2 正则化)。\n\n### Metropolis-Hastings 算法\n\nMetropolis-Hastings 算法用于生成一系列样本，这些样本构成一个马尔可夫链，其平稳分布是所需的目标后验分布 $p(m, b \\mid D, H)$。该算法过程如下：\n\n1.  **初始化**：从一个初始状态 $(m_0, b_0)$ 开始链。问题指定 $(m_0, b_0) = (0,0)$。\n\n2.  **迭代**：对于每一步 $t=1, 2, \\dots, N_{\\text{total}}$：\n    a.  **提议**：给定当前状态 $(m_t, b_t)$，从一个提议分布 $Q((m^\\star, b^\\star) \\mid (m_t, b_t))$ 中提议一个新的状态 $(m^\\star, b^\\star)$。问题指定了一个对称高斯随机游走提议：\n        $$\n        m^\\star = m_t + \\eta_m, \\quad \\text{其中} \\quad \\eta_m \\sim \\mathcal{N}(0, s_m^2)\n        $$\n        $$\n        b^\\star = b_t + \\eta_b, \\quad \\text{其中} \\quad \\eta_b \\sim \\mathcal{N}(0, s_b^2)\n        $$\n    b.  **接受概率**：计算接受概率 $\\alpha$，即移动到提议状态 $(m^\\star, b^\\star)$ 的概率：\n        $$\n        \\alpha = \\min\\left(1, \\frac{p(m^\\star, b^\\star \\mid D, H)}{p(m_t, b_t \\mid D, H)} \\cdot \\frac{Q((m_t, b_t) \\mid (m^\\star, b^\\star))}{Q((m^\\star, b^\\star) \\mid (m_t, b_t))}\\right)\n        $$\n        由于提议分布是对称的（即，从状态 A 提议移动到 B 的概率与从 B 移动到 A 的概率相同），提议密度的比率（Hastings 比率）为 $1$。接受概率简化为 Metropolis 准则：\n        $$\n        \\alpha = \\min\\left(1, \\frac{p(m^\\star, b^\\star \\mid D, H)}{p(m_t, b_t \\mid D, H)}\\right)\n        $$\n        为避免数值下溢，这使用对数概率计算：\n        $$\n        \\log(\\text{ratio}) = \\mathcal{L}_{un}(m^\\star, b^\\star) - \\mathcal{L}_{un}(m_t, b_t)\n        $$\n        $$\n        \\alpha = \\min(1, \\exp(\\log(\\text{ratio})))\n        $$\n    c.  **接受或拒绝**：从均匀分布 $U(0,1)$ 中生成一个随机数 $u$。如果 $u  \\alpha$，则接受提议，下一个状态为 $(m_{t+1}, b_{t+1}) = (m^\\star, b^\\star)$。否则，拒绝提议，链保持在其当前状态，$(m_{t+1}, b_{t+1}) = (m_t, b_t)$。\n\n3.  **分析**：在链运行 $N_{\\text{total}}$ 次迭代后，丢弃链的初始部分（预烧期，$N_{\\text{burn-in}}$），以使链收敛到其平稳分布。然后通过计算预烧期后样本的算术平均值来估计 $m$ 和 $b$ 的后验均值：\n    $$\n    \\hat{m}_{\\text{mean}} = \\frac{1}{N_{\\text{total}} - N_{\\text{burn-in}}} \\sum_{t=N_{\\text{burn-in}}+1}^{N_{\\text{total}}} m_t\n    $$\n    $$\n    \\hat{b}_{\\text{mean}} = \\frac{1}{N_{\\text{total}} - N_{\\text{burn-in}}} \\sum_{t=N_{\\text{burn-in}}+1}^{N_{\\text{total}}} b_t\n    $$\n此过程将应用于问题陈述中指定的三个测试用例中的每一个。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements a Metropolis-Hastings MCMC sampler for Bayesian linear regression\n    and applies it to three test cases.\n    \"\"\"\n\n    test_cases = [\n        # Case 1 (happy path)\n        {\n            \"n\": 20, \"x_range\": [-2.0, 2.0],\n            \"m_true\": 2.0, \"b_true\": -1.0, \"sigma\": 0.5,\n            \"tau_m\": 10.0, \"tau_b\": 10.0,\n            \"s_m\": 0.02, \"s_b\": 0.05,\n            \"data_seed\": 11, \"mcmc_seed\": 101,\n            \"total_iterations\": 20000, \"burn_in\": 5000\n        },\n        # Case 2 (boundary-size dataset with two points and low noise)\n        {\n            \"n\": 2, \"x_manual\": np.array([-1.0, 1.0]),\n            \"m_true\": -0.5, \"b_true\": 2.0, \"sigma\": 0.1,\n            \"tau_m\": 10.0, \"tau_b\": 10.0,\n            \"s_m\": 0.005, \"s_b\": 0.01,\n            \"data_seed\": 22, \"mcmc_seed\": 202,\n            \"total_iterations\": 30000, \"burn_in\": 10000\n        },\n        # Case 3 (noisy observations)\n        {\n            \"n\": 30, \"x_range\": [0.0, 5.0],\n            \"m_true\": 0.3, \"b_true\": 4.0, \"sigma\": 5.0,\n            \"tau_m\": 10.0, \"tau_b\": 10.0,\n            \"s_m\": 0.05, \"s_b\": 0.20,\n            \"data_seed\": 33, \"mcmc_seed\": 303,\n            \"total_iterations\": 25000, \"burn_in\": 8000\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        # Generate synthetic data\n        rng_data = np.random.default_rng(case[\"data_seed\"])\n        \n        if \"x_manual\" in case:\n            x = case[\"x_manual\"]\n        else:\n            x = np.linspace(case[\"x_range\"][0], case[\"x_range\"][1], case[\"n\"])\n            \n        noise = rng_data.normal(0, case[\"sigma\"], size=case[\"n\"])\n        y = case[\"m_true\"] * x + case[\"b_true\"] + noise\n\n        # Define the unnormalized log posterior function\n        def log_unnormalized_posterior(m, b, x, y, sigma, tau_m, tau_b):\n            residuals = y - (m * x + b)\n            sum_sq_residuals = np.sum(residuals**2)\n            log_likelihood = -0.5 * sum_sq_residuals / (sigma**2)\n            log_prior = -0.5 * (m**2 / tau_m**2 + b**2 / tau_b**2)\n            return log_likelihood + log_prior\n\n        # Initialize MCMC\n        rng_mcmc = np.random.default_rng(case[\"mcmc_seed\"])\n        m_curr, b_curr = 0.0, 0.0\n        \n        m_samples = np.zeros(case[\"total_iterations\"])\n        b_samples = np.zeros(case[\"total_iterations\"])\n        \n        log_post_curr = log_unnormalized_posterior(\n            m_curr, b_curr, x, y, case[\"sigma\"], case[\"tau_m\"], case[\"tau_b\"])\n\n        # Run MCMC sampler\n        for i in range(case[\"total_iterations\"]):\n            # Propose new parameters\n            m_prop = m_curr + rng_mcmc.normal(0, case[\"s_m\"])\n            b_prop = b_curr + rng_mcmc.normal(0, case[\"s_b\"])\n            \n            # Calculate log posterior of proposed parameters\n            log_post_prop = log_unnormalized_posterior(\n                m_prop, b_prop, x, y, case[\"sigma\"], case[\"tau_m\"], case[\"tau_b\"])\n            \n            # Calculate acceptance ratio\n            log_ratio = log_post_prop - log_post_curr\n            alpha = np.min([1.0, np.exp(log_ratio)])\n            \n            # Accept or reject\n            if rng_mcmc.uniform(0, 1)  alpha:\n                m_curr = m_prop\n                b_curr = b_prop\n                log_post_curr = log_post_prop\n            \n            m_samples[i] = m_curr\n            b_samples[i] = b_curr\n            \n        # Post-processing: discard burn-in and compute posterior means\n        post_burn_in_m = m_samples[case[\"burn_in\"]:]\n        post_burn_in_b = b_samples[case[\"burn_in\"]:]\n        \n        m_mean = np.mean(post_burn_in_m)\n        b_mean = np.mean(post_burn_in_b)\n        \n        results.extend([m_mean, b_mean])\n\n    # Format and print the final output\n    formatted_results = \",\".join([f\"{r:.4f}\" for r in results])\n    print(f\"[{formatted_results}]\")\n\nsolve()\n```", "id": "3250349"}]}