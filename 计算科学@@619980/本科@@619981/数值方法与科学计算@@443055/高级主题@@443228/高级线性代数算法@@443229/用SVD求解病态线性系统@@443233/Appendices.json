{"hands_on_practices": [{"introduction": "理解一个概念的最好方法之一是亲手构建它。这个练习将指导你从奇异值分解（SVD）的基本定义出发，构造一个具有特定奇异值分布的矩阵。通过这个过程，你将直观地感受到奇异值的巨大差异如何导致极高的条件数，从而深刻理解矩阵的病态性及其对数值计算稳定性的影响。[@problem_id:3280607]", "problem": "设矩阵 $A \\in \\mathbb{R}^{5 \\times 5}$ 通过奇异值分解 (SVD) 构造，即 $A = U \\Sigma V^{\\top}$，其中 $U \\in \\mathbb{R}^{5 \\times 5}$ 和 $V \\in \\mathbb{R}^{5 \\times 5}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{5 \\times 5}$ 是对角矩阵，其对角线上的非负元素为 $\\sigma_{1} \\ge \\sigma_{2} \\ge \\cdots \\ge \\sigma_{5} \\ge 0$。\n\n你的任务是设计一个矩阵 $A$，使其奇异值包含两个分离良好的簇：三个奇异值为 $1$，两个奇异值为 $10^{-16}$。然后分析相应线性系统的条件数。\n\n任务：\n1. 仅使用 SVD 和正交矩阵的定义，通过指定 $U$、$\\Sigma$ 和 $V$ 的有效选择，显式地构造一个这样的矩阵 $A$，以实现所要求的奇异值聚类。解释为什么你的构造确实具有所需的奇异值。\n2. 从向量 2-范数和诱导矩阵 2-范数的定义出发，并仅使用正交变换的性质，推导一个非奇异矩阵的 2-范数条件数 $\\kappa_{2}(A)$ 的表达式，该表达式用 $A$ 的奇异值表示。\n3. 为你构造的矩阵精确计算 $\\kappa_{2}(A)$。将最终结果表示为单个数字。无需四舍五入。", "solution": "所述问题具有科学依据、适定且客观。所有必要信息均已提供，任务逻辑结构清晰，可利用线性代数和数值分析的既定原理解答。因此，该问题被认为是有效的。\n\n解答分为三部分，对应题目陈述中的三个任务。\n\n### 第 1 部分：构造矩阵 $A$\n\n题目要求构造一个形式为 $A = U \\Sigma V^{\\top}$ 的矩阵 $A \\in \\mathbb{R}^{5 \\times 5}$，其中 $U$ 和 $V$ 是正交矩阵，$\\Sigma$ 是奇异值对角矩阵。指定的奇异值是三个 $1$ 和两个 $10^{-16}$。按照惯例，奇异值沿 $\\Sigma$ 的对角线按非递增顺序排列。\n\n设奇异值为 $\\sigma_1, \\sigma_2, \\sigma_3, \\sigma_4, \\sigma_5$。根据题目要求，我们必须有：\n$$\n\\sigma_1 = \\sigma_2 = \\sigma_3 = 1\n$$\n$$\n\\sigma_4 = \\sigma_5 = 10^{-16}\n$$\n这些值都是非负的，满足奇异值的定义。因此，矩阵 $\\Sigma \\in \\mathbb{R}^{5 \\times 5}$ 定义为：\n$$\n\\Sigma = \\text{diag}(1, 1, 1, 10^{-16}, 10^{-16}) =\n\\begin{pmatrix}\n1  & 0  & 0  & 0  & 0 \\\\\n0  & 1  & 0  & 0  & 0 \\\\\n0  & 0  & 1  & 0  & 0 \\\\\n0  & 0  & 0  & 10^{-16}  & 0 \\\\\n0  & 0  & 0  & 0  & 10^{-16}\n\\end{pmatrix}\n$$\n题目要求为正交矩阵 $U$ 和 $V$ 指定有效的选择。正交矩阵最简单的选择是单位矩阵 $I_5 \\in \\mathbb{R}^{5 \\times 5}$。如果 $Q^{\\top}Q = I$，则矩阵 $Q$ 是正交的。对于单位矩阵，$I_5^{\\top}I_5 = I_5 I_5 = I_5$，所以它确实是正交的。\n\n我们选择 $U = I_5$ 和 $V = I_5$。\n\n通过这些选择，矩阵 $A$ 构造如下：\n$$\nA = U \\Sigma V^{\\top} = I_5 \\Sigma I_5^{\\top} = \\Sigma\n$$\n因此，一个满足给定条件的矩阵 $A$ 是：\n$$\nA =\n\\begin{pmatrix}\n1  & 0  & 0  & 0  & 0 \\\\\n0  & 1  & 0  & 0  & 0 \\\\\n0  & 0  & 1  & 0  & 0 \\\\\n0  & 0  & 0  & 10^{-16}  & 0 \\\\\n0  & 0  & 0  & 0  & 10^{-16}\n\\end{pmatrix}\n$$\n根据定义，一个矩阵的奇异值是其奇异值分解中 $\\Sigma$ 矩阵的对角元素。我们的构造 $A = I_5 \\Sigma I_5^{\\top}$ 是一个有效的 SVD，并且 $\\Sigma$ 的对角元素正是题目所要求的值。因此，这个构造是有效的，并实现了所期望的奇异值聚类。\n\n### 第 2 部分：条件数表达式的推导\n\n非奇异矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 的 2-范数条件数定义为 $\\kappa_2(A) = \\|A\\|_2 \\|A^{-1}\\|_2$。诱导矩阵 2-范数定义为 $\\|A\\|_2 = \\max_{\\|x\\|_2=1} \\|Ax\\|_2$，其中 $\\|x\\|_2 = \\sqrt{x^{\\top}x}$ 是欧几里得向量范数。\n\n设 $A$ 的奇异值分解为 $A = U \\Sigma V^{\\top}$，其中 $U, V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\Sigma = \\text{diag}(\\sigma_1, \\sigma_2, \\dots, \\sigma_n)$ 且 $\\sigma_1 \\ge \\sigma_2 \\ge \\dots \\ge \\sigma_n \\ge 0$。\n\n首先，我们推导 $\\|A\\|_2$ 的表达式。考虑向量 $x$ 满足 $\\|x\\|_2 = 1$ 时的范数平方 $\\|Ax\\|_2^2$：\n$$\n\\|Ax\\|_2^2 = \\|U \\Sigma V^{\\top} x\\|_2^2\n$$\n由于 $U$ 是正交矩阵，它保持 2-范数不变，即对于任意向量 $y$，都有 $\\|Uy\\|_2 = \\|y\\|_2$。应用此性质，我们得到：\n$$\n\\|Ax\\|_2^2 = \\|\\Sigma V^{\\top} x\\|_2^2\n$$\n我们定义一个新向量 $y = V^{\\top} x$。由于 $V$ 是正交的，$V^{\\top}$ 也是正交的。因此，$V^{\\top}$ 也保持 2-范数不变：$\\|y\\|_2 = \\|V^{\\top} x\\|_2 = \\|x\\|_2 = 1$。当 $x$ 遍历所有单位长度的向量时，对应的向量 $y$ 也遍历所有单位长度的向量。因此，求 $\\|A\\|_2$ 的问题等价于求 $\\|y\\|_2=1$ 时 $\\|\\Sigma y\\|_2$ 的最大值。\n\n我们展开 $\\|\\Sigma y\\|_2^2$：\n$$\n\\|\\Sigma y\\|_2^2 = (\\Sigma y)^{\\top}(\\Sigma y) = y^{\\top}\\Sigma^{\\top}\\Sigma y = y^{\\top}\\Sigma^2 y\n$$\n因为 $\\Sigma$ 是对角矩阵，所以 $\\Sigma^2 = \\text{diag}(\\sigma_1^2, \\sigma_2^2, \\dots, \\sigma_n^2)$。该表达式变成一个加权和：\n$$\n\\|\\Sigma y\\|_2^2 = \\sum_{i=1}^{n} \\sigma_i^2 y_i^2\n$$\n我们希望在约束条件 $\\|y\\|_2^2 = \\sum_{i=1}^{n} y_i^2 = 1$ 下最大化这个量。由于奇异值是按顺序排列的 $\\sigma_1^2 \\ge \\sigma_2^2 \\ge \\dots \\ge \\sigma_n^2$，我们可以建立一个上界：\n$$\n\\sum_{i=1}^{n} \\sigma_i^2 y_i^2 \\le \\sigma_1^2 \\sum_{i=1}^{n} y_i^2 = \\sigma_1^2 \\cdot 1 = \\sigma_1^2\n$$\n当 $y$ 是第一个标准基向量 $e_1 = (1, 0, \\dots, 0)^{\\top}$ 时，达到这个最大值。\n因此，$\\max_{\\|y\\|_2=1} \\|\\Sigma y\\|_2^2 = \\sigma_1^2$，这意味着 $\\|A\\|_2 = \\sqrt{\\sigma_1^2} = \\sigma_1$。这是 $A$ 的最大奇异值，记为 $\\sigma_{\\max}(A)$。所以，$\\|A\\|_2 = \\sigma_{\\max}(A)$。\n\n接下来，我们推导 $\\|A^{-1}\\|_2$ 的表达式。由于 $A$ 是非奇异的，它的所有奇异值都必须是严格正的：$\\sigma_n > 0$。$A$ 的逆是：\n$$\nA^{-1} = (U \\Sigma V^{\\top})^{-1} = (V^{\\top})^{-1} \\Sigma^{-1} U^{-1} = V \\Sigma^{-1} U^{\\top}\n$$\n这个表达式是 $A^{-1}$ 的一个有效 SVD，其中正交矩阵是 $V$ 和 $U$，对角矩阵是 $\\Sigma^{-1} = \\text{diag}(1/\\sigma_1, 1/\\sigma_2, \\dots, 1/\\sigma_n)$。$A^{-1}$ 的奇异值是 $\\Sigma^{-1}$ 的对角元素。为了找到 $A^{-1}$ 的最大奇异值，我们必须在 $\\{1/\\sigma_i\\}$ 中找到最大的元素。由于 $\\sigma_1 \\ge \\sigma_2 \\ge \\dots \\ge \\sigma_n > 0$，可以得出 $1/\\sigma_n \\ge 1/\\sigma_{n-1} \\ge \\dots \\ge 1/\\sigma_1 > 0$。\n$A^{-1}$ 的最大奇异值是 $\\sigma_{\\max}(A^{-1}) = 1/\\sigma_n$，它是 $A$ 的最小奇异值 $\\sigma_{\\min}(A)$ 的倒数。\n\n使用我们为矩阵的 2-范数推导出的结果，我们有：\n$$\n\\|A^{-1}\\|_2 = \\sigma_{\\max}(A^{-1}) = \\frac{1}{\\sigma_{\\min}(A)}\n$$\n最后，我们结合这些结果来求条件数 $\\kappa_2(A)$：\n$$\n\\kappa_2(A) = \\|A\\|_2 \\|A^{-1}\\|_2 = \\sigma_{\\max}(A) \\cdot \\frac{1}{\\sigma_{\\min}(A)} = \\frac{\\sigma_{\\max}(A)}{\\sigma_{\\min}(A)}\n$$\n这就是用 $A$ 的奇异值表示的 2-范数条件数的所求表达式。\n\n### 第 3 部分：计算 $\\kappa_2(A)$\n\n对于第 1 部分中构造的矩阵 $A$，其奇异值为：\n$$\n\\sigma_1 = 1, \\quad \\sigma_2 = 1, \\quad \\sigma_3 = 1, \\quad \\sigma_4 = 10^{-16}, \\quad \\sigma_5 = 10^{-16}\n$$\n最大奇异值为 $\\sigma_{\\max}(A) = \\sigma_1 = 1$。\n最小奇异值为 $\\sigma_{\\min}(A) = \\sigma_5 = 10^{-16}$。\n矩阵 $A$ 是非奇异的，因为它的最小奇异值大于 $0$。\n\n使用第 2 部分推导的公式，我们构造的矩阵 $A$ 的 2-范数条件数为：\n$$\n\\kappa_2(A) = \\frac{\\sigma_{\\max}(A)}{\\sigma_{\\min}(A)} = \\frac{1}{10^{-16}} = 10^{16}\n$$\n这个条件数非常大，表明使用此矩阵 $A$ 的线性系统 $Ax=b$ 是严重病态的。$b$ 中的小扰动可能导致解 $x$ 的巨大变化，这是由其最大和最小奇异值之间的巨大比率所解释的典型行为。", "answer": "$$\\boxed{10^{16}}$$", "id": "3280607"}, {"introduction": "在了解了奇异值如何导致病态问题之后，我们将探究一个在现实世界中常见的病态来源：数据中的信息冗余。本练习模拟了机器学习或统计建模中一个特征被重复复制的情景，你将分析这如何导致一个零奇异值的出现。更重要的是，你将推导并理解 Moore-Penrose 伪逆是如何通过在重复特征间平均分配权重，来给出一个稳定且有意义的最小范数解。[@problem_id:3280708]", "problem": "考虑一个线性回归设计矩阵，其具有两个特征，由矩阵 $A_{0} \\in \\mathbb{R}^{3 \\times 2}$ 的列表示，\n$$\nA_{0} = \\begin{pmatrix}\n1  & 0 \\\\\n0  & 1 \\\\\n0  & 0\n\\end{pmatrix}.\n$$\n现在通过复制 $A_{0}$ 的第一列来构造一个新矩阵 $A \\in \\mathbb{R}^{3 \\times 3}$，使得\n$$\nA = \\begin{pmatrix}\n1  & 1  & 0 \\\\\n0  & 0  & 1 \\\\\n0  & 0  & 0\n\\end{pmatrix}.\n$$\n设观测响应向量为\n$$\n\\mathbf{b} = \\begin{pmatrix}\n2 \\\\\n3 \\\\\n0\n\\end{pmatrix}.\n$$\n从奇异值分解 (SVD) 和 Moore-Penrose 伪逆的核心定义出发，分析复制一个特征（列）如何影响矩阵的奇异值和条件数。推导 $A$ 的显式奇异值分解，识别与重复特征的零空间相关联的零奇异值和右奇异向量，并用此求得 $A \\mathbf{x} = \\mathbf{b}$ 的最小范数最小二乘解 $\\mathbf{x}^{+}$。从第一性原理出发，解释伪逆如何在重复的列之间重新分配权重。\n\n作为最终答案，报告最小范数最小二乘解的第一个分量 $x_{1}^{+}$ 的值。无需四舍五入，不涉及单位。", "solution": "用户想要分析一个由设计矩阵中特征重复引起的病态线性系统。这需要推导奇异值分解 (SVD)，用它来计算 Moore-Penrose 伪逆，并找到最小范数最小二乘解。\n\n### 第 1 步：提取已知条件\n问题提供了以下数据：\n- 初始设计矩阵 $A_{0} \\in \\mathbb{R}^{3 \\times 2}$：\n$$\nA_{0} = \\begin{pmatrix}\n1  & 0 \\\\\n0  & 1 \\\\\n0  & 0\n\\end{pmatrix}\n$$\n- 新的设计矩阵 $A \\in \\mathbb{R}^{3 \\times 3}$，通过复制 $A_{0}$ 的第一列形成：\n$$\nA = \\begin{pmatrix}\n1  & 1  & 0 \\\\\n0  & 0  & 1 \\\\\n0  & 0  & 0\n\\end{pmatrix}\n$$\n- 观测响应向量 $\\mathbf{b} \\in \\mathbb{R}^{3}$：\n$$\n\\mathbf{b} = \\begin{pmatrix}\n2 \\\\\n3 \\\\\n0\n\\end{pmatrix}\n$$\n\n### 第 2 步：使用提取的已知条件进行验证\n该问题在科学上和数学上是合理的。这是一个适定的数值线性代数练习，特别关注秩亏矩阵的 SVD 和 Moore-Penrose 伪逆。所提供的数据是自洽且一致的。矩阵 $A$ 的列线性相关（$\\text{col}_1 = \\text{col}_2$），使其成为奇异矩阵，这是旨在测试病态条件处理能力的问题核心。所有术语都是标准的且客观定义的。因此，该问题是有效的。\n\n### 第 3 步：结论与行动\n问题有效。将提供完整解答。\n\n### 求解推导\n\n核心任务是找到系统 $A\\mathbf{x} = \\mathbf{b}$ 的最小范数最小二乘解 $\\mathbf{x}^{+}$。该解由 $\\mathbf{x}^{+} = A^{+}\\mathbf{b}$ 给出，其中 $A^{+}$ 是 $A$ 的 Moore-Penrose 伪逆。我们可以从 $A$ 的奇异值分解 (SVD) $A = U \\Sigma V^\\top$ 计算 $A^{+}$。\n\n**1. 计算 $A$ 的 SVD**\n\nSVD 需要找到矩阵 $U$、$\\Sigma$ 和 $V$。我们从计算 $A^\\top A$ 开始。\n$$\nA^\\top = \\begin{pmatrix}\n1  & 0  & 0 \\\\\n1  & 0  & 0 \\\\\n0  & 1  & 0\n\\end{pmatrix}\n$$\n$$\nA^\\top A = \\begin{pmatrix}\n1  & 0  & 0 \\\\\n1  & 0  & 0 \\\\\n0  & 1  & 0\n\\end{pmatrix}\n\\begin{pmatrix}\n1  & 1  & 0 \\\\\n0  & 0  & 1 \\\\\n0  & 0  & 0\n\\end{pmatrix}\n= \\begin{pmatrix}\n1  & 1  & 0 \\\\\n1  & 1  & 0 \\\\\n0  & 0  & 1\n\\end{pmatrix}\n$$\n$A$ 的奇异值 $\\sigma_i$ 是 $A^\\top A$ 的特征值 $\\lambda_i$ 的平方根。$V$ 的列是相应的归一化特征向量。我们通过求解特征方程 $\\det(A^\\top A - \\lambda I) = 0$ 来找到特征值。\n$$\n\\det \\begin{pmatrix}\n1-\\lambda  & 1  & 0 \\\\\n1  & 1-\\lambda  & 0 \\\\\n0  & 0  & 1-\\lambda\n\\end{pmatrix} = (1-\\lambda) \\left[ (1-\\lambda)^2 - 1 \\right] = 0\n$$\n$$\n(1-\\lambda) (\\lambda^2 - 2\\lambda + 1 - 1) = 0\n$$\n$$\n(1-\\lambda) (\\lambda^2 - 2\\lambda) = 0\n$$\n$$\n\\lambda (1-\\lambda) (\\lambda - 2) = 0\n$$\n特征值为 $\\lambda_1 = 2$，$\\lambda_2 = 1$，和 $\\lambda_3 = 0$。\n奇异值是它们的平方根，从大到小排列：\n$\\sigma_1 = \\sqrt{2}$，$\\sigma_2 = \\sqrt{1} = 1$，$\\sigma_3 = \\sqrt{0} = 0$。\n矩阵 $\\Sigma$ 是一个以这些奇异值为对角线元素的 $3 \\times 3$ 对角矩阵：\n$$\n\\Sigma = \\begin{pmatrix}\n\\sqrt{2}  & 0  & 0 \\\\\n0  & 1  & 0 \\\\\n0  & 0  & 0\n\\end{pmatrix}\n$$\n现在，我们求 $A^\\top A$ 的特征向量以构成 $V$ 的列。\n\n- 对于 $\\lambda_1 = 2$：$(A^\\top A - 2I)\\mathbf{v}_1 = \\mathbf{0}$\n$$\n\\begin{pmatrix}\n-1  & 1  & 0 \\\\\n1  & -1  & 0 \\\\\n0  & 0  & -1\n\\end{pmatrix}\n\\begin{pmatrix} x \\\\ y \\\\ z \\end{pmatrix} = \\mathbf{0} \\implies\n\\begin{cases} -x+y=0 \\\\ z=0 \\end{cases}\n$$\n一个特征向量是 $\\begin{pmatrix} 1  & 1  & 0 \\end{pmatrix}^\\top$。将其归一化得到 $\\mathbf{v}_1 = \\begin{pmatrix} 1/\\sqrt{2}  & 1/\\sqrt{2}  & 0 \\end{pmatrix}^\\top$。\n\n- 对于 $\\lambda_2 = 1$：$(A^\\top A - 1I)\\mathbf{v}_2 = \\mathbf{0}$\n$$\n\\begin{pmatrix}\n0  & 1  & 0 \\\\\n1  & 0  & 0 \\\\\n0  & 0  & 0\n\\end{pmatrix}\n\\begin{pmatrix} x \\\\ y \\\\ z \\end{pmatrix} = \\mathbf{0} \\implies\n\\begin{cases} y=0 \\\\ x=0 \\end{cases}\n$$\n一个特征向量是 $\\begin{pmatrix} 0  & 0  & 1 \\end{pmatrix}^\\top$。它已经是归一化的，所以 $\\mathbf{v}_2 = \\begin{pmatrix} 0  & 0  & 1 \\end{pmatrix}^\\top$。\n\n- 对于 $\\lambda_3 = 0$：$(A^\\top A - 0I)\\mathbf{v}_3 = \\mathbf{0}$\n$$\n\\begin{pmatrix}\n1  & 1  & 0 \\\\\n1  & 1  & 0 \\\\\n0  & 0  & 1\n\\end{pmatrix}\n\\begin{pmatrix} x \\\\ y \\\\ z \\end{pmatrix} = \\mathbf{0} \\implies\n\\begin{cases} x+y=0 \\\\ z=0 \\end{cases}\n$$\n一个特征向量是 $\\begin{pmatrix} 1  & -1  & 0 \\end{pmatrix}^\\top$。将其归一化得到 $\\mathbf{v}_3 = \\begin{pmatrix} 1/\\sqrt{2}  & -1/\\sqrt{2}  & 0 \\end{pmatrix}^\\top$。这个向量张成了 $A$ 的零空间，并表示前两列之间的线性相关性。\n\n组合这些归一化的特征向量，我们得到 $V$：\n$$\nV = \\begin{pmatrix}\n\\mathbf{v}_1  & \\mathbf{v}_2  & \\mathbf{v}_3\n\\end{pmatrix} =\n\\begin{pmatrix}\n1/\\sqrt{2}  & 0  & 1/\\sqrt{2} \\\\\n1/\\sqrt{2}  & 0  & -1/\\sqrt{2} \\\\\n0  & 1  & 0\n\\end{pmatrix}\n$$\n对于 $\\sigma_i > 0$，$U$ 的列由 $\\mathbf{u}_i = \\frac{1}{\\sigma_i} A \\mathbf{v}_i$ 给出。\n$$\n\\mathbf{u}_1 = \\frac{1}{\\sqrt{2}} A \\mathbf{v}_1 = \\frac{1}{\\sqrt{2}} \\begin{pmatrix}\n1  & 1  & 0 \\\\\n0  & 0  & 1 \\\\\n0  & 0  & 0\n\\end{pmatrix}\n\\begin{pmatrix} 1/\\sqrt{2} \\\\ 1/\\sqrt{2} \\\\ 0 \\end{pmatrix}\n= \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 2/\\sqrt{2} \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\n$$\n\\mathbf{u}_2 = \\frac{1}{1} A \\mathbf{v}_2 = \\begin{pmatrix}\n1  & 1  & 0 \\\\\n0  & 0  & 1 \\\\\n0  & 0  & 0\n\\end{pmatrix}\n\\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix}\n= \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}\n$$\n因为 $U$ 必须是正交矩阵，$\\mathbf{u}_3$ 必须是与 $\\mathbf{u}_1$ 和 $\\mathbf{u}_2$ 正交的单位向量。显而易见的选择是 $\\mathbf{u}_3 = \\begin{pmatrix} 0  & 0  & 1 \\end{pmatrix}^\\top$。这个向量张成了 $A^\\top$ 的零空间。\n$$\nU = \\begin{pmatrix}\n\\mathbf{u}_1  & \\mathbf{u}_2  & \\mathbf{u}_3\n\\end{pmatrix} =\n\\begin{pmatrix}\n1  & 0  & 0 \\\\\n0  & 1  & 0 \\\\\n0  & 0  & 1\n\\end{pmatrix} = I\n$$\n\n**2. 计算伪逆 $A^{+}$**\n\n伪逆 $A^{+}$ 由 $A^{+} = V \\Sigma^{+} U^\\top$ 给出。矩阵 $\\Sigma^{+}$ 是通过对 $\\Sigma$ 中的非零奇异值取倒数，然后转置得到的。\n$$\n\\Sigma^{+} = \\begin{pmatrix}\n1/\\sqrt{2}  & 0  & 0 \\\\\n0  & 1  & 0 \\\\\n0  & 0  & 0\n\\end{pmatrix}\n$$\n因为 $U = I$，所以我们有 $U^\\top = I$。\n$$\nA^{+} = V \\Sigma^{+} I = V \\Sigma^{+} = \n\\begin{pmatrix}\n1/\\sqrt{2}  & 0  & 1/\\sqrt{2} \\\\\n1/\\sqrt{2}  & 0  & -1/\\sqrt{2} \\\\\n0  & 1  & 0\n\\end{pmatrix}\n\\begin{pmatrix}\n1/\\sqrt{2}  & 0  & 0 \\\\\n0  & 1  & 0 \\\\\n0  & 0  & 0\n\\end{pmatrix}\n$$\n$$\nA^{+} = \\begin{pmatrix}\n(1/\\sqrt{2})(1/\\sqrt{2})  & 0  & 0 \\\\\n(1/\\sqrt{2})(1/\\sqrt{2})  & 0  & 0 \\\\\n0  & 1  & 0\n\\end{pmatrix}\n= \\begin{pmatrix}\n1/2  & 0  & 0 \\\\\n1/2  & 0  & 0 \\\\\n0  & 1  & 0\n\\end{pmatrix}\n$$\n\n**3. 计算最小范数最小二乘解 $\\mathbf{x}^{+}$**\n\n解是 $\\mathbf{x}^{+} = A^{+} \\mathbf{b}$。\n$$\n\\mathbf{x}^{+} = \\begin{pmatrix}\n1/2  & 0  & 0 \\\\\n1/2  & 0  & 0 \\\\\n0  & 1  & 0\n\\end{pmatrix}\n\\begin{pmatrix}\n2 \\\\\n3 \\\\\n0\n\\end{pmatrix}\n= \\begin{pmatrix}\n(1/2)(2) + (0)(3) + (0)(0) \\\\\n(1/2)(2) + (0)(3) + (0)(0) \\\\\n(0)(2) + (1)(3) + (0)(0)\n\\end{pmatrix}\n= \\begin{pmatrix}\n1 \\\\\n1 \\\\\n3\n\\end{pmatrix}\n$$\n所以最小范数最小二乘解是 $\\mathbf{x}^{+} = \\begin{pmatrix} 1  & 1  & 3 \\end{pmatrix}^\\top$。第一个分量是 $x_1^{+} = 1$。\n\n**4. 权重重新分配的解释**\n\n使用 $A_0$ 的原始问题将有两个特征的系数。对于 $A_0 \\mathbf{x}' = \\mathbf{b}$ 的最小二乘解，会将系数 $2$ 分配给第一个特征，将系数 $3$ 分配给第二个特征。\n\n在修改后的问题 $A\\mathbf{x}=\\mathbf{b}$ 中，第一个特征现在由两个相同的列（$A$ 的第一列和第二列）表示，其关联的系数为 $x_1$ 和 $x_2$。第二个特征由第三列表示，其系数为 $x_3$。第一个特征对模型的总贡献是 $(x_1 + x_2)$ 乘以该特征向量。\n\n最小二乘问题的正规方程是 $A^\\top A \\mathbf{x} = A^\\top \\mathbf{b}$。\n$$\n\\begin{pmatrix}\n1  & 1  & 0 \\\\\n1  & 1  & 0 \\\\\n0  & 0  & 1\n\\end{pmatrix}\n\\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix}\n=\n\\begin{pmatrix}\n1  & 0  & 0 \\\\\n1  & 0  & 0 \\\\\n0  & 1  & 0\n\\end{pmatrix}\n\\begin{pmatrix} 2 \\\\ 3 \\\\ 0 \\end{pmatrix}\n=\n\\begin{pmatrix} 2 \\\\ 2 \\\\ 3 \\end{pmatrix}\n$$\n这给出了方程组：\n$$\n\\begin{cases}\nx_1 + x_2 = 2 \\\\\nx_1 + x_2 = 2 \\\\\nx_3 = 3\n\\end{cases}\n$$\n这定义了一个最小二乘解的仿射子空间。对于任何标量 $c$，形式为 $\\mathbf{x}_{LS} = \\begin{pmatrix} c  & 2-c  & 3 \\end{pmatrix}^\\top$ 的任何向量都能最小化残差范数 $\\|A\\mathbf{x} - \\mathbf{b}\\|$。\n\nMoore-Penrose 伪逆从此子空间中选择具有最小欧几里得范数 $\\|\\mathbf{x}_{LS}\\|$ 的唯一解。我们需要最小化 $\\|\\mathbf{x}_{LS}\\|^2 = c^2 + (2-c)^2 + 3^2$。\n$$\nf(c) = c^2 + 4 - 4c + c^2 + 9 = 2c^2 - 4c + 13\n$$\n为了找到最小值，我们将导数设为零：$f'(c) = 4c - 4 = 0$，得到 $c=1$。\n将 $c=1$ 代回，得到最小范数解：\n$$\n\\mathbf{x}^{+} = \\begin{pmatrix} 1  & 2-1  & 3 \\end{pmatrix}^\\top = \\begin{pmatrix} 1  & 1  & 3 \\end{pmatrix}^\\top\n$$\n这证实了我们从 SVD 得到的结果。第一个特征的总系数权重为 $2$，它被平均分配到两个重复的列上（$x_1^{+} = 1$, $x_2^{+} = 1$），因为这种配置在约束条件 $x_1+x_2=2$ 下最小化了范数 $x_1^2+x_2^2$。这是伪逆解对于具有重复特征问题的一个普遍性质。\n\n最终要求的值是该解的第一个分量 $x_1^{+}$。", "answer": "$$\\boxed{1}$$", "id": "3280708"}, {"introduction": "理论和解析解是理想化的，但真实世界的数据总是伴随着噪声。这个编码练习将理论付诸实践，让你模拟一个现实场景。你将亲眼观察到测量中的微小噪声是如何被微小的奇异值灾难性地放大，并验证截断奇异值分解（TSVD）作为一种正则化方法，如何通过过滤掉这些不稳定的分量来提供一个稳健的近似解。[@problem_id:3280674]", "problem": "给定一个由实数矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 和右端向量 $b \\in \\mathbb{R}^{n}$ 表示的方形、病态线性系统。目标是研究对于一个固定的截断水平 $k$，当 $b$ 中的噪声水平增加时，$A x = b$ 的截断奇异值分解 (TSVD) 解的质量如何下降。您的程序必须是一个完整且可运行的实现，能够构造一个特定的病态矩阵，生成可控的带噪右端项，计算 TSVD 解，并在一组预定义的测试套件上报告解质量的定量度量。\n\n使用以下基本基础和设置：\n- 对于任意实数矩阵 $A$，奇异值分解 (SVD) 定义为 $A = U \\Sigma V^{\\top}$，其中 $U$ 和 $V$ 是正交矩阵，$\\Sigma$ 是对角元素为非负的对角矩阵。\n- 对于固定的截断水平 $k$，TSVD 解定义为通过限制在 $A$ 的前 $k$ 个主导奇异分量上获得的最小二乘解。\n- 矩阵 $A$ 通过指定快速衰减的奇异值来构造成病态矩阵。\n\n遵循以下确定性构造步骤：\n1. 选择问题规模 $n=30$，并固定截断水平 $k=10$。\n2. 将正交矩阵 $U \\in \\mathbb{R}^{n \\times n}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 构造为两个独立的、$n \\times n$ 大小的矩阵的QR分解得到的Q因子。这两个矩阵的元素均为独立同分布的标准正态分布。为确保两个矩阵的确定性，请使用固定的伪随机种子，其中 $U$ 的种子为 $0$，$V$ 的种子为 $1$。\n3. 为 $i = 1, 2, \\dots, n$ 定义奇异值 $\\sigma_i = 10^{-\\frac{i-1}{2}}$，并构成对角矩阵 $\\Sigma = \\operatorname{diag}(\\sigma_1, \\dots, \\sigma_n)$。\n4. 设置 $A = U \\Sigma V^{\\top}$。\n5. 通过 $x_{\\text{true},i} = \\frac{1}{i}$（$i = 1, 2, \\dots, n$）定义真实解向量 $x_{\\text{true}} \\in \\mathbb{R}^{n}$，并计算无噪声的右端项 $b_{\\text{clean}} = A x_{\\text{true}}$。\n6. 固定一个确定性的噪声方向 $z \\in \\mathbb{R}^{n}$，该向量由种子为 $7$ 的标准正态分布生成，并归一化为单位欧几里得范数，即 $z \\leftarrow z / \\|z\\|_2$。\n7. 对于每个噪声比例 $\\eta$，定义带噪右端项 $b(\\eta) = b_{\\text{clean}} + \\eta \\|b_{\\text{clean}}\\|_2 \\, z$。\n\n为每个 $b(\\eta)$ 实现秩为 $k$ 的 TSVD 解，并使用相对解误差来量化解的质量：\n$$\ne(\\eta) = \\frac{\\|x_k(\\eta) - x_{\\text{true}}\\|_2}{\\|x_{\\text{true}}\\|_2},\n$$\n其中 $x_k(\\eta)$ 表示从 $b(\\eta)$ 在截断水平 $k$ 下得到的 TSVD 解。\n\n测试套件：\n- 使用以下噪声比例 $\\eta$ 集合来探测不同区间，包括一个边界情况和逐渐增大的噪声幅度：\n$$\n\\{\\eta_1, \\eta_2, \\eta_3, \\eta_4, \\eta_5, \\eta_6\\} = \\{0.0, 10^{-8}, 10^{-4}, 10^{-2}, 10^{-1}, 1.0\\}.\n$$\n\n最终输出格式：\n- 您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表，列表项根据测试套件中的噪声比例排序：\n$$\n[e(\\eta_1), e(\\eta_2), e(\\eta_3), e(\\eta_4), e(\\eta_5), e(\\eta_6)].\n$$\n- 输出为无量纲浮点数，不涉及任何物理单位。", "solution": "所提出的问题是一个适定且确定性的数值实验，旨在研究使用截断奇异值分解 (TSVD) 求解病态线性系统时，噪声对解的影响。该问题的验证是成功的，因为它在数值线性代数方面具有科学依据，提供了一套完整且一致的指令，并且其表述是客观的。因此，我们可以着手提供一个完整的解决方案。\n\n问题的核心在于求解线性系统 $A x = b$，其中 $A \\in \\mathbb{R}^{n \\times n}$ 是一个病态矩阵，$x \\in \\mathbb{R}^{n}$ 是未知向量，$b \\in \\mathbb{R}^{n}$ 是观测向量。\n\n矩阵 $A$ 的奇异值分解 (SVD) 为分析和求解提供了必要的框架。SVD 由 $A = U \\Sigma V^{\\top}$ 给出，其中 $U, V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵 ($U^{\\top}U = I$, $V^{\\top}V = I$)，$\\Sigma \\in \\mathbb{R}^{n \\times n}$ 是一个对角矩阵，其对角线上的元素为非负、非递增的条目 $\\sigma_1 \\ge \\sigma_2 \\ge \\dots \\ge \\sigma_n \\ge 0$。这些条目是 $A$ 的奇异值。$U$ 的列是左奇异向量，$V$ 的列是右奇异向量。\n\n将 SVD 代入线性系统得到 $U \\Sigma V^{\\top} x = b$。通过分离 $x$ 可以推导出其形式解：\n$$\nx = V \\Sigma^{-1} U^{\\top} b\n$$\n这可以表示为求和形式：\n$$\nx = \\sum_{i=1}^{n} \\frac{u_i^{\\top} b}{\\sigma_i} v_i\n$$\n其中 $u_i$ 和 $v_i$ 分别是 $U$ 和 $V$ 的第 $i$ 列。\n\n如果一个矩阵的条件数 $\\kappa(A) = \\sigma_1 / \\sigma_n$ 非常大，则该矩阵是病态的。这种情况发生在奇异值快速衰减，导致 $\\sigma_n$ 接近于零时。从解的求和形式可以明显看出，右端项 $b$ 在左奇异向量 $u_i$ 上的任何分量都会被因子 $1/\\sigma_i$ 放大。如果 $\\sigma_i$ 很小，这种放大会非常巨大。在实际应用中，向量 $b$ 常常被噪声污染，即 $b = b_{\\text{clean}} + \\delta b$。噪声项 $\\delta b$ 不可避免地会被微小的奇异值放大，从而淹没真实解。\n\n问题指定奇异值为 $\\sigma_i = 10^{-\\frac{i-1}{2}}$，$i=1, \\dots, n$。当 $n=30$ 时，条件数为 $\\kappa(A) = \\sigma_1 / \\sigma_{30} = 10^0 / 10^{-29/2} = 10^{14.5}$，这表明矩阵是严重病态的。\n\n截断SVD (TSVD) 是一种用于对抗这种噪声放大的正则化方法。它不是使用全部 $n$ 个奇异分量，而是在一个水平 $k < n$ 处截断求和。TSVD 解（记为 $x_k$）定义为：\n$$\nx_k = \\sum_{i=1}^{k} \\frac{u_i^{\\top} b}{\\sigma_i} v_i\n$$\n这等价于使用 $A$ 的截断伪逆 $A_k^{\\dagger} = V_k \\Sigma_k^{-1} U_k^{\\top}$，其中 $U_k$ 和 $V_k$ 分别包含 $U$ 和 $V$ 的前 $k$ 列，$\\Sigma_k$ 是 $\\Sigma$ 的前导 $k \\times k$ 子矩阵。解则为 $x_k = A_k^{\\dagger} b$。通过丢弃 $i > k$ 的项，我们滤除了与小奇异值 $\\sigma_{k+1}, \\dots, \\sigma_n$ 相关的不稳定分量。$k$ 的选择至关重要：它必须足够小以确保稳定性，但又要足够大以捕获解的关键特征。\n\n该问题构建了一个特定的、可复现的场景来观察这种行为。\n1. 设置问题维度 $n=30$ 和截断水平 $k=10$。\n2. 从两个特定随机矩阵的 QR 分解中构造确定性的正交矩阵 $U$ 和 $V$，通过固定的种子（$0$ 和 $1$）确保可复现性。\n3. 使用指定的奇异值 $\\sigma_i = 10^{-\\frac{i-1}{2}}$ 构造矩阵 $A = U \\Sigma V^{\\top}$。\n4. 定义真实解 $x_{\\text{true}}$，其分量为 $x_{\\text{true},i} = 1/i$。\n5. 计算相应的“无噪声”右端项 $b_{\\text{clean}} = A x_{\\text{true}}$。\n6. 生成一个确定性的噪声向量 $z$（使用种子 $7$）并将其归一化。\n7. 对于一组噪声比例 $\\eta \\in \\{0.0, 10^{-8}, 10^{-4}, 10^{-2}, 10^{-1}, 1.0\\}$，创建一系列带噪右端项 $b(\\eta) = b_{\\text{clean}} + \\eta \\|b_{\\text{clean}}\\|_2 \\, z$。\n\n对于每个 $\\eta$，我们使用固定的截断水平 $k=10$ 计算 TSVD 解 $x_k(\\eta)$：\n$$\nx_k(\\eta) = \\sum_{i=1}^{k} \\frac{u_i^{\\top} b(\\eta)}{\\sigma_i} v_i\n$$\n该解的质量通过相对解误差来衡量：\n$$\ne(\\eta) = \\frac{\\|x_k(\\eta) - x_{\\text{true}}\\|_2}{\\|x_{\\text{true}}\\|_2}\n$$\n误差 $e(\\eta)$ 来自两个来源：\n-   **截断（或正则化）误差**：即使在没有噪声（$\\eta=0$）的情况下也存在的误差。它是由丢弃 $x_{\\text{true}}$ 中对应于奇异值 $\\sigma_{k+1}, \\dots, \\sigma_n$ 的分量引起的。这个误差是 $e(0)=\\|x_k(0) - x_{\\text{true}}\\|_2 / \\|x_{\\text{true}}\\|_2$。\n-   **噪声传播误差**：由噪声项 $\\eta \\|b_{\\text{clean}}\\|_2 \\, z$ 的放大所产生的误差。这部分误差随 $\\eta$ 的增大而增大。\n\n实现将系统地遵循这些步骤。对于测试套件中的每个 $\\eta$ 值，我们将构造 $b(\\eta)$，使用 TSVD 公式计算 $x_k(\\eta)$，并计算相对误差 $e(\\eta)$。最终输出将是这些误差的列表，展示解的质量如何随着噪声水平的增加而下降。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes TSVD solutions and their errors for an ill-conditioned system\n    with varying noise levels in the right-hand-side vector.\n    \"\"\"\n    # 1. Choose problem size n and truncation level k.\n    n = 30\n    k = 10\n\n    # 2. Construct orthogonal matrices U and V.\n    # Use fixed seeds for determinism.\n    rng_u = np.random.default_rng(seed=0)\n    matrix_for_u = rng_u.standard_normal(size=(n, n))\n    U, _ = np.linalg.qr(matrix_for_u)\n\n    rng_v = np.random.default_rng(seed=1)\n    matrix_for_v = rng_v.standard_normal(size=(n, n))\n    V, _ = np.linalg.qr(matrix_for_v)\n\n    # 3. Define singular values sigma_i and form diagonal matrix Sigma.\n    # sigma_i = 10^(-(i-1)/2) for i = 1, ..., n\n    indices = np.arange(n)\n    sigmas = 10.0**(-0.5 * indices)\n    Sigma = np.diag(sigmas)\n\n    # 4. Set A = U * Sigma * V^T.\n    A = U @ Sigma @ V.T\n\n    # 5. Define the true solution vector x_true and compute b_clean.\n    # x_true_i = 1/i for i = 1, ..., n\n    x_true = 1.0 / np.arange(1, n + 1)\n    b_clean = A @ x_true\n\n    # 6. Fix a deterministic noise direction z.\n    rng_z = np.random.default_rng(seed=7)\n    z = rng_z.standard_normal(size=n)\n    z /= np.linalg.norm(z)\n\n    # Test Suite: noise fractions.\n    noise_fractions = [0.0, 1e-8, 1e-4, 1e-2, 1e-1, 1.0]\n    \n    results = []\n    \n    # Pre-calculate components for TSVD solution for efficiency.\n    U_k = U[:, :k]\n    V_k = V[:, :k]\n    sigmas_k_inv = 1.0 / sigmas[:k]\n    norm_x_true = np.linalg.norm(x_true)\n    norm_b_clean = np.linalg.norm(b_clean)\n\n    for eta in noise_fractions:\n        # 7. Define the noisy right-hand-side b(eta).\n        b_eta = b_clean + eta * norm_b_clean * z\n\n        # Implement the TSVD solution at rank k.\n        # x_k(eta) = V_k @ (diag(1/sigma_i) @ U_k.T @ b_eta)\n        # The inner part is a component-wise multiplication.\n        x_k_eta = V_k @ (sigmas_k_inv * (U_k.T @ b_eta))\n        \n        # Quantify solution quality using relative solution error.\n        error = np.linalg.norm(x_k_eta - x_true) / norm_x_true\n        results.append(error)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3280674"}]}