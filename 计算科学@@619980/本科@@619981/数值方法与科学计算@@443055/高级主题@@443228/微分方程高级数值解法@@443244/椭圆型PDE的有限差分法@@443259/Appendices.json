{"hands_on_practices": [{"introduction": "本练习是学习有限差分法的基石。你将亲手实现二维泊松方程的标准五点差分格式，并利用无矩阵共轭梯度法求解。更重要的是，本练习将引导你通过数值实验来验证方法的理论收敛阶，这是验证任何数值代码正确性的关键技能，同时你也会观察到精确解的光滑度如何影响收敛效果。[@problem_id:3228788]", "problem": "考虑单位正方形区域 $\\Omega = (0,1) \\times (0,1)$ 上的二维泊松方程，其带有狄利克雷边界条件，\n$$\n-\\Delta u(x,y) = f(x,y) \\quad \\text{在 } \\Omega \\text{ 内}, \n\\qquad\nu(x,y) = g(x,y) \\quad \\text{在 } \\partial\\Omega \\text{ 上}.\n$$\n从二维拉普拉斯算子的定义以及由泰勒展开推导出的经典二阶导数中心差分近似出发。仅使用这些基本原理，推导在网格间距为 $h = 1/N$ 的均匀网格上，对于内部节点 $(x_i,y_j) = (ih,jh)$（其中 $i,j \\in \\{1,\\dots,N-1\\}$）的标准五点有限差分法：\n$$\n\\frac{4u_{i,j} - u_{i-1,j} - u_{i+1,j} - u_{i,j-1} - u_{i,j+1}}{h^2} = f_{i,j},\n$$\n其中 $\\partial\\Omega$ 上的边界值 $u_{i,j}$ 由 $g(x,y)$ 指定。解释为什么在 $u \\in C^4(\\overline{\\Omega})$ 的假设下，局部截断误差为 $\\mathcal{O}(h^2)$，以及离散极值原理如何导出全局误差界 $\\lVert u - u_h \\rVert_\\infty = \\mathcal{O}(h^2)$。\n\n接下来，实现一个求解该格式产生的离散线性系统的求解器，该求解器使用共轭梯度迭代法处理与五点格式相关的对称正定矩阵。求解器必须是无矩阵的：通过格式直接将离散算子应用于网格函数，并通过将已知的边界贡献加到右端项来处理狄利克雷边界数据。使用基于残差范数相对于右端项范数减小到用户指定容差的停止准则。\n\n您将为两个精确解验证误差估计和观察到的收敛率。在每种情况下，在 $\\partial \\Omega$ 上设 $g(x,y) = u(x,y)$，在 $\\Omega$ 内设 $f(x,y) = -\\Delta u(x,y)$。对于每个网格尺寸，计算离散解 $u_h$，将其嵌入到包括边界节点的完整网格中，并计算最大范数误差\n$$\nE(h) = \\max_{0 \\le i,j \\le N} \\left| u(x_i,y_j) - u_h(x_i,y_j) \\right|.\n$$\n给定一个网格间距列表 $\\{h_k\\}$及其对应的误差 $\\{E(h_k)\\}$，在关系式 $\\log E(h) \\approx \\log C + p \\log h$ 中，将实验收敛阶（EOC）估计为最小二乘斜率 $p$。\n\n使用以下两个精确解：\n- 光滑解：$u_s(x,y) = \\sin(\\pi x)\\sin(\\pi y)$，对于此解，$f_s(x,y) = 2\\pi^2 \\sin(\\pi x)\\sin(\\pi y)$ 且 $g_s = u_s$。\n- 奇异解：$u_{sg}(x,y) = r^\\alpha$，其中 $\\alpha = 3/2$ 且 $r = \\sqrt{x^2 + y^2}$。对于此解，当 $r>0$ 时，有 $\\Delta u_{sg}(x,y) = \\alpha^2 r^{\\alpha - 2}$，因此 $f_{sg}(x,y) = -\\alpha^2 r^{\\alpha - 2}$ 且 $g_{sg} = u_{sg}$。如果需要，可通过连续性定义 $f_{sg}(0,0)$；请注意 $(0,0)$ 是一个边界点，因此不是内部节点。\n\n设计一个程序，执行以下测试套件，并报告每种情况下的 EOC：\n- 情况 A（理想情况，光滑且分辨率良好）：对 $u_s$ 使用 $N \\in \\{8,16,32,64\\}$。\n- 情况 B（正则性降低，在边界角点附近奇异）：对 $u_{sg}$ 和 $\\alpha = 3/2$ 使用 $N \\in \\{8,16,32,64\\}$。\n- 情况 C（边界粗分辨率边缘情况）：对 $u_s$ 使用 $N \\in \\{4,8,16\\}$。\n\n您的程序必须实现五点法、无矩阵共轭梯度求解器、最大范数误差计算以及最小二乘 EOC 估算。对于每种情况，对 $\\log E(h)$ 与 $\\log h$ 进行线性回归，并报告估计的斜率 $p$。\n\n不涉及物理单位。所有角度（如果存在）均以弧度为单位。最终输出必须是单行，包含情况 A、B 和 C 的三个 EOC 估计值的逗号分隔列表，四舍五入到三位小数并用方括号括起来，顺序为 [A,B,C]。例如，如果三个估计阶为 $p_A$、$p_B$ 和 $p_C$，您的程序应输出形如 $[p_A,p_B,p_C]$ 的单行。", "solution": "该问题是有效的，因为它代表了偏微分方程数值分析中一个适定、标准的练习，植根于已建立的数学原理。它是自洽的、客观的，并且其要求是可以用算法形式化的。\n\n该任务涉及推导泊松方程的五点有限差分格式，分析其误差，并实现一个无矩阵共轭梯度求解器来计算两种不同测试用例的实验收敛阶（EOC）。\n\n### 第一部分：五点格式的推导\n\n我们从单位正方形 $\\Omega = (0,1) \\times (0,1)$ 上的二维泊松方程开始：\n$$\n-\\Delta u(x,y) = f(x,y)\n$$\n其中 $\\Delta u = \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2}$ 是拉普拉斯算子。该区域使用均匀网格进行离散化，两个方向的网格间距均为 $h=1/N$。网格点为 $(x_i, y_j) = (ih, jh)$，其中整数 $i,j \\in \\{0, 1, \\dots, N\\}$。我们寻求近似值 $u_{i,j} \\approx u(x_i, y_j)$。\n\n有限差分法的核心是使用泰勒级数展开来近似导数。考虑一个足够光滑的函数 $u(x,y)$ 在点 $(x_i, y_j)$ 附近的展开：\n$$\nu(x_i \\pm h, y_j) = u(x_i, y_j) \\pm h \\frac{\\partial u}{\\partial x}(x_i, y_j) + \\frac{h^2}{2} \\frac{\\partial^2 u}{\\partial x^2}(x_i, y_j) \\pm \\frac{h^3}{6} \\frac{\\partial^3 u}{\\partial x^3}(x_i, y_j) + \\frac{h^4}{24} \\frac{\\partial^4 u}{\\partial x^4}(x_i, y_j) + \\mathcal{O}(h^5)\n$$\n将 $u(x_{i+1}, y_j)$ 和 $u(x_{i-1}, y_j)$ 的展开式相加：\n$$\nu(x_{i+1}, y_j) + u(x_{i-1}, y_j) = 2u(x_i, y_j) + h^2 \\frac{\\partial^2 u}{\\partial x^2}(x_i, y_j) + \\frac{h^4}{12} \\frac{\\partial^4 u}{\\partial x^4}(x_i, y_j) + \\mathcal{O}(h^6)\n$$\n重新整理以求解关于 $x$ 的二阶偏导数，得到二阶中心差分近似：\n$$\n\\frac{\\partial^2 u}{\\partial x^2}(x_i, y_j) = \\frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{h^2} - \\frac{h^2}{12} \\frac{\\partial^4 u}{\\partial x^4}(x_i, y_j) + \\mathcal{O}(h^4)\n$$\n对 $y$ 方向进行相同的论证：\n$$\n\\frac{\\partial^2 u}{\\partial y^2}(x_i, y_j) = \\frac{u_{i,j+1} - 2u_{i,j} + u_{i,j-1}}{h^2} - \\frac{h^2}{12} \\frac{\\partial^4 u}{\\partial y^4}(x_i, y_j) + \\mathcal{O}(h^4)\n$$\n将这两个表达式相加，得到拉普拉斯算子的近似值：\n$$\n\\Delta u(x_i, y_j) = \\frac{u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - 4u_{i,j}}{h^2} - \\frac{h^2}{12} \\left( \\frac{\\partial^4 u}{\\partial x^4} + \\frac{\\partial^4 u}{\\partial y^4} \\right)(x_i, y_j) + \\mathcal{O}(h^4)\n$$\n我们定义离散拉普拉斯算子，记为 $\\Delta_h$，如下：\n$$\n\\Delta_h u_{i,j} = \\frac{u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - 4u_{i,j}}{h^2}\n$$\n将此代入泊松方程 $-\\Delta u(x_i, y_j) = f(x_i, y_j)$，并忽略高阶项，即可得到对于内部节点 $(i,j)$（其中 $i,j \\in \\{1, \\dots, N-1\\}$）的五点有限差分格式：\n$$\n-\\Delta_h u_{i,j} = \\frac{4u_{i,j} - u_{i-1,j} - u_{i+1,j} - u_{i,j-1} - u_{i,j+1}}{h^2} = f_{i,j}\n$$\n其中 $f_{i,j} = f(x_i, y_j)$。这就是所求的公式。\n\n### 第二部分：局部截断误差与全局误差\n\n局部截断误差（LTE），$\\tau_{i,j}$，是将精确解 $u(x,y)$ 代入离散方程时得到的残差。设 $L_h = -\\Delta_h$。离散系统为 $L_h u_h = f$，其中 $u_h$ 是数值解向量。将该算子应用于精确解 $u$：\n$$\n\\tau_{i,j} = L_h u(x_i, y_j) - f(x_i, y_j) = L_h u(x_i, y_j) - (-\\Delta u(x_i, y_j))\n$$\n根据上面的泰勒展开分析，我们有：\n$$\n\\Delta_h u(x_i, y_j) = \\Delta u(x_i, y_j) + \\frac{h^2}{12} \\left( \\frac{\\partial^4 u}{\\partial x^4} + \\frac{\\partial^4 u}{\\partial y^4} \\right)(x_i, y_j) + \\mathcal{O}(h^4)\n$$\n因此，LTE 为：\n$$\n\\tau_{i,j} = - \\left( \\Delta u(x_i, y_j) + \\frac{h^2}{12} \\left( \\frac{\\partial^4 u}{\\partial x^4} + \\frac{\\partial^4 u}{\\partial y^4} \\right) + \\mathcal{O}(h^4) \\right) + \\Delta u(x_i, y_j)\n$$\n$$\n\\tau_{i,j} = - \\frac{h^2}{12} \\left( \\frac{\\partial^4 u}{\\partial x^4}(x_i,y_j) + \\frac{\\partial^4 u}{\\partial y^4}(x_i,y_j) \\right) + \\mathcal{O}(h^4)\n$$\n如果精确解 $u$ 属于 $C^4(\\overline{\\Omega})$，意味着其四阶偏导数在闭区域 $\\overline{\\Omega}$ 上是连续的，因而是有界的，那么存在一个常数 $M$，使得 $|\\frac{\\partial^4 u}{\\partial x^4}| \\le M$ 和 $|\\frac{\\partial^4 u}{\\partial y^4}| \\le M$。因此，LTE 的最大范数有界：\n$$\n\\lVert \\tau \\rVert_\\infty = \\max_{i,j} |\\tau_{i,j}| \\le \\frac{h^2}{12} (M+M) + \\mathcal{O}(h^4) = \\mathcal{O}(h^2)\n$$\n该格式是2阶相容的。\n\n全局误差定义为 $e_{i,j} = u(x_i, y_j) - u_{h, i,j}$，其中 $u_h$ 是离散系统的解。将离散算子 $L_h$ 应用于误差：\n$$\nL_h e_{i,j} = L_h (u_{i,j} - u_{h, i,j}) = L_h u_{i,j} - L_h u_{h, i,j}\n$$\n根据定义，$L_h u_{h, i,j} = f_{i,j}$ 且 $L_h u_{i,j} = f_{i,j} + \\tau_{i,j}$。两者相减，我们得到误差方程：\n$$\nL_h e_{i,j} = \\tau_{i,j}\n$$\n对于所有内部节点。在边界 $\\partial\\Omega$ 上，误差为零，即 $e_{i,j} = 0$，因为精确解和数值解都取预设的边界值 $g(x,y)$。\n\nLTE 和全局误差之间的联系是通过离散算子 $L_h$ 的稳定性建立的。算子 $L_h$ 满足离散极值原理（DMP）。对于像 $L_h$ 这样的算子，DMP 指出，如果在所有内部节点上 $L_h v_{i,j} \\ge 0$，那么 $v$ 在整个网格上的最大值必定出现在边界上。DMP 的一个关键推论是其逆算子在最大范数下的稳定性。也就是说，存在一个与 $h$ 无关的正常数 $C$，使得对于任意网格函数 $z$，满足零边界条件的方程 $L_h v = z$ 的解 $v$ 满足：\n$$\n\\lVert v \\rVert_\\infty \\le C \\lVert z \\rVert_\\infty\n$$\n这表示为 $\\lVert L_h^{-1} \\rVert_\\infty \\le C$。将此稳定性估计应用于误差方程 $e = L_h^{-1} \\tau$：\n$$\n\\lVert e \\rVert_\\infty = \\lVert L_h^{-1} \\tau \\rVert_\\infty \\le \\lVert L_h^{-1} \\rVert_\\infty \\lVert \\tau \\rVert_\\infty \\le C \\lVert \\tau \\rVert_\\infty\n$$\n既然我们已经证明 $\\lVert \\tau \\rVert_\\infty = \\mathcal{O}(h^2)$，那么最大范数下的全局误差也是二阶精确的：\n$$\n\\lVert u - u_h \\rVert_\\infty = \\lVert e \\rVert_\\infty = \\mathcal{O}(h^2)\n$$\n这证明了，对于足够光滑的解（$u \\in C^4(\\overline{\\Omega})$），五点格式以 $2$ 的阶全局收敛。\n\n### 第三部分：算法设计\n\n该实现将包含一个无矩阵共轭梯度（CG）求解器。必须构建线性系统 $A u_h = b$，其中 $A$ 对应于 $(N-1)^2$ 个内部节点上的离散算子 $L_h$。\n\n**系统构建：**向量 $u_h$ 包含内部节点的未知值。矩阵 $A$ 代表五点格式。右端项向量 $b$ 结合了源项 $f(x,y)$ 和来自已知狄利克雷边界值 $g(x,y)$ 的贡献。对于一个内部节点 $(x_i,y_j)$：\n$$\nb_{i,j} = f(x_i, y_j) + \\frac{1}{h^2} \\left[ \\delta_{i,1}g(x_0,y_j) + \\delta_{i,N-1}g(x_N,y_j) + \\delta_{j,1}g(x_i,y_0) + \\delta_{j,N-1}g(x_i,y_N) \\right]\n$$\n其中 $\\delta_{k,l}$ 是克罗内克（Kronecker）δ。这种形式将所有已知的边界项移到方程的右边。\n\n**无矩阵共轭梯度法：**CG 算法迭代求解一个对称正定系统。五点格式的矩阵具有此性质。CG 中的关键操作是矩阵-向量乘积 $A\\vec{p}$。在无矩阵方法中，我们不组装 $(N-1)^2 \\times (N-1)^2$ 的矩阵 $A$。相反，我们实现一个函数，用于计算算子 $L_h$ 对一个网格函数 $\\vec{p}$（代表搜索方向）的作用。这是通过在每个内部节点应用五点格式来完成的。\n\n**EOC 估算：**EOC $p$ 是通过模型 $\\log E(h) \\approx \\log C + p \\log h$，从一系列网格尺寸 $h_k$ 对应的误差 $E(h_k)$ 中估算出来的。这是一个关于数据对 $(\\log h_k, \\log E_k)$ 的线性回归问题。斜率 $p$ 使用标准的最小二乘公式计算。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and compute EOC for all cases.\n    \"\"\"\n\n    # --- Test Case Definitions ---\n\n    # Case 1: Smooth solution u_s(x,y) = sin(pi*x)sin(pi*y)\n    u_s = lambda x, y: np.sin(np.pi * x) * np.sin(np.pi * y)\n    f_s = lambda x, y: 2 * np.pi**2 * np.sin(np.pi * x) * np.sin(np.pi * y)\n    \n    # Case 2: Singular solution u_sg(x,y) = r^(3/2)\n    def u_sg(x, y):\n        r = np.sqrt(x**2 + y**2)\n        # Handle r=0 case to avoid 0**negative power in f_sg\n        return np.power(r, 1.5)\n\n    def f_sg(x, y):\n        # f is evaluated only at interior points, so r > 0.\n        r = np.sqrt(x**2 + y**2)\n        alpha = 1.5\n        return -alpha**2 * np.power(r, alpha - 2)\n\n    # --- Test Suite ---\n    test_cases = [\n        # Case A: Smooth solution, standard refinement\n        {'name': 'A', 'Ns': [8, 16, 32, 64], 'u_func': u_s, 'f_func': f_s},\n        # Case B: Singular solution\n        {'name': 'B', 'Ns': [8, 16, 32, 64], 'u_func': u_sg, 'f_func': f_sg},\n        # Case C: Smooth solution, coarse grids\n        {'name': 'C', 'Ns': [4, 8, 16], 'u_func': u_s, 'f_func': f_s},\n    ]\n\n    eoc_results = []\n\n    for case in test_cases:\n        h_values = []\n        error_values = []\n\n        for N in case['Ns']:\n            h = 1.0 / N\n            u_func = case['u_func']\n            f_func = case['f_func']\n            g_func = u_func # Boundary condition is the exact solution\n\n            # 1. Set up grid and coordinates\n            # Grid for interior points (1..N-1)\n            int_coords = np.linspace(h, 1.0 - h, N - 1)\n            X_int, Y_int = np.meshgrid(int_coords, int_coords, indexing='ij')\n\n            # Full grid for error calculation (0..N)\n            full_coords = np.linspace(0, 1.0, N + 1)\n            X_full, Y_full = np.meshgrid(full_coords, full_coords, indexing='ij')\n\n            # 2. Construct the right-hand side (RHS) vector 'b'\n            b = f_func(X_int, Y_int)\n            h2_inv = 1.0 / (h**2)\n            \n            # Add boundary contributions\n            # j = 1, ..., N-1\n            b[0, :] += h2_inv * g_func(0, int_coords)  # Left boundary i=0\n            b[-1, :] += h2_inv * g_func(1, int_coords) # Right boundary i=N\n            # i = 1, ..., N-1\n            b[:, 0] += h2_inv * g_func(int_coords, 0)  # Bottom boundary j=0\n            b[:, -1] += h2_inv * g_func(int_coords, 1) # Top boundary j=N\n\n            # 3. Solve the linear system using matrix-free Conjugate Gradient\n            u_h_interior = cg_solver(b, h, tol=1e-12)\n\n            # 4. Construct full solution grid and compute error\n            u_h_full = np.zeros((N + 1, N + 1))\n            # Set boundary values\n            u_h_full[0, :] = g_func(0, full_coords)\n            u_h_full[N, :] = g_func(1, full_coords)\n            u_h_full[:, 0] = g_func(full_coords, 0)\n            u_h_full[:, N] = g_func(full_coords, 1)\n            # Fill interior\n            u_h_full[1:N, 1:N] = u_h_interior\n\n            u_exact_full = u_func(X_full, Y_full)\n            \n            error = np.max(np.abs(u_exact_full - u_h_full))\n            \n            h_values.append(h)\n            error_values.append(error)\n\n        # 5. Compute EOC using least-squares fit\n        log_h = np.log(np.array(h_values))\n        log_e = np.log(np.array(error_values))\n        \n        # Fit a line (degree 1 polynomial) to (log_h, log_e)\n        # The slope is the first coefficient returned by polyfit.\n        p_eoc = np.polyfit(log_h, log_e, 1)[0]\n        eoc_results.append(p_eoc)\n    \n    # Final print statement\n    print(f\"[{','.join(f'{p:.3f}' for p in eoc_results)}]\")\n\ndef apply_A_matvec(v, h):\n    \"\"\"\n    Computes the matrix-free matrix-vector product for the 5-point stencil.\n    Assumes zero boundary conditions for the input vector v.\n    \n    Args:\n        v (np.ndarray): A 2D numpy array of size (N-1)x(N-1) representing the vector.\n        h (float): The mesh spacing.\n    \n    Returns:\n        np.ndarray: The result of Av, a 2D array of size (N-1)x(N-1).\n    \"\"\"\n    if v.shape[0] == 0:\n        return np.array([])\n    N_minus_1 = v.shape[0]\n    Av = np.zeros_like(v)\n    h2_inv = 1.0 / (h**2)\n    \n    # Pad with zeros for boundary conditions\n    v_padded = np.pad(v, pad_width=1, mode='constant', constant_values=0)\n    \n    for i in range(N_minus_1):\n        for j in range(N_minus_1):\n            # Convert to padded indices\n            ip, jp = i + 1, j + 1\n            center = v_padded[ip, jp]\n            left = v_padded[ip - 1, jp]\n            right = v_padded[ip + 1, jp]\n            down = v_padded[ip, jp - 1]\n            up = v_padded[ip, jp + 1]\n            \n            Av[i, j] = h2_inv * (4 * center - left - right - down - up)\n            \n    return Av\n\ndef cg_solver(b, h, tol=1e-10, max_iter=1000):\n    \"\"\"\n    Solves Ax=b using matrix-free Conjugate Gradient method.\n    \n    Args:\n        b (np.ndarray): The right-hand side vector as a 2D (N-1)x(N-1) array.\n        h (float): The mesh spacing.\n        tol (float): The relative tolerance for the residual norm.\n        max_iter (int): Maximum number of iterations.\n    \n    Returns:\n        np.ndarray: The solution vector x as a 2D (N-1)x(N-1) array.\n    \"\"\"\n    if b.size == 0:\n        return np.array([])\n    x = np.zeros_like(b)\n    r = b - apply_A_matvec(x, h)\n    p = r.copy()\n    rs_old = np.sum(r**2)\n    \n    b_norm = np.sqrt(np.sum(b**2))\n    if b_norm == 0:\n        return x\n\n    for k in range(max_iter):\n        Ap = apply_A_matvec(p, h)\n        pAp = np.sum(p * Ap)\n\n        if pAp == 0:\n            break\n            \n        alpha = rs_old / pAp\n        x += alpha * p\n        r -= alpha * Ap\n        \n        rs_new = np.sum(r**2)\n        \n        if np.sqrt(rs_new)  tol * b_norm:\n            break\n            \n        p = r + (rs_new / rs_old) * p\n        rs_old = rs_new\n        \n    return x\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3228788"}, {"introduction": "在建立了一个二阶精度的求解器之后，我们自然会问：能否在不改变基本离散格式的复杂度的情况下，进一步提升计算精度？理查森外推法 (Richardson extrapolation) 提供了一个优雅而强大的答案。这个练习将指导你如何巧妙地组合在不同尺度网格上得到的数值解，从而对消掉误差中的主导项，获得远高于原始方法精度的结果。[@problem_id:3228920]", "problem": "考虑单位正方形域 $[0,1] \\times [0,1]$ 上的二维泊松偏微分方程(PDE)，其笛卡尔坐标为 $(x,y)$，\n$$- \\Delta u(x,y) = f(x,y),$$\n该方程服从齐次狄利克雷边界条件\n$$u(x,y) = 0 \\quad \\text{for} \\quad (x,y) \\in \\partial([0,1] \\times [0,1]).$$\n假设精确解由\n$$u(x,y) = \\sin(\\pi x)\\sin(\\pi y),$$\n给出，因此源项由拉普拉斯算子 $\\Delta$ 的恒等式确定，\n$$- \\Delta u(x,y) = 2 \\pi^2 \\sin(\\pi x)\\sin(\\pi y).$$\n所有三角函数的角度都必须以弧度为单位进行解释。\n\n使用标准的五点中心有限差分(FD)格式对拉普拉斯算子在间距为 $h$ 的均匀网格上进行离散，内部网格节点 $(i,j)$ 处的离散算子根据二阶导数的定义构建，并产生一个线性代数系统。在 $u(x,y)$ 的光滑性假设下，该系统以渐近正比于 $h^2$ 的截断误差逼近该偏微分方程。设内部网格大小为 $n \\times n$，网格间距为 $h = \\frac{1}{n+1}$，内部索引为 $i,j \\in \\{1,2,\\dots,n\\}$。用 $U_h$ 表示在区域几何中心 $(x,y) = (0.5,0.5)$ 处计算的 $u$ 的有限差分近似值，当 $n$ 为奇数时，这对应于内部索引 $(i,j) = \\left(\\frac{n+1}{2},\\frac{n+1}{2}\\right)$。\n\n你的任务是：\n- 构建由 $- \\Delta u = f$ 在齐次狄利克雷边界条件 $u = 0$ on $\\partial \\Omega$ 下的五点有限差分离散所产生的线性系统，在三个间距分别为 $h$、$h/2$ 和 $h/4$ 的嵌套均匀网格上求解该系统，并提取在中心点得到的三个近似值，记为 $U_h$、$U_{h/2}$ 和 $U_{h/4}$。\n- 对序列 $\\{U_h, U_{h/2}, U_{h/4}\\}$ 应用理查森外推法，加密比为 $r = 2$，以消除主导的 $O(h^2)$ 截断误差项，然后消除次主导的 $O(h^4)$ 项，从而在中心点产生一个更高阶的精确近似值。你必须基于渐近误差展开和加密比，推导并实现能够消除主导和次主导误差项的代数组合。\n- 计算中心点的绝对误差，定义为 $|U_{\\text{extrap}} - u(0.5,0.5)|$，其中 $U_{\\text{extrap}}$ 是你经过三级理查森外推得到的值，且 $u(0.5,0.5) = \\sin(\\pi/2)\\sin(\\pi/2) = 1$。\n\n测试套件：\n- 程序必须对定义粗网格的三个基础内部尺寸 $n_0$ 运行该过程。对于每个 $n_0$，构建内部尺寸分别为 $n_0$、$2n_0+1$ 和 $4n_0+3$（分别对应间距 $h$、$h/2$ 和 $h/4$）的三个嵌套网格，并如前所述执行外推。使用以下测试用例：\n    1. $n_0 = 1$ (边缘情况的粗网格，最小内部),\n    2. $n_0 = 7$ (典型的中等分辨率情况),\n    3. $n_0 = 15$ (更精细的粗网格)。\n这些选择确保几何中心 $(0.5,0.5)$ 在每个嵌套网格上都与一个网格点重合。\n\n最终输出规范：\n- 你的程序应该产生单行输出，其中包含三个测试用例的三级理查森外推中心值的绝对误差，形式为方括号内用逗号分隔的列表，例如 $$[e_1,e_2,e_3],$$ 其中每个 $e_k$ 是一个浮点数，表示第 $k$ 个测试用例的绝对误差。", "solution": "### 问题验证\n\n根据指定标准对问题陈述进行严格审查。\n\n#### 第 1 步：提取已知条件\n\n- **PDE**：二维泊松方程给定为在区域 $\\Omega = [0,1] \\times [0,1]$ 上的 $- \\Delta u(x,y) = f(x,y)$。\n- **边界条件 (BCs)**：指定了齐次狄利克雷边界条件：对于 $(x,y) \\in \\partial\\Omega$，$u(x,y) = 0$。\n- **精确解**：问题的精确解提供为 $u(x,y) = \\sin(\\pi x)\\sin(\\pi y)$。\n- **源项**：源项 $f(x,y)$ 由精确解确定：$f(x,y) = - \\Delta u(x,y) = 2 \\pi^2 \\sin(\\pi x)\\sin(\\pi y)$。所有三角函数均以弧度为单位。\n- **离散化方法**：将使用标准五点中心有限差分 (FD) 格式，作用于间距为 $h$ 的均匀网格上。截断误差据称渐近正比于 $h^2$。\n- **网格定义**：网格有 $n \\times n$ 个内部节点。网格间距为 $h = \\frac{1}{n+1}$，内部索引为 $i,j \\in \\{1,2,\\dots,n\\}$。\n- **关注量**：区域几何中心 $(x,y) = (0.5,0.5)$ 处的有限差分近似值 $U_h$。对于奇数 $n$，这对应于网格索引 $(i,j) = \\left(\\frac{n+1}{2},\\frac{n+1}{2}\\right)$。\n- **任务**:\n    1.  在三个间距分别为 $h$、$h/2$ 和 $h/4$ 的嵌套网格上求解 FD 系统，得到中心点的近似值 $U_h, U_{h/2}, U_{h/4}$。\n    2.  对序列 $\\{U_h, U_{h/2}, U_{h/4}\\}$ 应用两阶段理查森外推，以获得更高阶的近似值 $U_{\\text{extrap}}$。\n    3.  计算绝对误差 $|U_{\\text{extrap}} - u(0.5,0.5)|$，其中精确值为 $u(0.5,0.5) = 1$。\n- **测试用例**：该过程将针对三个基础内部网格尺寸 $n_0$ 运行：\n    1.  $n_0 = 1$：使用 $n=1, 3, 7$ 的网格。\n    2.  $n_0 = 7$：使用 $n=7, 15, 31$ 的网格。\n    3.  $n_0 = 15$：使用 $n=15, 31, 63$ 的网格。\n    嵌套网格由 $n_0$、$n_1=2n_0+1$ 和 $n_2=4n_0+3$ 定义，这正确地对应于间距 $h$、$h/2$ 和 $h/4$。\n\n#### 第 2 步：使用提取的已知条件进行验证\n\n- **科学基础**：该问题是偏微分方程数值分析领域的经典练习。泊松方程、有限差分法和理查森外推都是标准且成熟的课题。提供的精确解和推导出的源项是一致的。\n- **适定性**：带有狄利克雷边界条件的泊松方程是一个适定的椭圆型偏微分方程。其有限差分离散化产生一个非奇异、唯一可解的线性系统。任务定义清晰，并能得出唯一的数值结果。\n- **客观性**：问题使用精确的数学语言陈述，没有主观或含糊的术语。\n- **完整性和一致性**：提供了所有必要信息（PDE、区域、边界条件、离散格式、精确解和测试参数）。网格尺寸 $n$ 和间距 $h$ 之间的关系在嵌套加密中保持一致。选择奇数值的 $n$ 确保了区域中心 $(0.5,0.5)$ 始终是一个网格点，这是该任务的必要条件。\n\n问题没有显示出任何科学缺陷、不一致或含糊之处。\n\n#### 第 3 步：结论和行动\n\n问题是 **有效的**。将提供一个解决方案。\n\n### 解决方案\n\n该解决方案通过遵循一个系统的程序来制定，该程序包括离散化、线性系统构建和理查森外推。\n\n#### 1. 有限差分离散化\n泊松方程为 $-(\\partial^2 u/\\partial x^2 + \\partial^2 u/\\partial y^2) = f(x,y)$。我们引入一个在每个方向上都有 $n$ 个内部点的均匀网格，使得网格间距为 $h=1/(n+1)$。网格点为 $(x_i, y_j) = (ih, jh)$，其中 $i,j = 0, 1, \\dots, n+1$。内部点对应于索引 $i,j = 1, \\dots, n$。\n\n二阶偏导数使用中心差分进行近似：\n$$ \\frac{\\partial^2 u}{\\partial x^2}\\bigg|_{(x_i, y_j)} \\approx \\frac{U_{i+1,j} - 2U_{i,j} + U_{i-1,j}}{h^2} $$\n$$ \\frac{\\partial^2 u}{\\partial y^2}\\bigg|_{(x_i, y_j)} \\approx \\frac{U_{i,j+1} - 2U_{i,j} + U_{i,j-1}}{h^2} $$\n其中 $U_{i,j}$ 是 $u(x_i, y_j)$ 的数值近似。\n\n将这些代入泊松方程，得到每个内部节点 $(i,j)$ 处负拉普拉斯算子的五点格式：\n$$ -\\Delta_h U_{i,j} = \\frac{4U_{i,j} - U_{i+1,j} - U_{i-1,j} - U_{i,j+1} - U_{i,j-1}}{h^2} = f(x_i, y_j) $$\n对于 $i,j=1, \\dots, n$。齐次狄利克雷边界条件意味着如果 $i$ 或 $j$ 为 $0$ 或 $n+1$，则 $U_{i,j}=0$。\n\n#### 2. 线性系统构建\n关于未知内部值 $U_{i,j}$ 的 $n^2$ 个线性方程组可以写成矩阵形式 $A\\vec{U} = \\vec{F}$。未知量向量 $\\vec{U}$ 是一个 $n^2 \\times 1$ 的列向量，由 $U_{i,j}$ 值排序而成。使用标准的行优先（或自然）排序，其中索引 $j$ 变化最快，从二维网格索引 $(i,j)$（其中 $i,j \\in \\{1,\\dots,n\\}$）到一维向量索引 $k \\in \\{1,\\dots,n^2\\}$ 的映射是 $k = (i-1)n+j$。\n\n矩阵 $A$ 是一个 $n^2 \\times n^2$ 的稀疏、对称、正定、块三对角矩阵：\n$$ A = \\frac{1}{h^2} \\begin{pmatrix}\nT  -I    \\\\\n-I  T  -I   \\\\\n \\ddots  \\ddots  \\ddots  \\\\\n  -I  T  -I \\\\\n   -I  T\n\\end{pmatrix} $$\n其中 $I$ 是 $n \\times n$ 的单位矩阵，$T$ 是 $n \\times n$ 的三对角矩阵：\n$$ T = \\begin{pmatrix}\n4  -1    \\\\\n-1  4  -1   \\\\\n \\ddots  \\ddots  \\ddots  \\\\\n  -1  4  -1 \\\\\n   -1  4\n\\end{pmatrix} $$\n这种结构直接源于五点格式。矩阵 $A$ 可以使用克罗内克积优雅地构建。设 $A_{1D} = T/h^2$ 是表示一维负二阶导数的矩阵。那么二维算子矩阵是 $A = I \\otimes A_{1D} + A_{1D} \\otimes I$。\n\n右端向量 $\\vec{F}$ 是一个 $n^2 \\times 1$ 的列向量，包含在内部网格点 $(x_i, y_j)$ 处计算的源项 $f(x,y) = 2\\pi^2\\sin(\\pi x)\\sin(\\pi y)$ 的值，其排序与 $\\vec{U}$ 一致。对于每个测试用例，我们构建这个系统并使用标准的线性求解器求解 $\\vec{U}$。\n\n#### 3. 理查森外推法\n对于对称域上足够光滑的解，有限差分格式的截断误差可以表示为关于 $h$ 的偶数次幂的渐近级数：\n$$ U_h = u + C_1 h^2 + C_2 h^4 + C_3 h^6 + \\dots $$\n其中 $U_h$ 是某点的数值近似值，$u$ 是该点的精确解，$C_k$ 是与 $h$ 无关的常数。\n\n我们计算在间距为 $h_0$、$h_1=h_0/2$ 和 $h_2=h_0/4$ 的三个网格上区域中心的解。设相应的数值解为 $A_0, A_1, A_2$。\n$$ A_0 = u + C_1 h_0^2 + C_2 h_0^4 + O(h_0^6) $$\n$$ A_1 = u + C_1 (h_0/2)^2 + C_2 (h_0/2)^4 + O(h_0^6) = u + \\frac{1}{4}C_1 h_0^2 + \\frac{1}{16}C_2 h_0^4 + O(h_0^6) $$\n$$ A_2 = u + C_1 (h_0/4)^2 + C_2 (h_0/4)^4 + O(h_0^6) = u + \\frac{1}{16}C_1 h_0^2 + \\frac{1}{256}C_2 h_0^4 + O(h_0^6) $$\n\n**第一次外推（至 $O(h^4)$ 阶）：**\n我们组合成对的近似值以消除主导的 $O(h^2)$ 误差项。对于加密比 $r$ 和误差阶 $p$，通用公式为 $(r^p A_{fine} - A_{coarse}) / (r^p-1)$。此处，$r=2$ 且 $p=2$。\n设 $B_0$ 是从 $A_0$ 和 $A_1$ 外推得到的值：\n$$ B_0 = \\frac{2^2 A_1 - A_0}{2^2 - 1} = \\frac{4A_1 - A_0}{3} = u - \\frac{1}{4}C_2 h_0^4 + O(h_0^6) $$\n设 $B_1$ 是从 $A_1$ 和 $A_2$ 外推得到的值：\n$$ B_1 = \\frac{2^2 A_2 - A_1}{2^2 - 1} = \\frac{4A_2 - A_1}{3} = u - \\frac{1}{4}C_2 (h_0/2)^4 + O(h_0^6) = u - \\frac{1}{64}C_2 h_0^4 + O(h_0^6) $$\n$B_0$ 和 $B_1$ 现在是四阶精确的近似值。\n\n**第二次外推（至 $O(h^6)$ 阶）：**\n我们组合 $B_0$ 和 $B_1$ 以消除 $O(h^4)$ 误差项。主导误差的阶为 $p=4$。\n$$ U_{\\text{extrap}} = \\frac{2^4 B_1 - B_0}{2^4 - 1} = \\frac{16B_1 - B_0}{15} $$\n代入 $B_0$ 和 $B_1$ 的表达式：\n$$ U_{\\text{extrap}} = \\frac{1}{15} \\left[ 16\\left(\\frac{4A_2 - A_1}{3}\\right) - \\left(\\frac{4A_1 - A_0}{3}\\right) \\right] $$\n$$ U_{\\text{extrap}} = \\frac{1}{45} \\left[ 16(4A_2 - A_1) - (4A_1 - A_0) \\right] $$\n$$ U_{\\text{extrap}} = \\frac{64A_2 - 16A_1 - 4A_1 + A_0}{45} = \\frac{64A_2 - 20A_1 + A_0}{45} $$\n这个最终值 $U_{\\text{extrap}}$ 的截断误差为 $O(h_0^6)$。\n\n#### 4. 计算过程\n对每个测试用例 $n_0 \\in \\{1, 7, 15\\}$ 实现以下算法：\n1.  定义三个内部网格尺寸：$n_h = n_0$、$n_{h/2} = 2n_0+1$ 和 $n_{h/4} = 4n_0+3$。\n2.  对于每个网格尺寸 $n \\in \\{n_h, n_{h/2}, n_{h/4}\\}$：\n    a. 计算网格间距 $h = 1/(n+1)$。\n    b. 构建 $n^2 \\times n^2$ 矩阵 $A$ 和 $n^2 \\times 1$ 的右端向量 $\\vec{F}$。\n    c. 求解线性系统 $A\\vec{U} = \\vec{F}$ 以获得解向量 $\\vec{U}$。\n    d. 提取中心网格点的解。对于一个 $n \\times n$ 的内部网格（使用从 $0$ 到 $n-1$ 的 0-基索引），中心索引为 $(i_c,j_c) = ((n-1)/2, (n-1)/2)$。相应的一维索引是 $k_c = i_c \\cdot n + j_c$。中心值为 $U_{i_c,j_c}$。\n3.  将三个中心值存储为 $A_0 = U_h$、$A_1 = U_{h/2}$ 和 $A_2 = U_{h/4}$。\n4.  计算外推值 $U_{\\text{extrap}} = (64A_2 - 20A_1 + A_0) / 45$。\n5.  中心点 $(0.5,0.5)$ 处的精确解是 $u(0.5,0.5) = \\sin(\\pi/2)\\sin(\\pi/2) = 1$。\n6.  计算绝对误差：$E = |U_{\\text{extrap}} - 1|$。\n7.  收集三个 $n_0$ 值的误差，并以列表形式呈现。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve_poisson_center(n):\n    \"\"\"\n    Solves the 2D Poisson equation -Delta u = f on the unit square\n    using a five-point finite difference scheme on an n x n interior grid.\n\n    Args:\n        n (int): The number of interior grid points in one dimension.\n                 n must be odd.\n\n    Returns:\n        float: The numerical solution at the center of the domain (0.5, 0.5).\n    \"\"\"\n    if n % 2 == 0:\n        raise ValueError(\"n must be an odd integer for the center to be a grid point.\")\n\n    h = 1.0 / (n + 1)\n    \n    # Construct the n x n tridiagonal matrix T for the 1D operator.\n    # This corresponds to the stencil [-1, 4, -1].\n    # The problem defines the discrete operator as (4U_ij - U_i-1,j - ...)/h^2\n    # which leads to a matrix A with 4/h^2 on the main diagonal.\n    T = 4 * np.eye(n) - np.eye(n, k=1) - np.eye(n, k=-1)\n    \n    # Construct the n^2 x n^2 matrix A for the 2D operator -Delta_h\n    # using Kronecker products. This forms the block-tridiagonal matrix.\n    # The full matrix is A = (1/h^2) * (I kron T_diag_2 + T_diag_2 kron I)\n    # where T_diag_2 has diag [ -1 2 -1 ].\n    # Our T has diag [-1 4 -1], so we need to adjust.\n    # Let T_std = 2*eye - eye(k=1) - eye(k=-1). Then operator is (I kron T_std + T_std kron I)/h^2\n    # (I kron T_std + T_std kron I) = I kron (T-2I) + (T-2I) kron I\n    # = I kron T - 2(I kron I) + T kron I - 2(I kron I) = I kron T + T kron I - 4I\n    # Our stencil is (4U - ...), which corresponds to A = (1/h^2) * block_tridiag(T, -I).\n    # Let's build A directly.\n    A_mat = np.zeros((n*n, n*n))\n\n    # Diagonal blocks (T)\n    for i in range(n):\n        A_mat[i*n:(i+1)*n, i*n:(i+1)*n] = T\n\n    # Off-diagonal blocks (-I)\n    off_diag_block = -np.eye(n)\n    for i in range(n - 1):\n        A_mat[(i+1)*n:(i+2)*n, i*n:(i+1)*n] = off_diag_block\n        A_mat[i*n:(i+1)*n, (i+1)*n:(i+2)*n] = off_diag_block\n    \n    A_mat /= h**2\n    \n    # Construct the right-hand side vector F\n    # Create grid coordinates for interior points\n    x = np.linspace(h, 1.0 - h, n)\n    y = np.linspace(h, 1.0 - h, n)\n    # Use 'ij' indexing to match row-major flattening\n    xx, yy = np.meshgrid(x, y, indexing='ij')\n    \n    # Evaluate the source function f(x,y)\n    F_grid = 2 * (np.pi**2) * np.sin(np.pi * xx) * np.sin(np.pi * yy)\n    \n    # Flatten grid to a vector, matching the matrix's row-major ordering\n    F_vec = F_grid.flatten()\n    \n    # Solve the linear system A * U = F\n    U_vec = np.linalg.solve(A_mat, F_vec)\n    \n    # Extract the solution at the center\n    # For an n x n grid (0-indexed), the center is at ( (n-1)/2, (n-1)/2 )\n    center_idx_1d = (n - 1) // 2\n    center_k = center_idx_1d * n + center_idx_1d\n    \n    return U_vec[center_k]\n\ndef solve():\n    \"\"\"\n    Main function to run the Richardson extrapolation procedure for the given test cases.\n    \"\"\"\n    # The program must run the procedure for three base interior sizes n0.\n    # The test cases specify these base sizes.\n    test_cases = [1, 7, 15]\n    \n    results = []\n    \n    for n0 in test_cases:\n        # Define the three nested grid sizes\n        n_h = n0\n        n_h_div_2 = 2 * n0 + 1\n        n_h_div_4 = 4 * n0 + 3\n        \n        # Calculate the numerical solution at the center for each grid\n        A0 = solve_poisson_center(n_h)        # Coarsest grid, h\n        A1 = solve_poisson_center(n_h_div_2)  # Medium grid, h/2\n        A2 = solve_poisson_center(n_h_div_4)  # Finest grid, h/4\n        \n        # Apply the three-level Richardson extrapolation formula:\n        # U_extrap = (64 * A2 - 20 * A1 + A0) / 45\n        U_extrap = (64.0 * A2 - 20.0 * A1 + A0) / 45.0\n        \n        # Exact solution at the center (0.5, 0.5)\n        u_exact_center = np.sin(np.pi / 2.0) * np.sin(np.pi / 2.0) # which is 1.0\n        \n        # Compute the absolute error\n        error = np.abs(U_extrap - u_exact_center)\n        results.append(error)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{err:.16e}' for err in results)}]\")\n\nsolve()\n\n```", "id": "3228920"}, {"introduction": "当为了追求高精度而加密网格时，我们得到的线性方程组的规模会急剧增大，直接求解变得非常耗时。本练习将带你探索一种前沿且高效的迭代方法——多重网格法 (multigrid method)。你将通过实现一个简单的一维双层V-循环，亲身体验多重网格法如何利用不同尺度网格间的协作，以惊人的效率解决大规模线性系统，从而攻克计算成本这一核心挑战。[@problem_id:3228782]", "problem": "实现一个完整且可运行的程序，该程序构建并应用一个双层多重网格V循环来求解一维泊松方程。考虑在单位区间上带齐次狄利克雷边界条件的一维泊松方程的边值问题：\n给定区间 $[0,1]$ 上的右端项函数 $f(x)$，求解\n$-u''(x)=f(x)$，其中 $x \\in (0,1)$，且 $u(0)=0$ 和 $u(1)=0$。\n从基础的有限差分构造开始：对于整数 $N \\ge 1$，引入一个均匀网格，包含 $N$ 个内点 $x_i = i h$，其中 $h = 1/(N+1)$ 且 $i=1,2,\\dots,N$。二阶导数 $u''(x_i)$ 通过标准的中心差分进行近似，该方法由 $x_i$ 点的泰勒展开导出。这会产生一个线性系统 $A_f \\, u_f = b_f$，其中 $u_f \\in \\mathbb{R}^N$ 是 $u(x)$ 在内点处的近似值，$b_f \\in \\mathbb{R}^N$ 的元素为 $f(x_i)$，而 $A_f \\in \\mathbb{R}^{N \\times N}$ 是带狄利克雷边界条件的离散拉普拉斯矩阵。\n\n你必须实现一个双层多重网格V循环，其步骤由误差方程 $A_f e_f = r_f$ 给出，其中 $e_f$ 是误差，$r_f=b_f-A_f u_f$ 是残差。算法必须遵循以下要求：\n- 前平滑：对 $A_f u_f = b_f$ 应用 $\\nu_1$ 次阻尼 Jacobi 迭代。一次阻尼 Jacobi 迭代通过 $u_f \\leftarrow u_f + \\omega D_f^{-1}(b_f - A_f u_f)$ 更新 $u_f$，其中 $D_f$ 是 $A_f$ 的对角部分，$0  \\omega  1$ 是一个阻尼参数。使用 $\\omega = 2/3$。\n- 粗网格校正：\n  1. 使用全权重限制算子 $R \\in \\mathbb{R}^{N_c \\times N}$ 将细网格残差 $r_f$ 限制到粗网格上，其中 $N_c = (N-1)/2$（假设 $N$ 为奇数）。限制后的残差为 $r_c = R r_f$。全权重限制将每个粗网格残差项映射为一个细网格点及其两个邻居的加权平均值，从而确保线性函数在转移到粗网格时得以保持。\n  2. 通过 Galerkin 构造 $A_c = R A_f P$ 定义粗网格算子，其中 $P \\in \\mathbb{R}^{N \\times N_c}$ 是线性插值（延拓）算子。延拓算子 $P$ 应将粗网格值注入到对应的偶数索引细网格点，并在相邻粗网格点之间对奇数索引的细网格点进行线性插值。在边界处，如果相邻的粗网格点会超出定义域，由于齐次狄利克雷边界条件，其边界贡献实际上为零。\n  3. 使用直接线性求解器在粗网格上精确求解 $A_c e_c = r_c$，这是合理的，因为对于此模型问题，$A_c$ 是一个小的对称正定矩阵。\n  4. 将粗网格误差 $e_c$ 延拓到细网格，得到 $e_f = P e_c$，并校正 $u_f \\leftarrow u_f + e_f$。\n- 后平滑：使用相同的 $\\omega$ 应用 $\\nu_2$ 次额外的阻尼 Jacobi 迭代。\n\n程序必须采用以下从基础有限差分和线性代数构造中推导出的通用原则：\n- 有限差分矩阵 $A_f$ 源于将泰勒定理应用于每个 $x_i$ 处的 $u(x)$，从而得到 $-u''(x)$ 的标准二阶中心近似，并通过从未知向量中排除边界节点来强制施加齐次狄利克雷边界条件。\n- 残差方程 $A_f e_f = r_f$ 为粗网格校正提供了理论依据，其中 $R$ 和 $P$ 的选择是为了使细网格上的光滑（低频）误差分量在粗网格上得到很好的表示和高效的校正。\n- Galerkin 算子 $A_c = R A_f P$ 确保了网格层级之间的变分一致性。\n\n必须强制执行的实现细节：\n- 使用零初始猜测 $u_f^{(0)} = 0$。\n- 对前平滑和后平滑均使用阻尼参数 $\\omega = 2/3$ 的阻尼 Jacobi 方法。\n- 如上所述，使用全权重限制和线性插值延拓，并使用 Galerkin 公式 $A_c = R A_f P$ 构造 $A_c$。\n- 迭代V循环，直到相对残差范数满足 $\\|r_f^{(k)}\\|_2 / \\|r_f^{(0)}\\|_2 \\le \\tau$（给定容差 $\\tau$），或直到达到最大200次V循环，以先到者为准。\n- 为了验证，选择具有已知精确解的右端项。具体来说，令 $u_{\\text{exact}}(x) = \\sin(k \\pi x)$，其中 $k \\in \\mathbb{N}$，因此 $f(x) = k^2 \\pi^2 \\sin(k \\pi x)$。使用弧度制计算正弦函数。\n\n测试套件和要求输出：\n实现求解器并在以下三个测试用例上运行。在每个用例中，通过在内部网格点 $x_i = i h$（其中 $h = 1/(N+1)$）上对 $f(x)$ 采样来形成 $b_f$，并将初始猜测设置为零向量。\n- 测试用例 A（理想路径）：$N = 63$，$k = 1$，$\\nu_1 = 2$，$\\nu_2 = 2$，$\\tau = 10^{-8}$。\n- 测试用例 B（减少平滑）：$N = 31$，$k = 2$，$\\nu_1 = 1$，$\\nu_2 = 1$，$\\tau = 10^{-8}$。\n- 测试用例 C（更大问题）：$N = 127$，$k = 1$，$\\nu_1 = 3$, $\\nu_2 = 3$, $\\tau = 10^{-8}$。\n\n对于每个测试用例，在收敛后，报告两个量：\n- 所用的V循环次数，以整数形式。\n- 细网格上误差的无穷范数 $\\|u_f - u_{\\text{exact}}\\|_{\\infty}$，以浮点数形式。\n\n最终输出格式：\n你的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表。该列表必须按 A、B、C 的顺序包含三个测试用例的结果，每个测试用例有两个条目：首先是整数V循环次数，然后是浮点数无穷范数误差。例如，输出必须是 $[n_A,e_A,n_B,e_B,n_C,e_C]$ 的形式，其中 $n_A$、$n_B$、$n_C$ 是整数，$e_A$、$e_B$、$e_C$ 是浮点数。", "solution": "所提供的问题是偏微分方程数值分析领域中一个适定且标准的练习。它具有科学依据，形式明确，并且内部一致。实现用于一维泊松方程的双层多重网格V循环所需的所有必要参数和定义均已提供。因此，该问题是有效的，可以构建一个解。\n\n该问题要求解带齐次狄利克雷边界条件的一维泊松方程：\n$$\n-u''(x) = f(x), \\quad x \\in (0, 1) \\\\\nu(0) = 0, \\quad u(1) = 0\n$$\n我们首先对问题域进行离散化。定义一个均匀网格，包含 $N$ 个内点 $x_i = i h$（$i=1, 2, \\dots, N$），其中网格间距为 $h = 1/(N+1)$。每个内点上的二阶导数 $u''(x_i)$ 使用从泰勒级数展开推导出的二阶精度中心差分公式进行近似：\n$$\nu''(x_i) \\approx \\frac{u(x_i - h) - 2u(x_i) + u(x_i + h)}{h^2} = \\frac{u_{i-1} - 2u_i + u_{i+1}}{h^2}\n$$\n其中 $u_i \\approx u(x_i)$。将此代入泊松方程，得到关于未知值 $u_i$ 的线性方程组：\n$$\n-\\frac{u_{i-1} - 2u_i + u_{i+1}}{h^2} = f(x_i) \\quad \\text{for } i=1, \\dots, N\n$$\n边界条件 $u(0)=0$ 和 $u(1)=0$ 意味着 $u_0=0$ 和 $u_{N+1}=0$。该系统可以写成矩阵形式 $A_f u_f = b_f$，其中 $u_f = [u_1, u_2, \\dots, u_N]^T$ 是细网格上未知解值的向量，$b_f = [f(x_1), f(x_2), \\dots, f(x_N)]^T$ 是在网格点上求值的右端项函数向量，而 $A_f$ 是 $N \\times N$ 的离散拉普拉斯矩阵：\n$$\nA_f = \\frac{1}{h^2}\n\\begin{pmatrix}\n2  -1    \\\\\n-1  2  -1   \\\\\n  \\ddots  \\ddots  \\ddots  \\\\\n   -1  2  -1 \\\\\n    -1  2\n\\end{pmatrix}\n$$\n多重网格方法的核心是通过利用网格层次结构来迭代求解该系统。V循环算法基于以下原理：松弛法（平滑子）能有效减少误差的高频（振荡）分量，而粗网格能有效减少误差的低频（光滑）分量。给定解 $u_f$ 的当前近似值 $\\tilde{u}_f$，误差为 $e_f = u_f - \\tilde{u}_f$，残差为 $r_f = b_f - A_f \\tilde{u}_f$。这些量通过残差方程相关联：$A_f e_f = r_f$。多重网格循环近似误差 $e_f$ 并用它来校正解。\n\n双层V循环包括三个主要阶段：\n\n1.  **前平滑**：我们对当前近似解应用 $\\nu_1$ 次平滑子迭代。该问题指定了阻尼 Jacobi 方法。对于第 $m$ 次迭代，更新公式为：\n    $$\n    u_f^{(m+1)} = u_f^{(m)} + \\omega D_f^{-1} (b_f - A_f u_f^{(m)})\n    $$\n    其中 $D_f$ 是 $A_f$ 的对角部分。对于我们的矩阵，$D_f = \\frac{2}{h^2} I$，其中 $I$ 是单位矩阵。给定的阻尼参数为 $\\omega = 2/3$。平滑操作减少了误差 $e_f$ 的高频分量。\n\n2.  **粗网格校正**：此时剩余的误差主要是光滑的，可以在更粗的网格上有效地表示。\n    *   **限制**：将细网格残差 $r_f = b_f - A_f u_f$ 转移到粗网格。假设 $N$ 为奇数，粗网格有 $N_c = (N-1)/2$ 个内点。该转移通过限制算子 $R \\in \\mathbb{R}^{N_c \\times N}$ 完成，得到粗网格残差 $r_c = R r_f$。指定的全权重限制算子使用一个模板 $[1/4, 1/2, 1/4]$，意味着粗网格上某点的残差是细网格上对应点及其两个直接邻居的残差的加权平均。\n    *   **粗网格问题**：我们在粗网格上求解残差方程 $A_c e_c = r_c$，以得到粗网格误差 $e_c$。粗网格算子 $A_c$ 通过 Galerkin 构造 $A_c = R A_f P$ 形成，其中 $P \\in \\mathbb{R}^{N \\times N_c}$ 是延拓（插值）算子。这种构造确保了粗算子以变分一致的方式继承细算子的属性。由于 $A_c$ 是一个小矩阵，该系统被直接求解（例如，使用LU分解）。\n    *   **延拓**：将计算出的粗网格误差 $e_c$ 插值回细网格，形成细网格误差校正量 $e_f = P e_c$。指定的线性插值算子 $P$ 将粗网格点映射到偶数索引的细网格点，并对奇数索引的细网格点进行线性插值。通常，对于 Galerkin 方法，限制算子和延拓算子通过 $R = c P^T$ 相关联，其中 $c$ 是某个常数；对于标准的一维情况，$c=1/2$。\n    *   **校正**：使用插值后的误差校正细网格解：$u_f \\leftarrow u_f + e_f$。\n\n3.  **后平滑**：我们对校正后的解应用 $\\nu_2$ 次额外的阻尼 Jacobi 平滑迭代，以消除延拓步骤引入的任何高频误差。\n\n这整个序列构成一个V循环。重复此过程，直到残差的相对 $L_2$-范数低于指定的容差 $\\tau$：\n$$\n\\frac{\\|r_f^{(k)}\\|_2}{\\|r_f^{(0)}\\|_2} \\le \\tau\n$$\n其中 $r_f^{(k)}$ 是第 $k$ 次V循环后的残差，$r_f^{(0)}$ 是初始残差。\n\n为了验证实现，我们使用一个人造解 $u_{\\text{exact}}(x) = \\sin(k \\pi x)$，它满足齐次狄利克雷边界条件。相应的右端项是 $f(x) = -u_{\\text{exact}}''(x) = (k \\pi)^2 \\sin(k \\pi x)$。计算解 $u_f$ 的最终精度通过误差的无穷范数来衡量，即 $\\|u_f - u_{\\text{exact}}\\|_{\\infty} = \\max_i |(u_f)_i - u_{\\text{exact}}(x_i)|$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef damped_jacobi(u, b, A, omega, nu):\n    \"\"\"\n    Applies nu iterations of the damped Jacobi smoother.\n    \n    Args:\n        u (np.ndarray): The current solution vector.\n        b (np.ndarray): The right-hand side vector.\n        A (np.ndarray): The system matrix.\n        omega (float): The damping parameter.\n        nu (int): The number of smoothing iterations.\n        \n    Returns:\n        np.ndarray: The solution vector after smoothing.\n    \"\"\"\n    # D_inv is a diagonal matrix. For the 1D Poisson matrix, A[0,0] = 2/h^2.\n    # D_inv * vector is equivalent to (h^2/2) * vector.\n    diag_inv = 1.0 / A[0, 0]\n    for _ in range(nu):\n        residual = b - A @ u\n        u = u + omega * diag_inv * residual\n    return u\n\ndef v_cycle(u_f, b_f, A_f, P, R, A_c, nu1, nu2, omega):\n    \"\"\"\n    Performs one two-level V-cycle.\n    \n    Args:\n        u_f (np.ndarray): Fine-grid solution vector.\n        b_f (np.ndarray): Fine-grid right-hand side vector.\n        A_f (np.ndarray): Fine-grid operator.\n        P (np.ndarray): Prolongation operator.\n        R (np.ndarray): Restriction operator.\n        A_c (np.ndarray): Coarse-grid operator.\n        nu1 (int): Number of pre-smoothing steps.\n        nu2 (int): Number of post-smoothing steps.\n        omega (float): Damping parameter for Jacobi.\n        \n    Returns:\n        np.ndarray: Updated fine-grid solution vector.\n    \"\"\"\n    # 1. Pre-smoothing\n    u_f = damped_jacobi(u_f, b_f, A_f, omega, nu1)\n    \n    # 2. Coarse-grid correction\n    # a. Compute residual\n    r_f = b_f - A_f @ u_f\n    \n    # b. Restrict residual to coarse grid\n    r_c = R @ r_f\n    \n    # c. Solve coarse-grid problem exactly\n    e_c = np.linalg.solve(A_c, r_c)\n    \n    # d. Prolongate error to fine grid and correct solution\n    e_f = P @ e_c\n    u_f = u_f + e_f\n    \n    # 3. Post-smoothing\n    u_f = damped_jacobi(u_f, b_f, A_f, omega, nu2)\n    \n    return u_f\n\ndef solve():\n    \"\"\"\n    Main function to run the multigrid solver for the specified test cases.\n    \"\"\"\n    test_cases = [\n        # (N, k, nu1, nu2, tolerance)\n        (63, 1, 2, 2, 1e-8),  # Test case A\n        (31, 2, 1, 1, 1e-8),  # Test case B\n        (127, 1, 3, 3, 1e-8), # Test case C\n    ]\n\n    results = []\n    omega = 2/3\n    max_cycles = 200\n\n    for N, k, nu1, nu2, tol in test_cases:\n        # 1. Setup grids and operators\n        h = 1.0 / (N + 1)\n        x_fine = np.linspace(h, 1.0 - h, N)\n        Nc = (N - 1) // 2\n\n        # Fine-grid operator A_f (discrete Laplacian)\n        diag_main = np.full(N, 2.0)\n        diag_sub = np.full(N - 1, -1.0)\n        A_f = (1.0 / h**2) * (np.diag(diag_main) + np.diag(diag_sub, k=1) + np.diag(diag_sub, k=-1))\n\n        # Prolongation operator P (linear interpolation)\n        P = np.zeros((N, Nc))\n        for j in range(Nc):\n            # Injection from coarse point j to fine point 2j+1\n            P[2 * j + 1, j] = 1.0\n            # Interpolation for neighbors\n            P[2 * j, j] += 0.5\n            if 2 * j + 2  N:\n                P[2 * j + 2, j] += 0.5\n\n        # Restriction operator R (full weighting)\n        # For standard 1D linear interpolation, R relates to P as R = 0.5 * P.T\n        R = 0.5 * P.T\n\n        # Coarse-grid operator Ac (Galerkin operator)\n        A_c = R @ A_f @ P\n\n        # 2. Setup problem: RHS and exact solution\n        f = lambda x_pts, k_val: (k_val * np.pi)**2 * np.sin(k_val * np.pi * x_pts)\n        b_f = f(x_fine, k)\n        u_exact = np.sin(k * np.pi * x_fine)\n\n        # 3. Iteratively solve using V-cycles\n        u_f = np.zeros(N)  # Initial guess is the zero vector\n        \n        r_0 = b_f - A_f @ u_f\n        r0_norm = np.linalg.norm(r_0, 2)\n        \n        if r0_norm == 0:\n            cycle_count = 0\n        else:\n            for cycle_count in range(1, max_cycles + 1):\n                u_f = v_cycle(u_f, b_f, A_f, P, R, A_c, nu1, nu2, omega)\n                \n                r_k = b_f - A_f @ u_f\n                relative_residual = np.linalg.norm(r_k, 2) / r0_norm\n                \n                if relative_residual  tol:\n                    break\n        \n        # 4. Calculate final error against exact solution\n        error_inf_norm = np.linalg.norm(u_f - u_exact, np.inf)\n        \n        results.extend([cycle_count, error_inf_norm])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{val:.8e}' if isinstance(val, float) else str(val) for val in results)}]\")\n\nsolve()\n```", "id": "3228782"}]}