{"hands_on_practices": [{"introduction": "本练习是分析敏感性分析的基础练习。我们将从一个经典的微观经济学线性供需模型入手，阐述其核心原理：利用偏导数来精确量化模型的输出（在这里是市场均衡价格）如何响应其参数的变化。通过这个动手推导，你将巩固对敏感度作为局部瞬时变化率的理解，并为更复杂的数值和概念分析打下坚实的基础 [@problem_id:3191079]。", "problem": "一位计算经济学家正在建立一个简单的市场模型，以研究响应参数的估计值如何影响计算出的均衡价格。该模型使用线性的供给和需求函数，其中供给量和需求量取决于价格。设供给由 $Q_{s} = a + bP$ 给出，需求由 $Q_{d} = c - dP$ 给出，其中 $Q_{s}$ 和 $Q_{d}$ 是数量，$P$ 是价格，$a$、$b$、$c$、$d$ 是严格为正的参数，分别代表基线水平（$a$、$c$）和响应系数（$b$、$d$）。假设 $c > a$，以确保市场出清价格为正。\n\n从市场均衡（供给量等于需求量）和敏感性分析（模型输出相对于其参数的变化，通过偏导数定义）的定义出发，推导出均衡价格 $P^{*}$ 作为 $a$、$b$、$c$ 和 $d$ 的函数。然后，从第一性原理出发，通过计算精确的偏导数 $\\frac{\\partial P^{*}}{\\partial b}$ 和 $\\frac{\\partial P^{*}}{\\partial d}$，来量化 $P^{*}$ 对响应系数 $b$ 和 $d$ 的敏感度。\n\n用包含 $a$、$b$、$c$ 和 $d$ 的两个闭式解析表达式来表示你的最终答案。无需四舍五入，最终表达式中不应包含单位。", "solution": "首先将对问题陈述进行严格的验证过程。\n\n### 步骤 1：提取已知信息\n问题陈述中提供的明确信息如下：\n- 供给函数：$Q_{s} = a + bP$\n- 需求函数：$Q_{d} = c - dP$\n- 变量：$Q_s$（供给量）、$Q_d$（需求量）、$P$（价格）。\n- 参数：$a, b, c, d$ 均为严格为正的实数。\n- 参数解释：$a, c$ 是基线水平；$b, d$ 是响应系数。\n- 约束条件：$c > a$。\n- 市场均衡的定义：$Q_s = Q_d$。\n- 敏感性分析的定义：通过模型输出对其参数的偏导数来量化。\n- 目标：\n    1. 推导均衡价格（记为 $P^*$）作为 $a, b, c, d$ 的函数。\n    2. 计算敏感度 $\\frac{\\partial P^{*}}{\\partial b}$ 和 $\\frac{\\partial P^{*}}{\\partial d}$。\n\n### 步骤 2：使用提取的已知信息进行验证\n根据既定标准对问题进行评估：\n- **科学依据：** 该问题使用了标准的线性供给-需求模型，这是微观经济学理论的基石，也是计算建模中的一个常见例子。市场均衡和敏感性分析的概念是基础且公认的原则。该设置在科学上是合理的。\n- **适定性：** 该问题提供了确定唯一解所需的所有方程和约束条件。条件 $b > 0$ 和 $d > 0$ 确保了供给曲线斜率为正，需求曲线斜率为负，这符合标准。总和 $b + d$ 将出现在价格表达式的分母中；由于两者都严格为正，它们的和不为零，从而避免了除以零。条件 $c > a$ 确保了由此产生的均衡价格 $P^*$ 为正，这在此背景下具有物理意义。因此，存在一个唯一的、稳定的、有意义的解。\n- **客观性：** 该问题使用精确且无歧义的数学和经济学语言进行陈述。没有主观论断或意见。\n\n### 步骤 3：结论与行动\n该问题在科学上是合理的、适定的、客观的和完整的。这是一个需要进行形式化推导的有效问题。我们可以继续进行求解。\n\n### 求解推导\n目标是求出均衡价格 $P^*$，然后计算其对参数 $b$ 和 $d$ 的敏感度。\n\n首先，我们确定均衡价格 $P^*$。当供给量等于需求量时，即 $Q_s = Q_d$，市场达到均衡。我们代入给定的供给和需求函数形式：\n$$a + bP = c - dP$$\n为了解出价格 $P$，我们重新排列方程以分离出 $P$。我们将所有含 $P$ 的项移到方程的一边，将常数项移到另一边。\n$$bP + dP = c - a$$\n从左侧提取公因子 $P$ 可得：\n$$P(b + d) = c - a$$\n然后通过除以 $(b+d)$ 这一项来求得均衡价格 $P^*$。由于 $b > 0$ 且 $d > 0$，可以保证 $b+d > 0$，因此该除法是明确定义的。\n$$P^{*} = \\frac{c - a}{b + d}$$\n问题指定 $c > a$，这确保了分子 $c - a$ 为正。分母 $b+d$ 也为正。因此，均衡价格 $P^*$ 严格为正，与经济现实相符。\n\n接下来，我们量化均衡价格 $P^*$ 对响应系数 $b$ 和 $d$ 的敏感度。这通过计算 $P^*$ 对这些参数各自的偏导数来完成。\n\n为计算 $P^*$ 对 $b$ 的偏导数（记为 $\\frac{\\partial P^{*}}{\\partial b}$），我们将 $a$、$c$ 和 $d$ 视为常数。我们对 $P^*$ 的表达式应用商的求导法则：\n$$\\frac{\\partial P^{*}}{\\partial b} = \\frac{\\partial}{\\partial b} \\left( \\frac{c - a}{b + d} \\right)$$\n商的求导法则指出，对于函数 $f(x) = \\frac{u(x)}{v(x)}$，其导数为 $f'(x) = \\frac{u'(x)v(x) - u(x)v'(x)}{[v(x)]^2}$。在我们的例子中，变量是 $b$，分子是 $u(b) = c - a$，分母是 $v(b) = b + d$。\n$u$ 和 $v$ 对 $b$ 的导数分别是：\n$$\\frac{\\partial u}{\\partial b} = \\frac{\\partial}{\\partial b}(c - a) = 0$$\n$$\\frac{\\partial v}{\\partial b} = \\frac{\\partial}{\\partial b}(b + d) = 1$$\n将这些代入商的求导法则公式中：\n$$\\frac{\\partial P^{*}}{\\partial b} = \\frac{(0)(b + d) - (c - a)(1)}{(b + d)^2}$$\n简化后得到：\n$$\\frac{\\partial P^{*}}{\\partial b} = -\\frac{c - a}{(b + d)^2}$$\n\n同样地，为计算 $P^*$ 对 $d$ 的偏导数（记为 $\\frac{\\partial P^{*}}{\\partial d}$），我们将 $a$、$b$ 和 $c$ 视为常数。我们再次对 $P^*$ 的表达式应用商的求导法则：\n$$\\frac{\\partial P^{*}}{\\partial d} = \\frac{\\partial}{\\partial d} \\left( \\frac{c - a}{b + d} \\right)$$\n这里，变量是 $d$，分子是 $u(d) = c - a$，分母是 $v(d) = b + d$。\n$u$ 和 $v$ 对 $d$ 的导数分别是：\n$$\\frac{\\partial u}{\\partial d} = \\frac{\\partial}{\\partial d}(c - a) = 0$$\n$$\\frac{\\partial v}{\\partial d} = \\frac{\\partial}{\\partial d}(b + d) = 1$$\n将这些代入商的求导法则公式中：\n$$\\frac{\\partial P^{*}}{\\partial d} = \\frac{(0)(b + d) - (c - a)(1)}{(b + d)^2}$$\n简化后得到：\n$$\\frac{\\partial P^{*}}{\\partial d} = -\\frac{c - a}{(b + d)^2}$$\n\n因此，这两个敏感度是相同的。两个导数都为负，这符合预期。无论是供给响应性（$b$）还是需求响应性（$d$）的增加，都会导致均衡价格的下降，因为一个更具弹性的市场对价格变化的反应更强烈，从而拉低均衡价格。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n-\\frac{c-a}{(b+d)^{2}} & -\\frac{c-a}{(b+d)^{2}}\n\\end{pmatrix}\n}\n$$", "id": "3191079"}, {"introduction": "从分析模型转向计算流程，本练习在图像处理的背景下探讨数值敏感度。许多算法（如高斯模糊）依赖于其最优值并非显而易见的参数。在这里，我们研究高斯模糊的输出对其标准差参数 $\\sigma$ 的微小变化的敏感程度。这个编程练习 [@problem_id:3272432] 将指导你完成一个完整的敏感性分析，从推导敏感度核到使用离散傅里叶变换 (DFT) 等数值方法进行高效计算，为你评估科学软件的稳健性提供实践经验。", "problem": "考虑一个表示为实值数组 $I \\in \\mathbb{R}^{n \\times n}$（其中 $n = 16$）的二维离散图像。标准差为 $\\sigma > 0$ 的高斯模糊定义为图像 $I$ 与一个二维可分离高斯核 $K_{\\sigma}$ 的卷积，该核由一维高斯函数 $g(x;\\sigma)$ 沿各轴构建。一维高斯函数由以下基本定义给出\n$$\ng(x;\\sigma) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma}\\exp\\!\\left(-\\frac{x^{2}}{2\\sigma^{2}}\\right),\n$$\n而在有限模板上的二维核为 $K_{\\sigma}(x,y) = g(x;\\sigma)\\,g(y;\\sigma)$，在整数格点 $(x,y) \\in \\{-R,\\ldots,R\\} \\times \\{-R,\\ldots,R\\}$ 上求值，其中 $R = 7$ 是用于数值近似的固定模板半宽。当 $R$ 相对于 $\\sigma$ 足够大时，这种有限支撑近似在科学上是合理的，并且在此处固定该值以保证所有测试用例的可复现性。\n\n对于离散图像，卷积使用二维离散傅里叶变换（DFT）执行，这对应于周期性边界条件下的卷积（循环卷积）。具体来说，模糊后的图像 $B_{\\sigma}$ 由下式给出\n$$\nB_{\\sigma} = \\mathcal{F}^{-1}\\!\\left(\\mathcal{F}(I)\\,\\odot\\,\\mathcal{F}(K_{\\sigma}^{\\mathrm{pad}})\\right),\n$$\n其中 $\\mathcal{F}$ 表示 DFT，$\\mathcal{F}^{-1}$ 表示其逆变换，$\\odot$ 表示逐点乘积，而 $K_{\\sigma}^{\\mathrm{pad}}$ 是将核 $K_{\\sigma}$ 零填充至图像大小 $n \\times n$ 并进行循环移位，使其中心与 DFT 域中的零移位对齐。\n\n定义高斯模糊图像对 $\\sigma$ 的敏感度为以下比率\n$$\nS(I,\\sigma) = \\frac{\\left\\lVert \\frac{\\partial B_{\\sigma}}{\\partial \\sigma} \\right\\rVert_{F}}{\\left\\lVert B_{\\sigma} \\right\\rVert_{F}},\n$$\n其中 $\\lVert\\cdot\\rVert_{F}$ 表示弗罗贝尼乌斯范数。如果 $\\lVert B_{\\sigma} \\rVert_{F} = 0$，为避免除以零，按惯例定义 $S(I,\\sigma) = 0$。利用乘积结构 $K_{\\sigma}(x,y) = g(x;\\sigma)g(y;\\sigma)$ 以及微分和卷积的线性性质，可以通过将 $I$ 与 $\\frac{\\partial K_{\\sigma}}{\\partial \\sigma}$ 卷积来计算敏感度，而 $\\frac{\\partial K_{\\sigma}}{\\partial \\sigma}$ 本身可从一维高斯函数对 $\\sigma$ 的导数得到：\n$$\n\\frac{\\partial g(x;\\sigma)}{\\partial \\sigma} = g(x;\\sigma)\\left(\\frac{x^{2}}{\\sigma^{3}} - \\frac{1}{\\sigma}\\right),\n$$\n然后对可分离的二维核应用乘法法则。\n\n你的任务是实现一个程序：\n- 对于每个给定的 $\\sigma$，在大小为 $(2R+1)\\times(2R+1)$（其中 $R=7$）的有限模板上构建 $K_{\\sigma}$ 和 $\\frac{\\partial K_{\\sigma}}{\\partial \\sigma}$。\n- 使用 DFT 执行循环卷积以获得 $B_{\\sigma}$ 和 $\\frac{\\partial B_{\\sigma}}{\\partial \\sigma}$。\n- 对每个测试用例，使用弗罗贝尼乌斯范数计算 $S(I,\\sigma)$。\n\n使用以下图像和参数的测试套件：\n- 用例 1：$I$ 是一个脉冲图像，其中 $I_{8,8} = 1$ 且所有其他项为 $0$，$\\sigma = 1.0$。\n- 用例 2：$I$ 是一个斜坡图像，定义为 $I_{i,j} = \\frac{i + j}{30}$，其中索引 $i,j \\in \\{0,\\ldots,15\\}$，$\\sigma = 0.5$。\n- 用例 3：$I$ 是一个常数图像，其中对所有 $i,j$ 都有 $I_{i,j} = 1$，$\\sigma = 2.0$。\n- 用例 4：$I$ 是一个棋盘格图像，定义为 $I_{i,j} = (-1)^{i+j}$，$\\sigma = 3.0$。\n- 用例 5：$I$ 是一个随机图像，由以 $0$ 为种子的伪随机数生成器生成，其项独立地从 $[0,1]$ 上的均匀分布中抽取，$\\sigma = 0.1$。\n\n所有图像的大小均为 $16 \\times 16$。不使用角度。不涉及物理单位。每个用例的输出必须是代表 $S(I,\\sigma)$ 的一个实数。\n\n你的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔的结果列表（例如，$[s_{1},s_{2},s_{3},s_{4},s_{5}]$）。每个 $s_{k}$ 必须是浮点数。为便于阅读，你可以将每个数字格式化为六位小数。", "solution": "该问题是有效的。它提出了一个应用于图像处理的数值敏感度分析中明确定义的任务。所有概念，包括高斯模糊、通过离散傅里叶变换（DFT）进行卷积以及敏感度的定义，在科学和数学上都是合理的。该问题是自洽的，为获得唯一、可验证的解提供了所有必要的参数、公式和测试用例。\n\n目标是计算高斯模糊图像 $B_{\\sigma}$ 相对于高斯标准差 $\\sigma$ 的敏感度 $S(I, \\sigma)$。敏感度定义为模糊图像关于 $\\sigma$ 的导数的弗罗贝尼乌斯范数与模糊图像本身的弗罗贝尼乌斯范数之比：\n$$\nS(I,\\sigma) = \\frac{\\left\\lVert \\frac{\\partial B_{\\sigma}}{\\partial \\sigma} \\right\\rVert_{F}}{\\left\\lVert B_{\\sigma} \\right\\rVert_{F}}\n$$\n其中 $\\lVert\\cdot\\rVert_{F}$ 表示弗罗贝尼乌斯范数。对于矩阵 $A \\in \\mathbb{R}^{n \\times n}$，弗罗贝尼乌斯范数为 $\\lVert A \\rVert_{F} = \\sqrt{\\sum_{i=0}^{n-1} \\sum_{j=0}^{n-1} |A_{ij}|^2}$。按照惯例，如果分母为零，则 $S(I,\\sigma) = 0$。\n\n对于每个测试用例，计算过程分为几个步骤，每个用例都将一个输入图像 $I \\in \\mathbb{R}^{n \\times n}$（其中 $n=16$）与一个参数 $\\sigma$ 配对。\n\n首先，我们构建所需的卷积核。模糊处理使用一个在离散模板上定义的可分离二维高斯核 $K_{\\sigma}$ 进行。该核由一维高斯函数构建：\n$$\ng(x;\\sigma) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma}\\exp\\!\\left(-\\frac{x^{2}}{2\\sigma^{2}}\\right)\n$$\n问题指定了一个半宽为 $R=7$ 的有限模板，因此离散坐标为 $x, y \\in \\{-7, -6, \\ldots, 6, 7\\}$。二维核是在这些坐标上求值的一维函数的外积：$K_{\\sigma}(x,y) = g(x;\\sigma)g(y;\\sigma)$。\n\n为了计算敏感度表达式的分子，我们需要模糊图像的导数 $\\frac{\\partial B_{\\sigma}}{\\partial \\sigma}$。由于卷积和微分的线性性质，这等同于将原始图像 $I$ 与核的导数 $\\frac{\\partial K_{\\sigma}}{\\partial \\sigma}$ 进行卷积。我们首先求一维高斯函数相对于 $\\sigma$ 的导数：\n$$\n\\frac{\\partial g(x;\\sigma)}{\\partial \\sigma} = g(x;\\sigma)\\left(\\frac{x^{2}}{\\sigma^{3}} - \\frac{1}{\\sigma}\\right)\n$$\n对可分离的二维核 $K_{\\sigma}(x,y) = g(x;\\sigma)g(y;\\sigma)$ 使用微分的乘法法则，我们得到其导数：\n$$\n\\frac{\\partial K_{\\sigma}(x,y)}{\\partial \\sigma} = \\frac{\\partial g(x;\\sigma)}{\\partial \\sigma} g(y;\\sigma) + g(x;\\sigma) \\frac{\\partial g(y;\\sigma)}{\\partial \\sigma}\n$$\n$K_{\\sigma}$ 和 $\\frac{\\partial K_{\\sigma}}{\\partial \\sigma}$ 都被构建为 $(2R+1) \\times (2R+1) = 15 \\times 15$ 的矩阵。\n\n其次，我们使用离散傅里叶变换（DFT）执行卷积。卷积定理指出，空间域中的卷积等同于频率域中的逐点乘积。因此，模糊图像 $B_{\\sigma}$ 及其导数 $\\frac{\\partial B_{\\sigma}}{\\partial \\sigma}$ 计算如下：\n$$\nB_{\\sigma} = \\mathcal{F}^{-1}\\!\\left(\\mathcal{F}(I)\\,\\odot\\,\\mathcal{F}(K_{\\sigma}^{\\mathrm{pad}})\\right)\n$$\n$$\n\\frac{\\partial B_{\\sigma}}{\\partial \\sigma} = I * \\frac{\\partial K_{\\sigma}}{\\partial \\sigma} = \\mathcal{F}^{-1}\\!\\left(\\mathcal{F}(I)\\,\\odot\\,\\mathcal{F}\\left(\\left[\\frac{\\partial K_{\\sigma}}{\\partial \\sigma}\\right]^{\\mathrm{pad}}\\right)\\right)\n$$\n这里，$\\mathcal{F}$ 和 $\\mathcal{F}^{-1}$ 分别代表二维 DFT 及其逆变换，$\\odot$ 是逐点乘积。该操作要求将核填充以匹配图像大小 $n \\times n = 16 \\times 16$。符号 $K^{\\mathrm{pad}}$ 表示将 $15 \\times 15$ 的核放置在一个 $16 \\times 16$ 的零数组中并进行循环移位。此移位将核的概念中心（在模板上的坐标 $(0,0)$）与 DFT 域中的零频分量（对应于数组的索引 $(0,0)$）对齐。这是通过 DFT 实现卷积的标准程序。\n\n总体算法如下：\n1.  对于每个测试用例，生成 $16 \\times 16$ 的图像矩阵 $I$ 并设置相应的 $\\sigma$ 值。\n2.  定义从 $x=-7$ 到 $x=7$ 的一维模板坐标。\n3.  计算一维高斯函数 $g(x;\\sigma)$ 及其导数 $\\frac{\\partial g(x;\\sigma)}{\\partial \\sigma}$ 在模板上所有点的值。\n4.  使用一维数组的外积构建二维 $15 \\times 15$ 的核 $K_{\\sigma}$ 和 $\\frac{\\partial K_{\\sigma}}{\\partial \\sigma}$。\n5.  创建这些核的填充和移位后的版本 $K_{\\sigma}^{\\mathrm{pad}}$ 和 $[\\frac{\\partial K_{\\sigma}}{\\partial \\sigma}]^{\\mathrm{pad}}$，大小为 $16 \\times 16$。\n6.  计算图像 $I$ 和两个填充后核的二维 DFT。\n7.  在频率域中进行逐点乘积，以获得 $B_{\\sigma}$ 和 $\\frac{\\partial B_{\\sigma}}{\\partial \\sigma}$ 的频谱。\n8.  计算这些频谱的二维逆 DFT，以获得空间域矩阵 $B_{\\sigma}$ 和 $\\frac{\\partial B_{\\sigma}}{\\partial \\sigma}$。取结果的实部以丢弃由数值误差产生的可忽略的虚部。\n9.  计算弗罗贝尼乌斯范数 $\\left\\lVert B_{\\sigma} \\right\\rVert_{F}$ 和 $\\left\\lVert \\frac{\\partial B_{\\sigma}}{\\partial \\sigma} \\right\\rVert_{F}$。\n10. 将它们的比值作为敏感度 $S(I,\\sigma)$ 进行计算，处理分母为零的情况。\n11. 将所有测试用例的结果整理成最终的输出格式。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the sensitivity of a Gaussian-blurred image to the blur parameter sigma.\n    \"\"\"\n\n    def calculate_sensitivity(I, sigma, n, R):\n        \"\"\"\n        Calculates S(I, sigma) for a given image I and parameter sigma.\n        \n        Args:\n            I (np.ndarray): The input image (n x n).\n            sigma (float): The standard deviation of the Gaussian blur.\n            n (int): The dimension of the image.\n            R (int): The half-width of the kernel stencil.\n\n        Returns:\n            float: The computed sensitivity.\n        \"\"\"\n        # 1. Construct Kernels\n        k_size = 2 * R + 1\n        x_coords = np.arange(-R, R + 1, dtype=float)\n        \n        # 1D Gaussian function\n        # Check for sigma being very small to avoid overflow in exp, though not needed for test cases\n        if sigma  1e-9: \n            return 0.0\n        g_1d = (1 / (np.sqrt(2 * np.pi) * sigma)) * np.exp(-x_coords**2 / (2 * sigma**2))\n        \n        # 1D Gaussian derivative with respect to sigma\n        dg_dsigma_1d = g_1d * (x_coords**2 / sigma**3 - 1 / sigma)\n\n        # 2D kernels from outer products, based on separability\n        K_sigma = np.outer(g_1d, g_1d)\n        dK_dsigma = np.outer(dg_dsigma_1d, g_1d) + np.outer(g_1d, dg_dsigma_1d)\n\n        # 2. Pad and shift kernels for DFT convolution\n        def pad_and_shift(kernel, n_pad):\n            \"\"\"Pads a kernel to size n_pad x n_pad and shifts it for FFT convolution.\"\"\"\n            padded = np.zeros((n_pad, n_pad), dtype=float)\n            padded[:k_size, :k_size] = kernel\n            # Roll to move kernel center (R, R) to (0, 0)\n            return np.roll(padded, (-R, -R), axis=(0, 1))\n\n        K_sigma_pad = pad_and_shift(K_sigma, n)\n        dK_dsigma_pad = pad_and_shift(dK_dsigma, n)\n        \n        # 3. Perform convolution via DFT\n        F_I = np.fft.fft2(I)\n        F_K = np.fft.fft2(K_sigma_pad)\n        F_dK = np.fft.fft2(dK_dsigma_pad)\n        \n        # 4. Get results in the spatial domain via inverse DFT\n        # The result should be real; np.real handles small imaginary parts from numerical error.\n        B_sigma = np.real(np.fft.ifft2(F_I * F_K))\n        dB_dsigma = np.real(np.fft.ifft2(F_I * F_dK))\n        \n        # 5. Calculate norms and sensitivity\n        norm_B = np.linalg.norm(B_sigma)  # Frobenius norm is the default for 2D arrays\n        norm_dB = np.linalg.norm(dB_dsigma)\n        \n        if norm_B == 0:\n            return 0.0\n        else:\n            return norm_dB / norm_B\n\n    # Define problem parameters and test cases\n    n = 16\n    R = 7\n\n    # Case 1: Impulse image\n    I1 = np.zeros((n, n), dtype=float)\n    I1[8, 8] = 1.0\n\n    # Case 2: Ramp image\n    ii, jj = np.ogrid[0:n, 0:n]\n    I2 = (ii + jj) / 30.0\n\n    # Case 3: Constant image\n    I3 = np.ones((n, n), dtype=float)\n\n    # Case 4: Checkerboard image\n    I4 = ((-1)**(ii + jj)).astype(float)\n\n    # Case 5: Random image\n    rng = np.random.default_rng(seed=0)\n    I5 = rng.uniform(0, 1, size=(n, n))\n\n    test_cases = [\n        (I1, 1.0),\n        (I2, 0.5),\n        (I3, 2.0),\n        (I4, 3.0),\n        (I5, 0.1),\n    ]\n\n    results = []\n    for I, sigma in test_cases:\n        sensitivity = calculate_sensitivity(I, sigma, n, R)\n        results.append(sensitivity)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```", "id": "3272432"}, {"introduction": "最后的这个练习将我们的重点从定量计算转向机器学习领域内的定性、概念性洞察。我们不再问“变化多少？”，而是问“它到底会不会变？”。我们将分析一个支持向量机 (SVM)，并思考移除一个看似不重要的数据点会产生什么影响。这个思想实验 [@problem_id:3272515] 挑战你应用对模型底层优化原理（KKT 条件）的理论知识来预测其决策边界的稳定性，揭示了对模型结构的深刻理解是敏感性分析的最终形式。", "problem": "考虑一个线性的二分类软间隔支持向量机 (SVM)，它在一个数据集 $\\{(x_i,y_i)\\}_{i=1}^n$ 上进行训练，其中 $x_i \\in \\mathbb{R}^d$ 且 $y_i \\in \\{-1, +1\\}$。其原始问题为\n$$\n\\min_{w,b,\\xi} \\;\\; \\frac{1}{2}\\|w\\|_2^2 + C \\sum_{i=1}^n \\xi_i \\quad \\text{subject to } \\quad y_i\\,(w^\\top x_i + b) \\ge 1 - \\xi_i,\\;\\; \\xi_i \\ge 0 \\;\\; \\text{for all } i,\n$$\n其中 $C0$ 是给定的。令 $(w^\\star,b^\\star,\\xi^\\star)$ 为一个原始最优解，并令 $\\alpha^\\star \\in \\mathbb{R}^n$ 表示由 Karush-Kuhn-Tucker (KKT) 条件得到的与间隔约束相关的最优拉格朗日乘子。如果 $\\alpha_j^\\star0$，则称训练点 $(x_j,y_j)$ 为一个支持向量。\n\n假设对于某个特定的索引 $j$ 满足以下条件：在最优解处，$\\alpha_j^\\star = 0$ 且函数间隔严格大于间隔阈值，即 $y_j\\,(w^{\\star\\top} x_j + b^\\star)  1$。考虑将数据点 $(x_j,y_j)$ 从训练集中移除，并使用相同的 $C$ 值在缩减后的数据集上重新训练 SVM。假设对于原始问题和缩减后的问题，其最优解都是唯一的。\n\n哪个陈述最能描述移除点 $(x_j,y_j)$ 对学到的决策边界的影响？\n\nA. 决策边界，即 $w^\\star$ 和 $b^\\star$ 均保持不变。\n\nB. 法向量 $w^\\star$ 保持不变，但偏置 $b^\\star$ 会移动以保持剩余点的可行性。\n\nC. 间隔宽度严格增加，等价于 $\\|w^\\star\\|_2$ 严格减小，因为一个约束被移除了。\n\nD. 即使 $\\alpha_j^\\star=0$，决策边界也可能发生显著旋转，因为移除后可行集发生了变化。\n\nE. 即使最终的 $w^\\star$ 与之前相同，剩余点的支持向量集合和系数 $\\alpha_i^\\star$ 也可能发生变化。", "solution": "用户希望我分析移除特定类型的数据点对软间隔支持向量机 (SVM) 解的影响。\n\n### 步骤 1：问题验证\n\n我将首先提取给定信息并验证问题陈述。\n\n#### 已知条件\n1.  **模型**：二分类软间隔支持向量机 (SVM)，线性情况。\n2.  **数据集**：$\\{(x_i,y_i)\\}_{i=1}^n$ 其中 $x_i \\in \\mathbb{R}^d$ 且 $y_i \\in \\{-1, +1\\}$。\n3.  **原始优化问题**：\n    $$\n    \\min_{w,b,\\xi} \\;\\; \\frac{1}{2}\\|w\\|_2^2 + C \\sum_{i=1}^n \\xi_i\n    $$\n    约束条件：\n    $$\n    y_i\\,(w^\\top x_i + b) \\ge 1 - \\xi_i, \\quad \\xi_i \\ge 0 \\quad \\text{for all } i=1, \\dots, n.\n    $$\n4.  **超参数**：一个给定的常数 $C0$。\n5.  **最优解**：令 $(w^\\star,b^\\star,\\xi^\\star)$ 为一个原始最优解。令 $\\alpha^\\star \\in \\mathbb{R}^n$ 为与间隔约束相关的最优拉格朗日乘子。\n6.  **支持向量定义**：如果 $\\alpha_j^\\star  0$，则点 $(x_j, y_j)$ 是一个支持向量。\n7.  **关于点 $j$ 的条件**：对于特定的索引 $j$，假设在最优解处，$\\alpha_j^\\star = 0$ 和 $y_j(w^{\\star\\top} x_j + b^\\star)  1$。\n8.  **操作**：移除点 $(x_j, y_j)$，并使用相同的 $C$ 在缩减后的数据集上重新训练 SVM。\n9.  **唯一性假设**：原始问题和缩减后的问题的最优解都是唯一的。\n\n#### 验证\n问题陈述描述了支持向量机分析中的一个标准场景。原始问题的表述是正确的。Karush-Kuhn-Tucker (KKT) 条件是分析解的标准理论工具，并且所提供的假设与这些条件一致。\n\n让我们回顾一下原始问题的 KKT 条件。拉格朗日函数为：\n$$\nL(w, b, \\xi, \\alpha, \\mu) = \\frac{1}{2}\\|w\\|_2^2 + C \\sum_{i=1}^n \\xi_i - \\sum_{i=1}^n \\alpha_i [y_i(w^\\top x_i + b) - 1 + \\xi_i] - \\sum_{i=1}^n \\mu_i \\xi_i\n$$\n其中 $\\alpha_i \\ge 0$ 和 $\\mu_i \\ge 0$ 是拉格朗日乘子。在最优解 $(w^\\star, b^\\star, \\xi^\\star, \\alpha^\\star, \\mu^\\star)$ 处的 KKT 条件包括：\n1.  $\\nabla_w L = w^\\star - \\sum_{i=1}^n \\alpha_i^\\star y_i x_i = 0 \\implies w^\\star = \\sum_{i=1}^n \\alpha_i^\\star y_i x_i$。\n2.  $\\nabla_b L = -\\sum_{i=1}^n \\alpha_i^\\star y_i = 0$。\n3.  对于所有 $i$，$\\nabla_{\\xi_i} L = C - \\alpha_i^\\star - \\mu_i^\\star = 0$。\n4.  互补松弛性：对于所有 $i$，$\\alpha_i^\\star [y_i(w^{\\star\\top} x_i + b^\\star) - 1 + \\xi_i^\\star] = 0$ 且 $\\mu_i^\\star \\xi_i^\\star = 0$。\n\n给定关于点 $j$ 的条件是 $\\alpha_j^\\star = 0$ 和 $y_j(w^{\\star\\top} x_j + b^\\star)  1$。\n从条件 3 可知，$\\alpha_j^\\star = 0 \\implies \\mu_j^\\star=C$。因为 $C0$，所以 $\\mu_j^\\star  0$。\n从互补松弛性可知，$\\mu_j^\\star  0 \\implies \\xi_j^\\star=0$。\n当 $\\xi_j^\\star=0$ 时，原始可行性约束 $y_j(w^{\\star\\top} x_j + b^\\star) \\ge 1 - \\xi_j^\\star$ 变为 $y_j(w^{\\star\\top} x_j + b^\\star) \\ge 1$。给定的假设 $y_j(w^{\\star\\top} x_j + b^\\star)  1$ 是一个更强但完全有效的情况，此时该约束是非激活的。互补松弛性条件 $\\alpha_j^\\star [y_j(w^{\\star\\top} x_j + b^\\star) - 1 + \\xi_j^\\star] = 0$ 因为 $\\alpha_j^\\star = 0$ 而得到满足。\n\n这个问题在科学上是合理的，是适定问题（尤其是在唯一性假设下），并且是客观的。它不违反任何验证标准。\n\n**结论**：问题有效。\n\n### 步骤 2：求解推导\n\n关键的洞察在于理解最优解是如何构建的。KKT 条件定义了最优解。让我们来分析移除点 $j$ 对这些条件的影响。\n\n最优权重向量 $w^\\star$ 由 $w^\\star = \\sum_{i=1}^n \\alpha_i^\\star y_i x_i$ 给出。由于我们已知 $\\alpha_j^\\star = 0$，点 $(x_j, y_j)$ 对这个求和没有贡献。该点不是支持向量。求和实际上是针对支持向量集 $SV = \\{i \\mid \\alpha_i^\\star  0\\}$ 进行的。\n$$\nw^\\star = \\sum_{i \\in SV} \\alpha_i^\\star y_i x_i\n$$\n类似地，关于乘子的条件 $\\sum_{i=1}^n \\alpha_i^\\star y_i = 0$ 也不涉及索引为 $j$ 的项，因为 $\\alpha_j^\\star = 0$。\n\n现在，考虑移除点 $(x_j, y_j)$ 后的新问题。新的优化问题是：\n$$\n\\min_{w',b',\\xi'} \\;\\; \\frac{1}{2}\\|w'\\|_2^2 + C \\sum_{i \\ne j} \\xi'_i\n$$\n约束条件：\n$$\ny_i\\,(w'^\\top x_i + b') \\ge 1 - \\xi'_i, \\quad \\xi'_i \\ge 0 \\quad \\text{for all } i \\ne j.\n$$\n让我们看看原始解 $(w^\\star, b^\\star)$ 是否是这个新问题的有效解。我们可以为新问题提出一个候选解，其中与剩余点对应的变量保留其原始最优值：\n-   $w'_{cand} = w^\\star$\n-   $b'_{cand} = b^\\star$\n-   对于 $i \\ne j$，$\\xi'_{cand, i} = \\xi_i^\\star$\n-   对于 $i \\ne j$，$\\alpha'_{cand, i} = \\alpha_i^\\star$\n\n我们必须检查这个候选解是否满足新问题的 KKT 条件。新问题的 KKT 条件涉及对 $i \\ne j$ 的求和。\n\n1.  **关于 $w'$ 的平稳性条件**：我们需要 $w'_{cand} - \\sum_{i \\ne j} \\alpha'_{cand, i} y_i x_i = 0$。\n    代入候选值，得到 $w^\\star - \\sum_{i \\ne j} \\alpha_i^\\star y_i x_i = 0$。从原始问题中，我们知道 $w^\\star = \\sum_{i=1}^n \\alpha_i^\\star y_i x_i$。由于 $\\alpha_j^\\star = 0$，这个和与 $\\sum_{i \\ne j} \\alpha_i^\\star y_i x_i$ 是相同的。因此，$w^\\star - w^\\star = 0$。此条件满足。\n\n2.  **关于 $b'$ 的平稳性条件**：我们需要 $-\\sum_{i \\ne j} \\alpha'_{cand, i} y_i = 0$。\n    这变为 $-\\sum_{i \\ne j} \\alpha_i^\\star y_i = 0$。从原始问题中，我们知道 $\\sum_{i=1}^n \\alpha_i^\\star y_i = 0$。由于 $\\alpha_j^\\star = 0$，这个和与 $\\sum_{i \\ne j} \\alpha_i^\\star y_i$ 是相同的。此条件也满足。\n\n3.  **其他 KKT 条件**：对于所有点 $i \\ne j$ 的原始可行性、对偶可行性和互补松弛性也通过构造得到满足，因为它们与原始问题中 $(w^\\star, b^\\star, \\xi^\\star, \\alpha^\\star)$ 已经满足的条件相同。点 $(x_j, y_j)$ 及其相关的约束和乘子只是被移除了，不再考虑。\n\n这意味着原始解 $(w^\\star, b^\\star)$，连同剩余点对应的松弛变量和乘子，构成了新问题的一个 KKT 点。对于像 SVM 这样的凸优化问题，任何 KKT 点都是一个全局最优解。\n\n问题陈述中包含了缩减后问题的最优解是唯一的这一假设。既然我们已经找到了一个最优解——即从原始问题继承而来的解——它就必定是*那个*唯一的最优解。\n\n因此，新的最优权重向量 $w'^\\star$ 等于原始的 $w^\\star$，新的最优偏置 $b'^\\star$ 等于原始的 $b^\\star$。由方程 $w^\\top x + b = 0$ 定义的决策边界保持不变。\n\n### 步骤 3：逐项分析选项\n\n**A. 决策边界，即 $w^\\star$ 和 $b^\\star$ 均保持不变。**\n如上所述，原始最优解 $(w^\\star, b^\\star)$ 满足移除点 $j$ 后新问题的 KKT 条件。鉴于唯一性假设，新的最优解必须与旧的相同。因此，法向量 $w^\\star$ 和偏置 $b^\\star$ 都保持不变。这个陈述是**正确的**。\n\n**B. 法向量 $w^\\star$ 保持不变，但偏置 $b^\\star$ 会移动以保持剩余点的可行性。**\n我们的分析表明 $w^\\star$ 和 $b^\\star$ 都保持不变。$b^\\star$ 的移动将意味着原始解对 $(w^\\star, b^\\star)$ 对于新问题不是最优的，这与我们的 KKT 分析相矛盾。这个陈述是**不正确的**。\n\n**C. 间隔宽度严格增加，等价于 $\\|w^\\star\\|_2$ 严格减小，因为一个约束被移除了。**\n间隔宽度由 $2/\\|w\\|_2$ 给出。宽度的增加对应于 $\\|w\\|_2$ 的减小。我们的推导得出结论，新的最优权重向量与旧的相同，即 $w'^\\star = w^\\star$。因此，$\\|w'^\\star\\|_2 = \\|w^\\star\\|_2$，间隔宽度不变。那种“移除一个约束可能会导致更好的（更低的）目标值”的一般直觉在这里不适用，因为被移除的约束 $y_j(w^{\\star\\top}x_j+b^\\star) \\ge 1-\\xi_j^\\star$ 在原始最优解处是非激活的（$y_j(w^{\\star\\top}x_j+b^\\star)  1$ 且 $\\xi_j^\\star=0$）。移除一个非激活约束不会改变凸优化问题的最优解。这个陈述是**不正确的**。\n\n**D. 即使 $\\alpha_j^\\star=0$，决策边界也可能发生显著旋转，因为移除后可行集发生了变化。**\n决策边界的旋转意味着法向量 $w^\\star$ 方向的改变。如前所示，$w^\\star$ 保持不变。优化问题的可行集确实发生了变化，但由于被移除的约束在最优解处是非激活的，这种变化不影响最小值的位置。这个陈述是**不正确的**。\n\n**E. 即使最终的 $w^\\star$ 与之前相同，剩余点的支持向量集合和系数 $\\alpha_i^\\star$ 也可能发生变化。**\n我们的分析表明，剩余点的最优拉格朗日乘子 $\\alpha'_i{^\\star}$ (对于 $i \\ne j$) 与原始的 $\\alpha_i^\\star$ 相同。因此，剩余点中的支持向量集合 $\\{i \\ne j \\mid \\alpha_i^\\star  0\\}$ 也保持不变。该陈述声称它们可能改变，这在给定条件下是错误的。这个陈述是**不正确的**。", "answer": "$$\\boxed{A}$$", "id": "3272515"}]}