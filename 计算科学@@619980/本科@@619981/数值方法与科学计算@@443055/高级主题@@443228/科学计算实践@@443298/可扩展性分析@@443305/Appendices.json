{"hands_on_practices": [{"introduction": "本练习将从性能分析中的一项基本任务入手：对一个并行程序的特性进行逆向工程。您将利用一组给定的运行时测量数据，应用阿姆达尔定律（Amdahl's Law）来估计程序的串行分数 $s$，这是决定其强扩展性（strong-scaling）潜力的关键参数。这项实践将理论模型与实际性能数据联系起来，旨在锻炼您在数据分析和模型拟合方面的技能。[@problem_id:3270745]", "problem": "给定一个黑盒科学程序在一台拥有多达 $P=1024$ 个相同处理核心的分布式内存高性能计算 (HPC) 环境中执行的测量数据。您的目标是在固定规模问题的假设下，推断该程序工作负载的串行分数 $s$。请使用以下基本原理来指导您的推理和方法：对于固定的工作负载，在 $P$ 个处理单元上的加速比定义为 $S(P)=T(1)/T(P)$，其中 $T(P)$ 是使用 $P$ 个处理单元的执行时间；总运行时间可以分解为一个无法并行化的部分和一个可以在各处理单元间均匀分布的部分，同时忽略其他开销来源并假设负载完美均衡。\n\n您的任务是设计并实现一个程序，针对每个提供的数据集，通过将固定规模运行时间分解模型拟合到观测到的加速比曲线上，来估计串行分数 $s$。您的估计算法必须对数据中存在 $P=1$ 的情况具有鲁棒性。每个数据集的输出必须是一个十进制形式的实数 $s$。报告的 $s$ 值需四舍五入到六位小数。$s$ 是无量纲的，因此不需要单位。\n\n实现要求：\n- 使用定义 $S(P)=T(1)/T(P)$。\n- 每个数据集使用所有提供的数据点。\n- 为便于估计，请将模型假设视为精确的；如果数据完全符合模型，您的估计算法应能精确地恢复 $s$。如果数据中存在 $P=1$ 的情况，请在您的拟合过程中正确处理，避免出现除以零或未定义的操作。\n\n测试套件：\n对于下面的每个数据集，您会得到一个核心数列表和一个相应的测量时间列表。在每个数据集中，所有时间都以相同的任意时间单位给出。\n\n- 数据集 A（宽 $P$ 值范围，中等串行分数）：\n  - $P$: $[1,2,4,8,16,32,64,128,256,512,1024]$\n  - $T(P)$: $[100.0,56.0,34.0,23.0,17.5,14.75,13.375,12.6875,12.34375,12.171875,12.0859375]$\n\n- 数据集 B（宽 $P$ 值范围，极小串行分数）：\n  - $P$: $[1,2,4,8,16,32,64,128,256,512,1024]$\n  - $T(P)$: $[100.0,50.5,25.75,13.375,7.1875,4.09375,2.546875,1.7734375,1.38671875,1.193359375,1.0966796875]$\n\n- 数据集 C（有限 $P$ 值范围，大串行分数）：\n  - $P$: $[1,2,4,8,16]$\n  - $T(P)$: $[80.0,60.0,50.0,45.0,42.5]$\n\n- 数据集 D（宽 $P$ 值范围，理想并行情况）：\n  - $P$: $[1,2,4,8,16,32,64,128,256,512,1024]$\n  - $T(P)$: $[64.0,32.0,16.0,8.0,4.0,2.0,1.0,0.5,0.25,0.125,0.0625]$\n\n- 数据集 E（宽 $P$ 值范围，完全串行情况）：\n  - $P$: $[1,2,4,8,16,32,64,128,256,512,1024]$\n  - $T(P)$: $[42.0,42.0,42.0,42.0,42.0,42.0,42.0,42.0,42.0,42.0,42.0]$\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，“[rA,rB,rC,rD,rE]”），其中 rA 是数据集 A 的估计值，rB 是数据集 B 的估计值，依此类推至数据集 E。每个值必须使用标准四舍五入规则保留六位小数（当距离相等时取远离零的数，这与典型的浮点格式化实现一致）。", "solution": "问题陈述已经过分析，并被认为是有效的。它科学地基于并行计算的原理，特别是针对固定规模问题的阿姆达尔定律。该问题是适定的，提供了足够的数据和明确的目标来估计模型参数 $s$。所用术语精确客观。所提供的数据集是一致的，可作为所提出模型的有效测试用例，包括理想情况和边界情况。\n\n问题的核心是，在给定 $P$ 个处理核心上的一系列运行时间测量值 $T(P)$ 的情况下，估计程序的串行分数 $s$。其指导原则是将单个处理器上的总运行时间 $T(1)$ 分解为串行部分和可并行化部分。\n\n设 $s$ 为串行分数，其中 $0 \\le s \\le 1$。那么程序中可并行的部分所占比例为 $(1-s)$。\n工作负载串行部分所需的时间为 $s \\cdot T(1)$。无论处理器数量 $P$ 为多少，这个时间都是恒定的。\n工作负载可并行化部分在单个处理器上所需的时间为 $(1-s) \\cdot T(1)$。当分布到 $P$ 个处理器上，并假设无开销的完美并行时，这个时间变为 $\\frac{(1-s) \\cdot T(1)}{P}$。\n\n在 $P$ 个处理器上的总执行时间 $T(P)$ 是串行执行时间和并行执行时间之和：\n$$T(P) = s \\cdot T(1) + \\frac{(1-s) \\cdot T(1)}{P}$$\n这个方程是阿姆达尔定律关于运行时间的一种具体表述。我们的目标是根据所提供的数据对 $(P_i, T(P_i))$ 来估计 $s$。\n\n为了估计 $s$，我们可以将这个方程重构为一个线性模型，该模型适用于标准的线性回归技术。我们定义一个新的自变量 $x = 1/P$。该方程可以重写为：\n$$T(P) = (s \\cdot T(1)) + ( (1-s) \\cdot T(1) ) \\cdot \\frac{1}{P}$$\n该方程符合直线方程 $y = c + m \\cdot x$ 的形式，其中：\n- 因变量是 $y = T(P)$。\n- 自变量是 $x = 1/P$。\n- y 轴截距是 $c = s \\cdot T(1)$。这代表了纯串行部分的运行时间，也就是当 $P \\to \\infty$（即 $x \\to 0$）时的理论运行时间。\n- 斜率是 $m = (1-s) \\cdot T(1)$。这代表了工作负载中可并行化部分在单核上运行时的总时间。\n\n我们有 $N$ 个数据点 $(P_i, T_i)$，由此可以生成一组用于线性回归的点 $(x_i, y_i) = (1/P_i, T_i)$。这包括了 $P=1$（此时 $x=1$）的数据点。通过对这些点进行线性最小二乘回归，我们可以找到截距 $\\hat{c}$ 和斜率 $\\hat{m}$ 的最佳拟合估计值。\n\n一旦我们得到 $\\hat{c}$ 和 $\\hat{m}$，就可以推导出 $s$ 的估计值。根据我们对斜率和截距的定义，它们的和是：\n$$\\hat{c} + \\hat{m} \\approx s \\cdot T(1) + (1-s) \\cdot T(1) = T(1)$$\n这个和 $\\hat{c} + \\hat{m}$ 提供了基于所有可用数据的模型对总单处理器运行时间 $T(1)$ 的最佳估计。\n\n串行分数 $s$ 是串行执行时间与总单处理器执行时间的比率。使用我们估计的参数：\n$$\\hat{s} = \\frac{\\text{serial time}}{\\text{total time}} = \\frac{s \\cdot T(1)}{T(1)} \\approx \\frac{\\hat{c}}{\\hat{c} + \\hat{m}}$$\n这个公式提供了一个鲁棒的 $s$ 估计算法，它结合了从完整数据集中推导出的斜率和截距的信息。该方法能正确处理边界情况：\n- 对于理想并行程序（$s=0$），运行时间为 $T(P) = T(1)/P$。线性模型为 $y = 0 + T(1) \\cdot x$。回归将得出 $\\hat{c} = 0$，因此 $\\hat{s} = 0 / (0 + \\hat{m}) = 0$。\n- 对于完全串行程序（$s=1$），运行时间为 $T(P) = T(1)$。线性模型为 $y = T(1) + 0 \\cdot x$。回归将得出 $\\hat{m} = 0$，因此 $\\hat{s} = \\hat{c} / (\\hat{c} + 0) = 1$。\n\n实现将使用 `numpy.linalg.lstsq` 来执行线性回归。对于每组运行时间 $T$ 和核心数 $P$ 的数据集，我们求解线性系统 $A \\cdot \\mathbf{p} = T$ 以获得参数向量 $\\mathbf{p} = [\\hat{c}, \\hat{m}]^T$。设计矩阵 $A$ 的构造方式是：其第一列全为 1（用于截距 $\\hat{c}$），第二列包含 $x_i = 1/P_i$ 的值（用于斜率 $\\hat{m}$）。求解出 $\\hat{c}$ 和 $\\hat{m}$ 后，使用推导出的公式计算串行分数 $\\hat{s}$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Estimates the serial fraction 's' for several datasets of parallel program runtimes.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Dataset A\n        (\n            [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024],\n            [100.0, 56.0, 34.0, 23.0, 17.5, 14.75, 13.375, 12.6875, 12.34375, 12.171875, 12.0859375]\n        ),\n        # Dataset B\n        (\n            [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024],\n            [100.0, 50.5, 25.75, 13.375, 7.1875, 4.09375, 2.546875, 1.7734375, 1.38671875, 1.193359375, 1.0966796875]\n        ),\n        # Dataset C\n        (\n            [1, 2, 4, 8, 16],\n            [80.0, 60.0, 50.0, 45.0, 42.5]\n        ),\n        # Dataset D\n        (\n            [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024],\n            [64.0, 32.0, 16.0, 8.0, 4.0, 2.0, 1.0, 0.5, 0.25, 0.125, 0.0625]\n        ),\n        # Dataset E\n        (\n            [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024],\n            [42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0]\n        )\n    ]\n\n    results = []\n    for p_cores, t_times in test_cases:\n        # Convert data to numpy arrays for vectorized operations.\n        P = np.array(p_cores, dtype=np.float64)\n        T = np.array(t_times, dtype=np.float64)\n\n        # The model is T(P) = c + m * (1/P), where c is the serial time component\n        # and m is the parallel time component on one core.\n        # We perform a linear regression of T vs. 1/P.\n        # The independent variable x is the reciprocal of the number of cores.\n        x = 1.0 / P\n        \n        # The dependent variable y is the measured runtime.\n        y = T\n\n        # We set up the design matrix A for the linear least squares problem y = A @ [c, m].\n        # The first column is ones (for the intercept c) and the second is x (for the slope m).\n        A = np.column_stack([np.ones_like(x), x])\n        \n        # Use np.linalg.lstsq to find the best-fit parameters [c, m].\n        params = np.linalg.lstsq(A, y, rcond=None)[0]\n        c, m = params[0], params[1]\n\n        # The serial fraction s is the ratio of the serial time component (c)\n        # to the total single-core time (c + m).\n        # We handle the case where c + m could be zero to avoid division by zero,\n        # although with the given data this is not expected.\n        total_single_core_time = c + m\n        if np.isclose(total_single_core_time, 0):\n            # If T(1) is zero, s is undefined. This is an invalid physical scenario.\n            # We can define s=0 as a fallback, as no work is being done.\n            s = 0.0\n        else:\n            s = c / total_single_core_time\n        \n        results.append(s)\n\n    # Format the final output string as a comma-separated list of values\n    # rounded to six decimal places, enclosed in square brackets.\n    # Standard f-string formatting is sufficient here as the problem data is perfect,\n    # leading to exact results that don't require complex rounding logic.\n    output_str = f\"[{','.join(f'{r:.6f}' for r in results)}]\"\n    print(output_str)\n\nsolve()\n```", "id": "3270745"}, {"introduction": "在探讨了强扩展性的局限之后，我们现在将视角转向弱扩展性（weak scaling），这种情况更适合用古斯塔夫森定律（Gustafson's Law）来描述。本题通过一个引人注目的数值天气预报案例，阐明了如何利用增长的计算能力，在固定的时间内解决更大、更精细的问题。通过这个练习，您将理解建造更大型超级计算机的理由，并学会应用古斯塔夫森的框架来评估可扩展问题规模的应用的性能。[@problem_id:3270675]", "problem": "一个国家气象机构运行一个数值天气预报模型，其计算成本与整个预报过程中的网格点更新总数成正比：即空间网格点数与时间步数的乘积。假设这是一个具有均匀立方体网格间距的三维域。根据Courant–Friedrichs–Lewy (CFL) 稳定性条件，当空间网格间距在每个空间维度上被细化一个因子 $\\gamma$ 时，时间步数会增加一个因子 $\\gamma$，因此网格点更新的总数大约增加 $\\gamma^4$ 倍。\n\n在一台拥有 $P_0 = 256$ 个处理器的基准机器上，一个空间分辨率为 $\\Delta x_0$ 的预报在 $T^\\star$ 小时内完成。对该运行的性能分析显示，可并行化的时间分数为 $(1 - f_s)$，串行分数为 $f_s = 0.05$。其中 $f_s$ 是墙上时钟时间中用于严格串行工作（初始化、输入/输出、全局同步）的部分，而 $(1 - f_s)$ 用于完全并行工作（独立的网格点更新）。该机构正在考虑一台拥有 $P = 8192$ 个处理器的新超级计算机，并希望在将每个空间维度的网格细化相同因子 $\\gamma$ 以提高预报分辨率的同时，将墙上时钟时间保持在 $T^\\star$。\n\n假设：\n- 当墙上时钟时间固定时，从 $P_0$ 迁移到 $P$ 时，分数 $f_s$ 没有明显变化，\n- 并行部分在处理器之间表现出理想的可扩展性，\n- 在此分析层面，通信和内存效应可以忽略。\n\n在这些假设下，并从加速比和工作负载的定义出发，哪个陈述最符合应用通常归因于Gustafson定律的弱扩展视角来证明构建更大系统的合理性？\n\nA. 你可以在每个空间维度上细化大约 $\\gamma \\approx 2.4$，同时将墙上时钟时间固定在 $T^\\star$，因为在时间 $T^\\star$ 内可以完成的总工作量除了串行尾部外几乎与 $P$ 呈线性增长。\n\nB. 你最多只能细化到 $\\gamma \\approx 2.0$，因为串行分数 $f_s$ 为加速比设定了一个绝对上限，这个上限无法通过增加 $P$ 来克服。\n\nC. 你可以细化大约 $\\gamma \\approx 3.2$，因为在三维中，计算工作量仅按 $\\gamma^3$ 的方式增加。\n\nD. 对于 $f_s = 0.05$ 的情况，你完全不能进行细化，因为加速比的上限为 $1 / f_s = 20$，这与增加多少处理器无关。", "solution": "该问题陈述已经过验证，被认为是科学上可靠、提法恰当、客观且内部一致的。它为高性能计算中的可扩展性分析提供了一个标准场景。\n\n问题的核心是在墙上时钟时间 $T^\\star$ 保持不变的约束下，确定当计算规模从一台拥有 $P_0$ 个处理器的机器扩展到一台拥有 $P$ 个处理器的机器时，可实现的细化因子 $\\gamma$。这是一个经典的弱扩展问题，适用于归因于Gustafson的框架。\n\n设 $T$ 为并行系统上一次计算的总墙上时钟时间。这个时间是代码串行部分所花费的时间 $T_s$ 和并行部分所花费的时间 $T_p$ 的总和。\n$$T = T_s + T_p$$\n问题指定了时间的串行分数为 $f_s$，使得 $T_s = f_s T$，时间的并行分数为 $(1 - f_s)$，因此 $T_p = (1 - f_s)T$。由于我们保持墙上时钟时间固定，所以对于基准运行和扩展后的运行，这一点都成立。\n\n让我们对在时间 $T$ 内可以完成的总计算工作量 $W$进行建模。工作的串行部分 $W_s$ 由单个处理单元执行。假设每个处理器的工作速率为每秒 $\\kappa$ 次操作，那么完成的串行工作量为：\n$$W_s = \\kappa T_s = \\kappa f_s T$$\n工作的并行部分 $W_p$ 分布在所有 $P$ 个处理器上。在理想扩展的情况下，完成的总并行工作量为：\n$$W_p = \\kappa P T_p = \\kappa P (1 - f_s) T$$\n在 $P$ 个处理器上，于时间 $T$ 内可以完成的总工作量 $W(P)$ 是串行和并行工作分量的总和：\n$$W(P) = W_s + W_p = \\kappa f_s T + \\kappa P (1 - f_s) T = \\kappa T (f_s + P(1-f_s))$$\n这个方程描述了对于固定的时间 $T$ 和串行分数 $f_s$，可处理的工作量如何随处理器数量 $P$ 扩展。这就是Gustafson定律或弱扩展视角的精髓。\n\n我们有两个给定的场景：\n1.  **基准系统**：$P_0 = 256$ 个处理器，工作负载 $W_0$，时间 $T^\\star$。\n2.  **新系统**：$P = 8192$ 个处理器，工作负载 $W_1$，时间 $T^\\star$。\n\n两次运行的串行分数都为 $f_s = 0.05$。因此，$1 - f_s = 0.95$。\n\n对于基准系统，在时间 $T^\\star$ 内完成的总工作量 $W_0$ 是：\n$$W_0 = \\kappa T^\\star (f_s + P_0(1-f_s))$$\n对于新系统，在相同时间 $T^\\star$ 内完成的总工作量 $W_1$ 是：\n$$W_1 = \\kappa T^\\star (f_s + P(1-f_s))$$\n工作负载的比率代表了在保持运行时间不变的情况下，问题规模可以增加的因子。\n$$\\frac{W_1}{W_0} = \\frac{\\kappa T^\\star (f_s + P(1-f_s))}{\\kappa T^\\star (f_s + P_0(1-f_s))} = \\frac{f_s + P(1-f_s)}{f_s + P_0(1-f_s)}$$\n问题陈述指出，将空间网格间距细化因子 $\\gamma$ 会使总计算成本（工作量）增加因子 $\\gamma^4$。因此，我们有：\n$$\\frac{W_1}{W_0} = \\gamma^4$$\n结合这两个表达式，得到关于 $\\gamma$ 的控制方程：\n$$\\gamma^4 = \\frac{f_s + P(1-f_s)}{f_s + P_0(1-f_s)}$$\n现在，我们代入给定值：$f_s = 0.05$，$P_0 = 256$ 和 $P = 8192$。\n$$\\gamma^4 = \\frac{0.05 + 8192(0.95)}{0.05 + 256(0.95)}$$\n$$\\gamma^4 = \\frac{0.05 + 7782.4}{0.05 + 243.2} = \\frac{7782.45}{243.25}$$\n计算该比率：\n$$\\gamma^4 \\approx 31.99568$$\n这个比率非常接近 $32$。为了找到细化因子 $\\gamma$，我们取四次方根：\n$$\\gamma = (31.99568)^{1/4} \\approx 2.3784$$\n因此，空间网格可以被细化大约 $\\gamma \\approx 2.38$ 的因子。\n\n现在，我们评估每个给定的选项。\n\n**A. 我们的计算值为 $\\gamma \\approx 2.38$，可以很好地近似为 $2.4$。所提供的理由也是合理的。总工作量 $W(P) \\propto f_s + P(1 - f_s)$ 是 $P$ 的一个线性函数。对于较小的 $f_s$，$W(P) \\approx P(1-f_s)$，这是一个几乎线性的增长。对于给定的较大 $P_0$ 和 $P$ 值，工作负载比率 $\\frac{W_1}{W_0}$ 非常接近处理器比率 $\\frac{P}{P_0} = \\frac{8192}{256} = 32$。我们计算出的 $\\gamma^4 \\approx 32$ 证实了这一点。该陈述准确地反映了弱扩展的原理。**结论：正确。**\n\n**B. 该理由援引了Amdahl定律所描述的强扩展极限，其中加速比 $S(P) = \\frac{1}{f_s + (1-f_s)/P}$ 的上限为 $1/f_s$。Amdahl定律适用于固定规模问题（强扩展），而不适用于问题规模随机器规模增加而增加的问题（弱扩展）。该问题明确要求从弱扩展的视角进行分析。$\\gamma \\approx 2.0$ 的值将意味着 $\\gamma^4 \\approx 16$，这大约是可实现的工作负载增量的一半。**结论：不正确。**\n\n**C. 该陈述在前提方面包含一个事实错误。问题明确指出，由于CFL条件，网格点更新总数（工作量）大约增加 $\\gamma^4$ 倍，而不是 $\\gamma^3$ 倍。$\\gamma^3$ 因子只考虑了空间网格点的增加，忽略了所需的时间步长缩减。此外，$\\gamma \\approx 3.2$ 的细化将意味着工作量扩展为 $\\gamma^4 \\approx (3.2)^4 \\approx 105$，这与我们的计算不一致。**结论：不正确。**\n\n**D. 与选项B类似，该陈述错误地应用了Amdahl定律（强扩展）及其相关的加速比极限 $1/f_s = 1/0.05 = 20$。该问题涉及弱扩展，其中这样的极限不适用；相反，可扩展加速比随 $P$ 增长。无法进行任何细化（$\\gamma=1$）的结论显然是错误的，因为可以实现分辨率的显著提高。**结论：不正确。**", "answer": "$$\\boxed{A}$$", "id": "3270675"}, {"introduction": "我们的最后一个练习将从高层次的定律转向一个具体的、基于组件的性能模型，该模型针对一个常见的科学计算任务：使用迭代法求解线性系统。您将把共轭梯度（Conjugate Gradient）算法的运行时间分解为计算和通信部分，并探讨使用单精度与双精度之间的权衡。这项练习将教您如何构建和分析多方面的性能模型，这对于预测复杂并行代码的性能和识别瓶颈至关重要。[@problem_id:3270755]", "problem": "考虑使用共轭梯度（CG）方法求解一个由三维椭圆偏微分方程离散化产生的大型稀疏对称正定线性系统。CG的每次迭代包括一次稀疏矩阵向量乘积、一次最近邻光环交换和两次全局点积。假设使用消息传递接口（MPI）进行并行实现，并有以下设定：\n\n- 计算受内存带宽限制，每个进程的内存带宽为 $BW$（GB/秒），每次迭代的内存流量为 $V$（GB）。每次迭代的计算时间模型为通过内存移动 $V$ 所需的时间。\n- 光环交换在每次迭代中，每个进程通过网络发送 $M$（GB）的数据，网络带宽为 $R$（GB/秒），产生的通信时间模型为发送 $M$ 所需的时间。\n- 每个全局点积通过一次归约操作完成，其时间主要由延迟决定，模型为每次归约 $L \\log_2(p)$ 秒，其中 $p$ 是进程数。每次迭代有两次这样的归约操作。\n\n假设矩阵和向量存储使用两种数值精度：\n- 双精度：每次迭代的总内存流量为 $V_d = 6.4$ GB，每次迭代的光环交换数据量为 $M_d = 0.2$ GB，达到目标相对残差容差 $\\tau$ 所需的迭代次数为 $k_d = 500$。\n- 单精度：每次迭代的总内存流量为 $V_s = 3.6$ GB，每次迭代的光环交换数据量为 $M_s = 0.1$ GB，达到相同目标容差 $\\tau$ 所需的迭代次数为 $k_s = 1000$。\n\n机器和网络参数如下：\n- 每进程内存带宽 $BW = 40$ GB/秒，\n- 网络带宽 $R = 10$ GB/秒，\n- 归约延迟常数 $L = 3 \\times 10^{-4}$ 秒，\n- 从 $p = 1$ 到 $p = 32$ 个进程进行强扩展，分区均匀且忽略负载不均衡。\n\n使用这些假设以及基于带宽受限计算和基于延迟/带宽通信的性能建模第一原理，分析在 $p = 1$ 和 $p = 32$ 时两种精度的求解时间和强扩展效率。然后确定以下哪些陈述是正确的：\n\nA. 在 $p = 32$ 时，单精度CG比双精度CG的求解时间更短，且强扩展效率更高，因为减少数据量主导了总成本。\n\nB. 在 $p = 32$ 时，双精度比单精度的求解时间更短；此外，单精度和双精度的强扩展效率差异小于 $5\\%$。\n\nC. 在 $p = 32$ 时，两种精度的强扩展效率主要受限于全局归约的延迟，因此进一步增加 $BW$ 不会显著减少求解时间。\n\nD. 在 $p = 1$ 时，单精度的求解时间比双精度慢，因为迭代次数的增加超过了因数据量减少带来的单次迭代加速。\n\n选择所有适用的选项。", "solution": "### 问题验证\n\n**步骤1：提取给定信息**\n\n问题为并行共轭梯度（CG）方法提供了以下数据和模型：\n\n- **方法组件**：每次迭代包括一次稀疏矩阵向量乘积（计算）、一次最近邻光环交换（通信）和两次全局点积（通信）。\n- **性能模型（在 $p$ 个进程上每次迭代的时间）**：\n    - 计算时间：$T_{comp}(p) = \\frac{V/p}{BW}$。问题陈述“每次迭代的总内存流量为 $V$”，并使用强扩展。因此，每个进程的流量为 $V/p$。时间是该流量除以每进程内存带宽 $BW$。\n    - 光环交换时间：$T_{halo}(p) = M/R$。问题陈述“每次迭代每个进程 $M$（GB）”，这使得当 $p>1$ 时，这是一个恒定的开销。\n    - 全局归约时间：$T_{redux}(p) = 2 L \\log_2(p)$。这考虑了两次归约。\n- **物理假设**：对于 $p=1$，没有进程间通信。因此，$T_{halo}(1)=0$ 且 $T_{redux}(1)=0$。\n- **精度数据（双精度）**：\n    - 总内存流量：$V_d = 6.4$ GB。\n    - 每进程光环交换数据量：$M_d = 0.2$ GB。\n    - 迭代次数：$k_d = 500$。\n- **精度数据（单精度）**：\n    - 总内存流量：$V_s = 3.6$ GB。\n    - 每进程光环交换数据量：$M_s = 0.1$ GB。\n    - 迭代次数：$k_s = 1000$。\n- **机器/网络参数**：\n    - 每进程内存带宽：$BW = 40$ GB/秒。\n    - 网络带宽：$R = 10$ GB/秒。\n    - 归约延迟常数：$L = 3 \\times 10^{-4}$ 秒。\n- **扩展参数**：\n    - 从 $p=1$ 到 $p=32$ 个进程的强扩展。\n\n**步骤2：使用提取的给定信息进行验证**\n\n根据验证标准评估问题陈述：\n\n1.  **科学依据**：该问题在高性能计算（HPC）和数值方法的原理方面有充分的依据。将运行时间分解为计算、点对点通信（光环交换）和集体通信（归约）的性能模型是一种标准方法。将这些组件建模为内存带宽、网络带宽和延迟的函数也是标准实践。数值精度（影响收敛速度，即迭代次数）和数据量（影响每次迭代的时间）之间的权衡是科学计算中的一个基本概念。\n2.  **问题定义明确**：问题提供了一套完整的参数和清晰的性能模型，从而可以对感兴趣的量（求解时间和效率）进行唯一、确定性的计算。\n3.  **客观性**：问题以精确、定量和客观的语言陈述，没有主观性断言。\n4.  **一致性和现实性**：提供的带宽、延迟和数据大小的数值对于现代超级计算硬件是现实的。该模型做了一个简化的假设，即每进程光环交换数据量 $M$ 是恒定的。实际上，对于一个在强扩展下的三维问题，每进程的表面积与体积之比会发生变化，这意味着 $M$ 会依赖于 $p$（具体来说，按 $p^{-1/3}$ 比例缩放）。然而，这是一个明确给出的建模假设（“假设以下……”），而不是一个隐藏的矛盾。它简化了分析，而没有使练习的逻辑失效，该练习旨在应用给定的模型。在其陈述的假设下，问题是自洽的。\n\n**步骤3：结论与行动**\n\n问题陈述是**有效的**。它提出了一个基于既定原则的、定义明确的理论性能建模练习，尽管带有一个标准的简化假设。可以进行求解过程。\n\n### 求解推导\n\n总求解时间 $TTS(p)$，对于 $p$ 个进程，是迭代次数 $k$ 和每次迭代时间 $T_{iter}(p)$ 的乘积。\n\n当 $p > 1$ 时，每次迭代的时间为：\n$$T_{iter}(p) = T_{comp}(p) + T_{halo}(p) + T_{redux}(p) = \\frac{V}{p \\cdot BW} + \\frac{M}{R} + 2 L \\log_2(p)$$\n对于串行情况（$p=1$），通信项为零：\n$$T_{iter}(1) = T_{comp}(1) = \\frac{V}{BW}$$\n总求解时间为 $TTS(p) = k \\cdot T_{iter}(p)$。\n强扩展效率定义为 $E(p) = \\frac{TTS(1)}{p \\cdot TTS(p)}$。\n\n我们分析两种精度格式。\n\n**1. 双精度分析**\n- 已知：$V_d = 6.4$ GB, $M_d = 0.2$ GB, $k_d = 500$, $BW = 40$ GB/s, $R = 10$ GB/s, $L = 3 \\times 10^{-4}$ s。\n\n- **$p=1$ 时的求解时间：**\n$$TTS_d(1) = k_d \\cdot T_{iter,d}(1) = 500 \\cdot \\left(\\frac{V_d}{BW}\\right) = 500 \\cdot \\left(\\frac{6.4}{40}\\right) \\text{ s} = 500 \\cdot 0.16 \\text{ s} = 80 \\text{ s}$$\n\n- **$p=32$ 时的求解时间：**\n$$T_{iter,d}(32) = \\frac{V_d}{32 \\cdot BW} + \\frac{M_d}{R} + 2 L \\log_2(32)$$\n$$T_{iter,d}(32) = \\frac{6.4}{32 \\cdot 40} + \\frac{0.2}{10} + 2 \\cdot (3 \\times 10^{-4}) \\cdot 5$$\n$$T_{iter,d}(32) = \\frac{6.4}{1280} + 0.02 + 10 \\cdot (3 \\times 10^{-4}) = 0.005 + 0.02 + 0.003 = 0.028 \\text{ s}$$\n$$TTS_d(32) = k_d \\cdot T_{iter,d}(32) = 500 \\cdot 0.028 \\text{ s} = 14.0 \\text{ s}$$\n\n- **$p=32$ 时的强扩展效率：**\n$$E_d(32) = \\frac{TTS_d(1)}{32 \\cdot TTS_d(32)} = \\frac{80}{32 \\cdot 14} = \\frac{80}{448} \\approx 0.17857 \\text{ or } 17.86\\%$$\n\n**2. 单精度分析**\n- 已知：$V_s = 3.6$ GB, $M_s = 0.1$ GB, $k_s = 1000$。\n\n- **$p=1$ 时的求解时间：**\n$$TTS_s(1) = k_s \\cdot T_{iter,s}(1) = 1000 \\cdot \\left(\\frac{V_s}{BW}\\right) = 1000 \\cdot \\left(\\frac{3.6}{40}\\right) \\text{ s} = 1000 \\cdot 0.09 \\text{ s} = 90 \\text{ s}$$\n\n- **$p=32$ 时的求解时间：**\n$$T_{iter,s}(32) = \\frac{V_s}{32 \\cdot BW} + \\frac{M_s}{R} + 2 L \\log_2(32)$$\n$$T_{iter,s}(32) = \\frac{3.6}{32 \\cdot 40} + \\frac{0.1}{10} + 2 \\cdot (3 \\times 10^{-4}) \\cdot 5$$\n$$T_{iter,s}(32) = \\frac{3.6}{1280} + 0.01 + 0.003 = 0.0028125 + 0.01 + 0.003 = 0.0158125 \\text{ s}$$\n$$TTS_s(32) = k_s \\cdot T_{iter,s}(32) = 1000 \\cdot 0.0158125 \\text{ s} = 15.8125 \\text{ s}$$\n\n- **$p=32$ 时的强扩展效率：**\n$$E_s(32) = \\frac{TTS_s(1)}{32 \\cdot TTS_s(32)} = \\frac{90}{32 \\cdot 15.8125} = \\frac{90}{506} \\approx 0.17786 \\text{ or } 17.79\\%$$\n\n### 逐项分析\n\n**A. 在 $p = 32$ 时，单精度CG比双精度CG的求解时间更短，且强扩展效率更高，因为减少数据量主导了总成本。**\n- 比较 $p=32$ 时的求解时间：$TTS_s(32) = 15.8125$ s，而 $TTS_d(32) = 14.0$ s。单精度更慢，而不是更快。陈述的第一部分是错误的。\n- 比较 $p=32$ 时的效率：$E_s(32) \\approx 17.79\\%$，而 $E_d(32) \\approx 17.86\\%$。单精度的效率略低，而不是更高。第二部分也是错误的。\n- **结论：错误。**\n\n**B. 在 $p = 32$ 时，双精度比单精度的求解时间更短；此外，单精度和双精度的强扩展效率差异小于 $5\\%$。**\n- 比较 $p=32$ 时的求解时间：$TTS_d(32) = 14.0$ s 确实低于 $TTS_s(32) = 15.8125$ s。陈述的第一部分是正确的。\n- 比较效率：效率分别为 $E_d(32) \\approx 17.86\\%$ 和 $E_s(32) \\approx 17.79\\%$。绝对差异为 $|17.86\\% - 17.79\\%| = 0.07\\%$。由于 $0.07\\%  5\\%$，陈述的第二部分也是正确的。\n- **结论：正确。**\n\n**C. 在 $p = 32$ 时，两种精度的强扩展效率主要受限于全局归约的延迟，因此进一步增加 $BW$ 不会显著减少求解时间。**\n- 分析 $p=32$ 时的时间分量：\n  - 双精度：$T_{iter,d}(32) = T_{comp} + T_{halo} + T_{redux} = 0.005\\text{ s} + 0.020\\text{ s} + 0.003\\text{ s}$。主导项是 $T_{halo}$（$0.020$ s），而不是 $T_{redux}$（$0.003$ s）。\n  - 单精度：$T_{iter,s}(32) = T_{comp} + T_{halo} + T_{redux} = 0.0028\\text{ s} + 0.010\\text{ s} + 0.003\\text{ s}$。同样，主导项是 $T_{halo}$（$0.010$ s），而不是 $T_{redux}$（$0.003$ s）。\n- “效率主要受限于全局归约的延迟”这一前提是错误的。在此模型中，主要的瓶颈是恒定时间的光环交换开销，这严重影响了强扩展。\n- **结论：错误。**\n\n**D. 在 $p = 1$ 时，单精度的求解时间比双精度慢，因为迭代次数的增加超过了因数据量减少带来的单次迭代加速。**\n- 比较 $p=1$ 时的求解时间：$TTS_s(1) = 90$ s，而 $TTS_d(1) = 80$ s。单精度的确更慢。陈述的第一部分是正确的。\n- 分析原因：\n  - 迭代次数的比率为 $k_s/k_d = 1000/500 = 2$。单精度需要两倍的迭代次数。\n  - 每次迭代时间的比率为 $T_{iter,s}(1)/T_{iter,d}(1) = 0.09/0.16 = 9/16 = 0.5625$。单精度的迭代更快。\n  - 总求解时间的比率为 $TTS_s(1)/TTS_d(1) = (k_s/k_d) \\cdot (T_{iter,s}(1)/T_{iter,d}(1)) = 2 \\cdot (9/16) = 18/16 = 1.125$。\n  - 迭代次数增加的2倍，大于每次迭代的加速因子，即 $T_{iter,d}(1)/T_{iter,s}(1) = 16/9 \\approx 1.78$。因为 $2 > 1.78$，迭代次数的增加确实超过了单次迭代的加速。所提供的理由是正确的。\n- **结论：正确。**", "answer": "$$\\boxed{BD}$$", "id": "3270755"}]}