{"hands_on_practices": [{"introduction": "数值微分的核心挑战在于选择一个“恰到好处”的步长 $h$。步长太小，舍入误差会淹没结果；步长太大，近似公式本身的截断误差又会占据主导。这个练习将让你直面这一权衡，通过一个简化的误差模型，你将用解析的方法推导出使总误差最小化的最优步长 [@problem_id:2167887]。这个基础练习旨在清晰地揭示截断误差与舍入误差之间的根本性制衡关系。", "problem": "在数值分析领域，一个基本的挑战是平衡截断误差（来自数学近似）和舍入误差（来自有限精度硬件）。考虑使用中心差分公式计算函数 $f(x) = \\sin(x)$ 在任意点 $x=a$ 处的导数这一任务。\n\n总误差 $E_{total}(h)$ 作为步长 $h$ 的函数，被建模为这两种误差大小之和。\n中心差分法的截断误差大小由以下表达式给出：\n$$|E_{trunc}(h)| = \\frac{h^2}{6} |f'''(a)|$$\n舍入误差的大小，其源于浮点运算的限制，被建模为：\n$$|E_{round}(h)| = \\frac{\\epsilon}{h}$$\n此处，$\\epsilon$ 是一个小的正常数，表示单次函数求值的绝对误差的上界。\n\n因此，总误差可由和 $E_{total}(h) = |E_{trunc}(h)| + |E_{round}(h)|$ 近似。您的任务是找到最小化此总误差的最优步长 $h_{opt}$。\n\n请以参数 $a$ 和 $\\epsilon$ 的闭式解析表达式形式给出您的答案。您可以假设 $\\cos(a) \\neq 0$。", "solution": "给定函数 $f(x) = \\sin(x)$ 和中心差分总误差模型\n$$E_{total}(h) = |E_{trunc}(h)| + |E_{round}(h)| = \\frac{h^{2}}{6}\\,|f'''(a)| + \\frac{\\epsilon}{h}.$$\n对于 $f(x) = \\sin(x)$，其三阶导数为 $f'''(x) = -\\cos(x)$，因此 $|f'''(a)| = |\\cos(a)|$。所以，\n$$E_{total}(h) = \\frac{h^{2}}{6}\\,|\\cos(a)| + \\frac{\\epsilon}{h}, \\quad h>0.$$\n为求得使误差最小化的步长，我们对 $h$ 求导并令其为零：\n$$\\frac{dE_{total}}{dh} = \\frac{2h}{6}\\,|\\cos(a)| - \\frac{\\epsilon}{h^{2}} = \\frac{h}{3}\\,|\\cos(a)| - \\frac{\\epsilon}{h^{2}}.$$\n令 $\\frac{dE_{total}}{dh}=0$ 可得\n$$\\frac{h}{3}\\,|\\cos(a)| = \\frac{\\epsilon}{h^{2}} \\quad \\Longrightarrow \\quad \\frac{|\\cos(a)|}{3}\\,h^{3} = \\epsilon \\quad \\Longrightarrow \\quad h^{3} = \\frac{3\\epsilon}{|\\cos(a)|}.$$\n于是，\n$$h_{opt} = \\left(\\frac{3\\epsilon}{|\\cos(a)|}\\right)^{\\frac{1}{3}}.$$\n为验证这是一个最小值，计算其二阶导数：\n$$\\frac{d^{2}E_{total}}{dh^{2}} = \\frac{1}{3}\\,|\\cos(a)| + \\frac{2\\epsilon}{h^{3}},$$\n对于 $h>0$，该二阶导数严格为正，这证实了该临界点是一个极小值点。因此，最优步长为\n$$h_{opt} = \\left(\\frac{3\\epsilon}{|\\cos(a)|}\\right)^{\\frac{1}{3}}.$$", "answer": "$$\\boxed{\\left(\\frac{3\\epsilon}{|\\cos(a)|}\\right)^{\\frac{1}{3}}}$$", "id": "2167887"}, {"introduction": "上一个练习中的误差模型是一个理想化的起点，但现实世界的计算往往更加复杂。有时，函数求值本身就会因“灾难性抵消”而引入巨大的舍入误差，这种误差与微分过程中的误差相互作用。本练习将通过一个经典函数 $(\\exp(x)-1)/x$ 来探讨这种情况，并要求你通过编程比较“朴素”实现与使用数值稳定算法 (`expm1`) 的差异 [@problem_id:3269491]。这将让你亲身体会到，一个稳定的算法对于获得精确的数值导数是何等重要。", "problem": "考虑函数 $f(x) = \\frac{\\exp(x) - 1}{x}$，以及使用对称中心差分法在 $x=0$ 附近数值逼近其导数的任务。函数 $f(x)$ 是光滑的，但在 $x$ 很小时容易发生灾难性抵消，因为从 $\\exp(x)$ 中减去 $1$ 会消除对精度至关重要的有效数字。这种数值上的脆弱性与导数近似计算相互作用，导数近似本身就涉及两个几乎相等的值的相减。你必须确定能够最小化数值微分总误差的步长 $h$。总误差来源于泰勒级数近似引起的截断误差和由电气与电子工程师协会 (IEEE) 754 标准规定的有限精度算术引起的舍入误差的组合。\n\n从核心定义和经过充分检验的事实出发，使用幂级数论证推导出 $f'(0)$ 的精确值。然后，使用在 $x=0$ 附近的泰勒展开，推导应用于 $x=0$ 处函数 $f$ 的对称中心差分的主阶截断误差项。使用单位舍入 $\\epsilon_{\\text{mach}}$ 来模拟 IEEE 754 意义下的浮点舍入效应，使得计算 $f(h)$ 和 $f(-h)$ 然后相减所贡献的舍入项，在相差一个与方法相关的常数因子的情况下，其大小与 $\\epsilon_{\\text{mach}}$ 除以 $h$ 成比例。将这些组合成一个依赖于 $h$ 的单一误差模型，并将其最小化，以得出 binary64 精度的理论最优步长 $h^\\star$。\n\n你的程序必须实现并比较两种 $f$ 的求值器：\n1. 一个朴素求值器 $f_{\\text{naive}}(x) = \\frac{\\exp(x) - 1}{x}$，使用标准指数函数。\n2. 一个稳定求值器 $f_{\\text{stab}}(x) = \\frac{\\mathrm{expm1}(x)}{x}$，其中 $\\mathrm{expm1}(x)$ 在 $x$ 很小时能以高相对精度计算 $\\exp(x) - 1$。\n\n使用对称中心差分 $D(h) = \\frac{f(h) - f(-h)}{2h}$ 来近似 $f'(0)$。对于每个求值器，在 binary64 算术中，对候选步长集合 $H = \\{10^{-1}, 10^{-2}, \\ldots, 10^{-16}\\}$ 进行搜索，以找到最小化绝对误差 $|D(h) - f'(0)|$ 的 $h$。此外，使用你推导的误差模型，在方法相关常数因子取为 1 的情况下，计算 binary64 精度的理论最优步长 $h^\\star$。最后，作为一个探索精度效应的边界条件，在相同的候选集 $H$（转换为 binary32）上使用 binary32 算术重复朴素求值，并找到最小化误差的 $h$。\n\n测试套件：\n- 情况 1：Binary64，朴素求值器，在 $H$ 上搜索以找到最小化 $|D(h) - f'(0)|$ 的 $h$。\n- 情况 2：Binary64，稳定求值器，在 $H$ 上搜索以找到最小化 $|D(h) - f'(0)|$ 的 $h$。\n- 情况 3：Binary64，根据你推导的模型使用 binary64 单位舍入 $\\epsilon_{\\text{mach}}$ 计算的理论 $h^\\star$。\n- 情况 4：Binary32，朴素求值器，在 $H$（转换为 binary32）上搜索以找到最小化 $|D(h) - f'(0)|$ 的 $h$。\n\n你的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表，按上述情况的顺序排列。每个结果都必须是一个浮点数。例如：“[h_case1,h_case2,h_case3,h_case4]”。此问题不涉及物理单位或角度，因此无需进行单位转换。程序必须是自包含的，且不需要用户输入。", "solution": "该问题要求对函数 $f(x) = \\frac{\\exp(x) - 1}{x}$ 在 $x=0$ 处的数值微分进行多步分析。该分析必须首先在理论上进行，以找到精确的导数和最优步长，然后在计算上进行，使用不同的求值策略和浮点精度来验证理论。\n\n### 步骤 1：问题验证\n\n问题陈述已经过审查，并被确定为 **有效**。它在科学上基于数值分析的原理，特别是关于数值微分、泰勒级数分析、截断误差以及 IEEE 754 浮点运算中的舍入误差。函数 $f(x)$ 是灾难性抵消的一个标准案例研究。这个问题是适定的 (well-posed)，具有明确的目标，提供了所有必要的数据和条件（函数、导数公式、误差模型指导、精度标准、 $h$ 的搜索空间），并且没有内部矛盾。它要求理论推导和计算验证的非平凡组合，使其成为一项实质性的、结构良好的任务。\n\n### 步骤 2：理论分析\n\n#### 2.1：精确导数 $f'(0)$\n\n函数 $f(x) = \\frac{\\exp(x) - 1}{x}$ 在 $x=0$ 处有一个可去奇点。为了找到它在该点的行为，我们使用 $\\exp(x)$ 的麦克劳林级数展开：\n$$\n\\exp(x) = \\sum_{k=0}^{\\infty} \\frac{x^k}{k!} = 1 + x + \\frac{x^2}{2!} + \\frac{x^3}{3!} + \\dots\n$$\n减去 $1$ 并除以 $x$ 得到 $f(x)$ 的级数：\n$$\nf(x) = \\frac{1}{x} \\left( \\sum_{k=1}^{\\infty} \\frac{x^k}{k!} \\right) = \\sum_{k=1}^{\\infty} \\frac{x^{k-1}}{k!} = 1 + \\frac{x}{2!} + \\frac{x^2}{3!} + \\frac{x^3}{4!} + \\dots\n$$\n这个级数表示对所有 $x$ 都有效，我们可以定义 $f(0) = 1$ 使函数处处连续且无限可微。为了求导数 $f'(x)$，我们对级数逐项微分：\n$$\nf'(x) = \\frac{d}{dx} \\left( \\sum_{k=0}^{\\infty} \\frac{x^k}{(k+1)!} \\right) = \\sum_{k=1}^{\\infty} \\frac{k x^{k-1}}{(k+1)!} = \\frac{1}{2!} + \\frac{2x}{3!} + \\frac{3x^2}{4!} + \\dots\n$$\n在 $x=0$ 处求值，除第一项外的所有项都消失，从而得到导数的精确值：\n$$\nf'(0) = \\frac{1}{2!} = \\frac{1}{2}\n$$\n\n#### 2.2：截断误差\n\n$f'(x)$ 的对称中心差分近似为 $D(h) = \\frac{f(x+h) - f(x-h)}{2h}$。这种近似的误差称为截断误差。它可以通过 $f(x+h)$ 和 $f(x-h)$ 在 $x$ 点的泰勒展开来推导：\n$$\nf(x+h) = f(x) + hf'(x) + \\frac{h^2}{2}f''(x) + \\frac{h^3}{6}f'''(x) + O(h^4)\n$$\n$$\nf(x-h) = f(x) - hf'(x) + \\frac{h^2}{2}f''(x) - \\frac{h^3}{6}f'''(x) + O(h^4)\n$$\n用第一个式子减去第二个式子得到：\n$$\nf(x+h) - f(x-h) = 2hf'(x) + \\frac{h^3}{3}f'''(x) + O(h^5)\n$$\n除以 $2h$ 并重新整理，我们得到近似值及其误差项：\n$$\n\\frac{f(x+h) - f(x-h)}{2h} = f'(x) + \\frac{h^2}{6}f'''(x) + O(h^4)\n$$\n在 $x=0$ 处的主阶截断误差是 $E_{\\text{trunc}}(h) = \\frac{h^2}{6}f'''(0)$。我们从 $f(x)$ 的级数中找到 $f'''(0)$：\n$$\nf(x) = 1 + \\frac{1}{2}x + \\frac{1}{6}x^2 + \\frac{1}{24}x^3 + \\dots = \\sum_{k=0}^{\\infty} \\frac{f^{(k)}(0)}{k!} x^k\n$$\n通过比较系数，我们看到 $\\frac{f'''(0)}{3!} = \\frac{1}{4!}$，这给出 $f'''(0) = \\frac{3!}{4!} = \\frac{1}{4}$。\n因此，截断误差为：\n$$\nE_{\\text{trunc}}(h) = \\frac{h^2}{6} \\cdot \\frac{1}{4} = \\frac{h^2}{24}\n$$\n\n#### 2.3：舍入误差和最优步长 $h^\\star$\n\n舍入误差源于浮点运算的有限精度。总误差 $E(h)$ 是截断误差（随 $h$ 减小而减小）和舍入误差（随 $h$ 减小而增大）之和。\n\n该问题要求通过假设减法 $f(h) - f(-h)$ 是主要误差源来对舍入误差进行建模。设 $\\tilde{f}(x)$ 是在浮点运算中计算出的 $f(x)$ 的值。误差可以建模为 $\\tilde{f}(x) = f(x) + \\delta(x)$，其中 $|\\delta(x)|$ 是有界的。对于一个稳定的求值方法（例如使用 `expm1`），相对误差很小，因此 $|\\delta(x)| \\approx \\epsilon_{\\text{mach}}|f(x)|$。计算出的差是 $(\\tilde{f}(h) - \\tilde{f}(-h))$，它引入的舍入误差量级约为 $|\\delta(h)| + |\\delta(-h)|$。对于小的 $h$，$f(h) \\approx f(0) = 1$ 且 $f(-h) \\approx f(0) = 1$。因此，分子中的误差约为 $\\approx 2 \\epsilon_{\\text{mach}}$。导数近似中的舍入误差是这个分子误差除以 $2h$：\n$$\n|E_{\\text{round}}(h)| \\approx \\frac{2 \\epsilon_{\\text{mach}}}{2h} = \\frac{\\epsilon_{\\text{mach}}}{h}\n$$\n这与问题指定的模型相匹配，其中与方法相关的常数为 $1$。\n\n总误差是截断误差和舍入误差的绝对值之和：\n$$\nE(h) = |E_{\\text{trunc}}(h)| + |E_{\\text{round}}(h)| = \\frac{h^2}{24} + \\frac{\\epsilon_{\\text{mach}}}{h}\n$$\n为了找到使总误差最小化的步长 $h^\\star$，我们将 $E(h)$ 对 $h$ 求导，并令结果为零：\n$$\n\\frac{dE}{dh} = \\frac{2h}{24} - \\frac{\\epsilon_{\\text{mach}}}{h^2} = \\frac{h}{12} - \\frac{\\epsilon_{\\text{mach}}}{h^2}\n$$\n令 $\\frac{dE}{dh} = 0$ 得到：\n$$\n\\frac{h^\\star}{12} = \\frac{\\epsilon_{\\text{mach}}}{(h^\\star)^2} \\implies (h^\\star)^3 = 12 \\epsilon_{\\text{mach}}\n$$\n因此，理论上的最优步长是：\n$$\nh^\\star = \\sqrt[3]{12 \\epsilon_{\\text{mach}}}\n$$\n该模型最适用于稳定求值器，因为在这种情况下 $f(x)$ 本身的求值是准确的。对于朴素求值器，对于小的 $x$ ，$\\exp(x)-1$ 中的灾难性抵消会引入大得多的舍入误差，其量级为 $\\epsilon_{\\text{mach}}/h^2$，从而导致一个不同的最优 $h$。问题要求一个单一的理论 $h^\\star$，这对应于这种“最佳情况”场景。对于 binary64，$\\epsilon_{\\text{mach}} = 2^{-52}$。\n\n### 步骤 3：计算实现\n\n以下步骤在 Python 代码中实现：\n1.  **精确值和搜索空间**：定义精确值 $f'(0)=0.5$。创建搜索空间 $H = \\{10^{-1}, 10^{-2}, \\ldots, 10^{-16}\\}$。\n2.  **求值器**：定义了两个用于 $f(x)$ 的函数，$f_{\\text{naive}}(x) = (\\exp(x) - 1)/x$ 和 $f_{\\text{stab}}(x) = \\mathrm{expm1}(x)/x$。\n3.  **数值搜索**：\n    *   **情况 1 (binary64, 朴素)**：使用 `float64` 精度的 $f_{\\text{naive}}$ 为每个 $h \\in H$ 计算导数。找到最小化绝对误差 $|D(h) - f'(0)|$ 的 $h$。\n    *   **情况 2 (binary64, 稳定)**：使用 `float64` 精度的 $f_{\\text{stab}}$ 重复该过程。\n    *   **情况 4 (binary32, 朴素)**：使用 $f_{\\text{naive}}$ 重复该过程，但所有计算和数据类型都转换为 `float32`。这展示了较低精度的影响。\n4.  **理论计算**：\n    *   **情况 3 (binary64, 理论)**：使用推导出的公式 $h^\\star = \\sqrt[3]{12 \\epsilon_{\\text{mach}}}$ 和 binary64 的机器 epsilon 计算 $h^\\star$。\n\n然后将这四个结果收集起来，并按指定格式打印。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the numerical differentiation problem as specified.\n    Derives the optimal step size h for approximating f'(0) where f(x) = (exp(x)-1)/x.\n    Compares theoretical and empirical results for naive and stabilized evaluators in\n    binary64 and binary32 precision.\n    \"\"\"\n\n    # --- Setup ---\n    # The exact value of the derivative f'(0) is 1/2.\n    f_prime_0_exact_64 = np.float64(0.5)\n    f_prime_0_exact_32 = np.float32(0.5)\n\n    # Candidate set of step sizes H.\n    h_values = np.logspace(-1, -16, 16, dtype=np.float64)\n\n    # Machine epsilon values for binary64 (double) and binary32 (single).\n    eps_64 = np.finfo(np.float64).eps\n    eps_32 = np.finfo(np.float32).eps\n\n    # --- Evaluator Functions ---\n    def f_naive(x):\n        # Naive implementation susceptible to catastrophic cancellation.\n        # Ensure input is float64 for this case.\n        x = np.float64(x)\n        return (np.exp(x) - np.float64(1)) / x\n\n    def f_stab(x):\n        # Stabilized implementation using expm1 for high accuracy at small x.\n        # Ensure input is float64 for this case.\n        x = np.float64(x)\n        return np.expm1(x) / x\n\n    def f_naive_32(x):\n        # Naive implementation explicitly using float32 for all operations.\n        x = np.float32(x)\n        one = np.float32(1)\n        return (np.exp(x) - one) / x\n\n    def central_difference(f_eval, h_vals, dtype):\n        # Symmetric central difference D(h) = (f(h) - f(-h)) / (2h)\n        h = np.array(h_vals, dtype=dtype)\n        two = dtype(2)\n        return (f_eval(h) - f_eval(-h)) / (two * h)\n\n    results = []\n\n    # --- Case 1: Binary64, naive evaluator ---\n    d_approx_naive_64 = central_difference(f_naive, h_values, np.float64)\n    errors_naive_64 = np.abs(d_approx_naive_64 - f_prime_0_exact_64)\n    min_error_idx = np.argmin(errors_naive_64)\n    h_case1 = h_values[min_error_idx]\n    results.append(h_case1)\n\n    # --- Case 2: Binary64, stabilized evaluator ---\n    d_approx_stab_64 = central_difference(f_stab, h_values, np.float64)\n    errors_stab_64 = np.abs(d_approx_stab_64 - f_prime_0_exact_64)\n    min_error_idx = np.argmin(errors_stab_64)\n    h_case2 = h_values[min_error_idx]\n    results.append(h_case2)\n\n    # --- Case 3: Binary64, theoretical h* ---\n    # Derived optimal h* = (12 * eps_mach)^(1/3)\n    h_case3 = (12 * eps_64)**(1/3)\n    results.append(h_case3)\n\n    # --- Case 4: Binary32, naive evaluator ---\n    h_values_32 = h_values.astype(np.float32)\n    d_approx_naive_32 = central_difference(f_naive_32, h_values_32, np.float32)\n    # Some h values might become 0 in float32, leading to NaN.\n    # We should ignore these results when finding the minimum error.\n    valid_indices = ~np.isnan(d_approx_naive_32)\n    errors_naive_32 = np.abs(d_approx_naive_32[valid_indices] - f_prime_0_exact_32)\n    min_error_idx_32 = np.argmin(errors_naive_32)\n    h_case4 = h_values_32[valid_indices][min_error_idx_32]\n    results.append(h_case4)\n\n    # --- Final Output ---\n    # The final print statement must match the required format exactly.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3269491"}, {"introduction": "如果选择的步长 $h$ 小到计算机无法区分 $x$ 和 $x \\pm h$ 会发生什么？这将导致有限差分公式灾难性地失败，直接输出零。本章的最终练习挑战你从分析者转变为设计者：你需要构建一个“智能”的微分器，它能够检测到这种因 $h$ 过小导致的计算失败，并自适应地寻找一个可用的步长 [@problem_id:3269293]。这个练习将迫使你思考如何构建一个在极端条件下依然稳健的数值算法，这是数值计算库设计中的一个核心问题。", "problem": "您需要研究在符合电气与电子工程师协会 754 (IEEE 754) 标准的浮点（FP）算术中，舍入误差如何与使用对称有限差分的数值微分相互作用。其基本依据是导数作为对称差商极限的定义：对于一个可微函数 $f$，在点 $x$ 处的导数是 $f^{\\prime}(x) = \\lim_{h \\to 0} \\dfrac{f(x+h) - f(x-h)}{2h}$。在有限精度算術中，当 $h$相对于 $x$ 极小时，浮点和 $x+h$ 与 $x-h$ 可能会精确舍入为 $x$，导致 $f(x+h) - f(x-h)$ 的计算结果为零。您将设计并实现一个算法，该算法能检测到这种情况，并以乘法方式增加 $h$ 直到出现非零差值，然后使用第一个这样的 $h$ 来计算对称差商。您还将量化所得导数估计值与已知解析导数之间的偏差（绝对误差）。\n\n实现一个执行以下操作的程序。\n\n1) 实现一个函数，给定一个函数 $f$、一个点 $x_0$、一个初始步长 $h_0$、一个乘法增长因子 $r$（$r > 1$）以及最大增长步数 $N_{\\max}$，该函数通过以下过程尝试计算在 $x_0$ 点的对称有限差分导数：\n   - 使用当前的 $h$ 计算分子 $f(x_0 + h) - f(x_0 - h)$。\n   - 如果分子在数值上等于零，则将 $h$ 替换为 $r h$ 并重复此过程，计为一个增长步数。\n   - 在分子非零的第一个 $h$ 处停止，或者当增长步数达到 $N_{\\max}$ 时停止。\n   - 返回在停止时的 $h$ 计算出的导数估计值 $(f(x_0 + h) - f(x_0 - h))/(2h)$、实际使用的 $h$、所用的增长步数以及一个布尔标志，该标志指示循环是否因达到 $N_{\\max}$ 且分子仍为零（停滞）而终止。所有三角函数的参数必须解释为弧度。\n\n2) 对于下面的每个测试用例，计算并报告绝对偏差，定义为 $| \\widehat{f^{\\prime}}(x_0) - f^{\\prime}(x_0) |$，其中 $\\widehat{f^{\\prime}}(x_0)$ 是您的数值估计值，$f^{\\prime}(x_0)$ 是在 $x_0$ 点的精确解析导数。\n\n3) 使用以下测试套件，该套件旨在覆盖不同的情况：\n   - 情况 A（由于 $|h_0|$ 远小于局部间距而导致初始为零）：$f(x) = e^{x}$，$x_0 = 1$，$h_0 = 10^{-20}$，$r = 2$，$N_{\\max} = 60$。\n   - 情况 B（由于 $x_0$ 精确可表示且零附近的间距稠密而没有初始为零）：$f(x) = \\sin(x)$，$x_0 = 0$，$h_0 = 10^{-20}$，$r = 2$，$N_{\\max} = 60$。角度使用弧度。\n   - 情况 C（对于所有 $h$ 都是结构性零分子，而非舍入误差的产物）：$f(x) = \\cos(x)$，$x_0 = 0$，$h_0 = 10^{-20}$，$r = 2$，$N_{\\max} = 60$。角度使用弧度。\n   - 情况 D（大数值的 $x_0$ 和微小的 $h_0$ 导致 $x_0 \\pm h$ 最初舍入为相同的浮点数）：$f(x) = x^{2}$，$x_0 = 10^{8}$，$h_0 = 10^{-20}$，$r = 2$，$N_{\\max} = 60$。\n\n   对于每种情况，用于计算偏差的精确解析导数分别为：对于 $e^{x}$ 是 $f^{\\prime}(x) = e^{x}$，对于 $\\sin(x)$ 是 $f^{\\prime}(x) = \\cos(x)$，对于 $\\cos(x)$ 是 $f^{\\prime}(x) = -\\sin(x)$，对于 $x^{2}$ 是 $f^{\\prime}(x) = 2x$。\n\n4) 最终输出格式：您的程序应生成单行输出，其中包含四个案例的结果，形式为一个用方括号括起来的逗号分隔列表。每个案例的结果必须是一个包含五个项目的列表，顺序如下：实际使用的 $h$（浮点数）、所用的增长步数（整数）、停滞标志（布尔值）、导数估计值（浮点数）和绝对偏差（浮点数）。因此，完整输出是这样的一行：\n   [$[h_{\\mathrm{A}},n_{\\mathrm{A}},\\mathrm{stall}_{\\mathrm{A}},\\widehat{d}_{\\mathrm{A}},b_{\\mathrm{A}}],[h_{\\mathrm{B}},n_{\\mathrm{B}},\\mathrm{stall}_{\\mathrm{B}},\\widehat{d}_{\\mathrm{B}},b_{\\mathrm{B}}],[h_{\\mathrm{C}},n_{\\mathrm{C}},\\mathrm{stall}_{\\mathrm{C}},\\widehat{d}_{\\mathrm{C}},b_{\\mathrm{C}}],[h_{\\mathrm{D}},n_{\\mathrm{D}},\\mathrm{stall}_{\\mathrm{D}},\\widehat{d}_{\\mathrm{D}},b_{\\mathrm{D}}]$]\n   其中，此描述中的每个数学实体都将由您的程序进行数值计算。\n\n科学真实性和推导重点：将您的推理建立在导数的极限定义、IEEE 754 双精度语义下浮点加法 $x \\pm h$ 中的舍入行为以及 $f$ 关于 $x_0$ 的泰勒展开之上，以便在上下文中理解当 $h$ 增加时产生的偏差。不要在问题陈述中引用任何预先推导的误差平衡公式。不涉及物理单位。如上所述，角度（若适用）必须以弧度为单位。", "solution": "我们从导数作为极限的基本定义开始。对于在 $x_0$ 处可微的函数 $f$，其导数满足\n$$\nf^{\\prime}(x_0) \\;=\\; \\lim_{h \\to 0} \\frac{f(x_0 + h) - f(x_0 - h)}{2h}.\n$$\n选择对称商是因为它能消去泰勒展开中的主要奇数阶项，从而减少截断误差。具体来说，使用泰勒定理，\n$$\n\\begin{aligned}\nf(x_0 + h) = f(x_0) + f^{\\prime}(x_0) h + \\frac{f^{\\prime\\prime}(x_0)}{2} h^{2} + \\frac{f^{(3)}(x_0)}{6} h^{3} + \\mathcal{O}(h^{4}),\\\\\nf(x_0 - h) = f(x_0) - f^{\\prime}(x_0) h + \\frac{f^{\\prime\\prime}(x_0)}{2} h^{2} - \\frac{f^{(3)}(x_0)}{6} h^{3} + \\mathcal{O}(h^{4}).\n\\end{aligned}\n$$\n两式相减得到\n$$\nf(x_0 + h) - f(x_0 - h) \\;=\\; 2 f^{\\prime}(x_0) h + \\frac{f^{(3)}(x_0)}{3} h^{3} + \\mathcal{O}(h^{5}).\n$$\n除以 $2h$ 得到带有截断偏差的经典中心差分导数\n$$\n\\frac{f(x_0 + h) - f(x_0 - h)}{2h} \\;=\\; f^{\\prime}(x_0) + \\frac{f^{(3)}(x_0)}{6} h^{2} + \\mathcal{O}(h^{4}).\n$$\n因此，从第一性原理出发，截断偏差与 $h^{2}$ 成比例，其常数涉及 $f^{(3)}(x_0)$。\n\n在遵循电气与电子工程师协会 754 (IEEE 754) 双精度模型的浮点（FP）算术中，每个实数 $x$ 都由一个邻近的机器数表示，而像 $x \\pm h$ 这样的运算结果会被舍入到最近的可表示数。在一个非零的 $x$ 周围，实数轴上相邻可表示数之间存在一个间距 $\\operatorname{ulp}(x)$。如果 $|h|  \\frac{1}{2}\\operatorname{ulp}(x)$，那么 $x+h$ 和 $x-h$ 的浮点计算结果都会精确地舍入为 $x$。当这种情况发生时，函数求值在相同的参数上进行，因此即使数学上的差值可能非零，数值上 $f(x+h) - f(x-h) = 0$。这不是微积分的失败，而是离散表示和舍入的结果。\n\n算法设计原则：检测分子为零的情况，并通过增加 $h$ 来摆脱它。\n- 从 $h = h_0$ 开始。\n- 使用浮点算术计算 $y_{+} = f(x_0 + h)$ 和 $y_{-} = f(x_0 - h)$。\n- 如果数值上 $y_{+} - y_{-} = 0$，这表明 (a) $x_0 \\pm h$ 被舍入为同一个浮点数（这在 $|h|$ 相对于 $|x_0|$ 太小时很常见），或者 (b) 函数本身具有某种对称性，使得对于所有 $h$ 都有 $f(x_0 + h) = f(x_0 - h)$（例如，在 $x_0 = 0$ 时的 $f(x) = \\cos(x)$）。在情况 (a) 中，我们应该增加 $h$，而在情况 (b) 中，增加 $h$ 永远不会打破这种相等关系。因此，算法将 $h$ 乘以一个固定因子 $r  1$ 并重试，最多进行 $N_{\\max}$ 次增长步骤。\n- 循环在第一个非零分子出现时结束，或者当达到 $N_{\\max}$ 次增长步骤且分子仍为零时结束；在后者的“停滞”情况下，我们报告算法未能找到非零差值。\n\n算法增加 $h$ 时的偏差分析：从上面推导的泰勒展开式可知，一旦获得非零差值，中心差分估计的截断偏差近似为 $\\tfrac{f^{(3)}(x_0)}{6} h^{2}$。因为算法会增加 $h$ 直到观察到非零差值，所以选择的 $h$ 通常接近局部可表示间距的阈值。这保证了分子可以被分辨出来，但与理想的无穷小极限相比，这也增大了 $h$，从而增加了截断偏差。在 $f(x_0 + h) - f(x_0 - h)$ 中存在一个来自相减抵消的竞争性舍入误差贡献；然而，本算法的主要效果是离开两个参数相同的舍入区域，同时仍保持 $h$ 合理地小。在具体测试中观察到的总偏差可以量化为 $|\\widehat{f^{\\prime}}(x_0) - f^{\\prime}(x_0)|$。\n\n测试套件覆盖范围的基本原理：\n- 情况 A，$f(x) = e^{x}$ 在 $x_0 = 1$，$h_0 = 10^{-20}$，$r = 2$，迫使 $x_0 \\pm h$ 最初舍入为 $x_0$，因为 $x_0 = 1$ 附近的单位舍入值约为 $2^{-52} \\approx 2.22 \\times 10^{-16}$。算法必须多次增加 $h$ 才能使分子变为非零。这探测了预期的检测与逃逸行为。\n- 情况 B，$f(x) = \\sin(x)$ 在 $x_0 = 0$，$h_0 = 10^{-20}$，立即产生不同的 $x_0 \\pm h$，因为零附近的间距是绝对的并且非常精细；对于任何非零的 $h$，$\\sin(h) - \\sin(-h)$ 都是非零的。这证实了算法在不必要时保持 $h$ 不变。角度以弧度为单位。\n- 情况 C，$f(x) = \\cos(x)$ 在 $x_0 = 0$，由于偶对称性而非舍入，对所有 $h$ 产生 $f(x_0 + h) - f(x_0 - h) = 0$。算法将达到 $N_{\\max}$ 并设置停滞标志。真实导数为 $0$，返回的估计值也是 $0$，因此偏差为 $0$，同时仍能正确报告停滯。\n- 情况 D，$f(x) = x^{2}$ 在 $x_0 = 10^{8}$，$h_0 = 10^{-20}$，同样迫使 $h$ 多次增加，因为大数值 $x_0$ 附近的局部间距很大（与 $|x_0|$ 成比例）。这检验了在大数值下的行为。对于二次多项式，在精确算术中对称差分是精确的，因此观察到的任何偏差都源于浮点效应而非截断。\n\n实现的算法细节：\n- 通过默认的 NumPy 浮点类型使用双精度算术。\n- 在每一步，计算 $y_{+} = f(x_0 + h)$ 和 $y_{-} = f(x_0 - h)$，形成 $\\Delta = y_{+} - y_{-}$，并测试 $\\Delta$ 作为一个浮点数是否精确为零。\n- 如果 $\\Delta \\neq 0$，则返回 $\\widehat{f^{\\prime}}(x_0) = \\Delta/(2h)$，以及所用的 $h$、增长步数和设置为假的停滞标志。\n- 如果循环在 $N_{\\max}$ 次增长后以 $\\Delta = 0$ 结束，则返回估计值 $0$（因为 $\\Delta=0$）并将停滞标志设置为真。\n- 对于每个测试用例，计算解析导数 $f^{\\prime}(x_0)$ 和绝对偏差 $|\\widehat{f^{\\prime}}(x_0) - f^{\\prime}(x_0)|$。\n- 将四个案例的结果打印为包含四个列表的单个列表，每个内部列表包含 $[h_{\\text{used}}, \\text{steps}, \\text{stall}, \\widehat{f^{\\prime}}(x_0), \\text{bias}]$。\n\n这个过程直接源于导数定义和浮点算术的离散特性。增加 $h$ 时的偏差行为源于泰勒展开，它显示对称差分有一个 $\\mathcal{O}(h^{2})$ 的截断项，意味着更大的 $h$ 会增加截断偏差，而过小的 $h$ 会因舍入导致分子为零。所提出的算法确保分子变得可分辨，同时在所选的几何增长方式下保持 $h$ 尽可能小。", "answer": "```python\n# Execution environment:\n# - language: Python 3.12\n# - libraries: numpy 1.23.5 only (plus standard library)\nimport numpy as np\n\ndef central_diff_with_growth(f, x0, h0, r, max_steps):\n    \"\"\"\n    Compute symmetric finite difference derivative at x0 using step h,\n    increasing h geometrically by factor r  1 until the numerator\n    f(x0+h) - f(x0-h) is nonzero or until max_steps is reached.\n\n    Returns:\n        h_used (float): The final h used to compute the derivative.\n        steps (int): The number of growth steps taken (0 means used initial h0).\n        stalled (bool): True if max_steps reached with zero numerator; False otherwise.\n        derivative_est (float): The derivative estimate (0.0 if stalled with zero numerator).\n    \"\"\"\n    h = float(h0)\n    steps = 0\n    stalled = False\n\n    # Defensive: ensure r  1; if not, force a minimal growth factor\n    if not (r  1.0):\n        r = 2.0\n\n    # Try up to max_steps increases\n    for k in range(max_steps + 1):\n        # Compute numerator in floating-point arithmetic\n        y_plus = f(x0 + h)\n        y_minus = f(x0 - h)\n        delta = y_plus - y_minus\n\n        if delta != 0.0:\n            # Found a usable h\n            derivative_est = delta / (2.0 * h)\n            return h, steps, False, float(derivative_est)\n\n        # If here, delta == 0.0\n        if k == max_steps:\n            stalled = True\n            break\n        else:\n            h *= r\n            steps += 1\n\n    # If stalled, derivative estimate defaults to zero (since numerator is zero)\n    return h, steps, stalled, 0.0\n\ndef run_test_cases():\n    # Define functions and their exact derivatives\n    def f_exp(x): return np.exp(x)\n    def df_exp(x): return np.exp(x)\n\n    def f_sin(x): return np.sin(x)  # radians\n    def df_sin(x): return np.cos(x)\n\n    def f_cos(x): return np.cos(x)  # radians\n    def df_cos(x): return -np.sin(x)\n\n    def f_sq(x): return x * x\n    def df_sq(x): return 2.0 * x\n\n    test_cases = [\n        # Each case: (f, df, x0, h0, r, max_steps)\n        (f_exp, df_exp, 1.0, 1e-20, 2.0, 60),       # Case A\n        (f_sin, df_sin, 0.0, 1e-20, 2.0, 60),       # Case B\n        (f_cos, df_cos, 0.0, 1e-20, 2.0, 60),       # Case C\n        (f_sq,  df_sq,  1.0e8, 1e-20, 2.0, 60),     # Case D\n    ]\n\n    results = []\n    for f, df, x0, h0, r, max_steps in test_cases:\n        h_used, steps, stalled, d_est = central_diff_with_growth(f, x0, h0, r, max_steps)\n        true_deriv = df(x0)\n        bias = abs(d_est - true_deriv)\n        results.append([h_used, int(steps), bool(stalled), float(d_est), float(bias)])\n    return results\n\ndef solve():\n    results = run_test_cases()\n    # Print as a single line in the exact required format: a list of lists\n    print(str(results))\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3269293"}]}