{"hands_on_practices": [{"introduction": "牛顿冷却定律是描述物体在恒定环境温度下冷却过程的经典物理模型，其本质是一个指数衰减过程。通过对温度差取对数，我们可以将这条指数曲线“拉直”成一条直线。这个练习 [@problem_id:3221524] 将指导你如何运用对数变换来实现数据线性化，并使用线性回归方法从实验数据中估算冷却常数 $k$，这是数据分析中最常用的线性化技巧之一。", "problem": "一杯咖啡在恒定环境温度的房间里因与环境的热交换而冷却。描述此过程的唯象定律是牛顿冷却定律，该定律指出，咖啡温度的瞬时变化率与咖啡温度和环境温度之差成正比。在数学上，其控制常微分方程为 $\\,\\dfrac{dT}{dt} = -k\\,(T - T_{\\mathrm{env}})\\,$，其中 $\\,T\\,$ 是咖啡温度，$\\,t\\,$ 是时间，$\\,T_{\\mathrm{env}}\\,$ 是环境温度，$\\,k > 0\\,$ 是衰减常数。您的任务是使用数据线性化方法，根据实验测量值来估计衰减常数 $\\,k\\,$。\n\n实现一个完整、可运行的程序，该程序：\n- 从控制常微分方程 $\\,\\dfrac{dT}{dt} = -k\\,(T - T_{\\mathrm{env}})\\,$ 作为基本出发点。\n- 推导并应用适合指数衰减的线性化策略，从而将 $\\,k\\,$ 的估计简化为使用普通最小二乘法 (OLS) 拟合一条直线。\n- 通过排除任何 $\\,T - T_{\\mathrm{env}} \\le 0\\,$ 的数据点来处理自然对数的定义域限制。\n- 从线性化数据中计算 OLS 斜率，并为每个测试用例返回相应的 $\\,k\\,$ 的估计值。\n\n所有时间值必须以分钟为单位，所有温度值以摄氏度为单位，$\\,k\\,$ 的最终估计值必须以反分钟（即 $\\,\\mathrm{min}^{-1}\\,$）表示。本任务中不涉及角度或百分比。\n\n使用以下测量的时间-温度数据集测试套件，每个数据集都与一个已知的环境温度配对。每个元组的形式为 $\\,(\\text{时间}, \\text{温度}, T_{\\mathrm{env}})\\,$，其中列表是有序的，时间单位为分钟：\n- 测试用例 $\\,1\\,$ (具有轻微噪声的一般情况)：$\\,([0,2,4,6,8,10,12],\\,[85.0,\\,71.86,\\,61.48,\\,52.86,\\,45.666,\\,41.063,\\,36.724],\\,22.0)\\,$。\n- 测试用例 $\\,2\\,$ (包含一个等于环境温度的读数的边缘情况；排除非正差异)：$\\,([0,5,10,15,20],\\,[90.0,\\,66.52,\\,51.65,\\,41.07,\\,20.0],\\,20.0)\\,$。\n- 测试用例 $\\,3\\,$ (用于线性拟合的最少可用点数的边界情况)：$\\,([0,7],\\,[80.0,\\,52.6],\\,25.0)\\,$。\n- 测试用例 $\\,4\\,$ (晚期读数，其中 $\\,T - T_{\\mathrm{env}}\\,$ 很小但为正)：$\\,([0,12,24,36],\\,[70.0,\\,49.145,\\,37.946,\\,31.399],\\,24.0)\\,$。\n\n您的程序应：\n- 对于每个测试用例，根据控制常微分方程构建线性化数据集，并应用普通最小二乘法来估计斜率。\n- 将估计的斜率映射到衰减常数 $\\,k\\,$，单位为 $\\,\\mathrm{min}^{-1}\\,$。\n- 从线性化过程中排除任何 $\\,T - T_{\\mathrm{env}} \\le 0\\,$ 的数据点；如果排除后剩余的数据点少于 $\\,2\\,$ 个，则该测试用例返回一个浮点类型的“非数值”(Not-a-Number)。\n\n最终输出格式规范：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，例如 $\\,\\,[k_1,k_2,k_3,k_4]\\,$, 其中每个 $\\,k_i\\,$ 是从相应测试用例计算出的浮点估计值，单位为 $\\,\\mathrm{min}^{-1}\\,$。\n\n覆盖性设计：\n- 测试用例 $\\,1\\,$ 验证了具有多个点和轻微测量噪声的常规“理想路径”。\n- 测试用例 $\\,2\\,$ 通过包含一个等于环境温度的值来检查对无效对数输入的正确排除。\n- 测试用例 $\\,3\\,$ 确保在恰好有两个可用点（这是线性拟合的最低要求）时程序能正常运行。\n- 测试用例 $\\,4\\,$ 探测在晚期时间，温差很小但仍为正值时的稳定性。\n\n确保程序是自包含的，按指定格式生成输出，并且不需要用户输入。所有计算出的 $\\,k\\,$ 值必须以 $\\,\\mathrm{min}^{-1}\\,$ 表示。", "solution": "该问题要求使用实验数据估计牛顿冷却定律中的衰减常数 $k$。指定的方法是数据线性化，然后进行普通最小二乘法 (OLS) 回归。解决方案的开发过程是：首先推导理论模型，然后形式化数据线性化过程，最后设计一个算法来计算 $k$ 的估计值。\n\n**1. 理论模型与线性化**\n\n该物理过程由牛顿冷却定律的一阶常微分方程 (ODE) 描述：\n$$\n\\frac{dT}{dt} = -k(T - T_{\\mathrm{env}})\n$$\n其中 $T(t)$ 是物体在时间 $t$ 的温度，$T_{\\mathrm{env}}$ 是恒定的环境温度，$k > 0$ 是待确定的衰减常数。\n\n为了线性化此模型，我们首先求解该 ODE。设 $\\Delta T(t) = T(t) - T_{\\mathrm{env}}$。由于 $T_{\\mathrm{env}}$ 是常数，因此 $\\frac{d(\\Delta T)}{dt} = \\frac{dT}{dt}$。该 ODE 可以重写为：\n$$\n\\frac{d(\\Delta T)}{dt} = -k(\\Delta T)\n$$\n这是一个可分离的微分方程。我们可以分离变量并积分：\n$$\n\\int \\frac{d(\\Delta T)}{\\Delta T} = \\int -k \\, dt\n$$\n$$\n\\ln|\\Delta T| = -kt + C_1\n$$\n其中 $C_1$ 是积分常数。由于物体正在冷却，因此 $T(t) \\ge T_{\\mathrm{env}}$，所以 $\\Delta T \\ge 0$。我们可以去掉绝对值符号，但需注意对数仅对 $\\Delta T > 0$ 有定义。对两边取指数可得：\n$$\n\\Delta T = e^{-kt + C_1} = e^{C_1}e^{-kt}\n$$\n设常数 $A = e^{C_1}$。解为 $\\Delta T(t) = A e^{-kt}$。如果我们考虑初始条件 $T(0) = T_0$，则 $\\Delta T(0) = T_0 - T_{\\mathrm{env}} = A e^0 = A$。因此，特解为：\n$$\nT(t) - T_{\\mathrm{env}} = (T_0 - T_{\\mathrm{env}}) e^{-kt}\n$$\n为了线性化这个指数关系，我们对两边取自然对数。此步骤仅对满足 $T(t) > T_{\\mathrm{env}}$ 或 $T(t) - T_{\\mathrm{env}} > 0$ 的数据点有效。\n$$\n\\ln(T(t) - T_{\\mathrm{env}}) = \\ln\\left((T_0 - T_{\\mathrm{env}}) e^{-kt}\\right)\n$$\n利用对数的性质 $\\ln(ab) = \\ln(a) + \\ln(b)$ 和 $\\ln(e^x) = x$，我们得到：\n$$\n\\ln(T(t) - T_{\\mathrm{env}}) = \\ln(T_0 - T_{\\mathrm{env}}) - kt\n$$\n此方程现在是直线形式 $Y = mX + c$：\n- 设因变量为 $Y = \\ln(T - T_{\\mathrm{env}})$。\n- 设自变量为 $X = t$。\n- 直线的斜率为 $m = -k$。\n- y轴截距为 $c = \\ln(T_0 - T_{\\mathrm{env}})$。\n\n关键的洞见是，衰减常数 $k$ 可以通过对转换后数据进行线性拟合的斜率来估计：$k = -m$。\n\n**2. 参数估计算法设计**\n\n给定一组 $N$ 个实验数据点 $(t_i, T_i)$ 和一个已知的 $T_{\\mathrm{env}}$，我们可以通过以下步骤估计 $k$：\n\n**步骤 2.1：数据转换和筛选**\n首先，我们将原始数据转换为线性化坐标系 $(X_i, Y_i)$。\n1.  对于每个测量对 $(t_i, T_i)$，计算温差 $\\Delta T_i = T_i - T_{\\mathrm{env}}$。\n2.  问题要求处理自然对数的定义域。我们必须筛选数据集，只包括 $\\Delta T_i > 0$ 的点。任何 $\\Delta T_i \\le 0$ 的点都将被丢弃。\n3.  线性拟合至少需要两个点。如果在筛选后，剩余的数据点少于两个，则无法估计斜率。在这种情况下，对于给定的数据集，该问题是病态的，结果应为“非数值”(NaN)。\n4.  对于剩余的有效点，构建线性化数据集：\n    $$\n    X_i = t_i\n    $$\n    $$\n    Y_i = \\ln(\\Delta T_i) = \\ln(T_i - T_{\\mathrm{env}})\n    $$\n\n**步骤 2.2：普通最小二乘 (OLS) 回归**\n我们对筛选和转换后的数据点 $(X_i, Y_i)$ 应用 OLS，以找到最佳拟合直线的斜率 $m$。使残差平方和最小化的 OLS 斜率公式为：\n$$\nm = \\frac{\\sum_{i=1}^{N'} (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum_{i=1}^{N'} (X_i - \\bar{X})^2}\n$$\n其中 $N'$ 是筛选后有效数据点的数量，$\\bar{X}$ 和 $\\bar{Y}$ 分别是 $X_i$ 和 $Y_i$ 值的样本均值。\n\n**步骤 2.3：参数恢复**\n最后，我们从估计的斜率 $m$ 中恢复衰减常数 $k$ 的估计值：\n$$\nk = -m\n$$\n由于温度 $T$ 随时间降低，转换后的变量 $Y = \\ln(T - T_{\\mathrm{env}})$ 也将随时间 $X=t$ 减小。因此，斜率 $m$ 将为负，从而确保估计的 $k = -m$ 为正，这与其作为衰减常数的物理定义一致。\n\n这套完整的流程提供了一种基于系统基本物理原理和标准数值技术的稳健方法，用于从实验数据中估计 $k$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef estimate_k_from_data(times, temperatures, T_env):\n    \"\"\"\n    Estimates the decay constant k from time-temperature data using linearization.\n\n    The function linearizes the solution to Newton's law of cooling,\n    T(t) - T_env = (T0 - T_env) * exp(-k*t), by taking the natural log:\n    ln(T - T_env) = -k*t + ln(T0 - T_env).\n    This is a linear equation y = m*x + c, where y = ln(T - T_env), \n    x = t, and the slope m = -k.\n\n    Args:\n        times (list or np.ndarray): A list of time points in minutes.\n        temperatures (list or np.ndarray): A list of temperature readings in Celsius.\n        T_env (float): The constant ambient temperature in Celsius.\n\n    Returns:\n        float: The estimated decay constant k in min^-1, or np.nan if a fit is not possible.\n    \"\"\"\n    # Convert inputs to numpy arrays for vectorized operations\n    times = np.array(times, dtype=float)\n    temperatures = np.array(temperatures, dtype=float)\n\n    # Calculate the temperature difference\n    delta_T = temperatures - T_env\n\n    # Filter out data points where delta_T is not positive, as ln(x) is defined for x > 0.\n    # The problem specifies T - T_env = 0 should be excluded.\n    valid_indices = np.where(delta_T > 0)\n    \n    filtered_times = times[valid_indices]\n    filtered_delta_T = delta_T[valid_indices]\n\n    # A line fit requires at least 2 points.\n    if len(filtered_times)  2:\n        return np.nan\n\n    # Create the variables for the linear regression\n    # X = t\n    # Y = ln(T - T_env)\n    x_data = filtered_times\n    y_data = np.log(filtered_delta_T)\n\n    # Perform Ordinary Least Squares (OLS) to find the slope m.\n    # m = Cov(x, y) / Var(x)\n    # Using the direct summation formula for clarity:\n    # m = sum((x - x_bar)(y - y_bar)) / sum((x - x_bar)^2)\n    x_mean = np.mean(x_data)\n    y_mean = np.mean(y_data)\n    \n    numerator = np.sum((x_data - x_mean) * (y_data - y_mean))\n    denominator = np.sum((x_data - x_mean)**2)\n\n    # Avoid division by zero, although not expected if len(x_data) >= 2 and times are not identical\n    if denominator == 0:\n        return np.nan\n\n    slope_m = numerator / denominator\n\n    # The decay constant k is the negative of the slope\n    k = -slope_m\n    \n    return k\n\ndef solve():\n    \"\"\"\n    Runs the estimation for all test cases and prints the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each tuple: (times, temperatures, T_env)\n    test_cases = [\n        # Test case 1 (general case with mild noise)\n        ([0, 2, 4, 6, 8, 10, 12], [85.0, 71.86, 61.48, 52.86, 45.666, 41.063, 36.724], 22.0),\n        # Test case 2 (edge case with T = T_env)\n        ([0, 5, 10, 15, 20], [90.0, 66.52, 51.65, 41.07, 20.0], 20.0),\n        # Test case 3 (boundary case with minimum points)\n        ([0, 7], [80.0, 52.6], 25.0),\n        # Test case 4 (late-time readings with small but positive delta_T)\n        ([0, 12, 24, 36], [70.0, 49.145, 37.946, 31.399], 24.0)\n    ]\n\n    results = []\n    for case in test_cases:\n        times, temperatures, T_env = case\n        k_estimate = estimate_k_from_data(times, temperatures, T_env)\n        results.append(k_estimate)\n\n    # Format output as a comma-separated list in brackets\n    # Use a custom formatter to handle floating point representation\n    formatted_results = [f'{r:.7f}' for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3221524"}, {"introduction": "波的频率和波长之间存在反比关系，这是另一个常见的非线性模型。本练习将探讨如何通过倒数变换将这种反比关系线性化，从而估算波速 $v$。与上一个练习不同，这个物理模型 [@problem_id:3221525] 还要求拟合的直线必须通过原点，这为我们提供了一个练习有约束线性回归的绝佳机会。", "problem": "给定一组带有噪声的波长和频率测量值，这些波遵循基本色散关系 $f = v / \\lambda$，其中 $f$ 是频率（单位：赫兹），$\\lambda$ 是波长（单位：米），$v$ 是波速（单位：米/秒）。您的任务是将此反比关系线性化，并使用基于原理的数值方法从数据中估计 $v$。\n\n基本原理：使用核心物理模型 $f = v / \\lambda$ 和最小二乘法（定义为残差平方和的最小化）的定义。不要使用任何预封装或快捷的拟合公式。您的程序必须通过变换变量来计算线性化拟合，使模型在未知数上变为线性，然后通过在该线性化空间中最小化误差平方和来估计该未知数。为符合物理现实，将拟合直线约束为通过原点，这与当 $v$ 为常数且 $f$ 无偏移时，$f = 0$ 对应于 $\\lambda \\to \\infty$ 的情况一致。\n\n算法任务规范：\n- 将模型线性化为在 $v$ 上呈线性的形式。\n- 使用普通最小二乘法（定义为最小化残差平方和），在线条通过原点的约束下，从线性化数据中计算估计值 $\\hat{v}$。\n- 直接根据最小二乘法的定义实现此计算，不依赖任何库拟合例程。\n- 所有估计值必须以米/秒为单位表示，并四舍五入到小数点后恰好六位。\n\n测试套件：\n为以下五个独立的数据集中的每一个计算 $\\hat{v}$。每个数据集提供以米为单位的波长值和以赫兹为单位的频率值。存在小的乘性测量噪声以确保场景的真实性。\n\n- 情况A（理想情况，中等波长）：\n  - 波长（米）：$[0.5, 0.8, 1.2, 1.5, 2.0]$\n  - 频率（赫兹）：$[689.1456, 427.713, 286.572, 227.656, 171.7716]$\n\n- 情况B（大波长，低频率）：\n  - 波长（米）：$[2.5, 5.0, 7.5, 10.0, 12.5]$\n  - 频率（赫兹）：$[592.8, 296.9928, 197.4024, 148.6446, 118.32288]$\n\n- 情况C（极小波长，极高频率）：\n  - 波长（米）：$[4.0\\times 10^{-7}, 5.0\\times 10^{-7}, 6.0\\times 10^{-7}, 7.0\\times 10^{-7}]$\n  - 频率（赫兹）：$[7.5\\times 10^{14}, 5.9994\\times 10^{14}, 5.001\\times 10^{14}, 4.285071428571429\\times 10^{14}]$\n\n- 情况D（两个点的边界情况）：\n  - 波长（米）：$[3.0, 4.0]$\n  - 频率（赫兹）：$[40.4, 29.85]$\n\n- 情况E（一个离群值的影响）：\n  - 波长（米）：$[1.0, 2.0, 3.0, 4.0, 5.0]$\n  - 频率（赫兹）：$[1000.0, 500.0, 366.6666666666667, 250.0, 200.0]$\n\n输出格式：\n- 您的程序必须生成单行输出，其中包含一个Python风格的列表，内含五个估计速度，每个速度以米/秒为单位，按A、B、C、D、E的顺序排列，并四舍五入到小数点后恰好六位。例如，输出必须看起来像 $[a,b,c,d,e]$，其中 $a,b,c,d,e$ 均为浮点数，小数点后恰好有六位。\n\n不应从标准输入读取任何输入。所有常量和数据集已在上方提供。不涉及角度。所有输出必须以米/秒为单位，并且必须四舍五入到小数点后恰好六位。最终输出必须是符合指定格式的单行列表。", "solution": "问题要求从带有噪声的波长 $\\lambda$ 和频率 $f$ 的测量集合中估计波速 $v$。其控制物理模型是基本色散关系：\n$$\nf = \\frac{v}{\\lambda}\n$$\n这种关系是非线性的，具体来说是 $f$ 和 $\\lambda$ 之间的反比关系。为了应用线性估计方法，我们必须首先将模型线性化。\n\n让我们定义一组新变量。令自变量为 $x = 1/\\lambda$，因变量为 $y = f$。将这些代入物理模型得到：\n$$\ny = v \\cdot x\n$$\n这个变换后的方程表示 $y$ 和 $x$ 之间的线性关系。它描述了在 $(x, y)$ 平面中一条通过原点 $(0, 0)$ 的直线。这条线的斜率就是波速 $v$，也就是我们希望估计的参数。拟合直线必须通过原点的约束在物理上是合理的，因为对于有限的波速 $v$，当波长 $\\lambda$ 趋于无穷大时（即当 $x = 1/\\lambda$ 趋于 $0$ 时），频率 $f$ 趋于 $0$。\n\n任务是使用普通最小二乘法（OLS）原理，对于通过原点的回归来估计 $v$。给定一组 $N$ 个数据点 $(\\lambda_i, f_i)$，我们首先将它们变换为 $(x_i, y_i) = (1/\\lambda_i, f_i)$。模型预测，对于给定的 $x_i$，相应的 $y$ 值应为 $\\hat{y}_i = v x_i$。观测值 $y_i$ 与预测值 $\\hat{y}_i$ 之间的差是残差 $r_i$：\n$$\nr_i = y_i - \\hat{y}_i = y_i - v x_i\n$$\nOLS方法找到参数 $v$ 的值，该值使得这些残差的平方和（记为 $S(v)$）最小化：\n$$\nS(v) = \\sum_{i=1}^{N} r_i^2 = \\sum_{i=1}^{N} (y_i - v x_i)^2\n$$\n为了找到最小值，我们计算 $S(v)$ 关于 $v$ 的导数并将其设为零。\n$$\n\\frac{dS}{dv} = \\frac{d}{dv} \\sum_{i=1}^{N} (y_i - v x_i)^2\n$$\n根据微分的线性性质，我们可以将导数移到求和符号内部：\n$$\n\\frac{dS}{dv} = \\sum_{i=1}^{N} \\frac{d}{dv} (y_i - v x_i)^2\n$$\n使用链式法则，其中内函数是 $g(v) = y_i - v x_i$，外函数是 $h(g) = g^2$：\n$$\n\\frac{d}{dv} (y_i - v x_i)^2 = 2(y_i - v x_i) \\cdot \\frac{d}{dv}(y_i - v x_i) = 2(y_i - v x_i)(-x_i) = -2(y_i x_i - v x_i^2)\n$$\n将此代回 $S(v)$ 的导数表达式中：\n$$\n\\frac{dS}{dv} = \\sum_{i=1}^{N} -2(y_i x_i - v x_i^2) = -2 \\left( \\sum_{i=1}^{N} y_i x_i - v \\sum_{i=1}^{N} x_i^2 \\right)\n$$\n将导数设为零，以找到使 $S(v)$ 最小化的 $v$ 值（我们称之为估计值 $\\hat{v}$）：\n$$\n-2 \\left( \\sum_{i=1}^{N} y_i x_i - \\hat{v} \\sum_{i=1}^{N} x_i^2 \\right) = 0\n$$\n$$\n\\sum_{i=1}^{N} y_i x_i - \\hat{v} \\sum_{i=1}^{N} x_i^2 = 0\n$$\n求解 $\\hat{v}$：\n$$\n\\hat{v} \\sum_{i=1}^{N} x_i^2 = \\sum_{i=1}^{N} y_i x_i\n$$\n$$\n\\hat{v} = \\frac{\\sum_{i=1}^{N} x_i y_i}{\\sum_{i=1}^{N} x_i^2}\n$$\n这就是强制通过原点的回归线斜率的OLS估计量。注意，二阶导数为 $\\frac{d^2S}{dv^2} = \\sum_{i=1}^{N} 2x_i^2$，只要不是所有的 $x_i$ 都为零，该值就为正，这确保了该临界点确实是一个最小值。\n\n将原始变量 $x_i = 1/\\lambda_i$ 和 $y_i = f_i$ 代回，估计波速的公式变为：\n$$\n\\hat{v} = \\frac{\\sum_{i=1}^{N} (1/\\lambda_i) f_i}{\\sum_{i=1}^{N} (1/\\lambda_i)^2}\n$$\n现在将此公式应用于所提供的五个数据集中的每一个。对于每种情况，使用波长 $\\lambda_i$ 和频率 $f_i$ 来计算分子 $\\sum (f_i/\\lambda_i)$ 和分母 $\\sum (1/\\lambda_i^2)$，以找到估计值 $\\hat{v}$。计算将使用浮点运算执行，最终结果将按要求四舍五入到六位小数。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the wave speed v from noisy (wavelength, frequency) data.\n\n    The method involves linearizing the model f = v / lambda to y = v*x,\n    where y = f and x = 1/lambda. The estimate for v is then found by\n    ordinary least squares for a line forced through the origin, which\n    minimizes the sum of squared residuals. The derived formula is:\n    v_hat = sum(x*y) / sum(x*x).\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A (happy path, moderate wavelengths)\n        (np.array([0.5, 0.8, 1.2, 1.5, 2.0]), \n         np.array([689.1456, 427.713, 286.572, 227.656, 171.7716])),\n        \n        # Case B (large wavelengths, low frequencies)\n        (np.array([2.5, 5.0, 7.5, 10.0, 12.5]), \n         np.array([592.8, 296.9928, 197.4024, 148.6446, 118.32288])),\n        \n        # Case C (very small wavelengths, very high frequencies)\n        (np.array([4.0e-7, 5.0e-7, 6.0e-7, 7.0e-7]), \n         np.array([7.5e14, 5.9994e14, 5.001e14, 4.285071428571429e14])),\n        \n        # Case D (boundary case with two points)\n        (np.array([3.0, 4.0]), \n         np.array([40.4, 29.85])),\n        \n        # Case E (influence of an outlier)\n        (np.array([1.0, 2.0, 3.0, 4.0, 5.0]), \n         np.array([1000.0, 500.0, 366.6666666666667, 250.0, 200.0]))\n    ]\n\n    results = []\n    for wavelengths, frequencies in test_cases:\n        # Transform variables for linearization: x = 1/lambda, y = f\n        x = 1.0 / wavelengths\n        y = frequencies\n\n        # Calculate the terms for the OLS estimator\n        # v_hat = sum(x_i * y_i) / sum(x_i^2)\n        sum_xy = np.sum(x * y)\n        sum_x_squared = np.sum(x**2)\n\n        # Compute the estimated wave speed\n        v_hat = sum_xy / sum_x_squared\n        \n        results.append(v_hat)\n\n    # Format the results to exactly six decimal places\n    formatted_results = [f\"{res:.6f}\" for res in results]\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3221525"}, {"introduction": "在真实的科研探索中，我们往往无法预先知道数据背后精确的物理规律。因此，能够系统地评估并选择最合适的模型至关重要。这个综合性练习 [@problem_id:3221527] 要求你编写一个程序，它能自动测试多种常见的线性化方法，并根据拟合优度 ($R^2$) 和残差的随机性对它们进行排序。这个实践将帮助你从简单地套用公式，迈向构建智能化数据分析工具的更高层次。", "problem": "你必须编写一个完整、可运行的程序，对于给定的一小组二维数据集，自动应用一组预定义的数据线性化方法，并根据一个结合了决定系数和残差随机性检验的综合得分对它们进行排序。程序必须实现以下基于基本定义的内容：作为残差平方和最小化器的普通最小二乘法（OLS）线性回归、根据平方和定义的决定系数 $R^2$，以及使用双边渐近正态近似的用于检验残差随机性的 Wald–Wolfowitz 游程检验。程序必须能处理变换的定义域限制，并能确定性地解决平局问题。\n\n定义和要求：\n- 数据线性化是指通过变换将数据 $(x,y)$ 映射到 $(u,v)$，从而使线性模型 $v = a + b u$ 变得适合使用普通最小二乘法（OLS）进行拟合的过程。有效的线性化必须遵守变换的定义域。\n- 对于变换后的数据 $(u_i,v_i)$，使用 OLS 作为唯一的最小二乘解，该解通过最小化 $\\sum_{i=1}^n (v_i - a - b u_i)^2$ 来求解 $a$ 和 $b$。\n- 根据基于与 $v$ 均值相关的平方和比率的基本定义来计算决定系数 $R^2$；通过将 $R^2$ 设为 $0$ 来处理总平方和为零的退化情况。\n- 对于残差随机性，对按 $u$ 递增（升序）排序的残差序列使用 Wald–Wolfowitz 游程检验，其中每个残差的符号定义为：如果大于或等于零则为非负，否则为负。使用标准的双边渐近正态近似来计算 $p$ 值。如果所有残差的符号相同，或游程计数的方差退化，则将 $p$ 值设为 $0$。\n- 将 $p$ 值转换为一个单位区间内的“随机性得分”，该得分奖励接近 $0.5$ 的值，并惩罚接近 $0$ 或 $1$ 的值。\n- 使用固定权重将 $R^2$ 和随机性得分组合成一个综合得分。\n\n待测试的变换及其整数代码：\n- 代码 $0$：对 $x$ 和 $y$ 进行恒等变换（无变换）。定义域：所有实数 $x$ 和 $y$。\n- 代码 $1$：对 $x$ 进行恒等变换，对 $y$ 取自然对数。定义域：所有数据点的 $y_i > 0$。\n- 代码 $2$：对 $x$ 取自然对数，对 $y$ 进行恒等变换。定义域：所有数据点的 $x_i > 0$。\n- 代码 $3$：对 $x$ 和 $y$ 均取自然对数。定义域：所有数据点的 $x_i > 0$ 且 $y_i > 0$。\n- 代码 $4$：对 $x$ 取倒数，对 $y$ 进行恒等变换。定义域：所有数据点的 $x_i \\ne 0$。\n- 代码 $5$：对 $x$ 进行恒等变换，对 $y$ 取倒数。定义域：所有数据点的 $y_i \\ne 0$。\n\n评分和决胜规则：\n- 对于每个有效变换，通过 OLS 拟合 $v = a + b u$，计算 $R^2$，计算按 $u$ 递增排序的残差的游程检验双边 $p$ 值，并将其转换为随机性得分 $s_{\\text{rand}} = 1 - 2 \\lvert p - 0.5 \\rvert$，裁剪到区间 $\\left[0,1\\right]$。\n- 使用 $w_R = 0.7$ 和 $w_P = 0.3$ 计算综合得分 $S = w_R R^2 + w_P s_{\\text{rand}}$。\n- 按 $S$ 的降序对变换进行排序。平局处理规则如下：如果 $\\lvert S_1 - S_2 \\rvert \\le \\varepsilon$（其中 $\\varepsilon = 10^{-12}$），则优先选择 $R^2$ 较大者；如果仍然平局，则按代码顺序 $[0,1,2,3,4,5]$ 优先选择较简单者。\n\n无效变换：\n- 如果任何变换后的值不是有限实数或违反了定义域条件，则该变换对于该数据集是无效的，必须跳过。\n\n残差排序：\n- 对于游程检验，将变换后的输入 $u_i$ 按升序排序，并使用该顺序下的残差序列。\n\n测试套件：\n你的程序必须处理以下数据集，每个数据集都以 $(x,y)$ 对的显式列表形式给出。不涉及角度。没有物理单位。\n\n- 数据集 $1$（近似指数）：\n  - $( $0.0$ , $2.04$ )$, $( $0.5$ , $2.924$ )$, $( $1.0$ , $4.496$ )$, $( $1.5$ , $6.640$ )$, $( $2.0$ , $9.609$ )$, $( $2.5$ , $15.221$ )$, $( $3.0$ , $22.046$ )$。\n- 数据集 $2$（近似幂律）：\n  - $( $1.0$ , $1.5$ )$, $( $1.5$ , $3.697$ )$, $( $2.0$ , $7.601$ )$, $( $2.5$ , $12.577$ )$, $( $3.5$ , $26.512$ )$, $( $4.5$ , $48.177$ )$, $( $6.0$ , $92.52$ )$。\n- 数据集 $3$（近似线性）：\n  - $( $0$ , $-3.0$ )$, $( $1$ , $-1.7$ )$, $( $2$ , $-0.65$ )$, $( $3$ , $0.7$ )$, $( $4$ , $1.7$ )$, $( $5$ , $3.0$ )$, $( $6$ , $4.25$ )$, $( $7$ , $5.35$ )$, $( $8$ , $6.7$ )$, $( $9$ , $7.7$ )$, $( $10$ , $9.0$ )$。\n- 数据集 $4$（$x$ 近似倒数关系）：\n  - $( $1$ , $3.0$ )$, $( $2$ , $2.05$ )$, $( $3$ , $1.6467$ )$, $( $4$ , $1.53$ )$, $( $6$ , $1.3233$ )$, $( $8$ , $1.27$ )$, $( $10$ , $1.2$ )$。\n- 数据集 $5$（$y$ 值近似恒定）：\n  - $( $1$ , $5.02$ )$, $( $2$ , $5.01$ )$, $( $3$ , $5.00$ )$, $( $4$ , $4.99$ )$, $( $5$ , $5.01$ )$, $( $6$ , $5.00$ )$。\n\n要求的最终输出：\n- 对于上述按顺序列出的每个数据集，根据所述的综合得分和决胜规则，输出排名最高的单个变换的整数代码。\n- 你的程序应生成单行输出，其中包含一个方括号括起来的逗号分隔列表形式的结果，例如 $[c_1,c_2,c_3,c_4,c_5]$，其中每个 $c_i$ 是一个整数变换代码。\n\n约束条件：\n- 仅使用上述指定的变换代码和定义。\n- 使用 $w_R = 0.7$，$w_P = 0.3$，$\\varepsilon = 10^{-12}$。\n- 游程检验的排序必须按变换后的输入 $u$ 的升序进行。\n- 等于零的残差计为非负。\n- 如果 $v$ 的总平方和为零，则将 $R^2$ 设为 $0$。\n- 如果游程检验退化（所有符号相同或方差为零），则将 $p$ 值设为 $0$，此时随机性得分为 $0$。\n\n你的实现必须是一个如下文所述的完整、可运行的程序，并且只产生所要求的单行输出。不从标准输入读取任何输入。不使用外部文件。", "solution": "该问题要求实现一个综合性的数据分析流程，为一组给定的二维数据集选择最佳的数据线性化变换。选择过程基于一个确定性的排序程序，该程序结合了模型拟合优度（$R^2$）和残差随机性统计检验（Wald-Wolfowitz 游程检验）。\n\n对每个数据集的总体流程如下：\n1.  对于六种预定义变换中的每一种，根据其定义域约束检查它对给定数据集是否有效。\n2.  对于每种有效变换，将其应用于数据 $(x_i, y_i)$ 以获得变换后的数据 $(u_i, v_i)$。\n3.  对变换后的数据执行普通最小二乘法（OLS）线性回归，以拟合模型 $v = a + b u$。\n4.  计算决定系数 $R^2$，以量化拟合优度。\n5.  对线性拟合的残差执行 Wald–Wolfowitz 游程检验，以评估其随机性。残差根据变换后自变量 $u$ 的升序值进行排序。\n6.  将游程检验得到的 $p$ 值转换为一个随机性得分 $s_{\\text{rand}}$。\n7.  计算最终的综合得分 $S$，作为 $R^2$ 和 $s_{\\text{rand}}$ 的加权平均值。\n8.  对该数据集的所有有效变换，按照其综合得分 $S$ 的降序进行排序，并应用指定的决胜规则。\n9.  排名最高的变换被选为该数据集的最佳变换。\n\n以下是所用数学和统计方法的详细分步描述。\n\n**1. 数据变换与有效性**\n\n对每个数据点 $(x_i, y_i)$ 应用变换，以生成新点 $(u_i, v_i)$。由整数代码标识的六种指定变换是：\n- 代码 $0$（恒等）：$u = x$, $v = y$。定义域：所有实数 $x, y$。\n- 代码 $1$（半对数）：$u = x$, $v = \\ln(y)$。定义域：要求所有 $y_i > 0$。\n- 代码 $2$（半对数）：$u = \\ln(x)$, $v = y$。定义域：要求所有 $x_i > 0$。\n- 代码 $3$（双对数）：$u = \\ln(x)$, $v = \\ln(y)$。定义域：要求所有 $x_i > 0$ 且所有 $y_i > 0$。\n- 代码 $4$（$x$ 倒数）：$u = 1/x$, $v = y$。定义域：要求所有 $x_i \\neq 0$。\n- 代码 $5$（$y$ 倒数）：$u = x$, $v = 1/y$。定义域：要求所有 $y_i \\neq 0$。\n\n如果任何数据点违反了变换的定义域，或者任何生成的 $u_i$ 或 $v_i$ 不是有限实数（即为 $\\pm\\infty$ 或 NaN），则该变换对该数据集被视为无效。无效变换将从该数据集的后续分析中排除。\n\n**2. 普通最小二乘法（OLS）线性回归**\n\n对于一组 $n$ 个变换后的数据点 $(u_i, v_i)$，我们寻求找到线性模型 $\\hat{v} = a + b u$ 的系数 $a$（截距）和 $b$（斜率），以最小化残差平方和（SSR）：\n$$SSR = \\sum_{i=1}^{n} (v_i - \\hat{v}_i)^2 = \\sum_{i=1}^{n} (v_i - a - b u_i)^2$$\n最小化此量的唯一解由以下公式给出：\n$$b = \\frac{\\sum_{i=1}^{n} (u_i - \\bar{u})(v_i - \\bar{v})}{\\sum_{i=1}^{n} (u_i - \\bar{u})^2} = \\frac{n \\sum u_i v_i - (\\sum u_i)(\\sum v_i)}{n \\sum u_i^2 - (\\sum u_i)^2}$$\n$$a = \\bar{v} - b \\bar{u}$$\n其中 $\\bar{u} = \\frac{1}{n} \\sum u_i$ 和 $\\bar{v} = \\frac{1}{n} \\sum v_i$ 是变换后数据的样本均值。\n\n**3. 决定系数 ($R^2$)**\n\n决定系数 $R^2$ 衡量因变量 $v$ 的方差中可由自变量 $u$ 预测的比例。其定义为：\n$$R^2 = 1 - \\frac{SSR}{SST}$$\n其中 $SSR$ 是如上定义的残差平方和，而 $SST$ 是总平方和：\n$$SST = \\sum_{i=1}^{n} (v_i - \\bar{v})^2$$\n根据问题规范，如果 $SST = 0$（当且仅当所有 $v_i$ 都相同时发生），则 $R^2$ 定义为 $0$。\n\n**4. Wald–Wolfowitz 游程检验**\n\n这种非参数检验用于评估数据序列是随机的这一假设。在这里，它应用于 OLS 拟合的残差序列。\n\n首先，根据 $u_i$ 的值对数据点 $(u_i, v_i)$ 进行升序排序。然后按这个新顺序计算残差 $e_i = v_i - (a + b u_i)$。每个残差被分类为非负（$+$）（如果 $e_i \\ge 0$）或负（$-$）（如果 $e_i  0$）。\n\n“游程”是连续的相同符号序列。计算总游程数 $R$。设 $n_P$ 为非负残差的数量，$n_N$ 为负残差的数量，其中 $N = n_P + n_N$。\n\n在随机性原假设下，游程数 $R$ 近似服从正态分布，其均值为 $\\mu_R$，方差为 $\\sigma_R^2$：\n$$\\mu_R = \\frac{2 n_P n_N}{N} + 1$$\n$$\\sigma_R^2 = \\frac{2 n_P n_N (2 n_P n_N - N)}{N^2 (N - 1)}$$\n如果检验退化（即，如果 $n_P = 0$ 或 $n_N = 0$，或者 $\\sigma_R^2 \\le 0$），则将 $p$ 值设为 $0$。\n\n否则，计算检验统计量 $Z$：\n$$Z = \\frac{R - \\mu_R}{\\sigma_R}$$\n然后，双边 $p$ 值计算为 $p = 2(1 - \\Phi(|Z|))$，其中 $\\Phi$ 是标准正态分布的累积分布函数（CDF）。CDF 是使用误差函数 $\\text{erf}(x)$ 实现的，即 $\\Phi(z) = 0.5 \\cdot (1 + \\text{erf}(z/\\sqrt{2}))$。\n\n**5. 评分和排序**\n\n回归和随机性检验的结果被组合成一个单一的分数。\n\n首先，将游程检验的 $p$ 值转换为一个随机性得分 $s_{\\text{rand}}$，该得分奖励接近 $0.5$ 的 $p$ 值（表示随机性），并惩罚接近 $0$ 或 $1$ 的值（表示存在模式）。其定义为：\n$$s_{\\text{rand}} = 1 - 2 |p - 0.5|$$\n$s_{\\text{rand}}$ 的值被裁剪到区间 $[0, 1]$ 内。\n\n接下来，计算最终的综合得分 $S$，作为 $R^2$ 和 $s_{\\text{rand}}$ 的加权和：\n$$S = w_R R^2 + w_P s_{\\text{rand}}$$\n使用指定的权重 $w_R = 0.7$ 和 $w_P = 0.3$。\n\n最后，对每个数据集，有效的变换根据以下确定性标准进行排序：\n1.  主排序：按综合得分 $S$ 的降序排列。\n2.  第一决胜规则：如果 $|S_1 - S_2| \\le \\varepsilon = 10^{-12}$，则优先选择 $R^2$ 值较大的变换。\n3.  第二决胜规则：如果 $R^2$ 值也相同，则优先选择整数代码较小的变换（即，更简单的变换）。\n\n排名最高的变换被选为该数据集的最优选择。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\nfrom functools import cmp_to_key\n\ndef solve():\n    \"\"\"\n    Solves the data linearization problem by applying, scoring, and ranking\n    a predefined set of transformations for several datasets.\n    \"\"\"\n    # Define constants as per problem statement\n    W_R = 0.7\n    W_P = 0.3\n    EPSILON = 1e-12\n\n    # Define the datasets to be analyzed\n    test_cases = [\n        # Dataset 1 (approximately exponential)\n        np.array([\n            (0.0, 2.04), (0.5, 2.924), (1.0, 4.496), (1.5, 6.640),\n            (2.0, 9.609), (2.5, 15.221), (3.0, 22.046)\n        ]),\n        # Dataset 2 (approximately power law)\n        np.array([\n            (1.0, 1.5), (1.5, 3.697), (2.0, 7.601), (2.5, 12.577),\n            (3.5, 26.512), (4.5, 48.177), (6.0, 92.52)\n        ]),\n        # Dataset 3 (approximately linear)\n        np.array([\n            (0, -3.0), (1, -1.7), (2, -0.65), (3, 0.7), (4, 1.7),\n            (5, 3.0), (6, 4.25), (7, 5.35), (8, 6.7), (9, 7.7), (10, 9.0)\n        ]),\n        # Dataset 4 (approximately reciprocal in x)\n        np.array([\n            (1, 3.0), (2, 2.05), (3, 1.6467), (4, 1.53),\n            (6, 1.3233), (8, 1.27), (10, 1.2)\n        ]),\n        # Dataset 5 (near-constant y)\n        np.array([\n            (1, 5.02), (2, 5.01), (3, 5.00), (4, 4.99), (5, 5.01), (6, 5.00)\n        ]),\n    ]\n\n    def apply_transformation(data, code):\n        \"\"\"Applies a transformation, checking for domain and finite value violations.\"\"\"\n        x, y = data[:, 0], data[:, 1]\n        \n        # Check domain validity before applying transformation\n        if code == 1 and not np.all(y > 0): return None, None\n        if code == 2 and not np.all(x > 0): return None, None\n        if code == 3 and not (np.all(x > 0) and np.all(y > 0)): return None, None\n        if code == 4 and not np.all(x != 0): return None, None\n        if code == 5 and not np.all(y != 0): return None, None\n\n        with np.errstate(divide='ignore', invalid='ignore'):\n            if code == 0: u, v = x, y\n            elif code == 1: u, v = x, np.log(y)\n            elif code == 2: u, v = np.log(x), y\n            elif code == 3: u, v = np.log(x), np.log(y)\n            elif code == 4: u, v = np.reciprocal(x), y\n            elif code == 5: u, v = x, np.reciprocal(y)\n\n        if not (np.all(np.isfinite(u)) and np.all(np.isfinite(v))):\n            return None, None\n        return u, v\n\n    def perform_ols(u, v):\n        \"\"\"Performs OLS regression and computes R^2.\"\"\"\n        n = len(u)\n        if n  2: return np.nan, np.nan, 0.0\n\n        u_mean, v_mean = np.mean(u), np.mean(v)\n        ss_ux = np.sum((u - u_mean)**2)\n        \n        if ss_ux == 0:  # All u values are identical, OLS slope is undefined.\n            return np.nan, np.nan, 0.0\n\n        b = np.sum((u - u_mean) * (v - v_mean)) / ss_ux\n        a = v_mean - b * u_mean\n        \n        ssr = np.sum((v - (a + b * u))**2)\n        sst = np.sum((v - v_mean)**2)\n\n        r2 = 0.0 if sst == 0 else 1.0 - (ssr / sst)\n        return a, b, r2\n\n    def wald_wolfowitz_test(residuals):\n        \"\"\"Computes the p-value from the Wald-Wolfowitz runs test.\"\"\"\n        n = len(residuals)\n        if n == 0: return 0.0\n\n        n_p = np.sum(residuals >= 0)\n        n_n = n - n_p\n\n        if n_p == 0 or n_n == 0: return 0.0\n\n        signs = residuals >= 0\n        runs = np.sum(signs[:-1] != signs[1:]) + 1\n        \n        mu_r = 2 * n_p * n_n / n + 1\n        var_num = 2 * n_p * n_n * (2 * n_p * n_n - n)\n        var_den = (n**2) * (n - 1)\n\n        if var_den == 0: return 0.0\n        var_r = var_num / var_den\n        if var_r = 0: return 0.0\n        \n        sigma_r = math.sqrt(var_r)\n        z = (runs - mu_r) / sigma_r\n        \n        # Standard normal CDF from erf\n        phi_abs_z = 0.5 * (1.0 + math.erf(abs(z) / math.sqrt(2.0)))\n        p_value = 2 * (1.0 - phi_abs_z)\n        \n        return p_value\n\n    def comparison_function(item1, item2):\n        \"\"\"Custom comparison function for sorting according to tie-breaking rules.\"\"\"\n        s1, r2_1, code1 = item1\n        s2, r2_2, code2 = item2\n\n        # 1. Primary sort key: Composite Score S (descending)\n        if abs(s1 - s2) > EPSILON:\n            return -1 if s1 > s2 else 1\n        \n        # 2. First tie-breaker: R^2 (descending)\n        if r2_1 != r2_2:\n            return -1 if r2_1 > r2_2 else 1\n            \n        # 3. Second tie-breaker: Transformation Code (ascending)\n        return code1 - code2\n\n    results = []\n    for dataset in test_cases:\n        transform_evals = []\n        for code in range(6):\n            u, v = apply_transformation(dataset, code)\n            \n            if u is None:\n                continue\n            \n            # Sort by u for consistent residual ordering\n            sorted_indices = np.argsort(u)\n            u_sorted, v_sorted = u[sorted_indices], v[sorted_indices]\n\n            a, b, r2 = perform_ols(u_sorted, v_sorted)\n            if not np.isfinite(a) or not np.isfinite(b):\n                continue\n            \n            residuals = v_sorted - (a + b * u_sorted)\n            p_value = wald_wolfowitz_test(residuals)\n            \n            s_rand = 1.0 - 2.0 * abs(p_value - 0.5)\n            s_rand = max(0.0, min(1.0, s_rand))  # Clip to [0, 1]\n            \n            s_composite = W_R * r2 + W_P * s_rand\n            \n            transform_evals.append((s_composite, r2, code))\n\n        # Sort transformations using the custom comparison logic\n        sorted_evals = sorted(transform_evals, key=cmp_to_key(comparison_function))\n        best_code = sorted_evals[0][2]\n        results.append(best_code)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3221527"}]}