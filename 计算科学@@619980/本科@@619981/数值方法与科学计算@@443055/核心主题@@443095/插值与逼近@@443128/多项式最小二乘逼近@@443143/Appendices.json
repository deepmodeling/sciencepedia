{"hands_on_practices": [{"introduction": "任何最小二乘法的核心都是一个优化问题：找到最小化误差平方和的模型参数。本练习将引导你从第一性原理出发，通过微积分推导著名的“正规方程组”，从而为一个简单的二次多项式模型求解。通过处理包含重复测量值的真实世界数据特征[@problem_id:3262996]，你将为后续更复杂的应用打下坚实的理论基础。", "problem": "一个实验室正在校准一个传感器，其输出由一个二次多项式建模。在输入值 $x \\in \\{0,1,1,2\\}$ 处进行了四次独立测量，按相同顺序产生的输出为 $y \\in \\{10,8,6,3\\}$。重复的输入 $x=1$ 是为了减少不确定性而进行的有意重复实验；两次重复观测都必须视为对拟合准则的独立贡献。模型是一个二次多项式 $p(x) = a x^{2} + b x + c$。最小二乘法意义下的最佳近似定义为选择系数 $a$、$b$ 和 $c$，使得给定数据点的残差平方和 $\\sum (p(x_{i}) - y_{i})^{2}$ 最小。\n\n仅从最小二乘最小化的基本定义和标准线性代数知识出发，通过将目标函数对系数的梯度设为零来推导最优性的必要条件，并仔细考虑在 $x=1$ 处有两次不同输出的测量。然后精确求解所得方程组，以确定最佳拟合二次多项式的首项系数 $a$。\n\n将您的最终答案表示为一个精确的数字；不要四舍五入。", "solution": "首先根据指定标准对问题进行验证。\n\n### 步骤 1：提取已知条件\n-   输入值：$x \\in \\{0,1,1,2\\}$。\n-   输出值：$y \\in \\{10,8,6,3\\}$，与输入值一一对应。\n-   数据点 $(x_i, y_i)$：$(0, 10)$、$(1, 8)$、$(1, 6)$、$(2, 3)$。测量总数为 $n=4$。\n-   模型：二次多项式 $p(x) = a x^{2} + b x + c$。\n-   目标：最小化残差平方和 $S = \\sum_{i=1}^{4} (p(x_{i}) - y_{i})^{2}$，以求得最佳拟合系数 $a$、$b$ 和 $c$。\n-   任务：从第一性原理出发，通过将 $S$ 的梯度设为零来推导最小值的必要条件，然后求解系数 $a$。\n\n### 步骤 2：使用提取的已知条件进行验证\n-   **科学依据：** 该问题描述了一个标准的多项式最小二乘拟合过程，这是数值方法、统计学和数据分析中一种基础且广泛使用的技术。它基于公认的数学原理。\n-   **适定性：** 问题提供了四个数据点来确定三个未知系数（$a, b, c$）。该系统是超定的，这是最小二乘拟合的标准情况。当且仅当设计矩阵的列线性无关时，存在唯一解。此问题的设计矩阵 $A$ 由下式给出\n    $$A = \\begin{pmatrix} x_1^2  x_1  1 \\\\ x_2^2  x_2  1 \\\\ x_3^2  x_3  1 \\\\ x_4^2  x_4  1 \\end{pmatrix} = \\begin{pmatrix} 0^2  0  1 \\\\ 1^2  1  1 \\\\ 1^2  1  1 \\\\ 2^2  2  1 \\end{pmatrix} = \\begin{pmatrix} 0  0  1 \\\\ 1  1  1 \\\\ 1  1  1 \\\\ 4  2  1 \\end{pmatrix}$$\n    这些列是线性无关的，可以通过将线性组合设为零来证明：$\\alpha_1 [0,1,1,4]^T + \\alpha_2 [0,1,1,2]^T + \\alpha_3 [1,1,1,1]^T = [0,0,0,0]^T$。第一行意味着 $\\alpha_3=0$。这使方程组简化为 $\\alpha_1+\\alpha_2=0$ 和 $4\\alpha_1+2\\alpha_2=0$，解得 $\\alpha_1=\\alpha_2=0$。因此，这些列是线性无关的，矩阵 $A^T A$ 是可逆的，存在唯一解。问题是适定的。\n-   **目标明确性：** 问题陈述清晰、精确，并使用了标准术语。将重复测量视为独立贡献的指令是明确的。\n\n### 步骤 3：结论与行动\n问题有效。它具有科学合理性、适定性且目标明确。我将继续进行求解。\n\n### 推导与求解\n\n传感器输出的模型是二次多项式 $p(x) = a x^{2} + b x + c$。数据点为 $(x_1, y_1) = (0, 10)$、$(x_2, y_2) = (1, 8)$、$(x_3, y_3) = (1, 6)$ 和 $(x_4, y_4) = (2, 3)$。\n\n目标是找到系数 $a$、$b$ 和 $c$ 以最小化残差平方和 $S(a, b, c)$。函数 $S$ 定义为：\n$$S(a, b, c) = \\sum_{i=1}^{4} (p(x_i) - y_i)^2$$\n代入给定的数据和多项式模型：\n$$S(a, b, c) = (a(0)^2 + b(0) + c - 10)^2 + (a(1)^2 + b(1) + c - 8)^2 + (a(1)^2 + b(1) + c - 6)^2 + (a(2)^2 + b(2) + c - 3)^2$$\n$$S(a, b, c) = (c - 10)^2 + (a + b + c - 8)^2 + (a + b + c - 6)^2 + (4a + 2b + c - 3)^2$$\n\n为了最小化 $S(a,b,c)$，我们必须找到其关于系数的梯度为零向量的点。这给出了最优性的必要条件：\n$$\\frac{\\partial S}{\\partial a} = 0, \\quad \\frac{\\partial S}{\\partial b} = 0, \\quad \\frac{\\partial S}{\\partial c} = 0$$\n\n我们使用链式法则计算每个偏导数：\n\n1.  关于 $a$ 的偏导数：\n    $$\\frac{\\partial S}{\\partial a} = 0 + 2(a + b + c - 8)(1) + 2(a + b + c - 6)(1) + 2(4a + 2b + c - 3)(4) = 0$$\n    等式两边除以 $2$：\n    $$(a + b + c - 8) + (a + b + c - 6) + 4(4a + 2b + c - 3) = 0$$\n    $$(1+1+16)a + (1+1+8)b + (1+1+4)c = 8 + 6 + 12$$\n    $$18a + 10b + 6c = 26$$\n    $$9a + 5b + 3c = 13 \\quad (1)$$\n\n2.  关于 $b$ 的偏导数：\n    $$\\frac{\\partial S}{\\partial b} = 0 + 2(a + b + c - 8)(1) + 2(a + b + c - 6)(1) + 2(4a + 2b + c - 3)(2) = 0$$\n    等式两边除以 $2$：\n    $$(a + b + c - 8) + (a + b + c - 6) + 2(4a + 2b + c - 3) = 0$$\n    $$(1+1+8)a + (1+1+4)b + (1+1+2)c = 8 + 6 + 6$$\n    $$10a + 6b + 4c = 20$$\n    $$5a + 3b + 2c = 10 \\quad (2)$$\n\n3.  关于 $c$ 的偏导数：\n    $$\\frac{\\partial S}{\\partial c} = 2(c - 10)(1) + 2(a + b + c - 8)(1) + 2(a + b + c - 6)(1) + 2(4a + 2b + c - 3)(1) = 0$$\n    等式两边除以 $2$：\n    $$(c - 10) + (a + b + c - 8) + (a + b + c - 6) + (4a + 2b + c - 3) = 0$$\n    $$(1+1+4)a + (1+1+2)b + (1+1+1+1)c = 10 + 8 + 6 + 3$$\n    $$6a + 4b + 4c = 27 \\quad (3)$$\n\n我们现在得到了一个关于三个未知系数 $a$、$b$ 和 $c$ 的三元线性方程组，称为正规方程组：\n1.  $9a + 5b + 3c = 13$\n2.  $5a + 3b + 2c = 10$\n3.  $6a + 4b + 4c = 27$\n\n问题要求解出首项系数 $a$。我们可以使用消元法来解这个方程组。我们先消去 $c$。\n将方程 (2) 乘以 $3$，方程 (1) 乘以 $2$：\n$$2 \\times (1): \\quad 18a + 10b + 6c = 26$$\n$$3 \\times (2): \\quad 15a + 9b + 6c = 30$$\n用第一个新方程减去第二个新方程：\n$$(18a - 15a) + (10b - 9b) + (6c - 6c) = 26 - 30$$\n$$3a + b = -4 \\quad (4)$$\n\n接下来，使用方程 (2) 和 (3) 消去 $c$。将方程 (2) 乘以 $2$：\n$$2 \\times (2): \\quad 10a + 6b + 4c = 20$$\n$$(3): \\quad 6a + 4b + 4c = 27$$\n从方程 (3) 中减去新得到的方程：\n$$(6a - 10a) + (4b - 6b) + (4c - 4c) = 27 - 20$$\n$$-4a - 2b = 7 \\quad (5)$$\n\n现在我们得到一个关于 $a$ 和 $b$ 的二元一次方程组：\n4.  $3a + b = -4$\n5.  $-4a - 2b = 7$\n\n从方程 (4) 中，我们可以用 $a$ 表示 $b$：\n$$b = -4 - 3a$$\n将这个关于 $b$ 的表达式代入方程 (5)：\n$$-4a - 2(-4 - 3a) = 7$$\n$$-4a + 8 + 6a = 7$$\n$$2a = 7 - 8$$\n$$2a = -1$$\n$$a = -\\frac{1}{2}$$\n\n最佳拟合二次多项式的首项系数恰好是 $-\\frac{1}{2}$。", "answer": "$$\\boxed{-\\frac{1}{2}}$$", "id": "3262996"}, {"introduction": "在掌握了基本原理之后，我们来探讨一个更贴近现实的场景：当数据点的可靠性不同时该怎么办？本练习将介绍加权最小二乘法，这是一种为更精确的测量值赋予更高权重的强大技术。你将推导加权问题的修正正规方程组[@problem_id:3262884]，体会如何扩展基本理论来构建更精细、更准确的模型。", "problem": "一个实验室在输入 $x_{1}=-1$，$x_{2}=0$ 和 $x_{3}=1$ 处收集了某个潜在线性响应的 $3$ 个标量测量值。报告的测量值为 $y_{1}=0$，$y_{2}=1$ 和 $y_{3}=2$。测量误差是独立的、零均值的，并且具有已知的标准差 $\\sigma_{1}=1$，$\\sigma_{2}=\\tfrac{1}{2}$ 和 $\\sigma_{3}=1$。您需要寻找一个线性多项式 $p(x)=c_{0}+c_{1}x$ 的多项式最小二乘近似，该近似通过为更可靠的数据分配更高的权重来考虑测量值的不同可靠性。使用对角矩阵 $W=\\mathrm{diag}\\!\\big(\\tfrac{1}{\\sigma_{1}},\\tfrac{1}{\\sigma_{2}},\\tfrac{1}{\\sigma_{3}}\\big)$ 将目标定义为加权残差的欧几里得二范数 (L2) 的平方，即最小化 $\\|W(Ac-y)\\|_{2}^{2}$，其中 $A$ 是设计矩阵，$c=\\begin{pmatrix}c_{0}\\\\c_{1}\\end{pmatrix}$，$y=\\begin{pmatrix}y_{1}\\\\y_{2}\\\\y_{3}\\end{pmatrix}$。\n\n任务：\n1) 写出与此问题相关的显式矩阵和向量 $A$、$W$ 和 $y$。\n2) 从将可微标量目标函数关于 $c$ 的梯度设为零以求最小化的基本原理出发，推导出表征最小化子的线性系统。\n3) 求解 $c_{0}$ 和 $c_{1}$，然后计算拟合多项式在 $x=2$ 处的值。\n\n提供 $p(2)$ 的唯一最终值，结果为精确数。不要四舍五入。", "solution": "该问题是适定的且有科学依据，代表了数值分析中加权最小二乘法的标准应用。唯一解所需的所有数据和条件都已提供且自洽。\n\n### 步骤 1：问题验证\n\n**逐字提取的已知条件：**\n*   测量次数：$3$。\n*   输入：$x_{1}=-1$，$x_{2}=0$，$x_{3}=1$。\n*   测量值：$y_{1}=0$，$y_{2}=1$，$y_{3}=2$。\n*   标准差：$\\sigma_{1}=1$，$\\sigma_{2}=\\tfrac{1}{2}$，$\\sigma_{3}=1$。\n*   模型：线性多项式 $p(x)=c_{0}+c_{1}x$。\n*   权重矩阵：$W=\\mathrm{diag}\\!\\big(\\tfrac{1}{\\sigma_{1}},\\tfrac{1}{\\sigma_{2}},\\tfrac{1}{\\sigma_{3}}\\big)$。\n*   目标函数：最小化 $\\|W(Ac-y)\\|_{2}^{2}$。\n*   参数向量：$c=\\begin{pmatrix}c_{0}\\\\c_{1}\\end{pmatrix}$。\n*   测量向量：$y=\\begin{pmatrix}y_{1}\\\\y_{2}\\\\y_{3}\\end{pmatrix}$。\n\n**验证分析：**\n该问题是一个定义明确的加权线性回归数学练习。它在科学上是合理的，因为加权最小二乘法是拟合具有非均匀方差数据的基本统计技术。该问题是自包含的，提供了所有必要的数值和函数形式。输入 $x_i$ 导出的设计矩阵 $A$ 具有线性无关的列，确保了得到的正规方程组有唯一解，因此问题是适定的。术语精确客观。此问题有效。\n\n### 步骤 2：求解推导\n\n问题要求找到线性多项式 $p(x) = c_0 + c_1x$ 的系数 $c_0$ 和 $c_1$，以最小化加权残差向量的欧几里得范数的平方。\n\n#### 任务 1：显式矩阵和向量\n\n首先，我们根据给定数据构造矩阵和向量 $A$、$W$ 和 $y$。\n\n方程组为 $p(x_i) \\approx y_i$，$i=1, 2, 3$：\n$$\n\\begin{cases}\nc_0 + c_1(-1) \\approx 0 \\\\\nc_0 + c_1(0) \\approx 1 \\\\\nc_0 + c_1(1) \\approx 2\n\\end{cases}\n$$\n这可以写成矩阵形式 $Ac \\approx y$。设计矩阵 $A$ 是通过在每个输入 $x_i$ 处计算基函数（$1$ 和 $x$）的值形成的：\n$$\nA = \\begin{pmatrix} 1  -1 \\\\ 1  0 \\\\ 1  1 \\end{pmatrix}\n$$\n测量向量 $y$ 是：\n$$\ny = \\begin{pmatrix} y_1 \\\\ y_2 \\\\ y_3 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 1 \\\\ 2 \\end{pmatrix}\n$$\n权重矩阵 $W$ 由 $W=\\mathrm{diag}\\!\\big(\\tfrac{1}{\\sigma_{1}},\\tfrac{1}{\\sigma_{2}},\\tfrac{1}{\\sigma_{3}}\\big)$ 给出。已知 $\\sigma_{1}=1$，$\\sigma_{2}=\\tfrac{1}{2}$ 和 $\\sigma_{3}=1$，我们有：\n$$\nW = \\mathrm{diag}\\!\\big(\\tfrac{1}{1},\\tfrac{1}{1/2},\\tfrac{1}{1}\\big) = \\mathrm{diag}(1, 2, 1) = \\begin{pmatrix} 1  0  0 \\\\ 0  2  0 \\\\ 0  0  1 \\end{pmatrix}\n$$\n\n#### 任务 2：线性系统的推导\n\n目标是最小化标量函数 $J(c) = \\|W(Ac-y)\\|_{2}^{2}$。\n使用欧几里得范数的定义（$ \\|v\\|_2^2 = v^T v $），我们可以将目标函数写为：\n$$\nJ(c) = \\big(W(Ac-y)\\big)^T \\big(W(Ac-y)\\big)\n$$\n使用转置性质 $(XY)^T = Y^T X^T$：\n$$\nJ(c) = (Ac-y)^T W^T W (Ac-y)\n$$\n为了找到最小值，我们计算 $J(c)$ 关于 $c$ 的梯度并将其设为零。让我们展开 $J(c)$ 的表达式：\n$$\nJ(c) = (c^T A^T - y^T) W^T W (Ac - y)\n$$\n$$\nJ(c) = c^T A^T W^T W A c - c^T A^T W^T W y - y^T W^T W A c + y^T W^T W y\n$$\n项 $c^T A^T W^T W y$ 和 $y^T W^T W A c$ 是标量，并且互为转置。因此，它们相等。\n$$\nJ(c) = c^T (A^T W^T W A) c - 2 c^T (A^T W^T W y) + y^T W^T W y\n$$\n关于向量 $c$ 的梯度是：\n$$\n\\nabla_c J(c) = \\nabla_c \\Big( c^T (A^T W^T W A) c - 2 c^T (A^T W^T W y) + y^T W^T W y \\Big)\n$$\n使用矩阵微积分恒等式，对于对称矩阵 $M$ 有 $\\nabla_c(c^T M c) = 2Mc$，以及 $\\nabla_c(c^T b) = b$：\n$$\n\\nabla_c J(c) = 2(A^T W^T W A) c - 2(A^T W^T W y)\n$$\n将梯度设为零，$\\nabla_c J(c) = 0$：\n$$\n2(A^T W^T W A) c - 2(A^T W^T W y) = 0\n$$\n$$\n(A^T W^T W A) c = A^T W^T W y\n$$\n这就是表征最小化子 $c$ 的线性系统，称为加权最小二乘问题的正规方程组。\n\n#### 任务 3：求解 $c_0$、$c_1$ 并计算 $p(2)$\n\n我们现在求解系统 $(A^T W^T W A) c = A^T W^T W y$。\n由于 $W$ 是实对角矩阵，所以 $W^T = W$。系统变为 $(A^T W^2 A) c = A^T W^2 y$。\n首先，我们计算矩阵 $W^2$：\n$$\nW^2 = W^T W = \\begin{pmatrix} 1  0  0 \\\\ 0  2  0 \\\\ 0  0  1 \\end{pmatrix} \\begin{pmatrix} 1  0  0 \\\\ 0  2  0 \\\\ 0  0  1 \\end{pmatrix} = \\begin{pmatrix} 1  0  0 \\\\ 0  4  0 \\\\ 0  0  1 \\end{pmatrix}\n$$\n该矩阵的对角线上包含逆方差 $1/\\sigma_i^2$，这与标准加权最小二乘法的预期一致。\n\n接下来，我们计算左侧的矩阵 $A^T W^2 A$：\n$$\nA^T W^2 A = \\begin{pmatrix} 1  1  1 \\\\ -1  0  1 \\end{pmatrix} \\begin{pmatrix} 1  0  0 \\\\ 0  4  0 \\\\ 0  0  1 \\end{pmatrix} \\begin{pmatrix} 1  -1 \\\\ 1  0 \\\\ 1  1 \\end{pmatrix}\n$$\n$$\nA^T W^2 A = \\begin{pmatrix} 1  1  1 \\\\ -1  0  1 \\end{pmatrix} \\begin{pmatrix} 1  -1 \\\\ 4  0 \\\\ 1  1 \\end{pmatrix}\n$$\n$$\nA^T W^2 A = \\begin{pmatrix} (1)(1)+(1)(4)+(1)(1)  (1)(-1)+(1)(0)+(1)(1) \\\\ (-1)(1)+(0)(4)+(1)(1)  (-1)(-1)+(0)(0)+(1)(1) \\end{pmatrix} = \\begin{pmatrix} 6  0 \\\\ 0  2 \\end{pmatrix}\n$$\n现在，我们计算右侧的向量 $A^T W^2 y$：\n$$\nA^T W^2 y = \\begin{pmatrix} 1  1  1 \\\\ -1  0  1 \\end{pmatrix} \\begin{pmatrix} 1  0  0 \\\\ 0  4  0 \\\\ 0  0  1 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\\\ 2 \\end{pmatrix}\n$$\n$$\nA^T W^2 y = \\begin{pmatrix} 1  1  1 \\\\ -1  0  1 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 4 \\\\ 2 \\end{pmatrix}\n$$\n$$\nA^T W^2 y = \\begin{pmatrix} (1)(0)+(1)(4)+(1)(2) \\\\ (-1)(0)+(0)(4)+(1)(2) \\end{pmatrix} = \\begin{pmatrix} 6 \\\\ 2 \\end{pmatrix}\n$$\n求解 $c = \\begin{pmatrix} c_0 \\\\ c_1 \\end{pmatrix}$ 的线性系统是：\n$$\n\\begin{pmatrix} 6  0 \\\\ 0  2 \\end{pmatrix} \\begin{pmatrix} c_0 \\\\ c_1 \\end{pmatrix} = \\begin{pmatrix} 6 \\\\ 2 \\end{pmatrix}\n$$\n这个对角系统直接给出解：\n$$\n6c_0 = 6 \\implies c_0 = 1\n$$\n$$\n2c_1 = 2 \\implies c_1 = 1\n$$\n拟合的多项式是 $p(x) = c_0 + c_1 x = 1 + x$。\n\n最后，我们计算该多项式在 $x=2$ 处的值：\n$$\np(2) = 1 + 2 = 3\n$$\n数据点 $(-1, 0)$、$(0, 1)$ 和 $(1, 2)$ 是共线的，并且完美地落在直线 $y=x+1$ 上。因此，无论权重如何，最小二乘拟合都会得到这条精确的直线，从而导致残差误差为零。我们推导出的系数 $c_0=1$ 和 $c_1=1$ 与这一观察结果一致。", "answer": "$$\\boxed{3}$$", "id": "3262884"}, {"introduction": "掌握了标准和加权拟合的工具后，理解其局限性就变得至关重要。这个计算练习是一个极具警示意义的案例。你将通过编程发现，一个高次多项式即使能完美拟合一组数据点，在预测原始数据范围之外的数值时也可能遭遇灾难性的失败[@problem_id:3262865]。这个实践突显了内插与外推之间的本质区别，并告诫我们必须审慎评估模型的泛化能力。", "problem": "您将实现并分析一个对无噪声采样的周期性目标函数的多项式最小二乘逼近。目标是通过计算证明，多项式拟合在训练区间上可以非常精确，但在该区间外进行外插时会灾难性地失败，从而无法捕捉函数的周期性。\n\n您的推导和算法必须基于最小二乘逼近的核心原理。使用以下经过充分检验的事实和定义作为基础出发点：\n- 离散最小二乘逼近旨在从一个有限维空间中寻找一个函数，该函数在给定的样本点上最小化残差平方和。\n- 对于多项式模型，最小二乘问题可以使用范德蒙矩阵（Vandermonde matrix）写成矩阵形式，该矩阵编码了单项式基在样本点上的求值。\n- 一组点上的均方根误差 (RMSE) 是残差平方的平均值的平方根。\n\n任务：\n- 考虑目标函数 $f(x)=\\sin(x)$，其中 $x$ 的单位是弧度。\n- 对于每个测试用例，通过在区间 $[x_{\\min},x_{\\max}]$ 上均匀采样 $N_{\\text{train}}$ 个点来生成训练数据集。使用 $y_i=f(x_i)$，不加噪声。\n- 在离散最小二乘意义下，将一个 $d$ 次多项式 $p_d(x)$ 拟合到此数据，使用数值稳定的方法求解由范德蒙矩阵定义的线性最小二乘问题。如果您的环境中有更稳定的方法，请不要直接使用正规方程。\n- 计算训练点上的样本内均方根误差，记为 $\\text{RMSE}_{\\text{train}}=\\sqrt{\\frac{1}{N_{\\text{train}}}\\sum_{i=1}^{N_{\\text{train}}}\\left(p_d(x_i)-f(x_i)\\right)^2}$。\n- 为评估外插行为，定义一个测试区间 $[u_{\\min},u_{\\max}]$，在其上均匀生成 $N_{\\text{test}}$ 个点（选择 $N_{\\text{test}}=200$），并类似地计算样本外均方根误差 $\\text{RMSE}_{\\text{test}}$。\n- 使用以下决策规则来确定多项式拟合是否同时满足样本内精确且样本外灾难性失败的条件：\n  - 定义阈值 $\\varepsilon_{\\text{in}}=10^{-2}$ 和 $\\varepsilon_{\\text{out}}=5\\times 10^{-1}$。\n  - 如果 $\\text{RMSE}_{\\text{train}}\\le \\varepsilon_{\\text{in}}$ 且 $\\text{RMSE}_{\\text{test}}\\ge \\varepsilon_{\\text{out}}$，则输出整数 $1$；否则输出整数 $0$。\n\n角度单位：所有三角函数求值必须使用弧度。\n\n测试套件：\n- 用例 $1$：$d=9$， $N_{\\text{train}}=64$， $[x_{\\min},x_{\\max}]=[0,2\\pi]$， $[u_{\\min},u_{\\max}]=[10\\pi,12\\pi]$。\n- 用例 $2$：$d=15$， $N_{\\text{train}}=100$， $[x_{\\min},x_{\\max}]=[0,2\\pi]$， $[u_{\\min},u_{\\max}]=[8\\pi,10\\pi]$。\n- 用例 $3$：$d=20$， $N_{\\text{train}}=120$， $[x_{\\min},x_{\\max}]=[0,2\\pi]$， $[u_{\\min},u_{\\max}]=[-12\\pi,-10\\pi]$。\n- 用例 $4$（用于测试当样本内拟合不够精确时决策规则的边界情况）：$d=1$， $N_{\\text{train}}=64$， $[x_{\\min},x_{\\max}]=[0,2\\pi]$， $[u_{\\min},u_{\\max}]=[8\\pi,10\\pi]$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含按测试用例顺序排列的结果，形式为方括号括起来的逗号分隔列表。例如，输出形式应为 $[r_1,r_2,r_3,r_4]$，其中每个 $r_k$ 是按上文定义的 $0$ 或 $1$。", "solution": "该问题要求实现并分析对周期函数 $f(x) = \\sin(x)$ 的多项式最小二乘逼近。核心目标是证明多项式模型虽然能够在指定的训练区间上实现高精度拟合，但由于其非周期性，从根本上不适合外插。当模型在远离训练数据域的范围进行评估时，这会导致灾难性的失败。\n\n该过程包括将一个 $d$ 次多项式拟合到区间 $[x_{\\min}, x_{\\max}]$ 上的一组 $N_{\\text{train}}$ 个 $f(x)$ 的无噪声样本。拟合的质量通过训练数据（样本内）和一个独立的、不重叠的测试区间 $[u_{\\min}, u_{\\max}]$（样本外）进行评估。然后应用一个决策规则来分类拟合是否同时满足样本内良好和样本外差的条件。\n\n设 $d$ 次多项式模型表示为 $p_d(x)$：\n$$\np_d(x) = \\sum_{j=0}^{d} c_j x^j = c_0 + c_1 x + c_2 x^2 + \\dots + c_d x^d\n$$\n任务是确定系数向量 $\\mathbf{c} = [c_0, c_1, \\dots, c_d]^T$，使其在最小二乘意义下最佳拟合训练数据。训练数据由 $N_{\\text{train}}$ 个点对 $(x_i, y_i)$ 组成，其中点 $x_i$ 从 $[x_{\\min}, x_{\\max}]$ 中均匀采样，且 $y_i = f(x_i) = \\sin(x_i)$。\n\n离散最小二乘问题是找到最小化残差平方和 $S$ 的系数向量 $\\mathbf{c}$：\n$$\nS = \\sum_{i=1}^{N_{\\text{train}}} (p_d(x_i) - y_i)^2\n$$\n这可以表述为一个线性代数问题。设 $\\mathbf{y} = [y_1, y_2, \\dots, y_{N_{\\text{train}}}]^T$ 是观测函数值的向量。对于 $i=1, \\dots, N_{\\text{train}}$ 的方程组 $p_d(x_i) = y_i$ 构成一个超定线性系统 $A\\mathbf{c} \\approx \\mathbf{y}$，其中 $A$ 是 $N_{\\text{train}} \\times (d+1)$ 的范德蒙矩阵（Vandermonde matrix）：\n$$\nA =\n\\begin{pmatrix}\n1  x_1  x_1^2  \\dots  x_1^d \\\\\n1  x_2  x_2^2  \\dots  x_2^d \\\\\n\\vdots  \\vdots  \\vdots  \\ddots  \\vdots \\\\\n1  x_{N_{\\text{train}}}  x_{N_{\\text{train}}}^2  \\dots  x_{N_{\\text{train}}}^d\n\\end{pmatrix}\n$$\n那么，最小二乘问题就等价于找到一个向量 $\\mathbf{c}$，以最小化残差向量的欧几里得范数 $\\|\\mathbf{y} - A\\mathbf{c}\\|_2$。\n\n尽管这个最小化问题可以形式上通过正规方程 $A^TA\\mathbf{c} = A^T\\mathbf{y}$ 求解，但这种方法在数值上是不稳定的。矩阵 $A^TA$ 的条件数是 $A$ 的条件数的平方，而范德蒙矩阵是出了名的病态矩阵，尤其是在高阶 $d$ 的情况下。一种数值上更优的方法是使用矩阵分解，例如对 $A$ 进行奇异值分解（SVD），本题将采用此方法。现代数值库提供了基于这类方法的鲁棒线性最小二乘解算器。我们将为此使用 `numpy.linalg.lstsq`。\n\n每个测试用例的算法流程如下：\n1.  在 $[x_{\\min}, x_{\\max}]$ 上均匀生成 $N_{\\text{train}}$ 个训练点 $x_i$，并计算相应的目标值 $y_i = \\sin(x_i)$。\n2.  构建 $N_{\\text{train}} \\times (d+1)$ 的范德蒙矩阵 $A$，其中 $A_{ij} = x_i^j$，对于 $i=1, \\dots, N_{\\text{train}}$ 和 $j=0, \\dots, d$。\n3.  求解线性最小二乘系统 $A\\mathbf{c} \\approx \\mathbf{y}$，得到系数向量 $\\mathbf{c}$。\n4.  计算样本内均方根误差 ($\\text{RMSE}_{\\text{train}}$)。训练集上的预测值为 $\\hat{y}_i = p_d(x_i)$。\n    $$\n    \\text{RMSE}_{\\text{train}} = \\sqrt{\\frac{1}{N_{\\text{train}}}\\sum_{i=1}^{N_{\\text{train}}} (\\hat{y}_i - y_i)^2}\n    $$\n5.  在外插区间 $[u_{\\min}, u_{\\max}]$ 上均匀生成 $N_{\\text{test}} = 200$ 个测试点 $u_k$，并计算真实函数值 $v_k = \\sin(u_k)$。\n6.  在测试点上评估多项式 $p_d(x)$，得到预测值 $\\hat{v}_k = p_d(u_k)$。\n7.  计算样本外均方根误差 ($\\text{RMSE}_{\\text{test}}$)：\n    $$\n    \\text{RMSE}_{\\text{test}} = \\sqrt{\\frac{1}{N_{\\text{test}}}\\sum_{k=1}^{N_{\\text{test}}} (\\hat{v}_k - v_k)^2}\n    $$\n8.  应用决策规则：如果 $\\text{RMSE}_{\\text{train}} \\le \\varepsilon_{\\text{in}}$ 且 $\\text{RMSE}_{\\text{test}} \\ge \\varepsilon_{\\text{out}}$，其中 $\\varepsilon_{\\text{in}} = 10^{-2}$ 且 $\\varepsilon_{\\text{out}} = 5 \\times 10^{-1}$，则该测试用例的结果为 $1$。否则，结果为 $0$。\n\n将此流程系统地应用于所有指定的测试用例以确定最终输出。高次多项式模型预计能很好地拟合正弦波的单个周期，但由于多项式是非周期性的，并且当 $|x| \\to \\infty$ 时会无界增长，它们将在远离原点的区间上与周期性的正弦函数产生巨大偏差，从而导致较大的 $\\text{RMSE}_{\\text{test}}$。低次线性模型（用例 4）不够灵活，无法捕捉正弦函数的曲率，导致样本内拟合效果差，从而不满足决策规则的第一个条件。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and analyzes polynomial least squares approximation to demonstrate\n    the failure of extrapolation for non-periodic models of periodic functions.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: d=9, N_train=64, [x_min,x_max]=[0,2pi], [u_min,u_max]=[10pi,12pi]\n        {'d': 9, 'N_train': 64, 'x_range': [0, 2 * np.pi], 'u_range': [10 * np.pi, 12 * np.pi]},\n        # Case 2: d=15, N_train=100, [x_min,x_max]=[0,2pi], [u_min,u_max]=[8pi,10pi]\n        {'d': 15, 'N_train': 100, 'x_range': [0, 2 * np.pi], 'u_range': [8 * np.pi, 10 * np.pi]},\n        # Case 3: d=20, N_train=120, [x_min,x_max]=[0,2pi], [u_min,u_max]=[-12pi,-10pi]\n        {'d': 20, 'N_train': 120, 'x_range': [0, 2 * np.pi], 'u_range': [-12 * np.pi, -10 * np.pi]},\n        # Case 4: d=1, N_train=64, [x_min,x_max]=[0,2pi], [u_min,u_max]=[8pi,10pi]\n        {'d': 1, 'N_train': 64, 'x_range': [0, 2 * np.pi], 'u_range': [8 * np.pi, 10 * np.pi]},\n    ]\n\n    # Constants defined in the problem\n    N_test = 200\n    eps_in = 1e-2\n    eps_out = 0.5\n    \n    results = []\n\n    for case in test_cases:\n        d = case['d']\n        N_train = case['N_train']\n        x_min, x_max = case['x_range']\n        u_min, u_max = case['u_range']\n\n        # 1. Generate training data\n        x_train = np.linspace(x_min, x_max, N_train)\n        y_train = np.sin(x_train)\n\n        # 2. Construct the Vandermonde matrix for the training data\n        # The polynomial is p(x) = c_0 + c_1*x + ... + c_d*x^d\n        # increasing=True makes columns 1, x, x^2, ...\n        A_train = np.vander(x_train, N=d + 1, increasing=True)\n        \n        # 3. Solve for the polynomial coefficients c = [c_0, c_1, ..., c_d]\n        # np.linalg.lstsq provides a numerically stable SVD-based solution.\n        coeffs, _, _, _ = np.linalg.lstsq(A_train, y_train, rcond=None)\n\n        # 4. Compute in-sample RMSE\n        # Evaluate polynomial on training points\n        y_pred_train = A_train @ coeffs\n        rmse_train = np.sqrt(np.mean((y_pred_train - y_train)**2))\n\n        # 5. Generate test data\n        x_test = np.linspace(u_min, u_max, N_test)\n        y_test_true = np.sin(x_test)\n\n        # 6. Compute out-of-sample RMSE\n        # Evaluate polynomial on test points.\n        # np.polyval expects coefficients for descending powers (c_d, c_{d-1}, ...),\n        # so we reverse the 'coeffs' array.\n        y_pred_test = np.polyval(coeffs[::-1], x_test)\n        rmse_test = np.sqrt(np.mean((y_pred_test - y_test_true)**2))\n        \n        # 7. Apply the decision rule\n        if rmse_train = eps_in and rmse_test >= eps_out:\n            results.append(1)\n        else:\n            results.append(0)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3262865"}]}