{"hands_on_practices": [{"introduction": "要真正理解局部截断误差，必须从其数学定义和推导入手。本练习将指导您使用泰勒展开，为经典的二阶求解器——休恩（Heun）方法——找出其误差的主导项。通过这种方式，您不仅能掌握局部截断误差的计算，还能深化对数值方法精度来源的理解 [@problem_id:2185092]。", "problem": "考虑一阶常微分方程 $y'(t) = \\cos(t) + y(t)^2$。Heun方法，也称为改进欧拉法，是一种用于近似求解的数值格式。它使用以下两步过程将解从点 $(t_n, y_n)$ 推进到 $(t_{n+1}, y_{n+1})$：\n\n1.  预测步：$y_{n+1}^* = y_n + h f(t_n, y_n)$\n2.  校正步：$y_{n+1} = y_n + \\frac{h}{2} [f(t_n, y_n) + f(t_{n+1}, y_{n+1}^*)]$\n\n这里，$h = t_{n+1} - t_n$ 是常数步长，且 $f(t,y) = y'(t)$。\n\n局部截断误差 $\\tau_{n+1}$ 定义为在步长起始点的值是精确的（即 $y_n = y(t_n)$）的假设下，$t_{n+1}$ 处的精确解值与单步数值近似解之间的差值。因此，局部截断误差由 $\\tau_{n+1} = y(t_{n+1}) - y_{n+1}$ 给出。\n\n对于给定的微分方程，确定局部截断误差 $\\tau_{n+1}$ 的首项。首项是指 $h$ 的最低次幂项中系数不为零的项。请用步长 $h$、精确解 $y(t)$ 及其导数 $y''(t)$ 和 $y'''(t)$ 来表示你的答案，所有这些量都在 $t=t_n$ 处取值。", "solution": "我们考虑常微分方程 $y'(t)=f(t,y)=\\cos(t)+y^{2}$ 和Heun方法\n$$\ny_{n+1}=y_{n}+\\frac{h}{2}\\bigl[f(t_{n},y_{n})+f(t_{n+1},y_{n}+h f(t_{n},y_{n}))\\bigr],\n$$\n对于局部截断误差，我们设 $y_{n}=y(t_{n})$。令 $t=t_{n}$，并记 $y=y(t)$、$y'=y'(t)$、$y''=y''(t)$、$y'''=y'''(t)$，所有这些量都在 $t=t_{n}$ 处取值。\n\n精确解满足泰勒展开\n$$\ny(t+h)=y+h y'+\\frac{h^{2}}{2}y''+\\frac{h^{3}}{6}y'''+\\mathcal{O}(h^{4}).\n$$\nHeun方法使用预测值 $y^{*}=y+h f(t,y)$。将 $f(t+h,y^{*})$ 在 $(t,y)$ 点展开到二阶，得到\n$$\nf(t+h,y^{*})=f+h f_{t}+h f_{y}f+\\frac{h^{2}}{2}f_{tt}+h^{2}f_{ty}f+\\frac{h^{2}}{2}f_{yy}f^{2}+\\mathcal{O}(h^{3}),\n$$\n因此单步数值解为\n$$\ny_{n+1}=y+h f+\\frac{h^{2}}{2}\\bigl(f_{t}+f_{y}f\\bigr)+\\frac{h^{3}}{4}\\bigl(f_{tt}+2 f_{ty}f+f_{yy}f^{2}\\bigr)+\\mathcal{O}(h^{4}).\n$$\n沿着精确解，有 $y'=f$，$y''=f_{t}+f_{y}f$，以及\n$$\ny'''=f_{tt}+2 f_{ty}f+f_{yy}f^{2}+f_{y}y''.\n$$\n因此，\n$$\nf_{tt}+2 f_{ty}f+f_{yy}f^{2}=y'''-f_{y}y'',\n$$\n局部截断误差变为\n$$\n\\tau_{n+1}=y(t+h)-y_{n+1}=h^{3}\\left(\\frac{1}{6}y'''-\\frac{1}{4}\\bigl(y'''-f_{y}y''\\bigr)\\right)+\\mathcal{O}(h^{4})\n=h^{3}\\left(-\\frac{1}{12}y'''+\\frac{1}{4}f_{y}y''\\right)+\\mathcal{O}(h^{4}).\n$$\n对于给定的 $f(t,y)=\\cos(t)+y^{2}$，我们有 $f_{y}=2y$。因此首项是\n$$\n\\tau_{n+1}=h^{3}\\left(-\\frac{1}{12}y'''(t_{n})+\\frac{1}{2}y(t_{n})\\,y''(t_{n})\\right)+\\mathcal{O}(h^{4}).\n$$\n所以，局部截断误差的首项是 $h^{3}\\left(-\\frac{1}{12}y'''(t_{n})+\\frac{1}{2}y(t_{n})y''(t_{n})\\right)$。", "answer": "$$\\boxed{h^{3}\\left(-\\frac{1}{12}\\,y'''(t_{n})+\\frac{1}{2}\\,y(t_{n})\\,y''(t_{n})\\right)}$$", "id": "2185092"}, {"introduction": "理论与实践之间如何架起桥梁？本练习将探讨局部截断误差（一个 $\\mathcal{O}(h^{p+1})$ 的局部性质）与可观测的全局误差（一个 $\\mathcal{O}(h^p)$ 的性质）之间的深刻联系。您将学习如何设计一个计算实验，来确定一个“黑箱”求解器的收敛阶，这是验证数值软件时一项至关重要的技能 [@problem_id:3248932]。", "problem": "考虑一个单步黑箱常微分方程（ODE）求解器，对于一个足够光滑的初值问题，其数值输出的终点全局误差被认为与步长之间表现出可预测的缩放关系。目标是通过测量不同步长下的全局误差并识别其缩放指数，来实验性地确定该求解器的阶 $p$。从以下基本概念出发：单步方法的局部截断误差的定义、相容性和零稳定性。然后设计一种方法，在不依赖于任何求解器内部知识的情况下，利用可观测的全局误差来推断阶 $p$。\n\n使用的定义和假设：\n- 将一个单步方法应用于常微分方程（ODE）的初值问题：$$\\frac{dy}{dt} = f(t,y), \\quad y(t_0) = y_0.$$\n- 局部截断误差是当提供精确数据时，方法在单步内产生的误差；对于一个 $p$ 阶方法，每步的局部截断误差的缩放关系如下：$$\\tau(h) = \\mathcal{O}(h^{p+1})$$ 对于足够小的步长 $h$。\n- 在相容性和零稳定性的标准假设下，固定终点时刻 $T$ 的全局误差的缩放关系如下：$$E(h) = \\mathcal{O}(h^{p}).$$\n\n任务：\n1. 基于上述基础，推导一种仅使用多个步长下的终点全局误差测量值来估计黑箱单步求解器阶 $p$ 的方法。你的推导必须解释如何使用一个与上述基础一致且数学上合理的模型，将测量数据转换为对 $p$ 的估计，并明确说明为使该估计有意义所需的假设。\n2. 将推导出的方法实现为一个完整、可运行的程序，该程序应：\n   - 选择具有已知解析解 $y(t)$ 的常微分方程，以计算固定终点时刻 $T$ 的全局误差。\n   - 对多个步长 $h$ 运行黑箱求解器，并测量绝对全局误差 $$E(h) = \\left|y_{\\text{num}}(T;h) - y_{\\text{exact}}(T)\\right|.$$\n   - 将误差与步长的数据拟合到幂律模型，并计算缩放指数作为估计的阶 $p$。\n3. 程序必须通过封装三种典型的单步方法来实现黑箱求解器接口，每种方法都作为黑箱处理：前向欧拉法、显式梯形法（Heun 法）和经典的四阶 Runge–Kutta 法。该实现除了将方法作为黑箱应用于常微分方程外，不应使用任何特定于方法的解析知识。\n4. 使用以下测试套件。对下面的每个测试用例，使用所述过程估计 $p$ 并报告一个浮点数。在所有情况下，均使用终点时刻的全局误差的绝对值。不涉及物理单位。\n   - 测试用例 1：求解器为前向欧拉法，应用于 $$\\frac{dy}{dt} = -y, \\quad y(0) = 1,$$ 解析解为 $$y(t) = e^{-t},$$ 终点时刻 $$T = 1,$$ 步长为 $$h \\in \\left\\{\\frac{1}{4}, \\frac{1}{8}, \\frac{1}{16}, \\frac{1}{32}\\right\\}.$$\n   - 测试用例 2：求解器为显式梯形法（Heun 法），应用于与上述相同的 ODE、初始条件和解析解，其中 $$T = 1$$ 且步长为 $$h \\in \\left\\{\\frac{1}{4}, \\frac{1}{8}, \\frac{1}{16}, \\frac{1}{32}\\right\\}.$$\n   - 测试用例 3：求解器为经典的四阶 Runge–Kutta 法，应用于与上述相同的 ODE、初始条件和解析解，其中 $$T = 1$$ 且步长为 $$h \\in \\left\\{\\frac{1}{10}, \\frac{1}{20}, \\frac{1}{40}, \\frac{1}{80}\\right\\}.$$\n   - 测试用例 4：求解器为经典的四阶 Runge–Kutta 法，应用于与上述相同的 ODE、初始条件和解析解，其中 $$T = 1$$ 且步长为 $$h \\in \\left\\{2^{-8}, 2^{-9}, 2^{-10}, 2^{-11}, 2^{-12}, 2^{-13}, 2^{-14}, 2^{-15}\\right\\}.$$ 此用例旨在探究在极小步长下潜在的舍入误差效应，以测试估计方法的鲁棒性。\n   - 测试用例 5：求解器为前向欧拉法，应用于 $$\\frac{dy}{dt} = y, \\quad y(0) = 1,$$ 解析解为 $$y(t) = e^{t},$$ 终点时刻 $$T = 1,$$ 步长为 $$h \\in \\left\\{\\frac{1}{2}, \\frac{1}{4}, \\frac{1}{8}\\right\\}.$$ 此用例旨在通过相对较粗的步长来探究远离渐近区域时的行为。\n5. 你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，例如 $$[p_1,p_2,p_3,p_4,p_5].$$ 每个 $p_i$ 必须是一个浮点数。\n\n程序必须是自包含的，无需输入，并且仅使用 Python 标准库和指定的数值库。估计过程必须通过在对数尺度上进行线性拟合来推断指数 $p$。", "solution": "该问题要求推导并实现一种方法，用以实验性地确定黑箱单步常微分方程（ODE）求解器的精度阶 $p$。这个过程被称为实验收敛阶（EOC）研究，是数值分析中的一种标准验证技术。\n\n该方法的基础在于收敛数值方法的全局误差与步长之间的关系。一个应用于初值问题\n$$ \\frac{dy}{dt} = f(t,y), \\quad y(t_0) = y_0 $$\n的单步方法，如果其局部截断误差（LTE）$\\tau(h)$ 的缩放级别为 $\\mathcal{O}(h^{p+1})$，则称该方法为 $p$ 阶。LTE 是假设从精确解开始，在单步内引入的误差。对于一个既是相容的（即 $p \\ge 1$）又是零稳定的（所有合理的单步方法，包括此处考虑的方法，都满足此条件）方法，其在固定终点时刻 $T$ 的全局误差 $E(h)$ 被证明与步长 $h$ 存在如下缩放关系：\n$$ E(h) = \\mathcal{O}(h^p) $$\n这个结果源于局部误差在约 $(T-t_0)/h$ 个步长上的累积。\n\n为了推导出一个估计 $p$ 的实用方法，我们将这种渐近关系形式化。对于足够小的步长 $h$，$\\mathcal{O}(h^p)$ 的行为意味着全局误差可以由其误差展开式的主项来近似：\n$$ E(h) \\approx C h^p $$\n其中 $C$ 是一个常数，它依赖于具体的 ODE、所用方法以及积分区间长度 $T-t_0$，但与步长 $h$ 无关。核心假设是所选的步长足够小，以至于处于该近似有效的*渐近区域*。\n\n我们的目标是从一组测量数据点 $(h_i, E_i)$ 中确定指数 $p$，其中 $E_i = E(h_i)$ 是在给定步长 $h_i$ 下观测到的全局误差。幂律关系 $E \\approx C h^p$ 可以通过对两边取自然对数来线性化：\n$$ \\ln(E(h)) \\approx \\ln(C h^p) $$\n利用对数的性质，这变为：\n$$ \\ln(E(h)) \\approx \\ln(C) + \\ln(h^p) = \\ln(C) + p \\ln(h) $$\n这个方程是线性方程 $Y = mX + b$ 的形式，其中：\n- 因变量是 $Y = \\ln(E(h))$。\n- 自变量是 $X = \\ln(h)$。\n- 直线的斜率是 $m = p$。\n- y 轴截距是 $b = \\ln(C)$。\n\n这一洞见构成了估计方法的基础。给定一组在相应步长序列 $\\{ h_1, h_2, \\dots, h_N \\}$ 下的 $N$ 个全局误差测量值 $\\{ E_1, E_2, \\dots, E_N \\}$，我们可以按如下方式估计 $p$：\n1.  对每个测量对 $(h_i, E_i)$，计算变换后的坐标 $x_i = \\ln(h_i)$ 和 $y_i = \\ln(E_i)$。\n2.  对变换后的点集 $\\{(x_i, y_i)\\}_{i=1}^N$ 进行线性回归，以找到最佳拟合线的斜率。一种标准的技术是最小二乘法。\n3.  这条线的斜率即为实验估计的收敛阶 $p$。\n\n对于数据点 $(x_i, y_i)$，最小二乘回归线的斜率 $p$ 由以下公式给出：\n$$ p = \\frac{N \\sum_{i=1}^{N}(x_i y_i) - \\left(\\sum_{i=1}^{N} x_i\\right) \\left(\\sum_{i=1}^{N} y_i\\right)}{N \\sum_{i=1}^{N}(x_i^2) - \\left(\\sum_{i=1}^{N} x_i\\right)^2} $$\n\n为使此方法得出有意义的 $p$ 估计值，必须满足两个关键假设：\n1.  **渐近区域**：步长 $h_i$ 必须足够小，以使近似式 $E(h) \\approx C h^p$ 成立。如果 $h$ 太大，误差展开式中的高阶项将不可忽略，对数-对数图将不是线性的。\n2.  **截断误差主导**：步长 $h_i$ 必须足够大，以使全局误差由截断误差主导，而不是由浮点舍入误差主导。当 $h \\to 0$ 时，截断误差消失，但舍入误差（会随着步数增加而累积）可能成为主要的误差来源。这种效应可能导致全局误差在 $h$ 非常小时趋于平稳甚至增加，从而破坏线性拟合。\n\n该实现将把此过程应用于指定的测试用例。它涉及：\n- 将三种单步方法（前向欧拉法、显式梯形法/Heun 法和经典 RK4 法）实现为黑箱函数。\n- 一个通用驱动函数，它接受一个求解器函数、一个 ODE 和一个步长 $h$，并计算在终点时刻 $T$ 的数值解。\n- 一个分析函数，它为每个测试用例组织一系列步长的运行，根据已知的解析解计算全局误差，并对对数变换后的数据进行线性回归以提取斜率 $p$。\n- `numpy.polyfit` 函数提供了一种直接而鲁棒的方法来执行所需的线性回归。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and implements a method to experimentally determine the convergence order\n    of black-box ODE solvers and applies it to a suite of test cases.\n    \"\"\"\n\n    # --- Black-box solver implementations ---\n    def forward_euler(f, t, y, h):\n        \"\"\"First-order forward Euler method.\"\"\"\n        return y + h * f(t, y)\n\n    def heun_method(f, t, y, h):\n        \"\"\"Second-order explicit trapezoidal method (Heun's method).\"\"\"\n        k1 = f(t, y)\n        y_pred = y + h * k1\n        k2 = f(t + h, y_pred)\n        return y + (h / 2.0) * (k1 + k2)\n\n    def rk4_method(f, t, y, h):\n        \"\"\"Fourth-order classical Runge-Kutta method.\"\"\"\n        k1 = f(t, y)\n        k2 = f(t + h / 2.0, y + (h / 2.0) * k1)\n        k3 = f(t + h / 2.0, y + (h / 2.0) * k2)\n        k4 = f(t + h, y + h * k3)\n        return y + (h / 6.0) * (k1 + 2.0 * k2 + 2.0 * k3 + k4)\n\n    # --- Generic ODE solver runner ---\n    def run_ode_solver(solver_func, f, t0, y0, T, h):\n        \"\"\"\n        Integrates an ODE from t0 to T using a given solver and step size.\n\n        Args:\n            solver_func: The black-box one-step solver function.\n            f: The ODE function dy/dt = f(t, y).\n            t0: Initial time.\n            y0: Initial value.\n            T: Final time.\n            h: Step size.\n\n        Returns:\n            The numerical solution at time T.\n        \"\"\"\n        t = float(t0)\n        y = float(y0)\n        \n        # Use round to robustly handle floating-point representation of h\n        num_steps = int(round((T - t0) / h))\n\n        for _ in range(num_steps):\n            y = solver_func(f, t, y, h)\n            t += h\n        \n        return y\n\n    # --- Order estimation logic ---\n    def estimate_order(solver_func, f, y_exact_func, t0, y0, T, h_values):\n        \"\"\"\n        Estimates the convergence order p by fitting a line to log-log data.\n        \"\"\"\n        log_h_list = []\n        log_error_list = []\n\n        for h in h_values:\n            y_numerical = run_ode_solver(solver_func, f, t0, y0, T, h)\n            y_exact = y_exact_func(T)\n            error = np.abs(y_numerical - y_exact)\n            \n            # Avoid log(0) which is -inf; this happens if the error is below\n            # machine precision. Such points do not follow the truncation\n            # error model and should be excluded from the fit.\n            if error  1e-16:\n                continue\n\n            log_h_list.append(np.log(h))\n            log_error_list.append(np.log(error))\n\n        # Perform linear regression on log-log data.\n        # np.polyfit(x, y, 1) returns [slope, intercept] for a linear fit.\n        # The slope is the estimated order p.\n        if len(log_h_list)  2:\n            return np.nan # Not enough data points for a fit\n\n        p_estimate = np.polyfit(log_h_list, log_error_list, 1)[0]\n        return p_estimate\n\n    # --- Test Case Definitions ---\n    \n    # ODE and analytical solution for cases 1, 2, 3, 4\n    def f1(t, y):\n        return -y\n    def y_exact1(t):\n        return np.exp(-t)\n\n    # ODE and analytical solution for case 5\n    def f2(t, y):\n        return y\n    def y_exact2(t):\n        return np.exp(t)\n\n    test_cases = [\n        # Case 1: Forward Euler on y'=-y\n        {'solver': forward_euler, 'f': f1, 'y_exact': y_exact1, 't0': 0.0, 'y0': 1.0, 'T': 1.0,\n         'h_list': [1.0/4, 1.0/8, 1.0/16, 1.0/32]},\n        # Case 2: Heun's method on y'=-y\n        {'solver': heun_method, 'f': f1, 'y_exact': y_exact1, 't0': 0.0, 'y0': 1.0, 'T': 1.0,\n         'h_list': [1.0/4, 1.0/8, 1.0/16, 1.0/32]},\n        # Case 3: RK4 method on y'=-y\n        {'solver': rk4_method, 'f': f1, 'y_exact': y_exact1, 't0': 0.0, 'y0': 1.0, 'T': 1.0,\n         'h_list': [1.0/10, 1.0/20, 1.0/40, 1.0/80]},\n        # Case 4: RK4 with very small steps (probing roundoff effects)\n        {'solver': rk4_method, 'f': f1, 'y_exact': y_exact1, 't0': 0.0, 'y0': 1.0, 'T': 1.0,\n         'h_list': [2.0**-i for i in range(8, 16)]},\n        # Case 5: Forward Euler on y'=y (probing non-asymptotic regime)\n        {'solver': forward_euler, 'f': f2, 'y_exact': y_exact2, 't0': 0.0, 'y0': 1.0, 'T': 1.0,\n         'h_list': [1.0/2, 1.0/4, 1.0/8]},\n    ]\n    \n    results = []\n    for case in test_cases:\n        p = estimate_order(case['solver'], case['f'], case['y_exact'], case['t0'], case['y0'], case['T'], case['h_list'])\n        results.append(p)\n\n    # Format output as a comma-separated list of floats in brackets\n    print(f\"[{','.join(f'{r:.10f}' for r in results)}]\")\n\nsolve()\n```", "id": "3248932"}, {"introduction": "局部截断误差不仅是用于分析的理论工具，更是构建高效、稳健算法的基石。本练习将揭示嵌入式龙格-库塔（Runge-Kutta）方法的巧妙机制，看它如何同时计算两个不同阶的近似解，从而在无需知道精确解的情况下实时估计并控制局部截断误差。理解这一过程是掌握现代自适应步长求解器核心思想的关键 [@problem_id:3248991]。", "problem": "考虑一个常微分方程 (ODE) 的初值问题，$y'(t) = f(t,y(t))$，其中 $y(t_0) = y_0$，$f$ 足够光滑。一个 $p$ 阶和 $p+1$ 阶的 Runge-Kutta-Fehlberg (RKF) 嵌入对（例如，经典的 RKF $4(5)$ 对），在大小为 $h$ 的单个步长上，使用相同的内部阶段求值但不同的输出权重，计算出在 $t_{n+1} = t_n + h$ 处的两个近似解：一个 $p$ 阶的低阶解 $y_{n+1}^{[p]}$ 和一个 $p+1$ 阶的高阶解 $y_{n+1}^{[p+1]}$。对于单步法，在第 $n$ 步的局部截断误差 (LTE) 定义为从 $t_n$ 处的精确值出发，在一步之内产生的误差。自适应步长控制器试图在无法获知精确解 $y(t_{n+1})$ 的情况下，将局部截断误差（LTE）控制在用户指定的容差范围内。\n\n下列哪项陈述正确解释了这种自适应控制器如何在不知道 $y(t_{n+1})$ 的情况下估计 LTE 并调整步长？选择所有适用的选项。\n\nA. 嵌入差 $\\delta_{n+1} = y_{n+1}^{[p+1]} - y_{n+1}^{[p]}$ 在主导阶上是低阶方法局部截断误差（LTE）的一个 $\\mathcal{O}(h^{p+1})$ 近似；控制器使用 $\\delta_{n+1}$ 来估计 LTE 的大小，同时接受 $y_{n+1}^{[p+1]}$ 作为该步的结果。\n\nB. 因为 $\\delta_{n+1}$ 直接估计了高阶解 $y_{n+1}^{[p+1]}$ 的 LTE，一个保守的控制器应该拒绝任何不满足 $\\lVert \\delta_{n+1} \\rVert \\le \\text{tol}$ 的步长，并保留 $y_{n+1}^{[p]}$ 作为接受值，以避免低估误差。\n\nC. 如果主导 LTE 项的表现形式为 $C h^{p+1}$（其中 $C$ 为某个常数），那么在根据 $\\delta_{n+1}$ 构造一个标量误差度量后，下一步的步长近似选择为 $h_{\\text{new}} = h \\,\\alpha \\left(\\frac{\\text{tol}}{\\text{err}}\\right)^{1/(p+1)}$，其中 $\\alpha \\in (0,1)$ 是一个安全因子，这样估计的 LTE 就能缩放到容差水平。\n\nD. 为了比较不同量级的误差分量，控制器通常用权重 $w_i = \\text{atol}_i + \\text{rtol}_i \\max\\!\\left(|y_{n,i}|,\\,|y_{n+1,i}^{[p+1]}|\\right)$ 来缩放 $\\delta_{n+1}$ 的每个分量 $i \\in \\{1,\\dots,d\\}$，并使用诸如加权均方根 (RMS) 范数 $\\left(\\frac{1}{d}\\sum_{i=1}^d (\\delta_{n+1,i}/w_i)^2\\right)^{1/2}$ 这样的范数来决定是接受还是拒绝该步。\n\nE. 由于两种公式共享所有内部阶段，嵌入差 $\\delta_{n+1}$ 消除了所有直到 $h^{p+1}$ 阶的截断误差项，因此 $\\delta_{n+1} = \\mathcal{O}(h^{p+2})$，这直接估计了高阶解的 LTE。", "solution": "问题陈述已经过验证并且是合理的。它准确地描述了使用嵌入式 Runge-Kutta-Fehlberg (RKF) 方法对常微分方程 (ODE) 进行自适应步长控制的背景。所用术语和概念在数值分析领域是标准的。我们可以开始进行解答。\n\n一个 $p$ 阶和 $p+1$ 阶的嵌入式 RKF 方法的核心原理是，在大小为 $h$ 的单个步长上，使用同一组函数求值（阶段）来生成两个不同的数值近似。让我们将从 $(t_n, y_n)$ 开始的初值问题的精确解表示为 $\\tilde{y}(t)$。在 $t_{n+1} = t_n + h$ 处的两个数值近似与精确解有以下关系：\n\n1.  低阶近似 $y_{n+1}^{[p]}$ 具有 $p+1$ 阶的局部截断误差 (LTE)：\n    $$y_{n+1}^{[p]} = \\tilde{y}(t_{n+1}) - \\boldsymbol{C}_{p+1} h^{p+1} + \\mathcal{O}(h^{p+2})$$\n    其中 $\\boldsymbol{C}_{p+1}$ 是 $p$ 阶方法的主误差系数向量。LTE 定义为 $LTE^{[p]} = \\tilde{y}(t_{n+1}) - y_{n+1}^{[p]} = \\boldsymbol{C}_{p+1} h^{p+1} + \\mathcal{O}(h^{p+2})$。\n\n2.  高阶近似 $y_{n+1}^{[p+1]}$ 具有 $p+2$ 阶的 LTE：\n    $$y_{n+1}^{[p+1]} = \\tilde{y}(t_{n+1}) - \\boldsymbol{C}_{p+2} h^{p+2} + \\mathcal{O}(h^{p+3})$$\n    LTE 为 $LTE^{[p+1]} = \\tilde{y}(t_{n+1}) - y_{n+1}^{[p+1]} = \\boldsymbol{C}_{p+2} h^{p+2} + \\mathcal{O}(h^{p+3})$。\n\n自适应控制器需要 LTE 的一个估计值来决定是否接受该步并选择下一步的步长。由于真实解 $\\tilde{y}(t_{n+1})$ 是未知的，LTE 不能被直接计算。取而代之的是，它通过使用两个数值近似之间的差 $\\delta_{n+1}$ 来进行估计：\n$$\\delta_{n+1} = y_{n+1}^{[p+1]} - y_{n+1}^{[p]}$$\n代入上面的表达式，我们得到：\n$$\\delta_{n+1} = \\left(\\tilde{y}(t_{n+1}) - \\boldsymbol{C}_{p+2} h^{p+2} + \\dots\\right) - \\left(\\tilde{y}(t_{n+1}) - \\boldsymbol{C}_{p+1} h^{p+1} + \\dots\\right)$$\n$$\\delta_{n+1} = \\boldsymbol{C}_{p+1} h^{p+1} - \\boldsymbol{C}_{p+2} h^{p+2} + \\dots$$\n在主导阶上，这个差值为：\n$$\\delta_{n+1} = \\boldsymbol{C}_{p+1} h^{p+1} + \\mathcal{O}(h^{p+2})$$\n将此与低阶方法的 LTE $LTE^{[p]} = \\boldsymbol{C}_{p+1} h^{p+1} + \\mathcal{O}(h^{p+2})$ 比较，我们看到 $\\delta_{n+1}$ 是 $p$ 阶方法 LTE 的一个良好近似。\n$$LTE^{[p]} \\approx \\delta_{n+1}$$\n这个误差估计是自适应控制机制的基础。\n\n在此基础上，我们可以分析每个选项。\n\n**A. 嵌入差 $\\delta_{n+1} = y_{n+1}^{[p+1]} - y_{n+1}^{[p]}$ 在主导阶上是低阶方法局部截断误差（LTE）的一个 $\\mathcal{O}(h^{p+1})$ 近似；控制器使用 $\\delta_{n+1}$ 来估计 LTE 的大小，同时接受 $y_{n+1}^{[p+1]}$ 作为该步的结果。**\n这个陈述完全正确。如上所推导，$\\delta_{n+1}$ 是 $p$ 阶方法 LTE ($LTE^{[p]}$) 的一个 $\\mathcal{O}(h^{p+1})$ 近似。这个估计值用于误差控制。此外，一种称为局部外推的标准做法是，使用更精确的高阶解 $y_{n+1}^{[p+1]}$ 作为传播到下一步的值，因为它的局部误差阶 ($\\mathcal{O}(h^{p+2})$) 高于被控制的误差阶。\n结论：**正确**。\n\n**B. 因为 $\\delta_{n+1}$ 直接估计了高阶解 $y_{n+1}^{[p+1]}$ 的 LTE，一个保守的控制器应该拒绝任何不满足 $\\lVert \\delta_{n+1} \\rVert \\le \\text{tol}$ 的步长，并保留 $y_{n+1}^{[p]}$ 作为接受值，以避免低估误差。**\n这个陈述有根本性缺陷。误差估计 $\\delta_{n+1}$ 是 $\\mathcal{O}(h^{p+1})$ 阶的。高阶解的 LTE ($LTE^{[p+1]}$) 是 $\\mathcal{O}(h^{p+2})$ 阶的。一个 $\\mathcal{O}(h^{p+1})$ 阶的量不能直接估计一个 $\\mathcal{O}(h^{p+2})$ 阶的量。该前提是错误的。此外，尽管一些控制器可能会传播 $y_{n+1}^{[p]}$，但所提供的理由很弱，且该陈述的主要论点是不正确的。\n结论：**不正确**。\n\n**C. 如果主导 LTE 项的表现形式为 $C h^{p+1}$（其中 $C$ 为某个常数），那么在根据 $\\delta_{n+1}$ 构造一个标量误差度量后，下一步的步长近似选择为 $h_{\\text{new}} = h \\,\\alpha \\left(\\frac{\\text{tol}}{\\text{err}}\\right)^{1/(p+1)}$，其中 $\\alpha \\in (0,1)$ 是一个安全因子，这样估计的 LTE 就能缩放到容差水平。**\n这个陈述正确地描述了步长自适应公式。设 $\\text{err}$ 是误差估计 $\\delta_{n+1}$ 的一个标量范数。我们有 $\\text{err} \\approx K h^{p+1}$，其中 $K$ 为某个常数。目标是找到一个新的步长 $h_{\\text{new}}$，使得该步的误差 $\\text{err}_{\\text{new}}$ 大约等于期望的容差 $\\text{tol}$。假设 $K$ 是常数，我们有 $\\text{tol} \\approx K h_{\\text{new}}^{p+1}$。对这两个关系式取比值，得到 $\\frac{\\text{tol}}{\\text{err}} \\approx \\left(\\frac{h_{\\text{new}}}{h}\\right)^{p+1}$。求解 $h_{\\text{new}}$ 得到 $h_{\\text{new}} \\approx h \\left(\\frac{\\text{tol}}{\\text{err}}\\right)^{1/(p+1)}$。为了保守起见，包含一个安全因子 $\\alpha \\in (0,1)$ 是标准做法。选项中给出的公式是自适应 ODE 求解器中使用的正确且标准的公式。\n结论：**正确**。\n\n**D. 为了比较不同量级的误差分量，控制器通常用权重 $w_i = \\text{atol}_i + \\text{rtol}_i \\max\\!\\left(|y_{n,i}|,\\,|y_{n+1,i}^{[p+1]}|\\right)$ 来缩放 $\\delta_{n+1}$ 的每个分量 $i \\in \\{1,\\dots,d\\}$，并使用诸如加权均方根 (RMS) 范数 $\\left(\\frac{1}{d}\\sum_{i=1}^d (\\delta_{n+1,i}/w_i)^2\\right)^{1/2}$ 这样的范数来决定是接受还是拒绝该步。**\n这个陈述准确地描述了为 ODE 系统 ($y \\in \\mathbb{R}^d$) 计算标量误差度量的一种标准方法。当解向量 $y$ 的分量具有不同量级时，简单的欧几里得范数是不合适的。此时使用混合绝对/相对误差控制。权重 $w_i = \\text{atol}_i + \\text{rtol}_i \\max\\!\\left(|y_{n,i}|,\\,|y_{n+1,i}^{[p+1]}|\\right)$ 提供了分量级的容差。使用 $\\max(|y_{n,i}|, |y_{n+1,i}^{[p+1]}|)$ 是一种鲁棒的方法，用以估计解分量在步长内的量级。然后，缩放后的误差 $\\delta_{n+1,i}/w_i$ 通过一个范数（例如所示的加权 RMS 范数）组合起来。如果这个最终的标量误差 $\\le 1$，则该步被接受。这是对现代误差控制策略的正确描述。\n结论：**正确**。\n\n**E. 由于两种公式共享所有内部阶段，嵌入差 $\\delta_{n+1}$ 消除了所有直到 $h^{p+1}$ 阶的截断误差项，因此 $\\delta_{n+1} = \\mathcal{O}(h^{p+2})$，这直接估计了高阶解的 LTE。**\n这个陈述不正确。如初始推导所示，差值 $\\delta_{n+1} = y_{n+1}^{[p+1]} - y_{n+1}^{[p]}$ 的结果是 $\\delta_{n+1} = \\boldsymbol{C}_{p+1}h^{p+1} + \\mathcal{O}(h^{p+2})$。低阶方法的主导截断误差项，即 $\\mathcal{O}(h^{p+1})$ 阶的项，*并不会*被抵消。嵌入对设计的根本目的就在于两种方法具有不同的主误差系数，这样它们的差值就能分离出精度较低的方法的主导误差项。因此，$\\delta_{n+1}$ 是 $\\mathcal{O}(h^{p+1})$ 阶的，而不是 $\\mathcal{O}(h^{p+2})$ 阶的。所以，它不能估计 $\\mathcal{O}(h^{p+2})$ 阶的高阶解的 LTE。\n结论：**不正确**。\n\n总而言之，陈述 A、C 和 D 正确地描述了使用嵌入式 Runge-Kutta 对进行自适应步长控制的基本方面。", "answer": "$$\\boxed{ACD}$$", "id": "3248991"}]}