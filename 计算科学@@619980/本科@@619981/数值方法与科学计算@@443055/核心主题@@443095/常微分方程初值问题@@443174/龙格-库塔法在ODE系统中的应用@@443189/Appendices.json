{"hands_on_practices": [{"introduction": "理论知识告诉我们，高阶龙格-库塔方法在相同步长下通常具有更高的精度。然而，高阶方法每步需要更多的函数求值，这意味着更高的计算成本。本实践旨在通过一个具体的常微分方程组，让你亲手实现并比较二阶、三阶和四阶龙格-库塔方法，量化分析计算成本与全局误差之间的权衡关系，从而为在实际问题中选择合适的数值方法提供直观感受。[@problem_id:3205643]", "problem": "您需要研究将固定步长显式 Runge–Kutta 方法应用于耦合、非刚性、线性常微分方程组 (ODEs) 时，计算成本与精度之间的权衡。考虑以下系统的初值问题\n$$\n\\begin{cases}\n\\dfrac{d y_1}{d t} = - y_1 \\\\\n\\dfrac{d y_2}{d t} = y_1 - 2 y_2 \\\\\n\\dfrac{d y_3}{d t} = y_2 - 3 y_3\n\\end{cases},\n\\quad t \\in [0,T], \\quad\n\\mathbf{y}(0) = \\begin{bmatrix} y_1(0) \\\\ y_2(0) \\\\ y_3(0) \\end{bmatrix}\n= \\begin{bmatrix} 1.3 \\\\ -0.9 \\\\ 0.7 \\end{bmatrix},\n\\quad T = 4.0.\n$$\n\n您的任务是：\n- 为常微分方程组实现三种显式 Runge–Kutta 方法：\n  - 二阶方法（显式中点法），\n  - 三阶方法（经典三阶 Kutta 法），\n  - 四阶方法（经典四阶 Runge–Kutta 法）。\n- 每次仿真使用固定的时间步长，并将数值解从 $t=0$ 传播到 $t=T$。\n- 将单次运行的计算成本定义为函数求值的总次数（常微分方程组右端项的求值次数）。对于一个有 $N$ 个步长的 $s$ 级 Runge–Kutta 方法，成本为 $s \\cdot N$。\n- 将精度度量为 $t=T$ 时全局误差的欧几里得范数，即 $\\lVert y_{\\text{num}}(T) - y_{\\text{true}}(T) \\rVert_2$。\n\n为进行误差评估，请使用从第一性原理推导出的该三角线性系统的精确解。设 $a = y_1(0)$，$b = y_2(0)$，$c = y_3(0)$。在时间 $t$ 的精确解分量为：\n$$\ny_1(t) = a e^{-t},\n$$\n$$\ny_2(t) = a e^{-t} + (b - a) e^{-2t},\n$$\n$$\ny_3(t) = \\frac{a}{2} e^{-t} + (b - a) e^{-2t} + \\left(c - b + \\frac{a}{2}\\right) e^{-3t}.\n$$\n\n使用以下测试套件来探究成本与精度的关系。对于每种方法，在 $[0, T]$ 区间上使用 $N \\in \\{1, 2, 5, 10, 20, 40\\}$ 个均匀步长进行仿真：\n- 对于二阶方法（显式中点法），使用 $N \\in \\{1, 2, 5, 10, 20, 40\\}$。\n- 对于三阶方法（经典三阶 Kutta 法），使用 $N \\in \\{1, 2, 5, 10, 20, 40\\}$。\n- 对于四阶方法（经典法），使用 $N \\in \\{1, 2, 5, 10, 20, 40\\}$。\n\n对于每次运行，记录数据对 $[m, e]$，其中 $m$ 是函数求值的总次数，$e$ 是 $t=T$ 时全局误差的欧几里得范数。最终的程序输出必须按以下顺序将所有结果汇总到一个列表中：\n- 首先按上述给定的 $N$ 顺序列出二阶方法的所有结果，\n- 然后按上述给定的 $N$ 顺序列出三阶方法的所有结果，\n- 最后按上述给定的 $N$ 顺序列出四阶方法的所有结果。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如：$[ [m_1,e_1], [m_2,e_2], \\dots ]$）。此问题不涉及物理单位，所有可能出现的角度都应视为无量纲实数。所有数值答案都必须在输出列表中以原始十进制数的形式报告，不含额外文本。", "solution": "用户的要求是分析将三种不同的显式 Runge-Kutta (RK) 方法应用于线性常微分方程组 (ODEs) 时的计算成本与精度之间的权衡关系。该问题定义明确、科学合理且内容自洽，提供了常微分方程组、初始条件、时间区间、具体的数值方法、成本和误差的定义，以及用于验证的精确解析解。因此，该问题被判定为 **有效**。\n\n问题的核心在于对以下形式的初值问题 (IVP) 进行数值积分：\n$$\n\\frac{d\\mathbf{y}}{dt} = f(t, \\mathbf{y}), \\quad \\mathbf{y}(t_0) = \\mathbf{y}_0\n$$\n其中 $\\mathbf{y}(t) \\in \\mathbb{R}^3$。给定的系统是：\n$$\nf(t, \\mathbf{y}) = \\begin{bmatrix} -y_1 \\\\ y_1 - 2y_2 \\\\ y_2 - 3y_3 \\end{bmatrix}\n$$\n初始条件为 $\\mathbf{y}(0) = [1.3, -0.9, 0.7]^T$，区间为 $t \\in [0, 4.0]$。\n\n一个 $s$ 级显式 Runge-Kutta 方法使用以下通用公式将解从时间 $t_n$推进到 $t_{n+1} = t_n + h$：\n$$\n\\mathbf{y}_{n+1} = \\mathbf{y}_n + h \\sum_{i=1}^s b_i \\mathbf{k}_i\n$$\n其中，各级 $\\mathbf{k}_i$ 按顺序计算：\n$$\n\\mathbf{k}_i = f\\left(t_n + c_i h, \\mathbf{y}_n + h \\sum_{j=1}^{i-1} a_{ij} \\mathbf{k}_j\\right)\n$$\n每次计算 $\\mathbf{k}_i$ 都构成对函数 $f$ 的一次求值。因此，对于单个时间步长，$s$ 级方法需要 $s$ 次函数求值。在 $N$ 个步长上，函数求值的总次数（定义为计算成本 $m$）为 $m = s \\cdot N$。\n\n精度由最终时间 $T$ 的全局误差的欧几里得范数来度量，$e = \\lVert \\mathbf{y}_{\\text{num}}(T) - \\mathbf{y}_{\\text{true}}(T) \\rVert_2$。\n\n指定的三种方法是：\n\n1.  **二阶方法（显式中点法）**：这是一个 2 级 ($s=2$)、2 阶 ($p=2$) 的方法。其更新公式为：\n    $$\n    \\begin{align*}\n    \\mathbf{k}_1 = f(t_n, \\mathbf{y}_n) \\\\\n    \\mathbf{k}_2 = f\\left(t_n + \\frac{1}{2}h, \\mathbf{y}_n + \\frac{1}{2}h\\mathbf{k}_1\\right) \\\\\n    \\mathbf{y}_{n+1} = \\mathbf{y}_n + h\\mathbf{k}_2\n    \\end{align*}\n    $$\n\n2.  **三阶方法（经典 Kutta 法）**：这是一个 3 级 ($s=3$)、3 阶 ($p=3$) 的方法。所使用的具体变体是：\n    $$\n    \\begin{align*}\n    \\mathbf{k}_1 = f(t_n, \\mathbf{y}_n) \\\\\n    \\mathbf{k}_2 = f\\left(t_n + \\frac{1}{2}h, \\mathbf{y}_n + \\frac{1}{2}h\\mathbf{k}_1\\right) \\\\\n    \\mathbf{k}_3 = f\\left(t_n + h, \\mathbf{y}_n - h\\mathbf{k}_1 + 2h\\mathbf{k}_2\\right) \\\\\n    \\mathbf{y}_{n+1} = \\mathbf{y}_n + \\frac{h}{6}(\\mathbf{k}_1 + 4\\mathbf{k}_2 + \\mathbf{k}_3)\n    \\end{align*}\n    $$\n\n3.  **四阶方法（经典 RK4）**：这是一个 4 级 ($s=4$)、4 阶 ($p=4$) 的方法。其公式为：\n    $$\n    \\begin{align*}\n    \\mathbf{k}_1 = f(t_n, \\mathbf{y}_n) \\\\\n    \\mathbf{k}_2 = f\\left(t_n + \\frac{1}{2}h, \\mathbf{y}_n + \\frac{1}{2}h\\mathbf{k}_1\\right) \\\\\n    \\mathbf{k}_3 = f\\left(t_n + \\frac{1}{2}h, \\mathbf{y}_n + \\frac{1}{2}h\\mathbf{k}_2\\right) \\\\\n    \\mathbf{k}_4 = f\\left(t_n + h, \\mathbf{y}_n + h\\mathbf{k}_3\\right) \\\\\n    \\mathbf{y}_{n+1} = \\mathbf{y}_n + \\frac{h}{6}(\\mathbf{k}_1 + 2\\mathbf{k}_2 + 2\\mathbf{k}_3 + \\mathbf{k}_4)\n    \\end{align*}\n    $$\n\n计算误差所需的解析解已提供，可以实现为时间 $t$ 的函数。设 $a=y_1(0)$，$b=y_2(0)$ 和 $c=y_3(0)$：\n$$\n\\begin{align*}\ny_1(t) = a e^{-t} \\\\\ny_2(t) = a e^{-t} + (b - a) e^{-2t} \\\\\ny_3(t) = \\frac{a}{2} e^{-t} + (b - a) e^{-2t} + \\left(c - b + \\frac{a}{2}\\right) e^{-3t}\n\\end{align*}\n$$\n\n该解是通过创建一个通用的求解器函数来实现的，该函数接受一个步进函数（RK 方法之一）作为参数。一个主循环遍历这三种方法，并对每种方法，遍历指定的步数列表 $N \\in \\{1, 2, 5, 10, 20, 40\\}$。对于每次运行，固定时间步长为 $h = T/N$。求解器将解从 $t=0$ 传播到 $t=T$。最后，计算并存储成本 $m$ 和误差 $e$。所有运行的结果按规定汇总到单个列表中。值得注意的是，对于显式方法，步长 $h$ 必须足够小，以保持在绝对稳定域内。系统矩阵的特征值为 $\\lambda = -1, -2, -3$。对于限制性最强的特征值 $\\lambda = -3$，稳定性要求 $h \\le 2/3$。因此，使用大步长（$N=1, h=4.0$；$N=2, h=2.0$；$N=5, h=0.8$）的仿真预计会不稳定，并产生非常大的误差。这种行为是分析的一部分。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the ODE system using three Runge-Kutta methods and calculates\n    the cost-vs-accuracy trade-off for various step counts.\n    \"\"\"\n    \n    # Problem parameters\n    T = 4.0\n    y0 = np.array([1.3, -0.9, 0.7])\n    a, b, c = y0[0], y0[1], y0[2]\n    N_values = [1, 2, 5, 10, 20, 40]\n\n    # Define the ODE system dy/dt = f(t, y)\n    def f(t, y):\n        \"\"\"\n        Right-hand side of the ODE system.\n        \"\"\"\n        # The 't' argument is unused as the system is autonomous, but it is\n        # included for compatibility with general-purpose ODE solver signatures.\n        dydt = np.zeros_like(y, dtype=float)\n        dydt[0] = -y[0]\n        dydt[1] = y[0] - 2.0 * y[1]\n        dydt[2] = y[1] - 3.0 * y[2]\n        return dydt\n\n    # Define the exact analytical solution\n    def y_true_func(t):\n        \"\"\"\n        Calculates the exact solution at a given time t.\n        \"\"\"\n        exp_t = np.exp(-t)\n        exp_2t = np.exp(-2.0 * t)\n        exp_3t = np.exp(-3.0 * t)\n        \n        y1_t = a * exp_t\n        y2_t = a * exp_t + (b - a) * exp_2t\n        y3_t = (a / 2.0) * exp_t + (b - a) * exp_2t + (c - b + a / 2.0) * exp_3t\n        \n        return np.array([y1_t, y2_t, y3_t])\n\n    # --- Runge-Kutta Stepper Functions ---\n    # Each stepper function advances the solution by one time step h.\n    \n    def rk2_step(f_func, t, y, h):\n        \"\"\"Explicit Midpoint (2 stages, 2nd order)\"\"\"\n        k1 = f_func(t, y)\n        k2 = f_func(t + 0.5 * h, y + 0.5 * h * k1)\n        return y + h * k2\n\n    def rk3_step(f_func, t, y, h):\n        \"\"\"Classic Kutta (3 stages, 3rd order)\"\"\"\n        k1 = f_func(t, y)\n        k2 = f_func(t + 0.5 * h, y + 0.5 * h * k1)\n        k3 = f_func(t + h, y - h * k1 + 2.0 * h * k2)\n        return y + (h / 6.0) * (k1 + 4.0 * k2 + k3)\n\n    def rk4_step(f_func, t, y, h):\n        \"\"\"Classical Runge-Kutta (4 stages, 4th order)\"\"\"\n        k1 = f_func(t, y)\n        k2 = f_func(t + 0.5 * h, y + 0.5 * h * k1)\n        k3 = f_func(t + 0.5 * h, y + 0.5 * h * k2)\n        k4 = f_func(t + h, y + h * k3)\n        return y + (h / 6.0) * (k1 + 2.0 * k2 + 2.0 * k3 + k4)\n\n    # General-purpose ODE solver for a fixed number of steps\n    def solve_ivp(stepper, f_func, y_initial, t_final, n_steps):\n        h = t_final / n_steps\n        y = y_initial.copy()\n        t = 0.0\n        for _ in range(n_steps):\n            y = stepper(f_func, t, y, h)\n            t += h\n        return y\n\n    # --- Main Calculation Loop ---\n    all_results = []\n    \n    methods = [\n        (rk2_step, 2),  # (stepper_function, number_of_stages)\n        (rk3_step, 3),\n        (rk4_step, 4)\n    ]\n    \n    y_exact_at_T = y_true_func(T)\n    \n    for stepper, s in methods:\n        for N in N_values:\n            # Calculate numerical solution at T\n            y_num_at_T = solve_ivp(stepper, f, y0, T, N)\n            \n            # Calculate Euclidean norm of the global error\n            error = np.linalg.norm(y_num_at_T - y_exact_at_T)\n            \n            # Calculate computational cost (total function evaluations)\n            cost = s * N\n            \n            all_results.append([cost, error])\n\n    # Format the results into a single string `[[m1,e1],[m2,e2],...]`\n    # This manual formatting ensures no spaces are included.\n    string_parts = [f\"[{m},{e}]\" for m, e in all_results]\n    final_output = f\"[{','.join(string_parts)}]\"\n\n    print(final_output)\n\nsolve()\n```", "id": "3205643"}, {"introduction": "我们已经看到不同阶数的龙格-库塔方法在精度上的差异，但方法“阶数”的理论保证是建立在微分方程足够“光滑”的假设之上的。本实践将引导你探究当方程的右函数在某点（如原点）不满足解析性时，经典四阶龙格-库塔方法的收敛阶表现。通过编写代码，使用参考解来估计全局误差，并利用对数-对数坐标下的线性回归来经验性地验证收敛阶，你将深刻理解数值方法理论与实践之间的联系。[@problem_id:3205579]", "problem": "考虑一个由以下公式给出的常微分方程组 (ODEs) 的初值问题 (IVP)\n$$\n\\frac{d}{dt}\n\\begin{bmatrix}\ny_1(t) \\\\\ny_2(t)\n\\end{bmatrix}\n=\n\\begin{bmatrix}\ny_2(t) \\\\\n-\\dfrac{y_1(t)}{\\sqrt{y_1(t)^2 + y_2(t)^2}}\n\\end{bmatrix},\n\\quad\n\\text{with}\n\\quad\n\\begin{bmatrix}\ny_1(0) \\\\\ny_2(0)\n\\end{bmatrix}\n=\n\\begin{bmatrix}\ny_{1,0} \\\\\ny_{2,0}\n\\end{bmatrix}.\n$$\n从状态 $\\left(y_1, y_2\\right)$ 到右端项的映射在原点 $\\left(0,0\\right)$ 处是非解析的，因为函数 $\\sqrt{y_1^2 + y_2^2}$ 在该点不是解析函数。经典的显式 Runge–Kutta 方法，例如四阶方法，是在光滑性假设下（例如，$f$ 拥有足够多的连续导数）推导出来的，这些假设在远离奇点时是满足的。本问题的目标是，通过测量在固定的最终时间 $T$ 和不同的初始条件 $\\left(y_{1,0}, y_{2,0}\\right)$ 下，全局误差如何随着时间步长 $h$ 的减小而变化，来实验性地验证经典四阶 Runge–Kutta 方法 (RK4) 应用于该系统时的收敛阶。\n\n使用以下基本事实。\n- 一个自治形式的常微分方程组可以写成 $\\dfrac{d}{dt} \\mathbf{y}(t) = f\\left(\\mathbf{y}(t)\\right)$，其中 $\\mathbf{y}(0)=\\mathbf{y}_0$，$\\mathbf{y}(t)\\in\\mathbb{R}^n$ 且 $f:\\mathbb{R}^n\\to\\mathbb{R}^n$。\n- 对于一个 p 阶单步法，在 $f$ 满足适当光滑性条件的假设下，对于足够小的 $h$，在固定的终端时间 $T$ 的全局误差量级为 $C h^p$，其中 $C$ 是一个与 $h$ 无关的常数，而 $p$ 是该方法的阶数。\n\n为系统实现经典四阶 Runge–Kutta 方法，在固定的时间区间 $\\left[0,T\\right]$ 上，使用多个步长 $h$ 来近似解 $\\mathbf{y}(T)$。为了估计在 $T$ 时的全局误差，使用相同的数值方法但采用一个显著更小的步长 $h_{\\text{ref}}$ 来计算一个高精度参考解 $\\mathbf{y}_{\\text{ref}}(T)$，并将其作为参考。对于每个测试的 $h$，使用欧几里得范数来测量误差：\n$$\nE(h) = \\left\\| \\mathbf{y}_h(T) - \\mathbf{y}_{\\text{ref}}(T) \\right\\|_2,\n$$\n其中 $\\mathbf{y}_h(T)$ 表示使用步长 $h$ 在 $T$ 时刻得到的数值解。然后，通过最小二乘法在对数坐标中拟合模型 $E(h) \\approx C h^p$ 来估计观测到的阶数 $p$，即对 $\\log E(h)$ 关于 $\\log h$ 进行回归，并将斜率作为 $p$ 的估计值。\n\n您的程序必须对以下测试套件中的每个参数集执行此估计。所有角度和量都是无量纲的。答案不涉及物理单位。\n\n测试套件规格：\n- 情况 $\\text{A}$（理想路径，远离奇点）：$\\left(y_{1,0}, y_{2,0}\\right) = \\left(0, 1\\right)$，$T = 1$。\n- 情况 $\\text{B}$（初始半径接近奇异，但非零）：$\\left(y_{1,0}, y_{2,0}\\right) = \\left(10^{-3}, 0\\right)$，$T = 1$。\n- 情况 $\\text{C}$（更长的时间范围）：$\\left(y_{1,0}, y_{2,0}\\right) = \\left(1, 0\\right)$，$T = 5$。\n- 情况 $\\text{D}$（中等时间，混合符号初始条件）：$\\left(y_{1,0}, y_{2,0}\\right) = \\left(-1, 1.5\\right)$，$T = 2.5$。\n\n对于每种情况，使用步长\n$$\nh \\in \\left\\{0.2,\\; 0.1,\\; 0.05,\\; 0.025\\right\\}.\n$$\n当积分到最终时间 $T$ 时，如果由于浮点数表示的原因 $T/h$ 不是整数，则通过设置 $N = \\mathrm{round}\\!\\left(T/h\\right)$ 并使用 $h_{\\text{eff}} = T/N$ 作为积分和回归的有效步长来调整。对于参考解，在每种情况下使用步长 $h_{\\text{ref}}$，其定义为 $h_{\\text{ref}} = \\min(h_{\\text{eff}})/64$，同样根据相同的规则进行调整以使 $T/h_{\\text{ref}}$ 成为整数。\n\n对于这四种情况中的每一种，从对应于四个步长的点对集合 $\\left(\\log h_{\\text{eff}}, \\log E(h_{\\text{eff}})\\right)$ 中计算最小二乘斜率 $p$。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，顺序为 $\\left[p_\\text{A}, p_\\text{B}, p_\\text{C}, p_\\text{D}\\right]$。将每个 $p$ 表示为保留小数点后三位的小数。最终输出格式必须严格为\n$$\n\\left[\\text{p\\_A},\\text{p\\_B},\\text{p\\_C},\\text{p\\_D}\\right].\n$$", "solution": "该问题要求对应用于一个二维自治常微分方程组 (ODEs) 的经典四阶 Runge-Kutta (RK4) 方法的收敛阶进行实验性验证。该系统由以下初值问题 (IVP) 定义：\n$$\n\\frac{d\\mathbf{y}}{dt} = f(\\mathbf{y}), \\quad \\mathbf{y}(t) = \\begin{bmatrix} y_1(t) \\\\ y_2(t) \\end{bmatrix}, \\quad \\mathbf{y}(0) = \\mathbf{y}_0 = \\begin{bmatrix} y_{1,0} \\\\ y_{2,0} \\end{bmatrix}\n$$\n其中右端函数 $f: \\mathbb{R}^2 \\to \\mathbb{R}^2$ 由下式给出：\n$$\nf(\\mathbf{y}) = \\begin{bmatrix} y_2 \\\\ -\\dfrac{y_1}{\\sqrt{y_1^2 + y_2^2}} \\end{bmatrix}\n$$\n该系统的一个关键特征是 $f(\\mathbf{y})$ 在原点 $\\mathbf{y} = \\mathbf{0}$ 处的奇点，函数在该点不是解析的。Runge-Kutta 方法的收敛阶理论证明假设 $f$ 具有足够的光滑性，而这个条件在奇点处被违反了。本研究将量化该方法在各种情景下的有效收敛阶，其中一些情景可能涉及接近或从该奇点附近开始的轨迹。\n\n每个测试案例的解决方案核心包括一个四步过程：(1) 实现 RK4 积分器，(2) 生成一个高精度参考解，(3) 为一系列步长计算全局误差，以及 (4) 通过在对数空间中进行线性回归来估计收敛阶。\n\n**1. 四阶 Runge-Kutta (RK4) 方法**\n\nRK4 方法是一种用于近似 IVP 解的单步数值程序。对于一个常微分方程组，从时间 $t_n$ 的状态 $\\mathbf{y}_n$ 更新到时间 $t_{n+1} = t_n + h$ 的状态 $\\mathbf{y}_{n+1}$ 的计算如下，其中所有的 $k_i$ 和 $\\mathbf{y}$ 都是 $\\mathbb{R}^2$ 中的向量：\n$$\n\\begin{aligned}\n\\mathbf{k}_1 = f(\\mathbf{y}_n) \\\\\n\\mathbf{k}_2 = f(\\mathbf{y}_n + \\frac{h}{2} \\mathbf{k}_1) \\\\\n\\mathbf{k}_3 = f(\\mathbf{y}_n + \\frac{h}{2} \\mathbf{k}_2) \\\\\n\\mathbf{k}_4 = f(\\mathbf{y}_n + h \\mathbf{k}_3) \\\\\n\\mathbf{y}_{n+1} = \\mathbf{y}_n + \\frac{h}{6}(\\mathbf{k}_1 + 2\\mathbf{k}_2 + 2\\mathbf{k}_3 + \\mathbf{k}_4)\n\\end{aligned}\n$$\n该算法在一个函数中实现，该函数将系统从 $t=0$ 积分到最终时间 $T$。根据规定，步数 $N$ 计算为 $N = \\mathrm{round}(T/h_{\\text{nom}})$，其中 $h_{\\text{nom}}$ 是名义步长。然后，用于积分的有效步长是 $h_{\\text{eff}} = T/N$。这确保了能够精确达到最终时间 $T$。\n\n**2. 参考解与误差估计**\n\n收敛阶 $p$ 通过模型 $E(h) \\approx C h^p$ 将固定时间 $T$ 上的全局误差 $E$ 与步长 $h$ 联系起来（对于某个常数 $C$ 和足够小的 $h$）。为了估计 $p$，我们必须首先测量 $E(h)$。全局误差定义为数值解 $\\mathbf{y}_h(T)$ 与真实解 $\\mathbf{y}(T)$ 之间的欧几里得距离：\n$$\nE(h) = \\|\\mathbf{y}_h(T) - \\mathbf{y}(T)\\|_2\n$$\n由于真实解 $\\mathbf{y}(T)$ 通常是未知的，我们用一个高精度参考解 $\\mathbf{y}_{\\text{ref}}(T)$ 来近似它。该参考解使用相同的 RK4 方法但以一个更小的步长 $h_{\\text{ref}}$ 计算得出，具体如问题所述。对于每个测试案例，我们首先确定有效步长集合 $\\{h_{\\text{eff}, i}\\}$，然后根据它们的最小值定义一个参考步长：\n$$\nh_{\\text{ref, nom}} = \\frac{\\min(\\{h_{\\text{eff}, i}\\})}{64}\n$$\n用于参考解计算的步数是 $N_{\\text{ref}} = \\mathrm{round}(T / h_{\\text{ref, nom}})$，积分使用相应的有效步长 $h_{\\text{ref}} = T / N_{\\text{ref}}$。误差则近似为：\n$$\nE(h) \\approx \\|\\mathbf{y}_h(T) - \\mathbf{y}_{\\text{ref}}(T)\\|_2\n$$\n\n**3. 通过对数-对数回归确定收敛阶**\n\n对误差模型 $E(h) \\approx C h^p$ 取自然对数，得到：\n$$\n\\ln(E(h)) \\approx \\ln(C) + p \\ln(h)\n$$\n这揭示了 $\\ln(E)$ 和 $\\ln(h)$ 之间存在线性关系，其斜率即为收敛阶 $p$。为了估计 $p$，我们对每个测试案例执行以下步骤：\n1.  对于每个名义步长 $h_{\\text{nom}} \\in \\{0.2, 0.1, 0.05, 0.025\\}$，计算有效步长 $h_{\\text{eff}}$ 和相应的数值解 $\\mathbf{y}_{h_{\\text{eff}}}(T)$。\n2.  使用预先计算的参考解 $\\mathbf{y}_{\\text{ref}}(T)$，为每个解计算全局误差 $E(h_{\\text{eff}})$。\n3.  收集数据对 $(\\ln(h_{\\text{eff}}), \\ln(E(h_{\\text{eff}})))$。\n4.  对这些数据点进行线性最小二乘回归。最佳拟合线的斜率提供了收敛阶 $p$ 的经验估计值。\n\n**4. 测试案例的实现**\n\n所述过程应用于四个指定的测试案例（A、B、C、D）中的每一个，这些案例的初始条件 $(y_{1,0}, y_{2,0})$ 和最终积分时间 $T$ 各不相同。实现将这些步骤整合到一个单一的程序中。使用 `numpy` 库进行向量运算和 `polyfit` 函数，该函数可以方便地执行最小二乘回归。最终结果四舍五入到小数点后三位，并按要求进行格式化。原点处奇点的存在由问题设计来处理，确保所有初始条件都不在 $(0,0)$，并且系统动力学在积分区间内不会将轨迹引向该点。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of empirically verifying the convergence order of the RK4 method\n    for a given system of ODEs with a singularity.\n    \"\"\"\n\n    # Define the ODE system's right-hand-side function f(y)\n    def f_ode(y):\n        \"\"\"\n        Computes the derivative dy/dt for the given state y.\n        y is a 2D numpy array [y1, y2].\n        \"\"\"\n        norm_y = np.linalg.norm(y)\n        # A small tolerance is used for robustness, though the problem setup avoids y=(0,0).\n        if norm_y  1e-15:\n            return np.array([0.0, 0.0])\n        \n        dy1_dt = y[1]\n        dy2_dt = -y[0] / norm_y\n        return np.array([dy1_dt, dy2_dt])\n\n    # Implement the classical RK4 step for a system of ODEs\n    def rk4_step(func, y, h):\n        \"\"\"\n        Performs a single RK4 step.\n        \"\"\"\n        k1 = func(y)\n        k2 = func(y + 0.5 * h * k1)\n        k3 = func(y + 0.5 * h * k2)\n        k4 = func(y + h * k3)\n        return y + (h / 6.0) * (k1 + 2*k2 + 2*k3 + k4)\n\n    # Function to integrate the ODE from t=0 to t=T for a specified number of steps\n    def integrate_with_n_steps(y0, T, num_steps):\n        \"\"\"\n        Integrates the ODE using RK4 for a given number of steps.\n        \"\"\"\n        if num_steps == 0:\n            return np.array(y0, dtype=float)\n        \n        h = T / num_steps\n        y = np.array(y0, dtype=float)\n        for _ in range(num_steps):\n            y = rk4_step(f_ode, y, h)\n        return y\n    \n    # Function to estimate the convergence order for a given case\n    def estimate_order(y0_tuple, T):\n        \"\"\"\n        Calculates the empirical order of convergence for a single test case.\n        \"\"\"\n        y0 = np.array(y0_tuple, dtype=float)\n        h_nom_values = [0.2, 0.1, 0.05, 0.025]\n        \n        # Calculate N and h_eff for each nominal h to be tested\n        step_configs = []\n        for h_nom in h_nom_values:\n            # As per problem, N = round(T/h). Ensure at least 1 step if T > 0.\n            num_steps = max(1, int(round(T / h_nom)))\n            h_eff = T / num_steps\n            step_configs.append({'N': num_steps, 'h_eff': h_eff})\n\n        h_eff_values = [sc['h_eff'] for sc in step_configs]\n\n        # Determine parameters for the high-accuracy reference solution\n        min_h_eff = min(h_eff_values)\n        h_ref_nominal = min_h_eff / 64.0\n        N_ref = max(1, int(round(T / h_ref_nominal)))\n        \n        # Compute the reference solution\n        y_ref = integrate_with_n_steps(y0, T, N_ref)\n\n        log_h_list = []\n        log_E_list = []\n\n        # Calculate errors for each step size\n        for config in step_configs:\n            N = config['N']\n            h_eff = config['h_eff']\n            \n            # Compute numerical solution for this h_eff\n            y_h = integrate_with_n_steps(y0, T, N)\n            \n            # Calculate the global error against the reference solution\n            error = np.linalg.norm(y_h - y_ref)\n            \n            # Store log-log data for regression. Avoid log(0) if error is numerically zero.\n            if error > 1e-16:\n                log_h_list.append(np.log(h_eff))\n                log_E_list.append(np.log(error))\n\n        # Perform linear regression on log-log data to find the slope (order p)\n        if len(log_h_list)  2:\n            return np.nan # Not enough valid data points to fit a line\n\n        # np.polyfit(x, y, 1) returns [slope, intercept] for a linear fit\n        p_estimate, _ = np.polyfit(log_h_list, log_E_list, 1)\n        \n        return p_estimate\n\n    # Define the test cases from the problem statement\n    test_cases = [\n        {'y0': (0.0, 1.0), 'T': 1.0},    # Case A\n        {'y0': (1e-3, 0.0), 'T': 1.0},   # Case B\n        {'y0': (1.0, 0.0), 'T': 5.0},    # Case C\n        {'y0': (-1.0, 1.5), 'T': 2.5}    # Case D\n    ]\n\n    results = []\n    for case in test_cases:\n        p_est = estimate_order(case['y0'], case['T'])\n        # Format the result to three decimal places\n        results.append(f\"{p_est:.3f}\")\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3205579"}, {"introduction": "在前两个实践中，我们都使用了固定的步长$h$。然而，在求解复杂问题时，一个理想的求解器应该能“智能”地调整步长：在解变化平缓时使用大步长以提高效率，在解剧烈变化时自动减小步长以保证精度。本实践将指导你从零开始实现一个自适应步长的嵌入式龙格-库塔求解器，并用它来求解一个具有有限时间奇点（“爆破”）的方程组，你将直观地观察到当解趋近于奇点时，求解器为了控制误差，步长是如何自动收缩的。[@problem_id:3205626]", "problem": "您需要设计并分析一个表现出有限时间奇点的小型常微分方程 (ODE) 系统，然后实现一个自适应嵌入式龙格－库塔求解器对其进行数值积分，同时观察当解逼近奇点时步长如何收缩。此任务完全是数学和计算性质的，并且必须通过编写一个完整的、可运行的程序来解决。\n\n考虑系统\n$$\n\\begin{cases}\n\\frac{dr}{dt} = r^2, \\\\\n\\frac{d\\theta}{dt} = 1,\n\\end{cases}\n$$\n其初始条件为 $r(t_0) = r_0$，$\\theta(t_0) = \\theta_0$，其中 $\\theta$ 是以弧度为单位的角度变量。该系统是自治的，引入角度变量是为了使问题成为一个二维系统，同时在动力学上保持简单。标量分量 $r$ 具有一个有限时间奇点，这可以从微分方程 $\\frac{dr}{dt} = r^2$ 的一个基本事实——通过分离变量法推导出，它意味着解无法延伸超过一个有限的爆破时间 $t_{\\mathrm{sing}}$，该时间取决于 $r_0$ 和 $t_0$。\n\n您的程序必须实现一个自适应嵌入式显式龙格－库塔方法，该方法使用两个不同阶的近似来估计局部截断误差，并相应地调整步长 $h$，以满足局部误差目标。该方法必须：\n- 从 $t_0$ 开始，使用状态向量 $[r,\\theta]^T$，通过一个基于嵌入对误差估计进行自适应调整的步长 $h$，将解在时间上向前推进。\n- 使用绝对误差容限 $a_{\\mathrm{tol}}$ 和相对误差容限 $r_{\\mathrm{tol}}$，按照数值分析中的标准方式对误差估计进行逐分量缩放，然后将其聚合成一个单一的误差范数，用于决定是接受还是拒绝一个步长。\n- 当步长被拒绝时，缩小 $h$；当步长被接受时，推进时间并更新状态，如果估计误差远低于容限，则可以增大 $h$。\n- 当达到最终时间 $t_{\\mathrm{end}}$，或在达到 $t_{\\mathrm{end}}$ 之前，误差控制所要求的自适应步长降至预设的最小值 $h_{\\min}$ 以下时，程序停止。在后一种情况下，求解器被认为已在预设最小步长的限制下逼近了奇点。\n- 在积分过程中，跟踪所遇到的最小的被接受的步长。\n\n对于每个测试，报告以下内容：\n- 求解器达到的最终时间 $t_{\\mathrm{final}}$。\n- 遇到的最小的被接受的步长 $h_{\\mathrm{min,acc}}$。\n- 一个布尔标志，指示求解器是否因为误差控制导致 $h$ 降至 $h_{\\min}$ 以下而在 $t_{\\mathrm{end}}$ 之前终止（这被解释为在给定容限下逼近奇点）。\n- 差值 $t_{\\mathrm{sing}} - t_{\\mathrm{final}}$，其中 $t_{\\mathrm{sing}}$ 是从初始条件 $(t_0,r_0)$ 推导出的理论爆破时间。\n\n根据局部截断误差控制和嵌入式龙格－库塔对的基本定义，实现所述的自适应方法。除了可以从 $\\frac{dr}{dt} = r^2$ 通过分离变量法和嵌入式龙格－库塔自适应的基本原理推导出的内容外，不要为这个特定系统假定任何先验的特殊公式。\n\n测试套件。您的程序必须在以下4个参数集上运行求解器：\n- 测试 A: $t_0 = 0$, $r_0 = 1$, $\\theta_0 = 0$, $t_{\\mathrm{end}} = 1.5$, $r_{\\mathrm{tol}} = 10^{-6}$, $a_{\\mathrm{tol}} = 10^{-8}$, $h_{\\min} = 10^{-12}$。\n- 测试 B: $t_0 = 0$, $r_0 = 0.1$, $\\theta_0 = 0$, $t_{\\mathrm{end}} = 2$, $r_{\\mathrm{tol}} = 10^{-6}$, $a_{\\mathrm{tol}} = 10^{-8}$, $h_{\\min} = 10^{-12}$。\n- 测试 C: $t_0 = 0$, $r_0 = 5$, $\\theta_0 = 0$, $t_{\\mathrm{end}} = 1$, $r_{\\mathrm{tol}} = 10^{-6}$, $a_{\\mathrm{tol}} = 10^{-8}$, $h_{\\min} = 10^{-12}$。\n- 测试 D: $t_0 = 0$, $r_0 = 1$, $\\theta_0 = 0$, $t_{\\mathrm{end}} = 1.5$, $r_{\\mathrm{tol}} = 10^{-9}$, $a_{\\mathrm{tol}} = 10^{-12}$, $h_{\\min} = 10^{-12}$。\n\n对于每个测试，使用分离变量法计算由初始条件和方程 $\\frac{dr}{dt} = r^2$ 所蕴含的解析爆破时间 $t_{\\mathrm{sing}}$，并与数值输出一同报告 $t_{\\mathrm{sing}} - t_{\\mathrm{final}}$。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个结果列表，每个测试一个结果。每个测试结果本身是一个形如 $[t_{\\mathrm{final}}, h_{\\mathrm{min,acc}}, \\text{blew\\_up}, t_{\\mathrm{sing}} - t_{\\mathrm{final}}]$ 的列表。总输出必须是单行，由这些用逗号分隔的、并用方括号括起来的每个测试的列表组成，例如：[[t_final_A,hmin_A,flag_A,delta_A],[t_final_B,hmin_B,flag_B,delta_B],[t_final_C,hmin_C,flag_C,delta_C],[t_final_D,hmin_D,flag_D,delta_D]]。", "solution": "用户希望使用一个自行构建的自适应龙格－库塔求解器来求解一个表现出有限时间奇点的常微分方程 (ODE) 系统。\n\n### 第一步：提取已知信息\n\n- **常微分方程系统**：\n  $$\n  \\begin{cases}\n  \\frac{dr}{dt} = r^2, \\\\\n  \\frac{d\\theta}{dt} = 1,\n  \\end{cases}\n  $$\n- **初始条件**：$r(t_0) = r_0$, $\\theta(t_0) = \\theta_0$。\n- **求解器要求**：\n  - 一个自适应嵌入式显式龙格－库塔方法。\n  - 基于局部截断误差估计的步长自适应。\n  - 使用绝对容限 ($a_{\\mathrm{tol}}$) 和相对容限 ($r_{\\mathrm{tol}}$) 进行误差控制。\n  - 逐分量的误差缩放并聚合成单一误差范数。\n  - 步长拒绝和接受逻辑。\n- **终止条件**：\n  1.  求解器时间 $t$ 达到最终时间 $t_{\\mathrm{end}}$。\n  2.  自适应步长 $h$ 降至最小阈值 $h_{\\min}$ 以下。\n- **每个测试所需的输出**：\n  - $t_{\\mathrm{final}}$: 求解器达到的最终时间。\n  - $h_{\\mathrm{min,acc}}$: 遇到的最小的被接受的步长。\n  - `blew_up`: 一个布尔标志，如果因为 $h  h_{\\min}$ 而终止，则为真。\n  - $t_{\\mathrm{sing}} - t_{\\mathrm{final}}$: 理论爆破时间与求解器最终时间之差。\n- **测试套件**：\n  - 测试 A: $t_0 = 0$, $r_0 = 1$, $\\theta_0 = 0$, $t_{\\mathrm{end}} = 1.5$, $r_{\\mathrm{tol}} = 10^{-6}$, $a_{\\mathrm{tol}} = 10^{-8}$, $h_{\\min} = 10^{-12}$。\n  - 测试 B: $t_0 = 0$, $r_0 = 0.1$, $\\theta_0 = 0$, $t_{\\mathrm{end}} = 2$, $r_{\\mathrm{tol}} = 10^{-6}$, $a_{\\mathrm{tol}} = 10^{-8}$, $h_{\\min} = 10^{-12}$。\n  - 测试 C: $t_0 = 0$, $r_0 = 5$, $\\theta_0 = 0$, $t_{\\mathrm{end}} = 1$, $r_{\\mathrm{tol}} = 10^{-6}$, $a_{\\mathrm{tol}} = 10^{-8}$, $h_{\\min} = 10^{-12}$。\n  - 测试 D: $t_0 = 0$, $r_0 = 1$, $\\theta_0 = 0$, $t_{\\mathrm{end}} = 1.5$, $r_{\\mathrm{tol}} = 10^{-9}$, $a_{\\mathrm{tol}} = 10^{-12}$, $h_{\\min} = 10^{-12}$。\n\n### 第二步：使用提取的已知信息进行验证\n\n1.  **科学基础**：该问题基于常微分方程及其求解的数值方法的成熟理论。方程 $\\frac{dr}{dt} = r^2$ 是一个具有有限时间奇点（爆破）的常微分方程的典型例子。使用自适应龙格－库塔方法是科学计算中的一项标准和基本技术。该问题在数学和数值分析方面有坚实的基础。\n2.  **适定性**：该问题是适定的。给定初始条件的常微分方程系统具有唯一的局部解。任务是数值近似此解，直到它不再存在或达到预定时间。求解器的标准和所需的输出都已明确指定。\n3.  **客观性**：该问题以精确、客观的数学和计算语言陈述。没有主观或基于意见的成分。\n4.  **完整性**：每个测试用例的所有必要数据（$t_0, r_0, \\theta_0, t_{\\mathrm{end}}, r_{\\mathrm{tol}}, a_{\\mathrm{tol}}, h_{\\min}$）均已提供。常微分方程系统和数值方法的原理都已明确定义。\n\n### 第三步：结论与行动\n该问题是有效的。这是数值分析中一个标准的、定义明确的练习。我将继续进行求解。\n\n### 解析准备：奇点\n该系统由两个独立的常微分方程组成。$\\theta$ 的方程是平凡的：$\\frac{d\\theta}{dt} = 1$ 积分得到 $\\theta(t) = t - t_0 + \\theta_0$。关键的动力学在于 $r$ 分量：\n$$\n\\frac{dr}{dt} = r^2\n$$\n这是一个可分离方程。对于 $r \\neq 0$：\n$$\n\\frac{dr}{r^2} = dt\n$$\n将两边从初始条件 $(t_0, r_0)$ 积分到后来的状态 $(t, r(t))$：\n$$\n\\int_{r_0}^{r(t)} \\frac{1}{\\rho^2} d\\rho = \\int_{t_0}^t d\\tau\n$$\n$$\n\\left[ -\\frac{1}{\\rho} \\right]_{r_0}^{r(t)} = \\left[ \\tau \\right]_{t_0}^t\n$$\n$$\n-\\frac{1}{r(t)} + \\frac{1}{r_0} = t - t_0\n$$\n解出 $r(t)$：\n$$\n\\frac{1}{r(t)} = \\frac{1}{r_0} - (t - t_0)\n$$\n$$\nr(t) = \\frac{1}{\\frac{1}{r_0} - (t - t_0)}\n$$\n当分母变为零时，解 $r(t)$ 会“爆破”至无穷大。这定义了奇点时间 $t_{\\mathrm{sing}}$：\n$$\n\\frac{1}{r_0} - (t_{\\mathrm{sing}} - t_0) = 0 \\implies t_{\\mathrm{sing}} = t_0 + \\frac{1}{r_0}\n$$\n这个 $t_{\\mathrm{sing}}$ 的解析结果将用于评估数值求解器的性能。\n\n### 数值方法：自适应嵌入式龙格－库塔\n一个嵌入式龙格－库塔方法在单步内计算两个不同阶（比如 $p$ 和 $p+1$）的近似解。设高阶解为 $y_{n+1}$，低阶（嵌入式）解为 $y_{n+1}^*$。差值 $E_n = y_{n+1} - y_{n+1}^*$ 可作为低阶方法局部截断误差的估计。自适应算法的核心是调整步长 $h$，以将此误差估计保持在期望的容限内。\n1.  **误差缩放**：状态向量的每个分量 $j$ 的误差估计 $E_{n,j}$ 与一个容限尺度 $\\text{Tol}_j$ 进行比较：\n    $$\n    \\text{Tol}_j = a_{\\mathrm{tol}} + r_{\\mathrm{tol}} \\cdot \\max(|y_{n,j}|, |y_{n+1,j}|)\n    $$\n2.  **误差范数**：将各个缩放后的误差聚合成一个单一的标量范数。一个常见的选择是加权均方根：\n    $$\n    S = \\sqrt{\\frac{1}{D} \\sum_{j=1}^D \\left( \\frac{E_{n,j}}{\\text{Tol}_j} \\right)^2}\n    $$\n    其中 $D$ 是系统的维度（此问题中 $D=2$）。\n3.  **步长控制**：\n    - 如果 $S \\le 1$，则接受该步长。推进解：$t_{n+1} = t_n + h$，$y_{n+1} = y_{n+1}$（使用高阶结果）。\n    - 如果 $S  1$，则拒绝该步长。用更小的步长重试当前步。\n    - 无论哪种情况，都提出一个新的最佳步长 $h_{\\mathrm{new}}$：\n      $$\n      h_{\\mathrm{new}} = h \\cdot S_f \\cdot \\left( \\frac{1}{S} \\right)^{1/(p+1)}\n      $$\n      这里，$S_f$ 是一个安全因子（通常约为 0.9），$p$ 是嵌入（低阶）方法的阶数。新步长通常会受到约束，以防止过快的变化。\n\n对于此实现，将使用 Cash-Karp 4(5) 方法。这是一个著名的6级方法，提供一个5阶解和一个用于误差估计的嵌入式4阶解（因此 $p=4$）。Butcher 表定义了各级和解更新的系数。\n\n### 实现策略\n将开发一个 Python 程序来执行以下操作：\n1.  定义 ODE 系统 $\\frac{d\\vec{y}}{dt} = \\vec{f}(t, \\vec{y})$，其中 $\\vec{y} = [r, \\theta]^T$，$\\vec{f}(t, \\vec{y}) = [r^2, 1]^T$。\n2.  实现一个函数，该函数使用 Cash-Karp 系数执行上述自适应龙格－库塔步进逻辑。\n3.  对于提供的每个测试用例：\n    a. 计算理论奇点时间 $t_{\\mathrm{sing}} = t_0 + 1/r_0$。\n    b. 使用指定的参数运行自适应求解器。\n    c. 收集所需的输出：$t_{\\mathrm{final}}$、$h_{\\mathrm{min,acc}}$、`blew_up` 和 $t_{\\mathrm{sing}} - t_{\\mathrm{final}}$。\n4.  将收集到的结果格式化为单行输出，并遵循指定的列表嵌套列表结构。\n\n求解器将按照规定，使用 `numpy` 进行向量运算，从基本原理构建。最终代码将是独立的、可运行的。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the given ODE system for multiple test cases using an adaptive\n    Runge-Kutta method and formats the output as specified.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test A\n        {'t0': 0.0, 'r0': 1.0, 'theta0': 0.0, 'tend': 1.5, 'rtol': 1e-6, 'atol': 1e-8, 'hmin': 1e-12},\n        # Test B\n        {'t0': 0.0, 'r0': 0.1, 'theta0': 0.0, 'tend': 2.0, 'rtol': 1e-6, 'atol': 1e-8, 'hmin': 1e-12},\n        # Test C\n        {'t0': 0.0, 'r0': 5.0, 'theta0': 0.0, 'tend': 1.0, 'rtol': 1e-6, 'atol': 1e-8, 'hmin': 1e-12},\n        # Test D\n        {'t0': 0.0, 'r0': 1.0, 'theta0': 0.0, 'tend': 1.5, 'rtol': 1e-9, 'atol': 1e-12, 'hmin': 1e-12}\n    ]\n\n    # Cash-Karp 4(5) Butcher Tableau and properties.\n    # C: Nodes, A: Matrix, B: 5th-order weights, E: Error weights (B - B*), P: Lower order\n    C_CK = np.array([0., 1/5., 3/10., 3/5., 1., 7/8.], dtype=np.float64)\n    A_CK = np.array([\n        [0., 0., 0., 0., 0., 0.],\n        [1/5., 0., 0., 0., 0., 0.],\n        [3/40., 9/40., 0., 0., 0., 0.],\n        [3/10., -9/10., 6/5., 0., 0., 0.],\n        [-11/54., 5/2., -70/27., 35/27., 0., 0.],\n        [1631/55296., 175/512., 575/13824., 44275/110592., 253/4096., 0.]\n    ], dtype=np.float64)\n    B_CK = np.array([37/378., 0., 250/621., 125/594., 0., 512/1771.], dtype=np.float64)\n    B_STAR_CK = np.array([2825/27648., 0., 18575/48384., 13525/55296., 277/14336., 1/4.], dtype=np.float64)\n    E_CK = B_CK - B_STAR_CK\n    P_CK = 4\n    \n    def ode_func(t, y):\n        \"\"\" The ODE system: dr/dt = r^2, d(theta)/dt = 1 \"\"\"\n        r, theta = y\n        return np.array([r**2, 1.0], dtype=np.float64)\n\n    def adaptive_rk_solver(f, t0, y0, tend, rtol, atol, hmin):\n        \"\"\"\n        Implements an adaptive embedded Runge-Kutta solver using the Cash-Karp 4(5) method.\n        \"\"\"\n        # Solver control parameters\n        SAFETY_FACTOR = 0.9\n        MAX_GROWTH = 5.0\n        MIN_SHRINK = 0.2\n        \n        # Initialization\n        t = float(t0)\n        y = np.array(y0, dtype=np.float64)\n        h = 1e-6  # A conservative initial step size\n\n        h_min_accepted = float('inf')\n        blew_up = False\n        \n        while t  tend:\n            # Check for termination due to step size limit\n            if h  hmin:\n                blew_up = True\n                break\n            \n            # Ensure the last step does not overshoot the end time\n            if t + h > tend:\n                h = tend - t\n            \n            # If the remaining interval is too small, break\n            if h = 0:\n                break\n\n            # Calculate the six stages (K_i) for the Cash-Karp method\n            K = np.zeros((6, len(y0)), dtype=np.float64)\n            for i in range(6):\n                y_stage_update = h * np.dot(A_CK[i, :i], K[:i, :])\n                y_stage = y + y_stage_update\n                K[i, :] = f(t + C_CK[i] * h, y_stage)\n\n            # Compute the higher-order (5th) solution and the error estimate\n            y_next = y + h * np.dot(K.T, B_CK)\n            error_est = h * np.dot(K.T, E_CK)\n\n            # Compute the error norm\n            scale = atol + rtol * np.maximum(np.abs(y), np.abs(y_next))\n            scale[scale = 0] = atol # Prevent division by zero or negative scale\n            \n            error_norm = np.sqrt(np.mean((error_est / scale)**2))\n\n            # Step size control logic\n            if error_norm = 1.0:  # Step accepted\n                h_min_accepted = min(h_min_accepted, h)\n                t += h\n                y = y_next\n                \n                # Propose new step size\n                if error_norm == 0.0:\n                    h_new = h * MAX_GROWTH\n                else:\n                    h_new = h * SAFETY_FACTOR * (1.0 / error_norm)**(1.0 / (P_CK + 1))\n                h = min(h_new, h * MAX_GROWTH)\n            else:  # Step rejected\n                # Propose new (smaller) step size\n                h_new = h * SAFETY_FACTOR * (1.0 / error_norm)**(1.0 / (P_CK + 1))\n                h = max(h_new, h * MIN_SHRINK)\n        \n        t_final = t\n        if np.isinf(h_min_accepted):\n            h_min_accepted = 0.0  # Case where no steps were accepted\n        \n        return t_final, h_min_accepted, blew_up\n\n    results = []\n    for case in test_cases:\n        y0 = [case['r0'], case['theta0']]\n        \n        # Calculate theoretical singularity time\n        t_sing = case['t0'] + 1.0/case['r0'] if case['r0'] != 0 else float('inf')\n\n        # Run the solver\n        t_final, h_min_acc, blew_up = adaptive_rk_solver(\n            ode_func, case['t0'], y0, case['tend'], \n            case['rtol'], case['atol'], case['hmin']\n        )\n        \n        # Calculate the difference to the singularity\n        delta_t = t_sing - t_final\n        \n        results.append([t_final, h_min_acc, blew_up, delta_t])\n\n    # Final print statement in the exact required format.\n    # Manually construct the string to avoid spaces from standard list conversion.\n    list_of_strs = []\n    for res in results:\n        res_str = f\"[{res[0]},{res[1]},{str(res[2]).lower()},{res[3]}]\"\n        list_of_strs.append(res_str)\n    final_output = f\"[{','.join(list_of_strs)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "3205626"}]}