{"hands_on_practices": [{"introduction": "这个首个练习将我们带回基础。在编写复杂代码之前，熟练掌握牛顿法的核心公式至关重要。本练习 [@problem_id:3255024] 要求你将该方法应用于一个巧妙选择的函数 $f(x) = 1/x - a$，并通过代数操作，推导出一个著名的、用于计算倒数的高效算法，而这个算法本身竟能完全避免除法运算。", "problem": "设 $a \\neq 0$ 为一个固定的实数常数，考虑通过使用牛顿法求解标量求根问题 $f(x) = 1/x - a = 0$ 来计算其倒数 $1/a$。仅使用标量方程的牛顿法的核心定义和基本代数，推导出一个在其计算中不需要任何显式除法的迭代更新式。你的推导应从牛顿法的一般定义开始，并通过符号操作进行，直到除法运算被抵消。假设使用精确算术，不引入近似。将最终的更新映射 $T(x)$ 以一个只包含乘法和加/减法的单一闭式表达式的形式给出。最终答案必须是这个单一的表达式。", "solution": "基本依据是标量方程的牛顿法定义。给定一个可微函数 $f(x)$，用于近似 $f(x) = 0$ 的一个根 $x^{\\ast}$ 的牛顿迭代法是\n$$\nx_{k+1} = x_k - \\frac{f(x_k)}{f'(x_k)}.\n$$\n我们将此方法应用于函数 $f(x) = \\frac{1}{x} - a$，其中 $a \\neq 0$ 是一个实数常数。首先计算其导数：\n$$\nf'(x) = -\\frac{1}{x^{2}}.\n$$\n将 $f(x_k)$ 和 $f'(x_k)$ 代入牛顿更新公式：\n$$\nx_{k+1} = x_k - \\frac{\\frac{1}{x_k} - a}{-\\frac{1}{x_k^{2}}}.\n$$\n我们现在对商进行符号化简，以消除最终形式中的显式除法。化简该分式：\n$$\n\\frac{\\frac{1}{x_k} - a}{-\\frac{1}{x_k^{2}}} = \\left(\\frac{1}{x_k} - a\\right)\\left(-x_k^{2}\\right) = -x_k + a x_k^{2}.\n$$\n因此，\n$$\nx_{k+1} = x_k - \\left(-x_k + a x_k^{2}\\right) = x_k + x_k - a x_k^{2} = x_k\\left(2 - a x_k\\right).\n$$\n这个表达式只涉及乘法和加/减法，不包含显式的除法运算。因此，一旦推导出这个闭式形式，该迭代就可以在没有除法的情况下实现。\n\n为完整起见，我们验证该迭代确实以倒数为目标。设 $x^{\\ast} = \\frac{1}{a}$ 是 $f(x) = 0$ 的精确根。定义误差 $e_k = x_k - x^{\\ast}$。使用更新式 $x_{k+1} = x_k(2 - a x_k)$，\n$$\ne_{k+1} = x_k(2 - a x_k) - \\frac{1}{a}.\n$$\n代入 $x_k = \\frac{1}{a} + e_k$：\n$$\ne_{k+1} = \\left(\\frac{1}{a} + e_k\\right)\\left(2 - a\\left(\\frac{1}{a} + e_k\\right)\\right) - \\frac{1}{a}\n= \\left(\\frac{1}{a} + e_k\\right)\\left(2 - 1 - a e_k\\right) - \\frac{1}{a}\n= \\left(\\frac{1}{a} + e_k\\right)\\left(1 - a e_k\\right) - \\frac{1}{a}.\n$$\n展开：\n$$\ne_{k+1} = \\frac{1}{a} - e_k - a e_k^{2} - \\frac{1}{a} = -a e_k^{2}.\n$$\n因此，该方法在 $x^{\\ast}$ 附近表现出二次收敛性，并且该迭代形式与牛顿法一致，同时其计算仅需要乘法和加/减法。因此，所求的更新映射 $T(x)$ 是\n$$\nT(x) = x\\left(2 - a x\\right).\n$$", "answer": "$$\\boxed{x\\left(2 - a x\\right)}$$", "id": "3255024"}, {"introduction": "纯粹的牛顿法虽然强大，但如果初始猜测远离根，就可能发生灾难性的失败，这种现象被称为“过冲”(overshoot)。本练习 [@problem_id:3255187] 使用函数 $f(x) = \\arctan(x)$ 提供了一个经典示例，并指导你实现一个关键的改进：带有回溯线搜索的阻尼牛顿法。通过比较无阻尼和阻尼版本的行为，你将亲身体验到使求根算法变得稳健和具备全局收敛性的最重要技术之一。", "problem": "考虑由函数 $f(x)=\\arctan(x)$ 定义的标量非线性方程，其中 $\\arctan(\\cdot)$ 返回以弧度为单位的角度。你的任务是分析为什么当 $|x|$ 较大时，直接应用经典牛顿迭代会表现出“过冲”行为，并实现一个能够避免此陷阱的全局收敛的阻尼牛顿算法。\n\n从以下基本原理出发：可微函数 $f(x)$ 在点 $x$ 附近的一阶泰勒展开，即 $f(x+s)\\approx f(x)+f^{\\prime}(x)\\,s$，以及求根迭代试图通过求解局部线性模型来选择一个增量 $s$，以近似满足 $f(x+s)=0$。以此为基础，推导出无阻尼牛顿搜索方向，推导过程不依赖任何现成的快捷公式。然后，对于函数 $f(x)=\\arctan(x)$，分析当 $|x|$ 很大时该方向的渐近行为，并解释为什么会发生“过冲”（即步长过大，远超根的位置）。\n\n设计并实现两个用于 $f(x)=\\arctan(x)$ 的迭代求解器：\n\n- 一个无阻尼牛顿法，该方法应用推导出的搜索方向并采用完整步长，残差 $|f(x)|$ 的停止容差为 $\\varepsilon=10^{-12}$，最大迭代次数为 $50$ 次。如果任何迭代值变为非有限数，或在迭代过程中 $|x|$ 超过 $10^{16}$，则视为迭代失败。\n\n- 一个阻尼牛顿法，该方法使用相同的搜索方向，但通过回溯线搜索（Backtracking Line Search, BLS）选择一个步长 $\\lambda\\in(0,1]$，以确保价值函数 $\\phi(x)=\\tfrac{1}{2}f(x)^{2}$ 的充分下降。使用充分下降（Armijo）条件\n$$\n\\phi(x+\\lambda p)\\le \\phi(x)-2c\\,\\lambda\\,\\phi(x),\n$$\n参数设置为 $c=10^{-4}$，几何回溯因子 $\\beta=\\tfrac{1}{2}$，初始试探步长 $\\lambda=1$。如果线搜索在 $100$ 次回溯缩减内未能找到合适的步长，或者任何候选迭代值变为非有限数或满足 $|x|>10^{16}$，则声明失败。使用与无阻尼方法相同的残差容差 $\\varepsilon=10^{-12}$ 和最大外层迭代次数 $50$ 次。\n\n测试套件和输出规范：\n\n- 使用初始值 $x_{0}\\in\\{0,1,10,10^{3},-10^{3}\\}$。\n\n- 对于每个初始值，运行无阻尼和阻尼求解器。报告每个求解器达到 $|f(x)|\\le \\varepsilon$ 所需的整数迭代次数。如果某个求解器根据上述标准失败，则对该初始值报告 $-1$。\n\n- 最终的程序输出必须是单行，其中包含一个方括号内的逗号分隔列表，按以下顺序汇总结果：\n$[k_{\\text{undamped}}(0),k_{\\text{damped}}(0),k_{\\text{undamped}}(1),k_{\\text{damped}}(1),k_{\\text{undamped}}(10),k_{\\text{damped}}(10),k_{\\text{undamped}}(10^{3}),k_{\\text{damped}}(10^{3}),k_{\\text{undamped}}(-10^{3}),k_{\\text{damped}}(-10^{3})]$,\n其中 $k_{\\text{undamped}}(x_{0})$ 和 $k_{\\text{damped}}(x_{0})$ 表示对应初始值 $x_{0}$ 的如上定义的迭代次数。每个条目必须是整数。\n\n你的实现必须是完全自包含的。不允许用户输入。程序打印的最后一行必须严格符合指定的列表格式。", "solution": "我们从一阶泰勒模型开始。对于一个可微的标量函数 $f(x)$ 和当前迭代点 $x$，一个小增量 $s$ 满足\n$$\nf(x+s)\\approx f(x)+f^{\\prime}(x)\\,s.\n$$\n为了寻找根，我们令模型方程 $f(x)+f^{\\prime}(x)\\,s=0$ 成立并求解 $s$，从而得到无阻尼牛顿搜索方向\n$$\np=-\\frac{f(x)}{f^{\\prime}(x)}.\n$$\n相应的采用完整步长的无阻尼迭代为 $x_{+}=x+p$。\n\n对于特定函数 $f(x)=\\arctan(x)$，我们有 $f^{\\prime}(x)=\\dfrac{1}{1+x^{2}}$。因此，无阻尼牛顿方向的形式为\n$$\np=-\\frac{\\arctan(x)}{\\tfrac{1}{1+x^{2}}}=-(1+x^{2})\\,\\arctan(x).\n$$\n为了理解过冲现象，考虑当 $|x|$ 很大时 $\\arctan(x)$ 的渐近行为。当 $x\\to+\\infty$ 时，$\\arctan(x)\\to \\frac{\\pi}{2}$；当 $x\\to-\\infty$ 时，$\\arctan(x)\\to -\\frac{\\pi}{2}$。更精确地，当 $|x|\\to\\infty$ 时，可以使用展开式 $\\arctan(x)=\\operatorname{sgn}(x)\\,\\frac{\\pi}{2}-\\frac{1}{x}+O(x^{-3})$。将此与 $f^{\\prime}(x)=\\dfrac{1}{1+x^{2}}$ 结合，对于大的 $|x|$，可得\n$$\np\\approx -\\left(1+x^{2}\\right)\\left(\\operatorname{sgn}(x)\\,\\frac{\\pi}{2}\\right)\\sim -\\operatorname{sgn}(x)\\,\\frac{\\pi}{2}\\,x^{2}.\n$$\n因此，完整步长的更新 $x_{+}=x+p$ 的行为类似于\n$$\nx_{+}\\sim x-\\operatorname{sgn}(x)\\,\\frac{\\pi}{2}\\,x^{2},\n$$\n其绝对值随 $|x|$ 呈二次方增长。这会在根 $x=0$ 两侧产生巨大的跳跃，并通常导致迭代值符号交替出现，同时其绝对值不断增大，这是从远离根部开始的无阻尼方法出现“过冲”和发散的典型特征。\n\n为了获得一个全局收敛的方法，我们保留牛顿方向 $p$，但使用基于价值函数的线搜索来对步长进行阻尼。一个标准的选择是残差平方价值函数\n$$\n\\phi(x)=\\frac{1}{2}\\,f(x)^{2}.\n$$\n其导数为 $\\phi^{\\prime}(x)=f(x)\\,f^{\\prime}(x)$。沿牛顿方向 $p$ 的方向导数为\n$$\n\\phi^{\\prime}(x)\\,p=f(x)\\,f^{\\prime}(x)\\,\\left(-\\frac{f(x)}{f^{\\prime}(x)}\\right)=-f(x)^{2}=-2\\,\\phi(x)\n$$\n只要 $f(x)\\neq 0$，$p$ 就是 $\\phi$ 的一个严格下降方向。回溯线搜索（Backtracking Line Search, BLS）通过选择一个步长 $\\lambda\\in(0,1]$ 来确保充分下降，使得 Armijo 条件成立：\n$$\n\\phi(x+\\lambda p)\\le \\phi(x)+c\\,\\lambda\\,\\phi^{\\prime}(x)\\,p=\\phi(x)-c\\,\\lambda\\,f(x)^{2}=\\phi(x)-2c\\,\\lambda\\,\\phi(x),\n$$\n其中 $c\\in(0,1/2)$。从 $\\lambda=1$ 开始，并以 $\\beta\\in(0,1)$ 的比例缩减 $\\lambda\\leftarrow\\beta\\,\\lambda$，直到该不等式被满足，这样可以产生一个以 $0$ 为下界的单调递减序列 $\\{\\phi(x_{k})\\}$，从而保证了价值函数值的收敛，并为牛顿法提供了一个鲁棒的全局化策略。对于 $f(x)=\\arctan(x)$，当 $|x|$ 很大时，这种阻尼策略通过急剧减小 $\\lambda$ 来避免平方级的大步长，从而将迭代值推向根。\n\n算法设计：\n\n- 无阻尼法：用 $x_{0}$ 初始化，然后迭代 $x_{k+1}=x_{k}+p_{k}$，其中 $p_{k}=-\\dfrac{f(x_{k})}{f^{\\prime}(x_{k})}$，直到 $|f(x_{k})|\\le \\varepsilon$ 或 $k$ 达到最大迭代次数。如果任何 $x_{k}$ 为非有限数或 $|x_{k}|>10^{16}$，则声明失败。\n\n- 阻尼法：在每次迭代中，计算相同的 $p_{k}$，并执行一个从 $\\lambda=1$ 开始、$\\beta=\\tfrac{1}{2}$、 $c=10^{-4}$ 的回溯搜索，接受第一个满足\n$$\n\\phi(x_{k}+\\lambda p_{k})\\le \\phi(x_{k})-2c\\,\\lambda\\,\\phi(x_{k})\n$$\n的 $\\lambda$。更新 $x_{k+1}=x_{k}+\\lambda p_{k}$。使用相同的停止和失败条件，并将回溯次数限制在 100 次缩减以内。\n\n测试套件：\n\n- 起始点 $x_{0}\\in\\{0,1,10,10^{3},-10^{3}\\}$ 用于探查一个平凡的精确根、一个中等距离的情况，以及无阻尼牛顿法会发生过冲的严峻大数值情况。\n\n预期的定性结果：\n\n- 对于 $x_{0}=0$，由于 $f(0)=0$，两种方法都会立即终止，迭代次数为 $0$。\n\n- 对于 $x_{0}=1$，无阻尼法会在几次迭代内快速收敛；阻尼法在解附近通常会接受完整步长，其迭代次数会与无阻尼法相匹配或相近。\n\n- 对于 $x_{0}=10$、$x_{0}=10^{3}$ 和 $x_{0}=-10^{3}$，无阻尼法会表现出过冲并在给定的安全措施下失败，而阻尼法则通过回溯来控制步长，并在允许的迭代次数内收敛。\n\n程序必须打印单行列表\n$[k_{\\text{undamped}}(0),k_{\\text{damped}}(0),k_{\\text{undamped}}(1),k_{\\text{damped}}(1),k_{\\text{undamped}}(10),k_{\\text{damped}}(10),k_{\\text{undamped}}(10^{3}),k_{\\text{damped}}(10^{3}),k_{\\text{undamped}}(-10^{3}),k_{\\text{damped}}(-10^{3})]$,\n其中每个 $k$ 是收敛时的迭代次数（整数），或按定义失败时为 $-1$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef f(x: float) -> float:\n    # f(x) = arctan(x)\n    return float(np.arctan(x))\n\ndef fprime(x: float) -> float:\n    # f'(x) = 1 / (1 + x^2)\n    return 1.0 / (1.0 + x * x)\n\ndef phi(x: float) -> float:\n    # phi(x) = 0.5 * f(x)^2\n    fx = f(x)\n    return 0.5 * fx * fx\n\ndef is_finite_scalar(x: float) -> bool:\n    return np.isfinite(x)\n\ndef newton_undamped(x0: float, tol: float = 1e-12, max_iter: int = 50,\n                    blowup: float = 1e16) -> int:\n    # Return iteration count to reach |f(x)| <= tol, else -1 on failure\n    x = float(x0)\n    fx = f(x)\n    if not is_finite_scalar(x) or not is_finite_scalar(fx):\n        return -1\n    if abs(fx) <= tol:\n        return 0\n    for k in range(1, max_iter + 1):\n        fpx = fprime(x)\n        # For arctan, f'(x) > 0 always; check safety anyway.\n        if not is_finite_scalar(fpx) or fpx == 0.0:\n            return -1\n        step = -fx / fpx\n        x_new = x + step\n        if not is_finite_scalar(x_new) or abs(x_new) > blowup:\n            return -1\n        x = x_new\n        fx = f(x)\n        if not is_finite_scalar(fx):\n            return -1\n        if abs(fx) <= tol:\n            return k\n    return -1\n\ndef newton_damped(x0: float, tol: float = 1e-12, max_iter: int = 50,\n                  c: float = 1e-4, beta: float = 0.5, max_backtrack: int = 100,\n                  blowup: float = 1e16) -> int:\n    # Return iteration count to reach |f(x)| <= tol, else -1 on failure\n    x = float(x0)\n    fx = f(x)\n    if not is_finite_scalar(x) or not is_finite_scalar(fx):\n        return -1\n    if abs(fx) <= tol:\n        return 0\n    for k in range(1, max_iter + 1):\n        fpx = fprime(x)\n        if not is_finite_scalar(fpx) or fpx == 0.0:\n            return -1\n        p = -fx / fpx\n        phi_x = 0.5 * fx * fx\n        lam = 1.0\n        accepted = False\n        for _ in range(max_backtrack):\n            x_trial = x + lam * p\n            if not is_finite_scalar(x_trial) or abs(x_trial) > blowup:\n                lam *= beta\n                continue\n            phi_trial = phi(x_trial)\n            # Armijo: phi(x + lam p) <= phi(x) - 2 c lam phi(x)\n            if phi_trial <= phi_x - 2.0 * c * lam * phi_x:\n                x = x_trial\n                fx = f(x)\n                accepted = True\n                break\n            lam *= beta\n        if not accepted:\n            return -1\n        if not is_finite_scalar(fx):\n            return -1\n        if abs(fx) <= tol:\n            return k\n    return -1\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [0.0, 1.0, 10.0, 1.0e3, -1.0e3]\n\n    results = []\n    for x0 in test_cases:\n        ku = newton_undamped(x0, tol=1e-12, max_iter=50, blowup=1e16)\n        kd = newton_damped(x0, tol=1e-12, max_iter=50, c=1e-4, beta=0.5,\n                           max_backtrack=100, blowup=1e16)\n        results.append(int(ku))\n        results.append(int(kd))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3255187"}, {"introduction": "拥有一个稳健的算法固然很好，但理解其性能极限才是区分从业者和专家的关键。这最后一个练习 [@problem_id:3255046] 深入探讨了病态条件 (ill-conditioning) 和收敛速度的概念。通过构造一个具有“近水平”根的函数，你将研究解附近的微小导数如何影响问题的敏感性和方法的收敛率，学会使用分析工具来预测和理解牛顿法在挑战性场景下的行为。", "problem": "考虑标量非线性方程 $f(x) = \\varepsilon x - \\sin x$，其中 $x$ 以弧度为单位。目标是分析当 $\\varepsilon$ 极小时，近水平交叉点与牛顿法求解标量方程性能之间的相互作用。使用一阶 Taylor 展开（线性化 $f(x+\\Delta) \\approx f(x) + f'(x)\\Delta$）作为基本原理，推导出一个迭代方法来近似求解 $f(x)=0$ 的一个根。您必须将此方法实现在一个无需用户输入的、完整的、可运行的程序中，并用它来研究收敛行为和条件数。\n\n为了创建一个近水平交叉点，选择参数值使得方程在一个斜率 $f'(x)$ 极小的点上有一个精确的单根。对于一个非负整数 $n$，令 $x_m = \\frac{\\pi}{2} + 2\\pi n$，并设置 $\\varepsilon = \\frac{1}{x_m}$。这样就有 $f(x_m) = 0$ 且 $f'(x_m) = \\varepsilon - \\cos x_m = \\frac{1}{x_m}$，当 $x_m$ 很大时，该值很小。角度必须以弧度为单位进行解释。\n\n实现从一阶 Taylor 原理推导出的迭代方案，包含一个基于残差 $\\lvert f(x_k)\\rvert \\leq 10^{-12}$ 或最大 $100$ 次迭代的停止规则（以先到者为准），并使用纯牛顿步长，不带启发式阻尼。对于每个测试用例，从指定的偏移量 $\\delta$ 的初始猜测 $x_0 = x_m + \\delta$ 开始，并运行您的算法。\n\n对于每个测试用例，报告以下量：\n- 一个布尔值，指示是否在迭代预算内满足了基于残差的停止规则。\n- 执行的迭代次数（整数）。\n- 根的最终浮点近似值。\n- 相对于已知精确根 $x_m$ 的浮点绝对误差 $\\lvert x_{\\text{approx}} - x_m\\rvert$。\n- 在精确根处评估的灵敏度（条件数）的浮点数量级 $\\left\\lvert \\frac{\\partial x^*}{\\partial \\varepsilon} \\right\\rvert$，该值通过对 $f(x)=0$ 关于 $\\varepsilon$ 进行隐式微分得到。\n- 在精确根处评估的牛顿渐近二次误差常数 $c = \\left\\lvert \\frac{f''(x^*)}{2 f'(x^*)} \\right\\rvert$ 的浮点数量级，其中 $x^*$ 表示精确根。\n\n使用以下测试套件，它涵盖了一个一般情况、一个条件数逐渐变差的情况以及一个在迭代预算内可能不会收敛的具有挑战性的极端情况：\n- 测试 1：$n = 3$, $\\delta = 10^{-2}$。\n- 测试 2：$n = 50$, $\\delta = 10^{-3}$。\n- 测试 3：$n = 2000$, $\\delta = 10^{-2}$。\n\n所有角度均以弧度为单位。灵敏度和渐近常数必须使用 $f'(x) = \\varepsilon - \\cos x$ 和 $f''(x) = \\sin x$ 进行符号计算，然后在精确根 $x_m$ 处，使用 $\\varepsilon = \\frac{1}{x_m}$ 进行求值。您的程序应生成单行输出，其中包含以逗号分隔的列表形式聚合的结果，并用方括号括起来，每个测试用例一个列表，顺序如下：$[\\,[\\text{案例 1 结果}], [\\text{案例 2 结果}], [\\text{案例 3 结果}]\\,]$。每个案例的列表必须按以下顺序排列：$[\\text{converged}, \\text{iterations}, x_{\\text{approx}}, \\lvert x_{\\text{approx}} - x_m\\rvert, \\left\\lvert \\frac{\\partial x^*}{\\partial \\varepsilon} \\right\\rvert, c]$。", "solution": "### 解决方案推导\n解决方案涉及推导迭代算法和必要的解析量，然后实现算法以处理指定的测试用例。\n\n**1. 迭代方法的推导**\n问题要求从 $f(x)$ 在迭代点 $x_k$ 周围的一阶 Taylor 展开推导出一个迭代方法：\n$$f(x_k + \\Delta x) \\approx f(x_k) + f'(x_k)\\Delta x$$\n为了找到根，我们寻求一个校正量 $\\Delta x$ 使得 $f(x_k + \\Delta x) = 0$。将线性近似设为零可得：\n$$f(x_k) + f'(x_k)\\Delta x = 0$$\n解出 $\\Delta x$ 得到校正步长：\n$$\\Delta x = -\\frac{f(x_k)}{f'(x_k)}$$\n这导出了下一个近似值 $x_{k+1} = x_k + \\Delta x$ 的迭代公式：\n$$x_{k+1} = x_k - \\frac{f(x_k)}{f'(x_k)}$$\n这就是牛顿法。对于给定的函数 $f(x) = \\varepsilon x - \\sin x$ 及其导数 $f'(x) = \\varepsilon - \\cos x$，具体的迭代公式为：\n$$x_{k+1} = x_k - \\frac{\\varepsilon x_k - \\sin x_k}{\\varepsilon - \\cos x_k}$$\n\n**2. 根灵敏度的推导**\n根 $x^*$ 对参数 $\\varepsilon$ 变化的灵敏度由导数 $\\frac{\\partial x^*}{\\partial \\varepsilon}$ 给出。我们从根的隐式定义 $f(x^*(\\varepsilon), \\varepsilon) = 0$ 开始，即 $\\varepsilon x^*(\\varepsilon) - \\sin(x^*(\\varepsilon)) = 0$。使用乘法法则和链式法则对 $\\varepsilon$ 求导：\n$$\\frac{d}{d\\varepsilon} \\left( \\varepsilon x^* - \\sin(x^*) \\right) = (1 \\cdot x^* + \\varepsilon \\cdot \\frac{dx^*}{d\\varepsilon}) - \\cos(x^*) \\cdot \\frac{dx^*}{d\\varepsilon} = 0$$\n对包含 $\\frac{dx^*}{d\\varepsilon}$ 的项进行分组：\n$$x^* + (\\varepsilon - \\cos x^*) \\frac{dx^*}{d\\varepsilon} = 0$$\n注意到 $\\varepsilon - \\cos x^* = f'(x^*)$，我们有 $x^* + f'(x^*) \\frac{dx^*}{d\\varepsilon} = 0$。解出灵敏度：\n$$\\frac{dx^*}{d\\varepsilon} = -\\frac{x^*}{f'(x^*)}$$\n该式必须在精确根 $x^* = x_m$ 处求值。在该点，$f'(x_m) = \\frac{1}{x_m}$。\n$$\\left. \\frac{\\partial x^*}{\\partial \\varepsilon} \\right|_{x_m} = -\\frac{x_m}{1/x_m} = -x_m^2$$\n问题要求的是其大小，即 $\\left\\lvert -x_m^2 \\right\\rvert = x_m^2$。\n\n**3. 渐近误差常数的推导**\n牛顿法的渐近二次误差常数是 $c = \\left\\lvert \\frac{f''(x^*)}{2 f'(x^*)} \\right\\rvert$。二阶导数为 $f''(x) = \\frac{d}{dx}(\\varepsilon - \\cos x) = \\sin x$。\n我们在精确根 $x^* = x_m$ 处计算 $c$：\n- $f'(x_m) = \\frac{1}{x_m}$\n- $f''(x_m) = \\sin(x_m) = \\sin(\\frac{\\pi}{2} + 2\\pi n) = 1$\n将这些值代入 $c$ 的公式中：\n$$c = \\left\\lvert \\frac{1}{2(1/x_m)} \\right\\rvert = \\left\\lvert \\frac{x_m}{2} \\right\\rvert$$\n由于对于非负整数 $n$，有 $x_m = \\frac{\\pi}{2} + 2\\pi n > 0$，因此常数为 $c = \\frac{x_m}{2}$。\n\n**4. 实现计划**\n将编写一个程序，为每个测试用例 $(n, \\delta)$ 执行以下逻辑：\n1. 计算 $x_m = \\frac{\\pi}{2} + 2\\pi n$ 和 $\\varepsilon = 1/x_m$。\n2. 初始化迭代值 $x_k = x_m + \\delta$。\n3. 循环最多 100 次迭代：\n    a. 计算残差 $f(x_k)$。如果 $\\lvert f(x_k) \\rvert \\le 10^{-12}$，将收敛状态设为真，记录迭代次数，并终止循环。\n    b. 计算导数 $f'(x_k)$。如果为零，方法失败；终止循环。\n    c. 使用牛顿步长更新迭代值：$x_{k+1} = x_k - f(x_k)/f'(x_k)$。\n4. 循环终止后（无论是通过收敛、失败还是达到 100 次迭代限制），计算所需的输出量：收敛状态、迭代次数、最终近似值 $x_{\\text{approx}}$、绝对误差 $\\lvert x_{\\text{approx}} - x_m\\rvert$、灵敏度 $x_m^2$ 和渐近常数 $x_m/2$。\n5. 收集所有测试用例的结果，并按指定格式打印。$n$ 的值从 $3$ 增加到 $2000$，使得根的条件数逐渐变差，因为灵敏度 $x_m^2$ 和误差常数 $c = x_m/2$ 都在增长，这为算法的行为提供了一个鲁棒的测试。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem, orchestrating the test cases and printing the final result.\n    \"\"\"\n\n    def run_newton_for_case(n, delta):\n        \"\"\"\n        Executes Newton's method for a single test case (n, delta).\n        \n        Args:\n            n (int): The non-negative integer parameter for defining the root.\n            delta (float): The initial offset from the exact root.\n            \n        Returns:\n            A list containing the results for the case in the specified format.\n        \"\"\"\n        # Setup problem parameters based on the test case\n        pi = np.pi\n        xm = pi / 2.0 + 2.0 * pi * float(n)\n        eps = 1.0 / xm\n        \n        # Algorithm parameters from the problem statement\n        x_k = xm + delta\n        max_iterations = 100\n        tolerance = 1e-12\n        \n        # Run Newton's method\n        for k in range(max_iterations):\n            # Calculate the residual f(x_k)\n            f_val = eps * x_k - np.sin(x_k)\n            \n            # Check for convergence based on the residual tolerance\n            if np.abs(f_val) <= tolerance:\n                # Convergence achieved, calculate final metrics and return\n                abs_error = np.abs(x_k - xm)\n                sensitivity = xm**2\n                asymptotic_constant = xm / 2.0\n                return [True, k, x_k, abs_error, sensitivity, asymptotic_constant]\n            \n            # Calculate the derivative f'(x_k) for the Newton step\n            fp_val = eps - np.cos(x_k)\n            \n            # Check for division by zero (catastrophic failure)\n            if fp_val == 0.0:\n                # Iteration failed. Report non-convergence.\n                abs_error = np.abs(x_k - xm)\n                sensitivity = xm**2\n                asymptotic_constant = xm / 2.0\n                # k+1 iterations were attempted before failure.\n                return [False, k + 1, x_k, abs_error, sensitivity, asymptotic_constant]\n            \n            # Perform the Newton update step\n            x_k = x_k - f_val / fp_val\n\n        # If the loop completes, the maximum number of iterations was reached without convergence\n        abs_error = np.abs(x_k - xm)\n        sensitivity = xm**2\n        asymptotic_constant = xm / 2.0\n        return [False, max_iterations, x_k, abs_error, sensitivity, asymptotic_constant]\n\n    # Define the test suite from the problem statement.\n    test_cases = [\n        (3, 1e-2),\n        (50, 1e-3),\n        (2000, 1e-2),\n    ]\n\n    all_results = []\n    for case in test_cases:\n        n_val, delta_val = case\n        result = run_newton_for_case(n_val, delta_val)\n        all_results.append(result)\n\n    # Final print statement. The default string representation of a list of lists \n    # in Python matches the required output format \"[ [case1], [case2], ... ]\".\n    print(all_results)\n\n# Execute the solver\nsolve()\n```", "id": "3255046"}]}