{"hands_on_practices": [{"introduction": "牛顿法的主要吸引力在于其快速的二次收敛性，但这依赖于一个关键假设：根是“简单”的，即在根处函数的导数不为零 ($f'(x^\\star) \\neq 0$)。本练习通过一个精心选择的函数 $f(x) = x|x|$，引导我们分析当这个条件不满足时会发生什么。你将通过精确的代数推导，揭示当根不是简单根时，牛顿法是如何失去其二次收敛特性并退化为线性收敛的。[@problem_id:3262164]", "problem": "考虑由函数 $f(x)=x|x|$ 定义的非线性方程。方程 $f(x)=0$ 在 $x=0$ 处有一个根。请分析从此函数的一个任意非零初始猜测值开始，应用牛顿法时的行为。\n\n请仅使用标量函数的牛顿法核心定义（即当 $f^{\\prime}(x_{k})\\neq 0$ 时，迭代公式为 $x_{k+1}=x_{k}-\\frac{f(x_{k})}{f^{\\prime}(x_{k})}$）和微积分的标准可微性法则，为该函数 $f$ 推导精确的迭代映射。对于所有 $x_{k}\\neq 0$，将其简化为 $x_k$ 的函数，然后通过迭代得到 $x_n$ 关于 $x_0$ 和 $n$（对于所有 $n \\in \\mathbb{N}$）的闭式表达式。利用你得到的显式表达式，通过计算以下极限来确定牛顿迭代序列趋近于根 $x^{\\star}=0$ 的渐近速率：\n$$\nL=\\lim_{k\\to\\infty}\\frac{|x_{k+1}-x^{\\star}|}{|x_{k}-x^{\\star}|}.\n$$\n\n请仅使用牛顿法局部收敛理论中通常引用的基本条件，仔细解释在本问题中哪个（些）条件不成立，以及这种不成立如何体现在所计算的极限中。你的最终答案必须是 $L$ 的精确实数值（无需四舍五入）。", "solution": "本题要求分析将牛顿法应用于函数 $f(x) = x|x|$ 以求根 $x^{\\star} = 0$ 的过程。分析内容包括推导迭代映射、寻找迭代序列的闭式表达式、以及计算渐近收敛速率。最后，需要通过指出牛顿法收敛理论的标准条件中哪个不成立，来解释为什么收敛不是二次的。\n\n首先，我们推导牛顿法的迭代公式，其形式为 $x_{k+1} = x_{k} - \\frac{f(x_{k})}{f'(x_{k})}$。我们必须计算 $f(x) = x|x|$ 的导数。该函数可以写成分段形式：\n$$\nf(x) = \\begin{cases}\nx^2  & \\text{若 } x \\ge 0 \\\\\n-x^2 & \\text{若 } x  0\n\\end{cases}\n$$\n对于 $x \\neq 0$，$f(x)$ 的导数可以对每一段分别计算：\n- 当 $x > 0$ 时，$f(x) = x^2$，所以 $f'(x) = 2x$。\n- 当 $x  0$ 时，$f(x) = -x^2$，所以 $f'(x) = -2x$。\n这两个表达式可以使用绝对值函数合并成一个单一形式：$f'(x) = 2|x|$，对所有 $x \\neq 0$ 成立。\n\n题目说明初始猜测值 $x_0$ 是非零的。只要 $f'(x_k) \\neq 0$，牛顿迭代就是有定义的。由于 $f'(x_k) = 2|x_k|$，导数仅在 $x_k=0$ 时为零。我们将证明，如果 $x_k \\neq 0$，那么 $x_{k+1} \\neq 0$，因此对所有 $k \\in \\mathbb{N}$，迭代都是良定义的。\n\n将 $f(x_k)=x_k|x_k|$ 和 $f'(x_k)=2|x_k|$ 代入牛顿法公式，对于一个非零迭代值 $x_k$：\n$$\nx_{k+1} = x_k - \\frac{x_k|x_k|}{2|x_k|}\n$$\n因为 $x_k \\neq 0$，我们有 $|x_k| \\neq 0$，可以进行化简：\n$$\nx_{k+1} = x_k - \\frac{x_k}{2} = \\frac{1}{2}x_k\n$$\n这就是对任意 $x_k \\neq 0$ 的精确迭代映射。从此映射可以清楚地看到，如果 $x_k \\neq 0$，那么 $x_{k+1} = \\frac{1}{2}x_k \\neq 0$。因此，从任意 $x_0 \\neq 0$ 开始，所有后续的迭代值 $x_n$ 都将是非零的。\n\n接下来，我们推导 $x_n$ 关于初始猜测值 $x_0$ 和迭代次数 $n$ 的闭式表达式。关系式 $x_{k+1} = \\frac{1}{2}x_k$ 是一个简单的几何递推关系。\n当 $k=0$ 时，我们有 $x_1 = \\frac{1}{2}x_0$。\n当 $k=1$ 时，我们有 $x_2 = \\frac{1}{2}x_1 = \\frac{1}{2}\\left(\\frac{1}{2}x_0\\right) = \\left(\\frac{1}{2}\\right)^2 x_0$。\n通过归纳法，第 $n$ 次迭代的闭式表达式为：\n$$\nx_n = \\left(\\frac{1}{2}\\right)^n x_0\n$$\n对所有 $n \\in \\mathbb{N}$ 成立。\n\n现在，我们通过计算极限 $L$ 来求渐近收敛速率。根是 $x^{\\star} = 0$。\n$$\nL = \\lim_{k\\to\\infty}\\frac{|x_{k+1}-x^{\\star}|}{|x_{k}-x^{\\star}|} = \\lim_{k\\to\\infty}\\frac{|x_{k+1}-0|}{|x_{k}-0|} = \\lim_{k\\to\\infty}\\frac{|x_{k+1}|}{|x_k|}\n$$\n使用迭代映射 $x_{k+1} = \\frac{1}{2}x_k$：\n$$\nL = \\lim_{k\\to\\infty}\\frac{|\\frac{1}{2}x_k|}{|x_k|} = \\lim_{k\\to\\infty} \\frac{\\frac{1}{2}|x_k|}{|x_k|}\n$$\n因为 $x_0 \\neq 0$，所以对所有 $k$ 都有 $x_k \\neq 0$，因此我们可以约去分子和分母中的 $|x_k|$：\n$$\nL = \\lim_{k\\to\\infty} \\frac{1}{2} = \\frac{1}{2}\n$$\n值 $L = 1/2$ 表示收敛是线性的，每一步的误差都减少一个常数因子 $1/2$。\n\n最后，我们通过考察牛顿法局部收敛的基本条件来解释这种行为。牛顿法收敛到根 $x^{\\star}$ 的二次收敛标准定理需要若干条件，包括：\n1. $f(x^{\\star}) = 0$。\n2. $f'(x^{\\star}) \\neq 0$（根必须是单根或非奇异根）。\n3. $f(x)$ 必须在 $x^{\\star}$ 的一个邻域内二阶连续可微。\n\n我们来检验函数 $f(x) = x|x|$ 在根 $x^{\\star} = 0$ 处是否满足这些条件。\n1.  条件 1：$f(0) = 0|0| = 0$。此条件得到满足。\n2.  条件 2：我们需要计算 $f'(0)$。在 $x=0$ 处的导数由以下极限定义：\n    $$\n    f'(0) = \\lim_{h\\to 0} \\frac{f(0+h) - f(0)}{h} = \\lim_{h\\to 0} \\frac{h|h| - 0}{h} = \\lim_{h\\to 0} |h| = 0\n    $$\n    条件 $f'(x^{\\star}) \\neq 0$ **不成立**，因为 $f'(0) = 0$。这是牛顿法对此函数未能实现二次收敛的主要原因。当 $f'(x^{\\star})=0$ 时，根不是单根。从几何上看，曲线 $y=f(x)$ 在根 $x^{\\star}=0$ 处的切线是水平的（即 x 轴本身）。当迭代值 $x_k$ 趋近于 $0$ 时，在 $x_k$ 处的切线斜率 $f'(x_k) = 2|x_k|$ 也趋近于 $0$。函数在根附近的这种“扁平化”减慢了收敛速度，使其从二次收敛降为线性收敛。推导出的极限 $L=1/2$ 正是这种减速的体现：连续误差的比值趋向于一个常数 $L \\in (0, 1)$，而不是像二次收敛那样趋向于0（在二次收敛中，有 $|x_{k+1}|/|x_k|^2 \\to C$）。\n\n3.  条件 3：我们考察二阶导数 $f''(x)$。我们有 $f'(x) = 2|x|$。为了检查在 $x=0$ 处的二阶可微性，我们计算定义 $f''(0)$ 的极限：\n    $$\n    f''(0) = \\lim_{h\\to 0} \\frac{f'(0+h) - f'(0)}{h} = \\lim_{h\\to 0} \\frac{2|h| - 0}{h} = \\lim_{h\\to 0} \\frac{2|h|}{h}\n    $$\n    这个极限不存在，因为左极限和右极限不同：\n    - 右极限：$\\lim_{h\\to 0^+} \\frac{2h}{h} = 2$。\n    - 左极限：$\\lim_{h\\to 0^-} \\frac{-2h}{h} = -2$。\n    由于该极限不存在，$f(x)$ 在 $x=0$ 处不是二阶可微的。因此，函数在根的邻域内是 $C^2$ 的这一条件也**不成立**。\n\n总之，未能满足二次收敛的标准条件，最关键的是要求根为单根（$f'(x^{\\star}) \\neq 0$），导致了所观察到的线性收敛，其速率常数为 $L=1/2$。", "answer": "$$\n\\boxed{\\frac{1}{2}}\n$$", "id": "3262164"}, {"introduction": "在上一个练习中，我们诊断出多重根是导致牛顿法收敛速度从二次退化为线性的原因。那么，我们能修复这个问题吗？本练习将介绍一种直接的解决方案：修正牛顿法。通过将根的重数 $p$ 作为一个已知参数引入迭代公式，我们可以调整牛顿步长，从而恢复算法所期望的快速收敛特性。[@problem_id:3262250]", "problem": "设函数 $f:\\mathbb{R}\\to\\mathbb{R}$ 由 $f(x)=(x-\\pi)^4$ 给出，该函数在 $x^\\star=\\pi$ 处有一个重数为 $p=4$ 的根。考虑由 Newton 法给出的求根基本方法，其迭代式定义为 $x_{k+1}=x_k-\\frac{f(x_k)}{f'(x_k)}$，以及根的重数概念：如果 $f(x)=(x-x^\\star)^p g(x)$ 且 $g(x^\\star)\\neq 0$，则 $x^\\star$ 是一个重数为 $p1$ 的根。众所周知，标准的 Newton 法在处理多重根时会失去其典型的二次收敛性。你的任务是：从这些基本原理出发，推导出一个通过常数因子重新缩放 Newton 步长的修正方法，分析其对于多重根的误差动态，然后在函数 $f(x)=(x-\\pi)^4$ 上实现并评估该方法。\n\n要求：\n- 从基本 Newton 迭代式 $x_{k+1}=x_k-\\frac{f(x_k)}{f'(x_k)}$ 和重数的定义出发，推导出一个步长缩放方法族的误差更新，其中 Newton 步长乘以一个实数参数 $m$。写出误差 $e_k=x_k-x^\\star$，并仅使用代数以及微分的乘法和链式法则，推导出当 $f(x)=(x-x^\\star)^p$ 时 $e_{k+1}$ 的精确映射关系。\n- 使用你的推导，以纯数学术语解释为什么标准 Newton 法在处理多重根时仅表现出线性收敛，以及如何通过恰当地选择缩放因子来恢复至少二次收敛性。你的推理必须从基本定义出发，不得假定任何已知的专门公式。\n- 在程序中实现步长缩放迭代法，并在函数 $f(x)=(x-\\pi)^4$ 上评估以下测试套件，使用 $x^\\star=\\pi$ 和 $p=4$。对每种情况，定义 $e_k=x_k-\\pi$ 并按照说明计算该情况所需的输出：\n    - 测试 1 (二次收敛性丧失)：使用 $m=1$ 和 $x_0=0$。执行恰好 1 次迭代以获得 $x_1$，并以浮点数形式报告观测到的线性因子 $r_1=\\frac{|e_1|}{|e_0|}$。\n    - 测试 2 (恢复快速收敛)：使用 $m=4$ 和 $x_0=0$。迭代直到 $|e_k|  \\varepsilon$（容差 $\\varepsilon=10^{-12}$），或直到达到 50 次迭代的最大次数。报告达到容差要求所需的整数迭代次数 $N_4$。\n    - 测试 3 (修正不足的缩放)：使用 $m=3$ 和 $x_0=-1$。执行恰好 1 次迭代，并以浮点数形式报告 $r_3=\\frac{|e_1|}{|e_0|}$。\n    - 测试 4 (修正过度但收敛的缩放)：使用 $m=5$ 和 $x_0=4$。执行恰好 1 次迭代，并以浮点数形式报告有符号比率 $\\rho_5=\\frac{e_1}{e_0}$。\n    - 测试 5 (因过度缩放导致的发散)：使用 $m=9$ 和 $x_0=0$。执行 3 次迭代，产生 $e_1$、$e_2$ 和 $e_3$。如果 $|e_1||e_0|$、$|e_2||e_1|$ 且 $|e_3||e_2|$，则报告布尔值 $\\mathrm{True}$，否则报告 $\\mathrm{False}$。\n- 你的程序应：\n    - 实现函数 $f(x)=(x-\\pi)^4$ 及其导数 $f'(x)=4(x-\\pi)^3$。\n    - 实现使用参数 $m$ 的单步步长缩放 Newton 更新。\n    - 对于浮点数输出，在生成最终输出前四舍五入到 6 位小数。\n- 最终输出格式：你的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表（例如 [resultA,resultB,resultC,resultD,resultE]）。结果必须按顺序 $[r_1,N_4,r_3,\\rho_5,\\text{diverged}]$ 排列，其中 $r_1$、$r_3$ 和 $\\rho_5$ 是四舍五入到 6 位小数的浮点数，$N_4$ 是一个整数，$\\text{diverged}$ 是一个布尔值。本问题不涉及单位，根据 $\\pi$ 的定义，所有角度均以弧度为单位。", "solution": "寻找函数 $f(x)$ 的根 $x^\\star$ 是数值分析中的一个基石问题。Newton 法为此提供了一种强大的迭代算法。然而，其著名的二次收敛性取决于根是单根。对于重数 $p  1$ 的根 $x^\\star$，其收敛性会降级为线性收敛。本分析将推导当一个缩放版本的 Newton 法应用于具有多重根的函数时其精确的误差动态，解释这种收敛性降级的机制，并展示一个特定的缩放如何能够恢复快速收敛。\n\n设函数为 $f:\\mathbb{R}\\to\\mathbb{R}$，且 $x^\\star$ 是一个重数为 $p$ 的根，这意味着 $f(x) = (x-x^\\star)^p g(x)$ 且 $g(x^\\star) \\neq 0$。本题要求分析 $f(x)=(x-x^\\star)^p$ 的特定情况，这对应于对所有 $x$ 都有 $g(x)=1$。\n\n缩放的 Newton 迭代法由下式给出\n$$x_{k+1} = x_k - m \\frac{f(x_k)}{f'(x_k)}$$\n其中 $m$ 是一个实值缩放参数。第 $k$ 次迭代的误差定义为 $e_k = x_k - x^\\star$。因此，我们可以写出 $x_k = x^\\star + e_k$ 和 $x_{k+1} = x^\\star + e_{k+1}$。将这些代入迭代公式可得：\n$$x^\\star + e_{k+1} = (x^\\star + e_k) - m \\frac{f(x^\\star + e_k)}{f'(x^\\star + e_k)}$$\n从两边减去 $x^\\star$ 得到误差更新方程：\n$$e_{k+1} = e_k - m \\frac{f(x^\\star + e_k)}{f'(x^\\star + e_k)}$$\n\n遵照问题的指示，我们对特定函数 $f(x) = (x-x^\\star)^p$ 进行分析。\n首先，我们计算函数在 $x_k = x^\\star + e_k$ 处的值：\n$$f(x_k) = f(x^\\star + e_k) = ((x^\\star + e_k) - x^\\star)^p = e_k^p$$\n接下来，我们使用链式法则和幂法则求 $f(x)$ 的导数：\n$$f'(x) = \\frac{d}{dx}(x-x^\\star)^p = p(x-x^\\star)^{p-1} \\cdot \\frac{d}{dx}(x-x^\\star) = p(x-x^\\star)^{p-1}$$\n计算导数在 $x_k = x^\\star + e_k$ 处的值：\n$$f'(x_k) = f'(x^\\star + e_k) = p((x^\\star + e_k) - x^\\star)^{p-1} = p e_k^{p-1}$$\n现在，我们将 $f(x_k)$ 和 $f'(x_k)$ 的这些表达式代入误差更新方程：\n$$e_{k+1} = e_k - m \\frac{e_k^p}{p e_k^{p-1}}$$\n假设 $e_k \\neq 0$（即我们尚未收敛），我们可以简化这个分数：\n$$e_{k+1} = e_k - m \\frac{e_k}{p}$$\n提出公因子 $e_k$，我们得到该函数的精确误差映射：\n$$e_{k+1} = e_k \\left(1 - \\frac{m}{p}\\right)$$\n\n这个推导出的关系式 $e_{k+1} = C e_k$（其中 $C = 1 - \\frac{m}{p}$ 是一个常数）是线性收敛的定义。每一步的误差都按一个固定的因子减小。收敛速度取决于这个因子的大小 $|C|$。为了保证收敛，我们需要 $|C|1$。\n\n现在我们可以基于这个结果来分析 Newton 法的行为。\n首先，考虑标准的 Newton 法，它对应于缩放因子 $m=1$。误差更新方程变为：\n$$e_{k+1} = e_k \\left(1 - \\frac{1}{p}\\right)$$\n对于多重根，我们有 $p  1$。因此，收敛因子 $C = 1 - \\frac{1}{p}$ 是一个满足 $0  C  1$ 的常数。对于 $p=4$ 的特定情况，该因子为 $1 - \\frac{1}{4} = \\frac{3}{4}$。每一步误差仅减少 $25\\%$，这清晰地展示了其是线性收敛而非二次收敛。这就解释了为什么标准 Newton 法在处理多重根时会失去快速收敛性。\n\n其次，考虑如何恢复更快的收敛速度。目标是选择缩放参数 $m$，使得收敛因子 $|C| = |1 - \\frac{m}{p}|$ 最小化。$C$ 的理想值是 $0$，因为这将意味着 $e_{k+1}=0$，即在单步内收敛。\n将该因子设为零：\n$$1 - \\frac{m}{p} = 0 \\implies m=p$$\n通过选择等于根的重数 $p$ 的缩放因子 $m$，我们得到 $e_{k+1} = e_k(1-\\frac{p}{p}) = 0$。这表明对于形式为 $f(x)=(x-x^\\star)^p$ 的函数，使用 $m=p$ 的修正 Newton 法可以在单次迭代中找到精确根（假设为无限精度算术）。对于更一般的情况 $f(x)=(x-x^\\star)^p g(x)$，一个涉及泰勒级数的更详细分析表明，设置 $m=p$ 可以消除误差展开式中的线性项，从而得到 $e_{k+1} = O(e_k^2)$，因此恢复了至少二次收敛性。恰当地选择 $m$ 从根本上改变了误差动态，移除了导致线性收敛的瓶颈。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and evaluates a scaled-step Newton's method for a function with a multiple root.\n    \"\"\"\n    # Define pi from numpy for precision\n    pi = np.pi\n    p = 4  # Multiplicity of the root for f(x) = (x-pi)^4\n\n    # Define the function and its derivative\n    def f(x_val):\n        return (x_val - pi)**p\n\n    def fp(x_val):\n        if x_val == pi:\n            return 0.0\n        return p * (x_val - pi)**(p - 1)\n\n    # --- Test Cases ---\n\n    results = []\n\n    # Test 1: Standard Newton's method (m=1), showing linear convergence\n    m1 = 1\n    x0_1 = 0.0\n    # Calculate one iteration\n    e0_1 = x0_1 - pi\n    # The term f(x)/f'(x) simplifies to (x-pi)/p\n    x1_1 = x0_1 - m1 * (x0_1 - pi) / p\n    e1_1 = x1_1 - pi\n    r1 = abs(e1_1 / e0_1)\n    results.append(round(r1, 6))\n\n    # Test 2: Modified Newton (m=p), restoring fast convergence\n    m2 = p\n    x0_2 = 0.0\n    tol = 1e-12\n    max_iter = 50\n    xk_2 = x0_2\n    N4 = 0\n    for k in range(max_iter + 1):\n        ek_2 = xk_2 - pi\n        if abs(ek_2)  tol:\n            N4 = k\n            break\n        # Avoid division by zero if already at the root\n        deriv_val = fp(xk_2)\n        if deriv_val == 0:\n            N4 = k\n            break\n        xk_2 = xk_2 - m2 * f(xk_2) / deriv_val\n    else:\n        N4 = max_iter\n    results.append(N4)\n\n    # Test 3: Undercorrected scaling (m=3)\n    m3 = 3\n    x0_3 = -1.0\n    # Calculate one iteration\n    e0_3 = x0_3 - pi\n    # The term f(x)/f'(x) simplifies to (x-pi)/p\n    x1_3 = x0_3 - m3 * (x0_3 - pi) / p\n    e1_3 = x1_3 - pi\n    r3 = abs(e1_3 / e0_3)\n    results.append(round(r3, 6))\n\n    # Test 4: Overcorrected but convergent scaling (m=5)\n    m4 = 5\n    x0_4 = 4.0\n    # Calculate one iteration\n    e0_4 = x0_4 - pi\n    # The term f(x)/f'(x) simplifies to (x-pi)/p\n    x1_4 = x0_4 - m4 * (x0_4 - pi) / p\n    e1_4 = x1_4 - pi\n    rho5 = e1_4 / e0_4\n    results.append(round(rho5, 6))\n\n    # Test 5: Divergence from excessive scaling (m=9)\n    m5 = 9\n    x0_5 = 0.0\n    errors = [x0_5 - pi]\n    xk_5 = x0_5\n    for _ in range(3):\n        # The term f(x)/f'(x) simplifies to (x-pi)/p\n        xk_5 = xk_5 - m5 * (xk_5 - pi) / p\n        errors.append(xk_5 - pi)\n    \n    diverged = (abs(errors[1]) > abs(errors[0])) and \\\n               (abs(errors[2]) > abs(errors[1])) and \\\n               (abs(errors[3]) > abs(errors[2]))\n    results.append(diverged)\n\n    # Final print statement in the exact required format.\n    # Results are [r1, N4, r3, rho5, diverged]\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3262250"}, {"introduction": "到目前为止，我们的关注点主要在根邻域的局部收敛性质上。然而，如果初始猜测点距离根很远，牛顿法可能会出现“过冲”现象，即一个巨大的迭代步长反而使下一次的迭代点更远离解。本练习将探讨这一常见的全局化问题，并引入一种强大而通用的解决方案——回溯线搜索（Backtracking Line Search），该技术通过确保每一步迭代都能使某个“价值函数”充分下降，从而极大地增强了牛顿法的稳健性。[@problem_id:3262151]", "problem": "考虑非线性函数 $f:\\mathbb{R}\\to\\mathbb{R}$（定义为 $f(x)=\\tanh(10x)-0.5$）的标量求根问题。求解 $f(x)=0$ 的牛顿法基于 $f$ 在当前迭代点 $x_k$ 附近的一阶泰勒展开，即 $f(x_k+p)\\approx f(x_k)+f'(x_k)p$，该展开忽略了高阶项。将此线性化模型设为零并求解 $p$，可得到牛顿步 $p_k=-\\frac{f(x_k)}{f'(x_k)}$，以及下一个迭代点 $x_{k+1}=x_k+p_k$。导数 $f'(x)$ 是双曲正切函数的导数，必须精确计算。在实践中，当 $|f'(x_k)|$ 很小或 $|p_k|$ 很大时，该方法可能会出现过冲现象，将 $x_k$ 推向函数 $f$ 饱和且 $f'(x)$ 接近于零的区域，从而影响收敛。\n\n为缓解过冲问题，您必须通过回溯线搜索（BLS）实现一种阻尼策略。采用价值函数 $\\phi(x)=\\tfrac{1}{2}f(x)^2$，它编码了残差大小的标量度量。对于标量牛顿方向 $p_k=-\\frac{f(x_k)}{f'(x_k)}$，回溯线搜索选择一个步长 $t_k\\in(0,1]$ 以确保 $\\phi$ 有充分的下降。具体来说，从 $t_k=1$ 开始，用 $\\beta\\in(0,1)$ 反复迭代 $t_k\\leftarrow\\beta\\,t_k$，直到对于选定的常数 $c\\in(0,1)$，满足 Armijo 型不等式\n$$\n\\phi(x_k+t_k p_k)\\le (1-c\\,t_k)\\,\\phi(x_k)\n$$\n为止。如果导数的绝对值 $|f'(x_k)|$ 低于预设阈值，则必须拒绝该步，以避免因除以一个极小的数而引起的数值不稳定性。如果在最小步长 $t_{\\min}0$ 之上没有 $t_k$ 满足该不等式，则算法应终止并报告该迭代序列失败。\n\n您的程序必须在同个测试套件上实现两种算法：\n- 无阻尼牛顿法（每次迭代均采用完整步长 $t_k=1$）。\n- 使用上述回溯线搜索的阻尼牛顿法。\n\n使用以下科学上一致的规范：\n- 函数 $f(x)=\\tanh(10x)-0.5$ 及其导数 $f'(x)=10\\,\\operatorname{sech}^2(10x)$，其中 $\\operatorname{sech}(z)=\\frac{1}{\\cosh(z)}$，而 $\\cosh(z)$ 是双曲余弦。\n- 价值函数 $\\phi(x)=\\tfrac{1}{2}f(x)^2$。\n- 残差大小的收敛容差：如果 $|f(x_k)|\\le 10^{-12}$ 则停止。\n- 每次运行的最大迭代次数：$50$。\n- 导数保护：如果 $|f'(x_k)|  10^{-12}$，则终止当前运行。\n- 回溯参数：$c=10^{-4}$，$\\beta=0.5$，$t_{\\min}=10^{-8}$。\n\n测试套件和覆盖范围：\n- 理想情况：$x_0=0.1$（离根较近）。\n- 易于过冲的初始点：$x_0=0.3$（牛顿法的完整步长非常大）。\n- 导数接近于零的边界情况：$x_0=2.0$（$f'(x)$ 极小的饱和区）。\n- 符号相反的起始点：$x_0=-0.2$（必须跨越到唯一的正根）。\n\n对于每个测试用例，运行这两种方法，并记录每种方法的最终残差大小 $|f(x_{\\text{final}})|$（作为浮点数）。要求的最终输出格式是单行、方括号括起来的逗号分隔列表，按顺序汇总每个测试用例的无阻尼残差和阻尼残差。例如，输出必须类似于\n$$\n[\\text{residual\\_undamped\\_case1},\\text{residual\\_damped\\_case1},\\text{residual\\_undamped\\_case2},\\text{residual\\_damped\\_case2},\\text{residual\\_undamped\\_case3},\\text{residual\\_damped\\_case3},\\text{residual\\_undamped\\_case4},\\text{residual\\_damped\\_case4}]\n$$\n其中每个条目都是一个浮点数。不涉及物理单位；所有量均为无量纲实数。", "solution": "该设计始于通过一阶泰勒展开推导出的标量牛顿法。对于一个可微的标量函数 $f:\\mathbb{R}\\to\\mathbb{R}$，其在当前迭代点 $x_k$ 附近的泰勒展开为\n$$\nf(x_k+p)\\approx f(x_k)+f'(x_k)\\,p.\n$$\n在此线性模型中令 $f(x_k+p)=0$，可得到牛顿步\n$$\np_k=-\\frac{f(x_k)}{f'(x_k)},\n$$\n下一个迭代点为 $x_{k+1}=x_k+p_k$。在标准条件下，该方法是局部二次收敛的：$f$ 足够光滑，在根 $x^\\star$ 处 $f'(x^\\star)\\ne 0$，并且初始猜测值足够接近 $x^\\star$。然而，远离根部或在 $f'(x)$ 较小的区域，$|p_k|$ 可能会非常大，有可能将迭代点 $x_k$ 带入 $f$ 饱和且 $f'(x)$ 接近于零的区域，从而降低进展。这种现象就是过冲。\n\n对于特定函数 $f(x)=\\tanh(10x)-0.5$，存在一个根，因为双曲正切函数是严格递增的，并且界于 -1 和 1 之间。根 $x^\\star$ 满足 $\\tanh(10x^\\star)=0.5$，因此 $10x^\\star=\\operatorname{artanh}(0.5)$ 且 $x^\\star=\\operatorname{artanh}(0.5)/10$，其中 $\\operatorname{artanh}$ 表示反双曲正切。其导数为\n$$\nf'(x)=10\\,\\operatorname{sech}^2(10x)=10\\left(\\frac{1}{\\cosh(10x)}\\right)^2.\n$$\n当 $|10x|$ 很大时，$\\cosh(10x)$ 也很大，因此 $f'(x)$ 变得非常小，这使得牛顿步 $p_k=-\\frac{f(x_k)}{f'(x_k)}$ 的量级极大且不稳定。这样的步长很容易将迭代点 $x_k$ 传播到饱和区，在该区域 $\\tanh(10x)\\approx \\pm 1$ 且 $f'(x)\\approx 0$，从而导致数值计算上的困难。\n\n为缓解过冲，我们使用回溯线搜索（BLS）和一个价值函数\n$$\n\\phi(x)=\\frac{1}{2}f(x)^2,\n$$\n来对牛顿步进行阻尼，该价值函数用于衡量残差的大小。标量牛顿方向 $p_k=-\\frac{f(x_k)}{f'(x_k)}$ 在根附近是 $\\phi$ 的一个下降方向。实际上，$\\phi$ 在方向 $p$ 上的方向导数是\n$$\n\\phi'(x_k;p)=f(x_k)f'(x_k)\\,p,\n$$\n代入 $p_k$ 可得 $\\phi'(x_k;p_k)=-f(x_k)^2$，只要 $f(x_k)\\ne 0$，该值就为负。这表明，在局部上，牛顿步会减小价值函数 $\\phi$。然而，采取完整步长 $t_k=1$ 可能无法在全局上减小 $\\phi$。因此，回溯线搜索选择一个步长 $t_k\\in(0,1]$，使得 Armijo 型充分下降条件成立：\n$$\n\\phi(x_k+t_k p_k)\\le (1-c\\,t_k)\\,\\phi(x_k),\n$$\n其中 $c\\in(0,1)$ 是一个小常数，$t_k$ 从 1 开始，并按因子 $\\beta\\in(0,1)$ 递减，直到满足该不等式。这个过程确保了残差度量 $\\phi$ 的单调减少，从而防止了过冲。$\\phi$ 的连续性意味着足够小的 $t_k$ 将产生下降，因为 $p_k$ 是一个下降方向。因此，除非 $f'(x_k)$ 实际上为零，否则回溯过程将以一个可接受的 $t_k$ 终止。\n\n阻尼方法在第 $k$ 次迭代的算法步骤如下：\n1. 计算 $f(x_k)$ 和 $f'(x_k)$。如果 $|f(x_k)|\\le 10^{-12}$，则停止。\n2. 如果 $|f'(x_k)|10^{-12}$，则终止以避免不稳定的步长。\n3. 计算牛顿方向 $p_k=-\\frac{f(x_k)}{f'(x_k)}$。\n4. 初始化 $t_k=1$。当 $t_k\\ge t_{\\min}$ 时循环：\n   - 构建候选点 $x_k^{\\text{cand}}=x_k+t_k p_k$ 并计算 $\\phi(x_k^{\\text{cand}})$。\n   - 如果 $\\phi(x_k^{\\text{cand}})\\le (1-c\\,t_k)\\,\\phi(x_k)$，则接受该步：设置 $x_{k+1}=x_k^{\\text{cand}}$ 并跳出循环。\n   - 否则，减小步长：$t_k\\leftarrow\\beta\\,t_k$。\n5. 如果在 $t_k  t_{\\min}$ 时循环终止，则声明失败。否则，进入下一次迭代。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef f(x: float) - float:\n    # f(x) = tanh(10x) - 0.5\n    return float(np.tanh(10.0 * x) - 0.5)\n\ndef df(x: float) - float:\n    # f'(x) = 10 * sech^2(10x), where sech(z) = 1/cosh(z)\n    # Implement carefully to avoid overflow: for large |z|, cosh(z) can overflow to inf; 1/inf - 0 safely.\n    z = 10.0 * x\n    cosh_z = np.cosh(z)\n    # Handle potential overflow: if cosh_z is inf, then sech^2 is 0.\n    if not np.isfinite(cosh_z):\n        return 0.0\n    sech_z = 1.0 / cosh_z\n    return float(10.0 * (sech_z ** 2))\n\ndef newton_undamped(x0: float, max_iters: int = 50, tol_res: float = 1e-12, min_df: float = 1e-12) - float:\n    x = float(x0)\n    for _ in range(max_iters):\n        fx = f(x)\n        if abs(fx) = tol_res:\n            break\n        dfx = df(x)\n        if abs(dfx)  min_df:\n            # Derivative too small; stop to avoid unstable steps\n            break\n        step = -fx / dfx\n        x = x + step\n    return abs(f(x))\n\ndef newton_backtracking(x0: float,\n                        max_iters: int = 50,\n                        tol_res: float = 1e-12,\n                        c: float = 1e-4,\n                        beta: float = 0.5,\n                        t_min: float = 1e-8,\n                        min_df: float = 1e-12) - float:\n    x = float(x0)\n    for _ in range(max_iters):\n        fx = f(x)\n        if abs(fx) = tol_res:\n            break\n        dfx = df(x)\n        if abs(dfx)  min_df:\n            # Derivative too small; stop to avoid unstable steps\n            break\n        p = -fx / dfx\n        phi_x = 0.5 * (fx ** 2)\n        t = 1.0\n        accepted = False\n        # Backtracking loop\n        while t >= t_min:\n            x_candidate = x + t * p\n            f_cand = f(x_candidate)\n            phi_cand = 0.5 * (f_cand ** 2)\n            if phi_cand = (1.0 - c * t) * phi_x:\n                x = x_candidate\n                accepted = True\n                break\n            t *= beta\n        if not accepted:\n            # Could not find an acceptable step size\n            break\n    return abs(f(x))\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Initial guesses: happy path, overshooting-prone, boundary case (near-zero derivative), sign-opposite start\n    initial_guesses = [0.1, 0.3, 2.0, -0.2]\n\n    # Algorithm parameters as specified\n    max_iters = 50\n    tol_res = 1e-12\n    c = 1e-4\n    beta = 0.5\n    t_min = 1e-8\n    min_df = 1e-12\n\n    results = []\n    for x0 in initial_guesses:\n        r_undamped = newton_undamped(x0, max_iters=max_iters, tol_res=tol_res, min_df=min_df)\n        r_damped = newton_backtracking(x0, max_iters=max_iters, tol_res=tol_res,\n                                       c=c, beta=beta, t_min=t_min, min_df=min_df)\n        results.append(r_undamped)\n        results.append(r_damped)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3262151"}]}