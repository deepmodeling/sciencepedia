{"hands_on_practices": [{"introduction": "这个首个练习将帮助我们突破解是单一值的思维定势。通过分析一个简单的多项式函数，你将发现使其最小化的点集可以形成一个独特的几何图形，这强化了 $\\operatorname{argmin}$ 是一个*集合*而非单个点的概念 [@problem_id:3098641]。这个练习为理解解集的多样性和几何特性打下了基础。", "problem": "设函数 $f:\\mathbb{R}^{2}\\to\\mathbb{R}$ 定义为 $f(x,y)=x^{2}y^{2}$，可行集为闭合正方形 $D=[-1,1]^{2}=\\{(x,y)\\in\\mathbb{R}^{2}:-1\\leq x\\leq 1,\\,-1\\leq y\\leq 1\\}$。仅使用优化理论的核心定义，确定 $f$ 在 $D$ 上的 $\\operatorname{argmin}$ 集合，并根据第一性原理阐释其在 $D$ 内的几何形状。然后，计算该 $\\operatorname{argmin}$ 集合的一维欧几里得总长度，该长度理解为构成它的线段长度之和，交点只计算一次。将最终答案表示为一个精确的数。", "solution": "用户希望解决以下问题：设函数 $f:\\mathbb{R}^{2}\\to\\mathbb{R}$ 定义为 $f(x,y)=x^{2}y^{2}$，可行集为闭合正方形 $D=[-1,1]^{2}=\\{(x,y)\\in\\mathbb{R}^{2}:-1\\leq x\\leq 1,\\,-1\\leq y\\leq 1\\}$。仅使用优化理论的核心定义，确定 $f$ 在 $D$ 上的 $\\operatorname{argmin}$ 集合，并根据第一性原理阐释其在 $D$ 内的几何形状。然后，计算该 $\\operatorname{argmin}$ 集合的一维欧几里得总长度，该长度理解为构成它的线段长度之和，交点只计算一次。将最终答案表示为一个精确的数。\n\n这是一个有效的优化问题。它是自洽的、有数学和科学依据的，并且是适定的。函数 $f(x,y) = x^2 y^2$ 在紧集 $D = [-1,1]^2$ 上是连续的，因此根据极值定理，全局最小值存在。问题要求找到达到该最小值的点集（$\\operatorname{argmin}$ 集合）及其几何性质，这些都是定义明确的数学任务。所有提供的信息都清晰、一致，并且足以得出一个唯一的解。\n\n我们首先回顾 $\\operatorname{argmin}$ 集合的正式定义。对于定义在集合 $D$ 上的函数 $f$，$f$ 在 $D$ 上的 $\\operatorname{argmin}$ 是 $D$ 中使得 $f$ 达到其最小值的点的集合。令 $m = \\min_{(x,y) \\in D} f(x,y)$。那么，我们记为 $S^*$ 的 $\\operatorname{argmin}$ 集合由下式给出：\n$$S^* = \\operatorname{argmin}_{(x,y) \\in D} f(x,y) = \\{(x,y) \\in D \\mid f(x,y) = m\\}$$\n\n第一步是确定函数 $f(x,y) = x^2y^2$ 在可行集 $D = [-1,1]^2$ 上的最小值 $m$。该函数可以写为 $f(x,y) = (xy)^2$。对于任何实数 $x$ 和 $y$，项 $x^2$ 和 $y^2$ 都是非负的。即 $x^2 \\geq 0$ 且 $y^2 \\geq 0$。因此，它们的乘积 $f(x,y) = x^2y^2$ 对于所有 $(x,y) \\in \\mathbb{R}^2$ 也必须是非负的，因此对于所有 $(x,y) \\in D$ 也必须是非负的。\n$$f(x,y) = x^2y^2 \\geq 0$$\n一个非负函数能取的最低可能值是 $0$。我们必须验证在定义域 $D$ 内是否存在某个点 $(x,y)$ 使得 $f(x,y)$ 能达到这个值。条件 $f(x,y) = 0$ 等价于：\n$$x^2y^2 = 0$$\n该方程成立当且仅当 $x^2 = 0$ 或 $y^2 = 0$，这可以简化为 $x=0$ 或 $y=0$。\n\n因此，函数 $f(x,y)$ 在任何至少有一个坐标为零的点 $(x,y)$ 处达到值 $0$。因为我们已经确定对于所有点 $f(x,y) \\geq 0$，并且值 $0$ 在 $D$ 内是可以达到的（例如，在点 $(0,0) \\in D$ 处，$f(0,0)=0$），所以 $f$ 在 $D$ 上的全局最小值为 $m=0$。\n\n现在我们可以确定 $\\operatorname{argmin}$ 集合 $S^*$。这是定义域 $D$ 中所有满足 $f(x,y) = 0$ 的点 $(x,y)$ 的集合。\n$$S^* = \\{(x,y) \\in D \\mid f(x,y) = 0\\}$$\n如上所述，这个条件当且仅当 $x=0$ 或 $y=0$ 时满足。因此，我们在寻找正方形 $D = [-1,1]^2$ 中 $x$ 坐标或 $y$ 坐标为零的点的集合。\n$$S^* = \\{(x,y) \\in [-1,1]^2 \\mid x=0 \\text{ or } y=0\\}$$\n这个集合可以表示为两个子集的并集：\n1.  $x=0$ 的点的集合：$S_x = \\{(0,y) \\mid -1 \\leq y \\leq 1\\}$。\n2.  $y=0$ 的点的集合：$S_y = \\{(x,0) \\mid -1 \\leq x \\leq 1\\}$。\n因此，$\\operatorname{argmin}$ 集合是 $S^* = S_x \\cup S_y$。\n\n接下来，我们阐释这个集合的几何形状。定义域 $D$ 是一个以原点为中心、边长为 $2$ 的正方形。集合 $S_x$ 是 $y$ 轴上从点 $(0,-1)$ 到 $(0,1)$ 的垂直线段。集合 $S_y$ 是 $x$ 轴上从点 $(-1,0)$ 到 $(1,0)$ 的水平线段。这两个线段的并集 $S^*$ 形成一个以原点为中心的“+”字形，其臂延伸到正方形 $D$ 的边界。这两条线段相交于原点 $(0,0)$。\n\n最后，我们计算集合 $S^*$ 的一维欧几里得总长度。问题指明要计算线段长度之和，交点只计算一次。集合 $S^*$ 是线段 $S_x$ 和线段 $S_y$ 的并集。\n从 $(0,-1)$ 到 $(0,1)$ 的垂直线段 $S_x$ 的长度是其端点之间的欧几里得距离：\n$$L_x = \\sqrt{(0-0)^2 + (1 - (-1))^2} = \\sqrt{0^2 + 2^2} = 2$$\n从 $(-1,0)$ 到 $(1,0)$ 的水平线段 $S_y$ 的长度是：\n$$L_y = \\sqrt{(1 - (-1))^2 + (0 - 0)^2} = \\sqrt{2^2 + 0^2} = 2$$\n两个集合并集的总长度是它们各自长度之和减去它们交集的长度。两条线段的交点是 $x=0$ 且 $y=0$ 的单一点：\n$$S_x \\cap S_y = \\{(0,0)\\}$$\n一个单一点的一维测度（长度）为 $0$。因此，$S^*$ 的总长度 $L$ 是：\n$$L = L_x + L_y - \\text{Length}(S_x \\cap S_y) = 2 + 2 - 0 = 4$$\n或者，我们可以将这个“+”字形看作由四条长度为 $1$ 的不同线段组成，它们都在原点交汇：从 $(-1,0)$ 到 $(0,0)$ 的线段，从 $(0,0)$ 到 $(1,0)$ 的线段，从 $(0,-1)$ 到 $(0,0)$ 的线段，以及从 $(0,0)$ 到 $(0,1)$ 的线段。它们的长度之和是 $1+1+1+1 = 4$。两种方法都得到相同的结果。总长度是 $4$。", "answer": "$$\n\\boxed{4}\n$$", "id": "3098641"}, {"introduction": "本练习探讨了现代数据科学中的一个核心概念：$\\ell_1$ 与 $\\ell_2$ 范数约束之间的区别。通过在两种不同的范数球上寻找一个线性函数的 $\\operatorname{argmax}$ 集合，你将从几何角度直观地理解为什么 $\\ell_1$ 优化能够促进稀疏性 [@problem_id:3098617]。这一特性是压缩感知、特征选择和机器学习中正则化方法（如 Lasso 回归）的理论基石。", "problem": "设 $n \\in \\mathbb{N}$，且设 $a \\in \\mathbb{R}^{n}$ 是一个非零向量。考虑在两个不同的单位球上最大化相同线性泛函的两个优化问题：\n- $A_{1} \\coloneqq \\operatorname{argmax}\\{a^{\\top}x : \\|x\\|_{1} \\leq 1\\}$,\n- $A_{2} \\coloneqq \\operatorname{argmax}\\{a^{\\top}x : \\|x\\|_{2} \\leq 1\\}$,\n其中 $\\|\\cdot\\|_{1}$ 表示 $\\ell_{1}$ 范数，$\\|\\cdot\\|_{2}$ 表示欧几里得范数。\n\n仅从 $\\operatorname{argmax}$、$\\ell_{1}$ 和 $\\ell_{2}$ 范数的定义、三角不等式以及柯西-施瓦茨不等式出发，确定集合 $A_{1}$ 和 $A_{2}$ 的确切形式，并确定它们的仿射维度（即包含每个集合的最小仿射子空间的维度）。设 $M \\coloneqq \\max_{1 \\leq i \\leq n} |a_{i}|$ 且 $J \\coloneqq \\{i \\in \\{1,\\dots,n\\} : |a_{i}| = M\\}$，并记 $k \\coloneqq |J|$。因为 $a \\neq 0$，我们假设 $k \\geq 1$。\n\n以 $k$ 的函数形式，计算量 $\\Delta \\coloneqq \\dim(A_{1}) - \\dim(A_{2})$ 的封闭形式表达式。你的最终答案必须是关于 $k$ 的单一解析表达式。无需四舍五入。", "solution": "我们首先回顾将要使用的定义和基本不等式。对于一个集合 $S \\subset \\mathbb{R}^{n}$ 和一个函数 $f : \\mathbb{R}^{n} \\to \\mathbb{R}$，$\\operatorname{argmax}_{x \\in S} f(x)$ 表示集合 $S$ 中使得 $f$ 在 $S$ 上达到其最大值的点 $x$ 的集合。$\\ell_{1}$ 范数为 $\\|x\\|_{1} = \\sum_{i=1}^{n} |x_{i}|$，$\\ell_{2}$ 范数为 $\\|x\\|_{2} = \\left(\\sum_{i=1}^{n} x_{i}^{2}\\right)^{1/2}$。我们将使用三角不等式 $|u+v| \\leq |u| + |v|$ 和柯西-施瓦茨不等式 $|u^{\\top}v| \\leq \\|u\\|_{2}\\|v\\|_{2}$，以及基本界限 $\\sum_{i=1}^{n} |a_{i}||x_{i}| \\leq \\left(\\max_{i} |a_{i}|\\right)\\sum_{i=1}^{n} |x_{i}|$。\n\n我们分别分析这两个问题，然后比较得到的 argmax 集合。\n\n步骤 $1$：在 $\\ell_{2}$ 约束下对 $A_{2}$ 进行刻画。对于任何满足 $\\|x\\|_{2} \\leq 1$ 的 $x$，应用柯西-施瓦茨不等式：\n$$\na^{\\top}x \\leq \\|a\\|_{2}\\|x\\|_{2} \\leq \\|a\\|_{2}.\n$$\n因此，最优值至多为 $\\|a\\|_{2}$。柯西-施瓦茨不等式中的等号成立当且仅当 $x$ 是 $a$ 的标量倍数，即对于某个 $\\lambda \\in \\mathbb{R}$ 有 $x = \\lambda a$。为了同时满足 $\\|x\\|_{2} \\leq 1$ 并达到上界 $\\|a\\|_{2}$，我们需要 $\\|x\\|_{2} = 1$ 且 $a^{\\top}x = \\|a\\|_{2}\\|x\\|_{2} = \\|a\\|_{2}$。这要求 $x$ 与 $a$ 方向相同，即 $x = a/\\|a\\|_{2}$。因此，\n$$\nA_{2} = \\left\\{\\frac{a}{\\|a\\|_{2}}\\right\\}.\n$$\n这个集合是一个单点集，所以其仿射维度为 $0$，即 $\\dim(A_{2}) = 0$。\n\n步骤 $2$：在 $\\ell_{1}$ 约束下对 $A_{1}$ 进行刻画。对于任何满足 $\\|x\\|_{1} \\leq 1$ 的 $x$，我们有界限：\n$$\na^{\\top}x = \\sum_{i=1}^{n} a_{i} x_{i} \\leq \\sum_{i=1}^{n} |a_{i}||x_{i}| \\leq \\left(\\max_{1 \\leq i \\leq n} |a_{i}|\\right) \\sum_{i=1}^{n} |x_{i}| \\leq M.\n$$\n因此，最优值至多为 $M$。我们现在刻画不等式链中等号同时成立的条件：\n- 对于第一个不等式，我们要求对每个 $i$ 都有 $a_{i}x_{i} = |a_{i}||x_{i}|$，这等价于 $x_{i}$ 与 $a_{i}$同号（或 $x_{i} = 0$）。\n- 对于第二个不等式，我们要求只要 $|x_{i}| > 0$，就必须有 $|a_{i}| = M$；也就是说，$x$ 的支撑集必须包含在 $J = \\{i : |a_{i}| = M\\}$ 中。\n- 对于第三个不等式，我们需要 $\\|x\\|_{1} = 1$。\n\n结合这些条件，等号成立的情况恰好是满足以下条件的 $x \\in \\mathbb{R}^{n}$ 的集合：\n$$\nx_{i} = 0 \\text{ for } i \\notin J,\\quad x_{i} \\text{ has sign } \\operatorname{sign}(a_{i}) \\text{ for } i \\in J,\\quad \\sum_{i \\in J} |x_{i}| = 1.\n$$\n等价地，令 $t_{i} \\coloneqq |x_{i}| \\geq 0$ (对于 $i \\in J$)，条件变为\n$$\n\\sum_{i \\in J} t_{i} = 1,\\quad t_{i} \\geq 0 \\text{ for each } i \\in J,\n$$\n其中对于 $i \\in J$ 有 $x_{i} = \\operatorname{sign}(a_{i})\\,t_{i}$，对于 $i \\notin J$ 有 $x_{i} = 0$。集合 $\\{t \\in \\mathbb{R}^{k}_{\\ge 0} : \\sum_{i \\in J} t_{i} = 1\\}$ 是维度为 $k-1$ 的标准单纯形，而将 $t$ 映射到 $x$ 的映射（该映射赋予固定的符号并嵌入到 $\\mathbb{R}^{n}$ 中）是到 $A_{1}$ 的一个仿射同构。因此，\n$$\n\\dim(A_{1}) = k - 1.\n$$\n\n步骤 $3$：计算仿射维度的差值。由以上可知，\n$$\n\\Delta \\coloneqq \\dim(A_{1}) - \\dim(A_{2}) = (k - 1) - 0 = k - 1.\n$$\n该公式对于任何满足 $k = |J| \\geq 1$ 的非零向量 $a$ 都有效。在 $k = 1$ 的特殊情况下，两个 argmax 集合都是单点集，且 $\\Delta = 0$；当 $k > 1$ 时，$\\ell_{1}$ argmax 集合是一个 $(k-1)$ 维的面，而 $\\ell_{2}$ argmax 集合仍然是一个单点，从而得到所推导的 $\\Delta = k - 1$。", "answer": "$$\\boxed{k-1}$$", "id": "3098617"}, {"introduction": "在最后的练习中，理论与实践在此交汇，它融合了数学分析与编程模拟。你将研究函数 $f(x) = \\sqrt{|x|}$，以理解为什么平滑性假设（如 Lipschitz 连续性）对基于梯度的优化算法的可靠收敛至关重要 [@problem_id:3098631]。通过动手实现，你将亲眼目睹梯度下降法在处理非光滑函数时可能出现的“振荡”行为，这将为理解算法的性能边界提供一个深刻而难忘的教训。", "problem": "考虑由 $f(x)=\\sqrt{|x|}$ 定义的函数 $f:\\mathbb{R}\\to\\mathbb{R}$。其目的是分析 $\\operatorname{argmin}$ 集合和 $\\varepsilon$-近似-$\\operatorname{argmin}$ 集合，验证正则性性质，并凭经验证明梯度下降 (GD) 方法如何在一个非 Lipschitz 函数的非平凡近似-$\\operatorname{argmin}$ 区域内外徘徊。仅使用下面指定的基本定义和性质。\n\n使用的基本定义：\n- $f$ 的 $\\operatorname{argmin}$ 集合是 $\\operatorname{argmin} f := \\{x\\in\\mathbb{R} : f(x) = \\inf_{y\\in\\mathbb{R}} f(y)\\}$。\n- $\\varepsilon$-近似-$\\operatorname{argmin}$ 集合（也称为 $\\varepsilon$-近似最小化子集）是 $A_{\\varepsilon} := \\{x\\in\\mathbb{R} : f(x) \\le \\inf_{y\\in\\mathbb{R}} f(y) + \\varepsilon \\}$，对于任何 $\\varepsilon > 0$。\n- 如果对于所有 $x,y\\in\\mathbb{R}$，都有 $|f(x)-f(y)| \\le L|x-y|$ 成立，那么函数 $f$ 是 Lipschitz 连续的，常数为 $L>0$。\n- 具有固定步长 $\\alpha>0$ 的梯度下降 (GD) 在梯度存在时更新 $x_{k+1} := x_k - \\alpha \\nabla f(x_k)$；如果某一点的梯度不存在，为了避免迭代未定义，本次模拟取 $\\nabla f(0):=0$。\n\n任务：\n1. 从第一性原理出发，证明 $f(x)=\\sqrt{|x|}$ 有唯一的最小化子，确定 $\\operatorname{argmin} f$，并验证 $f$ 在 $x=0$ 的任何邻域上都不是 Lipschitz 连续的。\n2. 对于一般的 $\\varepsilon>0$，明确描述 $A_{\\varepsilon}$ 的特征，并导出其宽度（用 $\\varepsilon$ 表示）。\n3. 对函数 $f$ 实现 GD，在导数存在的地方使用导数：对于 $x\\neq 0$，使用 $\\nabla f(x)=\\frac{1}{2}\\frac{\\operatorname{sign}(x)}{\\sqrt{|x|}}$，对于 $x=0$，设置 $\\nabla f(0):=0$。对 $k=0,1,\\dots,N-1$ 运行迭代 $x_{k+1} := x_k - \\alpha \\nabla f(x_k)$。\n4. 对于每次模拟，计算以下量化指标：\n   - $x$ 域中 $A_{\\varepsilon}$ 的宽度，即区间 $A_{\\varepsilon}$ 的长度。\n   - $A_{\\varepsilon}$ 内部迭代点的比例，定义为 $\\frac{1}{N}\\sum_{k=0}^{N-1} \\mathbf{1}\\{|x_k|\\le \\varepsilon^2\\}$，其中 $\\mathbf{1}\\{\\cdot\\}$ 是指示函数。\n   - $A_{\\varepsilon}$ 的边界穿越次数，定义为在迭代序列 $\\{x_k\\}_{k=0}^{N-1}$ 中，$A_{\\varepsilon}$ 成员资格切换的次数（即序列在 $A_{\\varepsilon}$ 内部和外部之间切换了多少次）。\n   - $\\{x_k\\}$ 中符号变化的次数，定义为满足 $\\operatorname{sign}(x_{k}) \\ne \\operatorname{sign}(x_{k-1})$ 的索引 $k$ 的总数，约定 $\\operatorname{sign}(0):=0$。\n5. 使用以下测试套件，其设计旨在覆盖一般行为和边缘情况：\n   - 测试 1（正常路径，中等步长）：$(x_0,\\alpha,\\varepsilon,N) = (1.0,\\,0.2,\\,0.1,\\,200)$。\n   - 测试 2（较小步长）：$(x_0,\\alpha,\\varepsilon,N) = (1.0,\\,0.02,\\,0.1,\\,200)$。\n   - 测试 3（从最小化子开始）：$(x_0,\\alpha,\\varepsilon,N) = (0.0,\\,0.2,\\,0.1,\\,200)$。\n   - 测试 4（接近零的起点，中等步长）：$(x_0,\\alpha,\\varepsilon,N) = (10^{-6},\\,0.2,\\,0.1,\\,200)$。\n\n最终输出规格：\n- 对于每个测试用例，您的程序必须输出一个列表 $[w,\\rho,c,s]$，其中 $w$ 是 $A_{\\varepsilon}$ 的宽度（浮点数），$\\rho$ 是内部迭代点比例（浮点数），$c$ 是边界穿越次数（整数），$s$ 是符号变化次数（整数）。\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，四个测试用例的结果按顺序排列。例如，输出格式必须类似于 $[[w_1,\\rho_1,c_1,s_1],[w_2,\\rho_2,c_2,s_2],[w_3,\\rho_3,c_3,s_3],[w_4,\\rho_4,c_4,s_4]]$。\n- 本问题不涉及物理单位或角度单位。所有输出均为指定类型的实值浮点数或整数。", "solution": "问题陈述已经过评估，被认为是有效的。它在科学上基于实分析和优化理论，给出了所有必要的定义和参数，问题设定良好，并且其表述是客观的。因此，我们可以进行完整的解答。\n\n该问题要求对函数 $f(x) = \\sqrt{|x|}$ 进行多部分分析，重点是其最小化性质以及应用于其上的梯度下降 (GD) 算法的行为。这个函数是一个典型的非光滑、非 Lipschitz 目标函数，它对标准优化方法构成了挑战。\n\n### 第 1 部分：最小化子和 Lipschitz 连续性分析\n\n首先，我们证明 $f(x)=\\sqrt{|x|}$ 有一个唯一的最小化子，并确定 $\\operatorname{argmin}$ 集合。$f$ 的定义域是 $\\mathbb{R}$。绝对值函数 $|x|$ 总是非负的，即对所有 $x \\in \\mathbb{R}$ 都有 $|x| \\ge 0$。平方根函数对非负输入是单调递增的。因此，$f(x) = \\sqrt{|x|} \\ge \\sqrt{0} = 0$。$f(x)$ 的最小可能值为 $0$。\n\n函数的下确界是 $\\inf_{y\\in\\mathbb{R}} f(y) = 0$。我们现在找出达到这个下确界的点的集合。这就是 $\\operatorname{argmin}$ 集合：\n$$ \\operatorname{argmin} f = \\{x\\in\\mathbb{R} : f(x) = 0\\} $$\n$$ f(x) = 0 \\iff \\sqrt{|x|} = 0 \\iff |x| = 0 \\iff x = 0 $$\n因此，最小化子是唯一的，位于 $x=0$。\n$$ \\operatorname{argmin} f = \\{0\\} $$\n\n接下来，我们验证 $f$ 在 $x=0$ 的任何邻域上都不是 Lipschitz 连续的。如果存在一个常数 $L>0$，使得对于集合 $S \\subseteq \\mathbb{R}$ 中的所有 $x, y$，不等式 $|f(x)-f(y)| \\le L|x-y|$ 都成立，则函数 $f$ 在 $S$ 上是 Lipschitz 连续的。\n我们考虑 $0$ 的任意邻域，比如 $(-\\delta, \\delta)$，其中 $\\delta > 0$。为了证明 $f$ 在这个邻域上不是 Lipschitz 的，我们必须证明比率 $\\frac{|f(x)-f(y)|}{|x-y|}$ 对于 $x, y \\in (-\\delta, \\delta)$ 是无界的。\n我们选择 $y=0$ 和 $x \\in (0, \\delta)$。\n那么 $f(y) = f(0) = 0$ 且 $f(x) = \\sqrt{x}$。该比率变为：\n$$ \\frac{|f(x)-f(0)|}{|x-0|} = \\frac{|\\sqrt{x}-0|}{|x-0|} = \\frac{\\sqrt{x}}{x} = \\frac{1}{\\sqrt{x}} $$\n当我们让 $x$ 从正侧趋近于 $0$（$x \\to 0^+$）时，这个比率 $\\frac{1}{\\sqrt{x}}$ 的值趋向于无穷大。由于这个比率在任何区间 $(0, \\delta)$ 上都是无界的，因此找不到有限的 Lipschitz 常数 $L$ 能满足在 $0$ 的任何邻域中对所有点都成立的定义。因此，$f(x)=\\sqrt{|x|}$ 在 $x=0$ 的任何邻域上都不是 Lipschitz 连续的。\n\n### 第 2 部分：$\\varepsilon$-近似-$\\operatorname{argmin}$ 集合的特征描述\n\n$\\varepsilon$-近似-$\\operatorname{argmin}$ 集合 $A_{\\varepsilon}$ 定义为：\n$$ A_{\\varepsilon} := \\{x\\in\\mathbb{R} : f(x) \\le \\inf_{y\\in\\mathbb{R}} f(y) + \\varepsilon \\} $$\n从第 1 部分，我们知道 $\\inf_{y\\in\\mathbb{R}} f(y) = 0$。将此代入定义中得到：\n$$ A_{\\varepsilon} = \\{x\\in\\mathbb{R} : \\sqrt{|x|} \\le \\varepsilon \\} $$\n由于 $\\varepsilon > 0$ 且 $\\sqrt{|x|} \\ge 0$，我们可以对不等式两边进行平方而不改变其方向：\n$$ |x| \\le \\varepsilon^2 $$\n这个不等式等价于区间 $[-\\varepsilon^2, \\varepsilon^2]$。因此，该集合的明确特征描述为：\n$$ A_{\\varepsilon} = [-\\varepsilon^2, \\varepsilon^2] $$\n$A_{\\varepsilon}$ 的宽度是该区间的长度，计算方法是其端点之差：\n$$ w = \\varepsilon^2 - (-\\varepsilon^2) = 2\\varepsilon^2 $$\n这证实了问题陈述中用于计算 $A_\\varepsilon$ 内部迭代点比例的条件 $\\{|x_k|\\le \\varepsilon^2\\}$ 确实是 $A_\\varepsilon$ 成员资格的正确条件。\n\n### 第 3 部分：梯度下降模拟分析\n\n梯度下降 (GD) 的更新规则是 $x_{k+1} := x_k - \\alpha \\nabla f(x_k)$。对于 $x \\neq 0$，$f(x)=\\sqrt{|x|}$ 的梯度是 $\\nabla f(x) = \\frac{d}{dx} \\sqrt{|x|} = \\frac{\\operatorname{sign}(x)}{2\\sqrt{|x|}}$。问题指定在模拟中使用 $\\nabla f(0) := 0$。这个选择是一个有效的次梯度，因为 $f$ 在 $x=0$ 处的次微分是 $\\partial f(0)=\\mathbb{R}$。\n\n$\\nabla f(x)$ 的关键特征是其大小 $|\\nabla f(x)| = \\frac{1}{2\\sqrt{|x|}}$ 在 $x \\to 0$ 时趋于无穷。这违反了 GD 收敛的标准条件，该条件要求梯度是 Lipschitz 连续的（即有界的变化率）。当迭代点 $x_k$ 接近最小化子 $x=0$ 时，这种无界性导致算法采取极大的步长。\n\nGD 更新可以分段写成：\n$$ x_{k+1} = \\begin{cases} x_k - \\alpha \\frac{1}{2\\sqrt{x_k}} & \\text{if } x_k > 0 \\\\ x_k - \\alpha \\frac{-1}{2\\sqrt{-x_k}} & \\text{if } x_k < 0 \\\\ 0 & \\text{if } x_k = 0 \\end{cases} $$\n如果一个迭代点恰好落在 $x=0$ 上，它将在所有后续迭代中保持在那里。然而，由于浮点运算的性质和更新规则，这仅在起始点为 $x_0=0$ 时才能得到保证。\n\n当一个迭代点 $x_k$ 很小但非零时（即在 $A_\\varepsilon$ 内部），项 $\\frac{\\alpha}{2\\sqrt{|x_k|}}$ 会变得非常大。下一个迭代点 $x_{k+1}$ 将约等于 $-\\alpha \\nabla f(x_k)$，导致一次大的跳跃，越过 $x=0$ 处的最小值，并落在原点另一侧很远的地方。这导致了“徘徊”行为，即迭代序列反复进入小的邻域 $A_\\varepsilon$，但随即被弹出。这将表现为 $A_\\varepsilon$ 的高边界穿越次数和序列 $\\{x_k\\}$ 中的高符号变化次数。\n\n- **测试 1 ($x_0=1.0, \\alpha=0.2, \\varepsilon=0.1, N=200$)**: 使用相对较大的步长 $\\alpha$，过冲现象将非常明显。我们预计只有一小部分迭代点会留在 $A_\\varepsilon$ 内部，并且会有大量的边界穿越和符号变化。\n- **测试 2 ($x_0=1.0, \\alpha=0.02, \\varepsilon=0.1, N=200$)**: 步长小了十倍。步长大小 $\\alpha |\\nabla f(x_k)|$ 将会更小，导致更小的过冲。迭代点仍会徘徊，但不会那么剧烈。与测试 1 相比，我们预计 $A_\\varepsilon$ 内部的迭代点比例会更高，穿越和符号变化次数会更少。\n- **测试 3 ($x_0=0.0, \\alpha=0.2, \\varepsilon=0.1, N=200$)**: 起始点是最小化子。由于我们定义了 $\\nabla f(0)=0$，第一次更新是 $x_1 = 0 - \\alpha \\cdot 0 = 0$。所有后续迭代点都将是 $0$。因此，所有迭代点都将在 $A_\\varepsilon$ 内部，边界穿越和符号变化次数都将为零。\n- **测试 4 ($x_0=10^{-6}, \\alpha=0.2, \\varepsilon=0.1, N=200$)**: 起始点非常接近 $0$ 并且在 $A_\\varepsilon = [-0.01, 0.01]$ 内部。梯度大小 $|\\nabla f(10^{-6})|$ 将会非常大（约 500）。更新步长将是巨大的，导致剧烈的过冲。这个案例将最清楚地展示不稳定性，表现为 $A_\\varepsilon$ 内部的迭代点比例非常低（在第一个迭代点之后），并且有许多穿越和符号变化。\n\n这些理论预期将由最终答案中实现的数值模拟来证实。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by running Gradient Descent simulations\n    for the function f(x) = sqrt(|x|) and calculating specified metrics.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (x_0, alpha, epsilon, N)\n        (1.0, 0.2, 0.1, 200),\n        (1.0, 0.02, 0.1, 200),\n        (0.0, 0.2, 0.1, 200),\n        (1e-6, 0.2, 0.1, 200),\n    ]\n\n    results = []\n    for x0, alpha, epsilon, N in test_cases:\n        # --- Run Gradient Descent Simulation ---\n        x_iterates = np.zeros(N, dtype=np.float64)\n        x_iterates[0] = x0\n\n        for k in range(N - 1):\n            x_k = x_iterates[k]\n            \n            # Calculate gradient based on the problem's definition\n            if x_k == 0.0:\n                grad_f = 0.0\n            else:\n                grad_f = np.sign(x_k) / (2.0 * np.sqrt(np.abs(x_k)))\n\n            # Update rule for Gradient Descent\n            x_k_plus_1 = x_k - alpha * grad_f\n            x_iterates[k + 1] = x_k_plus_1\n            \n        # --- Compute Quantitative Indicators ---\n\n        # 1. Width of A_epsilon\n        # A_epsilon is the interval [-epsilon^2, epsilon^2]\n        # Width w = epsilon^2 - (-epsilon^2) = 2 * epsilon^2\n        w = 2.0 * epsilon**2\n\n        # 2. Fraction of iterates inside A_epsilon\n        # The condition for being inside A_epsilon is |x_k| = epsilon^2\n        is_inside = np.abs(x_iterates) = epsilon**2\n        rho = np.mean(is_inside)\n\n        # 3. Number of boundary crossings of A_epsilon\n        # A crossing occurs if an iterate is inside and the next is outside, or vice versa.\n        # This is equivalent to checking where the 'is_inside' status toggles.\n        # We compare element k with element k-1 for k=1...N-1.\n        crossings = np.sum(is_inside[1:] != is_inside[:-1])\n        c = int(crossings)\n        \n        # 4. Number of sign changes in {x_k}\n        # A sign change occurs if sign(x_k) != sign(x_{k-1})\n        # np.sign(0) is 0, which correctly handles iterates that are exactly zero.\n        signs = np.sign(x_iterates)\n        sign_changes = np.sum(signs[1:] != signs[:-1])\n        s = int(sign_changes)\n\n        # Append the results for the current test case\n        results.append([w, rho, c, s])\n\n    # Final print statement in the exact required format.\n    # The map(str, results) ensures each inner list is converted to its string representation.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3098631"}]}