{"hands_on_practices": [{"introduction": "我们从一个看似简单但极具启发性的函数 $f(x)=\\|x\\|^4$ 开始。通过分析这个径向对称函数的黑塞矩阵，我们将揭示其特征值和特征向量如何与输入向量 $x$ 的方向和大小直接关联。这项练习 [@problem_id:3124793] 将清晰地展示，黑塞矩阵在原点的奇异性（即存在零特征值）如何直接影响牛顿法的行为，从而为理解优化算法的收敛性奠定基础。", "problem": "考虑函数 $f:\\mathbb{R}^{n}\\to\\mathbb{R}$，其定义为 $f(x)=\\|x\\|^{4}$，其中 $\\|\\cdot\\|$ 表示欧几里得范数。从 $\\mathbb{R}^{n}$ 上光滑标量场的梯度和海森矩阵的核心定义出发，推导任意 $x$ 的 $\\nabla f(x)$ 和 $\\nabla^{2} f(x)$。对于任意 $x\\neq 0$，通过确定 $\\nabla^{2} f(x)$ 在哪些方向上作用如同单位矩阵的标量倍，来确定 $\\nabla^{2} f(x)$ 的完整特征值-特征向量结构，并解释为什么该谱仅依赖于 $\\|x\\|$ 而不依赖于 $x$ 的方向（旋转下的各向同性）。然后，使用无约束最小化问题的牛顿步的定义线性系统，即点 $x$ 处的牛頓步 $p(x)$ 满足 $\\nabla^{2} f(x)\\,p(x)=-\\nabla f(x)$，求解 $x\\neq 0$ 时 $p(x)$ 的闭式解，并在原点 $x=0$ 处海森矩阵奇异的背景下，讨论当 $\\|x\\|\\to 0$ 时 $p(x)$ 的行为。将您的最终答案表示为 $p(x)$ 作为 $x$ 的函数的单一闭式解析表达式。无需四舍五入，且不涉及物理单位。", "solution": "该问题要求对函数 $f(x) = \\|x\\|^{4}$ 在 $\\mathbb{R}^{n}$ 上进行完整分析，包括其梯度、海森矩阵、海森矩阵的谱性质以及相关的无约束最小化问题的牛顿步。\n\n首先，我们验证问题陈述。\n**步骤 1：提取已知条件**\n- 函数：$f(x)=\\|x\\|^{4}$，其中 $f:\\mathbb{R}^{n}\\to\\mathbb{R}$，$\\|\\cdot\\|$ 是欧几里得范数。\n- 任务 1：推导梯度 $\\nabla f(x)$ 和海森矩阵 $\\nabla^{2} f(x)$。\n- 任务 2：对于任意 $x\\neq 0$，确定 $\\nabla^{2} f(x)$ 的完整特征值-特征向量结构。\n- 任务 3：解释 $\\nabla^{2} f(x)$ 的谱在旋转下的各向同性。\n- 任务 4：求解牛顿步方程 $\\nabla^{2} f(x)\\,p(x)=-\\nabla f(x)$，得到 $x\\neq 0$ 时牛顿步 $p(x)$ 的闭式解。\n- 任务 5：在原点 $x=0$ 处海森矩阵奇异的背景下，讨论当 $\\|x\\|\\to 0$ 时 $p(x)$ 的行为。\n- 最终答案：$p(x)$ 作为 $x$ 的函数的单一闭式解析表达式。\n\n**步骤 2：使用提取的已知条件进行验证**\n该问题在数学上是良定义的且自洽的。函数 $f(x)$ 是多元微积分和优化理论中的一个标准例子。所有使用的概念——梯度、海森矩阵、特征值、特征向量和牛顿法——都是这些领域的基础。该问题具有科学依据、客观，并且没有矛盾或缺失的信息。它是指定领域内一个标准的可形式化问题。\n\n**步骤 3：结论与行动**\n问题有效。我们继续进行求解。\n\n**梯度 $\\nabla f(x)$ 的推导**\n\n函数由 $f(x) = \\|x\\|^{4}$ 给出，其中 $x \\in \\mathbb{R}^{n}$。我们可以用向量 $x$ 的分量 $x_i$ 将其写为 $f(x) = \\left( \\sum_{i=1}^{n} x_i^{2} \\right)^{2}$。欧几里得范数的平方是 $\\|x\\|^{2} = x^{T}x$。因此，$f(x) = (x^{T}x)^{2}$。\n\n梯度 $\\nabla f(x)$ 是一个向量，其第 $k$ 个分量是偏导数 $\\frac{\\partial f}{\\partial x_k}$。我们使用链式法则：\n$$\n(\\nabla f(x))_k = \\frac{\\partial f}{\\partial x_k} = \\frac{\\partial}{\\partial x_k} \\left( \\left( \\sum_{i=1}^{n} x_i^{2} \\right)^{2} \\right)\n$$\n$$\n= 2 \\left( \\sum_{i=1}^{n} x_i^{2} \\right) \\cdot \\frac{\\partial}{\\partial x_k} \\left( \\sum_{i=1}^{n} x_i^{2} \\right)\n$$\n该和的导数是 $\\frac{\\partial}{\\partial x_k} \\left( \\sum_{i=1}^{n} x_i^{2} \\right) = 2x_k$。\n将其代回，我们得到：\n$$\n\\frac{\\partial f}{\\partial x_k} = 2 \\|x\\|^{2} \\cdot (2x_k) = 4\\|x\\|^{2} x_k\n$$\n以向量形式表示，这意味着梯度是：\n$$\n\\nabla f(x) = 4\\|x\\|^{2} x\n$$\n\n**海森矩阵 $\\nabla^{2} f(x)$ 的推导**\n\n海森矩阵 $\\nabla^{2} f(x)$ 的元素为 $(\\nabla^{2} f(x))_{jk} = \\frac{\\partial^{2} f}{\\partial x_j \\partial x_k}$。我们将梯度的第 $k$ 个分量对 $x_j$ 求导：\n$$\n\\frac{\\partial^{2} f}{\\partial x_j \\partial x_k} = \\frac{\\partial}{\\partial x_j} \\left( 4\\|x\\|^{2} x_k \\right) = \\frac{\\partial}{\\partial x_j} \\left[ 4 \\left( \\sum_{i=1}^{n} x_i^{2} \\right) x_k \\right]\n$$\n使用乘法求导法则：\n$$\n\\frac{\\partial^{2} f}{\\partial x_j \\partial x_k} = 4x_k \\frac{\\partial}{\\partial x_j} \\left( \\sum_{i=1}^{n} x_i^{2} \\right) + 4 \\left( \\sum_{i=1}^{n} x_i^{2} \\right) \\frac{\\partial x_k}{\\partial x_j}\n$$\n这些项的值为：\n- $\\frac{\\partial}{\\partial x_j} \\left( \\sum_{i=1}^{n} x_i^{2} \\right) = 2x_j$\n- $\\frac{\\partial x_k}{\\partial x_j} = \\delta_{jk}$ (克罗内克 delta)\n\n代入这些，我们得到海森矩阵的元素：\n$$\n(\\nabla^{2} f(x))_{jk} = 4x_k(2x_j) + 4\\|x\\|^{2}\\delta_{jk} = 8x_j x_k + 4\\|x\\|^{2}\\delta_{jk}\n$$\n在矩阵表示法中，项 $x_j x_k$ 对应于外积矩阵 $xx^{T}$，项 $\\delta_{jk}$ 对应于单位矩阵 $I$。因此，海森矩阵是：\n$$\n\\nabla^{2} f(x) = 8xx^{T} + 4\\|x\\|^{2} I\n$$\n\n**$x \\neq 0$ 时 $\\nabla^{2} f(x)$ 的特征值和特征向量结构**\n\n海森矩阵为 $\\nabla^{2} f(x) = 8xx^{T} + 4\\|x\\|^{2} I$。为了找到特征值和特征向量，我们考虑向量 $v \\in \\mathbb{R}^{n}$ 的两种情况。\n\n情况 1：$v$ 与 $x$ 平行。\n设 $v = \\alpha x$，其中标量 $\\alpha \\neq 0$。不失一般性，我们可以直接测试向量 $x$ 本身。\n$$\n(\\nabla^{2} f(x)) x = (8xx^{T} + 4\\|x\\|^{2} I)x = 8x(x^{T}x) + 4\\|x\\|^{2}(Ix) = 8x\\|x\\|^{2} + 4\\|x\\|^{2}x = 12\\|x\\|^{2}x\n$$\n这表明 $x$ 是 $\\nabla^{2} f(x)$ 的一个特征向量，对应的特征值为 $\\lambda_1 = 12\\|x\\|^{2}$。该特征值的特征空间是由 $x$ 张成的一维子空间，即 $\\text{span}\\{x\\}$。\n\n情况 2：$v$ 与 $x$ 正交。\n设 $v$ 是任意非零向量，使得 $x^{T}v = 0$。\n$$\n(\\nabla^{2} f(x)) v = (8xx^{T} + 4\\|x\\|^{2} I)v = 8x(x^{T}v) + 4\\|x\\|^{2}(Iv) = 8x(0) + 4\\|x\\|^{2}v = 4\\|x\\|^{2}v\n$$\n这表明任何与 $x$ 正交的向量 $v$ 都是 $\\nabla^{2} f(x)$ 的一个特征向量，对应的特征值为 $\\lambda_2 = 4\\|x\\|^{2}$。与 $x$ 正交的向量空间（即 $\\text{span}\\{x\\}$ 的正交补）的维数为 $n-1$。因此，$\\lambda_2 = 4\\|x\\|^{2}$ 是一个重数为 $n-1$ 的特征值。\n\n总之，对于 $x \\neq 0$，海森矩阵 $\\nabla^{2} f(x)$ 有两个不同的特征值：\n- $\\lambda_1 = 12\\|x\\|^{2}$，重数为 $1$，其特征空间为 $\\text{span}\\{x\\}$。\n- $\\lambda_2 = 4\\|x\\|^{2}$，重数为 $n-1$，其特征空间为 $\\{v \\in \\mathbb{R}^{n} \\mid x^{T}v=0\\}$。\n\n**特征值谱的各向同性**\n\n特征值 $\\lambda_1 = 12\\|x\\|^{2}$ 和 $\\lambda_2 = 4\\|x\\|^{2}$ 仅依赖于标量 $\\|x\\|$，即 $x$ 的欧几里得范数。它们不依赖于向量 $x$ 的方向。因此，对于任意两个具有相同范数（$\\|x\\|=\\|y\\|$）的向量 $x$ 和 $y$，$\\nabla^{2} f(x)$ 的谱将与 $\\nabla^{2} f(y)$ 的谱相同。\n更正式地，考虑一个旋转，它由一个正交矩阵 $R$ 表示（满足 $R^T R = I$ 和 $\\det(R)=1$）。向量 $Rx$ 是 $x$ 旋转后的版本，且 $\\|Rx\\|^{2} = (Rx)^{T}(Rx) = x^{T}R^{T}Rx = x^{T}Ix = \\|x\\|^{2}$。在旋转后的点 $Rx$ 处的海森矩阵为：\n$$\n\\nabla^{2} f(Rx) = 8(Rx)(Rx)^{T} + 4\\|Rx\\|^{2}I = 8Rxx^{T}R^{T} + 4\\|x\\|^{2}RR^{T} = R(8xx^{T} + 4\\|x\\|^{2}I)R^{T}\n$$\n因此，$\\nabla^{2} f(Rx) = R(\\nabla^{2} f(x))R^{T}$。这表明在 $Rx$ 处的海森矩阵通过一个相似变换与在 $x$ 处的海森矩阵相关联。由于相似变换保持特征值不变，$\\nabla^{2} f(x)$ 的谱在 $x$ 的旋转下是不变的。这种各向同性是原始函数 $f(x) = \\|x\\|^{4}$ 旋转不变性的直接结果，因为 $f(Rx) = \\|Rx\\|^{4} = \\|x\\|^{4} = f(x)$。\n\n**求解牛顿步 $p(x)$**\n\n牛顿步 $p(x)$ 由线性系统 $\\nabla^{2} f(x) p(x) = -\\nabla f(x)$ 定义。对于 $x \\neq 0$，梯度和海森矩阵均非零。海森矩阵的特征值（$12\\|x\\|^{2}$ 和 $4\\|x\\|^{2}$）是严格为正的，所以海森矩阵是正定的，因此是可逆的。这保证了 $p(x)$ 有唯一解。\n代入梯度和海森矩阵的表达式：\n$$\n(8xx^{T} + 4\\|x\\|^{2} I) p(x) = -4\\|x\\|^{2} x\n$$\n鉴于右侧是 $x$ 的倍数，我们可以假设一个形式为 $p(x) = c x$ 的解，其中 $c$ 是某个标量。将此假设代入方程：\n$$\n(8xx^{T} + 4\\|x\\|^{2} I) (cx) = -4\\|x\\|^{2} x\n$$\n$$\nc(8xx^{T}x + 4\\|x\\|^{2}Ix) = -4\\|x\\|^{2} x\n$$\n$$\nc(8x\\|x\\|^{2} + 4\\|x\\|^{2}x) = -4\\|x\\|^{2} x\n$$\n$$\nc(12\\|x\\|^{2}x) = -4\\|x\\|^{2} x\n$$\n$$\n12c\\|x\\|^{2}x = -4\\|x\\|^{2}x\n$$\n因为这个方程对任意 $x \\neq 0$ 都必须成立，我们可以令标量系数相等：\n$$\n12c\\|x\\|^{2} = -4\\|x\\|^{2}\n$$\n由于 $x \\neq 0$，我们有 $\\|x\\|^{2} \\neq 0$，所以我们可以两边同除以它来求 $c$：\n$$\n12c = -4 \\implies c = -\\frac{4}{12} = -\\frac{1}{3}\n$$\n因此，牛顿步是：\n$$\np(x) = -\\frac{1}{3}x\n$$\n\n**当 $\\|x\\| \\to 0$ 时的行为及原点处的奇异海森矩阵**\n\n我们来考察原点 $x=0$ 处的情况。\n在原点的梯度是 $\\nabla f(0) = 4\\|0\\|^{2}(0) = 0$。\n在原点的海森矩阵是 $\\nabla^{2} f(0) = 8(0)(0)^{T} + 4\\|0\\|^{2}I = 0$，即零矩阵。\n零矩阵是奇异的（其所有特征值都为 $0$）。\n在 $x=0$ 处的牛顿步方程变为：\n$$\n\\nabla^{2} f(0) p(0) = -\\nabla f(0) \\implies 0 \\cdot p(0) = 0\n$$\n这个方程对任意向量 $p(0) \\in \\mathbb{R}^{n}$ 都成立，这意味着牛顿步在原点没有唯一定义。\n然而，如果我们考虑当 $x$ 趋近于 $0$ 时牛顿步的极限：\n$$\n\\lim_{x \\to 0} p(x) = \\lim_{x \\to 0} \\left(-\\frac{1}{3}x\\right) = 0\n$$\n极限存在且为零向量。因此，虽然牛顿步在奇异点 $x=0$ 处形式上是不确定的，但可以通过连续性来定义。在优化的背景下，这意味着对于任意接近最小值点 $0$ 的点 $x_k$，下一个迭代点将是 $x_{k+1} = x_k + p(x_k) = x_k - \\frac{1}{3}x_k = \\frac{2}{3}x_k$。这表明以 $\\frac{2}{3}$ 的速率线性收敛到最小值，这比牛顿法在最小值点具有非奇异海森矩阵的函数上预期的二次收敛要慢。这种减速是由于函数 $f(x)=\\|x\\|^4$ 在其最小值点附近的平坦性所致，而这种平坦性由奇异（零）海森矩阵所表征。\n\n问题要求给出 $p(x)$ 作为 $x$ 的函数的单一闭式解析表达式。这就是为 $x \\neq 0$ 推导出的结果，它在 $x=0$ 处也是连续的。", "answer": "$$\n\\boxed{-\\frac{1}{3}x}\n$$", "id": "3124793"}, {"introduction": "接下来，我们将研究一个在机器学习中常见的函数，其形式为 $f(\\mathbf{x})=\\sum_{i=1}^{n}\\ln(1+\\exp(x_{i}))$，它与 softplus 激活函数密切相关。这个练习 [@problem_id:3124755] 的目标是计算其黑塞矩阵并分析其结构，从而引出条件数这一重要概念。通过计算特定点的条件数，你将亲身体会到函数在不同区域的“病态”程度，并理解为什么这对于优化算法的性能至关重要。", "problem": "考虑函数 $f:\\mathbb{R}^{n}\\to\\mathbb{R}$，其定义为 $f(\\mathbf{x})=\\sum_{i=1}^{n}\\ln\\!\\big(1+\\exp(x_{i})\\big)$，其中 $\\mathbf{x}=(x_{1},\\dots,x_{n})$。从梯度（一阶偏导数向量）和Hessian矩阵（二阶偏导数矩阵）的定义出发，推导 $\\nabla f(\\mathbf{x})$ 和 $\\nabla^{2} f(\\mathbf{x})$ 的表达式。仅使用偏微分的性质，描述 $\\nabla^{2} f(\\mathbf{x})$ 的结构，然后确定其特征值和特征向量。\n\n接下来，计算Hessian矩阵在点 $\\mathbf{x}^{\\ast}=\\big(\\ln(9),\\,0,\\,-\\ln(999),\\,\\ln(3),\\,-\\ln(3)\\big)\\in\\mathbb{R}^{5}$ 处的谱条件数（最大特征值与最小特征值之比）。将最终数值答案四舍五入到 $4$ 位有效数字。", "solution": "该问题要求推导给定函数的梯度和Hessian矩阵，描述Hessian矩阵的特征值和特征向量，并计算其在特定点处的谱条件数。\n\n函数由 $f:\\mathbb{R}^{n}\\to\\mathbb{R}$ 给出，其中对于 $\\mathbf{x}=(x_{1},\\dots,x_{n})$，$f(\\mathbf{x})=\\sum_{i=1}^{n}\\ln(1+\\exp(x_{i}))$。\n\n首先，我们推导梯度 $\\nabla f(\\mathbf{x})$。梯度的第 $j$ 个分量是 $f$ 关于 $x_j$ 的偏导数：\n$$ [\\nabla f(\\mathbf{x})]_j = \\frac{\\partial f}{\\partial x_j} = \\frac{\\partial}{\\partial x_j} \\left( \\sum_{i=1}^{n}\\ln(1+\\exp(x_{i})) \\right) $$\n根据微分算子的线性性质，我们可以写出：\n$$ \\frac{\\partial f}{\\partial x_j} = \\sum_{i=1}^{n} \\frac{\\partial}{\\partial x_j} \\ln(1+\\exp(x_{i})) $$\n项 $\\ln(1+\\exp(x_{i}))$ 仅在索引 $i$ 等于 $j$ 时才依赖于变量 $x_j$。对于所有 $i \\neq j$，偏导数为零。因此，该和式简化为对应于 $i=j$ 的单个项：\n$$ \\frac{\\partial f}{\\partial x_j} = \\frac{d}{d x_j} \\ln(1+\\exp(x_j)) $$\n使用链式法则 $\\frac{d}{du}\\ln(u) = \\frac{1}{u}$，我们得到：\n$$ \\frac{\\partial f}{\\partial x_j} = \\frac{1}{1+\\exp(x_j)} \\cdot \\frac{d}{d x_j}(1+\\exp(x_j)) = \\frac{1}{1+\\exp(x_j)} \\cdot \\exp(x_j) = \\frac{\\exp(x_j)}{1+\\exp(x_j)} $$\n这是逻辑S型函数（logistic sigmoid function），通常表示为 $\\sigma(x_j)$。因此，梯度向量为：\n$$ \\nabla f(\\mathbf{x}) = \\begin{pmatrix} \\frac{\\exp(x_1)}{1+\\exp(x_1)} \\\\ \\frac{\\exp(x_2)}{1+\\exp(x_2)} \\\\ \\vdots \\\\ \\frac{\\exp(x_n)}{1+\\exp(x_n)} \\end{pmatrix} $$\n\n接下来，我们推导Hessian矩阵 $\\nabla^2 f(\\mathbf{x})$，其元素为二阶偏导数 $H_{jk} = \\frac{\\partial^2 f}{\\partial x_j \\partial x_k}$。\n我们考虑索引 $j$ 和 $k$ 的两种情况。\n\n情况1：非对角线元素 ($j \\neq k$)。\n$$ H_{jk} = \\frac{\\partial^2 f}{\\partial x_j \\partial x_k} = \\frac{\\partial}{\\partial x_j} \\left( \\frac{\\partial f}{\\partial x_k} \\right) = \\frac{\\partial}{\\partial x_j} \\left( \\frac{\\exp(x_k)}{1+\\exp(x_k)} \\right) $$\n由于关于 $x_j$ 的导数内的表达式仅是 $x_k$ 的函数，因此其关于 $x_j$ 的偏导数为零。\n$$ H_{jk} = 0 \\quad \\text{for } j \\neq k $$\n\n情况2：对角线元素 ($j = k$)。\n$$ H_{jj} = \\frac{\\partial^2 f}{\\partial x_j^2} = \\frac{d}{dx_j} \\left( \\frac{\\partial f}{\\partial x_j} \\right) = \\frac{d}{dx_j} \\left( \\frac{\\exp(x_j)}{1+\\exp(x_j)} \\right) $$\n我们应用商法则 $\\frac{d}{dx}(\\frac{u}{v}) = \\frac{u'v - uv'}{v^2}$，其中 $u(x_j) = \\exp(x_j)$ 且 $v(x_j) = 1+\\exp(x_j)$。它们的导数是 $u'(x_j) = \\exp(x_j)$ 和 $v'(x_j) = \\exp(x_j)$。\n$$ H_{jj} = \\frac{\\exp(x_j)(1+\\exp(x_j)) - \\exp(x_j)\\exp(x_j)}{(1+\\exp(x_j))^2} = \\frac{\\exp(x_j) + \\exp(2x_j) - \\exp(2x_j)}{(1+\\exp(x_j))^2} = \\frac{\\exp(x_j)}{(1+\\exp(x_j))^2} $$\n\nHessian矩阵 $\\nabla^2 f(\\mathbf{x})$ 是一个对角矩阵，因为其所有非对角线元素都为零。其结构为：\n$$ \\nabla^2 f(\\mathbf{x}) = \\text{diag}\\left(\\frac{\\exp(x_1)}{(1+\\exp(x_1))^2}, \\frac{\\exp(x_2)}{(1+\\exp(x_2))^2}, \\dots, \\frac{\\exp(x_n)}{(1+\\exp(x_n))^2}\\right) $$\n\n对于一个对角矩阵 $D = \\text{diag}(d_1, d_2, \\dots, d_n)$，其特征值是对角线元素 $d_i$，相应的特征向量是标准基向量 $\\mathbf{e}_i$（其中 $\\mathbf{e}_i$ 是第 $i$ 个位置为 $1$ 其余位置为 $0$ 的向量）。\n因此，Hessian矩阵 $\\nabla^2 f(\\mathbf{x})$ 的特征值为：\n$$ \\lambda_i = H_{ii} = \\frac{\\exp(x_i)}{(1+\\exp(x_i))^2} \\quad \\text{for } i = 1, \\dots, n $$\n相应的特征向量是 $\\mathbf{v}_i = \\mathbf{e}_i$。\n\n我们被要求计算Hessian矩阵在点 $\\mathbf{x}^{\\ast}=\\big(\\ln(9),\\,0,\\,-\\ln(999),\\,\\ln(3),\\,-\\ln(3)\\big)\\in\\mathbb{R}^{5}$ 处的谱条件数。这里，$n=5$。谱条件数 $\\kappa$ 是最大特征值与最小特征值之比，即 $\\kappa = \\frac{\\lambda_{\\max}}{\\lambda_{\\min}}$。\n\n令 $g(x) = \\frac{\\exp(x)}{(1+\\exp(x))^2}$。特征值为 $\\lambda_i = g(x_i^*)$。\n1.  对于 $x_1^* = \\ln(9)$：$\\exp(x_1^*) = 9$。\n    $\\lambda_1 = g(\\ln(9)) = \\frac{9}{(1+9)^2} = \\frac{9}{100} = 0.09$。\n2.  对于 $x_2^* = 0$：$\\exp(x_2^*) = 1$。\n    $\\lambda_2 = g(0) = \\frac{1}{(1+1)^2} = \\frac{1}{4} = 0.25$。\n3.  对于 $x_3^* = -\\ln(999)$：$\\exp(x_3^*) = \\exp(-\\ln(999)) = \\frac{1}{999}$。\n    $\\lambda_3 = g(-\\ln(999)) = \\frac{1/999}{(1+1/999)^2} = \\frac{1/999}{(1000/999)^2} = \\frac{1}{999} \\frac{999^2}{1000^2} = \\frac{999}{1000^2} = 0.000999$。\n4.  对于 $x_4^* = \\ln(3)$：$\\exp(x_4^*) = 3$。\n    $\\lambda_4 = g(\\ln(3)) = \\frac{3}{(1+3)^2} = \\frac{3}{16} = 0.1875$。\n5.  对于 $x_5^* = -\\ln(3)$：$\\exp(x_5^*) = \\frac{1}{3}$。\n    $\\lambda_5 = g(-\\ln(3)) = \\frac{1/3}{(1+1/3)^2} = \\frac{1/3}{(4/3)^2} = \\frac{1}{3} \\frac{9}{16} = \\frac{3}{16} = 0.1875$。\n    注意 $g(x)$ 是一个偶函数，$g(x)=g(-x)$，这一点由 $\\lambda_5 = \\lambda_4$ 得到证实。\n\n计算出的特征值为 $\\{0.09, 0.25, 0.000999, 0.1875, 0.1875\\}$。\n最大特征值为 $\\lambda_{\\max} = \\max\\{0.09, 0.25, 0.000999, 0.1875\\} = 0.25 = \\frac{1}{4}$。\n最小特征值为 $\\lambda_{\\min} = \\min\\{0.09, 0.25, 0.000999, 0.1875\\} = 0.000999 = \\frac{999}{1000000}$。\n\n谱条件数是这个比值：\n$$ \\kappa = \\frac{\\lambda_{\\max}}{\\lambda_{\\min}} = \\frac{1/4}{999/1000000} = \\frac{1}{4} \\times \\frac{1000000}{999} = \\frac{250000}{999} $$\n为了得到数值，我们进行除法运算：\n$$ \\kappa = 250.250250\\dots = 250.\\overline{250} $$\n问题要求将此值四舍五入到 $4$ 位有效数字。$250.250\\dots$ 的前四位有效数字是 $2, 5, 0, 2$。第五位有效数字是 $5$，这要求对第四位数字进行向上取整。\n$$ \\kappa \\approx 250.3 $$", "answer": "$$\\boxed{250.3}$$", "id": "3124755"}, {"introduction": "理论分析的最终目的是指导实践。在这个压轴练习 [@problem_id:3124776] 中，你将扮演算法设计者的角色，亲手编写一个“谱截断牛顿法”。面对一个具有“平坦山脊”（对应于极小特征值）的函数，你将利用黑塞矩阵的谱分解来构建一个更稳健的优化算法，该算法能够智能地忽略不良曲率方向上的更新。这个编程实践将理论知识转化为实际代码，完美展示了如何利用黑塞矩阵的特征值来设计和改进现代优化算法。", "problem": "请考虑使用牛顿类方法对一个二次连续可微函数 $f : \\mathbb{R}^n \\to \\mathbb{R}$ 进行无约束最小化。经典的牛顿法通过最小化当前迭代点周围 $f$ 的局部二阶泰勒近似来选择更新方向。当存在曲率非常小的方向（“平坦脊”）时，海森矩阵的特征值可能接近于零，使得纯牛顿步不稳定或无效。\n\n您的任务是设计并实现一种谱截断牛顿法。在每次迭代中，该方法将海森矩阵分解为其特征值和特征向量，并跳过沿特征值低于用户指定阈值 $\\tau$ 的特征向量的更新。然后，在一个表现出平坦脊的函数上分析该方法的收敛行为。\n\n您应使用的基本原理：\n- 梯度 $\\nabla f(\\mathbf{x})$ 和海森矩阵 $\\nabla^2 f(\\mathbf{x})$ 由一阶和二阶导数定义，牛顿方向是最小化当前点 $f$ 的二阶泰勒模型的方向。\n- 对于对称矩阵 $\\mathbf{H}$，谱（特征）分解得到 $\\mathbf{H} = \\mathbf{Q} \\mathbf{\\Lambda} \\mathbf{Q}^\\top$，其中 $\\mathbf{Q}$ 是标准正交矩阵，$\\mathbf{\\Lambda}$ 是对角矩阵，其对角线元素为特征值。任何向量都可以投影到该特征基上。\n\n特定问题设置：\n- 在 $\\mathbb{R}^2$ 中处理目标函数\n$$\nf(x_1, x_2) = (x_1 - 1)^2 + x_2^4,\n$$\n该函数在 $x_2=0$ 附近沿 $x_2$ 轴有一个平坦脊。唯一的全局最小值点在 $(x_1^\\star, x_2^\\star) = (1, 0)$。\n- 在每次迭代 $(x_1, x_2)$ 时，构建海森矩阵，计算其特征值和特征向量，并构造一个只使用与大于或等于阈值 $\\tau  0$ 的特征值相关联的分量的更新方向。直观地说，沿曲率足够大的方向使用完整的牛顿步，而沿曲率低于 $\\tau$ 的脊则跳过更新。\n- 更新时使用单位步长。当更新步长的欧几里得范数小于容差 $\\varepsilon_{\\text{step}}$ 或达到最大迭代次数 $N_{\\max}$ 时，终止迭代。此问题中没有物理单位；所有量均为无单位实数。\n\n测试套件：\n使用 $N_{\\max} = 100$ 和 $\\varepsilon_{\\text{step}} = 10^{-15}$，在以下 $5$ 个测试用例上运行您的方法，每个用例由 $(x_1^{(0)}, x_2^{(0)}, \\tau)$ 指定：\n- 测试 $1$：$(0.0, 1.0, 10^{-12})$\n- 测试 $2$：$(0.0, 1.0, 0.05)$\n- 测试 $3$：$(0.0, 0.1, 0.5)$\n- 测试 $4$：$(10.0, 0.2, 3.0)$\n- 测试 $5$：$(-5.0, 0.0, 0.01)$\n\n对于每个测试用例，在终止后，计算最终迭代点 $(x_1^{(f)}, x_2^{(f)})$ 到 $(1, 0)$ 的欧几里得距离，即\n$$\nd = \\sqrt{(x_1^{(f)} - 1)^2 + (x_2^{(f)} - 0)^2}.\n$$\n\n最终输出格式：\n您的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表的结果（例如，$[d_1,d_2,d_3,d_4,d_5]$），其中 $d_i$ 是测试 $i$ 的距离。每个 $d_i$ 必须是一个实数（浮点数）。不应打印任何其他文本。", "solution": "用户提供的问题被评估为有效。这是一个数值优化领域中定义明确的问题，基于已建立的数学原理。问题陈述是自包含的，提供了所有必要的数据和条件。目标明确，要求的输出格式具体。\n\n该问题要求实现并分析一种谱截断牛顿法，用于最小化函数 $f(x_1, x_2) = (x_1 - 1)^2 + x_2^4$。该函数的特点是在最小值点附近的 $x_2$ 轴上存在一个“平坦脊”，这可能对标准优化算法构成挑战。所提出的方法根据海森矩阵特征值所编码的局部曲率来调整更新步长。\n\n首先，我们构建必要的数学组件。待最小化的函数是 $f : \\mathbb{R}^2 \\to \\mathbb{R}$，由下式给出：\n$$\nf(x_1, x_2) = (x_1 - 1)^2 + x_2^4\n$$\n唯一的全局最小值点位于 $\\mathbf{x}^\\star = (1, 0)$，此时 $f(1, 0) = 0$。\n\n$f$ 的梯度，记作 $\\nabla f(\\mathbf{x})$，是其一阶偏导数的向量：\n$$\n\\nabla f(\\mathbf{x}) = \\begin{pmatrix} \\frac{\\partial f}{\\partial x_1} \\\\ \\frac{\\partial f}{\\partial x_2} \\end{pmatrix} = \\begin{pmatrix} 2(x_1 - 1) \\\\ 4x_2^3 \\end{pmatrix}\n$$\n\n$f$ 的海森矩阵，记作 $\\nabla^2 f(\\mathbf{x})$ 或 $\\mathbf{H}(\\mathbf{x})$，是其二阶偏导数的矩阵：\n$$\n\\mathbf{H}(\\mathbf{x}) = \\begin{pmatrix} \\frac{\\partial^2 f}{\\partial x_1^2}  \\frac{\\partial^2 f}{\\partial x_1 \\partial x_2} \\\\ \\frac{\\partial^2 f}{\\partial x_2 \\partial x_1}  \\frac{\\partial^2 f}{\\partial x_2^2} \\end{pmatrix} = \\begin{pmatrix} 2  0 \\\\ 0  12x_2^2 \\end{pmatrix}\n$$\n对于任何点 $\\mathbf{x} = (x_1, x_2)$，海森矩阵都是一个对角矩阵。这极大地简化了谱分析。对角矩阵的特征值是其对角线元素，而标准基向量是相应的特征向量。\n特征值为：\n$$\n\\lambda_1 = 2\n$$\n$$\n\\lambda_2 = 12x_2^2\n$$\n相应的标准正交特征向量为：\n$$\n\\mathbf{q}_1 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\quad \\text{和} \\quad \\mathbf{q}_2 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\n$$\n特征值 $\\lambda_1 = 2$ 是常数，表示在 $x_1$ 方向上存在一个恒定的正曲率。特征值 $\\lambda_2 = 12x_2^2$ 取决于 $x_2$。当 $x_2$ 趋近于 $0$ 时，$\\lambda_2$ 也趋近于 $0$，表明 $x_2$ 方向的曲率变得极小。这对应于问题中提到的“平坦脊”。\n\n经典牛顿法的更新方向 $\\mathbf{p}_k$ 在迭代点 $\\mathbf{x}_k$ 处通过求解线性系统 $\\mathbf{H}(\\mathbf{x}_k) \\mathbf{p}_k = -\\nabla f(\\mathbf{x}_k)$ 得到。其解为 $\\mathbf{p}_k = -\\mathbf{H}(\\mathbf{x}_k)^{-1} \\nabla f(\\mathbf{x}_k)$。使用谱分解 $\\mathbf{H} = \\mathbf{Q} \\mathbf{\\Lambda} \\mathbf{Q}^\\top$，更新方向可以表示为每个特征向量方向贡献的总和：\n$$\n\\mathbf{p}_k = - \\sum_{i=1}^{2} \\frac{\\mathbf{q}_i^\\top \\nabla f(\\mathbf{x}_k)}{\\lambda_i} \\mathbf{q}_i\n$$\n该公式表明，沿每个特征向量 $\\mathbf{q}_i$ 的更新量与特征值 $\\lambda_i$ 的倒数成比例。如果一个特征值接近于零，这个缩放因子会变得非常大，可能导致不稳定且过大的更新步长。\n\n谱截断牛顿法通过忽略与小于给定阈值 $\\tau  0$ 的特征值相关的更新分量来解决此问题。修改后的更新方向（我们仍称之为 $\\mathbf{p}_k$）构造如下：\n$$\n\\mathbf{p}_k = - \\sum_{i \\text{ s.t. } \\lambda_i \\ge \\tau} \\frac{\\mathbf{q}_i^\\top \\nabla f(\\mathbf{x}_k)}{\\lambda_i} \\mathbf{q}_i\n$$\n让我们为我们的问题推导 $\\mathbf{p}_k$ 的具体分量。设 $\\mathbf{x}_k = (x_{1,k}, x_{2,k})$。\n梯度为 $\\mathbf{g}_k = \\nabla f(\\mathbf{x}_k) = \\begin{pmatrix} 2(x_{1,k} - 1) \\\\ 4x_{2,k}^3 \\end{pmatrix}$。\n梯度在特征向量上的投影为：\n$$\n\\mathbf{q}_1^\\top \\mathbf{g}_k = \\begin{pmatrix} 1  0 \\end{pmatrix} \\begin{pmatrix} 2(x_{1,k} - 1) \\\\ 4x_{2,k}^3 \\end{pmatrix} = 2(x_{1,k} - 1)\n$$\n$$\n\\mathbf{q}_2^\\top \\mathbf{g}_k = \\begin{pmatrix} 0  1 \\end{pmatrix} \\begin{pmatrix} 2(x_{1,k} - 1) \\\\ 4x_{2,k}^3 \\end{pmatrix} = 4x_{2,k}^3\n$$\n然后，通过检查每个分量的条件 $\\lambda_i \\ge \\tau$ 来构造更新方向 $\\mathbf{p}_k = \\begin{pmatrix} p_{1,k} \\\\ p_{2,k} \\end{pmatrix}$。\n\n对于第一个分量（沿 $\\mathbf{q}_1 = [1, 0]^\\top$）：\n特征值为 $\\lambda_1 = 2$。如果 $2 \\ge \\tau$，则更新分量为 $p_{1,k} = -\\frac{2(x_{1,k}-1)}{2} = -(x_{1,k} - 1)$。如果 $2  \\tau$，则跳过此分量，因此 $p_{1,k} = 0$。\n\n对于第二个分量（沿 $\\mathbf{q}_2 = [0, 1]^\\top$）：\n特征值为 $\\lambda_2 = 12x_{2,k}^2$。如果 $12x_{2,k}^2 \\ge \\tau$，并假设 $x_{2,k} \\neq 0$，则更新分量为 $p_{2,k} = -\\frac{4x_{2,k}^3}{12x_{2,k}^2} = -\\frac{x_{2,k}}{3}$。如果 $x_{2,k} = 0$，则 $\\lambda_2=0$，由于 $\\tau0$，条件 $0 \\ge \\tau$ 为假，从而正确地得到 $p_{2,k}=0$。$x_{2,k}=0$ 的情况无需特殊处理。如果 $12x_{2,k}^2  \\tau$，则跳过此分量，因此 $p_{2,k} = 0$。\n\n迭代算法如下：\n1. 初始化 $\\mathbf{x}_0 = (x_1^{(0)}, x_2^{(0)})$。\n2. 对于 $k=0, 1, \\dots, N_{\\max}-1$：\n   a. 设 $\\mathbf{x}_k = (x_{1,k}, x_{2,k})$。\n   b. 计算更新方向分量：\n      $p_{1,k} = \\begin{cases} -(x_{1,k}-1)  \\text{若 } 2 \\ge \\tau \\\\ 0  \\text{若 } 2  \\tau \\end{cases}$\n      $p_{2,k} = \\begin{cases} -x_{2,k}/3  \\text{若 } 12x_{2,k}^2 \\ge \\tau \\\\ 0  \\text{若 } 12x_{2,k}^2  \\tau \\end{cases}$\n   c. 构成更新向量 $\\mathbf{p}_k = \\begin{pmatrix} p_{1,k} \\\\ p_{2,k} \\end{pmatrix}$。\n   d. 检查终止条件：如果欧几里得范数 $\\|\\mathbf{p}_k\\|_2  \\varepsilon_{\\text{step}}$，则终止循环。\n   e. 使用单位步长更新迭代点：$\\mathbf{x}_{k+1} = \\mathbf{x}_k + \\mathbf{p}_k$。\n3. 设最终迭代点为 $\\mathbf{x}^{(f)}$。\n4. 计算到真正最小值点 $\\mathbf{x}^\\star = (1, 0)$ 的最终距离：$d = \\|\\mathbf{x}^{(f)} - \\mathbf{x}^\\star\\|_2 = \\sqrt{(x_1^{(f)} - 1)^2 + (x_2^{(f)})^2}$。\n\n该算法针对指定的五个测试用例进行实现。$\\tau$ 的选择对收敛性有关键影响。如果 $\\tau$ 太大，可能会过早停止在某些方向上的更新，使算法停滞在远离最优点的位置。如果 $\\tau$ 太小，算法行为类似于标准牛顿法，对于这个特定问题可能收敛得很好，但在具有不定海森矩阵的更复杂场景中可能会不稳定。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\n#\n# Execution Environment:\n# language: Python\n# version: 3.12\n# libraries:\n#   - name: numpy\n#     version: 1.23.5\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and runs the spectral-truncated Newton method for a set of\n    test cases to minimize f(x1, x2) = (x1 - 1)^2 + x2^4.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (initial_x1, initial_x2, threshold_tau)\n    test_cases = [\n        (0.0, 1.0, 10**-12),\n        (0.0, 1.0, 0.05),\n        (0.0, 0.1, 0.5),\n        (10.0, 0.2, 3.0),\n        (-5.0, 0.0, 0.01),\n    ]\n\n    # Constants for the optimization algorithm\n    N_max = 100\n    eps_step = 1e-15\n    x_star = np.array([1.0, 0.0])\n\n    results = []\n    for case in test_cases:\n        x1_0, x2_0, tau = case\n        x = np.array([x1_0, x2_0], dtype=float)\n\n        for _ in range(N_max):\n            x1, x2 = x[0], x[1]\n            \n            # The Hessian is diagonal: H = [[2, 0], [0, 12*x2^2]].\n            # Eigenvalues are the diagonal entries.\n            lambda1 = 2.0\n            lambda2 = 12.0 * x2**2\n            \n            # Initialize update direction vector p\n            p = np.zeros(2)\n\n            # Component 1 (along eigenvector q1 = [1, 0])\n            # The full Newton step component would be -(x1 - 1).\n            # We apply this step only if the eigenvalue is not too small.\n            if lambda1 = tau:\n                p[0] = -(x1 - 1)\n            \n            # Component 2 (along eigenvector q2 = [0, 1])\n            # The full Newton step component would be -x2 / 3.\n            # We apply this step only if the eigenvalue is not too small.\n            # The check `lambda2 = tau` also handles the x2=0 case, as\n            # lambda2 would be 0, and tau is specified to be  0.\n            if lambda2 = tau:\n                p[1] = -x2 / 3.0\n            \n            # Check for termination based on the norm of the update step\n            step_norm = np.linalg.norm(p)\n            if step_norm  eps_step:\n                break\n\n            # Update the iterate with a unit step size\n            x = x + p\n\n        # After the loop terminates (by convergence or max iterations),\n        # calculate the Euclidean distance to the global minimum.\n        final_distance = np.linalg.norm(x - x_star)\n        results.append(final_distance)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{d:.12f}' for d in results)}]\")\n\nsolve()\n\n```", "id": "3124776"}]}