{"hands_on_practices": [{"introduction": "在优化领域，理解迭代方法的行为至关重要。本次练习 [@problem_id:3137760] 在一个简洁的几何背景下，对一种此类方法——交替投影法——进行了微观层面的分析。通过从第一性原理出发推导收敛速度，你将深入理解集合的几何性质（在此例中为法向量之间的夹角）如何决定算法的性能。", "problem": "考虑配备标准欧几里得范数 $\\|\\cdot\\|_{2}$ 和内积 $x^{\\top}y$ 的欧几里得空间 $\\mathbb{R}^{2}$。令 $H$ 为闭半空间\n$$\nH \\;=\\; \\{\\, x \\in \\mathbb{R}^{2} \\mid n^{\\top} x \\le 0 \\,\\},\n$$\n其中 $n \\in \\mathbb{R}^{2}$ 是满足 $\\|n\\|_{2} = 1$ 的单位法向量。令 $S$ 为由直线给出的仿射子空间\n$$\nS \\;=\\; \\{\\, p + t\\,u \\mid t \\in \\mathbb{R} \\,\\},\n$$\n其中 $u \\in \\mathbb{R}^{2}$ 是满足 $\\|u\\|_{2}=1$ 的单位方向向量，而 $p \\in \\mathbb{R}^{2}$ 是一个满足 $n^{\\top}p = 0$ 的点（因此 $p$ 位于 $H$ 的边界超平面上）。定义交替投影序列 $x_{k+1} = P_{H}(P_{S}(x_{k}))$，其中对于任意非空闭凸集 $C$，$P_{C}(x)$ 表示 $x$ 到 $C$ 上的欧几里得投影，即 $\\|x - y\\|_{2}$ 在 $y \\in C$ 上的唯一最小化子。\n\n通过平移坐标 $p$ 使交点 $p$ 位于原点，并定义 $y_{k} = P_{H}(x_{k})$（在第 $k$ 个循环中经过半空间投影后的点）。假设初始点满足 $y_{0}$ 位于 $H$ 的边界超平面上，即 $n^{\\top}y_{0}=0$，并且序列对于所有 $k$ 都满足 $n^{\\top}P_{S}(y_{k}) \\ge 0$（也就是说，每次到 $S$ 的投影都产生一个位于 $H$ 上或外部的点，因此后续到 $H$ 的投影表现为到边界超平面的正交投影）。令 $\\theta \\in [0,\\pi]$ 表示单位向量 $n$ 和 $u$ 之间的夹角，即 $\\cos\\theta = n^{\\top}u$。\n\n从欧几里得投影的基本定义出发，推导迭代更新 $y_{k+1}$ 关于 $y_{k}$ 以及几何量 $n$、$u$ 和 $\\theta$ 的闭式表达式。然后，使用此表达式，确定每个交替投影完整周期的线性收敛速度，该速度由标量 $r(\\theta)$ 量化，使得对于所有足够大的 $k$，\n$$\n\\|y_{k+1}\\|_{2} \\;=\\; r(\\theta)\\,\\|y_{k}\\|_{2}.\n$$\n你的最终答案必须是 $r(\\theta)$ 关于 $\\theta$ 的单个闭式解析表达式。无需四舍五入，也不涉及单位。", "solution": "在尝试解答之前，对问题进行验证。\n\n### 步骤 1：提取已知条件\n- 空间是配备标准欧几里得范数 $\\|\\cdot\\|_{2}$ 和内积 $x^{\\top}y$ 的欧几里得空间 $\\mathbb{R}^{2}$。\n- 闭半空间为 $H = \\{\\, x \\in \\mathbb{R}^{2} \\mid n^{\\top} x \\le 0 \\,\\}$，其中 $n \\in \\mathbb{R}^{2}$ 是单位法向量，$\\|n\\|_{2} = 1$。\n- 仿射子空间是直线 $S = \\{\\, p + t\\,u \\mid t \\in \\mathbb{R} \\,\\}$，其中 $u \\in \\mathbb{R}^{2}$ 是单位方向向量，$\\|u\\|_{2}=1$，且 $p \\in \\mathbb{R}^{2}$。\n- 给定关于 $p$ 的条件：$n^{\\top}p = 0$，这意味着 $p$ 位于 $H$ 的边界上，记为 $\\partial H = \\{\\, x \\in \\mathbb{R}^{2} \\mid n^{\\top} x = 0 \\,\\}$。\n- 交替投影序列定义为 $x_{k+1} = P_{H}(P_{S}(x_{k}))$，其中 $P_{C}(x)$ 是 $x$ 到闭凸集 $C$ 上的欧几里得投影。\n- 定义了一个辅助序列 $y_{k} = P_{H}(x_{k})$。\n- 给定了辅助序列的初始条件：$y_{0}$ 位于边界超平面上，$n^{\\top}y_{0}=0$。\n- 对序列提供了一个关键假设：对于所有 $k \\ge 0$，$n^{\\top}P_{S}(y_{k}) \\ge 0$。\n- $n$ 和 $u$ 之间的夹角 $\\theta \\in [0,\\pi]$ 定义为 $\\cos\\theta = n^{\\top}u$。\n- 给出一个指令：“通过平移坐标 $p$ 使交点 $p$ 位于原点”。\n- 目标是推导 $y_{k+1}$ 关于 $y_k$ 的更新规则，然后找到由关系 $\\|y_{k+1}\\|_{2} = r(\\theta)\\,\\|y_{k}\\|_{2}$（对于足够大的 $k$）定义的线性收敛速度 $r(\\theta)$。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题是优化方法领域一个定义明确的练习，具体涉及交替投影算法的收敛性。\n- **科学依据（关键）**：该问题基于欧几里得几何、线性代数和凸分析（投影到凸集）的基本概念。它在数学上是合理的。\n- **适定性**：该问题是适定的。关于主序列 $x_k$ 和辅助序列 $y_k$ 之间关系的模糊性已通过问题结构解决。假设 $n^{\\top}P_{S}(y_{k}) \\ge 0$ 以及寻找 $\\|y_k\\|_2$ 递推关系的目标意味着，问题意在对有效序列 $y_{k+1} = P_H(P_S(y_k))$ 进行分析。在这种标准解释下，$r(\\theta)$ 的唯一解存在。\n- **客观性（关键）**：问题使用精确、客观的数学语言陈述。\n- **所有其他标准**：该问题不违反任何其他验证标准。它不是不完整的、矛盾的、不切实际的或琐碎的。\n\n### 步骤 3：结论与行动\n该问题是**有效的**。将提供完整解答。\n\n### 解答推导\n该问题要求对一个几何迭代进行分析。我们将遵循所提供的指令，并从第一性原理推导结果。\n\n首先，我们采用指定的坐标平移。设新的坐标系用撇号表示，其中 $x' = x - p$。直线和超平面边界的交点现在位于原点，$p' = p-p=0$。\n- 仿射集 $S$ 变为一个线性子空间：$S' = S - p = \\{\\, tu \\mid t \\in \\mathbb{R} \\,\\}$。\n- 半空间 $H$ 由 $n^{\\top}x \\le 0$ 描述。在新坐标中，$n^{\\top}(x'+p) \\le 0$，简化为 $n^{\\top}x' + n^{\\top}p \\le 0$。由于给定 $n^{\\top}p = 0$，半空间在新系统中有相同的形式：$H' = \\{\\, x' \\in \\mathbb{R}^{2} \\mid n^{\\top} x' \\le 0 \\,\\}$。\n- 迭代点被平移为 $y'_k = y_k - p$。初始条件 $n^{\\top}y_0 = 0$ 变为 $n^{\\top}(y'_0+p) = 0$，这意味着 $n^{\\top}y'_0 = 0$。因此，平移后的初始点 $y'_0$ 位于平移后的边界 $\\partial H'$ 上。\n\n为简便起见，从现在开始我们只在这个平移后的坐标系中工作，并省略撇号。问题现在是分析一个从超平面 $\\partial H = \\{\\, x \\mid n^{\\top}x = 0 \\,\\}$ 上的 $y_0$ 开始的迭代，其中 $S = \\{\\, tu \\mid t \\in \\mathbb{R} \\,\\}$ 是一条过原点的直线。\n\n问题要求找到 $y_{k+1}$ 和 $y_k$ 之间的关系。如验证步骤中所论证的，我们分析有效迭代 $y_{k+1} = P_{H}(P_{S}(y_{k}))$。序列从满足 $n^\\top y_0 = 0$ 的 $y_0$ 开始。\n\n迭代包括两个投影步骤：\n1.  **到 $S$ 的投影**：集合 $S$ 是沿单位向量 $u$ 方向穿过原点的直线。一个点 $y_k$ 到 $S$ 上的欧几里得投影由下式给出：\n    $$\n    P_{S}(y_k) = (y_k^{\\top}u)u\n    $$\n    这是通过最小化 $\\|y_k - tu\\|_2^2$ 关于 $t$ 得到的结果，最优的 $t = y_k^{\\top}u / \\|u\\|_2^2 = y_k^{\\top}u$。我们用 $z_k = P_S(y_k)$ 表示这个结果。\n\n2.  **到 $H$ 的投影**：点 $z_k$ 接着被投影到半空间 $H = \\{\\, x \\mid n^{\\top}x \\le 0 \\,\\}$。该投影的公式取决于 $z_k$ 是在 $H$ 内部还是外部。问题提供了一个关键假设，即对于所有 $k$，$n^{\\top}P_{S}(y_{k}) \\ge 0$。这意味着 $n^{\\top}z_k \\ge 0$。\n    - 如果 $n^{\\top}z_k = 0$，那么 $z_k$ 在边界 $\\partial H$ 上，因此 $z_k \\in H$，并且 $P_H(z_k) = z_k$。\n    - 如果 $n^{\\top}z_k > 0$，那么 $z_k$ 在 $H$ 外部。$z_k$ 到闭凸集 $H$ 上的投影是它到边界超平面 $\\partial H = \\{\\, x \\mid n^{\\top}x = 0 \\,\\}$ 上的正交投影。这个投影由下式给出：\n    $$\n    P_{H}(z_k) = z_k - (n^{\\top}z_k)n\n    $$\n    这个相同的公式也涵盖了 $n^{\\top}z_k = 0$ 的情况。因此，在给定的假设下，到 $H$ 的投影总是由这个表达式给出。\n\n现在，我们结合这两个步骤来找到 $y_{k+1}$ 的更新规则。\n$$\ny_{k+1} = P_{H}(z_k) = P_{H}(P_{S}(y_k)) = P_S(y_k) - (n^{\\top}P_S(y_k))n\n$$\n代入 $P_S(y_k)$ 的表达式：\n$$\ny_{k+1} = (y_k^{\\top}u)u - (n^{\\top}((y_k^{\\top}u)u))n\n$$\n项 $y_k^{\\top}u$ 是一个标量，所以我们可以把它提出来：\n$$\ny_{k+1} = (y_k^{\\top}u)u - (y_k^{\\top}u)(n^{\\top}u)n\n$$\n这就得到了迭代更新的闭式表达式：\n$$\ny_{k+1} = (y_k^{\\top}u) [u - (n^{\\top}u)n]\n$$\n这个递推关系的一个重要性质是，如果 $y_k \\in \\partial H$，那么 $y_{k+1} \\in \\partial H$。我们可以验证这一点：\n$n^{\\top}y_{k+1} = n^{\\top}((y_k^{\\top}u)[u - (n^{\\top}u)n]) = (y_k^{\\top}u)[n^{\\top}u - (n^{\\top}u)(n^{\\top}n)]$。因为 $\\|n\\|_2=1$，我们有 $n^{\\top}n=1$。因此，$n^{\\top}y_{k+1} = (y_k^{\\top}u)[n^{\\top}u - n^{\\top}u] = 0$。由于我们从边界上的 $y_0$ 开始，所有后续的迭代点 $y_k$ 都保持在边界 $\\partial H$ 上。\n\n接下来，我们通过求范数之比 $\\|y_{k+1}\\|_2 / \\|y_k\\|_2$ 来确定线性收敛速度 $r(\\theta)$。\n对更新方程取欧几里得范数：\n$$\n\\|y_{k+1}\\|_2 = \\| (y_k^{\\top}u) [u - (n^{\\top}u)n] \\|_2 = |y_k^{\\top}u| \\, \\|u - (n^{\\top}u)n\\|_2\n$$\n我们分析右侧的两项。\n\n第 1 项：$|y_k^{\\top}u|$。\n向量 $y_k$ 位于直线 $\\partial H = \\{\\, x \\mid n^{\\top}x = 0 \\,\\}$ 上。这意味着 $y_k$ 与单位向量 $n$ 正交。项 $y_k^{\\top}u$ 是 $y_k$ 和单位向量 $u$ 之间的内积。设 $\\phi$ 为 $y_k$ 和 $u$ 之间的夹角。那么 $y_k^{\\top}u = \\|y_k\\|_2 \\|u\\|_2 \\cos\\phi = \\|y_k\\|_2 \\cos\\phi$。\n向量 $u$ 与 $n$ 形成一个角度 $\\theta$。由于 $y_k$ 与 $n$ 正交， $u$ 与包含 $y_k$ 的直线之间的夹角是 $\\frac{\\pi}{2} - \\theta$。因此，$u$ 和 $y_k$ 之间的夹角 $\\phi$ 必须是 $\\frac{\\pi}{2} - \\theta$ 或 $\\frac{\\pi}{2} + \\theta$（取决于 $y_k$ 沿直线 $\\partial H$ 的方向）。在这两种情况下，$|\\cos\\phi| = |\\cos(\\frac{\\pi}{2} \\pm \\theta)| = |\\mp\\sin\\theta| = |\\sin\\theta|$。\n因为 $\\theta \\in [0, \\pi]$，所以 $\\sin\\theta \\ge 0$，因此 $|\\sin\\theta| = \\sin\\theta$。\n于是，$|y_k^{\\top}u| = \\|y_k\\|_2 \\sin\\theta$。\n\n第 2 项：$\\|u - (n^{\\top}u)n\\|_2$。\n向量 $v = u - (n^{\\top}u)n$ 是单位向量 $u$ 正交于 $n$ 的分量。这是应用 Gram-Schmidt 过程的结果。我们可以计算其范数的平方：\n$$\n\\|u - (n^{\\top}u)n\\|_2^2 = (u - (n^{\\top}u)n)^{\\top}(u - (n^{\\top}u)n)\n$$\n$$\n= u^{\\top}u - 2(n^{\\top}u)(u^{\\top}n) + (n^{\\top}u)^2(n^{\\top}n)\n$$\n因为 $u$ 和 $n$ 是单位向量，所以 $u^{\\top}u = 1$ 且 $n^{\\top}n = 1$。并且，$n^{\\top}u = \\cos\\theta$。\n$$\n= 1 - 2(\\cos\\theta)^2 + (\\cos\\theta)^2 = 1 - \\cos^2\\theta = \\sin^2\\theta\n$$\n取平方根得到 $\\|u - (n^{\\top}u)n\\|_2 = \\sqrt{\\sin^2\\theta} = |\\sin\\theta|$。因为 $\\theta \\in [0, \\pi]$，所以 $\\sin\\theta \\ge 0$，因此范数是 $\\sin\\theta$。\n\n结合这两项，我们得到 $y_{k+1}$ 的范数：\n$$\n\\|y_{k+1}\\|_2 = (\\|y_k\\|_2 \\sin\\theta) (\\sin\\theta) = (\\sin^2\\theta) \\|y_k\\|_2\n$$\n关系 $\\|y_{k+1}\\|_2 = r(\\theta)\\|y_k\\|_2$ 对所有 $k \\ge 0$ 成立。因此，每个周期的线性收敛速度由标量因子 $r(\\theta)$ 给出。\n\n$$\nr(\\theta) = \\sin^2\\theta\n$$", "answer": "$$\\boxed{\\sin^2(\\theta)}$$", "id": "3137760"}, {"introduction": "现实世界中的可行集通常是多个半空间的交集（即多面体），这构成了比单一半空间更复杂的几何结构。本次实践 [@problem_id:3137818] 旨在解决一个基本问题：如何找到这样一个集合中距离给定外部点最近的点。你将实现戴克斯特拉（Dykstra）算法，这是一种强大的迭代方法，它将交替投影的思想推广到多个集合的情况，从而将抽象的几何理论转化为实用的计算工具。", "problem": "考虑一个有限维实向量空间中的欧几里得投影问题。设 $n \\in \\mathbb{N}$，并给定 $\\mathbb{R}^n$ 中 $m \\in \\mathbb{N}$ 个闭半空间族，由形式为 $C_i = \\{x \\in \\mathbb{R}^n : a_i^\\top x \\le b_i\\}$（$i \\in \\{1,\\dots,m\\}$）的线性不等式给出，其中 $a_i \\in \\mathbb{R}^n$ 且 $b_i \\in \\mathbb{R}$。设 $x_0 \\in \\mathbb{R}^n$ 为一个点，我们寻求其在交集 $C = \\bigcap_{i=1}^m C_i$ 上的欧几里得投影，即一个点 $x^\\star \\in C$，该点最小化目标函数 $x \\mapsto \\tfrac{1}{2}\\|x - x_0\\|_2^2$。\n\n从 $\\mathbb{R}^n$ 中点到非空闭凸集上的欧几里得投影的基本定义，以及闭半空间的交集是闭凸集这一已知的成熟结论出发，推导并实现一种迭代方法。该方法使用对单个半空间的循环投影和逐集校正项，以收敛到 $x_0$ 在 $C$ 上的投影。该方法的设计必须使校正量沿半空间的法向量 $a_i$ 累积，从而提供一种在数值上直接观察这种累积的方式。对单个闭半空间的投影必须通过求解相应的、受一个线性不等式约束的最小距离问题来处理。当一个完整循环后迭代点的变化量低于预设的容差，或达到最大循环次数时，该迭代方法必须终止。\n\n您的程序必须实现此投影过程，并对下面测试套件中的每个测试用例，生成一个包含以下内容的实数列表作为其结果：\n- 首先，按顺序给出投影点 $x^\\star$ 的坐标。\n- 接着，对于给定顺序的每个半空间，给出一个标量，用于量化最终校正项沿相应法向量的累积。对于第 $i$ 个半空间，使用标量 $s_i = \\dfrac{a_i^\\top y_i}{\\|a_i\\|_2^2}$，其中 $y_i \\in \\mathbb{R}^n$ 表示迭代方法在终止时为集合 $i$ 存储的最终校正向量。该标量等于对该集合的最后一次校正中沿法向量方向 $a_i$ 所取的有符号步长，是校正量如何沿 $a_i$ 累积的简明度量。\n\n使用停止容差 $10^{-10}$ 和最多 $10000$ 次遍历所有半空间的循环。此问题不涉及物理单位。所有角度（如果隐式出现在向量运算中）均通过标准内积以弧度处理；不需要显式的角度单位。所有答案必须表示为实数。\n\n测试套件：\n- 情况1（二维，两个半空间构成非正象限）：$n = 2$, $m = 2$, $a_1 = [1, 0]^\\top$, $b_1 = 0$, $a_2 = [0, 1]^\\top$, $b_2 = 0$, $x_0 = [1, 2]^\\top$。\n- 情况2（二维，三个半空间构成一个带底的楔形）：$n = 2$, $m = 3$, $a_1 = [1, 1]^\\top$, $b_1 = 1$, $a_2 = [-1, 2]^\\top$, $b_2 = 2$, $a_3 = [0, -1]^\\top$, $b_3 = 0$, $x_0 = [2, 3]^\\top$。\n- 情况3（三维，轴对齐的盒子）：$n = 3$, $m = 6$, $a_1 = [1, 0, 0]^\\top$, $b_1 = 1$, $a_2 = [-1, 0, 0]^\\top$, $b_2 = 1$, $a_3 = [0, 1, 0]^\\top$, $b_3 = 1$, $a_4 = [0, -1, 0]^\\top$, $b_4 = 1$, $a_5 = [0, 0, 1]^\\top$, $b_5 = 1$, $a_6 = [0, 0, -1]^\\top$, $b_6 = 1$, $x_0 = [2, -3, 0.5]^\\top$。\n- 情况4（二维，四个半空间交于一点）：$n = 2$, $m = 4$, $a_1 = [1, 0]^\\top$, $b_1 = 1$, $a_2 = [-1, 0]^\\top$, $b_2 = -1$, $a_3 = [0, 1]^\\top$, $b_3 = -1$, $a_4 = [0, -1]^\\top$, $b_4 = 1$, $x_0 = [-2, 4]^\\top$。\n- 情况5（二维，位于情况2楔形内部的点）：$n = 2$, $m = 3$, $a_1 = [1, 1]^\\top$, $b_1 = 1$, $a_2 = [-1, 2]^\\top$, $b_2 = 2$, $a_3 = [0, -1]^\\top$, $b_3 = 0$, $x_0 = [0.2, 0.3]^\\top$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。此列表的每个元素必须是单个测试用例的 Python 列表表示，通过连接投影点 $x^\\star$ 的坐标和该用例中按半空间顺序排列的标量 $s_i$ 构建而成。例如，三个用例的输出应如下所示：$[ [x^\\star\\_1\\_1, x^\\star\\_1\\_2, s\\_{1,1}, s\\_{1,2}, \\dots], [x^\\star\\_2\\_1, x^\\star\\_2\\_2, s\\_{2,1}, s\\_{2,2}, \\dots], [x^\\star\\_3\\_1, x^\\star\\_3\\_2, x^\\star\\_3\\_3, s\\_{3,1}, \\dots ] ]$，不含任何额外文本。", "solution": "用户提供的问题是有效的。它在科学上基于凸优化领域，特别是欧几里得投影到凸集。该问题是适定的，因为一个点在非空闭凸集上的投影是唯一的。问题陈述客观、完整，且不包含矛盾。我们可以继续提供解决方案。\n\n### 投影到单个半空间\n\nDykstra 算法中的基本操作是投影到单个半空间上，即 $P_{C_i}(y)$，它寻找 $C_i$ 中距离给定点 $y \\in \\mathbb{R}^n$ 最近的点。这是一个凸优化子问题：\n$$\n\\text{minimize} \\quad \\frac{1}{2}\\|x - y\\|_2^2 \\quad \\text{subject to} \\quad a_i^\\top x \\le b_i\n$$\n其解可以使用 Karush-Kuhn-Tucker (KKT) 条件推导。拉格朗日函数为 $L(x, \\mu) = \\frac{1}{2}\\|x - y\\|_2^2 + \\mu(a_i^\\top x - b_i)$，其中 $\\mu \\ge 0$。\nKKT 条件如下：\n1.  **平稳性 (Stationarity)：** $\\nabla_x L = x - y + \\mu a_i = 0 \\implies x = y - \\mu a_i$。\n2.  **原始可行性 (Primal feasibility)：** $a_i^\\top x \\le b_i$。\n3.  **对偶可行性 (Dual feasibility)：** $\\mu \\ge 0$。\n4.  **互补松弛性 (Complementary slackness)：** $\\mu(a_i^\\top x - b_i) = 0$。\n\n由此产生两种情况：\n- 如果 $y$ 已经位于半空间 $C_i$ 内，则 $a_i^\\top y \\le b_i$。我们可以设 $\\mu = 0$。根据平稳性条件，有 $x = y$。所有 KKT 条件均满足，因此 $P_{C_i}(y) = y$。\n- 如果 $y$ 在 $C_i$ 之外，则 $a_i^\\top y > b_i$。这要求 $\\mu > 0$。根据互补松弛性，约束必须是活动的：$a_i^\\top x = b_i$。将 $x = y - \\mu a_i$ 代入此等式，得到 $a_i^\\top (y - \\mu a_i) = b_i$，解出 $\\mu = \\frac{a_i^\\top y - b_i}{\\|a_i\\|_2^2}$。由于 $a_i^\\top y > b_i$，我们有 $\\mu > 0$，符合要求。投影点为 $x = y - \\frac{a_i^\\top y - b_i}{\\|a_i\\|_2^2} a_i$。\n\n使用正部函数 $(z)_+ = \\max(0, z)$ 合并这两种情况，投影算子可表示为：\n$$\nP_{C_i}(y) = y - \\frac{(a_i^\\top y - b_i)_+}{\\|a_i\\|_2^2} a_i\n$$\n此公式假设 $a_i \\neq 0$，对于任何良定义的半空间，该假设均成立。\n\n### Dykstra 投影算法\n\nDykstra 算法是一种用于寻找点在交集 $C=\\bigcap_{i=1}^m C_i$ 上投影的迭代过程。它维护一个主迭代点（收敛到解 $x^\\star$）和一组 $m$ 个辅助校正向量（每个半空间一个）。这些向量（记为 $y_i$）“存储”了先前投影步骤中垂直于相应半空间边界的位移分量。问题陈述准确地描述了这些校正的作用。\n\n该算法按以下步骤进行：\n\n1.  **初始化：**\n    -   设置初始迭代点 $x^{(0)} = x_0$。\n    -   为 $i=1, \\dots, m$ 初始化 $m$ 个校正向量 $y_i^{(0)} = \\mathbf{0} \\in \\mathbb{R}^n$。\n\n2.  **迭代：** 对于每个循环 $k = 0, 1, 2, \\dots$（直到达到最大循环次数）：\n    a.  存储循环开始时的迭代点：$x_{\\text{start of cycle}} = x^{(k)}$。\n    b.  初始化循环的中间点：$z_0 = x^{(k)}$。\n    c.  对所有半空间 $i = 1, \\dots, m$ 执行一个完整的投影循环：\n        i.   定义要投影到 $C_i$ 上的点：$v_i = z_{i-1} + y_i^{(k)}$。\n        ii.  投影该点：$z_i = P_{C_i}(v_i)$。\n        iii. 更新用于下一个循环的校正向量：$y_i^{(k+1)} = v_i - z_i$。\n    d.  更新用于下一个循环的主迭代点：$x^{(k+1)} = z_m$。\n    e.  **终止检查：** 如果 $\\|x^{(k+1)} - x_{\\text{start of cycle}}\\|_2  \\text{tolerance}$，则算法已收敛。\n\n校正向量的更新规则 $y_i^{(k+1)} = v_i - P_{C_i}(v_i)$ 与投影算子的公式相结合，表明 $y_i^{(k+1)}$ 始终是法向量 $a_i$ 的一个非负标量倍数：\n$$\ny_i^{(k+1)} = \\frac{(a_i^\\top v_i - b_i)_+}{\\|a_i\\|_2^2} a_i\n$$\n这证实了问题描述中“校正量沿法向量 $a_i$ 累积”的说法。\n\n### 最终输出计算\n\n算法终止时，得到投影点 $x^\\star \\approx x^{(k+1)}$ 和最终的校正向量集 $\\{y_i^{\\text{final}}\\}$。问题要求为每个半空间计算一个标量 $s_i$，其定义为：\n$$\ns_i = \\frac{a_i^\\top y_i^{\\text{final}}}{\\|a_i\\|_2^2}\n$$\n由于 $y_i^{\\text{final}}$ 必为 $\\lambda_i a_i$ 的形式（其中 $\\lambda_i \\ge 0$ 为某个标量），我们可以将其代入 $s_i$ 的公式中：\n$$\ns_i = \\frac{a_i^\\top (\\lambda_i a_i)}{\\|a_i\\|_2^2} = \\frac{\\lambda_i (a_i^\\top a_i)}{\\|a_i\\|_2^2} = \\lambda_i\n$$\n因此，$s_i$ 正是将校正向量 $y_i^{\\text{final}}$ 与法向量 $a_i$ 关联起来的最终标量乘子。该值表示沿 $a_i$ 方向的累积校正幅度。\n\n实现将遵循此推导的算法，计算 $x^\\star$ 的最终坐标，然后使用最终的校正向量 $\\{y_i^{\\text{final}}\\}$ 来计算标量 $\\{s_i\\}$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Euclidean projection problem for a set of test cases using Dykstra's algorithm.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: 2D, nonpositive quadrant\n        {\n            \"x0\": np.array([1, 2], dtype=float),\n            \"a\": [np.array([1, 0], dtype=float), np.array([0, 1], dtype=float)],\n            \"b\": [0.0, 0.0]\n        },\n        # Case 2: 2D, wedge with floor\n        {\n            \"x0\": np.array([2, 3], dtype=float),\n            \"a\": [np.array([1, 1], dtype=float), np.array([-1, 2], dtype=float), np.array([0, -1], dtype=float)],\n            \"b\": [1.0, 2.0, 0.0]\n        },\n        # Case 3: 3D, axis-aligned box\n        {\n            \"x0\": np.array([2, -3, 0.5], dtype=float),\n            \"a\": [\n                np.array([1, 0, 0], dtype=float), np.array([-1, 0, 0], dtype=float),\n                np.array([0, 1, 0], dtype=float), np.array([0, -1, 0], dtype=float),\n                np.array([0, 0, 1], dtype=float), np.array([0, 0, -1], dtype=float)\n            ],\n            \"b\": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n        },\n        # Case 4: 2D, point intersection\n        {\n            \"x0\": np.array([-2, 4], dtype=float),\n            \"a\": [\n                np.array([1, 0], dtype=float), np.array([-1, 0], dtype=float),\n                np.array([0, 1], dtype=float), np.array([0, -1], dtype=float)\n            ],\n            \"b\": [1.0, -1.0, -1.0, 1.0]\n        },\n        # Case 5: 2D, interior point\n        {\n            \"x0\": np.array([0.2, 0.3], dtype=float),\n            \"a\": [np.array([1, 1], dtype=float), np.array([-1, 2], dtype=float), np.array([0, -1], dtype=float)],\n            \"b\": [1.0, 2.0, 0.0]\n        }\n    ]\n\n    # Algorithm parameters\n    TOLERANCE = 1e-10\n    MAX_CYCLES = 10000\n\n    results = []\n\n    def project_halfspace(y_proj, a_i, b_i):\n        \"\"\"\n        Projects a point y_proj onto the halfspace a_i^T x = b_i.\n        \"\"\"\n        a_norm_sq = np.dot(a_i, a_i)\n        if a_norm_sq == 0:\n            return y_proj\n\n        violation = np.dot(a_i, y_proj) - b_i\n        \n        if violation = 0:\n            return y_proj\n        \n        lambda_val = violation / a_norm_sq\n        return y_proj - lambda_val * a_i\n\n    for case in test_cases:\n        x0 = case[\"x0\"]\n        a_vectors = case[\"a\"]\n        b_scalars = case[\"b\"]\n        m = len(a_vectors)\n        n = len(x0)\n\n        # Initialization\n        x_k = np.copy(x0)\n        y_corrections = [np.zeros(n, dtype=float) for _ in range(m)]\n\n        for k in range(MAX_CYCLES):\n            x_start_of_cycle = np.copy(x_k)\n            \n            x_intermediate = x_k\n            for i in range(m):\n                a_i = a_vectors[i]\n                b_i = b_scalars[i]\n                \n                point_to_project = x_intermediate + y_corrections[i]\n                x_projected = project_halfspace(point_to_project, a_i, b_i)\n                \n                # Update correction vector for this halfspace\n                y_corrections[i] = point_to_project - x_projected\n                \n                # Update the intermediate point for the next projection in the cycle\n                x_intermediate = x_projected\n            \n            x_k = x_intermediate # Final point after one full cycle\n            \n            # Termination check\n            change = np.linalg.norm(x_k - x_start_of_cycle)\n            if change  TOLERANCE:\n                break\n        \n        x_star = x_k\n        \n        # Calculate final scalars s_i\n        s_values = []\n        for i in range(m):\n            a_i = a_vectors[i]\n            y_i = y_corrections[i]\n            a_norm_sq = np.dot(a_i, a_i)\n            if a_norm_sq > 0:\n                s_i = np.dot(a_i, y_i) / a_norm_sq\n            else:\n                s_i = 0.0 # Should not happen with valid halfspaces\n            s_values.append(s_i)\n            \n        # Combine results for this case\n        case_result = list(x_star) + s_values\n        results.append(case_result)\n\n    # Format the final output string\n    # str() on a list gives a nice '[...]' representation.\n    # We join these string representations with commas.\n    output_str = f\"[{','.join(map(str, results))}]\"\n    print(output_str)\n\nsolve()\n```", "id": "3137818"}, {"introduction": "在学会如何在给定的可行集中寻找点之后，我们将焦点转向约束本身的构建方式。本次练习 [@problem_id:3137852] 对比了必须严格满足的“硬约束”与允许违反但会施加惩罚的“软约束”。这是机器学习和鲁棒优化中的一个关键概念，理解通过惩罚函数和铰链损失（hinge loss）建立的联系，对于现代问题求解至关重要。", "problem": "考虑 $\\mathbb{R}^n$ 中的一个半空间约束族，由 $a_i^\\top x \\le b_i$ 给出，其中 $i \\in \\{1,\\dots,m\\}$，$a_i \\in \\mathbb{R}^n$ 且 $b_i \\in \\mathbb{R}$。定义目标函数为 $f(x) = \\tfrac{1}{2}\\|x\\|_2^2$。硬约束问题寻求精确的可行性：\n- 硬问题 $\\mathcal{P}_{\\mathrm{hard}}$：最小化 $f(x)$，约束条件为对所有 $i \\in \\{1,\\dots,m\\}$，都有 $a_i^\\top x \\le b_i$。\n\n为了探索半空间的软执行，定义铰链惩罚 $[t]_+ := \\max\\{0,t\\}$，并考虑对于一个惩罚权重 $\\mu  0$ 的无约束软惩罚问题：\n- 软问题 $\\mathcal{P}_{\\mathrm{soft}}(\\mu)$：在 $x \\in \\mathbb{R}^n$ 上最小化 $F_\\mu(x) := f(x) + \\mu \\sum_{i=1}^m [a_i^\\top x - b_i]_+$。\n\n在整个问题中，假设 $f$ 和 $[\\,\\cdot\\,]_+$ 的定义如上，且 $a_i$ 和 $b_i$ 是固定的数据。当一个陈述提到拉格朗日乘子时，应在不等式约束的标准凸对偶假设下进行解释（例如，Slater 条件，以确保最优的 Karush-Kuhn-Tucker (KKT) 乘子存在）。\n\n选择所有正确的陈述。\n\nA. 对每个 $\\mu  0$，函数 $F_\\mu$ 是凸且强制的，并且由于 $f$ 是强凸的，$\\mathcal{P}_{\\mathrm{soft}}(\\mu)$ 在 $\\mathbb{R}^n$ 中有唯一的最小化子。\n\nB. 如果可行集 $\\{x \\in \\mathbb{R}^n : a_i^\\top x \\le b_i \\ \\forall i\\}$ 非空，那么对于 $\\mu \\to +\\infty$，$\\mathcal{P}_{\\mathrm{soft}}(\\mu)$ 的任何最小化子序列 $\\{x_\\mu\\}$ 的所有聚点都是 $\\mathcal{P}_{\\mathrm{hard}}$ 的解。因为 $f$ 是强凸的，硬问题有唯一解 $x^\\star$，并且当 $\\mu \\to +\\infty$ 时，$x_\\mu \\to x^\\star$。\n\nC. 如果可行集非空，那么对于每个固定的 $\\mu  0$，$\\mathcal{P}_{\\mathrm{soft}}(\\mu)$ 的唯一最小化子必然对于硬约束是可行的。\n\nD. 如果可行集为空，令 $h(x) := \\sum_{i=1}^m [a_i^\\top x - b_i]_+$。当 $\\mu \\to +\\infty$ 时，$\\mathcal{P}_{\\mathrm{soft}}(\\mu)$ 的最小化子 $x_\\mu$ 的任何聚点都解决了这个字典序优化问题：首先在 $x \\in \\mathbb{R}^n$ 上最小化 $h(x)$，然后在 $h$ 的所有最小化子中，最小化 $f(x)$。\n\nE. 在 $n=1$ 的一维情况下，对于两个不一致的半空间 $x \\le 0$ 和 $x \\ge 1$，对每个 $\\mu0$，$\\mathcal{P}_{\\mathrm{soft}}(\\mu)$ 的唯一最小化子是 $x=0$。\n\n选择所有适用的选项：\nA, B, C, D, E.", "solution": "## 问题验证\n\n### 步骤 1：提取已知条件\n- **定义域**: $\\mathbb{R}^n$\n- **半空间约束**: $a_i^\\top x \\le b_i$，其中 $i \\in \\{1,\\dots,m\\}$，$a_i \\in \\mathbb{R}^n$ 且 $b_i \\in \\mathbb{R}$。\n- **目标函数**: $f(x) = \\tfrac{1}{2}\\|x\\|_2^2$。\n- **硬约束问题 ($\\mathcal{P}_{\\mathrm{hard}}$)**: 最小化 $f(x)$，约束条件为对所有 $i \\in \\{1,\\dots,m\\}$，都有 $a_i^\\top x \\le b_i$。\n- **铰链惩罚函数**: $[t]_+ := \\max\\{0,t\\}$。\n- **惩罚权重**: $\\mu  0$。\n- **软惩罚目标函数**: $F_\\mu(x) := f(x) + \\mu \\sum_{i=1}^m [a_i^\\top x - b_i]_+$。\n- **软惩罚问题 ($\\mathcal{P}_{\\mathrm{soft}}(\\mu)$)**: 在 $x \\in \\mathbb{R}^n$ 上最小化 $F_\\mu(x)$。\n- **对偶性假设**: 当提到拉格朗日乘子时，假定标准凸对偶假设（例如 Slater 条件）成立，以确保最优 Karush-Kuhn-Tucker (KKT) 乘子的存在。\n\n### 步骤 2：使用提取的已知条件进行验证\n问题陈述在科学和数学上是合理的。它描述了惩罚方法在凸二次规划问题中的一个标准应用。函数、变量和优化问题在凸优化领域内都得到了很好的定义。\n\n1.  **科学或事实上的不合理之处**：无。该问题基于凸分析和优化理论的既定原则。\n2.  **不可形式化或不相关**：无。该问题是一个形式化的数学问题，直接关系到超平面、半空间和优化方法。\n3.  **不完整或矛盾的设置**：无。该问题是自洽的。选项正确地探讨了不同的情景，例如约束集的可行性，这是分析的关键部分。\n4.  **不切实际或不可行**：无。该问题是抽象和数学的；物理现实主义不是一个相关的标准。\n5.  **不适定或结构不良**：无。问题 $\\mathcal{P}_{\\mathrm{hard}}$ 和 $\\mathcal{P}_{\\mathrm{soft}}(\\mu)$ 是标准的且适定的。解的存在性和唯一性是所涉函数性质的结果，这是一个需要分析的课题。\n6.  **伪深刻、琐碎或同义反复**：无。该问题需要对凸函数、惩罚方法及其收敛性质有扎实的理解。\n7.  **超出科学可验证性范围**：无。所有陈述都可以通过数学方法证明或证伪。\n\n### 步骤 3：结论与行动\n问题是**有效的**。解决方案将继续对每个选项进行详细的推导和评估。\n\n---\n\n### 函数分析\n\n目标函数是 $f(x) = \\tfrac{1}{2}\\|x\\|_2^2$。这个函数是强制的，因为当 $\\|x\\|_2 \\to +\\infty$ 时，$f(x) \\to +\\infty$。它的 Hessian 矩阵是单位矩阵，$\\nabla^2 f(x) = I$，这是正定的。因此，$f(x)$ 是一个 1-强凸函数。\n\n惩罚项涉及铰链函数 $[t]_+ = \\max\\{0,t\\}$，它是凸的。函数 $g_i(x) = a_i^\\top x - b_i$ 是仿射的，因此是凸的。复合函数 $[g_i(x)]_+$ 是凸的，因为 $[\\cdot]_+$ 是一个凸且非递减的函数。凸函数的和 $\\sum_{i=1}^m [a_i^\\top x - b_i]_+$ 也是凸的。\n\n软问题的目标函数是 $F_\\mu(x) = f(x) + \\mu \\sum_{i=1}^m [a_i^\\top x - b_i]_+$。\n\n### 逐项分析\n\n**A. 对每个 $\\mu  0$，函数 $F_\\mu$ 是凸且强制的，并且由于 $f$ 是强凸的，$\\mathcal{P}_{\\mathrm{soft}}(\\mu)$ 在 $\\mathbb{R}^n$ 中有唯一的最小化子。**\n\n-   **凸性**: $F_\\mu(x)$ 是 $f(x)$ 和 $\\mu \\sum_{i=1}^m [a_i^\\top x - b_i]_+$ 的和。如前所述，$f(x)$ 是强凸的，而惩罚项是凸的（作为凸函数的非负加权和）。一个强凸函数和一个凸函数的和是强凸的。因此，对于任何 $\\mu  0$，$F_\\mu(x)$ 都是强凸的。强凸性意味着严格凸性，而严格凸性又意味着凸性。\n-   **强制性**: 惩罚项 $\\mu \\sum_{i=1}^m [a_i^\\top x - b_i]_+$ 是非负的。因此，$F_\\mu(x) \\ge f(x) = \\tfrac{1}{2}\\|x\\|_2^2$。由于 $f(x)$ 是强制的（即当 $\\|x\\|_2 \\to +\\infty$ 时，$f(x) \\to +\\infty$），$F_\\mu(x)$ 也必须是强制的。\n-   **最小化子的存在性与唯一性**: 一个连续的强制函数在 $\\mathbb{R}^n$ 中至少有一个最小化子。一个严格凸函数至多有一个最小化子。由于 $F_\\mu(x)$ 是强凸的（因此是严格凸的）和强制的，它在 $\\mathbb{R}^n$ 中拥有唯一的最小化子。该陈述中的推理是正确的。\n\n**A 的结论：正确。**\n\n**B. 如果可行集 $\\{x \\in \\mathbb{R}^n : a_i^\\top x \\le b_i \\ \\forall i\\}$ 非空，那么对于 $\\mu \\to +\\infty$，$\\mathcal{P}_{\\mathrm{soft}}(\\mu)$ 的任何最小化子序列 $\\{x_\\mu\\}$ 的所有聚点都是 $\\mathcal{P}_{\\mathrm{hard}}$ 的解。因为 $f$ 是强凸的，硬问题有唯一解 $x^\\star$，并且当 $\\mu \\to +\\infty$ 时，$x_\\mu \\to x^\\star$。**\n\n这个陈述描述了惩罚方法对于一个可行问题的收敛性。\n-   令 $S = \\{x \\in \\mathbb{R}^n : a_i^\\top x \\le b_i \\ \\forall i\\}$ 为可行集。由于 $S$ 是一个非空闭凸集且 $f(x)$ 是强凸的，$\\mathcal{P}_{\\mathrm{hard}}$ 有一个唯一的解，我们记为 $x^\\star$。令 $f^\\star = f(x^\\star)$。\n-   令 $x_\\mu$ 为 $F_\\mu(x)$ 的唯一最小化子。根据定义，对任何 $x \\in \\mathbb{R}^n$，有 $F_\\mu(x_\\mu) \\le F_\\mu(x)$。\n-   我们选择 $x = x^\\star$。由于 $x^\\star \\in S$，对所有 $i$ 都有 $a_i^\\top x^\\star - b_i \\le 0$，这意味着 $[a_i^\\top x^\\star - b_i]_+ = 0$。因此，$F_\\mu(x^\\star) = f(x^\\star) = f^\\star$。\n-   不等式变为：$f(x_\\mu) + \\mu \\sum_{i=1}^m [a_i^\\top x_\\mu - b_i]_+ \\le f^\\star$。\n-   由此我们推断出两个事实：\n    1.  $f(x_\\mu) \\le f^\\star$，这意味着 $\\tfrac{1}{2}\\|x_\\mu\\|_2^2 \\le f^\\star$。这表明序列 $\\{x_\\mu\\}$ 是有界的。根据 Bolzano-Weierstrass 定理，它至少有一个聚点。\n    2.  $\\sum_{i=1}^m [a_i^\\top x_\\mu - b_i]_+ \\le \\frac{f^\\star - f(x_\\mu)}{\\mu} \\le \\frac{f^\\star}{\\mu}$。当 $\\mu \\to +\\infty$ 时，右侧趋向于 $0$。所以，$\\sum_{i=1}^m [a_i^\\top x_\\mu - b_i]_+ \\to 0$。\n-   令 $\\bar{x}$ 为 $\\{x_\\mu\\}$ 的任意聚点。存在一个子序列 $\\{x_{\\mu_k}\\}$ 使得 $x_{\\mu_k} \\to \\bar{x}$。\n-   根据连续性，$\\lim_{k\\to\\infty} \\sum_{i=1}^m [a_i^\\top x_{\\mu_k} - b_i]_+ = \\sum_{i=1}^m [a_i^\\top \\bar{x} - b_i]_+ = 0$。由于每一项都是非负的，这意味着对所有 $i$，都有 $[a_i^\\top \\bar{x} - b_i]_+ = 0$，即对所有 $i$，都有 $a_i^\\top \\bar{x} \\le b_i$。因此，$\\bar{x}$ 对于 $\\mathcal{P}_{\\mathrm{hard}}$ 是可行的。\n-   同时，对 $f(x_{\\mu_k}) \\le f^\\star$ 取极限得到 $f(\\bar{x}) \\le f^\\star$。\n-   由于 $\\bar{x}$ 是 $\\mathcal{P}_{\\mathrm{hard}}$ 的一个可行点，而 $x^\\star$ 是最小化子，我们必有 $f(\\bar{x}) \\ge f^\\star$。\n-   结合这两点可得 $f(\\bar{x}) = f^\\star$。由于 $x^\\star$ 是唯一的最小化子，必然有 $\\bar{x} = x^\\star$。\n-   一个有界的、只有一个聚点的序列会收敛到该点。因此，当 $\\mu \\to +\\infty$ 时，$x_\\mu \\to x^\\star$。这个陈述是惩罚方法中的一个经典结果。\n\n**B 的结论：正确。**\n\n**C. 如果可行集非空，那么对于每个固定的 $\\mu  0$，$\\mathcal{P}_{\\mathrm{soft}}(\\mu)$ 的唯一最小化子必然对于硬约束是可行的。**\n\n这个陈述声称惩罚方法对于任何有限的惩罚参数 $\\mu  0$ 都能找到一个可行解。这通常是不正确的。解 $x_\\mu$ 通常随着 $\\mu$ 的增加而趋近于可行域。\n让我们构造一个反例。\n令 $n=1$，单一约束为 $x \\le -1$。可行集为 $(-\\infty, -1]$，是非空的。\n$\\mathcal{P}_{\\mathrm{hard}}$：最小化 $\\tfrac{1}{2}x^2$，约束条件为 $x \\le -1$。解是 $x^\\star = -1$。\n$\\mathcal{P}_{\\mathrm{soft}}(\\mu)$：最小化 $F_\\mu(x) = \\tfrac{1}{2}x^2 + \\mu[x - (-1)]_+ = \\tfrac{1}{2}x^2 + \\mu[x+1]_+$。\n为了找到最小化子 $x_\\mu$，我们分析 $F_\\mu(x)$ 的次梯度：$\\partial F_\\mu(x) = x + \\mu \\partial[x+1]_+$。\n-   如果 $x  -1$，$\\partial F_\\mu(x) = \\{x+\\mu\\}$。设 $x+\\mu=0$ 得到 $x = -\\mu$。如果 $-\\mu  -1$，即 $\\mu  1$，这是一个有效的候选解。\n-   如果 $x  -1$，$\\partial F_\\mu(x) = \\{x\\}$。设 $x=0$ 与 $x  -1$ 矛盾。此处无解。\n-   如果 $x = -1$，$\\partial F_\\mu(-1) = -1 + \\mu[0,1] = [-1, -1+\\mu]$。如果 $-1+\\mu \\ge 0$，即 $\\mu \\ge 1$，则次梯度包含 $0$。\n所以，当 $\\mu \\in (0, 1)$ 时，最小化子是 $x_\\mu = -\\mu$，当 $\\mu \\ge 1$ 时，最小化子是 $x_\\mu=-1$。\n对于任何 $\\mu \\in (0, 1)$，最小化子是 $x_\\mu = -\\mu$。由于 $-\\mu  -1$，这个最小化子对于硬约束 $x \\le -1$ 是不可行的。例如，如果 $\\mu=0.5$，$x_{0.5} = -0.5$，这违反了 $x \\le -1$。\n\n**C 的结论：不正确。**\n\n**D. 如果可行集为空，令 $h(x) := \\sum_{i=1}^m [a_i^\\top x - b_i]_+$。当 $\\mu \\to +\\infty$ 时，$\\mathcal{P}_{\\mathrm{soft}}(\\mu)$ 的最小化子 $x_\\mu$ 的任何聚点都解决了这个字典序优化问题：首先在 $x \\in \\mathbb{R}^n$ 上最小化 $h(x)$，然后在 $h$ 的所有最小化子中，最小化 $f(x)$。**\n\n这描述了当约束不一致时，正则化问题的行为。\n-   令 $h^\\star = \\inf_{x \\in \\mathbb{R}^n} h(x)$。由于可行集为空，对所有 $x$ 都有 $h(x)  0$，所以 $h^\\star  0$（假设下确界可以达到）。令 $S_h = \\{x \\in \\mathbb{R}^n \\mid h(x) = h^\\star\\}$ 为 $h(x)$ 的最小化子集合。由于 $h(x)$ 是凸的，$S_h$ 是一个凸集。假设 $S_h$ 非空，我们可以定义字典序解。\n-   令 $x^\\star_{lex}$ 为 $\\min_{x \\in S_h} f(x)$ 的唯一解。该解存在且唯一，因为 $f(x)$ 是强凸的，且 $S_h$ 是一个闭凸集。\n-   令 $x_\\mu$ 为 $F_\\mu(x) = f(x) + \\mu h(x)$ 的最小化子。对任何 $x \\in S_h$，我们有 $f(x_\\mu) + \\mu h(x_\\mu) \\le f(x) + \\mu h(x) = f(x) + \\mu h^\\star$。特别地，使用 $x = x^\\star_{lex}$：$f(x_\\mu) + \\mu h(x_\\mu) \\le f(x^\\star_{lex}) + \\mu h^\\star$。\n-   这意味着 $f(x_\\mu) \\le f(x^\\star_{lex}) + \\mu(h^\\star - h(x_\\mu))$。由于 $h(x_\\mu) \\ge h^\\star$，第二项是非正的，所以 $f(x_\\mu) \\le f(x^\\star_{lex})$。这表明序列 $\\{x_\\mu\\}$ 是有界的。\n-   从同一个不等式，我们有 $h(x_\\mu) - h^\\star \\le \\frac{f(x^\\star_{lex}) - f(x_\\mu)}{\\mu} \\le \\frac{f(x^\\star_{lex})}{\\mu}$。当 $\\mu \\to +\\infty$ 时，这意味着 $h(x_\\mu) \\to h^\\star$。\n-   令 $\\bar{x}$ 为 $\\{x_\\mu\\}$ 的一个聚点。根据 $h(x)$ 的连续性，$h(\\bar{x}) = h^\\star$。所以，任何聚点 $\\bar{x}$ 都是 $h(x)$ 的一个最小化子，即 $\\bar{x} \\in S_h$。\n-   沿着收敛到 $\\bar{x}$ 的子序列，对不等式 $f(x_\\mu) \\le f(x^\\star_{lex})$ 取上极限，我们得到 $f(\\bar{x}) \\le f(x^\\star_{lex})$。\n-   但是根据 $x^\\star_{lex}$ 作为 $f(x)$ 在 $S_h$ 上的最小化子的定义，并且由于 $\\bar{x} \\in S_h$，我们必有 $f(\\bar{x}) \\ge f(x^\\star_{lex})$。\n-   因此，$f(\\bar{x}) = f(x^\\star_{lex})$。由于 $x^\\star_{lex}$ 是 $f$ 在 $S_h$ 上的唯一最小化子，我们必有 $\\bar{x} = x^\\star_{lex}$。\n-   由于有界序列 $\\{x_\\mu\\}$ 有唯一的聚点 $x^\\star_{lex}$，整个序列都收敛于它。该陈述是正确的。\n\n**D 的结论：正确。**\n\n**E. 在 $n=1$ 的一维情况下，对于两个不一致的半空间 $x \\le 0$ 和 $x \\ge 1$，对每个 $\\mu0$，$\\mathcal{P}_{\\mathrm{soft}}(\\mu)$ 的唯一最小化子是 $x=0$。**\n\n约束是 $x \\le 0$ 和 $-x \\le -1$。可行集为空。\n软目标函数是 $F_\\mu(x) = \\tfrac{1}{2}x^2 + \\mu([x-0]_+ + [-x-(-1)]_+) = \\tfrac{1}{2}x^2 + \\mu([x]_+ + [1-x]_+)$。\n让我们分析惩罚项 $h(x) = [x]_+ + [1-x]_+$：\n-   如果 $x  0$，$h(x) = 0 + (1-x) = 1-x$。\n-   如果 $0 \\le x \\le 1$，$h(x) = x + (1-x) = 1$。\n-   如果 $x  1$，$h(x) = x + 0 = x$。\n所以，我们最小化：\n$$ F_\\mu(x) = \\begin{cases} \\tfrac{1}{2}x^2 + \\mu(1-x)  \\text{如果 } x  0 \\\\ \\tfrac{1}{2}x^2 + \\mu  \\text{如果 } 0 \\le x \\le 1 \\\\ \\tfrac{1}{2}x^2 + \\mu x  \\text{如果 } x  1 \\end{cases} $$\n让我们在开区间上求导：\n-   对于 $x  0$，$F'_\\mu(x) = x - \\mu$。由于 $x  0$ 且 $\\mu  0$，$F'_\\mu(x)  0$。函数是递减的。\n-   对于 $0  x  1$，$F'_\\mu(x) = x$。由于 $x0$，$F'_\\mu(x)  0$。函数是递增的。\n-   对于 $x  1$，$F'_\\mu(x) = x + \\mu$。由于 $x1$ 且 $\\mu  0$，$F'_\\mu(x)  0$。函数是递增的。\n函数 $F_\\mu(x)$ 在 $x0$ 时递减，在 $x>0$ 时递增。全局最小值必须在 $x=0$ 处。\n严谨起见，我们检查 $x=0$ 处的次梯度。\n$\\partial F_\\mu(0) = \\nabla(\\tfrac{1}{2}x^2)|_{x=0} + \\mu \\partial h(x)|_{x=0}$。\n$\\partial h(0) = \\partial [x]_+|_{x=0} + \\partial [1-x]_+|_{x=0} = [0,1] + \\{-1\\} = [-1,0]$。\n所以，$\\partial F_\\mu(0) = \\{0\\} + \\mu[-1,0] = [-\\mu, 0]$。\n为了使 $x=0$ 成为一个最小化子，0 必须在次梯度中：$0 \\in [-\\mu, 0]$。这对所有 $\\mu  0$ 都成立。\n因此，对于任何 $\\mu  0$，$x=0$ 确实是唯一的最小化子。\n\n**E 的结论：正确。**", "answer": "$$\\boxed{ABDE}$$", "id": "3137852"}]}