{"hands_on_practices": [{"introduction": "在我们将泰勒定理应用于复杂的优化问题之前，熟练掌握其基本计算是至关重要的。本练习将通过一个具体函数，引导你实践计算二阶泰勒多项式。这个过程不仅是对你偏导数计算能力的检验，更是构建后续所有基于二次模型的优化算法（如牛顿法）的基石。[@problem_id:24079]", "problem": "一个二次可微函数 $f(x, y)$ 在点 $(a, b)$ 处的二阶泰勒多项式提供了该函数在该点附近的二次近似。其公式为：\n$$\nT_2(x, y) = f(a, b) + \\frac{\\partial f}{\\partial x}(a, b)(x - a) + \\frac{\\partial f}{\\partial y}(a, b)(y - b) + \\frac{1}{2!}\\left(\\frac{\\partial^2 f}{\\partial x^2}(a, b)(x - a)^2 + 2\\frac{\\partial^2 f}{\\partial x \\partial y}(a, b)(x - a)(y - b) + \\frac{\\partial^2 f}{\\partial y^2}(a, b)(y - b)^2\\right)\n$$\n考虑函数 $f(x, y) = \\frac{x}{y+1}$。求此函数在原点 $(a, b) = (0, 0)$ 处展开的二阶泰勒多项式。", "solution": "问题要求函数 $f(x, y) = \\frac{x}{y+1}$ 在点 $(a, b) = (0, 0)$ 处的二阶泰勒多项式。\n\n在点 $(a, b)$ 处的二阶泰勒多项式的一般公式为：\n$$\nT_2(x, y) = f(a, b) + f_x(a, b)(x-a) + f_y(a, b)(y-b) + \\frac{1}{2} \\left[ f_{xx}(a, b)(x-a)^2 + 2f_{xy}(a, b)(x-a)(y-b) + f_{yy}(a, b)(y-b)^2 \\right]\n$$\n其中下标表示偏微分（例如，$f_x = \\frac{\\partial f}{\\partial x}$ 和 $f_{xy} = \\frac{\\partial^2 f}{\\partial y \\partial x}$）。\n\n由于我们以原点 $(a, b) = (0, 0)$ 为中心展开多项式，公式简化为：\n$$\nT_2(x, y) = f(0, 0) + f_x(0, 0)x + f_y(0, 0)y + \\frac{1}{2} \\left[ f_{xx}(0, 0)x^2 + 2f_{xy}(0, 0)xy + f_{yy}(0, 0)y^2 \\right]\n$$\n\n我们必须计算该函数的值及其最高二阶的偏导数，然后在点 $(0, 0)$ 处求值。\n\n**步骤1：在 (0, 0) 处计算函数值。**\n$$\nf(x, y) = \\frac{x}{y+1}\n$$\n$$\nf(0, 0) = \\frac{0}{0+1} = 0\n$$\n\n**步骤2：计算一阶偏导数并在 (0, 0) 处求值。**\n$$\nf_x(x, y) = \\frac{\\partial}{\\partial x}\\left(\\frac{x}{y+1}\\right) = \\frac{1}{y+1}\n$$\n$$\nf_x(0, 0) = \\frac{1}{0+1} = 1\n$$\n$$\nf_y(x, y) = \\frac{\\partial}{\\partial y}\\left(x(y+1)^{-1}\\right) = x(-1)(y+1)^{-2} = -\\frac{x}{(y+1)^2}\n$$\n$$\nf_y(0, 0) = -\\frac{0}{(0+1)^2} = 0\n$$\n\n**步骤3：计算二阶偏导数并在 (0, 0) 处求值。**\n$$\nf_{xx}(x, y) = \\frac{\\partial}{\\partial x}(f_x) = \\frac{\\partial}{\\partial x}\\left(\\frac{1}{y+1}\\right) = 0\n$$\n$$\nf_{xx}(0, 0) = 0\n$$\n$$\nf_{xy}(x, y) = \\frac{\\partial}{\\partial y}(f_x) = \\frac{\\partial}{\\partial y}\\left((y+1)^{-1}\\right) = -1(y+1)^{-2} = -\\frac{1}{(y+1)^2}\n$$\n$$\nf_{xy}(0, 0) = -\\frac{1}{(0+1)^2} = -1\n$$\n$$\nf_{yy}(x, y) = \\frac{\\partial}{\\partial y}(f_y) = \\frac{\\partial}{\\partial y}\\left(-\\frac{x}{(y+1)^2}\\right) = -x \\frac{\\partial}{\\partial y}\\left((y+1)^{-2}\\right) = -x(-2)(y+1)^{-3} = \\frac{2x}{(y+1)^3}\n$$\n$$\nf_{yy}(0, 0) = \\frac{2(0)}{(0+1)^3} = 0\n$$\n\n**步骤4：将这些值代入泰勒多项式公式。**\n$$\nT_2(x, y) = f(0, 0) + f_x(0, 0)x + f_y(0, 0)y + \\frac{1}{2} \\left[ f_{xx}(0, 0)x^2 + 2f_{xy}(0, 0)xy + f_{yy}(0, 0)y^2 \\right]\n$$\n$$\nT_2(x, y) = 0 + (1)x + (0)y + \\frac{1}{2} \\left[ (0)x^2 + 2(-1)xy + (0)y^2 \\right]\n$$\n$$\nT_2(x, y) = x + \\frac{1}{2} (-2xy)\n$$\n$$\nT_2(x, y) = x - xy\n$$\n函数 $f(x, y) = \\frac{x}{y+1}$ 在原点处展开的二阶泰勒多项式为 $x - xy$。", "answer": "$$\\boxed{x - xy}$$", "id": "24079"}, {"introduction": "泰勒定理的威力不仅在于近似，更在于它能帮助我们量化近似的误差。这个练习将展示如何利用泰勒余项来推导模型误差的上界，这是确保信赖域等优化算法稳定收敛的关键一步。通过估算一个安全的步长（即信赖域半径 $\\Delta$），我们将抽象的数学理论与具体的算法设计参数联系起来。[@problem_id:3191337]", "problem": "考虑函数 $f:\\mathbb{R}^{n}\\to\\mathbb{R}$，其定义为 $f(x)=\\|x\\|^{2}+\\alpha \\sin\\!\\big(\\beta\\,u^{\\top}x\\big)$，其中 $\\alpha>0$ 和 $\\beta>0$ 是固定标量，而 $u\\in\\mathbb{R}^{n}$ 是满足 $\\|u\\|=1$ 的固定单位向量。令 $m_{2}(s)$ 表示函数 $f$ 在中心点 $x=0$ 处关于步长 $s\\in\\mathbb{R}^{n}$ 的二阶泰勒模型，这是优化中信赖域 (TR) 方法所使用的二次模型。使用多元函数的泰勒定理，并且仅利用基本定义和已证实的结论，通过计算函数 $f$ 的海森矩阵在该球上的利普希茨常数，推导三阶余项 $R_{3}(s)$ 的一个界，该界对于球 $\\{s\\in\\mathbb{R}^{n}:\\|s\\|\\leq \\Delta\\}$ 内的所有步长 $s$ 一致成立。然后，对于一个给定的容差 $\\tau>0$（用于衡量泰勒余项可接受的最大量级），确定最大的信赖域半径 $\\Delta=\\Delta(\\alpha,\\beta,\\tau)$，使得对于所有满足 $\\|s\\|\\leq \\Delta$ 的步长 $s$，都有 $|R_{3}(s)|\\leq\\tau$。将你的最终答案表示为关于 $\\alpha$、$\\beta$ 和 $\\tau$ 的单个闭式解析表达式。不需要进行数值近似或四舍五入。", "solution": "该问题是有效的。这是一个在多元微积分和数值优化领域中的适定问题，基于标准的定义和定理。所有必要信息都已提供，且目标已明确说明。我们开始求解。\n\n问题要求我们为函数 $f:\\mathbb{R}^{n}\\to\\mathbb{R}$ 找到最大的信赖域半径 $\\Delta$，该函数定义为 $f(x)=\\|x\\|^{2}+\\alpha \\sin(\\beta u^{\\top}x)$，其中 $\\alpha>0$，$\\beta>0$，且 $u\\in\\mathbb{R}^{n}$ 是一个满足 $\\|u\\|=1$ 的单位向量。条件是，对于给定的容差 $\\tau>0$，在中心点 $x=0$ 附近的三阶泰勒余项 $R_{3}(s)$ 必须对信赖域内（即 $\\|s\\|\\leq \\Delta$）的所有步长 $s$ 满足 $|R_{3}(s)| \\leq \\tau$。\n\n根据对于具有连续三阶导数的函数的泰勒定理，$f$ 在点 $x_c$ 附近的展开式为：\n$$f(x_c+s) = f(x_c) + \\nabla f(x_c)^{\\top}s + \\frac{1}{2}s^{\\top}\\nabla^{2}f(x_c)s + R_{3}(s)$$\n其中 $s$ 是步长向量，$\\nabla f$ 是梯度，$\\nabla^{2}f$ 是海森矩阵。$m_2(s) = f(x_c) + \\nabla f(x_c)^{\\top}s + \\frac{1}{2}s^{\\top}\\nabla^{2}f(x_c)s$ 这一项是 $f$ 在 $x_c$ 附近的二阶泰勒模型。余项 $R_{3}(s)$ 是 $O(\\|s\\|^{3})$ 阶的。\n\n优化理论中的一个标准结果为该余项提供了一个界。如果海森矩阵 $\\nabla^2 f(x)$ 在一个包含 $x_c$ 和 $x_c+s$ 的凸集上是利普希茨连续的，常数为 $L_H$，即对于集合中所有的 $y,z$ 都有 $\\|\\nabla^{2}f(y) - \\nabla^{2}f(z)\\| \\leq L_H\\|y-z\\|$，那么余项的界为：\n$$|R_{3}(s)| = |f(x_c+s) - m_2(s)| \\leq \\frac{L_H}{6}\\|s\\|^{3}$$\n利普希茨常数 $L_H$ 可以取为三阶导数张量范数的上确界，即 $L_H = \\sup_x \\|\\nabla^3 f(x)\\|$。\n\n我们的展开以 $x_c=0$ 为中心。首先，我们计算 $f(x) = x^{\\top}x + \\alpha \\sin(\\beta u^{\\top}x)$ 的必要导数。\n\n函数 $f(x)$ 的梯度是：\n$$\\nabla f(x) = \\frac{\\partial}{\\partial x} \\left(x^{\\top}x + \\alpha \\sin(\\beta u^{\\top}x)\\right) = 2x + \\alpha \\cos(\\beta u^{\\top}x) (\\beta u) = 2x + \\alpha\\beta\\cos(\\beta u^{\\top}x)u$$\n\n函数 $f(x)$ 的海森矩阵是二阶偏导数矩阵：\n$$\\nabla^{2}f(x) = \\frac{\\partial}{\\partial x^{\\top}} \\left(2x + \\alpha\\beta\\cos(\\beta u^{\\top}x)u\\right) = 2I + \\alpha\\beta(-\\sin(\\beta u^{\\top}x) (\\beta u^{\\top}))u = 2I - \\alpha\\beta^{2}\\sin(\\beta u^{\\top}x)uu^{\\top}$$\n其中 $I$ 是 $n\\times n$ 单位矩阵，$uu^{\\top}$ 是一个 $n\\times n$ 矩阵。\n\n为了找到海森矩阵的利普希茨常数，我们计算 $f(x)$ 的三阶导数。这是一个三阶张量，其分量为 $\\frac{\\partial^3 f(x)}{\\partial x_i \\partial x_j \\partial x_k}$。对海森矩阵求导：\n$$\\frac{\\partial}{\\partial x_k}\\left(\\nabla^{2}f(x)\\right)_{ij} = \\frac{\\partial}{\\partial x_k}\\left(2\\delta_{ij} - \\alpha\\beta^{2}\\sin(\\beta u^{\\top}x)u_{i}u_{j}\\right) = -\\alpha\\beta^{2}\\cos(\\beta u^{\\top}x)(\\beta u_{k})u_{i}u_{j} = -\\alpha\\beta^{3}\\cos(\\beta u^{\\top}x)u_{i}u_{j}u_{k}$$\n三阶导数张量作用于三个向量 $v_1, v_2, v_3 \\in \\mathbb{R}^n$ 的结果是：\n$$D^{3}f(x)[v_1,v_2,v_3] = \\sum_{i,j,k=1}^{n} \\frac{\\partial^3 f(x)}{\\partial x_i \\partial x_j \\partial x_k} (v_1)_i (v_2)_j (v_3)_k = -\\alpha\\beta^{3}\\cos(\\beta u^{\\top}x)\\sum_{i,j,k=1}^{n} u_{i}u_{j}u_{k}(v_1)_i (v_2)_j (v_3)_k$$\n这可以简化为：\n$$D^{3}f(x)[v_1,v_2,v_3] = -\\alpha\\beta^{3}\\cos(\\beta u^{\\top}x)(u^{\\top}v_1)(u^{\\top}v_2)(u^{\\top}v_3)$$\n\n该张量在点 $x$ 的范数定义为 $\\|\\nabla^3 f(x)\\| = \\sup_{\\|v_1\\|=\\|v_2\\|=\\|v_3\\|=1} |D^{3}f(x)[v_1,v_2,v_3]|$。\n$$\\|\\nabla^3 f(x)\\| = \\sup_{\\|v_1\\|=\\|v_2\\|=\\|v_3\\|=1} |-\\alpha\\beta^{3}\\cos(\\beta u^{\\top}x)(u^{\\top}v_1)(u^{\\top}v_2)(u^{\\top}v_3)|$$\n由于 $\\alpha>0$ 且 $\\beta>0$：\n$$\\|\\nabla^3 f(x)\\| = \\alpha\\beta^{3}|\\cos(\\beta u^{\\top}x)| \\sup_{\\|v_1\\|=\\|v_2\\|=\\|v_3\\|=1} |(u^{\\top}v_1)(u^{\\top}v_2)(u^{\\top}v_3)|$$\n根据柯西-施瓦茨不等式， $|u^{\\top}v| \\leq \\|u\\|\\|v\\|$。由于 $\\|u\\|=1$ 且我们取 $\\|v\\|=1$，我们有 $|u^{\\top}v| \\leq 1$。当 $v_1, v_2, v_3$ 都选择为 $u$ 或 $-u$ 时，可以达到上确界，此时 $|u^{\\top}v|=1$。因此，上确界为 $1$。\n$$\\|\\nabla^3 f(x)\\| = \\alpha\\beta^{3}|\\cos(\\beta u^{\\top}x)|$$\n\n问题要求一个对于球 $\\|s\\|\\leq \\Delta$ 内所有步长 $s$ 一致成立的界。余项的界使用了一个在以 $x=0$ 为中心、半径为 $\\Delta$ 的球（即集合 $\\{x \\in \\mathbb{R}^n : \\|x\\| \\leq \\Delta\\}$）上有效的海森矩阵利普希茨常数 $L_H$。\n$$L_H = \\sup_{\\|x\\|\\leq\\Delta} \\|\\nabla^3 f(x)\\| = \\sup_{\\|x\\|\\leq\\Delta} \\alpha\\beta^{3}|\\cos(\\beta u^{\\top}x)|$$\n$|\\cos(z)|$ 的最大值为 $1$，当 $z$ 是 $\\pi$ 的整数倍时取到。对于任何 $\\Delta > 0$，当 $\\|x\\|\\le\\Delta$ 时，自变量 $\\beta u^{\\top}x$ 的范围是 $[-\\beta \\Delta, \\beta \\Delta]$。这个区间总是包含 $0$，且 $\\cos(0)=1$。因此：\n$$\\sup_{\\|x\\|\\leq\\Delta} |\\cos(\\beta u^{\\top}x)| = 1$$\n因此，海森矩阵的利普希茨常数是 $L_H = \\alpha\\beta^{3}$。\n\n使用这个常数，对于任何步长 $s$，余项 $R_{3}(s)$ 的界为：\n$$|R_{3}(s)| \\leq \\frac{L_H}{6}\\|s\\|^{3} = \\frac{\\alpha\\beta^{3}}{6}\\|s\\|^{3}$$\n\n我们需要找到最大的半径 $\\Delta$，使得对于所有满足 $\\|s\\| \\leq \\Delta$ 的步长 $s$，都有 $|R_{3}(s)| \\leq \\tau$。这要求 $|R_3(s)|$ 的上界在该区域内不超过 $\\tau$。\n$$\\frac{\\alpha\\beta^{3}}{6}\\|s\\|^{3} \\leq \\tau \\quad \\forall s \\text{ such that } \\|s\\|\\leq\\Delta$$\n左边是关于 $\\|s\\|$ 的单调递增函数。因此，如果该条件对于 $\\|s\\|$ 的最大值（即 $\\Delta$）成立，那么它就成立。\n$$\\frac{\\alpha\\beta^{3}}{6}\\Delta^{3} \\leq \\tau$$\n为了找到满足这个不等式的最大 $\\Delta$，我们解相应的等式：\n$$\\frac{\\alpha\\beta^{3}}{6}\\Delta^{3} = \\tau$$\n$$\\Delta^{3} = \\frac{6\\tau}{\\alpha\\beta^{3}}$$\n解出 $\\Delta$，我们得到信赖域可能的最大半径：\n$$\\Delta = \\left(\\frac{6\\tau}{\\alpha\\beta^{3}}\\right)^{\\frac{1}{3}}$$\n这就得到了所要求的、以参数 $\\alpha$、$\\beta$ 和 $\\tau$ 表示的 $\\Delta$ 的闭式解析表达式。", "answer": "$$ \\boxed{\\left(\\frac{6\\tau}{\\alpha\\beta^{3}}\\right)^{\\frac{1}{3}}} $$", "id": "3191337"}, {"introduction": "当标准的二阶（二次）模型在某些点（例如退化的驻点）无法提供有用信息时，我们该怎么办？这个进阶练习将探讨这种情况，展示泰勒展开式中的三阶项如何变得至关重要。我们将利用这些高阶项来判断驻点的性质，并设计一个更精细的“三阶感知”优化步，这揭示了前沿优化方法背后的核心思想。[@problem_id:3191338]", "problem": "考虑由 $f(x,y)=x^{3}+3\\,x\\,y^{2}$ 定义的函数 $f:\\mathbb{R}^{2}\\to\\mathbb{R}$。令 $x^{\\star}=(0,0)$。\n\n任务：\n- 验证 $x^{\\star}$ 是一个驻点，且 $f$ 在 $x^{\\star}$ 处的 Hessian 矩阵是零矩阵，同时 $x^{\\star}$ 处的某些三阶偏导数非零。\n- 使用以 $x^{\\star}$ 为中心的多元函数泰勒定理，对驻点 $x^{\\star}$ 进行分类。\n- 本着信赖域方法的思想，通过在球面 $\\{s\\in\\mathbb{R}^{2}:\\|s\\|_{2}=r\\}$（其中 $r>0$ 是给定的）上最小化以 $x^{\\star}$ 为中心的 $f$ 的三阶泰勒模型，来设计一个“三次感知”的优化步。在所有极小化子中，选择 $y>0$ 的那一个。以单个行向量的形式，给出显式的优化步 $s^{\\star}(r)$。\n\n你的最终答案必须是仅用 $r$ 表示的 $s^{\\star}(r)$ 的显式表达式，写成行矩阵的形式。无需进行四舍五入。", "solution": "问题要求我们分析函数 $f(x,y)=x^{3}+3\\,x\\,y^{2}$ 在点 $x^{\\star}=(0,0)$ 处的情况，对该驻点进行分类，然后通过在半径为 $r$ 的球面上最小化 $f$ 的三阶泰勒模型来找到一个最优步 $s^{\\star}(r)$。\n\n首先，我们验证 $x^{\\star}=(0,0)$ 是一个驻点，并且其 Hessian 矩阵是零矩阵。我们计算 $f$ 的梯度，记为 $\\nabla f$。偏导数为：\n$$\n\\frac{\\partial f}{\\partial x} = 3x^{2}+3y^{2}\n$$\n$$\n\\frac{\\partial f}{\\partial y} = 6xy\n$$\n梯度为 $\\nabla f(x,y) = \\begin{pmatrix} 3x^{2}+3y^{2} \\\\ 6xy \\end{pmatrix}$。\n在 $x^{\\star}=(0,0)$ 处求值，我们得到：\n$$\n\\nabla f(0,0) = \\begin{pmatrix} 3(0)^{2}+3(0)^{2} \\\\ 6(0)(0) \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}\n$$\n由于在 $x^{\\star}=(0,0)$ 处的梯度是零向量，所以 $x^{\\star}$ 是 $f$ 的一个驻点。\n\n接下来，我们计算 $f$ 的 Hessian 矩阵，记为 $\\nabla^{2}f$。二阶偏导数为：\n$$\n\\frac{\\partial^{2} f}{\\partial x^{2}} = \\frac{\\partial}{\\partial x}(3x^{2}+3y^{2}) = 6x\n$$\n$$\n\\frac{\\partial^{2} f}{\\partial y^{2}} = \\frac{\\partial}{\\partial y}(6xy) = 6x\n$$\n$$\n\\frac{\\partial^{2} f}{\\partial x \\partial y} = \\frac{\\partial}{\\partial y}(3x^{2}+3y^{2}) = 6y\n$$\nHessian 矩阵为 $\\nabla^{2}f(x,y) = \\begin{pmatrix} 6x & 6y \\\\ 6y & 6x \\end{pmatrix}$。\n在 $x^{\\star}=(0,0)$ 处求值：\n$$\n\\nabla^{2}f(0,0) = \\begin{pmatrix} 6(0) & 6(0) \\\\ 6(0) & 6(0) \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix}\n$$\n这证实了 $f$ 在 $x^{\\star}$ 处的 Hessian 矩阵是零矩阵。对于该驻点的分类，二阶导数检验无法得出结论。\n\n我们现在计算在 $x^{\\star}=(0,0)$ 处的三阶偏导数：\n$$\n\\frac{\\partial^{3} f}{\\partial x^{3}} = 6 \\implies \\frac{\\partial^{3} f}{\\partial x^{3}}(0,0) = 6\n$$\n$$\n\\frac{\\partial^{3} f}{\\partial y^{3}} = 0 \\implies \\frac{\\partial^{3} f}{\\partial y^{3}}(0,0) = 0\n$$\n$$\n\\frac{\\partial^{3} f}{\\partial x^{2} \\partial y} = 0 \\implies \\frac{\\partial^{3} f}{\\partial x^{2} \\partial y}(0,0) = 0\n$$\n$$\n\\frac{\\partial^{3} f}{\\partial x \\partial y^{2}} = 6 \\implies \\frac{\\partial^{3} f}{\\partial x \\partial y^{2}}(0,0) = 6\n$$\n我们可以看到，在 $x^{\\star}$ 处的某些三阶偏导数确实非零。\n\n为了对该驻点进行分类，我们使用 $f$ 在 $x^{\\star}=(0,0)$ 周围的泰勒展开。对于一个向量 $s=(s_x, s_y)$，其展开式为：\n$f(s_x, s_y) = f(0,0) + \\nabla f(0,0)^{T}s + \\frac{1}{2}s^{T}\\nabla^{2}f(0,0)s + \\dots$\n由于 $f(0,0)=0$，$\\nabla f(0,0)=0$，且 $\\nabla^{2}f(0,0)=0$，最低阶的非零项是三阶项。函数 $f(x,y)=x^3+3xy^2$ 是一个3次齐次多项式。它关于原点的泰勒展开就是函数本身。\n因此，在原点附近，$f$ 的行为由 $f(x,y) = x^3 + 3xy^2 = x(x^2 + 3y^2)$ 给出。\n在 $(0,0)$ 的任意小邻域内：\n- 如果我们选择一个点满足 $x > 0$，那么 $x^2+3y^2 > 0$（除非 $(x,y)=(0,0)$），所以 $f(x,y) > 0$。\n- 如果我们选择一个点满足 $x < 0$，那么 $f(x,y) < 0$。\n由于 $f(0,0)=0$ 且函数在 $(0,0)$ 的任意邻域内都取正值和负值，因此点 $x^{\\star}=(0,0)$ 是一个鞍点（具体来说，是一个退化鞍点或高阶鞍点）。\n\n最后，我们通过在球面 $\\{s\\in\\mathbb{R}^{2}:\\|s\\|_{2}=r\\}$ 上最小化以 $x^{\\star}$ 为中心的 $f$ 的三阶泰勒模型，来设计“三次感知”优化步。令 $s = (s_x, s_y)$。三阶泰勒模型 $m(s)$ 为：\n$$\nm(s) = f(0,0) + \\nabla f(0,0)^{T}s + \\frac{1}{2}s^{T}\\nabla^{2}f(0,0)s + \\frac{1}{3!}\\sum_{i,j,k=1}^{2} \\frac{\\partial^3 f(0,0)}{\\partial x_i \\partial x_j \\partial x_k}s_i s_j s_k\n$$\n如前所述，前三项为零，且三阶展开式与函数本身相符。所以我们要最小化 $m(s_x, s_y) = s_x^3 + 3s_x s_y^2$，约束条件为 $s_x^2 + s_y^2 = r^2$，其中 $r>0$。\n\n我们可以使用极坐标来参数化约束条件：$s_x = r\\cos\\theta$ 和 $s_y = r\\sin\\theta$，其中 $\\theta \\in [0, 2\\pi)$。将此代入目标函数，得到一个关于 $\\theta$ 的函数：\n$$\nh(\\theta) = (r\\cos\\theta)^{3} + 3(r\\cos\\theta)(r\\sin\\theta)^{2}\n$$\n$$\nh(\\theta) = r^{3}\\cos^{3}\\theta + 3r^{3}\\cos\\theta\\sin^{2}\\theta = r^{3}\\cos\\theta(\\cos^{2}\\theta + 3\\sin^{2}\\theta)\n$$\n使用恒等式 $\\cos^{2}\\theta = 1 - \\sin^{2}\\theta$：\n$$\nh(\\theta) = r^{3}\\cos\\theta(1 - \\sin^{2}\\theta + 3\\sin^{2}\\theta) = r^{3}\\cos\\theta(1 + 2\\sin^{2}\\theta)\n$$\n为了找到最小值，我们计算关于 $\\theta$ 的导数并将其设为零：\n$$\n\\frac{dh}{d\\theta} = r^{3}[(-\\sin\\theta)(1+2\\sin^{2}\\theta) + (\\cos\\theta)(4\\sin\\theta\\cos\\theta)]\n$$\n$$\n\\frac{dh}{d\\theta} = r^{3}[-\\sin\\theta - 2\\sin^{3}\\theta + 4\\sin\\theta\\cos^{2}\\theta] = r^{3}\\sin\\theta[-1 - 2\\sin^{2}\\theta + 4\\cos^{2}\\theta]\n$$\n令 $\\frac{dh}{d\\theta}=0$（并且由于 $r>0$），我们有两种情况：\n情况1：$\\sin\\theta = 0$。这意味着 $\\theta=0$ 或 $\\theta=\\pi$。\n- 如果 $\\theta=0$，$h(0)=r^{3}\\cos(0)(1+0) = r^{3}$。\n- 如果 $\\theta=\\pi$，$h(\\pi)=r^{3}\\cos(\\pi)(1+0) = -r^{3}$。\n\n情况2：$-1 - 2\\sin^{2}\\theta + 4\\cos^{2}\\theta = 0$。使用 $\\cos^{2}\\theta = 1-\\sin^{2}\\theta$：\n$$\n-1 - 2\\sin^{2}\\theta + 4(1-\\sin^{2}\\theta) = 0 \\implies 3 - 6\\sin^{2}\\theta = 0 \\implies \\sin^{2}\\theta = \\frac{1}{2}\n$$\n这也意味着 $\\cos^{2}\\theta = 1 - \\frac{1}{2} = \\frac{1}{2}$。目标函数的值为 $h(\\theta) = r^{3}\\cos\\theta(1 + 2(\\frac{1}{2})) = 2r^{3}\\cos\\theta$。\n- 如果 $\\cos\\theta = \\sqrt{\\frac{1}{2}} = \\frac{1}{\\sqrt{2}}$，那么 $h(\\theta) = 2r^{3}(\\frac{1}{\\sqrt{2}}) = \\sqrt{2}r^{3}$。\n- 如果 $\\cos\\theta = -\\sqrt{\\frac{1}{2}} = -\\frac{1}{\\sqrt{2}}$，那么 $h(\\theta) = 2r^{3}(-\\frac{1}{\\sqrt{2}}) = -\\sqrt{2}r^{3}$。\n\n比较所有值 $\\{r^3, -r^3, \\sqrt{2}r^3, -\\sqrt{2}r^3\\}$，最小值是 $-\\sqrt{2}r^{3}$。这发生在 $\\cos\\theta = -1/\\sqrt{2}$ 且 $\\sin^2\\theta = 1/2$ 时。可能的角度是 $\\theta = \\frac{3\\pi}{4}$ 和 $\\theta = \\frac{5\\pi}{4}$。\n相应的极小化子 $s=(s_x,s_y)$ 是：\n1. 对于 $\\theta = \\frac{3\\pi}{4}$：$s_x = r\\cos(\\frac{3\\pi}{4}) = -\\frac{r}{\\sqrt{2}}$，$s_y = r\\sin(\\frac{3\\pi}{4}) = \\frac{r}{\\sqrt{2}}$。极小化子是 $(-\\frac{r}{\\sqrt{2}}, \\frac{r}{\\sqrt{2}})$。\n2. 对于 $\\theta = \\frac{5\\pi}{4}$：$s_x = r\\cos(\\frac{5\\pi}{4}) = -\\frac{r}{\\sqrt{2}}$，$s_y = r\\sin(\\frac{5\\pi}{4}) = -\\frac{r}{\\sqrt{2}}$。极小化子是 $(-\\frac{r}{\\sqrt{2}}, -\\frac{r}{\\sqrt{2}})$。\n\n问题要求选择 $y > 0$ 的极小化子，这对应于 $s_y > 0$。这是第一种情况。\n因此，显式的优化步是 $s^{\\star}(r) = (-\\frac{r}{\\sqrt{2}}, \\frac{r}{\\sqrt{2}})$。分母有理化后得到 $s^{\\star}(r) = (-\\frac{\\sqrt{2}}{2}r, \\frac{\\sqrt{2}}{2}r)$。\n我们将其表示为行矩阵。\n$$\ns^{\\star}(r) = \\begin{pmatrix} -\\frac{\\sqrt{2}}{2}r & \\frac{\\sqrt{2}}{2}r \\end{pmatrix}\n$$", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n-\\frac{\\sqrt{2}}{2}r & \\frac{\\sqrt{2}}{2}r\n\\end{pmatrix}\n}\n$$", "id": "3191338"}]}