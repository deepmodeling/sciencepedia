{"hands_on_practices": [{"introduction": "粒子群优化（PSO）是一种受鸟群觅食等社会行为启发的优化算法。其核心机制在于速度更新法则，该法则引导每个“粒子”根据自身的惯性、个体历史最佳位置以及整个群体的全局最佳位置来调整其移动方向和速度。本练习 [@problem_id:2166499] 提供了一个具体的计算情景，旨在帮助你牢固掌握这一基本概念。", "problem": "一架自主无人机是一个蜂群的一部分，该蜂群在一个广阔的开放场地上搜索无线电信号强度最大的位置，该场地被建模为二维笛卡尔平面。搜索过程由粒子群优化（PSO）算法引导。在每个时间步，每架无人机都会根据其当前速度、自身找到的最佳位置以及整个蜂群中任何无人机找到的最佳位置来更新其速度。\n\n单个粒子（无人机）在时间步 $t+1$ 的速度更新由以下方程给出：\n$$ \\vec{v}(t+1) = \\omega \\vec{v}(t) + c_1 r_1 (\\vec{p} - \\vec{x}(t)) + c_2 r_2 (\\vec{g} - \\vec{x}(t)) $$\n其中：\n- $\\vec{v}(t)$ 是无人机当前的速度矢量。\n- $\\vec{x}(t)$ 是无人机当前的位置矢量。\n- $\\vec{p}$ 是无人机迄今为止找到的自身最佳位置。\n- $\\vec{g}$ 是整个蜂群迄今为止找到的全局最佳位置。\n- $\\omega$ 是惯性权重，控制先前速度的影响。\n- $c_1$ 和 $c_2$ 分别是认知系数和社会系数，用于权衡自身最佳位置和全局最佳位置的影响。\n- $r_1$ 和 $r_2$ 是在 $[0, 1]$ 上均匀分布的随机数。\n\n考虑在特定时间步 $t$ 的一架特定无人机。该无人机的状态和蜂群参数如下：\n- 当前位置：$\\vec{x}(t) = \\begin{pmatrix} 8.0 & 14.0 \\end{pmatrix}$\n- 当前速度：$\\vec{v}(t) = \\begin{pmatrix} -1.0 & 2.0 \\end{pmatrix}$\n- 自身最佳位置：$\\vec{p} = \\begin{pmatrix} 10.0 & 12.0 \\end{pmatrix}$\n- 全局最佳位置：$\\vec{g} = \\begin{pmatrix} 11.0 & 10.0 \\end{pmatrix}$\n- 惯性权重：$\\omega = 0.7$\n- 认知系数：$c_1 = 1.5$\n- 社会系数：$c_2 = 1.5$\n对于此特定更新步骤，生成的随机数为 $r_1 = 0.4$ 和 $r_2 = 0.9$。\n\n计算无人机的新速度矢量 $\\vec{v}(t+1)$。所有位置以米为单位，速度以米/秒（m/s）为单位。请将您的答案表示为 m/s 为单位的二元行矩阵 $[v_x, v_y]$。将矢量的每个分量四舍五入到三位有效数字。", "solution": "我们应用 PSO 速度更新规则\n$$\\vec{v}(t+1)=\\omega \\vec{v}(t)+c_{1}r_{1}\\left(\\vec{p}-\\vec{x}(t)\\right)+c_{2}r_{2}\\left(\\vec{g}-\\vec{x}(t)\\right).$$\n计算位移矢量：\n$$\\vec{p}-\\vec{x}(t)=\\begin{pmatrix}10.0-8.0 \\\\ 12.0-14.0\\end{pmatrix}=\\begin{pmatrix}2 \\\\ -2\\end{pmatrix},\\quad \\vec{g}-\\vec{x}(t)=\\begin{pmatrix}11.0-8.0 \\\\ 10.0-14.0\\end{pmatrix}=\\begin{pmatrix}3 \\\\ -4\\end{pmatrix}.$$\n计算每一项：\n$$\\omega \\vec{v}(t)=0.7\\begin{pmatrix}-1.0 \\\\ 2.0\\end{pmatrix}=\\begin{pmatrix}-0.7 \\\\ 1.4\\end{pmatrix},$$\n$$c_{1}r_{1}\\left(\\vec{p}-\\vec{x}(t)\\right)=1.5\\cdot 0.4\\begin{pmatrix}2 \\\\ -2\\end{pmatrix}=0.6\\begin{pmatrix}2 \\\\ -2\\end{pmatrix}=\\begin{pmatrix}1.2 \\\\ -1.2\\end{pmatrix},$$\n$$c_{2}r_{2}\\left(\\vec{g}-\\vec{x}(t)\\right)=1.5\\cdot 0.9\\begin{pmatrix}3 \\\\ -4\\end{pmatrix}=1.35\\begin{pmatrix}3 \\\\ -4\\end{pmatrix}=\\begin{pmatrix}4.05 \\\\ -5.4\\end{pmatrix}.$$\n将各项贡献相加得到\n$$\\vec{v}(t+1)=\\begin{pmatrix}-0.7 \\\\ 1.4\\end{pmatrix}+\\begin{pmatrix}1.2 \\\\ -1.2\\end{pmatrix}+\\begin{pmatrix}4.05 \\\\ -5.4\\end{pmatrix}=\\begin{pmatrix}4.55 \\\\ -5.2\\end{pmatrix}.$$\n将每个分量四舍五入到三位有效数字，得到\n$$\\vec{v}(t+1)=\\begin{pmatrix}4.55 \\\\ -5.20\\end{pmatrix}.$$\n表示为行矩阵，即 $\\begin{pmatrix}4.55 & -5.20\\end{pmatrix}$，单位为米/秒。", "answer": "$$\\boxed{\\begin{pmatrix}4.55 & -5.20\\end{pmatrix}}$$", "id": "2166499"}, {"introduction": "Nelder-Mead 算法是一种经典的直接搜索方法，它在 $n$ 维空间中使用一个包含 $n+1$ 个顶点的单纯形（在二维空间中是一个三角形）来探索和逼近最优点。虽然该算法在许多问题上表现出色，但理解其潜在的失效模式对于稳健地应用它至关重要。本练习 [@problem_id:2166485] 提出了一个“退化”单纯形的假设情景，旨在引导你批判性地思考算法的几何行为及其在特殊情况下的稳健性。", "problem": "Nelder-Mead 算法是一种广泛使用的无导数优化方法，用于在 $n$ 维空间中寻找函数 $f(\\mathbf{x})$ 的最小值。在二维空间中 ($n=2$)，该算法维护一个单纯形，它是由三个顶点 $\\mathbf{x}_1, \\mathbf{x}_2, \\mathbf{x}_3$ 定义的三角形。在每次迭代中，算法尝试通过用一个新的、更好的点替换函数值最高（最差）的顶点 $\\mathbf{x}_h$来改进单纯形。\n\n这个过程的第一步是反射。算法计算除最差顶点 $\\mathbf{x}_h$ 之外的所有顶点的质心 $\\mathbf{x}_c$。然后它使用公式 $\\mathbf{x}_r = \\mathbf{x}_c + \\alpha(\\mathbf{x}_c - \\mathbf{x}_h)$ 计算一个反射点 $\\mathbf{x}_r$，其中 $\\alpha$ 是一个正的反射系数，通常设为 $\\alpha=1$。\n\n考虑一个场景，一个二维 Nelder-Mead 优化程序使用以下三个顶点及其对应的函数值进行初始化：\n- 顶点 $\\mathbf{x}_1 = (2, 3)$，函数值为 $f(\\mathbf{x}_1) = 8$。\n- 顶点 $\\mathbf{x}_2 = (6, 9)$，函数值为 $f(\\mathbf{x}_2) = 20$。\n- 顶点 $\\mathbf{x}_3 = (-2, -3)$，函数值为 $f(\\mathbf{x}_3) = 4$。\n\n该算法使用标准反射系数 $\\alpha = 1$。Nelder-Mead 方法的一个关键失败模式是“单纯形退化”，它发生在单纯形的顶点变为共线时（即，它们都位于一条直线上）。在所描述的初始状态下，单纯形退化在第一个反射步骤中产生最直接和最即时的后果是什么？\n\nA. 非最差点（即除最差点外的点）的质心 $\\mathbf{x}_c$ 将与最佳顶点相同。\n\nB. 反射点 $\\mathbf{x}_r$ 无法计算，因为它涉及到除以零。\n\nC. 反射点 $\\mathbf{x}_r$ 将与最差顶点 $\\mathbf{x}_h$ 相同，导致算法进入无限循环而单纯形不发生改变。\n\nD. 通过用反射点替换最差顶点形成的新单纯形，其顶点也将与原始退化单纯形位于同一条直线上。\n\nE. 反射点 $\\mathbf{x}_r$ 将位于原点 $(0, 0)$。", "solution": "二维中的 Nelder-Mead 反射步骤用反射点替换最差顶点 $\\mathbf{x}_{h}$\n$$\n\\mathbf{x}_{r}=\\mathbf{x}_{c}+\\alpha\\left(\\mathbf{x}_{c}-\\mathbf{x}_{h}\\right),\n$$\n其中 $\\mathbf{x}_{c}$ 是两个非最差顶点的质心，并且 $\\alpha>0$ (此处 $\\alpha=1$)。质心是两个保留顶点的算术平均值：\n$$\n\\mathbf{x}_{c}=\\frac{\\mathbf{x}_{i}+\\mathbf{x}_{j}}{2},\n$$\n其中 $\\{\\mathbf{x}_{i},\\mathbf{x}_{j}\\}=\\{\\mathbf{x}_{1},\\mathbf{x}_{2},\\mathbf{x}_{3}\\}\\setminus\\{\\mathbf{x}_{h}\\}$。\n\n在二维中，如果一个单纯形的三个顶点共线，则它是退化的。如果 $\\mathbf{x}_{1},\\mathbf{x}_{2},\\mathbf{x}_{3}$ 共线，则存在一个非零向量 $\\mathbf{v}$ 和标量 $p_{1},p_{2},p_{3}$，使得对于 $k\\in\\{1,2,3\\}$，有 $\\mathbf{x}_{k}=p_{k}\\mathbf{v}$。不失一般性地，设最差顶点为 $\\mathbf{x}_{h}=p_{h}\\mathbf{v}$，两个非最差顶点为 $\\mathbf{x}_{i}=p_{i}\\mathbf{v}$ 和 $\\mathbf{x}_{j}=p_{j}\\mathbf{v}$。那么质心为\n$$\n\\mathbf{x}_{c}=\\frac{\\mathbf{x}_{i}+\\mathbf{x}_{j}}{2}=\\frac{p_{i}+p_{j}}{2}\\,\\mathbf{v},\n$$\n它位于由 $\\mathbf{v}$ 张成的同一条直线上。当 $\\alpha=1$ 时的反射点为\n$$\n\\mathbf{x}_{r}=\\mathbf{x}_{c}+(\\mathbf{x}_{c}-\\mathbf{x}_{h})=2\\mathbf{x}_{c}-\\mathbf{x}_{h}=\\left(p_{i}+p_{j}-p_{h}\\right)\\mathbf{v},\n$$\n它也位于由 $\\mathbf{v}$ 张成的同一条直线上。因此，用 $\\mathbf{x}_{r}$ 替换 $\\mathbf{x}_{h}$ 会产生一个新的单纯形，其三个顶点仍然共线，所以在反射步骤之后，退化现象持续存在。\n\n将此应用于给定的数据，证实了一般性结论。函数值为 $f(\\mathbf{x}_{2})=20$ (最差)、$f(\\mathbf{x}_{1})=8$ 和 $f(\\mathbf{x}_{3})=4$ (最佳)，所以 $\\mathbf{x}_{h}=\\mathbf{x}_{2}=(6,9)$，非最差顶点是 $\\mathbf{x}_{1}=(2,3)$ 和 $\\mathbf{x}_{3}=(-2,-3)$。这三个顶点是共线的，因为每个都是 $\\mathbf{v}=(2,3)$ 的标量倍数，即 $\\mathbf{x}_{1}=1\\cdot\\mathbf{v}$、$\\mathbf{x}_{2}=3\\cdot\\mathbf{v}$ 和 $\\mathbf{x}_{3}=-1\\cdot\\mathbf{v}$。质心是\n$$\n\\mathbf{x}_{c}=\\frac{\\mathbf{x}_{1}+\\mathbf{x}_{3}}{2}=\\frac{(2,3)+(-2,-3)}{2}=(0,0),\n$$\n反射点是\n$$\n\\mathbf{x}_{r}=2\\mathbf{x}_{c}-\\mathbf{x}_{h}=(0,0)-(6,9)=(-6,-9)=-3\\cdot\\mathbf{v},\n$$\n它位于同一条直线上。因此，新的单纯形 $\\{\\mathbf{x}_{1},\\mathbf{x}_{3},\\mathbf{x}_{r}\\}$ 仍然是共线的。\n\n因此，反射步骤中退化的最直接和最即时的后果是新的单纯形仍然是退化的，即所有顶点都位于同一条直线上。这对应于选项 D，而：\n- A 通常是错误的，在这里也是错误的，因为 $\\mathbf{x}_{c}=(0,0)\\neq\\mathbf{x}_{3}=(-2,-3)$。\n- B 是错误的，因为反射不使用除法。\n- C 通常不是由退化所必然导致的；它需要 $\\mathbf{x}_{c}=\\mathbf{x}_{h}$，而这在这里不成立。\n- E 是错误的；这里是 $\\mathbf{x}_{c}$ 在原点，而不是 $\\mathbf{x}_{r}$。", "answer": "$$\\boxed{D}$$", "id": "2166485"}, {"introduction": "信赖域方法是一类强大的优化技术，它通过迭代地调整一个“信赖半径”来约束搜索步长，从而在稳定性和收敛速度之间取得平衡。最后一个高级实践 [@problem_id:3117671] 将你从简单的计算推向一个完整的编程实现任务。通过亲手编写一个简单的无导数优化器，你将对步长提议、成功/失败逻辑和自适应参数控制等核心概念形成更深刻、更综合的理解。", "problem": "您需要实现并分析一个简单的二维无导数信赖域优化方法。目标是研究对于不同的目标函数和参数选择，信赖域半径更新规则如何影响收敛速度和稳定性。此任务的基本基础包括信赖域的定义和迭代优化的通用机制：从一个初始点开始，在一个邻域内提出步长，接受能够减小目标函数值的步长，并根据成功或失败更新邻域的大小。\n\n定义与设置：\n- 考虑一个函数 $f:\\mathbb{R}^2\\to\\mathbb{R}$，该函数可以在任何点求值，但其梯度不可用。这属于无导数优化（Derivative-Free Optimization, DFO）的范畴。\n- 在第 $k$ 次迭代中，信赖域由一个半径 $\\Delta_k > 0$ 来表征，它约束步长 $s_k$ 满足 $\\|s_k\\|_2 \\le \\Delta_k$。\n- 如果一个步长产生了严格的减小 $f(x_k + s_k) < f(x_k)$，则该步长被视为成功，否则为失败。\n- 信赖域半径的更新规则是：\n  $$\\Delta_{k+1} = \\gamma \\Delta_k \\text{ 成功时，以及 } \\Delta_{k+1} = \\beta \\Delta_k \\text{ 失败时}，$$\n  其中 $\\gamma > 1$ 且 $0 < \\beta < 1$。\n- 一种不使用导数的简单搜索机制（罗盘搜索）会探索一个有限的方向集 $d \\in \\mathcal{D}$，并对 $s = \\Delta_k \\, d / \\|d\\|_2$ 计算 $f(x_k + s)$ 的值，以遵循信赖域约束。使用方向集\n  $$\\mathcal{D} = \\{(1,0), (-1,0), (0,1), (0,-1), (1,1), (-1,1), (1,-1), (-1,-1)\\}.$$\n- 接受规则：如果在这些方向内的任何试验点能产生严格减小，则接受下降幅度最大的那个试验点；否则声明失败并保持 $x_{k+1} = x_k$。\n\n在您的程序中实现以下内容：\n1. 一个例程，给定目标函数 $f$、初始点 $x_0 \\in \\mathbb{R}^2$、初始半径 $\\Delta_0 > 0$、参数 $\\gamma > 1$ 和 $\\beta \\in (0,1)$、最大半径 $\\Delta_{\\max} > 0$、容差 $\\varepsilon > 0$ 以及最大迭代次数 $N_{\\max}$，该例程在信赖域内执行迭代式罗盘搜索。在每次迭代 $k$ 中，在当前点以及沿着 $\\mathcal{D}$ 中的所有方向，以步长 $\\Delta_k$ 计算 $f$ 的值。接受最好的严格减小，并将半径扩大因子 $\\gamma$（上限为 $\\Delta_{\\max}$），否则将半径缩小因子 $\\beta$。\n2. 当信赖域半径满足 $\\Delta_k < \\varepsilon$（声明收敛）或当 $k$ 达到 $N_{\\max}$（声明未收敛）时终止。\n3. 跟踪并报告：\n   - 执行的总迭代次数 $k_{\\text{end}}$。\n   - 函数求值的总次数（包括当前点和所有试验点）。\n   - 最终目标函数值 $f(x_{k_{\\text{end}}})$。\n   - 一个布尔标志，指示是否收敛（如果在终止时 $\\Delta_k < \\varepsilon$，则为真）。\n   - 失败率，定义为失败迭代次数除以 $k_{\\text{end}}$，以小数表示。\n\n使用的目标函数：\n- 凸碗（球面）： $$f_1(x) = x_1^2 + x_2^2.$$\n- 窄谷（Rosenbrock 函数）： $$f_2(x) = 100\\left(x_2 - x_1^2\\right)^2 + \\left(1 - x_1\\right)^2.$$\n- 不可微绝对值和： $$f_3(x) = |x_1| + |x_2|.$$\n\n测试套件：\n对以下参数集运行优化器（每个都是一个独立的测试用例）。在每种情况下，$x_0$ 都是二维的，所有标量都是实数。\n- 用例 A（理想情况，凸碗）：$f=f_1$, $x_0 = [2.0, -1.5]$, $\\Delta_0 = 1.0$, $\\Delta_{\\max} = 10.0$, $\\gamma = 2.0$, $\\beta = 0.5$, $\\varepsilon = 10^{-6}$, $N_{\\max} = 500$。\n- 用例 B（窄谷，温和参数）：$f=f_2$, $x_0 = [-1.2, 1.0]$, $\\Delta_0 = 0.5$, $\\Delta_{\\max} = 10.0$, $\\gamma = 1.5$, $\\beta = 0.7$, $\\varepsilon = 10^{-6}$, $N_{\\max} = 1000$。\n- 用例 C（不可微，激进扩张，强力收缩）：$f=f_3$, $x_0 = [3.0, -4.0]$, $\\Delta_0 = 1.0$, $\\Delta_{\\max} = 20.0$, $\\gamma = 3.0$, $\\beta = 0.2$, $\\varepsilon = 10^{-6}$, $N_{\\max} = 500$。\n- 用例 D（近边界参数，半径变化缓慢）：$f=f_1$, $x_0 = [2.0, -1.5]$, $\\Delta_0 = 1.0$, $\\Delta_{\\max} = 10.0$, $\\gamma = 1.05$, $\\beta = 0.95$, $\\varepsilon = 10^{-6}$, $N_{\\max} = 500$。\n- 用例 E（窄谷，非常激进的参数）：$f=f_2$, $x_0 = [-1.2, 1.0]$, $\\Delta_0 = 0.25$, $\\Delta_{\\max} = 10.0$, $\\gamma = 4.0$, $\\beta = 0.1$, $\\varepsilon = 10^{-6}$, $N_{\\max} = 1000$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表。每个测试用例的结果必须是 $[k_{\\text{end}}, \\text{evals}, f_{\\text{final}}, \\text{converged}, \\text{failure\\_fraction}]$ 形式的列表，其中 $k_{\\text{end}}$ 和 $\\text{evals}$ 是整数，$f_{\\text{final}}$ 和 $\\text{failure\\_fraction}$ 是浮点数，而 $\\text{converged}$ 是布尔值。例如，输出应如下所示\n`[[3, 25, 0.0, True, 0.3333333333], [...]]`", "solution": "用户要求基于罗盘搜索策略实现并分析一个无导数信赖域优化算法。该问题定义明确，科学上合理，并为完整实现提供了所有必要的参数和规范。任务的核心是构建一个迭代优化器，并在一套包含标准基准函数的测试用例上评估其性能。\n\n### 算法设计与原理\n\n该优化方法是一个迭代过程，旨在寻找函数 $f: \\mathbb{R}^2 \\to \\mathbb{R}$ 的局部最小值，而无需访问其导数。从初始点 $x_0$ 开始，算法生成一系列点 $\\{x_k\\}_{k=0,1,2,\\dots}$，理想情况下会收敛到一个极小值点。每次迭代都涉及探索当前点 $x_k$ 的局部邻域以寻找更佳的点。这个邻域由一个信赖域定义，即以 $x_k$ 为中心、半径为 $\\Delta_k$ 的球体。\n\n**1. 状态变量**\n算法在第 $k$ 次迭代的状态由两个主要变量定义：\n- 当前迭代点，$x_k \\in \\mathbb{R}^2$。\n- 信赖域半径，$\\Delta_k > 0$。\n\n**2. 步长生成：罗盘搜索**\n在每次迭代 $k$ 中，我们在 $x_k$ 周围探测一组试验点。这些探测的方向由一个固定的8个向量集合给出：\n$$\n\\mathcal{D} = \\{(1,0), (-1,0), (0,1), (0,-1), (1,1), (-1,1), (1,-1), (-1,-1)\\}\n$$\n为确保试验步长遵循信赖域约束 $\\|s_k\\|_2 \\le \\Delta_k$，实际步长 $s$ 是通过缩放方向向量 $d \\in \\mathcal{D}$ 使其长度恰好为 $\\Delta_k$ 来构造的。因此，试验步长定义为：\n$$\ns = \\Delta_k \\frac{d}{\\|d\\|_2}\n$$\n这会在信赖域的边界上创建8个试验点 $x_k + s$。\n\n**3. 步长接受与状态更新**\n每次迭代的核心逻辑是在所有8个试验点上评估目标函数 $f$，并将它们与当前点的值 $f(x_k)$ 进行比较。\n\n- **成功：** 如果至少有一个试验点 $x_k + s$ 产生严格的改进，即 $f(x_k + s) < f(x_k)$，则迭代是成功的。如果有多个试验点带来改进，则选择导致函数值最小的那个。设这个最佳步长为 $s^*$。然后按如下方式更新状态：\n  - 接受下一个迭代点：$x_{k+1} = x_k + s^*$。\n  - 扩大信赖域半径，以便在下一次迭代中探索更大的区域，这反映了对当前搜索方向的信心。新半径为 $\\Delta_{k+1} = \\gamma \\Delta_k$，其中 $\\gamma > 1$ 是扩张因子。此扩张受最大允许半径 $\\Delta_{\\max}$ 的限制，因此更新规则为 $\\Delta_{k+1} = \\min(\\gamma \\Delta_k, \\Delta_{\\max})$。\n\n- **失败：** 如果8个试验点中没有一个能使函数值严格低于 $f(x_k)$，则迭代失败。这表明当前的信赖域半径 $\\Delta_k$ 太大，无法找到局部改进。状态按如下方式更新：\n  - 位置不改变：$x_{k+1} = x_k$。\n  - 收缩信赖域半径，将搜索集中在更小、更有希望的邻域。新半径为 $\\Delta_{k+1} = \\beta \\Delta_k$，其中 $0 < \\beta < 1$ 是收缩因子。\n\n**4. 终止准则**\n迭代过程持续进行，直到满足以下两个条件之一：\n- **收敛：** 如果信赖域半径变得非常小，即 $\\Delta_k < \\varepsilon$（其中 $\\varepsilon$ 是一个小的正容差），算法成功终止。这表明搜索已经细化到非常小的尺度，并且 $x_k$ 被认为是局部最小值的近似。\n- **达到最大迭代次数：** 如果迭代次数 $k$ 达到预定的最大值 $N_{\\max}$，算法在未收敛的情况下终止。这是防止运行时间过长或不收敛的保障措施。\n\n**5. 性能指标计算**\n为了分析算法的行为，跟踪了几个指标：\n- **总迭代次数 ($k_{\\text{end}}$)：** 终止前执行的总迭代次数。\n- **函数求值总次数：** 开始时，计算一次 $f(x_0)$。在 $k_{\\text{end}}$ 次迭代的每一次中，函数在所有8个试验点上进行评估。因此，求值总次数为 $1 + 8 \\times k_{\\text{end}}$。\n- **最终目标函数值 ($f_{\\text{final}}$)：** 最终点处的目标函数值，$f(x_{k_{\\text{end}}})$。\n- **收敛标志：** 一个布尔值，指示终止是由于收敛（$\\Delta_k < \\varepsilon$）还是达到 $N_{\\max}$。\n- **失败率：** 失败迭代次数与总迭代次数 $k_{\\text{end}}$ 的比率。此指标提供了对搜索过程效率的洞察。\n\n### 实现\n实现将此逻辑封装在一个单一函数中。该函数将目标函数、初始参数和控制设置作为输入，并返回指定的性能指标。实现的核心是一个执行搜索-评估-更新循环的循环。向量运算使用 `numpy` 库来提高效率和清晰度。通过为每个指定的参数集调用此函数并收集结果来执行测试套件。最终输出按要求格式化为精确的字符串表示。", "answer": "```python\nimport numpy as np\n\ndef f1(x: np.ndarray) -> float:\n    \"\"\"Convex bowl (sphere) function.\"\"\"\n    return x[0]**2 + x[1]**2\n\ndef f2(x: np.ndarray) -> float:\n    \"\"\"Narrow valley (Rosenbrock) function.\"\"\"\n    return 100.0 * (x[1] - x[0]**2)**2 + (1.0 - x[0])**2\n\ndef f3(x: np.ndarray) -> float:\n    \"\"\"Nondifferentiable absolute sum function.\"\"\"\n    return np.abs(x[0]) + np.abs(x[1])\n\ndef run_optimizer(f, x0, delta0, delta_max, gamma, beta, epsilon, n_max):\n    \"\"\"\n    Performs derivative-free trust-region optimization using compass search.\n    \"\"\"\n    x_k = np.array(x0, dtype=float)\n    delta_k = float(delta0)\n    k = 0\n    num_failures = 0\n\n    # Direction set from the problem description\n    D = np.array([\n        [1.0, 0.0], [-1.0, 0.0], [0.0, 1.0], [0.0, -1.0],\n        [1.0, 1.0], [-1.0, 1.0], [1.0, -1.0], [-1.0, -1.0]\n    ], dtype=float)\n\n    # Pre-normalize the direction vectors\n    norms = np.linalg.norm(D, axis=1)\n    D_normalized = D / norms[:, np.newaxis]\n\n    # Initial function evaluation\n    f_k = f(x_k)\n    total_evals = 1\n\n    while k < n_max:\n        if delta_k < epsilon:\n            break\n\n        # Generate trial points and evaluate\n        f_best_trial = f_k\n        best_s = None\n        \n        trial_steps = delta_k * D_normalized\n        total_evals += len(D_normalized)\n\n        for s in trial_steps:\n            x_trial = x_k + s\n            f_trial = f(x_trial)\n            if f_trial < f_best_trial:\n                f_best_trial = f_trial\n                best_s = s\n        \n        # Update based on success or failure\n        if best_s is not None:  # Success\n            x_k = x_k + best_s\n            f_k = f_best_trial\n            delta_k = min(gamma * delta_k, delta_max)\n        else:  # Failure\n            num_failures += 1\n            delta_k = beta * delta_k\n        \n        k += 1\n\n    # Prepare results\n    k_end = k\n    converged = delta_k < epsilon\n    f_final = f_k\n    failure_fraction = num_failures / k_end if k_end > 0 else 0.0\n\n    return [k_end, total_evals, f_final, converged, failure_fraction]\n\ndef solve():\n    \"\"\"\n    Runs the optimizer on the test suite and prints the formatted results.\n    \"\"\"\n    functions = {\n        'f1': f1,\n        'f2': f2,\n        'f3': f3,\n    }\n\n    test_cases = [\n        # Case A\n        {'f_name': 'f1', 'x0': [2.0, -1.5], 'delta0': 1.0, 'delta_max': 10.0, \n         'gamma': 2.0, 'beta': 0.5, 'epsilon': 1e-6, 'n_max': 500},\n        # Case B\n        {'f_name': 'f2', 'x0': [-1.2, 1.0], 'delta0': 0.5, 'delta_max': 10.0,\n         'gamma': 1.5, 'beta': 0.7, 'epsilon': 1e-6, 'n_max': 1000},\n        # Case C\n        {'f_name': 'f3', 'x0': [3.0, -4.0], 'delta0': 1.0, 'delta_max': 20.0,\n         'gamma': 3.0, 'beta': 0.2, 'epsilon': 1e-6, 'n_max': 500},\n        # Case D\n        {'f_name': 'f1', 'x0': [2.0, -1.5], 'delta0': 1.0, 'delta_max': 10.0,\n         'gamma': 1.05, 'beta': 0.95, 'epsilon': 1e-6, 'n_max': 500},\n        # Case E\n        {'f_name': 'f2', 'x0': [-1.2, 1.0], 'delta0': 0.25, 'delta_max': 10.0,\n         'gamma': 4.0, 'beta': 0.1, 'epsilon': 1e-6, 'n_max': 1000},\n    ]\n\n    all_results = []\n    for case in test_cases:\n        f = functions[case.pop('f_name')]\n        result = run_optimizer(f, **case)\n        all_results.append(result)\n    \n    formatted_results = []\n    for res in all_results:\n        # Format: [k_end, evals, f_final, converged, failure_fraction]\n        # Python's default str for bool ('True'/'False') and float is sufficient.\n        inner_str = f\"[{res[0]},{res[1]},{res[2]},{res[3]},{res[4]}]\"\n        formatted_results.append(inner_str)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3117671"}]}