{"hands_on_practices": [{"introduction": "模拟退火算法的核心在于其独特的接受准则，即Metropolis准则。该准则允许算法以一定的概率接受一个“更差”的解，这正是它能够跳出局部最优、探索全局最优解空间的关键。这个练习将通过一个具体的计算任务，帮助你深入理解能量变化 $\\Delta C$、系统温度 $T$ 和接受概率 $P_{\\text{accept}}$ 之间的定量关系。[@problem_id:2202507]", "problem": "一个数据中心正在使用模拟退火算法来优化其服务器集群上的计算任务分配。其目标是最小化总运营成本。在此背景下，特定分配配置的“能量”被定义为其预估的运营成本，以抽象的“成本单位”来衡量。\n\n该算法目前正在评估一个我们称之为当前状态的配置，其成本为 $C_{current} = 85.5$ 成本单位。通过移动一个特定任务，提出了一个新的配置，即相邻状态。这一变化导致了更高的预估成本 $C_{neighbor} = 88.0$ 成本单位。\n\n模拟退火算法有时会接受“上坡”移动（即，移动到成本更高的状态）以逃离局部最小值。接受这种移动的概率由一个类似玻尔兹曼的分布决定，该分布依赖于一个称为“温度”的控制参数 $T$。在这个模型中，温度 $T$ 与成本具有相同的单位。\n\n为了使算法在此阶段能有效探索解空间，系统设计者已经确定，这个特定的上坡移动被接受的概率应恰好为 $0.15$。要达到这个接受概率，温度参数 $T$ 的所需值是多少？\n\n将您的最终答案四舍五入到三位有效数字。", "solution": "在模拟退火中，成本增加量为 $\\Delta C$ 的上坡移动被接受的概率由类似玻尔兹曼的因子给出：\n$$\nP_{\\text{accept}} = \\exp\\!\\left(-\\frac{\\Delta C}{T}\\right).\n$$\n这里，当前状态的成本为 $C_{\\text{current}} = 85.5$，相邻状态的成本为 $C_{\\text{neighbor}} = 88.0$，因此成本增加量为\n$$\n\\Delta C = C_{\\text{neighbor}} - C_{\\text{current}} = 88.0 - 85.5 = 2.5.\n$$\n我们要求这个移动被接受的概率为 $0.15$，所以\n$$\n\\exp\\!\\left(-\\frac{2.5}{T}\\right) = 0.15.\n$$\n对两边取自然对数并求解 $T$ 可得\n$$\n-\\frac{2.5}{T} = \\ln(0.15) \\quad \\Rightarrow \\quad T = -\\frac{2.5}{\\ln(0.15)} = \\frac{2.5}{\\ln\\!\\left(\\frac{1}{0.15}\\right)} = \\frac{2.5}{\\ln\\!\\left(\\frac{20}{3}\\right)}.\n$$\n进行数值计算并四舍五入到三位有效数字，\n$$\nT \\approx 1.32.\n$$", "answer": "$$\\boxed{1.32}$$", "id": "2202507"}, {"introduction": "理解了接受概率的计算方法后，我们来探讨一个更深层次的概念：温度 $T$ 在算法中的战略性作用。温度不仅是公式中的一个参数，更是控制算法“探索”与“利用”平衡的“旋钮”。此练习旨在揭示初始温度 $T_0$ 的设置对算法行为的决定性影响，并阐明为何一个“高”的初始温度对于有效搜索至关重要。[@problem_id:2202486]", "problem": "一位初级机器人工程师的任务是优化仓库中机械臂的路径，以便从指定位置拾取一系列物品。目标是找到能够最小化机械臂末端执行器总行进距离的拾取顺序。这是旅行商问题的一个变种。工程师决定使用模拟退火 (SA) 算法来完成这项优化任务。\n\n在 SA 算法中，一个“状态”是特定的拾取顺序，而一个状态的“能量”或“成本”是该顺序的总行进距离。该算法从一个随机顺序开始，并迭代地提出一个微小的改变（例如，交换序列中的两个物品）。如果新顺序的总距离更短（能量更低），则该改变总是被接受。如果新顺序的总距离更长（能量更高，$\\Delta E > 0$），它将以概率 $P = \\exp(-\\Delta E / T)$ 被接受，其中 $T$ 是系统的当前“温度”。温度从一个较高的值开始，并根据冷却计划逐渐降低。\n\n工程师希望加速寻找一个好的解决方案，于是将初始温度 $T_0$ 设置为一个非常小的、接近于零的正值。下列哪个陈述最准确地描述了这一选择对算法行为最直接和最显著的影响？\n\nA. 算法将表现得像一个贪婪下降（或爬山）法，很可能陷入靠近初始状态的局部最小值。\n\nB. 算法将以高度随机的方式探索解空间，需要很长时间才能收敛到任何稳定解。\n\nC. 与初始温度较高的情况相比，算法接受增加行进距离的移动的概率会更高。\n\nD. 算法将更有效地找到全局最优路径，因为它不会浪费时间探索次优路径。", "solution": "在模拟退火中，对于一个能量变化为 $\\Delta E$ 的提议移动，Metropolis 接受准则是\n$$\nP_{\\text{accept}}(\\Delta E,T)=\n\\begin{cases}\n1, & \\Delta E \\le 0,\\\\\n\\exp\\!\\left(-\\frac{\\Delta E}{T}\\right), & \\Delta E > 0.\n\\end{cases}\n$$\n考虑将初始温度 $T_{0}$ 设置为一个非常小的正值的直接影响。对于任意固定的 $\\Delta E>0$，\n$$\n\\lim_{T \\to 0^{+}} \\exp\\!\\left(-\\frac{\\Delta E}{T}\\right)=\\exp\\!\\left(-\\lim_{T \\to 0^{+}}\\frac{\\Delta E}{T}\\right)=\\exp(-\\infty)=0.\n$$\n因此，在 $T_{0}\\approx 0^{+}$ 时，接受任何上坡移动（$\\Delta E>0$）的概率基本为零，而所有下坡移动（$\\Delta E\\le 0$）都以概率 $1$ 被接受。等价地，相对于提议的局部移动算子，该算法退化为一个贪婪下降（爬山）过程。\n\n此外，对于 $\\Delta E>0$，接受概率是关于 $T$ 的严格递增函数，因为\n$$\n\\frac{\\partial}{\\partial T}\\exp\\!\\left(-\\frac{\\Delta E}{T}\\right)=\\exp\\!\\left(-\\frac{\\Delta E}{T}\\right)\\frac{\\Delta E}{T^{2}}>0,\n$$\n所以选择一个非常小的 $T_{0}$ 会最小化接受上坡移动的机会，从而最小化探索行为。因此，最直接和最显著的后果是算法很可能会陷入靠近初始状态的局部最小值，这与选项 A 相符。选项 B 和 C 与上坡移动接受概率随 $T$ 单调增加的性质相矛盾，而选项 D 是错误的，因为缺乏对上坡移动的接受能力会阻碍算法逃离局部最小值，从而妨碍全局优化。", "answer": "$$\\boxed{A}$$", "id": "2202486"}, {"introduction": "现在，我们将理论付诸实践，将所有独立的知识点整合成一个完整的解决方案。解决实际的优化问题需要系统地设计状态空间、能量函数、邻域移动、接受准则和冷却策略。这个综合性练习将指导你从零开始为一个经典的装箱问题（Bin Packing Problem）构建一个模拟退火求解器，这是将抽象概念转化为实用技能的绝佳机会。[@problem_id:3182664]", "problem": "你将从第一性原理出发，为一个离散的装箱能量最小化问题实现一个完整的模拟退火求解器。你将定义一个惩罚箱子溢出和不平衡的能量函数，提出探索构型空间的局部移动，为一个基于统计原理的接受准则提供理由，并研究温度调度如何影响冲突的减少。此问题纯粹是数学和离散的；没有物理单位，也没有角度测量。\n\n给定一组包含 $n$ 个物品的集合，其尺寸非负，记为 $\\{s_i\\}_{i=1}^n$，以及固定数量的箱子 $B$ 和箱子容量 $C$，一个构型是一个函数 $x:\\{1,\\dots,n\\}\\to\\{1,\\dots,B\\}$，它将每个物品分配到一个箱子中。对于箱子 $b\\in\\{1,\\dots,B\\}$，其负载为 $L_b(x)=\\sum_{i: x(i)=b} s_i$，并定义利用率为 $u_b(x)=L_b(x)/C$。定义能量为\n$$\nE(x)=\\alpha\\sum_{b=1}^B \\max\\{0,\\,u_b(x)-1\\}+\\beta\\left(\\frac{1}{B}\\sum_{b=1}^B \\left(u_b(x)-\\bar{u}(x)\\right)^2\\right),\n$$\n其中 $\\bar{u}(x)=\\frac{1}{B}\\sum_{b=1}^B u_b(x)$ 是平均利用率，$\\alpha>0$ 控制溢出惩罚的强度，$\\beta>0$ 通过利用率的方差控制不平衡惩罚的强度。目标是最小化 $E(x)$ 并理解模拟退火中温度的作用。\n\n你必须从第一性原理出发实现一个模拟退火算法，具体如下，从具有玻尔兹曼平稳律的马尔可夫链是通过提议的对称性和细致平衡获得的这一基础开始：\n\n- 状态空间和能量：状态是所有分配方案 $x$；能量是如上定义的 $E(x)$。\n- 移动提议：使用由两种对称移动类型构成的提议分布，这两种移动类型保持了状态空间的连通性：\n  1. 单物品重分配：从 $\\{1,\\dots,n\\}$ 中均匀随机选择一个物品索引 $i$，并从 $\\{1,\\dots,B\\}$ 中均匀随机选择一个满足 $b'\\neq x(i)$ 的目标箱子 $b'$，然后将 $i$ 重新分配到 $b'$。\n  2. 双物品交换：均匀随机地选择两个不同的物品 $i\\neq j$；如果 $x(i)\\neq x(j)$，则交换它们的箱子分配。\n- 接受准则：使用源于与能量 $E(x)$ 在温度 $T>0$ 下相关联的玻尔兹曼分布的 Metropolis 型接受准则。在你的书面解决方案中，必须从细致平衡原理出发对该接受准则进行论证，并且你的程序必须实现你推导出的显式接受概率。你的实现还必须包含当 $T\\to 0^+$ 时的正确极限行为。\n- 温度调度：使用几何（乘法）降温调度 $T_k = T_0 r^k$，其中 $T_0\\ge 0$ 和 $r\\in(0,1)$，并定性分析其对减少冲突（溢出和不平衡）能力的影响。你的书面解决方案必须论证为何此调度从一个简单的衰减原理出发对应于指数降温行为。\n\n必须遵循的实现细节：\n- 从一个确定性的贪婪负载均衡分配开始初始化：按尺寸非递增顺序对物品进行排序，并将每个物品放入当前负载最小的箱子中（通过最低索引的箱子来打破平局）。这确保了所有测试用例的起点相同。\n- 在每次迭代中以相等的概率使用两种移动类型，从符合条件的选项中均匀随机抽样。\n- 对于接受决策，推导并实现一个正确且数值稳定的接受概率。如果在任何迭代中 $T=0$，算法必须简化为纯粹的下降，只接受不使情况恶化的移动。\n- 跟踪遇到的最佳能量 $E^*$，并在每次测试用例运行结束时返回它。\n- 为每个测试用例使用提供的固定种子的伪随机数生成器，以确保可复现性。\n\n测试套件和要求的程序输出：\n为以下四个测试用例提供结果。对每个案例，运行模拟退火固定次数的迭代 $K$。算法参数必须与指定完全一致。对于所有案例，除非另有说明，否则使用相同的能量参数 $\\alpha$ 和 $\\beta$。\n\n通用能量参数：$\\alpha=20.0$, $\\beta=1.0$。\n\n- 案例 A（中等降温下的一般探索）：\n  - 物品 $\\{s_i\\}$: $[7,5,6,2,3,4,8,1,9,2,6,5]$\n  - 箱子数量 $B$: $4$\n  - 容量 $C$: $10$\n  - 初始温度 $T_0$: $5.0$\n  - 降温因子 $r$: $0.997$\n  - 迭代次数 $K$: $4000$\n  - 种子: $11$\n- 案例 B（零温度下的边界行为，贪婪下降）：\n  - 物品 $\\{s_i\\}$: $[7,5,6,2,3,4,8,1,9,2,6,5]$\n  - 箱子数量 $B$: $4$\n  - 容量 $C$: $10$\n  - 初始温度 $T_0$: $0.0$\n  - 降温因子 $r$: $0.500$\n  - 迭代次数 $K$: $4000$\n  - 种子: $11$\n- 案例 C（从高温开始的极慢降温）：\n  - 物品 $\\{s_i\\}$: $[7,5,6,2,3,4,8,1,9,2,6,5]$\n  - 箱子数量 $B$: $4$\n  - 容量 $C$: $10$\n  - 初始温度 $T_0$: $20.0$\n  - 降温因子 $r$: $0.999$\n  - 迭代次数 $K$: $4000$\n  - 种子: $11$\n- 案例 D（溢出主导的实例，中等降温）：\n  - 物品 $\\{s_i\\}$: $[9,9,8,7,6,6,5,5,4,4]$\n  - 箱子数量 $B$: $4$\n  - 容量 $C$: $10$\n  - 初始温度 $T_0$: $10.0$\n  - 降温因子 $r$: $0.998$\n  - 迭代次数 $K$: $5000$\n  - 种子: $99$\n\n对于每个案例，你的程序必须输出找到的最佳能量值 $E^*$，四舍五入到恰好 $4$ 位小数。你的程序应生成单行输出，其中包含一个方括号内的逗号分隔列表的结果，顺序为 $[E^*_A,E^*_B,E^*_C,E^*_D]$。例如，输出格式必须类似于“[0.1234,0.2345,0.3456,0.4567]”。", "solution": "我们从统计力学和马尔可夫链蒙特卡洛的基础出发。一个基本且经过充分检验的原理是，一个在绝对温度 $T>0$ 下处于热平衡的系统，其占据微观状态 $x$ 的概率与玻尔兹曼权重 $\\exp(-E(x)/T)$ 成正比，其中 $E(x)$ 是一个能量函数。为了构造一个在该状态空间上具有此平稳分布的马尔可夫链，一种标准方法是使用 Metropolis-Hastings 方法，其提议需满足细致平衡条件。\n\n令 $q(x\\to y)$ 为给定当前状态 $x$ 时到状态 $y$ 的提议分布。如果我们确保 $q$ 是对称的，即对于所有概率非零的对 $(x,y)$ 都有 $q(x\\to y)=q(y\\to x)$，那么相对于玻尔兹曼分布的细致平衡条件就简化为对接受概率 $A(x\\to y)$ 的一个条件：\n$$\n\\pi_T(x) q(x\\to y) A(x\\to y) = \\pi_T(y) q(y\\to x) A(y\\to x),\n$$\n其中 $\\pi_T(x)\\propto \\exp(-E(x)/T)$ 是目标分布。在 $q$ 对称的条件下，我们得到\n$$\n\\frac{A(x\\to y)}{A(y\\to x)} = \\frac{\\pi_T(y)}{\\pi_T(x)} = \\exp\\left(-\\frac{E(y)-E(x)}{T}\\right) = \\exp\\left(-\\frac{\\Delta E}{T}\\right).\n$$\n一个满足此比率且能使 $A\\in[0,1]$ 的、经过充分检验的选择是 Metropolis 接受函数\n$$\nA(x\\to y) = \\min\\left\\{1,\\; \\exp\\left(-\\frac{\\Delta E}{T}\\right)\\right\\},\n$$\n其中 $\\Delta E=E(y)-E(x)$。这有两个与优化一致的极限性质：如果 $\\Delta E\\le 0$，则 $A=1$，所有改进的移动都被接受；如果 $\\Delta E>0$ 且 $T\\to 0^+$，则 $A\\to 0$，上坡移动被拒绝，恢复为贪婪下降。在严格正值的 $T$ 下，链偶尔会接受上坡移动，从而有助于逃离局部最小值。\n\n接下来我们定义离散优化问题。对于 $B$ 个容量为 $C$ 的箱子和物品尺寸 $\\{s_i\\}_{i=1}^n$，一个构型 $x$ 将每个物品分配到一个箱子中。箱子 $b$ 的负载是 $L_b(x)=\\sum_{i: x(i)=b} s_i$，利用率是 $u_b(x)=L_b(x)/C$。能量函数是两项之和：\n- 一个溢出惩罚 $\\alpha\\sum_{b=1}^B \\max\\{0,\\,u_b(x)-1\\}$，如果每个箱子都在容量范围内，则该项为零，否则随溢出线性增加。标量 $\\alpha>0$ 调整溢出被惩罚的强度。\n- 一个方差惩罚 $\\beta\\cdot \\frac{1}{B}\\sum_{b=1}^B \\left(u_b(x)-\\bar{u}(x)\\right)^2$，其中 $\\bar{u}(x)=\\frac{1}{B}\\sum_{b=1}^B u_b(x)$ 是平均利用率。该项鼓励箱子负载均衡，并由 $\\beta>0$ 进行缩放。\n\n由于利用率 $u_b$ 已经通过 $C$ 进行了归一化，因此这两项都是无量纲的。\n\n移动提议必须是对称的，才能使用 Metropolis 接受准则而无需显式的 Hastings 校正。我们以相等的概率选择两种移动类型：\n- 单物品重分配：从 $\\{1,\\dots,n\\}$ 中均匀选择一个物品索引 $i$，并从 $\\{1,\\dots,B\\}\\setminus\\{x(i)\\}$ 中均匀选择一个目标箱子 $b'$，然后将 $i$ 重新分配到 $b'$。反向移动具有相同的概率，从而建立了对称性。\n- 双物品交换：均匀随机地选择不同的物品 $i\\neq j$。如果 $x(i)\\neq x(j)$，则交换它们的箱子。反向操作是相同的交换，同样是对称的。\n\n对于温度调度，我们采用几何降温 $T_k=T_0 r^k$，其中 $r\\in(0,1)$。该调度是通过离散化一个由简单线性微分方程 $\\frac{dT}{dk}=-\\lambda T$ 控制的指数衰减得到的，其解为 $T(k)=T_0 e^{-\\lambda k}$。使用一个离散的乘法递减，其中 $r=e^{-\\lambda}$，便得到 $T_k=T_0 r^k$，这是实践中一种标准且经过充分检验的调度。在高温下，即使对于适度正值的 $\\Delta E$，接受概率 $A(x\\to y)$ 也接近 $1$，从而产生广泛的探索；随着 $T$ 的降低，因子 $\\exp(-\\Delta E/T)$ 对于正的 $\\Delta E$ 会减小，从而越来越倾向于改进的移动并收敛到最小值。因此，高 $T_0$ 和缓慢降温（大的 $r$ 接近 $1$）促进了全局探索和冲突的减少，它允许可能暂时恶化方差以缓解溢出的重排，而 $T_0=0$ 则恢复为纯粹的下降，这可能很快会停滞。\n\n算法设计：\n- 初始化使用确定性的贪婪负载均衡启发式方法：按非递增顺序对物品进行排序，并将每个物品放入当前负载最小的箱子中，通过箱子索引打破平局。这产生了一个与随机种子无关的可复现的起始 $x_0$。\n- 迭代地使用两种对称类型之一提议一个移动，计算 $\\Delta E$，并以 Metropolis 概率接受。如果 $T=0$，则仅在 $\\Delta E\\le 0$ 时接受，以避免除以零并实现正确的极限行为。\n- 维护当前状态和所见过的最佳状态（最低能量）。每次迭代通过 $T\\leftarrow rT$ 更新温度。\n\n测试套件设计和覆盖范围：\n- 案例 A 使用中等初始温度和降温因子，模拟典型场景。\n- 案例 B 设置 $T_0=0$ 来测试模拟退火简化为没有上坡接受的贪婪下降的边界情况；这探讨了温度对逃离局部最小值的影响。\n- 案例 C 使用非常高的 $T_0$ 和非常缓慢的降温（$r$ 接近 $1$），测试在相同迭代预算内广泛探索及其对最终能量的影响。\n- 案例 D 使用一个总物品尺寸超过总容量的实例，迫使出现溢出。这测试了算法在中等降温下在分配溢出和平衡方差之间的权衡。\n\n对于每个案例，输出是遇到的最佳能量 $E^*$，四舍五入到 $4$ 位小数，按 $[E^*_A,E^*_B,E^*_C,E^*_D]$ 的顺序打印为单个列表。由于每个案例的随机种子是固定的，结果是可复现的。\n\n程序精确地实现了以上所有规范，并产生了所需的单行输出。", "answer": "```python\nimport numpy as np\n\ndef greedy_initial_assignment(sizes, B):\n    # Deterministic greedy: sort items by size desc, place into bin with min load\n    n = len(sizes)\n    indices = sorted(range(n), key=lambda i: (-sizes[i], i))\n    loads = [0.0] * B\n    assignment = [0] * n\n    for i in indices:\n        b = min(range(B), key=lambda k: (loads[k], k))\n        assignment[i] = b\n        loads[b] += sizes[i]\n    return assignment, np.array(loads, dtype=float)\n\ndef energy_from_loads(loads, C, alpha, beta):\n    B = len(loads)\n    u = loads / C\n    overflow = np.maximum(0.0, u - 1.0).sum()\n    mean_u = u.mean() if B > 0 else 0.0\n    var_u = ((u - mean_u) ** 2).mean() if B > 0 else 0.0\n    return alpha * overflow + beta * var_u\n\ndef propose_move(rng, assignment, loads, sizes, B):\n    n = len(assignment)\n    move_type = rng.integers(0, 2)  # 0: single-item move, 1: two-item swap\n    new_assignment = assignment.copy()\n    new_loads = loads.copy()\n    if move_type == 0:\n        # Single-item reassignment\n        i = int(rng.integers(0, n))\n        current_bin = new_assignment[i]\n        # Choose a different bin\n        if B > 1:\n            dest_bin = int(rng.integers(0, B - 1))\n            if dest_bin >= current_bin:\n                dest_bin += 1\n        else:\n            dest_bin = current_bin\n        if dest_bin != current_bin:\n            size_i = sizes[i]\n            new_assignment[i] = dest_bin\n            new_loads[current_bin] -= size_i\n            new_loads[dest_bin] += size_i\n        # else, identity move; return unchanged (will lead to deltaE = 0)\n    else:\n        # Two-item swap\n        if n >= 2:\n            i = int(rng.integers(0, n))\n            j = int(rng.integers(0, n - 1))\n            if j >= i:\n                j += 1\n            bi, bj = new_assignment[i], new_assignment[j]\n            if bi != bj:\n                # swap assignments\n                new_assignment[i], new_assignment[j] = bj, bi\n                si, sj = sizes[i], sizes[j]\n                # update loads\n                new_loads[bi] -= si\n                new_loads[bj] += si\n                new_loads[bj] -= sj\n                new_loads[bi] += sj\n            # else, identity (no change)\n    return new_assignment, new_loads\n\ndef simulated_annealing(sizes, B, C, alpha, beta, T0, r, iterations, seed):\n    rng = np.random.default_rng(seed)\n    assignment, loads = greedy_initial_assignment(sizes, B)\n    current_E = energy_from_loads(loads, C, alpha, beta)\n    best_E = current_E\n    best_assignment = assignment.copy()\n    best_loads = loads.copy()\n    T = float(T0)\n\n    for k in range(iterations):\n        cand_assignment, cand_loads = propose_move(rng, assignment, loads, sizes, B)\n        cand_E = energy_from_loads(cand_loads, C, alpha, beta)\n        deltaE = cand_E - current_E\n\n        accept = False\n        if deltaE <= 0.0:\n            accept = True\n        else:\n            if T < 1e-12:\n                accept = False\n            else:\n                # Metropolis acceptance\n                # Clip exponent to avoid overflow in extreme cases\n                exponent = -deltaE / T\n                # numpy exp is stable for moderate exponents; large negative exponents underflow to 0 naturally\n                p = np.exp(exponent) if exponent > -745 else 0.0\n                u = rng.random()\n                accept = (u < p)\n\n        if accept:\n            assignment = cand_assignment\n            loads = cand_loads\n            current_E = cand_E\n            if current_E < best_E:\n                best_E = current_E\n                best_assignment = assignment.copy()\n                best_loads = loads.copy()\n\n        # geometric cooling\n        T *= r\n\n    return best_E, best_assignment, best_loads\n\ndef solve():\n    # Common energy parameters\n    alpha = 20.0\n    beta = 1.0\n\n    test_cases = [\n        # Case A\n        {\n            \"sizes\": [7, 5, 6, 2, 3, 4, 8, 1, 9, 2, 6, 5],\n            \"B\": 4,\n            \"C\": 10,\n            \"T0\": 5.0,\n            \"r\": 0.997,\n            \"iterations\": 4000,\n            \"seed\": 11\n        },\n        # Case B\n        {\n            \"sizes\": [7, 5, 6, 2, 3, 4, 8, 1, 9, 2, 6, 5],\n            \"B\": 4,\n            \"C\": 10,\n            \"T0\": 0.0,\n            \"r\": 0.500,\n            \"iterations\": 4000,\n            \"seed\": 11\n        },\n        # Case C\n        {\n            \"sizes\": [7, 5, 6, 2, 3, 4, 8, 1, 9, 2, 6, 5],\n            \"B\": 4,\n            \"C\": 10,\n            \"T0\": 20.0,\n            \"r\": 0.999,\n            \"iterations\": 4000,\n            \"seed\": 11\n        },\n        # Case D\n        {\n            \"sizes\": [9, 9, 8, 7, 6, 6, 5, 5, 4, 4],\n            \"B\": 4,\n            \"C\": 10,\n            \"T0\": 10.0,\n            \"r\": 0.998,\n            \"iterations\": 5000,\n            \"seed\": 99\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        sizes = case[\"sizes\"]\n        B = case[\"B\"]\n        C = case[\"C\"]\n        T0 = case[\"T0\"]\n        r = case[\"r\"]\n        iterations = case[\"iterations\"]\n        seed = case[\"seed\"]\n\n        best_E, _, _ = simulated_annealing(\n            np.array(sizes, dtype=float), B, C, alpha, beta, T0, r, iterations, seed\n        )\n        results.append(best_E)\n\n    # Format results to 4 decimal places\n    formatted = \"[\" + \",\".join(f\"{x:.4f}\" for x in results) + \"]\"\n    print(formatted)\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3182664"}]}