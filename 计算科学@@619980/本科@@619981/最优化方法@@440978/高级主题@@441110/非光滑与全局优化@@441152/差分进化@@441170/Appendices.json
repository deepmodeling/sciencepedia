{"hands_on_practices": [{"introduction": "掌握差异演化算法的理论仅仅是第一步，真正的挑战在于构建一个能够在复杂现实问题中稳健运行的求解器。这项练习将引导你实现一个完整的差异演化算法，并加入两个关键的实用技术：用于跳出局部最优的重启策略，以及确保解可行性的“反弹”边界处理机制。通过在标准的多峰测试函数上实践，你将深入理解这些机制如何提升算法的探索能力和最终性能。[@problem_id:3120583]", "problem": "要求您实现一个完整的、确定性的程序，该程序使用带有重启策略和反弹边界处理的差分进化算法来最小化多模态目标函数。该程序的设计必须在其算法步骤中体现第一性原理推导，并为指定的测试套件生成数值结果。\n\n差分进化（DE）是一种基于种群的优化方法，定义于函数 $f : \\mathbb{R}^d \\to \\mathbb{R}$ 在边界约束 $[\\mathbf{L}, \\mathbf{U}]$ 上，其中 $\\mathbf{L}, \\mathbf{U} \\in \\mathbb{R}^d$ 且对于所有 $j \\in \\{1, \\dots, d\\}$ 都有 $\\mathbf{L}_j < \\mathbf{U}_j$。核心的差分进化算子由以下基本要素指定：\n\n1. 初始化：在 $[\\mathbf{L}, \\mathbf{U}]$ 内均匀随机采样 $N_p$ 个候选向量，其中 $N_p \\in \\mathbb{N}$ 是种群大小。\n\n2. 变异 (DE/rand/1)：对于每个目标索引 $i$，选择三个与 $i$ 不同的索引 $r_1, r_2, r_3$，并形成供体向量\n$$\n\\mathbf{v}_i = \\mathbf{x}_{r_1} + F \\cdot (\\mathbf{x}_{r_2} - \\mathbf{x}_{r_3}),\n$$\n其中 $F \\in \\mathbb{R}$ 是变异因子。\n\n3. 交叉（二项式，也称为均匀交叉）：对于每个分量 $j \\in \\{1, \\dots, d\\}$，\n$$\nu_{i, j} = \n\\begin{cases}\nv_{i, j},  & \\text{如果 } \\text{rand} \\le CR \\text{ 或 } j = j_{\\text{rand}}, \\\\\nx_{i, j},  & \\text{其他情况},\n\\end{cases}\n$$\n其中 $CR \\in [0, 1]$ 是交叉率，$\\text{rand}$ 是从 $[0, 1]$ 上的均匀分布中新抽取的独立样本，而 $j_{\\text{rand}}$ 是在 $\\{1, \\dots, d\\}$ 中均匀选择的一个索引，以确保至少有一个分量来自供体向量。\n\n4. 选择（贪婪）：如果 $f(\\mathbf{u}_i) \\le f(\\mathbf{x}_i)$，则设置 $\\mathbf{x}_i \\leftarrow \\mathbf{u}_i$，否则保持 $\\mathbf{x}_i$ 不变。\n\n边界处理必须确保试验向量的可行性。按如下方式实现用于保证可行性的反弹反射：对于任何具有下界 $L$ 和上界 $U$ 的标量分量 $y \\in \\mathbb{R}$，反复地在被违反的边界上进行反射，直到 $y \\in [L, U]$，\n$$\ny \\leftarrow \n\\begin{cases}\n2L - y,  & \\text{如果 } y < L, \\\\\n2U - y,  & \\text{如果 } y > U,\n\\end{cases}\n$$\n如果反射后的 $y$ 仍然违反边界，则重复此过程。当反弹被禁用时，改用截断\n$$\ny \\leftarrow \\min(\\max(y, L), U).\n$$\n\n精确定义停滞和重启策略。跟踪每一代中的最优目标值，\n$$\nf^\\star(g) = \\min_{i \\in \\{1, \\dots, N_p\\}} f(\\mathbf{x}_i(g)),\n$$\n其中 $\\mathbf{x}_i(g)$ 是第 $g$ 代的个体 $i$。令 $\\epsilon = 10^{-12}$。如果 $f^\\star(g) < f^\\star(g-1) - \\epsilon$，则认为一代有所改进。停滞期是没有改进的连续代序列。当停滞期长度达到 $S \\in \\mathbb{N}$ 时，通过将变异因子和交叉率重置为探索性值 $(F_{\\text{explore}}, CR_{\\text{explore}})$ 来触发重启策略，持续 $g_{\\text{explore}} \\in \\mathbb{N}$ 代。在此探索窗口期间，使用 $(F, CR) = (F_{\\text{explore}}, CR_{\\text{explore}})$。窗口结束后，恢复为基础值 $(F_{\\text{base}}, CR_{\\text{base}})$。如果之后再次出现长度为 $S$ 的停滞期，则以同样的方式触发另一个探索窗口。\n\n使用以下多模态目标函数，每个函数都经过广泛使用和良好测试：\n\n- $d$ 维 Rastrigin 函数，参数 $A = 10$，全局最小值在 $\\mathbf{x} = \\mathbf{0}$：\n$$\nf_{\\text{Rastrigin}}(\\mathbf{x}) = A d + \\sum_{j=1}^{d} \\left( x_j^2 - A \\cos(2\\pi x_j) \\right).\n$$\n\n- $d$ 维 Ackley 函数，参数 $a = 20$, $b = 0.2$, $c = 2\\pi$，全局最小值在 $\\mathbf{x} = \\mathbf{0}$：\n$$\nf_{\\text{Ackley}}(\\mathbf{x}) = -a \\exp\\left( -b \\sqrt{ \\frac{1}{d} \\sum_{j=1}^d x_j^2 } \\right)\n- \\exp\\left( \\frac{1}{d} \\sum_{j=1}^d \\cos(c x_j) \\right)\n+ a + e.\n$$\n\n您的程序必须实现所述的带有反弹边界处理和重启策略的差分进化过程。它必须通过为每个测试用例使用固定的随机种子来保证确定性。\n\n测试套件：\n对于下面的每个测试用例，运行差分进化恰好 $G_{\\max}$ 代，并返回最终的最优目标值（浮点数）。\n\n- 用例 $1$（正常路径，Rastrigin 反弹）：\n  - 函数: $f_{\\text{Rastrigin}}$.\n  - 维度: $d = 5$.\n  - 边界: $L_j = -5.12$, $U_j = 5.12$ 对所有 $j$.\n  - 种群大小: $N_p = 40$.\n  - 代数: $G_{\\max} = 300$.\n  - 基础参数: $F_{\\text{base}} = 0.5$, $CR_{\\text{base}} = 0.9$.\n  - 探索性参数: $F_{\\text{explore}} = 0.95$, $CR_{\\text{explore}} = 0.2$.\n  - 停滞阈值: $S = 25$.\n  - 探索窗口长度: $g_{\\text{explore}} = 10$.\n  - 反弹: 启用.\n  - 随机种子: $42$.\n\n- 用例 $2$（Ackley 反弹，更高的崎岖度）：\n  - 函数: $f_{\\text{Ackley}}$.\n  - 维度: $d = 5$.\n  - 边界: $L_j = -32.768$, $U_j = 32.768$ 对所有 $j$.\n  - 种群大小: $N_p = 30$.\n  - 代数: $G_{\\max} = 400$.\n  - 基础参数: $F_{\\text{base}} = 0.7$, $CR_{\\text{base}} = 0.6$.\n  - 探索性参数: $F_{\\text{explore}} = 1.0$, $CR_{\\text{explore}} = 0.1$.\n  - 停滞阈值: $S = 40$.\n  - 探索窗口长度: $g_{\\text{explore}} = 15$.\n  - 反弹: 启用.\n  - 随机种子: $123$.\n\n- 用例 $3$（Rastrigin 反弹，频繁重启的边缘情况）：\n  - 函数: $f_{\\text{Rastrigin}}$.\n  - 维度: $d = 2$.\n  - 边界: $L_j = -5.12$, $U_j = 5.12$ 对所有 $j$.\n  - 种群大小: $N_p = 10$.\n  - 代数: $G_{\\max} = 200$.\n  - 基础参数: $F_{\\text{base}} = 0.5$, $CR_{\\text{base}} = 0.9$.\n  - 探索性参数: $F_{\\text{explore}} = 1.2$, $CR_{\\text{explore}} = 0.1$.\n  - 停滞阈值: $S = 5$.\n  - 探索窗口长度: $g_{\\text{explore}} = 8$.\n  - 反弹: 启用.\n  - 随机种子: $7$.\n\n- 用例 $4$（Ackley 使用截断代替反弹，用于对比分析）：\n  - 函数: $f_{\\text{Ackley}}$.\n  - 维度: $d = 5$.\n  - 边界: $L_j = -32.768$, $U_j = 32.768$ 对所有 $j$.\n  - 种群大小: $N_p = 30$.\n  - 代数: $G_{\\max} = 400$.\n  - 基础参数: $F_{\\text{base}} = 0.7$, $CR_{\\text{base}} = 0.6$.\n  - 探索性参数: $F_{\\text{explore}} = 1.0$, $CR_{\\text{explore}} = 0.1$.\n  - 停滞阈值: $S = 40$.\n  - 探索窗口长度: $g_{\\text{explore}} = 15$.\n  - 反弹: 禁用 (使用截断).\n  - 随机种子: $123$.\n\n最终输出格式：\n您的程序应生成单行输出，其中包含来自测试套件的四个最终最优目标值，按顺序排列在一个用方括号括起来的逗号分隔列表中，例如 $[$result1$,$result2$,$result3$,$result4$]$。每个结果都必须是一个浮点数，并且打印的行不能包含任何其他文本。", "solution": "该问题要求实现差分进化（DE）算法，并结合针对停滞的特定重启策略和反弹边界处理机制。该解决方案将通过一套在标准多模态基准函数上的测试用例进行验证。整个过程必须是确定性的，这通过为每个测试用例使用固定的随机种子来实现。\n\n解决方案的设计遵循基于种群的随机优化的第一性原理以及问题描述中定义的特定算子。\n\n首先，我们定义目标函数。$d$ 维 Rastrigin 函数，参数为 $A$，由以下公式给出：\n$$\nf_{\\text{Rastrigin}}(\\mathbf{x}) = A d + \\sum_{j=1}^{d} \\left( x_j^2 - A \\cos(2\\pi x_j) \\right)\n$$\n$d$ 维 Ackley 函数，参数为 $a$, $b$, 和 $c$，由以下公式给出：\n$$\nf_{\\text{Ackley}}(\\mathbf{x}) = -a \\exp\\left( -b \\sqrt{ \\frac{1}{d} \\sum_{j=1}^d x_j^2 } \\right)\n- \\exp\\left( \\frac{1}{d} \\sum_{j=1}^d \\cos(c x_j) \\right)\n+ a + e\n$$\n其中 $e$ 是自然对数的底数，$e \\approx 2.71828$。\n\n算法的核心是差分进化过程。\n1.  **初始化**：创建一个包含 $N_p$ 个候选向量的初始种群，$\\{\\mathbf{x}_1, \\dots, \\mathbf{x}_{N_p}\\}$。每个向量 $\\mathbf{x}_i \\in \\mathbb{R}^d$ 都是在指定的边界 $[\\mathbf{L}, \\mathbf{U}]$ 内从均匀分布中采样的。也就是说，对于每个分量 $j \\in \\{1, \\dots, d\\}$，$x_{i,j}$ 是从 $U(L_j, U_j)$ 中采样的。该过程使用种子以确保可复现性。\n\n2.  **代循环**：算法最多迭代 $G_{\\max}$ 代。在每一代中，都会创建一个新的试验向量种群，并与当前种群进行比较。\n\n3.  **变异**：对于当前种群中的每个目标向量 $\\mathbf{x}_i$，使用 \"DE/rand/1\" 策略生成一个供体向量 $\\mathbf{v}_i$。随机选择三个不同的索引 $r_1, r_2, r_3 \\in \\{1, \\dots, N_p\\}$，并确保它们也不同于目标索引 $i$。然后计算供体向量：\n    $$\n    \\mathbf{v}_i = \\mathbf{x}_{r_1} + F \\cdot (\\mathbf{x}_{r_2} - \\mathbf{x}_{r_3})\n    $$\n    这里，$F \\in \\mathbb{R}$ 是变异因子，一个控制差异变异放大程度的关键参数。\n\n4.  **交叉**：通过组合目标向量 $\\mathbf{x}_i$ 和供体向量 $\\mathbf{v}_i$ 的分量来形成试验向量 $\\mathbf{u}_i$。采用指定的二项式交叉方案。对于每个分量 $j \\in \\{1, \\dots, d\\}$：\n    $$\n    u_{i, j} = \n    \\begin{cases}\n    v_{i, j},  & \\text{如果 } \\text{rand}_j \\le CR \\text{ 或 } j = j_{\\text{rand}}, \\\\\n    x_{i, j},  & \\text{其他情况},\n    \\end{cases}\n    $$\n    其中 $CR \\in [0, 1]$ 是交叉率，$\\text{rand}_j$ 是为每个分量从 $U(0, 1)$ 中新抽取的一个样本，而 $j_{\\text{rand}}$ 是从 $\\{1, \\dots, d\\}$ 中随机选择的一个索引。$j=j_{\\text{rand}}$ 条件保证了试验向量 $\\mathbf{u}_i$ 至少从供体向量 $\\mathbf{v}_i$ 接收一个分量。\n\n5.  **边界处理**：试验向量 $\\mathbf{u}_i$ 可能有分量超出了可行边界 $[\\mathbf{L}, \\mathbf{U}]$。这些必须在函数评估前进行修正。\n    *   **截断**：这是一种较简单的方法，当反弹被禁用时使用，将分量截断到边界：$u_{i,j} \\leftarrow \\min(\\max(u_{i,j}, L_j), U_j)$。\n    *   **反弹反射**：此方法将被违反边界的分量反射回可行范围内。对于分量 $y$ 和边界 $[L, U]$，规则是：\n        $$\n        y \\leftarrow \n        \\begin{cases}\n        2L - y,  & \\text{如果 } y < L, \\\\\n        2U - y,  & \\text{如果 } y > U.\n        \\end{cases}\n        $$\n        由于如果分量远在边界之外（例如，$y < L - (U-L)$），单次反射可能不足以使其回到界内，因此该过程必须在循环中迭代应用，直到 $y \\in [L, U]$。\n\n6.  **选择**：贪婪选择策略决定了试验向量 $\\mathbf{u}_i$ 是否在下一代替换目标向量 $\\mathbf{x}_i$。比较目标函数值：\n    $$\n    \\mathbf{x}_i^{\\text{next}} = \n    \\begin{cases}\n    \\mathbf{u}_i,  & \\text{如果 } f(\\mathbf{u}_i) \\le f(\\mathbf{x}_i), \\\\\n    \\mathbf{x}_i,  & \\text{其他情况}.\n    \\end{cases}\n    $$\n    这确保了种群的适应度在各代之间只会改善或保持不变。\n\n7.  **重启策略**：该机制旨在通过周期性地促进探索来逃离局部最优。它由一个停滞计数器控制。\n    *   令 $f^\\star(g)$ 为第 $g$ 代种群中的最优目标值。改进定义为 $f^\\star(g) < f^\\star(g-1) - \\epsilon$，其中 $\\epsilon = 10^{-12}$ 是一个用于考虑浮点数不精确性的微小容差。\n    *   `stagnation_streak` 计数器在每一代没有改进时递增。一旦有改进，它就被重置为 $0$。\n    *   如果 `stagnation_streak` 达到阈值 $S$，则触发重启。DE 参数 $(F, CR)$ 被设置为它们的探索性值 $(F_{\\text{explore}}, CR_{\\text{explore}})$，持续时间为 $g_{\\text{explore}}$ 代。`stagnation_streak` 计数器被重置为 $0$，以防止立即再次触发。\n    *   一个 `exploratory_counter` 管理此阶段的持续时间。它被初始化为 $g_{\\text{explore}}$ 并在每一代递减。当它达到 $0$ 时，参数 $(F, CR)$ 恢复为它们的基础值 $(F_{\\text{base}}, CR_{\\text{base}})$。\n\n通过将这些基于原理的步骤组合成一个确定性程序（通过固定种子实现），我们可以系统地评估该算法在指定测试套件上的性能。每个用例的最终输出将是在 $G_{\\max}$ 代后找到的最优目标函数值。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Main solver function that orchestrates the execution of all test cases.\n    \"\"\"\n    \n    # Define objective functions\n    def rastrigin(x, A=10):\n        d = len(x)\n        return A * d + np.sum(x**2 - A * np.cos(2 * np.pi * x))\n\n    def ackley(x, a=20, b=0.2, c=2*np.pi):\n        d = len(x)\n        sum_sq_term = -b * np.sqrt(np.sum(x**2) / d)\n        sum_cos_term = np.sum(np.cos(c * x)) / d\n        return -a * np.exp(sum_sq_term) - np.exp(sum_cos_term) + a + np.e\n\n    # Define test cases as a list of dictionaries\n    test_cases = [\n        {\n            \"name\": \"Case 1\",\n            \"function\": rastrigin,\n            \"d\": 5,\n            \"bounds\": (-5.12, 5.12),\n            \"Np\": 40,\n            \"G_max\": 300,\n            \"F_base\": 0.5, \"CR_base\": 0.9,\n            \"F_explore\": 0.95, \"CR_explore\": 0.2,\n            \"S\": 25,\n            \"g_explore\": 10,\n            \"bounce_back\": True,\n            \"seed\": 42,\n        },\n        {\n            \"name\": \"Case 2\",\n            \"function\": ackley,\n            \"d\": 5,\n            \"bounds\": (-32.768, 32.768),\n            \"Np\": 30,\n            \"G_max\": 400,\n            \"F_base\": 0.7, \"CR_base\": 0.6,\n            \"F_explore\": 1.0, \"CR_explore\": 0.1,\n            \"S\": 40,\n            \"g_explore\": 15,\n            \"bounce_back\": True,\n            \"seed\": 123,\n        },\n        {\n            \"name\": \"Case 3\",\n            \"function\": rastrigin,\n            \"d\": 2,\n            \"bounds\": (-5.12, 5.12),\n            \"Np\": 10,\n            \"G_max\": 200,\n            \"F_base\": 0.5, \"CR_base\": 0.9,\n            \"F_explore\": 1.2, \"CR_explore\": 0.1,\n            \"S\": 5,\n            \"g_explore\": 8,\n            \"bounce_back\": True,\n            \"seed\": 7,\n        },\n        {\n            \"name\": \"Case 4\",\n            \"function\": ackley,\n            \"d\": 5,\n            \"bounds\": (-32.768, 32.768),\n            \"Np\": 30,\n            \"G_max\": 400,\n            \"F_base\": 0.7, \"CR_base\": 0.6,\n            \"F_explore\": 1.0, \"CR_explore\": 0.1,\n            \"S\": 40,\n            \"g_explore\": 15,\n            \"bounce_back\": False, # Use clipping\n            \"seed\": 123,\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        final_best_val = run_de(case)\n        results.append(f\"{final_best_val:.12f}\")\n\n    print(f\"[{','.join(results)}]\")\n\ndef run_de(params):\n    \"\"\"\n    Executes the Differential Evolution algorithm for a single test case.\n    \"\"\"\n    # Unpack parameters\n    obj_func = params[\"function\"]\n    d = params[\"d\"]\n    L, U = params[\"bounds\"]\n    bounds = np.array([L, U] * d).reshape(d, 2)\n    Np = params[\"Np\"]\n    G_max = params[\"G_max\"]\n    F_base, CR_base = params[\"F_base\"], params[\"CR_base\"]\n    F_explore, CR_explore = params[\"F_explore\"], params[\"CR_explore\"]\n    S = params[\"S\"]\n    g_explore = params[\"g_explore\"]\n    use_bounce_back = params[\"bounce_back\"]\n    seed = params[\"seed\"]\n    epsilon = 1e-12\n\n    # Initialize random number generator for reproducibility\n    rng = np.random.default_rng(seed)\n\n    # 1. Initialization\n    population = rng.uniform(L, U, size=(Np, d))\n    fitness = np.array([obj_func(ind) for ind in population])\n    \n    # Restart schedule state variables\n    stagnation_streak = 0\n    exploratory_counter = 0\n    F, CR = F_base, CR_base\n    best_obj_val = np.min(fitness)\n\n    population_indices = list(range(Np))\n\n    # 2. Main generational loop\n    for _ in range(G_max):\n        new_population = population.copy()\n        new_fitness = fitness.copy()\n\n        for i in range(Np):\n            # 3. Mutation (DE/rand/1)\n            choices = population_indices[:i] + population_indices[i+1:]\n            r1, r2, r3 = rng.choice(choices, size=3, replace=False)\n            \n            x_r1 = population[r1]\n            x_r2 = population[r2]\n            x_r3 = population[r3]\n\n            donor_vector = x_r1 + F * (x_r2 - x_r3)\n\n            # 4. Crossover (Binomial)\n            target_vector = population[i]\n            trial_vector = target_vector.copy()\n            \n            rand_vals = rng.random(size=d)\n            j_rand = rng.integers(0, d)\n            \n            crossover_mask = (rand_vals = CR) | (np.arange(d) == j_rand)\n            trial_vector[crossover_mask] = donor_vector[crossover_mask]\n            \n            # 5. Boundary Handling\n            if use_bounce_back:\n                # Iterative bounce-back\n                for j in range(d):\n                    while trial_vector[j]  bounds[j, 0] or trial_vector[j] > bounds[j, 1]:\n                        if trial_vector[j]  bounds[j, 0]:\n                            trial_vector[j] = 2 * bounds[j, 0] - trial_vector[j]\n                        if trial_vector[j] > bounds[j, 1]:\n                            trial_vector[j] = 2 * bounds[j, 1] - trial_vector[j]\n            else:\n                # Clipping\n                np.clip(trial_vector, bounds[:, 0], bounds[:, 1], out=trial_vector)\n\n            # 6. Selection (Greedy)\n            trial_fitness = obj_func(trial_vector)\n            if trial_fitness = fitness[i]:\n                new_population[i] = trial_vector\n                new_fitness[i] = trial_fitness\n        \n        population = new_population\n        fitness = new_fitness\n\n        # 7. Restart Schedule Logic\n        current_best_gen_val = np.min(fitness)\n        \n        if current_best_gen_val  best_obj_val - epsilon:\n            stagnation_streak = 0\n        else:\n            stagnation_streak += 1\n        \n        best_obj_val = min(best_obj_val, current_best_gen_val)\n        \n        # Manage state for the *next* generation's parameters\n        if exploratory_counter > 0:\n            exploratory_counter -= 1\n            if exploratory_counter == 0:\n                F, CR = F_base, CR_base\n        \n        if stagnation_streak >= S:\n            F, CR = F_explore, CR_explore\n            exploratory_counter = g_explore\n            stagnation_streak = 0\n\n    return np.min(fitness)\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3120583"}, {"introduction": "一个好的开端是成功的一半，这句格言在优化算法中同样适用。种群的初始质量可以直接影响差异演化算法的收敛速度和求解质量。这项练习将介绍一种名为“对立学习”（Opposition-Based Learning, OBL）的智能初始化策略，它通过在搜索空间中生成与随机点“相对”的点，来增加找到更优初始解的几率。你将亲手实现并对比标准均匀采样与基于对立的初始化方法，从而直观地理解 OBL 在不同搜索空间对称性下的优势与局限。[@problem_id:3120621]", "problem": "你需要实现并比较两种初始化策略，这两种策略可用于热启动一个差分进化算法，以在一个超矩形域上最小化函数 $f(\\mathbf{x}) = \\|\\mathbf{x}\\|^2$。你的比较必须在固定的、有限的目标函数评估预算下进行。\n\n从以下基本概念开始：\n- 向量 $\\mathbf{x} \\in \\mathbb{R}^d$ 的欧几里得范数定义为 $\\|\\mathbf{x}\\| = \\sqrt{\\sum_{i=1}^d x_i^2}$。因此，目标函数 $f(\\mathbf{x}) = \\|\\mathbf{x}\\|^2$ 为 $f(\\mathbf{x}) = \\sum_{i=1}^d x_i^2$，当 $\\mathbf{0}$ 位于定义域内时，它在 $\\mathbf{x}=\\mathbf{0}$ 处达到其全局最小值 $0$。\n- 超矩形域由分量级边界 $\\mathbf{l} \\le \\mathbf{x} \\le \\mathbf{u}$ 描述，其中 $\\mathbf{l} = (l,\\dots,l)$ 和 $\\mathbf{u} = (u,\\dots,u)$ 为标量边界 $l  u$。\n- 对立学习 (Opposition-Based Learning, OBL) 将 $\\mathbf{x}$ 关于边界 $\\mathbf{l}$ 和 $\\mathbf{u}$ 的逐点对立点定义为 $\\tilde{\\mathbf{x}}$，其分量为 $\\tilde{x}_i = l_i + u_i - x_i$。当 $l=-u$ 时，这是通过原点的反射，即 $\\tilde{\\mathbf{x}} = -\\mathbf{x}$。\n\n你的任务：\n- 在固定的评估预算 $M$ 下实现两种热启动采样策略：\n  1. 纯均匀采样 (Pure Uniform Sampling, URS)：从 $[l,u]^d$ 中均匀抽取 $M$ 个独立样本 $\\mathbf{x}^{(1)},\\dots,\\mathbf{x}^{(M)}$，对它们全部评估 $f$ 函数，并将热启动质量定义为 $q_{\\mathrm{URS}}=\\min_{1\\le k\\le M} f(\\mathbf{x}^{(k)})$。\n  2. 使用对立学习 (OBL) 的基于对立的初始化 (Opposition-Based Initialization, OBI)：从 $[l,u]^d$ 中均匀抽取 $M/2$ 个独立基点 $\\mathbf{x}^{(1)},\\dots,\\mathbf{x}^{(M/2)}$，通过 $\\tilde{x}^{(k)}_i = l_i + u_i - x^{(k)}_i$ 构建它们的逐点对立点 $\\tilde{\\mathbf{x}}^{(k)}$，对每个基点及其对立点都评估 $f$ 函数，并将热启动质量定义为 $q_{\\mathrm{OBI}}=\\min\\{ f(\\mathbf{x}^{(k)}), f(\\tilde{\\mathbf{x}}^{(k)}) : 1\\le k\\le M/2 \\}$。假设 $M$ 为偶数，因此 $M/2$ 是整数。\n- 对于每种策略，确保精确计算 $M$ 次函数评估，以便在有限的评估预算下进行公平比较。\n\n比较指标：\n- 对于每个测试用例，计算标量 $c = q_{\\mathrm{URS}} - q_{\\mathrm{OBI}}$。$c$ 的正值表示基于对立的初始化在相同预算下提供了严格更优（更小）的热启动目标值。\n\n实现细节：\n- 使用来自 $[l,u]^d$ 上均匀分布的独立同分布 (i.i.d.) 采样。\n- 所有计算必须以双精度浮点数进行。\n- 必须通过伪随机种子控制随机性，以使结果可以精确复现。\n\n测试套件：\n- 在以下五个测试用例上评估你的实现，每个用例指定为元组 $(d,l,u,M,s)$：\n  1. $(d,l,u,M,s) = (2, -5.0, 5.0, 100, 42)$。\n  2. $(d,l,u,M,s) = (10, -1.0, 1.0, 200, 7)$。\n  3. $(d,l,u,M,s) = (30, -100.0, 100.0, 60, 123)$。\n  4. $(d,l,u,M,s) = (5, 0.0, 1.0, 10, 999)$。\n  5. $(d,l,u,M,s) = (1, -10.0, 10.0, 2, 2024)$。\n\n最终输出要求：\n- 你的程序必须输出单行，其中包含一个 Python 风格的列表，该列表包含上述测试用例的五个标量 $c$，顺序与列表顺序相同，每个值使用标准四舍五入规则精确到六位小数。例如：\"[0.123456,-0.000001,0.500000,0.000000,1.234568]\"。\n- 角度和物理单位不适用。所有输出都是无单位的实数。\n\n科学真实性和约束：\n- 确保实现严格遵循上述定义，并按规定计算目标函数评估次数。\n- 不要在程序输出中提供任何额外的注释或诊断信息。", "solution": "我们使用优化和概率论的核心定义来形式化此比较。目标函数为 $f(\\mathbf{x}) = \\|\\mathbf{x}\\|^2 = \\sum_{i=1}^d x_i^2$，这是一个严格凸的、径向对称的函数，当可行时，在 $\\mathbf{0}$ 处取得最小值。定义域是超矩形 $[l,u]^d$，其中 $l  u$。热启动的目标是为后续的优化算法（如差分进化）提供具有低目标值的初始点，但这里我们仅关注在受限的目标函数评估预算下的初始化阶段。\n\n两种策略是：\n\n- 纯均匀采样 (URS)：从 $[l,u]^d$ 上的均匀分布中抽取 $M$ 个独立同分布样本，并取找到的最佳目标值。这恰好使用 $M$ 次评估。因为样本是独立的，所以 $M$ 个独立同分布抽样的最小值倾向于随着 $M$ 的增长而减小。\n\n- 使用对立学习 (OBL) 的基于对立的初始化 (OBI)：对于每个均匀抽取的基点 $\\mathbf{x}^{(k)}$，构造其逐点对立点 $\\tilde{\\mathbf{x}}^{(k)}$，由 $\\tilde{x}^{(k)}_i = l_i + u_i - x^{(k)}_i$ 给出。这种反射是关于每个坐标区间的中点 $\\frac{l_i + u_i}{2}$。通过抽取 $M/2$ 个基点并评估每个基点及其对立点来强制执行预算，总共进行 $M$ 次函数评估。这 $M$ 次评估中的最佳目标值即为热启动质量。\n\n正确性与公平性：\n- 两种策略都恰好消耗 $M$ 次评估，确保了公平的比较。\n- OBL 映射保持可行性：如果 $x^{(k)}_i \\in [l_i,u_i]$，那么 $\\tilde{x}^{(k)}_i = l_i + u_i - x^{(k)}_i \\in [l_i,u_i]$。\n\n基于目标函数结构的定性分析：\n- 当定义域关于原点对称时，即 $l = -u$，对立映射简化为 $\\tilde{\\mathbf{x}} = -\\mathbf{x}$。因为 $f(\\mathbf{x}) = \\|\\mathbf{x}\\|^2 = \\|-\\mathbf{x}\\|^2$，每个评估对 $(\\mathbf{x}, -\\mathbf{x})$ 产生相同的目标值。在固定的预算 $M$ 下，OBI 产生 $M/2$ 个不同的基点位置（重复仅通过对称性产生），但对两种符号都进行评估；相比之下，URS 产生 $M$ 个独立的抽样。因此，当 $l=-u$ 时，OBI 中每对的最佳值与其中任一元素相同，每对没有提供改进，同时将独立位置的总数减少了 2 倍。因此，$M$ 个独立 URS 抽样的最小值可能小于 OBI 中 $M/2$ 个独立基点抽样的最小值，导致 $c = q_{\\mathrm{URS}} - q_{\\mathrm{OBI}}$ 平均为非正或负值。\n\n- 当定义域相对于最小化点不对称时，例如 $[0,1]^d$，其中最小化点 $\\mathbf{0}$ 位于下边界上，对立映射 $\\tilde{x}_i = 1 - x_i$ 将 $x_i$ 关于 $0.5$ 反射。对于接近 $1$ 的 $x_i$，其对立点会更接近 $0$；因此 $f(\\tilde{\\mathbf{x}})$ 可能显著小于 $f(\\mathbf{x})$。在这种情况下，同时评估 $\\mathbf{x}$ 和 $\\tilde{\\mathbf{x}}$ 增加了这对中至少有一个更接近最小化点的机会。尽管 OBI 仅评估 $M/2$ 个基点，但在相同的预算 $M$ 下，“对中取优”效应可能产生比 URS 更小的最小值，可能产生正的 $c$。\n\n算法设计：\n1. 对于给定的 $(d,l,u,M,s)$ 的 URS：\n   - 使用种子 $s$ 初始化一个伪随机数生成器。\n   - 抽取一个包含 $M$ 个向量的数组，其分量从 $[l,u]$ 上的均匀分布中独立同分布采样。\n   - 对每个向量计算 $f$ 函数，即其分量的平方和。\n   - 将 $q_{\\mathrm{URS}}$ 记录为这 $M$ 个值中的最小值。\n\n2. 对于相同的 $(d,l,u,M,s)$ 的 OBI：\n   - 使用相同的种子 $s$ 初始化一个独立的伪随机数生成器，以确保在每个测试用例中进行公平且可复现的比较，同时通过分开抽样或使用不同流来保持策略间样本的独立性。为每个策略自己的生成器使用相同的种子确保了可复现性，并且因为我们根据指定的分布进行抽样，策略间的任何相关性都不会影响每个策略分布的正确性。\n   - 从 $[l,u]^d$ 中均匀抽取 $M/2$ 个基向量。\n   - 通过 $\\tilde{x}_i = l + u - x_i$ 计算它们的对立点 $\\tilde{\\mathbf{x}}$。\n   - 对两组点都评估 $f$ 函数，并将 $q_{\\mathrm{OBI}}$ 作为这 $M$ 个目标值中的最小值。\n\n3. 计算 $c = q_{\\mathrm{URS}} - q_{\\mathrm{OBI}}$。\n\n测试套件中的边界情况：\n- $(1, -10.0, 10.0, 2, 2024)$ 是一个边界情况，具有最小的偶数预算和一维空间。当 $l = -u$ 时，OBI 评估一对具有相等目标值的 $(x,-x)$，而 URS 评估两个独立同分布的抽样；由于独立性，比较可能略微有利于 URS。\n- 具有宽边界和有限预算的更高维度 $(30, -100.0, 100.0, 60, 123)$ 测试了高维度的影响，此时与原点的典型距离更大，策略之间的差异更多地由样本数量驱动，而不是每对的对立优势。\n- 不对称情况 $(5, 0.0, 1.0, 10, 999)$ 可以展示 OBI 的优势，因为关于中点的反射可以将点移近位于原点的最小化点。\n\n输出：\n- 对五个测试用例中的每一个，计算 $c$ 并四舍五入到六位小数。\n- 输出单行，其中包含一个 Python 风格的列表，按顺序列出这五个值。不得打印任何额外文本。\n\n这种方法遵循了目标函数、定义域和对立学习的核心定义，并确保了在有限评估预算下的比较是原则性的和可复现的。采样的随机性由固定的种子完全控制，保证了每次运行的输出完全相同。结论与 $f(\\mathbf{x}) = \\|\\mathbf{x}\\|^2$ 的几何特性以及定义域边界的对称性或不对称性相符。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef f_obj(x: np.ndarray) - np.ndarray:\n    # Computes f(x) = ||x||^2 for a batch of points (rows of x)\n    # Returns a 1D array of objective values.\n    return np.sum(x * x, axis=1)\n\ndef uniform_best_min(d: int, l: float, u: float, M: int, seed: int) - float:\n    rng = np.random.default_rng(seed)\n    # Sample M points uniformly in [l,u]^d\n    X = rng.uniform(l, u, size=(M, d))\n    vals = f_obj(X)\n    return float(np.min(vals))\n\ndef opposition_best_min(d: int, l: float, u: float, M: int, seed: int) - float:\n    assert M % 2 == 0, \"M must be even for opposition-based evaluation budget.\"\n    rng = np.random.default_rng(seed)\n    base_count = M // 2\n    X = rng.uniform(l, u, size=(base_count, d))\n    X_opp = (l + u) - X\n    vals_base = f_obj(X)\n    vals_opp = f_obj(X_opp)\n    # Combine both sets of evaluations (total M evaluations)\n    min_val = float(np.min(np.concatenate([vals_base, vals_opp], axis=0)))\n    return min_val\n\ndef run_case(d: int, l: float, u: float, M: int, seed: int) - float:\n    q_urs = uniform_best_min(d, l, u, M, seed)\n    q_obi = opposition_best_min(d, l, u, M, seed)\n    return q_urs - q_obi  # Positive means OBI better\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case is (d, l, u, M, seed)\n    test_cases = [\n        (2, -5.0, 5.0, 100, 42),\n        (10, -1.0, 1.0, 200, 7),\n        (30, -100.0, 100.0, 60, 123),\n        (5, 0.0, 1.0, 10, 999),\n        (1, -10.0, 10.0, 2, 2024),\n    ]\n\n    results = []\n    for d, l, u, M, seed in test_cases:\n        c = run_case(d, l, u, M, seed)\n        results.append(c)\n\n    # Round to exactly six decimal places and format as required.\n    formatted = \"[\" + \",\".join(f\"{v:.6f}\" for v in results) + \"]\"\n    print(formatted)\n\nsolve()\n```", "id": "3120621"}, {"introduction": "差异演化算法本质上是为连续优化问题设计的，然而许多工程和科学领域的挑战却是离散的。这项练习将带你探索一种强大的技术，即将连续优化器应用于离散问题。你将通过求解一个连续松弛问题，然后将得到的连续解映射回整数域，来解决一个整数规划问题。这个过程不仅展示了差异演化算法的灵活性，也让你掌握了处理混合整数或纯整数优化问题的一种实用方法论。[@problem_id:3120707]", "problem": "考虑在边界约束下对整数向量 $\\mathbf{k}\\in\\mathbb{Z}^n$ 进行离散优化。设目标函数为 $f(\\mathbf{k})=\\sum_{i=1}^n \\lvert k_i - 3\\rvert$，其中每个坐标 $k_i$ 都受 $\\ell_i \\le k_i \\le u_i$ 的约束，且 $\\ell_i,u_i\\in\\mathbb{Z}$ 和 $\\ell_i \\le u_i$。您将使用一个连续代理来近似该离散问题，然后将连续解映射回整数域。具体来说，定义连续代理 $g(\\mathbf{x})=\\sum_{i=1}^n \\lvert x_i - 3\\rvert$，其中 $\\mathbf{x}\\in\\mathbb{R}^n$ 且具有箱式约束 $\\ell_i \\le x_i \\le u_i$。在 $\\mathbb{R}^n$ 上使用差分进化 (DE) 算法，在箱式约束下最小化 $g(\\mathbf{x})$，以获得一个连续最优解 $\\mathbf{x}^\\star$。通过将每个坐标取整到最近的整数（平局向上取整）来将 $\\mathbf{x}^\\star$ 映射到整数域，即对于每个 $i$，计算 $k^{\\mathrm{DE}}_i = \\min\\big(\\max\\big(\\lfloor x_i^\\star + 0.5 \\rfloor,\\ell_i\\big),u_i\\big)$ 以强制可行性。然后计算离散目标 $f(\\mathbf{k}^{\\mathrm{DE}})$。独立地，计算精确的离散最优值 $f(\\mathbf{k}^\\star)$，其中 $\\mathbf{k}^\\star\\in\\mathbb{Z}^n$ 在相同边界下最小化 $f(\\mathbf{k})$。将给定实例的舍入偏差定义为 $b = f(\\mathbf{k}^{\\mathrm{DE}}) - f(\\mathbf{k}^\\star)$。您的任务是实现一个程序，对每个指定的测试用例执行所述步骤，并返回舍入偏差 $b$ 作为浮点数。\n\n使用以下边界约束实例的测试套件，表示为为每个坐标定义箱式范围的 $(\\ell_i,u_i)$ 对列表：\n- 测试用例 $1$：$n=5$，对于所有 $i\\in\\{1,2,3,4,5\\}$，边界为 $(\\ell_i,u_i)=(0,10)$。\n- 测试用例 $2$：$n=4$，对于所有 $i\\in\\{1,2,3,4\\}$，边界为 $(\\ell_i,u_i)=(4,8)$。\n- 测试用例 $3$：$n=3$，边界为 $(\\ell_1,u_1)=(2,2)$、$(\\ell_2,u_2)=(3,3)$、$(\\ell_3,u_3)=(5,5)$。\n- 测试用例 $4$：$n=6$，边界为 $(\\ell_1,u_1)=(0,5)$、$(\\ell_2,u_2)=(1,1)$、$(\\ell_3,u_3)=(10,10)$、$(\\ell_4,u_4)=(2,7)$、$(\\ell_5,u_5)=(4,4)$、$(\\ell_6,u_6)=(3,9)$。\n\n程序应在给定边界上对连续代理 $g(\\mathbf{x})$ 使用差分进化 (DE) 算法，然后应用上述的舍入和钳位规则以获得 $\\mathbf{k}^{\\mathrm{DE}}$ 并计算 $f(\\mathbf{k}^{\\mathrm{DE}})$。它还必须精确计算真实的离散最优值 $f(\\mathbf{k}^\\star)$。对于每个测试用例，输出如上定义的舍入偏差 $b$。\n\n最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，每个测试用例一个条目，按测试用例 1 到 4 的顺序排列为 $[b_1,b_2,b_3,b_4]$。此问题不涉及物理单位或角度，所有输出均为实数（浮点数）。", "solution": "用户提供的问题陈述经过严格分析并被认为是有效的。这是一个数值优化领域的适定问题，具有科学依据且形式上明确。\n\n该问题要求为离散优化问题的几个实例计算一个“舍入偏差”（表示为 $b$）。该偏差定义为通过启发式方法获得的目标函数值与精确最优解的值之间的差值。该启发式方法涉及求解问题的连续松弛，然后将解舍入回整数域。\n\n让我们将所需的计算分解为一个系统化的、分步的过程。\n\n### 1. 离散优化问题\n\n核心任务是对于一个整数向量 $\\mathbf{k} = (k_1, k_2, \\ldots, k_n) \\in \\mathbb{Z}^n$ 最小化目标函数 $f(\\mathbf{k}) = \\sum_{i=1}^n \\lvert k_i - 3\\rvert$。搜索空间受每个坐标的一组下界和上界约束：$\\ell_i \\le k_i \\le u_i$，其中 $\\ell_i, u_i \\in \\mathbb{Z}$。\n\n### 2. 寻找精确的离散最优解, $f(\\mathbf{k}^\\star)$\n\n目标函数 $f(\\mathbf{k})$ 是可分的，意味着它可以表示为单个变量函数的总和：$f(\\mathbf{k}) = \\sum_{i=1}^n f_i(k_i)$，其中 $f_i(k_i) = \\lvert k_i - 3\\rvert$。为了最小化这个和，我们可以独立地在各自的域 $[\\ell_i, u_i]$ 上最小化每一项 $f_i(k_i)$。\n\n函数 $f_i(k_i) = \\lvert k_i - 3\\rvert$ 衡量 $k_i$ 到值 $3$ 的距离。当 $k_i$ 是区间 $[\\ell_i, u_i]$ 中最接近 $3$ 的整数时，达到最小值。设这个最优整数为 $k_i^\\star$。\n\n我们可以如下确定 $k_i^\\star$：\n- 如果值 $3$ 在区间 $[\\ell_i, u_i]$ 内，即 $\\ell_i \\le 3 \\le u_i$，那么最接近的整数就是 $3$ 本身。所以，$k_i^\\star = 3$。\n- 如果 $3  \\ell_i$，那么区间内所有整数都大于 $3$。最接近 $3$ 的是最小的那个，即 $\\ell_i$。所以，$k_i^\\star = \\ell_i$。\n- 如果 $3  u_i$，那么区间内所有整数都小于 $3$。最接近 $3$ 的是最大的那个，即 $u_i$。所以，$k_i^\\star = u_i$。\n\n这个逻辑可以用一个裁剪操作来紧凑地表示。由于 $\\ell_i$ 和 $u_i$ 是整数，第 $i$ 个坐标的最优离散值 $k_i^\\star$ 是通过将目标值 $3$ 钳位到区间 $[\\ell_i, u_i]$ 给出的：\n$$k_i^\\star = \\max(\\ell_i, \\min(u_i, 3))$$\n精确的最优整数向量是 $\\mathbf{k}^\\star = (k_1^\\star, k_2^\\star, \\ldots, k_n^\\star)$。那么最小目标值为：\n$$f(\\mathbf{k}^\\star) = \\sum_{i=1}^n \\lvert k_i^\\star - 3\\rvert$$\n\n### 3. 连续松弛与舍入启发式\n\n该问题指定了一种启发式方法来寻找近似的整数解。\n\n**步骤 3a：连续代理问题**\n通过允许变量为实数，离散问题被松弛为连续问题。代理目标函数为 $g(\\mathbf{x}) = \\sum_{i=1}^n \\lvert x_i - 3\\rvert$，其中 $\\mathbf{x} = (x_1, x_2, \\ldots, x_n) \\in \\mathbb{R}^n$ 受相同的箱式约束 $\\ell_i \\le x_i \\le u_i$。\n\n与离散情况类似，这个连续、可分函数的最小值出现在每个 $x_i$ 是 $[\\ell_i, u_i]$ 中最接近 $3$ 的实数时。这给出了精确的连续最优解 $\\mathbf{x}^\\star$，其坐标为：\n$$x_i^\\star = \\max(\\ell_i, \\min(u_i, 3))$$\n值得注意的是，由于 $\\ell_i$ 和 $u_i$ 是整数，真实连续最优解的坐标 $x_i^\\star$ 本身就是整数，事实上，$\\mathbf{x}^\\star = \\mathbf{k}^\\star$。\n\n**步骤 3b：使用差分进化 (DE) 进行数值优化**\n问题强制要求使用差分进化 (DE) 算法来寻找连续最优解。DE 是一种随机的、基于种群的优化器。对于像 $g(\\mathbf{x})$ 这样的简单凸函数，DE 预期会找到一个解向量 $\\mathbf{x}^{\\mathrm{DE}}$，它是真实最优解 $\\mathbf{x}^\\star$ 的一个非常接近的浮点近似。\n\n**步骤 3c：舍入和钳位**\n将数值上获得的连续解 $\\mathbf{x}^{\\mathrm{DE}}$ 映射回整数域，以获得一个近似的整数解 $\\mathbf{k}^{\\mathrm{DE}}$。每个坐标的规则是：\n$$k^{\\mathrm{DE}}_i = \\min\\big(\\max\\big(\\lfloor x^{\\mathrm{DE}}_i + 0.5 \\rfloor,\\ell_i\\big),u_i\\big)$$\n操作 $\\lfloor z + 0.5 \\rfloor$ 对应于将 $z$ 取整到最近的整数，其中平局情况（例如 $2.5$）向上取整。外围的 $\\min$ 和 $\\max$ 函数确保最终的整数 $k^{\\mathrm{DE}}_i$ 位于可行范围 $[\\ell_i, u_i]$ 内。\n\n**步骤 3d：评估启发式解**\n然后在这个新的整数向量 $\\mathbf{k}^{\\mathrm{DE}}$ 上评估目标函数：\n$$f(\\mathbf{k}^{\\mathrm{DE}}) = \\sum_{i=1}^n \\lvert k_i^{\\mathrm{DE}} - 3\\rvert$$\n\n### 4. 计算舍入偏差\n\n最后一步是计算舍入偏差 $b$，定义为启发式解的目标值与精确最优值之间的差：\n$$b = f(\\mathbf{k}^{\\mathrm{DE}}) - f(\\mathbf{k}^\\star)$$\n\n### 预期结果\n由于真实的连续最优解 $\\mathbf{x}^\\star$ 与真实的离散最优解 $\\mathbf{k}^\\star$ 相同，并且 DE 预期会找到一个非常精确的近似解 $\\mathbf{x}^{\\mathrm{DE}} \\approx \\mathbf{x}^\\star$，因此舍入步骤极有可能恢复出精确的整数解。也就是说，对于每个坐标 $i$，预期误差 $|x^{\\mathrm{DE}}_i - x_i^\\star|$ 将远小于 $0.5$，从而导致 $\\lfloor x^{\\mathrm{DE}}_i + 0.5 \\rfloor = x_i^\\star = k_i^\\star$。在钳位之后（由于 $k_i^\\star$ 已经在边界内，所以钳位没有效果），我们会发现 $\\mathbf{k}^{\\mathrm{DE}} = \\mathbf{k}^\\star$。这意味着 $f(\\mathbf{k}^{\\mathrm{DE}}) = f(\\mathbf{k}^\\star)$，因此舍入偏差 $b = 0$。该实现将为每个测试用例通过计算验证这一点。\n\n所提供的 Python 代码将为每个测试用例忠实地执行这些步骤，包括运行 DE 优化。DE 将使用一个固定的随机种子以确保可复现性。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import differential_evolution\n\ndef solve():\n    \"\"\"\n    Solves the optimization problem for all test cases and prints the rounding bias.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1: n=5, bounds (0,10) for all i\n        [(0, 10)] * 5,\n        # Test case 2: n=4, bounds (4,8) for all i\n        [(4, 8)] * 4,\n        # Test case 3: n=3, bounds (2,2), (3,3), (5,5)\n        [(2, 2), (3, 3), (5, 5)],\n        # Test case 4: n=6, bounds (0,5), (1,1), (10,10), (2,7), (4,4), (3,9)\n        [(0, 5), (1, 1), (10, 10), (2, 7), (4, 4), (3, 9)],\n    ]\n\n    results = []\n    # Use a fixed seed for the stochastic DE algorithm for reproducibility.\n    RANDOM_SEED = 42\n    \n    # The target value for the objective function.\n    TARGET_VALUE = 3\n\n    for bounds in test_cases:\n        # Extract lower and upper bounds as numpy arrays for vectorized operations.\n        lower_bounds = np.array([b[0] for b in bounds])\n        upper_bounds = np.array([b[1] for b in bounds])\n\n        # 1. Compute the exact discrete optimum f(k*)\n        # The optimal integer k_i* is the integer in [l_i, u_i] closest to 3.\n        # This is equivalent to clipping the target value 3 to the integer interval.\n        k_star = np.clip(TARGET_VALUE, lower_bounds, upper_bounds)\n        f_k_star = np.sum(np.abs(k_star - TARGET_VALUE))\n\n        # 2. Minimize the continuous surrogate g(x) using Differential Evolution\n        # Define the continuous objective function g(x).\n        def g(x):\n            return np.sum(np.abs(x - TARGET_VALUE))\n\n        # Run the DE optimization.\n        de_result = differential_evolution(\n            g, \n            bounds, \n            seed=RANDOM_SEED\n        )\n        x_star_de = de_result.x\n\n        # 3. Map the continuous solution x* back to the integer domain\n        # The rule is to round to the nearest integer (ties round up), then clamp.\n        # floor(x + 0.5) implements this rounding rule.\n        k_de_rounded = np.floor(x_star_de + 0.5)\n        \n        # Clamp the rounded vector to ensure it is within the feasible integer domain.\n        k_de = np.clip(k_de_rounded, lower_bounds, upper_bounds)\n\n        # Compute the objective value for the DE-based integer solution.\n        f_k_de = np.sum(np.abs(k_de - TARGET_VALUE))\n\n        # 4. Compute the rounding bias b\n        bias = f_k_de - f_k_star\n        results.append(float(bias))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3120707"}]}