{"hands_on_practices": [{"introduction": "我们如何将一个现实世界的问题，比如寻找一个函数的最小值，转换成遗传算法可以理解的二进制语言？这就是编码（encoding）的作用。编码的选择并非无关紧要，它直接塑造了算法所探索的“搜索景观”。一个好的编码方案能确保基因型上的微小变化对应解决方案的微小变化（即局部性原理），从而帮助遗传算法更有效地搜寻最优解。这项实践 [@problem_id:3132789] 让你直接比较两种常见的编码方式：标准二进制编码和格雷码。通过亲手实现并分析它们对搜索过程的影响，你将深刻理解为何表示法是应用遗传算法解决连续优化问题的关键第一步。", "problem": "您需要编写一个完整、可运行的程序，用于在优化球函数时，比较遗传算法（Genetic Algorithm, GA）中使用的两种基因型编码：标准二进制编码和格雷码。目标函数为球函数 $f(\\mathbf{x}) = \\sum_{i=1}^{n} x_i^2$，定义在一个有界超矩形 $[L, U]^n$ 上，其中 $L < 0 < U$。每个决策变量 $x_i$ 由 $b$ 个比特表示，并通过均匀线性量化解码为一个实数值。\n\n使用的基本原理和定义：\n- 球函数 $f(\\mathbf{x}) = \\sum_{i=1}^{n} x_i^2$ 按坐标是可分离的。\n- 基因型到表现型的映射是一个线性量化器：对于每个坐标，一个 $b$ 比特的码字表示一个整数 $k \\in \\{0,1,\\dots,2^b - 1\\}$，该整数映射到一个实数值 $x = L + \\dfrac{U - L}{2^b - 1}\\,k$。这在每个坐标上形成一个包含端点 $L$ 和 $U$ 在内的 $2^b$ 个点的均匀网格。\n- 对于二进制编码，码字是 $k$ 的标准二进制表示。对于格雷码，码字是 $k$ 的格雷编码，解码时先应用格雷码到二进制的转换来恢复整数 $k$，然后再进行到 $x$ 的线性映射。\n- 单比特突变定义为在所有 $nb$ 个基因型比特中，随机均匀地选择一个比特并将其翻转。\n\n为每个测试用例计算并报告以下内容：\n1) 离散化误差。将离散化误差定义为：由所选 $b$ 产生的离散网格上 $f(\\mathbf{x})$ 可达到的最小值（两种编码均可，因为它们产生相同的表现型网格点集）与 $f(\\mathbf{x})$ 在 $[L, U]^n$ 上的连续最优值之差。您必须精确计算此值，而不是通过采样。\n2) 通过单步改进概率衡量的搜索偏好。将一种编码的单步改进概率 $P_{\\mathrm{improve}}$ 定义为：在基因型服从均匀分布且在 $nb$ 个比特位置中均匀选择的条件下，单比特翻转严格减小 $f(\\mathbf{x})$ 值的概率。您必须通过枚举精确计算此概率，而不是通过模拟。形式上，\n$$\nP_{\\mathrm{improve}} = \\frac{1}{(2^b)^n \\cdot nb} \\sum_{\\text{genotypes } g} \\sum_{p=1}^{nb} \\mathbf{1}\\big(f(g^{(p)}) < f(g)\\big),\n$$\n其中 $g^{(p)}$ 是 $g$ 翻转第 $p$ 个比特后的基因型，$\\mathbf{1}(\\cdot)$ 是指示函数。利用 $f$ 的可分离性以及比特翻转仅影响一个坐标的事实，将此问题简化为对单个 $b$ 比特坐标的等效精确枚举。\n\n您的程序必须：\n- 对任何整数 $b \\ge 1$，精确实现二进制和格雷码两种编码。\n- 使用精确逻辑而非浮点数比较来测试比特翻转是否改善了单个坐标的贡献 $x^2$。具体方法是观察到，对于对称边界 $L = -U$ 和步长为 $\\Delta = \\dfrac{U - L}{2^b - 1}$ 的均匀量化，每个坐标的值等于 $x = \\Delta\\,(k - m)$，其中 $m = \\dfrac{2^b - 1}{2}$。因此，当且仅当 $\\lvert k' - m \\rvert < \\lvert k - m \\rvert$ 时，一次翻转会改善目标函数，这等价于 $\\lvert 2k' - (2^b - 1) \\rvert < \\lvert 2k - (2^b - 1) \\rvert$。\n- 从第一性原理出发精确计算离散化误差，而不是通过数值搜索网格。如果 $0 \\in [L, U]$，则连续最小值为 $0$，在 $\\mathbf{x} = \\mathbf{0}$ 处取得；否则，它是每个坐标上离 $0$ 最近的边界点。\n- 对于每个测试用例，输出一个包含四个数字的列表：二进制编码下的离散化误差、格雷码下的离散化误差、二进制编码下的单步改进概率以及格雷码下的单步改进概率。所有数字必须以小数形式打印，并四舍五入到 $12$ 位小数。\n\n测试套件：\n使用以下五个测试用例，每个用例指定为一个元组 $(n, b, L, U)$，其中 $n$ 是维度，$b$ 是每个坐标的比特长度，$[L, U]$ 是边界区间：\n- $(1, 3, -1.0, 1.0)$\n- $(5, 4, -1.0, 1.0)$\n- $(10, 8, -1.0, 1.0)$\n- $(3, 1, -1.0, 1.0)$\n- $(2, 12, -1.0, 1.0)$\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含五个测试用例的结果。结果为一个长度为五的逗号分隔列表，其中每个元素本身是按上述顺序排列的四个十进制数的逗号分隔列表，每个十进制数都四舍五入到 $12$ 位小数。例如，一个有效的格式是\n$$\n[\\,[d_1^{\\text{bin}}, d_1^{\\text{gray}}, p_1^{\\text{bin}}, p_1^{\\text{gray}}],\\dots,[d_5^{\\text{bin}}, d_5^{\\text{gray}}, p_5^{\\text{bin}}, p_5^{\\text{gray}}]\\,].\n$$\n不应打印任何额外文本。", "solution": "用户提供的问题已经过分析和验证。该问题具有科学依据，定义明确，并且所有定义和约束都是自洽和一致的。任务是计算遗传算法在优化球函数时，二进制编码和格雷码两种编码的两个度量指标：离散化误差和单步改进概率。\n\n### 1. 离散化误差\n\n目标函数是球函数 $f(\\mathbf{x}) = \\sum_{i=1}^{n} x_i^2$，定义域为 $\\mathbf{x} \\in [L, U]^n$。对于所有测试用例，$L = -1.0$ 且 $U = 1.0$，因此 $L < 0 < U$。$f(\\mathbf{x})$ 的连续最小值为 $f(\\mathbf{0}) = 0$，在 $\\mathbf{x} = \\mathbf{0}$ 处取得。\n\n问题描述了一种均匀线性量化方案，其中每个坐标 $x_i$ 从一个 $b$ 比特的码字映射而来。该码字对应一个整数 $k \\in \\{0, 1, \\dots, 2^b-1\\}$，该整数又映射到一个实数值 $x_k = L + \\frac{U-L}{2^b-1}k$。每个坐标可能的实数值集合，即网格点，由 $k$ 的范围决定。\n\n二进制编码和格雷码都提供了从 $b$ 比特字符串集合到整数集合 $\\{0, 1, \\dots, 2^b-1\\}$ 的双射。因此，两种编码的可达表现型值集合（即网格点）是相同的。离散化误差定义为网格上的最小值与连续最小值之差，因此它与选择二进制编码还是格雷码无关。\n\n为了找到 $f(\\mathbf{x})$ 在网格上的最小值，我们必须为每个坐标找到最接近 $0$ 的网格点 $x_k$。使 $x_k$ 最接近 $0$ 的 $k$ 值是与实数 $k_{\\text{real}} = -L \\frac{2^b-1}{U-L}$ 最接近的整数。\n给定 $L=-1.0$ 和 $U=1.0$，这变为 $k_{\\text{real}} = -(-1.0) \\frac{2^b-1}{1.0 - (-1.0)} = \\frac{2^b-1}{2}$。\n由于 $b \\ge 1$，$2^b-1$ 始终为奇数，所以 $k_{\\text{real}}$ 永远不是整数。与 $k_{\\text{real}}$ 最接近的两个整数是 $k_1 = \\lfloor \\frac{2^b-1}{2} \\rfloor = 2^{b-1}-1$ 和 $k_2 = \\lceil \\frac{2^b-1}{2} \\rceil = 2^{b-1}$。\n对应的表现型值为：\n$x_{k_1} = -1.0 + \\frac{2.0}{2^b-1}(2^{b-1}-1) = \\frac{-(2^b-1) + 2^b-2}{2^b-1} = \\frac{-1}{2^b-1}$。\n$x_{k_2} = -1.0 + \\frac{2.0}{2^b-1}(2^{b-1}) = \\frac{-(2^b-1) + 2^b}{2^b-1} = \\frac{1}{2^b-1}$。\n一个坐标可能的最小绝对值为 $|x^*| = \\frac{1}{2^b-1}$。\n离散网格上 $f(\\mathbf{x})$ 的最小值在每个 $|x_i| = |x^*|$ 时取得，所以 $\\min_{\\text{grid}} f(\\mathbf{x}) = \\sum_{i=1}^{n} (x^*)^2 = n \\left(\\frac{1}{2^b-1}\\right)^2$。\n因此，离散化误差 $D$ 为：\n$$ D = \\min_{\\text{grid}} f(\\mathbf{x}) - \\min_{\\text{continuous}} f(\\mathbf{x}) = \\frac{n}{(2^b-1)^2} - 0 = \\frac{n}{(2^b-1)^2} $$\n这个值对于二进制编码和格雷码是相同的，所以 $D_{\\text{binary}} = D_{\\text{Gray}}$。\n\n### 2. 单步改进概率 ($P_{\\mathrm{improve}}$)\n\n单步改进概率定义为：\n$$ P_{\\mathrm{improve}} = \\frac{1}{(2^b)^n \\cdot nb} \\sum_{\\text{genotypes } g} \\sum_{p=1}^{nb} \\mathbf{1}\\big(f(g^{(p)}) < f(g)\\big) $$\n由于球函数 $f(\\mathbf{x}) = \\sum_{i=1}^n x_i^2$ 的可分离性，基因型中的单比特翻转只影响一个坐标，比如说 $x_i \\to x_i'$。改进的条件 $f(g^{(p)}) < f(g)$ 简化为 $(x_i')^2 < x_i^2$，这等价于 $|x_i'| < |x_i|$。\n总的改进移动次数可以对每个坐标独立求和。设 $S$ 为单个 $b$ 比特坐标在所有 $2^b$ 种可能状态下，导致改进的单比特翻转总数。\n$$ S = \\sum_{c \\in \\{0,1\\}^b} \\sum_{j=1}^{b} \\mathbf{1}\\big( |x'(c^{(j)})| < |x(c)| \\big) $$\n其中 $c$ 是一个 $b$ 比特的码字，$c^{(j)}$ 是 $c$ 翻转第 $j$ 个比特后的码字，$x(c)$ 是对应于 $c$ 的表现型值。\n在所有 $n$ 个坐标和所有 $(2^b)^n$ 个基因型中，总的改进移动次数为 $n \\cdot (2^b)^{n-1} \\cdot S$。\n将此代入概率公式可显著简化：\n$$ P_{\\mathrm{improve}} = \\frac{n \\cdot (2^b)^{n-1} \\cdot S}{(2^b)^n \\cdot nb} = \\frac{S}{2^b \\cdot b} $$\n这意味着我们只需要分析一个 $b$ 比特的坐标就能找到概率。$S$ 的值在二进制编码和格雷码之间会有所不同，因为从码字 $c$ 到整数 $k$（并因此到表现型值 $x$）的映射是不同的。\n\n为避免浮点数不精确的问题，我们使用建议的基于整数的比较。对于 $L=-U$，条件 $|x'| < |x|$ 等价于 $|k' - m| < |k - m|$，其中 $m = (2^b-1)/2$。这可以通过乘以 $2$ 重写为 $|2k' - (2^b-1)| < |2k - (2^b-1)|$。\n\n为每种编码计算 $S$ 的算法如下：\n1.  初始化改进移动计数器 `improvements` 为 $0$。令 $M = 2^b - 1$。\n2.  遍历每个可能的 $b$ 比特码字 $c$，表示为从 $0$ 到 $2^b-1$ 的整数。\n3.  对于每个 $c$，确定其在给定编码（二进制或格雷码）下的整数值 $k$。\n    - 对于二进制编码，$k_{\\text{bin}}$ 是 $c$ 的整数值。\n    - 对于格雷码，$k_{\\text{gray}}$ 是通过对 $c$ 进行格雷码到二进制转换得到的。\n4.  计算当前状态下与适应度相关的项：$V_{\\text{bin}} = |2k_{\\text{bin}} - M|$ 和 $V_{\\text{gray}} = |2k_{\\text{gray}} - M|$。\n5.  遍历每个比特位置 $j$，从 $0$ 到 $b-1$。\n    a. 通过翻转 $c$ 的第 $j$ 个比特来确定新的码字 $c'$。\n    b. 解码 $c'$ 以获得新的整数值 $k'_{\\text{bin}}$ 和 $k'_{\\text{gray}}$。\n    c. 计算新的适应度项 $V'_{\\text{bin}} = |2k'_{\\text{bin}} - M|$ 和 $V'_{\\text{gray}} = |2k'_{\\text{gray}} - M|$。\n    d. 如果 $V'_{\\text{bin}} < V_{\\text{bin}}$，则增加二进制编码的计数器。\n    e. 如果 $V'_{\\text{gray}} < V_{\\text{gray}}$，则增加格雷码的计数器。\n6.  遍历所有码字和比特翻转后，得到总计数 $S_{\\text{bin}}$ 和 $S_{\\text{gray}}$。\n7.  概率则为 $P_{\\mathrm{improve}}^{\\text{bin}} = S_{\\text{bin}} / (2^b \\cdot b)$ 和 $P_{\\mathrm{improve}}^{\\text{gray}} = S_{\\text{gray}} / (2^b \\cdot b)$。\n\n这个过程在提供的代码中得到了精确实现。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes discretization error and one-step improvement probability for\n    binary and Gray encodings on the sphere function.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (n, b, L, U)\n        (1, 3, -1.0, 1.0),\n        (5, 4, -1.0, 1.0),\n        (10, 8, -1.0, 1.0),\n        (3, 1, -1.0, 1.0),\n        (2, 12, -1.0, 1.0),\n    ]\n\n    def gray_to_bin_int(g: int) -> int:\n        \"\"\"\n        Converts a Gray-coded integer to its corresponding binary integer value.\n        \"\"\"\n        b = g\n        mask = g >> 1\n        while mask > 0:\n            b ^= mask\n            mask >>= 1\n        return b\n\n    # Store results as formatted strings to match output specification.\n    formatted_results = []\n\n    for n, b, L, U in test_cases:\n        # 1. Discretization Error Calculation\n        # For L = -U, the continuous minimum is 0. The discrete grid point closest to 0\n        # for a coordinate is at |U|/(2^b - 1). The minimum of sum(x_i^2) is n * (|U|/(2^b - 1))^2.\n        # Since all test cases have U=1.0, this simplifies.\n        if (2**b - 1) == 0:\n             disc_error = float('inf') if n > 0 else 0.0\n        else:\n             disc_error = n * (U / (2**b - 1))**2\n        \n        # Discretization error is independent of the encoding strategy, as both\n        # cover the same set of phenotype points.\n        d_bin = disc_error\n        d_gray = disc_error\n\n        # 2. One-Step Improvement Probability Calculation\n        improvements_bin = 0\n        improvements_gray = 0\n        num_states = 2**b\n        # Precompute a map from Gray coded integers to binary integers for efficiency.\n        gray_map = {g: gray_to_bin_int(g) for g in range(num_states)}\n        \n        # This value is used for the integer-based fitness comparison\n        # |2k' - M|  |2k - M| to avoid floating point issues.\n        M = num_states - 1\n\n        # Iterate over all possible b-bit codewords (represented as integers 0..2^b-1)\n        for c_int in range(num_states):\n            # For binary encoding, the integer value k is the codeword itself.\n            k_bin = c_int\n            # For Gray encoding, the codeword c_int must be converted to find k.\n            k_gray = gray_map[c_int]\n\n            # Objective value proxy for the current state for each encoding\n            val_bin = abs(2 * k_bin - M)\n            val_gray = abs(2 * k_gray - M)\n\n            # Iterate over all possible single-bit flips\n            for j in range(b):\n                # Flipping the j-th bit is equivalent to XOR with 2^j\n                c_prime_int = c_int ^ (1  j)\n\n                # --- Binary Encoding ---\n                k_prime_bin = c_prime_int\n                val_prime_bin = abs(2 * k_prime_bin - M)\n                if val_prime_bin  val_bin:\n                    improvements_bin += 1\n\n                # --- Gray Encoding ---\n                k_prime_gray = gray_map[c_prime_int]\n                val_prime_gray = abs(2 * k_prime_gray - M)\n                if val_prime_gray  val_gray:\n                    improvements_gray += 1\n\n        # The total number of possible one-bit mutations for a single coordinate\n        # is the number of states times the number of bits.\n        total_mutations = num_states * b\n        \n        p_bin = improvements_bin / total_mutations if total_mutations > 0 else 0.0\n        p_gray = improvements_gray / total_mutations if total_mutations > 0 else 0.0\n\n        sub_result = [d_bin, d_gray, p_bin, p_gray]\n        result_str = f\"[{','.join(f'{x:.12f}' for x in sub_result)}]\"\n        formatted_results.append(result_str)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3132789"}, {"introduction": "定义了解决方案的表示法之后，我们需要理解遗传算法究竟是如何工作的。它是怎样将优秀的“解决方案片段”组合起来，从而构建出更好的完整解决方案的呢？模式定理（Schema Theorem）为我们观察这一过程提供了数学视角，它描述了“构建模块”（短的、低阶的、高适应度的模式）在代际间预期会如何增殖。尽管这是一个简化的模型，但它为我们揭示了选择、交叉和变异三者相互作用的关键洞见。这项练习 [@problem_id:3137469] 将通过模拟来检验模式定理的预测，从而揭开其神秘面纱。你将实现一个遗传算法并追踪一个特定模式，将其在群体中的实际传播情况与理论下界进行比较，从而将抽象的理论与具体的算法行为联系起来。", "problem": "考虑一个采用适应度比例选择、单点交叉和独立位翻转突变的二进制串遗传算法 (GA)。模式 (schema) 是一个作用于二进制串的模板，它将某些位置固定为指定值，而其他位置则保留为通配符。模式的阶 (order) 是固定位置的数量，其定义长度 (defining length) 是最低和最高固定位置索引之间的距离。模式定理结合了选择和破坏效应，为一代之后模式实例的期望数量提供了一个下界。您的任务是通过模拟来经验性地检验该下界，同时根据 GA 操作的基本定义仔细推导所需的量。\n\n使用的基本原理：\n- 二进制串 GA 通过选择、交叉和突变来转换种群。在适应度比例选择下，一个个体对下一代贡献的期望副本数与其适应度除以种群平均适应度的值成正比。\n- 在单点交叉中，交叉点在所有可能的位位置边界之间均匀选择。如果该交叉点严格落在模式的定义长度内，则该模式被破坏。以每个位固定速率进行的独立位翻转突变，如果模式的任何固定位置发生翻转，则会破坏该模式。\n\nGA 设置如下：\n- 二进制串长度为 $n = 20$。\n- 每代种群大小为 $N = 500$。\n- 适应度函数 $f(x)$ 是 $x$ 的位数之和（即所谓的 OneMax 问题）。\n- 选择是适应度比例选择，并使用随机通用采样以减少方差。\n- 交叉是单点交叉，每对交叉率为 $p_c$。\n- 突变是独立位翻转，每位突变率为 $p_m$。\n- 模式 $H$ 将位置 $P = \\{2, 6, 11, 18\\}$ 固定为值 $V = \\{1, 0, 1, 1\\}$，因此模式的阶为 $o = 4$，定义长度为 $l = 18 - 2 = 16$。\n- 模拟从第 $t$ 代（选择前种群）到第 $t + 1$ 代（突变后种群）的一代过程。\n\n对于每个测试用例的每次重复实验：\n1. 初始化一个大小为 $N$ 的第 $t$ 代种群，其中每个位都独立地从参数为 $0.5$ 的伯努利分布中抽取。\n2. 计算匹配模式 $H$ 的串的数量 $m(H, t)$。\n3. 计算匹配 $H$ 的串的平均适应度（表示为 $\\overline{f}_H$）和种群的总体平均适应度（表示为 $\\overline{f}$）。\n4. 仅基于上述 GA 定义，结合选择的期望效应以及在交叉和突变下的存活概率，推导并计算 $m(H, t + 1)$ 期望值的模式定理下界。\n5. 执行适应度比例选择与随机通用采样，形成 $N$ 个父代，对父代对应用率为 $p_c$ 的单点交叉，对每个位独立应用率为 $p_m$ 的突变，然后计算实际的 $m(H, t + 1)$。\n6. 重复指定的重复实验次数，并通过计算 $m(H, t + 1)$ 的样本均值和推导的下界的样本均值来汇总结果。\n\n验证目标：\n- 对于每个测试用例，验证不等式，即实际 $m(H, t + 1)$ 的样本均值大于或等于推导的下界的样本均值。为每个测试用例报告一个布尔值，如果该不等式在数值容差 $\\epsilon = 10^{-9}$ 内成立，则为 true，否则为 false。\n\n测试套件参数，以覆盖典型、边界和高破坏条件：\n- 案例 1：$p_c = 0.7$，$p_m = 0.001$，重复实验次数 $R = 200$。\n- 案例 2：$p_c = 0$，$p_m = 0$，重复实验次数 $R = 100$。\n- 案例 3：$p_c = 1.0$，$p_m = 0.05$，重复实验次数 $R = 200$。\n- 案例 4：$p_c = 0.9$，$p_m = 0.02$，重复实验次数 $R = 150$。\n\n最终输出格式：\n- 您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个测试用例对应一个布尔值，顺序如上所述（例如，`[True,False,True,True]`）。使用 Python 规范的布尔字面量，使输出看起来像 `[True,False,True,True]`。", "solution": "目标是经验性地检验模式定理在一代 GA 后模式实例期望数的下界。我们从遗传算法 (GA) 操作的基本定义出发，推导计算该下界所需的量。\n\n我们考虑一个作用于长度为 $n = 20$ 的二进制串、种群大小为 $N = 500$ 的 GA。适应度函数是位数之和，因此对于一个串 $x \\in \\{0,1\\}^n$，我们定义 $f(x) = \\sum_{i=1}^{n} x_i$。模式 $H$ 由固定位置 $P = \\{2, 6, 11, 18\\}$ 和对应值 $V = \\{1, 0, 1, 1\\}$ 定义，其阶为 $o = |P| = 4$，定义长度为 $l = \\max(P) - \\min(P) = 18 - 2 = 16$。定义长度计算的是，如果单点交叉的边界严格落在从第一个到最后一个固定位置的跨度内，可能破坏该模式的交叉点数量。\n\n我们逐步推导该下界：\n\n选择的贡献：\n在适应度比例选择下，一个个体 $x$ 贡献的期望副本数为 $f(x) / \\overline{f}$，其中 $\\overline{f}$ 是种群的平均适应度。设 $S_t$ 是第 $t$ 代个体的多重集，$H_t \\subseteq S_t$ 是匹配 $H$ 的子集。仅经过选择后 $H$ 实例的期望数量，表示为 $E_{\\text{sel}}[m(H, t+1)]$，是 $H_t$ 中每个个体期望繁殖数的总和，即\n$$\nE_{\\text{sel}}[m(H, t+1)] = \\sum_{x \\in H_t} \\frac{f(x)}{\\overline{f}} = m(H,t) \\cdot \\frac{\\overline{f}_H}{\\overline{f}},\n$$\n其中 $\\overline{f}_H$ 是 $H_t$ 中串的平均适应度。这源于期望的线性性质和适应度比例选择的定义。\n\n交叉存活概率：\n考虑以概率 $p_c$ 应用于选定父代对的单点交叉。对于长度为 $n$ 的串中定义长度为 $l$ 的模式，有 $n - 1$ 个可能的交叉点均匀分布。除非交叉点严格落在定义长度内，否则模式会在子代中存活。因此，交叉不被应用或不破坏模式的概率是\n$$\nP_{\\text{cross-survive}} = 1 - p_c \\cdot \\frac{l}{n - 1}.\n$$\n这种处理对破坏的估计是保守的：如果交叉点落在定义跨度之外，则该模式至少在一个子代中被保留。\n\n突变存活概率：\n以每位 $p_m$ 的速率进行的独立位翻转突变，如果一个阶为 $o$ 的模式的 $o$ 个固定位都没有翻转，则该模式得以保留。由于翻转是独立的，\n$$\nP_{\\text{mut-survive}} = (1 - p_m)^{o}.\n$$\n\n将效应组合成模式定理下界：\n模式定理通过将期望选择副本数与保守的破坏存活概率相乘，给出了经过一整代（选择、交叉、突变）后模式实例期望数的下界。这得出\n$$\nE[m(H, t+1)] \\ge m(H, t) \\cdot \\frac{\\overline{f}_H}{\\overline{f}} \\cdot \\left(1 - p_c \\cdot \\frac{l}{n - 1}\\right) \\cdot (1 - p_m)^{o}.\n$$\n该下界对交叉破坏采用了保守处理，并且除了定义长度外，不假定父代模式的具体构成。\n\n经验性流程：\n对于每个测试用例的每次重复实验，我们通过以参数 $0.5$ 独立采样每个位来初始化第 $t$ 代种群。然后我们计算 $m(H, t)$、$\\overline{f}_H$（如果 $m(H,t)  0$；否则下界为 $0$）和 $\\overline{f}$。使用推导的下界，\n$$\nB = m(H, t) \\cdot \\frac{\\overline{f}_H}{\\overline{f}} \\cdot \\left(1 - p_c \\cdot \\frac{l}{n - 1}\\right) \\cdot (1 - p_m)^{o},\n$$\n我们模拟一代 GA 的过程：使用随机通用采样的适应度比例选择，配对父代，以概率 $p_c$ 应用单点交叉，以概率 $p_m$ 应用位翻转突变，并计算实际的 $m(H, t+1)$。我们对指定的重复实验次数 $R$ 进行重复，将实际计数值和下界值汇总为样本均值：\n$$\n\\widehat{E}[m(H, t+1)] = \\frac{1}{R} \\sum_{r=1}^{R} m_r(H, t+1), \\quad\n\\widehat{B} = \\frac{1}{R} \\sum_{r=1}^{R} B_r.\n$$\n\n验证和决策规则：\n我们通过测试以下不等式来验证：\n$$\n\\widehat{E}[m(H, t+1)] \\ge \\widehat{B} - \\epsilon,\n$$\n其中数值容差为 $\\epsilon = 10^{-9}$，并为每个测试用例报告一个布尔值。此设计考虑了采样可变性，同时忠实于推导出的下界。\n\n测试套件覆盖理由：\n- 案例 1（$p_c = 0.7$，$p_m = 0.001$，$R = 200$）是一个典型的 GA 配置，用于在适度交叉和低突变下测试下界。\n- 案例 2（$p_c = 0$，$p_m = 0$，$R = 100$）移除了破坏效应，使下界紧密贴合选择期望，并作为一个边界条件。\n- 案例 3（$p_c = 1.0$，$p_m = 0.05$，$R = 200$）引入了最大交叉和相对较高的突变，强调了破坏效应，并验证了下界仍然是保守的。\n- 案例 4（$p_c = 0.9$，$p_m = 0.02$，$R = 150$）在强交叉和适度突变下对下界进行压力测试。\n\n最终的程序精确地实现了这个过程，并输出一个单行的布尔值列表，按测试套件案例的顺序，指示经验样本均值是否至少为推导的下界。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef one_max_fitness(pop):\n    # Sum of bits across rows\n    return pop.sum(axis=1)\n\ndef is_in_schema(pop, positions, values):\n    # Check if individuals match schema H at given positions with given values\n    return np.all(pop[:, positions] == values, axis=1)\n\ndef stochastic_universal_sampling(fitness, n_select, rng):\n    total_fit = fitness.sum()\n    if total_fit == 0:\n        # Fallback to uniform selection if all fitness are zero\n        probs = np.ones_like(fitness) / fitness.size\n    else:\n        probs = fitness / total_fit\n    cum_probs = np.cumsum(probs)\n    # Start point in [0, 1/n_select)\n    start = rng.uniform(0.0, 1.0 / n_select)\n    pointers = start + (np.arange(n_select) / n_select)\n    # Map pointers to indices via cumulative sum\n    idx = np.searchsorted(cum_probs, pointers, side='right')\n    return idx\n\ndef single_point_crossover(parents, pc, rng):\n    n = parents.shape[1]\n    # Pair parents: assume even number n_parents, if odd, last one will be paired with previous (but here n_parents = N even)\n    n_parents = parents.shape[0]\n    children = np.empty_like(parents)\n    for i in range(0, n_parents, 2):\n        p1 = parents[i]\n        p2 = parents[i+1]\n        if rng.random()  pc:\n            # Choose crossover point from 1..n-1\n            point = rng.integers(1, n)\n            c1 = np.concatenate([p1[:point], p2[point:]])\n            c2 = np.concatenate([p2[:point], p1[point:]])\n        else:\n            c1 = p1.copy()\n            c2 = p2.copy()\n        children[i] = c1\n        children[i+1] = c2\n    return children\n\ndef mutate(pop, pm, rng):\n    if pm == 0.0:\n        return pop\n    n_ind, n_bits = pop.shape\n    # Generate mutation mask: True where bit flips\n    mut_mask = rng.random(size=(n_ind, n_bits))  pm\n    # XOR with mask flips bits\n    return np.bitwise_xor(pop, mut_mask.astype(np.uint8))\n\ndef schema_bound(mHt, fbarH, fbar, pc, pm, l, n, o):\n    if mHt == 0 or fbar == 0:\n        return 0.0\n    # Bound: m(H,t) * (fbarH / fbar) * (1 - pc * (l/(n-1))) * (1 - pm)^o\n    survive_cross = 1.0 - pc * (l / (n - 1))\n    if survive_cross  0.0:\n        survive_cross = 0.0  # numerical safety\n    survive_mut = (1.0 - pm) ** o\n    return mHt * (fbarH / fbar) * survive_cross * survive_mut\n\ndef run_case(pc, pm, R, base_seed, positions, values, n_bits=20, N=500, eps=1e-9):\n    # Constants for schema\n    o = len(positions)\n    l = positions.max() - positions.min()\n    # Accumulators\n    bounds = []\n    realized = []\n    for r in range(R):\n        seed = base_seed + hash((pc, pm, R, r)) % (2**31 - 1)\n        rng = np.random.default_rng(seed)\n        # Initialize population at generation t\n        pop_t = rng.integers(0, 2, size=(N, n_bits), dtype=np.uint8)\n        fitness_t = one_max_fitness(pop_t)\n        fbar = fitness_t.mean()\n        in_H_t = is_in_schema(pop_t, positions, values)\n        mHt = int(in_H_t.sum())\n        if mHt > 0:\n            fbarH = fitness_t[in_H_t].mean()\n        else:\n            fbarH = 0.0\n        # Compute bound for this replicate\n        B = schema_bound(mHt, fbarH, fbar, pc, pm, l, n_bits, o)\n        bounds.append(B)\n        # Selection via SUS\n        sel_idx = stochastic_universal_sampling(fitness_t, N, rng)\n        parents = pop_t[sel_idx]\n        # Crossover\n        children = single_point_crossover(parents, pc, rng)\n        # Mutation\n        pop_tp1 = mutate(children, pm, rng)\n        # Realized schema count\n        mHt1 = int(is_in_schema(pop_tp1, positions, values).sum())\n        realized.append(mHt1)\n    # Compare sample means\n    realized_mean = float(np.mean(realized))\n    bound_mean = float(np.mean(bounds))\n    return realized_mean >= (bound_mean - eps)\n\ndef solve():\n    # Schema positions and values\n    positions = np.array([2, 6, 11, 18], dtype=int)  # zero-based indexing consistent with numpy\n    values = np.array([1, 0, 1, 1], dtype=np.uint8)\n    # Test cases: (pc, pm, R)\n    test_cases = [\n        (0.7, 0.001, 200),  # Typical GA configuration\n        (0.0, 0.0, 100),    # No disruption boundary\n        (1.0, 0.05, 200),   # High disruption\n        (0.9, 0.02, 150),   # Strong crossover, moderate mutation\n    ]\n    base_seed = 123456789\n    results = []\n    for pc, pm, R in test_cases:\n        ok = run_case(pc, pm, R, base_seed, positions, values, n_bits=20, N=500, eps=1e-9)\n        results.append(ok)\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3137469"}, {"introduction": "在许多现实世界的应用中，评估一个解决方案的质量并非一个完美的过程，例如工程设计或机器学习。测量可能带有噪声，评估也可能存在误差。噪声会误导遗传算法的选择机制，可能导致算法错误地抛弃了真正优秀的解决方案，或者偏爱那些偶然获得高评估值的个体。一个鲁棒的遗传算法设计需要包含一些策略来减轻噪声的影响，例如对个体进行重复评估，或者使用对异常值不那么敏感的选择方法。这项实践挑战 [@problem_id:3137379] 要求你在适应度反馈不可靠的情况下，调整遗传算法以完成优化任务。通过实现和比较不同的选择和评估策略，你将学到构建鲁棒进化算法的基本技巧，使其能够在理想化的无噪声环境之外取得成功。", "problem": "您的任务是实现并比较在含噪声适应度评估下的遗传算法（GA）选择策略。基本原理包括：(i) 通过选择和变异进行演化的遗传算法种群的定义；(ii) 针对位串 $\\mathbf{x} \\in \\{0,1\\}^{L}$ 的 OneMax 目标函数 $f(\\mathbf{x}) = \\sum_{i=1}^{L} x_i$；(iii) 观察到的含噪声适应度 $\\tilde{f}(\\mathbf{x}) = f(\\mathbf{x}) + \\epsilon$，其中 $\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)$；以及 (iv) 独立高斯变量之和与均值的期望和方差的性质。您必须设计一个程序，该程序运行一个带有噪声评估的遗传算法，并针对一组指定的测试用例，报告找到的最佳真实适应度。最佳真实适应度定义为在演化运行期间任何时刻观察到的（跨代至今最优的）无噪声的 $f(\\mathbf{x})$ 的最大值。\n\n需要实现的算法设置：\n- 表示法：个体是长度为 $L$ 的位串，其中 $L = 24$。\n- 目标函数：真实适应度 $f(\\mathbf{x}) = \\sum_{i=1}^{L} x_i$。\n- 含噪声评估：对于给定的噪声标准差 $\\sigma \\ge 0$，每次评估都会独立抽取一个 $\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)$ 并返回 $\\tilde{f}(\\mathbf{x}) = f(\\mathbf{x}) + \\epsilon$。\n- 重评估与聚合：为减轻噪声影响，您可以对同一个体进行 $m \\in \\mathbb{N}$ 次独立评估，得到 $\\tilde{f}_1,\\dots,\\tilde{f}_m$，并通过样本均值或样本中位数对其进行聚合。将聚合结果记为 $g_m(\\mathbf{x})$。当 $m=1$ 时，$g_1(\\mathbf{x}) = \\tilde{f}(\\mathbf{x})$。在每一代中，每个个体的聚合值 $g_m(\\mathbf{x})$ 只计算一次，并用于该代所有的选择决策。\n- 种群：大小 $N = 80$。初始种群是独立同分布的，每个位以 $1/2$ 的概率从伯努利分布中采样为 $1$。\n- 需要实现的选择策略：\n  1. 适应度比例（轮盘赌）选择，使用聚合得分 $g_m(\\mathbf{x})$：令第 $i$ 个个体的 $w_i = g_m(\\mathbf{x}^{(i)})$。为避免非正权重，计算移位的非负权重 $u_i = \\max\\{w_i - \\min_j w_j + \\delta, \\delta\\}$，其中 $\\delta = 10^{-9}$。有放回地选择 $N$ 个父代，选择个体 $i$ 的概率为 $u_i / \\sum_{k=1}^{N} u_k$。\n  2. 规模为 $\\tau = 3$ 的锦标赛选择，使用聚合得分 $g_m(\\mathbf{x})$：为选择一个父代，从 $\\{1,\\dots,N\\}$ 中均匀采样 $\\tau$ 个不同的索引，并选择其中 $g_m(\\mathbf{x})$ 最大的个体。重复此过程直到选出 $N$ 个父代。\n- 变异：仅使用变异。每个被选中的父代通过独立的位翻转突变产生一个后代，每个位的突变概率为 $p_m = 1/L$。不使用交叉。\n- 替换：代际替换。$N$ 个后代构成下一代。不使用显式精英主义。但是，为了报告结果，需要记录整个运行过程中观察到的至今最优真实适应度 $\\max f(\\mathbf{x})$。\n- 代数：每个测试用例运行 $T = 250$ 代。\n\n数学和统计约定：\n- 除非另有说明，所有随机变量都是独立的。在不同代之间，会抽取新的噪声样本。在每一代中，每个个体的聚合得分 $g_m(\\mathbf{x})$ 使用新的噪声计算，并在该代的所有选择决策中重复使用。\n- 当 $m  1$ 时，聚合函数是 $m$ 次独立含噪声评估的样本均值或样本中位数；两种聚合器都作用于独立同分布的高斯样本。\n\n测试套件：\n每个测试用例是一个元组 $(\\sigma, \\text{selection}, m, \\text{aggregator}, s)$，其中 $\\sigma$ 是噪声标准差，$\\text{selection}$ 是字符串 \"roulette\" 或 \"tournament\"，$m$ 是每代每个个体的正整数重评估次数，$\\text{aggregator}$ 是字符串 \"mean\" 或 \"median\"，$s$ 是用于初始化伪随机数生成器的整数种子。使用以下参数集：\n- 用例 1： $(0, \\text{\"roulette\"}, 1, \\text{\"mean\"}, 42)$。\n- 用例 2： $(2, \\text{\"roulette\"}, 1, \\text{\"mean\"}, 7)$。\n- 用例 3： $(2, \\text{\"tournament\"}, 1, \\text{\"mean\"}, 7)$。\n- 用例 4： $(2, \\text{\"tournament\"}, 5, \\text{\"mean\"}, 7)$。\n- 用例 5： $(6, \\text{\"roulette\"}, 1, \\text{\"mean\"}, 13)$。\n- 用例 6： $(6, \\text{\"tournament\"}, 1, \\text{\"mean\"}, 13)$。\n- 用例 7： $(6, \\text{\"tournament\"}, 5, \\text{\"mean\"}, 13)$。\n- 用例 8： $(6, \\text{\"tournament\"}, 5, \\text{\"median\"}, 13)$。\n\n对于每个测试用例，运行上述遗传算法，并返回整数形式的至今最优真实适应度，即运行期间所有曾出现过的个体的精确 OneMax 分数 $f(\\mathbf{x}) = \\sum_{i=1}^{L} x_i$（无噪声）的最大值。所有真实适应度的计算都是精确且无噪声的。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表顺序与上述测试用例相同。例如，输出应类似于 $[r_1,r_2,\\dots,r_8]$，其中每个 $r_i$ 是用例 $i$ 的整数形式的至今最优真实适应度。", "solution": "已根据指定标准对用户提供的问题进行了分析和验证。\n\n### 第 1 步：提取已知信息\n- **问题领域**：在含噪声适应度评估下的 OneMax 问题的遗传算法（GA）。\n- **目标函数（真实适应度）**：$f(\\mathbf{x}) = \\sum_{i=1}^{L} x_i$，适用于位串 $\\mathbf{x} \\in \\{0,1\\}^{L}$。\n- **含噪声适应度评估**：$\\tilde{f}(\\mathbf{x}) = f(\\mathbf{x}) + \\epsilon$，其中 $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$。\n- **GA 参数**：\n    - 表示法：长度为 $L = 24$ 的位串。\n    - 种群大小：$N = 80$。\n    - 代数：$T = 250$。\n    - 初始种群：位是独立同分布的伯努利变量，其中 $p=1/2$。\n    - 变异：按位突变，概率为 $p_m = 1/L$。无交叉。\n    - 替换：代际替换（后代替换父代）。无显式精英主义。\n- **噪声处理**：\n    - 重评估：每代每个个体进行 $m$ 次独立评估。\n    - 聚合函数 ($g_m(\\mathbf{x})$)：$m$ 次评估的样本均值或样本中位数。当 $m=1$ 时，$g_1(\\mathbf{x}) = \\tilde{f}(\\mathbf{x})$。\n- **选择策略**：\n    1.  **适应度比例（轮盘赌）**：有放回地选择 $N$ 个父代。个体 $i$ 的选择概率与 $u_i = \\max\\{w_i - \\min_j w_j + \\delta, \\delta\\}$ 成正比，其中 $w_i = g_m(\\mathbf{x}^{(i)})$ 且 $\\delta = 10^{-9}$。\n    2.  **锦标赛选择**：从一个随机抽样的规模为 $\\tau=3$ 的锦标赛中选择最佳个体作为父代。重复 $N$ 次以形成父代池。\n- **报告指标**：在一次运行的所有代的所有个体中观察到的最佳真实适应度 $f(\\mathbf{x})$（至今最优）。\n- **测试用例**：提供了一组 8 个测试用例，每个用例由一个元组 $(\\sigma, \\text{selection}, m, \\text{aggregator}, s)$ 定义，其中 $s$ 是伪随机数生成器的种子。\n    - 用例 1： $(0, \\text{\"roulette\"}, 1, \\text{\"mean\"}, 42)$\n    - 用例 2： $(2, \\text{\"roulette\"}, 1, \\text{\"mean\"}, 7)$\n    - 用例 3： $(2, \\text{\"tournament\"}, 1, \\text{\"mean\"}, 7)$\n    - 用例 4： $(2, \\text{\"tournament\"}, 5, \\text{\"mean\"}, 7)$\n    - 用例 5： $(6, \\text{\"roulette\"}, 1, \\text{\"mean\"}, 13)$\n    - 用例 6： $(6, \\text{\"tournament\"}, 1, \\text{\"mean\"}, 13)$\n    - 用例 7： $(6, \\text{\"tournament\"}, 5, \\text{\"mean\"}, 13)$\n    - 用例 8： $(6, \\text{\"tournament\"}, 5, \\text{\"median\"}, 13)$\n\n### 第 2 步：使用提取的已知信息进行验证\n1.  **科学依据**：该问题是计算科学领域的标准练习，特别是在演化算法领域。OneMax 问题是一个典型的基准问题，使用加性高斯噪声对含噪声目标函数进行建模是一种成熟的做法。所有指定的组件（选择、变异等）都是遗传算法中的基本概念。该问题具有科学合理性。\n2.  **良构性**：所有参数（$L, N, T, p_m, \\tau$ 等）都有精确定义。初始条件、终止条件（代数）和评估过程都清晰明确。为每个测试用例使用特定的随机数生成器种子确保了随机模拟是可复现的，从而为每个用例带来唯一、可验证的解。\n3.  **客观性**：问题描述使用了清晰、正式、客观的语言，不含任何主观或基于观点的陈述。\n\n### 第 3 步：结论与行动\n问题是**有效的**。它自成体系、科学合理、良构且客观。不存在矛盾、歧义或信息缺失。该任务是一个非平凡但可行的标准科学模拟实现。因此，我将继续提供一个完整的解决方案。\n\n该解决方案按规定实现了一个遗传算法。核心逻辑封装在 `run_ga` 函数中，该函数为一组给定的参数执行一次完整的演化运行。\n\n算法流程如下：\n1.  **初始化**：为一个随机数生成器设定种子。创建包含 $N$ 个位串的初始种群，每个位以等概率为 $0$ 或 $1$。通过计算这个初始种群中每个个体的真实适应度并取最大值来初始化 `best_so_far_fitness`。\n2.  **代际循环**：算法迭代 $T$ 代。在每一代中：\n    a. **评估**：对当前种群中的每个个体，计算其聚合适应度得分 $g_m(\\mathbf{x})$。这包括计算真实适应度 $f(\\mathbf{x})$，向其添加 $m$ 个独立的服从 $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$ 的高斯噪声变量，然后使用样本均值或中位数聚合这 $m$ 个含噪声的结果。这些聚合得分被存储起来用于选择步骤。\n    b. **选择**：根据聚合得分，从当前种群中选出一个包含 $N$ 个父代的父代池。选择过程使用指定的轮盘赌法或锦标赛法进行。\n    c. **变异**：$N$ 个被选中的父代各自产生一个后代。后代是通过对父代的副本应用位翻转突变生成的，其中每个位有 $p_m = 1/L$ 的概率被翻转。\n    d. **替换**：这组 $N$ 个后代成为下一代的种群。\n    e. **追踪**：计算新后代种群中所有个体的真实适应度，如果发现新的最大值，则更新 `best_so_far_fitness`。\n3.  **结果**：经过 $T$ 代后，返回最终的 `best_so_far_fitness`（作为整数）。\n\n主脚本定义了测试用例并遍历它们，为每个用例调用 `run_ga` 函数并收集结果。最后，它以指定的逗号分隔格式打印结果。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to define, run, and print the results of the GA test suite.\n    \"\"\"\n\n    def noisy_evaluation(true_f, sigma, m, aggregator, rng):\n        \"\"\"\n        Computes the aggregated noisy fitness score for an individual.\n        \n        Args:\n            true_f (float): The true fitness of the individual.\n            sigma (float): The standard deviation of the Gaussian noise.\n            m (int): The number of re-evaluations.\n            aggregator (str): The aggregation method ('mean' or 'median').\n            rng (np.random.Generator): The random number generator.\n            \n        Returns:\n            float: The aggregated noisy fitness score.\n        \"\"\"\n        if sigma == 0.0:\n            return true_f\n        \n        # Generate m independent noisy samples\n        noisy_samples = rng.normal(loc=true_f, scale=sigma, size=m)\n        \n        if m == 1:\n            return noisy_samples[0]\n        \n        if aggregator == \"mean\":\n            return np.mean(noisy_samples)\n        elif aggregator == \"median\":\n            return np.median(noisy_samples)\n        else:\n            # This path should not be reached with the given test cases.\n            raise ValueError(\"Invalid aggregator specified.\")\n\n    def roulette_selection(aggregated_scores, N, rng):\n        \"\"\"\n        Performs fitness-proportionate (roulette) selection.\n        \n        Args:\n            aggregated_scores (np.ndarray): Array of scores for the population.\n            N (int): Population size.\n            rng (np.random.Generator): The random number generator.\n        \n        Returns:\n            np.ndarray: An array of N selected parent indices.\n        \"\"\"\n        delta = 1e-9\n        # Shift scores to be non-negative to create weights.\n        # u_i = max{w_i - min_j w_j + delta, delta}\n        min_score = np.min(aggregated_scores)\n        weights = np.maximum(aggregated_scores - min_score + delta, delta)\n        \n        # Normalize weights to get selection probabilities.\n        sum_weights = np.sum(weights)\n        if sum_weights == 0:\n            # Uniform selection if all weights are zero (highly unlikely).\n            probabilities = np.full(N, 1.0 / N)\n        else:\n            probabilities = weights / sum_weights\n            \n        parent_indices = rng.choice(N, size=N, replace=True, p=probabilities)\n        return parent_indices\n\n    def tournament_selection(aggregated_scores, N, tau, rng):\n        \"\"\"\n        Performs tournament selection.\n        \n        Args:\n            aggregated_scores (np.ndarray): Array of scores for the population.\n            N (int): Population size.\n            tau (int): Tournament size.\n            rng (np.random.Generator): The random number generator.\n        \n        Returns:\n            np.ndarray: An array of N selected parent indices.\n        \"\"\"\n        parent_indices = np.zeros(N, dtype=int)\n        for i in range(N):\n            # Select tau distinct individuals for the tournament.\n            contender_indices = rng.choice(N, size=tau, replace=False)\n            contender_scores = aggregated_scores[contender_indices]\n            \n            # The winner is the one with the highest aggregated score.\n            winner_local_index = np.argmax(contender_scores)\n            winner_global_index = contender_indices[winner_local_index]\n            parent_indices[i] = winner_global_index\n            \n        return parent_indices\n\n    def mutation(parents, L, p_m, rng):\n        \"\"\"\n        Applies bit-flip mutation to a set of parents to create offspring.\n        \n        Args:\n            parents (np.ndarray): A (N, L) array of parent bit-strings.\n            L (int): The length of the bit-strings.\n            p_m (float): The per-bit mutation probability.\n            rng (np.random.Generator): The random number generator.\n            \n        Returns:\n            np.ndarray: A (N, L) array of offspring bit-strings.\n        \"\"\"\n        # Create a boolean mask for mutations. True indicates a flip.\n        mutation_mask = rng.random(size=parents.shape)  p_m\n        # Apply mutation using XOR operator.\n        offspring = parents ^ mutation_mask\n        return offspring.astype(np.int8)\n\n    def run_ga(L, N, T, sigma, selection_strat, m, aggregator, s):\n        \"\"\"\n        Runs a full Genetic Algorithm simulation for a single test case.\n        \n        Args:\n            L, N, T: GA structural parameters.\n            sigma, selection_strat, m, aggregator, s: Test case parameters.\n            \n        Returns:\n            int: The best-so-far true fitness found during the run.\n        \"\"\"\n        # --- Setup ---\n        rng = np.random.default_rng(s)\n        p_m = 1.0 / L\n        tau = 3  # Tournament size\n\n        # --- 1. Initialization ---\n        population = rng.integers(0, 2, size=(N, L), dtype=np.int8)\n        \n        # Calculate true fitness for the initial population (gen 0)\n        true_fitnesses = np.sum(population, axis=1)\n        best_so_far_fitness = np.max(true_fitnesses)\n\n        # --- 2. Generational Loop ---\n        for _ in range(T):\n            # --- a. Evaluation ---\n            # Calculate true fitnesses once per generation for noise calculation.\n            current_true_fitnesses = np.sum(population, axis=1)\n            \n            # Compute aggregated noisy scores for the current population.\n            aggregated_scores = np.array([\n                noisy_evaluation(f, sigma, m, aggregator, rng) for f in current_true_fitnesses\n            ])\n\n            # --- b. Selection ---\n            if selection_strat == \"roulette\":\n                parent_indices = roulette_selection(aggregated_scores, N, rng)\n            else:  # tournament\n                parent_indices = tournament_selection(aggregated_scores, N, tau, rng)\n            \n            parents = population[parent_indices]\n\n            # --- c. Variation ---\n            offspring = mutation(parents, L, p_m, rng)\n\n            # --- d. Replacement ---\n            population = offspring\n\n            # --- e. Update Best-So-Far ---\n            # The new population's individuals have been \"seen,\" so check their true fitness.\n            true_fitnesses_offspring = np.sum(population, axis=1)\n            current_max_true = np.max(true_fitnesses_offspring)\n            if current_max_true > best_so_far_fitness:\n                best_so_far_fitness = current_max_true\n        \n        return int(best_so_far_fitness)\n\n    # --- Main ---\n    # Global parameters for the GA.\n    L = 24\n    N = 80\n    T = 250\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (sigma, selection, m, aggregator, seed)\n        (0.0, \"roulette\", 1, \"mean\", 42),\n        (2.0, \"roulette\", 1, \"mean\", 7),\n        (2.0, \"tournament\", 1, \"mean\", 7),\n        (2.0, \"tournament\", 5, \"mean\", 7),\n        (6.0, \"roulette\", 1, \"mean\", 13),\n        (6.0, \"tournament\", 1, \"mean\", 13),\n        (6.0, \"tournament\", 5, \"mean\", 13),\n        (6.0, \"tournament\", 5, \"median\", 13),\n    ]\n\n    results = []\n    for case in test_cases:\n        sigma, selection, m, aggregator, s_seed = case\n        result = run_ga(L, N, T, sigma, selection, m, aggregator, s_seed)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3137379"}]}