{"hands_on_practices": [{"introduction": "理解粒子群优化算法的第一步是掌握其核心驱动机制——速度更新方程。该方程巧妙地融合了三个关键部分：维持当前运动趋势的“惯性”，借鉴自身历史最佳位置的“认知”，以及学习群体共享信息的“社会”部分。本练习将引导你完成一个具体的一步计算，以巩固对单个粒子在一个时间步内如何确定其飞行轨迹的理解。[@problem_id:2166499]", "problem": "一架自主无人机是一个蜂群的一部分，该蜂群在一个广阔的开阔场地中搜索无线电信号强度最大的位置。该场地被建模为一个二维笛卡尔平面。搜索过程由粒子群优化（PSO）算法引导。在每个时间步，每架无人机根据其当前速度、自身找到的最佳位置以及整个蜂群中任何无人机找到的最佳位置来更新其速度。\n\n单个粒子（无人机）在时间步 $t+1$ 的速度更新由以下方程给出：\n$$ \\vec{v}(t+1) = \\omega \\vec{v}(t) + c_1 r_1 (\\vec{p} - \\vec{x}(t)) + c_2 r_2 (\\vec{g} - \\vec{x}(t)) $$\n其中：\n- $\\vec{v}(t)$ 是无人机的当前速度矢量。\n- $\\vec{x}(t)$ 是无人机的当前位置矢量。\n- $\\vec{p}$ 是无人机迄今为止找到的个体最佳位置。\n- $\\vec{g}$ 是整个蜂群迄今为止找到的全局最佳位置。\n- $\\omega$ 是惯性权重，控制先前速度的影响。\n- $c_1$ 和 $c_2$ 分别是认知系数和社会系数，用于加权个体最佳位置和全局最佳位置的影响。\n- $r_1$ 和 $r_2$ 是在 $[0, 1]$ 上均匀分布的随机数。\n\n考虑在特定时间步 $t$ 的一架特定无人机。该无人机的状态和蜂群参数如下：\n- 当前位置：$\\vec{x}(t) = \\begin{pmatrix} 8.0 \\\\ 14.0 \\end{pmatrix}$\n- 当前速度：$\\vec{v}(t) = \\begin{pmatrix} -1.0 \\\\ 2.0 \\end{pmatrix}$\n- 个体最佳位置：$\\vec{p} = \\begin{pmatrix} 10.0 \\\\ 12.0 \\end{pmatrix}$\n- 全局最佳位置：$\\vec{g} = \\begin{pmatrix} 11.0 \\\\ 10.0 \\end{pmatrix}$\n- 惯性权重：$\\omega = 0.7$\n- 认知系数：$c_1 = 1.5$\n- 社会系数：$c_2 = 1.5$\n对于此特定的更新步骤，生成的随机数为 $r_1 = 0.4$ 和 $r_2 = 0.9$。\n\n计算无人机的新速度矢量 $\\vec{v}(t+1)$。所有位置以米为单位，速度以米/秒（m/s）为单位。将您的答案表示为一个2元行矩阵 $[v_x, v_y]$，单位为 m/s。将矢量的每个分量四舍五入到三位有效数字。", "solution": "我们应用PSO速度更新规则\n$$\\vec{v}(t+1)=\\omega \\vec{v}(t)+c_{1}r_{1}\\left(\\vec{p}-\\vec{x}(t)\\right)+c_{2}r_{2}\\left(\\vec{g}-\\vec{x}(t)\\right)。$$\n计算位移矢量：\n$$\\vec{p}-\\vec{x}(t)=\\begin{pmatrix}10.0-8.0 \\\\ 12.0-14.0\\end{pmatrix}=\\begin{pmatrix}2 \\\\ -2\\end{pmatrix},\\quad \\vec{g}-\\vec{x}(t)=\\begin{pmatrix}11.0-8.0 \\\\ 10.0-14.0\\end{pmatrix}=\\begin{pmatrix}3 \\\\ -4\\end{pmatrix}。$$\n计算每一项：\n$$\\omega \\vec{v}(t)=0.7\\begin{pmatrix}-1.0 \\\\ 2.0\\end{pmatrix}=\\begin{pmatrix}-0.7 \\\\ 1.4\\end{pmatrix}，$$\n$$c_{1}r_{1}\\left(\\vec{p}-\\vec{x}(t)\\right)=1.5\\cdot 0.4\\begin{pmatrix}2 \\\\ -2\\end{pmatrix}=0.6\\begin{pmatrix}2 \\\\ -2\\end{pmatrix}=\\begin{pmatrix}1.2 \\\\ -1.2\\end{pmatrix}，$$\n$$c_{2}r_{2}\\left(\\vec{g}-\\vec{x}(t)\\right)=1.5\\cdot 0.9\\begin{pmatrix}3 \\\\ -4\\end{pmatrix}=1.35\\begin{pmatrix}3 \\\\ -4\\end{pmatrix}=\\begin{pmatrix}4.05 \\\\ -5.4\\end{pmatrix}。$$\n将各部分贡献相加得到\n$$\\vec{v}(t+1)=\\begin{pmatrix}-0.7 \\\\ 1.4\\end{pmatrix}+\\begin{pmatrix}1.2 \\\\ -1.2\\end{pmatrix}+\\begin{pmatrix}4.05 \\\\ -5.4\\end{pmatrix}=\\begin{pmatrix}4.55 \\\\ -5.2\\end{pmatrix}。$$\n将每个分量四舍五入到三位有效数字，得到\n$$\\vec{v}(t+1)=\\begin{pmatrix}4.55 \\\\ -5.20\\end{pmatrix}。$$\n表示为行矩阵，结果是 $\\begin{pmatrix}4.55  -5.20\\end{pmatrix}$，单位是米/秒。", "answer": "$$\\boxed{\\begin{pmatrix}4.55  -5.20\\end{pmatrix}}$$", "id": "2166499"}, {"introduction": "从单个计算步骤到完整的算法实现，本练习将挑战你从头开始构建粒子群优化器。你将关注一个至关重要的实用机制——速度钳位（$v^{\\max}$），它对于平衡算法的探索（exploration）与利用（exploitation）以及确保搜索过程的稳定性至关重要。通过实验性地分析其影响，你将掌握超参数调整这一元启发式算法应用中的关键技能。[@problem_id:3161041]", "problem": "您的任务是研究粒子群优化（Particle Swarm Optimization, PSO）中速度钳位（velocity clamping）的影响。粒子群优化（PSO）是一种基于群体的随机搜索方法，它通过使用受个体和社会信息影响的速度来迭代更新粒子位置。考虑一个由 $N$ 个粒子组成的群体，每个粒子都有一个位置 $x_j \\in \\mathbb{R}^d$ 和一个速度 $v_j \\in \\mathbb{R}^d$，其中 $j \\in \\{1,\\dots,N\\}$ 是粒子索引，$d$ 是维度。令 $p_j$ 表示粒子 $j$ 到目前为止找到的个体最优位置，令 $g$ 表示整个群体找到的全局最优位置。速度钳位在每次迭代中对每个分量强制施加一个边界 $\\lVert v_j \\rVert_{\\infty} \\le v^{\\max}$，这意味着对于所有 $k \\in \\{1,\\dots,d\\}$，每个分量都满足 $\\lvert v_{j,k} \\rvert \\le v^{\\max}$。\n\n基本原理。从离散时间迭代优化方法的核心定义和随机搜索的成熟理论出发：\n- 迭代方法使用一个规则来更新状态，该规则结合了前一状态的惯性（inertia）和与误差信号成比例的校正反馈。在PSO中，惯性是先前的速度，校正信号是与 $p_j$ 和 $g$ 的差异，并由随机系数进行调节。\n- 目标函数是实值、连续且有下界的。您将使用球面函数 $f(x) = \\sum_{k=1}^d x_k^2$，这是一个凸函数，在 $x^\\star = 0$ 处有唯一的全局最小值，且 $f(x^\\star) = 0$。\n\n您的任务：\n1. 从上述基本原理出发（不使用现成公式），推导出体现了惯性以及对 $p_j$ 和 $g$ 的校正反馈的离散时间更新方程，并引入将速度的每个分量限制在 $v^{\\max}$ 内的速度钳位算子。定性和定量地解释速度钳位如何影响在有界域上对 $f(x)$ 最小化器的收敛速度。\n2. 实现一个PSO变体，使用推导出的速度钳位来最小化函数 $f(x) = \\sum_{k=1}^d x_k^2$，搜索范围为盒子 $[-5,5]^d$。对所有测试用例使用以下固定的超参数：维度 $d = 5$，粒子群规模 $N = 25$，惯性权重 $w = 0.7$，迭代次数 $T = 100$，以及位置钳位以始终将 $x_j$ 保持在 $[-5,5]^d$ 内。在每次迭代中，为所有粒子 $j$ 和维度 $k$ 抽取新的独立随机变量 $r_{1,j,k}, r_{2,j,k} \\sim \\mathcal{U}(0,1)$，其中 $\\mathcal{U}(0,1)$ 表示在 $[0,1]$ 上的均匀分布。\n3. 为保证可复现性，请使用确定性的伪随机种子。对于索引为 $i$（从 $i=0$ 开始）的测试用例和索引为 $r \\in \\{0,\\dots,R-1\\}$ 的重复实验，使用 $s = 1000 + 100 \\cdot i + r$ 作为随机数生成器的种子，并为每个测试用例运行 $R = 5$ 次独立的重复实验。将粒子位置 $x_j$ 在 $[-5,5]^d$ 内进行均匀初始化，将初始个体最优位置 $p_j$ 设置为这些位置，相应地初始化全局最优位置 $g$，并将速度 $v_j$ 在 $[-v^{\\max}, v^{\\max}]^d$ 内进行均匀初始化。\n4. 对于每个测试用例，在 $T$ 次迭代后，计算 $R$ 次重复实验中找到的最优值的平均值 $\\bar{f}(g)$，其中 $f(g)$ 是在每次重复实验的最终全局最优位置上计算的。您的程序必须输出一行，其中包含所有测试用例的这些平均值，格式为用方括号括起来的逗号分隔列表，例如 $[a_1,a_2,\\dots,a_m]$，其中每个 $a_i$ 是一个浮点数。\n\n测试套件。评估以下 $m=6$ 组参数，每组参数以 $(c_1,c_2,v^{\\max})$ 的形式给出：\n- 用例 0：$(c_1,c_2,v^{\\max}) = (2.0, 2.0, 0.0)$，一个没有移动的边界情况。\n- 用例 1：$(c_1,c_2,v^{\\max}) = (2.0, 2.0, 0.5)$，具有对称认知项和社会项的中等钳位。\n- 用例 2：$(c_1,c_2,v^{\\max}) = (2.0, 2.0, 2.0)$，具有对称认知项和社会项的较大钳位。\n- 用例 3：$(c_1,c_2,v^{\\max}) = (3.0, 0.5, 1.0)$，认知主导模式下的中等钳位。\n- 用例 4：$(c_1,c_2,v^{\\max}) = (0.5, 3.0, 1.0)$，社会主导模式下的中等钳位。\n- 用例 5：$(c_1,c_2,v^{\\max}) = (1.0, 1.0, 1.0)$，弱对称影响。\n\n答案规格。对于每个用例，计算出的平均最优值 $\\bar{f}(g)$ 是一个浮点数。您的程序应生成单行输出，包含用方括号括起来的逗号分隔结果列表（例如，$[r_0,r_1,r_2,r_3,r_4,r_5]$）。不允许有其他输出。", "solution": "该问题要求推导和实现一种带速度钳位的粒子群优化（PSO）算法，并分析钳位对收敛性的影响。验证表明该问题具有科学依据、提法明确且内容完整。因此，我们可以着手进行严谨的求解。\n\n### 1. PSO 更新方程的推导\n\n我们从离散时间迭代优化方法的基本原理开始。在离散时间步 $t$，群体中每个粒子 $j$ 的状态由其位置向量 $x_j(t) \\in \\mathbb{R}^d$ 和速度向量 $v_j(t) \\in \\mathbb{R}^d$ 描述。目标是迭代更新这些状态，以找到目标函数 $f(x)$ 的最小值。\n\n**速度更新规则：**\n问题指出，速度的更新规则必须结合惯性和校正反馈。下一时间步的速度 $v_j(t+1)$ 由三个部分构成：\n\n1.  **惯性（Inertia）：** 粒子倾向于沿其当前方向继续运动。这被建模为其先前速度的一部分，由惯性权重 $w$ 控制。惯性项为 $w v_j(t)$。\n\n2.  **认知校正反馈（Cognitive Corrective Feedback）：** 每个粒子都被引向其自身找到的最优位置，记为 $p_j(t)$。这代表了粒子的个体经验。“误差信号”是向量差 $(p_j(t) - x_j(t))$。校正项与该差异成比例，由认知加速系数 $c_1$ 和一个随机元素 $r_{1,j}(t)$ 调节以引入探索。该项为 $c_1 r_{1,j}(t) \\odot (p_j(t) - x_j(t))$，其中 $\\odot$ 表示逐元素相乘，且 $r_{1,j}(t)$ 的每个分量都从均匀分布 $\\mathcal{U}(0,1)$ 中抽取。\n\n3.  **社会校正反馈（Social Corrective Feedback）：** 每个粒子也被引向整个群体中任何粒子找到的最优位置，记为 $g(t)$。这代表了群体的集体经验。误差信号是 $(g(t) - x_j(t))$。校正项与此成比例，由社会加速系数 $c_2$ 和一个随机元素 $r_{2,j}(t) \\sim \\mathcal{U}(0,1)$ 调节。该项为 $c_2 r_{2,j}(t) \\odot (g(t) - x_j(t))$。\n\n将这三个部分结合起来，得到钳位前速度向量的方程，我们将其表示为 $v'_j(t+1)$：\n$$\nv'_j(t+1) = w v_j(t) + c_1 r_{1,j}(t) \\odot (p_j(t) - x_j(t)) + c_2 r_{2,j}(t) \\odot (g(t) - x_j(t))\n$$\n对于每个维度 $k \\in \\{1, \\dots, d\\}$，其分量形式为：\n$$\nv'_{j,k}(t+1) = w v_{j,k}(t) + c_1 r_{1,j,k}(t) (p_{j,k}(t) - x_{j,k}(t)) + c_2 r_{2,j,k}(t) (g_k(t) - x_{j,k}(t))\n$$\n\n**速度钳位：**\n问题要求每个速度分量的大小都必须以 $v^{\\max}$ 为界，即 $|v_{j,k}| \\le v^{\\max}$。我们定义一个钳位算子 $C_{v^{\\max}}(\\cdot)$ 来施加此约束。对于一个标量值 $u$，该算子为：\n$$\nC_{v^{\\max}}(u) = \\text{sign}(u) \\cdot \\min(|u|, v^{\\max}) = \\max(-v^{\\max}, \\min(u, v^{\\max}))\n$$\n该算子逐分量地应用于钳位前的速度向量 $v'_j(t+1)$，以获得最终速度 $v_j(t+1)$：\n$$\nv_{j,k}(t+1) = C_{v^{\\max}}(v'_{j,k}(t+1)) \\quad \\forall k \\in \\{1, \\dots, d\\}\n$$\n\n**位置更新与钳位：**\n根据离散时间系统中速度的基本定义，使用新计算的速度来更新粒子的位置：\n$$\nx_j(t+1) = x_j(t) + v_j(t+1)\n$$\n为确保粒子保持在搜索域（此处指定为 $[-5, 5]^d$）内，更新后会应用位置钳位机制。对每个分量 $k$：\n$$\nx_{j,k}(t+1) \\leftarrow \\max(-5, \\min(x_{j,k}(t+1), 5))\n$$\n\n**最优位置更新：**\n在更新粒子位置后，评估其新的适应度值 $f(x_j(t+1))$。个体最优和全局最优位置更新如下：\n-   **个体最优（Personal Best）：** 如果 $f(x_j(t+1))  f(p_j(t))$，则 $p_j(t+1) = x_j(t+1)$。否则，$p_j(t+1) = p_j(t)$。\n-   **全局最优（Global Best）：** 全局最优位置 $g(t+1)$ 从所有个体最优位置的集合 $\\{p_j(t+1) \\mid j=1, \\dots, N\\}$ 中选取，使得 $f(g(t+1)) = \\min_{j} f(p_j(t+1))$。\n\n### 2. 速度钳位分析\n\n**定性分析：**\n速度钳位是控制粒子群动态的关键机制。\n-   **稳定性：** 如果没有钳位，粒子的速度可能会无限制地增加，这种现象被称为“粒子群爆炸”。如果参数 $w, c_1, c_2$ 造成了不稳定的动态，就会发生这种情况。一个爆炸的粒子群其粒子移动速度极快，以至于它们会“飞过”搜索空间中有希望的区域，从而严重损害或完全阻止收敛。钳位对粒子在一次迭代中可以采取的步长施加了硬性限制，从而确保了搜索过程的稳定性。\n-   **探索与利用的权衡：** $v^{\\max}$ 的值直接调节全局探索（exploration）和局部利用（exploitation）之间的平衡。\n    -   一个**较小**的 $v^{\\max}$ 会迫使粒子采取小步长。这会增强当前位置周围的局部搜索（利用），但如果最优点很远，则会减慢收敛速度。它还会增加粒子群过早陷入局部最优的风险，因为粒子可能缺乏逃逸的动量。\n    -   一个**较大**的 $v^{\\max}$ 允许粒子快速穿越搜索空间，促进全局搜索（探索）。然而，如果 $v^{\\max}$ 过大，钳位会变得无效，从而重新带来不稳定和超调（overshooting）的风险。\n-   **边界情况 ($v^{\\max} = 0.0$)：** 这是一个退化的情况。规范要求在 $[-v^{\\max}, v^{\\max}]^d$ 范围内均匀初始化速度，对于 $v^{\\max}=0.0$，这意味着所有初始速度 $v_j(0)$ 均为 $0$。在随后的每次迭代中，速度更新会计算出一个非零的 $v'_{j,k}(t+1)$（除非粒子已经处于 $p_j=g=x_j$ 的点），但钳位算子 $C_{0.0}(\\cdot)$ 会立即将其强制变回 $0$。因此，对于所有 $t>0$，$v_j(t)=0$。结果是 $x_j(t+1) = x_j(t) + 0 = x_j(t)$。粒子永远不会从其初始位置移动。最终的全局最优解将只是在初始随机生成的种群中找到的最佳解。\n\n**定量分析：**\n速度钳位对球面函数 $f(x) = \\sum_{k=1}^d x_k^2$ 收敛速度的影响可以通过考虑粒子的步长来分析。\n-   **远离最优点时：** 当粒子 $j$ 远离位于 $x^\\star = 0$ 的全局最小值时，项 $(p_{j,k} - x_{j,k})$ 和 $(g_k - x_{j,k})$ 可能会很大。这导致未钳位的速度 $v'_{j,k}$ 的量值很大。如果 $|v'_{j,k}| > v^{\\max}$，钳位将生效，设置 $|v_{j,k}| = v^{\\max}$。在这种情况下，粒子向最优点移动的过程不受粒子群动态的限制，而是受硬性限制 $v^{\\max}$ 的制约。收敛速度近似为线性，因为粒子每次迭代移动的距离接近一个常数，欧几里得距离最多为 $\\sqrt{d} \\cdot v^{\\max}$。一个更大的 $v^{\\max}$（例如，用例 2 与用例 1 相比）将允许更快地接近全局最优点的吸引盆。\n-   **接近最优点时：** 随着粒子接近最优点，其位置 $x_j$、其个体最优位置 $p_j$ 和全局最优位置 $g$ 彼此之间以及与 $x^\\star=0$ 都变得接近。差值 $(p_j - x_j)$ 和 $(g - x_j)$ 变小。因此，计算出的速度 $v'_j$ 的量值自然会减小。最终，对于所有分量，都有 $|v'_{j,k}| \\le v^{\\max}$，钳位不再生效。在此阶段，收敛由系数 $w, c_1, c_2$ 所描述的线性系统的特征动态所支配。这些参数的选择决定了最终的收敛速度，以及粒子是会稳定地收敛到最优点还是在其周围振荡。\n-   **认知主导与社会主导（用例 3 与用例 4）：** 对于凸的、单峰的球面函数，一个强的社会拉力（$c_2 > c_1$，用例 4）通常是有益的。它鼓励整个群体迅速收敛到目前为止找到的唯一最佳位置。一个强的认知拉力（$c_1 > c_2$，用例 3）鼓励粒子在它们各自的最优位置周围进行探索，从而促进多样性。虽然这对于多峰问题很有用，但对于像球面函数这样的简单单峰函数，它可能会减慢收敛速度，因为群体不会那么快地聚集。因此，我们预期用例 4 会比用例 3 产生更好（更低）的最终适应度值。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the PSO problem for a suite of test cases.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (c1, c2, v_max)\n    test_cases = [\n        (2.0, 2.0, 0.0),  # Case 0\n        (2.0, 2.0, 0.5),  # Case 1\n        (2.0, 2.0, 2.0),  # Case 2\n        (3.0, 0.5, 1.0),  # Case 3\n        (0.5, 3.0, 1.0),  # Case 4\n        (1.0, 1.0, 1.0),  # Case 5\n    ]\n\n    # Fixed hyperparameters\n    d = 5          # Dimension\n    N = 25         # Swarm size\n    w = 0.7        # Inertia weight\n    T = 100        # Number of iterations\n    R = 5          # Number of replicates\n    x_min, x_max = -5.0, 5.0 # Search space bounds\n\n    # Objective function (Sphere function)\n    def f(x):\n        # x is an (N, d) array of positions\n        return np.sum(x**2, axis=1)\n\n    results = []\n    # Loop through each test case\n    for i, (c1, c2, v_max) in enumerate(test_cases):\n        replicate_best_vals = []\n        \n        # Run R independent replicates for each test case\n        for r in range(R):\n            # Seed the random number generator for reproducibility\n            seed = 1000 + 100 * i + r\n            rng = np.random.default_rng(seed)\n\n            # --- Initialization ---\n            # Initialize positions uniformly in the search space\n            positions = rng.uniform(x_min, x_max, size=(N, d))\n            \n            # Initialize velocities uniformly in [-v_max, v_max]\n            velocities = rng.uniform(-v_max, v_max, size=(N, d))\n            \n            # Initialize personal best positions and values\n            pbest_positions = np.copy(positions)\n            pbest_values = f(pbest_positions)\n            \n            # Initialize global best position and value\n            min_idx = np.argmin(pbest_values)\n            gbest_position = np.copy(pbest_positions[min_idx])\n            gbest_value = pbest_values[min_idx]\n\n            # --- Iterations ---\n            for _ in range(T):\n                # Generate random coefficients for velocity update\n                r1 = rng.random(size=(N, d))\n                r2 = rng.random(size=(N, d))\n                \n                # Update velocities (with inertia, cognitive, and social components)\n                # The gbest_position (1,d) is broadcasted for the subtraction\n                new_velocities = (w * velocities +\n                                  c1 * r1 * (pbest_positions - positions) +\n                                  c2 * r2 * (gbest_position - positions))\n                \n                # Apply velocity clamping\n                velocities = np.clip(new_velocities, -v_max, v_max)\n                \n                # Update positions\n                positions = positions + velocities\n                \n                # Apply position clamping (containment in search space)\n                positions = np.clip(positions, x_min, x_max)\n                \n                # Evaluate new positions\n                current_values = f(positions)\n                \n                # Update personal bests\n                improvement_mask = current_values  pbest_values\n                pbest_positions[improvement_mask] = positions[improvement_mask]\n                pbest_values[improvement_mask] = current_values[improvement_mask]\n                \n                # Update global best\n                min_pbest_idx = np.argmin(pbest_values)\n                if pbest_values[min_pbest_idx]  gbest_value:\n                    gbest_value = pbest_values[min_pbest_idx]\n                    gbest_position = np.copy(pbest_positions[min_pbest_idx])\n            \n            # Store the final global best value for this replicate\n            replicate_best_vals.append(gbest_value)\n            \n        # Compute the average best-found value across replicates for the current case\n        avg_best_value = np.mean(replicate_best_vals)\n        results.append(avg_best_value)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.10f}' for r in results)}]\")\n\nsolve()\n```", "id": "3161041"}, {"introduction": "像粒子群优化这样的元启发式算法的威力在于其出色的适应性。本练习展示了如何将PSO的基本思想从连续空间扩展到离散优化领域，以解决经典的0-1背包问题。你将学习如何将“速度”这一连续概念重新诠释为状态变化的“概率”，这是构建二进制粒子群优化（BPSO）的关键一步。[@problem_id:3161067]", "problem": "要求您从粒子群优化 (PSO) 的基本原理出发，为 $0$-$1$ 背包问题设计并实现一个二进制粒子群优化 (BPSO) 算法。在连续域中，PSO 维护一个包含位置和速度的粒子群，并通过惯性以及对个体最佳和全局最佳的吸引力来使其演化。在位置必须为二进制的离散域中，将速度重新解释为控制比特变化的随机趋势，并推导出一个从速度到比特翻转概率的概率映射。实现最终的算法，并将其应用于一组指定的背包实例。\n\n出发点与要求：\n- 从每个粒子 $i$ 拥有一个位置向量 $x_i \\in \\{0,1\\}^d$ 和一个速度向量 $v_i \\in \\mathbb{R}^d$ 的原理开始。更新必须由一个惯性项以及对粒子个体最佳和群体全局最佳的吸引力来控制。对于每个粒子和每个维度，更新必须通过在 $\\left[0,1\\right]$ 范围内的独立均匀随机变量来实现随机性。\n- 在离散设置中，将速度重新解释为决定比特翻转概率的参数。基于经过充分检验的数学函数，选择一个从 $\\mathbb{R}$到$\\left(0,1\\right)$的平滑、单调映射，并推导出一个映射 $p_j$，使得翻转比特 $j$ 的概率为 $p_j$。然后，通过以概率 $p_j$ 翻转 $x_{ij}$，否则保持 $x_{ij}$ 不变的方式来更新每个比特。确保您的映射是无量纲的，并且在 $\\lvert v_{ij} \\rvert$ 增大时能适当地饱和。\n- 对于 $0$-$1$ 背包目标，设有物品重量 $w_j$、价值 $u_j$ 和容量 $C$。可行目标为 $\\sum_{j=1}^{d} u_j x_j$，约束条件为 $\\sum_{j=1}^{d} w_j x_j \\le C$。为处理搜索过程中的不可行解，使用一个惩罚目标函数，该函数会减去一个与容量超出量平方成正比的惩罚项。具体而言，对于一个候选解 $x$，计算惩罚目标 $F(x) = \\sum_{j=1}^{d} u_j x_j - \\lambda \\cdot \\max\\!\\left(0, \\sum_{j=1}^{d} w_j x_j - C\\right)^2$，其中 $\\lambda$ 是一个正的惩罚系数。您的程序最终必须返回发现的最佳可行目标值（而不是惩罚后的值）。如果在迭代预算内没有发现可行解，则返回 $0$。\n- 通过使用在所有测试用例中共享的单个伪随机数生成器种子 $42$ 来固定所有随机性，并在每次迭代中为每个粒子和每个维度进行独立的均匀随机抽样。\n- 使用 PSO 超参数：惯性权重 $w = 0.7$，认知系数 $c_1 = 1.6$，社会系数 $c_2 = 1.6$，速度限制 $v_{\\min} = -4$ 和 $v_{\\max} = 4$，种群规模 $N = 60$ 个粒子，迭代预算 $T = 300$，以及惩罚系数 $\\lambda = 100$。\n\n测试套件：\n在以下四个背包实例上实现您的算法。在所有情况下，$d$ 等于物品列表的长度。\n1. 案例 A（一般情况，中等规模）：\n   - 重量 $[2,3,5,7,1,4,1]$\n   - 价值 $[10,5,15,7,6,18,3]$\n   - 容量 $15$\n2. 案例 B（边界情况：容量非常小）：\n   - 重量 $[5,8,3]$\n   - 价值 $[9,11,4]$\n   - 容量 $4$\n3. 案例 C（边界情况：容量大于总重量）：\n   - 重量 $[1,1,1,1]$\n   - 价值 $[2,2,2,2]$\n   - 容量 $10$\n4. 案例 D（边缘情况：多个价值相等的最佳子集）：\n   - 重量 $[3,2,2,1]$\n   - 价值 $[5,3,3,2]$\n   - 容量 $5$\n\n实现细节和评估：\n- 将位置表示为 $0$-$1$ 向量，速度表示为实数向量。使用惯性和对个体最佳及全局最佳的随机吸引力来更新每个维度的速度。每次更新后将速度限制在 $[v_{\\min}, v_{\\max}]$ 范围内。\n- 推导并使用一个从速度到比特翻转概率的概率映射，该映射应平滑、关于速度单调，并将 $\\mathbb{R}$ 映射到 $(0,1)$；然后相应地执行随机比特翻转。\n- 评估惩罚目标 $F(x)$ 以更新个体最佳和全局最佳。在每次迭代中，同时跟踪迄今为止观察到的最佳可行目标 $\\sum u_j x_j$；这是每个测试用例需要报告的数值。\n\n要求的最终输出格式：\n您的程序应生成单行输出，其中包含四个案例的最佳可行目标值，格式为逗号分隔并用方括号括起来的列表，例如 $[v_A,v_B,v_C,v_D]$，其中 $v_A$、$v_B$、$v_C$ 和 $v_D$ 是整数。输出必须仅占一行，并采用此方括号逗号分隔格式。", "solution": "所述问题是有效的，因为它描述了优化方法领域内一个定义明确的计算任务。它要求为 $0$-$1$ 背包问题设计并实现一个二进制粒子群优化 (BPSO) 算法。所有必要的参数和测试用例都已提供。任务的一个关键部分是推导从粒子的连续速度到其位置的离散二进制变化的映射。这个推导过程需要仔细考虑，以确保最终算法的动态特性是合理的。\n\n我们从粒子群优化 (PSO) 的基本原理开始。一个由 $N$ 个粒子组成的粒子群在一个 $d$ 维搜索空间中进行探索。对于有 $d$ 个物品的 $0$-$1$ 背包问题，每个粒子 $i$ 有一个位置向量 $\\mathbf{x}_i \\in \\{0, 1\\}^d$，其中 $x_{ij} = 1$ 表示物品 $j$ 被放入背包，而 $x_{ij} = 0$ 表示未被放入。每个粒子还有一个速度向量 $\\mathbf{v}_i \\in \\mathbb{R}^d$，它影响粒子在搜索空间中的移动。\n\nPSO 的核心是一个迭代过程，其中粒子根据自身找到的最佳解和整个群体找到的最佳解来调整其速度。在迭代 $t+1$ 时，粒子 $i$ 在维度 $j$ 上的速度更新公式为：\n$$v_{ij}(t+1) = w v_{ij}(t) + c_1 r_{1j}(t) (\\text{pbest}_{ij} - x_{ij}(t)) + c_2 r_{2j}(t) (\\text{gbest}_j - x_{ij}(t))$$\n其中：\n- $w = 0.7$ 是惯性权重，控制先前速度的影响。\n- $c_1 = 1.6$ 和 $c_2 = 1.6$ 分别是认知系数和社会系数，用于衡量对个体最佳和全局最佳位置的吸引力权重。\n- $r_{1j}(t)$ 和 $r_{2j}(t)$ 是在每次迭代中为每个粒子和每个维度从均匀分布 $U(0, 1)$ 中独立抽取的随机数。\n- $\\mathbf{pbest}_i$ 是粒子 $i$ 迄今为止找到的个体最佳位置。\n- $\\mathbf{gbest}$ 是群体中任何粒子迄今为止找到的全局最佳位置。\n- $x_{ij}(t)$ 是当前的位置比特。\n\n每次更新后，速度 $v_{ij}$ 被限制在范围 $[v_{\\min}, v_{\\max}]$ 内，即 $[-4, 4]$，以防止不受控制的发散。\n\nBPSO 的关键步骤是将连续速度 $v_{ij}$ 转换为二进制位置 $x_{ij}$ 的变化。问题要求建立一个到“翻转概率”的映射。一种字面解释，即将翻转比特 $x_{ij}$ 的概率由 $v_{ij}$ 的单调函数（例如 sigmoid 函数）确定，会导致有缺陷的动态特性。例如，如果 $x_{ij}=1$ 且目标（例如 $\\text{pbest}_{ij}$）是 $0$，则速度 $v_{ij}$ 会变为负数。此时，sigmoid 映射 $P(\\text{flip}) = S(v_{ij})$ 会产生一个低的翻转概率，从而阻碍粒子向更优解移动。\n\n因此，一种更符合原理且功能上正确的方法是，将速度解释为控制比特处于状态 $1$ 的概率，这种方法与 Kennedy 和 Eberhart 提出的经典 BPSO 模型一致。我们选择逻辑 S 型函数（logistic sigmoid function）进行此映射，因为它平滑、单调，并将 $\\mathbb{R}$ 映射到 $(0, 1)$，满足所有问题约束：\n$$S(v) = \\frac{1}{1 + e^{-v}}$$\n然后，位置更新规则定义如下：对每个维度 $j$，抽取一个随机数 $r_{3j} \\sim U(0,1)$。根据概率 $S(v_{ij}(t+1))$ 设置新的比特 $x_{ij}(t+1)$：\n$$x_{ij}(t+1) = \\begin{cases} 1  \\text{若 } r_{3j}  S(v_{ij}(t+1)) \\\\ 0  \\text{否则} \\end{cases}$$\n这种公式能正确引导粒子群：大的正速度会增加比特为 $1$ 的概率，而大的负速度会增加其为 $0$ 的概率。\n\n为处理背包容量约束 $\\sum_{j=1}^{d} w_j x_j \\le C$，我们使用惩罚方法。潜在解 $\\mathbf{x}$ 的适应度通过一个惩罚目标函数 $F(\\mathbf{x})$ 来评估，粒子群的目标是最大化该函数。此函数定义为总价值减去一个与容量超出量平方成正比的惩罚项：\n$$F(\\mathbf{x}) = \\left(\\sum_{j=1}^{d} u_j x_j\\right) - \\lambda \\cdot \\max\\left(0, \\left(\\sum_{j=1}^{d} w_j x_j\\right) - C\\right)^2$$\n惩罚系数为 $\\lambda = 100$。个体最佳 $\\mathbf{pbest}_i$ 和全局最佳 $\\mathbf{gbest}$ 基于此惩罚适应度值 $F(\\mathbf{x})$进行更新。\n\n在整个搜索过程中，我们还必须跟踪找到的最佳*可行*解。一个单独的变量存储满足容量约束的位置 $\\mathbf{x}$ 所能达到的最高目标值 $\\sum u_j x_j$。这是需要报告的值。如果在 $T=300$ 次迭代后没有找到可行解，则结果为 $0$。\n\n整个算法流程如下：\n1.  **初始化**：设置随机种子为 $42$。对于一个包含 $N=60$ 个粒子的粒子群，在 $\\{0, 1\\}^d$ 中随机初始化位置 $\\mathbf{x}_i$，并将速度 $\\mathbf{v}_i$ 初始化为零。为每个粒子评估初始的惩罚适应度 $F(\\mathbf{x}_i)$。设置 $\\mathbf{pbest}_i = \\mathbf{x}_i$。通过找到具有最高初始适应度的粒子来确定初始的 $\\mathbf{gbest}$。将迄今为止找到的最佳可行值初始化为 $0$（或初始种群中最佳可行解的值）。\n2.  **迭代**：对于 $t = 1, \\dots, T$：\n    a. 对每个粒子 $i = 1, \\dots, N$：\n        i. 使用 PSO 更新方程更新速度向量 $\\mathbf{v}_i$ 的每个分量 $v_{ij}$，并将其限制在 $[-4, 4]$ 范围内。\n        ii. 使用 sigmoid 映射和随机抽样更新位置向量 $\\mathbf{x}_i$ 的每个分量 $x_{ij}$。\n    b. 评估所有粒子新位置的惩罚适应度 $F(\\mathbf{x}_i)$。\n    c. 对每个粒子，如果其新适应度大于其个体最佳适应度，则更新 $\\mathbf{pbest}_i$ 及其相关适应度。\n    d. 通过在整个群体中选择最佳的 $\\mathbf{pbest}_i$ 来确定新的 $\\mathbf{gbest}$。\n    e. 检查所有新位置的可行性。如果一个可行位置产生的价值高于当前已知的最佳可行值，则更新后者。\n3.  **终止**：经过 $T$ 次迭代后，算法终止。最终结果是记录的最佳可行值。\n此过程将应用于四个指定的背包实例中的每一个。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import expit as sigmoid\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and run the BPSO algorithm for each.\n    The final print statement produces the required single-line output.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A\n        {\n            \"weights\": np.array([2, 3, 5, 7, 1, 4, 1]),\n            \"values\": np.array([10, 5, 15, 7, 6, 18, 3]),\n            \"capacity\": 15\n        },\n        # Case B\n        {\n            \"weights\": np.array([5, 8, 3]),\n            \"values\": np.array([9, 11, 4]),\n            \"capacity\": 4\n        },\n        # Case C\n        {\n            \"weights\": np.array([1, 1, 1, 1]),\n            \"values\": np.array([2, 2, 2, 2]),\n            \"capacity\": 10\n        },\n        # Case D\n        {\n            \"weights\": np.array([3, 2, 2, 1]),\n            \"values\": np.array([5, 3, 3, 2]),\n            \"capacity\": 5\n        }\n    ]\n\n    # PSO hyperparameters as specified in the problem\n    params = {\n        \"swarm_size\": 60,\n        \"iterations\": 300,\n        \"inertia_weight\": 0.7,\n        \"cognitive_coeff\": 1.6,\n        \"social_coeff\": 1.6,\n        \"v_min\": -4.0,\n        \"v_max\": 4.0,\n        \"penalty_coeff\": 100.0,\n        \"seed\": 42\n    }\n\n    # Set the global seed for reproducibility across all test cases\n    np.random.seed(params[\"seed\"])\n\n    results = []\n    for case in test_cases:\n        best_value = run_bpso(\n            case[\"weights\"],\n            case[\"values\"],\n            case[\"capacity\"],\n            params\n        )\n        results.append(best_value)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\n\ndef run_bpso(weights, values, capacity, params):\n    \"\"\"\n    Executes the Binary Particle Swarm Optimization for a single knapsack instance.\n    \"\"\"\n    d = len(weights)\n    N = params[\"swarm_size\"]\n    T = params[\"iterations\"]\n    w = params[\"inertia_weight\"]\n    c1 = params[\"cognitive_coeff\"]\n    c2 = params[\"social_coeff\"]\n    v_min = params[\"v_min\"]\n    v_max = params[\"v_max\"]\n    lambda_ = params[\"penalty_coeff\"]\n\n    # 1. Initialization\n    # Initialize positions: N particles, d dimensions.\n    positions = np.random.randint(0, 2, size=(N, d))\n    # Initialize velocities to zero arrays.\n    velocities = np.zeros((N, d), dtype=float)\n    \n    # Initialize personal best positions and fitness\n    pbest_positions = np.copy(positions)\n    \n    # Evaluate initial fitness using the penalized objective function\n    total_values = positions @ values\n    total_weights = positions @ weights\n    violations = np.maximum(0, total_weights - capacity)\n    pbest_fitness = total_values - lambda_ * (violations ** 2)\n\n    # Initialize global best position and its fitness from personal bests\n    gbest_idx = np.argmax(pbest_fitness)\n    gbest_position = np.copy(pbest_positions[gbest_idx])\n    gbest_fitness = pbest_fitness[gbest_idx]\n\n    # Initialize tracker for the best feasible objective value found so far\n    best_feasible_value = 0\n    feasible_mask = (total_weights = capacity)\n    if np.any(feasible_mask):\n        best_feasible_value = np.max(total_values[feasible_mask])\n\n    # 2. Main PSO Loop\n    for _ in range(T):\n        # Generate random numbers for velocity update (one matrix for c1, one for c2)\n        r1 = np.random.rand(N, d)\n        r2 = np.random.rand(N, d)\n\n        # Update velocities based on inertia, personal best, and global best\n        velocities = (w * velocities +\n                      c1 * r1 * (pbest_positions - positions) +\n                      c2 * r2 * (gbest_position - positions))\n        \n        # Clamp velocities to the range [v_min, v_max]\n        np.clip(velocities, v_min, v_max, out=velocities)\n        \n        # Update positions using the sigmoid function\n        prob_one = sigmoid(velocities)\n        rand_matrix = np.random.rand(N, d)\n        positions = (rand_matrix  prob_one).astype(int)\n        \n        # Evaluate fitness of new positions\n        current_values = positions @ values\n        current_weights = positions @ weights\n        current_violations = np.maximum(0, current_weights - capacity)\n        current_fitness = current_values - lambda_ * (current_violations ** 2)\n        \n        # Update personal bests\n        update_mask = current_fitness  pbest_fitness\n        pbest_positions[update_mask] = positions[update_mask]\n        pbest_fitness[update_mask] = current_fitness[update_mask]\n\n        # Update global best\n        current_gbest_idx = np.argmax(pbest_fitness)\n        if pbest_fitness[current_gbest_idx]  gbest_fitness:\n            gbest_fitness = pbest_fitness[current_gbest_idx]\n            gbest_position = np.copy(pbest_positions[current_gbest_idx])\n        \n        # Update the best feasible objective value found so far\n        feasible_mask = (current_weights = capacity)\n        if np.any(feasible_mask):\n            max_feasible_in_iter = np.max(current_values[feasible_mask])\n            if max_feasible_in_iter  best_feasible_value:\n                best_feasible_value = max_feasible_in_iter\n    \n    return int(best_feasible_value)\n\nsolve()\n```", "id": "3161067"}]}