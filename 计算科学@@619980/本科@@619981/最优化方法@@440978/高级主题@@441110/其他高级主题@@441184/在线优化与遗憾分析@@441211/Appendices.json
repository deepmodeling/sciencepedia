{"hands_on_practices": [{"introduction": "在线梯度下降（Online Gradient Descent, OGD）是在线凸优化的基石。这个实践旨在巩固你对该核心算法的理解，它要求你不仅从第一性原理出发，推导出经典的 $O(\\sqrt{T})$ 遗憾上界，还要通过编写代码，在模拟环境中亲手验证这一理论界限。完成这项练习将为你深入理解学习率、问题参数与算法性能之间的权衡关系打下坚实基础。", "problem": "考虑在线凸优化（Online Convex Optimization, OCO）的设定。设决策集为以原点为中心、半径为 $R > 0$ 的闭欧几里得球 $\\mathcal{X} = \\{x \\in \\mathbb{R}^d : \\lVert x \\rVert_2 \\le R\\}$。在每一轮 $t \\in \\{1,2,\\dots,T\\}$，在线学习器选择一个点 $x_t \\in \\mathcal{X}$，之后对手揭示一个凸损失函数 $f_t : \\mathcal{X} \\to \\mathbb{R}$。该函数关于欧几里得范数是 $G$-利普希茨（$G$-Lipschitz）的，即对于所有 $x \\in \\mathcal{X}$，每个次梯度 $g_t \\in \\partial f_t(x)$ 都满足 $\\lVert g_t \\rVert_2 \\le G$，其中 $G > 0$。学习器产生损失 $f_t(x_t)$。$T$ 轮后的累积遗憾（cumulative regret）定义为\n$$\n\\mathrm{Regret}_T \\triangleq \\sum_{t=1}^T f_t(x_t) - \\min_{x \\in \\mathcal{X}} \\sum_{t=1}^T f_t(x).\n$$\n学习器使用在线次梯度下降（Online Subgradient Descent，也称为投影次梯度下降 Projected Subgradient Descent）：从 $x_1 = 0$ 开始，对于选定的步长 $\\eta > 0$，更新规则为\n$$\nx_{t+1} = \\Pi_{\\mathcal{X}}\\big(x_t - \\eta \\, g_t\\big),\n$$\n其中 $g_t \\in \\partial f_t(x_t)$ 是在 $x_t$ 处的一个次梯度，$\\Pi_{\\mathcal{X}}$ 表示到集合 $\\mathcal{X}$ 上的欧几里得投影。\n\n任务：\n1) 从凸性、次梯度和欧几里得投影的定义出发，推导 $\\mathrm{Regret}_T$ 的一个非渐近上界，该上界对 $T$ 表现出次线性依赖关系。假设步长 $\\eta$ 是一个常数，你需要将其选择为 $R$、$G$ 和 $T$ 的函数。你的推导必须仅依赖于基本事实：凸函数的次梯度不等式、欧几里得投影的非扩张性以及初等代数恒等式。你的最终界限必须用 $R$、$G$ 和 $T$ 显式表示，并且其缩放级别应为 $O(\\sqrt{T})$。\n\n2) 实现一个程序，在形如 $f_t(x) = g_t^\\top x$ 且 $\\lVert g_t \\rVert_2 \\le G$ 的合成线性损失族上实例化上述算法，并通过数值方式验证在几个测试案例中，观测到的遗憾受你推导的理论上界的约束。对于线性损失，你必须通过欧几里得球上最小化点的闭式解来精确计算比较器 $\\arg\\min_{x \\in \\mathcal{X}} \\sum_{t=1}^T f_t(x)$，从而计算精确的遗憾。使用你在任务1中选择的恒定步长 $\\eta$。\n\n使用以下测试套件。在每个案例中，常数 $G$ 表示 $g_t$ 的范数界，维度为 $d$，时限为 $T$，球半径为 $R$。所有随机数生成必须使用给定的种子来保证可复现性，并且每个生成的 $g_t$ 都必须满足 $\\lVert g_t \\rVert_2 = G$。\n\n- A情况（理想路径，随机化）：$d = 5$, $R = 3.0$, $G = 2.0$, $T = 400$。通过从具有独立分量且方差为1的零均值正态分布中采样生成每个 $g_t$，然后归一化为单位欧几里得范数并缩放至范数 $G$。对随机数生成器使用种子 $0$。\n\n- B情况（边界，单步）：$d = 3$, $R = 1.0$, $G = 1.0$, $T = 1$。使用确定性次梯度 $g_1 = G \\cdot e_1$，其中 $e_1$ 是 $\\mathbb{R}^d$ 中的第一个标准基向量。\n\n- C情况（对抗性，方向跟随迭代）：$d = 7$, $R = 2.0$, $G = 1.5$, $T = 600$。对于 $t \\ge 1$，定义 $g_t = G \\cdot \\frac{x_t}{\\max(\\lVert x_t \\rVert_2, 10^{-12})}$，并约定如果 $\\lVert x_t \\rVert_2 = 0$，则 $g_t = G \\cdot e_1$。\n\n- D情况（交替固定方向，近似抵消的和）：$d = 10$, $R = 2.0$, $G = 3.0$, $T = 2500$。使用种子 $42$，从具有独立分量且方差为1的零均值正态分布中抽取一个固定的非零向量 $u \\in \\mathbb{R}^d$，然后设置 $u \\leftarrow u / \\lVert u \\rVert_2$。对于奇数 $t$，设置 $g_t = G u$；对于偶数 $t$，设置 $g_t = -G u$。\n\n- E情况（强梯度，频繁投影到边界）：$d = 2$, $R = 0.5$, $G = 10.0$, $T = 200$。与A情况完全一样地生成每个 $g_t$，使用种子 $123$。\n\n对于每个案例，使用 $x_1 = 0$ 和你的恒定步长 $\\eta$ 运行在线次梯度下降，计算精确的遗憾 $\\mathrm{Regret}_T$，并将其与你得到的关于 $R$、$G$ 和 $T$ 的显式上界函数进行比较。确定一个布尔结果，当且仅当 $\\mathrm{Regret}_T \\le \\text{Bound}(R,G,T) + \\varepsilon$ 时，该结果为真，其中 $\\varepsilon = 10^{-9}$。\n\n最终输出格式要求：\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，“[result1,result2,result3]”），其中每个结果是按A、B、C、D、E顺序对应的案例的布尔值。不允许有其他输出。", "solution": "为在线次梯度下降算法推导遗憾界是在线凸优化分析中的一个标准任务。该问题陈述是有效的，因为它科学地基于已建立的优化理论，问题提法是适定的（well-posed），并且是客观的。我们着手处理这两项任务。\n\n### 任务1：遗憾界的推导\n\n我们的目标是推导遗憾的上界，其定义为 $\\mathrm{Regret}_T \\triangleq \\sum_{t=1}^T f_t(x_t) - \\min_{x \\in \\mathcal{X}} \\sum_{t=1}^T f_t(x)$。令 $x^* = \\arg\\min_{x \\in \\mathcal{X}} \\sum_{t=1}^T f_t(x)$ 为一个事后最优解。由于每个 $f_t$ 都是凸函数，它们的和也是凸函数，并且由于定义域 $\\mathcal{X}$ 是紧集，这样的最小化点 $x^*$ 保证存在。遗憾可以重写为 $\\mathrm{Regret}_T = \\sum_{t=1}^T f_t(x_t) - \\sum_{t=1}^T f_t(x^*)$。\n\n推导过程依赖于三个基本性质：\n1.  **次梯度不等式：** 对于凸函数 $f_t$ 和任意次梯度 $g_t \\in \\partial f_t(x_t)$，我们有 $f_t(x_t) - f_t(x^*) \\le g_t^\\top(x_t - x^*)$。\n2.  **投影性质：** 欧几里得投影算子 $\\Pi_{\\mathcal{X}}$ 是非扩张的。对于任意 $y \\in \\mathbb{R}^d$ 和任意 $z \\in \\mathcal{X}$，一个关键推论是 $\\lVert \\Pi_{\\mathcal{X}}(y) - z \\rVert_2^2 \\le \\lVert y - z \\rVert_2^2$。\n3.  **利普希茨条件：** 损失函数是 $G$-利普希茨的，这意味着任意次梯度 $g_t \\in \\partial f_t(x)$ 的欧几里得范数有界，即 $\\lVert g_t \\rVert_2 \\le G$。\n\n让我们分析迭代点 $x_t$ 与固定最优点 $x^*$ 之间的距离。更新规则为 $x_{t+1} = \\Pi_{\\mathcal{X}}(x_t - \\eta g_t)$。考虑平方欧几里得距离 $\\lVert x_{t+1} - x^* \\rVert_2^2$。由于 $x^* \\in \\mathcal{X}$，我们可以应用投影性质：\n$$\n\\lVert x_{t+1} - x^* \\rVert_2^2 = \\lVert \\Pi_{\\mathcal{X}}(x_t - \\eta g_t) - x^* \\rVert_2^2 \\le \\lVert (x_t - \\eta g_t) - x^* \\rVert_2^2\n$$\n使用恒等式 $\\lVert a - b \\rVert_2^2 = \\lVert a \\rVert_2^2 - 2a^\\top b + \\lVert b \\rVert_2^2$ 展开右侧项：\n$$\n\\lVert (x_t - x^*) - \\eta g_t \\rVert_2^2 = \\lVert x_t - x^* \\rVert_2^2 - 2\\eta g_t^\\top(x_t - x^*) + \\eta^2 \\lVert g_t \\rVert_2^2\n$$\n结合这些不等式，我们得到：\n$$\n\\lVert x_{t+1} - x^* \\rVert_2^2 \\le \\lVert x_t - x^* \\rVert_2^2 - 2\\eta g_t^\\top(x_t - x^*) + \\eta^2 \\lVert g_t \\rVert_2^2\n$$\n这个不等式是分析的核心。我们对其进行重排，以分离出出现在次梯度不等式中的项 $g_t^\\top(x_t - x^*)$：\n$$\n2\\eta g_t^\\top(x_t - x^*) \\le \\lVert x_t - x^* \\rVert_2^2 - \\lVert x_{t+1} - x^* \\rVert_2^2 + \\eta^2 \\lVert g_t \\rVert_2^2\n$$\n两边除以 $2\\eta$（因为 $\\eta > 0$）：\n$$\ng_t^\\top(x_t - x^*) \\le \\frac{1}{2\\eta} \\left( \\lVert x_t - x^* \\rVert_2^2 - \\lVert x_{t+1} - x^* \\rVert_2^2 \\right) + \\frac{\\eta}{2} \\lVert g_t \\rVert_2^2\n$$\n现在，我们应用次梯度不等式 $f_t(x_t) - f_t(x^*) \\le g_t^\\top(x_t - x^*)$ 来约束每轮的遗憾：\n$$\nf_t(x_t) - f_t(x^*) \\le \\frac{1}{2\\eta} \\left( \\lVert x_t - x^* \\rVert_2^2 - \\lVert x_{t+1} - x^* \\rVert_2^2 \\right) + \\frac{\\eta}{2} \\lVert g_t \\rVert_2^2\n$$\n为了得到总遗憾，我们将此不等式从 $t=1$ 到 $T$ 求和：\n$$\n\\sum_{t=1}^T (f_t(x_t) - f_t(x^*)) \\le \\sum_{t=1}^T \\left[ \\frac{1}{2\\eta} \\left( \\lVert x_t - x^* \\rVert_2^2 - \\lVert x_{t+1} - x^* \\rVert_2^2 \\right) + \\frac{\\eta}{2} \\lVert g_t \\rVert_2^2 \\right]\n$$\n左边恰好是 $\\mathrm{Regret}_T$。右边可以分成两个和：\n$$\n\\mathrm{Regret}_T \\le \\frac{1}{2\\eta} \\sum_{t=1}^T \\left( \\lVert x_t - x^* \\rVert_2^2 - \\lVert x_{t+1} - x^* \\rVert_2^2 \\right) + \\frac{\\eta}{2} \\sum_{t=1}^T \\lVert g_t \\rVert_2^2\n$$\n第一个求和是一个伸缩级数：\n$$\n\\sum_{t=1}^T \\left( \\lVert x_t - x^* \\rVert_2^2 - \\lVert x_{t+1} - x^* \\rVert_2^2 \\right) = (\\lVert x_1 - x^* \\rVert_2^2 - \\lVert x_2 - x^* \\rVert_2^2) + \\dots + (\\lVert x_T - x^* \\rVert_2^2 - \\lVert x_{T+1} - x^* \\rVert_2^2) = \\lVert x_1 - x^* \\rVert_2^2 - \\lVert x_{T+1} - x^* \\rVert_2^2\n$$\n由于 $\\lVert x_{T+1} - x^* \\rVert_2^2 \\ge 0$，我们可以用 $\\lVert x_1 - x^* \\rVert_2^2$ 来作为这个伸缩求和的上界。\n遗憾界变为：\n$$\n\\mathrm{Regret}_T \\le \\frac{1}{2\\eta} \\lVert x_1 - x^* \\rVert_2^2 + \\frac{\\eta}{2} \\sum_{t=1}^T \\lVert g_t \\rVert_2^2\n$$\n我们现在使用问题中的具体条件。初始点为 $x_1 = 0$。比较器 $x^*$ 在决策集 $\\mathcal{X} = \\{x \\in \\mathbb{R}^d : \\lVert x \\rVert_2 \\le R\\}$ 中，所以 $\\lVert x^* \\rVert_2 \\le R$。因此，$\\lVert x_1 - x^* \\rVert_2^2 = \\lVert 0 - x^* \\rVert_2^2 = \\lVert x^* \\rVert_2^2 \\le R^2$。次梯度有界为 $G$，所以对于所有 $t$，$\\lVert g_t \\rVert_2^2 \\le G^2$。代入这些可得：\n$$\n\\mathrm{Regret}_T \\le \\frac{R^2}{2\\eta} + \\frac{\\eta}{2} \\sum_{t=1}^T G^2 = \\frac{R^2}{2\\eta} + \\frac{\\eta T G^2}{2}\n$$\n这个界对任何恒定步长 $\\eta > 0$ 都成立。为了实现关于 $T$ 的次线性遗憾，我们必须将 $\\eta$ 选择为 $T$ 的函数。我们选择 $\\eta$ 来最小化这个上界。令 $B(\\eta) = \\frac{R^2}{2\\eta} + \\frac{\\eta T G^2}{2}$。我们通过将关于 $\\eta$ 的导数设为零来找到最小值：\n$$\n\\frac{dB}{d\\eta} = -\\frac{R^2}{2\\eta^2} + \\frac{TG^2}{2} = 0 \\implies \\eta^2 = \\frac{R^2}{TG^2} \\implies \\eta = \\frac{R}{G\\sqrt{T}}\n$$\n将这个最优的恒定步长代回遗憾界：\n$$\n\\mathrm{Regret}_T \\le \\frac{R^2}{2} \\left( \\frac{G\\sqrt{T}}{R} \\right) + \\frac{T G^2}{2} \\left( \\frac{R}{G\\sqrt{T}} \\right) = \\frac{RG\\sqrt{T}}{2} + \\frac{RG\\sqrt{T}}{2} = RG\\sqrt{T}\n$$\n因此，遗憾的一个非渐近上界是 $\\mathrm{Regret}_T \\le RG\\sqrt{T}$。这个界限表现出所要求的对时间范围 $T$ 的次线性 $O(\\sqrt{T})$ 依赖关系。对于我们的数值验证，我们将使用步长 $\\eta = \\frac{R}{G\\sqrt{T}}$ 和上界 $\\mathrm{Bound}(R, G, T) = RG\\sqrt{T}$。\n\n### 任务2：实现和数值验证\n\n实现遵循在线次梯度下降算法。对于每个测试案例，我们使用指定的参数和次梯度生成规则模拟在线学习过程的 $T$ 轮。我们计算精确的遗憾，并验证它小于或等于推导出的理论上界 $RG\\sqrt{T}$ 加上一个小的容差 $\\varepsilon = 10^{-9}$。\n\n对于线性损失 $f_t(x) = g_t^\\top x$，累积损失为 $\\sum_{t=1}^T f_t(x) = (\\sum_{t=1}^T g_t)^\\top x$。比较器的累积损失是 $\\min_{x \\in \\mathcal{X}} (\\sum_{t=1}^T g_t)^\\top x$。令 $S = \\sum_{t=1}^T g_t$。我们想要在 $\\lVert x \\rVert_2 \\le R$ 的约束下最小化 $S^\\top x$。当 $x$ 的方向与 $S$ 相反且位于球的边界上时，达到最小值。最小化点为 $x^* = -R \\frac{S}{\\lVert S \\rVert_2}$（如果 $S \\neq 0$）。最小损失为 $S^\\top x^* = -R \\frac{S^\\top S}{\\lVert S \\rVert_2} = -R \\lVert S \\rVert_2$。如果 $S=0$，则任何 $x \\in \\mathcal{X}$ 都是最小化点，最小损失为 $0$。\n\n以下代码为所有测试案例实现了这个过程。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_simulation(d: int, R: float, G: float, T: int, case: str, seed: int | None) -> bool:\n    \"\"\"\n    Runs one instance of the Online Subgradient Descent simulation.\n\n    Args:\n        d: Dimension of the space.\n        R: Radius of the Euclidean ball.\n        G: Lipschitz constant (norm bound on subgradients).\n        T: Time horizon (number of rounds).\n        case: A string identifying the test case ('A', 'B', 'C', 'D', 'E').\n        seed: Random seed for reproducibility.\n\n    Returns:\n        A boolean indicating if the observed regret is within the theoretical bound.\n    \"\"\"\n    if seed is not None:\n        rng = np.random.default_rng(seed)\n\n    # Optimal constant step size from the theoretical derivation\n    if T > 0:\n        eta = R / (G * np.sqrt(T))\n    else: # Handle T=0 case, though not in test suite.\n        eta = 0.0\n\n    # Initialization\n    x = np.zeros(d)  # Initial iterate x_1 = 0\n    learner_loss = 0.0\n    sum_g = np.zeros(d)\n\n    # Pre-computation for case D\n    if case == 'D':\n        u_vec = rng.normal(size=d)\n        u_norm = np.linalg.norm(u_vec)\n        if u_norm > 1e-15:\n            u = u_vec / u_norm\n        else:  # Fallback for the highly unlikely event of a zero vector\n            u = np.zeros(d)\n            u[0] = 1.0\n\n    # Main OCO loop for T rounds\n    for t in range(1, T + 1):\n        # 1. Adversary reveals subgradient g_t at x_t (current x)\n        if case == 'A' or case == 'E':\n            g_vec = rng.normal(size=d)\n            g_norm = np.linalg.norm(g_vec)\n            if g_norm > 1e-15:\n                g = G * g_vec / g_norm\n            else: # Fallback\n                g = np.zeros(d)\n                g[0] = G\n        elif case == 'B':\n            g = np.zeros(d)\n            g[0] = G\n        elif case == 'C':\n            x_norm = np.linalg.norm(x)\n            if x_norm == 0:  # Convention for x_t = 0\n                g = np.zeros(d)\n                g[0] = G\n            else:\n                g = G * x / max(x_norm, 1e-12)\n        elif case == 'D':\n            if t % 2 == 1:  # Odd t\n                g = G * u\n            else:  # Even t\n                g = -G * u\n        else:\n            raise ValueError(f\"Unknown case: {case}\")\n        \n        # 2. Learner incurs loss f_t(x_t) = g_t^T x_t\n        learner_loss += g @ x\n\n        # 3. Update sum of gradients for comparator calculation\n        sum_g += g\n\n        # 4. Learner computes next iterate x_{t+1}\n        # Unprojected update\n        y = x - eta * g\n        # Projection onto the Euclidean ball\n        y_norm = np.linalg.norm(y)\n        if y_norm > R:\n            x = R * y / y_norm\n        else:\n            x = y\n    \n    # After T rounds, calculate the exact regret\n    # 1. Calculate the comparator's total loss\n    sum_g_norm = np.linalg.norm(sum_g)\n    if sum_g_norm > 1e-12:\n        # x_star = -R * sum_g / sum_g_norm\n        # comparator_loss = sum_g @ x_star = -R * ||sum_g||_2\n        comparator_loss = -R * sum_g_norm\n    else:\n        comparator_loss = 0.0\n\n    # 2. Compute the final regret\n    regret = learner_loss - comparator_loss\n\n    # 3. Compute the theoretical upper bound\n    bound = R * G * np.sqrt(T)\n    \n    # 4. Verify if regret is within the bound, with a small numerical tolerance\n    epsilon = 1e-9\n    return regret <= bound + epsilon\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = [\n        {'d': 5, 'R': 3.0, 'G': 2.0, 'T': 400, 'case': 'A', 'seed': 0},\n        {'d': 3, 'R': 1.0, 'G': 1.0, 'T': 1, 'case': 'B', 'seed': None},\n        {'d': 7, 'R': 2.0, 'G': 1.5, 'T': 600, 'case': 'C', 'seed': None},\n        {'d': 10, 'R': 2.0, 'G': 3.0, 'T': 2500, 'case': 'D', 'seed': 42},\n        {'d': 2, 'R': 0.5, 'G': 10.0, 'T': 200, 'case': 'E', 'seed': 123},\n    ]\n\n    results = []\n    for params in test_cases:\n        is_bounded = run_simulation(**params)\n        results.append(is_bounded)\n\n    # Format the final output as a comma-separated list of booleans in lowercase.\n    # Python str(bool) gives 'True', 'False'; problem example is ambiguous.\n    # Standard practice often uses lowercase for JSON/API-style booleans.\n    # To be safe and explicit, we will use lowercase strings.\n    print(f\"[{','.join(map(lambda b: str(b).lower(), results))}]\")\n\nsolve()\n```", "id": "3188888"}, {"introduction": "标准的在线梯度下降在欧氏空间中表现出色，但当决策空间具有特殊几何结构（如概率单纯形）时，我们需要更精巧的工具。本实践将引导你探索镜像下降（Mirror Descent），这是一种强大的泛化方法，它利用“镜像映射”来更好地匹配问题的几何特性。你将实现指数梯度算法（Exponentiated Gradient），这是镜像下降在熵正则化下的一个经典实例，从而掌握处理资源分配、投资组合或概率建模等领域常见约束的关键技巧。", "problem": "要求您通过使用熵镜像映射的镜像下降法，为单纯形约束优化实现随机梯度下降（SGD），并根据经验评估累积遗憾如何以 $\\mathcal{O}(\\sqrt{T})$ 的阶数扩展，其中 $T$ 是轮数。对于给定的维度 $K$，域是概率单纯形 $\\Delta^K = \\{x \\in \\mathbb{R}^K \\mid x_i \\ge 0, \\sum_{i=1}^K x_i = 1\\}$。在每一轮 $t \\in \\{1,\\dots,T\\}$，算法选择一个点 $x_t \\in \\Delta^K$，然后实现一个随机线性损失 $f_t(x_t) = g_t^\\top x_t$，其中 $g_t \\in \\mathbb{R}^K$ 是一个坐标有界的随机向量。相对于 $\\Delta^K$ 中最佳固定比较器的累积遗憾定义为\n$$\nR_T = \\sum_{t=1}^T f_t(x_t) - \\min_{x \\in \\Delta^K} \\sum_{t=1}^T f_t(x).\n$$\n\n您将实现的程序必须使用带有熵镜像映射的镜像下降法。熵镜像映射通过负香农熵 $R(x) = \\sum_{i=1}^K x_i \\log x_i$ 和相关的 Bregman 散度 $D_R(y\\|x) = R(y) - R(x) - \\nabla R(x)^\\top (y - x)$ 定义。您的实现应执行由无偏梯度样本控制的随机更新，并在每一轮都遵守单纯形约束。随机梯度样本 $g_t$ 必须从具有有界坐标的科学合理模型中生成。具体来说，对于每个测试用例，将 $g_t$ 构造为固定基础成本向量 $c \\in [0,B]^K$ 的一个带有加性零均值噪声的裁剪版本，并将 $g_t$ 的每个坐标裁剪到区间 $[0,B]$ 内，以强制执行界限 $\\|g_t\\|_\\infty \\le B$，其中 $B > 0$ 是给定的。初始点必须是 $\\Delta^K$ 上的均匀分布。\n\n您的任务是：\n- 使用熵镜像映射和上述指定的随机线性损失，在 $\\Delta^K$ 上实现镜像下降算法，生成一个保持在 $\\Delta^K$ 内的序列 $\\{x_t\\}_{t=1}^T$。\n- 对于每个测试用例，计算相对于 $\\Delta^K$ 中最佳固定点的累积遗憾 $R_T$，然后用 $\\sqrt{T}$ 对其进行归一化，以获得量 $R_T / \\sqrt{T}$。\n- 使用提供的种子进行伪随机数生成，以确保确定性的可复现性。\n\n推导和实现的基本基础：\n- 损失函数 $f_t(x) = g_t^\\top x$ 的凸性和概率单纯形 $\\Delta^K$ 的定义。\n- 镜像下降作为一种优化方法的定义，该方法基于选定的严格凸正则化项 $R$，使用相应的 Bregman 散度 $D_R$ 进行迭代更新。\n- 负香农熵作为 $\\Delta^K$ 上严格凸正则化项的性质。\n- 在线优化中累积遗憾 $R_T$ 的概念，以及在适当选择学习率和有界梯度的情况下，其相对于 $T$ 的扩展性。\n\n测试套件规范：\n实现程序以运行以下 $5$ 个测试用例。在每个用例中，$K$ 是单纯形的维度，$T$ 是迭代次数，$B$ 是随机梯度坐标的上限，$\\sigma$ 是加性噪声的标准差，$c$ 是基础成本向量，$\\text{seed}$ 是伪随机种子。$c$ 的所有条目都在 $[0,B]$ 范围内。\n\n- 用例 $1$：$K=5$，$T=2000$，$B=1.0$，$\\sigma=0.2$，$c = [0.1, 0.2, 0.3, 0.4, 0.5]$，$\\text{seed}=42$。\n- 用例 $2$：$K=2$，$T=500$，$B=1.0$，$\\sigma=0.3$，$c = [0.0, 0.5]$，$\\text{seed}=7$。\n- 用例 $3$：$K=10$，$T=5000$，$B=2.0$，$\\sigma=0.5$，$c$ 是一个从 $0.1$ 到 $1.0$ 的等距向量，长度为 $10$，$\\text{seed}=17$。\n- 用例 $4$：$K=1$，$T=1000$，$B=1.0$，$\\sigma=0.1$，$c = [0.7]$，$\\text{seed}=99$。\n- 用例 $5$：$K=5$，$T=4000$，$B=1.0$，$\\sigma=0.2$，$c = [0.1, 0.2, 0.3, 0.4, 0.5]$，$\\text{seed}=123$。\n\n输出要求：\n您的程序应生成单行输出，其中包含 $5$ 个测试用例的归一化遗憾 $R_T / \\sqrt{T}$，形式为方括号括起来的逗号分隔列表（例如，$[r_1,r_2,r_3,r_4,r_5]$）。每个 $r_i$ 必须是实数（一个小数）。输出中不允许超出此单行的任何额外文本或格式。\n\n此问题不涉及物理单位。不使用角度。不要用百分号表示任何数量；需要时请使用小数。", "solution": "问题是在概率单纯形 $\\Delta^K = \\{x \\in \\mathbb{R}^K \\mid x_i \\ge 0, \\sum_{i=1}^K x_i = 1\\}$ 上为一系列线性损失函数实现随机镜像下降算法。在每个时间步 $t \\in \\{1, \\dots, T\\}$，算法选择一个点 $x_t \\in \\Delta^K$ 并产生损失 $f_t(x_t) = g_t^\\top x_t$，其中 $g_t$ 是一个随机梯度。目标是计算归一化的累积遗憾 $R_T / \\sqrt{T}$，其中 $R_T = \\sum_{t=1}^T f_t(x_t) - \\min_{x \\in \\Delta^K} \\sum_{t=1}^T f_t(x)$。\n\n解决方案的核心是镜像下降更新规则。这是一种推广了标准梯度下降的迭代优化方法。从 $x_t$到 $x_{t+1}$ 的更新由下式给出：\n$$\nx_{t+1} = \\arg\\min_{x \\in \\Delta^K} \\left\\{ \\eta_t g_t^\\top x + D_R(x \\| x_t) \\right\\}\n$$\n其中 $\\eta_t$ 是学习率，$g_t = \\nabla f_t(x_t)$ 是损失函数的梯度，$D_R(y \\| x)$ 是与严格凸正则化函数 $R(x)$ 相关联的 Bregman 散度。\n\n对于此问题，正则化项是定义在单纯形内部的负香农熵：\n$$\nR(x) = \\sum_{i=1}^K x_i \\log x_i\n$$\n该正则化项的梯度是 $\\nabla R(x)$，其分量为 $(\\nabla R(x))_i = \\log x_i + 1$。Bregman 散度是 $D_R(y \\| x) = R(y) - R(x) - \\nabla R(x)^\\top (y - x)$。\n\n将这些代入更新规则，并省略相对于最小化变量 $x$ 的常数项，更新步骤变为：\n$$\nx_{t+1} = \\arg\\min_{x \\in \\Delta^K} \\left\\{ \\eta_t g_t^\\top x + R(x) - (\\nabla R(x_t))^\\top x \\right\\}\n$$\n$$\nx_{t+1} = \\arg\\min_{x \\in \\Delta^K} \\left\\{ \\sum_{i=1}^K \\eta_t (g_t)_i x_i + \\sum_{i=1}^K x_i \\log x_i - \\sum_{i=1}^K (\\log (x_t)_i + 1) x_i \\right\\}\n$$\n这是一个在单纯形上的凸优化问题。为约束 $\\sum_i x_i = 1$ 引入拉格朗日乘子 $\\lambda$，一阶最优性条件为每个分量 $(x_{t+1})_i$ 产生一个闭式解：\n$$\n(x_{t+1})_i = \\frac{(x_t)_i \\exp(-\\eta_t (g_t)_i)}{\\sum_{j=1}^K (x_t)_j \\exp(-\\eta_t (g_t)_j)}\n$$\n这个更新规则被称为指数梯度算法。它确保如果 $x_t \\in \\Delta^K$，那么 $x_{t+1}$ 也位于 $\\Delta^K$ 中。初始点是单纯形的中心 $x_1$，其中对于所有 $i \\in \\{1, \\dots, K\\}$，$(x_1)_i = 1/K$。\n\n学习率的选择对于实现期望的 $\\mathcal{O}(\\sqrt{T})$ 遗憾扩展至关重要。对于坐标有界（即 $\\|g_t\\|_\\infty \\le B$）的在线镜像下降，理论遗憾界由下式给出：\n$$\nR_T \\le \\frac{D_{R, \\text{max}}}{\\eta} + \\frac{\\eta}{2} \\sum_{t=1}^T \\|g_t\\|_*^2\n$$\n对于熵正则化项，相关范围是 $D_{R, \\text{max}} = \\max_{x \\in \\Delta^K} R(x) - \\min_{x \\in \\Delta^K} R(x) = 0 - (-\\log K) = \\log K$。对此设置使用更具体的界和固定的学习率 $\\eta$，累积遗憾的界为 $R_T \\le \\frac{\\log K}{\\eta} + \\frac{\\eta T B^2}{2}$。为了最小化这个上界，我们选择 $\\eta$ 来平衡这两项：\n$$\n\\frac{\\log K}{\\eta} = \\frac{\\eta T B^2}{2} \\implies \\eta^2 = \\frac{2 \\log K}{T B^2} \\implies \\eta = \\frac{\\sqrt{2 \\log K}}{B \\sqrt{T}}\n$$\n使用这个固定的学习率，遗憾的界为 $R_T \\le B\\sqrt{2T\\log K}$，这表现出所需的 $\\mathcal{O}(\\sqrt{T})$ 扩展性。实现将使用这个有理论依据的学习率。对于 $K=1$ 的特殊情况，$\\log K = 0$，所以 $\\eta=0$，意味着点永远不会离开其初始状态，这是正确的，因为 $\\Delta^1$ 是一个单点。\n\n对于给定的具有参数 $K, T, B, \\sigma, c, \\text{seed}$ 的测试用例，总体算法如下：\n1.  使用给定的 `seed` 初始化伪随机数生成器。\n2.  初始化点 $x_1$，其中 $(x_1)_i = 1/K$，对于 $i=1, \\dots, K$。\n3.  计算学习率 $\\eta = \\frac{\\sqrt{2 \\log K}}{B \\sqrt{T}}$。\n4.  初始化总算法损失 $\\mathcal{L}_{alg} = 0$ 和总梯度和向量 $G_T = \\mathbf{0} \\in \\mathbb{R}^K$。\n5.  迭代 $t=1, \\dots, T$：\n    a. 生成随机梯度 $g_t$：创建一个噪声向量 $\\epsilon_t$，其分量从正态分布 $\\mathcal{N}(0, \\sigma^2)$ 中抽取，然后设置 $g_t = \\text{clip}(c + \\epsilon_t, 0, B)$。\n    b. 产生当前轮次的损失：$l_t = g_t^\\top x_t$。\n    c. 更新总损失：$\\mathcal{L}_{alg} = \\mathcal{L}_{alg} + l_t$。\n    d. 更新总梯度和：$G_T = G_T + g_t$。\n    e. 使用学习率 $\\eta$ 和指数梯度更新规则计算下一个点 $x_{t+1}$。\n6.  循环结束后，计算事后看来最佳固定点的损失。这是单纯形上线性函数的最小值，该最小值必须出现在一个顶点上：$\\mathcal{L}_{opt} = \\min_{x \\in \\Delta^K} G_T^\\top x = \\min_{i \\in \\{1,\\dots,K\\}} (G_T)_i$。\n7.  计算累积遗憾 $R_T = \\mathcal{L}_{alg} - \\mathcal{L}_{opt}$。\n8.  计算归一化遗憾 $r = R_T / \\sqrt{T}$。\n\n此过程将应用于所有 $5$ 个测试用例以生成最终输出。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements Stochastic Mirror Descent with an entropic regularizer (Exponentiated Gradient)\n    on the probability simplex to calculate normalized cumulative regret for several test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'K': 5, 'T': 2000, 'B': 1.0, 'sigma': 0.2, 'c': np.array([0.1, 0.2, 0.3, 0.4, 0.5]), 'seed': 42},\n        {'K': 2, 'T': 500, 'B': 1.0, 'sigma': 0.3, 'c': np.array([0.0, 0.5]), 'seed': 7},\n        {'K': 10, 'T': 5000, 'B': 2.0, 'sigma': 0.5, 'c': np.linspace(0.1, 1.0, 10), 'seed': 17},\n        {'K': 1, 'T': 1000, 'B': 1.0, 'sigma': 0.1, 'c': np.array([0.7]), 'seed': 99},\n        {'K': 5, 'T': 4000, 'B': 1.0, 'sigma': 0.2, 'c': np.array([0.1, 0.2, 0.3, 0.4, 0.5]), 'seed': 123},\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        K = case['K']\n        T = case['T']\n        B = case['B']\n        sigma = case['sigma']\n        c = case['c']\n        seed = case['seed']\n\n        rng = np.random.default_rng(seed)\n\n        # Handle the trivial case K=1\n        if K == 1:\n            results.append(0.0)\n            continue\n            \n        # 1. Initialize point x_1 at the center of the simplex\n        x = np.ones(K) / K\n        \n        # 2. Calculate the theoretically optimal fixed learning rate eta\n        eta = np.sqrt(2 * np.log(K) / (T * B**2))\n\n        # 3. Initialize tracking variables\n        total_algorithm_loss = 0.0\n        total_gradient_sum = np.zeros(K)\n\n        # 4. Main loop for T rounds\n        for t in range(T):\n            # a. Generate stochastic gradient g_t\n            noise = rng.normal(0, sigma, size=K)\n            g_t = np.clip(c + noise, 0, B)\n\n            # b. Incur loss and update total loss\n            loss_t = np.dot(g_t, x)\n            total_algorithm_loss += loss_t\n\n            # c. Update total gradient sum\n            total_gradient_sum += g_t\n            \n            # d. Update point x_t to x_{t+1} using Exponentiated Gradient rule\n            # Numerically stable implementation: find max_val and subtract it inside exp\n            # This does not change the result due to normalization.\n            unnormalized_weights = x * np.exp(-eta * g_t)\n            # The check for sum being zero is for extreme cases, very unlikely here.\n            norm_factor = np.sum(unnormalized_weights)\n            if norm_factor > 0:\n                x = unnormalized_weights / norm_factor\n            else:\n                # If all weights become numerically zero, reset to uniform.\n                # This is a safeguard and shouldn't be hit with the chosen eta.\n                x = np.ones(K) / K\n\n        # 5. Calculate loss of the best fixed point in hindsight\n        # This is min_{x in Delta^K} (sum g_t)^T x = min_i (sum_t g_t)_i\n        best_fixed_loss = np.min(total_gradient_sum)\n\n        # 6. Compute cumulative regret\n        regret = total_algorithm_loss - best_fixed_loss\n\n        # 7. Normalize regret and store the result\n        normalized_regret = regret / np.sqrt(T)\n        results.append(normalized_regret)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.10f}' for r in results)}]\")\n\nsolve()\n```", "id": "3186873"}]}