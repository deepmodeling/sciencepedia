{"hands_on_practices": [{"introduction": "掌握多目标优化的第一步是深刻理解权衡曲线（即帕累托前沿）是如何产生的。本练习将指导您使用加权和方法，从基本原理出发，为一个简单的凸问题分析推导出帕累托前沿的参数形式。通过这个过程，您将清晰地看到决策变量、权重和目标空间之间的联系，从而为更复杂的问题打下坚实的理论基础。[@problem_id:3154179]", "problem": "考虑一个单决策变量 $x \\in \\mathbb{R}$ 的双目标最小化问题，其目标函数为 $f_{1}(x) = (x - 1)^{2} + 1$ 和 $f_{2}(x) = (x + 1)^{2} + 1$。任务是利用多目标优化的基本原理来描述这两个目标之间的权衡关系。\n\n从帕累托最优性的定义以及对于凸问题最小化正加权目标和可以生成帕累托最优点这一原理出发，使用权重 $\\alpha \\in [0, 1]$ 的加权和（WS）标量化方法 $J_{\\alpha}(x) = \\alpha f_{1}(x) + (1 - \\alpha) f_{2}(x)$，解析地推导出目标空间中帕累托前沿的参数形式。你的推导必须从凸函数的一阶最优性条件和帕累托支配的定义开始。\n\n接下来，考虑最小化问题中目标空间内有限集合的超体积（HV）指标，其定义为由该集合弱支配且由一个参考点作为上界的区域的勒贝格测度，该参考点比集合中每个点都严格差（分量上更大）。设参考点为 $r = (6, 6)$，对于每个 $\\alpha \\in [0, 1]$，令 $x^{\\star}(\\alpha)$ 为 $J_{\\alpha}(x)$ 的一个最小化子。将单点集 $\\{(f_{1}(x^{\\star}(\\alpha)), f_{2}(x^{\\star}(\\alpha)))\\}$ 视为在权重 $\\alpha$ 下对帕累托前沿的近似。\n\n仅使用上述定义和一阶条件，推导出此单点集相对于参考点 $r = (6, 6)$ 的超体积 $HV(\\alpha)$ 的闭式表达式，该表达式应为 $\\alpha$ 的函数。请以精确、简化的解析形式给出 $HV(\\alpha)$ 的最终表达式。不要对答案进行四舍五入。最终答案必须是单个表达式。", "solution": "用户希望我解决一个多目标优化问题。\n\n### 步骤1：提取已知条件\n- **决策变量：** $x \\in \\mathbb{R}$。\n- **目标函数（最小化）：**\n  - $f_{1}(x) = (x - 1)^{2} + 1$\n  - $f_{2}(x) = (x + 1)^{2} + 1$\n- **标量化方法：** 加权和（WS） $J_{\\alpha}(x) = \\alpha f_{1}(x) + (1 - \\alpha) f_{2}(x)$。\n- **权重参数：** $\\alpha \\in [0, 1]$。\n- **优化原理：** 最小化凸标量化函数 $J_{\\alpha}(x)$ 可生成帕累托最优点。推导必须使用一阶最优性条件。\n- **超体积（HV）指标定义：** 对于目标空间中的一个有限集和一个参考点 $r$，HV 是该集合弱支配且以 $r$ 为上界的区域的勒贝格测度。\n- **参考点：** $r = (6, 6)$。\n- **用于HV计算的集合：** 单点集 $\\{(f_{1}(x^{\\star}(\\alpha)), f_{2}(x^{\\star}(\\alpha)))\\}$，其中 $x^{\\star}(\\alpha)$ 是 $J_{\\alpha}(x)$ 的一个最小化子。\n- **最终任务：** 推导超体积 $HV(\\alpha)$ 作为 $\\alpha$ 的函数的闭式表达式。\n\n### 步骤2：使用提取的已知条件进行验证\n1.  **科学或事实合理性：** 该问题基于多目标优化的标准理论。帕累托最优性、用于凸问题的加权和方法以及超体积指标等概念都是该领域的成熟概念。所提供的函数是简单的凸二次函数，适合此类分析。该问题在科学和数学上是合理的。\n2.  **非形式化或不相关：** 该问题是高度形式化的，与多目标优化主题直接相关。\n3.  **不完整或矛盾的设置：** 提供了所有必要信息。目标、约束、标量化方法和参考点都已明确定义。没有矛盾之处。\n4.  **不切实际或不可行：** 该问题是一个理论练习；物理现实性不是一个相关标准，但数学设置是完全可行的。\n5.  **不适定或结构不良：** 该问题是适定的。目标函数是凸的，确保对于任何 $\\alpha \\in (0,1)$，加权和都有唯一的最小化子，从而得到一个定义明确的帕累托前沿和唯一的 $HV(\\alpha)$ 值。\n6.  **伪深刻、琐碎或同义反复：** 该问题需要一个涉及微积分和优化定义应用的多步推导。这是一个实质性的练习，不是琐碎或同义反复的问题。\n7.  **超出科学可验证性：** 推导和最终表达式在数学上是可验证的。\n\n### 步骤3：结论与行动\n问题有效。我将继续进行求解。\n\n该双目标最小化问题涉及两个目标函数：$f_{1}(x) = (x - 1)^{2} + 1$ 和 $f_{2}(x) = (x + 1)^{2} + 1$。两个函数在 $\\mathbb{R}$ 上都是凸函数。任务是使用加权和（WS）方法找到帕累托前沿的参数表示，然后推导出超体积指标作为权重 $\\alpha$ 的函数表达式。\n\n首先，我们定义加权和（WS）标量化方法，它使用权重 $\\alpha \\in [0, 1]$ 将两个目标合并为一个单一目标函数 $J_{\\alpha}(x)$：\n$$J_{\\alpha}(x) = \\alpha f_{1}(x) + (1 - \\alpha) f_{2}(x)$$\n代入 $f_{1}(x)$ 和 $f_{2}(x)$ 的表达式：\n$$J_{\\alpha}(x) = \\alpha ((x - 1)^{2} + 1) + (1 - \\alpha) ((x + 1)^{2} + 1)$$\n由于 $f_{1}(x)$ 和 $f_{2}(x)$ 是凸函数，且 $\\alpha \\ge 0$, $1 - \\alpha \\ge 0$，它们的非负加权和 $J_{\\alpha}(x)$ 也是一个凸函数。对于凸函数，可以通过将其关于 $x$ 的一阶导数设为零来找到最小值。这是一阶最优性条件。\n$$\\frac{dJ_{\\alpha}(x)}{dx} = \\frac{d}{dx} \\left[ \\alpha (x - 1)^{2} + \\alpha + (1 - \\alpha) (x + 1)^{2} + (1 - \\alpha) \\right] = 0$$\n$$\\frac{dJ_{\\alpha}(x)}{dx} = \\alpha [2(x - 1)] + (1 - \\alpha) [2(x + 1)] = 0$$\n两边除以 $2$，我们得到：\n$$\\alpha (x - 1) + (1 - \\alpha) (x + 1) = 0$$\n$$x + 1 - 2\\alpha = 0$$\n求解 $x$，我们得到最优决策变量 $x^{\\star}$ 作为 $\\alpha$ 的函数：\n$$x^{\\star}(\\alpha) = 2\\alpha - 1$$\n该表达式给出了对于每个 $\\alpha \\in [0, 1]$ 在决策空间中的帕累托最优解。所有这些解的集合 $\\{x | x = 2\\alpha - 1, \\alpha \\in [0, 1]\\}$ 对应于区间 $[-1, 1]$。\n\n接下来，我们将这些最优解映射到目标空间以找到帕累托前沿。帕累托前沿是目标向量的集合 $(f_{1}(x^{\\star}(\\alpha)), f_{2}(x^{\\star}(\\alpha)))$，其中 $\\alpha \\in [0, 1]$。我们定义帕累托前沿上的点为 $p(\\alpha) = (p_1(\\alpha), p_2(\\alpha))$。\n$$p_1(\\alpha) = f_{1}(x^{\\star}(\\alpha)) = f_{1}(2\\alpha - 1) = ((2\\alpha - 1) - 1)^{2} + 1 = (2\\alpha - 2)^{2} + 1 = 4(\\alpha - 1)^{2} + 1$$\n$$p_2(\\alpha) = f_{2}(x^{\\star}(\\alpha)) = f_{2}(2\\alpha - 1) = ((2\\alpha - 1) + 1)^{2} + 1 = (2\\alpha)^{2} + 1 = 4\\alpha^{2} + 1$$\n帕累托前沿的参数形式为 $(4(\\alpha - 1)^{2} + 1, 4\\alpha^{2} + 1)$，其中 $\\alpha \\in [0, 1]$。\n\n问题的第二部分要求计算单点集 $\\{p(\\alpha)\\}$ 相对于参考点 $r = (6, 6)$ 的超体积（HV）指标。在这个二维案例中，HV 对应于由点 $p(\\alpha)$ 和参考点 $r$ 形成的超矩形的面积。\n一个点 $(p_1, p_2)$ 相对于参考点 $(r_1, r_2)$ 的 HV 计算公式为：\n$$HV = (r_1 - p_1)(r_2 - p_2)$$\n我们必须首先验证参考点 $r = (6, 6)$ 严格支配帕累托前沿上的所有点。\n对于 $\\alpha \\in [0, 1]$，$p_1(\\alpha) = 4(\\alpha - 1)^{2} + 1$ 的最大值在 $\\alpha = 0$ 时取得，为 $p_1(0) = 5$。$p_2(\\alpha) = 4\\alpha^{2} + 1$ 的最大值在 $\\alpha = 1$ 时取得，为 $p_2(1) = 5$。因此，对于前沿上的任意点 $(p_1, p_2)$，都有 $p_1 \\le 5$ 和 $p_2 \\le 5$。由于 $r_1=6$ 且 $r_2=6$，该参考点确实是一个有效的上界。\n\n现在，我们计算 $HV(\\alpha)$ 作为 $\\alpha$ 的函数：\n$$HV(\\alpha) = (6 - p_1(\\alpha))(6 - p_2(\\alpha))$$\n我们需要将 $p_1(\\alpha)$ 和 $p_2(\\alpha)$ 表示为 $\\alpha$ 的多项式：\n$$p_1(\\alpha) = 4(\\alpha^{2} - 2\\alpha + 1) + 1 = 4\\alpha^{2} - 8\\alpha + 5$$\n$$p_2(\\alpha) = 4\\alpha^{2} + 1$$\n将这些代入 HV 公式：\n$$HV(\\alpha) = (6 - (4\\alpha^{2} - 8\\alpha + 5))(6 - (4\\alpha^{2} + 1))$$\n$$HV(\\alpha) = (1 + 8\\alpha - 4\\alpha^{2})(5 - 4\\alpha^{2})$$\n现在，我们展开乘积以获得 $HV(\\alpha)$ 的简化多项式表达式：\n$$HV(\\alpha) = 1(5) + 1(-4\\alpha^{2}) + 8\\alpha(5) + 8\\alpha(-4\\alpha^{2}) - 4\\alpha^{2}(5) - 4\\alpha^{2}(-4\\alpha^{2})$$\n$$HV(\\alpha) = 5 - 4\\alpha^{2} + 40\\alpha - 32\\alpha^{3} - 20\\alpha^{2} + 16\\alpha^{4}$$\n最后，我们按 $\\alpha$ 的降幂合并同类项：\n$$HV(\\alpha) = 16\\alpha^{4} - 32\\alpha^{3} + (-4 - 20)\\alpha^{2} + 40\\alpha + 5$$\n$$HV(\\alpha) = 16\\alpha^{4} - 32\\alpha^{3} - 24\\alpha^{2} + 40\\alpha + 5$$\n这就是单点帕累托点近似的超体积关于权重 $\\alpha$ 的闭式表达式。", "answer": "$$\\boxed{16\\alpha^{4} - 32\\alpha^{3} - 24\\alpha^{2} + 40\\alpha + 5}$$", "id": "3154179"}, {"introduction": "从理论走向实践，我们必须面对一个常见的现实挑战：目标尺度的差异。当不同目标的量纲或数值范围相差悬殊时（例如，成本以“元”计，而环境影响以“分”计），直接使用加权和方法可能会得到有失偏颇的结果。本练习通过一个编程实践，直观地展示了目标归一化对最终决策的巨大影响，并揭示了为何它是在多目标决策中一个至关重要的预处理步骤。[@problem_id:3162727]", "problem": "考虑一个双目标最小化问题，其决策变量为 $x$，目标为 $f_1(x)$ 和 $f_2(x)$，这些目标在一个有限候选集 $X$ 上进行评估。帕累托支配是按分量定义的：一个决策 $x_a$ 支配一个决策 $x_b$，当且仅当对于所有 $i \\in \\{1,2\\}$ 都有 $f_i(x_a) \\le f_i(x_b)$，并且至少存在一个索引 $j \\in \\{1,2\\}$ 使得 $f_j(x_a)  f_j(x_b)$。帕累托集是 $X$ 的一个子集，由 $X$ 中所有不被任何其他决策所支配的决策组成。归一化是使用在候选集 $X$ 上计算的分量乌托邦点和天底点进行的，即 $z_i^\\text{utopia} = \\min_{x \\in X} f_i(x)$ 和 $z_i^\\text{nadir} = \\max_{x \\in X} f_i(x)$，归一化目标定义为\n$$\nf_i'(x) = \\frac{f_i(x) - z_i^\\text{utopia}}{z_i^\\text{nadir} - z_i^\\text{utopia}}, \\quad i \\in \\{1,2\\}.\n$$\n您的任务是研究归一化如何影响帕累托集以及由等权重线性标量化产生的选择。对于下方的每个测试用例，您必须：\n(1) 按照规定构建候选集 $X$，并为所有 $x \\in X$ 计算 $f_1(x)$ 和 $f_2(x)$。\n(2) 根据 $X$ 上的目标值计算 $z_i^\\text{utopia}$ 和 $z_i^\\text{nadir}$，并为所有 $x \\in X$ 构建归一化目标 $f_i'(x)$。\n(3) 使用原始目标 $(f_1,f_2)$ 确定 $X$ 中的帕累托集，并使用归一化目标 $(f_1',f_2')$ 确定帕累托集。报告这两个帕累托集是否相同，使用上面定义的严格帕累托支配。\n(4) 使用相等权重 $\\mathbf{w} = (1,1)$，计算未归一化标量化 $g(x) = w_1 f_1(x) + w_2 f_2(x)$ 和归一化标量化 $g'(x) = w_1 f_1'(x) + w_2 f_2'(x)$ 在 $X$ 中的最小值点。如果存在多个最小值点，选择其中最小的 $x$。\n对于每个测试用例，以列表 $[\\text{pareto\\_equal}, \\text{pareto\\_count}, x^\\star_{\\text{unnorm}}, x^\\star_{\\text{norm}}]$ 的形式生成结果，其中 $\\text{pareto\\_equal}$ 是一个布尔值，表示帕累托集是否相同，$\\text{pareto\\_count}$ 是帕累托集中的点数（使用原始目标），$x^\\star_{\\text{unnorm}}$ 和 $x^\\star_{\\text{norm}}$ 是给出 $g$ 和 $g'$ 的选定最小值点的浮点数。您的程序应将所有测试用例的结果聚合到单行输出中，其中结果为一个用方括号括起来的逗号分隔列表，每个测试用例的结果本身也格式化为用方括号括起来的逗号分隔列表，例如 $[[\\dots],[\\dots],[\\dots]]$。\n使用以下三个科学上合理的测试用例，它们突出了归一化的不同方面：\n测试用例 A（具有严格单调冲突的尺度差异）：\n- 候选集：$X = \\{0, 0.01, 0.02, \\dots, 1.00\\}$。\n- 目标：$f_1(x) = 1000 x$，$f_2(x) = 1 - \\sqrt{x}$。\n测试用例 B（具有非单调第二目标的尺度差异）：\n- 候选集：$X = \\{0, 0.01, 0.02, \\dots, 1.00\\}$。\n- 目标：$f_1(x) = 1000 x^2$，$f_2(x) = (x - 0.6)^2$。\n测试用例 C（粗糙网格边缘情况）：\n- 候选集：$X = \\{0, 0.5, 1.0\\}$。\n- 目标：$f_1(x) = 1000 x$，$f_2(x) = 1 - x$。\n所有量都是无量纲的。您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果（例如 $[[\\text{result}_1],[\\text{result}_2],[\\text{result}_3]]$）。每个测试用例的结果必须遵循上述格式，并且只包含布尔值、整数和浮点数。", "solution": "用户希望我分析一个双目标最小化问题，重点关注归一化对帕累托集以及通过线性标量化获得的解的影响。该分析必须针对三个特定的测试用例进行。\n\n首先验证问题的正确性和可解性。\n\n### 第 1 步：提取已知信息\n- **决策变量**：$x$\n- **候选集**：一个有限集 $X$。\n- **目标**：两个待最小化的函数，$f_1(x)$ 和 $f_2(x)$。\n- **帕累托支配**：一个决策 $x_a$ 支配 $x_b$，当且仅当对于所有 $i \\in \\{1,2\\}$ 都有 $f_i(x_a) \\le f_i(x_b)$，并且至少存在一个索引 $j \\in \\{1,2\\}$ 使得 $f_j(x_a)  f_j(x_b)$。\n- **帕累托集**：$X$ 的一个子集，包含 $X$ 中所有不被任何其他决策支配的决策。\n- **归一化**：\n    - 乌托邦点：$z_i^\\text{utopia} = \\min_{x \\in X} f_i(x)$。\n    - 天底点：$z_i^\\text{nadir} = \\max_{x \\in X} f_i(x)$。\n    - 归一化目标：$f_i'(x) = \\frac{f_i(x) - z_i^\\text{utopia}}{z_i^\\text{nadir} - z_i^\\text{utopia}}$，其中 $i \\in \\{1,2\\}$。\n- **线性标量化**：\n    - 权重：$\\mathbf{w} = (w_1, w_2) = (1,1)$。\n    - 未归一化标量化：$g(x) = w_1 f_1(x) + w_2 f_2(x)$。\n    - 归一化标量化：$g'(x) = w_1 f_1'(x) + w_2 f_2'(x)$。\n- **平局打破规则**：如果标量化存在多个最小值点，选择 $x$ 值最小的那个。\n- **测试用例**：\n    - **A**：$X = \\{0, 0.01, \\dots, 1.00\\}$，$f_1(x) = 1000 x$，$f_2(x) = 1 - \\sqrt{x}$。\n    - **B**：$X = \\{0, 0.01, \\dots, 1.00\\}$，$f_1(x) = 1000 x^2$，$f_2(x) = (x - 0.6)^2$。\n    - **C**：$X = \\{0, 0.5, 1.0\\}$，$f_1(x) = 1000 x$，$f_2(x) = 1 - x$。\n- **每个用例的所需输出**：一个列表 $[\\text{pareto\\_equal}, \\text{pareto\\_count}, x^\\star_{\\text{unnorm}}, x^\\star_{\\text{norm}}]$。\n\n### 第 2 步：使用提取的已知信息进行验证\n该问题在科学和数学上是合理的。它涉及多目标优化中的标准、明确定义的概念：帕累托支配、归一化和线性标量化。问题是自包含的，提供了所有必要的定义、函数和数据集。候选集 $X$ 是有限的，目标函数在其各自的定义域上是良态的，确保了乌托邦点和天底点是明确定义的。对于所有指定的测试用例，归一化分母 $z_i^\\text{nadir} - z_i^\\text{utopia}$ 均不为零，因为没有一个目标函数在候选集 $X$ 上是常数。平局打破规则确保了标量化最小化的解是唯一的。问题是适定的，没有违反任何科学原理或包含逻辑矛盾。\n\n### 第 3 步：结论与行动\n问题有效。将制定一个完整的解决方案。\n\n### 基于原理的解决方案\n核心任务是分析归一化如何影响帕累托最优性以及等权重线性标量化方法的结果。我们将首先建立一个关于帕累托集的理论原则，然后概述计算算法，以确定每个测试用例所需的所有量。\n\n**1. 帕累托集在归一化下的不变性**\n\n指定的归一化是一种分量仿射变换，形式为 $f_i'(x) = a_i f_i(x) + b_i$，其中：\n$$ a_i = \\frac{1}{z_i^\\text{nadir} - z_i^\\text{utopia}} \\quad \\text{和} \\quad b_i = \\frac{-z_i^\\text{utopia}}{z_i^\\text{nadir} - z_i^\\text{utopia}} $$\n对于在候选集 $X$ 上的非常数目标函数，我们有 $z_i^\\text{nadir} > z_i^\\text{utopia}$，这意味着 $a_i > 0$。具有正尺度因子（$a_i > 0$）的仿射变换是严格递增的。\n\n让我们研究这种变换如何影响帕累托支配关系。假设一个决策 $x_a$ 在原始目标空间中支配一个决策 $x_b$。根据定义：\n1. 对于 $i \\in \\{1,2\\}$，有 $f_i(x_a) \\le f_i(x_b)$。\n2. 对于至少一个 $j \\in \\{1,2\\}$，有 $f_j(x_a)  f_j(x_b)$。\n\n由于 $a_i > 0$，我们可以将不等式两边乘以 $a_i$ 而不改变它们的方向：\n1. 对于 $i \\in \\{1,2\\}$，有 $a_i f_i(x_a) \\le a_i f_i(x_b)$。\n2. 对于至少一个 $j \\in \\{1,2\\}$，有 $a_j f_j(x_a)  a_j f_j(x_b)$。\n\n在两边加上常数 $b_i$ 同样保持不等式：\n1. $a_i f_i(x_a) + b_i \\le a_i f_i(x_b) + b_i \\implies f_i'(x_a) \\le f_i'(x_b)$，对于 $i \\in \\{1,2\\}$。\n2. $a_j f_j(x_a) + b_j  a_j f_j(x_b) + b_j \\implies f_j'(x_a)  f_j'(x_b)$，对于至少一个 $j \\in \\{1,2\\}$。\n\n这表明 $x_a$ 在归一化目标空间中也支配 $x_b$。通过相同的逻辑，反向推论也成立。因此，对于原始目标和归一化目标，支配关系是相同的。因此，非支配解的集合——即帕累托集——在这种归一化下是不变的。这意味着对于所有测试用例，布尔值 `pareto_equal` 都将为 `True`。\n\n**2. 算法流程**\n\n对每个测试用例执行以下流程：\n- **第 2.1 步：评估。** 生成候选集 $X$。对于每个 $x \\in X$，计算并存储目标向量 $\\mathbf{f}(x) = (f_1(x), f_2(x))$。\n- **第 2.2 步：帕累托集识别。** 通过两两比较来识别帕累托集。对于每个候选解 $x_i$，将其与每个其他候选解 $x_j$ 进行比较。如果任何 $x_j$ 支配 $x_i$（根据定义），则将 $x_i$ 标记为被支配。所有未被标记为被支配的候选解构成帕累托集。该集合的大小为 `pareto_count`。\n- **第 2.3 步：归一化。** 通过取每个目标 $i \\in \\{1,2\\}$ 的已评估目标值的最小值和最大值，找到乌托邦点和天底点 $z_i^\\text{utopia}$ 和 $z_i^\\text{nadir}$。然后为所有 $x \\in X$ 计算归一化目标 $f_i'(x)$。如已证明，这不会改变帕累托集。\n- **第 2.4 步：标量化和最小化。** 为所有 $x \\in X$ 计算未归一化和归一化的标量化目标函数：\n$$ g(x) = f_1(x) + f_2(x) $$\n$$ g'(x) = f_1'(x) + f_2'(x) $$\n找到每个函数的最小值 $\\min_{x \\in X} g(x)$ 和 $\\min_{x \\in X} g'(x)$。识别出所有达到此最小值的 $x$ 值集合。根据平局打破规则，从该集合中选择最小的 $x$ 作为最小值点，从而得到 $x^\\star_{\\text{unnorm}}$ 和 $x^\\star_{\\text{norm}}$。\n\n**3. 应用于测试用例**\n\n- **测试用例 A**：$f_1(x) = 1000 x$ 和 $f_2(x) = 1 - \\sqrt{x}$。在 $X = \\{0, 0.01, \\dots, 1.00\\}$上，$f_1(x)$ 严格递增，而 $f_2(x)$ 严格递减。这造成了直接冲突，意味着没有解能支配其他解。整个包含 $101$ 个点的集合 $X$ 就是帕累托集。$f_1$ 的大尺度主导了未归一化的标量化 $g(x) = 1000x + 1 - \\sqrt{x}$，将其最小值推向 $x=0$。归一化后，目标 $f_1'(x) = x$ 和 $f_2'(x) = 1 - \\sqrt{x}$ 处于可比较的尺度上。$g'(x) = x + 1 - \\sqrt{x}$ 的最小值在 $x=0.25$ 处找到。\n- **测试用例 B**：$f_1(x) = 1000 x^2$ 和 $f_2(x) = (x - 0.6)^2$。对于 $x \\in [0, 0.6]$，$f_1(x)$ 增加而 $f_2(x)$ 减少，形成一个帕累托前沿。对于 $x > 0.6$， $f_1(x)$ 和 $f_2(x)$ 都增加，因此任何 $x > 0.6$ 的解都被 $x=0.6$ 的解所支配。因此，帕累托集为 $\\{0, 0.01, \\dots, 0.60\\}$，包含 $61$ 个点。未归一化的标量化 $g(x)$ 再次被高数量级的 $f_1$ 项主导，将最小值置于 $x=0$。归一化平衡了尺度，归一化标量化 $g'(x)$ 的最小值在解析最小值 $x \\approx 0.441$ 附近找到，对应于离散网格上的 $x=0.44$。\n- **测试用例 C**：$f_1(x) = 1000 x$ 和 $f_2(x) = 1 - x$ 在粗糙网格 $X=\\{0, 0.5, 1.0\\}$ 上。这些点是 $(0,1)$，$(500, 0.5)$ 和 $(1000,0)$。这三点互相不支配，所以帕累托集有 $3$ 个点。未归一化的标量化 $g(x) = 999x + 1$ 在 $x=0$ 处最小化。归一化完美地平衡了目标，得到 $f_1'(x)=x$ 和 $f_2'(x)=1-x$。归一化的标量化变为 $g'(x) = x + (1-x) = 1$，对于所有 $x \\in X$ 都是常数。所有三个点都是最小值点。平局打破规则选择最小的 $x$，因此 $x^\\star_{\\text{norm}} = 0$。\n\n该分析为接下来的计算实现提供了基础。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the multi-objective optimization problem for three test cases.\n    \"\"\"\n\n    def find_pareto_indices(objectives: np.ndarray) -> set:\n        \"\"\"\n        Identifies the indices of Pareto optimal solutions in a set.\n\n        Args:\n            objectives: An (n_candidates, n_objectives) numpy array of objective values.\n\n        Returns:\n            A set of integer indices corresponding to the Pareto optimal solutions.\n        \"\"\"\n        num_candidates = objectives.shape[0]\n        is_dominated = np.zeros(num_candidates, dtype=bool)\n\n        for i in range(num_candidates):\n            # Check if candidate i is dominated by any other candidate j\n            for j in range(num_candidates):\n                if i == j:\n                    continue\n                \n                # Strict Pareto dominance check:\n                # j dominates i if f_k(j) = f_k(i) for all objectives k\n                # and f_k(j)  f_k(i) for at least one objective k.\n                if np.all(objectives[j] = objectives[i]) and np.any(objectives[j]  objectives[i]):\n                    is_dominated[i] = True\n                    break  # i is dominated, no need to check other j's\n\n        pareto_indices = np.where(~is_dominated)[0]\n        return set(pareto_indices)\n\n    def process_case(x_values: np.ndarray, f1_func: callable, f2_func: callable) -> list:\n        \"\"\"\n        Performs the full analysis for a single test case.\n\n        Args:\n            x_values: 1D numpy array of decision variable candidates.\n            f1_func: The first objective function.\n            f2_func: The second objective function.\n\n        Returns:\n            A list containing [pareto_equal, pareto_count, x_star_unnorm, x_star_norm].\n        \"\"\"\n        # (1) Compute objectives for all candidates\n        f1_values = f1_func(x_values)\n        f2_values = f2_func(x_values)\n        objectives = np.vstack([f1_values, f2_values]).T\n\n        # (2) Compute normalized objectives\n        z1_utopia, z1_nadir = np.min(f1_values), np.max(f1_values)\n        z2_utopia, z2_nadir = np.min(f2_values), np.max(f2_values)\n\n        # The problem statement ensures denominators are non-zero for these test cases.\n        denom1 = z1_nadir - z1_utopia if z1_nadir > z1_utopia else 1.0\n        denom2 = z2_nadir - z2_utopia if z2_nadir > z2_utopia else 1.0\n\n        f1_prime = (f1_values - z1_utopia) / denom1\n        f2_prime = (f2_values - z2_utopia) / denom2\n        normalized_objectives = np.vstack([f1_prime, f2_prime]).T\n\n        # (3) Determine Pareto sets and compare\n        original_pareto_indices = find_pareto_indices(objectives)\n        # As proven, normalization does not change the Pareto set.\n        # We can computationally verify this, but it must be true.\n        normalized_pareto_indices = find_pareto_indices(normalized_objectives)\n        \n        pareto_equal = (original_pareto_indices == normalized_pareto_indices)\n        pareto_count = len(original_pareto_indices)\n        \n        # (4) Compute minimizers of scalarizations (w = [1, 1])\n        # Unnormalized scalarization\n        g = f1_values + f2_values\n        min_g = np.min(g)\n        min_g_indices = np.where(np.isclose(g, min_g))[0]\n        # Tie-breaking: select smallest x\n        x_star_unnorm = x_values[min_g_indices[0]]\n\n        # Normalized scalarization\n        g_prime = f1_prime + f2_prime\n        min_g_prime = np.min(g_prime)\n        min_g_prime_indices = np.where(np.isclose(g_prime, min_g_prime))[0]\n        # Tie-breaking: select smallest x\n        x_star_norm = x_values[min_g_prime_indices[0]]\n\n        return [pareto_equal, pareto_count, float(x_star_unnorm), float(x_star_norm)]\n\n    # Define the test cases from the problem statement.\n    test_cases_defs = [\n        {\n            \"x_values\": np.linspace(0, 1.0, 101, dtype=float),\n            \"f1\": lambda x: 1000.0 * x,\n            \"f2\": lambda x: 1.0 - np.sqrt(x)\n        },\n        {\n            \"x_values\": np.linspace(0, 1.0, 101, dtype=float),\n            \"f1\": lambda x: 1000.0 * x**2,\n            \"f2\": lambda x: (x - 0.6)**2\n        },\n        {\n            \"x_values\": np.array([0.0, 0.5, 1.0], dtype=float),\n            \"f1\": lambda x: 1000.0 * x,\n            \"f2\": lambda x: 1.0 - x\n        }\n    ]\n\n    results = []\n    for case_def in test_cases_defs:\n        result = process_case(case_def[\"x_values\"], case_def[\"f1\"], case_def[\"f2\"])\n        results.append(result)\n    \n    # Format the results into a single string as specified\n    result_str = \"[\" + \",\".join([f\"[{r[0]},{r[1]},{r[2]},{r[3]}]\" for r in results]) + \"]\"\n\n    # Final print statement in the exact required format.\n    print(result_str)\n\nsolve()\n```", "id": "3162727"}, {"introduction": "加权和方法虽然强大，但它存在一个局限性：通常只能找到构成可行目标集凸包的“支撑”解。本练习将介绍一类不同的问题——离散优化，并引入一种强大的精确算法——动态规划。您将学习如何通过该方法找出完整的帕累托前沿，包括那些位于权衡曲线凹陷区域的“非支撑”解，这对于在复杂的非凸权衡中做出最优决策至关重要。[@problem_id:3154185]", "problem": "考虑以下表述为最小化问题的双目标 $0$-$1$ 背包问题。存在一个包含 $n$ 个物品的集合，物品索引为 $i \\in \\{1,\\dots,n\\}$。每个物品 $i$ 都有一个非负价值 $p_i \\in \\mathbb{R}_{\\ge 0}$ 和一个非负重量 $w_i \\in \\mathbb{R}_{\\ge 0}$。决策变量 $x_i \\in \\{0,1\\}$ 表示是否选择物品 $i$。背包的容量为 $C \\in \\mathbb{R}_{\\ge 0}$，并强制执行约束 $\\sum_{i=1}^{n} w_i x_i \\le C$。定义目标向量\n$$\n\\mathbf{f}(\\mathbf{x}) = \\left(f_1(\\mathbf{x}), f_2(\\mathbf{x})\\right) = \\left(-\\sum_{i=1}^{n} p_i x_i,\\; \\sum_{i=1}^{n} w_i x_i\\right).\n$$\n优化任务是在满足容量约束的前提下，最小化 $f_1$ 和 $f_2$。其中，最小化 $f_1$ 等同于最大化总价值 $\\sum_{i=1}^{n} p_i x_i$。\n\n在多目标优化中，如果一个具有目标向量 $\\mathbf{f}(\\mathbf{x}) = (f_1(\\mathbf{x}), f_2(\\mathbf{x}))$ 的解 $\\mathbf{x}$ 与另一个具有目标向量 $\\mathbf{f}(\\mathbf{y}) = (f_1(\\mathbf{y}), f_2(\\mathbf{y}))$ 的解 $\\mathbf{y}$ 满足 $f_1(\\mathbf{x}) \\le f_1(\\mathbf{y})$ 且 $f_2(\\mathbf{x}) \\le f_2(\\mathbf{y})$，并且至少有一个不等式是严格的，那么我们称解 $\\mathbf{x}$ 支配解 $\\mathbf{y}$。如果没有任何其他可行解能支配某个解，则该解是非支配的。所有非支配目标向量的集合构成了帕累托前沿。\n\n从基础概念——二元决策、容量约束下的可行集、帕累托支配以及支撑动态规划的最优性原理——出发，推导一种算法方法。该方法通过逐个考虑物品并在每一步修剪被支配的状态，来迭代地构建非支配集。您的推导必须证明为什么可以安全地丢弃被支配的状态而不会丢失任何帕累托最优解。\n\n然后，实现所推导的动态规划算法，以枚举以下测试套件的非支配目标向量。对于每个测试用例，物品以配对 $(p_i,w_i)$ 的形式给出，容量为 $C$。每个测试用例的输出必须是非支配目标向量 $[f_1,f_2]$ 的列表，按 $f_1$ 升序排序，当 $f_1$ 相同时，再按 $f_2$ 升序排序。如果出现重复的目标向量，每个唯一向量只应包含一次。\n\n测试套件：\n- 测试 $1$ (常规路径): 物品 $[(9,4),(7,3),(5,2),(6,5),(4,3)]$，容量 $C=10$。\n- 测试 $2$ (边界容量): 物品 $[(3,2),(4,5)]$，容量 $C=0$。\n- 测试 $3$ (零重量物品边缘情况): 物品 $[(2,0),(5,4),(1,1)]$，容量 $C=4$。\n- 测试 $4$ (重复物品边缘情况): 物品 $[(3,2),(3,2)]$，容量 $C=4$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个元素对应一个测试用例，并且本身也是一个目标向量列表。例如，最终输出格式应如下所示：\n$$\n[\\text{list\\_for\\_test1},\\text{list\\_for\\_test2},\\text{list\\_for\\_test3},\\text{list\\_for\\_test4}],\n$$\n其中每个 $\\text{list\\_for\\_testk}$ 是一个 $[f_1,f_2]$ 列表的列表。不涉及物理单位或角度，所有数值输出均为纯整数。", "solution": "该问题要求推导并实现一个动态规划算法，用以寻找一个双目标 $0$-$1$ 背包问题的非支配目标向量集。其目标是在背包容量约束下，最小化总价值的负数和总重量。\n\n首先，我们将问题形式化。给定一个包含 $n$ 个物品的集合，其中物品 $i$ 的价值为 $p_i \\ge 0$，重量为 $w_i \\ge 0$。背包的容量为 $C$。一个解是一个二元向量 $\\mathbf{x} = (x_1, \\dots, x_n)$，其中如果选择物品 $i$，则 $x_i=1$，否则 $x_i=0$。如果一个解满足容量约束，则它是可行的：\n$$\n\\sum_{i=1}^{n} w_i x_i \\le C\n$$\n目标是最小化向量函数 $\\mathbf{f}(\\mathbf{x}) = (f_1(\\mathbf{x}), f_2(\\mathbf{x}))$，定义为：\n$$\n\\mathbf{f}(\\mathbf{x}) = \\left(-\\sum_{i=1}^{n} p_i x_i, \\sum_{i=1}^{n} w_i x_i\\right)\n$$\n最小化 $f_1$ 等价于最大化总价值。最小化 $f_2$ 是最小化总重量。\n\n一个解 $\\mathbf{x}$ 支配另一个解 $\\mathbf{y}$，如果 $f_1(\\mathbf{x}) \\le f_1(\\mathbf{y})$ 且 $f_2(\\mathbf{x}) \\le f_2(\\mathbf{y})$，且至少有一个不等式是严格的。如果没有任何其他可行解能支配某个解，则该解是非支配的（或称帕累托最优）。与非支配解对应的目标向量集合称为帕累托前沿。\n\n我们可以通过顺序处理物品来推导动态规划算法。其核心思想是在过程的每个阶段维护可实现的非支配目标向量集。\n\n令 $S_k$ 为使用前 $k$ 个物品（即物品 $\\{1, \\dots, k\\}$）的子集所能形成的非支配目标向量集。$S_k$ 中的每个向量都是一个对应于前 $k$ 个物品的某个可行选择的配对 $(f_1, f_2)$。\n\n**1. 基本情况（初始化）：**\n在考虑任何物品之前（即 $k=0$ 时），唯一可能的解是不选择任何物品。这对应于决策向量 $\\mathbf{x} = \\mathbf{0}$。目标向量为 $\\mathbf{f}(\\mathbf{0}) = (0, 0)$。因此，初始的非支配向量集为：\n$$\nS_0 = \\{(0, 0)\\}\n$$\n\n**2. 递归步骤：**\n假设我们已经计算出 $S_{k-1}$，即前 $k-1$ 个物品的非支配目标向量集。我们现在考虑第 $k$ 个物品，其价值为 $p_k$，重量为 $w_k$。对于 $S_{k-1}$ 中每个已有的非支配向量 $(f_1, f_2)$，我们可以通过包含物品 $k$ 来形成一个新的潜在解。这仅在产生的总重量不超过容量 $C$ 时才可能。\n\n新解对应的目标向量为 $(f'_1, f'_2)$，其中：\n$$\nf'_1 = f_1 - p_k\n$$\n$$\nf'_2 = f_2 + w_k\n$$\n这仅在 $f'_2 \\le C$ 时有效。\n\n令 $S'_{k}$ 为一个通过考虑物品 $k$ 生成的临时目标向量集。它由两组向量构成：\n- $S_{k-1}$ 中的向量（对应于不选择物品 $k$）。\n- 通过将物品 $k$ 添加到 $S_{k-1}$ 中每个可行状态而新生成的向量。\n令 $S_{k-1}^{+}$ 为新生成的向量集：\n$$\nS_{k-1}^{+} = \\{ (f_1 - p_k, f_2 + w_k) \\mid (f_1, f_2) \\in S_{k-1} \\text{ and } f_2 + w_k \\le C \\}\n$$\n前 $k$ 个物品的潜在向量的组合集是其并集：\n$$\nT_k = S_{k-1} \\cup S_{k-1}^{+}\n$$\n\n**3. 修剪步骤与证明：**\n$T_k$ 集合可能包含被 $T_k$ 中其他向量支配的向量。为得到 $S_k$，我们必须通过移除所有被支配的向量来修剪 $T_k$。$S_k$ 是 $T_k$ 中的非支配向量集。\n\n这种修剪是基于多目标优化的最优性原理。假设在阶段 $k$，我们在 $T_k$ 中有两个目标向量 $\\mathbf{u} = (u_1, u_2)$ 和 $\\mathbf{v} = (v_1, v_2)$，它们都对应于对前 $k$ 个物品的可行选择，且 $\\mathbf{u}$ 支配 $\\mathbf{v}$。这意味着 $u_1 \\le v_1$ 且 $u_2 \\le v_2$，并且至少有一个不等式是严格的。\n对于与 $\\mathbf{v}$ 对应的解，任何可行的补全（通过添加物品 $\\{k+1, \\dots, n\\}$ 的子集，其目标贡献为 $(\\Delta f_1, \\Delta f_2)$）都会得到一个最终目标向量 $\\mathbf{f}_{\\mathbf{v}} = (v_1 + \\Delta f_1, v_2 + \\Delta f_2)$。同样的补全可以应用于与 $\\mathbf{u}$ 对应的解，得到 $\\mathbf{f}_{\\mathbf{u}} = (u_1 + \\Delta f_1, u_2 + \\Delta f_2)$。由于 $u_2 \\le v_2$，如果该补全对于 $\\mathbf{v}$ 是可行的（即 $v_2 + \\Delta f_2 \\le C$），那么它对于 $\\mathbf{u}$ 也是可行的（即 $u_2 + \\Delta f_2 \\le v_2 + \\Delta f_2 \\le C$）。\n比较最终的向量，我们发现 $u_1 + \\Delta f_1 \\le v_1 + \\Delta f_1$ 且 $u_2 + \\Delta f_2 \\le v_2 + \\Delta f_2$，且至少有一个不等式是严格的。因此，$\\mathbf{f}_{\\mathbf{u}}$ 支配或等于 $\\mathbf{f}_{\\mathbf{v}}$。这表明，任何可能基于状态 $\\mathbf{v}$ 构建的帕累托最优解，都可以被一个基于状态 $\\mathbf{u}$ 构建的相等或更优的解所替代。因此，在阶段 $k$ 可以安全地丢弃被支配状态 $\\mathbf{v}$，而不会丢失任何最终的非支配解。\n\n最终的帕累托前沿是在处理完所有 $n$ 个物品后的集合 $S_n$。\n\n**修剪的算法实现：**\n一种修剪集合 $T_k$ 的高效方法如下：\n1.  将 $T_k$ 中的向量 $(f_1, f_2)$ 首先按 $f_1$ 升序排序，其次按 $f_2$ 升序排序。\n2.  移除所有重复的向量。\n3.  遍历排序后的唯一列表以构建新的非支配集 $S_k$。初始化一个空列表 `pruned_list` 和一个变量 `min_f2_so_far` 为无穷大。\n4.  对于排序列表中的每个向量 $(f_1, f_2)$，如果 $f_2  \\text{min\\_f2\\_so\\_far}$，那么该向量未被任何先前接受的向量所支配。将 $(f_1, f_2)$ 添加到 `pruned_list` 中，并更新 $\\text{min\\_f2\\_so\\_far} = f_2$。\n5.  如果 $f_2 \\ge \\text{min\\_f2\\_so\\_far}$，则当前向量被一个先前接受的向量（其 $f_1$ 更小或相等，且 $f_2$ 更小）所支配，应被丢弃。\n\n最终算法如下：\n初始化 $S = \\{(0, 0)\\}$。\n对于从 $i=1$ 到 $n$ 的每个物品 $(p_i, w_i)$：\n1.  生成新向量：$S_{\\text{new}} = \\{ (f_1-p_i, f_2+w_i) \\mid (f_1, f_2) \\in S \\text{ 且 } f_2+w_i \\le C \\}$。\n2.  合并与筛选：$S = \\text{prune}(S \\cup S_{\\text{new}})$。\n遍历所有物品后，得到的集合 $S$ 就是所求的帕累托前沿。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the test cases and print the results.\n    \"\"\"\n    \n    def find_nondominated(items, C):\n        \"\"\"\n        Calculates the nondominated set for a bi-objective 0-1 knapsack problem.\n\n        Args:\n            items (list of tuples): A list of (value, weight) pairs for each item.\n            C (float or int): The capacity of the knapsack.\n\n        Returns:\n            list of lists: The set of nondominated objective vectors [f1, f2],\n                          sorted by f1 and then f2.\n        \"\"\"\n        # S is the set of nondominated objective vectors [f1, f2].\n        # f1 = -total_value, f2 = total_weight\n        # Initialize with the state of selecting no items.\n        S = [[0, 0]]\n\n        for p, w in items:\n            # Generate new states by adding the current item to existing states.\n            newly_generated = []\n            for f1, f2 in S:\n                # Check if adding the new item exceeds capacity.\n                if f2 + w = C:\n                    newly_generated.append([f1 - p, f2 + w])\n\n            # Merge the set of states from not adding the item (S)\n            # with the new states from adding the item (newly_generated).\n            combined_S = S + newly_generated\n\n            # Pruning Step:\n            # 1. Sort primarily by f1 (ascending), secondarily by f2 (ascending).\n            # Python's default sort on lists of lists achieves this.\n            combined_S.sort()\n\n            # 2. Filter out dominated and duplicate solutions.\n            pruned_S = []\n            if not combined_S:\n                S = []\n                continue\n\n            # Remove duplicates from the sorted list.\n            unique_S = [combined_S[0]]\n            for i in range(1, len(combined_S)):\n                if combined_S[i] != combined_S[i-1]:\n                    unique_S.append(combined_S[i])\n            \n            # Identify the nondominated front from the unique, sorted candidates.\n            # A point (f1, f2) is kept if its f2 is strictly smaller than the f2\n            # of all previously kept points. Since the list is sorted by f1,\n            # this guarantees nondominance.\n            min_f2_so_far = float('inf')\n            for f1, f2 in unique_S:\n                if f2  min_f2_so_far:\n                    pruned_S.append([f1, f2])\n                    min_f2_so_far = f2\n            \n            S = pruned_S\n\n        # The pruning logic already produces a list sorted by f1.\n        # A final sort ensures compliance with the output format specification.\n        S.sort()\n        return S\n\n    test_cases = [\n        # Test 1 (happy path)\n        ([(9, 4), (7, 3), (5, 2), (6, 5), (4, 3)], 10),\n        # Test 2 (boundary capacity)\n        ([(3, 2), (4, 5)], 0),\n        # Test 3 (zero-weight item edge case)\n        ([(2, 0), (5, 4), (1, 1)], 4),\n        # Test 4 (duplicate items edge case)\n        ([(3, 2), (3, 2)], 4),\n    ]\n\n    results = []\n    for items, C in test_cases:\n        nondominated_set = find_nondominated(items, C)\n        results.append(str(nondominated_set).replace(\" \", \"\"))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3154185"}]}