{"hands_on_practices": [{"introduction": "这个练习为 ε-约束法提供了一个直观的几何入门。通过将一个多目标问题置于一个简单的几何情境中——在约束面积的同时最小化距离——我们可以直接观察到最优解如何随着 ε 边界的变化而移动。这使得权衡曲线的概念变得具体而有形 [@problem_id:3199339]。", "problem": "考虑一个平面上的双目标几何设计问题。设固定点为 $\\mathbf{a} = (0,0)$ 和 $\\mathbf{b} = (4,0)$。一个设计点 $\\mathbf{x} = (x_1,x_2) \\in \\mathbb{R}^2$ 与顶点 $\\mathbf{a}$、$\\mathbf{b}$ 和 $\\mathbf{x}$ 构成一个三角形。第一个目标是最小化到目标点 $\\mathbf{x}_0 = (2,3)$ 的欧几里得范数（二维欧几里得范数，L2）距离：\n$$\nf_1(\\mathbf{x}) = \\|\\mathbf{x} - \\mathbf{x}_0\\|_2.\n$$\n第二个目标是三角形 $\\triangle(\\mathbf{a},\\mathbf{b},\\mathbf{x})$ 的面积，记为\n$$\nf_2(\\mathbf{x}) = \\text{Area}\\big(\\triangle(\\mathbf{a},\\mathbf{b},\\mathbf{x})\\big).\n$$\n使用 $\\varepsilon$-约束方法，考虑以下单目标问题族\n$$\n\\min_{\\mathbf{x} \\in \\mathbb{R}^2} \\; f_1(\\mathbf{x}) \\quad \\text{subject to} \\quad f_2(\\mathbf{x}) \\le \\varepsilon,\n$$\n其中 $\\varepsilon \\ge 0$ 是一个参数。\n\n从欧几里得距离的基本定义和三角形的几何面积公式（底乘以高除以 $2$）出发，推断当 $\\varepsilon$ 变化时可行集和最优解的性质。选择所有正确的陈述。\n\nA. 对于一个通用的 $\\varepsilon \\ge 0$，可行集是所有点构成的集合，这些点到经过 $\\mathbf{a}$ 和 $\\mathbf{b}$ 的直线的垂直距离不超过 $2\\varepsilon / \\|\\mathbf{b}-\\mathbf{a}\\|_2$。\n\nB. 对于具体数据 $\\mathbf{a} = (0,0)$、$\\mathbf{b} = (4,0)$ 和 $\\mathbf{x}_0 = (2,3)$，$\\varepsilon$-约束最优解为：当 $0 \\le \\varepsilon  6$ 时，$\\mathbf{x}^*(\\varepsilon) = (2,\\varepsilon/2)$；当 $\\varepsilon \\ge 6$ 时，$\\mathbf{x}^*(\\varepsilon) = (2,3)$。\n\nC. 作为 $\\varepsilon$ 函数的最优目标值为 $f_1^*(\\varepsilon) = \\max\\{0,\\, 3 - \\varepsilon/2\\}$。\n\nD. 当 $\\varepsilon$ 从 $0$ 增加到 $6$ 时，$\\varepsilon$-约束最优解的集合在决策空间中描绘出由 $\\{(2,y): 0 \\le y \\le 3\\}$ 给出的帕累托有效集。\n\nE. 对于 $0 \\le \\varepsilon  6$，最优解不唯一，并构成沿直线 $y = \\varepsilon/2$ 的一个水平线段。", "solution": "用户要求对问题陈述进行细致的验证，然后进行完整的推导和选项评估。\n\n### 问题验证\n\n**步骤 1：提取已知条件**\n- 固定点：$\\mathbf{a} = (0,0)$ 和 $\\mathbf{b} = (4,0)$\n- 设计点：$\\mathbf{x} = (x_1,x_2) \\in \\mathbb{R}^2$\n- 第一个目标函数（最小化）：$f_1(\\mathbf{x}) = \\|\\mathbf{x} - \\mathbf{x}_0\\|_2$，目标点为 $\\mathbf{x}_0 = (2,3)$\n- 第二个目标函数（隐式最小化，用作约束）：$f_2(\\mathbf{x}) = \\text{Area}\\big(\\triangle(\\mathbf{a},\\mathbf{b},\\mathbf{x})\\big)$\n- $\\varepsilon$-约束问题：$\\min_{\\mathbf{x} \\in \\mathbb{R}^2} \\; f_1(\\mathbf{x}) \\quad \\text{subject to} \\quad f_2(\\mathbf{x}) \\le \\varepsilon$，对于 $\\varepsilon \\ge 0$。\n\n**步骤 2：使用提取的已知条件进行验证**\n- **科学依据：** 该问题使用欧几里得几何（距离、面积）和最优化理论（多目标优化、$\\varepsilon$-约束方法）的基本概念进行表述。所有定义和原理都是标准的且在数学上是合理的。\n- **适定性：** 该问题是适定的。它指定了两个目标函数，并为给定的参数 $\\varepsilon$ 构建了一个标准的约束单目标问题。目标是找到一个点 $\\mathbf{x}$，使其在满足所定义三角形面积小于阈值 $\\varepsilon$ 的同时，最接近指定的目标点 $\\mathbf{x}_0$。对于给定的 $\\varepsilon \\ge 0$，存在唯一解。\n- **客观性：** 问题陈述使用了精确、无歧义的数学语言。\n- 该问题是自洽的、一致的，并且不违反任何数学原理或包含事实错误。它是多目标优化领域一个标准的说明性问题。\n\n**步骤 3：结论和行动**\n问题陈述是 **有效的**。现在开始求解过程。\n\n### 推导与求解\n\n核心任务是求解以下针对任意给定 $\\varepsilon \\ge 0$ 的优化问题：\n$$\n\\min_{\\mathbf{x} = (x_1,x_2) \\in \\mathbb{R}^2} \\; f_1(\\mathbf{x}) \\quad \\text{subject to} \\quad f_2(\\mathbf{x}) \\le \\varepsilon\n$$\n我们将从基本定义出发，推导目标函数和约束函数的显式表达式。\n\n**目标函数, $f_1(\\mathbf{x})$**\n第一个目标是设计点 $\\mathbf{x}=(x_1,x_2)$ 与目标点 $\\mathbf{x}_0=(2,3)$ 之间的欧几里得距离。其表达式为：\n$$\nf_1(\\mathbf{x}) = \\sqrt{(x_1 - 2)^2 + (x_2 - 3)^2}\n$$\n最小化 $f_1(\\mathbf{x})$ 等价于最小化其平方，$f_1(\\mathbf{x})^2 = (x_1 - 2)^2 + (x_2 - 3)^2$。无约束的最小值为 $0$，在 $\\mathbf{x} = \\mathbf{x}_0 = (2,3)$ 处取得。从几何上看，我们是在可行集中寻找离点 $(2,3)$ 最近的点 $\\mathbf{x}$。\n\n**约束函数, $f_2(\\mathbf{x})$**\n第二个目标，用作约束，是顶点为 $\\mathbf{a}=(0,0)$、$\\mathbf{b}=(4,0)$ 和 $\\mathbf{x}=(x_1,x_2)$ 的三角形的面积。\n三角形的面积由公式 $\\frac{1}{2} \\times \\text{底} \\times \\text{高}$ 给出。\n我们可以将连接 $\\mathbf{a}$ 和 $\\mathbf{b}$ 的线段作为三角形的底。底的长度为：\n$$\n\\|\\mathbf{b} - \\mathbf{a}\\|_2 = \\|(4,0) - (0,0)\\|_2 = \\sqrt{(4-0)^2 + (0-0)^2} = 4\n$$\n包含这个底的直线是 $x_1$ 轴，其方程为 $x_2 = 0$。三角形的高是从点 $\\mathbf{x}=(x_1,x_2)$ 到这条直线的垂直距离。这个距离就是 $|x_2|$。\n因此，面积为：\n$$\nf_2(\\mathbf{x}) = \\frac{1}{2} \\times 4 \\times |x_2| = 2|x_2|\n$$\n\n**约束优化问题**\n将 $f_2(\\mathbf{x})$ 的表达式代入约束条件，我们得到：\n$$\n2|x_2| \\le \\varepsilon\n$$\n因为 $\\varepsilon \\ge 0$，这等价于：\n$$\n|x_2| \\le \\frac{\\varepsilon}{2} \\quad \\text{或} \\quad -\\frac{\\varepsilon}{2} \\le x_2 \\le \\frac{\\varepsilon}{2}\n$$\n问题是找到一个点 $\\mathbf{x}=(x_1,x_2)$，其坐标 $x_2$ 在区间 $[-\\varepsilon/2, \\varepsilon/2]$ 内，并且该点离点 $(2,3)$ 最近。$\\mathbf{x}$ 的定义域是 $\\mathbb{R}^2$，因此对 $x_1$ 没有约束。\n\n为了最小化距离 $\\sqrt{(x_1-2)^2 + (x_2-3)^2}$：\n1.  通过选择 $x_1 = 2$，可以最小化（使其变为 $0$）项 $(x_1-2)^2$。\n2.  项 $(x_2-3)^2$ 必须在 $x_2 \\in [-\\varepsilon/2, \\varepsilon/2]$ 的约束下最小化。这是一个一维问题，即在一个区间内找到离点 $3$ 最近的点。\n\n我们根据 $\\varepsilon$ 的值对此进行分析：\n\n**情况 1: $\\varepsilon \\ge 6$**\n如果 $\\varepsilon \\ge 6$，那么 $\\varepsilon/2 \\ge 3$。$x_2$ 的可行区间是 $[-\\varepsilon/2, \\varepsilon/2]$，其中包含 $3$。\n在这种情况下，我们可以选择 $x_2 = 3$。这个选择将 $(x_2-3)^2$ 最小化为 $0$。\n因此，最优解是 $\\mathbf{x}^*(\\varepsilon) = (2,3)$，最小目标值为 $f_1^*(\\varepsilon) = f_1(2,3) = 0$。\n\n**情况 2: $0 \\le \\varepsilon  6$**\n如果 $0 \\le \\varepsilon  6$，那么 $0 \\le \\varepsilon/2  3$。$x_2$ 的可行区间是 $[-\\varepsilon/2, \\varepsilon/2]$。点 $3$ 在此区间之外。\n区间 $[-\\varepsilon/2, \\varepsilon/2]$ 内离 $3$ 最近的点是上端点 $x_2 = \\varepsilon/2$。\n因此，最优解是 $\\mathbf{x}^*(\\varepsilon) = (2, \\varepsilon/2)$。\n最小目标值为：\n$$\nf_1^*(\\varepsilon) = f_1(2, \\varepsilon/2) = \\sqrt{(2-2)^2 + (\\varepsilon/2 - 3)^2} = \\sqrt{(\\varepsilon/2 - 3)^2} = |\\varepsilon/2 - 3|\n$$\n由于 $\\varepsilon/2  3$，项 $\\varepsilon/2 - 3$ 是负数。因此， $|\\varepsilon/2 - 3| = -(\\varepsilon/2 - 3) = 3 - \\varepsilon/2$。\n\n**结果总结**\n作为 $\\varepsilon$ 函数的最优解为：\n$$\n\\mathbf{x}^*(\\varepsilon) = \\begin{cases} (2, \\varepsilon/2)  \\text{if } 0 \\le \\varepsilon  6 \\\\ (2, 3)  \\text{if } \\varepsilon \\ge 6 \\end{cases}\n$$\n作为 $\\varepsilon$ 函数的最优目标值为：\n$$\nf_1^*(\\varepsilon) = \\begin{cases} 3 - \\varepsilon/2  \\text{if } 0 \\le \\varepsilon  6 \\\\ 0  \\text{if } \\varepsilon \\ge 6 \\end{cases}\n$$\n这可以紧凑地写成 $f_1^*(\\varepsilon) = \\max\\{0, 3 - \\varepsilon/2\\}$。\n\n### 逐项分析\n\n**A. 对于一个通用的 $\\varepsilon \\ge 0$，可行集是所有点构成的集合，这些点到经过 $\\mathbf{a}$ 和 $\\mathbf{b}$ 的直线的垂直距离不超过 $2\\varepsilon / \\|\\mathbf{b}-\\mathbf{a}\\|_2$。**\n可行集由约束 $f_2(\\mathbf{x}) \\le \\varepsilon$ 定义。面积为 $f_2(\\mathbf{x}) = \\frac{1}{2} \\times \\text{底} \\times \\text{高}$。底是 $\\|\\mathbf{b}-\\mathbf{a}\\|_2$，高是从 $\\mathbf{x}$ 到经过 $\\mathbf{a}$ 和 $\\mathbf{b}$ 的直线的垂直距离。设此距离为 $d$。约束变为 $\\frac{1}{2} \\|\\mathbf{b}-\\mathbf{a}\\|_2 d \\le \\varepsilon$。重新整理得到距离 $d \\le \\frac{2\\varepsilon}{\\|\\mathbf{b}-\\mathbf{a}\\|_2}$。这个陈述是对可行集的精确文字描述。\n**结论：正确。**\n\n**B. 对于具体数据 $\\mathbf{a} = (0,0)$、$\\mathbf{b} = (4,0)$ 和 $\\mathbf{x}_0 = (2,3)$，$\\varepsilon$-约束最优解为：当 $0 \\le \\varepsilon  6$ 时，$\\mathbf{x}^*(\\varepsilon) = (2,\\varepsilon/2)$；当 $\\varepsilon \\ge 6$ 时，$\\mathbf{x}^*(\\varepsilon) = (2,3)$。**\n这个陈述与上面推导出的最优解 $\\mathbf{x}^*(\\varepsilon)$ 的总结完全匹配。对于 $0 \\le \\varepsilon  6$，可行带中离 $(2,3)$ 最近的点位于上边界 $x_2=\\varepsilon/2$ 处，且 $x_1=2$。对于 $\\varepsilon \\ge 6$，点 $(2,3)$ 本身就是可行的，从而得到可能的最小距离 $0$。\n**结论：正确。**\n\n**C. 作为 $\\varepsilon$ 函数的最优目标值为 $f_1^*(\\varepsilon) = \\max\\{0,\\, 3 - \\varepsilon/2\\}$。**\n这个陈述与上面推导出的最优目标值 $f_1^*(\\varepsilon)$ 的总结完全匹配。对于 $0 \\le \\varepsilon  6$，值为 $3 - \\varepsilon/2$，是正数。对于 $\\varepsilon \\ge 6$，值为 $0$。函数 $\\max\\{0, 3 - \\varepsilon/2\\}$ 精确地概括了这种分段定义。\n**结论：正确。**\n\n**D. 当 $\\varepsilon$ 从 $0$ 增加到 $6$ 时，$\\varepsilon$-约束最优解的集合在决策空间中描绘出由 $\\{(2,y): 0 \\le y \\le 3\\}$ 给出的帕累托有效集。**\n根据我们的推导，对于 $0 \\le \\varepsilon \\le 6$，最优解是 $\\mathbf{x}^*(\\varepsilon) = (2, \\varepsilon/2)$。当 $\\varepsilon$ 从 $0$ 变化到 $6$ 时，第二个坐标 $\\varepsilon/2$ 从 $0$ 变化到 $3$。因此解集是 $\\{(2,y) \\mid y = \\varepsilon/2, 0 \\le \\varepsilon \\le 6\\}$，这恰好是垂直线段 $\\{(2,y) \\mid 0 \\le y \\le 3\\}$。对于这个双目标问题，它是凸的（凸的目标函数 $f_1$，由 $f_2$ 定义的凸约束集），$\\varepsilon$-约束方法在 $\\varepsilon$ 从 $0$ 到 $f_2(\\mathbf{x}_1^*)$（其中 $\\mathbf{x}_1^*$ 是最小化 $f_1$ 的解）的范围内可以描绘出整个帕累托前沿。这里，$\\mathbf{x}_1^*=(2,3)$，且 $f_2(2,3) = 2|3| = 6$。范围 $0 \\le \\varepsilon \\le 6$ 是生成帕累托集的正确范围。所描述的线段确实是决策空间中的帕累托有效集。\n**结论：正确。**\n\n**E. 对于 $0 \\le \\varepsilon  6$，最优解不唯一，并构成沿直线 $y = \\varepsilon/2$ 的一个水平线段。**\n对于 $0 \\le \\varepsilon  6$，问题是在 $x_2 \\in [-\\varepsilon/2, \\varepsilon/2]$ 的约束下最小化 $(x_1-2)^2 + (x_2-3)^2$。$x_2$ 的最小化点唯一地是 $x_2 = \\varepsilon/2$。$x_1$ 的最小化点唯一地是 $x_1=2$，因为任何其他选择都会严格增加目标函数的值。因此，对于此范围内的每个 $\\varepsilon$ 值，最优解 $\\mathbf{x}^*(\\varepsilon) = (2, \\varepsilon/2)$ 都是唯一的。该陈述关于非唯一性的说法是错误的。\n**结论：错误。**", "answer": "$$\\boxed{ABCD}$$", "id": "3199339"}, {"introduction": "在掌握了基础知识之后，这个练习将探讨 ε-约束法一个更微妙的方面：它所生成解的质量。这个问题展示了一种情况，即该方法可能产生一个“弱帕累托有效”但实际上仍次优的解 [@problem_id:3199355]。通过分析这个例子，我们可以理解这种情况发生的原因，从而加深对该方法结果的批判性理解。", "problem": "考虑一个双目标最小化问题，决策变量为 $x$ 和 $y$：\n最小化目标向量 $(f_1(x,y), f_2(x,y))$，其中 $f_1(x,y) = x$ 且 $f_2(x,y) = y$，并满足以下线性约束条件\n$$x \\ge 0,\\quad y \\ge 0,\\quad x + y \\ge 1,\\quad y \\le 5,\\quad x \\le 2.$$\n$\\varepsilon$-约束方法通过最小化一个目标，同时对另一个目标施加上界 $\\varepsilon$ 来构造一个单目标问题。具体来说，这里我们在原始约束的基础上，最小化 $f_1(x,y)$，并满足 $f_2(x,y) \\le \\varepsilon$。如果存在另一个可行解，在两个目标上都分量不差，且至少在一个目标上严格更优，则称一个解为帕累托被支配的 (Pareto dominated)。如果不存在另一个可行解在两个目标上同时都严格更优，则称一个解为弱帕累托有效的 (weakly Pareto efficient)。\n\n哪个选项正确地指出了一个 $\\varepsilon$ 的选择和一个对应的 $\\varepsilon$-约束问题的最优解，该解是弱帕累托有效的，但被另一个可行解在一个目标上帕累托支配，并且这种情况的发生是因为添加的 $\\varepsilon$-约束相对于原始约束是冗余的？\n\nA. $\\varepsilon = 6$，一个最优的 $\\varepsilon$-约束解是 $(x,y) = (0,5)$。\n\nB. $\\varepsilon = 0.5$，一个最优的 $\\varepsilon$-约束解是 $(x,y) = (0.5,0.5)$。\n\nC. $\\varepsilon = 1$，一个最优的 $\\varepsilon$-约束解是 $(x,y) = (0,1)$。\n\nD. $\\varepsilon = 4$，一个最优的 $\\varepsilon$-约束解是 $(x,y) = (0,4)$。", "solution": "用户希望我通过分析 $\\varepsilon$-约束方法来解决一个多目标优化问题。\n\n### 第一步：提取已知条件\n- **问题类型**：双目标最小化。\n- **决策变量**：$x$, $y$。\n- **目标函数**：最小化向量 $(f_1(x,y), f_2(x,y))$，其中 $f_1(x,y) = x$ 且 $f_2(x,y) = y$。\n- **原始约束**：\n  1. $x \\ge 0$\n  2. $y \\ge 0$\n  3. $x + y \\ge 1$\n  4. $y \\le 5$\n  5. $x \\le 2$\n- **$\\varepsilon$-约束方法**：在满足原始约束和附加约束 $f_2(x,y) \\le \\varepsilon$（即 $y \\le \\varepsilon$）的条件下，最小化 $f_1(x,y)$。\n- **定义**：\n  - **帕累托被支配**：如果存在另一个可行解，在分量上不差，且至少在一个目标上严格更优，则一个解是帕累托被支配的。\n  - **弱帕累托有效**：如果不存在另一个可行解在两个目标上都严格更优，则一个解是弱帕累托有效的。\n- **问题**：找出一个 $\\varepsilon$ 的选择和一个对应的 $\\varepsilon$-约束问题的最优解，该解满足：\n  1. 弱帕累托有效，\n  2. 被另一个可行解在一个目标上帕累托支配，以及\n  3. 这种情况的发生是因为添加的约束 $y \\le \\varepsilon$ 相对于原始约束是冗余的。\n\n### 第二步：使用提取的已知条件进行验证\n问题陈述是多目标优化理论中的一个标准练习。它概述了一个双目标线性规划问题，并询问通过 $\\varepsilon$-约束方法获得的解的性质。所提供的帕累托支配和弱帕累托效率的定义是标准的。约束条件在 $\\mathbb{R}^2$ 中定义了一个非空、闭合且有界（即紧致）的凸可行域。语言精确客观。该问题具有科学依据，提法得当，没有歧义或矛盾。\n\n### 第三步：判断与行动\n问题有效。我将继续进行求解推导。\n\n### 求解推导\n\n首先，我们来描述由原始约束定义的可行集 $S$：\n$S = \\{(x,y) \\in \\mathbb{R}^2 \\mid x \\ge 0, y \\ge 0, x+y \\ge 1, y \\le 5, x \\le 2\\}$。\n这是一个凸多边形。其顶点可以通过边界线的交点找到：\n- $x=0$ 和 $x+y=1 \\implies (0,1)$\n- $x=0$ 和 $y=5 \\implies (0,5)$\n- $x=2$ 和 $y=5 \\implies (2,5)$\n- $x=2$ 和 $y=0 \\implies (2,0)$\n- $y=0$ 和 $x+y=1 \\implies (1,0)$\n可行集 $S$ 是这五个顶点的凸包：$(0,1)$、$(0,5)$、$(2,5)$、$(2,0)$ 和 $(1,0)$。\n\n问题要求我们分析一个涉及 $\\varepsilon$-约束方法的特定场景。让我们分解这些条件。限制性最强的条件是第三个：“这种情况的发生是因为添加的 $\\varepsilon$-约束相对于原始约束是冗余的”。\n\n添加的约束是 $y \\le \\varepsilon$。要使这个约束冗余，原始可行集 $S$ 中的每个点 $(x,y)$ 都必须已经满足 $y \\le \\varepsilon$。这等价于要求 $\\varepsilon$ 大于或等于 $S$ 中 $y$ 的最大可能值。\n从 $S$ 的顶点来看，$y$ 的最大值是 $5$，在点 $(0,5)$ 和 $(2,5)$ 处取得。\n因此，要使约束 $y \\le \\varepsilon$ 冗余，我们必须有 $\\varepsilon \\ge 5$。\n\n让我们基于这个发现来检查给定的选项：\n- A：$\\varepsilon = 6$。由于 $6 \\ge 5$，此选项满足冗余条件。\n- B：$\\varepsilon = 0.5$。由于 $0.5  5$，此选项违反了冗余条件。\n- C：$\\varepsilon = 1$。由于 $1  5$，此选项违反了冗余条件。\n- D：$\\varepsilon = 4$。由于 $4  5$，此选项违反了冗余条件。\n\n仅根据冗余条件，只有选项 A 是候选。我们现在必须验证选项 A 是否满足所有其他条件。\n\n### 逐项分析\n\n**A. $\\varepsilon = 6$，一个最优的 $\\varepsilon$-约束解是 $(x,y) = (0,5)$。**\n\n1.  **冗余性**：如前所述，对于 $\\varepsilon=6$，约束 $y \\le 6$ 是冗余的，因为可行集 $S$ 中的所有点都满足 $y \\le 5$。此条件满足。\n\n2.  **$\\varepsilon$-约束问题的最优解**：当 $\\varepsilon=6$ 时，$\\varepsilon$-约束问题是：\n    最小化 $f_1(x,y) = x$\n    约束条件为 $(x,y) \\in S$ 且 $y \\le 6$。\n    由于 $y \\le 6$ 是冗余的，问题就简化为在原始可行集 $S$ 上最小化 $x$。\n    通过检查 $S$ 的顶点，我们发现 $x$ 的最小值是 $0$。这个最小值在连接 $(0,1)$ 和 $(0,5)$ 的线段上的任何点都可以达到。这个最优解集是 $X^*_6 = \\{(0,y) \\mid 1 \\le y \\le 5\\}$。\n    点 $(0,5)$ 在这个集合 $X^*_6$ 中，所以它确实是 $\\varepsilon=6$ 时 $\\varepsilon$-约束问题的一个最优解。此条件满足。\n\n3.  **弱帕累托有效性**：如果不存在另一个可行解 $(x', y') \\in S$ 使得 $f_1(x',y')  f_1(x^*,y^*)$ 且 $f_2(x',y')  f_2(x^*,y^*)$，则解 $(x^*, y^*)$ 是弱帕累托有效的。在我们的例子中，这意味着 $x'  x^*$ 且 $y'  y^*$。\n    对于解 $(x^*, y^*) = (0,5)$，我们需要检查是否存在一个点 $(x', y') \\in S$ 满足 $x'  0$ 和 $y'  5$。由于约束 $x \\ge 0$ 是 $S$ 定义的一部分，因此不存在 $x'  0$ 的可行点。因此，不存在这样的点 $(x',y')$，解 $(0,5)$ 是弱帕累托有效的。此条件满足。\n\n4.  **帕累托支配**：如果存在另一个可行解 $(x',y') \\in S$ 使得 $(f_1(x',y'), f_2(x',y')) \\le (f_1(x^*,y^*), f_2(x^*,y^*))$ 且 $(f_1(x',y'), f_2(x',y')) \\ne (f_1(x^*,y^*), f_2(x^*,y^*))$，则解 $(x^*, y^*)$ 是帕累托被支配的。这意味着 $(x',y') \\le (x^*,y^*)$ 且 $(x',y') \\ne (x^*,y^*)$。\n    对于 $(x^*, y^*) = (0,5)$，我们寻找一个点 $(x',y') \\in S$ 满足 $x' \\le 0$ 和 $y' \\le 5$，且至少有一个不等式是严格的。\n    约束 $x \\ge 0$ 意味着我们必须有 $x'=0$。\n    所以我们需要一个点 $(0,y') \\in S$ 满足 $y'  5$。$y$ 轴上的可行线段是从 $y=1$ 到 $y=5$。\n    让我们选择可行点 $(0,4)$。我们有 $0 \\le 0$ 和 $4  5$。因此，解 $(0,4)$ 帕累托支配解 $(0,5)$。$(0,4)$ 的目标向量是 $(0,4)$，它在第二个分量上严格优于 $(0,5)$，在第一个分量上相等。\n    问题陈述中的“在一个目标上帕累托支配”正是描述了这种情况。此条件满足。\n\n$\\varepsilon$-约束问题的最优解集（即集合 $X^*_6$）的非唯一性，允许选择像 $(0,5)$ 这样的点，它对于主目标 ($f_1=x$) 是最优的，但对于该集合内的次要目标 ($f_2=y$) 并非最优。这导致它被 $X^*_6$ 中的其他点（如 $(0,1)$）帕累托支配。这种非唯一性是当应用冗余的 $\\varepsilon$-约束时，可行集几何形状的直接结果。所有条件都完全满足。\n\n**选项 A 的结论：正确。**\n\n**B. $\\varepsilon = 0.5$，一个最优的 $\\varepsilon$-约束解是 $(x,y) = (0.5,0.5)$。**\n约束 $y \\le 0.5$ 不是冗余的，因为像 $(0,1)$ 这样的点在 $S$ 中。冗余条件不满足。此外，对于 $\\varepsilon=0.5$，问题是在 $x+y \\ge 1$ 和 $0 \\le y \\le 0.5$（以及 $x \\ge 0, x \\le 2$）的条件下最小化 $x$。当 $y$ 取最大值，即 $y=0.5$ 时，$x$ 取得最小值。此时 $x=1-y=0.5$。解 $(0.5,0.5)$ 是唯一的。$\\varepsilon$-约束问题的唯一解总是帕累托有效的（而不仅仅是弱有效），因此不会被支配。此选项在多个方面都不满足要求。\n**选项 B 的结论：不正确。**\n\n**C. $\\varepsilon = 1$，一个最优的 $\\varepsilon$-约束解是 $(x,y) = (0,1)$。**\n约束 $y \\le 1$ 不是冗余的，因为像 $(0,5)$ 这样的点在 $S$ 中。冗余条件不满足。对于 $\\varepsilon=1$，问题是在 $y \\le 1$ 和原始约束条件下最小化 $x$。最小值 $x=0$ 在点 $(0,1)$ 处唯一达到。作为一个唯一的解，它是帕累托有效的，不会被支配。此选项不满足要求。\n**选项 C 的结论：不正确。**\n\n**D. $\\varepsilon = 4$，一个最优的 $\\varepsilon$-约束解是 $(x,y) = (0,4)$。**\n约束 $y \\le 4$ 不是冗余的，因为像 $(0,5)$ 这样的点在 $S$ 中。冗余条件不满足。虽然点 $(0,4)$ 确实是 $\\varepsilon=4$ 时 $\\varepsilon$-约束问题的一个最优解，是弱帕累托有效的，并且被帕累托支配（例如，被 $(0,3)$ 支配），但它不满足关键条件，即这种现象是由于冗余的 $\\varepsilon$-约束造成的。\n**选项 D 的结论：不正确。**\n\n只有选项 A 满足所有指定条件。", "answer": "$$\\boxed{A}$$", "id": "3199355"}, {"introduction": "最后的这个实践练习将理论上的帕累托前沿概念与其实际的数值计算联系起来。它要求您实现 ε-约束法来生成一个*近似*的帕累托集，并且至关重要地，量化这种近似所带来的误差。这对于任何优化算法的真实世界应用来说，都是一项至关重要的技能 [@problem_id:3199284]。", "problem": "考虑二维欧几里得空间中的双目标最小化问题：同时最小化 $f_1(\\mathbf{x})$ 和 $f_2(\\mathbf{x})$，其中 $\\mathbf{x} \\in \\mathbb{R}^2$，$f_1(\\mathbf{x}) = \\lVert \\mathbf{x} - \\mathbf{a} \\rVert_2^2$，$f_2(\\mathbf{x}) = \\lVert \\mathbf{x} - \\mathbf{b} \\rVert_2^2$，且 $\\mathbf{a}, \\mathbf{b} \\in \\mathbb{R}^2$ 为给定值。如果不存在点 $\\mathbf{x}$ 使得 $f_1(\\mathbf{x}) \\le f_1(\\mathbf{x}^\\star)$ 和 $f_2(\\mathbf{x}) \\le f_2(\\mathbf{x}^\\star)$ 同时成立且至少有一个不等式为严格不等式，则点 $\\mathbf{x}^\\star$ 是帕累托最优的。$\\varepsilon$-约束方法将双目标问题转化为标量优化问题：最小化 $f_1(\\mathbf{x})$，约束条件为 $f_2(\\mathbf{x}) \\le \\varepsilon$，其中界限 $\\varepsilon \\ge 0$ 为选定值。\n\n从上述基本定义和关于欧几里得投影的几何事实出发，您的任务是：\n\n1. 通过求解由 $\\varepsilon$-约束方法生成的标量优化问题，推导所述问题在目标空间中的精确帕累托集。求解时需覆盖区间 $[0, \\varepsilon_{\\max}]$ 内所有的 $\\varepsilon$，其中 $\\varepsilon_{\\max}$ 的选择应包含约束变为非约束性的边界情况。将精确帕累托集表示为从 $\\varepsilon$到目标对 $(f_1, f_2)$ 的连续映射。\n\n2. 使用一个在 $0$ 和 $\\varepsilon_{\\max}$ 之间（含两端）具有 $N$ 个采样点的 $\\varepsilon$ 值均匀网格，构建一个近似帕累托集。该网格为 $\\{\\varepsilon_k\\}_{k=1}^N$，其中 $\\varepsilon_k$ 是均匀间隔的。对于每个 $\\varepsilon_k$，求解标量问题并记录目标对 $(f_1(\\mathbf{x}_k), f_2(\\mathbf{x}_k))$。\n\n3. 通过两种方式量化使用粗糙 $\\varepsilon$ 网格引入的近似误差：\n   - 最近邻集近似：对于给定 $\\varepsilon$ 下连续帕累托集上的每个精确点，测量其在目标空间中到近似集中最近采样点的欧几里得距离，并取其在 $\\varepsilon \\in [0, \\varepsilon_{\\max}]$ 上的上确界。这定义了一个从连续集到离散近似的定向类豪斯多夫误差。通过在 $0$ 和 $\\varepsilon_{\\max}$ 之间（含两端）具有 $M$ 个等间距 $\\varepsilon$ 值的精细评估网格上进行评估，来数值近似该上确界。将此误差报告为非负浮点数。\n   - 分段线性插值：构建一个关于 $\\varepsilon$ 的分段线性函数，该函数对采样得到的 $f_1$ 值（在对应的采样 $\\varepsilon$ 值处）进行插值。对于精细网格中的每个评估值 $\\varepsilon$，计算精确的 $f_1(\\varepsilon)$ 与在相同 $\\varepsilon$ 处的插值 $f_1$ 之间的绝对差，并取其在整个评估网格上的上确界。将此误差报告为非负浮点数。\n\n4. 提出并实现上述两种插值/近似策略（目标空间中的最近邻和标量映射中的分段线性），并计算它们相应的误差。\n\n仅使用纯数学定义；不涉及物理单位。不涉及角度。您的程序必须以浮点数形式产生可量化的输出。\n\n测试套件：\n对于下面的每个测试用例，使用 $\\varepsilon_{\\max} = \\lVert \\mathbf{a} - \\mathbf{b} \\rVert_2^2$，以及评估网格大小 $M = 10001$。\n\n- 测试用例 1: $\\mathbf{a} = (3, 1)$，$\\mathbf{b} = (0, 0)$，$N = 5$。\n- 测试用例 2: $\\mathbf{a} = (2, -1)$，$\\mathbf{b} = (1, 2)$，$N = 50$。\n- 测试用例 3: $\\mathbf{a} = (0.5, -0.5)$，$\\mathbf{b} = (0, 0)$，$N = 2$。\n- 测试用例 4: $\\mathbf{a} = (1.3, 2.1)$，$\\mathbf{b} = (-0.7, 1.6)$，$N = 11$。\n\n最终输出格式：\n您的程序应产生单行输出，其中包含一个用方括号括起来的逗号分隔列表。列表中的每个元素对应一个测试用例，其本身是一个包含两个浮点数的列表，顺序为 $[E_{\\text{nn}}, E_{\\text{lin}}]$，其中 $E_{\\text{nn}}$ 是最近邻近似的定向类豪斯多夫误差，$E_{\\text{lin}}$ 是分段线性近似的最大绝对插值误差。例如：“[[e_nn_case1,e_lin_case1],[e_nn_case2,e_lin_case2],...]”。", "solution": "所提出的问题是一个适定的双目标优化问题，它基于基本的数学原理。它要求推导一对特定目标函数的帕累托最优集，并分析由采用离散化约束边界网格的 $\\varepsilon$-约束方法所引入的近似误差。所有术语都得到了正式定义，提供的数据一致且完整。因此，该问题被认为是有效的，有必要提供完整的解决方案。\n\n问题的核心是同时最小化两个目标：\n$f_1(\\mathbf{x}) = \\lVert \\mathbf{x} - \\mathbf{a} \\rVert_2^2$\n$f_2(\\mathbf{x}) = \\lVert \\mathbf{x} - \\mathbf{b} \\rVert_2^2$\n其中 $\\mathbf{x}, \\mathbf{a}, \\mathbf{b} \\in \\mathbb{R}^2$。目标函数表示点 $\\mathbf{x}$ 到两个固定点 $\\mathbf{a}$ 和 $\\mathbf{b}$ 的欧几里得距离的平方。一个解必须在与 $\\mathbf{a}$ 的邻近度和与 $\\mathbf{b}$ 的邻近度之间进行权衡。所有这些最优权衡解的集合构成了帕累托集。\n\n一个关键的几何洞察是，任何帕累托最优解 $\\mathbf{x}^\\star$ 都必须位于连接 $\\mathbf{a}$ 和 $\\mathbf{b}$ 的线段上。对于不在此线段上的任何点 $\\mathbf{x}$，其到该线段的正交投影 $\\mathbf{p}$ 将支配它（即，$\\mathbf{p}$ 在至少一个目标上严格更优，而在另一个目标上不差），因为对于包含 $\\mathbf{p}$ 的任何子线段，$\\mathbf{p}$ 都更接近其两个端点。这意味着决策空间中的帕累托前沿是线段 $[\\mathbf{a}, \\mathbf{b}]$。我们将使用 $\\varepsilon$-约束方法正式推导目标空间中相应的帕累托集。\n\n**1. 精确帕累托集的推导**\n\n$\\varepsilon$-约束方法将双目标问题转化为一系列单目标约束问题。对于给定的上界 $\\varepsilon \\ge 0$，我们求解问题 $P_\\varepsilon$：\n$$\n\\begin{aligned}\n \\underset{\\mathbf{x} \\in \\mathbb{R}^2}{\\text{minimize}}\n  f_1(\\mathbf{x}) = \\lVert \\mathbf{x} - \\mathbf{a} \\rVert_2^2 \\\\\n \\text{subject to}\n  f_2(\\mathbf{x}) = \\lVert \\mathbf{x} - \\mathbf{b} \\rVert_2^2 \\le \\varepsilon\n\\end{aligned}\n$$\n这个问题等价于在以 $\\mathbf{b}$ 为中心、半径为 $\\sqrt{\\varepsilon}$ 的闭圆盘中，寻找离点 $\\mathbf{a}$ 最近的点 $\\mathbf{x}$。这是一个欧几里得投影问题。最优解 $\\mathbf{x}^*(\\varepsilon)$ 是 $\\mathbf{a}$ 在该圆盘上的投影。\n\n我们根据 $\\mathbf{a}$相对于可行圆盘的位置考虑两种情况：\n- 如果 $\\mathbf{a}$ 在圆盘内部或边界上，即 $\\lVert \\mathbf{a} - \\mathbf{b} \\rVert_2^2 \\le \\varepsilon$，则 $f_1(\\mathbf{x})$ 的无约束最小化子 $\\mathbf{x} = \\mathbf{a}$ 是可行的。因此，$\\mathbf{x}^*(\\varepsilon) = \\mathbf{a}$。这对应于 $f_1$ 的最小可能值，即 $f_1(\\mathbf{a}) = 0$。对于任何 $\\varepsilon \\ge \\lVert \\mathbf{a} - \\mathbf{b} \\rVert_2^2$，该约束变为非约束性的。问题指定了 $\\varepsilon_{\\max} = \\lVert \\mathbf{a} - \\mathbf{b} \\rVert_2^2$，这恰好是这个边界情况。\n- 如果 $\\mathbf{a}$ 在圆盘外部，即 $\\lVert \\mathbf{a} - \\mathbf{b} \\rVert_2^2  \\varepsilon$，则解 $\\mathbf{x}^*(\\varepsilon)$ 位于圆盘的边界上，意味着约束是活性的：$f_2(\\mathbf{x}^*(\\varepsilon)) = \\varepsilon$。边界上最近的点是连接中心 $\\mathbf{b}$ 和外部点 $\\mathbf{a}$ 的线段上的点。解可以表示为：\n$$\n\\mathbf{x}^*(\\varepsilon) = \\mathbf{b} + \\sqrt{\\varepsilon} \\frac{\\mathbf{a} - \\mathbf{b}}{\\lVert \\mathbf{a} - \\mathbf{b} \\rVert_2}\n$$\n现在，我们计算在该点处的 $f_1$ 值。令 $D = \\lVert \\mathbf{a} - \\mathbf{b} \\rVert_2$。\n$$\n\\mathbf{x}^*(\\varepsilon) - \\mathbf{a} = \\left(\\mathbf{b} + \\frac{\\sqrt{\\varepsilon}}{D}(\\mathbf{a} - \\mathbf{b})\\right) - \\mathbf{a} = (\\mathbf{b} - \\mathbf{a}) + \\frac{\\sqrt{\\varepsilon}}{D}(\\mathbf{a} - \\mathbf{b}) = \\left(\\frac{\\sqrt{\\varepsilon}}{D} - 1\\right)(\\mathbf{a} - \\mathbf{b})\n$$\n目标值 $f_1$ 为：\n$$\nf_1(\\mathbf{x}^*(\\varepsilon)) = \\left\\lVert \\left(\\frac{\\sqrt{\\varepsilon}}{D} - 1\\right)(\\mathbf{a} - \\mathbf{b}) \\right\\rVert_2^2 = \\left(\\frac{\\sqrt{\\varepsilon}}{D} - 1\\right)^2 D^2 = ( \\sqrt{\\varepsilon} - D)^2 = (D - \\sqrt{\\varepsilon})^2\n$$\n该公式在整个关注范围 $\\varepsilon \\in [0, \\varepsilon_{\\max}]$ 内都成立。当 $\\varepsilon = \\varepsilon_{\\max} = D^2$ 时，它给出 $f_1 = (D - \\sqrt{D^2})^2 = 0$，这与第一种情况一致。\n\n因此，目标空间中的精确帕累托集是当 $\\varepsilon$ 从 $0$ 变化到 $\\varepsilon_{\\max}$ 时，由 $(f_1, f_2)$ 描绘出的参数曲线：\n$$\n(f_1(\\varepsilon), f_2(\\varepsilon)) = \\left( (D - \\sqrt{\\varepsilon})^2, \\varepsilon \\right), \\quad \\text{for } \\varepsilon \\in [0, D^2]\n$$\n其中 $D = \\lVert \\mathbf{a} - \\mathbf{b} \\rVert_2$。令 $f_1=y_1$ 和 $f_2=y_2$，这个关系可以写成 $\\sqrt{y_1} + \\sqrt{y_2} = D$，这是一段抛物线弧的方程。\n\n**2. 近似帕累托集与误差量化**\n\n通过为区间 $[0, \\varepsilon_{\\max}]$ 内一组离散的 $N$ 个均匀间隔的 $\\varepsilon$ 值求解 $P_\\varepsilon$，可以构建一个近似帕累托集。设此网格为 $\\{\\varepsilon_k\\}_{k=1}^N$。近似集是目标对的集合：\n$$ \\mathcal{P}_{\\text{approx}} = \\{ (f_1(\\varepsilon_k), f_2(\\varepsilon_k)) \\}_{k=1}^N $$\n问题要求使用一个包含 $M$ 个点的精细评估网格（对于 $\\varepsilon \\in [0, \\varepsilon_{\\max}]$）来近似上确界，从而通过两种方式量化这种离散近似的误差。\n\n- **最近邻集近似误差 ($E_{\\text{nn}}$)**：此误差衡量真实连续帕累托曲线上任意点到计算出的离散点集的距离。它被定义为从精确集 $\\mathcal{P}_{\\text{exact}}$ 到近似集 $\\mathcal{P}_{\\text{approx}}$ 的一个定向豪斯多夫距离：\n$$\nE_{\\text{nn}} = \\sup_{\\mathbf{p} \\in \\mathcal{P}_{\\text{exact}}} \\inf_{\\mathbf{q} \\in \\mathcal{P}_{\\text{approx}}} \\lVert \\mathbf{p} - \\mathbf{q} \\rVert_2\n$$\n这通过计算 $\\max_i \\min_k \\lVert \\mathbf{p}_i - \\mathbf{q}_k \\rVert_2$ 来进行数值近似，其中 $\\{\\mathbf{p}_i\\}$ 是在精细的 M 点网格上采样的真实帕累托曲线上的点，而 $\\{\\mathbf{q}_k\\}$ 是 $\\mathcal{P}_{\\text{approx}}$ 中的点。\n\n- **分段线性插值误差 ($E_{\\text{lin}}$)**：此误差评估了函数 $f_1(\\varepsilon)$ 能否通过线性插值从 $N$ 个样本中很好地重建。我们创建一个分段线性函数 $\\tilde{f}_1(\\varepsilon)$，它对点 $(\\varepsilon_k, f_1(\\varepsilon_k))$ 进行插值。误差是真实函数与插值函数在评估区间上的最大绝对差：\n$$\nE_{\\text{lin}} = \\sup_{\\varepsilon \\in [0, \\varepsilon_{\\max}]} |f_1(\\varepsilon) - \\tilde{f}_1(\\varepsilon)|\n$$\n这通过在精细的 M 点 $\\varepsilon$ 值网格上取此差值的最大值来进行数值近似。\n\n**3. 算法实现**\n\n计算这些误差的算法如下：\n1. 对于给定的测试用例 $(\\mathbf{a}, \\mathbf{b}, N)$，首先计算 $D = \\lVert \\mathbf{a} - \\mathbf{b} \\rVert_2$ 和 $\\varepsilon_{\\max} = D^2$。\n2. 使用 `np.linspace(0, epsilon_max, N)` 生成包含 $N$ 个点的粗糙网格 $\\{\\varepsilon_k\\}$。\n3. 通过对每个 $\\varepsilon_k$ 计算 $( (D - \\sqrt{\\varepsilon_k})^2, \\varepsilon_k )$ 来计算近似帕累托集 $\\mathcal{P}_{\\text{approx}}$。这将得到一个包含 $N$ 个 $\\mathbb{R}^2$ 中点的数组。\n4. 生成包含 $M$ 个点的精细评估网格 $\\{\\varepsilon_i^{\\text{eval}}\\}$。\n5. 为精细网格计算“真实”帕累托点 $\\mathbf{p}_i = ( (D - \\sqrt{\\varepsilon_i^{\\text{eval}}})^2, \\varepsilon_i^{\\text{eval}} )$。\n6. 为计算 $E_{\\text{nn}}$，对于每个点 $\\mathbf{p}_i$，计算其到 $\\mathcal{P}_{\\text{approx}}$ 中所有点的欧几里得距离并找到最小值。这些最小距离中的最大值即为 $E_{\\text{nn}}$。这可以通过使用 NumPy 的广播功能来高效地计算一个 $M \\times N$ 的距离矩阵来完成。\n7. 为计算 $E_{\\text{lin}}$，首先获取粗糙网格上的值 $f_1(\\varepsilon_k)$。然后，使用 `np.interp` 在精细网格上找到插值 $\\tilde{f}_1(\\varepsilon_i^{\\text{eval}})$。同时，计算真实值 $f_1(\\varepsilon_i^{\\text{eval}})$。绝对差 $|f_1(\\varepsilon_i^{\\text{eval}}) - \\tilde{f}_1(\\varepsilon_i^{\\text{eval}})|$ 的最大值即为 $E_{\\text{lin}}$。\n8. 记录该测试用例的误差对 $[E_{\\text{nn}}, E_{\\text{lin}}]$。对所有测试用例重复此过程。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the bi-objective optimization problem for a series of test cases.\n    For each case, it calculates two types of approximation errors:\n    1. E_nn: A directed Hausdorff-like distance from the continuous Pareto\n       set to a discrete approximation.\n    2. E_lin: The maximum absolute error of a piecewise-linear interpolation\n       of the first objective function.\n    \"\"\"\n    test_cases = [\n        (np.array([3.0, 1.0]), np.array([0.0, 0.0]), 5),\n        (np.array([2.0, -1.0]), np.array([1.0, 2.0]), 50),\n        (np.array([0.5, -0.5]), np.array([0.0, 0.0]), 2),\n        (np.array([1.3, 2.1]), np.array([-0.7, 1.6]), 11),\n    ]\n    M = 10001 # Size of the fine evaluation grid\n\n    all_results = []\n    for case in test_cases:\n        a, b, N = case\n\n        # Part 1: Setup parameters\n        D_sq = np.sum((a - b)**2)\n        \n        # Handle the degenerate case where a = b\n        if D_sq == 0:\n            all_results.append([0.0, 0.0])\n            continue\n        \n        D = np.sqrt(D_sq)\n        epsilon_max = D_sq\n\n        # Part 2: Generate the N-point approximate Pareto set\n        eps_grid_N = np.linspace(0, epsilon_max, N)\n        f1_grid_N = (D - np.sqrt(eps_grid_N))**2\n        f2_grid_N = eps_grid_N\n        # approx_set shape: (N, 2)\n        approx_set = np.vstack((f1_grid_N, f2_grid_N)).T\n\n        # Part 3: Setup for error evaluation using the M-point fine grid\n        eval_eps = np.linspace(0, epsilon_max, M, endpoint=True)\n        eval_f1 = (D - np.sqrt(eval_eps))**2\n        eval_f2 = eval_eps\n        # exact_points shape: (M, 2)\n        exact_points = np.vstack((eval_f1, eval_f2)).T\n\n        # Part 4: Calculate Nearest-Neighbor Error (E_nn)\n        # We compute the squared Euclidean distance from each of the M exact points\n        # to each of the N approximate points.\n        # Broadcasting: exact_points (M,1,2) - approx_set (1,N,2) -> diff (M,N,2)\n        diff = exact_points[:, np.newaxis, :] - approx_set[np.newaxis, :, :]\n        dist_sq_matrix = np.sum(diff**2, axis=2) # Shape (M, N)\n        \n        # For each exact point, find the squared distance to the nearest neighbor\n        # in the approximate set.\n        min_dist_sq_per_exact_point = np.min(dist_sq_matrix, axis=1) # Shape (M,)\n        \n        # The error E_nn is the supremum (max) of these minimum distances.\n        E_nn = np.sqrt(np.max(min_dist_sq_per_exact_point))\n\n        # Part 5: Calculate Piecewise-Linear Interpolation Error (E_lin)\n        # Interpolate f1 values from the coarse grid onto the fine grid.\n        interp_f1 = np.interp(eval_eps, eps_grid_N, f1_grid_N)\n        \n        # E_lin is the maximum absolute difference between the exact f1\n        # and the interpolated f1 over the fine grid.\n        abs_diff = np.abs(eval_f1 - interp_f1)\n        E_lin = np.max(abs_diff)\n        \n        all_results.append([E_nn, E_lin])\n\n    # Format the final output string as specified in the problem.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "3199284"}]}