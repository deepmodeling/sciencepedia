{"hands_on_practices": [{"introduction": "这第一个练习是基础。我们将处理一个右侧存在不确定性的线性系统，通过应用最坏情况分析原则和对偶范数的概念，我们会将这个不确定问题转化为一个确定性问题——即其“鲁棒对应项”。这个练习对于理解如何使约束对共享的$\\ell_1$-范数不确定性预算免疫至关重要。[@problem_id:3173984]", "problem": "考虑一个不确定线性不等式系统，其中包含一个 $m \\times n$ 矩阵 $A$、一个向量 $b \\in \\mathbb{R}^m$ 以及一个决策向量 $x \\in \\mathbb{R}^n$。不确定性仅限于右侧，并建模为 $A x \\le b + \\Delta b$，其中扰动向量 $\\Delta b \\in \\mathbb{R}^m$ 属于集合 $\\{\\Delta b : \\|\\Delta b\\|_{1} \\le \\rho\\}$，对于给定的预算 $\\rho \\ge 0$。鲁棒可行性要求是，对于该集合中的每一个 $\\Delta b$，所有 $m$ 个不等式都必须成立。\n\n从鲁棒可行性的定义和$\\ell_1$范数的对偶范数定义出发，推导出一个不含 $\\Delta b$ 的确定性等价形式（鲁棒对应形式），该形式必须对 $x$ 成立以保证鲁棒可行性。证明存在一个仅依赖于 $\\rho$ 的单一标量安全裕度 $\\tau(\\rho) \\ge 0$，使得鲁棒对应形式可以表示为 $A x \\le b - \\tau(\\rho)\\,\\mathbf{1}_{m}$，其中 $\\mathbf{1}_{m} \\in \\mathbb{R}^{m}$ 是全一向量。确定 $\\tau(\\rho)$ 的精确闭式表达式。\n\n运用你的推导，简要解释共享预算 $\\|\\Delta b\\|_{1} \\le \\rho$ 如何在鲁棒对应形式的约束之间引入冗余。\n\n你的最终答案必须是 $\\tau(\\rho)$ 的单一闭式表达式，不带单位，也无需四舍五入。", "solution": "问题在于找到一个不确定线性不等式系统的确定性鲁棒对应形式，并确定一个特定的安全裕度函数 $\\tau(\\rho)$。\n\n### 第1步：问题验证\n\n该问题陈述是鲁棒优化理论中的一个标准练习。\n**给定条件：**\n- 一个不确定线性不等式系统 $A x \\le b + \\Delta b$，其中 $A$ 是一个 $m \\times n$ 矩阵，$x \\in \\mathbb{R}^n$ 是决策向量，$b \\in \\mathbb{R}^m$。\n- 不确定性向量 $\\Delta b \\in \\mathbb{R}^m$ 属于不确定性集合 $U = \\{\\Delta b \\in \\mathbb{R}^m : \\|\\Delta b\\|_{1} \\le \\rho\\}$，其中 $\\rho \\ge 0$ 是给定的不确定性预算。范数 $\\|\\cdot\\|_1$ 是 $\\ell_1$-范数，定义为 $\\|\\Delta b\\|_1 = \\sum_{i=1}^m |(\\Delta b)_i|$。\n- 鲁棒可行性要求：不等式 $A x \\le b + \\Delta b$ 必须对每个 $\\Delta b \\in U$ 都成立。\n- 鲁棒对应形式的目标形式为 $A x \\le b - \\tau(\\rho)\\,\\mathbf{1}_{m}$，其中 $\\mathbf{1}_{m}$ 是 $m$ 维全一向量。\n\n**验证：**\n- **科学依据：** 该问题坚实地植根于数学领域的鲁棒优化，这是优化方法的一个子学科。$\\ell_p$-范数、对偶范数和鲁棒对应形式等概念都已是公认的。\n- **适定性：** 该问题陈述清晰，并要求推导一个特定的结果。它是自洽的，并且有一个唯一的、明确定义的解。\n- **客观性：** 其语言是正式的、数学的，没有任何主观性或模糊性。\n\n该问题是有效的，因为它满足了一个适定科学问题的所有标准。它不是推测性的、不完整的、矛盾的或琐碎的。\n\n### 第2步：推导鲁棒对应形式\n\n鲁棒可行性要求指出，不等式系统 $A x \\le b + \\Delta b$ 必须对其定义集 $U$ 内不确定性向量 $\\Delta b$ 的所有可能实现都成立。\n设 $a_i^T$ 是矩阵 $A$ 的第 $i$ 行，因此 $(Ax)_i = a_i^T x$。鲁棒可行性条件可以写成：\n$$ a_i^T x \\le b_i + (\\Delta b)_i, \\quad \\forall i \\in \\{1, \\dots, m\\}, \\quad \\forall \\Delta b \\in U = \\{\\Delta b : \\|\\Delta b\\|_1 \\le \\rho\\} $$\n全称量词 $\\forall \\Delta b \\in U$ 适用于整个 $m$ 个不等式集合。我们可以交换全称量词 $\\forall i$ 和 $\\forall \\Delta b$ 的顺序而不改变逻辑陈述。这使我们能够解耦问题并单独考虑每个约束。对于每个约束 $i \\in \\{1, \\dots, m\\}$，不等式 $a_i^T x \\le b_i + (\\Delta b)_i$ 必须对集合 $U$ 中的所有 $\\Delta b$ 成立。\n\n对于一个固定的决策向量 $x$ 和一个固定的约束索引 $i$，项 $a_i^T x - b_i$ 是一个常数。该不等式即使对于 $\\Delta b \\in U$ 的“最坏情况”选择也必须成立，即最小化右侧 $b_i + (\\Delta b)_i$ 的情况。因此，对于每个 $i$，我们必须满足：\n$$ a_i^T x \\le b_i + \\min_{\\Delta b \\in U} \\{(\\Delta b)_i\\} $$\n问题简化为在不确定性集合上评估 $\\Delta b$ 的第 $i$ 个分量的最小值。设 $e_i \\in \\mathbb{R}^m$ 是第 $i$ 个标准基向量（一个在第 $i$ 个位置为1，其余位置为0的向量）。那么 $(\\Delta b)_i$ 可以写成内积 $e_i^T \\Delta b$。优化问题是：\n$$ \\min_{\\|\\Delta b\\|_1 \\le \\rho} e_i^T \\Delta b $$\n这等价于：\n$$ - \\max_{\\|\\Delta b\\|_1 \\le \\rho} (-e_i^T \\Delta b) = - \\max_{\\|\\Delta b\\|_1 \\le \\rho} \\Delta b^T (-e_i) $$\n我们现在使用对偶范数的定义。$\\ell_1$-范数的对偶范数是 $\\ell_\\infty$-范数，记为 $\\|\\cdot\\|_\\infty$。对于一个通用向量 $v$，对偶关系由下式给出：\n$$ \\sup_{\\|\\Delta b\\|_1 \\le \\rho} \\Delta b^T v = \\rho \\|v\\|_\\infty $$\n在我们的例子中，向量 $v$ 是 $-e_i$。我们计算它的 $\\ell_\\infty$-范数：\n$$ \\|-e_i\\|_\\infty = \\max_{j=1, \\dots, m} |(-e_i)_j| = 1 $$\n将这个结果代入我们的表达式中，我们找到最大值：\n$$ \\max_{\\|\\Delta b\\|_1 \\le \\rho} \\Delta b^T (-e_i) = \\rho \\|-e_i\\|_\\infty = \\rho \\cdot 1 = \\rho $$\n因此，我们寻求的最小值是：\n$$ \\min_{\\|\\Delta b\\|_1 \\le \\rho} (\\Delta b)_i = -\\rho $$\n这个最小值由特定的扰动 $\\Delta b^* = -\\rho e_i$ 达到，它满足 $\\|\\Delta b^*\\|_1 = |-\\rho| = \\rho$，因此是不确定性集合 $U$ 的一个元素。\n\n将这个最小值代入第 $i$ 个约束的不等式中，得到其确定性鲁棒对应形式：\n$$ a_i^T x \\le b_i - \\rho $$\n因为这必须对所有 $i \\in \\{1, \\dots, m\\}$ 成立，我们可以用向量形式写出完整的鲁棒对应形式：\n$$ A x \\le b - \\rho\\,\\mathbf{1}_{m} $$\n其中 $\\mathbf{1}_{m} \\in \\mathbb{R}^{m}$ 是全一向量。\n\n### 第3步：确定 $\\tau(\\rho)$\n\n问题要求将鲁棒对应形式表示为 $A x \\le b - \\tau(\\rho)\\,\\mathbf{1}_{m}$ 的形式。通过将其与我们推导出的鲁棒对应形式 $A x \\le b - \\rho\\,\\mathbf{1}_{m}$ 进行比较，我们可以直接确定安全裕度 $\\tau(\\rho)$ 的闭式表达式。\n$$ \\tau(\\rho) = \\rho $$\n\n### 第4步：冗余性解释\n\n推导出的鲁棒对应形式 $A x \\le b - \\rho\\,\\mathbf{1}_{m}$ 是原始不确定问题的精确、非保守的确定性等价形式。问题陈述中提到的“冗余”指的是根据共享的不确定性预算来解释此对应形式的结构。\n\n我们的推导表明，每一行 $i$ 的鲁棒约束是 $a_i^T x \\le b_i - \\rho$。将约束加强一个量 $\\rho$ 是必要的，以防止该行的特定最坏情况扰动，即 $\\Delta b = -\\rho e_i$。这种扰动将整个不确定性预算 $\\rho$ 用于对第 $i$ 个约束产生不利影响，而使所有其他约束 $j \\neq i$ 不受扰动（因为 $(\\Delta b)_j=0$）。\n\n共享预算约束 $\\|\\Delta b\\|_1 \\le \\rho$ 在影响不同不等式的扰动之间建立了耦合关系。例如，如果作用于约束 $i=1$ 的扰动很大，比如 $|(\\Delta b)_1| = \\rho$，那么对于所有 $j > 1$，必然有 $(\\Delta b)_j = 0$。两个约束，比如说 $i=1$ 和 $i=2$，不可能同时经历它们各自的最坏情况扰动（分别为 $\\Delta b = -\\rho e_1$ 和 $\\Delta b = -\\rho e_2$），因为这两种情况都会耗尽整个共享预算。\n\n鲁棒对应形式，作为 $m$ 个不等式 $\\{a_i^T x \\le b_i - \\rho\\}_{i=1}^m$ 的集合，有效地确保了解 $x$ 对于 $m$ 个互斥的最坏情况场景中的每一个都是可行的。因此，该公式在结构上是冗余的，因为它为一组 $m$ 个极端事件做准备，而在任何给定时间点，这些事件中只有一个可能发生。鲁棒性的总“成本”，以右侧减去的总和来衡量，是 $m\\rho$，尽管总的不确定性“供给”被限制在 $\\rho$。这说明了共享预算如何在构成鲁棒对应形式的约束系统中引入一种冗余。", "answer": "$$ \\boxed{\\rho} $$", "id": "3173984"}, {"introduction": "基于我们推导鲁棒对应项的能力，这个练习将探讨我们如何对不确定性进行建模所带来的实际影响。我们将比较一个能够捕捉相关性的复杂椭球不确定性集合与一个忽略这些相关性的简单箱形集合，这个具体的反例将展示忽略相关性会导致过度保守的解决方案，从而凸显了深思熟虑地进行不确定性建模的重要性。[@problem_id:3173992]", "problem": "考虑以下具有相关系数不确定性的鲁棒优化（Robust Optimization, RO）模型。给定一个具有不确定线性约束的双变量线性规划问题。设决策向量为 $x = (x_1, x_2)^\\top$，其中 $x_1 \\ge 0$ 且 $x_2 \\ge 0$。约束中的名义系数向量为 $a_0 = (1, 1)^\\top$，不确定扰动为一个向量 $z \\in \\mathbb{R}^2$。目标是最大化决策变量之和。不确定约束必须对指定不确定性集合中的所有扰动 $z$ 成立：\n- 真实相关不确定性集合（椭球体）：$U_{\\text{ellip}} = \\{ z \\in \\mathbb{R}^2 : z^\\top \\Sigma^{-1} z \\le 1 \\}$，其中 $\\Sigma = \\begin{pmatrix} 1  \\rho \\\\ \\rho  1 \\end{pmatrix}$ 且 $\\rho = -0.8$。\n- 朴素区间膨胀不确定性集合（轴对齐盒式）：$U_{\\text{box}} = \\{ z \\in \\mathbb{R}^2 : |z_1| \\le 1, |z_2| \\le 1 \\}$，通过膨胀到界定 $U_{\\text{ellip}}$ 的独立边缘区间获得。\n\n鲁棒优化问题为：最大化 $x_1 + x_2$，约束条件为对所有 $z \\in U$ 都有 $(a_0 + z)^\\top x \\le b$，以及 $x_1 \\ge 0, x_2 \\ge 0$。其中 $b = 4$，而 $U$ 可选择为 $U_{\\text{ellip}}$（真实相关鲁棒对应）或 $U_{\\text{box}}$（朴素区间膨胀）。\n\n从鲁棒可行性的定义、集合上确界的性质以及 Cauchy–Schwarz 不等式出发，推导出两种鲁棒对应形式（一种针对 $U_{\\text{ellip}}$，一种针对 $U_{\\text{box}}$）。然后，精确求解这两个鲁棒优化问题，并计算朴素区间膨胀下的最优目标值与真实相关鲁棒对应下的最优目标值之比 $R$，\n$$\nR \\equiv \\frac{V_{\\text{box}}}{V_{\\text{ellip}}}.\n$$\n该比率展示了一个具体的反例，说明在相关不确定性下，朴素区间膨胀劣于真实鲁棒对应。\n\n将您关于 $R$ 的最终数值答案四舍五入到四位有效数字。无需单位。", "solution": "该问题要求我们分析一个不确定性下的双变量线性规划问题，为两种不同的不确定性集合推导其鲁棒对应形式，求解这些对应问题，并计算它们最优目标值的比率。\n\n鲁棒优化问题如下所示：\n$$\n\\begin{aligned}\n\\text{maximize} \\quad  x_1 + x_2 \\\\\n\\text{subject to} \\quad  (a_0 + z)^\\top x \\le b \\quad \\forall z \\in U \\\\\n x_1 \\ge 0, x_2 \\ge 0\n\\end{aligned}\n$$\n其中决策向量为 $x = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}$，名义系数向量为 $a_0 = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$，右侧值为 $b=4$。\n\n问题的核心在于将不确定约束重新表述为确定性等价形式。该约束必须对不确定性集合 $U$ 中的所有 $z$ 成立：\n$$\n(a_0 + z)^\\top x \\le b \\quad \\forall z \\in U\n$$\n这可以重写为：\n$$\na_0^\\top x + z^\\top x \\le b \\quad \\forall z \\in U\n$$\n这等价于确保名义部分加上最坏情况下的扰动不超过界限：\n$$\na_0^\\top x + \\sup_{z \\in U} (z^\\top x) \\le b\n$$\n我们现在为每个指定的不确定性集合 $U$ 推导其鲁棒对应形式。\n\n**第1部分：朴素区间膨胀 ($U = U_{\\text{box}}$)**\n\n第一个不确定性集合是轴对齐盒式，定义为：\n$$\nU_{\\text{box}} = \\{ z \\in \\mathbb{R}^2 : |z_1| \\le 1, |z_2| \\le 1 \\}\n$$\n我们需要计算上确界项 $\\sup_{z \\in U_{\\text{box}}} (z^\\top x)$。\n$$\n\\sup_{z \\in U_{\\text{box}}} (z^\\top x) = \\sup_{|z_1| \\le 1, |z_2| \\le 1} (z_1 x_1 + z_2 x_2)\n$$\n求和中的各项是可分的：\n$$\n\\sup_{|z_1| \\le 1, |z_2| \\le 1} (z_1 x_1 + z_2 x_2) = \\sup_{|z_1| \\le 1} (z_1 x_1) + \\sup_{|z_2| \\le 1} (z_2 x_2)\n$$\n为了在 $|z_i| \\le 1$ 的范围内最大化 $z_i x_i$，我们应该选择与 $x_i$ 同号且具有最大可能量值（即1）的 $z_i$。因此，$z_i$ 的最优选择是 $\\text{sgn}(x_i)$。$z_i x_i$ 的上确界因此为 $|\\text{sgn}(x_i) x_i| = |x_i|$。\n所以，我们有：\n$$\n\\sup_{z \\in U_{\\text{box}}} (z^\\top x) = |x_1| + |x_2|\n$$\n由于问题包含约束 $x_1 \\ge 0$ 和 $x_2 \\ge 0$，这可以简化为：\n$$\n\\sup_{z \\in U_{\\text{box}}} (z^\\top x) = x_1 + x_2\n$$\n将此代入鲁棒约束的公式中，得到：\n$$\na_0^\\top x + (x_1 + x_2) \\le b\n$$\n当 $a_0 = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$ 且 $b=4$ 时，约束变为：\n$$\n(x_1 + x_2) + (x_1 + x_2) \\le 4\n$$\n$$\n2x_1 + 2x_2 \\le 4 \\implies x_1 + x_2 \\le 2\n$$\n因此，针对盒式不确定性集合的鲁棒优化问题是一个简单的线性规划：\n$$\n\\begin{aligned}\nV_{\\text{box}} = \\text{maximize} \\quad  x_1 + x_2 \\\\\n\\text{subject to} \\quad  x_1 + x_2 \\le 2 \\\\\n x_1 \\ge 0, x_2 \\ge 0\n\\end{aligned}\n$$\n目标函数与主约束的左侧相同。通过观察可知，$x_1 + x_2$ 的最大值为 $2$。\n$$\nV_{\\text{box}} = 2\n$$\n\n**第2部分：真实相关不确定性 ($U = U_{\\text{ellip}}$)**\n\n第二个不确定性集合是由以下公式定义的椭球体：\n$$\nU_{\\text{ellip}} = \\{ z \\in \\mathbb{R}^2 : z^\\top \\Sigma^{-1} z \\le 1 \\}\n$$\n其中 $\\Sigma = \\begin{pmatrix} 1  \\rho \\\\ \\rho  1 \\end{pmatrix}$ 且 $\\rho = -0.8$。矩阵 $\\Sigma$ 是正定的，因为其行列式为 $1-\\rho^2 = 1 - (-0.8)^2 = 0.36 > 0$。\n\n我们需要计算上确界项 $\\sup_{z \\in U_{\\text{ellip}}} (z^\\top x)$。这是鲁棒优化中的一个标准结果。线性函数在椭球体上的上确界由对偶范数给出。\n$$\n\\sup_{z^\\top \\Sigma^{-1} z \\le 1} (z^\\top x) = \\sqrt{x^\\top \\Sigma x}\n$$\n为了证明这一点，我们可以使用 Cauchy-Schwarz 不等式。令 $y = \\Sigma^{-1/2} z$ 和 $w = \\Sigma^{1/2} x$。那么 $z = \\Sigma^{1/2} y$。约束 $z^\\top \\Sigma^{-1} z \\le 1$ 变为 $(\\Sigma^{1/2} y)^\\top \\Sigma^{-1} (\\Sigma^{1/2} y) = y^\\top \\Sigma^{1/2} \\Sigma^{-1} \\Sigma^{1/2} y = y^\\top y = \\|y\\|_2^2 \\le 1$。表达式 $z^\\top x$ 变为 $(\\Sigma^{1/2} y)^\\top x = y^\\top (\\Sigma^{1/2} x) = y^\\top w$。\n问题现在是求 $\\sup_{\\|y\\|_2 \\le 1} (y^\\top w)$。根据 Cauchy-Schwarz 不等式，$y^\\top w \\le \\|y\\|_2 \\|w\\|_2$。由于 $\\|y\\|_2 \\le 1$，我们有 $y^\\top w \\le \\|w\\|_2$。当 $y$ 与 $w$ 对齐且范数为1时，达到上确界，所以 $\\sup_{\\|y\\|_2 \\le 1} (y^\\top w) = \\|w\\|_2$。\n将 $w = \\Sigma^{1/2} x$ 代回：\n$$\n\\sup_{z \\in U_{\\text{ellip}}} (z^\\top x) = \\|\\Sigma^{1/2} x\\|_2 = \\sqrt{(\\Sigma^{1/2} x)^\\top (\\Sigma^{1/2} x)} = \\sqrt{x^\\top \\Sigma x}\n$$\n现在我们计算二次型 $x^\\top \\Sigma x$：\n$$\nx^\\top \\Sigma x = \\begin{pmatrix} x_1 & x_2 \\end{pmatrix} \\begin{pmatrix} 1 & \\rho \\\\ \\rho & 1 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} = x_1^2 + 2\\rho x_1 x_2 + x_2^2\n$$\n椭球体集合的鲁棒约束是：\n$$\na_0^\\top x + \\sqrt{x_1^2 + 2\\rho x_1 x_2 + x_2^2} \\le b\n$$\n当 $a_0 = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$ 且 $b=4$ 时，我们得到：\n$$\nx_1 + x_2 + \\sqrt{x_1^2 + 2\\rho x_1 x_2 + x_2^2} \\le 4\n$$\n该鲁棒优化问题是一个二阶锥规划（SOCP）：\n$$\n\\begin{aligned}\nV_{\\text{ellip}} = \\text{maximize} \\quad  x_1 + x_2 \\\\\n\\text{subject to} \\quad  x_1 + x_2 + \\sqrt{x_1^2 + 2\\rho x_1 x_2 + x_2^2} \\le 4 \\\\\n x_1 \\ge 0, x_2 \\ge 0\n\\end{aligned}\n$$\n目标函数和约束函数关于 $x_1$ 和 $x_2$ 是对称的。可行集是凸的。因此，最优解必定存在于直线 $x_1 = x_2$ 上。我们设 $x_1 = x_2 = x^*$，其中 $x^* \\ge 0$。\n目标函数变为 $2x^*$。约束变为：\n$$\nx^* + x^* + \\sqrt{(x^*)^2 + 2\\rho(x^*)^2 + (x^*)^2} \\le 4\n$$\n$$\n2x^* + \\sqrt{2(x^*)^2 + 2\\rho(x^*)^2} \\le 4\n$$\n由于 $x^* \\ge 0$，我们可以将其从平方根中提出来：\n$$\n2x^* + x^*\\sqrt{2 + 2\\rho} \\le 4\n$$\n$$\nx^* (2 + \\sqrt{2(1+\\rho)}) \\le 4\n$$\n为了最大化目标 $2x^*$，我们必须选择可能的最大 $x^*$，因此我们取等式：\n$$\nx^* = \\frac{4}{2 + \\sqrt{2(1+\\rho)}}\n$$\n最优目标值为 $V_{\\text{ellip}} = 2x^*$：\n$$\nV_{\\text{ellip}} = \\frac{8}{2 + \\sqrt{2(1+\\rho)}}\n$$\n我们已知 $\\rho = -0.8$。代入这个值：\n$$\n1 + \\rho = 1 - 0.8 = 0.2\n$$\n$$\n2(1 + \\rho) = 2(0.2) = 0.4\n$$\n$$\nV_{\\text{ellip}} = \\frac{8}{2 + \\sqrt{0.4}} = \\frac{8}{2 + \\sqrt{4/10}} = \\frac{8}{2 + 2/\\sqrt{10}} = \\frac{4}{1 + 1/\\sqrt{10}} = \\frac{4\\sqrt{10}}{1+\\sqrt{10}}\n$$\n\n**第3部分：计算比率 $R$**\n\n我们被要求计算比率 $R = \\frac{V_{\\text{box}}}{V_{\\text{ellip}}}$。\n我们得到 $V_{\\text{box}} = 2$ 和 $V_{\\text{ellip}} = \\frac{8}{2 + \\sqrt{0.4}}$。\n$$\nR = \\frac{2}{\\frac{8}{2 + \\sqrt{0.4}}} = \\frac{2(2 + \\sqrt{0.4})}{8} = \\frac{2 + \\sqrt{0.4}}{4}\n$$\n这可以写成：\n$$\nR = \\frac{1}{2} + \\frac{\\sqrt{0.4}}{4} = \\frac{1}{2} + \\frac{\\sqrt{4/10}}{4} = \\frac{1}{2} + \\frac{2/\\sqrt{10}}{4} = \\frac{1}{2} + \\frac{1}{2\\sqrt{10}} = \\frac{1}{2} \\left( 1 + \\frac{1}{\\sqrt{10}} \\right)\n$$\n现在我们计算数值并四舍五入到四位有效数字：\n$$\n\\sqrt{10} \\approx 3.16227766...\n$$\n$$\n\\frac{1}{\\sqrt{10}} \\approx 0.316227766...\n$$\n$$\nR \\approx \\frac{1}{2} (1 + 0.316227766) = \\frac{1}{2} (1.316227766) \\approx 0.658113883...\n$$\n四舍五入到四位有效数字得到 $R \\approx 0.6581$。\n\n比率小于1表明，与真实相关模型相比，朴素区间膨胀模型过于保守。通过忽略不确定参数之间的负相关性，盒式不确定性集合包含了不切实际的情景（例如两个参数同时取其最不利的最大值），导致问题受到更严格的约束，从而得到更低的最优目标值。", "answer": "$$\n\\boxed{0.6581}\n$$", "id": "3173992"}, {"introduction": "最后一个练习将鲁棒优化与机器学习的世界联系起来，揭示了两者之间深刻而令人惊讶的关系。我们将从数学上证明，对线性回归模型进行特征不确定性的鲁棒化，等同于在目标函数中加入一个正则化项。这个练习不仅通过推导巩固了理论理解，还通过编码实现将其付诸实践，展示了抽象概念如何转化为实用的算法。[@problem_id:3173939]", "problem": "在此问题中，您需要根据稳健优化的框架，对线性模型在不确定性下的稳健化（robustification）和正则化（regularization）进行实证比较。您将使用最小绝对偏差损失进行线性回归，该损失在包含 $n$ 个样本和 $d$ 个特征的数据集上定义的目标函数为 $\\sum_{i=1}^{n} \\left| y_i - \\mathbf{x}_i^{\\top}\\mathbf{w} \\right|$，其中 $\\mathbf{x}_i \\in \\mathbb{R}^{d}$ 是样本 $i$ 的特征向量，$y_i \\in \\mathbb{R}$ 是响应值，$\\mathbf{w} \\in \\mathbb{R}^{d}$ 是待学习的权重向量。\n\n请基于以下基础进行推导和算法设计：\n- 稳健优化通过在不确定性集合上优化最坏情况下的目标来对不确定性进行建模。对于每个样本 $i$，假设特征存在一个加性扰动 $\\boldsymbol{\\delta}_i \\in \\mathbb{R}^{d}$，因此扰动后的特征变为 $\\mathbf{x}_i + \\boldsymbol{\\delta}_i$。稳健目标函数则为 $\\sum_{i=1}^{n} \\max_{\\boldsymbol{\\delta}_i \\in \\mathcal{U}} \\left| y_i - (\\mathbf{x}_i + \\boldsymbol{\\delta}_i)^{\\top} \\mathbf{w} \\right|$，其中 $\\mathcal{U}$ 是一个范数球不确定性集合。\n- 使用对偶范数的定义：对于任意范数 $\\|\\cdot\\|$，其对偶范数 $\\|\\cdot\\|_{*}$ 定义为 $\\|\\mathbf{v}\\|_{*} = \\sup_{\\|\\mathbf{u}\\| \\leq 1} \\mathbf{u}^{\\top}\\mathbf{v}$。\n- 使用范数球的支撑函数：对于半径 $\\rho \\geq 0$ 和任意向量 $\\mathbf{v}$，$\\sup_{\\|\\boldsymbol{\\delta}\\| \\leq \\rho} \\boldsymbol{\\delta}^{\\top}\\mathbf{v} = \\rho \\|\\mathbf{v}\\|_{*}$。\n\n您的任务是：\n1. 从上述定义出发，推导带有范数球特征不确定性的稳健化最小绝对偏差目标函数与一个在 $\\mathbf{w}$ 上添加范数惩罚的正则化最小绝对偏差目标函数之间的等价性。通过对偶性，明确指出正则化强度 $\\lambda$ 和不确定性半径 $\\rho$ 之间的关系，该关系是样本数量 $n$ 和所选范数的函数。不要使用任何快捷公式；请从给定的基础定义出发推导结果。\n2. 为正则化最小绝对偏差问题实现两个线性规划求解器：\n   - 情况 A（范数类型 $\\ell_{\\infty}$）：最小化 $\\sum_{i=1}^{n} \\left| y_i - \\mathbf{x}_i^{\\top}\\mathbf{w} \\right| + \\lambda \\|\\mathbf{w}\\|_{1}$。\n   - 情况 B（范数类型 $\\ell_{1}$）：最小化 $\\sum_{i=1}^{n} \\left| y_i - \\mathbf{x}_i^{\\top}\\mathbf{w} \\right| + \\lambda \\|\\mathbf{w}\\|_{\\infty}$。\n   每个求解器必须使用标准的变量分裂方法处理绝对值，并构建成一个线性规划问题。\n3. 根据您在任务 1 中的推导，通过将其支撑函数等价形式替换内部最大化来实现一个稳健化求解器。对于范数类型 $\\ell_{\\infty}$，不确定性集合为 $\\{ \\boldsymbol{\\delta} : \\|\\boldsymbol{\\delta}\\|_{\\infty} \\leq \\rho \\}$；对于范数类型 $\\ell_{1}$，不确定性集合为 $\\{ \\boldsymbol{\\delta} : \\|\\boldsymbol{\\delta}\\|_{1} \\leq \\rho \\}$。\n4. 为每个测试案例生成合成数据，方法如下：对于给定的 $n$、$d$ 和一个固定的种子（seed），从标准正态分布中独立抽取 $\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$ 的元素，从独立标准正态分布中抽取一个真实权重向量 $\\mathbf{w}_{\\text{true}} \\in \\mathbb{R}^{d}$，并设置 $\\mathbf{y} = \\mathbf{X}\\mathbf{w}_{\\text{true}} + \\boldsymbol{\\varepsilon}$，其中噪声向量 $\\boldsymbol{\\varepsilon} \\in \\mathbb{R}^{n}$ 的元素独立地从均值为 $0$、标准差为 $0.1$ 的正态分布中抽取。\n5. 对于每个测试案例，求解：\n   - 使用相应范数类型和不确定性半径 $\\rho$ 的稳健化问题，并通过您在任务 1 中基于对偶性的关系将其转换为正则化最小绝对偏差问题。\n   - 使用给定的 $\\lambda$ 和相应范数类型的直接正则化问题。\n   对于每个测试案例，报告一个浮点数，该数等于两个计算出的权重向量坐标之间的最大绝对差值，即 $\\max_{j \\in \\{1,\\dots,d\\}} \\left| w^{\\text{rob}}_j - w^{\\text{reg}}_j \\right|$。\n\n测试套件：\n- 测试案例 1：范数类型 $\\ell_{\\infty}$，$n = 20$，$d = 5$，种子 $= 0$，$\\rho = 0.03$，$\\lambda = 0.60$。\n- 测试案例 2：范数类型 $\\ell_{\\infty}$，$n = 20$，$d = 5$，种子 $= 0$，$\\rho = 0.03$，$\\lambda = 0.30$。\n- 测试案例 3：范数类型 $\\ell_{1}$，$n = 30$，$d = 4$，种子 $= 1$，$\\rho = 0.02$，$\\lambda = 0.60$。\n- 测试案例 4：范数类型 $\\ell_{1}$，$n = 30$，$d = 4$，种子 $= 1$，$\\rho = 0.02$，$\\lambda = 0.45$。\n- 测试案例 5：范数类型 $\\ell_{\\infty}$，$n = 10$，$d = 3$，种子 $= 2$，$\\rho = 0.00$，$\\lambda = 0.00$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，\"[result1,result2,result3]\"）。每个元素必须是任务 5 中为相应测试案例指定的浮点数，顺序与上面列出的一致。", "solution": "用户希望分析最小绝对偏差（LAD）线性回归问题中稳健优化与正则化之间的关系。解决方案需要对此等价性进行数学推导，然后实现线性规划求解器，以在合成数据集上实证验证所推导的关系。\n\n### 任务 1：等价性推导\n\n问题始于标准的LAD目标函数：\n$$ \\min_{\\mathbf{w}} \\sum_{i=1}^{n} \\left| y_i - \\mathbf{x}_i^{\\top}\\mathbf{w} \\right| $$\n其中 $\\mathbf{w} \\in \\mathbb{R}^{d}$ 是权重向量，$\\mathbf{x}_i \\in \\mathbb{R}^{d}$ 是样本 $i$ 的特征向量，$y_i \\in \\mathbb{R}$ 是对应的响应值。\n\n稳健优化通过考虑最坏情况来处理不确定性。在这里，我们假设特征 $\\mathbf{x}_i$ 受到来自范数球不确定性集合 $\\mathcal{U} = \\{ \\boldsymbol{\\delta} \\in \\mathbb{R}^{d} : \\|\\boldsymbol{\\delta}\\| \\leq \\rho \\}$ 的加性扰动 $\\boldsymbol{\\delta}_i$，其中 $\\|\\cdot\\|$ 是某个范数，$\\rho \\geq 0$ 是不确定性半径。稳健化目标函数是：\n$$ \\min_{\\mathbf{w}} \\sum_{i=1}^{n} \\max_{\\boldsymbol{\\delta}_i \\in \\mathcal{U}} \\left| y_i - (\\mathbf{x}_i + \\boldsymbol{\\delta}_i)^{\\top}\\mathbf{w} \\right| $$\n\n为了建立与正则化目标函数的等价性，我们关注单个样本 $i$ 的内部最大化项：\n$$ \\max_{\\|\\boldsymbol{\\delta}_i\\| \\leq \\rho} \\left| y_i - \\mathbf{x}_i^{\\top}\\mathbf{w} - \\boldsymbol{\\delta}_i^{\\top}\\mathbf{w} \\right| $$\n令 $r_i = y_i - \\mathbf{x}_i^{\\top}\\mathbf{w}$。表达式变为 $\\max_{\\|\\boldsymbol{\\delta}_i\\| \\leq \\rho} \\left| r_i - \\boldsymbol{\\delta}_i^{\\top}\\mathbf{w} \\right|$。利用对于任意实数 $a$，$|a| = \\max(a, -a)$ 的性质，我们可以将最大化重写为：\n$$ \\max \\left( \\max_{\\|\\boldsymbol{\\delta}_i\\| \\leq \\rho} (r_i - \\boldsymbol{\\delta}_i^{\\top}\\mathbf{w}), \\quad \\max_{\\|\\boldsymbol{\\delta}_i\\| \\leq \\rho} -(r_i - \\boldsymbol{\\delta}_i^{\\top}\\mathbf{w}) \\right) $$\n我们来分析外部 $\\max(\\cdot, \\cdot)$ 内部的两个项：\n1.  $\\max_{\\|\\boldsymbol{\\delta}_i\\| \\leq \\rho} (r_i - \\boldsymbol{\\delta}_i^{\\top}\\mathbf{w}) = r_i + \\max_{\\|\\boldsymbol{\\delta}_i\\| \\leq \\rho} (-\\boldsymbol{\\delta}_i^{\\top}\\mathbf{w}) = r_i - \\min_{\\|\\boldsymbol{\\delta}_i\\| \\leq \\rho} (\\boldsymbol{\\delta}_i^{\\top}\\mathbf{w})$。\n2.  $\\max_{\\|\\boldsymbol{\\delta}_i\\| \\leq \\rho} (-r_i + \\boldsymbol{\\delta}_i^{\\top}\\mathbf{w}) = -r_i + \\max_{\\|\\boldsymbol{\\delta}_i\\| \\leq \\rho} (\\boldsymbol{\\delta}_i^{\\top}\\mathbf{w})$。\n\n问题给出了范数球的支撑函数的定义：$\\sup_{\\|\\boldsymbol{\\delta}\\| \\leq \\rho} \\boldsymbol{\\delta}^{\\top}\\mathbf{v} = \\rho \\|\\mathbf{v}\\|_{*}$，其中 $\\|\\cdot\\|_{*}$ 是 $\\|\\cdot\\|$ 的对偶范数。由于不确定性集合 $\\mathcal{U}$ 是对称的（如果 $\\boldsymbol{\\delta} \\in \\mathcal{U}$，则 $-\\boldsymbol{\\delta} \\in \\mathcal{U}$），我们有 $\\min_{\\|\\boldsymbol{\\delta}\\| \\leq \\rho} \\boldsymbol{\\delta}^{\\top}\\mathbf{v} = -\\sup_{\\|\\boldsymbol{\\delta}\\| \\leq \\rho} \\boldsymbol{\\delta}^{\\top}\\mathbf{v} = -\\rho \\|\\mathbf{v}\\|_{*}$。\n\n将此应用于我们的项，并令 $\\mathbf{v} = \\mathbf{w}$：\n1.  $r_i - (-\\rho \\|\\mathbf{w}\\|_{*}) = r_i + \\rho \\|\\mathbf{w}\\|_{*}$.\n2.  $-r_i + \\rho \\|\\mathbf{w}\\|_{*}$.\n\n代回后，对 $\\boldsymbol{\\delta}_i$ 的内部最大化变为：\n$$ \\max(r_i + \\rho \\|\\mathbf{w}\\|_{*}, -r_i + \\rho \\|\\mathbf{w}\\|_{*}) = |r_i| + \\rho \\|\\mathbf{w}\\|_{*} = \\left| y_i - \\mathbf{x}_i^{\\top}\\mathbf{w} \\right| + \\rho \\|\\mathbf{w}\\|_{*} $$\n完整的稳健目标函数是所有 $n$ 个样本的总和：\n$$ \\min_{\\mathbf{w}} \\sum_{i=1}^{n} \\left( \\left| y_i - \\mathbf{x}_i^{\\top}\\mathbf{w} \\right| + \\rho \\|\\mathbf{w}\\|_{*} \\right) $$\n这可以重新整理为：\n$$ \\min_{\\mathbf{w}} \\left( \\sum_{i=1}^{n} \\left| y_i - \\mathbf{x}_i^{\\top}\\mathbf{w} \\right| \\right) + n \\rho \\|\\mathbf{w}\\|_{*} $$\n这是一个形式为 $\\min_{\\mathbf{w}} \\sum_{i=1}^{n} \\left| y_i - \\mathbf{x}_i^{\\top}\\mathbf{w} \\right| + \\lambda \\|\\mathbf{w}\\|_{*}$ 的正则化LAD问题。通过比较这两种形式，我们找到了正则化强度 $\\lambda$ 和不确定性半径 $\\rho$ 之间的关系：\n$$ \\lambda = n \\rho $$\n正则化范数 $\\|\\cdot\\|_{*}$ 是用于定义不确定性集合的范数 $\\|\\cdot\\|$ 的对偶范数。\n- **情况 A（$\\ell_{\\infty}$ 范数不确定性）：** 如果不确定性集合由 $\\|\\boldsymbol{\\delta}\\|_{\\infty} \\leq \\rho$ 定义，则对偶范数是 $\\ell_1$-范数，即 $\\|\\mathbf{w}\\|_{*} = \\|\\mathbf{w}\\|_1$。等价问题是 $\\ell_1$-正则化LAD。\n- **情况 B（$\\ell_{1}$ 范数不确定性）：** 如果不确定性集合由 $\\|\\boldsymbol{\\delta}\\|_{1} \\leq \\rho$ 定义，则对偶范数是 $\\ell_{\\infty}$-范数，即 $\\|\\mathbf{w}\\|_{*} = \\|\\mathbf{w}\\|_{\\infty}$。等价问题是 $\\ell_{\\infty}$-正则化LAD。\n\n### 任务 2：线性规划公式\n\n为了解决这些优化问题，我们将其构建为线性规划（LP）问题。\n\n**情况 A：$\\ell_1$-正则化LAD**\n问题是 $\\min_{\\mathbf{w}} \\sum_{i=1}^{n} |y_i - \\mathbf{x}_i^{\\top}\\mathbf{w}| + \\lambda \\|\\mathbf{w}\\|_1$。\n我们引入变量 $e_i \\ge 0$ 使得 $e_i \\geq |y_i - \\mathbf{x}_i^{\\top}\\mathbf{w}|$。我们还将 $\\mathbf{w}$ 分解为其正部和负部，$\\mathbf{w} = \\mathbf{w}^+ - \\mathbf{w}^-$，其中 $\\mathbf{w}^+, \\mathbf{w}^- \\ge 0$。那么 $\\|\\mathbf{w}\\|_1 = \\sum_{j=1}^{d} (w_j^+ + w_j^-)$。\n该LP为：\n$$ \\begin{aligned}\n\\min_{\\mathbf{w}^+, \\mathbf{w}^-, \\mathbf{e}} \\quad  \\sum_{i=1}^{n} e_i + \\lambda \\sum_{j=1}^{d} (w_j^+ + w_j^-) \\\\\n\\text{s.t.} \\quad  \\mathbf{x}_i^{\\top}(\\mathbf{w}^+ - \\mathbf{w}^-) + e_i \\ge y_i, \\quad i=1, \\dots, n \\\\\n -\\mathbf{x}_i^{\\top}(\\mathbf{w}^+ - \\mathbf{w}^-) + e_i \\ge -y_i, \\quad i=1, \\dots, n \\\\\n \\mathbf{w}^+ \\ge 0, \\mathbf{w}^- \\ge 0, \\mathbf{e} \\ge 0\n\\end{aligned} $$\n决策变量向量为 $\\mathbf{z} = [\\mathbf{w}^+; \\mathbf{w}^-; \\mathbf{e}] \\in \\mathbb{R}^{2d+n}$。\n\n**情况 B：$\\ell_{\\infty}$-正则化LAD**\n问题是 $\\min_{\\mathbf{w}} \\sum_{i=1}^{n} |y_i - \\mathbf{x}_i^{\\top}\\mathbf{w}| + \\lambda \\|\\mathbf{w}\\|_{\\infty}$。\n我们像之前一样引入变量 $e_i \\ge 0$。对于 $\\ell_{\\infty}$-范数，我们引入一个单一变量 $t \\ge 0$ 使得 $t \\geq \\|\\mathbf{w}\\|_{\\infty} = \\max_j |w_j|$。这等价于对所有 $j=1, \\dots, d$，都有 $t \\ge w_j$ 和 $t \\ge -w_j$。向量 $\\mathbf{w}$ 不需要被拆分。\n该LP为：\n$$ \\begin{aligned}\n\\min_{\\mathbf{w}, t, \\mathbf{e}} \\quad  \\sum_{i=1}^{n} e_i + \\lambda t \\\\\n\\text{s.t.} \\quad  \\mathbf{x}_i^{\\top}\\mathbf{w} + e_i \\ge y_i, \\quad i=1, \\dots, n \\\\\n -\\mathbf{x}_i^{\\top}\\mathbf{w} + e_i \\ge -y_i, \\quad i=1, \\dots, n \\\\\n t - w_j \\ge 0, \\quad j=1, \\dots, d \\\\\n t + w_j \\ge 0, \\quad j=1, \\dots, d \\\\\n t \\ge 0, \\mathbf{e} \\ge 0\n\\end{aligned} $$\n决策变量向量为 $\\mathbf{z} = [\\mathbf{w}; t; \\mathbf{e}] \\in \\mathbb{R}^{d+1+n}$。\n\n实现将为这些LP构建相应的矩阵和向量，并使用 `scipy.optimize.linprog` 来找到最优权重 $\\mathbf{w}$。对于每个测试案例，我们使用 $\\lambda_{\\text{rob}} = n\\rho$ 计算 $\\mathbf{w}^{\\text{rob}}$，并使用给定的 $\\lambda$ 计算 $\\mathbf{w}^{\\text{reg}}$，然后报告坐标上的最大绝对差值。", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import linprog\n\ndef solve_l1_regularized_lad(X, y, lam):\n    \"\"\"\n    Solves the L1-regularized Least Absolute Deviations problem.\n    min sum(e_i) + lam * ||w||_1\n    s.t. |y_i - x_i^T w| = e_i\n    \"\"\"\n    n, d = X.shape\n\n    # Decision variables z = [w+, w-, e], shape (2d + n)\n    # w = w+ - w-\n    # ||w||_1 = sum(w+ + w-)\n    # Objective: min lam * sum(w+) + lam * sum(w-) + sum(e)\n    c = np.hstack([lam * np.ones(d), lam * np.ones(d), np.ones(n)])\n\n    # Constraints A_ub @ z = b_ub\n    # y_i - x_i^T(w+ - w-) = e_i  =>  x_i^T(w- - w+) - e_i = -y_i\n    # -(y_i - x_i^T(w+ - w-)) = e_i =>  x_i^T(w+ - w-) - e_i = y_i\n\n    A_ub = np.zeros((2 * n, 2 * d + n))\n    b_ub = np.zeros(2 * n)\n\n    # x_i^T(w- - w+) - e_i = -y_i\n    A_ub[:n, :d] = -X\n    A_ub[:n, d:2*d] = X\n    A_ub[:n, 2*d:] = -np.eye(n)\n    b_ub[:n] = -y\n\n    # x_i^T(w+ - w-) - e_i = y_i\n    A_ub[n:, :d] = X\n    A_ub[n:, d:2*d] = -X\n    A_ub[n:, 2*d:] = -np.eye(n)\n    b_ub[n:] = y\n\n    # All variables are non-negative\n    bounds = [(0, None)] * (2 * d + n)\n\n    res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n\n    if not res.success:\n        raise RuntimeError(f\"LP solver failed for L1-reg with lambda={lam}: {res.message}\")\n\n    w_plus = res.x[:d]\n    w_minus = res.x[d:2*d]\n    w = w_plus - w_minus\n    return w\n\ndef solve_linf_regularized_lad(X, y, lam):\n    \"\"\"\n    Solves the L-infinity-regularized Least Absolute Deviations problem.\n    min sum(e_i) + lam * ||w||_inf\n    s.t. |y_i - x_i^T w| = e_i\n    \"\"\"\n    n, d = X.shape\n\n    # Decision variables z = [w, t, e], shape (d + 1 + n)\n    # ||w||_inf = t\n    # Objective: min sum(e) + lam * t\n    c = np.hstack([np.zeros(d), [lam], np.ones(n)])\n\n    # Constraints A_ub @ z = b_ub\n    num_vars = d + 1 + n\n    num_constraints = 2 * n + 2 * d\n    A_ub = np.zeros((num_constraints, num_vars))\n    b_ub = np.zeros(num_constraints)\n\n    # |y_i - x_i^T w| = e_i constraints:\n    # -Xw - e = -y\n    A_ub[0:n, 0:d] = -X\n    A_ub[0:n, d+1:] = -np.eye(n)\n    b_ub[0:n] = -y\n    \n    # Xw - e = y\n    A_ub[n:2*n, 0:d] = X\n    A_ub[n:2*n, d+1:] = -np.eye(n)\n    b_ub[n:2*n] = y\n\n    # ||w||_inf = t constraints:\n    # w_j - t = 0\n    A_ub[2*n : 2*n+d, 0:d] = np.eye(d)\n    A_ub[2*n : 2*n+d, d] = -1\n    # -w_j - t = 0\n    A_ub[2*n+d : 2*n+2*d, 0:d] = -np.eye(d)\n    A_ub[2*n+d : 2*n+2*d, d] = -1\n\n    # Bounds: w is unbounded, t >= 0, e >= 0\n    bounds = [(None, None)] * d + [(0, None)] * (1 + n)\n\n    res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n    \n    if not res.success:\n        raise RuntimeError(f\"LP solver failed for Linf-reg with lambda={lam}: {res.message}\")\n\n    w = res.x[:d]\n    return w\n\ndef solve():\n    \"\"\"\n    Main function to run the test cases and produce the final output.\n    \"\"\"\n    test_cases = [\n        # (norm_type, n, d, seed, rho, lambda)\n        ('l_inf', 20, 5, 0, 0.03, 0.60),\n        ('l_inf', 20, 5, 0, 0.03, 0.30),\n        ('l_1', 30, 4, 1, 0.02, 0.60),\n        ('l_1', 30, 4, 1, 0.02, 0.45),\n        ('l_inf', 10, 3, 2, 0.00, 0.00),\n    ]\n\n    results = []\n\n    for case in test_cases:\n        norm_type, n, d, seed, rho, lam_given = case\n\n        # Generate synthetic data\n        rng = np.random.default_rng(seed)\n        X = rng.standard_normal(size=(n, d))\n        w_true = rng.standard_normal(size=d)\n        epsilon = rng.normal(loc=0.0, scale=0.1, size=n)\n        y = X @ w_true + epsilon\n\n        # Calculate lambda for the robust problem from rho\n        lam_rob = n * rho\n\n        if norm_type == 'l_inf':\n            # l-inf uncertainty -> l1 regularization\n            w_rob = solve_l1_regularized_lad(X, y, lam_rob)\n            w_reg = solve_l1_regularized_lad(X, y, lam_given)\n        elif norm_type == 'l_1':\n            # l1 uncertainty -> l-inf regularization\n            w_rob = solve_linf_regularized_lad(X, y, lam_rob)\n            w_reg = solve_linf_regularized_lad(X, y, lam_given)\n        else:\n            raise ValueError(f\"Unknown norm type: {norm_type}\")\n\n        # Compute the maximum absolute difference between weight vectors\n        max_abs_diff = np.max(np.abs(w_rob - w_reg))\n        results.append(max_abs_diff)\n    \n    # Format and print the final output\n    print(f\"[{','.join(f'{r:.10f}' for r in results)}]\")\n\nsolve()\n```", "id": "3173939"}]}