{"hands_on_practices": [{"introduction": "在应用样本均值近似（Sample Average Approximation, SAA）时，一个核心问题是如何确定合适的样本量。虽然更大的样本量通常能带来更好的解，但也会产生更高的成本。本练习 [@problem_id:3174778] 将引导您对这一权衡进行一次实践性分析，量化采样带来的边际效益递减，并学习如何找到一个具有成本效益的样本量。", "problem": "考虑一个随机优化问题，其中选择一个决策变量 $x \\in \\mathbb{R}$ 来最小化期望目标 $F(x) = \\mathbb{E}\\left[ \\phi(x,\\xi) \\right]$，其中 $\\phi(x,\\xi) = (x - \\xi)^2$，$\\xi$ 是一个具有有限二阶矩的实值随机变量。样本均值近似 (SAA) 方法基于 $n$ 个独立同分布的样本 $\\xi_1, \\dots, \\xi_n$ 构建估计量 $\\hat{x}_n$，该估计量是样本均值 $\\frac{1}{n} \\sum_{i=1}^{n} \\phi(x, \\xi_i)$ 的最小化子。目标是从经验和理论上刻画函数 $n \\mapsto \\mathbb{E}\\left[ F(\\hat{x}_n) \\right]$ 中的收益递减现象，并利用这一刻画来确定何时增加一个额外样本不具备成本效益。\n\n使用的基本基础和定义：\n- 样本均值近似 (SAA) 估计量 $\\hat{x}_n$ 被定义为随机函数 $x \\mapsto \\frac{1}{n}\\sum_{i=1}^n \\phi(x, \\xi_i)$ 的任意最小化子。\n- 期望算子满足线性性，随机变量 $\\xi$ 的方差为 $\\operatorname{Var}(\\xi) = \\mathbb{E}\\left[(\\xi - \\mathbb{E}[\\xi])^2\\right]$。\n- 对于独立同分布的样本，样本均值 $\\bar{\\xi}_n = \\frac{1}{n}\\sum_{i=1}^n \\xi_i$ 满足 $\\mathbb{E}[\\bar{\\xi}_n] = \\mathbb{E}[\\xi]$ 和 $\\operatorname{Var}(\\bar{\\xi}_n) = \\operatorname{Var}(\\xi)/n$。\n\n任务：\n1. 经验刻画。对于下述每个测试用例，通过蒙特卡洛模拟构建函数 $n \\mapsto \\mathbb{E}\\left[ F(\\hat{x}_n) \\right]$ 的经验估计。使用一个固定的样本量网格 $\\mathcal{N} = \\{1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144\\}$，并且对于每个 $n \\in \\mathcal{N}$，执行固定次数的独立蒙特卡洛重复实验，通过对每次重复实验计算的 $F(\\hat{x}_n)$ 进行平均来估计 $\\mathbb{E}\\left[ F(\\hat{x}_n) \\right]$。在每次重复实验中，抽取 $n$ 个独立样本以构建 $\\hat{x}_n$，并使用 $\\xi$ 的一个独立实现或基于上述定义的等效无偏计算来评估 $F(\\hat{x}_n)$。在所有测试用例中使用固定的重复实验次数以确保可比性。\n2. 理论刻画。基于基本基础，推导 $\\mathbb{E}\\left[ F(\\hat{x}_n) \\right]$ 作为一个关于 $n$ 和 $\\operatorname{Var}(\\xi)$ 的函数的闭式表达式，并随着 $n$ 的增加，解析地刻画 $n \\mapsto \\mathbb{E}\\left[ F(\\hat{x}_n) \\right]$ 的斜率。\n3. 模型拟合与决策规则。通过最小二乘法将参数模型 $m(n) = a + \\frac{b}{n}$ 拟合到 $n \\in \\mathcal{N}$ 的经验估计曲线上，以获得估计值 $(\\hat{a}, \\hat{b})$。然后，对于给定的非负样本成本 $c$（与目标值单位相同），考虑总期望损失 $L(n) = \\mathbb{E}\\left[ F(\\hat{x}_n) \\right] + c \\, n$，并通过在整数 $n \\geq 1$ 上最小化拟合模型 $m(n) + c \\, n$ 来确定一个具有成本效益的样本量 $\\hat{n}$，此过程使用从拟合参数推导出的解析近似。\n4. 理论基准。对于每个测试用例，使用任务2中的解析刻画结合上述决策规则 $L(n)$ 来计算理论上的最优整数样本量 $n^\\star$。\n5. 输出规范。对于每个测试用例，按下列顺序列出，返回配对 $(\\hat{n}, n^\\star)$。将所有测试用例的输出汇总到一个单一列表中，顺序为：$\\left[\\hat{n}_1, n^\\star_1, \\hat{n}_2, n^\\star_2, \\hat{n}_3, n^\\star_3, \\hat{n}_4, n^\\star_4\\right]$，其中下标表示测试用例。你的程序应生成一行输出，包含此列表，格式为方括号括起来的逗号分隔列表（例如，$\\left[\\text{result}_1, \\text{result}_2, \\text{result}_3\\right]$）。\n\n测试套件：\n- 测试用例1：$\\xi \\sim \\mathcal{N}(\\mu, \\sigma^2)$，其中 $\\mu = 5$ 且 $\\sigma = 2$，样本成本 $c = 0.05$。\n- 测试用例2：$\\xi \\sim \\text{Uniform}[a,b]$，其中 $a = 0$ 且 $b = 10$，样本成本 $c = 0.1$。\n- 测试用例3：$\\xi \\sim \\text{Laplace}(\\mu, s)$，其中 $\\mu = 0$ 且尺度参数 $s = 1$，样本成本 $c = 3$。\n- 测试用例4：$\\xi \\sim \\mathcal{N}(\\mu, \\sigma^2)$，其中 $\\mu = 0$ 且 $\\sigma = 5$，样本成本 $c = 0.001$。\n\n所有数值答案应为无单位的实数或整数（视情况而定），且不涉及角度。最终答案必须是整数；基于模型拟合的决策 $\\hat{n}$ 和理论基准 $n^\\star$ 应四舍五入到最近的整数，并限制为至少为 $1$。", "solution": "该问题要求分析用于随机优化问题的样本均值近似 (SAA) 方法，并基于理论推导和经验模拟来确定一个具有成本效益的样本量。\n\n问题被表述为最小化期望目标函数 $F(x) = \\mathbb{E}\\left[ \\phi(x,\\xi) \\right]$，其中 $\\phi(x,\\xi) = (x - \\xi)^2$，$x \\in \\mathbb{R}$ 是决策变量，$\\xi$ 是一个具有有限二阶矩的实值随机变量。SAA 估计量 $\\hat{x}_n$ 是对于大小为 $n$ 的样本的样本均值目标 $\\frac{1}{n} \\sum_{i=1}^{n} \\phi(x, \\xi_i)$ 的最小化子。\n\n解决方案首先推导估计量和期望目标值的理论性质，然后详细说明经验模拟和拟合过程。\n\n### 1. 理论刻画\n\n首先，我们推导 $\\mathbb{E}\\left[ F(\\hat{x}_n) \\right]$ 作为样本量 $n$ 的函数的闭式表达式。这对应于任务2。\n\n真实目标函数是 $F(x) = \\mathbb{E}[(x-\\xi)^2]$。令 $\\mu = \\mathbb{E}[\\xi]$ 且 $\\sigma^2 = \\operatorname{Var}(\\xi)$。展开期望可得：\n$$F(x) = \\mathbb{E}[x^2 - 2x\\xi + \\xi^2] = x^2 - 2x\\mathbb{E}[\\xi] + \\mathbb{E}[\\xi^2] = x^2 - 2x\\mu + (\\mu^2 + \\sigma^2)$$\n这是一个关于 $x$ 的凸二次函数。通过将其一阶导数设为零，可以找到最小化子 $x^\\star$：\n$$\\frac{dF(x)}{dx} = 2x - 2\\mu = 0 \\implies x^\\star = \\mu$$\n真实目标的最小值为 $F(x^\\star) = F(\\mu) = (\\mu-\\mu)^2 + \\sigma^2 = \\sigma^2 = \\operatorname{Var}(\\xi)$。\n\nSAA 估计量 $\\hat{x}_n$ 最小化样本平均目标函数 $\\hat{F}_n(x) = \\frac{1}{n}\\sum_{i=1}^n (x - \\xi_i)^2$。将其导数设为零可得：\n$$\\frac{d\\hat{F}_n(x)}{dx} = \\frac{1}{n}\\sum_{i=1}^n 2(x - \\xi_i) = 2x - \\frac{2}{n}\\sum_{i=1}^n \\xi_i = 0$$\n这得出了 SAA 估计量 $\\hat{x}_n = \\frac{1}{n}\\sum_{i=1}^n \\xi_i$，即样本均值，记为 $\\bar{\\xi}_n$。\n\n我们关心的是该估计量的期望性能，即 $\\mathbb{E}[F(\\hat{x}_n)]$。这里的期望是关于决定 $\\hat{x}_n$ 的样本 $\\{\\xi_1, \\dots, \\xi_n\\}$ 的分布来取的。\n函数 $F(\\cdot)$ 在随机点 $\\hat{x}_n$ 处的求值为：\n$$F(\\hat{x}_n) = (\\hat{x}_n - \\mu)^2 + \\sigma^2$$\n这个表达式本身是一个随机变量，因为 $\\hat{x}_n$ 依赖于样本。为了求其期望值，我们对所有可能的样本取期望：\n$$\\mathbb{E}[F(\\hat{x}_n)] = \\mathbb{E}\\left[ (\\hat{x}_n - \\mu)^2 + \\sigma^2 \\right]$$\n利用期望的线性性，这变为：\n$$\\mathbb{E}[F(\\hat{x}_n)] = \\mathbb{E}\\left[ (\\hat{x}_n - \\mu)^2 \\right] + \\sigma^2$$\n项 $\\mathbb{E}\\left[ (\\hat{x}_n - \\mu)^2 \\right]$ 是 $\\hat{x}_n$ 的方差的定义，因为 $\\mathbb{E}[\\hat{x}_n] = \\mathbb{E}[\\bar{\\xi}_n] = \\mu$。对于独立同分布的样本，样本均值的方差是：\n$$\\operatorname{Var}(\\hat{x}_n) = \\operatorname{Var}(\\bar{\\xi}_n) = \\frac{\\operatorname{Var}(\\xi)}{n} = \\frac{\\sigma^2}{n}$$\n将其代回，我们得到理论刻画：\n$$\\mathbb{E}[F(\\hat{x}_n)] = \\sigma^2 + \\frac{\\sigma^2}{n} = \\operatorname{Var}(\\xi)\\left(1 + \\frac{1}{n}\\right)$$\n该表达式具有 $a+b/n$ 的形式，其中 $a = b = \\operatorname{Var}(\\xi)$。关于 $n$ 的斜率为 $-\\operatorname{Var}(\\xi)/n^2$，这表明随着 $n$ 的增加，收益递减。\n\n### 2. 最优样本量确定\n\n问题定义了一个总期望损失 $L(n) = \\mathbb{E}\\left[ F(\\hat{x}_n) \\right] + c \\, n$，其中 $c$ 是每个样本的成本。目标是找到最小化此总损失的样本量 $n$。\n\n**理论基准 ($n^\\star$)**\n使用推导出的 $\\mathbb{E}[F(\\hat{x}_n)]$ 的闭式表达式 (任务4)：\n$$L(n) = \\operatorname{Var}(\\xi) + \\frac{\\operatorname{Var}(\\xi)}{n} + cn$$\n为了找到最小值，我们将 $n > 0$ 的 $n$ 视为连续变量，并将其导数设为零：\n$$\\frac{dL(n)}{dn} = -\\frac{\\operatorname{Var}(\\xi)}{n^2} + c = 0$$\n这得出 $n^2 = \\frac{\\operatorname{Var}(\\xi)}{c}$，所以最优的连续样本量是 $n = \\sqrt{\\frac{\\operatorname{Var}(\\xi)}{c}}$。由于样本量必须是正整数，理论上的最优样本量 $n^\\star$ 是通过将此值四舍五入到最近的整数并确保其至少为 $1$ 来找到的：\n$$n^\\star = \\max\\left(1, \\left\\lfloor \\sqrt{\\frac{\\operatorname{Var}(\\xi)}{c}} + 0.5 \\right\\rfloor\\right)$$\n\n**经验估计 ($\\hat{n}$)**\n经验性过程 (任务1和3) 包括三个步骤：\n1.  **蒙特卡洛模拟**：对于每个样本量 $n_j \\in \\mathcal{N}$，我们通过在大量独立重复实验中取平均来估计 $\\mathbb{E}[F(\\hat{x}_n)]$。在每次重复实验中，我们抽取一个样本 $\\{\\xi_i\\}_{i=1}^n$，计算 $\\hat{x}_n = \\bar{\\xi}_n$，然后计算 $F(\\hat{x}_n) = (\\hat{x}_n - \\mu)^2 + \\sigma^2$。这些值在所有重复实验中的平均值提供了一个经验估计 $y_j \\approx \\mathbb{E}[F(\\hat{x}_n)]$。这将生成一组数据点 $(n_j, y_j)$，其中 $n_j \\in \\mathcal{N}$。\n2.  **模型拟合**：我们将参数模型 $m(n) = a + b/n$ 拟合到经验数据 $(n_j, y_j)_{j=1}^{|\\mathcal{N}|}$。如果我们令 $z_j = 1/n_j$，这是一个线性回归问题。我们寻求参数 $(\\hat{a}, \\hat{b})$ 以最小化平方误差和 $\\sum (y_j - (a + b/n_j))^2$。\n3.  **决策规则**：使用拟合模型，我们定义一个近似总损失函数 $\\hat{L}(n) = m(n) + cn = \\hat{a} + \\frac{\\hat{b}}{n} + cn$。相对于 $n$ 最小化该函数（假设 $\\hat{b} > 0$）可得到一个最优的连续样本量 $n = \\sqrt{\\frac{\\hat{b}}{c}}$。通过四舍五入获得整数值估计 $\\hat{n}$：\n$$\\hat{n} = \\max\\left(1, \\left\\lfloor \\sqrt{\\frac{\\hat{b}}{c}} + 0.5 \\right\\rfloor\\right)$$\n\n### 3. 应用于测试用例\n\n该过程应用于每个测试用例。\n-   **测试用例 1**：$\\xi \\sim \\mathcal{N}(\\mu=5, \\sigma=2)$。$\\operatorname{Var}(\\xi) = 2^2=4$。成本 $c=0.05$。\n    $n^\\star = \\max(1, \\text{round}(\\sqrt{4/0.05})) = \\max(1, \\text{round}(\\sqrt{80})) = \\max(1, \\text{round}(8.944)) = 9$。\n-   **测试用例 2**：$\\xi \\sim \\text{Uniform}[0, 10]$。$\\operatorname{Var}(\\xi) = (10-0)^2/12 = 100/12$。成本 $c=0.1$。\n    $n^\\star = \\max(1, \\text{round}(\\sqrt{(100/12)/0.1})) = \\max(1, \\text{round}(\\sqrt{83.333})) = \\max(1, \\text{round}(9.129)) = 9$。\n-   **测试用例 3**：$\\xi \\sim \\text{Laplace}(\\mu=0, s=1)$。$\\operatorname{Var}(\\xi) = 2s^2=2$。成本 $c=3$。\n    $n^\\star = \\max(1, \\text{round}(\\sqrt{2/3})) = \\max(1, \\text{round}(\\sqrt{0.667})) = \\max(1, \\text{round}(0.816)) = 1$。\n-   **测试用例 4**：$\\xi \\sim \\mathcal{N}(\\mu=0, \\sigma=5)$。$\\operatorname{Var}(\\xi) = 5^2=25$。成本 $c=0.001$。\n    $n^\\star = \\max(1, \\text{round}(\\sqrt{25/0.001})) = \\max(1, \\text{round}(\\sqrt{25000})) = \\max(1, \\text{round}(158.114)) = 158$。\n\n$\\hat{n}$ 的值取决于蒙特卡洛模拟的结果，并在附带的代码中计算。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the SAA problem by performing theoretical calculations and empirical simulations\n    to find the optimal sample sizes.\n    \"\"\"\n    \n    # Set a seed for reproducibility of random number generation.\n    np.random.seed(42)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'name': 'Case 1', 'dist': 'normal', 'params': {'mu': 5.0, 'sigma': 2.0}, 'c': 0.05},\n        {'name': 'Case 2', 'dist': 'uniform', 'params': {'a': 0.0, 'b': 10.0}, 'c': 0.1},\n        {'name': 'Case 3', 'dist': 'laplace', 'params': {'mu': 0.0, 's': 1.0}, 'c': 3.0},\n        {'name': 'Case 4', 'dist': 'normal', 'params': {'mu': 0.0, 'sigma': 5.0}, 'c': 0.001},\n    ]\n\n    # Fixed parameters for the Monte Carlo simulation.\n    N_GRID = np.array([1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144])\n    N_REPS = 50000  # Number of Monte Carlo replicates.\n\n    results = []\n    for case in test_cases:\n        c = case['c']\n        \n        # Determine distribution parameters and variance\n        if case['dist'] == 'normal':\n            mu = case['params']['mu']\n            sigma = case['params']['sigma']\n            var_xi = sigma**2\n            def sample_generator(size):\n                return np.random.normal(loc=mu, scale=sigma, size=size)\n        elif case['dist'] == 'uniform':\n            a, b = case['params']['a'], case['params']['b']\n            mu = (a + b) / 2.0\n            var_xi = (b - a)**2 / 12.0\n            def sample_generator(size):\n                return np.random.uniform(low=a, high=b, size=size)\n        elif case['dist'] == 'laplace':\n            mu = case['params']['mu']\n            s = case['params']['s']\n            var_xi = 2.0 * s**2\n            def sample_generator(size):\n                return np.random.laplace(loc=mu, scale=s, size=size)\n\n        # Task 1: Empirical characterization\n        empirical_y = []\n        for n in N_GRID:\n            # Vectorized computation for efficiency\n            # Generate all samples for all replicates at once\n            samples = sample_generator(size=(N_REPS, n))\n            # Compute SAA estimator (x_hat_n) for each replicate\n            x_hat_n_reps = np.mean(samples, axis=1)\n            # Compute F(x_hat_n) for each replicate using the analytical formula\n            F_x_hat_n_reps = (x_hat_n_reps - mu)**2 + var_xi\n            # Estimate E[F(x_hat_n)] by averaging over replicates\n            estimated_E_F_xn = np.mean(F_x_hat_n_reps)\n            empirical_y.append(estimated_E_F_xn)\n        \n        empirical_y = np.array(empirical_y)\n\n        # Task 3: Model fitting and decision rule\n        # Fit model m(n) = a + b/n, which is linear in 1/n\n        z = 1.0 / N_GRID\n        # Design matrix for least squares: y = a*1 + b*z\n        A = np.vstack([np.ones(len(z)), z]).T\n        \n        # Solve for [a, b] using least squares\n        # The result gives [intercept, slope], which corresponds to [a, b]\n        a_hat, b_hat = np.linalg.lstsq(A, empirical_y, rcond=None)[0]\n\n        # Determine empirically-derived optimal sample size n_hat\n        # Minimize L(n) = a_hat + b_hat/n + c*n\n        if b_hat = 0:\n            # If b_hat is non-positive, the cost function L(n) is monotonically increasing for n > 0.\n            # The minimum occurs at the smallest possible integer n.\n            n_hat = 1\n        else:\n            # From dL/dn = 0, we get n = sqrt(b_hat/c)\n            n_hat_continuous = np.sqrt(b_hat / c)\n            # Round to the nearest integer, with a minimum of 1.\n            n_hat = max(1, int(np.round(n_hat_continuous)))\n        \n        results.append(n_hat)\n\n        # Task 4: Theoretical benchmark\n        # Optimal n is derived from minimizing L(n) = var_xi + var_xi/n + c*n\n        # This gives n = sqrt(var_xi / c)\n        n_star_continuous = np.sqrt(var_xi / c)\n        # Round to the nearest integer, with a minimum of 1.\n        n_star = max(1, int(np.round(n_star_continuous)))\n        \n        results.append(n_star)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3174778"}, {"introduction": "SAA 的解是基于有限的随机样本得到的，因此可能对抽样噪声很敏感，这一现象与过拟合有关。本练习 [@problem_id:3174756] 介绍使用岭回归（ridge regularization）作为缓解此问题的工具。您将探索基本的偏差-方差权衡（bias-variance trade-off），学习如何通过引入少量可控的偏差来显著降低解的方差，从而获得更稳定和可靠的解。", "problem": "考虑一个最小化期望平方偏差的随机优化问题，其中决策 $x \\in \\mathbb{R}$ 在随机扰动 $\\xi$ 下的损失定义为 $f(x,\\xi) = \\frac{1}{2}(x - \\xi)^{2}$。假设 $\\xi$ 服从均值为 $\\mu \\neq 0$、方差为 $\\sigma^{2}$ 的正态分布，并设 $\\xi_{1},\\ldots,\\xi_{n}$ 是从该分布中抽取的独立同分布样本。\n\n基于样本均值近似（SAA），定义经验目标函数 $\\hat{f}_{n}(x) = \\frac{1}{2n}\\sum_{i=1}^{n}(x - \\xi_{i})^{2}$，并考虑岭正则化 SAA 问题\n$$\n\\min_{x \\in \\mathbb{R}} \\ \\hat{f}_{n}(x) + \\frac{\\lambda}{2}\\|x\\|^{2},\n$$\n其中 $\\lambda \\geq 0$ 是正则化参数，$\\|x\\|$ 表示欧几里得范数。\n\n从期望和方差的基本定义以及正态分布的性质出发，按以下步骤进行：\n\n1. 求解岭正则化 SAA 问题，以获得作为样本均值 $\\bar{\\xi} = \\frac{1}{n}\\sum_{i=1}^{n}\\xi_{i}$ 和 $\\lambda$ 的函数的最优解 $x_{n}^{\\lambda}$。\n\n2. 设 $F(x) = \\mathbb{E}[f(x,\\xi)]$，并用 $v^{\\star} = \\inf_{x \\in \\mathbb{R}}F(x)$ 表示真实最优值。考虑 $v^{\\star}$ 的代入估计量 $\\tilde{v}_{n}^{\\lambda} = F(x_{n}^{\\lambda})$。推导出偏差 $\\mathbb{E}[\\tilde{v}_{n}^{\\lambda}] - v^{\\star}$ 和方差 $\\mathrm{Var}(\\tilde{v}_{n}^{\\lambda})$ 关于 $\\mu$、$\\sigma^{2}$、$n$ 和 $\\lambda$ 的显式公式。\n\n3. 对于大的 $n$，使用一阶渐近分析，确定正则化参数 $\\lambda$（作为 $n$、$\\mu$ 和 $\\sigma^{2}$ 的函数），以使均方误差 $\\mathrm{MSE}(\\tilde{v}_{n}^{\\lambda}) = \\left(\\mathbb{E}[\\tilde{v}_{n}^{\\lambda}] - v^{\\star}\\right)^{2} + \\mathrm{Var}(\\tilde{v}_{n}^{\\lambda})$ 在 $1/n$ 的一阶上最小。你的推导必须从基本定义出发，并且只使用正态随机变量的期望和方差的性质。\n\n将你的最终答案表示为渐近最优 $\\lambda$ 关于 $n$、$\\mu$ 和 $\\sigma^{2}$ 的单个闭式解析表达式。无需四舍五入。", "solution": "用户希望我解决一个关于带岭正则化的样本均值近似（SAA）的三部分问题。\n\n### 问题验证\n\n**第1步：提取已知条件**\n\n-   损失函数: $f(x,\\xi) = \\frac{1}{2}(x - \\xi)^{2}$，其中 $x \\in \\mathbb{R}$。\n-   随机变量: $\\xi$ 服从均值为 $\\mu \\neq 0$、方差为 $\\sigma^{2}$ 的正态分布。即 $\\xi \\sim N(\\mu, \\sigma^2)$。\n-   样本: $\\xi_{1},\\ldots,\\xi_{n}$ 是从 $\\xi$ 的分布中抽取的独立同分布（i.i.d.）样本。\n-   SAA 目标函数: $\\hat{f}_{n}(x) = \\frac{1}{2n}\\sum_{i=1}^{n}(x - \\xi_{i})^{2}$。\n-   岭正则化 SAA 问题: $\\min_{x \\in \\mathbb{R}} \\ \\hat{f}_{n}(x) + \\frac{\\lambda}{2}\\|x\\|^{2}$，其中 $\\lambda \\geq 0$，$\\|x\\|$ 是欧几里得范数。\n-   样本均值: $\\bar{\\xi} = \\frac{1}{n}\\sum_{i=1}^{n}\\xi_{i}$。\n-   真实目标函数: $F(x) = \\mathbb{E}[f(x,\\xi)]$。\n-   真实最优值: $v^{\\star} = \\inf_{x \\in \\mathbb{R}}F(x)$。\n-   代入估计量: $\\tilde{v}_{n}^{\\lambda} = F(x_{n}^{\\lambda})$，其中 $x_{n}^{\\lambda}$ 是正则化 SAA 问题的解。\n-   均方误差 (MSE): $\\mathrm{MSE}(\\tilde{v}_{n}^{\\lambda}) = \\left(\\mathbb{E}[\\tilde{v}_{n}^{\\lambda}] - v^{\\star}\\right)^{2} + \\mathrm{Var}(\\tilde{v}_{n}^{\\lambda})$。\n\n**第2步：使用提取的已知条件进行验证**\n\n-   **科学依据**：该问题在统计学习理论和随机优化领域是公认的。它涉及 SAA、岭正则化、偏差-方差权衡和 MSE 分析等标准概念。使用二次损失函数和正态分布是常见且科学合理的。\n-   **适定性**：问题定义清晰。目标函数是凸的，确保存在唯一的最优解。任务是具体的，并能导出一个唯一的解析解。\n-   **客观性**：问题使用精确的数学语言陈述，没有任何主观或模棱两可的术语。\n\n**第3步：结论与行动**\n\n该问题是有效的，因为它是自洽的、科学合理的且适定的。我将进行完整求解。\n\n### 第1部分：求解岭正则化 SAA 问题\n\n正则化目标函数为 $L(x) = \\hat{f}_{n}(x) + \\frac{\\lambda}{2}\\|x\\|^{2}$。由于 $x \\in \\mathbb{R}$，$\\|x\\|^2 = x^2$。\n$$\nL(x) = \\frac{1}{2n}\\sum_{i=1}^{n}(x - \\xi_{i})^{2} + \\frac{\\lambda}{2}x^{2}\n$$\n对于 $\\lambda \\ge 0$，该函数是严格凸的（因为第一项是凸的，当 $\\lambda  0$ 时第二项是严格凸的，当 $\\lambda=0$ 时和是凸的）。通过将关于 $x$ 的一阶导数设为零，可以找到唯一的最优解 $x_{n}^{\\lambda}$。\n$$\n\\frac{d L(x)}{dx} = \\frac{d}{dx} \\left( \\frac{1}{2n}\\sum_{i=1}^{n}(x^{2} - 2x\\xi_{i} + \\xi_{i}^{2}) + \\frac{\\lambda}{2}x^{2} \\right) = \\frac{1}{2n}\\sum_{i=1}^{n}(2x - 2\\xi_{i}) + \\lambda x = 0\n$$\n$$\n\\frac{1}{n} \\left( \\sum_{i=1}^{n}x - \\sum_{i=1}^{n}\\xi_{i} \\right) + \\lambda x = 0\n$$\n$$\n\\frac{1}{n} (nx - n\\bar{\\xi}) + \\lambda x = 0\n$$\n$$\nx - \\bar{\\xi} + \\lambda x = 0\n$$\n$$\n(1+\\lambda)x = \\bar{\\xi}\n$$\n求解 $x$，我们得到最优解：\n$$\nx_{n}^{\\lambda} = \\frac{\\bar{\\xi}}{1+\\lambda}\n$$\n\n### 第2部分：代入估计量的偏差和方差\n\n首先，我们确定真实目标函数 $F(x)$ 和真实最优值 $v^{\\star}$。\n$$\nF(x) = \\mathbb{E}[f(x,\\xi)] = \\mathbb{E}\\left[\\frac{1}{2}(x - \\xi)^{2}\\right] = \\frac{1}{2}\\mathbb{E}[x^2 - 2x\\xi + \\xi^2]\n$$\n利用期望的线性性质，\n$$\nF(x) = \\frac{1}{2}(x^2 - 2x\\mathbb{E}[\\xi] + \\mathbb{E}[\\xi^2])\n$$\n我们知道 $\\mathbb{E}[\\xi] = \\mu$ 和 $\\mathrm{Var}(\\xi) = \\mathbb{E}[\\xi^2] - (\\mathbb{E}[\\xi])^2 = \\sigma^2$，所以 $\\mathbb{E}[\\xi^2] = \\sigma^2 + \\mu^2$。将这些代入 $F(x)$：\n$$\nF(x) = \\frac{1}{2}(x^2 - 2x\\mu + \\sigma^2 + \\mu^2) = \\frac{1}{2}((x-\\mu)^2 + \\sigma^2)\n$$\n真实最优值 $v^{\\star}$ 是 $F(x)$ 的最小值。这在 $x^{\\star} = \\mu$ 处取得，所以：\n$$\nv^{\\star} = F(\\mu) = \\frac{1}{2}((\\mu-\\mu)^2 + \\sigma^2) = \\frac{\\sigma^2}{2}\n$$\n代入估计量是 $\\tilde{v}_{n}^{\\lambda} = F(x_{n}^{\\lambda})$。\n$$\n\\tilde{v}_{n}^{\\lambda} = \\frac{1}{2}\\left(\\left(x_{n}^{\\lambda} - \\mu\\right)^2 + \\sigma^2\\right) = \\frac{1}{2}\\left(\\left(\\frac{\\bar{\\xi}}{1+\\lambda} - \\mu\\right)^2\\right) + \\frac{\\sigma^2}{2}\n$$\n偏差是 $\\mathbb{E}[\\tilde{v}_{n}^{\\lambda}] - v^{\\star}$。\n$$\n\\mathbb{E}[\\tilde{v}_{n}^{\\lambda}] - v^{\\star} = \\mathbb{E}\\left[\\frac{1}{2}\\left(\\frac{\\bar{\\xi}}{1+\\lambda} - \\mu\\right)^2\\right] + \\frac{\\sigma^2}{2} - \\frac{\\sigma^2}{2} = \\frac{1}{2}\\mathbb{E}\\left[\\left(\\frac{\\bar{\\xi}}{1+\\lambda} - \\mu\\right)^2\\right]\n$$\n设 $Y = \\frac{\\bar{\\xi}}{1+\\lambda} - \\mu$。偏差是 $\\frac{1}{2}\\mathbb{E}[Y^2]$。我们使用性质 $\\mathbb{E}[Y^2] = \\mathrm{Var}(Y) + (\\mathbb{E}[Y])^2$。\n样本均值 $\\bar{\\xi}$ 的均值为 $\\mathbb{E}[\\bar{\\xi}] = \\mu$，方差为 $\\mathrm{Var}(\\bar{\\xi}) = \\frac{\\sigma^2}{n}$。\n$Y$ 的均值为：\n$$\n\\mathbb{E}[Y] = \\mathbb{E}\\left[\\frac{\\bar{\\xi}}{1+\\lambda} - \\mu\\right] = \\frac{\\mathbb{E}[\\bar{\\xi}]}{1+\\lambda} - \\mu = \\frac{\\mu}{1+\\lambda} - \\mu = -\\frac{\\lambda\\mu}{1+\\lambda}\n$$\n$Y$ 的方差为：\n$$\n\\mathrm{Var}(Y) = \\mathrm{Var}\\left(\\frac{\\bar{\\xi}}{1+\\lambda} - \\mu\\right) = \\frac{1}{(1+\\lambda)^2}\\mathrm{Var}(\\bar{\\xi}) = \\frac{\\sigma^2}{n(1+\\lambda)^2}\n$$\n因此，$\\tilde{v}_{n}^{\\lambda}$ 的偏差是：\n$$\n\\text{Bias}(\\tilde{v}_{n}^{\\lambda}) = \\frac{1}{2}\\left(\\frac{\\sigma^2}{n(1+\\lambda)^2} + \\left(-\\frac{\\lambda\\mu}{1+\\lambda}\\right)^2\\right) = \\frac{1}{2(1+\\lambda)^2}\\left(\\frac{\\sigma^2}{n} + \\lambda^2\\mu^2\\right)\n$$\n接下来，我们计算方差 $\\mathrm{Var}(\\tilde{v}_{n}^{\\lambda})$。\n$$\n\\mathrm{Var}(\\tilde{v}_{n}^{\\lambda}) = \\mathrm{Var}\\left(\\frac{1}{2}Y^2 + \\frac{\\sigma^2}{2}\\right) = \\frac{1}{4}\\mathrm{Var}(Y^2)\n$$\n由于 $\\bar{\\xi} \\sim N(\\mu, \\sigma^2/n)$，变量 $Y = \\frac{\\bar{\\xi}}{1+\\lambda} - \\mu$ 也服从正态分布。根据上面计算的其均值和方差，可知 $Y \\sim N(-\\frac{\\lambda\\mu}{1+\\lambda}, \\frac{\\sigma^2}{n(1+\\lambda)^2})$。\n设 $Y = a + bZ$，其中 $Z \\sim N(0,1)$，$a = \\mathbb{E}[Y] = -\\frac{\\lambda\\mu}{1+\\lambda}$，以及 $b^2 = \\mathrm{Var}(Y) = \\frac{\\sigma^2}{n(1+\\lambda)^2}$。\n我们需要计算 $\\mathrm{Var}(Y^2) = \\mathrm{Var}((a+bZ)^2)$。使用标准正态随机变量的矩（$\\mathbb{E}[Z]=0, \\mathbb{E}[Z^2]=1, \\mathbb{E}[Z^3]=0, \\mathbb{E}[Z^4]=3$）：\n$$\n\\mathbb{E}[Y^2] = a^2+b^2\\mathbb{E}[Z^2] = a^2+b^2\n$$\n$$\n\\mathbb{E}[Y^4] = \\mathbb{E}[(a+bZ)^4] = \\mathbb{E}[a^4 + 4a^3bZ + 6a^2b^2Z^2 + 4ab^3Z^3 + b^4Z^4] = a^4 + 6a^2b^2 + 3b^4\n$$\n$$\n\\mathrm{Var}(Y^2) = \\mathbb{E}[Y^4] - (\\mathbb{E}[Y^2])^2 = (a^4 + 6a^2b^2 + 3b^4) - (a^2+b^2)^2 = 4a^2b^2 + 2b^4\n$$\n所以，$\\tilde{v}_{n}^{\\lambda}$ 的方差是：\n$$\n\\mathrm{Var}(\\tilde{v}_{n}^{\\lambda}) = \\frac{1}{4}(4a^2b^2 + 2b^4) = a^2b^2 + \\frac{1}{2}b^4\n$$\n代入 $a^2$ 和 $b^2$ 的表达式：\n$$\n\\mathrm{Var}(\\tilde{v}_{n}^{\\lambda}) = \\frac{\\lambda^2\\mu^2}{(1+\\lambda)^2} \\frac{\\sigma^2}{n(1+\\lambda)^2} + \\frac{1}{2}\\left(\\frac{\\sigma^2}{n(1+\\lambda)^2}\\right)^2 = \\frac{\\lambda^2\\mu^2\\sigma^2}{n(1+\\lambda)^4} + \\frac{\\sigma^4}{2n^2(1+\\lambda)^4}\n$$\n$$\n\\mathrm{Var}(\\tilde{v}_{n}^{\\lambda}) = \\frac{1}{(1+\\lambda)^4}\\left(\\frac{\\lambda^2\\mu^2\\sigma^2}{n} + \\frac{\\sigma^4}{2n^2}\\right)\n$$\n\n### 第3部分：渐近最优正则化参数\n\n均方误差为 $\\mathrm{MSE}(\\tilde{v}_{n}^{\\lambda}) = \\left(\\text{Bias}(\\tilde{v}_{n}^{\\lambda})\\right)^2 + \\mathrm{Var}(\\tilde{v}_{n}^{\\lambda})$。\n$$\n\\mathrm{MSE}(\\tilde{v}_{n}^{\\lambda}) = \\left(\\frac{1}{2(1+\\lambda)^2}\\left(\\frac{\\sigma^2}{n} + \\lambda^2\\mu^2\\right)\\right)^2 + \\frac{1}{(1+\\lambda)^4}\\left(\\frac{\\lambda^2\\mu^2\\sigma^2}{n} + \\frac{\\sigma^4}{2n^2}\\right)\n$$\n展开偏差的平方项：\n$$\n(\\text{Bias})^2 = \\frac{1}{4(1+\\lambda)^4}\\left(\\frac{\\sigma^4}{n^2} + \\frac{2\\lambda^2\\mu^2\\sigma^2}{n} + \\lambda^4\\mu^4\\right)\n$$\n加上方差：\n$$\n\\mathrm{MSE}(\\tilde{v}_{n}^{\\lambda}) = \\frac{1}{4(1+\\lambda)^4}\\left(\\frac{\\sigma^4}{n^2} + \\frac{2\\lambda^2\\mu^2\\sigma^2}{n} + \\lambda^4\\mu^4\\right) + \\frac{1}{(1+\\lambda)^4}\\left(\\frac{\\lambda^2\\mu^2\\sigma^2}{n} + \\frac{\\sigma^4}{2n^2}\\right)\n$$\n在共同的分母下合并各项：\n$$\n\\mathrm{MSE}(\\tilde{v}_{n}^{\\lambda}) = \\frac{1}{(1+\\lambda)^4} \\left[ \\frac{\\sigma^4}{4n^2} + \\frac{2\\lambda^2\\mu^2\\sigma^2}{4n} + \\frac{\\lambda^4\\mu^4}{4} + \\frac{4\\lambda^2\\mu^2\\sigma^2}{4n} + \\frac{2\\sigma^4}{4n^2} \\right]\n$$\n$$\n\\mathrm{MSE}(\\tilde{v}_{n}^{\\lambda}) = \\frac{1}{4(1+\\lambda)^4} \\left[ \\lambda^4\\mu^4 + \\frac{6\\lambda^2\\mu^2\\sigma^2}{n} + \\frac{3\\sigma^4}{n^2} \\right]\n$$\n为了找到最小化此 MSE 的最优 $\\lambda$，我们对其关于 $\\lambda$ 求导并将结果设为零。\n设 $f(\\lambda) = (1+\\lambda)^{-4}$ 和 $g(\\lambda) = \\lambda^4\\mu^4 + \\frac{6\\lambda^2\\mu^2\\sigma^2}{n} + \\frac{3\\sigma^4}{n^2}$。\n$\\mathrm{MSE} = \\frac{1}{4}f(\\lambda)g(\\lambda)$ 的导数为 $\\frac{1}{4}(f'g + fg')=0$。\n$ f'(\\lambda) = -4(1+\\lambda)^{-5} $，$ g'(\\lambda) = 4\\lambda^3\\mu^4 + \\frac{12\\lambda\\mu^2\\sigma^2}{n} $。\n将导数设为零得到 $-4(1+\\lambda)^{-5}g(\\lambda) + (1+\\lambda)^{-4}g'(\\lambda) = 0$。\n两边乘以 $(1+\\lambda)^5$：\n$$\n-4g(\\lambda) + (1+\\lambda)g'(\\lambda) = 0\n$$\n$$\n-4\\left(\\lambda^4\\mu^4 + \\frac{6\\lambda^2\\mu^2\\sigma^2}{n} + \\frac{3\\sigma^4}{n^2}\\right) + (1+\\lambda)\\left(4\\lambda^3\\mu^4 + \\frac{12\\lambda\\mu^2\\sigma^2}{n}\\right) = 0\n$$\n展开并按 $\\lambda$ 的幂次合并同类项：\n$$\n(-4\\lambda^4\\mu^4 - \\frac{24\\lambda^2\\mu^2\\sigma^2}{n} - \\frac{12\\sigma^4}{n^2}) + (4\\lambda^3\\mu^4 + \\frac{12\\lambda\\mu^2\\sigma^2}{n} + 4\\lambda^4\\mu^4 + \\frac{12\\lambda^2\\mu^2\\sigma^2}{n}) = 0\n$$\n$$\n4\\lambda^3\\mu^4 - \\frac{12\\lambda^2\\mu^2\\sigma^2}{n} + \\frac{12\\lambda\\mu^2\\sigma^2}{n} - \\frac{12\\sigma^4}{n^2} = 0\n$$\n$$\n\\lambda^3\\mu^4 - \\frac{3\\lambda^2\\mu^2\\sigma^2}{n} + \\frac{3\\lambda\\mu^2\\sigma^2}{n} - \\frac{3\\sigma^4}{n^2} = 0\n$$\n对于大的 $n$，我们期望 $\\lambda$ 很小。我们假设 $\\lambda$ 的尺度为 $c/n$（其中 $c$ 为某个常数）来进行渐近分析。设 $\\lambda = c/n$。\n$$\n\\frac{c^3\\mu^4}{n^3} - \\frac{3(c^2/n^2)\\mu^2\\sigma^2}{n} + \\frac{3(c/n)\\mu^2\\sigma^2}{n} - \\frac{3\\sigma^4}{n^2} = 0\n$$\n$$\n\\frac{c^3\\mu^4}{n^3} - \\frac{3c^2\\mu^2\\sigma^2}{n^3} + \\frac{3c\\mu^2\\sigma^2}{n^2} - \\frac{3\\sigma^4}{n^2} = 0\n$$\n为了找到主导阶行为，我们两边乘以 $n^2$：\n$$\n\\frac{c^3\\mu^4}{n} - \\frac{3c^2\\mu^2\\sigma^2}{n} + 3c\\mu^2\\sigma^2 - 3\\sigma^4 = 0\n$$\n当 $n \\to \\infty$ 时，含有 $1/n$ 的项消失，剩下主导平衡方程：\n$$\n3c\\mu^2\\sigma^2 - 3\\sigma^4 = 0\n$$\n由于 $\\mu \\neq 0$ 且 $\\sigma^2$ 是方差（假设为正），我们可以解出 $c$：\n$$\nc = \\frac{3\\sigma^4}{3\\mu^2\\sigma^2} = \\frac{\\sigma^2}{\\mu^2}\n$$\n因此，渐近最优正则化参数是 $\\lambda = c/n$。\n$$\n\\lambda = \\frac{\\sigma^2}{n\\mu^2}\n$$", "answer": "$$\\boxed{\\frac{\\sigma^2}{n\\mu^2}}$$", "id": "3174756"}, {"introduction": "随机优化的目标通常不仅是找到单个最优解，还包括比较不同候选决策的性能。在估计性能差异时，我们估计量的方差至关重要。本练习 [@problem_id:3174809] 展示了共同随机数（Common Random Numbers, CRN）这一方差缩减技术的威力，揭示了与使用独立样本相比，该技术如何能够实现更精确、统计效率更高的比较。", "problem": "考虑使用样本均值近似 (Sample Average Approximation, SAA) 来估计两个决策之间预期损失的差异。设预期损失定义为 $F(x) = \\mathbb{E}[g(x,\\xi)]$，SAA 估计量定义为\n$$\n\\hat{F}(x) = \\frac{1}{N} \\sum_{i=1}^{N} g(x,\\xi_i),\n$$\n其中 $\\xi_1,\\dots,\\xi_N$ 是随机输入 $\\xi$ 的独立同分布实现。对于决策 $x_1$，假设损失为 $g(x_1,\\xi) = 2\\xi + \\varepsilon_1$；对于决策 $x_2$，假设损失为 $g(x_2,\\xi) = 3\\xi + \\varepsilon_2$，其中 $\\xi \\sim \\mathcal{N}(0,1)$，$\\varepsilon_1 \\sim \\mathcal{N}(0,2)$，且 $\\varepsilon_2 \\sim \\mathcal{N}(0,3)$。假设 $\\xi$、$\\varepsilon_1$ 和 $\\varepsilon_2$ 相互独立，并且对于每个 $i=1,\\dots,N$，三元组 $(\\xi_i,\\varepsilon_{1,i},\\varepsilon_{2,i})$ 是 $(\\xi,\\varepsilon_1,\\varepsilon_2)$ 的独立同分布副本。\n\n比较用于估计差异 $\\hat{F}(x_1) - \\hat{F}(x_2)$ 的两种抽样方案：\n1. 使用共同随机数 (Common Random Numbers, CRN)，即对于每个 $i$，在 $g(x_1,\\xi_i)$ 和 $g(x_2,\\xi_i)$ 中使用相同的 $\\xi_i$，而 $\\varepsilon_{1,i}$ 和 $\\varepsilon_{2,i}$ 在不同的 $i$ 之间保持独立且相互独立。\n2. 使用独立抽样，即分别为 $x_1$ 和 $x_2$ 使用独立的序列 $\\{\\xi_i^{(1)}\\}_{i=1}^{N}$ 和 $\\{\\xi_i^{(2)}\\}_{i=1}^{N}$，每个序列都与 $\\xi$ 同分布，且所有噪声项在决策和样本间均独立。\n\n从期望、方差和协方差的定义以及独立随机变量和的性质出发，推导两种方案下 $\\operatorname{Var}\\!\\left(\\hat{F}(x_1) - \\hat{F}(x_2)\\right)$ 作为 $N$ 的函数的表达式。然后，对于 $N=100$，计算精确比率\n$$\n\\rho = \\frac{\\operatorname{Var}_{\\text{indep}}\\!\\left(\\hat{F}(x_1) - \\hat{F}(x_2)\\right)}{\\operatorname{Var}_{\\text{CRN}}\\!\\left(\\hat{F}(x_1) - \\hat{F}(x_2)\\right)}.\n$$\n将您的最终答案表示为一个精确的数字。", "solution": "### 步骤 1：提取已知条件\n- 预期损失：$F(x) = \\mathbb{E}[g(x,\\xi)]$\n- SAA 估计量：$\\hat{F}(x) = \\frac{1}{N} \\sum_{i=1}^{N} g(x,\\xi_i)$\n- 决策 $x_1$ 的损失函数：$g(x_1,\\xi) = 2\\xi + \\varepsilon_1$\n- 决策 $x_2$ 的损失函数：$g(x_2,\\xi) = 3\\xi + \\varepsilon_2$\n- 随机变量分布：\n    - $\\xi \\sim \\mathcal{N}(0,1)$，意味着 $\\mathbb{E}[\\xi] = 0$ 和 $\\operatorname{Var}(\\xi) = 1$。\n    - $\\varepsilon_1 \\sim \\mathcal{N}(0,2)$，意味着 $\\mathbb{E}[\\varepsilon_1] = 0$ 和 $\\operatorname{Var}(\\varepsilon_1) = 2$。\n    - $\\varepsilon_2 \\sim \\mathcal{N}(0,3)$，意味着 $\\mathbb{E}[\\varepsilon_2] = 0$ 和 $\\operatorname{Var}(\\varepsilon_2) = 3$。\n- 独立性假设：\n    - $\\xi$、$\\varepsilon_1$ 和 $\\varepsilon_2$ 相互独立。\n    - 对于每个 $i=1,\\dots,N$，三元组 $(\\xi_i, \\varepsilon_{1,i}, \\varepsilon_{2,i})$ 是独立同分布 (i.i.d.) 副本。\n- 用于估计 $\\hat{F}(x_1) - \\hat{F}(x_2)$ 的抽样方案比较：\n    1.  共同随机数 (CRN)：对于 $g(x_1,\\cdot)$ 和 $g(x_2,\\cdot)$ 使用相同的 $\\xi_i$。\n    2.  独立抽样：独立的序列 $\\{\\xi_i^{(1)}\\}_{i=1}^{N}$ 和 $\\{\\xi_i^{(2)}\\}_{i=1}^{N}$。\n- 目标：推导两种方案下 $\\operatorname{Var}\\!\\left(\\hat{F}(x_1) - \\hat{F}(x_2)\\right)$ 的表达式，然后计算 $N=100$ 时的比率 $\\rho = \\frac{\\operatorname{Var}_{\\text{indep}}}{\\operatorname{Var}_{\\text{CRN}}}$。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题具有科学依据，植根于概率论、统计学和模拟的原理，特别是在样本均值近似 (SAA) 和方差缩减技术的背景下。该问题是适定的，提供了推导唯一确定性解所需的所有信息。损失函数、随机变量及其分布的定义清晰明确。问题设定内部一致，不包含任何矛盾的陈述或科学上不合理的条件。目标陈述清晰且可形式化。该问题没有表现出验证清单中列出的任何缺陷。\n\n### 步骤 3：结论与行动\n问题有效。现在开始求解过程。\n\n目标是计算和比较在两种不同抽样方案下，预期损失差异的估计量 $\\hat{F}(x_1) - \\hat{F}(x_2)$ 的方差。我们感兴趣的量是 $\\operatorname{Var}(\\hat{F}(x_1) - \\hat{F}(x_2))$。利用方差的性质，我们有：\n$$\n\\operatorname{Var}(\\hat{F}(x_1) - \\hat{F}(x_2)) = \\operatorname{Var}(\\hat{F}(x_1)) + \\operatorname{Var}(\\hat{F}(x_2)) - 2\\operatorname{Cov}(\\hat{F}(x_1), \\hat{F}(x_2))\n$$\n首先，我们计算单个 SAA 估计量的方差，即 $\\operatorname{Var}(\\hat{F}(x_1))$ 和 $\\operatorname{Var}(\\hat{F}(x_2))$。这些方差与用于计算差异的抽样方案无关。\n\nSAA 估计量是 $N$ 个独立同分布随机变量的平均值。因此，其方差是单项方差的 $\\frac{1}{N}$ 倍。\n$$\n\\operatorname{Var}(\\hat{F}(x)) = \\operatorname{Var}\\left(\\frac{1}{N} \\sum_{i=1}^{N} g(x,\\xi_i)\\right) = \\frac{1}{N^2} \\sum_{i=1}^{N} \\operatorname{Var}(g(x,\\xi_i)) = \\frac{N \\operatorname{Var}(g(x,\\xi))}{N^2} = \\frac{\\operatorname{Var}(g(x,\\xi))}{N}\n$$\n我们需要计算每个损失函数的方差。\n对于决策 $x_1$，损失函数为 $g(x_1,\\xi,\\varepsilon_1) = 2\\xi + \\varepsilon_1$。由于 $\\xi$ 和 $\\varepsilon_1$ 独立，其方差为：\n$$\n\\operatorname{Var}(g(x_1,\\xi,\\varepsilon_1)) = \\operatorname{Var}(2\\xi + \\varepsilon_1) = \\operatorname{Var}(2\\xi) + \\operatorname{Var}(\\varepsilon_1) = 2^2 \\operatorname{Var}(\\xi) + \\operatorname{Var}(\\varepsilon_1) = 4(1) + 2 = 6\n$$\n对于决策 $x_2$，损失函数为 $g(x_2,\\xi,\\varepsilon_2) = 3\\xi + \\varepsilon_2$。由于 $\\xi$ 和 $\\varepsilon_2$ 独立，其方差为：\n$$\n\\operatorname{Var}(g(x_2,\\xi,\\varepsilon_2)) = \\operatorname{Var}(3\\xi + \\varepsilon_2) = \\operatorname{Var(3\\xi)} + \\operatorname{Var}(\\varepsilon_2) = 3^2 \\operatorname{Var}(\\xi) + \\operatorname{Var}(\\varepsilon_2) = 9(1) + 3 = 12\n$$\n因此，单个 SAA 估计量的方差为：\n$$\n\\operatorname{Var}(\\hat{F}(x_1)) = \\frac{\\operatorname{Var}(g(x_1,\\xi,\\varepsilon_1))}{N} = \\frac{6}{N}\n$$\n$$\n\\operatorname{Var}(\\hat{F}(x_2)) = \\frac{\\operatorname{Var}(g(x_2,\\xi,\\varepsilon_2))}{N} = \\frac{12}{N}\n$$\n\n现在我们来分析这两种抽样方案。\n\n**方案 1：独立抽样**\n在此方案下，使用独立的随机数集来评估 $\\hat{F}(x_1)$ 和 $\\hat{F}(x_2)$。具体来说，$\\hat{F}(x_1) = \\frac{1}{N}\\sum_{i=1}^{N} (2\\xi_i^{(1)} + \\varepsilon_{1,i})$ 且 $\\hat{F}(x_2) = \\frac{1}{N}\\sum_{i=1}^{N} (3\\xi_i^{(2)} + \\varepsilon_{2,i})$。所有的随机变量 $\\{\\xi_i^{(1)}\\}$、$\\{\\xi_i^{(2)}\\}$、$\\{\\varepsilon_{1,i}\\}$、$\\{\\varepsilon_{2,i}\\}$ 都是相互独立的。因此，两个估计量 $\\hat{F}(x_1)$ 和 $\\hat{F}(x_2)$ 是独立的随机变量。对于独立的变量，协方差为零：\n$$\n\\operatorname{Cov}_{\\text{indep}}(\\hat{F}(x_1), \\hat{F}(x_2)) = 0\n$$\n差异的方差是方差之和：\n$$\n\\operatorname{Var}_{\\text{indep}}(\\hat{F}(x_1) - \\hat{F}(x_2)) = \\operatorname{Var}(\\hat{F}(x_1)) + \\operatorname{Var}(\\hat{F}(x_2)) = \\frac{6}{N} + \\frac{12}{N} = \\frac{18}{N}\n$$\n\n**方案 2：共同随机数 (CRN)**\n在 CRN 下，两个估计量使用相同的随机数流 $\\xi_i$。设 $g_{1,i} = 2\\xi_i + \\varepsilon_{1,i}$ 和 $g_{2,i} = 3\\xi_i + \\varepsilon_{2,i}$。估计量的差异为：\n$$\n\\hat{F}(x_1) - \\hat{F}(x_2) = \\frac{1}{N}\\sum_{i=1}^{N} g_{1,i} - \\frac{1}{N}\\sum_{i=1}^{N} g_{2,i} = \\frac{1}{N}\\sum_{i=1}^{N} (g_{1,i} - g_{2,i})\n$$\n对于 $i=1, \\dots, N$，项 $(g_{1,i} - g_{2,i})$ 是独立同分布的。因此，它们的和的方差是：\n$$\n\\operatorname{Var}_{\\text{CRN}}(\\hat{F}(x_1) - \\hat{F}(x_2)) = \\operatorname{Var}\\left(\\frac{1}{N}\\sum_{i=1}^{N} (g_{1,i} - g_{2,i})\\right) = \\frac{1}{N}\\operatorname{Var}(g_1 - g_2)\n$$\n其中 $g_1 = 2\\xi + \\varepsilon_1$ 和 $g_2 = 3\\xi + \\varepsilon_2$。我们来计算差异 $g_1 - g_2$ 的方差：\n$$\ng_1 - g_2 = (2\\xi + \\varepsilon_1) - (3\\xi + \\varepsilon_2) = -\\xi + \\varepsilon_1 - \\varepsilon_2\n$$\n由于 $\\xi$、$\\varepsilon_1$ 和 $\\varepsilon_2$ 相互独立，这个和的方差是各项方差之和：\n$$\n\\operatorname{Var}(g_1 - g_2) = \\operatorname{Var}(-\\xi + \\varepsilon_1 - \\varepsilon_2) = \\operatorname{Var}(-\\xi) + \\operatorname{Var}(\\varepsilon_1) + \\operatorname{Var}(-\\varepsilon_2)\n$$\n使用性质 $\\operatorname{Var}(aX) = a^2\\operatorname{Var}(X)$：\n$$\n\\operatorname{Var}(g_1 - g_2) = (-1)^2\\operatorname{Var}(\\xi) + \\operatorname{Var}(\\varepsilon_1) + (-1)^2\\operatorname{Var}(\\varepsilon_2) = \\operatorname{Var}(\\xi) + \\operatorname{Var}(\\varepsilon_1) + \\operatorname{Var}(\\varepsilon_2)\n$$\n代入给定的方差值：\n$$\n\\operatorname{Var}(g_1 - g_2) = 1 + 2 + 3 = 6\n$$\n因此，在 CRN 下，差异估计量的方差为：\n$$\n\\operatorname{Var}_{\\text{CRN}}(\\hat{F}(x_1) - \\hat{F}(x_2)) = \\frac{\\operatorname{Var}(g_1 - g_2)}{N} = \\frac{6}{N}\n$$\n这个结果是正的，这与方差非负的性质是一致的。由共同随机数 $\\xi$ 引起的 $g_1$ 和 $g_2$ 之间的正协方差成功地减小了差异的方差。\n\n最后，我们计算所需的比率 $\\rho$。问题指定 $N=100$，但正如我们所见，该比率与 $N$ 无关。\n$$\n\\rho = \\frac{\\operatorname{Var}_{\\text{indep}}\\!\\left(\\hat{F}(x_1) - \\hat{F}(x_2)\\right)}{\\operatorname{Var}_{\\text{CRN}}\\!\\left(\\hat{F}(x_1) - \\hat{F}(x_2)\\right)} = \\frac{18/N}{6/N} = \\frac{18}{6} = 3\n$$\n$N=100$ 的值不影响最终的比率。该比率是一个精确的数字。", "answer": "$$\\boxed{3}$$", "id": "3174809"}]}