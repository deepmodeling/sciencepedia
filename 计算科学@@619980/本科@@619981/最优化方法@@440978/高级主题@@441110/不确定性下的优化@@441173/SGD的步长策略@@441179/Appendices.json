{"hands_on_practices": [{"introduction": "要想掌握步长策略，第一步是理解它如何与优化问题的几何结构相互作用。本练习 [@problem_id:3185955] 使用一个简单的二次型目标函数，揭示了目标函数海森矩阵的特征值（尤其是最大特征值 $\\lambda_{\\max}$）如何为梯度下降设置了一个基础的速度上限。通过编写代码进行仿真，你将亲身体会到为何病态条件问题难以优化，并观察不同步长策略如何应对不同曲率的误差分量。", "problem": "考虑使用随机梯度下降 (SGD) 来最小化一个严格凸二次目标函数。设目标由对称正定 (SPD) 矩阵 $Q \\in \\mathbb{R}^{d \\times d}$ 定义，损失函数为 $f(x) = \\tfrac{1}{2} x^{\\top} Q x$。经典的梯度下降迭代是 $x_{t+1} = x_t - \\eta_t \\nabla f(x_t)$，其中 $\\eta_t$ 是第 $t$ 次迭代的步长。为了分析，假设随机性可以忽略不计，并专注于沿 $Q$ 的每个特征方向的确定性收缩。\n\n从线性迭代的基本行为和 $Q$ 的谱分解出发，确定能够保证迭代在所有特征方向上都渐近稳定的最大恒定步长 $\\eta_{\\mathrm{safe}}$。然后，比较三种步长策略如何影响与 $Q$ 的最小和最大特征值对齐的误差分量的衰减：\n- 恒定策略：$\\eta_t = \\eta_0$，其中 $\\eta_0 = \\rho \\cdot \\eta_{\\mathrm{safe}}$。\n- 反比时间策略：$\\eta_t = \\dfrac{\\eta_0}{1 + t}$，其中 $\\eta_0 = \\rho \\cdot \\eta_{\\mathrm{safe}}$。\n- 指数策略：$\\eta_t = \\eta_0 \\cdot \\gamma^{t}$，其中 $\\eta_0 = \\rho \\cdot \\eta_{\\mathrm{safe}}$ 且固定 $\\gamma = 0.9$。\n\n使用以下原则来量化每个特征方向的衰减速度：如果 $y_t$ 表示沿特征值为 $\\lambda$ 的特征方向的误差分量，则每步线性收缩因子为 $|1 - \\eta_t \\lambda|$。将一个策略的半衰期 $H(\\lambda)$ 定义为满足 $\\prod_{\\tau=0}^{t-1} |1 - \\eta_{\\tau} \\lambda| \\leq 0.5$ 的最小非负整数 $t$。如果此条件在有限视界 $T_{\\max}$ 内未发生，则报告 $-1$。在所有测试用例中，使用 $T_{\\max} = 200$ 和固定的指数衰减参数 $\\gamma = 0.9$。\n\n您的任务是：\n1. 从在 SPD 二次型上进行梯度下降的线性稳定性的第一性原理出发，根据 $Q$ 的谱推导出 $\\eta_{\\mathrm{safe}}$。\n2. 对于每个测试用例，计算 $\\eta_{\\mathrm{safe}}$ 以及在上述三种策略下，对应最小特征值 $\\lambda_{\\min}$ 和最大特征值 $\\lambda_{\\max}$ 的半衰期，其中 $\\eta_0 = \\rho \\cdot \\eta_{\\mathrm{safe}}$。\n3. 确保策略的每次迭代都是稳定的；如果某个策略在 $[0, T_{\\max}-1]$ 内的任何迭代中违反了稳定性条件，仍然使用上述定义计算半衰期。半衰期的定义已经通过绝对值考虑了振荡但收缩的行为。\n\n实现一个程序，对以下谱和缩放参数的测试套件执行此计算：\n- 测试用例 1：特征值 $[1.0, 1.0, 1.0, 100.0]$，$\\rho = 0.9$。\n- 测试用例 2：特征值 $[1.0, 2.0, 3.0, 4.0]$，$\\rho = 0.9$。\n- 测试用例 3：特征值 $[0.01, 0.05, 0.1, 10.0]$，$\\rho = 0.5$。\n- 测试用例 4：特征值 $[5.0, 5.0, 5.0]$，$\\rho = 0.9$。\n- 测试用例 5：特征值 $[1.0, 1000.0]$，$\\rho = 0.9$。\n\n对于每个测试用例，输出一个包含以下内容的嵌套列表：\n$[\\eta_{\\mathrm{safe}}, H_{\\min}^{\\text{const}}, H_{\\max}^{\\text{const}}, H_{\\min}^{\\text{inv}}, H_{\\max}^{\\text{inv}}, H_{\\min}^{\\text{exp}}, H_{\\max}^{\\text{exp}}]$，\n其中 $H_{\\min}^{\\cdot}$ 和 $H_{\\max}^{\\cdot}$ 表示在指定策略下，对应最小和最大特征值的半衰期。\n\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果（例如，$[ [\\ldots], [\\ldots], \\ldots ]$）。不需要外部输入，也没有物理单位。任何角度（如有）都与此问题无关。", "solution": "用户希望分析在严格凸二次目标函数 $f(x) = \\tfrac{1}{2} x^{\\top} Q x$ 上的梯度下降的收敛性，其中 $Q$ 是一个对称正定 (SPD) 矩阵。分析侧重于确定性更新规则 $x_{t+1} = x_t - \\eta_t \\nabla f(x_t)$，忽略了随机效应。\n\n### 步骤 1：安全步长 $\\eta_{\\mathrm{safe}}$ 的推导\n\n目标函数的梯度是 $\\nabla f(x) = Qx$。因此，梯度下降迭代为：\n$$\nx_{t+1} = x_t - \\eta_t Q x_t = (I - \\eta_t Q) x_t\n$$\n这个强凸函数的唯一极小值点是 $x^* = 0$。因此，向量 $x_t$ 也代表了在第 $t$ 次迭代时的误差。该方法的收敛性取决于算子 $(I - \\eta_t Q)$ 的行为。\n\n为了分析这一点，我们执行到 $Q$ 的特征基的基变换。由于 $Q$ 是实对称矩阵，它允许进行谱分解 $Q = V \\Lambda V^\\top$，其中 $V$ 是一个正交矩阵，其列是 $Q$ 的特征向量 $v_i$，而 $\\Lambda$ 是一个包含相应实数特征值 $\\lambda_i$ 的对角矩阵。由于 $Q$ 是正定的，其所有特征值都严格为正，即对于所有 $i$ 都有 $\\lambda_i  0$。\n\n让我们将特征基中的误差定义为 $z_t = V^\\top x_t$。那么 $x_t = V z_t$。将此代入迭代方程得到：\n$$\nV z_{t+1} = (I - \\eta_t V \\Lambda V^\\top) V z_t\n$$\n从左侧乘以 $V^\\top$ 并利用 $V$ 的正交性（即 $V^\\top V = I$），我们简化表达式：\n$$\nz_{t+1} = V^\\top (V I V^\\top - \\eta_t V \\Lambda V^\\top) V z_t = (V^\\top V I V^\\top V - \\eta_t V^\\top V \\Lambda V^\\top V) z_t = (I - \\eta_t \\Lambda) z_t\n$$\n这将误差的动力学解耦为 $d$ 个独立的标量方程，每个方程对应于特征值 $\\lambda_i$ 的分量 $z_{t,i}$：\n$$\nz_{t+1, i} = (1 - \\eta_t \\lambda_i) z_{t, i}\n$$\n对于一个恒定步长 $\\eta_t = \\eta  0$，为了使迭代是渐近稳定的，误差必须在每一步对每个分量都收缩。这要求对所有 $i$，收缩因子的绝对值都严格小于 1：\n$$\n|1 - \\eta \\lambda_i|  1\n$$\n这个不等式等价于联立条件 $-1  1 - \\eta \\lambda_i$ 和 $1 - \\eta \\lambda_i  1$。\n第二个条件 $1 - \\eta \\lambda_i  1$ 简化为 $-\\eta \\lambda_i  0$。由于 $\\eta > 0$ 和 $\\lambda_i > 0$，这个条件总是满足的。\n第一个条件 $-1  1 - \\eta \\lambda_i$ 简化为 $\\eta \\lambda_i  2$，这意味着 $\\eta  \\frac{2}{\\lambda_i}$。\n\n为了使迭代对于任何初始条件都是稳定的，这个条件必须对所有特征值 $\\lambda_i$ 都成立。最严格的约束来自于最大特征值 $\\lambda_{\\max} = \\max_i \\lambda_i$。因此，步长必须满足：\n$$\n\\eta  \\frac{2}{\\lambda_{\\max}}\n$$\n问题要求找到保证渐近稳定性的最大恒定步长 $\\eta_{\\mathrm{safe}}$。这对应于 $\\eta$ 允许范围的上确界。因此，我们定义：\n$$\n\\eta_{\\mathrm{safe}} = \\frac{2}{\\lambda_{\\max}}\n$$\n\n### 步骤 2：不同策略下的半衰期计算\n\n沿第 $i$ 个特征方向的误差分量在 $t$ 步内的衰减由每步收缩因子的累积乘积给出：\n$$\nP_t(\\lambda_i) = \\prod_{\\tau=0}^{t-1} |1 - \\eta_{\\tau} \\lambda_i|\n$$\n半衰期 $H(\\lambda)$ 被定义为使 $P_t(\\lambda) \\leq 0.5$ 的最小非负整数 $t$。我们被要求为最小特征值 $\\lambda_{\\min}$ 和最大特征值 $\\lambda_{\\max}$，在三种不同的步长策略下计算这个值，所有策略都源自基础步长 $\\eta_0 = \\rho \\cdot \\eta_{\\mathrm{safe}}$。施加了最大迭代视界 $T_{\\max} = 200$。\n\n这些策略是：\n1.  **恒定策略**：$\\eta_t = \\eta_0$。对于给定的 $\\lambda$，收缩因子是恒定的。\n2.  **反比时间策略**：$\\eta_t = \\frac{\\eta_0}{1 + t}$。步长会衰减，所以当 $t \\to \\infty$ 时，收缩因子 $|1 - \\eta_t \\lambda|$ 趋近于 1。这意味着在后期阶段收敛变慢。\n3.  **指数策略**：$\\eta_t = \\eta_0 \\cdot \\gamma^t$，其中 $\\gamma = 0.9$。步长呈指数衰减，比反比时间策略更快。\n\n每个测试用例的计算过程如下：\n1.  从给定的谱中提取 $\\lambda_{\\min}$ 和 $\\lambda_{\\max}$。\n2.  计算 $\\eta_{\\mathrm{safe}} = 2 / \\lambda_{\\max}$。\n3.  使用给定的 $\\rho$ 计算 $\\eta_0 = \\rho \\cdot \\eta_{\\mathrm{safe}}$。\n4.  对于三种策略中的每一种以及 $\\{\\lambda_{\\min}, \\lambda_{\\max}\\}$ 中的每个特征值：\n    a. 初始化累积乘积 $P = 1.0$。\n    b. 从 $0$ 到 $T_{\\max}-1$ 迭代 $\\tau$。\n    c. 在每次迭代中，根据策略计算步长 $\\eta_{\\tau}$。\n    d. 更新乘积：$P \\leftarrow P \\cdot |1 - \\eta_{\\tau} \\lambda|$。\n    e. 如果 $P \\leq 0.5$，则半衰期为 $\\tau+1$。记录该值并终止此 $(\\lambda, \\text{schedule})$ 对的内循环。\n    f. 如果循环完成而条件未满足，则半衰期记录为 $-1$。\n5.  将测试用例的结果组装成指定的列表格式：$[\\eta_{\\mathrm{safe}}, H_{\\min}^{\\text{const}}, H_{\\max}^{\\text{const}}, H_{\\min}^{\\text{inv}}, H_{\\max}^{\\text{inv}}, H_{\\min}^{\\text{exp}}, H_{\\max}^{\\text{exp}}]$。\n对每个提供的测试用例都实现了此过程。", "answer": "```python\nimport numpy as np\n\ndef calculate_half_life(lambda_val: float, schedule_name: str, eta_0: float, T_max: int, gamma: float) - int:\n    \"\"\"\n    Calculates the half-life for a given eigenvalue and step-size schedule.\n\n    The half-life is the smallest integer t such that the cumulative product of\n    contraction factors is = 0.5.\n\n    Args:\n        lambda_val: The eigenvalue.\n        schedule_name: The name of the schedule ('const', 'inv', 'exp').\n        eta_0: The initial step size.\n        T_max: The maximum number of iterations to check.\n        gamma: The decay factor for the exponential schedule.\n\n    Returns:\n        The half-life as an integer, or -1 if not reached within T_max.\n    \"\"\"\n    cumulative_product = 1.0\n    for t_idx in range(T_max):\n        eta_t = 0.0\n        if schedule_name == 'const':\n            eta_t = eta_0\n        elif schedule_name == 'inv':\n            eta_t = eta_0 / (1.0 + t_idx)\n        elif schedule_name == 'exp':\n            eta_t = eta_0 * (gamma ** t_idx)\n        \n        contraction_factor = abs(1.0 - eta_t * lambda_val)\n        cumulative_product *= contraction_factor\n        \n        if cumulative_product = 0.5:\n            return t_idx + 1\n            \n    return -1\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    \"\"\"\n    test_cases = [\n        # (eigenvalues, rho)\n        ([1.0, 1.0, 1.0, 100.0], 0.9),\n        ([1.0, 2.0, 3.0, 4.0], 0.9),\n        ([0.01, 0.05, 0.1, 10.0], 0.5),\n        ([5.0, 5.0, 5.0], 0.9),\n        ([1.0, 1000.0], 0.9),\n    ]\n\n    T_max = 200\n    gamma = 0.9\n\n    results = []\n    for eigenvalues, rho in test_cases:\n        lambda_min = min(eigenvalues)\n        lambda_max = max(eigenvalues)\n        \n        # 1. Derive eta_safe from first principles.\n        # Stability requires |1 - eta*lambda|  1 for all eigenvalues lambda.\n        # This implies eta  2/lambda for all lambda.\n        # The tightest constraint is from lambda_max, so eta  2/lambda_max.\n        # eta_safe is the supremum of this range.\n        eta_safe = 2.0 / lambda_max\n        \n        eta_0 = rho * eta_safe\n        \n        # 2. Compute half-lives for the three schedules.\n        \n        # Constant schedule\n        H_min_const = calculate_half_life(lambda_min, 'const', eta_0, T_max, gamma)\n        H_max_const = calculate_half_life(lambda_max, 'const', eta_0, T_max, gamma)\n        \n        # Inverse-time schedule\n        H_min_inv = calculate_half_life(lambda_min, 'inv', eta_0, T_max, gamma)\n        H_max_inv = calculate_half_life(lambda_max, 'inv', eta_0, T_max, gamma)\n\n        # Exponential schedule\n        H_min_exp = calculate_half_life(lambda_min, 'exp', eta_0, T_max, gamma)\n        H_max_exp = calculate_half_life(lambda_max, 'exp', eta_0, T_max, gamma)\n        \n        case_result = [eta_safe, H_min_const, H_max_const, H_min_inv, H_max_inv, H_min_exp, H_max_exp]\n        results.append(case_result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3185955"}, {"introduction": "在确定性分析的基础上，本练习引入了随机梯度下降（SGD）中的关键元素——随机噪声。这个分析性练习 [@problem_id:3185967] 将引导你探索SGD中的一个基本权衡：步长需要足够大以保证优化进程，同时又要足够小以抑制噪声。通过推导，你将理解“噪声下限”（noise floor）这一概念，并从数学上揭示为何特定的步长衰减率是算法收敛到真正最小值的必要条件。", "problem": "考虑随机梯度下降（SGD），其迭代更新定义为 $x_{t+1} = x_t - \\eta_t g_t$，作用于一维目标函数 $f(x) = \\frac{1}{2}x^2$，其真实梯度为 $\\nabla f(x_t) = x_t$。假设随机梯度为 $g_t = x_t + \\xi_t$，其中 $(\\xi_t)_{t \\geq 0}$ 是独立同分布的随机变量，满足 $\\mathbb{E}[\\xi_t] = 0$ 和 $\\mathrm{Var}(\\xi_t) = \\sigma^2$，且与过去无关。设步长序列为 $\\eta_t = \\eta_0 t^{-\\alpha}$，其中 $\\eta_0  0$ 和 $\\alpha \\in (0, \\frac{1}{2})$ 为固定常数，初始条件 $x_0$ 是确定且有限的。\n\n仅从 SGD、目标函数及其梯度的给定定义，以及方差和期望的基本性质出发，完成以下任务：\n\n1.  推导 $\\mathbb{E}[x_{t+1}^2]$ 关于 $\\eta_t$、$\\mathbb{E}[x_t^2]$ 和 $\\sigma^2$ 的封闭递推关系。\n2.  利用由缓慢变化的步长序列 $\\eta_t = \\eta_0 t^{-\\alpha}$ 所保证的渐近分析，确定当 $t \\to \\infty$ 时 $\\mathbb{E}[x_t^2]$ 的主阶行为，并阐明其与随机梯度引起的瞬时“噪声地板”之间的关系。\n3.  计算缩放极限的精确值\n$$\nL \\;=\\; \\lim_{t \\to \\infty} \\frac{t^{\\alpha}\\,\\mathbb{E}[x_t^2]}{\\eta_0 \\sigma^2}.\n$$\n\n你必须将 $L$ 表示为单个闭式常数。无需进行数值四舍五入。此构造可作为一个反例，表明对于 $\\alpha \\le \\frac{1}{2}$，在上述极限 $L$ 所捕捉的意义上，该序列表现出一个量级为 $\\mathcal{O}(\\eta_t \\sigma^2)$ 的不消失的归一化误差下限。", "solution": "用户希望分析随机梯度下降（SGD）在一个简单的一维二次目标函数上的渐近行为。该分析将按要求分三部分进行：推导状态二阶矩的递推关系，确定其渐近行为，以及计算一个特定的缩放极限。\n\n### 问题验证\n\n**步骤 1：提取已知条件**\n-   SGD 更新规则：$x_{t+1} = x_t - \\eta_t g_t$\n-   目标函数：$f(x) = \\frac{1}{2}x^2$\n-   真实梯度：$\\nabla f(x_t) = x_t$\n-   随机梯度：$g_t = x_t + \\xi_t$\n-   噪声过程 $(\\xi_t)_{t \\geq 0}$：独立同分布（i.i.d.）的随机变量。\n-   噪声性质：$\\mathbb{E}[\\xi_t] = 0$ 且 $\\mathrm{Var}(\\xi_t) = \\mathbb{E}[\\xi_t^2] - (\\mathbb{E}[\\xi_t])^2 = \\sigma^2$。由于 $\\mathbb{E}[\\xi_t]=0$，这意味着 $\\mathbb{E}[\\xi_t^2] = \\sigma^2$。噪声与过去无关，即与 $x_0, x_1, \\dots, x_t$ 无关。\n-   步长序列：$\\eta_t = \\eta_0 t^{-\\alpha}$，其中常数 $\\eta_0  0$ 且 $\\alpha \\in (0, \\frac{1}{2})$。\n-   初始条件：$x_0$ 是一个确定且有限的值。\n\n**步骤 2：使用提取的已知条件进行验证**\n-   **科学上是合理的：** 该问题是随机优化算法（特别是 SGD）分析中的一个标准、基础的练习。该设定是教科书和研究论文中用于理解 SGD 收敛性质的典型模型。\n-   **适定的：** 该问题是适定的。所有变量和参数都有清晰的定义，并且对它们的约束（例如 $\\alpha \\in (0, \\frac{1}{2})$）也已指明。任务是精确的数学目标，会导向唯一的答案。\n-   **客观性：** 该问题以精确、形式化的数学语言陈述，没有歧义或主观陈述。\n\n**步骤 3：结论与行动**\n该问题是有效的，因为它在科学上是合理的、适定的且客观的。我将继续进行解答。\n\n### 第 1 部分：推导 $\\mathbb{E}[x_{t+1}^2]$ 的递推关系\n\n我们从 SGD 更新规则开始：\n$$\nx_{t+1} = x_t - \\eta_t g_t\n$$\n代入随机梯度的表达式 $g_t = x_t + \\xi_t$：\n$$\nx_{t+1} = x_t - \\eta_t (x_t + \\xi_t) = (1 - \\eta_t)x_t - \\eta_t \\xi_t\n$$\n接下来，我们将方程两边平方：\n$$\nx_{t+1}^2 = \\left( (1 - \\eta_t)x_t - \\eta_t \\xi_t \\right)^2 = (1 - \\eta_t)^2 x_t^2 - 2(1 - \\eta_t)\\eta_t x_t \\xi_t + \\eta_t^2 \\xi_t^2\n$$\n现在，我们对两边取期望。令 $\\mathcal{F}_t$ 是由截至时间 t 的过程历史生成的 σ-代数，即 $\\sigma(x_0, \\xi_0, \\dots, \\xi_{t-1})$。迭代量 $x_t$ 关于 $\\mathcal{F}_t$ 是可测的。我们使用全期望定律，$\\mathbb{E}[Y] = \\mathbb{E}[\\mathbb{E}[Y | \\mathcal{F}_t]]$。\n$$\n\\mathbb{E}[x_{t+1}^2] = \\mathbb{E}\\left[ (1 - \\eta_t)^2 x_t^2 - 2(1 - \\eta_t)\\eta_t x_t \\xi_t + \\eta_t^2 \\xi_t^2 \\right]\n$$\n根据期望的线性性质：\n$$\n\\mathbb{E}[x_{t+1}^2] = (1 - \\eta_t)^2 \\mathbb{E}[x_t^2] - 2(1 - \\eta_t)\\eta_t \\mathbb{E}[x_t \\xi_t] + \\eta_t^2 \\mathbb{E}[\\xi_t^2]\n$$\n我们计算涉及噪声 $\\xi_t$ 的期望项。\n对于交叉项 $\\mathbb{E}[x_t \\xi_t]$，我们以过去为条件：\n$$\n\\mathbb{E}[x_t \\xi_t] = \\mathbb{E}[\\mathbb{E}[x_t \\xi_t | \\mathcal{F}_t]] = \\mathbb{E}[x_t \\mathbb{E}[\\xi_t | \\mathcal{F}_t]]\n$$\n因为 $\\xi_t$ 与过去无关，所以 $\\mathbb{E}[\\xi_t | \\mathcal{F}_t] = \\mathbb{E}[\\xi_t] = 0$。因此：\n$$\n\\mathbb{E}[x_t \\xi_t] = \\mathbb{E}[x_t \\cdot 0] = 0\n$$\n对于噪声方差项，我们已知 $\\mathbb{E}[\\xi_t]=0$ 和 $\\mathrm{Var}(\\xi_t)=\\sigma^2$，所以：\n$$\n\\mathbb{E}[\\xi_t^2] = \\mathrm{Var}(\\xi_t) + (\\mathbb{E}[\\xi_t])^2 = \\sigma^2 + 0^2 = \\sigma^2\n$$\n将这些结果代回关于 $\\mathbb{E}[x_{t+1}^2]$ 的方程中：\n$$\n\\mathbb{E}[x_{t+1}^2] = (1 - \\eta_t)^2 \\mathbb{E}[x_t^2] + \\eta_t^2 \\sigma^2\n$$\n展开平方项 $(1-\\eta_t)^2 = 1 - 2\\eta_t + \\eta_t^2$，我们得到最终的封闭递推关系：\n$$\n\\mathbb{E}[x_{t+1}^2] = (1 - 2\\eta_t + \\eta_t^2) \\mathbb{E}[x_t^2] + \\eta_t^2 \\sigma^2\n$$\n\n### 第 2 部分：$\\mathbb{E}[x_t^2]$ 的渐近分析\n\n令 $w_t = \\mathbb{E}[x_t^2]$。递推关系为：\n$$\nw_{t+1} = (1 - 2\\eta_t + \\eta_t^2) w_t + \\eta_t^2 \\sigma^2\n$$\n这可以改写为一个差分方程：\n$$\nw_{t+1} - w_t = (-2\\eta_t + \\eta_t^2) w_t + \\eta_t^2 \\sigma^2\n$$\n问题指出步长序列 $\\eta_t = \\eta_0 t^{-\\alpha}$ 是“缓慢变化的”。这为进行准静态分析提供了依据。在这种体系下，系统的状态 $w_t$ 会快速适应参数 $\\eta_t$ 的缓慢变化。因此，我们可以通过找到动力系统的“移动不动点”来近似其渐近行为，这对应于将变化量 $w_{t+1} - w_t$ 设为零。\n$$\n0 \\approx (-2\\eta_t + \\eta_t^2) w_t + \\eta_t^2 \\sigma^2\n$$\n求解 $w_t$：\n$$\n(2\\eta_t - \\eta_t^2) w_t \\approx \\eta_t^2 \\sigma^2\n$$\n$$\nw_t \\approx \\frac{\\eta_t^2 \\sigma^2}{2\\eta_t - \\eta_t^2} = \\frac{\\eta_t \\sigma^2}{2 - \\eta_t}\n$$\n该表达式描述了问题中提到的“瞬时噪声地板”。它代表了一个平衡水平，在此水平上，向原点的漂移（由项 $-2\\eta_t w_t$ 引起）与随机噪声引入的方差（项 $\\eta_t^2 \\sigma^2$）以及高阶自校正项 $\\eta_t^2 w_t$ 相平衡。\n\n当 $t \\to \\infty$ 时，由于 $\\alpha  0$，我们有 $\\eta_t = \\eta_0 t^{-\\alpha} \\to 0$。因此，分母 $2 - \\eta_t \\to 2$。$\\mathbb{E}[x_t^2]$ 的主阶渐近行为是：\n$$\nw_t = \\mathbb{E}[x_t^2] \\sim \\frac{\\eta_t \\sigma^2}{2} = \\frac{\\eta_0 \\sigma^2}{2} t^{-\\alpha}\n$$\n条件 $\\alpha \\in (0, 1/2)$ 保证了步长是不可和的，$\\sum \\eta_t = \\infty$，但不是平方可和的。前一个条件是收敛到目标函数最小值所必需的，而后者（平方可和）是方差消失所需要的。在这里，由于 $\\alpha \\le 1/2$，$\\sum_t \\eta_t^2 = \\eta_0^2 \\sum_t t^{-2\\alpha}$ 发散（因为 $2\\alpha \\le 1$），导致一个以 $\\eta_t$ 速率衰减的不消失的误差下限。我们的渐近分析精确地捕捉到了这个下限的量级。\n\n### 第 3 部分：计算缩放极限 $L$\n\n我们需要计算缩放极限的精确值：\n$$\nL = \\lim_{t \\to \\infty} \\frac{t^{\\alpha}\\,\\mathbb{E}[x_t^2]}{\\eta_0 \\sigma^2}\n$$\n使用第 2 部分中关于 $\\mathbb{E}[x_t^2] = w_t$ 的渐近结果，我们将更精确的表达式 $w_t \\approx \\frac{\\eta_t \\sigma^2}{2 - \\eta_t}$ 代入极限中。\n$$\nL = \\lim_{t \\to \\infty} \\frac{t^{\\alpha} \\left( \\frac{\\eta_t \\sigma^2}{2 - \\eta_t} \\right)}{\\eta_0 \\sigma^2}\n$$\n现在，代入步长的定义 $\\eta_t = \\eta_0 t^{-\\alpha}$：\n$$\nL = \\lim_{t \\to \\infty} \\frac{t^{\\alpha} \\left( \\frac{(\\eta_0 t^{-\\alpha}) \\sigma^2}{2 - \\eta_0 t^{-\\alpha}} \\right)}{\\eta_0 \\sigma^2}\n$$\n分子中的项 $t^{\\alpha}$ 和 $t^{-\\alpha}$ 相互抵消：\n$$\nL = \\lim_{t \\to \\infty} \\frac{\\frac{\\eta_0 \\sigma^2}{2 - \\eta_0 t^{-\\alpha}}}{\\eta_0 \\sigma^2}\n$$\n我们可以消去公因子 $\\eta_0 \\sigma^2$：\n$$\nL = \\lim_{t \\to \\infty} \\frac{1}{2 - \\eta_0 t^{-\\alpha}}\n$$\n由于 $\\alpha  0$，当 $t \\to \\infty$ 时，项 $t^{-\\alpha} \\to 0$。因此，极限为：\n$$\nL = \\frac{1}{2 - 0} = \\frac{1}{2}\n$$\n极限值是一个常数，与 $\\eta_0$、$\\sigma^2$ 和 $\\alpha$ 无关（在指定范围内）。这证实了对于 $\\alpha \\le 1/2$，归一化误差 $\\frac{\\mathbb{E}[x_t^2]}{\\eta_t \\sigma^2}$ 收敛到一个非零常数。", "answer": "$$\n\\boxed{\\frac{1}{2}}\n$$", "id": "3185967"}, {"introduction": "最后的练习将综合前面所学的概念，解决一个更接近实际应用的步长策略设计问题。现代深度学习常采用复杂的多阶段策略，如“预热-平稳-衰减”（warmup-plateau-decay），而非简单的幂律衰减。本练习 [@problem_id:3185881] 要求你分析这样一种策略，并通过优化其关键参数，来平衡训练初期快速降低偏差和训练末期控制方差累积的需求。", "problem": "考虑将一维随机梯度下降 (SGD, Stochastic Gradient Descent) 应用于带有加性梯度噪声的二次目标函数 $f(x) = \\frac{1}{2} x^{2}$。其离散时间更新为\n$$\nx_{t+1} = x_{t} - \\eta_{t} \\bigl( x_{t} + \\xi_{t} \\bigr),\n$$\n其中 $\\{\\xi_{t}\\}$ 是一个独立序列，满足 $\\mathbb{E}[\\xi_{t}] = 0$ 和 $\\operatorname{Var}(\\xi_{t}) = \\sigma^{2}$，而 $\\{\\eta_{t}\\}$ 是一个非负步长方案。设时间范围为 $T = w + p + d$，其中 $w  0$，$p  0$ 且 $d  0$。考虑以下在连续时间下的分段线性步长方案 $\\eta(t)$：\n- 在 $t \\in [0,w]$ 上预热：$\\eta(t) = \\eta_{\\max} \\frac{t}{w}$。\n- 在 $t \\in (w, w + p]$ 上平稳：$\\eta(t) = \\eta_{\\max}$。\n- 在 $t \\in (w + p, w + p + d]$ 上线性衰减：$\\eta(t) = \\eta_{\\max} \\left( 1 - \\frac{t - (w + p)}{d} \\right)$。\n\n假设 $x_{t}$ 二阶矩的小步长连续时间近似是有效的，并通过简化的偏差-方差表达式来建模期望最终平方误差\n$$\n\\mathbb{E}\\bigl[x(T)^{2}\\bigr] \\approx x_{0}^{2} \\exp\\!\\left( - 2 \\int_{0}^{T} \\eta(t) \\, dt \\right) + \\sigma^{2} \\int_{0}^{T} \\eta(t)^{2} \\, dt,\n$$\n其中 $x_{0}$ 是确定性初始条件。\n\n仅使用 SGD 的基本定义和给定的噪声模型，从第一性原理推导出上述表达式，然后在保持 $w$、$p$、$d$、$x_{0}$ 和 $\\sigma$ 固定的情况下，对平稳阶段水平 $\\eta_{\\max}$ 进行最小化。将您的最终答案表示为关于 $w$、$p$、$d$、$x_{0}$ 和 $\\sigma$ 的最优 $\\eta_{\\max}$ 的单个闭式解析表达式。无需四舍五入。", "solution": "该问题要求完成两个主要任务：首先，推导给定的一维随机梯度下降 (SGD) 过程的期望最终平方误差的简化表达式；其次，对于一个特定的分段线性方案，就峰值步长 $\\eta_{\\max}$ 对该误差进行最小化。\n\n### 第1部分：误差模型的推导\n\n我们被要求推导期望最终平方误差 $\\mathbb{E}[x(T)^2]$ 的以下表达式：\n$$\n\\mathbb{E}\\bigl[x(T)^{2}\\bigr] \\approx x_{0}^{2} \\exp\\!\\left( - 2 \\int_{0}^{T} \\eta(t) \\, dt \\right) + \\sigma^{2} \\int_{0}^{T} \\eta(t)^{2} \\, dt\n$$\n推导从目标函数 $f(x) = \\frac{1}{2}x^2$ 的离散时间 SGD 更新规则开始，其梯度为 $\\nabla f(x) = x$。随机梯度为 $g(x_t, \\xi_t) = x_t + \\xi_t$。\n更新规则为：\n$$\nx_{t+1} = x_{t} - \\eta_{t} (x_{t} + \\xi_{t}) = (1 - \\eta_{t})x_{t} - \\eta_{t}\\xi_{t}\n$$\n其中 $\\xi_t$ 是一个噪声项，满足 $\\mathbb{E}[\\xi_t] = 0$ 且 $\\operatorname{Var}(\\xi_t) = \\sigma^2$。\n\n我们将均方误差分解为其偏差和方差分量：\n$$\n\\mathbb{E}[x_T^2] = \\left(\\mathbb{E}[x_T]\\right)^2 + \\operatorname{Var}(x_T)\n$$\n\n**1. 偏差项分析：**\n首先，我们找出 $x_t$ 均值的演化。令 $y_t = \\mathbb{E}[x_t]$。对更新规则取期望：\n$$\n\\mathbb{E}[x_{t+1}] = \\mathbb{E}[(1 - \\eta_{t})x_{t} - \\eta_{t}\\xi_{t}]\n$$\n由于 $\\xi_t$ 与 $x_t$ 独立且均值为零，$\\mathbb{E}[\\eta_t \\xi_t] = \\eta_t \\mathbb{E}[\\xi_t] = 0$。\n$$\ny_{t+1} = (1 - \\eta_{t}) y_{t}\n$$\n在小步长、连续时间极限下（$\\eta_t \\to 0$，$t$ 变为连续变量），这个递推关系可以近似为一个微分方程。设 $y(t)$ 是 $y_t$ 的连续时间对应物。变化量 $y_{t+1} - y_t$ 对应于导数 $\\frac{dy}{dt}$。\n$$\ny_{t+1} - y_t = -\\eta_t y_t \\implies \\frac{dy}{dt} = -\\eta(t) y(t)\n$$\n这是一个一阶线性常微分方程。在初始条件 $y(0) = \\mathbb{E}[x_0] = x_0$（因为 $x_0$ 是确定性的）下，解为：\n$$\ny(T) = x_0 \\exp\\left(-\\int_0^T \\eta(t) dt\\right)\n$$\n因此，在时间 $T$ 的偏差平方为：\n$$\n\\left(\\mathbb{E}[x_T]\\right)^2 = x_0^2 \\exp\\left(-2\\int_0^T \\eta(t) dt\\right)\n$$\n这与给定表达式中的第一项相匹配。\n\n**2. 方差项分析：**\n第二项代表累积方差。项 $\\sigma^2 \\int_0^T \\eta(t)^2 dt$ 是方差的一个简化模型。严格的推导会得到一个更复杂的表达式，$\\sigma^2 \\int_0^T \\eta(t)^2 \\exp(-2\\int_t^T \\eta(s)ds) dt$。问题中给出的表达式是一个常见的简化，其理由如下：\n在每个离散步骤 $t$，更新会增加一个噪声项 $-\\eta_t \\xi_t$。该项的方差为：\n$$\n\\operatorname{Var}(-\\eta_t \\xi_t) = \\eta_t^2 \\operatorname{Var}(-\\xi_t) = \\eta_t^2 \\operatorname{Var}(\\xi_t) = \\eta_t^2 \\sigma^2\n$$\n时间 $T$ 的总方差的简化模型假设最终方差是每一步引入的方差的简单加和，忽略了动力学对先前累积方差的收缩效应。当步长 $\\eta_t$ 很小，以至于系统状态不会发生剧烈变化时，这种近似最准确。\n在这个简化假设下，总方差是增量贡献的总和：\n$$\n\\operatorname{Var}(x_T) \\approx \\sum_{t=0}^{T-1} \\eta_t^2 \\sigma^2\n$$\n在连续时间极限下，这个和变成一个积分：\n$$\n\\operatorname{Var}(x_T) \\approx \\sigma^2 \\int_0^T \\eta(t)^2 dt\n$$\n这与给定表达式中的第二项相匹配。\n\n**3. 合并项：**\n将推导出的偏差平方和简化的方差结合起来，得到期望最终平方误差的所需表达式：\n$$\n\\mathbb{E}[x(T)^2] \\approx x_0^2 \\exp\\left(-2\\int_0^T \\eta(t) dt\\right) + \\sigma^2 \\int_0^T \\eta(t)^2 dt\n$$\n这就完成了模型的推导。\n\n### 第2部分：误差的最小化\n\n我们现在对 $\\eta_{\\max}$ 最小化 $\\mathbb{E}[x(T)^2]$ 的表达式。令 $E(\\eta_{\\max}) = \\mathbb{E}[x(T)^2]$。该表达式为：\n$$\nE(\\eta_{\\max}) = x_0^2 \\exp(-2 I_1) + \\sigma^2 I_2\n$$\n其中 $I_1 = \\int_0^T \\eta(t) dt$ 且 $I_2 = \\int_0^T \\eta(t)^2 dt$。我们首先为给定的分段线性方案 $\\eta(t)$ 计算这些积分。\n\n**$I_1$ 的计算：**\n$I_1 = \\int_0^w \\eta_{\\max} \\frac{t}{w} dt + \\int_w^{w+p} \\eta_{\\max} dt + \\int_{w+p}^{w+p+d} \\eta_{\\max} \\left( 1 - \\frac{t - (w+p)}{d} \\right) dt$。\n1.  预热阶段： $\\int_0^w \\eta_{\\max} \\frac{t}{w} dt = \\frac{\\eta_{\\max}}{w} \\left[\\frac{t^2}{2}\\right]_0^w = \\frac{1}{2} w \\eta_{\\max}$。\n2.  平稳阶段： $\\int_w^{w+p} \\eta_{\\max} dt = \\eta_{\\max} [t]_w^{w+p} = p \\eta_{\\max}$。\n3.  衰减阶段： $\\int_{w+p}^{w+p+d} \\eta_{\\max} \\left( 1 - \\frac{t - (w+p)}{d} \\right) dt = \\eta_{\\max} \\left[ t - \\frac{(t-(w+p))^2}{2d} \\right]_{w+p}^{w+p+d} = \\eta_{\\max} \\left( (w+p+d) - \\frac{d^2}{2d} - (w+p) \\right) = \\frac{1}{2} d \\eta_{\\max}$。\n各部分求和：\n$$\nI_1 = \\left(\\frac{w}{2} + p + \\frac{d}{2}\\right) \\eta_{\\max} = \\left(\\frac{w+d+2p}{2}\\right) \\eta_{\\max}\n$$\n\n**$I_2$ 的计算：**\n$I_2 = \\int_0^w \\left(\\eta_{\\max} \\frac{t}{w}\\right)^2 dt + \\int_w^{w+p} \\eta_{\\max}^2 dt + \\int_{w+p}^{w+p+d} \\left(\\eta_{\\max} \\left( 1 - \\frac{t - (w+p)}{d} \\right)\\right)^2 dt$。\n1.  预热阶段： $\\int_0^w \\frac{\\eta_{\\max}^2}{w^2} t^2 dt = \\frac{\\eta_{\\max}^2}{w^2} \\left[\\frac{t^3}{3}\\right]_0^w = \\frac{1}{3} w \\eta_{\\max}^2$。\n2.  平稳阶段： $\\int_w^{w+p} \\eta_{\\max}^2 dt = \\eta_{\\max}^2 [t]_w^{w+p} = p \\eta_{\\max}^2$。\n3.  衰减阶段： 令 $u=t-(w+p)$。$\\int_0^d \\eta_{\\max}^2 (1-\\frac{u}{d})^2 du = \\eta_{\\max}^2 \\left[u - \\frac{u^2}{d} + \\frac{u^3}{3d^2}\\right]_0^d = \\eta_{\\max}^2 \\left(d - d + \\frac{d}{3}\\right) = \\frac{1}{3} d \\eta_{\\max}^2$。\n各部分求和：\n$$\nI_2 = \\left(\\frac{w}{3} + p + \\frac{d}{3}\\right) \\eta_{\\max}^2 = \\left(\\frac{w+d+3p}{3}\\right) \\eta_{\\max}^2\n$$\n\n令 $C_1 = \\frac{w+d+2p}{2}$ 和 $C_2 = \\frac{w+d+3p}{3}$。目标函数变为：\n$$\nE(\\eta_{\\max}) = x_0^2 \\exp(-2 C_1 \\eta_{\\max}) + \\sigma^2 C_2 \\eta_{\\max}^2\n$$\n为了找到最小值，我们对 $\\eta_{\\max}$ 求导并令其为零。为简单起见，令 $y = \\eta_{\\max}$。\n$$\n\\frac{dE}{dy} = x_0^2 (-2C_1) \\exp(-2C_1 y) + \\sigma^2 C_2 (2y) = 0\n$$\n$$\n2 \\sigma^2 C_2 y = 2 C_1 x_0^2 \\exp(-2C_1 y)\n$$\n$$\ny \\exp(2C_1 y) = \\frac{C_1 x_0^2}{\\sigma^2 C_2}\n$$\n这是一个超越方程，可以使用 Lambert W 函数求解，其定义为 $z = W(z) \\exp(W(z))$。为了匹配这种形式，令 $z = 2C_1 y$。那么 $y = z/(2C_1)$。\n$$\n\\frac{z}{2C_1} \\exp(z) = \\frac{C_1 x_0^2}{\\sigma^2 C_2}\n$$\n$$\nz \\exp(z) = \\frac{2 C_1^2 x_0^2}{\\sigma^2 C_2}\n$$\n$z$ 的解是 $z = W\\left(\\frac{2 C_1^2 x_0^2}{\\sigma^2 C_2}\\right)$，其中 $W$ 是 Lambert W 函数的主分支，因为其参数是非负的（$w, p, d  0$ 意味着 $C_1, C_2  0$）。\n\n二阶导数 $\\frac{d^2E}{dy^2} = 4C_1^2 x_0^2 \\exp(-2C_1y) + 2\\sigma^2 C_2$ 对于 $y0$ 恒为正，确认了这是一个最小值。\n\n代回 $y = \\eta_{\\max}$ 和 $z=2C_1 \\eta_{\\max}$：\n$$\n\\eta_{\\max} = \\frac{z}{2C_1} = \\frac{1}{2C_1} W\\left(\\frac{2 C_1^2 x_0^2}{\\sigma^2 C_2}\\right)\n$$\n最后，我们代入 $C_1$ 和 $C_2$ 的表达式：\n$$\n\\eta_{\\max} = \\frac{1}{2\\left(\\frac{w+d+2p}{2}\\right)} W\\left(\\frac{2 \\left(\\frac{w+d+2p}{2}\\right)^2 x_0^2}{\\sigma^2 \\left(\\frac{w+d+3p}{3}\\right)}\\right)\n$$\n$$\n\\eta_{\\max} = \\frac{1}{w+d+2p} W\\left(\\frac{2 \\frac{(w+d+2p)^2}{4} x_0^2}{\\frac{\\sigma^2(w+d+3p)}{3}}\\right)\n$$\n$$\n\\eta_{\\max} = \\frac{1}{w+d+2p} W\\left(\\frac{\\frac{(w+d+2p)^2}{2} x_0^2}{\\frac{\\sigma^2(w+d+3p)}{3}}\\right)\n$$\n化简 Lambert W 函数的参数，得到最终结果：\n$$\n\\eta_{\\max} = \\frac{1}{w+d+2p} W\\left(\\frac{3 x_0^2 (w+d+2p)^2}{2 \\sigma^2 (w+d+3p)}\\right)\n$$\n这就是最优 $\\eta_{\\max}$ 的闭式解析表达式。", "answer": "$$\n\\boxed{\\frac{1}{w+d+2p} W\\left(\\frac{3 x_0^2 (w+d+2p)^2}{2 \\sigma^2 (w+d+3p)}\\right)}\n$$", "id": "3185881"}]}