{"hands_on_practices": [{"introduction": "为了有效使用交替方向乘子法（ADMM），你必须首先掌握如何求解其核心子问题。本次初级练习聚焦于最基础的情形：当其中一个目标函数是简单的二次项时，这种情况在最小二乘和正则化问题中频繁出现。通过推导变量 $x$ 的闭式更新法则，你将应用基本的微积分和线性代数知识，从而理解一个复杂的全局问题是如何分解为可管理的、能够解析求解的步骤的。", "problem": "交替方向乘子法 (ADMM) 是一种求解以下形式优化问题的算法：\n$$ \\min_{x, z} f(x) + g(z) $$\n$$ \\text{subject to } Ax + Bz = b $$\n其中变量为 $x \\in \\mathbb{R}^n$ 和 $z \\in \\mathbb{R}^m$，问题数据由矩阵 $A \\in \\mathbb{R}^{p \\times n}$、$B \\in \\mathbb{R}^{p \\times m}$、向量 $b \\in \\mathbb{R}^p$ 以及凸函数 $f: \\mathbb{R}^n \\to \\mathbb{R}$ 和 $g: \\mathbb{R}^m \\to \\mathbb{R}$ 给出。\n\n该算法基于增广拉格朗日量：\n$$ L_\\rho(x, z, y) = f(x) + g(z) + y^T(Ax + Bz - b) + \\frac{\\rho}{2}\\|Ax + Bz - b\\|_2^2 $$\n其中 $y \\in \\mathbb{R}^p$ 是对偶变量（或拉格朗日乘子），$\\rho > 0$ 是一个惩罚参数。在每次迭代 $k$ 中，ADMM 顺序执行以下更新：\n1.  $x^{k+1} := \\arg\\min_x L_\\rho(x, z^k, y^k)$\n2.  $z^{k+1} := \\arg\\min_z L_\\rho(x^{k+1}, z, y^k)$\n3.  $y^{k+1} := y^k + \\rho(Ax^{k+1} + Bz^{k+1} - b)$\n\n考虑该问题的一个具体实例，其中函数 $f(x)$ 定义为一个二次函数：\n$$ f(x) = \\frac{1}{2}\\|x - c\\|_2^2 $$\n对于一个给定的常数向量 $c \\in \\mathbb{R}^n$。\n\n推导 $x$-更新步骤 $x^{k+1}$ 的一个闭式解析表达式。您的表达式应以问题数据 $A, B, b, c$、惩罚参数 $\\rho$ 以及前一次迭代的值 $z^k$ 和 $y^k$ 来表示。在您的推导中，令 $I$ 表示 $n \\times n$ 的单位矩阵，并假设矩阵 $(I + \\rho A^T A)$ 是可逆的。", "solution": "我们通过将 $z^k$ 和 $y^k$ 保持固定，最小化关于 $x$ 的增广拉格朗日量来推导 $x$-更新。$x$-子问题是\n$$\nx^{k+1} := \\arg\\min_{x}\\left\\{\\frac{1}{2}\\|x-c\\|_{2}^{2} + (y^{k})^{T}(Ax + B z^{k} - b) + \\frac{\\rho}{2}\\|Ax + B z^{k} - b\\|_{2}^{2}\\right\\}.\n$$\n定义 $d := B z^{k} - b$，则目标函数变为\n$$\n\\frac{1}{2}\\|x-c\\|_{2}^{2} + (y^{k})^{T}(A x + d) + \\frac{\\rho}{2}\\|A x + d\\|_{2}^{2}.\n$$\n与 $x$ 无关的项不影响最小值点，因此我们只关注与 $x$ 相关的部分。对 $x$ 求梯度并令其为零，得到\n$$\n\\nabla_{x}\\left(\\frac{1}{2}\\|x-c\\|_{2}^{2}\\right) + \\nabla_{x}\\left((y^{k})^{T}A x\\right) + \\nabla_{x}\\left(\\frac{\\rho}{2}\\|A x + d\\|_{2}^{2}\\right) = 0,\n$$\n简化为\n$$\n(x - c) + A^{T} y^{k} + \\rho A^{T}(A x + d) = 0.\n$$\n合并关于 $x$ 的项，得到\n$$\n\\left(I + \\rho A^{T}A\\right) x = c - A^{T} y^{k} - \\rho A^{T} d.\n$$\n代入 $d = B z^{k} - b$，我们有\n$$\n\\left(I + \\rho A^{T}A\\right) x = c - A^{T} y^{k} - \\rho A^{T}(B z^{k} - b).\n$$\n在 $\\left(I + \\rho A^{T}A\\right)$ 可逆的假设下，唯一的最小值点是\n$$\nx^{k+1} = \\left(I + \\rho A^{T}A\\right)^{-1}\\left(c - A^{T} y^{k} - \\rho A^{T}(B z^{k} - b)\\right).\n$$", "answer": "$$\\boxed{\\left(I+\\rho A^{T}A\\right)^{-1}\\left(c-A^{T}y^{k}-\\rho A^{T}\\left(Bz^{k}-b\\right)\\right)}$$", "id": "2153727"}, {"introduction": "ADMM 的一个关键优势在于它能将复杂的约束条件转化为更简单的几何运算。本次练习将探讨指示函数（代表一个硬性约束）如何将相应的 ADMM 子问题转变为一个到凸集上的欧几里得投影。理解这种联系对于将 ADMM 应用于信号处理和机器学习等领域至关重要，在这些领域中，解必须满足特定的可行集。", "problem": "考虑一个离散时间信号重构问题，其中估计值 $x \\in \\mathbb{R}^{n}$ 必须满足已知的凸约束，这些约束模拟了关于可行信号的先验知识。将该重构问题表述为如下分裂问题\n$$\n\\min_{x \\in \\mathbb{R}^{n},\\, z \\in \\mathbb{R}^{n}} \\; f(x) + g(z) \\quad \\text{subject to} \\quad x - z = 0,\n$$\n其中 $f:\\mathbb{R}^{n} \\to \\mathbb{R}$ 是一个真、闭、凸函数，用于编码信号模型的数据保真度和正则化，而 $g:\\mathbb{R}^{n} \\to \\mathbb{R} \\cup \\{+\\infty\\}$ 是一个非空、闭、凸集 $C \\subset \\mathbb{R}^{n}$ 的指示函数，定义为\n$$\ng(z) = \\begin{cases}\n0,  \\text{if } z \\in C,\\\\\n+\\infty,  \\text{if } z \\notin C.\n\\end{cases}\n$$\n将采用缩放形式的交替方向乘子法（ADMM）来解决此问题。令 $\\rho > 0$ 为罚参数，$u \\in \\mathbb{R}^{n}$ 表示缩放对偶变量。缩放增广拉格朗日量为\n$$\n\\mathcal{L}_{\\rho}(x,z,u) = f(x) + g(z) + \\frac{\\rho}{2}\\,\\|x - z + u\\|_{2}^{2} - \\frac{\\rho}{2}\\,\\|u\\|_{2}^{2}.\n$$\n点 $v \\in \\mathbb{R}^{n}$ 到集合 $C$ 上的欧几里得投影定义为\n$$\n\\Pi_{C}(v) := \\arg\\min_{z \\in C} \\;\\|z - v\\|_{2}.\n$$\n仅从这些定义出发，推导 ADMM 迭代中 $z$-更新的闭式表达式，\n$$\nz^{k+1} \\in \\arg\\min_{z \\in \\mathbb{R}^{n}} \\left\\{ g(z) + \\frac{\\rho}{2}\\,\\|x^{k+1} - z + u^{k}\\|_{2}^{2} \\right\\}.\n$$\n将您的最终结果明确表示为某个仿射宗量在 $C$ 上的欧几里得投影。您的最终答案必须是仅包含 $\\Pi_{C}$、$x^{k+1}$ 和 $u^{k}$ 的单个符号表达式。最终答案中不要包含任何等号。不需要进行数值近似，也不涉及任何单位。", "solution": "我们从问题结构和缩放增广拉格朗日量开始。问题是\n$$\n\\min_{x,z} \\; f(x) + g(z) \\quad \\text{subject to} \\quad x - z = 0,\n$$\n其中 $g$ 是一个非空、闭、凸集 $C \\subset \\mathbb{R}^{n}$ 的指示函数。在缩放形式的交替方向乘子法（ADMM）中，我们交替地最小化缩放增广拉格朗日量\n$$\n\\mathcal{L}_{\\rho}(x,z,u) = f(x) + g(z) + \\frac{\\rho}{2}\\,\\|x - z + u\\|_{2}^{2} - \\frac{\\rho}{2}\\,\\|u\\|_{2}^{2}\n$$\n关于 $x$ 和 $z$ 进行最小化，然后更新 $u$。我们关注 $z$-更新，对于固定的 $x^{k+1}$ 和 $u^{k}$，其表达式为\n$$\nz^{k+1} \\in \\arg\\min_{z \\in \\mathbb{R}^{n}} \\left\\{ g(z) + \\frac{\\rho}{2}\\,\\|x^{k+1} - z + u^{k}\\|_{2}^{2} \\right\\}.\n$$\n根据指示函数 $g$ 的定义，在 $z \\in \\mathbb{R}^{n}$ 上最小化 $g(z)$ 加上任何其他函数，等价于在约束 $z \\in C$ 下最小化另一个函数。因此，$z$-更新简化为约束二次最小化问题\n$$\nz^{k+1} \\in \\arg\\min_{z \\in C} \\;\\frac{\\rho}{2}\\,\\|x^{k+1} - z + u^{k}\\|_{2}^{2}.\n$$\n由于 $\\rho > 0$ 是一个正常数，它不改变最小化子的位置。因此，等价地有\n$$\nz^{k+1} \\in \\arg\\min_{z \\in C} \\;\\|x^{k+1} - z + u^{k}\\|_{2}^{2}.\n$$\n我们重写平方范数，以将其表示为投影目标：\n$$\n\\|x^{k+1} - z + u^{k}\\|_{2}^{2} = \\|z - (x^{k+1} + u^{k})\\|_{2}^{2}.\n$$\n因此，\n$$\nz^{k+1} \\in \\arg\\min_{z \\in C} \\;\\|z - (x^{k+1} + u^{k})\\|_{2}^{2}.\n$$\n根据到非空、闭、凸集 $C$ 上的欧几里得投影的定义，最小化子是点 $x^{k+1} + u^{k}$ 在 $C$ 上的投影。特别地，由于 $C$ 是非空、闭且凸的，该投影是唯一确定的，我们有\n$$\nz^{k+1} = \\Pi_{C}\\!\\big(x^{k+1} + u^{k}\\big).\n$$\n这就将 $z$-更新以闭式形式表示为仿射宗量 $x^{k+1} + u^{k}$ 在凸集 $C$ 上的欧几里得投影，这是直接从指示函数、缩放增广拉格朗日量和欧几里得投影的定义推导出来的。", "answer": "$$\\boxed{\\Pi_{C}\\!\\left(x^{k+1} + u^{k}\\right)}$$", "id": "2852062"}, {"introduction": "本次综合练习将前面学习到的概念整合到一个重要的实际应用中。你将亲自推导著名的基追踪（basis pursuit）问题的 ADMM 更新规则，并完成一次完整的数值迭代，从而将抽象的理论转化为具体的计算。通过解决这个问题，你将看到 ADMM 如何将一个复杂问题分解为两种核心操作——仿射集投影和软阈值算子，这是理解该算法在稀疏恢复等领域强大能力的关键。", "problem": "考虑基追踪问题，即通过求解凸规划 $\\min_{x} \\|x\\|_{1}$ 约束为 $A x = b$ 来寻找一个稀疏向量。引入一个副本变量 $z$ 和约束 $x=z$，将问题重写为在 $x=z$ 的约束下最小化 $\\|z\\|_{1} + \\mathcal{I}_{\\{x: A x = b\\}}(x)$，其中 $\\mathcal{I}_{\\{x: A x = b\\}}$ 是仿射集 $\\{x: A x = b\\}$ 的指示函数。使用交替方向乘子法 (ADMM)，从增广拉格朗日量的定义和交替最小化的第一性原理出发，推导 $x$、$z$ 和缩放对偶变量 $u$ 的缩放形式更新规则。明确指出出现的近端算子。\n\n然后，将您的推导应用于以下具体实例。设 $A \\in \\mathbb{R}^{2 \\times 3}$ 和 $b \\in \\mathbb{R}^{2}$ 为\n$$\nA = \\begin{pmatrix}\n1  1  0 \\\\\n0  1  1\n\\end{pmatrix}, \\quad\nb = \\begin{pmatrix}\n1 \\\\\n1\n\\end{pmatrix}.\n$$\n假设惩罚参数 $\\rho$ 为 $\\rho = 2$，分裂变量的初始迭代值为 $z^{0} = \\begin{pmatrix} 0.8 \\\\ 0.4 \\\\ 0.1 \\end{pmatrix}$，以及初始缩放对偶变量为 $u^{0} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}$。计算一次完整的 ADMM 迭代，并精确报告更新后的 $x^{1}$。\n\n最后，假设传感矩阵 $A$ 满足限制等距性质 (RIP)，其常数足够小以确保 $A x^{\\star} = b$ 的 $s$-稀疏解 $x^{\\star}$ 的唯一性（例如，一个阶数为 $2s$ 的 RIP，其常数小到足以保证基追踪能够精确恢复），根据凸问题的 ADMM 收敛理论，解释为什么精确稀疏恢复不依赖于 $\\rho$ 的值（只要 $\\rho > 0$），并阐明 $\\rho$ 如何影响收敛速度和数值稳定性。\n\n您最终报告的答案必须是使用 $\\texttt{pmatrix}$ 环境写成的单个 $x^{1}$ 行向量表达式。无需进行四舍五入。", "solution": "基追踪问题被表述为通过求解以下凸优化规划来寻找一个稀疏向量 $x$：\n$$\n\\min_{x} \\|x\\|_{1} \\quad \\text{subject to} \\quad A x = b\n$$\n为了应用交替方向乘子法 (ADMM)，我们引入一个分裂变量 $z$ 和一个辅助约束 $x=z$。问题被重写为等价形式：\n$$\n\\min_{x, z} f(x) + g(z) \\quad \\text{subject to} \\quad x - z = 0\n$$\n其中 $f(x) = \\mathcal{I}_{\\{x: A x = b\\}}(x)$ 且 $g(z) = \\|z\\|_{1}$。函数 $\\mathcal{I}_{\\{x: A x = b\\}}(x)$ 是仿射集 $\\{x \\in \\mathbb{R}^n: A x = b\\}$ 的指示函数，如果 $A x = b$，则其值为 $0$，否则为 $+\\infty$。\n\n该问题的增广拉格朗日量为：\n$$\nL_{\\rho}(x, z, y) = f(x) + g(z) + y^T(x - z) + \\frac{\\rho}{2}\\|x - z\\|_{2}^{2}\n$$\n这里，$y$ 是拉格朗日乘子（或对偶变量），$\\rho > 0$ 是惩罚参数。ADMM 的缩放形式使用一个缩放对偶变量 $u = (1/\\rho)y$，这简化了更新步骤。用 $u$ 表示的增广拉格朗日量可以通过配方法写出：\n$$\nL_{\\rho}(x, z, u) = f(x) + g(z) + \\rho u^T(x - z) + \\frac{\\rho}{2}\\|x - z\\|_{2}^{2} = f(x) + g(z) + \\frac{\\rho}{2}\\|x - z + u\\|_{2}^{2} - \\frac{\\rho}{2}\\|u\\|_{2}^{2}\n$$\nADMM 算法包含三个步骤，在每一步 $k$ 进行迭代：\n1. $x$-最小化: $x^{k+1} = \\arg\\min_{x} L_{\\rho}(x, z^k, u^k)$\n2. $z$-最小化: $z^{k+1} = \\arg\\min_{z} L_{\\rho}(x^{k+1}, z, u^k)$\n3. 对偶更新: $u^{k+1} = u^k + x^{k+1} - z^{k+1}$\n\n我们现在推导 $x$ 和 $z$ 的具体更新规则。\n\n$x$-更新步骤为：\n$$\nx^{k+1} = \\arg\\min_{x} \\left( f(x) + g(z^k) + \\frac{\\rho}{2}\\|x - z^k + u^k\\|_{2}^{2} - \\frac{\\rho}{2}\\|u^k\\|_{2}^{2} \\right)\n$$\n由于 $g(z^k)$ 和 $\\|u^k\\|_2^2$ 相对于 $x$ 是常数，这等价于：\n$$\nx^{k+1} = \\arg\\min_{x} \\left( \\mathcal{I}_{\\{x: A x = b\\}}(x) + \\frac{\\rho}{2}\\|x - (z^k - u^k)\\|_{2}^{2} \\right)\n$$\n这个最小化问题等价于在仿射集 $\\{x : Ax=b\\}$ 中找到一个点 $x$，使其最接近点 $v^k = z^k - u^k$。这是一个将 $v^k$ 投影到该仿射集上的欧几里得投影。令 $\\Pi_{\\{x: Ax=b\\}}(\\cdot)$ 表示此投影算子。更新为：\n$$\nx^{k+1} = \\Pi_{\\{x: Ax=b\\}}(z^k - u^k)\n$$\n\n$z$-更新步骤为：\n$$\nz^{k+1} = \\arg\\min_{z} \\left( f(x^{k+1}) + g(z) + \\frac{\\rho}{2}\\|x^{k+1} - z + u^k\\|_{2}^{2} - \\frac{\\rho}{2}\\|u^k\\|_{2}^{2} \\right)\n$$\n由于 $f(x^{k+1})$ 和 $\\|u^k\\|_2^2$ 相对于 $z$ 是常数，这简化为：\n$$\nz^{k+1} = \\arg\\min_{z} \\left( \\|z\\|_{1} + \\frac{\\rho}{2}\\|z - (x^{k+1} + u^k)\\|_{2}^{2} \\right)\n$$\n这是 $\\ell_1$-范数的近端算子的定义。函数 $h$ 的近端算子定义为 $\\text{prox}_{\\lambda h}(v) = \\arg\\min_u (h(u) + \\frac{1}{2\\lambda}\\|u-v\\|_2^2)$。在我们的例子中，$h(z) = \\|z\\|_1$ 且 $\\frac{1}{2\\lambda} = \\frac{\\rho}{2}$，这意味着 $\\lambda = 1/\\rho$。$\\ell_1$-范数的近端算子是软阈值算子，记为 $S_{\\kappa}(\\cdot)$，其中 $\\kappa = 1/\\rho$。该算子逐分量作用：$(S_{\\kappa}(v))_i = \\text{sign}(v_i)\\max(|v_i| - \\kappa, 0)$。\n所以，$z$-更新为：\n$$\nz^{k+1} = S_{1/\\rho}(x^{k+1} + u^k)\n$$\n出现的近端算子是软阈值算子，也就是 $\\ell_1$ 范数的近端算子。\n\n对偶变量的更新保持不变：\n$$\nu^{k+1} = u^k + x^{k+1} - z^{k+1}\n$$\n\n接下来，我们使用给定数据实例化一次迭代：\n$A = \\begin{pmatrix} 1  1  0 \\\\ 0  1  1 \\end{pmatrix}$， $b = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$， $\\rho = 2$， $z^{0} = \\begin{pmatrix} 0.8 \\\\ 0.4 \\\\ 0.1 \\end{pmatrix}$， $u^{0} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}$。\n我们需要计算 $x^1$。第一步是 $x$-更新：\n$$\nx^1 = \\Pi_{\\{x: Ax=b\\}}(z^0 - u^0)\n$$\n令 $v^0 = z^0 - u^0 = \\begin{pmatrix} 0.8 \\\\ 0.4 \\\\ 0.1 \\end{pmatrix}$。对于一个行满秩矩阵 $A$，将点 $v$ 投影到仿射集 $\\{x : Ax=b\\}$ 的公式为 $x = v - A^T(AA^T)^{-1}(Av-b)$。\n我们首先计算矩阵 $AA^T$：\n$$\nAA^T = \\begin{pmatrix} 1  1  0 \\\\ 0  1  1 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 1  1 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} 1(1)+1(1)+0(0)  1(0)+1(1)+0(1) \\\\ 0(1)+1(1)+1(0)  0(0)+1(1)+1(1) \\end{pmatrix} = \\begin{pmatrix} 2  1 \\\\ 1  2 \\end{pmatrix}\n$$\n其逆矩阵为：\n$$\n(AA^T)^{-1} = \\frac{1}{(2)(2) - (1)(1)} \\begin{pmatrix} 2  -1 \\\\ -1  2 \\end{pmatrix} = \\frac{1}{3} \\begin{pmatrix} 2  -1 \\\\ -1  2 \\end{pmatrix}\n$$\n接下来，我们计算 $Av^0 - b$：\n$$\nAv^0 = \\begin{pmatrix} 1  1  0 \\\\ 0  1  1 \\end{pmatrix} \\begin{pmatrix} 0.8 \\\\ 0.4 \\\\ 0.1 \\end{pmatrix} = \\begin{pmatrix} 0.8+0.4 \\\\ 0.4+0.1 \\end{pmatrix} = \\begin{pmatrix} 1.2 \\\\ 0.5 \\end{pmatrix}\n$$\n$$\nAv^0 - b = \\begin{pmatrix} 1.2 \\\\ 0.5 \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 0.2 \\\\ -0.5 \\end{pmatrix}\n$$\n现在我们计算 $A^T(AA^T)^{-1}(Av^0-b)$：\n$$\n(AA^T)^{-1}(Av^0-b) = \\frac{1}{3} \\begin{pmatrix} 2  -1 \\\\ -1  2 \\end{pmatrix} \\begin{pmatrix} 0.2 \\\\ -0.5 \\end{pmatrix} = \\frac{1}{3} \\begin{pmatrix} 2(0.2) - (-0.5) \\\\ -0.2 + 2(-0.5) \\end{pmatrix} = \\frac{1}{3} \\begin{pmatrix} 0.4+0.5 \\\\ -0.2-1.0 \\end{pmatrix} = \\frac{1}{3} \\begin{pmatrix} 0.9 \\\\ -1.2 \\end{pmatrix} = \\begin{pmatrix} 0.3 \\\\ -0.4 \\end{pmatrix}\n$$\n$$\nA^T \\left( (AA^T)^{-1}(Av^0-b) \\right) = \\begin{pmatrix} 1  0 \\\\ 1  1 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 0.3 \\\\ -0.4 \\end{pmatrix} = \\begin{pmatrix} 0.3 \\\\ 0.3-0.4 \\\\ -0.4 \\end{pmatrix} = \\begin{pmatrix} 0.3 \\\\ -0.1 \\\\ -0.4 \\end{pmatrix}\n$$\n最后，我们计算 $x^1$：\n$$\nx^1 = v^0 - A^T(AA^T)^{-1}(Av^0-b) = \\begin{pmatrix} 0.8 \\\\ 0.4 \\\\ 0.1 \\end{pmatrix} - \\begin{pmatrix} 0.3 \\\\ -0.1 \\\\ -0.4 \\end{pmatrix} = \\begin{pmatrix} 0.8 - 0.3 \\\\ 0.4 - (-0.1) \\\\ 0.1 - (-0.4) \\end{pmatrix} = \\begin{pmatrix} 0.5 \\\\ 0.5 \\\\ 0.5 \\end{pmatrix}\n$$\n以分数形式表示，$x^1 = \\begin{pmatrix} 1/2 \\\\ 1/2 \\\\ 1/2 \\end{pmatrix}$。\n\n最后，我们讨论惩罚参数 $\\rho$ 的作用。\n凸问题的 ADMM 收敛理论保证了如果优化问题存在解，ADMM 的迭代序列将会收敛到一个解。具体到我们的问题，迭代序列 $(x^k, z^k)$ 将收敛到一个点对 $(x^*, z^*)$，使得 $x^*=z^*$ 是基追踪问题的一个最优解。问题陈述假设传感矩阵 $A$ 满足一个适当阶数和常数的限制等距性质 (RIP)。在此条件下，$Ax=b$ 的 $s$-稀疏解 $x^{\\star}$ 是唯一的，并且也是基追踪问题 $\\min \\|x\\|_1$ 约束为 $Ax=b$ 的唯一解。由于 ADMM 保证会收敛到这个凸问题的一个解，并且在 RIP 假设下该解是唯一的，所以无论参数 $\\rho$ 如何选择（只要 $\\rho > 0$），算法都将收敛到这个唯一的稀疏向量 $x^{\\star}$。极限点由问题的 Karush-Kuhn-Tucker (KKT) 最优性条件决定，而这些条件与 $\\rho$ 无关。\n\n然而，参数 $\\rho$ 在算法的收敛*速度*和数值行为中扮演着至关重要的角色。$\\rho$ 的选择决定了在最小化目标函数和满足一致性约束 $x=z$ 之间的平衡。\n- 如果 $\\rho$ 很大，增广拉格朗日量中对原始残差 $\\|x-z\\|_2^2$ 的惩罚会很高。这会迫使迭代值 $x^k$ 和 $z^k$ 彼此接近。然而，大的 $\\rho$ 意味着软阈值参数 $1/\\rho$ 很小。这导致在 $z$ 更新步骤中收缩量很小，从而减慢了使 $z$（以及 $x$）变得稀疏的进程，而这正是主要目标。\n- 如果 $\\rho$ 很小，对原始残差的惩罚就很低，允许 $x^k$ 和 $z^k$ 相距较远。软阈值参数 $1/\\rho$ 较大，导致在 $z$ 更新步骤中进行激进的阈值处理。这可以迅速将 $z$ 的许多分量驱动到零，从而在 $\\ell_1$ 目标上取得快速进展。然而，对 $x=z$ 约束的弱执行可能意味着迭代需要很长时间才能收敛到对原始问题可行的点（即满足 $x=z$ 和 $Ax=b$ 的点）。\n\n总而言之，这里存在一种权衡：$\\rho$ 平衡了最小化目标和满足约束。$\\rho$ 的最优选择（通常与问题相关）能带来最快的收敛速度。尽管任意正 $\\rho$ 都能保证最终收敛到正确的稀疏解（在 RIP 条件下），但一个糟糕的选择可能导致收敛极其缓慢，在实践中可能被误认为是数值不稳定或不收敛。子问题本身（一个投影和一个软阈值）的数值稳定性通常很好，因此 $\\rho$ 的主要影响在于整个算法的收敛速率。", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{1}{2}  \\frac{1}{2}  \\frac{1}{2} \\end{pmatrix}}\n$$", "id": "3096765"}]}