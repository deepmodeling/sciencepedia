{"hands_on_practices": [{"introduction": "我们首先深入剖析原始-对偶方法单次迭代的核心机制。这个练习将引导你使用牛顿法求解Karush-Kuhn-Tucker (KKT) 条件，从而完成一次搜索方向的基本计算。通过处理一个具体的二维示例，你将对仿射缩放步骤获得切实的理解，并亲眼见证它是如何致力于减小对偶间隙的。[@problem_id:3164522]", "problem": "考虑线性规划 (LP) 问题：在约束条件 $Ax=b$ 和 $x \\ge 0$ 下，最小化 $c^{\\top}x$。其中数据为 $A=\\begin{pmatrix}1  2\\end{pmatrix}$，$b=3$ 和 $c=\\begin{pmatrix}2 \\\\ 1\\end{pmatrix}$。在一个原始-对偶内点法中，假设您处于一个严格可行的原始-对偶点 $x^{(0)}=\\begin{pmatrix}1 \\\\ 1\\end{pmatrix}$，$y^{(0)}=0.25$。对偶松弛变量 $s^{(0)}$ 由对偶可行性条件 $A^{\\top}y^{(0)}+s^{(0)}=c$ 定义，因此 $s^{(0)}=\\begin{pmatrix}2 \\\\ 1\\end{pmatrix}-\\begin{pmatrix}1 \\\\ 2\\end{pmatrix}\\cdot 0.25$。\n\n从 Karush-Kuhn-Tucker (KKT) 条件及其在中心化参数为零时的预测（仿射伸缩）步的牛顿线性化出发，推导出预测方向 $(\\Delta x_{\\mathrm{aff}}, \\Delta y_{\\mathrm{aff}}, \\Delta s_{\\mathrm{aff}})$。然后，沿着步长为 $\\alpha \\ge 0$ 的射线 $x(\\alpha)=x^{(0)}+\\alpha\\,\\Delta x_{\\mathrm{aff}}$、$s(\\alpha)=s^{(0)}+\\alpha\\,\\Delta s_{\\mathrm{aff}}$，构建对偶间隙 $g(\\alpha)=x(\\alpha)^{\\top}s(\\alpha)$，并确定精确线搜索步长 $\\alpha^{\\star}$，该步长在保持严格正性 $x(\\alpha) > 0$ 和 $s(\\alpha) > 0$（逐分量）的约束下最小化 $g(\\alpha)$。同时，计算在到边界固定比例步长 $\\alpha=\\frac{1}{2}\\alpha_{\\max}$ 和 $\\alpha=\\frac{9}{10}\\alpha_{\\max}$ 处的对偶间隙，其中 $\\alpha_{\\max}$ 是保持 $x(\\alpha)$ 和 $s(\\alpha)$ 所有分量非负性的最大步长。\n\n将您最终报告的 $\\alpha^{\\star}$ 四舍五入至四位有效数字。无需单位。", "solution": "用户希望解决一个关于原始-对偶内点法的问题。\n\n### 步骤 1：问题验证\n我将首先验证问题陈述。\n\n#### 提取的已知条件\n- **LP 问题**：在约束 $Ax=b$ 和 $x \\ge 0$ 下最小化 $c^{\\top}x$。\n- **数据**：\n  - $A = \\begin{pmatrix}1  2\\end{pmatrix}$\n  - $b = 3$\n  - $c = \\begin{pmatrix}2 \\\\ 1\\end{pmatrix}$\n- **初始点**：\n  - 原始变量：$x^{(0)} = \\begin{pmatrix}1 \\\\ 1\\end{pmatrix}$\n  - 对偶变量：$y^{(0)} = 0.25$\n  - 对偶松弛变量：$s^{(0)}$ 由 $A^{\\top}y^{(0)} + s^{(0)} = c$ 定义。\n- **任务**：\n  1. 使用中心化参数为零，通过对 Karush-Kuhn-Tucker (KKT) 条件进行牛顿法，推导预测（仿射伸缩）方向 $(\\Delta x_{\\mathrm{aff}}, \\Delta y_{\\mathrm{aff}}, \\Delta s_{\\mathrm{aff}})$。\n  2. 定义搜索射线 $x(\\alpha) = x^{(0)} + \\alpha\\Delta x_{\\mathrm{aff}}$ 和 $s(\\alpha) = s^{(0)} + \\alpha\\Delta s_{\\mathrm{aff}}$。\n  3. 构建对偶间隙函数 $g(\\alpha) = x(\\alpha)^{\\top}s(\\alpha)$。\n  4. 找到在保持严格正性（$x(\\alpha) > 0$，$s(\\alpha) > 0$）的同时最小化 $g(\\alpha)$ 的步长 $\\alpha^{\\star}$。\n  5. 计算在步长 $\\alpha = \\frac{1}{2}\\alpha_{\\max}$ 和 $\\alpha = \\frac{9}{10}\\alpha_{\\max}$ 处的对偶间隙，其中 $\\alpha_{\\max}$ 是最大可行步长。\n  6. 报告四舍五入至四位有效数字的 $\\alpha^{\\star}$。\n\n#### 验证\n该问题设置在线性规划和内点法的标准数学框架内。我将检查所提供数据的自洽性。\n\n- **$x^{(0)}$ 的原始可行性**：\n  - $A x^{(0)} = \\begin{pmatrix}1  2\\end{pmatrix} \\begin{pmatrix}1 \\\\ 1\\end{pmatrix} = 1 \\cdot 1 + 2 \\cdot 1 = 3$。这与给定的 $b=3$ 相匹配。约束 $Ax=b$ 得到满足。\n  - $x^{(0)} = \\begin{pmatrix}1 \\\\ 1\\end{pmatrix} \\ge 0$。该条件得到满足。实际上，$x^{(0)} > 0$，所以它是一个严格可行的原始点。\n\n- **$y^{(0)}$ 的对偶可行性**：\n  - 对偶可行性约束为 $A^{\\top}y + s = c$。问题要求使用 $y^{(0)}$ 从此条件定义 $s^{(0)}$。\n  - $A^{\\top} = \\begin{pmatrix}1 \\\\ 2\\end{pmatrix}$。\n  - $s^{(0)} = c - A^{\\top}y^{(0)} = \\begin{pmatrix}2 \\\\ 1\\end{pmatrix} - \\begin{pmatrix}1 \\\\ 2\\end{pmatrix}(0.25) = \\begin{pmatrix}2 - 0.25 \\\\ 1 - 0.5\\end{pmatrix} = \\begin{pmatrix}1.75 \\\\ 0.5\\end{pmatrix}$。\n  - 我们必须检查是否 $s^{(0)} \\ge 0$。确实，所有分量都为正，因此 $(y^{(0)}, s^{(0)})$ 构成一个严格可行的对偶点。\n\n初始点 $(x^{(0)}, y^{(0)}, s^{(0)})$ 对原始问题和对偶问题都是严格可行的。该问题定义明确、科学上合理且内部一致。\n\n#### 结论\n问题有效。\n\n### 步骤 2：求解\n\n原始-对偶内点法旨在求解以下 KKT 条件系统：\n$$\n\\begin{cases}\nA^{\\top}y + s = c   \\text{(对偶可行性)} \\\\\nAx = b   \\text{(原始可行性)} \\\\\nXSe = 0   \\text{(互补性)}\n\\end{cases}\n$$\n其中 $X = \\text{diag}(x)$，$S = \\text{diag}(s)$，并且 $e$ 是全一向量。该方法将互补性条件扰动为 $XSe = \\mu e$，并应用牛顿法来寻找朝向解的步长 $(\\Delta x, \\Delta y, \\Delta s)$。\n\n线性化系统是：\n$$\n\\begin{pmatrix}\n0  A^{\\top}  I \\\\\nA  0  0 \\\\\nS  0  X\n\\end{pmatrix}\n\\begin{pmatrix}\n\\Delta x \\\\\n\\Delta y \\\\\n\\Delta s\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nc - A^{\\top}y - s \\\\\nb - Ax \\\\\n\\sigma\\mu e - XSe\n\\end{pmatrix}\n$$\n在可行点 $(x^{(0)}, y^{(0)}, s^{(0)})$ 处，可行性残差为零：$c - A^{\\top}y^{(0)} - s^{(0)} = 0$ 和 $b - Ax^{(0)} = 0$。对于预测（仿射伸缩）步，中心化参数 $\\sigma$ 设置为 0。方向 $(\\Delta x_{\\mathrm{aff}}, \\Delta y_{\\mathrm{aff}}, \\Delta s_{\\mathrm{aff}})$ 的系统简化为：\n$$\n\\begin{align*}\nA^{\\top} \\Delta y_{\\mathrm{aff}} + \\Delta s_{\\mathrm{aff}} = 0 \\\\\nA \\Delta x_{\\mathrm{aff}} = 0 \\\\\nS^{(0)} \\Delta x_{\\mathrm{aff}} + X^{(0)} \\Delta s_{\\mathrm{aff}} = -X^{(0)}S^{(0)}e\n\\end{align*}\n$$\n让我们代入给定的值：\n$A = \\begin{pmatrix}1  2\\end{pmatrix}$，$x^{(0)} = \\begin{pmatrix}1 \\\\ 1\\end{pmatrix}$，$s^{(0)} = \\begin{pmatrix}1.75 \\\\ 0.5\\end{pmatrix}$。\n$X^{(0)} = \\text{diag}(x^{(0)}) = \\begin{pmatrix}1  0 \\\\ 0  1\\end{pmatrix}$，$S^{(0)} = \\text{diag}(s^{(0)}) = \\begin{pmatrix}1.75  0 \\\\ 0  0.5\\end{pmatrix}$。\n注意 $X^{(0)}$ 是单位矩阵 $I$。设 $\\Delta x_{\\mathrm{aff}} = \\begin{pmatrix}\\Delta x_1 \\\\ \\Delta x_2\\end{pmatrix}$，$\\Delta s_{\\mathrm{aff}} = \\begin{pmatrix}\\Delta s_1 \\\\ \\Delta s_2\\end{pmatrix}$，$\\Delta y_{\\mathrm{aff}}$ 是一个标量。\n\n从 $A \\Delta x_{\\mathrm{aff}} = 0$ 得：\n$\\begin{pmatrix}1  2\\end{pmatrix} \\begin{pmatrix}\\Delta x_1 \\\\ \\Delta x_2\\end{pmatrix} = 0 \\implies \\Delta x_1 + 2\\Delta x_2 = 0$。\n\n从 $A^{\\top} \\Delta y_{\\mathrm{aff}} + \\Delta s_{\\mathrm{aff}} = 0$ 得：\n$\\begin{pmatrix}1 \\\\ 2\\end{pmatrix} \\Delta y_{\\mathrm{aff}} + \\begin{pmatrix}\\Delta s_1 \\\\ \\Delta s_2\\end{pmatrix} = \\begin{pmatrix}0 \\\\ 0\\end{pmatrix} \\implies \\Delta s_1 = -\\Delta y_{\\mathrm{aff}}$ 且 $\\Delta s_2 = -2\\Delta y_{\\mathrm{aff}}$。\n\n从 $S^{(0)} \\Delta x_{\\mathrm{aff}} + X^{(0)} \\Delta s_{\\mathrm{aff}} = -X^{(0)}S^{(0)}e$ 得：\n$\\begin{pmatrix}1.75  0 \\\\ 0  0.5\\end{pmatrix} \\begin{pmatrix}\\Delta x_1 \\\\ \\Delta x_2\\end{pmatrix} + \\begin{pmatrix}1  0 \\\\ 0  1\\end{pmatrix} \\begin{pmatrix}\\Delta s_1 \\\\ \\Delta s_2\\end{pmatrix} = -\\begin{pmatrix}1.75 \\cdot 1 \\\\ 0.5 \\cdot 1\\end{pmatrix} = \\begin{pmatrix}-1.75 \\\\ -0.5\\end{pmatrix}$。\n这给出了两个方程：\n$1.75 \\Delta x_1 + \\Delta s_1 = -1.75$\n$0.5 \\Delta x_2 + \\Delta s_2 = -0.5$\n\n我们有一个方程组需要求解。代入 $\\Delta x_1, \\Delta s_1, \\Delta s_2$ 的表达式：\n$1.75 (-2\\Delta x_2) + (-\\Delta y_{\\mathrm{aff}}) = -1.75 \\implies -3.5\\Delta x_2 - \\Delta y_{\\mathrm{aff}} = -1.75$\n$0.5 \\Delta x_2 + (-2\\Delta y_{\\mathrm{aff}}) = -0.5 \\implies 0.5\\Delta x_2 - 2\\Delta y_{\\mathrm{aff}} = -0.5$\n\n从第二个方程， $0.5\\Delta x_2 = 2\\Delta y_{\\mathrm{aff}} - 0.5 \\implies \\Delta x_2 = 4\\Delta y_{\\mathrm{aff}} - 1$。\n代入第一个方程：\n$-3.5(4\\Delta y_{\\mathrm{aff}} - 1) - \\Delta y_{\\mathrm{aff}} = -1.75$\n$-14\\Delta y_{\\mathrm{aff}} + 3.5 - \\Delta y_{\\mathrm{aff}} = -1.75$\n$-15\\Delta y_{\\mathrm{aff}} = -5.25$\n$\\Delta y_{\\mathrm{aff}} = \\frac{5.25}{15} = \\frac{21/4}{15} = \\frac{21}{60} = \\frac{7}{20} = 0.35$。\n\n现在，我们反向代入以找到其他分量：\n$\\Delta x_2 = 4(0.35) - 1 = 1.4 - 1 = 0.4 = \\frac{2}{5}$。\n$\\Delta x_1 = -2\\Delta x_2 = -2(0.4) = -0.8 = -\\frac{4}{5}$。\n$\\Delta s_1 = -\\Delta y_{\\mathrm{aff}} = -0.35 = -\\frac{7}{20}$。\n$\\Delta s_2 = -2\\Delta y_{\\mathrm{aff}} = -2(0.35) = -0.7 = -\\frac{7}{10}$。\n\n预测方向是 $(\\Delta x_{\\mathrm{aff}}, \\Delta y_{\\mathrm{aff}}, \\Delta s_{\\mathrm{aff}})$，其中：\n$\\Delta x_{\\mathrm{aff}} = \\begin{pmatrix}-0.8 \\\\ 0.4\\end{pmatrix}$，$\\Delta y_{\\mathrm{aff}} = 0.35$，$\\Delta s_{\\mathrm{aff}} = \\begin{pmatrix}-0.35 \\\\ -0.7\\end{pmatrix}$。\n\n接下来，我们沿着该方向定义的射线，为步长 $\\alpha \\ge 0$ 构建对偶间隙函数 $g(\\alpha) = x(\\alpha)^{\\top}s(\\alpha)$：\n$x(\\alpha) = x^{(0)} + \\alpha\\Delta x_{\\mathrm{aff}} = \\begin{pmatrix}1 \\\\ 1\\end{pmatrix} + \\alpha\\begin{pmatrix}-0.8 \\\\ 0.4\\end{pmatrix} = \\begin{pmatrix}1 - 0.8\\alpha \\\\ 1 + 0.4\\alpha\\end{pmatrix}$。\n$s(\\alpha) = s^{(0)} + \\alpha\\Delta s_{\\mathrm{aff}} = \\begin{pmatrix}1.75 \\\\ 0.5\\end{pmatrix} + \\alpha\\begin{pmatrix}-0.35 \\\\ -0.7\\end{pmatrix} = \\begin{pmatrix}1.75 - 0.35\\alpha \\\\ 0.5 - 0.7\\alpha\\end{pmatrix}$。\n\n对偶间隙是 $g(\\alpha) = (x^{(0)} + \\alpha\\Delta x_{\\mathrm{aff}})^{\\top}(s^{(0)} + \\alpha\\Delta s_{\\mathrm{aff}})$。\n$g(\\alpha) = (x^{(0)})^{\\top}s^{(0)} + \\alpha((x^{(0)})^{\\top}\\Delta s_{\\mathrm{aff}} + (\\Delta x_{\\mathrm{aff}})^{\\top}s^{(0)}) + \\alpha^2 (\\Delta x_{\\mathrm{aff}})^{\\top}\\Delta s_{\\mathrm{aff}}$。\n初始对偶间隙是 $(x^{(0)})^{\\top}s^{(0)} = 1(1.75) + 1(0.5) = 2.25$。\n线性项的系数是 $\\sum_i(x_i^{(0)}\\Delta s_i + s_i^{(0)}\\Delta x_i)$。从牛顿系统可知，这等于 $\\sum_i(-x_i^{(0)}s_i^{(0)}) = -(x^{(0)})^{\\top}s^{(0)} = -2.25$。\n二次项的系数是 $(\\Delta x_{\\mathrm{aff}})^{\\top}\\Delta s_{\\mathrm{aff}}$。理论上，由于 $A\\Delta x_{\\mathrm{aff}}=0$ 且 $\\Delta s_{\\mathrm{aff}} = -A^{\\top}\\Delta y_{\\mathrm{aff}}$，该项为 $(\\Delta x_{\\mathrm{aff}})^{\\top}(-A^{\\top}\\Delta y_{\\mathrm{aff}}) = -(A\\Delta x_{\\mathrm{aff}})^{\\top}\\Delta y_{\\mathrm{aff}} = 0$。\n让我们用我们的数值来验证：$(\\Delta x_{\\mathrm{aff}})^{\\top}\\Delta s_{\\mathrm{aff}} = (-0.8)(-0.35) + (0.4)(-0.7) = 0.28 - 0.28 = 0$。\n因此对偶间隙函数是线性的：\n$g(\\alpha) = 2.25 - 2.25\\alpha$。\n\n为了找到 $\\alpha^{\\star}$，我们必须保持严格正性：$x(\\alpha) > 0$ 和 $s(\\alpha) > 0$。\n$1 - 0.8\\alpha > 0 \\implies \\alpha  1/0.8 = 1.25$。\n$1 + 0.4\\alpha > 0$，这对所有 $\\alpha \\ge 0$ 都成立。\n$1.75 - 0.35\\alpha > 0 \\implies \\alpha  1.75/0.35 = 5$。\n$0.5 - 0.7\\alpha > 0 \\implies \\alpha  0.5/0.7 \\approx 0.7142857$ (即 $5/7$)。\n保持所有分量为正的最大 $\\alpha$ 是 $\\alpha_{\\max} = \\min(1.25, 5, 5/7) = 5/7$。\n因此，$\\alpha$ 必须在区间 $[0, 5/7)$ 内。\n\n我们要最小化 $g(\\alpha) = 2.25 - 2.25\\alpha$，这是一个关于 $\\alpha$ 的严格递减函数。为了使 $g(\\alpha)$ 尽可能小，我们必须选择尽可能大的 $\\alpha$。$\\alpha$ 的可行集上确界是 $\\alpha_{\\max}=5/7$。虽然在开区间 $[0, 5/7)$ 上无法达到最小值，但寻找“精确线搜索步长”的问题通常被理解为找到达到下确界的边界点。因此，我们取 $\\alpha^{\\star} = \\alpha_{\\max}$。\n$\\alpha^{\\star} = 5/7 \\approx 0.7142857...$\n四舍五入到四位有效数字，我们得到 $\\alpha^{\\star} \\approx 0.7143$。\n\n最后，我们计算分数步长的对偶间隙。\n$\\alpha_{\\max} = 5/7$。\n第一步是 $\\alpha_1 = \\frac{1}{2}\\alpha_{\\max} = \\frac{1}{2} \\cdot \\frac{5}{7} = \\frac{5}{14}$。\n$g(\\frac{5}{14}) = 2.25(1 - \\frac{5}{14}) = \\frac{9}{4} \\cdot \\frac{9}{14} = \\frac{81}{56}$。\n\n第二步是 $\\alpha_2 = \\frac{9}{10}\\alpha_{\\max} = \\frac{9}{10} \\cdot \\frac{5}{7} = \\frac{45}{70} = \\frac{9}{14}$。\n$g(\\frac{9}{14}) = 2.25(1 - \\frac{9}{14}) = \\frac{9}{4} \\cdot \\frac{5}{14} = \\frac{45}{56}$。\n\n问题要求将 $\\alpha^{\\star}$ 的值四舍五入到四位有效数字。", "answer": "$$\n\\boxed{0.7143}\n$$", "id": "3164522"}, {"introduction": "计算迭代步长是一回事，但判断算法是否已找到足够好的解则是另一回事。本练习将我们的重点转移到内点法中至关重要的停止准则问题上。通过一个巧妙的思维实验，你将发现为什么仅仅满足原始和对偶可行性约束是不够的，以及为什么对偶间隙是衡量最优性的一个不可或缺的指标。[@problem_id:3164561]", "problem": "考虑应用于线性规划 (LP) 的原始-对偶内点法 (PDIP)，其中原始问题是最小化 $c^{\\top}x$，约束条件为 $Ax=b$ 和 $x \\geq 0$；对偶问题是最大化 $b^{\\top}y$，约束条件为 $A^{\\top}y + s = c$ 和 $s \\geq 0$。从最优性的 Karush-Kuhn-Tucker (KKT) 条件出发，推导与原始可行性和对偶可行性相关的残差，根据原始和对偶变量定义对偶间隙，并利用这些来获得一个以残差和对偶间隙的无穷范数界表示的停止准则，其中容差参数为 $\\epsilon > 0$。然后，构造一个具体的 LP 和一个严格为正的原始-对偶迭代点，该迭代点的原始和对偶残差非常小，但对偶间隙很大，并解释其对 PDIP 中停止决策的影响。\n\n具体来说，考虑 LP 问题，其中 $A = \\begin{pmatrix}1  1\\end{pmatrix}$，$b = 1$，以及 $c = \\begin{pmatrix}0 \\\\ 0\\end{pmatrix}$。取迭代点 $x = \\begin{pmatrix}\\frac{1}{2} \\\\ \\frac{1}{2}\\end{pmatrix}$，$y = -100$，以及 $s = \\begin{pmatrix}100 \\\\ 100\\end{pmatrix}$。计算该迭代点的对偶间隙 $x^{\\top}s$。将您的最终答案表示为精确值。无需四舍五入。", "solution": "该问题要求分析应用于线性规划 (LP) 的原始-对偶内点法 (PDIP) 的停止准则，并最终通过一个旨在阐明关键原则的具体示例进行计算。\n\n首先，我们建立理论背景。原始 LP 问题的标准形式是：\n$$ \\text{最小化} \\quad z_p = c^{\\top}x $$\n$$ \\text{约束条件} \\quad Ax = b, \\quad x \\geq 0 $$\n其中 $x \\in \\mathbb{R}^n$, $c \\in \\mathbb{R}^n$, $A \\in \\mathbb{R}^{m \\times n}$，以及 $b \\in \\mathbb{R}^m$。\n\n相应的对偶 LP 问题是：\n$$ \\text{最大化} \\quad z_d = b^{\\top}y $$\n$$ \\text{约束条件} \\quad A^{\\top}y + s = c, \\quad s \\geq 0 $$\n其中 $y \\in \\mathbb{R}^m$ 是对偶变量，$s \\in \\mathbb{R}^n$ 是对偶松弛变量。\n\n对于原始-对偶对 $(x, y, s)$，Karush-Kuhn-Tucker (KKT) 条件为其最优性的充要条件。这些条件是：\n1.  **原始可行性**：$Ax = b$ 且 $x \\geq 0$。\n2.  **对偶可行性**：$A^{\\top}y + s = c$ 且 $s \\geq 0$。\n3.  **互补松弛性**：对所有 $i=1, \\dots, n$，有 $x_i s_i = 0$。这可以写成向量形式 $XSe = 0$，其中 $X = \\text{diag}(x)$，$S = \\text{diag}(s)$，$e$ 是全一向量。\n\nPDIP 方法生成一系列迭代点 $(x^k, y^k, s^k)$，这些点是严格为正的 ($x^k > 0$, $s^k > 0$)，但不一定满足其他 KKT 条件。为了监控向最优性收敛的进程，我们定义了衡量这些条件违背程度的残差。\n\n**原始可行性残差** $r_p$ 衡量对原始等式约束的违背程度：\n$$ r_p = b - Ax $$\n**对偶可行性残差** $r_d$ 衡量对对偶等式约束的违背程度：\n$$ r_d = c - A^{\\top}y - s $$\n如果 $r_p=0$，则迭代点被认为是原始可行的；如果 $r_d=0$，则被认为是对偶可行的。\n\n**对偶间隙**是原始和对偶目标函数值之差，$z_p - z_d = c^{\\top}x - b^{\\top}y$。对于一个原始可行的 $x$ 和一个对偶可行的 $(y, s)$，这个间隙可以简化为：\n$$ c^{\\top}x - b^{\\top}y = (A^{\\top}y + s)^{\\top}x - (Ax)^{\\top}y = (y^{\\top}A + s^{\\top})x - x^{\\top}A^{\\top}y = y^{\\top}Ax + s^{\\top}x - y^{\\top}Ax = x^{\\top}s $$\n因此，表达式 $x^{\\top}s$ 就是对偶间隙，根据互补松弛性条件，在最优解处该值必须为零。\n\n一个鲁棒的 PDIP 方法停止准则必须确保所有 KKT 条件都近似满足。这包括检查可行性残差是否很小以及对偶间隙是否很小。对于给定的容差 $\\epsilon > 0$，一个常见的停止准则是当相对残差和相对对偶间隙都小于 $\\epsilon$ 时终止：\n$$ \\frac{\\|r_p\\|_{\\infty}}{1 + \\|b\\|_{\\infty}} \\leq \\epsilon, \\quad \\frac{\\|r_d\\|_{\\infty}}{1 + \\|c\\|_{\\infty}} \\leq \\epsilon, \\quad \\frac{x^{\\top}s}{n(1 + |c^{\\top}x|)} \\leq \\epsilon $$\n问题要求一个基于绝对界的停止准则，可以表述为：\n$$ \\|b - Ax\\|_{\\infty} \\leq \\epsilon_p, \\quad \\|c - A^{\\top}y - s\\|_{\\infty} \\leq \\epsilon_d, \\quad |x^{\\top}s| \\leq \\epsilon_g $$\n其中 $\\epsilon_p$，$\\epsilon_d$ 和 $\\epsilon_g$ 是小的正容差，可能由单个参数 $\\epsilon$ 导出。\n\n现在，我们分析所给出的具体 LP 问题，以说明为什么停止准则的所有三个组成部分都是必要的。该问题定义如下：\n$$ A = \\begin{pmatrix}1  1\\end{pmatrix}, \\quad b = 1, \\quad c = \\begin{pmatrix}0 \\\\ 0\\end{pmatrix} $$\n给定的迭代点是：\n$$ x = \\begin{pmatrix}\\frac{1}{2} \\\\ \\frac{1}{2}\\end{pmatrix}, \\quad y = -100, \\quad s = \\begin{pmatrix}100 \\\\ 100\\end{pmatrix} $$\n我们已知 $x > 0$ 和 $s > 0$，这对该迭代点是成立的。让我们计算残差和对偶间隙。\n\n1.  **原始可行性残差**：\n    $$ r_p = b - Ax = 1 - \\begin{pmatrix}1  1\\end{pmatrix} \\begin{pmatrix}\\frac{1}{2} \\\\ \\frac{1}{2}\\end{pmatrix} = 1 - (\\frac{1}{2} + \\frac{1}{2}) = 1 - 1 = 0 $$\n    由于 $r_p = 0$，该迭代点是完全原始可行的。$\\|r_p\\|_{\\infty} = 0$，这是“非常小”的。\n\n2.  **对偶可行性残差**：\n    $$ r_d = c - A^{\\top}y - s = \\begin{pmatrix}0 \\\\ 0\\end{pmatrix} - \\begin{pmatrix}1 \\\\ 1\\end{pmatrix}(-100) - \\begin{pmatrix}100 \\\\ 100\\end{pmatrix} = \\begin{pmatrix}0 \\\\ 0\\end{pmatrix} - \\begin{pmatrix}-100 \\\\ -100\\end{pmatrix} - \\begin{pmatrix}100 \\\\ 100\\end{pmatrix} = \\begin{pmatrix}0 \\\\ 0\\end{pmatrix} $$\n    由于 $r_d = 0$，该迭代点是完全对偶可行的。$\\|r_d\\|_{\\infty} = 0$，这也是“非常小”的。\n\n3.  **对偶间隙**：问题要求计算对偶间隙 $x^{\\top}s$。\n    $$ x^{\\top}s = \\begin{pmatrix}\\frac{1}{2}  \\frac{1}{2}\\end{pmatrix} \\begin{pmatrix}100 \\\\ 100\\end{pmatrix} = \\frac{1}{2} \\cdot 100 + \\frac{1}{2} \\cdot 100 = 50 + 50 = 100 $$\n\n**对停止决策的影响**：\n这个例子展示了一个关键点。给定的迭代点 $(x, y, s)$ 的原始和对偶可行性残差均为零。如果停止准则只检查这些残差（即 $\\|r_p\\|_{\\infty} \\leq \\epsilon$ 和 $\\|r_d\\|_{\\infty} \\leq \\epsilon$），算法可能会终止，特别是当 $\\epsilon$ 是任何大于 $0$ 的值时。然而，其对偶间隙为 $x^{\\top}s = 100$，这个值并不小。互补松弛性乘积为 $x_1 s_1 = 50$ 和 $x_2 s_2 = 50$，远未达到最优性所要求的 $0$。该问题的最优目标值为 $0$（因为 $c=0$，任何可行解 $x$ 都能达到），因此就对偶间隙而言，当前目标值为 $c^{\\top}x = 0$ 的迭代点远非最优。\n\n这说明一个迭代点可以同时是原始问题和对偶问题的完全可行解，但离最优解仍然很远。在这种情况下，与最优解的“距离”由对偶间隙来衡量。因此，一个可靠的 PDIP 方法停止准则必须包括一个关于对偶间隙（或单个互补松弛性乘积）的条件。仅仅依赖于小的可行性残差可能导致算法过早终止，得到一个高度次优的解。\n\n最后的任务是给出计算出的对偶间隙的值。\n$$ x^{\\top}s = 100 $$\n这是一个精确值。", "answer": "$$\\boxed{100}$$", "id": "3164561"}, {"introduction": "在掌握了各个组成部分之后，现在是时候构建一个完整且功能强大的求解器了。这个高级练习将指导你实现一个完整的预测-校正内点法，这是现代优化领域的主力算法，即使从高度不可行的点开始也能收敛。通过用差异极大的初始猜测来测试你的实现，你将亲眼见证定义这些算法的卓越鲁棒性。[@problem_id:3164599]", "problem": "考虑标准形式的线性规划问题：最小化线性目标 $c^{\\top} x$，满足等式约束 $A x = b$ 和非负性约束 $x \\ge 0$。对偶变量为对应等式约束的 $y$ 和松弛变量 $s \\ge 0$，其对偶可行性关系为 $A^{\\top} y + s = c$。该问题的理论基础包括凸优化的 Karush-Kuhn-Tucker (KKT) 条件和基于障碍函数的中心路径，它们共同表明在最优点处满足 $A x = b$，$A^{\\top} y + s = c$，$x \\ge 0$，$s \\ge 0$，以及对所有索引 $i$ 都有 $x_i s_i = 0$。\n\n您的任务是从 KKT 条件和障碍函数公式出发，推导并实现一种原始-对偶内点法 (IPM)。该方法必须能够从具有大残差的不可行点开始，并稳健地收敛到最优解。该方法必须是一种带有预测-校正步和边界分数规则的不可行起始原始-对偶 IPM，以确保 $x$ 和 $s$ 在整个迭代过程中保持严格为正。您必须使用一个基于仿射缩放预测步自适应选择的中心化参数。\n\n您必须求解以下具体实例：\n- 矩阵 $A \\in \\mathbb{R}^{2 \\times 3}$，向量 $b \\in \\mathbb{R}^{2}$ 和向量 $c \\in \\mathbb{R}^{3}$ 分别为\n$$\nA = \\begin{bmatrix} 1  1  1 \\\\ 2  1  0 \\end{bmatrix}, \\quad\nb = \\begin{bmatrix} 3 \\\\ 3 \\end{bmatrix}, \\quad\nc = \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix}.\n$$\n\n仅从 KKT 条件和障碍中心路径定义出发（不使用任何快捷公式），推导出为对偶步长产生对称正定 Schur 补系统的牛顿线性化，实现一个预测-校正原始-对偶 IPM，并使用边界分数规则来强制保持正性。使用的停止准则是：当原始残差 $A x - b$ 的欧几里得范数、对偶残差 $A^{\\top} y + s - c$ 的欧几里得范数以及平均互补性 $\\mu = \\frac{x^{\\top} s}{n}$（其中 $n$ 是 $x$ 的维度）三者的最大值小于容差 $\\varepsilon$ 时终止，其中 $\\varepsilon = 10^{-8}$。\n\n设计并评估不同初始化 $(x^{(0)}, y^{(0)}, s^{(0)})$ 对收敛性的影响。构建具有大残差的不可行起始点，以展示内点法 (IPM) 的稳健收敛性。使用以下包含四种初始化的测试套件：\n- 测试用例 1（可行起始点）：$x^{(0)} = \\begin{bmatrix}1, 1, 1\\end{bmatrix}^{\\top}$，$y^{(0)} = \\begin{bmatrix}0, 0\\end{bmatrix}^{\\top}$，$s^{(0)} = c$。\n- 测试用例 2（具有大残差的不可行点）：$x^{(0)} = \\begin{bmatrix}10.0, 0.1, 5.0\\end{bmatrix}^{\\top}$，$y^{(0)} = \\begin{bmatrix}0, 0\\end{bmatrix}^{\\top}$，$s^{(0)} = 10 \\, c$。\n- 测试用例 3（具有微小原始变量和不一致对偶变量的不可行点）：$x^{(0)} = \\begin{bmatrix}10^{-6}, 2 \\cdot 10^{-6}, 3 \\cdot 10^{-6}\\end{bmatrix}^{\\top}$，$y^{(0)} = \\begin{bmatrix}100, -200\\end{bmatrix}^{\\top}$，$s^{(0)} = \\begin{bmatrix}5, 1, 4\\end{bmatrix}^{\\top}$。\n- 测试用例 4（具有极大尺度原始变量和不一致松弛变量的不可行点）：$x^{(0)} = \\begin{bmatrix}10^{6}, 2 \\cdot 10^{6}, 10^{6}\\end{bmatrix}^{\\top}$，$y^{(0)} = \\begin{bmatrix}-1000, 500\\end{bmatrix}^{\\top}$，$s^{(0)} = \\begin{bmatrix}0.5, 0.5, 0.5\\end{bmatrix}^{\\top}$。\n\n对每个测试用例，运行 IPM，最大迭代次数为 100，容差为 $\\varepsilon = 10^{-8}$，并根据停止准则记录收敛所需的迭代次数。如果在 100 次迭代内未达到收敛，则记录数值 100。\n\n您的程序应生成单行输出，其中包含按测试用例顺序排列的结果，格式为方括号括起来的逗号分隔列表，每个条目是该测试用例的整数迭代次数（例如 $[k_1,k_2,k_3,k_4]$）。", "solution": "用户提供了一个数值优化领域的适定问题。任务是为一个特定的线性规划 (LP) 问题推导并实现一个原始-对偶内点法 (IPM)，然后在一组四个初始条件下测试其收敛性。该问题具有科学依据，规定明确，并要求基于第一性原理进行非平凡的实现。验证标准已满足，可以生成解决方案。\n\n### 1. 问题公式化与最优性条件\n\n线性规划 (LP) 的标准形式如下：\n$$\n\\begin{align*}\n\\text{minimize} \\quad  c^{\\top} x \\\\\n\\text{subject to} \\quad  A x = b \\\\\n x \\ge 0\n\\end{align*}\n$$\n其中 $A \\in \\mathbb{R}^{m \\times n}$，$b \\in \\mathbb{R}^{m}$，$c \\in \\mathbb{R}^{n}$，优化变量为 $x \\in \\mathbb{R}^{n}$。\n\n相应的对偶问题是：\n$$\n\\begin{align*}\n\\text{maximize} \\quad  b^{\\top} y \\\\\n\\text{subject to} \\quad  A^{\\top} y + s = c \\\\\n s \\ge 0\n\\end{align*}\n$$\n其中 $y \\in \\mathbb{R}^{m}$ 和 $s \\in \\mathbb{R}^{n}$ 是对偶变量。\n\n最优性的 Karush-Kuhn-Tucker (KKT) 条件将原始问题和对偶问题联系起来。一个点 $(x, y, s)$ 是最优的，当且仅当它满足以下条件：\n1.  **原始可行性**: $A x = b$\n2.  **对偶可行性**: $A^{\\top} y + s = c$\n3.  **非负性**: $x \\ge 0, s \\ge 0$\n4.  **互补松弛性**: 对 $i = 1, \\dots, n$，$x_i s_i = 0$。这可以写成 $XSe = 0$，其中 $X = \\text{diag}(x)$，$S = \\text{diag}(s)$，$e$ 是全一向量。\n\n### 2. 中心路径与障碍函数公式\n\n内点法通过遍历可行域的内部（$x > 0, s > 0$）来逼近解。它们用目标函数中的一个对数障碍项替换非负性约束 $x \\ge 0$，并用一个扰动版本 $XSe = \\tau e$（其中障碍参数 $\\tau > 0$）替换互补松弛性条件 $XSe = 0$。\n\nKKT 条件被松弛以定义**中心路径**，这是一组满足以下条件的点 $(x(\\tau), y(\\tau), s(\\tau))$：\n$$\n\\begin{align*}\nA x = b \\\\\nA^{\\top} y + s = c \\\\\nXSe = \\tau e\n\\end{align*}\n$$\n当 $\\tau \\to 0$ 时，中心路径上的点收敛到原始 LP 的一个最优解。IPM 生成一个迭代序列，该序列近似地沿着这条路径走向解。\n\n### 3. 求解 KKT 系统的牛顿法\n\n对于一个一般的（且可能不可行的）迭代点 $(x, y, s)$，其中 $x > 0$ 且 $s > 0$，我们定义 KKT 系统的残差：\n-   原始残差: $r_b = A x - b$\n-   对偶残差: $r_c = A^{\\top} y + s - c$\n\n我们寻求一个牛顿步长 $(\\Delta x, \\Delta y, \\Delta s)$，它将当前迭代点移近中心路径上的一个点。这涉及到对 KKT 系统进行线性化：\n$$\n\\begin{align*}\nA(x + \\Delta x) = b \\implies A \\Delta x = -r_b \\\\\nA^{\\top}(y + \\Delta y) + (s + \\Delta s) = c \\implies A^{\\top} \\Delta y + \\Delta s = -r_c \\\\\n(X + \\Delta X)(S + \\Delta S)e \\approx XSe + S\\Delta x + X\\Delta s = \\sigma \\mu e \\implies S\\Delta x + X\\Delta s = \\sigma \\mu e - XSe\n\\end{align*}\n$$\n此处，$\\mu = (x^{\\top}s)/n$ 是当前的平均互补间隙，$\\sigma \\in [0, 1]$ 是一个中心化参数。这为搜索方向 $(\\Delta x, \\Delta y, \\Delta s)$ 提供了以下块结构线性系统：\n$$\n\\begin{bmatrix}\nA  0  0 \\\\\n0  A^{\\top}  I \\\\\nS  0  X\n\\end{bmatrix}\n\\begin{bmatrix}\n\\Delta x \\\\\n\\Delta y \\\\\n\\Delta s\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n-r_b \\\\\n-r_c \\\\\n\\sigma \\mu e - XSe\n\\end{bmatrix}\n$$\n\n### 4. 通过 Schur 补求解系统\n\n这个系统可以使用块消元法高效求解。\n从第二行得到：$\\Delta s = -r_c - A^{\\top} \\Delta y$。\n将 $\\Delta s$ 代入第三行：\n$S \\Delta x + X(-r_c - A^{\\top} \\Delta y) = \\sigma \\mu e - XSe$\n$S \\Delta x - XA^{\\top} \\Delta y = \\sigma \\mu e - XSe + Xr_c$\n由于 $x, s > 0$，$S$ 是可逆的。令 $D^2 = S^{-1}X$，这是一个对角元素为正值 $x_i/s_i$ 的对角矩阵。\n$\\Delta x = S^{-1}(\\sigma \\mu e - XSe + Xr_c + XA^{\\top} \\Delta y) = S^{-1}(\\sigma \\mu e - XSe + Xr_c) + D^2 A^{\\top} \\Delta y$。\n\n最后，将 $\\Delta x$ 代入第一行 $A \\Delta x = -r_b$：\n$A(S^{-1}(\\sigma \\mu e - XSe + Xr_c) + D^2 A^{\\top} \\Delta y) = -r_b$\n$(A D^2 A^{\\top}) \\Delta y = -r_b - A(S^{-1}(\\sigma \\mu e - XSe + Xr_c))$\n$(A D^2 A^{\\top}) \\Delta y = -r_b - A S^{-1}(\\sigma \\mu e - XSe) - A D^2 r_c$\n\n这就是关于 $\\Delta y$ 的 **Schur 补系统**。矩阵 $M = A D^2 A^{\\top}$ 是一个 $m \\times m$ 的对称正定矩阵（假设 $A$ 是行满秩的），可以被高效求解。一旦求得 $\\Delta y$，就可以通过回代恢复 $\\Delta s$ 和 $\\Delta x$：\n1.  求解 $(A D^2 A^{\\top}) \\Delta y = -r_b - A S^{-1}(\\sigma \\mu e - XSe) - A D^2 r_c$ 以得到 $\\Delta y$。\n2.  计算 $\\Delta s = -r_c - A^{\\top} \\Delta y$。\n3.  计算 $\\Delta x = S^{-1}(\\sigma \\mu e - XSe - X \\Delta s)$。\n\n### 5. 预测-校正法\n\nMehrotra 的预测-校正法通过在每次迭代中使用两阶段方法来改善收敛性。\n\n**预测步**：首先，我们通过设置 $\\sigma=0$ 计算一个“仿射缩放”方向。这个方向直接指向最优解，而不试图保持在中心路径上。\n$$\n\\begin{bmatrix}\nA  0  0 \\\\\n0  A^\\top  I \\\\\nS  0  X\n\\end{bmatrix}\n\\begin{bmatrix}\n\\Delta x^{aff} \\\\ \\Delta y^{aff} \\\\ \\Delta s^{aff}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n-r_b \\\\\n-r_c \\\\\n-X S e\n\\end{bmatrix}\n$$\n\n**校正与中心化步**：\n1.  **自适应中心化**：仿射步用于估计互补间隙将减少多少。基于此，选择一个自适应的中心化参数 $\\sigma$。\n    -   沿仿射方向计算到边界的步长 $\\alpha_{aff}$。\n    -   估计在此投影点的互补间隙：$\\mu_{aff} = (x + \\alpha_{aff} \\Delta x^{aff})^{\\top} (s + \\alpha_{aff} \\Delta s^{aff}) / n$。\n    -   设置 $\\sigma = (\\mu_{aff} / \\mu)^3$。当取得良好进展时，这种流行的启发式方法会减少中心化的工作量。\n\n2.  **校正项**：互补条件 $XSe=\\sigma\\mu e$ 的线性化忽略了二阶项 $\\Delta X \\Delta S e$。校正步将此项加回，使用仿射步作为其估计：$\\Delta X^{aff} \\Delta S^{aff} e$。互补方程的右端项变为 $\\sigma \\mu e - XSe - \\Delta X^{aff} \\Delta S^{aff} e$。\n\n3.  **最终方向**：使用更新后的右端项，求解第二个线性系统以获得最终搜索方向 $(\\Delta x, \\Delta y, \\Delta s)$。\n$$\n\\begin{bmatrix}\nA  0  0 \\\\\n0  A^\\top  I \\\\\nS  0  X\n\\end{bmatrix}\n\\begin{bmatrix}\n\\Delta x \\\\\n\\Delta y \\\\\n\\Delta s\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n-r_b \\\\\n-r_c \\\\\n\\sigma \\mu e - X S e - \\Delta X^{aff} \\Delta S^{aff} e\n\\end{bmatrix}\n$$\n\n### 6. 步长计算与更新\n\n为保持 $x$ 和 $s$ 的严格正性，我们不能取完整的牛顿步。使用边界分数规则来确定分别为原始和对偶的步长 $\\alpha_p$ 和 $\\alpha_d$。\n1.  计算在 $x$ 或 $s$ 的某个分量变为零之前可以采取的最大步长：\n    $$\n    \\alpha_{p, \\text{max}} = \\min_{i: \\Delta x_i  0} \\left( \\frac{-x_i}{\\Delta x_i} \\right) \\quad \\text{and} \\quad \\alpha_{d, \\text{max}} = \\min_{i: \\Delta s_i  0} \\left( \\frac{-s_i}{\\Delta s_i} \\right)\n    $$\n2.  选择实际步长为最大可能步长的一个较大比例 $\\eta  1$（例如 $\\eta = 0.995$），且上限为 $1.0$：\n    $$\n    \\alpha_p = \\min(1.0, \\eta \\alpha_{p, \\text{max}}) \\quad \\text{and} \\quad \\alpha_d = \\min(1.0, \\eta \\alpha_{d, \\text{max}})\n    $$\n3.  更新变量：\n    $$\n    x^{(k+1)} = x^{(k)} + \\alpha_p \\Delta x \\quad , \\quad y^{(k+1)} = y^{(k)} + \\alpha_d \\Delta y \\quad , \\quad s^{(k+1)} = s^{(k)} + \\alpha_d \\Delta s\n    $$\n\n算法迭代进行，直到原始残差范数 $\\|r_b\\|_2$、对偶残差范数 $\\|r_c\\|_2$ 和平均互补间隙 $\\mu$ 均低于指定的容差 $\\varepsilon$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve_ipm(A, b, c, x0, y0, s0, tol=1e-8, max_iter=100, eta=0.995):\n    \"\"\"\n    Implements a primal-dual predictor-corrector interior-point method\n    for a linear program in standard form: min c^T x, s.t. Ax = b, x > 0.\n\n    Args:\n        A (np.ndarray): Constraint matrix.\n        b (np.ndarray): Constraint vector.\n        c (np.ndarray): Objective function vector.\n        x0, y0, s0 (np.ndarray): Initial primal, dual, and slack variables.\n        tol (float): Convergence tolerance.\n        max_iter (int): Maximum number of iterations.\n        eta (float): Fraction-to-the-boundary parameter.\n\n    Returns:\n        int: Number of iterations required for convergence. Returns max_iter if\n             the method does not converge within the iteration limit.\n    \"\"\"\n    m, n = A.shape\n\n    # Use float64 for better numerical precision.\n    x = np.copy(x0).astype(np.float64)\n    y = np.copy(y0).astype(np.float64)\n    s = np.copy(s0).astype(np.float64)\n\n    # Iteration counter.\n    for k in range(max_iter):\n        # --- Evaluate residuals and duality gap ---\n        r_b = A @ x - b\n        r_c = A.T @ y + s - c\n        mu = (x.T @ s) / n\n\n        # --- Check for convergence ---\n        norm_rb = np.linalg.norm(r_b)\n        norm_rc = np.linalg.norm(r_c)\n        \n        if max(norm_rb, norm_rc, mu)  tol:\n            return k\n\n        # --- Predictor Step (Affine-Scaling) ---\n        # The RHS of the complementarity equation is -XSe\n        rhs_xs_aff = -x * s\n        \n        # Build and solve the Schur complement system for dy_aff\n        D_squared = x / s\n        M = A @ (D_squared[:, np.newaxis] * A.T)\n        \n        rhs_y_aff = -r_b - A @ (rhs_xs_aff / s + D_squared * r_c)\n        \n        try:\n            dy_aff = np.linalg.solve(M, rhs_y_aff)\n        except np.linalg.LinAlgError:\n            return max_iter\n\n        # Back-substitute to find ds_aff and dx_aff\n        ds_aff = -r_c - A.T @ dy_aff\n        dx_aff = (rhs_xs_aff - x * ds_aff) / s\n\n        # --- Calculate adaptive centering parameter sigma ---\n        alpha_p_aff = 1.0\n        indices_p = dx_aff  -1e-12\n        if np.any(indices_p):\n            alpha_p_aff = min(1.0, np.min(-x[indices_p] / dx_aff[indices_p]))\n\n        alpha_d_aff = 1.0\n        indices_d = ds_aff  -1e-12\n        if np.any(indices_d):\n            alpha_d_aff = min(1.0, np.min(-s[indices_d] / ds_aff[indices_d]))\n\n        mu_aff = ((x + alpha_p_aff * dx_aff).T @ (s + alpha_d_aff * ds_aff)) / n\n        sigma = (mu_aff / mu)**3 if mu > 1e-12 else 0.0\n\n        # --- Corrector and Centering Step ---\n        rhs_xs_corr = sigma * mu - dx_aff * ds_aff\n        \n        rhs_y = -r_b - A @ ((rhs_xs_aff + rhs_xs_corr) / s + D_squared * r_c)\n\n        try:\n            dy = np.linalg.solve(M, rhs_y)\n        except np.linalg.LinAlgError:\n            return max_iter\n\n        # Back-substitute for the final directions ds and dx\n        ds = -r_c - A.T @ dy\n        dx = (rhs_xs_aff + rhs_xs_corr - x * ds) / s\n\n        # --- Step length calculation (fraction-to-the-boundary) ---\n        alpha_p_max = 1.0\n        indices_p = dx  -1e-12\n        if np.any(indices_p):\n            alpha_p_max = np.min(-x[indices_p] / dx[indices_p])\n        \n        alpha_d_max = 1.0\n        indices_d = ds  -1e-12\n        if np.any(indices_d):\n            alpha_d_max = np.min(-s[indices_d] / ds[indices_d])\n        \n        alpha_p = min(1.0, eta * alpha_p_max)\n        alpha_d = min(1.0, eta * alpha_d_max)\n\n        # --- Update variables ---\n        x += alpha_p * dx\n        y += alpha_d * dy\n        s += alpha_d * ds\n    \n    return max_iter\n\n\ndef solve():\n    A = np.array([[1, 1, 1], [2, 1, 0]], dtype=float)\n    b = np.array([3, 3], dtype=float)\n    c = np.array([1, 2, 3], dtype=float)\n    \n    test_cases = [\n        (np.array([1.0, 1.0, 1.0]), np.array([0.0, 0.0]), np.copy(c)),\n        (np.array([10.0, 0.1, 5.0]), np.array([0.0, 0.0]), 10.0 * c),\n        (np.array([1e-6, 2e-6, 3e-6]), np.array([100.0, -200.0]), np.array([5.0, 1.0, 4.0])),\n        (np.array([1e6, 2e6, 1e6]), np.array([-1000.0, 500.0]), np.array([0.5, 0.5, 0.5]))\n    ]\n\n    results = []\n    for x0, y0, s0 in test_cases:\n        iters = solve_ipm(A, b, c, x0, y0, s0, tol=1e-8, max_iter=100)\n        results.append(iters)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3164599"}]}