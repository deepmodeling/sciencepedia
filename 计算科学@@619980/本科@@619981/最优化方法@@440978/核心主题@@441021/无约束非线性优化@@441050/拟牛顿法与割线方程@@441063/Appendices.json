{"hands_on_practices": [{"introduction": "拟牛顿法的核心在于如何根据迭代过程中的信息来逐步构建对真实Hessian矩阵的近似。本练习 [@problem_id:3170225] 将从最简单的情形出发，即假设初始的Hessian近似为单位矩阵，它完全忽略了变量间的耦合关系。通过一步BFGS更新，您将亲手计算并见证非对角线元素是如何从无到有地出现的，从而直观地理解算法如何利用割线方程捕捉并学习函数真实的曲率结构。", "problem": "考虑在 $\\mathbb{R}^{2}$ 中对一个严格凸二次目标函数进行无约束光滑最小化，该函数由 $f(x) = \\frac{1}{2} x^{\\top} Q x$ 给出，其中 $Q \\in \\mathbb{R}^{2 \\times 2}$ 是对称正定矩阵。其梯度为 $\\nabla f(x) = Q x$，海森矩阵为常数矩阵 $Q$。拟牛顿法通过强制满足割线方程 $B_{k+1} s_{k} = y_{k}$ 来构建对海森矩阵的逐次对称正定近似 $B_{k}$，其中 $s_{k} = x_{k+1} - x_{k}$，$y_{k} = \\nabla f(x_{k+1}) - \\nabla f(x_{k})$。Broyden–Fletcher–Goldfarb–Shanno (BFGS) 更新是通过选择满足割线方程且在正定度量下对 $B_{k}$ 做出最小可能改变，同时保持对称性和正定性的 $B_{k+1}$ 来获得的。\n\n使用具体数据 $Q = \\begin{pmatrix} 2  1 \\\\ 1  3 \\end{pmatrix}$，初始点 $x_{0} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$，以及初始海森矩阵近似 $B_{0} = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}$。使用搜索方向 $p_{0} = - B_{0}^{-1} \\nabla f(x_{0})$ 和步长 $\\alpha_{0} = \\frac{1}{2}$ 进行一步拟牛顿迭代，得到 $x_{1} = x_{0} + \\alpha_{0} p_{0}$。定义 $s_{0} = x_{1} - x_{0}$ 和 $y_{0} = \\nabla f(x_{1}) - \\nabla f(x_{0})$。然后进行一次对称秩二 BFGS 更新以获得 $B_{1}$。\n\n计算 $B_{1}$ 的 (1,2) 项（右上角的非对角元素），并将最终数值精确表示为最简分数。从割线方程和曲率耦合的角度简要解释，为什么即使在单次更新后，一个初始为对角矩阵的 $B_{0}$ 也会产生非对角项。最终报告的量必须是等于 $B_{1}$ 的 (1,2) 项的那个单一数字。", "solution": "该问题被验证为具有科学依据、适定且客观。它是 BFGS 拟牛顿法在凸二次函数上的一个标准应用。所有必要的数据都已提供且内部一致。\n\n目标函数为 $f(x) = \\frac{1}{2} x^{\\top} Q x$，其中 $Q = \\begin{pmatrix} 2  1 \\\\ 1  3 \\end{pmatrix}$。梯度为 $\\nabla f(x) = Qx$。\n初始条件为点 $x_{0} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ 和海森矩阵近似 $B_{0} = I = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}$。\n\n首先，我们计算在初始点 $x_{0}$ 处的梯度：\n$$\n\\nabla f(x_{0}) = Q x_{0} = \\begin{pmatrix} 2  1 \\\\ 1  3 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}\n$$\n\n接着，我们使用初始海森矩阵近似 $B_{0}$ 计算搜索方向 $p_{0}$：\n$$\np_{0} = -B_{0}^{-1} \\nabla f(x_{0}) = -I^{-1} \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = -\\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} -2 \\\\ -1 \\end{pmatrix}\n$$\n\n使用给定的步长 $\\alpha_{0} = \\frac{1}{2}$，我们求出下一个迭代点 $x_{1}$ 和步长向量 $s_{0}$：\n$$\ns_{0} = \\alpha_{0} p_{0} = \\frac{1}{2} \\begin{pmatrix} -2 \\\\ -1 \\end{pmatrix} = \\begin{pmatrix} -1 \\\\ -\\frac{1}{2} \\end{pmatrix}\n$$\n$$\nx_{1} = x_{0} + s_{0} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} + \\begin{pmatrix} -1 \\\\ -\\frac{1}{2} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ -\\frac{1}{2} \\end{pmatrix}\n$$\n\n现在，我们计算在新点 $x_{1}$ 处的梯度，以求得梯度变化量 $y_{0}$：\n$$\n\\nabla f(x_{1}) = Q x_{1} = \\begin{pmatrix} 2  1 \\\\ 1  3 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ -\\frac{1}{2} \\end{pmatrix} = \\begin{pmatrix} -\\frac{1}{2} \\\\ -\\frac{3}{2} \\end{pmatrix}\n$$\n$$\ny_{0} = \\nabla f(x_{1}) - \\nabla f(x_{0}) = \\begin{pmatrix} -\\frac{1}{2} \\\\ -\\frac{3}{2} \\end{pmatrix} - \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} -\\frac{5}{2} \\\\ -\\frac{5}{2} \\end{pmatrix}\n$$\n对于二次函数，我们有性质 $y_{k} = Q s_{k}$。我们可以验证这一点：\n$$\nQ s_{0} = \\begin{pmatrix} 2  1 \\\\ 1  3 \\end{pmatrix} \\begin{pmatrix} -1 \\\\ -\\frac{1}{2} \\end{pmatrix} = \\begin{pmatrix} -2 - \\frac{1}{2} \\\\ -1 - \\frac{3}{2} \\end{pmatrix} = \\begin{pmatrix} -\\frac{5}{2} \\\\ -\\frac{5}{2} \\end{pmatrix} = y_{0}\n$$\n计算结果是一致的。\n\n$B_{1}$ 的 BFGS 更新公式为：\n$$\nB_{1} = B_{0} - \\frac{B_{0} s_{0} s_{0}^{\\top} B_{0}}{s_{0}^{\\top} B_{0} s_{0}} + \\frac{y_{0} y_{0}^{\\top}}{y_{0}^{\\top} s_{0}}\n$$\n由于 $B_{0} = I$，公式简化为：\n$$\nB_{1} = I - \\frac{s_{0} s_{0}^{\\top}}{s_{0}^{\\top} s_{0}} + \\frac{y_{0} y_{0}^{\\top}}{y_{0}^{\\top} s_{0}}\n$$\n\n我们需要计算标量分母和外积矩阵。\n第一个分母是：\n$$\ns_{0}^{\\top} s_{0} = (-1)^{2} + \\left(-\\frac{1}{2}\\right)^{2} = 1 + \\frac{1}{4} = \\frac{5}{4}\n$$\n第二个分母是：\n$$\ny_{0}^{\\top} s_{0} = \\begin{pmatrix} -\\frac{5}{2}  -\\frac{5}{2} \\end{pmatrix} \\begin{pmatrix} -1 \\\\ -\\frac{1}{2} \\end{pmatrix} = \\left(-\\frac{5}{2}\\right)(-1) + \\left(-\\frac{5}{2}\\right)\\left(-\\frac{1}{2}\\right) = \\frac{5}{2} + \\frac{5}{4} = \\frac{15}{4}\n$$\n值 $y_{0}^{\\top} s_{0}$ 必须为正，以确保 $B_{1}$ 可以是正定的，这一点在此成立。\n\n问题要求计算 $B_{1}$ 的 (1,2) 项，我们记作 $(B_{1})_{1,2}$。我们可以直接计算这个元素，而无需构建整个矩阵 $B_1$：\n$$\n(B_{1})_{1,2} = (I)_{1,2} - \\frac{(s_{0} s_{0}^{\\top})_{1,2}}{s_{0}^{\\top} s_{0}} + \\frac{(y_{0} y_{0}^{\\top})_{1,2}}{y_{0}^{\\top} s_{0}}\n$$\n单位矩阵 $I$ 的 (1,2) 项是 $0$。\n外积矩阵的元素为：\n$$\n(s_{0} s_{0}^{\\top})_{1,2} = (s_{0})_{1} (s_{0})_{2} = (-1)\\left(-\\frac{1}{2}\\right) = \\frac{1}{2}\n$$\n$$\n(y_{0} y_{0}^{\\top})_{1,2} = (y_{0})_{1} (y_{0})_{2} = \\left(-\\frac{5}{2}\\right)\\left(-\\frac{5}{2}\\right) = \\frac{25}{4}\n$$\n将这些值代入 $(B_{1})_{1,2}$ 的表达式中：\n$$\n(B_{1})_{1,2} = 0 - \\frac{\\frac{1}{2}}{\\frac{5}{4}} + \\frac{\\frac{25}{4}}{\\frac{15}{4}}\n$$\n$$\n(B_{1})_{1,2} = -\\left(\\frac{1}{2} \\cdot \\frac{4}{5}\\right) + \\frac{25}{15} = -\\frac{4}{10} + \\frac{5}{3} = -\\frac{2}{5} + \\frac{5}{3}\n$$\n$$\n(B_{1})_{1,2} = \\frac{-2 \\cdot 3 + 5 \\cdot 5}{15} = \\frac{-6 + 25}{15} = \\frac{19}{15}\n$$\n\n简要解释：\n$B_{1}$ 中出现非对角项，是因为更新过程包含了关于目标函数真实曲率的信息，而这些信息被编码在非对角的海森矩阵 $Q$ 中。初始近似 $B_{0}=I$ 假设变量之间没有耦合。BFGS 更新修正了这一点。更新的核心是满足割线方程 $B_{1}s_0 = y_0$。这里，$s_0 = (-1, -1/2)^\\top$ 且 $y_0 = (-5/2, -5/2)^\\top$。由于 $y_0$ 不是 $s_0$ 的标量倍数，执行此映射所需的矩阵 $B_1$ 不能是单位矩阵的倍数；它必须包含非对角项来表示真实海森矩阵的旋转和剪切效应。BFGS 公式中的 $\\frac{y_0 y_0^\\top}{y_0^\\top s_0}$ 项明确地引入了这种耦合。向量 $y_0=Q s_0$ 捕捉了真实海森矩阵 $Q$ 对步长 $s_0$ 的影响。外积 $y_0 y_0^\\top$ 创建了一个秩一矩阵，其结构反映了这种相互作用。因为 $y_0$ 的两个分量都非零，所以 $y_0 y_0^\\top$ 的非对角项也非零，从而将观察到的曲率耦合注入到新的海森矩阵近似 $B_1$ 中。", "answer": "$$\\boxed{\\frac{19}{15}}$$", "id": "3170225"}, {"introduction": "虽然BFGS方法因其稳健性而广受欢迎，但它强制保持Hessian矩阵正定性的特性，在处理非凸问题（例如包含鞍点的函数）时也可能成为一种限制。本练习 [@problem_id:3170247] 通过一个精心设计的例子，对比了BFGS和对称秩一（SR1）更新在面对不定Hessian时的不同表现。您将分析为何SR1方法能够捕捉到负曲率信息，从而可能更有效地逃离鞍点，这揭示了不同拟牛顿方法在算法设计哲学上的根本差异。", "problem": "考虑无约束最小化问题，其二次模型函数为 $f:\\mathbb{R}^{2}\\to\\mathbb{R}$，由 $f(x)=\\tfrac{1}{2}x^{\\top}Qx$ 给出，其中 $Q=\\begin{pmatrix}1  0\\\\ 0  -0.2\\end{pmatrix}$。您观察到两个连续的迭代点 $x_{k}$ 和 $x_{k+1}$，其位移为 $s_{k}=x_{k+1}-x_{k}=\\begin{pmatrix}1\\\\ 1\\end{pmatrix}$。令 $g(x)=\\nabla f(x)=Qx$，则梯度位移为 $y_{k}=g(x_{k+1})-g(x_{k})$。取初始Hessian近似矩阵为 $B_{k}=I$。\n\n仅使用拟牛顿法通过割线方程和对称性所施加的基本定义，以及对称秩一（SR1）和Broyden–Fletcher–Goldfarb–Shanno（BFGS）Hessian更新的标准构造原则，完成以下任务：\n\n1) 根据 $Q$ 和 $s_{k}$ 计算 $y_{k}$。\n\n2) 使用 $B_{k}$ 和曲率对 $(s_{k},y_{k})$ 进行SR1 Hessian更新，构造 $B_{k+1}^{\\text{SR1}}$。使用 $B_{k}$ 和相同的 $(s_{k},y_{k})$ 进行BFGS Hessian更新，构造 $B_{k+1}^{\\text{BFGS}}$。利用向量 $(y_{k}-B_{k}s_{k})$ 解释为什么SR1更新能够引入与 $Q$ 的鞍点方向一致的负曲率，而BFGS更新在条件 $s_{k}^{\\top}y_{k}>0$ 下保持正定性。\n\n3) 令 $x_{k+1}=\\begin{pmatrix}0\\\\ 1\\end{pmatrix}$，从而得到 $g_{k+1}=g(x_{k+1})$。从每个更新后的Hessian矩阵出发，构造一个拟牛顿步，$p_{k+1}^{\\text{SR1}}=-\\left(B_{k+1}^{\\text{SR1}}\\right)^{-1}g_{k+1}$ 和 $p_{k+1}^{\\text{BFGS}}=-\\left(B_{k+1}^{\\text{BFGS}}\\right)^{-1}g_{k+1}$。\n\n4) $Q$ 的负曲率特征方向是单位向量 $v_{-}=\\begin{pmatrix}0\\\\ 1\\end{pmatrix}$。计算余弦平方 $\\cos^{2}(\\theta_{\\text{SR1}})$ 和 $\\cos^{2}(\\theta_{\\text{BFGS}})$，其中 $\\theta_{\\text{method}}$ 是 $p_{k+1}^{\\text{method}}$ 和 $v_{-}$ 之间的夹角。然后计算比率\n$$\nR=\\frac{\\cos^{2}(\\theta_{\\text{SR1}})}{\\cos^{2}(\\theta_{\\text{BFGS}})}.\n$$\n\n将 $R$ 的最终结果表示为一个简化的精确分数。无需四舍五入。", "solution": "该问题已经过验证，被认为是科学上合理的、适定的和客观的。所有数据和条件都是自洽且一致的。我们可以开始求解。\n\n该问题要求对一个具有不定Hessian矩阵的二次函数，进行一系列与SR1和BFGS拟牛顿更新相关的计算。我们将按顺序解决问题的四个部分。\n\n函数为 $f(x)=\\tfrac{1}{2}x^{\\top}Qx$，其中 $Q=\\begin{pmatrix}1  0\\\\ 0  -0.2\\end{pmatrix}$。\n梯度为 $g(x)=\\nabla f(x)=Qx$。\n初始Hessian近似矩阵为 $B_{k}=I=\\begin{pmatrix}1  0\\\\ 0  1\\end{pmatrix}$。\n位移向量为 $s_{k}=x_{k+1}-x_{k}=\\begin{pmatrix}1\\\\ 1\\end{pmatrix}$。\n\n**第1部分：计算 $y_{k}$**\n梯度位移 $y_{k}$ 定义为 $y_{k}=g(x_{k+1})-g(x_{k})$。由于 $g(x)=Qx$ 是 $x$ 的线性函数，我们可以写出：\n$$y_{k} = Qx_{k+1} - Qx_{k} = Q(x_{k+1}-x_{k}) = Qs_{k}$$\n将给定的矩阵 $Q$ 和 $s_{k}$ 代入：\n$$y_{k} = \\begin{pmatrix}1  0\\\\ 0  -0.2\\end{pmatrix} \\begin{pmatrix}1\\\\ 1\\end{pmatrix} = \\begin{pmatrix}(1)(1) + (0)(1)\\\\ (0)(1) + (-0.2)(1)\\end{pmatrix} = \\begin{pmatrix}1\\\\ -0.2\\end{pmatrix}$$\n\n**第2部分：构造 $B_{k+1}^{\\text{SR1}}$ 和 $B_{k+1}^{\\text{BFGS}}$ 并进行分析**\n首先，我们计算必要的中间量。\n曲率条件项为 $s_{k}^{\\top}y_{k}$：\n$$s_{k}^{\\top}y_{k} = \\begin{pmatrix}1  1\\end{pmatrix} \\begin{pmatrix}1\\\\ -0.2\\end{pmatrix} = (1)(1) + (1)(-0.2) = 1 - 0.2 = 0.8$$\n由于 $s_{k}^{\\top}y_{k} > 0$，标准的BFGS更新是适定的，并将保持 $B_{k}$ 的正定性。\n\n对于SR1更新，我们需要向量 $y_{k}-B_{k}s_{k}$：\n$$B_{k}s_{k} = I s_{k} = \\begin{pmatrix}1  0\\\\ 0  1\\end{pmatrix} \\begin{pmatrix}1\\\\ 1\\end{pmatrix} = \\begin{pmatrix}1\\\\ 1\\end{pmatrix}$$\n$$y_{k}-B_{k}s_{k} = \\begin{pmatrix}1\\\\ -0.2\\end{pmatrix} - \\begin{pmatrix}1\\\\ 1\\end{pmatrix} = \\begin{pmatrix}0\\\\ -1.2\\end{pmatrix}$$\nSR1更新的分母是 $(y_{k}-B_{k}s_{k})^{\\top}s_{k}$：\n$$(y_{k}-B_{k}s_{k})^{\\top}s_{k} = \\begin{pmatrix}0  -1.2\\end{pmatrix} \\begin{pmatrix}1\\\\ 1\\end{pmatrix} = (0)(1) + (-1.2)(1) = -1.2$$\n由于此分母非零，SR1更新是适定的。\n\n现在，我们构造更新后的Hessian近似矩阵。\nSR1更新公式为：\n$$B_{k+1}^{\\text{SR1}} = B_{k} + \\frac{(y_{k}-B_{k}s_{k})(y_{k}-B_{k}s_{k})^{\\top}}{(y_{k}-B_{k}s_{k})^{\\top}s_{k}}$$\n$$B_{k+1}^{\\text{SR1}} = \\begin{pmatrix}1  0\\\\ 0  1\\end{pmatrix} + \\frac{1}{-1.2} \\begin{pmatrix}0\\\\ -1.2\\end{pmatrix} \\begin{pmatrix}0  -1.2\\end{pmatrix} = \\begin{pmatrix}1  0\\\\ 0  1\\end{pmatrix} - \\frac{1}{1.2} \\begin{pmatrix}0  0\\\\ 0  1.44\\end{pmatrix}$$\n$$B_{k+1}^{\\text{SR1}} = \\begin{pmatrix}1  0\\\\ 0  1\\end{pmatrix} - \\begin{pmatrix}0  0\\\\ 0  1.2\\end{pmatrix} = \\begin{pmatrix}1  0\\\\ 0  -0.2\\end{pmatrix}$$\n值得注意的是，$B_{k+1}^{\\text{SR1}} = Q$。SR1更新在一步之内就恢复了二次函数的精确Hessian矩阵。\n\nBFGS更新公式为：\n$$B_{k+1}^{\\text{BFGS}} = B_{k} - \\frac{B_{k}s_{k}s_{k}^{\\top}B_{k}}{s_{k}^{\\top}B_{k}s_{k}} + \\frac{y_{k}y_{k}^{\\top}}{y_{k}^{\\top}s_{k}}$$\n我们需要以下各项 $s_{k}^{\\top}B_{k}s_{k} = s_{k}^{\\top}Is_{k} = s_{k}^{\\top}s_{k} = 1^{2}+1^{2}=2$ 和 $B_{k}s_{k} = s_{k}$。\n$$s_{k}s_{k}^{\\top} = \\begin{pmatrix}1\\\\ 1\\end{pmatrix}\\begin{pmatrix}1  1\\end{pmatrix} = \\begin{pmatrix}1  1\\\\ 1  1\\end{pmatrix}$$\n$$y_{k}y_{k}^{\\top} = \\begin{pmatrix}1\\\\ -0.2\\end{pmatrix}\\begin{pmatrix}1  -0.2\\end{pmatrix} = \\begin{pmatrix}1  -0.2\\\\ -0.2  0.04\\end{pmatrix}$$\n代入BFGS公式：\n$$B_{k+1}^{\\text{BFGS}} = \\begin{pmatrix}1  0\\\\ 0  1\\end{pmatrix} - \\frac{1}{2}\\begin{pmatrix}1  1\\\\ 1  1\\end{pmatrix} + \\frac{1}{0.8}\\begin{pmatrix}1  -0.2\\\\ -0.2  0.04\\end{pmatrix}$$\n$$B_{k+1}^{\\text{BFGS}} = \\begin{pmatrix}1  0\\\\ 0  1\\end{pmatrix} - \\begin{pmatrix}0.5  0.5\\\\ 0.5  0.5\\end{pmatrix} + \\begin{pmatrix}1.25  -0.25\\\\ -0.25  0.05\\end{pmatrix}$$\n$$B_{k+1}^{\\text{BFGS}} = \\begin{pmatrix}1-0.5+1.25  0-0.5-0.25 \\\\ 0-0.5-0.25  1-0.5+0.05\\end{pmatrix} = \\begin{pmatrix}1.75  -0.75\\\\ -0.75  0.55\\end{pmatrix}$$\n\n分析：向量 $y_{k}-B_{k}s_{k}$ 表示观测到的梯度变化 $y_{k}$ 与当前Hessian模型 $B_{k}$ 预测的变化之间的差异。\nSR1更新公式直接将此差异向量并入一个秩一校正中：$B_{k+1} = B_{k} + \\frac{v v^{\\top}}{v^{\\top}s_{k}}$，其中 $v = y_{k}-B_{k}s_{k}$。在本题中，分母 $v^{\\top}s_{k} = -1.2$ 为负。这意味着加到 $B_{k}$ 上的秩一矩阵是负半定的。这使得SR1更新能够减小Hessian近似矩阵的特征值，并且在这个特定情况下，它引入了一个负特征值，从而正确地识别了 $Q$ 的负曲率。\n相比之下，BFGS更新的构造是为了在曲率条件 $y_{k}^{\\top}s_{k}>0$ 成立时保持正定性。尽管它也源于相同的割线方程 $B_{k+1}s_{k}=y_{k}$，但其结构是 $B_{k}$（减去一个秩一矩阵）与另一个秩一矩阵 $\\frac{y_{k}y_{k}^{\\top}}{y_{k}^{\\top}s_{k}}$ 的和，这保证了如果 $B_{k}$ 是正定的，$B_{k+1}^{\\text{BFGS}}$ 也将保持正定。它不能引入负曲率。它有效地“平均”了包含在曲率对 $(s_{k}, y_{k})$ 中的曲率信息，从而产生一个安全的、正定的模型，即使真实的Hessian矩阵是不定的。\n\n**第3部分：拟牛顿步**\n给定 $x_{k+1}=\\begin{pmatrix}0\\\\ 1\\end{pmatrix}$。该点的梯度为：\n$$g_{k+1} = g(x_{k+1}) = Qx_{k+1} = \\begin{pmatrix}1  0\\\\ 0  -0.2\\end{pmatrix} \\begin{pmatrix}0\\\\ 1\\end{pmatrix} = \\begin{pmatrix}0\\\\ -0.2\\end{pmatrix}$$\n搜索方向为 $p_{k+1} = -B_{k+1}^{-1}g_{k+1}$。\n\n对于SR1更新：\n$$B_{k+1}^{\\text{SR1}} = Q = \\begin{pmatrix}1  0\\\\ 0  -0.2\\end{pmatrix} \\implies (B_{k+1}^{\\text{SR1}})^{-1} = \\begin{pmatrix}1  0\\\\ 0  -5\\end{pmatrix}$$\n$$p_{k+1}^{\\text{SR1}} = -\\begin{pmatrix}1  0\\\\ 0  -5\\end{pmatrix} \\begin{pmatrix}0\\\\ -0.2\\end{pmatrix} = -\\begin{pmatrix}0\\\\ 1\\end{pmatrix} = \\begin{pmatrix}0\\\\ -1\\end{pmatrix}$$\n\n对于BFGS更新：\n$$B_{k+1}^{\\text{BFGS}} = \\begin{pmatrix}1.75  -0.75\\\\ -0.75  0.55\\end{pmatrix} = \\begin{pmatrix}\\frac{7}{4}  -\\frac{3}{4}\\\\ -\\frac{3}{4}  \\frac{11}{20}\\end{pmatrix}$$\n行列式为 $\\det(B_{k+1}^{\\text{BFGS}}) = (\\frac{7}{4})(\\frac{11}{20}) - (-\\frac{3}{4})^{2} = \\frac{77}{80} - \\frac{9}{16} = \\frac{77-45}{80} = \\frac{32}{80} = \\frac{2}{5}$。\n逆矩阵为：\n$$(B_{k+1}^{\\text{BFGS}})^{-1} = \\frac{1}{2/5} \\begin{pmatrix}\\frac{11}{20}  \\frac{3}{4}\\\\ \\frac{3}{4}  \\frac{7}{4}\\end{pmatrix} = \\frac{5}{2} \\begin{pmatrix}\\frac{11}{20}  \\frac{15}{20}\\\\ \\frac{15}{20}  \\frac{35}{20}\\end{pmatrix} = \\frac{1}{8} \\begin{pmatrix}11  15\\\\ 15  35\\end{pmatrix}$$\n搜索方向为：\n$$p_{k+1}^{\\text{BFGS}} = -\\frac{1}{8} \\begin{pmatrix}11  15\\\\ 15  35\\end{pmatrix} \\begin{pmatrix}0\\\\ -0.2\\end{pmatrix} = -\\frac{1}{8} \\begin{pmatrix}11  15\\\\ 15  35\\end{pmatrix} \\begin{pmatrix}0\\\\ -\\frac{1}{5}\\end{pmatrix}$$\n$$p_{k+1}^{\\text{BFGS}} = -\\frac{1}{8} \\begin{pmatrix}-3\\\\ -7\\end{pmatrix} = \\begin{pmatrix}\\frac{3}{8}\\\\ \\frac{7}{8}\\end{pmatrix}$$\n\n**第4部分：计算比率R**\n$Q$ 的负曲率特征方向是 $v_{-}=\\begin{pmatrix}0\\\\ 1\\end{pmatrix}$。我们有 $\\|v_{-}\\| = 1$。向量 $p$ 和 $v_{-}$ 之间夹角 $\\theta$ 的余弦平方由 $\\cos^{2}(\\theta) = \\frac{(p^{\\top}v_{-})^{2}}{\\|p\\|^{2}\\|v_{-}\\|^{2}} = \\frac{(p^{\\top}v_{-})^{2}}{\\|p\\|^{2}}$ 给出。\n\n对于SR1步：\n$$p_{k+1}^{\\text{SR1}} = \\begin{pmatrix}0\\\\ -1\\end{pmatrix}$$\n$$p_{k+1}^{\\text{SR1}\\top}v_{-} = \\begin{pmatrix}0  -1\\end{pmatrix}\\begin{pmatrix}0\\\\ 1\\end{pmatrix} = -1$$\n$$\\|p_{k+1}^{\\text{SR1}}\\|^{2} = 0^{2} + (-1)^{2} = 1$$\n$$\\cos^{2}(\\theta_{\\text{SR1}}) = \\frac{(-1)^{2}}{1} = 1$$\n\n对于BFGS步：\n$$p_{k+1}^{\\text{BFGS}} = \\begin{pmatrix}\\frac{3}{8}\\\\ \\frac{7}{8}\\end{pmatrix}$$\n$$p_{k+1}^{\\text{BFGS}\\top}v_{-} = \\begin{pmatrix}\\frac{3}{8}  \\frac{7}{8}\\end{pmatrix}\\begin{pmatrix}0\\\\ 1\\end{pmatrix} = \\frac{7}{8}$$\n$$\\|p_{k+1}^{\\text{BFGS}}\\|^{2} = \\left(\\frac{3}{8}\\right)^{2} + \\left(\\frac{7}{8}\\right)^{2} = \\frac{9}{64} + \\frac{49}{64} = \\frac{58}{64} = \\frac{29}{32}$$\n$$\\cos^{2}(\\theta_{\\text{BFGS}}) = \\frac{(\\frac{7}{8})^{2}}{\\frac{29}{32}} = \\frac{\\frac{49}{64}}{\\frac{29}{32}} = \\frac{49}{64} \\cdot \\frac{32}{29} = \\frac{49}{2 \\cdot 29} = \\frac{49}{58}$$\n\n最后，我们计算比率 $R$：\n$$R = \\frac{\\cos^{2}(\\theta_{\\text{SR1}})}{\\cos^{2}(\\theta_{\\text{BFGS}})} = \\frac{1}{\\frac{49}{58}} = \\frac{58}{49}$$", "answer": "$$\\boxed{\\frac{58}{49}}$$", "id": "3170247"}, {"introduction": "理论的深刻理解最终要通过解决实际问题来检验。在现实世界的优化任务中，目标函数往往是非凸的，这给BFGS等方法的稳定性带来了挑战。本编程练习 [@problem_id:3170188] 旨在将前面练习的理论洞察应用于实践，指导您实现一种带“重启”策略的BFGS算法。当算法检测到曲率信息不可靠时（$s_k^\\top y_k$ 过小或为负），通过将Hessian近似重置为单位矩阵，可以帮助算法摆脱病态区域，显著提升其在非凸问题上的鲁棒性和收敛成功率。", "problem": "考虑在 $\\mathbb{R}^n$ 中使用拟牛顿法对一个二次连续可微的目标函数进行无约束平滑最小化。您需要研究 Broyden–Fletcher–Goldfarb–Shanno (BFGS) 方法在应用于非凸目标函数时重启策略的作用。从基本原理出发：对于无约束最小化问题，最速下降方向是负梯度，而牛顿法使用海森矩阵（Hessian）来生成搜索方向。拟牛顿法旨在仅使用梯度评估来迭代地逼近逆海森矩阵，并强制执行能捕捉沿迭代点采样的局部曲率的割线方程。割线方程表明，逆海森矩阵的近似 $H_{k+1}$ 应满足 $H_{k+1} y_k = s_k$，其中 $s_k = x_{k+1} - x_k$，$y_k = \\nabla f(x_{k+1}) - \\nabla f(x_k)$。$H_k$ 的正定性对于生成下降方向 $p_k = -H_k \\nabla f(x_k)$ 至关重要。\n\n您的任务是：\n- 从割线方程和一个在合适范数下的最小变化原则出发，推导出一个保持割线方程的对称正定逆矩阵更新，并证明该更新保持正定性的条件。\n- 实现一个 BFGS 类型的拟牛顿法，该方法使用满足 Armijo 充分下降条件的回溯线搜索。三角函数内的角度必须以弧度处理。\n- 引入一个重启策略：当曲率度量 $s_k^\\top y_k$ 相对于 $\\|s_k\\| \\, \\|y_k\\|$ 过小时，将逆矩阵近似重置为单位矩阵。在特定的非凸目标上比较使用和不使用此类重启的运行情况，并量化鲁棒性的提升。\n\n在 $\\mathbb{R}^2$ 中使用以下非凸目标函数：\n$$\nf(x_1,x_2) = \\tfrac{1}{2}(x_1^2 - x_2^2) + 0.1(x_1^4 + x_2^4) + 2\\cos(x_1) + 2\\cos(x_2),\n$$\n其中 $\\cos(\\cdot)$ 中的所有角度均以弧度为单位。梯度是关于 $x_1$ 和 $x_2$ 的偏导数向量。\n\n实现算法，该算法：\n- 将 $H_0$ 初始化为单位矩阵。\n- 在第 $k$ 次迭代时，形成搜索方向 $p_k = -H_k \\nabla f(x_k)$。\n- 使用回溯线搜索找到一个步长 $\\alpha_k$，该步长满足 Armijo 条件 $f(x_k + \\alpha_k p_k) \\le f(x_k) + c_1 \\alpha_k \\nabla f(x_k)^\\top p_k$，其中 $c_1 \\in (0,1)$。\n- 更新 $x_{k+1} = x_k + \\alpha_k p_k$，$s_k = x_{k+1} - x_k$ 以及 $y_k = \\nabla f(x_{k+1}) - \\nabla f(x_k)$。\n- 在曲率条件 $s_k^\\top y_k > 0$ 成立时，应用强制执行割线方程并保持对称性和正定性的逆海森矩阵更新。\n- 引入重启规则，当启用时，如果对于给定的阈值 $\\tau \\ge 0$ 满足 $s_k^\\top y_k \\le \\tau \\|s_k\\| \\, \\|y_k\\|$，则重置 $H_{k+1} = I$；否则，如果 $s_k^\\top y_k > 0$，则执行逆矩阵更新。如果搜索方向不是下降方向（即 $\\nabla f(x_k)^\\top p_k \\ge 0$），则强制执行保障措施以确保下降。\n\n将收敛定义为在最大迭代次数内，对于给定的容差 $\\varepsilon > 0$，满足 $\\|\\nabla f(x_k)\\| \\le \\varepsilon$。\n\n测试套件：\n- 对所有运行使用以下通用设置：容差 $\\varepsilon = 10^{-5}$，最大迭代次数 $300$，回溯参数 $c_1 = 10^{-4}$，步长缩减因子 $0.5$，以及每次迭代最多 $50$ 次回溯缩减。\n- 将算法应用于以下初始点集 $x_0 \\in \\mathbb{R}^2$：\n$$\n[-3,-3],\\ [2,2],\\ [4,-4],\\ [0.1,-0.1],\\ [-2.5,2.25],\\ [5,5],\\ [-5,5].\n$$\n- 评估以下五个参数案例：\n    1. 无重启：重启功能禁用（忽略 $\\tau$）。\n    2. 启用重启，$\\tau = 10^{-8}$。\n    3. 启用重启，$\\tau = 10^{-4}$。\n    4. 启用重启，$\\tau = 10^{-2}$。\n    5. 启用重启，$\\tau = 5 \\times 10^{-1}$。\n\n对于每个参数案例，针对整套初始点，计算：\n- 成功运行的整数计数（收敛的初始点数量）。\n- 仅在成功运行上的平均迭代次数，表示为实数（使用算术平均值；如果成功次数为零，则报告 $0.0$）。\n- 每次成功运行的平均回溯缩减次数，表示为实数（如果成功次数为零，则报告 $0.0$）。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。按上述顺序列出每个参数案例的三个数字，最终得到一个长度为 $15$ 的列表：\n$$\n[\\text{succ}_1,\\ \\text{mean\\_iters}_1,\\ \\text{mean\\_backs}_1,\\ \\ldots,\\ \\text{succ}_5,\\ \\text{mean\\_iters}_5,\\ \\text{mean\\_backs}_5].\n$$", "solution": "该问题要求推导 Broyden–Fletcher–Goldfarb–Shanno (BFGS) 逆海森矩阵更新，分析其正定性，并实现一个基于 BFGS 的拟牛顿优化器。此优化器将包含回溯线搜索和用于处理非凸性的重启策略。该算法在有无重启策略的情况下，其性能将在一个给定的非凸目标函数上进行评估。\n\n### 第 1 部分：BFGS 更新的推导与分析\n\n拟牛顿法构建一个矩阵序列 $\\{H_k\\}$，用以逼近目标函数 $f(x)$ 的逆海森矩阵。从 $H_k$ 到 $H_{k+1}$ 的更新必须满足捕捉曲率信息的割线方程。\n\n**割线方程**\n割线方程要求新的逆海森矩阵近似 $H_{k+1}$ 将梯度变化量 $y_k$ 映射到位置变化量 $s_k$：\n$$H_{k+1} y_k = s_k$$\n其中 $s_k = x_{k+1} - x_k$ 且 $y_k = \\nabla f(x_{k+1}) - \\nabla f(x_k)$。\n\n**从最小变化原则推导**\nBFGS 更新是通过寻找对海森矩阵近似 $B_k = H_k^{-1}$ 的更新来推导的，该更新需满足对称性、其版本的割线方程 ($B_{k+1}s_k = y_k$)，并且在合适的范数下与 $B_k$ 最接近。BFGS 的“最小变化”原则通常表述为求解关于校正量 $E = B_{k+1} - B_k$ 的以下优化问题：\n$$\n\\min_{E} \\|E\\| \\quad \\text{subject to} \\quad E=E^\\top \\text{ and } (B_k+E)s_k = y_k\n$$\n选择一个特定的加权弗罗贝尼乌斯范数（weighted Frobenius norm）会导出海森矩阵近似 $B_{k+1}$ 的 BFGS 更新公式：\n$$B_{k+1} = B_k + \\frac{y_k y_k^\\top}{y_k^\\top s_k} - \\frac{B_k s_k s_k^\\top B_k}{s_k^\\top B_k s_k}$$\n相应的逆海森矩阵近似 $H_{k+1} = B_{k+1}^{-1}$ 的更新可以通过两次应用 Sherman-Morrison-Woodbury 公式得到。这个过程产生了广泛使用的 BFGS 逆矩阵更新公式：\n$$H_{k+1} = \\left(I - \\frac{s_k y_k^\\top}{y_k^\\top s_k}\\right) H_k \\left(I - \\frac{y_k s_k^\\top}{y_k^\\top s_k}\\right) + \\frac{s_k s_k^\\top}{y_k^\\top s_k}$$\n其中 $I$ 是单位矩阵。这是最有效的拟牛顿更新公式之一。\n\n**保持正定性的条件**\nBFGS 更新的一个关键特性是它能够保持海森矩阵近似的正定性，这确保了搜索方向 $p_k = -H_k \\nabla f(x_k)$ 是一个下降方向。假设 $H_k$ 是对称正定的。我们希望找到 $H_{k+1}$ 也保持正定的条件。\n\n对于任意非零向量 $z \\in \\mathbb{R}^n$，我们考察二次型 $z^\\top H_{k+1} z$：\n$$z^\\top H_{k+1} z = z^\\top \\left(I - \\frac{s_k y_k^\\top}{y_k^\\top s_k}\\right) H_k \\left(I - \\frac{y_k s_k^\\top}{y_k^\\top s_k}\\right) z + z^\\top \\left(\\frac{s_k s_k^\\top}{y_k^\\top s_k}\\right) z$$\n令 $V = I - \\frac{s_k y_k^\\top}{y_k^\\top s_k}$。表达式变为：\n$$z^\\top H_{k+1} z = z^\\top V H_k V^\\top z + \\frac{(z^\\top s_k)^2}{y_k^\\top s_k} = (V^\\top z)^\\top H_k (V^\\top z) + \\frac{(z^\\top s_k)^2}{y_k^\\top s_k}$$\n由于 $H_k$ 是正定的，第一项 $(V^\\top z)^\\top H_k (V^\\top z)$ 是非负的。除非 $V^\\top z = 0$，否则它为严格正。\n为了使对于所有 $z \\neq 0$ 都有 $z^\\top H_{k+1} z > 0$，第二项 $\\frac{(z^\\top s_k)^2}{y_k^\\top s_k}$ 起着关键作用。其分母 $y_k^\\top s_k$ 必须为正。如果 $y_k^\\top s_k \\le 0$，我们无法保证正定性。\n如果我们假设**曲率条件** $s_k^\\top y_k > 0$ 成立，那么第二项 $\\frac{(z^\\top s_k)^2}{y_k^\\top s_k}$ 总是非负的。仅当两项都为零时，和才为零，这意味着 $(V^\\top z)^\\top H_k (V^\\top z) = 0$ 且 $(z^\\top s_k)^2 = 0$。这只在 $z=0$ 时发生。\n因此，如果 $H_k$ 是正定的，那么当且仅当曲率条件 $s_k^\\top y_k > 0$ 满足时，$H_{k+1}$ 保持正定。这个条件意味着函数 $f$ 沿线段 $s_k$ 的平均曲率为正。\n\n### 第 2 部分：算法实现\n\n该算法是一个带有回溯线搜索和用于处理非凸性的重启策略的 BFGS 拟牛顿法。\n\n**目标函数及其梯度**\n目标函数是 $f: \\mathbb{R}^2 \\to \\mathbb{R}$：\n$$ f(x_1,x_2) = \\tfrac{1}{2}(x_1^2 - x_2^2) + 0.1(x_1^4 + x_2^4) + 2\\cos(x_1) + 2\\cos(x_2) $$\n其梯度为 $\\nabla f(x_1, x_2) = [\\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2}]^\\top$：\n$$ \\nabla f(x_1, x_2) = \\begin{bmatrix} x_1 + 0.4x_1^3 - 2\\sin(x_1) \\\\ -x_2 + 0.4x_2^3 - 2\\sin(x_2) \\end{bmatrix} $$\n\n**算法步骤**\n1.  **初始化**：给定起始点 $x_0$，容差 $\\varepsilon = 10^{-5}$，最大迭代次数 $N_{max}=300$。初始化逆海森矩阵近似 $H_0 = I$（单位矩阵）。设置迭代计数器 $k=0$。\n\n2.  **收敛性检查**：在每次迭代 $k$ 时，计算梯度 $\\nabla f(x_k)$。如果 $\\|\\nabla f(x_k)\\| \\le \\varepsilon$，则算法收敛。\n\n3.  **搜索方向**：计算搜索方向 $p_k = -H_k \\nabla f(x_k)$。\n\n4.  **下降方向保障措施**：通过评估 $\\nabla f(x_k)^\\top p_k$ 来检查 $p_k$ 是否为下降方向。如果 $H_k$ 是正定的，这个值将是负的。如果由于数值问题或非正定的 $H_k$ 导致 $\\nabla f(x_k)^\\top p_k \\ge 0$，则该方向不是下降方向。保障措施将搜索方向重置为最速下降方向 $p_k = -\\nabla f(x_k)$，并重置 $H_k = I$ 以确保下一次迭代重新开始。\n\n5.  **线搜索**：使用回溯法找到一个步长 $\\alpha_k > 0$。从 $\\alpha_k=1.0$ 开始。当**Armijo 条件** $f(x_k + \\alpha_k p_k) \\le f(x_k) + c_1 \\alpha_k \\nabla f(x_k)^\\top p_k$ 不满足时（其中 $c_1=10^{-4}$），将 $\\alpha_k$ 乘以因子 $0.5$。此过程最多重复 $50$ 次。如果找不到合适的 $\\alpha_k$，则认为该次运行失败。\n\n6.  **更新位置**：更新迭代点：$x_{k+1} = x_k + \\alpha_k p_k$。\n\n7.  **带重启策略的海森矩阵近似更新**：\n    *   计算 $s_k = x_{k+1} - x_k$ 和 $y_k = \\nabla f(x_{k+1}) - \\nabla f(x_k)$。\n    *   计算曲率度量 $s_k^\\top y_k$ 和范数之积 $\\|s_k\\| \\|y_k\\|$。\n    *   **重启规则**：如果启用重启且对于给定的阈值 $\\tau$ 满足条件 $s_k^\\top y_k \\le \\tau \\|s_k\\| \\|y_k\\|$，则将逆海森矩阵近似重置为单位矩阵：$H_{k+1} = I$。这发生在曲率为负、零或不够正（即 $s_k$ 和 $y_k$ 之间的夹角较大）时。\n    *   **BFGS 更新**：如果不满足重启条件，则执行标准更新，但前提是曲率条件 $s_k^\\top y_k > 0$ 成立。这可以防止失去正定性。\n    *   **跳过更新**：如果重启规则未被触发，且正曲率条件也未满足（例如，在无重启情况下 $s_k^\\top y_k \\le 0$），则跳过更新：$H_{k+1} = H_k$。\n    *   为避免数值问题，当 $\\|s_k\\|$ 或 $\\|y_k\\|$ 接近于零时，也跳过更新。\n\n8.  **迭代**：增加 $k$ 并返回步骤 2。如果 $k$ 达到 $N_{max}$，则认为该次运行失败。\n\n### 第 3 部分：性能量化\n\n通过从 7 个初始点集对 5 种参数情况（一种无重启，四种不同 $\\tau$ 值）运行算法，来量化算法在不同重启策略下的鲁棒性和效率。对于每种情况，我们计算：\n1.  **成功计数**：算法从初始点收敛到满足 $\\|\\nabla f(x_k)\\| \\le 10^{-5}$ 的解的数量。\n2.  **平均迭代次数**：所有成功运行的迭代次数的算术平均值。如果没有成功运行，则为 $0.0$。\n3.  **平均回溯缩减次数**：所有成功运行的总回溯步长缩减次数的算术平均值。这表示线搜索的成本。如果没有成功运行，则为 $0.0$。\n\n比较这些跨参数案例的统计数据，可以揭示重启策略对算法在非凸环境中解决问题能力的影响。更高的成功计数表明更强的鲁棒性。在成功计数相近的情况下，较低的平均迭代次数和平均回溯缩减次数表明效率更高。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the BFGS experiments and print the results.\n    \"\"\"\n    \n    # ------------------ Problem Definition ------------------\n    \n    def f(x):\n        \"\"\"Nonconvex objective function.\"\"\"\n        x1, x2 = x[0], x[1]\n        return (0.5 * (x1**2 - x2**2) + \n                0.1 * (x1**4 + x2**4) + \n                2.0 * np.cos(x1) + 2.0 * np.cos(x2))\n\n    def grad_f(x):\n        \"\"\"Gradient of the objective function.\"\"\"\n        x1, x2 = x[0], x[1]\n        df_dx1 = x1 + 0.4 * x1**3 - 2.0 * np.sin(x1)\n        df_dx2 = -x2 + 0.4 * x2**3 - 2.0 * np.sin(x2)\n        return np.array([df_dx1, df_dx2])\n\n    # ------------------ BFGS Solver Implementation ------------------\n\n    def bfgs_solver(x0, restart_enabled, tau, epsilon, max_iter, c1, shrink, max_bt):\n        \"\"\"\n        BFGS solver with optional restarts.\n        Returns: (success, iterations, total_backtracking_reductions)\n        \"\"\"\n        x = np.array(x0, dtype=float)\n        n = len(x)\n        H = np.identity(n)\n        \n        total_bt_reductions = 0\n        \n        for k in range(max_iter):\n            g = grad_f(x)\n            \n            if np.linalg.norm(g)  epsilon:\n                return True, k, total_bt_reductions\n\n            p = -H @ g\n            grad_dot_p = g @ p\n            \n            # Safeguard against non-descent directions\n            if grad_dot_p  0:\n                H = np.identity(n)\n                p = -g\n                grad_dot_p = g @ p\n\n            # Backtracking line search (Armijo condition)\n            alpha = 1.0\n            fx = f(x)\n            num_bt = 0\n            while num_bt  max_bt:\n                x_new = x + alpha * p\n                if f(x_new)  fx + c1 * alpha * grad_dot_p:\n                    break\n                alpha *= shrink\n                num_bt += 1\n            \n            if num_bt == max_bt:\n                # Line search failed to find a step\n                return False, k + 1, total_bt_reductions\n\n            total_bt_reductions += num_bt\n            \n            # Update variables\n            s = alpha * p\n            x_new = x + s\n            g_new = grad_f(x_new)\n            y = g_new - g\n            \n            # Update H. Note: x is updated at the end of the loop\n            norm_s = np.linalg.norm(s)\n            norm_y = np.linalg.norm(y)\n\n            # Avoid numerical instability with very small steps/gradient changes\n            if norm_s  1e-12 and norm_y  1e-12:\n                sTy = s @ y\n                perform_restart = restart_enabled and (sTy  tau * norm_s * norm_y)\n\n                if perform_restart:\n                    H = np.identity(n)\n                elif sTy  0:\n                    # BFGS inverse Hessian update formula\n                    # H_{k+1} = (I - rho*s*y.T) H (I - rho*y*s.T) + rho*s*s.T\n                    rho = 1.0 / sTy\n                    Hy = H @ y\n                    # Using a numerically stable expansion\n                    H += rho * (1.0 + rho * (y @ Hy)) * np.outer(s, s) - \\\n                         rho * (np.outer(Hy, s) + np.outer(s, Hy))\n                # else: curvature condition not met, skip update (H remains H)\n            \n            x = x_new\n\n        return False, max_iter, total_bt_reductions\n\n    # ------------------ Experiment Setup ------------------\n\n    # Common settings\n    epsilon = 1e-5\n    max_iter = 300\n    c1 = 1e-4\n    shrink_factor = 0.5\n    max_bt_reductions = 50\n\n    # Initial points\n    initial_points = [\n        [-3.0, -3.0], [2.0, 2.0], [4.0, -4.0], [0.1, -0.1],\n        [-2.5, 2.25], [5.0, 5.0], [-5.0, 5.0]\n    ]\n\n    # Parameter cases\n    parameter_cases = [\n        {'restart_enabled': False, 'tau': 0.0},       # Case 1: No restarts\n        {'restart_enabled': True, 'tau': 1e-8},       # Case 2\n        {'restart_enabled': True, 'tau': 1e-4},       # Case 3\n        {'restart_enabled': True, 'tau': 1e-2},       # Case 4\n        {'restart_enabled': True, 'tau': 5e-1}        # Case 5\n    ]\n    \n    final_results = []\n\n    # ------------------ Run Experiments and Collect Data ------------------\n    \n    for case in parameter_cases:\n        successful_runs = 0\n        successful_iters = []\n        successful_backs = []\n        \n        for x0 in initial_points:\n            success, iters, backs = bfgs_solver(\n                x0,\n                case['restart_enabled'],\n                case['tau'],\n                epsilon,\n                max_iter,\n                c1,\n                shrink_factor,\n                max_bt_reductions\n            )\n            \n            if success:\n                successful_runs += 1\n                successful_iters.append(iters)\n                successful_backs.append(backs)\n        \n        # Calculate statistics for the case\n        mean_iters = np.mean(successful_iters) if successful_iters else 0.0\n        mean_backs = np.mean(successful_backs) if successful_backs else 0.0\n        \n        final_results.extend([successful_runs, mean_iters, mean_backs])\n\n    # ------------------ Format and Print Output ------------------\n    \n    # Format the results into the required string format\n    output_str = \",\".join(map(str, final_results))\n    print(f\"[{output_str}]\")\n\n\nsolve()\n\n```", "id": "3170188"}]}