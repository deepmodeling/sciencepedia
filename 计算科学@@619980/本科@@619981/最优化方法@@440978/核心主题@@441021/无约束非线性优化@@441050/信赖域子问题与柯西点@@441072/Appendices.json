{"hands_on_practices": [{"introduction": "在我们探索信赖域方法的过程中，首先理解柯西点 (Cauchy point) 在何种理想情况下能够达到全局最优，是至关重要的一步。这个练习通过构造一个梯度向量 $g$ 恰好是海森矩阵 $B$ 的特征向量的特例，来揭示柯西点的几何本质，并帮助你深入理解其与二次模型曲率之间的关系。[@problem_id:3194326] 通过分析一个微小的扰动如何打破这种最优性，你将更清晰地认识到柯西点有效性的边界条件。", "problem": "考虑一个在当前迭代点定义的二次连续可微函数的二次模型所对应的信赖域子问题：\n$$m(p) = g^{\\mathsf{T}} p + \\frac{1}{2} p^{\\mathsf{T}} B p,$$\n其约束条件为\n$$\\|p\\| \\leq \\Delta,$$\n其中 $B$ 是对称正定矩阵，$g$ 是梯度，$\\Delta>0$ 是信赖域半径。全局解 $p^{\\star}$ 满足从 Karush-Kuhn-Tucker (KKT) 条件导出的一阶条件，而柯西点 $p_{\\mathrm{C}}$ 是二次模型在约束线段 $\\{-t g : t \\geq 0, \\|t g\\| \\leq \\Delta\\}$ 上的极小值点。\n\n你将分析一个具体实例及其扰动情况。\n\n1. 构造如下情形\n$$B = \\begin{pmatrix} 1  0 \\\\ 0  4 \\end{pmatrix}, \\quad g = \\begin{pmatrix} 2 \\\\ 0 \\end{pmatrix}, \\quad \\Delta = 3.$$\n仅使用基本定义和一阶最优性条件，确定全局极小值点 $p^{\\star}$ 和柯西点 $p_{\\mathrm{C}}$，并验证在此信赖域子问题中柯西点是最优的。\n\n2. 现在将梯度轻微扰动为\n$$\\tilde{g} = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix},$$\n保持 $B$ 和 $\\Delta$ 不变。使用相同的原理，确定全局极小值点 $\\tilde{p}^{\\star}$ 和柯西点 $\\tilde{p}_{\\mathrm{C}}$，并计算模型值的精确差值\n$$m(\\tilde{p}_{\\mathrm{C}}) - m(\\tilde{p}^{\\star}).$$\n请用精确分数表示最终答案。不要四舍五入。", "solution": "该问题要求在梯度向量的两种不同情况下分析一个信赖域子问题。二次模型由 $m(p) = g^{\\mathsf{T}} p + \\frac{1}{2} p^{\\mathsf{T}} B p$ 给出，约束条件为 $\\|p\\| \\leq \\Delta$，其中 $\\|\\cdot\\|$ 是欧几里得范数。\n\n该问题的全局极小值点 $p^{\\star}$ 由 Karush-Kuhn-Tucker (KKT) 条件刻画。拉格朗日函数为 $\\mathcal{L}(p, \\lambda) = m(p) + \\frac{\\lambda}{2} (p^{\\mathsf{T}}p - \\Delta^2)$。一阶最优性条件如下：\n$1$. $\\nabla_p \\mathcal{L}(p, \\lambda) = g + Bp + \\lambda p = 0 \\implies (B + \\lambda I)p = -g$\n$2$. $\\lambda \\geq 0$\n$3$. $\\|p\\| \\leq \\Delta$\n$4$. $\\lambda (\\|p\\|^2 - \\Delta^2) = 0$ (互补松弛性)\n$5$. $B + \\lambda I$ 必须是半正定的。由于已知 $B$ 是正定的，该条件对任意 $\\lambda \\geq 0$ 都成立。\n\n如果无约束极小值点 $p_U = -B^{-1}g$ 满足 $\\|p_U\\| \\le \\Delta$，则通过设 $\\lambda=0$，所有 KKT 条件都得到满足，且 $p^{\\star} = p_U$。否则，解位于边界上，即 $\\|p^{\\star}\\| = \\Delta$，这意味着 $\\lambda > 0$。\n\n柯西点 $p_{\\mathrm{C}}$ 是模型 $m(p)$ 在最速下降方向上、限于信赖域内的极小值点。也就是说，我们要对 $t \\geq 0$ 且满足 $\\|-tg\\| \\leq \\Delta$ 的 $t$ 最小化 $\\phi(t) = m(-tg)$。路径为 $p(t) = -tg$。约束变为 $t\\|g\\| \\leq \\Delta$，因此 $0 \\leq t \\leq \\Delta/\\|g\\|$。\n将 $p(t)$ 代入模型：\n$$ \\phi(t) = g^{\\mathsf{T}}(-tg) + \\frac{1}{2}(-tg)^{\\mathsf{T}}B(-tg) = -t\\|g\\|^2 + \\frac{t^2}{2}g^{\\mathsf{T}}Bg $$\n这是一个关于 $t$ 的二次函数。通过设 $\\phi'(t) = -\\|g\\|^2 + t(g^{\\mathsf{T}}Bg) = 0$ 来找到无约束极小值点，得到 $t^* = \\frac{\\|g\\|^2}{g^{\\mathsf{T}}Bg}$。\n由于 $B$ 是正定的，因此 $g^{\\mathsf{T}}Bg > 0$，所以 $\\phi(t)$ 是一个严格凸函数。在区间 $[0, \\Delta/\\|g\\|]$ 上的极小值点为 $t_{\\mathrm{C}} = \\min(t^*, \\Delta/\\|g\\|)$。柯西点则为 $p_{\\mathrm{C}} = -t_{\\mathrm{C}}g$。\n\n**第 1 部分：初始情况分析**\n\n给定的参数为：\n$$ B = \\begin{pmatrix} 1  0 \\\\ 0  4 \\end{pmatrix}, \\quad g = \\begin{pmatrix} 2 \\\\ 0 \\end{pmatrix}, \\quad \\Delta = 3 $$\n首先，我们求全局极小值点 $p^{\\star}$。我们计算无约束极小值点 $p_U$。$B$ 的逆矩阵是 $B^{-1} = \\begin{pmatrix} 1  0 \\\\ 0  1/4 \\end{pmatrix}$。\n$$ p_U = -B^{-1}g = -\\begin{pmatrix} 1  0 \\\\ 0  1/4 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} -2 \\\\ 0 \\end{pmatrix} $$\n我们检查其范数：$\\|p_U\\| = \\sqrt{(-2)^2 + 0^2} = 2$。\n由于 $\\|p_U\\| = 2 < \\Delta = 3$，无约束极小值点是可行的。因此，全局极小值点为 $p^{\\star} = p_U = \\begin{pmatrix} -2 \\\\ 0 \\end{pmatrix}$。\n\n接下来，我们求柯西点 $p_{\\mathrm{C}}$。我们在 $t \\in [0, \\Delta/\\|g\\|]$ 上最小化 $\\phi(t)$。首先，计算必要的量：\n$$ \\|g\\|^2 = 2^2 + 0^2 = 4 $$\n$$ g^{\\mathsf{T}}Bg = \\begin{pmatrix} 2  0 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 0  4 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 2  0 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 0 \\end{pmatrix} = 4 $$\n$t$ 的无约束极小值点是 $t^* = \\frac{\\|g\\|^2}{g^{\\mathsf{T}}Bg} = \\frac{4}{4} = 1$。\n$t$ 的可行区间是 $[0, 3/2]$。因为 $t^*=1$ 在此区间内，我们有 $t_{\\mathrm{C}} = 1$。\n柯西点为 $p_{\\mathrm{C}} = -t_{\\mathrm{C}}g = -1 \\cdot \\begin{pmatrix} 2 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} -2 \\\\ 0 \\end{pmatrix}$。\n\n比较结果，我们发现 $p_{\\mathrm{C}} = p^{\\star} = \\begin{pmatrix} -2 \\\\ 0 \\end{pmatrix}$。这验证了对于这个特定的子问题实例，柯西点是最优的。发生这种情况是因为梯度 $g$ 是 Hessian 矩阵 $B$ 的一个特征向量。\n\n**第 2 部分：扰动情况分析**\n\n现在的参数为：\n$$ B = \\begin{pmatrix} 1  0 \\\\ 0  4 \\end{pmatrix}, \\quad \\tilde{g} = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}, \\quad \\Delta = 3 $$\n首先，我们求新的全局极小值点 $\\tilde{p}^{\\star}$。我们从无约束极小值点 $\\tilde{p}_U$ 开始：\n$$ \\tilde{p}_U = -B^{-1}\\tilde{g} = -\\begin{pmatrix} 1  0 \\\\ 0  1/4 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} -2 \\\\ -1/4 \\end{pmatrix} $$\n我们检查其范数：$\\|\\tilde{p}_U\\| = \\sqrt{(-2)^2 + (-1/4)^2} = \\sqrt{4 + 1/16} = \\sqrt{65/16} = \\frac{\\sqrt{65}}{4}$。\n由于 $8^2 = 64$ 且 $9^2=81$，我们有 $8 < \\sqrt{65} < 9$。因此，$2 < \\frac{\\sqrt{65}}{4} < \\frac{9}{4} = 2.25$。因为 $\\|\\tilde{p}_U\\| \\approx 2.015 < \\Delta = 3$，无约束极小值点是可行的。全局极小值点为 $\\tilde{p}^{\\star} = \\tilde{p}_U = \\begin{pmatrix} -2 \\\\ -1/4 \\end{pmatrix}$。\n\n接下来，我们计算在该点的模型值 $m(\\tilde{p}^{\\star})$：\n$$ m(\\tilde{p}^{\\star}) = \\tilde{g}^{\\mathsf{T}}\\tilde{p}^{\\star} + \\frac{1}{2}(\\tilde{p}^{\\star})^{\\mathsf{T}}B\\tilde{p}^{\\star} $$\n$$ \\tilde{g}^{\\mathsf{T}}\\tilde{p}^{\\star} = \\begin{pmatrix} 2  1 \\end{pmatrix} \\begin{pmatrix} -2 \\\\ -1/4 \\end{pmatrix} = -4 - \\frac{1}{4} = -\\frac{17}{4} $$\n$$ (\\tilde{p}^{\\star})^{\\mathsf{T}}B\\tilde{p}^{\\star} = \\begin{pmatrix} -2  -1/4 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 0  4 \\end{pmatrix} \\begin{pmatrix} -2 \\\\ -1/4 \\end{pmatrix} = \\begin{pmatrix} -2  -1/4 \\end{pmatrix} \\begin{pmatrix} -2 \\\\ -1 \\end{pmatrix} = 4 + \\frac{1}{4} = \\frac{17}{4} $$\n$$ m(\\tilde{p}^{\\star}) = -\\frac{17}{4} + \\frac{1}{2}\\left(\\frac{17}{4}\\right) = -\\frac{17}{8} $$\n\n现在，我们求新的柯西点 $\\tilde{p}_{\\mathrm{C}}$。我们计算最小化 $\\phi(t) = m(-t\\tilde{g})$ 所需的量：\n$$ \\|\\tilde{g}\\|^2 = 2^2 + 1^2 = 5 $$\n$$ \\tilde{g}^{\\mathsf{T}}B\\tilde{g} = \\begin{pmatrix} 2  1 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 0  4 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 2  1 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 4 \\end{pmatrix} = 4 + 4 = 8 $$\n$t$ 的无约束极小值点是 $t^* = \\frac{\\|\\tilde{g}\\|^2}{\\tilde{g}^{\\mathsf{T}}B\\tilde{g}} = \\frac{5}{8}$。\n$t$ 的可行区间是 $[0, \\Delta/\\|\\tilde{g}\\|] = [0, 3/\\sqrt{5}]$。我们检查 $t^*$ 是否在该区间内：$\\frac{5}{8} \\leq \\frac{3}{\\sqrt{5}} \\iff 5\\sqrt{5} \\leq 24 \\iff \\sqrt{125} \\leq 24 \\iff 125 \\leq 576$，这是成立的。\n所以，$t_{\\mathrm{C}} = t^* = 5/8$。柯西点为 $\\tilde{p}_{\\mathrm{C}} = -t_{\\mathrm{C}}\\tilde{g} = -\\frac{5}{8} \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} -5/4 \\\\ -5/8 \\end{pmatrix}$。\n\n我们计算在该点的模型值 $m(\\tilde{p}_{\\mathrm{C}})$。我们可以使用公式 $m(\\tilde{p}_{\\mathrm{C}}) = \\phi(t_{\\mathrm{C}}) = -\\frac{1}{2}\\frac{(\\|\\tilde{g}\\|^2)^2}{\\tilde{g}^{\\mathsf{T}}B\\tilde{g}}$：\n$$ m(\\tilde{p}_{\\mathrm{C}}) = -\\frac{1}{2} \\frac{5^2}{8} = -\\frac{25}{16} $$\n\n最后，我们计算模型值的差值：\n$$ m(\\tilde{p}_{\\mathrm{C}}) - m(\\tilde{p}^{\\star}) = \\left(-\\frac{25}{16}\\right) - \\left(-\\frac{17}{8}\\right) = -\\frac{25}{16} + \\frac{34}{16} = \\frac{34 - 25}{16} = \\frac{9}{16} $$", "answer": "$$\\boxed{\\frac{9}{16}}$$", "id": "3194326"}, {"introduction": "尽管柯西点为信赖域方法提供了全局收敛性保证，但它并非总是高效的。本练习将引导你探究柯西点的一个关键“盲点”：当模型存在与梯度方向正交的显著负曲率时，仅沿梯度方向搜索的柯西点将完全忽略这个能带来巨大模型下降的方向。[@problem_id:3194285] 通过精确推导全局最优解与柯西点的模型下降量，你将量化地看到两者之间的巨大差距，从而深刻体会到为何需要更复杂的算法来探索整个信赖域空间。", "problem": "考虑二次信赖域模型 $m(p) = g^{\\top}p + \\frac{1}{2} p^{\\top} B p$，其中梯度 $g \\in \\mathbb{R}^{2}$，对称矩阵 $B \\in \\mathbb{R}^{2 \\times 2}$。信赖域（TR）子问题旨在在约束 $\\|p\\| \\leq \\Delta$ 下最小化 $m(p)$，其中 $\\Delta > 0$ 是信赖域半径。设 $B = \\mathrm{diag}(\\beta_{1}, -M)$，其中 $\\beta_{1} \\geq 0$ 且 $M > 0$；设 $g = (\\gamma, 0)^{\\top}$，其中 $\\gamma \\neq 0$。注意，与特征值 $-M$ 相关的负曲率方向与 $g$ 正交。假设 $\\Delta$ 足够大，使得当分母不为零时，不等式 $\\Delta \\geq \\frac{|\\gamma|}{\\beta_{1} + M}$ 和 $\\Delta \\geq \\frac{|\\gamma|}{\\beta_{1}}$ 均成立，这确保了下面推导出的极小值点是可行的，而无需被约束截断。\n\n仅从信赖域模型和柯西点（通过在 $\\|-\\tau g\\| \\leq \\Delta$ 约束下，对标量步长 $\\tau$ 最小化 $m(-\\tau g)$ 得到的点）的定义出发，完成以下步骤：\n\n1. 推导此 $B$ 和 $g$ 的信赖域子问题的精确全局极小值点，并以闭式形式得到最小化的模型值 $m(p_{\\mathrm{TR}})$。你的推导过程必须说明为何精确极小值点位于边界上，以及它如何利用负曲率方向。\n2. 推导沿负梯度方向的柯西点 $p_{\\mathrm{C}}$，并以闭式形式得到最小化的模型值 $m(p_{\\mathrm{C}})$，并明确说明在此设置中负曲率方向为何不影响柯西点。\n3. 令 $R_{\\mathrm{TR}} := -m(p_{\\mathrm{TR}})$ 和 $R_{\\mathrm{C}} := -m(p_{\\mathrm{C}})$ 分别表示由精确信赖域步长和柯西点实现模型减少量。计算乘性最优性差距因子\n$$F := \\frac{R_{\\mathrm{TR}}}{R_{\\mathrm{C}}}$$\n并将其表示为关于 $\\beta_{1}$、$M$、$\\gamma$ 和 $\\Delta$ 的简化闭式解析表达式。\n\n将你的最终答案表示为单个闭式表达式。无需四舍五入。不涉及物理单位。", "solution": "此问题被验证为数值优化领域中一个适定、自洽且有科学依据的问题。\n\n二次模型由 $m(p) = g^{\\top}p + \\frac{1}{2} p^{\\top} B p$ 给出，优化问题为在 $\\|p\\| \\leq \\Delta$ 的约束下 $\\min_{p \\in \\mathbb{R}^2} m(p)$。\n给定的参数为梯度 $g = (\\gamma, 0)^{\\top}$（其中 $\\gamma \\neq 0$），以及对称 Hessian 矩阵 $B = \\mathrm{diag}(\\beta_{1}, -M)$（其中 $\\beta_{1} \\geq 0$ 且 $M > 0$）。信赖域半径为 $\\Delta > 0$。\n令 $p = (p_1, p_2)^{\\top}$。该模型可以明确写为：\n$$m(p) = \\gamma p_1 + \\frac{1}{2} (\\beta_1 p_1^2 - M p_2^2)$$\n约束条件为 $p_1^2 + p_2^2 \\leq \\Delta^2$。\n\n### 1. 信赖域子问题的全局极小值点\n\n信赖域子问题的解 $p_{\\mathrm{TR}}$ 必须满足 Karush-Kuhn-Tucker (KKT) 条件。存在一个拉格朗日乘子 $\\lambda \\geq 0$ 使得：\n1. $(B + \\lambda I) p_{\\mathrm{TR}} = -g$\n2. $\\lambda (\\Delta - \\|p_{\\mathrm{TR}}\\|) = 0$\n3. $B + \\lambda I$ 是半正定的。\n\n矩阵 $B$ 的特征值为 $\\beta_1$ 和 $-M$。由于 $M > 0$，$B$ 是不定的。要使矩阵 $B + \\lambda I = \\mathrm{diag}(\\beta_1 + \\lambda, -M + \\lambda)$ 成为半正定矩阵，其两个对角元素（即其特征值）都必须为非负。由于 $\\beta_1 \\geq 0$ 和 $\\lambda \\geq 0$，第一个特征值 $\\beta_1 + \\lambda$ 总是非负的。第二个特征值要求 $-M + \\lambda \\geq 0$，这意味着 $\\lambda \\geq M$。\n\n模型 $m(p)$ 包含项 $-\\frac{1}{2} M p_2^2$。由于 $M > 0$，对于任何固定的 $p_1$，通过增加 $|p_2|$ 可以使模型值任意小。这意味着二次函数在 $\\mathbb{R}^2$ 上是下方无界的，因此不存在无约束的极小值点。因此，任何在约束 $\\|p\\| \\leq \\Delta$ 下的极小值点都必须位于边界上，即 $\\|p_{\\mathrm{TR}}\\| = \\Delta$。\n\n从互补松弛条件 $\\lambda (\\Delta - \\|p_{\\mathrm{TR}}\\|) = 0$ 来看，由于 $\\|p_{\\mathrm{TR}}\\| = \\Delta > 0$，我们必须有 $\\lambda \\geq 0$。我们已经建立了一个更强的条件，即 $\\lambda \\geq M > 0$。\n\n让我们分析第一个 KKT 条件，$(B + \\lambda I) p = -g$：\n$$\n\\begin{pmatrix} \\beta_1 + \\lambda  0 \\\\ 0  -M + \\lambda \\end{pmatrix} \\begin{pmatrix} p_1 \\\\ p_2 \\end{pmatrix} = \\begin{pmatrix} -\\gamma \\\\ 0 \\end{pmatrix}\n$$\n这可以分解为两个方程：\n(a) $(\\beta_1 + \\lambda) p_1 = -\\gamma$\n(b) $(-M + \\lambda) p_2 = 0$\n\n我们考虑 $\\lambda \\geq M$ 的可能性。\n情况 1：$\\lambda > M$。在这种情况下，根据方程 (b)，必须有 $p_2=0$。方程 (a) 给出 $p_1 = -\\frac{\\gamma}{\\beta_1 + \\lambda}$。解在边界上，所以 $\\|p_{\\mathrm{TR}}\\|= |p_1| = \\Delta$，这意味着 $\\frac{|\\gamma|}{\\beta_1 + \\lambda} = \\Delta$，或 $\\lambda = \\frac{|\\gamma|}{\\Delta} - \\beta_1$。条件 $\\lambda > M$ 变为 $\\frac{|\\gamma|}{\\Delta} - \\beta_1 > M$，简化为 $\\Delta < \\frac{|\\gamma|}{\\beta_1 + M}$。然而，问题陈述假设 $\\Delta \\geq \\frac{|\\gamma|}{\\beta_1 + M}$，所以这种情况被排除。这种情况是信赖域文献中典型的“困难情况”。\n\n情况 2：$\\lambda = M$。这是唯一剩下的可能性。\n方程 (a) 给出 $(\\beta_1 + M) p_1 = -\\gamma$，所以 $p_1 = -\\frac{\\gamma}{\\beta_1 + M}$。由于 $\\beta_1 \\geq 0$ 且 $M > 0$，分母不为零。\n方程 (b) 变为 $(-M + M) p_2 = 0$，即 $0 \\cdot p_2 = 0$。此方程对任何 $p_2$ 的值都成立。\n解必须位于边界上，所以 $p_1^2 + p_2^2 = \\Delta^2$。我们可以解出 $p_2^2$：\n$$p_2^2 = \\Delta^2 - p_1^2 = \\Delta^2 - \\left(-\\frac{\\gamma}{\\beta_1 + M}\\right)^2 = \\Delta^2 - \\frac{\\gamma^2}{(\\beta_1 + M)^2}$$\n如果 $\\Delta^2 - \\frac{\\gamma^2}{(\\beta_1 + M)^2} \\geq 0$，即 $\\Delta \\geq \\frac{|\\gamma|}{\\beta_1 + M}$，则存在 $p_2$ 的实数解。这个不等式由问题的假设所保证。\n该解通过具有非零分量 $p_2$ 来利用负曲率方向（特征向量 $(0, 1)^{\\top}$）。模型值为 $m(p) = \\gamma p_1 + \\frac{1}{2}(\\beta_1 p_1^2 - M p_2^2)$。当 $p_1$ 固定时，通过最大化 $p_2^2$ 来最小化模型值，这正是我们通过强制边界条件所做的。$p_2$ 的符号不影响模型值。因此，存在两个全局极小值点。\n我们将其中一个极小值点表示为 $p_{\\mathrm{TR}}$，其分量为 $p_{1, \\mathrm{TR}} = -\\frac{\\gamma}{\\beta_1 + M}$ 和 $p_{2, \\mathrm{TR}}^2 = \\Delta^2 - \\frac{\\gamma^2}{(\\beta_1 + M)^2}$。\n\n最小化的模型值为：\n$m(p_{\\mathrm{TR}}) = \\gamma p_{1, \\mathrm{TR}} + \\frac{1}{2}(\\beta_1 p_{1, \\mathrm{TR}}^2 - M p_{2, \\mathrm{TR}}^2)$\n$m(p_{\\mathrm{TR}}) = \\gamma \\left(-\\frac{\\gamma}{\\beta_1 + M}\\right) + \\frac{1}{2}\\left[\\beta_1 \\frac{\\gamma^2}{(\\beta_1 + M)^2} - M \\left(\\Delta^2 - \\frac{\\gamma^2}{(\\beta_1 + M)^2}\\right)\\right]$\n$m(p_{\\mathrm{TR}}) = -\\frac{\\gamma^2}{\\beta_1 + M} + \\frac{1}{2}\\left[\\frac{(\\beta_1 + M)\\gamma^2}{(\\beta_1 + M)^2} - M \\Delta^2\\right]$\n$m(p_{\\mathrm{TR}}) = -\\frac{\\gamma^2}{\\beta_1 + M} + \\frac{1}{2}\\left(\\frac{\\gamma^2}{\\beta_1 + M} - M \\Delta^2\\right)$\n$$m(p_{\\mathrm{TR}}) = -\\frac{1}{2} \\frac{\\gamma^2}{\\beta_1 + M} - \\frac{1}{2} M \\Delta^2$$\n\n### 2. 柯西点\n\n柯西点 $p_{\\mathrm{C}}$ 是通过沿负梯度方向 $p(\\tau) = -\\tau g$（对于步长 $\\tau \\geq 0$）在信赖域约束 $\\|p(\\tau)\\| \\leq \\Delta$ 下最小化模型 $m(p)$ 得到的。\n这里，$p(\\tau) = -\\tau (\\gamma, 0)^{\\top} = (-\\tau\\gamma, 0)^{\\top}$。作为 $\\tau$ 的函数，模型为：\n$m(p(\\tau)) = g^{\\top}(-\\tau g) + \\frac{1}{2}(-\\tau g)^{\\top}B(-\\tau g) = -\\tau\\|g\\|^2 + \\frac{\\tau^2}{2}g^{\\top}Bg$。\n我们计算必要的量：\n$\\|g\\|^2 = \\gamma^2 + 0^2 = \\gamma^2$。\n$g^{\\top}Bg = \\begin{pmatrix} \\gamma  0 \\end{pmatrix} \\begin{pmatrix} \\beta_1  0 \\\\ 0  -M \\end{pmatrix} \\begin{pmatrix} \\gamma \\\\ 0 \\end{pmatrix} = \\beta_1 \\gamma^2$。\n所以，一维模型是 $m(\\tau) = -\\tau\\gamma^2 + \\frac{\\tau^2}{2}\\beta_1\\gamma^2$。\n\n与特征值 $-M$ 相关的负曲率方向是标准基向量 $e_2 = (0, 1)^{\\top}$。柯西点的搜索方向是 $-g = (-\\gamma, 0)^{\\top}$，它与 $e_1 = (1, 0)^{\\top}$ 平行。由于 $e_1$ 与 $e_2$ 正交，柯西点的搜索被限制在负曲率没有影响的子空间中。这一点很明显，因为项 $-M$ 没有出现在 $m(\\tau)$ 的表达式中。\n\n为了找到最优的 $\\tau$，我们分析 $m(\\tau)$。\n如果 $\\beta_1 > 0$，$m(\\tau)$ 是关于 $\\tau$ 的凸二次函数。其无约束极小值点通过将导数设为零得到：$m'(\\tau) = -\\gamma^2 + \\tau\\beta_1\\gamma^2 = \\gamma^2(\\tau\\beta_1-1) = 0$，这给出 $\\tau^* = 1/\\beta_1$。\n如果 $\\beta_1 = 0$，$m(\\tau) = -\\tau\\gamma^2$，这是 $\\tau$ 的严格递减函数。\n约束条件是 $\\|p(\\tau)\\| = \\|-\\tau g\\| = \\tau|\\gamma| \\leq \\Delta$，所以 $0 \\leq \\tau \\leq \\Delta/|\\gamma|$。\n\n问题陈述假设 $\\Delta \\geq \\frac{|\\gamma|}{\\beta_1}$ 在“分母不为零时”成立，即对于 $\\beta_1 > 0$。这个不等式等价于 $\\frac{\\Delta}{|\\gamma|} \\geq \\frac{1}{\\beta_1}$。\n对于 $\\beta_1 > 0$，柯西步长 $\\tau_{\\mathrm{C}}$ 是 $m(\\tau)$ 的有约束极小值点，即 $\\tau_{\\mathrm{C}} = \\min(\\tau^*, \\Delta/|\\gamma|) = \\min(1/\\beta_1, \\Delta/|\\gamma|)$。根据假设，这得到 $\\tau_{\\mathrm{C}} = 1/\\beta_1$。\n因此，问题的提法引导我们考虑 $\\beta_1 > 0$ 的情况。\n柯西点是 $p_{\\mathrm{C}} = -\\tau_{\\mathrm{C}} g = -\\frac{1}{\\beta_1}g = (-\\frac{\\gamma}{\\beta_1}, 0)^{\\top}$。\n在柯西点的模型值为：\n$m(p_{\\mathrm{C}}) = m(\\tau = 1/\\beta_1) = -\\frac{1}{\\beta_1}\\gamma^2 + \\frac{1}{2}\\left(\\frac{1}{\\beta_1}\\right)^2\\beta_1\\gamma^2 = -\\frac{\\gamma^2}{\\beta_1} + \\frac{1}{2}\\frac{\\gamma^2}{\\beta_1} = -\\frac{1}{2}\\frac{\\gamma^2}{\\beta_1}$。\n\n### 3. 最优性差距因子\n\nTR 极小值点的模型减少量为 $R_{\\mathrm{TR}} = m(0) - m(p_{\\mathrm{TR}})$。由于 $m(0)=0$, $R_{\\mathrm{TR}} = -m(p_{\\mathrm{TR}})$。\n$$R_{\\mathrm{TR}} = \\frac{1}{2} \\frac{\\gamma^2}{\\beta_1 + M} + \\frac{1}{2} M \\Delta^2$$\n柯西点的模型减少量为 $R_{\\mathrm{C}} = m(0) - m(p_{\\mathrm{C}}) = -m(p_{\\mathrm{C}})$。\n$$R_{\\mathrm{C}} = \\frac{1}{2}\\frac{\\gamma^2}{\\beta_1}$$\n最优性差距因子是 $F = \\frac{R_{\\mathrm{TR}}}{R_{\\mathrm{C}}}$。\n$$F = \\frac{\\frac{1}{2} \\frac{\\gamma^2}{\\beta_1 + M} + \\frac{1}{2} M \\Delta^2}{\\frac{1}{2}\\frac{\\gamma^2}{\\beta_1}} = \\frac{\\frac{\\gamma^2}{\\beta_1 + M} + M \\Delta^2}{\\frac{\\gamma^2}{\\beta_1}}$$\n我们可以拆分这个分数：\n$$F = \\left(\\frac{\\gamma^2}{\\beta_1 + M}\\right) \\left(\\frac{\\beta_1}{\\gamma^2}\\right) + (M \\Delta^2) \\left(\\frac{\\beta_1}{\\gamma^2}\\right)$$\n$$F = \\frac{\\beta_1}{\\beta_1 + M} + \\frac{M \\beta_1 \\Delta^2}{\\gamma^2}$$\n这就是最终的简化闭式表达式。", "answer": "$$\\boxed{\\frac{\\beta_1}{\\beta_1 + M} + \\frac{M \\beta_1 \\Delta^2}{\\gamma^2}}$$", "id": "3194285"}, {"introduction": "认识到柯西点的局限性后，一个自然的问题是：我们如何改进它？本练习将指导你构建一个超越纯粹梯度下降的“两阶段”步，该方法是共轭梯度法 (Conjugate Gradient) 等先进信赖域求解器的简化雏形。[@problem_id:3194258] 你将首先计算柯西点，然后在一个与梯度正交的子空间中，利用海森矩阵 $B$ 的信息寻找一个额外的曲率修正步，亲身体验如何有效地获得比柯西点更优的模型下降量。", "problem": "考虑一个光滑目标函数在当前迭代点附近的信赖域二次模型，由函数 $$m(p) = f_0 + g^\\top p + \\tfrac{1}{2} p^\\top B p,$$ 给出，其中 $$f_0 \\in \\mathbb{R}$$ 是一个常数参考值，$$g \\in \\mathbb{R}^n$$ 是梯度向量，$$B \\in \\mathbb{R}^{n \\times n}$$ 是一个表示曲率信息（例如，Hessian矩阵或其近似）的对称矩阵，而 $$p \\in \\mathbb{R}^n$$ 是一个受限于信赖域约束 $$\\|p\\| \\leq \\Delta$$（半径 $$\\Delta > 0$$）的步。\n\n模型对于一个步 $$p$$ 的预测下降量定义为 $$\\mathrm{PR}(p) = m(0) - m(p) = - g^\\top p - \\tfrac{1}{2} p^\\top B p.$$\n\n你的任务是推导、实现并评估一个两阶段的步构造方法。该方法首先计算柯西点（Cauchy point），然后进行一次与梯度正交的、捕获曲率的校正。这一方法的灵感来自于共轭梯度法（Conjugate Gradient, CG）的第一步：\n\n1. 从信赖域模型 $$m(p)$$ 和预测下降量 $$\\mathrm{PR}(p)$$ 的基本定义出发。仅使用这些基本原理，通过在最速下降方向 $$-g$$ 上最小化 $$m(p)$$ 的一维限制，并在信赖域约束下，推导出柯西点 $$p_C$$。将该步明确表示为 $$p_C = - t_C g$$ 的形式，其中选择 $$t_C \\ge 0$$ 以最小化标量函数 $$\\phi(t) = m(-t g)$$，$$t$$ 的取值范围限制在 $$[0, \\Delta / \\|g\\|]$$ 内。\n\n2. 基于 $$B g$$ 在与 $$g$$ 正交的子空间上的投影，构造一个单一的正交曲率捕获方向。定义正交投影算子 $$P = \\frac{g g^\\top}{\\|g\\|^2},$$ 以及曲率方向 $$v = (I - P) B g,$$ 其中 $$I$$ 是单位矩阵。证明 $$g^\\top v = 0,$$ 因此 $$v$$ 与 $$g$$ 正交，并论证为何在由 $$\\{-g, v\\}$$ 张成的二维子空间中，这种选择是整合曲率信息的一种有原则的方法。\n\n3. 从柯西点 $$p_C$$ 出发，沿方向 $$v$$ 进行满足信赖域约束的线搜索。由于 $$p_C$$ 与 $$-g$$ 共线，而 $$v$$ 与 $$g$$ 正交，请仔细论证为何 $$p_C$$ 和 $$v$$ 是正交的，并推导出步 $$p(\\alpha) = p_C + \\alpha v$$ 中标量步长 $$\\alpha$$ 的信赖域界限，即 $$\\alpha^2 \\le \\frac{\\Delta^2 - \\|p_C\\|^2}{\\|v\\|^2}$$。然后，在区间 $$[-\\alpha_{\\max}, \\alpha_{\\max}]$$ 上最小化一维模型 $$\\psi(\\alpha) = m(p_C + \\alpha v)$$，其中 $$\\alpha_{\\max} = \\sqrt{\\max\\{0, \\Delta^2 - \\|p_C\\|^2\\}} / \\|v\\|$$。提供一个有原则的策略来处理正定和不定两种情况的 $$B$$：\n   - 如果 $$v^\\top B v > 0,$$ 计算无约束极小化子 $$\\alpha^\\star = - \\frac{v^\\top B p_C}{v^\\top B v}$$，然后将其裁剪到可行区间 $$[-\\alpha_{\\max}, \\alpha_{\\max}]$$ 内。\n   - 如果 $$v^\\top B v \\le 0,$$ 解释为何关于 $$\\alpha$$ 的二次函数是非凸或线性的，并论证通过在两个端点 $$\\{-\\alpha_{\\max}, \\alpha_{\\max}\\}$$ 处评估 $$m(p_C + \\alpha v)$$ 的值来选择极小化子是合理的。\n\n4. 对每种情况，计算通过曲率捕获校正所实现的、相对于柯西点的预测下降量改进，定义为 $$\\Delta \\mathrm{PR} = \\mathrm{PR}(p_C + \\alpha v) - \\mathrm{PR}(p_C).$$\n\n将上述过程实现为一个完整的、可运行的程序。程序不得读取任何外部输入；相反，它必须使用以下由 $$B,$$ $$g,$$ 和 $$\\Delta$$ 指定的测试用例集：\n\n- 情况1（对称正定，二维，可能为内部柯西步）：\n  - $$B = \\begin{bmatrix} 4  1 \\\\ 1  3 \\end{bmatrix},\\quad g = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix},\\quad \\Delta = 1.0.$$\n- 情况2（对称正定的单位矩阵标量倍，二维，由于 $$B g$$ 与 $$g$$ 共线而无曲率改进）：\n  - $$B = \\begin{bmatrix} 2  0 \\\\ 0  2 \\end{bmatrix},\\quad g = \\begin{bmatrix} 1.5 \\\\ -0.5 \\end{bmatrix},\\quad \\Delta = 0.5.$$\n- 情况3（不定，二维，柯西步到达边界，存在曲率校正）：\n  - $$B = \\begin{bmatrix} -1  0 \\\\ 0  2 \\end{bmatrix},\\quad g = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix},\\quad \\Delta = 0.3.$$\n- 情况4（对称正定，二维，具有非平凡曲率方向的内部柯西步）：\n  - $$B = \\begin{bmatrix} 10  -3 \\\\ -3  2 \\end{bmatrix},\\quad g = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix},\\quad \\Delta = 0.7.$$\n- 情况5（负定，二维，需要选择端点的凹校正方向）：\n  - $$B = \\begin{bmatrix} -2  0 \\\\ 0  -1 \\end{bmatrix},\\quad g = \\begin{bmatrix} 1 \\\\ 0.2 \\end{bmatrix},\\quad \\Delta = 0.4.$$\n\n对于每个测试用例，你的程序必须计算出浮点数形式的 $$\\Delta \\mathrm{PR}$$。你的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表（例如，“[result1,result2,result3,result4,result5]”）。本问题中不出现任何物理单位、角度或百分比；所有量均为无量纲实数。", "solution": "该问题要求推导并实现一种两阶段方法，以近似求解信赖域子问题。该子问题旨在找到一个步长 $p$，以最小化二次模型 $$m(p) = f_0 + g^\\top p + \\tfrac{1}{2} p^\\top B p$$，并满足约束 $\\|p\\| \\leq \\Delta$。由于常数 $f_0$ 不依赖于 $p$，因此在最小化过程中可以忽略它。一个步长 $p$ 带来的预测下降量为 $\\mathrm{PR}(p) = m(0) - m(p) = -g^\\top p - \\frac{1}{2} p^\\top B p$。\n\n解答过程按照问题陈述中概述的四个阶段进行构建。\n\n### 1. 柯西点 ($p_C$) 的推导\n\n柯西点 $p_C$ 是模型 $m(p)$ 在信赖域内沿最速下降方向 $-g$ 的极小化子。沿此方向的任何步都可以写成 $p(t) = -t g$，其中 $t \\ge 0$ 是一个标量。信赖域约束 $\\|p(t)\\| \\le \\Delta$ 变为 $\\| -t g \\| = t \\|g\\| \\le \\Delta$，这意味着 $t \\in [0, \\Delta/\\|g\\|]$。只要 $g \\neq 0$，这个区间就是良定义的。如果 $g=0$，当前点是一个驻点，最优步长为 $p=0$。\n\n我们通过将 $m(p)$ 限制在直线 $p(t) = -tg$ 上来定义一个一维二次模型 $\\phi(t)$：\n$$\n\\phi(t) = m(-tg) = f_0 + g^\\top(-tg) + \\frac{1}{2}(-tg)^\\top B (-tg) = f_0 - t \\|g\\|^2 + \\frac{1}{2} t^2 (g^\\top B g)\n$$\n为了找到在区间 $[0, \\Delta/\\|g\\|]$ 上最小化 $\\phi(t)$ 的 $t$ 值，我们首先通过对 $t$ 求导并令其为零来找到无约束极小化子：\n$$\n\\phi'(t) = -\\|g\\|^2 + t (g^\\top B g)\n$$\n令 $\\phi'(t) = 0$ 得到无约束极小化子 $t^* = \\frac{\\|g\\|^2}{g^\\top B g}$。这仅在 $g^\\top B g \\neq 0$ 时有效。我们根据曲率 $g^\\top B g$ 的符号分析两种情况：\n\n情况1：$g^\\top B g > 0$。函数 $\\phi(t)$ 是一个严格凸的二次函数（开口向上），因此 $t^*$ 是唯一的全局最小值点。由于 $\\|g\\|^2 > 0$ 且 $g^\\top B g > 0$，我们有 $t^* > 0$。区间 $[0, \\Delta/\\|g\\|]$ 上的极小化子通过将 $t^*$ 裁剪到此区间内得到。\n$$t_C = \\min\\left(t^*, \\frac{\\Delta}{\\|g\\|}\\right) = \\min\\left(\\frac{\\|g\\|^2}{g^\\top B g}, \\frac{\\Delta}{\\|g\\|}\\right)$$\n\n情况2：$g^\\top B g \\le 0$。函数 $\\phi(t)$ 是凹的（当 $g^\\top B g < 0$）或线性的（当 $g^\\top B g = 0$）。在这两种情况下，$\\phi(t)$ 在闭区间上的最小值必然出现在某个端点。导数 $\\phi'(t) = -\\|g\\|^2 + t(g^\\top B g)$ 对所有 $t \\ge 0$ 都是非正的。因此，$\\phi(t)$ 在 $[0, \\infty)$ 上是一个非增函数，其在 $[0, \\Delta/\\|g\\|]$ 上的最小值必定在右端点处。\n$$t_C = \\frac{\\Delta}{\\|g\\|}$$\n\n因此，柯西点由 $p_C = -t_C g$ 给出，其中 $t_C$ 由上述规则确定。\n\n### 2. 正交曲率捕获方向 ($v$)\n\n该方法的第二阶段引入了对柯西点的校正，校正方向从矩阵 $B$ 中捕获曲率信息。该方向 $v$ 被构造为与梯度 $g$ 正交。\n\n其定义为 $v = (I-P)Bg$，其中 $P = \\frac{gg^\\top}{\\|g\\|^2}$ 是到由 $g$ 张成的子空间上的投影矩阵。为了确认正交性，我们计算点积 $g^\\top v$：\n$$\ng^\\top v = g^\\top (I-P)Bg = \\left(g^\\top - g^\\top\\left(\\frac{gg^\\top}{\\|g\\|^2}\\right)\\right)Bg = \\left(g^\\top - \\frac{(g^\\top g)g^\\top}{\\|g\\|^2}\\right)Bg\n$$\n由于 $g^\\top g = \\|g\\|^2$，括号中的项变为：\n$$\ng^\\top - \\frac{\\|g\\|^2 g^\\top}{\\|g\\|^2} = g^\\top - g^\\top = 0\n$$\n因此，$g^\\top v = 0$，证实了 $v$ 与 $g$ 正交。\n\n这种选择的理由是，最速下降方向 $-g$ 提供了最佳的局部线性改进。方向 $v$ 是 $Bg$ 中与 $g$ 正交的分量。向量 $Bg$ 近似了模型梯度在沿 $g$ 方向走一步后的变化。通过取与 $g$ 正交的分量，我们在柯西步未探索的方向上寻求改进，以一种有原则的方式（类似于共轭梯度法的第二步）整合二阶信息。\n\n### 3. 线搜索校正\n\n最终的步计算为 $p(\\alpha) = p_C + \\alpha v$，其中 $\\alpha$ 为某个标量。首先，我们证明 $p_C$ 和 $v$ 是正交的。由于 $p_C = -t_C g$ 且我们刚刚证明了 $g^\\top v = 0$：\n$$p_C^\\top v = (-t_C g)^\\top v = -t_C (g^\\top v) = 0$$\n由于这种正交性，信赖域约束 $\\|p(\\alpha)\\| \\le \\Delta$ 现在可以被简化：\n$$\\|p(\\alpha)\\|^2 = \\|p_C + \\alpha v\\|^2 = (p_C + \\alpha v)^\\top(p_C + \\alpha v) = p_C^\\top p_C + 2\\alpha p_C^\\top v + \\alpha^2 v^\\top v = \\|p_C\\|^2 + \\alpha^2\\|v\\|^2$$\n该约束变为 $\\|p_C\\|^2 + \\alpha^2\\|v\\|^2 \\le \\Delta^2$，整理后得到：\n$$\\alpha^2 \\le \\frac{\\Delta^2 - \\|p_C\\|^2}{\\|v\\|^2}$$\n这将 $\\alpha$ 的可行区间定义为 $[-\\alpha_{\\max}, \\alpha_{\\max}]$，其中 $\\alpha_{\\max} = \\frac{\\sqrt{\\max\\{0, \\Delta^2 - \\|p_C\\|^2\\}}}{\\|v\\|}$。与 $0$ 取 `max` 确保了平方根的参数为非负。注意，如果 $\\|v\\|=0$（当 $Bg$ 与 $g$ 共线时发生），则无法进行校正，我们必须取 $\\alpha=0$。\n\n我们寻求最小化一维模型 $\\psi(\\alpha) = m(p_C + \\alpha v)$：\n$$\n\\psi(\\alpha) = m(p_C) + \\alpha \\nabla m(p_C)^\\top v + \\frac{1}{2}\\alpha^2 v^\\top B v\n$$\n模型的梯度是 $\\nabla m(p) = g+Bp$。在 $p_C$ 点，沿 $v$ 的方向导数为：\n$$ \\nabla m(p_C)^\\top v = (g+Bp_C)^\\top v = g^\\top v + p_C^\\top B v = 0 + p_C^\\top B v = v^\\top B p_C $$\n（利用 $B$ 的对称性）。所以关于 $\\alpha$ 的模型是：\n$$\n\\psi(\\alpha) = m(p_C) + \\alpha (v^\\top B p_C) + \\frac{1}{2}\\alpha^2 (v^\\top B v)\n$$\n与柯西点类似，我们根据曲率 $v^\\top B v$ 分析情况：\n\n情况1：$v^\\top B v > 0$。二次函数 $\\psi(\\alpha)$ 是凸的。无约束极小化子是 $\\alpha^* = -\\frac{v^\\top B p_C}{v^\\top B v}$。最优步长 $\\alpha_{opt}$ 通过将 $\\alpha^*$ 裁剪到区间 $[-\\alpha_{\\max}, \\alpha_{\\max}]$ 内得到。\n\n情况2：$v^\\top B v \\le 0$。二次函数 $\\psi(\\alpha)$ 是凹的或线性的。在 $[-\\alpha_{\\max}, \\alpha_{\\max}]$ 上的最小值必然在端点处。我们比较 $\\psi(\\alpha_{\\max})$ 和 $\\psi(-\\alpha_{\\max})$。其差值为 $\\psi(\\alpha_{\\max}) - \\psi(-\\alpha_{\\max}) = 2\\alpha_{\\max}(v^\\top B p_C)$。为了最小化 $\\psi$，如果 $v^\\top B p_C > 0$，我们选择 $\\alpha_{opt} = -\\alpha_{max}$；如果 $v^\\top B p_C < 0$，我们选择 $\\alpha_{opt} = \\alpha_{max}$。如果 $v^\\top B p_C = 0$，两个端点产生相同的值。\n\n这里有一个关键的观察：如果柯西点 $p_C$ 位于信赖域边界上，那么 $\\|p_C\\|=\\Delta$。从推导出的约束 $\\|p_C\\|^2 + \\alpha^2\\|v\\|^2 \\le \\Delta^2$ 可知，$\\alpha^2\\|v\\|^2 \\le 0$。对于任何非零的校正方向 $v$，这迫使 $\\alpha=0$。因此，如果柯西步到达边界，该方法将无法进行进一步校正。这种情况在 $t_C = \\Delta/\\|g\\|$ 时发生。这适用于任何 $g^\\top B g \\le 0$ 的问题实例，以及当 $g^\\top B g > 0$ 但 $\\frac{\\|g\\|^2}{g^\\top B g} \\ge \\frac{\\Delta}{\\|g\\|}$ 的情况。这适用于测试用例3和5，其中数学上指定的程序会产生零校正，尽管问题陈述中的括号备注可能暗示了其他情况。我们严格遵循推导出的数学程序。\n\n### 4. 预测下降量的改进 ($\\Delta \\mathrm{PR}$)\n\n最终的步是 $p_{final} = p_C + \\alpha_{opt} v$。预测下降量的改进为 $\\Delta \\mathrm{PR} = \\mathrm{PR}(p_{final}) - \\mathrm{PR}(p_C)$。根据定义，$\\mathrm{PR}(p) = -m(p) + m(0)$，所以 $\\Delta \\mathrm{PR} = m(p_C) - m(p_{final})$。\n使用我们关于 $\\psi(\\alpha)$ 的表达式：\n$$m(p_{final}) = \\psi(\\alpha_{opt}) = m(p_C) + \\alpha_{opt} (v^\\top B p_C) + \\frac{1}{2}\\alpha_{opt}^2 (v^\\top B v)$$\n因此，改进量为：\n$$\n\\Delta \\mathrm{PR} = m(p_C) - m(p_{final}) = -\\alpha_{opt} (v^\\top B p_C) - \\frac{1}{2}\\alpha_{opt}^2 (v^\\top B v)\n$$\n一旦确定了 $\\alpha_{opt}$，此公式就允许直接计算改进量。如果 $\\|v\\|$ 接近零，或者如果 $\\alpha_{max}$ 为零，则 $\\alpha_{opt}=0$ 且 $\\Delta \\mathrm{PR} = 0$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the trust-region subproblem for a suite of test cases.\n    It implements a two-stage method:\n    1. Compute the Cauchy point.\n    2. Compute a curvature-capturing correction orthogonal to the gradient.\n    The function calculates the improvement in predicted reduction from the correction.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: SPD, 2D, interior Cauchy step\n        {\n            \"B\": np.array([[4.0, 1.0], [1.0, 3.0]]),\n            \"g\": np.array([1.0, 2.0]),\n            \"Delta\": 1.0,\n        },\n        # Case 2: SPD (scaled identity), 2D, no curvature improvement\n        {\n            \"B\": np.array([[2.0, 0.0], [0.0, 2.0]]),\n            \"g\": np.array([1.5, -0.5]),\n            \"Delta\": 0.5,\n        },\n        # Case 3: Indefinite, 2D, Cauchy step on boundary\n        {\n            \"B\": np.array([[-1.0, 0.0], [0.0, 2.0]]),\n            \"g\": np.array([1.0, 1.0]),\n            \"Delta\": 0.3,\n        },\n        # Case 4: SPD, 2D, interior Cauchy with nontrivial curvature direction\n        {\n            \"B\": np.array([[10.0, -3.0], [-3.0, 2.0]]),\n            \"g\": np.array([0.0, 1.0]),\n            \"Delta\": 0.7,\n        },\n        # Case 5: Negative-definite, 2D, concave correction direction\n        {\n            \"B\": np.array([[-2.0, 0.0], [0.0, -1.0]]),\n            \"g\": np.array([1.0, 0.2]),\n            \"Delta\": 0.4,\n        },\n    ]\n\n    results = []\n    eps = 1e-12 # Epsilon for floating-point comparisons\n\n    for case in test_cases:\n        B, g, Delta = case[\"B\"], case[\"g\"], case[\"Delta\"]\n\n        # Stage 1: Compute the Cauchy Point (p_C)\n        g_norm = np.linalg.norm(g)\n        if g_norm < eps:\n            results.append(0.0)\n            continue\n\n        g_dot_g = g_norm**2\n        gBg = g.T @ B @ g\n\n        if gBg > 0:\n            t_C = min(g_dot_g / gBg, Delta / g_norm)\n        else:\n            t_C = Delta / g_norm\n        \n        p_C = -t_C * g\n\n        # Stage 2: Construct the Orthogonal Curvature-Capturing Direction (v)\n        Bg = B @ g\n        # v = (I - gg^T/|g|^2)Bg = Bg - (g^T Bg / |g|^2)g\n        v = Bg - (g.T @ Bg / g_dot_g) * g\n\n        v_norm = np.linalg.norm(v)\n        if v_norm < eps:\n            results.append(0.0)\n            continue\n\n        # Stage 3: Line Search Correction\n        pC_norm_sq = np.linalg.norm(p_C)**2\n        \n        # Check if Cauchy point is on or outside the boundary due to precision\n        if pC_norm_sq >= Delta**2:\n             alpha_max = 0.0\n        else:\n             alpha_max = np.sqrt(Delta**2 - pC_norm_sq) / v_norm\n        \n        if alpha_max < eps:\n            results.append(0.0)\n            continue\n\n        # Coefficients for the quadratic model in alpha\n        vBv = v.T @ B @ v\n        # Note: B is symmetric, so v.T @ B @ p_C = p_C.T @ B @ v\n        vBpC = v.T @ B @ p_C\n\n        alpha_opt = 0.0\n        if vBv > eps: # Convex case\n            alpha_star = -vBpC / vBv\n            alpha_opt = max(-alpha_max, min(alpha_max, alpha_star))\n        else: # Concave or linear case\n            # Minimize psi(alpha) = m(p_C) + alpha*vBpC + 0.5*alpha^2*vBv\n            # The minimum on [-alpha_max, alpha_max] is at one of the endpoints.\n            # Compare psi(alpha_max) and psi(-alpha_max). The difference is 2*alpha_max*vBpC.\n            if vBpC > 0:\n                alpha_opt = -alpha_max\n            else: # vBpC <= 0\n                alpha_opt = alpha_max\n        \n        # Stage 4: Compute Improvement in Predicted Reduction\n        delta_PR = -alpha_opt * vBpC - 0.5 * alpha_opt**2 * vBv\n        results.append(delta_PR)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.16f}'.rstrip('0').rstrip('.') for r in results)}]\")\n\nsolve()\n```", "id": "3194258"}]}