{"hands_on_practices": [{"introduction": "在学习如何用高斯-牛顿法优化模型参数之前，我们首先需要掌握一个基本概念：残差。残差精确地量化了在当前参数下，模型预测值与实际观测数据之间的差异，是所有最小二乘法的核心。这个练习 [@problem_id:2214281] 将让你亲手计算残差向量，为后续理解高斯-牛顿法如何迭代减小这个误差打下坚实的基础。", "problem": "在非线性最小二乘拟合的背景下，一个常见的任务是最小化残差平方和。考虑一个描述某种物理现象的模型，由函数 $f(x, \\beta) = \\beta_1 \\sqrt{x} + \\beta_2$ 给出，其中 $\\beta = (\\beta_1, \\beta_2)^T$ 是待确定的参数向量。\n\n一次实验得到了两个数据点 $(x_i, y_i)$：第一个点是 $(4, 5)$，第二个点是 $(9, 7)$。\n\n第 $i$ 个数据点的残差定义为 $r_i(\\beta) = y_i - f(x_i, \\beta)$。残差向量 $r(\\beta)$ 是一个列向量，其分量是各个残差 $r_i(\\beta)$。\n\n给定参数的初始估计值 $\\beta^{(0)} = (1, 3)^T$，计算相应的残差向量 $r(\\beta^{(0)})$。将您的最终答案表示为一个包含两个元素的行矩阵，这两个元素对应于残差向量的分量。", "solution": "给定模型 $f(x,\\beta)=\\beta_{1}\\sqrt{x}+\\beta_{2}$，残差 $r_{i}(\\beta)=y_{i}-f(x_{i},\\beta)$，数据点 $(x_{1},y_{1})=(4,5)$ 和 $(x_{2},y_{2})=(9,7)$，以及初始估计值 $\\beta^{(0)}=(\\beta_{1}^{(0)},\\beta_{2}^{(0)})^{T}=(1,3)^{T}$。\n\n使用 $\\beta^{(0)}$ 计算在给定 $x_{i}$ 处的模型预测值：\n$$\nf(x_{1},\\beta^{(0)})=\\beta_{1}^{(0)}\\sqrt{x_{1}}+\\beta_{2}^{(0)}=1\\cdot\\sqrt{4}+3=2+3=5,\n$$\n$$\nf(x_{2},\\beta^{(0)})=\\beta_{1}^{(0)}\\sqrt{x_{2}}+\\beta_{2}^{(0)}=1\\cdot\\sqrt{9}+3=3+3=6.\n$$\n\n计算残差：\n$$\nr_{1}(\\beta^{(0)})=y_{1}-f(x_{1},\\beta^{(0)})=5-5=0,\n$$\n$$\nr_{2}(\\beta^{(0)})=y_{2}-f(x_{2},\\beta^{(0)})=7-6=1.\n$$\n\n因此，残差向量的分量为 $0$ 和 $1$。表示为包含两个元素的行矩阵，即 $\\begin{pmatrix}0  1\\end{pmatrix}$。", "answer": "$$\\boxed{\\begin{pmatrix}0  1\\end{pmatrix}}$$", "id": "2214281"}, {"introduction": "理解了残差之后，我们便可以开始真正执行一次参数优化的迭代步骤。高斯-牛顿法的精髓在于，它通过在当前参数点对非线性问题进行线性化，然后求解这个简化的线性最小二乘问题，来计算出参数的更新方向和步长。通过完成这个练习 [@problem_id:2214282]，你将完整地经历一次高斯-牛顿迭代的核心过程：计算雅可比矩阵、构建并求解正规方程，最终得到更新后的参数估计值。", "problem": "在一项实验研究中，某个物理过程由函数 $y(x) = \\frac{x}{1+ax}$ 建模，其中 $a$ 是一个待确定的未知参数。一位研究人员收集了两个数据点 $(x_i, y_i)$：第一个点是 $(1, 0.5)$，第二个点是 $(2, 0.8)$。\n\n为了找到在最小二乘意义下最佳拟合数据的参数 $a$ 的最优值，该研究人员决定使用高斯-牛顿法。从初始猜测值 $a_0 = 1$ 开始，执行恰好一次高斯-牛顿法的迭代，以找到参数的更新估计值，记为 $a_1$。\n\n将 $a_1$ 的答案表示为最简精确分数形式。", "solution": "我们用 $y(x;a)=\\dfrac{x}{1+a x}$ 来对数据进行建模。对于残差为 $r_{i}(a)=y(x_{i};a)-y_{i}$ 的最小二乘问题，从 $a_{0}$ 开始对单个参数 $a$ 的高斯-牛顿更新量为\n$$\n\\Delta a=-(J^{\\top}J)^{-1}J^{\\top}r,\n$$\n其中 $J_{i}=\\dfrac{\\partial r_{i}}{\\partial a}=\\dfrac{\\partial y(x_{i};a)}{\\partial a}$ 是在 $a_{0}$ 处计算的雅可比矩阵的项，而 $r$ 是在 $a_{0}$ 处计算的残差向量。那么更新后的参数为 $a_{1}=a_{0}+\\Delta a$。\n\n首先，计算模型关于 $a$ 的导数。将 $y(x;a)=x(1+a x)^{-1}$ 写出，我们得到\n$$\n\\frac{\\partial y}{\\partial a}=-x^{2}(1+a x)^{-2}.\n$$\n\n给定数据点 $(x_{1},y_{1})=(1,\\tfrac{1}{2})$ 和 $(x_{2},y_{2})=(2,\\tfrac{4}{5})$，以及初始猜测值 $a_{0}=1$，雅可比项为\n$$\nJ_{1}=\\left.-\\frac{x_{1}^{2}}{(1+a x_{1})^{2}}\\right|_{a=1}=-\\frac{1}{(1+1)^{2}}=-\\frac{1}{4},\\quad\nJ_{2}=\\left.-\\frac{x_{2}^{2}}{(1+a x_{2})^{2}}\\right|_{a=1}=-\\frac{4}{(1+2)^{2}}=-\\frac{4}{9}.\n$$\n\n在 $a_{0}=1$ 处的残差为\n$$\nr_{1}=y(1;1)-\\frac{1}{2}=\\frac{1}{2}-\\frac{1}{2}=0,\\quad\nr_{2}=y(2;1)-\\frac{4}{5}=\\frac{2}{3}-\\frac{4}{5}=-\\frac{2}{15}.\n$$\n\n计算标量值 $J^{\\top}r$ 和 $J^{\\top}J$：\n$$\nJ^{\\top}r=J_{1}r_{1}+J_{2}r_{2}=0+\\left(-\\frac{4}{9}\\right)\\left(-\\frac{2}{15}\\right)=\\frac{8}{135},\n$$\n$$\nJ^{\\top}J=J_{1}^{2}+J_{2}^{2}=\\frac{1}{16}+\\frac{16}{81}=\\frac{81+256}{1296}=\\frac{337}{1296}.\n$$\n\n因此，\n$$\n\\Delta a=-\\frac{J^{\\top}r}{J^{\\top}J}=-\\frac{\\frac{8}{135}}{\\frac{337}{1296}}=-\\frac{8}{135}\\cdot\\frac{1296}{337}=-\\frac{8\\cdot 48}{5\\cdot 337}=-\\frac{384}{1685}.\n$$\n\n所以，更新后的估计值为\n$$\na_{1}=a_{0}+\\Delta a=1-\\frac{384}{1685}=\\frac{1685-384}{1685}=\\frac{1301}{1685}.\n$$", "answer": "$$\\boxed{\\frac{1301}{1685}}$$", "id": "2214282"}, {"introduction": "标准的“纯”高斯-牛顿法有一个固有的弱点：当问题是病态的，即雅可比矩阵接近奇异时，算法会变得非常不稳定，可能导致步长过大或产生剧烈振荡。列文伯格-马夸特（Levenberg-Marquardt, LM）方法通过在正规方程中加入一个“阻尼项”来巧妙地解决这一问题，从而保证了算法的稳定性。这个编程练习 [@problem_id:3232802] 将让你通过代码直观地见证高斯-牛顿法在接近奇异点时的失效，并体会到LM阻尼项如何有效地稳定迭代过程，这是在实际应用中一项至关重要的技术。", "problem": "你需要编写一个完整、可运行的程序，用于分析高斯-牛顿法及其 Levenberg-Marquardt (LM) 稳定化方法在一个单参数非线性最小二乘问题中的表现。目标是通过有理有据的推导和具体的实现来证明，当雅可比矩阵接近奇异时，无阻尼的高斯-牛顿步可能会震荡或发散，而增加一个 Levenberg-Marquardt 阻尼项可以稳定迭代过程。\n\n从以下基本原理开始：\n- 非线性最小二乘的目标函数是 $F(x) = \\tfrac{1}{2}\\lVert r(x)\\rVert_2^2$，其中 $r(x)$ 是一个残差函数向量。\n- 在 $x$ 处的一阶泰勒线性化为 $r(x + \\Delta) \\approx r(x) + J(x)\\Delta$，其中 $J(x)$ 是 $r(x)$ 的雅可比矩阵。\n- 最小化线性化模型可以得到正规方程 $J(x)^\\top J(x)\\Delta = -J(x)^\\top r(x)$。\n- Levenberg-Marquardt (LM) 方法通过增加一个阻尼项 $\\lambda I$（其中 $I$ 是单位矩阵）来增广正规矩阵，求解 $\\big(J(x)^\\top J(x) + \\lambda I\\big)\\Delta = -J(x)^\\top r(x)$，其中 $\\lambda > 0$。\n\n你的程序必须实例化一个一维残差模型 $r(x) = \\sin(x)$（角度以弧度为单位），并执行高斯-牛顿法（无阻尼，对应于 $\\lambda = 0$）和 Levenberg-Marquardt 法（有阻尼，使用指定的 $\\lambda > 0$）的迭代。该残差模型意味着最小二乘目标函数为 $F(x) = \\tfrac{1}{2}\\sin^2(x)$。在这种情况下，雅可比矩阵 $J(x)$ 是一个标量。你必须：\n- 从基本定义出发，推导出针对一维残差 $r(x) = \\sin(x)$ 特化的高斯-牛顿和 LM 更新规则。\n- 使用推导出的更新规则，为这两种方法实现固定迭代次数的求解器。\n- 证明在 $J(x)$ 接近奇异的点附近（具体来说，是 $x \\approx \\tfrac{\\pi}{2} + k\\pi$ 附近，其中 $k$ 为整数），无阻尼的高斯-牛顿迭代会表现出震荡或发散（大幅度的交替步长或超出有界域的步长），而带有正阻尼参数的 LM 方法通过限制步长大小来稳定迭代过程。\n\n角度必须以弧度为单位。不涉及任何物理单位。除了恒定的 LM 阻尼外，你的算法不得使用任何线搜索或信赖域自适应调整。\n\n测试套件和输出规格：\n- 使用以下测试用例，每个用例指定为一个元组 $(x_0, \\lambda, N, L)$：\n  1. 雅可比矩阵近奇异情况，以引发不稳定性：$x_0 = \\tfrac{\\pi}{2} - 10^{-6}$, $\\lambda = 1.0$, $N = 10$, $L = 50$。\n  2. 震荡但可恢复的情况：$x_0 = 1.4$, $\\lambda = 0.5$, $N = 10$, $L = 50$。\n  3. 远离奇异点的理想情况：$x_0 = 2.0$, $\\lambda = 0.1$, $N = 10$, $L = 50$。\n- 对于每个用例，运行 $N$ 次无阻尼高斯-牛顿迭代（即，对高斯-牛顿法设置 $\\lambda = 0$）和 $N$ 次使用给定 $\\lambda$ 的 LM 迭代。对于每个用例中的每种方法，计算：\n  - 最终残差范数 $|r(x_N)|$，以浮点数表示。\n  - 一个稳定性标志（布尔值），如果所有迭代点 $x_k$ 都满足 $|x_k| \\le L$，则为真，否则为假。\n  - 最大步长 $\\max_k |\\Delta_k|$，以浮点数表示，其中 $\\Delta_k$ 是第 $k$ 次迭代的更新量。\n- 你的程序应生成单行输出，包含一个用方括号括起来的逗号分隔的结果列表。结果必须构造成一个列表的列表，每个内层列表对应一个测试用例，每个内层列表包含六个条目，顺序如下：$[\\text{gn\\_final\\_residual}, \\text{lm\\_final\\_residual}, \\text{gn\\_stable}, \\text{lm\\_stable}, \\text{gn\\_max\\_step}, \\text{lm\\_max\\_step}]$。例如，输出格式必须类似于 $[[r_{11}, r_{12}, b_{11}, b_{12}, s_{11}, s_{12}], [r_{21}, r_{22}, b_{21}, b_{22}, s_{21}, s_{22}], [r_{31}, r_{32}, b_{31}, b_{32}, s_{31}, s_{32}]]$，其中 $r_{ij}$ 是浮点数，$b_{ij}$ 是布尔值。\n\n科学真实性与覆盖范围：\n- 近奇异情况强制了一个边界条件，即无阻尼方法会遇到接近零的雅可比矩阵，这可能导致巨大的步长。LM 阻尼项 $\\lambda I$ 必须能缓解这种不稳定性。\n- 震荡情况展示了无阻尼高斯-牛顿法的大幅度交替步长，在 LM 阻尼下这些步长会减小。\n- 理想情况展示了两种方法的收敛性。\n- 角度以弧度为单位。\n- 所有输出必须是指定的基本类型（布尔值和浮点数）。", "solution": "该问题要求对高斯-牛顿（GN）方法及其 Levenberg-Marquardt（LM）稳定化在一个特定的一维非线性最小二乘问题中进行验证和实现。目标是展示当雅可比矩阵接近奇异时，LM 稳定化如何修正无阻尼高斯-牛顿方法中固有的不稳定性。\n\n首先，我们建立理论基础。一般的非线性最小二乘问题旨在最小化一个目标函数 $F(x)$，该函数定义为残差向量 $r(x)$ 的欧几里得范数平方的一半：\n$$\nF(x) = \\frac{1}{2}\\lVert r(x)\\rVert_2^2\n$$\n高斯-牛顿法通过在当前迭代点 $x_k$ 周围线性化残差函数 $r(x)$ 来近似每次迭代的目标函数。更新步长 $\\Delta$ 是通过求解以下线性化的最小二乘问题得到的：\n$$\n\\min_{\\Delta} \\frac{1}{2}\\lVert r(x_k) + J(x_k)\\Delta\\rVert_2^2\n$$\n其中 $J(x_k)$ 是 $r(x)$ 在 $x_k$ 处的雅可比矩阵。这个线性问题的解由正规方程给出：\n$$\nJ(x_k)^\\top J(x_k)\\Delta_{GN} = -J(x_k)^\\top r(x_k)\n$$\nLevenberg-Marquardt 方法引入一个阻尼参数 $\\lambda > 0$ 来对问题进行正则化，这在矩阵 $J(x_k)^\\top J(x_k)$ 奇异或病态时尤其有用。LM 更新步长 $\\Delta_{LM}$ 通过求解修正后的正规方程得到：\n$$\n\\left(J(x_k)^\\top J(x_k) + \\lambda I\\right)\\Delta_{LM} = -J(x_k)^\\top r(x_k)\n$$\n其中 $I$ 是单位矩阵。\n\n现在，我们将这些通用公式特化到给定的一维问题，其中残差是一个标量函数 $r(x) = \\sin(x)$。\n目标函数变为：\n$$\nF(x) = \\frac{1}{2}(r(x))^2 = \\frac{1}{2}\\sin^2(x)\n$$\n$F(x)$ 的极小值点出现在 $\\sin(x) = 0$ 的地方，即对于任意整数 $n$，$x = n\\pi$。\n在这个一维情况下，雅可比矩阵 $J(x)$ 是一个 $1 \\times 1$ 的矩阵（一个标量），对应于 $r(x)$ 的一阶导数：\n$$\nJ(x) = \\frac{dr}{dx} = \\frac{d}{dx}(\\sin(x)) = \\cos(x)\n$$\n当 $J(x) = \\cos(x) \\approx 0$ 时，雅可比矩阵是（接近）奇异的，这种情况发生在 $x \\approx \\frac{\\pi}{2} + k\\pi$（其中 $k$ 是任意整数）时。\n\n我们为这两种方法推导具体的更新规则。\n对于高斯-牛顿法（无阻尼，等价于 $\\lambda=0$），正规方程是：\n$$\n(\\cos(x_k))^\\top (\\cos(x_k))\\Delta_{GN} = -(\\cos(x_k))^\\top (\\sin(x_k))\n$$\n$$\n\\cos^2(x_k) \\Delta_{GN} = -\\sin(x_k)\\cos(x_k)\n$$\n假设 $\\cos(x_k) \\neq 0$，我们可以解出步长 $\\Delta_{GN}$：\n$$\n\\Delta_{GN} = -\\frac{\\sin(x_k)\\cos(x_k)}{\\cos^2(x_k)} = -\\frac{\\sin(x_k)}{\\cos(x_k)} = -\\tan(x_k)\n$$\n因此，高斯-牛顿法的更新规则是：\n$$\nx_{k+1} = x_k + \\Delta_{GN} = x_k - \\tan(x_k)\n$$\n当 $x_k$ 接近雅可比矩阵奇异的点，即 $x_k \\to \\frac{\\pi}{2} + k\\pi$ 时，该方法的不稳定性就变得很明显。在这些点上，$\\cos(x_k) \\to 0$，导致 $|\\tan(x_k)| \\to \\infty$。更新步长 $\\Delta_{GN}$ 变得任意大，从而导致发散或剧烈震荡。\n\n对于 Levenberg-Marquardt 方法，修正后的正规方程包含阻尼项 $\\lambda > 0$。在这个一维情况下，单位矩阵 $I$ 是标量 $1$：\n$$\n(\\cos^2(x_k) + \\lambda)\\Delta_{LM} = -\\sin(x_k)\\cos(x_k)\n$$\n由于 $\\cos^2(x_k) \\ge 0$ 且 $\\lambda > 0$，项 $(\\cos^2(x_k) + \\lambda)$ 总是正的，并且以 $\\lambda$ 为下界远离零。因此，该系统总是良态的。LM 的更新步长是：\n$$\n\\Delta_{LM} = -\\frac{\\sin(x_k)\\cos(x_k)}{\\cos^2(x_k) + \\lambda}\n$$\nLevenberg-Marquardt 的更新规则是：\n$$\nx_{k+1} = x_k + \\Delta_{LM} = x_k - \\frac{\\sin(x_k)\\cos(x_k)}{\\cos^2(x_k) + \\lambda}\n$$\n现在考虑在奇异点附近的行为，此时 $\\cos(x_k) \\to 0$。在此极限下，分子 $\\sin(x_k)\\cos(x_k)$ 也趋近于 $0$。分母趋近于 $\\lambda$。因此，步长 $\\Delta_{LM}$ 趋近于 $0$。阻尼项有效地限制了步长大小，防止了在无阻尼高斯-牛顿方法中观察到的灾难性行为。这确保了稳定性并促进了收敛，即使从雅可比矩阵奇异的区域附近开始迭代也是如此。\n\n实现过程将通过对给定的测试用例迭代这两个更新规则，以数值方式展示这一推导出的行为。结果将量化最终残差、在给定界限内的迭代序列稳定性以及所采取步长的大小。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Analyzes Gauss-Newton and Levenberg-Marquardt methods for a 1D\n    nonlinear least-squares problem, demonstrating LM stabilization.\n    \"\"\"\n\n    # Test cases as tuples of (x0, lambda, N, L)\n    test_cases = [\n        (np.pi / 2.0 - 1e-6, 1.0, 10, 50.0), # Near-singular Jacobian case\n        (1.4, 0.5, 10, 50.0),               # Oscillatory-but-recoverable case\n        (2.0, 0.1, 10, 50.0)                # Happy-path case\n    ]\n\n    results = []\n\n    def run_iterations(x0, N, L, damp_lambda):\n        \"\"\"\n        Performs N iterations of a solver for the objective F(x) = 0.5*sin^2(x).\n\n        Args:\n            x0 (float): Initial guess.\n            N (int): Number of iterations.\n            L (float): Stability bound for |x_k|.\n            damp_lambda (float): Damping parameter. If 0, use Gauss-Newton.\n                                 If > 0, use Levenberg-Marquardt.\n\n        Returns:\n            A tuple containing:\n            - final_residual (float): |r(x_N)|.\n            - is_stable (bool): True if all |x_k| = L.\n            - max_step (float): Maximum magnitude of any step delta_k.\n        \"\"\"\n        x = x0\n        stable = True\n        max_step_mag = 0.0\n\n        for _ in range(N):\n            # The Jacobian is singular when cos(x) is zero.\n            # Avoid division by zero for the pure Gauss-Newton case if x is exactly pi/2 + k*pi.\n            # np.tan will handle large values gracefully, returning inf.\n            cos_x = np.cos(x)\n            sin_x = np.sin(x)\n\n            if damp_lambda == 0:  # Gauss-Newton\n                # Delta = -tan(x)\n                # Avoid explicit division by zero if cos_x is extremely small.\n                # np.tan handles this by returning large numbers or inf.\n                delta = -np.tan(x)\n\n            else:  # Levenberg-Marquardt\n                # Delta = -sin(x)cos(x) / (cos^2(x) + lambda)\n                numerator = -sin_x * cos_x\n                denominator = cos_x**2 + damp_lambda\n                delta = numerator / denominator\n\n            if np.isinf(delta) or np.isnan(delta):\n                # If step is infinite/NaN, it's definitively unstable and huge.\n                # To assign a finite but large value for max_step.\n                # Using 2*L is arbitrary but indicates a large step.\n                current_step_mag = 2 * L \n                x = x + (2 * L * np.sign(-delta) if not np.isnan(delta) else 0)\n            else:\n                current_step_mag = abs(delta)\n\n            if current_step_mag > max_step_mag:\n                max_step_mag = current_step_mag\n\n            x = x + delta\n            \n            if abs(x) > L:\n                stable = False\n        \n        final_residual = abs(np.sin(x))\n        \n        return final_residual, stable, max_step_mag\n\n    for x0, lm_lambda, N, L in test_cases:\n        # Run Gauss-Newton (undamped, lambda = 0)\n        gn_final_residual, gn_stable, gn_max_step = run_iterations(x0, N, L, 0)\n\n        # Run Levenberg-Marquardt (damped)\n        lm_final_residual, lm_stable, lm_max_step = run_iterations(x0, N, L, lm_lambda)\n\n        case_results = [\n            gn_final_residual,\n            lm_final_residual,\n            gn_stable,\n            lm_stable,\n            gn_max_step,\n            lm_max_step,\n        ]\n        results.append(case_results)\n\n    # Format the final output string exactly as specified.\n    # The default str() representation for lists includes spaces, which is acceptable.\n    # The boolean values will be represented as 'True' and 'False'.\n    output_str = \"[\" + \",\".join(map(str, results)) + \"]\"\n    \n    print(output_str)\n\nsolve()\n```", "id": "3232802"}]}