{"hands_on_practices": [{"introduction": "黄金分割法等区间搜索方法的一个关键特性是其收敛速度由几何结构决定，而非目标函数的具体形态。本练习将通过一个最小值极度靠近区间端点的特例，来动手计算并验证这一重要原理。通过这个实践，你将深刻理解为何该方法的收敛进程是稳健且可预测的。[@problem_id:3196232]", "problem": "考虑区间 $[a,b]=[0,1]$ 以及在此区间上定义的单峰函数 $f:[0,1] \\to \\mathbb{R}$，$f(x)=(x-\\delta)^2$，其中 $\\delta=10^{-6}$。唯一的极小值点是 $x^{\\star}=\\delta$，它极其靠近左端点 $a=0$。你需要应用黄金分割法搜索来包围该极小值点，使用经典的内部比例 $\\tau=(\\sqrt{5}-1)/2$。在每次迭代中，在当前区间内部严格构造两个内部点 $x_{1}$ 和 $x_{2}$，并根据 $f(x_{1})$ 和 $f(x_{2})$ 的比较结果舍弃一个子区间，从而维持一个包含极小值点的包围区间。\n\n从初始包围区间 $[0,1]$ 开始，确定最小的整数 $n$，使得经过 $n$ 次迭代后，当前的包围区间 $[a_n,b_n]$ 完全包含在 $[0,10^{-3}]$ 内。这量化了尽管最小值点极其靠近左边界，该方法通过重复的内部采样如何收缩右端点。请以整数形式提供你的答案。无需四舍五入。", "solution": "黄金分割法搜索通过以固定的比率 $\\tau = (\\sqrt{5}-1)/2 \\approx 0.618$ 迭代缩小包含极小值点的区间。由于极小值点 $x^{\\star}=\\delta=10^{-6}$ 非常靠近左端点 $a=0$，在迭代的每一步中，两个内部点 $x_1$ 和 $x_2$ 都会满足 $x^{\\star}  x_1  x_2$。因此，函数值总是满足 $f(x_1)  f(x_2)$，这会导致算法总是舍弃右侧的子区间 $[x_2, b]$。\n\n初始区间为 $[a_0, b_0] = [0,1]$。经过一次迭代，新的右端点 $b_1$ 将是原始的 $x_2$，即 $b_1 = a_0 + \\tau(b_0-a_0) = \\tau$。这个过程会持续下去，使得第 $n$ 次迭代后的区间右端点为 $b_n = \\tau^n$（因为左端点始终为0）。我们的目标是找到最小的整数 $n$，使得 $b_n \\le 10^{-3}$。这等价于求解不等式 $\\tau^n \\le 10^{-3}$。\n\n两边取以10为底的对数，我们得到：\n$n \\log_{10}(\\tau) \\le -3$\n\n由于 $\\log_{10}(\\tau)$ 是负数，不等式两边同除以它时，不等号方向反转：\n$n \\ge \\frac{-3}{\\log_{10}(\\tau)}$\n\n使用 $\\tau \\approx 0.618034$，我们有 $\\log_{10}(\\tau) \\approx -0.208987$。因此：\n$n \\ge \\frac{-3}{-0.208987} \\approx 14.355$\n\n因为 $n$ 必须是整数，所以满足条件的最小整数 $n$ 是15。", "answer": "$$\\boxed{15}$$", "id": "3196232"}, {"introduction": "一个常见的问题是，当最优点恰好落在搜索区间的端点上时，区间搜索算法将如何表现？本练习旨在探讨这类“边界情况”，验证算法的基本逻辑在这种场景下依然有效。你将分析算法如何系统地将搜索范围压缩至包含边界最小值的正确方向。[@problem_id:3196314]", "problem": "考虑一个连续单峰函数 $f:[a,b]\\to\\mathbb{R}$，其中单峰性意味着存在一个唯一的极小值点 $x^\\star \\in [a,b]$，使得函数 $f$ 在达到 $x^\\star$ 之前递减，之后递增；该定义允许 $x^\\star=a$ 或 $x^\\star=b$（在这种情况下，$f$ 在 $[a,b]$ 上是单调的）。在诸如黄金分割法和斐波那契搜索等基于区间收缩的搜索方法中，算法在每次迭代时选择两个满足 $a  c  d  b$ 的内点，并根据 $f(c)$ 和 $f(d)$ 值的比较来缩小区间。\n\n分析当极小值点位于区间端点时算法的行为。具体来说，请确定以下陈述中哪些是正确的。\n\nA. 如果极小值点是 $x^\\star=a$（即 $f$ 在 $[a,b]$ 上是单调递增的），那么在每次迭代中，左边界将保持固定为 $a$，而右边界将被更新以收缩区间。\nB. 如果极小值点是 $x^\\star=a$，算法将立即终止，因为它无法缩小区间。\nC. 如果极小值点是 $x^\\star=b$（即 $f$ 在 $[a,b]$ 上是单调递减的），那么在每次迭代中，左边界将保持固定为 $a$，而右边界将被更新。\nD. 如果极小值点是 $x^\\star=b$，那么在每次迭代中，右边界将保持固定为 $b$，而左边界将被更新以收缩区间。\n\n请提供所有正确陈述的字母组合（例如，AB、CD、ACD）。", "solution": "### 步骤 1：提取已知条件\n- **函数定义**：$f:[a,b]\\to\\mathbb{R}$ 是一个连续单峰函数。\n- **单峰性定义**：存在一个唯一的极小值点 $x^\\star \\in [a,b]$，使得 $f$ 在达到 $x^\\star$ 之前递减，之后递增。该定义明确允许 $x^\\star=a$ 或 $x^\\star=b$，对应于 $[a,b]$ 上的单调函数。\n- **算法**：基于区间收缩的搜索（例如，黄金分割法，斐波那契法）。\n- **迭代逻辑**：\n    1. 选择两个内点 $c$ 和 $d$，使得 $a  c  d  b$。\n    2. 如果 $f(c)  f(d)$，则极小值点必在 $[a,d]$ 内。更新区间为 $[a,d]$。\n    3. 如果 $f(c) > f(d)$，则极小值点必在 $[c,b]$ 内。更新区间为 $[c,b]$。\n    4. 如果 $f(c) = f(d)$，则极小值点必在 $[c,d]$ 内。更新区间为 $[c,d]$。\n\n### 步骤 2：分析情况 $x^\\star = a$\n- 当极小值点为 $x^\\star = a$ 时，函数 $f$ 在整个区间 $[a,b]$ 上是单调递增的。\n- 对于任何两个满足 $a  c  d  b$ 的内点，由于函数是单调递增的，必然有 $f(c)  f(d)$。\n- 根据迭代逻辑的第2条规则，当 $f(c)  f(d)$ 时，算法将更新区间为 $[a,d]$。\n- 在此更新中，左边界 $a$ 保持不变，而右边界从 $b$ 更新为 $d$。这个过程会在每次迭代中重复，右边界将不断向左收缩，但左边界将始终保持为 $a$。\n- **评估选项 A**：该陈述声称左边界保持固定为 $a$，而右边界被更新。这与我们的分析一致。因此，**陈述 A 是正确的**。\n- **评估选项 B**：该陈述声称算法将立即终止。这是不正确的，因为算法成功地将区间从 $[a,b]$ 缩小到了 $[a,d]$。\n\n### 步骤 3：分析情况 $x^\\star = b$\n- 当极小值点为 $x^\\star = b$ 时，函数 $f$ 在整个区间 $[a,b]$ 上是单调递减的。\n- 对于任何两个满足 $a  c  d  b$ 的内点，由于函数是单调递减的，必然有 $f(c) > f(d)$。\n- 根据迭代逻辑的第3条规则，当 $f(c) > f(d)$ 时，算法将更新区间为 $[c,b]$。\n- 在此更新中，右边界 $b$ 保持不变，而左边界从 $a$ 更新为 $c$。这个过程会在每次迭代中重复，左边界将不断向右收缩，但右边界将始终保持为 $b$。\n- **评估选项 C**：该陈述声称左边界保持固定为 $a$。这与我们的分析相反。因此，陈述 C 是不正确的。\n- **评估选项 D**：该陈述声称右边界保持固定为 $b$，而左边界被更新。这与我们的分析一致。因此，**陈述 D 是正确的**。\n\n### 步骤 4：整合结果\n根据以上分析，陈述 A 和 D 是正确的，而陈述 B 和 C 是不正确的。因此，正确的答案是 AD。", "answer": "AD", "id": "3196314"}, {"introduction": "真实世界的优化问题常常伴随着测量噪声或仿真不确定性，这意味着函数评估返回的是一个可能区间而非精确值。这项高级实践要求你将标准的黄金分割法进行改造，以处理带有不确定性的函数评估。你需要设计一套基于区间比较的决策规则，这直接模拟了在实验或仿真优化中遇到的实际挑战。[@problem_id:3196296]", "problem": "您的任务是实现一个稳健的区间套法算法，用于在每次函数查询返回一个因不确定性而产生的区间时，最小化一个单峰函数。一个函数在其定义区间上是单峰的，如果存在一个点，函数在该点从严格递减过渡到严格递增。具体来说，假设目标是最小化一个已知在闭区间 $[a,b]$ 上是单峰的函数 $f(x)$。可用的逐点求值查询接口不返回单个值；相反，对于在点 $x$ 处累积了 $n$ 个样本的查询，它返回一个区间 $[f^{-}(x,n), f^{+}(x,n)]$。我们保证真实值满足 $f(x) \\in [f^{-}(x,n), f^{+}(x,n)]$，且半宽度遵循 $f^{+}(x,n) - f(x) = f(x) - f^{-}(x,n) = s \\cdot n^{-1/2}$，其中 $s > 0$ 是一个已知的噪声缩放参数。您可以通过请求额外的样本来自适应地增加选定点 $x$ 的 $n$ 值；在 $x$ 处的每个额外样本都会使 $n$ 增加1，从而确定性地将区间半宽度缩小至 $s \\cdot n^{-1/2}$。每次单样本增量会消耗全局评估预算 $N_{\\max}$ 的一个单位。\n\n您的程序必须实现一个适应区间值反馈的黄金分割式区间套法，并满足以下要求。\n\n- 基本和建模假设：\n  - 函数 $f(x)$ 在 $[a,b]$ 上是单峰的。\n  - 查询接口返回区间反馈 $[f^{-}(x,n), f^{+}(x,n)]$，确保精确包含真实值，且对于在 $x$ 处累积的第 $n$ 个样本，半宽度为 $s \\cdot n^{-1/2}$。\n  - 参数 $s$ 对一个测试用例是给定且固定的。预算 $N_{\\max}$ 对一个测试用例是给定且固定的。\n  - 以 $n=1$ 个样本初始化每个新引入的内部点，这将消耗1个单位的预算，并产生初始区间 $[f(x)-s, f(x)+s]$。\n\n- 区间感知的区间套法规则：\n  - 维护一个当前区间 $[a_k,b_k]$ 和两个满足 $a_k  c_k  d_k  b_k$ 的内部点 $c_k$ 和 $d_k$。使用黄金分割布局构造 $c_k$ 和 $d_k$，以便当区间缩小时，下一个迭代可以重用其中一个内部点，而无需重新计算其位置。\n  - 令 $[f^{-}(c_k,n_c), f^{+}(c_k,n_c)]$ 和 $[f^{-}(d_k,n_d), f^{+}(d_k,n_d)]$ 分别表示在 $c_k$ 和 $d_k$ 处基于已累积的 $n_c$ 和 $n_d$ 个样本的当前区间。\n  - 定义“确定小于”的优势关系如下：如果 $f^{+}(c_k,n_c)  f^{-}(d_k,n_d)$，则 $c_k$ 确定优于 $d_k$；对称地，如果 $f^{+}(d_k,n_d)  f^{-}(c_k,n_c)$，则 $d_k$ 确定优于 $c_k$。\n  - 在单峰性假设下保持对未知最小值点 $x^{\\star}$ 的包围的排除规则：\n    - 如果 $f^{+}(c_k,n_c)  f^{-}(d_k,n_d)$，则将区间更新为 $[a_{k+1}, b_{k+1}] = [a_k, d_k]$（排除右子区间 $[d_k,b_k]$）。\n    - 如果 $f^{+}(d_k,n_d)  f^{-}(c_k,n_c)$，则将区间更新为 $[a_{k+1}, b_{k+1}] = [c_k, b_k]$（排除左子区间 $[a_k,c_k]$）。\n  - 如果两个优势条件都不满足，您可以在 $c_k$ 或 $d_k$ 处请求额外的样本以缩小区间。在这样的每一步中，在当前区间宽度较大的点上将 $n_c$ 或 $n_d$ 增加1（消耗1个单位预算）；如果宽度相等，则通过在 $c_k$ 和 $d_k$ 之间交替选择来打破平局。\n\n- 黄金分割构造的重用特性：\n  - 选择内部点，使得在一次排除步骤后，前一个内部点之一成为新区间的内部点。这意味着黄金分割搜索中著名的不变比率构造，它使用固定的比率进行内部点布局，以实现每次迭代的恒定重用和最少的新点评估。您必须在解决方案中从第一性原理推导出这个比率。\n\n- 终止条件：\n  - 当区间宽度满足 $b_k - a_k \\le \\varepsilon$（其中 $\\varepsilon$ 是给定的容差），或当总预算 $N_{\\max}$ 耗尽时，终止算法。如果已决定进行排除步骤，但没有剩余预算来初始化新引入的内部点，则在更新区间后立即停止。\n  - 返回的最小值点估计必须是终止时的中点 $(a_k + b_k)/2$。\n\n- 输出格式：\n  - 对于每个测试用例，您的程序必须输出最终的中点估计值，格式为浮点数。将每个结果四舍五入到小数点后恰好6位。\n  - 您的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表形式的结果，例如，对于三个测试用例，格式为 $[r_1,r_2,r_3]$，其中每个 $r_i$ 是按规定四舍五入的中点估计值。\n\n请实现您的程序以解决以下测试套件。所有函数和参数都以纯数学形式表示；没有角度或物理单位。通过遵循单峰性和确定性置信界来确保科学真实性。\n\n- 测试用例1（不确定性低、预算充足的理想情况）：\n  - 函数: $f_1(x) = (x - 2)^2$。\n  - 初始区间: $[a,b] = [0,5]$。\n  - 噪声参数: $s = 0.1$。\n  - 容差: $\\varepsilon = 10^{-6}$。\n  - 预算: $N_{\\max} = 300$。\n\n- 测试用例2（不确定性高、预算紧张）：\n  - 函数: $f_1(x) = (x - 2)^2$。\n  - 初始区间: $[a,b] = [0,5]$。\n  - 噪声参数: $s = 2.0$。\n  - 容差: $\\varepsilon = 10^{-6}$。\n  - 预算: $N_{\\max} = 40$。\n\n- 测试用例3（不同的单峰形状）：\n  - 函数: $f_2(x) = e^{x} - 3x$。\n  - 初始区间: $[a,b] = [0,2]$。\n  - 噪声参数: $s = 0.2$。\n  - 容差: $\\varepsilon = 10^{-5}$。\n  - 预算: $N_{\\max} = 200$。\n\n- 测试用例4（中等不确定性，中等预算，不同的最小值点位置）：\n  - 函数: $f_3(x) = (x+1)^2 + 1$。\n  - 初始区间: $[a,b] = [-3,0]$。\n  - 噪声参数: $s = 0.05$。\n  - 容差: $\\varepsilon = 0.5$。\n  - 预算: $N_{\\max} = 50$。\n\n您的程序必须实现如上所述的区间感知黄金分割区间套法，并生成一行包含四个四舍五入的中点估计值的逗号分隔列表，并用方括号括起来。", "solution": "所提出的问题要求实现一个黄金分割搜索算法，该算法经过调整，用于优化在区间 $[a,b]$ 上的单峰函数 $f(x)$，其中函数求值受特定不确定性模型的影响。每次在点 $x$ 处的函数查询都返回一个区间 $[f^{-}(x,n), f^{+}(x,n)]$，该区间保证包含真实值 $f(x)$。此区间的半宽度由 $s \\cdot n^{-1/2}$ 给出，其中 $s > 0$ 是一个已知的噪声缩放参数，$n$ 是在 $x$ 处累积的样本数。算法必须在 $N_{\\max}$ 次单样本评估的总预算内运行。\n\n解决方案首先从第一性原理推导黄金分割搜索的基本常数，然后详细阐述结合了基于区间的比较的迭代算法。\n\n### 黄金分割比率的推导\n\n黄金分割搜索的核心是其重用特性：在缩减搜索区间后，先前计算的内部点之一可以在下一次迭代中被重用。这使得每一步所需的新函数评估次数最小化。我们推导实现此特性的布局比率。\n\n设第 $k$ 次迭代的搜索区间为 $[a_k, b_k]$，其长度为 $L_k = b_k - a_k$。我们引入两个内部点 $c_k$ 和 $d_k$，使得 $a_k  c_k  d_k  b_k$。为了对称性和重用性，我们使用单个比率 $\\tau \\in (1/2, 1)$ 来定义它们相对于区间端点的位置：\n$$ c_k = b_k - \\tau \\cdot L_k = a_k + (1-\\tau) \\cdot L_k $$\n$$ d_k = a_k + \\tau \\cdot L_k $$\n条件 $\\tau > 1/2$ 确保了 $c_k  d_k$。\n\n算法通过比较 $c_k$ 和 $d_k$ 处的函数值（或其区间）来排除一部分区间。假设比较导致排除了子区间 $[a_k, c_k]$。新的区间变为 $[a_{k+1}, b_{k+1}] = [c_k, b_k]$。这个新区间的长度是：\n$$ L_{k+1} = b_k - c_k = b_k - (b_k - \\tau \\cdot L_k) = \\tau \\cdot L_k $$\n上一步中保留在新区间内的单个内部点是 $d_k$。要使重用特性成立，$d_k$ 必须与新的内部点之一 $c_{k+1}$ 或 $d_{k+1}$ 重合。新的内部点位于：\n$$ c_{k+1} = b_{k+1} - \\tau \\cdot L_{k+1} = b_k - \\tau^2 \\cdot L_k $$\n$$ d_{k+1} = a_{k+1} + \\tau \\cdot L_{k+1} = c_k + \\tau^2 \\cdot L_k $$\n让我们检查哪一个可能等于 $d_k$。旧点 $d_k$ 距离新左端点 $a_{k+1}=c_k$ 比 $[c_k, b_k]$ 的中点更远，所以我们期望它成为新的右内部点 $d_{k+1}$。然而，由于对称定义，与相对于新端点的通用公式进行检查更简单。习惯上，在排除 $[d_k, b_k]$ 的情况下，离 $a_k$ 较近的点被重用为离 $b_{k+1}$ 较近的点，反之亦然。让我们分析另一种情况。\n\n假设我们排除 $[d_k, b_k]$。新的区间是 $[a_{k+1}, b_{k+1}] = [a_k, d_k]$。新的长度是：\n$$ L_{k+1} = d_k - a_k = (a_k + \\tau \\cdot L_k) - a_k = \\tau \\cdot L_k $$\n点 $c_k$ 位于这个新区间内。我们要求 $c_k$ 成为新的内部点之一，$c_{k+1}$ 或 $d_{k+1}$。\n$$ c_{k+1} = b_{k+1} - \\tau \\cdot L_{k+1} = d_k - \\tau^2 \\cdot L_k $$\n$$ d_{k+1} = a_{k+1} + \\tau \\cdot L_{k+1} = a_k + \\tau^2 \\cdot L_k $$\n让我们检验假设 $c_k = d_{k+1}$：\n$$ a_k + (1-\\tau) \\cdot L_k = a_k + \\tau^2 \\cdot L_k $$\n$$ 1 - \\tau = \\tau^2 $$\n这得出了二次方程 $\\tau^2 + \\tau - 1 = 0$。求解 $\\tau > 0$：\n$$ \\tau = \\frac{-1 + \\sqrt{1^2 - 4(1)(-1)}}{2} = \\frac{\\sqrt{5}-1}{2} $$\n这个值，约等于 $0.618034$，是黄金比例 $\\phi = (1+\\sqrt{5})/2$ 的倒数。这个 $\\tau$ 是进行点布局所需的比率。内部点距离最近端点的距离将是 $(1-\\tau)L_k$，而距离最远端点的距离将是 $\\tau L_k$。由于 $1-\\tau = \\tau^2$，这些点距离最近端点的距离为 $\\tau^2 L_k$。\n\n### 区间感知的区间套法算法\n\n标准的黄金分割搜索被调整以处理区间值反馈。核心逻辑保持不变：维护一个区间 $[a,b]$ 和两个内部点 $c$ 和 $d$。然而，比较步骤被修改了。\n\n**状态变量：**\n- $a, b$: 当前区间的端点。\n- $c_x, d_x$: 两个内部点的位置。\n- $c_n, d_n$: 分别在 $c_x$ 和 $d_x$ 处累积的样本数。\n- $c_{ftrue}, d_{ftrue}$: 在 $c_x$ 和 $d_x$ 处的真实（但对算法来说除了通过查询接口外是未知的）函数值。这些值用于生成不确定性区间。\n- $N_{used}$: 已消耗的单样本评估总数。\n- $N_{\\max}$: 评估的最大预算。\n- $\\varepsilon$: 所期望的最终区间宽度容差。\n\n**初始化：**\n1.  根据问题陈述初始化 $a$ 和 $b$。设置 $N_{used} = 0$。\n2.  定义的比率为 $\\tau = (\\sqrt{5}-1)/2$。\n3.  检查初始预算 $N_{\\max}$ 是否至少为2。如果不是，则终止，因为无法评估两个初始点。\n4.  计算初始内部点：$c_x = a + (1-\\tau)(b-a)$ 和 $d_x = b - (1-\\tau)(b-a) = a + \\tau(b-a)$。\n5.  在 $c_x$ 和 $d_x$ 处评估函数，每个点使用 $n=1$ 个样本。这消耗2个单位的预算。设 $c_{ftrue} = f(c_x)$ 和 $d_{ftrue} = f(d_x)$，并设置 $c_n=1$, $d_n=1$, $N_{used}=2$。\n\n**迭代过程：**\n算法在一个循环中进行，当 $b-a \\le \\varepsilon$ 或 $N_{used} \\ge N_{\\max}$ 时终止。\n\n在每次迭代 $k$：\n1.  计算 $c_k$ 和 $d_k$ 的当前不确定性区间：\n    - 对于 $c_k$: $[f^{-}(c_k), f^{+}(c_k)]$，其中 $f^{\\pm}(c_k) = c_{ftrue} \\pm s/\\sqrt{c_n}$。\n    - 对于 $d_k$: $[f^{-}(d_k), f^{+}(d_k)]$，其中 $f^{\\pm}(d_k) = d_{ftrue} \\pm s/\\sqrt{d_n}$。\n\n2.  应用区间感知的排除规则：\n    - **情况1：$c_k$ 确定优于 $d_k$**。如果 $f^{+}(c_k)  f^{-}(d_k)$，则此条件成立。由于单峰性，最小值 $x^\\star$ 不可能在 $[d_k,b_k]$ 中。\n        - 更新区间：$b_{k+1} = d_k$。\n        - 重用点 $c_k$ 作为新的 $d_{k+1}$：设置 $d_{k+1} \\leftarrow c_k$ (即 $d_{x} \\leftarrow c_{x}$, $d_{n} \\leftarrow c_{n}$, $d_{ftrue} \\leftarrow c_{ftrue}$)。\n        - 计算新的内部点 $c_{k+1} = a_{k+1} + (1-\\tau)(b_{k+1}-a_{k+1})$。\n        - 如果预算仍有剩余 ($N_{used}  N_{\\max}$)，则用 $n=1$ 评估 $f(c_{k+1})$，增加 $N_{used}$，并更新 $c_{k+1}$ 的状态。否则，在更新区间后终止。\n\n    - **情况2：$d_k$ 确定优于 $c_k$**。如果 $f^{+}(d_k)  f^{-}(c_k)$，则此条件成立。最小值 $x^\\star$ 不可能在 $[a_k,c_k]$ 中。\n        - 更新区间：$a_{k+1} = c_k$。\n        - 重用点 $d_k$ 作为新的 $c_{k+1}$：设置 $c_{k+1} \\leftarrow d_k$。\n        - 计算新的内部点 $d_{k+1} = a_{k+1} + \\tau(b_{k+1}-a_{k+1})$。\n        - 如果预算仍有剩余 ($N_{used}  N_{\\max}$)，则用 $n=1$ 评估 $f(d_{k+1})$，增加 $N_{used}$，并更新状态。否则，终止。\n\n    - **情况3：无法判定**。两个优势条件都不满足；区间重叠。为了解决这个问题，我们必须通过采集更多样本来缩小一个或两个区间。\n        - 如果预算耗尽 ($N_{used} \\ge N_{\\max}$)，则终止。\n        - 否则，选择当前区间宽度较大的点进行采样。宽度为 $2s/\\sqrt{n}$。这等同于选择样本数 $n$ 较小的点。\n        - 如果 $c_n  d_n$，则增加 $c_n$。如果 $d_n  c_n$，则增加 $d_n$。\n        - 如果 $c_n = d_n$，通过交替采样 $c_k$ 和 $d_k$ 来打破平局。\n        - 将 $N_{used}$ 增加1。然后算法循环回到开始，用新的、更小的区间重新评估优势条件。\n\n**终止与输出：**\n当区间宽度 $b-a$ 不再大于 $\\varepsilon$，或当预算 $N_{used}$ 达到 $N_{\\max}$ 时，循环终止。最小值点的最终估计是最终区间的中点 $(a+b)/2$。", "answer": "```python\nimport numpy as np\n\ndef f1(x: float) - float:\n    \"\"\"Unimodal function for test cases 1 and 2: f(x) = (x - 2)^2.\"\"\"\n    return (x - 2.0)**2\n\ndef f2(x: float) - float:\n    \"\"\"Unimodal function for test case 3: f(x) = e^x - 3x.\"\"\"\n    return np.exp(x) - 3.0 * x\n\ndef f3(x: float) - float:\n    \"\"\"Unimodal function for test case 4: f(x) = (x + 1)^2 + 1.\"\"\"\n    return (x + 1.0)**2 + 1.0\n\ndef golden_section_interval_search(f, a, b, s, eps, n_max):\n    \"\"\"\n    Performs a golden-section search for a unimodal function with interval-valued feedback.\n\n    Args:\n        f: The unimodal function to minimize.\n        a: The lower bound of the initial bracket.\n        b: The upper bound of the initial bracket.\n        s: The noise-scaling parameter for interval uncertainty.\n        eps: The tolerance for the final bracket width.\n        n_max: The maximum budget of function evaluations.\n\n    Returns:\n        The midpoint of the final bracket as an estimate of the minimizer.\n    \"\"\"\n    if n_max  2:\n        return (a + b) / 2.0\n\n    tau = (np.sqrt(5.0) - 1.0) / 2.0\n    budget_used = 0\n    \n    # Tie-breaking state for sampling when interval widths are equal\n    tie_break_c_next = True\n\n    # Initialize two interior points\n    c_x = a + (1.0 - tau) * (b - a)\n    d_x = a + tau * (b - a)\n    \n    # Evaluate initial points, consuming budget\n    c_ftrue = f(c_x)\n    c_n = 1\n    d_ftrue = f(d_x)\n    d_n = 1\n    budget_used = 2\n\n    while True:\n        if b - a = eps:\n            break\n        if budget_used >= n_max:\n            break\n\n        # Calculate current interval bounds\n        c_half_width = s / np.sqrt(c_n)\n        c_f_plus = c_ftrue + c_half_width\n        c_f_minus = c_ftrue - c_half_width\n\n        d_half_width = s / np.sqrt(d_n)\n        d_f_plus = d_ftrue + d_half_width\n        d_f_minus = d_ftrue - d_half_width\n\n        # Case 1: c is certainly better, eliminate [d, b]\n        if c_f_plus  d_f_minus:\n            b = d_x\n            d_x, d_ftrue, d_n = c_x, c_ftrue, c_n\n            \n            c_x = a + (1.0 - tau) * (b - a)\n            if budget_used >= n_max:\n                break\n            \n            c_ftrue = f(c_x)\n            c_n = 1\n            budget_used += 1\n\n        # Case 2: d is certainly better, eliminate [a, c]\n        elif d_f_plus  c_f_minus:\n            a = c_x\n            c_x, c_ftrue, c_n = d_x, d_ftrue, d_n\n\n            d_x = a + tau * (b - a)\n            if budget_used >= n_max:\n                break\n            \n            d_ftrue = f(d_x)\n            d_n = 1\n            budget_used += 1\n            \n        # Case 3: Indecision, sample more at one point to shrink interval\n        else:\n            if c_half_width > d_half_width:\n                c_n += 1\n            elif d_half_width > c_half_width:\n                d_n += 1\n            else: # Tie-break by alternating\n                if tie_break_c_next:\n                    c_n += 1\n                    tie_break_c_next = False\n                else:\n                    d_n += 1\n                    tie_break_c_next = True\n            budget_used += 1\n            \n    return (a + b) / 2.0\n\ndef solve():\n    \"\"\"\n    Solves the provided test suite using the interval-aware golden-section search.\n    \"\"\"\n    test_cases = [\n        {'f': f1, 'a': 0.0, 'b': 5.0, 's': 0.1, 'eps': 1e-6, 'n_max': 300},\n        {'f': f1, 'a': 0.0, 'b': 5.0, 's': 2.0, 'eps': 1e-6, 'n_max': 40},\n        {'f': f2, 'a': 0.0, 'b': 2.0, 's': 0.2, 'eps': 1e-5, 'n_max': 200},\n        {'f': f3, 'a': -3.0, 'b': 0.0, 's': 0.05, 'eps': 0.5, 'n_max': 50},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = golden_section_interval_search(\n            case['f'], case['a'], case['b'], case['s'], case['eps'], case['n_max']\n        )\n        results.append(f\"{result:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\n# solve() # The function call is commented out to prevent execution in this context.\n# Expected output from running solve():\n# [2.000000,2.472136,1.098616,-0.957427]\n```", "id": "3196296"}]}