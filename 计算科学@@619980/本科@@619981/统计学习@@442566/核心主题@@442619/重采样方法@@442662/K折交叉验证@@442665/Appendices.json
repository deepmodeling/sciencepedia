{"hands_on_practices": [{"introduction": "数据增强是提高模型泛化能力的强大工具，但它与交叉验证的结合是一个常见的错误来源。在将数据划分为折之前错误地应用增强会导致“数据泄露”，即验证集的信息污染了训练过程。本实践将指导您完成一个计算实验，以量化此类泄露导致的性能评估偏差，从而强化保持验证集真正独立这一关键原则。[@problem_id:3134696]", "problem": "您的任务是设计并实现一个计算实验，用于分析统计学习中，在使用图像旋转进行数据增强情况下的 $k$-折交叉验证 (CV)。目的是量化仅对训练折应用增强与增强泄漏到验证折中的情况相比有何不同。您的程序必须是一个完整的、可运行的实现，无需外部输入即可产生所要求的输出。\n\n使用的基本基础和定义：\n- 交叉验证 (CV)：对于给定的数据集 $D = \\{(x_i, y_i)\\}_{i=1}^n$ 和一个学习算法，$k$-折交叉验证的泛化误差估计量定义为 $k$ 个折上的平均验证损失。设索引集 $V_1, \\dots, V_k$ 是对 $\\{1,\\dots,n\\}$ 的划分，而 $T_j = \\{1,\\dots,n\\} \\setminus V_j$ 表示相应的训练索引。对于在 $T_j$ 上训练的模型 $\\hat{f}_j$，准确率的 CV 估计量为\n$$\n\\widehat{\\text{Acc}}_{\\text{CV}} = \\frac{1}{k} \\sum_{j=1}^k \\frac{1}{|V_j|} \\sum_{i \\in V_j} \\mathbf{1}\\{\\hat{f}_j(x_i) = y_i\\},\n$$\n其中 $\\mathbf{1}\\{\\cdot\\}$ 是指示函数。\n- 数据增强：一种保持标签的变换 $\\mathcal{A}_\\theta$，应用于输入 $x$。该变换由以度为单位的旋转角度 $\\theta$ 参数化。在此问题中，$\\theta \\in \\{90, 180, 270\\}$，且 $\\mathcal{A}_\\theta$ 是围绕图像中心旋转 $\\theta$ 度的图像旋转。\n- 独立性原则：正确的交叉验证要求验证样本在给定数据生成过程的条件下独立于训练样本。当同一基础样本的变换版本同时出现在训练折和验证折中时，就会发生泄漏，这违反了独立性假设并使估计量产生偏差。\n\n数据集构建：\n- 考虑 $n$ 个大小为 $h \\times w$ 的基础图像 $\\{x_i\\}_{i=1}^n$，其标签为 $y_i \\in \\{0,1\\}$，其中类别 0 是中心化的“+”图案，类别 1 是中心化的“×”图案。每个基础图像都是通过用线条粗细的微小随机偏移和标准差为 $\\sigma$ 的加性高斯噪声来扰动理想模板，然后将像素强度裁剪到区间 $[0,1]$ 内而生成的。$\\theta \\in \\{90,180,270\\}$ 的旋转会保持类别标签。\n- 分类器是基于平方 $\\ell_2$ 距离的最近质心分类器。对于一个训练集 $(X_{\\text{train}}, Y_{\\text{train}})$，计算类别质心\n$$\n\\mu_c = \\frac{1}{|\\{i: Y_{\\text{train},i} = c\\}|} \\sum_{i:Y_{\\text{train},i}=c} X_{\\text{train},i}, \\quad c \\in \\{0,1\\},\n$$\n并预测 $\\hat{y}(x) = \\arg\\min_{c \\in \\{0,1\\}} \\|x - \\mu_c\\|_2^2$。\n\n需要比较的两种 CV 估计量：\n1. 适当增强的 CV：对于每个折 $j \\in \\{1,\\dots,k\\}$，仅通过给定角度集 $S$（角度以度为单位）中的旋转来增强训练图像，即对于 $i \\in T_j$，使用 $\\{x_i\\} \\cup \\{\\mathcal{A}_\\theta(x_i): \\theta \\in S\\}$ 来训练 $\\hat{f}_j$，并在未增强的验证图像 $\\{x_i: i \\in V_j\\}$ 上进行评估。\n2. 泄漏的 CV：首先，通过 $S$ 中的旋转全局增强整个数据集，形成 $D' = \\bigcup_{i=1}^n \\left(\\{x_i\\} \\cup \\{\\mathcal{A}_\\theta(x_i): \\theta \\in S\\}\\right)$，然后对 $D'$ 执行 $k$-折交叉验证，在这些增强样本上进行训练和验证。此过程允许同一基础图像的增强变体出现在不同的折中，从而在训练样本和验证样本之间产生依赖性。\n\n您的程序必须：\n- 按规定生成合成数据集。\n- 实现最近质心分类器。\n- 计算两种过程的平均 $k$-折交叉验证准确率，并返回其差值\n$$\n\\Delta = \\widehat{\\text{Acc}}_{\\text{CV}}^{\\text{leak}} - \\widehat{\\text{Acc}}_{\\text{CV}}^{\\text{proper}}.\n$$\n\n角度单位：所有角度均以度为单位。\n\n答案类型：所有输出必须是实数（浮点数）。\n\n测试套件和覆盖范围：\n实现以下测试用例，每个用例定义为一个元组 $(n, h, w, k, S, \\sigma, \\text{seed})$ 并按顺序处理。对于每个测试用例，计算并输出 $\\Delta$。\n\n- 用例 1 (正常路径): $(n, h, w, k, S, \\sigma, \\text{seed}) = (60, 16, 16, 5, \\{90, 180, 270\\}, 0.10, 42)$。\n- 用例 2 (边界情况，无增强): $(60, 16, 16, 5, \\varnothing, 0.10, 43)$，其中 $\\varnothing$ 表示空角度集。\n- 用例 3 (折数较少): $(60, 16, 16, 2, \\{90, 180, 270\\}, 0.10, 44)$。\n- 用例 4 (高噪声): $(60, 16, 16, 5, \\{90, 180, 270\\}, 0.50, 45)$。\n- 用例 5 (单角度增强): $(60, 16, 16, 10, \\{90\\}, 0.10, 46)$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，结果的顺序与测试用例的顺序相同。例如，一个包含三个结果的输出应类似于 $[r_1,r_2,r_3]$，其中每个 $r_i$ 是一个浮点数。角度以度为单位。不应打印任何额外文本。", "solution": "我们从 $k$-折交叉验证（CV）的核心定义和独立性要求出发。$k$-折 CV 估计量计算不相交折的平均验证性能，其作为泛化性能估计量的可靠性取决于在给定数据生成过程的条件下，训练集和验证集之间的条件独立性。当增强仅应用于训练折时，变换 $\\mathcal{A}_\\theta$ 丰富了训练分布，同时保持验证样本是来自原始数据分布的独立抽样，从而维护了 CV 估计量的完整性。当增强泄漏到验证折中时——具体来说，通过在构建折之前增强整个数据集——同一基础样本的增强版本可能被同时分配到训练集和验证集，这违反了独立性并导致乐观偏差。\n\n我们将这两个估计量形式化：\n- 适当增强的 CV 估计量：\n$$\n\\widehat{\\text{Acc}}_{\\text{proper}} = \\frac{1}{k} \\sum_{j=1}^k \\frac{1}{|V_j|} \\sum_{i \\in V_j} \\mathbf{1}\\left\\{ \\arg\\min_{c \\in \\{0,1\\}} \\|x_i - \\mu_{c}^{(j)}\\|_2^2 = y_i \\right\\},\n$$\n其中\n$$\n\\mu_{c}^{(j)} = \\frac{1}{|\\{t \\in T_j: y_t = c\\}| + |\\{(t,\\theta): t \\in T_j, y_t = c, \\theta \\in S\\}|} \\left( \\sum_{t \\in T_j, y_t=c} x_t + \\sum_{t \\in T_j, y_t=c} \\sum_{\\theta \\in S} \\mathcal{A}_\\theta(x_t) \\right).\n$$\n验证使用未增强的 $x_i$（对于 $i \\in V_j$）。\n\n- 泄漏的 CV 估计量：\n构建 $D' = \\bigcup_{i=1}^n \\left(\\{x_i\\} \\cup \\{\\mathcal{A}_\\theta(x_i): \\theta \\in S\\}\\right)$，然后直接对 $D'$ 执行 $k$-折 CV。设 $V'_1, \\dots, V'_k$ 为折， $T'_j$ 为它们的补集。泄漏估计量为\n$$\n\\widehat{\\text{Acc}}_{\\text{leak}} = \\frac{1}{k} \\sum_{j=1}^k \\frac{1}{|V'_j|} \\sum_{(i,\\phi) \\in V'_j} \\mathbf{1}\\left\\{ \\arg\\min_{c \\in \\{0,1\\}} \\| \\mathcal{A}_\\phi (x_i) - \\tilde{\\mu}_{c}^{(j)} \\|_2^2 = y_i \\right\\},\n$$\n其中\n$$\n\\tilde{\\mu}_{c}^{(j)} = \\frac{1}{|\\{(t,\\psi) \\in T'_j: y_t = c\\}|} \\sum_{(t,\\psi) \\in T'_j, y_t=c} \\mathcal{A}_\\psi(x_t).\n$$\n\n偏差机制：\n在适当的程序中，验证集中的 $x_i$（无论是直接还是通过其变换副本）不会在训练中使用。在泄漏程序中，对于许多 $i$，某些变换后的 $\\mathcal{A}_\\psi(x_i)$ 可能存在于训练集中，而 $\\mathcal{A}_\\phi(x_i)$ 则用于验证，这在训练和验证样本之间造成了高相关性。对于最近质心分类器，这种相关性会减少 $\\| \\mathcal{A}_\\phi (x_i) - \\tilde{\\mu}_{y_i}^{(j)} \\|_2^2$ 并增加正确分类的概率，因此平均而言 $\\widehat{\\text{Acc}}_{\\text{leak}} \\ge \\widehat{\\text{Acc}}_{\\text{proper}}$。我们感兴趣的量是其差值\n$$\n\\Delta = \\widehat{\\text{Acc}}_{\\text{leak}} - \\widehat{\\text{Acc}}_{\\text{proper}}.\n$$\n\n算法设计：\n1. 合成数据生成：\n   - 创建 $n$ 个大小为 $h \\times w$ 的基础图像。对于类别 0，通过设置穿过中心的垂直和水平条中的像素来绘制一个中心化的“+”图案，线条粗细随机（例如 1 或 2 像素），中心有微小的随机偏移。对于类别 1，通过沿两条对角线设置像素来绘制一个中心化的“×”图案，线条粗细和偏移与前者类似。\n   - 为每个像素添加标准差为 $\\sigma$ 的独立高斯噪声，并将值裁剪到 $[0,1]$ 范围内。\n   - 分配标签，使每个类别包含 $n/2$ 个图像（平衡的），然后打乱顺序。\n\n2. 增强算子：\n   - 对于以度为单位的角度 $\\theta \\in S \\subseteq \\{90,180,270\\}$，通过 $90$ 度的增量（即使用 $k = \\theta/90$ 的 $\\text{np.rot90}$）实现 $\\mathcal{A}_\\theta$，并保持标签不变。\n\n3. 分类器：\n   - 基于平方 $\\ell_2$ 距离的最近质心分类器。为进行计算，将图像展平为 $\\mathbb{R}^{h \\cdot w}$ 中的向量。根据训练集（根据需要包括增强样本）计算类别质心，并通过最近质心预测验证样本的类别。\n\n4. $k$-折划分：\n   - 对于适当增强的 CV，将 $n$ 个基础样本划分为 $k$ 个折。对于折 $j$，仅使用 $S$ 中的角度增强训练集，保持验证集不增强，训练质心，并在验证折上计算准确率。对所有折求平均以获得 $\\widehat{\\text{Acc}}_{\\text{proper}}$。\n   - 对于泄漏的 CV，首先增强整个数据集（包括原始图像和 $S$ 中的旋转图像），然后在此增强数据集上执行 $k$-折 CV，在增强样本上进行训练和验证，以获得 $\\widehat{\\text{Acc}}_{\\text{leak}}$。\n\n5. 差值：\n   - 为每个测试用例计算 $\\Delta$。\n\n测试套件覆盖范围的基本原理：\n- 用例 1 使用适中的 $k$、多个角度和较小的噪声，代表一个典型场景。\n- 用例 2 使用 $S = \\varnothing$（无增强），此时我们预期 $\\Delta \\approx 0$，因为两种程序完全相同。\n- 用例 3 使用较小的 $k$，这增加了增强副本跨折出现的几率，可能放大泄漏效应。\n- 用例 4 增加了噪声 $\\sigma$，以检验鲁棒性；在嘈杂条件下，泄漏会人为地提升性能。\n- 用例 5 使用 $k = 10$ 和单个角度，测试对增强集大小的敏感性。\n\n最终输出：\n单行输出 $[\\Delta_1,\\Delta_2,\\Delta_3,\\Delta_4,\\Delta_5]$，其中浮点数按顺序对应上述用例。\n\n此设计严格遵守 CV 背后的独立性原则，并通过计算揭示了如何通过增强泄漏违反该原则，从而在估计的准确率中产生乐观偏差。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef make_plus_image(h, w, thickness, off_y, off_x):\n    \"\"\"\n    Create a centered plus '+' pattern with given thickness and small offsets.\n    Intensities are 1.0 on the pattern, 0.0 elsewhere.\n    \"\"\"\n    img = np.zeros((h, w), dtype=np.float64)\n    cy = h // 2 + off_y\n    cx = w // 2 + off_x\n    # Horizontal bar\n    y_start = max(cy - thickness, 0)\n    y_end = min(cy + thickness + 1, h)\n    img[y_start:y_end, :] = 1.0\n    # Vertical bar\n    x_start = max(cx - thickness, 0)\n    x_end = min(cx + thickness + 1, w)\n    img[:, x_start:x_end] = 1.0\n    return img\n\ndef make_x_image(h, w, thickness, off_y, off_x):\n    \"\"\"\n    Create a centered 'x' pattern (two diagonals) with given thickness and small offsets.\n    Intensities are 1.0 on the pattern, 0.0 elsewhere.\n    \"\"\"\n    img = np.zeros((h, w), dtype=np.float64)\n    cy = h // 2 + off_y\n    cx = w // 2 + off_x\n    # Draw diagonals with thickness by marking pixels close to diagonal lines\n    yy, xx = np.meshgrid(np.arange(h), np.arange(w), indexing='ij')\n    # Centered diagonals adjusted by offsets\n    # Line 1: slope +1 through (cy, cx) => y - x = cy - cx\n    d1 = np.abs((yy - xx) - (cy - cx))\n    # Line 2: slope -1 through (cy, cx) => y + x = cy + cx\n    d2 = np.abs((yy + xx) - (cy + cx))\n    mask = (d1 = thickness) | (d2 = thickness)\n    img[mask] = 1.0\n    return img\n\ndef add_noise_and_clip(img, noise_std, rng):\n    noisy = img + rng.normal(loc=0.0, scale=noise_std, size=img.shape)\n    return np.clip(noisy, 0.0, 1.0)\n\ndef generate_dataset(n, h, w, noise_std, seed):\n    \"\"\"\n    Generate n base images: half '+' class (label 0), half 'x' class (label 1),\n    with random thickness and small offsets, plus Gaussian noise.\n    Returns images (n, h, w) and labels (n,).\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    images = np.zeros((n, h, w), dtype=np.float64)\n    labels = np.zeros(n, dtype=np.int64)\n    # Balanced labels: 0 then 1 alternating\n    base_labels = np.array([0, 1] * (n // 2) + ([0] if n % 2 == 1 else []), dtype=np.int64)\n    # Shuffle labels for randomness\n    rng.shuffle(base_labels)\n    for i in range(n):\n        c = base_labels[i]\n        labels[i] = c\n        thickness = rng.integers(0, 2)  # 0 or 1, which translates to thickness 1 or 2\n        off_y = rng.integers(-1, 2)     # -1, 0, 1\n        off_x = rng.integers(-1, 2)     # -1, 0, 1\n        if c == 0:\n            img = make_plus_image(h, w, thickness, off_y, off_x)\n        else:\n            img = make_x_image(h, w, thickness, off_y, off_x)\n        img = add_noise_and_clip(img, noise_std, rng)\n        images[i] = img\n    return images, labels\n\ndef rotate_image(img, angle_deg):\n    \"\"\"\n    Rotate the image by angle degrees (must be in {90,180,270}) using np.rot90.\n    \"\"\"\n    if angle_deg % 90 != 0 or angle_deg == 0:\n        raise ValueError(\"Only 90, 180, 270 degrees supported for augmentation\")\n    k = (angle_deg // 90) % 4\n    return np.rot90(img, k)\n\ndef augment_images(images, labels, angles):\n    \"\"\"\n    For each image, return list of (original + rotated versions) according to angles.\n    \"\"\"\n    augmented_imgs = []\n    augmented_labels = []\n    for img, y in zip(images, labels):\n        # include original\n        augmented_imgs.append(img)\n        augmented_labels.append(y)\n        for ang in angles:\n            aug = rotate_image(img, ang)\n            augmented_imgs.append(aug)\n            augmented_labels.append(y)\n    return np.array(augmented_imgs), np.array(augmented_labels)\n\ndef kfold_indices(n, k, seed):\n    \"\"\"\n    Return list of k folds, each a numpy array of indices.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    indices = np.arange(n, dtype=np.int64)\n    rng.shuffle(indices)\n    folds = np.array_split(indices, k)\n    return folds\n\ndef compute_centroids(X_train, y_train):\n    \"\"\"\n    Compute class centroids for labels 0 and 1.\n    \"\"\"\n    c0 = (y_train == 0)\n    c1 = (y_train == 1)\n    if not np.any(c0) or not np.any(c1):\n        mu0 = X_train[c0].mean(axis=0) if np.any(c0) else np.zeros(X_train.shape[1], dtype=np.float64)\n        mu1 = X_train[c1].mean(axis=0) if np.any(c1) else np.zeros(X_train.shape[1], dtype=np.float64)\n        return mu0, mu1\n    mu0 = X_train[c0].mean(axis=0)\n    mu1 = X_train[c1].mean(axis=0)\n    return mu0, mu1\n\ndef predict_nearest_centroid(X_val, mu0, mu1):\n    \"\"\"\n    Predict labels for validation set X_val given centroids mu0 and mu1.\n    \"\"\"\n    d0 = np.sum((X_val - mu0) ** 2, axis=1)\n    d1 = np.sum((X_val - mu1) ** 2, axis=1)\n    return (d1  d0).astype(np.int64)\n\ndef cross_val_accuracy_proper(images, labels, k, angles, seed):\n    \"\"\"\n    Proper augmentation: augment only training folds; validate on original base images.\n    \"\"\"\n    n = images.shape[0]\n    folds = kfold_indices(n, k, seed)\n    h, w = images.shape[1], images.shape[2]\n    accs = []\n    for fold in folds:\n        val_idx = fold\n        train_idx = np.setdiff1d(np.arange(n, dtype=np.int64), val_idx, assume_unique=True)\n        \n        X_train_list = []\n        y_train_list = []\n        for idx in train_idx:\n            img = images[idx]\n            y = labels[idx]\n            X_train_list.append(img.reshape(h * w))\n            y_train_list.append(y)\n            for ang in angles:\n                aug = rotate_image(img, ang)\n                X_train_list.append(aug.reshape(h * w))\n                y_train_list.append(y)\n        X_train = np.stack(X_train_list, axis=0)\n        y_train = np.array(y_train_list, dtype=np.int64)\n        mu0, mu1 = compute_centroids(X_train, y_train)\n        \n        X_val = images[val_idx].reshape(len(val_idx), h * w)\n        y_val = labels[val_idx]\n        y_pred = predict_nearest_centroid(X_val, mu0, mu1)\n        acc = np.mean(y_pred == y_val)\n        accs.append(acc)\n    return float(np.mean(accs))\n\ndef cross_val_accuracy_leak(images, labels, k, angles, seed):\n    \"\"\"\n    Leakage augmentation: augment entire dataset first, then perform k-fold CV.\n    \"\"\"\n    aug_imgs, aug_labels = augment_images(images, labels, angles)\n    n_aug = aug_imgs.shape[0]\n    if n_aug == 0: return 0.5 # or some other baseline if no data\n    if len(angles) == 0: # special case, no augmentation\n        return cross_val_accuracy_proper(images, labels, k, angles, seed)\n\n    folds = kfold_indices(n_aug, k, seed)\n    h, w = images.shape[1], images.shape[2]\n    accs = []\n    for fold in folds:\n        val_idx = fold\n        train_idx = np.setdiff1d(np.arange(n_aug, dtype=np.int64), val_idx, assume_unique=True)\n        \n        X_train = aug_imgs[train_idx].reshape(len(train_idx), h * w)\n        y_train = aug_labels[train_idx]\n        mu0, mu1 = compute_centroids(X_train, y_train)\n        \n        X_val = aug_imgs[val_idx].reshape(len(val_idx), h * w)\n        y_val = aug_labels[val_idx]\n        y_pred = predict_nearest_centroid(X_val, mu0, mu1)\n        acc = np.mean(y_pred == y_val)\n        accs.append(acc)\n    return float(np.mean(accs))\n\ndef compute_delta(n, h, w, k, angles, noise_std, seed):\n    images, labels = generate_dataset(n, h, w, noise_std, seed)\n    acc_proper = cross_val_accuracy_proper(images, labels, k, list(angles), seed)\n    acc_leak = cross_val_accuracy_leak(images, labels, k, list(angles), seed)\n    return acc_leak - acc_proper\n\ndef solve():\n    test_cases = [\n        (60, 16, 16, 5, {90, 180, 270}, 0.10, 42),\n        (60, 16, 16, 5, set(), 0.10, 43),\n        (60, 16, 16, 2, {90, 180, 270}, 0.10, 44),\n        (60, 16, 16, 5, {90, 180, 270}, 0.50, 45),\n        (60, 16, 16, 10, {90}, 0.10, 46),\n    ]\n\n    results = []\n    for case in test_cases:\n        n, h, w, k, angles, noise_std, seed = case\n        delta = compute_delta(n, h, w, k, angles, noise_std, seed)\n        results.append(f\"{delta:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3134696"}, {"introduction": "除了防止错误，交叉验证的主要作用是构建鲁棒的模型，特别是通过超参数调优。本练习侧重于一个经典应用：为二元分类器选择最佳决策阈值以最大化 $F_\\beta$ 分数。您将实现并比较在整个数据集上找到的阈值与通过 K 折交叉验证得出的阈值，从而证明交叉验证如何帮助我们做出更具泛化能力的的参数选择。[@problem_id:3139044]", "problem": "给定一个深度学习模型的二进制分类输出，其形式为预测概率和真实标签。考虑一个由阈值 $t \\in [0,1]$ 参数化的决策规则，定义为：如果 $p_i \\ge t$，则 $\\hat{y}_i(t) = 1$，否则 $\\hat{y}_i(t) = 0$。其中 $\\mathbf{p} = (p_1,\\dots,p_N)$ 是预测概率，$\\mathbf{y} = (y_1,\\dots,y_N)$ 是真实标签，且 $y_i \\in \\{0,1\\}$。将阈值 $t$ 的混淆计数定义为 $\\mathrm{TP}(t)$、$\\mathrm{FP}(t)$ 和 $\\mathrm{FN}(t)$，分别代表真阳性、假阳性以及假阴性。\n\n加权 $F$-分数（$F_\\beta$ 分数）是为 $\\beta  0$ 定义的，它使用了经过充分检验的精确率 (precision) 和召回率 (recall) 公式。一种基于计数的、在边缘情况下也能良好定义的形式是：\n$$\nF_\\beta(t) = \\frac{(1+\\beta^2)\\,\\mathrm{TP}(t)}{(1+\\beta^2)\\,\\mathrm{TP}(t) + \\beta^2\\,\\mathrm{FN}(t) + \\mathrm{FP}(t)}.\n$$\n您将使用 $k$ 折交叉验证 (CV) 来实现 $F_\\beta$ 的阈值选择，比较聚合阈值与全局阈值，并研究在类别不平衡情况下的影响。请使用以下基础：精确率、召回率和 $F_\\beta$ 的定义，二进制决策规则 $\\hat{y}_i(t)$，以及标准的 $k$ 折交叉验证过程。该过程将索引划分为 $k$ 个连续的折 (fold)，各折的大小应尽可能相等，最多相差一个。\n\n算法要求：\n- 对于任何数据集 $(\\mathbf{p},\\mathbf{y})$，将全局阈值 $t^*$ 定义为在完整数据集上使 $F_\\beta(t)$ 最大化的 $t$ 值。请论证并实现一个离散搜索，搜索的候选阈值集由 $\\mathbf{p}$ 中所有唯一的预测概率以及增补的 $0$ 和 $1+\\epsilon$（其中 $\\epsilon = 10^{-6}$）组成。这种做法是有效的，因为决策规则仅在 $t$ 穿过一个预测概率值时才会改变，这使得 $F_\\beta(t)$ 在这些点之间是分段常数。\n- 通过选择在达到最大 $F_\\beta$ 值的阈值中最小的一个来解决平局问题。\n- 对于 $k$ 折交叉验证，将索引集 $\\{1,\\dots,N\\}$ 划分为 $k$ 个连续的折，其大小最多相差一（前 $r = N \\bmod k$ 个折的大小为 $\\lfloor N/k \\rfloor + 1$，其余折的大小为 $\\lfloor N/k \\rfloor$）。对于每个折 $j \\in \\{1,\\dots,k\\}$，仅使用该折的验证数据计算出使 $F_\\beta(t)$ 最大化的折最优阈值 $t_j$。将聚合阈值定义为 $\\bar{t} = \\frac{1}{k}\\sum_{j=1}^k t_j$。\n- 通过在完整数据集上评估 $F_\\beta(t^*)$ 和 $F_\\beta(\\bar{t})$，来比较全局阈值 $t^*$ 和聚合阈值 $\\bar{t}$。\n\n测试套件：\n- 案例 A（平衡，$k=5$，$\\beta=1$）：\n  - $\\mathbf{y} = [$ $1$, $0$, $1$, $0$, $1$, $0$, $1$, $0$, $1$, $0$, $1$, $0$, $1$, $0$, $1$, $0$, $1$, $0$, $1$, $0$ $]$。\n  - $\\mathbf{p} = [$ $0.92$, $0.18$, $0.88$, $0.32$, $0.83$, $0.41$, $0.77$, $0.47$, $0.71$, $0.52$, $0.66$, $0.56$, $0.61$, $0.60$, $0.59$, $0.62$, $0.58$, $0.63$, $0.54$, $0.68$ $]$。\n- 案例 B（不平衡，$k=3$，$\\beta=2$）：\n  - $\\mathbf{y}$ 的大小 $N = 30$，其中正例位于索引 $3, 7, 12, 18, 24, 29$ 处（描述使用基于 0 的索引）：$\\mathbf{y} = [$ $0$, $0$, $0$, $1$, $0$, $0$, $0$, $1$, $0$, $0$, $0$, $0$, $1$, $0$, $0$, $0$, $0$, $0$, $1$, $0$, $0$, $0$, $0$, $0$, $1$, $0$, $0$, $0$, $0$, $1$ $]$。\n  - $\\mathbf{p} = [$ $0.05$, $0.15$, $0.20$, $0.90$, $0.25$, $0.30$, $0.35$, $0.87$, $0.40$, $0.45$, $0.50$, $0.55$, $0.89$, $0.58$, $0.62$, $0.66$, $0.70$, $0.74$, $0.86$, $0.78$, $0.60$, $0.52$, $0.48$, $0.44$, $0.92$, $0.42$, $0.38$, $0.34$, $0.80$, $0.88$ $]$。\n- 案例 C（极端不平衡，$k=5$，$\\beta=0.5$）：\n  - $\\mathbf{y}$ 的大小 $N = 15$，只有一个正例，位于索引 $11$ 处：$\\mathbf{y} = [$ $0$, $0$, $0$, $0$, $0$, $0$, $0$, $0$, $0$, $0$, $0$, $1$, $0$, $0$, $0$ $]$。\n  - $\\mathbf{p} = [$ $0.10$, $0.20$, $0.30$, $0.40$, $0.45$, $0.50$, $0.55$, $0.60$, $0.65$, $0.85$, $0.88$, $0.95$, $0.70$, $0.72$, $0.75$ $]$。\n\n您的程序必须：\n- 完全按照规定实现阈值搜索和 $k$ 折交叉验证聚合，包括平局解决规则和使用 $\\epsilon = 10^{-6}$ 增广候选集。\n- 对于每个测试案例，计算全局阈值 $t^*$、聚合阈值 $\\bar{t}$，以及在完整数据集上评估的相应分数 $F_\\beta(t^*)$ 和 $F_\\beta(\\bar{t})$。\n\n最终输出格式：\n- 生成单行输出，其中包含三个测试案例的结果，形式为一个扁平的、用逗号分隔的列表，并用方括号括起来。该列表必须是\n  - [$t^*_A$, $\\bar{t}_A$, $F_\\beta(t^*_A)$, $F_\\beta(\\bar{t}_A)$, $t^*_B$, $\\bar{t}_B$, $F_\\beta(t^*_B)$, $F_\\beta(\\bar{t}_B)$, $t^*_C$, $\\bar{t}_C$, $F_\\beta(t^*_C)$, $F_\\beta(\\bar{t}_C)$]，\n  其中每个数值都格式化为六位小数。", "solution": "用户提供了一个在机器学习模型评估领域中定义明确的计算问题。该问题具有科学依据，可以形式化，并且是自包含的。所有必要的数据、定义和算法过程都已明确指定，没有歧义。因此，该问题是有效的，并将提供一个解决方案。\n\n问题的核心是比较为二进制分类器选择分类阈值 $t$ 的两种策略。在给定阈值下，分类器的性能通过加权 $F_\\beta$ 分数来衡量。\n\n首先，让我们将各个组成部分形式化。给定一组 $N$ 个真实标签 $\\mathbf{y} = (y_1, \\dots, y_N)$，其中 $y_i \\in \\{0,1\\}$，以及一组对应的预测概率 $\\mathbf{p} = (p_1, \\dots, p_N)$，其中 $p_i \\in [0,1]$。决策阈值 $t$ 用于将这些概率转换为二进制预测 $\\hat{\\mathbf{y}}(t) = (\\hat{y}_1(t), \\dots, \\hat{y}_N(t))$，其规则如下：\n$$\n\\hat{y}_i(t) = \\begin{cases} 1  \\text{if } p_i \\ge t \\\\ 0  \\text{if } p_i  t \\end{cases}\n$$\n基于这些预测，我们可以计算真阳性（$\\mathrm{TP}$）、假阳性（$\\mathrm{FP}$）和假阴性（$\\mathrm{FN}$）的数量，它们都是 $t$ 的函数：\n$$\n\\mathrm{TP}(t) = \\sum_{i=1}^N \\mathbf{1}(p_i \\ge t \\land y_i = 1)\n$$\n$$\n\\mathrm{FP}(t) = \\sum_{i=1}^N \\mathbf{1}(p_i \\ge t \\land y_i = 0)\n$$\n$$\n\\mathrm{FN}(t) = \\sum_{i=1}^N \\mathbf{1}(p_i  t \\land y_i = 1)\n$$\n其中 $\\mathbf{1}(\\cdot)$ 是指示函数。问题为给定的 $\\beta  0$ 提供了一个稳健的、基于计数的 $F_\\beta$ 分数定义：\n$$\nF_\\beta(t) = \\frac{(1+\\beta^2)\\,\\mathrm{TP}(t)}{(1+\\beta^2)\\,\\mathrm{TP}(t) + \\beta^2\\,\\mathrm{FN}(t) + \\mathrm{FP}(t)}\n$$\n即使在预测正例总数或实际正例总数为零的情况下，这种形式也具有良好的定义，此时分子为 $0$。如果分母也为 $0$（即 $\\mathrm{TP}=\\mathrm{FP}=\\mathrm{FN}=0$），则分数取为 $0$。\n\n主要任务是实现一个算法来找到使 $F_\\beta(t)$ 最大化的最优阈值 $t$。问题规定了一个特定的搜索策略。寻找最优 $t$ 不需要扫描整个区间 $[0,1]$。$\\mathrm{TP}(t)$、$\\mathrm{FP}(t)$ 和 $\\mathrm{FN}(t)$ 的值仅在阈值 $t$ 穿过某个概率值 $p_i$ 时才会改变。因此，函数 $F_\\beta(t)$ 是分段常数。可以在一个离散的候选阈值集上进行完整搜索。指定的候选集由 $\\mathbf{p}$ 中所有唯一的概率分数以及两个特殊值组成：$0$ 和 $1+\\epsilon$，其中 $\\epsilon=10^{-6}$。$t=0$ 考虑了所有样本都被分类为正例的情况，而 $t=1+\\epsilon$ 确保所有样本都被分类为负例（因为某些 $p_i$ 可能恰好为 $1$）。通过搜索这个排序后的候选集，我们可以找到最大的 $F_\\beta$ 值。问题指定了一个平局解决规则：如果多个阈值产生相同的最大 $F_\\beta$ 分数，必须选择其中最小的阈值。\n\n定义了此优化过程后，我们可以找到两种不同类型的阈值：\n\n1.  **全局阈值 ($t^*$):** 此阈值是通过将上述优化过程应用于整个数据集 $(\\mathbf{y}, \\mathbf{p})$ 来找到的。它代表了对于全部观测数据的单一最佳阈值。\n\n2.  **聚合阈值 ($\\bar{t}$):** 此阈值是使用 $k$ 折交叉验证得出的。数据集的索引 $\\{0, 1, \\dots, N-1\\}$ 被划分为 $k$ 个连续的、不重叠的折。划分是确定性的：前 $r = N \\bmod k$ 个折包含 $\\lfloor N/k \\rfloor + 1$ 个样本，其余的 $k-r$ 个折包含 $\\lfloor N/k \\rfloor$ 个样本。对于每个折 $j \\in \\{1, \\dots, k\\}$，该折内的数据作为验证集。通过仅使用对应于折 $j$ 的数据点 $(\\mathbf{y}_j, \\mathbf{p}_j)$ 来最大化 $F_\\beta(t)$，从而找到该折的最优阈值 $t_j$。然后，聚合阈值计算为这些特定于折的阈值的算术平均值：\n    $$\n    \\bar{t} = \\frac{1}{k} \\sum_{j=1}^k t_j\n    $$\n这种交叉验证方法模拟了在未见过的数据上寻找阈值的过程，而对结果进行平均可以提供一个更稳健的估计，不易对特定的数据划分产生过拟合。\n\n最后，问题要求比较这两种阈值 $t^*$ 和 $\\bar{t}$ 的性能。比较是通过在**整个数据集**上评估每个阈值的 $F_\\beta$ 分数来执行的。这允许直接评估哪种阈值选择策略在全部观测数据分布上产生更好的结果。\n\n该实现将包括三个主要部分：一个用于计算 $F_\\beta(t)$ 的函数，一个用于为给定数据集找到最优阈值的函数，以及一个主程序，用于协调每个测试用例的计算，包括 k 折划分逻辑和最终评估。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to execute the problem's requirements for all test cases.\n    \"\"\"\n    \n    # Define test cases from the problem statement\n    case_a = {\n        \"y\": [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0],\n        \"p\": [0.92, 0.18, 0.88, 0.32, 0.83, 0.41, 0.77, 0.47, 0.71, 0.52, 0.66, 0.56, 0.61, 0.60, 0.59, 0.62, 0.58, 0.63, 0.54, 0.68],\n        \"k\": 5,\n        \"beta\": 1.0,\n    }\n    \n    y_b = np.zeros(30, dtype=int)\n    pos_indices_b = [3, 7, 12, 18, 24, 29]\n    y_b[pos_indices_b] = 1\n    case_b = {\n        \"y\": y_b.tolist(),\n        \"p\": [0.05, 0.15, 0.20, 0.90, 0.25, 0.30, 0.35, 0.87, 0.40, 0.45, 0.50, 0.55, 0.89, 0.58, 0.62, 0.66, 0.70, 0.74, 0.86, 0.78, 0.60, 0.52, 0.48, 0.44, 0.92, 0.42, 0.38, 0.34, 0.80, 0.88],\n        \"k\": 3,\n        \"beta\": 2.0,\n    }\n    \n    y_c = np.zeros(15, dtype=int)\n    y_c[11] = 1\n    case_c = {\n        \"y\": y_c.tolist(),\n        \"p\": [0.10, 0.20, 0.30, 0.40, 0.45, 0.50, 0.55, 0.60, 0.65, 0.85, 0.88, 0.95, 0.70, 0.72, 0.75],\n        \"k\": 5,\n        \"beta\": 0.5,\n    }\n\n    test_cases = [case_a, case_b, case_c]\n    epsilon = 1e-6\n    results = []\n\n    def calculate_f_beta(y, p, t, beta):\n        \"\"\"Calculates the F-beta score for a given threshold.\"\"\"\n        if y.size == 0:\n            return 0.0\n        \n        y_pred = (p >= t).astype(int)\n        \n        tp = np.sum((y_pred == 1)  (y == 1))\n        fp = np.sum((y_pred == 1)  (y == 0))\n        fn = np.sum((y_pred == 0)  (y == 1))\n        \n        beta_sq = beta**2\n        numerator = (1 + beta_sq) * tp\n        denominator = (1 + beta_sq) * tp + beta_sq * fn + fp\n        \n        if denominator == 0:\n            return 0.0\n        else:\n            return numerator / denominator\n\n    def find_optimal_threshold(y, p, beta, epsilon):\n        \"\"\"Finds the optimal threshold that maximizes F-beta score.\"\"\"\n        if y.size == 0:\n            return 0.0\n        \n        unique_p = np.unique(p)\n        candidate_thresholds = np.concatenate(([0.0], unique_p, [1.0 + epsilon]))\n        candidate_thresholds.sort()\n        \n        best_t = candidate_thresholds[0]\n        max_f_beta = -1.0\n        \n        for t in candidate_thresholds:\n            f_beta_score = calculate_f_beta(y, p, t, beta)\n            if f_beta_score > max_f_beta:\n                max_f_beta = f_beta_score\n                best_t = t\n                \n        return best_t\n\n    def process_case(y, p, k, beta, epsilon):\n        \"\"\"Processes a single test case to find thresholds and scores.\"\"\"\n        y = np.array(y)\n        p = np.array(p)\n        N = len(y)\n        \n        t_star = find_optimal_threshold(y, p, beta, epsilon)\n        \n        fold_thresholds = []\n        n_per_fold = N // k\n        n_larger_folds = N % k\n        \n        current_idx = 0\n        for i in range(k):\n            fold_size = n_per_fold + 1 if i  n_larger_folds else n_per_fold\n            fold_indices = np.arange(current_idx, current_idx + fold_size)\n            \n            y_fold = y[fold_indices]\n            p_fold = p[fold_indices]\n            \n            t_j = find_optimal_threshold(y_fold, p_fold, beta, epsilon)\n            fold_thresholds.append(t_j)\n            \n            current_idx += fold_size\n            \n        t_bar = np.mean(fold_thresholds)\n        \n        f_beta_star = calculate_f_beta(y, p, t_star, beta)\n        f_beta_bar = calculate_f_beta(y, p, t_bar, beta)\n        \n        return t_star, t_bar, f_beta_star, f_beta_bar\n\n    for case in test_cases:\n        t_star, t_bar, f_beta_star, f_beta_bar = process_case(\n            case[\"y\"], case[\"p\"], case[\"k\"], case[\"beta\"], epsilon\n        )\n        results.extend([t_star, t_bar, f_beta_star, f_beta_bar])\n\n    formatted_results = [f\"{x:.6f}\" for x in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3139044"}, {"introduction": "交叉验证也可以更动态地集成到训练过程本身中，正如在早停等高级技术中所见。一种简单的方法可能会导致不稳定的决策，但本实践将挑战您实现一个复杂的、统一的早停规则。通过在每个周期聚合所有折的性能信号，该方法确保停止训练的决策是鲁棒的，防止因噪声或单个折的特殊行为而过早终止。[@problem_id:3139126]", "problem": "你的任务是为深度学习模型在$k$-折交叉验证（CV）下推导并实现一个统一的提前停止（ES）规则。请从以下基础依据和定义出发，构建一个有原则的停止准则，该准则能同时减少周期级别的噪声、聚合各折的证据，并避免因任何单折中特有的过拟合而停止。\n\n基础依据和核心定义：\n- 在监督学习中，经验风险最小化（ERM）选择参数以最小化经验风险。给定训练数据和通过周期更新参数的模型，验证损失在每个周期提供了泛化误差的估计。\n- 在$k$-折交叉验证（CV）中，数据被划分为$k$个折；对于$\\{1,\\dots,K\\}$中的每个折$k$，模型在$K-1$个折上进行训练，并在留出的那个折上进行验证，从而产生一个每个周期的验证损失序列$\\{\\ell_{k,t}\\}_{t=0}^{T-1}$。\n- 由于小批量随机性和优化器动态，验证损失在各个周期通常是含噪的。可以通过对每个折独立应用指数移动平均（EMA）来减少噪声，对于平滑系数$\\alpha \\in (0,1)$，定义为$S_{k,0} = \\ell_{k,0}$以及当$t \\ge 1$时，$S_{k,t} = \\alpha S_{k,t-1} + (1-\\alpha)\\ell_{k,t}$。\n- 在周期$t$时跨折的聚合由跨折均值$M_t = \\frac{1}{K}\\sum_{k=1}^{K} S_{k,t}$和跨折标准差$\\sigma_t = \\sqrt{\\frac{1}{K}\\sum_{k=1}^{K} (S_{k,t}-M_t)^2}$来捕捉。\n- 在周期$t$的改进是相对于迄今为止的最佳值来评估的，并带有一个小的容差$\\varepsilon  0$以忽略可忽略不计的变化。定义运行最小值$m_t = \\min\\{M_0,\\dots,M_t\\}$以及每个折$k$的$b_{k,t} = \\min\\{S_{k,0},\\dots,S_{k,t}\\}$。\n\n你的统一停止规则必须同时满足以下所有设计要求：\n1. 跨折平滑：对每个折$k$使用给定的$\\alpha$计算EMA $S_{k,t}$；用$M_t$和$\\sigma_t$进行聚合。\n2. 基于均值的耐心：将周期$t$时跨折均值的未改进指标定义为：如果$M_t  m_{t-1} - \\varepsilon$，则$I_t^{(\\text{mean})} = 1$，否则$I_t^{(\\text{mean})} = 0$（对于$t \\ge 1$；在$t=0$时，视为$I_0^{(\\text{mean})}=0$）。设$p \\in \\mathbb{N}$为耐心参数；要求在周期$t$停止时，$I_{t-p+1}^{(\\text{mean})}=\\dots=I_t^{(\\text{mean})}=1$。\n3. 避免逐折过拟合的跨折共识：在周期$t$，计算相对于各自迄今为止的最佳值未能改进超过$\\varepsilon$的折的比例：$q_t = \\frac{1}{K}\\sum_{k=1}^{K} \\mathbb{1}\\left(S_{k,t}  b_{k,t-1} - \\varepsilon\\right)$（其中$\\mathbb{1}$是指示函数）。设$q \\in (0,1]$为要求的共识阈值；要求在停止周期$t$时，$q_t \\ge q$。\n4. 方差增长控制：为避免在单个折过拟合而其他折仍在改进时停止，要求在停止周期$t$时，$\\sigma_t \\le r \\cdot \\min\\{\\sigma_0,\\dots,\\sigma_t\\}$，其中$r \\ge 1$。\n5. 预热：设$w \\in \\mathbb{N}$；停止规则不能在$t  w$时触发。\n\n将停止周期索引定义为满足所有条件2-5的最早的$t \\in \\{0,\\dots,T-1\\}$；如果不存在这样的周期，则返回$T-1$。所有索引均为从0开始的整数。\n\n你的程序必须实现上述规则，并在以下测试集上进行评估。每个测试用例提供：\n- 一个$K \\times T$的每折验证损失矩阵$\\ell_{k,t}$，\n- 参数$\\alpha$、$\\varepsilon$、$p$、$q$、$r$和$w$。\n\n测试集（所有数字均以小数形式提供；所有周期索引均为从0开始的整数）：\n\n案例1（正常路径平台期）：\n- $K = 5$, $T = 15$，\n- 每折$k=1,\\dots,5$的损失：\n  - 折1: $[1.00, 0.92, 0.85, 0.80, 0.78, 0.77, 0.77, 0.775, 0.78, 0.781, 0.782, 0.783, 0.785, 0.79, 0.795]$\n  - 折2: $[1.05, 0.95, 0.86, 0.81, 0.79, 0.78, 0.78, 0.782, 0.784, 0.785, 0.786, 0.787, 0.79, 0.795, 0.80]$\n  - 折3: $[0.98, 0.90, 0.83, 0.79, 0.77, 0.765, 0.765, 0.767, 0.768, 0.769, 0.77, 0.771, 0.773, 0.775, 0.78]$\n  - 折4: $[1.02, 0.93, 0.84, 0.80, 0.78, 0.77, 0.77, 0.771, 0.772, 0.773, 0.774, 0.776, 0.778, 0.782, 0.785]$\n  - 折5: $[1.01, 0.94, 0.85, 0.81, 0.79, 0.78, 0.78, 0.781, 0.782, 0.784, 0.785, 0.786, 0.788, 0.79, 0.792]$\n- 参数: $\\alpha = 0.6$, $\\varepsilon = 0.001$, $p = 3$, $q = 0.6$, $r = 1.5$, $w = 2$.\n\n案例2（持续改进，直到结束才停止）：\n- $K = 4$, $T = 12$，\n- 损失:\n  - 折1: $[1.2, 1.1, 1.0, 0.9, 0.8, 0.75, 0.70, 0.66, 0.63, 0.60, 0.58, 0.56]$\n  - 折2: $[1.3, 1.18, 1.06, 0.95, 0.85, 0.78, 0.72, 0.67, 0.64, 0.61, 0.59, 0.57]$\n  - 折3: $[1.15, 1.05, 0.96, 0.88, 0.81, 0.75, 0.71, 0.67, 0.64, 0.61, 0.59, 0.57]$\n  - 折4: $[1.25, 1.13, 1.00, 0.90, 0.82, 0.76, 0.71, 0.67, 0.64, 0.61, 0.59, 0.56]$\n- 参数: $\\alpha = 0.5$, $\\varepsilon = 0.0005$, $p = 2$, $q = 0.75$, $r = 2.0$, $w = 0$.\n\n案例3（噪声较大且一个折严重过拟合；方差控制防止了过早停止）：\n- $K = 3$, $T = 18$，\n- 损失:\n  - 折1: $[0.9, 0.85, 0.82, 0.79, 0.77, 0.76, 0.755, 0.753, 0.752, 0.753, 0.755, 0.758, 0.761, 0.765, 0.77, 0.772, 0.775, 0.778]$\n  - 折2: $[0.92, 0.86, 0.83, 0.80, 0.78, 0.765, 0.76, 0.76, 0.761, 0.763, 0.766, 0.77, 0.775, 0.78, 0.785, 0.79, 0.795, 0.80]$\n  - 折3: $[0.88, 0.84, 0.81, 0.78, 0.76, 0.75, 0.745, 0.743, 0.744, 0.748, 0.753, 0.759, 0.766, 0.775, 0.785, 0.795, 0.805, 0.815]$\n- 参数: $\\alpha = 0.7$, $\\varepsilon = 0.0015$, $p = 3$, $q = \\frac{2}{3}$, $r = 1.3$, $w = 3$.\n\n案例4（均值进入平台期但大多数折仍在改进；高共识阈值延迟停止）：\n- $K = 5$, $T = 14$，\n- 损失:\n  - 折1: $[1.0, 0.93, 0.87, 0.83, 0.80, 0.79, 0.785, 0.784, 0.784, 0.785, 0.786, 0.787, 0.788, 0.789]$\n  - 折2: $[0.99, 0.92, 0.86, 0.82, 0.79, 0.78, 0.775, 0.773, 0.772, 0.772, 0.773, 0.774, 0.776, 0.778]$\n  - 折3: $[1.02, 0.94, 0.88, 0.84, 0.81, 0.80, 0.796, 0.795, 0.795, 0.796, 0.797, 0.798, 0.799, 0.80]$\n  - 折4: $[1.01, 0.93, 0.87, 0.83, 0.80, 0.79, 0.785, 0.783, 0.782, 0.782, 0.783, 0.784, 0.786, 0.788]$\n  - 折5: $[1.03, 0.95, 0.89, 0.85, 0.82, 0.81, 0.805, 0.804, 0.804, 0.805, 0.806, 0.808, 0.81, 0.812]$\n- 参数: $\\alpha = 0.6$, $\\varepsilon = 0.001$, $p = 2$, $q = 0.8$, $r = 1.4$, $w = 2$.\n\n案例5（早期平台期但预热阶段防止了过早停止）：\n- $K = 4$, $T = 10$，\n- 损失:\n  - 折1: $[0.8, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.771, 0.772, 0.773]$\n  - 折2: $[0.82, 0.79, 0.78, 0.78, 0.78, 0.78, 0.781, 0.782, 0.783, 0.784]$\n  - 折3: $[0.81, 0.79, 0.78, 0.78, 0.78, 0.781, 0.782, 0.783, 0.784, 0.785]$\n  - 折4: $[0.83, 0.80, 0.79, 0.79, 0.79, 0.79, 0.791, 0.792, 0.793, 0.794]$\n- 参数: $\\alpha = 0.5$, $\\varepsilon = 0.0008$, $p = 2$, $q = 0.75$, $r = 1.2$, $w = 5$.\n\n最终输出规范：\n- 你的程序应生成单行输出，其中包含案例1-5的停止周期，形式为逗号分隔的列表并用方括号括起，例如：$[e_1,e_2,e_3,e_4,e_5]$。\n- 每个$e_i$必须是对应案例中$\\{0,\\dots,T-1\\}$范围内的整数周期索引。", "solution": "该问题要求推导并实现一个用于$k$-折交叉验证训练的深度学习模型的统一提前停止规则。该规则基于一组明确定义的数学和逻辑条件。因此，解决方案是构建一个精确实现这些定义和条件的算法。\n\n整个算法过程可分为两个主要阶段：\n1.  **时间序列指标的预计算：** 对于所有周期 $t \\in \\{0, \\dots, T-1\\}$，我们首先从原始的每折验证损失 $\\{\\ell_{k,t}\\}$ 中计算所有必要的统计量。\n2.  **迭代搜索停止周期：** 然后我们从指定的预热期开始遍历各个周期，以找到第一个同时满足所有停止条件的周期。\n\n让我们详细说明每个阶段涉及的步骤。\n\n**阶段1：指标的预计算**\n\n给定$K \\times T$的验证损失矩阵$\\ell_{k,t}$，我们为从$0$到$T-1$的每个周期$t$计算以下量。\n\n-   **平滑后的每折损失（$S_{k,t}$）：** 为减少周期级别的噪声，对每个折的损失序列应用指数移动平均（EMA）。折$k$在周期$t$的平滑损失$S_{k,t}$由以下递推关系定义：\n    $$\n    S_{k,t} = \\begin{cases} \\ell_{k,0}  \\text{if } t = 0 \\\\ \\alpha S_{k,t-1} + (1-\\alpha)\\ell_{k,t}  \\text{if } t \\ge 1 \\end{cases}\n    $$\n    其中$\\alpha \\in (0,1)$是平滑系数。\n\n-   **跨折聚合（$M_t, \\sigma_t$）：** 在每个周期$t$，所有$K$个折的平滑损失被聚合成一个均值$M_t$和一个总体标准差$\\sigma_t$：\n    $$\n    M_t = \\frac{1}{K}\\sum_{k=1}^{K} S_{k,t}\n    $$\n    $$\n    \\sigma_t = \\sqrt{\\frac{1}{K}\\sum_{k=1}^{K} (S_{k,t}-M_t)^2}\n    $$\n\n-   **运行最小值（$m_t, b_{k,t}$）：** 为了跟踪进展，我们为聚合均值和单个折的损失维持迄今为止见过的最佳（最小）值。\n    -   跨折均值的运行最小值为$m_t = \\min\\{M_0, M_1, \\dots, M_t\\}$。\n    -   每个折的平滑损失的运行最小值为$b_{k,t} = \\min\\{S_{k,0}, S_{k,1}, \\dots, S_{k,t}\\}$。\n\n-   **派生指标（$I_t^{(\\text{mean})}, q_t$）：** 使用上述量，我们计算两个主要的未改进指标。\n    -   **均值未改进指标（$I_t^{(\\text{mean})}$）：** 这个二元指标标记跨折均值$M_t$是否未能有效改进其迄今为止的最佳值$m_{t-1}$。\n        $$\n        I_t^{(\\text{mean})} = \\begin{cases} 0  \\text{if } t = 0 \\\\ 1  \\text{if } t \\ge 1 \\text{ and } M_t  m_{t-1} - \\varepsilon \\\\ 0  \\text{if } t \\ge 1 \\text{ and } M_t \\le m_{t-1} - \\varepsilon \\end{cases}\n        $$\n        其中$\\varepsilon  0$是一个小容差。\n    -   **折共识指标（$q_t$）：** 该指标量化了未能改进其自身最佳平滑损失$b_{k,t-1}$的折的比例。对于$t \\ge 1$，其定义为：\n        $$\n        q_t = \\frac{1}{K}\\sum_{k=1}^{K} \\mathbb{1}\\left(S_{k,t}  b_{k,t-1} - \\varepsilon\\right)\n        $$\n        其中$\\mathbb{1}(\\cdot)$是指示函数。对于$t=0$，$q_0$被视为$0$，因为没有先前的历史记录可供改进。\n\n**阶段2：确定停止周期**\n\n在为每个周期预计算了所有必要的指标之后，我们搜索停止周期，该周期定义为满足一组五个条件的最早整数周期索引$t$。我们从$t=0$到$T-1$进行迭代，并检查以下条件：\n\n1.  **预热（$w$）：** 该规则不能在指定的预热期之前触发。条件是$t \\ge w$，其中$w \\in \\mathbb{N}$。\n\n2.  **基于均值的耐心（$p$）：** 跨折均值必须连续$p$个周期未能改进。这要求均值未改进指标在整个耐心窗口内都处于激活状态：\n    $$\n    I_{t'}^{(\\text{mean})} = 1 \\quad \\forall t' \\in \\{t-p+1, \\dots, t\\}\n    $$\n    此条件意味着$t$也必须至少为$p-1$。\n\n3.  **跨折共识（$q$）：** 必须有最小比例的折同意训练不再有成效。条件是未改进的折的比例$q_t$必须达到或超过一个阈值$q \\in (0,1]$：\n    $$\n    q_t \\ge q\n    $$\n\n4.  **方差增长控制（$r$）：** 为防止因单个折的特有过度拟合（这会增加方差）而停止，跨折标准差$\\sigma_t$不得与其历史最小值相比过大。条件是：\n    $$\n    \\sigma_t \\le r \\cdot \\min\\{\\sigma_0, \\sigma_1, \\dots, \\sigma_t\\}\n    $$\n    其中因子$r \\ge 1$。\n\n停止周期是满足所有这四个条件的第一个$t$值（预热是第一道门槛）。如果循环完成而没有找到任何这样的$t$，则表示根据该规则过程尚未收敛，训练应继续到最后一个周期。在这种情况下，停止周期被指定为$T-1$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef find_stopping_epoch(losses, alpha, eps, p, q, r, w):\n    \"\"\"\n    Implements the unified Early Stopping rule under k-fold Cross-Validation.\n    \"\"\"\n    K, T = losses.shape\n\n    if T = 1:\n        return T - 1 if T > 0 else 0\n\n    S = np.zeros_like(losses, dtype=float)\n    S[:, 0] = losses[:, 0]\n    for t in range(1, T):\n        S[:, t] = alpha * S[:, t - 1] + (1 - alpha) * losses[:, t]\n\n    M = np.mean(S, axis=0)\n    sigma = np.std(S, axis=0, ddof=0)\n\n    m = np.minimum.accumulate(M)\n    b = np.minimum.accumulate(S, axis=1)\n\n    I_mean = np.zeros(T, dtype=int)\n    for t in range(1, T):\n        if M[t] > m[t - 1] - eps:\n            I_mean[t] = 1\n\n    q_t_arr = np.zeros(T)\n    for t in range(1, T):\n        not_improving_folds = S[:, t] > b[:, t - 1] - eps\n        q_t_arr[t] = np.mean(not_improving_folds)\n\n    consecutive_ones = np.zeros(T, dtype=int)\n    for t in range(1, T):\n        if I_mean[t] == 1:\n            consecutive_ones[t] = consecutive_ones[t - 1] + 1\n    \n    min_sigma_so_far = np.minimum.accumulate(sigma)\n\n    for t in range(T):\n        if t  w:\n            continue\n\n        if p > 0:\n            mean_patience_cond = (consecutive_ones[t] >= p)\n        else:\n            mean_patience_cond = True\n        \n        if not mean_patience_cond:\n            continue\n        \n        consensus_cond = (q_t_arr[t] >= q)\n        if not consensus_cond:\n            continue\n\n        variance_cond = (sigma[t] = r * min_sigma_so_far[t])\n        if not variance_cond:\n            continue\n        \n        return t\n\n    return T - 1\n\ndef solve():\n    \"\"\"\n    Defines test cases and runs the solver for each case.\n    \"\"\"\n    test_cases = [\n        # Case 1\n        (np.array([\n            [1.00, 0.92, 0.85, 0.80, 0.78, 0.77, 0.77, 0.775, 0.78, 0.781, 0.782, 0.783, 0.785, 0.79, 0.795],\n            [1.05, 0.95, 0.86, 0.81, 0.79, 0.78, 0.78, 0.782, 0.784, 0.785, 0.786, 0.787, 0.79, 0.795, 0.80],\n            [0.98, 0.90, 0.83, 0.79, 0.77, 0.765, 0.765, 0.767, 0.768, 0.769, 0.77, 0.771, 0.773, 0.775, 0.78],\n            [1.02, 0.93, 0.84, 0.80, 0.78, 0.77, 0.77, 0.771, 0.772, 0.773, 0.774, 0.776, 0.778, 0.782, 0.785],\n            [1.01, 0.94, 0.85, 0.81, 0.79, 0.78, 0.78, 0.781, 0.782, 0.784, 0.785, 0.786, 0.788, 0.79, 0.792]\n        ]), 0.6, 0.001, 3, 0.6, 1.5, 2),\n        # Case 2\n        (np.array([\n            [1.2, 1.1, 1.0, 0.9, 0.8, 0.75, 0.70, 0.66, 0.63, 0.60, 0.58, 0.56],\n            [1.3, 1.18, 1.06, 0.95, 0.85, 0.78, 0.72, 0.67, 0.64, 0.61, 0.59, 0.57],\n            [1.15, 1.05, 0.96, 0.88, 0.81, 0.75, 0.71, 0.67, 0.64, 0.61, 0.59, 0.57],\n            [1.25, 1.13, 1.00, 0.90, 0.82, 0.76, 0.71, 0.67, 0.64, 0.61, 0.59, 0.56]\n        ]), 0.5, 0.0005, 2, 0.75, 2.0, 0),\n        # Case 3\n        (np.array([\n            [0.9, 0.85, 0.82, 0.79, 0.77, 0.76, 0.755, 0.753, 0.752, 0.753, 0.755, 0.758, 0.761, 0.765, 0.77, 0.772, 0.775, 0.778],\n            [0.92, 0.86, 0.83, 0.80, 0.78, 0.765, 0.76, 0.76, 0.761, 0.763, 0.766, 0.77, 0.775, 0.78, 0.785, 0.79, 0.795, 0.80],\n            [0.88, 0.84, 0.81, 0.78, 0.76, 0.75, 0.745, 0.743, 0.744, 0.748, 0.753, 0.759, 0.766, 0.775, 0.785, 0.795, 0.805, 0.815]\n        ]), 0.7, 0.0015, 3, 2/3, 1.3, 3),\n        # Case 4\n        (np.array([\n            [1.0, 0.93, 0.87, 0.83, 0.80, 0.79, 0.785, 0.784, 0.784, 0.785, 0.786, 0.787, 0.788, 0.789],\n            [0.99, 0.92, 0.86, 0.82, 0.79, 0.78, 0.775, 0.773, 0.772, 0.772, 0.773, 0.774, 0.776, 0.778],\n            [1.02, 0.94, 0.88, 0.84, 0.81, 0.80, 0.796, 0.795, 0.795, 0.796, 0.797, 0.798, 0.799, 0.80],\n            [1.01, 0.93, 0.87, 0.83, 0.80, 0.79, 0.785, 0.783, 0.782, 0.782, 0.783, 0.784, 0.786, 0.788],\n            [1.03, 0.95, 0.89, 0.85, 0.82, 0.81, 0.805, 0.804, 0.804, 0.805, 0.806, 0.808, 0.81, 0.812]\n        ]), 0.6, 0.001, 2, 0.8, 1.4, 2),\n        # Case 5\n        (np.array([\n            [0.8, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.771, 0.772, 0.773],\n            [0.82, 0.79, 0.78, 0.78, 0.78, 0.78, 0.781, 0.782, 0.783, 0.784],\n            [0.81, 0.79, 0.78, 0.78, 0.78, 0.781, 0.782, 0.783, 0.784, 0.785],\n            [0.83, 0.80, 0.79, 0.79, 0.79, 0.79, 0.791, 0.792, 0.793, 0.794]\n        ]), 0.5, 0.0008, 2, 0.75, 1.2, 5),\n    ]\n\n    results = []\n    for case in test_cases:\n        losses, alpha, eps, p, q, r, w = case\n        result = find_stopping_epoch(losses, alpha, eps, p, q, r, w)\n        results.append(result)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3139126"}]}