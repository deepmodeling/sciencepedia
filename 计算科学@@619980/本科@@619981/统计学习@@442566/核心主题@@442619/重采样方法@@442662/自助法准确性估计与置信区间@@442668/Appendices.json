{"hands_on_practices": [{"introduction": "评估分类器性能时，我们得到的不仅仅是一个单一的准确率数值。此练习将指导您使用自助法（bootstrap）来量化混淆矩阵中各项指标（$TP, FP, TN, FN$）的不确定性，并由此构建模型准确率的置信区间。这是一个核心实践，能帮助您更全面地报告和理解模型的稳定性。[@problem_id:3106305]", "problem": "给定一个二元分类场景，您将获得一个数据集的观测混淆矩阵条目。混淆矩阵条目定义如下：$TP$ 是真阳性 (true positives) 的数量，$FP$ 是假阳性 (false positives) 的数量，$TN$ 是真阴性 (true negatives) 的数量，$FN$ 是假阴性 (false negatives) 的数量。准确率定义为 $A = (TP + TN)/n$，其中 $n = TP + FP + TN + FN$ 是总观测数。您将使用非参数自助法 (nonparametric bootstrap) 来量化混淆矩阵条目向量 $(TP, FP, TN, FN)$ 的不确定性，并将此不确定性传播到准确率的置信区间。您还将评估混淆矩阵条目之间的协方差效应。\n\n基本原理：\n- 非参数自助法通过从经验分布中进行有放回重抽样来近似抽样分布。\n- 四个分类结果 $(TP, FP, TN, FN)$ 的经验分布为每个类别 $k \\in \\{TP, FP, TN, FN\\}$ 分配概率质量 $\\hat{p}_k = c_k / n$，其中 $c_k$ 是观测到的计数。从经验分布中抽取的样本量为 $n$ 的自助样本会产生一个服从多项式分布的计数向量，其参数为 $n$ 和概率 $(\\hat{p}_{TP}, \\hat{p}_{FP}, \\hat{p}_{TN}, \\hat{p}_{FN})$。\n- 置信区间 (CI) 可以通过百分位数法形成：对于一个统计量 $T$，在选定的水平 $1-\\alpha$ 下，其下端点和上端点分别是 $T$ 的自助复制样本在 $\\alpha/2$ 和 $1-\\alpha/2$ 处的经验分位数。\n- 对于随机向量 $X$ 的平滑函数 $g$，delta 方法给出了一个近似式 $\\mathrm{Var}(g(X)) \\approx \\nabla g(\\mu)^\\top \\Sigma \\nabla g(\\mu)$，其中 $\\mu = \\mathbb{E}[X]$，$\\Sigma = \\mathrm{Cov}(X)$，$\\nabla g$ 是梯度。当 $\\Sigma$ 通过向量 $(TP, FP, TN, FN)$ 的自助协方差来估计时，由此可得出 $A$ 的正态近似置信区间。\n\n您的程序必须为每个测试用例实现以下步骤：\n1. 使用观测到的混淆矩阵计数 $(TP, FP, TN, FN)$ 和总数 $n$ 来定义经验概率 $\\hat{p}_{TP} = TP/n$，$\\hat{p}_{FP} = FP/n$，$\\hat{p}_{TN} = TN/n$，$\\hat{p}_{FN} = FN/n$。\n2. 通过从大小为 $n$、类别概率为 $(\\hat{p}_{TP}, \\hat{p}_{FP}, \\hat{p}_{TN}, \\hat{p}_{FN})$ 的多项式分布中抽样，生成 $B$ 个计数向量的自助复制样本。使用固定的随机种子以确保可复现性。\n3. 对于每个自助复制样本 $b$，计算其准确率 $A^{(b)} = (TP^{(b)} + TN^{(b)})/n$。\n4. 通过取 $\\{A^{(b)}\\}$ 在 $q_{\\mathrm{low}} = \\alpha/2$ 和 $q_{\\mathrm{high}} = 1-\\alpha/2$ 处的经验分位数，构建准确率在水平 $1-\\alpha$ 下的百分位数置信区间。\n5. 估计自助复制向量 $(TP, FP, TN, FN)$ 的协方差矩阵 $\\hat{\\Sigma}$，并使用 delta 方法构建准确率在水平 $1-\\alpha$ 下的正态近似置信区间。具体来说，使用在观测计数值处准确率作为 $(TP, FP, TN, FN)$ 函数的线性化来获得标准误，然后构建对称正态置信区间。不要将区间裁剪到 $[0,1]$ 内；以小数形式报告原始端点。\n6. 通过计算自助复制样本中 $(TP, TN)$ 之间以及 $(TP, FP)$ 之间的自助相关性来评估协方差效应。如果一对中的任一分量其自助方差为零，则将其相关性定义为 $0$。\n\n测试套件：\n- 用例 1（均衡，中等准确率）：$n = 200$，$(TP, FP, TN, FN) = (70, 20, 90, 20)$。\n- 用例 2（不均衡，稀有正例）：$n = 300$，$(TP, FP, TN, FN) = (5, 25, 260, 10)$。\n- 用例 3（小样本，退化预测器）：$n = 40$，$(TP, FP, TN, FN) = (0, 0, 28, 12)$。\n\n所有用例的通用设置：\n- 置信水平：$1-\\alpha = 0.95$（因此 $\\alpha = 0.05$）。\n- 自助复制次数：$B = 40000$。\n- 随机种子：$R = 1729$。\n- 所有与准确率相关的量都必须以小数形式报告，而不是百分比。\n\n每个测试用例所需的输出：\n- 一个包含 7 个浮点数的列表，顺序如下：\n  - 准确率点估计 $A$。\n  - $A$ 的百分位数置信区间下端点。\n  - $A$ 的百分位数置信区间上端点。\n  - $A$ 的 delta 方法置信区间下端点。\n  - $A$ 的 delta 方法置信区间上端点。\n  - 从自助复制样本中估计的 $(TP, TN)$ 之间的相关性。\n  - 从自助复制样本中估计的 $(TP, FP)$ 之间的相关性。\n- 如果由于任一分量的方差为零导致相关性未定义，则该相关性返回 $0$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个逗号分隔的列表，列表内是各测试用例的结果，并用方括号括起来。每个测试用例的结果本身也是一个用方括号括起来的、按上述顺序排列的逗号分隔列表。所有浮点数必须四舍五入到 $6$ 位小数。例如，包含两个用例的输出应如下所示：$[[0.800000,0.750000,0.840000,0.760000,0.840000,-0.300000,-0.200000],[\\dots]]$。", "solution": "用户先验地声明问题陈述是有效的。我的分析证实了这一点：该问题具有科学依据、问题定义明确、客观，并且没有其他使其无效的缺陷。它完全属于计算统计学和统计学习的领域，并且为获得唯一的、可验证的解提供了所有必要的参数和定义。\n\n目标是使用非参数自助法分析二元分类器准确率的不确定性，基于其混淆矩阵计数 $(TP, FP, TN, FN)$。我们将计算准确率的点估计，构建两种类型的置信区间（百分位数法和 delta 方法），并评估某些计数分量之间的相关性。总观测数为 $n = TP + FP + TN + FN$。\n\n准确率 $A$ 定义为正确预测的比例：\n$$A = \\frac{TP + TN}{n}$$\n这作为我们根据观测计数计算出的真实准确率的点估计。\n\n分析的核心是非参数自助法。该方法通过从观测数据中有放回地抽样来模拟抽样过程。对于由计数 $(c_{TP}, c_{FP}, c_{TN}, c_{FN})$ 总结的分类数据，这等同于从经验概率分布中抽样。每个类别 $k \\in \\{TP, FP, TN, FN\\}$ 的经验概率为 $\\hat{p}_k = c_k / n$。计数的自助样本是一个向量 $\\mathbf{c}^{(b)} = (TP^{(b)}, FP^{(b)}, TN^{(b)}, FN^{(b)})$，它从具有 $n$ 次试验和概率向量 $\\hat{\\mathbf{p}} = (\\hat{p}_{TP}, \\hat{p}_{FP}, \\hat{p}_{TN}, \\hat{p}_{FN})$ 的多项式分布中抽取。\n$$\\mathbf{c}^{(b)} \\sim \\mathrm{Multinomial}(n, \\hat{\\mathbf{p}})$$\n我们生成 $B = 40000$ 个这样的自助复制向量。\n\n对于每个计数的自助复制样本 $\\mathbf{c}^{(b)}$，我们计算其对应的准确率：\n$$A^{(b)} = \\frac{TP^{(b)} + TN^{(b)}}{n}$$\n这个过程产生了一个包含 $B$ 个自助准确率的分布 $\\{A^{(b)}\\}_{b=1}^B$，该分布近似于准确率估计 $A$ 的抽样分布。\n\n从这个自助分布中，我们使用百分位数法构建准确率的 $(1-\\alpha)$ 置信区间。对于 $1-\\alpha = 0.95$ 的置信水平（即 $\\alpha=0.05$），区间的下界和上界分别是自助准确率 $\\{A^{(b)}\\}$ 的 $q_{\\mathrm{low}} = \\alpha/2 = 0.025$ 和 $q_{\\mathrm{high}} = 1 - \\alpha/2 = 0.975$ 经验分位数。\n$$\\text{CI}_{\\text{percentile}} = [Q_{0.025}, Q_{0.975}]$$\n\n接下来，我们使用 delta 方法构建置信区间。该方法使用一阶泰勒展开来近似随机变量函数的方差。在这里，准确率是计数向量 $\\mathbf{c} = (TP, FP, TN, FN)$ 的函数：$A = g(\\mathbf{c}) = (TP + TN)/n$。该函数关于计数的梯度是一个常数向量：\n$$\\nabla g = \\left( \\frac{\\partial g}{\\partial TP}, \\frac{\\partial g}{\\partial FP}, \\frac{\\partial g}{\\partial TN}, \\frac{\\partial g}{\\partial FN} \\right)^\\top = \\left( \\frac{1}{n}, 0, \\frac{1}{n}, 0 \\right)^\\top$$\nDelta 方法将 $A$ 的方差近似为：\n$$\\widehat{\\mathrm{Var}}(A) \\approx (\\nabla g)^\\top \\hat{\\Sigma} (\\nabla g)$$\n其中 $\\hat{\\Sigma}$ 是自助计数向量 $\\{\\mathbf{c}^{(b)}\\}_{b=1}^B$ 的样本协方差矩阵。$A$ 的标准误为 $SE(A) = \\sqrt{\\widehat{\\mathrm{Var}}(A)}$。然后，围绕点估计 $A$ 对称地构建 $(1-\\alpha)$ 正态近似置信区间：\n$$\\text{CI}_{\\text{delta}} = [A - z_{1-\\alpha/2} \\cdot SE(A), A + z_{1-\\alpha/2} \\cdot SE(A)]$$\n其中 $z_{1-\\alpha/2}$ 是标准正态分布的 $(1-\\alpha/2)$-分位数。对于 $\\alpha=0.05$，$z_{0.975} \\approx 1.96$。\n\n最后，我们通过计算自助复制样本中计数分量之间的相关性来评估它们之间的关系。两个分量（例如 $TP$ 和 $TN$）之间的相关性 $X_i$ 和 $X_j$ 从自助协方差矩阵 $\\hat{\\Sigma}$ 中估计如下：\n$$\\hat{\\rho}_{ij} = \\frac{\\hat{\\Sigma}_{ij}}{\\sqrt{\\hat{\\Sigma}_{ii} \\hat{\\Sigma}_{jj}}}$$\n其中 $\\hat{\\Sigma}_{ii}$ 和 $\\hat{\\Sigma}_{jj}$ 是方差。如果任一分量的自助方差为 $0$（这在经验概率为 $0$ 时发生），则相关性定义为 $0$。\n\n实现过程将遍历每个测试用例，应用这些步骤，并使用固定的随机种子 $R=1729$ 以确保可复现性。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Computes bootstrap confidence intervals and correlations for classifier accuracy.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # ((TP, FP, TN, FN), n)\n        ((70, 20, 90, 20), 200),\n        ((5, 25, 260, 10), 300),\n        ((0, 0, 28, 12), 40),\n    ]\n\n    # Common settings for all cases\n    B = 40000\n    alpha = 0.05\n    R = 1729\n    rng = np.random.default_rng(R)\n\n    all_results_str = []\n    for case in test_cases:\n        counts, n = case\n        \n        # 1. Point estimate and empirical probabilities\n        tp, fp, tn, fn = counts\n        A = (tp + tn) / n\n        p_hat = np.array(counts) / n\n\n        # 2. Generate B bootstrap replicates of the count vector\n        # Each row is a draw from Multinomial(n, p_hat)\n        bootstrap_counts = rng.multinomial(n, p_hat, size=B)\n\n        # 3. Compute accuracy for each bootstrap replicate\n        bootstrap_accuracies = (bootstrap_counts[:, 0] + bootstrap_counts[:, 2]) / n\n\n        # 4. Construct percentile confidence interval\n        q_low = alpha / 2\n        q_high = 1 - alpha / 2\n        ci_percentile_low = np.quantile(bootstrap_accuracies, q_low)\n        ci_percentile_high = np.quantile(bootstrap_accuracies, q_high)\n\n        # 5. Construct delta-method confidence interval\n        # Estimate covariance matrix from bootstrap replicates\n        cov_mat = np.cov(bootstrap_counts, rowvar=False)\n        \n        # Gradient of accuracy function g(TP, FP, TN, FN) = (TP + TN)/n\n        grad_g = np.array([1/n, 0, 1/n, 0])\n        \n        # Delta method variance approximation\n        var_A_delta = grad_g.T @ cov_mat @ grad_g\n        # Use max(0, ...) for numerical stability, though var should be non-negative\n        se_A_delta = np.sqrt(max(0, var_A_delta))\n        \n        z_val = norm.ppf(q_high)\n        ci_delta_low = A - z_val * se_A_delta\n        ci_delta_high = A + z_val * se_A_delta\n\n        # 6. Assess covariance effects by computing correlations\n        var_tp = cov_mat[0, 0]\n        var_fp = cov_mat[1, 1]\n        var_tn = cov_mat[2, 2]\n\n        # Correlation between TP and TN\n        if var_tp == 0 or var_tn == 0:\n            corr_tp_tn = 0.0\n        else:\n            cov_tp_tn = cov_mat[0, 2]\n            corr_tp_tn = cov_tp_tn / np.sqrt(var_tp * var_tn)\n\n        # Correlation between TP and FP\n        if var_tp == 0 or var_fp == 0:\n            corr_tp_fp = 0.0\n        else:\n            cov_tp_fp = cov_mat[0, 1]\n            corr_tp_fp = cov_tp_fp / np.sqrt(var_tp * var_fp)\n\n        # Collate and format results for the current case\n        case_results = [A, ci_percentile_low, ci_percentile_high, ci_delta_low, ci_delta_high, corr_tp_tn, corr_tp_fp]\n        formatted_case_results = [f\"{x:.6f}\" for x in case_results]\n        all_results_str.append(f\"[{','.join(formatted_case_results)}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(all_results_str)}]\")\n\nsolve()\n```", "id": "3106305"}, {"introduction": "模型在训练集和测试集上的表现差异——即泛化差距（generalization gap）——是衡量过拟合程度的关键指标。本练习将引导您设计一个自助法实验，通过对训练和测试损失进行独立重采样，来估计泛化差距的置信区间。通过这个实践，您将学会如何评估模型泛化能力的稳定性，而不仅仅是依赖一个单一的差距值。[@problem_id:3106350]", "problem": "给定独立训练样本和测试样本在 0-1 损失下的逐例二元损失，要求您使用 bootstrap 方法估计泛化差距的置信区间。样本的经验损失定义为其逐例损失的算术平均值。泛化差距定义为经验训练损失与经验测试损失之差。您必须设计并实现一个程序，对于每个给定的案例，使用非参数 bootstrap 方法来近似泛化差距的抽样分布，然后通过百分位数法构建一个双边置信区间。\n\n从以下基本概念开始：\n- 对于一个样本，其逐例损失为 $l_1,\\dots,l_n \\in \\{0,1\\}$，经验损失为 $\\hat{L} = \\frac{1}{n}\\sum_{i=1}^n l_i$。\n- 泛化差距为 $G = \\hat{L}_{\\text{train}} - \\hat{L}_{\\text{test}}$。\n- 非参数 bootstrap 方法通过从观测数据中有放回地重抽样，并在每个重抽样样本上重新计算统计量，来近似该统计量的抽样分布。\n- 对于一个标量参数 $\\theta$，其水平为 $1-\\alpha$ 的双边百分位置信区间使用估计 $\\theta$ 的统计量的 bootstrap 分布的 $\\alpha/2$ 和 $1-\\alpha/2$ 分位数。\n\n算法任务：\n- 对于每个测试案例，分别在训练集和测试集内部进行有放回的重抽样。对于每一次 bootstrap 复制，计算重抽样数据上的经验训练损失和经验测试损失，然后计算相应的 bootstrap 复制值 $G^\\ast$。重复此过程 $B$ 次，得到 bootstrap 样本 $\\{G^\\ast_b\\}_{b=1}^B$。\n- 设 $\\hat{G}$ 为从原始数据计算出的点估计值，即原始经验训练损失与测试损失之差。通过取 bootstrap 样本 $\\{G^\\ast_b\\}_{b=1}^B$ 在概率 $\\alpha/2$ 和 $1-\\alpha/2$ 处的经验分位数，构建 $G$ 在水平为 $1-\\alpha$ 时的双边百分位置信区间。\n\n您的程序必须为以下测试套件实现此过程。在每个案例中，逐例损失明确以 $0$ 和 $1$ 的序列给出，bootstrap 复制次数为 $B$，名义水平为 $1-\\alpha$。bootstrap 的随机数生成必须使用指定的种子以确保确定性输出。\n\n测试套件：\n- 案例 A：\n  - 训练损失：$[0,0,1,0,0,0,1,0,0,1,0,0,0,0,1,0,0,0,0,1,0,1,0,0]$。\n  - 测试损失：$[0,1,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0]$。\n  - Bootstrap 复制次数：$B=5000$。\n  - 置信水平：$1-\\alpha=0.95$（因此 $\\alpha=0.05$）。\n  - 随机种子：$12345$。\n- 案例 B：\n  - 训练损失：$[1,0,0,1,0,0]$。\n  - 测试损失：$[0,1,0,0,0,0,1]$。\n  - Bootstrap 复制次数：$B=4000$。\n  - 置信水平：$1-\\alpha=0.90$（因此 $\\alpha=0.10$）。\n  - 随机种子：$2023$。\n- 案例 C：\n  - 训练损失：$[0,0,0,0,0,0,0,0,0,0,0,0]$。\n  - 测试损失：$[0,0,1,0,0,0,0,1,0,0,0,1]$。\n  - Bootstrap 复制次数：$B=8000$。\n  - 置信水平：$1-\\alpha=0.95$（因此 $\\alpha=0.05$）。\n  - 随机种子：$777$。\n\n要求：\n- 对于每个案例，计算来自原始数据的点估计值 $\\hat{G}$ 以及来自 $G^\\ast$ 的 bootstrap 分布的相应双边百分位置信区间 $\\left[q_{\\alpha/2}, q_{1-\\alpha/2}\\right]$。\n- 所有输出均表示为小数点后保留六位数字的实数。\n- 最终输出格式：您的程序应生成一行输出，其中包含所有案例的结果，格式为一个由方括号括起来的逗号分隔列表。每个案例本身必须是一个三元素列表，顺序为 $[\\hat{G}, \\text{lower}, \\text{upper}]$。例如，三个案例的输出必须类似于 $[[g_1,\\ell_1,u_1],[g_2,\\ell_2,u_2],[g_3,\\ell_3,u_3]]$，其中每个 $g_i,\\ell_i,u_i$ 都打印到小数点后六位。\n- 不允许用户输入；所有数据均已在上方指定，并且必须嵌入到程序中。此问题不涉及物理单位，所有概率或水平必须表示为小数而非百分号。", "solution": "该问题是有效的，因为它在计算统计学领域提出了一个定义明确、有科学依据的任务。所有必要的数据和参数都已提供，且所用方法是标准的、客观的。\n\n目标是估计泛化差距 $G$ 的置信区间，该差距是经验训练损失与经验测试损失之差。逐例损失是二元的，$l_i \\in \\{0, 1\\}$，代表 0-1 损失。给定一组逐例损失 $\\{l_i\\}_{i=1}^n$，经验损失定义为其算术平均值，$\\hat{L} = \\frac{1}{n}\\sum_{i=1}^n l_i$。\n\n设观测到的训练损失集合为 $S_{\\text{train}} = \\{l_{\\text{train},i}\\}_{i=1}^{n_{\\text{train}}}$，观测到的测试损失集合为 $S_{\\text{test}} = \\{l_{\\text{test},j}\\}_{j=1}^{n_{\\text{test}}}$，其中 $n_{\\text{train}}$ 和 $n_{\\text{test}}$ 分别是各自的样本大小。\n\n经验训练损失为 $\\hat{L}_{\\text{train}} = \\frac{1}{n_{\\text{train}}}\\sum_{i=1}^{n_{\\text{train}}} l_{\\text{train},i}$，经验测试损失为 $\\hat{L}_{\\text{test}} = \\frac{1}{n_{\\text{test}}}\\sum_{j=1}^{n_{\\text{test}}} l_{\\text{test},j}$。泛化差距统计量 $G$ 是它们的差值：\n$$G = \\hat{L}_{\\text{train}} - \\hat{L}_{\\text{test}}$$\n对于给定的数据集，点估计值（记为 $\\hat{G}$）是直接从原始训练和测试样本计算得出的。\n\n为了构建 $G$ 的置信区间，我们采用非参数 bootstrap 方法。该方法通过从观测数据中重复重抽样来近似统计量 $G$ 的抽样分布。其基本原理是，从经验分布（即观测样本）中进行重抽样，可以模拟从真实的基础分布中进行抽样的过程。\n\n算法流程如下：\n\n1.  **点估计**：使用原始的完整样本 $S_{\\text{train}}$ 和 $S_{\\text{test}}$ 计算点估计值 $\\hat{G} = \\hat{L}_{\\text{train}} - \\hat{L}_{\\text{test}}$。\n\n2.  **Bootstrap 重抽样**：对于从 $1$到 $B$ 的每一次 bootstrap 复制 $b$：\n    a.  通过从 $S_{\\texttrain}$ 中有放回地抽取 $n_{\\text{train}}$ 个观测值，生成一个 bootstrap 训练样本 $S_{\\text{train}}^{\\ast, b}$。\n    b.  通过从 $S_{\\text{test}}$ 中有放回地抽取 $n_{\\text{test}}$ 个观测值，生成一个 bootstrap 测试样本 $S_{\\text{test}}^{\\ast, b}$。训练和测试的重抽样过程是独立的。\n\n3.  **Bootstrap 统计量计算**：对于每次复制 $b$，计算泛化差距的 bootstrap 版本 $G_b^\\ast$：\n    a.  计算 bootstrap 训练样本的经验损失：$\\hat{L}_{\\text{train}}^{\\ast, b} = \\frac{1}{n_{\\text{train}}}\\sum_{l \\in S_{\\text{train}}^{\\ast, b}} l_i$。\n    b.  计算 bootstrap 测试样本的经验损失：$\\hat{L}_{\\text{test}}^{\\ast, b} = \\frac{1}{n_{\\text{test}}}\\sum_{l \\in S_{\\text{test}}^{\\ast, b}} l_j$。\n    c.  计算统计量的 bootstrap 复制值：$G_b^\\ast = \\hat{L}_{\\text{train}}^{\\ast, b} - \\hat{L}_{\\text{test}}^{\\ast, b}$。\n\n4.  **置信区间构建**：$B$ 个 bootstrap 统计量的集合 $\\{G_b^\\ast\\}_{b=1}^B$ 构成了 $G$ 的抽样分布的经验近似。百分位数法使用这个经验分布的分位数来构建置信区间。对于名义置信水平 $1-\\alpha$，双边百分位置信区间由下式给出：\n    $$[q_{\\alpha/2}, q_{1-\\alpha/2}]$$\n    其中 $q_p$ 表示 bootstrap 分布 $\\{G_b^\\ast\\}_{b=1}^B$ 的第 $p$ 个分位数。例如，置信水平为 $0.95$ 时，我们有 $\\alpha=0.05$。该区间由 bootstrap 复制值的第 $2.5$ 百分位数作为下界，第 $97.5$ 百分位数作为上界构成。\n\n该过程应用于所提供的三个测试案例中的每一个，使用带种子的随机数生成器以确保结果的确定性和可复现性。点估计值 $\\hat{G}$ 以及置信区间的下界和上界将被计算并报告至小数点后六位。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes a point estimate and a bootstrap percentile confidence interval\n    for the generalization gap for several test cases.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"train_losses\": [0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0],\n            \"test_losses\": [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n            \"B\": 5000,\n            \"alpha\": 0.05,\n            \"seed\": 12345\n        },\n        {\n            \"train_losses\": [1, 0, 0, 1, 0, 0],\n            \"test_losses\": [0, 1, 0, 0, 0, 0, 1],\n            \"B\": 4000,\n            \"alpha\": 0.10,\n            \"seed\": 2023\n        },\n        {\n            \"train_losses\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n            \"test_losses\": [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n            \"B\": 8000,\n            \"alpha\": 0.05,\n            \"seed\": 777\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        train_losses = np.array(case[\"train_losses\"])\n        test_losses = np.array(case[\"test_losses\"])\n        B = case[\"B\"]\n        alpha = case[\"alpha\"]\n        seed = case[\"seed\"]\n\n        n_train = len(train_losses)\n        n_test = len(test_losses)\n\n        # Step 1: Calculate the point estimate of the generalization gap\n        L_hat_train = np.mean(train_losses)\n        L_hat_test = np.mean(test_losses)\n        G_hat = L_hat_train - L_hat_test\n\n        # Initialize random number generator for reproducibility\n        np.random.seed(seed)\n\n        # Steps 2  3: Perform bootstrap resampling and compute the statistic\n        bootstrap_gaps = []\n        for _ in range(B):\n            # Resample with replacement from training and test sets\n            train_resample = np.random.choice(train_losses, size=n_train, replace=True)\n            test_resample = np.random.choice(test_losses, size=n_test, replace=True)\n\n            # Compute empirical losses for the bootstrap samples\n            L_star_train = np.mean(train_resample)\n            L_star_test = np.mean(test_resample)\n\n            # Compute and store the bootstrap replicate of the generalization gap\n            G_star = L_star_train - L_star_test\n            bootstrap_gaps.append(G_star)\n        \n        bootstrap_gaps = np.array(bootstrap_gaps)\n\n        # Step 4: Construct the percentile confidence interval\n        lower_percentile = (alpha / 2.0) * 100\n        upper_percentile = (1 - alpha / 2.0) * 100\n        \n        ci_lower, ci_upper = np.percentile(bootstrap_gaps, [lower_percentile, upper_percentile])\n\n        results.append([G_hat, ci_lower, ci_upper])\n\n    # Format and print the final output\n    formatted_results = [f\"[{gh:.6f},{l:.6f},{u:.6f}]\" for gh, l, u in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3106350"}, {"introduction": "标准的自助法假设数据点是独立同分布的，但在处理图像或时间序列等具有空间或时间相关性的数据时，这一假设不再成立。本练习通过一个模拟实验，让您亲手比较朴素的像素级自助法和更先进的块状自助法（block bootstrap）在处理空间相关数据时的表现。您将通过计算覆盖率，直观地理解为何必须考虑数据依赖性，以及如何选择正确的自助法策略来获得可靠的置信区间。[@problem_id:3106269]", "problem": "考虑一个在 $N \\times N$ 像素大小的单张合成图像上的二元像素分类任务，其中相邻像素的分类正确性表现出空间相关性。令 $X_{ij} \\in \\{0,1\\}$ 表示在像素 $(i,j)$ 处分类正确的指示变量，并定义整张图像的经验准确率为\n$$\n\\hat{A} \\;=\\; \\frac{1}{N^2} \\sum_{i=1}^{N} \\sum_{j=1}^{N} X_{ij}.\n$$\n假设空间相关的正确性遵循以下生成机制：\n- 为所有像素独立地抽取一个白噪声场 $W_{ij} \\sim \\mathcal{N}(0,1)$。\n- 将 $W$ 与一个标准差为 $s$ 的归一化各向同性高斯核进行卷积平滑，以获得一个相关场 $Z_{ij}$。\n- 设定一个基准 logit 值 $\\alpha = \\log\\left(\\frac{p}{1-p}\\right)$，其中 $p$ 是一个不相关模型的目标基线正确率概率。\n- 通过逻辑斯谛映射 $\\pi_{ij} = \\frac{1}{1 + e^{-(\\alpha + Z_{ij})}}$ 定义逐像素的正确率概率，然后在给定该场的条件下，对每个像素独立地抽取 $X_{ij} \\sim \\mathrm{Bernoulli}(\\pi_{ij})$。\n\n为了使用自助法对 $\\hat{A}$ 进行推断，考虑应用于单张观测图像的两种重采样方案：\n- 一种在像素级别上的独立同分布 (iid) 自助法重采样，其中重采样样本是通过从 $N^2$ 个观测像素中有放回地抽取 $N^2$ 个像素，并计算重采样后指示变量的均值来形成的。\n- 一种基于图像块的区块自助法重采样，它通过从图像中所有可能的重叠 $b \\times b$ 图像块中有放回地抽取边长为 $b$ 的方形图像块（区块）来保留空间依赖性；拼接足够数量的图像块以达到至少 $N^2$ 个像素，并计算拼接后图像块的前 $N^2$ 个像素的均值。\n\n对每种重采样方案，通过取重采样均值的自助法分布的 $0.025$ 和 $0.975$ 水平上的经验下分位数和上分位数，来构建 $\\hat{A}$ 的双侧自助法置信区间 (CI)。对于给定的方案和单次图像实现，将覆盖定义为置信区间包含在完整图像像素上计算出的真实经验准确率 $\\hat{A}$ 这一事件。在图像的重复独立实现（即重新抽取 $W$ 和 $X$）中，将覆盖率定义为置信区间包含相应 $\\hat{A}$ 的实现所占的比例。该覆盖率必须表示为 $[0,1]$ 内的一个小数。\n\n从自助法重采样、置信区间和经验准确率的核心定义出发，实现一个程序，该程序：\n1. 根据上述机制生成 $R$ 个独立的图像实现。\n2. 对每次实现，使用 $B$ 个自助法重采样样本为每种方案计算 $\\hat{A}$ 和两个自助法置信区间（iid 像素级和基于图像块的区块自助法）。\n3. 记录每个置信区间是否覆盖 $\\hat{A}$，并对两种方案在 $R$ 次实现中汇总覆盖率。\n\n使用固定的伪随机种子 $2025$ 以保证可复现性。使用一个高斯卷积核，其标准差为 $s$，方形支撑域边长为 $L = 2\\lceil 3s \\rceil + 1$ 像素，并进行归一化使其总和为 1。基线正确率参数 $p$ 仅通过 $\\alpha$ 出现；所有其他符号均已在上文定义。\n\n测试套件。对以下四组参数集运行该程序，其中 $N$ 是图像边长，$p$ 是基线正确率概率，$s$ 控制空间相关性（作为高斯核的标准差），$b$ 是区块自助法的图像块边长，$R$ 是实现次数，$B$ 是每种方案的自助法重采样次数：\n- 情况 1：$(N,p,s,b,R,B) = (\\,32,\\,0.80,\\,1.0,\\,1,\\,200,\\,400\\,)$。\n- 情况 2：$(N,p,s,b,R,B) = (\\,32,\\,0.80,\\,2.0,\\,4,\\,200,\\,400\\,)$。\n- 情况 3：$(N,p,s,b,R,B) = (\\,32,\\,0.80,\\,2.0,\\,8,\\,200,\\,400\\,)$。\n- 情况 4：$(N,p,s,b,R,B) = (\\,32,\\,0.80,\\,4.0,\\,4,\\,200,\\,400\\,)$。\n\n您的程序必须生成单行输出，包含所有四种情况下 iid 和区块自助法方案的覆盖率。要求的格式是一个由方括号括起来的、包含两个浮点数的列表的逗号分隔列表。具体而言，输出必须采用以下形式：\n$$\n[\\,[c^{\\mathrm{iid}}_1, c^{\\mathrm{block}}_1], [c^{\\mathrm{iid}}_2, c^{\\mathrm{block}}_2], [c^{\\mathrm{iid}}_3, c^{\\mathrm{block}}_3], [c^{\\mathrm{iid}}_4, c^{\\mathrm{block}}_4]\\,]\n$$\n其中 $c^{\\mathrm{iid}}_k$ 和 $c^{\\mathrm{block}}_k$ 分别是情况 $k$ 的覆盖率，每个都以 $[0,1]$ 内的小数形式报告。", "solution": "用户希望评估两种基于自助法的置信区间方案，在处理空间相关的合成图像上的逐像素分类器平均准确率时的覆盖率。该问题是良构的，并基于标准的统计模拟方法论。我们将通过实现指定的数据生成过程和两种重采样方案（IID 和区块自助法），并将它们包装在蒙特卡洛模拟中来估计覆盖概率。\n\n### 算法分解\n\n问题的核心是进行一项模拟研究。对于四个指定的参数集中的每一个，我们必须执行以下步骤：\n\n1.  **初始化**：为了可复现性，使用指定的种子 $2025$ 设置一个主伪随机数生成器 (RNG)。将 IID 和区块自助法方案的覆盖计数器初始化为零。\n\n2.  **蒙特卡洛循环**：重复 $R$ 次（对于 $R$ 次独立实现）：\n    a. **数据生成**：根据指定的空间相关模型，生成一个表示分类正确性的 $N \\times N$ 二值图像 $X$。\n        i.  生成一个 $N \\times N$ 的标准正态白噪声场 $W_{ij}$。\n        ii. 创建一个二维高斯卷积核，其标准差为 $s$，支撑域边长为 $L = 2\\lceil 3s \\rceil + 1$。该核必须归一化以使其总和为 1。\n        iii. 将噪声场 $W$ 与高斯核进行卷积，以生成一个空间相关的高斯场 $Z$。我们将使用周期性边界条件（`wrap`）来避免边界效应。\n        iv. 将基线正确率概率 $p$ 转换为 logit 尺度的参数 $\\alpha = \\log(p/(1-p))$。\n        v.  使用逻辑斯谛函数将相关场 $Z$ 转换为逐像素的正确率概率 $\\pi_{ij}$：$\\pi_{ij} = (1 + e^{-(\\alpha + Z_{ij})})^{-1}$。\n        vi. 生成最终的二值图像 $X$，其中每个像素 $X_{ij}$ 是一个成功概率为 $\\pi_{ij}$ 的独立伯努利试验。\n\n    b. **真实准确率**：为生成的图像 $X$ 计算经验准确率 $\\hat{A}$，它就是所有像素值的均值：$\\hat{A} = \\frac{1}{N^2} \\sum_{i,j} X_{ij}$。该值作为置信区间旨在捕获的“真实”参数。\n\n    c. **IID 自助法置信区间**：\n        i.  通过从图像 $X$ 的 $N^2$ 个像素中有放回地抽取 $N^2$ 个像素，生成 $B$ 个自助法样本。\n        ii. 对每个自助法样本计算其均值。这将产生一个包含 $B$ 个自助法均值的分布。\n        iii. 通过找到该分布的第 $2.5$ 和第 $97.5$ 百分位数来构建一个 $95\\%$ 的置信区间。\n\n    d. **区块自助法置信区间**：\n        i.  生成 $B$ 个区块自助法样本。每个样本的构建方法如下：\n            - 识别图像 $X$ 中所有重叠的 $b \\times b$ 区块。\n            - 计算要抽取的区块数量，$M = \\lceil N^2 / b^2 \\rceil$。\n            - 有放回地抽取 $M$ 个区块。\n            - 拼接抽出的区块并取前 $N^2$ 个像素。\n        ii. 对 $B$ 个得到的长度为 $N^2$ 的像素序列中的每一个，计算其均值。这将产生一个包含 $B$ 个区块自助法均值的分布。\n        iii. 使用该分布的第 $2.5$ 和第 $97.5$ 百分位数构建一个 $95\\%$ 的置信区间。\n\n    e. **覆盖检查**：\n        i.  检查 IID 自助法置信区间是否包含 $\\hat{A}$。如果包含，则将 IID 覆盖计数器加一。\n        ii. 检查区块自助法置信区间是否包含 $\\hat{A}$。如果包含，则将区块自助法覆盖计数器加一。\n\n3.  **计算覆盖率**：在 $R$ 次重复之后，通过将其覆盖计数器除以 $R$ 来计算每种方案的覆盖率。\n\n4.  **对所有情况重复**：对所提供的四个参数集中的每一个执行整个过程。\n\n### 实现细节\n\n-   **RNG**：将使用种子创建一个 `numpy.random.default_rng` 的单一实例，并将其传递给所有需要随机数生成的函数，以确保完全的可复现性。\n-   **向量化**：为确保计算效率，自助法过程将被向量化。我们将一次性为所有 $B$ 个自助法样本生成随机索引，而不是循环 $B$ 次，并使用 NumPy 的高级索引和广播功能来同时计算所有 $B$ 个自助法均值。\n-   **步幅技巧**：区块自助法中提取重叠区块的过程可能成为一个瓶颈，我们将使用 `numpy.lib.stride_tricks.as_strided` 高效地实现它。这将创建原始图像数据的内存高效视图，避免了在内存中显式存储所有区块的需要。\n-   **特殊情况**：对于区块自助法，如果区块边长 $b=1$，该过程在数学上等同于 IID 自助法。我们的实现将通过委托给 IID 自助法函数来处理这种情况。\n\n这种结构化的方法确保以科学严谨和计算高效的方式满足问题的所有要求。最终输出将严格按照指定格式进行格式化。", "answer": "```python\nimport numpy as np\nfrom scipy.signal import convolve2d\nfrom scipy.special import logit, expit\n\ndef solve():\n    \"\"\"\n    Solves the bootstrap coverage rate problem for all test cases.\n    \"\"\"\n\n    def generate_gaussian_kernel(s: float) -> np.ndarray:\n        \"\"\"\n        Generates a 2D Gaussian kernel normalized to sum to 1.\n        \n        Args:\n            s (float): Standard deviation of the Gaussian.\n        \n        Returns:\n            np.ndarray: The normalized 2D kernel.\n        \"\"\"\n        L = 2 * int(np.ceil(3 * s)) + 1\n        center = L // 2\n        coords = np.arange(L) - center\n        x, y = np.meshgrid(coords, coords)\n        kernel = np.exp(-(x**2 + y**2) / (2 * s**2))\n        return kernel / np.sum(kernel)\n\n    def generate_spatially_correlated_data(N: int, p: float, s: float, rng: np.random.Generator) -> np.ndarray:\n        \"\"\"\n        Generates a single realization of the spatially correlated binary image.\n        \n        Args:\n            N (int): Side length of the square image.\n            p (float): Baseline correctness probability.\n            s (float): Standard deviation for the Gaussian correlation kernel.\n            rng (np.random.Generator): The random number generator instance.\n        \n        Returns:\n            np.ndarray: The N x N binary image X.\n        \"\"\"\n        # Generate white noise field\n        W = rng.normal(size=(N, N))\n        \n        # Create and apply Gaussian kernel for spatial correlation\n        kernel = generate_gaussian_kernel(s)\n        Z = convolve2d(W, kernel, mode='same', boundary='wrap')\n        \n        # Define pixel-wise correctness probabilities\n        alpha = logit(p)\n        pi = expit(alpha + Z)\n        \n        # Draw binary outcomes\n        X = rng.binomial(1, pi)\n        return X\n\n    def iid_bootstrap(X: np.ndarray, B: int, rng: np.random.Generator) -> np.ndarray:\n        \"\"\"\n        Computes the IID bootstrap confidence interval for the mean of X.\n        \n        Args:\n            X (np.ndarray): The N x N data image.\n            B (int): The number of bootstrap resamples.\n            rng (np.random.Generator): The random number generator instance.\n        \n        Returns:\n            np.ndarray: A 2-element array [lower_bound, upper_bound].\n        \"\"\"\n        N = X.shape[0]\n        N_sq = N * N\n        X_flat = X.flatten()\n        \n        # Vectorized generation of B bootstrap samples\n        resample_indices = rng.choice(N_sq, size=(B, N_sq), replace=True)\n        bootstrap_samples = X_flat[resample_indices]\n        \n        # Compute means for all B samples\n        bootstrap_means = np.mean(bootstrap_samples, axis=1)\n        \n        # Calculate quantiles for the confidence interval\n        return np.quantile(bootstrap_means, [0.025, 0.975])\n\n    def block_bootstrap(X: np.ndarray, b: int, B: int, rng: np.random.Generator) -> np.ndarray:\n        \"\"\"\n        Computes the block bootstrap confidence interval for the mean of X.\n        \n        Args:\n            X (np.ndarray): The N x N data image.\n            b (int): The side length of the square blocks.\n            B (int): The number of bootstrap resamples.\n            rng (np.random.Generator): The random number generator instance.\n        \n        Returns:\n            np.ndarray: A 2-element array [lower_bound, upper_bound].\n        \"\"\"\n        N = X.shape[0]\n\n        if b == 1:\n            return iid_bootstrap(X, B, rng)\n            \n        N_sq = N * N\n\n        # Use stride tricks to get an efficient view of all overlapping blocks\n        n_blocks_dim = N - b + 1\n        block_view = np.lib.stride_tricks.as_strided(\n            X,\n            shape=(n_blocks_dim, n_blocks_dim, b, b),\n            strides=(X.strides[0], X.strides[1], X.strides[0], X.strides[1])\n        )\n        all_blocks = block_view.reshape(-1, b * b)\n        num_total_blocks = all_blocks.shape[0]\n\n        # Number of blocks to sample to get at least N^2 pixels\n        num_blocks_to_sample = int(np.ceil(N_sq / (b * b)))\n        \n        # Vectorized sampling of block indices for all B resamples\n        block_indices = rng.choice(num_total_blocks, size=(B, num_blocks_to_sample), replace=True)\n        \n        # Form B bootstrap samples by concatenating blocks\n        resampled_blocks = all_blocks[block_indices]\n        resampled_pixels = resampled_blocks.reshape(B, -1)[:, :N_sq]\n        \n        # Compute means for all B samples\n        bootstrap_means = np.mean(resampled_pixels, axis=1)\n        \n        # Calculate quantiles for the confidence interval\n        return np.quantile(bootstrap_means, [0.025, 0.975])\n\n    # --- Main Execution ---\n    \n    # Fixed seed for reproducibility\n    rng = np.random.default_rng(2025)\n    \n    test_cases = [\n        (32, 0.80, 1.0, 1, 200, 400),\n        (32, 0.80, 2.0, 4, 200, 400),\n        (32, 0.80, 2.0, 8, 200, 400),\n        (32, 0.80, 4.0, 4, 200, 400),\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        N, p, s, b, R, B = case\n        \n        iid_cover_count = 0\n        block_cover_count = 0\n        \n        for _ in range(R):\n            # 1. Generate one realization of the data\n            X = generate_spatially_correlated_data(N, p, s, rng)\n            A_hat = np.mean(X)\n            \n            # 2. Compute IID bootstrap CI and check coverage\n            iid_ci = iid_bootstrap(X, B, rng)\n            if iid_ci[0] = A_hat = iid_ci[1]:\n                iid_cover_count += 1\n            \n            # 3. Compute Block bootstrap CI and check coverage\n            block_ci = block_bootstrap(X, b, B, rng)\n            if block_ci[0] = A_hat = block_ci[1]:\n                block_cover_count += 1\n                \n        # 4. Calculate coverage rates for the current case\n        iid_rate = iid_cover_count / R\n        block_rate = block_cover_count / R\n        all_results.append([iid_rate, block_rate])\n\n    # Final print statement in the exact required format\n    # Example format: [[c_iid_1,c_block_1],[c_iid_2,c_block_2],...]\n    formatted_results = \",\".join(f\"[{res[0]},{res[1]}]\" for res in all_results)\n    print(f\"[{formatted_results}]\")\n\nsolve()\n```", "id": "3106269"}]}