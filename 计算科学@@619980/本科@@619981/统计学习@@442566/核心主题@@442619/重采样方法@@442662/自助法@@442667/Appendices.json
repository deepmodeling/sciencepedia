{"hands_on_practices": [{"introduction": "这项练习旨在揭开自助法（Bootstrap）过程的神秘面纱，让你亲手逐步完成计算。通过一个简化的符号示例[@problem_id:851901]，你将具体理解“有放回重抽样”如何生成一个用于估计标准误差的统计量分布，从而为更复杂的应用打下坚实基础。", "problem": "在统计分析中，非参数配对自助法（non-parametric pairs bootstrap）是一种强大的重抽样技术，用于在统计量的解析分布未知或依赖于强假设时，估计其不确定性。本题探讨如何应用自助法来估计回归系数的标准误。\n\n考虑一个简单线性回归模型，$Y = \\beta_0 + \\beta_1 X + \\epsilon$，其中斜率参数 $\\beta_1$ 是从一组 $n$ 个数据对 $\\{(x_i, y_i)\\}_{i=1}^n$ 中估计得到的。斜率的普通最小二乘 (OLS) 估计量由下式给出：\n$$\n\\hat{\\beta}_1 = \\frac{S_{xy}}{S_{xx}} = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2}\n$$\n其中 $\\bar{x}$ 和 $\\bar{y}$ 分别是 $X$ 和 $Y$ 的样本均值。\n\n估计 $\\hat{\\beta}_1$ 标准误的自助法步骤如下：\n1.  从原始数据集 $\\mathcal{D}$ 中通过有放回抽样，抽取 $B$ 个自助样本 $\\mathcal{D}^*_1, \\mathcal{D}^*_2, ..., \\mathcal{D}^*_B$，每个样本的大小为 $n$。\n2.  对于每个自助样本 $\\mathcal{D}^*_b$，计算其斜率估计值，记为 $\\hat{\\beta}_{1,b}^*$。\n3.  $\\hat{\\beta}_1$ 的标准误的自助估计量是 $B$ 个自助斜率估计值的样本标准差：\n    $$\n    \\hat{\\text{se}}_{\\text{boot}}(\\hat{\\beta}_1) = \\sqrt{\\frac{1}{B-1} \\sum_{b=1}^{B} (\\hat{\\beta}_{1,b}^* - \\bar{\\beta}_1^*)^2}\n    $$\n    其中 $\\bar{\\beta}_1^* = \\frac{1}{B} \\sum_{b=1}^{B} \\hat{\\beta}_{1,b}^*$ 是自助估计值的均值。\n\n**问题：**\n假设你有一个大小为 $n=3$ 的原始数据集：\n$$\n\\mathcal{D} = \\{ (0,0), (1, \\alpha), (2, \\beta) \\}\n$$\n其中 $\\alpha$ 和 $\\beta$ 是实值参数，并且已知 $\\beta \\neq 2\\alpha$，这确保了这三个点不共线。\n\n你使用极少数的自助样本（$B=2$）执行一次自助分析。得到的两个自助样本是：\n1.  $\\mathcal{D}^*_1 = \\{ (0,0), (0,0), (1, \\alpha) \\}$\n2.  $\\mathcal{D}^*_2 = \\{ (0,0), (1, \\alpha), (2, \\beta) \\}$ （与原始样本 $\\mathcal{D}$ 相同）\n\n推导斜率的标准误的自助估计量 $\\hat{\\text{se}}_{\\text{boot}}(\\hat{\\beta}_1)$ 的一个闭式表达式，该表达式用参数 $\\alpha$ 和 $\\beta$ 表示。", "solution": "1. 相关方程：\n   $\\displaystyle \\hat\\beta_1=\\frac{S_{xy}}{S_{xx}},\\quad S_{xy}=\\sum_{i=1}^n (x_i-\\bar x)(y_i-\\bar y),\\quad S_{xx}=\\sum_{i=1}^n (x_i-\\bar x)^2.$  \n   对于 $B=2$，自助标准误为  \n   $$\n   \\hat{\\mathrm{se}}_{\\mathrm{boot}}(\\hat\\beta_1)\n   =\\sqrt{\\frac{1}{B-1}\\sum_{b=1}^2\\bigl(\\hat\\beta_{1,b}^*-\\bar\\beta^*_1\\bigr)^2}\n   =\\sqrt{\\sum_{b=1}^2\\bigl(\\hat\\beta_{1,b}^*-\\bar\\beta^*_1\\bigr)^2}\\,,\n   $$\n   因为 $B-1=1$。\n\n2. 计算 $\\mathcal D_1^*=\\{(0,0),(0,0),(1,\\alpha)\\}$ 的 $\\hat\\beta_{1,1}^*$。\n   $$\n   \\bar x_1^*=\\frac{0+0+1}{3}=\\frac13,\\quad \\bar y_1^*=\\frac{0+0+\\alpha}{3}=\\frac\\alpha3;\n   $$\n   $$\n   S_{xy}^{(1)}=2\\bigl(-\\tfrac13\\bigr)\\bigl(-\\tfrac\\alpha3\\bigr)+\\bigl(\\tfrac23\\bigr)\\bigl(\\tfrac{2\\alpha}3\\bigr)\n   =\\frac{2\\alpha}{9}+\\frac{4\\alpha}{9}=\\frac{2\\alpha}{3},\\quad\n   S_{xx}^{(1)}=2\\!\\bigl(\\tfrac{1}{3}\\bigr)^2+\\bigl(\\tfrac{2}{3}\\bigr)^2=\\frac{2}{3},\n   $$\n   $$\n   \\hat\\beta_{1,1}^*=\\frac{S_{xy}^{(1)}}{S_{xx}^{(1)}}=\\frac{\\tfrac{2\\alpha}{3}}{\\tfrac{2}{3}}=\\alpha.\n   $$\n\n3. 计算原始样本 $\\{(0,0),(1,\\alpha),(2,\\beta)\\}$ 的 $\\hat\\beta_{1,2}^*$。\n   $$\n   \\bar x=1,\\quad \\bar y=\\frac{\\alpha+\\beta}{3},\\quad S_{xy}=\\sum(x_i-\\bar x)y_i = (-1)(0)+(0)(\\alpha)+(1)(\\beta)=\\beta,\\quad S_{xx}=1+0+1=2,\n   $$\n   $$\n   \\hat\\beta_{1,2}^*=\\frac{\\beta}{2}.\n   $$\n\n4. 自助斜率的均值：\n   $$\n   \\bar\\beta^*_1=\\frac{\\alpha+\\tfrac{\\beta}{2}}{2}=\\frac{2\\alpha+\\beta}{4}.\n   $$\n   偏差：\n   $$\n   \\hat\\beta_{1,1}^*-\\bar\\beta^*_1\n   =\\alpha-\\frac{2\\alpha+\\beta}{4}\n   =\\frac{2\\alpha-\\beta}{4},\\quad\n   \\hat\\beta_{1,2}^*-\\bar\\beta^*_1\n   =\\frac{\\beta}{2}-\\frac{2\\alpha+\\beta}{4}\n   =-\\frac{2\\alpha-\\beta}{4}.\n   $$\n   偏差平方和：\n   $$\n   \\sum_{b=1}^2\\bigl(\\hat\\beta_{1,b}^*-\\bar\\beta^*_1\\bigr)^2\n   =2\\Bigl(\\frac{2\\alpha-\\beta}{4}\\Bigr)^2\n   =\\frac{(2\\alpha-\\beta)^2}{8}.\n   $$\n\n5. 自助标准误：\n   $$\n   \\hat{\\mathrm{se}}_{\\mathrm{boot}}(\\hat\\beta_1)\n   =\\sqrt{\\frac{(2\\alpha-\\beta)^2}{8}}\n   =\\frac{|2\\alpha-\\beta|}{2\\sqrt2}.\n   $$", "answer": "$$\\boxed{\\frac{\\lvert\\beta-2\\alpha\\rvert}{2\\sqrt2}}$$", "id": "851901"}, {"introduction": "本练习将你的技能从简单应用提升到复杂的数据分析层面。通过编程实现“自助法后刀切法”（Jackknife-after-bootstrap）[@problem_id:3180777]，你将学习如何运用重抽样方法，不仅量化不确定性，还能诊断模型的稳定性，并识别出可能主导分析结果的影响点。这是一个现代统计实践中非常重要的动手挑战。", "problem": "给定三个独立的测试用例，每个用例都包含一个固定的成对观测数据集 $\\{(x_i,y_i)\\}_{i=1}^n$。对于每个测试用例，您必须使用 bootstrap 方法结合 jackknife-after-bootstrap 程序来量化每个观测值对所选统计量的 bootstrap 分布的影响，然后识别出高影响点。所选的统计量是通过普通最小二乘法（OLS）拟合的简单线性回归的斜率参数，该方法旨在最小化残差平方和。\n\n基础理论：\n- 简单线性回归的普通最小二乘法（OLS）估计旨在最小化 $S(b_0,b_1) = \\sum_{i=1}^n (y_i - b_0 - b_1 x_i)^2$。一阶最优性条件意味着估计量 $\\hat{b}_1$ 满足 $\\hat{b}_1 = \\dfrac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2}$，其中 $\\bar{x} = \\dfrac{1}{n}\\sum_{i=1}^n x_i$ 且 $\\bar{y} = \\dfrac{1}{n}\\sum_{i=1}^n y_i$。\n- Bootstrap 方法通过从 $\\{1,\\dots,n\\}$ 中重复地、有放回地抽取 $n$ 个索引来形成 bootstrap 重抽样样本，并在每个重抽样样本上计算统计量，从而近似统计量 $\\theta$ 的抽样分布。设 $B$ 表示 bootstrap 复制的次数。$B$ 个 bootstrap 统计量的经验分布近似于 $\\theta$ 的真实抽样分布。\n- Jackknife-after-bootstrap 方法通过移除每个观测值 $i$ 后重新计算 bootstrap 分布来评估其影响，从而为统计量得出一个新的 bootstrap 均值。将此均值与原始 bootstrap 均值进行比较，即可提供一个影响度量。\n\n具体任务：\n1. 对于每个测试用例，在大小为 $n$ 的每个 bootstrap 重抽样样本上计算 OLS 斜率统计量，使用 $B$ 次复制，以从完整数据集中获得一个斜率集合 $\\{\\hat{b}_1^{*(b)}\\}_{b=1}^B$。设 $\\bar{b}_{\\text{full}}$ 为有效 bootstrap 斜率的均值，设 $s_{\\text{full}}$ 为它们的样本标准差（自由度为 $1$）。\n2. 对于每个观测值索引 $i \\in \\{0,\\dots,n-1\\}$，移除该观测值以形成大小为 $n-1$ 的删减数据集，在该删减数据集上生成 $B$ 次 bootstrap 复制（有放回地重抽样 $n-1$ 个点），计算此删减数据集的 bootstrap 斜率，并设 $\\bar{b}_{(-i)}$ 为从此删减数据集中得到的有效斜率的均值。\n3. 将观测值 $i$ 的影响度量定义为\n$$\nI_i = \n\\begin{cases}\n\\dfrac{\\left|\\bar{b}_{(-i)} - \\bar{b}_{\\text{full}}\\right|}{s_{\\text{full}}},  \\text{若 } s_{\\text{full}} > 0 \\\\\n\\left|\\bar{b}_{(-i)} - \\bar{b}_{\\text{full}}\\right|,  \\text{若 } s_{\\text{full}} = 0\n\\end{cases}\n$$\n如果 $I_i > \\tau$，则将观测值 $i$ 分类为高影响点，其中 $\\tau$ 是给定的阈值。\n4. 您必须遵守的实现细节：\n   - 如果一个 bootstrap 重抽样样本导致 $x$ 的方差为零（即，对于该重抽样样本，$\\sum_{j} (x_j - \\bar{x})^2 = 0$），则 OLS 斜率未定义；您必须丢弃该复制，并且不将其包含在 $\\bar{b}$ 或 $s$ 的计算中。\n   - 如果对于给定的数据集，完全没有有效的 bootstrap 复制（对于所提供的测试用例，这种情况极不可能发生），则对所有 $i$ 定义 $I_i = 0$。\n   - 全程对观测值使用 0-基索引。\n   - 不要在输出中使用任何物理单位；所有结果都是无单位的实数或整数。\n\n您必须将上述方法应用于以下测试套件：\n\n- 测试用例 1：\n  - 数据：$x = (0, 1, 2, 3, 10)$, $y = (0.5, 2.1, 3.9, 6.2, 50.0)$\n  - 复制次数：$B = 1200$\n  - 阈值：$\\tau = 2.0$\n- 测试用例 2：\n  - 数据：$x = (0, 1, 2, 3, 4, 5, 6, 7, 8, 9)$, $y = (0.1, 3.2, 6.1, 9.0, 12.0, 15.1, 18.2, 21.3, 24.1, 27.0)$\n  - 复制次数：$B = 1200$\n  - 阈值：$\\tau = 2.0$\n- 测试用例 3：\n  - 数据：$x = (0, 1, 1, 2, 2, 100)$, $y = (0.1, 0.7, 0.6, 1.0, 0.9, 55.0)$\n  - 复制次数：$B = 1200$\n  - 阈值：$\\tau = 1.5$\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。每个元素对应一个测试用例，并且必须是一个整数列表，其中包含该用例的高影响观测值的 0-基索引，按升序排列。例如，最终输出格式必须类似于 $[[i\\_1,i\\_2],[j\\_1,j\\_2,j\\_3],[]]$，其中空方括号表示该用例没有高影响观测值。", "solution": "本问题的解决方案遵循“自助法后刀切法”（Jackknife-after-bootstrap）的程序，旨在识别对普通最小二乘（OLS）回归斜率有显著影响的数据点。算法的核心步骤如下：\n\n1.  **实现核心统计量**：首先，我们编写一个函数来计算OLS斜率 $\\hat{b}_1 = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum (x_i - \\bar{x})^2}$。该函数必须处理分母为零的特殊情况（即所有 $x$ 值相同时），此时斜率未定义。\n\n2.  **构建自助法函数**：接下来，我们创建一个函数，该函数接收一个数据集并执行自助法。此函数重复 $B$ 次以下操作：\n    - 从数据集中有放回地抽取 $n$ 个点，形成一个自助样本。\n    - 计算该自助样本的OLS斜率。\n    - 收集所有计算出的有效斜率，形成一个分布。\n\n3.  **执行Jackknife-after-Bootstrap分析**：\n    -   **基准计算**：对完整的原始数据集运行自助法程序，得到一组斜率值。计算这组值的均值 $\\bar{b}_{\\text{full}}$ 和样本标准差 $s_{\\text{full}}$。\n    -   **留一法循环**：遍历数据集中的每一个观测点 $i$。\n    -   对于每个点 $i$，创建一个移除了该点的“删减”数据集。\n    -   对此删减数据集再次运行自助法程序，得到另一组斜率值，并计算其均值 $\\bar{b}_{(-i)}$。\n    -   **计算影响值**：根据公式 $I_i = |\\bar{b}_{(-i)} - \\bar{b}_{\\text{full}}| / s_{\\text{full}}$ 计算观测点 $i$ 的影响分数。\n    -   **识别与排序**：将 $I_i$ 与给定的阈值 $\\tau$ 进行比较。如果 $I_i > \\tau$，则将索引 $i$ 标记为高影响点。\n\n4.  **整合与输出**：对所有三个测试用例重复此过程，并将找到的高影响点索引按升序排序后，格式化为最终输出。\n\n该方法通过系统性地评估每个数据点对模型参数自助估计的扰动，为诊断模型稳定性和识别异常值提供了量化依据。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    It implements the jackknife-after-bootstrap procedure to identify high-influence points.\n    \"\"\"\n\n    def ols_slope(x, y):\n        \"\"\"\n        Calculates the OLS slope for a simple linear regression.\n\n        Args:\n            x (np.ndarray): The independent variable data.\n            y (np.ndarray): The dependent variable data.\n\n        Returns:\n            float: The OLS slope, or np.nan if the slope is undefined.\n        \"\"\"\n        n = len(x)\n        if n  2:\n            return np.nan\n\n        x_mean = np.mean(x)\n        \n        # Denominator of the slope formula\n        ss_xx = np.sum((x - x_mean)**2)\n\n        # As per problem, if variance in x is zero, the slope is undefined.\n        if ss_xx == 0:\n            return np.nan\n\n        y_mean = np.mean(y)\n        # Numerator of the slope formula\n        ss_xy = np.sum((x - x_mean) * (y - y_mean))\n        \n        return ss_xy / ss_xx\n\n    def get_bootstrap_slopes(x, y, B):\n        \"\"\"\n        Generates a distribution of OLS slopes using the bootstrap method.\n\n        Args:\n            x (np.ndarray): The independent variable data.\n            y (np.ndarray): The dependent variable data.\n            B (int): The number of bootstrap replicates.\n\n        Returns:\n            np.ndarray: An array of valid bootstrap slopes.\n        \"\"\"\n        n = len(x)\n        if n == 0:\n            return np.array([])\n        \n        slopes = []\n        # Pre-generate all random indices for performance\n        # Each row is a set of indices for one bootstrap replicate\n        all_indices = np.random.choice(n, size=(B, n), replace=True)\n\n        for resample_indices in all_indices:\n            x_resample = x[resample_indices]\n            y_resample = y[resample_indices]\n            \n            slope = ols_slope(x_resample, y_resample)\n            \n            # Discard replicates where the slope is undefined\n            if not np.isnan(slope):\n                slopes.append(slope)\n                \n        return np.array(slopes)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test Case 1\n        (np.array([0, 1, 2, 3, 10]), np.array([0.5, 2.1, 3.9, 6.2, 50.0]), 1200, 2.0),\n        # Test Case 2\n        (np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), np.array([0.1, 3.2, 6.1, 9.0, 12.0, 15.1, 18.2, 21.3, 24.1, 27.0]), 1200, 2.0),\n        # Test Case 3\n        (np.array([0, 1, 1, 2, 2, 100]), np.array([0.1, 0.7, 0.6, 1.0, 0.9, 55.0]), 1200, 1.5)\n    ]\n\n    all_results = []\n    for x_full, y_full, B, tau in test_cases:\n        n = len(x_full)\n        \n        # 1. Compute bootstrap statistics for the full dataset.\n        full_slopes = get_bootstrap_slopes(x_full, y_full, B)\n        \n        # Per problem: if no valid replicates, I_i = 0 for all i.\n        # This means no high-influence points.\n        if len(full_slopes) == 0:\n            all_results.append([])\n            continue\n\n        b_full_mean = np.mean(full_slopes)\n        \n        # Per problem: sample standard deviation (ddof=1).\n        # If less than 2 valid slopes, standard deviation is 0.\n        b_full_std = 0.0\n        if len(full_slopes) >= 2:\n            b_full_std = np.std(full_slopes, ddof=1)\n            \n        high_influence_indices = []\n        # 2. Loop through each observation for jackknife-after-bootstrap.\n        for i in range(n):\n            # Create the reduced dataset by removing observation i.\n            x_reduced = np.delete(x_full, i)\n            y_reduced = np.delete(y_full, i)\n            \n            # Compute bootstrap mean for the reduced dataset.\n            reduced_slopes = get_bootstrap_slopes(x_reduced, y_reduced, B)\n            \n            # Per problem: if no valid replicates, I_i = 0.\n            if len(reduced_slopes) == 0:\n                influence_i = 0.0\n            else:\n                b_reduced_mean = np.mean(reduced_slopes)\n                \n                # 3. Define the influence measure for observation i.\n                diff = np.abs(b_reduced_mean - b_full_mean)\n                if b_full_std > 0:\n                    influence_i = diff / b_full_std\n                else:\n                    influence_i = diff\n            \n            # 4. Classify observation i as high-influence.\n            if influence_i > tau:\n                high_influence_indices.append(i)\n        \n        # Results must be in ascending order.\n        all_results.append(sorted(high_influence_indices))\n\n    # Final print statement in the exact required format.\n    formatted_results = [f\"[{','.join(map(str, res))}]\" for res in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3180777"}, {"introduction": "最后的这项练习鼓励你像统计学家一样思考，批判性地评估一种方法的性能。你不再仅仅是应用自助法，而是在一个受控的环境中分析其理论表现[@problem_id:851841]，探究一个“95%置信区间”是否真的在95%的情况下包含了真实的参数。这加深了你对自助法内在近似性质的理解，并凸显了验证方法有效性的重要性。", "problem": "自助法（bootstrap）是统计学中一种强大的重抽样方法，用于估计估计量的不确定性。本问题在一个简化的设定下，探讨非参数自助法置信区间的理论性质。\n\n考虑一个大小为 $n=3$ 的随机样本，记为 $X_1, X_2, X_3$，它们独立同分布地从一个未知速率参数为 $\\lambda$ 的指数分布中抽取。其概率密度函数为 $f(x; \\lambda) = \\lambda e^{-\\lambda x}$，$x \\ge 0$。我们感兴趣的是估计该分布的中位数，记为 $m$。\n\n一个用于中位数的非参数百分位数自助法置信区间按如下步骤构建：\n1.  从原始观测样本 $\\{x_1, x_2, x_3\\}$ 中，生成大量的（$B$ 个）“自助样本”。每个自助样本 $\\{x_1^*, x_2^*, x_3^*\\}$ 是一个大小为 $n=3$ 的新样本，通过从原始样本 $\\{x_1, x_2, x_3\\}$ 中有放回地抽样得到。\n2.  对于 $B$ 个自助样本中的每一个，计算其样本中位数 $\\hat{m}^*$。三个数的样本中位数是它们排序后的中间值。\n3.  这 $B$ 个自助中位数的集合 $\\{\\hat{m}^*_1, \\dots, \\hat{m}^*_B\\}$ 构成一个经验分布，该分布近似于样本中位数的抽样分布。\n4.  真实中位数 $m$ 的一个近似 95% 置信区间由该经验分布的第 2.5 百分位数和第 97.5 百分位数给出。\n\n对于本问题，我们考虑理想情况，即自助重抽样的次数 $B \\to \\infty$。在此极限下，百分位数由自助中位数 $\\hat{m}^*$ 在给定原始样本条件下的精确理论概率质量函数确定。对于一个离散分布，第 $p$ 百分位数定义为满足累积概率 $P(\\hat{m}^* \\le v)$ 至少为 $p$ 的最小值 $v$。\n\n你的任务是推导这个 95% 自助法置信区间的精确理论覆盖概率。覆盖概率定义为由样本 $\\{X_1, X_2, X_3\\}$ 构建的随机区间成功包含真实总体中位数 $m$ 的概率。", "solution": "1. 从 $\\{x_{(1)},x_{(2)},x_{(3)}\\}$ 中有放回地抽取三次，得到的自助中位数 $\\hat m^*$ 取值为 $x_{(1)},x_{(2)},x_{(3)}$，其概率为\n$$P(\\hat m^*=x_{(1)})=P(N_1\\ge2)=\\sum_{k=2}^3\\binom{3}{k}\\Bigl(\\tfrac13\\Bigr)^k\\Bigl(\\tfrac23\\Bigr)^{3-k}=\\frac7{27},$$\n$$P(\\hat m^*=x_{(3)})=P(N_3\\ge2)=\\frac7{27},\\quad\nP(\\hat m^*=x_{(2)})=1-\\frac{7+7}{27}=\\frac{13}{27}.$$\n2. 第 2.5 百分位数是满足 $P(\\hat m^*\\le v)\\ge0.025$ 的最小 $v$。由于 $P(\\hat m^*\\le x_{(1)})=7/270.025$，所以下界是 $x_{(1)}$。第 97.5 百分位数是满足 $P(\\hat m^*\\le v) \\ge 0.975$ 的最小 $v$。由于 $P(\\hat m^*\\le x_{(2)})=20/27  0.975$ 但 $P(\\hat m^*\\le x_{(3)})=1\\ge0.975$，所以上界是 $x_{(3)}$。因此，置信区间是 $[X_{(1)},X_{(3)}]$。\n3. 覆盖概率为\n$$P\\bigl(X_{(1)}\\le m\\le X_{(3)}\\bigr)\n=1-P(X_{(3)}  m) - P(X_{(1)} > m) = 1 - P(\\text{所有 } X_i  m) - P(\\text{所有 } X_i > m) = 1 - (1/2)^3 - (1/2)^3 = 1 - 1/4 = 3/4.$$", "answer": "$$\\boxed{\\frac{3}{4}}$$", "id": "851841"}]}