{"hands_on_practices": [{"introduction": "理论是基础，但真正的理解来自于实践。本练习将指导你从头开始实现前向逐步选择算法，并通过在训练集和验证集上评估模型性能，亲眼见证模型选择中的一个核心概念：随着模型复杂度的增加，训练误差通常会单调下降，而验证误差则常常呈现出先降后升的“U”形曲线。这个实践将加深你对偏误-方差权衡（bias-variance tradeoff）以及过拟合现象的理解。[@problem_id:3104976]", "problem": "考虑使用前向逐步选择的线性回归。设训练观测值为 $\\{(x_i, y_i)\\}_{i=1}^n$，其中 $x_i \\in \\mathbb{R}^p$ 且 $y_i \\in \\mathbb{R}$。对于由 $S \\subseteq \\{1,\\dots,p\\}$ 索引的任何预测变量子集，定义一个包含截距和 $S$ 中预测变量的模型，并将其训练残差平方和 (RSS) 表示为 $\\text{RSS}(S) = \\sum_{i=1}^n \\left(y_i - \\hat{y}_i(S)\\right)^2$，其中 $\\hat{y}_i(S)$ 是使用 $S$ 中预测变量的最小二乘拟合。前向逐步选择构建了一个所选集合的嵌套序列 $(S_k)_{k=0}^p$，使得 $S_0 = \\varnothing$ 并且，对于 $k \\geq 0$，有 $S_{k+1} = S_k \\cup \\{j^*\\}$，其中 $j^*$ 是从 $\\{1,\\dots,p\\} \\setminus S_k$ 中选择的，以最小化大小为 $k+1$ 时的训练 RSS。\n\n从以下基本概念开始：\n- 线性最小二乘拟合在所选预测变量和截距的张成空间上最小化误差平方和。\n- 如果回归量集合扩大，设计矩阵的列（包括截距）的张成空间会扩大或保持不变，因此最小化的 RSS 不会增加。\n\n您的任务：\n1. 在训练集上实现前向逐步选择，以生成大小为 $k = 0,1,\\dots,p$ 的模型 $S_k$。对于每个 $k$，在一个大小为 $m$ 的独立验证集上计算训练 RSS 和验证均方误差 $\\text{MSE}_{\\text{val}}(k) = \\frac{1}{m}\\sum_{i=1}^m \\left(y^{\\text{val}}_i - \\hat{y}^{\\text{val}}_i(S_k)\\right)^2$，其中 $\\hat{y}^{\\text{val}}_i(S_k)$ 使用在训练集上拟合的系数。\n2. 通过计算证明，对于通用数据，在前向选择中，随着 $k$ 的增加，训练 RSS 是严格递减的（使用一个小的数值容差来防止浮点效应）。\n3. 证明验证误差 $\\text{MSE}_{\\text{val}}(k)$ 作为 $k$ 的函数可以呈现 U 型行为：由于偏差减小而初始下降，然后由于过拟合导致的方差膨胀而增加。设计至少一个数据集，其中最小化的 $k$ 严格介于 $0$ 和 $p$ 之间。\n4. 使用以下数据集生成器参数的测试套件。每个数据集通过如下方式抽样预测变量和响应来生成：抽取 $X_{\\text{train}} \\in \\mathbb{R}^{n \\times p}$ 和 $X_{\\text{val}} \\in \\mathbb{R}^{m \\times p}$，其条目为独立的标准正态分布；选择一个系数向量 $\\beta \\in \\mathbb{R}^p$；生成 $y_{\\text{train}} = X_{\\text{train}} \\beta + \\varepsilon_{\\text{train}}$ 和 $y_{\\text{val}} = X_{\\text{val}} \\beta + \\varepsilon_{\\text{val}}$，其中噪声项具有均值为 $0$、标准差为 $\\sigma$ 的独立正态分布条目。在所有拟合模型中使用截距。测试套件的参数是：\n   - 情况 A（中间最优）：$n = 50$，$m = 400$，$p = 20$，$\\beta = (3.0, -2.5, 1.5, 0, \\dots, 0)$，$\\sigma = 2.0$，seed $= 2024$。\n   - 情况 B（空模型最佳）：$n = 60$，$m = 400$，$p = 12$，$\\beta = (0, \\dots, 0)$，$\\sigma = 1.0$，seed $= 2025$。\n   - 情况 C（全模型最佳）：$n = 80$，$m = 400$，$p = 6$，$\\beta = (1.0, -1.5, 0.8, 2.0, -1.0, 0.5)$，$\\sigma = 0.2$，seed $= 7$。\n5. 对于每种情况，返回三个量：\n   - 一个布尔值，指示序列 $\\text{RSS}(S_k)$ 是否在 $k = 0,1,\\dots,p$ 的范围内随着 $k$ 的增加而严格递减。\n   - 在 $\\{0,1,\\dots,p\\}$ 中最小化 $\\text{MSE}_{\\text{val}}(k)$ 的整数 $k^\\star$。\n   - 一个布尔值，指示验证误差是否呈现 U 型曲线，即 $0  < k^\\star < p$ 且 $\\max\\{\\text{MSE}_{\\text{val}}(0), \\dots, \\text{MSE}_{\\text{val}}(k^\\star - 1)\\} > \\text{MSE}_{\\text{val}}(k^\\star)$ 和 $\\max\\{\\text{MSE}_{\\text{val}}(k^\\star + 1), \\dots, \\text{MSE}_{\\text{val}}(p)\\} > \\text{MSE}_{\\text{val}}(k^\\star)$ 同时成立。\n6. 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每种情况的结果都是一个按上述顺序排列的三元素列表。例如：`[[True,3,True],[True,0,False],[True,6,False]]`。不涉及物理单位或角度，任何百分比（若有）都必须表示为小数。确保所有数学计算都遵循标准的线性代数运算。\n\n程序必须按规定实现数据生成和前向逐步选择，运行三种情况，并生成与上述格式完全匹配的单行输出。", "solution": "用户提供的问题被评估为**有效**。\n\n该问题是统计学习中一个定义明确的计算练习，专注于实现和分析线性回归前向逐步选择的行为。它在科学上基于回归、模型选择和偏差-方差权衡的既定原则。问题陈述是自包含的，提供了所有必要的参数、数据生成过程、用于可复现性的随机种子以及所需输出的精确定义。它没有歧义、主观声明或事实错误。这些任务在计算上是可行的，并测试了基本概念，例如训练误差的单调递减和验证误差的典型 U 型曲线，这些是理解模型复杂度和过拟合的核心。\n\n### 基于原则的设计\n\n解决方案是围绕线性回归和前向逐步模型选择的核心原则构建的。\n\n#### 1. 前向逐步选择算法\n\n前向逐步选择是一种用于为模型选择预测变量子集的贪心迭代算法。该过程从一个仅包含截距的空模型开始，然后迭代地一次添加一个预测变量。\n\n- **初始化 ($k=0$)**：过程从最简单的模型 $S_0 = \\varnothing$ 开始，该模型不包含任何预测变量，只有一个截距。对每个观测值的预测就是训练响应变量的均值 $\\hat{y}_i = \\bar{y}_{\\text{train}}$。为这个基础模型计算初始的训练残差平方和 $\\text{RSS}(S_0)$ 和验证均方误差 $\\text{MSE}_{\\text{val}}(0)$。\n\n- **迭代步骤 ($k \\to k+1$)**：对于从 $0$ 到 $p-1$ 的每一步 $k$，算法会考虑从尚未在模型中的预测变量集合 $\\{1, \\dots, p\\} \\setminus S_k$ 中添加一个预测变量。对于每个候选预测变量 $j$，一个包含预测变量 $S_k \\cup \\{j\\}$ 的临时模型会拟合到训练数据上，并计算其训练 RSS。算法会贪心地选择能够最大程度减少 RSS 的预测变量 $j^*$：\n$$\nj^* = \\arg\\min_{j \\in \\{1,\\dots,p\\} \\setminus S_k} \\text{RSS}(S_k \\cup \\{j\\})\n$$\n然后将新模型定义为 $S_{k+1} = S_k \\cup \\{j^*\\}$。此过程生成一个从 0 到 $p$ 大小递增的嵌套模型序列 $S_0 \\subset S_1 \\subset \\dots \\subset S_p$。\n\n每个线性模型的拟合都是使用普通最小二乘法 (OLS) 进行的。对于一个包含预测变量集合 $S$ 的模型，设计矩阵 $\\tilde{X}_S$ 是通过在所选预测变量矩阵 $X_S$ 前面增广一列全为 1 的列来构建的，以代表截距。OLS 系数向量 $\\hat{\\beta}_S$ 是通过求解正规方程找到的，可以表示为 $\\hat{\\beta}_S = (\\tilde{X}_S^T \\tilde{X}_S)^{-1} \\tilde{X}_S^T y_{\\text{train}}$。此计算使用像 `numpy.linalg.lstsq` 这样的数值稳定方法。\n\n#### 2. 训练 RSS 的单调性\n\n训练 RSS 是模型大小 $k$ 的一个非增函数。这是最小二乘法的一个基本性质。当添加一个预测变量时，线性模型的基向量集合（设计矩阵的列）会扩大。OLS 拟合找到了响应向量 $y_{\\text{train}}$ 在设计矩阵列空间上的投影。向基中添加一个向量只会扩大这个空间或使其保持不变。因此，在新、更大的空间上的投影不会比在原始、更小的空间上的投影离 $y_{\\text{train}}$ 更远。这意味着残差向量的长度，以及 RSS，都不会增加。\n\n对于“通用”数据，例如从连续分布（如标准正态分布）生成的数据，新预测变量列与现有列完全线性相关的概率为零。因此，列空间在每一步都会严格扩大，从而保证训练 RSS 是**严格递减**的。我们通过检查是否对所有 $k$ 都有 $\\text{RSS}(S_k) > \\text{RSS}(S_{k+1})$ 来在计算上验证这一点，并使用一个小的数值容差来处理浮点运算。\n\n#### 3. 验证误差与偏差-方差权衡\n\n虽然训练误差随模型复杂度的增加而单调递减，但由于偏差-方差权衡，验证误差表现出更复杂的行为。\n\n- **偏差**：一个简单的模型（小 $k$）可能无法捕捉到预测变量和响应之间的真实潜在关系。这种系统误差被称为偏差。最初，当我们添加相关的预测变量时，模型的灵活性增加，能更好地符合真实信号，从而导致偏差急剧减少，验证误差也随之降低。\n\n- **方差**：一个复杂的模型（大 $k$）具有很高的灵活性，可以捕捉到复杂的模式。然而，它可能会开始拟合训练数据中的随机噪声，这种现象称为过拟合。这会导致高方差，因为拟合的模型会随着训练集的不同而发生巨大变化。这种过拟合会降低模型泛化到未见数据的能力，导致验证误差增加。\n\n偏差和方差之间的相互作用通常导致验证误差作为模型复杂度 $k$ 的函数呈现出 U 型曲线。误差随着偏差的减少而下降，然后随着方差的主导而增加。最优模型对应于这个“U”型曲线底部的 $k^\\star$ 值，它平衡了偏差和方差，以在未见数据上实现最佳的预测性能。问题要求识别出这个最优的 $k^\\star$，并验证验证误差曲线是否是“U 型”的，即其最小值严格位于内部（即 $0 < k^\\star < p$），并且在最小值之前和之后都存在误差更高的点。\n\n#### 4. 实现策略\n\n该解决方案是作为一个遵循指定环境的 Python 程序实现的。\n\n1.  **数据生成**：对于每个测试用例，为保证可复现性，会设置随机数生成器的种子。根据指定的维度 ($n, m, p$)、真实系数向量 ($\\beta$) 和噪声水平 ($\\sigma$) 对训练和验证数据集 ($X, y$) 进行采样。\n2.  **前向选择循环**：算法如上所述进行。对于每个模型大小 $k \\in \\{0, \\dots, p\\}$，存储训练 `RSS`。在确定最佳模型 $S_k$ 后，其系数在训练数据上最终确定，然后使用这些系数在验证集上预测响应，以计算 `MSE_val(k)`。\n3.  **结果计算**：循环完成后，分析存储的序列 `rss_k` 和 `mse_val_k`：\n    - 通过计算差值 `rss_k[k] - rss_k[k+1]` 并确保它们都为正（大于一个小的容差）来检查 `rss_k` 的严格递减性。\n    - 使用 `numpy.argmin` 在 `mse_val_k` 数组上找到最优模型大小 `k_star`。\n    - 通过检查 `k_star` 是否在 $0$ 和 $p$ 之间，以及在 `k_star` 的两侧是否存在严格大于最小值的验证误差值来评估 U 型条件。\n4.  **输出格式化**：每个测试用例的结果（一个包含三个值的列表）被格式化为精确的字符串表示 `[布尔值,整数,布尔值]`，然后聚合成最终所需的输出字符串 `[[...],[...],[...]]`。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_case(n, m, p, beta_coeffs, sigma, seed):\n    \"\"\"\n    Generates data, runs forward stepwise selection, and computes required metrics for one case.\n\n    Args:\n        n (int): Number of training observations.\n        m (int): Number of validation observations.\n        p (int): Number of predictors.\n        beta_coeffs (tuple): Non-zero coefficients for the true model.\n        sigma (float): Standard deviation of the noise.\n        seed (int): Random seed for reproducibility.\n\n    Returns:\n        list: A list containing [is_rss_decreasing, k_star, is_u_shaped].\n    \"\"\"\n    rng = np.random.default_rng(seed)\n\n    # 1. Generate data\n    X_train = rng.standard_normal(size=(n, p))\n    X_val = rng.standard_normal(size=(m, p))\n    \n    beta = np.zeros(p)\n    beta[:len(beta_coeffs)] = beta_coeffs\n    \n    eps_train = rng.normal(0, sigma, size=n)\n    eps_val = rng.normal(0, sigma, size=m)\n    \n    y_train = X_train @ beta + eps_train\n    y_val = X_val @ beta + eps_val\n\n    # Arrays to store results for k = 0, 1, ..., p\n    rss_k = np.zeros(p + 1)\n    mse_val_k = np.zeros(p + 1)\n    \n    selected_indices = []\n    available_indices = list(range(p))\n\n    # --- k = 0: Intercept-only model ---\n    y_train_mean = np.mean(y_train)\n    rss_k[0] = np.sum((y_train - y_train_mean)**2)\n    mse_val_k[0] = np.mean((y_val - y_train_mean)**2)\n\n    # --- k = 1 to p: Forward stepwise selection ---\n    for k in range(1, p + 1):\n        best_rss_at_step = np.inf\n        best_new_predictor = -1\n        \n        # Find the best predictor to add from the available set\n        for j in available_indices:\n            current_predictors = selected_indices + [j]\n            \n            # Create design matrix with intercept\n            X_train_subset = X_train[:, current_predictors]\n            design_matrix = np.c_[np.ones(n), X_train_subset]\n            \n            # Solve least squares and get RSS\n            _, residuals, _, _ = np.linalg.lstsq(design_matrix, y_train, rcond=None)\n            \n            rss_candidate = residuals[0] if residuals.size > 0 else np.sum((y_train - design_matrix @ np.linalg.lstsq(design_matrix, y_train, rcond=None)[0])**2)\n\n            if rss_candidate  best_rss_at_step:\n                best_rss_at_step = rss_candidate\n                best_new_predictor = j\n        \n        # Add the best predictor to the model for this step\n        selected_indices.append(best_new_predictor)\n        available_indices.remove(best_new_predictor)\n        \n        # Store RSS for the model of size k\n        rss_k[k] = best_rss_at_step\n        \n        # --- Calculate validation MSE for the new model S_k ---\n        # Fit model on training data to get coefficients\n        X_train_final_subset = X_train[:, selected_indices]\n        design_matrix_train = np.c_[np.ones(n), X_train_final_subset]\n        coeffs, _, _, _ = np.linalg.lstsq(design_matrix_train, y_train, rcond=None)\n        \n        # Predict on validation data using the fitted coefficients\n        X_val_subset = X_val[:, selected_indices]\n        design_matrix_val = np.c_[np.ones(m), X_val_subset]\n        y_val_pred = design_matrix_val @ coeffs\n        \n        # Calculate validation MSE\n        mse_val_k[k] = np.mean((y_val - y_val_pred)**2)\n\n    # 2. Check if RSS sequence is strictly decreasing\n    is_decreasing = bool(np.all(np.diff(rss_k)  -1e-9))\n    \n    # 3. Find k that minimizes validation MSE\n    k_star = int(np.argmin(mse_val_k))\n    \n    # 4. Check for U-shaped profile as defined in the problem\n    is_u_shaped = False\n    if 0  k_star  p:\n        min_mse = mse_val_k[k_star]\n        # Check that there is at least one point > min_mse before and after k_star\n        has_larger_before = np.any(mse_val_k[:k_star] > min_mse)\n        has_larger_after = np.any(mse_val_k[k_star+1:] > min_mse)\n        if has_larger_before and has_larger_after:\n            is_u_shaped = True\n\n    return [is_decreasing, k_star, is_u_shaped]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A: Intermediate optimum\n        {'n': 50, 'm': 400, 'p': 20, 'beta_coeffs': (3.0, -2.5, 1.5), 'sigma': 2.0, 'seed': 2024},\n        # Case B: Null model best\n        {'n': 60, 'm': 400, 'p': 12, 'beta_coeffs': (), 'sigma': 1.0, 'seed': 2025},\n        # Case C: Full model best\n        {'n': 80, 'm': 400, 'p': 6, 'beta_coeffs': (1.0, -1.5, 0.8, 2.0, -1.0, 0.5), 'sigma': 0.2, 'seed': 7},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_case(**case)\n        results.append(result)\n\n    # Format the output string exactly as specified\n    formatted_results = []\n    for res in results:\n        # Manually format to get \"[True,3,True]\" without spaces\n        s = '[' + ','.join(map(str, res)) + ']'\n        formatted_results.append(s)\n    \n    final_output_string = '[' + ','.join(formatted_results) + ']'\n    \n    # Final print statement in the exact required format.\n    print(final_output_string)\n\nsolve()\n```", "id": "3104976"}, {"introduction": "贪心算法（greedy algorithm）以其高效而著称，但其每一步都寻求局部最优解的策略，也可能使其错失全局最优解。在这个练习中，你将构建一个精巧的“对抗性”数据集，其中两个预测变量单独来看似乎对模型无益，但它们结合在一起却能极好地解释响应变量。通过这个实践，你将探索前向选择算法的局限性，并深刻理解为何局部最优不等于全局最优。[@problem_id:3105020]", "problem": "您将面临一个统计学习中的场景，该场景涉及使用前向逐步选择和沿前向路径进行最优子集评估的模型选择。目标是构建一个在第一步对贪心选择具有对抗性的设计矩阵，即单个变量在验证集上看起来没有帮助，但它们共同起来却能解释响应变量。您的程序必须实现指定的流程，在一套测试用例上进行评估，并按规定输出单行的聚合结果。\n\n需要使用的基本和核心定义：\n- 普通最小二乘 (OLS) 回归通过最小化训练残差平方和来估计系数。给定一个训练设计矩阵 $X \\in \\mathbb{R}^{n \\times p}$ 和响应向量 $y \\in \\mathbb{R}^{n}$，增广截距项的设计矩阵为 $\\tilde{X} = [\\mathbf{1}, X] \\in \\mathbb{R}^{n \\times (p+1)}$。OLS 估计量是以下问题的解 $\\hat{\\beta}$：\n$$\n\\hat{\\beta} \\in \\arg\\min_{\\beta \\in \\mathbb{R}^{p+1}} \\sum_{i=1}^{n} \\left( y_i - \\tilde{X}_{i\\cdot} \\beta \\right)^2,\n$$\n该解可通过 Moore-Penrose 伪逆或最小二乘程序计算。训练残差平方和 (RSS) 为\n$$\n\\mathrm{RSS}_{\\text{train}} = \\sum_{i=1}^{n} \\left( y_i - \\tilde{X}_{i\\cdot} \\hat{\\beta} \\right)^2.\n$$\n- 对于一个已拟合的模型，在大小为 $m$ 的验证集 $(X^{\\text{val}}, y^{\\text{val}})$ 上进行评估时，其验证均方误差 (MSE) 为\n$$\n\\mathrm{MSE}_{\\text{val}} = \\frac{1}{m} \\sum_{i=1}^{m} \\left( y^{\\text{val}}_i - \\tilde{X}^{\\text{val}}_{i\\cdot} \\hat{\\beta} \\right)^2,\n$$\n其中 $\\hat{\\beta}$ 仅在训练数据上拟合得到。本问题不涉及物理单位。\n\n对抗性设计的构建：\n- 考虑 $X \\in \\mathbb{R}^{n \\times 2}$ 中的两个预测变量，记为 $x_1$ 和 $x_2$，它们的生成方式使其呈负相关：\n$$\nx_{1,i} \\sim \\mathcal{N}(0,1), \\quad r_i \\sim \\mathcal{N}(0,s^2), \\quad x_{2,i} = -x_{1,i} + r_i,\n$$\n对于 $i \\in \\{1,\\dots,n\\}$ 独立。\n- 响应变量按如下方式生成：\n$$\ny_i = x_{1,i} + x_{2,i} + \\varepsilon_i = r_i + \\varepsilon_i, \\quad \\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2),\n$$\n对于 $i$ 独立。通过这种构造，$x_1$ 和 $x_2$ 呈负相关，并且它们的和 $x_1 + x_2$ 分离出直接驱动 $y$ 的残差分量 $r$。在边际上，$y$ 和 $x_1$ 之间的协方差为 $0$，$y$ 和 $x_2$ 之间的协方差等于 $s^2$，通过选择一个较小的 $s$ 可以使其变得很小。因此，在有限样本中，每个变量单独在验证时可能显得无用，而这两个变量合在一起则能解释 $y$。\n\n需要实现的流程：\n1. 在训练数据上进行前向逐步路径：从仅含截距项的模型开始，在第 $k \\in \\{1,2\\}$ 步，在剩余的变量中，加入那个在用截距项和所有先前已选变量重新拟合模型时产生最小 $\\mathrm{RSS}_{\\text{train}}$ 的变量。\n2. 沿前向路径的最优子集：对于每个模型大小 $k \\in \\{0,1,2\\}$（其中 $k=0$ 表示仅含截距项的模型），在训练集上对前向路径截至大小为 $k$ 所定义的子集拟合 OLS，然后在验证集上计算 $\\mathrm{MSE}_{\\text{val}}$。选择具有最小 $\\mathrm{MSE}_{\\text{val}}$ 的模型大小。\n3. 基于验证的带早停的贪心前向选择：从仅含截距项的模型开始，在第 1 步，尝试性地加入每个候选变量，在训练集上拟合，并计算 $\\mathrm{MSE}_{\\text{val}}$；仅当新的 $\\mathrm{MSE}_{\\text{val}}$ 严格小于当前值时才加入该变量。如果第 1 步有改进，则对第 2 步重复此过程。如果在某一步没有发生改进，则停止并选择当前模型。\n\n每个测试用例需要报告的量：\n- 报告两个布尔值，形式为列表 $[b_1, b_2]$，其中：\n    - $b_1$ 为真当且仅当第 2 步的前向路径包含两个变量，大小为 $k \\in \\{0,1,2\\}$ 的模型中（按最小 $\\mathrm{MSE}_{\\text{val}}$ 判断）最优子集是大小为 2 的模型，并且大小为 1 的模型的 $\\mathrm{MSE}_{\\text{val}}$ 严格大于大小为 0（仅含截距项）的模型。这测试了该变量对是否仅在第 2 步被恢复，以及每个单独的变量是否会损害在验证集上的拟合效果。\n    - $b_2$ 为真当且仅当基于验证的贪心前向选择从未添加任何变量（即，两个变量都未选择），这表明它未能恢复共同提供信息的变量对。\n  \n测试套件参数：\n- 每个测试用例由 $(n_{\\text{train}}, n_{\\text{val}}, s, \\sigma, \\text{seed})$ 定义，包含以下三种情况：\n    1. 情况 A（对抗性强负相关，小残差）：$(n_{\\text{train}} = 60, n_{\\text{val}} = 2000, s = 0.05, \\sigma = 0.02, \\text{seed} = 0)$。\n    2. 情况 B（中等负相关）：$(n_{\\text{train}} = 60, n_{\\text{val}} = 2000, s = 0.5, \\sigma = 0.02, \\text{seed} = 1)$。\n    3. 情况 C（极端负相关和非常小的残差噪声）：$(n_{\\text{train}} = 30, n_{\\text{val}} = 5000, s = 0.005, \\sigma = 0.005, \\text{seed} = 2)$。\n\n您的程序必须：\n- 为每个测试用例使用上述构造方法生成训练集和验证集。\n- 实现所述流程，并为每种情况计算两个布尔值 $b_1$ 和 $b_2$。\n- 生成单行输出，其中包含一个逗号分隔的列表的列表，用方括号括起来，例如 `[[True,False],[False,False],[True,True]]`。\n\n最终输出格式要求：\n- 您的程序应生成单行输出，包含三个测试用例的结果，形式为逗号分隔的列表的列表，用方括号括起来，其确切形式为 `[[b11,b12],[b21,b22],[b31,b32]]`，其中每个 `b_ij` 是一个 Python 布尔值（`True` 或 `False`）。", "solution": "此问题被评估为有效。这是一个在计算统计学领域内良构的、有科学依据且客观的问题，要求在特定的数据生成方案下实现并评估模型选择算法。所有必要的参数和流程都已明确定义，从而能够得到唯一的、可验证的解决方案。\n\n该问题要求构建一个特定的场景，在此场景中贪心模型选择方法会失败。这是通过生成两个强负相关的预测变量 $x_1$ 和 $x_2$ 来实现的，而响应变量 $y$ 则由它们的和决定。这创造了一种情况：每个预测变量单独与响应变量的相关性很低，但它们共同起来却能解释其方差的很大一部分。我们将评估两种模型选择策略——沿前向路径的最优子集选择和基于验证的贪心前向搜索——来展示这种行为。解决方案的步骤是首先生成数据，然后实现指定的算法，最后评估所需布尔值输出的条件。\n\n**1. 数据生成**\n\n对于每个测试用例，我们给定参数 $(n_{\\text{train}}, n_{\\text{val}}, s, \\sigma, \\text{seed})$。我们生成一个大小为 $n_{\\text{train}}$ 的训练集 $(X, y)$ 和一个大小为 $n_{\\text{val}}$ 的验证集 $(X^{\\text{val}}, y^{\\text{val}})$。设计矩阵 $X$ 包含两个预测变量，$x_1$ 和 $x_2$。\n\n对于大小为 $N$ 的数据集（$n_{\\text{train}}$ 或 $n_{\\text{val}}$），每个观测值 $i \\in \\{1, \\dots, N\\}$ 的生成过程如下：\n- 抽取一个标准正态变量：$x_{1,i} \\sim \\mathcal{N}(0, 1)$。\n- 为第二个预测变量抽取一个残差分量：$r_i \\sim \\mathcal{N}(0, s^2)$。\n- 构建第二个预测变量，使其与第一个呈负相关：$x_{2,i} = -x_{1,i} + r_i$。\n- 为响应变量抽取一个误差项：$\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$。\n- 响应变量由预测变量之和加噪声生成：$y_i = x_{1,i} + x_{2,i} + \\varepsilon_i$。代入 $x_1$ 和 $x_2$ 的表达式，可简化为 $y_i = r_i + \\varepsilon_i$。\n\n使用特定的 `seed` 来确保随机数生成器的可复现性。\n\n**2. 普通最小二乘 (OLS) 回归**\n\n所有模型都使用 OLS 进行拟合。对于一个包含从 $X$ 中选出的预测变量集的模型，我们通过在前面附加一列全为 1 的截距项来形成一个增广设计矩阵 $\\tilde{X}$。系数向量 $\\hat{\\beta}$ 通过最小化训练数据上的残差平方和 (RSS) 来估计：\n$$\n\\hat{\\beta} = \\arg\\min_{\\beta} \\| y_{\\text{train}} - \\tilde{X}_{\\text{train}} \\beta \\|_2^2\n$$\n这是通过一个标准的数值最小二乘程序来求解的，等同于使用 Moore-Penrose 伪逆。一旦求得 $\\hat{\\beta}$，对任何设计矩阵 $\\tilde{Z}$ 的预测值由 $\\hat{y} = \\tilde{Z}\\hat{\\beta}$ 给出。训练 RSS 为 $\\mathrm{RSS}_{\\text{train}} = \\| y_{\\text{train}} - \\tilde{X}_{\\text{train}}\\hat{\\beta} \\|_2^2$。验证均方误差为 $\\mathrm{MSE}_{\\text{val}} = \\frac{1}{m} \\| y_{\\text{val}} - \\tilde{X}_{\\text{val}}\\hat{\\beta} \\|_2^2$，其中 $m = n_{\\text{val}}$。\n\n**3. 布尔值 $b_1$ 的计算**\n\n$b_1$ 的值通过分析沿前向逐步路径的模型的性能来确定。这涉及两个阶段。\n\n**3.1. 前向逐步路径的构建**\n从仅含截距项的模型 $\\mathcal{M}_0$ 开始，我们通过逐步添加预测变量来构建一系列模型 $\\mathcal{M}_1, \\mathcal{M}_2$。\n- **第 1 步：** 我们比较两个模型：$\\mathcal{M}_{\\{1\\}}$（含截距项和 $x_1$）和 $\\mathcal{M}_{\\{2\\}}$（含截距项和 $x_2$）。每个模型都在训练数据上进行拟合。将导致较低 $\\mathrm{RSS}_{\\text{train}}$ 的预测变量添加到模型中。设这个预测变量为 $j_1$。第 1 步的模型是 $\\mathcal{M}_1 = \\mathcal{M}_{\\{j_1\\}}$。\n- **第 2 步：** 将剩余的预测变量 $j_2$ 添加进来，形成模型 $\\mathcal{M}_2 = \\mathcal{M}_{\\{j_1, j_2\\}}$，该模型包含截距项以及 $x_1$ 和 $x_2$ 两个变量。\n\n**3.2. $b_1$ 条件的评估**\n我们对来自前向路径的模型 $\\mathcal{M}_0$, $\\mathcal{M}_1$ 和 $\\mathcal{M}_2$ 在验证集上进行评估。\n- 令 $\\mathrm{MSE}_{\\text{val}}(0)$ 为仅含截距项模型 $\\mathcal{M}_0$ 的验证 MSE。\n- 令 $\\mathrm{MSE}_{\\text{val}}(1)$ 为大小为 1 的模型 $\\mathcal{M}_1$ 的验证 MSE。\n- 令 $\\mathrm{MSE}_{\\text{val}}(2)$ 为大小为 2 的模型 $\\mathcal{M}_2$ 的验证 MSE。\n\n当且仅当以下所有三个条件都成立时，布尔值 $b_1$ 为真：\n1. 第 2 步的前向路径包含两个变量。对于 $p=2$ 个预测变量，这显然是真的。\n2. 根据最小 $\\mathrm{MSE}_{\\text{val}}$ 判断，最优模型是大小为 2 的模型：$\\mathrm{MSE}_{\\text{val}}(2)  \\mathrm{MSE}_{\\text{val}}(1)$ 且 $\\mathrm{MSE}_{\\text{val}}(2)  \\mathrm{MSE}_{\\text{val}}(0)$。\n3. 大小为 1 的模型在验证集上的表现比仅含截距项的模型差：$\\mathrm{MSE}_{\\text{val}}(1) > \\mathrm{MSE}_{\\text{val}}(0)$。\n\n这些条件形式化了对抗性场景：添加“最优”的单个预测变量会增加验证误差，但同时添加两个预测变量才能得到最优模型。\n\n**4. 布尔值 $b_2$ 的计算**\n\n$b_2$ 的值通过应用一个使用验证 MSE 进行决策并包含早停的贪心前向选择过程来确定。\n- **第 0 步：** 当前模型是仅含截距项的模型 $\\mathcal{M}_0$。我们计算它的验证误差 $\\mathrm{MSE}_{\\text{val}}(0)$。\n- **第 1 步：** 我们评估两个候选模型：$\\mathcal{M}_{\\{1\\}}$（含 $x_1$）和 $\\mathcal{M}_{\\{2\\}}$（含 $x_2$）。我们计算它们的验证误差 $\\mathrm{MSE}_{\\text{val}}(\\{1\\})$ 和 $\\mathrm{MSE}_{\\text{val}}(\\{2\\})$。\n- **决策：** 算法检查是否有任何候选模型提供了严格的改进。如果 $\\min(\\mathrm{MSE}_{\\text{val}}(\\{1\\}), \\mathrm{MSE}_{\\text{val}}(\\{2\\}))  \\mathrm{MSE}_{\\text{val}}(0)$，则将最优的那个加入模型，并继续进行第 2 步。否则，算法停止，不添加任何预测变量。\n\n当且仅当贪心算法在第 1 步停止，没有添加任何变量时，$b_2$ 为真。这种情况发生在两个单预测变量模型都没有提供比仅含截距项模型更低的验证 MSE 时：\n$$\n\\mathrm{MSE}_{\\text{val}}(\\{1\\}) \\ge \\mathrm{MSE}_{\\text{val}}(0) \\quad \\text{and} \\quad \\mathrm{MSE}_{\\text{val}}(\\{2\\}) \\ge \\mathrm{MSE}_{\\text{val}}(0)\n$$\n此条件表明，基于验证的贪心搜索未能识别出有用的预测变量对。\n\n对于每个测试用例，我们执行这些流程并计算 $[b_1, b_2]$。最终输出汇总了这些结果。", "answer": "```python\nimport numpy as np\n\ndef fit_ols(X_train: np.ndarray, y_train: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Fits an Ordinary Least Squares model with an intercept.\n    \n    Args:\n        X_train: Predictor matrix (n_samples, n_features).\n        y_train: Response vector (n_samples,).\n        \n    Returns:\n        Coefficient vector beta_hat, including the intercept.\n    \"\"\"\n    X_aug = np.c_[np.ones(X_train.shape[0]), X_train]\n    beta, _, _, _ = np.linalg.lstsq(X_aug, y_train, rcond=None)\n    return beta\n\ndef predict(X: np.ndarray, beta: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Makes predictions using a fitted OLS model.\n    \n    Args:\n        X: Predictor matrix (n_samples, n_features).\n        beta: Coefficient vector, including the intercept.\n        \n    Returns:\n        Predicted response vector (n_samples,).\n    \"\"\"\n    X_aug = np.c_[np.ones(X.shape[0]), X]\n    return X_aug @ beta\n\ndef calculate_mse(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n    \"\"\"Calculates Mean Squared Error.\"\"\"\n    return np.mean((y_true - y_pred)**2)\n\ndef calculate_rss(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n    \"\"\"Calculates Residual Sum of Squares.\"\"\"\n    return np.sum((y_true - y_pred)**2)\n\ndef solve_case(n_train, n_val, s, sigma, seed):\n    \"\"\"\n    Solves a single test case for the model selection problem.\n    \"\"\"\n    # 1. Data Generation\n    rng = np.random.default_rng(seed)\n\n    # Training data\n    x1_train = rng.normal(loc=0.0, scale=1.0, size=n_train)\n    r_train = rng.normal(loc=0.0, scale=s, size=n_train)\n    x2_train = -x1_train + r_train\n    eps_train = rng.normal(loc=0.0, scale=sigma, size=n_train)\n    y_train = r_train + eps_train\n    X_train = np.stack([x1_train, x2_train], axis=1)\n\n    # Validation data\n    x1_val = rng.normal(loc=0.0, scale=1.0, size=n_val)\n    r_val = rng.normal(loc=0.0, scale=s, size=n_val)\n    x2_val = -x1_val + r_val\n    eps_val = rng.normal(loc=0.0, scale=sigma, size=n_val)\n    y_val = r_val + eps_val\n    X_val = np.stack([x1_val, x2_val], axis=1)\n\n    # Empty matrix for intercept-only model\n    X_empty_train = np.empty((n_train, 0))\n    X_empty_val = np.empty((n_val, 0))\n\n    # --- Computation for b1 ---\n    \n    # 2.1. Forward stepwise path on training data (minimizing RSS)\n    # Step 1: Find which variable to add first\n    beta1 = fit_ols(X_train[:, [0]], y_train)\n    y_pred_train1 = predict(X_train[:, [0]], beta1)\n    rss1 = calculate_rss(y_train, y_pred_train1)\n\n    beta2 = fit_ols(X_train[:, [1]], y_train)\n    y_pred_train2 = predict(X_train[:, [1]], beta2)\n    rss2 = calculate_rss(y_train, y_pred_train2)\n    \n    forward_path = [0, 1] if rss1 = rss2 else [1, 0]\n\n    # 2.2. Best subset along the forward path (evaluating with validation MSE)\n    # Model k=0 (intercept-only)\n    beta_k0 = fit_ols(X_empty_train, y_train)\n    y_pred_val_k0 = predict(X_empty_val, beta_k0)\n    mse_k0 = calculate_mse(y_val, y_pred_val_k0)\n    \n    # Model k=1 (from forward path)\n    var_k1 = forward_path[0]\n    beta_k1 = fit_ols(X_train[:, [var_k1]], y_train)\n    y_pred_val_k1 = predict(X_val[:, [var_k1]], beta_k1)\n    mse_k1 = calculate_mse(y_val, y_pred_val_k1)\n\n    # Model k=2 (both variables)\n    beta_k2 = fit_ols(X_train, y_train)\n    y_pred_val_k2 = predict(X_val, beta_k2)\n    mse_k2 = calculate_mse(y_val, y_pred_val_k2)\n    \n    # 2.3. Evaluate b1 conditions\n    # Cond 1: Path has both vars (always true for p=2)\n    # Cond 2: Size-2 model is best\n    cond2_best_is_k2 = mse_k2  mse_k1 and mse_k2  mse_k0\n    # Cond 3: Size-1 model is worse than size-0\n    cond3_k1_worse_than_k0 = mse_k1 > mse_k0\n    b1 = cond2_best_is_k2 and cond3_k1_worse_than_k0\n\n    # --- Computation for b2 ---\n\n    # 3.1. Greedy validation-based forward selection with early stopping\n    # Step 1: Check if adding any single variable improves on k=0 model\n    # We need validation MSE for both size-1 models\n    beta_v1 = fit_ols(X_train[:, [0]], y_train)\n    y_pred_val_v1 = predict(X_val[:, [0]], beta_v1)\n    mse_v1 = calculate_mse(y_val, y_pred_val_v1)\n    \n    beta_v2 = fit_ols(X_train[:, [1]], y_train)\n    y_pred_val_v2 = predict(X_val[:, [1]], beta_v2)\n    mse_v2 = calculate_mse(y_val, y_pred_val_v2)\n    \n    # 3.2. Evaluate b2 condition\n    # Greedy search stops if neither variable offers a strict improvement\n    b2 = mse_v1 >= mse_k0 and mse_v2 >= mse_k0\n\n    return [b1, b2]\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        (60, 2000, 0.05, 0.02, 0),    # Case A\n        (60, 2000, 0.5, 0.02, 1),     # Case B\n        (30, 5000, 0.005, 0.005, 2), # Case C\n    ]\n\n    results = []\n    for case in test_cases:\n        n_train, n_val, s, sigma, seed = case\n        result = solve_case(n_train, n_val, s, sigma, seed)\n        results.append(result)\n\n    # Format the final list of lists into the required string representation\n    formatted_results = [f\"[{str(b1)},{str(b2)}]\" for b1, b2 in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3105020"}]}