{"hands_on_practices": [{"introduction": "学术界广泛使用赤池信息准则（Akaike Information Criterion, $AIC$）作为模型选择的基石，因为它在拟合优度和模型复杂度之间提供了优雅的平衡。然而，$AIC$ 的理论推导基于大样本假设，当样本量较小时，它可能会倾向于选择过于复杂的模型。本练习将引导你探索其小样本修正版 $AIC_c$，通过编程实现一个场景，量化并展示何时这种修正变得至关重要，从而揭示了在实践中审慎选择和应用信息准则的必要性。", "problem": "考虑在高斯误差的线性回归中，两个嵌套参数模型之间的模型选择问题，该问题基于最大似然估计 (MLE) 和 Kullback–Leibler 散度。赤池信息准则 (Akaike Information Criterion, AIC) 和修正的赤池信息准则 (Corrected Akaike Information Criterion, AICc) 均在最小化预期信息损失的目标下由 MLE 推导得出。修正版本引入了一个显式的小样本调整项，该调整项取决于样本大小和模型维度。您的任务是构建一个完整的程序，构造一个场景，在该场景中小样本情况下修正准则优于未修正准则，并量化修正项何时会实质性地改变所选模型。\n\n从高斯线性模型（具有未知方差）的最大化对数似然取决于残差平方和这一基本基础出发，假定每个测试案例的设置如下：\n- 两个候选模型 $\\mathcal{M}_1$ 和 $\\mathcal{M}_2$，其参数数量分别为 $k_1$ 和 $k_2$，包括所有估计的参数（截距、回归系数和误差方差），并具有共同的样本大小 $n$。\n- $\\mathcal{M}_1$ 和 $\\mathcal{M}_2$ 的残差平方和分别由 $RSS_1$ 和 $RSS_2$ 给出。\n- 较小的准则值选择对应的模型。\n\n“实质性改变”的定义如下：如果 AIC 会选择 $\\mathcal{M}_2$ 而 AICc 会选择 $\\mathcal{M}_1$，或者反之，则修正项实质性地改变了所选模型。此外，通过计算使两个修正准则相等的最小整数 $n^\\star$ 来量化样本大小阈值，计算时保持观测到的最大化对数似然和参数数量固定，仅在修正项中改变 $n$。如果不存在有限解，则返回一个大的哨兵整数。\n\n实现一个程序，为每个测试案例计算：\n- 在 AIC 下选择的模型，以整数表示（$\\mathcal{M}_1$ 为 $1$，$\\mathcal{M}_2$ 为 $2$）。\n- 在 AICc 下选择的模型，以整数表示（$\\mathcal{M}_1$ 为 $1$，$\\mathcal{M}_2$ 为 $2$）。\n- 一个整数标志，指示修正项是否实质性地改变了所选模型（如果 AIC 和 AICc 选择的模型不同，则为 $1$，否则为 $0$）。\n- 最小整数 $n^\\star$，使得在保持拟合的最大化对数似然和参数数量固定的情况下，修正后的准则相等。如果相等发生在非整数 $n$ 处，则取大于该值的最小整数。如果由于退化而没有有限解，则返回一个大的哨兵整数（使用 $10^9$）。\n\n使用以下参数值测试套件，每个测试案例指定为元组 $(n, k_1, k_2, RSS_1, RSS_2)$：\n- 测试 $1$：$(12, 3, 4, 10.0, 8.0)$，一个复杂模型拟合度有适度改善的小样本案例。\n- 测试 $2$：$(100, 3, 4, 80.0, 78.0)$，一个修正项很小的大样本案例。\n- 测试 $3$：$(20, 3, 6, 10.0, 7.0)$，一个模型维度差异较大的中小样本案例。\n- 测试 $4$：$(200, 3, 6, 160.0, 152.0)$，一个模型维度差异较大但修正影响极小的大样本案例。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。每个测试案例的结果本身必须是包含四个整数的列表，顺序为 $[aic\\_selected, aicc\\_selected, changed\\_flag, n^\\star]$。例如，总输出格式为 $[[r_{11}, r_{12}, r_{13}, r_{14}], [r_{21}, r_{22}, r_{23}, r_{24}], [r_{31}, r_{32}, r_{33}, r_{34}], [r_{41}, r_{42}, r_{43}, r_{44}]]$.", "solution": "该问题要求使用赤池信息准则 (AIC) 及其小样本修正版——修正的赤池信息准则 (AICc) 来分析两个线性回归模型之间的模型选择。我们必须计算每个准则选择哪个模型，确定选择是否不同，并计算一个临界样本大小 $n^\\star$，在该样本大小下，假定其他估计量保持固定，两个 AICc 值将相等。\n\nAIC 和 AICc 的理论基础都源于信息论。它们旨在估计拟合模型与未知真实数据生成过程之间的预期相对 Kullback-Leibler 散度。较低的准则值表示模型预期损失的信息较少，从而在拟合优度和模型复杂性之间提供了更好的平衡。\n\n对于一个具有 $k$ 个估计参数的参数化统计模型，AIC 的一般形式为：\n$$\nAIC = -2 \\hat{\\mathcal{L}} + 2k\n$$\n其中 $\\hat{\\mathcal{L}}$ 是模型对数似然函数的最大化值。\n\n在线性回归模型与正态分布误差的特定情境下，参数是回归系数（包括截距）和误差方差 $\\sigma^2$。如果一个模型有 $p$ 个预测变量，则有 $p+1$ 个回归系数需要估计。方差 $\\sigma^2$ 也需要估计。因此，估计参数的总数为 $k = p+2$。问题陈述提供了 $\\mathcal{M}_1$ 和 $\\mathcal{M}_2$ 模型的总参数数量分别为 $k_1$ 和 $k_2$。\n\n对于一个样本大小为 $n$ 且残差平方和 (RSS) 已知的高斯线性模型，其最大化对数似然为：\n$$\n\\hat{\\mathcal{L}} = -\\frac{n}{2} \\left( \\log(2\\pi) + \\log\\left(\\frac{RSS}{n}\\right) + 1 \\right)\n$$\n将此代入 AIC 公式，得到：\n$$\nAIC = n \\left( \\log(2\\pi) + \\log\\left(\\frac{RSS}{n}\\right) + 1 \\right) + 2k\n$$\n当基于相同大小为 $n$ 的数据集比较两个模型 $\\mathcal{M}_1$ 和 $\\mathcal{M}_2$ 时，项 $n(\\log(2\\pi) + 1)$ 是一个公共的加性常数，可以在不影响选择的情况下忽略。此外，项 $-n\\log(n)$ 对两者来说也是共同的。因此，为了比较，可以使用一个简化的等价形式：\n$$\nAIC' = n\\log(RSS) + 2k\n$$\n我们将使用此简化形式来确定 AIC 选择的模型。$AIC'$ 值较低的模型更优。\n\n修正的赤池信息准则 (AICc) 调整了惩罚项，以考虑小样本量的情况，在小样本下 AIC 倾向于偏爱过于复杂的模型。其公式为：\n$$\nAICc = AIC + \\frac{2k(k+1)}{n - k - 1}\n$$\n当 $n$ 相对于 $k$ 较小时，此修正项显著，但随着 $n \\to \\infty$ 而收敛于 $0$。分母要求 $n - k - 1 > 0$，即 $n > k+1$，这是模型可识别且 AICc 有定义的必要条件。对于每个测试案例，我们计算 $AICc_1$ 和 $AICc_2$ 并选择值较小的模型。\n\n对于每个测试案例 $(n, k_1, k_2, RSS_1, RSS_2)$，分析过程如下：\n\n$1$. **基于 AIC 的模型选择**：我们计算 $AIC'_1 = n\\log(RSS_1) + 2k_1$ 和 $AIC'_2 = n\\log(RSS_2) + 2k_2$。如果 $AIC'_1  AIC'_2$，我们选择模型 $\\mathcal{M}_1$；否则，我们选择模型 $\\mathcal{M}_2$。这决定了 `aic_selected`。\n\n$2$. **基于 AICc 的模型选择**：我们计算完整的 $AIC_1$ 和 $AIC_2$ 值（或简化的 $AIC'_1$ 和 $AIC'_2$）及其各自的修正项。\n$$\nAICc_1 = AIC'_1 + \\frac{2k_1(k_1+1)}{n - k_1 - 1}\n$$\n$$\nAICc_2 = AIC'_2 + \\frac{2k_2(k_2+1)}{n - k_2 - 1}\n$$\n选择 $AICc$ 值较低的模型。这决定了 `aicc_selected`。\n\n$3$. **实质性改变标志**：如果 `aic_selected` $\\ne$ `aicc_selected`，则 `changed_flag` 设置为 $1$，否则为 $0$。\n\n$4$. **临界样本大小 $n^\\star$**：我们被要求找到最小的整数 $n^\\star$，使得两个修正准则相等，前提是最大化对数似然（因此 $AIC'$ 值）固定在其观测值上，而只允许 $n$ 在修正项中变化。设观测值为 $AIC'_{1,obs}$ 和 $AIC'_{2,obs}$。我们必须在以下方程中求解 $n$：\n$$\nAIC'_{1,obs} + \\frac{2k_1(k_1+1)}{n - k_1 - 1} = AIC'_{2,obs} + \\frac{2k_2(k_2+1)}{n - k_2 - 1}\n$$\n令 $\\Delta AIC'_{obs} = AIC'_{1,obs} - AIC'_{2,obs}$，$P_1 = 2k_1(k_1+1)$，以及 $P_2 = 2k_2(k_2+1)$。方程为：\n$$\n\\Delta AIC'_{obs} = \\frac{P_2}{n - k_2 - 1} - \\frac{P_1}{n - k_1 - 1}\n$$\n整理后可得一个关于 $n$ 的二次方程，形式为 $an^2 + bn + c = 0$，其中：\n- $a = \\Delta AIC'_{obs}$\n- $b = -\\Delta AIC'_{obs}(k_1+k_2+2) - (P_2-P_1)$\n- $c = \\Delta AIC'_{obs}(k_1+1)(k_2+1) + P_2(k_1+1) - P_1(k_2+1)$\n\n可以使用二次公式求解该方程以得到 $n$。我们寻求满足条件 $n > \\max(k_1, k_2) + 1$ 的最小实数根 $n$。最终值 $n^\\star$ 是大于或等于此根的最小整数（即 $\\lceil n \\rceil$）。如果不存在这样的有限、有效的根（例如，由于判别式非正，或根不满足条件，或准则对所有 $n$ 都相等的退化情况），则返回一个哨兵值 $10^9$。如果 $k_1=k_2$ 且 $RSS_1=RSS_2$，则会出现退化情况，这使得 $\\Delta AIC'_{obs}=0$ 和 $P_1=P_2$，方程简化为 $0=0$。\n\n现在将通过对每个提供的测试案例应用这四步流程来进行实现。", "answer": "```python\nimport numpy as np\nimport math\n\ndef solve():\n    \"\"\"\n    Solves the model selection problem for the test cases provided.\n    \"\"\"\n    \n    test_cases = [\n        # (n, k1, k2, RSS1, RSS2)\n        (12, 3, 4, 10.0, 8.0),\n        (100, 3, 4, 80.0, 78.0),\n        (20, 3, 6, 10.0, 7.0),\n        (200, 3, 6, 160.0, 152.0),\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        n, k1, k2, rss1, rss2 = case\n\n        # Step 1: Compute AIC and select model\n        # The comparative AIC can be simplified to n*log(RSS) + 2k, as other terms cancel out.\n        aic1_obs = n * np.log(rss1) + 2 * k1\n        aic2_obs = n * np.log(rss2) + 2 * k2\n        aic_selected = 1 if aic1_obs  aic2_obs else 2\n\n        # Step 2: Compute AICc and select model\n        # Check for valid denominators for AICc correction term\n        if n - k1 - 1 = 0 or n - k2 - 1 = 0:\n            # This case should not happen with the given test data, but is a necessary check.\n            # Set AICc to infinity to indicate it's not applicable.\n            aicc1 = float('inf')\n            aicc2 = float('inf')\n        else:\n            correction1 = (2 * k1 * (k1 + 1)) / (n - k1 - 1)\n            correction2 = (2 * k2 * (k2 + 1)) / (n - k2 - 1)\n            aicc1 = aic1_obs + correction1\n            aicc2 = aic2_obs + correction2\n\n        aicc_selected = 1 if aicc1  aicc2 else 2\n\n        # Step 3: Determine if the selection materially changed\n        changed_flag = 1 if aic_selected != aicc_selected else 0\n\n        # Step 4: Compute n_star\n        n_star = calculate_n_star(aic1_obs - aic2_obs, k1, k2)\n        \n        results.append([aic_selected, aicc_selected, changed_flag, int(n_star)])\n\n    # Format the final output as a string representation of a list of lists.\n    # e.g., [[r11, r12, r13, r14], [r21, r22, r23, r24]]\n    # This avoids numpy formatting and creates the exact required output string.\n    output_str = \"[\" + \", \".join(map(str, results)) + \"]\"\n    output_str = output_str.replace(\" \", \"\") # Remove spaces for exact match\n    print(output_str)\n\ndef calculate_n_star(delta_aic, k1, k2):\n    \"\"\"\n    Calculates the smallest integer n* where AICc1(n) = AICc2(n),\n    holding observed log-likelihoods constant.\n    \"\"\"\n    sentinel_value = 10**9\n    \n    # Check for degeneracy: if models are identical in parameters and fit,\n    # their AIC and AICc values will always be identical.\n    if k1 == k2 and abs(delta_aic)  1e-9:\n        return sentinel_value\n\n    p1 = 2 * k1 * (k1 + 1)\n    p2 = 2 * k2 * (k2 + 1)\n    \n    a = delta_aic\n    b = -delta_aic * (k1 + k2 + 2) - (p2 - p1)\n    c = delta_aic * (k1 + 1) * (k2 + 1) + p2 * (k1 + 1) - p1 * (k2 + 1)\n\n    min_n_valid = max(k1, k2) + 1\n\n    valid_roots = []\n\n    if abs(a)  1e-9: # Linear equation bn + c = 0\n        if abs(b) > 1e-9:\n            n_sol = -c / b\n            if n_sol > min_n_valid:\n                valid_roots.append(n_sol)\n    else: # Quadratic equation\n        discriminant = b**2 - 4 * a * c\n        if discriminant >= 0:\n            sqrt_d = np.sqrt(discriminant)\n            n1 = (-b + sqrt_d) / (2 * a)\n            n2 = (-b - sqrt_d) / (2 * a)\n            \n            if n1 > min_n_valid:\n                valid_roots.append(n1)\n            if n2 > min_n_valid:\n                valid_roots.append(n2)\n\n    if not valid_roots:\n        return sentinel_value\n    else:\n        # Return the ceiling of the smallest valid root\n        return math.ceil(min(valid_roots))\n\nsolve()\n\n```", "id": "3149493"}, {"introduction": "模型选择领域存在两种主要的思想流派：一种是基于惩罚似然的方法，如贝叶斯信息准则（Bayesian Information Criterion, $BIC$）；另一种是直接估计预测误差的重采样方法，如交叉验证（Cross-Validation）。本练习为你提供了一个在多项式回归这一经典场景中，从第一性原理出发实现并对比这两种方法的宝贵机会。通过亲手实践，你将深刻理解它们在选择最佳模型复杂度时的基本逻辑、计算成本和性能表现上的差异。", "problem": "您将研究特征工程与模型选择的相互作用，具体方法是通过交叉验证进行多项式特征次数选择，并将其与使用贝叶斯信息准则（BIC）的惩罚似然选择进行比较。您的工作将完全在一维回归设置中进行，并采用多项式特征工程。您的任务是从第一性原理出发，推导出必要的模型选择准则，并实现一个程序，将这两种准则应用于一组固定的测试实例，返回所选的多项式次数。\n\n从以下基础出发：\n- 在加性、独立、同分布高斯噪声的假设下，以回归为目标的监督学习。\n- 在高斯噪声下，普通最小二乘法作为条件均值函数的最大似然估计。\n- 通过数据分割和平均进行风险估计的思想，以及用于模型选择的惩罚似然概念。\n\n您不得使用任何预设目标公式的结论。相反，您需要从上述基础出发，推导出交叉验证风险估计和贝叶斯信息准则所需的所有公式。\n\n考虑以下数据生成过程。对于给定的整数多项式次数 $d_{\\mathrm{true}} \\in \\{0,1,2,\\dots\\}$，定义真实的回归函数\n$$\nf_{\\mathrm{true}}(x) \\;=\\; \\sum_{j=0}^{d_{\\mathrm{true}}} c_j\\, x^j,\n$$\n其系数由 $c_0=1$ 和对所有整数 $j \\ge 1$ 的 $c_j = (-1)^j/(j+1)$ 确定性地给出。数据由 $n$ 个独立抽样 $x_i \\sim \\mathrm{Uniform}(-1,1)$ 和 $y_i = f_{\\mathrm{true}}(x_i) + \\varepsilon_i$ 组成，其中 $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$ 是独立的，并且独立于 $x_i$。用于选择的回归模型类别是次数为 $d \\in \\{0,1,\\dots,d_{\\max}\\}$ 的多项式均值函数集，对多项式特征 $[1, x, x^2, \\dots, x^d]$ 进行标准线性回归拟合。\n\n您的任务：\n- 从高斯噪声假设和线性回归模型的最大似然出发，为以次数 $d$ 索引的模型推导出一个明确的、可实现的贝叶斯信息准则表达式。明确指定惩罚项中使用的参数数量。在残差平方和等于零的极端情况下，说明如何通过在应用对数之前将其替换为一个严格为正的常数 $10^{-12}$ 来进行正则化，以避免未定义的对数。\n- 为每个次数 $d$ 推导出一个可计算的 $K$-折交叉验证的均方预测误差估计值，从期望预测风险的概念出发，精确指定如何构建折以及如何对所有折计算平均值。使用确定性的 $K$-折划分，该划分通过将观测索引 $i \\in \\{0,1,\\dots,n-1\\}$ 分配到折 $\\left(i \\bmod K\\right)$ 来定义，不进行随机打乱。\n- 对两种选择方法，指定一个确定性的平局打破规则：如果多个次数达到了相同的最小准则值（在数值公差 $\\tau$ 范围内），则选择其中最小的次数。使用 $\\tau=10^{-12}$。\n\n实现要求：\n- 对于每个候选次数 $d$，使用 Moore–Penrose 伪逆通过普通最小二乘法拟合线性模型，以确保即使在设计矩阵是病态的情况下也能保持数值稳定性。次数为 $d$ 的设计矩阵应包含对应于 $x^0$ 的列作为截距项。\n- 在贝叶斯信息准则中使用自然对数。\n- 均方误差定义为评估集上残差平方的平均值。\n\n测试套件：\n在以下五个测试用例上评估您的实现，每个用例由元组 $(n, \\sigma, d_{\\mathrm{true}}, d_{\\max}, K, \\text{seed})$ 指定：\n- $T_1 = (100, 0.3, 3, 10, 5, 1234)$\n- $T_2 = (40, 0.1, 5, 8, 5, 202)$\n- $T_3 = (60, 1.0, 3, 10, 5, 999)$\n- $T_4 = (30, 0.3, 0, 6, 5, 77)$\n- $T_5 = (50, 0.5, 8, 8, 5, 555)$\n\n对于每个测试用例：\n- 使用给定的整数种子初始化伪随机数生成器，从 $[-1,1]$ 上的均匀分布中生成 $n$ 个独立输入 $x_i$。\n- 根据给定的 $\\sigma$ 和 $d_{\\mathrm{true}}$，按照所述的数据生成过程生成 $y_i$。\n- 对于 $d \\in \\{0,1,\\dots,d_{\\max}\\}$，计算：\n  - $K$-折交叉验证的均方误差估计值，并选择使其最小化的次数 $d_{\\mathrm{CV}}$（使用指定的平局打破规则）。\n  - 贝叶斯信息准则，并选择使其最小化的次数 $d_{\\mathrm{BIC}}$（使用指定的平局打破规则）。\n- 为该测试用例记录列表 $[d_{\\mathrm{CV}}, d_{\\mathrm{BIC}}, \\text{agree}]$，其中如果 $d_{\\mathrm{CV}}=d_{\\mathrm{BIC}}$，则 $\\text{agree}$ 为 $1$，否则为 $0$。\n\n最终输出格式：\n您的程序应生成单行输出，该输出是一个 Python 风格的列表字面量，包含五个按 $[T_1, T_2, T_3, T_4, T_5]$ 固定顺序排列的测试用例列表。输出必须只有一行，且仅包含此列表字面量。此问题不涉及物理单位，也不涉及角度或百分比。", "solution": "该问题提法明确，具有科学依据，并包含唯一解所需的所有必要信息。定义和约束清晰、一致，并且可以形式化为一个标准的统计模拟研究。因此，该问题被认为是**有效的**。\n\n目标是比较多项式回归的两种模型选择方法：$K$-折交叉验证（CV）和贝叶斯信息准则（BIC）。我们必须从基本原理出发推导出必要的公式，并实现它们以从候选集 $d \\in \\{0, 1, \\dots, d_{\\max}\\}$ 中选择最优的多项式次数 $d$。\n\n**1. 模型公式化与估计**\n\n我们考虑一个一维回归问题，其数据为 $(\\mathbf{x}, \\mathbf{y})$，其中 $\\mathbf{x} = (x_1, \\dots, x_n)^T$ 且 $\\mathbf{y} = (y_1, \\dots, y_n)^T$。次数为 $d$ 的多项式模型假定 $y_i = f_d(x_i) + \\varepsilon_i$，其中 $f_d(x) = \\sum_{j=0}^d \\beta_j x^j$，$\\varepsilon_i$ 是独立同分布（i.i.d.）的高斯噪声项，$\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$。\n\n这可以表示为矩阵形式 $\\mathbf{y} = X_d \\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}$，其中：\n-   $\\mathbf{y}$ 是观测值的 $n \\times 1$ 向量。\n-   $X_d$ 是 $n \\times (d+1)$ 的设计矩阵，其元素为 $(X_d)_{ij} = x_i^{j-1}$，其中 $i \\in \\{1, \\dots, n\\}$ 且 $j \\in \\{1, \\dots, d+1\\}$。第一列对应于截距项 $x_i^0=1$。\n-   $\\boldsymbol{\\beta}$ 是系数 $(\\beta_0, \\dots, \\beta_d)^T$ 的 $(d+1) \\times 1$ 向量。\n-   $\\boldsymbol{\\varepsilon}$ 是噪声项的 $n \\times 1$ 向量。\n\n在高斯噪声的假设下，$\\boldsymbol{\\beta}$ 的最大似然估计（MLE）是普通最小二乘（OLS）估计。为确保数值稳定性，我们使用设计矩阵的 Moore-Penrose 伪逆 $X_d^+$ 来计算：\n$$\n\\hat{\\boldsymbol{\\beta}}_d = X_d^+ \\mathbf{y}\n$$\n预测值则为 $\\hat{\\mathbf{y}}_d = X_d \\hat{\\boldsymbol{\\beta}}_d$。\n\n**2. 贝叶斯信息准则（BIC）的推导**\n\nBIC 是一种用于模型选择的惩罚似然准则。我们从指定模型下数据的似然函数推导它。\n\n在给定 $x_i$ 和模型参数 $(\\boldsymbol{\\beta}, \\sigma^2)$ 的情况下，单个观测值 $y_i$ 的概率密度函数是：\n$$\np(y_i | x_i, \\boldsymbol{\\beta}, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_i - \\mathbf{x}_{i,d}^T\\boldsymbol{\\beta})^2}{2\\sigma^2}\\right)\n$$\n其中 $\\mathbf{x}_{i,d}^T$ 是设计矩阵 $X_d$ 的第 $i$ 行。\n\n假设观测值是独立同分布的，整个数据集 $\\mathcal{D} = \\{ (x_i, y_i) \\}_{i=1}^n$ 的似然是各个概率的乘积：\n$$\nL(\\boldsymbol{\\beta}, \\sigma^2 | \\mathcal{D}) = \\prod_{i=1}^n p(y_i | x_i, \\boldsymbol{\\beta}, \\sigma^2)\n$$\n对数似然 $\\ell$ 是：\n$$\n\\ell(\\boldsymbol{\\beta}, \\sigma^2) = \\log L = \\sum_{i=1}^n \\left( -\\frac{1}{2}\\log(2\\pi\\sigma^2) - \\frac{(y_i - \\mathbf{x}_{i,d}^T\\boldsymbol{\\beta})^2}{2\\sigma^2} \\right)\n$$\n$$\n\\ell(\\boldsymbol{\\beta}, \\sigma^2) = -\\frac{n}{2}\\log(2\\pi) - \\frac{n}{2}\\log(\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\mathbf{x}_{i,d}^T\\boldsymbol{\\beta})^2\n$$\n为了找到最大化的对数似然，我们代入 $\\boldsymbol{\\beta}$ 和 $\\sigma^2$ 的最大似然估计。$\\boldsymbol{\\beta}$ 的 MLE 是 OLS 估计 $\\hat{\\boldsymbol{\\beta}}_d$。该拟合的误差平方和是残差平方和，$\\mathrm{RSS}_d = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2$。方差 $\\sigma^2$ 的 MLE 是通过将 $\\ell$ 对 $\\sigma^2$ 求导并令结果为零得到的，即 $\\hat{\\sigma}^2 = \\mathrm{RSS}_d / n$。\n\n将 $\\hat{\\boldsymbol{\\beta}}_d$ 和 $\\hat{\\sigma}^2$ 代入对数似然函数，得到最大化值 $\\ell_{\\max}$：\n$$\n\\ell_{\\max} = -\\frac{n}{2}\\log(2\\pi) - \\frac{n}{2}\\log\\left(\\frac{\\mathrm{RSS}_d}{n}\\right) - \\frac{\\mathrm{RSS}_d}{2(\\mathrm{RSS}_d/n)} = -\\frac{n}{2}\\left(\\log(2\\pi) + \\log\\left(\\frac{\\mathrm{RSS}_d}{n}\\right) + 1\\right)\n$$\nBIC 定义为 $\\mathrm{BIC} = k\\log n - 2\\ell_{\\max}$，其中 $k$ 是模型中估计的参数数量。对于一个次数为 $d$ 的多项式，我们估计 $d+1$ 个系数（$\\beta_0, \\dots, \\beta_d$）和一个方差参数（$\\sigma^2$），所以 $k = (d+1) + 1 = d+2$。\n$$\n\\mathrm{BIC}(d) = (d+2)\\log n - 2\\left(-\\frac{n}{2}\\left(\\log(2\\pi) + \\log\\left(\\frac{\\mathrm{RSS}_d}{n}\\right) + 1\\right)\\right)\n$$\n$$\n\\mathrm{BIC}(d) = (d+2)\\log n + n\\log(2\\pi) + n + n\\log\\left(\\frac{\\mathrm{RSS}_d}{n}\\right)\n$$\n在为同一数据集比较模型时，不依赖于模型复杂度 $d$ 的项（即 $n\\log(2\\pi)$ 和 $n$）可以省略。这样可以得到一个对于模型选择等价的比例量：\n$$\n\\mathrm{BIC}(d) \\propto n\\log\\left(\\frac{\\mathrm{RSS}_d}{n}\\right) + (d+2)\\log n\n$$\n我们将使用此形式。根据问题要求，必须使用自然对数。如果 $\\mathrm{RSS}_d = 0$，我们在应用对数之前将其替换为 $\\mathrm{RSS}_d = 10^{-12}$，以防止数学错误。\n\n**3. $K$-折交叉验证估计的推导**\n\n交叉验证提供了对期望预测误差（风险）的估计，其定义为 $R(\\hat{f}) = \\mathbb{E}_{(x,y)}[(y - \\hat{f}(x))^2]$，其中期望是针对真实数据生成分布计算的。\n\n$K$-折交叉验证通过将数据集 $\\mathcal{D}$ 划分为 $K$ 个大小大致相等的不相交的折 $\\mathcal{D}_1, \\dots, \\mathcal{D}_K$ 来近似这个期望。问题指定了一个确定性的划分规则：索引为 $i \\in \\{0, 1, \\dots, n-1\\}$ 的观测值被分配到折 $j = (i \\bmod K)$。\n\n对于每个折 $j \\in \\{0, \\dots, K-1\\}$，我们对给定的模型复杂度（次数 $d$）执行以下步骤：\n1.  定义训练集为 $\\mathcal{T}_j = \\mathcal{D} \\setminus \\mathcal{D}_j$，验证集为 $\\mathcal{V}_j = \\mathcal{D}_j$。\n2.  在训练数据 $\\mathcal{T}_j$ 上拟合次数为 $d$ 的多项式回归模型，以获得估计量 $\\hat{f}_d^{(-j)}$。\n3.  在留出的验证数据 $\\mathcal{V}_j$ 上计算均方误差（MSE）：\n    $$\n    \\mathrm{MSE}_j(d) = \\frac{1}{|\\mathcal{V}_j|} \\sum_{(x_i, y_i) \\in \\mathcal{V}_j} (y_i - \\hat{f}_d^{(-j)}(x_i))^2\n    $$\n    其中 $|\\mathcal{V}_j|$ 是折 $j$ 中的样本数量。\n\n次数为 $d$ 的风险的 $K$-折交叉验证估计是这 $K$ 个折的误差平均值：\n$$\n\\mathrm{CV}_K(d) = \\frac{1}{K} \\sum_{j=0}^{K-1} \\mathrm{MSE}_j(d)\n$$\n\n**4. 模型选择与平局打破**\n\n对于这两种方法，最优次数是通过在候选次数集 $\\{0, 1, \\dots, d_{\\max}\\}$ 上最小化各自的准则来选择的：\n$$\nd_{\\mathrm{BIC}} = \\arg\\min_{d} \\mathrm{BIC}(d) \\quad\\text{and}\\quad d_{\\mathrm{CV}} = \\arg\\min_{d} \\mathrm{CV}_K(d)\n$$\n问题指定了一个确定性的平局打破规则：如果多个次数产生的准则值在数值公差 $\\tau=10^{-12}$ 内达到最小值，则选择其中最小的次数。形式上，对于给定的分数函数 $S(d)$，我们找到 $S_{\\min} = \\min_d S(d)$。所选次数为 $d^* = \\min \\{d \\mid S(d) \\le S_{\\min} + \\tau \\}$。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and compares model selection for polynomial regression using\n    K-fold Cross-Validation and the Bayesian Information Criterion.\n    \"\"\"\n\n    # Helper function for selection with tie-breaking\n    def select_degree_with_tiebreak(scores, tau):\n        \"\"\"\n        Selects the best degree from a list of scores.\n        If multiple degrees are within tau of the minimum score,\n        the smallest degree is chosen.\n        \"\"\"\n        scores_arr = np.array(scores)\n        # Defensive check for cases where all models fail to fit.\n        if np.all(np.isinf(scores_arr)): \n            return 0\n        \n        min_score = np.nanmin(scores_arr)\n        # Find indices of scores close to the minimum. np.where returns sorted indices.\n        candidate_indices = np.where(scores_arr = min_score + tau)[0]\n        # Return the smallest degree among candidates.\n        return candidate_indices[0]\n\n    # Test cases as specified in the problem statement\n    test_cases = [\n        (100, 0.3, 3, 10, 5, 1234),\n        (40, 0.1, 5, 8, 5, 202),\n        (60, 1.0, 3, 10, 5, 999),\n        (30, 0.3, 0, 6, 5, 77),\n        (50, 0.5, 8, 8, 5, 555),\n    ]\n\n    # Constants from the problem statement\n    TOLERANCE = 1e-12\n    RSS_REGULARIZATION = 1e-12\n\n    all_results = []\n\n    for n, sigma, d_true, d_max, K, seed in test_cases:\n        # 1. Generate Data\n        rng = np.random.default_rng(seed)\n        x = rng.uniform(-1, 1, size=n)\n\n        # Generate true function values y_true = f_true(x)\n        coeffs_true = [1.0]\n        if d_true > 0:\n            coeffs_true.extend([(-1)**j / (j + 1) for j in range(1, d_true + 1)])\n        \n        X_true = np.vander(x, d_true + 1, increasing=True)\n        y_true = X_true @ np.array(coeffs_true)\n\n        # Add Gaussian noise\n        noise = rng.normal(0, sigma, size=n)\n        y = y_true + noise\n\n        bic_scores = []\n        cv_scores = []\n\n        # 2. Iterate through candidate polynomial degrees\n        for d in range(d_max + 1):\n            # Create the design matrix for degree d\n            X = np.vander(x, d + 1, increasing=True)\n            \n            # --- Bayesian Information Criterion (BIC) ---\n            beta_hat = np.linalg.pinv(X) @ y\n            y_hat = X @ beta_hat\n            \n            rss = np.sum((y - y_hat)**2)\n            \n            # Regularize if RSS is zero, as specified.\n            if rss == 0.0:\n                rss = RSS_REGULARIZATION\n\n            # Number of parameters k = (d+1) coefficients + 1 variance\n            k_params = d + 2\n            \n            # BIC formula: n*log(RSS/n) + k*log(n), using natural log\n            bic = n * np.log(rss / n) + k_params * np.log(n)\n            bic_scores.append(bic)\n\n            # --- K-Fold Cross-Validation ---\n            fold_errors = []\n            \n            # Deterministic fold assignment\n            fold_indices = np.arange(n) % K\n\n            for k_fold in range(K):\n                train_mask = (fold_indices != k_fold)\n                val_mask = (fold_indices == k_fold)\n\n                x_train, y_train = x[train_mask], y[train_mask]\n                x_val, y_val = x[val_mask], y[val_mask]\n\n                # If a training fold is too small to fit the model, its error is infinite.\n                if x_train.shape[0]  d + 1:\n                    fold_errors.append(np.inf)\n                    continue\n\n                X_train = np.vander(x_train, d + 1, increasing=True)\n                beta_hat_k = np.linalg.pinv(X_train) @ y_train\n                \n                X_val = np.vander(x_val, d + 1, increasing=True)\n                y_hat_val = X_val @ beta_hat_k\n                \n                # Mean Squared Error for the fold\n                mse_k = np.mean((y_val - y_hat_val)**2)\n                fold_errors.append(mse_k)\n            \n            cv_scores.append(np.mean(fold_errors))\n\n        # 3. Select best degree for each criterion using the tie-breaking rule\n        d_cv = select_degree_with_tiebreak(cv_scores, TOLERANCE)\n        d_bic = select_degree_with_tiebreak(bic_scores, TOLERANCE)\n\n        # 4. Record results for the test case\n        agree = 1 if d_cv == d_bic else 0\n        all_results.append([d_cv, d_bic, agree])\n\n    # 5. Print the final list of results in the required format\n    print(all_results)\n\n# Execute the main function\nsolve()\n```", "id": "3149417"}, {"introduction": "超越传统的频率派方法，我们进入贝叶斯模型选择的现代领域，其中模型的评估是基于其完整的后验预测分布。本练习将指导你实现两种先进的贝叶斯模型评估工具：广泛适用信息准则（Widely Applicable Information Criterion, WAIC）和留一交叉验证（Leave-One-Out Cross-Validation, LOO-CV）。更重要的是，你将通过改变模型系数的先验方差 $\\tau^2$ 来探索贝叶斯分析中的一个核心议题：模型选择结果对先验设定（即先验强度）的敏感性。", "problem": "您的任务是实现并分析贝叶斯模型选择对先验强度的敏感性，具体是在一个高斯线性回归模型中，比较广泛适用信息准则（WAIC）和留一交叉验证（LOO-CV）。教育背景设定为本科中级水平的统计学习，重点是模型选择方法。分析必须基于贝叶斯推断和预测性能评估的基本原则。\n\n考虑已知观测噪声方差的高斯线性回归模型。假设有 $n$ 个观测值，设计矩阵为 $X \\in \\mathbb{R}^{n \\times p}$，响应向量为 $y \\in \\mathbb{R}^n$。似然定义为\n$$\ny \\mid X, \\beta \\sim \\mathcal{N}\\left(X \\beta,\\ \\sigma^2 I_n\\right),\n$$\n其中 $\\beta \\in \\mathbb{R}^p$ 是回归系数，$\\sigma^2  0$ 是已知的噪声方差。对 $\\beta$ 设置一个零均值各向同性高斯先验：\n$$\n\\beta \\sim \\mathcal{N}\\left(0,\\ \\tau^2 I_p\\right),\n$$\n其中 $\\tau^2  0$ 是控制收缩强度的先验方差（较小的 $\\tau^2$ 表示更强的先验正则化）。您必须研究改变 $\\tau^2$ 如何影响以下两种贝叶斯模型选择准则：广泛适用信息准则（WAIC）和留一交叉验证（LOO-CV），其定义如下。\n\n- 广泛适用信息准则（WAIC）：通过聚合后验上的逐点预测密度来评估样本外预测拟合，并针对有效模型复杂度进行校正。您必须通过对后验进行蒙特卡洛积分来计算它。\n- 留一交叉验证（LOO-CV）：评估预测性能的方法是，对于每个观测值 $i$，将其排除，用剩余的 $n-1$ 个观测值重新计算后验，然后在后验抽样上聚合被排除观测值的对数预测密度。\n\n您的推导和实现必须基于以下基本原则：\n- 高斯线性模型中基于共轭先验的贝叶斯更新。\n- 期望对数预测密度的定义，即在后验上的积分。\n- 模型复杂度调整的含义，即在后验下对数似然的方差。\n\n数据构建必须是确定性的和纯数学的。对于给定的 $(n, p)$ 且 $p=3$，按如下方式构建 $X$ 和 $y$。对于 $i = 1, 2, \\ldots, n$，定义 $X$ 的第 $i$ 行为\n$$\nx_{i1} = \\frac{i}{n}, \\quad x_{i2} = \\left(\\frac{i}{n}\\right)^2, \\quad x_{i3} = \\sin(i),\n$$\n其中正弦函数的参数以弧度为单位。通过以下线性关系定义 $y$\n$$\ny_i = 1.5\\,x_{i1} - 2.0\\,x_{i2} + 0.5\\,x_{i3}.\n$$\n本问题中所有三角函数的角度必须以弧度解释。\n\n实现要求：\n- 使用具有固定后验抽样数 $S$ 的蒙特卡洛近似来计算 WAIC 和 LOO-CV。所有计算中设置 $S = 3000$ 个后验样本。\n- 使用单一固定的随机种子，以使结果完全可复现。\n- 对于 WAIC，计算似然在后验抽样上的逐点对数平均值，并减去对数似然的逐点后验方差。将这些值对所有观测值求和以获得一个标量分数，并选择使该分数最大化的先验方差 $\\tau^2$。\n- 对于 LOO-CV，对于每个观测值 $i$，排除 $(x_i, y_i)$ 后重新计算后验，计算 $y_i$ 在来自留一后验的后验抽样下的似然的对数平均值，将这些值对所有观测值求和以获得一个标量分数，并选择使该分数最大化的先验方差 $\\tau^2$。\n- 对于每个测试用例，返回在 WAIC 和 LOO-CV 下最优 $\\tau^2$ 的索引。索引必须是与给定 $\\tau^2$ 网格中位置对应的从零开始的整数。\n\n测试套件：\n评估以下四个测试用例。在所有情况下，使用 $p = 3$ 和上述指定的数据构建方法。\n1. 用例 A：$n = 20$，$\\sigma^2 = 1.0$，$\\tau^2$ 网格 $[0.1, 0.5, 1.0, 2.0, 10.0]$。\n2. 用例 B：$n = 20$，$\\sigma^2 = 0.25$，$\\tau^2$ 网格 $[0.01, 0.1, 0.5, 2.0, 100.0]$。\n3. 用例 C：$n = 20$，$\\sigma^2 = 4.0$，$\\tau^2$ 网格 $[0.01, 0.05, 0.1, 0.5, 2.0]$。\n4. 用例 D（边界样本量）：$n = 5$，$\\sigma^2 = 1.0$，$\\tau^2$ 网格 $[0.1, 1.0, 10.0]$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个逗号分隔的对偶列表，并用方括号括起来。每个对偶是 WAIC 和 LOO-CV 下最优 $\\tau^2$ 的从零开始的索引，分别对应于按上述顺序列出的一个测试用例。例如，一个包含四个用例的输出可能如下所示\n$$\n[[i_{A,\\mathrm{WAIC}}, i_{A,\\mathrm{LOO}}],[i_{B,\\mathrm{WAIC}}, i_{B,\\mathrm{LOO}}],[i_{C,\\mathrm{WAIC}}, i_{C,\\mathrm{LOO}}],[i_{D,\\mathrm{WAIC}}, i_{D,\\mathrm{LOO}}]],\n$$\n其中每个 $i$ 是一个整数。最终输出必须严格按照此格式打印为单行，不含空格。", "solution": "该问题要求在一个高斯线性回归设置中，分析贝叶斯模型选择准则对先验强度的敏感性。我们被要求比较广泛适用信息准则（WAIC）和留一交叉验证（LOO-CV）在从给定的值网格中选择最优先验方差 $\\tau^2$ 方面的表现。\n\n首先，我们建立贝叶斯分析的数学框架。模型由以下部分指定：\n1.  对于给定的设计矩阵 $X \\in \\mathbb{R}^{n \\times p}$ 和回归系数 $\\beta \\in \\mathbb{R}^p$，响应向量 $y \\in \\mathbb{R}^n$ 的高斯似然：\n    $$ y \\mid X, \\beta \\sim \\mathcal{N}(X \\beta, \\sigma^2 I_n) $$\n    噪声方差 $\\sigma^2$ 假定为已知。\n2.  对回归系数 $\\beta$ 的零均值各向同性高斯先验：\n    $$ \\beta \\sim \\mathcal{N}(0, \\tau^2 I_p) $$\n    超参数 $\\tau^2$ 控制先验正则化的强度，较小的值会强制系数更强地向零收缩。\n\n由于高斯先验与高斯似然的共轭性，$\\beta$ 的后验分布也是高斯分布，$p(\\beta \\mid y, X) \\sim \\mathcal{N}(\\mu_{post}, \\Sigma_{post})$。我们通过组合似然和先验密度函数的指数部分来推导后验参数。后验对数密度正比于：\n$$ -\\frac{1}{2\\sigma^2} (y - X\\beta)^T(y - X\\beta) - \\frac{1}{2\\tau^2} \\beta^T\\beta $$\n对 $\\beta$ 进行配方可以揭示后验精度矩阵（协方差的逆）为 $\\Sigma_{post}^{-1} = \\frac{1}{\\sigma^2} X^T X + \\frac{1}{\\tau^2} I_p$，后验均值为 $\\mu_{post} = \\frac{1}{\\sigma^2} \\Sigma_{post} X^T y$。因此，后验分布完全由以下参数刻画：\n$$ \\Sigma_{post} = \\left( \\frac{1}{\\sigma^2} X^T X + \\frac{1}{\\tau^2} I_p \\right)^{-1} $$\n$$ \\mu_{post} = \\frac{1}{\\sigma^2} \\Sigma_{post} X^T y $$\n\n为了评估模型选择准则，我们通过从后验分布 $\\mathcal{N}(\\mu_{post}, \\Sigma_{post})$ 中抽取 $S$ 个样本 $\\{\\beta^{(s)}\\}_{s=1}^S$ 来采用蒙特卡洛积分。\n\n**广泛适用信息准则 (WAIC)**\n\nWAIC 提供了样本外预测准确性的估计。问题定义了一个需要最大化的分数，即逐点对数预测密度的总和，并由一个模型复杂度的惩罚项进行校正。对于每个数据点 $i \\in \\{1, \\dots, n\\}$，我们计算：\n1.  逐点对数预测密度 $\\text{lppd}_i$，通过后验样本上似然的平均值的对数来近似：\n    $$ \\text{lppd}_i = \\log\\left(\\frac{1}{S} \\sum_{s=1}^S p(y_i \\mid \\beta^{(s)})\\right) $$\n    在数值上，这使用 log-sum-exp 技巧来保持稳定性：$\\text{lppd}_i = \\text{logsumexp}_{s}(\\log p(y_i \\mid \\beta^{(s)})) - \\log S$。\n2.  复杂度惩罚项 $p_{WAIC,i}$，通过后验样本上对数似然的样本方差来近似：\n    $$ p_{WAIC,i} \\approx \\text{Var}_{s}(\\log p(y_i \\mid \\beta^{(s)})) $$\n\n需要最大化的总 WAIC 分数是 $W = \\sum_{i=1}^n (\\text{lppd}_i - p_{WAIC,i})$。单个观测值 $y_i$ 的对数似然是 $\\log p(y_i \\mid \\beta) = -\\frac{1}{2}\\log(2\\pi\\sigma^2) - \\frac{(y_i - x_i^T\\beta)^2}{2\\sigma^2}$。\n\n**留一交叉验证 (LOO-CV)**\n\nLOO-CV 提供了一个更直接但计算上更密集的样本外预测性能估计。对于每个观测值 $i=1, \\dots, n$，我们执行以下步骤：\n1.  移除第 $i$ 个数据点 $(x_i, y_i)$ 以形成一个缩减的数据集 $(X_{-i}, y_{-i})$。\n2.  基于此缩减数据集重新计算后验分布。这产生一个留一后验 $p(\\beta \\mid y_{-i}, X_{-i}) \\sim \\mathcal{N}(\\mu_{post,-i}, \\Sigma_{post,-i})$。其参数计算如下：\n    $$ \\Sigma_{post, -i} = \\left( \\frac{1}{\\sigma^2} X_{-i}^T X_{-i} + \\frac{1}{\\tau^2} I_p \\right)^{-1} $$\n    $$ \\mu_{post, -i} = \\frac{1}{\\sigma^2} \\Sigma_{post, -i} X_{-i}^T y_{-i} $$\n3.  从该留一后验中抽取 $S$ 个样本 $\\{\\beta^{(-i,s)}\\}_{s=1}^S$。\n4.  计算被排除点 $y_i$ 的对数预测密度，并在这些样本上取平均：\n    $$ \\text{lpd}_{-i} = \\log\\left(\\frac{1}{S} \\sum_{s=1}^S p(y_i \\mid \\beta^{(-i,s)})\\right) $$\n\n需要最大化的总 LOO-CV 分数是这些单个对数预测密度的总和：$L = \\sum_{i=1}^n \\text{lpd}_{-i}$。\n\n**计算流程**\n\n对于每个测试用例，整体算法按以下步骤进行：\n1.  初始化空列表，用于存储给定网格中每个 $\\tau^2$ 值的 WAIC 和 LOO-CV 分数。\n2.  对于给定的 $n$，按规定构建数据矩阵 $X$ 和响应向量 $y$。注意，$y$ 的数据生成过程是确定性的（无噪声），这在模拟研究中是常见的设置，以提供已知的基准真相。\n3.  遍历网格中的每个 $\\tau^2$ 值：\n    a. 计算 WAIC 分数，首先计算完整后验，抽取 $S=3000$ 个样本，然后聚合逐点的 $\\text{lppd}_i$ 和 $p_{WAIC,i}$ 值。\n    b. 计算 LOO-CV 分数，通过从 $i=1$ 到 $n$ 进行迭代，每次在 $n-1$ 个数据点上重新计算后验，抽取 $S=3000$ 个新样本，并评估被排除的单个点的对数预测密度。将这些对数密度相加。\n4.  在计算完所有 $\\tau^2$ 值的分数后，找出 WAIC 和 LOO-CV 的最大分数的从零开始的索引。这两个索引构成该测试用例的结果。\n5.  将所有测试用例的索引对聚合到最终列表中，并格式化输出。固定的随机种子确保了蒙特卡洛抽样的可复现性。", "answer": "```python\nimport numpy as np\nfrom scipy.special import logsumexp\n\ndef solve():\n    \"\"\"\n    实现并分析贝叶斯模型选择对先验强度的敏感性，\n    比较高斯线性回归模型中的 WAIC 和 LOO-CV。\n    \"\"\"\n    S = 3000  # Number of Monte Carlo samples\n    P = 3     # Number of features\n    SEED = 42 # Fixed random seed for reproducibility\n\n    def compute_scores(n, p, sigma_sq, tau_sq, X, y, rng):\n        \"\"\"\n        Computes WAIC and LOO-CV scores for a given model configuration.\n        \"\"\"\n        # Common terms for log-likelihood calculations\n        log_lik_const = -0.5 * np.log(2 * np.pi * sigma_sq)\n        inv_2_sigma_sq = 1.0 / (2.0 * sigma_sq)\n\n        # ---------------- WAIC Calculation ----------------\n        \n        # Full posterior distribution\n        precision_post = (1.0 / sigma_sq) * (X.T @ X) + (1.0 / tau_sq) * np.identity(p)\n        cov_post = np.linalg.inv(precision_post)\n        mean_post = (1.0 / sigma_sq) * (cov_post @ X.T @ y)\n\n        # Draw samples from the full posterior\n        beta_samples = rng.multivariate_normal(mean_post, cov_post, size=S)\n\n        # Calculate pointwise log-likelihoods for all samples\n        # Shape: (n, S)\n        pred_means = X @ beta_samples.T\n        sq_errors = (y[:, np.newaxis] - pred_means)**2\n        log_liks = log_lik_const - sq_errors * inv_2_sigma_sq\n\n        # Compute lppd and p_waic for each data point\n        lppd = logsumexp(log_liks, axis=1) - np.log(S)\n        p_waic = np.var(log_liks, axis=1, ddof=1) # Using ddof=1 for sample variance estimate\n        \n        waic_score = np.sum(lppd - p_waic)\n\n        # ---------------- LOO-CV Calculation ----------------\n        \n        total_loo_score = 0.0\n        for i in range(n):\n            # Create leave-one-out dataset\n            X_loo = np.delete(X, i, axis=0)\n            y_loo = np.delete(y, i)\n            x_i, y_i = X[i], y[i]\n\n            # Recompute posterior for the LOO dataset\n            precision_post_loo = (1.0 / sigma_sq) * (X_loo.T @ X_loo) + (1.0 / tau_sq) * np.identity(p)\n            cov_post_loo = np.linalg.inv(precision_post_loo)\n            mean_post_loo = (1.0 / sigma_sq) * (cov_post_loo @ X_loo.T @ y_loo)\n\n            # Draw samples from the LOO posterior\n            beta_samples_loo = rng.multivariate_normal(mean_post_loo, cov_post_loo, size=S)\n            \n            # Compute predictive density for the held-out point\n            pred_means_i = x_i @ beta_samples_loo.T\n            sq_errors_i = (y_i - pred_means_i)**2\n            log_liks_i = log_lik_const - sq_errors_i * inv_2_sigma_sq\n            \n            lpd_i = logsumexp(log_liks_i) - np.log(S)\n            total_loo_score += lpd_i\n        \n        return waic_score, total_loo_score\n\n    test_cases = [\n        (20, 1.0, np.array([0.1, 0.5, 1.0, 2.0, 10.0])),\n        (20, 0.25, np.array([0.01, 0.1, 0.5, 2.0, 100.0])),\n        (20, 4.0, np.array([0.01, 0.05, 0.1, 0.5, 2.0])),\n        (5, 1.0, np.array([0.1, 1.0, 10.0]))\n    ]\n\n    all_results = []\n    rng = np.random.default_rng(seed=SEED)\n\n    for n, sigma_sq, tau_sq_grid in test_cases:\n        # Generate data deterministically based on n\n        X = np.zeros((n, P))\n        y = np.zeros(n)\n        for j in range(n):\n            i_math = j + 1.0\n            x_i1 = i_math / n\n            x_i2 = (i_math / n)**2\n            x_i3 = np.sin(i_math)\n            X[j, :] = [x_i1, x_i2, x_i3]\n            y[j] = 1.5 * x_i1 - 2.0 * x_i2 + 0.5 * x_i3\n\n        waic_scores = []\n        loo_scores = []\n        for tau_sq in tau_sq_grid:\n            waic, loo = compute_scores(n, P, sigma_sq, tau_sq, X, y, rng)\n            waic_scores.append(waic)\n            loo_scores.append(loo)\n        \n        best_waic_idx = np.argmax(waic_scores)\n        best_loo_idx = np.argmax(loo_scores)\n        \n        all_results.append([best_waic_idx, best_loo_idx])\n\n    formatted_results = [f\"[{r[0]},{r[1]}]\" for r in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\n\nsolve()\n```", "id": "3149441"}]}