{"hands_on_practices": [{"introduction": "本实践的核心是探索自助法聚合（Bagging）在回归问题中的一个主要优势：降低模型的方差。我们将使用高次多项式回归作为基学习器，这是一种本身非常灵活但容易过拟合（即具有高方差）的模型。通过该练习 [@problem_id:3101761]，你将亲手实现自助法聚合过程，并观察它是如何通过平均多个不稳定的模型来创建一个更稳定、泛化能力更强的集成预测器。同时，你还将计算袋外（OOB）误差，并验证它作为集成模型泛化误差的可靠估计，而无需依赖单独的测试集。", "problem": "给定一个监督回归问题，其中假设复杂度由基学习器使用的多项式特征的阶数控制。需要实现并分析自助汇聚法（bagging）以及其袋外（Out-of-Bag, OOB）误差估计。任务是编写一个程序，该程序从一个固定的数据生成过程构造一个合成数据集，在 bagging 方案中训练多项式回归模型，计算袋外均方误差，并将其与单个未经过 bagging 的模型和经过 bagging 的集成模型的测试均方误差进行比较，同时改变多项式的阶数和自助拟合的次数。\n\n基本基础和设置：\n- 设数据生成过程由确定性函数 $f(x) = \\sin(2\\pi x) + 0.5x$ 和加性噪声定义。对于任意 $x \\in [-1,1]$，响应为 $y = f(x) + \\varepsilon$，其中 $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^2)$ 且 $\\sigma = 0.3$。\n- 构建一个训练集 $\\mathcal{D}_{\\text{train}} = \\{(x_i, y_i)\\}_{i=1}^{n_{\\text{train}}}$，其中 $n_{\\text{train}} = 80$，每个 $x_i \\sim \\text{Uniform}([-1,1])$；以及一个测试集 $\\mathcal{D}_{\\text{test}} = \\{(x_j^{\\text{test}}, y_j^{\\text{test}})\\}_{j=1}^{n_{\\text{test}}}$，其中 $n_{\\text{test}} = 400$，每个 $x_j^{\\text{test}} \\sim \\text{Uniform}([-1,1])$。两者均为独立采样。使用固定的随机种子 $s_{\\text{data}} = 24680$ 生成训练输入和噪声，并使用独立的固定随机种子 $s_{\\text{test}} = 24681$ 生成测试输入和噪声。所有 $x$ 值都是没有物理单位的实数。\n- 对于一个指定的多项式阶数 $d \\in \\{0,1,2,\\dots\\}$，定义特征映射 $\\phi_d(x) = [1, x, x^2, \\dots, x^d]^\\top$。基学习器是一个多项式回归模型，它在其接收到的训练数据上最小化残差平方和。这就是普通最小二乘法（OLS）。\n\nBagging 和袋外估计：\n- 对于给定的自助拟合次数 $M \\in \\mathbb{N}$ 和阶数 $d$，通过从 $\\{1,\\dots,n_{\\text{train}}\\}$ 中有放回地采样索引，构建 $M$ 个大小为 $n_{\\text{train}}$ 的自助样本。对于每个自助样本 $b \\in \\{1,\\dots,M\\}$，仅使用该样本拟合一个阶数为 $d$ 的 OLS 多项式回归，得到预测器 $g_b(x)$。\n- 将经过 bagging 的预测器定义为算术平均值 $G_M(x) = \\frac{1}{M}\\sum_{b=1}^M g_b(x)$。\n- 对于袋外（OOB）误差估计，针对每个训练索引 $i \\in \\{1,\\dots,n_{\\text{train}}\\}$，仅从那些其自助样本不包含 $i$ 的模型 $b$ 中收集预测 $g_b(x_i)$。用 $\\mathcal{B}_i = \\{b \\in \\{1,\\dots,M\\} : i \\text{ is not in bootstrap sample } b\\}$ 表示 $i$ 的袋外模型集合。如果 $\\mathcal{B}_i$ 非空，则定义 OOB 预测为 $\\hat{y}_i^{\\text{OOB}} = \\frac{1}{|\\mathcal{B}_i|}\\sum_{b \\in \\mathcal{B}_i} g_b(x_i)$。OOB 均方误差是在所有至少有一个 OOB 预测的索引上计算的：\n$$\n\\mathrm{MSE}_{\\text{OOB}} = \\frac{1}{|\\mathcal{I}_{\\text{OOB}}|}\\sum_{i \\in \\mathcal{I}_{\\text{OOB}}} \\left(y_i - \\hat{y}_i^{\\text{OOB}}\\right)^2,\n$$\n其中 $\\mathcal{I}_{\\text{OOB}} = \\{i : |\\mathcal{B}_i| \\ge 1\\}$。\n\n对每个测试用例 $(d, M)$ 需要计算的评估指标：\n- 经过 bagging 的集成模型的 OOB 均方误差，$\\mathrm{MSE}_{\\text{OOB}}$。\n- 在完整训练集上拟合一次的单个阶数为 $d$ 的模型的测试均方误差，记为 $\\mathrm{MSE}_{\\text{single,test}}$。\n- 经过 bagging 的集成模型 $G_M$ 的测试均方误差，记为 $\\mathrm{MSE}_{\\text{bag,test}}$。\n\n随机性与可复现性要求：\n- 如上所述，使用固定的种子 $s_{\\text{data}} = 24680$ 和 $s_{\\text{test}} = 24681$ 生成训练集和测试集。\n- 对于每个测试用例 $(d,M)$，在创建 $M$ 个自助样本并拟合 $M$ 个基学习器之前，将自助采样的种子重新设置为 $s_{\\text{boot}} = 100000 + 1000\\cdot d + M$。这确保了每个用例都是可复现的，并且独立于其他用例。\n\n程序输出与数值格式：\n- 对于每个测试用例 $(d,M)$，计算三元组 $[\\mathrm{MSE}_{\\text{OOB}}, \\mathrm{MSE}_{\\text{single,test}}, \\mathrm{MSE}_{\\text{bag,test}}]$。\n- 在输出中将每个均方误差四舍五入到 $6$ 位小数。\n- 你的程序应生成单行输出，其中包含一个逗号分隔的列表，该列表用方括号括起来，每个元素是按指定顺序排列的、用方括号括起来的逗号分隔的三元组（例如，\"[[a,b,c],[d,e,f],...]\"）。\n\n测试套件：\n使用以下测试用例，它们必须按照所列的精确顺序进行评估并在输出中报告：\n1. $(d, M) = (0, 25)$\n2. $(d, M) = (1, 25)$\n3. $(d, M) = (5, 25)$\n4. $(d, M) = (9, 25)$\n5. $(d, M) = (9, 200)$\n6. $(d, M) = (12, 1)$\n\n科学真实性与解释：\n- 选择这些用例是为了检验低阶欠拟合（$d=0,1$）、中等阶数（$d=5$）和高阶过拟合（$d=9,12$），以及通过增加 $M$（在 $d=9$ 时比较 $M=25$ 和 $M=200$）来削减方差的效果。袋外误差提供了一种对 bagging 模型的泛化误差的内部估计，而无需使用测试集。\n\n最终输出格式：\n- 程序必须精确打印一行：一个单独的列表，其元素是按给定精确顺序排列的 6 个三元组。每个数值必须四舍五入到 6 位小数，并以十进制形式打印。", "solution": "该问题要求实现并评估用于多项式回归的自助汇聚法（bagging）。我们将通过比较袋外（OOB）误差估计与单个模型和 bagging 集成模型在不同模型复杂度（多项式阶数 $d$）和不同自助拟合次数（$M$）下的测试误差来分析其性能。\n\n### 数学公式与方法论\n\n**1. 数据生成过程**\n合成数据由以下模型生成：\n$$\ny = f(x) + \\varepsilon\n$$\n其中 $f(x) = \\sin(2\\pi x) + 0.5x$ 是真实的潜在函数，$\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$ 表示标准差为 $\\sigma = 0.3$ 的高斯噪声。输入变量 $x$ 从区间 $[-1, 1]$ 中均匀采样。我们生成一个大小为 $n_{\\text{train}} = 80$ 的训练集 $\\mathcal{D}_{\\text{train}}$ 和一个大小为 $n_{\\text{test}} = 400$ 的测试集 $\\mathcal{D}_{\\text{test}}$。通过使用指定的随机种子，使得生成过程可复现。\n\n**2. 基学习器：多项式回归**\n基学习器是一个阶数为 $d$ 的多项式回归模型。对于给定的输入 $x$，我们构造一个特征向量 $\\boldsymbol{\\phi}_d(x) = [1, x, x^2, \\dots, x^d]^\\top$。模型的预测是这些特征的线性组合：\n$$\n\\hat{y}(x) = \\boldsymbol{\\phi}_d(x)^\\top \\boldsymbol{\\beta}\n$$\n系数向量 $\\boldsymbol{\\beta} \\in \\mathbb{R}^{d+1}$ 通过普通最小二乘法（OLS）确定，该方法在给定的训练集 $\\{(x_i, y_i)\\}_{i=1}^n$ 上最小化残差平方和：\n$$\n\\hat{\\boldsymbol{\\beta}} = \\arg\\min_{\\boldsymbol{\\beta}} \\sum_{i=1}^{n} \\left(y_i - \\boldsymbol{\\phi}_d(x_i)^\\top \\boldsymbol{\\beta}\\right)^2\n$$\n这个优化问题的解通过正规方程 $\\hat{\\boldsymbol{\\beta}} = (\\mathbf{\\Phi}^\\top \\mathbf{\\Phi})^{-1} \\mathbf{\\Phi}^\\top \\mathbf{y}$ 得到，其中 $\\mathbf{\\Phi}$ 是设计矩阵，其行是 $\\boldsymbol{\\phi}_d(x_i)^\\top$。为了数值稳定性，这个线性系统使用诸如 QR 分解等方法求解，例如 `numpy.linalg.lstsq` 中实现的方法。\n\n**3. Bagging 与误差估计**\n问题的核心在于 bagging 算法及其相关的误差度量。\n\n- **单个模型误差 ($\\mathrm{MSE}_{\\text{single,test}}$)**：一个阶数为 $d$ 的单个多项式回归模型，记为 $g_{\\text{single}}(x)$，在整个训练集 $\\mathcal{D}_{\\text{train}}$ 上进行训练。其泛化性能通过在测试集上的均方误差来衡量：\n$$\n\\mathrm{MSE}_{\\text{single,test}} = \\frac{1}{n_{\\text{test}}} \\sum_{j=1}^{n_{\\text{test}}} \\left(y_j^{\\text{test}} - g_{\\text{single}}(x_j^{\\text{test}})\\right)^2\n$$\n\n- **Bagging 和 Bagging 模型误差 ($\\mathrm{MSE}_{\\text{bag,test}}$)**：Bagging 旨在减少不稳定学习器（如高阶多项式）的方差。其过程如下：\n    1.  对于 $b = 1, \\dots, M$，通过从 $\\mathcal{D}_{\\text{train}}$ 中有放回地抽取 $n_{\\text{train}}$ 个点来创建一个自助样本 $\\mathcal{D}_b$。\n    2.  在每个 $\\mathcal{D}_b$ 上训练一个基学习器 $g_b(x)$。\n    3.  最终的 bagging 预测器 $G_M(x)$ 是这些单个预测器的平均值：$G_M(x) = \\frac{1}{M}\\sum_{b=1}^M g_b(x)$。\nbagging 模型的泛化性能在测试集上评估：\n$$\n\\mathrm{MSE}_{\\text{bag,test}} = \\frac{1}{n_{\\text{test}}} \\sum_{j=1}^{n_{\\text{test}}} \\left(y_j^{\\text{test}} - G_M(x_j^{\\text{test}})\\right)^2\n$$\n\n- **袋外（OOB）误差 ($\\mathrm{MSE}_{\\text{OOB}}$)**：Bagging 的一个关键优势是能够在没有单独验证集的情况下估计泛化误差。对于每个训练点 $(x_i, y_i)$，其 OOB 预测是所有那些自助样本 $\\mathcal{D}_b$ 未包含 $(x_i, y_i)$ 的模型 $g_b$ 的预测平均值。设 $\\mathcal{B}_i$ 是这些模型的索引集。OOB 预测为：\n$$\n\\hat{y}_i^{\\text{OOB}} = \\frac{1}{|\\mathcal{B}_i|}\\sum_{b \\in \\mathcal{B}_i} g_b(x_i)\n$$\n这仅在 $\\mathcal{B}_i$ 非空时定义。然后，OOB 均方误差是在所有至少有一个 OOB 预测器的训练点上计算的：\n$$\n\\mathrm{MSE}_{\\text{OOB}} = \\frac{1}{|\\mathcal{I}_{\\text{OOB}}|}\\sum_{i \\in \\mathcal{I}_{\\text{OOB}}} \\left(y_i - \\hat{y}_i^{\\text{OOB}}\\right)^2\n$$\n其中 $\\mathcal{I}_{\\text{OOB}} = \\{i \\mid |\\mathcal{B}_i| \\ge 1\\}$。$\\mathrm{MSE}_{\\text{OOB}}$ 作为 $\\mathrm{MSE}_{\\text{bag,test}}$ 的一个估计。\n\n### 算法实现\n\n实现过程首先生成固定的训练和测试数据集。然后，对于提供的每个测试用例 $(d, M)$：\n1. 为了可复现性，将自助采样的随机种子设置为 $s_{\\text{boot}} = 100000 + 1000\\cdot d + M$。\n2. 在完整数据集上训练一个阶数为 $d$ 的单个多项式模型，以计算 $\\mathrm{MSE}_{\\text{single,test}}$。\n3. 执行 bagging 循环 $M$ 次。在每次迭代中，创建一个自助样本，训练一个模型，累加其在测试集上的预测，并累加其对其 OOB 训练点的预测。\n4. 循环结束后，使用累加的 OOB 预测和计数来计算 $\\mathrm{MSE}_{\\text{OOB}}$。将累加的测试集预测求平均，以形成最终的 bagging 预测并计算 $\\mathrm{MSE}_{\\text{bag,test}}$。\n5. 将得到的 MSE 值三元组进行四舍五入并存储。最终输出格式化为这些三元组的列表。\n\n对所有指定的测试用例重复此过程，这些用例旨在说明模型复杂度和集成规模对偏差、方差以及 bagging 有效性的影响。例如，比较 $(d=9, M=25)$ 和 $(d=9, M=200)$ 的结果将展示增加 $M$ 如何提高 bagging 集成的稳定性和准确性，而比较 $d=9$ 时的 $\\mathrm{MSE}_{\\text{single,test}}$ 和 $\\mathrm{MSE}_{\\text{bag,test}}$ 将凸显 bagging 对高方差模型的方差削减能力。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and evaluates bagging with OOB error estimation for polynomial regression.\n    \"\"\"\n    # Define constants from the problem statement\n    N_TRAIN = 80\n    N_TEST = 400\n    SIGMA = 0.3\n    S_DATA = 24680\n    S_TEST = 24681\n\n    # Define the true data generating function\n    def f(x):\n        return np.sin(2 * np.pi * x) + 0.5 * x\n\n    # Generate fixed training data for reproducibility\n    rng_data = np.random.default_rng(S_DATA)\n    x_train = rng_data.uniform(-1, 1, N_TRAIN)\n    y_train = f(x_train) + rng_data.normal(0, SIGMA, N_TRAIN)\n    \n    # Generate fixed test data for reproducibility\n    rng_test = np.random.default_rng(S_TEST)\n    x_test = rng_test.uniform(-1, 1, N_TEST)\n    y_test = f(x_test) + rng_test.normal(0, SIGMA, N_TEST)\n\n    # Helper function to create a polynomial feature matrix (design matrix)\n    def create_polynomial_features(x, degree):\n        # np.vander is a convenient way to generate powers of x.\n        # increasing=True makes the columns [x^0, x^1, ..., x^degree]\n        return np.vander(x, degree + 1, increasing=True)\n\n    # Test suite from the problem statement\n    test_cases = [\n        (0, 25),\n        (1, 25),\n        (5, 25),\n        (9, 25),\n        (9, 200),\n        (12, 1)\n    ]\n\n    all_results_str = []\n\n    # --- Pre-computation for efficiency ---\n    # Cache test design matrices and single model errors, as degrees can repeat.\n    X_test_dict = {}\n    for d, _ in test_cases:\n        if d not in X_test_dict:\n            X_test_dict[d] = create_polynomial_features(x_test, d)\n\n    single_model_mse_dict = {}\n    for d, _ in test_cases:\n        if d not in single_model_mse_dict:\n            X_train_full = create_polynomial_features(x_train, d)\n            # Use np.linalg.lstsq for a numerically stable OLS solution\n            beta_single, _, _, _ = np.linalg.lstsq(X_train_full, y_train, rcond=None)\n            y_pred_single = X_test_dict[d] @ beta_single\n            mse_single = np.mean((y_test - y_pred_single)**2)\n            single_model_mse_dict[d] = mse_single\n\n    # --- Main loop over test cases ---\n    for d, M in test_cases:\n        # Re-seed the bootstrap sampling for each case for reproducibility\n        s_boot = 100000 + 1000 * d + M\n        rng_boot = np.random.default_rng(s_boot)\n\n        # Get pre-computed values\n        X_test = X_test_dict[d]\n        mse_single_test = single_model_mse_dict[d]\n\n        # Prepare for bagging procedure\n        X_train = create_polynomial_features(x_train, d)\n        \n        oob_predictions_sum = np.zeros(N_TRAIN)\n        oob_counts = np.zeros(N_TRAIN, dtype=int)\n        bagged_test_predictions_sum = np.zeros(N_TEST)\n        train_indices = np.arange(N_TRAIN)\n\n        # Bagging loop: fit M models on bootstrap samples\n        for _ in range(M):\n            # Create a bootstrap sample of indices\n            bootstrap_indices = rng_boot.choice(train_indices, size=N_TRAIN, replace=True)\n            X_boot = X_train[bootstrap_indices]\n            y_boot = y_train[bootstrap_indices]\n\n            # Fit OLS model on the bootstrap sample\n            beta_b, _, _, _ = np.linalg.lstsq(X_boot, y_boot, rcond=None)\n\n            # Accumulate predictions on the test set for the bagged model\n            bagged_test_predictions_sum += X_test @ beta_b\n            \n            # Identify Out-of-Bag (OOB) indices for the current model\n            oob_indices = np.setdiff1d(train_indices, bootstrap_indices, assume_unique=False)\n            \n            # Accumulate predictions for OOB points\n            if oob_indices.size > 0:\n                X_oob = X_train[oob_indices]\n                y_pred_oob = X_oob @ beta_b\n                oob_predictions_sum[oob_indices] += y_pred_oob\n                oob_counts[oob_indices] += 1\n        \n        # --- Calculate and Store MSE Metrics ---\n        \n        # 1. MSE_OOB\n        # Identify indices with at least one OOB prediction (I_OOB)\n        I_oob = np.where(oob_counts > 0)[0]\n        if I_oob.size > 0:\n            y_oob_true = y_train[I_oob]\n            # Average the OOB predictions\n            y_oob_pred = oob_predictions_sum[I_oob] / oob_counts[I_oob]\n            mse_oob = np.mean((y_oob_true - y_oob_pred)**2)\n        else:\n            # This case is highly unlikely for M > 0 and should not occur here.\n            mse_oob = np.nan\n\n        # 2. MSE_single,test (already computed)\n\n        # 3. MSE_bag,test\n        # Average the predictions from all M models on the test set\n        y_pred_bagged = bagged_test_predictions_sum / M\n        mse_bag_test = np.mean((y_test - y_pred_bagged)**2)\n        \n        # Format the results for the current test case\n        result_triple = [mse_oob, mse_single_test, mse_bag_test]\n        # Round each value to 6 decimal places and format as a string\n        formatted_triple = [f\"{round(val, 6):.6f}\" for val in result_triple]\n        all_results_str.append(f\"[{','.join(formatted_triple)}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(all_results_str)}]\")\n\nsolve()\n```", "id": "3101761"}, {"introduction": "为了巩固自助法聚合是一种通用元算法的理解，本实践将该技术应用于一个完全不同的场景：使用 K-近邻（k-NN）进行分类。与参数化的多项式回归不同，k-NN 是一种非参数模型，其复杂度由邻域大小 $k$ 控制。通过这个练习 [@problem_id:3101765]，你将探索自助法聚合如何与 k-NN 这样的基学习器相互作用，并通过计算袋外（OOB）准确率来评估集成模型在不同复杂度（即不同 $k$ 值）下的性能。", "problem": "要求您实现一个完整的实验，以研究使用 $k$-近邻（$k$-NN）作为基学习器的自助聚合（Bagging）方法，并估计当邻域大小 $k$ 变化时袋外（OOB）准确率。设计必须从基本定义出发，并明确地构建所有必需的组件。\n\n基本定义：\n- 自助聚合（Bagging）通过从一个大小为 $N$ 的训练数据集中抽取 $B$ 个自助样本来构建一个集成。每个自助样本是通过从 $\\{0,1,\\dots,N-1\\}$ 中有放回地独立均匀抽样 $N$ 个索引而得到的，从而形成一个袋内集。对于一个自助样本，其袋外（OOB）集是袋内集在 $N$ 个训练索引中的补集。袋外（OOB）指的是未包含在特定自助样本中的观测值子集。OOB 准确率通过聚合仅由那些将每个观测值视为 OOB 的模型所做的预测来估计预测性能。\n- 对于一个查询点，$k$-近邻（$k$-NN）分类器会计算它到所有训练点的距离，选择 $k$ 个最小的距离，并预测这 $k$ 个邻居中占多数的类别。当这 $k$ 个邻居中的多数类别出现平局时，您必须通过预测类别 $0$ 来确定性地打破平局。\n- 对于 OOB 估计，集成预测的聚合必须通过对每个观测值在 $B$ 个自助模型中所有可用的 OOB 预测进行多数投票来完成。如果某个观测值的 OOB 多数投票出现平局，您必须通过预测类别 $0$ 来确定性地打破平局。在任何 $B$ 个模型中都没有 OOB 预测的观测值必须从 OOB 准确率的计算中排除。\n\n您的任务：\n- 在 $\\mathbb{R}^2$ 中生成一个包含 $N=200$ 个样本的合成二元分类数据集。其中恰好 $N/2=100$ 个样本属于类别 $0$，另外 $N/2=100$ 个样本属于类别 $1$。类别 $0$ 的特征从均值为 $\\mu_0=(-0.8,0.0)$、协方差矩阵为 $\\Sigma=0.6\\cdot I_2$ 的高斯分布中抽取；类别 $1$ 的特征从均值为 $\\mu_1=(0.8,0.0)$、协方差矩阵同为 $\\Sigma=0.6\\cdot I_2$ 的高斯分布中抽取，其中 $I_2$ 表示 $2\\times 2$ 的单位矩阵。使用固定的伪随机生成器种子 $s_{\\text{data}}=42$ 以确保确定性。\n- 构建一个包含 $B=60$ 个自助模型的 bagging 集成。对于每个自助模型，在袋内数据上（将重复项视为独立的训练点）训练一个 $k$-NN 分类器，并仅对 OOB 观测值产生预测。OOB 准确率是在至少有一个 OOB 预测的观测值中，被正确预测的标签所占的比例。\n- 在 $\\mathbb{R}^2$ 中实现欧几里得距离，并在基学习器层面和 OOB 聚合层面都使用上述的确定性平局打破规则进行多数投票。\n\n测试套件：\n- 对集成的 OOB 准确率在以下邻域大小 $k$ 上进行评估：$k\\in\\{1,2,5,15,60,200\\}$。这些情况包括一个典型的小邻域（$k=1$）、一个可能导致平局的偶数邻域（$k=2$）、中等大小的邻域（$k=5$ 和 $k=15$）、一个较大的邻域（$k=60$），以及等于自助样本大小的最大邻域（$k=200$）。在集成中的所有自助抽样过程中，使用固定的伪随机生成器种子 $s_{\\text{bag}}=123$ 以确保确定性。\n- 对于测试套件中的每个 $k$，计算其 OOB 准确率，结果为 $[0,1]$ 范围内的小数。\n\n科学真实性与推导基础：\n- 您的设计和推理应基于上述定义以及经过充分检验的预测模型偏差-方差分解原理：期望预测误差可以分解为来自不可约减的噪声、偏差的平方和方差的贡献。Bagging 旨在通过对训练集的不同自助实现进行平均来降低方差。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的每个 OOB 准确率都四舍五入到六位小数，并按照上面指定的 $k$ 值的相同顺序排列。例如：“[$a_1,$$a_2,$$a_3,$$a_4,$$a_5,$$a_6$]”，其中每个 $a_i$ 是对应 $k$ 计算出的 OOB 准确率。", "solution": "问题陈述已经过仔细审查，并被确定为有效。它具有科学依据、问题良定、客观，并包含推导出唯一、可验证解所需的所有必要信息和约束。该任务是计算统计学中一个标准的、定义明确的练习，要求实现以 $k$-近邻（$k$-NN）为基学习器的自助聚合（Bagging）元算法，并使用袋外（OOB）误差估计来评估其性能。\n\n根据要求，解决方案将从第一性原理出发进行开发。其核心原理是偏差-方差权衡。Bagging 是一种旨在降低模型预测误差中方差分量的集成方法，当应用于高方差、低偏差的基学习器（通常称为“不稳定”学习器）时最为有效。$k$-NN 算法的稳定性直接由邻域大小 $k$ 控制。一个小的 $k$（例如 $k=1$）会导致复杂的决策边界，从而产生低偏差但高方差。相反，一个大的 $k$ 会通过过度平滑决策边界来增加偏差，但会降低方差。本实验研究了随着 $k$ 的变化，bagging 带来的方差降低与 $k$-NN 学习器内在的偏差-方差特性之间的相互作用。\n\n该算法按以下结构化步骤进行：\n\n**1. 合成数据生成**\n生成一个在 $\\mathbb{R}^2$ 中包含 $N=200$ 个样本的数据集。该数据集是平衡的，类别 $0$ 和类别 $1$各有 $100$ 个样本。\n- 类别 $0$ 的特征从二元高斯分布 $\\mathcal{N}(\\mu_0, \\Sigma)$ 中抽取，其中均值为 $\\mu_0 = [-0.8, 0.0]^T$，协方差矩阵为 $\\Sigma = 0.6 \\cdot I_2$。\n- 类别 $1$ 的特征从 $\\mathcal{N}(\\mu_1, \\Sigma)$ 中抽取，其中均值为 $\\mu_1 = [0.8, 0.0]^T$，协方差矩阵同为 $\\Sigma = 0.6 \\cdot I_2$。$I_2$ 是 $2 \\times 2$ 的单位矩阵。\n通过使用 $s_{\\text{data}}=42$ 为伪随机数生成器设置种子，使此过程具有确定性。特征数据存储在矩阵 $X \\in \\mathbb{R}^{200 \\times 2}$ 中，相应的标签存储在向量 $y \\in \\{0, 1\\}^{200}$ 中。\n\n**2. Bagging 集成构建和 OOB 预测**\n实验的核心是为每个指定的 $k$ 值构建一个包含 $B=60$ 个模型的 bagging 集成。该过程对每个 $k \\in \\{1, 2, 5, 15, 60, 200\\}$ 重复进行，具体如下。使用以 $s_{\\text{bag}}=123$ 为种子的独立伪随机生成器进行所有自助抽样，以确保不同 $k$ 值的运行之间的可复现性。\n对于 $B=60$ 次迭代中的每一次：\n- **自助抽样**：通过从集合 $\\{0, 1, \\dots, 199\\}$ 中有放回地均匀抽取 $N=200$ 个索引来创建一个自助样本。这些索引构成了当前模型的“袋内”集。与这些索引对应的原始数据点构成了该模型的训练集。请注意，此训练集的大小为 $N=200$，并且通常包含重复实例。\n- **袋外（OOB）集识别**：当前模型的 OOB 集由原始数据集中所有未被选入袋内集的数据点组成。\n- **k-NN 模型训练和 OOB 预测**：在袋内数据上概念性地训练一个 $k$-NN 分类器。对 OOB 集中的每个数据点进行预测。对单个 OOB 查询点 $\\mathbf{x}_{\\text{query}}$ 的预测过程如下：\n    1.  计算查询点到袋内训练集中每个点 $\\mathbf{x}_j$ 的欧几里得距离 $d(\\mathbf{x}_{\\text{query}}, \\mathbf{x}_j)$。\n    2.  识别出训练集中与 $\\mathbf{x}_{\\text{query}}$ 距离最小的 $k$ 个点。这些就是 $k$ 个最近邻。\n    3.  统计这 $k$ 个邻居的标签中类别 $0$ 和类别 $1$ 出现的次数。设这些计数为 $c_0$ 和 $c_1$。\n    4.  预测的类别由多数票决定。根据指定的平局打破规则，如果 $c_1 > c_0$，则预测为 $1$。否则（如果 $c_0 > c_1$ 或 $c_0 = c_1$），预测为 $0$。\n- **存储 OOB 预测**：对于 $N=200$ 个原始数据点中的每一个，我们都为其 OOB 预测维护一个动态总计。具体来说，我们使用一个 $200 \\times 2$ 的矩阵来存储类别 $0$ 和类别 $1$ 的投票计数，并使用一个长度为 $200$ 的向量来统计每个点出现在 OOB 集中的次数。\n\n**3. OOB 准确率计算**\n在为给定的 $k$ 处理完所有 $B=60$ 个模型后，计算 OOB 准确率。\n- **预测聚合**：对于每个数据点 $i \\in \\{0, 1, \\dots, 199\\}$，我们首先检查它是否收到了至少一个 OOB 预测。如果没有，它将被排除在准确率计算之外。一个点在所有 $B=60$ 个模型中都处于袋内的概率是 $(1-(1-1/N)^N)^B \\approx (1-e^{-1})^{60}$，这个值小到可以忽略不计，因此我们预计所有点都会被包括在内。对于每个被包括的点，我们聚合其收集到的 OOB 预测。设类别 $0$ 的总票数为 $V_0$，类别 $1$ 的总票数为 $V_1$。\n- **最终 OOB 预测**：点 $i$ 的最终聚合预测，表示为 $\\hat{y}_i^{\\text{OOB}}$，由最终的多数票决定。根据问题的平局打破规则，如果 $V_1 > V_0$，则 $\\hat{y}_i^{\\text{OOB}} = 1$。否则（如果 $V_0 > V_1$ 或 $V_0 = V_1$），则 $\\hat{y}_i^{\\text{OOB}} = 0$。\n- **准确率计算**：OOB 准确率是在至少有一个 OOB 预测的点中，被正确分类的点的比例。设 $S_{\\text{OOB}}$ 是具有一个或多个 OOB 预测的点的索引集合。OOB 准确率为：\n$$\n\\text{Accuracy}_{\\text{OOB}} = \\frac{1}{|S_{\\text{OOB}}|} \\sum_{i \\in S_{\\text{OOB}}} \\mathbb{I}(\\hat{y}_i^{\\text{OOB}} = y_i)\n$$\n其中 $\\mathbb{I}(\\cdot)$ 是指示函数，当其参数为真时为 $1$，否则为 $0$。\n\n对测试套件中的每个 $k$ 值重复整个过程，并收集最终的 OOB 准确率。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Implements the complete experiment to study Bagging with k-NN, evaluating\n    Out-of-Bag (OOB) accuracy for varying neighborhood sizes k.\n    \"\"\"\n    \n    # --- Problem Parameters ---\n    N = 200  # Total number of samples\n    B = 60   # Number of bootstrap models in the ensemble\n    s_data = 42  # Seed for data generation\n    s_bag = 123  # Seed for bootstrap sampling\n    mu_0 = np.array([-0.8, 0.0])\n    mu_1 = np.array([0.8, 0.0])\n    cov = np.array([[0.6, 0.0], [0.0, 0.6]])\n    k_values = [1, 2, 5, 15, 60, 200]\n\n    # --- Step 1: Generate Synthetic Dataset ---\n    rng_data = np.random.default_rng(s_data)\n    \n    # Generate N/2 samples for each class\n    n_per_class = N // 2\n    X_0 = rng_data.multivariate_normal(mu_0, cov, size=n_per_class)\n    X_1 = rng_data.multivariate_normal(mu_1, cov, size=n_per_class)\n    \n    # Combine into a single dataset\n    X = np.vstack((X_0, X_1))\n    y = np.array([0] * n_per_class + [1] * n_per_class)\n\n    oob_accuracies = []\n\n    # --- Main Loop: Iterate over k values ---\n    for k in k_values:\n        \n        # --- Step 2: Bagging and OOB Prediction Collection ---\n        # oob_preds_counts[i, j] stores the number of times observation i\n        # was predicted as class j in an OOB context.\n        oob_preds_counts = np.zeros((N, 2), dtype=int)\n        # oob_sample_counts[i] stores the number of times observation i was OOB.\n        oob_sample_counts = np.zeros(N, dtype=int)\n\n        rng_bag = np.random.default_rng(s_bag)\n        \n        for _ in range(B):\n            # C.1: Bootstrap Sampling and OOB Identification\n            in_bag_indices = rng_bag.choice(N, size=N, replace=True)\n            oob_indices = np.setdiff1d(np.arange(N), np.unique(in_bag_indices), assume_unique=True)\n            \n            # C.2: Prepare training data for the current bootstrap model\n            X_train_b = X[in_bag_indices]\n            y_train_b = y[in_bag_indices]\n            \n            # C.3: Predict for OOB points\n            for i in oob_indices:\n                query_point = X[i:i+1] # Shape (1, 2)\n                \n                # k-NN prediction logic\n                distances = np.linalg.norm(X_train_b - query_point, axis=1)\n                \n                # Get labels of k nearest neighbors\n                neighbor_indices = np.argsort(distances)[:k]\n                neighbor_labels = y_train_b[neighbor_indices]\n                \n                # Majority vote with deterministic tie-breaking for k-NN\n                votes_for_1 = np.sum(neighbor_labels)\n                votes_for_0 = k - votes_for_1\n                \n                # Predict 1 if it has a strict majority, else 0\n                prediction = 1 if votes_for_1 > votes_for_0 else 0\n                \n                # Record OOB prediction vote\n                oob_preds_counts[i, prediction] += 1\n                oob_sample_counts[i] += 1\n\n        # --- Step 3: OOB Accuracy Calculation ---\n        n_oob_samples_total = 0\n        n_oob_correct = 0\n        \n        for i in range(N):\n            # Consider only samples that were OOB at least once\n            if oob_sample_counts[i] > 0:\n                n_oob_samples_total += 1\n                \n                votes_0 = oob_preds_counts[i, 0]\n                votes_1 = oob_preds_counts[i, 1]\n                \n                # OOB aggregation majority vote with deterministic tie-breaking\n                final_oob_pred = 1 if votes_1 > votes_0 else 0\n                \n                if final_oob_pred == y[i]:\n                    n_oob_correct += 1\n\n        if n_oob_samples_total > 0:\n            oob_accuracy = n_oob_correct / n_oob_samples_total\n        else:\n            # This case is highly unlikely but included for robustness\n            oob_accuracy = 0.0\n        \n        oob_accuracies.append(oob_accuracy)\n        \n    # --- Final Output ---\n    # Format results to six decimal places as requested\n    formatted_results = [f\"{acc:.6f}\" for acc in oob_accuracies]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3101765"}, {"introduction": "袋外（OOB）估计的价值远不止于提供一个简单的误差度量。这个高级实践将向你展示如何利用 OOB 预测进行数据诊断——这是一项在构建稳健机器学习模型中至关重要的技能。在本练习 [@problem_id:3101746] 中，我们将通过分析 OOB 预测与给定标签持续不一致的数据点，来识别训练集中潜在的“标签噪声”或错误标记的样本。这个过程不仅能帮助我们评估模型的性能，更能反过来提升训练数据的质量。", "problem": "要求您实现一个程序，该程序使用来自自助汇聚 (bagging) 集成的袋外 (OOB) 预测来识别二元分类数据集中可能被错误标记的数据点。该问题首先侧重于构建一个注入了标签噪声且数学上明确定义的合成数据集，然后使用 $k$-最近邻 (kNN) 基学习器执行带 OOB 估计的 bagging，最后标记那些 OOB 预测与其给定标签持续不一致的数据点。所有必要的定义、参数和输出要求都在下面指定。\n\n基本原理和定义：\n- Bagging 通过从原始数据集中有放回地重复抽样一个自助训练多重集，并为每个自助样本拟合一个基学习器来构建集成。对于每个数据点，给定袋的袋外 (OOB) 集合是未包含在该袋的自助多重集中的索引集合。\n- 袋外 (OOB) 估计仅对那些未用于训练相应基学习器的数据点进行预测。这样，对于每个数据点，就产生了一个在该数据点是 OOB 的所有袋中的预测集合。\n- $k$-最近邻 (kNN) 算法通过在欧几里得度量下，其 $k$ 个最近的训练点中的多数投票来对查询点进行分类，平局则倾向于类别标签值较低的一方。\n\n数据集构建：\n- 生成一个包含 $n$ 个点、$d$ 个维度的平衡二元分类数据集。类别 $0$ 的数据独立地从均值向量为 $\\mu_0$、协方差矩阵为 $d \\times d$ 单位矩阵 $I_d$ 的多元正态分布中抽取，而类别 $1$ 的数据则独立地从均值向量为 $\\mu_1$、协方差矩阵为 $I_d$ 的多元正态分布中抽取。其中恰好有 $\\lfloor n/2 \\rfloor$ 个点属于类别 $0$，其余点属于类别 $1$。\n- 设标签为 $y_i \\in \\{0,1\\}$，其中 $i \\in \\{1,\\dots,n\\}$。以比率 $r$ 注入标签噪声，方法是（无放回地）从数据中均匀随机选择一个大小为 $\\lfloor r n \\rfloor$ 的子集 $\\mathcal{M}$，并对每个选定的标签进行翻转，即 $y_i \\leftarrow 1 - y_i$。集合 $\\mathcal{M}$ 是由注入噪声引起的错误标记点的真实集合。\n\n带 OOB 预测的 Bagging：\n- 对于 $b \\in \\{1,\\dots,B\\}$：\n  - 通过从 $\\{1,\\dots,n\\}$ 中有放回地抽样索引，来抽取一个大小为 $n$ 的自助训练多重集 $\\mathcal{T}_b$。\n  - 定义 OOB 集合 $\\mathcal{O}_b = \\{ i \\in \\{1,\\dots,n\\} : i \\notin \\mathcal{T}_b \\}$。\n  - 在 $\\{(X_j, y_j): j \\in \\mathcal{T}_b\\}$ 上训练一个 $k$-最近邻 (kNN) 分类器，并对于每个 $i \\in \\mathcal{O}_b$，使用欧几里得距离、$k$ 个邻居以及倾向于较低标签的平局打破规则来计算预测标签 $\\hat{y}_i^{(b)}$。\n- 对于每个索引 $i \\in \\{1,\\dots,n\\}$：\n  - 令 $m_i$ 表示索引 $i$ 属于 $\\mathcal{O}_b$ 的袋的数量（即，对索引 $i$ 可用的 OOB 预测计数）。\n  - 通过多数投票定义聚合的 OOB 预测为 $$\\hat{y}_i^{\\text{OOB}} = \\text{majority} \\big( \\{ \\hat{y}_i^{(b)} : i \\in \\mathcal{O}_b \\} \\big).$$\n  - 定义 OOB 不一致分数为 $$\\delta_i = \\frac{1}{m_i} \\sum_{b : i \\in \\mathcal{O}_b} \\mathbf{1}\\{ \\hat{y}_i^{(b)} \\neq y_i \\}.$$\n\n标记规则和度量指标：\n- 给定一个阈值 $\\tau \\in [0,1]$ 和一个最小 OOB 计数 $m_{\\min} \\in \\mathbb{N}$，如果 $m_i \\ge m_{\\min}$ 且 $\\delta_i \\ge \\tau$，则标记索引 $i$。令 $\\mathcal{F}$ 为被标记索引的集合。\n- 定义 bagged 集成的 OOB 误差估计为 $$E_{\\text{OOB}} = \\frac{1}{|\\{ i : m_i > 0 \\}|} \\sum_{i : m_i > 0} \\mathbf{1}\\{ \\hat{y}_i^{\\text{OOB}} \\neq y_i \\}.$$\n- 使用真实错误标记索引集 $\\mathcal{M}$ 和已标记索引集 $\\mathcal{F}$，计算用于检测注入噪声的精确率、召回率和 $F_1$ 分数：\n  - $$P = \\begin{cases} \\frac{|\\mathcal{F} \\cap \\mathcal{M}|}{|\\mathcal{F}|},  |\\mathcal{F}| > 0, \\\\ 0,  \\text{otherwise,} \\end{cases} \\quad R = \\begin{cases} \\frac{|\\mathcal{F} \\cap \\mathcal{M}|}{|\\mathcal{M}|},  |\\mathcal{M}| > 0, \\\\ 0,  \\text{otherwise,} \\end{cases}$$\n  - $$F_1 = \\begin{cases} \\frac{2 P R}{P + R},  P + R > 0, \\\\ 0,  \\text{otherwise.} \\end{cases}$$\n- 所有度量指标必须表示为小数，计数表示为整数。\n\n测试套件：\n您的程序必须评估以下四个参数集。对于每种情况，请使用一个由给定种子初始化的独立伪随机数生成器。此问题不涉及物理单位。\n1. 情况 1：$n = 120$, $d = 2$, $\\mu_0 = [-1.0, -1.0]$, $\\mu_1 = [1.0, 1.0]$, $r = 0.1$, $B = 64$, $k = 5$, $\\tau = 0.6$, $m_{\\min} = 5$, 种子 $= 12345$。\n2. 情况 2：$n = 120$, $d = 2$, $\\mu_0 = [-1.0, -1.0]$, $\\mu_1 = [1.0, 1.0]$, $r = 0.0$, $B = 64$, $k = 5$, $\\tau = 0.6$, $m_{\\min} = 5$, 种子 $= 12346$。\n3. 情况 3：$n = 120$, $d = 2$, $\\mu_0 = [-0.8, 0.8]$, $\\mu_1 = [0.8, -0.8]$, $r = 0.4$, $B = 64$, $k = 7$, $\\tau = 0.7$, $m_{\\min} = 5$, 种子 $= 12347$。\n4. 情况 4：$n = 30$, $d = 2$, $\\mu_0 = [-1.2, -1.2]$, $\\mu_1 = [1.2, 1.2]$, $r = 0.2$, $B = 32$, $k = 3$, $\\tau = 0.6$, $m_{\\min} = 1$, 种子 $= 12348$。\n\n要求的最终输出格式：\n- 对于每个测试用例，生成一个结果列表 $[E_{\\text{OOB}}, P, R, F_1, |\\mathcal{F}|]$。\n- 您的程序应生成单行输出，其中包含所有四个测试用例的结果，格式为这些单例列表的逗号分隔列表，不含空格，并用方括号括起来。例如，输出必须类似于 $$[[e_1,p_1,r_1,f_1,c_1],[e_2,p_2,r_2,f_2,c_2],[e_3,p_3,r_3,f_3,c_3],[e_4,p_4,r_4,f_4,c_4]]$$ 其中每个 $e_i$、$p_i$、$r_i$、$f_i$ 是小数，每个 $c_i$ 是整数。", "solution": "此问题被评估为有效，因为它在统计学习理论中具有科学依据，具有特定的参数和确定性程序，是适定的，并且是客观地表述的。所有定义和算法步骤均已提供，从而可以得到唯一且可验证的解决方案。\n\n任务是实现一个程序，用于在合成的二元分类数据集中识别错误标记的数据点。这是通过在自助汇聚 (bagging) 框架内使用 $k$-最近邻 (kNN) 分类器集成来实现的。核心思想是利用袋外 (OOB) 预测，即由未在该数据点上训练过的分类器对该数据点做出的预测。一个点的给定标签与其 OOB 预测之间的高度不一致表明它可能被错误标记了。\n\n该过程可分为四个主要阶段：\n\n**1. 合成数据集生成与噪声注入**\n首先，构建一个受控数据集作为测试平台。该数据集包含 $d$ 维特征空间中的 $n$ 个点。\n数据从两个类别生成，标记为 $0$ 和 $1$。\n- 类别 $0$ 包含 $n_0 = \\lfloor n/2 \\rfloor$ 个点，从多元正态分布 $\\mathcal{N}(\\mu_0, I_d)$ 中抽取，其中 $\\mu_0$ 是类别 $0$ 的均值向量，$I_d$ 是 $d \\times d$ 的单位矩阵。\n- 类别 $1$ 包含 $n_1 = n - \\lfloor n/2 \\rfloor$ 个点，从 $\\mathcal{N}(\\mu_1, I_d)$ 中抽取。\n特征矩阵表示为 $X \\in \\mathbb{R}^{n \\times d}$，初始的正确标签表示为 $y_{\\text{true}}$。\n\n为了模拟标签错误，我们引入了标签噪声。从 $\\{1, \\dots, n\\}$ 中无放回地均匀选择一个大小为 $|\\mathcal{M}| = \\lfloor rn \\rfloor$ 的随机索引子集 $\\mathcal{M}$，其中 $r$ 是噪声率。对于每个索引 $i \\in \\mathcal{M}$，其真实标签被翻转：$y_i \\leftarrow 1 - y_i$。这就创建了最终的、可能带有噪声的标签向量 $y$，用于训练和评估。集合 $\\mathcal{M}$ 作为错误标记点的真实基准。\n\n**2. 使用 kNN 和 OOB 预测的 Bagging**\n该方法的核心是一个由 $B$ 个 kNN 分类器组成的 bagging 集成。对于 $B$ 次迭代中的每一次（由 $b=1, \\dots, B$ 索引）：\n- 通过从 $\\{1, \\dots, n\\}$ 中有放回地抽样 $n$ 个索引，创建一个自助多重集 $\\mathcal{T}_b$。该集合构成第 $b$ 个分类器的训练数据。\n- 袋外 (OOB) 集合 $\\mathcal{O}_b$ 定义为不存在于自助样本 $\\mathcal{T}_b$ 中的索引集合。即 $\\mathcal{O}_b = \\{i \\in \\{1, \\dots, n\\} \\mid i \\notin \\mathcal{T}_b\\}$。\n- 在与 $\\mathcal{T}_b$ 对应的数据上，即 $\\{(X_j, y_j) : j \\in \\mathcal{T}_b\\}$，训练一个 $k$-最近邻分类器。\n- 然后使用该分类器为 OOB 集合中的所有点 $\\{X_i : i \\in \\mathcal{O}_b\\}$ 预测标签。令 $\\hat{y}_i^{(b)}$ 为点 $i$ 的预测值。kNN 预测由训练集中 $k$ 个最近邻的多数投票决定，距离由欧几里得度量衡量。平局则倾向于较低的类别标签 ($0$)。\n\n经过 $B$ 次迭代后，对于每个数据点 $i$，我们将得到一个 OOB 预测的集合，即 $\\{\\hat{y}_i^{(b)} : b \\text{ 使得 } i \\in \\mathcal{O}_b\\}$。\n\n**3. OOB 聚合与不一致性计算**\n对于每个数据点 $i \\in \\{1, \\dots, n\\}$，我们分析其 OOB 预测。\n- 令 $m_i$ 为数据点 $i$ 处于 OOB 集合中的次数。\n- 聚合的 OOB 预测 $\\hat{y}_i^{\\text{OOB}}$ 是通过对其 $m_i$ 个 OOB 预测进行多数投票计算得出的。平局再次倾向于类别 $0$。\n- OOB 不一致分数 $\\delta_i$ 是指数据点 $i$ 的 OOB 预测中与其给定标签 $y_i$ 不匹配的比例：\n$$\n\\delta_i = \\frac{1}{m_i} \\sum_{b : i \\in \\mathcal{O}_b} \\mathbf{1}\\{ \\hat{y}_i^{(b)} \\neq y_i \\}\n$$\n其中 $\\mathbf{1}\\{\\cdot\\}$ 是指示函数。这个 $\\delta_i$ 值量化了数据点 $i$ 可能被错误标记的证据。一个高的 $\\delta_i$ 值表明，未在数据点 $i$ 上训练的集成成员一致地预测出一个与 $y_i$ 不同的标签。\n\n**4. 错误标记点标记与性能评估**\n如果一个点 $i$ 满足两个条件，它就会被标记为可能被错误标记：\n1. 它有足够数量的 OOB 预测：$m_i \\ge m_{\\min}$。\n2. 它的 OOB 不一致分数超过某个阈值：$\\delta_i \\ge \\tau$。\n所有这些被标记索引的集合表示为 $\\mathcal{F}$。\n\n该检测方法的性能通过使用标准分类度量指标进行评估，将标记集 $\\mathcal{F}$ 与真实基准的错误标记集 $\\mathcal{M}$ 进行比较：\n- **精确率 ($P$)**：被标记的点中真正被错误标记的比例。\n$$P = \\frac{|\\mathcal{F} \\cap \\mathcal{M}|}{|\\mathcal{F}|} \\quad (\\text{if } |\\mathcal{F}| > 0 \\text{, else } 0)$$\n- **召回率 ($R$)**：真正被错误标记的点中被成功标记的比例。\n$$R = \\frac{|\\mathcal{F} \\cap \\mathcal{M}|}{|\\mathcal{M}|} \\quad (\\text{if } |\\mathcal{M}| > 0 \\text{, else } 0)$$\n- **$F_1$ 分数**：精确率和召回率的调和平均数。\n$$F_1 = \\frac{2 P R}{P + R} \\quad (\\text{if } P+R > 0 \\text{, else } 0)$$\n\n此外，bagged 集成的整体 OOB 分类误差计算如下：\n$$\nE_{\\text{OOB}} = \\frac{\\sum_{i : m_i > 0} \\mathbf{1}\\{ \\hat{y}_i^{\\text{OOB}} \\neq y_i \\}}{|\\{ i : m_i > 0 \\}|}\n$$\n这代表了在 OOB 样本上估计的集成错误率。\n\n将此完整过程应用于测试套件中提供的每个参数集，以生成所需的输出度量指标。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.spatial.distance import cdist\n\ndef knn_predict(X_train, y_train, X_test, k):\n    \"\"\"\n    Predicts labels for X_test using k-NN trained on X_train, y_train.\n    \n    Ties in majority vote are broken in favor of the lower class label (0).\n    \"\"\"\n    if X_train.shape[0] == 0 or X_test.shape[0] == 0:\n        return np.array([])\n        \n    distances = cdist(X_test, X_train, 'euclidean')\n    \n    # Get indices of the k nearest neighbors for each test point\n    k_nearest_indices = np.argsort(distances, axis=1)[:, :k]\n    \n    # Get the labels of these neighbors\n    k_nearest_labels = y_train[k_nearest_indices]\n    \n    # Predict by majority vote. Sum of labels gives vote count for class 1.\n    # Prediction is 1 if votes_for_1 > k/2.\n    # If votes_for_1 = k/2 (including ties), prediction is 0.\n    votes_for_1 = np.sum(k_nearest_labels, axis=1)\n    predictions = (votes_for_1 > k / 2).astype(int)\n    \n    return predictions\n\ndef solve_case(n, d, mu_0, mu_1, r, B, k, tau, m_min, seed):\n    \"\"\"\n    Executes the entire procedure for a single test case.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n\n    # 1. Dataset Generation\n    n0 = n // 2\n    n1 = n - n0\n    \n    X0 = rng.multivariate_normal(mu_0, np.identity(d), size=n0)\n    X1 = rng.multivariate_normal(mu_1, np.identity(d), size=n1)\n    \n    X = np.vstack((X0, X1))\n    y_true = np.array([0] * n0 + [1] * n1)\n    \n    # 2. Label Noise Injection\n    num_mislabeled = int(np.floor(r * n))\n    mislabeled_indices = np.array([], dtype=int)\n    y = np.copy(y_true)\n    \n    if num_mislabeled > 0:\n        indices_to_flip = rng.choice(n, size=num_mislabeled, replace=False)\n        y[indices_to_flip] = 1 - y[indices_to_flip]\n        mislabeled_indices = indices_to_flip\n        \n    # 3. Bagging and OOB Prediction\n    oob_preds_per_point = [[] for _ in range(n)]\n    \n    for _ in range(B):\n        # Create bootstrap sample and identify OOB set\n        train_indices = rng.choice(n, n, replace=True)\n        oob_indices = np.setdiff1d(np.arange(n), np.unique(train_indices))\n        \n        if len(oob_indices) == 0:\n            continue\n            \n        X_train_b, y_train_b = X[train_indices], y[train_indices]\n        X_oob = X[oob_indices]\n        \n        # Predict labels for OOB points\n        y_oob_pred = knn_predict(X_train_b, y_train_b, X_oob, k)\n        \n        # Store predictions\n        for i, idx in enumerate(oob_indices):\n            oob_preds_per_point[idx].append(y_oob_pred[i])\n            \n    # 4. Aggregation and Analysis\n    y_hat_oob_agg = np.full(n, -1, dtype=int)\n    deltas = np.full(n, -1.0, dtype=float)\n    m_counts = np.array([len(p) for p in oob_preds_per_point])\n    \n    oob_analyzed_indices = np.where(m_counts > 0)[0]\n    \n    for i in oob_analyzed_indices:\n        preds = np.array(oob_preds_per_point[i])\n        m_i = m_counts[i]\n        \n        # Aggregated OOB prediction (majority vote, tie-break to 0)\n        votes_for_1 = np.sum(preds)\n        y_hat_oob_agg[i] = 1 if votes_for_1 > m_i / 2 else 0\n        \n        # OOB disagreement fraction\n        deltas[i] = np.sum(preds != y[i]) / m_i\n\n    # 5. Flagging and Metric Calculation\n    # E_OOB calculation\n    y_target_oob = y[oob_analyzed_indices]\n    y_pred_oob_agg = y_hat_oob_agg[oob_analyzed_indices]\n    e_oob = np.sum(y_target_oob != y_pred_oob_agg) / len(oob_analyzed_indices) if len(oob_analyzed_indices) > 0 else 0.0\n    \n    # Flagging\n    flagged_indices = np.where((m_counts >= m_min) & (deltas >= tau))[0]\n    \n    # Precision, Recall, F1\n    m_set = set(mislabeled_indices)\n    f_set = set(flagged_indices)\n    \n    intersection_size = len(f_set.intersection(m_set))\n    f_size = len(f_set)\n    m_size = len(m_set)\n    \n    p = intersection_size / f_size if f_size > 0 else 0.0\n    r_val = intersection_size / m_size if m_size > 0 else 0.0\n    f1 = (2 * p * r_val) / (p + r_val) if (p + r_val) > 0 else 0.0\n    \n    return [e_oob, p, r_val, f1, f_size]\n\ndef solve():\n    test_cases = [\n        {'n': 120, 'd': 2, 'mu_0': [-1.0, -1.0], 'mu_1': [1.0, 1.0], 'r': 0.1, 'B': 64, 'k': 5, 'tau': 0.6, 'm_min': 5, 'seed': 12345},\n        {'n': 120, 'd': 2, 'mu_0': [-1.0, -1.0], 'mu_1': [1.0, 1.0], 'r': 0.0, 'B': 64, 'k': 5, 'tau': 0.6, 'm_min': 5, 'seed': 12346},\n        {'n': 120, 'd': 2, 'mu_0': [-0.8, 0.8], 'mu_1': [0.8, -0.8], 'r': 0.4, 'B': 64, 'k': 7, 'tau': 0.7, 'm_min': 5, 'seed': 12347},\n        {'n': 30, 'd': 2, 'mu_0': [-1.2, -1.2], 'mu_1': [1.2, 1.2], 'r': 0.2, 'B': 32, 'k': 3, 'tau': 0.6, 'm_min': 1, 'seed': 12348},\n    ]\n\n    all_results = []\n    for case in test_cases:\n        result = solve_case(\n            n=case['n'],\n            d=case['d'],\n            mu_0=case['mu_0'],\n            mu_1=case['mu_1'],\n            r=case['r'],\n            B=case['B'],\n            k=case['k'],\n            tau=case['tau'],\n            m_min=case['m_min'],\n            seed=case['seed']\n        )\n        all_results.append(result)\n\n    # Final print statement in the exact required format (no spaces)\n    print(str(all_results).replace(\" \", \"\"))\n\nsolve()\n```", "id": "3101746"}]}