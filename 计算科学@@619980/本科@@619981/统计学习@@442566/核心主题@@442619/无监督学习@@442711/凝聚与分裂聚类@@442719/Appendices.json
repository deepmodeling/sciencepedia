{"hands_on_practices": [{"introduction": "这第一个练习将带你深入 Ward 连锁法的数学核心。你将不再是简单地接受公式，而是通过第一性原理，亲手推导出簇内平方和的增量表达式。理解这个推导过程，是掌握 Ward 方法为何倾向于生成紧凑球形簇的关键，它能让你更深刻地洞察该算法的决策机制。[@problem_id:3097665]", "problem": "考虑在欧几里得空间中对数据集 $\\mathcal{X} \\subset \\mathbb{R}^{p}$ 进行凝聚层次聚类，使用 Ward 链接法。该方法在每次合并时选择能使总簇内平方和增量最小的一对簇。设 $A$ 和 $B$ 为两个不相交的簇，其大小分别为 $|A|=m$ 和 $|B|=n$，质心（均值）$\\mu_A$ 和 $\\mu_B$ 定义为 $\\mu_C=\\frac{1}{|C|}\\sum_{x \\in C} x$（对于任意簇 $C$）。簇 $C$ 的簇内平方和为 $W(C)=\\sum_{x \\in C}\\|x-\\mu_C\\|^2$，总簇内平方和为 $W_{\\mathrm{tot}}=\\sum_{C} W(C)$，其中求和遍及所有当前簇。首先，仅使用这些定义和标准的线性代数恒等式，推导合并后簇 $A \\cup B$ 的质心关于 $m$、$n$、$\\mu_A$ 和 $\\mu_B$ 的精确表达式。其次，推导因合并 $A$ 和 $B$ 而导致的总簇内平方和的增量 $\\Delta W = W(A \\cup B) - W(A) - W(B)$ 的精确表达式，该表达式仅用 $m$、$n$ 和欧几里得距离 $\\|\\mu_A-\\mu_B\\|$ 表示。第三，对于在 $\\mathbb{R}^{2}$ 中的情况，$m=7$，$n=3$，$\\mu_A=(1,2)$，$\\mu_B=(5,8)$，使用你推导出的 $\\Delta W$ 表达式和标准的欧几里得范数，计算该增量的数值。最后，定性地讨论在质心距离 $\\|\\mu_A-\\mu_B\\|$ 保持不变时，成本增量如何依赖于大小比率 $r=m/n$。作为最终答案，请仅提供针对指定的 $m$、$n$、$\\mu_A$ 和 $\\mu_B$ 的增量数值，并四舍五入到4位有效数字。", "solution": "解答过程按问题陈述的要求分为四个部分。\n\n首先，我们推导合并后簇 $\\mu_{A \\cup B}$ 的质心表达式。设 $A$ 和 $B$ 是两个不相交的簇，其大小分别为 $|A|=m$ 和 $|B|=n$，质心分别为 $\\mu_A$ 和 $\\mu_B$。合并后的簇为 $C = A \\cup B$，其大小为 $|C| = |A| + |B| = m+n$。\n\n根据质心的定义，$\\mu_C = \\frac{1}{|C|} \\sum_{x \\in C} x$。将此应用于合并后的簇 $A \\cup B$：\n$$ \\mu_{A \\cup B} = \\frac{1}{|A \\cup B|} \\sum_{x \\in A \\cup B} x $$\n由于 $A$ 和 $B$ 不相交，求和可以拆分：\n$$ \\mu_{A \\cup B} = \\frac{1}{m+n} \\left( \\sum_{x \\in A} x + \\sum_{x \\in B} x \\right) $$\n根据单个簇质心的定义，我们知道 $\\sum_{x \\in A} x = |A|\\mu_A = m\\mu_A$ 且 $\\sum_{x \\in B} x = |B|\\mu_B = n\\mu_B$。将这些代入表达式，得到合并后簇的质心：\n$$ \\mu_{A \\cup B} = \\frac{m\\mu_A + n\\mu_B}{m+n} $$\n\n其次，我们推导总簇内平方和的增量 $\\Delta W = W(A \\cup B) - W(A) - W(B)$ 的表达式。合并后簇 $A \\cup B$ 的簇内平方和为：\n$$ W(A \\cup B) = \\sum_{x \\in A \\cup B} \\|x - \\mu_{A \\cup B}\\|^2 $$\n同样，我们将求和拆分到不相交的集合 $A$ 和 $B$ 上：\n$$ W(A \\cup B) = \\sum_{x \\in A} \\|x - \\mu_{A \\cup B}\\|^2 + \\sum_{x \\in B} \\|x - \\mu_{A \\cup B}\\|^2 $$\n让我们分析第一项 $\\sum_{x \\in A} \\|x - \\mu_{A \\cup B}\\|^2$。我们可以在范数内部加上和减去质心 $\\mu_A$ 来引入它：\n$$ \\sum_{x \\in A} \\|(x - \\mu_A) + (\\mu_A - \\mu_{A \\cup B})\\|^2 $$\n展开平方范数 $\\|u+v\\|^2 = \\|u\\|^2 + 2u \\cdot v + \\|v\\|^2$：\n$$ \\sum_{x \\in A} \\left( \\|x - \\mu_A\\|^2 + 2(x - \\mu_A) \\cdot (\\mu_A - \\mu_{A \\cup B}) + \\|\\mu_A - \\mu_{A \\cup B}\\|^2 \\right) $$\n我们可以分配求和：\n$$ \\sum_{x \\in A} \\|x - \\mu_A\\|^2 + 2 \\left( \\sum_{x \\in A} (x - \\mu_A) \\right) \\cdot (\\mu_A - \\mu_{A \\cup B}) + \\sum_{x \\in A} \\|\\mu_A - \\mu_{A \\cup B}\\|^2 $$\n根据定义，第一项是 $W(A)$。第二项的求和部分为 $\\sum_{x \\in A} (x - \\mu_A) = \\sum_{x \\in A} x - \\sum_{x \\in A} \\mu_A = m\\mu_A - m\\mu_A = 0$。因此，整个第二项为零。第三项是 $m$ 个相同项的和，因此它等于 $m\\|\\mu_A - \\mu_{A \\cup B}\\|^2$。\n因此，对簇 $A$ 的求和简化为：\n$$ \\sum_{x \\in A} \\|x - \\mu_{A \\cup B}\\|^2 = W(A) + m\\|\\mu_A - \\mu_{A \\cup B}\\|^2 $$\n对于簇 $B$，通过相同的论证可得：\n$$ \\sum_{x \\in B} \\|x - \\mu_{A \\cup B}\\|^2 = W(B) + n\\|\\mu_B - \\mu_{A \\cup B}\\|^2 $$\n将这些代回 $W(A \\cup B)$ 的表达式中：\n$$ W(A \\cup B) = W(A) + m\\|\\mu_A - \\mu_{A \\cup B}\\|^2 + W(B) + n\\|\\mu_B - \\mu_{A \\cup B}\\|^2 $$\n增量 $\\Delta W$ 于是为：\n$$ \\Delta W = W(A \\cup B) - W(A) - W(B) = m\\|\\mu_A - \\mu_{A \\cup B}\\|^2 + n\\|\\mu_B - \\mu_{A \\cup B}\\|^2 $$\n现在我们必须用 $m$、$n$ 和 $\\|\\mu_A - \\mu_B\\|$ 来表示它。我们使用 $\\mu_{A \\cup B}$ 的表达式：\n$$ \\mu_A - \\mu_{A \\cup B} = \\mu_A - \\frac{m\\mu_A + n\\mu_B}{m+n} = \\frac{(m+n)\\mu_A - (m\\mu_A + n\\mu_B)}{m+n} = \\frac{n(\\mu_A - \\mu_B)}{m+n} $$\n$$ \\mu_B - \\mu_{A \\cup B} = \\mu_B - \\frac{m\\mu_A + n\\mu_B}{m+n} = \\frac{(m+n)\\mu_B - (m\\mu_A + n\\mu_B)}{m+n} = \\frac{m(\\mu_B - \\mu_A)}{m+n} = -\\frac{m(\\mu_A - \\mu_B)}{m+n} $$\n将这些代入 $\\Delta W$ 的表达式中：\n$$ \\Delta W = m\\left\\|\\frac{n(\\mu_A - \\mu_B)}{m+n}\\right\\|^2 + n\\left\\|-\\frac{m(\\mu_A - \\mu_B)}{m+n}\\right\\|^2 $$\n使用性质 $\\|\\lambda v\\|^2 = \\lambda^2\\|v\\|^2$：\n$$ \\Delta W = m\\left(\\frac{n}{m+n}\\right)^2\\|\\mu_A - \\mu_B\\|^2 + n\\left(\\frac{m}{m+n}\\right)^2\\|\\mu_A - \\mu_B\\|^2 $$\n$$ \\Delta W = \\left( \\frac{mn^2}{(m+n)^2} + \\frac{nm^2}{(m+n)^2} \\right) \\|\\mu_A - \\mu_B\\|^2 $$\n$$ \\Delta W = \\frac{mn^2 + nm^2}{(m+n)^2} \\|\\mu_A - \\mu_B\\|^2 = \\frac{mn(n+m)}{(m+n)^2} \\|\\mu_A - \\mu_B\\|^2 $$\n$$ \\Delta W = \\frac{mn}{m+n} \\|\\mu_A - \\mu_B\\|^2 $$\n这就是所求的簇内平方和增量的表达式。\n\n第三，我们计算 $m=7$，$n=3$，$\\mu_A=(1,2)$ 和 $\\mu_B=(5,8)$ 时的数值。\n系数为：\n$$ \\frac{mn}{m+n} = \\frac{7 \\times 3}{7+3} = \\frac{21}{10} = 2.1 $$\n质心之间的欧几里得距离的平方是：\n$$ \\|\\mu_A - \\mu_B\\|^2 = \\|(1-5, 2-8)\\|^2 = \\|(-4, -6)\\|^2 = (-4)^2 + (-6)^2 = 16 + 36 = 52 $$\n平方和的增量是：\n$$ \\Delta W = (2.1) \\times (52) = 109.2 $$\n数值 $109.2$ 具有所要求的四位有效数字。\n\n第四，我们定性地讨论在质心距离 $\\|\\mu_A - \\mu_B\\|$ 保持不变时，成本增量 $\\Delta W$ 如何依赖于大小比率 $r=m/n$。令 $D = \\|\\mu_A - \\mu_B\\|$ 为常数。成本为 $\\Delta W = \\frac{mn}{m+n} D^2$。其依赖关系由系数 $C(m,n) = \\frac{mn}{m+n}$ 决定。让我们用比率 $r=m/n$ 和其中一个簇中的点数（比如 $n$）来表示这个系数。通过代入 $m=rn$，我们得到：\n$$ C(m,n) = \\frac{(rn)n}{rn+n} = \\frac{rn^2}{n(r+1)} = \\frac{rn}{r+1} $$\n这表明成本不仅取决于比率 $r$，还取决于簇的绝对大小。分析比率影响的一个更好的方法是固定总大小 $N=m+n$。那么 $m = N-n$，且 $C(m,n) = \\frac{(N-n)n}{N}$。这个关于 $n$ 的函数（对于 $1 \\le n  N$）是一个开口向下的抛物线，在 $n=N/2$ 时达到最大值。这对应于 $m=n$，即大小比率 $r=1$。\n当 $r=1$（簇大小相等）时，对于固定的距离 $D$ 和总大小 $N$，合并成本最高。当大小比率变得非常大或非常小（即 $r \\to \\infty$ 或 $r \\to 0$）时，系数 $\\frac{mn}{m+n}$ 趋近于 $\\min(m,n)$。对于固定的总大小 $N$，当一个簇的大小趋近于 $N$ 而另一个簇的大小趋近于 $0$ 时，这个最小值趋近于 $0$。\n总之，相比于将一个小簇合并到一个大簇中，Ward 方法对合并两个大小相等的平衡簇施加更重的惩罚。这一特性促进了大小大致相等的簇的形成，是该链接法的一个显著特征。", "answer": "$$\\boxed{109.2}$$", "id": "3097665"}, {"introduction": "从理论转向实践，这个练习旨在揭示不同连锁方法鲜明的“个性”。通过在一个精心设计的数据集上应用单连锁和全连锁算法，你将亲眼观察并量化单连锁法著名的“链式效应”。这项动手编程任务将连锁标准等抽象概念变得具体可感，并展示算法选择如何戏剧性地改变聚类结果。[@problem_id:3097643]", "problem": "您将实现并比较两种连接方法的凝聚聚类算法。该算法将应用于一个确定性的平面数据集，其中包含两个由稀疏链条连接的稠密团块。您的目标是通过计算在距离阈值 $h$ 的函数下，有多少次合并操作将一个稠密团块与该团块之外的任何部分（包括链条或对面的团块）连接起来，从而量化链式效应。\n\n数据集定义：\n- 在 $\\mathbb{R}^2$ 中构造一个点集，由三部分组成：\n  1. 左侧团块 $L$：一个大小为 $3 \\times 3$ 的网格，中心在 $(-4,0)$ 附近，其坐标为 $x \\in \\{-4.1,-4.0,-3.9\\}$ 和 $y \\in \\{-0.1,0.0,0.1\\}$。这会产生 $9$ 个点。\n  2. 右侧团块 $R$：一个大小为 $3 \\times 3$ 的网格，中心在 $(4,0)$ 附近，其坐标为 $x \\in \\{3.9,4.0,4.1\\}$ 和 $y \\in \\{-0.1,0.0,0.1\\}$。这会产生 $9$ 个点。\n  3. 链条 $C$：沿 $x$ 轴的共线点，位于 $y=0$，其 $x$ 坐标为 $\\{-2.5,-2.0,-1.5,-1.0,-0.5,0.0,0.5,1.0,1.5,2.0,2.5\\}$。这会产生 $11$ 个点。\n- 总点数为 $29$。\n\n方法的基本原理：\n- 使用点 $\\mathbf{x},\\mathbf{y}\\in\\mathbb{R}^2$ 之间的欧几里得距离 $d(\\mathbf{x},\\mathbf{y})=\\|\\mathbf{x}-\\mathbf{y}\\|_{2}$。\n- 在凝聚聚类中，从单例簇开始，重复合并具有最小簇间相异度的簇对 $\\mathcal{A},\\mathcal{B}$。对于单连接，簇间相异度为 $\\min\\{d(\\mathbf{x},\\mathbf{y}) : \\mathbf{x}\\in\\mathcal{A}, \\mathbf{y}\\in\\mathcal{B}\\}$。对于全连接，它为 $\\max\\{d(\\mathbf{x},\\mathbf{y}) : \\mathbf{x}\\in\\mathcal{A}, \\mathbf{y}\\in\\mathcal{B}\\}$。\n- 树状图的合并高度是合并发生步骤时的簇间相异度。\n\n链式效应计数规则：\n- 将左侧团块的索引集定义为 $L$，右侧团块的索引集定义为 $R$，链条的索引集定义为 $C$（即 $L\\cup R$ 的补集）。\n- 在每个合并步骤中，假设两个当前簇 $\\mathcal{A}$ 和 $\\mathcal{B}$ 在高度 $h_{\\text{merge}}$ 处合并。定义指示符 $I_{L}(\\mathcal{A})=\\mathbf{1}[\\mathcal{A}\\cap L\\neq\\emptyset]$ 和 $I_{R}(\\mathcal{A})=\\mathbf{1}[\\mathcal{A}\\cap R\\neq\\emptyset]$（对 $\\mathcal{B}$ 也类似）。\n- 如果 $(I_{L}(\\mathcal{A}) \\oplus I_{L}(\\mathcal{B})) \\lor (I_{R}(\\mathcal{A}) \\oplus I_{R}(\\mathcal{B}))$ 为真，则该合并被计为“跨链”合并，其中 $\\oplus$ 是异或，$\\lor$ 是逻辑或。直观地说，当且仅当一次合并将一个团块的任何部分附加到某个不包含该相同团块的物件上时，这次合并才被计数。\n\n阈值计数：\n- 对于给定的阈值 $h$，将链式计数 $M_{\\text{linkage}}(h)$ 定义为在所有合并高度满足 $h_{\\text{merge}} \\le h$ 的树状图合并中，根据上述规则计数的合并总数。\n- 您必须为指定的阈值计算 $M_{\\text{single}}(h)$ 和 $M_{\\text{complete}}(h)$。\n\n测试套件：\n- 使用以下阈值 $h$（单位与数据的欧几里得单位相同）：$[0.0,\\,0.1,\\,0.5,\\,1.401,\\,6.61,\\,8.21]$。\n  - 这些值包括边界情况 $h=0.0$、团块内部间距 $h=0.1$、链条间距 $h=0.5$、略高于左/右团块到链条接触尺度的 $h=1.401$、一个高于全连接下左团块到链条合并高度但低于左链到右团块全连接高度的中间尺度 $h=6.61$，以及一个大于全连接下左链到右团块合并高度的大尺度 $h=8.21$。\n\n所需输出：\n- 您的程序必须执行两次凝聚聚类（单连接和全连接），为测试套件中的每个 $h$ 计算 $M_{\\text{single}}(h)$ 和 $M_{\\text{complete}}(h)$，并输出一行内容，该行包含一个按阈值顺序排列的逗号分隔的配对列表，其中每个配对的形式为 $[M_{\\text{single}}(h),M_{\\text{complete}}(h)]$。\n- 最终输出格式必须是单一行：\n  - 其确切形状的示例如下：$[[a_1,b_1],[a_2,b_2],\\dots,[a_6,b_6]]$，其中每个 $a_i$ 和 $b_i$ 都是整数。\n\n约束和注意事项：\n- 严格按照所述定义，使用欧几里得距离来实现聚类。不要假定任何预构建的层次聚类例程。\n- 不涉及角度；没有单位转换。\n- 所有输出都必须是整数。", "solution": "该问题要求针对一个特殊构造的平面数据集，从第一性原理出发，为单连接和全连接这两种连接方法实现凝聚层次聚类。目标是通过计算在距离阈值 $h$ 的函数下，连接数据集不同区域之间的合并次数，来量化“链式效应”。\n\n**1. 数据集构建**\n\n首先，我们按照规定在 $\\mathbb{R}^2$ 中构建数据集。它包含 $N=29$ 个点，分为三组：\n- 左侧团块 $L$：一个 $3 \\times 3$ 的网格，包含 $9$ 个点。坐标由 $x \\in \\{-4.1, -4.0, -3.9\\}$ 和 $y \\in \\{-0.1, 0.0, 0.1\\}$ 生成。我们为这些点分配索引 $i \\in \\{0, 1, \\dots, 8\\}$。\n- 右侧团块 $R$：一个 $3 \\times 3$ 的网格，包含 $9$ 个点。坐标由 $x \\in \\{3.9, 4.0, 4.1\\}$ 和 $y \\in \\{-0.1, 0.0, 0.1\\}$ 生成。我们为这些点分配索引 $i \\in \\{9, 10, \\dots, 17\\}$。\n- 链条 $C$：沿 $x$ 轴（$y=0$）的一组 $11$ 个共线点。坐标为 $x \\in \\{-2.5, -2.0, \\dots, 2.5\\}$，步长为 $0.5$。我们为这些点分配索引 $i \\in \\{18, 19, \\dots, 28\\}$。\n\n任意两点 $\\mathbf{p}_i = (x_i, y_i)$ 和 $\\mathbf{p}_j = (x_j, y_j)$ 之间的距离度量是欧几里得距离，$d(\\mathbf{p}_i, \\mathbf{p}_j) = \\sqrt{(x_i - x_j)^2 + (y_i - y_j)^2}$。我们预先计算所有成对距离，并将它们存储在一个对称的 $N \\times N$ 矩阵 $\\mathbf{D}$ 中，其中 $\\mathbf{D}_{ij} = d(\\mathbf{p}_i, \\mathbf{p}_j)$。\n\n**2. 凝聚聚类算法**\n\n我们根据其基本定义实现凝聚聚类算法，而不依赖于预打包的库函数来实现聚类逻辑本身。一般过程如下：\n\n1.  **初始化**：从 $N=29$ 个簇开始，每个簇都是一个包含一个点的单例集，例如，$\\mathcal{C}_i = \\{i\\}$，其中 $i=0, \\dots, 28$。我们维护一个活动簇的列表。簇之间的相异度矩阵用成对点距离 $\\mathbf{D}$ 进行初始化。\n\n2.  **迭代合并**：重复 $N-1=28$ 个步骤，直到只剩下一个簇：\n    a.  **寻找最近对**：识别具有最小簇间相异度的不同活动簇对 $\\mathcal{A}$ 和 $\\mathcal{B}$。这个最小相异度值就是合并高度 $h_{\\text{merge}}$。\n    b.  **应用链式计数规则**：在合并之前，我们应用指定的规则来确定此次合并是否构成“链式”事件。\n    c.  **合并**：形成一个新簇 $\\mathcal{A} \\cup \\mathcal{B}$。停用旧簇 $\\mathcal{A}$ 和 $\\mathcal{B}$。\n    d.  **更新相异度**：计算新簇与所有其他活动簇之间的相异度。\n\n此过程对单连接和全连接分别执行。关键区别在于相异度的更新规则（步骤2d），该规则由 Lance-Williams 公式控制。如果簇 $\\mathcal{U}$ 是通过合并 $\\mathcal{A}$ 和 $\\mathcal{B}$ 形成的，它与任何其他簇 $\\mathcal{V}$ 的相异度为：\n\n-   **单连接**：$d_{\\text{single}}(\\mathcal{U}, \\mathcal{V}) = \\min(d(\\mathcal{A}, \\mathcal{V}), d(\\mathcal{B}, \\mathcal{V}))$。这对应于 $\\mathcal{U}$ 中的任意点与 $\\mathcal{V}$ 中的任意点之间的最小距离。\n-   **全连接**：$d_{\\text{complete}}(\\mathcal{U}, \\mathcal{V}) = \\max(d(\\mathcal{A}, \\mathcal{V}), d(\\mathcal{B}, \\mathcal{V}))$。这对应于 $\\mathcal{U}$ 中的任意点与 $\\mathcal{V}$ 中的任意点之间的最大距离。\n\n**3. 链式效应计数规则**\n\n在每个合并步骤中，对于要合并的两个簇 $\\mathcal{A}$ 和 $\\mathcal{B}$，我们评估一个特定的逻辑条件。我们根据一个簇是否包含来自原始团块 $L$ 和 $R$ 的点来定义指示函数：\n- $I_{L}(\\mathcal{A}) = \\mathbf{1}[\\mathcal{A} \\cap L \\neq \\emptyset]$，如果簇 $\\mathcal{A}$ 包含至少一个来自团块 $L$ 的点，则为 $1$，否则为 $0$。\n- $I_{R}(\\mathcal{A}) = \\mathbf{1}[\\mathcal{A} \\cap R \\neq \\emptyset]$，对于团块 $R$ 也类似。\n\n如果条件 $(I_{L}(\\mathcal{A}) \\oplus I_{L}(\\mathcal{B})) \\lor (I_{R}(\\mathcal{A}) \\oplus I_{R}(\\mathcal{B}))$ 为真，则该合并被计数。这里，$\\oplus$ 表示异或（XOR）运算，$\\lor$ 表示逻辑或运算。此规则有效地标记了任何将包含特定团块中点的簇与不包含这些点的簇连接起来的合并，从而捕捉了团块“伸向”链条或其他团块的行为。\n\n对于 $28$ 次合并中的每一次，我们记录一个元组 $(h_{\\text{merge}}, \\text{is\\_counted})$，其中 `is_counted` 是根据上述规则得到的二进制值（$1$ 或 $0$）。\n\n**4. 阈值计数计算**\n\n在完成给定连接类型的聚类过程并获得 $28$ 个合并记录的列表后，我们为每个指定的阈值 $h$ 计算最终计数。阈值计数 $M_{\\text{linkage}}(h)$ 是所有合并高度 $h_{\\text{merge}} \\le h$ 的合并中 `is_counted` 值的累加和。\n\n对于测试套件 $\\{0.0, 0.1, 0.5, 1.401, 6.61, 8.21\\}$ 中的每个阈值 $h$，我们计算 $M_{\\text{single}}(h)$ 和 $M_{\\text{complete}}(h)$。\n\n- **单连接分析**：此方法对簇之间的最近点敏感。团块内部（$d \\ge 0.1$）和链条上（$d=0.5$）的短距离导致在合并高度略高于 $0.5$ 时形成三个大簇：$\\mathcal{L}$（所有 $L$）、$\\mathcal{R}$（所有 $R$）和 $\\mathcal{C}$（所有 $C$）。接下来的合并会连接这些超簇。$\\mathcal{L}$ 和 $\\mathcal{C}$ 之间的最小距离是 $1.4$，$\\mathcal{R}$ 和 $\\mathcal{C}$ 之间的最小距离也是 $1.4$。第一次被计数的合并发生在 $h=1.4$ 时（例如，$\\mathcal{L}$ 与 $\\mathcal{C}$ 合并）。随后，所产生的簇 $(\\mathcal{L} \\cup \\mathcal{C})$ 与 $\\mathcal{R}$ 的合并也发生在 $h=1.4$ 时，并且也被计数。这导致了 $2$ 次被计数的“链式”合并。\n\n- **全连接分析**：此方法对簇之间的最远点（直径）敏感。团块 $\\mathcal{L}$ 和 $\\mathcal{R}$ 会迅速合并，因为它们的直径很小（$\\approx 0.28$）。链条 $\\mathcal{C}$ 的直径很大，为 $5.0$。一个关键的观察是，形成单个簇 $\\mathcal{C}$ 的合并高度是 $5.0$，这小于将一个团块连接到链条所需的合并高度。完全形成的簇 $\\mathcal{L}$ 和完全形成的簇 $\\mathcal{C}$ 之间的全连接相异度由它们的最远点决定，$d((-4.1, \\cdot), (2.5,0)) \\approx 6.60$。因此，第一次被计数的合并发生在这个大得多的高度。最后一次合并，即 $(\\mathcal{L} \\cup \\mathcal{C})$ 和 $\\mathcal{R}$ 之间的合并，发生在更高的高度 $\\approx 8.20$。该方法能在达到高距离阈值之前稳健地分离团块。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.spatial.distance import pdist, squareform\n\ndef solve():\n    \"\"\"\n    Main function to perform agglomerative clustering and calculate chaining counts.\n    \"\"\"\n\n    # 1. Dataset Definition\n    # Left blob L\n    points_l = np.array([[x, y] for x in [-4.1, -4.0, -3.9] for y in [-0.1, 0.0, 0.1]])\n    # Right blob R\n    points_r = np.array([[x, y] for x in [3.9, 4.0, 4.1] for y in [-0.1, 0.0, 0.1]])\n    # Chain C\n    points_c = np.array([[x, 0.0] for x in np.arange(-2.5, 2.51, 0.5)])\n    \n    points = np.vstack([points_l, points_r, points_c])\n    n_points = len(points)\n    \n    # Indices for each group\n    n_l, n_r, n_c = len(points_l), len(points_r), len(points_c)\n    indices_l = set(range(n_l))\n    indices_r = set(range(n_l, n_l + n_r))\n\n    # --- Agglomerative Clustering Implementation ---\n    def run_clustering(points, linkage, indices_l, indices_r):\n        \"\"\"\n        Performs agglomerative clustering from first principles.\n        \n        Args:\n            points (np.ndarray): The N x 2 array of data points.\n            linkage (str): 'single' or 'complete'.\n            indices_l (set): Indices of points in the left blob.\n            indices_r (set): Indices of points in the right blob.\n            \n        Returns:\n            list: A list of tuples (merge_height, is_counted) for each merge.\n        \"\"\"\n        n = len(points)\n        \n        # Initial pairwise distance matrix for points\n        dist_matrix = squareform(pdist(points, 'euclidean'))\n        # Using a large number for infinity to handle self-distances\n        # and distances to merged clusters.\n        inf = np.finfo(dist_matrix.dtype).max\n        np.fill_diagonal(dist_matrix, inf)\n        \n        # Each point starts as its own cluster\n        clusters = [{i} for i in range(n)]\n        \n        # Keep track of which blobs are in each cluster\n        # blob_content[i] = (has_L, has_R)\n        blob_content = []\n        for i in range(n):\n            has_l = i in indices_l\n            has_r = i in indices_r\n            blob_content.append([has_l, has_r])\n            \n        active_clusters = list(range(n))\n        merge_log = []\n\n        for _ in range(n - 1):\n            if len(active_clusters)  2:\n                break\n                \n            min_dist = inf\n            merge_idx1, merge_idx2 = -1, -1\n            \n            # Find the closest pair of active clusters\n            # Iterating through upper triangle of distance matrix for active clusters\n            for i_idx, c1_idx in enumerate(active_clusters):\n                for c2_idx in active_clusters[i_idx + 1:]:\n                    d = dist_matrix[c1_idx, c2_idx]\n                    if d  min_dist:\n                        min_dist = d\n                        merge_idx1, merge_idx2 = c1_idx, c2_idx\n            \n            merge_height = min_dist\n            \n            # Apply the chaining-effect counting rule\n            content1 = blob_content[merge_idx1]\n            content2 = blob_content[merge_idx2]\n            \n            # (I_L(A) XOR I_L(B)) OR (I_R(A) XOR I_R(B))\n            is_counted = (content1[0] ^ content2[0]) or (content1[1] ^ content2[1])\n            merge_log.append((merge_height, 1 if is_counted else 0))\n            \n            # Merge clusters and update dissimilarities (Lance-Williams)\n            # We merge merge_idx2 into merge_idx1\n            \n            # Update blob content for the merged cluster\n            blob_content[merge_idx1][0] = content1[0] or content2[0]\n            blob_content[merge_idx1][1] = content1[1] or content2[1]\n\n            # Update distance matrix row/col for merge_idx1\n            for other_idx in active_clusters:\n                if other_idx != merge_idx1 and other_idx != merge_idx2:\n                    d1 = dist_matrix[merge_idx1, other_idx]\n                    d2 = dist_matrix[merge_idx2, other_idx]\n                    \n                    if linkage == 'single':\n                        new_dist = min(d1, d2)\n                    elif linkage == 'complete':\n                        new_dist = max(d1, d2)\n                    else:\n                        raise ValueError(\"Invalid linkage method\")\n\n                    dist_matrix[merge_idx1, other_idx] = new_dist\n                    dist_matrix[other_idx, merge_idx1] = new_dist\n            \n            # Deactivate merge_idx2\n            dist_matrix[merge_idx2, :] = inf\n            dist_matrix[:, merge_idx2] = inf\n            active_clusters.remove(merge_idx2)\n\n        return merge_log\n\n    # --- Calculate Thresholded Counts ---\n    def calculate_counts(merge_log, thresholds):\n        \"\"\"Calculates cumulative counts for given thresholds.\"\"\"\n        counts = []\n        sorted_merges = sorted(merge_log)\n        \n        for h in thresholds:\n            count = 0\n            for merge_height, is_counted in sorted_merges:\n                if merge_height = h:\n                    count += is_counted\n                else:\n                    break\n            counts.append(count)\n        return counts\n\n    # Test suite of thresholds\n    thresholds = [0.0, 0.1, 0.5, 1.401, 6.61, 8.21]\n\n    # Run for single linkage\n    merges_single = run_clustering(points, 'single', indices_l, indices_r)\n    counts_single = calculate_counts(merges_single, thresholds)\n\n    # Run for complete linkage\n    merges_complete = run_clustering(points, 'complete', indices_l, indices_r)\n    counts_complete = calculate_counts(merges_complete, thresholds)\n\n    # Format the final output\n    results = []\n    for s_count, c_count in zip(counts_single, counts_complete):\n        results.append(f\"[{s_count},{c_count}]\")\n    \n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3097643"}, {"introduction": "掌握聚类分析的最后一步是理解它如何与你的数据相互作用。这个练习将阐明一个至关重要的实践问题：基于距离的算法结果对特征缩放高度敏感。通过推导能够改变 Ward 方法合并顺序的精确缩放因子，你将深刻体会到为何在聚类分析前进行特征标准化往往是必不可少的第一步。[@problem_id:3097578]", "problem": "考虑一个在二维特征空间 $\\mathbb{R}^{2}$ 中，使用 Ward 链接法的凝聚式聚类场景。设有 $4$ 个数据点\n$$\nx_{1} = (0,0), \\quad x_{2} = (0,3), \\quad x_{3} = (4,1), \\quad x_{4} = (5,1).\n$$\n假设第二个特征通过线性映射 $S_{\\alpha} : \\mathbb{R}^{2} \\to \\mathbb{R}^{2}$ (定义为 $S_{\\alpha}(x,y) = (x, \\alpha y)$) 被一个正因子 $\\alpha  0$ 重缩放。Ward 的凝聚式方法在每一步选择使总簇内平方和 (WSS) 增量最小化的合并，其中一个包含点 $\\{z_{i}\\}$ 且均值为 $\\mu_C$ 的簇 $C$ 的簇内平方和 (WSS) 定义为 $\\sum_{z_{i} \\in C} \\|z_{i} - \\mu_C\\|^2$，使用欧几里得范数。\n\n在初始步骤（每个点构成其自身的簇），考虑在重缩放 $S_{\\alpha}$ 后的两个候选合并：合并 $\\{x_{1}\\}$ 与 $\\{x_{2}\\}$，以及合并 $\\{x_{3}\\}$ 与 $\\{x_{4}\\}$。令 $\\Delta_{1}(\\alpha)$ 表示在 Ward 准则下合并 $\\{x_{1}\\}$ 与 $\\{x_{2}\\}$ 时总 WSS 的增量，令 $\\Delta_{2}(\\alpha)$ 表示合并 $\\{x_{3}\\}$ 与 $\\{x_{4}\\}$ 时的相应增量。\n\n仅从上述定义（WSS 的定义、重缩放 $S_{\\alpha}$ 的效果以及 Ward 方法使用的准则）出发，推导出唯一的正临界缩放因子 $\\alpha^{\\star}$ 的精确解析表达式，在该因子下两个合并成本相等，即 $\\Delta_{1}(\\alpha^{\\star}) = \\Delta_{2}(\\alpha^{\\star})$。提供 $\\alpha^{\\star}$ 的精确值；无需四舍五入。", "solution": "解题过程首先根据 Ward 方法的要求，推导出合并两个单点簇时总簇内平方和 (WSS) 增量的一般表达式。然后，将此表达式应用于具体的缩放后数据点，以求得两个合并成本 $\\Delta_{1}(\\alpha)$ 和 $\\Delta_{2}(\\alpha)$。最后，令这两个成本相等，解出临界缩放因子 $\\alpha^{\\star}$。\n\n在凝聚式聚类的初始步骤，每个数据点构成其自身的簇。对于单点簇 $C_i = \\{z_i\\}$，其均值为 $\\mu_{C_i} = z_i$。因此，该簇的 WSS 为 $\\text{WSS}(C_i) = \\|z_i - \\mu_{C_i}\\|^2 = \\|z_i - z_i\\|^2 = 0$。\n\nWard 方法选择使总 WSS 增量最小化的合并。当合并两个簇 $C_i$ 和 $C_j$ 形成一个新簇 $C_{ij} = C_i \\cup C_j$ 时，总 WSS 的增量由下式给出：\n$$\n\\Delta(C_i, C_j) = \\text{WSS}(C_{ij}) - (\\text{WSS}(C_i) + \\text{WSS}(C_j))\n$$\n由于我们处于初始步骤，我们合并的是两个单点簇，其 WSS 均为 $0$。因此，对于合并 $C_i=\\{z_i\\}$ 和 $C_j=\\{z_j\\}$，WSS 的增量简化为：\n$$\n\\Delta(\\{z_i\\}, \\{z_j\\}) = \\text{WSS}(\\{z_i, z_j\\})\n$$\n让我们计算新的两点簇 $C_{ij} = \\{z_i, z_j\\}$ 的 WSS。该簇的均值为 $\\mu_{ij} = \\frac{z_i + z_j}{2}$。根据定义，WSS 为：\n$$\n\\text{WSS}(C_{ij}) = \\|z_i - \\mu_{ij}\\|^2 + \\|z_j - \\mu_{ij}\\|^2\n$$\n代入均值的表达式：\n$$\n\\text{WSS}(C_{ij}) = \\left\\|z_i - \\frac{z_i + z_j}{2}\\right\\|^2 + \\left\\|z_j - \\frac{z_i + z_j}{2}\\right\\|^2\n$$\n$$\n= \\left\\|\\frac{z_i - z_j}{2}\\right\\|^2 + \\left\\|\\frac{z_j - z_i}{2}\\right\\|^2\n$$\n利用范数的性质 $\\|-\\mathbf{v}\\|^2 = \\|\\mathbf{v}\\|^2$：\n$$\n= \\frac{1}{4}\\|z_i - z_j\\|^2 + \\frac{1}{4}\\|z_i - z_j\\|^2 = \\frac{1}{2}\\|z_i - z_j\\|^2\n$$\n因此，合并两个单点时 WSS 的增量是它们之间欧几里得距离平方的一半。\n\n接下来，我们将缩放变换 $S_{\\alpha}(x,y) = (x, \\alpha y)$ 应用于给定的数据点：\n$x_1 = (0,0) \\quad \\rightarrow \\quad z_1 = S_{\\alpha}(0,0) = (0, 0\\alpha) = (0,0)$\n$x_2 = (0,3) \\quad \\rightarrow \\quad z_2 = S_{\\alpha}(0,3) = (0, 3\\alpha)$\n$x_3 = (4,1) \\quad \\rightarrow \\quad z_3 = S_{\\alpha}(4,1) = (4, 1\\alpha) = (4,\\alpha)$\n$x_4 = (5,1) \\quad \\rightarrow \\quad z_4 = S_{\\alpha}(5,1) = (5, 1\\alpha) = (5,\\alpha)$\n\n现在，我们计算两个合并成本作为 $\\alpha$ 的函数。\n\n1.  **合并 $\\{x_1\\}$ 和 $\\{x_2\\}$ (即 $\\{z_1\\}$ 和 $\\{z_2\\}$) 的成本 $\\Delta_{1}(\\alpha)$：**\n    $$\n    \\Delta_{1}(\\alpha) = \\frac{1}{2}\\|z_1 - z_2\\|^2\n    $$\n    向量差为 $z_1 - z_2 = (0 - 0, 0 - 3\\alpha) = (0, -3\\alpha)$。\n    欧几里得距离的平方为 $\\|z_1 - z_2\\|^2 = 0^2 + (-3\\alpha)^2 = 9\\alpha^2$。\n    因此，成本为：\n    $$\n    \\Delta_{1}(\\alpha) = \\frac{1}{2}(9\\alpha^2) = \\frac{9}{2}\\alpha^2\n    $$\n\n2.  **合并 $\\{x_3\\}$ 和 $\\{x_4\\}$ (即 $\\{z_3\\}$ 和 $\\{z_4\\}$) 的成本 $\\Delta_{2}(\\alpha)$：**\n    $$\n    \\Delta_{2}(\\alpha) = \\frac{1}{2}\\|z_3 - z_4\\|^2\n    $$\n    向量差为 $z_3 - z_4 = (4 - 5, \\alpha - \\alpha) = (-1, 0)$。\n    欧几里得距离的平方为 $\\|z_3 - z_4\\|^2 = (-1)^2 + 0^2 = 1$。\n    因此，成本为：\n    $$\n    \\Delta_{2}(\\alpha) = \\frac{1}{2}(1) = \\frac{1}{2}\n    $$\n\n问题要求解出两个合并成本相等时的临界值 $\\alpha^{\\star}$：$\\Delta_{1}(\\alpha^{\\star}) = \\Delta_{2}(\\alpha^{\\star})$。\n$$\n\\frac{9}{2}(\\alpha^{\\star})^2 = \\frac{1}{2}\n$$\n两边同乘以 $2$ 得：\n$$\n9(\\alpha^{\\star})^2 = 1\n$$\n$$\n(\\alpha^{\\star})^2 = \\frac{1}{9}\n$$\n对两边取平方根，得到两个可能的解：\n$$\n\\alpha^{\\star} = \\pm \\sqrt{\\frac{1}{9}} = \\pm \\frac{1}{3}\n$$\n问题指定 $\\alpha$ 是一个正缩放因子，即 $\\alpha  0$。因此，我们选择正解。\n唯一的正临界缩放因子是 $\\alpha^{\\star} = \\frac{1}{3}$。", "answer": "$$\n\\boxed{\\frac{1}{3}}\n$$", "id": "3097578"}]}