{"hands_on_practices": [{"introduction": "K-中心点聚类的核心在于它能够灵活使用任意距离度量，这使其应用范围超越了仅依赖欧几里得距离的 K-均值。本练习旨在通过动手实践，加深你对不同距离度量如何影响聚类结果的理解。你将针对同一数据集，分别使用曼哈顿距离 ($d_1$)、欧几里得距离 ($d_2$) 和余弦距离 ($d_{\\cos}$) 来寻找最佳中心点，并通过 Jaccard 相异度来量化这些选择对结果的影响。[@problem_id:3135257]", "problem": "您的任务是实现并分析在相同数据集上使用三种不同距离度量的 K-中心点聚类，并量化中心点位置对度量选择的敏感性。这三种度量分别是曼哈顿距离 $d_1$、欧几里得距离 $d_2$ 和余弦角距离 $d_{\\cos}$。此任务的基础是度量空间的定义、一个旨在最小化点到其分配代表点距离之和的聚类目标，以及将中心点定义为受限于实际数据点的代表点。您的程序必须对中心点选择中的任何平局情况使用确定性选择规则：每当出现平局时，始终选择最小的索引。索引必须按照数据点给定的顺序从 $0$ 开始分配。\n\n使用的定义：\n- 两个向量 $x \\in \\mathbb{R}^p$ 和 $y \\in \\mathbb{R}^p$ 之间的曼哈顿距离 $d_1$ 是 $d_1(x,y)=\\sum_{i=1}^p |x_i-y_i|$。\n- 两个向量 $x \\in \\mathbb{R}^p$ 和 $y \\in \\mathbb{R}^p$ 之间的欧几里得距离 $d_2$ 是 $d_2(x,y)=\\sqrt{\\sum_{i=1}^p (x_i-y_i)^2}$。\n- 两个向量 $x \\in \\mathbb{R}^p$ 和 $y \\in \\mathbb{R}^p$ 之间的余弦角距离 $d_{\\cos}$ 是 $d_{\\cos}(x,y)=1-\\dfrac{x \\cdot y}{\\|x\\|\\|y\\|}$，其中 $x \\cdot y$ 是点积，$\\|x\\|$ 是欧几里得范数。如果 $\\|x\\|=0$ 或 $\\|y\\|=0$ 但并非两者都为零，则定义 $d_{\\cos}(x,y)=1$；如果两个范数都为零，则定义 $d_{\\cos}(x,y)=0$。\n\nK-中心点目标是选择一个包含 $k$ 个索引的集合 $M \\subset \\{0,1,\\dots,n-1\\}$，并将每个数据点分配给所选度量下最近的选定中心点，以最小化总的簇内距离。中心点是数据点之一。您必须实现一个确定性过程，该过程从这个目标出发，仅使用经过充分检验的规则和定义，为每个度量和每个数据集找出一组中心点索引。必须通过始终选择最小索引来打破平局，以保证确定性。\n\n在为每个数据集获得三种度量的中心点集合后，使用中心点索引集之间的 Jaccard 集相异性来量化中心点位置对度量选择的敏感性。给定两个集合 $A$ 和 $B$，Jaccard 相似度为 $J(A,B)=\\dfrac{|A \\cap B|}{|A \\cup B|}$，Jaccard 相异性为 $1-J(A,B)$。对于每个数据集，计算度量对 $(d_1,d_2)$、$(d_1,d_{\\cos})$ 和 $(d_2,d_{\\cos})$ 的三个成对相异性。\n\n测试套件：\n- 数据集 $X_1 \\in \\mathbb{R}^{9 \\times 2}$，其中 $k_1=3$：\n$$\nX_1=\\begin{bmatrix}\n-0.5  & 0.2 \\\\\n0.3  & -0.2 \\\\\n0.1  & 0.3 \\\\\n5.1  & 5.2 \\\\\n4.9  & 5.05 \\\\\n5.3  & 4.9 \\\\\n-5.2  & 5.1 \\\\\n-4.8  & 4.9 \\\\\n-5.1  & 5.3\n\\end{bmatrix}, \\quad k_1=3.\n$$\n- 数据集 $X_2 \\in \\mathbb{R}^{5 \\times 2}$，其中 $k_2=1$：\n$$\nX_2=\\begin{bmatrix}\n1  & 0 \\\\\n2  & 0 \\\\\n3  & 0 \\\\\n0  & 10 \\\\\n0  & 8\n\\end{bmatrix}, \\quad k_2=1.\n$$\n- 数据集 $X_3 \\in \\mathbb{R}^{4 \\times 2}$，其中 $k_3=2$：\n$$\nX_3=\\begin{bmatrix}\n1  & 0 \\\\\n2  & 0 \\\\\n3  & 0 \\\\\n10  & 0\n\\end{bmatrix}, \\quad k_3=2.\n$$\n\n您的程序必须：\n- 对于每个数据集 $X_i$ 及其 $k_i$，使用一个根据目标定义推导并符合上述平局打破规则的确定性 K-中心点过程，计算在 $d_1$、$d_2$ 和 $d_{\\cos}$ 下的中心点索引集。\n- 对于每个数据集，按顺序计算度量对 $(d_1,d_2)$、$(d_1,d_{\\cos})$ 和 $(d_2,d_{\\cos})$ 的中心点索引集之间的三个 Jaccard 相异性。\n- 生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，其中每个结果本身是一个包含三个浮点数的列表，对应于该数据集按指定顺序的三个相异性。例如，外层列表为 $\\big[\\,[\\delta_{12}^{(1)},\\delta_{1c}^{(1)},\\delta_{2c}^{(1)}],\\,[\\delta_{12}^{(2)},\\delta_{1c}^{(2)},\\delta_{2c}^{(2)}],\\,[\\delta_{12}^{(3)},\\delta_{1c}^{(3)},\\delta_{2c}^{(3)}]\\,\\big]$，其中 $\\delta_{ab}^{(i)}$ 是在数据集 $i$ 上使用度量 $a$ 和 $b$ 找到的中心点索引集之间的 Jaccard 相异性。将每个浮点数四舍五入到 $3$ 位小数。", "solution": "用户提供的问题被评估为有效。它在统计学习领域，特别是 K-中心点聚类方面，具有科学依据。该问题定义明确、客观且自成体系，为得到唯一的确定性解提供了所有必要的数据、定义和约束。对于给定的数据集大小，穷举搜索方法在计算上是可行的，并保证能找到由 K-中心点目标函数定义的最优解。\n\n### 基于原则的设计\n\n这个问题的核心是为一个给定的包含 $n$ 个点的数据集 $X = \\{x_0, x_1, \\dots, x_{n-1}\\}$ 找到一个最优的 $k$ 个中心点集合，以最小化总成本函数。中心点必须是来自 $X$ 的数据点之一。对于一个选定的包含 $k$ 个中心点索引的集合 $M \\subset \\{0, 1, \\dots, n-1\\}$，其中 $|M|=k$，总的簇内距离之和定义为：\n\n$$\nC(M) = \\sum_{i=0}^{n-1} \\min_{m \\in M} d(x_i, x_{m})\n$$\n\n这里，$d(x_i, x_m)$ 是数据点 $x_i$ 和中心点数据点 $x_m$ 在指定度量下的距离。该任务要求对三种不同的距离度量进行此优化：曼哈顿距离 ($d_1$)、欧几里得距离 ($d_2$) 和余弦距离 ($d_{\\cos}$)。\n\n找到最小化 $C(M)$ 的全局最优中心点集 $M^*$ 是一个 NP-难问题。然而，所提供的数据集足够小，可以对所有可能的 $k$ 个中心点组合进行穷举搜索。此类组合的数量由二项式系数 $\\binom{n}{k}$ 给出。对于给定的数据集：\n- $X_1$: $n=9, k=3 \\implies \\binom{9}{3} = 84$ 种组合。\n- $X_2$: $n=5, k=1 \\implies \\binom{5}{1} = 5$ 种组合。\n- $X_3$: $n=4, k=2 \\implies \\binom{4}{2} = 6$ 种组合。\n\n由于这些数字很小，穷举搜索在计算上是易于处理的，并保证能找到成本函数 $C(M)$ 的全局最小值，从而满足问题中要求直接从目标定义推导过程的要求。\n\n解决方案按以下步骤进行：\n\n1.  **距离函数**：根据定义实现所需的三种距离度量：\n    -   曼哈顿距离：$d_1(x,y)=\\sum_{i=1}^p |x_i-y_i|$\n    -   欧几里得距离：$d_2(x,y)=\\sqrt{\\sum_{i=1}^p (x_i-y_i)^2}$\n    -   余弦角距离：$d_{\\cos}(x,y)=1-\\frac{x \\cdot y}{\\|x\\|\\|y\\|}$，并按规定特殊处理零向量。\n\n2.  **最优中心点搜索**：对于每个数据集和每个度量：\n    a.  为给定的度量预先计算 $n \\times n$ 距离矩阵，以优化后续的成本计算。\n    b.  从集合 $\\{0, 1, \\dots, n-1\\}$ 中生成所有可能的 $k$ 个索引的组合。\n    c.  对于每种组合（一个候选中心点集 $M$）：\n        i.  通过对 $n$ 个数据点中每个点到其在 $M$ 中最近的中心点的距离求和，来计算总成本 $C(M)$。\n    d.  识别产生最小成本的中心点集 $M^*$。为确保在出现平局（即多个集合产生相同的最小成本）时的确定性，我们依赖于标准库函数（如 Python 的 `itertools.combinations`）生成的组合的字典序。选择遇到的第一个达到最小成本的集合。这是通过仅在找到严格更小的成本时才更新已找到的最佳集合来实现的。\n\n3.  **敏感性分析**：在为给定数据集确定了三种度量（$M_{d_1}$、$M_{d_2}$、$M_{d_{\\cos}}$）的最优中心点索引集后：\n    a.  计算三对集合的 Jaccard 相异性：$(M_{d_1}, M_{d_2})$、$(M_{d_1}, M_{d_{\\cos}})$ 和 $(M_{d_2}, M_{d_{\\cos}})$。\n    b.  两个集合 $A$ 和 $B$ 之间的 Jaccard 相异性由 $1 - J(A,B) = 1 - \\frac{|A \\cap B|}{|A \\cup B|}$ 给出。这量化了因度量变化而导致的中心点位置的差异。\n\n4.  **输出格式化**：收集每个数据集计算出的相异性，并根据指定的输出格式将其格式化为浮点数列表的列表，四舍五入到三位小数。\n\n这种结构化的方法通过直接优化目标函数来确保正确性，通过明确定义的平局打破程序来保证确定性，并满足问题陈述的所有要求。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\nfrom itertools import combinations\n\ndef solve():\n    \"\"\"\n    Main function to solve the k-medoids problem for the given test suite.\n    \"\"\"\n\n    def d_manhattan(p1, p2):\n        \"\"\"Computes Manhattan distance.\"\"\"\n        return np.sum(np.abs(p1 - p2))\n\n    def d_euclidean(p1, p2):\n        \"\"\"Computes Euclidean distance.\"\"\"\n        return np.linalg.norm(p1 - p2)\n\n    def d_cosine(p1, p2):\n        \"\"\"Computes Cosine angular distance with specified handling for zero vectors.\"\"\"\n        norm_p1 = np.linalg.norm(p1)\n        norm_p2 = np.linalg.norm(p2)\n\n        if norm_p1 == 0 and norm_p2 == 0:\n            return 0.0\n        if norm_p1 == 0 or norm_p2 == 0:\n            return 1.0\n        \n        dot_product = np.dot(p1, p2)\n        cos_sim = dot_product / (norm_p1 * norm_p2)\n        # Clamp to handle potential floating point inaccuracies\n        cos_sim = np.clip(cos_sim, -1.0, 1.0)\n        return 1.0 - cos_sim\n\n    def find_optimal_medoids(data, k, metric_func):\n        \"\"\"\n        Finds the optimal set of k medoids using an exhaustive search.\n        \"\"\"\n        n = data.shape[0]\n        indices = range(n)\n        \n        dist_matrix = np.zeros((n, n))\n        for i in range(n):\n            for j in range(i, n):\n                d = metric_func(data[i], data[j])\n                dist_matrix[i, j] = d\n                dist_matrix[j, i] = d\n\n        min_total_cost = float('inf')\n        best_medoids = None\n\n        for medoid_indices_tuple in combinations(indices, k):\n            current_total_cost = 0.0\n            for i in indices:\n                min_dist_to_medoid = min(dist_matrix[i, m] for m in medoid_indices_tuple)\n                current_total_cost += min_dist_to_medoid\n            \n            if current_total_cost  min_total_cost:\n                min_total_cost = current_total_cost\n                best_medoids = medoid_indices_tuple\n        \n        return set(best_medoids)\n\n    def jaccard_dissimilarity(set1, set2):\n        \"\"\"Computes the Jaccard dissimilarity between two sets.\"\"\"\n        intersection_size = len(set1.intersection(set2))\n        union_size = len(set1.union(set2))\n        if union_size == 0:\n            return 0.0\n        return 1.0 - (intersection_size / union_size)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (np.array([\n            [-0.5, 0.2], [0.3, -0.2], [0.1, 0.3],\n            [5.1, 5.2], [4.9, 5.05], [5.3, 4.9],\n            [-5.2, 5.1], [-4.8, 4.9], [-5.1, 5.3]\n        ]), 3),\n        (np.array([\n            [1, 0], [2, 0], [3, 0],\n            [0, 10], [0, 8]\n        ]), 1),\n        (np.array([\n            [1, 0], [2, 0], [3, 0], [10, 0]\n        ]), 2)\n    ]\n\n    metrics = {\n        'd1': d_manhattan,\n        'd2': d_euclidean,\n        'dcos': d_cosine\n    }\n    \n    all_results = []\n\n    for data, k in test_cases:\n        medoid_sets = {}\n        for name, func in metrics.items():\n            medoid_sets[name] = find_optimal_medoids(data, k, func)\n        \n        m1 = medoid_sets['d1']\n        m2 = medoid_sets['d2']\n        m_cos = medoid_sets['dcos']\n\n        dis_1_2 = jaccard_dissimilarity(m1, m2)\n        dis_1_cos = jaccard_dissimilarity(m1, m_cos)\n        dis_2_cos = jaccard_dissimilarity(m2, m_cos)\n        \n        dataset_results = [round(dis_1_2, 3), round(dis_1_cos, 3), round(dis_2_cos, 3)]\n        all_results.append(dataset_results)\n    \n    # Format the final output string precisely\n    output_parts = []\n    for res_list in all_results:\n        formatted_floats = [f\"{x:.3f}\" for x in res_list]\n        list_str = f\"[{','.join(formatted_floats)}]\"\n        output_parts.append(list_str)\n        \n    final_output_str = f\"[{','.join(output_parts)}]\"\n    print(final_output_str)\n\nsolve()\n```", "id": "3135257"}, {"introduction": "K-中心点算法对异常值具有稳健性，一个关键原因在于其目标函数在隔离异常点和保持簇内紧凑性之间的权衡。本练习将通过一个精心设计的思想实验，让你定量地探索这一特性。你将分析在数据集中加入一个远离所有其他点的异常点时，该点在何种条件下会“自立门户”成为一个独立的簇，从而揭示 K-中心点目标函数的内在工作机制。[@problem_id:3135235]", "problem": "考虑在实数轴上使用欧几里得距离的 K-中心点聚类目标，其中中心点被限制为从数据点中选择。设原始数据集为多重集 $X = \\{-1, 0, 1, 9, 10, 11\\}$，并固定 $k = 2$。一个位于位置 $s \\in \\mathbb{R}$ 的新点 $z$ 被加入，形成 $X' = X \\cup \\{z\\}$。K-中心点目标旨在寻找一个基数为 $k$ 的子集 $M \\subset X'$，以及将 $X'$ 中的每个点分配给 $M$ 中最近的中心点，从而最小化总距离和。从基本定义（即 K-中心点目标等于所有点到其最近的选定中心点的距离之和）出发，确定阈值距离 $D^*$，使得如果 $r = \\min\\{|s|, |s - 10|\\} > D^*$，全局最优的 K-中心点解会使用 $z$ 作为中心点之一（从而 $z$ 形成一个单例簇）。请将您的最终答案表示为一个精确的数（无需四舍五入）。", "solution": "用户希望找到一个阈值距离 $D^*$，对于一个添加到数据集 $X$ 的新点 $z$ 而言，如果该点与原始簇的距离大于 $D^*$，它就会成为 $k=2$ 聚类中的两个中心点之一。\n\n首先，我们来建立必要的定义。\n原始数据集是多重集 $X = \\{-1, 0, 1, 9, 10, 11\\}$。\n中心点的数量是 $k=2$。\n一个位于位置 $s \\in \\mathbb{R}$ 的新点 $z$ 被加入，形成新的数据集 $X' = X \\cup \\{z\\}$。\n中心点必须从 $X'$ 中的点中选择。\n目标是找到一个基数为 $|M|=k=2$ 的中心点集 $M \\subset X'$，以最小化 $X'$ 中每个点到其在 $M$ 中最近中心点的欧几里得距离的总和。成本函数为 $C(M) = \\sum_{p \\in X'} \\min_{m \\in M} |p-m|$。\n变量 $r$ 定义为 $r = \\min\\{|s|, |s - 10|\\}$。我们寻求一个阈值 $D^*$，使得对于任何满足 $r > D^*$ 的 $s$，全局最优中心点集 $M_{opt}$ 必须包含 $z$。\n\n这个问题需要比较在两种情况下可实现的最小成本：\n1.  情况1：两个中心点仅从原始集合 $X$ 中选择。设此最小成本为 $C_{no-z}$。\n2.  情况2：一个中心点是新点 $z$，另一个从 $X$ 中选择。设此最小成本为 $C_{with-z}$。\n\n$z$ 成为最优解一部分的条件是 $C_{with-z}  C_{no-z}$。我们需要找到关于 $r$ 的阈值 $D^*$，以保证这个不等式成立。\n\n我们来分析情况1：$z$ 不是中心点。\n中心点集为 $M = \\{m_1, m_2\\}$，其中 $m_1, m_2 \\in X$。成本是：\n$$C(M) = \\sum_{p \\in X'} \\min_{m \\in M} |p-m| = \\left( \\sum_{x \\in X} \\min(|x-m_1|, |x-m_2|) \\right) + \\min(|s-m_1|, |s-m_2|)$$\n数据集 $X$ 由两个不同的簇组成：$X_1 = \\{-1, 0, 1\\}$ 和 $X_2 = \\{9, 10, 11\\}$。直观上，为了最小化 $X$ 中各点的距离和，两个中心点应该从每个簇中各选一个。对于一条线上的点集，最好的单个中心点是其中位数。\n对于 $X_1$，中位数是 $0$。距离和为 $|-1-0| + |0-0| + |1-0| = 2$。\n对于 $X_2$，中位数是 $10$。距离和为 $|9-10| + |10-10| + |11-10| = 2$。\n我们选择中心点集 $M_A = \\{0, 10\\}$。来自 $X$ 中各点的成本贡献是：\n$$\\sum_{x \\in X} \\min(|x-0|, |x-10|) = \\sum_{x \\in X_1} |x-0| + \\sum_{x \\in X_2} |x-10| = 2 + 2 = 4$$\n从 $X$ 中选择任何其他两个中心点都会导致 $X$ 中各点的成本更高。例如，对于 $M=\\{1,9\\}$，$X$ 上的成本是 $(\\sum_{x \\in X_1} |x-1|) + (\\sum_{x \\in X_2} |x-9|) = (2+1+0) + (0+1+2) = 6$。\n当新点 $z$ 远离 $X$ 时（即对于大的 $r$），项 $\\sum_{x \\in X} \\min(|x-m_1|, |x-m_2|)$ 在为 $X$ 聚类选择中心点时起主导作用。点对 $\\{0,10\\}$ 使该项最小化。\n新点 $z$ 在中心点为 $\\{0, 10\\}$ 时的成本分量是 $\\min(|s-0|, |s-10|)$，这正是 $r$ 的定义。\n因此，选择此中心点的总成本是 $C(M_A) = 4 + r$。\n对于大的 $r$，从 $X$ 中选择其他中心点会导致更高的成本。例如，考虑 $M_B = \\{0, 11\\}$，$X$ 上的成本是 $\\sum_{x \\in X}\\min(|x-0|,|x-11|) = (1+0+1) + (2+1+0) = 5$。对于大的正数 $s$，$z$ 的成本将是 $|s-11| = s-11$。总成本是 $5+s-11 = s-6$。对于 $M_A=\\{0,10\\}$，成本是 $4+|s-10|=4+s-10=s-6$。在这个极限下，成本是相等的。对大的负数 $s$ 进行类似分析表明，像 $\\{-1,10\\}$ 这样的点对也产生相同的最小成本 $4+r$。因此，我们可以确信地断言，对于大的 $r$：\n$$C_{no-z} = 4 + r$$\n\n现在，我们来分析情况2：$z$ 是一个中心点。\n中心点集为 $M = \\{m_1, z\\}$，其中 $m_1 \\in X$。成本是：\n$$C(M) = \\sum_{p \\in X'} \\min(|p-m_1|, |p-s|)$$\n由于 $z$ 是一个中心点，它到最近中心点的距离为 $0$。成本简化为对 $X$ 中各点的求和：\n$$C_{with-z} = \\min_{m_1 \\in X} \\left( \\sum_{x \\in X} \\min(|x-m_1|, |x-s|) \\right)$$\n问题要求的是关于 $r$ 的阈值 $D^*$。我们考虑 $r$ 很大的情况。大的 $r$ 意味着 $s$ 远离区间 $[0, 10]$。\n如果 $s$ 离 $X$ 很远，那么对于任何点 $x \\in X$ 和任何潜在的中心点 $m_1 \\in X$，距离 $|x-m_1|$ 将显著小于 $|x-s|$。\n形式上，对于任何 $x, m_1 \\in X$，我们有 $|x-m_1| \\leq |11 - (-1)| = 12$。对于足够大的 $|s|$，距离 $|x-s|$ 将会大于这个值。例如，如果 $s > 11$，$X$ 中离 $s$ 最近的点是 $11$。条件 $|x-m_1||x-s|$ 需要对所有的 $x, m_1 \\in X$ 成立。最坏的情况是 $x=11$ 和 $m_1=-1$：我们需要 $|11-(-1)|  |11-s|$，所以 $12  s-11$，即 $s > 23$。如果 $s  -1$，最坏的情况是 $x=-1, m_1=11$：我们需要 $|-1-11|  |-1-s|$，所以 $12  |-1-s| = -s-1$，即 $s  -13$。\n如果对于足够大的 $D^*$ 有 $r > D^*$，则该条件成立，并且 $X$ 中的每个点 $x$ 都将被分配给中心点 $m_1$。\n成本表达式于是简化为寻找集合 $X$ 的 1-中心点：\n$$C_{with-z} = \\min_{m_1 \\in X} \\sum_{x \\in X} |x-m_1|$$\n我们需要为每个可能的中心点 $m_1 \\in X$ 计算这个和。设 $S(m_1) = \\sum_{x \\in X} |x-m_1|$。\n- $S(-1) = (0) + (1) + (2) + (10) + (11) + (12) = 36$\n- $S(0) = (1) + (0) + (1) + (9) + (10) + (11) = 32$\n- $S(1) = (2) + (1) + (0) + (8) + (9) + (10) = 30$\n- $S(9) = (10) + (9) + (8) + (0) + (1) + (2) = 30$\n- $S(10) = (11) + (10) + (9) + (1) + (0) + (1) = 32$\n- $S(11) = (12) + (11) + (10) + (2) + (1) + (0) = 36$\n最小值为 $30$，当中心点 $m_1$ 选为 $1$ 或 $9$ 时出现。\n所以，对于足够大的 $r$，当 $z$ 是一个中心点时的最小成本是：\n$$C_{with-z} = 30$$\n\n最后，我们确定阈值 $D^*$。\n全局最优解使用 $z$ 作为中心点的条件是 $C_{with-z}  C_{no-z}$。\n代入导出的成本：\n$$30  4 + r$$\n$$26  r$$\n这给出了一个阈值 $D^*=26$。对于 $r>26$，选择 $z$ 作为中心点的成本 ($30$) 严格小于不选择它的成本 ($4+r > 4+26 = 30$)。\n用于简化成本函数的逻辑对于 $r>26$ 是有效的。例如，$r>26$ 意味着 $s>36$ 或 $s-16$。这两种情况都满足条件（$s>23$ 或 $s-13$），即 $X$ 中的所有点都比到 $z$ 更接近内部中心点 $m_1$。\n\n因此，阈值距离是 $D^*=26$。", "answer": "$$\n\\boxed{26}\n$$", "id": "3135235"}, {"introduction": "在将理论算法转化为可靠代码的过程中，处理“平局”（ties）是确保结果确定性和可复现性的关键。本练习将引导你关注 K-medoids 实现中的一个重要细节：平局决胜规则的设计。你将基于一个预先计算好的相异度矩阵，探索两种不同的平局决胜策略如何影响中心点的最终选择和聚类分配，从而体会到严谨的算法设计在实践中的重要性。[@problem_id:3135303]", "problem": "给定一个预先计算好的相异度矩阵 $D \\in \\mathbb{R}^{n \\times n}$，其条目对称、非负，并且对于所有 $i \\in \\{0,\\dots,n-1\\}$ 都有 $D_{i,i} = 0$。在 K-中心点聚类中，选择一个中心点集合 $M \\subseteq \\{0,\\dots,n-1\\}$ 且 $|M| = k$，以最小化聚类目标\n$$\nJ(M) \\equiv \\sum_{i=0}^{n-1} \\min_{m \\in M} D_{i,m}.\n$$\n当 $D$ 包含相同值时，存在两种不同的模糊性来源，必须通过明确的平局打破规则来解决：\n- 分配平局：对于给定的 $M$，如果对于某个索引 $i$，存在多个中心点 $m \\in M$ 使得 $D_{i,m}$ 达到相同的最小值，则发生分配平局。每当发生此类平局时，分配平局打破规则 $T_a$ 必须指定哪个中心点接收 $i$。\n- 中心点集平局：如果存在多个中心点集 $M$ 最小化 $J(M)$，则发生中心点集平局。中心点集平局打破规则 $T_m$ 必须在最小化集合中指定返回哪个中心点集。\n\n设计两种确定性的平局打破策略，每种策略都解决这两种类型的平局：\n- 策略 $\\mathcal{A}$：$T_m$ 选择字典序最小的中心点集（当中心点索引按升序排列时），$T_a$ 将存在平局的点分配给最小的中心点索引。\n- 策略 $\\mathcal{B}$：$T_m$ 选择字典序最大的中心点集（当中心点索引按升序排列时），$T_a$ 将存在平局的点分配给最大的中心点索引。\n\n从 K-中心点目标 $J(M)$ 的核心定义和集合 $\\{0,\\dots,n-1\\}$ 上的隶属关系属性出发，实现一个精确求解器，该求解器能够：\n- 枚举所有 $|M| = k$ 的中心点集 $M$，并使用给定的 $D$ 计算 $J(M)$。\n- 应用指定策略中的 $T_m$ 从中心点集最小化器中进行选择。\n- 使用指定策略中的 $T_a$ 生成每个索引 $i$ 到 $M$ 中一个中心点的最终分配。\n\n使用以下测试套件，演示平局打破如何影响中心点身份和 $J(M)$ 的稳定性。对于每个测试用例，使用提供的 $D$ 和 $k$，在策略 $\\mathcal{A}$ 和 $\\mathcal{B}$ 下运行求解器，并报告结果。\n\n测试套件：\n- 案例 1（存在多个最优中心点集的理想情况）：设 $n = 6$, $k = 2$, 且\n$$\nD_1 = \\begin{pmatrix}\n0   1   1   4   4   4 \\\\\n1   0   1   4   4   4 \\\\\n1   1   0   4   4   4 \\\\\n4   4   4   0   1   1 \\\\\n4   4   4   1   0   1 \\\\\n4   4   4   1   1   0 \\\\\n\\end{pmatrix}.\n$$\n- 案例 2（$k=1$ 且所有可能的中心点之间存在对称平局的边界条件）：设 $n = 4$, $k = 1$, 且\n$$\nD_2 = \\begin{pmatrix}\n0   1   2   1 \\\\\n1   0   1   2 \\\\\n2   1   0   1 \\\\\n1   2   1   0 \\\\\n\\end{pmatrix}.\n$$\n- 案例 3（存在重复点和分配平局的边缘情况）：设 $n = 5$, $k = 2$, 且\n$$\nD_3 = \\begin{pmatrix}\n0   0   2   2   3 \\\\\n0   0   2   2   3 \\\\\n2   2   0   0   3 \\\\\n2   2   0   0   3 \\\\\n3   3   3   3   0 \\\\\n\\end{pmatrix}.\n$$\n\n对于每个案例，您的程序必须计算并返回一个包含以下内容的单一列表：\n- 策略 $\\mathcal{A}$ 下的中心点索引，以升序列表形式表示。\n- 策略 $\\mathcal{A}$ 下的分配向量，以列表形式表示，其中第 $i$ 个条目是分配给 $i$ 的中心点索引。\n- 策略 $\\mathcal{A}$ 下的目标值 $J(M)$，为一个整数。\n- 策略 $\\mathcal{B}$ 下的中心点索引，以升序列表形式表示。\n- 策略 $\\mathcal{B}$ 下的分配向量，以列表形式表示，其中第 $i$ 个条目是分配给 $i$ 的中心点索引。\n- 策略 $\\mathcal{B}$ 下的目标值 $J(M)$，为一个整数。\n- 一个布尔值，指示在此案例中两种策略下的 $J(M)$ 是否相同。\n- 一个布尔值，指示在此案例中两种策略下的中心点身份是否相同。\n\n您的程序应生成单行输出，其中包含三个案例的聚合结果，格式为方括号内包含的逗号分隔列表：\n$$\n[\\text{case1\\_result},\\text{case2\\_result},\\text{case3\\_result}],\n$$\n其中每个 $\\text{caseX\\_result}$ 本身就是上述的列表。不应打印任何额外文本。", "solution": "在尝试任何解决方案之前，需对问题陈述进行验证。\n\n### 第一步：提取已知信息\n\n1.  **目标函数**：需要最小化的 K-中心点聚类目标是 $J(M) \\equiv \\sum_{i=0}^{n-1} \\min_{m \\in M} D_{i,m}$，其中 $M$ 是一个包含 $k$ 个中心点索引的集合。\n2.  **相异度矩阵**：提供一个矩阵 $D \\in \\mathbb{R}^{n \\times n}$，该矩阵是对称的（$D_{i,j} = D_{j,i}$），具有非负条目（$D_{i,j} \\ge 0$），且对角线为零（$D_{i,i} = 0$）。\n3.  **平局来源**：\n    -   **分配平局**：对于给定的中心点集 $M$，一个点 $i$ 与 $M$ 中的多个中心点具有相同的最小相异度。\n    -   **中心点集平局**：多个不同的中心点集 $M$ 产生相同的最小目标函数值 $J(M)$。\n4.  **平局打破策略**：\n    -   **策略 $\\mathcal{A}$**：\n        -   $T_m$ (中心点集)：在最小化器中选择字典序最小的中心点集。\n        -   $T_a$ (分配)：将存在平局的点分配给索引最小的中心点。\n    -   **策略 $\\mathcal{B}$**：\n        -   $T_m$ (中心点集)：在最小化器中选择字典序最大的中心点集。\n        -   $T_a$ (分配)：将存在平局的点分配给索引最大的中心点。\n5.  **任务**：实现一个精确求解器，该求解器枚举所有可能的中心点集，应用指定的平局打破策略，并确定最终的中心点集和分配。\n6.  **测试用例**：\n    -   **案例 1**：$n = 6$, $k = 2$, $D_1 = \\begin{pmatrix} 0   1   1   4   4   4 \\\\ 1   0   1   4   4   4 \\\\ 1   1   0   4   4   4 \\\\ 4   4   4   0   1   1 \\\\ 4   4   4   1   0   1 \\\\ 4   4   4   1   1   0 \\end{pmatrix}$。\n    -   **案例 2**：$n = 4$, $k = 1$, $D_2 = \\begin{pmatrix} 0   1   2   1 \\\\ 1   0   1   2 \\\\ 2   1   0   1 \\\\ 1   2   1   0 \\end{pmatrix}$。\n    -   **案例 3**：$n = 5$, $k = 2$, $D_3 = \\begin{pmatrix} 0   0   2   2   3 \\\\ 0   0   2   2   3 \\\\ 2   2   0   0   3 \\\\ 2   2   0   0   3 \\\\ 3   3   3   3   0 \\end{pmatrix}$。\n7.  **要求输出**：对于每个案例，一个包含八个元素的列表：策略 $\\mathcal{A}$ 下的中心点、策略 $\\mathcal{A}$ 下的分配、策略 $\\mathcal{A}$ 下的目标值、策略 $\\mathcal{B}$ 下的中心点、策略 $\\mathcal{B}$ 下的分配、策略 $\\mathcal{B}$ 下的目标值、一个指示目标值是否相等的布尔值，以及一个指示中心点集是否相等的布尔值。最终输出必须是包含这三个案例的结果列表的单行。\n\n### 第二步：使用提取的已知信息进行验证\n\n根据验证标准对问题进行分析。\n\n-   **科学依据**：该问题植根于统计学习这一成熟领域，特别是非监督聚类。K-中心点算法及其目标函数 $J(M)$ 是标准概念。相异度矩阵 $D$ 的属性与其数学定义一致。该问题是科学合理的。\n-   **适定性**：任务是通过穷举枚举找到一个最优中心点集。搜索空间由大小为 $n$ 的集合的所有 $k$ 元素子集组成，是有限的。对于任何给定的中心点集，目标函数 $J(M)$ 都有唯一定义。提供的平局打破规则 $T_m$ 和 $T_a$ 是确定且无歧义的，确保对于每种策略（$\\mathcal{A}$ 和 $\\mathcal{B}$），都存在一个单一、唯一的解。因此，该问题是适定的。\n-   **客观性**：该问题使用精确的数学语言和定义进行表述。所有术语都有明确定义，测试用例也用具体的数值数据指定，没有主观解释的余地。\n-   **未发现缺陷**：该问题不违反任何基本原则，不是隐喻性的，包含了所有必要信息，在给定约束（$n$ 很小）下计算上是可行的，并且结构清晰。\n\n### 第三步：结论与行动\n\n问题有效。将按要求开发并实现解决方案。\n\n### 解决方案推导\n\n该解决方案需要一个精确算法，对所有可能的中心点集进行穷举搜索。其设计遵循以下原则。\n\n**1. 候选中心点集的组合枚举**\n所有可能的中心点集是索引集 $\\{0, 1, \\dots, n-1\\}$ 的所有 $k$ 元素子集的集合。这个候选中心点集集合（表示为 $\\mathcal{C}_M$）可以被系统地生成。该搜索空间的大小由二项式系数 $\\binom{n}{k} = \\frac{n!}{k!(n-k)!}$ 给出。对于测试套件中较小的 $n$ 和 $k$ 值，这种枚举在计算上是可行的。\n\n**2. 目标函数的计算**\n对于每个候选中心点集 $M \\in \\mathcal{C}_M$，必须计算目标函数 $J(M)$。其定义为 $J(M) = \\sum_{i=0}^{n-1} \\min_{m \\in M} D_{i,m}$。该计算过程包括：对于每个数据点 $i$，找到其与 $M$ 中所选中心点的最小相异度，然后将这些最小相异度在所有数据点上求和。\n\n**3. 最小化与中心点集平局打破 ($T_m$)**\n在为所有 $M \\in \\mathcal{C}_M$ 计算 $J(M)$ 之后，确定最小目标值 $J_{\\min} = \\min_{M \\in \\mathcal{C}_M} J(M)$。可能存在多个中心点集达到此最小值。设最优中心点集为 $\\mathcal{M}_{\\text{opt}} = \\{M \\in \\mathcal{C}_M \\mid J(M) = J_{\\min}\\}$。如果 $|\\mathcal{M}_{\\text{opt}}| > 1$，则发生中心点集平局。应用平局打破规则 $T_m$ 从 $\\mathcal{M}_{\\text{opt}}$ 中选择一个中心点集：\n-   在策略 $\\mathcal{A}$ 下，选择字典序最小的集合。假设每个集合内的索引已排序，这对应于使用标准元组比较找到 $\\min(\\mathcal{M}_{\\text{opt}})$。\n-   在策略 $\\mathcal{B}$ 下，选择字典序最大的集合，即 $\\max(\\mathcal{M}_{\\text{opt}})$。\n\n设唯一选定的中心点集为 $M_{\\text{final}}$。\n\n**4. 最终分配与分配平局打破 ($T_a$)**\n确定最终中心点集 $M_{\\text{final}}$ 后，将每个数据点 $i \\in \\{0, \\dots, n-1\\}$ 分配给 $M_{\\text{final}}$ 中的一个中心点。点 $i$ 的分配是一个中心点 $m_i^* \\in M_{\\text{final}}$，使得 $D_{i, m_i^*} = \\min_{m \\in M_{\\text{final}}} D_{i,m}$。如果满足此条件的中心点集 $M_i^{\\text{tie}} = \\{m \\in M_{\\text{final}} \\mid D_{i,m} = \\min_{m' \\in M_{\\text{final}}} D_{i,m'}\\}$ 包含多个元素，则发生分配平局。分配平局打破规则 $T_a$ 对此进行解决：\n-   在策略 $\\mathcal{A}$ 下，点 $i$ 被分配给 $M_i^{\\text{tie}}$ 中索引最小的中心点，因此 $m_i^* = \\min(M_i^{\\text{tie}})$。\n-   在策略 $\\mathcal{B}$ 下，点 $i$ 被分配给 $M_i^{\\text{tie}}$ 中索引最大的中心点，因此 $m_i^* = \\max(M_i^{\\text{tie}})$。\n\n此过程产生一个最终的分配向量，其中第 $i$ 个元素是点 $i$ 所分配到的中心点的索引。\n\n该算法通过将此逻辑封装到一个函数中来执行，该函数可为每个策略和每个测试用例运行。然后按指定要求对结果进行聚合和格式化。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom itertools import combinations\n\ndef solve_k_medoids_exact(D, k, policy):\n    \"\"\"\n    Implements an exact k-medoids solver with specified tie-breaking policies.\n\n    Args:\n        D (np.ndarray): A precomputed n x n dissimilarity matrix.\n        k (int): The number of medoids.\n        policy (str): The tie-breaking policy, either 'A' or 'B'.\n            - Policy 'A': Lexicographically smallest for medoid-set ties,\n                          smallest index for assignment ties.\n            - Policy 'B': Lexicographically largest for medoid-set ties,\n                          largest index for assignment ties.\n\n    Returns:\n        tuple: A tuple containing:\n            - list: The final medoid indices, sorted.\n            - list: The assignment vector for each point.\n            - int: The objective function value.\n    \"\"\"\n    n = D.shape[0]\n    indices = range(n)\n    \n    # Generate all candidate medoid sets\n    candidate_medoid_sets = list(combinations(indices, k))\n    \n    min_objective_val = float('inf')\n    optimal_medoid_sets = []\n    \n    # Step 1  2: Enumerate and calculate objective function J(M)\n    for medoids_tuple in candidate_medoid_sets:\n        medoids = list(medoids_tuple)\n        \n        # For each point, find the dissimilarity to the nearest medoid\n        dissimilarities = np.min(D[:, medoids], axis=1)\n        objective_val = np.sum(dissimilarities)\n        \n        # Check for a new minimum or a tie\n        if objective_val  min_objective_val:\n            min_objective_val = objective_val\n            optimal_medoid_sets = [medoids_tuple]\n        elif objective_val == min_objective_val:\n            optimal_medoid_sets.append(medoids_tuple)\n\n    # Step 3: Apply medoid-set tie-breaking (Tm)\n    if policy == 'A':\n        final_medoids_tuple = min(optimal_medoid_sets)\n    elif policy == 'B':\n        final_medoids_tuple = max(optimal_medoid_sets)\n    else:\n        raise ValueError(\"Policy must be 'A' or 'B'\")\n        \n    final_medoids = list(final_medoids_tuple)\n\n    # Step 4: Apply assignment tie-breaking (Ta)\n    assignments = np.zeros(n, dtype=int)\n    for i in range(n):\n        # Dissimilarities from point i to each chosen medoid\n        d_to_medoids = D[i, final_medoids]\n        min_dist = np.min(d_to_medoids)\n        \n        # Find all medoids that achieve this minimum distance\n        tying_medoid_indices_in_list = np.where(d_to_medoids == min_dist)[0]\n        tying_medoids = [final_medoids[j] for j in tying_medoid_indices_in_list]\n        \n        if policy == 'A':\n            assignments[i] = min(tying_medoids)\n        else: # Policy 'B'\n            assignments[i] = max(tying_medoids)\n            \n    # The objective value is an integer as per problem statement's Ds\n    return sorted(final_medoids), assignments.tolist(), int(round(min_objective_val))\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results in the required format.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"n\": 6, \"k\": 2,\n            \"D\": np.array([\n                [0, 1, 1, 4, 4, 4],\n                [1, 0, 1, 4, 4, 4],\n                [1, 1, 0, 4, 4, 4],\n                [4, 4, 4, 0, 1, 1],\n                [4, 4, 4, 1, 0, 1],\n                [4, 4, 4, 1, 1, 0],\n            ])\n        },\n        {\n            \"n\": 4, \"k\": 1,\n            \"D\": np.array([\n                [0, 1, 2, 1],\n                [1, 0, 1, 2],\n                [2, 1, 0, 1],\n                [1, 2, 1, 0],\n            ])\n        },\n        {\n            \"n\": 5, \"k\": 2,\n            \"D\": np.array([\n                [0, 0, 2, 2, 3],\n                [0, 0, 2, 2, 3],\n                [2, 2, 0, 0, 3],\n                [2, 2, 0, 0, 3],\n                [3, 3, 3, 3, 0],\n            ])\n        }\n    ]\n\n    all_case_results = []\n    for case in test_cases:\n        D_matrix, k_val = case[\"D\"], case[\"k\"]\n        \n        medoids_A, assignments_A, J_A = solve_k_medoids_exact(D_matrix, k_val, 'A')\n        medoids_B, assignments_B, J_B = solve_k_medoids_exact(D_matrix, k_val, 'B')\n        \n        j_equal = (J_A == J_B)\n        medoids_equal = (medoids_A == medoids_B)\n        \n        case_result = [\n            medoids_A,\n            assignments_A,\n            J_A,\n            medoids_B,\n            assignments_B,\n            J_B,\n            j_equal,\n            medoids_equal\n        ]\n        all_case_results.append(case_result)\n\n    # Custom string formatting to match the required output (no spaces in lists)\n    def format_item(item):\n        if isinstance(item, list):\n            return f\"[{','.join(map(str, item))}]\"\n        return str(item).lower() if isinstance(item, bool) else str(item)\n\n    case_strings = []\n    for case_res in all_case_results:\n        item_strings = [format_item(item) for item in case_res]\n        case_strings.append(f\"[{','.join(item_strings)}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(case_strings)}]\")\n\nsolve()\n```", "id": "3135303"}]}