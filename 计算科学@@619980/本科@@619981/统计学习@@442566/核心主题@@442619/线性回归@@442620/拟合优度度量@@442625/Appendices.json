{"hands_on_practices": [{"introduction": "在现实世界的分类任务中，我们经常遇到类别不平衡的数据集，此时单一的准确率指标可能会产生误导。本练习将通过一个多类别分类的场景，指导你计算和解读宏平均$F_1$分数、微平均$F_1$分数和对数损失(log-loss)，从而对分类器的性能有一个更全面和细致的评估。通过亲手计算，你将深刻理解不同指标在评估不平衡数据时的侧重点和独特价值 [@problem_id:3147853]。", "problem": "一个单标签、多类分类器在一个包含 $N=100$ 个观测值的数据集上进行训练，这些观测值分为 A、B 和 C 三个类别。真实的类别数量为 $|A|=80$，$|B|=15$ 和 $|C|=5$。对于每个观测值，该分类器都会生成一个预测的类别标签和一个关于各个类别的概率分布。\n\n其在测试集上的整体表现如下：\n- 对于真实类别为 $A$ 的观测值：$70$ 个被预测为 $A$，$10$ 个被预测为 $B$。\n- 对于真实类别为 $B$ 的观测值：$8$ 个被预测为 $B$，$7$ 个被预测为 $A$。\n- 对于真实类别为 $C$ 的观测值：$1$ 个被预测为 $C$，$4$ 个被预测为 $A$。\n\n对于每组观测值，分配给真实类别的概率（即分配给正确标签的概率质量，无论预测标签是什么）如下：\n- 真实为 $A$，预测为 $A$：每个观测值在类别 $A$ 上的概率为 $0.90$。\n- 真实为 $A$，预测为 $B$：每个观测值在类别 $A$ 上的概率为 $0.05$。\n- 真实为 $B$，预测为 $B$：每个观测值在类别 $B$ 上的概率为 $0.85$。\n- 真实为 $B$，预测为 $A$：每个观测值在类别 $B$ 上的概率为 $0.10$。\n- 真实为 $C$，预测为 $C$：这一个实例在类别 $C$ 上的概率为 $0.80$。\n- 真实为 $C$，预测为 $A$：每个观测值在类别 $C$ 上的概率为 $0.02$。\n\n仅使用每个类别的精确率、每个类别的召回率、$F_1$分数、宏平均、微平均和平均负对数似然（对数损失，使用自然对数）的基本定义，确定哪个选项正确描述了宏 $F_1$、微 $F_1$ 和对数损失，以及它们在给定的类别不平衡情况下揭示了关于拟合质量的什么信息。\n\nA. 宏 $F_1 \\approx 0.563$ 远低于微 $F_1 \\approx 0.790$，且对数损失约为 $0.706$，这表明尽管微观性能很高，但对少数类的过度自信的错误抬高了对数损失。\n\nB. 宏 $F_1 \\approx 0.790$ 等于微 $F_1$，且对数损失约为 $0.300$，表明该分类器在所有类别上表现同样出色。\n\nC. 宏 $F_1 \\approx 0.563$ 且微 $F_1$ 也约为 $0.563$，对数损失约为 $0.200$，因此两种 $F_1$ 变体和对数损失都反映了相同的情况。\n\nD. 宏 $F_1 \\approx 0.790$ 高于微 $F_1 \\approx 0.563$，且对数损失约为 $0.706$，这意味着宏平均降低了对不平衡错误的敏感性。", "solution": "问题陈述已经过评估并被证实是有效的。它在科学上基于统计学习的原理，提法恰当，数据充分且一致，并以客观语言表述。因此，我们可以开始推导解答。\n\n首要步骤是构建混淆矩阵 $M$，其中条目 $M_{ij}$ 表示真实类别为 $i$ 但被预测为类别 $j$ 的观测值数量。问题提供了以下数据：\n总观测值 $N=100$。\n真实类别计数：$|A|=80$，$|B|=15$，$|C|=5$。\n\n根据分类器表现的描述：\n- 对于真实类别为 $A$ 的观测值：$70$ 个预测为 $A$，$10$ 个预测为 $B$。\n- 对于真实类别为 $B$ 的观测值：$8$ 个预测为 $B$，$7$ 个预测为 $A$。\n- 对于真实类别为 $C$ 的观测值：$1$ 个预测为 $C$，$4$ 个预测为 $A$。\n\n这导出了以下混淆矩阵：\n$$\nM = \n\\begin{pmatrix}\n  \\text{预测 } A & \\text{预测 } B & \\text{预测 } C \\\\\n\\text{真实 } A & 70 & 10 & 0 \\\\\n\\text{真实 } B & 7 & 8 & 0 \\\\\n\\text{真实 } C & 4 & 0 & 1 \n\\end{pmatrix}\n$$\n行和正确地与真实类别计数相匹配（$70+10=80$，$7+8=15$，$4+1=5$）。列和得出每个类别的总预测数：\n- 预测为 $A$：$70+7+4 = 81$\n- 预测为 $B$：$10+8+0 = 18$\n- 预测为 $C$：$0+0+1 = 1$\n总观测值为 $81+18+1=100$，证实了数据的一致性。\n\n根据混淆矩阵，我们为每个类别 $k \\in \\{A, B, C\\}$ 计算真阳性（$TP_k$）、假阳性（$FP_k$）和假阴性（$FN_k$）。\n\n对于类别 $A$：\n- $TP_A = 70$\n- $FP_A = 7+4 = 11$\n- $FN_A = 10+0 = 10$\n\n对于类别 $B$：\n- $TP_B = 8$\n- $FP_B = 10+0 = 10$\n- $FN_B = 7+0 = 7$\n\n对于类别 $C$：\n- $TP_C = 1$\n- $FP_C = 0+0 = 0$\n- $FN_C = 4+0 = 4$\n\n接下来，我们计算每个类别的精确率（$P_k$）和召回率（$R_k$）：\n$P_k = \\frac{TP_k}{TP_k + FP_k}$ 和 $R_k = \\frac{TP_k}{TP_k + FN_k}$。\n\n- 类别 $A$：\n  $P_A = \\frac{70}{70+11} = \\frac{70}{81}$\n  $R_A = \\frac{70}{70+10} = \\frac{70}{80} = \\frac{7}{8} = 0.875$\n- 类别 $B$：\n  $P_B = \\frac{8}{8+10} = \\frac{8}{18} = \\frac{4}{9}$\n  $R_B = \\frac{8}{8+7} = \\frac{8}{15}$\n- 类别 $C$：\n  $P_C = \\frac{1}{1+0} = 1$\n  $R_C = \\frac{1}{1+4} = \\frac{1}{5} = 0.2$\n\n每个类别的 $F_1$ 分数是精确率和召回率的调和平均数：$F_{1,k} = 2 \\frac{P_k R_k}{P_k + R_k}$。\n- $F_{1,A} = 2 \\frac{(70/81)(7/8)}{(70/81)+(7/8)} = 2 \\frac{490/648}{560/648 + 567/648} = 2 \\frac{490}{1127} = \\frac{980}{1127} \\approx 0.8696$\n- $F_{1,B} = 2 \\frac{(4/9)(8/15)}{(4/9)+(8/15)} = 2 \\frac{32/135}{60/135 + 72/135} = 2 \\frac{32}{132} = \\frac{64}{132} = \\frac{16}{33} \\approx 0.4848$\n- $F_{1,C} = 2 \\frac{1 \\cdot (1/5)}{1 + (1/5)} = 2 \\frac{1/5}{6/5} = \\frac{2}{6} = \\frac{1}{3} \\approx 0.3333$\n\n现在我们可以计算宏平均和微平均的 $F_1$ 分数。\n\n**宏 $F_1$ 分数**是各类别 $F_1$ 分数的未加权平均值。\n$$\n\\text{Macro } F_1 = \\frac{F_{1,A} + F_{1,B} + F_{1,C}}{3} = \\frac{1}{3} \\left(\\frac{980}{1127} + \\frac{16}{33} + \\frac{1}{3}\\right) \\approx \\frac{0.8696 + 0.4848 + 0.3333}{3} = \\frac{1.6877}{3} \\approx 0.5626\n$$\n\n**微 $F_1$ 分数**需要微平均精确率和召回率，它们是通过对所有的 $TP$、$FP$ 和 $FN$求和来计算的。\n- $\\sum TP_k = 70+8+1 = 79$\n- $\\sum FP_k = 11+10+0 = 21$\n- $\\sum FN_k = 10+7+4 = 21$\n$P_{micro} = \\frac{\\sum TP_k}{\\sum TP_k + \\sum FP_k} = \\frac{79}{79+21} = \\frac{79}{100} = 0.79$\n$R_{micro} = \\frac{\\sum TP_k}{\\sum TP_k + \\sum FN_k} = \\frac{79}{79+21} = \\frac{79}{100} = 0.79$\n注意，在多类分类中，微精确率、微召回率和总体准确率是相同的，均为 $\\frac{\\text{正确分类数}}{\\text{总数}}$。\n$$\n\\text{Micro } F_1 = 2 \\frac{P_{micro} R_{micro}}{P_{micro} + R_{micro}} = \\frac{2 \\cdot 0.79 \\cdot 0.79}{0.79+0.79} = 0.79\n$$\n\n最后，我们使用自然对数计算平均负对数似然（对数损失）$L$。公式为 $L = -\\frac{1}{N} \\sum_{i=1}^N \\ln(p_{i, \\text{true}})$，其中 $p_{i, \\text{true}}$ 是模型为观测值 $i$ 的真实类别所分配的概率。我们对指定组别的对数概率进行求和：\n- 真实为 $A$，预测为 $A$：$70$ 个实例，$p=0.90$。贡献：$70 \\times \\ln(0.90)$。\n- 真实为 $A$，预测为 $B$：$10$ 个实例，$p=0.05$。贡献：$10 \\times \\ln(0.05)$。\n- 真实为 $B$，预测为 $B$：$8$ 个实例，$p=0.85$。贡献：$8 \\times \\ln(0.85)$。\n- 真实为 $B$，预测为 $A$：$7$ 个实例，$p=0.10$。贡献：$7 \\times \\ln(0.10)$。\n- 真实为 $C$，预测为 $C$：$1$ 个实例，$p=0.80$。贡献：$1 \\times \\ln(0.80)$。\n- 真实为 $C$，预测为 $A$：$4$ 个实例，$p=0.02$。贡献：$4 \\times \\ln(0.02)$。\n\n$$\n\\begin{align*} L &= -\\frac{1}{100} [70\\ln(0.90) + 10\\ln(0.05) + 8\\ln(0.85) + 7\\ln(0.10) + 1\\ln(0.80) + 4\\ln(0.02)] \\\\\n&\\approx -\\frac{1}{100} [70(-0.1054) + 10(-2.9957) + 8(-0.1625) + 7(-2.3026) + 1(-0.2231) + 4(-3.9120)] \\\\\n&\\approx -\\frac{1}{100} [-7.378 - 29.957 - 1.300 - 16.118 - 0.223 - 15.648] \\\\\n&\\approx -\\frac{1}{100} [-70.624] \\approx 0.706\n\\end{align*}\n$$\n计算指标总结：\n- 宏 $F_1 \\approx 0.563$\n- 微 $F_1 = 0.790$\n- 对数损失 $\\approx 0.706$\n\n现在我们来评估每个选项。\n\nA. 宏 $F_1 \\approx 0.563$ 远低于微 $F_1 \\approx 0.790$，且对数损失约为 $0.706$，这表明尽管微观性能很高，但对少数类的过度自信的错误抬高了对数损失。\n宏 $F_1$、微 $F_1$ 和对数损失的计算值都是正确的。其解释也是合理的。宏 $F_1$ 之所以低，是因为它对少数类 $B$（$F_1$ 分数 $\\approx 0.485$）和 $C$（$F_1$ 分数 $\\approx 0.333$）的极差表现给予了同等权重。微 $F_1$ 之所以高，是因为它主要由模型在多数类 $A$（占数据总量的 $80\\%$）上的良好表现所主导。对数损失被那些模型为真实类别分配了极低概率的错误显著抬高（例如，在类别 $C$ 上的 $4$ 个错误，其概率 $p=0.02$，对总损失 $0.706$ 的贡献为 $-\\frac{4}{100}\\ln(0.02) \\approx 0.156$，这仅仅 $4\\%$ 的数据却贡献了不成比例的巨大损失）。这些确实是针对少数类的过度自信的错误。该陈述是对模型性能正确且富有洞察力的总结。**正确。**\n\nB. 宏 $F_1 \\approx 0.790$ 等于微 $F_1$，且对数损失约为 $0.300$，表明该分类器在所有类别上表现同样出色。\n宏 $F_1$ 和对数损失的值不正确。此外，宏 $F_1$ 等于微 $F_1$ 的说法是错误的，分类器在各类别上表现一致出色的说法也是错误的。各类别 $F_1$ 分数（$0.870, 0.485, 0.333$）显示出高度不均匀的性能。**不正确。**\n\nC. 宏 $F_1 \\approx 0.563$ 且微 $F_1$ 也约为 $0.563$，对数损失约为 $0.200$，因此两种 $F_1$ 变体和对数损失都反映了相同的情况。\n微 $F_1$ 的值不正确；它应为 $0.790$，而不是 $0.563$。对数损失的值也不正确。两种 $F_1$ 变体反映了相同情况的前提是错误的；它们的差异才是此处的关键洞见。**不正确。**\n\nD. 宏 $F_1 \\approx 0.790$ 高于微 $F_1 \\approx 0.563$，且对数损失约为 $0.706$，这意味着宏平均降低了对不平衡错误的敏感性。\n宏 $F_1$ 和微 $F_1$ 的值被对调了。宏 $F_1 \\approx 0.563$ 而微 $F_1$ 是 $0.790$。其解释也正好相反；宏平均*增加*了对少数类性能的敏感性，而不是降低它。**不正确。**", "answer": "$$\\boxed{A}$$", "id": "3147853"}, {"introduction": "当数据具有层次或分组结构时，例如嵌套在学校中的学生，简单的线性模型就不再适用，我们需要线性混合效应模型(LMM)等更复杂的工具。那么，我们该如何衡量这类复杂模型的拟合优度呢？本练习将经典的决定系数$R^2$推广到混合模型中，让你计算边际$R^2$和条件$R^2$，从而学会区分和量化模型中固定效应和随机效应各自解释的变异量 [@problem_id:3147863]。", "problem": "一个研究团队使用一个线性混合效应模型（LMM）来拟合跨学校测量的学生考试分数，其中每个学生只属于一所学校。模型为\n$$\ny_{ij} = \\beta_0 + \\beta_1 x_{ij} + b_j + \\varepsilon_{ij},\n$$\n其中，特定于学校的随机截距为 $b_j \\sim \\mathcal{N}(0,\\sigma_b^2)$，独立残差为 $\\varepsilon_{ij} \\sim \\mathcal{N}(0,\\sigma_\\varepsilon^2)$，且 $b_j$ 与 $\\varepsilon_{ij}$ 相互独立。此处，$i$ 是学校 $j$ 内学生的索引，$x_{ij}$ 是一个中心化的预测变量（在所有观测值上的均值为零）。拟合后，团队报告：\n- 固定效应线性预测变量 $\\hat{\\eta}_{ij}^{(F)} = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_{ij}$ 在所有观测值上的样本方差为 $\\widehat{\\sigma}_F^2 = 6.0$，\n- 估计的随机截距方差为 $\\widehat{\\sigma}_b^2 = 4.0$，\n- 估计的残差方差为 $\\widehat{\\sigma}_\\varepsilon^2 = 10.0$。\n\n使用决定系数（$R^2$）的方差分解定义，该定义区分了固定效应和随机效应的贡献，请选择正确报告边际 $R^2$ 和条件 $R^2$ 的选项，并为每个值对固定效应与整个模型的拟合优度意味着什么提供有效的解释。\n\nA. 边际 $R^2 = 0.30$，条件 $R^2 = 0.50$。解释：仅固定效应解释了拟合模型所隐含的总方差的 $30\\%$；当同时考虑固定效应和随机效应时，模型解释了总方差的 $50\\%$。因此，固定效应部分具有中等的解释能力，而随机截距捕捉了额外的校际异质性，从而改善了整体拟合。\n\nB. 边际 $R^2 = 0.375$，条件 $R^2 = 0.50$。解释：在仅考虑残差噪声后，固定效应解释了 $37.5\\%$ 的变异性，添加随机截距将解释的变异性提高到总体的 $50\\%$，因此固定效应是拟合的主要来源。\n\nC. 边际 $R^2 = 0.60$，条件 $R^2 = 0.80$。解释：固定效应本身解释了 $60\\%$ 的观测结果，包含随机截距后解释了 $80\\%$，表明这是一个由固定效应主导的极佳拟合。\n\nD. 边际 $R^2 = 0.30$，条件 $R^2 = 0.70$。解释：固定效应解释了 $30\\%$，随机效应单独解释了 $40\\%$，因此随机效应对拟合优度的贡献大于固定效应，它们共同解释了总方差的 $70\\%$。", "solution": "首先验证问题陈述，以确保其科学上合理、问题定义良好且客观。\n\n### 步骤 1：提取已知信息\n-   **模型：** 一个线性混合效应模型（LMM）被指定为 $y_{ij} = \\beta_0 + \\beta_1 x_{ij} + b_j + \\varepsilon_{ij}$。\n-   **索引：** $i$ 代表学生，$j$ 代表学校。\n-   **预测变量：** $x_{ij}$ 是一个中心化的预测变量，意味着其样本均值为零。\n-   **随机效应：** 特定于学校的随机截距为 $b_j \\sim \\mathcal{N}(0, \\sigma_b^2)$。\n-   **残差：** 残差为 $\\varepsilon_{ij} \\sim \\mathcal{N}(0, \\sigma_\\varepsilon^2)$。\n-   **独立性：** $b_j$ 和 $\\varepsilon_{ij}$ 相互独立。\n-   **估计的方差分量：**\n    1.  固定效应线性预测变量的样本方差，$\\widehat{\\sigma}_F^2 = \\text{Var}(\\hat{\\eta}_{ij}^{(F)}) = \\text{Var}(\\hat{\\beta}_0 + \\hat{\\beta}_1 x_{ij})$，为 $\\widehat{\\sigma}_F^2 = 6.0$。\n    2.  估计的随机截距方差为 $\\widehat{\\sigma}_b^2 = 4.0$。\n    3.  估计的残差方差为 $\\widehat{\\sigma}_\\varepsilon^2 = 10.0$。\n-   **目标：** 计算边际 $R^2$ 和条件 $R^2$，并解释它们对拟合优度的意义。\n\n### 步骤 2：使用提取的已知信息进行验证\n该问题基于线性混合效应模型的既定统计框架。将 LMM 的 $R^2$ 分解为边际和条件 $R^2$（通过分解方差分量来定义）是统计学习和生态学中一种标准且被广泛接受的方法（例如，Nakagawa & Schielzeth, 2013）。所提供的模型结构是一个典型的随机截距模型。给定的方差分量数值均为正数，符合要求，并且没有内部矛盾。该问题是自洽的、客观的、定义良好的，并根据所提供的数据和标准定义承认一个唯一的解。\n\n### 步骤 3：结论与行动\n问题是**有效的**。将推导解答。\n\n### 解答推导\n线性混合效应模型的拟合优度可以使用决定系数 $R^2$ 进行评估，并将其扩展为边际和条件版本。这些指标将结果变量的总方差分解为可归因于模型的固定效应、随机效应和残差误差的分量。\n\n根据模型，响应变量 $y_{ij}$ 的总方差是其组成部分方差的总和，因为它们是独立的：\n$$\n\\text{Var}(y_{ij}) = \\text{Var}(\\beta_0 + \\beta_1 x_{ij} + b_j + \\varepsilon_{ij}) = \\underbrace{\\text{Var}(\\beta_0 + \\beta_1 x_{ij})}_{\\sigma_F^2} + \\underbrace{\\text{Var}(b_j)}_{\\sigma_b^2} + \\underbrace{\\text{Var}(\\varepsilon_{ij})}_{\\sigma_\\varepsilon^2}\n$$\n使用提供的估计值，响应变量的总方差为：\n$$\n\\widehat{\\sigma}_{\\text{Total}}^2 = \\widehat{\\sigma}_F^2 + \\widehat{\\sigma}_b^2 + \\widehat{\\sigma}_\\varepsilon^2\n$$\n代入给定值：\n$$\n\\widehat{\\sigma}_{\\text{Total}}^2 = 6.0 + 4.0 + 10.0 = 20.0\n$$\n\n**边际决定系数 ($R_m^2$)**\n边际 $R^2$ 量化了仅由固定效应解释的总方差的比例。其计算公式为：\n$$\nR_m^2 = \\frac{\\text{由固定效应解释的方差}}{\\text{总方差}} = \\frac{\\widehat{\\sigma}_F^2}{\\widehat{\\sigma}_F^2 + \\widehat{\\sigma}_b^2 + \\widehat{\\sigma}_\\varepsilon^2}\n$$\n使用给定值：\n$$\nR_m^2 = \\frac{6.0}{20.0} = 0.30\n$$\n这意味着固定预测变量 $x_{ij}$ 和总体截距共同解释了学生考试分数方差的 $30\\%$。\n\n**条件决定系数 ($R_c^2$)**\n条件 $R^2$ 量化了由固定效应和随机效应共同解释的总方差的比例。其计算公式为：\n$$\nR_c^2 = \\frac{\\text{由固定和随机效应解释的方差}}{\\text{总方差}} = \\frac{\\widehat{\\sigma}_F^2 + \\widehat{\\sigma}_b^2}{\\widehat{\\sigma}_F^2 + \\widehat{\\sigma}_b^2 + \\widehat{\\sigma}_\\varepsilon^2}\n$$\n使用给定值：\n$$\nR_c^2 = \\frac{6.0 + 4.0}{20.0} = \\frac{10.0}{20.0} = 0.50\n$$\n这意味着完整的模型，在考虑了预测变量 $x_{ij}$ 和学校层面的差异（随机截距 $b_j$）后，解释了考试分数方差的 $50\\%$。差值 $R_c^2 - R_m^2 = 0.50 - 0.30 = 0.20$ 是专门归因于随机效应（即按学校聚类）的方差比例，这与 $\\widehat{\\sigma}_b^2 / \\widehat{\\sigma}_{\\text{Total}}^2 = 4.0/20.0 = 0.20$ 一致。\n\n### 评估选项\n\n**A. 边际 $R^2 = 0.30$，条件 $R^2 = 0.50$。解释：仅固定效应解释了拟合模型所隐含的总方差的 $30\\%$；当同时考虑固定效应和随机效应时，模型解释了总方差的 $50\\%$。因此，固定效应部分具有中等的解释能力，而随机截距捕捉了额外的校际异质性，从而改善了整体拟合。**\n- 计算出的值 $R_m^2 = 0.30$ 和 $R_c^2 = 0.50$ 是正确的。\n- 解释是精确且逻辑上合理的。它正确地陈述了每个指标所代表的含义。定性总结（“中等的解释能力”，“捕捉额外的校际异质性”）是对结果的合理而准确的评估。\n- **结论：正确**\n\n**B. 边际 $R^2 = 0.375$，条件 $R^2 = 0.50$。解释：在仅考虑残差噪声后，固定效应解释了 $37.5\\%$ 的变异性，添加随机截距将解释的变异性提高到总体的 $50\\%$，因此固定效应是拟合的主要来源。**\n- 边际 $R^2$ 的值是错误的。值 $0.375$ 似乎源于一个错误的公式，可能是 $\\widehat{\\sigma}_F^2 / (\\widehat{\\sigma}_F^2 + \\widehat{\\sigma}_\\varepsilon^2) = 6.0 / (6.0 + 10.0) = 6/16 = 0.375$，这个公式错误地从代表总方差的分母中省略了随机效应方差。\n- **结论：错误**\n\n**C. 边际 $R^2 = 0.60$，条件 $R^2 = 0.80$。解释：固定效应本身解释了 $60\\%$ 的观测结果，包含随机截距后解释了 $80\\%$，表明这是一个由固定效应主导的极佳拟合。**\n- 边际和条件 $R^2$ 的值都是错误的。值 $0.60$ 似乎是通过计算由固定效应解释的*已解释*方差的比例得出的，即 $\\widehat{\\sigma}_F^2 / (\\widehat{\\sigma}_F^2 + \\widehat{\\sigma}_b^2) = 6.0 / (6.0 + 4.0) = 0.60$，但这不是边际 $R^2$ 的定义。条件 $R^2$ 的值 $0.80$ 不对应任何标准计算。\n- **结论：错误**\n\n**D. 边际 $R^2 = 0.30$，条件 $R^2 = 0.70$。解释：固定效应解释了 $30\\%$，随机效应单独解释了 $40\\%$，因此随机效应对拟合优度的贡献大于固定效应，它们共同解释了总方差的 $70\\%$。**\n- 边际 $R^2$ 的值是正确的，但条件 $R^2$ 是错误的。我们的计算得出 $R_c^2 = 0.50$。\n- 解释中包含多个错误。随机效应解释了 $\\widehat{\\sigma}_b^2 / \\widehat{\\sigma}_{\\text{Total}}^2 = 4.0/20.0 = 20\\%$，而不是 $40\\%$。固定效应对已解释方差的贡献（$\\widehat{\\sigma}_F^2 = 6.0$）大于随机效应（$\\widehat{\\sigma}_b^2 = 4.0$）。合并解释的方差是 $50\\%$，而不是 $70\\%$。\n- **结论：错误**", "answer": "$$\\boxed{A}$$", "id": "3147863"}, {"introduction": "一个高质量的模型不仅要“准”，还要“稳”，即其预测结果不应因输入特征的微小、无意义扰动而发生剧烈变化。本练习引入了对抗性机器学习中的一个前沿概念，让你使用快速梯度符号法(FGSM)来量化模型的敏感度或稳健性。通过亲手构造针对模型的“最差情况”微小扰动，并衡量其导致的损失函数增量，你将学会一种超越传统静态评估的、动态“压力测试”模型的方法 [@problem_id:3147847]。", "problem": "考虑一个固定的预测模型，其参数保持不变，以及一个由特征向量和标签组成的数据集。目标是量化已拟合模型对于在范数约束下直接应用于输入特征的微小、最坏情况扰动的敏感性。该敏感性通过未使用扰动和使用对抗性扰动的输入之间的损失变化来衡量，其中回归任务使用均方根误差 (RMSE)，二元分类任务使用逻辑对数损失。均方根误差 (RMSE) 定义为 $$\\mathrm{RMSE} = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}\\left(\\hat{y}_{i} - y_{i}\\right)^{2}},$$ 其中 $\\hat{y}_{i}$ 是模型预测值，$y_{i}$ 是真实响应。对于预测为 $\\hat{y}_{i} = x_{i}^{\\top} w$ 的线性回归模型，其中 $x_{i} \\in \\mathbb{R}^{d}$ 是样本 $i$ 的特征向量，$w \\in \\mathbb{R}^{d}$ 是一个固定的参数向量，RMSE 是其拟合优度度量。对于二元分类，其预测 $p_{i} = \\sigma(x_{i}^{\\top} w)$（其中 $\\sigma(z) = \\frac{1}{1 + e^{-z}}$）的逻辑对数损失（也称为负对数似然或交叉熵）为 $$\\mathcal{L}_{\\mathrm{log}} = -\\frac{1}{n} \\sum_{i=1}^{n} \\left[ y_{i} \\log p_{i} + (1 - y_{i}) \\log (1 - p_{i}) \\right],$$ 其中 $y_{i} \\in \\{0,1\\}$ 是标签，$p_{i}$ 是预测概率。\n\n您将使用快速梯度符号法 (Fast Gradient Sign Method, FGSM) 构建对抗性扰动。该方法定义为所选损失函数对每个样本特征向量的梯度的逐元素符号，通过一个非负标量界 $\\epsilon$ 进行缩放，并在 $\\ell_{\\infty}$ 范数约束下应用 $$\\|\\Delta x_{i}\\|_{\\infty} \\le \\epsilon.$$ 模型参数 $w$ 是固定的（不进行重新拟合）。具体来说，对于使用 RMSE 的回归问题，令 $e_{i} = \\hat{y}_{i} - y_{i}$ 且 $$\\mathrm{MSE} = \\frac{1}{n}\\sum_{i=1}^{n} e_{i}^{2}.$$ RMSE 相对于特征向量 $x_{i}$ 的梯度是 $$\\nabla_{x_{i}} \\mathrm{RMSE} = \\frac{e_{i}}{n \\sqrt{\\mathrm{MSE}}} w.$$ 由于乘法标量 $\\frac{e_{i}}{n \\sqrt{\\mathrm{MSE}}}$ 的符号取决于 $e_{i}$，因此 RMSE 的快速梯度符号法方向与 $e_{i} w$ 的逐元素符号一致。因此，回归问题的对抗性扰动为 $$\\Delta x_{i} = \\epsilon \\cdot \\mathrm{sign}\\!\\left(e_{i} w\\right).$$ 对于使用逻辑对数损失的二元分类，其相对于 $x_{i}$ 的梯度是 $$\\nabla_{x_{i}} \\mathcal{L}_{\\mathrm{log}} = \\frac{1}{n} (p_{i} - y_{i}) w,$$ 因此对抗性扰动为 $$\\Delta x_{i} = \\epsilon \\cdot \\mathrm{sign}\\!\\left((p_{i} - y_{i}) w\\right).$$ 每个样本经对抗性扰动后的特征为 $(x_{i} + \\Delta x_{i})$，敏感性为所选损失的非负变化量：对抗性损失减去基线损失。\n\n实现一个程序，为每个提供的测试用例执行以下步骤：\n1. 使用 $X \\in \\mathbb{R}^{n \\times d}$、$y$ 和固定的 $w$ 计算基线损失（回归任务为 RMSE，分类任务为逻辑对数损失）。\n2. 使用给定的 $\\epsilon$ 对每个样本应用上述的 FGSM 方法来构建 $\\Delta X$。\n3. 在 $(X + \\Delta X)$ 上计算对抗性损失。\n4. 输出对抗性损失与基线损失之间的标量差值。\n\n将所有计算都视为无单位的标量；不涉及物理单位。在应用对数函数之前，应通过将 $p_{i}$ 裁剪到区间 $[10^{-15}, 1 - 10^{-15}]$ 内来对二元分类的概率进行数值稳定。\n\n测试套件：\n- 案例1（回归，一般情况）：$X = \\begin{bmatrix}1.0 & 2.0\\\\ 0.5 & -1.0\\\\ 3.0 & 0.0\\end{bmatrix}$，$y = \\begin{bmatrix}4.0\\\\ -1.0\\\\ 5.0\\end{bmatrix}$，$w = \\begin{bmatrix}1.2\\\\ 0.8\\end{bmatrix}$，$\\epsilon = 0.1$。\n- 案例2（回归，边界情况 $\\epsilon = 0$）：$X = \\begin{bmatrix}2.0 & -0.5\\\\ -1.0 & 1.0\\end{bmatrix}$，$y = \\begin{bmatrix}1.0\\\\ 0.0\\end{bmatrix}$，$w = \\begin{bmatrix}0.5\\\\ -0.5\\end{bmatrix}$，$\\epsilon = 0.0$。\n- 案例3（分类，一般情况）：$X = \\begin{bmatrix}0.2 & -0.1\\\\ 1.5 & 0.3\\\\ -0.3 & 0.8\\end{bmatrix}$，$y = \\begin{bmatrix}0\\\\ 1\\\\ 1\\end{bmatrix}$，$w = \\begin{bmatrix}0.7\\\\ -0.5\\end{bmatrix}$，$\\epsilon = 0.2$。\n- 案例4（分类，零权重边缘情况）：$X = \\begin{bmatrix}1.0 & 2.0\\\\ -0.5 & 0.5\\end{bmatrix}$，$y = \\begin{bmatrix}0\\\\ 1\\end{bmatrix}$，$w = \\begin{bmatrix}0.0\\\\ 0.0\\end{bmatrix}$，$\\epsilon = 0.5$。\n- 案例5（分类，大 $\\epsilon$ 压力测试）：$X = \\begin{bmatrix}2.0 & -1.0\\\\ -1.0 & 2.5\\\\ 0.3 & -0.7\\\\ 1.0 & 1.0\\end{bmatrix}$，$y = \\begin{bmatrix}1\\\\ 0\\\\ 0\\\\ 1\\end{bmatrix}$，$w = \\begin{bmatrix}1.0\\\\ 1.5\\end{bmatrix}$，$\\epsilon = 2.0$。\n\n您的程序应生成单行输出，其中包含所有五个测试用例的结果，结果为逗号分隔的列表，并用方括号括起来，顺序与上面列出的案例顺序一致，例如：“[result1,result2,result3,result4,result5]”。每个结果必须是一个实数（浮点数），等于相应案例的对抗性损失减去基线损失。不应打印任何其他文本。", "solution": "该问题要求计算模型对其输入特征的对抗性扰动的敏感性。当使用快速梯度符号法 (FGSM) 修改输入时，这种敏感性被量化为拟合优度度量（损失函数）的变化。模型参数 $w$ 保持不变。该过程涉及两种类型的模型：使用均方根误差 (RMSE) 损失的线性回归，以及使用逻辑对数损失进行二元分类的逻辑回归。\n\n该方法的核心是为输入数据矩阵 $X \\in \\mathbb{R}^{n \\times d}$ 计算一个扰动 $\\Delta X$，其中 $n$ 是样本数量，$d$ 是特征数量。每个样本 $x_i$ 的扰动源自损失函数 $\\mathcal{L}$ 相对于 $x_i$ 的梯度，并受 $\\ell_{\\infty}$ 范数约束：\n$$\n\\Delta x_{i} = \\epsilon \\cdot \\mathrm{sign}(\\nabla_{x_{i}} \\mathcal{L})\n$$\n其中 $\\epsilon \\geq 0$ 是扰动幅度。每个测试用例的最终输出是差值 $\\mathcal{L}_{\\mathrm{adv}} - \\mathcal{L}_{\\mathrm{base}}$，其中 $\\mathcal{L}_{\\mathrm{base}}$ 是原始数据 $X$ 上的损失，$\\mathcal{L}_{\\mathrm{adv}}$ 是扰动后数据 $X + \\Delta X$ 上的损失。\n\n首先，我们分析回归案例。模型对样本 $x_i$ 的预测是 $\\hat{y}_i = x_i^\\top w$。损失函数是均方根误差 (RMSE)：\n$$\n\\mathrm{RMSE} = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}\\left(\\hat{y}_{i} - y_{i}\\right)^{2}} = \\sqrt{\\mathrm{MSE}}\n$$\n其中 $y_i$ 是真实的连续值响应。RMSE 相对于特征向量 $x_i$ 的梯度由下式给出：\n$$\n\\nabla_{x_{i}} \\mathrm{RMSE} = \\frac{e_{i}}{n \\sqrt{\\mathrm{MSE}}} w\n$$\n其中 $e_i = \\hat{y}_i - y_i$ 是样本 $i$ 的预测误差。由于标量因子 $\\frac{1}{n \\sqrt{\\mathrm{MSE}}}$ 是正的（对于 $\\mathrm{MSE} > 0$），梯度的符号由 $e_i w$ 的符号决定。因此，第 $i$ 个样本特征向量 $x_i$ 的扰动是：\n$$\n\\Delta x_i = \\epsilon \\cdot \\mathrm{sign}(e_i w)\n$$\n为了同时对所有样本实施此操作，我们计算预测值 $\\hat{y} = Xw$ 和误差向量 $e = \\hat{y} - y$。扰动矩阵 $\\Delta X \\in \\mathbb{R}^{n \\times d}$ 可以通过将误差向量 $e$（一个 $n \\times 1$ 的列向量）与参数向量 $w^\\top$（一个 $1 \\times d$ 的行向量）进行广播，取其逐元素符号，然后乘以 $\\epsilon$ 来计算：\n$$\n\\Delta X = \\epsilon \\cdot \\mathrm{sign}(e w^\\top)\n$$\n基线损失 $\\mathrm{RMSE}_{\\mathrm{base}}$ 在 $X$ 上计算。对抗性特征是 $X_{\\mathrm{adv}} = X + \\Delta X$。对抗性损失 $\\mathrm{RMSE}_{\\mathrm{adv}}$ 使用 $X_{\\mathrm{adv}}$ 计算。结果是 $\\mathrm{RMSE}_{\\mathrm{adv}} - \\mathrm{RMSE}_{\\mathrm{base}}$。\n\n接下来，我们分析二元分类案例。模型使用 sigmoid 函数预测类别 1 的概率，$p_i = \\sigma(x_i^\\top w)$，其中 $\\sigma(z) = (1 + e^{-z})^{-1}$。损失函数是逻辑对数损失（或交叉熵）：\n$$\n\\mathcal{L}_{\\mathrm{log}} = -\\frac{1}{n} \\sum_{i=1}^{n} \\left[ y_{i} \\log p_{i} + (1 - y_{i}) \\log (1 - p_{i}) \\right]\n$$\n其中 $y_i \\in \\{0, 1\\}$ 是真实的二元标签。对数损失相对于 $x_i$ 的梯度由下式给出：\n$$\n\\nabla_{x_{i}} \\mathcal{L}_{\\mathrm{log}} = \\frac{1}{n} (p_{i} - y_{i}) w\n$$\n因子 $1/n$ 是一个正标量，因此梯度的符号由 $(p_i - y_i)w$ 的符号决定。样本 $i$ 的扰动为：\n$$\n\\Delta x_i = \\epsilon \\cdot \\mathrm{sign}((p_i - y_i)w)\n$$\n与回归案例类似，我们可以为所有样本计算扰动矩阵 $\\Delta X$。设 $p$ 为概率向量，$y$ 为真实标签向量。\n$$\n\\Delta X = \\epsilon \\cdot \\mathrm{sign}((p - y)w^\\top)\n$$\n基线损失 $\\mathcal{L}_{\\mathrm{base}}$ 使用原始数据 $X$ 计算。为确保数值稳定性，在将预测概率 $p_i$ 传递给对数函数之前，会将其裁剪到范围 $[10^{-15}, 1 - 10^{-15}]$ 内。对抗性特征是 $X_{\\mathrm{adv}} = X + \\Delta X$，对抗性损失 $\\mathcal{L}_{\\mathrm{adv}}$ 在这些特征上计算（对新的概率应用裁剪）。结果是 $\\mathcal{L}_{\\mathrm{adv}} - \\mathcal{L}_{\\mathrm{base}}$。\n\n在 $\\epsilon = 0$ 或梯度为零向量（例如，如果 $w=0$）的特殊情况下，扰动 $\\Delta X$ 变成一个零矩阵。在这种情况下，$X_{\\mathrm{adv}} = X$，对抗性损失等于基线损失，敏感性为 $0$。这一点由逐元素符号函数自然处理，因为 $\\mathrm{sign}(0) = 0$。\n\n整体算法遍历每个测试用例，识别问题类型（回归或分类），并应用相应的逻辑来计算基线损失、FGSM 扰动、对抗性损失，最后计算两者之差。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    \"\"\"\n\n    def compute_regression_sensitivity(X, y, w, epsilon):\n        \"\"\"\n        Computes the sensitivity for a linear regression model.\n        \"\"\"\n        n, d = X.shape\n        # Ensure y and w are column vectors for matrix operations\n        y = y.reshape(-1, 1)\n        w = w.reshape(-1, 1)\n\n        # 1. Compute baseline loss (RMSE)\n        y_hat = X @ w\n        errors = y_hat - y\n        mse_base = np.mean(np.square(errors))\n        # Handle case where MSE is zero\n        rmse_base = np.sqrt(mse_base) if mse_base > 0 else 0.0\n\n        if epsilon == 0.0:\n            return 0.0\n\n        # 2. Construct adversarial perturbation delta_X\n        # Shape of errors: (n, 1), w.T: (1, d) -> result: (n, d)\n        sign_matrix = np.sign(errors @ w.T)\n        delta_X = epsilon * sign_matrix\n\n        # 3. Compute adversarial loss\n        X_adv = X + delta_X\n        y_hat_adv = X_adv @ w\n        errors_adv = y_hat_adv - y\n        mse_adv = np.mean(np.square(errors_adv))\n        rmse_adv = np.sqrt(mse_adv) if mse_adv > 0 else 0.0\n        \n        # 4. Return the difference\n        return rmse_adv - rmse_base\n\n    def compute_classification_sensitivity(X, y, w, epsilon):\n        \"\"\"\n        Computes the sensitivity for a logistic classification model.\n        \"\"\"\n        n, d = X.shape\n        # Ensure y and w are column vectors for matrix operations\n        y = y.reshape(-1, 1)\n        w = w.reshape(-1, 1)\n        \n        clip_val = 1e-15\n\n        def sigmoid(z):\n            return 1 / (1 + np.exp(-z))\n\n        def log_loss(p, y_true):\n            p_clipped = np.clip(p, clip_val, 1 - clip_val)\n            return -np.mean(y_true * np.log(p_clipped) + (1 - y_true) * np.log(1 - p_clipped))\n\n        # 1. Compute baseline loss (Log-Loss)\n        z_base = X @ w\n        p_base = sigmoid(z_base)\n        loss_base = log_loss(p_base, y)\n\n        if epsilon == 0.0 or np.all(w == 0):\n             return 0.0\n\n        # 2. Construct adversarial perturbation delta_X\n        # Use unclipped probabilities for gradient calculation\n        pred_errors = p_base - y\n        # Shape of pred_errors: (n, 1), w.T: (1, d) -> result: (n, d)\n        sign_matrix = np.sign(pred_errors @ w.T)\n        delta_X = epsilon * sign_matrix\n        \n        # 3. Compute adversarial loss\n        X_adv = X + delta_X\n        z_adv = X_adv @ w\n        p_adv = sigmoid(z_adv)\n        loss_adv = log_loss(p_adv, y)\n\n        # 4. Return the difference\n        return loss_adv - loss_base\n\n    test_cases = [\n        # Case 1 (Regression, general case)\n        ('regression', \n         np.array([[1.0, 2.0], [0.5, -1.0], [3.0, 0.0]]), \n         np.array([4.0, -1.0, 5.0]), \n         np.array([1.2, 0.8]), 0.1),\n        # Case 2 (Regression, boundary epsilon = 0)\n        ('regression', \n         np.array([[2.0, -0.5], [-1.0, 1.0]]), \n         np.array([1.0, 0.0]), \n         np.array([0.5, -0.5]), 0.0),\n        # Case 3 (Classification, general case)\n        ('classification', \n         np.array([[0.2, -0.1], [1.5, 0.3], [-0.3, 0.8]]), \n         np.array([0, 1, 1]), \n         np.array([0.7, -0.5]), 0.2),\n        # Case 4 (Classification, zero-weights edge)\n        ('classification', \n         np.array([[1.0, 2.0], [-0.5, 0.5]]), \n         np.array([0, 1]), \n         np.array([0.0, 0.0]), 0.5),\n        # Case 5 (Classification, large epsilon stress)\n        ('classification', \n         np.array([[2.0, -1.0], [-1.0, 2.5], [0.3, -0.7], [1.0, 1.0]]), \n         np.array([1, 0, 0, 1]), \n         np.array([1.0, 1.5]), 2.0),\n    ]\n\n    results = []\n    for case in test_cases:\n        case_type, X, y, w, epsilon = case\n        if case_type == 'regression':\n            result = compute_regression_sensitivity(X, y, w, epsilon)\n        else: # 'classification'\n            result = compute_classification_sensitivity(X, y, w, epsilon)\n        results.append(result)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3147847"}]}