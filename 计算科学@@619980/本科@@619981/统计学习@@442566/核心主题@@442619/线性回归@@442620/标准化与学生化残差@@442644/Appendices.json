{"hands_on_practices": [{"introduction": "理论知识的学习需要通过实践来巩固。本节的第一个练习旨在通过一个非常简单的场景——仅有截距项的回归模型——来建立你对标准化残差的直观理解。通过从头推导，你会发现标准化残差与你可能已经熟悉的统计量“Z分数”之间的紧密联系，并理解两者之间的关键区别。这个练习将帮助你揭开标准化残差公式的神秘面纱，为后续更复杂的应用打下坚实的基础。[@problem_id:3176927]", "problem": "考虑一个仅含截距项的单变量线性回归：对于索引为 $i \\in \\{1,2,\\ldots,n\\}$ 的观测值，模型为 $y_{i} = \\beta_{0} + \\varepsilon_{i}$，其中 $\\varepsilon_{i}$ 独立同分布于 $\\mathcal{N}(0,\\sigma^{2})$。令设计矩阵为 $X = \\mathbf{1}$，即一个 $n \\times 1$ 的全一向量。令 $\\hat{y}_{i}$ 表示拟合值，$e_{i} = y_{i} - \\hat{y}_{i}$ 为残差，$H$ 为帽子矩阵，其元素为 $h_{ij}$。定义残差平方和 $\\mathrm{RSS} = \\sum_{i=1}^{n} e_{i}^{2}$ 和残差标准误 $s = \\sqrt{\\mathrm{RSS}/(n-p)}$，其中 $p=1$。标准化残差定义为 $r_{i} = \\dfrac{e_{i}}{s \\sqrt{1 - h_{ii}}}$。令 $\\bar{y} = \\dfrac{1}{n}\\sum_{i=1}^{n} y_{i}$，样本标准差为 $s_{y} = \\sqrt{\\dfrac{1}{n-1}\\sum_{i=1}^{n} (y_{i} - \\bar{y})^{2}}$。定义 $z$-分数为 $z_{i} = \\dfrac{y_{i} - \\bar{y}}{s_{y}}$。\n\n从线性模型中帽子矩阵、残差和方差估计量的标准定义出发，并且不预先假设任何仅含截距项模型的特定结果，推导出 $h_{ii}$，展示 $s$ 和 $s_{y}$ 之间的关系，并获得一个仅用 $z_{i}$ 和 $n$ 表示的标准化残差 $r_{i}$ 的闭式表达式。请将您的最终答案表示为仅包含 $z_{i}$ 和 $n$ 的 $r_{i}$ 的单个闭式解析表达式。无需进行数值四舍五入。", "solution": "目标是为一个仅含截距项的单变量线性回归模型推导标准化残差 $r_{i}$ 的闭式表达式，该表达式仅用 $z$-分数 $z_{i}$ 和样本量 $n$ 来表示。根据要求，推导将从第一性原理出发。\n\n模型设定为 $y_{i} = \\beta_{0} + \\varepsilon_{i}$，其中 $i \\in \\{1, 2, \\ldots, n\\}$，误差项 $\\varepsilon_{i}$ 独立同分布于 $\\mathcal{N}(0,\\sigma^{2})$。此模型的设计矩阵是 $X = \\mathbf{1}$，一个 $n \\times 1$ 的全一列向量。\n\n首先，我们确定参数 $\\beta_{0}$ 的普通最小二乘（OLS）估计量，记为 $\\hat{\\beta}_{0}$。OLS 估计向量的一般公式为 $\\hat{\\beta} = (X^{T}X)^{-1}X^{T}y$。我们为我们的特定模型计算这些组成部分。\n$X^{T}X$ 项为：\n$$X^{T}X = \\mathbf{1}^{T}\\mathbf{1} = \\sum_{i=1}^{n} 1^{2} = n$$\n其逆为 $(X^{T}X)^{-1} = n^{-1} = \\frac{1}{n}$。\n$X^{T}y$ 项为：\n$$X^{T}y = \\mathbf{1}^{T}y = \\sum_{i=1}^{n} y_{i}$$\n根据定义，样本均值为 $\\bar{y} = \\frac{1}{n} \\sum_{i=1}^{n} y_{i}$，这意味着 $\\sum_{i=1}^{n} y_{i} = n\\bar{y}$。\n将这些代入 OLS 公式，得到标量估计 $\\hat{\\beta}_{0}$：\n$$\\hat{\\beta}_{0} = \\left(\\frac{1}{n}\\right)(n\\bar{y}) = \\bar{y}$$\n\n接下来，我们计算拟合值 $\\hat{y}_{i}$。拟合值向量为 $\\hat{y} = X\\hat{\\beta}_{0}$。\n$$\\hat{y} = \\mathbf{1}\\bar{y}$$\n这意味着对于所有 $i \\in \\{1, \\ldots, n\\}$，每个单独的拟合值为 $\\hat{y}_{i} = \\bar{y}$。\n\n帽子矩阵 $H$ 定义为 $H = X(X^{T}X)^{-1}X^{T}$。使用我们之前计算的项：\n$$H = \\mathbf{1}\\left(\\frac{1}{n}\\right)\\mathbf{1}^{T} = \\frac{1}{n}\\mathbf{1}\\mathbf{1}^{T}$$\n外积 $\\mathbf{1}\\mathbf{1}^{T}$ 得到一个 $n \\times n$ 的矩阵，其中每个元素都为 1。因此，帽子矩阵 $H$ 是一个 $n \\times n$ 的矩阵，其中每个元素 $h_{ij}$ 都等于 $\\frac{1}{n}$。因此，计算标准化残差所需的帽子矩阵的对角元素为 $h_{ii} = \\frac{1}{n}$（对所有 $i$）。\n\n残差定义为 $e_{i} = y_{i} - \\hat{y}_{i}$。代入拟合值的表达式，我们得到：\n$$e_{i} = y_{i} - \\bar{y}$$\n\n残差平方和（RSS）是残差的平方之和：\n$$\\mathrm{RSS} = \\sum_{i=1}^{n} e_{i}^{2} = \\sum_{i=1}^{n} (y_{i} - \\bar{y})^{2}$$\n\n残差标准误 $s$ 定义为 $s = \\sqrt{\\mathrm{RSS}/(n-p)}$，其中 $p$ 是模型中估计的参数数量。对于仅含截距项的模型，我们估计一个参数 $\\beta_0$，所以 $p=1$。\n$$s = \\sqrt{\\frac{\\mathrm{RSS}}{n-1}} = \\sqrt{\\frac{\\sum_{i=1}^{n} (y_{i} - \\bar{y})^{2}}{n-1}}$$\n\n问题中给出了 $y$ 的样本标准差的定义为 $s_{y} = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^{n} (y_{i} - \\bar{y})^{2}}$。通过直接比较 $s$ 和 $s_{y}$ 的表达式，我们建立了关键关系 $s = s_{y}$。\n\n现在我们准备推导标准化残差 $r_{i}$ 的表达式。其定义为 $r_{i} = \\dfrac{e_{i}}{s \\sqrt{1 - h_{ii}}}$。\n我们代入上面推导出的表达式：$e_{i} = y_{i} - \\bar{y}$，$s = s_{y}$ 和 $h_{ii} = \\frac{1}{n}$。\n$$r_{i} = \\frac{y_{i} - \\bar{y}}{s_{y} \\sqrt{1 - \\frac{1}{n}}}$$\n简化分母中的项：\n$$r_{i} = \\frac{y_{i} - \\bar{y}}{s_{y} \\sqrt{\\frac{n-1}{n}}}$$\n\n最后一步是用给定的 $z$-分数来表示这个结果，其定义为 $z_{i} = \\dfrac{y_{i} - \\bar{y}}{s_{y}}$。我们将 $z_i$ 代入 $r_i$ 的表达式中：\n$$r_{i} = \\frac{z_{i}}{\\sqrt{\\frac{n-1}{n}}}$$\n重新整理这个表达式，得到标准化残差 $r_i$ 和 $z$-分数 $z_i$ 之间的最终闭式关系：\n$$r_{i} = z_{i} \\sqrt{\\frac{n}{n-1}}$$\n该表达式仅依赖于 $z_{i}$ 和 $n$，符合要求。", "answer": "$$\\boxed{z_{i} \\sqrt{\\frac{n}{n-1}}}$$", "id": "3176927"}, {"introduction": "在掌握了基本概念后，让我们通过编码实践来观察不同类型的残差在实际数据分析中的表现。这个练习将指导你构建一个包含两种特殊数据点的数据集：一个具有高杠杆率但残差很小，另一个杠杆率低但残差巨大。通过亲手计算和比较标准化残差 ($r_i$) 与学生化残差 ($t_i$)，你将直观地体验到学生化残差在识别“隐藏”的离群点方面的优越性，并深刻理解杠杆值在残差分析中的关键作用。[@problem_id:3176898]", "problem": "考虑经典线性回归模型 $y = X\\beta + \\varepsilon$，其中 $X \\in \\mathbb{R}^{n \\times p}$ 是一个固定的设计矩阵（其中一列为1，用于对截距建模），$\\beta \\in \\mathbb{R}^p$ 是参数向量，$\\varepsilon \\in \\mathbb{R}^{n}$ 是一个随机误差向量，假设满足 $\\mathbb{E}[\\varepsilon] = 0$ 和 $\\mathrm{Var}(\\varepsilon) = \\sigma^2 I_n$。使用普通最小二乘 (OLS) 估计量 $\\hat{\\beta}$ 和相关的残差向量 $e = y - X\\hat{\\beta}$、帽子矩阵 $H = X(X^\\top X)^{-1}X^\\top$（其对角线元素为 $h_{ii}$）以及自由度 $n - p$，从第一性原理构建和分析标准化残差和学生化残差。\n\n您必须编写一个完整的程序，该程序：\n- 构建几个数据集，每个数据集都包含一组接近真实直线的基准点以及两个特殊点：\n  1. 一个具有大杠杆值（大的 $h_{ii}$）但残差大小 $|e_i|$ 小的点。\n  2. 一个具有小杠杆值（小的 $h_{ii}$）但残差大小 $|e_i|$ 大的点。\n- 对每个数据集拟合带有截距和一个预测变量的 OLS 模型，计算所有观测值的 $e_i$ 和 $h_{ii}$，然后从线性回归的模型假设和核心定义出发，计算每个观测值的标准化残差 $r_i$ 和学生化残差 $t_i$。不要使用任何预封装的回归函数；直接从 OLS、帽子矩阵和基于残差的方差估计量的定义中推导并实现所有需要的量。\n\n对于基准线，使用确定性模型 $y = \\beta_0 + \\beta_1 x$，其中 $\\beta_0 = 2$ 和 $\\beta_1 = 1.5$。通过以下方式构建每个数据集：\n- 创建 $n_{\\text{base}}$ 个在闭区间 $[-x_{\\max}, x_{\\max}]$ 上关于 $0$ 对称均匀分布的设计点 $x$，噪声为零。\n- 在 $x_{\\text{HL}}$ 处附加高杠杆点，其响应值恰好在真实直线上，外加一个指定的小偏移量 $\\epsilon_{\\text{HL}}$。\n- 在 $x = 0$ 处附加低杠杆点，但其响应值与真实直线偏离一个指定的大量值 $\\delta_{\\text{LL}}$。\n\n观测值从 $0$ 开始索引，并按顺序将两个特殊点附加到末尾：首先是高杠杆点，然后是低杠杆大残差点的索引为 $n_{\\text{base}} + 1$。\n\n仅使用模型假设和定义，计算：\n- 所有 $i$ 的 OLS 估计 $\\hat{\\beta}$ 和残差 $e_i$。\n- 通过帽子矩阵 $H$ 计算所有 $i$ 的杠杆值 $h_{ii}$。\n- 所有 $i$ 的标准化残差 $r_i$ 和学生化残差 $t_i$。\n\n您的程序必须处理以下参数集测试套件，每个参数集以元组 $(n_{\\text{base}}, x_{\\max}, x_{\\text{HL}}, \\delta_{\\text{LL}}, \\epsilon_{\\text{HL}})$ 的形式给出：\n- 测试用例 1：$(12, 3, 15, 15, 0)$。\n- 测试用例 2：$(10, 2, 50, 10, 0)$。\n- 测试用例 3：$(12, 3, 8, 6, 0.5)$。\n\n对每个数据集，生成四个量：\n1. 具有最大绝对标准化残差 $|r_i|$ 的观测值索引 $i_r$。\n2. 具有最大绝对学生化残差 $|t_i|$ 的观测值索引 $i_t$。\n3. 一个布尔值 $b_1$，表示对于低杠杆大残差点，学生化残差的绝对值是否超过标准化残差的绝对值，即在索引 $n_{\\text{base}}+1$ 处是否有 $|t_i| > |r_i|$。\n4. 一个布尔值 $b_2$，表示对于高杠杆小残差点，标准化残差的绝对值是否至少与学生化残差的绝对值一样大，即在索引 $n_{\\text{base}}$ 处是否有 $|r_i| \\ge |t_i|$。\n\n您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，其中每个结果本身是一个列表 $[i_r, i_t, b_1, b_2]$，对应一个测试用例，顺序与测试套件相同（例如，$[[i_{r,1}, i_{t,1}, b_{1,1}, b_{2,1}], [i_{r,2}, i_{t,2}, b_{1,2}, b_{2,2}], [i_{r,3}, i_{t,3}, b_{1,3}, b_{2,3}]]$）。此问题不涉及物理单位或角度单位。", "solution": "用户提供的问题是有效的。这是一个在统计学习领域中明确定义的计算任务，基于线性回归分析的既定原则。该问题是自包含的、科学上合理的，所有参数和目标都已明确指定。解决方案按要求从第一性原理实现所需的计算。\n\n### 理论基础与方法\n\n该问题要求分析简单线性回归模型 $y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i$ 中的残差。这可以表示为矩阵形式 $y = X\\beta + \\varepsilon$，其中 $y$ 是 $n \\times 1$ 的响应向量，$X$ 是 $n \\times p$ 的设计矩阵（对于简单线性回归，$p=2$），$\\beta$ 是 $p \\times 1$ 的参数向量，$\\varepsilon$ 是 $n \\times 1$ 的随机误差向量。假设误差是独立同分布的，均值为 $0$，方差为 $\\sigma^2$，即 $\\mathbb{E}[\\varepsilon] = 0$ 和 $\\mathrm{Var}(\\varepsilon) = \\sigma^2 I_n$。\n\n**1. 普通最小二乘 (OLS) 估计**\n参数向量 $\\beta$ 的 OLS 估计量 $\\hat{\\beta}$ 是通过最小化残差平方和 $S(\\beta) = (y - X\\beta)^\\top(y - X\\beta)$ 得到的。这会产生正规方程 $(X^\\top X)\\hat{\\beta} = X^\\top y$。假设矩阵 $X^\\top X$ 是可逆的（如果 $X$ 是满列秩的，则此条件成立），唯一的 OLS 估计量为：\n$$ \\hat{\\beta} = (X^\\top X)^{-1} X^\\top y $$\n拟合值向量为 $\\hat{y} = X\\hat{\\beta}$，残差向量为 $e = y - \\hat{y}$。\n\n**2. 帽子矩阵和杠杆值**\n拟合值可以表示为观测值 $y$ 的线性变换：\n$$ \\hat{y} = X((X^\\top X)^{-1} X^\\top y) = H y $$\n矩阵 $H = X(X^\\top X)^{-1}X^\\top$ 被称为“帽子矩阵”，因为它将 $y$ 变换为 $\\hat{y}$。它是一个 $n \\times n$ 的对称且幂等（$H^2 = H$）的投影矩阵。帽子矩阵的对角元素 $h_{ii}$ 被称为杠杆值。每个 $h_{ii}$ 衡量第 $i$ 个响应值 $y_i$ 对其自身拟合值 $\\hat{y}_i$ 的影响程度，因为 $\\hat{y}_i = \\sum_{j=1}^n H_{ij} y_j = h_{ii}y_i + \\sum_{j \\ne i} h_{ij} y_j$。杠杆值的范围是 $0 \\le h_{ii} \\le 1$。高杠杆值表示第 $i$ 个观测值在预测变量（$x$ 值）空间中是一个离群点。\n\n**3. 残差分析**\n残差由 $e = y - \\hat{y} = y - Hy = (I - H)y$ 给出。残差的方差-协方差矩阵为：\n$$ \\mathrm{Var}(e) = \\mathrm{Var}((I-H)y) = (I-H)\\mathrm{Var}(y)(I-H)^\\top = (I-H)(\\sigma^2 I)(I-H) = \\sigma^2(I-H) $$\n因此，单个残差 $e_i$ 的方差为 $\\mathrm{Var}(e_i) = \\sigma^2(1 - h_{ii})$。误差方差 $\\sigma^2$ 的一个无偏估计量是均方误差 (MSE)：\n$$ \\hat{\\sigma}^2 = \\frac{e^\\top e}{n-p} = \\frac{\\sum_{i=1}^n e_i^2}{n-p} $$\n其中 $n-p$ 是残差自由度。\n\n**4. 标准化残差**\n标准化残差考虑了原始残差 $e_i$ 方差不同的事实。观测值 $i$ 的标准化残差，记作 $r_i$，是原始残差除以其标准差的估计值：\n$$ r_i = \\frac{e_i}{\\widehat{\\mathrm{sd}}(e_i)} = \\frac{e_i}{\\hat{\\sigma}\\sqrt{1 - h_{ii}}} $$\n该度量根据每个残差的杠杆值进行调整。高杠杆点（大的 $h_{ii}$）的残差将被放大。\n\n**5. 学生化残差**\n标准化残差的一个关键问题是，被评估的观测值 $i$ 会对估计值 $\\hat{\\sigma}$ 产生影响。如果观测值 $i$ 是一个显著的离群点，它可能会夸大 $\\hat{\\sigma}$，从而通过产生较小的标准化残差来“掩盖”其自身的离群点状态。学生化残差（或外学生化残差）$t_i$ 通过使用一个在移除第 $i$ 个观测值后进行回归拟合计算出的方差估计值 $\\hat{\\sigma}_{(i)}^2$ 来解决这个问题：\n$$ t_i = \\frac{e_i}{\\hat{\\sigma}_{(i)}\\sqrt{1 - h_{ii}}} $$\n一个计算上高效的公式将 $t_i$ 与标准化残差 $r_i$ 联系起来：\n$$ t_i = r_i \\sqrt{\\frac{n - p - 1}{n - p - r_i^2}} $$\n该公式表明，当且仅当 $r_i^2 > 1$ 时，才有 $|t_i| > |r_i|$，这意味着学生化残差会进一步放大大标准化残差的量级，使其成为检测离群点更敏感的诊断工具。\n\n### 实现策略\n\n程序将按如下方式处理每个测试用例：\n1.  **数据构建**：对于每组参数 $(n_{\\text{base}}, x_{\\max}, x_{\\text{HL}}, \\delta_{\\text{LL}}, \\epsilon_{\\text{HL}})$，生成 $x$ 和 $y$ 向量。这包括在直线 $y = 2 + 1.5x$ 上创建基准点，并附加指定的高杠杆点和低杠杆/大残差点。\n2.  **模型拟合**：通过在 $x$ 向量前添加一列1来构建设计矩阵 $X$。然后，使用矩阵运算计算 OLS 估计 $\\hat{\\beta} = (X^\\top X)^{-1} X^\\top y$。\n3.  **残差和杠杆值计算**：计算残差 $e = y - X\\hat{\\beta}$ 和作为帽子矩阵 $H = X(X^\\top X)^{-1}X^\\top$ 对角线元素的杠杆值 $h_{ii}$。\n4.  **诊断计算**：计算方差估计 $\\hat{\\sigma}^2$，然后使用各自的公式计算标准化残差 $r$ 和学生化残差 $t$ 的向量。\n5.  **结果提取**：从计算出的向量中，识别最大绝对标准化残差和学生化残差的索引，并评估关于特殊点的两个指定布尔条件。\n6.  **输出格式化**：将所有测试用例的结果整理成一个列表的列表，并将其格式化为字符串以供最终输出。\n\n该实现依赖于 `numpy` 库进行数值线性代数运算，严格遵守从第一性原理推导出的公式。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_residuals(n_base: int, x_max: float, x_HL: float, delta_LL: float, epsilon_HL: float) -> list:\n    \"\"\"\n    Constructs a dataset, fits an OLS model from first principles, and computes\n    standardized and studentized residuals to identify influential points.\n\n    Args:\n        n_base: Number of base points for the regression line.\n        x_max: The maximum absolute value for the range of base x-points.\n        x_HL: The x-coordinate of the high-leverage point.\n        delta_LL: The y-offset for the low-leverage, large-residual point.\n        epsilon_HL: The y-offset for the high-leverage point.\n\n    Returns:\n        A list containing [i_r, i_t, b1, b2]:\n        i_r: Index of the max absolute standardized residual.\n        i_t: Index of the max absolute studentized residual.\n        b1: Boolean, |t_i| > |r_i| for the low-leverage point.\n        b2: Boolean, |r_i| >= |t_i| for the high-leverage point.\n    \"\"\"\n    # True model parameters\n    beta0_true = 2.0\n    beta1_true = 1.5\n\n    # 1. Construct the dataset\n    # Base points on the true line\n    x_base = np.linspace(-x_max, x_max, n_base)\n    y_base = beta0_true + beta1_true * x_base\n    \n    # High-leverage point\n    x_hl = float(x_HL)\n    y_hl = (beta0_true + beta1_true * x_hl) + epsilon_HL\n    \n    # Low-leverage, large-residual point\n    x_ll = 0.0\n    y_ll = (beta0_true + beta1_true * x_ll) + delta_LL\n    \n    # Combine into the full dataset\n    x = np.concatenate((x_base, [x_hl, x_ll]))\n    y = np.concatenate((y_base, [y_hl, y_ll]))\n    \n    n = len(x)\n    p = 2  # Number of parameters (intercept beta0, slope beta1)\n    \n    # Indices of the special points\n    idx_hl = n_base\n    idx_ll = n_base + 1\n    \n    # 2. Fit OLS model from first principles\n    # Construct the design matrix X\n    X = np.c_[np.ones(n), x]\n    \n    # OLS estimator: beta_hat = (X'X)^-1 X'y\n    XTX_inv = np.linalg.inv(X.T @ X)\n    beta_hat = XTX_inv @ X.T @ y\n    \n    # Predicted values and residuals\n    y_hat = X @ beta_hat\n    e = y - y_hat\n    \n    # 3. Compute leverage values (h_ii)\n    # Hat matrix: H = X(X'X)^-1 X'\n    H = X @ XTX_inv @ X.T\n    h = np.diag(H)\n    \n    # 4. Compute standardized and studentized residuals\n    \n    # Unbiased estimator for error variance sigma^2\n    rss = e.T @ e\n    sigma2_hat = rss / (n - p)\n    sigma_hat = np.sqrt(sigma2_hat)\n    \n    # Standardized residuals: r_i = e_i / (sigma_hat * sqrt(1 - h_ii))\n    # Handle potential division by zero if h_ii is close to 1\n    sqrt_1_minus_h = np.sqrt(1 - h)\n    r = np.zeros_like(e)\n    valid_indices_r = (1 - h) > 1e-12\n    r[valid_indices_r] = e[valid_indices_r] / (sigma_hat * sqrt_1_minus_h[valid_indices_r])\n    \n    # Studentized residuals: t_i = r_i * sqrt((n - p - 1) / (n - p - r_i^2))\n    df_full = n - p\n    df_del = n - p - 1\n    \n    denom_t_sq = df_full - r**2\n    t = np.zeros_like(r)\n    \n    # Handle r_i^2  n-p for valid square root\n    valid_indices_t = denom_t_sq > 1e-12\n    t[valid_indices_t] = r[valid_indices_t] * np.sqrt(df_del / denom_t_sq[valid_indices_t])\n    \n    # If r_i^2 -> n-p, t -> inf\n    infinite_indices = np.abs(denom_t_sq) = 1e-12\n    t[infinite_indices] = np.inf * np.sign(r[infinite_indices])\n    \n    # 5. Determine the required outputs\n    i_r = int(np.argmax(np.abs(r)))\n    i_t = int(np.argmax(np.abs(t)))\n\n    b1 = bool(np.abs(t[idx_ll]) > np.abs(r[idx_ll]))\n    b2 = bool(np.abs(r[idx_hl]) >= np.abs(t[idx_hl]))\n    \n    return [i_r, i_t, b1, b2]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (n_base, x_max, x_HL, delta_LL, epsilon_HL)\n        (12, 3, 15, 15, 0),\n        (10, 2, 50, 10, 0),\n        (12, 3, 8, 6, 0.5),\n    ]\n\n    results = []\n    for case in test_cases:\n        # Unpack tuple into named arguments for clarity\n        n_base, x_max, x_HL, delta_LL, epsilon_HL = case\n        result = calculate_residuals(n_base, x_max, x_HL, delta_LL, epsilon_HL)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # The str() conversion of a list includes spaces, which is standard.\n    # The problem example is symbolic; this literal interpretation of the template is safest.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3176898"}, {"introduction": "理解一个工具的强大之处同样需要了解它的局限性。最后一个练习是一个思想实验，它将我们推向一个极端情况：当模型对训练数据达到“完美”拟合时会发生什么？通过分析这种饱和模型（或称过拟合模型），你将探索为何在这种情况下，我们常用的残差诊断工具（如标准化和学生化残差）会失效。这个练习不仅能巩固你对杠杆值和残差定义的理解，更能揭示模型诊断与过拟合等核心统计概念之间的深刻联系。[@problem_id:3176882]", "problem": "考虑普通最小二乘法（OLS）线性回归，其设计矩阵为 $X \\in \\mathbb{R}^{n \\times p}$，响应向量为 $y \\in \\mathbb{R}^n$。拟合值是 $y$ 在 $X$ 的列空间上的正交投影，通过对称幂等投影矩阵 $H$ 实现，因此 $\\hat{y} = H y$，残差向量为 $e = y - \\hat{y} = (I_n - H) y$，其中 $I_n$ 是 $n \\times n$ 的单位矩阵。观测值 $i$ 的杠杆值是 $H$ 的第 $i$ 个对角元素 $h_{ii}$。观测值 $i$ 的标准化残差由 $r_i = e_i / \\big( s \\sqrt{1 - h_{ii}} \\big)$ 给出，其中 $s$ 是基于残差的常用噪声尺度无偏估计量；外学生化残差由 $\\tilde{r}_i = e_i / \\big( s_{(i)} \\sqrt{1 - h_{ii}} \\big)$ 给出，其中 $s_{(i)}$ 是在移除观测值 $i$ 后重新拟合模型计算出的无偏噪声估计。\n\n假设模型对训练数据达到完美拟合，即 $X$ 的列空间等于 $\\mathbb{R}^n$。从正交投影算子的性质和上述定义出发，判断下列哪些陈述是正确的。\n\nA. 在完美拟合且 $\\operatorname{col}(X) = \\mathbb{R}^n$ 的情况下，帽子矩阵满足 $H = I_n$，残差向量为 $e = 0$。\n\nB. 在完美拟合下，杠杆值对所有 $i$ 满足 $h_{ii} = 0$，这意味着所有标准化残差均为 $0$。\n\nC. 在完美拟合下，标准化残差 $r_i$ 和外学生化残差 $\\tilde{r}_i$ 是未定义的，因为 $\\sqrt{1 - h_{ii}} = 0$，并且在饱和拟合中尺度因子 $s$ 和 $s_{(i)}$ 没有良好定义。\n\nD. 完美拟合意味着零训练误差，但损害了异常值检测和泛化能力；基于残差的诊断方法失效，这标志着过拟合。\n\nE. 即使在完美拟合下，外学生化残差 $\\tilde{r}_i$ 仍然有良好定义，并服从自由度为 $n - p - 1$ 的 $t$ 分布。", "solution": "在继续之前，对问题陈述进行验证。\n\n核心前提是，对于一个设计矩阵为 $X \\in \\mathbb{R}^{n \\times p}$ 的普通最小二乘法（OLS）模型，该模型达到了“完美拟合”，其严格定义为 $X$ 的列空间张成了整个环境空间，即 $\\operatorname{col}(X) = \\mathbb{R}^n$。问题使用了帽子矩阵 $H$、残差向量 $e$、杠杆值 $h_{ii}$、标准化残差 $r_i$ 和外学生化残差 $\\tilde{r}_i$ 的标准定义。\n\n条件 $\\operatorname{col}(X) = \\mathbb{R}^n$ 意味着矩阵 $X$ 的秩等于空间的维度，即 $n$。所以，$\\operatorname{rank}(X) = n$。由于矩阵的秩不能超过其行数或列数，我们有 $\\operatorname{rank}(X) \\le \\min(n, p)$。为了使 $\\operatorname{rank}(X) = n$，必须有 $p \\ge n$。这种情况对应于一个“饱和”模型，其中预测变量的数量至少与观测值的数量一样多。这是回归分析中一个有效但极端的理论案例，常用于研究过拟合的性质。该问题具有科学依据，提法恰当且客观。因此，问题陈述是有效的。\n\n现在我们根据给定的前提进行推导。\n\n首先，我们分析帽子矩阵 $H$ 的性质。帽子矩阵 $H$ 被定义为到 $X$ 的列空间 $\\operatorname{col}(X)$ 上的正交投影矩阵。给定条件 $\\operatorname{col}(X) = \\mathbb{R}^n$，则 $H$ 是到 $\\mathbb{R}^n$ 上的投影矩阵。唯一一个将 $\\mathbb{R}^n$ 中每个向量都映射到整个 $\\mathbb{R}^n$ 的投影矩阵是单位矩阵 $I_n$。\n$$ H = I_n $$\n\n接下来，我们确定拟合值 $\\hat{y}$ 和残差向量 $e$。\n拟合值由 $\\hat{y} = H y$ 给出。代入 $H = I_n$：\n$$ \\hat{y} = I_n y = y $$\n这证实了“完美拟合”的含义：模型的预测与观测数据完全匹配。\n残差向量为 $e = y - \\hat{y}$。代入 $\\hat{y} = y$：\n$$ e = y - y = 0 $$\n残差向量是零向量，意味着对于 $i = 1, \\dots, n$，每个单独的残差 $e_i = 0$。\n\n现在，我们评估杠杆值 $h_{ii}$。观测值 $i$ 的杠杆值是帽子矩阵 $H$ 的第 $i$ 个对角元素。由于 $H = I_n$，其对角元素全为 $1$。\n$$ h_{ii} = 1 \\quad \\text{for all } i \\in \\{1, \\dots, n\\} $$\n\n我们现在可以分析标准化残差和学生化残差。\n观测值 $i$ 的标准化残差定义为 $r_i = e_i / \\big( s \\sqrt{1 - h_{ii}} \\big)$。\n我们发现分子是 $e_i = 0$。对于分母，我们有 $\\sqrt{1 - h_{ii}} = \\sqrt{1 - 1} = 0$。因此，$r_i$ 的表达式呈现为不定形式 $0/0$。\n此外，我们来考察尺度估计量 $s$。误差方差的常用无偏估计量是 $s^2 = \\text{RSS} / (n-p)$，其中 $\\text{RSS} = \\sum_{i=1}^n e_i^2$ 是残差平方和。由于 $e=0$，我们有 $\\text{RSS} = 0$。误差的自由度是 $n-p$。如前所述，条件 $\\operatorname{col}(X) = \\mathbb{R}^n$ 要求 $p \\ge n$，这意味着自由度 $n-p \\le 0$。一个有效的方差估计需要正的自由度。所以，$s^2 = 0 / (\\text{非正值})$，这是未定义的。\n因此，标准化残差 $r_i$ 是未定义的，原因有二：分母中包含一个零因子（$\\sqrt{1-h_{ii}}$），并且尺度估计 $s$ 本身没有良好定义。\n\n外学生化残差是 $\\tilde{r}_i = e_i / \\big( s_{(i)} \\sqrt{1 - h_{ii}} \\big)$。\n这个表达式的分子同样是 $e_i = 0$，分母中也含有一个因子 $\\sqrt{1-h_{ii}} = 0$，所以它也是不定形式 $0/0$。留一法尺度估计 $s_{(i)}$ 是通过对 $n-1$ 个观测值和 $p$ 个预测变量拟合模型来计算的。这个新模型的自由度将是 $(n-1) - p$。由于 $p \\ge n$，这些自由度为负或零。在简化数据集上的模型（假设 $X$ 的列处于一般位置）也将产生完美拟合，导致残差平方和为零。因此，$s_{(i)}^2$ 也是未定义的。\n\n有了这些结果，我们可以评估每个陈述。\n\n**A. 在完美拟合且 $\\operatorname{col}(X) = \\mathbb{R}^n$ 的情况下，帽子矩阵满足 $H = I_n$，残差向量为 $e = 0$。**\n我们的推导表明，如果 $\\operatorname{col}(X)=\\mathbb{R}^n$，投影矩阵 $H$ 必须是 $I_n$。因此，残差向量 $e = (I_n-H)y = (I_n-I_n)y = 0$。这个陈述是前提的直接且正确的数学推论。\n**结论：正确。**\n\n**B. 在完美拟合下，杠杆值对所有 $i$ 满足 $h_{ii} = 0$，这意味着所有标准化残差均为 $0$。**\n我们的推导表明，在完美拟合下，$H=I_n$，这意味着杠杆值为 $h_{ii}=1$ 对所有 $i$ 成立。声称 $h_{ii}=0$ 是错误的。因此，该陈述不正确。\n**结论：不正确。**\n\n**C. 在完美拟合下，标准化残差 $r_i$ 和外学生化残差 $\\tilde{r}_i$ 是未定义的，因为 $\\sqrt{1 - h_{ii}} = 0$，并且在饱和拟合中尺度因子 $s$ 和 $s_{(i)}$ 没有良好定义。**\n我们的推导表明，对于所有 $i$，$h_{ii}=1$，这使得项 $\\sqrt{1-h_{ii}}$ 等于 $0$。仅此一点就使得 $r_i$ 和 $\\tilde{r}_i$ 的分母为零。此外，我们证明了误差的自由度为非正（$n-p \\le 0$），使得尺度估计量 $s$ 和 $s_{(i)}$ 未定义。该陈述为为什么这些残差诊断在这种情况下未定义提供了完整且正确的解释。\n**结论：正确。**\n\n**D. 完美拟合意味着零训练误差，但损害了异常值检测和泛化能力；基于残差的诊断方法失效，这标志着过拟合。**\n该陈述对数学结果提供了统计学解释。\n- “完美拟合意味着零训练误差”：正确，因为我们证明了 $e=0$。\n- “损害了异常值检测”：正确。基于残差的异常值检测方法完全无效，因为所有残差都恰好为零。所有点也都具有最大杠杆值 $h_{ii}=1$，因此杠杆图对于区分点也无信息。\n- “损害了...泛化能力”：正确。一个 $p \\ge n$ 且完美拟合训练数据的模型是过拟合的典型例子。这样的模型捕捉了训练数据中的噪声，并预期在未见过的数据上表现不佳。这是统计学习中的一个基本概念。\n- “基于残差的诊断方法失效”：正确。如选项C的分析所示，像 $r_i$ 和 $\\tilde{r}_i$ 这样的量变得未定义。\n- “这标志着过拟合”：正确。这种诊断方法的失效是饱和、过拟合模型的一个关键标志。\n整个陈述是对给定情景后果的合理且正确的描述。\n**结论：正确。**\n\n**E. 即使在完美拟合下，外学生化残差 $\\tilde{r}_i$ 仍然有良好定义，并服从自由度为 $n - p - 1$ 的 $t$ 分布。**\n这个陈述是错误的。如选项C的分析所示，外学生化残差 $\\tilde{r}_i$ 是未定义的。$t$ 分布的结果需要标准的回归假设，包括 $n  p$，这在这里被违反了。此外，$t$ 分布的自由度参数必须为正，但这里的 $n-p-1$ 将为负，这是无效的。\n**结论：不正确。**", "answer": "$$\\boxed{ACD}$$", "id": "3176882"}]}