{"hands_on_practices": [{"introduction": "理论知识为我们构建预测区间提供了公式，但真正的理解来自于动手实践。这个练习旨在剖析预测区间宽度的核心组成部分：学生$t$分位数、残差标准误（$\\hat{\\sigma}$）和新数据点的杠杆值。通过一个精心设计的模拟，你将量化样本量$n$的增加如何系统性地收窄预测区间，从而深化对模型不确定性来源的理解。[@problem_id:3160052]", "problem": "要求您将线性模型中双侧预测区间的构建与学生$t$分布的分位数和残差标准误如何共同控制其宽度联系起来。请从第一性原理出发，从以下基础开始。\n\n假设线性模型为 $y = X\\beta + \\varepsilon$，有 $n$ 个观测值和 $p$ 个参数，其中 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^{2} I_{n})$。使用普通最小二乘法 (OLS) 估计量和高斯误差模型，推导新设计点 $x_{0} \\in \\mathbb{R}^{p}$ 处标准化预测误差的抽样分布。然后推导新响应 $y_{0}$ 在 $x_{0}$ 处的精确双侧 $(1 - \\alpha)$ 预测区间及其宽度。您的推导应清楚地说明自由度为 $n-p$ 的学生$t$分布的分位数和残差标准误 $\\hat{\\sigma}$ 如何出现在宽度表达式中，以及设计依赖性如何通过 $x_{0}$ 处的杠杆率引入。\n\n在完成推导后，编写一个程序，为一个受控设计实现所推导的公式，以分离并量化 $t$-分位数和 $\\hat{\\sigma}$ 的作用。在所有测试用例中，使用以下通用的确定性设置：\n\n- 模型：含截距项和单个中心化预测变量的简单线性回归，因此 $p = 2$。\n- 设计矩阵 $X \\in \\mathbb{R}^{n \\times 2}$ 的第一列为全1向量，第二列 $x \\in \\mathbb{R}^{n}$ 按如下确定性方式构建：在 $[-1, 1]$ 上取 $n$ 个等距点，将其中心化使其经验均值为 $0$，然后进行缩放以使 $\\sum_{i=1}^{n} x_{i}^{2} = n$。这确保 $X^{\\top} X$ 在数值对称性范围内是对角矩阵，其对角线元素近似为 $(n, n)$。\n- 用于预测的新设计点：$x_{0} = (1, 0)^{\\top}$，即在中心化预测变量水平上进行预测。\n- 残差平方和 (RSS) 在所有比较中固定为相同的值，$\\mathrm{RSS} = 100$（无单位）。残差标准误为 $\\hat{\\sigma} = \\sqrt{\\mathrm{RSS}/(n-p)}$。\n- 使用由 $\\alpha$ 指定的双侧名义水平。\n\n对于下面的每个测试用例，令 $n$ 表示基线样本量，$2n$ 表示加倍后的样本量，两者具有相同的 $\\alpha$ 和相同的 $\\mathrm{RSS} = 100$。对于每个测试用例，您的程序必须计算：\n\n1. 在上述设计下，样本量为 $2n$ 时的预测区间宽度与样本量为 $n$ 时的宽度之比 $r_{\\mathrm{full}}$，对每个 $n$ 使用由 $X$ 隐含的 $x_{0}$ 处的精确杠杆率。\n2. 绝对偏差 $|r_{\\mathrm{full}} - 0.5|$，以量化宽度比与“一半”的差距。\n3. 从宽度中移除设计杠杆率后得到的比率 $r_{t,\\sigma}$，即从 $n$ 变为 $2n$ 时，仅依赖于 $t$-分位数和 $\\hat{\\sigma}$ 的因子的比率。\n\n所有量都是无单位的；不涉及物理单位。不使用角度。\n\n测试套件（每项是一个序对 $(n,\\alpha)$；始终使用 $p = 2$ 和 $\\mathrm{RSS} = 100$）：\n- 案例 A（理想情况，小自由度）：$(n, \\alpha) = (3, 0.05)$。\n- 案例 B（趋近边界，仍为小样本）：$(n, \\alpha) = (6, 0.05)$。\n- 案例 C（中等样本）：$(n, \\alpha) = (20, 0.05)$。\n- 案例 D（更严格的水平对 $t$ 的影响）：$(n, \\alpha) = (50, 0.01)$。\n\n最终输出格式：您的程序应生成单行输出，其中包含按测试套件顺序列出的结果，形式为逗号分隔的列表的列表，每个内部列表为 $[r_{\\mathrm{full}}, |r_{\\mathrm{full}} - 0.5|, r_{t,\\sigma}]$。例如，一个有效的输出看起来像\n[[a11,a12,a13],[a21,a22,a23],[a31,a32,a33],[a41,a42,a43]]\n其中每个 $a_{ij}$ 的位置是浮点数。", "solution": "用户提供的问题被评估为有效。该问题在科学上基于线性统计模型理论，问题设定良好，目标明确，信息充分，并使用客观、正式的语言。任务是推导预测区间的宽度，然后实现一个程序，以研究其在特定条件下的行为。\n\n解决方案分为两部分。首先，对预测区间及其宽度进行理论推导。其次，实现一个程序，根据此推导计算特定量值。\n\n**第 1 部分：预测区间及其宽度的推导**\n\n我们从指定的线性模型开始：\n$$ y = X\\beta + \\varepsilon $$\n其中 $y \\in \\mathbb{R}^{n}$ 是观测响应向量，$X \\in \\mathbb{R}^{n \\times p}$ 是秩为 $p$ 的已知设计矩阵，$\\beta \\in \\mathbb{R}^{p}$ 是未知参数向量，$\\varepsilon \\in \\mathbb{R}^{n}$ 是未观测到的随机误差向量。我们假设误差是独立同分布的，服从高斯分布，即 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^{2} I_{n})$，其中 $\\sigma^2$ 是未知的误差方差，$I_n$ 是 $n \\times n$ 单位矩阵。\n\n$\\beta$ 的普通最小二乘 (OLS) 估计量由下式给出：\n$$ \\hat{\\beta} = (X^{\\top}X)^{-1}X^{\\top}y $$\n给定 $\\varepsilon$ 的分布假设，OLS 估计量 $\\hat{\\beta}$ 也是一个服从高斯分布的随机变量。其期望值为 $E[\\hat{\\beta}] = (X^{\\top}X)^{-1}X^{\\top}E[y] = (X^{\\top}X)^{-1}X^{\\top}(X\\beta) = \\beta$，因此它是一个无偏估计量。其协方差矩阵为 $\\mathrm{Var}(\\hat{\\beta}) = \\mathrm{Var}((X^{\\top}X)^{-1}X^{\\top}y) = (X^{\\top}X)^{-1}X^{\\top}(\\sigma^2 I_n)X(X^{\\top}X)^{-1} = \\sigma^2(X^{\\top}X)^{-1}$。因此，该估计量的抽样分布为：\n$$ \\hat{\\beta} \\sim \\mathcal{N}(\\beta, \\sigma^2(X^{\\top}X)^{-1}) $$\n\n我们感兴趣的是在一个新设计点 $x_0 \\in \\mathbb{R}^{p}$ 预测一个新的响应 $y_0$。这个新观测的模型为：\n$$ y_0 = x_0^{\\top}\\beta + \\varepsilon_0 $$\n其中 $\\varepsilon_0 \\sim \\mathcal{N}(0, \\sigma^2)$ 假设与训练误差 $\\varepsilon$ 独立。\n\n$y_0$ 的点预测是通过将估计参数 $\\hat{\\beta}$ 代入新点的模型方程得到的：\n$$ \\hat{y}_0 = x_0^{\\top}\\hat{\\beta} $$\n预测误差是未来真实观测值 $y_0$ 与我们的预测值 $\\hat{y}_0$ 之间的差：\n$$ y_0 - \\hat{y}_0 = (x_0^{\\top}\\beta + \\varepsilon_0) - x_0^{\\top}\\hat{\\beta} = \\varepsilon_0 - x_0^{\\top}(\\hat{\\beta} - \\beta) $$\n预测误差是高斯随机变量（$\\varepsilon_0$ 和 $\\hat{\\beta}$ 的元素）的线性组合，因此它也服从正态分布。其期望值为 $E[y_0 - \\hat{y}_0] = E[\\varepsilon_0] - x_0^{\\top}E[\\hat{\\beta} - \\beta] = 0 - x_0^{\\top}(0) = 0$。\n\n预测误差的方差计算如下，利用了 $\\varepsilon_0$ 和 $\\hat{\\beta}$（它是训练数据的函数）的独立性：\n$$ \\mathrm{Var}(y_0 - \\hat{y}_0) = \\mathrm{Var}(\\varepsilon_0) + \\mathrm{Var}(x_0^{\\top}(\\hat{\\beta} - \\beta)) $$\n$$ \\mathrm{Var}(y_0 - \\hat{y}_0) = \\sigma^2 + x_0^{\\top}\\mathrm{Var}(\\hat{\\beta})x_0 = \\sigma^2 + x_0^{\\top}(\\sigma^2(X^{\\top}X)^{-1})x_0 $$\n提出 $\\sigma^2$ 因子，我们得到：\n$$ \\mathrm{Var}(y_0 - \\hat{y}_0) = \\sigma^2 \\left(1 + x_0^{\\top}(X^{\\top}X)^{-1}x_0\\right) $$\n因此，预测误差的分布为：\n$$ y_0 - \\hat{y}_0 \\sim \\mathcal{N}\\left(0, \\sigma^2 \\left(1 + x_0^{\\top}(X^{\\top}X)^{-1}x_0\\right)\\right) $$\n项 $h_0 = x_0^{\\top}(X^{\\top}X)^{-1}x_0$ 被称为新点 $x_0$ 的杠杆率。\n\n如果 $\\sigma^2$ 已知，我们可以构建一个标准正态枢轴量：\n$$ Z = \\frac{y_0 - \\hat{y}_0}{\\sigma \\sqrt{1 + x_0^{\\top}(X^{\\top}X)^{-1}x_0}} \\sim \\mathcal{N}(0, 1) $$\n然而，$\\sigma^2$ 通常是未知的，必须从数据中估计。$\\sigma^2$ 的无偏估计量是均方误差 (MSE)，它基于残差平方和 (RSS)：\n$$ \\hat{\\sigma}^2 = \\frac{\\mathrm{RSS}}{n-p} = \\frac{1}{n-p}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2 $$\n量 $\\hat{\\sigma} = \\sqrt{\\hat{\\sigma}^2}$ 是残差标准误。线性模型理论在高斯误差下的一个基本结果表明：\n$$ \\frac{(n-p)\\hat{\\sigma}^2}{\\sigma^2} = \\frac{\\mathrm{RSS}}{\\sigma^2} \\sim \\chi^2_{n-p} $$\n其中 $\\chi^2_{n-p}$ 是自由度为 $n-p$ 的卡方分布。此外，$\\hat{\\beta}$ 和 $\\hat{\\sigma}^2$ 是独立的。\n\n为了构造一个不依赖于 $\\sigma$ 的枢轴量，我们构建一个学生t统计量。该统计量是一个标准正态变量与一个独立的、除以其自由度的卡方变量的平方根之比。\n$$ T = \\frac{\\frac{y_0 - \\hat{y}_0}{\\sigma \\sqrt{1 + h_0}}}{\\sqrt{\\frac{(n-p)\\hat{\\sigma}^2/\\sigma^2}{n-p}}} = \\frac{\\frac{y_0 - \\hat{y}_0}{\\sigma \\sqrt{1 + h_0}}}{\\frac{\\hat{\\sigma}}{\\sigma}} = \\frac{y_0 - \\hat{y}_0}{\\hat{\\sigma} \\sqrt{1 + h_0}} $$\n这个量 $T$ 服从自由度为 $n-p$ 的学生t分布：\n$$ \\frac{y_0 - \\hat{y}_0}{\\hat{\\sigma} \\sqrt{1 + x_0^{\\top}(X^{\\top}X)^{-1}x_0}} \\sim t_{n-p} $$\n这就是标准化预测误差的抽样分布。\n\n为了构造 $y_0$ 的一个双侧 $(1 - \\alpha)$ 预测区间，我们使用 $t_{n-p}$ 分布的分位数。令 $t_{\\alpha/2, n-p}$ 为满足 $P(T > t_{\\alpha/2, n-p}) = \\alpha/2$ 的值。那么：\n$$ P(-t_{\\alpha/2, n-p} \\le \\frac{y_0 - \\hat{y}_0}{\\hat{\\sigma} \\sqrt{1 + x_0^{\\top}(X^{\\top}X)^{-1}x_0}} \\le t_{\\alpha/2, n-p}) = 1 - \\alpha $$\n在不等式中心分离出 $y_0$ 得到预测区间：\n$$ \\hat{y}_0 \\pm t_{\\alpha/2, n-p} \\hat{\\sigma} \\sqrt{1 + x_0^{\\top}(X^{\\top}X)^{-1}x_0} $$\n该区间的宽度 $W$ 是上界和下界之差：\n$$ W = 2 \\cdot t_{\\alpha/2, n-p} \\cdot \\hat{\\sigma} \\cdot \\sqrt{1 + x_0^{\\top}(X^{\\top}X)^{-1}x_0} $$\n这个表达式按要求清晰地将宽度分解为三个关键组成部分：\n1. 学生t分布的分位数，$t_{\\alpha/2, n-p}$，它取决于置信水平 $\\alpha$ 和自由度 $n-p$。\n2. 残差标准误，$\\hat{\\sigma} = \\sqrt{\\mathrm{RSS}/(n-p)}$，它估计了数据的内在变异性 $\\sigma$。\n3. 依赖于设计的因子，$\\sqrt{1+h_0} = \\sqrt{1 + x_0^{\\top}(X^{\\top}X)^{-1}x_0}$，它解释了估计 $\\beta$ 的不确定性以及这种不确定性如何传播到在 $x_0$ 处的预测。它取决于训练设计 $X$ 和新点 $x_0$ 的位置。\n\n**第 2 部分：针对特定设计的实现**\n\n问题要求在一个受控的设置下进行实现。对于简单线性回归 ($p=2$)，设计矩阵 $X$ 的第一列为全1向量，第二列为中心化的预测变量 $x_i$，满足 $\\sum_{i=1}^n x_i = 0$ 和 $\\sum_{i=1}^n x_i^2 = n$。对于这个特定设计，矩阵 $X^{\\top}X$ 变为对角矩阵：\n$$ X^{\\top}X = \\begin{pmatrix} \\sum 1  \\sum x_i \\\\ \\sum x_i  \\sum x_i^2 \\end{pmatrix} = \\begin{pmatrix} n  0 \\\\ 0  n \\end{pmatrix} = nI_2 $$\n其逆矩阵为 $(X^{\\top}X)^{-1} = \\frac{1}{n}I_2$。\n新设计点为 $x_0 = (1, 0)^{\\top}$。该点的杠杆率为：\n$$ h_0 = x_0^{\\top}(X^{\\top}X)^{-1}x_0 = \\begin{pmatrix} 1  0 \\end{pmatrix} \\begin{pmatrix} 1/n  0 \\\\ 0  1/n \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\frac{1}{n} $$\n因此，对于此特定情况，宽度公式简化为：\n$$ W(n, \\alpha) = 2 \\cdot t_{\\alpha/2, n-2} \\cdot \\sqrt{\\frac{\\mathrm{RSS}}{n-2}} \\cdot \\sqrt{1 + \\frac{1}{n}} $$\n程序将计算样本量为 $n$ 和 $2n$ 时的宽度（或其比例分量），以求得所需的比率。宽度比 $W_{2n} / W_n$ 为：\n$$ r_{\\mathrm{full}} = \\frac{2 \\cdot t_{\\alpha/2, 2n-2} \\cdot \\sqrt{\\frac{\\mathrm{RSS}}{2n-2}} \\cdot \\sqrt{1 + \\frac{1}{2n}}}{2 \\cdot t_{\\alpha/2, n-2} \\cdot \\sqrt{\\frac{\\mathrm{RSS}}{n-2}} \\cdot \\sqrt{1 + \\frac{1}{n}}} = \\left(\\frac{t_{\\alpha/2, 2n-2}}{t_{\\alpha/2, n-2}}\\right) \\left(\\sqrt{\\frac{n-2}{2n-2}}\\right) \\left(\\sqrt{\\frac{1+1/(2n)}{1+1/n}}\\right) $$\n比率 $r_{t,\\sigma}$ 是上述表达式中前两项的乘积，不包括依赖于杠杆率的项。\n$$ r_{t,\\sigma} = \\left(\\frac{t_{\\alpha/2, 2n-2}}{t_{\\alpha/2, n-2}}\\right) \\left(\\sqrt{\\frac{n-2}{2n-2}}\\right) $$\n以下代码为给定的测试用例实现了这些计算。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import t\n\ndef solve():\n    \"\"\"\n    Calculates prediction interval width ratios for specified test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (baseline sample size n, significance level alpha)\n    test_cases = [\n        (3, 0.05),   # Case A\n        (6, 0.05),   # Case B\n        (20, 0.05),  # Case C\n        (50, 0.01)   # Case D\n    ]\n\n    # Fixed parameters from the problem statement\n    p = 2      # Number of parameters (intercept + 1 predictor)\n    RSS = 100.0  # Residual Sum of Squares\n\n    results = []\n\n    def calculate_width_components(n_sample, alpha_level):\n        \"\"\"\n        Calculates the components of the prediction interval width.\n        \n        Args:\n            n_sample (int): The sample size n.\n            alpha_level (float): The significance level alpha.\n            \n        Returns:\n            A tuple containing the t-quantile, residual standard error, and leverage factor.\n        \"\"\"\n        if n_sample = p:\n            # Degrees of freedom must be positive.\n            return np.nan, np.nan, np.nan\n        \n        # Degrees of freedom for the t-distribution\n        df = n_sample - p\n        \n        # 1. Student's t-quantile\n        t_quantile = t.ppf(1 - alpha_level / 2, df)\n        \n        # 2. Residual standard error\n        sigma_hat = np.sqrt(RSS / df)\n        \n        # 3. Design dependence (leverage factor)\n        # For the given design, h_0 = 1/n.\n        h0 = 1 / n_sample\n        leverage_factor = np.sqrt(1 + h0)\n        \n        return t_quantile, sigma_hat, leverage_factor\n\n    for n_base, alpha in test_cases:\n        # Calculate components for the baseline sample size n\n        t_n, sigma_n, lev_n = calculate_width_components(n_base, alpha)\n        \n        # Calculate components for the doubled sample size 2n\n        n_doubled = 2 * n_base\n        t_2n, sigma_2n, lev_2n = calculate_width_components(n_doubled, alpha)\n        \n        # --- Calculate r_full ---\n        # The width is proportional to t_quantile * sigma_hat * leverage_factor.\n        # The constant factor of 2 cancels in the ratio.\n        width_prop_n = t_n * sigma_n * lev_n\n        width_prop_2n = t_2n * sigma_2n * lev_2n\n        \n        r_full = width_prop_2n / width_prop_n\n        \n        # --- Calculate |r_full - 0.5| ---\n        abs_dev_from_half = abs(r_full - 0.5)\n        \n        # --- Calculate r_t,sigma ---\n        # Ratio of factors depending only on t-quantile and sigma_hat\n        factor_ts_n = t_n * sigma_n\n        factor_ts_2n = t_2n * sigma_2n\n        \n        r_t_sigma = factor_ts_2n / factor_ts_n\n        \n        # Append the triple of results for the current test case.\n        results.append([r_full, abs_dev_from_half, r_t_sigma])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3160052"}, {"introduction": "上一个练习揭示了杠杆值对预测不确定性的影响。现在，我们将这个概念推向极限，探讨“外推”——在训练数据范围之外进行预测——的危险性。你将通过编程模拟，直观地看到杠杆值$h_0$如何随着预测点远离数据中心而急剧增长，导致预测区间宽度爆炸式增加，并学习如何通过数据增强等方法来应对这一挑战。[@problem_id:3160049]", "problem": "考虑标准简单线性回归模型，该模型满足正态线性模型假设：有 $n$ 个观测值，每个观测值都有一个标量预测变量 $x \\in \\mathbb{R}$ 和一个响应变量 $y \\in \\mathbb{R}$，它们满足 $y = \\beta_0 + \\beta_1 x + \\varepsilon$，其中噪声项 $\\varepsilon$ 是独立同分布的，服从 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$，并且与 $x$ 无关。训练设计矩阵 $X$ 由一个截距列和一个预测变量列构成，并使用普通最小二乘 (OLS) 估计量来拟合模型。对于一个新的预测变量值 $x_0$ 处的未来响应，其预测区间 (PI) 应基于正态线性模型所蕴含的抽样分布以及根据 OLS 残差得到的残差方差估计值来构建。残差标准误 (RSE) 是估计的残差方差的平方根。$x_0$ 处的杠杆值（表示为 $h_0$）是使用 OLS 几何定义的，并取决于设计的经验二阶矩矩阵的逆。\n\n您的任务是以编程方式创建一个具体的场景，该场景展示了在预测变量空间边界或其附近进行预测的情况，并量化杠杆值 $h_0$ 如何增长以及预测区间宽度如何响应。然后，您必须实现并量化两种补救措施：(i) 在边界附近进行数据增强；(ii) 通过将 $x_0$ 裁剪到观测到的预测变量范围内，来施加一个禁止在观测范围之外进行预测的约束。\n\n使用以下科学上真实且可复现的设置：\n- 将随机种子固定为 $42$。\n- 真实参数：$\\beta_0 = 1.25$，$\\beta_1 = -0.8$，以及 $\\sigma = 0.4$。\n- 基线训练设计：从 $[-1, 1]$ 上的均匀分布（即 $x_i \\sim \\mathrm{Uniform}(-1, 1)$）中独立生成 $n = 30$ 个训练预测变量 $x_i$，并生成响应 $y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i$，其中 $\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$。\n- 拟合带截距的 OLS 模型，以从训练残差中获得 OLS 估计值和残差标准误 (RSE) $s$。\n\n对于每个测试用例，计算：\n- 使用 OLS 诱导的帽子矩阵几何，在指定的 $x_0$ 处的杠杆值 $h_0$。\n- 该案例中使用的训练集的拟合 OLS 模型所得到的残差标准误 $s$。\n- 在方差未知的正态线性模型下，根据适当的抽样分布为 $x_0$ 处的新响应构建的置信水平为 $0.95$ 的对称预测区间的全宽 $W$。\n\n设计以下测试套件：\n- 案例 1 (内部预测)：基线训练；在 $x_0 = 0.0$ 处进行预测。\n- 案例 2 (边界预测)：基线训练；在 $x_0 = 1.0$ 处进行预测。\n- 案例 3 (外部预测)：基线训练；在 $x_0 = 1.5$ 处进行预测。\n- 案例 4 (数据增强补救)：通过添加从 $[1.2, 1.8]$ 上的均匀分布中独立抽取的 $m = 30$ 个额外预测变量及其根据相同真实模型生成的响应来增强基线训练集；在增强后的数据上重新拟合 OLS；在 $x_0 = 1.5$ 处进行预测。\n- 案例 5 (裁剪约束补救)：在基线训练拟合下，将外部预测 $x_0 = 1.5$ 裁剪到观测到的预测变量范围 $[-1, 1]$ 内（得到 $x_0^\\text{clip} = 1.0$），并在裁剪后的值处计算预测区间。\n\n您的程序必须：\n- 实现带截距的 OLS，计算残差平方和 (RSS)、残差标准误 $s$ 和逆矩阵 $(X^\\top X)^{-1}$。\n- 使用 OLS 几何计算每个指定 $x_0$ 的杠杆值 $h_0$。\n- 基于适当的分布为每个 $x_0$ 处的未来响应构建 $0.95$ 预测区间，并输出区间的全宽 $W$。\n\n最终输出格式：\n- 生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。每个元素对应一个测试用例，并且其本身必须是按顺序 [$h_0$, $s$, $W$] 排列的包含三个浮点数的列表。\n- 例如，您的程序应为单个案例打印一行类似 [$a_1$, $a_2$, $a_3$] 的内容，对于多个案例，则应为 [$\\text{case}_1$, $\\text{case}_2$, $\\text{case}_3$, $\\text{case}_4$, $\\text{case}_5$]，其中每个 $\\text{case}_k$ 本身就是一个列表 [$h_0$, $s$, $W$]。\n\n在此问题中，所有量都是无单位的。确保您的实现遵循正态线性模型和普通最小二乘法 (OLS) 的定义和构造，并且除了这些基础所隐含的公式外，不使用任何捷径或预计算的公式。", "solution": "经评估，用户提供的问题是有效的。它在科学上基于统计学习的原理，问题陈述完整、一致，并以客观、正式的语言表达。它代表了一个标准、可验证的线性回归分析练习。因此，我们可以着手提供完整的解决方案。\n\n该问题要求对简单线性回归中的预测区间进行定量分析，重点关注在训练数据范围的边界或之外进行预测时杠杆值的影响。我们将首先建立理论框架，然后将其应用于所概述的具体测试用例。\n\n### 理论框架：简单线性回归\n\n我们考虑简单线性回归模型：\n$$ y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i, \\quad i = 1, \\dots, n $$\n模型假设是噪声项 $\\varepsilon_i$ 独立同分布 (i.i.d.)，服从均值为 $0$、方差为 $\\sigma^2$ 的正态分布，记为 $\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$。\n\n在矩阵表示法中，整个训练集的模型为：\n$$ \\mathbf{y} = X\\beta + \\varepsilon $$\n其中 $\\mathbf{y} = [y_1, \\dots, y_n]^\\top$ 是响应向量，$\\beta = [\\beta_0, \\beta_1]^\\top$ 是真实系数向量，$\\varepsilon = [\\varepsilon_1, \\dots, \\varepsilon_n]^\\top$ 是噪声向量。设计矩阵 $X$ 是一个 $n \\times 2$ 的矩阵，其中一列是用于截距的全 1 列，另一列是预测变量值：\n$$ X = \\begin{pmatrix} 1  x_1 \\\\ 1  x_2 \\\\ \\vdots  \\vdots \\\\ 1  x_n \\end{pmatrix} $$\n\n**1. 普通最小二乘 (OLS) 估计**\n\nOLS 估计量 $\\hat{\\beta}$ 是通过最小化残差平方和 (RSS) $RSS(\\beta) = (\\mathbf{y} - X\\beta)^\\top (\\mathbf{y} - X\\beta)$ 找到的。这会产生正规方程组：\n$$ (X^\\top X) \\hat{\\beta} = X^\\top \\mathbf{y} $$\n假设 $X^\\top X$ 是可逆的（如果 $x_i$ 值存在变异，则该条件成立），那么 OLS 估计量是唯一的，由下式给出：\n$$ \\hat{\\beta} = (X^\\top X)^{-1} X^\\top \\mathbf{y} $$\n\n**2. 残差标准误 (RSE)**\n\n残差是观测值与拟合值之间的差异：$\\mathbf{e} = \\mathbf{y} - \\hat{\\mathbf{y}} = \\mathbf{y} - X\\hat{\\beta}$。RSS 可以表示为 $\\mathbf{e}^\\top \\mathbf{e}$。在正态线性模型假设下，误差方差 $\\sigma^2$ 的一个无偏估计量是均方误差 $s^2$：\n$$ s^2 = \\frac{RSS}{n-p} = \\frac{\\mathbf{e}^\\top \\mathbf{e}}{n-2} $$\n其中 $p=2$ 是被估计的参数数量（$\\beta_0$ 和 $\\beta_1$）。残差标准误 (RSE) 是该值的平方根，即 $s = \\sqrt{s^2}$，它可作为误差标准差 $\\sigma$ 的估计值。\n\n**3. 预测与杠杆值**\n\n对于一个新的预测变量值 $x_0$，预测响应为 $\\hat{y}_0 = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_0$。这可以写成向量形式 $\\hat{y}_0 = (\\mathbf{x}_0^*)^\\top \\hat{\\beta}$，其中 $\\mathbf{x}_0^* = [1, x_0]^\\top$。\n\n该预测的质量取决于其不确定性。一个未来响应 $y_0$ 在 $x_0$ 处的预测区间考虑了两个误差来源：估计回归线的不确定性（即 $\\hat{y}_0$ 的方差）和新观测值围绕真实回归线的内在变异性（$\\varepsilon_0$ 的方差，即 $\\sigma^2$）。预测误差为 $y_0 - \\hat{y}_0$。其方差为：\n$$ \\mathrm{Var}(y_0 - \\hat{y}_0) = \\mathrm{Var}(y_0) + \\mathrm{Var}(\\hat{y}_0) = \\sigma^2 + \\mathrm{Var}((\\mathbf{x}_0^*)^\\top \\hat{\\beta}) $$\n使用性质 $\\mathrm{Var}(\\hat{\\beta}) = \\sigma^2(X^\\top X)^{-1}$，我们得到：\n$$ \\mathrm{Var}(y_0 - \\hat{y}_0) = \\sigma^2 + (\\mathbf{x}_0^*)^\\top (\\sigma^2(X^\\top X)^{-1}) \\mathbf{x}_0^* = \\sigma^2 \\left( 1 + (\\mathbf{x}_0^*)^\\top (X^\\top X)^{-1} \\mathbf{x}_0^* \\right) $$\n项 $h_0 = (\\mathbf{x}_0^*)^\\top (X^\\top X)^{-1} \\mathbf{x}_0^*$ 被定义为点 $x_0$ 的**杠杆值**。它衡量了该点对其自身拟合值的影响。因此，预测误差的方差为 $\\sigma^2(1+h_0)$。在简单线性回归中，杠杆值的解析表达式为 $h_0 = \\frac{1}{n} + \\frac{(x_0 - \\bar{x})^2}{\\sum_{i=1}^n (x_i - \\bar{x})^2}$，这清楚地表明，随着 $x_0$ 远离训练预测变量的均值 $\\bar{x}$，杠杆值呈二次方增长。\n\n**4. 预测区间 (PI)**\n\n由于 $\\sigma^2$ 未知，我们使用其估计值 $s^2$。标准化预测误差服从自由度为 $n-2$ 的学生 t 分布：\n$$ \\frac{y_0 - \\hat{y}_0}{s \\sqrt{1 + h_0}} \\sim t_{n-2} $$\n为 $y_0$ 构建的 $100(1 - \\alpha)\\%$ 预测区间为：\n$$ \\hat{y}_0 \\pm t_{n-2, 1-\\alpha/2} \\cdot s \\sqrt{1 + h_0} $$\n其中 $t_{n-2, 1-\\alpha/2}$ 是给定置信水平下 t 分布的临界值。对于此问题，置信水平为 $0.95$，因此 $\\alpha=0.05$，我们使用尾部概率为 $0.025$ 的 t 分位数。该区间的全宽 $W$ 为：\n$$ W = 2 \\cdot t_{n-2, 1-\\alpha/2} \\cdot s \\sqrt{1 + h_0} $$\n此公式表明，预测区间宽度直接受 RSE ($s$) 的影响，并随着杠杆值 ($h_0$) 的增大而增大。\n\n### 测试用例的计算程序\n\n问题指定了五个测试用例来演示这些概念。\n\n- **案例 1 (内部)：** $x_0 = 0.0$。此处，$x_0$ 接近训练数据分布 $\\mathrm{Uniform}(-1, 1)$ 的中心。我们预计杠杆值较低，预测区间相对较窄。\n- **案例 2 (边界)：** $x_0 = 1.0$。该点位于训练数据支撑集的边界。杠杆值将高于案例 1，导致区间更宽。\n- **案例 3 (外部)：** $x_0 = 1.5$。这是外推，因为 $x_0$ 位于训练范围之外。杠杆值以及因此的 PI 宽度预计将大幅增加。\n- **案例 4 (数据增强)：** 通过在 $[1.2, 1.8]$ 区域添加新的训练数据点，我们扩展了训练数据的支撑集。当我们再在 $x_0=1.5$ 处进行预测时，该点不再是外推而是内插。与案例 3 相比，这应该会显著降低在 $x_0=1.5$ 处的杠杆值，并缩小区间的宽度。RSE $s$ 也将在更大的数据集（大小为 $n+m=60$）上重新估计。\n- **案例 5 (裁剪约束)：** 这种补救措施通过强制规定来避免外推。任何在既定范围 $[-1, 1]$ 之外的 $x_0$ 预测查询都会被裁剪到最近的边界点。对于 $x_0=1.5$，裁剪后的值为 $x_0^\\text{clip}=1.0$。然后使用原始基线模型在该裁剪点上进行分析。因此，此案例的计算和结果将与案例 2 的完全相同。\n\n对于每个案例，我们将以编程方式生成指定的数据，拟合 OLS 模型，并计算所需的三个量：杠杆值 $h_0$、RSE $s$ 和 PI 宽度 $W$。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import t\n\ndef solve():\n    \"\"\"\n    Computes leverage, RSE, and prediction interval width for five test cases\n    in a simple linear regression scenario.\n    \"\"\"\n    # Define problem constants and setup\n    RANDOM_SEED = 42\n    BETA_0 = 1.25\n    BETA_1 = -0.8\n    SIGMA = 0.4\n    N_BASE = 30\n    CONFIDENCE_LEVEL = 0.95\n    ALPHA = 1.0 - CONFIDENCE_LEVEL\n\n    rng = np.random.default_rng(RANDOM_SEED)\n\n    # Generate baseline training data\n    x_base = rng.uniform(-1, 1, size=N_BASE)\n    epsilon_base = rng.normal(0, SIGMA, size=N_BASE)\n    y_base = BETA_0 + BETA_1 * x_base + epsilon_base\n\n    # Define the five test cases\n    test_cases_config = [\n        {'id': 1, 'x0': 0.0, 'augment': False, 'clip': False},\n        {'id': 2, 'x0': 1.0, 'augment': False, 'clip': False},\n        {'id': 3, 'x0': 1.5, 'augment': False, 'clip': False},\n        {'id': 4, 'x0': 1.5, 'augment': True,  'clip': False},\n        {'id': 5, 'x0': 1.5, 'augment': False, 'clip': True},\n    ]\n\n    results = []\n\n    for case in test_cases_config:\n        x_train, y_train = x_base, y_base\n        \n        # Case 4: Augment the training data\n        if case['augment']:\n            M_AUG = 30\n            x_aug = rng.uniform(1.2, 1.8, size=M_AUG)\n            epsilon_aug = rng.normal(0, SIGMA, size=M_AUG)\n            y_aug = BETA_0 + BETA_1 * x_aug + epsilon_aug\n            x_train = np.concatenate((x_base, x_aug))\n            y_train = np.concatenate((y_base, y_aug))\n\n        x_pred = case['x0']\n        \n        # Case 5: Clip the prediction point\n        if case['clip']:\n            # As per problem statement, clip to the theoretical range [-1, 1]\n            x_pred = np.clip(x_pred, -1.0, 1.0)\n            \n        # OLS estimation\n        n = len(x_train)\n        p = 2  # Number of parameters (beta_0, beta_1)\n        df = n - p # Degrees of freedom\n\n        # Construct the design matrix X\n        X = np.c_[np.ones(n), x_train]\n\n        # Calculate inverse of (X^T * X)\n        try:\n            inv_XTX = np.linalg.inv(X.T @ X)\n        except np.linalg.LinAlgError:\n            # This should not happen with the generated data\n            results.append([float('nan'), float('nan'), float('nan')])\n            continue\n\n        # Estimate coefficients beta_hat\n        beta_hat = inv_XTX @ X.T @ y_train\n\n        # Calculate Residual Sum of Squares (RSS)\n        y_hat = X @ beta_hat\n        residuals = y_train - y_hat\n        rss = residuals.T @ residuals\n\n        # Calculate Residual Standard Error (RSE), s\n        s = np.sqrt(rss / df)\n\n        # Calculate leverage h_0 for the new point x_pred\n        x0_star = np.array([1.0, x_pred])\n        h0 = x0_star.T @ inv_XTX @ x0_star\n\n        # Calculate prediction interval width W\n        # Find the t-critical value for the 95% PI\n        t_crit = t.ppf(1 - ALPHA / 2, df)\n        \n        # Calculate full width W\n        W = 2 * t_crit * s * np.sqrt(1 + h0)\n        \n        results.append([h0, s, W])\n\n    # Format the final output string as specified\n    formatted_results = [f\"[{h:.10f},{s:.10f},{w:.10f}]\" for h, s, w in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3160049"}, {"introduction": "我们的讨论到目前为止主要集中在新的预测点$x_0$的位置。然而，训练数据本身的质量同样至关重要。本练习将引导你扮演数据侦探的角色，学习使用库克距离（Cook's distance）等诊断工具来识别和评估“强影响点”的破坏力，并量化移除这些点后，预测区间如何变得更加可靠。[@problem_id:3160002]", "problem": "给定三个独立的简单线性回归场景。在每个场景中，数据均来自模型 $y = \\beta_0 + \\beta_1 x + \\varepsilon$，其中误差项 $\\varepsilon$ 被假定为独立同分布，其均值为 $0$，方差为常数 $\\sigma^2$。对于每个场景，您必须拟合带截距的普通最小二乘模型，计算残差标准误 $\\hat{\\sigma}$，使用 Cook 距离识别强影响点，并研究（一次移除一个）每个强影响点对未来观测值在三个典型设计点上的双侧预测区间宽度的影响。您的程序必须是一个完整的、可运行的程序，且仅使用指定的运行时环境。所有计算都必须以纯数学术语进行，不涉及物理单位。不涉及角度。请用小数表示任何置信水平，不要使用百分号。\n\n在问题陈述中应使用的基本原则（无需引用快捷公式）：普通最小二乘法最小化残差平方和；残差标准误由残差平方和及相应的自由度计算得出；杠杆值源于由设计矩阵定义的帽子矩阵；Cook 距离衡量每个观测值对拟合回归的影响；在误差正态分布的假设下，未来观测值的双侧预测区间是使用学生t分布构建的，并同时考虑了估计不确定性和不可约误差。\n\n为每个场景实施以下步骤：\n- 拟合带截距的普通最小二乘模型，以获得 $\\hat{\\beta}_0$、$\\hat{\\beta}_1$ 和残差。\n- 根据拟合残差和自由度 $n - p$ 计算残差标准误 $\\hat{\\sigma}$，其中 $n$ 是样本量，$p$ 是包括截距在内的已拟合参数数量。\n- 计算每个观测值的帽子矩阵对角线元素（杠杆值）和 Cook 距离。将 Cook 距离超过该场景指定阈值 $\\tau$ 的观测值识别为强影响点。\n- 将 $x$ 的最小值、$x$ 的均值和 $x$ 的最大值定义为三个典型设计点。对于每个拟合模型，使用置信水平 $1 - \\alpha$（$\\alpha$ 值如下所示）计算在这三个设计点上各自的双侧预测区间宽度。然后，通过计算这三个宽度的平均值来汇总，为该模型生成一个单一的宽度摘要。\n- 对于每个场景，报告一个浮点数列表，其中包含基线平均宽度（使用所有数据），其后是逐个移除每个强影响点后的平均宽度（每次移除一个强影响点，重新拟合，然后重新计算）。如果没有强影响点，则该列表仅包含基线平均宽度。\n\n使用以下测试套件。在每种情况下，数组应按元素方式解释，并且所有数字都是精确常数。\n\n场景 A：\n- 输入：\n  - $x = [0,1,2,3,4,5,6,7,8,9,10,11]$。\n  - 通过 $y_i = 2 + 1.3 x_i + r_i$ 定义 $y$，其中残差 $r = [0.2,-0.1,0.0,0.1,-0.2,0.05,-0.15,0.1,-0.05,0.1,16.0,-0.1]$。\n  - 置信参数 $\\alpha = 0.05$。\n  - Cook 距离阈值规则 $\\tau = 4/n$，其中 $n$ 是此场景中的观测值数量。\n- 场景 A 的输出：一个浮点数列表 $[w_0, w_1, \\dots]$，其中 $w_0$ 是在三个典型设计点上的基线平均宽度，$w_j$（$j \\ge 1$）是移除第 $j$ 个强影响点（强影响点按其原始索引升序排列）后的平均宽度。\n\n场景 B：\n- 输入：\n  - $x = [0,1,2,3,4,5,6,7,8,9]$。\n  - 通过 $y_i = 1 + 2 x_i + r_i$ 定义 $y$，其中残差 $r = [0.02,-0.03,0.01,0.00,-0.02,0.01,-0.01,0.02,0.00,-0.02]$。\n  - 置信参数 $\\alpha = 0.05$。\n  - Cook 距离阈值 $\\tau = 10$。\n- 场景 B 的输出：一个如上所述的浮点数列表。如果未检测到强影响点，则仅返回基线平均宽度。\n\n场景 C：\n- 输入：\n  - $x = [-5,-3,-1,0,1,2,3,4,5,20,-10,6,7,8,9]$。\n  - 通过 $y_i = 0.5 + 0.8 x_i + r_i$ 定义 $y$，其中残差 $r = [0.1,-0.1,0.05,0.0,0.02,-0.03,0.04,-0.02,0.01,-11.5,12.5,-0.05,0.03,-0.04,0.02]$。\n  - 置信参数 $\\alpha = 0.05$。\n  - Cook 距离阈值规则 $\\tau = 4/n$，其中 $n$ 是此场景中的观测值数量。\n- 场景 C 的输出：一个如上所述的浮点数列表。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含三个场景的结果，格式为用方括号括起来的、以逗号分隔的列表的列表，例如 $[[a_1,a_2],[b_1],[c_1,c_2,c_3]]$，每个浮点数使用标准四舍五入到 $6$ 位小数。这三个列表必须按场景 A、场景 B、场景 C 的顺序出现。不应打印任何其他文本。", "solution": "该问题要求对三个不同场景下的简单线性回归模型进行分析。核心任务包括拟合模型、识别强影响数据点，以及评估它们对预测区间宽度的影响。该方法基于普通最小二乘（OLS）回归和标准统计诊断的原理。\n\n**1. 简单线性回归模型**\n基础统计模型是一个简单线性回归：\n$$y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i$$\n其中 $y_i$ 是第 $i$ 个观测值的响应变量，$x_i$ 是预测变量，$\\beta_0$ 是截距，$\\beta_1$ 是斜率，$\\varepsilon_i$ 是独立同分布的随机误差，其均值为 $E[\\varepsilon_i] = 0$，方差为常数 $\\text{Var}(\\varepsilon_i) = \\sigma^2$。问题为每个场景提供了数据对 $(x_i, y_i)$。\n\n**2. 普通最小二乘（OLS）估计**\nOLS 方法通过最小化残差平方和（RSS）来估计参数 $\\beta_0$ 和 $\\beta_1$。估计参数（表示为 $\\hat{\\beta}_0$ 和 $\\hat{\\beta}_1$）由以下公式给出：\n$$ \\hat{\\beta}_1 = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2} $$\n$$ \\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x} $$\n其中 $n$ 是观测值的数量，$\\bar{x} = \\frac{1}{n}\\sum_{i=1}^n x_i$ 是预测变量的样本均值，$\\bar{y} = \\frac{1}{n}\\sum_{i=1}^n y_i$ 是响应变量的样本均值。\n\n拟合值为 $\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i$，残差为 $e_i = y_i - \\hat{y}_i$。\n\n**3. 残差标准误（RSE）**\nRSE，表示为 $\\hat{\\sigma}$，是误差项标准差 $\\sigma$ 的一个估计。它由 RSS 计算得出：\n$$ \\text{RSS} = \\sum_{i=1}^n e_i^2 = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 $$\n然后 RSE 按如下方式计算：\n$$ \\hat{\\sigma} = \\sqrt{\\frac{\\text{RSS}}{n-p}} $$\n其中自由度为 $n-p$。对于带截距的简单线性回归，估计的参数数量为 $p=2$（对应 $\\hat{\\beta}_0$ 和 $\\hat{\\beta}_1$），因此自由度为 $n-2$。\n\n**4. 影响诊断**\n为识别强影响点，我们使用 Cook 距离。该度量结合了数据点的杠杆值及其残差大小的信息。\n\n首先，计算每个观测值 $i$ 的杠杆值 $h_{ii}$。杠杆值衡量一个观测值的预测变量值 $x_i$ 与所有预测变量值均值的偏离程度。高杠杆点有可能对回归拟合产生强烈影响。杠杆值是帽子矩阵 $H = X(X^T X)^{-1} X^T$ 的第 $i$ 个对角元素，其中 $X$ 是设计矩阵。对于简单线性回归，这可以简化为：\n$$ h_{ii} = \\frac{1}{n} + \\frac{(x_i - \\bar{x})^2}{\\sum_{j=1}^n (x_j - \\bar{x})^2} $$\n\n其次，为每个观测值计算 Cook 距离 $D_i$：\n$$ D_i = \\frac{e_i^2}{p \\cdot \\hat{\\sigma}^2} \\left[ \\frac{h_{ii}}{(1-h_{ii})^2} \\right] $$\n如果一个观测值的 Cook 距离超过给定阈值，即 $D_i > \\tau$，则该观测值被识别为强影响点。在此问题中，阈值 $\\tau$ 是一个固定值或样本量 $n$ 的函数，例如 $\\tau = 4/n$。\n\n**5. 预测区间（PI）**\n预测区间提供了一个范围，在给定的预测变量值 $x_0$ 下，未来观测值 $y_0$ 有望以一定的置信水平 $1-\\alpha$ 落入该范围。假设误差 $\\varepsilon_i$ 服从正态分布，$100(1-\\alpha)\\%$ 的 PI 构建如下：\n$$ \\hat{y}_0 \\pm t_{n-p, \\alpha/2} \\cdot \\hat{\\sigma} \\sqrt{1 + \\frac{1}{n} + \\frac{(x_0 - \\bar{x})^2}{\\sum_{j=1}^n (x_j - \\bar{x})^2}} $$\n其中 $\\hat{y}_0 = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_0$ 是在 $x_0$ 处的预测值，$t_{n-p, \\alpha/2}$ 是自由度为 $n-p$ 的学生 $t$ 分布的临界值，其上尾面积为 $\\alpha/2$。预测的标准误既包含了估计回归线的不确定性，也包含了一个新观测值的内在变异性（$\\sigma^2$）。\n\n该区间的宽度为：\n$$ W(x_0) = 2 \\cdot t_{n-p, \\alpha/2} \\cdot \\hat{\\sigma} \\sqrt{1 + \\frac{1}{n} + \\frac{(x_0 - \\bar{x})^2}{\\sum_{j=1}^n (x_j - \\bar{x})^2}} $$\n\n**6. 算法实现**\n对于每个场景，执行以下过程：\n1.  **数据生成**：按照问题陈述中的规定构造向量 $x$ 和 $y$。\n2.  **基线分析**：\n    a. 对完整数据集 $(x, y)$ 拟合一个简单线性回归模型，以获得 $\\hat{\\beta}_0$、$\\hat{\\beta}_1$、$\\hat{\\sigma}$ 及其他模型统计量。\n    b. 在三个特定的设计点计算 PI 宽度 $W(x_0)$：$x_{0, \\text{min}} = \\min(x)$、 $x_{0, \\text{mean}} = \\bar{x}$ 和 $x_{0, \\text{max}} = \\max(x)$。\n    c. 通过平均这三个宽度来计算基线平均宽度 $w_0$。这是该场景结果列表中的第一个值。\n3.  **影响分析**：\n    a. 使用完整模型，计算所有观测值的杠杆值 $h_{ii}$ 和 Cook 距离 $D_i$。\n    b. 通过收集满足 $D_i > \\tau$ 的索引 $i$ 来确定强影响点集合。这些索引按升序排序。\n4.  **敏感性分析**：\n    a. 如果未找到强影响点，则该场景的处理终止，结果就是 $[w_0]$。\n    b. 如果找到强影响点，则遍历它们排序后的索引。对于每个强影响点，将其从数据集中移除，创建一个新的、更小的数据集。\n    c. 对于每个新数据集，重新拟合回归模型，并使用与步骤 2 相同的程序（使用新数据集的属性：$n_{new}$、$\\bar{x}_{new}$ 等）重新计算平均 PI 宽度 ($w_j$)。\n    d. 将每个新的平均宽度 ($w_1, w_2, \\dots$) 追加到结果列表中。\n5.  **最终输出**：整理所有场景的宽度列表，并将其格式化为指定的最终输出字符串。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import t\n\ndef solve():\n    \"\"\"\n    Main function to solve the three regression scenarios and print the results.\n    \"\"\"\n\n    def fit_and_get_stats(x, y):\n        \"\"\"\n        Fits a simple linear regression model and computes relevant statistics.\n        Returns a dictionary of statistics or None if fitting is not possible.\n        \"\"\"\n        n = len(x)\n        if n = 2:  # Cannot fit or compute RSE with = 2 points\n            return None\n        \n        x_mean = np.mean(x)\n        y_mean = np.mean(y)\n        \n        S_xx = np.sum((x - x_mean)**2)\n        if S_xx == 0:  # Avoid division by zero if all x are the same\n            return None\n            \n        S_xy = np.sum((x - x_mean) * (y - y_mean))\n        \n        beta1_hat = S_xy / S_xx\n        beta0_hat = y_mean - beta1_hat * x_mean\n        \n        y_hat = beta0_hat + beta1_hat * x\n        residuals = y - y_hat\n        rss = np.sum(residuals**2)\n        p = 2  # Number of parameters (intercept and slope)\n        dof = n - p\n        rse = np.sqrt(rss / dof)\n        \n        leverages = 1/n + (x - x_mean)**2 / S_xx\n        cooks_d = (residuals**2 / (p * rse**2)) * (leverages / (1 - leverages)**2)\n        \n        return {\n            'n': n,\n            'dof': dof,\n            'rse': rse,\n            'cooks_d': cooks_d,\n            'x_mean': x_mean,\n            'S_xx': S_xx\n        }\n\n    def get_avg_pi_width(stats, x_coords, alpha_val):\n        \"\"\"\n        Calculates the average prediction interval width for a given fitted model.\n        \"\"\"\n        if stats is None:\n            return np.nan\n        \n        n = stats['n']\n        dof = stats['dof']\n        rse = stats['rse']\n        x_mean = stats['x_mean']\n        S_xx = stats['S_xx']\n        \n        if S_xx == 0:\n            return np.nan\n\n        t_crit = t.ppf(1 - alpha_val / 2, dof)\n        \n        x0_points = [np.min(x_coords), np.mean(x_coords), np.max(x_coords)]\n        \n        widths = []\n        for x0 in x0_points:\n            se_pred_factor = np.sqrt(1 + 1/n + (x0 - x_mean)**2 / S_xx)\n            width = 2 * t_crit * rse * se_pred_factor\n            widths.append(width)\n            \n        return np.mean(widths)\n\n    def process_scenario(x_data, y_data, alpha, tau_val):\n        \"\"\"\n        Runs the full analysis for a single scenario.\n        \"\"\"\n        results_for_scenario = []\n        \n        # 1. Baseline analysis on the full dataset\n        baseline_stats = fit_and_get_stats(x_data, y_data)\n        baseline_avg_width = get_avg_pi_width(baseline_stats, x_data, alpha)\n        results_for_scenario.append(baseline_avg_width)\n        \n        # 2. Identify influential points\n        cooks_distances = baseline_stats['cooks_d']\n        influential_indices = np.where(cooks_distances  tau_val)[0]\n        # np.where returns sorted indices, so no extra sorting is needed.\n        \n        # 3. Re-run analysis after removing each influential point one-by-one\n        for idx in influential_indices:\n            x_new = np.delete(x_data, idx)\n            y_new = np.delete(y_data, idx)\n            \n            new_stats = fit_and_get_stats(x_new, y_new)\n            new_avg_width = get_avg_pi_width(new_stats, x_new, alpha)\n            results_for_scenario.append(new_avg_width)\n            \n        return results_for_scenario\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"x_raw\": [0,1,2,3,4,5,6,7,8,9,10,11],\n            \"y_def\": lambda x, r: 2 + 1.3 * x + r,\n            \"r_raw\": [0.2,-0.1,0.0,0.1,-0.2,0.05,-0.15,0.1,-0.05,0.1,16.0,-0.1],\n            \"alpha\": 0.05,\n            \"tau_rule\": lambda n: 4/n\n        },\n        {\n            \"x_raw\": [0,1,2,3,4,5,6,7,8,9],\n            \"y_def\": lambda x, r: 1 + 2 * x + r,\n            \"r_raw\": [0.02,-0.03,0.01,0.00,-0.02,0.01,-0.01,0.02,0.00,-0.02],\n            \"alpha\": 0.05,\n            \"tau_rule\": lambda n: 10\n        },\n        {\n            \"x_raw\": [-5,-3,-1,0,1,2,3,4,5,20,-10,6,7,8,9],\n            \"y_def\": lambda x, r: 0.5 + 0.8 * x + r,\n            \"r_raw\": [0.1,-0.1,0.05,0.0,0.02,-0.03,0.04,-0.02,0.01,-11.5,12.5,-0.05,0.03,-0.04,0.02],\n            \"alpha\": 0.05,\n            \"tau_rule\": lambda n: 4/n\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        x = np.array(case['x_raw'], dtype=float)\n        r = np.array(case['r_raw'], dtype=float)\n        y = case['y_def'](x, r)\n        alpha = case['alpha']\n        n = len(x)\n        tau = case['tau_rule'](n)\n        \n        scenario_results = process_scenario(x, y, alpha, tau)\n        all_results.append(scenario_results)\n\n    # Format the final output string as specified\n    output_parts = []\n    for res_list in all_results:\n        formatted_list = [f\"{x:.6f}\" for x in res_list]\n        output_parts.append(f\"[{','.join(formatted_list)}]\")\n    \n    final_output_string = f\"[{','.join(output_parts)}]\"\n    print(final_output_string)\n\nsolve()\n```", "id": "3160002"}]}