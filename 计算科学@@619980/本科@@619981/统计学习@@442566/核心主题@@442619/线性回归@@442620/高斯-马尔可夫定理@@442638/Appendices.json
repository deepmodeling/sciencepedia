{"hands_on_practices": [{"introduction": "在高斯-马尔可夫定理中，“最佳线性无偏估计量”（BLUE）设定了三个标准：线性、无偏和最佳（即最小方差）。在我们寻找“最佳”估计量之前，首先必须理解前两个基本资格标准：线性和无偏性。本练习将帮助你识别哪些潜在的估计量满足这些基本要求，并揭示一个重要事实：满足这些条件的估计量可能不止一个，这就引出了我们为何需要一个更进一步的“最佳”标准的问题。", "problem": "在统计建模中，估计量是根据观测数据计算给定数量的估计值的一种规则。考虑一个简单的模型，其中对一个恒定但未知的物理量 $\\mu$ 进行了一系列 $n$ 次测量，即 $Y_1, Y_2, \\dots, Y_n$。该模型由下式给出：\n$$Y_i = \\mu + \\epsilon_i, \\quad \\text{for } i=1, \\dots, n$$\n项 $\\epsilon_i$ 代表随机测量误差。这些误差被假定为不相关的，其期望值为零（$E[\\epsilon_i]=0$），并且对于所有的 $i$，都有一个恒定的方差 $\\text{Var}(\\epsilon_i)=\\sigma^2$。\n\n如果参数 $\\mu$ 的一个估计量 $\\hat{\\mu}$ 可以写成观测值的线性组合：$\\hat{\\mu} = \\sum_{i=1}^n c_i Y_i$，其中系数 $c_i$ 是常数，则该估计量被定义为*线性*估计量。\n如果一个估计量 $\\hat{\\mu}$ 的期望值等于它所估计的真实参数，即 $E[\\hat{\\mu}]=\\mu$，则该估计量被定义为*无偏*估计量。\n\n基于这组观测数据，提出了三种不同的估计量来估计 $\\mu$。假设 $n > 1$。\n1.  $\\hat{\\mu}_1 = \\frac{1}{n} \\sum_{i=1}^n Y_i$\n2.  $\\hat{\\mu}_2 = \\frac{1}{n-1} \\sum_{i=1}^n Y_i$\n3.  $\\hat{\\mu}_3 = \\frac{Y_1 + Y_n}{2}$\n\n这三个估计量中，哪些既是线性的又是无偏的？\n\nA. 仅 $\\hat{\\mu}_1$\n\nB. 仅 $\\hat{\\mu}_3$\n\nC. $\\hat{\\mu}_1$ 和 $\\hat{\\mu}_2$\n\nD. $\\hat{\\mu}_1$ 和 $\\hat{\\mu}_3$\n\nE. 所有三个估计量都是线性和无偏的。", "solution": "我们给定的模型是 $Y_{i}=\\mu+\\epsilon_{i}$，其中 $E[\\epsilon_{i}]=0$ 且 $\\text{Var}(\\epsilon_{i})=\\sigma^{2}$，并且 $\\epsilon_{i}$ 是不相关的。因此，对于每个 $i$，\n$$\nE[Y_{i}]=E[\\mu+\\epsilon_{i}]=\\mu+E[\\epsilon_{i}]=\\mu.\n$$\n一个线性估计量具有形式 $\\hat{\\mu}=\\sum_{i=1}^{n}c_{i}Y_{i}$。其期望值为\n$$\nE[\\hat{\\mu}]=E\\Bigg[\\sum_{i=1}^{n}c_{i}Y_{i}\\Bigg]=\\sum_{i=1}^{n}c_{i}E[Y_{i}]=\\sum_{i=1}^{n}c_{i}\\mu=\\mu\\sum_{i=1}^{n}c_{i}.\n$$\n因此，无偏性的充分必要条件是\n$$\n\\sum_{i=1}^{n}c_{i}=1.\n$$\n\n现在检查每个提出的估计量。\n\n1) 对于 $\\hat{\\mu}_{1}=\\frac{1}{n}\\sum_{i=1}^{n}Y_{i}$，系数为 $c_{i}=\\frac{1}{n}$（对所有 $i$）。那么\n$$\n\\sum_{i=1}^{n}c_{i}=\\sum_{i=1}^{n}\\frac{1}{n}=1,\n$$\n所以 $\\hat{\\mu}_{1}$ 是线性和无偏的。\n\n2) 对于 $\\hat{\\mu}_{2}=\\frac{1}{n-1}\\sum_{i=1}^{n}Y_{i}$，系数为 $c_{i}=\\frac{1}{n-1}$（对所有 $i$）。那么\n$$\n\\sum_{i=1}^{n}c_{i}=\\sum_{i=1}^{n}\\frac{1}{n-1}=\\frac{n}{n-1}\\neq 1 \\quad \\text{for } n>1,\n$$\n所以 $\\hat{\\mu}_{2}$ 是线性的但不是无偏的。\n\n3) 对于 $\\hat{\\mu}_{3}=\\frac{Y_{1}+Y_{n}}{2}$，系数为 $c_{1}=\\frac{1}{2}$，$c_{n}=\\frac{1}{2}$，且对于 $i\\notin\\{1,n\\}$，$c_{i}=0$。那么\n$$\n\\sum_{i=1}^{n}c_{i}=\\frac{1}{2}+\\frac{1}{2}=1,\n$$\n所以 $\\hat{\\mu}_{3}$ 是线性和无偏的。\n\n因此，在这三个估计量中，恰好 $\\hat{\\mu}_{1}$ 和 $\\hat{\\mu}_{3}$ 既是线性的又是无偏的。", "answer": "$$\\boxed{D}$$", "id": "1919547"}, {"introduction": "既然我们知道可以存在多个线性无偏估计量 [@problem_id:1919547]，我们该如何选择？本练习将引入效率的概念，它通过方差来衡量。通过直接比较两个不同无偏估计量的方差，你将具体理解高斯-马尔可夫定理中“最佳”的含义——即拥有最小的方差。", "problem": "在一个确定物理常数 $\\mu$ 的实验中，进行了三次独立测量 $y_1, y_2,$ 和 $y_3$。这些测量值由方程 $y_i = \\mu + \\epsilon_i$ 建模，其中 $i \\in \\{1, 2, 3\\}$。随机误差 $\\epsilon_i$ 是不相关的，每个误差的期望值为零，并具有一个记为 $\\sigma^2$ 的常数有限方差。\n\n提出了两种不同的 $\\mu$ 估计量：\n1.  标准样本均值：$\\hat{\\mu}_1 = \\frac{y_1 + y_2 + y_3}{3}$\n2.  一个舍弃第二次测量的替代估计量：$\\hat{\\mu}_2 = \\frac{y_1 + y_3}{2}$\n\n可以证明 $\\hat{\\mu}_1$ 和 $\\hat{\\mu}_2$ 都是 $\\mu$ 的无偏估计量。你的任务是比较它们的效率。具体来说，计算替代估计量的方差与样本均值方差的比值，$\\frac{\\text{Var}(\\hat{\\mu}_2)}{\\text{Var}(\\hat{\\mu}_1)}$。", "solution": "我们首先计算每个估计量的方差。根据方差的性质，对于不相关的随机变量 $Y_i$，线性组合的方差为 $\\operatorname{Var}(\\sum a_i Y_i) = \\sum a_i^2 \\operatorname{Var}(Y_i)$。题目中给出，每次测量的方差为 $\\operatorname{Var}(y_i) = \\sigma^2$。\n\n对于估计量 $\\hat{\\mu}_1 = \\frac{y_1 + y_2 + y_3}{3}$：\n$$\n\\operatorname{Var}(\\hat{\\mu}_1) = \\operatorname{Var}\\left(\\frac{1}{3}y_1 + \\frac{1}{3}y_2 + \\frac{1}{3}y_3\\right) = \\left(\\frac{1}{3}\\right)^2 \\operatorname{Var}(y_1) + \\left(\\frac{1}{3}\\right)^2 \\operatorname{Var}(y_2) + \\left(\\frac{1}{3}\\right)^2 \\operatorname{Var}(y_3)\n$$\n$$\n\\operatorname{Var}(\\hat{\\mu}_1) = \\frac{1}{9}\\sigma^2 + \\frac{1}{9}\\sigma^2 + \\frac{1}{9}\\sigma^2 = \\frac{3\\sigma^2}{9} = \\frac{\\sigma^2}{3}\n$$\n对于估计量 $\\hat{\\mu}_2 = \\frac{y_1 + y_3}{2}$：\n$$\n\\operatorname{Var}(\\hat{\\mu}_2) = \\operatorname{Var}\\left(\\frac{1}{2}y_1 + \\frac{1}{2}y_3\\right) = \\left(\\frac{1}{2}\\right)^2 \\operatorname{Var}(y_1) + \\left(\\frac{1}{2}\\right)^2 \\operatorname{Var}(y_3)\n$$\n$$\n\\operatorname{Var}(\\hat{\\mu}_2) = \\frac{1}{4}\\sigma^2 + \\frac{1}{4}\\sigma^2 = \\frac{2\\sigma^2}{4} = \\frac{\\sigma^2}{2}\n$$\n最后，我们计算两个方差的比值：\n$$\n\\frac{\\operatorname{Var}(\\hat{\\mu}_2)}{\\operatorname{Var}(\\hat{\\mu}_1)} = \\frac{\\sigma^2/2}{\\sigma^2/3} = \\frac{1}{2} \\cdot \\frac{3}{1} = \\frac{3}{2}\n$$", "answer": "$$\\boxed{\\frac{3}{2}}$$", "id": "1919577"}, {"introduction": "我们已经学会了如何比较给定的估计量，但我们能从第一性原理出发，推导出最优的那个吗？[@problem_id:1919577] 本练习将指导你在一个简单情景下，通过最小化一般线性估计量的方差，找到“最佳线性无偏估计量”（BLUE）。你将亲自证明为何一组特定的权重（最终构成我们所熟悉的样本均值）是最高效的选择，从而领会高斯-马尔可夫定理的核心思想。", "problem": "一位实验员对一个真实未知值为 $\\mu$ 的物理量进行了两次独立测量，得到了 $y_1$ 和 $y_2$。每次测量都受到随机误差的影响。这些测量的统计模型由 $y_i = \\mu + \\epsilon_i$ 给出，其中 $i=1, 2$。\n\n假设随机误差 $\\epsilon_1$ 和 $\\epsilon_2$ 满足以下标准性质：\n1.  每个误差的期望值为零，即 $E[\\epsilon_i] = 0$。\n2.  误差具有一个共同的、有限的方差，记为 $\\sigma^2 > 0$。\n3.  误差是不相关的，意味着 $\\text{Cov}(\\epsilon_1, \\epsilon_2) = 0$。\n\n为了将两次测量结果合并成对 $\\mu$ 的单一改进估计，提出了一个形式为 $\\tilde{\\mu} = w y_1 + (1-w) y_2$ 的线性估计量，其中 $w$ 是一个实值权重。您的任务是找到使该估计量方差 $\\text{Var}(\\tilde{\\mu})$ 最小化的 $w$ 的具体数值。", "solution": "目标是找到使估计量 $\\tilde{\\mu} = w y_1 + (1-w) y_2$ 的方差最小化的权重 $w$ 的值。该估计量的方差记为 $\\text{Var}(\\tilde{\\mu})$。\n\n首先，我们使用方差的性质来表示 $\\tilde{\\mu}$ 的方差。对于随机变量的线性组合，其方差由下式给出：\n$$\n\\text{Var}(aX + bY) = a^2 \\text{Var}(X) + b^2 \\text{Var}(Y) + 2ab \\text{Cov}(X, Y)\n$$\n在我们的情况下，估计量是 $\\tilde{\\mu} = w y_1 + (1-w) y_2$。变量是 $y_1$ 和 $y_2$，系数为 $a=w$ 和 $b=1-w$。\n$$\n\\text{Var}(\\tilde{\\mu}) = \\text{Var}(w y_1 + (1-w) y_2) = w^2 \\text{Var}(y_1) + (1-w)^2 \\text{Var}(y_2) + 2w(1-w) \\text{Cov}(y_1, y_2)\n$$\n接下来，我们需要求出每次测量 $y_i$ 的方差以及它们之间的协方差。\n$y_i$ 的方差是：\n$$\n\\text{Var}(y_i) = \\text{Var}(\\mu + \\epsilon_i)\n$$\n由于 $\\mu$ 是一个常数，其方差为零。因此，$y_i$ 的方差就是误差项 $\\epsilon_i$ 的方差。\n$$\n\\text{Var}(y_i) = \\text{Var}(\\epsilon_i) = \\sigma^2\n$$\n这对 $i=1$ 和 $i=2$ 都成立。\n\n$y_1$ 和 $y_2$ 之间的协方差是：\n$$\n\\text{Cov}(y_1, y_2) = \\text{Cov}(\\mu + \\epsilon_1, \\mu + \\epsilon_2)\n$$\n由于 $\\mu$ 是一个常数，它不影响协方差。\n$$\n\\text{Cov}(y_1, y_2) = \\text{Cov}(\\epsilon_1, \\epsilon_2)\n$$\n问题陈述中说明了误差是不相关的，这意味着 $\\text{Cov}(\\epsilon_1, \\epsilon_2) = 0$。因此，$\\text{Cov}(y_1, y_2) = 0$。\n\n现在，我们将这些结果代回到 $\\text{Var}(\\tilde{\\mu})$ 的表达式中：\n$$\n\\text{Var}(\\tilde{\\mu}) = w^2 (\\sigma^2) + (1-w)^2 (\\sigma^2) + 2w(1-w)(0)\n$$\n$$\n\\text{Var}(\\tilde{\\mu}) = w^2 \\sigma^2 + (1-w)^2 \\sigma^2\n$$\n我们可以将常数方差 $\\sigma^2$ 提取出来：\n$$\n\\text{Var}(\\tilde{\\mu}) = \\sigma^2 [w^2 + (1-w)^2]\n$$\n为了找到使该方差最小的 $w$ 值，我们可以定义一个函数 $f(w) = w^2 + (1-w)^2$ 并求其最小值。由于 $\\sigma^2 > 0$，最小化 $f(w)$ 等价于最小化 $\\text{Var}(\\tilde{\\mu})$。\n\n让我们展开函数 $f(w)$：\n$$\nf(w) = w^2 + (1 - 2w + w^2) = 2w^2 - 2w + 1\n$$\n这是一个关于 $w$ 的二次函数，代表一个开口向上的抛物线。可以通过微积分求其最小值，即对 $w$ 求一阶导数并令其为零。\n$$\n\\frac{df}{dw} = \\frac{d}{dw}(2w^2 - 2w + 1) = 4w - 2\n$$\n将导数设为零以找到临界点：\n$$\n4w - 2 = 0\n$$\n$$\n4w = 2\n$$\n$$\nw = \\frac{2}{4} = \\frac{1}{2}\n$$\n为了确认这是一个最小值，我们可以使用二阶导数检验。二阶导数是：\n$$\n\\frac{d^2f}{dw^2} = \\frac{d}{dw}(4w - 2) = 4\n$$\n由于二阶导数为正（$4 > 0$），临界点 $w = 1/2$ 对应一个局部最小值。因为 $f(w)$ 是一个抛物线，所以这是一个全局最小值。\n\n因此，当 $w = 1/2$ 时，估计量 $\\tilde{\\mu}$ 的方差最小。", "answer": "$$\\boxed{\\frac{1}{2}}$$", "id": "1919555"}]}