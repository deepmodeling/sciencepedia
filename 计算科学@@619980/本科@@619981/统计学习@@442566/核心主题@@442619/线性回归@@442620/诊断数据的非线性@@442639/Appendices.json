{"hands_on_practices": [{"introduction": "我们从一个常见的数据分析场景开始：你有一个理论依据或视觉线索，怀疑数据中存在一个特定的非线性关系，比如饱和效应。这个练习将指导你模拟这类数据，并分别拟合一个简单的线性模型和一个正确的非线性模型。你将学习如何使用具体的诊断工具——比如残差模式和拟合优度指标——来判断哪个模型更合适，从而为选择更复杂的模型提供正当理由。这项实践旨在培养非线性模型拟合的基本技能和对残差分析的批判性思维。[@problem_id:3114995]", "problem": "给定一个表现出饱和现象的数据生成过程。响应根据模型 $$y = \\alpha + \\beta\\left(1 - e^{-\\gamma x}\\right) + \\varepsilon,$$ 生成，其中 $x$ 是预测变量，$\\alpha$ 是截距，$\\beta$ 是振幅参数，$\\gamma$ 是控制饱和度的速率参数，$\\varepsilon$ 是均值为零的噪声项。您的任务是实现一个程序，该程序为每个指定的测试用例模拟此模型的数据，拟合线性和非线性模型，计算用于评估非线性的诊断指标，然后为每个测试用例输出一个布尔值决策，指示诊断是否检测到非线性。\n\n任务的基本原理：\n- 普通最小二乘法（OLS）通过最小化残差平方和来拟合线性模型。给定观测对 $(x_i, y_i)$（$i=1,\\dots,n$），线性模型 $$y_i = a + b x_i + \\text{residual}_i$$ 的拟合通过最小化 $$\\sum_{i=1}^n \\left(y_i - a - b x_i\\right)^2$$ 来完成。设拟合值为 $\\hat{y}_i^{\\text{lin}}$，残差为 $r_i^{\\text{lin}} = y_i - \\hat{y}_i^{\\text{lin}}$。\n- 非线性最小二乘法通过最小化残差平方和来拟合参数化非线性模型。对于饱和模型 $$y_i = \\alpha + \\beta\\left(1 - e^{-\\gamma x_i}\\right) + \\text{residual}_i,$$ 我们通过最小化 $$\\sum_{i=1}^n \\left(y_i - \\alpha - \\beta\\left(1 - e^{-\\gamma x_i}\\right)\\right)^2$$ 来获得拟合值 $\\hat{y}_i^{\\text{nl}}$ 和残差 $r_i^{\\text{nl}} = y_i - \\hat{y}_i^{\\text{nl}}$。\n- 对于一组残差 $\\{r_i\\}_{i=1}^n$，均方误差（MSE）为 $$\\text{MSE} = \\frac{1}{n}\\sum_{i=1}^n r_i^2.$$\n- 决定系数定义为 $$R^2 = 1 - \\frac{\\sum_{i=1}^n r_i^2}{\\sum_{i=1}^n (y_i - \\bar{y})^2},$$ 其中 $\\bar{y}$ 是 $y_i$ 的样本均值。\n- 两个序列 $(u_i)$ 和 $(v_i)$ 之间的斯皮尔曼等级相关系数衡量了基于等级的单调关联。将其表示为 $\\rho_s(u, v)$。\n\n检测非线性的诊断标准：\n- 为每个用例计算线性拟合和非线性饱和拟合。从每次拟合中，计算 $\\text{MSE}_{\\text{lin}}$、$\\text{MSE}_{\\text{nl}}$、$R^2_{\\text{lin}}$、$R^2_{\\text{nl}}$，以及线性残差 $r^{\\text{lin}}$ 与预测变量 $x$ 之间的斯皮尔曼等级相关系数 $\\rho_s(r^{\\text{lin}}, x)$。\n- 如果以下两个条件均成立，则声明检测到某测试用例存在非线性：\n  1. $$\\frac{\\text{MSE}_{\\text{lin}}}{\\text{MSE}_{\\text{nl}}} \\ge \\tau,$$ 其中 $\\tau = 1.05$。\n  2. $$\\left|\\rho_s\\left(r^{\\text{lin}}, x\\right)\\right| \\ge t,$$ 其中 $t = 0.25$。\n这些标准将两个互补的诊断方法操作化：非线性拟合在误差上有实质性改进，以及线性残差中存在单调结构。\n\n数据模拟详情：\n- 对于每个测试用例，在区间 $[0, x_{\\max}]$ 上（含端点）生成 $n$ 个等距点 $x$。\n- 为每个观测值独立生成 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$。\n- 使用每个测试用例指定的参数 $(\\alpha, \\beta, \\gamma, \\sigma, x_{\\max}, n)$。\n- 为了可复现性，使用固定的随机数生成器种子 $12345$。\n\n测试套件：\n- 用例 1：$(\\alpha, \\beta, \\gamma, \\sigma, x_{\\max}, n) = (0.5, 1.5, 0.02, 0.1, 5.0, 200)$\n- 用例 2：$(\\alpha, \\beta, \\gamma, \\sigma, x_{\\max}, n) = (0.5, 1.5, 1.0, 0.1, 5.0, 200)$\n- 用例 3：$(\\alpha, \\beta, \\gamma, \\sigma, x_{\\max}, n) = (0.5, 0.0, 0.5, 0.1, 5.0, 200)$\n- 用例 4：$(\\alpha, \\beta, \\gamma, \\sigma, x_{\\max}, n) = (0.5, 1.5, 0.5, 1.5, 5.0, 200)$\n- 用例 5：$(\\alpha, \\beta, \\gamma, \\sigma, x_{\\max}, n) = (0.5, 1.0, 0.5, 0.2, 3.0, 150)$\n\n您的程序必须：\n- 为每个测试用例实现数据模拟和两种模型拟合。\n- 计算 $\\text{MSE}_{\\text{lin}}$、$\\text{MSE}_{\\text{nl}}$、$R^2_{\\text{lin}}$、$R^2_{\\text{nl}}$ 和 $\\rho_s\\left(r^{\\text{lin}}, x\\right)$。\n- 应用决策规则（$\\tau = 1.05$ 和 $t = 0.25$）为每个用例生成一个布尔值，指示是否检测到非线性。\n\n最终输出格式：\n- 您的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表的结果，例如 $$[\\text{result}_1,\\text{result}_2,\\dots,\\text{result}_5],$$ 其中每个 $\\text{result}_k$ 是一个对应于第 $k$ 个测试用例的布尔值。", "solution": "我们从基本框架开始：普通最小二乘法（OLS）旨在寻找最小化残差平方和的参数。对于线性模型 $$y_i = a + b x_i + \\text{residual}_i,$$ OLS 估计值通过最小化 $$\\sum_{i=1}^n \\left(y_i - a - b x_i\\right)^2$$ 获得。此优化可以通过正规方程或最小二乘求解器解决；其有效性依赖于这样一个性质：在经典假设下（如误差独立、均值为零且方差有限），OLS 提供线性模型参数的无偏估计量，并且根据 Gauss-Markov 定理，它是最佳线性无偏估计量（BLUE）。即使没有这些假设，OLS 也能得出残差平方和的最小化器。\n\n对于饱和非线性模型 $$y_i = \\alpha + \\beta\\left(1 - e^{-\\gamma x_i}\\right) + \\text{residual}_i,$$ 非线性最小二乘法旨在最小化 $$\\sum_{i=1}^n \\left(y_i - \\alpha - \\beta\\left(1 - e^{-\\gamma x_i}\\right)\\right)^2.$$ 虽然非线性模型通常没有闭式解，但迭代数值优化方法（如信赖域方法）可以从有根据的初始猜测值开始，高效地估计 $(\\alpha, \\beta, \\gamma)$。好的初始值可以通过简单的启发式方法构建：例如，$\\alpha$ 可初始化为接近 $y$ 的最小值，$\\beta$ 接近 $y$ 的范围，$\\gamma$ 接近 $1/x_{\\max}$ 以反映饱和的尺度。\n\n诊断指标：\n- 均方误差（MSE）$$\\text{MSE} = \\frac{1}{n}\\sum_{i=1}^n r_i^2$$ 量化了平均残差平方的大小。比较 $\\text{MSE}_{\\text{lin}}$ 和 $\\text{MSE}_{\\text{nl}}$ 表明非线性拟合相对于线性拟合在多大程度上减少了误差。\n- 决定系数 $$R^2 = 1 - \\frac{\\sum_{i=1}^n r_i^2}{\\sum_{i=1}^n (y_i - \\bar{y})^2}$$ 衡量了模型解释的方差比例。虽然它不用于决策规则，但提供了补充性的背景信息。\n- 斯皮尔曼等级相关 $\\rho_s(r^{\\text{lin}}, x)$ 捕捉了线性残差相对于 $x$ 的单调模式。如果真实关系是非线性的（例如，饱和），线性拟合通常会留下表现出与 $x$ 单调趋势的结构化残差。斯皮尔曼系数对非高斯分布具有稳健性，并反映基于等级的单调关联，使其适合于检测基于顺序的结构。\n\n决策规则：\n- 如果两个独立提出的诊断指标都表明存在非线性，我们就声明检测到非线性：\n  1. 非线性拟合有足够的 MSE 改进：$$\\frac{\\text{MSE}_{\\text{lin}}}{\\text{MSE}_{\\text{nl}}} \\ge \\tau,$$ 其中 $\\tau = 1.05$ 被设定为要求至少有适度的改进。\n  2. 线性残差中存在显著的单调结构：$$\\left|\\rho_s\\left(r^{\\text{lin}}, x\\right)\\right| \\ge t,$$ 其中 $t = 0.25$ 被选择用来标记在一个设定良好的线性模型下不太可能出现的残差排序。\n\n每个测试用例的算法步骤：\n1. 在 $[0, x_{\\max}]$ 上生成 $n$ 个等距的 $x$。使用固定的种子以保证可复现性，抽取 $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$。构造 $$y_i = \\alpha + \\beta\\left(1 - e^{-\\gamma x_i}\\right) + \\varepsilon_i.$$\n2. 通过最小二乘法拟合线性模型，得到 $(a, b)$，计算拟合值 $\\hat{y}_i^{\\text{lin}}$ 和残差 $r_i^{\\text{lin}} = y_i - \\hat{y}_i^{\\text{lin}}$。\n3. 通过非线性最小二乘法（有界信赖域方法）拟合饱和非线性模型，如前所述初始化 $(\\alpha, \\beta, \\gamma)$，并计算拟合值 $\\hat{y}_i^{\\text{nl}}$ 和残差 $r_i^{\\text{nl}}$。\n4. 计算 $\\text{MSE}_{\\text{lin}}$、$\\text{MSE}_{\\text{nl}}$、$R^2_{\\text{lin}}$、$R^2_{\\text{nl}}$ 和 $\\rho_s\\left(r^{\\text{lin}}, x\\right)$。\n5. 应用决策规则（$\\tau = 1.05$ 和 $t = 0.25$）为非线性生成一个布尔分类。\n\n测试套件的覆盖范围：\n- 用例 1 使用小的 $\\gamma$ 来近似线性行为（当 $\\gamma x$ 很小时，$e^{-\\gamma x} \\approx 1 - \\gamma x$），因此非线性模型不应明显优于线性模型，且残差的单调结构应较弱。\n- 用例 2 使用大的 $\\gamma$ 以实现快速饱和，这导致线性拟合在残差中留下明显的结构，而非线性拟合则提供了显著的误差减少。\n- 用例 3 设置 $\\beta = 0$，使 $y$ 变为常数加噪声，因此不应检测到与 $x$ 的关系，也不应强烈偏好任一模型。\n- 用例 4 引入了高噪声和中等大小的 $\\gamma$，使得信号被掩盖；诊断应该会趋于保守。\n- 用例 5 在较短的 $x$ 区间上引入了中等程度的饱和和中等程度的噪声，根据标准可以检测到非线性。\n\n程序将所有用例的布尔结果汇总为指定的单个方括号内、逗号分隔的列表，并通过固定的随机种子确保确定性输出。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import curve_fit\nfrom scipy.stats import spearmanr\n\ndef saturating_model(x, alpha, beta, gamma):\n    return alpha + beta * (1.0 - np.exp(-gamma * x))\n\ndef fit_linear(x, y):\n    # Design matrix for linear model: [1, x]\n    X = np.column_stack((np.ones_like(x), x))\n    # Solve least squares\n    coef, _, _, _ = np.linalg.lstsq(X, y, rcond=None)\n    a, b = coef\n    y_hat = a + b * x\n    residuals = y - y_hat\n    return a, b, y_hat, residuals\n\ndef fit_nonlinear(x, y):\n    # Initial guesses: alpha near min(y), beta near (max(y)-min(y)),\n    # gamma near 1/x_max (positive).\n    y_min = np.min(y)\n    y_max = np.max(y)\n    alpha0 = y_min\n    beta0 = max(y_max - y_min, 1e-3)\n    x_max = np.max(x)\n    gamma0 = 1.0 / max(x_max, 1.0)\n    p0 = (alpha0, beta0, gamma0)\n\n    # Bounds: gamma > 0; alpha and beta unbounded.\n    bounds = ((-np.inf, -np.inf, 1e-9), (np.inf, np.inf, np.inf))\n    try:\n        popt, _ = curve_fit(saturating_model, x, y, p0=p0, bounds=bounds, maxfev=10000)\n        alpha, beta, gamma = popt\n        y_hat = saturating_model(x, alpha, beta, gamma)\n        residuals = y - y_hat\n        return alpha, beta, gamma, y_hat, residuals\n    except Exception:\n        # Fallback: if nonlinear fit fails, return linear-like results to avoid crash\n        # This will make diagnostics conservative (likely not detect nonlinearity).\n        y_hat = np.full_like(y, np.mean(y))\n        residuals = y - y_hat\n        return np.mean(y), 0.0, 1.0, y_hat, residuals\n\ndef mse(residuals):\n    return float(np.mean(residuals**2))\n\ndef r2(y, y_hat):\n    y_mean = np.mean(y)\n    sse = np.sum((y - y_hat)**2)\n    sst = np.sum((y - y_mean)**2)\n    if sst == 0.0:\n        return 0.0\n    return float(1.0 - sse / sst)\n\ndef detect_nonlinearity(mse_lin, mse_nl, spearman_r, tau=1.05, t=0.25):\n    improvement_ratio = mse_lin / mse_nl if mse_nl > 0 else np.inf\n    return (improvement_ratio >= tau) and (abs(spearman_r) >= t)\n\ndef simulate_case(alpha, beta, gamma, sigma, x_max, n, rng):\n    x = np.linspace(0.0, x_max, n)\n    eps = rng.normal(loc=0.0, scale=sigma, size=n)\n    y = alpha + beta * (1.0 - np.exp(-gamma * x)) + eps\n    return x, y\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (alpha, beta, gamma, sigma, x_max, n)\n        (0.5, 1.5, 0.02, 0.1, 5.0, 200),  # Case 1: near-linear\n        (0.5, 1.5, 1.0, 0.1, 5.0, 200),   # Case 2: strong saturation\n        (0.5, 0.0, 0.5, 0.1, 5.0, 200),   # Case 3: no relationship\n        (0.5, 1.5, 0.5, 1.5, 5.0, 200),   # Case 4: high noise\n        (0.5, 1.0, 0.5, 0.2, 3.0, 150),   # Case 5: moderate saturation\n    ]\n\n    # Fixed seed for reproducibility\n    rng = np.random.default_rng(12345)\n\n    results = []\n    for case in test_cases:\n        alpha, beta, gamma, sigma, x_max, n = case\n        x, y = simulate_case(alpha, beta, gamma, sigma, x_max, n, rng)\n\n        # Fit linear model\n        a_lin, b_lin, yhat_lin, resid_lin = fit_linear(x, y)\n\n        # Fit nonlinear saturating model\n        a_nl, b_nl, g_nl, yhat_nl, resid_nl = fit_nonlinear(x, y)\n\n        # Compute diagnostics\n        mse_lin = mse(resid_lin)\n        mse_nl = mse(resid_nl)\n        r2_lin = r2(y, yhat_lin)\n        r2_nl = r2(y, yhat_nl)\n        # Spearman rank correlation between linear residuals and x\n        spearman_r, _ = spearmanr(resid_lin, x)\n\n        # Decision rule\n        flag = detect_nonlinearity(mse_lin, mse_nl, spearman_r, tau=1.05, t=0.25)\n        results.append(flag)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3114995"}, {"introduction": "然而，我们常常怀疑数据存在非线性，却不清楚其具体形式。在这种情况下，我们需要一个更通用的诊断测试。Ramsey RESET 测试就是一个经典且强大的工具，它通过检验一个线性模型的拟合值的幂是否能显著改善模型，来间接检测是否存在被忽略的非线性项。通过这个动手模拟，你将从零开始实现 RESET 测试并研究其统计功效，从而更深入地理解嵌套模型比较和规范检验背后的逻辑。[@problem_id:3115010]", "problem": "您的任务是实现并研究拉姆齐回归方程设定误差检验（RESET），这是一种用于检测线性模型中遗漏非线性项的经典诊断方法，并通过模拟来校准其在二次备擇假設下的功效。您的程序必须是一个完整的、可运行的实现，能够生成合成数据、应用该检验并报告经验拒绝率。\n\n考虑一个单变量预测变量的设定，其中观测值为独立同分布。对于每次模拟重复，按如下方式生成数据。对于给定的样本量 $n$，独立地抽取预测变量 $x_i \\sim \\mathcal{N}(0,1)$，其中 $i=1,\\dots,n$。给定参数 $\\beta_0$、$\\beta_1$、$\\gamma$ 和噪声尺度 $\\sigma0$，根据以下数据生成过程生成响应变量\n$$\ny_i \\;=\\; \\beta_0 \\;+\\; \\beta_1 x_i \\;+\\; \\gamma x_i^2 \\;+\\; \\varepsilon_i,\\quad \\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)\\ \\text{independently}.\n$$\n\n定义省略了非线性项的受约束线性模型为\n$$\ny_i \\;=\\; \\theta_0 \\;+\\; \\theta_1 x_i \\;+\\; u_i,\n$$\n并通过普通最小二乘法（OLS）对其进行估计。令 $\\widehat{y}_i$ 表示从此受约束模型得到的拟合值。拉姆齐回归方程设定误差检验（RESET）通过向受约束模型中添加拟合值的幂来构成一个非受约束模型，\n$$\ny_i \\;=\\; \\theta_0 \\;+\\; \\theta_1 x_i \\;+\\; \\sum_{j=2}^{p} \\delta_j \\,\\widehat{y}_i^{\\,j} \\;+\\; v_i,\n$$\n其中 $p \\ge 2$ 是所选的 RESET 阶数。原假设断言所有增广系数都为零，即 $H_0: \\delta_2=\\dots=\\delta_p=0$。您必须使用 Fisher–Snedecor 分布实现经典的嵌套模型决策规则：计算受约束模型和非受约束模型的普通最小二乘法残差平方和，通过适当的比率对它们进行比较，该比率产生一个 $F$ 统计量，其分子自由度等于新增回归变量的数量，分母自由度等于非受约束模型的残差自由度，如果该统计量落在由 $F$ 分布的上 $\\alpha$ 分位数确定的拒绝域中，则在显著性水平 $\\alpha$ 下拒绝 $H_0$。显著性水平 $\\alpha$ 必须以小数形式表示（例如，$0.05$）。\n\n您的程序必须执行蒙特卡洛模拟，通过对每个参数集重复以下步骤 $R$ 次来估计二次备择假设下的拒绝概率（经验功效）：在指定参数下模拟一个数据集，以阶数 $p$ 和水平 $\\alpha$ 运行拉姆齐 RESET 检验，并记录 $H_0$ 是否被拒绝。一个参数集的最终结果是这 $R$ 次重复中拒绝指标的平均值。在 $\\gamma=0$ 的特殊情况下，此数量估计的是经验规模。\n\n您必须依赖的基础理论：\n- 普通最小二乘估计量最小化残差平方和，并求解线性回归的正规方程。\n- 对于具有高斯误差的嵌套线性模型，在原假设下，缩放后的残差平方和减少量服从 $F$ 分布，其自由度由新增参数的数量（分子）和非受约束模型的残差自由度（分母）给出。\n- 拉姆齐 RESET 通过受约束模型的拟合值的幂来增强受约束模型，以代理遗漏的回归变量非线性函数；如果存在此类非线性，这些增强项会改善拟合，导致拒绝频率高于名义水平。\n\n使用以下测试套件参数集实现模拟。每个测试用例是一个元组 $(n,\\beta_0,\\beta_1,\\gamma,\\sigma,\\alpha,R,p,\\text{seed})$：\n- 案例 A（原假设下的经验规模）：$(n,\\beta_0,\\beta_1,\\gamma,\\sigma,\\alpha,R,p,\\text{seed}) = (\\,200,\\,0,\\,1,\\,0,\\,1,\\,0.05,\\,500,\\,3,\\,12345\\,)$。\n- 案例 B（中度非线性，较大样本）：$(\\,200,\\,0,\\,1,\\,0.2,\\,1,\\,0.05,\\,500,\\,3,\\,54321\\,)$。\n- 案例 C（强非线性，较小样本，较低阶数）：$(\\,50,\\,1,\\,1,\\,0.8,\\,1,\\,0.05,\\,500,\\,2,\\,2024\\,)$。\n- 案例 D（无线性效应，噪声大，宽松水平）：$(\\,50,\\,0,\\,0,\\,0.5,\\,3,\\,0.1,\\,400,\\,3,\\,777\\,)$。\n\n对于每个案例，您的程序必须以十进制浮点数形式输出估计的拒绝概率。您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表（例如，\"[0.052,0.412,0.873,0.268]\"）。将每个报告的拒绝概率四舍五入到三位小数。不需要读取输入；所有参数都嵌入在程序中。使用指定的随机种子以确保跨次运行的可复现性。", "solution": "该问题要求实现一个蒙特卡洛模拟，以研究拉姆齐回归方程设定误差检验（RESET）的统计功效。该模拟将估计在各种参数配置下检验的拒绝概率，包括一个用于评估其经验规模的原假设情况和包含二次非线性的备择假设情况以评估其功效。\n\n### 理论框架\n\n分析始于一个已定义的数据生成过程（DGP），其中响应变量 $y_i$ 和预测变量 $x_i$ 之间的真实关系包含一个二次项。该设定由以下公式给出：\n$$\ny_i \\;=\\; \\beta_0 \\;+\\; \\beta_1 x_i \\;+\\; \\gamma x_i^2 \\;+\\; \\varepsilon_i\n$$\n其中 $x_i \\sim \\mathcal{N}(0,1)$ 且误差 $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$ 是独立同分布的。参数 $\\gamma$ 控制非线性的程度。如果 $\\gamma=0$，真实模型是线性的。如果 $\\gamma \\neq 0$，则简单的线性模型由于遗漏变量 $x_i^2$ 而存在设定错误。\n\n拉姆齐 RESET 是用于此类设定错误的一种通用检验。该过程包括以下步骤：\n\n1.  **估计受约束模型**：首先，我们假设一个简单的线性模型，这可能是设定错误的。这是在正确设定的原假设下的受约束模型：\n    $$\n    y_i \\;=\\; \\theta_0 \\;+\\; \\theta_1 x_i \\;+\\; u_i\n    $$\n    此模型使用普通最小二乘法（OLS）进行估计，得到估计系数 $\\widehat{\\theta}_0$ 和 $\\widehat{\\theta}_1$，以及相应的拟合值：\n    $$\n    \\widehat{y}_i \\;=\\; \\widehat{\\theta}_0 \\;+\\; \\widehat{\\theta}_1 x_i\n    $$\n\n2.  **构建非受约束（增广）模型**：RESET 的核心思想是，如果真实模型是非线性的，那么来自设定错误的线性模型的拟合值 $\\widehat{y}_i$ 本身将是预测变量的函数，因此可能捕捉到一些遗漏的非线性效应。这些拟合值的幂 $\\widehat{y}_i^j$ 可以作为未知非线性项的代理变量。通过用这些代理变量增广受约束模型来形成非受约束模型：\n    $$\n    y_i \\;=\\; \\theta_0 \\;+\\; \\theta_1 x_i \\;+\\; \\sum_{j=2}^{p} \\delta_j \\,\\widehat{y}_i^{\\,j} \\;+\\; v_i\n    $$\n    其中 $p \\ge 2$ 是一个定义检验阶数的整数。\n\n### 嵌套模型的 F 检验\n\n模型设定的假设检验被构建为对新增项系数的检验。原假设 $H_0$ 指出受约束模型是正确设定的，这意味着增广项的系数全部为零：\n$$\nH_0: \\delta_2 = \\delta_3 = \\dots = \\delta_p = 0\n$$\n备择假设 $H_1$ 是至少有一个 $\\delta_j \\neq 0$，其中 $j \\in \\{2, \\dots, p\\}$。\n\n由于受约束模型嵌套在非受约束模型之内（通过将 $\\delta_j$ 系数设为零得到），我们可以使用 F 检验来比较它们的拟合优度。设 $\\text{RSS}_R$ 为受约束模型 OLS 估计的残差平方和，设 $\\text{RSS}_U$ 为非受约束模型的 RSS。F 统计量定义为：\n$$\nF = \\frac{(\\text{RSS}_R - \\text{RSS}_U) / q}{\\text{RSS}_U / (n - k_U)}\n$$\n该统计量的参数为：\n-   $n$：观测数量。\n-   $q$：约束的数量，即新增回归变量的数量。这里，$q = p-1$。\n-   $k_U$：非受约束模型中的总参数数量。该模型包括一个截距（1）、原始预测变量 $x_i$（1），以及从 $2$ 到 $p$ 的 $\\widehat{y}_i$ 的幂（$p-1$ 项）。因此，$k_U = 1 + 1 + (p-1) = p+1$。\n\n因此，F 检验的自由度为分子的 $df_1 = q = p-1$ 和分母的 $df_2 = n - k_U = n - (p+1)$。检验统计量为：\n$$\nF = \\frac{(\\text{RSS}_R - \\text{RSS}_U) / (p-1)}{\\text{RSS}_U / (n - (p+1))}\n$$\n在原假设 $H_0$ 下，该统计量服从自由度为 $p-1$ 和 $n-(p+1)$ 的 F 分布，即 $F \\sim F_{p-1, n-(p+1)}$。\n\n对于给定的显著性水平 $\\alpha$，决策规则是如果计算出的 F 统计量超过临界值 $F^{(\\alpha)}_{p-1, n-(p+1)}$（即相应 F 分布的上 $\\alpha$-分位数），则拒绝 $H_0$。\n\n### 蒙特卡洛模拟算法\n\n为了估计每个参数集 $(n, \\beta_0, \\beta_1, \\gamma, \\sigma, \\alpha, R, p, \\text{seed})$ 的拒绝概率，我们执行以下模拟：\n\n1.  **初始化**：对于给定的测试用例，为保证可复现性设置随机数生成器种子。将拒绝计数器初始化为零。\n2.  **重复循环**：重复 $R$ 次：\n    a. **数据生成**：生成大小为 $n$ 的数据集。抽取 $x_i \\sim \\mathcal{N}(0,1)$ 和 $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$。计算 $y_i = \\beta_0 + \\beta_1 x_i + \\gamma x_i^2 + \\varepsilon_i$。\n    b. **模型估计**：\n       i.  定义大小为 $n \\times 2$ 的受约束设计矩阵 $X_R$（一列 1 和 $x$ 向量）。使用 OLS 估计受约束模型 $y = X_R\\beta_R + u$，以获得拟合值 $\\widehat{y} = X_R\\widehat{\\beta}_R$ 和残差平方和 $\\text{RSS}_R$。\n       ii. 构建幂 $\\widehat{y}^2, \\dots, \\widehat{y}^p$。通过用这些新回归变量增广 $X_R$ 来形成大小为 $n \\times (p+1)$ 的非受约束设计矩阵 $X_U$。使用 OLS 估计非受约束模型 $y = X_U\\beta_U + v$ 以获得 $\\text{RSS}_U$。\n    c. **假设检验**：\n       i.  计算自由度：$df_1 = p-1$ 和 $df_2 = n-(p+1)$。\n       ii. 计算 F 统计量。由于有限精度算术，如果 $\\text{RSS}_R \\le \\text{RSS}_U$ 或 $\\text{RSS}_U$ 接近于零，则该统计量是病态的；在这种情况下，我们不拒绝 $H_0$。否则，计算 $F = ((\\text{RSS}_R - \\text{RSS}_U)/df_1) / (\\text{RSS}_U/df_2)$。\n       iii. 使用 F 分布的逆累积分布函数（百分点函数）找到临界值 $F_{\\text{crit}} = F^{(\\alpha)}_{df_1, df_2}$。\n    d. **决策**：如果 $F  F_{\\text{crit}}$，则拒绝计数器加一。\n3.  **结果计算**：经过 $R$ 次重复后，估计的拒绝概率是总拒绝次数除以 $R$。该值四舍五入到三位小数。\n\n对所有指定的测试用例重复此过程，以评估拉姆齐 RESET 的经验规模（当 $\\gamma=0$ 时）和功效（当 $\\gamma \\neq 0$ 时）。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import f\n\ndef solve():\n    \"\"\"\n    Implements and studies the Ramsey RESET diagnostic test via Monte Carlo simulation.\n\n    This function iterates through a suite of test cases, each defining a specific\n    data generating process and test parameters. For each case, it simulates data,\n    applies the Ramsey RESET, and calculates the empirical rejection rate over\n    many replications.\n    \"\"\"\n    test_cases = [\n        # (n, beta0, beta1, gamma, sigma, alpha, R, p, seed)\n        (200, 0, 1, 0, 1, 0.05, 500, 3, 12345),      # Case A: Empirical size\n        (200, 0, 1, 0.2, 1, 0.05, 500, 3, 54321),     # Case B: Moderate nonlinearity\n        (50, 1, 1, 0.8, 1, 0.05, 500, 2, 2024),       # Case C: Strong nonlinearity\n        (50, 0, 0, 0.5, 3, 0.1, 400, 3, 777)          # Case D: No linear effect, noisy\n    ]\n\n    results = []\n    for n, beta0, beta1, gamma, sigma, alpha, R, p, seed in test_cases:\n        # Set seed for reproducibility for each test case\n        rng = np.random.default_rng(seed)\n        rejection_count = 0\n\n        for _ in range(R):\n            # Step 1: Generate synthetic data according to the DGP\n            x = rng.normal(loc=0, scale=1, size=n)\n            epsilon = rng.normal(loc=0, scale=sigma, size=n)\n            y = beta0 + beta1 * x + gamma * x**2 + epsilon\n\n            # Step 2: Estimate the restricted linear model (y ~ 1 + x)\n            X_r = np.c_[np.ones(n), x]\n            \n            # Use np.linalg.lstsq to perform OLS regression\n            # It returns coefficients, sum of squared residuals, rank, singular values\n            beta_r_hat, residuals_r, _, _ = np.linalg.lstsq(X_r, y, rcond=None)\n            \n            # If the model is not full rank or sample size is too small, lstsq returns empty residuals\n            if residuals_r.size == 0:\n                continue # Skip this replication if OLS fails\n\n            rss_r = residuals_r[0]\n            y_hat = X_r @ beta_r_hat\n\n            # Step 3: Estimate the unrestricted model (y ~ 1 + x + y_hat^2 + ... + y_hat^p)\n            # Create the augmented regressors\n            y_hat_powers = np.array([y_hat**j for j in range(2, p + 1)]).T\n            X_u = np.c_[X_r, y_hat_powers]\n\n            beta_u_hat, residuals_u, _, _ = np.linalg.lstsq(X_u, y, rcond=None)\n\n            if residuals_u.size == 0:\n                continue # Skip if OLS fails\n\n            rss_u = residuals_u[0]\n\n            # Step 4: Compute the F-statistic\n            k_r = X_r.shape[1]  # Number of parameters in restricted model (2)\n            k_u = X_u.shape[1]  # Number of parameters in unrestricted model (p+1)\n            \n            df1 = k_u - k_r   # Numerator degrees of freedom (p-1)\n            df2 = n - k_u     # Denominator degrees of freedom (n-(p+1))\n            \n            f_statistic = 0.0\n            # Ensure valid degrees of freedom and that RSS_R > RSS_U\n            # RSS_R should be >= RSS_U. A small negative difference can occur due to floating point error.\n            if df2 > 0 and rss_u > 1e-9 and (rss_r - rss_u) > 1e-9:\n                f_statistic = ((rss_r - rss_u) / df1) / (rss_u / df2)\n\n            # Step 5: Perform the hypothesis test\n            # Get the critical value from the F-distribution\n            critical_value = f.ppf(1 - alpha, df1, df2) if df1 > 0 and df2 > 0 else np.inf\n\n            if f_statistic > critical_value:\n                rejection_count += 1\n        \n        # Calculate the empirical rejection probability (power or size)\n        rejection_prob = rejection_count / R\n        results.append(round(rejection_prob, 3))\n\n    # Print the final results in the specified format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3115010"}, {"introduction": "在确定关系是非线性之后，下一步就是如何有效地对其建模。最后的这个练习将介绍一系列灵活性递增的方法，从简单的多项式回归到强大的样条函数和核方法。你将实施一个模拟研究，使用交叉验证来公平地比较这些方法在不同噪声水平下检测非线性信号的能力。这项练习强调了在模型灵活性、可解释性和检测能力之间的关键权衡，为你提供了为特定问题选择合适工具的框架。[@problem_id:3114979]", "problem": "要求您实现一个完整、可运行的程序，通过构建一个嵌套的诊断课程来凭经验诊断数据中的非线性：从基于残差的增强开始，然后转向样条，再到核方法。您的程序将使用受控的模拟设计，比较每种诊断方法在不同噪声水平下的经验检测阈值。\n\n本问题的基础包括以下经过充分检验的定义和过程：\n- 普通最小二乘法 (OLS)：给定设计矩阵 $X \\in \\mathbb{R}^{n \\times p}$ 和响应向量 $y \\in \\mathbb{R}^{n}$，OLS 估计量 $\\hat{\\beta}$ 最小化平方误差 $\\|y - X \\beta\\|_2^2$。\n- 残差：对于拟合值 $\\hat{y} = X \\hat{\\beta}$，残差为 $r = y - \\hat{y}$。\n- $K$-折交叉验证：将索引 $\\{1,\\ldots,n\\}$ 分成 $K$ 个大小近似相等的不相交的折；对每个折 $k$，在 $\\{1,\\ldots,n\\} \\setminus \\text{fold}_k$上拟合模型，并在 $\\text{fold}_k$上评估均方误差 (MSE)；跨折聚合结果。\n- 学生$t$分布：对于具有 $K$ 个折的成对折间误差差异，在标准假设下，$t$ 统计量近似服从具有 $K-1$ 个自由度的学生$t$分布，其中 $\\bar{d}$ 是差异的样本均值，$s_d$ 是差异的样本标准差。\n\n您的任务是实现以下基于模拟的检测流程并报告检测阈值。\n\n数据生成过程：\n- 对于 $i = 1,\\ldots,n$，独立地从 $\\text{Uniform}(0,1)$ 分布中抽取输入 $x_i$。\n- 定义线性基线 $y_i^{\\text{lin}} = \\beta_0 + \\beta_1 x_i$ 和非线性分量 $g(x_i) = \\sin(2\\pi x_i)$。\n- 对于给定的非线性振幅 $a \\ge 0$ 和噪声标准差 $\\sigma  0$，生成\n$$\ny_i = y_i^{\\text{lin}} + a \\, g(x_i) + \\varepsilon_i, \\quad \\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2) \\text{ independently}.\n$$\n\n待比较的诊断方法（按灵活性递增；每种方法都与相同的线性基线进行比较）：\n1. 基于残差的增强（多项式附加项）：用 $x^2$ 增强线性模型（可解释为检测残差图中可见的曲率）。具体来说，比较基线 $[1, x]$ 与增强后的 $[1, x, x^2]$。\n2. 样条：使用截断幂基拟合一个立方回归样条，其内部节点位于固定位置；设计矩阵为 $[1, x, (x - t_1)_+^3, \\ldots, (x - t_K)_+^3]$，其中 $(u)_+ = \\max(u,0)$。\n3. 通过随机傅里叶特征（RFF）近似高斯核的核方法：将 $x$ 映射到一个特征向量 $\\phi(x) \\in \\mathbb{R}^{m}$，其条目为 $\\sqrt{2/m} \\cos(\\omega_j x + b_j)$，其中 $\\omega_j \\sim \\mathcal{N}(0, \\ell^{-2})$ 且 $b_j \\sim \\text{Uniform}(0,2\\pi)$，然后对这些特征进行线性岭回归拟合（包括截距）。\n\n检测逻辑（对所有诊断方法统一）：\n- 使用 $K$-折交叉验证计算基线模型的各折均方误差 $\\{\\text{MSE}_{\\text{base},k}\\}_{k=1}^K$ 和诊断模型的各折均方误差 $\\{\\text{MSE}_{\\text{diag},k}\\}_{k=1}^K$。\n- 计算成对差异 $d_k = \\text{MSE}_{\\text{base},k} - \\text{MSE}_{\\text{diag},k}$，其中 $k=1,\\ldots,K$。\n- 计算单侧 $t$ 统计量\n$$\nt = \\frac{\\bar{d}}{s_d/\\sqrt{K}}, \\quad \\text{with} \\quad \\bar{d} = \\frac{1}{K}\\sum_{k=1}^K d_k,\\quad s_d^2 = \\frac{1}{K-1}\\sum_{k=1}^K (d_k - \\bar{d})^2.\n$$\n- 设 $p$ 为在具有 $K-1$ 个自由度的学生$t$分布下，针对备择假设 $\\bar{d}  0$ 的单侧 $p$ 值。如果 $\\bar{d}  0$ 且 $p  \\alpha$，则宣布检测到非线性。\n\n经验检测概率和阈值：\n- 对于固定的 $(a,\\sigma)$，独立重复数据生成和检测决策 $R$ 次；将宣布检测到的重复实验比例估计为检测概率。\n- 对于一个振幅网格 $\\mathcal{A} = \\{a_1, a_2, \\ldots, a_G\\}$，将经验检测阈值定义为 $\\mathcal{A}$ 中使得估计检测概率至少达到目标功效 $\\pi^\\star$ 的最小 $a_g$。如果没有 $a_g$ 达到目标功效，则报告一个哨兵值。\n\n测试套件和固定参数：\n- 使用 $n = 120$，$\\beta_0 = 0$，$\\beta_1 = 1$，$K = 5$ 折，$\\alpha = 0.05$，$R = 40$ 以及目标功效 $\\pi^\\star = 0.8$。\n- 样条内部节点使用 $t_j \\in \\{0.2, 0.4, 0.6, 0.8\\}$。\n- 对于随机傅里叶特征，使用特征维度 $m = 40$，高斯核长度尺度 $\\ell = 0.2$，以及岭惩罚项 $\\lambda = 10^{-3}$。\n- 振幅网格 $\\mathcal{A} = \\{0.0, 0.2, 0.4, 0.6, 0.8, 1.0\\}$。\n- 待测试的噪声水平：$\\sigma \\in \\{0.1, 0.5, 1.0\\}$。\n\n输出规范：\n- 对于给定顺序中的每个噪声水平 $\\sigma$，分别计算基于残差的增强、样条和核方法的经验检测阈值。如果在 $\\mathcal{A}$ 中的任何振幅下都未达到目标功效，则在该噪声水平下为该诊断方法输出哨兵值 $-1.0$。\n- 您的程序应生成单行输出，其中包含九个阈值，以逗号分隔的列表形式包含在方括号中，顺序如下\n$$\n[\\theta_{\\text{poly}}(\\sigma=0.1),\\ \\theta_{\\text{spline}}(\\sigma=0.1),\\ \\theta_{\\text{kernel}}(\\sigma=0.1),\\ \\theta_{\\text{poly}}(\\sigma=0.5),\\ \\theta_{\\text{spline}}(\\sigma=0.5),\\ \\theta_{\\text{kernel}}(\\sigma=0.5),\\ \\theta_{\\text{poly}}(\\sigma=1.0),\\ \\theta_{\\text{spline}}(\\sigma=1.0),\\ \\theta_{\\text{kernel}}(\\sigma=1.0)].\n$$\n- 将每个阈值表示为小数点后保留两位的小数。\n\n角度单位不适用。不涉及物理单位。不得使用百分比；所有概率都应视为 $[0,1]$ 内的实数。\n\n您的程序必须是自包含的，不得要求输入，并且必须遵循这些确切的规范。在内部使用固定的随机种子以确保结果的可复现性。", "solution": "提出的问题是进行一项基于模拟的研究，以在回归情境下凭经验评估和比较三种不同统计方法诊断非线性的检测阈值。该问题定义明确，科学上基于已建立的统计学习原则，并为可复现的计算实验提供了一套完整的参数和程序。因此，该问题被认为是有效的。我们接下来详细描述解决方法。\n\n任务的核心是确定，对于不同的噪声水平，每种诊断方法可靠地检测到非线性分量所需其存在的最小信号强度。\n\n**1. 数据生成过程 (DGP)**\n\n该模拟基于一个受控的数据生成过程。对于 $R$ 次重复实验中的每一次，我们生成一个大小为 $n = 120$ 的数据集。首先，预测变量 $x_i$ 从均匀分布中独立抽取：\n$$x_i \\sim \\text{Uniform}(0, 1) \\quad \\text{for } i = 1, \\dots, n$$\n响应变量 $y_i$ 由一个线性分量、一个非线性分量和一个随机噪声项的总和构成。线性基线由 $y_i^{\\text{lin}} = \\beta_0 + \\beta_1 x_i$ 给出，其中指定系数 $\\beta_0 = 0$ 和 $\\beta_1 = 1$。非线性信号是一个正弦函数 $g(x_i) = \\sin(2\\pi x_i)$。响应的总体模型是：\n$$y_i = (\\beta_0 + \\beta_1 x_i) + a \\cdot g(x_i) + \\varepsilon_i$$\n其中 $a \\ge 0$ 是非线性分量的振幅，而 $\\varepsilon_i$ 是从正态分布 $\\mathcal{N}(0, \\sigma^2)$ 中抽取的独立同分布噪声项。这个框架允许我们系统地改变非线性强度 $a$ 和噪声水平 $\\sigma$。\n\n**2. 诊断方法与模型比较**\n\n我们将三种灵活性递增的诊断模型与一个共同的基线模型进行比较。基线模型始终是简单线性回归模型，该模型尝试仅使用一个截距和 $x$ 的一个线性项来拟合数据。其设计矩阵为 $X_{\\text{base}} = [1, x]$。\n\n三种诊断方法如下：\n1.  **基于残差的增强（多项式）**：此方法通过添加二次项 $x^2$ 来增强线性模型。这个增强模型的设计矩阵是 $X_{\\text{poly}} = [1, x, x^2]$。该模型能有效捕捉简单的、对称的曲率，这种曲率可能在线性模型残差对预测变量 $x$ 的图中显现出来。\n\n2.  **立方样条**：此方法通过使用分段多项式函数提供了更大的灵活性。我们采用一个带有截断幂基的立方回归样条。设计矩阵构造如下：\n    $$X_{\\text{spline}} = [1, x, (x - t_1)_+^3, \\dots, (x - t_4)_+^3]$$\n    其中 $(u)_+ = \\max(u, 0)$，内部节点固定在 $t_j \\in \\{0.2, 0.4, 0.6, 0.8\\}$。与简单的全局多项式相比，样条模型能适应更复杂的局部非线性模式。\n\n3.  **核方法（通过随机傅里叶特征）**：这是最灵活的方法，旨在近似一个基于高斯核 $k(x, x') = \\exp(-\\|x-x'\\|^2 / (2\\ell^2))$ 的模型。直接的核方法计算量可能很大。这里，我们使用随机傅里叶特征（RFF）作为一种计算上高效的近似。输入 $x$ 通过一个特征映射 $\\phi(x) \\in \\mathbb{R}^{m}$ 被映射到一个维度为 $m=40$ 的更高维特征空间。$\\phi(x)$ 的第 $j$ 个分量是：\n    $$\\phi_j(x) = \\sqrt{\\frac{2}{m}} \\cos(\\omega_j x + b_j)$$\n    其中频率 $\\omega_j$ 从 $\\mathcal{N}(0, \\ell^{-2})$ 中抽取，相位移 $b_j$ 从 $\\text{Uniform}(0, 2\\pi)$ 中抽取。核长度尺度固定为 $\\ell=0.2$。然后，在这些特征上拟合一个线性岭回归模型，并加入一个截距项。使用岭惩罚项 $\\lambda = 10^{-3}$ 来正则化模型，并防止在高维特征空间中发生过拟合。\n\n**3. 统计检测逻辑**\n\n对于每种诊断方法，其性能都通过 $K$-折交叉验证与基线线性模型进行比较，其中 $K = 5$。数据集被分成 $K$ 个不相交的折。对于每个折 $k \\in \\{1, \\dots, K\\}$，基线模型和诊断模型都在其余的 $K-1$ 个折上进行训练。然后，在第 $k$ 折的留出数据上计算它们各自的均方误差（MSE），记为 $\\text{MSE}_{\\text{base},k}$ 和 $\\text{MSE}_{\\text{diag},k}$。\n\n这个过程产生 $K$ 组成对的误差度量。我们计算成对差异 $d_k = \\text{MSE}_{\\text{base},k} - \\text{MSE}_{\\text{diag},k}$。$d_k$ 的正值表示诊断模型在第 $k$ 折上具有较低的预测误差，表明它提供了更好的拟合。\n\n为了统计上评估诊断模型是否显著更优，我们进行一个单侧配对 $t$-检验。原假设是诊断模型不比基线模型好（$\\mathbb{E}[d] \\le 0$），而备择假设是它更好（$\\mathbb{E}[d] > 0$）。$t$-统计量计算如下：\n$$t = \\frac{\\bar{d}}{s_d / \\sqrt{K}}$$\n其中 $\\bar{d} = \\frac{1}{K}\\sum_{k=1}^K d_k$ 是差异的样本均值，而 $s_d^2 = \\frac{1}{K-1}\\sum_{k=1}^K (d_k - \\bar{d})^2$ 是样本方差。\n\n在原假设下，该统计量近似服从自由度为 $K-1=4$ 的学生$t$分布。我们计算单侧 $p$ 值。如果满足两个条件，即宣布非线性被“检测到”：诊断模型的平均交叉验证误差较低（$\\bar{d}  0$），并且结果在统计上是显著的（$p  \\alpha$，显著性水平为 $\\alpha = 0.05$）。\n\n**4. 经验检测阈值**\n\n整个模拟过程通过对每个指定的噪声水平 $\\sigma \\in \\{0.1, 0.5, 1.0\\}$ 测试一个非线性振幅网格 $\\mathcal{A} = \\{0.0, 0.2, 0.4, 0.6, 0.8, 1.0\\}$ 来进行。\n\n对于每对 $(a, \\sigma)$ 和每种诊断方法，我们将整个数据生成和检测过程重复 $R = 40$ 次。检测概率被估计为在这 $R$ 次重复实验中检测到非线性的比例。\n\n对于给定的诊断方法和噪声水平，经验检测阈值 $\\theta$ 被定义为在网格 $\\mathcal{A}$ 中，使得估计的检测概率达到或超过目标功效 $\\pi^\\star = 0.8$ 的最小振幅 $a_g$。如果网格中没有振幅达到此目标功效，则阈值报告为哨兵值 $-1.0$。\n\n最终输出包括为每种诊断方法和噪声水平的组合计算出的九个阈值，四舍五入到小数点后两位，并按照问题陈述中指定的顺序排列。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import t as t_dist\n\ndef solve():\n    \"\"\"\n    Implements the full simulation pipeline to find detection thresholds for \n    non-linearity diagnostics.\n    \"\"\"\n    # Fixed parameters from the problem statement\n    N_SAMPLES = 120\n    BETA_0 = 0.0\n    BETA_1 = 1.0\n    N_FOLDS = 5\n    ALPHA = 0.05\n    N_REPLICATIONS = 40\n    TARGET_POWER = 0.8\n    SPLINE_KNOTS = np.array([0.2, 0.4, 0.6, 0.8])\n    RFF_M = 40\n    RFF_L = 0.2\n    RIDGE_LAMBDA = 1e-3\n    AMPLITUDE_GRID = np.array([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n    SIGMA_LEVELS = [0.1, 0.5, 1.0]\n    SENTINEL_VALUE = -1.0\n    \n    # Set a fixed random seed for reproducibility\n    np.random.seed(42)\n\n    def generate_data(a, sigma):\n        \"\"\"Generates data from the specified model.\"\"\"\n        x = np.random.uniform(0, 1, N_SAMPLES)\n        y_lin = BETA_0 + BETA_1 * x\n        g_x = np.sin(2 * np.pi * x)\n        epsilon = np.random.normal(0, sigma, N_SAMPLES)\n        y = y_lin + a * g_x + epsilon\n        return x, y\n\n    def solve_ols(X, y):\n        \"\"\"Solves Ordinary Least Squares.\"\"\"\n        beta, _, _, _ = np.linalg.lstsq(X, y, rcond=None)\n        return beta\n\n    def solve_ridge(X, y, lam):\n        \"\"\"Solves Ridge Regression with a penalty on all but the intercept.\"\"\"\n        p = X.shape[1]\n        penalty_matrix = lam * np.eye(p)\n        penalty_matrix[0, 0] = 0.0  # Do not penalize the intercept\n        A = X.T @ X + penalty_matrix\n        b = X.T @ y\n        beta = np.linalg.solve(A, b)\n        return beta\n\n    def make_design_matrix(x, method, knots=None, omega=None, b=None):\n        \"\"\"Creates the design matrix for a given method.\"\"\"\n        x_reshaped = x.reshape(-1, 1)\n        if method == 'base':\n            return np.c_[np.ones(len(x)), x]\n        elif method == 'poly':\n            return np.c_[np.ones(len(x)), x, x**2]\n        elif method == 'spline':\n            base_matrix = np.c_[np.ones(len(x)), x]\n            # Truncated power basis: (x - t)_+^3\n            spline_features = np.maximum(0, x_reshaped - knots)**3\n            return np.c_[base_matrix, spline_features]\n        elif method == 'kernel':\n            # RFF features: sqrt(2/m) * cos(omega*x + b)\n            rff_features = np.sqrt(2.0 / RFF_M) * np.cos(x_reshaped * omega + b)\n            return np.c_[np.ones(len(x)), rff_features]\n        else:\n            raise ValueError(f\"Unknown method '{method}'\")\n\n    def run_cv_comparison(x, y, diag_method_name, knots, rff_params):\n        \"\"\"\n        Performs K-fold CV and returns paired MSE differences.\n        \"\"\"\n        indices = np.arange(N_SAMPLES)\n        np.random.shuffle(indices)\n        fold_indices = np.array_split(indices, N_FOLDS)\n        \n        mse_diffs = []\n        for k in range(N_FOLDS):\n            val_idx = fold_indices[k]\n            train_idx = np.concatenate([fold_indices[j] for j in range(N_FOLDS) if j != k])\n            \n            x_train, y_train = x[train_idx], y[train_idx]\n            x_val, y_val = x[val_idx], y[val_idx]\n            \n            # Base model\n            X_base_train = make_design_matrix(x_train, 'base')\n            beta_base = solve_ols(X_base_train, y_train)\n            X_base_val = make_design_matrix(x_val, 'base')\n            y_pred_base = X_base_val @ beta_base\n            mse_base = np.mean((y_val - y_pred_base)**2)\n            \n            # Diagnostic model\n            if diag_method_name == 'kernel':\n                omega, b = rff_params\n                X_diag_train = make_design_matrix(x_train, 'kernel', omega=omega, b=b)\n                beta_diag = solve_ridge(X_diag_train, y_train, RIDGE_LAMBDA)\n                X_diag_val = make_design_matrix(x_val, 'kernel', omega=omega, b=b)\n            else: # poly or spline\n                X_diag_train = make_design_matrix(x_train, diag_method_name, knots=knots)\n                beta_diag = solve_ols(X_diag_train, y_train)\n                X_diag_val = make_design_matrix(x_val, diag_method_name, knots=knots)\n            \n            y_pred_diag = X_diag_val @ beta_diag\n            mse_diag = np.mean((y_val - y_pred_diag)**2)\n            \n            mse_diffs.append(mse_base - mse_diag)\n            \n        return np.array(mse_diffs)\n\n    def test_detection(mse_diffs):\n        \"\"\"Performs a one-sided paired t-test.\"\"\"\n        d_bar = np.mean(mse_diffs)\n        if d_bar = 0:\n            return False\n        \n        s_d = np.std(mse_diffs, ddof=1)\n        if s_d == 0:\n            # If all differences are identical and positive, it's a perfect improvement.\n            # This can happen in noise-free or low-noise scenarios. Treat as significant.\n            return True if d_bar > 0 else False\n        \n        t_stat = d_bar / (s_d / np.sqrt(N_FOLDS))\n        p_val = t_dist.sf(t_stat, df=N_FOLDS - 1)\n        \n        return p_val  ALPHA\n\n    all_thresholds = []\n    \n    diagnostic_methods = ['poly', 'spline', 'kernel']\n    \n    for sigma in SIGMA_LEVELS:\n        for method_name in diagnostic_methods:\n            detection_probs = {}\n            for a in AMPLITUDE_GRID:\n                detection_count = 0\n                for _ in range(N_REPLICATIONS):\n                    x_data, y_data = generate_data(a, sigma)\n                    \n                    # RFF parameters must be fixed for a given dataset (i.e., per replication)\n                    rff_p = None\n                    if method_name == 'kernel':\n                        omega = np.random.normal(0, 1.0 / RFF_L, size=RFF_M)\n                        b = np.random.uniform(0, 2 * np.pi, size=RFF_M)\n                        rff_p = (omega, b)\n\n                    mse_differences = run_cv_comparison(x_data, y_data, method_name, SPLINE_KNOTS, rff_p)\n                    \n                    if test_detection(mse_differences):\n                        detection_count += 1\n                \n                detection_probs[a] = detection_count / N_REPLICATIONS\n            \n            # Find the detection threshold\n            threshold = SENTINEL_VALUE\n            for a_val in AMPLITUDE_GRID:\n                if detection_probs[a_val] >= TARGET_POWER:\n                    threshold = a_val\n                    break\n            \n            all_thresholds.append(threshold)\n            \n    # Format the final output\n    formatted_results = [f\"{t:.2f}\" for t in all_thresholds]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3114979"}]}