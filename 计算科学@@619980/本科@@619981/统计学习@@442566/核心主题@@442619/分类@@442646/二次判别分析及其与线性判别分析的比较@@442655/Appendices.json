{"hands_on_practices": [{"introduction": "要真正理解二次判别分析（QDA）与线性判别分析（LDA）的根本区别，最有效的方法莫过于亲手推导它们的决策边界。本实践将引导你在一个一维高斯分布的假设场景下，从贝叶斯定理出发，完整地推导出QDA的二次决策边界和LDA的线性决策边界。通过这个过程，你将清晰地看到模型的数学结构如何直接决定其分类行为。[@problem_id:3164341]", "problem": "两个类别 $Y \\in \\{1,2\\}$ 具有一维特征 $X \\in \\mathbb{R}$，其类条件密度建模为高斯分布：$X \\mid Y=k \\sim \\mathcal{N}(\\mu_{k}, \\sigma_{k}^{2})$，其中 $k \\in \\{1,2\\}$。先验概率为 $\\pi_{1} = 0.7$ 和 $\\pi_{2} = 0.3$。参数为 $\\mu_{1} = 0$，$\\sigma_{1}^{2} = 1$，$\\mu_{2} = 3$，以及 $\\sigma_{2}^{2} = 4$。仅使用贝叶斯法则和高斯密度的定义，完成以下任务：\n- 在此一维设定下，为二次判别分析（QDA）推导闭式后验 $p(Y=1 \\mid X=x)$，并证明对数优势比是 $x$ 的二次函数。\n- 通过求解方程 $p(Y=1 \\mid X=x) = p(Y=2 \\mid X=x)$，求得并简化 QDA 的显式决策阈值；以闭式形式给出两个阈值。\n- 简要解释在此设定下，不相等的先验概率和不相等的方差如何导致 QDA 在实数线上产生不对称的决策区域。\n- 作为对比，在线性判别分析（LDA）的公共方差和相等先验假设下，推导其决策阈值，并为给定的均值提供闭式阈值。\n\n将最终阈值表示为精确的解析表达式，不进行数值舍入。您的最终答案必须是一个单行矩阵，其中包含两个 QDA 阈值（从小到大排序），后跟单个 LDA 阈值。", "solution": "首先对问题进行验证，以确保其在科学上是合理的、良定的和客观的。\n\n### 问题验证\n\n**步骤 1：提取已知条件**\n- 类别：$Y \\in \\{1,2\\}$\n- 特征空间：$X \\in \\mathbb{R}$（一维）\n- 类条件密度：$X \\mid Y=k \\sim \\mathcal{N}(\\mu_{k}, \\sigma_{k}^{2})$，其中 $k \\in \\{1,2\\}$\n- QDA 的先验概率：$\\pi_{1} = 0.7$，$\\pi_{2} = 0.3$\n- QDA 的参数：$\\mu_{1} = 0$，$\\sigma_{1}^{2} = 1$，$\\mu_{2} = 3$，$\\sigma_{2}^{2} = 4$\n- 任务 1 (QDA)：推导后验概率 $p(Y=1 \\mid X=x)$ 并证明对数优势比是 $x$ 的二次函数。\n- 任务 2 (QDA)：通过求解 $p(Y=1 \\mid X=x) = p(Y=2 \\mid X=x)$ 找到决策阈值。\n- 任务 3 (QDA)：解释不相等的先验和方差如何导致不对称的决策区域。\n- 任务 4 (LDA)：在假设公共方差和相等先验的情况下，使用给定的均值 $\\mu_1 = 0$ 和 $\\mu_2 = 3$ 推导 LDA 阈值。\n\n**步骤 2：使用提取的已知条件进行验证**\n该问题具有科学依据，因为它涉及基于高斯分布的标准贝叶斯分类模型（QDA 和 LDA），这是统计学习中的一个核心主题。该问题是良定的；QDA 部分所需的所有参数都已提供。对于 LDA 部分，作出了公共方差的假设，并且正如将要展示的，其具体值是不需要的，因为它在推导阈值的过程中被消去了。该问题是客观的，使用了清晰明确的数学定义。它不违反任何无效性标准。\n\n**步骤 3：结论与行动**\n该问题被认为是有效的。将提供一个完整的解答。\n\n### 解答推导\n\n**第 1 部分：QDA 后验概率和对数优势比**\n在给定观测值 $X=x$ 的情况下，类别 $Y=1$ 的后验概率由贝叶斯法则给出：\n$$p(Y=1 \\mid X=x) = \\frac{p(X=x \\mid Y=1) p(Y=1)}{p(X=x \\mid Y=1) p(Y=1) + p(X=x \\mid Y=2) p(Y=2)}$$\n设 $\\pi_k = p(Y=k)$ 为类别 $k$ 的先验概率，并设 $f_k(x) = p(X=x \\mid Y=k)$ 为类条件概率密度。对于高斯分布，它为：\n$$f_k(x) = \\frac{1}{\\sqrt{2\\pi\\sigma_k^2}} \\exp\\left(-\\frac{(x-\\mu_k)^2}{2\\sigma_k^2}\\right)$$\n类别 1 的后验概率为：\n$$p(Y=1 \\mid X=x) = \\frac{\\pi_1 f_1(x)}{\\pi_1 f_1(x) + \\pi_2 f_2(x)}$$\n对数优势比（logit）是后验概率比值的自然对数：\n$$\\text{log-odds} = \\ln\\left(\\frac{p(Y=1 \\mid X=x)}{p(Y=2 \\mid X=x)}\\right) = \\ln\\left(\\frac{\\frac{\\pi_1 f_1(x)}{\\pi_1 f_1(x) + \\pi_2 f_2(x)}}{\\frac{\\pi_2 f_2(x)}{\\pi_1 f_1(x) + \\pi_2 f_2(x)}}\\right) = \\ln\\left(\\frac{\\pi_1 f_1(x)}{\\pi_2 f_2(x)}\\right)$$\n这可以展开为：\n$$\\text{log-odds} = \\ln\\left(\\frac{\\pi_1}{\\pi_2}\\right) + \\ln(f_1(x)) - \\ln(f_2(x))$$\n代入高斯对数密度的表达式，其中 $\\ln(f_k(x)) = -\\frac{1}{2}\\ln(2\\pi\\sigma_k^2) - \\frac{(x-\\mu_k)^2}{2\\sigma_k^2}$：\n$$\\text{log-odds} = \\ln\\left(\\frac{\\pi_1}{\\pi_2}\\right) - \\frac{1}{2}\\ln(2\\pi\\sigma_1^2) - \\frac{(x-\\mu_1)^2}{2\\sigma_1^2} - \\left(-\\frac{1}{2}\\ln(2\\pi\\sigma_2^2) - \\frac{(x-\\mu_2)^2}{2\\sigma_2^2}\\right)$$\n$$\\text{log-odds} = \\ln\\left(\\frac{\\pi_1}{\\pi_2}\\right) + \\frac{1}{2}\\ln\\left(\\frac{\\sigma_2^2}{\\sigma_1^2}\\right) - \\frac{(x-\\mu_1)^2}{2\\sigma_1^2} + \\frac{(x-\\mu_2)^2}{2\\sigma_2^2}$$\n为证明这是 $x$ 的二次函数，我们展开包含 $x$ 的项：\n$$- \\frac{x^2 - 2x\\mu_1 + \\mu_1^2}{2\\sigma_1^2} + \\frac{x^2 - 2x\\mu_2 + \\mu_2^2}{2\\sigma_2^2}$$\n按 $x$ 的幂次分组，我们得到：\n$$x^2 \\left(\\frac{1}{2\\sigma_2^2} - \\frac{1}{2\\sigma_1^2}\\right) + x \\left(\\frac{\\mu_1}{\\sigma_1^2} - \\frac{\\mu_2}{\\sigma_2^2}\\right) + C$$\n其中 $C$ 包含所有常数项。由于方差不相等（$\\sigma_1^2 \\neq \\sigma_2^2$），$x^2$ 项的系数 $\\frac{1}{2\\sigma_2^2} - \\frac{1}{2\\sigma_1^2}$ 是非零的。因此，对数优势比是 $x$ 的二次函数。\n\n**第 2 部分：QDA 决策阈值**\n决策阈值是后验概率相等时的 $x$ 值，这等价于对数优势比为零。\n$$\\ln\\left(\\frac{\\pi_1}{\\pi_2}\\right) + \\frac{1}{2}\\ln\\left(\\frac{\\sigma_2^2}{\\sigma_1^2}\\right) - \\frac{(x-\\mu_1)^2}{2\\sigma_1^2} + \\frac{(x-\\mu_2)^2}{2\\sigma_2^2} = 0$$\n我们代入给定的参数：$\\pi_{1} = 0.7$，$\\pi_{2} = 0.3$，$\\mu_{1} = 0$，$\\sigma_{1}^{2} = 1$，$\\mu_{2} = 3$，$\\sigma_{2}^{2} = 4$。\n$$\\ln\\left(\\frac{0.7}{0.3}\\right) + \\frac{1}{2}\\ln\\left(\\frac{4}{1}\\right) - \\frac{(x-0)^2}{2(1)} + \\frac{(x-3)^2}{2(4)} = 0$$\n$$\\ln\\left(\\frac{7}{3}\\right) + \\frac{1}{2}\\ln(4) - \\frac{x^2}{2} + \\frac{x^2 - 6x + 9}{8} = 0$$\n由于 $\\frac{1}{2}\\ln(4) = \\ln(\\sqrt{4}) = \\ln(2)$，方程变为：\n$$\\ln\\left(\\frac{7}{3}\\right) + \\ln(2) - \\frac{x^2}{2} + \\frac{x^2 - 6x + 9}{8} = 0$$\n$$\\ln\\left(\\frac{14}{3}\\right) - \\frac{4x^2}{8} + \\frac{x^2 - 6x + 9}{8} = 0$$\n乘以 8：\n$$8\\ln\\left(\\frac{14}{3}\\right) - 4x^2 + x^2 - 6x + 9 = 0$$\n$$-3x^2 - 6x + \\left(9 + 8\\ln\\left(\\frac{14}{3}\\right)\\right) = 0$$\n$$3x^2 + 6x - \\left(9 + 8\\ln\\left(\\frac{14}{3}\\right)\\right) = 0$$\n我们使用二次公式 $x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$ 求解这个二次方程 $ax^2 + bx + c = 0$，其中 $a=3$，$b=6$，以及 $c = -\\left(9 + 8\\ln\\left(\\frac{14}{3}\\right)\\right)$：\n$$x = \\frac{-6 \\pm \\sqrt{6^2 - 4(3)\\left(-\\left(9 + 8\\ln\\left(\\frac{14}{3}\\right)\\right)\\right)}}{2(3)}$$\n$$x = \\frac{-6 \\pm \\sqrt{36 + 12\\left(9 + 8\\ln\\left(\\frac{14}{3}\\right)\\right)}}{6}$$\n$$x = \\frac{-6 \\pm \\sqrt{36 + 108 + 96\\ln\\left(\\frac{14}{3}\\right)}}{6}$$\n$$x = \\frac{-6 \\pm \\sqrt{144 + 96\\ln\\left(\\frac{14}{3}\\right)}}{6}$$\n我们可以从平方根下的项中提出因子 16：\n$$x = \\frac{-6 \\pm \\sqrt{16\\left(9 + 6\\ln\\left(\\frac{14}{3}\\right)\\right)}}{6} = \\frac{-6 \\pm 4\\sqrt{9 + 6\\ln\\left(\\frac{14}{3}\\right)}}{6}$$\n$$x = -1 \\pm \\frac{2}{3}\\sqrt{9 + 6\\ln\\left(\\frac{14}{3}\\right)}$$\n两个阈值，从小到大排序为：\n$$x_1 = -1 - \\frac{2}{3}\\sqrt{9 + 6\\ln\\left(\\frac{14}{3}\\right)}$$\n$$x_2 = -1 + \\frac{2}{3}\\sqrt{9 + 6\\ln\\left(\\frac{14}{3}\\right)}$$\n\n**第 3 部分：不对称的决策区域**\n在此 QDA 设定中，决策区域之所以不对称，主要有两个原因：\n1.  **不相等的方差 ($\\sigma_1^2 \\neq \\sigma_2^2$)：** 这是产生二次边界的根本原因。高斯密度的对数比包含一个 $x^2$ 项，导致对数优势比呈抛物线形。一个二次方程 $ax^2+bx+c=0$ 通常有两个不同的根 ($x_1, x_2$)。在此问题中，对数优势比中 $x^2$ 的系数是负的（$\\frac{1}{2\\sigma_2^2} - \\frac{1}{2\\sigma_1^2} = \\frac{1}{8} - \\frac{1}{2} = -\\frac{3}{8}  0$），所以抛物线开口向下。这意味着对于 $x \\in [x_1, x_2]$（一个有限区间），预测为类别 1。对于 $x \\in (-\\infty, x_1) \\cup (x_2, \\infty)$（一个由两个无限区间组成的不连通区域），预测为类别 2。决策区域在几何性质上的这种内在差异（一个是单个有限线段，另一个不是）构成了一种不对称性。\n2.  **不相等的先验概率 ($\\pi_1 \\neq \\pi_2$)：** 先验概率通过项 $\\ln(\\pi_1 / \\pi_2)$ 影响对数优势比的常数项。如果先验概率不相等，该项非零，导致对数优势比抛物线发生垂直平移。这种平移会移动决策边界 $x_1$ 和 $x_2$，从而改变决策区域的大小。例如，由于 $\\pi_1=0.7 > \\pi_2=0.3$，对数先验项为正，将抛物线向上平移，因此与先验相等的情形相比，扩大了偏向于类别 1 的区间 $[x_1, x_2]$。\n\n**第 4 部分：LDA 阈值**\n线性判别分析（LDA）假设方差是公共的，即 $\\sigma_1^2 = \\sigma_2^2 = \\sigma^2$。对于这部分，我们也被告知要假设先验相等，即 $\\pi_1 = \\pi_2$。\n对数优势比方程显著简化。项 $\\ln(\\pi_1/\\pi_2) = \\ln(1) = 0$。对数密度比中涉及方差的项也消去了：$\\frac{1}{2}\\ln(\\sigma_2^2/\\sigma_1^2) = \\frac{1}{2}\\ln(1) = 0$。对数优势比方程变为：\n$$\\text{log-odds} = - \\frac{(x-\\mu_1)^2}{2\\sigma^2} + \\frac{(x-\\mu_2)^2}{2\\sigma^2} = 0$$\n乘以 $2\\sigma^2$（假设 $\\sigma^2 > 0$）：\n$$-(x-\\mu_1)^2 + (x-\\mu_2)^2 = 0$$\n$$(x-\\mu_2)^2 = (x-\\mu_1)^2$$\n这是关于 $x$ 的一个线性方程：\n$$x^2 - 2x\\mu_2 + \\mu_2^2 = x^2 - 2x\\mu_1 + \\mu_1^2$$\n$$-2x\\mu_2 + \\mu_2^2 = -2x\\mu_1 + \\mu_1^2$$\n$$2x\\mu_1 - 2x\\mu_2 = \\mu_1^2 - \\mu_2^2$$\n$$2x(\\mu_1 - \\mu_2) = (\\mu_1 - \\mu_2)(\\mu_1 + \\mu_2)$$\n假设 $\\mu_1 \\neq \\mu_2$，我们两边除以 $2(\\mu_1 - \\mu_2)$：\n$$x = \\frac{\\mu_1 + \\mu_2}{2}$$\n公共方差 $\\sigma^2$ 确实被消去了。阈值就是两个均值的中点。使用给定的均值 $\\mu_1 = 0$ 和 $\\mu_2 = 3$：\n$$x = \\frac{0 + 3}{2} = \\frac{3}{2}$$", "answer": "$$\n\\boxed{\\begin{pmatrix} -1 - \\frac{2}{3}\\sqrt{9 + 6\\ln\\left(\\frac{14}{3}\\right)}  -1 + \\frac{2}{3}\\sqrt{9 + 6\\ln\\left(\\frac{14}{3}\\right)}  \\frac{3}{2} \\end{pmatrix}}\n$$", "id": "3164341"}, {"introduction": "理论学习之后，我们通过一个巧妙的思想实验来探索模型的边界。想象一个场景：两个类别的中心完全重合，仅在数据的“离散程度”（即方差）上有所不同。这个练习旨在揭示，在这种LDA因其“共享方差”假设而完全失效的情况下，QDA如何仅凭方差信息就能构建出有效的非线性分类器。[@problem_id:3164271]", "problem": "考虑一个统计学习中的二元分类问题，其中有两个类别 $Y \\in \\{0,1\\}$ 和一个实值特征 $X \\in \\mathbb{R}$。类别先验概率满足 $\\mathbb{P}(Y=0)=\\mathbb{P}(Y=1)=\\tfrac{1}{2}$。类条件分布是均值相等但方差不同的高斯分布：$X \\mid (Y=0) \\sim \\mathcal{N}(0,1)$ 和 $X \\mid (Y=1) \\sim \\mathcal{N}(0,9)$。假设分类器已知真实的类条件参数和先验概率。贝叶斯决策规则选择使后验概率 $\\mathbb{P}(Y=k \\mid X=x)$ 最大化的类别，该后验概率与类别先验概率 $\\mathbb{P}(Y=k)$ 和类条件密度 $p(x \\mid Y=k)$ 的乘积成正比。二次判别分析 (QDA) 为每个类别使用其自身的协方差进行建模，而线性判别分析 (LDA) 则为所有类别使用一个共享的协方差进行建模。\n\n从上述定义和高斯概率密度函数出发，推导在所述一维设置下的贝叶斯最优决策规则。然后，推断 QDA 和 LDA 在这些条件下会如何表现。哪个选项是正确的？\n\nA. 在先验概率相等的情况下，贝叶斯最优决策规则是：如果 $\\lvert x \\rvert  t$，则预测为类别 $1$，否则预测为类别 $0$，其中\n$$t \\;=\\; \\sqrt{\\frac{2\\,\\sigma_0^2\\,\\sigma_1^2}{\\sigma_1^2 - \\sigma_0^2}\\,\\ln\\!\\left(\\frac{\\sigma_1}{\\sigma_0}\\right)}\\,,$$\n其中 $\\sigma_0^2=1$ 且 $\\sigma_1^2=9$，所以 $t=\\sqrt{\\tfrac{9}{4}\\ln 3}$。当真实参数已知时，二次判别分析 (QDA) 能恢复此贝叶斯规则。线性判别分析 (LDA)，在均值和先验概率相等的情况下，无法通过 $x$ 来区分这两个类别，实际上无论 $x$ 取何值，都预测为同一个类别。\n\nB. 贝叶斯最优决策规则在 $\\lvert x \\rvert$ 较大时预测为类别 $0$，因为较小的方差意味着较重的尾部，从而对于较大的 $\\lvert x \\rvert$ 有更大的似然值。\n\nC. 当类别均值在 $0$ 处相等时，线性判别分析 (LDA) 会在 $x=0$ 处产生一个阈值，从而在此设置中实现贝叶斯最优分类器。\n\nD. 在先验概率和均值相等的情况下，贝叶斯决策边界是线性的，规则为：如果 $xt$ 则预测为类别 $1$，否则预测为类别 $0$，其中 $t=\\sqrt{2\\ln(\\sigma_1/\\sigma_0)}$；在所述设置中，QDA 和 LDA 都能恢复此边界。", "solution": "我们从贝叶斯决策原则开始：预测使后验概率 $\\mathbb{P}(Y=k \\mid X=x)$ 最大化的类别 $k \\in \\{0,1\\}$。根据贝叶斯定理，\n$$\n\\mathbb{P}(Y=k \\mid X=x) \\;\\propto\\; \\mathbb{P}(Y=k)\\, p(x \\mid Y=k).\n$$\n在先验概率相等 $\\mathbb{P}(Y=0)=\\mathbb{P}(Y=1)=\\tfrac{1}{2}$ 的情况下，决策简化为比较类条件似然：\n$$\n\\text{预测 } Y=1 \\text{ 如果 } p(x \\mid Y=1)  p(x \\mid Y=0), \\text{ 否则预测 } Y=0.\n$$\n对于高斯分布 $\\mathcal{N}(0,\\sigma_k^2)$，其密度为\n$$\np(x \\mid Y=k) \\;=\\; \\frac{1}{\\sqrt{2\\pi}\\,\\sigma_k}\\,\\exp\\!\\left(-\\frac{x^{2}}{2\\sigma_k^{2}}\\right).\n$$\n考虑对数似然比\n$$\n\\Lambda(x) \\;=\\; \\ln\\!\\frac{p(x \\mid Y=1)}{p(x \\mid Y=0)}\n\\;=\\; -\\ln \\sigma_1 + \\ln \\sigma_0 \\;-\\; \\frac{x^2}{2}\\left(\\frac{1}{\\sigma_1^2} - \\frac{1}{\\sigma_0^2}\\right).\n$$\n在先验概率相等的情况下，如果 $\\Lambda(x)  0$ 则预测 $Y=1$，如果 $\\Lambda(x)  0$ 则预测 $Y=0$。对 $\\Lambda(x)  0$ 求解 $\\lvert x \\rvert$，得到一个形式如下的阈值\n$$\n\\lvert x \\rvert \\;\\; t \\quad\\text{其中}\\quad\nt \\;=\\; \\sqrt{\\frac{2\\,\\sigma_0^2\\,\\sigma_1^2}{\\sigma_1^2 - \\sigma_0^2}\\,\\ln\\!\\left(\\frac{\\sigma_1}{\\sigma_0}\\right)}.\n$$\n要理解这一点，可以观察到当 $\\sigma_1  \\sigma_0$ 时，我们有 $\\frac{1}{\\sigma_1^2} - \\frac{1}{\\sigma_0^2}  0$，所以 $x^2$ 的二次项会改变符号，较大的 $\\lvert x \\rvert$ 会有利于方差较大的类别，而较小的 $\\lvert x \\rvert$ 则有利于方差较小的类别。代入 $\\sigma_0^2=1$ 和 $\\sigma_1^2=9$ 得\n$$\nt \\;=\\; \\sqrt{\\frac{2\\cdot 1 \\cdot 9}{9-1}\\,\\ln(3)} \\;=\\; \\sqrt{\\frac{18}{8}\\,\\ln(3)} \\;=\\; \\sqrt{\\frac{9}{4}\\,\\ln(3)}.\n$$\n因此，在先验概率和均值相等的情况下，贝叶斯最优规则是：\n- 如果 $\\lvert x \\rvert  t$，预测为 $Y=1$（方差较大的类别），\n- 如果 $\\lvert x \\rvert \\le t$，预测为 $Y=0$。\n\n二次判别分析 (QDA) 使用特定于类别的协方差参数来形成二次判别式。在一维情况下，如果参数已知，其决策边界与上面推导的贝叶斯最优规则一致，因为 QDA 通过使用各自的 $\\sigma_k^2$ 建模 $p(x \\mid Y=k)$ 来最大化相同的后验概率。\n\n线性判别分析 (LDA) 假设所有类别共享一个共同的协方差。在一维中，对于共享方差 $\\sigma^2$ 和相等的均值 $\\mu_0=\\mu_1=0$，类条件密度对于所有 $x$ 都变得相同，因此后验概率仅取决于先验概率：\n$$\np(x \\mid Y=0) = p(x \\mid Y=1) \\quad\\Rightarrow\\quad \\mathbb{P}(Y=0 \\mid X=x) = \\mathbb{P}(Y=0), \\quad \\mathbb{P}(Y=1 \\mid X=x) = \\mathbb{P}(Y=1).\n$$\n在先验概率相等的情况下，这对所有 $x$ 都会导致平局，所以 LDA 无法基于 $x$ 进行区分，实际上会预测为单个类别或任意打破平局；它不能复现基于方差的贝叶斯最优规则。\n\n逐项分析：\n- 选项 A：它正确地陈述了在先验概率相等的情况下，贝叶斯决策规则是关于 $\\lvert x \\rvert$ 的一个阈值，给出了正确的 $t$ 的通用公式以及在 $\\sigma_0^2=1, \\sigma_1^2=9$ 下正确的数值特例 $t=\\sqrt{\\tfrac{9}{4}\\ln 3}$。它还正确地描述了当参数已知时，QDA 能恢复此规则，而 LDA 在均值和先验概率相等的情况下无法通过 $x$ 进行区分，实际上预测为单个类别。结论：正确。\n- 选项 B：它声称较小的方差意味着较重的尾部，因此对于较大的 $\\lvert x \\rvert$ 有更大的似然值。这与事实恰恰相反：较大的方差产生较重的尾部。对于较大的 $\\lvert x \\rvert$，方差较大的类别具有更高的似然值，因此贝叶斯规则会分配给方差较大的类别，而不是方差较小的类别。结论：不正确。\n- 选项 C：它断言 LDA 在 $x=0$ 处产生一个阈值，并在此处达到贝叶斯最优。在均值相等和共享方差的情况下，LDA 产生相同的类条件密度；在先验概率相等的情况下，所有 $x$ 的后验概率在各个类别上都相同，因此 $x$ 中没有信息可以形成阈值，并且在这种方差不同的场景下 LDA 不是贝叶斯最优的。结论：不正确。\n- 选项 D：它断言决策边界在 $x$ 上是线性的，并提出了一个不正确的阈值公式 $t=\\sqrt{2\\ln(\\sigma_1/\\sigma_0)}$，该公式缺少必要的方差缩放。正确的贝叶斯边界是关于 $x$ 的二次边界（一个关于 $\\lvert x \\rvert$ 的阈值），并且在均值和先验概率相等的情况下，LDA 无法恢复它。结论：不正确。", "answer": "$$\\boxed{A}$$", "id": "3164271"}, {"introduction": "现在，让我们进入一个更高级、也更微妙的二维分类场景。在这个假设性问题中，两个类别的均值和各特征的独立方差均完全相同，唯一的区别在于特征之间的相关性结构。本实践挑战你思考QDA如何利用协方差矩阵中的非对角线元素来捕捉这种特征间的依赖关系，从而构建出LDA无法企及的复杂决策边界。[@problem_id:3164346]", "problem": "考虑一个在 $\\mathbb{R}^2$ 中的二元分类问题，其特征向量为 $x = (x_1,x_2)^\\top$，类别标签为 $Y \\in \\{1,2\\}$。假设类别条件分布是多元正态分布，具有相等的先验概率、相等的均值、相等的边际方差，但相关性不同：\n- $X \\mid Y=1 \\sim \\mathcal{N}(\\mu, \\Sigma_1)$，其中 $\\mu = (0,0)^\\top$，$\\Sigma_1 = \\begin{pmatrix} 1  \\rho \\\\ \\rho  1 \\end{pmatrix}$，\n- $X \\mid Y=2 \\sim \\mathcal{N}(\\mu, \\Sigma_2)$，具有相同的 $\\mu = (0,0)^\\top$，且 $\\Sigma_2 = \\begin{pmatrix} 1  -\\rho \\\\ -\\rho  1 \\end{pmatrix}$，\n其中 $\\rho \\in (0,1)$（为具体起见，可以认为 $\\rho = 0.8$），类别先验概率为 $\\pi_1 = \\pi_2 = 1/2$。因此，两个类别具有相同的均值和相同的边际方差，仅在相关性结构（协方差矩阵的非对角元素）上有所不同。\n\n仅使用关于多元正态模型下贝叶斯最优分类的基本原理，以及线性判别分析（LDA）和二次判别分析（QDA）的基本建模假设，判断下列哪些陈述是正确的。\n\nA. 在二次判别分析（QDA）下，两个类别之间的贝叶斯决策边界是满足 $x_1 x_2 = 0$ 的点集，它将平面划分为四个象限；$x_1 x_2  0$ 的点被分配到类别1，而 $x_1 x_2  0$ 的点被分配到类别2（在坐标轴上的零测集除外）。\n\nB. 在线性判别分析（LDA）和相等先验概率下，混合协方差保留了非对角线信息，并产生一个沿着 $x_1 = x_2$ 的非平凡线性分隔器。\n\nC. 由于类别均值和边际方差相等，任何具有相等先验概率的LDA规则都会为所有 $x$ 分配相同的判别分数（可能存在平局），从而产生 $50\\%$ 的预期错误率。\n\nD. 在这种设置下，LDA使用的混合协方差矩阵的非对角线项等于 $0$，因此LDA无法利用类别之间的相关性差异。\n\nE. 贝叶斯最优分类器（因此，在模型设定正确的情况下的QDA）实现了严格低于 $50\\%$ 的错误率，因为每个类别的概率质量都集中在其相关性符号所对应的象限中。", "solution": "我们从贝叶斯分类器的定义开始：对于具有类别条件密度 $p_k(x)$ 和先验概率 $\\pi_k$ 的两个类别，贝叶斯规则将 $x$ 分配给后验概率较大的类别，这等价于 $\\pi_k p_k(x)$ 较大。当 $p_k$ 是多元正态分布且先验概率相等时，比较 $\\pi_k p_k(x)$ 就简化为比较 $p_k(x)$，进而比较它们的对数密度。二次判别分析（QDA）是使用特定于类别的协方差矩阵的代入规则，而线性判别分析（LDA）则假设一个共同的协方差，并使用混合估计。\n\n对于给定的高斯分布的贝叶斯/QDA边界。对于 $k \\in \\{1,2\\}$，给定 $\\mu_k = \\mu = 0$ 和 $\\Sigma_k$，对数密度为\n$\\log p_k(x) = -\\tfrac{1}{2}\\log |\\Sigma_k| - \\tfrac{1}{2} x^\\top \\Sigma_k^{-1} x + \\text{const}$。\n在先验概率相等的情况下，决策边界满足 $\\log p_1(x) = \\log p_2(x)$，即\n$-\\tfrac{1}{2}\\log |\\Sigma_1| - \\tfrac{1}{2} x^\\top \\Sigma_1^{-1} x = -\\tfrac{1}{2}\\log |\\Sigma_2| - \\tfrac{1}{2} x^\\top \\Sigma_2^{-1} x$，\n等价于\n$x^\\top (\\Sigma_2^{-1} - \\Sigma_1^{-1}) x = \\log |\\Sigma_2| - \\log |\\Sigma_1|$。\n这里 $|\\Sigma_1| = 1 - \\rho^2 = |\\Sigma_2|$，因此 $\\log |\\Sigma_2| - \\log |\\Sigma_1| = 0$，所以边界简化为\n$x^\\top (\\Sigma_2^{-1} - \\Sigma_1^{-1}) x = 0$。\n\n我们计算 $\\Sigma_k^{-1}$。对于 $\\Sigma(\\rho) = \\begin{pmatrix} 1  \\rho \\\\ \\rho  1 \\end{pmatrix}$ 且 $|\\rho|1$，其逆矩阵为\n$\\Sigma(\\rho)^{-1} = \\dfrac{1}{1 - \\rho^2} \\begin{pmatrix} 1  -\\rho \\\\ -\\rho  1 \\end{pmatrix}$。\n因此\n$\\Sigma_1^{-1} = \\dfrac{1}{1 - \\rho^2} \\begin{pmatrix} 1  -\\rho \\\\ -\\rho  1 \\end{pmatrix}, \\quad \\Sigma_2^{-1} = \\dfrac{1}{1 - \\rho^2} \\begin{pmatrix} 1  \\rho \\\\ \\rho  1 \\end{pmatrix}$，\n进而\n$\\Sigma_2^{-1} - \\Sigma_1^{-1} = \\dfrac{1}{1 - \\rho^2} \\begin{pmatrix} 0  2\\rho \\\\ 2\\rho  0 \\end{pmatrix} = \\dfrac{2\\rho}{1 - \\rho^2} \\begin{pmatrix} 0  1 \\\\ 1  0 \\end{pmatrix}$。\n因此，\n$x^\\top (\\Sigma_2^{-1} - \\Sigma_1^{-1}) x = \\dfrac{2\\rho}{1 - \\rho^2} \\, x^\\top \\begin{pmatrix} 0  1 \\\\ 1  0 \\end{pmatrix} x = \\dfrac{4\\rho}{1 - \\rho^2} \\cdot x_1 x_2$。\n对于 $\\rho \\in (0,1)$，常数因子 $\\dfrac{4\\rho}{1 - \\rho^2}  0$，所以边界 $x^\\top (\\Sigma_2^{-1} - \\Sigma_1^{-1}) x = 0$ 等价于 $x_1 x_2 = 0$。\n\n决策规则是选择后验概率最大的类别。在先验概率相等的情况下，这等价于选择类条件似然 $p_k(x)$ 最大的类别。因此，我们预测类别 1 如果 $\\log p_1(x) > \\log p_2(x)$。代入对数似然表达式，该不等式变为：\n$-\\tfrac{1}{2} x^\\top \\Sigma_1^{-1} x > -\\tfrac{1}{2} x^\\top \\Sigma_2^{-1} x$\n$x^\\top \\Sigma_2^{-1} x > x^\\top \\Sigma_1^{-1} x$\n$x^\\top (\\Sigma_2^{-1} - \\Sigma_1^{-1}) x > 0$\n代入我们之前计算的 $\\Sigma_2^{-1} - \\Sigma_1^{-1}$，我们得到：\n$\\dfrac{4\\rho}{1 - \\rho^2} x_1 x_2 > 0$\n因为 $\\rho \\in (0,1)$，系数 $\\dfrac{4\\rho}{1 - \\rho^2}$ 是正的。因此，当 $x_1 x_2 > 0$ 时我们预测类别 1，当 $x_1 x_2  0$ 时预测类别 2。这与直觉相符：类别 1 具有正相关性，其数据点倾向于分布在 $x_1$ 和 $x_2$ 同号的象限（第一和第三象限）；类别 2 具有负相关性，其数据点倾向于分布在 $x_1$ 和 $x_2$ 异号的象限（第二和第四象限）。\n因此，QDA（贝叶斯）边界是坐标轴 $x_1 = 0$ 或 $x_2 = 0$ 的并集，分类区域是由 $x_1 x_2$ 的符号决定的象限。\n\n在共同协方差下的LDA。LDA假设一个共同的协方差 $\\Sigma_p$，通常是跨类别混合的。给定两个类别的协方差，混合协方差为\n$\\Sigma_p = \\dfrac{1}{2}(\\Sigma_1 + \\Sigma_2) = \\dfrac{1}{2} \\begin{pmatrix} 1  \\rho \\\\ \\rho  1 \\end{pmatrix} + \\dfrac{1}{2} \\begin{pmatrix} 1  -\\rho \\\\ -\\rho  1 \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}$。\n因此，非对角线项抵消为 $0$。类别 $k$ 的LDA判别分数具有以下形式（忽略对两个类别都相同的加性常数）$\\delta_k(x) = x^\\top \\Sigma_p^{-1} \\mu_k - \\tfrac{1}{2} \\mu_k^\\top \\Sigma_p^{-1} \\mu_k + \\log \\pi_k$。由于 $\\mu_1 = \\mu_2 = 0$ 且先验概率相等，我们得到对于所有 $x$ 都有 $\\delta_1(x) = \\delta_2(x)$。因此，LDA在任何地方都产生平局，无法进行区分；在任何不使用 $x$ 的平局打破规则下，给定相等的先验概率，预期错误率为 $50\\%$。\n\n错误率比较与直觉。贝叶斯/QDA分类器根据 $x_1 x_2$ 的符号进行分离，这与依赖结构相符：对于一个零均值、相关性为 $\\rho > 0$ 的二元正态分布， $x_1$ 和 $x_2$ 同号的概率严格大于 $1/2$；对于 $\\rho  0$，该概率严格小于 $1/2$。一个关于零均值二元正态分布的著名恒等式给出 $\\mathbb{P}(x_1 x_2 > 0) = \\tfrac{1}{2} + \\tfrac{1}{\\pi} \\arcsin(\\rho)$，对于 $\\rho > 0$ 该值严格大于 $\\tfrac{1}{2}$，对于 $\\rho  0$ 该值严格小于 $\\tfrac{1}{2}$。因此，根据 $x_1 x_2$ 的符号分配类别的贝叶斯/QDA规则实现了严格低于 $50\\%$ 的错误率，而对于这种构造，LDA的错误率则停留在 $50\\%$。\n\n逐项分析：\n- 选项A：推导表明贝叶斯/QDA边界是 $x_1 x_2 = 0$，分类规则是根据 $x_1 x_2$ 的符号来分配类别。我们的推导确认了当 $x_1 x_2 > 0$ 时分配给类别1，当 $x_1 x_2  0$ 时分配给类别2。该陈述是正确的。结论：正确。\n- 选项B：混合协方差为 $\\Sigma_p = I_2$，它丢弃了非对角线信息。因此，LDA不会产生像 $x_1=x_2$ 这样的非平凡线性边界；实际上，在均值和先验概率相等的情况下，它处处产生平局，无法分离。结论：不正确。\n- 选项C：由于 $\\mu_1 = \\mu_2 = 0$，$\\Sigma_p = I_2$，且先验概率相等，对于所有 $x$ 都有 $\\delta_1(x) = \\delta_2(x)$，因此LDA处处平局，预期错误率为 $50\\%$。结论：正确。\n- 选项D：我们计算出 $\\Sigma_p = \\tfrac{1}{2}(\\Sigma_1 + \\Sigma_2) = I_2$，其非对角线项为 $0$。因此LDA无法利用相关性差异。结论：正确。\n- 选项E：如前所述，贝叶斯/QDA规则与相关性引起的符号结构一致，对于任何 $\\rho \\in (0,1)$，其错误率都严格低于 $50\\%$。结论：正确。", "answer": "$$\\boxed{ACDE}$$", "id": "3164346"}]}