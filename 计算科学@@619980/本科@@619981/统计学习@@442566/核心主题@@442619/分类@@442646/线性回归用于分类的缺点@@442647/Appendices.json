{"hands_on_practices": [{"introduction": "将线性回归用于分类是一个诱人但存在缺陷的捷径。实践者遇到的首要问题之一是如何对二元标签进行编码。本练习将探讨不同的标签编码方式（例如 $\\{0, 1\\}$ 与 $\\{-1, 1\\}$）如何影响模型的参数和预测。通过实现和比较这些模型，您将具体地理解为什么线性回归的输出值不是概率，以及决策阈值如何与任意的编码选择紧密相连 [@problem_id:3117107]。", "problem": "要求你研究普通最小二乘线性回归在用于二元分类时，在不同标签编码下的行为，以及这对决策边界和可解释性有何影响。请完全使用数学术语，并基于以下基础：\n\n- 普通最小二乘法 (OLS) 最小化均方误差 (MSE) 目标函数，该函数由 $$\\min_{\\beta} \\sum_{i=1}^{n} (y_i - z_i^\\top \\beta)^2$$ 给出，其中每个训练输入具有增广特征向量 $$z_i = [1, x_i^\\top]^\\top \\in \\mathbb{R}^{d+1}$$（如果包含截距），或者当不使用截距时为 $$z_i = x_i \\in \\mathbb{R}^{d}$$。\n- OLS 解满足正规方程 $$Z^\\top Z \\, \\beta = Z^\\top y$$，其中 $$Z \\in \\mathbb{R}^{n \\times p}$$ 是通过将 $$z_i^\\top$$ 按行堆叠而成的设计矩阵，如果使用截距则 $$p = d+1$$，否则 $$p = d$$；$$y \\in \\mathbb{R}^{n}$$ 是标签向量。\n\n你的程序必须在二元分类的两种常见标签编码下实现 OLS 拟合：\n- 编码 A：$$y \\in \\{0, 1\\}.$$\n- 编码 B：$$y' \\in \\{-1, 1\\}.$$\n\n在编码 A 下，通常通过将拟合值 $$\\hat{y} = z^\\top \\beta$$ 在 $$0.5$$ 处进行阈值处理来执行分类；即，如果 $$\\hat{y} \\ge 0.5$$，则预测为类别 $$1$$，否则为类别 $$0$$。在编码 B 下，通常通过将 $$\\hat{y}' = z^\\top \\beta'$$ 在 $$0$$ 处进行阈值处理来执行分类；即，如果 $$\\hat{y}' \\ge 0$$，则预测为类别 $$1$$，否则为类别 $$-1$$。这些阈值的确切处理方式以及编码选择的影响是本练习的重点。\n\n数据规格：\n- 训练集包含 $$n = 10$$ 个在 $$\\mathbb{R}^2$$ 中的点：\n  - 类别 $$0$$ 的点（编码 A 标签为 $$0$$，编码 B 标签为 $$-1$$）：$$x = [-5, 3], [-4, 2], [-3, 1], [-2, 0.5], [-1, -0.5].$$\n  - 类别 $$1$$ 的点（编码 A 标签为 $$1$$，编码 B 标签为 $$1$$）：$$x = [2, 1], [3, 2], [4, 2.5], [5, 3], [6, 4].$$\n- 对于“带截距”的模型，使用增广特征 $$z = [1, x_1, x_2]^\\top$$。对于“不带截距”的模型，使用特征 $$z = [x_1, x_2]^\\top$$。\n\n评估网格：\n- 定义一个测试点网格 $$x = (x_1, x_2)$$，其中 $$x_1 \\in \\{-6, -5, \\dots, 6\\}$$ 且 $$x_2 \\in \\{-3, -2, \\dots, 6\\}$$，形成一个 $$13 \\times 10$$ 的网格点。使用这些点来评估决策区域和可解释性属性。\n\n你必须实现以下四个测试用例，以探讨线性回归用于分类的缺点的不同方面。每个测试用例必须生成一个基本类型的值：布尔值、整数或浮点数。\n\n- 测试用例 $$1$$（在正确阈值下、包含截距时，决策边界在不同编码间的恒定性）：\n  - 在编码 A 下拟合带截距的 OLS，以获得 $$\\hat{y}(x)$$，并使用阈值 $$0.5$$ 将网格点分类到标签 $$\\{0,1\\}$$。\n  - 在编码 B 下拟合带截距的 OLS，以获得 $$\\hat{y}'(x)$$，并使用阈值 $$0$$ 将网格点分类到标签 $$\\{-1,1\\}$$。通过 $$-1 \\mapsto 0, 1 \\mapsto 1$$ 将这些标签映射到 $$\\{0,1\\}$$。\n  - 返回一个布尔值，指示网格上两种分类标签对于所有网格点是否完全相同。\n\n- 测试用例 $$2$$（在编码 A 下、包含截距时，拟合值超出范围）：\n  - 使用在编码 A 下带截距的 OLS 拟合，计算其拟合值 $$\\hat{y}(x)$$ 落在 $$[0, 1]$$ 范围之外的网格点的比例。将此比例作为 $$[0,1]$$ 内的浮点数返回。这量化了一个缺点：线性回归的拟合值不是概率，并且可能超出可解释的范围。\n\n- 测试用例 $$3$$（在不带截距时，仿射一致性的失效）：\n  - 在两种编码下拟合不带截距的 OLS，以在训练输入上获得拟合值 $$\\hat{y}(x_i)$$ 和 $$\\hat{y}'(x_i)$$。\n  - 令 $$a$$ 和 $$c$$ 为唯一的标量，使得 $$a \\cdot 0 + c = -1$$ 和 $$a \\cdot 1 + c = 1$$（从 $$[0,1]$$ 到 $$[-1,1]$$ 的唯一仿射映射）。计算在训练点上 $$\\hat{y}'(x_i)$$ 与 $$a \\, \\hat{y}(x_i) + c$$ 之间的最大绝对偏差。将此最大偏差作为浮点数返回。非零偏差表明，当省略截距时，编码的改变会改变拟合的决策函数。\n\n- 测试用例 $$4$$（在编码 B 下、包含截距时，依赖于编码的阈值处理）：\n  - 使用在编码 B 下带截距的 OLS 拟合，对网格点进行两次分类：一次使用阈值 $$0$$，另一次对 $$\\hat{y}'(x)$$ 使用阈值 $$0.5$$。\n  - 返回一个整数，等于在这两个阈值下分类结果不同的网格点数量。这量化了编码和阈值的改变如何移动决策边界并影响可解释性。\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含测试用例 $$1$$ 到 $$4$$ 的结果，形式为方括号内以逗号分隔的列表，顺序为 $$[\\text{TC1}, \\text{TC2}, \\text{TC3}, \\text{TC4}]$$。例如，$$[ \\text{boolean}, \\text{float}, \\text{float}, \\text{integer} ]$$。\n- 不允许外部输入；所有数据均如上所述。", "solution": "用户提供了一个问题，要求分析普通最小二乘 (OLS) 线性回归在用于二元分类时的行为。分析重点是不同标签编码以及包含或排除截距项的影响。该问题定义明确，科学上合理，并提供了所有必要的数据和评估标准。这是统计学习中的一个有效问题。\n\nOLS 的核心是最小化均方误差 (MSE)，其定义为观测标签 $$y_i$$ 与预测值 $$\\hat{y}_i = z_i^\\top \\beta$$ 之间平方差的总和。目标函数为 $$J(\\beta) = \\sum_{i=1}^{n} (y_i - z_i^\\top \\beta)^2$$。最小化此目标的最优参数向量 $$\\beta$$ 通过求解正规方程 $$Z^\\top Z \\beta = Z^\\top y$$ 找到，其中 $$Z$$ 是设计矩阵，$$y$$ 是标签向量。解为 $$\\beta = (Z^\\top Z)^{-1} Z^\\top y$$，前提是矩阵 $$Z^\\top Z$$ 可逆，对于给定的非共线数据，这是成立的。\n\n我们将继续解决四个指定的测试用例。\n\n### 测试用例 1：决策边界在不同编码间的恒定性\n该测试用例检验当模型包含截距时，决策边界是否对标签的仿射变换保持不变。\n设编码 A 使用标签 $$y_A \\in \\{0, 1\\}$$，编码 B 使用标签 $$y_B \\in \\{-1, 1\\}$$。这两种编码通过仿射变换 $$y_B = 2y_A - 1$$ 相关联。设 $$\\beta_A$$ 和 $$\\beta_B$$ 分别是对应于 $$y_A$$ 和 $$y_B$$ 的 OLS 系数向量，用于带截距的模型。设计矩阵 $$Z$$ 对两种拟合都是相同的，并且包含一列全为 1 的值，即 $$z_i = [1, x_i^\\top]^\\top$$。\n\n系数向量之间的关系是：\n$$\\beta_B = (Z^\\top Z)^{-1} Z^\\top y_B = (Z^\\top Z)^{-1} Z^\\top (2y_A - \\mathbf{1})$$\n$$= 2(Z^\\top Z)^{-1} Z^\\top y_A - (Z^\\top Z)^{-1} Z^\\top \\mathbf{1} = 2\\beta_A - (Z^\\top Z)^{-1} Z^\\top \\mathbf{1}$$\n其中 $$\\mathbf{1}$$ 是一个全为 1 的列向量。由于模型包含截距，$$Z$$ 的第一列是 $$\\mathbf{1}$$$。设 $$e_1 = [1, 0, \\dots, 0]^\\top$$。则 $$Z e_1 = \\mathbf{1}$$，这意味着 $$Z^\\top \\mathbf{1} = Z^\\top Z e_1$$。将此代入 $$\\beta_B$$ 的表达式中可得：\n$$\\beta_B = 2\\beta_A - (Z^\\top Z)^{-1} (Z^\\top Z e_1) = 2\\beta_A - e_1$$\n这意味着如果 $$\\beta_A = [\\beta_{A,0}, \\beta_{A,1}, \\dots]^\\top$$，那么 $$\\beta_B = [2\\beta_{A,0} - 1, 2\\beta_{A,1}, \\dots]^\\top$$。\n\n对于任何输入点 $$z = [1, x^\\top]^\\top$$，拟合值之间的关系为：\n$$\\hat{y}_B(z) = z^\\top \\beta_B = z^\\top(2\\beta_A - e_1) = 2z^\\top\\beta_A - z^\\top e_1 = 2\\hat{y}_A(z) - 1$$\n因此，预测值也通过相同的仿射变换相关联。\n\n分类规则如下：\n- 编码 A：如果 $$\\hat{y}_A(z) \\ge 0.5$$，预测为类别 1。\n- 编码 B：如果 $$\\hat{y}_B(z) \\ge 0$$，预测为类别 1。\n\n将拟合值之间的关系代入编码 B 的规则中可得：\n$$2\\hat{y}_A(z) - 1 \\ge 0 \\implies 2\\hat{y}_A(z) \\ge 1 \\implies \\hat{y}_A(z) \\ge 0.5$$\n这与编码 A 的分类规则完全相同。因此，所有网格点上的分类结果将是相同的。结果是一个布尔值 `True`。\n\n### 测试用例 2：拟合值超出范围\n该测试用例突出了 OLS 用于分类的一个关键缺点：拟合值 $$\\hat{y}(z) = z^\\top\\beta$$ 不被约束在标签的范围内（例如 $$[0, 1]$$）。预测是输入特征的线性函数，因此是无界的。对于远离由 $$z^\\top\\beta_A = 0.5$$ 定义的决策超平面的点，$$z^\\top\\beta_A$$ 的值可能远大于 $$1$$ 或远小于 $$0$$。这种行为与逻辑回归等模型形成对比，后者使用 sigmoid 函数将线性预测器映射到 $$[0, 1]$$ 区间内，从而允许概率解释。我们将计算在所有网格点上使用编码 A 的模型的拟合值，并计算落在 $$[0, 1]$$ 范围之外的比例。\n\n### 测试用例 3：在不带截距时，仿射一致性的失效\n该测试研究了当省略截距项时，仿射等变性属性会发生什么变化。现在的模型是 $$ \\hat{y}(x) = x^\\top \\beta $$。设计矩阵 $$Z$$ 现在仅由特征列 $$x_i^\\top$$ 组成。\n根据测试用例 1 的推导，$$\\beta_B = 2\\beta_A - (Z^\\top Z)^{-1} Z^\\top \\mathbf{1}$$。当不包含截距时，$$Z$$ 的列空间通常不包含向量 $$\\mathbf{1}$$。因此，项 $$(Z^\\top Z)^{-1} Z^\\top \\mathbf{1}$$ 不会简化为 $$e_1$$。训练集上拟合值之间的关系变为：\n$$\\hat{y}_B = Z \\beta_B = 2Z\\beta_A - Z(Z^\\top Z)^{-1} Z^\\top \\mathbf{1} = 2\\hat{y}_A - H\\mathbf{1}$$\n其中 $$H = Z(Z^\\top Z)^{-1} Z^\\top$$ 是帽子矩阵。\n仿射关系 $$\\hat{y}_B = 2\\hat{y}_A - \\mathbf{1}$$ 仅在 $$H\\mathbf{1} = \\mathbf{1}$$ 时成立，这要求 $$\\mathbf{1}$$ 位于 $$Z$$ 的列空间中。在没有截距的情况下，这无法保证，并且对于给定数据不成立。此测试计算训练点上的最大绝对偏差 $$|\\hat{y}'(x_i) - (2 \\hat{y}(x_i) - 1)|$$，这等同于计算向量 $$| (2\\hat{y}_A - H\\mathbf{1}) - (2\\hat{y}_A - \\mathbf{1}) | = | \\mathbf{1} - H\\mathbf{1} |$$ 的元素级最大绝对值。非零结果证明了仿射一致性的失效。\n\n### 测试用例 4：依赖于编码的阈值处理\n分类阈值的选择与标签编码有着内在的联系。对于 $$\\{0, 1\\}$$ 编码，自然阈值是 $$0.5$$，即标签的中点。对于 $$\\{-1, 1\\}$$ 编码，自然阈值是 $$0$$。该测试用例量化了使用“不正确”阈值的影响。它使用在编码 B（标签为 $$\\{-1, 1\\}$$）下拟合的模型，并使用两个不同的阈值对网格点进行分类：正确的阈值（$$0$$）和对于另一种编码来说是自然的阈值（$$0.5$$）。分类发生变化的网格点数量揭示了决策边界移动的程度。如果一个点的拟合值 $$\\hat{y}_B(z)$$ 落在两个阈值之间，即 $$0 \\le \\hat{y}_B(z)  0.5$$，其分类就会改变。由此产生的整数计数表明了这种可解释性错误的非平凡影响。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the four test cases related to the use of ordinary least squares\n    for binary classification.\n    \"\"\"\n    \n    # --- Data Specification ---\n    X_train = np.array([\n        [-5, 3], [-4, 2], [-3, 1], [-2, 0.5], [-1, -0.5], # Class 0\n        [2, 1], [3, 2], [4, 2.5], [5, 3], [6, 4]         # Class 1\n    ])\n    \n    # Encoding A: y in {0, 1}\n    y_A = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n    \n    # Encoding B: y' in {-1, 1}\n    y_B = np.array([-1, -1, -1, -1, -1, 1, 1, 1, 1, 1])\n\n    # Evaluation grid\n    x1_grid = np.arange(-6, 7)  # 13 points from -6 to 6\n    x2_grid = np.arange(-3, 7)  # 10 points from -3 to 6\n    xx1, xx2 = np.meshgrid(x1_grid, x2_grid, indexing='ij')\n    grid_points = np.vstack([xx1.ravel(), xx2.ravel()]).T\n\n    # --- Helper Functions ---\n    def fit_ols(X, y, intercept=True):\n        \"\"\"Fits an OLS model and returns the parameters beta.\"\"\"\n        if intercept:\n            Z = np.hstack([np.ones((X.shape[0], 1)), X])\n        else:\n            Z = X\n        \n        # Solve the normal equations: Z.T Z beta = Z.T y\n        try:\n            beta = np.linalg.solve(Z.T @ Z, Z.T @ y)\n        except np.linalg.LinAlgError:\n            # Fallback for singular matrices, though not expected here\n            # as the problem is well-posed.\n            Z_pinv = np.linalg.pinv(Z)\n            beta = Z_pinv @ y\n            \n        return beta\n\n    def predict_ols(X_new, beta, intercept=True):\n        \"\"\"Computes predictions y_hat = Z beta.\"\"\"\n        if intercept:\n            Z_new = np.hstack([np.ones((X_new.shape[0], 1)), X_new])\n        else:\n            Z_new = X_new\n        return Z_new @ beta\n\n    # --- Test Case 1: Decision boundary invariance ---\n    beta_A_int = fit_ols(X_train, y_A, intercept=True)\n    beta_B_int = fit_ols(X_train, y_B, intercept=True)\n    \n    y_hat_A_grid = predict_ols(grid_points, beta_A_int, intercept=True)\n    y_hat_B_grid = predict_ols(grid_points, beta_B_int, intercept=True)\n    \n    # Classification with Encoding A model and threshold 0.5\n    classif_A = (y_hat_A_grid >= 0.5)\n    \n    # Classification with Encoding B model, threshold 0, then map to {0, 1}\n    pred_B = np.where(y_hat_B_grid >= 0, 1, -1)\n    classif_B = (pred_B == 1)\n    \n    tc1_result = bool(np.array_equal(classif_A, classif_B))\n\n    # --- Test Case 2: Out-of-range fitted values ---\n    out_of_range = (y_hat_A_grid  0) | (y_hat_A_grid > 1)\n    tc2_result = float(np.sum(out_of_range) / len(grid_points))\n\n    # --- Test Case 3: Failure of affine consistency ---\n    beta_A_noint = fit_ols(X_train, y_A, intercept=False)\n    beta_B_noint = fit_ols(X_train, y_B, intercept=False)\n    \n    y_hat_A_train = predict_ols(X_train, beta_A_noint, intercept=False)\n    y_hat_B_train = predict_ols(X_train, beta_B_noint, intercept=False)\n    \n    # Affine map from [0,1] to [-1,1] is f(t) = 2*t - 1\n    y_hat_A_transformed = 2 * y_hat_A_train - 1\n    \n    deviations = np.abs(y_hat_B_train - y_hat_A_transformed)\n    tc3_result = float(np.max(deviations))\n    \n    # --- Test Case 4: Encoding-dependent thresholding ---\n    # Use y_hat_B_grid from Test Case 1\n    classif_B_thresh0 = (y_hat_B_grid >= 0)\n    classif_B_thresh05 = (y_hat_B_grid >= 0.5)\n    \n    differences = np.sum(classif_B_thresh0 != classif_B_thresh05)\n    tc4_result = int(differences)\n\n    # --- Final Output ---\n    results = [tc1_result, tc2_result, tc3_result, tc4_result]\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3117107"}, {"introduction": "除了标签编码问题外，线性回归对数据点的分布，特别是异常值，表现出高度的敏感性。本练习将展示高杠杆点 (high-leverage points) 的影响，这些点虽然远离特征空间的中心，但即使被正确分类，也可能对回归模型产生不成比例的影响。通过一个动手编程的例子，您将观察到少数几个异常值如何“拉扯”回归线，虽然能达到完美的分类准确率，但却产生无法解释的得分，这些得分无法反映模型的置信度——这对于任何实际应用都是一个致命的缺陷 [@problem_id:3117088]。", "problem": "要求您编写一个完整、可运行的程序，该程序构建三个合成的二元分类数据集，并使用普通最小二乘法 (OLS) 拟合一个线性回归模型。目标是通过精确计算证明，在线性可分的情况下，OLS 可以实现零训练分类错误，但其产生的实值预测不适合作为概率，因此无法反映不确定性，并使得弃权和风险控制变得困难。\n\n请从统计学习中的以下基本概念开始：\n- 二元标签编码为 $y_i \\in \\{0,1\\}$。\n- 普通最小二乘法 (OLS) 为线性预测器 $f(\\mathbf{x}) = \\mathbf{w}^{\\top}\\mathbf{x} + b$ 寻找参数 $(\\mathbf{w}, b)$，以最小化经验平方损失 $\\sum_{i=1}^{n} (y_i - f(\\mathbf{x}_i))^2$。\n- 从回归输出中导出的分类规则以 $0.5$ 为阈值：如果 $f(\\mathbf{x}_i) \\geq 0.5$，则预测类别为 $\\hat{y}_i = 1$，否则为 $\\hat{y}_i = 0$。\n- 线性可分性意味着存在 $(\\mathbf{w}^\\ast, b^\\ast)$，使得对于所有 $y_i = 1$ 的点，有 $f^\\ast(\\mathbf{x}_i) \\geq 0.5$；对于所有 $y_i = 0$ 的点，有 $f^\\ast(\\mathbf{x}_i)  0.5$。\n\n您的程序必须使用正规方程或数值上等效的稳定方法来实现 OLS 拟合。使用一个设计矩阵 $X \\in \\mathbb{R}^{n \\times d}$，并为其添加一列全为 1 的截距项，因此线性模型为 $f(\\mathbf{x}) = \\mathbf{w}^{\\top}\\mathbf{x} + b$。通过求解 $X_{\\text{aug}}\\boldsymbol{\\theta} \\approx \\mathbf{y}$ 的最小二乘解来计算 OLS 解，其中 $X_{\\text{aug}} = [X \\,\\, \\mathbf{1}] \\in \\mathbb{R}^{n \\times (d+1)}$ 且 $\\boldsymbol{\\theta} \\in \\mathbb{R}^{d+1}$ 连接了 $\\mathbf{w}$ 和 $b$。\n\n对于每个数据集，在拟合 OLS 后，计算以下三个量：\n1. 零训练分类错误的布尔指标，定义为 $\\frac{1}{n}\\sum_{i=1}^{n} \\mathbb{I}[\\hat{y}_i \\neq y_i] = 0$ 是否成立，其中 $\\hat{y}_i = \\mathbb{I}[f(\\mathbf{x}_i) \\geq 0.5]$。\n2. 回归预测值在单位区间外的比例，定义为 $\\frac{1}{n}\\sum_{i=1}^{n} \\mathbb{I}[f(\\mathbf{x}_i)  0 \\,\\lor\\, f(\\mathbf{x}_i) > 1]$。\n3. 在边距水平 $\\epsilon$ 下的弃权覆盖率，定义为回归输出与极值（0 或 1）的距离在 $\\epsilon$ 以内的点的比例，即 $\\frac{1}{n}\\sum_{i=1}^{n} \\mathbb{I}\\big(\\min\\{|f(\\mathbf{x}_i) - 0|, |f(\\mathbf{x}_i) - 1|\\} \\leq \\epsilon\\big)$。该指标量化了如果我们将回归输出视为概率，并只接受被认为是“高置信度”的决策时，会有多少预测被保留；它揭示了 OLS 输出不是概率所导致的不匹配。\n\n您的程序必须精确构建以下测试数据集（所有特征都是一维的，$d=1$，并且包含截距项）：\n\n- 测试用例 A（均衡，中等间隔）：\n  - 负类 ($y=0$)：$x \\in \\{-3,-2,-1\\}$，每个值重复 10 次。\n  - 正类 ($y=1$)：$x \\in \\{1,2,3\\}$，每个值重复 10 次。\n  - 边距参数 $\\epsilon = 0.1$。\n\n- 测试用例 B（均衡，但带有大幅值离群点，这些离群点会增大方差并将大多数预测压缩到 $0.5$ 附近）：\n  - 负类 ($y=0$)：$x = -1$ 重复 20 次，$x = -100$ 重复 5 次。\n  - 正类 ($y=1$)：$x = 1$ 重复 20 次，$x = 100$ 重复 5 次。\n  - 边距参数 $\\epsilon = 0.05$。\n\n- 测试用例 C（与测试用例 B 数据集相同，但通过更严格的边距进行更严格的风险控制）：\n  - 负类 ($y=0$)：$x = -1$ 重复 20 次，$x = -100$ 重复 5 次。\n  - 正类 ($y=1$)：$x = 1$ 重复 20 次，$x = 100$ 重复 5 次。\n  - 边距参数 $\\epsilon = 0.01$。\n\n对于每个测试用例，拟合 OLS 模型，生成上述三个指标，并按以下顺序将所有结果聚合到一个列表中：\n$[\\text{A\\_zero\\_error}, \\text{A\\_frac\\_outside}, \\text{A\\_coverage}, \\text{B\\_zero\\_error}, \\text{B\\_frac\\_outside}, \\text{B\\_coverage}, \\text{C\\_zero\\_error}, \\text{C\\_frac\\_outside}, \\text{C\\_coverage}]$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，$[r_1,r_2,\\dots,r_9]$）。本问题不涉及物理单位或角度单位。所有输出必须是基本类型：布尔值和浮点数。计算过程必须是确定性的和自包含的，不需要用户输入或外部文件。", "solution": "此问题的目标是通过编程方式展示使用普通最小二乘法 (OLS) 线性回归进行二元分类任务的一个根本缺陷。具体来说，我们将展示即使数据是线性可分的，且 OLS 实现了零训练分类错误，其产生的实值预测也不适合作为概率分数。这是因为 OLS 对特征空间中数据点的位置很敏感，这一特性被称为杠杆效应 (leverage)。高杠杆点会扭曲回归拟合，产生的预测值可能远远超出 $[0,1]$ 区间，并将其他点的预测值压缩到决策边界附近，因此无法提供有意义的分类置信度度量。\n\n我们首先对问题进行形式化描述。对于一个包含 $n$ 个点 $(\\mathbf{x}_i, y_i)$ 的数据集，其中 $\\mathbf{x}_i \\in \\mathbb{R}^d$ 是特征向量，$y_i \\in \\{0, 1\\}$ 是二元标签，OLS 会找到一个线性函数 $f(\\mathbf{x}) = \\mathbf{w}^{\\top}\\mathbf{x} + b$，该函数最小化预测值与真实标签之间的平方误差和：\n$$\n\\mathcal{L}(\\mathbf{w}, b) = \\sum_{i=1}^{n} (y_i - f(\\mathbf{x}_i))^2 = \\sum_{i=1}^{n} (y_i - (\\mathbf{w}^{\\top}\\mathbf{x}_i + b))^2\n$$\n为了方便地处理截距项 $b$，我们通过在特征向量 $\\mathbf{x}_i$ 前面添加一个 1（或如问题所指定，在后面追加）来增强它。设特征矩阵为 $X \\in \\mathbb{R}^{n \\times d}$。我们构建一个增广设计矩阵 $X_{\\text{aug}} = [X \\,\\, \\mathbf{1}] \\in \\mathbb{R}^{n \\times (d+1)}$，其中 $\\mathbf{1}$ 是一个全为 1 的列向量。设 $\\boldsymbol{\\theta} = [\\mathbf{w}^{\\top} \\,\\, b]^{\\top} \\in \\mathbb{R}^{d+1}$ 为参数向量。OLS 的目标是找到 $\\boldsymbol{\\theta}$ 以最小化残差向量的平方 $L_2$ 范数，即 $\\|\\mathbf{y} - X_{\\text{aug}}\\boldsymbol{\\theta}\\|_2^2$。该解可以通过求解正规方程 $(X_{\\text{aug}}^{\\top}X_{\\text{aug}})\\boldsymbol{\\theta} = X_{\\text{aug}}^{\\top}\\mathbf{y}$ 来找到，或者更可靠地使用奇异值分解 (SVD) 等数值方法，这些方法已在标准科学计算库中实现。\n\n一旦找到最优的 $\\boldsymbol{\\theta}$，我们就可以为每个数据点获得回归预测值 $f(\\mathbf{x}_i)$。为了将这些值转换为类别标签，我们应用 $0.5$ 的阈值：\n$$\n\\hat{y}_i = \\mathbb{I}[f(\\mathbf{x}_i) \\geq 0.5]\n$$\n其中 $\\mathbb{I}[\\cdot]$ 是指示函数。\n\n我们将使用以下三个指标在三个合成的一维 ($d=1$) 数据集上评估 OLS 分类器：\n$1$. **零训练分类错误**：一个布尔值，指示分类错误率 $\\frac{1}{n}\\sum_{i=1}^{n} \\mathbb{I}[\\hat{y}_i \\neq y_i]$ 是否恰好为 $0$。这验证了 OLS 模型是否为训练数据找到了一个完美的分割超平面。\n$2$. **单位区间外的预测比例**：回归输出不在 $[0, 1]$ 范围内的数据点所占的比例，计算公式为 $\\frac{1}{n}\\sum_{i=1}^{n} \\mathbb{I}[f(\\mathbf{x}_i)  0 \\lor f(\\mathbf{x}_i) > 1]$。该指标直接量化了 OLS 未能产生类概率输出的失败程度。\n$3$. **弃权覆盖率**：预测值因接近理想概率值 0 或 1 而被视为“高置信度”的数据点所占的比例。对于给定的边距 $\\epsilon$，其计算公式为 $\\frac{1}{n}\\sum_{i=1}^{n} \\mathbb{I}\\big(\\min\\{|f(\\mathbf{x}_i) - 0|, |f(\\mathbf{x}_i) - 1|\\} \\leq \\epsilon\\big)$。该指标值较低表明大多数预测远离极值，意味着置信度低，并使得风险控制决策（即对低置信度预测弃权）变得困难。\n\n每个测试用例的算法流程如下：\n$1$. 根据测试用例的规范构建特征向量 $\\mathbf{x}$ 和标签向量 $\\mathbf{y}$。\n$2$. 通过取列向量 $\\mathbf{x}$ 并附加一列全为 1 的向量来创建设计矩阵 $X_{\\text{aug}}$。\n$3$. 使用最小二乘求解器求解线性系统 $X_{\\text{aug}}\\boldsymbol{\\theta} \\approx \\mathbf{y}$，以计算 OLS 参数向量 $\\boldsymbol{\\theta} = [w, b]^{\\top}$。\n$4$. 计算所有数据点的回归预测值：$\\mathbf{f} = X_{\\text{aug}}\\boldsymbol{\\theta}$。\n$5$. 使用预测向量 $\\mathbf{f}$、真实标签 $\\mathbf{y}$ 和指定的边距 $\\epsilon$，计算所需的三个指标。\n\n这些测试用例旨在说明高杠杆点的影响。测试用例 A 提供了一个基准，其数据表现良好且中等可分。测试用例 B 和 C 在特征空间中引入了离群点（$x=-100$ 和 $x=100$）。由于 OLS 最小化平方误差，这些离群点对回归线产生强烈影响（高杠杆效应）。为了最小化与这些点相关的大误差，OLS 将拟合一条斜率远小于仅针对内点数据所选斜率的直线。回归线的这种“扁平化”导致了两种效应：($i$) 为了满足损失函数，离群点的预测值被推向极端值（通常在 $[0,1]$ 之外），以及 ($ii$) 数量更多的内点的预测值被压缩到决策边界 ($0.5$) 附近，导致大多数数据的置信度分数较低。这种行为与逻辑回归等模型形成鲜明对比，后者专为分类设计，并且对此类离群点更为稳健。程序将精确计算这些效应。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef process_case(x_data, y_data, epsilon):\n    \"\"\"\n    Fits an OLS model and computes the three specified metrics for a given dataset.\n\n    Args:\n        x_data (np.ndarray): 1D feature data.\n        y_data (np.ndarray): Binary labels (0 or 1).\n        epsilon (float): Margin for the abstention coverage metric.\n    \n    Returns:\n        tuple: A tuple containing the three metrics:\n               (zero_error, frac_outside, coverage).\n    \"\"\"\n    # Reshape x_data to be a column vector for the design matrix\n    X_mat = x_data.reshape(-1, 1)\n    \n    # Construct the augmented design matrix with an intercept column of ones.\n    # X_aug = [X, 1], so the model is f(x) = w*x + b\n    X_aug = np.hstack([X_mat, np.ones((x_data.shape[0], 1))])\n    \n    # Solve for the OLS parameters theta = [w, b]^T using np.linalg.lstsq.\n    # This provides a numerically stable solution to the normal equations.\n    theta, _, _, _ = np.linalg.lstsq(X_aug, y_data, rcond=None)\n    \n    # Calculate the continuous regression predictions f(x_i)\n    y_pred_reg = X_aug @ theta\n    \n    # --- Metric 1: Zero training misclassification ---\n    # Classify by thresholding regression outputs at 0.5\n    y_pred_class = (y_pred_reg >= 0.5).astype(int)\n    # The rate is the mean of the indicator I[y_pred != y_true]\n    misclassification_rate = np.mean(y_pred_class != y_data)\n    zero_error = (misclassification_rate == 0.0)\n    \n    # --- Metric 2: Fraction of predictions outside the unit interval [0, 1] ---\n    frac_outside = np.mean((y_pred_reg  0) | (y_pred_reg > 1))\n    \n    # --- Metric 3: Abstention coverage at margin epsilon ---\n    # This is the fraction of points where the prediction is within epsilon of 0 or 1.\n    # The metric is min(|f(x)-0|, |f(x)-1|) = epsilon\n    dist_to_extremes = np.minimum(np.abs(y_pred_reg - 0.0), np.abs(y_pred_reg - 1.0))\n    coverage = np.mean(dist_to_extremes = epsilon)\n    \n    return zero_error, frac_outside, coverage\n\n\ndef solve():\n    \"\"\"\n    Constructs datasets, runs OLS, computes metrics, and prints the final result.\n    \"\"\"\n    # The final list to be populated with 9 results.\n    all_results = []\n    \n    # --- Test Case A (balanced, moderate separation) ---\n    x_neg_A = np.repeat([-3.0, -2.0, -1.0], 10)\n    x_pos_A = np.repeat([1.0, 2.0, 3.0], 10)\n    x_A = np.concatenate([x_neg_A, x_pos_A])\n    y_A = np.concatenate([np.zeros(len(x_neg_A)), np.ones(len(x_pos_A))])\n    epsilon_A = 0.1\n    results_A = process_case(x_A, y_A, epsilon_A)\n    all_results.extend(results_A)\n\n    # --- Test Case B (balanced with large-magnitude outliers) ---\n    x_neg_B = np.concatenate([np.full(20, -1.0), np.full(5, -100.0)])\n    x_pos_B = np.concatenate([np.full(20, 1.0), np.full(5, 100.0)])\n    x_B = np.concatenate([x_neg_B, x_pos_B])\n    y_B = np.concatenate([np.zeros(len(x_neg_B)), np.ones(len(x_pos_B))])\n    epsilon_B = 0.05\n    results_B = process_case(x_B, y_B, epsilon_B)\n    all_results.extend(results_B)\n\n    # --- Test Case C (same as B, stricter margin) ---\n    # Data is identical to Test Case B\n    x_C, y_C = x_B, y_B\n    epsilon_C = 0.01\n    results_C = process_case(x_C, y_C, epsilon_C)\n    all_results.extend(results_C)\n    \n    # Final print statement in the exact required format.\n    # `map(str, ...)` converts boolean `True`/`False` and floats to strings.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "3117088"}, {"introduction": "我们已经通过实践看到了线性回归的各种缺点，现在让我们从决策制定的角度，来形式化地分析为什么使用来自线性回归的未校准分数是有问题的。本练习要求您从第一性原理出发，在考虑错分成本和回归分数潜在分布的情况下，推导出最优决策阈值。推导出的公式将揭示，对于一个 OLS 分数，其最优阈值依赖于许多未知的数据分布参数，这使得在实践中难以设定，这与那些输出已校准概率的模型（如逻辑回归）形成了鲜明对比，也为反对在涉及风险评估的分类任务中使用 OLS 提供了有力的理论依据 [@problem_id:3117097]。", "problem": "考虑一个二分类问题，其类别标签为 $Y \\in \\{0,1\\}$，先验概率为 $\\pi_{1} = \\mathbb{P}(Y=1)$ 和 $\\pi_{0} = 1 - \\pi_{1}$。一个通过普通最小二乘法（OLS）训练的线性回归模型产生一个实值分数 $S \\in \\mathbb{R}$，该分数通过阈值法用于分类：如果 $S \\ge t$，则预测 $\\hat{Y} = 1$，否则预测 $\\hat{Y} = 0$。错误分类会产生由以下成本结构指定的成本：假阳性（当 $Y=0$ 时预测为 $1$）产生的成本为 $c_{01} > 0$，假阴性（当 $Y=1$ 时预测为 $0$）产生的成本为 $c_{10} > 0$，而正确预测的成本为零。假设在给定类别的情况下，OLS 分数具有以下共享方差的高斯类条件分布：$S \\mid (Y=1) \\sim \\mathcal{N}(\\mu_{1}, \\sigma^{2})$ 和 $S \\mid (Y=0) \\sim \\mathcal{N}(\\mu_{0}, \\sigma^{2})$，其中 $\\mu_{1} > \\mu_{0}$ 且 $\\sigma > 0$。将分数 $S$ 视为由这些分布给出（也就是说，不假设 $S$ 等于一个经过校准的概率）。在这些假设下，通过最小化关于阈值 $t$ 的期望错误分类成本，推导出一个用 $\\mu_{0}$、$\\mu_{1}$、$\\sigma$、$\\pi_{0}$、$\\pi_{1}$、$c_{01}$ 和 $c_{10}$ 表示的成本最小化阈值 $t^{\\star}$ 的闭式表达式。然后，简要解释为什么与输出经过校准的后验概率的方法相比，这个结果凸显了使用普通最小二乘法进行分类的一个缺点。你的最终答案应该是 $t^{\\star}$ 的单一闭式解析表达式，无需进行数值计算。", "solution": "我们从 Bayes 风险最小化原理开始。对于一个固定的阈值 $t$，分类规则是如果 $S \\ge t$ 则预测 $\\hat{Y}=1$，否则预测 $\\hat{Y}=0$。在此规则下的期望错误分类成本（风险）为\n$$\nR(t) \\equiv \\mathbb{E}[\\text{cost}] \n= c_{10}\\,\\mathbb{P}(\\hat{Y}=0, Y=1) \\;+\\; c_{01}\\,\\mathbb{P}(\\hat{Y}=1, Y=0).\n$$\n在阈值规则下，$\\{\\hat{Y}=0\\}$ 是事件 $\\{S  t\\}$，而 $\\{\\hat{Y}=1\\}$ 是事件 $\\{S \\ge t\\}$。因此，期望成本可以根据条件概率重写：\n$$ R(t) = c_{10}\\,\\mathbb{P}(S  t \\mid Y=1)\\,\\pi_1 \\;+\\; c_{01}\\,\\mathbb{P}(S \\ge t \\mid Y=0)\\,\\pi_0 $$\n为了找到最小化 $R(t)$ 的 $t$，我们对 $t$ 求导并令其为零。利用莱布尼茨法则，这产生了最优性条件：$c_{10}\\,\\pi_1\\,p(t|Y=1) = c_{01}\\,\\pi_0\\,p(t|Y=0)$，其中 $p(\\cdot|Y=k)$ 是类条件概率密度函数。将高斯密度函数代入并求解 $t$ 便可得到最终的表达式。", "answer": "$$\\boxed{\\frac{\\mu_{1}+\\mu_{0}}{2}+\\frac{\\sigma^{2}}{\\mu_{1}-\\mu_{0}}\\,\\ln\\!\\left(\\frac{c_{01}\\,\\pi_{0}}{c_{10}\\,\\pi_{1}}\\right)}$$", "id": "3117097"}]}