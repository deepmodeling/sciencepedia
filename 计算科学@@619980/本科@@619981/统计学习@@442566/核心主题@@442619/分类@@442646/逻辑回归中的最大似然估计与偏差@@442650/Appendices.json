{"hands_on_practices": [{"introduction": "偏差 (Deviance) 是衡量逻辑回归模型拟合优度的核心指标。本练习将揭开其神秘面纱，向你展示如何将总体偏差分解为来自每个数据点的单独“误差”贡献。这种逐点分析的视角，将偏差从一个抽象的数字，转变为一种强大的诊断工具，帮助我们识别对模型影响最大或拟合最差的观测点 [@problem_id:3147524]。", "problem": "考虑一个通过最大似然估计（MLE）拟合的二元响应逻辑斯谛回归模型。设观测响应为 $\\{y_{i}\\}_{i=1}^{n}$，其中 $y_{i}\\in\\{0,1\\}$，拟合概率为 $\\{\\hat{p}_{i}\\}_{i=1}^{n}$，其中每个 $y_{i}$ 被建模为条件独立的 $\\operatorname{Bernoulli}(\\hat{p}_{i})$ 分布。从伯努利对数似然的定义以及偏差（deviance）的定义（饱和模型对数似然与拟合模型对数似然之差的两倍）出发。仅使用这些定义，推导出一个表达式，表明偏差是各观测特定项的总和。然后，使用您推导的表达式，计算以下八个观测值的总偏差：\n$$\n\\begin{aligned}\ny_{1}=1,\\ \\hat{p}_{1}=0.84;\\quad y_{2}=0,\\ \\hat{p}_{2}=0.15;\\quad y_{3}=1,\\ \\hat{p}_{3}=0.62;\\\\\ny_{4}=0,\\ \\hat{p}_{4}=0.80;\\quad y_{5}=1,\\ \\hat{p}_{5}=0.30;\\quad y_{6}=0,\\ \\hat{p}_{6}=0.25;\\\\\ny_{7}=1,\\ \\hat{p}_{7}=0.95;\\quad y_{8}=0,\\ \\hat{p}_{8}=0.55.\n\\end{aligned}\n$$\n最后，设计一个诊断规则，用于标记具有最大逐点偏差贡献的观测值，确保最多标记 $k=2$ 个观测值，并将其应用于上述数据以确定哪些索引将被标记。将总偏差的最终数值四舍五入到四位有效数字。不涉及物理单位，最终数值答案必须是单个实数。", "solution": "该问题陈述经评估有效。它在科学上基于统计学习的原理，特别是关于逻辑斯谛回归和拟合优度度量。该问题是适定的，提供了所有必要的数据和定义来推导所需的表达式、计算数值结果并应用诊断规则。没有矛盾、歧义或事实错误。\n\n我们首先推导二元逻辑斯谛回归模型中偏差的一般表达式。问题陈述指出，偏差 $D$ 定义为饱和模型的对数似然 $\\ell_{sat}$ 与拟合模型的对数似然 $\\ell_{fit}$ 之差的两倍：\n$$\nD = 2(\\ell_{sat} - \\ell_{fit})\n$$\n观测值 $\\{y_i\\}_{i=1}^n$ 被建模为独立的伯努利试验，其中 $y_i \\in \\{0, 1\\}$。单个观测值 $Y_i$（参数为 $p_i$）的概率质量函数是 $P(Y_i=y_i) = p_i^{y_i}(1-p_i)^{1-y_i}$。因此，单个观测值的对数似然为 $\\ln(P(Y_i=y_i)) = y_i \\ln(p_i) + (1-y_i) \\ln(1-p_i)$。\n\n首先，我们确定拟合模型的对数似然 $\\ell_{fit}$。这是通过使用拟合概率 $\\{\\hat{p}_i\\}_{i=1}^n$ 对各个对数似然求和得到的：\n$$\n\\ell_{fit} = \\sum_{i=1}^{n} \\left[ y_i \\ln(\\hat{p}_i) + (1 - y_i) \\ln(1 - \\hat{p}_i) \\right]\n$$\n接下来，我们确定饱和模型的对数似然 $\\ell_{sat}$。饱和模型是能够完美拟合数据的模型。对于一个伯努利观测值 $y_i$，如果模型的概率等于其结果，就实现了完美拟合。也就是说，饱和模型的概率参数 $p_i^{sat}$ 等于 $y_i$。\n$$\np_i^{sat} = y_i\n$$\n因此，饱和模型的对数似然为：\n$$\n\\ell_{sat} = \\sum_{i=1}^{n} \\left[ y_i \\ln(p_i^{sat}) + (1 - y_i) \\ln(1 - p_i^{sat}) \\right] = \\sum_{i=1}^{n} \\left[ y_i \\ln(y_i) + (1 - y_i) \\ln(1 - y_i) \\right]\n$$\n我们必须计算这个和中的各项。\n- 如果 $y_i = 1$，则该项为 $1 \\ln(1) + (1-1) \\ln(1-1) = \\ln(1) + 0 \\ln(0) = 0$。\n- 如果 $y_i = 0$，则该项为 $0 \\ln(0) + (1-0) \\ln(1-0) = 0 \\ln(0) + \\ln(1) = 0$。\n在这两种情况下，我们都利用了 $\\lim_{x\\to 0^+} x \\ln(x) = 0$ 这一事实。因此，$\\ell_{sat}$ 求和中的每一项都为零，这意味着饱和模型的总对数似然为零：\n$$\n\\ell_{sat} = 0\n$$\n将 $\\ell_{sat}$ 和 $\\ell_{fit}$ 的表达式代入偏差的定义中，得到：\n$$\nD = 2 \\left( 0 - \\sum_{i=1}^{n} \\left[ y_i \\ln(\\hat{p}_i) + (1-y_i) \\ln(1-\\hat{p}_i) \\right] \\right)\n$$\n$$\nD = -2 \\sum_{i=1}^{n} \\left[ y_i \\ln(\\hat{p}_i) + (1 - y_i) \\ln(1 - \\hat{p}_i) \\right]\n$$\n这个表达式表明偏差是各观测特定项的总和。第 $i$ 个观测值对总偏差的贡献，我们可以称之为逐点偏差 $d_i$，是：\n$$\nd_i = -2 \\left[ y_i \\ln(\\hat{p}_i) + (1 - y_i) \\ln(1 - \\hat{p}_i) \\right]\n$$\n这个表达式根据 $y_i$ 的值可以简化为：\n- 如果 $y_i=1$，则 $d_i = -2 \\ln(\\hat{p}_i)$。\n- 如果 $y_i=0$，则 $d_i = -2 \\ln(1-\\hat{p}_i)$。\n\n现在，我们通过计算每个 $d_i$ 并将它们相加来计算给定的 $n=8$ 个观测值的总偏差。\n$d_1$：对于 $y_1=1, \\hat{p}_1=0.84$， $d_1 = -2 \\ln(0.84) \\approx 0.34870$\n$d_2$：对于 $y_2=0, \\hat{p}_2=0.15$， $d_2 = -2 \\ln(1-0.15) = -2 \\ln(0.85) \\approx 0.32504$\n$d_3$：对于 $y_3=1, \\hat{p}_3=0.62$， $d_3 = -2 \\ln(0.62) \\approx 0.95607$\n$d_4$：对于 $y_4=0, \\hat{p}_4=0.80$， $d_4 = -2 \\ln(1-0.80) = -2 \\ln(0.20) \\approx 3.21888$\n$d_5$：对于 $y_5=1, \\hat{p}_5=0.30$， $d_5 = -2 \\ln(0.30) \\approx 2.40795$\n$d_6$：对于 $y_6=0, \\hat{p}_6=0.25$， $d_6 = -2 \\ln(1-0.25) = -2 \\ln(0.75) \\approx 0.57536$\n$d_7$：对于 $y_7=1, \\hat{p}_7=0.95$， $d_7 = -2 \\ln(0.95) \\approx 0.10258$\n$d_8$：对于 $y_8=0, \\hat{p}_8=0.55$， $d_8 = -2 \\ln(1-0.55) = -2 \\ln(0.45) \\approx 1.59702$\n\n总偏差是各项之和 $D = \\sum_{i=1}^{8} d_i$：\n$$\nD \\approx 0.34870 + 0.32504 + 0.95607 + 3.21888 + 2.40795 + 0.57536 + 0.10258 + 1.59702\n$$\n$$\nD \\approx 9.53160\n$$\n四舍五入到四位有效数字，总偏差为 $9.532$。\n\n最后，我们设计并应用诊断规则。该规则是标记具有最大逐点偏差贡献的观测值，最多标记 $k=2$ 个。这需要将各个偏差贡献 $d_i$ 按降序排列，并选择前两个。\n计算出的逐点偏差为：\n$d_4 \\approx 3.21888$\n$d_5 \\approx 2.40795$\n$d_8 \\approx 1.59702$\n$d_3 \\approx 0.95607$\n$d_6 \\approx 0.57536$\n$d_1 \\approx 0.34870$\n$d_2 \\approx 0.32504$\n$d_7 \\approx 0.10258$\n\n最大的两个值是 $d_4$ 和 $d_5$。它们对应于索引为 $4$ 和 $5$ 的观测值。因此，该诊断规则将标记观测值 $y_4$ 和 $y_5$。这些大的偏差贡献之所以产生，是因为模型为一个观测到的失败（$y_4=0$）赋予了高的成功概率（$\\hat{p}_4=0.80$），并为一个观测到的成功（$y_5=1$）赋予了低的成功概率（$\\hat{p}_5=0.30$）。\n\n所要求的最终数值答案是四舍五入到四位有效数字的总偏差。", "answer": "$$\n\\boxed{9.532}\n$$", "id": "3147524"}, {"introduction": "在评估分类模型时，区分模型的概率预测质量和基于这些概率的分类决策至关重要。本练习通过一个具体案例阐明，偏差评估的是模型预测概率本身的准确性，它独立于任何分类阈值的选择。相比之下，诸如错分率之类的指标则完全依赖于所选的阈值，改变阈值会直接影响决策结果，但不会改变模型本身的拟合优度 [@problem_id:3147489]。", "problem": "考虑一个由逻辑回归建模的二元结果场景，其中对于每个观测值 $i \\in \\{1,2,\\dots,n\\}$ 及其特征 $\\mathbf{x}_i$，模型生成一个拟合概率 $p_i \\in (0,1)$ 表示 $Y_i=1$。参数 $\\boldsymbol{\\beta}$ 的 Bernoulli 似然 $L(\\boldsymbol{\\beta})$ 定义为模型下观测数据的概率，其对数似然为 $\\log L(\\boldsymbol{\\beta})$。残差偏离度定义为拟合模型与饱和模型似然比的对数的 $-2$ 倍，其中饱和模型是能完美拟合观测数据的模型。决策规则使用一个阈值 $t \\in (0,1)$ 将每个拟合概率 $p_i$ 映射到一个预测类别 $\\hat{y}_i(t) \\in \\{0,1\\}$，其中如果 $p_i \\ge t$，则 $\\hat{y}_i(t)=1$，否则 $\\hat{y}_i(t)=0$。\n\n给定 $n=6$ 个观测值，其观测结果和来自单次逻辑回归拟合的拟合概率如下：\n- $y = (y_1,y_2,y_3,y_4,y_5,y_6) = (1,1,0,1,0,0)$，\n- $p = (p_1,p_2,p_3,p_4,p_5,p_6) = (0.85,0.55,0.29,0.31,0.25,0.05)$。\n\n考虑两个决策阈值 $t_1=0.50$ 和 $t_2=0.30$。\n\n下列哪些陈述是正确的？\n\nA. 改变决策阈值不影响此固定逻辑回归拟合的残差偏离度；对于上述数据，根据拟合概率计算出的残差偏离度约为 $5.23$，无论使用 $t=0.50$ 还是 $t=0.30$ 进行类别决策，该值都保持不变。\n\nB. 在 $t=0.50$ 下，误分类计数为 $1$，而在 $t=0.30$ 下，误分类计数为 $0$。\n\nC. 对于任何固定的阈值 $t$，最小化误分类计数等同于最大化逻辑回归的 Bernoulli 似然（从而最小化偏离度）。\n\nD. 当误分类成本非对称时，最优决策规则使用的阈值 $t^{\\ast}$ 取决于成本比率，而最大似然估计 (MLE) 拟合及其偏离度保持与阈值无关；因此，通过偏离度进行模型评估和通过阈值化进行策略决策是可分离的。\n\nE. 降低阈值必然会减少偏离度，因为它使更多的正向预测与真阳性对齐。\n\n选择所有适用的选项。", "solution": "用户要求对问题陈述进行严格验证，然后通过详细的解决方案推导出正确答案并评估每个选项。\n\n### 问题验证\n\n**第 1 步：提取已知条件**\n- 模型：用于二元结果 $Y_i \\in \\{0, 1\\}$ 的逻辑回归。\n- 对于每个观测值 $i \\in \\{1, 2, \\dots, n\\}$，模型生成一个拟合概率 $p_i = P(Y_i=1 | \\mathbf{x}_i)$。\n- 残差偏离度定义为拟合模型与饱和模型似然比的对数的 $-2$ 倍。饱和模型能完美拟合数据。\n- 决策规则：对于阈值 $t \\in (0,1)$，如果 $p_i \\ge t$，则预测类别为 $\\hat{y}_i(t) = 1$；如果 $p_i < t$，则预测类别为 $\\hat{y}_i(t) = 0$。\n- 样本量：$n = 6$。\n- 观测结果：$y = (y_1, y_2, y_3, y_4, y_5, y_6) = (1, 1, 0, 1, 0, 0)$。\n- 拟合概率：$p = (p_1, p_2, p_3, p_4, p_5, p_6) = (0.85, 0.55, 0.29, 0.31, 0.25, 0.05)$。\n- 待考虑的决策阈值：$t_1 = 0.50$ 和 $t_2 = 0.30$。\n\n**第 2 步：使用提取的已知条件进行验证**\n- **科学依据：** 该问题基于统计学习的标准理论，特别是逻辑回归、最大似然估计、偏离度和分类阈值。所有提供的定义都是标准的。\n- **定义明确：** 该问题提供了评估陈述所需的所有数据（$y$, $p$, $t_1$, $t_2$）和清晰的定义。可以进行唯一的分析。\n- **客观性：** 语言正式且无歧义。问题涉及可验证的数学和统计属性。\n- **缺陷检查：** 问题陈述没有列出的缺陷。\n    - 它不违反任何科学原则。数据点 $(y_4=1, p_4=0.31)$ 中，模型为一个已发生的事件分配了较低的概率，这代表了模型误差，是统计建模中的现实特征。\n    - 这是一个其领域内的正式问题。\n    - 设置完整且一致。\n    - 数据对于一个小样本问题是合理的。\n\n**第 3 步：结论与行动**\n问题陈述有效。我将继续进行解题和逐项分析。\n\n---\n\n### 解题推导\n\n问题的核心在于区分模型的拟合优度（由似然和偏离度衡量）和其分类性能（由误分类计数等依赖于所选决策阈值的指标衡量）。\n\n对于一组 $n$ 个独立观测值，逻辑回归模型的对数似然是：\n$$ \\ell(\\boldsymbol{\\beta}) = \\sum_{i=1}^n \\left[ y_i \\log(p_i) + (1-y_i) \\log(1-p_i) \\right] $$\n其中 $p_i$ 是拟合概率，是模型参数 $\\boldsymbol{\\beta}$ 的函数。\n\n饱和模型是一个假设的模型，它能完美拟合数据，意味着其对数似然为 $0$。拟合模型的残差偏离度定义为：\n$$ D = -2 \\times (\\ell(\\text{拟合模型}) - \\ell(\\text{饱和模型})) = -2 \\ell(\\text{拟合模型}) $$\n$$ D = -2 \\sum_{i=1}^n \\left[ y_i \\log(p_i) + (1-y_i) \\log(1-p_i) \\right] $$\n关键在于，偏离度 $D$ 仅依赖于真实结果 $y_i$ 和拟合概率 $p_i$。它不依赖于任何决策阈值 $t$。\n\n### 逐项分析\n\n**A. 改变决策阈值不影响此固定逻辑回归拟合的残差偏离度；对于上述数据，根据拟合概率计算出的残差偏离度约为 $5.23$，无论使用 $t=0.50$ 还是 $t=0.30$ 进行类别决策，该值都保持不变。**\n\n陈述的第一部分“改变决策阈值不影响残差偏离度”根据定义是正确的。偏离度是基于最大似然估计 (MLE) 过程产生的概率 $p_i$ 的拟合度量，该过程不涉及阈值。阈值是作为一个独立的后续步骤应用于类别预测。\n\n我们来验证计算。\n给定 $y = (1, 1, 0, 1, 0, 0)$ 和 $p = (0.85, 0.55, 0.29, 0.31, 0.25, 0.05)$。\n对数似然为：\n$$ \\ell = \\log(0.85) + \\log(0.55) + \\log(1-0.29) + \\log(0.31) + \\log(1-0.25) + \\log(1-0.05) $$\n$$ \\ell = \\log(0.85) + \\log(0.55) + \\log(0.71) + \\log(0.31) + \\log(0.75) + \\log(0.95) $$\n使用自然对数：\n$$ \\ell \\approx -0.162519 - 0.597837 - 0.342490 - 1.171182 - 0.287682 - 0.051293 \\approx -2.613003 $$\n偏离度为 $D = -2 \\times \\ell$:\n$$ D \\approx -2 \\times (-2.613003) \\approx 5.226006 $$\n该值约为 $5.23$。概念性主张和计算都是正确的。\n\n结论：**正确**。\n\n**B. 在 $t=0.50$ 下，误分类计数为 $1$，而在 $t=0.30$ 下，误分类计数为 $0$。**\n\n我们来计算每个阈值下的预测类别 $\\hat{y}$，并与真实结果 $y = (1, 1, 0, 1, 0, 0)$ 进行比较。拟合概率为 $p = (0.85, 0.55, 0.29, 0.31, 0.25, 0.05)$。\n\n- 对于阈值 $t_1 = 0.50$：\n规则是如果 $p_i \\ge 0.50$，则 $\\hat{y}_i = 1$。\n$p_1=0.85 \\ge 0.50 \\implies \\hat{y}_1=1$ (正确, $y_1=1$)\n$p_2=0.55 \\ge 0.50 \\implies \\hat{y}_2=1$ (正确, $y_2=1$)\n$p_3=0.29 < 0.50 \\implies \\hat{y}_3=0$ (正确, $y_3=0$)\n$p_4=0.31 < 0.50 \\implies \\hat{y}_4=0$ (错误, $y_4=1$)\n$p_5=0.25 < 0.50 \\implies \\hat{y}_5=0$ (正确, $y_5=0$)\n$p_6=0.05 < 0.50 \\implies \\hat{y}_6=0$ (正确, $y_6=0$)\n预测向量为 $\\hat{y}(0.50) = (1, 1, 0, 0, 0, 0)$。在索引 $4$ 处有一个不匹配。误分类计数为 $1$。\n\n- 对于阈值 $t_2 = 0.30$：\n规则是如果 $p_i \\ge 0.30$，则 $\\hat{y}_i = 1$。\n$p_1=0.85 \\ge 0.30 \\implies \\hat{y}_1=1$ (正确, $y_1=1$)\n$p_2=0.55 \\ge 0.30 \\implies \\hat{y}_2=1$ (正确, $y_2=1$)\n$p_3=0.29 < 0.30 \\implies \\hat{y}_3=0$ (正确, $y_3=0$)\n$p_4=0.31 \\ge 0.30 \\implies \\hat{y}_4=1$ (正确, $y_4=1$)\n$p_5=0.25 < 0.30 \\implies \\hat{y}_5=0$ (正确, $y_5=0$)\n$p_6=0.05 < 0.30 \\implies \\hat{y}_6=0$ (正确, $y_6=0$)\n预测向量为 $\\hat{y}(0.30) = (1, 1, 0, 1, 0, 0)$。这与真实结果向量 $y$ 完全相同。误分类计数为 $0$。\n\n该陈述是对两个计算的事实报告，两者都是正确的。\n\n结论：**正确**。\n\n**C. 对于任何固定的阈值 $t$，最小化误分类计数等同于最大化逻辑回归的 Bernoulli 似然（从而最小化偏离度）。**\n\n这个陈述从根本上是错误的。它混淆了两个不同的目标函数。\n1.  **最大化似然（最小化偏离度）：** 逻辑回归的 MLE 的目标是找到参数 $\\boldsymbol{\\beta}$ 以最大化对数似然 $\\sum [y_i \\log(p_i) + (1-y_i) \\log(1-p_i)]$。这是关于概率 $p_i$（以及 $\\boldsymbol{\\beta}$）的连续可微函数。它提供了一种“软”拟合度量，对置信度高的正确预测的奖励多于勉强正确的预测。这个优化过程不涉及阈值 $t$。\n2.  **最小化误分类计数：** 这个目标函数 $\\sum I(y_i \\neq \\hat{y}_i(t))$ 是一个离散的、不可微的“硬”错误计数，它依赖于一个预先指定的阈值 $t$。\n通常情况下，最大化似然并不会得到与在给定 $t$ 下最小化误分类计数相同的解。本题中的数据本身就证明了这一点：MLE 拟合是固定的，但随着阈值的改变，误分类计数从 $1$ 变为 $0$。\n\n结论：**错误**。\n\n**D. 当误分类成本非对称时，最优决策规则使用的阈值 $t^{\\ast}$ 取决于成本比率，而最大似然估计 (MLE) 拟合及其偏离度保持与阈值无关；因此，通过偏离度进行模型评估和通过阈值化进行策略决策是可分离的。**\n\n这个陈述准确地描述了统计决策理论的一个关键原则。\n- **非对称成本下的最优阈值：** 设 $C_{10}$ 是假阳性（真实为 $0$ 预测为 $1$）的成本，$C_{01}$ 是假阴性（真实为 $1$ 预测为 $0$）的成本。为了最小化一个概率为 $p_i$ 的观测值的期望成本，当预测为 $1$ 的期望成本低于预测为 $0$ 的期望成本时，应预测为 $1$：$(1-p_i)C_{10} < p_iC_{01}$。这个不等式可以重新排列为 $p_i > \\frac{C_{10}}{C_{10} + C_{01}}$。最优阈值是 $t^{\\ast} = \\frac{C_{10}}{C_{10} + C_{01}}$，这显然取决于成本。\n- **MLE/偏离度的阈值无关性：** 如选项 A 的分析所确立，MLE 过程通过最大化似然函数来确定概率 $p_i$。这个过程独立于这些概率的任何后续使用，包括使用非对称成本进行分类。偏离度仅仅是这个最大化似然的一个变换。\n- **可分离性：** 结论是正确的。构建概率模型（MLE 拟合）的任务与使用该模型做出决策（通过阈值化进行策略决策）的任务是分开的。模型提供概率，而决策规则将成本和阈值应用于这些概率。这种分离是根本性的。\n\n结论：**正确**。\n\n**E. 降低阈值必然会减少偏离度，因为它使更多的正向预测与真阳性对齐。**\n\n这个陈述在两个层面上都是错误的。\n- 前提“降低阈值必然会减少偏离度”是错误的。如前所述，一个拟合模型的偏离度是一个固定值，不依赖于决策阈值。\n- 理由“因为它使更多的正向预测与真阳性对齐”描述的是一个分类指标（如真阳性率或灵敏度）的变化，而不是模型偏离度的变化。虽然降低阈值确实会增加正向预测的数量，从而可能增加真阳性的数量，但它对偏离度没有影响。该陈述混淆了分类性能结果与基于似然的拟合优度度量。\n\n结论：**错误**。", "answer": "$$\\boxed{ABD}$$", "id": "3147489"}, {"introduction": "偏差不仅能评估单个模型，更是正式比较不同模型的有力工具。本练习将引导你探究著名的辛普森悖论 (Simpson’s paradox)，通过比较整合模型 (pooled model) 与分组模型 (subgroup-specific model) 的偏差，你将学会如何利用偏差下降 (deviance drop) 来为更复杂的模型提供统计支持，并揭示简单模型可能掩盖的混杂效应 [@problem_id:3147557]。", "problem": "给定一个使用逻辑回归建模的二元结果分类情景。结果变量为 $y \\in \\{0,1\\}$，预测变量为一个二元处理指标 $x \\in \\{0,1\\}$，还有一个二元亚组指标 $g \\in \\{A,B\\}$。统计学习的目标是比较一个忽略亚组成员身份的合并逻辑回归模型与一对在每个亚组内独立拟合的亚组特异性逻辑回归模型。该比较使用最大似然估计（MLE）下的偏差（deviance）进行，从伯努利似然和逻辑联结函数的定义出发。您的任务是从第一性原理出发，推导、实现并计算以下内容，而不依赖于预先推导出的快捷公式：\n\n- 通过直接优化逻辑联结函数下的伯努利对数似然来实现逻辑回归的 MLE，使用一种基于对数似然对参数求导得出的、有原则的迭代方法。\n- 根据基本定义来定义和计算已拟合逻辑回归模型的偏差，其中饱和模型为每个观测值精确赋了 $y_i$ 值，而拟合模型使用从 MLE 得到的估计概率。\n- 对于合并模型，仅使用一个截距和单一预测变量 $x$（即忽略亚组 $g$）对整个数据集拟合一个逻辑回归模型。\n- 对于亚组特异性模型，拟合两个独立的逻辑回归模型：一个在亚组 $A$ 内，另一个在亚组 $B$ 内，每个模型都使用一个截距和单一预测变量 $x$。总的亚组特异性对数似然是两个亚组对数似然之和，相应的偏差由此组合对数似然计算得出。\n- 计算偏差下降值，定义为合并模型偏差减去亚组特异性模型偏差。正的偏差下降值表示亚组特异性建模比合并建模产生更低的偏差（更好的拟合效果）。\n\n使用以下数据集测试套件，这些数据集以计数形式表示，需要扩展为单个观测值。每个数据集为每个亚组 $g \\in \\{A,B\\}$ 和处理水平 $x \\in \\{0,1\\}$ 指定了观测总数和成功次数。您必须根据这些计数构建与之一致的个体二元结果 $y$ 以及相应的 $x$ 和 $g$ 标签。这些数据集旨在探究辛普森悖论（Simpson’s paradox）的存在与否，并检验典型和边缘情况下的行为。\n\n- 测试用例 1（强辛普森悖论：由于亚组的混杂作用，处理在亚组内有益，但在合并时有害）：\n  - 亚组 $A$：\n    - $x=0$：总数 $80$，成功 $56$。\n    - $x=1$：总数 $20$，成功 $16$。\n  - 亚组 $B$：\n    - $x=0$：总数 $20$，成功 $2$。\n    - $x=1$：总数 $80$，成功 $16$。\n- 测试用例 2（平衡分配，处理在亚组内和总体上均有益）：\n  - 亚组 $A$：\n    - $x=0$：总数 $50$，成功 $35$。\n    - $x=1$：总数 $50$，成功 $40$。\n  - 亚组 $B$：\n    - $x=0$：总数 $50$，成功 $5$。\n    - $x=1$：总数 $50$，成功 $10$。\n- 测试用例 3（边缘情况：无处理效应且无亚组差异；合并拟合与亚组特异性拟合应相似）：\n  - 亚组 $A$：\n    - $x=0$：总数 $40$，成功 $20$。\n    - $x=1$：总数 $40$，成功 $20$。\n  - 亚组 $B$：\n    - $x=0$：总数 $40$，成功 $20$。\n    - $x=1$：总数 $40$，成功 $20$。\n\n您的程序必须：\n- 对每个测试用例，构建与指定计数一致的个体级别数据集。\n- 拟合参数为 $(\\beta_0, \\beta_1)$ 的合并逻辑回归模型，其中 $\\beta_0$ 是截距，$\\beta_1$ 与 $x$ 相乘。\n- 拟合两个亚组特异性逻辑回归模型：\n  - 对亚组 $A$，仅使用 $g=A$ 的数据拟合 $(\\beta_{0A}, \\beta_{1A})$。\n  - 对亚组 $B$，仅使用 $g=B$ 的数据拟合 $(\\beta_{0B}, \\beta_{1B})$。\n- 计算合并偏差和亚组特异性偏差（每个都从伯努利似然和饱和模型定义），并报告每种情况下的偏差下降值（合并偏差减去亚组特异性偏差）。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含三个测试用例的偏差下降值，格式为方括号内的逗号分隔列表，例如 $[d_1,d_2,d_3]$，其中每个 $d_i$ 是一个四舍五入到 $6$ 位小数的浮点数。不应打印任何其他文本。\n\n此问题中的所有量都是没有物理单位的纯数，且不涉及角度。所有数值答案均以小数（而非百分比）表示。请确保您的实现基于伯努利似然和逻辑联结函数的基本定义，并且迭代优化过程是从这些基础推导出来的，而不是使用预封装的快捷方式。", "solution": "用户希望使用逻辑回归分析二元结果数据，并基于偏差比较合并模型与亚组特异性模型。从最大似然估计（MLE）到偏差计算的整个过程都必须从第一性原理推导得出。\n\n### 步骤 1：提取给定信息\n- **结果变量**：$y \\in \\{0, 1\\}$（二元）。\n- **预测变量**：$x \\in \\{0, 1\\}$（二元处理指标），$g \\in \\{A, B\\}$（二元亚组指标）。\n- **统计模型**：逻辑回归，它使用逻辑联结函数对成功概率 $p = P(y=1)$ 进行建模。\n- **目标**：使用偏差下降值比较合并模型与亚组特异性模型。\n- **合并模型**：对 $y$ 关于截距和 $x$ 的单一逻辑回归。线性预测器为 $\\eta = \\beta_0 + \\beta_1 x$。\n- **亚组特异性模型**：两个独立的逻辑回归：一个用于亚组 $A$（数据中 $g=A$），预测器为 $\\eta_A = \\beta_{0A} + \\beta_{1A} x$；另一个用于亚组 $B$（数据中 $g=B$），预测器为 $\\eta_B = \\beta_{0B} + \\beta_{1B} x$。\n- **估计方法**：最大似然估计（MLE），通过直接优化伯努利对数似然，并使用从其导数推导出的有原则的迭代方法。\n- **比较指标**：偏差，定义为 $D = 2(\\ell_{sat} - \\ell_{fit})$，其中 $\\ell_{sat}$ 是完美预测每个结果 $y_i$ 的饱和模型的对数似然，$\\ell_{fit}$ 是拟合模型的对数似然。偏差下降值定义为 $D_{pooled} - D_{subgroup}$。\n- **数据集（测试用例）**：提供了三个数据集，以每个亚组 $g$ 和处理 $x$ 组合的成功次数和总数形式给出。\n    - **测试用例 1**：亚组 A：（$x=0$：$56/80$ 次成功；$x=1$：$16/20$ 次成功）。亚组 B：（$x=0$：$2/20$ 次成功；$x=1$：$16/80$ 次成功）。\n    - **测试用例 2**：亚组 A：（$x=0$：$35/50$ 次成功；$x=1$：$40/50$ 次成功）。亚组 B：（$x=0$：$5/50$ 次成功；$x=1$：$10/50$ 次成功）。\n    - **测试用例 3**：亚组 A：（$x=0$：$20/40$ 次成功；$x=1$：$20/40$ 次成功）。亚组 B：（$x=0$：$20/40$ 次成功；$x=1$：$20/40$ 次成功）。\n- **要求输出**：包含三个测试用例偏差下降值的单行逗号分隔列表，四舍五入到 $6$ 位小数：$[d_1, d_2, d_3]$。\n\n### 步骤 2：使用提取的给定信息进行验证\n- **科学依据**：该问题植根于基本的统计理论，特别是广义线性模型、逻辑回归、最大似然估计以及通过偏差进行模型比较。这些都是标准的、完善的概念。所提供的数据集，包括一个展示辛普森悖论的数据集，是教授这些概念时使用的经典例子。该问题在科学上是合理的。\n- **定义明确**：该问题定义明确。目标清晰，模型已指定，数据已提供，并且要求的输出格式毫不含糊。要求从第一性原理推导方法的指令为获得唯一且有意义的解决方案提供了清晰的路径。数据没有表现出完美分离，确保了参数的有限 MLE 估计值存在。\n- **客观性**：问题陈述是客观的，使用了精确的统计术语并提供了具体的数值数据。没有主观或基于意见的元素。\n\n该问题没有任何无效性缺陷。它在科学上是合理的、形式上是指定的、完整的和客观的。\n\n### 步骤 3：结论与行动\n问题是有效的。将提供一个完整、合理的解决方案。\n\n### 解题推导\n\n该解决方案需要从第一性原理实现逻辑回归。这包括最大化对数似然函数以找到模型参数的 MLE，然后使用这些参数计算模型偏差。\n\n**1. 逻辑回归模型与似然**\n\n对于单个观测值 $i$，其结果为 $y_i \\in \\{0, 1\\}$，预测变量向量为 $\\mathbf{x}_i$（其中包括一个用于截距的 $1$），逻辑回归模型假设结果服从伯努利分布，$y_i \\sim \\text{Bernoulli}(p_i)$。成功概率 $p_i$ 通过 logit 联结函数的逆函数（逻辑函数或 sigmoid 函数）与预测变量的线性组合 $\\eta_i = \\mathbf{x}_i^T \\boldsymbol{\\beta}$ 相关联：\n$$ p_i = P(y_i=1 | \\mathbf{x}_i, \\boldsymbol{\\beta}) = \\frac{e^{\\eta_i}}{1 + e^{\\eta_i}} = \\frac{1}{1 + e^{-\\eta_i}} $$\n单个观测的似然由伯努利概率质量函数给出：\n$$ L_i(\\boldsymbol{\\beta}) = p_i^{y_i} (1 - p_i)^{1 - y_i} $$\n对于 $N$ 个独立观测的数据集，总似然是单个似然的乘积，$L(\\boldsymbol{\\beta}) = \\prod_{i=1}^N L_i(\\boldsymbol{\\beta})$。在计算上，处理对数似然 $\\ell(\\boldsymbol{\\beta})$ 更为方便：\n$$ \\ell(\\boldsymbol{\\beta}) = \\log(L(\\boldsymbol{\\beta})) = \\sum_{i=1}^N \\log(L_i(\\boldsymbol{\\beta})) = \\sum_{i=1}^N [y_i \\log(p_i) + (1-y_i) \\log(1-p_i)] $$\n将 $p_i$ 用 $\\eta_i$ 的表达式代入：\n$$ \\log(p_i) = \\eta_i - \\log(1 + e^{\\eta_i}) $$\n$$ \\log(1-p_i) = -\\log(1 + e^{\\eta_i}) $$\n对数似然变为：\n$$ \\ell(\\boldsymbol{\\beta}) = \\sum_{i=1}^N [y_i \\eta_i - \\log(1 + e^{\\eta_i})] = \\sum_{i=1}^N [y_i (\\mathbf{x}_i^T \\boldsymbol{\\beta}) - \\log(1 + e^{\\mathbf{x}_i^T \\boldsymbol{\\beta}})] $$\n\n**2. 通过牛顿-拉弗森法进行最大似然估计**\n\n为了找到 MLE 参数 $\\hat{\\boldsymbol{\\beta}}$，我们必须最大化 $\\ell(\\boldsymbol{\\beta})$。这通过找到其梯度 $\\nabla \\ell(\\boldsymbol{\\beta}) = \\mathbf{0}$ 的根来实现。我们使用牛顿-拉弗森法，这是一种迭代算法，需要对数似然的梯度（得分向量）和海森矩阵（二阶导数矩阵）。\n\n关于参数 $\\beta_j$ 的梯度是：\n$$ \\frac{\\partial \\ell}{\\partial \\beta_j} = \\sum_{i=1}^N \\left[ y_i x_{ij} - \\frac{e^{\\eta_i}}{1 + e^{\\eta_i}} x_{ij} \\right] = \\sum_{i=1}^N (y_i - p_i) x_{ij} $$\n在矩阵形式中，$\\mathbf{X}$ 是设计矩阵，$\\mathbf{y}$ 是结果向量，$\\mathbf{p}$ 是概率向量，梯度为：\n$$ \\nabla \\ell(\\boldsymbol{\\beta}) = \\mathbf{X}^T (\\mathbf{y} - \\mathbf{p}) $$\n海森矩阵 $H$ 的元素为 $H_{jk} = \\frac{\\partial^2 \\ell}{\\partial \\beta_j \\partial \\beta_k}$：\n$$ \\frac{\\partial^2 \\ell}{\\partial \\beta_j \\partial \\beta_k} = \\frac{\\partial}{\\partial \\beta_k} \\sum_{i=1}^N (y_i - p_i) x_{ij} = \\sum_{i=1}^N - \\frac{\\partial p_i}{\\partial \\beta_k} x_{ij} $$\n使用链式法则，$\\frac{\\partial p_i}{\\partial \\beta_k} = \\frac{\\partial p_i}{\\partial \\eta_i} \\frac{\\partial \\eta_i}{\\partial \\beta_k}$。因为 $\\frac{\\partial p_i}{\\partial \\eta_i} = p_i(1-p_i)$ 且 $\\frac{\\partial \\eta_i}{\\partial \\beta_k} = x_{ik}$，我们得到：\n$$ H_{jk} = \\sum_{i=1}^N -p_i(1-p_i) x_{ij} x_{ik} $$\n在矩阵形式中，这是 $H(\\boldsymbol{\\beta}) = -\\mathbf{X}^T \\mathbf{W} \\mathbf{X}$，其中 $\\mathbf{W}$ 是一个对角矩阵，其对角元素为 $W_{ii} = p_i(1-p_i)$。\n\n第 $t+1$ 次迭代的牛顿-拉弗森更新规则是：\n$$ \\boldsymbol{\\beta}^{(t+1)} = \\boldsymbol{\\beta}^{(t)} - [H(\\boldsymbol{\\beta}^{(t)})]^{-1} \\nabla \\ell(\\boldsymbol{\\beta}^{(t)}) $$\n$$ \\boldsymbol{\\beta}^{(t+1)} = \\boldsymbol{\\beta}^{(t)} + (\\mathbf{X}^T \\mathbf{W}^{(t)} \\mathbf{X})^{-1} \\mathbf{X}^T (\\mathbf{y} - \\mathbf{p}^{(t)}) $$\n该算法也称为迭代重加权最小二乘法（IRLS）。我们初始化 $\\boldsymbol{\\beta}$（例如，初始化为零）并迭代直至收敛。\n\n**3. 偏差计算**\n\n模型的偏差为 $D = 2(\\ell_{sat} - \\ell_{fit})$。\n- $\\ell_{fit}$ 是拟合模型的对数似然，$\\ell(\\hat{\\boldsymbol{\\beta}})$，使用 MLE 参数计算得出。\n- $\\ell_{sat}$ 是饱和模型的对数似然。饱和模型每个观测值有一个参数，使其能够完美拟合数据。对于伯努利结果 $y_i$，饱和模型预测概率 $\\hat{p}_{i,sat} = y_i$。观测值 $i$ 的对数似然是 $y_i \\log(\\hat{p}_{i,sat}) + (1-y_i) \\log(1 - \\hat{p}_{i,sat})$。如果 $y_i=1$，此项为 $1 \\log(1) + 0 \\log(0) = 0$。如果 $y_i=0$，此项为 $0 \\log(0) + 1 \\log(1) = 0$。（使用 $0 \\log(0) = 0$ 的约定）。因此，每个观测值的对数似然贡献为 $0$，饱和模型的总对数似然为 $\\ell_{sat} = 0$。\n\n因此，偏差简化为：\n$$ D = -2 \\ell_{fit} = -2 \\sum_{i=1}^N [y_i \\log(\\hat{p}_i) + (1-y_i) \\log(1-\\hat{p}_i)] $$\n其中 $\\hat{p}_i$ 是由拟合模型预测的概率。\n\n**4. 模型比较**\n\n我们拟合两个指定的模型：\n- **合并模型**：对整个数据集进行单一逻辑回归。设计矩阵 $\\mathbf{X}$ 有两列：一个截距（全为 1）和处理指标 $x$。我们计算 $\\hat{\\boldsymbol{\\beta}}_{pooled}$ 和相应的偏差 $D_{pooled}$。\n- **亚组特异性模型**：我们进行两次独立的拟合。\n    1. 对于亚组 $A$，仅使用 $g=A$ 的数据，拟合一个模型以获得 $\\hat{\\boldsymbol{\\beta}}_A$ 及其偏差 $D_A$。\n    2. 对于亚组 $B$，仅使用 $g=B$ 的数据，拟合一个模型以获得 $\\hat{\\boldsymbol{\\beta}}_B$ 及其偏差 $D_B$。\n亚组特异性方法的总对数似然为 $\\ell_{subgroup} = \\ell_A + \\ell_B$。总偏差为 $D_{subgroup} = D_A + D_B$。\n\n偏差下降值为 $D_{pooled} - D_{subgroup}$。该值是用于比较两个嵌套模型的似然比检验统计量。正值表示更复杂的亚组特异性模型比更简单的合并模型能更好地拟合数据。\n\n此框架被应用于每个测试用例，以计算所需的偏差下降值。", "answer": "```python\nimport numpy as np\n\n# A small epsilon for numerical stability in log calculations and matrix inversion\nEPSILON = 1e-15\n\ndef sigmoid(eta):\n    \"\"\"Computes the sigmoid function.\"\"\"\n    # Clip eta to avoid overflow in exp\n    eta = np.clip(eta, -500, 500)\n    return 1.0 / (1.0 + np.exp(-eta))\n\ndef construct_dataset(counts):\n    \"\"\"\n    Expands dataset from counts into individual observations.\n    \n    Args:\n        counts (list): A list of tuples, where each tuple is\n                       (subgroup_char, x_val, total, successes).\n\n    Returns:\n        tuple: A tuple of numpy arrays (y, x, g).\n    \"\"\"\n    y_list, x_list, g_list = [], [], []\n    g_map = {'A': 0, 'B': 1}\n    for g_char, x_val, total, successes in counts:\n        failures = total - successes\n        # Add successes\n        y_list.extend([1] * successes)\n        x_list.extend([x_val] * successes)\n        g_list.extend([g_map[g_char]] * successes)\n        # Add failures\n        y_list.extend([0] * failures)\n        x_list.extend([x_val] * failures)\n        g_list.extend([g_map[g_char]] * failures)\n    return np.array(y_list), np.array(x_list), np.array(g_list)\n\ndef fit_logistic_regression(X, y, tol=1e-8, max_iter=30):\n    \"\"\"\n    Fits a logistic regression model using Newton-Raphson (IRLS).\n\n    Args:\n        X (np.ndarray): Design matrix (N_samples, N_features), with intercept.\n        y (np.ndarray): Binary outcome vector (N_samples,).\n        tol (float): Convergence tolerance for the norm of the step vector.\n        max_iter (int): Maximum number of iterations.\n\n    Returns:\n        np.ndarray: The fitted coefficient vector beta.\n    \"\"\"\n    # Initialize beta coefficients to zero\n    beta = np.zeros(X.shape[1])\n    \n    for _ in range(max_iter):\n        eta = X @ beta\n        p = sigmoid(eta)\n        \n        # Diagonal of the weight matrix W\n        W_diag = p * (1 - p)\n        # Ensure weights are not exactly zero to avoid singular matrix\n        W_diag = np.maximum(W_diag, EPSILON)\n        \n        # Gradient of the log-likelihood\n        grad = X.T @ (y - p)\n        \n        # Hessian of the log-likelihood is -X.T @ W @ X\n        # We compute J = -H, the Fisher Information Matrix\n        # (W_diag[:, np.newaxis] * X) performs row-wise multiplication (efficiently)\n        J = X.T @ (W_diag[:, np.newaxis] * X)\n        \n        try:\n            # Solve J * step = grad for the step vector\n            # This is more numerically stable than computing the inverse of J\n            step = np.linalg.solve(J, grad)\n        except np.linalg.LinAlgError:\n            # This may happen with (quasi-)complete separation, but the data\n            # given in the problem does not have this issue.\n            break\n\n        beta = beta + step\n        \n        if np.linalg.norm(step)  tol:\n            break\n            \n    return beta\n\ndef calculate_deviance(y, X, beta):\n    \"\"\"\n    Calculates the deviance of a fitted logistic regression model.\n\n    Args:\n        y (np.ndarray): True outcome vector.\n        X (np.ndarray): Design matrix.\n        beta (np.ndarray): Fitted coefficient vector.\n\n    Returns:\n        float: The deviance of the model.\n    \"\"\"\n    if y.size == 0:\n        return 0.0\n\n    eta = X @ beta\n    p_hat = sigmoid(eta)\n    \n    # Clip probabilities to avoid log(0)\n    p_hat = np.clip(p_hat, EPSILON, 1 - EPSILON)\n    \n    # Log-likelihood of the fitted model\n    log_likelihood = np.sum(y * np.log(p_hat) + (1 - y) * np.log(1 - p_hat))\n    \n    # Deviance = -2 * log_likelihood (since log_likelihood of saturated model is 0\n    # for individual Bernoulli trials)\n    return -2.0 * log_likelihood\n\ndef solve():\n    \"\"\"\n    Main function to run the analysis for all test cases and print the result.\n    \"\"\"\n    test_cases = [\n        # Test case 1 (strong Simpson's paradox)\n        [('A', 0, 80, 56), ('A', 1, 20, 16), ('B', 0, 20, 2), ('B', 1, 80, 16)],\n        # Test case 2 (balanced assignment, consistent effect)\n        [('A', 0, 50, 35), ('A', 1, 50, 40), ('B', 0, 50, 5), ('B', 1, 50, 10)],\n        # Test case 3 (edge case: no effect)\n        [('A', 0, 40, 20), ('A', 1, 40, 20), ('B', 0, 40, 20), ('B', 1, 40, 20)],\n    ]\n    \n    results = []\n    \n    for case_counts in test_cases:\n        y, x, g = construct_dataset(case_counts)\n        \n        # Design matrix with intercept\n        X = np.c_[np.ones(x.shape[0]), x]\n        \n        # 1. Pooled Model\n        beta_pooled = fit_logistic_regression(X, y)\n        deviance_pooled = calculate_deviance(y, X, beta_pooled)\n        \n        # 2. Subgroup-specific Model\n        \n        # Subgroup A\n        mask_A = (g == 0)\n        y_A, X_A = y[mask_A], X[mask_A]\n        beta_A = fit_logistic_regression(X_A, y_A)\n        deviance_A = calculate_deviance(y_A, X_A, beta_A)\n\n        # Subgroup B\n        mask_B = (g == 1)\n        y_B, X_B = y[mask_B], X[mask_B]\n        beta_B = fit_logistic_regression(X_B, y_B)\n        deviance_B = calculate_deviance(y_B, X_B, beta_B)\n\n        deviance_subgroup = deviance_A + deviance_B\n        \n        # 3. Deviance Drop\n        deviance_drop = deviance_pooled - deviance_subgroup\n        results.append(round(deviance_drop, 6))\n\n    # Format and print the final output\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3147557"}]}