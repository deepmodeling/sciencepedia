{"hands_on_practices": [{"introduction": "学习任何新模型的第一步都是看它如何拟合一个我们熟知的函数。这个练习将指导你使用自然三次样条来近似指数函数 $f(x) = \\exp(x)$。通过改变节点数量并计算 $L^2$ 逼近误差，你将亲身体验到增加样条的灵活性如何提高其逼近精度 [@problem_id:3153014]。", "problem": "要求您实现一个程序，为函数 $f(x) = e^x$ 在区间 $[0,1]$ 上构建自然三次样条近似，其中使用几种指定的节点总数，并计算每个样条的 $L^2$ 近似误差。在统计学习的背景下，自然样条是一个分段三次多项式函数，它二阶连续可微，并在端点处满足线性边界条件。这些条件限制了函数在边界附近的灵活性，并通常能减少方差。对于三次自然样条，自然边界条件将区间端点处的二阶导数设置为零。\n\n从以下基本定义开始：\n- 在 $[0,1]$ 上，一个总节点数为 $K$ 的自然三次样条 $s_K(x)$ 是一个函数，它在由非递减节点序列 $0 = \\tau_0 \\le \\tau_1 \\le \\dots \\le \\tau_{K-1} = 1$ 决定的子区间上是分段三次多项式，满足所有 $i \\in \\{0,1,\\dots,K-1\\}$ 的插值约束 $s_K(\\tau_i) = f(\\tau_i)$，在 $[0,1]$ 上具有连续的一阶和二阶导数，并满足边界条件 $s_K''(0) = 0$ 和 $s_K''(1) = 0$。\n- 在 $[0,1]$ 上的 $L^2$ 近似误差定义为\n$$\nE_K \\;=\\; \\left( \\int_{0}^{1} \\big( s_K(x) - f(x) \\big)^2 \\, dx \\right)^{1/2}.\n$$\n\n您的任务是：\n1. 对于每个指定的总节点数 $K$，在 $[0,1]$ 上构建一个由 $\\tau_i = \\frac{i}{K-1}$（其中 $i \\in \\{0,1,\\dots,K-1\\}$）给出的均匀节点序列。\n2. 使用这些节点，形成在节点处插值 $f(x) = e^x$ 并且满足 $s_K''(0) = 0$ 和 $s_K''(1) = 0$ 的自然三次样条 $s_K(x)$。\n3. 通过数值计算积分，为每个样条计算其在 $[0,1]$ 上的 $L^2$ 近似误差 $E_K$。\n\n实现要求：\n- 使用数值稳定且精确的方法来评估定义 $E_K$ 的积分。最终的误差值必须计算到高精度。\n- 此问题不涉及物理单位和角度。\n- 您的程序必须是一个完整的、可运行的程序，不需要任何外部输入。\n\n测试套件：\n- 使用以下总节点数 $K$: $\\{2, 3, 5, 11\\}$。\n  - $K = 2$ 用于测试仅有端点作为节点的边界情况。\n  - $K = 3$ 在 $x = \\frac{1}{2}$ 处包含一个内部节点。\n  - $K = 5$ 引入了中等数量的内部节点。\n  - $K = 11$ 在 $[0,1]$ 上提供了一个更精细的节点网格。\n\n要求的最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，结果按所提供测试用例的顺序排列。每个 $E_K$ 必须四舍五入到小数点后八位。例如：“[a,b,c,d]”，其中 $a$、$b$、$c$ 和 $d$ 分别是 $K \\in \\{2,3,5,11\\}$ 的四舍五入值。", "solution": "该问题要求构建自然三次样条来近似函数 $f(x) = e^x$ 在区间 $[0, 1]$ 上的表现，并随后为一组给定的总节点数 $K$ 计算 $L^2$ 近似误差。该解决方案包括两个主要阶段：首先，构建样条；其次，评估误差积分。\n\n**1. 自然三次样条的构建**\n\n一个具有 $K$ 个节点 $\\tau_0, \\tau_1, \\dots, \\tau_{K-1}$ 的三次样条 $s_K(x)$ 是一个分段三次多项式函数。在每个子区间 $[\\tau_i, \\tau_{i+1}]$（其中 $i \\in \\{0, 1, \\dots, K-2\\}$）上，样条 $s_K(x)$ 由一个唯一的三次多项式表示，我们将其记为 $s_i(x)$。这 $K-1$ 个多项式总共有 $4(K-1)$ 个未知系数。这些系数通过施加一组条件来确定。\n\n插值三次样条的标准条件是：\n-   **插值**：样条必须穿过给定的数据点。对于每个节点 $\\tau_i$，我们要求 $s_K(\\tau_i) = f(\\tau_i)$。设 $y_i = f(\\tau_i)$。这提供了 $K$ 个条件，具体来说，对于所有 $i \\in \\{0, \\dots, K-2\\}$，有 $s_i(\\tau_i) = y_i$ 和 $s_i(\\tau_{i+1}) = y_{i+1}$。这些构成了 $2(K-1)$ 个约束。\n-   **一阶导数的连续性**：在每个内部节点 $\\tau_i$（其中 $i \\in \\{1, \\dots, K-2\\}$）处，样条的一阶导数必须连续：$s'_{i-1}(\\tau_i) = s'_i(\\tau_i)$。这增加了 $K-2$ 个约束。\n-   **二阶导数的连续性**：同样，在每个内部节点 $\\tau_i$（其中 $i \\in \\{1, \\dots, K-2\\}$）处，二阶导数必须连续：$s''_{i-1}(\\tau_i) = s''_i(\\tau_i)$。这又增加了 $K-2$ 个约束。\n\n来自插值和连续性的总约束数为 $2(K-1) + (K-2) + (K-2) = 4K-6$。由于有 $4(K-1)$ 个系数需要确定，我们还需要两个额外的约束。这些约束由边界条件提供。对于**自然三次样条**，边界条件是：\n-   **自然边界条件**：样条的二阶导数在区间的端点处为零。给定区间 $[0, 1]$，其中 $\\tau_0=0$ 且 $\\tau_{K-1}=1$，这些条件是 $s_K''(0) = 0$ 和 $s_K''(1) = 0$。\n\n一种确定样条系数的标准且计算上稳定的方法是首先求解节点处的二阶导数，记为 $M_i = s_K''(\\tau_i)$。对于均匀节点序列，其中任意两个连续节点之间的间距是常数 $h = \\tau_{i+1} - \\tau_i = \\frac{1}{K-1}$，连续性条件会导出一个关于未知值 $M_1, \\dots, M_{K-2}$ 的线性方程组。对于 $i \\in \\{1, \\dots, K-2\\}$，其控制方程为：\n$$\nM_{i-1} + 4M_i + M_{i+1} = \\frac{6}{h^2}(y_{i+1} - 2y_i + y_{i-1})\n$$\n自然边界条件提供了 $M_0 = 0$ 和 $M_{K-1} = 0$。将这些代入方程组，得到一个用于求解内部二阶导数 $M_1, \\dots, M_{K-2}$ 的 $(K-2) \\times (K-2)$ 三对角线性方程组。该系统是严格对角占优的，因此有唯一解。\n\n一旦所有 $M_i$ 的值都已知，任何子区间 $[\\tau_i, \\tau_{i+1}]$ 上的三次多项式 $s_i(x)$ 就由以下公式唯一确定：\n$$\ns_i(x) = M_i \\frac{(\\tau_{i+1}-x)^3}{6h} + M_{i+1} \\frac{(x-\\tau_i)^3}{6h} + \\left(\\frac{y_{i+1}-y_i}{h} - \\frac{h}{6}(M_{i+1}-M_i)\\right)(x-\\tau_i) + \\left(y_i - \\frac{M_i h^2}{6}\\right)\n$$\n可以使用成熟的数值库方便而稳健地执行此手动构建过程。Python 的 SciPy 库中的 `scipy.interpolate.CubicSpline` 类，配合 `bc_type='natural'` 参数，可以自动完成整个过程。它接收节点位置 $\\tau_i$ 和相应的函数值 $y_i=e^{\\tau_i}$ 作为输入，并构建所需的样条函数。\n\n**2. $L^2$ 近似误差计算**\n\n样条近似的质量由 $L^2$ 误差来衡量，其定义为：\n$$\nE_K = \\left( \\int_{0}^{1} \\big( s_K(x) - f(x) \\big)^2 \\, dx \\right)^{1/2}\n$$\n在这个问题中，$f(x) = e^x$。被积函数是 $(s_K(x) - e^x)^2$。由于 $s_K(x)$ 是一个分段多项式，而 $e^x$ 是一个无限可微函数，因此被积函数是连续且性质良好的，这使其适合进行高精度的数值积分。\n\n积分是在整个区间 $[0, 1]$ 上进行评估的。一种高效的计算方法是使用自适应求积例程，它会调整步长以达到所需的精度，将计算精力集中在被积函数变化最剧烈的区域。`scipy.integrate.quad` 函数是完成此任务的绝佳选择，因为它提供了 QUADPACK 库自适应积分算法的稳健而精确的实现。\n\n**3. 算法实现**\n\n对于每个指定的总节点数 $K$，总体算法如下：\n1.  **生成节点和数据**：对于给定的 $K$，在区间 $[0, 1]$ 上创建均匀节点序列 $\\tau_i = \\frac{i}{K-1}$，其中 $i \\in \\{0, 1, \\dots, K-1\\}$。计算相应的函数值 $y_i = e^{\\tau_i}$。\n2.  **构建样条**：使用 `scipy.interpolate.CubicSpline`，传入节点 $\\tau$、函数值 $y$ 以及边界条件类型 `bc_type='natural'`，来创建样条函数 $s_K(x)$。\n3.  **定义被积函数**：定义一个 Python 函数，用于计算任意给定 $x \\in [0, 1]$ 的平方误差 $(s_K(x) - e^x)^2$。\n4.  **数值积分**：使用 `scipy.integrate.quad` 计算平方误差函数从 $x=0$ 到 $x=1$ 的定积分。\n5.  **计算误差**：通过取积分结果的平方根，计算最终的 $L^2$ 误差 $E_K$。\n6.  **格式化输出**：按要求将计算出的误差 $E_K$ 格式化为八位小数。\n\n对测试套件 $\\{2, 3, 5, 11\\}$ 中的每个 $K$ 值重复此过程。特殊情况 $K=2$ 会产生一个线性函数，`CubicSpline` 构造函数使用自然边界条件可以正确处理这种情况。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.interpolate import CubicSpline\nfrom scipy.integrate import quad\n\ndef solve():\n    \"\"\"\n    Constructs natural cubic splines for f(x) = e^x and computes their L2 error.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [2, 3, 5, 11]\n\n    results = []\n    for K in test_cases:\n        # Step 1: Generate a uniform knot sequence on [0,1] and evaluate f(x) at these knots.\n        # The number of knots is K. The knots are tau_i = i/(K-1) for i in {0, ..., K-1}.\n        knots = np.linspace(0.0, 1.0, K)\n        \n        # The function to approximate is f(x) = e^x.\n        y_values = np.exp(knots)\n        \n        # Step 2: Construct the natural cubic spline.\n        # The 'bc_type=\"natural\"' argument sets the second derivatives at the endpoints\n        # (x=0 and x=1) to zero, which is the definition of a natural spline.\n        # This function handles the underlying linear algebra (solving the tridiagonal system) internally.\n        natural_spline = CubicSpline(knots, y_values, bc_type='natural')\n        \n        # Step 3: Define the integrand for the L^2 error calculation.\n        # The integrand is the squared difference between the spline and the true function.\n        def squared_error_integrand(x):\n            return (natural_spline(x) - np.exp(x))**2\n            \n        # Step 4: Numerically evaluate the integral of the squared error over [0,1].\n        # scipy.integrate.quad uses adaptive quadrature for high accuracy.\n        # It returns a tuple: (result, estimated_absolute_error). We only need the result.\n        integral_value, _ = quad(squared_error_integrand, 0.0, 1.0)\n        \n        # Step 5: Compute the L^2 error, which is the square root of the integral.\n        l2_error = np.sqrt(integral_value)\n        \n        # Append the result, formatted to exactly eight decimal places.\n        results.append(f\"{l2_error:.8f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3153014"}, {"introduction": "自然样条的一个关键优势在于其在数据范围之外的稳定表现，这与全局多项式可能出现的剧烈振荡形成鲜明对比。本练习 [@problem_id:3153008] 通过直接比较两种模型在包含外推区域的区间上的积分平方误差，来量化和展示自然样条线性尾部约束的价值。这个对比清晰地揭示了为什么在对模型外推行为有要求时，自然样条通常是更稳健的选择。", "problem": "给定一个综合回归设定，其目标是比较自然三次样条和全局三次多项式拟合在逼近未知目标函数时的行为。从最小二乘回归的基本原理和带自然边界条件的三次样条的定义出发，在相同的训练数据上实现两个回归估计器：(i) 一个全局三次多项式和 (ii) 一个在训练输入范围内具有等间距节点的自然三次样条。然后，使用数值积分，在包含训练范围并延伸到尾部的指定评估区间上，为每个估计器计算积分平方误差。\n\n使用以下基本基础：\n- 普通最小二乘回归：给定设计矩阵 $X \\in \\mathbb{R}^{n \\times p}$ 和响应 $y \\in \\mathbb{R}^n$，最小二乘估计器 $\\hat{\\beta}$ 最小化 $\\sum_{i=1}^n (y_i - (X \\hat{\\beta})_i)^2$，并对于一个特征向量 $x$ 产生 $\\hat{f}(x) = x^\\top \\hat{\\beta}$。\n- 三次样条回归：三次样条是在节点处具有一阶和二阶导数连续性的分段三次函数。自然三次样条施加自然边界条件，要求二阶导数在边界节点处为零，这意味着在边界节点区间之外呈线性行为。\n- 积分平方误差：对于一个估计器 $\\hat{f}$ 和真实函数 $f$，在区间 $[A,B]$ 上的积分平方误差是 $\\int_A^B \\left(\\hat{f}(x) - f(x)\\right)^2 \\, dx$，它可以通过在精细网格上使用黎曼和或梯形法则进行数值近似。\n\n实现以下内容，不要在问题文本中提供或依赖快捷公式：\n\n1. 数据生成。对于每个测试用例，生成在 $[a,b]$ 区间内均匀分布的训练输入 $x_i$ 和输出 $y_i = f(x_i) + \\epsilon_i$，其中 $\\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$ 是独立同分布的高斯噪声。对于任何三角函数，使用弧度角。\n2. 估计器。\n   - 全局三次多项式：使用特征映射 $x \\mapsto [1, x, x^2, x^3]$ 进行回归。\n   - 自然三次样条：使用一个标准的自然三次样条基，其边界节点位于 $a$ 和 $b$，并在 $[a,b]$ 区间内有 $M-2$ 个等间距的内部节点，从而产生一个 $M$ 维的设计。其中前两列代表线性部分，其余 $M-2$ 列代表强制执行自然边界条件的调整后截断三次分量。\n3. 评估。对于每个拟合模型，通过在 $N_{\\text{eval}}$ 个点的均匀网格上评估真实函数 $f$ 和拟合函数 $\\hat{f}$，并应用梯形法则，来近似计算在 $[A,B]$ 上的积分平方误差。\n\n测试套件。实现并运行以下四个测试用例，每个用例由 $(f, a, b, A, B, n_{\\text{train}}, \\sigma, M, N_{\\text{eval}}, \\text{seed})$ 指定：\n- 用例 1 (具有中等尾部的理想路径): $f(x) = \\sin(2x) + 0.3 x$, $a=-3$, $b=3$, $A=-5$, $B=5$, $n_{\\text{train}}=61$, $\\sigma=0.1$, $M=7$, $N_{\\text{eval}}=10001$, $\\text{seed}=1$。\n- 用例 2 (无噪声且线性主导的尾部): $f(x) = x + 0.5 \\sin(x)$, $a=-1$, $b=1$, $A=-4$, $B=4$, $n_{\\text{train}}=41$, $\\sigma=0.0$, $M=5$, $N_{\\text{eval}}=10001$, $\\text{seed}=2$。\n- 用例 3 (曲率加线性趋势，中等噪声): $f(x) = e^{-x^2} + x$, $a=-2$, $b=2$, $A=-3$, $B=3$, $n_{\\text{train}}=81$, $\\sigma=0.05$, $M=6$, $N_{\\text{eval}}=10001$, $\\text{seed}=3$。\n- 用例 4 (具有最少节点和宽尾部的边缘情况): $f(x) = \\sin(x)$, $a=-2$, $b=2$, $A=-6$, $B=6$, $n_{\\text{train}}=51$, $\\sigma=0.0$, $M=3$, $N_{\\text{eval}}=10001$, $\\text{seed}=4$。\n\n对于每个用例，计算三个量：自然样条的积分平方误差 $\\text{ISE}_{\\text{ns}}$，三次多项式的积分平方误差 $\\text{ISE}_{\\text{cp}}$，以及差值 $\\text{ISE}_{\\text{ns}} - \\text{ISE}_{\\text{cp}}$。将所有报告的浮点数四舍五入到 $6$ 位小数。\n\n最终输出格式。您的程序应生成单行输出，其中包含结果，形式为列表的列表，每个子列表对应一个测试用例，按用例 $1$ 到 $4$ 的顺序排列。每个子列表必须为 $[\\text{ISE}_{\\text{ns}}, \\text{ISE}_{\\text{cp}}, \\text{ISE}_{\\text{ns}} - \\text{ISE}_{\\text{cp}}]$ 的形式，并且所有数字都四舍五入到 $6$ 位小数，例如：$[[0.123456,0.234567,-0.111111],[...],...]$。", "solution": "该问题要求通过评估两种回归模型——全局三次多项式和自然三次样条——在指定区间上拟合目标函数的性能，来对它们进行比较。性能指标是积分平方误差 (ISE)。分析从普通最小二乘 (OLS) 回归的基本原理以及每个模型基函数的数学定义出发。\n\n两种模型的基础都是 OLS 回归。给定一组 $n_{\\text{train}}$ 个训练对 $(x_i, y_i)$，我们的目标是找到一个函数 $\\hat{f}$ 来最小化残差平方和 $\\text{RSS}(\\beta) = \\sum_{i=1}^{n_{\\text{train}}} (y_i - \\hat{f}(x_i))^2$。对于形式为 $\\hat{f}(x) = \\sum_{j=1}^{p} \\beta_j h_j(x)$ 的线性模型，其中 $\\{h_j(x)\\}_{j=1}^p$ 是一组基函数，这等价于求解最小化 $\\|y - X\\beta\\|^2$ 的系数向量 $\\hat{\\beta} \\in \\mathbb{R}^p$。这里，$y = [y_1, \\dots, y_{n_{\\text{train}}}]^\\top$ 是响应向量，$X$ 是 $n_{\\text{train}} \\times p$ 的设计矩阵，其元素为 $X_{ij} = h_j(x_i)$。众所周知的解由 $\\hat{\\beta} = (X^\\top X)^{-1} X^\\top y$ 给出，在数值上最好使用奇异值分解等方法计算，正如标准线性代数库 (`lstsq`) 中所实现的那样。\n\n第一个模型是**全局三次多项式**，其中函数假定为形式 $\\hat{f}_{\\text{cp}}(x) = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\beta_3 x^3$。基函数为 $\\{h_1(x), h_2(x), h_3(x), h_4(x)\\} = \\{1, x, x^2, x^3\\}$。相应的设计矩阵 $X_{\\text{cp}}$ 是一个 $n_{\\text{train}} \\times 4$ 的矩阵，其中第 $i$ 行为 $[1, x_i, x_i^2, x_i^3]$。\n\n第二个模型是**自然三次样条**。三次样条是在一系列称为节点的点上连续且具有连续一阶和二阶导数的分段三次多项式。自然三次样条施加了一个额外的约束：函数在边界节点之外必须是线性的。这通过要求二阶导数在最小和最大节点处为零来实现。对于一组 $M$ 个节点 $\\xi_1, \\xi_2, \\dots, \\xi_M$，其中 $\\xi_1$ 和 $\\xi_M$ 是边界节点，一个标准 $M$ 维基由以下给出：\n- $N_1(x) = 1$\n- $N_2(x) = x$\n- $N_{j+2}(x) = d_j(x) - d_{M-1}(x)$，对于 $j = 1, \\dots, M-2$。\n$d_j(x)$ 函数定义为：\n$$d_j(x) = \\frac{(x - \\xi_j)_+^3 - (x - \\xi_M)_+^3}{\\xi_M - \\xi_j}$$\n其中如果 $u > 0$ 则 $(u)_+ = u$，否则为 $0$。这种基函数的选择明确确保了它们的任何线性组合在 $x  \\xi_1$ 和 $x > \\xi_M$ 时都是线性的。对于每个测试用例，我们在训练区间 $[a,b]$ 上构造一组 $M$ 个等间距的节点，使得 $\\xi_1=a$ 和 $\\xi_M=b$。相应的 $n_{\\text{train}} \\times M$ 设计矩阵 $X_{\\text{ns}}$ 被构造出来，其第 $i$ 行为 $[N_1(x_i), N_2(x_i), \\dots, N_M(x_i)]$。\n\n一旦两个模型都拟合到训练数据 $(x_i, y_i = f(x_i) + \\mathcal{N}(0, \\sigma^2))$ 以获得估计器 $\\hat{f}_{\\text{cp}}(x)$ 和 $\\hat{f}_{\\text{ns}}(x)$，我们就评估它们的性能。度量标准是在评估区间 $[A,B]$ 上的积分平方误差 (ISE)：\n$$\\text{ISE}(\\hat{f}) = \\int_A^B (\\hat{f}(x) - f(x))^2 \\, dx$$\n这个积分使用梯形法则进行数值近似。在区间 $[A,B]$ 上创建一个由 $N_{\\text{eval}}$ 个点组成的精细均匀网格。设这些点为 $z_k$（$k=1, \\dots, N_{\\text{eval}}$），具有恒定的间距 $\\Delta z = (B-A)/(N_{\\text{eval}}-1)$。然后 ISE 近似为：\n$$\\text{ISE}(\\hat{f}) \\approx \\sum_{k=1}^{N_{\\text{eval}}-1} \\frac{(\\hat{f}(z_k) - f(z_k))^2 + (\\hat{f}(z_{k+1}) - f(z_{k+1}))^2}{2} \\Delta z$$\n此过程被应用于计算三次多项式的 $\\text{ISE}_{\\text{cp}}$ 和自然样条的 $\\text{ISE}_{\\text{ns}}$，为比较它们的行为提供了一个定量基础，尤其是在训练区间 $[a,b]$ 之外的外推区域。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and compares global cubic polynomial and natural cubic spline\n    regression models based on their integrated squared error.\n    \"\"\"\n\n    # Define the true functions for the test cases.\n    # Angles are in radians.\n    functions = {\n        1: lambda x: np.sin(2 * x) + 0.3 * x,\n        2: lambda x: x + 0.5 * np.sin(x),\n        3: lambda x: np.exp(-x**2) + x,\n        4: lambda x: np.sin(x),\n    }\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1, -3, 3, -5, 5, 61, 0.1, 7, 10001, 1),\n        (2, -1, 1, -4, 4, 41, 0.0, 5, 10001, 2),\n        (3, -2, 2, -3, 3, 81, 0.05, 6, 10001, 3),\n        (4, -2, 2, -6, 6, 51, 0.0, 3, 10001, 4),\n    ]\n\n    def build_natural_spline_basis(x, knots):\n        \"\"\"\n        Constructs the design matrix for a natural cubic spline.\n        The basis is derived from \"The Elements of Statistical Learning\".\n        \"\"\"\n        M = len(knots)\n        x = np.asarray(x)\n        basis = np.zeros((len(x), M))\n        \n        basis[:, 0] = 1.0\n        if M > 1:\n            basis[:, 1] = x\n\n        if M > 2:\n            def d_func(x_vec, knot_k, knot_M):\n                # Implements the d_k(x) function for the spline basis\n                term1 = np.maximum(0, x_vec - knot_k)**3\n                term2 = np.maximum(0, x_vec - knot_M)**3\n                return (term1 - term2) / (knot_M - knot_k)\n\n            knot_M_val = knots[-1]\n            d_M_minus_1_vec = d_func(x, knots[M-2], knot_M_val)\n            \n            for j in range(1, M - 1):\n                knot_j = knots[j-1]\n                d_j_vec = d_func(x, knot_j, knot_M_val)\n                basis[:, j + 1] = d_j_vec - d_M_minus_1_vec\n                \n        return basis\n\n    results = []\n    for case in test_cases:\n        f_id, a, b, A, B, n_train, sigma, M, N_eval, seed = case\n        f = functions[f_id]\n\n        # 1. Data Generation\n        rng = np.random.default_rng(seed)\n        x_train = np.linspace(a, b, n_train)\n        noise = rng.normal(0, sigma, size=n_train)\n        y_train = f(x_train) + noise\n\n        # 2. Estimators\n        # Global Cubic Polynomial\n        X_cp_train = np.vander(x_train, 4, increasing=True)\n        beta_cp = np.linalg.lstsq(X_cp_train, y_train, rcond=None)[0]\n\n        def f_hat_cp(x_eval):\n            X_cp_eval = np.vander(x_eval, 4, increasing=True)\n            return X_cp_eval @ beta_cp\n\n        # Natural Cubic Spline\n        knots = np.linspace(a, b, M)\n        X_ns_train = build_natural_spline_basis(x_train, knots)\n        beta_ns = np.linalg.lstsq(X_ns_train, y_train, rcond=None)[0]\n        \n        def f_hat_ns(x_eval):\n            X_ns_eval = build_natural_spline_basis(x_eval, knots)\n            return X_ns_eval @ beta_ns\n\n        # 3. Evaluation\n        x_eval = np.linspace(A, B, N_eval)\n        y_true_eval = f(x_eval)\n\n        # ISE for Cubic Polynomial\n        y_hat_cp_eval = f_hat_cp(x_eval)\n        squared_error_cp = (y_hat_cp_eval - y_true_eval)**2\n        ise_cp = np.trapz(squared_error_cp, x_eval)\n\n        # ISE for Natural Spline\n        y_hat_ns_eval = f_hat_ns(x_eval)\n        squared_error_ns = (y_hat_ns_eval - y_true_eval)**2\n        ise_ns = np.trapz(squared_error_ns, x_eval)\n\n        # Store results rounded to 6 decimal places\n        diff = ise_ns - ise_cp\n        results.append([round(ise_ns, 6), round(ise_cp, 6), round(diff, 6)])\n\n    # Final print statement in the exact required format.\n    case_strs = []\n    for res in results:\n        num_strs = [str(val) for val in res]\n        case_strs.append(f\"[{','.join(num_strs)}]\")\n    print(f\"[{','.join(case_strs)}]\")\n\nsolve()\n```", "id": "3153008"}, {"introduction": "“自然”边界条件假设函数在边界处的二阶导数为零，但这并非总是成立。本练习 [@problem_id:2189207] 通过一个精心设计的例子，即用自然样条插值 $f(x) = x^4$ 函数，来揭示当真实函数在边界处有显著曲率时，这种假设会如何导致较大的近似误差。这个计算将帮助你建立对模型假设的批判性思维，并理解其潜在的局限性。", "problem": "考虑函数 $f(x) = x^4$。构造一个自然三次样条 $S(x)$，在节点 $x_0 = 0$、$x_1 = 1$ 和 $x_2 = 2$ 处对该函数进行插值。三次样条被定义为在节点上二阶连续可导的分段三次多项式。自然三次样条还额外满足边界条件 $S''(x_0) = 0$ 和 $S''(x_n) = 0$，其中 $x_0$ 和 $x_n$ 分别是第一个和最后一个节点。\n\n这种边界条件的选择虽然在数学上很方便，但如果真实函数的二阶导数在边界处不为零，则可能导致较大的近似误差。\n\n计算在点 $x = 1.8$ 处二阶导数近似的绝对误差，定义为 $|S''(1.8) - f''(1.8)|$。\n\n将您的最终答案四舍五入到四位有效数字。", "solution": "目标是计算绝对误差 $|S''(1.8) - f''(1.8)|$。该过程包括三个主要部分：\n1.  计算函数 $f(x)$ 在 $x=1.8$ 处的真实二阶导数。\n2.  确定自然三次样条 $S(x)$ 在 $x=1.8$ 处的二阶导数。\n3.  计算绝对差值。\n\n**步骤 1：计算真实二阶导数 $f''(1.8)$**\n\n给定函数为 $f(x) = x^4$。我们求其一阶和二阶导数：\n$$f'(x) = \\frac{d}{dx}(x^4) = 4x^3$$\n$$f''(x) = \\frac{d}{dx}(4x^3) = 12x^2$$\n现在，我们计算在 $x = 1.8$ 处的二阶导数：\n$$f''(1.8) = 12(1.8)^2 = 12(3.24) = 38.88$$\n\n**步骤 2：确定样条的二阶导数 $S''(1.8)$**\n\n为了找到 $S''(x)$，我们首先需要找到样条在节点处的二阶导数值，记为 $M_i = S''(x_i)$。节点为 $x_0=0, x_1=1, x_2=2$。对应的函数值为：\n$$y_0 = f(x_0) = 0^4 = 0$$\n$$y_1 = f(x_1) = 1^4 = 1$$\n$$y_2 = f(x_2) = 2^4 = 16$$\n步长为 $h_i = x_{i+1} - x_i$：\n$$h_0 = x_1 - x_0 = 1 - 0 = 1$$\n$$h_1 = x_2 - x_1 = 2 - 1 = 1$$\n\n三次样条的矩 $M_i$ 通过以下关于内部节点（本例中仅为 $i=1$）的方程组相关联：\n$$h_{i-1}M_{i-1} + 2(h_{i-1} + h_i)M_i + h_i M_{i+1} = 6 \\left( \\frac{y_{i+1}-y_i}{h_i} - \\frac{y_i-y_{i-1}}{h_{i-1}} \\right)$$\n对于 $i=1$：\n$$h_0 M_0 + 2(h_0 + h_1)M_1 + h_1 M_2 = 6 \\left( \\frac{y_2 - y_1}{h_1} - \\frac{y_1 - y_0}{h_0} \\right)$$\n我们已知该样条是*自然*三次样条，这意味着端点处的二阶导数为零：\n$$M_0 = S''(x_0) = S''(0) = 0$$\n$$M_2 = S''(x_2) = S''(2) = 0$$\n将所有已知值代入 $M_1$ 的方程中：\n$$(1)(0) + 2(1 + 1)M_1 + (1)(0) = 6 \\left( \\frac{16 - 1}{1} - \\frac{1 - 0}{1} \\right)$$\n$$4M_1 = 6 (15 - 1)$$\n$$4M_1 = 6 (14)$$\n$$4M_1 = 84$$\n$$M_1 = 21$$\n因此，样条的矩为 $M_0=0, M_1=21, M_2=0$。\n\n在区间 $[x_i, x_{i+1}]$ 上，三次样条的二阶导数是一个线性函数，它对矩 $M_i$ 和 $M_{i+1}$ 进行插值：\n$$S_i''(x) = M_i \\frac{x_{i+1} - x}{h_i} + M_{i+1} \\frac{x - x_i}{h_i}$$\n点 $x=1.8$ 位于第二个区间 $[x_1, x_2] = [1, 2]$ 中，因此我们设 $i=1$：\n$$S_1''(x) = M_1 \\frac{x_2 - x}{h_1} + M_2 \\frac{x - x_1}{h_1}$$\n代入已知值 $M_1=21, M_2=0, x_1=1, x_2=2, h_1=1$：\n$$S''(x) = 21 \\frac{2 - x}{1} + 0 \\frac{x - 1}{1} = 21(2-x) \\quad \\text{for } x \\in [1, 2]$$\n现在我们可以计算样条在 $x=1.8$ 处的二阶导数：\n$$S''(1.8) = 21(2 - 1.8) = 21(0.2) = 4.2$$\n\n**步骤 3：计算绝对误差**\n\n最后，我们计算题目中定义的绝对误差：\n$$\\text{Error} = |S''(1.8) - f''(1.8)|$$\n$$\\text{Error} = |4.2 - 38.88| = |-34.68| = 34.68$$\n题目要求将答案四舍五入到四位有效数字。数字 $34.68$ 已经有四位有效数字。", "answer": "$$\\boxed{34.68}$$", "id": "2189207"}]}