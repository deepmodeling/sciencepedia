{"hands_on_practices": [{"introduction": "理论最好的伙伴是实践。在迁移学习中，一个最直接且常见的问题是“先验概率偏移”，即源域和目标域中类别的分布比例不同（例如，不同地区疾病的患病率不同）。幸运的是，如果我们可以估计出这些先验概率，我们就能通过一个优雅的数学变换直接校准我们的模型。这个练习将指导你推导并实现这种校准方法，让你亲身体验如何通过调整模型的“逻辑值”（logits）来精确地修正先验偏移带来的影响 [@problem_id:3189015]。", "problem": "考虑源域和目标域之间存在先验概率偏移的多类别域自适应问题。该问题的基本基础包括以下定义和事实。对于随机输入 $x$ 和离散标签 $y \\in \\{0,1,\\ldots,K-1\\}$，令 $p_S(y)$ 和 $p_T(y)$ 分别表示源域和目标域的类别先验分布。令 $p_S(y \\mid x)$ 和 $p_T(y \\mid x)$ 表示源域和目标域的后验概率。假设在先验偏移模型中，类条件密度在域之间是不变的，即对于所有 $y$，$p_S(x \\mid y) = p_T(x \\mid y)$。根据贝叶斯法则和先验偏移假设，目标域后验概率满足 $p_T(y \\mid x) \\propto p_S(y \\mid x) \\cdot \\frac{p_T(y)}{p_S(y)}$。在多项式逻辑斯蒂模型中，分类器由一个得分向量（logits）$h(x) \\in \\mathbb{R}^K$ 表示，其 softmax 函数通过 $p_S(y=k \\mid x) = \\frac{\\exp(h_k(x))}{\\sum_{j=0}^{K-1} \\exp(h_j(x))}$ 产生源域概率。多类别分类的标准监督训练目标是交叉熵损失，对于一个带标签的样本 $(x,y)$，其定义为 $\\ell(h(x), y) = -\\log\\left( \\frac{\\exp(h_y(x))}{\\sum_{j=0}^{K-1} \\exp(h_j(x))} \\right)$，这在 softmax 模型下是负对数似然。最大后验概率（MAP）决策规则选择使后验概率最大化的类别。\n\n任务。从先验偏移模型以及上述 softmax 和交叉熵损失的定义出发，推导出校准感知自适应原理，该原理通过一个从目标域与源域类别先验比率中导出的、依赖于类别的偏移量来修改 logits，从而使交叉熵反映目标域的后验概率。然后，在一个程序中实现这一原理，该程序对下面的每个测试用例计算：\n- 在给定的带标签目标样本上，未经自适应的平均交叉熵损失（基础损失）。\n- 在相同样本上，经过校准感知自适应的平均交叉熵损失（自适应损失）。\n- 未经自适应的分类准确率（基础准确率），表示为 $[0,1]$ 范围的小数。\n- 经过自适应的分类准确率（自适应准确率），表示为 $[0,1]$ 范围的小数。\n\n计算时使用以下定义：\n- 对于任何 logits 向量 $z \\in \\mathbb{R}^K$，softmax 函数为 $\\operatorname{softmax}(z)_k = \\frac{\\exp(z_k)}{\\sum_{j=0}^{K-1}\\exp(z_j)}$。\n- 对于 logits 为 $z$、标签为 $y$ 的样本，交叉熵为 $\\ell(z, y) = -\\log(\\operatorname{softmax}(z)_y)$。\n- 分类规则为 $\\hat{y} = \\arg\\max_{k \\in \\{0,\\ldots,K-1\\}} z_k$。\n- 校准感知自适应通过添加一个 $\\mathbb{R}^K$ 中的常数偏移向量来修改 logits，该向量仅依赖于类别索引 $k$ 和给定的域先验，然后使用相同的 softmax 和交叉熵定义。\n\n数值要求：\n- 所有平均损失必须四舍五入到六位小数。\n- 所有准确率必须四舍五入到四位小数，并以小数形式表示（而非百分比）。\n- 不涉及物理单位或角度。\n\n测试套件。每个测试用例提供类别数 $K$、源域先验 $\\pi_S \\in \\mathbb{R}^K$、目标域先验 $\\pi_T \\in \\mathbb{R}^K$、一组目标域 logits $\\{h^{(i)}\\}_{i=1}^n$ 以及相应的目标标签 $\\{y^{(i)}\\}_{i=1}^n$。\n\n- 测试用例 1（无先验偏移）：\n  - $K = 3$。\n  - $\\pi_S = [\\,0.4,\\,0.35,\\,0.25\\,]$。\n  - $\\pi_T = [\\,0.4,\\,0.35,\\,0.25\\,]$。\n  - Logits 行：\n    - $[\\,2.0,\\,0.5,\\,-1.0\\,]$, $y=0$。\n    - $[\\,0.2,\\,1.5,\\,0.0\\,]$, $y=1$。\n    - $[\\,\\,-0.5,\\,-0.2,\\,1.0\\,]$, $y=2$。\n    - $[\\,1.0,\\,1.2,\\,0.8\\,]$, $y=1$。\n    - $[\\,0.9,\\,-1.0,\\,0.3\\,]$, $y=0$。\n\n- 测试用例 2（目标域先验严重偏向类别 0）：\n  - $K = 3$。\n  - $\\pi_S = [\\,0.3333333333,\\,0.3333333333,\\,0.3333333333\\,]$。\n  - $\\pi_T = [\\,0.7,\\,0.2,\\,0.1\\,]$。\n  - Logits 行：\n    - $[\\,\\,-0.2,\\,0.4,\\,0.0\\,]$, $y=0$。\n    - $[\\,0.1,\\,0.0,\\,0.2\\,]$, $y=0$。\n    - $[\\,1.0,\\,-0.5,\\,-0.3\\,]$, $y=0$。\n    - $[\\,0.0,\\,1.1,\\,-0.1\\,]$, $y=1$。\n    - $[\\,\\,-0.8,\\,0.3,\\,0.4\\,]$, $y=2$。\n    - $[\\,0.6,\\,-0.2,\\,0.0\\,]$, $y=0$。\n\n- 测试用例 3（相反的先验偏移，目标域偏向类别 1 和 2）：\n  - $K = 3$。\n  - $\\pi_S = [\\,0.6,\\,0.3,\\,0.1\\,]$。\n  - $\\pi_T = [\\,0.2,\\,0.5,\\,0.3\\,]$。\n  - Logits 行：\n    - $[\\,1.5,\\,0.2,\\,-0.2\\,]$, $y=1$。\n    - $[\\,0.8,\\,0.7,\\,0.6\\,]$, $y=2$。\n    - $[\\,\\,-0.3,\\,0.9,\\,0.0\\,]$, $y=1$。\n    - $[\\,2.0,\\,-0.5,\\,-0.2\\,]$, $y=0$。\n    - $[\\,\\,-0.5,\\,0.1,\\,1.2\\,]$, $y=2$。\n    - $[\\,0.1,\\,0.2,\\,0.0\\,]$, $y=1$。\n    - $[\\,0.5,\\,-0.3,\\,0.4\\,]$, $y=2$。\n\n程序输出规范。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。对于每个测试用例，按 $[L_{\\text{base}}, L_{\\text{adapt}}, A_{\\text{base}}, A_{\\text{adapt}}]$ 的顺序将四个数字附加到此列表中，其中 $L_{\\text{base}}$ 是四舍五入到六位小数的平均基础损失，$L_{\\text{adapt}}$ 是四舍五入到六位小数的平均自适应损失，$A_{\\text{base}}$ 是四舍五入到四位小数的基础准确率，$A_{\\text{adapt}}$ 是四舍五入到四位小数的自适应准确率。因此，对于 3 个测试用例，输出列表必须包含 12 个数字。程序必须是自包含的，并且不得读取任何输入或访问外部文件。", "solution": "该问题要求推导并实现一种在先验概率偏移下的域自适应方法，即校准感知自适应方法。核心任务是调整源域分类器的 logits $h(x)$，以正确反映目标域的后验概率。\n\n首先，我们根据给定的条件来形式化问题。我们给定一个源域 $S$ 和一个目标域 $T$。对于一个输入 $x$ 和一个类别标签 $y \\in \\{0, 1, \\ldots, K-1\\}$，源域和目标域的类别先验概率分别表示为 $p_S(y)$ 和 $p_T(y)$，对于 $y=k$ 我们将其写作 $\\pi_S(k)$ 和 $\\pi_T(k)$。核心假设是先验偏移，即类条件密度在不同域之间是不变的：\n$$ p_S(x \\mid y) = p_T(x \\mid y) \\quad \\forall y $$\n源域分类器提供 logits $h(x) \\in \\mathbb{R}^K$，通过 softmax 函数可以从中获得源域后验概率 $p_S(y \\mid x)$：\n$$ p_S(y=k \\mid x) = \\frac{\\exp(h_k(x))}{\\sum_{j=0}^{K-1} \\exp(h_j(x))} $$\n目标是为 logits $h(x)$ 找到一个变换，得到新的 logits $h'_{\\text{adapt}}(x)$，使得这些新 logits 的 softmax 对应于目标域后验概率 $p_T(y \\mid x)$。\n\n我们从先验偏移假设下目标域和源域后验概率之间的关系开始推导。根据贝叶斯法则，$p_T(y \\mid x) = \\frac{p_T(x \\mid y) p_T(y)}{p_T(x)}$。边际概率 $p_T(x)$ 是关于 $y$ 的归一化常数，因此我们可以将其写成正比关系：\n$$ p_T(y \\mid x) \\propto p_T(x \\mid y) p_T(y) $$\n利用类条件不变性 $p_T(x \\mid y) = p_S(x \\mid y)$，我们有：\n$$ p_T(y \\mid x) \\propto p_S(x \\mid y) p_T(y) $$\n根据源域中的贝叶斯法则，我们可以将 $p_S(x \\mid y)$ 表示为 $p_S(x \\mid y) = \\frac{p_S(y \\mid x) p_S(x)}{p_S(y)}$。将其代入正比关系中得到：\n$$ p_T(y \\mid x) \\propto \\frac{p_S(y \\mid x) p_S(x)}{p_S(y)} p_T(y) $$\n$p_S(x)$ 项对于给定的 $x$ 是一个常数，可以被吸收到比例常数中。因此，我们得到了题目中给出的关键关系：\n$$ p_T(y=k \\mid x) \\propto p_S(y=k \\mid x) \\cdot \\frac{\\pi_T(k)}{\\pi_S(k)} $$\n现在，我们代入源域后验概率 $p_S(y=k \\mid x)$ 的 softmax 定义：\n$$ p_T(y=k \\mid x) \\propto \\left( \\frac{\\exp(h_k(x))}{\\sum_{j=0}^{K-1} \\exp(h_j(x))} \\right) \\cdot \\frac{\\pi_T(k)}{\\pi_S(k)} $$\n分母 $\\sum_{j=0}^{K-1} \\exp(h_j(x))$ 对于类别索引 $k$ 也是一个常数，可以被吸收到比例常数中。剩下：\n$$ p_T(y=k \\mid x) \\propto \\exp(h_k(x)) \\cdot \\frac{\\pi_T(k)}{\\pi_S(k)} $$\n利用属性 $a \\cdot b = \\exp(\\log(a)) \\cdot \\exp(\\log(b)) = \\exp(\\log(a) + \\log(b))$，我们可以将表达式重写为：\n$$ p_T(y=k \\mid x) \\propto \\exp\\left(h_k(x) + \\log\\left(\\frac{\\pi_T(k)}{\\pi_S(k)}\\right)\\right) $$\n这个结果表明，类别 $k$ 的目标域后验概率与一个修正后的 logit 的指数成正比。这定义了**校准感知自适应原理**：通过在原始源域 logits 上加上一个依赖于类别的偏移量来获得自适应 logits $h'_{\\text{adapt}}(x)$。设该偏移向量为 $c \\in \\mathbb{R}^K$，其分量为 $c_k$：\n$$ c_k = \\log\\left(\\frac{\\pi_T(k)}{\\pi_S(k)}\\right) $$\n那么，对于给定的输入 $x$，自适应 logits 为：\n$$ h'_{k, \\text{adapt}}(x) = h_k(x) + c_k $$\n这些自适应 logits 的 softmax 将正确地产生目标域的后验概率：\n$$ p_T(y=k \\mid x) = \\operatorname{softmax}(h'_{\\text{adapt}}(x))_k = \\frac{\\exp(h'_{k, \\text{adapt}}(x))}{\\sum_{j=0}^{K-1} \\exp(h'_{j, \\text{adapt}}(x))} $$\n基于这个推导出的原理，我们现在可以定义所需的度量指标。对于一个 logits 为 $h(x)$ 的给定样本 $(x, y)$，我们计算：\n1.  **基础（未自适应）度量指标**：使用原始 logits $h(x)$ 计算。\n    *   基础交叉熵损失：$\\ell_{\\text{base}}(h(x), y) = -\\log(\\operatorname{softmax}(h(x))_y)$。\n    *   基础预测：$\\hat{y}_{\\text{base}} = \\arg\\max_{k} h_k(x)$。\n    *   平均基础损失 $L_{\\text{base}}$ 和基础准确率 $A_{\\text{base}}$ 是这些量在数据集上的平均值。\n\n2.  **自适应度量指标**：使用自适应 logits $h'_{\\text{adapt}}(x) = h(x) + c$ 计算。\n    *   自适应交叉熵损失：$\\ell_{\\text{adapt}}(h'_{\\text{adapt}}(x), y) = -\\log(\\operatorname{softmax}(h'_{\\text{adapt}}(x))_y)$。这是目标域模型下的负对数似然。\n    *   自适应预测（目标域后验概率的 MAP 规则）：$\\hat{y}_{\\text{adapt}} = \\arg\\max_{k} h'_{k, \\text{adapt}}(x)$。\n    *   平均自适应损失 $L_{\\text{adapt}}$ 和自适应准确率 $A_{\\text{adapt}}$ 是这些量在数据集上的平均值。\n\n实现过程将首先根据给定的源域和目标域先验 $\\pi_S$ 和 $\\pi_T$ 计算常数偏移向量 $c$ 来处理每个测试用例。然后，对于每个样本，它将计算四个度量指标：基础损失、自适应损失、基础准确率和自适应准确率。最后，它将对测试用例中的所有样本取平均值，并将它们四舍五入到指定的精度。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the domain adaptation problem for the given test suite.\n    Derives and applies calibration-aware adaptation, then computes and\n    formats the required metrics.\n    \"\"\"\n    \n    test_cases = [\n        {\n            \"K\": 3,\n            \"pi_S\": [0.4, 0.35, 0.25],\n            \"pi_T\": [0.4, 0.35, 0.25],\n            \"logits\": [\n                [2.0, 0.5, -1.0], [0.2, 1.5, 0.0], [-0.5, -0.2, 1.0],\n                [1.0, 1.2, 0.8], [0.9, -1.0, 0.3]\n            ],\n            \"labels\": [0, 1, 2, 1, 0]\n        },\n        {\n            \"K\": 3,\n            \"pi_S\": [0.3333333333, 0.3333333333, 0.3333333333],\n            \"pi_T\": [0.7, 0.2, 0.1],\n            \"logits\": [\n                [-0.2, 0.4, 0.0], [0.1, 0.0, 0.2], [1.0, -0.5, -0.3],\n                [0.0, 1.1, -0.1], [-0.8, 0.3, 0.4], [0.6, -0.2, 0.0]\n            ],\n            \"labels\": [0, 0, 0, 1, 2, 0]\n        },\n        {\n            \"K\": 3,\n            \"pi_S\": [0.6, 0.3, 0.1],\n            \"pi_T\": [0.2, 0.5, 0.3],\n            \"logits\": [\n                [1.5, 0.2, -0.2], [0.8, 0.7, 0.6], [-0.3, 0.9, 0.0],\n                [2.0, -0.5, -0.2], [-0.5, 0.1, 1.2], [0.1, 0.2, 0.0],\n                [0.5, -0.3, 0.4]\n            ],\n            \"labels\": [1, 2, 1, 0, 2, 1, 2]\n        }\n    ]\n\n    def softmax(z):\n        \"\"\"Computes the numerically stable softmax of a vector.\"\"\"\n        z_shifted = z - np.max(z)\n        exps = np.exp(z_shifted)\n        return exps / np.sum(exps)\n\n    def compute_metrics_for_case(pi_S_list, pi_T_list, logits_list, labels_list):\n        \"\"\"\n        Computes base and adapted metrics for a single test case.\n        \"\"\"\n        pi_S = np.array(pi_S_list, dtype=np.float64)\n        pi_T = np.array(pi_T_list, dtype=np.float64)\n        logits = np.array(logits_list, dtype=np.float64)\n        labels = np.array(labels_list)\n        n_samples = len(labels)\n\n        # The prior shift assumption requires pi_S(k) > 0 for the ratio to be defined.\n        # Problem data adheres to this.\n        offset = np.log(pi_T / pi_S)\n\n        base_losses = []\n        base_correct_count = 0\n        adapted_losses = []\n        adapted_correct_count = 0\n\n        for i in range(n_samples):\n            h = logits[i]\n            y = labels[i]\n\n            # Base (unadapted) metrics\n            base_probs = softmax(h)\n            base_loss = -np.log(base_probs[y])\n            base_losses.append(base_loss)\n            \n            base_pred = np.argmax(h)\n            if base_pred == y:\n                base_correct_count += 1\n\n            # Adapted metrics\n            h_adapt = h + offset\n            adapted_probs = softmax(h_adapt)\n            adapted_loss = -np.log(adapted_probs[y])\n            adapted_losses.append(adapted_loss)\n            \n            adapted_pred = np.argmax(h_adapt)\n            if adapted_pred == y:\n                adapted_correct_count += 1\n\n        mean_base_loss = np.mean(base_losses)\n        base_accuracy = base_correct_count / n_samples\n        mean_adapted_loss = np.mean(adapted_losses)\n        adapted_accuracy = adapted_correct_count / n_samples\n        \n        # Rounding to specified precision\n        L_base = round(mean_base_loss, 6)\n        L_adapt = round(mean_adapted_loss, 6)\n        A_base = round(base_accuracy, 4)\n        A_adapt = round(adapted_accuracy, 4)\n\n        return [L_base, L_adapt, A_base, A_adapt]\n\n    all_results = []\n    for case in test_cases:\n        case_results = compute_metrics_for_case(\n            case[\"pi_S\"],\n            case[\"pi_T\"],\n            case[\"logits\"],\n            case[\"labels\"]\n        )\n        all_results.extend(case_results)\n\n    # Format output according to specification.\n    # Losses to 6 decimal places, accuracies to 4 decimal places.\n    formatted_results = [\n        f\"{res:.6f}\" if i % 4  2 else f\"{res:.4f}\"\n        for i, res in enumerate(all_results)\n    ]\n    \n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3189015"}, {"introduction": "在很多现实场景中，我们可能无法预知领域偏移的具体类型。因此，我们需要一种更通用的策略，即首先量化源域和目标域之间的“差异”有多大，然后根据这个差异程度来调整我们的模型。这个练习 [@problem_id:3189023] 将带领你实现一个非常核心的领域自适应思想：通过训练一个“领域判别器”来估计领域间的散度（Proxy A-distance），并利用这个度量来自动调整学习算法的正则化强度，从而让模型在面对不同程度的领域差异时能做出更智能的调整。", "problem": "你的任务是为迁移学习场景下的线性分类器设计一个自适应正则化方案。目标是根据源域和目标域之间的估计散度来选择欧几里得平方范数正则化（L2）的强度。你的程序必须实现以下原则：当域非常相似时，使用弱正则化；当域非常不同时，使用强正则化。\n\n从以下核心定义和事实开始：\n- 使用 L2 正则化的经验风险最小化（ERM）使用的惩罚与参数向量的欧几里得平方范数成正比。对于参数向量 $w$ 和经验风险 $R(w)$，正则化目标是 $R(w) + \\lambda \\lVert w \\rVert_2^2$，其中 $\\lambda \\ge 0$ 是正则化强度。\n- 在域自适应中，目标域上的泛化性能可以由源域风险、域间散度以及一个不可约的联合误差项来界定。一个代表性的界表明，对于假设类别 $\\mathcal{H}$ 中的任何假设 $h$，目标风险由源风险加上一个散度项（如对称差假设散度 $d_{\\mathcal{H}\\Delta\\mathcal{H}}$），再加上一个取决于最佳联合假设的常数所控制。这启发我们在域间隙较大时，通过增 大$\\lambda$ 来增加归纳偏置。\n- $d_{\\mathcal{H}\\Delta\\mathcal{H}}$ 的一个实用的、数据驱动的代理是所谓的代理A-距离（Proxy A-distance, PAD），它是通过训练一个分类器来区分源域与目标域样本（使用来自 $\\mathcal{H}$ 的假设）的误差计算得出的。设 $\\hat{\\varepsilon}$ 为这样一个域判别器在留出数据上的经验错误率。那么，散度的一个标准估计量是 $\\hat{d} = 2 \\left(1 - 2 \\min(\\hat{\\varepsilon}, 1 - \\hat{\\varepsilon})\\right)$，其值域为 $[0, 2]$。\n\n你的任务是推导、证明并实现一个从估计散度 $\\hat{d}$ 到正则化强度 $\\hat{\\lambda}$ 的自适应映射，该映射需满足以下约束：\n- $\\hat{\\lambda}$ 必须是关于 $\\hat{d}$ 的单调非减函数。\n- 当 $\\hat{d} = 0$ 时，设置 $\\hat{\\lambda} = \\lambda_{\\mathrm{base}}$，其中 $\\lambda_{\\mathrm{base}} = 0.1$。\n- 当 $\\hat{d} = 2$ 时，设置 $\\hat{\\lambda} = \\lambda_{\\mathrm{max}}$，其中 $\\lambda_{\\mathrm{max}} = 10.0$。\n- 在所有满足上述约束的函数中，选择与将散度用作目标风险放大的线性信号相一致的最简单的非平凡选择。\n\n每个测试用例需要实现的程序：\n1. 数据生成。你将在 $\\mathbb{R}^2$ 中为源域和目标域合成仅含特征的数据。对于给定的随机种子 $s$、源域样本大小 $n_s$、目标域样本大小 $n_t$、源域均值向量 $\\mu_s \\in \\mathbb{R}^2$ 以及目标域均值向量 $\\mu_t \\in \\mathbb{R}^2$，按如下方式独立抽取样本：\n   - 源域特征 $X_s \\sim \\mathcal{N}(\\mu_s, I_2)$，一个均值为 $\\mu_s$、协方差为单位矩阵 $I_2$ 的高斯分布。\n   - 目标域特征 $X_t \\sim \\mathcal{N}(\\mu_t, I_2)$。\n   使用给定的种子 $s$ 初始化一个伪随机数生成器，以确保你的结果是确定性的。\n2. 域判别器与散度估计。\n   - 为所有源域样本分配域标签 $0$，为所有目标域样本分配域标签 $1$。\n   - 使用与上述相同的伪随机数生成器分别对每个域进行随机打乱，然后将每个域分成两半（源域的前 $\\lfloor n_s/2 \\rfloor$ 个样本用于训练，其余用于测试；目标域类似）。\n   - 训练一个线性逻辑回归分类器，使用训练集的一半来从二维特征预测域标签。该逻辑回归应最小化平均逻辑损失，不带任何显式正则化项。使用一个截距（偏置）项。对于特征为 $x \\in \\mathbb{R}^2$、标签为 $y \\in \\{0,1\\}$、参数向量为 $w \\in \\mathbb{R}^3$（包括偏置）的单个样本，其逻辑损失为 $\\ell(w; x, y) = \\log\\left(1 + e^{z}\\right) - y z$，其中 $z = w^\\top \\tilde{x}$，$\\tilde{x}$ 是为偏置项增广了一个常数 $1$ 的 $x$。\n   - 使用逻辑S型函数的阈值 $0.5$，在留出（测试）的一半数据上计算经验域分类误差 $\\hat{\\varepsilon}$。为确保散度估计为非负，定义 $\\hat{\\varepsilon}_{\\min} = \\min(\\hat{\\varepsilon}, 1 - \\hat{\\varepsilon})$。\n   - 计算估计散度 $\\hat{d} = 2 \\left(1 - 2 \\hat{\\varepsilon}_{\\min}\\right)$，并通过构造确保 $\\hat{d} \\in [0, 2]$。\n3. 自适应正则化映射。\n   - 推导满足 $\\hat{d}=0$ 时 $\\hat{\\lambda} = \\lambda_{\\mathrm{base}}$ 和 $\\hat{d}=2$ 时 $\\hat{\\lambda} = \\lambda_{\\mathrm{max}}$ 的关于 $\\hat{d}$ 的最简单单调函数，并用它来计算 $\\hat{\\lambda}$。\n   - 将每个测试用例的 $\\hat{\\lambda}$ 值作为浮点数输出，四舍五入到 $6$ 位小数。\n\n测试套件：\n为以下参数集按给定顺序实现上述流程。在所有情况下，特征维度为 $2$，协方差为单位矩阵 $I_2$。\n- 情况 1：seed = 7, $n_s = 200$, $n_t = 200$, $\\mu_s = (0.0, 0.0)$, $\\mu_t = (0.0, 0.0)$。\n- 情况 2：seed = 13, $n_s = 200$, $n_t = 200$, $\\mu_s = (0.0, 0.0)$, $\\mu_t = (1.0, 0.5)$。\n- 情况 3：seed = 21, $n_s = 200$, $n_t = 200$, $\\mu_s = (0.0, 0.0)$, $\\mu_t = (3.0, 3.0)$。\n- 情况 4：seed = 5, $n_s = 40$, $n_t = 40$, $\\mu_s = (0.0, 0.0)$, $\\mu_t = (0.8, -0.8)$。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含一个逗号分隔的列表，用方括号括起来（例如，\"[result1,result2,result3,result4]\"）。每个结果是对应情况下 $\\hat{\\lambda}$ 的四舍五入值，按上述顺序排列。不需要单位，因为 $\\lambda$ 是无量纲的。不涉及角度。不得使用百分比；所有值均为小数。", "solution": "该问题要求在迁移学习背景下，为线性分类器设计并实现一个自适应正则化方案。正则化强度，记为 $\\hat{\\lambda}$，将由源域和目标域之间的估计散度 $\\hat{d}$ 决定。解决方案分为两个主要阶段：首先，推导从 $\\hat{d}$ 到 $\\hat{\\lambda}$ 的函数映射；其次，详述从数据中估计 $\\hat{d}$ 并随后计算 $\\hat{\\lambda}$ 的算法流程。\n\n### 第1部分：自适应正则化函数的推导\n\n问题为函数 $\\hat{\\lambda}(\\hat{d})$ 指定了三个约束，该函数将估计的代理A-距离 $\\hat{d} \\in [0, 2]$ 映射到正则化强度 $\\hat{\\lambda}$：\n1.  $\\hat{\\lambda}(\\hat{d})$ 必须是关于 $\\hat{d}$ 的单调非减函数。\n2.  $\\hat{\\lambda}(0) = \\lambda_{\\mathrm{base}} = 0.1$。\n3.  $\\hat{\\lambda}(2) = \\lambda_{\\mathrm{max}} = 10.0$。\n\n此外，我们被指示选择“与将散度用作目标风险放大的线性信号相一致的最简单的非平凡选择”。线性函数是能够满足这些约束的最简单的非恒定函数，并且与将 $\\hat{d}$ 解释为线性信号相符。\n\n让我们将该线性函数定义为：\n$$\n\\hat{\\lambda}(\\hat{d}) = m \\hat{d} + c\n$$\n其中 $m$ 是斜率，$c$ 是截距。为使函数单调非减，必须有 $m \\ge 0$。\n\n我们使用两个边界条件来确定参数 $m$ 和 $c$：\n-   应用第一个条件, $\\hat{\\lambda}(0) = 0.1$:\n    $$\n    m(0) + c = 0.1 \\implies c = 0.1\n    $$\n-   应用第二个条件, $\\hat{\\lambda}(2) = 10.0$, 并代入 $c=0.1$:\n    $$\n    m(2) + 0.1 = 10.0 \\\\\n    2m = 9.9 \\\\\n    m = 4.95\n    $$\n由于 $m = 4.95 > 0$，单调性约束得到满足。\n因此，推导出的自适应正则化函数是：\n$$\n\\hat{\\lambda}(\\hat{d}) = 4.95 \\hat{d} + 0.1\n$$\n\n### 第2部分：算法实现\n\n任务的核心是实现一个流程，为几个测试用例计算 $\\hat{\\lambda}$。这包括数据生成、训练域判别器以估计 $\\hat{d}$，最后应用上面推导的函数。\n\n1.  **数据生成**：对于每个由随机种子 $s$、源样本量 $n_s$、目标样本量 $n_t$、源均值 $\\mu_s \\in \\mathbb{R}^2$ 和目标均值 $\\mu_t \\in \\mathbb{R}^2$ 定义的测试用例，我们生成数据。使用种子 $s$ 初始化一个伪随机数生成器以保证可复现性。\n    -   源域数据 $X_s$ 由从多元正态分布 $\\mathcal{N}(\\mu_s, I_2)$ 中抽取的 $n_s$ 个样本组成，其中 $I_2$ 是 $2 \\times 2$ 的单位矩阵。\n    -   目标域数据 $X_t$ 由从 $\\mathcal{N}(\\mu_t, I_2)$ 中抽取的 $n_t$ 个样本组成。\n\n2.  **域判别器与散度估计**：\n    -   **标注**：我们为域分类创建一个新的数据集。来自 $X_s$ 的源样本被赋予标签 $y=0$，来自 $X_t$ 的目标样本被赋予标签 $y=1$。\n    -   **数据分割**：源数据集和目标数据集都独立地进行打乱。然后每个数据集被分成训练集和测试集。训练集由前 $\\lfloor n/2 \\rfloor$ 个样本组成，测试集由剩余样本组成。来自两个域的训练数据合并构成判别器的训练集，测试数据也同样处理。\n    -   **模型训练**：在合并的训练数据上训练一个线性逻辑回归分类器，以区分源域（$y=0$）和目标域（$y=1$）。模型的参数向量 $w \\in \\mathbb{R}^3$ 包括两个特征的权重和一个偏置项。这是通过为每个特征向量 $x \\in \\mathbb{R}^2$ 增广一个常数 $1$ 来实现的，形成 $\\tilde{x} \\in \\mathbb{R}^3$。目标是找到参数向量 $w^*$，以最小化训练集上的平均逻辑损失 $J(w)$：\n        $$\n        w^* = \\arg\\min_w J(w) = \\arg\\min_w \\frac{1}{N_{\\text{train}}} \\sum_{i=1}^{N_{\\text{train}}} \\left[ \\log\\left(1 + e^{w^\\top \\tilde{x}_i}\\right) - y_i (w^\\top \\tilde{x}_i) \\right]\n        $$\n        这是一个凸优化问题，可以使用数值方法（如基于梯度的优化器，例如BFGS）来解决。此类优化器所需的平均损失的梯度为：\n        $$\n        \\nabla_w J(w) = \\frac{1}{N_{\\text{train}}} \\sum_{i=1}^{N_{\\text{train}}} (\\sigma(w^\\top \\tilde{x}_i) - y_i) \\tilde{x}_i\n        $$\n        其中 $\\sigma(z) = (1 + e^{-z})^{-1}$ 是逻辑S型函数。\n    -   **散度计算**：使用训练好的分类器（参数为 $w^*$）在留出的测试集上预测域标签。对于具有增广特征 $\\tilde{x}$ 的样本，其预测概率为 $p = \\sigma((w^*)^\\top \\tilde{x})$。如果 $p \\ge 0.5$，则预测标签为 $1$，否则为 $0$。\n        经验错误率 $\\hat{\\varepsilon}$ 是测试集中被错误分类的样本比例。为考虑标签交换的模糊性，我们计算 $\\hat{\\varepsilon}_{\\min} = \\min(\\hat{\\varepsilon}, 1 - \\hat{\\varepsilon})$。\n        最后，代理A-距离估计为：\n        $$\n        \\hat{d} = 2(1 - 2\\hat{\\varepsilon}_{\\min})\n        $$\n\n3.  **自适应正则化计算**：\n    -   将估计的散度 $\\hat{d}$ 代入推导出的线性映射中，计算最终的正则化强度：\n        $$\n        \\hat{\\lambda} = 4.95 \\hat{d} + 0.1\n        $$\n    -   按要求将得到的 $\\hat{\\lambda}$ 值四舍五入到 $6$ 位小数。对问题陈述中指定的每个测试用例重复此过程。", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    It orchestrates the calculation of the adaptive regularization parameter lambda_hat\n    for each specified scenario.\n    \"\"\"\n    \n    test_cases = [\n        # (seed, n_s, n_t, mu_s, mu_t)\n        (7, 200, 200, (0.0, 0.0), (0.0, 0.0)),\n        (13, 200, 200, (0.0, 0.0), (1.0, 0.5)),\n        (21, 200, 200, (0.0, 0.0), (3.0, 3.0)),\n        (5, 40, 40, (0.0, 0.0), (0.8, -0.8)),\n    ]\n\n    results = []\n    for case in test_cases:\n        seed, n_s, n_t, mu_s, mu_t = case\n        lambda_hat = compute_lambda_for_case(seed, n_s, n_t, np.array(mu_s), np.array(mu_t))\n        results.append(round(lambda_hat, 6))\n\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef compute_lambda_for_case(seed, n_s, n_t, mu_s, mu_t):\n    \"\"\"\n    Implements the full pipeline for a single test case:\n    1. Generates source and target data.\n    2. Trains a domain discriminator (logistic regression).\n    3. Computes the Proxy A-distance.\n    4. Maps the distance to a regularization parameter lambda_hat.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n\n    # 1. Data Generation\n    cov = np.identity(2)\n    source_data = rng.multivariate_normal(mu_s, cov, size=n_s)\n    target_data = rng.multivariate_normal(mu_t, cov, size=n_t)\n\n    # 2. Domain discriminator and divergence estimation\n    \n    # Shuffle each domain's data separately\n    source_data_shuffled = source_data[rng.permutation(n_s)]\n    target_data_shuffled = target_data[rng.permutation(n_t)]\n    \n    # Split each domain into training and testing halves\n    s_split_idx = n_s // 2\n    source_train, source_test = source_data_shuffled[:s_split_idx], source_data_shuffled[s_split_idx:]\n    \n    t_split_idx = n_t // 2\n    target_train, target_test = target_data_shuffled[:t_split_idx], target_data_shuffled[t_split_idx:]\n\n    # Combine to form domain discriminator datasets\n    X_train = np.vstack((source_train, target_train))\n    y_train = np.hstack((np.zeros(len(source_train)), np.ones(len(target_train))))\n    \n    X_test = np.vstack((source_test, target_test))\n    y_test = np.hstack((np.zeros(len(source_test)), np.ones(len(target_test))))\n    \n    # Augment features with a bias term (column of ones)\n    X_train_aug = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n    X_test_aug = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n\n    # Define objective function (average logistic loss) and its gradient\n    def logistic_loss(w, X, y):\n        z = X @ w\n        # Numerically stable computation of log(1 + exp(z))\n        log_1_p_ez = np.zeros_like(z)\n        pos_mask = z  0\n        log_1_p_ez[pos_mask] = z[pos_mask] + np.log1p(np.exp(-z[pos_mask]))\n        log_1_p_ez[~pos_mask] = np.log1p(np.exp(z[~pos_mask]))\n        \n        loss = np.sum(log_1_p_ez - y * z)\n        return loss / len(y)\n\n    def sigmoid(z):\n        # Numerically stable sigmoid function\n        res = np.zeros_like(z, dtype=float)\n        p_mask = z = 0\n        n_mask = ~p_mask\n        res[p_mask] = 1.0 / (1.0 + np.exp(-z[p_mask]))\n        exp_z_n = np.exp(z[n_mask])\n        res[n_mask] = exp_z_n / (1.0 + exp_z_n)\n        return res\n\n    def logistic_gradient(w, X, y):\n        # Gradient of the average logistic loss\n        predictions = sigmoid(X @ w)\n        error = predictions - y\n        grad = (X.T @ error) / len(y)\n        return grad\n    \n    # Train the logistic regression model\n    initial_w = np.zeros(X_train_aug.shape[1])\n    opt_result = minimize(\n        logistic_loss, \n        initial_w, \n        args=(X_train_aug, y_train), \n        jac=logistic_gradient, \n        method='BFGS'\n    )\n    w_opt = opt_result.x\n\n    # Compute classification error on the test set\n    test_probs = sigmoid(X_test_aug @ w_opt)\n    test_preds = (test_probs = 0.5).astype(int)\n    error_rate = np.mean(test_preds != y_test)\n    \n    # Compute Proxy A-distance\n    eps_min = min(error_rate, 1 - error_rate)\n    d_hat = 2 * (1 - 2 * eps_min)\n\n    # 3. Adaptive regularization mapping\n    lambda_hat = 4.95 * d_hat + 0.1\n    \n    return lambda_hat\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3189023"}, {"introduction": "当我们应用了一种领域自适应方法后，如何判断它是否真的有效？一个更高的准确率或 AUC 分数是否就意味着模型变得更好了？这个练习将揭示一个评估过程中至关重要的细微之处：一个方法可能在提升模型排序能力（判别能力，以 AUC 衡量）的同时，损害了其输出概率的可靠性（校准度，以 Brier 分数衡量）。通过模拟一个判别能力和校准度此消彼长的场景 [@problem_id:3188990]，本练习强调了在评估自适应模型时采用多维度量指标的必要性，尤其是在那些需要可信概率预测的应用中。", "problem": "考虑一个具有一个源域和多个目标域的二元分类问题。目标是以一种有原则的方式研究域漂移下的校准与判别之间的权衡，并实现一个程序，以展示在何种情况下，一种改善目标域判别能力的方法可能会恶化其校准性。\n\n从以下基本定义开始。\n\n1. 设输入为实值特征，表示为 $x \\in \\mathbb{R}$，标签为 $y \\in \\{0,1\\}$。一个概率分类器输出一个分数 $s(x) \\in \\mathbb{R}$ 和一个预测概率 $\\hat{p}(x) \\in [0,1]$，通常通过逻辑斯蒂链接函数 $\\sigma(t) = 1/(1+e^{-t})$ 实现，其中 $\\hat{p}(x) = \\sigma(s(x))$。\n\n2. 在一个分布上，受试者工作特征曲线下面积（AUC）是一个随机选择的正样本得分高于一个随机选择的负样本得分的概率。形式上，对于分数 $s(X)$ 和标签 $Y$，\n$$\n\\mathrm{AUC} = \\mathbb{P}\\big(s(X^+)  s(X^-)\\big) + \\tfrac{1}{2}\\mathbb{P}\\big(s(X^+) = s(X^-)\\big).\n$$\n判别质量由 $\\mathrm{AUC}$ 评估；它仅取决于由 $s(x)$ 产生的排序。\n\n3. Brier 分数是预测概率的均方误差，\n$$\n\\mathrm{Brier} = \\mathbb{E}\\big[(\\hat{p}(X) - Y)^2\\big],\n$$\n它是一种强调校准性的恰当评分规则。\n\n4. 源域 $\\mathcal{S}$ 由一个具有共享方差的同方差高斯类条件模型生成。具体来说，设 $Y \\sim \\mathrm{Bernoulli}(\\pi_{\\mathcal{S}})$，其中 $\\pi_{\\mathcal{S}} = 0.5$，条件分布为\n$$\nX \\mid Y=1 \\sim \\mathcal{N}(\\mu_{1,\\mathcal{S}}, \\sigma_{\\mathcal{S}}^2), \\quad X \\mid Y=0 \\sim \\mathcal{N}(\\mu_{0,\\mathcal{S}}, \\sigma_{\\mathcal{S}}^2),\n$$\n其中 $\\mu_{1,\\mathcal{S}} = 1.5$，$\\mu_{0,\\mathcal{S}} = -1.5$，且 $\\sigma_{\\mathcal{S}} = 1.0$。\n\n5. 在此源模型下，Bayes 后验对数优势比（log-odds）是 $x$ 的线性函数。根据基本的高斯似然和 Bayes' 法则，对数后验优势比的形式为\n$$\n\\log\\frac{\\mathbb{P}(Y=1\\mid X=x)}{\\mathbb{P}(Y=0\\mid X=x)} = \\log\\frac{\\pi_{\\mathcal{S}}}{1-\\pi_{\\mathcal{S}}} + \\frac{\\mu_{1,\\mathcal{S}} - \\mu_{0,\\mathcal{S}}}{\\sigma_{\\mathcal{S}}^2}\\,x - \\frac{\\mu_{1,\\mathcal{S}}^2 - \\mu_{0,\\mathcal{S}}^2}{2\\sigma_{\\mathcal{S}}^2}.\n$$\n因此，一个校准的源模型是\n$$\ns_{\\mathrm{base}}(x) = w_{\\mathcal{S}} x + b_{\\mathcal{S}}, \\quad \\hat{p}_{\\mathrm{base}}(x) = \\sigma\\big(s_{\\mathrm{base}}(x)\\big),\n$$\n其中 $w_{\\mathcal{S}} = (\\mu_{1,\\mathcal{S}} - \\mu_{0,\\mathcal{S}})/\\sigma_{\\mathcal{S}}^2$ 且 $b_{\\mathcal{S}} = \\log\\frac{\\pi_{\\mathcal{S}}}{1-\\pi_{\\mathcal{S}}} - \\frac{\\mu_{1,\\mathcal{S}}^2 - \\mu_{0,\\mathcal{S}}^2}{2\\sigma_{\\mathcal{S}}^2}$。\n\n6. 一个为方差漂移的目标域设计的、专注于排序的域适应评分函数由二次统计量定义，\n$$\ns_{\\mathrm{rank}}(x) = \\gamma x^2 + \\delta, \\quad \\hat{p}_{\\mathrm{rank}}(x) = \\sigma\\big(s_{\\mathrm{rank}}(x)\\big),\n$$\n其中常数固定为 $\\gamma = 1.0$ 和 $\\delta = 2.0$。这一选择有意地优先考虑基于幅值 $\\lvert x \\rvert$ 的判别，而不是以概率校准为目标。注意，对于类条件分布具有相同均值但不同方差的目标域，对数似然比是 $x$ 的二次函数，因此按 $x^2$ 排序与该设置下最强大的检验是一致的。\n\n您将评估这两种方法在三个目标域上的表现，以突显不同类型漂移下的校准与判别之间的权衡。每个目标域 $\\mathcal{T}$ 都有自己的标签先验 $\\pi_{\\mathcal{T}}$ 和类条件高斯参数。对于每个目标案例，从指定的目标分布中生成一个大小为 $n_{\\mathcal{T}}$ 的独立同分布数据集，评估基础模型和专注于排序的模型的 $\\mathrm{AUC}$ 和 $\\mathrm{Brier}$ 分数，然后返回一个布尔值，该布尔值指示专注于排序的模型是否在目标域上严格改善了 $\\mathrm{AUC}$，同时严格恶化了 Brier 分数。\n\n目标域的测试套件：\n\n- 案例 A（方差漂移，均值相等）：$n_{\\mathcal{T}} = 80000$，$\\pi_{\\mathcal{T}} = 0.2$，$X \\mid Y=1 \\sim \\mathcal{N}(0.0, 2.0^2)$，$X \\mid Y=0 \\sim \\mathcal{N}(0.0, 0.5^2)$。此目标域具有相等的均值和不同的方差，有利于基于 $\\lvert x \\rvert$ 的二次排序。\n\n- 案例 B（无漂移）：$n_{\\mathcal{T}} = 80000$，$\\pi_{\\mathcal{T}} = 0.5$，$X \\mid Y=1 \\sim \\mathcal{N}(1.5, 1.0^2)$，$X \\mid Y=0 \\sim \\mathcal{N}(-1.5, 1.0^2)$。此目标域与源域相同。\n\n- 案例 C（仅标签漂移）：$n_{\\mathcal{T}} = 80000$，$\\pi_{\\mathcal{T}} = 0.2$，$X \\mid Y=1 \\sim \\mathcal{N}(1.5, 1.0^2)$，$X \\mid Y=0 \\sim \\mathcal{N}(-1.5, 1.0^2)$。此目标域保持条件分布不变，但改变了类先验。\n\n实现要求：\n\n- 使用源参数解析计算 $w_{\\mathcal{S}}$ 和 $b_{\\mathcal{S}}$。然后，对于每个目标案例，模拟数据，计算 $\\hat{p}_{\\mathrm{base}}$ 和 $\\hat{p}_{\\mathrm{rank}}$ 的 $\\mathrm{AUC}$ 和 $\\mathrm{Brier}$ 分数，并确定是否\n$$\n\\big(\\mathrm{AUC}_{\\mathrm{rank}}  \\mathrm{AUC}_{\\mathrm{base}}\\big) \\;\\;\\text{and}\\;\\; \\big(\\mathrm{Brier}_{\\mathrm{rank}}  \\mathrm{Brier}_{\\mathrm{base}}\\big)\n$$\n成立。使用固定的随机种子以确保结果是确定性的。\n\n- 您的程序必须输出一行，其中包含一个对应于案例 A、B 和 C 的三个布尔值的列表（按此顺序）。第 $i$ 个布尔值为真，当且仅当专注于排序的模型在第 $i$ 个目标案例上的 $\\mathrm{AUC}$ 严格高于基础模型，并且 Brier 分数也严格更高（更差）。输出格式为一行，包含一个用方括号括起来的逗号分隔列表，例如，“[True,False,True]”。\n\n额外的概念性任务（在您的书面解决方案中解决，而不是在代码中）：基于第一性原理，解释为什么在存在漂移的情况下，一种方法可以在提高 $\\mathrm{AUC}$ 的同时恶化 Brier 分数，并提出一个用于域适应的评估指标套件，该套件能联合评估判别能力和校准性，并根据经过充分检验的定义明确论证每个指标的合理性。此问题不涉及物理单位。", "solution": "该问题已经过验证，被确定为统计学习领域一个有效、适定且具有科学依据的练习。它为分析域漂移下概率分类器的判别能力与校准性之间的权衡提供了一个清晰而完整的框架。所有的定义、参数和评估标准都得到了正式和正确的陈述。\n\n解决方案分三个阶段进行。首先，我们确定所提供模型的解析形式。其次，我们分析每个模型在三个目标域上的预期行为。第三，我们解决关于判别和校准指标差异的概念性问题。\n\n**1. 解析模型规范**\n\n问题定义了一个从源域 $\\mathcal{S}$ 派生的基础模型和一个专注于排序的模型。\n\n源域参数为 $\\pi_{\\mathcal{S}} = 0.5$，$\\mu_{1,\\mathcal{S}} = 1.5$，$\\mu_{0,\\mathcal{S}} = -1.5$ 和 $\\sigma_{\\mathcal{S}} = 1.0$。\n\n基础模型的分数函数为 $s_{\\mathrm{base}}(x) = w_{\\mathcal{S}} x + b_{\\mathcal{S}}$，其中参数是从源分布的 Bayes 后验对数优势比派生出来的。\n权重 $w_{\\mathcal{S}}$ 计算如下：\n$$\nw_{\\mathcal{S}} = \\frac{\\mu_{1,\\mathcal{S}} - \\mu_{0,\\mathcal{S}}}{\\sigma_{\\mathcal{S}}^2} = \\frac{1.5 - (-1.5)}{1.0^2} = \\frac{3.0}{1.0} = 3.0\n$$\n偏置 $b_{\\mathcal{S}}$ 计算如下：\n$$\nb_{\\mathcal{S}} = \\log\\frac{\\pi_{\\mathcal{S}}}{1-\\pi_{\\mathcal{S}}} - \\frac{\\mu_{1,\\mathcal{S}}^2 - \\mu_{0,\\mathcal{S}}^2}{2\\sigma_{\\mathcal{S}}^2}\n$$\n给定 $\\pi_{\\mathcal{S}} = 0.5$，第一项 $\\log\\frac{0.5}{1-0.5} = \\log(1) = 0$。\n给定 $\\mu_{1,\\mathcal{S}} = 1.5$ 和 $\\mu_{0,\\mathcal{S}} = -1.5$，第二项的分子是 $\\mu_{1,\\mathcal{S}}^2 - \\mu_{0,\\mathcal{S}}^2 = (1.5)^2 - (-1.5)^2 = 2.25 - 2.25 = 0$。\n因此，$b_{\\mathcal{S}} = 0 - 0 = 0$。\n\n因此，基础模型为：\n$$\ns_{\\mathrm{base}}(x) = 3.0x, \\quad \\hat{p}_{\\mathrm{base}}(x) = \\sigma(3.0x)\n$$\n根据其构造，该模型是源域 $\\mathcal{S}$ 的 Bayes 最优分类器，意味着它在该特定数据分布上是完美校准且具有最大判别能力的。\n\n专注于排序的模型具有给定的固定参数 $\\gamma = 1.0$ 和 $\\delta = 2.0$：\n$$\ns_{\\mathrm{rank}}(x) = 1.0x^2 + 2.0, \\quad \\hat{p}_{\\mathrm{rank}}(x) = \\sigma(x^2 + 2.0)\n$$\n该模型被设计用于在一种特定类型的域漂移下表现良好，即类别具有相同的均值但不同的方差，这使得对数似然比成为 $x$ 的二次函数。\n\n**2. 目标域上的性能分析**\n\n我们对每个目标案例评估条件 $(\\mathrm{AUC}_{\\mathrm{rank}}  \\mathrm{AUC}_{\\mathrm{base}}) \\land (\\mathrm{Brier}_{\\mathrm{rank}}  \\mathrm{Brier}_{\\mathrm{base}})$。\n\n**案例 A（方差漂移）：**\n目标分布的参数为 $\\pi_{\\mathcal{T}} = 0.2$，$X \\mid Y=1 \\sim \\mathcal{N}(0.0, 2.0^2)$ 和 $X \\mid Y=0 \\sim \\mathcal{N}(0.0, 0.5^2)$。\n在这里，类条件均值相等，$\\mu_{1,\\mathcal{T}} = \\mu_{0,\\mathcal{T}} = 0.0$，但方差不同，$\\sigma_{1,\\mathcal{T}}^2 = 4.0$ 和 $\\sigma_{0,\\mathcal{T}}^2 = 0.25$。该目标域的 Bayes 最优分数函数（与对数似然比成正比）是 $x$ 的二次函数。具体来说，由于 $\\sigma_{1,\\mathcal{T}}  \\sigma_{0,\\mathcal{T}}$，较大的 $|x|$ 值为 $Y=1$ 提供了证据。\n-   **判别能力 (AUC)：**专注于排序的模型的得分 $s_{\\mathrm{rank}}(x) = x^2 + 2.0$ 随 $|x|$ 增大而增大，正确地捕捉了此目标域的排序原则。基础模型的得分 $s_{\\mathrm{base}}(x) = 3.0x$ 将表现不佳，因为相同幅值的正负 $x$ 值会被评定为非常不同的分数，即使它们为 $Y=1$ 提供了相同的证据。因此，我们预期 $\\mathrm{AUC}_{\\mathrm{rank}}  \\mathrm{AUC}_{\\mathrm{base}}$。\n-   **校准性 (Brier 分数)：**专注于排序的模型使用任意系数 $\\gamma=1.0, \\delta=2.0$，这些系数并非从目标分布的参数（$\\pi_{\\mathcal{T}}, \\mu_i, \\sigma_i$）推导得出。因此，概率 $\\hat{p}_{\\mathrm{rank}}(x)$ 将不会校准到真实的后验概率 $\\mathbb{P}(Y=1|X=x)$，从而导致较高的 Brier 分数。基础模型同样是错误设定的，也会是未校准的。然而，专注于排序的模型虽然在排序上更优，但很可能严重失准，导致更高（更差）的 Brier 分数。我们预期 $\\mathrm{Brier}_{\\mathrm{rank}}  \\mathrm{Brier}_{\\mathrm{base}}$。\n-   **结论：**该条件预期为 **True**。\n\n**案例 B（无漂移）：**\n目标分布与源分布相同。\n-   **判别能力 (AUC)：**基础模型 $s_{\\mathrm{base}}(x)$ 是此分布的 Bayes 最优分类器，将达到可能的最大 AUC。专注于排序的模型 $s_{\\mathrm{rank}}(x)$ 是错误设定的，因为最优判别器是线性的，而不是二次的。我们预期 $\\mathrm{AUC}_{\\mathrm{rank}}  \\mathrm{AUC}_{\\mathrm{base}}$。\n-   **校准性 (Brier 分数)：**基础模型根据其构造是完美校准的，并将达到可能的最低 Brier 分数。专注于排序的模型是错误设定的，校准性会很差，导致 Brier 分数高得多。\n-   **结论：**条件的第一个部分 $\\mathrm{AUC}_{\\mathrm{rank}}  \\mathrm{AUC}_{\\mathrm{base}}$ 不成立。该条件预期为 **False**。\n\n**案例 C（仅标签漂移）：**\n类条件分布与源域相同，但类先验变为 $\\pi_{\\mathcal{T}} = 0.2$。\n-   **判别能力 (AUC)：**AUC 是一种衡量排序的指标，对类别平衡（标签漂移）不敏感。实例的最优排序由似然比 $p(x|Y=1)/p(x|Y=0)$ 决定，该比率与源域相比没有变化。因此，线性分数 $s_{\\mathrm{base}}(x)$ 仍然是最优的排序器。二次分数 $s_{\\mathrm{rank}}(x)$ 仍然是错误设定的。因此，我们预期 $\\mathrm{AUC}_{\\mathrm{rank}}  \\mathrm{AUC}_{\\mathrm{base}}$。\n-   **校准性 (Brier 分数)：**基础模型的概率 $\\hat{p}_{\\mathrm{base}}(x) = \\sigma(3.0x)$ 通过截距 $b_{\\mathcal{S}}=0$ 隐式地假设了源先验 $\\pi_{\\mathcal{S}}=0.5$。针对目标域的正确校准模型应为 $\\hat{p}(x) = \\sigma(3.0x + b_{\\mathcal{T}})$，其中 $b_{\\mathcal{T}} = \\log(\\pi_{\\mathcal{T}}/(1-\\pi_{\\mathcal{T}})) = \\log(0.2/0.8) \\approx -1.386$。由于其截距错误，基础模型现在是失准的。专注于排序的模型也是失准的。然而，基础模型远比排序模型更接近真实形式。\n-   **结论：**条件的第一个部分 $\\mathrm{AUC}_{\\mathrm{rank}}  \\mathrm{AUC}_{\\mathrm{base}}$ 不成立。该条件预期为 **False**。\n\n**3. 概念性任务：判别与校准及指标套件**\n\n**为什么 AUC 会在 Brier 分数恶化的情况下增加**\n\n这种现象是这两种指标所评估的不同属性的直接结果。\n-   **AUC (判别能力)：**ROC 曲线下面积是一种基于排序的指标。它对于分类器分数的任何严格保序变换都是不变的。也就是说，如果一个模型输出分数 $s(x)$，其 AUC 与另一个输出分数 $f(s(x))$ 的模型相同，其中 $f$ 是任何严格递增函数。AUC 仅衡量分类器是否一致地为正实例分配比负实例更高的分数。\n-   **Brier 分数 (校准性)：**Brier 分数 $\\mathbb{E}[(\\hat{p}(X) - Y)^2]$ 是一种恰当评分规则，用于衡量预测概率的均方误差。它对 $\\hat{p}(x)$ 的实际数值高度敏感。如果一个模型对于它预测概率为（比如说）0.8 的所有实例，其中大约 80% 确实是正例，那么这个模型就是良好校准的。对分数 $s(x)$ 应用任意的单调变换 $f$ 通常会破坏校准性，因为新的“概率” $\\sigma(f(s(x)))$ 将不再对应于真实的后验概率 $\\mathbb{P}(Y=1|X=x)$。\n\n在域漂移下，一种新的特征变换（如案例 A 中的二次分数）可能能更好地分离目标域中的类别，从而改善排序并提高 AUC。然而，如果产生的分数不是目标分布上对数后验优势比的恰当表示，应用 sigmoid 函数将产生失准的概率。这会导致更高（更差）的 Brier 分数，从而产生观察到的权衡：以恶化校准性为代价提高判别能力。\n\n**用于域适应的建议评估指标套件**\n\n为了在域适应后全面评估分类器的性能，需要一套能够分别和联合评估判别能力和校准性的指标。\n\n1.  **判别能力指标：ROC 曲线下面积 (AUC)**\n    -   **论证理由：**作为衡量模型排序能力的标准指标，AUC 对于理解模型是否能区分不同类别至关重要。其对分数变换和类别流行度的不变性使其成为纯粹判别能力的一个稳健指标，而判别能力是适应的主要目标之一。\n\n2.  **校准性指标：期望校准误差 (ECE)**\n    -   **论证理由：**ECE 通过将预测根据其置信度（预测概率）划分到不同的箱（bin）中，并计算每个箱中平均置信度与观察到的准确率之差的加权平均值，从而直接衡量失准程度。形式上，$\\mathrm{ECE} = \\sum_{m=1}^{M} \\frac{|B_m|}{n} |\\mathrm{acc}(B_m) - \\mathrm{conf}(B_m)|$。与 Brier 分数不同，ECE 孤立了校准误差，使其在诊断特定于校准的失败时具有很高的可解释性。一个好的适应方法不应显著增加 ECE。\n\n3.  **整体质量指标：Brier 分数**\n    -   **论证理由：**Brier 分数是一种恰当评分规则，这意味着模型被激励去报告其真实信念以最小化该分数。它巧妙地结合了判别能力和校准性两个方面。Brier 分数可以分解为可靠性（校准性）、分辨率（判别能力的一个方面）和不确定性分量。一个低的 Brier 分数表明模型既有判别力（高分辨率）又校准良好（低可靠性误差）。它可以作为概率预测整体质量的绝佳单值摘要。\n\n这套 $\\{\\mathrm{AUC}, \\mathrm{ECE}, \\mathrm{Brier\\ Score}\\}$ 指标提供了一个全面的视角。一个理想的适应方法应在提高 AUC 的同时保持 ECE 和 Brier 分数较低。观察到 AUC 的增加伴随着 ECE 和 Brier 分数的增加，明确地表明了此问题旨在强调的权衡关系。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import expit as sigmoid\n\ndef solve():\n    \"\"\"\n    Solves the problem by simulating three target domains and evaluating two models\n    on each, checking for a discrimination-calibration trade-off.\n    \"\"\"\n\n    # Set a fixed random seed for reproducibility\n    np.random.seed(0)\n\n    # --- Analytical Parameters ---\n    # Source parameters\n    mu1_s, mu0_s, sigma_s, pi_s = 1.5, -1.5, 1.0, 0.5\n    \n    # Base model parameters (derived analytically)\n    w_s = (mu1_s - mu0_s) / sigma_s**2\n    b_s = np.log(pi_s / (1.0 - pi_s)) - (mu1_s**2 - mu0_s**2) / (2 * sigma_s**2)\n\n    # Rank model parameters (given)\n    gamma, delta = 1.0, 2.0\n\n    # Test suite of target domain parameters\n    test_cases = [\n        # Case A: Variance shift, equal means\n        {'name': 'A', 'n_t': 80000, 'pi_t': 0.2, 'mu1_t': 0.0, 'sigma1_t': 2.0, 'mu0_t': 0.0, 'sigma0_t': 0.5},\n        # Case B: No shift\n        {'name': 'B', 'n_t': 80000, 'pi_t': 0.5, 'mu1_t': 1.5, 'sigma1_t': 1.0, 'mu0_t': -1.5, 'sigma0_t': 1.0},\n        # Case C: Label shift only\n        {'name': 'C', 'n_t': 80000, 'pi_t': 0.2, 'mu1_t': 1.5, 'sigma1_t': 1.0, 'mu0_t': -1.5, 'sigma0_t': 1.0},\n    ]\n\n    results = []\n\n    for case in test_cases:\n        # --- Data Generation ---\n        n_t, pi_t = case['n_t'], case['pi_t']\n        n1_t = int(n_t * pi_t)\n        n0_t = n_t - n1_t\n\n        x1_t = np.random.normal(loc=case['mu1_t'], scale=case['sigma1_t'], size=n1_t)\n        x0_t = np.random.normal(loc=case['mu0_t'], scale=case['sigma0_t'], size=n0_t)\n\n        x_target = np.concatenate((x1_t, x0_t))\n        y_target = np.concatenate((np.ones(n1_t), np.zeros(n0_t)))\n\n        # --- Model Evaluation ---\n        # Base model\n        s_base = w_s * x_target + b_s\n        p_base = sigmoid(s_base)\n        \n        # Rank-focused model\n        s_rank = gamma * x_target**2 + delta\n        p_rank = sigmoid(s_rank)\n\n        # --- Metric Calculation ---\n        # Brier score\n        brier_base = np.mean((p_base - y_target)**2)\n        brier_rank = np.mean((p_rank - y_target)**2)\n        \n        # AUC calculation (using the efficient rank-based method)\n        def calculate_auc(y_true, y_score):\n            y_true = np.asarray(y_true, dtype=bool)\n            \n            n1 = np.count_nonzero(y_true)\n            n0 = len(y_true) - n1\n            \n            if n1 == 0 or n0 == 0:\n                return 0.5 # Or handle as undefined, 0.5 is a common convention\n            \n            # Use argsort to get ranks efficiently\n            order = np.argsort(y_score)\n            y_true_sorted = y_true[order]\n            \n            # Sum of ranks for the positive class\n            # np.where returns a tuple, we need the first element\n            pos_ranks_sum = np.sum(np.where(y_true_sorted)[0] + 1)\n            \n            # Wilcoxon-Mann-Whitney U statistic relationship\n            auc = (pos_ranks_sum - n1 * (n1 + 1) / 2) / (n1 * n0)\n            return auc\n\n        auc_base = calculate_auc(y_target, s_base)\n        auc_rank = calculate_auc(y_target, s_rank)\n\n        # --- Condition Check ---\n        # Did the rank model strictly improve AUC and strictly worsen Brier?\n        trade_off_occurred = (auc_rank  auc_base) and (brier_rank  brier_base)\n        results.append(trade_off_occurred)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3188990"}]}