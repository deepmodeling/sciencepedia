{"hands_on_practices": [{"introduction": "崩溃点是稳健统计学中的一个核心概念，它量化了估计器对数据污染的恢复能力。本练习通过要求您确定“破坏”常见位置估计器所需的最小异常值比例来探索这一基本思想，从而建立对何种统计程序是稳健的直观理解。[@problem_id:3171418]", "problem": "考虑一维稳健统计学习中的epsilon污染模型，其中大小为 $n$ 的训练样本包含 $(1-\\epsilon)n$ 个从基础分布中抽取的干净点和 $\\epsilon n$ 个对抗性离群值。在本问题中，将基础分布视为在 $0$ 处的退化分布，因此干净点均为 $0$。同时，让对抗方将所有离群值放置在一个大的正值 $M$ 处。这种最坏情况下的污染使得分析变为纯粹的组合问题，并避免了随机性。\n\n定义三个位置估计量：\n1. 样本均值 $\\bar{x}$。\n2. 对称τ截尾均值，其中 $0 \\le \\tau  \\frac{1}{2}$。该方法截去 $k = \\lfloor \\tau n \\rfloor$ 个最小值和 $k$ 个最大值，并对剩余的 $n - 2k$ 个观测值求平均。对于一个排序后的样本 $x_{(1)} \\le \\cdots \\le x_{(n)}$，截尾均值为\n$$\n\\bar{x}_{\\mathrm{trim}} = \\frac{1}{n - 2k} \\sum_{i=k+1}^{n-k} x_{(i)}.\n$$\n3. 由Tukey深度定义的Tukey中位数（在一维情况下，这等于样本中位数）。当 $n$ 为奇数时，它是 $x_{((n+1)/2)}$；当 $n$ 为偶数时，它是 $\\frac{1}{2}\\left(x_{(n/2)} + x_{(n/2+1)}\\right)$。\n\n使用稳健统计学中崩溃点的基本定义：对于一个视为泛函 $T$ 的估计量，其在分布 $P$ 上的崩溃点是指，能够通过对抗性污染使估计量被驱动至无界的最小污染水平 $\\epsilon$，即\n$$\n\\varepsilon^\\star(T, P) = \\inf \\left\\{\\epsilon \\in [0,1]: \\sup_Q \\left\\| T\\left( (1-\\epsilon)P + \\epsilon Q \\right) \\right\\| = \\infty \\right\\},\n$$\n其中 $Q$ 遍及所有可能的污染分布。在上述显式构造的有限样本设置中，这简化为求解最小的离群值比例 $\\epsilon$（等价于整数计数 $m = \\epsilon n$），使得当 $M \\to \\infty$ 时，估计量的值无限增长。\n\n您的任务是：\n- 从上述稳健崩溃点定义和干净点在 $0$、对抗性离群值在 $M$ 的显式污染构造出发，推导在有限样本设置下，当 $M \\to \\infty$ 时，使每个估计量无界所需的最小污染比例 $\\epsilon^\\star$。在适用时，将答案表示为 $n$ 和 $\\tau$ 的函数，并对因离群值整数计数所需的所有取整操作给出合理解释。\n- 同时，确定这三个估计量的渐近崩溃点，解释大样本极限下的epsilon污染模型，并提供不依赖于 $n$ 的值。\n- 实现一个确定性程序，对于每个测试用例 $(n,\\tau)$，返回两个三元组：\n  - 渐近崩溃点 $[\\varepsilon^\\star(\\text{mean}), \\varepsilon^\\star(\\text{trimmed mean}), \\varepsilon^\\star(\\text{Tukey median})]$。\n  - 有限样本污染阈值 $[\\epsilon^\\star_{\\text{mean}}(n), \\epsilon^\\star_{\\text{trim}}(n,\\tau), \\epsilon^\\star_{\\text{Tukey}}(n)]$。\n\n测试套件：\n- 使用以下参数集 $(n,\\tau)$：\n  1. $(100, 0.1)$ 作为一般情况。\n  2. $(101, 0.1)$ 用于测试奇数 $n$ 对中位数的影响。\n  3. $(100, 0.0)$ 用于测试截尾消失的边界情况。\n  4. $(20, 0.2)$ 用于测试中等截尾程度下的离散取整效应。\n  5. $(2, 0.0)$ 用于测试最小的偶数样本量。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，不含空格。每个测试用例贡献一对包含三个浮点数的列表：第一个列表是按上述顺序排列的渐近崩溃点，第二个列表是按相同顺序排列的有限样本阈值。总输出是所有测试用例的这些对组成的列表。例如，格式应如下所示\n$$\n\\left[\\left[[a_1,a_2,a_3],[b_1,b_2,b_3]\\right],\\left[[\\cdots],[\\cdots]\\right],\\ldots\\right]\n$$\n其中 $a_i$ 和 $b_i$ 是十进制数。", "solution": "该问题是有效的，因为它科学地基于稳健统计学的原理，定义清晰、问题明确，并以客观、正式的语言表述。分析位置估计量的崩溃点是一个标准的理论问题。我们将着手推导所需的量。\n\n该问题定义了一个特定的污染场景：对于一个大小为 $n$ 的样本，我们有 $n-m$ 个值为 $0$ 的“干净”数据点和 $m$ 个值为一个大的正数 $M$ 的“对抗性”离群点。污染比例为 $\\epsilon = m/n$。我们寻求导致估计量的值在 $M \\to \\infty$ 时变得无界的最小整数离群点数 $m$。有限样本崩溃点就是这个最小比例 $\\epsilon^\\star = m/n$。渐近崩溃点是当 $n \\to \\infty$ 时该比例的极限。\n\n排序后的样本，记为 $x_{(1)} \\le x_{(2)} \\le \\cdots \\le x_{(n)}$，将由 $n-m$ 个零和 $m$ 个值 $M$ 组成。具体来说，$x_{(i)} = 0$ 对 $i \\le n-m$ 成立，而 $x_{(i)} = M$ 对 $i  n-m$ 成立。\n\n**1. 样本均值 ($\\bar{x}$)**\n\n样本均值定义为 $\\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i$。\n对于给定的污染样本，总和由 $n-m$ 个等于 $0$ 的项和 $m$ 个等于 $M$ 的项组成。\n样本均值的值为：\n$$\n\\bar{x} = \\frac{1}{n} \\left( (n-m) \\cdot 0 + m \\cdot M \\right) = \\frac{m M}{n}\n$$\n要使估计量在 $M \\to \\infty$ 时趋于无穷大， $M$ 的系数必须非零。\n$$\n\\lim_{M \\to \\infty} \\frac{m M}{n} = \\infty \\quad \\iff \\quad \\frac{m}{n}  0 \\quad \\iff \\quad m  0\n$$\n满足 $m  0$ 的最小整数 $m$ 是 $m=1$。\n\n- **有限样本崩溃点**：最小离群点数为 $m=1$。相应的比例为：\n$$ \\epsilon^\\star_{\\text{mean}}(n) = \\frac{1}{n} $$\n- **渐近崩溃点**：取样本量 $n$ 趋于无穷大的极限：\n$$ \\varepsilon^\\star(\\text{mean}) = \\lim_{n \\to \\infty} \\frac{1}{n} = 0 $$\n\n**2. 对称τ截尾均值 ($\\bar{x}_{\\mathrm{trim}}$)**\n\nτ截尾均值通过移除 $k = \\lfloor \\tau n \\rfloor$ 个最小值和 $k$ 个最大值，并对剩余的 $n-2k$ 个点求平均来计算。其公式为：\n$$\n\\bar{x}_{\\mathrm{trim}} = \\frac{1}{n - 2k} \\sum_{i=k+1}^{n-k} x_{(i)}\n$$\n估计量的值由点 $x_{(k+1)}, \\dots, x_{(n-k)}$ 决定。在我们的设置中，这些点要么是 $0$，要么是 $M$。如果求和中的所有点都是 $0$，估计量将是有界的（等于 $0$）。如果求和中至少有一个点是 $M$，它将变得无界。\n\n值为 $M$ 的离群值占据了排序后样本中最大的 $m$ 个位置：$x_{(n-m+1)}, \\dots, x_{(n)}$。\n最大的 $k$ 个值被截去。它们是 $x_{(n-k+1)}, \\dots, x_{(n)}$。\n如果离群值的数量 $m$ 小于或等于高端截尾点的数量 $k$（即 $m \\le k$），那么所有离群值都将是截尾集合的一部分。剩余点的最大索引是 $n-k$。离群值的最小索引是 $n-m+1$。如果 $n-m+1  n-k$，或者说 $k+1  m$，则所有离群值都被截去。\n当至少有一个离群值*未*被截去时，就会发生崩溃。这种情况发生在离群值的数量 $m$ 大到足以“溢出”到被平均的样本部分时。这要求离群值的数量大于从顶端截去的点的数量 $k$。\n因此，崩溃的条件是 $m  k$。\n满足此条件的最小整数 $m$ 是 $m = k+1$。代入 $k = \\lfloor \\tau n \\rfloor$，最小离群点数为 $m = \\lfloor \\tau n \\rfloor + 1$。\n\n- **有限样本崩溃点**：最小污染比例为：\n$$ \\epsilon^\\star_{\\text{trim}}(n, \\tau) = \\frac{\\lfloor \\tau n \\rfloor + 1}{n} $$\n- **渐近崩溃点**：我们取 $n \\to \\infty$ 的极限。利用性质 $\\lim_{n\\to\\infty} \\frac{\\lfloor \\tau n \\rfloor}{n} = \\tau$：\n$$ \\varepsilon^\\star(\\text{trimmed mean}) = \\lim_{n \\to \\infty} \\frac{\\lfloor \\tau n \\rfloor + 1}{n} = \\lim_{n \\to \\infty} \\left(\\frac{\\lfloor \\tau n \\rfloor}{n} + \\frac{1}{n}\\right) = \\tau + 0 = \\tau $$\n\n**3. Tukey中位数（样本中位数）**\n\n样本中位数的定义取决于 $n$ 的奇偶性。\n如果中位数的值为 $M$ 或包含一个与 $M$ 成比例的项，就会发生崩溃，这种情况发生于中心数据点之一是值为 $M$ 的离群值时。\n\n- **情况1：$n$ 是奇数**。设 $n = 2j+1$。中位数是唯一的中心值 $x_{((n+1)/2)} = x_{(j+1)}$。如果这个点是离群值，就会发生崩溃。离群值是 $x_{(n-m+1)}, \\dots, x_{(n)}$。因此，我们需要中位数的索引在离群值范围内：\n$$ \\frac{n+1}{2}  n-m \\implies m  n - \\frac{n+1}{2} = \\frac{n-1}{2} $$\n因为 $n$ 是奇数，所以 $(n-1)/2 = j$ 是一个整数。满足 $m  j$ 的最小整数 $m$ 是 $m = j+1 = (n+1)/2$。\n\n- **情况2：$n$ 是偶数**。设 $n = 2j$。中位数是两个中心值的平均值，$\\frac{1}{2}(x_{(n/2)} + x_{(n/2+1)}) = \\frac{1}{2}(x_{(j)} + x_{(j+1)})$。如果这两个点中至少有一个是 $M$，则估计量变得无界。如果索引较高的点 $x_{(j+1)}$ 是一个离群值，则可以保证这一点。条件是：\n$$ \\frac{n}{2}+1  n-m \\implies m  n - \\left(\\frac{n}{2}+1\\right) = \\frac{n}{2}-1 $$\n因为 $n$ 是偶数，所以 $n/2-1 = j-1$ 是一个整数。满足 $m  j-1$ 的最小整数 $m$ 是 $m = j = n/2$。\n\n我们可以统一这两种情况。对于奇数 $n$，最小离群点数为 $m=(n+1)/2$；对于偶数 $n$，为 $m=n/2$。这对应于 $m = \\lceil n/2 \\rceil$。\n\n- **有限样本崩溃点**：最小污染比例为：\n$$ \\epsilon^\\star_{\\text{Tukey}}(n) = \\frac{\\lceil n/2 \\rceil}{n} $$\n- **渐近崩溃点**：在大 $n$ 极限下，$\\lceil n/2 \\rceil \\approx n/2$。\n$$ \\varepsilon^\\star(\\text{Tukey median}) = \\lim_{n \\to \\infty} \\frac{\\lceil n/2 \\rceil}{n} = \\frac{1}{2} = 0.5 $$\n\n**结果总结**\n\n| 估计量 | 渐近崩溃点 ($\\varepsilon^\\star$) | 有限样本崩溃点 ($\\epsilon^\\star$) |\n| :--- | :---: | :---: |\n| 样本均值 | $0$ | $\\frac{1}{n}$ |\n| 截尾均值 | $\\tau$ | $\\frac{\\lfloor \\tau n \\rfloor + 1}{n}$ |\n| Tukey中位数 | $0.5$ | $\\frac{\\lceil n/2 \\rceil}{n}$ |\n\n这些公式被实现用来计算给定测试用例的结果。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Calculates the asymptotic and finite-sample breakdown points for three estimators\n    under an epsilon-contamination model for several test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (100, 0.1),  # General case\n        (101, 0.1),  # Odd n effects on the median\n        (100, 0.0),  # Trimming vanishes, should equal mean\n        (20, 0.2),   # Discrete rounding effects\n        (2, 0.0),    # Smallest even sample size\n    ]\n\n    all_results = []\n    for n, tau in test_cases:\n        # 1. Asymptotic Breakdown Points\n        # These are derived theoretical limits as n -> infinity.\n        # Mean: 0\n        # Trimmed Mean: tau\n        # Median: 0.5\n        asymptotic_bps = [0.0, tau, 0.5]\n\n        # 2. Finite-Sample Breakdown Points\n        # These depend on the sample size n and integer arithmetic.\n        \n        # For the sample mean, 1 outlier is sufficient to cause breakdown.\n        # Minimal fraction of outliers = 1/n.\n        finite_mean_bp = 1 / n\n\n        # For the trimmed mean, breakdown occurs if outliers exceed the trim count k.\n        # k = floor(tau * n). Minimal outliers m = k + 1.\n        # Minimal fraction = (k + 1) / n.\n        k = np.floor(tau * n)\n        finite_trimmed_mean_bp = (k + 1) / n\n\n        # For the median, breakdown occurs if more than half the points are outliers.\n        # Minimal outliers m = ceil(n / 2).\n        # Minimal fraction = ceil(n/2) / n.\n        finite_median_bp = np.ceil(n / 2) / n\n\n        finite_bps = [finite_mean_bp, finite_trimmed_mean_bp, finite_median_bp]\n        \n        all_results.append([asymptotic_bps, finite_bps])\n\n    # Format the final output string to match the problem specification\n    # precisely (list of lists, no spaces).\n    case_strings = []\n    for async_res, finite_res in all_results:\n        async_str = f\"[{','.join(map(str, async_res))}]\"\n        finite_str = f\"[{','.join(map(str, finite_res))}]\"\n        case_strings.append(f\"[{async_str},{finite_str}]\")\n    \n    final_output = f\"[{','.join(case_strings)}]\"\n    \n    # Final print statement in the exact required format.\n    print(final_output)\n\nsolve()\n```", "id": "3171418"}, {"introduction": "从一般的数据污染转向有针对性的对抗性攻击，我们可以为模型的稳健性提供形式化的保证。本练习介绍了可验证鲁棒性半径的概念，它利用向量范数之间的对偶关系来计算数据点周围的一个“安全”区域，在该区域内线性分类器的预测保证是稳定的。您将比较 $\\ell_1$ 和 $\\ell_2$ 扰动的可验证半径，从而获得构建可验证防御关键方法的实践洞见。[@problem_id:3171496]", "problem": "给定一个二维二元分类器，由线性评分函数 $f(\\mathbf{x}) = \\mathbf{w}^{\\top} \\mathbf{x} + b$ 定义，其参数 $\\mathbf{w} \\in \\mathbb{R}^{2}$ 和 $b \\in \\mathbb{R}$ 是固定的。分类由 $f(\\mathbf{x})$ 的符号决定，标签为 $y \\in \\{-1, +1\\}$，带符号间隔为 $m(\\mathbf{x}, y) = y \\cdot f(\\mathbf{x})$。考虑在 $\\mathbf{x}$ 周围的 $\\ell_{p}$ 范数球内受约束的对抗性扰动 $\\boldsymbol{\\delta} \\in \\mathbb{R}^{2}$，其中对抗者试图通过选择 $\\boldsymbol{\\delta}$ 使 $f(\\mathbf{x} + \\boldsymbol{\\delta}) \\leq 0$ 来改变分类符号。通过 Hölder 不等式建立的对偶范数之间的联系提供了一种通过为所需扰动大小提供下界来验证鲁棒性的方法。您必须构建一个简单的二维数据集，应用该固定的线性分类器，并使用梯度 $\\nabla_{\\mathbf{x}} f(\\mathbf{x})$ 和对偶范数关系，比较在 $\\ell_{1}$ 和 $\\ell_{2}$ 扰动模型下的可验证鲁棒性。\n\n使用的基本事实：\n- Hölder 不等式和对偶范数：对于任意 $\\mathbf{a}, \\mathbf{b} \\in \\mathbb{R}^{d}$，有 $|\\mathbf{a}^{\\top} \\mathbf{b}| \\leq \\|\\mathbf{a}\\|_{q} \\|\\mathbf{b}\\|_{p}$，其中 $1/p + 1/q = 1$。$p=1$ 的对偶是 $q=\\infty$，而 $p=2$ 的对偶是 $q=2$。\n- 对于线性模型 $f(\\mathbf{x}) = \\mathbf{w}^{\\top} \\mathbf{x} + b$，其关于输入的梯度为 $\\nabla_{\\mathbf{x}} f(\\mathbf{x}) = \\mathbf{w}$。\n\n构建数据集：\n- 为分类器使用以下固定参数：$\\mathbf{w} = (0.8, -0.6)$ 和 $b = 0.1$。\n- 考虑 $\\mathbb{R}^{2}$ 中的以下五个带标签的点：\n    1. $\\mathbf{x}_{1} = (2.0, -1.0)$，标签为 $y_{1} = +1$。\n    2. $\\mathbf{x}_{2} = (0.5, 0.5)$，标签为 $y_{2} = -1$。\n    3. $\\mathbf{x}_{3} = (-1.0, 2.0)$，标签为 $y_{3} = -1$。\n    4. $\\mathbf{x}_{4} = (0.125, 0.0)$，标签为 $y_{4} = +1$。\n    5. $\\mathbf{x}_{5} = (-0.125, 0.0)$，标签为 $y_{5} = +1$。\n\n任务：\n- 对于每个测试点 $(\\mathbf{x}_{i}, y_{i})$，计算带符号间隔 $m_{i} = y_{i} \\cdot f(\\mathbf{x}_{i})$。\n- 使用梯度 $\\mathbf{g} = \\nabla_{\\mathbf{x}} f(\\mathbf{x}) = \\mathbf{w}$ 和 Hölder 不等式提供的对偶范数关系，确定针对 $\\ell_{1}$ 和 $\\ell_{2}$ 对抗者的可验证鲁棒性半径。可验证半径是最大的 $\\epsilon$，使得对于所有满足 $\\|\\boldsymbol{\\delta}\\|_{p} \\leq \\epsilon$ 的扰动 $\\boldsymbol{\\delta}$ 都不能改变 $f(\\mathbf{x})$ 的符号。如果 $m_{i} \\leq 0$，则可验证半径为 $0$，因为该点已经被错误分类或位于决策边界上。将每个点的 $\\ell_{1}$ 和 $\\ell_{2}$ 可验证半径表示为非负实数。\n- 将每个计算出的半径四舍五入到六位小数。\n\n测试套件：\n- 上述五个点涵盖了具有较大正间隔的一般情况、一个被错误分类的点（负间隔）、另一个具有中等间隔的正确分类点、一个具有较小正间隔的近边界情况，以及一个间隔恰好为零的边界情况。这为典型情况和边界条件提供了覆盖。\n\n要求的最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个测试用例贡献一个两元素列表 $[\\text{radius}_{\\ell_{1}}, \\text{radius}_{\\ell_{2}}]$，顺序与上面的测试用例相同。例如，输出应如下所示：\n$[[r_{1,\\ell_{1}}, r_{1,\\ell_{2}}],[r_{2,\\ell_{1}}, r_{2,\\ell_{2}}],\\dots,[r_{5,\\ell_{1}}, r_{5,\\ell_{2}}]]$\n所有半径必须是四舍五入到六位小数的浮点数。不应打印其他任何文本。", "solution": "该问题陈述被评估为具有科学依据、定义明确且客观。它为解决线性模型对抗性鲁棒性中的一个标准问题提供了一套完整且一致的定义、参数和数据。任务是为给定的线性分类器和一组数据点计算可验证鲁棒性半径，这是一个定义明确的数学过程。因此，该问题被视为**有效**。\n\n解决方案首先推导线性分类器可验证鲁棒性半径的通用公式，然后将此公式应用于数据集中提供的特定点。\n\n线性分类器由一个评分函数 $f(\\mathbf{x}) = \\mathbf{w}^{\\top} \\mathbf{x} + b$ 定义，其中 $\\mathbf{x} \\in \\mathbb{R}^{d}$ 是输入向量，$\\mathbf{w} \\in \\mathbb{R}^{d}$ 是权重向量， $b \\in \\mathbb{R}$ 是偏置。预测标签为 $\\text{sign}(f(\\mathbf{x}))$。真实标签用 $y \\in \\{-1, +1\\}$ 表示。如果 $y \\cdot f(\\mathbf{x})  0$，则点 $(\\mathbf{x}, y)$ 被正确分类。量 $m(\\mathbf{x}, y) = y \\cdot f(\\mathbf{x})$ 是带符号间隔。\n\n对抗性鲁棒性关注的是分类器预测在输入受到小扰动时的稳定性。对抗者试图找到一个具有小范数 $\\|\\boldsymbol{\\delta}\\|_{p}$ 的扰动 $\\boldsymbol{\\delta}$，以导致错误分类。对于一个正确分类的点，这意味着找到一个 $\\boldsymbol{\\delta}$，使得分类器输出的符号翻转，即 $y \\cdot f(\\mathbf{x} + \\boldsymbol{\\delta}) \\leq 0$。\n\n可验证鲁棒性半径 $\\epsilon_p$ 是这样一个最大值：对于所有满足 $\\|\\boldsymbol{\\delta}\\|_{p} \\leq \\epsilon_p$ 的扰动 $\\boldsymbol{\\delta}$，分类保持不变，即 $y \\cdot f(\\mathbf{x} + \\boldsymbol{\\delta})  0$。\n\n对于线性模型，在扰动 $\\boldsymbol{\\delta}$ 下评分函数的变化可以由一阶近似精确给出：\n$$f(\\mathbf{x} + \\boldsymbol{\\delta}) = \\mathbf{w}^{\\top} (\\mathbf{x} + \\boldsymbol{\\delta}) + b = (\\mathbf{w}^{\\top}\\mathbf{x} + b) + \\mathbf{w}^{\\top}\\boldsymbol{\\delta} = f(\\mathbf{x}) + \\nabla_{\\mathbf{x}}f(\\mathbf{x})^{\\top} \\boldsymbol{\\delta}$$\n由于 $\\nabla_{\\mathbf{x}}f(\\mathbf{x}) = \\mathbf{w}$，我们有 $f(\\mathbf{x} + \\boldsymbol{\\delta}) = f(\\mathbf{x}) + \\mathbf{w}^{\\top}\\boldsymbol{\\delta}$。\n\n为确定鲁棒性，我们必须找到范数 $\\|\\boldsymbol{\\delta}\\|_p \\leq \\epsilon$ 的扰动 $\\boldsymbol{\\delta}$，它能使 $y \\cdot f(\\mathbf{x} + \\boldsymbol{\\delta})$ 在负方向上变化最大。\n$$y \\cdot f(\\mathbf{x} + \\boldsymbol{\\delta}) = y \\cdot (f(\\mathbf{x}) + \\mathbf{w}^{\\top}\\boldsymbol{\\delta}) = y \\cdot f(\\mathbf{x}) + y \\cdot (\\mathbf{w}^{\\top}\\boldsymbol{\\delta})$$\n项 $y \\cdot f(\\mathbf{x})$ 是初始的带符号间隔 $m(\\mathbf{x}, y)$。对抗者试图使项 $y \\cdot (\\mathbf{w}^{\\top}\\boldsymbol{\\delta})$ 尽可能为负。\n根据 Hölder 不等式，我们有 $|\\mathbf{a}^{\\top}\\mathbf{b}| \\leq \\|\\mathbf{a}\\|_{q}\\|\\mathbf{b}\\|_{p}$，其中 $1/p + 1/q = 1$。这意味着 $\\mathbf{w}^{\\top}\\boldsymbol{\\delta}$ 的最小值为 $-\\|\\mathbf{w}\\|_{q}\\|\\boldsymbol{\\delta}\\|_{p}$。\n因此，$y \\cdot f(\\mathbf{x} + \\boldsymbol{\\delta})$ 的最小值为：\n$$\\min_{\\|\\boldsymbol{\\delta}\\|_p \\leq \\epsilon} \\left( y \\cdot f(\\mathbf{x} + \\boldsymbol{\\delta}) \\right) = y \\cdot f(\\mathbf{x}) - |y| \\cdot \\|\\mathbf{w}\\|_q \\epsilon = m(\\mathbf{x}, y) - \\|\\mathbf{w}\\|_q \\epsilon$$\n只要这个最小值大于 $0$，分类器就保证是鲁棒的：\n$$m(\\mathbf{x}, y) - \\|\\mathbf{w}\\|_q \\epsilon  0 \\implies \\epsilon  \\frac{m(\\mathbf{x}, y)}{\\|\\mathbf{w}\\|_q}$$\n可验证半径 $\\epsilon_p$ 是阈值 $\\frac{m(\\mathbf{x}, y)}{\\|\\mathbf{w}\\|_q}$。此公式仅对正确分类的点（即 $m(\\mathbf{x}, y)  0$）有效。如果一个点被错误分类或在边界上（$m(\\mathbf{x}, y) \\leq 0$），则不需要任何扰动即可满足非正间隔条件，因此可验证半径为 $0$。\n因此，可验证半径的通用公式为：\n$$\\epsilon_p(\\mathbf{x}, y) = \\max\\left(0, \\frac{y \\cdot f(\\mathbf{x})}{\\|\\mathbf{w}\\|_q}\\right)$$\n其中 $1/p + 1/q = 1$。\n\n问题提供了分类器参数：$\\mathbf{w} = (0.8, -0.6)$ 和 $b = 0.1$。\n我们需要计算针对 $\\ell_1$ 和 $\\ell_2$ 扰动的可验证半径。\n对于 $\\ell_1$ 扰动（$p=1$），对偶范数是 $\\ell_\\infty$ 范数（$q=\\infty$）。\n$$\\|\\mathbf{w}\\|_{\\infty} = \\max(|0.8|, |-0.6|) = 0.8$$\n对于 $\\ell_2$ 扰动（$p=2$），对偶范数是 $\\ell_2$ 范数（$q=2$）。\n$$\\|\\mathbf{w}\\|_2 = \\sqrt{0.8^2 + (-0.6)^2} = \\sqrt{0.64 + 0.36} = \\sqrt{1} = 1.0$$\n半径的公式为：\n$$r_{\\ell_1} = \\max\\left(0, \\frac{m(\\mathbf{x}, y)}{0.8}\\right)$$\n$$r_{\\ell_2} = \\max\\left(0, \\frac{m(\\mathbf{x}, y)}{1.0}\\right)$$\n\n现在我们将这些公式应用于给定的五个数据点。\n\n1.  **点 1**：$\\mathbf{x}_{1} = (2.0, -1.0)$, $y_{1} = +1$\n    $f(\\mathbf{x}_1) = (0.8)(2.0) + (-0.6)(-1.0) + 0.1 = 1.6 + 0.6 + 0.1 = 2.3$\n    $m_1 = y_1 \\cdot f(\\mathbf{x}_1) = (+1)(2.3) = 2.3$。由于 $m_1  0$：\n    $r_{1, \\ell_1} = 2.3 / 0.8 = 2.875$\n    $r_{1, \\ell_2} = 2.3 / 1.0 = 2.3$\n\n2.  **点 2**：$\\mathbf{x}_{2} = (0.5, 0.5)$, $y_{2} = -1$\n    $f(\\mathbf{x}_2) = (0.8)(0.5) + (-0.6)(0.5) + 0.1 = 0.4 - 0.3 + 0.1 = 0.2$\n    $m_2 = y_2 \\cdot f(\\mathbf{x}_2) = (-1)(0.2) = -0.2$。由于 $m_2 \\leq 0$（错误分类）：\n    $r_{2, \\ell_1} = 0.0$\n    $r_{2, \\ell_2} = 0.0$\n\n3.  **点 3**：$\\mathbf{x}_{3} = (-1.0, 2.0)$, $y_{3} = -1$\n    $f(\\mathbf{x}_3) = (0.8)(-1.0) + (-0.6)(2.0) + 0.1 = -0.8 - 1.2 + 0.1 = -1.9$\n    $m_3 = y_3 \\cdot f(\\mathbf{x}_3) = (-1)(-1.9) = 1.9$。由于 $m_3  0$：\n    $r_{3, \\ell_1} = 1.9 / 0.8 = 2.375$\n    $r_{3, \\ell_2} = 1.9 / 1.0 = 1.9$\n\n4.  **点 4**：$\\mathbf{x}_{4} = (0.125, 0.0)$, $y_{4} = +1$\n    $f(\\mathbf{x}_4) = (0.8)(0.125) + (-0.6)(0.0) + 0.1 = 0.1 + 0.0 + 0.1 = 0.2$\n    $m_4 = y_4 \\cdot f(\\mathbf{x}_4) = (+1)(0.2) = 0.2$。由于 $m_4  0$：\n    $r_{4, \\ell_1} = 0.2 / 0.8 = 0.25$\n    $r_{4, \\ell_2} = 0.2 / 1.0 = 0.2$\n\n5.  **点 5**：$\\mathbf{x}_{5} = (-0.125, 0.0)$, $y_{5} = +1$\n    $f(\\mathbf{x}_5) = (0.8)(-0.125) + (-0.6)(0.0) + 0.1 = -0.1 + 0.0 + 0.1 = 0.0$\n    $m_5 = y_5 \\cdot f(\\mathbf{x}_5) = (+1)(0.0) = 0.0$。由于 $m_5 \\leq 0$（在决策边界上）：\n    $r_{5, \\ell_1} = 0.0$\n    $r_{5, \\ell_2} = 0.0$\n\n最终计算出的半径，四舍五入到六位小数，如下所示：\n- 点 1: $[2.875000, 2.300000]$\n- 点 2: $[0.000000, 0.000000]$\n- 点 3: $[2.375000, 1.900000]$\n- 点 4: $[0.250000, 0.200000]$\n- 点 5: $[0.000000, 0.000000]$", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the certified robustness radii for a linear classifier\n    against l1 and l2 perturbations for a given set of data points.\n    \"\"\"\n    # Fixed parameters for the classifier\n    w = np.array([0.8, -0.6])\n    b = 0.1\n\n    # Dataset of labeled points\n    test_cases = [\n        (np.array([2.0, -1.0]), 1),\n        (np.array([0.5, 0.5]), -1),\n        (np.array([-1.0, 2.0]), -1),\n        (np.array([0.125, 0.0]), 1),\n        (np.array([-0.125, 0.0]), 1)\n    ]\n\n    # Calculate dual norms of the weight vector w\n    # For l1 radius (p=1), we need the dual norm q=inf\n    norm_w_inf = np.linalg.norm(w, ord=np.inf)\n    # For l2 radius (p=2), we need the dual norm q=2\n    norm_w_2 = np.linalg.norm(w, ord=2)\n\n    results = []\n    for x, y in test_cases:\n        # Compute the scoring function output\n        f_x = w.T @ x + b\n        \n        # Compute the signed margin\n        margin = y * f_x\n        \n        # If the point is misclassified or on the boundary, the radius is 0\n        if margin = 0:\n            r_l1 = 0.0\n            r_l2 = 0.0\n        else:\n            # Compute certified radii using the formula: margin / ||w||_q\n            r_l1 = margin / norm_w_inf\n            r_l2 = margin / norm_w_2\n            \n        results.append((r_l1, r_l2))\n\n    # Format the results into the required string format with 6 decimal places.\n    # e.g., [[r1_l1,r1_l2],[r2_l1,r2_l2],...]\n    formatted_results = [f\"[{r[0]:.6f},{r[1]:.6f}]\" for r in results]\n    output_string = f\"[{','.join(formatted_results)}]\"\n    \n    print(output_string)\n\nsolve()\n```", "id": "3171496"}, {"introduction": "崩溃点告诉我们估计器何时会完全失效，而影响函数则提供了更细致、更微观的稳健性视角。本练习演示了如何计算单个数据点对回归模型参数的影响，通过对比异常值对普通最小二乘法 (Ordinary Least Squares, OLS) 的无界影响与对更稳健的Huber回归的有界影响。通过这种比较，您将更深入地理解稳健方法如何在局部层面实现其稳定性。[@problem_id:3171489]", "problem": "考虑一个带截距的一维线性回归模型，其数据生成过程定义为 $y = \\beta_0 + \\beta_1 x + \\varepsilon$，其中 $x$ 是一个标量预测变量，$\\varepsilon$ 是独立噪声。采用经验风险最小化 (ERM) 作为基本框架：通过最小化数据分布下的期望损失来估计参数。对于普通最小二乘法 (OLS)，损失是平方损失；对于 Huber 回归，损失是带阈值参数的 Huber 损失。稳健性通过影响函数 (IF) 进行研究，该函数衡量当数据分布在单一点上受到污染时，参数估计值的无穷小变化。\n\n你需要构建并分析一个具有重尾噪声的统计上合理的场景，具体如下：\n\n1. 使用模型 $y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i$（参数为 $\\beta_0 = 1.0$ 和 $\\beta_1 = 1.5$）生成一个大小为 $n = 5000$ 的合成数据集。预测变量 $x_i$ 独立地从均值为 $0$、方差为 $1$ 的标准正态分布中抽取。噪声 $\\varepsilon_i$ 独立地从自由度 $\\nu = 3$、尺度 $s = 1.0$ 的学生 t 分布中抽取。为保证可复现性，使用固定的随机种子 $42$。\n\n2. 在用于带截距和单个预测变量的线性回归的 ERM 中，将设计向量写为 $\\tilde{x} = \\begin{bmatrix}1 \\\\ x\\end{bmatrix}$。设损失为残差 $r = y - \\tilde{x}^\\top \\theta$ 的函数 $\\rho(r)$，其中 $\\theta = \\begin{bmatrix}\\beta_0 \\\\ \\beta_1\\end{bmatrix}$。定义得分函数 $\\psi(r) = \\frac{d}{dr}\\rho(r)$ 和估计方程 $\\mathbb{E}[\\psi(r)\\tilde{x}] = 0$。在污染点 $z_0 = (x_0, y_0)$ 处的影响函数 (IF) 由参数泛函相对于 $\\varepsilon$-污染的 Gateaux 导数给出：考虑受污染的分布 $(1 - \\varepsilon)P + \\varepsilon \\Delta_{z_0}$，并在 $\\varepsilon = 0$ 处对估计方程的解进行微分。使用敏感度矩阵 $A = \\mathbb{E}\\left[\\frac{\\partial}{\\partial \\theta}\\{\\psi(r)\\tilde{x}\\}\\right]$ 来表示 IF。通过对生成数据的样本均值来计算期望。\n\n3. 对于 OLS，使用平方损失，其中 $\\rho_{\\text{OLS}}(r) = \\frac{1}{2} r^2$ 且 $\\psi_{\\text{OLS}}(r) = r$。对于 Huber 回归，使用阈值参数 $\\delta  0$ 的 Huber 损失，定义为 $\\rho_{\\delta}(r) = \\begin{cases} \\frac{1}{2}r^2  \\text{if } |r| \\le \\delta \\\\ \\delta|r| - \\frac{1}{2}\\delta^2  \\text{if } |r|  \\delta \\end{cases}$，因此 $\\psi_{\\delta}(r) = \\begin{cases} r  \\text{if } |r| \\le \\delta \\\\ \\delta \\,\\mathrm{sign}(r)  \\text{if } |r|  \\delta \\end{cases}$。将阈值设为 $\\delta = k \\cdot \\hat{\\sigma}$，其中 $k = 1.345$ 是一个常数，$\\hat{\\sigma}$ 是 $\\varepsilon$ 的一个稳健尺度估计，通过中位数绝对偏差 (MAD) 乘以 $1.4826$ 计算得出。在计算 $\\psi_{\\delta}$ 和 Huber 回归的敏感度矩阵时使用此 $\\delta$。\n\n4. 通过样本均值来近似敏感度矩阵。对于 OLS，使用 $A_{\\text{OLS}} \\approx -\\frac{1}{n}\\sum_{i=1}^{n} \\tilde{x}_i \\tilde{x}_i^\\top$，因为 $\\psi_{\\text{OLS}}'(r) = 1$。对于 Huber 回归，使用 $A_{\\text{Huber}} \\approx -\\frac{1}{n}\\sum_{i=1}^{n} I(|\\varepsilon_i| \\le \\delta)\\, \\tilde{x}_i \\tilde{x}_i^\\top$，其中 $I(\\cdot)$ 是指示函数，并且当 $|r| \\le \\delta$ 时 $\\psi_{\\delta}'(r) = 1$，否则为 $0$。在构建残差和敏感度矩阵时，使用真实参数 $\\theta^\\star = \\begin{bmatrix}1.0 \\\\ 1.5\\end{bmatrix}$，因此 $r_i = \\varepsilon_i$。\n\n5. 对于一个污染点 $z_0 = (x_0, y_0)$，其残差为 $r_0 = y_0 - \\tilde{x}_0^\\top \\theta^\\star$，IF 向量为 $\\mathsf{IF}(z_0) = -A^{-1}\\{\\psi(r_0)\\tilde{x}_0\\}$。分别计算 OLS 和 Huber 回归的此值。为了比较稳健性，对每个测试案例报告标量比率 $R = \\|\\mathsf{IF}_{\\text{Huber}}(z_0)\\|_2 \\big/ \\|\\mathsf{IF}_{\\text{OLS}}(z_0)\\|_2$，其中 $\\|\\cdot\\|_2$ 表示欧几里得范数。\n\n使用以下以 $(x_0, r_0)$ 表示的污染点测试集，并为每个点定义 $y_0 = \\beta_0 + \\beta_1 x_0 + r_0$：\n- 案例 1：$(x_0, r_0) = (0.0, 0.5)$，所以 $y_0 = 1.0 + 1.5 \\cdot 0.0 + 0.5$。\n- 案例 2：$(x_0, r_0) = (0.0, 10.0)$，所以 $y_0 = 1.0 + 1.5 \\cdot 0.0 + 10.0$。\n- 案例 3：$(x_0, r_0) = (5.0, 0.5)$，所以 $y_0 = 1.0 + 1.5 \\cdot 5.0 + 0.5$。\n- 案例 4：$(x_0, r_0) = (5.0, 10.0)$，所以 $y_0 = 1.0 + 1.5 \\cdot 5.0 + 10.0$。\n\n你的程序应生成单行输出，其中包含上述案例的四个比率 $R$，格式为用方括号括起来的逗号分隔列表（例如 $[r_1,r_2,r_3,r_4]$）。输出必须是实数（浮点数）。此问题不涉及角度或物理单位。", "solution": "该问题被评估为有效。这是一个在稳健统计学（统计学习的一个子领域）中定义明确、具有科学依据的练习。所有提供的数据、定义和方程在内部是一致的，是该领域的标准，并且足以推导出一个唯一的数值解。该问题要求使用影响函数 (IF) 对普通最小二乘法 (OLS) 和 Huber 回归的稳健性进行定量比较，IF 是用于此目的的标准工具。\n\n目标是计算对于四个不同的污染点 $z_0$，Huber 回归与 OLS 回归的影响函数的欧几里得范数之比，$R = \\|\\mathsf{IF}_{\\text{Huber}}(z_0)\\|_2 \\big/ \\|\\mathsf{IF}_{\\text{OLS}}(z_0)\\|_2$。较小的比率表示对特定污染具有更强的稳健性。步骤如下：\n\n首先，我们根据问题规范生成一个合成数据集。\n- 样本量：$n = 5000$。\n- 预测变量 $x_i$（其中 $i=1, \\dots, n$）独立地从标准正态分布 $x_i \\sim \\mathcal{N}(0, 1)$ 中抽取。\n- 噪声项 $\\varepsilon_i$ 独立地从自由度 $\\nu = 3$、尺度 $s=1.0$ 的学生 t 分布中抽取。\n- 数据生成过程为 $y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i$，真实参数为 $\\beta_0 = 1.0$ 和 $\\beta_1 = 1.5$。\n为保证可复现性，使用固定的随机种子 $42$。每个观测的设计向量为 $\\tilde{x}_i = [1, x_i]^\\top$。\n\n分析中使用真实参数向量 $\\theta^\\star = [\\beta_0, \\beta_1]^\\top = [1.0, 1.5]^\\top$ 来计算残差，这将残差简化为噪声项本身，即 $r_i = y_i - \\tilde{x}_i^\\top \\theta^\\star = \\varepsilon_i$。\n\n对于 Huber 回归，损失函数 $\\rho_{\\delta}(r)$ 需要一个阈值参数 $\\delta$。该值设为 $\\delta = k \\cdot \\hat{\\sigma}$，其中 $k=1.345$，$\\hat{\\sigma}$ 是噪声标准差的稳健估计。我们通过 $1.4826 \\times \\text{MAD}(\\varepsilon)$ 计算 $\\hat{\\sigma}$，其中 $\\text{MAD}(\\varepsilon)$ 是噪声项的中位数绝对偏差，由 $\\text{median}_i(|\\varepsilon_i - \\text{median}_j(\\varepsilon_j)|)$ 给出。\n\n对于一个污染点 $z_0 = (x_0, y_0)$，其影响函数由 $\\mathsf{IF}(z_0) = -A^{-1}\\{\\psi(r_0)\\tilde{x}_0\\}$ 给出，其中 $r_0 = y_0 - \\tilde{x}_0^\\top\\theta^\\star$ 是污染点的残差，$\\psi(\\cdot)$ 是得分函数（损失函数 $\\rho(\\cdot)$ 的导数），$A$ 是敏感度矩阵。\n\n敏感度矩阵 $A$ 定义为 $A = \\mathbb{E}\\left[\\frac{\\partial}{\\partial \\theta}\\{\\psi(r)\\tilde{x}\\}\\right] = \\mathbb{E}[-\\psi'(r)\\tilde{x}\\tilde{x}^\\top]$。我们使用生成数据集上的样本均值来近似这个期望。\n- 对于 OLS，损失为 $\\rho_{\\text{OLS}}(r) = \\frac{1}{2}r^2$，因此得分函数为 $\\psi_{\\text{OLS}}(r) = r$，其导数为 $\\psi'_{\\text{OLS}}(r) = 1$。敏感度矩阵为 $A_{\\text{OLS}} \\approx -\\frac{1}{n} \\sum_{i=1}^n \\tilde{x}_i \\tilde{x}_i^\\top$。\n- 对于 Huber 回归，得分函数为 $\\psi_{\\delta}(r) = \\text{sign}(r) \\min(|r|, \\delta)$。其导数为 $\\psi'_{\\delta}(r) = I(|r| \\le \\delta)$，其中 $I(\\cdot)$ 是指示函数。敏感度矩阵为 $A_{\\text{Huber}} \\approx -\\frac{1}{n} \\sum_{i=1}^n I(|\\varepsilon_i| \\le \\delta) \\tilde{x}_i \\tilde{x}_i^\\top$。\n\n对于由污染点 $(x_0, r_0)$ 定义的四个测试案例中的每一个：\n1. 设计向量为 $\\tilde{x}_0 = [1, x_0]^\\top$。\n2. 计算得分函数值 $\\psi_{\\text{OLS}}(r_0) = r_0$ 和 $\\psi_{\\delta}(r_0) = \\text{sign}(r_0) \\min(|r_0|, \\delta)$。\n3. 构建向量 $\\{\\psi_{\\text{OLS}}(r_0)\\tilde{x}_0\\}$ 和 $\\{\\psi_{\\delta}(r_0)\\tilde{x}_0\\}$。\n4. 通过求解相应的线性系统，计算影响函数向量 $\\mathsf{IF}_{\\text{OLS}}(z_0) = -A_{\\text{OLS}}^{-1}\\{\\psi_{\\text{OLS}}(r_0)\\tilde{x}_0\\}$ 和 $\\mathsf{IF}_{\\text{Huber}}(z_0) = -A_{\\text{Huber}}^{-1}\\{\\psi_{\\delta}(r_0)\\tilde{x}_0\\}$。\n5. 计算这些向量的欧几里得范数 $\\|\\mathsf{IF}_{\\text{OLS}}(z_0)\\|_2$ 和 $\\|\\mathsf{IF}_{\\text{Huber}}(z_0)\\|_2$。\n6. 计算并收集最终的比率 $R$。\n\n对所有测试案例重复此过程，并将所得比率格式化为所需的输出。", "answer": "```python\nimport numpy as np\nfrom scipy import stats\n\ndef solve():\n    \"\"\"\n    Computes the ratio of influence function norms for Huber vs. OLS regression.\n    \"\"\"\n    # 1. Define constants and set up the simulation environment\n    n = 5000\n    beta_0 = 1.0\n    beta_1 = 1.5\n    theta_star = np.array([beta_0, beta_1])\n    nu = 3.0\n    s_scale = 1.0\n    seed = 42\n    k = 1.345\n    mad_const = 1.4826\n\n    # 2. Generate synthetic data\n    rng = np.random.default_rng(seed)\n    x = rng.normal(loc=0.0, scale=1.0, size=n)\n    # Per problem statement, residuals for matrix calculation are the noise terms\n    eps = stats.t.rvs(df=nu, loc=0.0, scale=s_scale, size=n, random_state=rng)\n    \n    # Construct the design matrix with an intercept term\n    X_tilde = np.c_[np.ones(n), x]\n\n    # 3. Calculate the Huber threshold parameter delta\n    # Compute MAD of the noise terms\n    med_eps = np.median(eps)\n    mad = np.median(np.abs(eps - med_eps))\n    \n    # Compute the robust scale estimate sigma_hat\n    sigma_hat = mad_const * mad\n    \n    # Compute the Huber threshold delta\n    delta = k * sigma_hat\n\n    # 4. Compute the sensitivity matrices A_OLS and A_Huber\n    # For OLS\n    A_ols = (-1/n) * (X_tilde.T @ X_tilde)\n    \n    # For Huber\n    # Find indices where residuals are within the delta threshold\n    inlier_indices = np.abs(eps) = delta\n    # Create the sub-matrix of inliers\n    X_tilde_inliers = X_tilde[inlier_indices]\n    A_huber = (-1/n) * (X_tilde_inliers.T @ X_tilde_inliers)\n\n    # 5. Define test cases and compute ratios\n    test_cases = [\n        (0.0, 0.5),   # Case 1: No leverage, small residual\n        (0.0, 10.0),  # Case 2: No leverage, large residual (vertical outlier)\n        (5.0, 0.5),   # Case 3: High leverage, small residual\n        (5.0, 10.0),  # Case 4: High leverage, large residual\n    ]\n    \n    results = []\n    \n    for x0, r0 in test_cases:\n        x_tilde_0 = np.array([1.0, x0])\n        \n        # --- OLS Influence Function ---\n        # Score function value for OLS\n        psi_ols_r0 = r0\n        # Vector for the IF formula\n        v_ols = psi_ols_r0 * x_tilde_0\n        # Compute IF by solving the linear system A * IF = -v\n        if_ols = np.linalg.solve(A_ols, -v_ols)\n        # Compute the L2 norm\n        norm_if_ols = np.linalg.norm(if_ols)\n        \n        # --- Huber Influence Function ---\n        # Score function value for Huber (clipped at delta)\n        psi_huber_r0 = np.sign(r0) * min(np.abs(r0), delta)\n        # Vector for the IF formula\n        v_huber = psi_huber_r0 * x_tilde_0\n        # Compute IF by solving the linear system\n        if_huber = np.linalg.solve(A_huber, -v_huber)\n        # Compute the L2 norm\n        norm_if_huber = np.linalg.norm(if_huber)\n        \n        # --- Ratio Calculation ---\n        # Handle the case where the denominator might be zero (unlikely here)\n        if norm_if_ols == 0:\n            ratio = np.inf if norm_if_huber > 0 else 0\n        else:\n            ratio = norm_if_huber / norm_if_ols\n            \n        results.append(ratio)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3171489"}]}