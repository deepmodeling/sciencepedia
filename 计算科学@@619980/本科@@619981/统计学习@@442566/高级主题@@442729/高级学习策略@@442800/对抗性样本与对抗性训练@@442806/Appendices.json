{"hands_on_practices": [{"introduction": "在构建防御模型之前，我们首先需要一种方法来量化其鲁棒性。这个练习将指导您推导出一个精确的公式，用以计算能使线性分类器做出错误分类的最小扰动。这项实践不仅能让您深入理解模型参数如何直接影响其鲁棒性，也为后续更复杂的鲁棒性分析奠定了“基石” [@problem_id:3097068]。", "problem": "考虑一个作用于输入 $x \\in \\mathbb{R}^d$ 的多类线性分类器，该分类器有 $K$ 个类别。对于每个类别 $i \\in \\{1,\\dots,K\\}$，其分数为 $f_i(x) = w_i^\\top x + b_i$，其中参数为 $w_i \\in \\mathbb{R}^d$ 和 $b_i \\in \\mathbb{R}$。预测的类别为 $y = \\arg\\max_{i} f_i(x)$。在 $\\ell_{\\infty}$ 范数下的对抗性扰动是任何满足 $\\|\\delta\\|_{\\infty} \\le \\varepsilon$（对于某个 $\\varepsilon \\ge 0$）的 $\\delta \\in \\mathbb{R}^d$。将改变预测类别（使其不再是 $y$）所需的最小 $\\ell_{\\infty}$ 范数定义为最小的 $\\varepsilon$，使得存在一个 $\\delta$ 满足 $\\|\\delta\\|_{\\infty} \\le \\varepsilon$ 且存在某个 $i \\neq y$ 满足 $f_i(x+\\delta) \\ge f_y(x+\\delta)$。\n\n任务 A（推导）：仅从上述定义和实数分析中的标准不等式出发，推导出这个最小 $\\varepsilon$ 关于模型参数 $\\{w_i,b_i\\}_{i=1}^K$ 和输入 $x$ 的闭式表达式。您的推导必须明确说明该表达式是如何从范数性质以及真实类别 $y$ 与任何备选类别 $i \\neq y$ 之间的分数差异中得出的。\n\n任务 B（在具体模型上进行数值验证）：考虑 $d = 2$，$K = 3$，以及\n- $w_1 = \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix}$，$b_1 = 1$，\n- $w_2 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$，$b_2 = 0$，\n- $w_3 = \\begin{pmatrix} -1 \\\\ 0 \\end{pmatrix}$，$b_3 = 2$，\n输入为 $x = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$。\n执行以下操作：\n- 确定在 $x$ 处的预测类别 $y$。\n- 使用您在任务 A 中得到的表达式，计算在 $x$ 处的认证 $\\ell_{\\infty}$ 半径 $r$，该半径定义为上述意义下改变预测类别（使其不再是 $y$）所需的最小 $\\varepsilon$。\n- 通过显式构造一个对抗性扰动 $\\delta^\\star$，其满足 $\\|\\delta^\\star\\|_{\\infty} = r$ 且使某个 $i \\neq y$ 满足 $f_i(x+\\delta^\\star) \\ge f_y(x+\\delta^\\star)$，从而在数值上验证其紧致性。\n\n在任务 B 中，仅提供给定数值实例的单一数字 $r$ 作为您的最终答案（无单位，无附加文本）。不要四舍五入；给出精确值。", "solution": "该问题被评估为有效，因为它科学地基于统计学习的原理，是适定、客观的，并包含得出唯一解所需的所有必要信息。\n\n**任务 A：最小 $\\ell_{\\infty}$ 扰动的推导**\n\n设输入为 $x \\in \\mathbb{R}^d$，线性分类器由分数函数 $f_i(x) = w_i^\\top x + b_i$ 定义，其中 $i \\in \\{1, \\dots, K\\}$。预测类别为 $y = \\arg\\max_{i} f_i(x)$。我们假设对于给定的 $x$，最大值是唯一的，因此对于所有 $j \\neq y$，有 $f_y(x) > f_j(x)$。\n\n我们寻求一个对抗性扰动 $\\delta \\in \\mathbb{R}^d$，使得 $\\|\\delta\\|_{\\infty} \\le \\varepsilon$（对于某个 $\\varepsilon \\ge 0$），并且在新点 $x+\\delta$ 处的预测类别不再是 $y$。这种变化的边界条件发生在：至少有一个类别 $i \\neq y$ 的分数变得等于或大于原始类别 $y$ 的分数。即，对于某个 $i \\neq y$：\n$$f_i(x+\\delta) \\ge f_y(x+\\delta)$$\n代入分数函数的定义，我们得到：\n$$w_i^\\top (x+\\delta) + b_i \\ge w_y^\\top (x+\\delta) + b_y$$\n展开各项可得：\n$$w_i^\\top x + w_i^\\top \\delta + b_i \\ge w_y^\\top x + w_y^\\top \\delta + b_y$$\n我们可以重排这个不等式，以分离出含 $\\delta$ 的项：\n$$w_i^\\top \\delta - w_y^\\top \\delta \\ge (w_y^\\top x + b_y) - (w_i^\\top x + b_i)$$\n右边是原始分数的差值，$f_y(x) - f_i(x)$。左边可以因式分解为：\n$$(w_i - w_y)^\\top \\delta \\ge f_y(x) - f_i(x)$$\n对于一个固定的目标类别 $i \\neq y$，我们希望找到最小的 $\\varepsilon$，使得存在一个满足 $\\|\\delta\\|_{\\infty} \\le \\varepsilon$ 且满足此不等式的 $\\delta$。为了找到最小的 $\\varepsilon$，我们应该选择一个扰动 $\\delta$ 来最大化左边的项 $(w_i - w_y)^\\top \\delta$，在给定的范数界限 $\\|\\delta\\|_{\\infty} = \\varepsilon$ 下。\n\n$\\ell_1$ 范数和 $\\ell_{\\infty}$ 范数之间的关系由 Hölder 不等式定义，该不等式指出，对于任意两个向量 $u, v \\in \\mathbb{R}^d$，有 $|u^\\top v| \\le \\|u\\|_1 \\|v\\|_{\\infty}$。当 $v$ 的元素根据 $u$ 的元素的符号被恰当选择时，等号成立。为了最大化点积 $(w_i - w_y)^\\top \\delta$，我们应该选择 $\\delta$，使其每个分量 $\\delta_j$ 与向量 $(w_i - w_y)$ 对应分量的符号相同，且其大小最大化，即 $|\\delta_j| = \\varepsilon$。\n具体来说，$\\delta$ 的最优选择是 $\\delta = \\varepsilon \\cdot \\text{sign}(w_i - w_y)$，其中 sign 函数是按元素应用的。通过这个选择，点积变为：\n$$(w_i - w_y)^\\top \\delta = (w_i - w_y)^\\top (\\varepsilon \\cdot \\text{sign}(w_i - w_y)) = \\varepsilon \\sum_{j=1}^d (w_i - w_y)_j \\cdot \\text{sign}((w_i - w_y)_j) = \\varepsilon \\sum_{j=1}^d |(w_i - w_y)_j| = \\varepsilon \\|w_i - w_y\\|_1$$\n这代表了在约束 $\\|\\delta\\|_{\\infty} \\le \\varepsilon$ 下，不等式左边的最大可能值。\n\n将此最大值代回不等式，我们找到了成功攻击类别 $y$ 以支持类别 $i$ 时 $\\varepsilon$ 需满足的条件：\n$$\\varepsilon \\|w_i - w_y\\|_1 \\ge f_y(x) - f_i(x)$$\n由于 $f_y(x) > f_i(x)$ 且 $\\|w_i - w_y\\|_1 > 0$（假设 $w_i \\neq w_y$），使类别 $i$ 成为潜在对抗类别所需的最小 $\\varepsilon$（记为 $\\varepsilon_i$）是：\n$$\\varepsilon_i = \\frac{f_y(x) - f_i(x)}{\\|w_i - w_y\\|_1}$$\n问题要求的是将预测类别从 $y$ 改变为*任何*其他类别所需的最小 $\\varepsilon$。这对应于找到“最脆弱”的方向，即需要最小扰动 $\\varepsilon_i$ 的类别 $i \\neq y$。因此，总体的最小扰动 $\\varepsilon$ 是在所有可能的对抗目标类别 $i \\neq y$ 上这些值的最小值：\n$$\\varepsilon = \\min_{i \\neq y} \\left\\{ \\varepsilon_i \\right\\} = \\min_{i \\neq y} \\frac{f_y(x) - f_i(x)}{\\|w_i - w_y\\|_1}$$\n这就是最小 $\\ell_{\\infty}$ 范数扰动的闭式表达式。\n\n**任务 B：在具体模型上进行数值验证**\n\n给定的参数为 $d=2$, $K=3$，其中：\n$w_1 = \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix}, b_1 = 1$,\n$w_2 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}, b_2 = 0$,\n$w_3 = \\begin{pmatrix} -1 \\\\ 0 \\end{pmatrix}, b_3 = 2$,\n输入为 $x = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$。\n\n首先，我们通过计算分数 $f_i(x)$ 来确定预测类别 $y$：\n$f_1(x) = w_1^\\top x + b_1 = (2)(1) + (-1)(2) + 1 = 2 - 2 + 1 = 1$.\n$f_2(x) = w_2^\\top x + b_2 = (0)(1) + (1)(2) + 0 = 0 + 2 + 0 = 2$.\n$f_3(x) = w_3^\\top x + b_3 = (-1)(1) + (0)(2) + 2 = -1 + 0 + 2 = 1$.\n分数为 $\\{1, 2, 1\\}$。最大分数为 $f_2(x)=2$，所以预测类别是 $y=2$。\n\n接下来，我们计算认证 $\\ell_{\\infty}$ 半径 $r$，这是任务 A 中的最小 $\\varepsilon$。我们必须为每个备选类别 $i \\in \\{1, 3\\}$ 评估所需的扰动。\n对于 $i=1$：\n分数差为 $f_y(x) - f_1(x) = f_2(x) - f_1(x) = 2 - 1 = 1$。\n权重差向量为 $w_1 - w_y = w_1 - w_2 = \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix} - \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ -2 \\end{pmatrix}$。\n此向量的 $\\ell_1$-范数是 $\\|w_1 - w_2\\|_1 = |2| + |-2| = 4$。\n这对类别的最小扰动是 $\\varepsilon_1 = \\frac{1}{4}$。\n\n对于 $i=3$：\n分数差为 $f_y(x) - f_3(x) = f_2(x) - f_3(x) = 2 - 1 = 1$。\n权重差向量为 $w_3 - w_y = w_3 - w_2 = \\begin{pmatrix} -1 \\\\ 0 \\end{pmatrix} - \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} -1 \\\\ -1 \\end{pmatrix}$。\n此向量的 $\\ell_1$-范数是 $\\|w_3 - w_2\\|_1 = |-1| + |-1| = 2$。\n这对类别的最小扰动是 $\\varepsilon_3 = \\frac{1}{2}$。\n\n认证半径 $r$ 是这些值的最小值：\n$r = \\min\\{\\varepsilon_1, \\varepsilon_3\\} = \\min\\left\\{\\frac{1}{4}, \\frac{1}{2}\\right\\} = \\frac{1}{4}$。\n\n最后，我们通过构造一个对抗性扰动 $\\delta^\\star$（其中 $\\|\\delta^\\star\\|_{\\infty} = r = \\frac{1}{4}$）来验证这个结果。最小值是针对目标类别 $i=1$ 找到的。最优扰动构造为 $\\delta^\\star = r \\cdot \\text{sign}(w_1 - w_2)$。\n使用 $w_1 - w_2 = \\begin{pmatrix} 2 \\\\ -2 \\end{pmatrix}$，我们得到 $\\text{sign}(w_1 - w_2) = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$。\n因此，$\\delta^\\star = \\frac{1}{4} \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} = \\begin{pmatrix} 1/4 \\\\ -1/4 \\end{pmatrix}$。\n其 $\\ell_{\\infty}$-范数为 $\\|\\delta^\\star\\|_{\\infty} = \\max\\{|1/4|, |-1/4|\\} = 1/4 = r$，符合要求。\n扰动后的输入为 $x' = x + \\delta^\\star = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} + \\begin{pmatrix} 1/4 \\\\ -1/4 \\end{pmatrix} = \\begin{pmatrix} 5/4 \\\\ 7/4 \\end{pmatrix}$。\n\n我们来计算在 $x'$ 处的分数：\n$f_1(x') = w_1^\\top x' + b_1 = (2)(\\frac{5}{4}) + (-1)(\\frac{7}{4}) + 1 = \\frac{10}{4} - \\frac{7}{4} + \\frac{4}{4} = \\frac{7}{4}$。\n$f_2(x') = w_2^\\top x' + b_2 = (0)(\\frac{5}{4}) + (1)(\\frac{7}{4}) + 0 = \\frac{7}{4}$。\n$f_3(x') = w_3^\\top x' + b_3 = (-1)(\\frac{5}{4}) + (0)(\\frac{7}{4}) + 2 = -\\frac{5}{4} + \\frac{8}{4} = \\frac{3}{4}$。\n\n在扰动 $\\delta^\\star$下，类别 1 和类别 2 的分数现在相等：$f_1(x') = f_2(x') = 7/4$。这满足了边界条件 $f_1(x+\\delta^\\star) \\ge f_2(x+\\delta^\\star)$，证实了这个最小尺寸的扰动足以造成平局，并且沿此方向任何稍微大一点的扰动都会将预测从类别 2 改变为类别 1。这验证了所推导半径的紧致性。\n计算出的认证半径为 $r = \\frac{1}{4}$。", "answer": "$$\n\\boxed{\\frac{1}{4}}\n$$", "id": "3097068"}, {"introduction": "学会了衡量鲁棒性之后，下一步自然是学习如何提升它。这个编码练习将引导您从零开始实现对抗训练——当前最主流和有效的防御策略之一。通过这个过程，您将亲身体验并验证一个核心现象：提升模型的鲁棒性通常需要以牺牲其在干净数据上的准确率为代价，这揭示了构建安全机器学习系统时面临的基本权衡 [@problem_id:3188152]。", "problem": "考虑在线性模型下由对抗性扰动引起的分布偏移的二元分类问题。设假设类别为线性决策函数 $f_{w,b}(\\mathbf{x}) = \\mathbf{w}^{\\top}\\mathbf{x} + b$，其参数为 $\\mathbf{w} \\in \\mathbb{R}^{d}$ 和 $b \\in \\mathbb{R}$。数据按如下方式独立同分布地抽取：标签 $y \\in \\{-1, +1\\}$ 是均匀分布的，特征 $\\mathbf{x} \\in \\mathbb{R}^{d}$ 通过 $\\mathbf{x} = y \\, m \\, \\mathbf{u} + \\boldsymbol{\\xi}$ 生成，其中 $\\mathbf{u} \\in \\mathbb{R}^{d}$ 具有单位欧几里得范数，且 $\\boldsymbol{\\xi} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma^{2}\\mathbf{I}_{d})$。在有限样本 $(\\mathbf{x}_{i}, y_{i})_{i=1}^{n}$ 上的经验分类误差为 $\\hat{R}_{\\text{train}}(w,b) = \\frac{1}{n}\\sum_{i=1}^{n}\\mathbb{I}\\{ y_{i} f_{w,b}(\\mathbf{x}_{i}) \\le 0 \\}$，表示为 $[0,1]$ 区间内的小数。\n\n我们考虑两种训练过程：\n- 标准训练最小化逻辑斯蒂损失 $\\ell(z) = \\log(1+\\exp(-z))$ 在 $\\ell(y_{i} f_{w,b}(\\mathbf{x}_{i}))$ 上的经验平均值，以及一个 $\\ell_{2}$ 惩罚项 $\\frac{\\lambda}{2}\\|\\mathbf{w}\\|_{2}^{2}$。\n- 半径为 $\\epsilon$ 的对抗性训练最小化在每个 $\\mathbf{x}_{i}$ 周围半径为 $\\epsilon$ 的 $\\ell_{2}$ 球内最坏情况扰动输入下评估的逻辑斯蒂损失的经验平均值，同样带有相同的 $\\ell_{2}$ 惩罚项。形式上，它最小化 $\\frac{1}{n}\\sum_{i=1}^{n} \\ell\\!\\left(\\min_{\\|\\boldsymbol{\\delta}\\|_{2}\\le \\epsilon} y_{i} f_{w,b}(\\mathbf{x}_{i}+\\boldsymbol{\\delta})\\right) + \\frac{\\lambda}{2}\\|\\mathbf{w}\\|_{2}^{2}$。\n\n在测试时，我们评估两种误差：\n- 干净测试误差 $R_{\\text{test, clean}}(w,b)$ 是在来自相同干净分布（无扰动）的新测试样本上的错分类率，表示为 $[0,1]$ 区间内的小数。\n- 偏移测试误差 $R_{\\text{test, perturbed}}(w,b;\\epsilon)$ 是当每个测试输入 $\\mathbf{x}$ 被最小化 $y f_{w,b}(\\mathbf{x}+\\boldsymbol{\\delta})$ 的最坏情况扰动 $\\mathbf{x}+\\boldsymbol{\\delta}$（其中 $\\|\\boldsymbol{\\delta}\\|_{2}\\le \\epsilon$）替换时的错分类率，表示为 $[0,1]$ 区间内的小数。\n\n需要从第一性原理实现的任务：\n1. 对于线性的 $f_{w,b}$ 和 $\\ell_{2}$ 有界扰动，推导并实现关于 $\\boldsymbol{\\delta}$ 的精确内部最小化，这既适用于训练（对抗性训练目标），也适用于测试（扰动评估）。您的实现必须仅依赖于上述定义和欧几里得范数的性质；不要对内部问题进行数值近似。\n2. 实现梯度下降来训练两个模型：\n   - 标准模型：最小化带 $\\ell_{2}$ 惩罚项 $\\frac{\\lambda}{2}\\|\\mathbf{w}\\|_{2}^{2}$ 的经验逻辑斯蒂目标函数。\n   - 对抗模型：最小化经验鲁棒逻辑斯蒂目标函数，其中每个样本的间隔被其在半径为 $\\epsilon$ 的 $\\ell_{2}$ 球内的最坏情况值替换，并带有相同的惩罚项。\n 使用测试套件中指定的固定学习率和迭代次数。\n3. 对于下方的每个测试用例，计算：\n   - 两个模型的干净经验训练误差 $\\hat{R}_{\\text{train}}$（在未扰动的训练数据上评估）。\n   - 两个模型的扰动测试误差 $R_{\\text{test, perturbed}}(\\cdot;\\epsilon)$（在一个新的测试集上评估，每个输入都在半径 $\\epsilon$ 内进行最坏情况扰动）。\n   - 一个布尔指标，当且仅当对抗性训练严格增加了干净经验训练误差，同时严格减少了扰动测试误差时为真，每个变化的幅度至少为容忍度 $\\tau$，其中 $\\tau = 0.01$（一个 $[0,1]$ 区间内的小数）。具体来说，如果 $\\hat{R}_{\\text{train}}^{\\text{adv}} - \\hat{R}_{\\text{train}}^{\\text{std}} \\ge \\tau$ 且 $R_{\\text{test, perturbed}}^{\\text{std}} - R_{\\text{test, perturbed}}^{\\text{adv}} \\ge \\tau$，则该指标为真。\n\n使用以下测试套件。每个元组是 $(\\text{seed}, n_{\\text{train}}, n_{\\text{test}}, d, m, \\sigma, \\lambda, \\text{lr}, \\text{steps}, \\epsilon)$，所有均为实数或整数，其中 $\\mathbf{u}$ 被选为 $\\mathbb{R}^{d}$ 中的第一个标准基向量：\n- 案例 1：$(0, 500, 4000, 5, 1.5, 0.6, 0.01, 0.1, 2000, 0.0)$\n- 案例 2：$(1, 500, 4000, 5, 1.5, 0.6, 0.01, 0.1, 2000, 0.5)$\n- 案例 3：$(2, 500, 4000, 5, 1.5, 0.6, 0.01, 0.1, 2000, 1.0)$\n- 案例 4：$(3, 500, 4000, 5, 1.5, 0.6, 0.01, 0.1, 2000, 2.0)$\n\n程序要求：\n- 不得有用户输入。随机性必须按照测试用例的种子进行设定。\n- 最终输出必须是单行，包含一个布尔值列表，每个案例一个，表示对抗性训练是否在干净数据上将 $\\hat{R}_{\\text{train}}$ 增加了至少 $\\tau$ 并且将 $R_{\\text{test, perturbed}}(\\cdot;\\epsilon)$ 减少了至少 $\\tau$，按上述案例的顺序排列。\n- 该列表必须以单行精确格式打印：一个逗号分隔的 Python 风格列表，例如 $[\\text{True},\\text{False},\\text{True},\\text{False}]$。\n- 所有错误率必须是 $[0,1]$ 区间内的小数，不带百分号。\n\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，$[\\text{result}_{1},\\text{result}_{2},\\text{result}_{3},\\text{result}_{4}]$）。", "solution": "用户提供的问题是一个定义明确的计算统计学习练习，专注于与对抗性训练相关的权衡。该问题要求实现并比较线性二元分类器的两种训练过程：标准经验风险最小化和对抗性训练。评估涉及比较两种模型在干净训练数据上的误差和在对抗性扰动测试数据上的误差。\n\n### 步骤 1：问题验证\n\n首先，对问题陈述进行严格的验证。\n\n**1.1. 提取的已知条件：**\n-   **假设类别**：线性函数 $f_{w,b}(\\mathbf{x}) = \\mathbf{w}^{\\top}\\mathbf{x} + b$，其中 $\\mathbf{w} \\in \\mathbb{R}^{d}$，$b \\in \\mathbb{R}$。\n-   **数据生成模型**：标签 $y \\in \\{-1, +1\\}$ 是均匀分布的。特征为 $\\mathbf{x} = y \\, m \\, \\mathbf{u} + \\boldsymbol{\\xi}$，其中 $\\|\\mathbf{u}\\|_2=1$ 且 $\\boldsymbol{\\xi} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma^{2}\\mathbf{I}_{d})$。在实现中，$\\mathbf{u}$ 是第一个标准基向量。\n-   **损失函数**：逻辑斯蒂损失 $\\ell(z) = \\log(1+\\exp(-z))$。\n-   **正则化**：$\\ell_{2}$ 惩罚项 $\\frac{\\lambda}{2}\\|\\mathbf{w}\\|_{2}^{2}$。\n-   **标准训练目标**：最小化 $\\frac{1}{n}\\sum_{i=1}^{n}\\ell(y_{i} f_{w,b}(\\mathbf{x}_{i})) + \\frac{\\lambda}{2}\\|\\mathbf{w}\\|_{2}^{2}$。\n-   **对抗性训练目标**：最小化 $\\frac{1}{n}\\sum_{i=1}^{n} \\ell\\!\\left(\\min_{\\|\\boldsymbol{\\delta}\\|_{2}\\le \\epsilon} y_{i} f_{w,b}(\\mathbf{x}_{i}+\\boldsymbol{\\delta})\\right) + \\frac{\\lambda}{2}\\|\\mathbf{w}\\|_{2}^{2}$。\n-   **评估指标**：\n    -   干净经验训练误差：$\\hat{R}_{\\text{train}} = \\frac{1}{n}\\sum_{i=1}^{n}\\mathbb{I}\\{ y_{i} f_{w,b}(\\mathbf{x}_{i}) \\le 0 \\}$。\n    -   扰动测试误差：$R_{\\text{test, perturbed}}(w,b;\\epsilon) = \\mathbb{E}_{(\\mathbf{x},y)}[\\mathbb{I}\\{ \\min_{\\|\\boldsymbol{\\delta}\\|_{2}\\le \\epsilon} y f_{w,b}(\\mathbf{x}+\\boldsymbol{\\delta}) \\le 0 \\}]$。这在一个有限的测试集上进行估计。\n-   **条件**：如果 $\\hat{R}_{\\text{train}}^{\\text{adv}} - \\hat{R}_{\\text{train}}^{\\text{std}} \\ge \\tau$ 并且 $R_{\\text{test, perturbed}}^{\\text{std}} - R_{\\text{test, perturbed}}^{\\text{adv}} \\ge \\tau$，则布尔指标为真，其中 $\\tau = 0.01$。\n-   **测试参数**：包含4个案例的套件，指定了 $(\\text{seed}, n_{\\text{train}}, n_{\\text{test}}, d, m, \\sigma, \\lambda, \\text{lr}, \\text{steps}, \\epsilon)$。\n\n**1.2. 验证结论：**\n问题是**有效的**。它在科学上基于已建立的机器学习原则，在数学上是良定的（凸目标函数，明确定义的过程），并使用精确、客观的语言。其设置是自洽的，没有矛盾或歧义。这项任务虽然需要仔细实现，但是一个理解对抗鲁棒性的标准且信息丰富的练习。\n\n### 步骤 2：理论推导\n\n在实现之前，我们推导必要的解析表达式。\n\n**2.1. 内部最小化（对抗性攻击）：**\n对抗性训练和评估的核心是为给定的样本 $(\\mathbf{x}, y)$ 和模型 $(\\mathbf{w}, b)$ 解决内部最小化问题：\n$$ \\min_{\\|\\boldsymbol{\\delta}\\|_{2}\\le \\epsilon} y f_{w,b}(\\mathbf{x}+\\boldsymbol{\\delta}) $$\n由于 $f_{w,b}$ 是线性的，这变为：\n$$ \\min_{\\|\\boldsymbol{\\delta}\\|_{2}\\le \\epsilon} y (\\mathbf{w}^{\\top}(\\mathbf{x}+\\boldsymbol{\\delta}) + b) = y (\\mathbf{w}^{\\top}\\mathbf{x} + b) + \\min_{\\|\\boldsymbol{\\delta}\\|_{2}\\le \\epsilon} y \\mathbf{w}^{\\top}\\boldsymbol{\\delta} $$\n当向量 $\\boldsymbol{\\delta}$ 与 $-y\\mathbf{w}$ 的方向最大程度对齐时，$y \\mathbf{w}^{\\top}\\boldsymbol{\\delta}$ 项被最小化。根据柯西-施瓦茨不等式，$\\mathbf{w}^{\\top}\\boldsymbol{\\delta}$ 的最小值为 $-\\epsilon\\|\\mathbf{w}\\|_2$，在 $\\boldsymbol{\\delta} = -\\epsilon \\frac{\\mathbf{w}}{\\|\\mathbf{w}\\|_2}$ 时达到。因此，最小化 $y \\mathbf{w}^{\\top}\\boldsymbol{\\delta}$ 的最优扰动 $\\boldsymbol{\\delta}^*$ 是：\n$$ \\boldsymbol{\\delta}^* = -y\\epsilon \\frac{\\mathbf{w}}{\\|\\mathbf{w}\\|_2} \\quad (\\text{如果 } \\mathbf{w} \\neq \\mathbf{0}; \\text{ 如果 } \\mathbf{w} = \\mathbf{0}, \\text{ 则为任何有效的 } \\boldsymbol{\\delta}) $$\n将其代回，损失函数参数的最小值为：\n$$ \\min_{\\|\\boldsymbol{\\delta}\\|_{2}\\le \\epsilon} y f_{w,b}(\\mathbf{x}+\\boldsymbol{\\delta}) = y(\\mathbf{w}^{\\top}\\mathbf{x} + b) - y^2 \\epsilon \\frac{\\mathbf{w}^{\\top}\\mathbf{w}}{\\|\\mathbf{w}\\|_2} = y(\\mathbf{w}^{\\top}\\mathbf{x} + b) - \\epsilon \\|\\mathbf{w}\\|_2 $$\n这定义了“鲁棒间隔”，它用于对抗性训练目标和扰动误差评估。\n\n**2.2. 梯度下降的梯度推导：**\n设总目标函数为 $J(\\mathbf{w}, b)$。我们寻求其梯度。设 $z_i = y_i(\\mathbf{w}^{\\top}\\mathbf{x}_i+b)$ 为标准间隔，$z_i^{\\text{adv}} = z_i - \\epsilon \\|\\mathbf{w}\\|_2$ 为鲁棒间隔。逻辑斯蒂损失的导数为 $\\ell'(z) = -1/(1+e^z)$。\n\n-   **标准训练梯度**：\n    目标函数是 $J_{\\text{std}} = \\frac{1}{n}\\sum_i \\ell(z_i) + \\frac{\\lambda}{2}\\|\\mathbf{w}\\|_2^2$。\n    $$ \\nabla_{\\mathbf{w}} J_{\\text{std}} = \\frac{1}{n} \\sum_{i=1}^{n} \\ell'(z_i) \\frac{\\partial z_i}{\\partial \\mathbf{w}} + \\lambda\\mathbf{w} = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{-y_i \\mathbf{x}_i}{1+\\exp(z_i)} + \\lambda\\mathbf{w} $$\n    $$ \\frac{\\partial J_{\\text{std}}}{\\partial b} = \\frac{1}{n} \\sum_{i=1}^{n} \\ell'(z_i) \\frac{\\partial z_i}{\\partial b} = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{-y_i}{1+\\exp(z_i)} $$\n\n-   **对抗性训练梯度**：\n    目标函数是 $J_{\\text{adv}} = \\frac{1}{n}\\sum_i \\ell(z_i^{\\text{adv}}) + \\frac{\\lambda}{2}\\|\\mathbf{w}\\|_2^2$。\n    鲁棒间隔关于 $\\mathbf{w}$ 的梯度为 $\\nabla_{\\mathbf{w}} z_i^{\\text{adv}} = y_i \\mathbf{x}_i - \\epsilon \\frac{\\mathbf{w}}{\\|\\mathbf{w}\\|_2}$（对于 $\\mathbf{w} \\neq \\mathbf{0}$）。\n    $$ \\nabla_{\\mathbf{w}} J_{\\text{adv}} = \\frac{1}{n} \\sum_{i=1}^{n} \\ell'(z_i^{\\text{adv}}) \\nabla_{\\mathbf{w}} z_i^{\\text{adv}} + \\lambda\\mathbf{w} = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{-1}{1+\\exp(z_i^{\\text{adv}})} \\left( y_i \\mathbf{x}_i - \\epsilon \\frac{\\mathbf{w}}{\\|\\mathbf{w}\\|_2} \\right) + \\lambda\\mathbf{w} $$\n    对 $b$ 的依赖性与标准情况相同：\n    $$ \\frac{\\partial J_{\\text{adv}}}{\\partial b} = \\frac{1}{n} \\sum_{i=1}^{n} \\ell'(z_i^{\\text{adv}}) \\frac{\\partial z_i^{\\text{adv}}}{\\partial b} = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{-y_i}{1+\\exp(z_i^{\\text{adv}})} $$\n\n### 步骤 3：算法实现\n\n基于这些推导，构建一个 Python 程序。\n\n1.  **数据生成**：一个函数 `generate_data` 根据指定的概率模型创建数据集，并为可复现性设置种子。\n2.  **模型训练**：一个函数 `train_model` 实现批量梯度下降。它接受一个布尔标志 `is_adversarial` 来在标准和对抗性梯度计算之间切换。参数 $(\\mathbf{w}, b)$ 分别初始化为零向量和标量。为提高效率，梯度被计算为向量化的 numpy 操作。在对抗性梯度计算中，使用一个小的容差 ($10^{-9}$) 来防止在归一化 $\\mathbf{w}$ 时出现除以零的情况。\n3.  **误差计算**：一个函数 `calculate_error_rate` 计算错分类率。它接受一个 `epsilon_eval` 参数。\n    -   如果 `epsilon_eval = 0.0`，它通过检查标准间隔 $y(\\mathbf{w}^{\\top}\\mathbf{x}+b) \\le 0$ 来计算干净误差。\n    -   如果 `epsilon_eval > 0.0`，它通过检查鲁棒间隔 $y(\\mathbf{w}^{\\top}\\mathbf{x}+b) - \\epsilon_{\\text{eval}}\\|\\mathbf{w}\\|_2 \\le 0$ 来计算扰动误差。\n4.  **主循环**：主脚本遍历测试用例。对于每个用例，它生成训练和测试数据，训练标准和对抗性模型，计算所需的四个误差指标（$\\hat{R}_{\\text{train}}^{\\text{std}}$, $\\hat{R}_{\\text{train}}^{\\text{adv}}$, $R_{\\text{test, perturbed}}^{\\text{std}}$, $R_{\\text{test, perturbed}}^{\\text{adv}}$），并评估布尔条件。收集结果并以指定格式打印。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the adversarial training problem by implementing and evaluating\n    standard and robust classifiers according to the problem specification.\n    \"\"\"\n\n    # Each tuple is (seed, n_train, n_test, d, m, sigma, lambda, lr, steps, epsilon)\n    test_cases = [\n        (0, 500, 4000, 5, 1.5, 0.6, 0.01, 0.1, 2000, 0.0),\n        (1, 500, 4000, 5, 1.5, 0.6, 0.01, 0.1, 2000, 0.5),\n        (2, 500, 4000, 5, 1.5, 0.6, 0.01, 0.1, 2000, 1.0),\n        (3, 500, 4000, 5, 1.5, 0.6, 0.01, 0.1, 2000, 2.0),\n    ]\n\n    tau = 0.01\n    results = []\n\n    def generate_data(n, d, m, sigma, u_vec, generator):\n        \"\"\"Generates data according to the problem's distributional model.\"\"\"\n        y = generator.choice([-1, 1], size=n)\n        xi = generator.normal(0, sigma, size=(n, d))\n        X = y[:, np.newaxis] * m * u_vec.reshape(1, d) + xi\n        return X, y\n\n    def train_model(X, y, is_adversarial, lambda_, lr, steps, epsilon):\n        \"\"\"\n        Trains a linear model with logistic loss using gradient descent.\n        Can perform standard (is_adversarial=False) or adversarial training.\n        \"\"\"\n        n, d_ = X.shape\n        w = np.zeros(d_)\n        b = 0.0\n\n        for _ in range(steps):\n            scores = X @ w + b\n            \n            if is_adversarial:\n                margins = y * scores\n                norm_w = np.linalg.norm(w)\n                effective_margins = margins - epsilon * norm_w\n                loss_grad_coeffs = -1 / (1 + np.exp(effective_margins))\n                grad_margin_w = y[:, np.newaxis] * X\n                if norm_w > 1e-9:\n                    grad_margin_w -= epsilon * (w / norm_w)\n                grad_w = (1/n) * np.sum(loss_grad_coeffs[:, np.newaxis] * grad_margin_w, axis=0)\n                grad_b = (1/n) * np.sum(loss_grad_coeffs * y)\n            else:\n                margins = y * scores\n                loss_grad_coeffs = -1 / (1 + np.exp(margins))\n                grad_w = (1/n) * np.sum((loss_grad_coeffs * y)[:, np.newaxis] * X, axis=0)\n                grad_b = (1/n) * np.sum(loss_grad_coeffs * y)\n\n            grad_w += lambda_ * w\n            w -= lr * grad_w\n            b -= lr * grad_b\n        \n        return w, b\n\n    def calculate_error_rate(X, y, w, b, epsilon_eval):\n        \"\"\"\n        Calculates misclassification rate. epsilon_eval=0 for clean error, > 0 for perturbed.\n        \"\"\"\n        n_samples = X.shape[0]\n        if n_samples == 0:\n            return 0.0\n        scores = X @ w + b\n        norm_w = np.linalg.norm(w)\n        effective_margins = y * scores - epsilon_eval * norm_w\n        misclassified_count = np.sum(effective_margins = 0)\n        return misclassified_count / n_samples\n\n    for case in test_cases:\n        seed, n_train, n_test, d, m, sigma, lambda_, lr, steps, epsilon = case\n        \n        rng = np.random.default_rng(seed)\n        \n        u_vec = np.zeros(d)\n        u_vec[0] = 1.0\n\n        X_train, y_train = generate_data(n_train, d, m, sigma, u_vec, rng)\n        X_test, y_test = generate_data(n_test, d, m, sigma, u_vec, rng)\n\n        # Train the standard model\n        w_std, b_std = train_model(X_train, y_train, is_adversarial=False, lambda_=lambda_, lr=lr, steps=steps, epsilon=0.0)\n        \n        # Train the adversarial model\n        w_adv, b_adv = train_model(X_train, y_train, is_adversarial=True, lambda_=lambda_, lr=lr, steps=steps, epsilon=epsilon)\n\n        # Calculate clean empirical training error for both models\n        R_train_std = calculate_error_rate(X_train, y_train, w_std, b_std, epsilon_eval=0.0)\n        R_train_adv = calculate_error_rate(X_train, y_train, w_adv, b_adv, epsilon_eval=0.0)\n\n        # Calculate perturbed test error for both models\n        R_test_pert_std = calculate_error_rate(X_test, y_test, w_std, b_std, epsilon_eval=epsilon)\n        R_test_pert_adv = calculate_error_rate(X_test, y_test, w_adv, b_adv, epsilon_eval=epsilon)\n\n        # Evaluate the specified boolean condition\n        cond_train_error = (R_train_adv - R_train_std) = tau\n        cond_test_error = (R_test_pert_std - R_test_pert_adv) = tau\n        \n        results.append(cond_train_error and cond_test_error)\n        \n    # Print the final list of boolean results\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3188152"}, {"introduction": "一个有效的防御机制必须是真正稳健的，而不仅仅是能够抵御某一特定类型的攻击。这个练习揭示了一种被称为“梯度混淆”（obfuscated gradients）的常见陷阱，即模型由于激活函数的饱和特性，使得基于梯度的攻击失效，从而产生一种虚假的安全感。通过对比白盒（基于梯度）攻击和简单的黑盒（基于查询）攻击，您将学会如何诊断这种虚假安全感，并理解全面评估的重要性 [@problem_id:3097022]。", "problem": "考虑在经验风险最小化的设定下的二元分类问题，其标量分数函数为 $z(x) = s \\cdot (w^\\top x + b)$，正类的概率为 $p(x)$。对于一个带标签的样本 $(x,y)$，其中 $y \\in \\{0,1\\}$，其损失函数为伯努利交叉熵，定义为 $L(x,y) = -\\left[y \\log p(x) + (1-y)\\log(1-p(x))\\right]$。对抗性训练中一种常见的防御方法是输入梯度正则化，它会对训练样本的梯度范数平方 $\\|\\nabla_x p(x)\\|_2^2$ 的均值进行惩罚。然而，如果激活函数饱和（例如，在中心线性区域之外是分段平坦的），那么 $\\nabla_x p(x)$ 可以在不提高真实鲁棒性的情况下被强制置为零，这可能导致混淆梯度。\n\n从以下基础出发：\n- 对参数 $w \\in \\mathbb{R}^d$，$b \\in \\mathbb{R}$ 和一个固定的缩放因子 $s \\in \\mathbb{R}$ 进行经验风险最小化。\n- 伯努利交叉熵 $L(x,y)$ 及其通过 $p(x)$ 与 $\\nabla_x L(x,y)$ 之间的链式法则关系。\n- 快速梯度符号法 (FGSM)，为 $\\ell_\\infty$ 预算 $\\epsilon  0$ 定义为 $x_{\\text{adv}} = x + \\epsilon \\cdot \\operatorname{sign}(\\nabla_x L(x,y))$。\n- 一种简单的黑盒攻击，它搜索一组有限的查询方向 $v$（其中 $\\|v\\|_\\infty = \\epsilon$），如果 $\\hat{y}(x+v) \\neq \\hat{y}(x)$，则宣布攻击成功，其中 $\\hat{y}(x) = \\mathbf{1}\\{p(x) \\ge 1/2\\}$。\n\n构建一个玩具反例，该反例包含两个模型：\n1. 一个平滑模型，使用 logistic 激活函数 $p_{\\text{soft}}(x) = \\sigma\\!\\left(s_{\\text{soft}} \\cdot (w^\\top x + b)\\right)$，其中 $\\sigma(u) = 1/(1+e^{-u})$。\n2. 一个饱和模型，使用硬饱和激活函数 $p_{\\text{hard}}(x) = \\frac{1}{2}\\left(\\operatorname{clip}\\!\\left(s_{\\text{hard}}\\cdot(w^\\top x + b), -1, 1\\right) + 1\\right)$，其中 $\\operatorname{clip}(u,-1,1)$ 是分段线性的，在 $[-1,1]$ 之外是平坦的。\n\n对于平滑模型，在决策边界附近 $\\nabla_x L(x,y)$ 是非零的；FGSM 通常在一个适度的 $\\ell_\\infty$ 预算内能够成功。对于饱和模型，当 $s_{\\text{hard}}\\cdot(w^\\top x + b)$ 位于 $[-1,1]$ 之外时，$p_{\\text{hard}}$ 对 $x$ 的导数恒为零，使得 $\\nabla_x L(x,y)$ 等于零，尽管输入空间中的决策边界可能仍在黑盒搜索的可及范围之内。这种不匹配是混淆梯度的例证：基于梯度的攻击失败，而基于查询的攻击成功。\n\n你的任务是编写一个完整的程序，该程序：\n- 实现 $p_{\\text{soft}}(x)$ 和 $p_{\\text{hard}}(x)$，使用固定的参数 $w$、$b$、$s_{\\text{soft}}$ 和 $s_{\\text{hard}}$。\n- 对两个模型计算 $\\nabla_x L(x,y)$，使用关于 $p(x)$ 和 $z(x)$ 的链式法则，并注意正确处理 $p_{\\text{hard}}(x)$ 的饱和导数。\n- 在 $\\ell_\\infty$ 预算 $\\epsilon$ 下应用 FGSM，并返回标签是否翻转。\n- 应用黑盒查询攻击，该攻击评估一组有限的扰动 $v$（其中 $\\|v\\|_\\infty = \\epsilon$，包括坐标轴和对角线方向），并返回是否有任何扰动使标签翻转。\n- 对一个测试用例诊断是否存在混淆梯度，其布尔值定义为 $\\left[\\text{FGSM 失败}\\right] \\wedge \\left[\\text{黑盒攻击成功}\\right]$。\n\n使用以下固定参数和测试套件。所有向量都在 $\\mathbb{R}^2$ 中：\n- 模型参数：$w = [1, 1]$，$b = 0$，$s_{\\text{soft}} = 1$，$s_{\\text{hard}} = 50$。\n- 预算：$\\epsilon = 0.2$（此为无量纲值，无物理单位）。\n- 测试用例（每个测试用例指定模型、输入 $x$ 和标签 $y$）：\n    1. 平滑模型，$x = [0.05, 0.05]$，$y = 1$。\n    2. 饱和模型，$x = [0.05, 0.05]$，$y = 1$。\n    3. 饱和模型，$x = [0.5, 0.5]$，$y = 1$。\n    4. 平滑模型，$x = [-0.05, -0.05]$，$y = 0$。\n\n对于每个测试用例，你的程序必须输出是否检测到混淆梯度，这由上述规则计算的布尔值定义。你的程序应生成单行输出，其中包含按测试用例顺序排列的结果，格式为逗号分隔的列表并用方括号括起，例如 $[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4]$，其中每个 $\\text{result}_i$ 是 $\\text{True}$ 或 $\\text{False}$。\n\n该程序必须是自包含的，不需要用户输入。它必须仅依赖于指定的运行时环境和库。", "solution": "此问题是有效的，因为它在统计学习和对抗样本领域内提出了一个适定且有科学依据的任务。它提供了所有必要的数学定义、参数和测试用例，以构建一个可行的反例来演示混淆梯度现象。\n\n解决方案首先推导模型梯度所需的数学表达式，然后指定对抗性攻击的算法，最后将此框架应用于提供的测试用例。\n\n问题的核心在于损失函数梯度 $\\nabla_x L(x,y)$ 的计算，这对于快速梯度符号法 (FGSM) 攻击至关重要。损失函数是伯努利交叉熵：\n$$L(x,y) = -\\left[y \\log p(x) + (1-y)\\log(1-p(x))\\right]$$\n其中 $y \\in \\{0,1\\}$ 是真实标签，$p(x)$ 是模型预测为正类（$y=1$）的概率。梯度 $\\nabla_x L(x,y)$ 可以通过链式法则求得。令 $u(x)$ 为预激活分数，使得 $p(x) = f(u(x))$，其中 $f$ 为某个激活函数。\n$$\\nabla_x L(x,y) = \\frac{\\partial L}{\\partial p} \\frac{dp}{du} \\nabla_x u(x)$$\n一个已知的简化形式给出 $\\frac{\\partial L}{\\partial p} = \\frac{p(x)-y}{p(x)(1-p(x))}$。其余项 $\\frac{dp}{du}$ 和 $\\nabla_x u(x)$ 取决于具体的模型。\n\n在这个问题中，预激活分数为 $u(x) = s \\cdot (w^\\top x + b)$。它关于输入 $x$ 的梯度为：\n$$\\nabla_x u(x) = s \\cdot w$$\n现在我们分析所提供的两个模型。\n\n1.  **平滑模型 (Logistic 激活函数)**\n    概率由 $p_{\\text{soft}}(x) = \\sigma(u(x))$ 给出，其中 $u(x) = s_{\\text{soft}} \\cdot (w^\\top x + b)$，$\\sigma(u) = 1/(1+e^{-u})$ 是 logistic sigmoid 函数。sigmoid 函数的导数是一个关键性质：$\\frac{d\\sigma}{du} = \\sigma(u)(1-\\sigma(u))$。\n    将此代入损失梯度的链式法则中：\n    $$\\frac{dp_{\\text{soft}}}{du} = \\frac{d\\sigma(u(x))}{du} = p_{\\text{soft}}(x)(1-p_{\\text{soft}}(x))$$\n    组合成完整的梯度：\n    $$\\nabla_x L(x,y) = \\frac{p_{\\text{soft}}(x)-y}{p_{\\text{soft}}(x)(1-p_{\\text{soft}}(x))} \\cdot \\left[p_{\\text{soft}}(x)(1-p_{\\text{soft}}(x))\\right] \\cdot (s_{\\text{soft}} \\cdot w)$$\n    这可以优雅地简化为：\n    $$\\nabla_x L(x,y) = (p_{\\text{soft}}(x) - y) \\cdot s_{\\text{soft}} \\cdot w$$\n    该梯度通常是非零的，尤其是在决策边界附近，此时 $p_{\\text{soft}}(x)$ 不接近 $y \\in \\{0, 1\\}$。\n\n2.  **饱和模型 (硬饱和激活函数)**\n    概率为 $p_{\\text{hard}}(x) = \\frac{1}{2}\\left(\\operatorname{clip}(u(x), -1, 1) + 1\\right)$，其中 $u(x) = s_{\\text{hard}} \\cdot (w^\\top x + b)$。clip 函数定义为：\n    $$\\operatorname{clip}(u, -1, 1) = \\begin{cases} 1  \\text{if } u > 1 \\\\ u  \\text{if } -1 \\le u \\le 1 \\\\ -1  \\text{if } u  -1 \\end{cases}$$\n    它的导数（在存在的地方）是一个阶跃函数：\n    $$\\frac{d}{du}\\operatorname{clip}(u, -1, 1) = \\begin{cases} 0  \\text{if } |u| > 1 \\\\ 1  \\text{if } |u|  1 \\end{cases}$$\n    因此，$p_{\\text{hard}}$ 关于 $u$ 的导数为：\n    $$\\frac{dp_{\\text{hard}}}{du} = \\frac{1}{2} \\cdot \\frac{d}{du}\\operatorname{clip}(u, -1, 1) = \\begin{cases} 0  \\text{if } |u| > 1 \\\\ 1/2  \\text{if } |u|  1 \\end{cases}$$\n    完整的梯度 $\\nabla_x L(x,y)$ 为：\n    $$\\nabla_x L(x,y) = \\frac{p_{\\text{hard}}(x)-y}{p_{\\text{hard}}(x)(1-p_{\\text{hard}}(x))} \\cdot \\frac{dp_{\\text{hard}}}{du} \\cdot (s_{\\text{hard}} \\cdot w)$$\n    关键的观察点在于饱和区域，其中 $|u(x)| = |s_{\\text{hard}} \\cdot (w^\\top x + b)| > 1$。在此区域，$\\frac{dp_{\\text{hard}}}{du} = 0$，这导致整个梯度变为零：\n    $$\\nabla_x L(x,y) = 0 \\quad \\text{if } |s_{\\text{hard}} \\cdot (w^\\top x + b)| > 1$$\n    这就是混淆梯度的数学根源。损失梯度消失不是因为模型鲁棒，而是因为选择了非平滑的饱和激活函数。\n\n对抗性攻击定义如下：\n- **FGSM 攻击**：一种白盒攻击，它在 $\\ell_\\infty$ 约束 $\\epsilon$ 下，沿着使损失最大化增加的方向扰动输入 $x$。对抗样本为 $x_{\\text{adv}} = x + \\epsilon \\cdot \\operatorname{sign}(\\nabla_x L(x,y))$。如果预测标签翻转，即 $\\hat{y}(x_{\\text{adv}}) \\neq \\hat{y}(x)$，则攻击成功，其中 $\\hat{y}(x) = \\mathbf{1}\\{p(x) \\ge 1/2\\}$。如果 $\\nabla_x L(x,y)=0$，则 $x_{\\text{adv}}=x$，攻击失败。\n\n- **黑盒攻击**：一种简单的基于查询的攻击，不使用梯度信息。它测试一组有限的扰动 $v$，其中 $\\|v\\|_\\infty = \\epsilon$。问题指定使用沿坐标轴和对角线的方向。对于 $\\mathbb{R}^2$，这对应于八个向量 $v \\in \\{ [c_1, c_2] \\mid c_1, c_2 \\in \\{-\\epsilon, 0, \\epsilon\\}, \\text{ 且不全为零} \\}$。如果对于集合中的任何 $v$，有 $\\hat{y}(x+v) \\neq \\hat{y}(x)$，则攻击成功。\n\n**诊断混淆梯度**：当基于梯度的攻击（FGSM）失败，而简单的无梯度攻击（黑盒搜索）成功时，就检测到了混淆梯度。该条件形式化为：\n$$[\\text{FGSM 失败}] \\land [\\text{黑盒攻击成功}]$$\n\n例如，在测试用例 2（饱和模型，$x = [0.05, 0.05]$）中，预激活值为 $u(x) = s_{\\text{hard}}(w^\\top x+b) = 50(0.05+0.05) = 5$。由于 $|u(x)|=5 > 1$，模型处于饱和区域，$\\nabla_x L(x,y) = 0$。因此 FGSM 失败。然而，决策边界是 $x_1+x_2 = 0$。一个黑盒扰动 $v = [-\\epsilon, 0] = [-0.2, 0]$ 产生 $x' = [0.05, 0.05] + [-0.2, 0] = [-0.15, 0.05]$。对于这个新点，$w^\\top x' + b = -0.15+0.05 = -0.1  0$，导致标签翻转。因此，黑盒攻击成功，满足了混淆梯度的条件。相反，对于远离边界的点（测试用例 3），即使是黑盒攻击也失败了，这表明对于该扰动预算具有真正的鲁棒性。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and evaluates models for obfuscated gradients in adversarial ML.\n    \"\"\"\n    # Fixed parameters\n    W = np.array([1.0, 1.0])\n    B = 0.0\n    S_SOFT = 1.0\n    S_HARD = 50.0\n    EPSILON = 0.2\n\n    # --- Model and Prediction Functions ---\n\n    def p_soft(x, w, b, s_soft):\n        \"\"\"Computes probability for the smooth model.\"\"\"\n        u = s_soft * (w @ x + b)\n        return 1.0 / (1.0 + np.exp(-u))\n\n    def p_hard(x, w, b, s_hard):\n        \"\"\"Computes probability for the saturated model.\"\"\"\n        u = s_hard * (w @ x + b)\n        clipped_u = np.clip(u, -1.0, 1.0)\n        return 0.5 * (clipped_u + 1.0)\n\n    def predict(p_val):\n        \"\"\"Computes the binary prediction from a probability.\"\"\"\n        return 1 if p_val = 0.5 else 0\n\n    # --- Gradient Calculation Functions ---\n\n    def nabla_L_soft(x, y, w, b, s_soft):\n        \"\"\"Computes the loss gradient for the smooth model.\"\"\"\n        p_val = p_soft(x, w, b, s_soft)\n        return (p_val - y) * s_soft * w\n\n    def nabla_L_hard(x, y, w, b, s_hard):\n        \"\"\"Computes the loss gradient for the saturated model.\"\"\"\n        u = s_hard * (w @ x + b)\n        if np.abs(u) = 1.0:\n            return np.array([0.0, 0.0])\n        \n        # This part is only for the linear region, but we can compute it\n        # more robustly to avoid division by zero if p is 0 or 1.\n        # Since the gradient is non-zero only when -1  u  1,\n        # p is strictly between 0 and 1, so no division by zero occurs.\n        p_val = p_hard(x, w, b, s_hard)\n        # Factor dp/du = 1/2, Factor du/dx=s_hard*w\n        # Chain rule for the linear region:\n        # dL/dp * dp/du * du/dx = ((p-y)/(p(1-p))) * (1/2) * s_hard * w\n        numerator = p_val - y\n        denominator = p_val * (1.0 - p_val)\n        if abs(denominator)  1e-9: # Avoid division by zero\n             return np.array([0.0, 0.0])\n        grad = (numerator / denominator) * (s_hard / 2.0) * w\n        return grad\n\n    # --- Adversarial Attack Functions ---\n\n    def fgsm_attack_succeeds(x, y, model_type):\n        \"\"\"\n        Performs an FGSM attack and returns True if the label flips.\n        \"\"\"\n        x = np.array(x)\n        \n        if model_type == 'soft':\n            p_func = p_soft\n            nabla_func = nabla_L_soft\n            s = S_SOFT\n        else: # model_type == 'hard'\n            p_func = p_hard\n            nabla_func = nabla_L_hard\n            s = S_HARD\n\n        y_pred_orig = predict(p_func(x, W, B, s))\n        \n        grad = nabla_func(x, y, W, B, s)\n        \n        # FGSM perturbation\n        x_adv = x + EPSILON * np.sign(grad)\n        \n        y_pred_adv = predict(p_func(x_adv, W, B, s))\n        \n        return y_pred_adv != y_pred_orig\n\n    def black_box_attack_succeeds(x, model_type):\n        \"\"\"\n        Performs a black-box query attack and returns True if any query flips the label.\n        \"\"\"\n        x = np.array(x)\n        \n        if model_type == 'soft':\n            p_func = p_soft\n            s = S_SOFT\n        else: # model_type == 'hard'\n            p_func = p_hard\n            s = S_HARD\n            \n        y_pred_orig = predict(p_func(x, W, B, s))\n        \n        # 8 query directions for R^2 (axes and diagonals)\n        perturbations = [\n            np.array([EPSILON, 0]), np.array([-EPSILON, 0]),\n            np.array([0, EPSILON]), np.array([0, -EPSILON]),\n            np.array([EPSILON, EPSILON]), np.array([EPSILON, -EPSILON]),\n            np.array([-EPSILON, EPSILON]), np.array([-EPSILON, -EPSILON])\n        ]\n        \n        for v in perturbations:\n            x_query = x + v\n            y_pred_query = predict(p_func(x_query, W, B, s))\n            if y_pred_query != y_pred_orig:\n                return True\n                \n        return False\n\n    # --- Test Suite ---\n    test_cases = [\n        {'model': 'soft', 'x': [0.05, 0.05], 'y': 1},\n        {'model': 'hard', 'x': [0.05, 0.05], 'y': 1},\n        {'model': 'hard', 'x': [0.5, 0.5], 'y': 1},\n        {'model': 'soft', 'x': [-0.05, -0.05], 'y': 0},\n    ]\n\n    results = []\n    for case in test_cases:\n        fgsm_failed = not fgsm_attack_succeeds(case['x'], case['y'], case['model'])\n        black_box_succeeded = black_box_attack_succeeds(case['x'], case['model'])\n        \n        # Diagnose obfuscated gradients as per the problem definition\n        obfuscated_gradient_detected = fgsm_failed and black_box_succeeded\n        results.append(obfuscated_gradient_detected)\n        \n    # Print results in the required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3097022"}]}