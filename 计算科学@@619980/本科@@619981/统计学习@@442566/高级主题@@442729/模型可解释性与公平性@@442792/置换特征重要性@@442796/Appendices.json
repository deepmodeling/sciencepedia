{"hands_on_practices": [{"introduction": "在应用机器学习中，最微妙也最具破坏性的挑战之一是数据泄漏。当训练数据中包含了目标变量的意外信息时，就会发生数据泄漏，导致模型在评估时表现出虚高的性能，但在实际部署中却表现不佳。置换特征重要性 (PFI) 为我们提供了一种强大的、与模型无关的方法，用于“审计”模型的特征，并标记那些预测能力异常强的特征，而这些特征往往就是数据泄漏的源头。这个实践练习 [@problem_id:3156657] 将指导你构建一个模拟场景，亲手实现一个泄漏检测器，从而直观地理解 PFI 在维护模型稳健性方面的关键作用。", "problem": "您必须编写一个完整、可运行的程序，该程序构建包含和不包含标签泄露的合成数据集，并使用置换特征重要性 (PFI) 来检测可疑特征。该程序必须从平方损失下的经验风险开始，从第一性原理实现所有计算，并且不得依赖任何外部机器学习库。程序将执行一个小的参数设置测试套件，并输出一行收集检测结果。\n\n背景与基本原理：从平方损失下的经验风险最小化开始。对于一个特征矩阵 $X \\in \\mathbb{R}^{n \\times d}$ 和目标向量 $y \\in \\mathbb{R}^{n}$，数据集上的平方损失是由均方误差 (MSE) 定义的经验风险，对于预测值 $\\hat{y}$，其定义为 $ \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 $。通过普通最小二乘法 (OLS) 或带有小 $\\ell_2$ 正则化项的数值稳定变体，最小化经验平方损失来拟合线性预测器。通过量化在保持模型固定的情况下，当单个特征被随机置换时经验风险的变化，来估计该特征的 PFI。\n\n数据生成：对于每个测试用例，生成一个包含 $n_{\\text{train}} = 800$ 个样本的训练集和一个包含 $n_{\\text{test}} = 200$ 个样本的测试集。对于训练集和测试集，从标准正态分布 $ \\mathcal{N}(0,1) $ 中独立抽取基础特征 $X_1, X_2, X_3$。将目标生成为 $ y = 3 X_1 - 2 X_2 + \\epsilon $，其中独立噪声 $ \\epsilon \\sim \\mathcal{N}(0, \\sigma_\\epsilon^2) $ 且 $ \\sigma_\\epsilon = 0.5 $。定义泄露特征 $ X_{\\text{leak}} = y + \\delta $，其中 $ \\delta \\sim \\mathcal{N}(0, \\sigma_\\delta^2) $ 且 $ \\sigma_\\delta = \\gamma \\cdot \\operatorname{std}(y_{\\text{train}}) $。这里 $ \\gamma \\ge 0 $ 是一个控制泄露强度的测试用例参数。在“无泄露”条件下，不使用 $ X_{\\text{leak}} = y + \\delta $，而是将 $ X_{\\text{leak}} $ 构建为一个独立的、均值为零、标准差等于 $ \\operatorname{std}(y_{\\text{train}}) $ 的正态特征，且独立于 $ y $。用列 $ [X_1, X_2, X_3, X_{\\text{leak}}] $ 构成完整的特征矩阵。\n\n模型拟合：通过最小化训练集上的经验平方损失来拟合一个线性模型 $ \\hat{y} = X w $。使用系数为 $ \\lambda = 10^{-6} $ 的小 $\\ell_2$ 正则化（岭回归）以确保数值稳定性。计算测试集上的基线 MSE。\n\nPFI 估计：对于每个特征索引 $ j \\in \\{0,1,2,3\\} $，通过重复地仅置换测试特征矩阵的第 $ j $ 列来估计其 PFI，同时保持训练好的模型不变，重新计算测试 MSE，并计算相对于基线的 MSE 增加量的平均值。每个特征使用 $ B = 30 $ 次独立置换进行平均。所有随机性必须由程序中的固定种子控制，以确保可复现性。\n\n可疑特征标记：为进行泄露检测，定义两个阈值。令 $ \\Delta_j $ 表示特征 $ j $ 的估计 PFI，令 $ \\Delta_{\\text{leak}} $ 为泄露特征的 PFI。令 $ \\Delta_{\\max,\\neg\\text{leak}} $ 为所有非泄露特征中的最大 PFI。如果同时满足以下两个条件，则声明泄露特征为可疑特征：\n- 绝对风险准则：$ \\Delta_{\\text{leak}} \\ge \\tau \\cdot \\text{MSE}_{\\text{baseline}} $，\n- 相对优势准则：$ \\Delta_{\\text{leak}} \\ge \\alpha \\cdot \\Delta_{\\max,\\neg\\text{leak}} $。\n这里 $ \\tau > 0 $ 和 $ \\alpha > 1 $ 是测试用例参数。\n\n测试套件：针对以下四个参数集运行程序，每个集合是一个元组 $ (\\gamma, \\text{has\\_leak}, \\tau, \\alpha) $：\n- 情况 1：$ (\\gamma = 0.0, \\text{has\\_leak} = 1, \\tau = 1.0, \\alpha = 2.0) $。\n- 情况 2：$ (\\gamma = 0.2, \\text{has\\_leak} = 1, \\tau = 1.0, \\alpha = 2.0) $。\n- 情况 3：$ (\\gamma = 4.0, \\text{has\\_leak} = 1, \\tau = 1.0, \\alpha = 2.0) $。\n- 情况 4：$ (\\gamma = 0.0, \\text{has\\_leak} = 0, \\tau = 1.0, \\alpha = 2.0) $。\n\n对于每种情况，输出一个布尔值，指示泄露特征是否被标记为可疑。在整个程序中使用单个固定的随机种子以保证可复现性。\n\n最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的、以逗号分隔的结果列表，顺序与测试套件的用例一致（例如，$[r_1,r_2,r_3,r_4]$，其中每个 $ r_i $ 是一个布尔值）。除了这一行之外，不得有任何额外的输出或空格。", "solution": "该问题被评估为有效，因为它在科学上基于统计学习理论，定义完整且一致，问题阐述良好，并且其表述是客观的。我们将着手构建一个解决方案。\n\n目标是从第一性原理出发，实现一个使用置换特征重要性 (PFI) 检测数据泄露的程序。这涉及数据合成、模型拟合和重要性估计，最终形成一个标记可疑特征的决策规则。\n\n### 1. 数据生成\n\n我们从合成数据集开始。对于每个测试用例，我们生成一个大小为 $n_{\\text{train}} = 800$ 的训练集和一个大小为 $n_{\\text{test}} = 200$ 的测试集。过程如下：\n\n- **基础特征**：三个独立的基础特征 $X_1$、$X_2$ 和 $X_3$ 从标准正态分布 $\\mathcal{N}(0,1)$ 中抽取。我们为每个特征生成 $n_{\\text{train}} + n_{\\text{test}} = 1000$ 个样本，然后将它们划分为训练集和测试集。设基础特征矩阵为 $X_{\\text{base, train}} \\in \\mathbb{R}^{800 \\times 3}$ 和 $X_{\\text{base, test}} \\in \\mathbb{R}^{200 \\times 3}$。\n\n- **目标变量**：目标变量 $y$ 是前两个基础特征的线性组合，并加入了高斯噪声。其关系由下式给出：\n$$ y = 3 X_1 - 2 X_2 + \\epsilon $$\n其中噪声项 $\\epsilon$ 从 $\\mathcal{N}(0, \\sigma_\\epsilon^2)$ 中抽取，且 $\\sigma_\\epsilon = 0.5$。目标向量 $y_{\\text{train}}$ 和 $y_{\\text{test}}$ 使用相应的特征和噪声样本生成。\n\n- **泄露特征**：第四个特征 $X_{\\text{leak}}$ 在由 `has_leak` 参数指定的两种不同条件下构建：\n    1.  **有泄露 (`has_leak = 1`)**：该特征是目标变量的一个直接的、带噪声的副本：\n        $$ X_{\\text{leak}} = y + \\delta $$\n        噪声 $\\delta$ 从正态分布 $\\mathcal{N}(0, \\sigma_\\delta^2)$ 中抽取，其中标准差 $\\sigma_\\delta$ 是训练集中目标变量标准差和泄露强度参数 $\\gamma$ 的函数：\n        $$ \\sigma_\\delta = \\gamma \\cdot \\operatorname{std}(y_{\\text{train}}) $$\n        较小的 $\\gamma$ 意味着更强的泄露。$\\gamma=0$ 表示完美泄露，此时 $X_{\\text{leak}} = y$。\n    2.  **无泄露 (`has_leak = 0`)**：该特征的生成独立于目标 $y$。它从一个均值为 $0$、标准差等于训练目标变量标准差的正态分布中抽取：\n        $$ X_{\\text{leak}} \\sim \\mathcal{N}(0, (\\operatorname{std}(y_{\\text{train}}))^2) $$\n        这种设计确保了 $X_{\\text{leak}}$ 的边际分布与目标的尺度相似，使其成为一个看似合理但无泄露的特征。\n\n- **最终特征矩阵**：通过将基础特征与泄露特征拼接，形成完整的特征矩阵 $X_{\\text{train}}$ 和 $X_{\\text{test}}$，得到具有四列的矩阵：$[X_1, X_2, X_3, X_{\\text{leak}}]$。\n\n### 2. 模型拟合：岭回归\n\n一个线性模型 $\\hat{y} = Xw$ 被拟合到训练数据上。权重向量 $w \\in \\mathbb{R}^4$ 通过最小化带有小 $\\ell_2$ 正则化项（岭回归）的经验平方损失来确定，以确保数值稳定性。训练数据上的目标函数 $J(w)$ 为：\n$$ J(w) = \\frac{1}{n_{\\text{train}}} \\| y_{\\text{train}} - X_{\\text{train}}w \\|_2^2 + \\lambda \\|w\\|_2^2 $$\n其中 $\\lambda = 10^{-6}$ 是正则化系数。通过将梯度 $\\nabla_w J(w)$ 设为零，可以找到最优权重向量 $w$ 的封闭解：\n$$ \\nabla_w J(w) = \\frac{2}{n_{\\text{train}}} X_{\\text{train}}^T (X_{\\text{train}}w - y_{\\text{train}}) + 2\\lambda w = 0 $$\n$$ (X_{\\text{train}}^T X_{\\text{train}} + n_{\\text{train}}\\lambda I)w = X_{\\text{train}}^T y_{\\text{train}} $$\n这得到解：\n$$ w = (X_{\\text{train}}^T X_{\\text{train}} + n_{\\text{train}}\\lambda I)^{-1} X_{\\text{train}}^T y_{\\text{train}} $$\n其中 $I$ 是 $4 \\times 4$ 的单位矩阵。\n\n### 3. 置换特征重要性 (PFI)\n\nPFI 通过量化当特征值被随机打乱时模型性能的下降来衡量特征的重要性。这种打乱操作破坏了该特征与目标变量之间的关系。\n\n- **基线分数**：首先，我们计算训练好的模型在未经修改的测试集上的基线均方误差 (MSE)：\n$$ \\text{MSE}_{\\text{baseline}} = \\frac{1}{n_{\\text{test}}} \\sum_{i=1}^{n_{\\text{test}}} (y_{\\text{test},i} - (X_{\\text{test}}w)_i)^2 $$\n\n- **置换后分数**：对于每个特征 $j \\in \\{0, 1, 2, 3\\}$，我们重复以下过程 $B=30$ 次：\n    1.  通过随机打乱 $X_{\\text{test}}$ 的第 $j$ 列，创建一个置换后的测试矩阵 $X_{\\text{test}}^{(j,b)}$。\n    2.  用这个置换后的矩阵计算 MSE：$\\text{MSE}^{(j,b)} = \\frac{1}{n_{\\text{test}}} \\| y_{\\text{test}} - X_{\\text{test}}^{(j,b)}w \\|_2^2$。\n\n- **PFI 计算**：特征 $j$ 的 PFI，记为 $\\Delta_j$，是所有置换中 MSE 相对于基线 MSE 的平均增量：\n$$ \\Delta_j = \\left( \\frac{1}{B} \\sum_{b=1}^{B} \\text{MSE}^{(j,b)} \\right) - \\text{MSE}_{\\text{baseline}} $$\n一个大的正值 $\\Delta_j$ 表明模型在进行预测时严重依赖特征 $j$。\n\n### 4. 泄露检测\n\n任务的核心是使用计算出的 PFI 分数将泄露特征 ($j=3$) 标记为可疑。一个特征如果不仅重要，而且与其他信息丰富的特征相比其重要性不成比例地高，则被认为是可疑的。这通过两个准则来形式化：\n\n-   **绝对风险准则**：泄露特征的 PFI，$\\Delta_{\\text{leak}} = \\Delta_3$，必须超过一个与基线模型误差成比例的阈值。这确保了该特征的影响在绝对意义上是显著的。\n    $$ \\Delta_{\\text{leak}} \\ge \\tau \\cdot \\text{MSE}_{\\text{baseline}} $$\n-   **相对优势准则**：泄露特征的 PFI 必须显著大于任何非泄露特征的最大 PFI，$\\Delta_{\\max,\\neg\\text{leak}} = \\max(\\Delta_0, \\Delta_1, \\Delta_2)$。这可以识别出那些可疑地占主导地位的特征。\n    $$ \\Delta_{\\text{leak}} \\ge \\alpha \\cdot \\Delta_{\\max,\\neg\\text{leak}} $$\n\n当且仅当这两个条件都满足时，泄露特征才会被标记。参数 $\\tau$ 和 $\\alpha$ 控制检测逻辑的灵敏度，并在每个测试用例中提供。这种双阈值方法有助于区分真正泄露的特征和仅仅是强大、合法的预测因子。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Constructs synthetic datasets, fits a linear model, and uses Permutation\n    Feature Importance (PFI) to detect a suspicious leakage feature based on\n    pre-defined criteria. The implementation is from first principles.\n    \"\"\"\n    \n    # Set a single fixed random seed for reproducibility across the entire program.\n    np.random.seed(42)\n    rng = np.random.default_rng(42)\n\n    # Test suite parameters: (gamma, has_leak, tau, alpha)\n    test_cases = [\n        (0.0, 1, 1.0, 2.0),\n        (0.2, 1, 1.0, 2.0),\n        (4.0, 1, 1.0, 2.0),\n        (0.0, 0, 1.0, 2.0),\n    ]\n\n    results = []\n\n    for case_params in test_cases:\n        gamma, has_leak, tau, alpha = case_params\n\n        # --- 1. Data Generation ---\n        n_train = 800\n        n_test = 200\n        n_total = n_train + n_test\n        sigma_eps = 0.5\n\n        # Base features X1, X2, X3 from N(0,1)\n        X_base_all = rng.standard_normal(size=(n_total, 3))\n        X_base_train = X_base_all[:n_train, :]\n        X_base_test = X_base_all[n_train:, :]\n\n        # Target variable y = 3*X1 - 2*X2 + noise\n        epsilon = rng.normal(loc=0.0, scale=sigma_eps, size=n_total)\n        y_all = 3 * X_base_all[:, 0] - 2 * X_base_all[:, 1] + epsilon\n        y_train = y_all[:n_train]\n        y_test = y_all[n_train:]\n        \n        y_train_std = np.std(y_train)\n\n        # Leakage feature X_leak\n        if has_leak:\n            # X_leak = y + delta\n            sigma_delta = gamma * y_train_std\n            delta = rng.normal(loc=0.0, scale=sigma_delta, size=n_total)\n            X_leak_all = y_all + delta\n        else:\n            # X_leak is independent N(0, std(y_train)^2)\n            X_leak_all = rng.normal(loc=0.0, scale=y_train_std, size=n_total)\n        \n        X_leak_train = X_leak_all[:n_train].reshape(-1, 1)\n        X_leak_test = X_leak_all[n_train:].reshape(-1, 1)\n\n        # Final feature matrices\n        X_train = np.hstack([X_base_train, X_leak_train])\n        X_test = np.hstack([X_base_test, X_leak_test])\n        \n        # --- 2. Model Fitting (Ridge Regression) ---\n        lambda_reg = 1e-6\n        n_features = X_train.shape[1]\n        \n        XTX = X_train.T @ X_train\n        I = np.identity(n_features)\n        # w = (X'X + n_train * lambda * I)^-1 * X'y\n        weights = np.linalg.inv(XTX + n_train * lambda_reg * I) @ X_train.T @ y_train\n\n        # --- 3. PFI Estimation ---\n        B = 30  # Number of permutations\n        \n        # Baseline MSE on test set\n        y_pred_baseline = X_test @ weights\n        mse_baseline = np.mean((y_test - y_pred_baseline)**2)\n        \n        pfi_scores = []\n        for j in range(n_features):\n            permuted_mses = []\n            for _ in range(B):\n                X_test_permuted = X_test.copy()\n                col_to_permute = X_test_permuted[:, j].copy()\n                rng.shuffle(col_to_permute)\n                X_test_permuted[:, j] = col_to_permute\n                \n                y_pred_permuted = X_test_permuted @ weights\n                mse_permuted = np.mean((y_test - y_pred_permuted)**2)\n                permuted_mses.append(mse_permuted)\n            \n            mean_permuted_mse = np.mean(permuted_mses)\n            pfi_j = mean_permuted_mse - mse_baseline\n            pfi_scores.append(pfi_j)\n\n        # --- 4. Leakage Detection ---\n        pfi_leak_feature = pfi_scores[3]\n        # Handle case where all non-leak PFIs are negative\n        pfi_non_leak_scores = pfi_scores[:3]\n        pfi_max_non_leak = np.max(pfi_non_leak_scores) if pfi_non_leak_scores else 0.0\n\n        # Absolute-risk criterion\n        abs_risk_cond = (pfi_leak_feature >= tau * mse_baseline)\n        \n        # Relative-dominance criterion\n        rel_dom_cond = (pfi_leak_feature >= alpha * pfi_max_non_leak)\n        \n        is_suspicious = abs_risk_cond and rel_dom_cond\n        results.append(str(is_suspicious))\n\n    # Final output must be a single line in the specified format\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3156657"}, {"introduction": "特征的“重要性”并非一个绝对的概念，它与我们评估模型性能的方式息息相关。PFI 计算出的重要性分数直接取决于我们选择的评估指标，例如 AUC、F1 分数或对数损失。不同的指标关注模型性能的不同方面——AUC 衡量排序能力，F1 分数关注分类阈值下的精确率和召回率，而对数损失则评估预测概率的准确性。这个实践练习 [@problem_id:3156641] 将深入探讨在类别不平衡的现实场景中，特征重要性排序如何根据所选指标发生显著变化，从而强调了在进行特征重要性分析时审慎选择评估指标的必要性。", "problem": "您必须编写一个完整、可运行的程序，以实证方式检验在二元分类中，排列特征重要性（permutation feature importance）如何响应类别不平衡。此项研究必须通过在具有倾斜类别先验 $p(y)$ 的合成数据上训练一个概率分类器，然后在三种不同的指标下评估排列特征重要性：受试者工作特征曲线下面积（Area Under the Receiver Operating Characteristic Curve, AUC）、对数损失（log-loss）和F1分数。\n\n请从以下基本定义开始。\n\n- 二元分类设置：设 $(\\mathbf{x}_i, y_i)$（其中 $i \\in \\{1,\\dots,n\\}$）为独立同分布的样本，其特征为 $\\mathbf{x}_i \\in \\mathbb{R}^d$，二元标签为 $y_i \\in \\{0,1\\}$，从一个联合分布中抽取，该分布的类别先验为 $p(y=1) = \\pi \\in (0,1)$。\n- 逻辑回归模型：一个带有参数 $\\mathbf{w} \\in \\mathbb{R}^{d+1}$ 的概率分类器，它将一个增广特征向量 $\\tilde{\\mathbf{x}} = [1, \\mathbf{x}^\\top]^\\top$ 映射到一个预测概率 $\\hat{p}(y=1 \\mid \\mathbf{x}) = \\sigma(\\mathbf{w}^\\top \\tilde{\\mathbf{x}})$，其中 $\\sigma(z) = \\frac{1}{1 + e^{-z}}$ 是逻辑S型函数。带有 $\\ell_2$ 惩罚项的正则化经验风险是平均负对数似然加上对非截距系数的惩罚项。\n- 受试者工作特征曲线下面积（AUC）：AUC是一个随机选择的正例比一个随机选择的负例获得更高分数的概率；它是一个在 $[0,1]$ 区间内的标量。\n- 对数损失：对数损失（交叉熵）是负对数似然的经验均值，即 $-\\frac{1}{n}\\sum_{i=1}^n \\left[y_i \\log \\hat{p}_i + (1-y_i)\\log(1-\\hat{p}_i)\\right]$。\n- F1分数：F1分数是精确率（precision）和召回率（recall）的调和平均数。使用 $0.5$ 的固定阈值，定义预测标签 $\\hat{y}_i = \\mathbb{I}[\\hat{p}_i \\ge 0.5]$，则精确率为 $\\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FP}}$，召回率为 $\\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FN}}$，F1分数为 $\\frac{2 \\cdot \\mathrm{precision} \\cdot \\mathrm{recall}}{\\mathrm{precision} + \\mathrm{recall}}$，并约定除以 $0$ 的结果为 $0$。\n- 排列特征重要性（PFI）：给定一个已训练的模型和一个性能指标，\n  - 对于需要最大化的指标（如AUC和F1），特征 $j$ 的重要性定义为 $\\Delta_j = S(\\text{基线}) - S(\\text{已排列 } j)$，其中 $S$ 表示在未排列或已排列的测试集上计算的指标，且模型参数保持固定。\n  - 对于需要最小化的指标（如对数损失），重要性定义为 $\\Delta_j = L(\\text{已排列 } j) - L(\\text{基线})$，其中 $L$ 表示损失。在这两种情况下，更大的 $\\Delta_j$ 表示更高的重要性。\n\n数据生成过程。您的程序必须在 $d = 3$ 维空间中生成具有条件高斯特征和可控类别先验的合成数据。对于每个样本，抽取 $y \\sim \\mathrm{Bernoulli}(\\pi)$，然后以 $y$ 为条件，抽取 $\\mathbf{x} \\mid y \\sim \\mathcal{N}(\\boldsymbol{\\mu}_y, \\mathbf{I}_3)$，其均值为\n- $\\boldsymbol{\\mu}_1 = [2.0,\\, 0.8,\\, 0.0]^\\top$ 和\n- $\\boldsymbol{\\mu}_0 = [0.0,\\, 0.0,\\, 0.0]^\\top$，\n协方差为单位矩阵 $\\mathbf{I}_3$。训练和测试使用独立的抽取。\n\n训练。通过最小化平均负对数似然加上对非截距系数的 $\\ell_2$ 惩罚项（正则化强度 $\\lambda = 1.0$），来拟合一个带截距项的逻辑回归模型。使用一个能够可靠收敛的数值稳定的优化器。\n\n评估与排列。对于每个测试用例，在测试集上计算基线AUC、对数损失和F1分数。然后，通过独立地排列相应的测试特征列 $K$ 次并对结果变化进行平均（其中 $K = 5$），在每个指标下为3个特征中的每一个计算PFI。每个测试用例使用固定的随机种子以确保可复现性。\n\n跨指标比较。为了总结关于类别不平衡和指标选择的敏感性，请对每个测试用例执行以下两项操作：\n- 在每个指标下，确定最重要的特征的索引（从零开始），即对于AUC、对数损失和F1，计算 $\\arg\\max_j \\Delta_j$。若重要性相同，则选择最小的索引。\n- 计算 (AUC, 对数损失)、(AUC, F1) 和 (对数损失, F1) 这几对的3维PFI向量之间的Spearman秩相关性。如果相关性因秩的方差为零而未定义，则该相关性返回 $0.0$。\n\n测试套件。您的程序必须运行以下三个测试用例，每个用例指定了类别先验 $\\pi$、样本量和随机种子：\n- 用例1（平衡）：$\\pi = 0.5$，$n_{\\text{train}} = 4000$，$n_{\\text{test}} = 20000$，种子 $= 123$。\n- 用例2（中度不平衡）：$\\pi = 0.2$，$n_{\\text{train}} = 4000$，$n_{\\text{test}} = 20000$，种子 $= 456$。\n- 用例3（严重不平衡）：$\\pi = 0.05$，$n_{\\text{train}} = 4000$，$n_{\\text{test}} = 20000$，种子 $= 789$。\n\n答案规格与输出格式。对于每个用例，按以下固定顺序生成一个包含6个数字的列表：\n- AUC下最重要特征的索引（整数，在 $\\{0,1,2\\}$ 中），\n- 对数损失下最重要特征的索引（整数，在 $\\{0,1,2\\}$ 中），\n- F1分数下最重要特征的索引（整数，在 $\\{0,1,2\\}$ 中），\n- AUC-PFI和对数损失-PFI之间的Spearman秩相关性（浮点数），\n- AUC-PFI和F1-PFI之间的Spearman秩相关性（浮点数），\n- 对数损失-PFI和F1-PFI之间的Spearman秩相关性（浮点数）。\n\n将所有三个用例的结果按顺序汇总到一个长度为18的单个扁平列表中。您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果（例如，$[a_1,a_2,\\dots,a_{18}]$）。浮点数必须四舍五入到恰好6位小数，整数打印时不带小数。不涉及物理单位。不使用角度。如果出现百分比，必须表示为小数，但此问题不要求明确报告任何百分比。", "solution": "用户提供了有效的问题陈述。\n\n### 1. 问题阐述与目标\n\n目标是实证研究在一个二元分类任务中，排列特征重要性（Permutation Feature Importance, PFI）在不同程度的类别不平衡下的稳定性。我们将训练一个概率分类器，具体为逻辑回归，并使用三种不同的性能指标来评估PFI：受试者工作特征曲线下面积（Area Under the Receiver Operating Characteristic Curve, AUC）、对数损失（log-loss）和F1分数。分析将重点关注随着类别先验概率 $\\pi = p(y=1)$ 变得更加倾斜，特征重要性排名以及这些排名之间的相关性如何变化。\n\n### 2. 合成数据生成\n\n数据在 $d=3$ 维空间中从一个条件高斯分布生成。每个样本 $(\\mathbf{x}, y)$ 的生成过程如下：\n1.  一个二元标签 $y$ 从伯努利分布中抽取：$y \\sim \\mathrm{Bernoulli}(\\pi)$。\n2.  以标签 $y$ 为条件，一个特征向量 $\\mathbf{x} \\in \\mathbb{R}^3$ 从一个多元正态分布中抽取：$\\mathbf{x} \\mid y \\sim \\mathcal{N}(\\boldsymbol{\\mu}_y, \\mathbf{I}_3)$。\n两个类别的均值分别为：$y=1$ 类的均值为 $\\boldsymbol{\\mu}_1 = [2.0, 0.8, 0.0]^\\top$，$y=0$ 类的均值为 $\\boldsymbol{\\mu}_0 = [0.0, 0.0, 0.0]^\\top$。协方差矩阵是单位矩阵 $\\mathbf{I}_3$，这表示特征是条件独立的，并且具有单位方差。\n\n均值之差 $\\boldsymbol{\\mu}_1 - \\boldsymbol{\\mu}_0 = [2.0, 0.8, 0.0]^\\top$ 决定了特征的内在预测能力。特征0具有最大的类别分离度，其次是特征1。特征2的类别条件均值之间没有差异，因此是一个不相关或噪声特征。\n\n### 3. 逻辑回归模型与训练\n\n我们采用一个逻辑回归模型，该模型预测给定特征向量 $\\mathbf{x}$ 时正类别 $y=1$ 的概率。模型使用一个增广特征向量 $\\tilde{\\mathbf{x}} = [1, \\mathbf{x}^\\top]^\\top$ 以包含截距项。预测概率为：\n$$\n\\hat{p}(y=1 \\mid \\mathbf{x}) = \\sigma(\\mathbf{w}^\\top \\tilde{\\mathbf{x}})\n$$\n其中 $\\mathbf{w} \\in \\mathbb{R}^{d+1}$ 是模型参数（权重）的向量，$\\sigma(z) = (1 + e^{-z})^{-1}$ 是逻辑S型函数。\n\n模型通过最小化一个正则化经验风险函数进行训练。根据规定，该函数是训练集上的平均负对数似然（NLL）与对特征系数（不包括截距 $w_0$）的 $\\ell_2$ 惩罚项之和。对于一个大小为 $n_{\\text{train}}$ 的训练集，要最小化的目标函数 $J(\\mathbf{w})$ 是：\n$$\nJ(\\mathbf{w}) = \\left( -\\frac{1}{n_{\\text{train}}} \\sum_{i=1}^{n_{\\text{train}}} \\left[ y_i \\log(\\hat{p}_i) + (1-y_i) \\log(1-\\hat{p}_i) \\right] \\right) + \\lambda \\sum_{j=1}^{d} w_j^2\n$$\n其中 $\\hat{p}_i = \\sigma(\\mathbf{w}^\\top \\tilde{\\mathbf{x}}_i)$，正则化强度为 $\\lambda = 1.0$。这个目标函数是凸的，确保了存在唯一的最小值。我们可以使用像L-BFGS这样的拟牛顿法找到最优参数 $\\mathbf{w}^*$，这需要目标函数的梯度：\n$$\n\\nabla_{\\mathbf{w}} J(\\mathbf{w}) = \\frac{1}{n_{\\text{train}}} \\sum_{i=1}^{n_{\\text{train}}} (\\hat{p}_i - y_i) \\tilde{\\mathbf{x}}_i + 2\\lambda \\mathbf{w}_{\\text{reg}}\n$$\n其中 $\\mathbf{w}_{\\text{reg}} = [0, w_1, \\dots, w_d]^\\top$ 是一个向量，其截距项为零，其余为用于惩罚项的系数值。\n\n### 4. 性能指标与排列特征重要性\n\n我们使用三个指标来评估模型性能和特征重要性：\n\n-   **AUC**：一个基于秩的指标，对类别不平衡和校准不敏感。它衡量一个随机选择的正样本比一个随机选择的负样本排名更高的概率。AUC为0.5表示不优于随机猜测，而1.0表示完美区分。\n-   **对数损失**：一个严格评分规则，用于评估预测概率的质量。它对区分度和校准度都敏感，并受类别不平衡影响。值越低越好。\n-   **F1分数**：精确率和召回率的调和平均数，在固定的0.5阈值下对二值化预测进行计算。该指标对阈值的选择和类别分布高度敏感。\n\n特征 $j$ 的排列特征重要性（PFI）通过测量当测试集中该特征的值被随机打乱时，模型性能的下降（对于损失函数则是上升）来计算。这种打乱操作破坏了该特征与目标变量之间的关系。其步骤如下：\n1.  在原始测试集上计算基线性能指标 $S_{\\text{base}}$。\n2.  对于每个特征 $j \\in \\{0, 1, 2\\}$：\n    a. 对于 $K=5$ 次重复中的每一次，创建测试集的一个副本，并随机排列对应于特征 $j$ 的列。\n    b. 在这个已排列的数据集上计算性能指标 $S_{\\text{perm}, k}$。\n    c. 对 $K$ 次重复的分数取平均值：$\\bar{S}_{\\text{perm}} = \\frac{1}{K} \\sum_{k=1}^K S_{\\text{perm}, k}$。\n3.  计算重要性 $\\Delta_j$：\n    -   对于AUC和F1（需要最大化的指标）：$\\Delta_j = S_{\\text{base}} - \\bar{S}_{\\text{perm}}$。\n    -   对于对数损失（需要最小化的指标）：$\\Delta_j = \\bar{S}_{\\text{perm}} - S_{\\text{base}}$。\n\n更大的 $\\Delta_j$ 值总是表示更高的重要性。\n\n### 5. 分析与算法实现\n\n对于每个测试用例，我们进行两种分析来比较三种指标的PFI结果：\n\n1.  **最重要的特征**：我们为三个PFI向量中的每一个确定最重要特征的索引，即 $\\arg\\max_j \\Delta_j$。这揭示了每个指标认为哪个特征影响最大。若重要性相同，则选择最小的索引。\n2.  **秩相关性**：我们计算 (AUC, 对数损失)、(AUC, F1) 和 (对数损失, F1) 这几对3维PFI向量之间的Spearman秩相关系数 $\\rho$。相关性为1.0表示这些指标产生相同的特征重要性排名。较低的值表明存在不一致。如果相关性未定义（由于秩的方差为零），则报告为0.0。\n\n总体算法在一个Python脚本中实现如下：\n-   一个主循环遍历由 $(\\pi, n_{\\text{train}}, n_{\\text{test}}, \\text{seed})$ 定义的三个测试用例。\n-   对于每个用例，使用给定的种子创建一个 `numpy.random.default_rng` 实例，以确保数据生成和排列的可复现性。\n-   生成合成的训练和测试数据集。\n-   使用 `scipy.optimize.minimize` 及 `L-BFGS-B` 求解器来训练逻辑回归模型，并为其提供目标函数及其解析梯度以提高效率和稳定性。\n-   通过实现上述排列过程，为每个特征和每个指标计算PFI。\n-   使用 `scipy.stats.rankdata` 实现的 Wilcoxon-Mann-Whitney U统计量公式来稳健地计算AUC。对数损失和F1分数根据其定义直接实现，并注意处理数值边界情况（例如 `log(0)` 或除以零）。\n-   计算最重要特征的索引和Spearman相关性。使用 `scipy.stats.spearmanr` 计算相关性，并检查 `NaN` 结果。\n-   收集每个用例的六个结果值，将其格式化到指定精度，并打印为单个逗号分隔的列表。", "answer": "```python\nimport numpy as np\nimport scipy.optimize\nimport scipy.special\nimport scipy.stats\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation across all test cases.\n    \"\"\"\n    test_cases = [\n        # Case 1 (balanced)\n        {'pi': 0.5, 'n_train': 4000, 'n_test': 20000, 'seed': 123},\n        # Case 2 (moderate imbalance)\n        {'pi': 0.2, 'n_train': 4000, 'n_test': 20000, 'seed': 456},\n        # Case 3 (severe imbalance)\n        {'pi': 0.05, 'n_train': 4000, 'n_test': 20000, 'seed': 789},\n    ]\n\n    mu1 = np.array([2.0, 0.8, 0.0])\n    mu0 = np.array([0.0, 0.0, 0.0])\n    d = 3\n    lambda_reg = 1.0\n    K_permutations = 5\n    \n    all_results = []\n\n    for case in test_cases:\n        pi, n_train, n_test, seed = case['pi'], case['n_train'], case['n_test'], case['seed']\n        \n        # RNG for reproducibility within a test case\n        rng = np.random.default_rng(seed)\n\n        # 1. Data Generation\n        def generate_data(n_samples, pi_val, rng_instance):\n            y = rng_instance.binomial(1, pi_val, size=n_samples)\n            X = np.zeros((n_samples, d))\n            n_pos = np.sum(y)\n            n_neg = n_samples - n_pos\n            X[y == 1, :] = mu1 + rng_instance.standard_normal(size=(n_pos, d))\n            X[y == 0, :] = mu0 + rng_instance.standard_normal(size=(n_neg, d))\n            return X, y\n        \n        X_train, y_train = generate_data(n_train, pi, rng)\n        X_test, y_test = generate_data(n_test, pi, rng)\n\n        # Add intercept term\n        X_train_aug = np.hstack([np.ones((n_train, 1)), X_train])\n        \n        # 2. Logistic Regression Training\n        def log_reg_cost_grad(w, X, y, lambda_val):\n            n_samples = X.shape[0]\n            z = X @ w\n            \n            # Cost Function (Average NLL + L2 Penalty)\n            # Use numerically stable log-sum-exp trick: log(1+exp(z)) = logaddexp(0, z)\n            avg_nll = np.sum(np.logaddexp(0, z) - y * z) / n_samples\n            penalty = lambda_val * np.sum(w[1:]**2)\n            cost = avg_nll + penalty\n            \n            # Gradient\n            p_hat = scipy.special.expit(z)\n            grad_nll = X.T @ (p_hat - y) / n_samples\n            grad_pen = np.zeros_like(w)\n            grad_pen[1:] = 2 * lambda_val * w[1:]\n            grad = grad_nll + grad_pen\n            \n            return cost, grad\n\n        w_initial = np.zeros(d + 1)\n        res = scipy.optimize.minimize(\n            lambda w: log_reg_cost_grad(w, X_train_aug, y_train, lambda_reg),\n            w_initial,\n            method='L-BFGS-B',\n            jac=True\n        )\n        w_opt = res.x\n\n        def predict_proba(X, w):\n            X_aug = np.hstack([np.ones((X.shape[0], 1)), X])\n            return scipy.special.expit(X_aug @ w)\n\n        # 3. Metric Implementations\n        def compute_auc(y_true, y_pred):\n            n_pos = np.sum(y_true == 1)\n            n_neg = np.sum(y_true == 0)\n            if n_pos == 0 or n_neg == 0:\n                return 0.5\n            ranks = scipy.stats.rankdata(y_pred)\n            rank_sum_pos = np.sum(ranks[y_true == 1])\n            u_stat = rank_sum_pos - (n_pos * (n_pos + 1) / 2)\n            return u_stat / (n_pos * n_neg)\n\n        def compute_log_loss(y_true, p_hat):\n            epsilon = 1e-15\n            p_hat_clipped = np.clip(p_hat, epsilon, 1 - epsilon)\n            return -np.mean(y_true * np.log(p_hat_clipped) + (1 - y_true) * np.log(1 - p_hat_clipped))\n\n        def compute_f1(y_true, p_hat):\n            y_pred = (p_hat >= 0.5).astype(int)\n            tp = np.sum((y_true == 1)  (y_pred == 1))\n            fp = np.sum((y_true == 0)  (y_pred == 1))\n            fn = np.sum((y_true == 1)  (y_pred == 0))\n            \n            precision_den = tp + fp\n            recall_den = tp + fn\n            \n            precision = tp / precision_den if precision_den > 0 else 0.0\n            recall = tp / recall_den if recall_den > 0 else 0.0\n            \n            f1_den = precision + recall\n            f1 = 2 * precision * recall / f1_den if f1_den > 0 else 0.0\n            return f1\n            \n        metrics = {\n            'auc': {'func': compute_auc, 'type': 'maximize'},\n            'log_loss': {'func': compute_log_loss, 'type': 'minimize'},\n            'f1': {'func': compute_f1, 'type': 'maximize'}\n        }\n        \n        # 4. PFI Calculation\n        pfi_results = {}\n        p_test_base = predict_proba(X_test, w_opt)\n\n        for name, metric_info in metrics.items():\n            metric_func = metric_info['func']\n            baseline_score = metric_func(y_test, p_test_base)\n            importances = np.zeros(d)\n            \n            for j in range(d):\n                permuted_scores = np.zeros(K_permutations)\n                for k in range(K_permutations):\n                    X_test_perm = X_test.copy()\n                    rng.shuffle(X_test_perm[:, j])\n                    p_test_perm = predict_proba(X_test_perm, w_opt)\n                    permuted_scores[k] = metric_func(y_test, p_test_perm)\n                \n                avg_permuted_score = np.mean(permuted_scores)\n                \n                if metric_info['type'] == 'maximize':\n                    importances[j] = baseline_score - avg_permuted_score\n                else: # minimize\n                    importances[j] = avg_permuted_score - baseline_score\n            \n            pfi_results[name] = importances\n\n        # 5. Analysis\n        pfi_auc = pfi_results['auc']\n        pfi_log_loss = pfi_results['log_loss']\n        pfi_f1 = pfi_results['f1']\n        \n        argmax_auc = np.argmax(pfi_auc)\n        argmax_log_loss = np.argmax(pfi_log_loss)\n        argmax_f1 = np.argmax(pfi_f1)\n        \n        def safe_spearmanr(x, y):\n            corr, _ = scipy.stats.spearmanr(x, y)\n            return corr if not np.isnan(corr) else 0.0\n\n        corr_auc_logloss = safe_spearmanr(pfi_auc, pfi_log_loss)\n        corr_auc_f1 = safe_spearmanr(pfi_auc, pfi_f1)\n        corr_logloss_f1 = safe_spearmanr(pfi_log_loss, pfi_f1)\n        \n        case_results = [\n            argmax_auc, argmax_log_loss, argmax_f1,\n            corr_auc_logloss, corr_auc_f1, corr_logloss_f1\n        ]\n        all_results.extend(case_results)\n\n    # Final formatting and printing\n    formatted_results = []\n    for item in all_results:\n        if isinstance(item, (int, np.integer)):\n            formatted_results.append(str(item))\n        else:\n            formatted_results.append(f\"{item:.6f}\")\n            \n    print(f\"[{','.join(formatted_results)}]\")\n\n\nsolve()\n```", "id": "3156641"}, {"introduction": "全局特征重要性（如标准 PFI）衡量的是特征在整个数据集上的平均影响，但这可能会掩盖更复杂的模式。在许多情况下，一个特征的重要性可能并非恒定不变，而是依赖于另一个特征的取值。例如，一个药物的剂量 ($X_j$) 的重要性可能只在特定年龄段 ($X_k$) 的患者中才显著。为了揭示这种条件效应或特征交互作用，我们可以使用分层 PFI (Stratified PFI)。这个实践练习 [@problem_id:3156620] 将向你展示如何根据一个特征 ($X_k$) 的分位数对数据进行分层，并在每个层内独立计算另一个特征 ($X_j$) 的 PFI，从而揭示特征之间隐藏的交互关系。", "problem": "您将实现分层置换特征重要性 (Stratified Permutation Feature Importance, PFI)，以研究一个特征在另一个特征的分位数定义层上的条件重要性。此任务的基础是在指定损失下的期望预测误差的定义及其经验近似。您将依赖以下要素。\n\n1. 损失与风险。设损失为平方误差损失，定义为 $L(y, \\hat{y}) = (y - \\hat{y})^2$。期望预测误差（风险）定义为 $R = \\mathbb{E}[L(Y, \\hat{f}(X))]$，我们通过有限样本上的经验均值来近似它。\n\n2. 置换特征重要性 (PFI)。对于给定的已训练预测器 $\\hat{f}$ 和目标特征 $X_j$，在特定损失下，$X_j$ 的 PFI 定义为：通过随机置换 $X_j$ 的值来打破 $X_j$ 与响应变量之间的关联后，风险的增加量。此过程中所有其他特征保持不变，从而保留了 $X_j$ 的边缘分布。此过程利用了所有其他特征与标签的联合分布在 $X_j$ 置换下的不变性。\n\n3. 分层 PFI。为分析条件重要性，您将在由另一特征 $X_k$ 的分位数区间定义的层内执行 PFI。具体而言，您将：\n   - 使用 $X_k$ 在概率 $0, \\frac{1}{Q}, \\ldots, 1$ 处的经验分位数，将测试数据划分为 $Q$ 个区间。\n   - 在每个区间内，计算基线经验误差，然后在仅在该区间内置换 $X_j$（以保留该层中 $X_k$ 的条件分布）后计算经验误差。\n   - 区间 $b$ 的分层 PFI 是该区间内置换后的经验误差与基线经验误差之差，并在多次独立置换上取平均。\n\n您的程序必须实现以下端到端流程：\n\nA. 数据生成。对于每个测试用例，从模型\n$$\nY = \\alpha + a\\,X_j + b\\,X_k + c\\,(X_j X_k) + \\varepsilon, \\quad \\varepsilon \\sim \\mathcal{N}(0, \\sigma^2),\n$$\n模拟独立同分布的样本 $(X_j, X_k, Y)$，其中 $(X_j, X_k)$ 服从联合高斯分布，均值为零，方差为单位，相关性为 $\\rho$。为生成具有指定相关性 $\\rho$ 的一对变量，独立抽取 $Z_1, Z_2 \\sim \\mathcal{N}(0,1)$，并设置 $X_k = Z_2$ 和 $X_j = \\rho Z_2 + \\sqrt{1-\\rho^2}\\, Z_1$。使用 $n_{\\text{train}}$ 个样本进行训练，使用 $n_{\\text{test}}$ 个样本进行测试。\n\nB. 模型拟合。通过普通最小二乘法 (OLS) 拟合一个线性模型 $\\hat{f}$，该模型包含一个截距项和三个原始特征：\n$$\n\\phi(X_j, X_k) = \\big[1,\\; X_j,\\; X_k,\\; X_j X_k\\big].\n$$\n在训练集上进行训练以获得系数向量 $\\hat{w}$，使得\n$$\n\\hat{f}(X_j, X_k) = \\hat{w}_0 + \\hat{w}_1 X_j + \\hat{w}_2 X_k + \\hat{w}_3 (X_j X_k).\n$$\n\nC. 在测试集上基于 $X_k$ 的分位数区间进行分层 PFI。对于固定的区间数 $Q$，在测试集上计算 $X_k$ 在概率 $0, \\frac{1}{Q}, \\ldots, 1$ 处的经验分位数，形成 $Q$ 个连续的区间。在区间 $q$ 中，执行以下操作：\n   - 计算该区间内的基线均方误差 (MSE)：\n     $$\n     \\text{MSE}_{\\text{base}, q} = \\frac{1}{m_q} \\sum_{i \\in \\text{bin } q} \\big(Y_i - \\hat{f}(X_{j,i}, X_{k,i})\\big)^2,\n     $$\n     其中 $m_q$ 是区间 $q$ 中的测试样本数。\n   - 对于 $R$ 次独立重复，随机置换区间 $q$ 内样本的 $X_j$ 值，使用置换后的 $X_j$ 和未改变的 $X_k$ 在模型 $\\hat{f}$ 内重新计算预测，并记录该区间内置换后的 MSE，即 $\\text{MSE}_{\\text{perm}, q}^{(r)}$。\n   - 区间 $q$ 的分层 PFI 为\n     $$\n     I_q = \\left(\\frac{1}{R} \\sum_{r=1}^R \\text{MSE}_{\\text{perm}, q}^{(r)} \\right) - \\text{MSE}_{\\text{base}, q}。\n     $$\n\nD. 输出。对于每个测试用例，输出列表 $[I_1, I_2, \\ldots, I_Q]$，结果四舍五入到 3 位小数。将所有测试用例的输出汇总到单行中，格式化为 Python 风格的列表之列表。例如，最后一行应类似于 $[[i_{1,1},\\ldots,i_{1,Q}], [i_{2,1},\\ldots,i_{2,Q}], \\ldots]$。\n\n实现细节和约束：\n\n- 使用平方误差损失 $L(y, \\hat{y}) = (y - \\hat{y})^2$。\n- 使用在测试集上由 $X_k$ 的经验四分位数定义的 $Q=4$ 个区间。区间的左边界是包含的，且最后一个区间也包含右边界，以覆盖所有测试点。\n- 每个区间使用 $R = 128$ 次独立置换。\n- 使用 $n_{\\text{train}} = 3000$ 和 $n_{\\text{test}} = 1500$。\n- 为保证数值稳定性，您可以通过最小二乘程序求解 OLS 问题。\n- 随机性与可复现性：\n  - 对于测试用例索引 $i \\in \\{0,1,2,3\\}$，使用种子 $s_{\\text{train}} = 1234 + 100 i$ 生成训练数据，使用种子 $s_{\\text{test}} = 5678 + 100 i$ 生成测试数据，使用种子 $s_{\\text{perm}} = 91011 + 100 i$ 用于置换的随机性。\n- 四舍五入与格式化：\n  - 在输出前将每个区间特定的重要性 $I_q$ 四舍五入到 3 位小数。\n  - 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，无额外文本。\n\n测试套件规范：\n\n为以下四个测试用例提供结果，每个用例由 $(\\alpha, a, b, c, \\sigma, \\rho)$ 定义：\n\n- 用例 1：$(\\alpha, a, b, c, \\sigma, \\rho) = (0.0, 1.0, 0.5, 1.0, 0.3, 0.4)$。\n- 用例 2：$(\\alpha, a, b, c, \\sigma, \\rho) = (0.0, 1.0, 0.5, 0.0, 0.3, 0.4)$。\n- 用例 3：$(\\alpha, a, b, c, \\sigma, \\rho) = (0.0, 1.0, 0.5, -1.0, 0.3, 0.4)$。\n- 用例 4：$(\\alpha, a, b, c, \\sigma, \\rho) = (0.0, 0.0, 1.0, 0.0, 0.3, 0.0)$。\n\n给开发者的说明：\n\n- 按描述实现完整的流程。\n- 不要读取任何输入；所有参数均按上述规定固定。\n- 最终输出必须是完全符合指定格式的单行，例如：$[ [0.123,0.234,0.345,0.456],[\\ldots],\\ldots]$。", "solution": "该问题是有效的。它是一项在计算统计学中定义明确、有科学依据的任务，要求实现分层置换特征重要性 (PFI)。所有参数、模型和程序都得到了清晰且一致的定义。\n\n在此，我们详细说明计算分层 PFI 的分步过程。\n\n### A. 数据生成\n\n第一步是模拟训练和测试数据集。对于四个测试用例中的每一个，由参数集 $(\\alpha, a, b, c, \\sigma, \\rho)$ 指定，我们生成两个独立的数据集：一个大小为 $n_{\\text{train}} = 3000$ 的训练集和一个大小为 $n_{\\text{test}} = 1500$ 的测试集。每个样本由一个三元组 $(X_j, X_k, Y)$ 组成。\n\n特征 $(X_j, X_k)$ 从一个二元高斯分布中抽取，该分布具有零均值、单位方差和指定的相关性 $\\rho$。这是通过首先生成两个独立的标准正态变量 $Z_1, Z_2 \\sim \\mathcal{N}(0,1)$，然后如下构造相关变量来实现的：\n$$\nX_k = Z_2\n$$\n$$\nX_j = \\rho Z_2 + \\sqrt{1-\\rho^2}\\, Z_1\n$$\n这种构造确保了 $\\mathbb{E}[X_j] = \\mathbb{E}[X_k] = 0$、$\\text{Var}[X_j] = \\text{Var}[X_k] = 1$ 和 $\\text{Cov}[X_j, X_k] = \\rho$。\n\n响应变量 $Y$ 是根据真实的结构模型生成的，该模型包含每个特征的主效应和一个交互项：\n$$\nY = \\alpha + a\\,X_j + b\\,X_k + c\\,(X_j X_k) + \\varepsilon\n$$\n噪声项 $\\varepsilon$ 从均值为零、方差为 $\\sigma^2$ 的正态分布中抽取，即 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$。\n\n为确保可复现性，对于每个由 $i \\in \\{0, 1, 2, 3\\}$ 索引的测试用例，使用不同的种子初始化独立的随机数生成器，分别用于训练数据生成 ($s_{\\text{train}}$)、测试数据生成 ($s_{\\text{test}}$) 和置换过程 ($s_{\\text{perm}}$)。\n\n### B. 模型拟合\n\n下一步是使用生成的训练数据拟合一个预测模型 $\\hat{f}$。指定的模型是一个线性回归模型，其特征包括一个截距、两个原始预测变量及其交互项。特征向量由 $\\phi(X_j, X_k) = [1, X_j, X_k, X_j X_k]$ 给出。该模型的功能形式是：\n$$\n\\hat{f}(X_j, X_k) = \\hat{w}_0 + \\hat{w}_1 X_j + \\hat{w}_2 X_k + \\hat{w}_3 (X_j X_k)\n$$\n系数向量 $\\hat{w} = [\\hat{w}_0, \\hat{w}_1, \\hat{w}_2, \\hat{w}_3]^T$ 是通过普通最小二乘法 (OLS) 确定的。这涉及找到使训练集上平方误差总和最小化的 $\\hat{w}$。该解通过求解线性系统 $\\Phi_{\\text{train}}^T \\Phi_{\\text{train}} \\hat{w} = \\Phi_{\\text{train}}^T Y_{\\text{train}}$ 获得，其中 $\\Phi_{\\text{train}}$ 是根据训练数据构建的 $n_{\\text{train}} \\times 4$ 设计矩阵。为了数值稳定性，这是使用诸如 `numpy.linalg.lstsq` 的最小二乘求解器实现的。\n\n### C. 分层置换特征重要性 (PFI)\n\n任务的核心是计算特征 $X_j$ 在特征 $X_k$ 取值条件下的 PFI。此操作在测试集上执行。\n\n1.  **分层：**测试数据根据 $X_k$ 的值被划分为 $Q=4$ 个不相交的区间（层）。这些区间由测试集上 $X_k$ 的经验四分位数定义。具体来说，我们找到对应于概率 $\\{0.25, 0.50, 0.75\\}$ 的分位数值，这些值作为四个区间的边界。这将数据划分为四个大小近似相等的组。\n\n2.  **区间内 PFI 计算：**对于每个区间 $q \\in \\{1, 2, 3, 4\\}$，我们按如下方式计算重要性得分 $I_q$：\n    *   **基线误差：**首先，我们使用原始、未置换的数据计算区间 $q$ 内样本的基线均方误差 (MSE)。设 $S_q$ 为区间 $q$ 中样本的索引集合，$m_q = |S_q|$ 为该区间中的样本数。基线误差为：\n        $$\n        \\text{MSE}_{\\text{base}, q} = \\frac{1}{m_q} \\sum_{i \\in S_q} \\big(Y_i - \\hat{f}(X_{j,i}, X_{k,i})\\big)^2\n        $$\n    *   **置换误差：**接下来，我们衡量在*层内*打破 $X_j$ 和 $Y$ 之间关联的影响。这是通过仅在区间 $q$ 的样本中重复置换 $X_j$ 的值来实现的。此过程对 $R=128$ 次独立置换进行重复。对于每次置换 $r \\in \\{1, \\ldots, R\\}$，我们得到一个置换后的特征向量 $X_{j, \\text{perm}}^{(r)}$ 并计算相应的 MSE：\n        $$\n        \\text{MSE}_{\\text{perm}, q}^{(r)} = \\frac{1}{m_q} \\sum_{i \\in S_q} \\big(Y_i - \\hat{f}(X_{j, \\text{perm}, i}^{(r)}, X_{k,i})\\big)^2\n        $$\n    *   **重要性得分：**置换误差在 $R$ 次重复中取平均值。区间 $q$ 的分层 PFI 是误差的增加量，定义为平均置换 MSE 与基线 MSE 之差：\n        $$\n        I_q = \\left(\\frac{1}{R} \\sum_{r=1}^R \\text{MSE}_{\\text{perm}, q}^{(r)} \\right) - \\text{MSE}_{\\text{base}, q}\n        $$\n\n### D. 输出生成\n\n对四个指定的测试用例中的每一个执行上述过程。对于每个用例，结果是一个包含四个重要性得分的列表 $[I_1, I_2, I_3, I_4]$，其中每个 $I_q$ 都四舍五入到 3 位小数。最终输出是将这些结果聚合成一个单一的 Python 风格的列表之列表，并格式化为字符串。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the complete pipeline for stratified Permutation Feature Importance.\n    \"\"\"\n\n    # --- Problem Parameters ---\n    Q = 4  # Number of quantile bins\n    R = 128  # Number of permutations per bin\n    n_train = 3000\n    n_test = 1500\n\n    test_cases = [\n        # Case 1: (alpha, a, b, c, sigma, rho)\n        (0.0, 1.0, 0.5, 1.0, 0.3, 0.4),\n        # Case 2: No interaction term\n        (0.0, 1.0, 0.5, 0.0, 0.3, 0.4),\n        # Case 3: Negative interaction term\n        (0.0, 1.0, 0.5, -1.0, 0.3, 0.4),\n        # Case 4: No effect from X_j and no correlation\n        (0.0, 0.0, 1.0, 0.0, 0.3, 0.0),\n    ]\n\n    all_results = []\n\n    for i, params in enumerate(test_cases):\n        alpha, a, b, c, sigma, rho = params\n\n        # --- A. Data Generation ---\n        # Set up random number generators for reproducibility\n        s_train = 1234 + 100 * i\n        s_test = 5678 + 100 * i\n        s_perm = 91011 + 100 * i\n        rng_train = np.random.default_rng(s_train)\n        rng_test = np.random.default_rng(s_test)\n        rng_perm = np.random.default_rng(s_perm)\n\n        # Generate training data\n        Z1_train = rng_train.normal(size=n_train)\n        Z2_train = rng_train.normal(size=n_train)\n        Xk_train = Z2_train\n        Xj_train = rho * Z2_train + np.sqrt(1 - rho**2) * Z1_train\n        eps_train = rng_train.normal(loc=0, scale=sigma, size=n_train)\n        Y_train = alpha + a * Xj_train + b * Xk_train + c * (Xj_train * Xk_train) + eps_train\n\n        # Generate test data\n        Z1_test = rng_test.normal(size=n_test)\n        Z2_test = rng_test.normal(size=n_test)\n        Xk_test = Z2_test\n        Xj_test = rho * Z2_test + np.sqrt(1 - rho**2) * Z1_test\n        eps_test = rng_test.normal(loc=0, scale=sigma, size=n_test)\n        Y_test = alpha + a * Xj_test + b * Xk_test + c * (Xj_test * Xk_test) + eps_test\n\n        # --- B. Model Fitting ---\n        # Construct design matrix for training: [1, Xj, Xk, Xj*Xk]\n        Phi_train = np.c_[np.ones(n_train), Xj_train, Xk_train, Xj_train * Xk_train]\n        \n        # Solve OLS to get model weights\n        w_hat, _, _, _ = np.linalg.lstsq(Phi_train, Y_train, rcond=None)\n\n        def predict(Xj, Xk, weights):\n            \"\"\"Makes predictions using the fitted linear model.\"\"\"\n            Phi = np.c_[np.ones(len(Xj)), Xj, Xk, Xj * Xk]\n            return Phi @ weights\n\n        def mean_squared_error(y_true, y_pred):\n            \"\"\"Computes the mean squared error.\"\"\"\n            return np.mean((y_true - y_pred)**2)\n\n        # --- C. Stratified PFI ---\n        # Define strata based on Xk_test quantiles\n        quantile_boundaries = np.quantile(Xk_test, [0.25, 0.5, 0.75])\n        bin_indices = np.digitize(Xk_test, bins=quantile_boundaries)\n\n        case_importances = []\n        for q in range(Q):\n            in_bin_mask = (bin_indices == q)\n            \n            # Skip if a bin is empty (unlikely for this data size)\n            if not np.any(in_bin_mask):\n                case_importances.append(0.0)\n                continue\n\n            Xj_bin = Xj_test[in_bin_mask]\n            Xk_bin = Xk_test[in_bin_mask]\n            Y_bin = Y_test[in_bin_mask]\n\n            # Compute baseline MSE in the bin\n            Y_pred_base = predict(Xj_bin, Xk_bin, w_hat)\n            mse_base = mean_squared_error(Y_bin, Y_pred_base)\n            \n            # Compute permuted MSEs over R repetitions\n            permuted_mses = []\n            for _ in range(R):\n                Xj_perm = rng_perm.permutation(Xj_bin)\n                Y_pred_perm = predict(Xj_perm, Xk_bin, w_hat)\n                mse_perm = mean_squared_error(Y_bin, Y_pred_perm)\n                permuted_mses.append(mse_perm)\n            \n            # Calculate importance score for the bin\n            avg_mse_perm = np.mean(permuted_mses)\n            importance_q = avg_mse_perm - mse_base\n            case_importances.append(round(importance_q, 3))\n        \n        all_results.append(case_importances)\n\n    # --- D. Output ---\n    # Format the results into a single string: [[...],[...],...]\n    inner_strings = [f\"[{','.join(map(str, res))}]\" for res in all_results]\n    final_string = f\"[{','.join(inner_strings)}]\"\n    print(final_string)\n\nsolve()\n```", "id": "3156620"}]}