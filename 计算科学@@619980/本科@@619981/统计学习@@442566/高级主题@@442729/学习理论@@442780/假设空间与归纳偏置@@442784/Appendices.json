{"hands_on_practices": [{"introduction": "在机器学习中，我们所做的选择，即使是像特征归一化这样的预处理步骤，也并非中立。这些选择会引入归纳偏见，影响学习算法的最终结果。本练习将通过一个具体的编码任务，探讨两种不同的特征归一化方法（Z-score 和 Min-Max）如何改变基于距离的学习器（如 K-最近邻）的假设空间，并让你亲眼见证这种偏见如何导致不同的预测结果。[@problem_id:3129970]", "problem": "您必须编写一个完整的程序，比较不同的特征归一化如何为基于距离的学习器导出不同的假设空间，并在此过程中量化归一化如何作为归纳偏置起作用。该学习器是 1-最近邻分类器，其形式化定义如下。给定一个训练集 $\\{(\\mathbf{x}_i, y_i)\\}_{i=1}^n$，其中 $\\mathbf{x}_i \\in \\mathbb{R}^d$ 且标签 $y_i \\in \\{0,1,\\dotsc,C-1\\}$，以及一个度量 $d(\\cdot,\\cdot)$，对于任何查询 $\\mathbf{q} \\in \\mathbb{R}^d$，假设空间 $\\mathcal{H}$ 中的假设 $h$ 返回使 $d(\\mathbf{q}, \\mathbf{x}_j)$ 最小化的训练点 $\\mathbf{x}_j$ 的标签 $y_j$（如果存在平局，则选择最小的索引 $j$）。因此，假设空间由度量的选择来参数化，而在此问题中，度量是由归一化导出的。\n\n您必须仅根据训练数据实现两种归一化方法：\n- Z-score 归一化：对于特征索引 $j \\in \\{1,\\dotsc,d\\}$，计算总体均值 $\\mu_j$ 和总体标准差 $\\sigma_j$，并通过以下方式定义导出的距离：\n$$\nd_{\\text{z}}(\\mathbf{q}, \\mathbf{x}) \\triangleq \\sqrt{\\sum_{j=1}^d \\left(\\frac{q_j - x_j}{\\sigma_j}\\right)^2},\n$$\n约定如果 $\\sigma_j = 0$，则该特征对总和的贡献为 $0$（也就是说，由于该特征在训练数据中方差为零，因此在距离计算中被忽略）。\n- Min-max 归一化：对于特征索引 $j$，计算最小值 $m_j$ 和最大值 $M_j$，定义范围 $r_j \\triangleq M_j - m_j$，并通过以下方式定义导出的距离：\n$$\nd_{\\text{mm}}(\\mathbf{q}, \\mathbf{x}) \\triangleq \\sqrt{\\sum_{j=1}^d \\left(\\frac{q_j - x_j}{r_j}\\right)^2},\n$$\n约定如果 $r_j = 0$，则该特征对总和的贡献为 $0$。\n\n这些定义通过度量中每个特征的权重来编码归纳偏置：具有较大训练变异性的特征被降权，而 $\\sigma_j$ 和 $r_j$ 之间的选择会产生不同的权重，从而导致不同的假设空间，并可能产生不同的预测。\n\n您必须为每种导出的距离实现 1-最近邻分类器，为每个查询点返回单个最近训练点的标签，并使用确定性的平局打破规则，在距离相等的最近训练点中选择最小的索引。\n\n从上述基本定义出发，构建一个程序，对下述每个测试用例执行以下操作：\n- 为每种归一化计算训练统计数据。\n- 对每个查询，计算在 $d_{\\text{z}}$ 和 $d_{\\text{mm}}$ 下的预测标签。\n- 计算两种归一化下预测标签一致的查询所占的比例，表示为四舍五入到 $3$ 位小数的小数。\n- 根据指定的输出格式，将所有测试用例的结果汇总到单行中。\n\n此问题不涉及物理单位。不出现角度。所有输出必须是整数、布尔值、浮点数或这些类型的列表。\n\n测试套件：\n- 测试用例 $1$（一般情况，具有不同的归纳偏置并存在零方差特征）：\n    - 训练输入 $\\mathbf{X}$，$n=6$，$d=3$：\n      $\\mathbf{x}_1 = (1000, 0, 0)$, $\\mathbf{x}_2 = (1000, 1, 0)$, $\\mathbf{x}_3 = (0, 5, 0)$, $\\mathbf{x}_4 = (0, 6, 0)$, $\\mathbf{x}_5 = (0, 7, 0)$, $\\mathbf{x}_6 = (0, 8, 0)$。\n    - 标签：$y = [0, 0, 1, 1, 1, 1]$。\n    - 查询：$\\mathbf{q}_1 = (700, 6, 0)$, $\\mathbf{q}_2 = (650, 5.5, 0)$, $\\mathbf{q}_3 = (600, 7.5, 0)$。\n- 测试用例 $2$（边界条件，两种归一化的各特征尺度成比例，这意味着度量也成比例，因此对于任何查询，最近邻的排名都相同）：\n    - 训练输入，$n=4$，$d=2$：\n      $\\mathbf{x}_1 = (0, 0)$, $\\mathbf{x}_2 = (1, 0)$, $\\mathbf{x}_3 = (0, 100)$, $\\mathbf{x}_4 = (1, 100)$。\n    - 标签：$y = [0, 0, 1, 1]$。\n    - 查询：$\\mathbf{q}_1 = (0.9, 10)$, $\\mathbf{q}_2 = (0.5, 90)$, $\\mathbf{q}_3 = (0.2, 30)$。\n- 测试用例 $3$（边缘情况，存在一个零方差特征，而查询在该特征上差异显著；该零方差特征必须被两种归一化忽略）：\n    - 训练输入，$n=3$，$d=2$：\n      $\\mathbf{x}_1 = (1, 5)$, $\\mathbf{x}_2 = (1, 5)$, $\\mathbf{x}_3 = (1, 10)$。\n    - 标签：$y = [0, 1, 1]$。\n    - 查询：$\\mathbf{q}_1 = (100, 7)$, $\\mathbf{q}_2 = (100, 5)$, $\\mathbf{q}_3 = (100, 9)$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。每个测试用例贡献一个包含三个元素的列表：\n    1. $d_{\\text{z}}$ 和 $d_{\\text{mm}}$ 下预测标签相同的查询所占的比例（四舍五入到 $3$ 位小数），作为浮点数。\n    2. 在 $d_{\\text{z}}$ 下对各查询的预测标签列表，作为整数。\n    3. 在 $d_{\\text{mm}}$ 下对各查询的预测标签列表，作为整数。\n- 具体来说，输出必须如下所示：\n$[\\,[f_1,[\\ell^{\\text{z}}_{1},\\dotsc],[\\ell^{\\text{mm}}_{1},\\dotsc]],\\,[f_2,[\\dotsc],[\\dotsc]],\\,[f_3,[\\dotsc],[\\dotsc]]\\,]$\n其中 $f_k$ 是测试用例 $k$ 的比例，$\\ell^{\\text{z}}$ 是 $d_{\\text{z}}$ 下的标签，$\\ell^{\\text{mm}}$ 是 $d_{\\text{mm}}$ 下的标签。\n\n您的程序必须是自包含的，并且不得读取任何输入。它应完全按照规定实现计算，在距离相等的情况下通过选择最小索引进行确定性的平局打破。", "solution": "用户在统计学习理论领域提供了一个定义明确的计算问题。任务是实现一个在两种不同特征归一化方案下的 1-最近邻（1-NN）分类器，并比较它们在一组查询点上的预测。该比较量化了归一化的选择（作为一种归纳偏置）如何影响假设空间。\n\n该问题是有效的。它在科学上是合理的、良构的且客观的。所有必需的定义、数据和过程都已明确规定，没有歧义。平局打破规则（最小索引）确保了唯一解。处理零方差特征的约定也已明确说明，防止了不明确的计算。\n\n问题的核心在于理解不同的归一化统计量——Z-score 归一化的总体标准差和 min-max 归一化的范围——如何导出不同的距离度量。查询点 $\\mathbf{q}$ 和训练点 $\\mathbf{x}$ 之间的距离定义为加权的欧几里得距离：\n$$\nd(\\mathbf{q}, \\mathbf{x}) = \\sqrt{\\sum_{j=1}^d \\left(w_j (q_j - x_j)\\right)^2}\n$$\n其中 $d$ 是特征的数量，$w_j$ 是第 $j$ 个特征的权重。对于 Z-score 归一化，权重是总体标准差的倒数，$w_j = 1/\\sigma_j$。对于 min-max 归一化，权重是特征范围的倒数，$w_j = 1/r_j$。训练集中变异性为零（$\\sigma_j=0$ 或 $r_j=0$）的特征对总距离的贡献为 $0$，实际上被忽略了。\n\n1-NN 假设 $h(\\mathbf{q})$ 将查询点 $\\mathbf{q}$ 映射到根据所选度量距离 $\\mathbf{q}$ 最近的训练点 $\\mathbf{x}_i$ 的标签 $y_i$。\n$$\nh(\\mathbf{q}) = y_k \\quad \\text{where} \\quad k = \\underset{i \\in \\{1,\\dots,n\\}}{\\arg\\min} \\, d(\\mathbf{q}, \\mathbf{x}_i)\n$$\n由于平方根函数是单调的，最小化 $d(\\mathbf{q}, \\mathbf{x}_i)$ 等价于最小化平方距离 $d^2(\\mathbf{q}, \\mathbf{x}_i)$，这在计算上更高效。选择最小索引的平局打破规则解决了任何歧义。\n\n每个测试用例的步骤如下：\n1.  **计算归一化统计量**：对于训练数据 $\\mathbf{X}$ 的每个特征 $j$，计算总体标准差 $\\sigma_j$ 和范围 $r_j$。\n2.  **定义度量权重**：Z-score 导出的度量的权重为 $\\{1/\\sigma_j\\}_{j=1}^d$，min-max 导出的度量的权重为 $\\{1/r_j\\}_{j=1}^d$。如果 $\\sigma_j=0$ 或 $r_j=0$，相应的权重实际上为 $0$，因为该特征对距离总和的贡献定义为 $0$。\n3.  **分类查询**：对于每个查询点 $\\mathbf{q}_k$，计算其在 $d_{\\text{z}}^2$ 和 $d_{\\text{mm}}^2$ 下与每个训练点 $\\mathbf{x}_i$ 的平方距离。为每种度量确定最近邻的索引，并应用平局打破规则。预测的标签就是这些最近邻的标签。\n4.  **计算一致性**：比较两种方法的预测列表。一致性比例是两种方法预测相同标签的查询数除以总查询数。\n\n我们将此过程应用于每个测试用例。\n\n**测试用例 1**：\n- 训练数据 $\\mathbf{X}$：$n=6, d=3$。\n- 特征 $j=1$ 的统计数据：$\\sigma_1 = 1000\\sqrt{2}/3 \\approx 471.4$, $r_1 = 1000$。\n- 特征 $j=2$ 的统计数据：$\\sigma_2 = \\sqrt{107/12} \\approx 2.986$, $r_2 = 8$。\n- 特征 $j=3$ 的统计数据：$\\sigma_3 = 0, r_3 = 0$。此特征被忽略。\n两种度量的权重不同，导致了不同的假设空间几何形状。这导致了对查询点的不同预测结果：\n- 对于 $\\mathbf{q}_1=(700, 6, 0)$，Z-score 度量下的预测为 $1$（最近邻为 $\\mathbf{x}_4$），而 Min-max 度量下的预测为 $0$（最近邻为 $\\mathbf{x}_2$）。\n- 对于 $\\mathbf{q}_2=(650, 5.5, 0)$，两种度量下的最近邻均为 $\\mathbf{x}_3$（根据平局规则），预测标签为 $1$。\n- 对于 $\\mathbf{q}_3=(600, 7.5, 0)$，两种度量下的最近邻均为 $\\mathbf{x}_5$（根据平局规则），预测标签为 $1$。\nZ-score方法的预测标签为 $[1, 1, 1]$，Min-max方法的预测标签为 $[0, 1, 1]$。一致性比例为 $2/3 \\approx 0.667$。\n\n**测试用例 2**：\n- 训练数据 $\\mathbf{X}$：$n=4, d=2$。\n- 特征 $j=1$ 的统计数据：$\\sigma_1=0.5, r_1=1$。\n- 特征 $j=2$ 的统计数据：$\\sigma_2=50, r_2=100$。\nZ-score 度量的尺度（权重）为 $(1/\\sigma_1, 1/\\sigma_2)=(2, 0.02)$。min-max 度量的尺度为 $(1/r_1, 1/r_2)=(1, 0.01)$。Z-score 的尺度恰好是 min-max 尺度的两倍。因此，$d_{\\text{z}}(\\mathbf{q}, \\mathbf{x}) = 2 \\cdot d_{\\text{mm}}(\\mathbf{q}, \\mathbf{x})$。由于一个度量是另一个度量的常数倍，它们将始终以相同的顺序对邻居进行排序。预测结果必须相同。\n- 对查询 $\\mathbf{q}_1=(0.9, 10), \\mathbf{q}_2=(0.5, 90), \\mathbf{q}_3=(0.2, 30)$ 的预测对于两种方法都是 $[0, 1, 0]$。一致性比例为 $3/3 = 1.0$。\n\n**测试用例 3**：\n- 训练数据 $\\mathbf{X}$：$n=3, d=2$。\n- 特征 $j=1$ 的统计数据：$\\sigma_1=0, r_1=0$。此特征被两种度量忽略。\n- 特征 $j=2$ 的统计数据：$\\sigma_2 = 5\\sqrt{2}/3, r_2 = 5$。\n由于两种度量的距离计算仅依赖于第二个特征，对于任何给定的查询，两者都会试图最小化 $(q_2 - x_{i2})^2$。对于一个固定的查询，缩放因子 $1/\\sigma_2^2$ 和 $1/r_2^2$ 在所有训练点上都是常数，不影响邻居的排名。因此，预测结果必须相同。\n- 训练点的特征 2 的值为 $[5, 5, 10]$，对应的标签为 $[0, 1, 1]$。\n- 对于 $\\mathbf{q}_1=(100, 7)$，$q_2=7$。最近的 $x_{i2}$ 是 $5$，对应于索引 $1$ 和 $2$。最小索引是 $1$，所以标签是 $0$。\n- 对于 $\\mathbf{q}_2=(100, 5)$，$q_2=5$。最近的 $x_{i2}$ 是 $5$，对应于索引 $1$ 和 $2$。最小索引是 $1$，所以标签是 $0$。\n- 对于 $\\mathbf{q}_3=(100, 9)$，$q_2=9$。最近的 $x_{i2}$ 是 $10$，对应于索引 $3$。标签是 $1$。\n两种方法的预测标签均为 $[0, 0, 1]$。一致性比例为 $3/3 = 1.0$。", "answer": "```python\nimport numpy as np\n\ndef one_nn_predict(queries, train_X, train_y, scales):\n    \"\"\"\n    Predicts labels for queries using the 1-NN rule with a scaled Euclidean distance.\n    The 'scales' vector contains the per-feature weights (e.g., 1/sigma or 1/range).\n    \"\"\"\n    n_train = train_X.shape[0]\n    predictions = []\n\n    for q in queries:\n        # We use the squared Euclidean distance to find the nearest neighbor.\n        # This avoids the computationally expensive sqrt operation and does not\n        # change the result of argmin, as sqrt is a monotonic function.\n        \n        # Broadcasted, vectorized calculation of all squared distances from q\n        # to each point in train_X.\n        # diff shape: (n_train, n_features)\n        diff = q - train_X\n        # scales shape: (n_features,). Broadcasting applies it to each row of diff.\n        scaled_diff = diff * scales\n        # Sum of squares along the feature axis (axis=1)\n        sq_distances = np.sum(scaled_diff**2, axis=1)\n\n        # np.argmin finds the index of the minimum value. In case of ties,\n        # it returns the index of the first occurrence, which matches the\n        # problem's tie-breaking rule (pick the smallest index).\n        nearest_neighbor_idx = np.argmin(sq_distances)\n        predictions.append(train_y[nearest_neighbor_idx])\n        \n    return predictions\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    \"\"\"\n    test_cases = [\n        {\n            \"X\": np.array([\n                [1000., 0., 0.], [1000., 1., 0.], [0., 5., 0.], \n                [0., 6., 0.], [0., 7., 0.], [0., 8., 0.]\n            ]),\n            \"y\": np.array([0, 0, 1, 1, 1, 1]),\n            \"Q\": np.array([\n                [700., 6., 0.], [650., 5.5, 0.], [600., 7.5, 0.]\n            ])\n        },\n        {\n            \"X\": np.array([\n                [0., 0.], [1., 0.], [0., 100.], [1., 100.]\n            ]),\n            \"y\": np.array([0, 0, 1, 1]),\n            \"Q\": np.array([\n                [0.9, 10.], [0.5, 90.], [0.2, 30.]\n            ])\n        },\n        {\n            \"X\": np.array([\n                [1., 5.], [1., 5.], [1., 10.]\n            ]),\n            \"y\": np.array([0, 1, 1]),\n            \"Q\": np.array([\n                [100., 7.], [100., 5.], [100., 9.]\n            ])\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        X, y, Q = case[\"X\"], case[\"y\"], case[\"Q\"]\n        \n        # Compute stats for Z-score normalization.\n        # np.std with default ddof=0 computes the population standard deviation.\n        sigma = np.std(X, axis=0)\n        \n        # Compute stats for Min-Max normalization.\n        m = np.min(X, axis=0)\n        M = np.max(X, axis=0)\n        r = M - m\n        \n        # Create scales (weights) for distances, handling zero variance/range.\n        # The scale is 1/sigma or 1/r. If the divisor is 0, the scale is 0.\n        # A small epsilon is used for robust floating point comparison.\n        scales_z = np.zeros_like(sigma)\n        valid_sigma_mask = sigma > 1e-12\n        scales_z[valid_sigma_mask] = 1.0 / sigma[valid_sigma_mask]\n        \n        scales_mm = np.zeros_like(r)\n        valid_r_mask = r > 1e-12\n        scales_mm[valid_r_mask] = 1.0 / r[valid_r_mask]\n        \n        # Get predictions for both normalizations.\n        preds_z = one_nn_predict(Q, X, y, scales_z)\n        preds_mm = one_nn_predict(Q, X, y, scales_mm)\n        \n        # Calculate the fraction of queries with agreeing predictions.\n        agreement_count = np.sum(np.array(preds_z) == np.array(preds_mm))\n        agreement_fraction = agreement_count / len(Q)\n        \n        # Format the result for this test case as specified.\n        case_result = [\n            round(agreement_fraction, 3),\n            preds_z,\n            preds_mm\n        ]\n        results.append(case_result)\n\n    # The problem provides a skeleton print statement, which implies that\n    # Python's default string representation of lists is the desired format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3129970"}, {"introduction": "理解了归纳偏见的存在后，我们能否量化它带来的影响？当我们的假设空间（例如，所有加性模型的集合）因结构所限，无法包含真实的数据生成过程（例如，一个乘性模型）时，即使有无限的数据，我们能达到的最佳性能也存在一个上限。本练习将引导你从理论上推导出在一个受限的假设空间 $\\mathcal{H}$ 中最佳的预测器，并计算出由于这种模型与现实不匹配而产生的不可避免的误差。[@problem_id:3130015]", "problem": "考虑一个监督学习设定，其中输入是两个实值随机变量 $X$ 和 $Y$，目标是一个实值函数 $T(X,Y)$。假设空间被限制为可分离加性模型，形式为 $h(x,y)=f(x)+g(y)$，其中 $f$ 和 $g$ 是可测函数。这一限制构成了对加性的归纳偏置。\n\n假设以下基本前提：\n- 学习器在假设空间上最小化期望平方损失 $L(h)=\\mathbb{E}\\left[(T(X,Y)-h(X,Y))^{2}\\right]$。\n- 条件期望 $\\mathbb{E}[Z\\mid \\mathcal{G}]$ 是平方可积随机变量 $Z$ 在希尔伯特空间 $L^{2}$ 中 $\\mathcal{G}$-可测函数子空间上的正交投影，其内积为 $\\langle U,V\\rangle=\\mathbb{E}[UV]$。\n- 对于独立的随机变量 $X$ 和 $Y$，分别依赖于 $X$ 和 $Y$ 的函数之积的期望可以分解，即 $\\mathbb{E}[\\phi(X)\\,\\psi(Y)]=\\mathbb{E}[\\phi(X)]\\,\\mathbb{E}[\\psi(Y)]$。\n\n在此场景下，假设真实的数据生成机制是乘性的，具体为 $T(x,y)=\\theta\\,x\\,y$，其中 $\\theta\\in\\mathbb{R}$ 是一个固定标量。$(X,Y)$ 的联合分布满足 $X$ 和 $Y$ 相互独立且分布已知。您必须：\n1. 从所提供的基本前提推导出最优加性预测器 $h^{\\star}(x,y)$，该预测器在所有 $h(x,y)=f(x)+g(y)$ 的形式中最小化期望平方损失 $L(h)$，并用 $X$ 和 $Y$ 的分布特征以及标量 $\\theta$ 来表示可达到的最小期望损失 $L(h^{\\star})$。\n2. 实现一个程序，为以下每个独立的测试用例计算最小期望损失 $L(h^{\\star})$。在所有用例中，$X$ 和 $Y$ 都是独立的。当指定一个分布时：\n   - 对于正态分布，记作 $\\mathcal{N}(\\mu,\\sigma^{2})$，直接使用给定的均值和方差。\n   - 对于 $[a,b]$ 上的均匀分布，方差为 $(b-a)^{2}/12$，均值为 $(a+b)/2$。\n   - 对于值为 $c$ 的常数分布，方差为 $0$，均值为 $c$。\n   测试套件包含五个用例：\n   - 用例 1：$X\\sim\\mathcal{N}(\\mu_{x},\\sigma_{x}^{2})$，其中 $\\mu_{x}=1$ 且 $\\sigma_{x}^{2}=2$，$Y\\sim\\mathcal{N}(\\mu_{y},\\sigma_{y}^{2})$，其中 $\\mu_{y}=3$ 且 $\\sigma_{y}^{2}=4$，并且 $\\theta=2$。\n   - 用例 2：$X\\sim\\text{Uniform}[0,1]$，$Y\\sim\\text{Uniform}[0,1]$，并且 $\\theta=1$。\n   - 用例 3：$X$ 是值为 $5$ 的常数，$Y\\sim\\mathcal{N}(\\mu_{y},\\sigma_{y}^{2})$，其中 $\\mu_{y}=0$ 且 $\\sigma_{y}^{2}=1$，并且 $\\theta=3$。\n   - 用例 4：$X\\sim\\mathcal{N}(\\mu_{x},\\sigma_{x}^{2})$，其中 $\\mu_{x}=-2$ 且 $\\sigma_{x}^{2}=10$，$Y\\sim\\mathcal{N}(\\mu_{y},\\sigma_{y}^{2})$，其中 $\\mu_{y}=4$ 且 $\\sigma_{y}^{2}=5$，并且 $\\theta=-1$。\n   - 用例 5：$X\\sim\\text{Uniform}[-1,1]$，$Y\\sim\\text{Uniform}[-10^{-6},10^{-6}]$，并且 $\\theta=10$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的每个条目都等于相应案例的最小期望平方损失 $L(h^{\\star})$，并按上述顺序列出。例如，您的输出格式必须为 $[\\text{result}_{1},\\text{result}_{2},\\text{result}_{3},\\text{result}_{4},\\text{result}_{5}]$。不涉及物理单位，所有数值输出必须是实值浮点数。", "solution": "该问题是有效的，因为它在科学上基于统计学习理论，在数学上是良定的、客观的且自包含的。所有必要组成部分，包括真实数据生成过程、假设空间、损失函数和分布假设，都得到了明确定义。\n\n目标是找到最优可分离加性模型 $h^{\\star}(x,y) = f(x) + g(y)$，以最小化期望平方损失 $L(h) = \\mathbb{E}[(T(X,Y) - h(X,Y))^2]$，其中真实模型为 $T(X,Y) = \\theta XY$，且随机变量 $X$ 和 $Y$ 相互独立。\n\n这个最小化问题可以被看作是在平方可积随机变量的希尔伯特空间 $L^2$ 中，将随机变量 $T$ 正交投影到加性函数子空间上。加性函数子空间 $\\mathcal{H}_{\\text{add}}$ 由所有形如 $h(X,Y) = f(X) + g(Y)$ 的函数组成，其中 $f$ 和 $g$ 是可测函数，满足 $\\mathbb{E}[f(X)^2]  \\infty$ 和 $\\mathbb{E}[g(Y)^2]  \\infty$。\n\n最优预测器 $h^{\\star}$ 是 $\\mathcal{H}_{\\text{add}}$ 中的唯一元素，使得误差向量 $T - h^{\\star}$ 与子空间 $\\mathcal{H}_{\\text{add}}$ 正交。此正交性条件表示为，对于所有 $h \\in \\mathcal{H}_{\\text{add}}$，都有 $\\mathbb{E}[(T - h^{\\star})h] = 0$。此条件必须对任何函数 $f_0(X) \\in \\mathcal{H}_{\\text{add}}$ 和任何函数 $g_0(Y) \\in \\mathcal{H}_{\\text{add}}$ 均成立。这产生了两个必要条件：\n$1.$ 对于所有有效的函数 $f_0$，有 $\\mathbb{E}[(T - f^{\\star}(X) - g^{\\star}(Y)) f_0(X)] = 0$。\n$2.$ 对于所有有效的函数 $g_0$，有 $\\mathbb{E}[(T - f^{\\star}(X) - g^{\\star}(Y)) g_0(Y)] = 0$。\n\n对第一个条件使用全期望定律：\n$\\mathbb{E}[\\mathbb{E}[(T - f^{\\star}(X) - g^{\\star}(Y)) f_0(X) | X]] = 0$\n由于 $f_0(X)$ 和 $f^{\\star}(X)$ 相对于由 $X$ 生成的 sigma-代数是可测的，因此在给定 $X$ 的条件下，它们在条件期望中可被视为常数。\n$\\mathbb{E}[f_0(X) (\\mathbb{E}[T|X] - f^{\\star}(X) - \\mathbb{E}[g^{\\star}(Y)|X])] = 0$\n鉴于 $X$ 和 $Y$ 独立，$\\mathbb{E}[g^{\\star}(Y)|X] = \\mathbb{E}[g^{\\star}(Y)]$。该方程变为：\n$\\mathbb{E}[f_0(X) (\\mathbb{E}[T|X] - f^{\\star}(X) - \\mathbb{E}[g^{\\star}(Y)])] = 0$\n此式必须对 $f_0$ 的任何选择都成立，这意味着乘以 $f_0(X)$ 的项必须几乎必然为零。因此，我们得到 $f^{\\star}(X)$ 的表达式：\n$f^{\\star}(X) = \\mathbb{E}[T|X] - \\mathbb{E}[g^{\\star}(Y)]$\n通过对第二个条件的对称论证，我们得到 $g^{\\star}(Y)$ 的表达式：\n$g^{\\star}(Y) = \\mathbb{E}[T|Y] - \\mathbb{E}[f^{\\star}(X)]$\n\n我们现在有一个由两个方程组成的方程组。设 $c_f = \\mathbb{E}[f^{\\star}(X)]$ 和 $c_g = \\mathbb{E}[g^{\\star}(Y)]$。对每个方程取期望，我们得到 $c_f = \\mathbb{E}[T] - c_g$ 和 $c_g = \\mathbb{E}[T] - c_f$。这两个方程都等价于 $c_f + c_g = \\mathbb{E}[T]$。这表明对于 $f^{\\star}$ 和 $g^{\\star}$ 单独而言存在可辨识性问题（我们可以给一个函数加上一个常数，然后从另一个函数中减去它），但它们的和 $h^{\\star}$ 是唯一的。将 $c_g = \\mathbb{E}[T] - c_f$ 代入 $f^{\\star}(X)$ 的方程没有帮助，但我们可以求解它们的和 $h^{\\star}(X,Y) = f^{\\star}(X) + g^{\\star}(Y)$。\n将 $f^{\\star}(X)$ 和 $g^{\\star}(Y)$ 的两个方程相加：\n$f^{\\star}(X) + g^{\\star}(Y) = \\mathbb{E}[T|X] + \\mathbb{E}[T|Y] - \\mathbb{E}[f^{\\star}(X)] - \\mathbb{E}[g^{\\star}(Y)]$\n$h^{\\star}(X,Y) = \\mathbb{E}[T|X] + \\mathbb{E}[T|Y] - (\\mathbb{E}[f^{\\star}(X)] + \\mathbb{E}[g^{\\star}(Y)])$\n$h^{\\star}(X,Y) = \\mathbb{E}[T|X] + \\mathbb{E}[T|Y] - \\mathbb{E}[T]$\n这就是最优加性预测器的一般形式。\n\n现在，我们将此结果应用于特定的真实模型 $T(X,Y) = \\theta XY$。设 $\\mu_X = \\mathbb{E}[X]$ 和 $\\mu_Y = \\mathbb{E}[Y]$。\n所需的期望为：\n$\\mathbb{E}[T] = \\mathbb{E}[\\theta XY] = \\theta \\mathbb{E}[X]\\mathbb{E}[Y] = \\theta\\mu_X\\mu_Y$（由于 $X,Y$ 的独立性）\n$\\mathbb{E}[T|X] = \\mathbb{E}[\\theta XY | X] = \\theta X \\mathbb{E}[Y|X] = \\theta X \\mu_Y$（由于独立性）\n$\\mathbb{E}[T|Y] = \\mathbb{E}[\\theta XY | Y] = \\theta Y \\mathbb{E}[X|Y] = \\theta Y \\mu_X$（由于独立性）\n\n将这些代入 $h^{\\star}$ 的表达式中：\n$h^{\\star}(X,Y) = \\theta X\\mu_Y + \\theta Y\\mu_X - \\theta\\mu_X\\mu_Y$\n\n利用最优预测器 $h^{\\star}$，我们可以找到可达到的最小期望损失 $L(h^{\\star})$。\n$L(h^{\\star}) = \\mathbb{E}[(T - h^{\\star})^2]$\n预测误差为：\n$T - h^{\\star} = \\theta XY - (\\theta X\\mu_Y + \\theta Y\\mu_X - \\theta\\mu_X\\mu_Y)$\n$T - h^{\\star} = \\theta (XY - X\\mu_Y - Y\\mu_X + \\mu_X\\mu_Y)$\n此表达式可以分解为：\n$T - h^{\\star} = \\theta (X(Y - \\mu_Y) - \\mu_X(Y - \\mu_Y)) = \\theta (X - \\mu_X)(Y - \\mu_Y)$\n\n现在我们计算期望平方误差：\n$L(h^{\\star}) = \\mathbb{E}[(\\theta(X - \\mu_X)(Y - \\mu_Y))^2] = \\theta^2 \\mathbb{E}[(X - \\mu_X)^2(Y - \\mu_Y)^2]$\n由于 $X$ 和 $Y$ 独立，它们的任何函数，例如 $(X-\\mu_X)^2$ 和 $(Y-\\mu_Y)^2$，也都是独立的。因此，乘积的期望等于期望的乘积：\n$L(h^{\\star}) = \\theta^2 \\mathbb{E}[(X - \\mu_X)^2] \\mathbb{E}[(Y - \\mu_Y)^2]$\n根据定义，随机变量 $Z$ 的方差为 $\\text{Var}(Z) = \\sigma_Z^2 = \\mathbb{E}[(Z - \\mu_Z)^2]$。\n因此，最小期望损失为：\n$$L(h^{\\star}) = \\theta^2 \\sigma_X^2 \\sigma_Y^2$$\n这个最终表达式以标量 $\\theta$ 以及 $X$ 和 $Y$ 的方差（它们是关键的分布特征）来表示可达到的最小期望损失。该公式将用于计算指定测试用例的结果。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the minimal expected squared loss for an additive model\n    approximating a multiplicative true model.\n\n    The minimal loss L(h*) for a true model T(X,Y) = theta * X * Y and an\n    additive hypothesis h(x,y) = f(x) + g(y) is given by the formula:\n    L(h*) = theta^2 * Var(X) * Var(Y)\n    where X and Y are independent random variables.\n    \"\"\"\n\n    # Test cases defined as tuples of (theta, var_x, var_y)\n    test_cases = [\n        # Case 1: X~N(1, 2), Y~N(3, 4), theta=2\n        # var_x = 2, var_y = 4\n        (2.0, 2.0, 4.0),\n\n        # Case 2: X~Uniform[0,1], Y~Uniform[0,1], theta=1\n        # a=0, b=1. var = (b-a)^2 / 12 = 1/12\n        (1.0, (1.0 - 0.0)**2 / 12.0, (1.0 - 0.0)**2 / 12.0),\n\n        # Case 3: X is Constant at 5, Y~N(0, 1), theta=3\n        # var_x = 0, var_y = 1\n        (3.0, 0.0, 1.0),\n\n        # Case 4: X~N(-2, 10), Y~N(4, 5), theta=-1\n        # var_x = 10, var_y = 5\n        (-1.0, 10.0, 5.0),\n\n        # Case 5: X~Uniform[-1,1], Y~Uniform[-1e-6, 1e-6], theta=10\n        # For X: a=-1, b=1. var_x = (1 - (-1))^2 / 12 = 4/12 = 1/3\n        # For Y: a=-1e-6, b=1e-6. var_y = (1e-6 - (-1e-6))^2 / 12 = (2e-6)^2 / 12\n        (10.0, (1.0 - (-1.0))**2 / 12.0, (1e-6 - (-1e-6))**2 / 12.0),\n    ]\n\n    results = []\n    for theta, var_x, var_y in test_cases:\n        # Calculate the minimal expected loss using the derived formula\n        min_loss = theta**2 * var_x * var_y\n        results.append(min_loss)\n\n    # Format the output as a comma-separated list in brackets\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3130015"}, {"introduction": "归纳偏见并非越少越好。“正确”的偏见程度取决于问题的复杂性和可用数据的数量。一个简单的模型（高偏见，低方差）在数据稀少时可能优于一个复杂的模型（低偏见，高方差），反之亦然。本练习将通过一个模拟实验，让你构建学习曲线，直观地观察和分析这两个相互竞争的因素，并揭示在不同数据量 $n$ 下，包含与不包含交互项的两个假设空间 $\\mathcal{H}_{\\text{add}}$ 和 $\\mathcal{H}_{\\text{int}}$ 之间的性能交叉点。[@problem_id:3129988]", "problem": "您的任务是设计并实现一个原则性模拟，用以在有限样本量的监督学习场景下比较两个假设空间，并通过学习曲线分析偏差-方差权衡。场景设置如下。设输入为 $\\mathbf{x} = (x_1, x_2)$，其中 $x_1$ 和 $x_2$ 从区间 $[-1,1]$ 上的均匀分布中独立同分布 (i.i.d.) 地抽取。真实回归函数为\n$$\nf^\\star(\\mathbf{x}) \\;=\\; \\beta_0 \\;+\\; \\beta_1 x_1 \\;+\\; \\beta_2 x_2 \\;+\\; \\beta_{12} x_1 x_2,\n$$\n观测输出为\n$$\ny \\;=\\; f^\\star(\\mathbf{x}) \\;+\\; \\varepsilon,\n$$\n其中 $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^2)$ 是方差为 $\\sigma^2$ 的独立高斯噪声。考虑以下两个用于线性最小二乘法的假设空间（函数集合）：\n- 不含交互项的加性假设空间，\n$$\n\\mathcal{H}_{\\text{add}} \\;=\\; \\left\\{ f(\\mathbf{x}) \\;=\\; \\theta_0 \\;+\\; \\theta_1 x_1 \\;+\\; \\theta_2 x_2 \\right\\},\n$$\n- 包含交互项的交互假设空间，\n$$\n\\mathcal{H}_{\\text{int}} \\;=\\; \\left\\{ f(\\mathbf{x}) \\;=\\; \\theta_0 \\;+\\; \\theta_1 x_1 \\;+\\; \\theta_2 x_2 \\;+\\; \\theta_{12} x_1 x_2 \\right\\}。\n$$\n您的程序必须模拟学习曲线，并将误差分解为偏差和方差，作为训练样本量 $n \\in \\{8,32,128\\}$ 的函数。对于每个固定的 $n$，使用 $R=200$ 次独立重复实验进行训练，每次重复实验使用从上述数据生成过程中抽取的 $n$ 个独立同分布的 $\\mathbf{x}$ 和 $y$ 样本。为了评估，使用一个大小为 $M=512$ 的固定测试集，该测试集包含从相同分布中抽取的独立同分布的 $\\mathbf{x}$，并通过偏差-方差分解来评估期望泛化误差。\n\n从核心定义开始：对于一个学到的预测器 $\\hat{f}$，在平方损失下，于一个固定点 $\\mathbf{x}$ 的期望平方预测误差是\n$$\n\\mathbb{E}\\!\\left[(\\hat{f}(\\mathbf{x}) - y)^2 \\mid \\mathbf{x}\\right] \\;=\\; \\left(\\mathbb{E}[\\hat{f}(\\mathbf{x})] - f^\\star(\\mathbf{x})\\right)^2 \\;+\\; \\mathrm{Var}(\\hat{f}(\\mathbf{x})) \\;+\\; \\sigma^2,\n$$\n其中期望和方差是针对随机训练样本（以及任何算法随机性）计算的。样本量为 $n$ 时的学习曲线是该量在 $\\mathbf{x}$ 的测试分布上的平均值。在您的模拟中，通过对 $R$ 次重复实验和 $M$ 个测试输入的蒙特卡洛平均来近似这些期望值。\n\n对于每个测试用例，计算 $\\mathcal{H}_{\\text{add}}$ 和 $\\mathcal{H}_{\\text{int}}$ 的学习曲线，然后报告交互假设空间的泛化误差小于或等于加性假设空间泛化误差时的最小训练样本量 $n$（从给定集合中选取）。如果对于给定的 $n$ 值没有出现这样的交叉，则该测试用例报告 $0$。\n\n使用以下参数值测试套件，其中所有未明确列出的参数固定为 $\\beta_0 = 0$，$\\beta_1 = 1$ 和 $\\beta_2 = 1$：\n- 测试用例 1：$\\beta_{12} = 0.8$，$\\sigma^2 = 0.05$，\n- 测试用例 2：$\\beta_{12} = 0.8$，$\\sigma^2 = 1.0$，\n- 测试用例 3：$\\beta_{12} = 0.0$，$\\sigma^2 = 0.05$。\n\n您的程序必须：\n- 对于每个测试用例，模拟并估计两个假设空间在 $n \\in \\{8,32,128\\}$ 时的学习曲线，\n- 使用 $R=200$ 次训练重复实验和大小为 $M=512$ 的固定测试集进行蒙特卡洛近似，\n- 对于每个测试用例，返回一个整数：交互空间的估计泛化误差小于或等于加性空间的估计泛化误差时的最小 $n$ 值，如果没有交叉发生，则返回 $0$。\n\n最终输出格式：您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。该列表必须为每个测试用例包含一个整数，并按上述顺序列出。", "solution": "该问题要求进行数值模拟，以比较两个嵌套线性模型：加性模型 $\\mathcal{H}_{\\text{add}}$ 和带有交互项的模型 $\\mathcal{H}_{\\text{int}}$ 的泛化性能。该比较是在偏差-方差权衡的背景下进行的，性能被评估为训练样本量 $n$ 的函数。目标是确定对于不同的数据生成参数，更复杂的模型 $\\mathcal{H}_{\\text{int}}$ 达到小于或等于更简单模型 $\\mathcal{H}_{\\text{add}}$ 的泛化误差所需的最小样本量。\n\n解决方案的核心是旨在估计期望泛化误差的蒙特卡洛模拟。对于一个学到的模型 $\\hat{f}$，在特定输入 $\\mathbf{x}$ 处的期望平方预测误差可分解为三个部分：\n$$\n\\mathbb{E}_{\\mathcal{D}, \\varepsilon}\\left[(\\hat{f}(\\mathbf{x}) - y)^2 \\mid \\mathbf{x}\\right] \\;=\\; \\underbrace{\\left(\\mathbb{E}_{\\mathcal{D}}[\\hat{f}(\\mathbf{x})] - f^\\star(\\mathbf{x})\\right)^2}_{\\text{偏差平方}} \\;+\\; \\underbrace{\\mathbb{E}_{\\mathcal{D}}\\left[\\left(\\hat{f}(\\mathbf{x}) - \\mathbb{E}_{\\mathcal{D}}[\\hat{f}(\\mathbf{x})]\\right)^2\\right]}_{\\text{方差}} \\;+\\; \\underbrace{\\sigma^2}_{\\text{不可约误差}}\n$$\n此处，期望 $\\mathbb{E}_{\\mathcal{D}}$ 是对固定大小为 $n$ 的训练数据集 $\\mathcal{D}$ 的分布求得的。总泛化误差是该量在测试输入 $\\mathbf{x}$ 分布上的期望。我们的模拟通过对大量抽样进行平均来近似这些期望值。\n\n模拟过程如下：\n\n首先，我们建立一个固定的测试集，以确保评估基准的一致性。生成一个包含 $M=512$ 个输入向量 $\\{\\mathbf{x}^{(i)}\\}_{i=1}^M$ 的集合，其中每个 $\\mathbf{x}^{(i)} = (x_1^{(i)}, x_2^{(i)})$ 的分量都独立地从 $\\mathcal{U}[-1, 1]$ 中抽取。对于这些测试点，我们使用真实函数 $f^\\star(\\mathbf{x}) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_{12} x_1 x_2$ 以及每个测试用例指定的参数，计算真实的、无噪声的函数值 $f^\\star(\\mathbf{x}^{(i)})$。\n\n接下来，对于每个训练样本量 $n \\in \\{8, 32, 128\\}$，我们进行 $R=200$ 次独立的训练重复实验。在每次重复实验 $r \\in \\{1, \\dots, R\\}$ 中：\n1.  生成一个新的大小为 $n$ 的训练数据集 $\\mathcal{D}_r$。输入 $\\{\\mathbf{x}_j\\}_{j=1}^n$ 从 $\\mathcal{U}[-1, 1] \\times \\mathcal{U}[-1, 1]$ 中独立同分布地抽取。相应的输出 $\\{y_j\\}_{j=1}^n$ 计算为 $y_j = f^\\star(\\mathbf{x}_j) + \\varepsilon_j$，其中 $\\varepsilon_j \\sim \\mathcal{N}(0, \\sigma^2)$。\n2.  将两个模型拟合到训练数据 $\\mathcal{D}_r$：一个来自 $\\mathcal{H}_{\\text{add}}$，另一个来自 $\\mathcal{H}_{\\text{int}}$。这是通过普通最小二乘法完成的，该方法找到最小化残差平方和的参数向量 $\\hat{\\theta}$。对于设计矩阵为 $X$、目标向量为 $y$ 的模型，解为 $\\hat{\\theta} = (X^T X)^{-1} X^T y$。在数值上，最好使用如奇异值分解等稳定方法来计算，例如 `numpy.linalg.lstsq` 中实现的方法。\n    -   对于 $\\mathcal{H}_{\\text{add}}$，设计矩阵的列对应于一个截距项、$x_1$ 和 $x_2$。\n    -   对于 $\\mathcal{H}_{\\text{int}}$，设计矩阵额外增加一列用于交互项 $x_1 x_2$。\n3.  然后，使用这两个拟合模型（我们称之为 $\\hat{f}_{\\text{add}, r}$ 和 $\\hat{f}_{\\text{int}, r}$）对 $M$ 个固定测试点进行预测。这将产生两个预测向量 $\\hat{y}_{\\text{add}, r}$ 和 $\\hat{y}_{\\text{int}, r}$，并将其存储起来。\n\n对于给定的 $n$，完成所有 $R=200$ 次重复实验后，我们对两个假设空间中的每个 $M$ 测试点都有 $R$ 个预测。现在我们可以近似偏差和方差项。对于每个测试点 $\\mathbf{x}^{(i)}$ 和每个模型类别（例如，“add”），我们执行以下计算：\n-   在所有重复实验中的平均预测，$\\bar{f}_{\\text{add}}(\\mathbf{x}^{(i)}) = \\frac{1}{R} \\sum_{r=1}^R \\hat{f}_{\\text{add}, r}(\\mathbf{x}^{(i)})$，近似于 $\\mathbb{E}_{\\mathcal{D}}[\\hat{f}_{\\text{add}}(\\mathbf{x}^{(i)})]$。\n-   在 $\\mathbf{x}^{(i)}$ 处的偏差平方估计为 $(\\bar{f}_{\\text{add}}(\\mathbf{x}^{(i)}) - f^\\star(\\mathbf{x}^{(i)}))^2$。\n-   在 $\\mathbf{x}^{(i)}$ 处的方差估计为 $\\frac{1}{R} \\sum_{r=1}^R (\\hat{f}_{\\text{add}, r}(\\mathbf{x}^{(i)}) - \\bar{f}_{\\text{add}}(\\mathbf{x}^{(i)}))^2$。\n\n模型的总泛化误差是三个分量的总和：在 $M$ 个测试点上估计的偏差平方的平均值，在 $M$ 个测试点上估计的方差的平均值，以及不可约误差 $\\sigma^2$。\n\n对每个训练样本量 $n$ 重复整个过程。最后，通过比较在每个 $n$ 处计算出的 $\\mathcal{H}_{\\text{add}}$ 和 $\\mathcal{H}_{\\text{int}}$ 的泛化误差，我们确定 $\\text{Error}(\\mathcal{H}_{\\text{int}}) \\le \\text{Error}(\\mathcal{H}_{\\text{add}})$ 成立的最小 $n$。如果对于任何指定的 $n$ 值，此条件都不满足，则该测试用例的结果为 $0$。该过程应用于三个测试用例，这些用例通过改变真实参数 $\\beta_{12}$ 和噪声方差 $\\sigma^2$ 来说明偏差-方差权衡的不同场景。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        # (beta_12, sigma_sq)\n        (0.8, 0.05),\n        (0.8, 1.0),\n        (0.0, 0.05),\n    ]\n\n    # Fixed parameters from problem statement\n    base_params = {'beta0': 0.0, 'beta1': 1.0, 'beta2': 1.0}\n    n_values = [8, 32, 128]\n    R = 200\n    M = 512\n\n    results = []\n    for beta_12, sigma_sq in test_cases:\n        params = base_params.copy()\n        params['beta_12'] = beta_12\n        params['sigma_sq'] = sigma_sq\n        \n        crossover_n = simulate_learning_curves(params, n_values, R, M)\n        results.append(crossover_n)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef simulate_learning_curves(params, n_values, R, M):\n    \"\"\"\n    Simulates learning curves for one set of parameters.\n\n    Args:\n        params (dict): Dictionary of parameters (beta0, beta1, beta2, beta_12, sigma_sq).\n        n_values (list): List of training sample sizes to test.\n        R (int): Number of training replicates.\n        M (int): Size of the fixed test set.\n\n    Returns:\n        int: The smallest n at which the interaction model's error is less than\n             or equal to the additive model's error, or 0 if no crossover occurs.\n    \"\"\"\n    # Use a fixed seed for reproducibility of the simulation.\n    np.random.seed(42)\n\n    beta_star = np.array([params['beta0'], params['beta1'], params['beta2'], params['beta_12']])\n    sigma_sq = params['sigma_sq']\n    sigma = np.sqrt(sigma_sq)\n\n    # 1. Generate a fixed test set\n    x_test_raw = np.random.uniform(-1, 1, size=(M, 2))\n    x1_test, x2_test = x_test_raw[:, 0], x_test_raw[:, 1]\n    \n    # Design matrices for the test set\n    X_test_add = np.c_[np.ones(M), x1_test, x2_test]\n    X_test_int = np.c_[X_test_add, x1_test * x2_test]\n    \n    # True function values on the test set\n    f_star_test = X_test_int @ beta_star\n\n    errors = {n: {} for n in n_values}\n\n    # 2. Iterate through training sizes\n    for n in n_values:\n        # Storage for predictions from all R replicates for the current n\n        preds_add = np.zeros((M, R))\n        preds_int = np.zeros((M, R))\n\n        # 3. Loop over R replicates\n        for r in range(R):\n            # a. Generate training data\n            x_train_raw = np.random.uniform(-1, 1, size=(n, 2))\n            x1_train, x2_train = x_train_raw[:, 0], x_train_raw[:, 1]\n            \n            X_train_add = np.c_[np.ones(n), x1_train, x2_train]\n            X_train_int = np.c_[X_train_add, x1_train * x2_train]\n\n            f_star_train = X_train_int @ beta_star\n            noise = np.random.normal(0, sigma, size=n)\n            y_train = f_star_train + noise\n            \n            # b. Fit models using linear least squares\n            theta_add, _, _, _ = np.linalg.lstsq(X_train_add, y_train, rcond=None)\n            theta_int, _, _, _ = np.linalg.lstsq(X_train_int, y_train, rcond=None)\n\n            # c. Make and store predictions on the test set\n            preds_add[:, r] = X_test_add @ theta_add\n            preds_int[:, r] = X_test_int @ theta_int\n\n        # 4. Calculate bias-squared, variance, and total generalization error\n        # For the additive model\n        E_f_hat_add = np.mean(preds_add, axis=1)\n        bias_sq_add = (E_f_hat_add - f_star_test)**2\n        var_add = np.var(preds_add, axis=1) # ddof=0 is default, correct for population var over replicates\n        total_err_add = np.mean(bias_sq_add) + np.mean(var_add) + sigma_sq\n        errors[n]['add'] = total_err_add\n        \n        # For the interaction model\n        E_f_hat_int = np.mean(preds_int, axis=1)\n        bias_sq_int = (E_f_hat_int - f_star_test)**2\n        var_int = np.var(preds_int, axis=1)\n        total_err_int = np.mean(bias_sq_int) + np.mean(var_int) + sigma_sq\n        errors[n]['int'] = total_err_int\n\n    # 5. Find the crossover point\n    for n in sorted(n_values):\n        if errors[n]['int'] = errors[n]['add']:\n            return n\n    \n    return 0\n\nsolve()\n```", "id": "3129988"}]}