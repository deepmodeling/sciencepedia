{"hands_on_practices": [{"introduction": "机器学习的一个核心目标是最小化训练误差和测试误差之间的差距，即泛化差距。这个练习将探讨一个极端情景：在“没有免费午餐”定理的随机标签假设下，一个完美拟合训练数据的算法会发生什么？通过推导，我们将揭示在没有真实模式可循的情况下，完美的训练表现（插值）反而会导致最差的泛化性能[@problem_id:3153395]。", "problem": "考虑一个 $K$ 类分类问题，其输入空间为 $\\mathcal{X}$，标签空间为 $\\mathcal{Y}=\\{1,2,\\dots,K\\}$。设 $(X,Y)$ 是一个随机对，其中 $X \\sim P_{X}$ 是任意的，且 $Y$ 与 $X$ 相互独立，并在 $\\mathcal{Y}$ 上均匀分布。你观察到一个训练样本 $S=\\{(x_{i},y_{i})\\}_{i=1}^{n}$，它是由 $n$ 个从 $P_{X} \\times \\text{Unif}(\\mathcal{Y})$ 中独立同分布抽取的样本组成。一个学习算法 $\\mathcal{A}$ 将样本 $S$（以及可能的内部随机性）映射到一个分类器 $\\hat{f}_{S}:\\mathcal{X}\\to\\mathcal{Y}$。假设 $\\mathcal{A}$ 是一个插值算法，这意味着训练数据上的经验 $0$-$1$ 风险恰好为零：\n$$\nR_{\\text{train}}(S) \\equiv \\frac{1}{n}\\sum_{i=1}^{n}\\mathbf{1}\\{\\hat{f}_{S}(x_{i}) \\neq y_{i}\\} = 0.\n$$\n将 $\\hat{f}_{S}$ 的条件测试风险定义为\n$$\nR_{\\text{test}}(S) \\equiv \\Pr\\big(\\hat{f}_{S}(X) \\neq Y \\,\\big|\\, S\\big),\n$$\n其中概率是关于一个独立的测试对 $(X,Y)\\sim P_{X}\\times \\text{Unif}(\\mathcal{Y})$ 计算的。设 $R_{\\text{baseline}}$ 表示一个分类器的错误率，该分类器独立于 $X$ 和 $S$，从 $\\mathcal{Y}$ 中随机均匀地猜测一个标签。\n\n仅使用基本定义（独立性、条件期望和 $0$-$1$ 损失的定义），推导期望泛化差距的精确表达式，该表达式是 $K$ 的函数：\n$$\n\\mathbb{E}\\big[R_{\\text{test}}(S)-R_{\\text{train}}(S)\\big],\n$$\n其中期望是关于样本 $S$ 的随机性（以及 $\\mathcal{A}$ 的任何内部随机性）计算的。请将您的最终答案表示为关于 $K$ 的单一闭式解析表达式。不需要近似或四舍五入，也不涉及单位。", "solution": "问题要求解期望泛化差距的精确表达式，该差距定义为 $\\mathbb{E}\\big[R_{\\text{test}}(S)-R_{\\text{train}}(S)\\big]$。期望是关于随机训练样本 $S$ 和学习算法 $\\mathcal{A}$ 的任何内部随机性计算的。\n\n首先，我们分析泛化差距中的两项：测试风险 $R_{\\text{test}}(S)$ 和训练风险 $R_{\\text{train}}(S)$。\n\n训练风险 $R_{\\text{train}}(S)$ 定义为 $R_{\\text{train}}(S) \\equiv \\frac{1}{n}\\sum_{i=1}^{n}\\mathbf{1}\\{\\hat{f}_{S}(x_{i}) \\neq y_{i}\\}$。问题陈述该算法 $\\mathcal{A}$ 是一个插值算法，这意味着训练数据上的经验 $0$-$1$ 风险恰好为零。因此，对于任何抽取的训练样本 $S$，我们有：\n$$\nR_{\\text{train}}(S) = 0\n$$\n该条件意味着学习到的分类器正确分类了所有训练样本：对于所有 $i \\in \\{1, 2, \\dots, n\\}$，都有 $\\hat{f}_{S}(x_{i}) = y_{i}$。\n\n由于 $R_{\\text{train}}(S) = 0$，期望泛化差距简化为：\n$$\n\\mathbb{E}\\big[R_{\\text{test}}(S)-R_{\\text{train}}(S)\\big] = \\mathbb{E}\\big[R_{\\text{test}}(S) - 0\\big] = \\mathbb{E}\\big[R_{\\text{test}}(S)\\big]\n$$\n问题因此简化为计算期望测试风险。\n\n条件测试风险 $R_{\\text{test}}(S)$ 定义为，在给定训练样本 $S$ 的条件下，在一个新的、独立的测试对 $(X, Y)$ 上的错误概率：\n$$\nR_{\\text{test}}(S) \\equiv \\Pr\\big(\\hat{f}_{S}(X) \\neq Y \\,\\big|\\, S\\big)\n$$\n期望 $\\mathbb{E}\\big[R_{\\text{test}}(S)\\big]$ 是对所有可能的训练集 $S$ 计算的。使用全期望定律（或塔性质），我们可以写出：\n$$\n\\mathbb{E}\\big[R_{\\text{test}}(S)\\big] = \\mathbb{E}_{S}\\left[\\Pr\\big(\\hat{f}_{S}(X) \\neq Y \\,\\big|\\, S\\big)\\right] = \\Pr\\big(\\hat{f}_{S}(X) \\neq Y\\big)\n$$\n右侧是总错误概率，其中概率是关于所有随机性来源计算的：训练样本 $S$、算法 $\\mathcal{A}$ 中的任何内部随机性，以及测试对 $(X, Y)$。\n\n为了计算这个概率，先计算正确预测的概率 $\\Pr\\big(\\hat{f}_{S}(X) = Y\\big)$ 会更容易。我们有：\n$$\n\\Pr\\big(\\hat{f}_{S}(X) \\neq Y\\big) = 1 - \\Pr\\big(\\hat{f}_{S}(X) = Y\\big)\n$$\n设测试输入 $X$ 的预测由随机变量 $\\hat{Y} = \\hat{f}_{S}(X)$ 表示。这个预测 $\\hat{Y}$ 是训练样本 $S$ 和测试输入 $X$（以及 $\\mathcal{A}$ 的任何内部随机性）的函数。测试点的真实标签是随机变量 $Y$。\n\n问题的核心在于指定的数据生成分布。测试标签 $Y$ 是从集合 $\\mathcal{Y}=\\{1, 2, \\dots, K\\}$ 中均匀抽取的，并且与测试输入 $X$ 独立。此外，整个测试对 $(X,Y)$ 与训练样本 $S$ 独立。因此，测试标签 $Y$ 与随机变量集合 $(X, S)$ 以及算法的任何内部随机性都独立。由于预测 $\\hat{Y} = \\hat{f}_{S}(X)$ 是 $(X, S)$（以及内部随机性）的函数，因此可以得出 $Y$ 与 $\\hat{Y}$ 相互独立。\n\n我们通过对所有可能的正确标签结果求和来计算正确预测的概率：\n$$\n\\Pr(\\hat{Y} = Y) = \\sum_{k=1}^{K} \\Pr(\\hat{Y} = k \\text{ and } Y = k)\n$$\n因为 $\\hat{Y}$ 和 $Y$ 是相互独立的随机变量，所以联合概率是边际概率的乘积：\n$$\n\\Pr(\\hat{Y} = k \\text{ and } Y = k) = \\Pr(\\hat{Y} = k) \\cdot \\Pr(Y = k)\n$$\n根据问题陈述，$Y$ 在 $\\mathcal{Y}$ 上均匀分布。因此，对于任何标签 $k \\in \\mathcal{Y}$：\n$$\n\\Pr(Y = k) = \\frac{1}{K}\n$$\n将此代入求和式中得到：\n$$\n\\Pr(\\hat{Y} = Y) = \\sum_{k=1}^{K} \\Pr(\\hat{Y} = k) \\cdot \\frac{1}{K} = \\frac{1}{K} \\sum_{k=1}^{K} \\Pr(\\hat{Y} = k)\n$$\n随机变量 $\\hat{Y}$ 所有可能结果的概率之和必须等于 1。由于 $\\hat{f}_{S}:\\mathcal{X}\\to\\mathcal{Y}$，$\\hat{Y}$ 的可能结果是 $\\mathcal{Y}$ 中的标签。因此：\n$$\n\\sum_{k=1}^{K} \\Pr(\\hat{Y} = k) = 1\n$$\n将此结果代回，我们得到正确预测的概率：\n$$\n\\Pr(\\hat{Y} = Y) = \\frac{1}{K} \\cdot 1 = \\frac{1}{K}\n$$\n这个结果与算法 $\\mathcal{A}$ 的选择无关，只要它对给定输入产生确定性预测，并且是标签 $Y$ 作为与特征 $X$ 没有统计依赖关系的纯噪声的直接结果。\n\n那么总错误概率为：\n$$\n\\Pr\\big(\\hat{f}_{S}(X) \\neq Y\\big) = 1 - \\Pr\\big(\\hat{f}_{S}(X) = Y\\big) = 1 - \\frac{1}{K}\n$$\n这就是期望测试风险 $\\mathbb{E}\\big[R_{\\text{test}}(S)\\big]$ 的值。\n\n最后，我们可以计算期望泛化差距：\n$$\n\\mathbb{E}\\big[R_{\\text{test}}(S)-R_{\\text{train}}(S)\\big] = \\mathbb{E}\\big[R_{\\text{test}}(S)\\big] - \\mathbb{E}\\big[R_{\\text{train}}(S)\\big]\n$$\n由于对于所有 $S$ 都有 $R_{\\text{train}}(S)=0$，其期望也为 $0$。\n$$\n\\mathbb{E}\\big[R_{\\text{test}}(S)-R_{\\text{train}}(S)\\big] = \\left(1 - \\frac{1}{K}\\right) - 0 = 1 - \\frac{1}{K}\n$$\n该表达式可重写为 $\\frac{K-1}{K}$。这个结果展示了“没有免费午餐”定理的一种形式：在特征和标签之间没有任何相关性的情况下，一个完美插值含噪训练数据的算法，其测试性能不优于随机猜测。插值条件只是将训练误差降为 $0$，从而最大化了测试性能和训练性能之间的差距。", "answer": "$$\n\\boxed{1 - \\frac{1}{K}}\n$$", "id": "3153395"}, {"introduction": "在上一个练习的基础上，我们更进一步，像一个“对手”一样思考：如何设计一个学习问题，使得任何算法都必然会失败？这个思想实验旨在澄清“没有免费午餐”定理的核心假设。通过构建一个对抗性学习场景，我们将理解，真正的“对手”并非某个刁钻的函数，而是在未知数据上所有可能性的完全均匀分布，这正是NFL框架的精髓所在[@problem_id:3153421]。", "problem": "考虑一个有限实例空间 $\\mathcal{X}$ 上的二元分类问题，其标签集为 $\\mathcal{Y}=\\{0,1\\}$。设 $|\\mathcal{X}|=m$，一个训练样本 $S=\\{(x_{i},y_{i})\\}_{i=1}^{n}$ 是从 $\\mathcal{X}$ 中无放回抽取的，其中标签 $y_{i}$ 由一个未知的目标函数 $f:\\mathcal{X}\\to\\mathcal{Y}$ 生成。假设训练样本可由假设类 $\\mathcal{H}$ 实现，因此一个一致性学习器会产生一个假设 $h\\in\\mathcal{H}$，满足对于所有 $(x_{i},y_{i})\\in S$ 都有 $h(x_{i})=y_{i}$。设测试点 $X_{\\text{test}}$ 是从未见数据集 $U=\\mathcal{X}\\setminus\\{x_{1},\\dots,x_{n}\\}$ 中均匀随机抽取的，并假设 $|U|=m-n$ 是偶数。\n\n在“没有免费午餐”（NFL）假设下，除了在训练样本上的取值外，对 $f$ 没有结构性约束。仅使用泛化误差 $\\Pr(h(X)\\neq f(X))$ 的基本定义和 NFL 原理（即 $f$ 可以在 $U$ 上分配任意标签），构造一个对抗性目标函数 $f$，该函数在 $S$ 上的标签与训练标签一致，但其选择会迫使每个一致性学习器在从 $U$ 中均匀随机抽取的测试点 $X_{\\text{test}}$ 上产生至少为 $\\frac{1}{2}$ 的测试误差。然后，计算由您的构造所导致的测试误差 $\\Pr(h(X_{\\text{test}})\\neq f(X_{\\text{test}}))$ 的确切值，并将最终答案表示为不带单位的最简分数。", "solution": "问题要求我们构造一个对抗性目标函数 $f$，然后计算任何一致性学习器产生的测试误差。“对抗性”一词必须在“没有免费午餐”（NFL）定理的背景下进行解释。\n\n一个天真的解释是，在未见数据集 $U$ 上构造一个单一的、确定性的目标函数 $f$，以保证对*任何*可能的一致性假设 $h$ 都有很高的误差。让我们考虑在 $U$ 上的这样一个固定的目标函数 $f$。一致性学习器的唯一约束是在训练集 $S$ 上匹配标签。在未见数据集 $U$ 上，学习器可以自由预测任何标签。如果学习器知道我们在 $U$ 上选择的 $f$，它可以简单地将其在 $U$ 上的假设 $h$ 定义为与 $f$ 相同，即对于所有 $x \\in U$，都有 $h(x) = f(x)$。这将导致测试误差为 $0$，违反了误差必须至少为 $\\frac{1}{2}$ 的条件。因此，在 $U$ 上，没有任何单一、固定、确定性的 $f$ 选择可以迫使*每个*可能的一致性学习器都产生高误差。\n\n“构造一个对抗性目标函数”这句话必须本着 NFL 定理核心原则的精神来理解，即在没有任何关于未见数据上目标函数的先验知识或假设的情况下，所有可能性都是等可能的。“对抗性”函数的构造指的是这种最大不确定性的情景。因此，我们将目标函数 $f$ 在集合 $U$ 上的行为建模为从所有从 $U$ 到 $\\mathcal{Y}$ 的可能函数集合中均匀随机抽取的。这样的函数有 $2^{|U|}$ 个，每个被选中的概率为 $2^{-|U|}$。从学习器的角度来看，这是目标函数的“最坏情况”或“对抗性”分布，因为它没有提供任何可利用的信息。问题接着要求计算由这种构造所引起的确切测试误差。\n\n设 $h$ 是由任意一个一致性学习器生成的假设。在训练集 $S$ 上，$h(x_i) = y_i$。在未见数据集 $U$ 上，学习器对任何 $x \\in U$ 的预测 $h(x)$ 是固定的，由其自身的归纳偏置决定。我们被要求计算测试误差，即概率 $\\Pr(h(X_{\\text{test}}) \\neq f(X_{\\text{test}}))$。这个概率是针对从 $U$ 中随机选择测试点 $X_{\\text{test}}$ 和在 $U$ 上随机选择目标函数的标签 $f(x)$ 计算的。\n\n测试误差是错误指示变量的期望值：\n$$ \\text{Error} = E_{X_{\\text{test}}, f} \\left[ \\mathbb{I}(h(X_{\\text{test}}) \\neq f(X_{\\text{test}})) \\right] $$\n我们可以使用全期望定律，以测试点 $X_{\\text{test}}$ 的选择为条件。设 $X_{\\text{test}} = x$，其中 $x$ 是 $U$ 中的一个特定点。\n$$ \\text{Error} = E_{X_{\\text{test}}} \\left[ E_{f} \\left[ \\mathbb{I}(h(X_{\\text{test}}) \\neq f(X_{\\text{test}})) \\mid X_{\\text{test}} = x \\right] \\right] = E_{X_{\\text{test}}} \\left[ \\Pr_{f}(h(x) \\neq f(x)) \\right] $$\n现在，我们来分析内部的概率 $\\Pr_{f}(h(x) \\neq f(x))$，对于一个固定的 $x \\in U$。假设 $h$ 对 $x$ 做出一个特定的预测，比如说 $h(x) = c$，其中 $c \\in \\{0, 1\\}$。根据我们的构造，目标标签 $f(x)$ 是从 $\\{0, 1\\}$ 中均匀随机选择的。\n在这个点 $x$ 上犯错的概率是 $f(x)$ 不等于 $c$ 的概率。\n$$ \\Pr_{f}(f(x) \\neq c) = \\Pr_{f}(f(x) = 1-c) $$\n由于 $f(x)$ 以相等的概率 $\\frac{1}{2}$ 被选为 $0$ 或 $1$，这个概率是：\n$$ \\Pr_{f}(h(x) \\neq f(x)) = \\frac{1}{2} $$\n这个结果对 $U$ 中的任何特定点 $x$ 都成立，无论学习器的预测 $h(x)$ 是什么。\n\n现在，我们可以把这个结果代回到关于 $X_{\\text{test}}$ 选择的外部期望中。由于对于 $U$ 中的任何 $x$ 的选择，内部概率都是一个常数 $\\frac{1}{2}$：\n$$ \\text{Error} = E_{X_{\\text{test}}} \\left[ \\frac{1}{2} \\right] $$\n一个常数的期望就是它本身。\n$$ \\text{Error} = \\frac{1}{2} $$\n这个结果表明，在 NFL 定理所蕴含的对抗性条件下——即在未见数据上所有可能的目标函数呈均匀分布——任何一致性学习算法的期望测试误差都恰好是 $\\frac{1}{2}$。这在这个期望的意义上满足了迫使每个学习器产生至少为 $\\frac{1}{2}$ 的误差的条件。\n\n$|U|=m-n$ 是偶数的条件对于这个结果并非必需。它可能被包含进来是为了暗示一条错误的路径，该路径涉及将 $U$ 确定性地划分为两个相等的一半，而如前所示，这种构造对于所有学习器来说都不是稳健的。NFL 的基本原理依赖于在函数空间上的平均，这对任何大小的 $U$ 都成立。\n由这种典型的对抗性构造所导致的测试误差的确切值是 $\\frac{1}{2}$。", "answer": "$$\\boxed{\\frac{1}{2}}$$", "id": "3153421"}, {"introduction": "现在，我们将从理论推导和思想实验转向代码实践。这个练习将直接通过计算来验证“没有免费午餐”定理的核心论点。我们将实现两种截然不同的学习算法——一个局部算法（1-近邻）和一个全局算法（多数投票），并在一系列随机生成的任务上比较它们的性能。这个练习通过统计检验，为NFL定理的结论——在所有可能任务的平均下，没有一种算法优于另一种——提供了经验证据[@problem_id:3153410]。", "problem": "给定两种监督学习算法，您需要在统计学习中的“没有免费的午餐”定理框架下对它们进行比较。输入域是所有固定长度二进制向量的有限集合。您的任务是通过在所有可能的标签上均匀采样目标函数来设计合成任务，并实现一个配对假设检验，以验证两种学习器之间的平均性能差异是否与零没有显著不同。\n\n使用的基本原理：\n- 有限域上监督学习的“没有免费的午餐”（NFL）原则：在有限域上的目标函数服从均匀分布且使用0-1损失的情况下，所有学习算法在未见点上的预期泛化性能是相等的。\n- 风险和准确率的定义：对于一个假设 $h$ 和目标函数 $f$，在有限集 $U$ 上使用0-1损失，准确率是 $\\frac{1}{|U|}\\sum_{x\\in U}\\mathbf{1}\\{h(x)=f(x)\\}$.\n- 使用配对学生t检验的经典假设检验：给定配对差异 $\\{d_t\\}_{t=1}^k$，假设它们独立且近似服从均值为 $\\mu_d$ 和有限方差的正态分布，我们使用检验统计量 $T=\\bar{d}/(s_d/\\sqrt{k})$ 和 $k-1$ 自由度来检验原假设 $H_0:\\mu_d=0$，其中 $\\bar{d}$ 是样本均值， $s_d$ 是经过贝塞尔校正的样本标准差。\n\n实验的设置和精确定义：\n- 输入空间：对于一个正整数 $m$，定义 $X=\\{0,1\\}^m$，使用二进制展开，通过整数 $\\{0,1,\\dots,2^m-1\\}$ 按字典序表示。\n- 训练集：固定一个训练集大小 $n$，其中 $0 \\le n \\le 2^m$。令训练索引集为 $X$ 中按字典序排列的前 $n$ 个元素，记为 $S=\\{x_0,\\dots,x_{n-1}\\}$。未见集为 $U=X\\setminus S$。\n- 目标函数采样：一个目标函数 $f:X\\to\\{0,1\\}$ 由一个二进制向量 $y\\in\\{0,1\\}^{|X|}$ 表示。为了均匀采样 $f$，独立地从参数为 $1/2$ 的伯努利分布中抽取每个 $y_i$，即对所有 $i\\in\\{0,\\dots,|X|-1\\}$， $y_i\\sim\\mathrm{Bernoulli}(1/2)$。对于 $k=2^{|X|}$ 的特殊情况，将这 $k$ 个任务定义为对 $X$ 所有可能的二进制标签的穷举，并按 $y$ 的字典序排序。\n- 学习器 $A_1$（在 $S$ 上使用汉明距离的1-最近邻）：给定 $S$ 和标签 $y|_S$，定义 $A_1$ 对任意 $x\\in X$ 预测其在 $\\{0,1\\}^m$ 上汉明距离下 $S$ 中的最近邻的标签。如果出现距离相同的情况，通过选择 $S$ 中字典序最小的训练点来打破僵局。\n- 学习器 $A_2$（经验多数常数）：给定 $S$ 和标签 $y|_S$，定义 $A_2$ 对所有 $x\\in X$ 预测 $S$ 中的经验多数标签。如果 $S$ 中出现票数平局，则预测 $0$。\n- 每项任务的性能：对于每个采样的任务 $f$，使用 $y|_S$ 在 $S$ 上训练 $A_1$ 和 $A_2$，并计算它们在 $U$ 上的准确率。设 $a_1$ 和 $a_2$ 为得到的准确率。定义配对差异 $d=a_1-a_2$。\n\n要实现的统计检验：\n- 对于给定的整数 $k\\ge 1$，通过如上所述均匀采样 $f$（或在 $k=2^{|X|}$ 时穷举所有 $2^{|X|}$ 个标签）来生成 $k$ 个独立任务。计算配对差异 $\\{d_t\\}_{t=1}^k$。\n- 使用配对学生t检验，在显著性水平 $\\alpha\\in(0,1)$ 下，检验原假设 $H_0:\\mu_d=0$ 与双边备择假设 $H_1:\\mu_d\\ne 0$。\n- 如果 $k  2$ 或样本标准差 $s_d$ 为零，则将p值定义为 $1$ 并且不拒绝 $H_0$。\n- 否则，计算自由度为 $k-1$ 的 $T=\\bar{d}/(s_d/\\sqrt{k})$，以及学生t分布的双边p值 $p=2\\cdot\\mathrm{sf}(|T|)$，其中 $\\mathrm{sf}$ 是生存函数。当 $p\\alpha$ 时，决定不拒绝 $H_0$。\n\n您的程序必须实现上述流程并为每个测试用例生成一个决策。\n\n测试套件和要求的输出：\n- 使用以下四个测试用例，每个用例指定为一个元组 $(m,n,k,\\text{seed},\\alpha)$：\n  1. $(5,8,64,12345,0.05)$\n  2. $(5,8,1,7,0.05)$\n  3. $(3,2,256,0,0.05)$，由于 $k=2^{|X|}$，进行穷举，种子被忽略。\n  4. $(6,10,100,2024,0.01)$\n- 对于 $k\\ne 2^{|X|}$ 的情况，使用给定的种子初始化一个伪随机数生成器，以按规定采样 $k$ 个作为独立同分布均匀标签的函数 $f$。\n- 对于每个测试用例，要求的答案是一个布尔值，指示在水平 $\\alpha$ 下平均性能差异是否与 $0$ 没有显著不同，也就是说，如果不拒绝 $H_0$ 则返回 $\\text{True}$，否则返回 $\\text{False}$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果。该列表必须按上述顺序包含四个测试用例的布尔决策，例如，“[$\\text{True}$,$\\text{False}$,$\\text{True}$,$\\text{True}$]”。输出行中不允许有任何其他文本。", "solution": "该问题要求对监督学习的“没有免费的午餐”（NFL）定理的一个核心原则进行经验性验证。该定理指出，在有限域上对所有可能的目标函数进行平均时，没有任何一种学习算法优于其他任何算法。我们将通过比较两种特定的学习算法 $A_1$ 和 $A_2$，并对它们的性能差异进行假设检验，来实现一个统计实验来测试这一原则。\n\n其理论基础是关于有限输入空间 $X$ 上监督学习的NFL定理。如果我们考虑在所有可能的目标函数 $f: X \\to \\{0,1\\}$ 的集合上采用均匀概率分布，那么对于任何学习算法，在未见点集 $U \\subset X$ 上的预期泛化准确率都是相同的。设 $\\mathcal{A}$ 是所有学习算法的空间， $S$ 是训练集。对于任意两种算法 $A_1, A_2 \\in \\mathcal{A}$，该定理意味着：\n$$\n\\mathbb{E}_{f \\sim \\text{Unif}}[\\text{Acc}_U(A_1(S, f|_S))] = \\mathbb{E}_{f \\sim \\text{Unif}}[\\text{Acc}_U(A_2(S, f|_S))]\n$$\n其中 $\\text{Acc}_U(h) = \\frac{1}{|U|} \\sum_{x \\in U} \\mathbf{1}\\{h(x) = f(x)\\}$ 是一个假设 $h$ 在未见集 $U$ 上的准确率。这直接导出了它们的准确率预期差异为零的结论：\n$$\n\\mu_d = \\mathbb{E}_{f \\sim \\text{Unif}}[\\text{Acc}_U(A_1) - \\text{Acc}_U(A_2)] = 0\n$$\n\n实验设计将这个理论结果转化为一个统计原假设 $H_0: \\mu_d = 0$，我们将其与备择假设 $H_1: \\mu_d \\neq 0$ 进行检验。该实验由以下几个部分定义：\n1.  **输入空间**：域是所有固定长度 $m$ 的二进制向量的集合 $X = \\{0,1\\}^m$。为计算方便，我们用整数 $i \\in \\{0, 1, \\dots, 2^m-1\\}$ 按字典序表示 $X$ 的元素。\n2.  **数据划分**：空间 $X$ 被划分为一个大小为 $n$ 的固定训练集 $S$（由字典序中的前 $n$ 个点组成）和一个未见集 $U = X \\setminus S$。\n3.  **任务生成**：一个任务由一个目标函数 $f: X \\to \\{0,1\\}$ 定义，由一个二进制向量 $y \\in \\{0,1\\}^{|X|}$ 表示。对于给定数量的任务 $k$，我们生成 $k$ 个这样的函数。如果 $k$ 小于可能函数的总数 $2^{|X|}$，我们独立且均匀地对它们进行采样，这等同于从 $\\mathrm{Bernoulli}(1/2)$ 分布中抽取每个标签 $y_i$。如果 $k=2^{|X|}$，我们对所有可能的函数进行穷举。\n4.  **学习算法**：\n    -   **$A_1$（1-最近邻）**：对于任意点 $x \\in X$，该算法在汉明距离下找到 $S$ 中与 $x$ 最近的点 $x_s$。预测值为该邻居的标签 $f(x_s)$。通过选择字典序最小的邻居来打破平局。\n    -   **$A_2$（经验多数）**：该算法确定训练集 $S$ 上的多数标签（0或1）。然后它对 $X$ 中的所有点都预测这个相同的标签。如果训练标签中出现平局，则默认预测 $0$。\n\n对于 $k$ 个生成的任务中的每一个，我们都在训练数据 $(S, f|_S)$ 上训练这两种算法，并计算它们在未见数据 $U$ 上的各自准确率 $a_1$ 和 $a_2$。任务 $t$ 的配对差异为 $d_t = a_{1,t} - a_{2,t}$。\n\n统计分析是对 $k$ 个差异的样本 $\\{d_t\\}_{t=1}^k$ 进行的。我们使用配对学生t检验。检验统计量计算如下：\n$$\nT = \\frac{\\bar{d}}{s_d / \\sqrt{k}}\n$$\n其中 $\\bar{d}$ 是差异的样本均值， $s_d$ 是经过贝塞尔校正的样本标准差（即使用 $k-1$ 作为分母）。在原假设下，统计量 $T$ 服从自由度为 $k-1$ 的学生t分布。双边p值的计算公式为 $p = 2 \\cdot \\mathrm{sf}(|T|)$，其中 $\\mathrm{sf}$ 是t分布的生存函数。根据问题规范，如果 $k  2$ 或者 $s_d=0$，则p值取为 $1$。如果得到的p值大于指定的显著性水平 $\\alpha$，我们不拒绝原假设 $H_0$。\n\n实现过程首先为每个测试用例 $(m, n, k, \\text{seed}, \\alpha)$ 初始化参数。然后生成输入空间 $X$ 的二进制表示，并将其划分为 $S$ 和 $U$。一个循环迭代 $k$ 次，每次都生成一个目标函数，训练两个学习器，评估它们在 $U$ 上的准确率，并计算差异。在收集完所有 $k$ 个差异后，执行t检验以获得一个p值，然后将其与 $\\alpha$ 进行比较，以决定是否拒绝原假设。最终输出是一个布尔值，指示每个测试用例的这一决策。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import t\n\ndef solve():\n    \"\"\"\n    Implements the experimental pipeline to test the No Free Lunch theorem.\n    For each test case, it compares two learning algorithms by performing a\n    paired t-test on their performance difference over a set of synthetic tasks.\n    \"\"\"\n    test_cases = [\n        (5, 8, 64, 12345, 0.05),\n        (5, 8, 1, 7, 0.05),\n        (3, 2, 256, 0, 0.05),\n        (6, 10, 100, 2024, 0.01),\n    ]\n\n    results = []\n    for m, n, k, seed, alpha in test_cases:\n        num_X = 2**m\n        num_U = num_X - n\n\n        # Pre-compute binary representations for the input space X\n        X_bin = np.zeros((num_X, m), dtype=np.int8)\n        for i in range(num_X):\n            binary_repr = np.binary_repr(i, width=m)\n            X_bin[i] = np.array(list(binary_repr), dtype=np.int8)\n\n        S_bin = X_bin[:n]\n        U_bin = X_bin[n:]\n\n        differences = []\n\n        is_exhaustive = (k == 2**num_X)\n        if not is_exhaustive:\n            rng = np.random.default_rng(seed)\n\n        for task_idx in range(k):\n            # Step 1: Generate a target function y\n            if is_exhaustive:\n                # Exhaustive enumeration of all possible labelings\n                y_repr = np.binary_repr(task_idx, width=num_X)\n                y = np.array(list(y_repr), dtype=np.int8)\n            else:\n                # Random sampling of labelings\n                y = rng.integers(0, 2, size=num_X, dtype=np.int8)\n\n            y_train = y[:n]\n            y_unseen = y[n:]\n\n            # Step 2: Run Learner A1 (1-NN)\n            h1_unseen = np.zeros(num_U, dtype=np.int8)\n            for i in range(num_U):\n                # Calculate Hamming distances from the current unseen point to all training points\n                distances = np.sum(S_bin != U_bin[i], axis=1)\n                # Find the index of the nearest neighbor. np.argmin breaks ties by first occurrence.\n                best_s_idx = np.argmin(distances)\n                h1_unseen[i] = y_train[best_s_idx]\n\n            # Step 3: Run Learner A2 (Empirical Majority)\n            num_ones = np.sum(y_train)\n            if num_ones > n / 2:\n                h2_pred = 1\n            else:  # Handles both minority and tie cases, predicting 0\n                h2_pred = 0\n            h2_unseen = np.full(num_U, h2_pred, dtype=np.int8)\n\n            # Step 4: Compute accuracies and their difference\n            # check if num_U is zero to avoid division by zero\n            if num_U > 0:\n                acc1 = np.sum(h1_unseen == y_unseen) / num_U\n                acc2 = np.sum(h2_unseen == y_unseen) / num_U\n                diff = acc1 - acc2\n            else:\n                diff = 0.0\n\n            differences.append(diff)\n\n        # Step 5: Perform paired t-test\n        diff_arr = np.array(differences)\n        \n        # As per problem, if k  2, or s_d is 0, p-value is 1.\n        # np.std with ddof=1 produces NaN for k=1, so check k  2 first.\n        s_d = 0.0\n        if k >= 2:\n            s_d = np.std(diff_arr, ddof=1)\n\n        if k  2 or s_d == 0:\n            p_value = 1.0\n        else:\n            d_bar = np.mean(diff_arr)\n            t_stat = d_bar / (s_d / np.sqrt(k))\n            df = k - 1\n            # Two-sided p-value\n            p_value = 2 * t.sf(np.abs(t_stat), df)\n\n        # Step 6: Make decision\n        # Do not reject H0 if p > alpha\n        decision = p_value > alpha\n        results.append(decision)\n\n    # Format and print the final output\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3153410"}]}