{"hands_on_practices": [{"introduction": "选择损失函数不仅仅是一个技术细节；它定义了我们学习算法的目标。本练习将说明，用于训练的损失函数（例如，绝对误差 $\\ell_1$）与用于评估的损失函数（例如，平方误差 $\\ell_2$）之间的不匹配，即使在拥有无限数据的情况下，也可能导致模型次优。通过解决这个问题 [@problem_id:3123205]，你将发现损失函数与均值、中位数等基本统计特性之间的深刻联系，并量化由这种不对齐引起的性能差距——即“超额风险”。", "problem": "考虑从分布 $Y=\\mu+X$ 中抽取的独立同分布 (i.i.d.) 观测值 $\\{Y_i\\}_{i=1}^{n}$，其中 $X$ 服从率参数为 $\\lambda>0$ 的指数分布。您考虑常数预测器的假设类别 $\\{f_{\\theta}:\\theta\\in\\mathbb{R}\\}$，其中对于所有输入，$f_{\\theta}(x)=\\theta$。训练是通过在绝对损失 $\\ell_{1}(y,\\theta)=|y-\\theta|$ 下最小化经验风险来进行的，也就是说，您选择一个经验风险最小化器 $\\hat{\\theta}_{n}\\in\\arg\\min_{\\theta}\\hat{R}_{\\ell_{1}}(\\theta)$，其中 $\\hat{R}_{\\ell_{1}}(\\theta)=\\frac{1}{n}\\sum_{i=1}^{n}|Y_{i}-\\theta|$。然而，评估是在平方损失 $\\ell_{2}(y,\\theta)=(y-\\theta)^{2}$ 下进行的，其期望风险为 $R_{\\ell_{2}}(\\theta)=\\mathbb{E}[(Y-\\theta)^{2}]$。\n\n仅从 $\\ell_{1}$ 和 $\\ell_{2}$ 的经验风险和期望风险的定义，以及期望和分位数的基本性质出发，在 $n\\to\\infty$ 的大样本极限下，完成以下任务：\n1. 论证在所选的假设类别内，经验 $\\ell_{1}$ 最小化器收敛到哪个总体参数，以及哪个总体参数能最小化期望 $\\ell_{2}$ 风险。\n2. 将用 $\\ell_{1}$ 训练的预测器的渐近超额 $\\ell_{2}$ 风险定义为 $\\mathcal{E}=R_{\\ell_{2}}(\\theta_{\\ell_{1}}^{\\star})-\\inf_{\\theta\\in\\mathbb{R}}R_{\\ell_{2}}(\\theta)$，其中 $\\theta_{\\ell_{1}}^{\\star}$ 是 $\\hat{\\theta}_{n}$ 在 $n\\to\\infty$ 时的几乎必然极限。推导一个仅用 $\\lambda$ 表示的 $\\mathcal{E}$ 的闭式表达式。\n3. 用总体统计量来陈述使 $\\mathcal{E}=0$ 的对齐条件，并讨论对于给定的指数平移模型，此条件是否可以成立。\n\n提供 $\\mathcal{E}$ 的精确闭式表达式作为您的最终答案。不要对结果进行近似或四舍五入。", "solution": "该问题要求分析当一个模型使用一种损失函数进行训练，但使用另一种损失函数进行评估时出现的性能错配。具体来说，我们考虑一个常数预测器 $f_{\\theta}(x) = \\theta$，它通过最小化经验 $\\ell_{1}$ 风险（绝对损失）进行训练，并根据其渐近期望 $\\ell_{2}$ 风险（平方损失）进行评估。数据 $\\{Y_i\\}_{i=1}^{n}$ 是来自 $Y = \\mu + X$ 的独立同分布样本，其中 $X$ 服从率参数为 $\\lambda > 0$ 的指数分布。\n\n首先，我们解决问题的三个部分：确定相关的总体参数，推导渐近超额风险，以及讨论对齐条件。\n\n1. 用于 $\\ell_{1}$ 和 $\\ell_{2}$ 风险最小化的总体参数\n\n训练过程涉及找到 $\\hat{\\theta}_{n} \\in \\arg\\min_{\\theta} \\hat{R}_{\\ell_{1}}(\\theta)$，其中经验风险为 $\\hat{R}_{\\ell_{1}}(\\theta) = \\frac{1}{n}\\sum_{i=1}^{n}|Y_{i}-\\theta|$。统计学中的一个基本结果是，使与一组点 $\\{Y_i\\}_{i=1}^n$ 的绝对差之和最小化的 $\\theta$ 值是这些点的样本中位数。因此，$\\hat{\\theta}_{n} = \\text{median}(\\{Y_i\\}_{i=1}^n)$。\n当样本大小 $n$ 趋于无穷大时，样本中位数几乎必然收敛于总体中位数。问题将 $\\theta_{\\ell_{1}}^{\\star}$ 定义为此极限。因此，\n$$ \\theta_{\\ell_{1}}^{\\star} = \\lim_{n\\to\\infty} \\hat{\\theta}_{n} = \\text{median}(Y) $$\n评估是使用期望 $\\ell_{2}$ 风险 $R_{\\ell_{2}}(\\theta) = \\mathbb{E}[(Y-\\theta)^{2}]$ 进行的。为了找到最小化此风险的参数 $\\theta$，我们可以对 $R_{\\ell_{2}}(\\theta)$ 关于 $\\theta$ 求导，并将导数设为零。\n$$ \\frac{d}{d\\theta}R_{\\ell_{2}}(\\theta) = \\frac{d}{d\\theta}\\mathbb{E}[(Y-\\theta)^{2}] = \\mathbb{E}\\left[\\frac{\\partial}{\\partial\\theta}(Y-\\theta)^{2}\\right] = \\mathbb{E}[-2(Y-\\theta)] = -2(\\mathbb{E}[Y] - \\theta) $$\n将此导数设为零得出 $\\theta = \\mathbb{E}[Y]$。二阶导数为 $\\frac{d^2}{d\\theta^2}R_{\\ell_{2}}(\\theta) = 2 > 0$，证实了 $\\theta$ 的这个值确实是一个最小化子。在期望平方损失下的最优参数是总体均值。我们把这个最小化子记为 $\\theta_{\\ell_2}^\\star$:\n$$ \\theta_{\\ell_2}^\\star = \\arg\\inf_{\\theta \\in \\mathbb{R}} R_{\\ell_2}(\\theta) = \\mathbb{E}[Y] $$\n总而言之，经验 $\\ell_{1}$ 最小化器收敛于总体中位数，而期望 $\\ell_{2}$ 风险由总体均值最小化。\n\n2. 渐近超额 $\\ell_{2}$ 风险的推导\n\n渐近超额 $\\ell_{2}$ 风险 $\\mathcal{E}$ 衡量了在 $\\ell_2$ 评估的背景下使用 $\\ell_{1}$ 最优参数 $\\theta_{\\ell_1}^\\star$ 所带来的惩罚。它被定义为：\n$$ \\mathcal{E} = R_{\\ell_{2}}(\\theta_{\\ell_{1}}^{\\star}) - \\inf_{\\theta\\in\\mathbb{R}}R_{\\ell_{2}}(\\theta) = R_{\\ell_{2}}(\\theta_{\\ell_{1}}^{\\star}) - R_{\\ell_2}(\\theta_{\\ell_2}^\\star) $$\n使用恒等式 $R_{\\ell_2}(\\theta) = \\mathbb{E}[(Y-\\theta)^2] = \\text{Var}(Y) + (\\mathbb{E}[Y]-\\theta)^2$，我们可以将超额风险表示为：\n$$ \\mathcal{E} = \\left(\\text{Var}(Y) + (\\mathbb{E}[Y]-\\theta_{\\ell_{1}}^{\\star})^2\\right) - \\left(\\text{Var}(Y) + (\\mathbb{E}[Y]-\\theta_{\\ell_{2}}^{\\star})^2\\right) $$\n由于 $\\theta_{\\ell_2}^\\star = \\mathbb{E}[Y]$，第二项得到化简，我们得到：\n$$ \\mathcal{E} = (\\mathbb{E}[Y] - \\theta_{\\ell_{1}}^{\\star})^2 = (\\mathbb{E}[Y] - \\text{median}(Y))^2 $$\n为了找到一个闭式表达式，我们必须计算指定分布 $Y = \\mu + X$ 的均值和中位数，其中 $X \\sim \\text{Exp}(\\lambda)$。$X$ 的概率密度函数为 $f_X(x) = \\lambda \\exp(-\\lambda x)$（对于 $x \\ge 0$）。\n\n$Y$ 的均值是：\n$$ \\mathbb{E}[Y] = \\mathbb{E}[\\mu + X] = \\mu + \\mathbb{E}[X] $$\n率参数为 $\\lambda$ 的指数分布的均值是 $\\mathbb{E}[X] = \\frac{1}{\\lambda}$。因此，\n$$ \\mathbb{E}[Y] = \\mu + \\frac{1}{\\lambda} $$\n$Y$ 的中位数，我们记为 $m_Y$，是满足 $P(Y \\le m_Y) = 1/2$ 的值。\n$$ P(Y \\le m_Y) = P(\\mu + X \\le m_Y) = P(X \\le m_Y - \\mu) = \\int_{0}^{m_Y - \\mu} \\lambda \\exp(-\\lambda x) dx = 1 - \\exp(-\\lambda(m_Y - \\mu)) $$\n将此概率设为 $1/2$：\n$$ 1 - \\exp(-\\lambda(m_Y - \\mu)) = \\frac{1}{2} \\implies \\exp(-\\lambda(m_Y - \\mu)) = \\frac{1}{2} $$\n对两边取自然对数：\n$$ -\\lambda(m_Y - \\mu) = \\ln\\left(\\frac{1}{2}\\right) = -\\ln(2) \\implies m_Y - \\mu = \\frac{\\ln(2)}{\\lambda} $$\n因此，$Y$ 的中位数是：\n$$ \\text{median}(Y) = m_Y = \\mu + \\frac{\\ln(2)}{\\lambda} $$\n现在我们可以通过将均值和中位数代入我们的表达式来计算超额风险 $\\mathcal{E}$：\n$$ \\mathcal{E} = \\left( \\left(\\mu + \\frac{1}{\\lambda}\\right) - \\left(\\mu + \\frac{\\ln(2)}{\\lambda}\\right) \\right)^2 = \\left( \\frac{1}{\\lambda} - \\frac{\\ln(2)}{\\lambda} \\right)^2 $$\n这可以化简为仅用 $\\lambda$ 表示的最终闭式表达式：\n$$ \\mathcal{E} = \\frac{(1 - \\ln(2))^2}{\\lambda^2} $$\n\n3. 对齐条件\n\n对齐条件是使超额风险 $\\mathcal{E}$ 为零的条件。根据我们的推导，$\\mathcal{E} = (\\mathbb{E}[Y] - \\text{median}(Y))^2$。这个量为零当且仅当：\n$$ \\mathbb{E}[Y] = \\text{median}(Y) $$\n用总体统计量的术语来说，当总体均值等于总体中位数时，就会发生对齐。在这种情况下，训练损失函数 ($\\ell_1$) 的最优参数与评估损失函数 ($\\ell_2$) 的最优参数相同，因此不会因为错配而导致性能下降。\n\n对于给定的指数平移模型，此条件将要求：\n$$ \\mu + \\frac{1}{\\lambda} = \\mu + \\frac{\\ln(2)}{\\lambda} $$\n由于 $\\lambda > 0$，这可以化简为 $1 = \\ln(2)$。然而，这是一个错误的陈述，因为 $\\ln(2) \\approx 0.6931$。指数分布是一种偏态分布，其均值和中位数不重合。具体来说，由于 $1 > \\ln(2)$，对于任何 $\\lambda > 0$，均值总是大于中位数。因此，对于这个模型，对齐条件永远不能成立，并且渐近超额风险 $\\mathcal{E}$ 总是严格为正。", "answer": "$$\n\\boxed{\\frac{\\left(1 - \\ln(2)\\right)^2}{\\lambda^2}}\n$$", "id": "3123205"}, {"introduction": "现实世界的数据往往是杂乱的，可能无法完美代表我们希望对其进行预测的目标总体。本实践探讨了一种称为“数据集偏移”的常见情景，其中训练数据的类别平衡与目标总体不同。你将学习到，在此类数据集上朴素地计算经验风险会得到对真实泛化误差的有偏估计 [@problem_id:3123242]。本练习的核心是设计并分析一种“重要性加权”方案，这是一种强大的技术，可以校正这种偏差，从而获得对真实风险的准确估计。", "problem": "考虑一个标签为 $Y \\in \\{0,1\\}$ 的二元分类任务和一个固定的分类器 $h$。损失函数为0-1损失 $\\ell(h(X),Y) = \\mathbf{1}\\{h(X) \\neq Y\\}$。我们所关注的总体是平衡的，即目标标签分布满足 $\\mathbb{P}(Y=1)=\\mathbb{P}(Y=0)=\\frac{1}{2}$。然而，训练样本是从一个不平衡的病例-对照设计中抽取的，其中标签的抽样分布为 $\\mathbb{P}_{\\text{sample}}(Y=1)=0.8$ 和 $\\mathbb{P}_{\\text{sample}}(Y=0)=0.2$。假设分类器的类条件错误率在总体和样本中是不变的：当 $Y=1$ 时，错分概率为 $\\alpha=0.1$，当 $Y=0$ 时，错分概率为 $\\beta=0.3$。假设在抽样分布下，观测值是独立同分布的 (i.i.d.)，并且在给定 $Y$ 的条件下，不同样本的损失是独立的伯努利随机变量，当 $Y=1$ 时参数为 $\\alpha$，当 $Y=0$ 时参数为 $\\beta$。样本大小为 $n=1000$。\n\n仅使用期望风险和经验风险的基本定义以及重要性加权原理，完成以下任务：\n\n(a) 定义在平衡目标总体下的期望风险，并用 $\\alpha$ 和 $\\beta$ 计算其值。\n\n(b) 定义朴素经验风险的期望值，该值通过对不平衡样本上的 $\\ell(h(X),Y)$ 进行平均计算（不进行任何重加权），并用给定参数计算其值。\n\n(c) 设计一个基于类的重加权方案，当应用于不平衡样本时，能够产生对平衡总体风险的无偏估计。从第一性原理出发，证明其无偏性。\n\n(d) 在不平衡抽样分布下，推导重加权经验风险估计量的方差，然后根据给定的参数和 $n=1000$ 计算其数值。\n\n将最终数值答案四舍五入到四位有效数字。以科学记数法的十进制形式表示最终答案。在答案的任何地方都不要使用百分号。", "solution": "本问题探讨了总体风险（泛化误差）与经验风险之间的关系，特别是在训练样本分布与目标总体分布不同的数据集偏移（dataset shift）背景下。我们将使用重要性加权原理来纠正这种不匹配。\n\n令 $P$ 表示目标（平衡）数据生成分布，令 $P_{\\text{sample}}$ 表示抽样（不平衡）分布。损失函数是0-1损失，$\\ell(h(X), Y) = \\mathbf{1}\\{h(X) \\neq Y\\}$。给定的类条件错误率为 $\\alpha = \\mathbb{P}(h(X) \\neq 1 | Y=1) = 0.1$ 和 $\\beta = \\mathbb{P}(h(X) \\neq 0 | Y=0) = 0.3$。假设这些错误率相对于分布是不变的，即对于 $y \\in \\{0,1\\}$，有 $\\mathbb{P}_{\\text{sample}}(h(X) \\neq y | Y=y) = \\mathbb{P}(h(X) \\neq y | Y=y)$。\n\n(a) 平衡目标总体下的期望风险。\n\n期望风险，或称泛化误差，$R(h)$，是关于目标总体分布 $P(X,Y)$ 的期望损失。\n$$R(h) = \\mathbb{E}_{P(X,Y)}[\\ell(h(X), Y)]$$\n使用全期望定律，我们可以对标签 $Y$ 取条件：\n$$R(h) = \\sum_{y \\in \\{0,1\\}} \\mathbb{P}(Y=y) \\mathbb{E}_{P(X|Y=y)}[\\ell(h(X), y) | Y=y]$$\n这可以简化为：\n$$R(h) = \\mathbb{P}(Y=1) \\mathbb{P}(h(X) \\neq 1 | Y=1) + \\mathbb{P}(Y=0) \\mathbb{P}(h(X) \\neq 0 | Y=0)$$\n在平衡目标总体中，$\\mathbb{P}(Y=1) = \\mathbb{P}(Y=0) = \\frac{1}{2}$。代入给定值：\n$$R(h) = \\left(\\frac{1}{2}\\right) \\alpha + \\left(\\frac{1}{2}\\right) \\beta = \\frac{1}{2}(\\alpha + \\beta)$$\n$$R(h) = \\frac{1}{2}(0.1 + 0.3) = \\frac{1}{2}(0.4) = 0.2$$\n\n(b) 朴素经验风险的期望值。\n\n朴素经验风险是在从 $P_{\\text{sample}}$ 中抽取的、大小为 $n$ 的不平衡样本上计算的平均损失。\n$$\\hat{R}_{\\text{naive}}(h) = \\frac{1}{n} \\sum_{i=1}^n \\ell(h(X_i), Y_i), \\quad \\text{其中 } (X_i, Y_i) \\sim P_{\\text{sample}}$$\n该估计量的期望值是关于抽样分布 $P_{\\text{sample}}$ 计算的。根据期望的线性和样本的独立同分布性质：\n$$\\mathbb{E}_{P_{\\text{sample}}}[\\hat{R}_{\\text{naive}}(h)] = \\mathbb{E}_{P_{\\text{sample}}} \\left[ \\frac{1}{n} \\sum_{i=1}^n \\ell(h(X_i), Y_i) \\right] = \\mathbb{E}_{P_{\\text{sample}}}[\\ell(h(X), Y)]$$\n这就是在抽样分布下的期望风险。再次应用全期望定律，但这次使用 $Y$ 的抽样概率：\n$$\\mathbb{E}_{P_{\\text{sample}}}[\\ell(h(X), Y)] = \\mathbb{P}_{\\text{sample}}(Y=1) \\mathbb{P}(h(X) \\neq 1 | Y=1) + \\mathbb{P}_{\\text{sample}}(Y=0) \\mathbb{P}(h(X) \\neq 0 | Y=0)$$\n我们已知 $\\mathbb{P}_{\\text{sample}}(Y=1) = 0.8$ 且 $\\mathbb{P}_{\\text{sample}}(Y=0) = 0.2$。\n$$\\mathbb{E}_{P_{\\text{sample}}}[\\hat{R}_{\\text{naive}}(h)] = (0.8)\\alpha + (0.2)\\beta = (0.8)(0.1) + (0.2)(0.3) = 0.08 + 0.06 = 0.14$$\n\n(c) 用于无偏估计的重加权方案。\n\n为了从 $P_{\\text{sample}}$ 抽取的样本中获得目标风险 $R(h)$ 的无偏估计，我们使用重要性加权。一个观测值 $(x,y)$ 的权重是其在目标分布下的概率与在抽样分布下的概率之比：$w(x,y) = \\frac{P(x,y)}{P_{\\text{sample}}(x,y)}$。\n由于条件分布 $P(X|Y)$ 是不变的，我们有 $P(x,y) = P(y) P(x|y)$ 和 $P_{\\text{sample}}(x,y) = P_{\\text{sample}}(y) P(x|y)$。权重简化为仅依赖于类别标签 $y$：\n$$w(y) = \\frac{P(y) P(x|y)}{P_{\\text{sample}}(y) P(x|y)} = \\frac{P(y)}{P_{\\text{sample}}(y)}$$\n我们定义两个权重，每个类别一个：\n$Y=1$ 的权重：$w_1 = w(1) = \\frac{\\mathbb{P}(Y=1)}{\\mathbb{P}_{\\text{sample}}(Y=1)} = \\frac{0.5}{0.8} = \\frac{5}{8} = 0.625$。\n$Y=0$ 的权重：$w_0 = w(0) = \\frac{\\mathbb{P}(Y=0)}{\\mathbb{P}_{\\text{sample}}(Y=0)} = \\frac{0.5}{0.2} = \\frac{5}{2} = 2.5$。\n重加权经验风险估计量 $\\hat{R}_{\\text{rw}}(h)$ 为：\n$$\\hat{R}_{\\text{rw}}(h) = \\frac{1}{n} \\sum_{i=1}^n w(Y_i) \\ell(h(X_i), Y_i)$$\n为了证明其无偏性，我们计算它关于抽样分布 $P_{\\text{sample}}$ 的期望：\n$$\\mathbb{E}_{P_{\\text{sample}}}[\\hat{R}_{\\text{rw}}(h)] = \\mathbb{E}_{P_{\\text{sample}}} \\left[ \\frac{1}{n} \\sum_{i=1}^n w(Y_i) \\ell(h(X_i), Y_i) \\right]$$\n$$= \\mathbb{E}_{P_{\\text{sample}}}[w(Y) \\ell(h(X), Y)]$$\n使用全期望定律：\n$$= \\sum_{y \\in \\{0,1\\}} \\mathbb{P}_{\\text{sample}}(Y=y) \\mathbb{E}_{P_{\\text{sample}}(X|Y=y)}[w(y) \\ell(h(X), y) | Y=y]$$\n因为给定 $y$ 时，$w(y)$ 是常数：\n$$= \\sum_{y \\in \\{0,1\\}} \\mathbb{P}_{\\text{sample}}(Y=y) w(y) \\mathbb{E}_{P(X|Y=y)}[\\ell(h(X), y) | Y=y]$$\n代入 $w(y) = \\frac{\\mathbb{P}(Y=y)}{\\mathbb{P}_{\\text{sample}}(Y=y)}$：\n$$= \\sum_{y \\in \\{0,1\\}} \\mathbb{P}_{\\text{sample}}(Y=y) \\frac{\\mathbb{P}(Y=y)}{\\mathbb{P}_{\\text{sample}}(Y=y)} \\mathbb{P}(h(X) \\neq y | Y=y)$$\n$$= \\sum_{y \\in \\{0,1\\}} \\mathbb{P}(Y=y) \\mathbb{P}(h(X) \\neq y | Y=y)$$\n这正是 (a) 部分中目标总体风险 $R(h)$ 的定义。因此，该估计量是无偏的：$\\mathbb{E}_{P_{\\text{sample}}}[\\hat{R}_{\\text{rw}}(h)] = R(h)$。\n\n(d) 重加权经验风险估计量的方差。\n\n令 $Z_i = w(Y_i) \\ell(h(X_i), Y_i)$。估计量为 $\\hat{R}_{\\text{rw}}(h) = \\frac{1}{n} \\sum_{i=1}^n Z_i$。由于样本 $(X_i, Y_i)$ 是从 $P_{\\text{sample}}$ 中抽取的独立同分布样本，随机变量 $Z_i$ 也是独立同分布的。\n估计量的方差是：\n$$\\text{Var}(\\hat{R}_{\\text{rw}}(h)) = \\text{Var}\\left(\\frac{1}{n} \\sum_{i=1}^n Z_i\\right) = \\frac{1}{n^2} \\sum_{i=1}^n \\text{Var}(Z_i) = \\frac{1}{n} \\text{Var}(Z_1)$$\n单个项 $Z_1$ 的方差由 $\\text{Var}(Z_1) = \\mathbb{E}[Z_1^2] - (\\mathbb{E}[Z_1])^2$ 给出。\n从 (c) 部分我们知道 $\\mathbb{E}[Z_1] = \\mathbb{E}_{P_{\\text{sample}}}[w(Y) \\ell(h(X), Y)] = R(h) = 0.2$。\n现在我们计算在抽样分布 $P_{\\text{sample}}$ 下的二阶矩 $\\mathbb{E}[Z_1^2]$：\n$$\\mathbb{E}[Z_1^2] = \\mathbb{E}_{P_{\\text{sample}}}[(w(Y) \\ell(h(X), Y))^2] = \\mathbb{E}_{P_{\\text{sample}}}[w(Y)^2 \\ell(h(X), Y)^2]$$\n由于损失函数 $\\ell$ 是一个指示函数 ($\\mathbf{1}\\{\\cdot\\}$)，其值要么是 $0$ 要么是 $1$。因此，$\\ell^2 = \\ell$。\n$$\\mathbb{E}[Z_1^2] = \\mathbb{E}_{P_{\\text{sample}}}[w(Y)^2 \\ell(h(X), Y)]$$\n应用全期望定律：\n$$\\mathbb{E}[Z_1^2] = \\mathbb{P}_{\\text{sample}}(Y=1) w_1^2 \\mathbb{P}(h(X) \\neq 1|Y=1) + \\mathbb{P}_{\\text{sample}}(Y=0) w_0^2 \\mathbb{P}(h(X) \\neq 0|Y=0)$$\n$$= \\mathbb{P}_{\\text{sample}}(Y=1) w_1^2 \\alpha + \\mathbb{P}_{\\text{sample}}(Y=0) w_0^2 \\beta$$\n代入已知值：\n$$\\mathbb{E}[Z_1^2] = (0.8)(0.625)^2(0.1) + (0.2)(2.5)^2(0.3)$$\n$$= (0.8)(0.390625)(0.1) + (0.2)(6.25)(0.3)$$\n$$= 0.03125 + 0.375 = 0.40625$$\n现在我们计算 $\\text{Var}(Z_1)$：\n$$\\text{Var}(Z_1) = \\mathbb{E}[Z_1^2] - (\\mathbb{E}[Z_1])^2 = 0.40625 - (0.2)^2 = 0.40625 - 0.04 = 0.36625$$\n最后，当 $n=1000$ 时，重加权估计量的方差为：\n$$\\text{Var}(\\hat{R}_{\\text{rw}}(h)) = \\frac{\\text{Var}(Z_1)}{n} = \\frac{0.36625}{1000} = 0.00036625$$\n四舍五入到四位有效数字，并用科学记数法表示：\n$$0.00036625 = 3.6625 \\times 10^{-4} \\approx 3.663 \\times 10^{-4}$$", "answer": "$$\\boxed{3.663 \\times 10^{-4}}$$", "id": "3123242"}, {"introduction": "在实践中，我们永远无法获得无限的数据，因此我们对模型性能的估计总是存在随机性。这最后一个练习旨在解决一个关键任务：在使用训练/验证集分割法评估模型时，量化这种不确定性。你将探索变异性如何同时源于验证集的有限规模（“分割内部”方差）和数据分割本身的随机性（“分割之间”方差） [@problem_id:3123300]。通过应用全方差定律，你将掌握一种稳健的方法来为真实期望风险构建置信区间，从而更完整、更真实地描绘模型的性能。", "problem": "一个二元分类模型在同一个独立同分布数据集的重复随机训练/验证集划分上进行训练。对于每个随机种子 $s \\in \\{1,\\dots,k\\}$，我们构建一个训练集，并在一个大小为 $n_{\\mathrm{val}}$ 的验证集上评估模型，得到一个验证集经验风险（平均0-1损失），记为 $\\hat{R}_{s}$。假设在不同种子下，$\\hat{R}_{s}$ 是同一数据生成机制的独立实现，并且每个 $\\hat{R}_{s}$ 都是期望（总体）风险 $R$ 的无偏估计量。目标是估计 $R$ 并量化不确定性，该不确定性需要同时考虑不同划分间的变异性（划分间变异性）和有限验证样本量带来的变异性（划分内变异性）。\n\n您可以假设：(i) 不同样本的验证损失是独立的伯努利随机变量，其成功概率等于该训练模型真实的误分类概率；(ii) 中心极限定理（CLT）适用于跨种子的平均值。\n\n在一次实验中，使用了 $k=8$ 个种子，每个种子的验证集大小为 $n_{\\mathrm{val}}=5000$，观测到的验证集经验风险为：\n$0.158,\\; 0.171,\\; 0.165,\\; 0.162,\\; 0.169,\\; 0.155,\\; 0.166,\\; 0.160$。\n\n从期望风险 $R$ 和经验风险 $\\hat{R}_{s}$ 的核心定义出发，使用全方差公式推导跨种子平均值 $\\bar{R} = \\frac{1}{k}\\sum_{s=1}^{k}\\hat{R}_{s}$ 的一个方差估计量，该估计量要明确地考虑划分间变异性和划分内验证集抽样噪声。然后，在 $\\bar{R}$ 的抽样分布服从自由度为 $\\nu=k-1$ 的学生t分布近似下，计算 $R$ 的95%双侧置信区间的半宽。\n\n将您的最终答案表示为单个十进制数值（仅半宽），并将您的答案四舍五入到四位有效数字。不需要单位。", "solution": "本题的目标是基于在 $k$ 个不同训练/验证集划分上观测到的经验风险 $\\hat{R}_s$，为模型的真实期望风险 $R$ 构建一个置信区间。这个过程需要量化估计的总不确定性。\n\n$\\bar{R} = \\frac{1}{k}\\sum_{s=1}^{k}\\hat{R}_{s}$ 是 $R$ 的一个无偏估计量。其方差为 $\\mathrm{Var}(\\bar{R}) = \\frac{1}{k}\\mathrm{Var}(\\hat{R}_{s})$。\n\n为了理解单个观测值 $\\hat{R}_{s}$ 的方差来源，我们应用全方差公式，以在划分 $s$ 上训练得到的模型 $\\theta_s$ 为条件：\n$$ \\mathrm{Var}(\\hat{R}_{s}) = \\mathrm{E}_{\\theta_s}[\\mathrm{Var}(\\hat{R}_{s} | \\theta_s)] + \\mathrm{Var}_{\\theta_s}(\\mathrm{E}[\\hat{R}_{s} | \\theta_s]) $$\n\n- 第一项 $\\mathrm{E}_{\\theta_s}[\\mathrm{Var}(\\hat{R}_{s} | \\theta_s)]$ 是**划分内方差**。它表示，对于一个固定的模型 $\\theta_s$，其在有限验证集（大小为 $n_{\\mathrm{val}}$）上的经验风险的方差，然后在所有可能的模型（即所有划分）上取平均。这部分方差源于验证集的随机抽样。\n- 第二项 $\\mathrm{Var}_{\\theta_s}(\\mathrm{E}[\\hat{R}_{s} | \\theta_s])$ 是**划分间方差**。$\\mathrm{E}[\\hat{R}_{s} | \\theta_s]$ 是模型 $\\theta_s$ 的真实风险 $R(\\theta_s)$。因此，这一项衡量的是由于训练数据的随机划分不同，导致训练出的模型本身的真实风险 $R(\\theta_s)$ 发生波动的情况。\n\n幸运的是，我们不需要分别估计这两个方差分量。观测到的 $k$ 个经验风险值 $\\{\\hat{R}_1, \\dots, \\hat{R}_k\\}$ 的样本方差 $S^2_{\\hat{R}}$，本身就是对总方差 $\\mathrm{Var}(\\hat{R}_{s})$ 的一个无偏估计：\n$$ S^2_{\\hat{R}} = \\frac{1}{k-1} \\sum_{s=1}^{k} (\\hat{R}_s - \\bar{R})^2 $$\n这个统计量凭经验地捕捉了两种方差来源的综合效应。因此，均值 $\\bar{R}$ 的标准误（Standard Error）可以估计为：\n$$ \\mathrm{SE}(\\bar{R}) = \\sqrt{\\frac{S^2_{\\hat{R}}}{k}} = \\frac{S_{\\hat{R}}}{\\sqrt{k}} $$\n\n**数值计算**\n\n对于给定的 $k=8$ 个观测值 $\\{0.158, 0.171, 0.165, 0.162, 0.169, 0.155, 0.166, 0.160\\}$：\n1.  计算样本均值 $\\bar{R}$：\n    $$ \\bar{R} = \\frac{1.306}{8} = 0.16325 $$\n2.  计算样本方差 $S^2_{\\hat{R}}$：\n    $$ S^2_{\\hat{R}} = \\frac{1}{8-1} \\sum_{s=1}^{8} (\\hat{R}_s - 0.16325)^2 = \\frac{0.0002115}{7} \\approx 3.02143 \\times 10^{-5} $$\n3.  计算标准误 $\\mathrm{SE}(\\bar{R})$：\n    $$ \\mathrm{SE}(\\bar{R}) = \\sqrt{\\frac{3.02143 \\times 10^{-5}}{8}} \\approx 0.0019434 $$\n\n**构建置信区间**\n\n使用自由度为 $\\nu = k-1 = 7$ 的学生t分布，95%置信区间的半宽 $H$ 计算如下：\n$$ H = t_{\\alpha/2, \\nu} \\times \\mathrm{SE}(\\bar{R}) $$\n其中 $\\alpha=0.05$，临界值 $t_{0.025, 7} \\approx 2.3646$。\n$$ H = 2.3646 \\times 0.0019434 \\approx 0.00459523 $$\n四舍五入到四位有效数字，半宽为 $0.004595$。", "answer": "$$\\boxed{0.004595}$$", "id": "3123300"}]}