{"hands_on_practices": [{"introduction": "混杂是因果推断中的一个核心挑战，它可能导致我们观察到的关联与真实的因果效应截然相反，这种现象被称为辛普森悖论。本练习将通过一个具体的数值实例，在潜在结果框架下构造一个辛普森悖论的场景。通过亲手计算和比较边际关联与分层关联，你将深刻理解混杂变量是如何扭曲我们对因果关系的感知的。[@problem_id:3110506]", "problem": "考虑一个二元处理 $A \\in \\{0,1\\}$，一个二元结果 $Y \\in \\{0,1\\}$，以及一个二元预处理协变量（混杂因子）$X \\in \\{0,1\\}$。令 $Y(1)$ 和 $Y(0)$ 分别表示在处理和控制下的潜在结果。假设以下数据生成过程有效：\n\n1. 协变量普遍性：$\\mathbb{P}(X=1)=\\frac{9}{10}$ 和 $\\mathbb{P}(X=0)=\\frac{1}{10}$。\n\n2. 处理分配取决于 $X$，但在给定 $X$ 的情况下不依赖于潜在结果（条件可交换性）。具体而言，$\\mathbb{P}(A=1 \\mid X=1)=\\frac{19}{20}$ 和 $\\mathbb{P}(A=1 \\mid X=0)=\\frac{1}{20}$。同时假设正值性成立且一致性成立，即观测结果满足 $Y=Y(A)$。\n\n3. 潜在结果分布（在 $X$ 的每个层内，处理都是有益的）：\n   - 对于 $X=1$：$Y(1)\\mid X=1 \\sim \\mathrm{Bernoulli}\\!\\left(\\frac{13}{20}\\right)$ 和 $Y(0)\\mid X=1 \\sim \\mathrm{Bernoulli}\\!\\left(\\frac{3}{5}\\right)$。\n   - 对于 $X=0$：$Y(1)\\mid X=0 \\sim \\mathrm{Bernoulli}\\!\\left(\\frac{19}{20}\\right)$ 和 $Y(0)\\mid X=0 \\sim \\mathrm{Bernoulli}\\!\\left(\\frac{9}{10}\\right)$。\n\n你的任务：\n\na) 仅使用概率定律和潜在结果框架（一致性、给定 $X$ 的条件可交换性以及正值性），计算以下期望值：\n- 边际期望 $\\mathbb{E}[Y \\mid A=1]$ 和 $\\mathbb{E}[Y \\mid A=0]$。\n- 对于 $x \\in \\{0,1\\}$ 的条件期望 $\\mathbb{E}[Y \\mid A=1, X=x]$ 和 $\\mathbb{E}[Y \\mid A=0, X=x]$。\n\nb) 定义边际关联对比 $\\Delta_{\\mathrm{marg}} \\equiv \\mathbb{E}[Y \\mid A=1]-\\mathbb{E}[Y \\mid A=0]$ 和层内关联对比 $\\Delta_{x} \\equiv \\mathbb{E}[Y \\mid A=1, X=x]-\\mathbb{E}[Y \\mid A=0, X=x]$（对于 $x \\in \\{0,1\\}$）。精确计算 $\\Delta_{\\mathrm{marg}}$、$\\Delta_{0}$ 和 $\\Delta_{1}$。\n\nc) 使用潜在结果术语和全期望定律，简要解释在此设置中，为什么 $\\Delta_{\\mathrm{marg}}$ 的符号相对于 $\\Delta_{0}$ 和 $\\Delta_{1}$ 的符号可以反转（即，证明由 $X$ 混杂导致的辛普森悖论）。\n\n答案规格：\n- 以单个行矩阵的形式，按顺序提供 $(\\Delta_{\\mathrm{marg}}, \\Delta_{0}, \\Delta_{1})$ 的最终数值结果，表示为精确的简化分数。\n- 无需四舍五入。不要包含任何单位。", "solution": "我们从基本原则出发：潜在结果框架，包括一致性 ($Y=Y(A)$)、给定 $X$ 的条件可交换性 ($A \\perp (Y(0),Y(1)) \\mid X$)、正值性，以及全概率和全期望定律。\n\n第1步：使用贝叶斯法则计算 $\\mathbb{P}(A=1)$、$\\mathbb{P}(A=0)$ 以及处理组内的协变量分布。\n\n给定 $\\mathbb{P}(X=1)=\\frac{9}{10}$ 和 $\\mathbb{P}(X=0)=\\frac{1}{10}$，以及 $\\mathbb{P}(A=1 \\mid X=1)=\\frac{19}{20}$、$\\mathbb{P}(A=1 \\mid X=0)=\\frac{1}{20}$，我们有\n$$\n\\mathbb{P}(A=1)=\\mathbb{P}(A=1 \\mid X=1)\\mathbb{P}(X=1)+\\mathbb{P}(A=1 \\mid X=0)\\mathbb{P}(X=0)\n=\\frac{19}{20}\\cdot \\frac{9}{10}+\\frac{1}{20}\\cdot \\frac{1}{10}\n=\\frac{171}{200}+\\frac{1}{200}\n=\\frac{172}{200}\n=\\frac{43}{50}.\n$$\n因此 $\\mathbb{P}(A=0)=1-\\frac{43}{50}=\\frac{7}{50}$。\n\n现在，\n$$\n\\mathbb{P}(X=1 \\mid A=1)=\\frac{\\mathbb{P}(A=1 \\mid X=1)\\mathbb{P}(X=1)}{\\mathbb{P}(A=1)}\n=\\frac{\\frac{19}{20}\\cdot \\frac{9}{10}}{\\frac{43}{50}}\n=\\frac{\\frac{171}{200}}{\\frac{43}{50}}\n=\\frac{171}{200}\\cdot \\frac{50}{43}\n=\\frac{171}{172},\n$$\n以及\n$$\n\\mathbb{P}(X=0 \\mid A=1)=1-\\frac{171}{172}=\\frac{1}{172}.\n$$\n对于 $A=0$ 类似地，\n$$\n\\mathbb{P}(X=1 \\mid A=0)=\\frac{\\mathbb{P}(A=0 \\mid X=1)\\mathbb{P}(X=1)}{\\mathbb{P}(A=0)}\n=\\frac{\\frac{1}{20}\\cdot \\frac{9}{10}}{\\frac{7}{50}}\n=\\frac{\\frac{9}{200}}{\\frac{7}{50}}\n=\\frac{9}{200}\\cdot \\frac{50}{7}\n=\\frac{9}{28},\n$$\n以及\n$$\n\\mathbb{P}(X=0 \\mid A=0)=1-\\frac{9}{28}=\\frac{19}{28}.\n$$\n\n第2步：计算条件期望 $\\mathbb{E}[Y \\mid A=a, X=x]$。\n\n根据一致性和给定 $X$ 的条件可交换性，我们有 $\\mathbb{E}[Y \\mid A=a, X=x]=\\mathbb{E}[Y(a)\\mid X=x]$。使用给定的潜在结果分布：\n- 对于 $X=1$：$\\mathbb{E}[Y \\mid A=1, X=1]=\\mathbb{E}[Y(1)\\mid X=1]=\\frac{13}{20}$ 和 $\\mathbb{E}[Y \\mid A=0, X=1]=\\mathbb{E}[Y(0)\\mid X=1]=\\frac{3}{5}=\\frac{12}{20}$。\n- 对于 $X=0$：$\\mathbb{E}[Y \\mid A=1, X=0]=\\mathbb{E}[Y(1)\\mid X=0]=\\frac{19}{20}$ 和 $\\mathbb{E}[Y \\mid A=0, X=0]=\\mathbb{E}[Y(0)\\mid X=0]=\\frac{9}{10}=\\frac{18}{20}$。\n\n因此，层内关联对比为\n$$\n\\Delta_{1}=\\mathbb{E}[Y \\mid A=1, X=1]-\\mathbb{E}[Y \\mid A=0, X=1]=\\frac{13}{20}-\\frac{12}{20}=\\frac{1}{20},\n$$\n$$\n\\Delta_{0}=\\mathbb{E}[Y \\mid A=1, X=0]-\\mathbb{E}[Y \\mid A=0, X=0]=\\frac{19}{20}-\\frac{18}{20}=\\frac{1}{20}.\n$$\n\n第3步：通过全期望定律计算边际期望 $\\mathbb{E}[Y \\mid A=1]$ 和 $\\mathbb{E}[Y \\mid A=0]$：\n$$\n\\mathbb{E}[Y \\mid A=1]=\\sum_{x \\in \\{0,1\\}} \\mathbb{E}[Y \\mid A=1, X=x]\\;\\mathbb{P}(X=x \\mid A=1)\n=\\frac{13}{20}\\cdot \\frac{171}{172}+\\frac{19}{20}\\cdot \\frac{1}{172}.\n$$\n精确计算：\n$$\n\\frac{13}{20}\\cdot \\frac{171}{172}=\\frac{2223}{3440},\\qquad \\frac{19}{20}\\cdot \\frac{1}{172}=\\frac{19}{3440},\n$$\n所以\n$$\n\\mathbb{E}[Y \\mid A=1]=\\frac{2223+19}{3440}=\\frac{2242}{3440}=\\frac{1121}{1720}.\n$$\n类似地，\n$$\n\\mathbb{E}[Y \\mid A=0]=\\sum_{x \\in \\{0,1\\}} \\mathbb{E}[Y \\mid A=0, X=x]\\;\\mathbb{P}(X=x \\mid A=0)\n=\\frac{3}{5}\\cdot \\frac{9}{28}+\\frac{9}{10}\\cdot \\frac{19}{28}.\n$$\n精确计算：\n$$\n\\frac{3}{5}\\cdot \\frac{9}{28}=\\frac{27}{140},\\qquad \\frac{9}{10}\\cdot \\frac{19}{28}=\\frac{171}{280},\n$$\n所以\n$$\n\\mathbb{E}[Y \\mid A=0]=\\frac{27}{140}+\\frac{171}{280}=\\frac{54}{280}+\\frac{171}{280}=\\frac{225}{280}=\\frac{45}{56}.\n$$\n\n第4步：计算边际关联对比 $\\Delta_{\\mathrm{marg}}$ 并确认反转。\n$$\n\\Delta_{\\mathrm{marg}}=\\mathbb{E}[Y \\mid A=1]-\\mathbb{E}[Y \\mid A=0]=\\frac{1121}{1720}-\\frac{45}{56}.\n$$\n通分。$1720$ 和 $56$ 的最小公倍数是 $12040$，所以\n$$\n\\frac{1121}{1720}=\\frac{7847}{12040},\\qquad \\frac{45}{56}=\\frac{9675}{12040},\n$$\n因此\n$$\n\\Delta_{\\mathrm{marg}}=\\frac{7847-9675}{12040}=-\\frac{1828}{12040}=-\\frac{457}{3010}.\n$$\n所以，\n$$\n\\Delta_{\\mathrm{marg}}=-\\frac{457}{3010},\\qquad \\Delta_{0}=\\frac{1}{20},\\qquad \\Delta_{1}=\\frac{1}{20}.\n$$\n我们观察到辛普森悖论：在 $X$ 的每个层内，关联对比是正的（处理看起来是有益的），但边际上关联对比是负的（处理看起来是有害的）。\n\n第5步：使用潜在结果解释符号反转。\n根据给定 $X$ 的条件可交换性，有 $\\mathbb{E}[Y \\mid A=a, X=x]=\\mathbb{E}[Y(a)\\mid X=x]$，所以层内对比 $\\Delta_{x}$ 反映了层内的因果对比，并且在这里是正的。然而，边际关联对比通过 $\\mathbb{E}[Y \\mid A=a]=\\sum_{x}\\mathbb{E}[Y(a)\\mid X=x]\\mathbb{P}(X=x \\mid A=a)$ 混合了具有不同基线风险的层。由于处理分配相对于 $X$ 是高度不平衡的（大多数处理组个体有 $X=1$，该层的结果较低；大多数对照组个体有 $X=0$，该层的结果较高），权重 $\\mathbb{P}(X=x \\mid A=a)$ 在 $A=1$ 和 $A=0$ 之间有显著差异。这种差异化的加权压倒了层内的益处，并反转了边际关联的符号。用潜在结果的术语来说，存在由 $X$ 引起的混杂，因此边际上 $A \\not\\perp (Y(0),Y(1))$，并且尽管特定于层的因果效应是有益的，边际关联并不等于因果效应。这正是辛普森悖论，它源于混合了具有不同基线风险的层以及跨层的不均匀处理分配。", "answer": "$$\\boxed{\\begin{pmatrix}-\\frac{457}{3010}  \\frac{1}{20}  \\frac{1}{20}\\end{pmatrix}}$$", "id": "3110506"}, {"introduction": "虽然为混杂变量进行调整是至关重要的，但“调整”并非总是良药，错误地调整变量反而会引入新的偏倚。本练习将引导你通过计算机模拟来探索一种常见的错误——“过度调整偏倚”。你将看到，当我们控制一个位于处理和结果之间因果路径上的变量（即中介变量）时，我们可能会错误地估计处理的总效应，这强调了在选择协变量时进行因果思考的绝对必要性。[@problem_id:3110508]", "problem": "您需要在一个潜在结果框架内，形式化并检验当所选特征受处理影响时，由结果驱动的特征选择如何在估计因果效应时引发过度调整偏误。考虑一个场景，其中包含一个二元处理 $A\\in\\{0,1\\}$，一个受处理影响的中介变量 $M$，以及一个同时受处理和中介变量影响的结果 $Y$。假设没有未测量的混淆，并且 $A$ 的分配是完全随机的。数据生成过程具有加性噪声和线性结构关系。一名实践者执行结果驱动的特征选择，他仅根据特征与合并数据（忽略 $A$）中 $Y$ 的样本相关性，从候选特征集中选择单个特征 $X$，然后通过对 $Y$ 关于 $A$ 和所选 $X$ 进行普通最小二乘法 (OLS) 回归来估计 $A$ 的效应。\n\n从潜在结果框架的核心定义和处理的随机分配出发，您必须推断感兴趣的估计目标，以及调整一个受处理影响的变量所产生的效应。然后，您必须实现一个模拟，以证明当 $X$ 是中介变量时，将在不考虑 $A$ 的情况下从 $Y$ 中选择的 $X$ 纳入模型会引发过度调整偏误。\n\n使用的基本原理：\n- 潜在结果 $Y(0)$ 和 $Y(1)$，其中平均处理效应 (ATE) 定义为 $E[Y(1)-Y(0)]$。\n- 随机化处理意味着 $A$ 与所有潜在结果和噪声项统计独立。\n- 普通最小二乘法 (OLS) 作为一种用于条件期望的线性估计方法。\n\n数据生成过程：\n- 处理 $A\\sim\\text{Bernoulli}(1/2)$。\n- 中介变量 $M=\\alpha A+\\varepsilon_m$，其中 $\\varepsilon_m\\sim\\mathcal{N}(0,\\sigma_m^2)$ 且与 $A$ 独立。\n- 结果 $Y=\\beta A+\\gamma M+\\varepsilon_y$，其中 $\\varepsilon_y\\sim\\mathcal{N}(0,\\sigma_y^2)$ 且与 $A$ 和 $\\varepsilon_m$ 独立。\n- 供选择的候选特征：$M$、$Z_1$、$Z_2$，其中 $Z_1\\sim\\mathcal{N}(0,1)$ 和 $Z_2\\sim\\mathcal{N}(0,1)$ 且与所有其他变量独立。\n\n特征选择协议：\n- 使用合并数据（忽略 $A$），计算 $\\{M,Z_1,Z_2\\}$ 中每个候选特征与 $Y$ 之间的样本相关性。\n- 令 $X$ 为与 $Y$ 的绝对样本相关性最大的单个特征。\n\n效应估计协议：\n- 从样本中计算朴素均值差估计量 $E[Y\\mid A=1]-E[Y\\mid A=0]$。\n- 对 $Y$ 关于 $A$ 和 $X$ 进行 OLS 回归（包括截距项），并记录 $A$ 的系数。\n\n任务：\n1. 使用潜在结果框架和随机分配，推导由 $A$ 定义的组间朴素均值差所针对的估计目标。\n2. 从第一性原理出发，分析调整一个受处理影响且仅因其与合并数据中 $Y$ 的相关性而被选择的单一变量 $X$ 所产生的效应。解释为什么当 $X=M$ 时这会构成过度调整偏误，以及该偏误与底层结构参数的关系。\n3. 实现一个模拟，该模拟遵循数据生成过程，执行特征选择，并使用朴素均值差和调整后的 OLS 系数来估计效应。比较这些量，并将偏误报告为朴素估计量与调整后回归系数之差。同时报告结构模型所蕴含的理论总效应。\n\n特定参数测试套件：\n- 对所有测试，使用噪声方差 $\\sigma_m^2=1$ 和 $\\sigma_y^2=1$。\n- 对每个测试用例，使用固定的随机种子生成 $n$ 个独立样本。\n- 测试用例为以下元组 $(\\alpha,\\beta,\\gamma,n,\\text{seed})$：\n  1. $(1.0, 1.0, 1.0, 100000, 0)$\n  2. $(1.5, 0.5, 2.0, 200000, 1)$\n  3. $(0.0, 2.0, 1.0, 200000, 2)$\n  4. $(1.0, -0.5, -1.0, 200000, 3)$\n  5. $(0.5, 1.0, 0.0, 200000, 4)$\n\n程序要求：\n- 完全按照规定实现数据生成、特征选择和效应估计。\n- 对每个测试用例，计算并返回四个浮点数：\n  - 基于 $A$ 的朴素均值差估计量。\n  - 在 $Y$ 对 $A$ 和所选 $X$ 的回归中， $A$ 的调整后 OLS 系数。\n  - 定义为朴素估计量减去调整后系数的偏误。\n  - 在所述假设下，由结构模型蕴含的理论总效应。\n- 将每个浮点数四舍五入到六位小数。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表形式的结果。外层列表的每个元素对应一个测试用例，其本身是按指定顺序包含四个四舍五入浮点数的列表。例如，两个测试用例的输出格式为：\n  \"[[y1,y2,y3,y4],[z1,z2,z3,z4]]\"\n- 不应打印任何附加文本。\n- 所有值都没有物理单位，应表示为十进制浮点数。", "solution": "该问题要求在潜在结果框架内分析过度调整偏误，特别是在基于特征与结果的相关性来选择该特征进行调整时的情形。这种情况是应用统计分析中的一个常见陷阱，即在未考虑变量的因果结构的情况下执行特征选择。我们将首先推导感兴趣的理论量，然后解释偏误的机制，最后实现一个模拟来展示这种效应。\n\n### 步骤1：理论分析与推导\n\n#### 任务1：朴素均值差的估计目标\n\n我们感兴趣的因果效应是平均处理效应 (ATE)，定义为在处理 ($A=1$) 和控制 ($A=0$) 条件下潜在结果之间的期望差异：\n$$\n\\text{ATE} = E[Y(1) - Y(0)]\n$$\n数据生成过程定义了变量之间的结构关系。我们可以通过代入结构方程来表示处理水平 $a \\in \\{0, 1\\}$ 的潜在结果 $Y(a)$。首先，中介变量 $M$ 的潜在结果是：\n$$\nM(a) = \\alpha a + \\varepsilon_m\n$$\n然后，$Y$ 的潜在结果是：\n$$\nY(a) = \\beta a + \\gamma M(a) + \\varepsilon_y\n$$\n将 $M(a)$ 的表达式代入 $Y(a)$，得到以外生噪声项表示的简化形式的潜在结果：\n$$\nY(a) = \\beta a + \\gamma (\\alpha a + \\varepsilon_m) + \\varepsilon_y = (\\beta + \\alpha\\gamma)a + \\gamma\\varepsilon_m + \\varepsilon_y\n$$\n利用这个表达式，我们可以计算 ATE：\n$$\nY(1) = (\\beta + \\alpha\\gamma)(1) + \\gamma\\varepsilon_m + \\varepsilon_y = \\beta + \\alpha\\gamma + \\gamma\\varepsilon_m + \\varepsilon_y\n$$\n$$\nY(0) = (\\beta + \\alpha\\gamma)(0) + \\gamma\\varepsilon_m + \\varepsilon_y = \\gamma\\varepsilon_m + \\varepsilon_y\n$$\n差值为 $Y(1) - Y(0) = \\beta + \\alpha\\gamma$。由于 $\\beta$、$\\alpha$ 和 $\\gamma$ 是常数，其期望很容易计算：\n$$\n\\text{ATE} = E[Y(1) - Y(0)] = E[\\beta + \\alpha\\gamma] = \\beta + \\alpha\\gamma\n$$\n这个量 $\\beta + \\alpha\\gamma$ 代表了 $A$ 对 $Y$ 的理论*总效应*。它包括*直接效应* $\\beta$（路径 $A \\to Y$）和*间接效应* $\\alpha\\gamma$（路径 $A \\to M \\to Y$）。\n\n朴素均值差估计量所针对的总体量是 $E[Y \\mid A=1] - E[Y \\mid A=0]$。问题陈述处理分配 $A$ 是完全随机的。这意味着 $A$ 与潜在结果 $\\{Y(0), Y(1) \\}$ 及噪声项 $\\{\\varepsilon_m, \\varepsilon_y\\}$ 统计独立。这就是*可忽略性*假设：$A \\perp \\{Y(0), Y(1)\\}$。\n\n在可忽略性假设下，我们有 $E[Y(a) \\mid A=a] = E[Y(a)]$。根据一致性假设（$Y = Y(A)$，观测到的结果是与所接受的处理相对应的潜在结果），我们可以写出：\n$$\nE[Y \\mid A=a] = E[Y(a) \\mid A=a] = E[Y(a)]\n$$\n因此，朴素均值差的估计目标是：\n$$\nE[Y \\mid A=1] - E[Y \\mid A=0] = E[Y(1)] - E[Y(0)] = \\text{ATE}\n$$\n因此，在随机实验中，朴素均值差提供了对真实平均处理效应（即总效应 $\\beta + \\alpha\\gamma$）的无偏估计。\n\n#### 任务2：过度调整偏误分析\n\n实践者的方案包括两个步骤：特征选择和效应估计。\n\n1.  **特征选择**：从集合 $\\{M, Z_1, Z_2\\}$ 中选择一个特征 $X$，其依据是在合并数据中与结果 $Y$ 具有最大的绝对样本相关性。变量 $Z_1$ 和 $Z_2$ 是纯噪声，与模型中所有其他变量独立。因此，它们与 $Y$ 的总体相关性为零：$\\text{Cor}(Z_1, Y) = 0$ 和 $\\text{Cor}(Z_2, Y) = 0$。在任何有限样本中，由于随机性，它们的样本相关性将非零，但随着样本量 $n \\to \\infty$，这些值将收敛到零。\n\n    相比之下，中介变量 $M$ 在结构上与 $Y$ 相关。它与 $Y$ 的总体协方差是：\n    $$\n    \\text{Cov}(M, Y) = \\text{Cov}(\\alpha A + \\varepsilon_m, (\\beta + \\alpha\\gamma)A + \\gamma\\varepsilon_m + \\varepsilon_y)\n    $$\n    利用 $A$, $\\varepsilon_m$, 和 $\\varepsilon_y$ 的独立性以及 $E[A]=1/2$, $\\text{Var}(A)=1/4$：\n    $$\n    \\text{Cov}(M, Y) = \\alpha(\\beta + \\alpha\\gamma)\\text{Var}(A) + \\gamma\\text{Var}(\\varepsilon_m) = \\frac{\\alpha(\\beta + \\alpha\\gamma)}{4} + \\gamma\\sigma_m^2\n    $$\n    只要这个协方差非零（对于大多数参数设置都是如此，例如案例1、2、4），总体相关性 $\\text{Cor}(M, Y)$ 也将非零。对于问题中指定的大样本量，样本相关性 $\\widehat{\\text{Cor}}(M, Y)$ 将非常接近其非零的总体值，而 $\\widehat{\\text{Cor}}(Z_1, Y)$ 和 $\\widehat{\\text{Cor}}(Z_2, Y)$ 将非常接近于零。因此，所选特征 $X$ 极有可能是中介变量 $M$。\n\n2.  **效应估计**：选择 $X=M$ 后，实践者拟合一个普通最小二乘法 (OLS) 回归模型：\n    $$\n    Y = \\theta_0 + \\theta_A A + \\theta_X X + \\text{error}\n    $$\n    当 $X=M$ 时，模型为 $Y = \\theta_0 + \\theta_A A + \\theta_M M + \\text{error}$。真实的数据生成结构过程是 $Y = \\beta A + \\gamma M + \\varepsilon_y$。由于这个结构方程是线性的，并且误差项 $\\varepsilon_y$ 与 $A$ 和 $M$ 独立（因为 $\\varepsilon_m$ 是 $M$ 的一个组成部分），OLS 回归是设定正确的。$A$ 的系数的 OLS 估计量（我们可表示为 $\\hat{\\theta}_A$）将是乘以 $A$ 的真实结构参数的一致估计量。\n    $$\n    \\hat{\\theta}_A \\xrightarrow{p} \\beta\n    $$\n    因此，调整后回归系数的估计目标是 $\\beta$，即 $A$ 对 $Y$ 的*直接效应*。\n\n偏误的产生是因为我们感兴趣的因果效应量是*总效应* (ATE = $\\beta + \\alpha\\gamma$)，但调整后的估计量针对的是*直接效应* ($\\beta$)。对中介变量 $M$——一个位于从 $A$ 到 $Y$ 的因果路径上的处理后变量——进行条件化，阻止了对该间接路径 ($A \\to M \\to Y$) 的估计。这种现象被称为**过度调整偏误**。偏误的大小是真实总效应与调整模型估计目标之间的差值：\n$$\n\\text{Bias} = (\\text{总效应}) - (\\text{调整模型的估计目标}) = (\\beta + \\alpha\\gamma) - \\beta = \\alpha\\gamma\n$$\n问题将偏误定义为`朴素估计量 - 调整后系数`。由于朴素估计量是总效应的无偏估计，这个定义恰好衡量了我们所识别的差异。在期望上，这个差异将是 $\\alpha\\gamma$。$\\alpha\\gamma$ 的非零值（即当 $A$ 影响 $M$ 且 $M$ 影响 $Y$ 时）将导致非零偏误。如果 $\\alpha=0$（$A$ 对 $M$ 没有影响）或 $\\gamma=0$（$M$ 对 $Y$ 没有影响），那么调整 $M$ 不会引发这种类型的偏误。\n\n### 步骤2：模拟实现\n\n对于每个测试用例 $(\\alpha, \\beta, \\gamma, n, \\text{seed})$，模拟将按以下步骤进行：\n1.  设置随机种子以确保可复现性。\n2.  为外生变量生成 $n$ 个样本：处理 $A \\sim \\text{Bernoulli}(1/2)$，噪声项 $\\varepsilon_m \\sim \\mathcal{N}(0, 1)$、$\\varepsilon_y \\sim \\mathcal{N}(0, 1)$，以及零特征 $Z_1, Z_2 \\sim \\mathcal{N}(0, 1)$。\n3.  根据结构方程生成内生变量：$M = \\alpha A + \\varepsilon_m$ 和 $Y = \\beta A + \\gamma M + \\varepsilon_y$。\n4.  执行特征选择：计算绝对样本相关性 $|\\widehat{\\text{Cor}}(M, Y)|$、 $|\\widehat{\\text{Cor}}(Z_1, Y)|$ 和 $|\\widehat{\\text{Cor}}(Z_2, Y)|$。识别与这三个值中的最大值相对应的特征 $X$。\n5.  估计效应：\n    a.  **朴素估计量**：计算 $A=1$ 组的 $Y$ 样本均值，然后减去 $A=0$ 组的 $Y$ 样本均值。\n    b.  **调整后估计量**：构建一个包含截距项、处理向量 $A$ 和所选特征向量 $X$ 的设计矩阵。使用 OLS（例如，通过 `numpy.linalg.lstsq`）将 $Y$ 回归到该矩阵上。与 $A$ 对应的系数即为调整后估计量。\n6.  计算所需输出：\n    a.  朴素估计量的值。\n    b.  调整后估计量的值。\n    c.  偏误，定义为`朴素估计量 - 调整后估计量`。\n    d.  理论总效应，$\\beta + \\alpha\\gamma$。\n7.  将四个得到的浮点数四舍五入到六位小数。模拟结果应证实我们的理论发现，特别是偏误应与 $\\alpha\\gamma$ 非常接近。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements a simulation to demonstrate overadjustment bias from\n    outcome-driven feature selection.\n    \"\"\"\n    test_cases = [\n        # (alpha, beta, gamma, n, seed)\n        (1.0, 1.0, 1.0, 100000, 0),\n        (1.5, 0.5, 2.0, 200000, 1),\n        (0.0, 2.0, 1.0, 200000, 2),\n        (1.0, -0.5, -1.0, 200000, 3),\n        (0.5, 1.0, 0.0, 200000, 4),\n    ]\n\n    all_results = []\n\n    for alpha, beta, gamma, n, seed in test_cases:\n        # Use a random number generator for modern, clean seeding\n        rng = np.random.default_rng(seed)\n\n        # 1. Data-Generating Process\n        sigma_m_sq = 1.0\n        sigma_y_sq = 1.0\n        \n        # Treatment assignment\n        A = rng.binomial(1, 0.5, size=n)\n        \n        # Noise terms\n        eps_m = rng.normal(0, np.sqrt(sigma_m_sq), size=n)\n        eps_y = rng.normal(0, np.sqrt(sigma_y_sq), size=n)\n\n        # Structural equations\n        M = alpha * A + eps_m\n        Y = beta * A + gamma * M + eps_y\n        \n        # Null candidate features\n        Z1 = rng.normal(0, 1, size=n)\n        Z2 = rng.normal(0, 1, size=n)\n\n        # 2. Feature Selection Protocol\n        candidates = {'M': M, 'Z1': Z1, 'Z2': Z2}\n        correlations = {}\n        for name, var in candidates.items():\n            # corrcoef returns a 2x2 matrix, we need the off-diagonal element\n            corr = np.corrcoef(Y, var)[0, 1]\n            correlations[name] = np.abs(corr)\n        \n        # Select the feature with the max absolute correlation with Y\n        selected_feature_name = max(correlations, key=correlations.get)\n        X = candidates[selected_feature_name]\n\n        # 3. Effect Estimation Protocol\n        # a. Naive difference in means estimator\n        y1 = Y[A == 1].mean()\n        y0 = Y[A == 0].mean()\n        naive_estimator = y1 - y0\n\n        # b. Adjusted OLS coefficient for A\n        # Design matrix: intercept, A, and selected feature X\n        design_matrix = np.vstack([np.ones(n), A, X]).T\n        \n        # Solve using least squares\n        coeffs, _, _, _ = np.linalg.lstsq(design_matrix, Y, rcond=None)\n        adjusted_coefficient = coeffs[1]\n\n        # 4. Compute Bias and Theoretical Effect\n        # Bias is defined as naive estimator minus adjusted coefficient\n        bias = naive_estimator - adjusted_coefficient\n        \n        # Theoretical total effect (ATE) is beta + alpha*gamma\n        theoretical_total_effect = beta + alpha * gamma\n\n        # 5. Store and round results\n        case_results = [\n            round(naive_estimator, 6),\n            round(adjusted_coefficient, 6),\n            round(bias, 6),\n            round(theoretical_total_effect, 6)\n        ]\n        all_results.append(case_results)\n\n    # Format the final output string as specified\n    sub_results_str = [f\"[{','.join(map(str, res))}]\" for res in all_results]\n    final_output = f\"[{','.join(sub_results_str)}]\"\n    \n    print(final_output)\n\nsolve()\n```", "id": "3110508"}, {"introduction": "在真实世界的研究中，我们永远无法百分之百地确定已经测量并控制了所有的混杂变量。那么，我们该如何评估研究结论的稳健性呢？本练习将介绍E值（E-value）这一敏感性分析工具。通过推导并计算E值，你将学会如何量化一个未观测混杂因素需要有多强，才能完全“解释掉”我们观察到的关联效应，这是批判性评估和报告观察性研究结果时的一项关键技能。[@problem_id:3110463]", "problem": "考虑一项关于二元处理 $A \\in \\{0,1\\}$ 和二元结局 $Y \\in \\{0,1\\}$ 的观察性研究。设潜在结局为 $Y(1)$ 和 $Y(0)$，并将因果风险比定义为 $RR^{\\text{causal}} = \\frac{\\mathbb{E}[Y(1)]}{\\mathbb{E}[Y(0)]}$。观测到的关联由风险比（RR）$\\widehat{RR} = \\frac{P(Y=1 \\mid A=1)}{P(Y=1 \\mid A=0)}$ 来概括。假设在对已测量的协变量进行条件化之后，可能存在一个与 $A$ 和 $Y$ 都有关联的单一未测量二元混杂因素 $U$。\n\n从潜在结局的定义和关于风险比尺度上未测量混杂所致乘性偏倚边界的成熟结果出发，推导E值作为 $\\widehat{RR}$ 函数的解析表达式。此处，E值被定义为最小的等强度风险比 $E$，使得 $U$ 与 $Y$ 之间的关联（在 $A$ 的各水平内）和 $U$ 与 $A$ 之间的关联能够共同作用，将 $RR^{\\text{causal}}$ 降至 $1$，同时再现观测到的 $\\widehat{RR}$。然后，使用您推导的表达式，计算当 $\\widehat{RR} = 1.8$ 时的E值。将您的数值答案四舍五入至 $4$ 位有效数字。无需单位。最后，简要解释该E值对于解释掉观测效应所需的最小混杂强度意味着什么。", "solution": "本问题要求我们推导E值（E-value）的解析表达式，并将其应用于一个具体的观测风险比。E值是敏感性分析中的一个重要工具，用于量化未测量的混杂因素需要多强才能“解释掉”一个观测到的关联。\n\n### E值公式推导\n我们从混杂偏倚的基本关系入手。一个未测量的混杂因素 $U$ 可以在观测风险比（$\\widehat{RR}$）和真实因果风险比（$RR^{\\text{causal}}$）之间引入偏倚。对于 $\\widehat{RR} > 1$，一个成熟的结论是，该偏倚的大小受一个偏倚因子 $B$ 的限制：\n$$ \\widehat{RR} \\le RR^{\\text{causal}} \\times B $$\n这个偏倚因子 $B$ 本身是混杂因素与处理关联强度（$RR_{AU}$）和与结局关联强度（$RR_{UY}$）的函数。\n\n要完全“解释掉”一个观测到的关联，意味着存在一个混杂场景，使得真实的因果效应为空，即 $RR^{\\text{causal}} = 1$。在这种情况下，上述不等式简化为：\n$$ \\widehat{RR} \\le B $$\nE值的定义是，在混杂因素-处理关联和混杂因素-结局关联强度相等（即 $RR_{AU} = RR_{UY} = E$）的假设下，能够满足 $\\widehat{RR} \\le B$ 的最小强度 $E$ 是多少。通过相关推导，可得 $E$ 和它能产生的最大偏倚 $\\widehat{RR}$ 之间的关系可以通过求解一个二次方程得到，其解为：\n$$ E = \\widehat{RR} + \\sqrt{\\widehat{RR}(\\widehat{RR}-1)} $$\n这就是E值的解析表达式，适用于 $\\widehat{RR} \\ge 1$。\n\n### 数值计算\n给定观测风险比 $\\widehat{RR} = 1.8$，我们代入公式：\n$$ E = 1.8 + \\sqrt{1.8(1.8 - 1)} $$\n$$ E = 1.8 + \\sqrt{1.8 \\times 0.8} $$\n$$ E = 1.8 + \\sqrt{1.44} $$\n$$ E = 1.8 + 1.2 $$\n$$ E = 3.0 $$\n四舍五入到4位有效数字，结果是 $3.000$。\n\n### 结果解释\nE值为 $3.000$ 意味着，一个未测量的混杂因素若要完全解释掉观测到的风险比 $1.8$（即，如果真实的因果风险比是 $1.0$），该混杂因素需要同时与处理和结局都有至少为3.0的风险比关联（在已测量的协变量之外）。研究者可以将这个强度（$E=3.0$）与该领域已知的风险因素的强度进行比较。如果认为存在如此强大的未测量混杂因素是不太可能的，那么关于处理存在真实因果效应的结论就更具稳健性。", "answer": "$$\n\\boxed{3.000}\n$$", "id": "3110463"}]}