{"hands_on_practices": [{"introduction": "为了在实践中应用倾向性得分匹配，我们首先必须掌握其核心计算。本练习将我们带入一个生态学场景，任务是为一个特定的森林地块计算其被划定为保护区的倾向性得分。通过这个具体计算，你将亲手操作一个预先估计好的逻辑回归模型，将模型的系数与协变量值结合起来，从而理解倾向性得分——即一个条件概率——是如何从模型中产生的。[@problem_id:2488850]", "problem": "一位环境科学家，为了将其经验性评估的角色与以倡导为导向的环保主义区分开来，旨在估算保护区指定对森林砍伐的因果影响。由于保护区的选址并非随机，如果被指定为保护区的区域在生物物理或政治特征上与未被指定的区域存在系统性差异，就可能产生选择偏差。为解决此问题，该科学家采用了倾向得分框架，其中倾向得分是在给定观测协变量的情况下，接受处理（被指定为保护区）的条件概率。\n\n您之前已经基于同一地区的训练样本，使用带有logit链接的广义线性模型（GLM）估算了一个用于保护区指定的二元响应模型。预测变量为坡度、到道路的距离以及一个表示是否邻近政治边界的指标。估算出的线性预测器使用以下系数（根据先前数据估算）：截距 $\\beta_{0}=-3.8$，坡度系数 $\\beta_{\\text{slope}}=0.07$ 每度（度是角度单位），到道路距离的系数 $\\beta_{\\text{dist}}=0.05$ 每公里，以及政治边界系数 $\\beta_{\\text{bound}}=0.60$（对于一个二元指标，若地块位于省界10公里以内则为$1$，否则为$0$）。\n\n对于一个坡度为$18$度、距离最近道路$25$公里、且位于省界$10$公里以内的特定林地地块（指标等于$1$），计算该地块被指定为保护区的倾向得分。请从倾向得分是给定协变量下处理的条件概率这一定义出发，并结合带有logit链接的广义线性模型中对数几率变换（logit）的定义，在代入数值之前推导出您需要的任何概率映射。\n\n将您最终的数值倾向得分四舍五入到四位有效数字，并以无单位的小数形式表示（不要使用百分比）。此外，请简要用文字概述在估算保护区对森林砍伐的影响时，基于此得分进行匹配如何能减少选择偏差，并阐明区分推断性评估与倡导活动的科学推理。\n\n最终数值答案仅需陈述计算出的倾向得分。", "solution": "对问题陈述进行验证。\n\n**步骤1：提取已知信息**\n- 模型：用于保护区指定二元响应的广义线性模型（GLM），使用logit链接。\n- 倾向得分定义为在给定观测协变量的情况下，接受处理（被指定为保护区）的条件概率。\n- 线性预测器系数：\n  - 截距 $\\beta_{0} = -3.8$\n  - 坡度系数 $\\beta_{\\text{slope}} = 0.07$ 每度\n  - 到道路距离的系数 $\\beta_{\\text{dist}} = 0.05$ 每公里\n  - 政治边界系数 $\\beta_{\\text{bound}} = 0.60$\n- 林地地块特征（协变量）：\n  - 坡度：$18$度\n  - 到最近道路的距离：$25$公里\n  - 邻近政治边界指标：$1$\n\n**步骤2：使用提取的已知信息进行验证**\n- 该问题具有**科学依据**。在观察性研究中，使用带有logit链接的广义线性模型和倾向得分框架是统计学和计量经济学中用于因果推断的标准、成熟的方法。\n- 该问题是**适定的**。它提供了计算唯一解所需的所有必要参数和变量值。问题没有歧义。\n- 该问题是**客观的**。它使用了精确的技术语言，并正确地构建了项目评估中选择偏差的方法论挑战，区分了经验科学角色与倡导活动。\n- 该问题不包含科学或事实上的不健全之处，并非不可形式化，没有不完整或矛盾的设置，并非不切实际或不可行，并非不适定，并非微不足道，并且是科学上可验证的。\n\n**步骤3：结论与行动**\n该问题是**有效的**。将推导解答。\n\n任务是计算特定林地地块的倾向得分，并解释倾向得分匹配的逻辑。倾向得分，我们记作 $p(X)$，是在给定观测协变量向量 $X$ 的情况下，接受处理（$T=1$）的条件概率。在此背景下，处理是指将一个地块指定为保护区。\n\n$$p(X) = P(T=1 | X)$$\n\n所用模型是带有logit链接函数的广义线性模型（GLM）。logit函数将一个概率 $p \\in (0, 1)$ 映射到实数轴 $(-\\infty, \\infty)$，其定义为几率的自然对数：\n\n$$\\text{logit}(p) = \\ln\\left(\\frac{p}{1-p}\\right)$$\n\n在GLM框架中，响应的条件均值的链接函数与线性预测器 $\\eta$ 相等。对于二元响应，条件均值就是概率 $p$。因此，我们有：\n\n$$\\eta = \\ln\\left(\\frac{p}{1-p}\\right)$$\n\n为了从线性预测器 $\\eta$ 计算概率 $p$，我们必须推导出logit函数的反函数，即逻辑S型函数（logistic sigmoid function）。我们首先对等式两边取指数：\n\n$$\\exp(\\eta) = \\frac{p}{1-p}$$\n\n现在，我们求解 $p$：\n$$\\exp(\\eta) \\cdot (1-p) = p$$\n$$\\exp(\\eta) - p \\cdot \\exp(\\eta) = p$$\n$$\\exp(\\eta) = p + p \\cdot \\exp(\\eta)$$\n$$\\exp(\\eta) = p \\cdot (1 + \\exp(\\eta))$$\n\n这就得到了倾向得分作为线性预测器函数的表达式：\n$$p = \\frac{\\exp(\\eta)}{1 + \\exp(\\eta)}$$\n\n线性预测器 $\\eta$ 是给定协变量及其相应系数的线性组合：\n$$\\eta = \\beta_{0} + \\beta_{\\text{slope}} \\cdot X_{\\text{slope}} + \\beta_{\\text{dist}} \\cdot X_{\\text{dist}} + \\beta_{\\text{bound}} \\cdot X_{\\text{bound}}$$\n\n问题提供了以下数值：\n- 截距：$\\beta_{0} = -3.8$\n- 系数：$\\beta_{\\text{slope}} = 0.07$, $\\beta_{\\text{dist}} = 0.05$, $\\beta_{\\text{bound}} = 0.60$\n- 地块协变量：$X_{\\text{slope}} = 18$, $X_{\\text{dist}} = 25$, $X_{\\text{bound}} = 1$\n\n我们代入这些值来计算线性预测器 $\\eta$：\n$$\\eta = -3.8 + (0.07 \\times 18) + (0.05 \\times 25) + (0.60 \\times 1)$$\n$$\\eta = -3.8 + 1.26 + 1.25 + 0.60$$\n$$\\eta = -3.8 + 3.11$$\n$$\\eta = -0.69$$\n\n现在，我们用这个 $\\eta$ 值来计算倾向得分 $p$：\n$$p = \\frac{\\exp(-0.69)}{1 + \\exp(-0.69)}$$\n\n计算数值：\n$$p \\approx \\frac{0.501574}{1 + 0.501574} = \\frac{0.501574}{1.501574} \\approx 0.334033$$\n\n问题要求四舍五入到四位有效数字。因此，该地块的倾向得分为 $0.3340$。\n\n关于此方法的效用，选择偏差源于保护区选址的非随机性。被指定为保护区的地块可能与未被指定的地块存在系统性差异（例如，它们可能更偏远、坡度更陡或农业潜力更低）。对森林砍伐等结果进行简单比较，会将保护措施的效果与这些预先存在的差异混为一谈。倾向得分匹配是一种旨在减轻这种偏差的统计技术。它在条件可忽略性假设下运作，该假设主张，在给定观测协变量 $X$ 的条件下，处理分配与潜在结果无关。通过将一个处理单元（受保护的地块）与一个或多个具有非常相似倾向得分的控制单元（未受保护的地块）进行匹配，我们创建了一个在观测协变量上达到平衡的比较组。也就是说，对于给定的倾向得分，一个处理单元和一个控制单元在事前具有相同的受保护概率。这个过程模仿了随机实验的特性，从而可以更可靠地估算保护措施的因果效应。这种纯粹的推断性目标——通过控制混淆因素来分离因果效应——是当前背景下环境科学的标志。它与环保主义截然不同，后者是一种倡导立场，无论保护措施是否具有经经验证明的、孤立的影响，都可能推动保护。科学家的角色是提供一个客观、基于证据的处理效应估算，而这种方法是实现该目标的关键工具。", "answer": "$$\n\\boxed{0.3340}\n$$", "id": "2488850"}, {"introduction": "掌握了基本计算后，我们面临一个更微妙的问题：应该在倾向性得分模型中包含哪些变量？一个常见的误区是“变量越多越好”，但这可能导致严重的偏差。本练习通过一个模拟实验，让你直面一种被称为“M-偏倚”（M-bias）的陷阱，即当模型中包含一个“对撞因子”（collider）时，反而会人为地引入偏差。通过这个编码实践，你将深刻理解在选择变量前进行因果推理（通常借助有向无环图，即DAG）的重要性。[@problem_id:3162896]", "problem": "要求您在统计学习中因果推断的潜在结果框架内，设计并实现一个基于模拟的倾向性得分匹配（PSM）中 M-偏倚的演示。从以下基本基础开始：在潜在结果框架下，平均处理效应（ATE）被定义为在处理和控制下的潜在结果之间的平均差异，而倾向性得分是在观测到的协变量条件下接受处理的概率。对撞机是一个由两个（或更多）变量引起的变量；对对撞机进行条件化可能会在原本独立的原因之间引入虚假的统计关联（M-偏倚），如果这些原因沿着不同路径影响结果和处理，就会使因果效应的估计产生偏倚。\n\n使用有向无环图（DAG）概念构建一个体现典型 M-偏倚结构的数据生成过程（DGP）。该 DAG 如下：存在潜变量 $U$ 和 $V$，使得 $U$ 影响处理 $T$ 但不影响结果 $Y$，$V$ 影响结果 $Y$ 但不影响处理 $T$，而对撞机 $C$ 同时受 $U$ 和 $V$ 的影响。此外还有一个观测到的协变量 $X$。结构方程如下：\n- 潜变量成因：$U \\sim \\mathcal{N}(0,1)$，$V \\sim \\mathcal{N}(0,1)$。\n- 观测协变量：$X \\sim \\mathcal{N}(0,1)$。\n- 对撞机：$C = \\gamma_U U + \\gamma_V V + \\varepsilon_C$，其中 $\\varepsilon_C \\sim \\mathcal{N}(0,1)$。\n- 处理分配：$T \\sim \\text{Bernoulli}(\\text{logit}^{-1}(\\alpha_0 + \\alpha_U U + \\alpha_X X))$，其中 $\\text{logit}^{-1}(z) = \\dfrac{1}{1 + e^{-z}}$。\n- 结果：$Y = \\beta_T T + \\beta_V V + \\beta_X X + \\varepsilon_Y$，其中 $\\varepsilon_Y \\sim \\mathcal{N}(0,1)$。\n\n在此 DGP 下，真实的平均处理效应（ATE）等于 $\\beta_T$。\n\n您的程序必须为每个测试用例执行以下操作：\n1. 根据上述 DGP 模拟 $N$ 个独立观测值。\n2. 使用逻辑回归（最大似然法）为 $T$ 估计两个倾向性得分模型，每个模型都包含一个截距项：\n   - 错误模型（包含对撞机）：协变量 $\\{X, C\\}$。\n   - 正确模型（不包含对撞机）：协变量 $\\{X\\}$。\n3. 对于每个拟合的倾向性得分，使用有放回的最近邻匹配，并对倾向性得分的绝对差值设置一个卡尺（caliper）。具体而言：\n   - 对于每个处理单元，在倾向性得分距离上找到最近的一个控制单元；如果距离小于或等于卡尺，则包含该配对。\n   - 对于每个控制单元，在倾向性得分距离上找到最近的一个处理单元；如果距离小于或等于卡尺，则包含该配对。\n   - 通过对双向形成的所有可用匹配对差异 $Y_{\\text{treated}} - Y_{\\text{control}}$ 进行平均，计算平均处理效应的匹配估计值（这种对称匹配估计量近似于平均处理效应，而不仅仅是处理组的平均处理效应）。\n   - 如果没有配对满足卡尺条件，则在不使用任何卡尺（即 caliper $= +\\infty$）的情况下重新运行最近邻匹配。\n4. 计算每个匹配估计量相对于真实 ATE 的偏倚：\n   - 包含对撞机的偏倚：$b_{\\text{incl}} = \\widehat{\\text{ATE}}_{\\text{incl}} - \\beta_T$。\n   - 不包含对撞机的偏倚：$b_{\\text{excl}} = \\widehat{\\text{ATE}}_{\\text{excl}} - \\beta_T$。\n   - 因包含对撞机而产生的额外绝对偏倚：$\\Delta = |b_{\\text{incl}}| - |b_{\\text{excl}}|$。\n5. 将所有测试用例的结果汇总到单行输出中，形式为以逗号分隔的每个用例的三元组列表，其中每个三元组是方括号内的列表 $[b_{\\text{incl}}, b_{\\text{excl}}, \\Delta]$。完整的输出必须用方括号括起来。例如：$[[b_1^{\\text{incl}}, b_1^{\\text{excl}}, \\Delta_1],[b_2^{\\text{incl}}, b_2^{\\text{excl}}, \\Delta_2]]$。\n\n测试套件与参数：\n为以下四个测试用例实现该过程。使用指定的随机种子以确保可复现性。\n\n- 用例 1（基线，中等强度对撞机）：\n  - $N = 4000$, $\\alpha_0 = 0$, $\\alpha_U = 1.0$, $\\alpha_X = 0.5$, $\\beta_T = 2.0$, $\\beta_V = 1.0$, $\\beta_X = 0.0$, $\\gamma_U = 0.8$, $\\gamma_V = 0.8$, 卡尺 $= 0.05$, 种子 $= 42$。\n\n- 用例 2（边界情况，无对撞机效应）：\n  - $N = 4000$, $\\alpha_0 = 0$, $\\alpha_U = 1.0$, $\\alpha_X = 0.5$, $\\beta_T = 2.0$, $\\beta_V = 1.0$, $\\beta_X = 0.0$, $\\gamma_U = 0.0$, $\\gamma_V = 0.0$, 卡尺 $= 0.05$, 种子 $= 1$。\n\n- 用例 3（强对撞机影响）：\n  - $N = 4000$, $\\alpha_0 = 0$, $\\alpha_U = 1.2$, $\\alpha_X = 0.5$, $\\beta_T = 2.0$, $\\beta_V = 1.0$, $\\beta_X = 0.0$, $\\gamma_U = 2.5$, $\\gamma_V = 2.5$, 卡尺 $= 0.05$, 种子 $= 7$。\n\n- 用例 4（小样本，中等强度对撞机）：\n  - $N = 600$, $\\alpha_0 = 0$, $\\alpha_U = 1.0$, $\\alpha_X = 0.5$, $\\beta_T = 2.0$, $\\beta_V = 1.0$, $\\beta_X = 0.0$, $\\gamma_U = 1.0$, $\\gamma_V = 1.0$, 卡尺 $= 0.07$, 种子 $= 123$。\n\n最终输出格式：\n您的程序应生成一行输出，其中包含结果，格式为以逗号分隔的每个用例的三元组列表，每个三元组本身是方括号内的逗号分隔列表，整个输出用方括号括起来。例如：$[[r_{11},r_{12},r_{13}],[r_{21},r_{22},r_{23}],[r_{31},r_{32},r_{33}],[r_{41},r_{42},r_{43}]]$。每个 $r_{ij}$ 必须是一个浮点数。", "solution": "问题陈述已经过验证，被认为是有效的。它在因果推断和统计学习领域提出了一个定义明确、具有科学依据的模拟练习。其目标是在倾向性得分匹配（PSM）的背景下，演示 M-偏倚，这是一种因对对撞机变量进行条件化而产生的特定类型的偏倚。所有参数、模型和过程都得到了明确定义，从而能够实现可复现的计算解决方案。\n\n### 理论框架\n\n该问题植根于因果推断的潜在结果框架。目标是估计平均处理效应（ATE），定义为 $\\mathbb{E}[Y(1) - Y(0)]$，其中 $Y(1)$ 和 $Y(0)$ 分别是处理和控制下的潜在结果。数据生成过程（DGP）由一组对应于有向无环图（DAG）的结构方程指定。该 DAG 的核心是“M-结构”：\n1. 一个未观测变量 $U$ 是处理 $T$ 的原因（$U \\rightarrow T$）。\n2. 另一个未观测变量 $V$ 是结果 $Y$ 的原因（$V \\rightarrow Y$）。\n3. $U$ 和 $V$ 是独立的，即它们之间没有路径。\n4. $U$ 和 $V$ 都是一个观测变量 $C$（对撞机）的原因（$U \\rightarrow C \\leftarrow V$）。\n\n在这种结构中，$T$ 和 $Y$ 不通过涉及 $U$ 和 $V$ 的路径相关联，因为路径 $T \\leftarrow U \\rightarrow C \\leftarrow V \\rightarrow Y$ 被对撞机 $C$ 阻断。然而，如果对对撞机 $C$ 进行条件化（例如，通过将其包含在回归模型中），这条路径就会被打开，从而在 $U$ 和 $V$ 之间引入虚假的统计关联。处理的原因（$U$）和结果的原因（$V$）之间的这种虚假关联在 $T$ 和 $Y$ 之间产生了一种非因果的统计关联，导致因果效应的估计出现偏倚。\n\n指定的 DGP 由以下公式给出：\n- 潜变量成因：$U \\sim \\mathcal{N}(0,1)$，$V \\sim \\mathcal{N}(0,1)$。\n- 观测协变量：$X \\sim \\mathcal{N}(0,1)$。\n- 对撞机：$C = \\gamma_U U + \\gamma_V V + \\varepsilon_C$，其中 $\\varepsilon_C \\sim \\mathcal{N}(0,1)$。\n- 处理分配：$T \\sim \\text{Bernoulli}(\\text{logit}^{-1}(\\alpha_0 + \\alpha_U U + \\alpha_X X))$。\n- 结果：$Y = \\beta_T T + \\beta_V V + \\beta_X X + \\varepsilon_Y$，其中 $\\varepsilon_Y \\sim \\mathcal{N}(0,1)$。\n\n真实的 ATE 由系数 $\\beta_T$ 给出。变量 $X$ 作为处理的一个观测到的预测变量被包含在内（$X \\rightarrow T$）。在给定的测试用例中，$\\beta_X=0$，因此 $X$ 不是一个混杂因素（即，不存在开放的后门路径 $T \\leftarrow X \\rightarrow Y$）。尽管如此，将处理的预测变量包含在倾向性得分模型中是标准做法。“正确”的倾向性得分模型包含能够阻断 $T$ 和 $Y$ 之间所有后门路径且不打开新路径的预测变量。在这里，这意味着对 $X$ 进行调整，但关键是不能对对撞机 $C$ 进行调整。\n\n### 模拟与估计过程\n\n对于每个测试用例，执行以下步骤：\n\n1.  **数据生成**：根据结构方程和指定参数模拟一个包含 $N$ 个观测值的数据集。固定的随机种子确保了可复现性。变量 $U、V、X、\\varepsilon_C、\\varepsilon_Y$ 从标准正态分布中抽取。然后根据其定义构建对撞机 $C$、二元处理 $T$ 和连续结果 $Y$。\n\n2.  **倾向性得分估计**：倾向性得分 $e(Z) = P(T=1|Z)$ 使用两种不同的逻辑回归模型进行估计，其中 $Z$ 是协变量集合。模型系数通过使用数值优化算法（BFGS）最大化对数似然函数来估计。\n    - **错误模型**：在协变量集合中包含对撞机 $C$，$Z = \\{X, C\\}$。估计的倾向性得分为 $\\hat{e}_{\\text{incl}}(X, C)$。由于对对撞机进行了条件化，预计该模型会产生有偏倚的结果。\n    - **正确模型**：不包含对撞机，$Z = \\{X\\}$。估计的倾向性得分为 $\\hat{e}_{\\text{excl}}(X)$。该模型避免了 M-偏倚。\n\n3.  **通过匹配进行 ATE 估计**：对于两个估计的倾向性得分中的每一个，使用有放回的对称最近邻匹配和一个卡尺来计算 ATE 的匹配估计值。\n    - **对称匹配**：为了估计 ATE（而不是 ATT 或 ATC），从两个方向寻找匹配。对于每个处理单元，找到最近的控制单元（在倾向性得分距离上）。对称地，对于每个控制单元，找到最近的处理单元。\n    - **卡尺**：只有当一对单元的倾向性得分绝对差值在指定的卡尺值之内时，才被视为有效匹配。\n    - **后备方案**：如果没有配对满足卡尺条件，则使用无限大的卡尺重复该过程（即，无论距离如何都找到最近的邻居）。\n    - **估计量**：ATE 被估计为在两个匹配方向上找到的所有有效匹配对的结果差异 $Y_{\\text{treated}} - Y_{\\text{control}}$ 的简单算术平均值。\n\n4.  **偏倚分析**：每个估计量的性能通过其偏倚来评估，即估计值与真实 ATE（$\\beta_T$）之间的差异。\n    - 偏倚（包含对撞机）：$b_{\\text{incl}} = \\widehat{\\text{ATE}}_{\\text{incl}} - \\beta_T$。\n    - 偏倚（不包含对撞机）：$b_{\\text{excl}} = \\widehat{\\text{ATE}}_{\\text{excl}} - \\beta_T$。\n    - 额外绝对偏倚：$\\Delta = |b_{\\text{incl}}| - |b_{\\text{excl}}|$。正的 $\\Delta$ 值表明，包含对撞机放大了估计偏倚，证明了 M-偏倚的有害影响。\n\n预计模拟将显示，当对撞机路径强度（$\\gamma_U, \\gamma_V$）非零时，$|b_{\\text{incl}}|$ 显著大于 $|b_{\\text{excl}}|$，并且这个差异 $\\Delta$ 随着对撞机强度的增加而增加。当 $\\gamma_U = \\gamma_V = 0$ 时，M-结构不存在，两个模型都应产生相似的、低偏倚的估计，导致 $\\Delta$ 接近于零。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.special import expit\n\ndef _logistic_regression(X_design, y_obs):\n    \"\"\"\n    Performs logistic regression using maximum likelihood estimation.\n    \"\"\"\n    def neg_log_likelihood(beta, X, y):\n        \"\"\"\n        Calculates the negative log-likelihood for a logistic model.\n        Uses np.logaddexp for numerical stability.\n        L = sum(y*z - log(1+exp(z))) where z = X @ beta\n        \"\"\"\n        linear_pred = X @ beta\n        log_likelihood = np.sum(y * linear_pred - np.logaddexp(0, linear_pred))\n        return -log_likelihood\n\n    initial_beta = np.zeros(X_design.shape[1])\n    result = minimize(\n        neg_log_likelihood,\n        initial_beta,\n        args=(X_design, y_obs),\n        method='BFGS'\n    )\n    return result.x\n\ndef _perform_matching(T, Y, ps, caliper):\n    \"\"\"\n    Performs symmetric nearest-neighbor matching and computes the ATE estimate.\n    \"\"\"\n    def find_matches(source_indices, target_indices, ps, T_full, Y_full, caliper_val):\n        \"\"\"Helper to find matches for a source group from a target group.\"\"\"\n        ps_source = ps[source_indices]\n        ps_target = ps[target_indices]\n        \n        # Sort target for efficient search\n        sort_map = np.argsort(ps_target)\n        ps_target_sorted = ps_target[sort_map]\n        \n        # Find insertion points for all source PSs into the sorted target PSs\n        insert_points = np.searchsorted(ps_target_sorted, ps_source)\n        \n        matched_diffs = []\n        for i, ps_s in enumerate(ps_source):\n            idx = insert_points[i]\n            \n            best_dist = np.inf\n            best_match_target_original_idx = -1\n\n            # Candidate 1: at insertion point\n            if idx  len(ps_target_sorted):\n                dist = np.abs(ps_s - ps_target_sorted[idx])\n                if dist  best_dist:\n                    best_dist = dist\n                    best_match_target_original_idx = target_indices[sort_map[idx]]\n\n            # Candidate 2: at insertion point - 1\n            if idx > 0:\n                dist = np.abs(ps_s - ps_target_sorted[idx-1])\n                if dist  best_dist:\n                    best_dist = dist\n                    best_match_target_original_idx = target_indices[sort_map[idx-1]]\n\n            source_original_idx = source_indices[i]\n            if best_match_target_original_idx != -1 and best_dist = caliper_val:\n                if T_full[source_original_idx] == 1: # Source is treated\n                    y_diff = Y_full[source_original_idx] - Y_full[best_match_target_original_idx]\n                else: # Source is control\n                    y_diff = Y_full[best_match_target_original_idx] - Y_full[source_original_idx]\n                matched_diffs.append(y_diff)\n        return matched_diffs\n\n    treated_indices = np.where(T == 1)[0]\n    control_indices = np.where(T == 0)[0]\n\n    # Guard against empty treatment/control groups\n    if len(treated_indices) == 0 or len(control_indices) == 0:\n        return np.nan\n\n    # Run with the given caliper\n    all_diffs = []\n    # T -> C matching\n    all_diffs.extend(find_matches(treated_indices, control_indices, ps, T, Y, caliper))\n    # C -> T matching\n    all_diffs.extend(find_matches(control_indices, treated_indices, ps, T, Y, caliper))\n    \n    # If no matches found, re-run with infinite caliper\n    if not all_diffs:\n        all_diffs.extend(find_matches(treated_indices, control_indices, ps, T, Y, np.inf))\n        all_diffs.extend(find_matches(control_indices, treated_indices, ps, T, Y, np.inf))\n        \n    return np.mean(all_diffs) if all_diffs else np.nan\n\ndef solve():\n    \"\"\"\n    Main function to run the M-bias simulation across all test cases.\n    \"\"\"\n    test_cases = [\n        {'N': 4000, 'alpha_0': 0.0, 'alpha_U': 1.0, 'alpha_X': 0.5, 'beta_T': 2.0, \n         'beta_V': 1.0, 'beta_X': 0.0, 'gamma_U': 0.8, 'gamma_V': 0.8, \n         'caliper': 0.05, 'seed': 42},\n        {'N': 4000, 'alpha_0': 0.0, 'alpha_U': 1.0, 'alpha_X': 0.5, 'beta_T': 2.0, \n         'beta_V': 1.0, 'beta_X': 0.0, 'gamma_U': 0.0, 'gamma_V': 0.0, \n         'caliper': 0.05, 'seed': 1},\n        {'N': 4000, 'alpha_0': 0.0, 'alpha_U': 1.2, 'alpha_X': 0.5, 'beta_T': 2.0, \n         'beta_V': 1.0, 'beta_X': 0.0, 'gamma_U': 2.5, 'gamma_V': 2.5, \n         'caliper': 0.05, 'seed': 7},\n        {'N': 600, 'alpha_0': 0.0, 'alpha_U': 1.0, 'alpha_X': 0.5, 'beta_T': 2.0, \n         'beta_V': 1.0, 'beta_X': 0.0, 'gamma_U': 1.0, 'gamma_V': 1.0, \n         'caliper': 0.07, 'seed': 123}\n    ]\n\n    results = []\n    for params in test_cases:\n        # Set seed for reproducibility\n        rng = np.random.default_rng(params['seed'])\n        N = params['N']\n\n        # 1. Simulate data according to the DGP\n        U = rng.normal(size=N)\n        V = rng.normal(size=N)\n        X = rng.normal(size=N)\n        eps_C = rng.normal(size=N)\n        C = params['gamma_U'] * U + params['gamma_V'] * V + eps_C\n        \n        linear_pred_T = params['alpha_0'] + params['alpha_U'] * U + params['alpha_X'] * X\n        prob_T = expit(linear_pred_T)\n        T = rng.binomial(1, prob_T)\n        \n        eps_Y = rng.normal(size=N)\n        Y = params['beta_T'] * T + params['beta_V'] * V + params['beta_X'] * X + eps_Y\n\n        # 2. Estimate two propensity score models\n        # Incorrect model (including collider)\n        X_incl = np.c_[np.ones(N), X, C]\n        coeffs_incl = _logistic_regression(X_incl, T)\n        ps_incl = expit(X_incl @ coeffs_incl)\n\n        # Correct model (excluding collider)\n        X_excl = np.c_[np.ones(N), X]\n        coeffs_excl = _logistic_regression(X_excl, T)\n        ps_excl = expit(X_excl @ coeffs_excl)\n        \n        # 3. Perform matching and estimate ATE for both models\n        ate_incl = _perform_matching(T, Y, ps_incl, params['caliper'])\n        ate_excl = _perform_matching(T, Y, ps_excl, params['caliper'])\n        \n        # 4. Compute bias\n        true_ate = params['beta_T']\n        b_incl = ate_incl - true_ate\n        b_excl = ate_excl - true_ate\n        \n        # 5. Compute excess absolute bias\n        delta = np.abs(b_incl) - np.abs(b_excl)\n        \n        results.append([b_incl, b_excl, delta])\n\n    # Final print statement in the exact required format.\n    output_str = \",\".join([f\"[{r[0]},{r[1]},{r[2]}]\" for r in results])\n    print(f\"[{output_str}]\")\n\nsolve()\n```", "id": "3162896"}, {"introduction": "在了解了应避免哪些变量之后，我们来探讨如何构建和优化倾向性得分模型。请记住，模型的最终目标不是完美预测处理分配，而是在处理组和控制组之间实现协变量的平衡。本练习将指导你完成一个完整的实践工作流：首先，使用变量重要性指标来“修剪”模型；然后，通过计算“标准化均值差”（Standardized Mean Difference, SMD）来评估这种修剪是否真正改善了协变量的平衡，而这正是匹配方法的最终检验标准。[@problem_id:3162937]", "problem": "给定一个任务，要求您算法化地确定一个倾向性得分模型的变量剪枝策略，并评估在对估计的倾向性得分进行一对一最近邻匹配后，剪枝如何影响协变量的平衡性。您必须基于因果推断和统计建模的基本定义，实现完整的流程，并在一小组测试集上进行量化比较。\n\n使用的基本原理和定义：\n- 倾向性得分定义为 $e(x) = \\mathbb{P}(T = 1 \\mid X = x)$，其中 $T \\in \\{0,1\\}$ 是一个二元处理，$X \\in \\mathbb{R}^p$ 是一个协变量向量。\n- 您将通过逻辑斯谛回归对倾向性得分进行建模，即 $\\text{logit}(e(x)) = \\beta_0 + x^\\top \\beta$，其中 $\\text{logit}(u) = \\log\\left(\\frac{u}{1-u}\\right)$ 且 $\\beta \\in \\mathbb{R}^p$。\n- 使用迭代重加权最小二乘法（IRLS）通过最大化二项对数似然来拟合逻辑斯谛回归，IRLS是应用于逻辑斯谛回归对数似然的Newton–Raphson方法。在信息矩阵上使用一个小的岭稳定化，以确保数值上的可逆性。\n- 在倾向模型中，需要计算两种变量重要性度量：\n  1. 绝对标准化系数大小，对于协变量 $j$ 定义为 $I^{(\\text{coef})}_j = \\lvert \\hat{\\beta}_j \\rvert$，在将协变量标准化为零均值和单位方差后计算。这度量了$X_j$每变化一个标准差，对数几率的变化幅度。\n  2. 绝对Wald $z$-统计量，定义为 $I^{(\\text{wald})}_j = \\left| \\frac{\\hat{\\beta}_j}{\\widehat{\\text{se}}(\\hat{\\beta}_j)} \\right|$，其中 $\\widehat{\\text{se}}(\\hat{\\beta}_j)$ 从最大似然估计处的观测Fisher信息矩阵的逆矩阵获得。这度量了一个在对数几率尺度上信噪比标准化的效应。\n- 通过秩平均聚合这两种度量：\n  - 对每种度量，赋予秩 $r^{(\\text{coef})}_j, r^{(\\text{wald})}_j \\in \\{1,2,\\dots,p\\}$，使得值越大，秩越高。按协变量索引顺序确定性地处理平级关系。将组合秩定义为 $r^{(\\text{comb})}_j = \\frac{r^{(\\text{coef})}_j + r^{(\\text{wald})}_j}{2}$。\n- 剪枝规则：给定一个剪枝比例 $q \\in [0,1)$，按 $r^{(\\text{comb})}_j$ 降序保留前 $\\lceil (1-q) \\cdot p \\rceil$ 个协变量，并舍弃其余的。\n- 匹配：在估计的倾向性得分上执行无放回的一对一最近邻匹配。定义绝对距离 $d(i,k) = \\lvert \\hat{e}_i - \\hat{e}_k \\rvert$。使用样本量较小的组（处理组或对照组）作为锚定集以保证完全匹配，按 $\\hat{e}$ 升序对锚定集进行排序，并为每个锚定单位选择最小化 $d(i,k)$ 的未匹配的对立组单位，通过选择最小的索引来打破平级关系以确保确定性。\n- 平衡性评估：对于每个协变量 $j \\in \\{1,\\dots,p\\}$，计算匹配后的标准化均值差（SMD）为\n  $$\\text{SMD}_j = \\frac{\\bar{x}^{(T=1)}_j - \\bar{x}^{(T=0)}_j}{\\sqrt{\\frac{s^{2,(T=1)}_j + s^{2,(T=0)}_j}{2}}},$$\n  其中 $\\bar{x}^{(T=t)}_j$ 和 $s^{2,(T=t)}_j$ 分别是处理状态为 $t \\in \\{0,1\\}$ 的匹配子样本的样本均值和无偏样本方差。如果分母为零，则定义 $\\text{SMD}_j = 0$。通过平均绝对标准化均值差来总结平衡性，即 $\\text{mSMD} = \\frac{1}{p} \\sum_{j=1}^p \\lvert \\text{SMD}_j \\rvert$。\n- 比较两个模型：完整模型（所有 $p$ 个协变量）与剪枝模型（仅保留的协变量，重新估计）。对每种情况，使用从各自模型的倾向性得分构建的匹配来计算 $\\text{mSMD}^{\\text{full}}$ 和 $\\text{mSMD}^{\\text{pruned}}$，并报告由剪枝引起的变化 $\\Delta = \\text{mSMD}^{\\text{pruned}} - \\text{mSMD}^{\\text{full}}$。负的 $\\Delta$ 值表示剪枝后平衡性得到改善。\n\n每个测试案例的数据生成过程：\n- 生成 $n$ 个观测值的 $p$ 维协变量 $X \\sim \\mathcal{N}(0, \\Sigma)$，其中 $\\Sigma_{ij} = \\rho^{\\lvert i-j \\rvert}$，$\\rho \\in [0,1)$ 是给定的相关参数。\n- 设真实的对数几率为 $\\eta = \\alpha_0 + X \\beta^{\\star}$，其中 $\\beta^{\\star} \\in \\mathbb{R}^p$ 是指定的向量，$\\alpha_0 \\in \\mathbb{R}$ 是截距，则各观测值独立地 $T \\sim \\text{Bernoulli}(\\sigma(\\eta))$，其中 $\\sigma(u) = \\frac{1}{1 + e^{-u}}$。\n- 在建模中，拟合逻辑斯谛回归前，将协变量标准化为零均值和单位方差，以使重要性度量 $I^{(\\text{coef})}_j$ 具有无尺度解释。\n\n测试套件：\n您必须按此确切顺序在以下三个参数集上运行您的程序。每个参数集指定 $(n, p, \\rho, \\text{seed}, \\beta^{\\star}, \\alpha_0, q)$，其中所有数字均为实数或整数。对于 $\\beta^{\\star}$，请按顺序列出 $p$ 个条目。\n\n- 测试案例A（一般情况）：\n  - $n = 400$, $p = 6$, $\\rho = 0.3$, $\\text{seed} = 2021$, $\\beta^{\\star} = [0.8, -0.7, 0.6, 0.0, 0.0, 0.0]$, $\\alpha_0 = 0.0$, $q = 0.5$。\n- 测试案例B（弱信号边界情况）：\n  - $n = 300$, $p = 5$, $\\rho = 0.2$, $\\text{seed} = 7$, $\\beta^{\\star} = [0.0, 0.0, 0.0, 0.0, 0.0]$, $\\alpha_0 = 0.0$, $q = 0.4$。\n- 测试案例C（高度共线性）：\n  - $n = 500$, $p = 5$, $\\rho = 0.9$, $\\text{seed} = 99$, $\\beta^{\\star} = [1.0, 0.0, 0.0, 0.0, 0.0]$, $\\alpha_0 = -0.2$, $q = 0.6$。\n\n程序要求：\n- 通过IRLS实现逻辑斯谛回归，并在观测信息矩阵上进行小的岭稳定化。使用标准化协变量并在模型中包含截距项。\n- 计算重要性度量 $I^{(\\text{coef})}_j$ 和 $I^{(\\text{wald})}_j$，通过秩平均进行聚合，并对每个测试案例按指定的比例 $q$ 进行剪枝。\n- 对于平衡性，如上所述，使用从完整模型和剪枝模型各自产生的倾向性得分生成的匹配，分别计算所有原始 $p$ 个协变量的 $\\text{mSMD}$。\n- 对于每个测试案例，输出单个浮点数 $\\Delta = \\text{mSMD}^{\\text{pruned}} - \\text{mSMD}^{\\text{full}}$。\n- 最终输出格式：您的程序应生成单行输出，其中包含三个测试案例的结果，形式为逗号分隔的列表，并用方括号括起来，每个浮点数精确到小数点后六位，例如，$\\texttt{[0.012345,-0.067890,0.000000]}$。\n\n无需用户输入。不涉及物理单位或角度。所有比例和概率必须以小数形式计算和呈现，不带百分号。", "solution": "用户提供了一个明确定义的统计模拟问题，其核心是倾向性得分分析。任务是实现一个从数据生成到模型拟合、变量选择、匹配和平衡性评估的完整流程。目标是量化倾向性得分模型中特定变量剪枝策略导致的协变量平衡性变化。\n\n### 1. 问题验证\n问题陈述已经过严格验证，并被确定为**有效**的。它在科学上基于既定的统计学和因果推断原则，问题设定良好，具有确定性的程序步骤，并以客观、正式的语言表述。所有必要的参数和定义都已提供，确保可以计算出唯一且可验证的解。\n\n### 2. 方法论框架与算法设计\n\n该解决方案通过构建一系列与分析的各个逻辑阶段相对应的函数来实现。\n\n#### 2.1. 数据生成\n对于每个测试案例，我们首先根据指定的参数 $(n, p, \\rho, \\text{seed}, \\beta^{\\star}, \\alpha_0)$ 模拟一个数据集。\n$p$ 维协变量 $X \\in \\mathbb{R}^{n \\times p}$ 从一个多元正态分布 $X \\sim \\mathcal{N}(0, \\Sigma)$ 中抽取。协方差矩阵 $\\Sigma$ 是一个自回归-1（AR-1）结构，其中 $\\Sigma_{ij} = \\rho^{\\lvert i-j \\rvert}$，对于 $i,j \\in \\{1, \\dots, p\\}$。该矩阵使用Toeplitz构造生成。\n然后为每个观测值 $i=1, \\dots, n$ 生成二元处理分配 $T \\in \\{0,1\\}^n$。接受处理的真实对数几率被建模为协变量的线性函数，$\\eta_i = \\alpha_0 + X_i^\\top \\beta^{\\star}$。然后，处理 $T_i$ 从一个伯努利分布中抽取，其概率为 $\\mathbb{P}(T_i = 1 \\mid X_i) = \\sigma(\\eta_i)$，其中 $\\sigma(u) = (1 + e^{-u})^{-1}$ 是logistic sigmoid函数。每个测试案例使用一个特定的随机种子以确保可复现性。\n\n#### 2.2. 协变量标准化与倾向性得分估计\n在拟合任何模型之前，生成的协变量 $X$ 被标准化，使每列的均值为0，标准差为1。设此标准化数据为 $X_{\\text{std}}$。此步骤确保基于系数的重要性度量 $I^{(\\text{coef})}$ 在不同协变量之间具有可比的尺度。\n\n倾向性得分 $e(x) = \\mathbb{P}(T=1 \\mid X=x)$ 使用逻辑斯谛回归模型 $\\text{logit}(e(x)) = \\gamma_0 + x_{\\text{std}}^\\top \\gamma$ 进行估计。我们使用迭代重加权最小二乘法（IRLS）算法来拟合此模型，这是Newton-Raphson方法在寻找参数 $\\gamma$（在问题描述中记为 $\\hat{\\beta}$，但我们在此用 $\\gamma$ 以区别于真实的 $\\beta^{\\star}$）的最大似然估计时的应用。IRLS的更新步骤是：\n$$ \\gamma^{(k+1)} = \\gamma^{(k)} + (X_{\\text{aug}}^\\top W^{(k)} X_{\\text{aug}} + \\lambda I)^{-1} X_{\\text{aug}}^\\top (T - \\mu^{(k)}) $$\n其中 $X_{\\text{aug}}$ 是增广了截距列的标准化协变量矩阵，$\\mu^{(k)} = \\sigma(X_{\\text{aug}}\\gamma^{(k)})$ 是在第 $k$ 次迭代时的预测概率，而 $W^{(k)}$ 是一个对角权重矩阵，其元素为 $W_{ii}^{(k)} = \\mu_i^{(k)}(1-\\mu_i^{(k)})$。项 $\\lambda I$ 表示一个小的岭惩罚（$\\lambda=10^{-8}$），加到Fisher信息矩阵 $(X_{\\text{aug}}^\\top W^{(k)} X_{\\text{aug}})$ 上，以确保数值稳定性，特别是在高度共线性的情况下。算法迭代进行，直到系数变化的L2范数低于容差 $10^{-7}$ 或达到最多25次迭代。\n该过程返回估计的系数 $\\hat{\\gamma}$ 及其估计的协方差矩阵 $\\widehat{\\text{Cov}}(\\hat{\\gamma}) = (X_{\\text{aug}}^\\top \\hat{W} X_{\\text{aug}} + \\lambda I)^{-1}$。\n\n#### 2.3. 变量重要性与剪枝\n为了识别用于剪枝的协变量，我们基于完整模型拟合结果为每个协变量 $j \\in \\{1, \\dots, p\\}$ 计算两种重要性度量：\n1.  绝对标准化系数大小：$I^{(\\text{coef})}_j = \\lvert \\hat{\\gamma}_j \\rvert$。\n2.  绝对Wald z-统计量：$I^{(\\text{wald})}_j = \\left| \\frac{\\hat{\\gamma}_j}{\\widehat{\\text{se}}(\\hat{\\gamma}_j)} \\right|$，其中 $\\widehat{\\text{se}}(\\hat{\\gamma}_j)$ 是从 $\\widehat{\\text{Cov}}(\\hat{\\gamma})$ 对角线元素的平方根得到的标准误。\n\n这两种度量通过秩平均进行聚合。对于每种度量，协变量从1到 $p$ 进行排序，使得重要性值越大，秩越高。平级关系通过将较低的秩分配给索引较小的协变量来确定性地打破。组合秩为 $r^{(\\text{comb})}_j = (r^{(\\text{coef})}_j + r^{(\\text{wald})}_j) / 2$。\n给定一个剪枝比例 $q$，我们保留组合秩最高的 $k = \\lceil (1-q)p \\rceil$ 个协变量。这定义了“剪枝后”的协变量集。然后，仅使用这个标准化协变量子集重新估计一个新的倾向性得分模型。\n\n#### 2.4. 一对一最近邻匹配\n对于完整模型和剪枝模型，我们都在估计的倾向性得分 $\\hat{e}$ 上执行无放回的一对一最近邻匹配。样本量较小的组（处理组或对照组）被指定为“锚定”组。锚定单位按其倾向性得分升序排序。对于每个锚定单位，我们在对立的（“目标”）组中找到一个倾向性得分绝对差 $d(i,k) = \\lvert \\hat{e}_i - \\hat{e}_k \\rvert$ 最小的单位。这个目标单位必须是之前未被匹配过的。距离上的平级关系通过选择原始行索引最小的目标单位来打破。此过程产生一个由配对组成的匹配样本，每对包含一个处理单位和一个对照单位。\n\n#### 2.5. 协变量平衡性评估\n匹配的有效性通过测量匹配样本中的协变量平衡性来评估。对于原始的 $p$ 个协变量（在其原始、未标准化的尺度上），我们计算标准化均值差（SMD）：\n$$ \\text{SMD}_j = \\frac{\\bar{x}^{(T=1)}_j - \\bar{x}^{(T=0)}_j}{\\sqrt{\\frac{s^{2,(T=1)}_j + s^{2,(T=0)}_j}{2}}} $$\n这里，$\\bar{x}^{(T=t)}_j$ 和 $s^{2,(T=t)}_j$ 分别是匹配子样本内处理组 $t$ 的协变量 $j$ 的样本均值和无偏样本方差。如果分母为零，$\\text{SMD}_j$ 定义为0。\n总体平衡性由平均绝对标准化均值差（mSMD）来概括，计算公式为 $\\text{mSMD} = \\frac{1}{p} \\sum_{j=1}^p \\lvert \\text{SMD}_j \\rvert$。\n\n#### 2.6. 评估协议\n对每个测试案例，整个流程执行两次：\n1.  **完整模型**：mSMD，记为 $\\text{mSMD}^{\\text{full}}$，使用从所有 $p$ 个协变量估计的倾向性得分衍生的匹配计算。\n2.  **剪枝模型**：mSMD，记为 $\\text{mSMD}^{\\text{pruned}}$，使用从剪枝后的协变量子集估计的倾向性得分衍生的匹配计算。\n\n为每个测试案例报告的最终指标是因剪枝引起的平衡性变化：$\\Delta = \\text{mSMD}^{\\text{pruned}} - \\text{mSMD}^{\\text{full}}$。$\\Delta$ 的负值表示变量剪枝策略改善了协变量的平衡性。", "answer": "```python\nimport numpy as np\nimport scipy.linalg\n\ndef generate_data(n, p, rho, seed, beta_star, alpha_0):\n    \"\"\"Generates synthetic data for a single test case.\"\"\"\n    rng = np.random.default_rng(seed)\n    # Generate covariates X ~ N(0, Sigma)\n    first_row = rho ** np.arange(p)\n    cov_matrix = scipy.linalg.toeplitz(first_row)\n    X = rng.multivariate_normal(np.zeros(p), cov_matrix, size=n)\n\n    # Generate treatment T ~ Bernoulli(sigma(alpha_0 + X @ beta_star))\n    eta = alpha_0 + X @ beta_star\n    prob_T = 1 / (1 + np.exp(-eta))\n    T = rng.binomial(1, prob_T)\n    \n    return X, T\n\ndef fit_logistic_irls(X, y, l2_penalty=1e-8, max_iter=25, tol=1e-7):\n    \"\"\"Fits logistic regression using Iteratively Reweighted Least Squares.\"\"\"\n    X_aug = np.hstack([np.ones((X.shape[0], 1)), X])\n    n_samples, n_features = X_aug.shape\n    beta = np.zeros(n_features)\n\n    for _ in range(max_iter):\n        eta = X_aug @ beta\n        mu = 1 / (1 + np.exp(-eta))\n        \n        gradient = X_aug.T @ (y - mu)\n        W_diag = mu * (1 - mu)\n        info_matrix = X_aug.T * W_diag @ X_aug\n        \n        # Add ridge stabilization\n        info_reg = info_matrix + l2_penalty * np.eye(n_features)\n        \n        delta_beta = np.linalg.solve(info_reg, gradient)\n        beta += delta_beta\n        \n        if np.linalg.norm(delta_beta)  tol:\n            break\n            \n    # Final Information Matrix and Covariance\n    eta = X_aug @ beta\n    mu = 1 / (1 + np.exp(-eta))\n    W_diag = mu * (1 - mu)\n    final_info_matrix = X_aug.T * W_diag @ X_aug\n    final_info_reg = final_info_matrix + l2_penalty * np.eye(n_features)\n    cov_beta = np.linalg.inv(final_info_reg)\n    \n    return beta, cov_beta\n\ndef get_pruning_indices(beta, cov_beta, p, q):\n    \"\"\"Determines which covariates to keep based on rank-averaged importance.\"\"\"\n    beta_coeffs = beta[1:]\n    se_beta = np.sqrt(np.diag(cov_beta))[1:]\n    \n    imp_coef = np.abs(beta_coeffs)\n    imp_wald = np.abs(np.divide(beta_coeffs, se_beta, out=np.zeros_like(beta_coeffs), where=se_beta != 0))\n    \n    covariate_indices = np.arange(p)\n    \n    # Ranking with tie-breaking: higher value -> higher rank. Tie -> smaller index -> smaller rank.\n    # Sort by (value, index) to achieve this.\n    sorted_by_coef = sorted(covariate_indices, key=lambda j: (imp_coef[j], j))\n    rank_coef = np.empty(p, dtype=int); rank_coef[sorted_by_coef] = np.arange(1, p + 1)\n    \n    sorted_by_wald = sorted(covariate_indices, key=lambda j: (imp_wald[j], j))\n    rank_wald = np.empty(p, dtype=int); rank_wald[sorted_by_wald] = np.arange(1, p + 1)\n    \n    rank_comb = (rank_coef + rank_wald) / 2\n    \n    num_to_keep = int(np.ceil((1 - q) * p))\n    # Sort indices by descending combined rank\n    indices_to_keep_sorted_by_rank = np.argsort(-rank_comb)\n    \n    kept_indices = indices_to_keep_sorted_by_rank[:num_to_keep]\n    return np.sort(kept_indices)\n\ndef perform_matching(pscores, T):\n    \"\"\"Performs 1-to-1 nearest neighbor matching without replacement.\"\"\"\n    treated_indices = np.where(T == 1)[0]\n    control_indices = np.where(T == 0)[0]\n    \n    if len(treated_indices) = len(control_indices):\n        anchor_indices, target_indices = treated_indices, control_indices\n        is_anchor_treated = True\n    else:\n        anchor_indices, target_indices = control_indices, treated_indices\n        is_anchor_treated = False\n        \n    sorted_anchor_indices = anchor_indices[np.argsort(pscores[anchor_indices])]\n    \n    target_pool = list(target_indices)\n    matched_targets = []\n    \n    for anchor_idx in sorted_anchor_indices:\n        anchor_pscore = pscores[anchor_idx]\n        \n        dists = np.abs(anchor_pscore - pscores[target_pool])\n        min_dist = np.min(dists)\n        \n        # Tie-breaking by smallest original index\n        candidate_pool_indices = np.where(dists == min_dist)[0]\n        candidate_original_indices = [target_pool[i] for i in candidate_pool_indices]\n        best_match_idx = min(candidate_original_indices)\n        \n        matched_targets.append(best_match_idx)\n        target_pool.remove(best_match_idx)\n        \n    matched_targets = np.array(matched_targets)\n    \n    if is_anchor_treated:\n        return sorted_anchor_indices, matched_targets\n    else:\n        return matched_targets, sorted_anchor_indices\n\ndef calculate_msmd(X_orig, matched_treated_indices, matched_control_indices):\n    \"\"\"Calculates the mean absolute standardized mean difference.\"\"\"\n    if len(matched_treated_indices) == 0 or len(matched_control_indices) == 0:\n        return 0.0\n\n    X_matched_treated = X_orig[matched_treated_indices, :]\n    X_matched_control = X_orig[matched_control_indices, :]\n    \n    mean_treated = np.mean(X_matched_treated, axis=0)\n    mean_control = np.mean(X_matched_control, axis=0)\n    \n    # Unbiased sample variance with ddof=1\n    var_treated = np.var(X_matched_treated, axis=0, ddof=1)\n    var_control = np.var(X_matched_control, axis=0, ddof=1)\n    \n    pooled_sd = np.sqrt((var_treated + var_control) / 2)\n    \n    smds = np.divide(mean_treated - mean_control, pooled_sd, out=np.zeros_like(pooled_sd), where=pooled_sd != 0)\n    \n    return np.mean(np.abs(smds))\n\ndef run_single_case(n, p, rho, seed, beta_star, alpha_0, q):\n    \"\"\"Executes the full pipeline for one test case.\"\"\"\n    # 1. Data Generation\n    X_orig, T = generate_data(n, p, rho, seed, beta_star, alpha_0)\n    \n    # 2. Standardization\n    X_mean = np.mean(X_orig, axis=0)\n    X_std = np.std(X_orig, axis=0)\n    X_std[X_std == 0] = 1.0  # Avoid division by zero for constant covariates\n    X_norm = (X_orig - X_mean) / X_std\n\n    # --- FULL MODEL ANALYSIS ---\n    beta_full, cov_beta_full = fit_logistic_irls(X_norm, T)\n    X_aug_full = np.hstack([np.ones((n, 1)), X_norm])\n    pscores_full = 1 / (1 + np.exp(-(X_aug_full @ beta_full)))\n    matched_treated_full, matched_control_full = perform_matching(pscores_full, T)\n    msmd_full = calculate_msmd(X_orig, matched_treated_full, matched_control_full)\n\n    # --- PRUNED MODEL ANALYSIS ---\n    indices_to_keep = get_pruning_indices(beta_full, cov_beta_full, p, q)\n    if len(indices_to_keep) > 0:\n        X_norm_pruned = X_norm[:, indices_to_keep]\n        beta_pruned, _ = fit_logistic_irls(X_norm_pruned, T)\n        X_aug_pruned = np.hstack([np.ones((n, 1)), X_norm_pruned])\n        pscores_pruned = 1 / (1 + np.exp(-(X_aug_pruned @ beta_pruned)))\n    else: # If all covariates are pruned, pscore is constant (based on intercept only)\n        beta_pruned_intercept_only, _ = fit_logistic_irls(np.empty((n,0)), T)\n        pscores_pruned = np.full(n, 1 / (1 + np.exp(-beta_pruned_intercept_only[0])))\n\n    matched_treated_pruned, matched_control_pruned = perform_matching(pscores_pruned, T)\n    msmd_pruned = calculate_msmd(X_orig, matched_treated_pruned, matched_control_pruned)\n    \n    # --- Final Result ---\n    delta = msmd_pruned - msmd_full\n    return delta\n\ndef solve():\n    \"\"\"Main function to run test suite and print results.\"\"\"\n    test_cases = [\n        # Test case A\n        dict(n=400, p=6, rho=0.3, seed=2021, beta_star=np.array([0.8, -0.7, 0.6, 0.0, 0.0, 0.0]), alpha_0=0.0, q=0.5),\n        # Test case B\n        dict(n=300, p=5, rho=0.2, seed=7, beta_star=np.array([0.0, 0.0, 0.0, 0.0, 0.0]), alpha_0=0.0, q=0.4),\n        # Test case C\n        dict(n=500, p=5, rho=0.9, seed=99, beta_star=np.array([1.0, 0.0, 0.0, 0.0, 0.0]), alpha_0=-0.2, q=0.6)\n    ]\n    \n    results = []\n    for params in test_cases:\n        delta = run_single_case(**params)\n        results.append(f\"{delta:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3162937"}]}