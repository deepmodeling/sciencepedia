{"hands_on_practices": [{"introduction": "GAN的训练过程以其不稳定性而著称，其中一个常见问题是判别器变得过于自信。这会导致为生成器提供的梯度消失，从而使训练停滞。标签平滑是一种简单而有效的正则化技术，通过将“真实”标签从 $1.0$ 略微下调（例如到 $0.9$），可以防止判别器过于确信，从而提供更平滑、更有意义的梯度。通过下面的练习，你将从第一性原理出发，推导标签平滑如何改变最优判别器的形式，并量化其对纳什均衡点的影响，从而深刻理解这一关键的稳定化技巧。[@problem_id:3124540]", "problem": "生成对抗网络 (GAN) 包含一个生成器和一个判别器。生成器在数据空间上建立一个模型分布 $p_{g}(x)$，判别器输出一个概率 $D(x) \\in (0,1)$，该概率表示 $x$ 来自真实数据分布 $p_{\\text{data}}(x)$ 的可能性。判别器通过最小化二元交叉熵进行训练，这等价于在真实样本和生成样本的混合体上最大化目标的期望对数似然。在标准训练中，真实样本的目标值为 $1$，生成样本的目标值为 $0$。在标签平滑中，真实样本的目标值被调整为一个值 $s \\in (0,1)$，而虚假样本的目标值保持平滑前的 $t=0$。\n\n假设判别器关于 $x$ 的目标函数是通过从 $p_{\\text{data}}(x)$ (目标值为 $s$) 和 $p_{g}(x)$ (目标值为 $t=0$) 采样而形成的期望二元交叉熵。在连续设定下进行推导，其中 $p_{\\text{data}}$ 和 $p_{g}$ 是在一个共同支撑集上的密度函数，并且通过对 $x$ 积分来计算期望。\n\n仅使用二元交叉熵的基本定义和 GAN 的极小化极大公式，从第一性原理推导：\n\n1) 在真实目标值为 $s=0.9$、虚假目标值为 $t=0$ 的标签平滑条件下，逐点最优判别器 $D^{*}(x)$，用 $p_{\\text{data}}(x)$ 和 $p_{g}(x)$ 表示。\n\n2) 在相同的标签平滑条件下，当生成器与数据匹配时（即 $p_{g}(x) = p_{\\text{data}}(x)$），在极小化极大均衡点处的最大化判别器目标值。通过计算为 $s=0.9$ 和 $t=0$ 得到的闭式表达式，将该均衡值表示为一个实数。\n\n请将您的最终答案以一个两元素行向量 $\\big[D^{*}(x), V^{*}\\big]$ 的形式给出，其中 $V^{*}$ 是均衡值。将该数值均衡值四舍五入到四位有效数字。无需单位。", "solution": "判别器 $D$ 的目标是最大化价值函数 $V(D,G)$，该函数表示正确识别真实样本和生成样本的对数似然。真实样本的训练目标值被平滑为 $s$，生成样本的训练目标值为 $t$。目标函数是真实数据分布 $p_{\\text{data}}(x)$ 和生成器分布 $p_g(x)$ 上的期望对数似然之和。\n\n对于给定的样本 $x$，其判别器输出为 $D(x)$，目标标签为 $y$，其对数似然由二元交叉熵表达式给出：$y \\ln(D(x)) + (1-y) \\ln(1-D(x))$。\n\n总价值函数 $V(D)$ 通过对所有 $x$ 积分来构建：\n$$V(D) = \\mathbb{E}_{x \\sim p_{\\text{data}}(x)} [s \\ln(D(x)) + (1-s) \\ln(1-D(x))] + \\mathbb{E}_{x \\sim p_g(x)} [t \\ln(D(x)) + (1-t) \\ln(1-D(x))]$$\n在具有密度函数的连续设定中，这变为：\n$$V(D) = \\int p_{\\text{data}}(x) [s \\ln(D(x)) + (1-s) \\ln(1-D(x))] dx + \\int p_g(x) [t \\ln(D(x)) + (1-t) \\ln(1-D(x))] dx$$\n为了找到在生成器固定的情况下最大化此值的最优判别器 $D^*(x)$，我们可以对每个 $x$ 逐点最大化被积函数。设被积函数为 $f(D(x))$：\n$$f(D(x)) = p_{\\text{data}}(x)[s \\ln(D(x)) + (1-s) \\ln(1-D(x))] + p_g(x)[t \\ln(D(x)) + (1-t) \\ln(1-D(x))]$$\n我们合并含有 $\\ln(D(x))$ 和 $\\ln(1-D(x))$ 的项：\n$$f(D(x)) = [s \\cdot p_{\\text{data}}(x) + t \\cdot p_g(x)] \\ln(D(x)) + [(1-s) p_{\\text{data}}(x) + (1-t) p_g(x)] \\ln(1-D(x))$$\n该函数具有 $A \\ln(y) + B \\ln(1-y)$ 的形式，其中 $y=D(x)$，且：\n$A = s \\cdot p_{\\text{data}}(x) + t \\cdot p_g(x)$\n$B = (1-s) p_{\\text{data}}(x) + (1-t) p_g(x)$\n\n为了求最大值，我们计算关于 $y$ 的导数并令其为 0：\n$$\\frac{df}{dy} = \\frac{A}{y} - \\frac{B}{1-y} = 0 \\implies A(1-y) = By \\implies y = \\frac{A}{A+B}$$\n将 $A$ 和 $B$ 代回，最优判别器 $D^*(x)$ 为：\n$$D^*(x) = \\frac{s \\cdot p_{\\text{data}}(x) + t \\cdot p_g(x)}{(s \\cdot p_{\\text{data}}(x) + t \\cdot p_g(x)) + ((1-s) p_{\\text{data}}(x) + (1-t) p_g(x))}$$\n分母化简为：\n$$s \\cdot p_{\\text{data}}(x) + t \\cdot p_g(x) + p_{\\text{data}}(x) - s \\cdot p_{\\text{data}}(x) + p_g(x) - t \\cdot p_g(x) = p_{\\text{data}}(x) + p_g(x)$$\n因此，最优判别器的通解为：\n$$D^*(x) = \\frac{s \\cdot p_{\\text{data}}(x) + t \\cdot p_g(x)}{p_{\\text{data}}(x) + p_g(x)}$$\n\n**1) 特定标签平滑下的最优判别器**\n\n对于给定的特定情况，真实目标值为 $s=0.9$，虚假目标值为 $t=0$。将这些值代入 $D^*(x)$ 的通式中：\n$$D^*(x) = \\frac{0.9 \\cdot p_{\\text{data}}(x) + 0 \\cdot p_g(x)}{p_{\\text{data}}(x) + p_g(x)} = \\frac{0.9 \\cdot p_{\\text{data}}(x)}{p_{\\text{data}}(x) + p_g(x)}$$\n这就是逐点最优判别器的表达式。\n\n**2) 均衡点处的最大化目标值**\n\n在极小化极大均衡点，生成器完美地模仿了真实数据分布，因此 $p_g(x) = p_{\\text{data}}(x)$。我们首先求出此均衡点处最优判别器的值：\n$$D^*_{\\text{eq}}(x) = \\frac{0.9 \\cdot p_{\\text{data}}(x)}{p_{\\text{data}}(x) + p_{\\text{data}}(x)} = \\frac{0.9 \\cdot p_{\\text{data}}(x)}{2 \\cdot p_{\\text{data}}(x)} = \\frac{0.9}{2} = 0.45$$\n在均衡点，最优判别器输出一个恒定的概率 $0.45$，与输入 $x$ 无关。\n\n接下来，我们使用 $D(x) = D^*_{\\text{eq}}(x) = 0.45$、均衡条件 $p_g(x) = p_{\\text{data}}(x)$ 以及标签 $s=0.9, t=0$ 来计算价值函数 $V(D)$。设最大化的均衡值为 $V^*$。\n$$V^* = \\int p_{\\text{data}}(x) [0.9 \\ln(0.45) + (1-0.9) \\ln(1-0.45)] dx + \\int p_{\\text{data}}(x) [0 \\ln(0.45) + (1-0) \\ln(1-0.45)] dx$$\n$$V^* = \\int p_{\\text{data}}(x) [0.9 \\ln(0.45) + 0.1 \\ln(0.55)] dx + \\int p_{\\text{data}}(x) [\\ln(0.55)] dx$$\n由于方括号内的项是常数，它们可以从积分中提出来。我们利用 $\\int p_{\\text{data}}(x) dx = 1$ 这一事实。\n$$V^* = [0.9 \\ln(0.45) + 0.1 \\ln(0.55)] \\int p_{\\text{data}}(x) dx + [\\ln(0.55)] \\int p_{\\text{data}}(x) dx$$\n$$V^* = (0.9 \\ln(0.45) + 0.1 \\ln(0.55)) \\cdot 1 + \\ln(0.55) \\cdot 1$$\n$$V^* = 0.9 \\ln(0.45) + 0.1 \\ln(0.55) + 1.0 \\ln(0.55)$$\n$$V^* = 0.9 \\ln(0.45) + 1.1 \\ln(0.55)$$\n现在，我们计算其数值：\n$\\ln(0.45) \\approx -0.7985077$\n$\\ln(0.55) \\approx -0.5978370$\n$$V^* \\approx 0.9 \\times (-0.7985077) + 1.1 \\times (-0.5978370)$$\n$$V^* \\approx -0.71865693 - 0.65762070$$\n$$V^* \\approx -1.37627763$$\n四舍五入到四位有效数字，我们得到 $V^* = -1.376$。\n最终答案由 $D^*(x)$ 的表达式和 $V^*$ 的数值组成。", "answer": "$$ \\boxed{ \\left[ \\frac{0.9 \\cdot p_{\\text{data}}(x)}{p_{\\text{data}}(x) + p_g(x)}, -1.376 \\right] } $$", "id": "3124540"}, {"introduction": "一个标准的GAN架构在理论上存在某些固有的局限性。一个深刻的例子是，当目标数据分布由多个相互分离的“簇”组成时（例如，包含猫和狗两个类别的图像数据集），一个由连续函数构成的标准生成器无法完美地对这种“断开的”分布进行建模。这个练习将引导你通过拓扑学的基本原理来理解这一限制，并评估不同的架构设计（如混合专家模型）是如何从根本上克服这一挑战，从而生成多样化且覆盖多个模式的样本。[@problem_id:3124513]", "problem": "考虑一个生成对抗网络 (GAN)，它包含一个生成器 $G$ 和一个判别器 $D$。设潜变量 $Z$ 服从 $\\mathbb{R}^m$ 上的一个先验分布 $p_Z$，数据分布 $p_{\\text{data}}$ 支撑于 $\\mathbb{R}^n$ 的一个子集上。生成器通过 $G$ 对 $p_Z$ 的前推 (pushforward) 导出一个模型分布 $p_G$，记作 $p_G = G_{\\#} p_Z$。假设以下基本事实：(i) 一个概率分布 $p$ 的支撑集 $\\mathrm{supp}(p)$ 是具有全测度的最小闭集，等价于这样一个点集的闭包：该集合中任意一点的任意开邻域都具有正概率；(ii) 对于一个连续映射 $G:\\mathbb{R}^m \\to \\mathbb{R}^n$，一个连通集 $S \\subset \\mathbb{R}^m$ 的像 $G(S)$ 是连通的，并且一个连通集的闭包是连通的；(iii) 如果 $p_Z$ 在 $\\mathbb{R}^m$ 上具有全支撑（即每个非空开集都具有正概率），那么 $G_{\\#} p_Z$ 的支撑集包含 $G(\\mathbb{R}^m)$ 并等于其闭包。假设 $p_{\\text{data}}$ 支撑于 $S_{\\text{data}} = M_1 \\cup M_2$，其中 $M_1$ 和 $M_2$ 是 $\\mathbb{R}^n$ 的不相交、紧致、光滑的子流形（为具体起见，可将 $M_1$ 和 $M_2$ 看作 $\\mathbb{R}^2$ 中两个间隔很远的圆），这使得 $S_{\\text{data}}$ 不连通。假设 $p_Z$ 是 $\\mathbb{R}^m$ 上的标准高斯分布，$G$ 是一个神经网络，作为函数 $\\mathbb{R}^m \\to \\mathbb{R}^n$ 是连续的，并且训练旨在最小化 $p_{\\text{data}}$ 和 $p_G$ 之间的散度（例如，Jensen–Shannon 散度 $D_{\\mathrm{JSD}}$ 或 Wasserstein 距离 $W$）。\n\n基于这些基础，推理 $\\mathrm{supp}(p_G)$ 上的拓扑约束，以及标准训练是否能克服这些约束。然后评估为解决不连通支撑集问题而提出的架构变更。\n\n以下哪些陈述是正确的？\n\nA. 如果 $G$ 是连续的且 $p_Z$ 具有连通的支撑集（例如，在 $\\mathbb{R}^m$ 上具有全支撑），那么 $\\mathrm{supp}(p_G)$ 是连通的（实际上 $\\mathrm{supp}(p_G) = \\overline{G(\\mathbb{R}^m)}$），因此 $p_G$ 无法精确匹配一个支撑集 $S_{\\text{data}}$ 不连通的 $p_{\\text{data}}$。\n\nB. 引入一个独立于 $Z$ 的离散潜选择器 $S \\in \\{1,\\dots,K\\}$，并定义 $G(Z,S) = G_S(Z)$，其中每个 $G_k$ 都是连续的，这会产生 $p_G(\\cdot) = \\sum_{k=1}^K \\pi_k \\,(G_k)_{\\#} p_Z$，其支撑集为 $\\mathrm{supp}(p_G) = \\bigcup_{k=1}^K \\overline{G_k(\\mathbb{R}^m)}$，这个支撑集可以是不连通的，因此可以覆盖像 $M_1 \\cup M_2$ 这样的不相交模式。\n\nC. 将训练目标从 Jensen–Shannon 散度 $D_{\\mathrm{JSD}}$ 切换到 Wasserstein 距离 $W$，能让一个具有连通潜支撑集的单个连续生成器生成一个模型分布 $p_G$，其支撑集在训练过程中变得不连通，从而消除了拓扑限制。\n\nD. 将先验 $p_Z$ 替换为具有不同均值的两个高斯分布的混合，会使 $\\mathrm{supp}(p_Z)$ 变得不连通，因此单个连续生成器可以精确表示具有不相交支撑集的 $p_{\\text{data}}$。\n\nE. 使用一个连续门控函数 $h:\\mathbb{R}^m \\to \\Delta^{K-1}$（$(K-1)$-单纯形）并定义 $G(\\mathbf{z}) = \\sum_{k=1}^K h_k(\\mathbf{z})\\,G_k(\\mathbf{z})$，会产生一个等于 $\\bigcup_{k=1}^K G_k(\\mathbb{R}^m)$ 的支撑集，并且可以在不引入任何离散变量的情况下表示不连通的支撑集。\n\n选择所有适用的选项。", "solution": "该问题要求分析由生成对抗网络（GAN）生成的分布的支撑集的拓扑性质，并评估对标准 GAN 架构提出的几种修改。问题的核心在于标准生成器映射的拓扑性质与目标数据分布的性质之间的冲突。\n\n让我们根据给定条件建立基本论证。\n1.  潜变量 $Z$ 服从 $p_Z$ 分布，即 $\\mathbb{R}^m$ 上的标准高斯分布。标准高斯分布的支撑集 $\\mathrm{supp}(p_Z)$ 是整个空间 $\\mathbb{R}^m$。\n2.  对于任何维度 $m \\ge 1$，集合 $\\mathbb{R}^m$ 是一个路径连通空间，因此也是一个连通空间。\n3.  生成器 $G$ 是一个神经网络，根据陈述，它是一个连续函数 $G: \\mathbb{R}^m \\to \\mathbb{R}^n$。\n4.  拓扑学中的一个基本定理，即作为事实(ii)给出的定理，指出连通集在连续映射下的像是连通的。因此，潜空间在生成器下的像 $G(\\mathrm{supp}(p_Z)) = G(\\mathbb{R}^m)$ 是 $\\mathbb{R}^n$ 的一个连通子集。\n5.  事实(iii)指出，由于 $p_Z$ 在 $\\mathbb{R}^m$ 上有全支撑，生成分布 $p_G$ 的支撑集是生成器像的闭包：$\\mathrm{supp}(p_G) = \\overline{G(\\mathbb{R}^m)}$。\n6.  事实(ii)还指出，连通集的闭包是连通的。由于 $G(\\mathbb{R}^m)$ 是连通的，其闭包 $\\overline{G(\\mathbb{R}^m)}$ 也是连通的。\n7.  综合以上几点，生成分布的支撑集 $\\mathrm{supp}(p_G)$ 必然是一个连通集。\n8.  问题陈述，目标数据分布的支撑集 $S_{\\text{data}} = \\mathrm{supp}(p_{\\text{data}})$ 是两个不相交集合的并集，$S_{\\text{data}} = M_1 \\cup M_2$。根据定义，一个由两个非空不相交闭集（紧致集是闭集）的并集构成的集合是不连通的。\n9.  要使生成器完美学习目标分布，我们需要 $p_G = p_{\\text{data}}$。此等式成立的一个必要条件是它们的支撑集必须相同：$\\mathrm{supp}(p_G) = \\mathrm{supp}(p_{\\text{data}})$。\n10. 这导致了一个矛盾：$\\mathrm{supp}(p_G)$ 必须是连通的，而 $\\mathrm{supp}(p_{\\text{data}})$ 是不连通的。因此，对于一个具有连续生成器和连通潜支撑集的标准 GAN 来说，在拓扑学上不可能精确地建模一个具有不连通支撑集的分布。\n\n在建立了这个主要结论之后，让我们来评估每个选项。\n\n**A. 如果 $G$ 是连续的且 $p_Z$ 具有连通的支撑集（例如，在 $\\mathbb{R}^m$ 上具有全支撑），那么 $\\mathrm{supp}(p_G)$ 是连通的（实际上 $\\mathrm{supp}(p_G) = \\overline{G(\\mathbb{R}^m)}$），因此 $p_G$ 无法精确匹配一个支撑集 $S_{\\text{data}}$ 不连通的 $p_{\\text{data}}$。**\n\n这个陈述是对上述基本论证的精确表述。前提（$G$ 是连续的，$\\mathrm{supp}(p_Z)$ 是连通的）基于所提供的关于连续映射和闭包的事实，直接导出了 $\\mathrm{supp}(p_G)$ 是连通的结论。由于目标支撑集 $S_{\\text{data}}$ 是不连通的，所以支撑集无法匹配，因此分布也不能相等。该推理是合理的，并且直接源于问题陈述和标准的拓扑学原理。\n\n结论：**正确**。\n\n**B. 引入一个独立于 $Z$ 的离散潜选择器 $S \\in \\{1,\\dots,K\\}$，并定义 $G(Z,S) = G_S(Z)$，其中每个 $G_k$ 都是连续的，这会产生 $p_G(\\cdot) = \\sum_{k=1}^K \\pi_k \\,(G_k)_{\\#} p_Z$，其支撑集为 $\\mathrm{supp}(p_G) = \\bigcup_{k=1}^K \\overline{G_k(\\mathbb{R}^m)}$，这个支撑集可以是不连通的，因此可以覆盖像 $M_1 \\cup M_2$ 这样的不相交模式。**\n\n这描述了一个混合模型生成器。生成过程首先从一个概率为 $\\pi_k = P(S=k)$ 的分类分布中采样一个离散类别 $k$，然后使用相应的连续生成器 $G_k(Z)$ 生成一个样本。得到的概率分布 $p_G$ 是由每个“专家”生成器 $G_k$ 生成的分布的混合。总体密度（非正式地）是 $p_G = \\sum_{k=1}^K \\pi_k p_{G_k}$，其中 $p_{G_k}$ 是对应于 $(G_k)_{\\#} p_Z$ 的分布。\n\n混合分布的支撑集是其组分分布的支撑集的并集。对于每个组分 $k$，生成器 $G_k$ 是连续的，因此根据我们的主要论证，其支撑集 $\\mathrm{supp}((G_k)_{\\#}p_Z)$ 是连通集 $\\overline{G_k(\\mathbb{R}^m)}$。因此，总体分布 $p_G$ 的支撑集是 $\\mathrm{supp}(p_G) = \\bigcup_{k=1}^K \\mathrm{supp}((G_k)_{\\#}p_Z) = \\bigcup_{k=1}^K \\overline{G_k(\\mathbb{R}^m)}$。\n\n连通集的并集不一定是连通的。对于支撑集为 $S_{\\text{data}} = M_1 \\cup M_2$ 的目标分布，我们可以使用 $K=2$ 个生成器。我们可以训练 $G_1$ 使其像 $G_1(\\mathbb{R}^m)$ 接近 $M_1$，训练 $G_2$ 使其像 $G_2(\\mathbb{R}^m)$ 接近 $M_2$。由于 $M_1$ 和 $M_2$ 不相交，两个组分分布的支撑集 $\\overline{G_1(\\mathbb{R}^m)}$ 和 $\\overline{G_2(\\mathbb{R}^m)}$ 也可以是不相交的。因此，它们的并集是一个不连通的集合，可以成功地匹配 $S_{\\text{data}}$ 的拓扑结构。该陈述正确地描述了支撑集的数学形式及其可以不连通的能力。\n\n结论：**正确**。\n\n**C. 将训练目标从 Jensen–Shannon 散度 $D_{\\mathrm{JSD}}$ 切换到 Wasserstein 距离 $W$，能让一个具有连通潜支撑集的单个连续生成器生成一个模型分布 $p_G$，其支撑集在训练过程中变得不连通，从而消除了拓扑限制。**\n\n散度或距离度量（$D_{\\mathrm{JSD}}$、$W$ 等）的选择会影响优化景观和训练过程中梯度的行为。Wasserstein 距离特别有用，因为它即使在两个分布的支撑集不相交时也能提供不会消失的梯度。然而，损失函数的选择不能改变生成器函数 $G$ 的基本拓扑性质。如前所述，如果 $G$ 是一个连续函数，且其定义域（$\\mathrm{supp}(p_Z) = \\mathbb{R}^m$）是连通的，那么其值域的像 $G(\\mathbb{R}^m)$ 和支撑集 $\\mathrm{supp}(p_G) = \\overline{G(\\mathbb{R}^m)}$ 必然是连通的。这是函数本身的性质，与其如何被训练无关。该陈述声称支撑集“变得不连通”在给定的架构约束下是拓扑学上不可能的。\n\n结论：**不正确**。\n\n**D. 将先验 $p_Z$ 替换为具有不同均值的两个高斯分布的混合，会使 $\\mathrm{supp}(p_Z)$ 变得不连通，因此单个连续生成器可以精确表示具有不相交支撑集的 $p_{\\text{data}}$。**\n\n这个陈述的前提是有缺陷的。在 $\\mathbb{R}^m$ 中，高斯分布的混合，例如 $p_Z(\\mathbf{z}) = \\alpha_1 \\phi(\\mathbf{z}; \\mu_1, \\Sigma_1) + \\alpha_2 \\phi(\\mathbf{z}; \\mu_2, \\Sigma_2)$，其概率密度函数是正函数的加权和。由于高斯密度 $\\phi$ 对 $\\mathbb{R}^m$ 中的所有输入都严格为正，因此得到的混合密度 $p_Z(\\mathbf{z})$ 对所有 $\\mathbf{z} \\in \\mathbb{R}^m$ 也严格为正。根据所提供的支撑集的定义（“该集合中任意一点的任意开邻域都具有正概率的点的集合的闭包”），如果密度处处为正，则支撑集是整个空间 $\\mathbb{R}^m$。集合 $\\mathbb{R}^m$ 是连通的。因此，用高斯混合替换先验分布*不会*使其支撑集变得不连通。由于先验分布的支撑集保持连通，对 $p_G$ 支撑集的最初拓扑限制仍然成立。\n\n结论：**不正确**。\n\n**E. 使用一个连续门控函数 $h:\\mathbb{R}^m \\to \\Delta^{K-1}$（$(K-1)$-单纯形）并定义 $G(\\mathbf{z}) = \\sum_{k=1}^K h_k(\\mathbf{z})\\,G_k(\\mathbf{z})$，会产生一个等于 $\\bigcup_{k=1}^K G_k(\\mathbb{R}^m)$ 的支撑集，并且可以在不引入任何离散变量的情况下表示不连通的支撑集。**\n\n这个架构将生成器 $G(\\mathbf{z})$ 定义为几个“专家”生成器 $G_k(\\mathbf{z})$ 的逐点凸组合。每个 $G_k$ 是连续的，门控函数 $h$ 也是连续的。连续函数的复合、和与积都是连续的。因此，总体映射 $G: \\mathbb{R}^m \\to \\mathbb{R}^n$ 是一个单一的连续函数。这样我们就回到了最初的情景：一个从连通的潜空间 $\\mathbb{R}^m$ 到数据空间 $\\mathbb{R}^n$ 的连续映射。根据同样的拓扑论证，所得分布的支撑集 $\\mathrm{supp}(p_G) = \\overline{G(\\mathbb{R}^m)}$ 必须是一个连通集。这种架构无法生成具有不连通支撑集的分布。此外，该陈述错误地声称支撑集是 $\\bigcup_{k=1}^K G_k(\\mathbb{R}^m)$。生成器的像是 $G(\\mathbb{R}^m) = \\{ \\sum_{k=1}^K h_k(\\mathbf{z})G_k(\\mathbf{z}) \\mid \\mathbf{z} \\in \\mathbb{R}^m \\}$，这与各个像的并集不同。连续的凸组合可以在原本分离的区域之间创建“桥梁”，从而增强了总像的连通性。\n\n结论：**不正确**。", "answer": "$$\\boxed{AB}$$", "id": "3124513"}, {"introduction": "在GAN的训练中，维持生成器和判别器之间的“军备竞赛”平衡至关重要。如果判别器学习得太慢，它无法为生成器提供有效的学习信号；如果它学习得太快，生成器又可能无法跟上。一个常见的实践技巧是，在每进行一次生成器更新之前，对判别器进行 $k$ 次更新。这个编码练习将让你在一个简化的环境中，通过经验性地探索不同 $k$ 值对训练稳定性的影响，来亲手绘制出稳定与不稳定区域的“相图”，从而对GAN训练的动态平衡有更直观的认识。[@problem_id:3128933]", "problem": "给定一个简化的生成对抗网络（GAN）实验，旨在分析在单维高斯数据集上，每个生成器步骤交替进行 $k$ 个判别器步骤如何影响训练稳定性。该实验基于以下第一性原理：一个生成器 $G$ 将标准正态噪声 $z \\sim \\mathcal{N}(0,1)$ 转换为 $x_g = a z + b$，一个判别器 $D$ 通过 $D(x) = \\sigma(w x + c)$ 估计输入为真实样本的概率，其中 $\\sigma$ 是 logistic sigmoid 函数。真实数据分布为 $x \\sim \\mathcal{N}(\\mu_r, \\sigma_r^2)$。判别器最大化正确分类真实样本和伪造样本的期望对数似然，而生成器则基于判别器的输出最小化非饱和损失。\n\n从深度学习和概率论中的以下基本依据和核心定义出发：\n- 生成对抗网络（GAN）的目标是生成器和判别器之间的双人极小极大博弈，该博弈由数据和噪声分布上的期望值驱动。\n- 基于梯度的学习动态使用蒙特卡洛样本来近似这些期望，并应用梯度上升进行最大化，应用梯度下降进行最小化。\n- 对于线性生成器 $G(z) = a z + b$，其中 $z \\sim \\mathcal{N}(0,1)$，生成器导出的分布是均值为 $b$、标准差为 $|a|$ 的高斯分布。\n- logistic sigmoid 函数为 $\\sigma(s) = \\frac{1}{1 + e^{-s}}$，求梯度所需的导数恒等式在统计学和机器学习中已经过充分检验。\n\n你的任务：\n1. 构建交替梯度动态：对于生成器参数 $(a,b)$ 在其非饱和目标上进行的每一次梯度下降更新，判别器参数 $(w,c)$ 在其目标上进行 $k$ 次梯度上升更新。对双方玩家使用固定批量大小和固定学习率的蒙特卡洛估计。通过控制输入域来确保 $\\sigma$ 的数值稳定性。\n2. 定义训练稳定性的经验性概念。使用以下复合标准：令 $d_t = \\sqrt{(\\mu_g(t) - \\mu_r)^2 + (\\sigma_g(t) - \\sigma_r)^2}$，其中 $\\mu_g(t) = b(t)$ 和 $\\sigma_g(t) = |a(t)|$ 是生成器在训练步骤 $t$ 时的均值和标准差。定义改进分数 $I = \\frac{d_0 - d_T}{\\max(d_0, \\epsilon)}$，其中 $\\epsilon$ 是一个很小的数；并定义振荡指数 $O = \\frac{\\sum_{t=1}^T \\|\\theta_g(t) - \\theta_g(t-1)\\|_2}{\\|\\theta_g(T) - \\theta_g(0)\\|_2 + \\epsilon}$，其中 $\\theta_g(t) = [a(t), b(t)]^\\top$。如果参数保持有限且有界，$I$ 超过最小阈值，且 $O$ 低于最大阈值，则将一次运行分类为稳定。\n3. 通过在一个简单数据集上对多个 $k$ 值运行训练，凭经验推导稳定性与 $k$ 的关系相图，并报告每次运行是稳定还是不稳定，稳定编码为 $1$，不稳定编码为 $0$。\n\n使用以下数据集、训练和评估设置：\n- 真实数据参数 $(\\mu_r, \\sigma_r)$ 和调度参数 $k$ 因测试用例而异。\n- 噪声分布为 $z \\sim \\mathcal{N}(0,1)$。\n- 生成器为 $G(z) = a z + b$，初始化为 $a = 0.2$ 和 $b = 0.0$。\n- 判别器为 $D(x) = \\sigma(w x + c)$，$(w,c)$ 初始化为 $(0.0, 0.0)$。\n- 判别器目标是真实样本上的 $\\log D(x)$ 和伪造样本上的 $\\log(1 - D(G(z)))$ 的期望总和；判别器使用梯度上升。\n- 生成器目标是 $- \\log D(G(z))$ 的期望值（非饱和）；生成器使用梯度下降。\n- 使用学习率 $\\alpha_D = 0.05$ 和 $\\alpha_G = 0.02$，批量大小 $B = 1024$，以及 $T = 200$ 个生成器步骤。\n- 为保证数值稳定性，在应用 $\\sigma(s)$ 之前，将 sigmoid 输入 $s$ 裁剪到区间 $[-50, 50]$。\n\n定义稳定性分类阈值和保障措施：\n- 使用 $\\epsilon = 10^{-8}$ 进行分母稳定化。\n- 如果任何参数的绝对值在任何时候超过 $100$ 或变为非数字（not-a-number），则声明为发散。\n- 使用阈值 $I_{\\min} = 0.25$ 和 $O_{\\max} = 2.5$。\n- 一次运行是稳定的，如果它不发散，并且 $I \\ge I_{\\min}$ 且 $O \\le O_{\\max}$。\n\n测试套件：\n- 情况 1：$(\\mu_r, \\sigma_r, k, \\text{seed}) = (0.0, 1.0, 0, 42)$。\n- 情况 2：$(\\mu_r, \\sigma_r, k, \\text{seed}) = (0.0, 1.0, 1, 42)$。\n- 情况 3：$(\\mu_r, \\sigma_r, k, \\text{seed}) = (0.0, 1.0, 5, 42)$。\n- 情况 4：$(\\mu_r, \\sigma_r, k, \\text{seed}) = (2.0, 0.5, 2, 123)$。\n- 情况 5：$(\\mu_r, \\sigma_r, k, \\text{seed}) = (-1.0, 1.5, 10, 7)$。\n\n要求的最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$[r_1,r_2,r_3,r_4,r_5]$），其中每个 $r_i$ 是一个整数，$1$ 表示稳定运行，$0$ 表示不稳定运行。", "solution": "该问题要求对一个简化的生成对抗网络（GAN）的训练稳定性进行经验性研究，该稳定性是判别器每次更新次数 $k$（对应于生成器的一次更新）的函数。这包括推导基于梯度的学习动态、实现模拟，并根据一组指定的稳定性标准评估结果。\n\n首先，我们将模型的组件形式化。真实数据分布是一个一维高斯分布，$x \\sim \\mathcal{N}(\\mu_r, \\sigma_r^2)$。生成器 $G$ 通过一个线性变换将一个标准正态噪声变量 $z \\sim \\mathcal{N}(0,1)$ 映射到一个样本 $x_g$：\n$$G(z) = a z + b$$\n生成器的参数是 $\\theta_G = (a, b)$。因此，由生成器导出的分布也是高斯分布，其均值为 $\\mu_g = b$，标准差为 $\\sigma_g = |a|$。判别器 $D$ 是一个逻辑回归器，它建模了输入 $x$ 来自真实数据分布的概率：\n$$D(x) = \\sigma(w x + c)$$\n其中 $\\sigma(s) = (1 + e^{-s})^{-1}$ 是 logistic sigmoid 函数。判别器的参数是 $\\theta_D = (w,c)$。\n\n训练过程是一个极小极大博弈。训练判别器以最大化目标函数 $V_D$，该函数是正确分类真实样本和伪造样本的对数似然之和：\n$$V_D(\\theta_D, \\theta_G) = \\mathbb{E}_{x \\sim p_{data}(x)}[\\log D(x)] + \\mathbb{E}_{z \\sim p_z(z)}[\\log(1 - D(G(z)))]$$\n训练生成器以最小化非饱和目标函数 $V_G$，该函数旨在生成被判别器分类为真实的样本：\n$$V_G(\\theta_G) = -\\mathbb{E}_{z \\sim p_z(z)}[\\log D(G(z))]$$\n\n为了实现学习动态，我们推导这些目标函数关于模型参数的梯度。期望值通过对一个大小为 $B$ 的批量进行蒙特卡洛估计来近似。\n\n判别器目标 $V_D$ 关于其参数 $w$ 和 $c$ 的梯度是使用链式法则和 sigmoid 函数的导数性质求得的，特别是 $\\frac{d}{ds}\\log \\sigma(s) = 1 - \\sigma(s)$ 和 $\\frac{d}{ds}\\log(1-\\sigma(s)) = -\\sigma(s)$。对于一批真实数据 $\\{x_i\\}_{i=1}^B$ 和生成数据 $\\{x_{g,i}\\}_{i=1}^B$，梯度为：\n$$ \\nabla_w \\hat{V}_D = \\frac{1}{B} \\sum_{i=1}^B \\left( (1 - D(x_i))x_i - D(x_{g,i})x_{g,i} \\right) $$\n$$ \\nabla_c \\hat{V}_D = \\frac{1}{B} \\sum_{i=1}^B \\left( (1 - D(x_i)) - D(x_{g,i}) \\right) $$\n判别器参数通过梯度上升更新：\n$$ w \\leftarrow w + \\alpha_D \\nabla_w \\hat{V}_D $$\n$$ c \\leftarrow c + \\alpha_D \\nabla_c \\hat{V}_D $$\n\n生成器的非饱和目标 $V_G$ 关于其参数 $a$ 和 $b$ 的梯度是：\n$$ \\nabla_a V_G = \\frac{\\partial V_G}{\\partial a} = -\\mathbb{E}_z\\left[ \\frac{\\partial}{\\partial a} \\log D(az+b) \\right] = -\\mathbb{E}_z\\left[ (1 - D(G(z))) \\frac{\\partial(w(az+b)+c)}{\\partial a} \\right] = -\\mathbb{E}_z\\left[ (1 - D(G(z))) w z \\right] $$\n$$ \\nabla_b V_G = \\frac{\\partial V_G}{\\partial b} = -\\mathbb{E}_z\\left[ \\frac{\\partial}{\\partial b} \\log D(az+b) \\right] = -\\mathbb{E}_z\\left[ (1 - D(G(z))) \\frac{\\partial(w(az+b)+c)}{\\partial b} \\right] = -\\mathbb{E}_z\\left[ (1 - D(G(z))) w \\right] $$\n用一批噪声 $\\{z_i\\}_{i=1}^B$ 进行近似，生成器参数通过梯度下降更新：\n$$ a \\leftarrow a - \\alpha_G \\left( -\\frac{w}{B} \\sum_{i=1}^B (1 - D(G(z_i))) z_i \\right) = a + \\frac{\\alpha_G w}{B} \\sum_{i=1}^B (1 - D(G(z_i))) z_i $$\n$$ b \\leftarrow b - \\alpha_G \\left( -\\frac{w}{B} \\sum_{i=1}^B (1 - D(G(z_i))) \\right) = b + \\frac{\\alpha_G w}{B} \\sum_{i=1}^B (1 - D(G(z_i))) $$\n\n完整的训练算法进行 $T$ 个生成器步骤。在每个步骤 $t \\in \\{1, \\dots, T\\}$ 中：\n1. 判别器更新 $k$ 次。对于每次判别器更新，都会抽取新的一批真实数据 $x \\sim \\mathcal{N}(\\mu_r, \\sigma_r^2)$ 和噪声 $z \\sim \\mathcal{N}(0,1)$。参数 $(w, c)$ 使用学习率 $\\alpha_D$ 通过梯度上升进行更新。\n2. 生成器更新一次。抽取新的一批噪声 $z \\sim \\mathcal{N}(0,1)$。参数 $(a, b)$ 使用学习率 $\\alpha_G$ 通过在非饱和损失上进行梯度下降来更新。\n在整个模拟过程中，参数值受到监控。如果任何参数的绝对值超过 $100$ 或变为非有限（NaN），则运行终止并归类为发散。sigmoid 函数的输入被裁剪到 $[-50, 50]$ 以防止数值溢出。\n\n完成 $T$ 步后，评估训练运行的稳定性。生成器的分布参数 $(\\mu_g(t)=b(t), \\sigma_g(t)=|a(t)|)$ 与目标真实数据参数 $(\\mu_r, \\sigma_r)$ 之间的距离定义为 $d_t = \\sqrt{(\\mu_g(t) - \\mu_r)^2 + (\\sigma_g(t) - \\sigma_r)^2}$。计算两个度量指标：\n1. 改进分数 $I$，衡量从初始状态到最终状态的距离的相对减少量：\n    $$ I = \\frac{d_0 - d_T}{\\max(d_0, \\epsilon)} $$\n    其中 $d_0$ 和 $d_T$ 是在步骤 $0$ 和 $T$ 时的距离，$\\epsilon = 10^{-8}$ 是一个用于数值稳定性的小常数。一次运行必须达到 $I \\ge I_{\\min} = 0.25$。\n2. 振荡指数 $O$，衡量生成器参数 $\\theta_g(t)=[a(t), b(t)]^\\top$ 的总路径长度与净位移的比率：\n    $$ O = \\frac{\\sum_{t=1}^T \\|\\theta_g(t) - \\theta_g(t-1)\\|_2}{\\|\\theta_g(T) - \\theta_g(0)\\|_2 + \\epsilon} $$\n    一次运行必须满足 $O \\le O_{\\max} = 2.5$。\n\n一次运行当且仅当它不发散，达到 $I \\ge I_{\\min}$，并且满足 $O \\le O_{\\max}$ 时，被分类为稳定（输出 $1$）。否则，它是不稳定（输出 $0$）。所提供的实现为每个测试用例执行这整个过程。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy is not required for this problem.\n\ndef solve():\n    \"\"\"\n    Main function to run the GAN stability analysis for all test cases.\n    \"\"\"\n    \n    test_cases = [\n        # (mu_r, sigma_r, k, seed)\n        (0.0, 1.0, 0, 42),\n        (0.0, 1.0, 1, 42),\n        (0.0, 1.0, 5, 42),\n        (2.0, 0.5, 2, 123),\n        (-1.0, 1.5, 10, 7)\n    ]\n\n    results = []\n    for case in test_cases:\n        mu_r, sigma_r, k, seed = case\n        result = run_training_and_evaluate(mu_r, sigma_r, k, seed)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef sigmoid(s):\n    \"\"\"\n    Computes the logistic sigmoid function with input clipping for numerical stability.\n    \"\"\"\n    s_clipped = np.clip(s, -50.0, 50.0)\n    return 1.0 / (1.0 + np.exp(-s_clipped))\n\ndef run_training_and_evaluate(mu_r, sigma_r, k, seed,\n                              a_init=0.2, b_init=0.0,\n                              w_init=0.0, c_init=0.0,\n                              alpha_D=0.05, alpha_G=0.02,\n                              B=1024, T=200,\n                              epsilon=1e-8, divergence_threshold=100.0,\n                              I_min=0.25, O_max=2.5):\n    \"\"\"\n    Simulates the GAN training for one parameter set and evaluates its stability.\n    \"\"\"\n    # Set seed for reproducibility\n    np.random.seed(seed)\n\n    # Initialize parameters\n    a, b = a_init, b_init\n    w, c = w_init, c_init\n\n    # History for stability metrics\n    theta_g_history = [np.array([a, b])]\n    diverged = False\n\n    # Calculate initial distance to target distribution parameters\n    d_0 = np.sqrt((b - mu_r)**2 + (np.abs(a) - sigma_r)**2)\n\n    # Main training loop (T generator steps)\n    for _ in range(T):\n        # --- Discriminator updates (k steps) ---\n        if k > 0:\n            for _ in range(k):\n                # Sample data\n                x_r = np.random.normal(loc=mu_r, scale=sigma_r, size=B)\n                z = np.random.normal(loc=0.0, scale=1.0, size=B)\n                x_g = a * z + b\n\n                # Discriminator predictions\n                d_real = sigmoid(w * x_r + c)\n                d_fake = sigmoid(w * x_g + c)\n                \n                # Discriminator gradients (for maximizing log-likelihood)\n                grad_w = np.mean((1.0 - d_real) * x_r - d_fake * x_g)\n                grad_c = np.mean((1.0 - d_real) - d_fake)\n\n                # Update D parameters via gradient ascent\n                w += alpha_D * grad_w\n                c += alpha_D * grad_c\n\n                # Check for D divergence\n                if not (np.isfinite(w) and np.isfinite(c) and\n                        abs(w) = divergence_threshold and abs(c) = divergence_threshold):\n                    diverged = True\n                    break\n            if diverged:\n                break\n\n        # --- Generator update (1 step) ---\n        z_g = np.random.normal(loc=0.0, scale=1.0, size=B)\n        x_g_g = a * z_g + b\n        d_fake_for_g = sigmoid(w * x_g_g + c)\n\n        # Generator gradients (for minimizing non-saturating loss -log(D(G(z))))\n        grad_V_G_a = -np.mean((1.0 - d_fake_for_g) * w * z_g)\n        grad_V_G_b = -np.mean((1.0 - d_fake_for_g) * w)\n        \n        # Update G parameters via gradient descent\n        a -= alpha_G * grad_V_G_a\n        b -= alpha_G * grad_V_G_b\n\n        # Check for G divergence\n        if not (np.isfinite(a) and np.isfinite(b) and\n                abs(a) = divergence_threshold and abs(b) = divergence_threshold):\n            diverged = True\n            break\n            \n        theta_g_history.append(np.array([a, b]))\n\n    # --- Stability Evaluation ---\n    if diverged:\n        return 0\n\n    a_T, b_T = theta_g_history[-1]\n    \n    # Final distance\n    d_T = np.sqrt((b_T - mu_r)**2 + (np.abs(a_T) - sigma_r)**2)\n    \n    # Improvement Fraction (I)\n    I = (d_0 - d_T) / max(d_0, epsilon)\n\n    # Oscillation Index (O)\n    path_length = np.sum([np.linalg.norm(theta_g_history[t] - theta_g_history[t-1]) for t in range(1, T + 1)])\n    net_displacement = np.linalg.norm(theta_g_history[-1] - theta_g_history[0])\n    O = path_length / (net_displacement + epsilon)\n\n    # Classify as stable (1) or unstable (0)\n    if I >= I_min and O = O_max:\n        return 1\n    else:\n        return 0\n\nsolve()\n```", "id": "3128933"}]}