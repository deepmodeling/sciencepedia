{"hands_on_practices": [{"introduction": "掌握Metropolis-Hastings算法的第一步是理解其核心机制：接受概率。本练习 [@problem_id:1932824] 提供了一个具体的场景，让你亲手实践这一基本计算。它聚焦于使用对称提议分布的简化情况（即Metropolis算法），此时接受率仅取决于目标分布，这有助于你清晰地把握算法的决策过程。", "problem": "一位统计学家正在使用马尔可夫链蒙特卡洛（MCMC）方法从参数 $\\lambda$ 的后验分布中抽样。已知该后验分布服从率参数为 $\\beta_0$ 的指数分布，其概率密度函数为：当 $\\lambda  0$ 时，$\\pi(\\lambda) = \\beta_0 \\exp(-\\beta_0 \\lambda)$；当 $\\lambda \\le 0$ 时，$\\pi(\\lambda)=0$。\n\nMCMC 模拟采用的是随机游走 Metropolis-Hastings 算法。给定当前状态 $\\lambda_c$，新状态 $\\lambda_p$ 的提议是从一个均值为当前状态、标准差为 $\\sigma$ 的正态分布中抽取的。即，提议分布为 $q(\\lambda_p | \\lambda_c)$，对应于正态分布 $\\mathcal{N}(\\lambda_c, \\sigma^2)$。\n\n假设后验分布的率参数为 $\\beta_0 = 0.5$，提议分布的标准差为 $\\sigma = 1.0$。在马尔可夫链的某一步，当前状态为 $\\lambda_c = 2.4$。算法接着提议了一个新状态 $\\lambda_p = 3.1$。当前状态和提议状态都在有效域 ($\\lambda  0$) 内。\n\n计算此提议移动的接受概率。将你的最终答案四舍五入到三位有效数字。", "solution": "在 Metropolis-Hastings 算法中，从 $\\lambda_{c}$ 到 $\\lambda_{p}$ 的提议移动的接受概率为\n$$\n\\alpha = \\min\\left(1,\\;\\frac{\\pi(\\lambda_{p})\\,q(\\lambda_{c}\\mid \\lambda_{p})}{\\pi(\\lambda_{c})\\,q(\\lambda_{p}\\mid \\lambda_{c})}\\right).\n$$\n对于由 $\\mathcal{N}(\\lambda_{c},\\sigma^{2})$ 给出的随机游走正态提议 $q(\\lambda_{p}\\mid \\lambda_{c})$，该提议是对称的，因此\n$$\nq(\\lambda_{c}\\mid \\lambda_{p})=q(\\lambda_{p}\\mid \\lambda_{c}),\n$$\n因而提议比率等于 $1$。于是，\n$$\n\\alpha=\\min\\left(1,\\;\\frac{\\pi(\\lambda_{p})}{\\pi(\\lambda_{c})}\\right).\n$$\n目标密度是率参数为 $\\beta_{0}$ 的指数分布：\n$$\n\\pi(\\lambda)=\\beta_{0}\\exp(-\\beta_{0}\\lambda)\\quad\\text{for}\\ \\lambda0,\\quad \\pi(\\lambda)=0\\ \\text{otherwise}.\n$$\n由于 $\\lambda_{c}$ 和 $\\lambda_{p}$ 均为正，我们有\n$$\n\\frac{\\pi(\\lambda_{p})}{\\pi(\\lambda_{c})}\n=\\frac{\\beta_{0}\\exp(-\\beta_{0}\\lambda_{p})}{\\beta_{0}\\exp(-\\beta_{0}\\lambda_{c})}\n=\\exp\\!\\big(-\\beta_{0}(\\lambda_{p}-\\lambda_{c})\\big).\n$$\n代入给定值 $\\beta_{0}=0.5$，$\\lambda_{c}=2.4$ 和 $\\lambda_{p}=3.1$，\n$$\n\\alpha=\\min\\left(1,\\;\\exp\\!\\big(-0.5\\cdot(3.1-2.4)\\big)\\right)\n=\\min\\left(1,\\;\\exp(-0.35)\\right)\n=\\exp(-0.35).\n$$\n数值上，$\\exp(-0.35)\\approx 0.704688\\ldots$，四舍五入到三位有效数字是 $0.705$。", "answer": "$$\\boxed{0.705}$$", "id": "1932824"}, {"introduction": "除了基础计算，理解MH算法的理论保证也至关重要。一个关键条件是遍历性（ergodicity），它确保采样器能够探索目标分布的整个空间。这个编程练习 [@problem_id:3160213] 让你通过代码亲身体验当此条件不满足时会发生什么，从而为不可约性（irreducibility）这一抽象概念建立起坚实的直观理解。", "problem": "考虑梅特罗波利斯-哈斯廷斯（Metropolis-Hastings, MH）算法，该算法构建一个具有指定平稳分布的马尔可夫链。设实值状态空间为两个不相交闭区间的并集，目标概率密度函数 $\\,\\pi(x)\\,$ 的支撑集为 $$S = [0,1] \\cup [2,3],$$ 在此支撑集之外的函数值为零。定义 $$\\pi(x) = \\begin{cases} \\tfrac{1}{2},  x \\in [0,1] \\text{ 或 } x \\in [2,3], \\\\ 0,  \\text{其他情况,} \\end{cases}$$ 这是一个有效的概率密度，因为 $S$ 的总长度为 $2$，且在每个单位长度的区间上密度均为 $\\tfrac{1}{2}$。考虑两种类型的提议：\n\n- 一个对称的局部提议 $\\,q(x' \\mid x)\\,$，由 $$[x - \\delta,\\, x + \\delta]$$ 上的均匀分布给出，其中 $\\,\\delta  0\\,$ 是一个固定的半宽。此提议的对称性体现在，只要 $\\,q(x' \\mid x)\\,$ 和 $\\,q(x \\mid x')\\,$ 均非零，它们就相等。\n- 一个独立提议 $\\,q(x' \\mid x) = q(x')\\,$，由 $$[0,3]$$ 上的均匀分布给出，它不依赖于当前状态 $\\,x$。\n\n您必须分析、实现并凭经验证明，当局部提议的半宽 $\\,\\delta\\,$ 太小以至于无法跨越区间之间的间隙时，遍历性（特别是 $\\psi$-不可约性）的失效，并将其与恢复不可约性的参数化或提议机制进行对比。\n\n从基本概念入手：马尔可夫链的定义、概率测度支撑集的概念、细致平衡条件以及不可约性的定义。特别地，要运用以下原则：MH 接受函数必须通过确保相对于目标密度 $\\,\\pi(x)\\,$ 的细致平衡来推导，并且落在 $\\,\\pi(x') = 0\\,$ 区域的提议必须被拒绝。\n\n对您的程序的算法要求：\n\n- 实现一个函数，该函数使用指定的提议类型和参数，从初始状态 $\\,x_0\\,$ 开始模拟 MH 链 $\\,N\\,$ 步。如果 $\\,\\pi(x_0) = 0$，实现必须能检测到无效的初始状态，并返回整数 $\\,1\\,$ 作为该情况的测试结果。\n- 对于有效的起始状态，跟踪链在 $\\,N\\,$ 步内是否曾访问过右侧区间 $$[2,3]$$。该情况的结果必须是一个布尔值：如果链至少访问过一次 $[2,3]$，则为 $\\,\\text{True}\\,$，否则为 $\\,\\text{False}\\,$。\n- 为每个测试用例使用固定的随机种子，以确保可复现性。\n- 使用闭区间进行成员资格测试；具体来说，使用 $\\,\\le\\,$ 比较，以便恰好在 $\\,0,\\,1,\\,2,\\,$ 和 $\\,3\\,$ 的点被认为在其各自的区间内。\n\n测试套件和覆盖范围：\n\n设间隙长度为 $$g = 1,$$，即 $[0,1]$ 的右端点与 $[2,3]$ 的左端点之间的距离为 $\\,g$。以下五个测试用例必须完全按照规定实现，以覆盖正常路径、边界条件和边缘情况：\n\n1. 局部对称提议，$\\,\\delta = 0.49,$，初始状态 $\\,x_0 = 0.5,$，步数 $\\,N = 20000,$，种子 $\\,42$。预期行为：链无法跨越间隙，因为 $\\,\\delta  g$。\n2. 局部对称提议，$\\,\\delta = 1.5,$，初始状态 $\\,x_0 = 1.0,$，步数 $\\,N = 20000,$，种子 $\\,123$。预期行为：链可以跨越间隙，因为 $\\,\\delta  g$。\n3. 局部对称提议，$\\,\\delta = 1.0,$，初始状态 $\\,x_0 = 1.0,$，步数 $\\,N = 20000,$，种子 $\\,2023$。边界行为：链无法以非零概率跨越间隙，因为从 $\\,x \\in [0,1]\\,$ 提议的值落在 $$[x - 1,\\, x + 1] \\subset [0,2],$$ 中，而事件 $\\,x' = 2\\,$ 的概率为 $\\,0$。\n4. 独立提议 $\\,q(x')\\,$，在 $[0,3]$ 上均匀分布，初始状态 $\\,x_0 = 0.5,$，步数 $\\,N = 100,$，种子 $\\,7$。预期行为：链是不可约的，因为从 $S$ 中的任何状态提议的值都有正概率落入 $[2,3]$。\n5. 无效的初始状态：局部对称提议，$\\,\\delta = 0.4,$，初始状态 $\\,x_0 = 1.5,$，步数 $\\,N = 100,$，种子 $\\,99$。要求行为：检测到 $\\,\\pi(x_0) = 0\\,$ 并返回整数 $\\,1$。\n\n最终输出格式：\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表内容为按上述五个测试用例顺序排列的结果。对于前四个测试用例，打印布尔值，指示链是否至少访问过一次 $[2,3]$；对于第五个测试用例，打印整数 $\\,1$。例如，打印的行必须具有 $$[b_1, b_2, b_3, b_4, i_5],$$ 的形式，其中每个 $\\,b_k\\,$ 是一个布尔值，而 $\\,i_5 = 1$。不应打印任何额外文本。", "solution": "该问题是有效的，因为它在科学上是合理的、问题陈述清晰，并且提供了所有必要的信息。它提出了一个在梅特罗波利斯-哈斯廷斯算法中不可约性失效的典型例子，这是计算科学和马尔可夫链蒙特卡洛方法中的一个基本概念。\n\n梅特罗波利斯-哈斯廷斯（MH）算法是一种从难以直接采样的概率分布中生成随机样本序列的方法。样本序列构成一个马尔可夫链，这是一个随机过程，其中转移到任何特定状态的概率仅取决于当前状态，而与之前的事件序列无关。MH 算法的核心思想是构建一个马尔可夫链，使其平稳分布是所需的目标分布 $\\pi(x)$。马尔可夫链要从支撑集内的任何起点收敛到其唯一的平稳分布，所需的一个关键性质是遍历性。遍历性意味着链既是不可约的也是非周期的。本分析侧重于不可约性。\n\n如果对于 $\\pi(x)$ 支撑集（记作 $\\text{supp}(\\pi)$）内的任何状态 $x$，以及任何具有正概率的集合 $A \\subseteq \\text{supp}(\\pi)$（即 $\\int_A \\pi(x) dx  0$），链在有限步内从 $x$ 移动到集合 $A$ 的概率不为零，则称该马尔可夫链是 $\\pi$-不可约的。在此问题中，目标分布的支撑集是集合 $S = [0,1] \\cup [2,3]$。为了使链不可约，它必须能够在两个不相交的区间 $[0,1]$ 和 $[2,3]$ 之间转移。\n\nMH 算法构建马尔可夫链的转移核，以满足关于 $\\pi(x)$ 的细致平衡条件。这个条件是 $\\pi(x)$ 成为平稳分布的一个充分但不必要条件。细致平衡由以下公式给出：\n$$\n\\pi(x) P(x' \\mid x) = \\pi(x') P(x \\mid x')\n$$\n其中 $P(x' \\mid x)$ 是从状态 $x$ 转移到状态 $x'$ 的概率密度。MH 算法通过一个两步过程定义此转移：提议和接受。首先，从一个提议分布 $q(x' \\mid x)$ 中提议一个候选状态 $x'$。其次，以概率 $\\alpha(x' \\mid x)$ 接受这个提议。因此，对于 $x' \\neq x$，转移密度为 $P(x' \\mid x) = q(x' \\mid x) \\alpha(x' \\mid x)$。将其代入细致平衡方程可得：\n$$\n\\pi(x) q(x' \\mid x) \\alpha(x' \\mid x) = \\pi(x') q(x \\mid x') \\alpha(x \\mid x')\n$$\n选择 MH 接受概率以满足此关系：\n$$\n\\alpha(x' \\mid x) = \\min \\left( 1, \\frac{\\pi(x') q(x \\mid x')}{\\pi(x) q(x' \\mid x)} \\right)\n$$\n如果提议的状态 $x'$ 位于 $\\pi(x)$ 的支撑集之外，则 $\\pi(x')=0$，导致接受概率 $\\alpha(x' \\mid x) = 0$。在这种情况下，提议总是被拒绝，链保持在当前状态，即 $x_{t+1} = x_t$。\n\n指定的目标分布是 $\\pi(x) = \\frac{1}{2}$ 对于 $x \\in S = [0,1] \\cup [2,3]$ 且在其他地方为 $\\pi(x) = 0$。从这个定义中可以得到一个关键的简化：对于任意两个状态 $x, x' \\in S$，目标密度的比率为 $\\frac{\\pi(x')}{\\pi(x)} = \\frac{1/2}{1/2} = 1$。因此，对于任何从 $x \\in S$ 到 $x' \\in S$ 的提议移动，接受概率公式简化为：\n$$\n\\alpha(x' \\mid x) = \\min \\left( 1, \\frac{q(x \\mid x')}{q(x' \\mid x)} \\right)\n$$\n我们分析两种提议机制：\n\n1.  **局部对称提议**：提议分布 $q(x' \\mid x)$ 对应于 $[x-\\delta, x+\\delta]$ 上的均匀分布。如果 $x' \\in [x-\\delta, x+\\delta]$，则密度为 $q(x' \\mid x) = \\frac{1}{2\\delta}$，否则为 0。这是对称的，意味着 $q(x' \\mid x) = q(x \\mid x')$，因为条件 $|x' - x| \\le \\delta$ 在 $x$ 和 $x'$ 中是对称的。因此，比率 $\\frac{q(x \\mid x')}{q(x' \\mid x)} = 1$。对于任何向状态 $x' \\in S$ 的提议移动，其接受概率为 $\\alpha(x' \\mid x) = \\min(1, 1) = 1$。所以，如果一个提议落在支撑集 $S$ 内，它总是被接受。如果它落在 $S$ 之外，它总是被拒绝。\n    链的不可约性取决于提议分布是否能跨越区间 $[0,1]$ 和 $[2,3]$ 之间的间隙 $g=1$。从状态 $x \\in [0,1]$ 提议的值生成自 $[x-\\delta, x+\\delta]$。源于 $[0,1]$ 的提议可能达到的最大值来自 $x=1$，这给出了一个提议区间 $[1-\\delta, 1+\\delta]$。为了让链能够从 $[0,1]$ 跳转到 $[2,3]$，这个区间必须与 $[2,3]$ 有非零的重叠。这要求 $1+\\delta \\ge 2$，即 $\\delta \\ge 1$。\n    -   **情况 1 ($\\delta = 0.49  1$)**：从 $x=1$ 的最大可达值为 $1.49$。不可能提议一个在 $[2,3]$ 内的状态。链是可约的，被困在它开始的区间内。\n    -   **情况 2 ($\\delta = 1.5  1$)**：从任何 $x \\in [0.5, 1]$，提议区间 $[x-1.5, x+1.5]$ 与 $[2,3]$ 有非空交集。例如，从 $x_0=1$，提议可以达到 $2.5$。转移是可能的，链是不可约的。\n    -   **情况 3 ($\\delta = 1.0$)**：从 $x=1$ 的最大可达值恰好是 $2$。提议区间是 $[0, 2]$。由于提议是从一个连续均匀分布中抽取的，生成精确值 $x'=2$ 的概率为 $0$。因此，链不能以非零概率跨越到 $[2,3]$ 的内部。链是可约的。\n\n2.  **独立提议**：提议分布是 $q(x' \\mid x) = q(x')$，在 $[0,3]$ 上均匀分布，因此密度为 $q(x') = \\frac{1}{3}$ 对于 $x' \\in [0,3]$。在这里，提议不依赖于当前状态 $x$。提议密度的比率为 $\\frac{q(x \\mid x')}{q(x' \\mid x)} = \\frac{q(x)}{q(x')} = \\frac{1/3}{1/3} = 1$ 对于任何 $x, x' \\in [0,3]$。与对称情况类似，任何移动到 $x' \\in S$ 的接受概率为 $\\alpha(x' \\mid x) = 1$。\n    不可约性得到了保证。从任何状态 $x \\in S$，都会从 $[0,3]$ 上均匀地提议一个新的状态 $x'$。该提议落入右侧区间 $[2,3]$ 的概率是 $\\frac{3-2}{3-0} = \\frac{1}{3}  0$。由于这样的提议将被接受，链可以在支撑集的两个部分之间单步移动。因此，该链是不可约的。\n\n最后，问题要求识别无效的初始状态。如果 $x_0$ 使得 $\\pi(x_0)=0$（例如，案例 5 中的 $x_0 = 1.5$），则链没有在目标分布的支撑集上正确初始化。实现必须检测到这一点。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Metropolis-Hastings problem by running five specified test cases.\n    \"\"\"\n\n    def pi(x: float) -> float:\n        \"\"\"\n        Target probability density function pi(x).\n        Supported on S = [0,1] U [2,3].\n        \"\"\"\n        if (0.0 = x = 1.0) or (2.0 = x = 3.0):\n            return 0.5\n        return 0.0\n\n    def run_mh_simulation(\n        proposal_type: str,\n        delta: float | None,\n        x0: float,\n        N: int,\n        seed: int\n    ) -> bool | int:\n        \"\"\"\n        Simulates the Metropolis-Hastings Markov chain for a given test case.\n\n        Args:\n            proposal_type: 'local' for symmetric or 'independent' for independent proposal.\n            delta: Half-width for the local proposal.\n            x0: Initial state.\n            N: Number of steps.\n            seed: Random seed for reproducibility.\n\n        Returns:\n            - Integer 1 if the initial state x0 is invalid (pi(x0) == 0).\n            - Boolean True if the chain visits the interval [2,3].\n            - Boolean False otherwise.\n        \"\"\"\n        # Step 1: Validate initial state\n        if pi(x0) == 0.0:\n            return 1\n\n        # Step 2: Initialize chain and tracking variables\n        rng = np.random.default_rng(seed)\n        current_x = x0\n        visited_right_interval = (2.0 = current_x = 3.0)\n\n        # Step 3: Run the MCMC simulation for N steps\n        for _ in range(N):\n            # Propose a new state x_prime\n            if proposal_type == 'local':\n                if delta is None:\n                    # This case should not happen based on problem description but is a safeguard\n                    raise ValueError(\"Delta must be provided for local proposal.\")\n                x_prime = rng.uniform(current_x - delta, current_x + delta)\n            elif proposal_type == 'independent':\n                x_prime = rng.uniform(0.0, 3.0)\n            else:\n                raise ValueError(f\"Unknown proposal type: {proposal_type}\")\n\n            # As derived in the solution, for this specific problem, the acceptance\n            # probability alpha is 1 for any proposal that lands in the support of pi,\n            # and 0 otherwise. This simplifies the accept/reject step.\n            if pi(x_prime) > 0.0:\n                current_x = x_prime\n\n            # Track if the chain has ever visited the right interval [2, 3]\n            if not visited_right_interval and (2.0 = current_x = 3.0):\n                visited_right_interval = True\n        \n        return visited_right_interval\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # 1. Local proposal, delta  gap, should not cross\n        {'proposal_type': 'local', 'delta': 0.49, 'x0': 0.5, 'N': 20000, 'seed': 42},\n        # 2. Local proposal, delta > gap, should cross\n        {'proposal_type': 'local', 'delta': 1.5, 'x0': 1.0, 'N': 20000, 'seed': 123},\n        # 3. Local proposal, delta = gap, cannot cross (prob=0 event)\n        {'proposal_type': 'local', 'delta': 1.0, 'x0': 1.0, 'N': 20000, 'seed': 2023},\n        # 4. Independent proposal, should be irreducible and cross\n        {'proposal_type': 'independent', 'delta': None, 'x0': 0.5, 'N': 100, 'seed': 7},\n        # 5. Invalid initial state, should return 1\n        {'proposal_type': 'local', 'delta': 0.4, 'x0': 1.5, 'N': 100, 'seed': 99},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_mh_simulation(\n            proposal_type=case['proposal_type'],\n            delta=case['delta'],\n            x0=case['x0'],\n            N=case['N'],\n            seed=case['seed']\n        )\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(str(r).capitalize() if isinstance(r, bool) else str(r) for r in results)}]\")\n\nsolve()\n```", "id": "3160213"}, {"introduction": "在许多实际应用中，模型参数是受限的（例如，方差必须为正）。一个强大的处理技巧是将参数变换到无约束空间进行采样。本练习 [@problem_id:3148250] 深入探讨了这一高级方法，展示了如何通过变换的雅可比行列式（Jacobian）正确调整目标密度以保证算法的正确性，这是构建稳健统计模型的关键技能。", "problem": "考虑马尔可夫链蒙特卡洛（MCMC）中的梅特罗波利斯-哈斯廷斯算法，该算法构建一个马尔可夫链，使其平稳分布等于一个期望的目标密度。梅特罗波利斯-哈斯廷斯接受概率从第一性原理定义如下。给定状态空间上的目标密度 $\\pi(x)$ 和一个提议核 $q(x' \\mid x)$，从状态 $x$ 移动到状态 $x'$ 的提议的接受概率为\n$$\n\\alpha(x \\to x') = \\min\\left(1,\\; \\frac{\\pi(x')\\, q(x \\mid x')}{\\pi(x)\\, q(x' \\mid x)}\\right).\n$$\n假设我们对一个变换后的变量 $u = g(x)$ 进行梅特罗波利斯-哈斯廷斯采样，其中 $g$ 是一个双射、可微的变换，其逆变换 $g^{-1}$ 也可微且雅可比行列式非零。目标密度必须通过变量替换被正确地变换为 $u$ 空间上的密度，记为 $\\pi_u(u)$，使用以下公式：\n$$\n\\pi_u(u) = \\pi_x\\big(g^{-1}(u)\\big)\\,\\left|\\det J_{g^{-1}}(u)\\right|,\n$$\n其中 $J_{g^{-1}}(u)$ 是 $g^{-1}$ 在 $u$ 处求值的雅可比矩阵。如果 $u$ 空间中的提议是 $q_u(u' \\mid u)$，那么 $u$ 空间中的梅特罗波利斯-哈斯廷斯接受概率为\n$$\n\\alpha_u(u \\to u') = \\min\\left(1,\\; \\frac{\\pi_u(u')\\, q_u(u \\mid u')}{\\pi_u(u)\\, q_u(u' \\mid u)}\\right).\n$$\n通过将 $u$ 空间中的提议通过 $x' = g^{-1}(u')$ 和 $x = g^{-1}(u)$ 映射回 $x$ 空间，可以通过变量替换获得隐含的提议密度 $q_x(x' \\mid x)$。在科学一致的实现中，使用正确变换后的目标在 $u$ 空间中计算的接受概率，必须与使用原始目标和导出的提议在 $x$ 空间中计算的接受概率一致。\n\n您的任务是推导变换后变量 $u$ 上的接受概率表达式，确定包含雅可比因子的正确变换后目标 $\\pi_u(u)$，并实现一个程序，以数值方式验证在一组测试案例中，$u$ 空间和 $x$ 空间计算出的接受概率是否一致。所有数学量必须以无量纲单位处理。\n\n您必须考虑以下变换和目标：\n- 对数变换 $u = \\log x$ 对于 $x  0$：\n  - $x$ 上的伽马目标：$\\pi_x(x) \\propto x^{k - 1} \\exp\\left(-\\frac{x}{\\theta}\\right)$，形状 $k  0$，尺度 $\\theta  0$。\n  - $x$ 上的指数目标：$\\pi_x(x) \\propto \\exp(-\\lambda x)$，率 $\\lambda  0$。\n- 恒等变换 $u = x$ 对于 $x \\in \\mathbb{R}$：\n  - $x$ 上的标准正态目标：$\\pi_x(x) \\propto \\exp\\left(-\\frac{x^2}{2}\\right)$。\n\n对于提议：\n- 在 $u$ 空间中，使用标准差为 $\\sigma  0$ 的高斯随机游走提议：$q_u(u' \\mid u) = \\mathcal{N}(u'; u, \\sigma^2)$。\n- 对于对数变换情况， $x$ 空间中导出的提议是对数正态分布：$q_x(x' \\mid x) = \\text{LogNormal}(x'; \\log x, \\sigma)$。\n- 对于恒等变换情况， $x$ 空间中导出的提议是高斯分布：$q_x(x' \\mid x) = \\mathcal{N}(x'; x, \\sigma^2)$。\n\n实现以下接受概率计算：\n- 在 $u$ 空间中：\n  $$\n  \\alpha_u(u \\to u') = \\min\\left(1,\\; \\exp\\left[\\log \\pi_u(u') - \\log \\pi_u(u) + \\log q_u(u \\mid u') - \\log q_u(u' \\mid u)\\right]\\right).\n  $$\n- 在 $x$ 空间中：\n  $$\n  \\alpha_x(x \\to x') = \\min\\left(1,\\; \\exp\\left[\\log \\pi_x(x') - \\log \\pi_x(x) + \\log q_x(x \\mid x') - \\log q_x(x' \\mid x)\\right]\\right).\n  $$\n\n使用以下参数值测试套件，在不同场景下验证 $\\alpha_u$ 和 $\\alpha_x$ 的一致性：\n1. 正常路径，对数变换与伽马目标：\n   - $k = 2.3$, $\\theta = 1.1$, $u = 0.25$, $u' = 0.7$, $\\sigma = 0.5$。\n2. 接近 $x \\approx 0$ 的边界情况，对数变换与伽马目标：\n   - $k = 2.3$, $\\theta = 1.1$, $u = -0.1$, $u' = -5.0$, $\\sigma = 0.5$。\n3. 基准恒等变换与标准正态目标：\n   - $u = 1.0$, $u' = -1.7$, $\\sigma = 1.0$。\n4. 对数变换与指数目标：\n   - $\\lambda = 1.7$, $u = 0.3$, $u' = -1.0$, $\\sigma = 0.7$。\n\n您的程序必须为每个测试案例计算绝对差\n$$\n\\Delta = \\left|\\alpha_u - \\alpha_x\\right|\n$$\n作为一个浮点数。最终输出必须是单行，包含一个用方括号括起来的逗号分隔列表，其中包含按上述顺序列出的四个 $\\Delta$ 值（例如，$\\left[\\delta_1,\\delta_2,\\delta_3,\\delta_4\\right]$）。不应打印任何其他文本。", "solution": "问题陈述已经过验证，被认为是有效的。它具有科学依据，定义明确，客观且内部一致。它提出了计算统计学中一个标准的、非平凡的问题，即在变量变换下，只要所有密度都得到正确变换，梅特罗波利斯-哈斯廷斯接受概率的不变性。\n\n核心任务是证明，无论是在变换空间（$u$ 空间）中使用变换后的目标密度计算，还是在原始空间（$x$ 空间）中使用原始目标密度和导出的提议密度计算，梅特罗波利斯-哈斯廷斯接受概率都保持不变。我们必须对几个测试案例证明 $\\alpha_u = \\alpha_x$。\n\n从状态 $s$ 移动到 $s'$ 的接受概率由下式给出\n$$ \\alpha(s \\to s') = \\min\\left(1, R\\right) \\quad \\text{其中} \\quad R = \\frac{\\pi(s') q(s \\mid s')}{\\pi(s) q(s' \\mid s)} $$\n使用对数在数值上更稳定：\n$$ \\alpha(s \\to s') = \\min\\left(1, \\exp\\left[\\log\\pi(s') - \\log\\pi(s) + \\log q(s \\mid s') - \\log q(s' \\mid s)\\right]\\right) $$\n\n我们首先建立理论上的等价性。设变换为 $u = g(x)$，其逆变换为 $x = g^{-1}(u)$。概率密度函数 $\\pi_x(x)$ 的变量替换公式是\n$$ \\pi_u(u) = \\pi_x\\big(g^{-1}(u)\\big) \\left|\\det J_{g^{-1}}(u)\\right| $$\n其中 $J_{g^{-1}}(u)$ 是逆变换的雅可比矩阵。\n\n$u$ 空间中的提议密度 $q_u(u' \\mid u)$ 在 $x$ 空间中导出提议密度 $q_x(x' \\mid x)$，这也通过变量替换关联起来：\n$$ q_x(x' \\mid x) = q_u\\big(g(x') \\mid g(x)\\big) \\left|\\det J_g(x')\\right| $$\n其中 $J_g(x')$ 是正向变换 $g$ 的雅可比矩阵。根据反函数定理，$\\left|\\det J_g(x')\\right| = 1 / \\left|\\det J_{g^{-1}}(u')\\right|$，其中 $u'=g(x')$。\n因此，\n$$ q_x(x' \\mid x) = \\frac{q_u(u' \\mid u)}{\\left|\\det J_{g^{-1}}(u')\\right|} \\quad \\text{并且类似地} \\quad q_x(x \\mid x') = \\frac{q_u(u \\mid u')}{\\left|\\det J_{g^{-1}}(u)\\right|} $$\n\n现在，让我们写出 $x$ 空间中的接受率 $R_x$ 并代入这些关系：\n$$ R_x = \\frac{\\pi_x(x') q_x(x \\mid x')}{\\pi_x(x) q_x(x' \\mid x)} = \\frac{\\pi_x(x')}{\\pi_x(x)} \\frac{q_u(u \\mid u') / \\left|\\det J_{g^{-1}}(u)\\right|}{q_u(u' \\mid u) / \\left|\\det J_{g^{-1}}(u')\\right|} = \\frac{\\pi_x(x')}{\\pi_x(x)} \\frac{q_u(u \\mid u')}{q_u(u' \\mid u)} \\frac{\\left|\\det J_{g^{-1}}(u')\\right|}{\\left|\\det J_{g^{-1}}(u)\\right|} $$\n整理项，我们得到：\n$$ R_x = \\left( \\frac{\\pi_x(x') \\left|\\det J_{g^{-1}}(u')\\right|}{\\pi_x(x) \\left|\\det J_{g^{-1}}(u)\\right|} \\right) \\left( \\frac{q_u(u \\mid u')}{q_u(u' \\mid u)} \\right) = \\frac{\\pi_u(u')}{\\pi_u(u)} \\frac{q_u(u \\mid u')}{q_u(u' \\mid u)} = R_u $$\n由于比率 $R_x$ 和 $R_u$ 是相同的，它们的接受概率 $\\alpha_x = \\min(1, R_x)$ 和 $\\alpha_u = \\min(1, R_u)$ 也必须相同。数值实现将验证这一基本性质。\n\n我们现在为每种情况推导具体的量。$u$ 空间中的提议始终是对称高斯随机游走，$q_u(u' \\mid u) = \\mathcal{N}(u'; u, \\sigma^2)$，这意味着 $q_u(u' \\mid u) = q_u(u \\mid u')$。因此，提议比率项 $\\log q_u(u \\mid u') - \\log q_u(u' \\mid u) = 0$。\n\n**1. 对数变换：$u = \\log x$ 对于 $x  0$**\n- 逆变换：$x = g^{-1}(u) = \\exp(u)$。\n- 雅可比行列式（一维情况）：$J_{g^{-1}}(u) = \\frac{dx}{du} = \\exp(u)$。\n- 雅可比行列式绝对值：$|\\det J_{g^{-1}}(u)| = \\exp(u)$。\n- $x$ 空间中导出的提议来自 $x' = \\exp(u')$，其中 $u' \\sim \\mathcal{N}(u, \\sigma^2) = \\mathcal{N}(\\log x, \\sigma^2)$。这意味着 $x'$ 服从对数正态分布。其概率密度函数为 $q_x(x' \\mid x) = \\frac{1}{x'\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(\\log x' - \\log x)^2}{2\\sigma^2}\\right)$。这个提议在 $x$ 和 $x'$ 中是不对称的。\n- $x$ 空间中提议的对数比为：\n  $$ \\log q_x(x \\mid x') - \\log q_x(x' \\mid x) = \\left(-\\log x - \\dots\\right) - \\left(-\\log x' - \\dots\\right) = \\log x' - \\log x = \\log(x'/x) $$\n\n**1(a). 伽马目标：** $\\pi_x(x) \\propto x^{k - 1} \\exp\\left(-\\frac{x}{\\theta}\\right)$\n- $x$ 空间中的对数目标：$\\log\\pi_x(x) = (k - 1)\\log x - \\frac{x}{\\theta} + C_x$。\n- $u$ 空间中的变换后目标：\n  $ \\pi_u(u) = \\pi_x(\\exp u) |\\exp u| \\propto (\\exp u)^{k-1} \\exp\\left(-\\frac{\\exp u}{\\theta}\\right) \\exp u = \\exp(ku - \\frac{\\exp u}{\\theta}) $\n- $u$ 空间中的对数目标：$\\log \\pi_u(u) = ku - \\frac{\\exp u}{\\theta} + C_u$。\n\n**1(b). 指数目标：** $\\pi_x(x) \\propto \\exp(-\\lambda x)$\n- $x$ 空间中的对数目标：$\\log\\pi_x(x) = -\\lambda x + C_x$。\n- $u$ 空间中的变换后目标：\n  $ \\pi_u(u) = \\pi_x(\\exp u) |\\exp u| \\propto \\exp(-\\lambda \\exp u) \\exp u $\n- $u$ 空间中的对数目标：$\\log \\pi_u(u) = u - \\lambda \\exp u + C_u$。\n\n**2. 恒等变换：$u = x$ 对于 $x \\in \\mathbb{R}$**\n- 逆变换：$x = g^{-1}(u) = u$。\n- 雅可比行列式：$J_{g^{-1}}(u) = \\frac{dx}{du} = 1$。\n- 雅可比行列式绝对值：$|\\det J_{g^{-1}}(u)| = 1$。\n- $x$ 空间中提议的对数比为 $0$，因为导出的提议 $q_x(x'|x) = \\mathcal{N}(x'; x, \\sigma^2)$ 是对称的。\n- 变换后的目标具有相同的形式：$\\pi_u(u) = \\pi_x(u)$。\n\n**2(a). 标准正态目标：** $\\pi_x(x) \\propto \\exp\\left(-\\frac{x^2}{2}\\right)$\n- $x$ 空间中的对数目标：$\\log \\pi_x(x) = -\\frac{x^2}{2} + C_x$。\n- $u$ 空间中的对数目标：$\\log \\pi_u(u) = -\\frac{u^2}{2} + C_u$。\n\n程序将通过实现这些推导出的对数密度函数和完整的接受概率公式，为每个测试案例计算差值 $\\Delta = |\\alpha_u - \\alpha_x|$。由于已证明的理论等价性，$\\Delta$ 应为零，只受限于浮点数的数值精度。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes and verifies the Metropolis-Hastings acceptance probability under a change of variables.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # 1. Happy path, log transform with gamma target\n        {'type': 'gamma_log', 'params': {'k': 2.3, 'theta': 1.1}, 'u': 0.25, 'u_prime': 0.7, 'sigma': 0.5},\n        # 2. Boundary case near x=0, log transform with gamma target\n        {'type': 'gamma_log', 'params': {'k': 2.3, 'theta': 1.1}, 'u': -0.1, 'u_prime': -5.0, 'sigma': 0.5},\n        # 3. Baseline identity transform with standard normal target\n        {'type': 'normal_identity', 'params': {}, 'u': 1.0, 'u_prime': -1.7, 'sigma': 1.0},\n        # 4. Log transform with exponential target\n        {'type': 'exp_log', 'params': {'lambda': 1.7}, 'u': 0.3, 'u_prime': -1.0, 'sigma': 0.7}\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        u = case['u']\n        u_prime = case['u_prime']\n        params = case['params']\n        \n        # --- U-Space Calculation ($\\alpha_u$) ---\n        \n        log_pi_u_val = 0.0\n        log_pi_u_prime_val = 0.0\n        \n        if case['type'] == 'gamma_log':\n            k, theta = params['k'], params['theta']\n            # log_pi_u(u) = k*u - exp(u)/theta\n            log_pi_u_val = k * u - np.exp(u) / theta\n            log_pi_u_prime_val = k * u_prime - np.exp(u_prime) / theta\n        elif case['type'] == 'exp_log':\n            lam = params['lambda']\n            # log_pi_u(u) = u - lambda*exp(u)\n            log_pi_u_val = u - lam * np.exp(u)\n            log_pi_u_prime_val = u_prime - lam * np.exp(u_prime)\n        elif case['type'] == 'normal_identity':\n            # log_pi_u(u) = -u^2 / 2\n            log_pi_u_val = -u**2 / 2.0\n            log_pi_u_prime_val = -u_prime**2 / 2.0\n            \n        # For a symmetric Gaussian proposal in u-space, the proposal ratio is 1, and its log is 0.\n        log_q_u_ratio = 0.0\n        \n        log_r_u = log_pi_u_prime_val - log_pi_u_val + log_q_u_ratio\n        alpha_u = min(1.0, np.exp(log_r_u))\n\n        # --- X-Space Calculation ($\\alpha_x$) ---\n        \n        log_pi_x_val = 0.0\n        log_pi_x_prime_val = 0.0\n        log_q_x_ratio = 0.0\n        \n        if 'log' in case['type']:\n            # Log transform: u = log(x) => x = exp(u)\n            x = np.exp(u)\n            x_prime = np.exp(u_prime)\n            # For a log-normal proposal, log q(x|x') - log q(x'|x) = log(x'/x)\n            log_q_x_ratio = np.log(x_prime / x) if x > 0 and x_prime > 0 else 0\n            \n            if 'gamma' in case['type']:\n                k, theta = params['k'], params['theta']\n                # log_pi_x(x) = (k - 1)*log(x) - x/theta\n                log_pi_x_val = (k - 1.0) * np.log(x) - x / theta if x > 0 else -np.inf\n                log_pi_x_prime_val = (k - 1.0) * np.log(x_prime) - x_prime / theta if x_prime > 0 else -np.inf\n            elif 'exp' in case['type']:\n                lam = params['lambda']\n                # log_pi_x(x) = -lambda*x\n                log_pi_x_val = -lam * x if x > 0 else -np.inf\n                log_pi_x_prime_val = -lam * x_prime if x_prime > 0 else -np.inf\n        \n        elif 'identity' in case['type']:\n            # Identity transform: u = x\n            x = u\n            x_prime = u_prime\n            # For a symmetric Gaussian proposal, the proposal ratio is 1, and its log is 0.\n            log_q_x_ratio = 0.0\n            \n            if 'normal' in case['type']:\n                # log_pi_x(x) = -x^2 / 2\n                log_pi_x_val = -x**2 / 2.0\n                log_pi_x_prime_val = -x_prime**2 / 2.0\n\n        log_r_x = log_pi_x_prime_val - log_pi_x_val + log_q_x_ratio\n        alpha_x = min(1.0, np.exp(log_r_x))\n        \n        # Calculate the absolute difference\n        delta = abs(alpha_u - alpha_x)\n        results.append(delta)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3148250"}]}