{"hands_on_practices": [{"introduction": "矩阵分解是现代推荐系统的基石，但一个简单的实现往往会遭受流行度偏差的影响，即过度推荐已经流行的项目。这项练习将挑战你从头开始实现一个矩阵分解模型，并直面这个问题。通过比较标准模型和重新加权损失函数的模型，你将亲身体验到在推荐准确性和多样性之间进行权衡的实践。[@problem_id:3167503]", "problem": "构建一个程序，该程序实现一个简单的经验风险最小化框架，用于隐式反馈推荐，该框架包含物品流行度重加权和不重加权两种情况，然后衡量 top-$K$ 准确率和推荐多样性的变化。设置如下。\n\n从以下基本基础开始：使用逐点逻辑损失、二元标签和线性预测器的经验风险最小化。给定一组用户、物品和一个二元训练交互集，通过最小化加权逻辑损失加上二次正则化来学习用户和物品的潜向量。对于一个标签为 $y_{ui} \\in \\{0,1\\}$、分数为 $x_{ui} = \\mathbf{p}_u^\\top \\mathbf{q}_i$ 的用户-物品对，逻辑损失为 $\\ell(y,x) = \\log(1 + \\exp(-(2y-1)x))$。在本问题中，使用等价的分离形式：\n$$\n\\ell_+(x) = \\log(1 + \\exp(-x)), \\quad \\ell_-(x) = \\log(1 + \\exp(x)).\n$$\n设训练集为一组正样本对 $\\mathcal{P} \\subseteq \\mathcal{U} \\times \\mathcal{I}$，并为每个用户 $u$ 定义负样本集，该集合包含所有未出现在该用户训练正样本中且不等于该用户留出测试物品的物品。将训练数据中物品的流行度定义为 $\\text{pop}(i) = \\sum_{(u,i)\\in \\mathcal{P}} 1$。\n\n训练两个模型，它们共享相同的结构（用户和物品嵌入以及相同的优化器），但对每个物品 $i$ 应用的正样本权重 $w_i$ 不同：\n- 无加权基线：对于所有 $\\text{pop}(i) > 0$ 的物品，$w_i = 1$。\n- 重加权：对于 $\\text{pop}(i) > 0$ 的物品，$w_i \\propto \\frac{1}{\\sqrt{\\text{pop}(i)}}$，并进行归一化，使得 $\\{w_i: \\text{pop}(i) > 0\\}$ 的平均值为 $1$。\n\n使用以下带正则化的经验风险：\n$$\n\\mathcal{L}(\\{\\mathbf{p}_u\\}, \\{\\mathbf{q}_i\\}) = \\sum_{(u,i)\\in \\mathcal{P}} w_i \\,\\ell_+(\\mathbf{p}_u^\\top \\mathbf{q}_i) \\;+\\; \\sum_{u \\in \\mathcal{U}} \\sum_{j \\in \\mathcal{N}(u)} c_0 \\,\\ell_-(\\mathbf{p}_u^\\top \\mathbf{q}_j) \\;+\\; \\frac{\\lambda}{2} \\left(\\sum_{u \\in \\mathcal{U}} \\|\\mathbf{p}_u\\|_2^2 + \\sum_{i \\in \\mathcal{I}} \\|\\mathbf{q}_i\\|_2^2\\right),\n$$\n其中 $\\mathcal{N}(u)$ 是用户 $u$ 的负样本集，$c_0$ 是一个常数负样本权重，$\\lambda$ 是正则化强度。\n\n使用固定的学习率，通过全批量梯度下降对损失进行固定次数的迭代优化。使用相同的伪随机种子初始化所有潜向量，以确保两个模型的确定性。\n\n训练完每个模型后，为每个用户计算 top-$K$ 推荐，方法是按预测分数 $x_{ui}$ 对所有候选物品（不在该用户训练正样本中的物品）进行排序。将 top-$K$ 准确率定义为 $K$ 位置的平均命中率：对于每个用户，如果其留出的物品在 top-$K$ 列表中，则命中指示符为 $1$，否则为 $0$；准确率是这些指示符在所有用户中的平均值。将推荐多样性定义为一减去所有推荐列表中物品频率的基尼系数：\n- 设 $f_i$ 为物品 $i$ 在所有用户的 top-$K$ 列表中出现的次数。\n- 基尼系数为\n$$\nG = \\frac{\\sum_{i=1}^{n}\\sum_{j=1}^{n} |f_i - f_j|}{2 n \\sum_{i=1}^{n} f_i},\n$$\n其中 $n$ 是物品的数量。将多样性定义为 $D = 1 - G$。较大的 $D$ 表示推荐在物品间的分布更均匀。\n\n您的程序必须在固定的测试套件上计算重加权模型和无加权模型在两种指标上的差异。对于每个测试用例，输出一个对 $[\\Delta \\text{Acc}, \\Delta D]$，其中 $\\Delta \\text{Acc} = \\text{Acc}_{\\text{reweighted}} - \\text{Acc}_{\\text{unweighted}}$ 且 $\\Delta D = D_{\\text{reweighted}} - D_{\\text{unweighted}}$。\n\n训练和评估协议及超参数：\n- 使用潜向量维度 $d = 3$。\n- 使用学习率 $\\eta = 0.02$。\n- 使用全批量迭代次数 $T = 300$。\n- 使用负样本权重 $c_0 = 0.05$。\n- 使用正则化 $\\lambda = 0.01$。\n- 对所有测试用例使用 top-$K$ 且 $K = 2$。\n- 使用 sigmoid 函数 $\\sigma(x) = \\frac{1}{1 + e^{-x}}$。\n- 对于负样本，为每个用户 $u$ 定义 $\\mathcal{N}(u)$ 为所有未出现在该用户训练正样本中且不等于该用户留出物品的物品。\n- 所有潜向量从均值为 $0$、标准差为 $0.01$ 的正态分布中初始化，伪随机种子固定为 $0$。\n\n测试套件：\n提供恰好三个测试用例，每个用例由一组训练交互和每个用户一个留出的正样本指定。在每个用例中，程序应根据给定数据构建用户-物品的基数。\n\n- 用例 $1$ (流行度偏斜；$|\\mathcal{U}| = 4$, $|\\mathcal{I}| = 6$)：\n  - 训练正样本 $\\mathcal{P}$：\n    - 用户 $0$：物品 $\\{0, 1\\}$\n    - 用户 $1$：物品 $\\{0\\}$\n    - 用户 $2$：物品 $\\{0\\}$\n    - 用户 $3$：物品 $\\{0\\}$\n  - 留出物品：\n    - 用户 $0$：物品 $2$\n    - 用户 $1$：物品 $2$\n    - 用户 $2$：物品 $3$\n    - 用户 $3$：物品 $4$\n\n- 用例 $2$ (均衡流行度；$|\\mathcal{U}| = 4$, $|\\mathcal{I}| = 6$)：\n  - 训练正样本 $\\mathcal{P}$：\n    - 用户 $0$：物品 $\\{0\\}$\n    - 用户 $1$：物品 $\\{1\\}$\n    - 用户 $2$：物品 $\\{2\\}$\n    - 用户 $3$：物品 $\\{3\\}$\n  - 留出物品：\n    - 用户 $0$：物品 $1$\n    - 用户 $1$：物品 $2$\n    - 用户 $2$：物品 $3$\n    - 用户 $3$：物品 $4$\n\n- 用例 $3$ (极端偏斜且带有一些尾部信号；$|\\mathcal{U}| = 5$, $|\\mathcal{I}| = 7$)：\n  - 训练正样本 $\\mathcal{P}$：\n    - 用户 $0$：物品 $\\{0, 1\\}$\n    - 用户 $1$：物品 $\\{0\\}$\n    - 用户 $2$：物品 $\\{0, 1\\}$\n    - 用户 $3$：物品 $\\{0, 2\\}$\n    - 用户 $4$：物品 $\\{0, 2\\}$\n  - 留出物品：\n    - 用户 $0$：物品 $3$\n    - 用户 $1$：物品 $2$\n    - 用户 $2$：物品 $4$\n    - 用户 $3$：物品 $5$\n    - 用户 $4$：物品 $6$\n\n要求的最终输出格式：\n- 您的程序应生成单行输出，其中包含结果，形式为一个以逗号分隔的对的列表，每个测试用例一个对，并用方括号括起来。每个对必须是一个双元素列表 $[\\Delta \\text{Acc}, \\Delta D]$，两个值都四舍五入到 $4$ 位小数。例如：$[[0.1250,0.3500],[0.0000,0.0000],[0.0500,0.1200]]$。\n\n本问题中没有物理单位。所有角度（如果有）必须以弧度解释，但这里没有出现角度。所有分数值都应表示为小数。如果用户的候选物品少于 $K$ 个，则使用 $K' = \\min(K, \\text{候选物品数量})$ 来为该用户形成推荐列表。", "solution": "用户的题目陈述已根据既定标准进行了仔细审查和验证。\n\n### 第一步：提取已知信息\n- **模型：** 带有用户-物品潜向量的经验风险最小化。\n- **评分函数：** 用户 $u$ 和物品 $i$ 的预测分数是其潜向量的点积：$x_{ui} = \\mathbf{p}_u^\\top \\mathbf{q}_i$。\n- **损失函数：** 带二次正则化的加权逐点逻辑损失。总损失 $\\mathcal{L}$ 由以下公式给出：\n$$\n\\mathcal{L}(\\{\\mathbf{p}_u\\}, \\{\\mathbf{q}_i\\}) = \\sum_{(u,i)\\in \\mathcal{P}} w_i \\,\\ell_+(\\mathbf{p}_u^\\top \\mathbf{q}_i) \\;+\\; \\sum_{u \\in \\mathcal{U}} \\sum_{j \\in \\mathcal{N}(u)} c_0 \\,\\ell_-(\\mathbf{p}_u^\\top \\mathbf{q}_j) \\;+\\; \\frac{\\lambda}{2} \\left(\\sum_{u \\in \\mathcal{U}} \\|\\mathbf{p}_u\\|_2^2 + \\sum_{i \\in \\mathcal{I}} \\|\\mathbf{q}_i\\|_2^2\\right)\n$$\n其中 $\\ell_+(x) = \\log(1 + \\exp(-x))$ 是正样本的损失，$\\ell_-(x) = \\log(1 + \\exp(x))$ 是负样本的损失。$\\mathcal{P}$ 是正训练样本对的集合。\n- **数据集：** 提供了三个测试用例，每个用例都有一组用户 $\\mathcal{U}$、物品 $\\mathcal{I}$、训练正样本 $\\mathcal{P}$，以及每个用户一个用于测试的留出正样本物品。\n- **负样本：** 对每个用户 $u$，负样本集 $\\mathcal{N}(u)$ 包括所有未出现在用户 $u$ 训练集中且不等于该用户留出测试物品的物品。\n- **加权方案：**\n  1.  **无加权：** 对于所有在 $\\mathcal{P}$ 中至少有一次交互的物品 $i$（即 $\\text{pop}(i) > 0$），$w_i = 1$。\n  2.  **重加权：** 对于 $\\text{pop}(i) > 0$ 的物品，$w_i \\propto \\frac{1}{\\sqrt{\\text{pop}(i)}}$，其中 $\\text{pop}(i) = \\sum_{(u,i)\\in \\mathcal{P}} 1$。权重 $\\{w_i: \\text{pop}(i) > 0\\}$ 被归一化以使其平均值为 $1$。\n- **超参数：**\n  - 潜向量维度：$d = 3$。\n  - 学习率：$\\eta = 0.02$。\n  - 训练迭代次数：$T = 300$。\n  - 负样本权重：$c_0 = 0.05$。\n  - 正则化强度：$\\lambda = 0.01$。\n  - 评估排名：$K = 2$。\n- **初始化：** 所有潜向量都将从一个正态分布 $\\mathcal{N}(0, 0.01^2)$ 中初始化，并使用固定的伪随机种子 $0$。\n- **评估指标：**\n  - **Top-$K$ 准确率：** 留出物品出现在其 top-$K$ 推荐物品列表中的用户所占的比例。为用户 $u$ 进行排名的候选物品包括除用户 $u$ 训练集中的物品之外的所有物品。\n  - **推荐多样性：** $D = 1 - G$，其中 $G$ 是物品推荐频率的基尼系数。$G = \\frac{\\sum_{i=1}^{n}\\sum_{j=1}^{n} |f_i - f_j|}{2 n \\sum_{i=1}^{n} f_i}$，其中 $f_i$ 是物品 $i$ 在所有用户的 top-$K$ 列表中出现的次数，$n=|\\mathcal{I}|$。\n- **任务：** 对每个测试用例，计算差异 $\\Delta \\text{Acc} = \\text{Acc}_{\\text{reweighted}} - \\text{Acc}_{\\text{unweighted}}$ 和 $\\Delta D = D_{\\text{reweighted}} - D_{\\text{unweighted}}$。\n- **输出格式：** 一个对的列表 `[[d_acc1, d_div1], [d_acc2, d_div2], ...]`，其中的值四舍五入到4位小数。\n\n### 第二步：使用提取的已知信息进行验证\n- **科学依据：** 该问题牢固地植根于统计学习和推荐系统的原理。它采用了标准的经验风险最小化（ERM）框架、逻辑损失、L2 正则化和梯度下降。使用重加权来减轻流行度偏差的概念是一项成熟的技术。评估指标是该领域的标准指标。\n- **适定性：** 问题是完全指定的。所有需要的数据、参数和过程都得到了明确的定义。确定性的初始化确保了唯一的训练轨迹和单一、可验证的解决方案。\n- **客观性：** 问题陈述是客观的，没有主观断言。\n\n### 第三步：结论与行动\n该问题是**有效的**。它自成体系、科学合理且适定。将构建一个解决方案。\n\n### 基于原则的设计\n解决方案通过实现指定的 ERM 框架来推进。对于每个测试用例，我们将训练两个模型——一个无加权模型和一个重加权模型——然后计算它们在指定指标上的性能差异。\n\n**模型与优化**\n目标函数 $\\mathcal{L}$ 对于潜向量 $\\mathbf{p}_u$ 和 $\\mathbf{q}_i$ 是可微的。我们使用全批量梯度下降来最小化此损失。梯度使用链式法则推导。设 $\\sigma(x) = (1 + e^{-x})^{-1}$ 为 sigmoid 函数。损失分量的导数为 $\\frac{d}{dx}\\ell_+(x) = \\sigma(x) - 1$ 和 $\\frac{d}{dx}\\ell_-(x) = \\sigma(x)$。\n\n总损失 $\\mathcal{L}$ 相对于用户向量 $\\mathbf{p}_u$ 和物品向量 $\\mathbf{q}_i$ 的梯度为：\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{p}_u} = \\sum_{i \\in \\text{Pos}(u)} w_i (\\sigma(\\mathbf{p}_u^\\top \\mathbf{q}_i) - 1) \\mathbf{q}_i + c_0 \\sum_{j \\in \\mathcal{N}(u)} \\sigma(\\mathbf{p}_u^\\top \\mathbf{q}_j) \\mathbf{q}_j + \\lambda \\mathbf{p}_u\n$$\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{q}_i} = \\sum_{u | (u,i) \\in \\mathcal{P}} w_i (\\sigma(\\mathbf{p}_u^\\top \\mathbf{q}_i) - 1) \\mathbf{p}_u + c_0 \\sum_{u | i \\in \\mathcal{N}(u)} \\sigma(\\mathbf{p}_u^\\top \\mathbf{q}_i) \\mathbf{p}_u + \\lambda \\mathbf{q}_i\n$$\n其中 $\\text{Pos}(u)$ 是用户 $u$ 在训练集 $\\mathcal{P}$ 中交互过的物品集合。\n\n为了计算效率，这些梯度以向量化的方式计算。我们构建一个大小为 $|\\mathcal{U}| \\times |\\mathcal{I}|$ 的误差矩阵 $E$，其中每个条目 $E_{ui}$ 表示对 $(u,i)$ 的误差信号。总误差是正样本和负样本误差的总和：\n$$\nE = (W_{\\text{pos}} \\odot (\\Sigma - 1)) + c_0 (M_{\\text{neg}} \\odot \\Sigma)\n$$\n这里，$\\odot$ 表示逐元素乘积，$\\Sigma$ 是 sigmoid 变换后的分数矩阵 $\\sigma(\\mathbf{p}_u^\\top \\mathbf{q}_i)$，$W_{\\text{pos}}$ 是一个矩阵，其中当 $(u,i) \\in \\mathcal{P}$ 时 $(W_{\\text{pos}})_{ui} = w_i$，否则为 $0$，$M_{\\text{neg}}$ 是一个指示负样本对的二元矩阵。\n潜因子矩阵 $P$ 和 $Q$ 的全批量梯度更新则为：\n$$\n\\nabla_P \\mathcal{L} = E Q + \\lambda P \\quad \\implies \\quad P \\leftarrow P - \\eta \\nabla_P \\mathcal{L}\n$$\n$$\n\\nabla_Q \\mathcal{L} = E^\\top P + \\lambda Q \\quad \\implies \\quad Q \\leftarrow Q - \\eta \\nabla_Q \\mathcal{L}\n$$\n这个过程重复 $T=300$ 次迭代。为确保公平比较，对于给定的测试用例，无加权和重加权模型都从完全相同的初始潜向量开始，这些向量是使用指定的随机种子生成的。\n\n**权重计算**\n对于重加权模型，物品权重基于它们在训练集中的流行度 $\\text{pop}(i)$ 来计算。令 $\\mathcal{I}_{\\text{pop}} = \\{i \\in \\mathcal{I} | \\text{pop}(i) > 0\\}$。对于一个物品 $i \\in \\mathcal{I}_{\\text{pop}}$，其原始权重为 $w'_i = 1/\\sqrt{\\text{pop}(i)}$。然后将这些权重归一化，以确保它们的平均值为 $1$：\n$$\nw_i = \\frac{w'_i}{\\frac{1}{|\\mathcal{I}_{\\text{pop}}|} \\sum_{j \\in \\mathcal{I}_{\\text{pop}}} w'_j}\n$$\n这个方案降低了流行物品的权重，提高了小众物品的权重，目的是在不过度损害准确率的情况下提高推荐多样性。对于无加权基线，$w_i=1$ 对所有 $i \\in \\mathcal{I}_{\\text{pop}}$。\n\n**评估**\n训练后，对每个模型进行评估。对于每个用户，我们计算所有候选物品（不在其训练集中的物品）的分数。对候选物品进行排序，前 $K=2$ 个物品构成推荐列表。\n- **准确率：** 我们通过检查用户的留出测试物品是否出现在他们的推荐列表中来计算命中率，并在所有用户上取平均。\n- **多样性：** 我们首先计算每个物品在所有生成的推荐列表中的频率 $f_i$。然后根据这些频率计算基尼系数 $G$，多样性报告为 $D=1-G$。较高的 $D$ 值表示推荐在物品目录中分布得更均匀。\n\n最终输出是重加权模型和无加权模型在这些指标上的差异。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport collections\nfrom scipy.special import expit as sigmoid\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final results.\n    \"\"\"\n    # Define hyperparameters from the problem statement.\n    D_LATENT = 3\n    LEARNING_RATE = 0.02\n    ITERATIONS = 300\n    C0_NEGATIVE_WEIGHT = 0.05\n    LAMBDA_REG = 0.01\n    K_TOP = 2\n    RANDOM_SEED = 0\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: Popularity skew\n        (4, 6, {0: [0, 1], 1: [0], 2: [0], 3: [0]}, {0: 2, 1: 2, 2: 3, 3: 4}),\n        # Case 2: Balanced popularity\n        (4, 6, {0: [0], 1: [1], 2: [2], 3: [3]}, {0: 1, 1: 2, 2: 3, 3: 4}),\n        # Case 3: Extreme skew with some tail signal\n        (5, 7, {0: [0, 1], 1: [0], 2: [0, 1], 3: [0, 2], 4: [0, 2]}, {0: 3, 1: 2, 2: 4, 3: 5, 4: 6}),\n    ]\n\n    # --- Helper Functions ---\n\n    def calculate_weights(num_items, train_pos, reweighted):\n        \"\"\"Calculates item weights for the loss function.\"\"\"\n        item_pops = np.zeros(num_items)\n        for _, items in train_pos.items():\n            for item in items:\n                item_pops[item] += 1\n                \n        active_items_mask = item_pops > 0\n        weights = np.zeros(num_items)\n\n        if not np.any(active_items_mask):\n            return weights\n\n        if not reweighted:\n            weights[active_items_mask] = 1.0\n        else:\n            raw_weights = np.zeros(num_items)\n            raw_weights[active_items_mask] = 1.0 / np.sqrt(item_pops[active_items_mask])\n            \n            avg_raw_weight = np.mean(raw_weights[active_items_mask])\n            if avg_raw_weight > 0:\n                weights[active_items_mask] = raw_weights[active_items_mask] / avg_raw_weight\n\n        return weights\n\n    def train_model(num_users, num_items, train_pos, held_out, p_init, q_init, weights):\n        \"\"\"Trains the model using full-batch gradient descent.\"\"\"\n        P = p_init.copy()\n        Q = q_init.copy()\n\n        pos_indicator = np.zeros((num_users, num_items))\n        for u, items in train_pos.items():\n            if items:\n                pos_indicator[u, items] = 1\n\n        pos_weights_matrix = np.zeros((num_users, num_items))\n        for u, items in train_pos.items():\n            if items:\n                pos_weights_matrix[u, items] = weights[items]\n\n        held_out_indicator = np.zeros((num_users, num_items))\n        if held_out:\n            held_out_users, held_out_items = zip(*held_out.items())\n            held_out_indicator[held_out_users, held_out_items] = 1\n\n        neg_indicator = 1.0 - pos_indicator - held_out_indicator\n\n        for _ in range(ITERATIONS):\n            scores = P @ Q.T\n            sigma_scores = sigmoid(scores)\n\n            error_pos = pos_weights_matrix * (sigma_scores - 1)\n            error_neg = C0_NEGATIVE_WEIGHT * (neg_indicator * sigma_scores)\n            total_error = error_pos + error_neg\n\n            grad_P = total_error @ Q + LAMBDA_REG * P\n            grad_Q = total_error.T @ P + LAMBDA_REG * Q\n\n            P -= LEARNING_RATE * grad_P\n            Q -= LEARNING_RATE * grad_Q\n\n        return P, Q\n\n    def evaluate_model(P, Q, num_users, num_items, train_pos, held_out):\n        \"\"\"Evaluates the model on top-K accuracy and recommendation diversity.\"\"\"\n        scores = P @ Q.T\n        hits = 0\n        all_recommendations = []\n        \n        for u in range(num_users):\n            training_items = set(train_pos.get(u, []))\n            candidate_items = [i for i in range(num_items) if i not in training_items]\n            \n            if not candidate_items:\n                continue\n                \n            candidate_scores = scores[u, candidate_items]\n            sorted_indices = np.argsort(-candidate_scores)\n            \n            k_prime = min(K_TOP, len(candidate_items))\n            top_k_items = [candidate_items[i] for i in sorted_indices[:k_prime]]\n            \n            all_recommendations.extend(top_k_items)\n            \n            if held_out.get(u) in top_k_items:\n                hits += 1\n\n        accuracy = hits / num_users if num_users > 0 else 0.0\n\n        if not all_recommendations:\n            diversity = 0.0\n        else:\n            item_counts = np.zeros(num_items)\n            counts = collections.Counter(all_recommendations)\n            for item, count in counts.items():\n                item_counts[item] = count\n            \n            abs_diff_sum = np.sum(np.abs(item_counts[:, None] - item_counts[None, :]))\n            total_recs = np.sum(item_counts)\n            \n            if total_recs == 0:\n                gini = 0.0\n            else:\n                denominator = 2 * num_items * total_recs\n                gini = abs_diff_sum / denominator if denominator > 0 else 0.0\n            \n            diversity = 1.0 - gini\n\n        return accuracy, diversity\n\n    def solve_case(num_users, num_items, train_pos, held_out):\n        \"\"\"Executes one full test case, returning performance differences.\"\"\"\n        rng = np.random.RandomState(RANDOM_SEED)\n        p_init = rng.normal(0, 0.01, (num_users, D_LATENT))\n        q_init = rng.normal(0, 0.01, (num_items, D_LATENT))\n        \n        unweighted_w = calculate_weights(num_items, train_pos, reweighted=False)\n        p_unweighted, q_unweighted = train_model(num_users, num_items, train_pos, held_out, p_init, q_init, unweighted_w)\n        acc_unweighted, div_unweighted = evaluate_model(p_unweighted, q_unweighted, num_users, num_items, train_pos, held_out)\n\n        reweighted_w = calculate_weights(num_items, train_pos, reweighted=True)\n        p_reweighted, q_reweighted = train_model(num_users, num_items, train_pos, held_out, p_init, q_init, reweighted_w)\n        acc_reweighted, div_reweighted = evaluate_model(p_reweighted, q_reweighted, num_users, num_items, train_pos, held_out)\n        \n        return acc_reweighted - acc_unweighted, div_reweighted - div_unweighted\n    \n    # --- Main Execution Logic ---\n    results = []\n    for case in test_cases:\n        delta_acc, delta_div = solve_case(*case)\n        results.append([delta_acc, delta_div])\n\n    case_strings = [f\"[{da:.4f},{dd:.4f}]\" for da, dd in results]\n    final_output = f\"[{','.join(case_strings)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "3167503"}, {"introduction": "除了潜在因子模型，基于图的算法为捕捉用户-项目关系提供了一个强大的替代方案。这项练习将指导你在一个用户-项目二分图上实现个性化PageRank（PPR），将推荐视为一个“随机游走”过程。通过探索传送参数 $\\alpha$ 的影响，你将理解如何平衡个性化信号与全局图结构，以生成有意义的推荐。[@problem_id:3167564]", "problem": "给定一个用户-物品二分图，请您在该图上实现个性化 PageRank 算法，然后分析推荐物品对传送参数和个性化向量的敏感性。您必须推导出您的解决方案，然后实现一个完整的、可运行的程序，该程序能为预定义的测试套件输出所要求的结果。\n\n使用的基本原理：\n- 一个具有列随机转移矩阵 $P$ 的有限状态马尔可夫链，其状态分布通过 $x_{t+1} = P x_t$ 演化。\n- 个性化 PageRank (PPR) 是仿射收缩 $F(x) = \\alpha p + (1-\\alpha) P x$ 的唯一不动点 $x^\\star$。其中，传送概率 $\\alpha \\in (0,1]$，个性化分布 $p$ 的各项非负且总和为 $1$，$P$ 是列随机矩阵。\n\n图的定义：\n- 图中包含 $3$ 个用户节点和 $4$ 个物品节点。用户标记为 $U_1, U_2, U_3$，物品标记为 $I_1, I_2, I_3, I_4$。\n- 完整的节点顺序为 $[U_1, U_2, U_3, I_1, I_2, I_3, I_4]$，总计 $7$ 个节点。\n- 无向边（每条无向边代表两条方向相反的有向边）：\n  - $U_1$ 与 $I_1$ 和 $I_2$ 相连。\n  - $U_2$ 与 $I_2$ 和 $I_3$ 相连。\n  - $U_3$ 与 $I_1$、$I_3$ 和 $I_4$ 相连。\n- 按如下方式构建一个列随机转移矩阵 $P \\in \\mathbb{R}^{7 \\times 7}$。对于每个节点 $j$，令 $\\deg(j)$ 为其在无向图中的邻居数量。对于 $j$ 的每个邻居 $i$，设置 $P_{i j} = 1/\\deg(j)$；如果 $i$ 不是 $j$ 的邻居，则设置 $P_{i j} = 0$。这定义了在该二分图上的一个随机游走过程，即从节点 $j$ 等概率地移动到其任意一个邻居。\n\n本问题的个性化 PageRank 定义：\n- 给定传送（重启）参数 $\\alpha \\in (0,1]$ 和一个各项非负且总和为 $1$ 的个性化向量 $p \\in \\mathbb{R}^7$，PPR 向量 $x^\\star \\in \\mathbb{R}^7$ 被定义为满足以下条件的唯一不动点\n$$\nx^\\star = \\alpha p + (1-\\alpha) P x^\\star.\n$$\n- 通过对仿射映射应用幂法来数值计算 $x^\\star$，即从任意初始分布 $x^{(0)}$ 开始迭代\n$$\nx^{(t+1)} = \\alpha p + (1-\\alpha) P x^{(t)}\n$$\n直到 $\\ell_1$-差分满足 $\\lVert x^{(t+1)} - x^{(t)} \\rVert_1 \\le \\varepsilon$，或达到最大迭代次数。使用容差 $\\varepsilon = 10^{-12}$ 和一个足够大的最大迭代次数。对于特殊情况 $\\alpha = 1$，精确定义 $x^\\star = p$。\n- 物品的推荐分数由 $x^\\star$ 中对应于指定节点顺序中物品索引 $I_1, I_2, I_3, I_4$ 的分量给出。\n\n平局处理与排名：\n- 对于任何物品分数列表，按分数降序对物品进行排名。如果出现平局，使用升序的物品索引来打破平局。如果两个分数的绝对差小于或等于 $10^{-12}$，则认为它们是平局。\n\n使用的个性化向量：\n- 令 $e_j \\in \\mathbb{R}^7$ 表示标准基向量，其在位置 $j$ 处为 $1$，其余位置为 $0$，节点顺序如上所述。\n- 情况 A（单用户个性化）：$p^{(A)} = e_1$（所有权重集中在 $U_1$ 上）。\n- 情况 B（双用户个性化）：$p^{(B)} = \\frac{1}{2} e_2 + \\frac{1}{2} e_3$（在 $U_2$ 和 $U_3$ 之间均匀分配权重）。\n\n测试套件：\n- 所有角度均不适用。不涉及物理单位。所有概率和距离必须以小数表示。\n- 使用以下 $5$ 个测试用例。对于每个测试用例，计算指定的输出。\n  1. 在 $\\alpha = 0.15$ 且 $p = p^{(A)}$ 的条件下，计算排名前 2 的物品。将排名前 2 的物品标识符以整数列表的形式输出，整数来自集合 $\\{1,2,3,4\\}$，对应于 $[I_1,I_2,I_3,I_4]$。\n  2. 在 $\\alpha = 0.85$ 且 $p = p^{(A)}$ 的条件下，计算排名前 2 的物品。按以上方式输出列表。\n  3. 在 $\\alpha = 1.00$ 且 $p = p^{(A)}$ 的条件下，计算排名前 2 的物品。按以上方式输出列表。\n  4. 在 $\\alpha = 0.15$ 且 $p = p^{(B)}$ 的条件下，计算排名前 2 的物品。按以上方式输出列表。\n  5. 对于固定的个性化向量 $p = p^{(A)}$，分析对传送参数的敏感性：计算在 $\\alpha = 0.15$ 和 $\\alpha = 0.85$ 条件下的物品分数子向量之间的 $\\ell_1$-距离。将此距离作为一个小数输出，精确到小数点后 $6$ 位。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。列表内容需严格按此顺序排列：测试用例 1 到 4 的四个排名前 2 物品列表，最后是测试用例 5 的单个小数值。\n- 该列表不得包含任何空白字符。例如，一个语法上有效的输出应类似于 $[[1,2],[1,3],[2,4],[3,1],0.123456]$。您的程序必须严格遵守此格式。", "solution": "用户的要求是在一个指定的用户-物品二分图上实现并分析个性化 PageRank (PPR) 算法。分析内容包括计算顶部物品推荐，并检验这些推荐对算法参数（特别是传送概率 $\\alpha$ 和个性化向量 $p$）的敏感性。\n\n### 1. 数学与算法框架\n\n该解决方案的基础是有限状态马尔可夫链理论和不动点迭代法。\n\n#### 1.1. 图表示与转移矩阵\n问题定义了一个包含 $N=7$ 个节点的二分图，其中包括 3 个用户（$U_1, U_2, U_3$）和 4 个物品（$I_1, I_2, I_3, I_4$）。指定的节点顺序为 $[U_1, U_2, U_3, I_1, I_2, I_3, I_4]$，对应于索引 0 到 6。\n\n图的边如下：\n- $U_1 \\leftrightarrow \\{I_1, I_2\\}$\n- $U_2 \\leftrightarrow \\{I_2, I_3\\}$\n- $U_3 \\leftrightarrow \\{I_1, I_3, I_4\\}$\n\n每个节点 $j$ 的度 $\\deg(j)$ 是其邻居的数量：\n- $\\deg(U_1) = 2$\n- $\\deg(U_2) = 2$\n- $\\deg(U_3) = 3$\n- $\\deg(I_1) = 2$（连接到 $U_1, U_3$）\n- $\\deg(I_2) = 2$（连接到 $U_1, U_2$）\n- $\\deg(I_3) = 2$（连接到 $U_2, U_3$）\n- $\\deg(I_4) = 1$（连接到 $U_3$）\n\n为该图上的随机游走构建一个列随机转移矩阵 $P \\in \\mathbb{R}^{7 \\times 7}$。矩阵元素 $P_{ij}$ 表示从节点 $j$ 转移到节点 $i$ 的概率。对于 $i$ 和 $j$ 之间的一条无向边，该概率为 $P_{ij} = 1/\\deg(j)$。所有其他元素为 0。得到的矩阵是：\n$$\nP = \\begin{pmatrix}\n0  0  0  1/2  1/2  0  0 \\\\\n0  0  0  0  1/2  1/2  0 \\\\\n0  0  0  1/2  0  1/2  1 \\\\\n1/2  0  1/3  0  0  0  0 \\\\\n1/2  1/2  0  0  0  0  0 \\\\\n0  1/2  1/3  0  0  0  0 \\\\\n0  0  1/3  0  0  0  0\n\\end{pmatrix}\n$$\n每个列的总和为 1，符合列随机矩阵的要求。\n\n#### 1.2. 个性化 PageRank (PPR)\nPPR 向量 $x^\\star \\in \\mathbb{R}^7$ 是一个修正后随机游走的平稳分布。它是以下不动点方程的唯一解：\n$$\nx^\\star = \\alpha p + (1-\\alpha) P x^\\star\n$$\n其中 $\\alpha \\in (0,1]$ 是传送概率，$p$ 是一个个性化向量（节点上的一个概率分布）。$\\alpha p$ 项代表“传送”或“重启”行为，即游走过程跳转到由 $p$ 定义的节点分布。$(1-\\alpha) P x^\\star$ 项代表一个标准的随机游走步骤。\n\n对于 $\\alpha \\in (0,1)$，映射 $F(x) = \\alpha p + (1-\\alpha) P x$ 是一个收缩映射。根据巴拿赫不动点定理（Banach fixed-point theorem），存在一个唯一的不动点 $x^\\star$，并且可以通过从任意初始分布 $x^{(0)}$ 开始迭代 $x^{(t+1)} = F(x^{(t)})$ 来找到它。迭代持续进行，直到连续向量之间的变化足够小，具体来说，是直到差分的 $\\ell_1$-范数低于容差 $\\varepsilon = 10^{-12}$：\n$$\n\\lVert x^{(t+1)} - x^{(t)} \\rVert_1 = \\sum_{i=0}^{N-1} |x^{(t+1)}_i - x^{(t)}_i| \\le \\varepsilon\n$$\n对于边界情况 $\\alpha = 1$，方程简化为 $x^\\star = 1 \\cdot p + (0) \\cdot P x^\\star = p$。\n\n#### 1.3. 推荐与排名\n计算得到的 PPR 向量 $x^\\star$ 中对应于物品节点（索引 3, 4, 5, 6）的分量作为推荐分数。物品按其分数的降序排列。规定了一个特定的平局处理规则：如果两个物品分数的绝对差小于或等于容差 $\\varepsilon = 10^{-12}$，则认为它们是平局，并通过按物品标识符升序排列来解决平局（例如，$I_1$ 在 $I_2$ 之前）。\n\n### 2. 测试用例的执行\n\n提供的测试套件要求计算不同场景下的 PPR。\n\n**个性化向量：**\n- 情况 A：$p^{(A)} = e_1$，其中 $e_1$ 是 $U_1$ 的标准基向量。$p^{(A)} = [1, 0, 0, 0, 0, 0, 0]^T$。\n- 情况 B：$p^{(B)} = \\frac{1}{2}e_2 + \\frac{1}{2}e_3$，对应于 $U_2$ 和 $U_3$。$p^{(B)} = [0, 1/2, 1/2, 0, 0, 0, 0]^T$。\n\n**测试用例 1：** $(\\alpha = 0.15, p = p^{(A)})$\n通过幂法计算 PPR 向量 $x^\\star$。从 $x^\\star$ 的分量 $x^\\star_3, x^\\star_4, x^\\star_5, x^\\star_6$ 中提取物品 $I_1, I_2, I_3, I_4$ 的分数。然后根据指定规则对这些物品进行排名，以找到排名前 2 的物品。\n\n**测试用例 2：** $(\\alpha = 0.85, p = p^{(A)})$\n此过程与用例 1 相同，但 $\\alpha = 0.85$。较高的 $\\alpha$ 值会增加传送回个性化节点 $U_1$ 的频率，从而使 PageRank 分数更集中于靠近 $U_1$ 的节点上。\n\n**测试用例 3：** $(\\alpha = 1.00, p = p^{(A)})$\n在这里，$x^\\star = p^{(A)} = [1, 0, 0, 0, 0, 0, 0]^T$。所有物品的分数均为 0。它们都处于平局状态。平局处理规则（升序的物品 ID）决定了排名，得到 $[I_1, I_2, I_3, I_4]$。排名前 2 的是 $I_1$ 和 $I_2$。\n\n**测试用例 4：** $(\\alpha = 0.15, p = p^{(B)})$\n此过程与用例 1 相同，但使用个性化向量 $p^{(B)}$。推荐结果将受到 $U_2$ 和 $U_3$ 邻域的影响。\n\n**测试用例 5：** 敏感性分析\n该用例量化了当 $p=p^{(A)}$ 时，$\\alpha$ 从 0.15 变为 0.85 导致的推荐变化。计算在用例 1 和用例 2 中获得的物品分数子向量之间的 $\\ell_1$-距离。设 $x^\\star_{(1)}$ 和 $x^\\star_{(2)}$ 为这两个用例的 PPR 向量。所需的距离为：\n$$\nd = \\lVert x^\\star_{(1)}[3:7] - x^\\star_{(2)}[3:7] \\rVert_1\n$$\n结果四舍五入到小数点后恰好 6 位。\n\n实现部分将把此逻辑封装到一个程序中，该程序会系统地执行每个测试用例，并按要求将结果格式化为单行的、无空格的逗号分隔字符串。", "answer": "```python\nimport numpy as np\nfrom functools import cmp_to_key\n\ndef solve():\n    \"\"\"\n    Solves the Personalized PageRank problem as specified.\n    - Constructs the transition matrix.\n    - Implements the PPR power method.\n    - Implements the item ranking logic with tie-breaking.\n    - Executes the 5 test cases and formats the output.\n    \"\"\"\n\n    # 1. Define graph structure and build the transition matrix P\n    # Node ordering: [U1, U2, U3, I1, I2, I3, I4] (indices 0-6)\n    P = np.array([\n        [0,   0,   0,   1/2, 1/2, 0,   0],    # U1 receives from I1, I2\n        [0,   0,   0,   0,   1/2, 1/2, 0],    # U2 receives from I2, I3\n        [0,   0,   0,   1/2, 0,   1/2, 1],    # U3 receives from I1, I3, I4\n        [1/2, 0,   1/3, 0,   0,   0,   0],    # I1 receives from U1, U3\n        [1/2, 1/2, 0,   0,   0,   0,   0],    # I2 receives from U1, U2\n        [0,   1/2, 1/3, 0,   0,   0,   0],    # I3 receives from U2, U3\n        [0,   0,   1/3, 0,   0,   0,   0]     # I4 receives from U3\n    ], dtype=float)\n\n    def compute_ppr(alpha, p, P_matrix, epsilon=1e-12, max_iter=2000):\n        \"\"\"\n        Computes the Personalized PageRank vector using the power method.\n        \"\"\"\n        if alpha == 1.0:\n            return p.astype(float)\n        \n        N = P_matrix.shape[0]\n        # Start with a uniform distribution\n        x_curr = np.full(N, 1.0 / N, dtype=float)\n        \n        alpha_p_term = alpha * p\n        one_minus_alpha = 1.0 - alpha\n        \n        for _ in range(max_iter):\n            x_next = alpha_p_term + one_minus_alpha * (P_matrix @ x_curr)\n            \n            # Check for convergence using L1 norm\n            if np.linalg.norm(x_next - x_curr, ord=1) = epsilon:\n                return x_next\n            \n            x_curr = x_next\n            \n        return x_curr # Return last state if max_iter is reached\n\n    def rank_items(x_star, tie_tol=1e-12):\n        \"\"\"\n        Ranks items based on their scores in the PPR vector, handling ties.\n        \"\"\"\n        # Item indices in x_star are 3, 4, 5, 6\n        # Item IDs are 1, 2, 3, 4\n        item_scores_list = []\n        for i in range(4):\n            item_id = i + 1\n            score = x_star[3 + i]\n            item_scores_list.append((item_id, score))\n\n        def compare_items(item1, item2):\n            \"\"\"Custom comparison function for sorting.\"\"\"\n            id1, score1 = item1\n            id2, score2 = item2\n            \n            # Check for tie based on tolerance\n            if abs(score1 - score2) = tie_tol:\n                # Tie: sort by item ID ascending\n                return id1 - id2\n            else:\n                # No tie: sort by score descending\n                return -1 if score1 > score2 else 1\n\n        sorted_items = sorted(item_scores_list, key=cmp_to_key(compare_items))\n        \n        return [item[0] for item in sorted_items]\n\n    # 2. Define personalization vectors\n    p_A = np.array([1.0, 0, 0, 0, 0, 0, 0])\n    p_B = np.array([0, 0.5, 0.5, 0, 0, 0, 0])\n\n    # 3. Execute test cases\n    results = []\n\n    # Case 1: alpha = 0.15, p = p_A\n    alpha1 = 0.15\n    x_star1 = compute_ppr(alpha1, p_A, P)\n    ranked1 = rank_items(x_star1)\n    results.append(ranked1[:2])\n\n    # Case 2: alpha = 0.85, p = p_A\n    alpha2 = 0.85\n    x_star2 = compute_ppr(alpha2, p_A, P)\n    ranked2 = rank_items(x_star2)\n    results.append(ranked2[:2])\n\n    # Case 3: alpha = 1.00, p = p_A\n    alpha3 = 1.00\n    x_star3 = compute_ppr(alpha3, p_A, P)\n    ranked3 = rank_items(x_star3)\n    results.append(ranked3[:2])\n\n    # Case 4: alpha = 0.15, p = p_B\n    x_star4 = compute_ppr(alpha1, p_B, P)\n    ranked4 = rank_items(x_star4)\n    results.append(ranked4[:2])\n\n    # Case 5: Sensitivity L1 distance\n    item_scores1 = x_star1[3:7]\n    item_scores2 = x_star2[3:7]\n    distance = np.linalg.norm(item_scores1 - item_scores2, ord=1)\n    # Format to exactly 6 decimal places, including trailing zeros\n    results.append(f\"{distance:.6f}\")\n\n    # 4. Format and print the final output string\n    formatted_parts = []\n    for res in results:\n        if isinstance(res, list):\n            formatted_parts.append(f\"[{','.join(map(str, res))}]\")\n        else:\n            formatted_parts.append(str(res))\n    \n    print(f\"[{','.join(formatted_parts)}]\")\n\nsolve()\n```", "id": "3167564"}, {"introduction": "生成准确的相关性分数只是成功的一半；最终的推荐列表通常还必须满足商业或公平性约束。这个问题将你置于一个真实的重排场景中，你必须在尊重内容提供商展示数量限制的同时，挑选出最佳项目。通过将其构建为一个约束优化问题，你将学到一项在推荐系统落地过程中至关重要的技能：如何在真实世界的约束下最大化价值。[@problem_id:3167527]", "problem": "一个内容平台执行第二阶段重排，从一个带有估计相关性分数的候选集中形成一个大小为 $K$ 的列表。为了满足提供商公平性约束，它施加了分组上限，限制了每个提供商组别中可以出现在列表中的项目数量。给定 $9$ 个候选项目，它们被分为三个提供商组别，并附有其估计的相关性分数 $r_i$：\n- 组 $\\mathcal{A}$：项目 $1,2,3$，分数为 $r_1=9$，$r_2=8.2$，$r_3=6.1$。\n- 组 $\\mathcal{B}$：项目 $4,5,6$，分数为 $r_4=7.5$，$r_5=7.4$，$r_6=4$。\n- 组 $\\mathcal{C}$：项目 $7,8,9$，分数为 $r_7=5.9$，$r_8=5.2$，$r_9=3.5$。\n\n平台通过求解以下二元优化问题来选择一个最多包含 $K=4$ 个项目的列表：\n$$\n\\max_{\\{x_i\\}_{i=1}^{9}} \\sum_{i=1}^{9} r_i x_i\n\\quad\\text{subject to}\\quad\n\\sum_{i=1}^{9} x_i \\le K,\\quad\n\\sum_{i \\in \\mathcal{G}_j} x_i \\le c_j \\ \\ \\forall j \\in \\{\\mathcal{A},\\mathcal{B},\\mathcal{C}\\},\\quad\nx_i \\in \\{0,1\\},\n$$\n其中 $\\mathcal{G}_{\\mathcal{A}}=\\{1,2,3\\}$，$\\mathcal{G}_{\\mathcal{B}}=\\{4,5,6\\}$，$\\mathcal{G}_{\\mathcal{C}}=\\{7,8,9\\}$，且分组上限为 $c_{\\mathcal{A}}=2$，$c_{\\mathcal{B}}=1$，$c_{\\mathcal{C}}=2$。\n\n仅使用二元决策优化的基本定义和 $0$–$1$ 背包框架，推导出一个等价的组合公式，该公式将分组上限的效果捕捉为类似容量的约束，并计算上述优化可实现的最大总相关性值的精确值。仅报告最优目标值作为最终答案。无需四舍五入，不涉及单位。", "solution": "用户提供了一个二元优化问题，并要求得到其最优目标值。\n\n### 第一步：提取已知条件\n问题提供了以下数据：\n- 一组 $9$ 个候选项目，索引为 $i=1, \\dots, 9$。\n- 列表大小限制 $K=4$。\n- 项目被分为三个提供商组别：\n  - 组 $\\mathcal{A}$：项目 $\\mathcal{G}_{\\mathcal{A}}=\\{1,2,3\\}$，相关性分数为 $r_1=9$，$r_2=8.2$，$r_3=6.1$。\n  - 组 $\\mathcal{B}$：项目 $\\mathcal{G}_{\\mathcal{B}}=\\{4,5,6\\}$，相关性分数为 $r_4=7.5$，$r_5=7.4$，$r_6=4$。\n  - 组 $\\mathcal{C}$：项目 $\\mathcal{G}_{\\mathcal{C}}=\\{7,8,9\\}$，相关性分数为 $r_7=5.9$，$r_8=5.2$，$r_9=3.5$。\n- 分组上限（每个组别中项目的最大数量）：\n  - $c_{\\mathcal{A}}=2$\n  - $c_{\\mathcal{B}}=1$\n  - $c_{\\mathcal{C}}=2$\n- 优化问题公式为：\n$$\n\\max_{\\{x_i\\}_{i=1}^{9}} \\sum_{i=1}^{9} r_i x_i\n$$\n约束条件为：\n1. $\\sum_{i=1}^{9} x_i \\le K$ (总项目数约束)\n2. $\\sum_{i \\in \\mathcal{G}_j} x_i \\le c_j \\ \\ \\forall j \\in \\{\\mathcal{A},\\mathcal{B},\\mathcal{C}\\}$ (分组上限约束)\n3. $x_i \\in \\{0,1\\}$ (二元决策变量)\n\n### 第二步：使用提取的已知条件进行验证\n问题根据指定标准进行验证。\n- **科学依据**：该问题是运筹学和计算机科学中一个成熟的公式，称为整数线性规划，特别是 $0$-$1$ 背包问题的一个变体（广义分配问题或多选多维背包问题）。它是资源分配的标准模型，具有科学合理性。\n- **适定性**：该问题是适定的。可行解的集合是有限的（$2^9$ 种可能性的一个子集），确保了最大值的存在。数据和约束条件定义清晰，能够得到唯一的最优目标值。\n- **客观性**：问题陈述完全客观，使用精确的数学定义和数值，没有任何主观或含糊的语言。\n- **完整性和一致性**：所有必要的数据（$r_i$, $K$, $c_j$ 和组别定义）都已提供。约束条件之间没有矛盾。例如，分组上限之和（$2+1+2=5$）大于总列表大小 $K=4$，这是一个非平凡的条件。\n- **未检测到其他缺陷。** 问题结构正式且可解。\n\n### 第三步：结论和行动\n问题有效。将提供完整的解答。\n\n### 解题推导\n问题是选择一个项目子集，使得在满足总基数约束和每组基数约束的情况下，总相关性最大化。题目要求基于 $0$-$1$ 背包框架推导一个等价的组合公式。这可以通过将问题重新表述为多重选择背包问题（MCKP）来实现。\n\n核心思想是，对于每个组 $\\mathcal{G}_j$，如果我们决定选择恰好 $k$ 个项目（其中 $0 \\le k \\le c_j$），最优选择总是选择该组内相关性分数最高的 $k$ 个项目。任何其他 $k$ 个项目的选择都会产生较小的总相关性，因此是次优的。\n\n这使我们能够为每个组别预先计算项目的“捆绑包”。每个捆绑包对应于从该组别中选择 $k$ 个项目的选择。一个捆绑包的特征是其“成本”（项目数量 $k$）和其“价值”（前 $k$ 个项目的相关性之和）。\n\n令 $V_{j,k}$ 为从组 $j$ 中选出的大小为 $k$ 的最优捆绑包的价值，$W_{j,k}$ 为其成本。成本就是 $W_{j,k}=k$。\n\n**组 $\\mathcal{A}$**：项目 $\\{1,2,3\\}$，分数 $\\{9, 8.2, 6.1\\}$，上限 $c_{\\mathcal{A}}=2$。\n按相关性排序的项目为项目 $1$ ($r_1=9$)，项目 $2$ ($r_2=8.2$) 和项目 $3$ ($r_3=6.1$)。\n- 捆绑包 $\\mathcal{A}_0$（选择 $k=0$ 个项目）：价值 $V_{\\mathcal{A},0}=0$，成本 $W_{\\mathcal{A},0}=0$。\n- 捆绑包 $\\mathcal{A}_1$（选择 $k=1$ 个项目）：选择项目 $1$。价值 $V_{\\mathcal{A},1}=9$，成本 $W_{\\mathcal{A},1}=1$。\n- 捆绑包 $\\mathcal{A}_2$（选择 $k=2$ 个项目）：选择项目 $1,2$。价值 $V_{\\mathcal{A},2}=r_1+r_2=9+8.2=17.2$，成本 $W_{\\mathcal{A},2}=2$。\n\n**组 $\\mathcal{B}$**：项目 $\\{4,5,6\\}$，分数 $\\{7.5, 7.4, 4\\}$，上限 $c_{\\mathcal{B}}=1$。\n按相关性排序的项目为项目 $4$ ($r_4=7.5$)，项目 $5$ ($r_5=7.4$) 和项目 $6$ ($r_6=4$)。\n- 捆绑包 $\\mathcal{B}_0$（选择 $k=0$ 个项目）：价值 $V_{\\mathcal{B},0}=0$，成本 $W_{\\mathcal{B},0}=0$。\n- 捆绑包 $\\mathcal{B}_1$（选择 $k=1$ 个项目）：选择项目 $4$。价值 $V_{\\mathcal{B},1}=7.5$，成本 $W_{\\mathcal{B},1}=1$。\n\n**组 $\\mathcal{C}$**：项目 $\\{7,8,9\\}$，分数 $\\{5.9, 5.2, 3.5\\}$，上限 $c_{\\mathcal{C}}=2$。\n按相关性排序的项目为项目 $7$ ($r_7=5.9$)，项目 $8$ ($r_8=5.2$) 和项目 $9$ ($r_9=3.5$)。\n- 捆绑包 $\\mathcal{C}_0$（选择 $k=0$ 个项目）：价值 $V_{\\mathcal{C},0}=0$，成本 $W_{\\mathcal{C},0}=0$。\n- 捆绑包 $\\mathcal{C}_1$（选择 $k=1$ 个项目）：选择项目 $7$。价值 $V_{\\mathcal{C},1}=5.9$，成本 $W_{\\mathcal{C},1}=1$。\n- 捆绑包 $\\mathcal{C}_2$（选择 $k=2$ 个项目）：选择项目 $7,8$。价值 $V_{\\mathcal{C},2}=r_7+r_8=5.9+5.2=11.1$，成本 $W_{\\mathcal{C},2}=2$。\n\n原问题现在等价于从每个组别中恰好选择一个捆绑包，使得成本之和（项目总数）不超过背包容量 $K=4$，并且价值之和最大化。令 $(k_{\\mathcal{A}}, k_{\\mathcal{B}}, k_{\\mathcal{C}})$ 为一个三元组，分别表示从组 $\\mathcal{A}$、$\\mathcal{B}$ 和 $\\mathcal{C}$ 中选择的项目数量。我们必须满足 $k_{\\mathcal{A}} \\le c_{\\mathcal{A}}$，$k_{\\mathcal{B}} \\le c_{\\mathcal{B}}$，$k_{\\mathcal{C}} \\le c_{\\mathcal{C}}$，以及总项目数约束 $k_{\\mathcal{A}} + k_{\\mathcal{B}} + k_{\\mathcal{C}} \\le K=4$。\n\n我们需要找到：\n$$\n\\max_{k_{\\mathcal{A}}, k_{\\mathcal{B}}, k_{\\mathcal{C}}} \\left( V_{\\mathcal{A},k_{\\mathcal{A}}} + V_{\\mathcal{B},k_{\\mathcal{B}}} + V_{\\mathcal{C},k_{\\mathcal{C}}} \\right)\n$$\n约束条件为：\n$$\nk_{\\mathcal{A}} \\in \\{0, 1, 2\\}, \\quad k_{\\mathcal{B}} \\in \\{0, 1\\}, \\quad k_{\\mathcal{C}} \\in \\{0, 1, 2\\}\n$$\n$$\nk_{\\mathcal{A}} + k_{\\mathcal{B}} + k_{\\mathcal{C}} \\le 4\n$$\n\n由于所有相关性分数都是正数，最优解将尽可能多地利用项目，直到达到总限制 $K=4$。因此，我们枚举所有和为 $4$ 或更小的组合 $(k_{\\mathcal{A}}, k_{\\mathcal{B}}, k_{\\mathcal{C}})$，并计算总价值。我们专注于和为 $4$ 的组合，因为它们最有可能成为最大值的候选者。\n\n和为 $4$ 的组合 $(k_{\\mathcal{A}}, k_{\\mathcal{B}}, k_{\\mathcal{C}})$：\n1.  $(k_{\\mathcal{A}}, k_{\\mathcal{B}}, k_{\\mathcal{C}}) = (2, 1, 1)$: 这个组合是有效的，因为 $k_{\\mathcal{A}}=2 \\le c_{\\mathcal{A}}$，$k_{\\mathcal{B}}=1 \\le c_{\\mathcal{B}}$，且 $k_{\\mathcal{C}}=1 \\le c_{\\mathcal{C}}$。\n    总价值 = $V_{\\mathcal{A},2} + V_{\\mathcal{B},1} + V_{\\mathcal{C},1} = 17.2 + 7.5 + 5.9 = 30.6$。\n    选择的项目是来自 $\\mathcal{A}$ 组的 $\\{1, 2\\}$，来自 $\\mathcal{B}$ 组的 $\\{4\\}$，以及来自 $\\mathcal{C}$ 组的 $\\{7\\}$。\n\n2.  $(k_{\\mathcal{A}}, k_{\\mathcal{B}}, k_{\\mathcal{C}}) = (2, 0, 2)$: 这个组合是有效的。\n    总价值 = $V_{\\mathcal{A},2} + V_{\\mathcal{B},0} + V_{\\mathcal{C},2} = 17.2 + 0 + 11.1 = 28.3$。\n\n3.  $(k_{\\mathcal{A}}, k_{\\mathcal{B}}, k_{\\mathcal{C}}) = (1, 1, 2)$: 这个组合是有效的。\n    总价值 = $V_{\\mathcal{A},1} + V_{\\mathcal{B},1} + V_{\\mathcal{C},2} = 9 + 7.5 + 11.1 = 27.6$。\n\n在遵守分组上限的情况下，没有其他和为 $4$ 的 $(k_{\\mathcal{A}}, k_{\\mathcal{B}}, k_{\\mathcal{C}})$ 组合。例如，$(1,2,1)$ 是无效的，因为 $k_{\\mathcal{B}}=2  c_{\\mathcal{B}}=1$。\n\n和小于 $4$ 的组合将具有较低的总价值。例如，和为 $3$ 的最佳组合是 $(k_{\\mathcal{A}}, k_{\\mathcal{B}}, k_{\\mathcal{C}}) = (2, 1, 0)$，其产生的价值为 $V_{\\mathcal{A},2} + V_{\\mathcal{B},1} + V_{\\mathcal{C},0} = 17.2 + 7.5 + 0 = 24.7$。这小于 $30.6$。\n\n比较和为 $4$ 的组合计算出的价值：\n- 组合 $(2,1,1)$ 产生的价值为 $30.6$。\n- 组合 $(2,0,2)$ 产生的价值为 $28.3$。\n- 组合 $(1,1,2)$ 产生的价值为 $27.6$。\n\n可实现的最大总相关性是这些价值中的最高者。\n\n最大值 = $\\max(30.6, 28.3, 27.6) = 30.6$。\n\n这对应于从 $\\mathcal{A}$ 组中选择 $2$ 个项目（项目 $1$ 和 $2$），从 $\\mathcal{B}$ 组中选择 $1$ 个项目（项目 $4$），以及从 $\\mathcal{C}$ 组中选择 $1$ 个项目（项目 $7$）。项目总数为 $2+1+1=4$，满足列表大小约束 $\\sum x_i \\le 4$。分组约束也得到满足。", "answer": "$$\n\\boxed{30.6}\n$$", "id": "3167527"}]}