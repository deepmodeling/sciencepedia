{"hands_on_practices": [{"introduction": "理解像期望最大化（EM）这样的迭代算法最好的方法之一就是亲手执行一次迭代。本练习提供了一个具体的数据集和初始参数，引导您逐步完成一个高斯混合模型的E步（计算每个数据点属于每个分量的“责任”）和M步（根据责任更新模型参数）。通过这个计算过程，EM算法的抽象概念将变得清晰而具体。[@problem_id:1960172]", "problem": "一位研究人员正在分析一个测量数据集，该数据集被认为是从两个不同总体 A 和 B 的混合体中抽样得到的。他们决定使用一个双组分高斯混合模型 (GMM) 对数据进行建模。单个数据点 $x$ 的概率密度函数 (PDF) 由下式给出：\n$$p(x | \\theta) = \\pi_A \\mathcal{N}(x | \\mu_A, \\sigma_A^2) + \\pi_B \\mathcal{N}(x | \\mu_B, \\sigma_B^2)$$\n其中 $\\pi_A$ 和 $\\pi_B$ 是混合比例 (满足 $\\pi_A + \\pi_B = 1$)，而 $\\mathcal{N}(x | \\mu, \\sigma^2)$ 是高斯概率密度函数 (PDF)：\n$$\\mathcal{N}(x | \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)$$\n\n数据集包含以下五个测量值：$\\{4.0, 4.5, 5.0, 8.0, 9.0\\}$。\n为简便起见，假设两个组分的方差已知并固定为 $\\sigma_A^2 = \\sigma_B^2 = 1.0$。\n\n研究人员按如下方式初始化期望最大化 (EM) 算法的模型参数：\n- 初始均值：$\\mu_A^{(0)} = 4.2$ 和 $\\mu_B^{(0)} = 8.8$。\n- 初始混合比例：$\\pi_A^{(0)} = 0.5$ 和 $\\pi_B^{(0)} = 0.5$。\n\n您的任务是执行一次完整的 EM 算法迭代，包括一个期望步骤 (E-step) 和一个最大化步骤 (M-step)，以计算更新后的参数。\n\n计算第一个组分均值的更新值 $\\mu_A^{(1)}$。将您的答案以实数形式报告，并四舍五入到四位有效数字。", "solution": "我们对双组分高斯混合模型应用一次期望最大化 (EM) 迭代，其固定方差为 $\\sigma_{A}^{2}=\\sigma_{B}^{2}=1$，初始参数为 $\\mu_{A}^{(0)}=4.2$，$\\mu_{B}^{(0)}=8.8$，$\\pi_{A}^{(0)}=\\pi_{B}^{(0)}=0.5$。\n\nE步（责任计算）：\n对于每个数据点 $x_{i}$，组分 $A$ 的责任为\n$$\nr_{iA} \\equiv \\gamma_{iA} = \\frac{\\pi_{A}^{(0)} \\mathcal{N}(x_{i} \\mid \\mu_{A}^{(0)},1)}{\\pi_{A}^{(0)} \\mathcal{N}(x_{i} \\mid \\mu_{A}^{(0)},1) + \\pi_{B}^{(0)} \\mathcal{N}(x_{i} \\mid \\mu_{B}^{(0)},1)}.\n$$\n由于 $\\pi_{A}^{(0)}=\\pi_{B}^{(0)}$ 且方差相等，公共因子可以消去：\n$$\nr_{iA}=\\frac{\\exp\\left(-\\frac{(x_{i}-\\mu_{A}^{(0)})^{2}}{2}\\right)}{\\exp\\left(-\\frac{(x_{i}-\\mu_{A}^{(0)})^{2}}{2}\\right)+\\exp\\left(-\\frac{(x_{i}-\\mu_{B}^{(0)})^{2}}{2}\\right)}=\\frac{1}{1+\\exp\\left(\\frac{(x_{i}-\\mu_{A}^{(0)})^{2}-(x_{i}-\\mu_{B}^{(0)})^{2}}{2}\\right)}.\n$$\n对于数据集 $\\{4.0,4.5,5.0,8.0,9.0\\}$ 和 $(\\mu_{A}^{(0)},\\mu_{B}^{(0)})=(4.2,8.8)$：\n- 对于 $x_{1}=4.0$：$(x_{1}-\\mu_{A}^{(0)})^{2}=0.04$，$(x_{1}-\\mu_{B}^{(0)})^{2}=23.04$，所以\n$$\nr_{1A}=\\frac{1}{1+\\exp(-11.5)}\\approx 0.9999898625.\n$$\n- 对于 $x_{2}=4.5$：$(x_{2}-\\mu_{A}^{(0)})^{2}=0.09$，$(x_{2}-\\mu_{B}^{(0)})^{2}=18.49$，所以\n$$\nr_{2A}=\\frac{1}{1+\\exp(-9.2)}\\approx 0.9998989606.\n$$\n- 对于 $x_{3}=5.0$：$(x_{3}-\\mu_{A}^{(0)})^{2}=0.64$，$(x_{3}-\\mu_{B}^{(0)})^{2}=14.44$，所以\n$$\nr_{3A}=\\frac{1}{1+\\exp(-6.9)}\\approx 0.9989932309.\n$$\n- 对于 $x_{4}=8.0$：$(x_{4}-\\mu_{A}^{(0)})^{2}=14.44$，$(x_{4}-\\mu_{B}^{(0)})^{2}=0.64$，所以\n$$\nr_{4A}=\\frac{1}{1+\\exp(6.9)}=1-r_{3A}\\approx 0.0010067691.\n$$\n- 对于 $x_{5}=9.0$：$(x_{5}-\\mu_{A}^{(0)})^{2}=23.04$，$(x_{5}-\\mu_{B}^{(0)})^{2}=0.04$，所以\n$$\nr_{5A}=\\frac{1}{1+\\exp(11.5)}=1-r_{1A}\\approx 0.0000101375.\n$$\n注意根据对称性，$r_{1A}+r_{5A}=1$ 且 $r_{3A}+r_{4A}=1$。\n\nM步（更新组分A的均值）：\n在方差固定的情况下，更新后的均值是责任加权平均值：\n$$\n\\mu_{A}^{(1)}=\\frac{\\sum_{i=1}^{5} r_{iA} x_{i}}{\\sum_{i=1}^{5} r_{iA}}.\n$$\n利用对称性计算分母：\n$$\n\\sum_{i=1}^{5} r_{iA}=(r_{1A}+r_{5A})+(r_{3A}+r_{4A})+r_{2A}=2+r_{2A}\\approx 2.9998989606.\n$$\n计算分子；将对称的对组合在一起：\n$$\n\\sum_{i=1}^{5} r_{iA} x_{i}=(r_{1A}\\cdot 4.0 + r_{5A}\\cdot 9.0) + (r_{3A}\\cdot 5.0 + r_{4A}\\cdot 8.0) + r_{2A}\\cdot 4.5.\n$$\n使用 $r_{5A}=1-r_{1A}$ 和 $r_{4A}=1-r_{3A}$：\n$$\nr_{1A}\\cdot 4.0 + r_{5A}\\cdot 9.0 = 9 - 5 r_{1A},\\quad\nr_{3A}\\cdot 5.0 + r_{4A}\\cdot 8.0 = 8 - 3 r_{3A}.\n$$\n因此\n$$\n\\sum_{i=1}^{5} r_{iA} x_{i} = 17 - 5 r_{1A} - 3 r_{3A} + 4.5 r_{2A} \\approx 13.5026163178.\n$$\n所以，\n$$\n\\mu_{A}^{(1)}=\\frac{13.5026163178}{2.9998989606}\\approx 4.501023693.\n$$\n四舍五入到四位有效数字，更新后的均值为 $4.501$。", "answer": "$$\\boxed{4.501}$$", "id": "1960172"}, {"introduction": "在掌握了EM算法的基本迭代步骤后，探索其对初始条件的敏感性至关重要。本练习提出了一个重要的“假设”情景：如果两个高斯分量的初始均值完全相同会发生什么？通过这个思想实验，您将发现一个看似合理但对称的初始化如何使EM算法陷入困境，无法有效分离数据簇，从而加深对算法行为和潜在陷阱的理解。[@problem_id:1960187]", "problem": "一位统计学家的任务是使用期望最大化（EM）算法将一个双组分高斯混合模型（GMM）拟合到一个小的一维数据集上。该数据集包含四个数据点：$X = \\{-3, -1, 1, 5\\}$。\n\nGMM有两个组分，记为 A 和 B。在初始步骤（迭代 $t=0$）中，参数被对称地初始化如下：\n-   混合系数：$\\pi_A^{(0)} = 0.5$ 和 $\\pi_B^{(0)} = 0.5$。\n-   均值：$\\mu_A^{(0)} = 0$ 和 $\\mu_B^{(0)} = 0$。\n-   方差：$\\sigma_A^{2(0)} = 1$ 和 $\\sigma_B^{2(0)} = 1$。\n\n你的任务是执行一次完整的 EM 算法迭代。计算在第一次期望步骤和最大化步骤之后均值的更新值 $\\mu_A^{(1)}$ 和 $\\mu_B^{(1)}$。将最终答案表示为 $(\\mu_A^{(1)}, \\mu_B^{(1)})$ 的一对精确值。", "solution": "我们用一个双组分一维高斯混合模型来对数据建模，在迭代 $t=0$ 时的参数为：$\\pi_{A}^{(0)}=\\pi_{B}^{(0)}=\\frac{1}{2}$，$\\mu_{A}^{(0)}=\\mu_{B}^{(0)}=0$，以及 $\\sigma_{A}^{2(0)}=\\sigma_{B}^{2(0)}=1$。高斯密度函数为\n$$\nf(x \\mid \\mu, \\sigma^{2})=\\frac{1}{\\sqrt{2\\pi \\sigma^{2}}}\\exp\\left(-\\frac{(x-\\mu)^{2}}{2\\sigma^{2}}\\right).\n$$\n\nE步：组分 $A$ 对数据点 $x_{i}$ 的响应度为\n$$\n\\gamma_{iA}^{(0)}=\\frac{\\pi_{A}^{(0)} f(x_{i}\\mid \\mu_{A}^{(0)}, \\sigma_{A}^{2(0)})}{\\pi_{A}^{(0)} f(x_{i}\\mid \\mu_{A}^{(0)}, \\sigma_{A}^{2(0)})+\\pi_{B}^{(0)} f(x_{i}\\mid \\mu_{B}^{(0)}, \\sigma_{B}^{2(0)})}.\n$$\n由于 $\\pi_{A}^{(0)}=\\pi_{B}^{(0)}$，$\\mu_{A}^{(0)}=\\mu_{B}^{(0)}$，且 $\\sigma_{A}^{2(0)}=\\sigma_{B}^{2(0)}$，分母中的两项对于每个 $x_{i}$ 都相等，因此\n$$\n\\gamma_{iA}^{(0)}=\\frac{1}{2},\\qquad \\gamma_{iB}^{(0)}=\\frac{1}{2}\\quad \\text{for all } i\\in\\{1,2,3,4\\}.\n$$\n\nM步：均值的更新公式为\n$$\n\\mu_{A}^{(1)}=\\frac{\\sum_{i=1}^{4}\\gamma_{iA}^{(0)} x_{i}}{\\sum_{i=1}^{4}\\gamma_{iA}^{(0)}},\\qquad\n\\mu_{B}^{(1)}=\\frac{\\sum_{i=1}^{4}\\gamma_{iB}^{(0)} x_{i}}{\\sum_{i=1}^{4}\\gamma_{iB}^{(0)}}.\n$$\n当 $\\gamma_{iA}^{(0)}=\\gamma_{iB}^{(0)}=\\frac{1}{2}$ 时，\n$$\n\\mu_{A}^{(1)}=\\frac{\\frac{1}{2}\\sum_{i=1}^{4} x_{i}}{\\frac{1}{2}\\cdot 4}=\\frac{\\sum_{i=1}^{4} x_{i}}{4},\\qquad\n\\mu_{B}^{(1)}=\\frac{\\sum_{i=1}^{4} x_{i}}{4}.\n$$\n对于数据集 $X=\\{-3,-1,1,5\\}$，\n$$\n\\sum_{i=1}^{4} x_{i}=(-3)+(-1)+1+5=2,\\quad \\text{所以}\\quad \\mu_{A}^{(1)}=\\mu_{B}^{(1)}=\\frac{2}{4}=\\frac{1}{2}.\n$$\n因此，在一次完整的 EM 迭代之后，更新后的均值均为 $\\frac{1}{2}$。", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{1}{2} & \\frac{1}{2} \\end{pmatrix}}$$", "id": "1960187"}, {"introduction": "EM算法是一个通用的框架，其应用远不止于高斯混合模型。为了检验您是否真正掌握了其核心思想，本练习将挑战您将EM算法应用于一个由指数分布组成的混合模型。您需要首先推导出适用于该模型的E步和M步更新公式，然后将您的推导应用于一个数值实例。这个过程不仅能巩固您的理论推导能力，也证明了您可以将EM的原理灵活运用于新的统计模型。[@problem_id:3119716]", "problem": "考虑一个由 $K$ 个分量组成的有限指数分布混合模型。观测数据为 $x_{1}, \\dots, x_{N}$，每个 $x_{n} \\in \\mathbb{R}_{+}$，假设它们独立同分布 (i.i.d.)，来自带有参数 $\\{\\pi_{k}\\}_{k=1}^{K}$ 和 $\\{\\lambda_{k}\\}_{k=1}^{K}$ 的混合模型，其中 $\\pi_{k} \\ge 0$, $\\sum_{k=1}^{K} \\pi_{k} = 1$, 且 $\\lambda_{k} > 0$。指数概率密度函数为 $p(x \\mid \\lambda) = \\lambda \\exp(-\\lambda x)$，其中 $x \\ge 0$。引入潜在指示变量 $z_{n,k} \\in \\{0,1\\}$，满足 $\\sum_{k=1}^{K} z_{n,k} = 1$。从贝叶斯法则和完全数据似然 $p(\\{x_{n}\\},\\{z_{n,k}\\} \\mid \\{\\pi_{k}\\},\\{\\lambda_{k}\\})$ 出发，推导期望最大化 (EM) 算法中的“责任”(responsibilities) $\\gamma_{n,k} = \\mathbb{E}[z_{n,k} \\mid x_{n}]$，以及通过最大化期望完全数据对数似然函数来推导指数率 $\\lambda_{k}$ 的最大化步骤 (M-step) 更新公式。\n\n然后，将您的推导应用于以下具体实例。设 $K=2$, $N=4$，数据为 $x_{1} = 0.2$, $x_{2} = 0.6$, $x_{3} = 1.0$, $x_{4} = 2.0$。假设在第 $t$ 次迭代时，当前参数为 $\\pi_{1}^{(t)} = 0.7$, $\\pi_{2}^{(t)} = 0.3$, $\\lambda_{1}^{(t)} = 2.0$, $\\lambda_{2}^{(t)} = 0.5$。计算 $n=1,2,3,4$ 时的“责任” $\\gamma_{n,1}$，然后使用您的 M 步表达式计算更新后的率 $\\lambda_{1}^{(t+1)}$。将您的最终数值答案四舍五入至四位有效数字。仅报告 $\\lambda_{1}^{(t+1)}$ 的值。", "solution": "该问题要求推导指数分布混合模型的期望最大化 (EM) 算法更新方程，并将这些方程应用于一个具体的数值例子。\n\n首先，我们推导通用方程。该模型是 $K$ 个指数分布的混合。观测数据为 $\\mathbf{x} = \\{x_1, \\dots, x_N\\}$，其中每个 $x_n \\in \\mathbb{R}_{+}$。参数为 $\\theta = \\{\\{\\pi_k\\}_{k=1}^K, \\{\\lambda_k\\}_{k=1}^K\\}$。对于率参数为 $\\lambda_k$ 的单个指数分布，其概率密度函数 (PDF) 为 $p(x \\mid \\lambda_k) = \\lambda_k \\exp(-\\lambda_k x)$。潜在变量 $z_{n,k} \\in \\{0,1\\}$ 指示数据点 $x_n$ 是由哪个分量生成的，且 $\\sum_{k=1}^K z_{n,k} = 1$。$z_{n,k}=1$ 的先验概率是混合系数 $\\pi_k$。\n\n给定观测数据 $\\mathbf{x}$ 和潜在变量 $\\mathbf{z} = \\{z_{n,k}\\}$，完全数据似然函数为：\n$$p(\\mathbf{x}, \\mathbf{z} \\mid \\theta) = \\prod_{n=1}^N p(x_n, \\mathbf{z}_n \\mid \\theta) = \\prod_{n=1}^N \\prod_{k=1}^K [p(x_n \\mid z_{n,k}=1, \\theta) p(z_{n,k}=1 \\mid \\theta)]^{z_{n,k}}$$\n$$p(\\mathbf{x}, \\mathbf{z} \\mid \\theta) = \\prod_{n=1}^N \\prod_{k=1}^K [\\pi_k p(x_n \\mid \\lambda_k)]^{z_{n,k}}$$\n代入指数 PDF，我们得到：\n$$p(\\mathbf{x}, \\mathbf{z} \\mid \\theta) = \\prod_{n=1}^N \\prod_{k=1}^K [\\pi_k \\lambda_k \\exp(-\\lambda_k x_n)]^{z_{n,k}}$$\n完全数据对数似然函数为：\n$$\\ln p(\\mathbf{x}, \\mathbf{z} \\mid \\theta) = \\sum_{n=1}^N \\sum_{k=1}^K z_{n,k} (\\ln \\pi_k + \\ln \\lambda_k - \\lambda_k x_n)$$\n\nEM 算法分两步进行：期望步骤 (E-step) 和最大化步骤 (M-step)。\n\n**E 步：责任的推导**\n在 E 步中，我们计算给定数据和当前参数估计值 $\\theta^{(t)} = \\{\\pi_k^{(t)}, \\lambda_k^{(t)}\\}$ 时，潜在变量的后验概率。这个后验概率就是“责任” $\\gamma_{n,k}$。\n$$\\gamma_{n,k} = p(z_{n,k}=1 \\mid x_n, \\theta^{(t)}) = \\mathbb{E}[z_{n,k} \\mid x_n, \\theta^{(t)}]$$\n使用贝叶斯法则：\n$$\\gamma_{n,k} = \\frac{p(x_n \\mid z_{n,k}=1, \\theta^{(t)}) p(z_{n,k}=1 \\mid \\theta^{(t)})}{\\sum_{j=1}^K p(x_n \\mid z_{n,j}=1, \\theta^{(t)}) p(z_{n,j}=1 \\mid \\theta^{(t)})} = \\frac{\\pi_k^{(t)} p(x_n \\mid \\lambda_k^{(t)})}{\\sum_{j=1}^K \\pi_j^{(t)} p(x_n \\mid \\lambda_j^{(t)})}$$\n代入指数 PDF，我们得到“责任”的表达式：\n$$\\gamma_{n,k} = \\frac{\\pi_k^{(t)} \\lambda_k^{(t)} \\exp(-\\lambda_k^{(t)} x_n)}{\\sum_{j=1}^K \\pi_j^{(t)} \\lambda_j^{(t)} \\exp(-\\lambda_j^{(t)} x_n)}$$\n\n**M 步：$\\lambda_k$ 更新公式的推导**\n在 M 步中，我们相对于参数 $\\theta$ 最大化期望完全数据对数似然函数，记为 $Q(\\theta \\mid \\theta^{(t)})$。\n$$Q(\\theta \\mid \\theta^{(t)}) = \\mathbb{E}_{\\mathbf{z} \\mid \\mathbf{x}, \\theta^{(t)}}[\\ln p(\\mathbf{x}, \\mathbf{z} \\mid \\theta)] = \\sum_{n=1}^N \\sum_{k=1}^K \\mathbb{E}[z_{n,k}] (\\ln \\pi_k + \\ln \\lambda_k - \\lambda_k x_n)$$\n由于 $\\mathbb{E}[z_{n,k}] = \\gamma_{n,k}$，我们有：\n$$Q(\\theta \\mid \\theta^{(t)}) = \\sum_{n=1}^N \\sum_{k=1}^K \\gamma_{n,k} (\\ln \\pi_k + \\ln \\lambda_k - \\lambda_k x_n)$$\n为了找到 $\\lambda_k$ 的更新公式，我们对 $Q$ 关于 $\\lambda_k$ 进行最大化。我们将 $Q$ 对 $\\lambda_k$ 求导，并令导数为零。我们只需要考虑包含 $\\lambda_k$ 的项：\n$$\\frac{\\partial Q}{\\partial \\lambda_k} = \\frac{\\partial}{\\partial \\lambda_k} \\sum_{n=1}^N \\gamma_{n,k} (\\ln \\lambda_k - \\lambda_k x_n) = \\sum_{n=1}^N \\gamma_{n,k} \\left( \\frac{1}{\\lambda_k} - x_n \\right) = 0$$\n求解 $\\lambda_k$：\n$$\\frac{1}{\\lambda_k} \\sum_{n=1}^N \\gamma_{n,k} = \\sum_{n=1}^N \\gamma_{n,k} x_n$$\n这就得到了率参数 $\\lambda_k$ 的 M 步更新方程：\n$$\\lambda_k^{(t+1)} = \\frac{\\sum_{n=1}^N \\gamma_{n,k}}{\\sum_{n=1}^N \\gamma_{n,k} x_n}$$\n\n现在我们将这些推导应用于具体实例。\n给定数据为 $K=2$, $N=4$, $x_1=0.2$, $x_2=0.6$, $x_3=1.0$, $x_4=2.0$。\n第 $t$ 次迭代的参数为 $\\pi_1^{(t)} = 0.7$, $\\pi_2^{(t)} = 0.3$, $\\lambda_1^{(t)} = 2.0$, $\\lambda_2^{(t)} = 0.5$。\n\n首先，我们使用推导出的 E 步公式计算 $n=1,2,3,4$ 的“责任” $\\gamma_{n,1}$。\n对于一个通用数据点 $x_n$，令分子项为 $A_n = \\pi_1^{(t)} \\lambda_1^{(t)} \\exp(-\\lambda_1^{(t)} x_n)$ 和 $B_n = \\pi_2^{(t)} \\lambda_2^{(t)} \\exp(-\\lambda_2^{(t)} x_n)$。那么 $\\gamma_{n,1} = A_n / (A_n + B_n)$。\n\n对于 $x_1 = 0.2$：\n$A_1 = 0.7 \\times 2.0 \\times \\exp(-2.0 \\times 0.2) = 1.4 \\exp(-0.4) \\approx 0.93845$\n$B_1 = 0.3 \\times 0.5 \\times \\exp(-0.5 \\times 0.2) = 0.15 \\exp(-0.1) \\approx 0.13573$\n$\\gamma_{1,1} = \\frac{0.93845}{0.93845 + 0.13573} \\approx 0.87365$\n\n对于 $x_2 = 0.6$：\n$A_2 = 1.4 \\exp(-2.0 \\times 0.6) = 1.4 \\exp(-1.2) \\approx 0.42167$\n$B_2 = 0.15 \\exp(-0.5 \\times 0.6) = 0.15 \\exp(-0.3) \\approx 0.11112$\n$\\gamma_{2,1} = \\frac{0.42167}{0.42167 + 0.11112} \\approx 0.79143$\n\n对于 $x_3 = 1.0$：\n$A_3 = 1.4 \\exp(-2.0 \\times 1.0) = 1.4 \\exp(-2.0) \\approx 0.18947$\n$B_3 = 0.15 \\exp(-0.5 \\times 1.0) = 0.15 \\exp(-0.5) \\approx 0.09098$\n$\\gamma_{3,1} = \\frac{0.18947}{0.18947 + 0.09098} \\approx 0.67563$\n\n对于 $x_4 = 2.0$：\n$A_4 = 1.4 \\exp(-2.0 \\times 2.0) = 1.4 \\exp(-4.0) \\approx 0.02564$\n$B_4 = 0.15 \\exp(-0.5 \\times 2.0) = 0.15 \\exp(-1.0) \\approx 0.05518$\n$\\gamma_{4,1} = \\frac{0.02564}{0.02564 + 0.05518} \\approx 0.31726$\n\n接下来，我们使用 M 步公式计算更新后的参数 $\\lambda_1^{(t+1)}$。\n分子：分量 1 的“责任”之和。\n$$\\sum_{n=1}^4 \\gamma_{n,1} \\approx 0.87365 + 0.79143 + 0.67563 + 0.31726 \\approx 2.65797$$\n分母：分量 1 的数据点的加权和。\n$$\\sum_{n=1}^4 \\gamma_{n,1} x_n \\approx (0.87365 \\times 0.2) + (0.79143 \\times 0.6) + (0.67563 \\times 1.0) + (0.31726 \\times 2.0)$$\n$$\\sum_{n=1}^4 \\gamma_{n,1} x_n \\approx 0.17473 + 0.47486 + 0.67563 + 0.63452 \\approx 1.95974$$\n最后，我们计算更新后的率 $\\lambda_1^{(t+1)}$：\n$$\\lambda_1^{(t+1)} = \\frac{\\sum_{n=1}^4 \\gamma_{n,1}}{\\sum_{n=1}^4 \\gamma_{n,1} x_n} \\approx \\frac{2.65797}{1.95974} \\approx 1.356294$$\n将最终答案四舍五入至四位有效数字，得到 $1.356$。", "answer": "$$\\boxed{1.356}$$", "id": "3119716"}]}