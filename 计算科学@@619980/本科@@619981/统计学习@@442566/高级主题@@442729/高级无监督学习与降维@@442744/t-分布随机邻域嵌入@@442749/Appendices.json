{"hands_on_practices": [{"introduction": "t-SNE 在可视化方面的成功并非偶然，而是源于一个关键的数学设计：在低维空间中使用学生 t-分布（Student's t-distribution）。这个练习将通过推导一个通用核函数的梯度（即点之间的“作用力”）来揭示这一选择的奥秘。通过比较标准 t-分布核与一个假设的拉普拉斯核（Laplace kernel），你将分析它们产生的远距离排斥力，从而理解为何重尾分布对于解决“拥挤问题”和形成清晰的类簇至关重要 [@problem_id:3179628]。", "problem": "考虑 t-分布随机邻域嵌入 (t-SNE) 方法，其目标可以写成高维邻域概率与低维核诱导概率之间的 Kullback-Leibler 散度 (KL)。令 $y_i \\in \\mathbb{R}^d$ 表示低维嵌入，$r_{ij} = \\lVert y_i - y_j \\rVert$ 表示成对距离。假设低维空间中的相似度由一个可微的径向核 $g(r)$ 定义，使得\n$$\nq_{ij} = \\frac{g(r_{ij})}{\\sum_{k \\ne \\ell} g(r_{k\\ell})},\n$$\n且目标函数为\n$$\nC(y) = \\sum_{i \\ne j} p_{ij} \\log\\left(\\frac{p_{ij}}{q_{ij}}\\right),\n$$\n其中 $p_{ij}$ 是固定的、对称的高维相似度，满足 $\\sum_{i \\ne j} p_{ij} = 1$。从这些核心定义出发，对于一个通用的可微核 $g(r)$，推导负梯度（“力”）$F_i = -\\frac{\\partial C}{\\partial y_i}$，并用 $p_{ij}$、$q_{ij}$、$g'(r)$ 和单位方向 $u_{ij} = \\frac{y_i - y_j}{r_{ij}}$ 来表示。然后，将您的表达式特化到远邻域（$p_{ij} + p_{ji} \\approx 0$ 的情况），并提取径向排斥力大小 $M(r)$ 作为 $r$ 的函数。\n\n接下来，考虑两个特定的核：\n- 自由度为 1 的 Student-t 核，定义为 $g_{\\mathrm{t}}(r) = (1 + r^2)^{-1}$。\n- 一个提出的拉普拉斯核变体，定义为 $g_{\\mathrm{L}}(r) = \\exp(-r)$。\n\n从第一性原理出发，确定当 $r \\to \\infty$ 时排斥力大小 $M_{\\mathrm{t}}(r)$ 和 $M_{\\mathrm{L}}(r)$ 的远距离渐进行为，并评估拉普拉斯核的尾部形状是否相对于 Student-t 核缓解了拥挤问题。您的分析必须从 KL 目标和上面 $q_{ij}$ 的定义出发；不要假设或使用 t-SNE 的预先给出的梯度公式。\n\n您的程序必须实现以下测试套件，每个测试产生一个基本类型的结果（布尔值或浮点数）：\n\n- 定义“力剖面比” $R(r)$ 如下\n$$\nR(r) = \\frac{\\left|g'_{\\mathrm{L}}(r)\\right|}{\\left|g'_{\\mathrm{t}}(r)\\right|},\n$$\n如果将归一化项 $\\sum_{k \\ne \\ell} g(r_{k\\ell})$ 视为一个与单个远距离点对无关的常数因子，则该比率与远邻排斥力大小之比成正比。计算集合 $\\{10^{-8}, 1, 5, 50\\}$ 中每个 $r$ 值的 $R(r)$，并以浮点数形式返回。\n\n- 返回一个布尔值，指示 $R(50)  10^{-6}$ 是否成立。\n\n- 计算浮点数\n$$\n\\Delta = \\int_{10}^{20} \\left|g'_{\\mathrm{L}}(r)\\right| \\, dr \\;-\\; \\int_{10}^{20} \\left|g'_{\\mathrm{t}}(r)\\right| \\, dr,\n$$\n使用数值积分，并返回 $\\Delta$。\n\n- 返回一个布尔值，指示 $\\Delta  0$ 是否成立。\n\n- 对于阈值 $\\tau = 10^{-3}$，分别计算使 $\\left|g'_{\\mathrm{L}}(r)\\right| = \\tau$ 和 $\\left|g'_{\\mathrm{t}}(r)\\right| = \\tau$ 成立的半径 $r^\\ast_{\\mathrm{L}}$ 和 $r^\\ast_{\\mathrm{t}}$，并返回浮点数比率 $r^\\ast_{\\mathrm{L}} / r^\\ast_{\\mathrm{t}}$。\n\n- 返回一个布尔值，指示 $r^\\ast_{\\mathrm{L}}  r^\\ast_{\\mathrm{t}}$ 是否成立。\n\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表（例如，“[result1,result2,result3,result4,result5,result6,result7,result8,result9]”）。此问题无需用户输入，也不涉及物理单位。", "solution": "问题的分析主要分两个阶段进行。首先，我们对通用核的 t-SNE 目标函数梯度进行形式化推导。其次，我们分析该梯度在两种特定核下的情况，并按要求评估其性质。\n\n### 步骤 1：通用梯度推导\n\n需要最小化的目标函数是高维相似度 $p_{ij}$ 和低维相似度 $q_{ij}$ 之间的 Kullback-Leibler (KL) 散度：\n$$\nC(y) = \\sum_{i \\ne j} p_{ij} \\log\\left(\\frac{p_{ij}}{q_{ij}}\\right)\n$$\n其中 $y_i \\in \\mathbb{R}^d$ 是低维嵌入。高维相似度 $p_{ij}$ 是给定的、固定的、对称的（$p_{ij}=p_{ji}$），并且归一化以满足 $\\sum_{i \\ne j} p_{ij} = 1$。低维相似度 $q_{ij}$ 由一个可微的径向核 $g(r)$ 定义：\n$$\nq_{ij} = \\frac{g(r_{ij})}{\\sum_{k \\ne \\ell} g(r_{k\\ell})} = \\frac{g(r_{ij})}{Z}\n$$\n其中 $r_{ij} = \\lVert y_i - y_j \\rVert$ 且 $Z = \\sum_{k \\ne \\ell} g(r_{k\\ell})$ 是归一化常数。\n\n我们可以通过分离包含 $y$ 的项来重写代价函数 $C(y)$：\n$$\nC(y) = \\sum_{i \\ne j} p_{ij} \\log p_{ij} - \\sum_{i \\ne j} p_{ij} \\log q_{ij}\n$$\n第一项相对于 $y_i$ 是常数。代入 $q_{ij}$ 的定义：\n$$\nC(y) = \\text{const} - \\sum_{i \\ne j} p_{ij} \\log \\left( \\frac{g(r_{ij})}{Z} \\right) = \\text{const} - \\sum_{i \\ne j} p_{ij} \\log g(r_{ij}) + \\left(\\sum_{i \\ne j} p_{ij}\\right) \\log Z\n$$\n由于 $\\sum_{i \\ne j} p_{ij} = 1$，我们有：\n$$\nC(y) = \\text{const} - \\sum_{i \\ne j} p_{ij} \\log g(r_{ij}) + \\log \\left( \\sum_{k \\ne \\ell} g(r_{k\\ell}) \\right)\n$$\n我们寻求负梯度，或称为“力”，$F_i = -\\frac{\\partial C}{\\partial y_i}$。我们计算梯度 $\\frac{\\partial C}{\\partial y_i}$：\n$$\n\\frac{\\partial C}{\\partial y_i} = -\\sum_{k \\ne \\ell} p_{k\\ell} \\frac{1}{g(r_{k\\ell})} \\frac{\\partial g(r_{k\\ell})}{\\partial y_i} + \\frac{1}{Z} \\frac{\\partial Z}{\\partial y_i}\n$$\n成对距离函数 $f(r_{k\\ell})$ 相对于 $y_i$ 的导数是：\n$$\n\\frac{\\partial f(r_{k\\ell})}{\\partial y_i} = f'(r_{k\\ell}) \\frac{\\partial r_{k\\ell}}{\\partial y_i} = f'(r_{k\\ell}) \\frac{y_k - y_\\ell}{r_{k\\ell}} (\\delta_{ik} - \\delta_{i\\ell}) = f'(r_{k\\ell}) u_{k\\ell} (\\delta_{ik} - \\delta_{i\\ell})\n$$\n其中 $u_{k\\ell} = (y_k - y_\\ell) / r_{k\\ell}$ 是单位方向向量。\n\n应用此公式，$\\frac{\\partial C}{\\partial y_i}$ 的第一项中的求和仅在 $k=i$ 或 $\\ell=i$ 时非零：\n$$\n-\\sum_{k \\ne \\ell} p_{k\\ell} \\frac{g'(r_{k\\ell})}{g(r_{k\\ell})} u_{k\\ell} (\\delta_{ik} - \\delta_{i\\ell}) = -\\sum_{j \\ne i} p_{ij} \\frac{g'(r_{ij})}{g(r_{ij})} u_{ij} - \\sum_{j \\ne i} p_{ji} \\frac{g'(r_{ji})}{g(r_{ji})} (-u_{ji})\n$$\n使用 $r_{ij}=r_{ji}$ 和 $u_{ij}=-u_{ji}$，第二部分变为 $-\\sum_{j \\ne i} p_{ji} \\frac{g'(r_{ij})}{g(r_{ij})} u_{ij}$。将它们合并得到：\n$$\n-\\sum_{j \\ne i} (p_{ij} + p_{ji}) \\frac{g'(r_{ij})}{g(r_{ij})} u_{ij}\n$$\n类似地，归一化常数 $Z$ 的导数是：\n$$\n\\frac{\\partial Z}{\\partial y_i} = \\sum_{k \\ne \\ell} g'(r_{k\\ell}) u_{k\\ell} (\\delta_{ik} - \\delta_{i\\ell}) = \\sum_{j \\ne i} g'(r_{ij})u_{ij} - \\sum_{j \\ne i} g'(r_{ji})u_{ji} = \\sum_{j \\ne i} (g'(r_{ij})u_{ij} - g'(r_{ij})(-u_{ij})) = 2\\sum_{j \\ne i} g'(r_{ij}) u_{ij}\n$$\n合并所有部分，梯度为：\n$$\n\\frac{\\partial C}{\\partial y_i} = -\\sum_{j \\ne i} (p_{ij} + p_{ji}) \\frac{g'(r_{ij})}{g(r_{ij})} u_{ij} + \\frac{2}{Z} \\sum_{j \\ne i} g'(r_{ij}) u_{ij}\n$$\n重新整理求和项：\n$$\n\\frac{\\partial C}{\\partial y_i} = \\sum_{j \\ne i} \\left( \\frac{2 g'(r_{ij})}{Z} - (p_{ij} + p_{ji}) \\frac{g'(r_{ij})}{g(r_{ij})} \\right) u_{ij}\n$$\n因此，力 $F_i = -\\frac{\\partial C}{\\partial y_i}$ 为：\n$$\nF_i = \\sum_{j \\ne i} \\left( (p_{ij} + p_{ji}) \\frac{g'(r_{ij})}{g(r_{ij})} - \\frac{2 g'(r_{ij})}{Z} \\right) u_{ij}\n$$\n此表达式将作用于点 $y_i$ 的力分解为来自其他点 $y_j$ 的成对贡献之和。与 $(p_{ij}+p_{ji})$ 成正比的项代表吸引力，而涉及 $Z$ 的项代表排斥力。注意 $g(r)$ 通常是一个递减函数，因此 $g'(r)  0$。吸引项将 $y_i$ 拉向 $y_j$（与 $u_{ij}$ 方向相反），而排斥项将 $y_i$ 推离 $y_j$（沿着 $u_{ij}$ 方向）。\n\n### 步骤 2：远邻排斥力大小\n\n对于点对 $(i, j)$，在远邻域情况下，高维相似度可以忽略不计，即 $p_{ij} + p_{ji} \\approx 0$。在这种情况下，来自 $y_j$ 的力的吸引部分消失了。力简化为一个纯粹的排斥分量：\n$$\nF_{i \\leftarrow j}^{\\text{far}} \\approx \\left( - \\frac{2 g'(r_{ij})}{Z} \\right) u_{ij}\n$$\n径向排斥力大小是该力贡献的模：\n$$\nM(r) = \\left| - \\frac{2 g'(r)}{Z} \\right| = \\frac{2 |g'(r)|}{\\sum_{k \\ne \\ell} g(r_{k\\ell})}\n$$\n在分析排斥力的函数形式时，对于给定的嵌入配置，$Z$ 被视为一个常数因子。因此，排斥力剖面的形状由 $|g'(r)|$ 决定。\n\n### 步骤 3：特定核的分析\n\n我们现在分析指定的两个核。\n\n1.  **Student-t 核**：$g_{\\mathrm{t}}(r) = (1 + r^2)^{-1}$\n    其导数为 $g'_{\\mathrm{t}}(r) = -2r(1 + r^2)^{-2}$。\n    排斥力大小的函数形式为 $M_{\\mathrm{t}}(r) \\propto |g'_{\\mathrm{t}}(r)| = 2r(1 + r^2)^{-2}$。\n    当 $r \\to \\infty$ 时，其渐进行为是 $M_{\\mathrm{t}}(r) \\propto r(r^2)^{-2} = r \\cdot r^{-4} = r^{-3}$。这是一种代数（幂律）衰减。\n\n2.  **拉普拉斯核**：$g_{\\mathrm{L}}(r) = \\exp(-r)$\n    其导数为 $g'_{\\mathrm{L}}(r) = -\\exp(-r)$。\n    排斥力大小的函数形式为 $M_{\\mathrm{L}}(r) \\propto |g'_{\\mathrm{L}}(r)| = \\exp(-r)$。\n    当 $r \\to \\infty$ 时，这表现为指数衰减。\n\n**拥挤问题的评估**：\nSNE 中的拥挤问题源于没有足够的排斥力来分离开在高维空间中相距很远的点。t-SNE 通过使用 Student-t 核来缓解这个问题，其代数衰减（$r^{-3}$）提供了“重尾”特性，因此与原始 SNE 中使用的高斯核的指数衰减相比，它提供了更长程的排斥力。\n\n将拉普拉斯核与 Student-t 核进行比较，我们发现排斥力大小 $M_{\\mathrm{L}}(r) \\propto e^{-r}$ 呈指数衰减，这比 $M_{\\mathrm{t}}(r) \\propto r^{-3}$ 的代数衰减快得多。指数衰减构成了作用范围更短的力。因此，拉普拉斯核在远距离点之间提供的排斥力将比 Student-t 核弱得多。这会加剧而不是缓解拥挤问题。在这方面，Student-t 核因其具有重尾的排斥力而更优越。\n\n### 步骤 4：数值计算\n\n该问题要求基于这些核进行一系列数值计算。\n\n- **核及其导数**：\n  $|g'_{\\mathrm{t}}(r)| = 2r(1 + r^2)^{-2}$\n  $|g'_{\\mathrm{L}}(r)| = \\exp(-r)$\n\n- **力剖面比**：$R(r) = |g'_{\\mathrm{L}}(r)| / |g'_{\\mathrm{t}}(r)| = \\frac{\\exp(-r)}{2r(1+r^2)^{-2}} = \\frac{\\exp(-r)(1+r^2)^2}{2r}$。\n\n- **积分差**：$\\Delta = \\int_{10}^{20} \\exp(-r) \\, dr - \\int_{10}^{20} 2r(1+r^2)^{-2} \\, dr$。这些积分可以进行数值计算或解析计算。\n  $\\int \\exp(-r) dr = -\\exp(-r)$\n  $\\int 2r(1+r^2)^{-2} dr = -(1+r^2)^{-1}$ （使用换元法 $u=1+r^2$）\n  $\\Delta = [-\\exp(-r)]_{10}^{20} - [-(1+r^2)^{-1}]_{10}^{20} = (e^{-10} - e^{-20}) - (\\frac{1}{101} - \\frac{1}{401})$。\n\n- **阈值为 $\\tau = 10^{-3}$ 时的半径**：\n  $r^\\ast_{\\mathrm{L}}$：求解 $|g'_{\\mathrm{L}}(r)| = e^{-r} = 10^{-3} \\implies r = -\\ln(10^{-3}) = 3\\ln(10)$。\n  $r^\\ast_{\\mathrm{t}}$：求解 $|g'_{\\mathrm{t}}(r)| = \\frac{2r}{(1+r^2)^2} = 10^{-3}$。这需要使用数值求根方法。\n\n这些计算在下面的 Python 代码中实现。", "answer": "```python\nimport numpy as np\nfrom scipy.integrate import quad\nfrom scipy.optimize import root_scalar\n\ndef solve():\n    \"\"\"\n    Performs the calculations specified in the problem statement.\n    \"\"\"\n\n    # Define the absolute values of the kernel derivatives\n    def abs_g_prime_t(r):\n        \"\"\"Absolute derivative of the Student-t kernel.\"\"\"\n        return 2 * r / ((1 + r**2)**2)\n\n    def abs_g_prime_l(r):\n        \"\"\"Absolute derivative of the Laplace kernel.\"\"\"\n        return np.exp(-r)\n\n    # Task 1: Compute the force-profile ratio R(r) for specific r values\n    def force_profile_ratio(r):\n        \"\"\"Computes R(r) = |g'_L(r)| / |g'_t(r)|.\"\"\"\n        if r == 0:\n            return np.inf  # The formula has 1/r dependency\n        return abs_g_prime_l(r) / abs_g_prime_t(r)\n\n    r_values = [1e-8, 1, 5, 50]\n    r_results = [force_profile_ratio(r) for r in r_values]\n\n    # Task 2: Check if R(50)  1e-6\n    r50_check = bool(r_results[-1]  1e-6)\n\n    # Task 3: Compute the integral difference Delta\n    integral_l, _ = quad(abs_g_prime_l, 10, 20)\n    integral_t, _ = quad(abs_g_prime_t, 10, 20)\n    delta = integral_l - integral_t\n\n    # Task 4: Check if Delta  0\n    delta_check = bool(delta  0)\n\n    # Task 5: Compute the radii ratio r_star_L / r_star_t\n    tau = 1e-3\n\n    # For Laplace kernel: exp(-r) = tau => r = -log(tau)\n    r_star_l = -np.log(tau)\n\n    # For Student-t kernel: 2r / (1+r^2)^2 = tau. Find root of f(r) = 0.\n    def f_t(r):\n        return abs_g_prime_t(r) - tau\n    \n    # Bracket the root. f(10) > 0, f(15)  0 based on preliminary analysis.\n    sol_t = root_scalar(f_t, bracket=[1, 20], method='brentq')\n    r_star_t = sol_t.root\n\n    radii_ratio = r_star_l / r_star_t\n\n    # Task 6: Check if r_star_L  r_star_t\n    radii_ratio_check = bool(r_star_l  r_star_t)\n    \n    # Consolidate all results\n    all_results = r_results + [r50_check, delta, delta_check, radii_ratio, radii_ratio_check]\n    \n    # Format and print the final output\n    # Using a mix of float formatting for readability where appropriate\n    formatted_results = []\n    for item in all_results:\n        if isinstance(item, bool):\n            formatted_results.append(str(item).lower())\n        else:\n            # Use general format for large/small numbers, and float for others\n            if abs(item) > 1e6 or (abs(item)  1e-4 and item != 0):\n                 formatted_results.append(f\"{item:.10e}\")\n            else:\n                 formatted_results.append(f\"{item:.10f}\")\n\n\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n\n```", "id": "3179628"}, {"introduction": "理解了 t-SNE 中吸引力与排斥力的基本原理后，我们可以更进一步，学习如何操控这些“作用力”来应对实际数据挑战。这个练习聚焦于一个常见问题：不平衡数据集，其中稀有类别在可视化中容易被忽略或淹没。通过为带样本权重的 t-SNE 目标函数推导梯度，你将学会如何通过调整权重来增强稀有类别内部的吸引力，从而在视觉上凸显它们 [@problem_id:3179611]。", "problem": "考虑一个包含 $N$ 个点 $\\{x_i\\}_{i=1}^N$ 的数据集，这些点具有类别标签 $c(i)$ 和正样本权重 $\\{w_i\\}_{i=1}^N$。在 t-分布随机邻居嵌入 (t-SNE) 中，您构建了条件性高维相似度\n$$\np_{j|i} \\equiv \\frac{\\exp\\!\\left(-\\|x_i - x_j\\|^2/(2\\sigma_i^2)\\right)}{\\sum_{k \\neq i} \\exp\\!\\left(-\\|x_i - x_k\\|^2/(2\\sigma_i^2)\\right)} \\quad \\text{for } i \\neq j,\n$$\n然后通过以下方式形成关于点对 $(i,j)$（$i \\neq j$）的加权对称联合分布\n$$\nP_{ij} \\equiv \\frac{w_i\\,p_{j|i} + w_j\\,p_{i|j}}{2\\,W}, \\quad \\text{where } W \\equiv \\sum_{a=1}^N w_a.\n$$\n在嵌入空间中，坐标为 $\\{y_i\\}_{i=1}^N \\subset \\mathbb{R}^d$，定义低维学生 t-分布（自由度为 1）相似度\n$$\nq_{ij} \\equiv \\frac{1}{1 + \\|y_i - y_j\\|^2} \\quad \\text{for } i \\neq j,\n$$\n及其归一化形式\n$$\nQ_{ij} \\equiv \\frac{q_{ij}}{\\sum_{a \\neq b} q_{ab}} \\quad \\text{for } i \\neq j.\n$$\n成本是 $P$ 和 $Q$ 之间的 Kullback–Leibler (KL) 散度，\n$$\nC \\equiv \\sum_{i \\neq j} P_{ij}\\,\\ln\\!\\left(\\frac{P_{ij}}{Q_{ij}}\\right).\n$$\n请从第一性原理出发，根据 $\\{y_j\\}$、$\\{w_j\\}$ 和 $\\{p_{j|i}\\}$ 推导梯度 $\\partial C/\\partial y_i$ 的显式封闭形式表达式。您的推导应仅从上述定义和多元微积分的标准法则开始。然后，简要说明选择 $w_i \\propto 1/f_{c(i)}$（其中 $f_c$ 是类别 $c$ 的类别频率）如何倾向于改变嵌入中稀有类别与常见类别之间吸引力与排斥力的相对强度。您的最终答案必须是 $\\partial C/\\partial y_i$ 的单个解析表达式。不要提供不等式或需要求解的方程；请提供表达式本身。无需四舍五入。", "solution": "该问题陈述是多元微积分和统计学习理论中的一个有效练习。它为 t-分布随机邻居嵌入 (t-SNE) 的加权变体提出了一个明确定义的成本函数，并要求推导其梯度。所有术语都经过了数学定义，问题本身是自洽的、有科学依据且客观的。\n\n我们的任务是推导成本函数 $C$ 相对于低维嵌入坐标 $y_i$ 的梯度。成本函数是联合概率分布 $P$ 和 $Q$ 之间的 Kullback-Leibler (KL) 散度：\n$$\nC \\equiv \\sum_{k \\neq l} P_{kl}\\,\\ln\\!\\left(\\frac{P_{kl}}{Q_{kl}}\\right)\n$$\n我们可以将其分解为两部分：\n$$\nC = \\sum_{k \\neq l} P_{kl}\\,\\ln(P_{kl}) - \\sum_{k \\neq l} P_{kl}\\,\\ln(Q_{kl})\n$$\n高维相似度 $p_{j|i}$ 以及随后的联合概率 $P_{ij}$ 仅取决于输入数据 $\\{x_i\\}$ 和权重 $\\{w_i\\}$，而不取决于嵌入坐标 $\\{y_i\\}$。因此，第一项 $\\sum_{k \\neq l} P_{kl}\\,\\ln(P_{kl})$ 相对于任何 $y_i$ 都是一个常数。其导数为零。我们只需要对第二项进行微分。\n\n让我们将成本函数的可变部分表示为 $C'$。\n$$\nC' = - \\sum_{k \\neq l} P_{kl}\\,\\ln(Q_{kl})\n$$\n相对于 $y_i$ 的梯度是：\n$$\n\\frac{\\partial C}{\\partial y_i} = \\frac{\\partial C'}{\\partial y_i} = -\\frac{\\partial}{\\partial y_i} \\left( \\sum_{k \\neq l} P_{kl}\\,\\ln(Q_{kl}) \\right)\n$$\n我们代入 $Q_{kl}$ 的定义：$Q_{kl} = q_{kl} / Z$，其中 $Z \\equiv \\sum_{a \\neq b} q_{ab}$。\n$$\nC' = - \\sum_{k \\neq l} P_{kl} \\left( \\ln(q_{kl}) - \\ln(Z) \\right) = - \\sum_{k \\neq l} P_{kl} \\ln(q_{kl}) + \\left(\\sum_{k \\neq l} P_{kl}\\right) \\ln(Z)\n$$\n所有 $P_{kl}$ 的总和等于 1。让我们来验证一下：\n$$\n\\sum_{k \\neq l} P_{kl} = \\sum_{k \\neq l} \\frac{w_k p_{l|k} + w_l p_{k|l}}{2W} = \\frac{1}{2W} \\left( \\sum_{k \\neq l} w_k p_{l|k} + \\sum_{k \\neq l} w_l p_{k|l} \\right)\n$$\n索引 $k$ 和 $l$ 是求和的哑变量，因此这两个和是相同的。\n$$\n\\sum_{k \\neq l} P_{kl} = \\frac{1}{W} \\sum_{k \\neq l} w_k p_{l|k} = \\frac{1}{W} \\sum_{k} w_k \\left( \\sum_{l \\neq k} p_{l|k} \\right)\n$$\n根据 $p_{l|k}$ 的定义，$\\sum_{l \\neq k} p_{l|k} = 1$。剩下：\n$$\n\\sum_{k \\neq l} P_{kl} = \\frac{1}{W} \\sum_{k} w_k = \\frac{W}{W} = 1\n$$\n因此，成本函数简化为：\n$$\nC = \\text{const} - \\sum_{k \\neq l} P_{kl} \\ln(q_{kl}) + \\ln(Z)\n$$\n现在我们可以通过对这两个可变项进行微分来计算梯度 $\\partial C / \\partial y_i$。\n\n第一项（吸引力）：\n$$\n\\frac{\\partial}{\\partial y_i} \\left( - \\sum_{k \\neq l} P_{kl} \\ln(q_{kl}) \\right) = - \\sum_{k \\neq l} P_{kl} \\frac{1}{q_{kl}} \\frac{\\partial q_{kl}}{\\partial y_i}\n$$\n导数 $\\partial q_{kl} / \\partial y_i$ 仅在 $k=i$ 或 $l=i$ 时非零。因此，总和简化为：\n$$\n- \\left( \\sum_{j \\neq i} P_{ij} \\frac{1}{q_{ij}} \\frac{\\partial q_{ij}}{\\partial y_i} + \\sum_{j \\neq i} P_{ji} \\frac{1}{q_{ji}} \\frac{\\partial q_{ji}}{\\partial y_i} \\right)\n$$\n由于 $P_{ij}=P_{ji}$ 和 $q_{ij}=q_{ji}$（因此 $\\partial q_{ij} / \\partial y_i = \\partial q_{ji} / \\partial y_i$），表达式变为：\n$$\n-2 \\sum_{j \\neq i} P_{ij} \\frac{1}{q_{ij}} \\frac{\\partial q_{ij}}{\\partial y_i}\n$$\n我们计算 $q_{ij} = (1 + \\|y_i - y_j\\|^2)^{-1}$ 的导数：\n$$\n\\frac{\\partial q_{ij}}{\\partial y_i} = - (1 + \\|y_i - y_j\\|^2)^{-2} \\cdot \\frac{\\partial}{\\partial y_i}(\\|y_i - y_j\\|^2) = -q_{ij}^2 \\cdot (2(y_i - y_j))\n$$\n将其代回，梯度的第一项变为：\n$$\n-2 \\sum_{j \\neq i} P_{ij} \\frac{1}{q_{ij}} (-2q_{ij}^2 (y_i - y_j)) = 4 \\sum_{j \\neq i} P_{ij} q_{ij} (y_i - y_j)\n$$\n第二项（排斥力）：\n$$\n\\frac{\\partial}{\\partial y_i} \\ln(Z) = \\frac{1}{Z} \\frac{\\partial Z}{\\partial y_i} = \\frac{1}{Z} \\frac{\\partial}{\\partial y_i} \\left( \\sum_{a \\neq b} q_{ab} \\right)\n$$\n同样，导数仅对包含 $y_i$ 的项非零：\n$$\n\\frac{\\partial Z}{\\partial y_i} = \\sum_{j \\neq i} \\frac{\\partial q_{ij}}{\\partial y_i} + \\sum_{j \\neq i} \\frac{\\partial q_{ji}}{\\partial y_i} = 2 \\sum_{j \\neq i} \\frac{\\partial q_{ij}}{\\partial y_i} = 2 \\sum_{j \\neq i} (-2q_{ij}^2 (y_i - y_j)) = -4 \\sum_{j \\neq i} q_{ij}^2 (y_i - y_j)\n$$\n所以梯度的第二项是：\n$$\n\\frac{1}{Z} \\left( -4 \\sum_{j \\neq i} q_{ij}^2 (y_i - y_j) \\right) = -4 \\sum_{j \\neq i} \\frac{q_{ij}}{Z} q_{ij} (y_i - y_j) = -4 \\sum_{j \\neq i} Q_{ij} q_{ij} (y_i - y_j)\n$$\n结合这两项，我们得到梯度：\n$$\n\\frac{\\partial C}{\\partial y_i} = 4 \\sum_{j \\neq i} P_{ij} q_{ij} (y_i - y_j) - 4 \\sum_{j \\neq i} Q_{ij} q_{ij} (y_i - y_j)\n$$\n这可以更紧凑地写成：\n$$\n\\frac{\\partial C}{\\partial y_i} = 4 \\sum_{j \\neq i} (P_{ij} - Q_{ij}) q_{ij} (y_i - y_j)\n$$\n为了得到最终的显式形式，我们代入 $P_{ij}$、$Q_{ij}$、$q_{ij}$ 和 $W$ 的定义：\n$$\n\\frac{\\partial C}{\\partial y_i} = 4 \\sum_{j \\neq i} \\left( \\frac{w_i p_{j|i} + w_j p_{i|j}}{2 \\sum_{k=1}^N w_k} - \\frac{(1 + \\|y_i - y_j\\|^2)^{-1}}{\\sum_{a \\neq b} (1 + \\|y_a - y_b\\|^2)^{-1}} \\right) \\frac{y_i - y_j}{1 + \\|y_i - y_j\\|^2}\n$$\n这就是所要求的梯度的封闭形式表达式。\n\n现在，我们分析加权方案 $w_i \\propto 1/f_{c(i)}$ 的效果，其中 $f_c$ 是类别 $c$ 的频率。点 $y_i$ 的梯度向量是所有其他点 $y_j$ 施加的力的总和。项 $4 P_{ij} q_{ij} (y_i - y_j)$ 表示一个将 $y_i$ 拉向 $y_j$ 的吸引力，其大小与 $P_{ij}$ 成正比。项 $-4 Q_{ij} q_{ij} (y_i - y_j)$ 表示一个将 $y_i$ 从 $y_j$ 推开的排斥力。\n\n吸引力的大小取决于 $P_{ij} = \\frac{w_i p_{j|i} + w_j p_{i|j}}{2W}$。在所提出的加权方案下，来自稀有类别的点会获得较大的权重 $w_i$，而来自常见类别的点会获得较小的权重。\n考虑来自同一个稀有类别的两个点 $i$ 和 $j$。$w_i$ 和 $w_j$ 都会很大。与非加权版本（其中所有 $w_i=1$）相比，这会增加 $P_{ij}$ 的值。因此，这两点之间的吸引力得到加强。\n相反，如果点 $i$ 和 $j$ 属于同一个常见类别，则 $w_i$ 和 $w_j$ 都很小，这会减小 $P_{ij}$ 并削弱它们之间的相互吸引力。\n\n排斥力取决于 $Q_{ij}$，它仅仅是低维坐标 $\\{y_k\\}$ 的函数，并且独立于权重 $\\{w_k\\}$。因此，加权方案不直接改变排斥力。\n\n通过加强稀有类别成员之间的吸引力并削弱常见类别成员之间的吸引力，同时保持排斥力不变，这种加权方案改变了力的平衡。对于稀有类别中的一个点 $i$，来自其邻居（很可能也属于该稀有类别）的吸引力相对于全局排斥力变得更强。这鼓励稀有类别的点在嵌入中形成更紧密、更清晰的簇。对于常见类别中的一个点，吸引力被削弱，使得排斥力具有更大的相对效应，这可能导致常见类别的簇更分散，防止其塌缩成一个单一的密集点并主导嵌入空间。", "answer": "$$\n\\boxed{4 \\sum_{j \\neq i} \\left( \\frac{w_i p_{j|i} + w_j p_{i|j}}{2 \\sum_{k=1}^N w_k} - \\frac{\\frac{1}{1 + \\|y_i - y_j\\|^2}}{\\sum_{a \\neq b} \\frac{1}{1 + \\|y_a - y_b\\|^2}} \\right) \\frac{y_i - y_j}{1 + \\|y_i - y_j\\|^2}}\n$$", "id": "3179611"}, {"introduction": "创建了可视化嵌入之后，我们如何判断其优劣？一幅漂亮的图像未必是一幅忠实于原始数据的图像。这个练习将重点从生成嵌入转移到评估其质量，介绍一个定量的评估指标：“可信度”（trustworthiness），它衡量了局部邻域结构的保存程度。通过亲手实现这一指标并应用于具体案例，你将获得一个强大的工具，用以批判性地分析 t-SNE 的输出结果，并诊断嵌入在哪些区域可能产生了误导 [@problem_id:3179626]。", "problem": "给定两个欧几里得空间：一个由 t-分布随机邻域嵌入 (t-SNE) 产生的高维数据空间和一个低维嵌入空间。对于一个由 $i \\in \\{0,1,\\dots,N-1\\}$ 索引的有限点集，令 $X = \\{x_i \\in \\mathbb{R}^D\\}$ 表示数据空间坐标，$Y = \\{y_i \\in \\mathbb{R}^d\\}$ 表示嵌入空间坐标。对于选定的邻域大小 $k \\in \\{1,2,\\dots,N-1\\}$，使用欧几里得范数，将点 $i$ 在数据空间中的 $k$-近邻集合定义为 $N_k^X(i)$，在嵌入空间中定义为 $N_k^Y(i)$。两点 $a,b \\in \\mathbb{R}^m$ 之间的欧几里得距离为 $\\|a-b\\|_2 = \\sqrt{\\sum_{j=1}^m (a_j-b_j)^2}$。点 $i$ 的 $k$-近邻集合是通过按距离 $\\|x_i - x_j\\|_2$（相应地，$\\|y_i - y_j\\|_2$）递增的顺序对所有索引 $j \\neq i$ 进行排序来获得的，若距离完全相等，则按索引 $j$ 较小者优先，然后取前 $k$ 个索引。对每个点 $i$，定义逐点邻域保持率\n$$\np_i(k) \\;=\\; \\frac{\\left|\\,N_k^X(i) \\,\\cap\\, N_k^Y(i)\\,\\right|}{k}.\n$$\n这个量 $p_i(k)$ 的值在 $[0,1]$ 范围内，可作为在给定 $k$ 值下单个点层级的可信度指标。\n\n你的任务是编写一个完整的程序，为每个指定的测试用例计算逐点邻域保持率向量 $[p_0(k),p_1(k),\\dots,p_{N-1}(k)]$，并识别出那些局部邻域未能在诊断容差范围内得到保持的点的索引。给定一个阈值 $\\tau \\in [0,1]$，将受损点集合定义为满足 $p_i(k)  \\tau$ 的那些索引 $i$。这可以用于诊断因 t-分布随机邻域嵌入 (t-SNE) 中的早期夸大或近似等机制而受损的区域，已知这些机制可能会破坏某些点的局部邻域，即使全局结构看起来是合理的。\n\n仅使用上述基本定义；不要依赖任何预打包的邻域保持或可信度函数。按照规定实现欧几里得距离、按较小索引的确定性平局打破规则以及严格的集合交集。对于每个测试用例，输出两项：列表 $[p_0(k),\\dots,p_{N-1}(k)]$（每个值四舍五入到三位小数），以及排序后的受损索引列表 $\\{i : p_i(k)  \\tau\\}$。\n\n测试套件。使用以下四个测试用例。在每个案例中，$X$ 和 $Y$ 均已明确给出。\n\n- 测试用例 1（理想情况：$Y$ 中的单调缩放保留了邻域）：\n  - $N = 6$, $D = 1$, $d = 1$, $k = 2$, $\\tau = 1.0$。\n  - $X^{(1)} = \\begin{bmatrix} 0 \\\\ 1 \\\\ 3 \\\\ 7 \\\\ 12 \\\\ 18 \\end{bmatrix}$。\n  - $Y^{(1)} = \\begin{bmatrix} 0 \\\\ 2 \\\\ 6 \\\\ 14 \\\\ 24 \\\\ 36 \\end{bmatrix}$。\n- 测试用例 2（诊断因 $Y$ 中类似夸大的失真而导致的局部受损区域）：\n  - $N = 6$, $D = 1$, $d = 1$, $k = 2$, $\\tau = 0.75$。\n  - $X^{(2)} = \\begin{bmatrix} 0 \\\\ 1 \\\\ 3 \\\\ 7 \\\\ 12 \\\\ 18 \\end{bmatrix}$。\n  - $Y^{(2)} = \\begin{bmatrix} 0 \\\\ 2 \\\\ 20 \\\\ 14 \\\\ 24 \\\\ 36 \\end{bmatrix}$。\n- 测试用例 3（在 $k=1$ 时导致最近邻翻转的类似近似的扰动）：\n  - $N = 5$, $D = 2$, $d = 2$, $k = 1$, $\\tau = 1.0$。\n  - $X^{(3)} = \\begin{bmatrix} 0.0  0.0 \\\\ 0.9  0.05 \\\\ 1.8  0.2 \\\\ 3.0  5.0 \\\\ 3.1  5.05 \\end{bmatrix}$。\n  - $Y^{(3)} = \\begin{bmatrix} 0.0  0.0 \\\\ 0.9  0.05 \\\\ 0.3  0.02 \\\\ 3.0  5.0 \\\\ 3.1  5.05 \\end{bmatrix}$。\n- 测试用例 4（边界情况：$k = N-1$ 使得每个点的邻域集合为所有其他点）：\n  - $N = 4$, $D = 2$, $d = 2$, $k = 3$, $\\tau = 1.0$。\n  - $X^{(4)} = \\begin{bmatrix} 0  0 \\\\ 1  0 \\\\ 0  1 \\\\ 1  1 \\end{bmatrix}$。\n  - $Y^{(4)} = \\begin{bmatrix} 1  1 \\\\ 0  1 \\\\ 1  0 \\\\ 0  0 \\end{bmatrix}$。\n\n最终输出格式。你的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表形式的结果。列表中的每个元素对应一个测试用例，并且本身是一个双元素列表：第一个元素是按点索引顺序排列的列表 $[p_0(k),\\dots,p_{N-1}(k)]$（四舍五入到三位小数），第二个元素是满足 $p_i(k)  \\tau$ 的已排序的受损索引列表。例如，整体结构必须为\n$[[[p^{(1)}_0,\\dots,p^{(1)}_{N-1}],[\\text{harmed}^{(1)}]], [[p^{(2)}_0,\\dots],[\\text{harmed}^{(2)}]], [[p^{(3)}_0,\\dots],[\\text{harmed}^{(3)}]], [[p^{(4)}_0,\\dots],[\\text{harmed}^{(4)}]]]$。", "solution": "该问题要求计算一个 t-SNE-风格嵌入的逐点局部邻域保持度量。这个度量，记为 $p_i(k)$，量化了高维数据空间 $X$ 中一个点 $x_i$ 的 $k$-近邻中，有多少比例同时也是其在低维嵌入空间 $Y$ 中对应点 $y_i$ 的 $k$-近邻。目标是实现一个程序来计算这些保持率的向量 $[p_0(k), p_1(k), \\ldots, p_{N-1}(k)]$，并识别出保持率低于指定容差阈值 $\\tau$ 的“受损”点集合。\n\n该问题定义明确且具有科学依据。所有术语都经过了精确的数学定义。数据空间坐标由集合 $X = \\{x_i \\in \\mathbb{R}^D\\}_{i=0}^{N-1}$ 给出，嵌入空间坐标由 $Y = \\{y_i \\in \\mathbb{R}^d\\}_{i=0}^{N-1}$ 给出。距离度量是标准的欧几里得范数 $\\|a-b\\|_2 = \\sqrt{\\sum_{j=1}^m (a_j-b_j)^2}$。一个关键细节是确定性的平局打破规则：当两个点与一个参考点的距离相等时，索引较小的点被认为更近。这确保了对于任何点 $i$ 和任何邻域大小 $k \\in \\{1, 2, \\ldots, N-1\\}$，$k$-近邻集合 $N_k^X(i)$ 和 $N_k^Y(i)$ 都是唯一确定的。\n\n逐点邻域保持率定义为：\n$$\np_i(k) \\;=\\; \\frac{\\left|\\,N_k^X(i) \\,\\cap\\, N_k^Y(i)\\,\\right|}{k}\n$$\n该值范围从 0（没有邻居被保留）到 1（所有 $k$ 个邻居都被保留）。受损点集合则定义为所有满足 $p_i(k)  \\tau$ 的索引 $i$。\n\n计算每个测试用例所需输出的算法流程如下。对于从 0 到 $N-1$ 的每个点 $i$：\n\n1.  **构建邻域列表**：\n    -   对于数据空间 $X$，为所有 $j \\neq i$ 创建一个元组列表 $(d_{ij}^X, j)$，其中 $d_{ij}^X = \\|x_i - x_j\\|_2$。\n    -   对于嵌入空间 $Y$，为所有 $j \\neq i$ 创建一个元组列表 $(d_{ij}^Y, j)$，其中 $d_{ij}^Y = \\|y_i - y_j\\|_2$。\n\n2.  **排序并确定 k-NN 集合**：\n    -   根据距离 $d_{ij}^X$（升序）作为主键和索引 $j$（升序）作为次键对 $X$ 空间的列表进行排序，以强制执行平局打破规则。此排序列表中的前 $k$ 个索引构成了 $k$-近邻集合 $N_k^X(i)$。\n    -   对来自 $Y$ 空间的列表执行相同的排序过程，以确定集合 $N_k^Y(i)$。\n\n3.  **计算保持率**：\n    -   计算两个集合的交集：$I_i = N_k^X(i) \\cap N_k^Y(i)$。\n    -   计算保持率 $p_i(k) = |I_i| / k$。\n\n4.  **识别受损点**：\n    -   在计算完所有 $i \\in \\{0, \\ldots, N-1\\}$ 的 $p_i(k)$ 后，将每个 $p_i(k)$ 与阈值 $\\tau$ 进行比较。受损索引的集合为 $\\{i \\mid p_i(k)  \\tau\\}$。\n\n此算法将应用于提供的四个测试用例中的每一个。\n\n-   **测试用例 1** ($N=6, k=2, \\tau=1.0$)：嵌入 $Y^{(1)}$ 是数据 $X^{(1)}$ 的线性缩放，即 $y_i = 2x_i$。这种变换保留了所有点间距离的顺序。因此，对于每个点 $i$，两个空间中的 $k$-近邻是相同的：$N_k^X(i) = N_k^Y(i)$。这导致所有 $i$ 的保持率都为完美的 $p_i(k) = 1.0$。由于 $p_i(k)$ 不小于 $\\tau=1.0$，没有点受损。\n\n-   **测试用例 2** ($N=6, k=2, \\tau=0.75$)：坐标 $y_2=20$ 是对原始数据结构的一次显著扭曲，在原始数据中，$x_2=3$ 接近 $x_1=1$ 和 $x_0=0$。这种位移使得点 2 在嵌入空间 $Y$ 中远离点 0 和 1，从而破坏了它们的局部邻域。具体来说，对于点 $i=2$，它在 $X$ 中的邻居是 $\\{0,1\\}$，但在 $Y$ 中变成了 $\\{3,4\\}$，导致 $p_2(2)=0.0$。类似的破坏也影响了点 0 和 1 的邻域，导致 $p_0(2)=0.5$ 和 $p_1(2)=0.5$。其余的点 $3, 4, 5$ 远离该扰动并保留了它们的邻域，因此对于 $i \\in \\{3,4,5\\}$，$p_i(2)=1.0$。索引 $0, 1, 2$ 被视为受损，因为它们的 $p_i(k)$ 值低于 $\\tau=0.75$。\n\n-   **测试用例 3** ($N=5, k=1, \\tau=1.0$)：这个案例展示了一种局部扰乱。在空间 $X$ 中，索引为 $0, 1, 2$ 的点形成一个链，其中 1 是 0 和 2 的最近邻，而 0 是 1 的最近邻。在空间 $Y$ 中，点 $y_2$ 被移动到非常靠近 $y_0$ 的位置。这打破了原有的邻域结构。$y_0$ 的最近邻变成了 $y_2$（而不是 $y_1$），$y_1$ 的最近邻变成了 $y_2$（而不是 $y_0$），而 $y_2$ 的最近邻变成了 $y_0$（而不是 $y_1$）。在这三种情况下，唯一的最近邻都没有被保留，因此 $p_0(1)=p_1(1)=p_2(1)=0.0$。点对 $(3,4)$ 远离这种扰乱，它们相互的最近邻关系得以保留，因此 $p_3(1)=p_4(1)=1.0$。受损索引为 $\\{0, 1, 2\\}$，因为它们的保持率低于 $\\tau=1.0$。\n\n-   **测试用例 4** ($N=4, k=3, \\tau=1.0$)：这是一个边界情况，其中 $k=N-1=3$。对于任何点 $i$，它的邻居集合自然是数据集中所有其他点的集合。也就是说，$N_3^X(i) = N_3^Y(i) = \\{0, 1, 2, 3\\} \\setminus \\{i\\}$。根据定义，交集是完美的。因此，对于所有 $i \\in \\{0,1,2,3\\}$，$p_i(3) = 3/3 = 1.0$。没有点受损。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef get_k_nearest_neighbors(points, i, k):\n    \"\"\"\n    Finds the k-nearest neighbors for point i in the given set of points.\n\n    Args:\n        points (np.ndarray): An NxD or Nxd array of points.\n        i (int): The index of the reference point.\n        k (int): The number of neighbors to find.\n\n    Returns:\n        set: A set of indices of the k nearest neighbors.\n    \"\"\"\n    N = points.shape[0]\n    distances = []\n    current_point = points[i]\n\n    for j in range(N):\n        if i == j:\n            continue\n        other_point = points[j]\n        # Euclidean distance calculation as per the problem definition\n        dist = np.linalg.norm(current_point - other_point)\n        # Store as a tuple of (distance, index) for sorting\n        distances.append((dist, j))\n\n    # Sort by distance (primary key) and then by index (secondary key for tie-breaking)\n    distances.sort(key=lambda x: (x[0], x[1]))\n\n    # Extract the indices of the first k neighbors\n    neighbors = {d[1] for d in distances[:k]}\n    return neighbors\n\ndef solve():\n    \"\"\"\n    Solves the neighbor preservation problem for the four given test cases.\n    \"\"\"\n    test_cases = [\n        {\n            \"N\": 6, \"k\": 2, \"tau\": 1.0,\n            \"X\": np.array([[0.0], [1.0], [3.0], [7.0], [12.0], [18.0]]),\n            \"Y\": np.array([[0.0], [2.0], [6.0], [14.0], [24.0], [36.0]])\n        },\n        {\n            \"N\": 6, \"k\": 2, \"tau\": 0.75,\n            \"X\": np.array([[0.0], [1.0], [3.0], [7.0], [12.0], [18.0]]),\n            \"Y\": np.array([[0.0], [2.0], [20.0], [14.0], [24.0], [36.0]])\n        },\n        {\n            \"N\": 5, \"k\": 1, \"tau\": 1.0,\n            \"X\": np.array([[0.0, 0.0], [0.9, 0.05], [1.8, 0.2], [3.0, 5.0], [3.1, 5.05]]),\n            \"Y\": np.array([[0.0, 0.0], [0.9, 0.05], [0.3, 0.02], [3.0, 5.0], [3.1, 5.05]])\n        },\n        {\n            \"N\": 4, \"k\": 3, \"tau\": 1.0,\n            \"X\": np.array([[0.0, 0.0], [1.0, 0.0], [0.0, 1.0], [1.0, 1.0]]),\n            \"Y\": np.array([[1.0, 1.0], [0.0, 1.0], [1.0, 0.0], [0.0, 0.0]])\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        N = case[\"N\"]\n        k = case[\"k\"]\n        tau = case[\"tau\"]\n        X = case[\"X\"]\n        Y = case[\"Y\"]\n\n        p_values = []\n        harmed_indices = []\n\n        for i in range(N):\n            # Find k-nearest neighbors in both spaces\n            neighbors_X = get_k_nearest_neighbors(X, i, k)\n            neighbors_Y = get_k_nearest_neighbors(Y, i, k)\n\n            # Calculate the size of the intersection\n            intersection_size = len(neighbors_X.intersection(neighbors_Y))\n            \n            # Calculate preservation fraction p_i(k)\n            if k > 0:\n                p_i_k = intersection_size / k\n            else:\n                p_i_k = 1.0 # By convention for k=0, though k >= 1 in this problem\n            \n            p_values.append(p_i_k)\n\n            # Check if the point is harmed\n            if p_i_k  tau:\n                harmed_indices.append(i)\n        \n        # Round p_values to three decimal places\n        rounded_p_values = [round(p, 3) for p in p_values]\n        \n        # Assemble the result for this test case\n        # harmed_indices is naturally sorted as the loop iterates from i=0 to N-1\n        case_result = [rounded_p_values, harmed_indices]\n        all_results.append(case_result)\n\n    # Format the final output string to match the exact requirement (no spaces)\n    # The default str() representation of lists is used, and then spaces are removed.\n    final_output_str = str(all_results).replace(\" \", \"\")\n    print(final_output_str)\n\nsolve()\n```", "id": "3179626"}]}