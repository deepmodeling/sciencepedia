{"hands_on_practices": [{"introduction": "第一个实践将探讨模型评估的一个基本方面：使用验证集进行超参数调优。我们将专注于为一个二元分类器选择最优的分类阈值以最大化 $F_\\beta$ 分数。通过这个练习 [@problem_id:3188635]，你将量化“阈值过拟合”这一概念，通过观察验证集和测试集之间的性能差距，从而加深对使用独立测试集进行无偏性能评估的重要性的理解。", "problem": "考虑一个二元分类模型，该模型在两个不相交的数据集上输出校准后的预测概率：一个验证集 $X_{\\text{val}}$ 和一个测试集 $X_{\\text{test}}$。设验证集由预测概率 $p^{(\\text{val})}_i \\in [0,1]$ 和二元标签 $y^{(\\text{val})}_i \\in \\{0,1\\}$（$i = 1,\\dots,n_{\\text{val}}$）组成，测试集类似，由 $p^{(\\text{test})}_j \\in [0,1]$ 和 $y^{(\\text{test})}_j \\in \\{0,1\\}$（$j = 1,\\dots,n_{\\text{test}}$）组成。一个阈值 $t \\in [0,1]$ 会产生预测标签，当且仅当 $p_i \\ge t$ 时，$\\hat{y}_i(t) = 1$，否则 $\\hat{y}_i(t) = 0$。\n\n从统计学习的核心定义开始：\n- 精确率 (Precision) $P$ 定义为 $P = \\frac{TP}{TP + FP}$，并约定当 $TP + FP = 0$ 时 $P = 0$。其中，$TP$ 表示真正例 (True Positives)，即 $(\\hat{y}=1, y=1)$ 的实例数量；$FP$ 表示假正例 (False Positives)，即 $(\\hat{y}=1, y=0)$ 的实例数量。\n- 召回率 (Recall) $R$ 定义为 $R = \\frac{TP}{TP + FN}$，并约定当 $TP + FN = 0$ 时 $R = 0$。其中，$FN$ 表示假反例 (False Negatives)，即 $(\\hat{y}=0, y=1)$ 的实例数量。\n- 对于 $\\beta > 0$，$F_\\beta$ 分数定义为精确率 $P$ 和召回率 $R$ 的加权调和平均数，即 $F_\\beta = \\frac{(1+\\beta^2) \\cdot P \\cdot R}{\\beta^2 \\cdot P + R}$，并约定当分母为 $0$ 时 $F_\\beta = 0$。\n\n目标是量化在类别分布偏移和不同 $\\beta$ 值的情况下，因在 $X_{\\text{val}}$ 上调优而导致的阈值过拟合。对于给定的 $\\beta$，通过在有限候选集 $\\{0\\} \\cup S \\cup \\{1\\}$（其中 $S$ 是 $p^{(\\text{val})}_i$ 的唯一值集合）上进行穷举搜索，来选择在 $X_{\\text{val}}$ 上使 $F_\\beta$ 最大化的阈值 $t^\\ast$。如果在 $X_{\\text{val}}$ 上有多个阈值达到了相同的最大 $F_\\beta$ 值，则选择这些最大化阈值中最大的一个来打破平局。然后，使用 $t^\\ast$ 计算在 $X_{\\text{val}}$ 和 $X_{\\text{test}}$ 上的 $F_\\beta$ 值，并报告定义为如下的过拟合差距\n$$\n\\Delta = F_\\beta\\big(X_{\\text{val}}; t^\\ast\\big) - F_\\beta\\big(X_{\\text{test}}; t^\\ast\\big).\n$$\n\n您的程序必须实现上述过程，并为以下参数值的测试套件生成过拟合差距。所有数组都是有序列表；所有数字都是实值标量。\n\n测试用例 A（正常路径，中等 $\\beta$ 值，轻微偏移）：\n- 验证集预测概率：$[0.92, 0.81, 0.76, 0.63, 0.58, 0.49, 0.45, 0.41, 0.35, 0.22, 0.17, 0.08]$。\n- 验证集标签：$[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]$。\n- 测试集预测概率：$[0.90, 0.84, 0.79, 0.70, 0.34, 0.30, 0.27, 0.20, 0.15, 0.12]$。\n- 测试集标签：$[1, 1, 0, 1, 0, 0, 0, 0, 0, 0]$。\n- $\\beta = 1$。\n\n测试用例 B（侧重召回率，更强偏移）：\n- 验证集预测概率：$[0.88, 0.83, 0.77, 0.74, 0.62, 0.52, 0.47, 0.40, 0.33, 0.25]$。\n- 验证集标签：$[1, 1, 1, 0, 1, 0, 0, 0, 0, 0]$。\n- 测试集预测概率：$[0.86, 0.80, 0.55, 0.51, 0.49, 0.45, 0.38, 0.31, 0.28, 0.18]$。\n- 测试集标签：$[0, 1, 1, 0, 0, 0, 0, 0, 0, 0]$。\n- $\\beta = 2$。\n\n测试用例 C（平坦分数，平局处理）：\n- 验证集预测概率：$[0.50, 0.50, 0.50, 0.50]$。\n- 验证集标签：$[1, 0, 0, 1]$。\n- 测试集预测概率：$[0.50, 0.50, 0.50]$。\n- 测试集标签：$[0, 0, 1]$。\n- $\\beta = 1$。\n\n测试用例 D（侧重精确率，极端偏移导致在 $t^\\ast$ 下 $X_{\\text{test}}$ 上无正例预测）：\n- 验证集预测概率：$[0.95, 0.90, 0.85, 0.40, 0.35, 0.30]$。\n- 验证集标签：$[1, 1, 1, 0, 0, 0]$。\n- 测试集预测概率：$[0.60, 0.55, 0.50, 0.45, 0.20, 0.10]$。\n- 测试集标签：$[1, 0, 0, 0, 0, 0]$。\n- $\\beta = 0.5$。\n\n实现要求：\n- 在 $X_{\\text{val}}$ 上使用指定的候选阈值进行穷举搜索以选择 $t^\\ast$。\n- 在计算 $F_\\beta$ 时，使用等效的基于计数的表达式\n$$\nF_\\beta = \\frac{(1+\\beta^2)\\,TP}{(1+\\beta^2)\\,TP + \\beta^2\\,FN + FP},\n$$\n并约定如果分母为 $0$，则 $F_\\beta = 0$。\n- 对于每个测试用例，按上述规定计算 $\\Delta$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。列表中的每个 $\\Delta$ 都表示为保留 6 位小数的十进制数，并按 A、B、C、D 的顺序排列。例如，格式必须为 $\\texttt{[0.123456,0.234567,0.345678,0.456789]}$。", "solution": "该问题要求我们量化二元分类模型的阈值过拟合程度。这是通过计算验证集 $X_{\\text{val}}$ 和测试集 $X_{\\text{test}}$ 之间的性能差距 $\\Delta$ 来实现的。性能指标是 $F_\\beta$ 分数。问题的核心在于，首先在验证集上选择一个最优分类阈值 $t^\\ast$，然后衡量该阈值下的性能在未见过的测试集上的泛化能力如何。一个较大的正差距 $\\Delta = F_\\beta(X_{\\text{val}}; t^\\ast) - F_\\beta(X_{\\text{test}}; t^\\ast)$ 表明阈值 $t^\\ast$ 对验证数据的特定特征存在过拟合。\n\n该解决方案的实现遵循一个确定性的、分步的程序，处理所提供的每个测试用例。\n\n**第 1 步：确定候选阈值**\n\n对于一个预测概率为 $p$ 的样本，其分类结果仅在阈值 $t$ 跨越 $p$ 值时才会改变。因此，要找到使 $F_\\beta$ 分数最大化的阈值，只需评估一个有限的候选阈值集合。问题指定该集合为 $\\{0\\} \\cup S \\cup \\{1\\}$，其中 $S$ 是验证集中唯一预测概率 $p^{(\\text{val})}_i$ 的集合。我们构建这个候选集，记为 $T_{\\text{candidates}}$，并按升序对其进行排序。排序对于正确实现指定的平局打破规则至关重要。\n\n**第 2 步：在验证集上选择最优阈值**\n\n我们在排序后的候选集 $T_{\\text{candidates}}$ 上进行穷举搜索，以找到最优阈值 $t^\\ast$。对于每个候选阈值 $t \\in T_{\\text{candidates}}$，我们计算其在验证数据 $X_{\\text{val}}$ 上的 $F_\\beta$ 分数。\n\n实例 $i$ 的预测标签由 $\\hat{y}_i(t) = 1$（如果其概率分数 $p_i \\ge t$）和 $\\hat{y}_i(t) = 0$（否则）给出。基于这些预测和真实标签 $y_i$，我们统计真正例（$TP$）、假正例（$FP$）和假反例（$FN$）的数量。\n\n$F_\\beta$ 分数随后使用提供的基于计数的公式进行计算，该公式数值稳定，并避免了在计算精确率和召回率中间步骤时出现除以零的情况：\n$$\nF_\\beta = \\frac{(1+\\beta^2) \\cdot TP}{(1+\\beta^2) \\cdot TP + \\beta^2 \\cdot FN + FP}\n$$\n如果分母为零（仅当 $TP=FP=FN=0$ 时发生），则分数定义为 $F_\\beta = 0$。\n\n我们遍历排序后的候选阈值 $t \\in T_{\\text{candidates}}$，并跟踪迄今为止找到的最大 $F_\\beta$ 分数（称之为 $F_{\\beta, \\text{max}}$）以及达到该分数的阈值 $t^\\ast$。更新规则如下：如果当前阈值 $t$ 产生的 $F_\\beta$ 分数大于或等于 $F_{\\beta, \\text{max}}$，我们就将 $F_{\\beta, \\text{max}}$ 更新为这个新分数，并将 $t^\\ast$ 设置为 $t$。因为我们是按升序遍历阈值的，所以此规则确保了如果多个阈值产生相同的最大分数，将选择其中最大的阈值作为 $t^\\ast$，从而满足问题的平局打破要求。\n\n**第 3 步：计算过拟合差距**\n\n一旦从验证集中确定了最优阈值 $t^\\ast$，我们就可以计算过拟合差距 $\\Delta$。\n\n首先，验证集上的 $F_\\beta$ 分数就是前一步中找到的最大分数：$F_\\beta(X_{\\text{val}}; t^\\ast) = F_{\\beta, \\text{max}}$。\n其次，我们通过将相同的阈值 $t^\\ast$ 应用于测试概率 $p^{(\\text{test})}_j$ 以生成预测，然后使用相同的 $F_\\beta$ 公式以及测试集的 $TP$、$FP$ 和 $FN$ 计数，来计算测试集上的 $F_\\beta$ 分数，即 $F_\\beta(X_{\\text{test}}; t^\\ast)$。\n\n过拟合差距是这两个分数之差：\n$$\n\\Delta = F_\\beta(X_{\\text{val}}; t^\\ast) - F_\\beta(X_{\\text{test}}; t^\\ast)\n$$\n\n该过程被封装在一个程序中，该程序处理四个指定的测试用例，计算相应的 $\\Delta$，并将结果格式化为单个逗号分隔的列表。该实现使用 `numpy` 库来高效地进行计数（$TP, FP, FN$）的向量化计算和数组操作。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_overfitting_gap(p_val, y_val, p_test, y_test, beta):\n    \"\"\"\n    Computes the F-beta overfitting gap for a given set of parameters.\n\n    1. Finds the optimal threshold t* on the validation set.\n    2. Calculates F_beta(X_val; t*) and F_beta(X_test; t*).\n    3. Returns the difference Delta.\n    \"\"\"\n    # Ensure inputs are numpy arrays for vectorized operations\n    p_val, y_val = np.array(p_val), np.array(y_val)\n    p_test, y_test = np.array(p_test), np.array(y_test)\n\n    # Step 1: Identify candidate thresholds\n    # The set is {0} U S U {1}, where S is the set of unique validation probabilities.\n    candidate_thresholds = sorted(list(set(p_val) | {0., 1.}))\n\n    # Step 2: Find the optimal threshold t* on the validation set\n    max_f_beta = -1.0\n    t_star = -1.0\n\n    beta_sq = beta**2\n    one_plus_beta_sq = 1 + beta_sq\n    \n    total_pos_val = np.sum(y_val)\n\n    for t in candidate_thresholds:\n        y_hat_val = (p_val >= t).astype(int)\n\n        tp = np.sum((y_hat_val == 1)  (y_val == 1))\n        fp = np.sum((y_hat_val == 1)  (y_val == 0))\n        # fn = np.sum((y_hat_val == 0)  (y_val == 1))\n        fn = total_pos_val - tp\n\n        numerator = one_plus_beta_sq * tp\n        denominator = (one_plus_beta_sq * tp) + (beta_sq * fn) + fp\n\n        f_beta = numerator / denominator if denominator > 0 else 0.0\n\n        # Tie-breaking rule: select the largest threshold.\n        # Since we iterate through sorted thresholds, this condition correctly captures it.\n        if f_beta >= max_f_beta:\n            max_f_beta = f_beta\n            t_star = t\n            \n    f_beta_val = max_f_beta\n\n    # Step 3: Calculate F_beta on the test set using t* and find the gap\n    total_pos_test = np.sum(y_test)\n    y_hat_test = (p_test >= t_star).astype(int)\n\n    tp_test = np.sum((y_hat_test == 1)  (y_test == 1))\n    fp_test = np.sum((y_hat_test == 1)  (y_test == 0))\n    # fn_test = np.sum((y_hat_test == 0)  (y_test == 1))\n    fn_test = total_pos_test - tp_test\n\n    numerator_test = one_plus_beta_sq * tp_test\n    denominator_test = (one_plus_beta_sq * tp_test) + (beta_sq * fn_test) + fp_test\n\n    f_beta_test = numerator_test / denominator_test if denominator_test > 0 else 0.0\n\n    gap = f_beta_val - f_beta_test\n    return gap\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = [\n        # Test case A\n        {\n            \"p_val\": [0.92, 0.81, 0.76, 0.63, 0.58, 0.49, 0.45, 0.41, 0.35, 0.22, 0.17, 0.08],\n            \"y_val\": [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n            \"p_test\": [0.90, 0.84, 0.79, 0.70, 0.34, 0.30, 0.27, 0.20, 0.15, 0.12],\n            \"y_test\": [1, 1, 0, 1, 0, 0, 0, 0, 0, 0],\n            \"beta\": 1.0\n        },\n        # Test case B\n        {\n            \"p_val\": [0.88, 0.83, 0.77, 0.74, 0.62, 0.52, 0.47, 0.40, 0.33, 0.25],\n            \"y_val\": [1, 1, 1, 0, 1, 0, 0, 0, 0, 0],\n            \"p_test\": [0.86, 0.80, 0.55, 0.51, 0.49, 0.45, 0.38, 0.31, 0.28, 0.18],\n            \"y_test\": [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n            \"beta\": 2.0\n        },\n        # Test case C\n        {\n            \"p_val\": [0.50, 0.50, 0.50, 0.50],\n            \"y_val\": [1, 0, 0, 1],\n            \"p_test\": [0.50, 0.50, 0.50],\n            \"y_test\": [0, 0, 1],\n            \"beta\": 1.0\n        },\n        # Test case D\n        {\n            \"p_val\": [0.95, 0.90, 0.85, 0.40, 0.35, 0.30],\n            \"y_val\": [1, 1, 1, 0, 0, 0],\n            \"p_test\": [0.60, 0.55, 0.50, 0.45, 0.20, 0.10],\n            \"y_test\": [1, 0, 0, 0, 0, 0],\n            \"beta\": 0.5\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        gap = compute_overfitting_gap(\n            case[\"p_val\"], case[\"y_val\"],\n            case[\"p_test\"], case[\"y_test\"],\n            case[\"beta\"]\n        )\n        results.append(gap)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join([f'{r:.6f}' for r in results])}]\")\n\nsolve()\n```", "id": "3188635"}, {"introduction": "现实世界的数据很少是完美的。这个实践 [@problem_id:3188658] 模拟了一个关键场景，即验证集中包含结构化的标签错误，这是一种隐蔽但破坏性极强的数据损坏形式。通过将在受损数据上选择的超参数与“先知”选择进行比较，你将研究这类缺陷如何误导模型选择，并学习一个干净的测试集如何帮助揭示这些问题。", "problem": "考虑在统计学习中遵循经验风险最小化（ERM）原则的二元分类问题。设 $D_{\\text{train}}$、$D_{\\text{val}}$ 和 $D_{\\text{test}}$ 是从同一数据生成过程抽取的独立同分布样本。对于一个假设 $h$ 和一个数据集 $D = \\{(x_i, y_i)\\}_{i=1}^n$，定义经验误分类风险为\n$$\nR(h; D) = \\frac{1}{n} \\sum_{i=1}^n \\mathbf{1}\\{h(x_i) \\neq y_i\\}.\n$$\n超参数选择遵循 ERM 原则，通过选择使 $R(h; D_{\\text{val}})$ 最小化的超参数，其中 $D_{\\text{val}}$ 仅用于模型选择。选择后，在 $D_{\\text{test}}$ 上评估性能。\n\n您将实现 $k$-近邻分类器，其中 $k$ 为奇数以避免平局的模糊性。对于一个查询点 $x$，$h_k(x)$ 预测其在 $D_{\\text{train}}$ 中按平方欧几里得距离计算的 $k$ 个最近邻居中的多数标签。当 $k$ 为奇数时不会出现平局；如果使用偶数 $k$，则需要一个确定性的平局打破规则（预测为 0），但本问题限制 $k$ 为奇数。\n\n数据生成过程如下。特征位于 $\\mathbb{R}^2$ 中。从一个具有单位协方差矩阵的标准正态分布中抽取 $x \\in \\mathbb{R}^2$。令潜得分数为 $s(x) = w^\\top x + b$，其中 $w \\in \\mathbb{R}^2$ 且 $b \\in \\mathbb{R}$。通过一个带噪声的线性分隔器生成标签：为每个样本独立抽取 $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$，并设置 $y = \\mathbf{1}\\{s(x) + \\epsilon  0\\}$。使用 $w = [1.0, -0.8]$，$b = 0.1$ 和 $\\sigma = 0.3$。使用 $n_{\\text{train}} = 200$，$n_{\\text{val}} = 150$，$n_{\\text{test}} = 400$ 和 $d = 2$。\n\n结构化损坏仅应用于 $D_{\\text{val}}$。通过参数 $(\\tau, \\omega)$ 定义一个损坏区域，并对特征满足 $(x_1  \\tau)$ 和 $(|x_2| \\le \\omega)$ 的验证样本确定性地翻转其标签。也就是说，对于这些样本，将 $y$ 替换为 $1 - y$。所有其他标签保持不变。这种损坏是结构化的，而非随机的。$D_{\\text{train}}$ 或 $D_{\\text{test}}$ 不应用任何损坏。\n\n超参数选择：给定一个网格 $\\mathcal{K} = \\{1, 3, 5, 11, 21, 41\\}$，对每个 $k \\in \\mathcal{K}$ 计算 $R(h_k; D_{\\text{val}}^{\\text{corrupt}})$，其中 $D_{\\text{val}}^{\\text{corrupt}}$ 表示带有结构化损坏的验证集。选择\n$$\nk^\\star = \\arg\\min_{k \\in \\mathcal{K}} R(h_k; D_{\\text{val}}^{\\text{corrupt}}),\n$$\n通过选择最小的 $k$ 来打破平局。同时计算神谕选择\n$$\nk^\\dagger = \\arg\\min_{k \\in \\mathcal{K}} R(h_k; D_{\\text{val}}^{\\text{clean}}),\n$$\n其中 $D_{\\text{val}}^{\\text{clean}}$ 具有未损坏的标签。在 $D_{\\text{test}}$ 上评估两个选定的模型，以获得它们的测试准确率。定义一个检测阈值 $\\delta = 0.02$。如果 $k^\\star \\neq k^\\dagger$ 或者使用损坏的验证标签选择的模型与神谕选择的模型之间的测试准确率绝对差值超过 $\\delta$，则声明 $D_{\\text{test}}$ 揭示了错选。\n\n此问题中没有物理单位。所有比率和阈值必须表示为小数或分数。如果存在角度，则不使用。您必须实现上述完整过程，并为以下由 $(\\tau, \\omega)$ 指定的结构化损坏测试套件生成结果：\n- 测试用例 1：$(\\tau, \\omega) = (100.0, 1.0)$，\n- 测试用例 2：$(\\tau, \\omega) = (0.2, 0.5)$，\n- 测试用例 3：$(\\tau, \\omega) = (-0.5, 10.0)$，\n- 测试用例 4：$(\\tau, \\omega) = (0.0, 0.15)$。\n\n对于每个测试用例，您的程序必须按以下顺序输出一个包含五个项目的列表：\n$[k^\\star, k^\\dagger, \\text{test\\_acc}(k^\\star), \\text{test\\_acc}(k^\\dagger), \\text{misselection\\_revealed}]$,\n其中 $k^\\star$ 和 $k^\\dagger$ 是整数，准确率是浮点数，错选指示符是布尔值。\n\n最终输出格式：您的程序应生成单行输出，其中包含所有测试用例的结果，形式为逗号分隔的列表，并用方括号括起来，其中每个元素是上面定义的单个测试用例的列表。例如，输出应类似于 $[[\\cdots],[\\cdots],[\\cdots],[\\cdots]]$，不含任何额外文本。", "solution": "设计始于经验风险最小化（ERM）原则。对于二元分类，在数据集 $D = \\{(x_i, y_i)\\}_{i=1}^n$ 上的经验误分类风险为\n$$\nR(h; D) = \\frac{1}{n} \\sum_{i=1}^n \\mathbf{1}\\{h(x_i) \\neq y_i\\}.\n$$\n超参数选择旨在寻找一个由超参数 $\\lambda$ 参数化的假设 $h_{\\lambda}$，以最小化 $R(h_{\\lambda}; D_{\\text{val}})$。这依赖于一个基本假设，即 $D_{\\text{val}}$ 是来自数据生成分布的一个代表性样本。当 $D_{\\text{val}}$ 中的标签被损坏时，$R(h_{\\lambda}; D_{\\text{val}})$ 可能会有偏差，所选的 $\\lambda$ 可能无法最小化真实的泛化风险。测试集 $D_{\\text{test}}$ 被保留下来用于评估性能；其干净的标签使得当性能与基于干净验证标签的神谕选择显著偏离时，能够检测到错选。\n\n我们将分类器实例化为 $k$-近邻（KNN）。对于每个查询点 $x$，KNN 使用按平方欧几里得距离计算的 $k$ 个最近的训练样本集。预测 $h_k(x)$ 是这些邻居中的多数标签。当 $k$ 为奇数时，不会出现平局，因为多数计数严格大于 $k/2$。该方法是非参数的，并直接依赖于 $D_{\\text{train}}$，而 $D_{\\text{train}}$ 保持未损坏。\n\n数据生成使用了一个经过充分测试的带加性高斯噪声的线性分隔器模型。我们从标准正态分布中独立抽取特征 $x \\in \\mathbb{R}^2$。潜得分数为 $s(x) = w^\\top x + b$，其中 $w = [1.0, -0.8]$ 和 $b = 0.1$ 是固定的。标签遵循 $y = \\mathbf{1}\\{s(x) + \\epsilon  0\\}$，其中 $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$ 且 $\\sigma = 0.3$。这会导致类别重叠，确保超参数的选择能有意义地影响准确率。我们使用的样本大小为 $n_{\\text{train}} = 200$，$n_{\\text{val}} = 150$ 和 $n_{\\text{test}} = 400$。\n\n结构化验证损坏在一个几何区域内确定性地翻转标签：对于 $x = (x_1, x_2)$，如果 $(x_1  \\tau)$ 且 $(|x_2| \\le \\omega)$，则标签被替换为 $1 - y$。这在 $D_{\\text{val}}$ 中造成了系统性偏差，该偏差取决于在特征空间中的位置。损坏参数 $(\\tau, \\omega)$ 定义了损坏的结构和严重程度。\n\n算法步骤：\n1. 根据指定的过程生成 $D_{\\text{train}}$、$D_{\\text{val}}$ 和 $D_{\\text{test}}$，使用固定的随机种子以确保确定性。\n2. 对每个测试用例 $(\\tau, \\omega)$，通过在损坏区域内翻转标签来生成 $D_{\\text{val}}^{\\text{corrupt}}$，保持 $D_{\\text{train}}$ 和 $D_{\\text{test}}$ 不变。\n3. 对于网格 $\\mathcal{K} = \\{1, 3, 5, 11, 21, 41\\}$ 中的每个 $k$：\n   - 使用在 $D_{\\text{train}}$ 上训练的 $h_k$ 计算对 $D_{\\text{val}}$ 的预测，并计算 $R(h_k; D_{\\text{val}}^{\\text{corrupt}})$ 以便使用损坏的标签进行选择。\n   - 同时计算 $R(h_k; D_{\\text{val}}^{\\text{clean}})$ 以便使用干净的验证标签进行神谕选择。\n4. 通过最小化相应的经验风险来选择 $k^\\star$ 和 $k^\\dagger$，向较小的 $k$ 打破平局。\n5. 在 $D_{\\text{test}}$ 上评估 $h_{k^\\star}$ 和 $h_{k^\\dagger}$，以分别获得测试准确率 $\\text{test\\_acc}(k^\\star)$ 和 $\\text{test\\_acc}(k^\\dagger)$。\n6. 如果 $k^\\star \\neq k^\\dagger$ 或者 $|\\text{test\\_acc}(k^\\star) - \\text{test\\_acc}(k^\\dagger)|  \\delta$（其中 $\\delta = 0.02$），则声明 $D_{\\text{test}}$ 揭示了错选。\n\n基于原则的推理：ERM 要求在代表性验证集上最小化经验风险，以近似最小化期望风险。结构化损坏通过在一个区域内系统性地翻转标签而违反了代表性，这可能偏向于那些与损坏标签而非底层数据生成过程一致的假设。对于 KNN，较大的 $k$ 值通过平均更多邻居来平滑决策；如果某个区域的标签被翻转，某些 $k$ 值可能更好地与损坏的标签对齐，从而改变选择。测试集是干净且独立抽取的，它提供了泛化性能的无偏估计。在损坏情况下选择的模型与神谕选择的模型之间在 $D_{\\text{test}}$ 上测量的差异，表明发生了错选。阈值 $\\delta$ 为超出随机变化的实际显著性设定了一个标准。\n\n测试套件覆盖范围：\n- $(\\tau, \\omega) = (100.0, 1.0)$ 的情况实际上不造成损坏，因为在标准正态分布下 $(x_1  100.0)$ 极不可能发生；这是一个边界条件，预期 $k^\\star = k^\\dagger$ 且准确率差异很小。\n- $(\\tau, \\omega) = (0.2, 0.5)$ 的情况在决策边界附近的一个区域引入了中等程度的结构化损坏，可能改变选择。\n- $(\\tau, \\omega) = (-0.5, 10.0)$ 的情况在一个大的半空间板状区域内翻转标签，是一种强损坏，预期会导致错选。\n- $(\\tau, \\omega) = (0.0, 0.15)$ 的情况将损坏集中在原点附近沿 $x_2$ 轴的区域，探测对狭窄局部损坏的敏感性。\n\n程序实现了这些步骤，并为每个测试用例输出元组 $[k^\\star, k^\\dagger, \\text{test\\_acc}(k^\\star), \\text{test\\_acc}(k^\\dagger), \\text{misselection\\_revealed}]$，汇总成一个单行打印的括号列表，按要求格式化。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef generate_data(n_train=200, n_val=150, n_test=400, d=2, w=np.array([1.0, -0.8]), b=0.1, noise_std=0.3, seed=42):\n    rng = np.random.default_rng(seed)\n    def make_split(n):\n        X = rng.normal(loc=0.0, scale=1.0, size=(n, d))\n        eps = rng.normal(loc=0.0, scale=noise_std, size=n)\n        s = X @ w + b + eps\n        y = (s > 0).astype(int)\n        return X, y\n    X_train, y_train = make_split(n_train)\n    X_val, y_val = make_split(n_val)\n    X_test, y_test = make_split(n_test)\n    return (X_train, y_train), (X_val, y_val), (X_test, y_test)\n\ndef corrupt_validation_labels(X_val, y_val, tau, omega):\n    # Structured corruption: flip labels when (x1 > tau) and (|x2| = omega)\n    mask = (X_val[:, 0] > tau)  (np.abs(X_val[:, 1]) = omega)\n    y_corrupt = y_val.copy()\n    y_corrupt[mask] = 1 - y_corrupt[mask]\n    return y_corrupt\n\ndef pairwise_sq_dists(X_query, X_train):\n    # Efficient squared Euclidean distances using expansion\n    # ||q - t||^2 = ||q||^2 + ||t||^2 - 2 q dot t\n    q_norm2 = np.sum(X_query**2, axis=1, keepdims=True)  # shape (n_query, 1)\n    t_norm2 = np.sum(X_train**2, axis=1)[None, :]        # shape (1, n_train)\n    dists = q_norm2 + t_norm2 - 2.0 * (X_query @ X_train.T)\n    return dists\n\ndef knn_predictions_sorted(train_X, train_y, query_X, sorted_idx, k):\n    # sorted_idx: indices of training points sorted by distance for each query, shape (n_query, n_train)\n    neighbors = sorted_idx[:, :k]  # shape (n_query, k)\n    neighbor_labels = train_y[neighbors]  # shape (n_query, k)\n    votes = np.sum(neighbor_labels, axis=1)  # number of 1's\n    # With odd k, majority is votes > k/2\n    preds = (votes > (k / 2.0)).astype(int)\n    return preds\n\ndef accuracy(preds, y_true):\n    return float(np.mean(preds == y_true))\n\ndef select_k(train_X, train_y, val_X, val_y_obs, sorted_idx_val, k_grid):\n    # Returns best k by minimizing misclassification risk (= 1 - accuracy), tie-breaker smallest k.\n    best_k = None\n    best_acc = -np.inf  # maximize accuracy\n    for k in k_grid:\n        preds = knn_predictions_sorted(train_X, train_y, val_X, sorted_idx_val, k)\n        acc = accuracy(preds, val_y_obs)\n        if acc > best_acc or (acc == best_acc and (best_k is None or k  best_k)):\n            best_acc = acc\n            best_k = k\n    return best_k, best_acc\n\ndef solve():\n    # Define the test cases from the problem statement: (tau, omega)\n    test_cases = [\n        (100.0, 1.0),   # effectively no corruption\n        (0.2, 0.5),     # moderate localized corruption\n        (-0.5, 10.0),   # severe widespread corruption\n        (0.0, 0.15),    # narrow band corruption\n    ]\n    # Generate data once (same underlying splits for all test cases)\n    (X_train, y_train), (X_val, y_val_clean), (X_test, y_test) = generate_data()\n    # Precompute sorted neighbor indices for val and test to reuse across k\n    dists_val = pairwise_sq_dists(X_val, X_train)\n    sorted_idx_val = np.argsort(dists_val, axis=1)\n    dists_test = pairwise_sq_dists(X_test, X_train)\n    sorted_idx_test = np.argsort(dists_test, axis=1)\n\n    k_grid = [1, 3, 5, 11, 21, 41]\n    delta = 0.02  # detection threshold for test accuracy difference\n\n    results = []\n    for tau, omega in test_cases:\n        # Apply structured corruption to validation labels\n        y_val_corrupt = corrupt_validation_labels(X_val, y_val_clean, tau, omega)\n\n        # Select k using corrupted validation labels\n        k_star, acc_val_star = select_k(X_train, y_train, X_val, y_val_corrupt, sorted_idx_val, k_grid)\n\n        # Oracle selection using clean validation labels\n        k_dagger, acc_val_dagger = select_k(X_train, y_train, X_val, y_val_clean, sorted_idx_val, k_grid)\n\n        # Evaluate both selections on the clean test set\n        preds_test_star = knn_predictions_sorted(X_train, y_train, X_test, sorted_idx_test, k_star)\n        test_acc_star = accuracy(preds_test_star, y_test)\n\n        preds_test_dagger = knn_predictions_sorted(X_train, y_train, X_test, sorted_idx_test, k_dagger)\n        test_acc_dagger = accuracy(preds_test_dagger, y_test)\n\n        # Determine if D_test reveals misselection\n        misselection_revealed = (k_star != k_dagger) or (abs(test_acc_star - test_acc_dagger) > delta)\n\n        results.append([k_star, k_dagger, round(test_acc_star, 6), round(test_acc_dagger, 6), misselection_revealed])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3188658"}, {"introduction": "对于时间序列数据，标准的独立同分布（i.i.d.）假设不再成立。最后一个实践 [@problem_id:3188604] 深入探讨了在时序数据上验证模型的复杂性，其中保留事件顺序至关重要。你将实现并比较不同的时间感知划分策略，并观察在数据行为随时间发生潜在变化时，模型选择的泛化能力（或泛化失败的情况）。", "problem": "给定一个人工合成的、完全指定的统计学习任务，旨在评估当特征提取使用滑动窗口时，训练、验证和测试集的划分策略如何与时间协变量和静态特征相互作用。您的目标是编写一个程序，实现一个完整的训练-验证-测试流水线，通过验证来选择特征提取窗口，并报告测试集的均方误差（以小数形式表示），同时遵守时间感知约束。该程序必须是自包含的，并且不得读取任何输入。\n\n数据生成过程定义如下。存在一个单一的静态特征和一个单变量的时间协变量。令 $t \\in \\{0,1,\\dots,T-1\\}$ 为时间索引。定义一个时间协变量序列 $c_t$ 为\n$$\nc_t = A \\cdot \\sin\\left(\\frac{2\\pi}{P} \\, t + \\phi_t\\right),\n$$\n其中相位 $\\phi_t$ 可能在指定的变化点 $T_{\\text{shift}}$ 处发生一次改变。具体来说，\n$$\n\\phi_t = \n\\begin{cases}\n0  \\text{若 } t  T_{\\text{shift}},\\\\\n\\phi_{\\text{shift}}  \\text{若 } t \\ge T_{\\text{shift}}.\n\\end{cases}\n$$\n所有三角函数参数均以弧度为单位。静态特征是在所有时间点都为常数标量 $s$。响应变量 $y_t$ 是使用时间协变量的滚动平均值生成的，其真实窗口大小可能在 $T_{\\text{shift}}$ 处改变：\n$$\nw^*(t) = \n\\begin{cases}\nw_1  \\text{若 } t  T_{\\text{shift}},\\\\\nw_2  \\text{若 } t \\ge T_{\\text{shift}},\n\\end{cases}\n$$\n并且\n$$\ny_t = \\beta_0 + \\beta_1 \\cdot \\frac{1}{w^*(t)} \\sum_{j=1}^{w^*(t)} c_{t-j} + \\beta_2 \\cdot s,\n$$\n这仅在 $t \\ge \\max\\{w_1,w_2\\}$ 时有良好定义。不存在随机噪声。\n\n您必须建立一个线性模型，以预测 $y_t$，其特征是使用应用于观测协变量 $c_t$ 的候选滚动窗口 $w$ 构建的：\n- 对于任何候选窗口 $w$，在时间 $t$ 的特征向量为\n$$\nx^{(w)}_t = \\left[\\,1,\\;\\frac{1}{w}\\sum_{j=1}^{w} c_{t-j},\\; s\\,\\right],\n$$\n这在 $t \\ge w$ 时有效。您必须从一个给定的有限集合 $\\mathcal{W}$ 中考虑多个候选窗口，并通过验证选择最佳窗口。\n\n训练-验证-测试过程和约束：\n- 令“合格”时间索引集合为 $\\mathcal{I} = \\{t_{\\min}, t_{\\min}+1, \\dots, T-1\\}$，其中 $t_{\\min} = \\max\\left(\\{w_1,w_2\\} \\cup \\mathcal{W}\\right)$，以确保所有滚动平均值都有良好定义。\n- 您必须支持两种确定性的划分策略：\n\n  1. **带间隔的连续时间块**：给定比例 $p_{\\text{train}} = 0.6$，$p_{\\text{val}} = 0.2$，以及一个整数间隔 $g \\ge 0$，将 $\\mathcal{I}$ 划分为不相交的连续段用于训练、验证和测试，在训练和验证之间插入一个大小为 $g$ 的间隔，在验证和测试之间再插入一个大小为 $g$ 的间隔。令 $n = |\\mathcal{I}|$。定义 $n_{\\text{train}} = \\lfloor 0.6n \\rfloor$，$n_{\\text{val}} = \\lfloor 0.2n \\rfloor$，并将考虑间隔后剩余的索引分配给测试集（剩余数量为 $n - n_{\\text{train}} - n_{\\text{val}} - 2g$，在提供的测试套件中假定为非负）。每个段内必须保持时间顺序。\n  \n  2. **交错周期性划分**：固定一个周期 $m = 5$。根据索引模 $m$ 的余数将 $\\mathcal{I}$ 中的索引分配给不同的集合：如果 $t \\bmod m \\in \\{0,1,2\\}$，则为训练集；如果 $t \\bmod m \\in \\{3\\}$，则为验证集；如果 $t \\bmod m \\in \\{4\\}$，则为测试集。\n\n- 对于每个候选窗口 $w \\in \\mathcal{W}$，在训练集上拟合一个普通最小二乘线性回归模型，以最小化从 $x^{(w)}_t$ 预测 $y_t$ 的经验平方损失。将训练设计矩阵表示为 $X_{\\text{train}}^{(w)}$，训练响应向量表示为 $y_{\\text{train}}$。最小二乘估计 $\\hat{\\theta}^{(w)}$ 满足正规方程 $X_{\\text{train}}^{(w)\\top} X_{\\text{train}}^{(w)} \\hat{\\theta}^{(w)} = X_{\\text{train}}^{(w)\\top} y_{\\text{train}}$。使用任何数值稳定的方法获得一个解（例如，摩尔-彭若斯伪逆）。\n- 通过其均方误差在验证集上评估每个 $w$\n$$\n\\text{MSE}_{\\text{val}}(w) = \\frac{1}{|\\mathcal{V}|} \\sum_{t \\in \\mathcal{V}} \\left(y_t - x^{(w)}_t \\cdot \\hat{\\theta}^{(w)}\\right)^2,\n$$\n并选择最小化 $\\text{MSE}_{\\text{val}}(w)$ 的窗口 $\\hat{w}$。如果 $\\text{MSE}_{\\text{val}}$ 出现平局，选择最小化器中最小的 $w$。\n- 选择 $\\hat{w}$ 后，使用训练集和验证集的并集，以相同的特征定义重新拟合模型，得到 $\\hat{\\theta}^{(\\hat{w})}_{\\text{refit}}$。\n- 报告测试集均方误差\n$$\n\\text{MSE}_{\\text{test}} = \\frac{1}{|\\mathcal{T}|} \\sum_{t \\in \\mathcal{T}} \\left(y_t - x^{(\\hat{w})}_t \\cdot \\hat{\\theta}^{(\\hat{w})}_{\\text{refit}}\\right)^2.\n$$\n\n角度单位要求：所有角度均以弧度为单位。\n\n您的程序必须为以下参数设置的测试套件实现上述过程。每个测试用例指定 $(T, P, A, \\beta_0, \\beta_1, \\beta_2, s, w_1, w_2, T_{\\text{shift}}, \\phi_{\\text{shift}}, \\text{split}, \\text{extra}, \\mathcal{W})$：\n\n- 测试用例 1（理想路径，无季节性相位或窗口变化）：\n  - $T=120$, $P=24$, $A=2$, $\\beta_0=0.5$, $\\beta_1=1.2$, $\\beta_2=-0.7$, $s=1.3$.\n  - $w_1=8$, $w_2=8$, $T_{\\text{shift}}=120$, $\\phi_{\\text{shift}}=0$.\n  - 划分：带间隔 $g=3$ 的连续块；使用如上定义的 $p_{\\text{train}}=0.6$, $p_{\\text{val}}=0.2$。\n  - 候选窗口 $\\mathcal{W}=\\{4,8,12\\}$。\n\n- 测试用例 2（季节性相位和窗口仅在测试时段变化）：\n  - $T=120$, $P=24$, $A=2$, $\\beta_0=0.5$, $\\beta_1=1.2$, $\\beta_2=-0.7$, $s=1.3$.\n  - $w_1=4$, $w_2=12$, $T_{\\text{shift}}=80$, $\\phi_{\\text{shift}}=\\frac{\\pi}{2}$.\n  - 划分：带间隔 $g=3$ 的连续块；使用如上定义的 $p_{\\text{train}}=0.6$, $p_{\\text{val}}=0.2$。\n  - 候选窗口 $\\mathcal{W}=\\{4,8,12\\}$。\n\n- 测试用例 3（在季节性相位和窗口变化下的交错划分）：\n  - $T=120$, $P=24$, $A=2$, $\\beta_0=0.5$, $\\beta_1=1.2$, $\\beta_2=-0.7$, $s=1.3$.\n  - $w_1=6$, $w_2=10$, $T_{\\text{shift}}=60$, $\\phi_{\\text{shift}}=\\frac{\\pi}{3}$.\n  - 划分：周期 $m=5$ 的交错划分，将训练分配给余数 $\\{0,1,2\\}$，验证分配给 $\\{3\\}$，测试分配给 $\\{4\\}$。\n  - 候选窗口 $\\mathcal{W}=\\{4,6,10,12\\}$。\n\n- 测试用例 4（窗口大小的边界情况且无变化）：\n  - $T=40$, $P=10$, $A=1.5$, $\\beta_0=0.5$, $\\beta_1=1.2$, $\\beta_2=-0.7$, $s=1.3$.\n  - $w_1=1$, $w_2=1$, $T_{\\text{shift}}=40$, $\\phi_{\\text{shift}}=0$.\n  - 划分：带间隔 $g=0$ 的连续块；使用如上定义的 $p_{\\text{train}}=0.6$, $p_{\\text{val}}=0.2$。\n  - 候选窗口 $\\mathcal{W}=\\{1,2\\}$。\n\n实现要求：\n- 对于每个测试用例，完全按照描述构建 $c_t$ 和 $y_t$。\n- 仅使用过去的协变量值 $c_{t-j}$ 计算特征；不要使用相对于 $t$ 的未来值。\n- 将指定的划分策略应用于合格索引集 $\\mathcal{I} = \\{t_{\\min},\\dots,T-1\\}$，其中 $t_{\\min} = \\max(\\{w_1,w_2\\}\\cup \\mathcal{W})$。\n- 在训练数据上为每个候选模型进行训练，通过最小化验证均方误差来选择 $\\hat{w}$，决胜规则偏向于较小的 $w$，在训练加验证集上为 $\\hat{w}$ 重新拟合，并计算测试均方误差。\n\n最终输出格式：\n- 您的程序应生成一行输出，其中包含一个方括号内的、以逗号分隔的结果列表，按测试用例 1 到 4 的顺序排列，每个均方误差四舍五入到恰好 6 位小数。例如，输出可能看起来像 `[0.000123,0.045678,0.010000,0.000000]`。", "solution": "该问题提出了一个人工合成的、确定性的统计学习任务，旨在评估在存在潜在结构性断点的时间序列背景下，模型选择策略的效果。该过程涉及数据生成、使用滑动窗口进行特征工程、时间感知的数据划分、模型训练、通过验证进行超参数（窗口大小）选择，以及在测试集上的最终性能评估。解决方案严格遵循指定的过程。\n\n**1. 数据生成**\n\n首先，对于每个测试用例，我们在时间范围 $t \\in \\{0, 1, \\dots, T-1\\}$ 上生成时间协变量序列 $c_t$ 和响应序列 $y_t$。\n\n时间协变量 $c_t$ 被定义为一个正弦函数：\n$$\nc_t = A \\cdot \\sin\\left(\\frac{2\\pi}{P} \\, t + \\phi_t\\right)\n$$\n其中相位 $\\phi_t$ 是分段常数，在给定的时间点 $t=T_{\\text{shift}}$ 从 $0$ 变为指定的 $\\phi_{\\text{shift}}$ 值：\n$$\n\\phi_t = \n\\begin{cases}\n0  \\text{若 } t  T_{\\text{shift}},\\\\\n\\phi_{\\text{shift}}  \\text{若 } t \\ge T_{\\text{shift}}.\n\\end{cases}\n$$\n\n响应变量 $y_t$ 是常数静态特征 $s$ 和 $c_t$ 过去值的滚动平均值的线性函数。用于此滚动平均的窗口大小 $w^*(t)$ 也是分段常数，在 $T_{\\text{shift}}$ 处从 $w_1$ 变为 $w_2$：\n$$\nw^*(t) = \n\\begin{cases}\nw_1  \\text{若 } t  T_{\\text{shift}},\\\\\nw_2  \\text{若 } t \\ge T_{\\text{shift}},\n\\end{cases}\n$$\n然后，响应 $y_t$ 由以下公式给出：\n$$\ny_t = \\beta_0 + \\beta_1 \\cdot \\left(\\frac{1}{w^*(t)} \\sum_{j=1}^{w^*(t)} c_{t-j}\\right) + \\beta_2 \\cdot s\n$$\n该值仅在回看窗口不延伸到 $t=0$ 之前的时间点 $t$ 上有定义。为确保所有候选模型和真实数据生成过程都有良好定义，我们在一个“合格”的时间索引集合 $\\mathcal{I} = \\{t_{\\min}, t_{\\min}+1, \\dots, T-1\\}$ 上操作，其中 $t_{\\min}$ 是所有涉及的窗口大小（真实的和候选的）中的最大值：$t_{\\min} = \\max\\left(\\{w_1, w_2\\} \\cup \\mathcal{W}\\right)$。\n\n**2. 数据划分**\n\n合格索引集 $\\mathcal{I}$ 根据两种指定策略之一被划分为训练、验证和测试集：\n\n- **连续时间块：** $\\mathcal{I}$ 的有序索引被划分为三个连续的块，分别用于训练、验证和测试。训练集取前 $\\lfloor 0.6n \\rfloor$ 个索引，验证集取接下来的 $\\lfloor 0.2n \\rfloor$ 个索引，其中 $n = |\\mathcal{I}|$。在训练集和验证集之间，以及验证集和测试集之间，强制设置一个大小为 $g$ 的时间间隔，以模拟接收数据的延迟。测试集包含所有剩余的索引。\n- **交错周期性划分：** 来自 $\\mathcal{I}$ 的索引根据其值模周期 $m=5$ 的结果分配到集合中。索引 $t \\bmod 5 \\in \\{0, 1, 2\\}$ 的构成训练集，$t \\bmod 5 = 3$ 的构成验证集，$t \\bmod 5 = 4$ 的构成测试集。这种策略确保所有三个集合都从整个时间段中抽取，如果数据属性随时间变化，这可能是有利的。\n\n**3. 特征工程与模型选择**\n\n预测模型是一个线性回归模型。对于集合 $\\mathcal{W}$ 中的每个候选窗口大小 $w$，在每个时间 $t$ 构建一个特征向量 $x^{(w)}_t$：\n$$\nx^{(w)}_t = \\left[\\,1,\\;\\frac{1}{w}\\sum_{j=1}^{w} c_{t-j},\\; s\\,\\right]\n$$\n该向量的三个分量分别对应于截距项、从时间协变量派生的特征以及静态特征。\n\n任务的核心是选择最优的窗口大小 $\\hat{w}$。这是通过以下步骤实现的：\n1.  对于每个候选窗口 $w \\in \\mathcal{W}$，使用训练数据拟合一个普通最小二乘（OLS）线性模型。模型系数 $\\hat{\\theta}^{(w)}$ 通过求解正规方程找到，为此我们使用摩尔-彭若斯伪逆以确保数值稳定性：$\\hat{\\theta}^{(w)} = (X_{\\text{train}}^{(w)\\top} X_{\\text{train}}^{(w)})^{-1} X_{\\text{train}}^{(w)\\top} y_{\\text{train}}$。在实现中，这被计算为 $\\hat{\\theta}^{(w)} = \\text{pinv}(X_{\\text{train}}^{(w)}) \\cdot y_{\\text{train}}$。\n2.  每个训练好的模型 $(\\hat{\\theta}^{(w)}, w)$ 的性能通过计算均方误差（MSE）在验证集上进行评估：\n    $$\n    \\text{MSE}_{\\text{val}}(w) = \\frac{1}{|\\mathcal{V}|} \\sum_{t \\in \\mathcal{V}} \\left(y_t - x^{(w)}_t \\cdot \\hat{\\theta}^{(w)}\\right)^2\n    $$\n3.  选择产生最小验证 MSE 的窗口大小 $\\hat{w}$ 作为最佳超参数。决胜规则规定，如果多个窗口导致相同的最小 MSE，则选择其中最小的窗口大小。\n\n**4. 最终评估**\n\n在确定了最优窗口大小 $\\hat{w}$ 后，模型被重新训练。这一次，训练数据用验证数据进行增强，形成一个合并的训练-验证集。这一步利用更多的数据来获得可能更稳健的模型参数估计。通过在这个合并的数据集上拟合具有特征集 $x^{(\\hat{w})}_t$ 的模型，获得新的系数 $\\hat{\\theta}^{(\\hat{w})}_{\\text{refit}}$。\n\n最后，在这个迄今未使用的测试集上评估这个重新拟合模型的性能。计算测试 MSE，它代表了模型在未见数据上的泛化误差：\n$$\n\\text{MSE}_{\\text{test}} = \\frac{1}{|\\mathcal{T}|} \\sum_{t \\in \\mathcal{T}} \\left(y_t - x^{(\\hat{w})}_t \\cdot \\hat{\\theta}^{(\\hat{w})}_{\\text{refit}}\\right)^2\n$$\n这个最终值是每个测试用例报告的结果。整个过程是确定性的，对于每组输入参数都会产生唯一的结果。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = [\n        # (T, P, A, beta0, beta1, beta2, s, w1, w2, T_shift, phi_shift, split_type, extra, W_set)\n        (120, 24, 2, 0.5, 1.2, -0.7, 1.3, 8, 8, 120, 0.0, 'contiguous', 3, {4, 8, 12}),\n        (120, 24, 2, 0.5, 1.2, -0.7, 1.3, 4, 12, 80, np.pi/2, 'contiguous', 3, {4, 8, 12}),\n        (120, 24, 2, 0.5, 1.2, -0.7, 1.3, 6, 10, 60, np.pi/3, 'interleaved', 5, {4, 6, 10, 12}),\n        (40, 10, 1.5, 0.5, 1.2, -0.7, 1.3, 1, 1, 40, 0.0, 'contiguous', 0, {1, 2}),\n    ]\n\n    results = []\n    for params in test_cases:\n        mse = solve_case(*params)\n        results.append(f\"{mse:.6f}\")\n    \n    print(f\"[{','.join(results)}]\")\n\ndef solve_case(T, P, A, beta0, beta1, beta2, s, w1, w2, T_shift, phi_shift, split_type, extra, W_set):\n    \"\"\"\n    Solves a single instance of the statistical learning problem.\n    \"\"\"\n    # 1. Determine eligible time indices\n    t_min = max(list(W_set) + [w1, w2])\n\n    # 2. Generate data: c_t and y_t\n    t_range = np.arange(T)\n    phi_t = np.where(t_range  T_shift, 0, phi_shift)\n    c_t = A * np.sin(2 * np.pi / P * t_range + phi_t)\n\n    w_star_t = np.where(t_range  T_shift, w1, w2)\n    y_full = np.full(T, np.nan)\n    for t in range(t_min, T):\n        w_star = w_star_t[t]\n        # Rolling mean for the true response. Slicing c_t[t-w_star:t] corresponds to c_{t-j} for j=1..w_star\n        mean_c = np.mean(c_t[t - w_star : t])\n        y_full[t] = beta0 + beta1 * mean_c + beta2 * s\n    \n    # 3. Create data splits\n    eligible_indices = np.arange(t_min, T)\n    if split_type == 'contiguous':\n        n = len(eligible_indices)\n        g = extra\n        n_train = int(0.6 * n)\n        n_val = int(0.2 * n)\n        \n        train_indices = eligible_indices[:n_train]\n        val_indices = eligible_indices[n_train + g : n_train + g + n_val]\n        test_indices = eligible_indices[n_train + g + n_val + g :]\n    elif split_type == 'interleaved':\n        m = extra\n        train_indices = eligible_indices[np.isin(eligible_indices % m, [0, 1, 2])]\n        val_indices = eligible_indices[eligible_indices % m == 3]\n        test_indices = eligible_indices[eligible_indices % m == 4]\n    else:\n        raise ValueError(\"Unknown split type\")\n\n    # 4. Pre-compute rolling mean features for all candidate windows\n    rolling_means = {}\n    for w in W_set:\n        means_w = np.full(T, np.nan)\n        for t in range(w, T):\n            means_w[t] = np.mean(c_t[t-w:t])\n        rolling_means[w] = means_w\n\n    # 5. Model selection loop (hyperparameter tuning)\n    val_mses = {}\n    for w in sorted(list(W_set)): # Sort for deterministic tie-breaking\n        # Construct training data matrix and response vector\n        X_train = np.c_[np.ones(len(train_indices)), rolling_means[w][train_indices], np.full(len(train_indices), s)]\n        y_train = y_full[train_indices]\n        \n        # Fit model using pseudoinverse for numerical stability\n        theta_hat = np.linalg.pinv(X_train) @ y_train\n        \n        # Evaluate on validation set\n        if len(val_indices) > 0:\n            X_val = np.c_[np.ones(len(val_indices)), rolling_means[w][val_indices], np.full(len(val_indices), s)]\n            y_val = y_full[val_indices]\n            \n            y_pred_val = X_val @ theta_hat\n            val_mses[w] = np.mean((y_val - y_pred_val)**2)\n        else: # Handle cases with empty validation set\n            val_mses[w] = np.inf\n\n    # Select best window w_hat based on validation MSE, with tie-breaking\n    w_hat = min(val_mses, key=lambda w: (val_mses[w], w))\n\n    # 6. Refit on train+validation and evaluate on test set\n    refit_indices = np.sort(np.concatenate((train_indices, val_indices)))\n    \n    X_refit = np.c_[np.ones(len(refit_indices)), rolling_means[w_hat][refit_indices], np.full(len(refit_indices), s)]\n    y_refit = y_full[refit_indices]\n    \n    theta_refit = np.linalg.pinv(X_refit) @ y_refit\n    \n    if len(test_indices) > 0:\n        X_test = np.c_[np.ones(len(test_indices)), rolling_means[w_hat][test_indices], np.full(len(test_indices), s)]\n        y_test = y_full[test_indices]\n        \n        y_pred_test = X_test @ theta_refit\n        test_mse = np.mean((y_test - y_pred_test)**2)\n    else: # Handle cases with empty test set\n        test_mse = 0.0\n    \n    return test_mse\n\nsolve()\n```", "id": "3188604"}]}