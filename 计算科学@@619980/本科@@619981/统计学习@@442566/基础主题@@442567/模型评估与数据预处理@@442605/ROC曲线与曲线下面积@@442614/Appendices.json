{"hands_on_practices": [{"introduction": "ROC曲线下面积（AUC）不仅是一个几何概念，它更有一个直观的概率解释：即随机抽取一个正样本，其得分高于随机抽取一个负样本的概率。这个练习将通过一个具体的数据集，帮助您深入理解AUC的这一概率意义，并探讨在处理真实世界中常见的离散或并列得分时，如何通过一个广义的AUC公式 $AUC_{\\lambda}$ 来系统地分析并列得分的影响。通过这个练习 [@problem_id:3167068]，您将掌握AUC的核心计算，并理解其对单调变换的不变性等重要性质。", "problem": "考虑一个二元分类场景，其中评分函数为每个实例分配一个实值分数 $S$。受试者工作特征（ROC）曲线绘制了当决策阈值 $\\tau$ 从 $+\\infty$ 扫描到 $-\\infty$ 时，真正例率（TPR）相对于假正例率（FPR）的变化情况，其中 $\\text{TPR}(\\tau) = \\mathbb{P}(S \\ge \\tau \\mid Y=1)$ 且 $\\text{FPR}(\\tau) = \\mathbb{P}(S \\ge \\tau \\mid Y=0)$。曲线下面积（AUC）是该ROC曲线下的面积。\n\n为了研究分数相等（ties）对曲线下面积的贡献，对于 $\\lambda \\in [0,1]$ 定义广义曲线下面积\n$$\nAUC_\\lambda \\;=\\; \\mathbb{P}(S^+ > S^-) \\;+\\; \\lambda \\,\\mathbb{P}(S^+ = S^-),\n$$\n其中 $S^+$ 是从正例中随机抽取的样本分数，$S^-$ 是从负例中随机抽取的样本分数，抽样在经验正负样本集上均匀进行，且两者相互独立。\n\n给定 $n_+ = 5$ 个正例和 $n_- = 5$ 个负例的分数：\n- 正例：$S^+ \\in \\{0.2,\\,0.4,\\,0.6,\\,0.6,\\,0.8\\}$，\n- 负例：$S^- \\in \\{0.1,\\,0.4,\\,0.4,\\,0.7,\\,0.9\\}$。\n\n首先，通过计算所有 $n_+ n_- = 25$ 个正-负样本对，并将计数转换为概率，来为给定列表计算 $\\mathbb{P}(S^+ > S^-)$ 和 $\\mathbb{P}(S^+ = S^-)$。然后，用这些值来评估当 $\\lambda \\in \\{0,\\,1/2,\\,1\\}$ 时的 $AUC_\\lambda$。\n\n选择所有正确的选项。\n\nA. 对于给定的分数，$AUC_{1/2} = 0.52$。\n\nB. 对于任何严格递增函数 $g:\\mathbb{R}\\to\\mathbb{R}$，对于所有 $\\lambda \\in [0,1]$，由 $g(S)$ 计算出的 $AUC_\\lambda$ 值与由 $S$ 计算出的值相同。\n\nC. 如果分数分布是连续的，使得 $\\mathbb{P}(S^+ = S^-)=0$，那么 $AUC_\\lambda$ 与 $\\lambda$ 无关，并且等于 $\\mathbb{P}(S^+ > S^-)$。\n\nD. 通过扫描阈值并使用梯形法则得到的标准经验ROC曲线下面积对应于 $\\lambda = 1$。\n\nE. 对于固定的分数分布，$AUC_\\lambda$ 是 $\\lambda$ 的线性函数，其斜率为 $\\mathbb{P}(S^+ = S^-)$。", "solution": "该问题陈述经核实具有科学依据、提法恰当且客观。它为广义曲线下面积 $AUC_\\lambda$ 提供了明确的定义，并给出了一个具体的数据集来进行计算和评估概念性陈述。没有矛盾、歧义或信息缺失。\n\n问题的核心是计算与分数比较相关的概率，然后分析 $AUC_\\lambda$ 函数的性质。\n\n首先，我们根据给定数据计算所需的概率。\n正例分数的集合是 $S^+ \\in \\{0.2, 0.4, 0.6, 0.6, 0.8\\}$，其中 $n_+ = 5$。\n负例分数的集合是 $S^- \\in \\{0.1, 0.4, 0.4, 0.7, 0.9\\}$，其中 $n_- = 5$。\n一个正例和一个负例组成的样本对总数为 $n_+ n_- = 5 \\times 5 = 25$。\n\n我们需要计算满足 $S^+ > S^-$、$S^+ = S^-$ 和 $S^+ < S^-$ 的样本对 $(S^+, S^-)$ 的数量。我们可以对每个正例分数系统地进行计算：\n- 对于 $S^+ = 0.2$：\n  - $0.2 > 0.1$（1 对）\n  - $0.2 < 0.4$（2 对）\n  - $0.2 < 0.7$（1 对）\n  - $0.2 < 0.9$（1 对）\n  - 对于 $S^+=0.2$ 的总计：1 对 $S^+ > S^-$，0 对 $S^+ = S^-$。\n\n- 对于 $S^+ = 0.4$：\n  - $0.4 > 0.1$（1 对）\n  - $0.4 = 0.4$（2 对）\n  - $0.4 < 0.7$（1 对）\n  - $0.4 < 0.9$（1 对）\n  - 对于 $S^+=0.4$ 的总计：1 对 $S^+ > S^-$，2 对 $S^+ = S^-$。\n\n- 对于两个分数为 $S^+ = 0.6$ 的每个分数：\n  - $0.6 > 0.1$（1 对）\n  - $0.6 > 0.4$（2 对）\n  - $0.6 < 0.7$（1 对）\n  - $0.6 < 0.9$（1 对）\n  - 对于每个 $S^+=0.6$ 的总计：3 对 $S^+ > S^-$，0 对 $S^+ = S^-$。\n  - 对于两个 $0.6$ 的分数，这提供了 $2 \\times 3 = 6$ 对 $S^+ > S^-$。\n\n- 对于 $S^+ = 0.8$：\n  - $0.8 > 0.1$（1 对）\n  - $0.8 > 0.4$（2 对）\n  - $0.8 > 0.7$（1 对）\n  - $0.8 < 0.9$（1 对）\n  - 对于 $S^+=0.8$ 的总计：4 对 $S^+ > S^-$，0 对 $S^+ = S^-$。\n\n将这些计数相加：\n- 满足 $S^+ > S^-$ 的总对数：$1 + 1 + 6 + 4 = 12$。\n- 满足 $S^+ = S^-$ 的总对数：$0 + 2 + 0 + 0 = 2$。\n- 其余的样本对必然满足 $S^+ < S^-$，其数量为 $25 - 12 - 2 = 11$。\n\n现在，我们通过除以总对数 $25$ 将这些计数转换为概率：\n$$\n\\mathbb{P}(S^+ > S^-) = \\frac{12}{25} = 0.48\n$$\n$$\n\\mathbb{P}(S^+ = S^-) = \\frac{2}{25} = 0.08\n$$\n\n广义曲线下面积的公式为：\n$$\nAUC_\\lambda = \\mathbb{P}(S^+ > S^-) + \\lambda \\mathbb{P}(S^+ = S^-)\n$$\n代入计算出的概率：\n$$\nAUC_\\lambda = 0.48 + \\lambda(0.08)\n$$\n\n现在我们评估每个选项。\n\n**A. 对于给定的分数，$AUC_{1/2} = 0.52$。**\n我们在我们推导出的 $AUC_\\lambda$ 表达式中设置 $\\lambda = 1/2$：\n$$\nAUC_{1/2} = 0.48 + \\frac{1}{2}(0.08) = 0.48 + 0.04 = 0.52\n$$\n该陈述与我们的计算相符。\n结论：**正确**。\n\n**B. 对于任何严格递增函数 $g:\\mathbb{R}\\to\\mathbb{R}$，对于所有 $\\lambda \\in [0,1]$，由 $g(S)$ 计算出的 $AUC_\\lambda$ 值与由 $S$ 计算出的值相同。**\n$AUC_\\lambda$ 的定义取决于概率 $\\mathbb{P}(S^+ > S^-)$ 和 $\\mathbb{P}(S^+ = S^-)$。这些概率由分数对的排序和相等关系决定。一个严格递增函数 $g$ 会保持排序关系，意味着对于任意两个数 $a$ 和 $b$：\n- $a > b \\iff g(a) > g(b)$\n- $a = b \\iff g(a) = g(b)$\n- $a < b \\iff g(a) < g(b)$\n因此，事件 $\\{S^+ > S^-\\}$ 和 $\\{g(S^+) > g(S^-)\\}$ 是等价的，事件 $\\{S^+ = S^-\\}$ 和 $\\{g(S^+) = g(S^-)\\}$ 也是等价的。这意味着它们的概率是相同的：\n$$\n\\mathbb{P}(g(S^+) > g(S^-)) = \\mathbb{P}(S^+ > S^-)\n$$\n$$\n\\mathbb{P}(g(S^+) = g(S^-)) = \\mathbb{P}(S^+ = S^-)\n$$\n由于构成 $AUC_\\lambda$ 的两个概率分量在这样的变换 $g$ 下是不变的，因此对于任何 $\\lambda$，$AUC_\\lambda$ 的值也是不变的。这是AUC的一个基本性质。\n结论：**正确**。\n\n**C. 如果分数分布是连续的，使得 $\\mathbb{P}(S^+ = S^-)=0$，那么 $AUC_\\lambda$ 与 $\\lambda$ 无关，并且等于 $\\mathbb{P}(S^+ > S^-)$。**\n给定公式 $AUC_\\lambda = \\mathbb{P}(S^+ > S^-) + \\lambda \\mathbb{P}(S^+ = S^-)$。\n如果我们假设分布是连续的，那么两个独立样本之间出现相等情况的概率为零，即 $\\mathbb{P}(S^+ = S^-) = 0$。\n将此代入公式得到：\n$$\nAUC_\\lambda = \\mathbb{P}(S^+ > S^-) + \\lambda \\cdot 0 = \\mathbb{P}(S^+ > S^-)\n$$\n所得表达式 $\\mathbb{P}(S^+ > S^-)$ 不包含 $\\lambda$。因此，在此条件下，$AUC_\\lambda$ 与 $\\lambda$ 无关。这是对于连续分数下AUC的标准定义。\n结论：**正确**。\n\n**D. 通过扫描阈值并使用梯形法则得到的标准经验ROC曲线下面积对应于 $\\lambda = 1$。**\n从一组分数计算经验AUC的标准方法包括构建ROC曲线并计算其下面积。ROC曲线是一组点 $(FPR, TPR)$。当在某个分数阈值上，正例和负例之间存在分数相等的情况时，曲线会沿对角线移动。使用梯形法则计算这个分段线性曲线下的面积等价于在ROC点之间进行线性插值。该方法也等价于Wilcoxon-Mann-Whitney U统计量，当归一化后，它计算AUC的方式如下：\n$$\nAUC = \\frac{1}{n_+ n_-} \\left( \\sum_{S^+ > S^-} 1 + \\frac{1}{2} \\sum_{S^+ = S^-} 1 \\right) = \\mathbb{P}(S^+ > S^-) + \\frac{1}{2}\\mathbb{P}(S^+ = S^-)\n$$\n这对应于 $AUC_{1/2}$，即 $\\lambda = 1/2$。这个选择反映了随机打破相等情况的思想。$\\lambda = 1$ 的情况对应于 $AUC_1 = \\mathbb{P}(S^+ > S^-) + \\mathbb{P}(S^+ = S^-) = \\mathbb{P}(S^+ \\ge S^-)$，这代表了一种对相等情况的乐观处理方式，即总是将它们计为正确的分类。这并非梯形法则所定义的标准。\n结论：**错误**。\n\n**E. 对于固定的分数分布，$AUC_\\lambda$ 是 $\\lambda$ 的线性函数，其斜率为 $\\mathbb{P}(S^+ = S^-)$。**\n公式为 $AUC_\\lambda = \\mathbb{P}(S^+ > S^-) + \\lambda \\mathbb{P}(S^+ = S^-)$。\n对于固定的分数分布，$\\mathbb{P}(S^+ > S^-)$ 和 $\\mathbb{P}(S^+ = S^-)$ 这两个量是常数。我们用 $C_1 = \\mathbb{P}(S^+ > S^-)$ 和 $C_2 = \\mathbb{P}(S^+ = S^-)$ 来表示它们。表达式变为：\n$$\nAUC_\\lambda = C_1 + C_2 \\lambda\n$$\n这是一个形如 $y = c + mx$ 的方程，其中 $y = AUC_\\lambda$，$x = \\lambda$，截距是 $c=C_1$，斜率为 $m=C_2$。因此，$AUC_\\lambda$ 确实是 $\\lambda$ 的线性函数，其斜率是 $\\lambda$ 的系数，即 $C_2 = \\mathbb{P}(S^+ = S^-)$。\n结论：**正确**。\n\n最终结论摘要：\n- A: 正确\n- B: 正确\n- C: 正确\n- D: 错误\n- E: 正确\n\n正确的选项是 A、B、C 和 E。", "answer": "$$\\boxed{ABCE}$$", "id": "3167068"}, {"introduction": "在不同的教科书或计算库中，您可能会遇到计算经验AUC的多种方法，例如基于ROC曲线的梯形法则，或是基于曼-惠特尼U统计量（Mann-Whitney U statistic）的成对比较。这可能会带来困惑：这些方法是否等价？本练习 [@problem_id:3167034] 旨在通过严谨的数学推导来消除这一疑虑，证明这两种最常见的经验AUC计算方法在代数上是完全等价的。完成这个练习将加深您对AUC度量鲁棒性的理解，并确信无论采用何种标准计算方法，其结果都具有一致性。", "problem": "一个二元分类器为每个实例分配一个实值分数。有 $n$ 个正实例和 $m$ 个负实例，其中 $n \\geq 1$ 且 $m \\geq 1$。考虑以下两种受试者工作特征（ROC）曲线下面积的经验估计量。\n\n1. 通过曼-惠特尼统计量定义经验曲线下面积（AUC）为\n$$\nA_{\\mathrm{MW}} \\;=\\; \\frac{1}{nm} \\sum_{i=1}^{n} \\sum_{j=1}^{m} \\left[ \\mathbf{1}\\big(s_{i}^{+} > s_{j}^{-}\\big) \\;+\\; \\frac{1}{2}\\,\\mathbf{1}\\big(s_{i}^{+} = s_{j}^{-}\\big) \\right],\n$$\n其中 $s_{i}^{+}$ 表示第 $i$ 个正实例的分数，$s_{j}^{-}$ 表示第 $j$ 个负实例的分数，$\\mathbf{1}(\\cdot)$ 是指示函数。\n\n2. 通过将所有实例按其分数非递增排序，并将它们分组到相同分数的块中，来构建经验ROC曲线。假设有 $B$ 个不同的分数级别；在级别 $b \\in \\{1,\\dots,B\\}$，有 $t_{b}$ 个正例和 $u_{b}$ 个负例，满足 $\\sum_{b=1}^{B} t_{b} = n$ 和 $\\sum_{b=1}^{B} u_{b} = m$。令块 $b$ 之前的累积假正例率和真正例率为\n$$\nx_{b-1} \\;=\\; \\frac{1}{m} \\sum_{a=1}^{b-1} u_{a}, \\qquad\ny_{b-1} \\;=\\; \\frac{1}{n} \\sum_{a=1}^{b-1} t_{a},\n$$\n块 $b$ 之后的累积假正例率和真正例率为\n$$\nx_{b} \\;=\\; x_{b-1} + \\frac{u_{b}}{m}, \\qquad\ny_{b} \\;=\\; y_{b-1} + \\frac{t_{b}}{n}.\n$$\n将这 $B+1$ 个点 $\\{(x_{b},y_{b})\\}_{b=0}^{B}$ 上的梯形法则AUC定义为\n$$\nA_{\\mathrm{trap}} \\;=\\; \\sum_{b=1}^{B} \\frac{y_{b-1} + y_{b}}{2} \\,\\big(x_{b} - x_{b-1}\\big).\n$$\n\n将分数 $\\{s_{i}^{+}\\}$ 和 $\\{s_{j}^{-}\\}$ 视为任意实数，它们决定了块大小 $\\{t_{b}\\}$ 和 $\\{u_{b}\\}$ 及其顺序。在所有可能的分数分配（等价于，在所有与 $n$ 和 $m$ 一致的可能 $\\{t_{b},u_{b}\\}_{b=1}^{B}$ 以及所有可能的块顺序）上，计算这两个AUC估计量之间绝对差异的上确界，\n$$\n\\sup \\left| A_{\\mathrm{MW}} \\,-\\, A_{\\mathrm{trap}} \\right|.\n$$\n\n您的最终答案必须是一个实数值。不需要四舍五入。", "solution": "问题要求计算两种ROC曲线下面积（AUC）估计量之间绝对差的上确界：一种基于曼-惠特尼统计量，$A_{\\mathrm{MW}}$，另一种基于梯形法则，$A_{\\mathrm{trap}}$。该上确界是在对 $n$ 个正实例和 $m$ 个负实例所有可能的分数分配上取。\n\n我们的策略是将 $A_{\\mathrm{MW}}$ 和 $A_{\\mathrm{trap}}$ 都表示为一个共同的、依赖于已排序分数结构的代数形式。当所有 $n+m$ 个分数按非递增顺序排序时，任何分数 $\\{s_i^+\\}$ 和 $\\{s_j^-\\}$ 的分配都会产生一个特定的、由相同分数组成的块序列。设存在 $B$ 个这样的块，索引为 $b=1, \\dots, B$，对应于不同的分数值 $S_1 > S_2 > \\dots > S_B$。设块 $b$ 包含 $t_b$ 个正实例和 $u_b$ 个负实例。正实例和负实例的总数是守恒的，因此我们有约束条件 $\\sum_{b=1}^{B} t_b = n$ 和 $\\sum_{b=1}^{B} u_b = m$。该问题等价于在所有可能的分区 $\\{t_b, u_b\\}_{b=1}^B$ 及其顺序上，找到 $|A_{\\mathrm{MW}} - A_{\\mathrm{trap}}|$ 的上确界。\n\n首先，我们分析梯形法则估计量 $A_{\\mathrm{trap}}$。\n它被定义为由经验ROC曲线上的点形成的梯形面积之和：\n$$\nA_{\\mathrm{trap}} \\;=\\; \\sum_{b=1}^{B} \\frac{y_{b-1} + y_{b}}{2} \\,\\big(x_{b} - x_{b-1}\\big).\n$$\nROC曲线的顶点是 $\\{(x_b, y_b)\\}_{b=0}^B$，其中 $(x_0, y_0) = (0,0)$。点 $(x_b, y_b)$ 表示在考虑了所有分数大于或等于 $S_b$ 的实例后，累积的假正例率（FPR）和真正例率（TPR）。\n第 $b$ 个梯形的宽度是由于块 $b$ 中的实例引起的FPR变化：\n$$\nx_b - x_{b-1} = \\frac{u_b}{m}.\n$$\n第 $b$ 个梯形的高度从 $y_{b-1}$ 变为 $y_b$。平均高度是 $\\frac{y_{b-1} + y_b}{2}$。我们可以用 $y_{b-1}$ 和块 $b$ 中正实例的数量 $t_b$ 来表示 $y_b$：\n$$\ny_b = y_{b-1} + \\frac{t_b}{n}.\n$$\n将此代入平均高度的表达式中，得到：\n$$\n\\frac{y_{b-1} + y_b}{2} = \\frac{y_{b-1} + (y_{b-1} + t_b/n)}{2} = y_{b-1} + \\frac{t_b}{2n}.\n$$\n在点 $b-1$ 处的TPR，$y_{b-1}$，是分数更高块（即块 $a=1, \\ldots, b-1$）中正实例的累积和：\n$$\ny_{b-1} = \\frac{1}{n} \\sum_{a=1}^{b-1} t_a.\n$$\n现在，我们将这些代回 $A_{\\mathrm{trap}}$ 的公式中：\n$$\nA_{\\mathrm{trap}} = \\sum_{b=1}^{B} \\left( \\frac{1}{n} \\sum_{a=1}^{b-1} t_a + \\frac{t_b}{2n} \\right) \\left( \\frac{u_b}{m} \\right).\n$$\n提出常数 $n$ 和 $m$，我们得到 $A_{\\mathrm{trap}}$ 的一个简化表达式：\n$$\nA_{\\mathrm{trap}} = \\frac{1}{nm} \\sum_{b=1}^{B} u_b \\left( \\sum_{a=1}^{b-1} t_a + \\frac{t_b}{2} \\right).\n$$\n\n接下来，我们分析曼-惠特尼估计量 $A_{\\mathrm{MW}}$。\n它通过对所有可能的一个正实例和一个负实例对进行平均来定义：\n$$\nA_{\\mathrm{MW}} \\;=\\; \\frac{1}{nm} \\sum_{i=1}^{n} \\sum_{j=1}^{m} \\left[ \\mathbf{1}\\big(s_{i}^{+} > s_{j}^{-}\\big) \\;+\\; \\frac{1}{2}\\,\\mathbf{1}\\big(s_{i}^{+} = s_{j}^{-}\\big) \\right].\n$$\n项 $\\mathbf{1}(s_i^+ > s_j^-) + \\frac{1}{2}\\mathbf{1}(s_i^+ = s_j^-)$ 可以解释为正实例 $i$ 和负实例 $j$ 分数之间比较的结果，其中正实例获胜得1分，平局得 $\\frac{1}{2}$ 分，失败得0分。\n为了简化这个表达式，我们可以改变求和顺序，并按分数块对各项进行分组。让我们首先对负实例 $j$ 求和：\n$$\nA_{\\mathrm{MW}} = \\frac{1}{m} \\sum_{j=1}^{m} \\left[ \\frac{1}{n} \\sum_{i=1}^{n} \\left( \\mathbf{1}(s_{i}^{+} > s_{j}^{-}) + \\frac{1}{2}\\mathbf{1}(s_{i}^{+} = s_{j}^{-}) \\right) \\right].\n$$\n考虑一个属于块 $b$ 的负实例 $j$。它的分数是 $s_j^- = S_b$。内部对 $i$ 的求和计算了分数 $s_i^+ > S_b$ 的正实例数量，加上分数 $s_i^+ = S_b$ 的正实例数量的一半。\n分数 $s_i^+ > S_b$ 的正实例是那些在块 $a=1, \\dots, b-1$ 中的实例。它们的总数是 $\\sum_{a=1}^{b-1} t_a$。\n分数 $s_i^+ = S_b$ 的正实例是那些在块 $b$ 中的实例。它们的数量是 $t_b$。\n因此，对于块 $b$ 中的任何负实例 $j$，内部对 $i$ 的求和的值是：\n$$\n\\sum_{i=1}^{n} \\left( \\mathbf{1}(s_{i}^{+} > S_b) + \\frac{1}{2}\\mathbf{1}(s_{i}^{+} = S_b) \\right) = \\left(\\sum_{a=1}^{b-1} t_a\\right) \\cdot 1 + t_b \\cdot \\frac{1}{2}.\n$$\n由于块 $b$ 中有 $u_b$ 个负实例，它们都具有相同的分数 $S_b$，我们可以将对 $j$ 的求和重写为对块 $b$ 的求和：\n$$\n\\sum_{j=1}^{m} \\left[ \\sum_{i=1}^{n} \\left(\\dots\\right) \\right] = \\sum_{b=1}^{B} u_b \\left( \\sum_{a=1}^{b-1} t_a + \\frac{t_b}{2} \\right).\n$$\n将此代回 $A_{\\mathrm{MW}}$ 的公式中：\n$$\nA_{\\mathrm{MW}} = \\frac{1}{nm} \\sum_{b=1}^{B} u_b \\left( \\sum_{a=1}^{b-1} t_a + \\frac{t_b}{2} \\right).\n$$\n通过比较推导出的表达式，我们发现\n$$\nA_{\\mathrm{trap}} = A_{\\mathrm{MW}} = \\frac{1}{nm} \\sum_{b=1}^{B} u_b \\left( \\sum_{a=1}^{b-1} t_a + \\frac{t_b}{2} \\right).\n$$\n这两个估计量在代数上是相同的。它们的相等性对任何分数的选择都成立，因为它只依赖于由分数决定的块计数 $\\{t_b, u_b\\}$ 及其排名顺序。\n\n因此，对于任何可能的分数分配，这两个估计量之间的差总是零：\n$$\nA_{\\mathrm{MW}} - A_{\\mathrm{trap}} = 0.\n$$\n因此，绝对差异也总是零：\n$$\n| A_{\\mathrm{MW}} - A_{\\mathrm{trap}} | = 0.\n$$\n问题要求在所有可能的分数分配上求这个量的上确界。由于该量是常数且等于 $0$，其上确界也是 $0$。\n$$\n\\sup \\left| A_{\\mathrm{MW}} \\,-\\, A_{\\mathrm{trap}} \\right| = \\sup \\{0\\} = 0.\n$$", "answer": "$$\n\\boxed{0}\n$$", "id": "3167034"}, {"introduction": "在模型评估之外，AUC本身也可以作为一个强大的优化目标，尤其是在我们更关心模型排序能力的“学习到排序”（learning-to-rank）任务中。然而，标准AUC的定义包含一个指示函数 $\\mathbf{1}\\{s_i - s_j \\gt 0\\}$，使其非连续且几乎处处梯度为零，无法直接用于基于梯度的优化算法。本练习 [@problem_id:3167109] 将引导您解决这个问题：首先推导AUC的（次）梯度，然后构造一个光滑、可微的替代函数（surrogate），并计算其梯度。掌握这一过程是理解和实现现代AUC优化算法的关键一步。", "problem": "考虑一个二元分类和学习排序场景，其中有 $n$ 个实例，由 $i \\in \\{1,\\dots,n\\}$ 索引，真实标签为 $y_i \\in \\{0,1\\}$，实值分数为 $s_i \\in \\mathbb{R}$。令 $\\mathcal{P} = \\{i: y_i = 1\\}$ 表示正例集合，其数量为 $n_{+} = |\\mathcal{P}|$；令 $\\mathcal{N} = \\{j: y_j = 0\\}$ 表示负例集合，其数量为 $n_{-} = |\\mathcal{N}|$。受试者工作特征 (ROC) 曲线的经验曲线下面积 (AUC) 定义为：对于所有正-负例对，正例分数超过负例分数的指示函数的平均值。\n\n从 Heaviside 指示函数和可微性的基本定义出发，完成以下任务：\n\n1) 从第一性原理出发，推导经验曲线下面积 (AUC) 关于分数向量 $s = (s_1,\\dots,s_n)$ 的梯度（或在适当情况下的次梯度）。AUC 的定义如下：\n$$\n\\mathrm{AUC}(s) \\equiv \\frac{1}{n_{+} n_{-}} \\sum_{i \\in \\mathcal{P}} \\sum_{j \\in \\mathcal{N}} \\mathbf{1}\\{ s_i - s_j > 0 \\}.\n$$\n明确说明该函数在何处可微，并给出 $\\nabla_{s} \\mathrm{AUC}(s)$ 的表达式，或在不可微时的次梯度。\n\n2) 为了获得一个适合优化的可微代理函数，用带有温度参数 $\\tau > 0$ 的 logistic sigmoid 函数 $\\sigma_{\\tau}(x) \\equiv \\frac{1}{1 + \\exp(-x/\\tau)}$ 替换指示函数 $\\mathbf{1}\\{x > 0\\}$，并定义平滑代理函数如下：\n$$\nA_{\\tau}(s) \\equiv \\frac{1}{n_{+} n_{-}} \\sum_{i \\in \\mathcal{P}} \\sum_{j \\in \\mathcal{N}} \\sigma_{\\tau}(s_i - s_j).\n$$\n推导梯度 $\\nabla_{s} A_{\\tau}(s)$ 的精确解析表达式。\n\n3) 考虑一个具体案例：$n = 4$，标签 $y = (1, 0, 1, 0)$，因此 $\\mathcal{P} = \\{1, 3\\}$ 且 $\\mathcal{N} = \\{2, 4\\}$，分数向量 $s = (1.2, 0.8, 0.5, 0.3)$，温度 $\\tau = 1$，方向向量 $v = (1, -2, 0.5, 3)$。计算平滑代理函数在点 $s$ 沿方向 $v$ 的方向导数，即：\n$$\nD A_{\\tau}(s)[v] \\equiv \\nabla_{s} A_{\\tau}(s)^{\\top} v,\n$$\n以实数形式给出结果。将您的最终数值结果四舍五入到四位有效数字。将您的答案表示为一个无单位的实数。", "solution": "该问题经评估具有科学依据、是良定的，并包含得出唯一解所需的所有信息。各步骤逻辑一致，且与统计学习中的标准概念相关。因此，该问题是有效的。\n\n解答按要求分为三部分呈现。\n\n### 第1部分：经验AUC的梯度\n\n经验曲线下面积 (AUC) 由下式给出：\n$$\n\\mathrm{AUC}(s) = \\frac{1}{n_{+} n_{-}} \\sum_{i \\in \\mathcal{P}} \\sum_{j \\in \\mathcal{N}} \\mathbf{1}\\{ s_i - s_j > 0 \\}\n$$\n其中 $\\mathbf{1}\\{\\cdot\\}$ 是指示函数，可以使用 Heaviside 阶跃函数 $H(x)$ 定义为 $\\mathbf{1}\\{x > 0\\} \\equiv H(x)$。函数 $H(x)$ 在 $x > 0$ 时为 1，在 $x \\leq 0$ 时为 0。函数 $\\mathrm{AUC}(s)$ 是这些阶跃函数的和，因此是分段常数函数。\n\n对于所有满足 $i \\in \\mathcal{P}$ 和 $j \\in \\mathcal{N}$ 的配对 $(i, j)$，只要 $s_i \\neq s_j$，函数就在点 $s$ 可微。在这些点上，对任何分数 $s_k$ 的微小扰动都不会改变任何指示函数的值，因此函数是局部恒定的。所以梯度是零向量：\n$$\n\\nabla_{s} \\mathrm{AUC}(s) = \\mathbf{0} \\quad \\text{if } s_i \\neq s_j \\text{ for all } i \\in \\mathcal{P}, j \\in \\mathcal{N}.\n$$\n当一个或多个正例的分数与负例的分数相等时，即对于某些 $i \\in \\mathcal{P}, j \\in \\mathcal{N}$ 有 $s_i = s_j$ 时，函数在这些点上是不可微的。在这些点上，需要使用次梯度或广义梯度的概念。\n\n在分布意义上，Heaviside 阶跃函数 $H(x)$ 的导数是 Dirac delta 函数 $\\delta(x)$。我们用它来定义一个广义梯度。$\\mathrm{AUC}(s)$ 关于分数向量 $s$ 的梯度是一个向量，其第 $k$ 个分量是偏导数 $\\frac{\\partial}{\\partial s_k} \\mathrm{AUC}(s)$。\n\n为了找到梯度的第 $k$ 个分量，我们对和式逐项求导：\n$$\n\\frac{\\partial}{\\partial s_k} \\mathrm{AUC}(s) = \\frac{1}{n_{+} n_{-}} \\sum_{i \\in \\mathcal{P}} \\sum_{j \\in \\mathcal{N}} \\frac{\\partial}{\\partial s_k} H(s_i - s_j)\n$$\n使用链式法则，$\\frac{\\partial}{\\partial s_k} H(s_i - s_j) = \\delta(s_i - s_j) \\frac{\\partial}{\\partial s_k}(s_i - s_j)$。项 $\\frac{\\partial}{\\partial s_k}(s_i - s_j)$ 在 $k=i$ 时为 $1$，在 $k=j$ 时为 $-1$，否则为 $0$。\n\n我们考虑索引 $k$ 的两种情况：\n\n情况1：$k \\in \\mathcal{P}$（第 $k$ 个实例是正例）。\n仅当 $i=k$ 时，导数 $\\frac{\\partial}{\\partial s_k}(s_i - s_j)$ 才非零。\n$$\n\\frac{\\partial \\mathrm{AUC}(s)}{\\partial s_k} = \\frac{1}{n_{+} n_{-}} \\sum_{j \\in \\mathcal{N}} \\delta(s_k - s_j) \\cdot (1) = \\frac{1}{n_{+} n_{-}} \\sum_{j \\in \\mathcal{N}} \\delta(s_k - s_j)\n$$\n\n情况2：$k \\in \\mathcal{N}$（第 $k$ 个实例是负例）。\n仅当 $j=k$ 时，导数 $\\frac{\\partial}{\\partial s_k}(s_i - s_j)$ 才非零。\n$$\n\\frac{\\partial \\mathrm{AUC}(s)}{\\partial s_k} = \\frac{1}{n_{+} n_{-}} \\sum_{i \\in \\mathcal{P}} \\delta(s_i - s_k) \\cdot (-1) = -\\frac{1}{n_{+} n_{-}} \\sum_{i \\in \\mathcal{P}} \\delta(s_i - s_k)\n$$\n这些表达式定义了广义梯度 $\\nabla_{s} \\mathrm{AUC}(s)$ 的分量。在可微处（即没有 $s_i=s_j$ 的情况），delta 函数的参数都非零，使得梯度为零向量，这与我们之前的观察一致。\n\n### 第2部分：平滑代理函数的梯度\n\nAUC 的平滑代理函数定义为：\n$$\nA_{\\tau}(s) = \\frac{1}{n_{+} n_{-}} \\sum_{i \\in \\mathcal{P}} \\sum_{j \\in \\mathcal{N}} \\sigma_{\\tau}(s_i - s_j)\n$$\n其中 logistic sigmoid 函数为 $\\sigma_{\\tau}(x) = \\frac{1}{1 + \\exp(-x/\\tau)}$。由于当 $\\tau > 0$ 时 $\\sigma_{\\tau}(x)$ 是一个平滑函数，所以 $A_{\\tau}(s)$ 也是平滑的，其梯度处处有定义。\n\n首先，我们推导 sigmoid 函数关于其参数 $x$ 的导数：\n\\begin{align*}\n\\frac{d}{dx} \\sigma_{\\tau}(x) &= \\frac{d}{dx} \\left(1 + \\exp(-x/\\tau)\\right)^{-1} \\\\\n&= -1 \\cdot \\left(1 + \\exp(-x/\\tau)\\right)^{-2} \\cdot \\left(\\exp(-x/\\tau) \\cdot \\left(-\\frac{1}{\\tau}\\right)\\right) \\\\\n&= \\frac{1}{\\tau} \\frac{\\exp(-x/\\tau)}{\\left(1 + \\exp(-x/\\tau)\\right)^2} \\\\\n&= \\frac{1}{\\tau} \\left(\\frac{1}{1 + \\exp(-x/\\tau)}\\right) \\left(\\frac{\\exp(-x/\\tau)}{1 + \\exp(-x/\\tau)}\\right) \\\\\n&= \\frac{1}{\\tau} \\sigma_{\\tau}(x) \\left(\\frac{1 + \\exp(-x/\\tau) - 1}{1 + \\exp(-x/\\tau)}\\right) \\\\\n&= \\frac{1}{\\tau} \\sigma_{\\tau}(x) \\left(1 - \\frac{1}{1 + \\exp(-x/\\tau)}\\right) \\\\\n&= \\frac{1}{\\tau} \\sigma_{\\tau}(x) \\left(1 - \\sigma_{\\tau}(x)\\right)\n\\end{align*}\n我们将这个导数记为 $\\sigma'_{\\tau}(x)$。为了找到梯度 $\\nabla_{s} A_{\\tau}(s)$ 的第 $k$ 个分量，我们求导：\n$$\n\\frac{\\partial A_{\\tau}(s)}{\\partial s_k} = \\frac{1}{n_{+} n_{-}} \\sum_{i \\in \\mathcal{P}} \\sum_{j \\in \\mathcal{N}} \\frac{\\partial}{\\partial s_k} \\sigma_{\\tau}(s_i - s_j)\n$$\n应用链式法则：\n$$\n\\frac{\\partial}{\\partial s_k} \\sigma_{\\tau}(s_i - s_j) = \\sigma'_{\\tau}(s_i - s_j) \\cdot \\frac{\\partial}{\\partial s_k}(s_i - s_j)\n$$\n和之前一样，我们考虑索引 $k$ 的两种情况：\n\n情况1：$k \\in \\mathcal{P}$\n$$\n\\frac{\\partial A_{\\tau}(s)}{\\partial s_k} = \\frac{1}{n_{+} n_{-}} \\sum_{j \\in \\mathcal{N}} \\sigma'_{\\tau}(s_k - s_j) = \\frac{1}{\\tau n_{+} n_{-}} \\sum_{j \\in \\mathcal{N}} \\sigma_{\\tau}(s_k - s_j) (1 - \\sigma_{\\tau}(s_k - s_j))\n$$\n\n情况2：$k \\in \\mathcal{N}$\n$$\n\\frac{\\partial A_{\\tau}(s)}{\\partial s_k} = \\frac{1}{n_{+} n_{-}} \\sum_{i \\in \\mathcal{P}} \\sigma'_{\\tau}(s_i - s_k) \\cdot (-1) = -\\frac{1}{\\tau n_{+} n_{-}} \\sum_{i \\in \\mathcal{P}} \\sigma_{\\tau}(s_i - s_k) (1 - \\sigma_{\\tau}(s_i - s_k))\n$$\n这些表达式给出了梯度向量 $\\nabla_{s} A_{\\tau}(s)$ 每个分量的精确解析公式。\n\n### 第3部分：方向导数计算\n\n我们需要计算方向导数 $D A_{\\tau}(s)[v] = \\nabla_{s} A_{\\tau}(s)^{\\top} v$。给定的参数如下：\n- 标签 $y = (1, 0, 1, 0)$，因此 $\\mathcal{P} = \\{1, 3\\}$ 且 $\\mathcal{N} = \\{2, 4\\}$。\n- $n_{+} = 2$, $n_{-} = 2$。\n- 分数 $s = (s_1, s_2, s_3, s_4) = (1.2, 0.8, 0.5, 0.3)$。\n- 温度 $\\tau = 1$。sigmoid 函数为 $\\sigma_{1}(x) = (1 + \\exp(-x))^{-1}$。\n- 方向向量 $v = (v_1, v_2, v_3, v_4) = (1, -2, 0.5, 3)$。\n\n梯度分量由第2部分的公式给出，其前置因子为 $\\frac{1}{\\tau n_{+} n_{-}} = \\frac{1}{1 \\cdot 2 \\cdot 2} = \\frac{1}{4}$。令 $\\sigma'(x) = \\sigma_1(x)(1-\\sigma_1(x))$。\n\n梯度分量为：\n- 对于 $k=1 \\in \\mathcal{P}$: $\\frac{\\partial A_1}{\\partial s_1} = \\frac{1}{4} \\left( \\sigma'(s_1-s_2) + \\sigma'(s_1-s_4) \\right)$\n- 对于 $k=3 \\in \\mathcal{P}$: $\\frac{\\partial A_1}{\\partial s_3} = \\frac{1}{4} \\left( \\sigma'(s_3-s_2) + \\sigma'(s_3-s_4) \\right)$\n- 对于 $k=2 \\in \\mathcal{N}$: $\\frac{\\partial A_1}{\\partial s_2} = -\\frac{1}{4} \\left( \\sigma'(s_1-s_2) + \\sigma'(s_3-s_2) \\right)$\n- 对于 $k=4 \\in \\mathcal{N}$: $\\frac{\\partial A_1}{\\partial s_4} = -\\frac{1}{4} \\left( \\sigma'(s_1-s_4) + \\sigma'(s_3-s_4) \\right)$\n\n分数差为：\n- $s_1 - s_2 = 1.2 - 0.8 = 0.4$\n- $s_1 - s_4 = 1.2 - 0.3 = 0.9$\n- $s_3 - s_2 = 0.5 - 0.8 = -0.3$\n- $s_3 - s_4 = 0.5 - 0.3 = 0.2$\n\n$\\sigma'(x)$ 的值为：\n- $\\sigma'(0.4) = \\sigma_1(0.4)(1-\\sigma_1(0.4)) \\approx 0.598688(1 - 0.598688) \\approx 0.240260$\n- $\\sigma'(0.9) = \\sigma_1(0.9)(1-\\sigma_1(0.9)) \\approx 0.710950(1 - 0.710950) \\approx 0.205504$\n- $\\sigma'(-0.3) = \\sigma_1(-0.3)(1-\\sigma_1(-0.3)) \\approx 0.425557(1 - 0.425557) \\approx 0.244460$\n- $\\sigma'(0.2) = \\sigma_1(0.2)(1-\\sigma_1(0.2)) \\approx 0.549834(1 - 0.549834) \\approx 0.247525$\n\n方向导数是点积：\n$D A_1(s)[v] = \\sum_{k=1}^{4} \\frac{\\partial A_1}{\\partial s_k} v_k$。\n$$\nD A_1(s)[v] = \\frac{\\partial A_1}{\\partial s_1} v_1 + \\frac{\\partial A_1}{\\partial s_2} v_2 + \\frac{\\partial A_1}{\\partial s_3} v_3 + \\frac{\\partial A_1}{\\partial s_4} v_4\n$$\n$$\n= \\frac{1}{4} \\left( \\sigma'(0.4) + \\sigma'(0.9) \\right) \\cdot (1) \\\\\n- \\frac{1}{4} \\left( \\sigma'(0.4) + \\sigma'(-0.3) \\right) \\cdot (-2) \\\\\n+ \\frac{1}{4} \\left( \\sigma'(-0.3) + \\sigma'(0.2) \\right) \\cdot (0.5) \\\\\n- \\frac{1}{4} \\left( \\sigma'(0.9) + \\sigma'(0.2) \\right) \\cdot (3)\n$$\n我们可以提取公因式 $\\frac{1}{4}$，并按 $\\sigma'$ 的值对各项进行分组：\n$$\n= \\frac{1}{4} \\left[ \\sigma'(0.4)(1+2) + \\sigma'(0.9)(1-3) + \\sigma'(-0.3)(2+0.5) + \\sigma'(0.2)(0.5-3) \\right]\n$$\n$$\n= \\frac{1}{4} \\left[ 3 \\sigma'(0.4) - 2 \\sigma'(0.9) + 2.5 \\sigma'(-0.3) - 2.5 \\sigma'(0.2) \\right]\n$$\n代入数值：\n$$\n\\approx \\frac{1}{4} \\left[ 3(0.240260) - 2(0.205504) + 2.5(0.244460) - 2.5(0.247525) \\right]\n$$\n$$\n= \\frac{1}{4} \\left[ 0.72078 - 0.411008 + 0.61115 - 0.6188125 \\right]\n$$\n$$\n= \\frac{1}{4} \\left[ 0.3021095 \\right] \\approx 0.075527375\n$$\n四舍五入到四位有效数字，我们得到 $0.07553$。", "answer": "$$\n\\boxed{0.07553}\n$$", "id": "3167109"}]}