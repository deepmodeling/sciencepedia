{"hands_on_practices": [{"introduction": "混淆矩阵是评估分类模型性能的基石。这个练习将带你亲手完成一个完整的流程：从应用一个已训练好的分类器（高斯朴素贝叶斯）进行预测，到根据预测结果和真实标签，一步步构建出一个多类别混淆矩阵。通过这个实践，你将深刻理解混淆矩阵中每个单元格的数字是如何从原始数据中产生的。[@problem_id:1423429]", "problem": "一位系统生物学家正在开发一个模型，用于将单细胞分类到三个不同的细胞周期阶段之一：阶段1 (P1)、阶段2 (P2) 和阶段3 (P3)。该分类基于两个关键调控基因（基因A和基因B）的归一化表达水平。\n\n此任务选用了高斯朴素贝叶斯分类器。该模型假设，对于给定的细胞周期阶段，基因A和基因B的表达水平是条件独立的。它还假设，在每个阶段内，每个基因的表达水平都服从正态（高斯）分布。\n\n从一个大型的预分类细胞数据集中，得出了以下训练数据的统计摘要：\n- 训练细胞总数为1000个。各阶段的细胞计数为：P1阶段400个细胞，P2阶段350个细胞，P3阶段250个细胞。\n- 下表给出了每个阶段中每个基因的归一化表达水平的均值（$\\mu$）和标准差（$\\sigma$）。表达水平是无量纲量。\n\n| 阶段 | 基因 A ($\\mu_A, \\sigma_A$) | 基因 B ($\\mu_B, \\sigma_B$) |\n|---|---|---|\n| P1 | (5.0, 1.0) | (4.0, 1.2) |\n| P2 | (8.0, 1.5) | (6.0, 1.0) |\n| P3 | (6.0, 1.2) | (9.0, 1.5) |\n\n为了评估分类器的性能，收集了一组新的包含6个已知真实阶段的测试细胞。它们的基因表达水平和真实阶段如下：\n\n| 细胞ID | 基因 A 表达量 | 基因 B 表达量 | 真实阶段 |\n|---|---|---|---|\n| S1 | 5.5 | 4.5 | P1 |\n| S2 | 7.5 | 5.8 | P2 |\n| S3 | 6.2 | 8.5 | P3 |\n| S4 | 4.8 | 6.5 | P1 |\n| S5 | 8.5 | 8.8 | P2 |\n| S6 | 7.0 | 7.0 | P3 |\n\n对于每个测试细胞，使用训练好的高斯朴素贝叶斯分类器确定其预测阶段。然后，构建该分类器在此测试集上性能的混淆矩阵。混淆矩阵应为一个3x3矩阵，其中行代表真实阶段（按P1、P2、P3的顺序），列代表预测阶段（按P1、P2、P3的顺序）。\n\n请按行顺序列出混淆矩阵的9个整数元素作为最终答案。也就是说，先提供（真实P1，预测P1）的元素，然后是（真实P1，预测P2）、（真实P1，预测P3），接着是（真实P2，预测P1），依此类推。", "solution": "我们使用高斯朴素贝叶斯分类器对类条件密度进行建模。设类别标签为 $c \\in \\{\\text{P1}, \\text{P2}, \\text{P3}\\}$，特征为基因A和基因B的 $x = (x_{A}, x_{B})$。该模型假设在给定类别的情况下条件独立，并且每个基因服从单变量正态分布：\n$$\np(x \\mid c) \\;=\\; \\prod_{j \\in \\{A,B\\}} \\frac{1}{\\sigma_{c,j}\\sqrt{2\\pi}} \\exp\\!\\left(-\\frac{(x_{j}-\\mu_{c,j})^{2}}{2\\sigma_{c,j}^{2}}\\right).\n$$\n由计数得出的类别先验概率为\n$$\n\\pi_{\\text{P1}}=\\frac{400}{1000}=0.4,\\quad \\pi_{\\text{P2}}=\\frac{350}{1000}=0.35,\\quad \\pi_{\\text{P3}}=\\frac{250}{1000}=0.25.\n$$\n为了进行预测，我们比较（未归一化的）对数后验分数\n$$\ns_{c}(x) \\;=\\; \\ln \\pi_{c} \\;+\\; \\sum_{j \\in \\{A,B\\}} \\left[-\\ln \\sigma_{c,j} \\;-\\; \\frac{(x_{j}-\\mu_{c,j})^{2}}{2\\sigma_{c,j}^{2}} \\right] \\;-\\; \\sum_{j \\in \\{A,B\\}} \\ln \\sqrt{2\\pi}.\n$$\n对于固定的 $x$，最后一项 $-\\sum_{j} \\ln \\sqrt{2\\pi}$ 在所有类别中是常数，因此在求 argmax 时可以省略。定义\n$$\n\\text{base}_{c} \\;=\\; \\ln \\pi_{c} \\;-\\; \\sum_{j \\in \\{A,B\\}} \\ln \\sigma_{c,j}, \\qquad Q_{c}(x) \\;=\\; \\sum_{j \\in \\{A,B\\}} \\frac{(x_{j}-\\mu_{c,j})^{2}}{2\\sigma_{c,j}^{2}},\n$$\n因此 $s_{c}(x)=\\text{base}_{c} - Q_{c}(x)$，不计一个与 $c$ 无关的加性常数。\n\n根据表格，参数为：\n- P1: $(\\mu_{A},\\sigma_{A})=(5.0,1.0)$, $(\\mu_{B},\\sigma_{B})=(4.0,1.2)$,\n- P2: $(\\mu_{A},\\sigma_{A})=(8.0,1.5)$, $(\\mu_{B},\\sigma_{B})=(6.0,1.0)$,\n- P3: $(\\mu_{A},\\sigma_{A})=(6.0,1.2)$, $(\\mu_{B},\\sigma_{B})=(9.0,1.5)$。\n\n计算基础项：\n$$\n\\ln \\pi_{\\text{P1}} = \\ln(0.4) \\approx -0.916291,\\quad -\\sum \\ln \\sigma_{\\text{P1},j} = -\\ln 1.0 - \\ln 1.2 \\approx -0.182322,\\quad \\text{base}_{\\text{P1}} \\approx -1.098613,\n$$\n$$\n\\ln \\pi_{\\text{P2}} = \\ln(0.35) \\approx -1.049822,\\quad -\\sum \\ln \\sigma_{\\text{P2},j} = -\\ln 1.5 - \\ln 1.0 \\approx -0.405465,\\quad \\text{base}_{\\text{P2}} \\approx -1.455287,\n$$\n$$\n\\ln \\pi_{\\text{P3}} = \\ln(0.25) \\approx -1.386294,\\quad -\\sum \\ln \\sigma_{\\text{P3},j} = -\\ln 1.2 - \\ln 1.5 \\approx -0.587787,\\quad \\text{base}_{\\text{P3}} \\approx -1.974081.\n$$\n\n对于每个测试细胞 $x=(x_{A},x_{B})$，计算 $Q_{c}(x)=\\sum_{j} \\frac{(x_{j}-\\mu_{c,j})^{2}}{2\\sigma_{c,j}^{2}}$，然后计算 $s_{c}(x)=\\text{base}_{c}-Q_{c}(x)$；预测 $s_{c}(x)$ 值最大的类别。\n\nS1: $(5.5,4.5)$。\n- P1: 偏差 $(0.5,0.5)$，方差 $(1.0,1.44)$，\n$$\nQ_{\\text{P1}} = \\frac{0.5^{2}}{2\\cdot 1.0} + \\frac{0.5^{2}}{2\\cdot 1.44} = 0.125 + 0.086806 \\approx 0.211806,\\quad s_{\\text{P1}} \\approx -1.098613 - 0.211806 = -1.310419.\n$$\n- P2: 偏差 $(-2.5,-1.5)$，方差 $(2.25,1.0)$，\n$$\nQ_{\\text{P2}} = \\frac{2.5^{2}}{2\\cdot 2.25} + \\frac{1.5^{2}}{2\\cdot 1.0} = 1.388889 + 1.125 = 2.513889,\\quad s_{\\text{P2}} \\approx -1.455287 - 2.513889 = -3.969176.\n$$\n- P3: 偏差 $(-0.5,-4.5)$，方差 $(1.44,2.25)$，\n$$\nQ_{\\text{P3}} = \\frac{0.5^{2}}{2\\cdot 1.44} + \\frac{4.5^{2}}{2\\cdot 2.25} = 0.086806 + 4.5 = 4.586806,\\quad s_{\\text{P3}} \\approx -1.974081 - 4.586806 = -6.560887.\n$$\n预测：P1。\n\nS2: $(7.5,5.8)$。\n- P1: 偏差 $(2.5,1.8)$，方差 $(1.0,1.44)$，\n$$\nQ_{\\text{P1}} = \\frac{2.5^{2}}{2\\cdot 1.0} + \\frac{1.8^{2}}{2\\cdot 1.44} = 3.125 + 1.125 = 4.25,\\quad s_{\\text{P1}} \\approx -1.098613 - 4.25 = -5.348613.\n$$\n- P2: 偏差 $(-0.5,-0.2)$，方差 $(2.25,1.0)$，\n$$\nQ_{\\text{P2}} = \\frac{0.5^{2}}{2\\cdot 2.25} + \\frac{0.2^{2}}{2\\cdot 1.0} = 0.055556 + 0.02 = 0.075556,\\quad s_{\\text{P2}} \\approx -1.455287 - 0.075556 = -1.530843.\n$$\n- P3: 偏差 $(1.5,-3.2)$，方差 $(1.44,2.25)$，\n$$\nQ_{\\text{P3}} = \\frac{1.5^{2}}{2\\cdot 1.44} + \\frac{3.2^{2}}{2\\cdot 2.25} = 0.78125 + 2.275556 = 3.056806,\\quad s_{\\text{P3}} \\approx -1.974081 - 3.056806 = -5.030887.\n$$\n预测：P2。\n\nS3: $(6.2,8.5)$。\n- P1: 偏差 $(1.2,4.5)$，方差 $(1.0,1.44)$，\n$$\nQ_{\\text{P1}} = \\frac{1.2^{2}}{2\\cdot 1.0} + \\frac{4.5^{2}}{2\\cdot 1.44} = 0.72 + 7.03125 = 7.75125,\\quad s_{\\text{P1}} \\approx -1.098613 - 7.75125 = -8.849863.\n$$\n- P2: 偏差 $(-1.8,2.5)$，方差 $(2.25,1.0)$，\n$$\nQ_{\\text{P2}} = \\frac{1.8^{2}}{2\\cdot 2.25} + \\frac{2.5^{2}}{2\\cdot 1.0} = 0.72 + 3.125 = 3.845,\\quad s_{\\text{P2}} \\approx -1.455287 - 3.845 = -5.300287.\n$$\n- P3: 偏差 $(0.2,-0.5)$，方差 $(1.44,2.25)$，\n$$\nQ_{\\text{P3}} = \\frac{0.2^{2}}{2\\cdot 1.44} + \\frac{0.5^{2}}{2\\cdot 2.25} = 0.013889 + 0.055556 = 0.0694449,\\quad s_{\\text{P3}} \\approx -1.974081 - 0.0694449 = -2.043526.\n$$\n预测：P3。\n\nS4: $(4.8,6.5)$。\n- P1: 偏差 $(-0.2,2.5)$，方差 $(1.0,1.44)$，\n$$\nQ_{\\text{P1}} = \\frac{0.2^{2}}{2\\cdot 1.0} + \\frac{2.5^{2}}{2\\cdot 1.44} = 0.02 + 2.170139 = 2.190139,\\quad s_{\\text{P1}} \\approx -1.098613 - 2.190139 = -3.288752.\n$$\n- P2: 偏差 $(-3.2,0.5)$，方差 $(2.25,1.0)$，\n$$\nQ_{\\text{P2}} = \\frac{3.2^{2}}{2\\cdot 2.25} + \\frac{0.5^{2}}{2\\cdot 1.0} = 2.275556 + 0.125 = 2.400556,\\quad s_{\\text{P2}} \\approx -1.455287 - 2.400556 = -3.855843.\n$$\n- P3: 偏差 $(-1.2,-2.5)$，方差 $(1.44,2.25)$，\n$$\nQ_{\\text{P3}} = \\frac{1.2^{2}}{2\\cdot 1.44} + \\frac{2.5^{2}}{2\\cdot 2.25} = 0.5 + 1.388889 = 1.888889,\\quad s_{\\text{P3}} \\approx -1.974081 - 1.888889 = -3.862970.\n$$\n预测：P1。\n\nS5: $(8.5,8.8)$。\n- P1: 偏差 $(3.5,4.8)$，方差 $(1.0,1.44)$，\n$$\nQ_{\\text{P1}} = \\frac{3.5^{2}}{2\\cdot 1.0} + \\frac{4.8^{2}}{2\\cdot 1.44} = 6.125 + 8 = 14.125,\\quad s_{\\text{P1}} \\approx -1.098613 - 14.125 = -15.223613.\n$$\n- P2: 偏差 $(0.5,2.8)$，方差 $(2.25,1.0)$，\n$$\nQ_{\\text{P2}} = \\frac{0.5^{2}}{2\\cdot 2.25} + \\frac{2.8^{2}}{2\\cdot 1.0} = 0.055556 + 3.92 = 3.975556,\\quad s_{\\text{P2}} \\approx -1.455287 - 3.975556 = -5.430843.\n$$\n- P3: 偏差 $(2.5,-0.2)$，方差 $(1.44,2.25)$，\n$$\nQ_{\\text{P3}} = \\frac{2.5^{2}}{2\\cdot 1.44} + \\frac{0.2^{2}}{2\\cdot 2.25} = 2.170139 + 0.008889 = 2.179028,\\quad s_{\\text{P3}} \\approx -1.974081 - 2.179028 = -4.153109.\n$$\n预测：P3。\n\nS6: $(7.0,7.0)$。\n- P1: 偏差 $(2.0,3.0)$，方差 $(1.0,1.44)$，\n$$\nQ_{\\text{P1}} = \\frac{2.0^{2}}{2\\cdot 1.0} + \\frac{3.0^{2}}{2\\cdot 1.44} = 2 + 3.125 = 5.125,\\quad s_{\\text{P1}} \\approx -1.098613 - 5.125 = -6.223613.\n$$\n- P2: 偏差 $(-1.0,1.0)$，方差 $(2.25,1.0)$，\n$$\nQ_{\\text{P2}} = \\frac{1.0^{2}}{2\\cdot 2.25} + \\frac{1.0^{2}}{2\\cdot 1.0} = 0.222222 + 0.5 = 0.722222,\\quad s_{\\text{P2}} \\approx -1.455287 - 0.722222 = -2.177509.\n$$\n- P3: 偏差 $(1.0,-2.0)$，方差 $(1.44,2.25)$，\n$$\nQ_{\\text{P3}} = \\frac{1.0^{2}}{2\\cdot 1.44} + \\frac{2.0^{2}}{2\\cdot 2.25} = 0.347222 + 0.888889 = 1.236111,\\quad s_{\\text{P3}} \\approx -1.974081 - 1.236111 = -3.210192.\n$$\n预测：P2。\n\n预测标签：\n- S1：P1；S4：P1（两者的真实阶段均为P1），\n- S2：P2；S5：P3（真实阶段为P2，其中一个预测正确，一个被误分类为P3），\n- S3：P3；S6：P2（真实阶段为P3，其中一个预测正确，一个被误分类为P2）。\n\n构建混淆矩阵，行代表真实阶段（P1, P2, P3），列代表预测阶段（P1, P2, P3）。计数：\n- 真实P1：预测为P1两次，P2零次，P3零次 → $(2,0,0)$。\n- 真实P2：预测为P1零次，P2一次，P3一次 → $(0,1,1)$。\n- 真实P3：预测为P1零次，P2一次，P3一次 → $(0,1,1)$。\n\n按行顺序列出，这9个元素是 $2, 0, 0, 0, 1, 1, 0, 1, 1$。", "answer": "$$\\boxed{\\begin{pmatrix}2 & 0 & 0 & 0 & 1 & 1 & 0 & 1 & 1\\end{pmatrix}}$$", "id": "1423429"}, {"introduction": "一个模型的性能在不同数据集上会发生变化，尤其是在类别分布不一致时。这个练习将向你展示如何利用混淆矩阵中的内在性能指标——真正例率(True Positive Rate, $TPR$)和假正例率(False Positive Rate, $FPR$)——来预测模型在全新数据分布下的表现。你将学会区分依赖于类别分布的指标（如精确率和$F_1$分数）和相对不变的指标，并利用后者进行推断，这是一项非常实用的技能。[@problem_id:2389108]", "problem": "一个二元分类器被训练用于识别一个蛋白质是膜蛋白（正类）还是可溶性蛋白（负类）。在一个包含 $2000$ 个蛋白质的精选验证集上，有 $1000$ 个膜蛋白和 $1000$ 个可溶性蛋白。该模型在此验证集上的混淆矩阵如下：\n- 真阳性 (TP): $720$\n- 假阴性 (FN): $280$\n- 假阳性 (FP): $180$\n- 真阴性 (TN): $820$\n\n假设当应用于一个新的蛋白质组时，该分类器的真阳性率和假阳性率保持不变。在这个新的蛋白质组中，膜蛋白的真实比例是 $0.30$。\n\n在这些假设下，该分类器在新的蛋白质组上对膜蛋白类的预期F1分数是多少？将您的答案四舍五入到四位有效数字。", "solution": "F1分数是精确率 ($P$) 和召回率 ($R$) 的调和平均数。\n$$ F1 = 2 \\cdot \\frac{P \\cdot R}{P + R} $$\n为了找到新蛋白质组上的预期F1分数，我们必须首先从验证集中确定分类器的内在性能特征，然后用这些特征来计算新场景下的预期精确率和召回率。\n\n首先，我们根据验证集数据计算真阳性率 (TPR)，也称为召回率或灵敏度，以及假阳性率 (FPR)。\n实际正例（膜蛋白）的数量是 $N_P = TP + FN = 720 + 280 = 1000$。\n实际负例（可溶性蛋白）的数量是 $N_N = FP + TN = 180 + 820 = 1000$。\n\n真阳性率是实际正例中被正确分类的比例。\n$$ TPR = \\frac{TP}{N_P} = \\frac{720}{1000} = 0.72 $$\n假阳性率是实际负例中被错误分类的比例。\n$$ FPR = \\frac{FP}{N_N} = \\frac{180}{1000} = 0.18 $$\n问题陈述指出，对于该分类器，这些比率是恒定的。\n\n现在，我们考虑新的蛋白质组，其中膜蛋白的流行度给定为 $p = P(\\text{正例}) = 0.30$。因此，可溶性蛋白的流行度为 $1 - p = P(\\text{负例}) = 0.70$。\n\n我们需要为这个新的分布计算预期的精确率和召回率。根据定义，新蛋白质组中的召回率 $R_{new}$ 等于TPR，而TPR被假设为恒定不变。\n$$ R_{new} = TPR = 0.72 $$\n\n精确率是预测为正例中实际为正例的比例。精确率依赖于类别流行度。让我们将新蛋白质组中混淆矩阵的各组成部分表示为总体的比例：$TP_{new\\_prop}$、$FP_{new\\_prop}$ 等。\n\n预期真阳性的比例是一个蛋白质为正例“并且”被分类为正例的概率。\n$$ TP_{new\\_prop} = P(\\text{预测为正} \\cap \\text{实际为正}) = P(\\text{预测为正} | \\text{实际为正}) \\cdot P(\\text{实际为正}) = TPR \\cdot p $$\n$$ TP_{new\\_prop} = 0.72 \\cdot 0.30 = 0.216 $$\n\n预期假阳性的比例是一个蛋白质为负例“但是”被分类为正例的概率。\n$$ FP_{new\\_prop} = P(\\text{预测为正} \\cap \\text{实际为负}) = P(\\text{预测为正} | \\text{实际为负}) \\cdot P(\\text{实际为负}) = FPR \\cdot (1-p) $$\n$$ FP_{new\\_prop} = 0.18 \\cdot (1 - 0.30) = 0.18 \\cdot 0.70 = 0.126 $$\n\n新蛋白质组中的精确率 $P_{new}$ 是预期真阳性与总预期预测阳性的比率。\n$$ P_{new} = \\frac{TP_{new\\_prop}}{TP_{new\\_prop} + FP_{new\\_prop}} = \\frac{0.216}{0.216 + 0.126} = \\frac{0.216}{0.342} $$\n为了保持精度，我们可以将其表示为分数：$\\frac{216}{342}$。两个数都可以被 $18$ 整除。$216 = 18 \\cdot 12$ 并且 $342 = 18 \\cdot 19$。\n$$ P_{new} = \\frac{12}{19} $$\n\n现在我们可以使用 $P_{new} = \\frac{12}{19}$ 和 $R_{new} = 0.72 = \\frac{72}{100} = \\frac{18}{25}$ 来计算新蛋白质组的F1分数 $F1_{new}$。\n$$ F1_{new} = 2 \\cdot \\frac{P_{new} \\cdot R_{new}}{P_{new} + R_{new}} = 2 \\cdot \\frac{\\frac{12}{19} \\cdot \\frac{18}{25}}{\\frac{12}{19} + \\frac{18}{25}} $$\n$$ F1_{new} = 2 \\cdot \\frac{\\frac{216}{475}}{\\frac{12 \\cdot 25 + 18 \\cdot 19}{19 \\cdot 25}} = 2 \\cdot \\frac{\\frac{216}{475}}{\\frac{300 + 342}{475}} = 2 \\cdot \\frac{216}{642} $$\n$$ F1_{new} = \\frac{432}{642} $$\n通过将分子和分母除以它们的最大公约数 $6$ 来简化分数：\n$$ F1_{new} = \\frac{72}{107} $$\n最后，我们按要求将这个精确的分数转换为小数，并四舍五入到四位有效数字。\n$$ F1_{new} = \\frac{72}{107} \\approx 0.67289719... $$\n四舍五入到四位有效数字得到 $0.6729$。", "answer": "$$\\boxed{0.6729}$$", "id": "2389108"}, {"introduction": "在处理类别不平衡的数据时，单一的评估指标（如总体准确率）可能会产生误导。这个高级练习旨在探讨不同评估指标（总体准确率 vs. 平衡准确率）之间的权衡，并揭示为什么优化一个指标可能会损害另一个。通过分析这个案例，你将学会根据具体的应用场景和不同类型错误的代价，来批判性地选择最合适的评估指标，从而做出更明智的模型评估决策。[@problem_id:3181064]", "problem": "考虑一个二元分类任务，其数据集大小为 $N = 1000$，高度不平衡，包含 $100$ 个正例和 $900$ 个负例。两个分类器，记为 $\\mathcal{A}$ 和 $\\mathcal{B}$，在该数据集上进行评估，并产生以下混淆矩阵（条目为实例计数）：对于 $\\mathcal{A}$，$\\mathrm{TP} = 20$，$\\mathrm{FN} = 80$，$\\mathrm{TN} = 891$，$\\mathrm{FP} = 9$；对于 $\\mathcal{B}$，$\\mathrm{TP} = 80$，$\\mathrm{FN} = 20$，$\\mathrm{TN} = 810$，$\\mathrm{FP} = 90$。仅使用混淆矩阵各项数量的核心定义及其衍生的标准率，从第一性原理出发，推断每个分类器优化了哪个指标，并判断选择一个优化按类别平均的度量的分类器是否会降低按流行度加权的总体准确率。然后，基于该推理，从以下选项中选择所有正确的陈述。不要假设任何未说明的公式；您的答案应基于混淆矩阵所隐含的计数和率的定义。\n\nA. 分类器 $\\mathcal{A}$ 的总体准确率高于分类器 $\\mathcal{B}$，但平衡准确率低于分类器 $\\mathcal{B}$；这种模式可能出现在不平衡数据中，因为按类别平均同等对待少数类和多数类。\n\nB. 分类器 $\\mathcal{B}$ 的总体准确率和平衡准确率都高于分类器 $\\mathcal{A}$；优化按类别平均的度量会降低总体准确率的现象不可能发生。\n\nC. 当类别先验高度不平衡且少数类和多数类中的错误被认为同等重要时，或者当少数类的召回率是主要目标时，优化平衡准确率是可取的，因为按类别平均可以抵消流行度的主导作用。\n\nD. 当目标是在同等的单实例错分成本下最小化总错误数时，优化平衡准确率是不可取的，因为总体准确率已经按流行度对类别进行了加权。\n\nE. 如果两个分类器具有相同的平衡准确率，那么无论类别是否不平衡，它们也必须具有相同的总体准确率。", "solution": "### 推导与选项分析\n\n我们将为两个分类器从第一性原理推导出相关指标。核心指标是真阳性率（TPR）、真阴性率（TNR）、总体准确率（ACC）和平衡准确率（BA）。设 $P$ 为正例数量，$N_{neg}$ 为负例数量。\n\n- **真阳性率（TPR）** 或 **召回率（Recall）**：$\\mathrm{TPR} = \\frac{\\mathrm{TP}}{P} = \\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FN}}$\n- **真阴性率（TNR）** 或 **特异度（Specificity）**：$\\mathrm{TNR} = \\frac{\\mathrm{TN}}{N_{neg}} = \\frac{\\mathrm{TN}}{\\mathrm{TN} + \\mathrm{FP}}$\n- **总体准确率（ACC）**：$\\mathrm{ACC} = \\frac{\\mathrm{TP} + \\mathrm{TN}}{P + N_{neg}}$\n- **平衡准确率（BA）**：$\\mathrm{BA} = \\frac{\\mathrm{TPR} + \\mathrm{TNR}}{2}$\n\n给定数据集有 $P=100$ 和 $N_{neg}=900$。\n\n**分类器 $\\mathcal{A}$ 的计算：**\n- $\\mathrm{TPR}_{\\mathcal{A}} = \\frac{\\mathrm{TP}_{\\mathcal{A}}}{P} = \\frac{20}{100} = 0.2$\n- $\\mathrm{TNR}_{\\mathcal{A}} = \\frac{\\mathrm{TN}_{\\mathcal{A}}}{N_{neg}} = \\frac{891}{900} = 0.99$\n- $\\mathrm{ACC}_{\\mathcal{A}} = \\frac{\\mathrm{TP}_{\\mathcal{A}} + \\mathrm{TN}_{\\mathcal{A}}}{P + N_{neg}} = \\frac{20 + 891}{1000} = \\frac{911}{1000} = 0.911$\n- $\\mathrm{BA}_{\\mathcal{A}} = \\frac{\\mathrm{TPR}_{\\mathcal{A}} + \\mathrm{TNR}_{\\mathcal{A}}}{2} = \\frac{0.2 + 0.99}{2} = \\frac{1.19}{2} = 0.595$\n\n**分类器 $\\mathcal{B}$ 的计算：**\n- $\\mathrm{TPR}_{\\mathcal{B}} = \\frac{\\mathrm{TP}_{\\mathcal{B}}}{P} = \\frac{80}{100} = 0.8$\n- $\\mathrm{TNR}_{\\mathcal{B}} = \\frac{\\mathrm{TN}_{\\mathcal{B}}}{N_{neg}} = \\frac{810}{900} = 0.90$\n- $\\mathrm{ACC}_{\\mathcal{B}} = \\frac{\\mathrm{TP}_{\\mathcal{B}} + \\mathrm{TN}_{\\mathcal{B}}}{P + N_{neg}} = \\frac{80 + 810}{1000} = \\frac{890}{1000} = 0.890$\n- $\\mathrm{BA}_{\\mathcal{B}} = \\frac{\\mathrm{TPR}_{\\mathcal{B}} + \\mathrm{TNR}_{\\mathcal{B}}}{2} = \\frac{0.8 + 0.9}{2} = \\frac{1.7}{2} = 0.85$\n\n**比较：**\n- 总体准确率：$\\mathrm{ACC}_{\\mathcal{A}} (0.911) > \\mathrm{ACC}_{\\mathcal{B}} (0.890)$\n- 平衡准确率：$\\mathrm{BA}_{\\mathcal{A}} (0.595) < \\mathrm{BA}_{\\mathcal{B}} (0.85)$\n\n分类器 $\\mathcal{A}$ 偏向于在多数（负）类上的性能，以极低的 $\\mathrm{TPR}_{\\mathcal{A}}$（0.2）为代价，实现了非常高的 $\\mathrm{TNR}_{\\mathcal{A}}$（0.99）。由于负类的高流行度（$90\\%$），该策略最大化了总体准确率。分类器 $\\mathcal{B}$ 在各个类别上表现更均衡，实现了较高的 $\\mathrm{TPR}_{\\mathcal{B}}$（$0.8$）和 $\\mathrm{TNR}_{\\mathcal{B}}$（$0.9$），从而获得了高得多的平衡准确率，但总体准确率略低。\n\n现在，我们评估每个选项。\n\n**A. 分类器 $\\mathcal{A}$ 的总体准确率高于分类器 $\\mathcal{B}$，但平衡准确率低于分类器 $\\mathcal{B}$；这种模式可能出现在不平衡数据中，因为按类别平均同等对待少数类和多数类。**\n- 第一个子句“分类器 $\\mathcal{A}$ 的总体准确率高于分类器 $\\mathcal{B}$，但平衡准确率低于分类器 $\\mathcal{B}$”由我们的计算证实（ACC 为 $0.911 > 0.890$，BA 为 $0.595 < 0.85$）。\n- 所提供的理由是“按类别平均同等对待少数类和多数类”。平衡准确率是各类别准确率（TPR 和 TNR）的算术平均值，给予每个类别 $1/2$ 的权重。总体准确率可以表示为加权平均值：$\\mathrm{ACC} = \\pi_P \\cdot \\mathrm{TPR} + \\pi_{N_{neg}} \\cdot \\mathrm{TNR}$，其中 $\\pi_P = P/(P+N_{neg}) = 0.1$ 和 $\\pi_{N_{neg}} = N_{neg}/(P+N_{neg}) = 0.9$ 是类别流行度。负类的高流行度 $\\pi_{N_{neg}}=0.9$ 意味着总体准确率主要由 TNR 主导。平衡准确率的均等加权抵消了这一点。该陈述完全正确。\n- 结论：**正确**。\n\n**B. 分类器 $\\mathcal{B}$ 的总体准确率和平衡准确率都高于分类器 $\\mathcal{A}$；优化按类别平均的度量会降低总体准确率的现象不可能发生。**\n- 第一个子句“分类器 $\\mathcal{B}$ 的总体准确率更高”是错误的，因为 $\\mathrm{ACC}_{\\mathcal{B}} = 0.890 < \\mathrm{ACC}_{\\mathcal{A}} = 0.911$。\n- 第二个子句“优化按类别平均的度量会降低总体准确率的现象不可能发生”也是错误的。这个问题本身就提供了一个反例：分类器 $\\mathcal{B}$ 的平衡准确率显著高于分类器 $\\mathcal{A}$，但总体准确率却更低。选择 $\\mathcal{B}$ 而非 $\\mathcal{A}$（即优化 BA）会降低 ACC。\n- 结论：**不正确**。\n\n**C. 当类别先验高度不平衡且少数类和多数类中的错误被认为同等重要时，或者当少数类的召回率是主要目标时，优化平衡准确率是可取的，因为按类别平均可以抵消流行度的主导作用。**\n- 这是一个关于平衡准确率效用的概念性陈述。当类别先验不平衡时，模型可以通过简单地预测多数类来获得高总体准确率。如果两个类别中的错误“同等重要”，那么一个按流行度加权类别性能的指标（如总体准确率）是不合适的。平衡准确率给予每个类别的性能相同的权重，满足了这一需求。此外，为了获得高平衡准确率，分类器不能有非常低的 TPR（少数类召回率），这使得在少数类召回率很重要时，它成为一个合适的目标。这种行为的原因被正确地识别为“按类别平均抵消了流行度的主导作用”。该陈述清晰准确地描述了使用平衡准确率的动机。\n- 结论：**正确**。\n\n**D. 当目标是在同等的单实例错分成本下最小化总错误数时，优化平衡准确率是不可取的，因为总体准确率已经按流行度对类别进行了加权。**\n- 目标“最小化总错误数”在数学上等同于最小化总和 $\\mathrm{FN} + \\mathrm{FP}$。总体准确率定义为 $\\mathrm{ACC} = 1 - \\frac{\\mathrm{FN} + \\mathrm{FP}}{N_{total}}$。因此，最大化总体准确率等同于最小化总错误数。\n- 我们的例子表明，分类器 $\\mathcal{A}$ 具有更高的 ACC（$0.911$）和更少的总错误数（$\\mathrm{FN}_{\\mathcal{A}} + \\mathrm{FP}_{\\mathcal{A}} = 80+9=89$）。分类器 $\\mathcal{B}$ 具有更高的 BA（$0.85$）但有更多的总错误数（$\\mathrm{FN}_{\\mathcal{B}} + \\mathrm{FP}_{\\mathcal{B}} = 20+90=110$）。如果目标是最小化总错误数，应该选择 $\\mathcal{A}$，即具有更高 ACC 的分类器，而不是更高 BA 的分类器。因此，优化 BA 将是错误的策略。所提供的理由也是正确的：总体准确率实现了这一目标，因为它同等加权每个实例，这意味着类别是按流行度加权的。\n- 结论：**正确**。\n\n**E. 如果两个分类器具有相同的平衡准确率，那么无论类别是否不平衡，它们也必须具有相同的总体准确率。**\n- 这个陈述可以通过一个反例来证明是错误的。设 $\\mathrm{BA}_{\\mathcal{C}} = \\mathrm{BA}_{\\mathcal{D}}$。这意味着 $\\frac{1}{2}(\\mathrm{TPR}_{\\mathcal{C}} + \\mathrm{TNR}_{\\mathcal{C}}) = \\frac{1}{2}(\\mathrm{TPR}_{\\mathcal{D}} + \\mathrm{TNR}_{\\mathcal{D}})$。\n- 总体准确率是 $\\mathrm{ACC} = \\pi_P \\mathrm{TPR} + \\pi_{N_{neg}} \\mathrm{TNR}$。\n- 假设我们的不平衡数据集有 $\\pi_P = 0.1$ 和 $\\pi_{N_{neg}} = 0.9$。\n- 设分类器 $\\mathcal{C}$ 具有 $\\mathrm{TPR}_{\\mathcal{C}} = 0.9$ 和 $\\mathrm{TNR}_{\\mathcal{C}} = 0.7$。则 $\\mathrm{BA}_{\\mathcal{C}} = (0.9+0.7)/2 = 0.8$。其准确率为 $\\mathrm{ACC}_{\\mathcal{C}} = (0.1)(0.9) + (0.9)(0.7) = 0.09 + 0.63 = 0.72$。\n- 设分类器 $\\mathcal{D}$ 具有 $\\mathrm{TPR}_{\\mathcal{D}} = 0.7$ 和 $\\mathrm{TNR}_{\\mathcal{D}} = 0.9$。则 $\\mathrm{BA}_{\\mathcal{D}} = (0.7+0.9)/2 = 0.8$。其准确率为 $\\mathrm{ACC}_{\\mathcal{D}} = (0.1)(0.7) + (0.9)(0.9) = 0.07 + 0.81 = 0.88$。\n- 这里，$\\mathrm{BA}_{\\mathcal{C}} = \\mathrm{BA}_{\\mathcal{D}}$，但是 $\\mathrm{ACC}_{\\mathcal{C}} \\neq \\mathrm{ACC}_{\\mathcal{D}}$。该陈述是错误的。它仅在平衡数据集的特殊情况下成立，即 $\\pi_P = \\pi_{N_{neg}} = 0.5$，此时 $\\mathrm{ACC} = 0.5(\\mathrm{TPR}+\\mathrm{TNR}) = \\mathrm{BA}$。短语“无论类别是否不平衡”使得该陈述绝对是错误的。\n- 结论：**不正确**。", "answer": "$$\\boxed{ACD}$$", "id": "3181064"}]}