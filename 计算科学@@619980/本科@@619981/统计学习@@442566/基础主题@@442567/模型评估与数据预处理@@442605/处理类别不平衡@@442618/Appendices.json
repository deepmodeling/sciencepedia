{"hands_on_practices": [{"introduction": "分类模型的价值通常不仅仅取决于其准确率。在处理类别不平衡问题时，不同类型的错误（例如，将罕见病患者误诊为健康）往往会带来截然不同的代价。本练习将引导你从第一性原理出发，通过最大化一个预定义的期望效用函数，来推导出一个最优决策阈值，这揭示了成本敏感学习在应对类别不平衡中的核心思想。[@problem_id:3127116]", "problem": "一个二元分类器产生一个实值分数 $s \\in \\mathbb{R}$，用于在少数正类 $Y=1$ 和多数负类 $Y=0$ 之间进行决策。正类的类先验概率为 $P(Y=1)=\\pi$，其中 $\\pi = 0.10$，而 $P(Y=0)=1-\\pi$。经科学测量，以类别为条件的分数分布是方差相等的高斯分布：$s \\mid Y=1 \\sim \\mathcal{N}(\\mu_{1},\\sigma^{2})$ 和 $s \\mid Y=0 \\sim \\mathcal{N}(\\mu_{0},\\sigma^{2})$，其中 $\\mu_{1} = 2$，$\\mu_{0} = 0$，$\\sigma = 1$。你需要选择一个单一的确定性阈值 $t$，如果 $s \\geq t$ 则预测 $Y=1$，否则预测 $Y=0$。\n\n根据每个决策的效用，将总体效用 $U(\\text{TP},\\text{FP},\\text{FN},\\text{TN})$ 线性定义为\n$$\nU(\\text{TP},\\text{FP},\\text{FN},\\text{TN}) \\;=\\; u_{\\text{TP}} \\cdot \\text{TP} \\;+\\; u_{\\text{FP}} \\cdot \\text{FP} \\;+\\; u_{\\text{FN}} \\cdot \\text{FN} \\;+\\; u_{\\text{TN}} \\cdot \\text{TN},\n$$\n其中 $\\text{TP}$、$\\text{FP}$、$\\text{FN}$ 和 $\\text{TN}$ 是在该阈值规则下真正例 (TP)、假正例 (FP)、假负例 (FN) 和真负例 (TN) 决策的计数。在一个高风险的罕见事件筛选情境中，错误分类一个正例的后果远比将一个负例标记出来要严重；假设每个决策的效用为 $u_{\\text{TP}} = 3$，$u_{\\text{FP}} = -1$，$u_{\\text{FN}} = -8$，以及 $u_{\\text{TN}} = 1$。\n\n仅从期望效用、条件概率和贝叶斯定理的基本定义出发，推导出在阈值族 $s \\geq t$ 下能最大化总体期望效用的决策规则，并求解给定 $\\pi$、$\\mu_{1}$、$\\mu_{0}$ 和 $\\sigma$ 下的最优阈值 $t^{\\star}$。给出你的最终数值 $t^{\\star}$，并四舍五入到四位有效数字。不需要单位。", "solution": "用户希望我扮演一位严谨的STEM教授。这要求我首先根据指定的标准验证问题陈述。\n\n### 问题验证\n\n**第1步：提取已知条件**\n\n*   **分类任务：** 在少数正类 $Y=1$ 和多数负类 $Y=0$ 之间的二元分类。\n*   **分类器分数：** 一个实值分数 $s \\in \\mathbb{R}$。\n*   **决策规则：** 如果 $s \\geq t$ 则预测 $Y=1$，如果 $s < t$ 则预测 $Y=0$。\n*   **类先验概率：** $P(Y=1) = \\pi = 0.10$，$P(Y=0) = 1-\\pi = 0.90$。\n*   **条件分数分布：**\n    *   对于正类：$s \\mid Y=1 \\sim \\mathcal{N}(\\mu_{1}, \\sigma^{2})$。\n    *   对于负类：$s \\mid Y=0 \\sim \\mathcal{N}(\\mu_{0}, \\sigma^{2})$。\n*   **分布参数：** $\\mu_{1} = 2$，$\\mu_{0} = 0$，$\\sigma = 1$。\n*   **效用函数：** $U(\\text{TP},\\text{FP},\\text{FN},\\text{TN}) = u_{\\text{TP}} \\cdot \\text{TP} + u_{\\text{FP}} \\cdot \\text{FP} + u_{\\text{FN}} \\cdot \\text{FN} + u_{\\text{TN}} \\cdot \\text{TN}$。\n*   **各决策效用：** $u_{\\text{TP}} = 3$，$u_{\\text{FP}} = -1$，$u_{\\text{FN}} = -8$，$u_{\\text{TN}} = 1$。\n*   **目标：** 推导最大化期望效用的决策规则，并找到最优阈值 $t^{\\star}$，提供一个四舍五入到四位有效数字的数值。\n\n**第2步：使用提取的已知条件进行验证**\n\n*   **科学依据：** 该问题牢固地植根于统计决策理论，这是统计学和机器学习的一个核心子领域。使用高斯分布来建模分数是一种标准且科学上有效的方法。最大化期望效用的目标是理性决策的基本原则。不存在科学缺陷。\n*   **适定性：** 这个问题是适定的。目标函数（期望效用）定义清晰，所有必要的参数（先验概率、分布参数、效用值）都已提供。高斯分布的性质确保了存在一个唯一的阈值来最大化效用函数。\n*   **客观性：** 该问题使用精确、客观和标准的数学及统计术语进行陈述。没有主观或基于意见的陈述。\n*   **完整性与一致性：** 整个设置是自洽且内部一致的。所有需要的信息都已提供，没有矛盾之处。\n*   **现实性与可行性：** 该场景代表了决策理论在医学筛选或欺诈检测等背景下的经典且现实的应用，在这些背景下，类别不平衡和不对称的错分成本是常见的。数值是合理的。\n\n**第3步：结论与行动**\n\n*   **结论：** 问题有效。\n*   **行动：** 继续进行推导和求解。\n\n### 推导与求解\n\n目标是找到能最大化分类规则期望效用的阈值 $t$。我们可以通过考虑在给定分数 $s$ 下单个决策的期望效用，然后选择能产生更高条件期望效用的行动（预测 $Y=1$ 或 $Y=0$）来实现这一目标。最优阈值 $t^{\\star}$ 将是两种行动的期望效用相等时的分数 $s$ 的值。\n\n令 $\\hat{Y}$ 表示预测的类别。对于给定的分数 $s$，我们可以预测 $\\hat{Y}=1$ 或 $\\hat{Y}=0$。\n\n在给定分数 $s$ 的条件下，预测 $\\hat{Y}=1$ 的条件期望效用是：\n$$\nE[U \\mid s, \\hat{Y}=1] = u_{\\text{TP}} P(Y=1 \\mid s) + u_{\\text{FP}} P(Y=0 \\mid s)\n$$\n这是因为如果我们预测 $\\hat{Y}=1$，结果要么是真正例（如果真实类别是 $Y=1$），其效用为 $u_{\\text{TP}}$；要么是假正例（如果真实类别是 $Y=0$），其效用为 $u_{\\text{FP}}$。这些结果的概率分别是后验概率 $P(Y=1 \\mid s)$ 和 $P(Y=0 \\mid s)$。\n\n类似地，在给定分数 $s$ 的条件下，预测 $\\hat{Y}=0$ 的条件期望效用是：\n$$\nE[U \\mid s, \\hat{Y}=0] = u_{\\text{FN}} P(Y=1 \\mid s) + u_{\\text{TN}} P(Y=0 \\mid s)\n$$\n这是通过考虑结果要么是假负例（效用为 $u_{\\text{FN}}$），要么是真负例（效用为 $u_{\\text{TN}}$）得出的。\n\n最优决策规则是在 $E[U \\mid s, \\hat{Y}=1] > E[U \\mid s, \\hat{Y}=0]$ 时预测 $\\hat{Y}=1$，否则预测 $\\hat{Y}=0$。阈值 $t^{\\star}$ 是这两个期望效用相等时的 $s$ 值，它定义了决策边界：\n$$\nu_{\\text{TP}} P(Y=1 \\mid s) + u_{\\text{FP}} P(Y=0 \\mid s) = u_{\\text{FN}} P(Y=1 \\mid s) + u_{\\text{TN}} P(Y=0 \\mid s)\n$$\n重新整理各项以对后验概率进行分组：\n$$\n(u_{\\text{TP}} - u_{\\text{FN}}) P(Y=1 \\mid s) = (u_{\\text{TN}} - u_{\\text{FP}}) P(Y=0 \\mid s)\n$$\n现在，我们应用贝叶斯定理，用似然 $p(s|Y)$ 和先验概率 $P(Y)$ 来表示后验概率。\n$$\nP(Y=c \\mid s) = \\frac{p(s \\mid Y=c) P(Y=c)}{p(s)} \\quad \\text{for } c \\in \\{0, 1\\}\n$$\n其中 $p(s) = p(s \\mid Y=1)P(Y=1) + p(s \\mid Y=0)P(Y=0)$ 是分数 $s$ 的边际概率密度。\n将这些代入等式中得到：\n$$\n(u_{\\text{TP}} - u_{\\text{FN}}) \\frac{p(s \\mid Y=1) P(Y=1)}{p(s)} = (u_{\\text{TN}} - u_{\\text{FP}}) \\frac{p(s \\mid Y=0) P(Y=0)}{p(s)}\n$$\n边际密度 $p(s)$ 从两边消去。我们可以重新整理方程，用似然比来表示它：\n$$\n\\frac{p(s \\mid Y=1)}{p(s \\mid Y=0)} = \\frac{u_{\\text{TN}} - u_{\\text{FP}}}{u_{\\text{TP}} - u_{\\text{FN}}} \\cdot \\frac{P(Y=0)}{P(Y=1)}\n$$\n最优阈值 $t^{\\star}$ 是满足此方程的 $s$ 值。\n\n条件分布被给定为高斯分布：\n$p(s \\mid Y=1) = \\mathcal{N}(s; \\mu_1, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(s-\\mu_1)^2}{2\\sigma^2}\\right)$\n$p(s \\mid Y=0) = \\mathcal{N}(s; \\mu_0, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(s-\\mu_0)^2}{2\\sigma^2}\\right)$\n\n似然比为：\n$$\n\\frac{p(s \\mid Y=1)}{p(s \\mid Y=0)} = \\frac{\\exp\\left(-\\frac{(s-\\mu_1)^2}{2\\sigma^2}\\right)}{\\exp\\left(-\\frac{(s-\\mu_0)^2}{2\\sigma^2}\\right)} = \\exp\\left(\\frac{(s-\\mu_0)^2 - (s-\\mu_1)^2}{2\\sigma^2}\\right)\n$$\n化简指数部分：\n$(s-\\mu_0)^2 - (s-\\mu_1)^2 = (s^2 - 2s\\mu_0 + \\mu_0^2) - (s^2 - 2s\\mu_1 + \\mu_1^2) = 2s(\\mu_1 - \\mu_0) - (\\mu_1^2 - \\mu_0^2)$\n$= 2s(\\mu_1 - \\mu_0) - (\\mu_1 - \\mu_0)(\\mu_1 + \\mu_0) = (\\mu_1 - \\mu_0) [2s - (\\mu_1 + \\mu_0)]$\n\n将此代回 $s=t^{\\star}$ 处的主方程中：\n$$\n\\exp\\left(\\frac{(\\mu_1 - \\mu_0) [2t^{\\star} - (\\mu_1 + \\mu_0)]}{2\\sigma^2}\\right) = \\frac{u_{\\text{TN}} - u_{\\text{FP}}}{u_{\\text{TP}} - u_{\\text{FN}}} \\cdot \\frac{1-\\pi}{\\pi}\n$$\n为了求解 $t^{\\star}$，我们对两边取自然对数：\n$$\n\\frac{(\\mu_1 - \\mu_0) [2t^{\\star} - (\\mu_1 + \\mu_0)]}{2\\sigma^2} = \\ln\\left(\\frac{u_{\\text{TN}} - u_{\\text{FP}}}{u_{\\text{TP}} - u_{\\text{FN}}} \\cdot \\frac{1-\\pi}{\\pi}\\right)\n$$\n现在，我们求解 $t^{\\star}$：\n$$\n2t^{\\star} - (\\mu_1 + \\mu_0) = \\frac{2\\sigma^2}{\\mu_1 - \\mu_0} \\ln\\left(\\frac{u_{\\text{TN}} - u_{\\text{FP}}}{u_{\\text{TP}} - u_{\\text{FN}}} \\cdot \\frac{1-\\pi}{\\pi}\\right)\n$$\n$$\n2t^{\\star} = (\\mu_1 + \\mu_0) + \\frac{2\\sigma^2}{\\mu_1 - \\mu_0} \\ln\\left(\\frac{u_{\\text{TN}} - u_{\\text{FP}}}{u_{\\text{TP}} - u_{\\text{FN}}} \\cdot \\frac{1-\\pi}{\\pi}\\right)\n$$\n$$\nt^{\\star} = \\frac{\\mu_1 + \\mu_0}{2} + \\frac{\\sigma^2}{\\mu_1 - \\mu_0} \\ln\\left(\\frac{u_{\\text{TN}} - u_{\\text{FP}}}{u_{\\text{TP}} - u_{\\text{FN}}} \\cdot \\frac{1-\\pi}{\\pi}\\right)\n$$\n这就是最优阈值的一般符号表达式。\n\n我们现在代入给定的数值：\n$\\mu_1 = 2$，$\\mu_0 = 0$，$\\sigma^2 = 1^2 = 1$，$\\pi=0.10$。\n$u_{\\text{TP}} = 3$，$u_{\\text{FP}} = -1$，$u_{\\text{FN}} = -8$，$u_{\\text{TN}} = 1$。\n\n计算表达式的各个组成部分：\n*   $\\frac{\\mu_1 + \\mu_0}{2} = \\frac{2 + 0}{2} = 1$\n*   $\\frac{\\sigma^2}{\\mu_1 - \\mu_0} = \\frac{1}{2 - 0} = \\frac{1}{2}$\n*   $u_{\\text{TN}} - u_{\\text{FP}} = 1 - (-1) = 2$\n*   $u_{\\text{TP}} - u_{\\text{FN}} = 3 - (-8) = 11$\n*   $\\frac{1-\\pi}{\\pi} = \\frac{1 - 0.10}{0.10} = \\frac{0.90}{0.10} = 9$\n\n将这些值代入 $t^{\\star}$ 的表达式中：\n$$\nt^{\\star} = 1 + \\frac{1}{2} \\ln\\left(\\frac{2}{11} \\cdot 9\\right)\n$$\n$$\nt^{\\star} = 1 + \\frac{1}{2} \\ln\\left(\\frac{18}{11}\\right)\n$$\n现在我们计算数值：\n$$\n\\frac{18}{11} \\approx 1.6363636...\n$$\n$$\n\\ln\\left(\\frac{18}{11}\\right) \\approx \\ln(1.6363636...) \\approx 0.492476...\n$$\n$$\nt^{\\star} \\approx 1 + \\frac{1}{2}(0.492476...) = 1 + 0.246238...\n$$\n$$\nt^{\\star} \\approx 1.246238...\n$$\n四舍五入到四位有效数字，我们得到 $t^{\\star} = 1.246$。\n推导出的决策规则是：如果分数 $s$ 大于或等于约 1.246，则预测 $Y=1$，否则预测 $Y=0$。这个阈值低于由对数先验项调整后的均值中点（$1 + 0.5\\ln(9) \\approx 2.0986$），但假负例相对于假正例的高成本（$\\ln(2/11) \\approx -1.7047$）又将其推高了。让我重新验证一下逻辑。\n完整的对数项是 $\\ln(\\frac{18}{11})$，是正数。项 $\\frac{\\sigma^2}{\\mu_1-\\mu_0}$ 是正数。所以阈值 $t^\\star$ 从中点 $\\frac{\\mu_0+\\mu_1}{2}=1$ 移动到了一个更高的值。我们来分析一下各个组成部分。先验项是 $\\ln(9) > 0$。成本项是 $\\ln(2/11) < 0$。总的调整量乘以了 $1/2$。\n$t^{\\star} = 1 + 0.5 \\times (\\ln(2/11) + \\ln(9)) = 1 + 0.5 \\times (-1.7047... + 2.1972...) = 1 + 0.5 \\times (0.4925...) = 1.246...$。计算是正确的。\n阈值从均值的中点 1 移动到了 1.246。这意味着与简单的中点规则相比，我们需要更多的证据才能分类为正例。考虑到假负例的高昂成本，这似乎有悖直觉。让我们重新检查一下决策规则。\n我们预测 $\\hat{Y}=1$ 如果 $E[U \\mid s, \\hat{Y}=1] \\ge E[U \\mid s, \\hat{Y}=0]$。这等价于 $\\frac{p(s \\mid Y=1)}{p(s \\mid Y=0)} \\ge \\frac{u_{\\text{TN}} - u_{\\text{FP}}}{u_{\\text{TP}} - u_{\\text{FN}}} \\cdot \\frac{1-\\pi}{\\pi}$。\n似然比 $\\frac{p(s \\mid Y=1)}{p(s \\mid Y=0)}$ 是 $s$ 的增函数，因为 $\\mu_1 > \\mu_0$。因此，$s \\ge t^{\\star}$ 是决策规则的正确形式。让我们重新审视这些项。\n成本比：$\\frac{u_{\\text{TN}} - u_{\\text{FP}}}{u_{\\text{TP}} - u_{\\text{FN}}} = \\frac{1 - (-1)}{3 - (-8)} = \\frac{2}{11}$。这是“避免一个假正例的收益”与“避免一个假负例的收益”之比。由于一个假负例的成本非常高（$u_{FN}=-8$），这个比率很小。\n先验比：$\\frac{1-\\pi}{\\pi} = \\frac{0.9}{0.1} = 9$。负类更为常见。\n似然比的阈值是 $\\frac{2}{11} \\times 9 = \\frac{18}{11} \\approx 1.636$。\n所以我们需要似然比至少为 $1.636$ 才能分类为正例。由于在 $s=1$（对数似然的中点）时似然比为 1，并且它随着 $s$ 的增加而增加，所以阈值必须大于 1。负类的高流行率（$9:1$ 的几率）需要强有力的证据来克服，而成本结构（成本比为 $2/11$）则将阈值推低，使得分类为正例变得更容易。这两种相互竞争的效应的乘积决定了最终的阈值。在这里，先验效应主导了成本效应，因为 $9 > 11/2=5.5$。因此，阈值必须高于均值的中点。我的推理是合理的。计算是正确的。\n\n最终值：$1.246238...$\n四舍五入到四位有效数字：$1.246$。", "answer": "$$\\boxed{1.246}$$", "id": "3127116"}, {"introduction": "除了调整决策过程，我们还可以直接改变训练数据本身来应对类别不平衡，这被称为数据层面方法。本练习将从理论转向一个动手编程挑战：你将实现一种先进的欠采样技术，它能智能地移除多数类样本，同时关键地保留决策边界附近的信息。通过这个实践，你将学会如何在重新平衡数据的同时，避免丢失对模型至关重要的结构信息。[@problem_id:3127121]", "problem": "给定一个在 $\\mathbb{R}^2$ 中具有严重类别不平衡的二元分类任务。设多数类标记为 $0$，少数类标记为 $1$。经验训练分布由样本 $\\{(x_i, y_i)\\}_{i=1}^n$ 表示，其中 $x_i \\in \\mathbb{R}^2$ 且 $y_i \\in \\{0,1\\}$。您将实现一种密度感知欠采样方法，该方法移除密集内部区域中的冗余多数类点，同时保留决策边界附近的点。然后，您将衡量这种欠采样对少数类召回率（定义为真阳性率）的影响。\n\n基本原理和定义：\n- 贝叶斯决策规则将一个点 $x$ 分类为类别 $1$（如果 $P(Y=1 \\mid X=x) > P(Y=0 \\mid X=x)$），否则分类为类别 $0$。在实践中，该规则通过使用经验数据学习的分类器来近似。\n- k-最近邻（k-NN）分类器通过在特征空间中对 $k$ 个最近的训练样本进行多数投票来近似贝叶斯决策规则。\n- 类别不平衡会扭曲 $P(Y \\mid X)$ 的经验估计，使分类器偏向多数类，这通常会降低少数类召回率。\n- 少数类召回率定义为 $R = \\frac{\\text{真阳性}}{\\text{真阳性} + \\text{假阴性}}$，表示为 $[0,1]$ 范围内的小数。\n\n您必须设计并实现一个算法，该算法移除位于高多数类密度区域且远离少数类点的多数类点，从而保留经验决策边界。设计必须从经过充分检验的公式开始：\n- 通过 $k$-最近邻距离进行局部密度估计。对于每个多数类点 $x$，定义局部密度代理\n$$d_M(x) = \\frac{1}{\\epsilon + \\frac{1}{k}\\sum_{j=1}^{k} \\|x - \\text{NN}_j^{(M)}(x)\\|_2},$$\n其中 $\\text{NN}_j^{(M)}(x)$ 表示 $x$ 在多数类点中的第 $j$ 个最近邻，$\\epsilon > 0$ 是一个用于避免除以零的小常数。\n- 通过到最近的少数类点的距离来衡量边界邻近度\n$$d_m(x) = \\min_{z \\in \\mathcal{X}_m} \\|x-z\\|_2,$$\n其中 $\\mathcal{X}_m$ 是少数类点的集合。\n\n通过最小-最大缩放将所有多数类点的 $d_M(x)$ 和 $d_m(x)$ 归一化到 $[0,1]$ 区间，以获得 $\\tilde{d}_M(x)$ 和 $\\tilde{d}_m(x)$。定义移除倾向性\n$$r(x) = \\tilde{d}_M(x) \\cdot \\tilde{d}_m(x).$$\n您必须保留 $r(x)$ 值最小的一部分多数类点，比例为 $f \\in (0,1]$，并移除其余的点。这将移除冗余的密集内部点，同时保留那些靠近少数类的点，这有助于保留经验决策边界。\n\n分类器和评估：\n- 在原始训练集上训练一个 $k=5$ 的 k-最近邻分类器，并在一个留出的测试集上评估少数类召回率。\n- 在欠采样后的训练集上训练同一个分类器，并在同一个测试集上评估少数类召回率。\n- 将召回率的提升报告为 $R_{\\text{after}} - R_{\\text{before}}$，表示为小数并四舍五入到四位小数。\n\n数据生成：\n- 对于训练数据，多数类是两个高斯分量的混合，其中心分别位于 $(-2,0)$ 和 $(2,0)$，每个分量的各向同性标准差为 $\\sigma_M$；样本在两个分量之间平均分配。少数类是单个高斯分布，中心位于 $(c_x,c_y)$，各向同性标准差为 $\\sigma_m$。\n- 对于测试数据，从相同的分布（具有独立的随机性）生成一个包含固定数量多数类和少数类点的新数据集；评估仅使用少数类部分来计算召回率。\n\n角度单位不适用。没有物理单位。百分比必须表示为小数。\n\n测试套件：\n实现程序以运行以下四个测试用例。对于每个用例 $i$，都提供了训练集大小、高斯参数和欠采样参数。必须按规定为随机数生成器设置种子，以确保确定性。\n\n- 用例 1（正常路径）：\n  - 种子 $= 7$。\n  - 训练集多数类数量 $= 1200$，训练集少数类数量 $= 60$。\n  - 多数类标准差 $\\sigma_M = 1.0$，少数类标准差 $\\sigma_m = 0.5$。\n  - 少数类中心 $(c_x,c_y) = (0, 0.5)$。\n  - 用于 $d_M$ 的密度 $k$：$k=15$。\n  - 多数类保留比例 $f = 0.35$。\n  - 测试集多数类数量 $= 400$，测试集少数类数量 $= 200$。\n\n- 用例 2（边界条件：不进行欠采样）：\n  - 种子 $= 17$。\n  - 训练集多数类数量 $= 800$，训练集少数类数量 $= 40$。\n  - 多数类标准差 $\\sigma_M = 1.0$，少数类标准差 $\\sigma_m = 0.6$。\n  - 少数类中心 $(c_x,c_y) = (0, 0.3)$。\n  - 用于 $d_M$ 的密度 $k$：$k=10$。\n  - 多数类保留比例 $f = 1.0$。\n  - 测试集多数类数量 $= 400$，测试集少数类数量 $= 200$。\n\n- 用例 3（极端不平衡）：\n  - 种子 $= 23$。\n  - 训练集多数类数量 $= 5000$，训练集少数类数量 $= 50$。\n  - 多数类标准差 $\\sigma_M = 1.0$，少数类标准差 $\\sigma_m = 0.6$。\n  - 少数类中心 $(c_x,c_y) = (0, 0.5)$。\n  - 用于 $d_M$ 的密度 $k$：$k=25$。\n  - 多数类保留比例 $f = 0.20$。\n  - 测试集多数类数量 $= 400$，测试集少数类数量 $= 200$。\n\n- 用例 4（少数类良好分离）：\n  - 种子 $= 101$。\n  - 训练集多数类数量 $= 1500$，训练集少数类数量 $= 80$。\n  - 多数类标准差 $\\sigma_M = 1.0$，少数类标准差 $\\sigma_m = 0.5$。\n  - 少数类中心 $(c_x,c_y) = (0, 3.0)$。\n  - 用于 $d_M$ 的密度 $k$：$k=15$。\n  - 多数类保留比例 $f = 0.30$。\n  - 测试集多数类数量 $= 400$，测试集少数类数量 $= 200$。\n\n实现要求：\n- 使用指定的算法进行密度感知欠采样。\n- 使用一个 $5$-最近邻分类器进行评估。\n- 少数类召回率必须以小数形式报告；为每个用例输出提升值 $R_{\\text{after}} - R_{\\text{before}}$，四舍五入到四位小数。\n- 最终输出格式：您的程序应生成单行文本，其中包含四个结果，形式为方括号括起来的逗号分隔列表，例如 $[r_1,r_2,r_3,r_4]$，其中每个 $r_i$ 是用例 $i$ 经四舍五入后的小数提升值。\n\n程序必须是完整的，并且无需任何用户输入或外部文件即可运行。", "solution": "问题陈述被评估为有效。它在统计学习领域内提出了一个适定的、有科学依据的任务。所有用于数据生成、算法实现和评估的必要参数和定义均已提供。在给定指定随机种子的情况下，该过程是确定性的，从而产生唯一且可验证的解决方案。关于密度代理公式中常数 $\\epsilon$ 的一个微小歧义，可以通过将其解释为一个用于确保数值稳定性的标准小正值来解决，`numpy.finfo(float).eps` 是一个规范的选择。这种解释不影响问题的完整性。\n\n该解决方案通过实现指定的密度感知欠采样算法，并评估其对 k-最近邻分类器性能的影响来进行。方法如下：\n\n1.  **数据生成**：为每个测试用例合成训练和测试数据集。标记为 $0$ 的多数类从两个二维高斯分布的混合中抽取，中心点分别为 $(−2, 0)$ 和 $(2, 0)$，标准差为 $\\sigma_M$。标记为 $1$ 的少数类从以 $(c_x, c_y)$ 为中心、标准差为 $\\sigma_m$ 的单个高斯分布中抽取。为随机数生成器设置种子以确保可复现性。\n\n2.  **密度感知欠采样**：这个核心步骤旨在通过选择性地移除多数类样本来重新平衡训练数据。其原理是移除那些既处于多数类密集区域又远离任何少数类点的点。这类点被认为是冗余的，移除它们不太可能扰动决策边界。这通过为每个多数类点 $x$ 计算一个移除倾向性 $r(x)$ 来形式化。\n    *   **局部多数类密度, $d_M(x)$**：多数类点 $x$ 周围的密度通过其在多数类内部的 $k$ 个最近邻的平均距离来估计。密度代理由以下公式给出：\n        $$d_M(x) = \\frac{1}{\\epsilon + \\frac{1}{k}\\sum_{j=1}^{k} \\|x - \\text{NN}_j^{(M)}(x)\\|_2}$$\n        较高的 $d_M(x)$ 值表示 $x$ 位于多数类的更密集区域。$\\text{NN}_j^{(M)}(x)$ 是 $x$ 在多数类点中的第 $j$ 个最近邻。\n    *   **少数类邻近度, $d_m(x)$**：一个多数类点 $x$ 到决策边界的邻近度通过其到最近的少数类点的欧几里得距离来近似：\n        $$d_m(x) = \\min_{z \\in \\mathcal{X}_m} \\|x-z\\|_2$$\n        其中 $\\mathcal{X}_m$ 是所有少数类点的集合。较大的 $d_m(x)$ 值表示 $x$ 离少数类更远。\n    *   **移除倾向性, $r(x)$**：所有多数类点的 $d_M(x)$ 和 $d_m(x)$ 值被归一化到 $[0, 1]$ 范围，产生 $\\tilde{d}_M(x)$ 和 $\\tilde{d}_m(x)$。移除倾向性是这些归一化分数的乘积：\n        $$r(x) = \\tilde{d}_M(x) \\cdot \\tilde{d}_m(x)$$\n        高 $r(x)$ 值表示一个点位于密集的多数类区域且远离少数类区域，使其成为移除的首要候选者。\n    *   **选择**：该算法保留 $r(x)$ 分数最低的比例为 $f$ 的多数类点，从而有效地保留了那些位于稀疏区域或靠近少数类的多数类点。\n\n3.  **分类器训练与评估**：使用一个 $k=5$ 的 k-最近邻（$k$-NN）分类器来评估欠采样的效果。\n    *   **基线召回率 ($R_{\\text{before}}$)**：首先在原始的不平衡训练集上训练分类器。通过在留出测试集的少数类样本上计算少数类召回率来衡量其性能。少数类召回率定义为 $R = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$，其中 $\\text{TP}$（真阳性）是被正确分类为少数类的少数类测试点，而 $\\text{FN}$（假阴性）是被错误分类为多数类的少数类测试点。\n    *   **欠采样后召回率 ($R_{\\text{after}}$)**：然后在新的、经过欠采样的训练集上训练分类器，该训练集由保留的多数类点和所有原始少数类点组成。在同一个测试集上重新评估少数类召回率。\n    *   **提升**：每个用例最终报告的指标是召回率的提升值 $R_{\\text{after}} - R_{\\text{before}}$，四舍五入到四位小数。\n\n对四个指定的测试用例中的每一个重复此整个过程，并将结果聚合到一个最终列表中。", "answer": "```python\nimport numpy as np\nfrom scipy.spatial import KDTree\nfrom scipy.spatial.distance import cdist\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for density-aware undersampling.\n    \"\"\"\n\n    test_cases = [\n        # Case 1 (happy path)\n        {'seed': 7, 'train_maj': 1200, 'train_min': 60, 'sigma_M': 1.0, 'sigma_m': 0.5, 'c_minority': (0, 0.5), 'density_k': 15, 'f': 0.35, 'test_maj': 400, 'test_min': 200},\n        # Case 2 (boundary condition: no undersampling)\n        {'seed': 17, 'train_maj': 800, 'train_min': 40, 'sigma_M': 1.0, 'sigma_m': 0.6, 'c_minority': (0, 0.3), 'density_k': 10, 'f': 1.0, 'test_maj': 400, 'test_min': 200},\n        # Case 3 (extreme imbalance)\n        {'seed': 23, 'train_maj': 5000, 'train_min': 50, 'sigma_M': 1.0, 'sigma_m': 0.6, 'c_minority': (0, 0.5), 'density_k': 25, 'f': 0.20, 'test_maj': 400, 'test_min': 200},\n        # Case 4 (minority well separated)\n        {'seed': 101, 'train_maj': 1500, 'train_min': 80, 'sigma_M': 1.0, 'sigma_m': 0.5, 'c_minority': (0, 3.0), 'density_k': 15, 'f': 0.30, 'test_maj': 400, 'test_min': 200},\n    ]\n\n    results = []\n    \n    epsilon = np.finfo(float).eps  # Small constant for numerical stability\n    k_classifier = 5  # k for the evaluation classifier\n\n    def min_max_scale(data):\n        \"\"\"Performs min-max normalization on a 1D numpy array.\"\"\"\n        min_val = np.min(data)\n        max_val = np.max(data)\n        if max_val > min_val:\n            return (data - min_val) / (max_val - min_val)\n        return np.zeros_like(data, dtype=float)\n\n    def density_aware_undersampling(X_maj, X_min, k_density, f):\n        \"\"\"\n        Performs density-aware undersampling on the majority class.\n        \"\"\"\n        n_maj = X_maj.shape[0]\n        if n_maj == 0 or X_min.shape[0] == 0:\n            return X_maj\n\n        # 1. Calculate local density proxy d_M(x)\n        maj_tree = KDTree(X_maj)\n        # Query for k+1 neighbors to exclude the point itself\n        distances, _ = maj_tree.query(X_maj, k=k_density + 1)\n        mean_dists = np.mean(distances[:, 1:], axis=1)\n        d_M_values = 1.0 / (epsilon + mean_dists)\n\n        # 2. Calculate boundary proximity d_m(x)\n        all_dists_to_min = cdist(X_maj, X_min, 'euclidean')\n        d_m_values = np.min(all_dists_to_min, axis=1)\n\n        # 3. Normalize and calculate removal propensity r(x)\n        tilde_d_M = min_max_scale(d_M_values)\n        tilde_d_m = min_max_scale(d_m_values)\n        r_values = tilde_d_M * tilde_d_m\n\n        # 4. Retain fraction f with smallest r(x)\n        n_keep = int(n_maj * f)\n        indices_to_keep = np.argsort(r_values)[:n_keep]\n        \n        return X_maj[indices_to_keep]\n\n    def knn_predict(X_train, y_train, X_test, k):\n        \"\"\"\n        Predicts labels for X_test using k-NN classifier trained on X_train, y_train.\n        \"\"\"\n        if X_train.shape[0] == 0:\n            return np.zeros(X_test.shape[0], dtype=int)\n        \n        actual_k = min(k, X_train.shape[0])\n\n        train_tree = KDTree(X_train)\n        _, indices = train_tree.query(X_test, k=actual_k)\n\n        if indices.ndim == 1:\n            indices = indices.reshape(1, -1)\n\n        neighbor_labels = y_train[indices].astype(int)\n        \n        # Majority vote using bincount\n        predictions = np.apply_along_axis(\n            lambda x: np.argmax(np.bincount(x, minlength=2)),\n            axis=1,\n            arr=neighbor_labels\n        )\n        return predictions\n\n    for case in test_cases:\n        np.random.seed(case['seed'])\n\n        # Generate training data\n        n_maj_1 = case['train_maj'] // 2\n        n_maj_2 = case['train_maj'] - n_maj_1\n        X_train_maj = np.vstack([\n            np.random.normal(loc=[-2, 0], scale=case['sigma_M'], size=(n_maj_1, 2)),\n            np.random.normal(loc=[2, 0], scale=case['sigma_M'], size=(n_maj_2, 2))\n        ])\n        y_train_maj = np.zeros(case['train_maj'])\n        X_train_min = np.random.normal(loc=case['c_minority'], scale=case['sigma_m'], size=(case['train_min'], 2))\n        y_train_min = np.ones(case['train_min'])\n        \n        X_train = np.vstack((X_train_maj, X_train_min))\n        y_train = np.hstack((y_train_maj, y_train_min))\n        \n        # Generate test data (only minority set is needed for recall calculation)\n        X_test_min = np.random.normal(loc=case['c_minority'], scale=case['sigma_m'], size=(case['test_min'], 2))\n        \n        # --- \"Before\" undersampling ---\n        y_pred_before = knn_predict(X_train, y_train, X_test_min, k=k_classifier)\n        R_before = np.mean(y_pred_before) # Recall = TP / (TP+FN) = sum(preds) / len(preds)\n\n        # --- Perform undersampling ---\n        if case['f']  1.0:\n            X_train_maj_resampled = density_aware_undersampling(\n                X_train_maj, X_train_min, case['density_k'], case['f'])\n        else:\n            X_train_maj_resampled = X_train_maj.copy()\n        \n        y_train_maj_resampled = np.zeros(X_train_maj_resampled.shape[0])\n        \n        X_train_resampled = np.vstack((X_train_maj_resampled, X_train_min))\n        y_train_resampled = np.hstack((y_train_maj_resampled, y_train_min))\n        \n        # --- \"After\" undersampling ---\n        y_pred_after = knn_predict(X_train_resampled, y_train_resampled, X_test_min, k=k_classifier)\n        R_after = np.mean(y_pred_after)\n\n        # --- Calculate improvement ---\n        improvement = R_after - R_before\n        results.append(f\"{improvement:.4f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3127121"}, {"introduction": "算法层面的方法则通过修改模型本身的学习过程或输出来解决不平衡问题。本练习聚焦于一种现代且高效的技术——对数调整（logit adjustment），它在模型的最终softmax激活之前，直接将类别先验概率信息整合到对数（logits）中。你将亲手实现这一过程，并分析它对模型准确率和校准度的双重影响，从而深入理解在现实应用中进行权衡的必要性。[@problem_id:3127123]", "problem": "在多类别分类问题中，当类别不平衡时，模型会为每个类别生成实值分数，通常称为 logits。softmax 函数将 logits 转换为类别上的概率分布。您将实现一种基于原则的 logit 调整方法，该方法融合了类别先验信息，然后量化此调整对两个不同方面的影响：排名（通过 top-1 准确率衡量）和校准（通过平均负对数似然衡量）。\n\n从贝叶斯法则给出的条件概率基本定义出发，对于任何输入特征向量 $x$ 和类别 $k$，后验概率满足\n$$\np(y=k \\mid x) \\propto p(x \\mid y=k)\\,p(y=k),\n$$\n其中比例常数由证据 $p(x)$ 给出。当一个判别模型的每个类别的 logit $z_k(x)$ 与类别条件对数似然在相差一个依赖于类别的可加常数下成比例时，通过在归一化之前将 logits 转换为与后验成比例的分数，可以得到正确考虑了类别先验 $p(y=k)$ 的概率预测。这启发我们进行一种编码先验信息的 logit 变换，之后通过 softmax 归一化获得概率。您的任务是从贝叶斯法则推导此变换，并实现未经调整和经过调整的 softmax 预测。\n\n您的程序必须：\n1. 实现从未经调整的 logits $z_{i,k}$ 到概率 $p_{i,k}$ 的 softmax 映射。\n2. 基于贝叶斯法则推导并实现一种融合先验信息的 logit 变换，该变换在 softmax 归一化后产生调整后的概率 $q_{i,k}$。\n3. 对每个测试用例，计算：\n   - 未经调整和经过调整的概率下的 Top-1 准确率，定义为预测类别 $\\arg\\max_k p_{i,k}$ 或 $\\arg\\max_k q_{i,k}$ 与真实标签相等的样本所占的比例（以小数表示）。\n   - 未经调整和经过调整的概率下的平均负对数似然 (NLL)，定义为所有样本 $i$ 的 $-\\log p_{i,y_i}$ 或 $-\\log q_{i,y_i}$ 的平均值，其中 $y_i$ 是样本 $i$ 的真实类别标签。\n4. 对每个测试用例，输出两个值：\n   - 准确率差异 $a = \\text{accuracy}_{\\text{adjusted}} - \\text{accuracy}_{\\text{unadjusted}}$。\n   - NLL 差异 $\\ell = \\text{NLL}_{\\text{adjusted}} - \\text{NLL}_{\\text{unadjusted}}$。\n   以小数形式报告 $a$ 和 $\\ell$（不带百分号），保留六位小数。\n\n使用的定义：\n- 对于每个具有 logits $\\{z_{i,1},\\dots,z_{i,K}\\}$ 的样本 $i$，未经调整的 softmax 概率为\n$$\np_{i,k} = \\frac{\\exp(z_{i,k})}{\\sum_{j=1}^{K} \\exp(z_{i,j})}.\n$$\n- 调整后的概率必须通过首先根据贝叶斯法则所暗示的方式使用类别先验信息变换 logits，然后应用 softmax 归一化以生成有效的类别分布来获得。\n\n测试套件规范。对于每个测试用例，给定一个 logit 矩阵 $Z \\in \\mathbb{R}^{n \\times K}$、整数标签 $\\boldsymbol{y} \\in \\{0,\\dots,K-1\\}^n$ 以及一个类别先验向量 $\\boldsymbol{\\pi} \\in \\mathbb{R}^K$，其条目在 $(0,1)$ 范围内且总和为 $1$。使用以下四个测试用例：\n\n测试用例 $1$（一般长尾分布）：\n$$\nZ^{(1)} = \\begin{bmatrix}\n2.5  1.0  0.0\\\\\n0.0  1.2  1.0\\\\\n1.2  0.2  0.1\\\\\n-1.0  0.0  3.0\\\\\n0.5  0.4  0.3\n\\end{bmatrix},\\quad\n\\boldsymbol{y}^{(1)} = \\begin{bmatrix}0\\\\1\\\\0\\\\2\\\\0\\end{bmatrix},\\quad\n\\boldsymbol{\\pi}^{(1)} = \\begin{bmatrix}0.7\\\\0.2\\\\0.1\\end{bmatrix}.\n$$\n\n测试用例 $2$（均匀先验边界；不变性检查）：\n$$\nZ^{(2)} = \\begin{bmatrix}\n2.5  1.0  0.0\\\\\n0.0  1.2  1.0\\\\\n1.2  0.2  0.1\\\\\n-1.0  0.0  3.0\\\\\n0.5  0.4  0.3\n\\end{bmatrix},\\quad\n\\boldsymbol{y}^{(2)} = \\begin{bmatrix}2\\\\2\\\\1\\\\2\\\\0\\end{bmatrix},\\quad\n\\boldsymbol{\\pi}^{(2)} = \\begin{bmatrix}\\tfrac{1}{3}\\\\\\tfrac{1}{3}\\\\\\tfrac{1}{3}\\end{bmatrix}.\n$$\n\n测试用例 $3$（极端不平衡；长尾压力测试）：\n$$\nZ^{(3)} = \\begin{bmatrix}\n4.0  3.9  5.5\\\\\n1.0  2.0  3.0\\\\\n3.0  0.0  0.5\\\\\n0.5  0.6  0.7\n\\end{bmatrix},\\quad\n\\boldsymbol{y}^{(3)} = \\begin{bmatrix}2\\\\2\\\\0\\\\1\\end{bmatrix},\\quad\n\\boldsymbol{\\pi}^{(3)} = \\begin{bmatrix}0.95\\\\0.04\\\\0.01\\end{bmatrix}.\n$$\n\n测试用例 $4$（二元边界；阈值敏感性）：\n$$\nZ^{(4)} = \\begin{bmatrix}\n2.0  1.8\\\\\n0.1  0.2\\\\\n-0.5  -0.6\\\\\n1.0  2.0\\\\\n0.0  0.0\n\\end{bmatrix},\\quad\n\\boldsymbol{y}^{(4)} = \\begin{bmatrix}0\\\\1\\\\0\\\\1\\\\0\\end{bmatrix},\\quad\n\\boldsymbol{\\pi}^{(4)} = \\begin{bmatrix}0.9\\\\0.1\\end{bmatrix}.\n$$\n\n最终输出格式：\n您的程序应生成一行输出，其中包含所有按顺序连接的结果，形式为用方括号括起来的逗号分隔列表。对于测试用例 $1$ 到 $4$，按顺序附加每个测试用例的配对值：首先是准确率差异 $a$，然后是 NLL 差异 $\\ell$，两者都保留六位小数。例如，输出必须采用以下格式\n$$\n[\\;a_1,\\ell_1,a_2,\\ell_2,a_3,\\ell_3,a_4,\\ell_4\\;].\n$$", "solution": "我们从贝叶斯法则开始，该法则指出对于任何输入 $x$ 和类别 $k$：\n$$\np(y=k \\mid x) = \\frac{p(x \\mid y=k)\\,p(y=k)}{p(x)} \\propto p(x \\mid y=k)\\,p(y=k).\n$$\n在许多用于多类别分类的判别模型中，模型会生成一个 logit 向量 $z(x) \\in \\mathbb{R}^K$。对 logits 的一种典型概率解释是，它们通过 softmax 函数参数化一个分类分布，\n$$\np_{k}(x) = \\frac{\\exp\\big(z_k(x)\\big)}{\\sum_{j=1}^{K} \\exp\\big(z_j(x)\\big)}.\n$$\n对于未经显式先验校正训练的模型，logits $z_k(x)$ 通常充当类别条件分数的比例代理（例如，作为 $\\log p(x \\mid y=k)$ 的仿射代理），而忽略了先验 $p(y=k)$。为了融合类别先验，我们必须构造一个变换后的分数 $\\tilde{z}_k(x)$，其指数与后验概率成正比。根据贝叶斯法则，\n$$\np(y=k \\mid x) \\propto p(x \\mid y=k)\\,p(y=k).\n$$\n如果 $z_k(x)$ 与 $\\log p(x \\mid y=k)$ 在一个不依赖于 $x$ 的可加常数下成比例，那么在指数内加上 $\\log p(y=k)$ 会使分数与后验概率对齐，即，\n$$\n\\exp\\big(\\tilde{z}_k(x)\\big) \\propto \\exp\\big(z_k(x)\\big)\\,p(y=k),\n$$\n这意味着 logit 变换为\n$$\n\\tilde{z}_k(x) = z_k(x) + \\log p(y=k) + c,\n$$\n其中 $c$ 是任何不依赖于 $k$ 的常数；softmax 归一化使得 $c$ 无关紧要。因此，满足贝叶斯法则的调整后概率可以通过对 $\\tilde{z}(x)$ 应用 softmax 获得：\n$$\nq_{k}(x) = \\frac{\\exp\\big(z_k(x) + \\log \\pi_k\\big)}{\\sum_{j=1}^{K} \\exp\\big(z_j(x) + \\log \\pi_j\\big)},\n$$\n其中 $\\pi_k = p(y=k)$ 表示类别先验。\n\n我们现在评估这种 logit 调整对两个属性的影响。\n\n排名：top-1 决策规则预测 $\\arg\\max_k p_k(x)$（未经调整）或 $\\arg\\max_k q_k(x)$（经过调整）。向所有 logits 添加相同的常数不会改变 argmax，但添加依赖于类别的常数 $\\log \\pi_k$ 可以改变类别之间的排序。当先验是均匀的，即对所有 $k$ 都有 $\\pi_k = \\tfrac{1}{K}$ 时，会出现一个边界情况，在此情况下，所有 $k$ 的 $\\log \\pi_k$ 都相等，因此 argmax 与未经调整的情况相同。更一般地，在不平衡的情况下，当未经调整的分数尚未编码先验时，调整后的 argmax 可能会偏向于频繁的类别；这可能会根据数据分布和原始 logits 的充分性而改变 top-1 准确率。\n\n校准：一种常见的校准指标是平均负对数似然 (NLL)，\n$$\n\\text{NLL} = -\\frac{1}{n} \\sum_{i=1}^{n} \\log r_{i,y_i},\n$$\n其中 $r_{i,k}$ 表示样本 $i$ 上类别 $k$ 的预测概率，而 $y_i$ 是真实标签。如果未经调整的 logits 近似地反映了没有先验的类别条件证据，那么注入 $\\log \\pi_k$ 会使模型更接近贝叶斯法则所暗示的后验分布，这通常会改善不平衡数据上的校准。然而，对 NLL 的影响取决于 logits 的质量和指定先验的正确性。\n\n每个测试用例的算法步骤：\n1. 通过对 $Z$ 的每一行应用数值稳定的 softmax 来计算未经调整的概率 $p_{i,k}$。\n2. 计算调整后的 logits $\\tilde{z}_{i,k} = z_{i,k} + \\log \\pi_k$，然后通过 softmax 计算调整后的概率 $q_{i,k}$。\n3. 计算 top-1 准确率：\n   $$\n   \\text{acc}_{\\text{unadj}} = \\frac{1}{n}\\sum_{i=1}^{n} \\mathbf{1}\\!\\left(\\arg\\max_k p_{i,k} = y_i\\right),\\quad\n   \\text{acc}_{\\text{adj}} = \\frac{1}{n}\\sum_{i=1}^{n} \\mathbf{1}\\!\\left(\\arg\\max_k q_{i,k} = y_i\\right).\n   $$\n4. 计算平均 NLL：\n   $$\n   \\text{NLL}_{\\text{unadj}} = -\\frac{1}{n}\\sum_{i=1}^{n} \\log p_{i,y_i},\\quad\n   \\text{NLL}_{\\text{adj}} = -\\frac{1}{n}\\sum_{i=1}^{n} \\log q_{i,y_i}.\n   $$\n5. 报告差异 $a = \\text{acc}_{\\text{adj}} - \\text{acc}_{\\text{unadj}}$ 和 $\\ell = \\text{NLL}_{\\text{adj}} - \\text{NLL}_{\\text{unadj}}$，保留六位小数。\n\n所提供测试套件的覆盖范围：\n- 测试用例 $1$ 是一个普遍的不平衡场景，其中先验偏向于一个类别；这测试了典型的长尾行为。\n- 测试用例 $2$ 使用均匀先验，这是一个边界情况，在此情况下，排名应该是不变的，校准在数值公差范围内也应保持不变；这验证了对添加与类别无关的常数的不变性。\n- 测试用例 $3$ 表现出极端的不平衡；当一个罕见类别获得较大的未经调整的 logits 时，这会对调整及其对排名和校准的影响进行压力测试。\n- 测试用例 $4$ 是二元的，并突出了先验如何在对数几率中引入有效的阈值偏移，这可以改变 top-1 决策，同时也会影响 NLL。\n\n程序将计算所有测试用例所要求的差异，并将其打印为单个列表 $[a_1,\\ell_1,a_2,\\ell_2,a_3,\\ell_3,a_4,\\ell_4]$，每个值都保留六位小数，并表示为不带百分号的小数。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Execution environment: Python 3.12, numpy 1.23.5, scipy 1.11.4 (not used).\nimport numpy as np\n\ndef softmax_rows(logits: np.ndarray) - np.ndarray:\n    \"\"\"\n    Numerically stable softmax applied row-wise.\n    logits: shape (n, K)\n    returns: probabilities, shape (n, K)\n    \"\"\"\n    # Subtract row-wise max for numerical stability.\n    z = logits - np.max(logits, axis=1, keepdims=True)\n    np.exp(z, out=z)\n    z_sum = np.sum(z, axis=1, keepdims=True)\n    # Avoid division by zero in degenerate cases.\n    z_sum = np.where(z_sum == 0.0, 1.0, z_sum)\n    return z / z_sum\n\ndef top1_accuracy(probs: np.ndarray, y: np.ndarray) - float:\n    preds = np.argmax(probs, axis=1)\n    return float(np.mean(preds == y))\n\ndef mean_nll(probs: np.ndarray, y: np.ndarray) - float:\n    # Clip to avoid log(0).\n    eps = 1e-15\n    p_true = probs[np.arange(probs.shape[0]), y]\n    p_true = np.clip(p_true, eps, 1.0)\n    return float(-np.mean(np.log(p_true)))\n\ndef logit_adjusted_probs(logits: np.ndarray, pi: np.ndarray) - np.ndarray:\n    \"\"\"\n    Apply Bayes-inspired logit adjustment: add log(pi_k) to class k logits.\n    \"\"\"\n    # Ensure pi is a proper distribution and strictly positive.\n    pi = np.asarray(pi, dtype=float)\n    pi_sum = np.sum(pi)\n    if pi_sum = 0.0:\n        raise ValueError(\"Class prior vector must have positive sum.\")\n    pi = pi / pi_sum\n    if np.any(pi = 0.0):\n        raise ValueError(\"Class priors must be strictly positive.\")\n    adjusted = logits + np.log(pi)[None, :]\n    return softmax_rows(adjusted)\n\ndef evaluate_case(Z: np.ndarray, y: np.ndarray, pi: np.ndarray):\n    # Unadjusted probabilities\n    p = softmax_rows(Z)\n    # Adjusted probabilities\n    q = logit_adjusted_probs(Z, pi)\n    # Metrics\n    acc_unadj = top1_accuracy(p, y)\n    acc_adj = top1_accuracy(q, y)\n    nll_unadj = mean_nll(p, y)\n    nll_adj = mean_nll(q, y)\n    # Differences\n    a = acc_adj - acc_unadj\n    l = nll_adj - nll_unadj\n    return a, l\n\ndef solve():\n    # Define the test cases from the problem statement.\n\n    # Test case 1\n    Z1 = np.array([\n        [2.5, 1.0, 0.0],\n        [0.0, 1.2, 1.0],\n        [1.2, 0.2, 0.1],\n        [-1.0, 0.0, 3.0],\n        [0.5, 0.4, 0.3]\n    ], dtype=float)\n    y1 = np.array([0, 1, 0, 2, 0], dtype=int)\n    pi1 = np.array([0.7, 0.2, 0.1], dtype=float)\n\n    # Test case 2 (uniform prior)\n    Z2 = np.array([\n        [2.5, 1.0, 0.0],\n        [0.0, 1.2, 1.0],\n        [1.2, 0.2, 0.1],\n        [-1.0, 0.0, 3.0],\n        [0.5, 0.4, 0.3]\n    ], dtype=float)\n    y2 = np.array([2, 2, 1, 2, 0], dtype=int)\n    pi2 = np.array([1/3, 1/3, 1/3], dtype=float)\n\n    # Test case 3 (extreme imbalance)\n    Z3 = np.array([\n        [4.0, 3.9, 5.5],\n        [1.0, 2.0, 3.0],\n        [3.0, 0.0, 0.5],\n        [0.5, 0.6, 0.7]\n    ], dtype=float)\n    y3 = np.array([2, 2, 0, 1], dtype=int)\n    pi3 = np.array([0.95, 0.04, 0.01], dtype=float)\n\n    # Test case 4 (binary)\n    Z4 = np.array([\n        [2.0, 1.8],\n        [0.1, 0.2],\n        [-0.5, -0.6],\n        [1.0, 2.0],\n        [0.0, 0.0]\n    ], dtype=float)\n    y4 = np.array([0, 1, 0, 1, 0], dtype=int)\n    pi4 = np.array([0.9, 0.1], dtype=float)\n\n    test_cases = [\n        (Z1, y1, pi1),\n        (Z2, y2, pi2),\n        (Z3, y3, pi3),\n        (Z4, y4, pi4),\n    ]\n\n    results = []\n    for Z, y, pi in test_cases:\n        a, l = evaluate_case(Z, y, pi)\n        # Round to six decimals as required\n        results.append(round(a + 0.0, 6))\n        results.append(round(l + 0.0, 6))\n\n    # Final print statement in the exact required format.\n    # Ensure each number has up to six decimal places formatting.\n    formatted = []\n    for val in results:\n        # Format with exactly six decimal places\n        formatted.append(f\"{val:.6f}\")\n    print(f\"[{','.join(formatted)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3127123"}]}