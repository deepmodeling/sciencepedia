{"hands_on_practices": [{"introduction": "中心极限定理 (Central Limit Theorem, CLT) 不僅僅是一个抽象的理论概念，它更是实践数据分析中的一个强大工具，尤其是在通过模拟来量化不确定性时。这个练习将指导您完成一个计算任务：通过蒙特卡洛模拟来估计一个机器学习模型在随机扰动下的“对抗性损失”和“鲁棒准确率”[@problem_id:3171846]。通过编写代码来生成样本、计算样本均值和方差，并应用中心极限定理构建置信区间，您将亲身体验如何为那些难以通过解析方法计算的量提供一个可靠的估计范围。这项动手实践将巩固您对中心极限定理如何连接理论概率与数据驱动估计的理解。", "problem": "考虑一个固定向量 $w \\in \\mathbb{R}^d$、一个标量间隔 $m \\in \\mathbb{R}$ 以及随机扰动 $\\delta \\sim \\mathcal{N}(0, \\sigma^2 I_d)$，其中 $I_d$ 是 $d \\times d$ 的单位矩阵。将在随机扰动下的对抗性铰链损失定义为\n$$\nL_{\\text{adv}}(\\delta) = \\max\\left(0,\\, m - w^\\top \\delta\\right).\n$$\n令 $\\{ \\delta_i \\}_{i=1}^n$ 为从 $\\mathcal{N}(0, \\sigma^2 I_d)$ 中抽取的独立同分布（i.i.d.）样本，并将平均对抗性损失定义为样本均值\n$$\n\\overline{L}_{\\text{adv}} = \\frac{1}{n} \\sum_{i=1}^{n} L_{\\text{adv}}(\\delta_i).\n$$\n将在随机扰动下的鲁棒准确率定义为在随机抽取 $\\delta$ 的情况下铰链损失恰好为零的概率，这等价于在扰动下间隔未被破坏的概率：\n$$\np = \\mathbb{P}\\left( L_{\\text{adv}}(\\delta) = 0 \\right) = \\mathbb{P}\\left( w^\\top \\delta \\ge m \\right).\n$$\n令 $Y_i = \\mathbb{I}\\{ L_{\\text{adv}}(\\delta_i) = 0 \\}$ 为第 $i$ 个扰动未造成破坏的指示函数，并令 $\\widehat{p} = \\frac{1}{n} \\sum_{i=1}^{n} Y_i$ 为未破坏的样本比例。\n\n您的任务是使用样本均值、方差和独立性的基本定义，以及针对独立同分布随机变量的中心极限定理（CLT），构建一个程序，该程序能够：\n- 生成指定的扰动测试套件，\n- 使用 CLT 计算 $\\overline{L}_{\\text{adv}}$ 及其双侧 $95\\%$ 置信区间，\n- 使用应用于伯努利随机变量的 CLT 计算 $\\widehat{p}$ 及 $p$ 的双侧 $95\\%$ 置信区间，\n- 将每个测试用例的结果汇总为一个包含六个浮点数的列表：\n$$\n\\left[\\overline{L}_{\\text{adv}},\\ \\text{CI}_{\\text{low}}(\\overline{L}_{\\text{adv}}),\\ \\text{CI}_{\\text{high}}(\\overline{L}_{\\text{adv}}),\\ \\widehat{p},\\ \\text{CI}_{\\text{low}}(p),\\ \\text{CI}_{\\text{high}}(p)\\right],\n$$\n其中 $\\text{CI}_{\\text{low}}$ 和 $\\text{CI}_{\\text{high}}$ 分别是置信区间的下界和上界。\n\n仅使用以下基本依据：\n- 样本均值和样本方差的定义，\n- 独立性和同分布的定义，\n- 针对具有有限方差的独立同分布随机变量的中心极限定理（CLT）陈述。\n\n除了 CLT 和基本样本统计量所蕴含的内容之外，您不得使用任何针对正态分布的闭式概率表达式或任何预先推导的公式。\n\n为保证数值可复现性，请对每个测试用例使用带有指定种子的伪随机数生成器。\n\n测试套件：\n- 用例 $1$ (一般理想情况)：$d = 5$，$w = [1.0,\\ -0.5,\\ 0.3,\\ 0.8,\\ -0.2]$，$m = 0.4$，$\\sigma = 0.5$，$n = 5000$，种子 $= 12345$。\n- 用例 $2$ (边界情况，小样本低鲁棒准确率)：$d = 10$，$w = [0.3,\\ -0.1,\\ 0.2,\\ -0.4,\\ 0.5,\\ -0.7,\\ 0.9,\\ -0.2,\\ 0.1,\\ -0.3]$，$m = 0.6$，$\\sigma = 0.1$，$n = 30$，种子 $= 2025$。\n- 用例 $3$ (边界情况，小样本高鲁棒准确率)：$d = 10$，$w = [0.3,\\ -0.1,\\ 0.2,\\ -0.4,\\ 0.5,\\ -0.7,\\ 0.9,\\ -0.2,\\ 0.1,\\ -0.3]$，$m = -0.6$，$\\sigma = 0.1$，$n = 30$，种子 $= 2026$。\n- 用例 $4$ (高维度，大样本)：$d = 50$，$w_j = (-1)^j \\left(0.1 + 0.02 j\\right)$ 对于 $j = 1,2,\\dots,50$，$m = 0.5$，$\\sigma = 0.05$，$n = 10000$，种子 $= 9876$。\n\n计算要求和输出规范：\n- 对于每个用例，计算样本均值 $\\overline{L}_{\\text{adv}}$、$\\{L_{\\text{adv}}(\\delta_i)\\}$ 的无偏样本方差 $S^2$，并使用 CLT 构建双侧 $95\\%$ 置信区间：\n$$\n\\overline{L}_{\\text{adv}} \\pm z_{0.975}\\ \\sqrt{\\frac{S^2}{n}},\n$$\n其中 $z_{0.975}$ 是标准正态分布的 $0.975$ 分位数。使用 $z_{0.975} \\approx 1.959964$。\n- 对于鲁棒准确率，计算样本比例 $\\widehat{p}$ 及其双侧 $95\\%$ CLT 区间：\n$$\n\\widehat{p} \\pm z_{0.975}\\ \\sqrt{\\frac{\\widehat{p}(1-\\widehat{p})}{n}},\n$$\n然后将边界裁剪以确保其位于 $[0,1]$ 区间内。\n- 您的程序应生成单行输出，其中包含所有四个测试用例的结果，格式为由方括号括起来的、逗号分隔的列表的列表。每个浮点数必须四舍五入到六位小数。例如，总体格式应为\n$$\n\\left[\\left[r_{1,1}, r_{1,2}, \\dots, r_{1,6}\\right], \\left[r_{2,1}, \\dots, r_{2,6}\\right], \\left[r_{3,1}, \\dots, r_{3,6}\\right], \\left[r_{4,1}, \\dots, r_{4,6}\\right]\\right],\n$$\n其中每个 $r_{i,j}$ 是一个四舍五入到六位小数的浮点数。\n\n不涉及物理单位或角度。所有数值量必须以小数形式表示。程序必须是完整且可运行的，无需任何用户输入、外部文件或网络访问。", "solution": "该问题要求构建一个计算程序，以基于蒙特卡洛模拟来估计两个量及其置信区间。该程序的基础在于抽样分布和中心极限定理（CLT）的原理。\n\n首先，我们对感兴趣的随机变量进行形式化。扰动向量 $\\delta$ 是一个从多元正态分布 $\\delta \\sim \\mathcal{N}(0, \\sigma^2 I_d)$ 中抽取的 $d$ 维随机变量，其中 $I_d$ 是 $d \\times d$ 的单位矩阵。该扰动在一个固定向量 $w \\in \\mathbb{R}^d$ 上的投影定义了一个新的一维随机变量 $Z = w^\\top \\delta$。由于 $Z$ 是独立高斯随机变量的线性组合，它本身也是一个高斯随机变量。其均值为 $\\mathbb{E}[Z] = \\mathbb{E}[w^\\top \\delta] = w^\\top \\mathbb{E}[\\delta] = w^\\top 0 = 0$。其方差为 $\\text{Var}(Z) = \\text{Var}(w^\\top \\delta) = w^\\top \\text{Cov}(\\delta) w = w^\\top (\\sigma^2 I_d) w = \\sigma^2 w^\\top w = \\sigma^2 \\|w\\|_2^2$。因此，$Z \\sim \\mathcal{N}(0, \\sigma^2 \\|w\\|_2^2)$。\n\n该问题定义了从 $Z$ 导出的两个关键量。第一，对抗性铰链损失，$L_{\\text{adv}}(\\delta) = \\max(0, m - w^\\top \\delta) = \\max(0, m - Z)$。这是随机变量 $Z$ 的一个变换。第二，鲁棒准确率，$p = \\mathbb{P}( L_{\\text{adv}}(\\delta) = 0 ) = \\mathbb{P}(m - w^\\top \\delta \\le 0) = \\mathbb{P}(Z \\ge m)$。\n\n期望损失 $\\mathbb{E}[L_{\\text{adv}}]$ 或概率 $p$ 的解析计算需要对 $Z$ 的概率密度函数进行积分，而这种方法是问题陈述所禁止的。因此，我们必须依赖蒙特卡洛模拟和中心极限定理。模拟过程包括从分布 $\\mathcal{N}(0, \\sigma^2 I_d)$ 中生成 $n$ 个独立同分布（i.i.d.）样本 $\\{\\delta_i\\}_{i=1}^n$。对于每个样本 $\\delta_i$，我们计算相应的标量投影 $z_i = w^\\top \\delta_i$。这给了我们一组来自 $Z$ 分布的 i.i.d. 样本 $\\{z_i\\}_{i=1}^n$。从这些样本中，我们生成两组 i.i.d. 随机变量：一组铰链损失 $\\{L_i\\}_{i=1}^n$，其中 $L_i = \\max(0, m - z_i)$，以及一组指示变量 $\\{Y_i\\}_{i=1}^n$，其中 $Y_i = \\mathbb{I}\\{z_i \\ge m\\}$。每个 $Y_i$ 是一个成功概率为 $p$ 的伯努利随机变量。任务的核心是估计 $L_{\\text{adv}}$ 和 $Y$ 的总体均值，并使用 CLT 为这些均值构建置信区间。\n\n为了估计平均对抗性损失及其置信区间，令 $\\mu_L = \\mathbb{E}[L_{\\text{adv}}]$ 为真实的平均对抗性损失。样本均值 $\\overline{L}_{\\text{adv}} = \\frac{1}{n} \\sum_{i=1}^{n} L_i$ 是 $\\mu_L$ 的一个无偏估计量。中心极限定理指出，对于足够大的样本量 $n$，样本均值的分布近似为正态分布：\n$$\n\\overline{L}_{\\text{adv}} \\approx \\mathcal{N}\\left(\\mu_L, \\frac{\\sigma_L^2}{n}\\right)\n$$\n其中 $\\sigma_L^2 = \\text{Var}(L_{\\text{adv}})$ 是损失的真实方差。由于 $\\sigma_L^2$ 未知，我们使用无偏样本方差 $S^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (L_i - \\overline{L}_{\\text{adv}})^2$ 来估计它。量 $\\frac{\\overline{L}_{\\text{adv}} - \\mu_L}{S/\\sqrt{n}}$ 近似服从标准正态分布 $\\mathcal{N}(0,1)$。为了构建 $\\mu_L$ 的 $95\\%$ 置信区间，我们找到值 $z_{0.975}$ 使得 $\\mathbb{P}(-z_{0.975} \\le \\mathcal{N}(0,1) \\le z_{0.975}) = 0.95$。这给出了区间 $\\overline{L}_{\\text{adv}} \\pm z_{0.975} \\frac{S}{\\sqrt{n}}$。使用给定的值 $z_{0.975} \\approx 1.959964$，置信区间的边界为 $\\text{CI}_{\\text{low}}(\\overline{L}_{\\text{adv}}) = \\overline{L}_{\\text{adv}} - 1.959964 \\cdot \\sqrt{\\frac{S^2}{n}}$ 和 $\\text{CI}_{\\text{high}}(\\overline{L}_{\\text{adv}}) = \\overline{L}_{\\text{adv}} + 1.959964 \\cdot \\sqrt{\\frac{S^2}{n}}$。\n\n为了估计鲁棒准确率及其置信区间，我们注意到 $p = \\mathbb{P}(Z \\ge m)$。变量 $Y_i = \\mathbb{I}\\{z_i \\ge m\\}$ 是一个成功概率为 $p$ 的伯努利试验。样本比例 $\\widehat{p} = \\frac{1}{n} \\sum_{i=1}^{n} Y_i$ 是这些伯努利变量的样本均值，并作为 $p$ 的无偏估计量。CLT 以棣莫弗-拉普拉斯定理的形式表明，对于大的 $n$，$\\widehat{p} \\approx \\mathcal{N}\\left(p, \\frac{p(1-p)}{n}\\right)$。$\\widehat{p}$ 的标准误差是 $\\sqrt{\\frac{p(1-p)}{n}}$。由于 $p$ 未知，我们代入其估计值 $\\widehat{p}$ 以获得估计的标准误差 $\\sqrt{\\frac{\\widehat{p}(1-\\widehat{p})}{n}}$。标准化后的量 $\\frac{\\widehat{p} - p}{\\sqrt{\\widehat{p}(1-\\widehat{p})/n}}$ 近似服从 $\\mathcal{N}(0,1)$。这导出了 $p$ 的瓦尔德型 $95\\%$ 置信区间，由 $\\widehat{p} \\pm z_{0.975} \\sqrt{\\frac{\\widehat{p}(1-\\widehat{p})}{n}}$ 给出。初始边界为 $\\text{CI}_{\\text{low}}'(p) = \\widehat{p} - 1.959964 \\cdot \\sqrt{\\frac{\\widehat{p}(1-\\widehat{p})}{n}}$ 和 $\\text{CI}_{\\text{high}}'(p) = \\widehat{p} + 1.959964 \\cdot \\sqrt{\\frac{\\widehat{p}(1-\\widehat{p})}{n}}$。由于 $p$ 是一个概率，它必须在 $[0, 1]$ 范围内。我们裁剪边界以确保它们落在此范围内：$\\text{CI}_{\\text{low}}(p) = \\max(0, \\text{CI}_{\\text{low}}'(p))$ 和 $\\text{CI}_{\\text{high}}(p) = \\min(1, \\text{CI}_{\\text{high}}'(p))$。这完成了理论框架。实现将针对每个测试用例遵循这些步骤。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy is not used as per the problem description.\n\ndef solve():\n    \"\"\"\n    Solves the problem by iterating through test cases, performing Monte Carlo\n    simulations to compute adversarial hinge loss and robust accuracy, and\n    calculating their 95% confidence intervals using the Central Limit Theorem.\n    \"\"\"\n    test_cases = [\n        {\n            \"d\": 5,\n            \"w\": np.array([1.0, -0.5, 0.3, 0.8, -0.2]),\n            \"m\": 0.4,\n            \"sigma\": 0.5,\n            \"n\": 5000,\n            \"seed\": 12345,\n        },\n        {\n            \"d\": 10,\n            \"w\": np.array([0.3, -0.1, 0.2, -0.4, 0.5, -0.7, 0.9, -0.2, 0.1, -0.3]),\n            \"m\": 0.6,\n            \"sigma\": 0.1,\n            \"n\": 30,\n            \"seed\": 2025,\n        },\n        {\n            \"d\": 10,\n            \"w\": np.array([0.3, -0.1, 0.2, -0.4, 0.5, -0.7, 0.9, -0.2, 0.1, -0.3]),\n            \"m\": -0.6,\n            \"sigma\": 0.1,\n            \"n\": 30,\n            \"seed\": 2026,\n        },\n        {\n            \"d\": 50,\n            \"w\": np.array([((-1)**(j + 1)) * (0.1 + 0.02 * (j + 1)) for j in range(50)]),\n            \"m\": 0.5,\n            \"sigma\": 0.05,\n            \"n\": 10000,\n            \"seed\": 9876,\n        },\n    ]\n\n    all_results = []\n    z_crit = 1.959964\n\n    for case in test_cases:\n        d, w, m, sigma, n, seed = (\n            case[\"d\"],\n            case[\"w\"],\n            case[\"m\"],\n            case[\"sigma\"],\n            case[\"n\"],\n            case[\"seed\"],\n        )\n\n        # Initialize the random number generator for reproducibility\n        rng = np.random.default_rng(seed)\n\n        # Generate n i.i.d. samples of perturbations\n        # delta_i ~ N(0, sigma^2 * I_d)\n        perturbations = rng.standard_normal(size=(n, d)) * sigma\n\n        # Compute the projections w^T * delta_i for all samples\n        projections = perturbations @ w\n\n        # --- Adversarial Loss Calculation ---\n        \n        # Compute the adversarial hinge loss for each sample\n        # L_adv(delta_i) = max(0, m - w^T * delta_i)\n        losses = np.maximum(0, m - projections)\n\n        # Compute the sample mean of the adversarial loss\n        mean_loss = np.mean(losses)\n\n        # Compute the unbiased sample variance of the loss (ddof=1 for n-1 denominator)\n        if n > 1:\n            var_loss = np.var(losses, ddof=1)\n        else:\n            var_loss = 0.0 # Variance is zero for a single sample\n\n        # Compute the standard error of the mean loss\n        se_loss = np.sqrt(var_loss / n) if n > 0 else 0.0\n\n        # Compute the 95% confidence interval for the mean loss\n        half_width_loss = z_crit * se_loss\n        ci_low_loss = mean_loss - half_width_loss\n        ci_high_loss = mean_loss + half_width_loss\n\n        # --- Robust Accuracy Calculation ---\n\n        # Compute the indicator for robust accuracy for each sample\n        # Y_i = I{w^T * delta_i >= m}\n        indicators = (projections >= m).astype(float)\n\n        # Compute the sample proportion (estimator for p)\n        p_hat = np.mean(indicators)\n\n        # Compute the standard error for the proportion\n        # The variance of the estimator p_hat is p(1-p)/n, estimated by p_hat(1-p_hat)/n\n        se_p = np.sqrt(p_hat * (1 - p_hat) / n) if n > 0 else 0.0\n\n        # Compute the 95% confidence interval for p\n        half_width_p = z_crit * se_p\n        ci_low_p = p_hat - half_width_p\n        ci_high_p = p_hat + half_width_p\n\n        # Clip the confidence interval for p to the valid range [0, 1]\n        ci_low_p_clipped = np.clip(ci_low_p, 0.0, 1.0)\n        ci_high_p_clipped = np.clip(ci_high_p, 0.0, 1.0)\n        \n        # Aggregate and round results to six decimal places\n        case_results = [\n            round(mean_loss, 6),\n            round(ci_low_loss, 6),\n            round(ci_high_loss, 6),\n            round(p_hat, 6),\n            round(ci_low_p_clipped, 6),\n            round(ci_high_p_clipped, 6),\n        ]\n        all_results.append(case_results)\n\n    # Format the final output string as a list of lists without spaces\n    output_str = str(all_results).replace(\" \", \"\")\n    print(output_str)\n\nsolve()\n```", "id": "3171846"}, {"introduction": "在将理论应用于实践时，我们经常会遇到更复杂的场景，例如分析现代深度学习算法的统计特性。本练习以批量归一化 (Batch Normalization) 为例，这是一个在神经网络训练中广泛使用的关键技术，它依赖于从数据的小批量 (mini-batches) 中计算出的统计量[@problem_id:3171886]。您将不再是简单地对原始数据应用中心极限定理，而是要将其应用于跨多个小批量计算出的 *统计量的均值*（即樣本均值的均值和樣本方差的均值）。通过推导这些聚合统计量的渐近分布，您将学会如何从理论层面分析复杂算法的性质，并为其参数的稳定性提供有理有据的量化保证。", "problem": "一个深度网络中的单个隐藏层使用了批量归一化（BN）。设 $X$ 表示某个固定通道上的标量激活前值，其模型为来自正态分布 $\\mathcal{N}(\\mu, \\sigma^{2})$ 的独立同分布（i.i.d.）样本。BN 观察 $B$ 个独立的小批量，每个小批量的大小为 $n$，并对每个批次 $b \\in \\{1, \\dots, B\\}$ 计算其批次内统计量：样本均值 $\\hat{\\mu}_{b}$ 和无偏样本方差 $\\hat{\\sigma}_{b}^{2}$。跨批次的平均BN统计量定义如下\n$$\\bar{\\mu}_{B} = \\frac{1}{B} \\sum_{b=1}^{B} \\hat{\\mu}_{b}, \\qquad \\bar{\\sigma}_{B}^{2} = \\frac{1}{B} \\sum_{b=1}^{B} \\hat{\\sigma}_{b}^{2}.$$\n从样本均值和样本方差的基本定义出发，并仅使用中心极限定理（CLT），推导当 $B$ 增大时 $\\bar{\\mu}_{B}$ 和 $\\bar{\\sigma}_{B}^{2}$ 的渐近抽样分布，并使用这些分布来论证运行平均值的基于正态性的不确定性界限的合理性。然后，对于一个BN层，其参数为 $n = 128$，$B = 50$，$\\mu = 0.2$ 和 $\\sigma = 0.9$，假设我们将其稳健的运行平均值设置在 $\\bar{\\mu}_{B}$ 和 $\\bar{\\sigma}_{B}^{2}$ 的期望值处，并为每个平均值附加置信水平为 $0.95$ 的对称不确定性界限。定义界限半径 $R$ 为 $\\bar{\\mu}_{B}$ 和 $\\bar{\\sigma}_{B}^{2}$ 的两个覆盖率为 $0.95$ 的基于正态分布的区间中较大的那个半宽度。计算 $R$ 并将答案四舍五入到四位有效数字。将最终值表示为无单位的纯数字。", "solution": "问题要求推导平均批量归一化（BN）统计量 $\\bar{\\mu}_{B}$ 和 $\\bar{\\sigma}_{B}^{2}$ 的渐近抽样分布，然后计算一个特定的不确定性界限半径 $R$。验证问题陈述的有效性是强制性的第一步。\n\n### 问题验证\n\n**步骤1：提取已知条件**\n- 激活前值 $X$ 被建模为来自正态分布 $X \\sim \\mathcal{N}(\\mu, \\sigma^{2})$ 的独立同分布（i.i.d.）样本。\n- 有 $B$ 个独立的小批量，每个小批量的大小为 $n$。\n- 对于每个批次 $b \\in \\{1, \\dots, B\\}$，批次内统计量是样本均值 $\\hat{\\mu}_{b}$ 和无偏样本方差 $\\hat{\\sigma}_{b}^{2}$。\n- 平均BN统计量定义为 $\\bar{\\mu}_{B} = \\frac{1}{B} \\sum_{b=1}^{B} \\hat{\\mu}_{b}$ 和 $\\bar{\\sigma}_{B}^{2} = \\frac{1}{B} \\sum_{b=1}^{B} \\hat{\\sigma}_{b}^{2}$。\n- 渐近抽样分布的推导必须通过调用中心极限定理（CLT）来完成。\n- 用于计算的数值：$n = 128$，$B = 50$，$\\mu = 0.2$，$\\sigma = 0.9$。\n- 不确定性界限的置信水平为 $0.95$。\n- 界限半径 $R$ 是 $\\bar{\\mu}_{B}$ 和 $\\bar{\\sigma}_{B}^{2}$ 的两个覆盖率为 $0.95$ 的基于正态分布的区间中较大的半宽度。\n- 最终答案必须四舍五入到四位有效数字。\n\n**步骤2：使用提取的已知条件进行验证**\n该问题具有科学依据，提法明确且客观。它探讨了批量归一化（深度学习中的一种标准技术）中使用的估计量的统计特性。该问题基于数理统计的基本原理，即抽样分布和中心极限定理。所有定义和参数均已提供，从而可以得出一个唯一且可验证的解。使用CLT的约束是统计问题中的一个标准指令，用以证明对样本均值使用正态近似的合理性，这在这里是合适的。该问题在数学上和科学上都是合理的。\n\n**步骤3：结论与行动**\n该问题被认定为有效。将提供完整的解答。\n\n### 解答\n\n解答分为三个部分：推导渐近抽样分布，论证基于正态性的界限的合理性，以及计算界限半径 $R$ 的数值。\n\n**1. $\\bar{\\mu}_{B}$ 的渐近抽样分布**\n\n设 $X_{i,b}$ 为第 $b$ 个小批量中的第 $i$ 个激活前值，其中 $i \\in \\{1, \\dots, n\\}$ 且 $b \\in \\{1, \\dots, B\\}$。根据假设，$X_{i,b} \\sim \\mathcal{N}(\\mu, \\sigma^2)$ 是独立同分布的。\n\n对于单个小批量 $b$，样本均值为 $\\hat{\\mu}_{b} = \\frac{1}{n} \\sum_{i=1}^{n} X_{i,b}$。由于独立正态随机变量的和也服从正态分布，因此 $\\hat{\\mu}_{b}$ 精确地服从正态分布。其期望和方差为：\n$$E[\\hat{\\mu}_{b}] = E\\left[\\frac{1}{n} \\sum_{i=1}^{n} X_{i,b}\\right] = \\frac{1}{n} \\sum_{i=1}^{n} E[X_{i,b}] = \\frac{1}{n} (n\\mu) = \\mu$$\n$$Var(\\hat{\\mu}_{b}) = Var\\left(\\frac{1}{n} \\sum_{i=1}^{n} X_{i,b}\\right) = \\frac{1}{n^2} \\sum_{i=1}^{n} Var(X_{i,b}) = \\frac{1}{n^2} (n\\sigma^2) = \\frac{\\sigma^2}{n}$$\n所以，对每个批次 $b$，样本均值是一个随机变量 $\\hat{\\mu}_{b} \\sim \\mathcal{N}(\\mu, \\sigma^2/n)$。\n\n平均统计量 $\\bar{\\mu}_{B}$ 是 $B$ 个独立同分布随机变量 $\\hat{\\mu}_{1}, \\dots, \\hat{\\mu}_{B}$ 的样本均值。中心极限定理（CLT）指出，对于大量的独立同分布随机变量，其样本均值近似服从正态分布。将中心极限定理应用于序列 $\\{\\hat{\\mu}_b\\}_{b=1}^B$，当 $B \\to \\infty$ 时，$\\bar{\\mu}_{B}$ 的渐近分布为：\n$$\\bar{\\mu}_{B} \\approx \\mathcal{N}\\left(E[\\hat{\\mu}_{b}], \\frac{Var(\\hat{\\mu}_{b})}{B}\\right)$$\n代入 $\\hat{\\mu}_{b}$ 的矩：\n$$\\bar{\\mu}_{B} \\approx \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2/n}{B}\\right) = \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{nB}\\right)$$\n（注意：由于每个 $\\hat{\\mu}_b$ 本身就服从正态分布，它们的均值 $\\bar{\\mu}_B$ 精确地服从正态分布，但题目要求通过中心极限定理进行论证，我们已经提供了该论证。）\n\n**2. $\\bar{\\sigma}_{B}^{2}$ 的渐近抽样分布**\n\n对于单个小批量 $b$，无偏样本方差为 $\\hat{\\sigma}_{b}^{2} = \\frac{1}{n-1} \\sum_{i=1}^{n} (X_{i,b} - \\hat{\\mu}_{b})^2$。\n对于来自正态分布的数据，量 $\\frac{(n-1)\\hat{\\sigma}_{b}^{2}}{\\sigma^2}$ 服从自由度为 $n-1$ 的卡方分布，即 $\\frac{(n-1)\\hat{\\sigma}_{b}^{2}}{\\sigma^2} \\sim \\chi_{n-1}^2$。\n\n由此，我们可以求出 $\\hat{\\sigma}_{b}^{2}$ 的期望和方差。一个 $\\chi_k^2$ 随机变量的均值和方差分别为 $k$ 和 $2k$。\n$$E[\\hat{\\sigma}_{b}^{2}] = E\\left[\\frac{\\sigma^2}{n-1} \\chi_{n-1}^2\\right] = \\frac{\\sigma^2}{n-1} E[\\chi_{n-1}^2] = \\frac{\\sigma^2}{n-1} (n-1) = \\sigma^2$$\n这证实了 $\\hat{\\sigma}_{b}^{2}$ 是 $\\sigma^2$ 的一个无偏估计量。\n$$Var(\\hat{\\sigma}_{b}^{2}) = Var\\left(\\frac{\\sigma^2}{n-1} \\chi_{n-1}^2\\right) = \\left(\\frac{\\sigma^2}{n-1}\\right)^2 Var(\\chi_{n-1}^2) = \\frac{\\sigma^4}{(n-1)^2} [2(n-1)] = \\frac{2\\sigma^4}{n-1}$$\n平均统计量 $\\bar{\\sigma}_{B}^{2}$ 是 $B$ 个独立同分布随机变量 $\\hat{\\sigma}_{1}^{2}, \\dots, \\hat{\\sigma}_{B}^{2}$ 的样本均值。这些变量不服从正态分布；它们服从一个缩放的卡方分布。因此，我们必须调用中心极限定理来求出它们的均值 $\\bar{\\sigma}_{B}^{2}$ 的渐近分布。当 $B \\to \\infty$ 时，中心极限定理给出：\n$$\\bar{\\sigma}_{B}^{2} \\approx \\mathcal{N}\\left(E[\\hat{\\sigma}_{b}^{2}], \\frac{Var(\\hat{\\sigma}_{b}^{2})}{B}\\right)$$\n代入 $\\hat{\\sigma}_{b}^{2}$ 的矩：\n$$\\bar{\\sigma}_{B}^{2} \\approx \\mathcal{N}\\left(\\sigma^2, \\frac{2\\sigma^4/(n-1)}{B}\\right) = \\mathcal{N}\\left(\\sigma^2, \\frac{2\\sigma^4}{B(n-1)}\\right)$$\n\n**3. 基于正态性的不确定性界限的合理性论证**\n\n由中心极限定理确立的 $\\bar{\\mu}_{B}$ 和 $\\bar{\\sigma}_{B}^{2}$ 的渐近正态性，是使用基于正态性的不确定性界限的理由。对于大量的批次 $B$，这些运行平均值的抽样分布可以很好地用正态分布来近似。对于一个均值为 $\\theta$、方差为 $V$ 的正态分布估计量 $\\hat{\\theta}$，其对称的 $(1-\\alpha)$ 置信区间由 $\\hat{\\theta} \\pm z_{1-\\alpha/2} \\sqrt{V}$ 给出。问题要求不确定性界限以估计量的期望值为中心。这样一个界限的半宽度是 $z_{1-\\alpha/2} \\sqrt{\\text{Var}(\\text{estimator})}$。\n\n**4. 界限半径 $R$ 的计算**\n\n我们已知 $n = 128$，$B = 50$，$\\mu = 0.2$ 和 $\\sigma = 0.9$。置信水平为 $0.95$，所以 $\\alpha = 0.05$。来自标准正态分布的临界值为 $z_{1-\\alpha/2} = z_{0.975} \\approx 1.95996$。我们将使用标准近似值 $z_{0.975} = 1.96$。\n\n首先，我们计算 $\\bar{\\mu}_{B}$ 的不确定性界限的半宽度，记为 $R_{\\mu}$。\n$$R_{\\mu} = z_{0.975} \\sqrt{Var(\\bar{\\mu}_{B})} = z_{0.975} \\sqrt{\\frac{\\sigma^2}{nB}}$$\n代入数值：$\\sigma^2 = (0.9)^2 = 0.81$。\n$$R_{\\mu} = 1.96 \\sqrt{\\frac{0.81}{128 \\times 50}} = 1.96 \\sqrt{\\frac{0.81}{6400}} = 1.96 \\times \\frac{0.9}{80} = 1.96 \\times 0.01125 = 0.02205$$\n\n接下来，我们计算 $\\bar{\\sigma}_{B}^{2}$ 的不确定性界限的半宽度，记为 $R_{\\sigma^2}$。\n$$R_{\\sigma^2} = z_{0.975} \\sqrt{Var(\\bar{\\sigma}_{B}^{2})} = z_{0.975} \\sqrt{\\frac{2\\sigma^4}{B(n-1)}}$$\n代入数值：$\\sigma^4 = (0.81)^2 = 0.6561$ 且 $n-1 = 127$。\n$$R_{\\sigma^2} = 1.96 \\sqrt{\\frac{2 \\times 0.6561}{50 \\times 127}} = 1.96 \\sqrt{\\frac{1.3122}{6350}} \\approx 1.96 \\sqrt{0.00020664567}$$\n$$R_{\\sigma^2} \\approx 1.96 \\times 0.0143751754 \\approx 0.0281753439$$\n\n界限半径 $R$ 定义为这两个半宽度中较大的一个。\n$$R = \\max(R_{\\mu}, R_{\\sigma^2}) = \\max(0.02205, 0.0281753439) = 0.0281753439$$\n将结果四舍五入到四位有效数字，得到：\n$$R \\approx 0.02818$$", "answer": "$$\\boxed{0.02818}$$", "id": "3171886"}, {"introduction": "经典中心极限定理通常建立在独立同分布 (i.i.d.) 随机抽样的前提下，但当面对海量数据集时，像 bootstrap 这样的标准重采样方法可能计算成本过高。本练习将引导您探索一种更具可扩展性的替代方案——子抽样 (subsampling)，并分析其在非标准抽样（即无放回抽样）设定下的统计行为[@problem_id:3171767]。您需要严谨地分解估计误差，并仔细推导子样本均值的渐近分布，同时计算其方差估计的偏差。这项练习将挑战您对中心极限定理基本假设的理解，并让您深入掌握在大规模数据分析场景下，如何精确分析估计量的统计属性。", "problem": "一位数据科学家分析了一个来自均值为 $\\mu$、方差为 $\\sigma^{2}\\in(0,\\infty)$ 的实值分布的大型独立同分布样本 $\\{X_{1},\\dots,X_{n}\\}$。假设 $\\mathbb{E}|X_{1}|^{3}  \\infty$。为了计算的可扩展性，这位科学家没有从 $n$ 个观测值中有放回地重抽样（即自助法），而是重复地从这 $n$ 个观测值中无放回地均匀抽取大小为 $b=b_{n}$ 的子样本，其中当 $n\\to\\infty$ 时，$b\\to\\infty$ 且 $b/n\\to 0$。令 $\\bar{X}_{n}=\\frac{1}{n}\\sum_{i=1}^{n}X_{i}$ 为全样本均值，并令 $\\bar{X}_{b}$ 表示从 $n$ 个观测值中无放回均匀抽取的大小为 $b$ 的子样本的均值。\n\n1) 仅使用期望和方差的基本定义以及经典中心极限定理 (CLT)，在 $b\\to\\infty$，$b/n\\to 0$ 的条件下，推导 $Z_{b}=\\sqrt{b}\\,(\\bar{X}_{b}-\\mu)$ 的渐近分布。你的推导必须从将 $Z_{b}$ 分解为一个衡量围绕 $\\bar{X}_{n}$ 的无放回抽样波动的项和一个涉及 $\\bar{X}_{n}-\\mu$ 的项开始，并且必须通过引用标准极限定理和矩条件来证明每个极限的合理性。\n\n2) 将观测值构成的有限总体的方差定义为 $S_{n}^{2}=\\frac{1}{n}\\sum_{i=1}^{n}(X_{i}-\\bar{X}_{n})^{2}$。从第一性原理出发（即，通过计算无放回简单随机抽样的指示符协方差并应用全方差定律），推导在给定 $X_{1},\\dots,X_{n}$ 的条件下，子抽样枢轴量 $T_{b}=\\sqrt{b}\\,(\\bar{X}_{b}-\\bar{X}_{n})$ 的条件均值和条件方差。然后计算该条件方差作为 $\\sigma^{2}$ 的估计量的精确期望偏差，即\n$$\n\\mathbb{E}\\!\\left[\\operatorname{Var}\\!\\left(T_{b}\\mid X_{1},\\dots,X_{n}\\right)\\right]-\\sigma^{2},\n$$\n用 $n$、$b$ 和 $\\sigma^{2}$ 的闭式形式表示。\n\n请以单一闭式表达式的形式提供这个精确的偏差作为你的最终答案。不需要数值近似或四舍五入。", "solution": "问题陈述经确认为科学上合理、提法恰当、客观且完整。所有条件和定义在统计学习和渐近理论领域都是标准的。该问题是概率论和统计学中的一个正式练习，具体涉及子抽样估计量的性质。我将继续进行所需的推导。\n\n问题分为两部分。首先，我们推导 $Z_{b}=\\sqrt{b}\\,(\\bar{X}_{b}-\\mu)$ 的渐近分布。其次，我们计算子抽样枢轴量 $T_{b}=\\sqrt{b}\\,(\\bar{X}_{b}-\\bar{X}_{n})$ 的条件方差作为总体方差 $\\sigma^{2}$ 的估计量的精确期望偏差。\n\n**第一部分：$Z_{b}$ 的渐近分布**\n\n我们被要求通过如下分解来推导 $Z_{b}=\\sqrt{b}\\,(\\bar{X}_{b}-\\mu)$ 的渐近分布：\n$$Z_{b} = \\sqrt{b}\\,(\\bar{X}_{b}-\\bar{X}_{n}) + \\sqrt{b}\\,(\\bar{X}_{n}-\\mu)$$\n我们将分析在 $n\\to\\infty$、$b\\to\\infty$ 和 $b/n\\to 0$ 的条件下每一项的渐近行为。\n\n我们来分析第二项 $\\sqrt{b}\\,(\\bar{X}_{n}-\\mu)$。我们可以将此项重写为：\n$$\\sqrt{b}\\,(\\bar{X}_{n}-\\mu) = \\sqrt{\\frac{b}{n}} \\left( \\sqrt{n}\\,(\\bar{X}_{n}-\\mu) \\right)$$\n样本 $\\{X_{1},\\dots,X_{n}\\}$ 由独立同分布 (i.i.d.) 的随机变量组成，其均值为 $\\mathbb{E}[X_{1}]=\\mu$，方差为 $\\operatorname{Var}(X_{1})=\\sigma^{2} \\in (0,\\infty)$。条件 $\\mathbb{E}|X_{1}|^{3}  \\infty$ 意味着二阶矩是有限的。根据经典中心极限定理 (CLT)，项 $\\sqrt{n}\\,(\\bar{X}_{n}-\\mu)$ 依分布收敛于一个均值为 $0$、方差为 $\\sigma^{2}$ 的正态分布：\n$$\\sqrt{n}\\,(\\bar{X}_{n}-\\mu) \\xrightarrow{d} N(0, \\sigma^{2}) \\text{ as } n\\to\\infty$$\n符号 $\\xrightarrow{d}$ 表示依分布收敛。一个依分布收敛的随机变量序列是随机有界的（或紧的）。\n问题指明当 $n \\to \\infty$ 时 $b/n \\to 0$。因此，前置因子 $\\sqrt{b/n}$ 收敛于 $0$：\n$$\\sqrt{\\frac{b}{n}} \\to 0 \\text{ as } n\\to\\infty$$\n根据斯卢茨基 (Slutsky) 定理，一个依分布收敛的随机变量序列与一个收敛于 $0$ 的常数序列的乘积依概率收敛于 $0$。令 $A_{n} = \\sqrt{n}\\,(\\bar{X}_{n}-\\mu)$ 且 $c_{n} = \\sqrt{b/n}$。由于 $A_{n} \\xrightarrow{d} A \\sim N(0, \\sigma^{2})$ 且 $c_{n} \\to 0$，我们有 $c_{n}A_{n} \\xrightarrow{d} 0 \\cdot A = 0$。依分布收敛于一个常数等价于依概率收敛。因此，\n$$\\sqrt{b}\\,(\\bar{X}_{n}-\\mu) \\xrightarrow{p} 0 \\text{ as } n\\to\\infty$$\n其中 $\\xrightarrow{p}$ 表示依概率收敛。\n\n现在，我们来分析第一项 $\\sqrt{b}\\,(\\bar{X}_{b}-\\bar{X}_{n})$。这一项代表子样本均值围绕全样本均值的波动，该波动源于无放回抽样过程。我们分析其在给定观测样本 $\\mathcal{X}_{n} = \\{X_{1},\\dots,X_{n}\\}$ 条件下的行为。在条件上，我们是从一个大小为 $n$、值为 $\\{X_{1},\\dots,X_{n}\\}$ 的固定有限总体中抽样。该总体的均值为 $\\bar{X}_{n}$，其方差为 $S_{n}^{2}=\\frac{1}{n}\\sum_{i=1}^{n}(X_{i}-\\bar{X}_{n})^{2}$。\n\n子样本均值 $\\bar{X}_{b}$ 的条件方差由无放回简单随机抽样的标准公式给出：\n$$\\operatorname{Var}(\\bar{X}_{b} \\mid \\mathcal{X}_{n}) = \\frac{\\sigma_{pop}^{2}}{b} \\left(1 - \\frac{b}{n}\\right)$$\n其中 $\\sigma_{pop}^{2} = \\frac{1}{n-1}\\sum_{i=1}^{n}(X_{i}-\\bar{X}_{n})^{2}$ 是（无偏）总体方差。用给定的 $S_{n}^{2}$ 表示，我们有 $\\sigma_{pop}^{2} = \\frac{n}{n-1}S_{n}^{2}$。代入可得：\n$$\\operatorname{Var}(\\bar{X}_{b} \\mid \\mathcal{X}_{n}) = \\frac{1}{b}\\frac{n}{n-1}S_{n}^{2} \\left(\\frac{n-b}{n}\\right) = \\frac{S_{n}^{2}}{b}\\frac{n-b}{n-1}$$\n项 $\\sqrt{b}\\,(\\bar{X}_{b}-\\bar{X}_{n})$ 在给定 $\\mathcal{X}_{n}$ 条件下的方差是：\n$$\\operatorname{Var}\\left(\\sqrt{b}\\,(\\bar{X}_{b}-\\bar{X}_{n}) \\mid \\mathcal{X}_{n}\\right) = b\\,\\operatorname{Var}(\\bar{X}_{b} \\mid \\mathcal{X}_{n}) = S_{n}^{2}\\frac{n-b}{n-1}$$\n根据大数定律，$\\bar{X}_{n} \\xrightarrow{p} \\mu$ 且 $\\frac{1}{n}\\sum_{i=1}^{n}X_{i}^{2} \\xrightarrow{p} \\mathbb{E}[X_{1}^{2}] = \\sigma^{2}+\\mu^{2}$。根据连续映射定理，$S_{n}^{2} = \\frac{1}{n}\\sum_{i=1}^{n}X_{i}^{2} - \\bar{X}_{n}^{2} \\xrightarrow{p} (\\sigma^{2}+\\mu^{2}) - \\mu^{2} = \\sigma^{2}$。因子 $\\frac{n-b}{n-1} = \\frac{1-b/n}{1-1/n} \\to 1$ 因为 $b/n \\to 0$。因此，条件方差依概率收敛于 $\\sigma^{2}$：\n$$\\operatorname{Var}\\left(\\sqrt{b}\\,(\\bar{X}_{b}-\\bar{X}_{n}) \\mid \\mathcal{X}_{n}\\right) \\xrightarrow{p} \\sigma^{2}$$\n一个关于从有限总体序列中进行无放回抽样的中心极限定理（例如，Hájek 的定理）指出，在条件 $b\\to\\infty$、$n-b\\to\\infty$（这由 $b/n\\to 0$ 蕴含）以及关于有限总体值的林德伯格 (Lindeberg) 型条件下，归一化的样本均值是渐近正态的。条件 $\\mathbb{E}|X_{1}|^{3}  \\infty$ 确保样本表现良好，足以使此中心极限定理依概率成立。因此，在给定 $\\mathcal{X}_{n}$ 的条件下，我们有 $\\sqrt{b}\\,(\\bar{X}_{b}-\\bar{X}_{n}) \\xrightarrow{d} N(0, \\sigma^{2})$。由于极限分布不依赖于 $\\mathcal{X}_{n}$ 的具体实现，这种收敛性也无条件成立：\n$$\\sqrt{b}\\,(\\bar{X}_{b}-\\bar{X}_{n}) \\xrightarrow{d} N(0, \\sigma^{2})$$\n对 $Z_{b}$ 的分解使用斯卢茨基 (Slutsky) 定理，我们结合这两个结果。令 $A_{n} = \\sqrt{b}\\,(\\bar{X}_{b}-\\bar{X}_{n})$ 和 $B_{n} = \\sqrt{b}\\,(\\bar{X}_{n}-\\mu)$。我们有 $A_{n} \\xrightarrow{d} N(0, \\sigma^{2})$ 和 $B_{n} \\xrightarrow{p} 0$。因此，它们的和依分布收敛于 $N(0, \\sigma^{2})$：\n$$Z_{b} = A_{n} + B_{n} \\xrightarrow{d} N(0, \\sigma^{2})$$\n\n**第二部分：条件矩和期望偏差**\n\n我们被要求推导在给定 $\\mathcal{X}_{n}=\\{X_{1},\\dots,X_{n}\\}$ 条件下 $T_{b}=\\sqrt{b}\\,(\\bar{X}_{b}-\\bar{X}_{n})$ 的条件均值和方差，然后计算期望偏差。\n\n在给定 $\\mathcal{X}_{n}$ 的条件下，值 $\\{X_{1},\\dots,X_{n}\\}$ 是固定的常数。令 $I_{i}$ 为一个指示变量，如果 $X_{i}$ 在大小为 $b$ 的子样本中，则 $I_{i}=1$，否则 $I_{i}=0$。子样本均值为 $\\bar{X}_{b}=\\frac{1}{b}\\sum_{i=1}^{n}I_{i}X_{i}$。\n\n$T_{b}$ 的条件均值是：\n$$\\mathbb{E}[T_{b} \\mid \\mathcal{X}_{n}] = \\mathbb{E}[\\sqrt{b}\\,(\\bar{X}_{b}-\\bar{X}_{n}) \\mid \\mathcal{X}_{n}] = \\sqrt{b}\\,(\\mathbb{E}[\\bar{X}_{b} \\mid \\mathcal{X}_{n}]-\\bar{X}_{n})$$\n对于无放回均匀抽样，$\\mathbb{P}(I_{i}=1) = b/n$。$\\bar{X}_{b}$ 的条件期望是：\n$$\\mathbb{E}[\\bar{X}_{b} \\mid \\mathcal{X}_{n}] = \\mathbb{E}\\left[\\frac{1}{b}\\sum_{i=1}^{n}I_{i}X_{i} \\mid \\mathcal{X}_{n}\\right] = \\frac{1}{b}\\sum_{i=1}^{n}X_{i}\\mathbb{E}[I_{i}] = \\frac{1}{b}\\sum_{i=1}^{n}X_{i}\\left(\\frac{b}{n}\\right) = \\frac{1}{n}\\sum_{i=1}^{n}X_{i} = \\bar{X}_{n}$$\n因此，条件均值为 $\\mathbb{E}[T_{b} \\mid \\mathcal{X}_{n}] = \\sqrt{b}\\,(\\bar{X}_{n}-\\bar{X}_{n})=0$。\n\n$T_{b}$ 的条件方差是 $\\operatorname{Var}(T_{b} \\mid \\mathcal{X}_{n}) = b\\,\\operatorname{Var}(\\bar{X}_{b} \\mid \\mathcal{X}_{n})$。我们使用指示符协方差从第一性原理计算它。\n$$\\operatorname{Var}(\\bar{X}_{b} \\mid \\mathcal{X}_{n}) = \\operatorname{Var}\\left(\\frac{1}{b}\\sum_{i=1}^{n}I_{i}X_{i}\\right) = \\frac{1}{b^{2}}\\operatorname{Var}\\left(\\sum_{i=1}^{n}I_{i}X_{i}\\right) = \\frac{1}{b^{2}}\\left(\\sum_{i=1}^{n}X_{i}^{2}\\operatorname{Var}(I_{i}) + \\sum_{i\\neq j}X_{i}X_{j}\\operatorname{Cov}(I_{i},I_{j})\\right)$$\n指示符 $I_{i}$ 的方差是 $\\operatorname{Var}(I_{i}) = \\frac{b}{n}(1-\\frac{b}{n})=\\frac{b(n-b)}{n^{2}}$。\n对于 $i\\neq j$，协方差为 $\\operatorname{Cov}(I_{i},I_{j}) = \\mathbb{E}[I_{i}I_{j}] - \\mathbb{E}[I_{i}]\\mathbb{E}[I_{j}]$。\n$\\mathbb{E}[I_{i}I_{j}] = \\mathbb{P}(I_{i}=1, I_{j}=1) = \\mathbb{P}(I_{j}=1|I_{i}=1)\\mathbb{P}(I_{i}=1) = \\frac{b-1}{n-1}\\frac{b}{n}$。\n$$\\operatorname{Cov}(I_{i},I_{j}) = \\frac{b(b-1)}{n(n-1)} - \\left(\\frac{b}{n}\\right)^{2} = \\frac{b}{n}\\left(\\frac{b-1}{n-1}-\\frac{b}{n}\\right) = \\frac{b}{n}\\frac{n(b-1)-b(n-1)}{n(n-1)} = -\\frac{b(n-b)}{n^{2}(n-1)}$$\n将这些代入方差表达式中：\n$$\\operatorname{Var}\\left(\\sum I_{i}X_{i}\\right) = \\frac{b(n-b)}{n^{2}}\\sum_{i=1}^{n}X_{i}^{2} - \\frac{b(n-b)}{n^{2}(n-1)}\\sum_{i\\neq j}X_{i}X_{j}$$\n使用 $\\sum_{i\\neq j}X_{i}X_{j} = (\\sum X_{i})^{2} - \\sum X_{i}^{2} = n^{2}\\bar{X}_{n}^{2} - \\sum X_{i}^{2}$：\n$$\\operatorname{Var}\\left(\\sum I_{i}X_{i}\\right) = \\frac{b(n-b)}{n^{2}(n-1)}\\left((n-1)\\sum X_{i}^{2} - (n^{2}\\bar{X}_{n}^{2} - \\sum X_{i}^{2})\\right)$$\n$$= \\frac{b(n-b)}{n^{2}(n-1)}\\left(n\\sum X_{i}^{2} - n^{2}\\bar{X}_{n}^{2}\\right) = \\frac{b n(n-b)}{n^{2}(n-1)}\\left(\\sum X_{i}^{2} - n\\bar{X}_{n}^{2}\\right)$$\n由于 $\\sum(X_{i}-\\bar{X}_{n})^{2} = \\sum X_{i}^{2} - n\\bar{X}_{n}^{2} = n S_{n}^{2}$：\n$$\\operatorname{Var}\\left(\\sum I_{i}X_{i}\\right) = \\frac{b(n-b)}{n(n-1)} (n S_{n}^{2}) = \\frac{b(n-b)}{n-1} S_{n}^{2}$$\n那么，$\\operatorname{Var}(\\bar{X}_{b} \\mid \\mathcal{X}_{n}) = \\frac{1}{b^{2}}\\frac{b(n-b)}{n-1}S_{n}^{2} = \\frac{n-b}{b(n-1)}S_{n}^{2}$。\n最后，$T_{b}$ 的条件方差是：\n$$\\operatorname{Var}(T_{b} \\mid \\mathcal{X}_{n}) = b\\,\\operatorname{Var}(\\bar{X}_{b} \\mid \\mathcal{X}_{n}) = \\frac{n-b}{n-1}S_{n}^{2}$$\n现在，我们计算此量作为 $\\sigma^{2}$ 的估计量的期望偏差：\n$$\\text{Bias} = \\mathbb{E}\\left[\\operatorname{Var}(T_{b} \\mid \\mathcal{X}_{n})\\right] - \\sigma^{2} = \\mathbb{E}\\left[\\frac{n-b}{n-1}S_{n}^{2}\\right] - \\sigma^{2} = \\frac{n-b}{n-1}\\mathbb{E}[S_{n}^{2}] - \\sigma^{2}$$\n我们需要求出 $S_{n}^{2}$ 的期望。\n$$S_{n}^{2} = \\frac{1}{n}\\sum_{i=1}^{n}(X_{i}-\\bar{X}_{n})^{2} = \\frac{1}{n}\\sum_{i=1}^{n}X_{i}^{2} - \\bar{X}_{n}^{2}$$\n取期望：\n$$\\mathbb{E}[S_{n}^{2}] = \\frac{1}{n}\\sum_{i=1}^{n}\\mathbb{E}[X_{i}^{2}] - \\mathbb{E}[\\bar{X}_{n}^{2}]$$\n对每个 $i$，$\\mathbb{E}[X_{i}^{2}] = \\operatorname{Var}(X_{i}) + (\\mathbb{E}[X_{i}])^{2} = \\sigma^{2}+\\mu^{2}$。\n对于样本均值 $\\bar{X}_{n}$，$\\mathbb{E}[\\bar{X}_{n}]=\\mu$ 且 $\\operatorname{Var}(\\bar{X}_{n})=\\sigma^{2}/n$。所以 $\\mathbb{E}[\\bar{X}_{n}^{2}] = \\operatorname{Var}(\\bar{X}_{n}) + (\\mathbb{E}[\\bar{X}_{n}])^{2} = \\frac{\\sigma^{2}}{n}+\\mu^{2}$。\n将这些代入：\n$$\\mathbb{E}[S_{n}^{2}] = \\frac{1}{n}\\sum_{i=1}^{n}(\\sigma^{2}+\\mu^{2}) - \\left(\\frac{\\sigma^{2}}{n}+\\mu^{2}\\right) = (\\sigma^{2}+\\mu^{2}) - \\frac{\\sigma^{2}}{n} - \\mu^{2} = \\sigma^{2} - \\frac{\\sigma^{2}}{n} = \\frac{n-1}{n}\\sigma^{2}$$\n现在我们将此结果代入偏差公式中：\n$$\\text{Bias} = \\frac{n-b}{n-1}\\left(\\frac{n-1}{n}\\sigma^{2}\\right) - \\sigma^{2} = \\frac{n-b}{n}\\sigma^{2} - \\sigma^{2}$$\n$$= \\left(\\frac{n-b}{n}-1\\right)\\sigma^{2} = \\left(\\frac{n-b-n}{n}\\right)\\sigma^{2} = -\\frac{b}{n}\\sigma^{2}$$\n这就是该条件方差作为 $\\sigma^{2}$ 的估计量的精确期望偏差。", "answer": "$$ \\boxed{-\\frac{b}{n}\\sigma^{2}} $$", "id": "3171767"}]}