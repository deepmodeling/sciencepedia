{"hands_on_practices": [{"introduction": "假设检验不仅仅是关于计算 p 值；它是一种指导决策的框架，而每个决策都可能带来后果。本练习将帮助你将 I 型和 II 型错误的抽象定义，转化为评估回归模型时所面临的实际问题。我们将探讨在检验模型残差是否符合正态分布时，犯下这两类错误分别意味着什么 [@problem_id:3130871]。", "problem": "一位研究人员对一个包含 $n=60$ 个观测值的数据集拟合了一个线性回归模型，并得到了残差 $\\{e_i\\}_{i=1}^{60}$。为了评估残差是否近似服从高斯分布，该研究人员计划对残差应用 Shapiro–Wilk 正态性检验。原假设为 $H_0$：“残差是从一个高斯分布中抽取的”，备择假设为 $H_1$：“残差不是高斯分布的”。研究人员将使用 $\\alpha=0.05$ 的显著性水平和以下决策规则：如果检验的 $p$ 值至多为 $\\alpha$，则拒绝 $H_0$。如果 $H_0$ 被拒绝，研究人员将调整模型（例如，通过对响应变量应用方差稳定变换，或使用对非高斯误差不太敏感的推断方法）；如果 $H_0$ 未被拒绝，研究人员将按最初指定的方式继续进行普通最小二乘法（OLS, Ordinary Least Squares）推断。假设在当前数据集上，该过程输出的 $p$ 值为 $p=0.03$。同时考虑真实残差分布是轻微右偏（与高斯分布有小的偏差）的可能性。\n\n下列哪个陈述是正确的？\n\nA. 使用 $\\alpha=0.05$ 时，第一类错误是在 $H_0$ 为真时拒绝 $H_0$；在此情境下，这对应于当残差实际上是高斯分布时，进行了不必要的模型调整。\n\nB. 如果真实的残差具有轻微的右偏性（因此 $H_0$ 为假），但检验在 $\\alpha=0.05$ 的水平上未能拒绝 $H_0$，这就是第二类错误；在此情境下，这有可能会夸大 OLS 推断对非高斯性的稳健性。\n\nC. 观测到 $p=0.03$ 意味着对于此数据集，$H_0$ 为真的概率是 $0.03$。\n\nD. 在 $H_0$ 之下，对于一个有效的连续检验，$p$ 值的分布是 $[0,1]$ 上的均匀分布；因此，如果 $H_0$ 为真，则 $p$ 值至多为 $0.12$ 的概率是 $0.12$。\n\nE. 将显著性水平从 $\\alpha=0.05$ 降低到 $\\alpha=0.01$ 会同时减少同一检验和样本量下第一类错误和第二类错误的概率。", "solution": "必须首先评估问题陈述的有效性。\n\n### 第1步：提取已知条件\n-   **样本量**：$n=60$ 个观测值。\n-   **模型**：线性回归。\n-   **用于检验的数据**：残差 $\\{e_i\\}_{i=1}^{60}$。\n-   **检验**：Shapiro–Wilk 正态性检验。\n-   **原假设 ($H_0$)**：“残差是从一个高斯分布中抽取的”。\n-   **备择假设 ($H_1$)**：“残差不是高斯分布的”。\n-   **显著性水平**：$\\alpha=0.05$。\n-   **决策规则**：如果 $p$ 值至多为 $\\alpha$，则拒绝 $H_0$。\n-   **拒绝后的行动**：调整模型。\n-   **不拒绝后的行动**：继续进行普通最小二乘法 (OLS) 推断。\n-   **观测数据**：一个具体实例产生的 $p$ 值为 $p=0.03$。\n-   **假设情景**：真实的残差分布是轻微右偏的。\n\n### 第2步：使用提取的已知条件进行验证\n该问题描述了应用统计学中的一个标准场景：使用假设检验对模型拟合的诊断量（残差）来评估线性回归模型的假设。所呈现的概念——原/备择假设、第一类和第二类错误、$p$ 值、显著性水平以及 Shapiro-Wilk 检验——都是统计学中基本且定义明确的概念。该设定是自洽且内部一致的。\n\n一个微妙之处在于，即使真实模型的误差是独立同分布的（i.i.d.），来自 OLS 的残差也并非严格独立同分布。它们具有一个协方差结构，$\\mathrm{Cov}(\\boldsymbol{e}) = \\sigma^2(\\boldsymbol{I} - \\boldsymbol{H})$，其中 $\\boldsymbol{H}$ 是帽子矩阵。像 Shapiro-Wilk 这样的标准正态性检验假设样本是独立同分布的。然而，在回归诊断中，将此类检验应用于残差是一种非常常见但近似的做法。问题陈述本身并未因这一细微差别而失效；相反，这一微妙之处可能与评估选项有关。“评估残差是否*近似*服从高斯分布”的措辞表明了对这种实际背景的认识。\n\n该问题具有科学依据，提法恰当，客观，并且没有违反任何导致其无效的标准。\n\n### 第3步：结论与行动\n问题是有效的。我现在将继续分析每个陈述。\n\n### 陈述分析\n\n频率派假设检验的核心原则在这里至关重要。\n-   **第一类错误**是拒绝一个为真的原假设 ($H_0$)。犯第一类错误的概率由显著性水平控制，$P(\\text{第一类错误}) = \\alpha$。\n-   **第二类错误**是未能拒绝一个为假的原假设 ($H_0$)。犯第二类错误的概率用 $\\beta$ 表示。\n-   **$p$ 值**是在假设 $H_0$ 为真的前提下，观测到至少与从样本数据中计算出的检验统计量一样极端的检验统计量的概率。即 $P(\\text{数据与观测一样极端或更极端} | H_0)$。\n\n**A. 使用 $\\alpha=0.05$ 时，第一类错误是在 $H_0$ 为真时拒绝 $H_0$；在此情境下，这对应于当残差实际上是高斯分布时，进行了不必要的模型调整。**\n\n该陈述首先给出了第一类错误的正确定义：当 $H_0$ 为真时拒绝 $H_0$。然后它将此定义应用于问题的具体情境。在这里，$H_0$ 是残差服从高斯分布的假设。拒绝 $H_0$ 的后果是“调整模型”。因此，如果 $H_0$ 为真（残差是高斯分布的）而我们拒绝了它（犯了第一类错误），我们就会进行一次不必要的模型调整，因为初始模型的误差假设是正确的。该陈述的定义和情境应用都是准确的。\n\n结论：**正确**。\n\n**B. 如果真实的残差具有轻微的右偏性（因此 $H_0$ 为假），但检验在 $\\alpha=0.05$ 的水平上未能拒绝 $H_0$，这就是第二类错误；在此情境下，这有可能会夸大 OLS 推断对非高斯性的稳健性。**\n\n该陈述考虑了 $H_0$ 为假的情景，因为真实分布是偏斜的。它正确地将未能拒绝一个假的 $H_0$ 识别为第二类错误。不拒绝 $H_0$ 的后果是“继续进行普通最小二乘法 (OLS) 推断”。标准的 OLS 推断，如系数的 t 检验和置信区间，依赖于误差正态分布的假设以保证其在有限样本下的有效性。如果这个假设被违反，推断可能就不可靠。通过未能检测到非正态性并继续进行标准推断，研究人员的行为就好像该方法对这种违规是稳健的。这确实带来了推断得出的结论不正确的风险。“有可能会夸大……的稳健性”的措辞精确地描述了在这种诊断情境下犯第二类错误的实际危险。\n\n结论：**正确**。\n\n**C. 观测到 $p=0.03$ 意味着对于此数据集，$H_0$ 为真的概率是 $0.03$。**\n\n这是对 $p$ 值的一个常见且根本性的误解。$p$ 值是在原假设为真的条件下，观测到当前数据（或更极端数据）的概率，即 $P(\\text{数据}|H_0)$。该陈述声称 $p$ 值是给定数据下原假设为真的概率，即 $P(H_0|\\text{数据})$。后一个量是一个贝叶斯概念（后验概率），如果不为 $H_0$ 指定一个先验概率，就无法计算。频率派的 $p$ 值不提供假设为真的概率。\n\n结论：**不正确**。\n\n**D. 在 $H_0$ 之下，对于一个有效的连续检验，$p$ 值的分布是 $[0,1]$ 上的均匀分布；因此，如果 $H_0$ 为真，则 $p$ 值至多为 $0.12$ 的概率是 $0.12$。**\n\n该陈述描述了 $p$ 值的一个基本性质。对于任何在原假设 $H_0$ 下检验统计量具有连续分布的假设检验，其 $p$ 值随机变量的分布是在区间 $[0,1]$ 上的均匀分布。如果一个随机变量 $P$ 服从 $U(0,1)$ 分布，其累积分布函数为 $F_P(c) = P(P \\le c) = c$，对于任何 $c \\in [0,1]$。因此，$P(p\\text{值} \\le 0.12) = 0.12$ 的推论在数学上是合理的。整个陈述是数理统计中的一个正确定理。\n\n结论：**正确**。\n\n**E. 将显著性水平从 $\\alpha=0.05$ 降低到 $\\alpha=0.01$ 会同时减少同一检验和样本量下第一类错误和第二类错误的概率。**\n\n第一类错误的概率 $P(\\text{第一类错误})$ 等于显著性水平 $\\alpha$。将 $\\alpha$ 从 $0.05$ 降低到 $0.01$ 直接减少了犯第一类错误的概率。然而，降低 $\\alpha$ 会使拒绝 $H_0$ 的标准更加严格（拒绝域变小）。这使得拒绝 $H_0$ 变得更加困难。因此，如果 $H_0$ 为假，未能拒绝它的概率就会增加。这意味着第二类错误的概率 $\\beta$ 会增加。对于固定的样本量和检验，$\\alpha$ 和 $\\beta$ 之间存在固有的权衡关系。仅通过改变显著性水平不可能同时减少两者。\n\n结论：**不正确**。\n\n重新审视正确的选项 A、B 和 D。这三个都是关于假设检验原则的正确陈述。陈述 A 在情境中正确定义了第一类错误。陈述 B 在情境中正确定义了第二类错误。陈述 D 正确陈述了关于p值在原假设下分布的一个基本定理。这三个陈述中没有不一致或不准确之处。", "answer": "$$\\boxed{ABD}$$", "id": "3130871"}, {"introduction": "理解了不同类型错误的含义后，我们可以更进一步，在收集数据之前主动地控制这些风险。一个设计良好的实验应当具备足够的统计功效（power）来检测出我们关心的效应。本练习将引导你推导出一个在统计学和数据科学中至关重要的公式，用于计算达到特定 I 型错误率 $\\alpha$ 和 II 型错误率 $\\beta$ 所需的最小样本量 [@problem_id:3130913]。", "problem": "一个安全运营团队监控系统日志，统计每个固定时间窗口内的异常标志数量。在科学上，将恒定速率机制下每个窗口的计数建模为来自率参数为 $\\lambda$ 的泊松分布的独立抽样是合理的。该团队希望检验异常率是否相对于已知的基线 $\\lambda_0$ 有所增加。\n\n构建一个单边假设检验，其原假设为 $H_0\\!:\\ \\lambda=\\lambda_0$，备择假设为 $H_1\\!:\\ \\lambda=\\lambda_1$，其中 $\\lambda_1=\\lambda_0(1+\\delta)$，$\\delta0$ 是一个小数。设 $Y_1,\\dots,Y_n$ 是在 $n$ 个独立窗口中观测到的计数值，并定义总计数为 $X=\\sum_{i=1}^{n} Y_i$。当 $X$ 超过一个阈值 $c$ 时，检验将拒绝 $H_0$。该阈值 $c$ 的选择是为了控制第一类错误率 $\\alpha$（即当 $H_0$ 为真时拒绝 $H_0$ 的概率）。该团队计划稍后通过在 $H_0$ 下从泊松模型中进行模拟抽样来验证所达到的 $\\alpha$ 值，但为了规划目的，他们需要一个样本量的解析表达式。\n\n从第一类错误 $\\alpha$ 和第二类错误 $\\beta$（即当 $H_1$ 为真时未能拒绝 $H_0$ 的概率）的核心定义出发，仅使用关于泊松分布的公认事实（均值和方差等于其率参数）以及中心极限定理（CLT）近似（即对于大的 $n$，$X$ 近似服从均值为 $n\\lambda$、方差为 $n\\lambda$ 的正态分布），推导出一个能达到第一类错误率 $\\alpha$ 和第二类错误率 $\\beta$ 的最小整数样本量 $n$ 的表达式，用于检测从 $\\lambda_0$ 到 $\\lambda_1=\\lambda_0(1+\\delta)$ 的增长。\n\n然后，对于规划参数 $\\lambda_0=5$，$\\delta=0.1$，$\\alpha=0.05$ 和 $\\beta=0.2$，对此表达式进行数值计算，并报告满足标准的最小整数 $n$。不要使用任何连续性校正。答案必须是一个整数。除了取最小整数外，没有其他舍入要求。", "solution": "该问题要求推导用于比较两个泊松率的单边假设检验的最小样本量 $n$，然后进行数值计算。推导将基于第一类和第二类错误的定义，并使用中心极限定理（CLT）进行近似。\n\n首先，我们来形式化问题设定。给定 $n$ 个独立同分布的随机变量 $Y_1, \\dots, Y_n$，其中 $Y_i \\sim \\text{Poisson}(\\lambda)$。检验统计量是它们的和，$X = \\sum_{i=1}^{n} Y_i$。泊松分布的一个性质是，独立泊松变量的和仍然是泊松变量。因此，$X \\sim \\text{Poisson}(n\\lambda)$。\n\n假设检验为：\n原假设 $H_0: \\lambda = \\lambda_0$\n备择假设 $H_1: \\lambda = \\lambda_1$，其中 $\\lambda_1 = \\lambda_0(1+\\delta)$ 且 $\\delta  0$。\n\n问题说明要使用中心极限定理近似。对于大的 $n$，$X$ 的分布可以近似为正态分布。\n在 $H_0$ 下，$X$ 的均值为 $E[X|H_0] = n\\lambda_0$，方差为 $\\text{Var}(X|H_0) = n\\lambda_0$。所以，$X \\stackrel{\\text{approx}}{\\sim} \\mathcal{N}(n\\lambda_0, n\\lambda_0)$。\n在 $H_1$ 下，$X$ 的均值为 $E[X|H_1] = n\\lambda_1$，方差为 $\\text{Var}(X|H_1) = n\\lambda_1$。所以，$X \\stackrel{\\text{approx}}{\\sim} \\mathcal{N}(n\\lambda_1, n\\lambda_1)$。\n\n决策规则是：如果 $X  c$，则拒绝 $H_0$，其中 $c$ 是一个临界值。\n\n第一类错误率 $\\alpha$ 是当 $H_0$ 为真时拒绝它的概率。\n$$ \\alpha = P(\\text{reject } H_0 | H_0) = P(X  c | \\lambda = \\lambda_0) $$\n使用 $H_0$ 下 $X$ 的正态近似，我们对变量进行标准化：\n$$ \\alpha = P\\left( \\frac{X - n\\lambda_0}{\\sqrt{n\\lambda_0}}  \\frac{c - n\\lambda_0}{\\sqrt{n\\lambda_0}} \\right) $$\n设 $Z$ 是一个标准正态随机变量，$Z \\sim \\mathcal{N}(0,1)$。设 $z_\\alpha$ 是标准正态分布的上 $\\alpha$-分位数，定义为 $P(Z  z_\\alpha) = \\alpha$。于是我们有：\n$$ \\frac{c - n\\lambda_0}{\\sqrt{n\\lambda_0}} = z_\\alpha $$\n解出临界值 $c$，我们得到第一个表达式：\n$$ c = n\\lambda_0 + z_\\alpha \\sqrt{n\\lambda_0} \\quad (1) $$\n\n第二类错误率 $\\beta$ 是当 $H_1$ 为真时未能拒绝 $H_0$ 的概率。\n$$ \\beta = P(\\text{fail to reject } H_0 | H_1) = P(X \\le c | \\lambda = \\lambda_1) $$\n使用 $H_1$ 下 $X$ 的正态近似（并根据指示忽略连续性校正，因此 $P(X \\le c) \\approx P(X  c)$），我们对变量进行标准化：\n$$ \\beta = P\\left( \\frac{X - n\\lambda_1}{\\sqrt{n\\lambda_1}} \\le \\frac{c - n\\lambda_1}{\\sqrt{n\\lambda_1}} \\right) $$\n设 $z_\\beta$ 是标准正态分布的上 $\\beta$-分位数，$P(Z  z_\\beta) = \\beta$。由于正态分布的对称性，$P(Z \\le -z_\\beta) = \\beta$。因此：\n$$ \\frac{c - n\\lambda_1}{\\sqrt{n\\lambda_1}} = -z_\\beta $$\n解出临界值 $c$，我们得到第二个表达式：\n$$ c = n\\lambda_1 - z_\\beta \\sqrt{n\\lambda_1} \\quad (2) $$\n\n现在，我们将方程 $(1)$ 和 $(2)$ 中 $c$ 的两个表达式相等，以求出所需的样本量 $n$。\n$$ n\\lambda_0 + z_\\alpha \\sqrt{n\\lambda_0} = n\\lambda_1 - z_\\beta \\sqrt{n\\lambda_1} $$\n重新整理各项以求解 $n$：\n$$ n\\lambda_1 - n\\lambda_0 = z_\\alpha \\sqrt{n\\lambda_0} + z_\\beta \\sqrt{n\\lambda_1} $$\n$$ n(\\lambda_1 - \\lambda_0) = \\sqrt{n} (z_\\alpha \\sqrt{\\lambda_0} + z_\\beta \\sqrt{\\lambda_1}) $$\n假设 $n  0$，我们可以两边同除以 $\\sqrt{n}$：\n$$ \\sqrt{n}(\\lambda_1 - \\lambda_0) = z_\\alpha \\sqrt{\\lambda_0} + z_\\beta \\sqrt{\\lambda_1} $$\n分离出 $\\sqrt{n}$：\n$$ \\sqrt{n} = \\frac{z_\\alpha \\sqrt{\\lambda_0} + z_\\beta \\sqrt{\\lambda_1}}{\\lambda_1 - \\lambda_0} $$\n两边平方，得到 $n$ 的表达式：\n$$ n = \\left( \\frac{z_\\alpha \\sqrt{\\lambda_0} + z_\\beta \\sqrt{\\lambda_1}}{\\lambda_1 - \\lambda_0} \\right)^2 $$\n我们已知 $\\lambda_1 = \\lambda_0(1+\\delta)$，所以 $\\lambda_1 - \\lambda_0 = \\lambda_0 \\delta$。将此代入公式：\n$$ n = \\frac{(z_\\alpha \\sqrt{\\lambda_0} + z_\\beta \\sqrt{\\lambda_0(1+\\delta)})^2}{(\\lambda_0 \\delta)^2} = \\frac{(\\sqrt{\\lambda_0}(z_\\alpha + z_\\beta \\sqrt{1+\\delta}))^2}{\\lambda_0^2 \\delta^2} $$\n$$ n = \\frac{\\lambda_0 (z_\\alpha + z_\\beta \\sqrt{1+\\delta})^2}{\\lambda_0^2 \\delta^2} = \\frac{(z_\\alpha + z_\\beta \\sqrt{1+\\delta})^2}{\\lambda_0 \\delta^2} $$\n这就是样本量 $n$ 的通用解析表达式。\n\n接下来，我们用给定的参数 $\\lambda_0=5$，$\\delta=0.1$，$\\alpha=0.05$ 和 $\\beta=0.2$ 来计算这个表达式的值。\n首先，我们找到标准正态分布对应的 $z$ 分数。\n对于第一类错误率 $\\alpha=0.05$，$z_{0.05}$ 是满足 $P(Z  z_{0.05}) = 0.05$ 的值。该值为 $z_{0.05} \\approx 1.64485$。\n对于第二类错误率 $\\beta=0.2$，$z_{0.2}$ 是满足 $P(Z  z_{0.2}) = 0.2$ 的值。该值为 $z_{0.2} \\approx 0.84162$。\n\n现在，我们将这些值代入推导出的 $n$ 的公式中：\n$$ n = \\frac{(1.64485 + 0.84162 \\sqrt{1+0.1})^2}{5 \\times (0.1)^2} $$\n$$ n = \\frac{(1.64485 + 0.84162 \\sqrt{1.1})^2}{5 \\times 0.01} $$\n我们来计算各项：\n$$ \\sqrt{1.1} \\approx 1.048809 $$\n$$ n \\approx \\frac{(1.64485 + 0.84162 \\times 1.048809)^2}{0.05} $$\n$$ n \\approx \\frac{(1.64485 + 0.88277)^2}{0.05} $$\n$$ n \\approx \\frac{(2.52762)^2}{0.05} $$\n$$ n \\approx \\frac{6.38886}{0.05} $$\n$$ n \\approx 127.777 $$\n由于样本量 $n$ 必须是整数，且计算出的值是达到所需错误率的最小值，我们必须对该值取上取整（ceiling）。样本量为 127 会导致错误率略高于规定值。因此，最小整数样本量是大于计算值的下一个整数。\n$$ n_{\\text{min}} = \\lceil 127.777 \\rceil = 128 $$", "answer": "$$\\boxed{128}$$", "id": "3130913"}, {"introduction": "最后，我们将理论与计算实践相结合，将假设检验应用于评估机器学习模型性能这一复杂任务中。本练习要求你通过编程来检验一个关于分类器真实正类率（True Positive Rate）的声明。通过这个过程，你将亲身体验分类器的决策阈值、I/II 型错误率以及检验功效之间微妙的权衡关系 [@problem_id:3130833]。", "problem": "给定一个二元分类器，它为每个实例输出一个实值分数。假设分数分布是固定的，并由以下科学上合理的模型给出：当真实类别为正时，分数呈均值为 $\\mu_1$、标准差为 $\\sigma$ 的 Gaussian 分布；当真实类别为负时，分数呈均值为 $\\mu_0$、标准差为 $\\sigma$ 的 Gaussian 分布，其中 $\\mu_1  \\mu_0$ 且 $\\sigma  0$。对于任何决策阈值 $\\tau$，如果分数至少为 $\\tau$，则分类为正。这会产生一条由 $(\\mu_0,\\mu_1,\\sigma)$ 固定的接收者操作特征 (ROC) 曲线。对于阈值 $\\tau$，真阳性率和假阳性率分别为\n$$\\mathrm{TPR}(\\tau) = 1 - \\Phi\\!\\left(\\frac{\\tau - \\mu_1}{\\sigma}\\right), \\quad \\mathrm{FPR}(\\tau) = 1 - \\Phi\\!\\left(\\frac{\\tau - \\mu_0}{\\sigma}\\right),$$\n其中 $\\Phi(\\cdot)$ 表示标准正态分布的累积分布函数。\n\n设计一个单边假设检验，以验证分类器在选定阈值 $\\tau$ 下的真阳性率至少为基准值 $p_0$。令 $p(\\tau)$ 表示在阈值 $\\tau$ 下的真阳性率。你从正类总体中观察 $m$ 次独立抽样，并记录在阈值 $\\tau$ 下的真阳性数量。根据 Bernoulli 模型，真阳性计数 $X$ 是一个参数为 $m$ 和 $p(\\tau)$ 的二项随机变量，记作 $X \\sim \\mathrm{Binomial}(m, p(\\tau))$。考虑检验\n$$H_0: \\ p(\\tau) \\ge p_0 \\quad \\text{versus} \\quad H_1: \\ p(\\tau)  p_0,$$\n使用形式为“如果 $X \\le k$ 则拒绝 $H_0$”的下尾拒绝规则，其中整数截断值 $k$ 的选择是为了在二项分布离散性允许的范围内尽可能接近目标显著性水平 $\\alpha_{\\text{target}}$。对于给定的 $k$，I 型错误概率 $\\alpha$ 是在 $H_0$ 为真时拒绝它的概率，在边界情况 $p(\\tau) = p_0$ 下，它等于 $\\alpha = \\Pr(X \\le k \\mid m, p_0)$。对于给定的 $k$，在特定真实率 $p(\\tau)$ 下的 II 型错误概率 $\\beta$ 是在 $H_1$ 为真时未能拒绝 $H_0$ 的概率，即当 $p(\\tau)  p_0$ 时，$\\beta = \\Pr(X  k \\mid m, p(\\tau))$。\n\n你的任务：\n- 从第一性原理出发，推导固定的 Gaussian 分数模型如何在给定 $(\\mu_0,\\mu_1,\\sigma)$ 的情况下，生成作为 $\\tau$ 函数的 $\\mathrm{TPR}(\\tau)$ 和 $\\mathrm{FPR}(\\tau)$。\n- 从二项模型以及 I 型和 II 型错误的定义出发，说明如何选择整数截断值 $k$ 以满足 $\\Pr(X \\le k \\mid m, p_0) \\le \\alpha_{\\text{target}}$，并计算由此产生的名义 I 型错误 $\\alpha_{\\text{nominal}} = \\Pr(X \\le k \\mid m, p_0)$。\n- 对于测试套件中的每个阈值 $\\tau$，计算：\n    1. 由固定 ROC 曲线导出的真阳性率 $p(\\tau)$ 和假阳性率 $\\mathrm{FPR}(\\tau)$。\n    2. 由 $k$、$m$ 和 $p_0$ 决定的名义 I 型错误 $\\alpha_{\\text{nominal}}$。\n    3. 在 $\\tau$ 处的实现 I 型错误，定义为 $\\alpha_{\\text{real}}(\\tau) = \\Pr(X \\le k \\mid m, p(\\tau))$; 这仅在 $p(\\tau) \\ge p_0$ 时有意义，但为了完整性，你仍应为所有 $\\tau$ 计算其值。\n    4. 在 $\\tau$ 处的实现 II 型错误，定义为 $\\beta_{\\text{real}}(\\tau) = \\Pr(X  k \\mid m, p(\\tau)) = 1 - \\Pr(X \\le k \\mid m, p(\\tau))$; 这在 $p(\\tau)  p_0$ 时有意义，但你应该为所有 $\\tau$ 计算其值，以观察在 ROC 曲线固定的情况下，移动 $\\tau$ 如何权衡 $\\alpha_{\\text{real}}(\\tau)$ 与 $\\beta_{\\text{real}}(\\tau)$。\n\n使用以下参数和测试套件：\n- 固定分数模型：$\\mu_0 = 0$, $\\mu_1 = 1.5$, $\\sigma = 1$。\n- 基准率：$p_0 = 0.85$（以小数表示）。\n- 样本量：$m = 50$。\n- 目标显著性水平：$\\alpha_{\\text{target}} = 0.05$（以小数表示）。\n- 阈值：$\\tau \\in \\{-0.5, \\ 0.0, \\ 0.464, \\ 1.0, \\ 1.5, \\ 2.5\\}$，其中选择 $\\tau = 0.464$ 以使 $\\mathrm{TPR}(\\tau)$ 接近 $p_0$。\n\n输出规格：\n- 你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。\n- 每个测试用例的结果必须是按 $[\\tau,\\mathrm{TPR}(\\tau),\\mathrm{FPR}(\\tau),\\alpha_{\\text{nominal}},\\alpha_{\\text{real}}(\\tau),\\beta_{\\text{real}}(\\tau)]$ 顺序排列的六个十进制值列表，每个值四舍五入到六位小数。\n- 因此，最终输出应为一个列表的列表，针对给定顺序的六个阈值，不含任何额外文本。例如，输出行将类似于“[ [t1,tp1,fp1,a_nom1,a_real1,b_real1], [t2,tp2,fp2,a_nom2,a_real2,b_real2], ... ]”。\n\n你的解决方案必须按规定实现为一个完整的、可运行的程序，并且不得要求任何用户输入。", "solution": "我们从固定的 Gaussian 分数模型开始。令分数 $S$ 在真实类别为正时服从 $S \\sim \\mathcal{N}(\\mu_1,\\sigma^2)$ 分布，在真实类别为负时服从 $S \\sim \\mathcal{N}(\\mu_0,\\sigma^2)$ 分布，其中 $\\mu_1  \\mu_0$。对于任何阈值 $\\tau$，如果 $S \\ge \\tau$，我们预测为正。\n\n根据 Gaussian 随机变量累积分布函数的定义，对于一个标准正态变量 $Z \\sim \\mathcal{N}(0,1)$ 和任何实数 $z$，我们有 $\\Pr(Z \\le z) = \\Phi(z)$，其中 $\\Phi(\\cdot)$ 是标准正态累积分布函数。利用单调变换性质，\n$$\\Pr(S \\ge \\tau \\mid \\text{positive}) = \\Pr\\!\\left(\\frac{S - \\mu_1}{\\sigma} \\ge \\frac{\\tau - \\mu_1}{\\sigma}\\right) = 1 - \\Phi\\!\\left(\\frac{\\tau - \\mu_1}{\\sigma}\\right),$$\n因为 $\\frac{S - \\mu_1}{\\sigma} \\sim \\mathcal{N}(0,1)$。这就是真阳性率 $\\mathrm{TPR}(\\tau)$。类似地，假阳性率为\n$$\\Pr(S \\ge \\tau \\mid \\text{negative}) = \\Pr\\!\\left(\\frac{S - \\mu_0}{\\sigma} \\ge \\frac{\\tau - \\mu_0}{\\sigma}\\right) = 1 - \\Phi\\!\\left(\\frac{\\tau - \\mu_0}{\\sigma}\\right),$$\n即 $\\mathrm{FPR}(\\tau)$。由于 $(\\mu_0,\\mu_1,\\sigma)$ 是固定的，ROC 曲线（$\\mathrm{TPR}(\\tau)$ 对 $\\mathrm{FPR}(\\tau)$ 随 $\\tau$ 变化的参数图）是固定的，移动 $\\tau$ 会沿着该曲线移动。\n\n接下来，考虑检验在阈值 $\\tau$ 下的真阳性率（记为 $p(\\tau)$）是否达到或超过基准值 $p_0$。我们观察一批 $m$ 个独立抽取的正类实例，并将在阈值 $\\tau$ 下的真阳性数量记为 $X$。在成功概率为 $p(\\tau)$ 的独立试验的 Bernoulli 模型下，我们有\n$$X \\sim \\mathrm{Binomial}(m, p(\\tau)).$$\n我们建立单边假设检验\n$$H_0: \\ p(\\tau) \\ge p_0 \\quad \\text{versus} \\quad H_1: \\ p(\\tau)  p_0.$$\n对此类单边检验，一个自然的拒绝规则是下尾截断：如果 $X \\le k$，则拒绝 $H_0$，其中 $k$ 为某个整数。对于给定的截断值 $k$，I 型错误概率 $\\alpha$ 定义为在原假设为真时错误拒绝它的概率。对于像二项分布这样关于 $p$ 具有单调似然比的族，在 $H_0$ 下的最坏情况 I 型错误发生在边界 $p(\\tau) = p_0$ 处，因此\n$$\\alpha = \\Pr(X \\le k \\mid X \\sim \\mathrm{Binomial}(m, p_0)).$$\n给定一个目标显著性水平 $\\alpha_{\\text{target}}$，我们选择 $k$ 为满足\n$$\\Pr(X \\le k \\mid X \\sim \\mathrm{Binomial}(m, p_0)) \\le \\alpha_{\\text{target}}.$$\n的最大整数。这确保了尽管二项分布是离散的，检验的规模（size）不会超过 $\\alpha_{\\text{target}}$。由此产生的名义 I 型错误为\n$$\\alpha_{\\text{nominal}} = \\Pr(X \\le k \\mid X \\sim \\mathrm{Binomial}(m, p_0)).$$\n\n对于特定的真实率 $p(\\tau)$（当 $p(\\tau)  p_0$ 时，它位于备择区域），II 型错误概率 $\\beta$ 是在 $H_0$ 为假时未能拒绝它的概率。在“如果 $X \\le k$ 则拒绝”的拒绝规则下，未能拒绝等价于 $X  k$，因此\n$$\\beta(p(\\tau)) = \\Pr\\!\\big(X  k \\mid X \\sim \\mathrm{Binomial}(m, p(\\tau))\\big) = 1 - \\Pr\\!\\big(X \\le k \\mid X \\sim \\mathrm{Binomial}(m, p(\\tau))\\big).$$\n为了研究在 ROC 固定的情况下，移动阈值如何影响错误概率，我们对每个 $\\tau$ 进行如下计算：\n- 由 Gaussian 分数模型导出的 $p(\\tau) = \\mathrm{TPR}(\\tau)$ 和 $\\mathrm{FPR}(\\tau)$；\n- 在 $p_0$ 下的名义 I 型错误 $\\alpha_{\\text{nominal}}$（与 $\\tau$ 无关，因为 $k$ 是用 $p_0$ 选择的）；\n- 在 $\\tau$ 处的实现 I 型错误，$\\alpha_{\\text{real}}(\\tau) = \\Pr(X \\le k \\mid m, p(\\tau))$，这在 $p(\\tau) \\ge p_0$ 时有意义，并且通常小于或等于 $\\alpha_{\\text{nominal}}$，因为随着成功概率的增加，下尾概率会减小；\n- 在 $\\tau$ 处的实现 II 型错误，$\\beta_{\\text{real}}(\\tau) = 1 - \\Pr(X \\le k \\mid m, p(\\tau))$，这在 $p(\\tau)  p_0$ 时有意义，并且随着 $p(\\tau)$ 的减小而增大。\n\n算法步骤：\n1. 使用标准正态累积分布函数 $\\Phi(\\cdot)$ 计算 $\\mathrm{TPR}(\\tau)$ 和 $\\mathrm{FPR}(\\tau)$，公式为\n$$\\mathrm{TPR}(\\tau) = 1 - \\Phi\\!\\left(\\frac{\\tau - \\mu_1}{\\sigma}\\right), \\quad \\mathrm{FPR}(\\tau) = 1 - \\Phi\\!\\left(\\frac{\\tau - \\mu_0}{\\sigma}\\right).$$\n2. 通过从 $k=-1$ 向上扫描，找到满足 $\\Pr(X \\le k \\mid m, p_0) \\le \\alpha_{\\text{target}}$ 的最大整数 $k$。这里 $k=-1$ 对应于一个空的拒绝域（永不拒绝），随着 $k$ 的增加，下尾概率也随之增加。\n3. 使用二项累积分布函数计算 $\\alpha_{\\text{nominal}} = \\Pr(X \\le k \\mid m, p_0)$。\n4. 对于每个 $\\tau$，计算 $\\alpha_{\\text{real}}(\\tau) = \\Pr(X \\le k \\mid m, p(\\tau))$ 和 $\\beta_{\\text{real}}(\\tau) = 1 - \\Pr(X \\le k \\mid m, p(\\tau))$。\n5. 将每个数值四舍五入到六位小数，并以要求的格式输出一个列表的列表。\n\n测试套件覆盖范围：\n- $\\tau = -0.5$ 和 $\\tau = 0.0$ 产生高于 $p_0$ 的高 $\\mathrm{TPR}(\\tau)$（原假设的理想路径）。\n- $\\tau = 0.464$ 目标是 $\\mathrm{TPR}(\\tau)$ 接近 $p_0$ 的边界（边界条件）。\n- $\\tau = 1.0$ 和 $\\tau = 1.5$ 产生低于 $p_0$ 的较低 $\\mathrm{TPR}(\\tau)$（备择区域，其中 $\\beta$ 变得相关）。\n- $\\tau = 2.5$ 产生非常低的 $\\mathrm{TPR}(\\tau)$（高 II 型错误的边缘情况）。\n\n所有概率均以小数表示，而非百分比。不涉及物理单位或角度单位。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm, binom\n\ndef compute_tpr_fpr(tau, mu0, mu1, sigma):\n    # TPR = 1 - Phi((tau - mu1)/sigma)\n    # FPR = 1 - Phi((tau - mu0)/sigma)\n    z_pos = (tau - mu1) / sigma\n    z_neg = (tau - mu0) / sigma\n    tpr = 1.0 - norm.cdf(z_pos)\n    fpr = 1.0 - norm.cdf(z_neg)\n    return tpr, fpr\n\ndef choose_critical_k(m, p0, alpha_target):\n    # Find largest integer k such that BinomCDF(k; m, p0) = alpha_target.\n    # Start from k = -1 (empty rejection region) and increment while condition holds.\n    k = -1\n    while True:\n        next_k = k + 1\n        if next_k > m:\n            # Cannot exceed m; break\n            break\n        cdf_next = binom.cdf(next_k, m, p0)\n        if cdf_next = alpha_target:\n            k = next_k\n        else:\n            break\n    return k\n\ndef solve():\n    # Fixed score model parameters\n    mu0 = 0.0\n    mu1 = 1.5\n    sigma = 1.0\n\n    # Hypothesis test parameters\n    p0 = 0.85        # baseline true positive rate under H0 (decimal)\n    m = 50           # number of positive instances sampled\n    alpha_target = 0.05  # target significance level (decimal)\n\n    # Thresholds to evaluate\n    thresholds = [-0.5, 0.0, 0.464, 1.0, 1.5, 2.5]\n\n    # Choose critical cutoff k based on m, p0, and alpha_target\n    k = choose_critical_k(m, p0, alpha_target)\n    # Compute nominal alpha at this k\n    alpha_nominal = binom.cdf(k, m, p0) if k >= 0 else 0.0\n\n    results = []\n    for tau in thresholds:\n        # Compute TPR and FPR from the fixed ROC model\n        tpr, fpr = compute_tpr_fpr(tau, mu0, mu1, sigma)\n        # Realized Type I error at tau (computed for completeness even if p(tau)  p0)\n        alpha_real = binom.cdf(k, m, tpr) if k >= 0 else 0.0\n        # Realized Type II error at tau\n        beta_real = 1.0 - alpha_real  # since accept region is X > k\n        # Round values to six decimal places as required\n        out = [\n            round(tau, 6),\n            round(tpr, 6),\n            round(fpr, 6),\n            round(alpha_nominal, 6),\n            round(alpha_real, 6),\n            round(beta_real, 6)\n        ]\n        results.append(out)\n\n    # Format as a single line: list of lists\n    # Ensure exact formatting with commas and brackets, no extra text.\n    def format_list(lst):\n        return \"[\" + \",\".join(str(x) for x in lst) + \"]\"\n    print(\"[\" + \",\".join(format_list(r) for r in results) + \"]\")\n\nsolve()\n```", "id": "3130833"}]}