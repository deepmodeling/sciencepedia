{"hands_on_practices": [{"introduction": "本次练习将提供一个基础的、基于代码的实践，帮助你识别欠拟合与过拟合。我们将从一个已知真实复杂度的多项式函数中生成一个合成数据集。通过拟合不同阶数和正则化强度的多项式模型，你将直接观察到模型容量如何影响性能。我们将开发并应用量化标准，包括训练/验证误差以及一个基于残差傅里叶变换的新颖指标，来自动地对每个模型进行分类。这个练习将偏见和方差这两个抽象概念变得具体，并展示了它们的典型特征。[@problem_id:3135788]", "problem": "给定一个一维回归的监督学习场景，该场景根据经验风险最小化（ERM）进行建模。设输入为 $x \\in [-1,1]$，真实目标函数为一个已知阶数 $d^\\star$ 的多项式，并受到零均值、方差为 $\\sigma^2$ 的高斯噪声污染。具体来说，数据通过 $y = f^\\star(x) + \\varepsilon$ 生成，其中 $f^\\star(x) = \\sum_{k=0}^{d^\\star} a_k x^k$，$d^\\star = 4$，系数为 $a_0 = 0.3$, $a_1 = -0.8$, $a_2 = 0.5$, $a_3 = 0.0$, $a_4 = 0.7$，噪声为 $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^2)$ 且 $\\sigma = 0.1$（因此 $\\sigma^2 = 0.01$）。数据集大小为 $N = 200$ 个点，其输入 $x$ 从 $[-1,1]$ 区间内均匀抽取。使用 $N_{\\text{train}} = 120$ 个样本进行训练， $N_{\\text{valid}} = 80$ 个样本进行验证。使用固定的随机种子 $42$ 以确保可复现性。\n\n您的任务是实现带岭正则化（也称为 $\\ell_2$ 正则化）的多项式回归。对于选定的模型阶数 $d$ 和正则化强度 $\\lambda \\ge 0$，构建设计矩阵 $\\Phi \\in \\mathbb{R}^{m \\times (d+1)}$，其元素为 $\\Phi_{i,k} = x_i^k$。给定训练数据 $(\\Phi_{\\text{train}}, y_{\\text{train}})$，使用闭式解计算岭估计量的系数 $w \\in \\mathbb{R}^{d+1}$\n$$\nw = \\left(\\Phi_{\\text{train}}^\\top \\Phi_{\\text{train}} + \\lambda I\\right)^{-1} \\Phi_{\\text{train}}^\\top y_{\\text{train}},\n$$\n其中 $I$ 是 $(d+1) \\times (d+1)$ 的单位矩阵。使用此估计量在训练集和验证集上进行预测，并计算残差 $r_{\\text{train}} = y_{\\text{train}} - \\hat{y}_{\\text{train}}$ 和 $r_{\\text{valid}} = y_{\\text{valid}} - \\hat{y}_{\\text{valid}}$。\n\n根据以下定义和测量方法，从第一性原理出发，识别欠拟合和过拟合：\n\n- 均方误差（MSE）定义为 $ \\text{MSE} = \\frac{1}{m} \\sum_{i=1}^m (y_i - \\hat{y}_i)^2 $。令 $\\text{MSE}_{\\text{train}}$ 和 $\\text{MSE}_{\\text{valid}}$ 分别表示训练和验证均方误差。\n- 残差中的振荡在频域中进行量化。计算验证残差序列的离散傅里叶变换（DFT）（首次出现：离散傅里叶变换（DFT）），该序列已根据其对应的输入 $x$ 按升序排序。使用实值离散傅里叶变换 $R = \\text{rfft}(r_{\\text{valid-sorted}})$ 并定义高频能量比如下\n$$\n\\rho_{\\text{HF}} = \\frac{\\sum_{k \\in \\mathcal{H}} |R_k|^2}{\\sum_{k \\in \\mathcal{P}} |R_k|^2},\n$$\n其中 $\\mathcal{P}$ 索引除零频仓外的所有正频仓，$\\mathcal{H}$ 索引正频仓中最高的四分之一（即 $\\mathcal{P}$ 中频率最高的 $25\\%$）。如果分母为零，则定义 $\\rho_{\\text{HF}} = 0$。\n\n使用以下带固定阈值的分类规则来判断模型是欠拟合、拟合良好还是过拟合。记已知噪声方差为 $\\sigma^2 = 0.01$，并设阈值为 $t_u = 1.3$, $t_o = 0.9$, $t_o' = 1.2$, $h_u = 0.35$, $h_o = 0.45$。\n\n- 欠拟合（代码 $0$）：如果 $d  d^\\star$，或者如果 $\\text{MSE}_{\\text{train}} \\ge t_u \\sigma^2$ 且 $\\text{MSE}_{\\text{valid}} \\ge t_u \\sigma^2$ 且 $\\rho_{\\text{HF}} \\le h_u$，则判断为欠拟合。\n- 过拟合（代码 $2$）：如果 $d  d^\\star$ 且 $\\text{MSE}_{\\text{train}} \\le t_o \\sigma^2$ 且 $\\text{MSE}_{\\text{valid}} \\ge t_o' \\sigma^2$ 且 $\\rho_{\\text{HF}} \\ge h_o$，则判断为过拟合。\n- 拟合良好（代码 $1$）：如果以上两个条件都不满足，则判断为拟合良好。\n\n实现以上步骤，并评估以下改变 $d$ 和 $\\lambda$ 的测试套件：\n\n- 情况 1：$d = 2$, $\\lambda = 0.001$。\n- 情况 2：$d = 4$, $\\lambda = 0.05$。\n- 情况 3：$d = 12$, $\\lambda = 0.0$。\n- 情况 4：$d = 12$, $\\lambda = 10.0$。\n- 情况 5：$d = 4$, $\\lambda = 0.0$。\n\n您的程序必须按规定生成数据集，为每种情况拟合模型，计算指标，并按给定顺序输出分类代码。您的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表（例如，$[0,1,2,0,1]$）。本问题不需要物理单位、角度单位或百分比。最终输出值为如上指定的整数。程序必须是完整且可直接运行的，无需外部输入或文件。请按规定使用确定性种子，以便任何人运行该程序时结果都是可复现的。", "solution": "问题陈述已经过仔细验证，并被确定为有效。它在科学上是合理的，内容是自洽的，且提法是适定的，在计算统计学和机器学习领域提供了一个清晰且可形式化的任务。\n\n任务是根据一套精确的量化标准，将多项式回归模型分类为欠拟合、拟合良好或过拟合。解决方案涉及多个测试案例的数据生成、模型拟合、指标计算和分类。由于指定了随机种子，整个过程是确定性的。\n\n### 步骤 1：数据生成与准备\n\n这个回归问题的基础是一个合成数据集。输入 $x$ 和输出 $y$ 之间的真实关系由一个已知的 $d^\\star=4$ 阶多项式函数 $f^\\star(x)$ 定义：\n$$\nf^\\star(x) = a_0 + a_1 x + a_2 x^2 + a_3 x^3 + a_4 x^4\n$$\n其系数为 $a_0 = 0.3$，$a_1 = -0.8$，$a_2 = 0.5$，$a_3 = 0.0$，$a_4 = 0.7$。\n\n观测数据被加性高斯白噪声 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$ 所污染，其中噪声方差为 $\\sigma^2 = 0.01$。因此，每个数据点 $(x_i, y_i)$ 根据以下模型生成：\n$$\ny_i = f^\\star(x_i) + \\varepsilon_i\n$$\n总共创建了 $N=200$ 个数据点。输入值 $x_i$ 从区间 $[-1, 1]$ 上的均匀分布中抽取。为确保可复现性，随机数生成器使用固定的种子 $42$ 进行初始化。\n\n生成的 $N=200$ 个点的数据集随后被确定性地打乱并分割成一个大小为 $N_{\\text{train}} = 120$ 的训练集和一个大小为 $N_{\\text{valid}} = 80$ 的验证集。这种划分使我们能够训练模型并独立评估其泛化性能。\n\n### 步骤 2：带岭正则化的多项式回归\n\n对于每个测试案例，我们将一个指定阶数 $d$ 的多项式模型拟合到训练数据上。模型假设的形式为：\n$$\n\\hat{y}(x) = \\sum_{k=0}^d w_k x^k = \\mathbf{w}^\\top \\phi(x)\n$$\n其中 $\\mathbf{w} \\in \\mathbb{R}^{d+1}$ 是待学习的模型系数向量，$\\phi(x) = [1, x, x^2, \\dots, x^d]^\\top$ 是特征向量。\n\n对于一组 $m$ 个训练样本，我们构建设计矩阵 $\\Phi_{\\text{train}} \\in \\mathbb{R}^{m \\times (d+1)}$，其中每个条目为 $(\\Phi_{\\text{train}})_{i,k} = x_i^k$，对于 $i \\in \\{1, \\dots, m\\}$ 和 $k \\in \\{0, \\dots, d\\}$。\n\n系数 $\\mathbf{w}$ 使用岭回归进行估计，该方法最小化正则化的平方误差和：\n$$\n\\mathcal{L}(\\mathbf{w}) = \\|\\mathbf{y}_{\\text{train}} - \\Phi_{\\text{train}}\\mathbf{w}\\|_2^2 + \\lambda \\|\\mathbf{w}\\|_2^2\n$$\n这里，$\\lambda \\ge 0$ 是正则化参数，它控制对系数大小的惩罚。最优权重向量 $\\mathbf{w}$ 的闭式解由正规方程给出：\n$$\n\\mathbf{w} = \\left(\\Phi_{\\text{train}}^\\top \\Phi_{\\text{train}} + \\lambda I\\right)^{-1} \\Phi_{\\text{train}}^\\top \\mathbf{y}_{\\text{train}}\n$$\n其中 $I$ 是 $(d+1) \\times (d+1)$ 的单位矩阵。为了数值稳定性，这个线性系统使用 `numpy.linalg.solve` 求解，而不是显式地计算矩阵的逆。\n\n### 步骤 3：模型评估指标\n\n一旦模型训练完成（即 $\\mathbf{w}$ 已计算得出），其性能将使用两个关键指标进行评估。\n\n**均方误差（MSE）：** MSE 衡量预测值 $\\hat{y}_i$ 与实际值 $y_i$ 之间平方差的平均值。它为训练集和验证集分别计算：\n$$\n\\text{MSE}_{\\text{train}} = \\frac{1}{N_{\\text{train}}} \\sum_{i=1}^{N_{\\text{train}}} (y_{\\text{train},i} - \\hat{y}_{\\text{train},i})^2\n$$\n$$\n\\text{MSE}_{\\text{valid}} = \\frac{1}{N_{\\text{valid}}} \\sum_{i=1}^{N_{\\text{valid}}} (y_{\\text{valid},i} - \\hat{y}_{\\text{valid},i})^2\n$$\n\n**高频能量比（$\\rho_{\\text{HF}}$）：** 该指标量化了模型在验证集上误差的振荡特性，这是过拟合的一个常见症状。其步骤如下：\n1.  计算验证残差：$\\mathbf{r}_{\\text{valid}} = \\mathbf{y}_{\\text{valid}} - \\hat{\\mathbf{y}}_{\\text{valid}}$。\n2.  根据其对应的输入值 $x_{\\text{valid}}$ 的升序对这些残差进行排序。令此排序后的序列为 $\\mathbf{r}_{\\text{valid-sorted}}$。\n3.  计算排序后残差的实值离散傅里叶变换（DFT）：$R = \\text{rfft}(\\mathbf{r}_{\\text{valid-sorted}})$。对于 $N_{\\text{valid}} = 80$，输出 $R$ 是一个长度为 $41$ 的复数数组。\n4.  正频仓集合 $\\mathcal{P}$ 包含除零频（DC）分量之外的所有频仓。对于 RFFT 输出 $R$，这些对应于索引 $k \\in \\{1, 2, \\dots, 40\\}$。\n5.  高频仓集合 $\\mathcal{H}$ 定义为 $\\mathcal{P}$ 中频率最高的四分之一（即最高的 $25\\%$）。这对应于最后的 $40 \\times 0.25 = 10$ 个频仓，其索引为 $k \\in \\{31, 32, \\dots, 40\\}$。\n6.  高频能量比即为 $\\mathcal{H}$ 中的能量与 $\\mathcal{P}$ 中总能量的比值：\n    $$\n    \\rho_{\\text{HF}} = \\frac{\\sum_{k \\in \\mathcal{H}} |R_k|^2}{\\sum_{k \\in \\mathcal{P}} |R_k|^2}\n    $$\n    如果分母为零，$\\rho_{\\text{HF}}$ 定义为 $0$。\n\n### 步骤 4：分类逻辑\n\n计算出的指标用于根据一套固定的规则将每个模型分类为欠拟合、拟合良好或过拟合。真实噪声方差为 $\\sigma^2 = 0.01$，阈值为 $t_u = 1.3$, $t_o = 0.9$, $t_o' = 1.2$, $h_u = 0.35$, $h_o = 0.45$。\n\n- **欠拟合（代码 $0$）：** 如果模型阶数 $d$ 小于真实阶数 $d^\\star$，*或者*模型在训练集和验证集上都表现出高误差，并且残差振荡较低，则判定为欠拟合。形式上：\n  $$\n  (d  d^\\star) \\lor (\\text{MSE}_{\\text{train}} \\ge t_u \\sigma^2 \\land \\text{MSE}_{\\text{valid}} \\ge t_u \\sigma^2 \\land \\rho_{\\text{HF}} \\le h_u)\n  $$\n\n- **过拟合（代码 $2$）：** 如果模型阶数 $d$ 大于 $d^\\star$，*并且*它表现出较低的训练误差、显著较高的验证误差以及残差中的高频振荡，则判定为过拟合。形式上：\n  $$\n  (d  d^\\star) \\land (\\text{MSE}_{\\text{train}} \\le t_o \\sigma^2 \\land \\text{MSE}_{\\text{valid}} \\ge t_o' \\sigma^2 \\land \\rho_{\\text{HF}} \\ge h_o)\n  $$\n\n- **拟合良好（代码 $1$）：** 如果一个模型既不满足欠拟合标准，也不满足过拟合标准，则将其分类为拟合良好。\n\n这些规则为偏差-方差权衡的概念提供了一个具体的、算法化的定义。程序为每个指定的测试案例实现这一逻辑，生成一个最终的分类代码列表。", "answer": "```python\nimport numpy as np\nimport scipy.fft\n\ndef solve():\n    \"\"\"\n    Main function to execute the polynomial regression analysis and classification.\n    \"\"\"\n    #\n    # Step 0: Define constants and problem parameters\n    #\n    RANDOM_SEED = 42\n    D_STAR = 4\n    A_COEFFS = np.array([0.3, -0.8, 0.5, 0.0, 0.7])\n    SIGMA = 0.1\n    SIGMA_SQUARED = SIGMA**2\n    N_TOTAL = 200\n    N_TRAIN = 120\n    N_VALID = 80\n\n    # Classification thresholds\n    T_U = 1.3\n    T_O = 0.9\n    T_O_PRIME = 1.2\n    H_U = 0.35\n    H_O = 0.45\n\n    # Test cases to evaluate\n    test_cases = [\n        {'d': 2, 'lambda': 0.001},  # Case 1\n        {'d': 4, 'lambda': 0.05},   # Case 2\n        {'d': 12, 'lambda': 0.0},    # Case 3\n        {'d': 12, 'lambda': 10.0},   # Case 4\n        {'d': 4, 'lambda': 0.0},    # Case 5\n    ]\n    \n    #\n    # Step 1: Generate dataset\n    #\n    rng = np.random.default_rng(RANDOM_SEED)\n\n    # Generate x values\n    x = rng.uniform(-1, 1, size=N_TOTAL)\n\n    # Generate true function values y_star\n    def f_star(x_in):\n        return A_COEFFS[0] + A_COEFFS[1] * x_in + A_COEFFS[2] * x_in**2 + \\\n               A_COEFFS[3] * x_in**3 + A_COEFFS[4] * x_in**4\n\n    y_star = f_star(x)\n\n    # Add Gaussian noise\n    noise = rng.normal(0, SIGMA, size=N_TOTAL)\n    y = y_star + noise\n\n    # Split into training and validation sets\n    indices = np.arange(N_TOTAL)\n    rng.shuffle(indices)\n    \n    train_indices = indices[:N_TRAIN]\n    valid_indices = indices[N_TRAIN:]\n\n    x_train, y_train = x[train_indices], y[train_indices]\n    x_valid, y_valid = x[valid_indices], y[valid_indices]\n\n    #\n    # Helper functions\n    #\n    def construct_design_matrix(x_data, degree):\n        \"\"\"Constructs the polynomial design matrix Phi.\"\"\"\n        return np.vander(x_data, degree + 1, increasing=True)\n\n    results = []\n\n    #\n    # Step 2-4: Process each test case\n    #\n    for case in test_cases:\n        d = case['d']\n        lambda_reg = case['lambda']\n\n        # Construct design matrices\n        phi_train = construct_design_matrix(x_train, d)\n        phi_valid = construct_design_matrix(x_valid, d)\n\n        # Fit the model using ridge regression (numerically stable)\n        d_plus_1 = d + 1\n        A = phi_train.T @ phi_train + lambda_reg * np.eye(d_plus_1)\n        b = phi_train.T @ y_train\n        w = np.linalg.solve(A, b)\n\n        # Make predictions\n        y_hat_train = phi_train @ w\n        y_hat_valid = phi_valid @ w\n\n        # Calculate metrics\n        # a) MSE\n        mse_train = np.mean((y_train - y_hat_train)**2)\n        mse_valid = np.mean((y_valid - y_hat_valid)**2)\n        \n        # b) High-frequency energy ratio rho_HF\n        residuals_valid = y_valid - y_hat_valid\n        \n        # Sort residuals according to x_valid\n        sort_indices = np.argsort(x_valid)\n        residuals_valid_sorted = residuals_valid[sort_indices]\n        \n        # Compute RFFT\n        R = scipy.fft.rfft(residuals_valid_sorted)\n        \n        # Calculate energies\n        # P: positive frequencies (indices 1 to end)\n        # H: top quartile of P (last 10 for N_valid=80)\n        # N_valid = 80 -> rfft length = 41. P_indices = 1..40. H_indices = 31..40.\n        num_positive_freqs = len(R) - 1\n        top_quartile_size = int(np.ceil(0.25 * num_positive_freqs))\n        \n        energy_P = np.sum(np.abs(R[1:])**2)\n        energy_H = np.sum(np.abs(R[-top_quartile_size:])**2)\n        \n        rho_hf = energy_H / energy_P if energy_P > 0 else 0.0\n        \n        # Apply classification rules\n        code = 1 # Default to well-fit\n\n        # Underfitting rule\n        is_underfit_by_degree = (d  D_STAR)\n        is_underfit_by_metrics = (mse_train >= T_U * SIGMA_SQUARED and \\\n                                  mse_valid >= T_U * SIGMA_SQUARED and \\\n                                  rho_hf = H_U)\n        if is_underfit_by_degree or is_underfit_by_metrics:\n            code = 0\n\n        # Overfitting rule\n        is_overfit_by_metrics = (d > D_STAR and \\\n                                 mse_train = T_O * SIGMA_SQUARED and \\\n                                 mse_valid >= T_O_PRIME * SIGMA_SQUARED and \\\n                                 rho_hf >= H_O)\n        if is_overfit_by_metrics:\n            code = 2\n            \n        results.append(code)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3135788"}, {"introduction": "在了解了模型复杂度过高会导致过拟合之后，我们现在转向一种强大的缓解技术：正则化。本练习将正则化置于分布鲁棒优化的概念框架下，我们寻求一个不仅在训练数据上表现良好，而且在其微小扰动下也同样稳健的模型。你将实现一系列正则化线性回归模型，并分析正则化参数 $\\lambda$ 如何影响欠拟合与过拟合之间的权衡。通过绘制训练和测试误差随 $\\lambda$ 变化的曲线，你将凭经验发现经典的“U形”测试误差曲线，并找到最小化泛化误差的最优正则化强度。[@problem_id:3189697]", "problem": "您将研究在一个简单的分布鲁棒优化设定下，一个鲁棒性参数如何在过拟合和欠拟合之间进行权衡。您的程序必须生成合成数据，训练一系列由鲁棒性参数索引的估计器，并计算诊断量，以验证适度的鲁棒性可以减少过拟合，而过度的鲁棒性则会导致欠拟合。\n\n基本原理。考虑使用平方损失的线性回归。设 $x \\in \\mathbb{R}^d$，$y \\in \\mathbb{R}$，以及一个带有参数 $w \\in \\mathbb{R}^d$ 的线性预测器 $f_w(x) = w^\\top x$。在训练数据 $\\{(x_i,y_i)\\}_{i=1}^n$ 上的经验风险最小化目标是平均平方损失 $n^{-1} \\sum_{i=1}^n (y_i - w^\\top x_i)^2$。分布鲁棒优化公式用一个围绕经验分布的模糊集（ambiguity set）上的最坏情况期望来取代名义期望。对于由特征的 $\\ell_2$ 范数有界扰动所导出的一大类模糊集，其鲁棒对应问题已知等价于经验风险加上对 $w$ 的 $\\ell_2$ 惩罚项，其惩罚权重随鲁棒性半径的增加而增加。这产生了一系列估计器，它们在经验风险最小化（低鲁棒性）和强正则化解（高鲁棒性）之间进行插值。\n\n数据生成。对于下面的每个测试用例，按如下方式从同一分布生成一个训练集和一个独立的测试集。对于给定的维度 $d$ 和样本大小 $n$，设 $G \\in \\mathbb{R}^{d \\times d}$ 具有独立的标准正态分布的元素。从 $G$ 的 $QR$ 分解中计算出瘦正交因子 $Q \\in \\mathbb{R}^{d \\times d}$。设特征值为 $e_k = 1 - 0.95 (k-1)/(d-1)$，其中 $k \\in \\{1,\\dots,d\\}$，并定义协方差矩阵 $\\Sigma = Q \\,\\mathrm{diag}(e_1,\\dots,e_d)\\, Q^\\top$。从均值为零、协方差为 $\\Sigma$ 的多元正态分布中独立抽取 $X \\in \\mathbb{R}^{n \\times d}$ 的各行，并以同样的方式抽取 $X_{\\mathrm{test}} \\in \\mathbb{R}^{n_{\\mathrm{test}} \\times d}$ 的各行，其中 $n_{\\mathrm{test}} = 2000$。通过 $w^\\star_j = 1/j$（对于 $j \\in \\{1,\\dots,10\\}$）和 $w^\\star_j = 0$（对于 $j \\in \\{11,\\dots,d\\}$）定义真实参数 $w^\\star \\in \\mathbb{R}^d$。生成 $y = X w^\\star + \\sigma \\,\\varepsilon$ 和 $y_{\\mathrm{test}} = X_{\\mathrm{test}} w^\\star + \\sigma \\,\\varepsilon_{\\mathrm{test}}$，其中 $\\varepsilon \\in \\mathbb{R}^n$ 和 $\\varepsilon_{\\mathrm{test}} \\in \\mathbb{R}^{n_{\\mathrm{test}}}$ 的元素是独立的标准正态随机变量。对每个测试用例，在生成 $G$、$X$、$X_{\\mathrm{test}}$、$\\varepsilon$ 和 $\\varepsilon_{\\mathrm{test}}$ 之前，使用指定的随机种子初始化伪随机数生成器。\n\n鲁棒估计器。对于每个非负的鲁棒性参数 $\\lambda$，训练一个估计器，该估计器最小化经验平方损失加上 $\\lambda$ 乘以 $w$ 的平方 $\\ell_2$ 范数，即最小化 $n^{-1} \\sum_{i=1}^n (y_i - w^\\top x_i)^2 + \\lambda \\|w\\|_2^2$。精确计算最小化器 $w_\\lambda$，然后计算：\n- 训练均方误差 $\\mathrm{MSE}_{\\mathrm{train}}(\\lambda) = n^{-1} \\sum_{i=1}^n (y_i - x_i^\\top w_\\lambda)^2$。\n- 测试均方误差 $\\mathrm{MSE}_{\\mathrm{test}}(\\lambda) = n_{\\mathrm{test}}^{-1} \\sum_{i=1}^{n_{\\mathrm{test}}} (y_{\\mathrm{test},i} - x_{\\mathrm{test},i}^\\top w_\\lambda)^2$。\n- 泛化差距 $g(\\lambda) = \\mathrm{MSE}_{\\mathrm{test}}(\\lambda) - \\mathrm{MSE}_{\\mathrm{train}}(\\lambda)$。\n\n您的程序必须处理以下三个测试用例。每个测试用例是一个元组 $(n,d,\\sigma,\\text{seed},\\Lambda)$，其中 $\\Lambda$ 是要评估的鲁棒性参数列表：\n- 测试用例 1：$(n=80, d=60, \\sigma=1.5, \\text{seed}=7, \\Lambda = [0, 0.1, 1, 10, 100])$。\n- 测试用例 2：$(n=100, d=30, \\sigma=2.0, \\text{seed}=11, \\Lambda = [0, 0.01, 0.1, 1, 5])$。\n- 测试用例 3：$(n=60, d=50, \\sigma=0.5, \\text{seed}=19, \\Lambda = [0, 0.01, 0.1, 1, 20])$。\n\n对于每个测试用例，计算并报告三个整数：\n1. 获得最小测试均方误差 $\\mathrm{MSE}_{\\mathrm{test}}(\\lambda)$ 的 $\\lambda \\in \\Lambda$ 的索引 $i^\\star$（从零开始），若有平局则选择最小的索引。\n2. 一个指示符 $b_1 \\in \\{0,1\\}$，如果序列 $\\mathrm{MSE}_{\\mathrm{train}}(\\lambda)$ 在 $\\Lambda$ 上随 $\\lambda$ 在数值公差范围内严格递增（将其解释为非递减且至少有一次严格增加，使用公差 $10^{-10}$），则其值为 $1$，否则为 $0$。\n3. 一个指示符 $b_2 \\in \\{0,1\\}$，如果泛化差距从 $\\lambda=0$ 到 $\\lambda = \\Lambda[i^\\star]$ 在数值公差范围内严格减小（即 $g(0)  g(\\Lambda[i^\\star]) + 10^{-10}$），则其值为 $1$，否则为 $0$。\n\n最终输出格式。您的程序应生成一行输出，其中包含一个由方括号括起来的、逗号分隔的整数列表，该列表由按顺序连接的各测试用例的三元组构成。例如，输出必须类似于 $[i^\\star_1,b_{1,1},b_{2,1},i^\\star_2,b_{1,2},b_{2,2},i^\\star_3,b_{1,3},b_{2,3}]$。\n\n不涉及物理单位或角度单位；所有量均为无量纲实数。通过在每个测试用例中使用指定的种子来初始化伪随机数生成器，确保所有计算都是确定性的。", "solution": "该问题要求在线性回归设定中，分析欠拟合与过拟合之间的权衡，其机制源于分布鲁棒优化。该框架引入了一个鲁棒性参数 $\\lambda$，如题目所述，它等价于岭回归（Ridge Regression）中的正则化参数。我们将首先确定估计器的解析解，然后详细说明数据生成和评估过程。\n\n### 基于原理的设计\n\n#### 1. 作为岭回归的鲁棒估计器\n\n问题定义了一个估计器 $w_\\lambda$，它对于给定的鲁棒性参数 $\\lambda \\ge 0$ 最小化目标函数：\n$$ J(w) = \\frac{1}{n} \\sum_{i=1}^n (y_i - w^\\top x_i)^2 + \\lambda \\|w\\|_2^2 $$\n该目标由两项组成：经验风险（训练数据上的平均平方误差）和正则化项（对参数向量 $w$ 的 $\\ell_2$ 惩罚）。这是众所周知的岭回归的目标函数。\n\n为了找到最小化 $J(w)$ 的最优参数向量 $w_\\lambda$，我们计算 $J(w)$ 关于 $w$ 的梯度并将其设为零。在矩阵表示法中，设 $X \\in \\mathbb{R}^{n \\times d}$ 是特征向量 $x_i^\\top$ 构成的矩阵， $y \\in \\mathbb{R}^n$ 是目标值 $y_i$ 构成的向量。目标函数可以写成：\n$$ J(w) = \\frac{1}{n} \\|y - Xw\\|_2^2 + \\lambda w^\\top w $$\n梯度 $\\nabla_w J(w)$ 为：\n$$ \\nabla_w J(w) = \\nabla_w \\left( \\frac{1}{n}(y - Xw)^\\top(y - Xw) + \\lambda w^\\top w \\right) $$\n$$ \\nabla_w J(w) = \\frac{1}{n} \\nabla_w (y^\\top y - 2y^\\top Xw + w^\\top X^\\top Xw) + 2\\lambda w $$\n$$ \\nabla_w J(w) = \\frac{1}{n} (-2X^\\top y + 2X^\\top Xw) + 2\\lambda w $$\n将梯度设为零以求最小值：\n$$ \\frac{1}{n} (2X^\\top Xw - 2X^\\top y) + 2\\lambda w = 0 $$\n$$ X^\\top Xw - X^\\top y + n\\lambda w = 0 $$\n$$ (X^\\top X + n\\lambda I)w = X^\\top y $$\n其中 $I$ 是 $d \\times d$ 的单位矩阵。\n\n这就得出了岭回归的正规方程。解 $w_\\lambda$ 通过求解这个线性系统得到：\n$$ w_\\lambda = (X^\\top X + n\\lambda I)^{-1} X^\\top y $$\n对于任何 $\\lambda  0$，矩阵 $(X^\\top X + n\\lambda I)$ 都是正定的，因此是可逆的，保证了唯一解的存在。对于 $\\lambda=0$，这简化为普通最小二乘法（OLS）。我们将使用一个数值稳定的线性系统求解器来为所提供的列表 $\\Lambda$ 中的每个值找到 $w_\\lambda$。\n\n#### 2. 数据生成过程\n\n问题指定了生成合成数据的详细过程，通过随机种子确保可复现性。\n1.  一个随机正交矩阵 $Q \\in \\mathbb{R}^{d \\times d}$ 是通过对一个具有标准正态元素的矩阵 $G$ 进行 QR 分解而生成的。$Q$ 的列将作为数据协方差矩阵的特征向量。\n2.  定义了一组特征值 $e_k = 1 - 0.95 \\frac{k-1}{d-1}$，其中 $k=1, \\dots, d$。这些特征值从 $e_1=1$ 线性衰减到 $e_d=0.05$，从而创建了一个结构化的协方差。\n3.  协方差矩阵构造为 $\\Sigma = Q \\mathrm{diag}(e_1, \\dots, e_d) Q^\\top$。\n4.  用于训练的特征向量（$X \\in \\mathbb{R}^{n \\times d}$）和用于测试的特征向量（$X_{\\mathrm{test}} \\in \\mathbb{R}^{n_{\\mathrm{test}} \\times d}$）从一个多元正态分布 $\\mathcal{N}(0, \\Sigma)$ 中抽取。\n5.  定义了一个真实参数向量 $w^\\star \\in \\mathbb{R}^d$，其具有稀疏的非零元素，模拟了只有少数特征是相关的场景。具体来说，$w^\\star_j = 1/j$ 对于 $j \\in \\{1,\\dots,10\\}$，而 $w^\\star_j = 0$ 对于 $j  10$。\n6.  目标值通过线性模型 $y = Xw^\\star + \\sigma \\varepsilon$ 和 $y_{\\mathrm{test}} = X_{\\mathrm{test}}w^\\star + \\sigma \\varepsilon_{\\mathrm{test}}$ 生成，其中 $\\varepsilon$ 和 $\\varepsilon_{\\mathrm{test}}$ 是独立同分布的标准正态噪声向量。\n\n#### 3. 评估与解释\n\n对于每个 $\\lambda \\in \\Lambda$，我们计算 $w_\\lambda$ 并使用三个关键指标评估其性能：\n-   **训练均方误差 ($\\mathrm{MSE}_{\\mathrm{train}}(\\lambda)$)**：衡量模型对其训练数据的拟合程度。过拟合的模型将具有非常低的训练均方误差。\n-   **测试均方误差 ($\\mathrm{MSE}_{\\mathrm{test}}(\\lambda)$)**：衡量模型对来自同一分布的未见过的新数据的泛化能力。这是模型性能的主要指标。\n-   **泛化差距 ($g(\\lambda)$)**：差值 $\\mathrm{MSE}_{\\mathrm{test}}(\\lambda) - \\mathrm{MSE}_{\\mathrm{train}}(\\lambda)$。巨大的差距是过拟合的典型特征。\n\n每个测试用例所需的输出旨在诊断过拟合和欠拟合：\n1.  **$i^\\star$**：这是使测试误差最小化的 $\\lambda$ 的索引。这个 $\\lambda_ {\\mathrm{opt}} = \\Lambda[i^\\star]$ 代表了最优的正则化量。如果 $\\lambda_{\\mathrm{opt}}  0$，则表明未正则化的 OLS 模型（$\\lambda=0$）是次优的，很可能是由于过拟合。\n2.  **$b_1$**：该指示符验证 $\\mathrm{MSE}_{\\mathrm{train}}(\\lambda)$ 是 $\\lambda$ 的一个非递减函数。这是一个预期的理论性质：随着正则化强度 $\\lambda$ 的增加，对 $w$ 的约束变得更紧，这不可能会降低训练集上的最小化损失。\n3.  **$b_2$**：该指示符检查在最优 $\\lambda_{\\mathrm{opt}}$ 处的泛化差距是否比 $\\lambda=0$ 时小。差距的显著减小（$g(0)  g(\\lambda_{\\mathrm{opt}})$）表明正则化已成功减轻了过拟合。\n\n参数 $\\lambda$ 控制着偏差-方差权衡。低 $\\lambda$（低鲁棒性）导致低偏差、高方差的估计器，可能会过拟合训练数据。高 $\\lambda$（高鲁棒性）导致高偏差、低方差的估计器，可能会欠拟合数据。最优的 $\\lambda$ 在两者之间取得平衡，最小化测试误差。\n\n解决方案的实现遵循这些步骤，为每个测试用例计算所需的量，并格式化最终输出。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Investigates the effect of a robustness parameter on overfitting and underfitting\n    in linear regression by solving a series of test cases.\n\n    The problem is framed as a distributionally robust optimization problem which is\n    equivalent to Ridge Regression. For each test case, the function performs:\n    1. Synthetic data generation based on specified parameters (n, d, sigma, seed).\n    2. Training a series of Ridge regression models for a list of robustness\n       parameters (lambda).\n    3. Computing training MSE, test MSE, and the generalization gap for each model.\n    4. Determining diagnostic quantities (i_star, b1, b2) that characterize the\n       model's behavior in terms of the bias-variance trade-off.\n    \"\"\"\n    test_cases = [\n        (80, 60, 1.5, 7, [0, 0.1, 1, 10, 100]),\n        (100, 30, 2.0, 11, [0, 0.01, 0.1, 1, 5]),\n        (60, 50, 0.5, 19, [0, 0.01, 0.1, 1, 20]),\n    ]\n\n    final_results = []\n    n_test = 2000\n    tol = 1e-10\n\n    for n, d, sigma, seed, Lambda in test_cases:\n        np.random.seed(seed)\n\n        # 1. Data Generation\n        # Generate covariance matrix Sigma\n        G = np.random.randn(d, d)\n        Q, _ = np.linalg.qr(G)\n        \n        # Eigenvalues e_k\n        if d == 1:\n            eigenvalues = np.array([1.0])\n        else:\n            k = np.arange(1, d + 1)\n            # The formula is e_k = 1 - 0.95 * (k-1)/(d-1)\n            eigenvalues = 1 - 0.95 * (k - 1) / (d - 1)\n        \n        Sigma = Q @ np.diag(eigenvalues) @ Q.T\n        \n        # Ground-truth parameter w_star\n        w_star = np.zeros(d)\n        num_nonzero = min(10, d)\n        w_star[:num_nonzero] = 1.0 / np.arange(1, num_nonzero + 1)\n        \n        # Generate feature matrices X and X_test\n        mean_vec = np.zeros(d)\n        X = np.random.multivariate_normal(mean_vec, Sigma, n)\n        X_test = np.random.multivariate_normal(mean_vec, Sigma, n_test)\n        \n        # Generate noise and target variables y and y_test\n        epsilon = np.random.randn(n)\n        epsilon_test = np.random.randn(n_test)\n        y = X @ w_star + sigma * epsilon\n        y_test = X_test @ w_star + sigma * epsilon_test\n\n        # 2. Model Training and Evaluation\n        train_mses = []\n        test_mses = []\n        gaps = []\n        \n        # Pre-compute parts of the normal equation for efficiency\n        XTX = X.T @ X\n        XTy = X.T @ y\n        \n        for lam in Lambda:\n            # Solve (X'X + n*lambda*I)w = X'y for w\n            A = XTX + n * lam * np.identity(d)\n            w_lambda = np.linalg.solve(A, XTy)\n            \n            # Compute training MSE\n            mse_train = np.mean((y - X @ w_lambda)**2)\n            train_mses.append(mse_train)\n            \n            # Compute test MSE\n            mse_test = np.mean((y_test - X_test @ w_lambda)**2)\n            test_mses.append(mse_test)\n            \n            # Compute generalization gap\n            gaps.append(mse_test - mse_train)\n            \n        # 3. Compute Required Outputs\n        \n        # Output 1: i_star (index of minimum test MSE)\n        i_star = np.argmin(test_mses)\n        \n        # Output 2: b1 (indicator for non-decreasing train MSE with strict increase)\n        train_mses_arr = np.array(train_mses)\n        if len(Lambda)  1:\n            diffs = np.diff(train_mses_arr)\n            is_nondecreasing = np.all(diffs = -tol)\n            has_strict_increase = np.any(diffs  tol)\n            b1 = 1 if is_nondecreasing and has_strict_increase else 0\n        else:\n            b1 = 0\n            \n        # Output 3: b2 (indicator for generalization gap reduction)\n        # Assumes Lambda[0] = 0, which is true for all test cases\n        g_zero = gaps[0]\n        g_istar = gaps[i_star]\n        b2 = 1 if g_zero  g_istar + tol else 0\n        \n        final_results.extend([i_star, b1, b2])\n\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```", "id": "3189697"}, {"introduction": "在实践中，模型误差会受到随机波动的影响。验证误差和训练误差之间的简单差异可能并非过拟合的确凿证据——它可能仅仅源于偶然。这个高级练习将引入一个形式化的统计框架来解决这种不确定性。你将学习把检测过拟合视为一个假设检验问题。利用来自交叉验证各折的误差数据，你将执行配对 $t$ 检验，以判断验证误差是否在统计上显著大于训练误差。你还将学习应用关键的多重比较校正方法，如 Bonferroni 和 Benjamini-Hochberg 程序，以便在同时评估多个模型时控制错误率。[@problem_id:3189600]", "problem": "给定多个超参数设置下，同一学习算法的交叉验证（CV）各折的训练和验证误差数组。目标是通过正式检验验证误差是否平均超过训练误差，来确定增加的模型容量是否会导致统计上显著的过拟合。将此问题构建为一组配对假设检验，每个超参数设置对应一个检验，并对多重比较进行校正。\n\n基本定义：对于由 $i \\in \\{1,2,3,4\\}$ 索引的每个超参数设置和由 $k \\in \\{1,\\dots,n\\}$（其中 $n=10$）索引的每个折叠，您拥有训练误差 $e_{\\text{train},i,k}$ 和验证误差 $e_{\\text{valid},i,k}$。定义配对差值 $d_{i,k} = e_{\\text{valid},i,k} - e_{\\text{train},i,k}$。过拟合被操作化为备择假设 $H_{1,i}: \\mathbb{E}[d_{i,k}]  0$，其对立的原假设为 $H_{0,i}: \\mathbb{E}[d_{i,k}] = 0$，使用配对学生t检验在配对样本的标准假设（各折独立，差值近似正态分布）下进行检验。使用与 $H_{1,i}$ 对应的单侧方向。\n\n您必须使用以下两种程序来控制 $m=4$ 个同步检验的总体错误率：\n- 用于控制族群错误率（FWER）的 Bonferroni 校正。\n- 用于控制错误发现率（FDR）的 Benjamini-Hochberg (BH) 程序。\n\n对两种校正均采用 $\\alpha = 0.05$ 的显著性水平。为每个超参数设置报告一个布尔型的过拟合决策：如果在指定的多重比较校正后，该设置的假设检验是显著的，并且 $d_{i,k}$ 的样本均值为正，则返回 $\\,\\text{True}\\,$，否则返回 $\\,\\text{False}\\,$。\n\n测试集：\n- 共有 $m=4$ 个超参数设置，每个设置有 $n=10$ 个折叠。下面的数组是各折的误差（无单位，以小数表示）。\n- 超参数 $i=1$（高容量模型，预期有强过拟合）：\n  - $e_{\\text{train},1,\\cdot} = [0.06, 0.05, 0.07, 0.08, 0.06, 0.05, 0.07, 0.06, 0.08, 0.05]$\n  - $e_{\\text{valid},1,\\cdot} = [0.16, 0.14, 0.18, 0.20, 0.16, 0.14, 0.17, 0.16, 0.20, 0.14]$\n- 超参数 $i=2$（调优良好的模型，预期无显著差异）：\n  - $e_{\\text{train},2,\\cdot} = [0.12, 0.13, 0.11, 0.12, 0.13, 0.11, 0.12, 0.12, 0.13, 0.11]$\n  - $e_{\\text{valid},2,\\cdot} = [0.121, 0.130, 0.112, 0.123, 0.131, 0.109, 0.118, 0.122, 0.131, 0.110]$\n- 超参数 $i=3$（低容量模型，预期欠拟合；验证误差不大于训练误差）：\n  - $e_{\\text{train},3,\\cdot} = [0.20, 0.19, 0.21, 0.22, 0.20, 0.19, 0.21, 0.22, 0.20, 0.19]$\n  - $e_{\\text{valid},3,\\cdot} = [0.18, 0.17, 0.19, 0.20, 0.18, 0.17, 0.19, 0.20, 0.18, 0.17]$\n- 超参数 $i=4$（边界情况，小的正差值伴随较大的变异性）：\n  - $e_{\\text{train},4,\\cdot} = [0.095, 0.105, 0.100, 0.110, 0.090, 0.103, 0.098, 0.107, 0.096, 0.104]$\n  - $e_{\\text{valid},4,\\cdot} = [0.090, 0.115, 0.140, 0.110, 0.105, 0.133, 0.088, 0.127, 0.101, 0.129]$\n\n算法要求：\n- 对于每个 $i$，计算 $H_{1,i}: \\mathbb{E}[d_{i,k}]  0$ 的单侧配对 $t$ 检验的 $p$ 值。\n- 应用 Bonferroni 校正：校正后的 $p$ 值为 $p^{\\text{Bonf}}_{i} = \\min(1, m \\cdot p_{i})$，如果 $p^{\\text{Bonf}}_{i}  \\alpha$ 且 $d_{i,k}$ 的样本均值为正，则判定为 $\\,\\text{True}\\,$。\n- 应用 Benjamini-Hochberg (BH) 升阶程序（step-up procedure），水平为 $\\alpha$：对 $p$ 值进行排序，找到最大的索引 $k$ 使得 $p_{(k)} \\leq \\frac{k}{m}\\alpha$，拒绝所有满足 $p_{i} \\leq p_{(k)}$ 的假设，并对那些被拒绝且 $d_{i,k}$ 样本均值为正的假设判定为 $\\,\\text{True}\\,$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个方括号括起来的逗号分隔列表，该列表由两个无空格的列表组成：第一个列表按顺序给出基于 Bonferroni 的对 $i=1,2,3,4$ 的决策，第二个列表按顺序给出基于 Benjamini-Hochberg 的对 $i=1,2,3,4$ 的决策。例如，一个有效的输出形式为 $[[\\text{True},\\text{False},\\text{False},\\text{True}],[\\text{True},\\text{False},\\text{False},\\text{True}]]$。", "solution": "该问题要求使用一个正式的统计程序来确定增加的模型容量是否会导致显著的过拟合。这通过对来自 $k$ 折交叉验证程序的训练和验证误差（针对 $m=4$ 个不同的超参数设置）进行一系列配对假设检验来完成。我们将使用 Bonferroni 和 Benjamini-Hochberg (BH) 两种方法来控制这些多重比较的总体错误率。\n\n基本原理是将过拟合操作化为期望验证误差大于期望训练误差的条件。对于给定的超参数设置 $i$，数据由配对的观测值组成，即每个 $n=10$ 折的训练误差 $e_{\\text{train},i,k}$ 和验证误差 $e_{\\text{valid},i,k}$。配对的产生是因为两种误差都是在相同的数据分区（折 $k$）上计算的。\n\n首先，我们定义每个超参数设置 $i$ 的每个折 $k$ 的差值为 $d_{i,k} = e_{\\text{valid},i,k} - e_{\\text{train},i,k}$。正的平均差值 $\\mathbb{E}[d_{i,k}]  0$ 表示过拟合。我们将其形式化为单侧假设检验：\n- 原假设 $H_{0,i}: \\mu_{d_i} = \\mathbb{E}[d_{i,k}] = 0$（验证误差和训练误差之间没有差异）。\n- 备择假设 $H_{1,i}: \\mu_{d_i}  0$（验证误差大于训练误差，即过拟合）。\n\n为此，我们使用配对学生t检验。每个假设 $i$ 的检验统计量计算如下：\n$$ t_i = \\frac{\\bar{d}_i}{s_{d_i} / \\sqrt{n}} $$\n其中 $\\bar{d}_i$ 是差值 $d_{i,k}$ 的样本均值，$s_{d_i}$ 是这些差值的样本标准差，$n=10$ 是折叠数（样本数）。在原假设下，该统计量服从自由度为 $n-1=9$ 的 $t$ 分布。由此，我们为 $m=4$ 个检验中的每一个计算一个单侧 $p$ 值 $p_i$。\n\n由于我们同时进行 $m=4$ 个检验，我们必须对多重比较进行校正，以在显著性水平 $\\alpha=0.05$ 下控制总体错误率。\n\n1.  **Bonferroni 校正（族群错误率控制）**：此方法控制在所有检验中至少犯一次 I 类错误（假阳性）的概率。它是一种保守的方法，将每个单独检验的显著性阈值调整为 $\\alpha' = \\alpha/m$。如果其对应的 $p$ 值 $p_i  \\alpha/m$，则拒绝原假设 $H_{0,i}$。如果 $H_{0,i}$ 被拒绝且样本均值差 $\\bar{d}_i  0$，则最终的过拟合决策为 $\\text{True}$。\n\n2.  **Benjamini-Hochberg (BH) 程序（错误发现率控制）**：此方法控制所有被拒绝的假设中假阳性的预期比例。它通常比 Bonferroni 更强大（不那么保守）。程序如下：\n    a. 将原始 $p$ 值按升序排序：$p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(m)}$。\n    b. 找到最大的秩 $k$，使得 $p_{(k)} \\le \\frac{k}{m}\\alpha$。设此为 $k_{\\text{max}}$。\n    c. 拒绝所有满足 $p_i \\le p_{(k_{\\text{max}})}$ 的原假设 $H_{0,i}$。如果不存在这样的 $k$，则不拒绝任何假设。\n    d. 如果 $H_{0,i}$ 被拒绝且 $\\bar{d}_i  0$，则最终的过拟合决策为 $\\text{True}$。\n\n**步骤 1：计算差值和原始 p 值**\n\n给定 $n=10$，$m=4$，以及 $\\alpha=0.05$。对于每个超参数设置 $i$，我们计算差值 $d_{i,k}$ 并执行单侧配对 $t$ 检验。\n\n-   **超参数 $i=1$**：\n    $e_{\\text{train},1} = [0.06, 0.05, 0.07, 0.08, 0.06, 0.05, 0.07, 0.06, 0.08, 0.05]$\n    $e_{\\text{valid},1} = [0.16, 0.14, 0.18, 0.20, 0.16, 0.14, 0.17, 0.16, 0.20, 0.14]$\n    $d_1 = [0.10, 0.09, 0.11, 0.12, 0.10, 0.09, 0.10, 0.10, 0.12, 0.09]$\n    $\\bar{d}_1 = 0.102$，$s_{d_1} \\approx 0.01135$。$t$ 统计量为 $t_1 \\approx 28.38$。自由度 $df=9$ 时， $p$ 值为 $p_1 \\approx 1.5 \\times 10^{-10}$。\n\n-   **超参数 $i=2$**：\n    $e_{\\text{train},2} = [0.12, 0.13, 0.11, 0.12, 0.13, 0.11, 0.12, 0.12, 0.13, 0.11]$\n    $e_{\\text{valid},2} = [0.121, 0.130, 0.112, 0.123, 0.131, 0.109, 0.118, 0.122, 0.131, 0.110]$\n    $d_2 = [0.001, 0.0, 0.002, 0.003, 0.001, -0.001, -0.002, 0.002, 0.001, 0.0]$\n    $\\bar{d}_2 = 0.0007$，$s_{d_2} \\approx 0.00164$。$t$ 统计量为 $t_2 \\approx 1.35$。自由度 $df=9$ 时， $p$ 值为 $p_2 \\approx 0.105$。\n\n-   **超参数 $i=3$**：\n    $e_{\\text{train},3} = [0.20, 0.19, 0.21, 0.22, 0.20, 0.19, 0.21, 0.22, 0.20, 0.19]$\n    $e_{\\text{valid},3} = [0.18, 0.17, 0.19, 0.20, 0.18, 0.17, 0.19, 0.20, 0.18, 0.17]$\n    $d_3 = [-0.02, -0.02, -0.02, -0.02, -0.02, -0.02, -0.02, -0.02, -0.02, -0.02]$\n    $\\bar{d}_3 = -0.02$。由于样本均值差为负，数据指向与备择假设 $H_{1,3}: \\mu_{d_3}  0$ 相反的方向。无论 $p$ 值如何，决策都为 $\\text{False}$。为完整起见，$p_3 \\approx 1.0$。\n\n-   **超参数 $i=4$**：\n    $e_{\\text{train},4} = [0.095, 0.105, 0.100, 0.110, 0.090, 0.103, 0.098, 0.107, 0.096, 0.104]$\n    $e_{\\text{valid},4} = [0.090, 0.115, 0.140, 0.110, 0.105, 0.133, 0.088, 0.127, 0.101, 0.129]$\n    $d_4 = [-0.005, 0.01, 0.04, 0.0, 0.015, 0.03, -0.01, 0.02, 0.005, 0.025]$\n    $\\bar{d}_4 = 0.013$，$s_{d_4} \\approx 0.0173$。$t$ 统计量为 $t_4 \\approx 2.38$。自由度 $df=9$ 时， $p$ 值为 $p_4 \\approx 0.0205$。\n\n原始 p 值和平均差值总结：\n- $i=1$: $\\bar{d}_1 = 0.102  0$, $p_1 \\approx 1.5 \\times 10^{-10}$\n- $i=2$: $\\bar{d}_2 = 0.0007  0$, $p_2 \\approx 0.105$\n- $i=3$: $\\bar{d}_3  0$, $p_3 \\approx 1.0$\n- $i=4$: $\\bar{d}_4 = 0.013  0$, $p_4 \\approx 0.0205$\n\n**步骤 2：应用 Bonferroni 校正**\n\n调整后的显著性水平为 $\\alpha' = \\alpha / m = 0.05 / 4 = 0.0125$。\n- $i=1$：$\\bar{d}_1  0$ 且 $p_1 \\approx 1.5 \\times 10^{-10}  0.0125$。结果：$\\text{True}$。\n- $i=2$：$\\bar{d}_2  0$ 但 $p_2 \\approx 0.105 \\not 0.0125$。结果：$\\text{False}$。\n- $i=3$：$\\bar{d}_3  0$。结果：$\\text{False}$。\n- $i=4$：$\\bar{d}_4  0$ 但 $p_4 \\approx 0.0205 \\not 0.0125$。结果：$\\text{False}$。\n\nBonferroni 决策列表为 $[\\text{True}, \\text{False}, \\text{False}, \\text{False}]$。\n\n**步骤 3：应用 Benjamini-Hochberg 程序**\n\n1.  排序后的 $p$ 值：\n    - $p_{(1)} = p_1 \\approx 1.5 \\times 10^{-10}$ (原始索引 1)\n    - $p_{(2)} = p_4 \\approx 0.0205$ (原始索引 4)\n    - $p_{(3)} = p_2 \\approx 0.105$ (原始索引 2)\n    - $p_{(4)} = p_3 \\approx 1.0$ (原始索引 3)\n\n2.  临界值 $\\frac{k}{m}\\alpha = \\frac{k}{4}(0.05) = k \\cdot 0.0125$：\n    - $k=1: 0.0125$\n    - $k=2: 0.0250$\n    - $k=3: 0.0375$\n    - $k=4: 0.0500$\n\n3.  找到最大的 $k$ 使得 $p_{(k)} \\le \\frac{k}{m}\\alpha$：\n    - 对于 $k=4$：$p_{(4)} \\approx 1.0 \\not\\le 0.0500$。\n    - 对于 $k=3$：$p_{(3)} \\approx 0.105 \\not\\le 0.0375$。\n    - 对于 $k=2$：$p_{(2)} \\approx 0.0205 \\le 0.0250$。此条件成立。\n    因此，$k_{\\text{max}}=2$。显著性阈值为 $p_{(2)} \\approx 0.0205$。\n\n4.  拒绝所有 $p_i \\le 0.0205$ 的 $H_{0,i}$。这适用于 $p_1$ 和 $p_4$。\n    - $i=1$：$H_0$ 被拒绝。$\\bar{d}_1  0$。结果：$\\text{True}$。\n    - $i=2$：$H_0$ 未被拒绝 ($p_2  0.0205$)。结果：$\\text{False}$。\n    - $i=3$：$\\bar{d}_3  0$。结果：$\\text{False}$。\n    - $i=4$：$H_0$ 被拒绝。$\\bar{d}_4  0$。结果：$\\text{True}$。\n\nBenjamini-Hochberg 决策列表为 $[\\text{True}, \\text{False}, \\text{False}, \\text{True}]$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\n\ndef solve():\n    \"\"\"\n    Performs paired t-tests and multiple comparison corrections to detect overfitting.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (\n            np.array([0.06, 0.05, 0.07, 0.08, 0.06, 0.05, 0.07, 0.06, 0.08, 0.05]),\n            np.array([0.16, 0.14, 0.18, 0.20, 0.16, 0.14, 0.17, 0.16, 0.20, 0.14])\n        ),\n        (\n            np.array([0.12, 0.13, 0.11, 0.12, 0.13, 0.11, 0.12, 0.12, 0.13, 0.11]),\n            np.array([0.121, 0.130, 0.112, 0.123, 0.131, 0.109, 0.118, 0.122, 0.131, 0.110])\n        ),\n        (\n            np.array([0.20, 0.19, 0.21, 0.22, 0.20, 0.19, 0.21, 0.22, 0.20, 0.19]),\n            np.array([0.18, 0.17, 0.19, 0.20, 0.18, 0.17, 0.19, 0.20, 0.18, 0.17])\n        ),\n        (\n            np.array([0.095, 0.105, 0.100, 0.110, 0.090, 0.103, 0.098, 0.107, 0.096, 0.104]),\n            np.array([0.090, 0.115, 0.140, 0.110, 0.105, 0.133, 0.088, 0.127, 0.101, 0.129])\n        )\n    ]\n\n    alpha = 0.05\n    m = len(test_cases)\n    \n    # --- Step 1: Calculate raw p-values and mean differences ---\n    p_values = []\n    mean_diffs = []\n    for e_train, e_valid in test_cases:\n        diffs = e_valid - e_train\n        mean_diffs.append(np.mean(diffs))\n        \n        # We only care about positive differences for overfitting\n        if np.mean(diffs) = 0:\n            p_values.append(1.0)\n        else:\n            # Perform one-sided paired t-test for valid > train\n            t_stat, p_val = stats.ttest_rel(e_valid, e_train, alternative='greater')\n            p_values.append(p_val)\n\n    # --- Step 2: Bonferroni Correction ---\n    bonferroni_threshold = alpha / m\n    bonferroni_decisions = []\n    for i in range(m):\n        is_significant = p_values[i]  bonferroni_threshold\n        is_positive_diff = mean_diffs[i] > 0\n        bonferroni_decisions.append(is_significant and is_positive_diff)\n\n    # --- Step 3: Benjamini-Hochberg (BH) Procedure ---\n    bh_decisions = [False] * m\n    \n    # Sort p-values while keeping track of original indices\n    # We use a stable sort to handle ties, although not strictly necessary here\n    sorted_indices = np.argsort(p_values)\n    sorted_p_values = np.array(p_values)[sorted_indices]\n\n    # Find the largest k such that p_(k) = (k/m)*alpha\n    k_max = 0\n    for k in range(m, 0, -1):\n        if sorted_p_values[k-1] = (k / m) * alpha:\n            k_max = k\n            break\n    \n    # If a threshold is found, reject corresponding hypotheses\n    if k_max > 0:\n        p_threshold = sorted_p_values[k_max - 1]\n        for i in range(m):\n            if p_values[i] = p_threshold and mean_diffs[i] > 0:\n                bh_decisions[i] = True\n\n    # --- Final Output Formatting ---\n    # Convert Python boolean to string 'True' or 'False'\n    bonf_str = ','.join(map(str, bonferroni_decisions))\n    bh_str = ','.join(map(str, bh_decisions))\n    \n    print(f\"[[{bonf_str}],[{bh_str}]]\")\n\nsolve()\n\n```", "id": "3189600"}]}