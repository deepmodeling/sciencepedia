{"hands_on_practices": [{"introduction": "这个练习将带你亲身体验灾难性抵消的经典案例。你将计算一个在数学上定义明确的函数 $f(x) = (\\tan(x) - \\sin(x))/x^3$，当 $x$ 趋近于 $0$ 时，直接计算会导致巨大的数值误差，因为 $\\tan(x)$ 和 $\\sin(x)$ 的值非常接近。通过对比直接计算与经过三角恒等式变换后的稳定形式，本实践 [@problem_id:2389878] 旨在揭示代数重构在避免数值不稳定问题中的强大作用。", "problem": "您的任务是评估当 $x$ 以弧度为单位且接近 $0$ 时，函数 $f(x) = \\dfrac{\\tan(x) - \\sin(x)}{x^3}$ 的数值稳定性和误差传播。您的程序必须对每个测试值 $x$ 实现两种不同的 $f(x)$ 数值计算方法，并相对于一个由截断级数展开式构建的高精度参考值来量化每种计算方法的误差。\n\n定义与要求：\n\n- 使用弧度制。\n- 对任意给定的非零 $x$，定义以下三种计算方法：\n  1. 直接计算法 $f_{\\mathrm{dir}}(x) = \\dfrac{\\tan(x) - \\sin(x)}{x^3}$。\n  2. 通过三角变换得到的数值稳定计算法\n     $$f_{\\mathrm{stab}}(x) = \\dfrac{2 \\sin(x) \\sin^2\\!\\left(\\dfrac{x}{2}\\right)}{x^3 \\cos(x)},$$\n     该方法通过使用 $1 - \\cos(x) = 2\\sin^2\\!\\left(\\dfrac{x}{2}\\right)$ 来避免相消误差。\n  3. 一个由 $f(x)$ 的麦克劳林级数构建的参考值，截断至 $x^6$ 阶：\n     $$f_{\\mathrm{ref}}(x) = \\dfrac{1}{2} + \\dfrac{x^2}{8} + \\dfrac{91}{1680} x^4 + \\dfrac{529}{24192} x^6.$$\n     该参考值在 $|x| \\leq 10^{-1}$ 时有效，其残差项为 $\\mathcal{O}(x^8)$。\n\n- 对于每个 $x$，计算绝对相对误差\n  $$E_{\\mathrm{dir}}(x) = \\dfrac{\\left| f_{\\mathrm{dir}}(x) - f_{\\mathrm{ref}}(x) \\right|}{\\left| f_{\\mathrm{ref}}(x) \\right|}, \\quad E_{\\mathrm{stab}}(x) = \\dfrac{\\left| f_{\\mathrm{stab}}(x) - f_{\\mathrm{ref}}(x) \\right|}{\\left| f_{\\mathrm{ref}}(x) \\right|}.$$\n\n测试集：\n\n计算并报告以下输入（均为弧度）的误差：$x \\in \\{10^{-1}, 10^{-4}, 10^{-8}, -10^{-8}, 10^{-12}, 10^{-16}\\}$。\n\n最终输出格式：\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的、由逗号分隔的结果列表。对于每个测试值 $x$，该列表必须按顺序首先包含 $E_{\\mathrm{dir}}(x)$，然后是 $E_{\\mathrm{stab}}(x)$。因此，对于按上述顺序给出的测试值，输出必须为：\n$$[E_{\\mathrm{dir}}(10^{-1}), E_{\\mathrm{stab}}(10^{-1}), E_{\\mathrm{dir}}(10^{-4}), E_{\\mathrm{stab}}(10^{-4}), E_{\\mathrm{dir}}(10^{-8}), E_{\\mathrm{stab}}(10^{-8}), E_{\\mathrm{dir}}(-10^{-8}), E_{\\mathrm{stab}}(-10^{-8}), E_{\\mathrm{dir}}(10^{-12}), E_{\\mathrm{stab}}(10^{-12}), E_{\\mathrm{dir}}(10^{-16}), E_{\\mathrm{stab}}(10^{-16})].$$\n所有角度必须解释为弧度。所有报告的量必须是十进制浮点数。", "solution": "所陈述的问题是有效的。这是一个在计算物理学中定义良好的问题，它具有科学依据、内部一致且没有歧义。该问题探讨了灾难性相消这一基本数值概念及其规避方法。\n\n核心任务是评估当 $x$ 值接近 $0$ 时函数 $f(x) = \\dfrac{\\tan(x) - \\sin(x)}{x^3}$ 的值。该评估使用三种不同的方法来展示和量化数值误差。\n\n第一种方法是直接计算法，$f_{\\mathrm{dir}}(x) = \\dfrac{\\tan(x) - \\sin(x)}{x^3}$。这种公式容易出现灾难性相消。当 $x \\approx 0$ 时，我们有 $\\tan(x) \\approx x$ 且 $\\sin(x) \\approx x$。在有限精度浮点运算中，计算 $\\tan(x) - \\sin(x)$ 涉及两个非常接近的数字相减。这个操作导致有效的高位数字被抵消，使得结果主要由表示误差主导。然后，这种精度损失被除以一个非常小的数 $x^3$ 的操作所放大。\n\n为了理解 $f(x)$ 在小 $x$ 时的行为，我们考察其分子各部分的麦克劳林级数展开：\n$$ \\tan(x) = x + \\frac{x^3}{3} + \\frac{2x^5}{15} + \\mathcal{O}(x^7) $$\n$$ \\sin(x) = x - \\frac{x^3}{6} + \\frac{x^5}{120} + \\mathcal{O}(x^7) $$\n对这两个级数做减法，揭示了分子的真实行为：\n$$ \\tan(x) - \\sin(x) = \\left( \\frac{1}{3} - (-\\frac{1}{6}) \\right) x^3 + \\left( \\frac{2}{15} - \\frac{1}{120} \\right) x^5 + \\mathcal{O}(x^7) = \\frac{1}{2}x^3 + \\frac{1}{8}x^5 + \\mathcal{O}(x^7) $$\n因此，当 $x \\to 0$ 时，函数 $f(x)$ 趋近于一个有限的极限：\n$$ \\lim_{x \\to 0} f(x) = \\lim_{x \\to 0} \\frac{\\frac{1}{2}x^3 + \\frac{1}{8}x^5 + \\mathcal{O}(x^7)}{x^3} = \\frac{1}{2} $$\n直接计算公式试图通过减去两个大得多的 $\\mathcal{O}(x)$ 阶项来计算一个小的 $\\mathcal{O}(x^3)$ 阶首项，这正是导致数值灾难的原因。\n\n第二种方法 $f_{\\mathrm{stab}}(x)$，采用一个三角恒等式来重构表达式，以避免这种相消。推导过程如下：\n$$ f(x) = \\frac{\\frac{\\sin(x)}{\\cos(x)} - \\sin(x)}{x^3} = \\frac{\\sin(x) \\left( \\frac{1}{\\cos(x)} - 1 \\right)}{x^3} = \\frac{\\sin(x) (1 - \\cos(x))}{x^3 \\cos(x)} $$\n对于小的 $x$，$1 - \\cos(x)$ 这一项仍然是一个有问题的减法。然而，它可以用半角恒等式 $1 - \\cos(x) = 2 \\sin^2\\left(\\frac{x}{2}\\right)$ 来替换。这便得到了数值稳定的形式：\n$$ f_{\\mathrm{stab}}(x) = \\frac{2 \\sin(x) \\sin^2\\left(\\frac{x}{2}\\right)}{x^3 \\cos(x)} $$\n这个表达式不包含任何近似相等量的减法，因此预期是数值稳定的。\n\n第三种方法是使用 $f(x)$ 本身的截断麦克劳林级数，提供了一个高精度的参考值 $f_{\\mathrm{ref}}(x)$。从 $\\tan(x) - \\sin(x)$ 的展开式中，我们推导出 $f(x)$ 的级数：\n$$ f(x) = \\frac{\\frac{1}{2}x^3 + \\frac{1}{8}x^5 + \\frac{13}{240}x^7 + \\dots}{x^3} = \\frac{1}{2} + \\frac{1}{8}x^2 + \\frac{13}{240}x^4 + \\dots $$\n问题提供了一个更精确的截断式：\n$$ f_{\\mathrm{ref}}(x) = \\frac{1}{2} + \\frac{x^2}{8} + \\frac{91}{1680} x^4 + \\frac{529}{24192} x^6 $$\n对于小的 $x$，这种多项式求值是内在稳定的，因为它仅涉及正项的加法（因为 $x$ 是平方的）和乘法。这使其成为一个理想的基准。\n\n数值实现将包含三个分别对应于 $f_{\\mathrm{dir}}$、$f_{\\mathrm{stab}}$ 和 $f_{\\mathrm{ref}}$ 的函数。然后，我们将遍历测试集中的 $x$ 值：$\\{10^{-1}, 10^{-4}, 10^{-8}, -10^{-8}, 10^{-12}, 10^{-16}\\}$。对于每个 $x$，我们计算直接计算法和稳定计算法相对于参考值的绝对相对误差：\n$$ E_{\\mathrm{dir}}(x) = \\frac{\\left| f_{\\mathrm{dir}}(x) - f_{\\mathrm{ref}}(x) \\right|}{\\left| f_{\\mathrm{ref}}(x) \\right|}, \\quad E_{\\mathrm{stab}}(x) = \\frac{\\left| f_{\\mathrm{stab}}(x) - f_{\\mathrm{ref}}(x) \\right|}{\\left| f_{\\mathrm{ref}}(x) \\right|} $$\n由于 $f_{\\mathrm{ref}}(x)$ 是一个正常数（$1/2$）和非负项之和，其值总是大于或等于 $1/2$，因此在计算误差时不存在除以零的风险。函数 $f(x)$ 是一个偶函数，意味着 $f(x) = f(-x)$，所以 $x=10^{-8}$ 和 $x=-10^{-8}$ 的结果预计是相同的。\n\n该实现将使用霍纳法则（Horner's method）进行 $f_{\\mathrm{ref}}(x)$ 的多项式求值，以优化性能并保持数值精度。最终输出将是一个列表，按指定顺序包含每个测试用例的计算误差 $E_{\\mathrm{dir}}(x)$ 和 $E_{\\mathrm{stab}}(x)$。我们预期随着 $|x| \\to 0$，$E_{\\mathrm{dir}}(x)$ 将急剧增加，而 $E_{\\mathrm{stab}}(x)$ 将保持很小，从而证实了重构表达式的优越稳定性。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef f_dir(x: float) -> float:\n    \"\"\"\n    Direct evaluation of f(x) = (tan(x) - sin(x)) / x**3.\n    This form is prone to catastrophic cancellation for x near 0.\n    \"\"\"\n    if x == 0.0:\n        return 0.5  # The limit as x -> 0\n    return (np.tan(x) - np.sin(x)) / (x**3)\n\ndef f_stab(x: float) -> float:\n    \"\"\"\n    Numerically stable evaluation of f(x) using trigonometric rearrangement.\n    f_stab(x) = (2 * sin(x) * sin(x/2)**2) / (x**3 * cos(x)).\n    \"\"\"\n    if x == 0.0:\n        return 0.5  # The limit as x -> 0\n    \n    # Pre-calculate common terms\n    sin_x = np.sin(x)\n    x_half = x / 2.0\n    sin_x_half = np.sin(x_half)\n    cos_x = np.cos(x)\n    x_cubed = x**3\n    \n    # Avoid division by zero if cos(x) is zero, though not for test cases\n    if cos_x == 0.0:\n        return np.inf * np.sign(sin_x)\n        \n    numerator = 2.0 * sin_x * sin_x_half**2\n    denominator = x_cubed * cos_x\n    \n    return numerator / denominator\n\ndef f_ref(x: float) -> float:\n    \"\"\"\n    Reference evaluation of f(x) using its Maclaurin series expansion\n    truncated at the O(x^6) term.\n    f_ref(x) = 1/2 + x^2/8 + (91/1680)x^4 + (529/24192)x^6.\n    \"\"\"\n    if x == 0.0:\n        return 0.5\n        \n    # Use Horner's method for efficient and stable polynomial evaluation\n    y = x**2\n    c0 = 1.0 / 2.0\n    c1 = 1.0 / 8.0\n    c2 = 91.0 / 1680.0\n    c3 = 529.0 / 24192.0\n\n    return c0 + y * (c1 + y * (c2 + y * c3))\n\ndef solve():\n    \"\"\"\n    Main function to execute the problem's requirements.\n    It calculates and reports the relative errors for two numerical methods\n    against a reference value for a given set of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        1e-1,\n        1e-4,\n        1e-8,\n        -1e-8,\n        1e-12,\n        1e-16\n    ]\n\n    results = []\n    for x in test_cases:\n        # Calculate the function value using all three methods\n        val_dir = f_dir(x)\n        val_stab = f_stab(x)\n        val_ref = f_ref(x)\n\n        # Calculate the absolute relative errors\n        # Note: abs(val_ref) is guaranteed to be >= 0.5, so no division by zero\n        error_dir = np.abs(val_dir - val_ref) / np.abs(val_ref)\n        error_stab = np.abs(val_stab - val_ref) / np.abs(val_ref)\n        \n        results.append(error_dir)\n        results.append(error_stab)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2389878"}, {"introduction": "在对长序列求和时，微小的舍入误差会逐渐累积，最终导致结果严重偏离。本练习 [@problem_id:2389876] 通过对一个带有微小偏差 $s$ 的交错序列求和，生动地展示了这一过程。你将通过编程实现标准求和方法与 Kahan 补偿求和算法，并比较它们的精度差异，从而深刻理解为何后者能有效控制误差累积，这对于许多科学计算任务至关重要。", "problem": "您的任务是量化在二进制浮点算术中对一个带有微小常数偏置的交替序列求和时，舍入误差是如何传播的，并比较标准求和与 Kahan 补偿求和的误差行为。设序列定义为\n$$\na_k = (-1)^{k+1} + s \\quad \\text{for} \\quad k=1,2,\\ldots,N,\n$$\n其中 $s>0$ 是一个实数偏置，$N$ 是一个正整数。对于下面指定的每个测试用例 $(N,s)$，请用 IEEE $754$ `binary64` 算术计算以下内容：\n- 标准的从左到右浮点和\n$$\nS_{\\text{std}}(N,s) = \\sum_{k=1}^{N} a_k.\n$$\n- Kahan 补偿浮点和\n$$\nS_{\\text{kah}}(N,s) = \\sum_{k=1}^{N} a_k,\n$$\n其中求和必须使用 Kahan 补偿求和方法以 `binary64` 算术执行。\n\n设精确的实数和为\n$$\nS_{\\text{exact}}(N,s) = \\sum_{k=1}^{N} \\left[(-1)^{k+1} + s\\right],\n$$\n解释为没有浮点舍入的实数。对于每个测试用例，计算绝对误差\n$$\nE_{\\text{std}} = \\left| S_{\\text{std}}(N,s) - S_{\\text{exact}}(N,s) \\right|, \n\\quad\nE_{\\text{kah}} = \\left| S_{\\text{kah}}(N,s) - S_{\\text{exact}}(N,s) \\right|.\n$$\n\n测试套件：\n- 用例 $1$：$(N,s)=(200000,\\,10^{-16})$。\n- 用例 $2$：$(N,s)=(200000,\\,2\\times 10^{-16})$。\n- 用例 $3$：$(N,s)=(200000,\\,10^{-12})$。\n- 用例 $4$：$(N,s)=(200001,\\,10^{-16})$。\n- 用例 $5$：$(N,s)=(2,\\,10^{-16})$。\n\n您的程序必须对这 $5$ 个用例中的每一个，输出浮点数对 $(E_{\\text{std}}, E_{\\text{kah}})$，但要按以下顺序汇总成一个单一的扁平列表：\n$$\n\\left[E_{\\text{std}}^{(1)},E_{\\text{kah}}^{(1)},E_{\\text{std}}^{(2)},E_{\\text{kah}}^{(2)},E_{\\text{std}}^{(3)},E_{\\text{kah}}^{(3)},E_{\\text{std}}^{(4)},E_{\\text{kah}}^{(4)},E_{\\text{std}}^{(5)},E_{\\text{kah}}^{(5)}\\right].\n$$\n\n最终输出格式：\n- 生成仅一行，包含一个由方括号括起来的列表，列表项由逗号分隔，无额外空格。\n- 每个数字必须以科学记数法打印，并保留 $12$ 位有效数字。\n- 所需样式示例（仅为说明）：$[1.234000000000e-03,4.560000000000e-07]$。\n\n不涉及物理单位。不使用角度。请勿在列表前后打印任何额外文本。计算 $S_{\\text{std}}(N,s)$ 和 $S_{\\text{kah}}(N,s)$ 时必须使用 `binary64` 浮点算术，而精确的实数和 $S_{\\text{exact}}(N,s)$ 仅用作误差计算的参考。每个测试用例的答案是如上定义的浮点数对 $(E_{\\text{std}},E_{\\text{kah}})$，最终输出按规定汇总所有用例。", "solution": "问题陈述是有效的。它在计算物理领域，特别是在浮点误差分析方面，提出了一个明确定义的数值实验。该问题在科学上基于数值分析的原理，设定良好，目标和约束清晰，并且没有任何事实或逻辑上的不一致之处。\n\n问题要求对一个带有微小正偏置的交替序列 $a_k = (-1)^{k+1} + s$ 进行标准（朴素）求和与 Kahan 补偿求和之间的定量比较。核心的数值挑战源于浮点算术的特性，特别是在相加两个数量级差异巨大的数时会发生有效位丢失（loss of significance）。\n\n首先，让我们确定和的精确值，它将作为我们计算误差的基准。该和定义为：\n$$\nS_{\\text{exact}}(N,s) = \\sum_{k=1}^{N} \\left[(-1)^{k+1} + s\\right]\n$$\n这可以分为两部分：\n$$\nS_{\\text{exact}}(N,s) = \\left(\\sum_{k=1}^{N} (-1)^{k+1}\\right) + \\left(\\sum_{k=1}^{N} s\\right)\n$$\n第二项就是 $N \\cdot s$。第一项是交替的 $+1$ 和 $-1$ 的和。\n如果 $N$ 是偶数，和为 $(1-1) + (1-1) + \\ldots = 0$。\n如果 $N$ 是奇数，和为 $(1-1) + \\ldots + (1-1) + 1 = 1$。\n这可以简洁地表示为 $N \\pmod 2$。\n因此，作为实数解释的精确和由以下解析公式给出：\n$$\nS_{\\text{exact}}(N,s) = (N \\pmod 2) + Ns\n$$\n此公式将用作计算绝对误差 $E_{\\text{std}}$ 和 $E_{\\text{kah}}$ 的参考值。\n\n接下来，我们分析两种求和方法在 `binary64` 浮点算术中的行为。\n\n标准求和 ($S_{\\text{std}}$)：\n标准方法通过一个简单的从左到右循环计算和：$S_k = S_{k-1} + a_k$。让我们追踪部分和。\n序列的项在 $k$ 为奇数时 $a_k \\approx 1$，在 $k$ 为偶数时 $a_k \\approx -1$。\n对于奇数 $k=2m-1$，部分和为 $S_{2m-1} = \\text{fl}(S_{2m-2} + a_{2m-1})$，其中 $\\text{fl}(\\cdot)$ 表示一个浮点运算。在这里，$S_{2m-2}$ 是 $m-1$ 对项 $(a_{2j-1}+a_{2j})$ 的和，每对的和为 $2s$。因此，$S_{2m-2} \\approx 2(m-1)s$，对于给定的参数来说这是一个很小的数。而项 $a_{2m-1} \\approx 1$。\n因此，加法是 $\\text{fl}(\\text{小数} + \\text{大数})$。在浮点算术中，此操作会丢失小数的大部分精度。$S_{2m-2}$ 的低位比特被截断。\n对于偶数 $k=2m$，部分和为 $S_{2m} = \\text{fl}(S_{2m-1} + a_{2m})$。由于 $S_{2m-1} \\approx 1$ 且 $a_{2m} \\approx -1$，此操作是灾难性抵消（catastrophic cancellation）的一个例子，即两个几乎相等的数相减导致结果具有很大的相对误差。\n每一步引入的舍入误差，特别是在奇数步，会累积起来。对于大量的项 $N$，预计这个累积误差会变得非常显著，导致 $S_{\\text{std}}$ 严重偏离 $S_{\\text{exact}}$。\n\nKahan 补偿求和 ($S_{\\text{kah}}$)：\nKahan 求和算法正是为解决此问题而设计的。它维护一个运行的补偿变量 $c$，该变量累积每次加法产生的舍入误差。每一步的算法如下：\n1. $y = a_k - c$\n2. $t = \\text{sum} + y$\n3. $c = (t - \\text{sum}) - y$\n4. $\\text{sum} = t$\n\n关键步骤是计算新的补偿项 $c = (t - \\text{sum}) - y$。在代数上，这应为零。然而，在浮点算术中，`t - sum` 恢复了成功加到 `sum` 上的 `y` 的高位部分，再从此结果中减去 `y` 则分离出在 `sum + y` 加法中丢失的 `y` 的低位部分的负值。这个丢失的部分 $c$ 随后在下一个项 $a_{k+1}$ 被加到运行总和之前，先从 $a_{k+1}$ 中减去，从而有效地重新注入了丢失的精度。这个过程防止了舍入误差的系统性累积。因此，预计误差 $E_{\\text{kah}}$ 会非常小，与最终和的机器精度在同一数量级，并且不应随 $N$ 显著增长。\n\n对于 $N=2$ 的特殊情况，Kahan 算法没有任何优势。补偿项 $c$ 在第二次（也是最后一次）加法后计算，但从未被使用。因此，对于 $N=2$，$S_{\\text{std}}$ 和 $S_{\\text{kah}}$ 将是相同的，从而 $E_{\\text{std}} = E_{\\text{kah}}$。\n\n要实现的算法如下：\n对于每个测试用例 $(N, s)$：\n1. 将输入值 $s$ 转换为 `binary64` 浮点数。\n2. 使用解析公式 $S_{\\text{exact}} = (N \\pmod 2) + Ns$ 计算参考值 $S_{\\text{exact}}$，使用 `binary64` 数字进行算术运算。\n3. 实现一个从 $k=1$ 到 $N$ 的循环来计算 $S_{\\text{std}}$。在每次迭代中，计算 $a_k = (-1)^{k+1} + s$ 并将其加到运行总和中。\n4. 实现第二个从 $k=1$ 到 $N$ 的循环，使用上述的 Kahan 求和算法来计算 $S_{\\text{kah}}$。所有变量（`sum`、`c`、`y`、`t`）必须是 `binary64`。\n5. 计算绝对误差 $E_{\\text{std}} = |S_{\\text{std}} - S_{\\text{exact}}|$ 和 $E_{\\text{kah}} = |S_{\\text{kah}} - S_{\\text{exact}}|$。\n6. 收集生成的误差对。\n在处理完所有测试用例后，将收集到的误差按规定格式化为单个列表。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes and compares the error propagation of standard vs. Kahan summation\n    for an alternating sequence with a small bias.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        (200000, 1e-16),\n        (200000, 2e-16),\n        (200000, 1e-12),\n        (200001, 1e-16),\n        (2, 1e-16),\n    ]\n\n    results = []\n    for N, s_val in test_cases:\n        # Use numpy.float64 to ensure computations are in IEEE 754 binary64.\n        s = np.float64(s_val)\n\n        # 1. Calculate the exact sum analytically.\n        # S_exact(N,s) = (N mod 2) + N*s\n        # The calculation is done in float64 to establish a consistent reference.\n        s_exact = np.float64(N % 2) + np.float64(N) * s\n\n        # 2. Compute the standard left-to-right floating-point sum.\n        s_std = np.float64(0.0)\n        for k in range(1, N + 1):\n            # Sequence term a_k = (-1)**(k+1) + s\n            # (-1)**(k+1) is 1 if k is odd, -1 if k is even.\n            term_sign = np.float64(1.0 if (k % 2 != 0) else -1.0)\n            a_k = term_sign + s\n            s_std += a_k\n\n        # 3. Compute the Kahan compensated floating-point sum.\n        s_kah = np.float64(0.0)\n        c = np.float64(0.0)  # A running compensation for lost low-order bits.\n        for k in range(1, N + 1):\n            term_sign = np.float64(1.0 if (k % 2 != 0) else -1.0)\n            a_k = term_sign + s\n            y = a_k - c\n            t = s_kah + y\n            # (t - s_kah) recovers the high-order part of y.\n            # Subtracting y recovers -(low part of y), which is the round-off error.\n            c = (t - s_kah) - y\n            s_kah = t\n\n        # 4. Compute the absolute errors.\n        e_std = np.abs(s_std - s_exact)\n        e_kah = np.abs(s_kah - s_exact)\n        \n        results.append(e_std)\n        results.append(e_kah)\n\n    # Final print statement in the exact required format.\n    # The format \"%.12e\" gives 1 digit before the decimal and 12 after,\n    # totaling 13 significant digits, as shown in the problem's example format style.\n    formatted_results = [f\"{r:.12e}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2389876"}, {"introduction": "数值稳定性是设计核心计算方法（如线性方程组求解器）时的关键考量。在这个实践中，你将探索高斯消元法在有限精度算术下的表现，特别是主元选择对结果精度的决定性影响。通过对一系列特制的线性系统 $A \\mathbf{x} = \\mathbf{b}$ [@problem_id:2375807] 分别应用不含主元选择和带有部分主元选择的高斯消元法，你将直观地看到一个看似微小的算法改进如何防止灾难性抵消，并确保解的可靠性。", "problem": "编写一个完整的、可运行的程序，该程序针对一组固定的线性系统，定量比较在不进行行交换的高斯消元法与带部分主元法的高斯消元法中，舍入误差和灾难性抵消的影响。所有消元和回代步骤的计算都必须以单精度二进制浮点算术（即，使用 $32$-bit 浮点数）进行，而您构建的任何参考值都可以用双精度计算。\n\n对于具有已知精确解 $\\mathbf{x}_{\\mathrm{true}}$ 的线性系统 $A \\mathbf{x} = \\mathbf{b}$，其近似解 $\\hat{\\mathbf{x}}$ 的相对前向误差定义为\n$$\nE(\\hat{\\mathbf{x}}) = \\frac{\\lVert \\hat{\\mathbf{x}} - \\mathbf{x}_{\\mathrm{true}} \\rVert_2}{\\lVert \\mathbf{x}_{\\mathrm{true}} \\rVert_2}.\n$$\n如果在无行交换的变体中因出现精确的零主元导致方法无法进行，则将相应的相对误差定义为 $+\\infty$，并将其输出为字符串 \"inf\"。\n\n您的程序必须为下面的每个测试用例计算：\n- $\\hat{\\mathbf{x}}_{\\mathrm{np}}$：通过不进行任何行交换的高斯消元法得到的解，\n- $\\hat{\\mathbf{x}}_{\\mathrm{pp}}$：通过带部分主元法的高斯消元法（即，在每个消元步骤中，将当前行与当前列中具有最大绝对值主元的下方某行进行交换）得到的解，\n\n两者都使用 $32$ 位浮点算术进行。然后使用上述定义计算 $E(\\hat{\\mathbf{x}}_{\\mathrm{np}})$ 和 $E(\\hat{\\mathbf{x}}_{\\mathrm{pp}})$。\n\n使用以下测试套件。在每种情况下，均使用双精度根据 $A$ 和指定的 $\\mathbf{x}_{\\mathrm{true}}$ 按 $\\mathbf{b} = A \\mathbf{x}_{\\mathrm{true}}$ 构建 $\\mathbf{b}$，然后按要求以单精度求解该系统。\n\n- 测试用例 $1$（表现良好的 $2 \\times 2$ 系统）：\n  $$\n  A_1 = \\begin{bmatrix} 2 & 1 \\\\ 1 & 3 \\end{bmatrix}, \\quad \\mathbf{x}_{\\mathrm{true},1} = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}.\n  $$\n- 测试用例 $2$（无主元 pivoting 时会触发灾难性抵消）：令 $\\varepsilon = 10^{-20}$，\n  $$\n  A_2 = \\begin{bmatrix} \\varepsilon & 1 \\\\ 1 & 1 \\end{bmatrix}, \\quad \\mathbf{x}_{\\mathrm{true},2} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}.\n  $$\n- 测试用例 $3$（无行交换时出现精确的零主元）：\n  $$\n  A_3 = \\begin{bmatrix} 0 & 1 & 1 \\\\ 1 & 1 & 1 \\\\ 1 & 1 & 2 \\end{bmatrix}, \\quad \\mathbf{x}_{\\mathrm{true},3} = \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix}.\n  $$\n- 测试用例 $4$（大小为 $5$ 的病态希尔伯特系统）：对于索引 $i,j \\in \\{1,2,3,4,5\\}$，\n  $$\n  \\left(A_4\\right)_{ij} = \\frac{1}{i + j - 1}, \\quad \\mathbf{x}_{\\mathrm{true},4} = \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{bmatrix}.\n  $$\n\n角度单位不适用。物理单位不适用。\n\n最终输出格式：您的程序应生成一行输出，其中包含用方括号括起来的、以逗号分隔的结果列表。对于每个测试用例 $k \\in \\{1,2,3,4\\}$，按顺序先报告 $E(\\hat{\\mathbf{x}}_{\\mathrm{np}})$，再报告 $E(\\hat{\\mathbf{x}}_{\\mathrm{pp}})$。因此，输出必须总共包含 8 个条目，顺序如下：\n$$\n\\left[E(\\hat{\\mathbf{x}}_{\\mathrm{np},1}),\\,E(\\hat{\\mathbf{x}}_{\\mathrm{pp},1}),\\,E(\\hat{\\mathbf{x}}_{\\mathrm{np},2}),\\,E(\\hat{\\mathbf{x}}_{\\mathrm{pp},2}),\\,E(\\hat{\\mathbf{x}}_{\\mathrm{np},3}),\\,E(\\hat{\\mathbf{x}}_{\\mathrm{pp},3}),\\,E(\\hat{\\mathbf{x}}_{\\mathrm{np},4}),\\,E(\\hat{\\mathbf{x}}_{\\mathrm{pp},4})\\right].\n$$\n每个有限浮点数必须四舍五入为以 10 为底的科学记数法，小数点后恰好有 6 位数字（例如，$1.234000\\mathrm{e}{-02}$），而 $+\\infty$ 必须打印为 \"inf\"。您的程序不得读取任何输入，也不得产生任何额外文本。", "solution": "该问题要求对带部分主元法和不带部分主元法的高斯消元法进行定量比较，重点关注灾难性抵消和舍入误差的影响。分析将在一个定义的线性系统 $A \\mathbf{x} = \\mathbf{b}$ 套件上进行，其中求解过程被限制为单精度（$32$ 位）浮点算术。近似解 $\\hat{\\mathbf{x}}$ 的质量通过其相对于已知真实解 $\\mathbf{x}_{\\mathrm{true}}$ 的相对前向误差 $E(\\hat{\\mathbf{x}})$ 来衡量。\n\n求解大小为 $n \\times n$ 的线性系统 $A \\mathbf{x} = \\mathbf{b}$ 的基本算法是高斯消元法。它包括两个阶段：前向消元和回代。前向消元阶段通过应用一系列初等行变换，将矩阵 $A$ 转换为一个上三角矩阵 $U$。这些相同的操作也应用于向量 $\\mathbf{b}$ 以产生一个修改后的向量 $\\mathbf{c}$。系统因此被转换为一个等价的系统 $U \\mathbf{x} = \\mathbf{c}$，该系统可以通过回代轻松求解。\n\n对列 $k$（从 $0$ 到 $n-2$）的前向消元过程，涉及使用主元 $A_{kk}$ 来消去其下方同一列中的系数。对于行 $k$ 下方的每一行 $i$（即 $i > k$），该行通过减去行 $k$ 的一个倍数来更新：\n$$\n\\text{Row}_i \\leftarrow \\text{Row}_i - m_{ik} \\cdot \\text{Row}_k\n$$\n其中乘子为 $m_{ik} = A_{ik} / A_{kk}$。只有当乘子 $m_{ik}$ 不会过大时，此过程才是数值稳定的。如果主元 $A_{kk}$ 相对于其所在列的其他元素为零或非常接近于零，乘子 $m_{ik}$ 可能会变得非常大。这会导致灾难性抵消：当我们计算 $A_{ij} - m_{ik} A_{kj}$ 时，如果 $m_{ik} A_{kj}$ 非常大且与 $A_{ij}$ 的量级相近，减法操作可能导致许多有效数字的损失。这会引入大量的舍入误差，该误差会在后续计算中传播，最终破坏最终解 $\\hat{\\mathbf{x}}$。\n\n所需的两种算法如下：\n\n1.  **不带主元法的高斯消元法**：这是上文描述的朴素实现。它在不重新排列方程的情况下进行。其主要弱点是容易受到小主元或零主元的影响。如果遇到精确的零主元 $A_{kk}=0$，算法将因乘子 $m_{ik}$ 未定义而失败。根据问题规范，此失败将导致无限大误差，表示为 \"inf\"。\n\n2.  **带部分主元法的高斯消元法**：这是一种为增强数值稳定性而设计的改进方法。在对列 $k$ 进行消元步骤之前，算法在子列 $\\{A_{ik} | i \\ge k\\}$ 中搜索绝对值最大的元素。设此元素为 $A_{pk}$。然后，算法将第 $p$ 行与第 $k$ 行交换。这确保了主元 $A_{kk}$ 是其所在列中（从对角线向下）可能的最大值，从而确保所有乘子 $|m_{ik}| = |A_{ik}/A_{kk}|$ 都小于或等于 $1$。此策略可防止乘子变大，并显著减轻灾难性抵消的风险。\n\n评估指标是相对前向误差，定义为：\n$$\nE(\\hat{\\mathbf{x}}) = \\frac{\\lVert \\hat{\\mathbf{x}} - \\mathbf{x}_{\\mathrm{true}} \\rVert_2}{\\lVert \\mathbf{x}_{\\mathrm{true}} \\rVert_2}\n$$\n其中 $\\lVert \\cdot \\rVert_2$ 表示欧几里得范数。该指标量化了计算解与真实解之间的偏差，该偏差是相对于真实解的量级而言的。\n\n测试套件旨在暴露无主元法的特定弱点：\n- **测试用例 1**：一个表现良好的 $2 \\times 2$ 系统。由于初始主元已是其所在列中最大的元素，预计两种方法都将产生高度精确的结果。\n- **测试用例 2**：此案例的矩阵 $A_2$ 具有一个非常小的主元 $A_{11} = \\varepsilon = 10^{-20}$。虽然不完全为零，但在单精度算术中，这个值小到足以在用作主元时产生一个非常大的乘子 $1/\\varepsilon$，从而在更新第二行时导致灾难性抵消。预计无主元法得到的解 $\\hat{\\mathbf{x}}_{\\mathrm{np}}$ 将非常不准确。而部分主元法会交换两行，使用 $1$ 作为主元，从而进行稳定的计算并得到准确的解 $\\hat{\\mathbf{x}}_{\\mathrm{pp}}$。\n- **测试用例 3**：此案例呈现了一个精确的零主元 $A_{11} = 0$。无主元算法必定失败，产生无限大误差。部分主元法会将第 1 行与第 2 行或第 3 行交换，因为这两行的第一列中都有非零元素，从而使算法能够继续进行并找到解。\n- **测试用例 4**：此案例涉及 $5 \\times 5$ 的希尔伯特矩阵，该矩阵是著名的病态矩阵。病态意味着 $A$ 或 $\\mathbf{b}$ 的微小变化都可能导致解 $\\mathbf{x}$ 的巨大变化。虽然主元法通过控制乘子增长来提高稳定性，但它无法消除病态系统固有的敏感性。因此，预计两种算法产生的解都将有显著误差，但部分主元法仍应比无主元法得到更准确的结果。\n\n该实现将包含两个主要函数，分别对应高斯消元法的每种变体。这些函数将使用 $32$ 位浮点数（`numpy.float32`）执行其所有内部算术运算。主程序将构建测试用例，用双精度（`float64`）计算右端向量 $\\mathbf{b} = A \\mathbf{x}_{\\mathrm{true}}$ 以获得高保真参考，然后调用单精度求解器，并计算相对前向误差以生成最终报告。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve_no_pivot(A: np.ndarray, b: np.ndarray) -> np.ndarray | None:\n    \"\"\"\n    Solves Ax=b using Gaussian elimination without pivoting in single precision.\n    Returns the solution vector x, or None if a zero pivot is encountered.\n    \"\"\"\n    n = A.shape[0]\n    # Create an augmented matrix and cast to float32 for all computations\n    Aug = np.hstack([A, b.reshape(-1, 1)]).astype(np.float32)\n\n    # Forward elimination\n    for k in range(n - 1):\n        pivot = Aug[k, k]\n        if pivot == np.float32(0.0):\n            return None  # Failure due to exact zero pivot\n\n        for i in range(k + 1, n):\n            multiplier = Aug[i, k] / pivot\n            Aug[i, k:] -= multiplier * Aug[k, k:]\n\n    # Backward substitution\n    x_hat = np.zeros(n, dtype=np.float32)\n    for i in range(n - 1, -1, -1):\n        # Check for singularity detected after elimination\n        if Aug[i, i] == np.float32(0.0):\n            return None\n        \n        s = np.dot(Aug[i, i + 1:n], x_hat[i + 1:])\n        x_hat[i] = (Aug[i, n] - s) / Aug[i, i]\n\n    return x_hat\n\ndef solve_partial_pivot(A: np.ndarray, b: np.ndarray) -> np.ndarray | None:\n    \"\"\"\n    Solves Ax=b using Gaussian elimination with partial pivoting in single precision.\n    Returns the solution vector x, or None if the matrix is singular.\n    \"\"\"\n    n = A.shape[0]\n    # Create an augmented matrix and cast to float32 for all computations\n    Aug = np.hstack([A, b.reshape(-1, 1)]).astype(np.float32)\n\n    # Forward elimination with pivoting\n    for k in range(n - 1):\n        # Find the row with the largest pivot in the current column\n        max_row_idx = k + np.argmax(np.abs(Aug[k:, k]))\n\n        # Swap rows if necessary\n        if max_row_idx != k:\n            Aug[[k, max_row_idx]] = Aug[[max_row_idx, k]]\n\n        pivot = Aug[k, k]\n        # If the pivot is zero after swapping, the matrix is singular\n        if pivot == np.float32(0.0):\n            return None\n\n        for i in range(k + 1, n):\n            multiplier = Aug[i, k] / pivot\n            Aug[i, k:] -= multiplier * Aug[k, k:]\n\n    # Backward substitution\n    x_hat = np.zeros(n, dtype=np.float32)\n    for i in range(n - 1, -1, -1):\n        if Aug[i, i] == np.float32(0.0):\n            return None # Singular matrix\n        \n        s = np.dot(Aug[i, i + 1:n], x_hat[i + 1:])\n        x_hat[i] = (Aug[i, n] - s) / Aug[i, i]\n\n    return x_hat\n\ndef relative_forward_error(x_hat: np.ndarray, x_true: np.ndarray) -> float:\n    \"\"\"\n    Computes the relative forward error using double precision for accuracy.\n    \"\"\"\n    # Use float64 for higher precision error calculation\n    x_hat_64 = x_hat.astype(np.float64)\n    x_true_64 = x_true.astype(np.float64)\n    \n    norm_diff = np.linalg.norm(x_hat_64 - x_true_64, 2)\n    norm_true = np.linalg.norm(x_true_64, 2)\n    \n    if norm_true == 0:\n        return 0.0 if norm_diff == 0.0 else np.inf\n    \n    return norm_diff / norm_true\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and print results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # All matrices and vectors are initially defined in float64.\n    \n    # Test case 1\n    A1 = np.array([[2, 1], [1, 3]], dtype=np.float64)\n    x_true1 = np.array([1, -1], dtype=np.float64)\n\n    # Test case 2\n    eps = 1e-20\n    A2 = np.array([[eps, 1], [1, 1]], dtype=np.float64)\n    x_true2 = np.array([1, 1], dtype=np.float64)\n\n    # Test case 3\n    A3 = np.array([[0, 1, 1], [1, 1, 1], [1, 1, 2]], dtype=np.float64)\n    x_true3 = np.array([1, 2, 3], dtype=np.float64)\n\n    # Test case 4 (Hilbert matrix)\n    n4 = 5\n    A4 = np.zeros((n4, n4), dtype=np.float64)\n    for i in range(1, n4 + 1):\n        for j in range(1, n4 + 1):\n            A4[i-1, j-1] = 1.0 / (i + j - 1)\n    x_true4 = np.ones(n4, dtype=np.float64)\n\n    test_cases = [\n        (A1, x_true1),\n        (A2, x_true2),\n        (A3, x_true3),\n        (A4, x_true4),\n    ]\n\n    results = []\n    for A, x_true in test_cases:\n        # Construct b = A @ x_true in double precision\n        b = A @ x_true\n        \n        # --- No Pivoting ---\n        x_np = solve_no_pivot(A.copy(), b.copy())\n        if x_np is None:\n            err_np_str = \"inf\"\n        else:\n            err_np = relative_forward_error(x_np, x_true)\n            err_np_str = f\"{err_np:.6e}\"\n        results.append(err_np_str)\n        \n        # --- Partial Pivoting ---\n        x_pp = solve_partial_pivot(A.copy(), b.copy())\n        if x_pp is None:\n            # This case should not be reached with the given test problems\n            # but is included for robustness.\n            err_pp_str = \"inf\" \n        else:\n            err_pp = relative_forward_error(x_pp, x_true)\n            err_pp_str = f\"{err_pp:.6e}\"\n        results.append(err_pp_str)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2375807"}]}