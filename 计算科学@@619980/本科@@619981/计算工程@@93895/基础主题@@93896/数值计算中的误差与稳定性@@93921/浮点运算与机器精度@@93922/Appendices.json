{"hands_on_practices": [{"introduction": "在编程中，用 `==` 检查两个数字是否相等是基本操作，但对于浮点数而言，这种比较却非常不可靠。本次实践将模拟一个看似简单的递归过程，但它可能因浮点数的表示误差和“吸收”现象而永远不会达到预期的终止条件 [@problem_id:2393700]。这个练习是培养编写健壮数值代码意识的基础，它直观地揭示了为何必须用带容差的比较来代替直接的相等性判断。", "problem": "考虑符合电气与电子工程师协会（IEEE）$754$ 标准（binary64）的双精度浮点计算，舍入模式为“向最近舍入，偶数优先”(round-to-nearest, ties-to-even)。设 $\\operatorname{fl}(\\cdot)$ 表示遵循此规则舍入后的单次浮点运算结果。定义一个递归过程，由序列 $\\{x_k\\}_{k \\ge 0}$ 描述，其初始值为 $x_0 \\in \\mathbb{R}$，增量为 $d \\in \\mathbb{R}$，具体如下：\n$$\nx_{k+1} = \\operatorname{fl}(x_k + d).\n$$\n该过程旨在当浮点等式 $x_k = y$ 对给定的目标值 $y \\in \\mathbb{R}$ 成立时，在最小的非负整数 $k$ 处终止。如果在预设的递归上限 $N_{\\max} \\in \\mathbb{N}$ 内不存在这样的 $k$，则宣布该过程对于给定参数是不终止的。\n\n您的任务是编写一个完整、可运行的程序。该程序需对下文测试套件中的每一组参数 $(x_0, d, y, N_{\\max})$，严格按照规定执行递归，且仅使用编程语言的浮点语义。对于每种情况，程序需要报告以下信息：\n- 一个布尔值，表明递归是否通过在某个 $k \\le N_{\\max}$ 处满足 $x_k = y$ 而终止，\n- 实际执行的整数步数 $k_{\\text{out}}$（如果终止，则为首次发生终止时的 $k$ 值；如果未终止，则为 $N_{\\max}$），\n- 最终的浮点值 $x_{k_{\\text{out}}}$，以及\n- 浮点绝对误差 $|x_{k_{\\text{out}}} - y|$。\n\n不涉及任何物理单位或角度。所有计算均为纯数值计算。程序不得读取任何输入。\n\n参数值测试套件：\n1. $(x_0, d, y, N_{\\max}) = (0.0, 0.5, 1.0, 10)$\n2. $(x_0, d, y, N_{\\max}) = (0.0, 0.1, 1.0, 50)$\n3. $(x_0, d, y, N_{\\max}) = (1.0, 2^{-55}, 1.0 + 2^{-52}, 900)$\n4. $(x_0, d, y, N_{\\max}) = (1.0, -0.5, 0.0, 10)$\n5. $(x_0, d, y, N_{\\max}) = (1.0, -0.1, 0.0, 50)$\n\n在情况3中，目标值 $y$ 是大于 $1.0$ 的下一个可表示浮点数，即在binary64格式下，$y = \\operatorname{nextafter}(1.0, +\\infty) = 1.0 + 2^{-52}$。\n\n要求的最终输出格式：\n您的程序应生成单行输出，其中包含所有测试用例的结果，形式为一个由方括号括起来的、逗号分隔的列表。每个测试用例的结果本身必须是一个形如 $[\\text{terminated}, k_{\\text{out}}, x_{k_{\\text{out}}}, |x_{k_{\\text{out}}} - y|]$ 的列表。例如，总输出格式必须如下所示：\n$[[\\text{bool}, \\text{int}, \\text{float}, \\text{float}], \\ldots]$\n输出在单行上，每个内部列表对应一个测试用例，并按上述顺序排列。", "solution": "经评估，该问题陈述是有效的。其科学基础是计算工程原理，特别是IEEE $754$ 标准所定义的浮点算术。该问题是良构的、客观的，并包含足够的信息来推导出唯一、可验证的解。\n\n任务是模拟一个由序列 $x_{k+1} = \\operatorname{fl}(x_k + d)$ 定义的递归过程，其中 $\\operatorname{fl}(\\cdot)$ 代表一次浮点运算。模拟必须遵循binary64（双精度）算术的语义。Python中的标准 `float` 类型及其相关的算术运算 (`+`) 在大多数平台上都符合IEEE $754$ binary64标准，并采用默认的“向最近舍入，偶数优先”舍入模式。因此，在Python中直接实现该递推关系将能准确地模拟所指定的过程。\n\n对于每个测试用例 $(x_0, d, y, N_{\\max})$，算法流程如下：\n1. 初始化状态变量：序列的当前值 $x_{\\text{current}} \\leftarrow x_0$，已执行的步数 $k_{\\text{out}} \\leftarrow 0$，以及终止标志 `terminated` $\\leftarrow$ `False`。所有数值参数（$x_0, d, y$）均被视为binary64浮点数。\n\n2. 检查是否立即终止。如果初始值 $x_0$ 等于目标值 $y$（在浮点比较中），则将 `terminated` 设为 `True`。步数为 $0$。\n\n3. 如果在 $k=0$ 时未终止，则开始一个迭代循环，`k` 从 $1$ 到 $N_{\\max}$。在每次迭代中（对应于递归的一步）：\n    a. 更新序列值：$x_{\\text{current}} \\leftarrow x_{\\text{current}} + d$。此操作直接实现了 $x_k \\leftarrow \\operatorname{fl}(x_{k-1} + d)$。\n    b. 设置 $k_{\\text{out}} \\leftarrow k$。\n    c. 检查终止条件：如果 $x_{\\text{current}} = y$。若为真，则将 `terminated` 设为 `True` 并退出循环。\n\n4. 循环结束后（无论是通过终止还是达到上限 $N_{\\max}$），收集最终结果：布尔值 `terminated`、整数 $k_{\\text{out}}$、最终值 $x_{k_{\\text{out}}}$ 以及最终的绝对误差 $|x_{k_{\\text{out}}} - y|$。\n\n此模拟揭示了浮点算术的一些基本行为：\n- **精确可表示性**：在测试用例1和4中，初始值、增量（$0.5 = 2^{-1}$）和目标值均可精确地表示为有限二进制小数。算术是精确的，过程如预期终止。\n- **表示与舍入误差**：在测试用例2和5中，增量 $d = \\pm 0.1$ 在二进制中是循环小数（$0.000110011..._2$），无法被精确表示。$d$ 的存储值是一个近似值。对这个近似值的重复加法会导致累积的舍入误差，使得序列 $x_k$ 永远不会精确地等于目标值（$1.0$ 或 $0.0$）。因此，该过程在迭代限制内不终止。\n- **吸收**：测试用例3演示了一种现象，即小的增量被“吸收”。序列的值约为 $x_k \\approx 1.0$。在binary64格式下，$1.0$ 附近的数的最后一位单位（ULP）是 $2^{-52}$。增量 $d = 2^{-55}$，它小于 $1.0$ 的半个ULP（即 $2^{-55}  0.5 \\times \\text{ulp}(1.0) = 2^{-53}$）。根据向最近舍入规则，精确和 $1.0 + 2^{-55}$ 的结果被舍入回最近的可表示数，即 $1.0$。因此，$x_{k+1} = \\operatorname{fl}(x_k + d) = \\operatorname{fl}(1.0 + 2^{-55}) = 1.0$。序列值保持在 $1.0$ 不变，永远不会达到目标 $y = 1.0 + 2^{-52}$，即 $1.0$ 之后的下一个可表示数。\n\n程序将为每种情况执行此直接模拟，并按规定格式化结果。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_simulation(x0: float, d: float, y: float, n_max: int):\n    \"\"\"\n    Performs the recursive floating-point simulation for a single test case.\n\n    Args:\n        x0 (float): The initial value x_0.\n        d (float): The increment d.\n        y (float): The target value y.\n        n_max (int): The maximum number of recursion steps.\n\n    Returns:\n        A list containing [terminated, k_out, x_final, error].\n    \"\"\"\n    x_current = float(x0)\n    terminated = False\n    k_out = 0\n\n    # Check for termination at k=0\n    if x_current == y:\n        terminated = True\n    else:\n        # Loop from k=1 up to N_max\n        for k in range(1, n_max + 1):\n            x_current = x_current + d\n            k_out = k\n            if x_current == y:\n                terminated = True\n                break\n\n    # Calculate final absolute error\n    abs_error = abs(x_current - y)\n\n    return [terminated, k_out, x_current, abs_error]\n\ndef solve():\n    \"\"\"\n    Defines test cases and runs the simulation for each, printing the\n    results in the specified format.\n    \"\"\"\n    # Test suite of parameter values: (x_0, d, y, N_max)\n    # The value for y in Case 3 is the next representable double-precision\n    # float after 1.0, which is precisely 1.0 + 2**-52.\n    # While np.nextafter(1.0, np.inf) could be used, the explicit form is clearer\n    # and avoids a dependency if numpy wasn't strictly needed otherwise.\n    # Given numpy is allowed, we use the explicit expression for clarity.\n    test_cases = [\n        (0.0, 0.5, 1.0, 10),\n        (0.0, 0.1, 1.0, 50),\n        (1.0, 2**-55, 1.0 + 2**-52, 900),\n        (1.0, -0.5, 0.0, 10),\n        (1.0, -0.1, 0.0, 50),\n    ]\n\n    results = []\n    for case in test_cases:\n        x0, d, y, n_max = case\n        result = run_simulation(x0, d, y, n_max)\n        results.append(result)\n\n    # Format the final output string as a list of lists.\n    # The str() of a list automatically handles bools and formats floats.\n    result_strings = [str(res) for res in results]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n```", "id": "2393700"}, {"introduction": "理解了浮点数比较的陷阱后，我们来探讨加法运算中的精度问题。对一列数字求和似乎是件简单任务，但本练习将通过一个精心设计的思想实验，展示当累加许多数字或数量级差异巨大的数字时，浮点加法的非结合性会导致巨大的累积误差 [@problem_id:2393714]。通过动手实现 Kahan 求和算法，你将掌握一种补偿舍入误差的经典技巧，从而在数值计算中有效保持精度。", "problem": "你的任务是通过对比朴素的滚动求和与一种补偿求和方法，来研究浮点加法中舍入误差的累积。你必须实现一个完整的、可运行的程序，该程序针对一个固定的测试套件，使用 Kahan 求和算法计算朴素浮点和与补偿和，并将两者与使用精确有理数算术计算的高精度参考值进行比较。你的程序不能读取任何输入，且必须按照下文规定打印单行输出。\n\n使用的基本原理是带有“舍入到最近”规则的浮点运算的标准舍入误差模型：对于任意两个实数 $a$ 和 $b$，计算出的浮点加法满足 $\\operatorname{fl}(a+b) = (a+b)(1+\\delta)$，其中 $|\\delta|\\le u$，$u$ 是所选格式的单位舍入。你也可以利用以下事实：$n$ 项的朴素求和在最坏情况下会累积 $O(nu)$ 量级的舍入误差，而补偿求和技术旨在通过显式地考虑因舍入而丢失的低位比特来减少主阶误差的累积。\n\n要求：\n- 实现两个对双精度实数列表进行操作的求和例程：\n  - 一个朴素求和，它对每个项 $x_i$ 通过 $s \\leftarrow s + x_i$ 迭代更新一个滚动和。\n  - 一个 Kahan 补偿求和，它使用一个补偿变量来结转每次加法中丢失的低位信息。\n- 为了获得高精度参考值，使用精确有理数算术（例如，一个将每个项 $x_i$ 表示为分数并进行精确求和的有理数类型）计算每个列表的精确和。该参考值作为实数算术中的基准真相（ground truth）。\n\n测试套件：\n- 使用以下四个测试用例，每个用例都指定为一个有序列表。每个列表包含大数量级项与小数量级项的混合，以暴露灾难性抵消和有效数字损失问题。\n  1. $[\\,10^{16},\\,1,\\,-10^{16}\\,]$.\n  2. $[\\,10^{16},\\,\\underbrace{1,\\,1,\\,\\dots,\\,1}_{100000\\ \\text{次}},\\,-10^{16}\\,]$. 精确的数学和是 $100000$。\n  3. $[\\,1,\\,\\underbrace{10^{-16},\\,10^{-16},\\,\\dots,\\,10^{-16}}_{100000\\ \\text{次}},\\,-1\\,]$. 精确的数学和是 $100000\\cdot 10^{-16}=10^{-11}$。\n  4. $[\\,10^{16},\\,\\underbrace{10^{-6},\\,10^{-6},\\,\\dots,\\,10^{-6}}_{100000\\ \\text{次}},\\,-10^{16}\\,]$. 精确的数学和是 $100000\\cdot 10^{-6}=10^{-1}$。\n\n计算与比较：\n- 对每个测试用例，计算：\n  - 朴素浮点和 $s_{\\text{naive}}\\in\\mathbb{R}$。\n  - Kahan 浮点和 $s_{\\text{kahan}}\\in\\mathbb{R}$。\n  - 使用精确有理数算术计算的精确参考和 $s_{\\star}\\in\\mathbb{R}$。\n- 对每个测试用例，计算绝对误差 $e_{\\text{naive}}=\\lvert s_{\\text{naive}}-s_{\\star}\\rvert$ 和 $e_{\\text{kahan}}=\\lvert s_{\\text{kahan}}-s_{\\star}\\rvert$，并确定一个布尔标志 $\\text{better}$，当且仅当 $e_{\\text{kahan}}e_{\\text{naive}}$ 时，该标志为真。\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含一个列表，该列表由四个对应于各测试用例的记录组成，顺序与上述测试套件相同。每个记录本身必须是包含四个元素的列表，顺序为 $[\\,s_{\\text{naive}},\\,s_{\\text{kahan}},\\,s_{\\star},\\,\\text{better}\\,]$，其中 $s_{\\text{naive}}$、$s_{\\text{kahan}}$ 和 $s_{\\star}$ 以浮点数形式输出，而 $\\text{better}$ 是一个布尔值。将这四个记录聚合到一个列表中，并以逗号分隔元素、方括号括起的形式打印为单行，例如\n  $[\\, [\\,\\cdot,\\cdot,\\cdot,\\cdot\\,], [\\,\\cdot,\\cdot,\\cdot,\\cdot\\,], [\\,\\cdot,\\cdot,\\cdot,\\cdot\\,], [\\,\\cdot,\\cdot,\\cdot,\\cdot\\,] \\,]$.\n\n注意：\n- 不涉及物理单位。\n- 不使用角度。\n- 不使用百分比；所有量均为 $\\mathbb{R}$ 中的实数。\n- 实现必须是自包含的，并且无需用户输入即可运行。使用精确有理数算术或你所用语言标准库中可用的多精度功能来计算 $s_{\\star}$，以使对 $e_{\\text{naive}}$ 和 $e_{\\text{kahan}}$ 的比较有意义。", "solution": "所述问题是有效的。它在科学上基于数值分析（特别是浮点运算）的既定原则。该问题是适定的，为要实现的算法、全套测试数据和明确的输出格式提供了清晰的定义。问题是客观的，没有矛盾或信息缺失。我们可以着手解决。\n\n所要解决的根本问题是，计算机浮点加法不满足结合律，并且会产生舍入误差。对于两个实数 $a$ 和 $b$，它们的浮点和被建模为 $\\operatorname{fl}(a+b) = (a+b)(1+\\delta)$，其中相对误差 $\\lvert\\delta\\rvert$ 的上界为单位舍入 $u$。当对一个数列求和时，这些微小的误差可能会累积。本分析将把朴素求和方法与一种旨在减轻这种误差累积的补偿方法进行对比。\n\n**1. 朴素求和**\n\n最直接的方法是遍历数列 $\\{x_i\\}_{i=1}^n$ 并在单个浮点变量 $s$ 中累加和。更新规则为 $s \\leftarrow \\operatorname{fl}(s + x_i)$。该方法的主要弱点是**淹没**。如果滚动和 $s$ 的量级远大于待加项 $x_i$ 的量级，$x_i$ 的贡献可能会在舍入过程中部分或完全丢失。例如，在标准双精度运算中，如果 $s \\approx 10^{16}$ 且 $x_i = 1$，则运算 $\\operatorname{fl}(10^{16} + 1)$ 的结果为 $10^{16}$，因为精度不足以精确表示该结果。项 $x_i$ 实际上被丢弃了。\n\n**2. Kahan 补偿求和**\n\nKahan 求和算法是一种能显著减少舍入误差累积的技术。它维护第二个变量，即一个补偿量 $c$，用于累积每一步中产生的误差。对于输入序列中的每个项 $x_i$，该算法执行以下操作：\n1.  修正当前项：$y \\leftarrow x_i - c$。此步骤从当前项中减去先前加法累积的误差。\n2.  加到总和中：$t \\leftarrow s + y$。这是标准的浮点加法，如果 $s$ 很大， $y$ 的低位比特可能会丢失。\n3.  恢复误差：$c \\leftarrow (t - s) - y$。这是关键步骤。项 $(t - s)$ 代表 $y$ 中已成功加到 $s$ 的部分。通过减去原始（修正后）的项 $y$，我们分离出了加法 $s+y$ 的舍入误差的负值。这个误差存储在 $c$ 中。\n4.  更新总和：$s \\leftarrow t$。\n\n这个迭代过程将每次加法中丢失的“零头”带到下一次计算中，并将其合并，从而确保最终累积的误差远小于朴素求和的情况。Kahan 求和的误差界为 $O(u + N\\epsilon u)$ 量级，其中 $\\epsilon$ 与机器精度有关，这相比朴素求和的最坏情况误差 $O(Nu)$ 是一个巨大的改进。\n\n**3. 精确有理数算术**\n\n为建立一个权威的基准真相，记为 $s_{\\star}$，我们必须在没有任何浮点误差的情况下计算总和。这通过使用精确有理数算术来实现。每个以浮点值形式给出的输入数，首先被转换为其精确的有理数表示，即分数 $p/q$，其中 $p, q \\in \\mathbb{Z}$。所有后续的加法都使用精确的分数运算法则（例如 $\\frac{a}{b} + \\frac{c}{d} = \\frac{ad+bc}{bd}$）执行。这个过程没有浮点系统的表示误差和计算误差，从而得到输入值的真实数学和。\n\n**评估过程**\n\n对于四个指定的测试用例中的每一个，我们计算朴素和 $s_{\\text{naive}}$、Kahan 和 $s_{\\text{kahan}}$以及精确参考和 $s_{\\star}$。这些测试用例经过专门设计，通过混合量级差异巨大的数字，来暴露朴素求和的失效模式，特别是淹没和灾难性抵消。然后我们计算绝对误差 $e_{\\text{naive}} = \\lvert s_{\\text{naive}} - s_{\\star} \\rvert$ 和 $e_{\\text{kahan}} = \\lvert s_{\\text{kahan}} - s_{\\star} \\rvert$。当且仅当 $e_{\\text{kahan}}  e_{\\text{naive}}$ 时，布尔标志 $\\text{better}$ 被设置为 $\\text{True}$，这从数量上证明了 Kahan 算法对于给定输入的优越准确性。最终输出的结构是一个记录列表，每个记录包含 $[s_{\\text{naive}}, s_{\\text{kahan}}, s_{\\star}, \\text{better}]$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport scipy\nfrom fractions import Fraction\n\ndef naive_sum(numbers: list[float]) - float:\n    \"\"\"\n    Computes the sum of a list of numbers using a naive iterative approach.\n    \"\"\"\n    s = 0.0\n    for x in numbers:\n        s += x\n    return s\n\ndef kahan_sum(numbers: list[float]) - float:\n    \"\"\"\n    Computes the sum of a list of numbers using the Kahan summation algorithm\n    to reduce the accumulation of floating-point error.\n    \"\"\"\n    s = 0.0  # The running sum.\n    c = 0.0  # The compensation for lost low-order bits.\n    for x in numbers:\n        y = x - c    # c is the error from the previous sum.\n        t = s + y    # s is large, y is small, so low-order digits of y are lost.\n        c = (t - s) - y  # (t - s) recovers the high-order part of y.\n                         # Subtracting y recovers the low part, negated.\n        s = t        # Algebraically, c should be 0. But with rounding, it's not.\n    return s\n\ndef exact_sum(numbers: list[float]) - float:\n    \"\"\"\n    Computes the exact sum of a list of floating-point numbers by\n    converting them to Fractions and using rational arithmetic.\n    \"\"\"\n    s = Fraction(0)\n    for x in numbers:\n        s += Fraction(x)\n    return float(s)\n\ndef solve():\n    \"\"\"\n    Runs the full test suite, comparing naive and Kahan summation against\n    an exact rational arithmetic reference, and prints the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: A simple case of catastrophic cancellation.\n        [1e16, 1.0, -1e16],\n        # Case 2: Summing many small numbers in the presence of a large one.\n        [1e16] + [1.0] * 100000 + [-1e16],\n        # Case 3: Summing many tiny numbers that are smaller than machine epsilon\n        # relative to the initial sum.\n        [1.0] + [1e-16] * 100000 + [-1.0],\n        # Case 4: A similar case to #2, but with smaller additions.\n        [1e16] + [1e-6] * 100000 + [-1e16],\n    ]\n\n    results = []\n    for case_data in test_cases:\n        # Compute the sum using all three methods.\n        s_naive = naive_sum(case_data)\n        s_kahan = kahan_sum(case_data)\n        s_star = exact_sum(case_data)\n        \n        # Calculate the absolute errors for both floating-point methods.\n        e_naive = abs(s_naive - s_star)\n        e_kahan = abs(s_kahan - s_star)\n        \n        # Determine if Kahan's method produced a smaller error.\n        better = e_kahan  e_naive\n        \n        # Store the record for this test case.\n        record = [s_naive, s_kahan, s_star, better]\n        results.append(record)\n\n    # Final print statement in the exact required format.\n    # The format template from the prompt is used: print(f\"[{','.join(map(str, results))}]\")\n    # str(list) in Python automatically includes spaces, which matches the example\n    # format diagram '[ [ . , . , . , . ], ... ]'.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2393714"}, {"introduction": "现在我们转向一个最剧烈的误差来源：灾难性抵消 (catastrophic cancellation)。当两个几乎相等的数字相减时，有效数字会大量丢失，从而产生这种误差。本练习将在数值微分这一核心计算任务的背景下，深入探究这一现象，并揭示数学近似的截断误差 ($O(h)$) 与计算精度限制的舍入误差 ($O(u/h)$) 之间的根本性权衡 [@problem_id:2393695]。通过对比一个朴素公式和一个经过代数重构的数值稳定公式，你将学会如何诊断并解决这类关键的精度问题。", "problem": "要求您演示并分析浮点抵消对使用有限差分的数值微分的影响，并实现一个程序来量化这种效应对一个设计函数的影响。请在计算工程中使用的标准浮点算术模型内进行工作：电气与电子工程师协会（IEEE）754双精度（binary64）。采用经典的浮点舍入模型，即任何浮点基本运算都可以表示为 $\\operatorname{fl}(a \\,\\circ\\, b) = (a \\,\\circ\\, b)(1 + \\delta)$，其中 $|\\delta| \\leq u$，$u$ 是单位舍入误差。\n\n通过选择一个在特定点附近求值时会表现出灾难性抵消的光滑表达式来设计一个函数。在您的分析和实现中使用以下具体设计：\n- 函数：$f(x) = \\sqrt{1 + x} - 1$。\n- 关注点：$x_0 = 0$。\n- 在该点处的精确导数：$f^{\\prime}(0)$。\n- 原理：在 $x = 0$ 附近，$\\sqrt{1 + x}$ 和 $1$ 这两项几乎相等，因此它们的相减会丢失有效数字的首位。\n\n您的任务是：\n1. 使用泰勒级数和浮点舍入模型，根据第一性原理推导在 $x_0 = 0$ 处由下式定义的前向差分导数估计的主阶截断误差和主导舍入误差项\n   $$ D_h^{\\mathrm{fwd}} f(0) = \\frac{f(0 + h) - f(0)}{h}. $$\n   表达总误差如何依赖于 $h$ 和 $u$，并指出被抵消放大的项。您必须从基本定义出发：$\\sqrt{1 + x}$ 在 $x = 0$ 附近的泰勒展开式和单位舍入误差为 $u$ 的浮点舍入模型。\n\n2. 展示 $f(x)$ 的一个代数重构形式，该形式可以避免灾难性抵消，并解释为什么它能减少舍入误差的放大。使用恒等式\n   $$ f(x) = \\sqrt{1 + x} - 1 = \\frac{x}{\\sqrt{1 + x} + 1}, $$\n   并由此推导出一个在 $x_0 = 0$ 处，仅用 $h$ 表示且不含相减抵消的数值稳定前向差分公式。\n\n3. 实现一个程序，对于一组递减的步长 $h$，评估朴素前向差分导数估计的绝对误差以及由代数重构得到的稳定估计的绝对误差。对于每个 $h$，计算比率\n   $$ R(h) = \\frac{\\big| D_h^{\\mathrm{naive}} f(0) - f^{\\prime}(0) \\big|}{\\big| D_h^{\\mathrm{stabilized}} f(0) - f^{\\prime}(0) \\big|}, $$\n   其中 $D_h^{\\mathrm{naive}} f(0)$ 将 $f(h)$ 计算为 $\\sqrt{1 + h} - 1$，而 $D_h^{\\mathrm{stabilized}} f(0)$ 使用代数上等价的无抵消形式。请使用 IEEE 754 双精度，并使用您所用语言的默认浮点类型进行计算。\n\n使用以下步长测试集：\n- $h \\in \\{10^{-1}, 10^{-5}, 10^{-8}, 10^{-12}, 10^{-16}\\}$。\n\n规格说明：\n- 精确导数 $f^{\\prime}(0)$ 必须通过解析方法计算，并在误差计算中用作基准真值。如果涉及角度，均以弧度表示。没有物理单位。\n- 对于测试集中的每个 $h$，您的程序必须计算上面定义的单个实数 $R(h)$。\n- 最终输出格式：您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表（例如，“[result1,result2,result3,result4,result5]”）。各项必须与上面列出的 $h$ 值顺序相同。", "solution": "该问题要求对使用有限差分格式计算导数时的数值误差进行严格分析。具体而言，我们必须将总误差分解为其组成部分——来自数学近似的截断误差和来自有限精度算术的舍入误差——并演示朴素评估中的灾难性抵消如何加剧舍入误差。然后，我们将引入并分析一个代数上等价但数值上更优的公式。\n\n首先，我们确定基准真值。函数为 $f(x) = \\sqrt{1 + x} - 1$。其导数可使用链式法则求得：\n$$ f^{\\prime}(x) = \\frac{d}{dx} (\\sqrt{1 + x} - 1) = \\frac{1}{2\\sqrt{1 + x}}. $$\n在关注点 $x_0 = 0$ 处，精确导数为：\n$$ f^{\\prime}(0) = \\frac{1}{2\\sqrt{1 + 0}} = \\frac{1}{2}. $$\n\n在 $x_0 = 0$ 处的导数前向差分近似定义为：\n$$ D_h^{\\mathrm{fwd}} f(0) = \\frac{f(0 + h) - f(0)}{h}. $$\n由于 $f(0) = \\sqrt{1+0} - 1 = 0$，上式可简化为：\n$$ D_h^{\\mathrm{fwd}} f(0) = \\frac{f(h)}{h} = \\frac{\\sqrt{1 + h} - 1}{h}. $$\n\n**1. 朴素公式的误差分析**\n\n计算出的导数的总误差是计算值（我们记为 $\\widehat{D}_h^{\\mathrm{naive}}$）与精确值 $f^{\\prime}(0)$ 之间的差。此误差来自两个来源：\n\n- **截断误差 ($E_{\\text{trunc}}$)**：这是有限差分公式在假设精确计算下的固有误差。它可以通过 $f(h)$ 在 $h=0$ 附近的泰勒级数展开来量化。$\\sqrt{1+h}$ 的二项式级数为：\n$$ \\sqrt{1+h} = 1 + \\frac{1}{2}h - \\frac{1}{8}h^2 + \\frac{1}{16}h^3 - \\dots $$\n将此代入 $f(h)$ 的表达式中，得到：\n$$ f(h) = \\left(1 + \\frac{1}{2}h - \\frac{1}{8}h^2 + O(h^3)\\right) - 1 = \\frac{1}{2}h - \\frac{1}{8}h^2 + O(h^3). $$\n现在，我们可以表达精确的有限差分近似：\n$$ D_h^{\\mathrm{fwd}} f(0) = \\frac{f(h)}{h} = \\frac{\\frac{1}{2}h - \\frac{1}{8}h^2 + O(h^3)}{h} = \\frac{1}{2} - \\frac{1}{8}h + O(h^2). $$\n截断误差是此近似值与真实导数之间的差：\n$$ E_{\\text{trunc}} = D_h^{\\mathrm{fwd}} f(0) - f^{\\prime}(0) = \\left(\\frac{1}{2} - \\frac{1}{8}h + O(h^2)\\right) - \\frac{1}{2} = -\\frac{1}{8}h + O(h^2). $$\n主阶截断误差为 $O(h)$ 阶。\n\n- **舍入误差 ($E_{\\text{round}}$)**：此误差源于有限精度浮点算术的使用。我们使用模型 $\\operatorname{fl}(a \\circ b) = (a \\circ b)(1+\\delta)$，其中 $|\\delta| \\le u$，$u$ 是单位舍入误差。关键问题在于计算 $f(h) = \\sqrt{1+h}-1$。对于小的 $h  0$，$\\sqrt{1+h}$ 是一个非常接近 $1$ 的数。相减操作 $\\sqrt{1+h}-1$ 是一个典型的**灾难性抵消**案例，其中两个操作数的最高有效位相抵消，导致结果由有效性较低且可能不准确的数字主导。\n\n我们来分析分子计算值 $\\hat{f}(h) = \\operatorname{fl}(\\sqrt{1+h} - 1)$。主要误差源于 $\\sqrt{1+h}$ 的求值。其计算值为 $\\operatorname{fl}(\\sqrt{1+h}) = \\sqrt{1+h}(1+\\delta_1)$，其中 $|\\delta_1| \\le u$。由于 $\\sqrt{1+h} \\approx 1$，此中间步骤的绝对误差约为 $u$。随后的减法操作并不会减小这个绝对误差。因此，计算出的分子为 $\\hat{f}(h) \\approx f(h) + \\epsilon_{\\text{num}}$，其中分子的误差 $\\epsilon_{\\text{num}}$ 的量级为 $u$。\n\n因此，计算出的导数为：\n$$ \\widehat{D}_h^{\\mathrm{naive}} \\approx \\frac{f(h) + \\epsilon_{\\text{num}}}{h} = \\frac{f(h)}{h} + \\frac{\\epsilon_{\\text{num}}}{h}. $$\n舍入误差部分为：\n$$ E_{\\text{round}} = \\widehat{D}_h^{\\mathrm{naive}} - D_h^{\\mathrm{fwd}} f(0) \\approx \\frac{\\epsilon_{\\text{num}}}{h}. $$\n舍入误差的大小由以下公式界定：\n$$ |E_{\\text{round}}| \\lesssim \\frac{u}{h}. $$\n该项被除以一个小的 $h$ 所放大。当 $h \\to 0$ 时，舍入误差无限增长。\n\n总绝对误差是两个误差分量大小之和：\n$$ |E_{\\text{total}}| \\approx |E_{\\text{trunc}}| + |E_{\\text{round}}| \\approx \\frac{h}{8} + \\frac{u}{h}. $$\n这个关于 $h$ 的函数有一个最小值。对于大的 $h$，截断误差占主导地位。对于小的 $h$，舍入误差占主导地位。\n\n**2. 为实现数值稳定性的代数重构**\n\n灾难性抵消可以通过对 $f(x)$ 表达式进行重构来避免。我们将分子和分母同乘以表达式的共轭式：\n$$ f(x) = \\sqrt{1+x} - 1 = (\\sqrt{1+x} - 1) \\times \\frac{\\sqrt{1+x} + 1}{\\sqrt{1+x} + 1} = \\frac{(1+x) - 1^2}{\\sqrt{1+x} + 1} = \\frac{x}{\\sqrt{1+x} + 1}. $$\n这个我们可称之为 $f_{\\text{stable}}(x)$ 的新形式，在数学上与原始的 $f(x)$ 等价，但在数值计算上更优越。近似数相减的操作被加法 $\\sqrt{1+x}+1$ 所取代，这在浮点运算中是一种良性操作，因为没有有效数字会丢失。\n\n使用这种稳定形式，我们推导出一个新的有限差分公式：\n$$ D_h^{\\mathrm{stabilized}} f(0) = \\frac{f_{\\text{stable}}(h)}{h} = \\frac{1}{h} \\left( \\frac{h}{\\sqrt{1+h} + 1} \\right) = \\frac{1}{\\sqrt{1+h} + 1}. $$\n这个导数近似公式完全用 $h$ 表示，并且不包含相减抵消。\n\n由于这个公式在数学上是等价的，其截断误差与朴素公式的截断误差相同：\n$$ E_{\\text{trunc}} = \\frac{1}{\\sqrt{1+h}+1} - \\frac{1}{2} = -\\frac{h}{8} + O(h^2). $$\n然而，其舍入误差表现得到了极大的改善。在评估 $\\widehat{D}_h^{\\mathrm{stabilized}} = \\operatorname{fl}\\left(\\frac{1}{\\sqrt{1+h}+1}\\right)$ 时，每一步（开方、加法、除法）引入的舍入误差都与 $u$ 成正比。不存在被小 $h$ 放大的情况。最终计算结果的相对误差在 $u$ 的量级，即 $|E_{\\text{round}}| \\approx f^{\\prime}(0) \\times (\\text{小常数}) \\times u \\approx \\frac{1}{2} k u$。这个舍入误差很小，并且不会随着 $h$ 的减小而增大。\n\n因此，对于稳定公式，在所有实际的 $h$ 值下，总误差主要由截断误差 $|E_{\\text{trunc}}| \\approx h/8$ 主导。\n\n**3. 比较与实现**\n\n程序将计算比率 $R(h) = \\frac{|\\text{朴素公式的误差}|}{|\\text{稳定公式的误差}|}$。根据我们的分析：\n$$ R(h) \\approx \\frac{\\frac{h}{8} + \\frac{u}{h}}{\\frac{h}{8}}. $$\n对于大的 $h$（例如，$h=10^{-1}$），此时 $\\frac{h}{8} \\gg \\frac{u}{h}$，比率 $R(h)$ 应接近 $1$。\n随着 $h$ 的减小，分子中的 $\\frac{u}{h}$ 项变得显著。对于 $h=10^{-8}$，在双精度（$u \\approx 10^{-16}$）下，这两项的量级相近。\n对于非常小的 $h$（例如，$h=10^{-16}$），舍入误差 $\\frac{u}{h} \\approx 1$ 完全主导了朴素误差，而稳定误差则保持很小（量级为 $h/8 \\approx 10^{-17}$）。因此，比率 $R(h)$ 预期会变得极大，从而量化了朴素方法的急剧失效。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Analyzes the effect of catastrophic cancellation on finite difference\n    approximations and compares a naive formula with a stabilized one.\n    \"\"\"\n\n    # The exact value of the derivative f'(0) for f(x) = sqrt(1+x) - 1.\n    # f'(x) = 1 / (2*sqrt(1+x)), so f'(0) = 1/2.\n    f_prime_at_0 = 0.5\n\n    # Define the test cases from the problem statement.\n    # The step sizes h to be evaluated.\n    test_cases = [1e-1, 1e-5, 1e-8, 1e-12, 1e-16]\n\n    results = []\n    for h in test_cases:\n        # --- Naive Forward-Difference Calculation ---\n        # This formula is prone to catastrophic cancellation for small h.\n        # f(h) = sqrt(1+h) - 1. f(0) = 0.\n        # D_naive = (f(h) - f(0)) / h = (sqrt(1+h) - 1) / h\n        f_h_naive = np.sqrt(1.0 + h) - 1.0\n        d_naive = f_h_naive / h\n        \n        # Calculate the absolute error of the naive method.\n        error_naive = abs(d_naive - f_prime_at_0)\n\n        # --- Stabilized Forward-Difference Calculation ---\n        # This formula is derived from the algebraic identity:\n        # f(h) = h / (sqrt(1+h) + 1).\n        # D_stabilized = (f(h) - f(0)) / h = 1 / (sqrt(1+h) + 1).\n        # This form avoids subtracting nearly equal numbers.\n        d_stabilized = 1.0 / (np.sqrt(1.0 + h) + 1.0)\n        \n        # Calculate the absolute error of the stabilized method.\n        # This error is primarily due to truncation for the given h values.\n        error_stabilized = abs(d_stabilized - f_prime_at_0)\n        \n        # --- Compute the Ratio of Errors ---\n        # This ratio quantifies how much worse the naive method is compared\n        # to the stabilized one.\n        # If error_stabilized is zero (unlikely for h0), we handle it.\n        # However, due to truncation and floating point representation, it\n        # will be a small non-zero number.\n        if error_stabilized == 0.0:\n            # This case indicates either an issue or that the stabilized formula\n            # was perfectly accurate, making the naive error infinitely worse.\n            # Handle by setting a large number or np.inf if appropriate.\n            # For this problem, it will not be hit.\n            ratio = np.inf\n        else:\n            ratio = error_naive / error_stabilized\n        \n        results.append(ratio)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2393695"}]}