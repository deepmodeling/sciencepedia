{"hands_on_practices": [{"introduction": "理论模型最好通过实践来理解，而并行编程实践的第一步是确保正确性。这个练习将带你进入并发编程的核心挑战之一：数据竞争（data race）。你将学习如何在一个常见的哈希表数据结构中，首先确定性地触发一个由于非原子性的“读取-修改-写入”操作序列而导致的“丢失更新”错误，然后再使用互斥锁（mutex）和原子操作等基本同步原语来修复它 [@problem_id:2422625]。掌握这些技能是成为一名合格的并行程序员的第一个，也是最关键的一步。", "problem": "创建一个完整、可运行的程序，该程序演示哈希表中的数据竞争，然后使用两种不同的同步范式消除它。程序必须实现一个固定容量、开放寻址的哈希表，用于存储整数键和整数值。设容量为正整数 $m$。哈希函数为 $h(k) = k \\bmod m$，冲突通过线性探测解决。该表必须支持一个操作：给定一个键 $k$，将其关联的值增加 1。\n\n精确指定语义如下：\n- 哈希表是一个从整数到整数的映射。对于给定的键 $k$，由 $T$ 个线程每个执行 $R$ 次并发增量操作，其数学上正确的效果是，假设初始值为 0 且没有其他操作发生，最终存储的值等于 $T \\times R$。\n- 增量操作的非同步实现会执行读取当前值、加 1 计算后继值、然后将结果写回的操作，此读-改-写序列没有任何同步保护。\n- 互斥（mutex）实现使用单个全局互斥锁，以确保每次增量操作都作为一个不可分割的临界区执行。\n- 原子操作实现使用一个“逐键原子取加”(per-key atomic fetch-and-add) 原语，其线性化规范如下：调用 `atomic_fetch_add`$(x, \\Delta)$ 会返回存储在 $x$ 处的先前值，并设置 $x \\leftarrow x + \\Delta$，如同该操作是瞬时且不可分割的一样。在此变体中，增量操作通过 `atomic_fetch_add(x, 1)` 执行。\n\n您的程序必须在非同步变体中构造一个确定性的数据竞争，方法是确保对同一键的两个并发增量操作在任一写入之前都读取相同的先前值。测试必须被构造成使得两个线程都读取值 $0$ 并都写回 $1$，从而使最终值为 $1$，而数学上正确的值为 $2$。\n\n使用以下测试套件。对于所有测试，使用固定容量 $m = 8$ 和相同的键 $k_0 = 7$，在任何增量操作之前将该键插入表中，并将其值初始化为 $0$。\n\n- 测试 1 (确定性数据竞争):\n  - 变体: unsynchronized (非同步)。\n  - 线程数: $T = 2$。\n  - 每线程增量次数: $R = 1$。\n  - 调度这两个线程，使它们都在任一写入之前完成读取，从而确保数据竞争和更新丢失。\n  - 预期数学正确值: 2。\n  - 测试结果是一个布尔值，指示观察到的最终值是否等于 2。\n\n- 测试 2 (粗粒度互斥，通用情况):\n  - 变体: mutex (互斥)。\n  - 线程数: $T = 4$。\n  - 每线程增量次数: $R = 1000$。\n  - 预期数学正确值: 4000。\n  - 测试结果是一个布尔值，指示观察到的最终值是否等于 4000。\n\n- 测试 3 (原子取加，通用情况):\n  - 变体: atomic operations (原子操作)。\n  - 线程数: $T = 8$。\n  - 每线程增量次数: $R = 1000$。\n  - 预期数学正确值: 8000。\n  - 测试结果是一个布尔值，指示观察到的最终值是否等于 8000。\n\n- 测试 4 (零工作量的边界条件):\n  - 变体: mutex (互斥)。\n  - 线程数: $T = 5$。\n  - 每线程增量次数: $R = 0$。\n  - 预期数学正确值: 0。\n  - 测试结果是一个布尔值，指示观察到的最终值是否等于 0。\n\n您的程序必须生成单行输出，其中包含按测试 1 到 4 的顺序排列的结果，格式为逗号分隔的列表并用方括号括起。例如，如果所有测试都通过，输出必须严格采用 \"[True,True,True,True]\" 的形式，不含空格。不涉及物理单位。不使用角度。不使用百分比。", "solution": "所提供的问题陈述是有效的。它在科学上基于并发编程的原理，问题提出得当，具有明確的目标和充分的数据，并且语言客观。该问题要求实现一个并发哈希表并演示数据竞争，以及使用标准同步技术解决该问题的方法，这是计算工程中一个经典且可形式化的问题。\n\n解决方案首先通过设计一个哈希表类 `ConcurrentHashTable` 来实现，该类能够以三种不同的模式运行：`unsynchronized`（非同步）、`mutex`（基于互斥锁）和 `atomic`（原子操作）。然后，程序执行一套包含四个测试的测试套件，以演示和验证这些模式的行为。\n\n**1. 哈希表设计**\n\n该哈希表使用带有线性探测的开放寻址法。其存储由两个 NumPy 数组组成：`_keys` 和 `_values`，每个数组的大小等于容量 $m$。空槽位由 `_keys` 数组中的一个特殊哨兵对象标记。哈希函数如指定为 $h(k) = k \\bmod m$。`_find_slot` 方法实现了线性探测，以为给定的键 $k$ 定位正确的槽位，它从索引 $h(k)$ 开始，顺序搜索，直到找到该键或一个空槽位。\n\n**2. 增量操作和同步变体**\n\n核心逻辑位于 `increment` 方法中，该方法修改与键 $k$ 关联的值。其行为由表实例化时指定的 `variant` 决定。\n\n-   **非同步变体 (`Unsynchronized`)**: 此实现执行一个非原子的读-改-写序列。它读取当前值，将其递增，然后在没有任何锁的情况下将其写回。此版本故意设计为易受数据竞争影响。为了进行确定性测试，此方法增加了一个可选的 `barrier` 参数。当提供一个 `threading.Barrier` 时，线程在读取值后会暂停，从而可以精确控制执行调度以强制产生数据竞争。\n\n-   **互斥（粗粒度锁定）变体 (`Mutex`)**: 此实现为整个哈希表使用一个单一的、全局的 `threading.Lock` 实例。任何希望执行增量操作的线程都必须首先获取此锁，从而使整个增量操作成为一个临界区。这确保了在任何给定时间只有一个线程可以修改表，从而防止所有数据竞争，但可能会限制并发性。\n\n-   **原子操作（细粒度锁定）变体 (`Atomic`)**: 问题指定了一个“逐键原子取加原语”(per-key atomic fetch-and-add primitive)。这是通过创建一个 `threading.Lock` 对象数组来实现的，其中每个锁对应哈希表中的一个槽位。在递增键 $k$ 时，线程首先找到其指定的槽位 $idx$，然后在修改 `_values[idx]` 之前获取锁 `_slot_locks[idx]`。这提供了细粒度的同步，因为映射到不同槽位的键上的操作可以并行进行。这正确地模拟了逐键原子性的语义。\n\n**3. 测试套件执行**\n\n`solve` 函数协调执行指定的四个测试。\n\n-   **测试 1 (确定性数据竞争)**: 此测试演示了一次更新丢失。它使用 `unsynchronized` 变体，有 $T=2$ 个线程，每个线程对键 $k_0=7$ 执行 $R=1$ 次增量操作。一个 `threading.Barrier(2)` 被传递给 `increment` 方法。两个线程都启动。每个线程读取初始值 0。然后它们都在屏障处等待。一旦两者都到达屏障，它们会同时被解除阻塞。然后两个线程都尝试将值 $0+1=1$ 写入同一位置。表中的最终值为 1。数学上正确的值是 $T \\times R = 2 \\times 1 = 2$。测试将观察到的值 (1) 与正确值 (2) 进行比较，得出 False，这正确地指出了由数据竞争导致的失败。\n\n-   **测试 2 (互斥同步)**: 此测试在较高负载下验证了粗粒度锁定方法的正确性。使用 $T=4$ 个线程，每个线程执行 $R=1000$ 次增量操作，全局锁确保所有 4000 次增量都是顺序应用的，尽管顺序不确定。最终值保证为数学上正确的 4000。测试结果为 True。\n\n-   **测试 3 (原子操作)**: 此测试验证了细粒度锁定机制。使用 $T=8$ 个线程，每个线程执行 $R=1000$ 次增量操作，特定于槽位的锁保护了对键值的更新。最终值将是所有增量的正确总和，即 8000。测试结果为 True。\n\n-   **测试 4 (边界条件)**: 此测试使用 `mutex` 变体，有 $T=5$ 个线程，执行 $R=0$ 次增量操作。由于增量次数为 0，工作线程不对哈希表执行任何操作。初始值 0 保持不变。期望值为 $T \\times R = 5 \\times 0 = 0$。测试结果为 True，证实了在零工作量情况下的正确行为。\n\n程序收集每个测试的布尔结果，并以指定的格式 `[result1,result2,result3,result4]` 打印它们。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport threading\n\nclass ConcurrentHashTable:\n    \"\"\"\n    A fixed-capacity, open-addressed hash table supporting concurrent increments.\n    \n    The table can be configured to use different synchronization paradigms:\n    - 'unsynchronized': No locking, vulnerable to data races.\n    - 'mutex': A single global lock for coarse-grained synchronization.\n    - 'atomic': A lock per hash slot for fine-grained synchronization.\n    \"\"\"\n\n    def __init__(self, capacity, variant):\n        if not isinstance(capacity, int) or capacity <= 0:\n            raise ValueError(\"Capacity must be a positive integer.\")\n        if variant not in ['unsynchronized', 'mutex', 'atomic']:\n            raise ValueError(\"Invalid variant specified.\")\n\n        self.capacity = capacity\n        self.variant = variant\n        \n        # Sentinel object to mark empty slots in the key array.\n        self._EMPTY = object()\n        \n        self._keys = np.full(self.capacity, self._EMPTY, dtype=object)\n        self._values = np.zeros(self.capacity, dtype=np.int64)\n\n        if self.variant == 'mutex':\n            self._lock = threading.Lock()\n        elif self.variant == 'atomic':\n            self._slot_locks = [threading.Lock() for _ in range(self.capacity)]\n\n    def _hash(self, key):\n        return key % self.capacity\n\n    def _find_slot(self, key):\n        \"\"\"Finds the slot for a key using linear probing.\"\"\"\n        start_idx = self._hash(key)\n        for i in range(self.capacity):\n            idx = (start_idx + i) % self.capacity\n            # Return slot if key is found or an empty slot is available for insertion.\n            if self._keys[idx] == key or self._keys[idx] == self._EMPTY:\n                return idx\n        raise RuntimeError(\"Hash table is full and key not found.\")\n\n    def insert(self, key, value=0):\n        \"\"\"Inserts a key-value pair. Assumes non-concurrent insertion.\"\"\"\n        idx = self._find_slot(key)\n        if self._keys[idx] == self._EMPTY:\n            self._keys[idx] = key\n            self._values[idx] = value\n        else: # Key already exists, update value.\n            self._values[idx] = value\n            \n    def get_value(self, key):\n        \"\"\"Retrieves the value for a given key.\"\"\"\n        idx = self._find_slot(key)\n        if self._keys[idx] == key:\n            return self._values[idx]\n        raise KeyError(\"Key not found in table.\")\n\n    def increment(self, key, barrier=None):\n        \"\"\"\n        Increments the value associated with a key by 1.\n        The synchronization behavior depends on the table's variant.\n        A barrier can be passed for deterministic testing of race conditions.\n        \"\"\"\n        idx = self._find_slot(key)\n        if self._keys[idx] != key:\n            raise KeyError(\"Key not found in table for increment.\")\n\n        if self.variant == 'unsynchronized':\n            # Non-atomic read-modify-write.\n            old_val = self._values[idx]\n            # Barrier for deterministic scheduling in Test 1.\n            if barrier:\n                try:\n                    barrier.wait()\n                except threading.BrokenBarrierError:\n                    pass # Barrier might be reset between threads\n            self._values[idx] = old_val + 1\n        \n        elif self.variant == 'mutex':\n            # Coarse-grained lock on the entire table.\n            with self._lock:\n                self._values[idx] += 1\n        \n        elif self.variant == 'atomic':\n            # Fine-grained lock on the specific hash slot.\n            with self._slot_locks[idx]:\n                self._values[idx] += 1\n\ndef solve():\n    \"\"\"\n    Executes the test suite to demonstrate data races and synchronization.\n    \"\"\"\n    test_params = [\n        {'id': 1, 'variant': 'unsynchronized', 'T': 2, 'R': 1, 'm': 8, 'k0': 7, 'correct': 2},\n        {'id': 2, 'variant': 'mutex',          'T': 4, 'R': 1000, 'm': 8, 'k0': 7, 'correct': 4000},\n        {'id': 3, 'variant': 'atomic',         'T': 8, 'R': 1000, 'm': 8, 'k0': 7, 'correct': 8000},\n        {'id': 4, 'variant': 'mutex',          'T': 5, 'R': 0, 'm': 8, 'k0': 7, 'correct': 0},\n    ]\n\n    results = []\n    \n    # --- Test 1: Deterministic Data Race ---\n    case = test_params[0]\n    table = ConcurrentHashTable(capacity=case['m'], variant=case['variant'])\n    table.insert(key=case['k0'], value=0)\n    \n    barrier = threading.Barrier(case['T'])\n    \n    def race_worker(tbl, key, bar):\n        tbl.increment(key, barrier=bar)\n\n    threads = []\n    for _ in range(case['T']):\n        thread = threading.Thread(target=race_worker, args=(table, case['k0'], barrier))\n        threads.append(thread)\n        thread.start()\n    \n    for thread in threads:\n        thread.join()\n        \n    observed = table.get_value(case['k0'])\n    results.append(observed == case['correct']) # Expected: False\n\n    # --- Tests 2, 3, 4: General Cases ---\n    def general_worker(tbl, key, num_increments):\n        for _ in range(num_increments):\n            tbl.increment(key)\n\n    for case in test_params[1:]:\n        table = ConcurrentHashTable(capacity=case['m'], variant=case['variant'])\n        table.insert(key=case['k0'], value=0)\n\n        threads = []\n        for _ in range(case['T']):\n            thread = threading.Thread(target=general_worker, args=(table, case['k0'], case['R']))\n            threads.append(thread)\n            thread.start()\n\n        for thread in threads:\n            thread.join()\n            \n        observed = table.get_value(case['k0'])\n        results.append(observed == case['correct'])\n    \n    # Final print statement in the exact required format.\n    # The str() of a bool in Python is 'True' or 'False' (capitalized).\n    # The problem example shows \"[True,True,True,True]\".\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2422625"}, {"introduction": "在使用基本锁确保了程序的正确性之后，我们可以探索对并发访问进行更精细的控制。本练习探讨经典的“读者-写者问题”，这是一个典型的同步场景，其中不同类型的操作具有不同的兼容性规则：多个读者可以同时访问，但任何一个写者都需要独占访问权。你将通过模拟一个精心设计的调度策略来解决这个问题，该策略优先考虑写者以防止其“饿死”[@problem_id:2422634]。这个实践将让你学会不仅仅将同步视为互斥的工具，而是将其视为实现复杂访问控制逻辑、平衡系统性能与公平性的机制。", "problem": "给定一个共享内存并行系统，其中有一个单一逻辑共享对象，可由两种类型的操作访问：读者和写者。每个操作都是一个请求，其特征在于一个到达时间和一段服务时长，两者都以离散的无单位时间步来衡量。一个操作一旦开始，就会在从其开始时间到其开始时间加上其时长的半开区间内占用共享对象，即在区间 $[s_i, s_i + d_i)$ 内，其中 $s_i$ 是开始时间，$d_i$ 是时长。\n\n系统必须满足以下语义和约束。\n\n1) 安全性约束。令 $R(t)$ 表示在时间 $t$ 的活动读者数量，令 $W(t) \\in \\{0,1\\}$ 表示在时间 $t$ 的活动写者数量。系统必须确保对于每个时间 $t$，如果 $W(t) = 1$ 则 $R(t) = 0$，并且任何时候都不能有超过一个写者同时活动。当没有写者活动时，多个读者可以并发活动。\n\n2) 写者公平性约束（写者免饿死）。一旦一个写者已到达并等待开始，那么在没有等待的写者之前，任何新的读者都不能开始。形式上，如果在时间 $t$ 存在一个写者 $j$，其到达时间 $a_j \\le t$ 且其开始时间 $s_j$ 满足 $s_j > t$，那么在时间 $t$ 就不能有读者开始。\n\n3) 确定性调度语义。时间在一系列离散的决策时间点上推进。在每个决策时间点 $t$，假定在瞬间 $t$ 内存在以下顺序：首先，所有结束时间恰好为 $t$ 的操作完成并释放资源；其次，所有到达时间等于 $t$ 的操作被视为已到达并加入等待集合；第三，根据以下规则确定新的开始操作：\n   a) 如果至少有一个等待的写者，并且没有活动的读者和活动的写者，那么最早到达的那个等待的写者必须在时间 $t$ 开始。\n   b) 否则，如果没有等待的写者且没有活动的写者，那么所有等待的读者都必须在时间 $t$ 开始。\n   c) 否则，在时间 $t$ 没有新的操作开始。\n如果多个请求共享相同的到达时间，它们的相对顺序是该测试用例输入中给出的顺序。操作的开始时间不得早于其到达时间。\n\n你的任务是实现一个程序，对于每个测试用例，给定一个有限的请求列表，为所有请求构建符合上述语义的开始时间，然后为每个测试用例计算以下三个量：\n- 一个布尔值，指示生成的调度是否同时满足上面定义的安全性约束和写者公平性约束。\n- 最大并发读者数，即在整个调度中的 $\\max_{t} R(t)$。\n- 完工时间，定义为最晚完成时间 $\\max_i (s_i + d_i)$ 与最早到达时间 $\\min_i a_i$ 之间的差值。\n\n测试套件。使用以下5个测试用例。每个测试用例是一个请求列表。每个请求是一个三元组 $(\\text{type}, a, d)$，其中 $\\text{type} \\in \\{\\text{R}, \\text{W}\\}$，$a$ 是到达时间，$d$ 是时长。对于测试用例中相等的到达时间，下面列出请求的顺序是必需的平局决胜顺序。\n\n- 测试用例 1:\n  `[('R', 0, 5), ('R', 1, 3), ('W', 2, 4), ('R', 6, 2), ('W', 6, 1)]`\n\n- 测试用例 2:\n  `[('R', 0, 2), ('R', 0, 2), ('R', 1, 1)]`\n\n- 测试用例 3:\n  `[('W', 0, 2), ('W', 1, 2), ('W', 3, 1)]`\n\n- 测试用例 4:\n  `[('R', 0, 5), ('R', 1, 5), ('W', 2, 2), ('R', 2, 1), ('R', 3, 1)]`\n\n- 测试用例 5:\n  `[('R', 0, 1), ('W', 0, 1)]`\n\n最终输出格式。你的程序应生成单行输出，其中包含一个用方括号括起来的、以逗号分隔的结果列表。每个元素对应一个测试用例，并且其本身必须是按 $[\\text{valid}, \\text{max\\_readers}, \\text{makespan}]$ 顺序排列的三元素列表，不含空格。例如，一个有效的输出形状是\n`[[True,2,7],[False,1,3],[True,3,5],[True,2,4],[True,1,1]]`\n但实际值由你对指定测试套件的实现来确定。", "solution": "该问题要求对共享资源上的读者-写者问题模拟一个确定性的调度策略。解决方案包括两个主要阶段：首先，在离散时间步上模拟系统以生成一个调度；其次，分析此调度以计算所需的指标。\n\n**1. 调度策略的模拟**\n\n任务的核心是实现一个离散时间模拟器，该模拟器严格遵守给定的调度语义。系统在任何时间 `t` 的状态可由活动操作集合和等待操作集合来描述。\n\n让我们形式化状态变量：\n- 一个未处理的请求列表，按其到达时间 $a_i$ 排序，若时间相同，则按其在输入中的顺序排序。每个请求 $i$ 是一个 (类型, $a_i$, $d_i$) 的元组。我们将为其增加一个唯一ID和用于记录开始时间 $s_i$ 的字段。\n- 一个等待的读者队列，`waiting_readers`。\n- 一个等待的写者队列，`waiting_writers`，根据到达时间按先进先出（FIFO）顺序维护。\n- 一个活动读者列表，`active_readers`。\n- 一个用于单个活动写者的变量，`active_writer`。\n\n模拟通过从 $t=0$ 开始递增时间变量 $t$ 来进行。当所有请求都已到达、开始并完成时，模拟终止。\n\n在每个时间步 $t$，必须按照问题陈述中指定的方式执行以下操作序列：\n\n**步骤 1：处理完成**\n任何完成时间 $s_i + d_i$ 等于 $t$ 的活动操作 $i$ 会结束其执行。\n- 如果一个活动写者 $j$ 的 $s_j + d_j = t$，则通过将 `active_writer` 设为 null 来释放资源。\n- 任何 $s_k + d_k = t$ 的活动读者 $k$ 将从 `active_readers` 列表中移除。\n\n**步骤 2：处理到达**\n所有到达时间 $a_i = t$ 的请求 $i$ 都从未处理列表移动到适当的等待队列（`waiting_readers` 或 `waiting_writers`）。添加到队列时必须遵守平局决胜规则（对具有相同到达时间的请求按输入顺序）。\n\n**步骤 3：作出调度决策**\n根据活动队列和等待队列的当前状态，遵循一套严格的规则来启动新操作：\n- **规则 (a):** 如果 `waiting_writers` 非空 并且 `active_readers` 为空 并且 `active_writer` 为 null，则从 `waiting_writers` 中将最早到达的写者出队并开始。其开始时间 $s_i$ 被设为 $t$，并成为 `active_writer`。\n- **规则 (b):** 否则，如果 `waiting_writers` 为空 并且 `active_writer` 为 null，则 `waiting_readers` 中的所有读者都开始。对于每个读者，其开始时间 $s_i$ 被设为 $t$，并被移动到 `active_readers` 列表中。然后清空 `waiting_readers` 队列。\n- **规则 (c):** 在所有其他情况下（例如，资源由写者持有，或在有写者等待时由读者持有），在时间 $t$ 没有新操作可以开始。\n\n这个 $t++$ 模拟循环会一直持续到所有请求都完成为止。\n\n**2. 对生成的调度进行分析**\n\n模拟完成后，所有请求都将有一个分配好的开始时间 $s_i$。然后我们分析这个完整的调度，为每个测试用例计算三个量。\n\n**A. 调度有效性**\n问题要求一个布尔值，指示生成的调度是否满足安全性和写者公平性约束。所提供的调度规则旨在通过其构造来生成一个有效的调度。因此，此检查可作为对模拟器实现的验证。\n- **安全性检查：** 如果在任何时间 $t$ 都没有写者与任何其他操作（读者或写者）并发活动，并且任何时候活动写者都不超过一个，则调度是安全的。这可以通过遍历时间并检查活动操作集合来验证。\n- **公平性检查：** 写者免饿死规则规定，如果有写者在等待，则在时间 $t$ 不能有新读者开始。这可以通过检查每个读者的开始时间 $s_k$ 来核实。在 $t = s_k$ 时，我们验证不存在满足 $a_j \\le s_k$ 且 $s_j > s_k$ 的写者 $j$。\n\n如果两项检查都通过，则调度有效。鉴于确定性的规则，对于正确的实现，此值应始终为 `True`。\n\n**B. 最大并发读者数**\n这是在调度的整个持续时间内 $R(t)$ 的最大值，其中 $R(t)$ 是在时间 $t$ 的活动读者数量。这可以通过分析调度来计算。一种高效的方法是在时间 $s_i$ 和 $s_i+d_i$ 分别创建“读者开始”和“读者结束”的事件列表。通过对这些事件进行排序并进行时间扫描，我们可以跟踪当前活动读者的数量并找到其最大值。\n\n**C. 完工时间**\n完工时间定义为从第一个到达事件到最后一个完成事件所经过的总时间。它的计算公式为：\n$$\n\\text{Makespan} = \\left( \\max_{i} (s_i + d_i) \\right) - \\left( \\min_{i} a_i \\right)\n$$\n最小到达时间 $\\min(a_i)$ 可从输入数据中找到。最大完成时间 $\\max(s_i + d_i)$ 由生成的调度确定。\n\n对每个测试用例遵循此程序，我们可以系统地推导出所需的结果。使用简单的时间步进模拟确保了对问题形式化规范的直接而忠实的实现。", "answer": "```python\nimport numpy as np\nfrom collections import deque\n\ndef solve():\n    \"\"\"\n    Solves the readers-writers scheduling problem for a suite of test cases.\n    \"\"\"\n    test_cases = [\n        # Test case 1\n        [('R', 0, 5), ('R', 1, 3), ('W', 2, 4), ('R', 6, 2), ('W', 6, 1)],\n        # Test case 2\n        [('R', 0, 2), ('R', 0, 2), ('R', 1, 1)],\n        # Test case 3\n        [('W', 0, 2), ('W', 1, 2), ('W', 3, 1)],\n        # Test case 4\n        [('R', 0, 5), ('R', 1, 5), ('W', 2, 2), ('R', 2, 1), ('R', 3, 1)],\n        # Test case 5\n        [('R', 0, 1), ('W', 0, 1)],\n    ]\n\n    all_results = []\n    for case_idx, case_data in enumerate(test_cases):\n        # 1. Initialize requests with unique IDs and start times\n        requests = []\n        for i, (req_type, arrival, duration) in enumerate(case_data):\n            requests.append({\n                'id': i,\n                'type': req_type,\n                'a': arrival,\n                'd': duration,\n                's': -1,  # Start time, -1 indicates not started\n            })\n\n        # 2. Simulation\n        time = 0\n        num_completed = 0\n        total_requests = len(requests)\n        \n        arrived_but_not_waiting_requests = sorted(requests, key=lambda r: (r['a'], r['id']))\n        arrived_idx = 0\n\n        waiting_readers = deque()\n        waiting_writers = deque()\n        active_readers = []\n        active_writer = None\n\n        while num_completed < total_requests:\n            # Step 1: Process completions at the beginning of time t\n            completed_this_step = []\n            if active_writer and (active_writer['s'] + active_writer['d'] == time):\n                completed_this_step.append(active_writer)\n                active_writer = None\n\n            remaining_active_readers = []\n            for r in active_readers:\n                if r['s'] + r['d'] == time:\n                    completed_this_step.append(r)\n                else:\n                    remaining_active_readers.append(r)\n            active_readers = remaining_active_readers\n            \n            num_completed += len(completed_this_step)\n\n            # Step 2: Process arrivals at time t\n            while arrived_idx < total_requests and arrived_but_not_waiting_requests[arrived_idx]['a'] == time:\n                req = arrived_but_not_waiting_requests[arrived_idx]\n                if req['type'] == 'R':\n                    waiting_readers.append(req)\n                else: # 'W'\n                    waiting_writers.append(req)\n                arrived_idx += 1\n\n            # Step 3: Make scheduling decisions\n            # Rule a: Start a writer if possible\n            if waiting_writers and not active_readers and not active_writer:\n                writer_to_start = waiting_writers.popleft()\n                writer_to_start['s'] = time\n                active_writer = writer_to_start\n            # Rule b: Otherwise, start readers if possible\n            elif not waiting_writers and not active_writer:\n                while waiting_readers:\n                    reader_to_start = waiting_readers.popleft()\n                    reader_to_start['s'] = time\n                    active_readers.append(reader_to_start)\n            # Rule c: Otherwise, wait\n            \n            time += 1\n        \n        # 3. Analysis of the schedule\n        schedule = requests\n        is_valid = True\n        \n        # Safety and Max Readers calculation\n        max_time = 0\n        if schedule:\n            max_time = max(r['s'] + r['d'] for r in schedule)\n\n        max_readers_count = 0\n        for t in range(max_time):\n            current_readers = [r for r in schedule if r['type'] == 'R' and r['s'] <= t < r['s'] + r['d']]\n            current_writers = [r for r in schedule if r['type'] == 'W' and r['s'] <= t < r['s'] + r['d']]\n            \n            num_r = len(current_readers)\n            num_w = len(current_writers)\n            \n            max_readers_count = max(max_readers_count, num_r)\n\n            if num_w > 1 or (num_w > 0 and num_r > 0):\n                is_valid = False\n                break\n        \n        # Fairness check\n        if is_valid:\n            for reader in schedule:\n                if reader['type'] == 'R':\n                    start_time = reader['s']\n                    for writer in schedule:\n                        if writer['type'] == 'W':\n                            # Writer was waiting if it arrived at or before reader start, and started after\n                            if writer['a'] <= start_time and writer['s'] > start_time:\n                                is_valid = False\n                                break\n                    if not is_valid:\n                        break\n        \n        # Makespan calculation\n        min_arrival_time = min(r['a'] for r in schedule) if schedule else 0\n        max_completion_time = max(r['s'] + r['d'] for r in schedule) if schedule else 0\n        makespan = max_completion_time - min_arrival_time\n\n        all_results.append([is_valid, max_readers_count, makespan])\n\n    # Final formatting\n    result_str = \",\".join([f\"[{v},{r},{m}]\" for v, r, m in all_results])\n    print(f\"[{result_str}]\")\n\n\nsolve()\n```", "id": "2422634"}, {"introduction": "在掌握了正确性和策略设计之后，并行计算的下一个前沿阵地是性能优化，这通常要求对硬件有深刻的理解。本练习将深入探讨 GPU 的微架构，特别是其片上共享内存（shared memory）系统。它聚焦于“存储体冲突”（bank conflict）这一现象，即当一个线程束（warp）中的多个线程同时访问同一个存储体时，访问会被串行化，从而严重影响性能 [@problem_id:2422580]。通过这个建模练习，你将能够量化存储体冲突对性能的影响，并评估一种标准的填充（padding）技术来缓解冲突，从而体会到“体系结构感知”编程对于释放并行硬件全部潜力的重要性。", "problem": "给定一个图形处理器（GPU）共享内存系统上的单指令多线程（SIMT）规约的正式模型。一个协作线程块由 $T$ 个线程组成，这些线程被划分为大小为 $w$ 的线程束。共享内存被组织成 $B$ 个存储体。每个共享内存元素占用 $e_b$ 字节，共享内存存储体字宽为 $b_w$ 字节，位于逻辑索引 $i \\in \\mathbb{Z}_{\\ge 0}$ 的元素的存储体索引定义为\n$$\n\\operatorname{bank}(i) = \\left\\lfloor \\frac{i \\cdot e_b}{b_w} \\right\\rfloor \\bmod B.\n$$\n假设基地址对齐，使得第一个元素的字节地址为 $0$。一个对 $M$ 个元素（其中 $M = \\min(N, T)$）的并行规约，通过标准的步长减半二叉树模式，在共享内存中进行原地更新，过程如下。对于每个步长 $s \\in \\{1, 2, 4, \\dots\\}$，当 $s < M$ 时，活动线程索引的集合为\n$$\nA_s = \\{\\, t \\in \\mathbb{Z} \\mid 0 \\le t < M,\\ t \\bmod (2s) = 0,\\ t + s < M \\,\\}.\n$$\n每个活动线程 $t \\in A_s$ 按顺序概念上执行三个共享内存操作：读取索引 $t$ 处的元素，读取索引 $t+s$ 处的元素，计算它们的和，并将结果写回索引 $t$。令 $f:\\mathbb{Z}_{\\ge 0} \\to \\mathbb{Z}_{\\ge 0}$ 为一个索引重映射，该重映射通过对共享内存进行可选的填充来减轻存储体冲突：\n- 不进行填充时，$f(i) = i$。\n- 使用避免冲突的填充时，$f(i) = i + \\lfloor \\frac{i}{B} \\rfloor$。\n\n对于给定的步长 $s$，定义三个子阶段，对应于一个线程束中的活动线程所访问的地址集：阶段1使用地址 $\\{ f(t) \\mid t \\in A_s \\cap W \\}$，阶段2使用地址 $\\{ f(t+s) \\mid t \\in A_s \\cap W \\}$，阶段3为了写入再次使用地址 $\\{ f(t) \\mid t \\in A_s \\cap W \\}$，其中 $W$ 是特定线程束中的线程索引集合。对于一个线程束 $j \\in \\{0,1,\\dots,\\lceil T/w \\rceil - 1\\}$，其线程索引集定义为\n$$\nW_j = \\{\\, jw, jw+1, \\dots, \\min(T-1, jw + w - 1) \\,\\}.\n$$\n在任何子阶段和线程束内，如果多个活动线程寻址的元素的存储体索引相同，这些访问将被串行化；该线程束的子阶段成本等于在该子阶段期间映射到同一存储体的活动线程的最大数量。如果一个线程束在某个子阶段没有活动线程，则其在该子阶段的成本为 $0$。步长 $s$ 的步长成本是所有线程束的三个子阶段成本的总和，而规约的总成本是所有满足 $s < M$ 的步长 $s$ 的步长成本的总和。\n\n您的任务是编写一个完整的、可运行的程序，为每个测试用例计算两个整数：\n- $C_{\\text{naive}}$：使用 $f(i) = i$ 时的总成本。\n- $C_{\\text{padded}}$：使用 $f(i) = i + \\lfloor \\frac{i}{B} \\rfloor$ 时的总成本。\n\n假设与要求：\n- 将 $N$、$T$、$w$、$B$、$e_b$ 和 $b_w$ 视为每个测试用例的给定整数。\n- 规约只考虑 $M = \\min(N, T)$ 个元素。\n- 不涉及角度和物理单位；所有输出都是纯整数。\n- 线程束的成本通过求和进行聚合；在成本模型中，不同线程束或子阶段之间没有重叠。\n\n测试套件（每个元组列出 $(N, T, w, B, e_b, b_w)$，所有数字均为十进制）：\n1. $(1024, 256, 32, 32, 4, 4)$\n2. $(1, 1, 32, 32, 4, 4)$\n3. $(1000, 256, 32, 32, 4, 4)$\n4. $(512, 256, 32, 16, 4, 4)$\n5. $(192, 64, 32, 32, 4, 4)$\n\n最终输出格式：\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。每个元素对应一个测试用例，并且本身是一个双元素列表 $[C_{\\text{naive}},C_{\\text{padded}}]$。输出中不得包含任何空白字符。例如，一个可能的输出结构是\n$[[$x_1$,$y_1$],[$x_2$,$y_2$],[$x_3$,$y_3$],[$x_4$,$y_4$],[$x_5$,$y_5$]]$\n其中每个 $x_i$ 和 $y_i$ 是您的程序为测试用例 $i$ 计算的整数。", "solution": "所提供的问题是一个定义明确的计算建模练习，要求在一个简化的图形处理器（GPU）共享内存架构上模拟一个并行规约算法。问题陈述在科学上基于并行计算的原理，逻辑上一致且完整。因此，该问题被认为是有效的，并将按照规定构建解决方案。\n\n任务是计算在两种不同的内存布局方案下，一次并行规约操作的总成本，该成本根据内存访问的串行化来定义。计算必须精确遵循所描述的正式模型。解决方案可以通过按部就班地模拟规约过程并按定义聚合成本来实现。\n\n总成本是规约中每个步骤成本的总和。对 $M$ 个元素的规约分阶段进行，由步长 $s$ 索引，该步长从 $s=1$ 开始，在每个阶段加倍，直到 $s < M$ 为止。因此，总成本 $C$ 为：\n$$\nC = \\sum_{s \\in \\{1, 2, 4, \\dots\\} \\text{ s.t. } s < M} \\text{StepCost}(s)\n$$\n其中 $M = \\min(N, T)$ 是参与规约的元素数量。\n\n对于步长 $s$ 的单步成本 $\\text{StepCost}(s)$，是线程块中所有线程束产生的所有成本的总和。一个包含 $T$ 个线程的线程块被划分为 $\\lceil T/w \\rceil$ 个大小为 $w$ 的线程束。\n$$\n\\text{StepCost}(s) = \\sum_{j=0}^{\\lceil T/w \\rceil - 1} \\text{WarpCost}(W_j, s)\n$$\n其中 $W_j$ 是线程束 $j$ 中的线程索引集合。\n\n在步长 $s$ 下，单个线程束 $W_j$ 的成本 $\\text{WarpCost}(W_j, s)$，是对应于活动线程执行的内存操作的三个不同子阶段的成本之和。步长 $s$ 的活动线程集合是 $A_s = \\{\\, t \\in \\mathbb{Z} \\mid 0 \\le t < M,\\ t \\bmod (2s) = 0,\\ t + s < M \\,\\}$。在线程束 $W_j$ 内，活动线程是 $A_{s,j} = A_s \\cap W_j$。\n这三个子阶段是：\n1.  对每个 $t \\in A_{s,j}$，从逻辑索引 $t$ 读取。\n2.  对每个 $t \\in A_{s,j}$，从逻辑索引 $t+s$ 读取。\n3.  对每个 $t \\in A_{s,j}$，向逻辑索引 $t$ 写入。\n\n一个线程束的子阶段成本是存储体冲突的程度，定义为该线程束中同时访问同一内存存储体的活动线程的最大数量。令 $\\mathcal{I}$ 为一个子阶段中访问的逻辑索引集合。成本为：\n$$\n\\text{SubPhaseCost}(\\mathcal{I}) = \\max_{k \\in \\{0, \\dots, B-1\\}} \\left| \\{\\, i \\in \\mathcal{I} \\mid \\operatorname{bank}(f(i)) = k \\,\\} \\right|\n$$\n如果 $\\mathcal{I}$ 为空，则成本为 $0$。逻辑索引 $k$ 的存储体索引由 $\\operatorname{bank}(k) = \\left\\lfloor \\frac{k \\cdot e_b}{b_w} \\right\\rfloor \\bmod B$ 给出。函数 $f(i)$ 将逻辑索引映射到内存索引，用于对填充进行建模。我们必须计算两种情况下的总成本：\n-   **朴素布局 (Naive layout)**：$C_{\\text{naive}}$，其中 $f(i) = i$。\n-   **填充布局 (Padded layout)**：$C_{\\text{padded}}$，其中 $f(i) = i + \\lfloor \\frac{i}{B} \\rfloor$。\n\n解决该问题的算法是此模型的直接实现。它包括一个遍历步长 $s$ 的主循环，一个遍历线程束 $j$ 的内循环，以及为每个线程束计算三个子阶段的成本。对于每个子阶段，我们识别出线程束中活动线程访问的逻辑索引集，应用适当的索引重映射函数 $f$，为每个得到的内存索引计算存储体索引，并找出任何单个存储体索引的最大出现频率。将所有子阶段、线程束和步长的这些成本相加，即可得出最终的总成本。这个过程对 $C_{\\text{naive}}$ 执行一次，对 $C_{\\text{padded}}$ 执行一次。对于提供的所有测试用例，$e_b = b_w = 4$，这将存储体索引的计算简化为 $\\operatorname{bank}(k) = k \\bmod B$。\n\n该实现将包含一个主函数，用于为给定的一组参数和指定的填充方案计算总成本。对于每个测试用例，将分别针对朴素方案和填充方案调用此函数。一个辅助函数将通过确定给定逻辑索引集的存储体索引并计算最大冲突数来计算子阶段成本。", "answer": "```python\nimport math\nfrom collections import Counter\n\ndef solve():\n    \"\"\"\n    Solves the GPU shared memory reduction cost problem for a suite of test cases.\n    \"\"\"\n\n    test_cases = [\n        (1024, 256, 32, 32, 4, 4),\n        (1, 1, 32, 32, 4, 4),\n        (1000, 256, 32, 32, 4, 4),\n        (512, 256, 32, 16, 4, 4),\n        (192, 64, 32, 32, 4, 4),\n    ]\n\n    results = []\n    for case in test_cases:\n        N, T, w, B, eb, bw = case\n        c_naive = compute_total_cost(N, T, w, B, eb, bw, 'naive')\n        c_padded = compute_total_cost(N, T, w, B, eb, bw, 'padded')\n        results.append([c_naive, c_padded])\n    \n    case_strings = [f\"[{res[0]},{res[1]}]\" for res in results]\n    print(f\"[{','.join(case_strings)}]\")\n\ndef compute_subphase_cost(indices, padding_type, B, eb, bw):\n    \"\"\"\n    Computes the cost of a single sub-phase for a warp, which is the maximum\n    number of threads accessing the same memory bank.\n    \"\"\"\n    if not indices:\n        return 0\n\n    bank_indices = []\n    for i in indices:\n        mapped_i = 0\n        if padding_type == 'naive':\n            mapped_i = i\n        elif padding_type == 'padded':\n            mapped_i = i + (i // B)\n\n        # Bank index is defined by floor((i * e_b) / b_w) mod B.\n        bank_idx = (mapped_i * eb // bw) % B\n        bank_indices.append(bank_idx)\n\n    if not bank_indices:\n        return 0\n    \n    # The cost is the max number of accesses to any single bank.\n    counts = Counter(bank_indices)\n    return max(counts.values())\n\ndef compute_total_cost(N, T, w, B, eb, bw, padding_type):\n    \"\"\"\n    Computes the total cost of a parallel reduction based on the given model.\n    \"\"\"\n    M = min(N, T)\n    if M < 2:\n        return 0\n        \n    total_cost = 0\n    s = 1\n    num_warps = (T + w - 1) // w\n\n    while s < M:\n        step_cost = 0\n        for j in range(num_warps):\n            warp_start_tid = j * w\n            warp_end_tid = min(T, (j + 1) * w)\n\n            active_threads_in_warp = []\n            for t in range(warp_start_tid, warp_end_tid):\n                # An active thread t must satisfy:\n                # 1. Be part of the reduction: t < M\n                # 2. Be the thread responsible for the sum: t % (2s) == 0\n                # 3. Have a partner to sum with: t + s < M\n                if t < M and t % (2 * s) == 0 and t + s < M:\n                    active_threads_in_warp.append(t)\n            \n            if not active_threads_in_warp:\n                continue\n\n            # Phase 1: Read from logical index t\n            cost1 = compute_subphase_cost(active_threads_in_warp, padding_type, B, eb, bw)\n            \n            # Phase 2: Read from logical index t+s\n            indices_phase2 = [t + s for t in active_threads_in_warp]\n            cost2 = compute_subphase_cost(indices_phase2, padding_type, B, eb, bw)\n\n            # Phase 3: Write to logical index t (same addresses as phase 1)\n            cost3 = cost1\n\n            step_cost += (cost1 + cost2 + cost3)\n\n        total_cost += step_cost\n        s *= 2\n        \n    return total_cost\n\nsolve()\n```", "id": "2422580"}]}