{"hands_on_practices": [{"introduction": "我们从一个标准遗传算法在视觉直观任务中的实际应用开始：图像优化。这项练习 [@problem_id:2396561] 挑战你进化一个二值图像以最大化其清晰度，这个问题类似于低分辨率显示屏的字体微调。你将实现遗传算法的核心组件——选择、交叉和变异——以在巨大的组合搜索空间中导航，并在有限的计算预算下找到高质量的解。", "problem": "您将处理一个离散全局搜索问题，该问题将低分辨率字形易读性形式化为一个组合优化任务。对于给定的整数网格尺寸 $N \\in \\mathbb{N}$，定义一个二值图像为矩阵 $X \\in \\{0,1\\}^{N \\times N}$，其中条目 $X_{r,c}=1$ 表示在第 $r$ 行和第 $c$ 列的像素被点亮，否则 $X_{r,c}=0$。令 $T \\in \\{0,1\\}^{N \\times N}$ 为一个具有相同形状的固定目标二值图像。对于一个候选图像 $X$，定义以下术语：\n- 匹配项 $m(X,T)$:\n$$\nm(X,T) \\;=\\; 1 \\;-\\; \\frac{1}{N^2} \\sum_{r=0}^{N-1}\\sum_{c=0}^{N-1} \\left| X_{r,c} - T_{r,c} \\right|.\n$$\n- 连通性项 $c(X)$: 令 $S(X)=\\{(r,c)\\,:\\,X_{r,c}=1\\}$ 并将 $(r,c)$ 的 $4$-邻域定义为 $\\{(r-1,c),(r+1,c),(r,c-1),(r,c+1)\\}$（当索引在边界内时）。如果存在一个 $4$-邻居 $(r',c')$ 满足 $X_{r',c'}=1$，则令 $h_{r,c}(X)=1$，否则 $h_{r,c}(X)=0$。定义\n$$\nc(X) \\;=\\; \\begin{cases}\n\\displaystyle \\frac{1}{|S(X)|}\\sum_{(r,c)\\in S(X)} h_{r,c}(X), & \\text{if } |S(X)|>0,\\\\\n0, & \\text{if } |S(X)|=0.\n\\end{cases}\n$$\n- 孤立项 $i(X)$: 令 $(r,c)$ 的 $8$-邻域为所有满足 $\\max(|r'-r|,|c'-c|)=1$ 的 $(r',c')$（当索引在边界内时）。如果存在一个 $8$-邻居 $(r',c')$ 满足 $X_{r',c'}=1$，则令 $g_{r,c}(X)=1$，否则 $g_{r,c}(X)=0$。定义孤立的点亮像素的比例\n$$\ni(X) \\;=\\; \\begin{cases}\n\\displaystyle \\frac{1}{|S(X)|}\\sum_{(r,c)\\in S(X)} \\big(1 - g_{r,c}(X)\\big), & \\text{if } |S(X)|>0,\\\\\n0, & \\text{if } |S(X)|=0.\n\\end{cases}\n$$\n- 面积偏差项 $a(X,T)$:\n$$\na(X,T) \\;=\\; \\frac{\\big|\\;|S(X)| - |S(T)|\\;\\big|}{N^2}.\n$$\n给定非负权重 $w_m,w_c,w_i,w_a \\in \\mathbb{R}_{\\ge 0}$，需要最大化的目标函数为\n$$\nF(X;T,w_m,w_c,w_i,w_a) \\;=\\; w_m\\, m(X,T) \\;+\\; w_c\\, c(X) \\;-\\; w_i\\, i(X) \\;-\\; w_a\\, a(X,T).\n$$\n\n您的程序必须在严格的评估预算 $B \\in \\mathbb{N}$ 的限制下，为每个指定的测试用例搜索域 $\\{0,1\\}^{N \\times N}$，并报告在该预算内找到的最大目标值。一次评估是指对一个特定的 $X$ 计算 $F(X;T,w_m,w_c,w_i,w_a)$ 的值。您必须将报告的每个值四舍五入到 $6$ 位小数。\n\n测试套件规范。在所有情况下，索引都是从零开始的，行 $r \\in \\{0,1,\\dots,N-1\\}$，列 $c \\in \\{0,1,\\dots,N-1\\}$。每个目标 $T$ 被明确定义为点亮像素的集合 $S(T) \\subset \\{0,\\dots,N-1\\} \\times \\{0,\\dots,N-1\\}$。\n\n- 案例 1 (常规路径): $N=8$，权重 $(w_m,w_c,w_i,w_a)=(0.6,\\,0.3,\\,0.4,\\,0.2)$，预算 $B=6000$。目标 $T$ 编码一个块状字母，类似于一个带有垂直主干和三个水平横条的字母 $E$：\n  1. 垂直主干：所有满足 $r \\in \\{1,2,3,4,5,6\\}$ 且 $c=1$ 的 $(r,c)$。\n  2. 顶部横条：所有满足 $r=1$ 且 $c \\in \\{1,2,3,4,5\\}$ 的 $(r,c)$。\n  3. 中间横条：所有满足 $r=3$ 且 $c \\in \\{1,2,3,4\\}$ 的 $(r,c)$。\n  4. 底部横条：所有满足 $r=6$ 且 $c \\in \\{1,2,3,4,5\\}$ 的 $(r,c)$。\n\n- 案例 2 (边界尺寸和更强的正则化): $N=5$，权重 $(w_m,w_c,w_i,w_a)=(0.5,\\,0.2,\\,0.7,\\,0.6)$，预算 $B=2000$。目标 $T$ 是一个最小化的 $E$：\n  1. 垂直主干：所有满足 $r \\in \\{1,2,3\\}$ 且 $c=1$ 的 $(r,c)$。\n  2. 顶部横条：所有满足 $r=1$ 且 $c \\in \\{1,2,3\\}$ 的 $(r,c)$。\n  3. 中间横条：所有满足 $r=2$ 且 $c \\in \\{1,2\\}$ 的 $(r,c)$。\n  4. 底部横条：所有满足 $r=3$ 且 $c \\in \\{1,2,3\\}$ 的 $(r,c)$。\n\n- 案例 3 (类对角线结构和连通性强调): $N=8$，权重 $(w_m,w_c,w_i,w_a)=(0.5,\\,0.6,\\,0.3,\\,0.2)$，预算 $B=8000$。目标 $T$ 编码一个块状字母，类似于一个带有两条垂直腿、一个顶部横条和一个横杠的字母 $A$：\n  1. 左腿：所有满足 $r \\in \\{2,3,4,5,6\\}$ 且 $c=1$ 的 $(r,c)$。\n  2. 右腿：所有满足 $r \\in \\{2,3,4,5,6\\}$ 且 $c=6$ 的 $(r,c)$。\n  3. 顶部横条：所有满足 $r=1$ 且 $c \\in \\{2,3,4,5\\}$ 的 $(r,c)$。\n  4. 横杠：所有满足 $r=4$ 且 $c \\in \\{2,3,4,5\\}$ 的 $(r,c)$。\n\n最终输出格式。您的程序应生成单行输出，其中包含案例 1、2 和 3 的三个四舍五入后的目标值，按顺序排列，形式为用方括号括起来的逗号分隔列表。例如，它必须以 [$v_1$,$v_2$,$v_3$] 的形式精确打印一行，其中每个 $v_k$ 是一个使用标准四舍五入规则保留 $6$ 位小数的实数。", "solution": "所提出的问题是一个离散全局搜索任务，它要求在一个高维二元空间上最大化一个复杂的目标函数。对于一个尺寸为 $N \\times N$ 的二值图像，其搜索空间为 $\\{0,1\\}^{N \\times N}$，包含 $2^{N^2}$ 种可能的配置。对于给定的 $N=5$ 和 $N=8$ 值，搜索空间分别有 $2^{25} \\approx 3.3 \\times 10^7$ 和 $2^{64} \\approx 1.8 \\times 10^{19}$ 个成员。穷举搜索在计算上是不可行的。该问题施加了严格的评估预算，这将其框定为一个黑盒优化任务，其目标是在有限的函数评估次数内找到尽可能好的解。这种结构使得使用元启发式搜索算法成为必要。\n\n遗传算法 (GA) 是解决此类问题的一种非常合适的方法论。遗传算法的灵感来源于自然选择过程，对于探索大型、复杂且知之甚少的搜索空间非常有效。目标函数 $F(X;T,w_m,w_c,w_i,w_a)$ 是衡量相似性、连通性和其他结构属性的几个分量的加权和，这很可能导致一个具有许多局部最优解的崎岖适应度景观。由于其基于种群的方法和诸如交叉、变异等随机算子，遗传算法能有效地避免陷入此类局部最优解。\n\n所实现的解决方案是一个标准的遗传算法，并根据该问题的具体情况进行了定制。\n\n**1. 表示方法与种群**\n种群中的一个个体代表一个候选解，它是一个 $N \\times N$ 的二值矩阵 $X$。种群由固定数量的此类个体组成。为保证可复现性，伪随机数生成器使用一个常量值作为种子。初始种群由目标图像 $T$ 本身、T 的几个变异版本以及大部分随机生成的图像构成，以确保在利用已知良好区域和探索更广阔搜索空间之间取得平衡。\n\n**2. 适应度评估**\n个体 $X$ 的适应度由目标函数 $F(X;T,w_m,w_c,w_i,w_a)$ 决定。该函数的各组成部分计算如下：\n- 匹配项 $m(X,T) = 1 - \\frac{1}{N^2} \\sum_{r,c} |X_{r,c} - T_{r,c}|$ 是候选图像与目标图像之间的归一化一致性。\n- 面积偏差项 $a(X,T) = \\frac{|\\sum X_{r,c} - \\sum T_{r,c}|}{N^2}$ 惩罚点亮像素数量上的差异。\n- 连通性项 $c(X)$ 和孤立项 $i(X)$ 需要分析像素邻域。这些项通过二维卷积进行高效计算。每个像素的点亮邻居数量可以利用 `scipy.signal.convolve2d` 及适当的卷积核，在单次操作中计算整个网格。对于使用 $4$-邻域的 $c(X)$，卷积核为 $\\begin{pmatrix} 0 & 1 & 0 \\\\ 1 & 0 & 1 \\\\ 0 & 1 & 0 \\end{pmatrix}$。对于基于 $8$-邻域的 $i(X)$，卷积核为 $\\begin{pmatrix} 1 & 1 & 1 \\\\ 1 & 0 & 1 \\\\ 1 & 1 & 1 \\end{pmatrix}$。这种向量化方法比遍历像素的效率要高得多。一个 `Evaluator` 类封装了适应度计算，并严格执行评估预算 $B$。\n\n**3. 选择**\n采用锦标赛选择法来为下一代选择亲代。在一个 $k$-路锦标赛中，从当前种群中随机选择 $k$ 个个体，其中适应度最高的个体被选为亲代。此方法在选择压力和种群多样性之间提供了良好的平衡。\n\n**4. 遗传算子**\n- **交叉**：采用均匀交叉。对于每个像素位置，通过一个随机选择来决定两个亲代中的哪一个将其像素值贡献给子代。这个算子能有效地组合来自两个亲代的特征。\n- **变异**：在交叉后对子代应用位翻转变异。每个像素值（位）都有一个小的、独立的概率被翻转。变异率设置为 $1/N^2$，这平均导致每个个体发生一次变异，从而引入新的遗传物质并防止过早收敛。\n\n**5. 世代循环与精英主义**\n遗传算法按代进行。在每个循环中，从旧种群中创建一个新种群。实施了精英主义，即保证当前代中少数表现最佳的个体会存活下来，从而保留高质量的解。新种群的其余部分由通过选择、交叉和变异产生的子代填充。一旦评估预算 $B$ 用尽，算法即终止，并将整个运行期间找到的最高适应度值作为结果报告。\n\n这种系统性的、基于原则的设计确保了一个稳健的搜索过程，能够在给定的计算约束下，驾驭复杂的适应度景观，为所述的字形易读性问题找到高质量的解。", "answer": "```python\nimport numpy as np\nfrom scipy.signal import convolve2d\n\n# Static seed for reproducibility across runs\nRNG = np.random.default_rng(42)\n\nclass FitnessEvaluator:\n    \"\"\"Calculates the fitness of a candidate image and manages the evaluation budget.\"\"\"\n    def __init__(self, target_matrix, weights, budget):\n        self.T = target_matrix\n        self.N = self.T.shape[0]\n        self.w_m, self.w_c, self.w_i, self.w_a = weights\n        \n        self.target_pixel_count = np.sum(self.T)\n        self.N_squared = self.N * self.N\n        \n        self.kernel_4_conn = np.array([[0, 1, 0], [1, 0, 1], [0, 1, 0]], dtype=np.uint8)\n        self.kernel_8_conn = np.array([[1, 1, 1], [1, 0, 1], [1, 1, 1]], dtype=np.uint8)\n        \n        self.eval_budget = budget\n        self.eval_count = 0\n        self.max_fitness_found = -np.inf\n\n    def calculate_fitness(self, X):\n        \"\"\"Computes the objective function F for a given image X.\"\"\"\n        if self.eval_count >= self.eval_budget:\n            return None\n\n        # Match term m(X, T)\n        match_term = 1.0 - np.sum(np.abs(X - self.T)) / self.N_squared\n        \n        pixel_count = np.sum(X)\n        \n        if pixel_count == 0:\n            conn_term = 0.0\n            iso_term = 0.0\n        else:\n            # Connectivity term c(X) using 4-neighborhood\n            neighbors_4 = convolve2d(X, self.kernel_4_conn, mode='same', boundary='fill', fillvalue=0)\n            connected_pixels = (neighbors_4 > 0) * X\n            conn_term = np.sum(connected_pixels) / pixel_count\n            \n            # Isolation term i(X) using 8-neighborhood\n            neighbors_8 = convolve2d(X, self.kernel_8_conn, mode='same', boundary='fill', fillvalue=0)\n            isolated_pixels = (neighbors_8 == 0) * X\n            iso_term = np.sum(isolated_pixels) / pixel_count\n            \n        # Area-deviation term a(X, T)\n        area_dev_term = np.abs(pixel_count - self.target_pixel_count) / self.N_squared\n        \n        fitness = (self.w_m * match_term + \n                   self.w_c * conn_term - \n                   self.w_i * iso_term - \n                   self.w_a * area_dev_term)\n        \n        self.eval_count += 1\n        if fitness > self.max_fitness_found:\n            self.max_fitness_found = fitness\n            \n        return fitness\n\ndef tournament_selection_idx(fitnesses, k):\n    \"\"\"Selects an individual's index using a tournament.\"\"\"\n    pop_size = len(fitnesses)\n    contender_indices = RNG.choice(pop_size, k, replace=False)\n    \n    best_contender_idx = -1\n    best_fitness = -np.inf\n    \n    for idx in contender_indices:\n        if fitnesses[idx] > best_fitness:\n            best_fitness = fitnesses[idx]\n            best_contender_idx = idx\n            \n    return best_contender_idx\n\ndef uniform_crossover(p1, p2):\n    \"\"\"Performs uniform crossover on two parents.\"\"\"\n    mask = RNG.integers(0, 2, size=p1.shape, dtype=np.uint8)\n    child1 = p1 * mask + p2 * (1 - mask)\n    child2 = p2 * mask + p1 * (1 - mask)\n    return child1, child2\n\ndef mutate(individual, mutation_rate):\n    \"\"\"Applies bit-flip mutation to an individual.\"\"\"\n    mutation_mask = RNG.random(individual.shape) < mutation_rate\n    individual[mutation_mask] = 1 - individual[mutation_mask]\n\ndef run_genetic_algorithm(N, target_pixels, weights, budget):\n    \"\"\"Main GA loop for a single test case.\"\"\"\n    \n    target_matrix = np.zeros((N, N), dtype=np.uint8)\n    for r, c in target_pixels:\n        target_matrix[r, c] = 1\n        \n    evaluator = FitnessEvaluator(target_matrix, weights, budget)\n    \n    # GA Parameters\n    pop_size = 100\n    elite_size = 2\n    tournament_k = 3\n    mutation_rate = 1.0 / (N * N)\n    crossover_prob = 0.9\n\n    # Initialization\n    population = []\n    fitnesses = []\n    \n    # Seed population with target, its mutations, and random individuals\n    initial_seeds = [(target_matrix.copy(), 0), (target_matrix.copy(), int(0.05 * N*N)), (target_matrix.copy(), int(0.1 * N*N))]\n    for ind, num_flips in initial_seeds:\n        if num_flips > 0:\n            indices_to_flip = RNG.choice(N * N, num_flips, replace=False)\n            flat_ind = ind.flatten()\n            flat_ind[indices_to_flip] = 1 - flat_ind[indices_to_flip]\n            ind = flat_ind.reshape((N, N))\n        \n        fit = evaluator.calculate_fitness(ind)\n        if fit is not None:\n            population.append(ind)\n            fitnesses.append(fit)\n\n    while len(population) < pop_size:\n        individual = RNG.integers(0, 2, size=(N, N), dtype=np.uint8)\n        fit = evaluator.calculate_fitness(individual)\n        if fit is None: break\n        population.append(individual)\n        fitnesses.append(fit)\n\n    if not population: return -np.inf\n\n    # Main generational loop\n    while evaluator.eval_count < evaluator.eval_budget:\n        # Sort population by fitness for elitism\n        sorted_indices = np.argsort(fitnesses)\n        new_population = [population[i] for i in sorted_indices[-elite_size:]]\n        new_fitnesses = [fitnesses[i] for i in sorted_indices[-elite_size:]]\n\n        # Generate offspring\n        while len(new_population) < pop_size:\n            parent1_idx = tournament_selection_idx(fitnesses, tournament_k)\n            parent2_idx = tournament_selection_idx(fitnesses, tournament_k)\n            parent1 = population[parent1_idx]\n            parent2 = population[parent2_idx]\n\n            if RNG.random() < crossover_prob:\n                child1, child2 = uniform_crossover(parent1, parent2)\n            else:\n                child1, child2 = parent1.copy(), parent2.copy()\n            \n            mutate(child1, mutation_rate)\n            mutate(child2, mutation_rate)\n\n            fit1 = evaluator.calculate_fitness(child1)\n            if fit1 is None: break\n            new_population.append(child1)\n            new_fitnesses.append(fit1)\n            \n            if len(new_population) < pop_size:\n                fit2 = evaluator.calculate_fitness(child2)\n                if fit2 is None: break\n                new_population.append(child2)\n                new_fitnesses.append(fit2)\n            \n        if evaluator.eval_count >= evaluator.eval_budget: break\n\n        population = new_population\n        fitnesses = new_fitnesses\n\n    return evaluator.max_fitness_found\n\ndef solve():\n    test_cases = [\n        {\n            \"N\": 8, \"weights\": (0.6, 0.3, 0.4, 0.2), \"budget\": 6000,\n            \"target_pixels\": set(\n                [(r, 1) for r in range(1, 7)] + [(1, c) for c in range(1, 6)] +\n                [(3, c) for c in range(1, 5)] + [(6, c) for c in range(1, 6)]\n            )\n        },\n        {\n            \"N\": 5, \"weights\": (0.5, 0.2, 0.7, 0.6), \"budget\": 2000,\n            \"target_pixels\": set(\n                [(r, 1) for r in range(1, 4)] + [(1, c) for c in range(1, 4)] +\n                [(2, c) for c in range(1, 3)] + [(3, c) for c in range(1, 4)]\n            )\n        },\n        {\n            \"N\": 8, \"weights\": (0.5, 0.6, 0.3, 0.2), \"budget\": 8000,\n            \"target_pixels\": set(\n                [(r, 1) for r in range(2, 7)] + [(r, 6) for r in range(2, 7)] +\n                [(1, c) for c in range(2, 6)] + [(4, c) for c in range(2, 6)]\n            )\n        }\n    ]\n    \n    results = []\n    for case in test_cases:\n        max_val = run_genetic_algorithm(\n            case[\"N\"], case[\"target_pixels\"], case[\"weights\"], case[\"budget\"]\n        )\n        results.append(round(max_val, 6))\n    \n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```", "id": "2396561"}, {"introduction": "掌握了处理离散问题的遗传算法后，我们现在转向在工程设计中十分常见的连续域。这项实践 [@problem_id:2396545] 要求使用实数编码的遗传算法来优化超材料单元的参数，目的是发现一种具有负热膨胀系数的几何结构。你将学习如何为实数值染色体调整遗传算法算子，并使用惩罚函数来处理设计约束。", "problem": "您的任务是实现一个实数编码遗传算法（GA），对一个超材料晶胞等效热膨胀响应的简化无量纲代理模型进行全局搜索。目标是最小化一个近似等效热膨胀系数的标量目标。所有角度必须以弧度为单位处理。最终答案必须是无量纲实数。\n\n本任务所需的基础知识包括：(i) 优化的定义，即在给定域上寻找使标量函数最小化的参数；(ii) 基于种群的随机搜索（遗传算法）的定义，其通过选择、交叉和变异进行繁殖；(iii) 用于约束优化的罚函数法。\n\n决策变量与定义域：\n- 设染色体为一个向量 $\\mathbf{x} = (t, s, \\phi)$，其中 $t$ 是厚度比，$s$ 是铰链柔度比，$\\phi$ 是以弧度为单位的凹角。这些都是无量纲的。\n- 标称变量定义域为：\n  - $t \\in [0.05, 0.95]$,\n  - $s \\in [0.10, 0.90]$,\n  - $\\phi \\in [0.10, 1.30]$ 弧度。\n- 一个派生的相对密度代理值为 $r_d(t,s) = 0.5\\,t + 0.5\\,(1 - s)$，它必须满足 $r_d \\in [0.20, 0.80]$。\n\n目标函数（待最小化）：\n定义代理目标函数 $f(t,s,\\phi)$ 为\n$$\nf(t,s,\\phi) = c_0 + c_1 t + c_2 s + c_3 \\sin(\\phi) + c_4 t s - c_5 s \\sin(\\phi) - c_6 (1 - t) \\sin(\\phi) + \\Pi_{\\text{dens}}(t,s) + \\Pi_{\\text{box}}(t,s,\\phi),\n$$\n其中常数为\n$$\nc_0=0.2,\\quad c_1=0.1,\\quad c_2=0.15,\\quad c_3=0.3,\\quad c_4=0.05,\\quad c_5=0.6,\\quad c_6=0.5.\n$$\n惩罚项用于施加约束，\n$$\n\\Pi_{\\text{dens}}(t,s) = M \\left(\\max\\{0, r_d(t,s) - 0.80\\}\\right)^2 + M \\left(\\max\\{0, 0.20 - r_d(t,s)\\}\\right)^2,\n$$\n$$\n\\Pi_{\\text{box}}(t,s,\\phi) = B\\left(\\max\\{0, t - \\overline{t}\\}\\right)^2 + B\\left(\\max\\{0, \\underline{t} - t\\}\\right)^2 + B\\left(\\max\\{0, s - \\overline{s}\\}\\right)^2 + B\\left(\\max\\{0, \\underline{s} - s\\}\\right)^2 + B\\left(\\max\\{0, \\phi - \\overline{\\phi}\\}\\right)^2 + B\\left(\\max\\{0, \\underline{\\phi} - \\phi\\}\\right)^2,\n$$\n其中 $M=10$，$B=100$，且 $(\\underline{t},\\overline{t})=(0.05,0.95)$，$(\\underline{s},\\overline{s})=(0.10,0.90)$，$(\\underline{\\phi},\\overline{\\phi})=(0.10,1.30)$，除非测试用例为 $\\phi$ 指定了不同的边界。\n\n遗传算法设计要求：\n- 染色体编码：实值向量 $\\mathbf{x}\\in\\mathbb{R}^3$。\n- 初始化：在每个决策变量的盒式边界内进行均匀采样。\n- 适应度：与 $f(t,s,\\phi)$ 相同；目标为最小化。\n- 选择：锦标赛选择，锦标赛规模 $k=3$。\n- 交叉：算术交叉，其中两个父代 $\\mathbf{x}^{(1)}$ 和 $\\mathbf{x}^{(2)}$ 生成两个子代\n  $\\mathbf{y}^{(1)} = \\omega \\mathbf{x}^{(1)} + (1-\\omega)\\mathbf{x}^{(2)}$，$\\mathbf{y}^{(2)} = \\omega \\mathbf{x}^{(2)} + (1-\\omega)\\mathbf{x}^{(1)}$，\n  其中 $\\omega \\sim \\text{Uniform}[0,1]$，以概率 $p_c$ 应用。\n- 变异：每个基因以概率 $p_m$ 进行独立高斯变异；对于基因 $j$，$y_j \\leftarrow y_j + \\mathcal{N}\\!\\left(0, \\sigma^2 (\\overline{b}_j - \\underline{b}_j)^2\\right)$，其中 $[\\underline{b}_j,\\overline{b}_j]$ 是基因 $j$ 的边界，$\\sigma$ 是一个标量缩放因子。变异后，将值裁剪至盒式边界内。\n- 精英主义：将最优的 $E=\\max\\{1,\\lfloor 0.05\\,N \\rfloor\\}$ 个个体不加改变地复制到下一代，其中 $N$ 是种群大小。\n- 终止条件：达到固定代数 $G$。\n- 随机性：所有随机数生成都必须按指定设置种子，以确保确定性输出。\n\n角度单位：\n- 所有角度 $\\phi$ 均以弧度为单位。\n\n测试套件：\n在以下三个测试用例上实现并运行遗传算法。每个测试用例都由其边界、算法超参数和随机种子完全指定。\n\n- 测试用例 A（通用“理想路径”）：\n  - 边界：$t \\in [0.05,0.95]$，$s \\in [0.10,0.90]$，$\\phi \\in [0.10,1.30]$ 弧度。\n  - 种群大小 $N=60$，代数 $G=120$，交叉概率 $p_c=0.9$，每基因变异概率 $p_m=0.2$，变异尺度 $\\sigma=0.05$。\n  - 随机种子：$12345$。\n\n- 测试用例 B（角度处于边界；小凹角）：\n  - 边界：$t \\in [0.05,0.95]$，$s \\in [0.10,0.90]$，$\\phi \\in [0.10,0.25]$ 弧度。\n  - 种群大小 $N=80$，代数 $G=180$，交叉概率 $p_c=0.9$，每基因变异概率 $p_m=0.2$，变异尺度 $\\sigma=0.04$。\n  - 随机种子：$2023$。\n\n- 测试用例 C（小种群但大角度的边缘情况）：\n  - 边界：$t \\in [0.05,0.95]$，$s \\in [0.10,0.90]$，$\\phi \\in [1.10,1.30]$ 弧度。\n  - 种群大小 $N=25$，代数 $G=300$，交叉概率 $p_c=0.8$，每基因变异概率 $p_m=0.3$，变异尺度 $\\sigma=0.06$。\n  - 随机种子：$314159$。\n\n要求输出：\n- 对于每个测试用例，计算遗传算法在终止时找到的最优（最低）目标值 $f_{\\min}$。\n- 您的程序应生成单行输出，其中包含三个结果，以逗号分隔的列表形式，并用方括号括起来，每个值按A、B、C的顺序四舍五入到 $6$ 位小数。例如，确切格式必须为 [$x_1,x_2,x_3$] 的形式，其中 $x_1$、$x_2$ 和 $x_3$ 是四舍五入到 $6$ 位小数的实数。", "solution": "该问题陈述已经过严格验证，并被确定为有效。它具有科学依据、问题适定且客观。它为实现一个实数编码遗传算法以解决一个明确定义的优化问题，提供了一个完整、自洽且计算上可行的规范。所有参数、约束和算法组件都得到了精确描述，从而可以得到一个确定性且可验证的解。\n\n任务是找到代理目标函数 $f(t,s,\\phi)$ 的最小值，该函数是三个无量纲决策变量的函数：厚度比 $t$、铰链柔度比 $s$ 和凹角 $\\phi$。搜索使用遗传算法（GA）进行，这是一种受自然选择原理启发的随机优化启发式算法。通过精确地按照规范实现该算法来构建解决方案。\n\n首先，我们定义要最小化的目标函数。它由一个基础代理模型和用于施加约束的惩罚项组成。完整的函数是：\n$$\nf(t,s,\\phi) = c_0 + c_1 t + c_2 s + c_3 \\sin(\\phi) + c_4 t s - c_5 s \\sin(\\phi) - c_6 (1 - t) \\sin(\\phi) + \\Pi_{\\text{dens}}(t,s) + \\Pi_{\\text{box}}(t,s,\\phi)\n$$\n常数给定为 $c_0=0.2$, $c_1=0.1$, $c_2=0.15$, $c_3=0.3$, $c_4=0.05$, $c_5=0.6$, 和 $c_6=0.5$。\n\n约束使用外部惩罚法处理。对派生量——相对密度代理值 $r_d(t,s) = 0.5\\,t + 0.5\\,(1 - s)$ 的一个约束，要求 $r_d \\in [0.20, 0.80]$。这由惩罚项 $\\Pi_{\\text{dens}}(t,s)$ 施加：\n$$\n\\Pi_{\\text{dens}}(t,s) = M \\left(\\max\\{0, r_d(t,s) - 0.80\\}\\right)^2 + M \\left(\\max\\{0, 0.20 - r_d(t,s)\\}\\right)^2\n$$\n惩罚参数 $M=10$。\n对决策变量的盒式约束，$t \\in [\\underline{t}, \\overline{t}]$, $s \\in [\\underline{s}, \\overline{s}]$ 和 $\\phi \\in [\\underline{\\phi}, \\overline{\\phi}]$，由惩罚项 $\\Pi_{\\text{box}}(t,s,\\phi)$ 进行形式化处理：\n$$\n\\Pi_{\\text{box}}(t,s,\\phi) = B\\sum_{j \\in \\{t,s,\\phi\\}} \\left( \\left(\\max\\{0, x_j - \\overline{x}_j\\}\\right)^2 + \\left(\\max\\{0, \\underline{x}_j - x_j\\}\\right)^2 \\right)\n$$\n惩罚参数 $B=100$。尽管指定的GA初始化和变异裁剪机制确保所有被评估的个体都位于这些盒式边界内，使得此项功能上为零，但根据问题陈述，为了形式上的完整性，它仍被包含在目标函数的定义中。\n\n遗传算法被实现为一个具有以下组件的代际模型：\n1.  **染色体与种群：** 种群中的每个个体（染色体）由一个实值向量 $\\mathbf{x} = (t, s, \\phi) \\in \\mathbb{R}^3$ 表示。一个种群由 $N$ 个这样的个体组成。初始种群是通过为每个个体的每个变量在其指定域内进行均匀随机采样来生成的。\n2.  **适应度评估：** 个体的适应度就是其目标函数值 $f(\\mathbf{x})$。算法旨在最小化此值。\n3.  **进化周期：** 算法进行固定的 $G$ 代。在每一代中，从旧种群创建一个新种群。\n4.  **精英主义：** 为确保保留迄今为止找到的最优解，一组精英个体被直接带到下一代。精英个体的数量为 $E=\\max\\{1,\\lfloor 0.05\\,N \\rfloor\\}$。\n5.  **繁殖：** 下一代的剩余 $N-E$ 个个体通过选择、交叉和变异产生。\n    -   **选择：** 使用锦标赛选择从当前种群中选择父代。对于所需的每个父代，都会进行一次规模为 $k=3$ 的锦标赛：从种群中随机选择 $3$ 个个体，适应度最优（最低）的个体被宣布为获胜者，并成为父代。\n    -   **交叉：** 被选中的父代进行配对。以交叉概率 $p_c$，一对父代 $\\mathbf{x}^{(1)}$ 和 $\\mathbf{x}^{(2)}$ 通过算术交叉产生两个子代 $\\mathbf{y}^{(1)}$ 和 $\\mathbf{y}^{(2)}$：\n        $$\n        \\mathbf{y}^{(1)} = \\omega \\mathbf{x}^{(1)} + (1-\\omega)\\mathbf{x}^{(2)}\n        $$\n        $$\n        \\mathbf{y}^{(2)} = \\omega \\mathbf{x}^{(2)} + (1-\\omega)\\mathbf{x}^{(1)}\n        $$\n        其中 $\\omega$ 是从 $\\text{Uniform}[0,1]$ 中抽取的随机变量。如果不发生交叉，子代是父代的直接副本。\n    -   **变异：** 每个新子代的每个基因（分量）都以概率 $p_m$ 进行变异。如果一个基因 $y_j$ 被选中进行变异，其值会通过添加高斯噪声来改变：\n        $$\n        y_j \\leftarrow y_j + \\mathcal{N}\\!\\left(0, \\sigma^2 (\\overline{b}_j - \\underline{b}_j)^2\\right)\n        $$\n        其中 $[\\underline{b}_j, \\overline{b}_j]$ 是基因 $j$ 的有效范围，$\\sigma$ 是给定的变异尺度因子。变异后，基因的值被裁剪以确保其保持在边界 $[\\underline{b}_j, \\overline{b}_j]$ 内。\n\n由于每个测试用例都使用了指定的随机种子，整个过程是确定性的。该算法针对提供的三个不同测试用例执行，并报告每个用例在终止时找到的最优适应度值。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\n\ndef solve():\n    \"\"\"\n    Main function to define, run, and report results for all test cases.\n    \"\"\"\n    # Global constants for the objective function as per the problem statement.\n    CONSTANTS = {\n        'c': [0.2, 0.1, 0.15, 0.3, 0.05, 0.6, 0.5], # c0 through c6\n        'M': 10.0,\n        'B': 100.0\n    }\n\n    def objective_function(x, bounds):\n        \"\"\"\n        Calculates the objective function value for a given individual x.\n        x is a numpy array [t, s, phi].\n        bounds is a dictionary {'t':(min,max), 's':(min,max), 'phi':(min,max)}.\n        \"\"\"\n        t, s, phi = x[0], x[1], x[2]\n        c0, c1, c2, c3, c4, c5, c6 = CONSTANTS['c']\n        M = CONSTANTS['M']\n        B = CONSTANTS['B']\n        \n        t_min, t_max = bounds['t']\n        s_min, s_max = bounds['s']\n        phi_min, phi_max = bounds['phi']\n\n        # Base surrogate objective function F(t,s,phi)\n        f_base = (c0 + c1 * t + c2 * s + c3 * math.sin(phi) + \n                  c4 * t * s - c5 * s * math.sin(phi) - \n                  c6 * (1.0 - t) * math.sin(phi))\n\n        # Derived relative density proxy and its penalty\n        r_d = 0.5 * t + 0.5 * (1.0 - s)\n        pi_dens = M * (max(0.0, r_d - 0.8)**2) + M * (max(0.0, 0.2 - r_d)**2)\n\n        # Box constraint penalty. This is included for formal correctness, though\n        # clipping in the GA ensures individuals are always within bounds.\n        pi_box_t = B * (max(0.0, t - t_max)**2) + B * (max(0.0, t_min - t)**2)\n        pi_box_s = B * (max(0.0, s - s_max)**2) + B * (max(0.0, s_min - s)**2)\n        pi_box_phi = B * (max(0.0, phi - phi_max)**2) + B * (max(0.0, phi_min - phi)**2)\n        pi_box = pi_box_t + pi_box_s + pi_box_phi\n\n        return f_base + pi_dens + pi_box\n\n    class GeneticAlgorithm:\n        \"\"\"\n        Implements the specified real-coded Genetic Algorithm.\n        \"\"\"\n        def __init__(self, bounds, N, G, pc, pm, sigma, k, seed):\n            self.bounds = bounds\n            self.bounds_arr = np.array([bounds['t'], bounds['s'], bounds['phi']])\n            self.N = N\n            self.G = G\n            self.pc = pc\n            self.pm = pm\n            self.sigma = sigma\n            self.k = k\n            self.rng = np.random.default_rng(seed)\n            self.E = max(1, math.floor(0.05 * self.N))\n            self.population = None\n            self.best_fitness_overall = float('inf')\n\n        def _initialize_population(self):\n            pop = np.zeros((self.N, 3))\n            pop[:, 0] = self.rng.uniform(self.bounds['t'][0], self.bounds['t'][1], self.N)\n            pop[:, 1] = self.rng.uniform(self.bounds['s'][0], self.bounds['s'][1], self.N)\n            pop[:, 2] = self.rng.uniform(self.bounds['phi'][0], self.bounds['phi'][1], self.N)\n            return pop\n\n        def _evaluate_population(self, pop):\n            return np.array([objective_function(ind, self.bounds) for ind in pop])\n\n        def _tournament_selection(self, pop, fitnesses):\n            indices = self.rng.choice(self.N, size=self.k, replace=False)\n            tournament_fitnesses = fitnesses[indices]\n            winner_idx_in_tournament = np.argmin(tournament_fitnesses)\n            winner_idx_in_pop = indices[winner_idx_in_tournament]\n            return pop[winner_idx_in_pop]\n\n        def _mutate_individual(self, ind):\n            for j in range(3):\n                if self.rng.random() < self.pm:\n                    gene_range = self.bounds_arr[j, 1] - self.bounds_arr[j, 0]\n                    std_dev = self.sigma * gene_range\n                    noise = self.rng.normal(loc=0.0, scale=std_dev)\n                    ind[j] += noise\n            return np.clip(ind, self.bounds_arr[:, 0], self.bounds_arr[:, 1])\n\n        def run(self):\n            self.population = self._initialize_population()\n\n            for _ in range(self.G):\n                fitnesses = self._evaluate_population(self.population)\n                \n                # Track the best fitness found in any generation\n                min_fitness_current_gen = np.min(fitnesses)\n                if min_fitness_current_gen < self.best_fitness_overall:\n                    self.best_fitness_overall = min_fitness_current_gen\n\n                # Elitism: preserve the best E individuals\n                elite_indices = np.argsort(fitnesses)[:self.E]\n                elites = self.population[elite_indices]\n                \n                new_population = [None] * self.N\n                new_population[:self.E] = elites\n\n                # Reproduction: create N-E new individuals\n                num_offspring = self.N - self.E\n                \n                offspring_list = []\n                for _ in range(num_offspring // 2):\n                    p1 = self._tournament_selection(self.population, fitnesses)\n                    p2 = self._tournament_selection(self.population, fitnesses)\n\n                    if self.rng.random() < self.pc:\n                        omega = self.rng.random()\n                        c1 = omega * p1 + (1 - omega) * p2\n                        c2 = omega * p2 + (1 - omega) * p1\n                    else:\n                        c1, c2 = p1.copy(), p2.copy()\n                    \n                    offspring_list.append(self._mutate_individual(c1))\n                    offspring_list.append(self._mutate_individual(c2))\n\n                if num_offspring % 2 == 1:\n                    p1 = self._tournament_selection(self.population, fitnesses)\n                    c1 = p1.copy()\n                    offspring_list.append(self._mutate_individual(c1))\n\n                new_population[self.E:] = offspring_list\n                self.population = np.array(new_population)\n            \n            # Final evaluation at termination\n            final_fitnesses = self._evaluate_population(self.population)\n            final_min_fitness = np.min(final_fitnesses)\n            if final_min_fitness < self.best_fitness_overall:\n                 self.best_fitness_overall = final_min_fitness\n            \n            return self.best_fitness_overall\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"bounds\": {'t': (0.05, 0.95), 's': (0.10, 0.90), 'phi': (0.10, 1.30)},\n            \"N\": 60, \"G\": 120, \"pc\": 0.9, \"pm\": 0.2, \"sigma\": 0.05, \"k\": 3, \"seed\": 12345\n        },\n        {\n            \"bounds\": {'t': (0.05, 0.95), 's': (0.10, 0.90), 'phi': (0.10, 0.25)},\n            \"N\": 80, \"G\": 180, \"pc\": 0.9, \"pm\": 0.2, \"sigma\": 0.04, \"k\": 3, \"seed\": 2023\n        },\n        {\n            \"bounds\": {'t': (0.05, 0.95), 's': (0.10, 0.90), 'phi': (1.10, 1.30)},\n            \"N\": 25, \"G\": 300, \"pc\": 0.8, \"pm\": 0.3, \"sigma\": 0.06, \"k\": 3, \"seed\": 314159\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        ga = GeneticAlgorithm(\n            bounds=case[\"bounds\"], N=case[\"N\"], G=case[\"G\"],\n            pc=case[\"pc\"], pm=case[\"pm\"], sigma=case[\"sigma\"],\n            k=case[\"k\"], seed=case[\"seed\"]\n        )\n        best_f = ga.run()\n        results.append(best_f)\n\n    # Final print statement in the exact required format.\n    rounded_results = [round(r, 6) for r in results]\n    print(f\"[{','.join(map(str, rounded_results))}]\")\n\nsolve()\n```", "id": "2396545"}, {"introduction": "我们的最终实践将探索一个高级且强大的概念：将领域特定知识嵌入到你的遗传算法中。你的任务是为图上的经典最小顶点覆盖问题设计一个自定义的交叉算子 [@problem_id:2396605]。这项练习将展示，创建能够理解问题结构（在本例中是保留关键子图）的算子，如何能够显著提升搜索效率和解的质量。", "problem": "给定一个有限、无向、简单的图 $G = (V,E)$，其中 $|V| = n$ 且 $|E| = m$。顶点覆盖是一个子集 $C \\subseteq V$，使得对于每条边 $(u,v) \\in E$，都有 $u \\in C$ 或 $v \\in C$。最小顶点覆盖问题旨在找到一个基数最小的顶点覆盖。一个染色体是一个二元向量 $x \\in \\{0,1\\}^n$，其中索引 $i$ 对应于顶点 $i \\in V$，并且当且仅当顶点 $i$ 被包含在候选覆盖中时，$x_i = 1$。由 $x$ 表示的覆盖的大小为 $|x| = \\sum_{i=0}^{n-1} x_i$。对于一个染色体 $x$，定义其未覆盖边数为 $U(x) = |\\{(u,v)\\in E \\mid x_u = 0 \\wedge x_v = 0\\}|$。定义惩罚适应度为 $f(x) = |x| + M \\cdot U(x)$，其中 $M = n + 1$。\n\n关键子图定义如下。一个三角形是任意一个包含3个顶点的子集 $\\{i,j,k\\} \\subseteq V$，使得三条边 $(i,j)$、$(j,k)$ 和 $(i,k)$ 都属于 $E$。一个以 $c \\in V$ 为中心的星形图是在 $\\{c\\} \\cup N(c)$ 上的导出子图，其中 $N(c)$ 是 $c$ 的邻域，且满足约束 $\\deg(c) \\ge 3$。通过以下按顺序应用的规则，构建一个不相交的关键子图族 $\\mathcal{H}$：首先包含所有三角形；然后，按度的非递增顺序，仅当以 $c$ 为中心的星形图的顶点集与已在 $\\mathcal{H}$ 中的所有子图的顶点集不相交时，才将其包含进来；当所有度至少为 $3$ 的中心点都已被考虑后，停止操作。因此，$\\mathcal{H}$ 中的每个 $H$ 要么是三角形，要么是星形图，并且 $\\mathcal{H}$ 中子图的顶点集两两不相交。\n\n一个交叉算子 $X$ 以图 $G$、不相交关键子图族 $\\mathcal{H}$ 和两个父代染色体 $p^{(1)}, p^{(2)} \\in \\{0,1\\}^n$ 作为输入，并生成一个满足以下所有性质的子代染色体 $c \\in \\{0,1\\}^n$：\n\n- 在关键子图上的保留：对于每个顶点集为 $V(H)$ 的 $H \\in \\mathcal{H}$，定义局部未覆盖计数 $U_H(p) = |\\{(u,v)\\in E \\mid u \\in V(H), v \\in V(H), p_u = 0, p_v = 0\\}|$，以及局部大小 $|p|_H = \\sum_{i \\in V(H)} p_i$。定义局部成本 $g_H(p) = |p|_H + M \\cdot U_H(p)$。子代必须满足对于所有 $i \\in V(H)$，$c_i = p^{(k)}_i$，其中选择 $k \\in \\{1,2\\}$ 以最小化 $g_H(p^{(k)})$；如果出现平局，则可以等概率地选择任一父代。\n- 在关键子图之外：对于所有 $j \\in V \\setminus \\bigcup_{H \\in \\mathcal{H}} V(H)$，子代必须满足 $c_j \\in \\{p^{(1)}_j, p^{(2)}_j\\}$，其中 $c_j = p^{(1)}_j$ 和 $c_j = p^{(2)}_j$ 在这些位置上以相等的概率独立发生。\n\n交叉之后，必须通过一个确定性的可行性修复步骤将 $c$ 转换为一个顶点覆盖，然后是一个确定性的剪枝步骤，该步骤迭代地移除任何冗余的已选顶点（将 $x_i$ 设置为 $0$），前提是移除操作能保持可行性，直到无法再进行此类移除为止。可行性修复和剪枝只能修改子代 $c$，并且必须在有限时间内终止。\n\n任务。实现一个完整的程序，该程序：\n\n- 对于下面列出的每个测试图，执行一个基于种群的搜索，该搜索在 $\\{0,1\\}^n$ 上进行，应用上述交叉算子 $X$ 作为唯一的重组机制，并使用惩罚适应度 $f(x)$ 来引导搜索。该搜索必须是随机的，但通过固定一个随机种子应是可复现的。它必须包括随机初始化和逐点位突变，每位的突变概率等于 $1/n$，该突变应用于修复和剪枝之前的子代。\n- 对于每个测试图，在对所有图都相同的固定计算预算之后，返回在 $f(x)$ 下找到的最佳染色体，并一同返回它是否是一个有效的顶点覆盖。\n\n测试套件。使用以下图；顶点从 $0$ 标记到 $n-1$，每条边 $(u,v)$ 都是无向的：\n\n- 测试 $1$（非二分图，包含一个三角形）：$n = 3$, $E = \\{(0,1),(1,2),(0,2)\\}$。\n- 测试 $2$（星形图，高度中心）：$n = 6$, $E = \\{(0,1),(0,2),(0,3),(0,4),(0,5)\\}$。\n- 测试 $3$（带对角线的环，包含一个三角形）：$n = 4$, $E = \\{(0,1),(1,2),(2,3),(3,0),(0,2)\\}$。\n- 测试 $4$（边界情况，空图）：$n = 5$, $E = \\emptyset$。\n\n计算预算和可复现性。对所有测试使用相同的固定随机种子。对每个测试，使用相同的种群大小和相同的代数。必须以每位 $1/n$ 的概率应用突变。在评估 $f(x)$ 之前，必须对所有个体应用可行性修复和剪枝。\n\n最终输出。您的程序必须生成单行输出，将所有测试结果聚合为一个由方括号括起来的逗号分隔列表。对于按上述顺序列出的每个测试，输出两个整数：找到的最佳覆盖大小 $|x^\\star|$ 和一个可行性指标，如果 $U(x^\\star) = 0$ 则定义为 $1$，否则为 $0$。因此，最终的输出格式是一个长度为 $8$ 的单一列表：$[|x^\\star_1|,b_1,|x^\\star_2|,b_2,|x^\\star_3|,b_3,|x^\\star_4|,b_4]$，其中对于每个测试 $i$，$b_i \\in \\{0,1\\}$。", "solution": "所提出的问题是演化算法领域的一项计算练习，专门针对无向图上的最小顶点覆盖问题而设计。问题陈述经过了严格验证，并被认为是有效的。它在科学上基于图论和遗传算法的既定原则，问题提法是适定的，其组成部分的描述具有足够的精确度（尽管有时微妙），足以支持形式化实现。尽管在选择机制或修复和剪枝的精确贪婪规则等领域存在一些轻微的模糊之处，但这些对于算法描述来说是典型的，并且可以通过采用标准的、确定性的实践来解决，这与创建*一个*完整程序的任务是一致的。因此，该问题是可解的。\n\n任务的核心是实现一个遗传算法（GA），该算法带有一个高度专门化的交叉算子和一个重组后的修复与剪枝序列。我们现在将根据所提供的原则来描绘该算法的设计。\n\n一个染色体是一个二元向量 $x \\in \\{0,1\\}^n$，其中 $n$ 是顶点的数量。如果 $x_i = 1$，顶点 $i$ 就在候选顶点覆盖中；如果 $x_i = 0$，则不在。染色体的质量通过惩罚适应度函数 $f(x) = |x| + M \\cdot U(x)$ 进行评估，其中 $|x|$ 是覆盖的大小（$x_i=1$ 的顶点数），$U(x)$ 是未被该顶点集覆盖的边数，而 $M=n+1$ 是一个惩罚系数。选择 $M > n$ 确保任何不可行解（$U(x) \\ge 1$）的适应度值都比任何可行解（$U(x)=0$）的要差，因为一个可行覆盖的最大大小是 $n$。\n\n指定的遗传算法按以下方式运行：\n\n1.  **关键子图识别**：在演化过程开始之前，分析图 $G$ 以识别一个不相交的关键子图族 $\\mathcal{H}$。构建过程是顺序且确定性的：\n    *   首先，识别图中的所有三角形。采用贪婪方法来形成这些三角形的一个不相交集：它们按确定性顺序（例如，按其顶点索引的字典序排序）进行处理，并且仅当一个三角形的顶点集与已添加到 $\\mathcal{H}$ 的子图的顶点集不相交时，才将其添加到 $\\mathcal{H}$。\n    *   接下来，按度的非递增顺序将顶点视为潜在的星形图中心。一个以 $c$ 为中心且度 $\\deg(c) \\ge 3$ 的星形图，仅当其顶点集 $\\{c\\} \\cup N(c)$ 与当前 $\\mathcal{H}$ 中所有子图的顶点集不相交时，才被添加到 $\\mathcal{H}$。\n    此过程产生一个由两两顶点不相交的三角形和星形图组成的集合 $\\mathcal{H}$。不属于 $\\mathcal{H}$ 中任何子图的顶点在交叉过程中被单独处理。\n\n2.  **遗传算法循环**：GA 以恒定的种群大小运行固定的代数。\n    *   **初始化**：创建一个随机染色体的初始种群。然后，每个染色体都由修复和剪枝算子处理，以确保起始种群完全由有效的、极小的顶点覆盖组成。\n    *   **选择**：为产生子代，从当前种群中选择父代。由于主种群由有效覆盖组成，它们的适应度 $f(x)$ 简化为其大小 $|x|$。标准的锦标赛选择是合适的：从种群中随机选择少量个体，大小最小（适应度最佳）的个体被选为父代。\n    *   **交叉**：专门的交叉算子 $X$ 从两个父代 $p^{(1)}$ 和 $p^{(2)}$ 生成一个子代 $c$。\n        *   对于每个关键子图 $H \\in \\mathcal{H}$，该算子为两个父代评估局部成本 $g_H(p) = |p|_H + M \\cdot U_H(p)$。此成本评估了父代在 $H$ 的顶点和导出边上的表现。对应于 $H$ 顶点的基因块从具有更优（更低）局部成本的父代复制到子代。平局随机打破。关键要注意的是，即使对于一个有效的全局覆盖 $p$，如果 $H$ 内的一条边被 $H$ 外的一个顶点所覆盖，其局部未覆盖计数 $U_H(p)$ 也可能为非零。\n        *   对于不属于 $\\mathcal{H}$ 中任何子图的所有顶点，子代的基因由均匀交叉确定：$c_j$ 以相等的概率从 $\\{p^{(1)}_j, p^{(2)}_j\\}$ 中随机选择。\n    *   **突变**：新创建的子代染色体经历逐点位翻转突变，其中每个位 $c_i$ 以 $1/n$ 的概率被翻转。\n    *   **修复与剪枝**：（可能不可行的）子代染色体被确定性地转换为一个有效的、极小的顶点覆盖。\n        1.  **可行性修复**：使染色体成为一个有效的顶点覆盖。应用一个确定性规则：以固定顺序遍历图的所有边。如果发现一条边 $(u,v)$ 未被覆盖（$x_u=0, x_v=0$），则将其中一个顶点添加到覆盖中（例如，通过设置 $x_u=1$，其中 $u<v$）。\n        2.  **剪枝**：通过一个贪婪的迭代过程，使得到的有效覆盖成为极小覆盖（但不一定是最小覆盖）。以固定顺序遍历覆盖中的每个顶点 $i$（$x_i=1$）。暂时将其移除（$x_i=0$），并检查覆盖是否仍然有效。如果有效，则永久移除。如果无效，则恢复该顶点。重复此过程，直到在一整轮遍历中没有更多顶点可以被移除。\n    *   **替换**：新一代由产生的子代形成。采用精英策略，其中父代中的最佳个体保证存活到下一代，从而保留找到的最佳解。\n    *   **终止**：算法在固定代数后终止。在整个运行过程中找到的最佳染色体，按其大小评估，作为结果报告。由于种群中所有被评估的个体都是有效的覆盖，可行性标志将为 $1$。\n\n此设计满足了问题陈述的所有要求。为了可复现性，使用了一个固定的随机种子。对于指定的测试套件，这个确定性算法将产生一个单一的、可验证的输出。\n<answer>```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# A complete and runnable Python 3.12 program.\n# This program implements the specified genetic algorithm for the minimum vertex cover problem.\n# It uses only the numpy library (version 1.23.5) as permitted.\n\n# Define GA parameters not specified in the problem statement.\n# These are kept constant across all test cases.\nPOPULATION_SIZE = 50\nGENERATIONS = 50\nTOURNAMENT_SIZE = 3\nRANDOM_SEED = 42\n\nclass VertexCoverGA:\n    \"\"\"\n    Implements the specialized genetic algorithm for the Minimum Vertex Cover problem\n    as described in the problem statement.\n    \"\"\"\n    def __init__(self, n, edges, pop_size, generations, seed):\n        self.n = n\n        # Ensure edges are consistently ordered, e.g., (min, max)\n        self.edges = sorted([tuple(sorted(e)) for e in edges])\n        self.pop_size = pop_size\n        self.generations = generations\n        self.rng = np.random.default_rng(seed)\n        self.M = n + 1\n        \n        self.adj = [set() for _ in range(n)]\n        for u, v in self.edges:\n            self.adj[u].add(v)\n            self.adj[v].add(u)\n        \n        self.H, self.non_h_vertices = self._find_critical_subgraphs()\n\n    def _find_critical_subgraphs(self):\n        \"\"\"\n        Constructs the disjoint family of critical sub-graphs H, following the\n        specified rules: triangles first, then stars.\n        \"\"\"\n        H = []\n        used_vertices = set()\n        \n        # 1. Greedily find all disjoint triangles\n        all_triangles = set()\n        if self.n >= 3:\n            for i in range(self.n):\n                # Sort neighbors to ensure deterministic processing and triangle representation\n                neighbors = sorted(list(self.adj[i]))\n                for j_idx in range(len(neighbors)):\n                    for k_idx in range(j_idx + 1, len(neighbors)):\n                        v, w = neighbors[j_idx], neighbors[k_idx]\n                        if v < i and w < i: # Avoid re-discovering triangles\n                            continue\n                        if w in self.adj[v]:\n                            triangle = tuple(sorted((i, v, w)))\n                            all_triangles.add(triangle)\n\n        # Sort triangles to have a deterministic order for greedy selection\n        sorted_triangles = sorted(list(all_triangles))\n        \n        for t_vertices in sorted_triangles:\n             t_set = set(t_vertices)\n             if not t_set.intersection(used_vertices):\n                 H.append({'type': 'triangle', 'vertices': t_set})\n                 used_vertices.update(t_set)\n\n        # 2. Greedily find disjoint stars\n        degrees = [(i, len(self.adj[i])) for i in range(self.n)]\n        degrees.sort(key=lambda x: (-x[1], x[0])) # Sort by degree desc, then index asc\n\n        for i, deg in degrees:\n            if deg < 3:\n                break\n            star_vertices = {i} | self.adj[i]\n            if not star_vertices.intersection(used_vertices):\n                H.append({'type': 'star', 'vertices': star_vertices})\n                used_vertices.update(star_vertices)\n        \n        non_h_vertices = sorted([v for v in range(self.n) if v not in used_vertices])        \n        return H, non_h_vertices\n\n    def _local_cost(self, p, h_block_vertices):\n        size_h = sum(p[i] for i in h_block_vertices)\n        uncovered_h = 0\n        h_v_list = list(h_block_vertices)\n        for i in range(len(h_v_list)):\n            for j in range(i + 1, len(h_v_list)):\n                u, v = h_v_list[i], h_v_list[j]\n                if v in self.adj[u] and p[u] == 0 and p[v] == 0:\n                    uncovered_h += 1\n        return size_h + self.M * uncovered_h\n\n    def crossover(self, p1, p2):\n        child = np.zeros(self.n, dtype=np.int8)\n        \n        for h_block in self.H:\n            h_vertices = h_block['vertices']\n            cost1 = self._local_cost(p1, h_vertices)\n            cost2 = self._local_cost(p2, h_vertices)\n            \n            winner = p1 if cost1 < cost2 else p2 if cost2 < cost1 else (p1 if self.rng.random() < 0.5 else p2)\n            \n            for v_idx in h_vertices:\n                child[v_idx] = winner[v_idx]\n\n        for j in self.non_h_vertices:\n            child[j] = p1[j] if self.rng.random() < 0.5 else p2[j]\n\n        return child\n\n    def mutate(self, chromosome):\n        if self.n == 0: return chromosome\n        mutation_prob = 1.0 / self.n if self.n > 0 else 0.0\n        if mutation_prob > 0:\n            for i in range(self.n):\n                if self.rng.random() < mutation_prob:\n                    chromosome[i] = 1 - chromosome[i]\n        return chromosome\n\n    def is_cover(self, chromosome):\n        return all(chromosome[u] == 1 or chromosome[v] == 1 for u, v in self.edges)\n\n    def repair(self, chromosome):\n        for u, v in self.edges:\n            if chromosome[u] == 0 and chromosome[v] == 0:\n                chromosome[u] = 1 # Deterministic rule: add vertex with smaller index\n        return chromosome\n\n    def prune(self, chromosome):\n        changed = True\n        node_order = list(range(self.n))\n        while changed:\n            changed = False\n            for i in node_order:\n                if chromosome[i] == 1:\n                    chromosome[i] = 0\n                    if not self.is_cover(chromosome):\n                        chromosome[i] = 1\n                    else:\n                        changed = True\n        return chromosome\n\n    def run(self):\n        population = self.rng.integers(0, 2, size=(self.pop_size, self.n), dtype=np.int8)\n        \n        for i in range(self.pop_size):\n            population[i] = self.repair(population[i])\n            population[i] = self.prune(population[i])\n\n        # Handle case of n=0 graph\n        if self.n == 0:\n            return 0, 1\n\n        best_chromosome = population[0].copy()\n        best_fitness = np.sum(best_chromosome)\n\n        for _ in range(self.generations):\n            fitnesses = np.sum(population, axis=1)\n\n            current_best_idx = np.argmin(fitnesses)\n            if fitnesses[current_best_idx] < best_fitness:\n                best_fitness = fitnesses[current_best_idx]\n                best_chromosome = population[current_best_idx].copy()\n            \n            new_population = np.zeros((self.pop_size, self.n), dtype=np.int8)\n            new_population[0] = best_chromosome.copy() # Elitism\n            \n            for i in range(1, self.pop_size):\n                tourn_indices1 = self.rng.choice(self.pop_size, TOURNAMENT_SIZE, replace=False)\n                p1_idx = tourn_indices1[np.argmin(fitnesses[tourn_indices1])]\n                \n                tourn_indices2 = self.rng.choice(self.pop_size, TOURNAMENT_SIZE, replace=False)\n                p2_idx = tourn_indices2[np.argmin(fitnesses[tourn_indices2])]\n\n                parent1 = population[p1_idx]\n                parent2 = population[p2_idx]\n                \n                child = self.crossover(parent1, parent2)\n                child = self.mutate(child)\n                child = self.repair(child)\n                child = self.prune(child)\n                \n                new_population[i] = child\n            \n            population = new_population\n\n        best_size = np.sum(best_chromosome)\n        is_feasible_flag = 1 if self.is_cover(best_chromosome) else 0\n        \n        return int(best_size), is_feasible_flag\n\ndef solve():\n    \"\"\"\n    Main function to run the GA on the test suite and print the results\n    in the specified format.\n    \"\"\"\n    test_cases = [\n        {'n': 3, 'edges': [(0, 1), (1, 2), (0, 2)]},\n        {'n': 6, 'edges': [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5)]},\n        {'n': 4, 'edges': [(0, 1), (1, 2), (2, 3), (3, 0), (0, 2)]},\n        {'n': 5, 'edges': []},\n    ]\n\n    results = []\n    for case in test_cases:\n        ga = VertexCoverGA(\n            n=case['n'],\n            edges=case['edges'],\n            pop_size=POPULATION_SIZE,\n            generations=GENERATIONS,\n            seed=RANDOM_SEED\n        )\n        best_size, is_feasible = ga.run()\n        results.extend([best_size, is_feasible])\n    \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```</answer>", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# A complete and runnable Python 3.12 program.\n# This program implements the specified genetic algorithm for the minimum vertex cover problem.\n# It uses only the numpy library (version 1.23.5) as permitted.\n\n# Define GA parameters not specified in the problem statement.\n# These are kept constant across all test cases.\nPOPULATION_SIZE = 50\nGENERATIONS = 50\nTOURNAMENT_SIZE = 3\nRANDOM_SEED = 42\n\nclass VertexCoverGA:\n    \"\"\"\n    Implements the specialized genetic algorithm for the Minimum Vertex Cover problem\n    as described in the problem statement.\n    \"\"\"\n    def __init__(self, n, edges, pop_size, generations, seed):\n        self.n = n\n        # Ensure edges are consistently ordered, e.g., (min, max)\n        self.edges = sorted([tuple(sorted(e)) for e in edges])\n        self.pop_size = pop_size\n        self.generations = generations\n        self.rng = np.random.default_rng(seed)\n        self.M = n + 1\n        \n        self.adj = [set() for _ in range(n)]\n        for u, v in self.edges:\n            self.adj[u].add(v)\n            self.adj[v].add(u)\n        \n        self.H, self.non_h_vertices = self._find_critical_subgraphs()\n\n    def _find_critical_subgraphs(self):\n        \"\"\"\n        Constructs the disjoint family of critical sub-graphs H, following the\n        specified rules: triangles first, then stars.\n        \"\"\"\n        H = []\n        used_vertices = set()\n        \n        # 1. Greedily find all disjoint triangles\n        all_triangles = set()\n        if self.n >= 3:\n            for i in range(self.n):\n                # Sort neighbors to ensure deterministic processing and triangle representation\n                neighbors = sorted(list(self.adj[i]))\n                for j_idx in range(len(neighbors)):\n                    for k_idx in range(j_idx + 1, len(neighbors)):\n                        v, w = neighbors[j_idx], neighbors[k_idx]\n                        if v < i and w < i: # Avoid re-discovering triangles\n                            continue\n                        if w in self.adj[v]:\n                            triangle = tuple(sorted((i, v, w)))\n                            all_triangles.add(triangle)\n\n        # Sort triangles to have a deterministic order for greedy selection\n        sorted_triangles = sorted(list(all_triangles))\n        \n        for t_vertices in sorted_triangles:\n             t_set = set(t_vertices)\n             if not t_set.intersection(used_vertices):\n                 H.append({'type': 'triangle', 'vertices': t_set})\n                 used_vertices.update(t_set)\n\n        # 2. Greedily find disjoint stars\n        degrees = [(i, len(self.adj[i])) for i in range(self.n)]\n        degrees.sort(key=lambda x: (-x[1], x[0])) # Sort by degree desc, then index asc\n\n        for i, deg in degrees:\n            if deg < 3:\n                break\n            star_vertices = {i} | self.adj[i]\n            if not star_vertices.intersection(used_vertices):\n                H.append({'type': 'star', 'vertices': star_vertices})\n                used_vertices.update(star_vertices)\n        \n        non_h_vertices = sorted([v for v in range(self.n) if v not in used_vertices])        \n        return H, non_h_vertices\n\n    def _local_cost(self, p, h_block_vertices):\n        size_h = sum(p[i] for i in h_block_vertices)\n        uncovered_h = 0\n        h_v_list = list(h_block_vertices)\n        for i in range(len(h_v_list)):\n            for j in range(i + 1, len(h_v_list)):\n                u, v = h_v_list[i], h_v_list[j]\n                if v in self.adj[u] and p[u] == 0 and p[v] == 0:\n                    uncovered_h += 1\n        return size_h + self.M * uncovered_h\n\n    def crossover(self, p1, p2):\n        child = np.zeros(self.n, dtype=np.int8)\n        \n        for h_block in self.H:\n            h_vertices = h_block['vertices']\n            cost1 = self._local_cost(p1, h_vertices)\n            cost2 = self._local_cost(p2, h_vertices)\n            \n            winner = p1 if cost1 < cost2 else p2 if cost2 < cost1 else (p1 if self.rng.random() < 0.5 else p2)\n            \n            for v_idx in h_vertices:\n                child[v_idx] = winner[v_idx]\n\n        for j in self.non_h_vertices:\n            child[j] = p1[j] if self.rng.random() < 0.5 else p2[j]\n\n        return child\n\n    def mutate(self, chromosome):\n        if self.n == 0: return chromosome\n        mutation_prob = 1.0 / self.n if self.n > 0 else 0.0\n        if mutation_prob > 0:\n            for i in range(self.n):\n                if self.rng.random() < mutation_prob:\n                    chromosome[i] = 1 - chromosome[i]\n        return chromosome\n\n    def is_cover(self, chromosome):\n        return all(chromosome[u] == 1 or chromosome[v] == 1 for u, v in self.edges)\n\n    def repair(self, chromosome):\n        for u, v in self.edges:\n            if chromosome[u] == 0 and chromosome[v] == 0:\n                chromosome[u] = 1 # Deterministic rule: add vertex with smaller index\n        return chromosome\n\n    def prune(self, chromosome):\n        changed = True\n        node_order = list(range(self.n))\n        while changed:\n            changed = False\n            for i in node_order:\n                if chromosome[i] == 1:\n                    chromosome[i] = 0\n                    if not self.is_cover(chromosome):\n                        chromosome[i] = 1\n                    else:\n                        changed = True\n        return chromosome\n\n    def run(self):\n        population = self.rng.integers(0, 2, size=(self.pop_size, self.n), dtype=np.int8)\n        \n        for i in range(self.pop_size):\n            population[i] = self.repair(population[i])\n            population[i] = self.prune(population[i])\n\n        # Handle case of n=0 graph\n        if self.n == 0:\n            return 0, 1\n\n        best_chromosome = population[0].copy()\n        best_fitness = np.sum(best_chromosome)\n\n        for _ in range(self.generations):\n            fitnesses = np.sum(population, axis=1)\n\n            current_best_idx = np.argmin(fitnesses)\n            if fitnesses[current_best_idx] < best_fitness:\n                best_fitness = fitnesses[current_best_idx]\n                best_chromosome = population[current_best_idx].copy()\n            \n            new_population = np.zeros((self.pop_size, self.n), dtype=np.int8)\n            new_population[0] = best_chromosome.copy() # Elitism\n            \n            for i in range(1, self.pop_size):\n                tourn_indices1 = self.rng.choice(self.pop_size, TOURNAMENT_SIZE, replace=False)\n                p1_idx = tourn_indices1[np.argmin(fitnesses[tourn_indices1])]\n                \n                tourn_indices2 = self.rng.choice(self.pop_size, TOURNAMENT_SIZE, replace=False)\n                p2_idx = tourn_indices2[np.argmin(fitnesses[tourn_indices2])]\n\n                parent1 = population[p1_idx]\n                parent2 = population[p2_idx]\n                \n                child = self.crossover(parent1, parent2)\n                child = self.mutate(child)\n                child = self.repair(child)\n                child = self.prune(child)\n                \n                new_population[i] = child\n            \n            population = new_population\n\n        best_size = np.sum(best_chromosome)\n        is_feasible_flag = 1 if self.is_cover(best_chromosome) else 0\n        \n        return int(best_size), is_feasible_flag\n\ndef solve():\n    \"\"\"\n    Main function to run the GA on the test suite and print the results\n    in the specified format.\n    \"\"\"\n    test_cases = [\n        {'n': 3, 'edges': [(0, 1), (1, 2), (0, 2)]},\n        {'n': 6, 'edges': [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5)]},\n        {'n': 4, 'edges': [(0, 1), (1, 2), (2, 3), (3, 0), (0, 2)]},\n        {'n': 5, 'edges': []},\n    ]\n\n    results = []\n    for case in test_cases:\n        ga = VertexCoverGA(\n            n=case['n'],\n            edges=case['edges'],\n            pop_size=POPULATION_SIZE,\n            generations=GENERATIONS,\n            seed=RANDOM_SEED\n        )\n        best_size, is_feasible = ga.run()\n        results.extend([best_size, is_feasible])\n    \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2396605"}]}