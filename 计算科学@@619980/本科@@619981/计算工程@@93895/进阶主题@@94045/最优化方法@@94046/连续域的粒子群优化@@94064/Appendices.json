{"hands_on_practices": [{"introduction": "粒子群优化算法的有效性并非必然，它在很大程度上依赖于其核心参数的精细选择，即惯性权重 $\\omega$、认知系数 $c_1$ 和社会系数 $c_2$。这个实践将让你扮演算法设计者的角色，完成元优化中的一个基本挑战：找到这些超参数的最优组合。通过在标准基准函数上系统地评估不同的参数组合，你将亲身体验如何校准优化器以达到最佳性能 [@problem_id:2423083]。", "problem": "您的任务是为一个称为粒子群优化（Particle Swarm Optimization, PSO）的连续域优化器选择超参数，以最小化一个标准的非凸函数。设目标函数为 $d$ 维 Ackley 函数，其对于 $\\mathbf{x} \\in \\mathbb{R}^d$ 定义为\n$$\nf(\\mathbf{x}) \\;=\\; -20\\exp\\!\\left(-0.2\\sqrt{\\frac{1}{d}\\sum_{i=1}^d x_i^2}\\right) \\;-\\; \\exp\\!\\left(\\frac{1}{d}\\sum_{i=1}^d \\cos(2\\pi x_i)\\right) \\;+\\; 20 \\;+\\; e,\n$$\n定义域约束为 $\\mathbf{x}\\in[-5,5]^d$。余弦函数使用弧度制角。PSO 的目标是在有限的评估预算下最小化 $f(\\mathbf{x})$；PSO 算法由三个实值超参数 $(\\omega,c_1,c_2)$ 参数化，这些超参数控制着粒子位置和速度的随机动力系统。\n\n对于一个包含 $n$ 个粒子和 $T$ 次迭代的 PSO 配置，定义在第 $t\\in\\{1,2,\\dots,T\\}$ 次迭代中，粒子 $p\\in\\{1,2,\\dots,n\\}$ 的坐标 $j\\in\\{1,2,\\dots,d\\}$ 的动态更新如下\n$$\nv_{p,j}^{(t)} \\;=\\; \\omega\\, v_{p,j}^{(t-1)} \\;+\\; c_1\\, r_{1,p,j}^{(t)}\\big(pbest_{p,j}^{(t-1)} - x_{p,j}^{(t-1)}\\big) \\;+\\; c_2\\, r_{2,p,j}^{(t)}\\big(gbest_{j}^{(t-1)} - x_{p,j}^{(t-1)}\\big),\n$$\n$$\nx_{p,j}^{(t)} \\;=\\; x_{p,j}^{(t-1)} \\;+\\; v_{p,j}^{(t)},\n$$\n其中 $r_{1,p,j}^{(t)}$ 和 $r_{2,p,j}^{(t)}$ 是从 $[0,1]$ 上的均匀分布中进行的独立抽样，$pbest_{p}^{(t-1)}$ 是截至第 $t-1$ 次迭代时观测到的粒子 $p$ 的最佳位置，$gbest^{(t-1)}$ 是截至第 $t-1$ 次迭代时所有粒子中的最佳位置。必须通过投影将位置保持在定义域内，即每次更新后，将每个坐标映射到 $\\min\\{5,\\max\\{-5,x_{p,j}^{(t)}\\}\\}$。将所有速度初始化为零向量，并将所有位置在 $[-5,5]^d$ 内进行独立的均匀初始化。在第 $T$ 次迭代结束时，将 $(\\omega,c_1,c_2)$ 的性能定义为截至（并包括）第 $T$ 次迭代时任何粒子所找到的最佳目标值，即 $\\min_{t\\in\\{0,\\dots,T\\}}\\min_{p\\in\\{1,\\dots,n\\}} f(x_p^{(t)})$。\n\n您必须从以下有限候选集中选择 $(\\omega,c_1,c_2)$:\n- $\\omega \\in \\{0.2,\\,0.6,\\,0.9\\}$,\n- $c_1 \\in \\{0.5,\\,1.5,\\,2.5\\}$,\n- $c_2 \\in \\{0.5,\\,1.5,\\,2.5\\}$。\n所有候选值均为所列出的实数。\n\n对于下方的每个测试用例，使用该测试用例相同的伪随机初始状态来评估每个候选三元组。也就是说，对于一个固定的测试用例，在评估每个候选者之前，必须将随机数生成器初始化为相同的种子，以确保所有候选者在相同的随机实现下进行比较。对于每个测试用例，报告产生最小最终最佳目标值的候选三元组 $(\\omega,c_1,c_2)$。如果有多个候选者在 $\\epsilon = 10^{-12}$ 的容差范围内达到了相同的最小值，则通过选择最小的 $\\omega$ 来按字典序打破平局；如果仍然持平，则选择最小的 $c_1$；然后是最小的 $c_2$。\n\n测试套件（每个测试用例指定维度 $d$、粒子群大小 $n$、迭代预算 $T$ 和伪随机种子 $s$）：\n- 测试用例 1: $d=2$, $n=20$, $T=200$, $s=1337$。\n- 测试用例 2: $d=10$, $n=30$, $T=180$, $s=9001$。\n- 测试用例 3: $d=2$, $n=50$, $T=30$, $s=42$。\n\n您的程序必须为每个测试用例计算出从给定候选集中选出的、能够最小化上述定义的性能指标的 $(\\omega,c_1,c_2)$。余弦函数中的角度以弧度为单位。没有需要报告的物理单位。\n\n最终输出格式：您的程序应生成单行输出，其中包含一个含三个内部列表的列表，每个内部列表对应一个测试用例，是所选的 $(\\omega,c_1,c_2)$，格式化为小数点后恰好一位的实数，无空格，并按测试用例的顺序排列。例如，如果选中的三元组是 $(0.6,1.5,2.5)$、$(0.2,0.5,0.5)$、$(0.9,2.5,1.5)$，则输出必须是\n[[0.6,1.5,2.5],[0.2,0.5,0.5],[0.9,2.5,1.5]]。", "solution": "问题陈述已经过严格验证，被认为是科学上合理、定义明确、无歧义且完整的。它描述了优化领域中的一个标准计算实验。将遵循指定的方法提供一个解决方案。\n\n任务是为粒子群优化（PSO）算法执行超参数选择。目标是从给定的有限集合中找到参数 $(\\omega, c_1, c_2)$ 的最优组合，以最小化 Ackley 函数，这是一个标准的非凸基准问题。\n\n待最小化的目标函数是 $d$ 维 Ackley 函数，由下式给出：\n$$\nf(\\mathbf{x}) = -20\\exp\\left(-0.2\\sqrt{\\frac{1}{d}\\sum_{i=1}^d x_i^2}\\right) - \\exp\\left(\\frac{1}{d}\\sum_{i=1}^d \\cos(2\\pi x_i)\\right) + 20 + e,\n$$\n其中 $\\mathbf{x} = (x_1, \\dots, x_d) \\in [-5, 5]^d$ 且 $e$ 是欧拉数，即自然对数的底。余弦函数的参数以弧度为单位。\n\nPSO 算法是一种基于种群的随机优化技术。粒子群由 $n$ 个粒子组成，每个粒子代表 $d$ 维搜索空间中的一个候选解。在第 $t$ 次迭代时，每个粒子 $p$ 都有一个位置向量 $\\mathbf{x}_p^{(t)} \\in \\mathbb{R}^d$ 和一个速度向量 $\\mathbf{v}_p^{(t)} \\in \\mathbb{R}^d$。该算法按以下步骤进行：\n\n1.  **初始化 ($t=0$)**：\n    - 粒子位置 $\\mathbf{x}_p^{(0)}$ 通过从定义域 $[-5, 5]$ 上的均匀分布中独立抽取坐标来初始化。\n    - 粒子速度 $\\mathbf{v}_p^{(0)}$ 初始化为零向量。\n    - 每个粒子的个体最佳位置 $\\mathbf{pbest}_p$ 被设置为其初始位置，即 $\\mathbf{pbest}_p^{(0)} = \\mathbf{x}_p^{(0)}$。\n    - 全局最佳位置 $\\mathbf{gbest}$ 被设置为具有最低初始目标函数值的粒子的个体最佳位置，即 $\\mathbf{gbest}^{(0)}$ 是使 $f(\\mathbf{pbest}_p^{(0)})$ 在所有 $p \\in \\{1, \\dots, n\\}$ 中最小的那个 $\\mathbf{pbest}_p^{(0)}$。\n\n2.  **迭代更新 (对于 $t=1, \\dots, T$)**：对于每个粒子 $p$ 和每个维度 $j$：\n    - 速度根据以下方程更新：\n      $$\n      v_{p,j}^{(t)} = \\omega\\, v_{p,j}^{(t-1)} + c_1\\, r_{1,p,j}^{(t)}\\left(pbest_{p,j}^{(t-1)} - x_{p,j}^{(t-1)}\\right) + c_2\\, r_{2,p,j}^{(t)}\\left(gbest_{j}^{(t-1)} - x_{p,j}^{(t-1)}\\right),\n      $$\n      其中 $\\omega$ 是惯性权重，$c_1$ 是认知系数，$c_2$ 是社会系数。项 $r_{1,p,j}^{(t)}$ 和 $r_{2,p,j}^{(t)}$ 是从均匀分布 $U[0, 1]$ 中独立抽取的随机数。\n    - 位置通过以下方式更新：\n      $$\n      x_{p,j}^{(t)} = x_{p,j}^{(t-1)} + v_{p,j}^{(t)}.\n      $$\n    - 位置更新后，将坐标限制在定义域 $[-5, 5]$ 内：$x_{p,j}^{(t)} = \\min(5, \\max(-5, x_{p,j}^{(t)}))$。\n    - 更新粒子的个体最佳位置：如果 $f(\\mathbf{x}_p^{(t)}) < f(\\mathbf{pbest}_p^{(t-1)})$，则 $\\mathbf{pbest}_p^{(t)} = \\mathbf{x}_p^{(t)}$；否则，$\\mathbf{pbest}_p^{(t)} = \\mathbf{pbest}_p^{(t-1)}$。\n    - 更新全局最佳位置：$\\mathbf{gbest}^{(t)}$ 被设置为在所有粒子中产生最小目标值的那个 $\\mathbf{pbest}_p^{(t)}$。\n\n超参数选择通过对候选集进行网格搜索来执行：$\\omega \\in \\{0.2, 0.6, 0.9\\}$，$c_1 \\in \\{0.5, 1.5, 2.5\\}$ 和 $c_2 \\in \\{0.5, 1.5, 2.5\\}$，总共产生 $3 \\times 3 \\times 3 = 27$ 个候选三元组 $(\\omega, c_1, c_2)$。\n\n对于每个由元组 $(d, n, T, s)$ 定义的测试用例，严格遵循以下评估协议：\n- 使用 27 个候选三元组中的每一个来运行 PSO 算法 $T$ 次迭代。\n- 关键的是，为确保公平比较，在评估每个候选三元组之前，伪随机数生成器都重置为相同的种子 $s$。这确保了所有三元组都在相同的随机条件下运行（即，相同的初始粒子群配置和用于速度更新的相同随机数序列）。\n- 一个三元组的性能定义为在第 $T$ 次迭代之前（含）任何粒子找到的最佳目标值，这等价于 $f(\\mathbf{gbest}^{(T)})$。\n\n测试用例的获胜三元组由最低的性能值决定。在出现平局的情况下，即性能值在 $\\epsilon = 10^{-12}$ 的容差范围内，通过选择字典序最小的三元组 $(\\omega, c_1, c_2)$ 来打破平局。这意味着首先选择 $\\omega$ 最小的三元组；如果仍然平局，则选择 $c_1$ 最小的三元组；如果还是平局，则选择 $c_2$ 最小的三元组。\n\n实现是用 Python 完成的，利用 NumPy 库进行高效的向量化计算。粒子群的位置和速度作为 $(n \\times d)$ 维数组进行管理。Ackley 函数以向量化形式实现，以同时计算所有粒子的目标值，从而加速评估步骤。一个主程序为每个测试用例执行工作流程：它遍历所有超参数候选者，运行 PSO 模拟，记录性能，然后应用指定的选择和打破平局的规则来识别最优三元组。最终结果根据问题规范进行格式化。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the hyperparameter selection problem for PSO.\n    It iterates through given test cases, evaluates all candidate hyperparameter\n    triples for each case, selects the best one based on performance and tie-breaking\n    rules, and prints the final result in the specified format.\n    \"\"\"\n\n    def ackley_vec(x: np.ndarray, d: int) -> np.ndarray:\n        \"\"\"\n        Vectorized implementation of the Ackley function.\n        \n        Args:\n            x (np.ndarray): A 2D array of shape (n, d) representing n particle positions.\n            d (int): The dimension of the problem space.\n\n        Returns:\n            np.ndarray: A 1D array of shape (n,) with the objective value for each particle.\n        \"\"\"\n        assert x.shape[1] == d, \"Dimension mismatch\"\n\n        sum_sq = np.sum(x**2, axis=1)\n        term1 = -20.0 * np.exp(-0.2 * np.sqrt(sum_sq / d))\n\n        sum_cos = np.sum(np.cos(2 * np.pi * x), axis=1)\n        term2 = -np.exp(sum_cos / d)\n\n        return term1 + term2 + 20.0 + np.e\n\n    def run_pso(omega: float, c1: float, c2: float, d: int, n: int, T: int, seed: int) -> float:\n        \"\"\"\n        Runs a single instance of the Particle Swarm Optimization algorithm.\n\n        Args:\n            omega (float): Inertia weight.\n            c1 (float): Cognitive coefficient.\n            c2 (float): Social coefficient.\n            d (int): Dimension of the problem.\n            n (int): Number of particles.\n            T (int): Number of iterations.\n            seed (int): Seed for the random number generator.\n\n        Returns:\n            float: The best objective function value found during the optimization run.\n        \"\"\"\n        rng = np.random.default_rng(seed)\n        \n        # Initialization\n        domain_min, domain_max = -5.0, 5.0\n        pos = rng.uniform(domain_min, domain_max, size=(n, d))\n        vel = np.zeros((n, d))\n\n        pbest_pos = pos.copy()\n        pbest_val = ackley_vec(pbest_pos, d)\n\n        min_val_idx = np.argmin(pbest_val)\n        gbest_val = pbest_val[min_val_idx]\n        gbest_pos = pbest_pos[min_val_idx].copy()\n\n        # Iteration loop\n        for _ in range(T):\n            r1 = rng.random(size=(n, d))\n            r2 = rng.random(size=(n, d))\n\n            vel = omega * vel + c1 * r1 * (pbest_pos - pos) + c2 * r2 * (gbest_pos - pos)\n            pos = pos + vel\n            pos = np.clip(pos, domain_min, domain_max)\n\n            current_vals = ackley_vec(pos, d)\n            \n            improvement_mask = current_vals < pbest_val\n            pbest_pos[improvement_mask] = pos[improvement_mask]\n            pbest_val[improvement_mask] = current_vals[improvement_mask]\n            \n            current_best_idx = np.argmin(pbest_val)\n            if pbest_val[current_best_idx] < gbest_val:\n                gbest_val = pbest_val[current_best_idx]\n                gbest_pos = pbest_pos[current_best_idx].copy()\n\n        return gbest_val\n\n    # Define test cases and hyperparameter candidates from the problem statement.\n    test_cases = [\n        (2, 20, 200, 1337),\n        (10, 30, 180, 9001),\n        (2, 50, 30, 42),\n    ]\n\n    omegas = [0.2, 0.6, 0.9]\n    c1s = [0.5, 1.5, 2.5]\n    c2s = [0.5, 1.5, 2.5]\n    epsilon = 1e-12\n\n    all_best_params = []\n\n    for d, n, T, s in test_cases:\n        case_results = []\n        for omega in omegas:\n            for c1 in c1s:\n                for c2 in c2s:\n                    performance = run_pso(omega, c1, c2, d, n, T, s)\n                    case_results.append({'params': (omega, c1, c2), 'perf': performance})\n        \n        # Selection and tie-breaking logic\n        min_perf = min(r['perf'] for r in case_results)\n        \n        contenders = [r for r in case_results if r['perf'] <= min_perf + epsilon]\n        \n        contenders.sort(key=lambda r: r['params']) # Sorts by (omega, c1, c2)\n        \n        best_params = contenders[0]['params']\n        all_best_params.append(list(best_params))\n\n    # Final print statement in the exact required format.\n    result_str_list = []\n    for params in all_best_params:\n        result_str_list.append(f\"[{params[0]:.1f},{params[1]:.1f},{params[2]:.1f}]\")\n    \n    final_output = f\"[{','.join(result_str_list)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "2423083"}, {"introduction": "在许多现实世界的工程和科学问题中，目标函数的评估并非完全精确，而是会受到测量或模拟中噪声的干扰。本实践超越了理想化的场景，挑战你在噪声环境中评估 PSO 的性能。你将探索算法的搜索行为和最终解的质量如何受到不确定性的影响，从而突显 PSO 在“迷雾”般的优化景观中导航时所固有的鲁棒性 [@problem_id:2423094]。", "problem": "考虑一个连续优化问题，其目标由一个真实函数 $f_{\\text{true}}: \\mathbb{R}^d \\to \\mathbb{R}$ 定义，但只能通过 $f_{\\text{eval}}(\\boldsymbol{x}) = f_{\\text{true}}(\\boldsymbol{x}) + \\epsilon$ 获得带噪评估值，其中 $\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)$ 是一个独立的、零均值、方差为 $\\sigma^2$ 的高斯随机变量。一个离散时间、基于种群的随机过程作用于 $N$ 个代理（由 $i \\in \\{1,\\dots,N\\}$ 索引），在迭代 $t \\in \\{0,1,\\dots,T\\}$ 时，它们具有位置 $\\boldsymbol{x}_i(t) \\in \\mathbb{R}^d$ 和速度 $\\boldsymbol{v}_i(t) \\in \\mathbb{R}^d$。对于每个代理，会维护其个体最佳位置 $\\boldsymbol{p}_i(t) \\in \\mathbb{R}^d$ 及其对应的最佳带噪观测值 $b_i(t) \\in \\mathbb{R}$。同时，还有一个全局最佳位置 $\\boldsymbol{g}(t) \\in \\mathbb{R}^d$，代表在相同带噪值下所有个体最佳位置中的最优者。动力学由以下规则给出：\n\n- 在 $t=0$ 进行初始化：\n  - 对于每个 $i \\in \\{1,\\dots,N\\}$ 和每个坐标 $j \\in \\{1,\\dots,d\\}$，从 $[L_j,U_j]$ 中独立且均匀地抽取 $x_{i,j}(0)$，其中 $\\boldsymbol{L},\\boldsymbol{U} \\in \\mathbb{R}^d$ 是给定的逐元素边界，对所有 $j$ 满足 $L_j < U_j$。\n  - 对所有 $i$ 设置 $\\boldsymbol{v}_i(0) = \\boldsymbol{0}$。\n  - 对所有 $i$ 设置 $\\boldsymbol{p}_i(0) = \\boldsymbol{x}_i(0)$ 和 $b_i(0) = f_{\\text{eval}}(\\boldsymbol{x}_i(0))$。\n  - 令 $\\ell \\in \\{1,\\dots,N\\}$ 为达到 $\\min_{i} b_i(0)$ 的索引（若有多个则取最小索引）。设置 $\\boldsymbol{g}(0) = \\boldsymbol{p}_\\ell(0)$。\n\n- 在 $t = 0,1,\\dots,T-1$ 时进行迭代：\n  - 对于每个 $i \\in \\{1,\\dots,N\\}$，抽取独立的随机向量 $\\boldsymbol{r}_{1,i}(t), \\boldsymbol{r}_{2,i}(t) \\in [0,1]^d$，其分量从 $[0,1]$ 上的均匀分布中独立采样。\n  - 使用以下公式更新速度\n    $$\\boldsymbol{v}_i(t+1) = \\omega \\,\\boldsymbol{v}_i(t) + c_1 \\,\\boldsymbol{r}_{1,i}(t) \\odot \\left(\\boldsymbol{p}_i(t) - \\boldsymbol{x}_i(t)\\right) + c_2 \\,\\boldsymbol{r}_{2,i}(t) \\odot \\left(\\boldsymbol{g}(t) - \\boldsymbol{x}_i(t)\\right),$$\n    其中 $\\odot$ 表示逐元素乘法，$\\omega, c_1, c_2 \\in \\mathbb{R}$ 是给定的系数。\n  - 使用以下公式更新位置\n    $$\\boldsymbol{x}_i(t+1) = \\mathrm{clip}\\left(\\boldsymbol{x}_i(t) + \\boldsymbol{v}_i(t+1), \\boldsymbol{L}, \\boldsymbol{U}\\right),$$\n    其中裁剪函数对每个坐标 $j$ 应用逐元素的饱和操作，使其保持在区间 $[L_j, U_j]$ 内。\n  - 获得一个新的带噪评估值 $y_i(t+1) = f_{\\text{eval}}(\\boldsymbol{x}_i(t+1))$。如果 $y_i(t+1) < b_i(t)$，则设置 $\\boldsymbol{p}_i(t+1) = \\boldsymbol{x}_i(t+1)$ 和 $b_i(t+1) = y_i(t+1)$；否则设置 $\\boldsymbol{p}_i(t+1) = \\boldsymbol{p}_i(t)$ 和 $b_i(t+1) = b_i(t)$。\n  - 令 $m \\in \\{1,\\dots,N\\}$ 为达到 $\\min_{i} b_i(t+1)$ 的索引（若有多个则取最小索引）。设置 $\\boldsymbol{g}(t+1) = \\boldsymbol{p}_m(t+1)$。\n\n经过 $T$ 次迭代后，将返回的解定义为 $\\boldsymbol{x}^\\star = \\boldsymbol{g}(T)$。对于一组固定的参数，考虑对上述整个过程进行 $R$ 次独立重复，每次重复使用独立的随机性，并报告终止时真实目标值的算术平均值，\n$$\\frac{1}{R} \\sum_{r=1}^{R} f_{\\text{true}}(\\boldsymbol{x}^\\star_r),$$\n其中 $\\boldsymbol{x}^\\star_r$ 表示第 $r$ 次重复返回的解。\n\n所有随机变量必须由一个伪随机数生成器生成，其种子指定如下。给定一个基础种子 $s$。对于零基索引为 $k$ 的测试用例和零基索引为 $r$ 的重复，在该次重复中的所有随机过程均使用种子 $s + 100000\\,k + r$。\n\n使用以下目标函数、定义域和参数。在所有情况下，都使用 $\\omega = 0.7298$，$c_1 = 1.49618$ 和 $c_2 = 1.49618$。函数 $f_{\\text{true}}$ 如下：\n- Sphere：对于任何 $d \\geq 1$，$f_{\\text{true}}(\\boldsymbol{x}) = \\sum_{j=1}^d x_j^2$，在 $\\boldsymbol{0}$ 处取得全局最小值 0。\n- Rosenbrock：对于任何 $d \\geq 2$，$f_{\\text{true}}(\\boldsymbol{x}) = \\sum_{j=1}^{d-1} \\left(100\\,(x_{j+1} - x_j^2)^2 + (1 - x_j)^2\\right)$，在 $\\boldsymbol{1}$ 处取得全局最小值 0。\n- Rastrigin：对于任何 $d \\geq 1$，$f_{\\text{true}}(\\boldsymbol{x}) = 10\\,d + \\sum_{j=1}^d \\left(x_j^2 - 10 \\cos(2 \\pi x_j)\\right)$，在 $\\boldsymbol{0}$ 处取得全局最小值 0。\n\n测试套件。对于每种情况，报告上面定义的均值。余弦函数中出现的角度，单位为弧度。没有物理单位。\n- 用例 0：函数 Sphere，$d = 5$，对所有 $j$ 边界为 $L_j = -5, U_j = 5$，噪声标准差 $\\sigma = 0.1$，种群大小 $N = 30$，迭代次数 $T = 200$，重复次数 $R = 30$，基础种子 $s = 20240901$。\n- 用例 1：函数 Sphere，$d = 5$，边界 $L_j = -5, U_j = 5$，$\\sigma = 0$，种群大小 $N = 30$，迭代次数 $T = 200$，重复次数 $R = 30$，基础种子 $s = 20240901$。\n- 用例 2：函数 Sphere，$d = 5$，边界 $L_j = -5, U_j = 5$，$\\sigma = 2.0$，种群大小 $N = 30$，迭代次数 $T = 200，重复次数 $R = 30$，基础种子 $s = 20240901$。\n- 用例 3：函数 Rastrigin，$d = 10$，边界 $L_j = -5.12, U_j = 5.12$，$\\sigma = 0.5$，种群大小 $N = 40$，迭代次数 $T = 300$，重复次数 $R = 20$，基础种子 $s = 20240901$。\n- 用例 4：函数 Rosenbrock，$d = 3$，边界 $L_j = -2, U_j = 2$，$\\sigma = 0.2$，种群大小 $N = 25$，迭代次数 $T = 400$，重复次数 $R = 20$，基础种子 $s = 20240901$。\n- 用例 5：函数 Sphere，$d = 5$，边界 $L_j = -5, U_j = 5$，$\\sigma = 0.1$，种群大小 $N = 5$，迭代次数 $T = 50$，重复次数 $R = 50$，基础种子 $s = 20240901$。\n\n最终输出格式。您的程序应生成单行输出，包含 $6$ 个结果，形式为逗号分隔的列表并用方括号括起，每个数字四舍五入到六位小数，且没有空格；例如 $[a_0,a_1,a_2,a_3,a_4,a_5]$，其中每个 $a_k$ 是用例 $k$ 的指定均值。", "solution": "问题陈述构成了一个实现并执行标准粒子群优化 (Particle Swarm Optimization, PSO) 算法模拟的请求。这是一种公认的用于连续优化问题的随机元启发式算法。该问题被判定为有效，因为它具有科学依据、适定、客观，并为计算实验提供了完整且一致的规范。每个参数、函数和程序步骤都以数学精度进行了详细说明，从而可以进行可复现的数值研究。\n\nPSO 算法作用于一个由 $N$ 个代理（称为粒子）组成的种群（或粒子群），由 $i \\in \\{1, \\dots, N\\}$ 索引。每个粒子在一个 $d$ 维连续搜索空间中进行探索，该空间由 $\\mathbb{R}^d$ 中的逐元素下界 $\\boldsymbol{L}$ 和上界 $\\boldsymbol{U}$ 定义。在离散时间步 $t$，粒子 $i$ 的状态由其位置向量 $\\boldsymbol{x}_i(t) \\in \\mathbb{R}^d$ 和速度向量 $\\boldsymbol{v}_i(t) \\in \\mathbb{R}^d$ 定义。该算法的目标是找到真实函数 $f_{\\text{true}}(\\boldsymbol{x})$ 的最小值，但它只能访问带噪评估值 $f_{\\text{eval}}(\\boldsymbol{x}) = f_{\\text{true}}(\\boldsymbol{x}) + \\epsilon$，其中 $\\epsilon$ 是从高斯分布 $\\mathcal{N}(0, \\sigma^2)$ 中抽取的随机变量。\n\n粒子群的动力学在 $T$ 次迭代中演进。在初始化 ($t=0$) 时，粒子位置 $\\boldsymbol{x}_i(0)$ 在搜索空间边界内均匀采样，速度 $\\boldsymbol{v}_i(0)$ 设置为 $\\boldsymbol{0}$。每个粒子都会记录其自身找到的最佳位置，即个体最佳位置 $\\boldsymbol{p}_i(t)$，它对应于该粒子遇到的产生最低带噪目标值 $b_i(t)$ 的位置。此外，整个粒子群共同跟踪全局最佳位置 $\\boldsymbol{g}(t)$，这是截至时间 $t$ 在整个种群中已达到最低带噪目标值的粒子的个体最佳位置。\n\nPSO 算法的核心在于其迭代更新规则。对于每次迭代 $t$ 中的每个粒子 $i$，下一个时间步 $t+1$ 的速度根据以下方程进行更新：\n$$\n\\boldsymbol{v}_i(t+1) = \\omega \\,\\boldsymbol{v}_i(t) + c_1 \\,\\boldsymbol{r}_{1,i}(t) \\odot \\left(\\boldsymbol{p}_i(t) - \\boldsymbol{x}_i(t)\\right) + c_2 \\,\\boldsymbol{r}_{2,i}(t) \\odot \\left(\\boldsymbol{g}(t) - \\boldsymbol{x}_i(t)\\right)\n$$\n此更新包含三个部分：第一项由惯性权重 $\\omega$ 缩放，提供来自先前速度的动量。第二项是‘认知’部分，由系数 $c_1$ 缩放，将粒子拉向其个体最佳位置 $\\boldsymbol{p}_i(t)$。第三项是‘社会’部分，由 $c_2$ 缩放，将粒子拉向全局最佳位置 $\\boldsymbol{g}(t)$。向量 $\\boldsymbol{r}_{1,i}(t)$ 和 $\\boldsymbol{r}_{2,i}(t)$ 引入了随机性，其分量从均匀分布 $\\mathcal{U}[0,1]$ 中独立抽取。符号 $\\odot$ 表示逐元素向量乘法。问题指定的系数为 $\\omega = 0.7298$，$c_1 = 1.49618$ 和 $c_2 = 1.49618$。\n\n速度更新后，通过加上新速度来更新粒子的位置，并通过裁剪操作将结果限制在搜索空间边界 $[\\boldsymbol{L}, \\boldsymbol{U}]$ 内：\n$$\n\\boldsymbol{x}_i(t+1) = \\mathrm{clip}\\left(\\boldsymbol{x}_i(t) + \\boldsymbol{v}_i(t+1), \\boldsymbol{L}, \\boldsymbol{U}\\right)\n$$\n更新位置后，进行一次新的带噪评估 $y_i(t+1) = f_{\\text{eval}}(\\boldsymbol{x}_i(t+1))$。该值用于更新粒子的个体最佳位置：如果 $y_i(t+1) < b_i(t)$，则将 $\\boldsymbol{p}_i(t+1)$ 设置为新位置 $\\boldsymbol{x}_i(t+1)$，并将 $b_i(t+1)$ 设置为 $y_i(t+1)$。否则，它们保持不变。随后，通过在整个粒子群中识别具有最小个体最佳值 $b_i(t+1)$ 的粒子来更新全局最佳位置 $\\boldsymbol{g}(t+1)$。\n\n实现将严格遵循此规范进行结构化。为保证可复现性，定义了严格的种子协议：对于索引为 $k$（零基）的测试用例和索引为 $r$（零基）的重复，伪随机数生成器 (RNG) 的种子设置为 $s + 100000\\,k + r$。此 RNG 必须用于所有随机元素：初始位置、噪声生成以及随机向量 $\\boldsymbol{r}_{1,i}$ 和 $\\boldsymbol{r}_{2,i}$。实现将利用 NumPy 对粒子种群进行高效的向量化操作。\n\n基准函数——Sphere、Rosenbrock 和 Rastrigin——是全局优化的标准测试问题。经过 $T$ 次迭代后，算法返回全局最佳位置 $\\boldsymbol{x}^\\star = \\boldsymbol{g}(T)$。每个测试用例的性能指标是在 $R$ 次独立重复中真实目标函数值的算术平均值，即 $\\frac{1}{R} \\sum_{r=1}^{R} f_{\\text{true}}(\\boldsymbol{x}^\\star_r)$。这种蒙特卡洛方法评估了该随机算法的期望性能。最终程序将为 $6$ 个指定的测试用例中的每一个计算此指标，并按要求格式化结果。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the PSO simulation for all specified test cases.\n    \"\"\"\n\n    # --- Objective Functions ---\n    def sphere(x: np.ndarray) -> np.ndarray:\n        \"\"\"Computes the Sphere function. x is a 2D array of positions.\"\"\"\n        return np.sum(x**2, axis=1)\n\n    def rosenbrock(x: np.ndarray) -> np.ndarray:\n        \"\"\"Computes the Rosenbrock function. x is a 2D array of positions.\"\"\"\n        term1 = 100 * (x[:, 1:] - x[:, :-1]**2)**2\n        term2 = (1 - x[:, :-1])**2\n        return np.sum(term1 + term2, axis=1)\n\n    def rastrigin(x: np.ndarray) -> np.ndarray:\n        \"\"\"Computes the Rastrigin function. x is a 2D array of positions.\"\"\"\n        d = x.shape[1]\n        sum_term = np.sum(x**2 - 10 * np.cos(2 * np.pi * x), axis=1)\n        return 10 * d + sum_term\n\n    # --- PSO Algorithm Implementation ---\n    def pso_run(f_true, d, L, U, sigma, N, T, omega, c1, c2, rng):\n        \"\"\"\n        Performs one full run of the Particle Swarm Optimization algorithm.\n        \n        Args:\n            f_true: The true objective function.\n            d: Dimension of the search space.\n            L, U: Lower and upper bounds for all dimensions.\n            sigma: Standard deviation of the Gaussian noise.\n            N: Population size.\n            T: Number of iterations.\n            omega, c1, c2: PSO coefficients.\n            rng: NumPy random number generator instance.\n\n        Returns:\n            The final global best position g(T).\n        \"\"\"\n        # Create vector bounds\n        L_vec = np.full(d, L)\n        U_vec = np.full(d, U)\n\n        # --- Initialization (t=0) ---\n        # Initialize positions and velocities\n        pos = rng.uniform(L, U, size=(N, d))\n        vel = np.zeros((N, d))\n        \n        # Evaluate initial positions\n        true_vals = f_true(pos)\n        noise = rng.normal(0, sigma, size=N) if sigma > 0 else 0\n        eval_vals = true_vals + noise\n\n        # Initialize personal bests\n        p_best_pos = np.copy(pos)\n        p_best_val = np.copy(eval_vals)\n\n        # Initialize global best\n        min_idx = np.argmin(p_best_val)\n        g_best_pos = np.copy(p_best_pos[min_idx])\n        \n        # --- Iteration Loop (t = 0 to T-1) ---\n        for _ in range(T):\n            # Generate random vectors for velocity update\n            r1 = rng.uniform(0, 1, size=(N, d))\n            r2 = rng.uniform(0, 1, size=(N, d))\n\n            # Update velocity\n            cognitive_comp = c1 * r1 * (p_best_pos - pos)\n            social_comp = c2 * r2 * (g_best_pos - pos)\n            vel = omega * vel + cognitive_comp + social_comp\n\n            # Update position and clip to bounds\n            pos = np.clip(pos + vel, L_vec, U_vec)\n            \n            # Evaluate new positions\n            true_vals = f_true(pos)\n            noise = rng.normal(0, sigma, size=N) if sigma > 0 else 0\n            eval_vals = true_vals + noise\n\n            # Update personal bests\n            update_mask = eval_vals < p_best_val\n            p_best_pos[update_mask] = pos[update_mask]\n            p_best_val[update_mask] = eval_vals[update_mask]\n\n            # Update global best\n            min_idx = np.argmin(p_best_val)\n            g_best_pos = np.copy(p_best_pos[min_idx])\n        \n        return g_best_pos\n\n    # --- Test Cases Configuration ---\n    test_cases = [\n        {'func_name': 'sphere', 'func': sphere, 'd': 5, 'bounds': (-5., 5.), 'sigma': 0.1, 'N': 30, 'T': 200, 'R': 30},\n        {'func_name': 'sphere', 'func': sphere, 'd': 5, 'bounds': (-5., 5.), 'sigma': 0.0, 'N': 30, 'T': 200, 'R': 30},\n        {'func_name': 'sphere', 'func': sphere, 'd': 5, 'bounds': (-5., 5.), 'sigma': 2.0, 'N': 30, 'T': 200, 'R': 30},\n        {'func_name': 'rastrigin', 'func': rastrigin, 'd': 10, 'bounds': (-5.12, 5.12), 'sigma': 0.5, 'N': 40, 'T': 300, 'R': 20},\n        {'func_name': 'rosenbrock', 'func': rosenbrock, 'd': 3, 'bounds': (-2., 2.), 'sigma': 0.2, 'N': 25, 'T': 400, 'R': 20},\n        {'func_name': 'sphere', 'func': sphere, 'd': 5, 'bounds': (-5., 5.), 'sigma': 0.1, 'N': 5, 'T': 50, 'R': 50},\n    ]\n\n    base_seed = 20240901\n    omega = 0.7298\n    c1 = 1.49618\n    c2 = 1.49618\n    \n    results = []\n    \n    # --- Main Execution Loop ---\n    for k, case in enumerate(test_cases):\n        rep_true_values = []\n        for r in range(case['R']):\n            seed = base_seed + 100000 * k + r\n            rng = np.random.default_rng(seed)\n            \n            g_final = pso_run(\n                f_true=case['func'],\n                d=case['d'],\n                L=case['bounds'][0],\n                U=case['bounds'][1],\n                sigma=case['sigma'],\n                N=case['N'],\n                T=case['T'],\n                omega=omega,\n                c1=c1,\n                c2=c2,\n                rng=rng\n            )\n            \n            # Evaluate the true objective function at the final solution\n            # Reshape g_final to (1,d) to be compatible with vectorized functions\n            true_value = case['func'](g_final.reshape(1, -1))[0]\n            rep_true_values.append(true_value)\n            \n        # Calculate the mean over all repetitions\n        mean_result = np.mean(rep_true_values)\n        results.append(mean_result)\n\n    # Final print statement in the exact required format.\n    formatted_results = [f\"{res:.6f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2423094"}, {"introduction": "优化问题并非总是静态的；在许多动态系统中，最优解本身会随时间变化。这个高级实践将你引入动态优化这一激动人心的领域，其目标不再是寻找一个静止的目标，而是追踪一个移动的目标。通过实现一个 PSO 来跟踪一个时变目标函数的最小值，你将学习到粒子群如何适应并持续搜索，这对于实时控制和自适应机器人等应用来说是一项至关重要的能力 [@problem_id:2423115]。", "problem": "给定一个粒子群的离散时间模型，该粒子群在一个时变目标函数下于连续域中演化。在离散时间索引 $t \\in \\{0,1,2,\\dots\\}$ 处的目标函数为\n$$\nf_t(\\mathbf{x}) = \\tfrac{1}{2} \\left(\\mathbf{x} - \\mathbf{x}_{\\min}(t)\\right)^\\top \\mathbf{Q} \\left(\\mathbf{x} - \\mathbf{x}_{\\min}(t)\\right),\n$$\n其中 $\\mathbf{x} \\in \\mathbb{R}^2$，$\\mathbf{Q} = \\operatorname{diag}(q_1,q_2)$ 是正定矩阵，且时变最小化点为\n$$\n\\mathbf{x}_{\\min}(t) = \\begin{bmatrix} a \\sin(\\omega t) \\\\ b \\cos(\\omega t) \\end{bmatrix}.\n$$\n角度以弧度为单位。一个粒子群由 $N$ 个粒子组成，索引为 $i \\in \\{1,\\dots,N\\}$。每个粒子具有位置 $\\mathbf{x}_i(t) \\in \\mathbb{R}^2$ 和速度 $\\mathbf{v}_i(t) \\in \\mathbb{R}^2$。状态在离散时间内同步更新，具体如下。定义每个粒子的个体最优位置 $\\mathbf{p}_i(t)$ 及其对应的最优值 $J_i(t)$ 为\n$$\nJ_i(t) = \\min_{0 \\le \\tau \\le t} f_\\tau(\\mathbf{x}_i(\\tau)), \\quad \\mathbf{p}_i(t) \\in \\arg\\min_{\\substack{0 \\le \\tau \\le t}} f_\\tau(\\mathbf{x}_i(\\tau)),\n$$\n约定当出现平局时，选择最新的时间索引。定义在所有粒子和截至时间 $t$ 的所有时刻中的全局最优位置 $\\mathbf{g}(t)$ 和最优值 $G(t)$ 为\n$$\nG(t) = \\min_{1 \\le i \\le N} J_i(t), \\quad \\mathbf{g}(t) \\in \\arg\\min_{1 \\le i \\le N} J_i(t),\n$$\n约定当出现平局时，选择最小的粒子索引。每个粒子的速度和位置更新如下\n$$\n\\mathbf{v}_i(t{+}1) = w \\,\\mathbf{v}_i(t) + c_1 \\, r_1 \\,\\big(\\mathbf{p}_i(t) - \\mathbf{x}_i(t)\\big) + c_2 \\, r_2 \\,\\big(\\mathbf{g}(t) - \\mathbf{x}_i(t)\\big),\n$$\n$$\n\\mathbf{x}_i(t{+}1) = \\mathbf{x}_i(t) + \\mathbf{v}_i(t{+}1),\n$$\n其中 $w$、$c_1$ 和 $c_2$ 是非负标量，$r_1$ 和 $r_2$ 是固定的确定性标量，等于 $r_1 = r_2 = 0.5$，并相同地应用于每个分量。速度和位置存在逐元素的边界。计算出 $\\mathbf{v}_i(t{+}1)$ 后，将其逐元素地裁剪到区间 $[-v_{\\max}, v_{\\max}]$ 内。计算出 $\\mathbf{x}_i(t{+}1)$ 后，将其逐元素地裁剪到区间 $[-R,R]$ 内。边界足够大，裁剪可能不会被触发，但必须严格按照规定实现裁剪操作。在 $t=0$ 时的初始化使用给定的位置和速度；初始的个体最优位置为 $\\mathbf{p}_i(0) = \\mathbf{x}_i(0)$，其值为 $J_i(0) = f_0(\\mathbf{x}_i(0))$，而初始的全局最优位置 $\\mathbf{g}(0)$ 按上文所述方式选择。\n\n定义瞬时跟踪误差\n$$\ne(t) = \\big\\|\\mathbf{g}(t) - \\mathbf{x}_{\\min}(t)\\big\\|_2,\n$$\n以及在 $T$ 步时间范围内的均方根跟踪误差为\n$$\nE_{\\mathrm{RMS}} = \\sqrt{\\frac{1}{T{+}1} \\sum_{t=0}^{T} e(t)^2 }.\n$$\n\n您的任务是精确地实现上述模型，并对下方的每个测试用例计算 $E_{\\mathrm{RMS}}$，结果为一个四舍五入到恰好6位小数的浮点数。\n\n所有用例的维度均为 $\\mathbb{R}^2$，其中 $\\mathbf{Q} = \\operatorname{diag}(q_1,q_2)$，$q_1 = 2.0$，$q_2 = 1.0$，$a = 1.0$，$b = 0.5$。$\\omega t$ 的角度单位是弧度。所有用例的初始位置和速度均相同，由下式给出\n$$\n\\mathbf{x}_1(0) = \\begin{bmatrix} -0.6 \\\\ -0.6 \\end{bmatrix},\\;\n\\mathbf{x}_2(0) = \\begin{bmatrix} 0.6 \\\\ -0.6 \\end{bmatrix},\\;\n\\mathbf{x}_3(0) = \\begin{bmatrix} -0.6 \\\\ 0.6 \\end{bmatrix},\\;\n\\mathbf{x}_4(0) = \\begin{bmatrix} 0.6 \\\\ 0.6 \\end{bmatrix},\n$$\n$$\n\\mathbf{v}_i(0) = \\begin{bmatrix} 0.0 \\\\ 0.0 \\end{bmatrix} \\text{ for } i \\in \\{1,2,3,4\\}.\n$$\n\n测试套件：\n- 用例1（理想情况，缓慢漂移）：$N = 4$，$T = 60$，$w = 0.70$，$c_1 = 1.50$，$c_2 = 1.50$，$\\omega = 0.10$，$v_{\\max} = 2.00$，$R = 10.00$。\n- 用例2（更快的漂移）：$N = 4$，$T = 60$，$w = 0.70$，$c_1 = 1.50$，$c_2 = 1.50$，$\\omega = 0.30$，$v_{\\max} = 2.00$，$R = 10.00$。\n- 用例3（无社会分量）：$N = 4$，$T = 60$，$w = 0.70$，$c_1 = 1.50$，$c_2 = 0.00$，$\\omega = 0.10$，$v_{\\max} = 2.00$，$R = 10.00$。\n\n您的程序应生成单行输出，其中包含用例1、2、3的 $E_{\\mathrm{RMS}}$ 结果，结果需按顺序排列，形式为一个用方括号括起来的逗号分隔列表，每个数字四舍五入到恰好6位小数，例如：“[0.123456,0.234567,0.345678]”。输出中不应出现任何空格。", "solution": "问题陈述经评估是有效的。这是一个在计算工程学领域内提法恰当、有科学依据的问题，具体涉及在动态环境中模拟粒子群优化（PSO）算法。所有参数、初始条件和程序规则（包括平局处理规则）的定义都具有足够的精度，可以得出一个唯一的、确定性的解。我们将着手构建解法。\n\n任务是模拟一个离散时间PSO算法，并计算其均方根跟踪误差。该环境的特点是一个时变的二次目标函数 $f_t(\\mathbf{x})$，其最小值点在 $\\mathbb{R}^2$ 中描绘出一条椭圆路径。\n\n在时间 $t$ 的目标函数由下式给出：\n$$f_t(\\mathbf{x}) = \\frac{1}{2} (\\mathbf{x} - \\mathbf{x}_{\\min}(t))^\\top \\mathbf{Q} (\\mathbf{x} - \\mathbf{x}_{\\min}(t))$$\n其中最小化点 $\\mathbf{x}_{\\min}(t)$ 的演化如下：\n$$\\mathbf{x}_{\\min}(t) = \\begin{bmatrix} a \\sin(\\omega t) \\\\ b \\cos(\\omega t) \\end{bmatrix}$$\n在指定常数参数 $a=1.0$，$b=0.5$ 和 $\\mathbf{Q} = \\operatorname{diag}(2.0, 1.0)$ 的情况下，对于 $\\mathbf{x} = [x_1, x_2]^\\top$，目标函数可以分量形式写为：\n$$f_t(x_1, x_2) = \\frac{1}{2} \\left( 2.0 \\cdot (x_1 - a \\sin(\\omega t))^2 + 1.0 \\cdot (x_2 - b \\cos(\\omega t))^2 \\right)$$\n\n模拟从初始时间 $t=0$ 迭代进行到最终时间 $t=T$。在任何时间 $t$，粒子群的状态由每个粒子 $i \\in \\{1, \\dots, N\\}$ 的位置 $\\mathbf{x}_i(t)$ 和速度 $\\mathbf{v}_i(t)$，以及它们的个体最优位置 $\\mathbf{p}_i(t)$ 和全局最优位置 $\\mathbf{g}(t)$ 共同描述。\n\n模拟算法如下：\n\n**1. 初始化 ($t=0$)：**\n- 所有 $N=4$ 个粒子的初始位置 $\\mathbf{x}_i(0)$ 和初始速度 $\\mathbf{v}_i(0)$ 均已给定。\n- 在 $t=0$ 时的最小化点为 $\\mathbf{x}_{\\min}(0) = [a \\sin(0), b \\cos(0)]^\\top = [0, 0.5]^\\top$。\n- 对于每个粒子 $i$，其初始个体最优位置是其初始位置，即 $\\mathbf{p}_i(0) = \\mathbf{x}_i(0)$。\n- 对应的个体最优值为 $J_i(0) = f_0(\\mathbf{x}_i(0))$。\n- 初始全局最优值 $G(0)$是所有初始个体最优值中的最小值：$G(0) = \\min_{1 \\le i \\le N} J_i(0)$。\n- 初始全局最优位置 $\\mathbf{g}(0)$ 是达到值 $G(0)$ 且索引最小的粒子 $i^*$ 的个体最优位置 $\\mathbf{p}_{i^*}(0)$。\n- 计算 $t=0$ 时的瞬时跟踪误差 $e(0) = \\|\\mathbf{g}(0) - \\mathbf{x}_{\\min}(0)\\|_2$。其平方 $e(0)^2$ 被存储起来。\n\n**2. 迭代更新 (对 $t = 0, 1, \\dots, T-1$)：**\n在每个时间步 $t$，使用粒子群的状态来计算时间 $t+1$ 的状态。此过程包括两个主要阶段：粒子移动和最优位置评估。\n\n**阶段 A：粒子移动**\n对每个粒子 $i$，计算其在时间 $t+1$ 的速度和位置：\n- 根据 PSO 动力学更新速度向量：\n$$ \\mathbf{v}_i(t{+}1)_{\\text{raw}} = w \\mathbf{v}_i(t) + c_1 r_1 (\\mathbf{p}_i(t) - \\mathbf{x}_i(t)) + c_2 r_2 (\\mathbf{g}(t) - \\mathbf{x}_i(t)) $$\n其中 $r_1=r_2=0.5$ 是固定标量。\n- 将得到的速度向量的每个分量裁剪到区间 $[-v_{\\max}, v_{\\max}]$ 内：\n$$ \\mathbf{v}_i(t{+}1) = \\text{clip}(\\mathbf{v}_i(t{+}1)_{\\text{raw}}, -v_{\\max}, v_{\\max}) $$\n- 使用裁剪后的速度更新位置向量：\n$$ \\mathbf{x}_i(t{+}1)_{\\text{raw}} = \\mathbf{x}_i(t) + \\mathbf{v}_i(t{+}1) $$\n- 将新位置向量的每个分量裁剪到区间 $[-R, R]$ 内：\n$$ \\mathbf{x}_i(t{+}1) = \\text{clip}(\\mathbf{x}_i(t{+}1)_{\\text{raw}}, -R, R) $$\n\n**阶段 B：评估与最优位置更新**\n在所有粒子移动到其新位置 $\\mathbf{x}_i(t+1)$ 后，更新时间 $t+1$ 的目标函数和最优位置：\n- 将目标最小化点更新到其新位置：$\\mathbf{x}_{\\min}(t+1) = [a \\sin(\\omega(t+1)), b \\cos(\\omega(t+1))]^\\top$。\n- 对每个粒子 $i$，计算新的目标值：$f_{t+1}(\\mathbf{x}_i(t+1))$。\n- 将这个新值与粒子的历史最优值 $J_i(t)$ 进行比较。如果 $f_{t+1}(\\mathbf{x}_i(t+1)) \\le J_i(t)$，则更新其个体最优。使用 $\\le$ 实现了偏好最新时间索引的平局处理规则。\n  - $J_i(t+1) = f_{t+1}(\\mathbf{x}_i(t+1))$\n  - $\\mathbf{p}_i(t+1) = \\mathbf{x}_i(t+1)$\n- 否则，个体最优保持不变：$J_i(t+1) = J_i(t)$ 且 $\\mathbf{p}_i(t+1) = \\mathbf{p}_i(t)$。\n- 在所有个体最优都更新后，通过取所有 $J_i(t+1)$ 的最小值来找到新的全局最优值 $G(t+1)$。\n- 新的全局最优位置 $\\mathbf{g}(t+1)$ 是达到 $G(t+1)$ 且索引最小的粒子 $i^*$ 的个体最优位置 $\\mathbf{p}_{i^*}(t+1)$。\n- 计算在 $t+1$ 时的瞬时跟踪误差 $e(t+1) = \\|\\mathbf{g}(t+1) - \\mathbf{x}_{\\min}(t+1)\\|_2$，并存储其平方。\n\n**3. 最终计算：**\n循环完成后（已计算出截至 $t=T$ 的所有状态和误差），在整个时间范围 $t \\in \\{0, \\dots, T\\}$ 上计算均方根跟踪误差：\n$$ E_{\\mathrm{RMS}} = \\sqrt{\\frac{1}{T+1} \\sum_{t=0}^{T} e(t)^2} $$\n对三个测试用例分别执行模拟，这些用例在参数 $\\omega$ 和 $c_2$ 上有所不同。每个用例得到的 $E_{\\mathrm{RMS}}$ 值都四舍五入到6位小数。\n该实现将使用 `numpy` 进行高效的向量和矩阵运算，确保所有计算都以浮点精度执行。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the particle swarm optimization problem for the given test cases.\n    \"\"\"\n\n    def run_pso_simulation(params):\n        \"\"\"\n        Runs a single PSO simulation for a given set of parameters.\n        \"\"\"\n        # Unpack parameters\n        N = params['N']\n        T = params['T']\n        w = params['w']\n        c1 = params['c1']\n        c2 = params['c2']\n        omega = params['omega']\n        v_max = params['v_max']\n        R_max = params['R']\n        \n        # Common parameters\n        q = np.array([2.0, 1.0])\n        Q = np.diag(q)\n        a = 1.0\n        b = 0.5\n        r1, r2 = 0.5, 0.5\n        \n        # Initial conditions\n        x = np.array([\n            [-0.6, -0.6], [0.6, -0.6], [-0.6, 0.6], [0.6, 0.6]\n        ])\n        v = np.zeros((N, 2))\n\n        # Personal best positions and values\n        p_best_pos = np.copy(x)\n        p_best_val = np.full(N, np.inf)\n\n        # Global best position and value\n        g_best_pos = np.zeros(2)\n        # The problem states g(t) is derived from J_i(t). J_i(t) is defined over history.\n        # My p_best_val represents J_i(t). So, I don't need a separate G(t).\n\n        squared_errors = []\n\n        # Simulation loop from t=0 to T\n        for t in range(T + 1):\n            \n            # 1. Update target minimizer for the current time t\n            x_min_t = np.array([a * np.sin(omega * t), b * np.cos(omega * t)])\n            \n            # --- EVALUATION AND BEST UPDATE ---\n            # At t=0, we evaluate initial positions. For t>0, we evaluate positions from previous step.\n            \n            # Evaluate current positions x_i(t) with current objective f_t\n            for i in range(N):\n                delta_x = x[i] - x_min_t\n                cost = 0.5 * delta_x.T @ Q @ delta_x\n                \n                # Update personal best J_i(t)\n                # J_i(t) = min(J_i(t-1), f_t(x_i(t)))\n                # The tie-breaking rule (prefer newer) is handled by '='\n                if cost = p_best_val[i]:\n                    p_best_val[i] = cost\n                    p_best_pos[i] = np.copy(x[i])\n\n            # Update global best g(t) for the current time t\n            # g(t) is the p_best_pos from the particle with the minimum J_i(t)\n            g_best_idx = np.argmin(p_best_val)\n            g_best_pos = p_best_pos[g_best_idx]\n\n            # 2. Calculate and store tracking error e(t)\n            error = np.linalg.norm(g_best_pos - x_min_t)\n            squared_errors.append(error**2)\n\n            # If it's the last iteration, don't calculate the next move.\n            if t == T:\n                break\n                \n            # --- PARTICLE MOVEMENT (to get state for t+1) ---\n            \n            # The global best g(t) to be used for velocity update is the one we just calculated\n            g_t_for_update = g_best_pos\n            \n            for i in range(N):\n                # Update velocity v_i(t+1)\n                cognitive_term = c1 * r1 * (p_best_pos[i] - x[i])\n                social_term = c2 * r2 * (g_t_for_update - x[i])\n                v_new_raw = w * v[i] + cognitive_term + social_term\n                \n                # Clip velocity\n                v[i] = np.clip(v_new_raw, -v_max, v_max)\n                \n                # Update position x_i(t+1)\n                x_new_raw = x[i] + v[i]\n                \n                # Clip position\n                x[i] = np.clip(x_new_raw, -R_max, R_max)\n\n        # 4. Final RMS error calculation\n        e_rms = np.sqrt(np.mean(squared_errors))\n        return e_rms\n\n    test_cases = [\n        # Case 1 (ideal, slow drift)\n        {'N': 4, 'T': 60, 'w': 0.70, 'c1': 1.50, 'c2': 1.50, 'omega': 0.10, 'v_max': 2.00, 'R': 10.00},\n        # Case 2 (faster drift)\n        {'N': 4, 'T': 60, 'w': 0.70, 'c1': 1.50, 'c2': 1.50, 'omega': 0.30, 'v_max': 2.00, 'R': 10.00},\n        # Case 3 (no social component)\n        {'N': 4, 'T': 60, 'w': 0.70, 'c1': 1.50, 'c2': 0.00, 'omega': 0.10, 'v_max': 2.00, 'R': 10.00},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_pso_simulation(case)\n        results.append(f\"{result:.6f}\")\n    \n    # Print the final result in the exact required format\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2423115"}]}