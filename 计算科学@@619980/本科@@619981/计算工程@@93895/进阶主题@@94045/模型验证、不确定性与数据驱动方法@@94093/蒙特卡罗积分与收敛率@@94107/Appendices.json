{"hands_on_practices": [{"introduction": "蒙特卡洛方法的核心优势在于其简洁性，但理解其收敛速度是评估其效率的关键。本练习让你通过数值实验，亲手验证标准蒙特卡洛估计量的收敛率，经验性地确认理论上 $N^{-1/2}$ 的收敛速度。这项实践是掌握蒙特卡洛方法性能分析的基础 [@problem_id:2414889]。", "problem": "一个二维金属板占据了总面积为 $1$ 的单位正方形区域。时间以离散步长进行度量，由 $k \\in \\mathbb{N}$ 索引。在每个时间索引 $k$，该板的边界温度在空间上是均匀的，等于一个随机温度 $X_k$（单位：开尔文），其中 $\\{X_k\\}_{k \\ge 1}$ 是独立同分布的随机变量，其分布由每个测试案例指定。假设相对于边界变化的间隔时间，热传导足够快，因此在每个时间索引 $k$，板的内部温度场在空间上是均匀的，且等于边界温度 $X_k$。因此，在时间索引 $k$ 时，板的空间平均温度等于 $X_k$，而长期平均板温度等于数学期望 $\\mu = \\mathbb{E}[X_1]$（单位：开尔文）。$\\mu$ 的估计是一个关于 $X_1$ 分布的蒙特卡洛积分问题。\n\n对于下述每个测试案例，请考虑以下定义。对于一个正整数 $n$，定义估计量 $\\widehat{\\mu}_n = \\frac{1}{n} \\sum_{i=1}^{n} X_i$，其中 $X_1, \\dots, X_n$ 是从测试案例指定的 $X_1$ 的分布中抽取的独立样本。对于一组样本大小 $\\{n_j\\}_{j=1}^{J}$ 和一个正整数 $R$，为每个 $n_j$ 定义经验平均绝对误差\n$$\nM_{n_j} \\;=\\; \\frac{1}{R} \\sum_{r=1}^{R} \\left| \\widehat{\\mu}^{(r)}_{n_j} - \\mu \\right|,\n$$\n其中 $\\widehat{\\mu}^{(r)}_{n_j}$ 表示 $\\widehat{\\mu}_{n_j}$ 的一次独立重复实验。将经验收敛速率指数 $\\widehat{r}$ 定义为对点 $\\left(x_j, y_j\\right)$（其中 $x_j = \\ln(n_j)$ 且 $y_j = \\ln(M_{n_j})$）进行线性拟合 $y = a + \\widehat{r}\\,x$ 的最小二乘斜率，其中 $\\ln(\\cdot)$ 表示自然对数。量 $\\widehat{r}$ 是无量纲的。每个测试案例还指定了一个用于伪随机数生成器的种子 $s$，以确保可复现性。\n\n测试套件：\n- 测试案例 1：$X_1 \\sim \\mathrm{Uniform}([0,1])$。精确均值为 $\\mu = \\frac{1}{2}$（单位：开尔文）。使用样本大小 $n \\in \\{100, 300, 1000, 3000, 10000\\}$，独立重复实验次数 $R = 400$，以及种子 $s = 12345$。\n- 测试案例 2：$X_1 \\sim \\mathrm{Beta}(\\alpha,\\beta)$，其中 $\\alpha = \\frac{1}{2}$ 且 $\\beta = \\frac{1}{2}$，支撑集为 $[0,1]$。精确均值为 $\\mu = \\frac{\\alpha}{\\alpha+\\beta} = \\frac{1}{2}$（单位：开尔文）。使用样本大小 $n \\in \\{100, 300, 1000, 3000, 10000\\}$，独立重复实验次数 $R = 400$，以及种子 $s = 2023$。\n- 测试案例 3：$X_1$ 是一个两点混合分布：$X_1 = 0$ 的概率为 $p = \\frac{9}{10}$，$X_1 = 1$ 的概率为 $1-p = \\frac{1}{10}$。精确均值为 $\\mu = \\frac{1}{10}$（单位：开尔文）。使用样本大小 $n \\in \\{100, 300, 1000, 3000, 10000\\}$，独立重复实验次数 $R = 400$，以及种子 $s = 777$。\n- 测试案例 4：$X_1 \\sim \\mathrm{Uniform}([0.49, 0.51])$。精确均值为 $\\mu = 0.5$（单位：开尔文）。使用样本大小 $n \\in \\{30, 100, 300, 1000, 3000\\}$，独立重复实验次数 $R = 400$，以及种子 $s = 4242$。\n\n角度单位不适用。所有温度单位均为开尔文。最终报告的量是四个实数 $\\widehat{r}_1, \\widehat{r}_2, \\widehat{r}_3, \\widehat{r}_4$，每个测试案例一个，分别等于上文定义的经验收敛速率指数。将报告的每个数值表示为小数（无百分号），并四舍五入到 $3$ 位小数。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含结果，格式为方括号内以逗号分隔的列表，按测试案例 1 到 4 的顺序排列，例如 $[\\widehat{r}_1,\\widehat{r}_2,\\widehat{r}_3,\\widehat{r}_4]$。", "solution": "问题陈述经评估有效。它在科学上基于蒙特卡洛方法的理论，问题设定完备，提供了所有必要信息，并且其表述客观。不存在不一致、歧义或事实上的不健全之处。\n\n该问题涉及对均值的蒙特卡洛估计量的收敛速率进行数值估计。涉及金属板的物理框架是一个类比；核心任务是统计问题。对于每个测试案例，要求我们使用样本均值估计量 $\\widehat{\\mu}_n = \\frac{1}{n} \\sum_{i=1}^{n} X_i$ 来估计随机变量 $X_1$ 的均值 $\\mu = \\mathbb{E}[X_1]$，该估计基于 $n$ 个独立同分布的样本 $X_1, \\dots, X_n$。\n\n该估计量的收敛速率是计算统计学中的一个核心结果。根据中心极限定理（CLT），对于具有有限均值 $\\mu$ 和有限非零方差 $\\sigma^2 = \\mathrm{Var}(X_1)$ 的独立同分布随机变量序列 $\\{X_i\\}$，样本均值估计量的分布收敛于正态分布。具体来说，当 $n \\to \\infty$ 时，随机变量 $\\sqrt{n}(\\widehat{\\mu}_n - \\mu)$ 在分布上收敛于正态随机变量 $\\mathcal{N}(0, \\sigma^2)$。\n\n这意味着对于较大的 $n$，估计量的误差 $\\widehat{\\mu}_n - \\mu$ 近似服从 $\\mathcal{N}(0, \\sigma^2/n)$ 分布。问题定义了平均绝对误差，其理论值为 $M_n = \\mathbb{E}[|\\widehat{\\mu}_n - \\mu|]$。使用正态近似，我们可以将 $M_n$ 与样本大小 $n$ 联系起来：\n$$\nM_n = \\mathbb{E}[|\\widehat{\\mu}_n - \\mu|] \\approx \\mathbb{E}\\left[\\left|\\frac{\\sigma}{\\sqrt{n}} Z\\right|\\right] = \\frac{\\sigma}{\\sqrt{n}} \\mathbb{E}[|Z|]\n$$\n其中 $Z \\sim \\mathcal{N}(0,1)$ 是一个标准正态随机变量。量 $\\mathbb{E}[|Z|] = \\sqrt{2/\\pi}$ 是一个常数。因此，我们有以下渐近关系：\n$$\nM_n \\propto n^{-1/2}\n$$\n这种比例关系表明，标准蒙特卡洛估计量的平均绝对误差以 $n^{-1/2}$ 的速率收敛到零。\n\n问题要求我们找到这个收敛速率指数的经验估计。这是通过对数变换后的数据点 $(x_j, y_j)$（其中 $x_j = \\ln(n_j)$ 且 $y_j = \\ln(M_{n_j})$）进行线性最小二乘拟合来完成的。对渐近关系取自然对数，得到：\n$$\n\\ln(M_n) \\approx \\ln(C) - \\frac{1}{2} \\ln(n)\n$$\n其中 $C$ 是比例常数。这是一个形式为 $y = a + \\widehat{r} x$ 的线性方程，其理论斜率（收敛速率指数）为 $\\widehat{r} = -1/2 = -0.5$。\n\n对于具有有限方差的分布的函数进行蒙特卡洛积分，这个 $-0.5$ 的理论速率是普适的。测试案例中指定的所有四种分布都具有有限方差：\n1. 对于 $X_1 \\sim \\mathrm{Uniform}([0,1])$，$\\sigma^2 = 1/12$。\n2. 对于 $X_1 \\sim \\mathrm{Beta}(1/2, 1/2)$，$\\sigma^2 = 1/8$。\n3. 对于两点混合分布（一次伯努利试验），$\\sigma^2 = p(1-p) = (1/10)(9/10) = 9/100$。\n4. 对于 $X_1 \\sim \\mathrm{Uniform}([0.49, 0.51])$，$\\sigma^2 = (0.51-0.49)^2/12 = (0.02)^2/12 \\approx 3.33 \\times 10^{-5}$。\n\n由于所有方差都是有限的，因此在所有四个测试案例中，理论收敛速率指数均为 $-0.5$。问题中描述的程序是一个验证此理论速率的数值实验。我们将对每个测试案例实施此程序。\n\n每个测试案例的算法如下：\n1. 为保证可复现性，设置伪随机数生成器的种子 $s$。\n2. 对于给定列表中的每个样本大小 $n_j$：\n    a. 执行 $R$ 次独立的模拟重复实验。\n    b. 在每次重复实验 $r \\in \\{1, \\dots, R\\}$ 中，从指定的 $X_1$ 分布中生成 $n_j$ 个随机样本。\n    c. 计算样本均值 $\\widehat{\\mu}^{(r)}_{n_j}$。\n    d. 计算绝对误差 $|\\widehat{\\mu}^{(r)}_{n_j} - \\mu|$，其中 $\\mu$ 是给定的精确均值。\n    e. 在 $R$ 次重复实验后，计算经验平均绝对误差 $M_{n_j} = \\frac{1}{R} \\sum_{r=1}^{R} |\\widehat{\\mu}^{(r)}_{n_j} - \\mu|$。\n3. 创建一组数据点 $(x_j, y_j)$，其中 $x_j = \\ln(n_j)$ 且 $y_j = \\ln(M_{n_j})$。\n4. 对这些点进行简单线性回归，以找到最佳拟合线 $y = a + \\widehat{r}x$ 的斜率 $\\widehat{r}$。此斜率即为经验收敛速率指数。\n5. 然后将结果四舍五入到 $3$ 位小数。\n\n将对所有四个测试案例执行此程序，以获得值 $\\widehat{r}_1, \\widehat{r}_2, \\widehat{r}_3, \\widehat{r}_4$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Monte Carlo convergence rate problem for all test cases.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"name\": \"Uniform(0,1)\",\n            \"dist_gen\": lambda rng, size: rng.uniform(0, 1, size),\n            \"mu\": 0.5,\n            \"n_values\": [100, 300, 1000, 3000, 10000],\n            \"R\": 400,\n            \"seed\": 12345\n        },\n        {\n            \"name\": \"Beta(0.5, 0.5)\",\n            \"dist_gen\": lambda rng, size: rng.beta(0.5, 0.5, size),\n            \"mu\": 0.5,\n            \"n_values\": [100, 300, 1000, 3000, 10000],\n            \"R\": 400,\n            \"seed\": 2023\n        },\n        {\n            \"name\": \"Two-point mixture\",\n            \"dist_gen\": lambda rng, size: rng.choice([0, 1], size=size, p=[0.9, 0.1]),\n            \"mu\": 0.1,\n            \"n_values\": [100, 300, 1000, 3000, 10000],\n            \"R\": 400,\n            \"seed\": 777\n        },\n        {\n            \"name\": \"Uniform(0.49, 0.51)\",\n            \"dist_gen\": lambda rng, size: rng.uniform(0.49, 0.51, size),\n            \"mu\": 0.5,\n            \"n_values\": [30, 100, 300, 1000, 3000],\n            \"R\": 400,\n            \"seed\": 4242\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        dist_gen = case[\"dist_gen\"]\n        mu = case[\"mu\"]\n        n_values = case[\"n_values\"]\n        R = case[\"R\"]\n        seed = case[\"seed\"]\n\n        rng = np.random.default_rng(seed)\n        \n        log_n_values = []\n        log_M_n_values = []\n\n        for n in n_values:\n            # Store absolute errors for R replicates\n            absolute_errors = np.zeros(R)\n            \n            for r in range(R):\n                # Generate n samples\n                samples = dist_gen(rng, n)\n                # Compute sample mean\n                mu_hat = np.mean(samples)\n                # Compute absolute error\n                absolute_errors[r] = np.abs(mu_hat - mu)\n            \n            # Compute empirical mean absolute error M_n\n            M_n = np.mean(absolute_errors)\n            \n            # Store log-transformed values for regression\n            log_n_values.append(np.log(n))\n            log_M_n_values.append(np.log(M_n))\n            \n        # Perform linear least-squares regression on (log(n), log(M_n))\n        # np.polyfit returns [slope, intercept] for degree 1\n        x = np.array(log_n_values)\n        y = np.array(log_M_n_values)\n        \n        # The slope r_hat is the first element of the result\n        r_hat = np.polyfit(x, y, 1)[0]\n        \n        results.append(r_hat)\n\n    # Format the final output as specified\n    formatted_results = [f\"{r:.3f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2414889"}, {"introduction": "当标准蒙特卡洛方法效率不足时，重要性采样提供了一种强大的优化途径，它通过集中在“重要”区域采样来降低方差。本练习将指导你为同一个积分设计两种不同的重要性采样方案，并从解析上推导和比较它们的性能。通过这个过程，你将深刻理解提议分布的选择对估计器效率的决定性影响 [@problem_id:2414928]。", "problem": "考虑积分\n$$\nI(a) \\;=\\; \\int_{-\\infty}^{\\infty} e^{-x^{2}} \\,\\sin^{2}(a\\,x)\\,dx,\n$$\n其中 $a \\ge 0$ 是一个实值频率参数，角度以弧度为单位。令 $f_{a}(x) = e^{-x^{2}}\\sin^{2}(a\\,x)$ 在 $(-\\infty,\\infty)$ 上。定义 $(-\\infty,\\infty)$ 上的两个绝对连续的提议密度：\n$$\nq_{1}(x) \\;=\\; \\frac{1}{\\sqrt{\\pi}}\\,e^{-x^{2}}, \n\\qquad\nq_{2}(x) \\;=\\; \\frac{1}{\\sqrt{2\\pi}}\\,e^{-x^{2}/2}.\n$$\n对于任何 $a \\ge 0$ 和任何样本量 $N \\in \\mathbb{N}$，考虑基于从 $q(x) \\in \\{q_{1}(x),q_{2}(x)\\}$ 中抽取的独立样本的标准重要性采样估计量 $I(a)$。令单样本重要性权重为 $Y_{q}(a;X) = f_{a}(X)/q(X)$，其中 $X \\sim q$。将估计量表示为 $N$ 个 $Y_{q}(a;X)$ 的独立副本的样本均值。给定 $q$ 和 $N$ 的标准误定义为此估计量的标准差。\n\n您的任务是：\n- 精确推导 $I(a)$。\n- 以闭式形式推导当 $q(x)=q_{1}(x)$ 和 $q(x)=q_{2}(x)$ 时估计量的精确标准误，作为 $a$ 和 $N$ 的函数。\n\n使用您的推导，为以下 $(a,N)$ 对的测试套件计算所需的输出：\n- 测试用例 1：$a = 100$, $N = 10000$。\n- 测试用例 2：$a = 0.5$, $N = 5000$。\n- 测试用例 3：$a = 0$, $N = 1234$。\n\n要求的最终输出格式：\n- 您的程序必须生成一个单行，其中包含一个用方括号括起来的逗号分隔列表。\n- 对于每个测试用例，按给定顺序输出三个实数，顺序如下：精确值 $I(a)$，给定 $N$ 时 $q_{1}(x)$ 的精确标准误，以及给定 $N$ 时 $q_{2}(x)$ 的精确标准误。\n- 因此，最终输出必须是一个长度为 $9$ 的单一列表：\n$$\n\\big[ I(a_{1}),\\ \\mathrm{SE}_{q_{1}}(a_{1},N_{1}),\\ \\mathrm{SE}_{q_{2}}(a_{1},N_{1}),\\ I(a_{2}),\\ \\mathrm{SE}_{q_{1}}(a_{2},N_{2}),\\ \\mathrm{SE}_{q_{2}}(a_{2},N_{2}),\\ I(a_{3}),\\ \\mathrm{SE}_{q_{1}}(a_{3},N_{3}),\\ \\mathrm{SE}_{q_{2}}(a_{3},N_{3}) \\big].\n$$\n所有输出必须是实数（以小数形式）。此问题不涉及物理单位。", "solution": "所述问题在数学和科学上是合理的。其提法恰当、完整且无歧义。因此，我们着手进行求解。\n\n任务是推导一个积分 $I(a)$ 的精确值，以及该积分的两个不同重要性采样估计量的精确标准误。\n\n积分为\n$$I(a) = \\int_{-\\infty}^{\\infty} e^{-x^{2}} \\sin^{2}(a\\,x)\\,dx$$\n其中 $a \\ge 0$。被积函数为 $f_{a}(x) = e^{-x^{2}}\\sin^{2}(a\\,x)$。\n\n**第一部分：$I(a)$ 的精确推导**\n\n为了计算 $I(a)$，我们采用三角恒等式 $\\sin^2(\\theta) = \\frac{1 - \\cos(2\\theta)}{2}$。将其应用于被积函数，得到：\n$$I(a) = \\int_{-\\infty}^{\\infty} e^{-x^{2}} \\left(\\frac{1 - \\cos(2ax)}{2}\\right) dx$$\n我们可以将其分为两个积分：\n$$I(a) = \\frac{1}{2} \\int_{-\\infty}^{\\infty} e^{-x^{2}} dx - \\frac{1}{2} \\int_{-\\infty}^{\\infty} e^{-x^{2}} \\cos(2ax)\\,dx$$\n第一个积分是标准高斯积分，其值是已知的：\n$$\\int_{-\\infty}^{\\infty} e^{-x^{2}} dx = \\sqrt{\\pi}$$\n第二个积分可以通过考虑高斯函数的傅里叶变换来求解。函数 $g(x) = e^{-bx^2}$ 的傅里叶变换由 $\\hat{g}(k) = \\int_{-\\infty}^{\\infty} e^{-bx^2} e^{-ikx} dx = \\sqrt{\\frac{\\pi}{b}} e^{-k^2/(4b)}$ 给出。我们表达式中的积分是这种变换的实部，指数上是正号，对于实偶函数，这会得到相同的结果。\n$$\\int_{-\\infty}^{\\infty} e^{-x^2} \\cos(2ax) dx = \\mathrm{Re}\\left[ \\int_{-\\infty}^{\\infty} e^{-x^2} e^{i(2a)x} dx \\right]$$\n使用傅里叶变换公式，其中 $b=1$ 且 $k=2a$，我们发现：\n$$\\int_{-\\infty}^{\\infty} e^{-x^2} \\cos(2ax) dx = \\sqrt{\\pi} e^{-(2a)^2/4} = \\sqrt{\\pi} e^{-a^2}$$\n将这些结果代入 $I(a)$ 的表达式中，我们得到：\n$$I(a) = \\frac{1}{2} \\sqrt{\\pi} - \\frac{1}{2} \\sqrt{\\pi} e^{-a^2} = \\frac{\\sqrt{\\pi}}{2} (1 - e^{-a^2})$$\n\n**第二部分：标准误的推导**\n\n使用 $N$ 个样本 $X_i \\sim q(x)$ 对 $I(a)$ 的重要性采样估计量是 $\\hat{I}_N = \\frac{1}{N} \\sum_{i=1}^{N} Y_i$，其中 $Y_i = \\frac{f_a(X_i)}{q(X_i)}$ 是独立同分布的随机变量。该估计量的标准误定义为其标准差：\n$$\\mathrm{SE}(\\hat{I}_N) = \\mathrm{Std}\\left( \\frac{1}{N} \\sum_{i=1}^{N} Y_i \\right) = \\frac{\\mathrm{Std}(Y_1)}{\\sqrt{N}} = \\frac{\\sqrt{\\mathrm{Var}(Y_1)}}{\\sqrt{N}}$$\n单个样本 $Y = Y_q(a;X)$ 的方差由 $\\mathrm{Var}(Y) = \\mathbb{E}_{X \\sim q}[Y^2] - (\\mathbb{E}_{X \\sim q}[Y])^2$ 给出。\n$Y$ 的均值为：\n$$\\mathbb{E}_{X \\sim q}[Y] = \\int_{-\\infty}^{\\infty} \\frac{f_a(x)}{q(x)} q(x) dx = \\int_{-\\infty}^{\\infty} f_a(x) dx = I(a)$$\n因此，我们只需要计算二阶矩 $\\mathbb{E}_{X \\sim q}[Y^2]$：\n$$\\mathbb{E}_{X \\sim q}[Y^2] = \\int_{-\\infty}^{\\infty} \\left(\\frac{f_a(x)}{q(x)}\\right)^2 q(x) dx = \\int_{-\\infty}^{\\infty} \\frac{f_a(x)^2}{q(x)} dx$$\n我们必须对每个提议密度 $q_1(x)$ 和 $q_2(x)$ 分别进行此计算。\n\n**情况 1：提议密度 $q_1(x) = \\frac{1}{\\sqrt{\\pi}} e^{-x^2}$**\n\n单样本权重为：\n$$Y_{q_1}(a;x) = \\frac{f_a(x)}{q_1(x)} = \\frac{e^{-x^2} \\sin^2(ax)}{\\frac{1}{\\sqrt{\\pi}} e^{-x^2}} = \\sqrt{\\pi} \\sin^2(ax)$$\n二阶矩为：\n$$\\mathbb{E}[Y_{q_1}^2] = \\int_{-\\infty}^{\\infty} \\frac{(e^{-x^2} \\sin^2(ax))^2}{\\frac{1}{\\sqrt{\\pi}} e^{-x^2}} dx = \\sqrt{\\pi} \\int_{-\\infty}^{\\infty} e^{-x^2} \\sin^4(ax) dx$$\n我们使用降幂恒等式 $\\sin^4(\\theta) = \\frac{3 - 4\\cos(2\\theta) + \\cos(4\\theta)}{8}$。\n$$\\mathbb{E}[Y_{q_1}^2] = \\frac{\\sqrt{\\pi}}{8} \\int_{-\\infty}^{\\infty} e^{-x^2} (3 - 4\\cos(2ax) + \\cos(4ax)) dx$$\n这可以分解为三种先前已确定的积分类型：\n$$\\mathbb{E}[Y_{q_1}^2] = \\frac{\\sqrt{\\pi}}{8} \\left( 3\\int_{-\\infty}^{\\infty} e^{-x^2} dx - 4\\int_{-\\infty}^{\\infty} e^{-x^2}\\cos(2ax)dx + \\int_{-\\infty}^{\\infty} e^{-x^2}\\cos(4ax)dx \\right)$$\n$$\\mathbb{E}[Y_{q_1}^2] = \\frac{\\sqrt{\\pi}}{8} \\left( 3\\sqrt{\\pi} - 4\\sqrt{\\pi}e^{-a^2} + \\sqrt{\\pi}e^{-(2a)^2} \\right) = \\frac{\\pi}{8} (3 - 4e^{-a^2} + e^{-4a^2})$$\n方差为 $\\mathrm{Var}(Y_{q_1}) = \\mathbb{E}[Y_{q_1}^2] - (I(a))^2$：\n$$\\mathrm{Var}(Y_{q_1}) = \\frac{\\pi}{8} (3 - 4e^{-a^2} + e^{-4a^2}) - \\left(\\frac{\\sqrt{\\pi}}{2}(1-e^{-a^2})\\right)^2$$\n$$\\mathrm{Var}(Y_{q_1}) = \\frac{\\pi}{8} (3 - 4e^{-a^2} + e^{-4a^2}) - \\frac{\\pi}{4}(1 - 2e^{-a^2} + e^{-2a^2})$$\n$$\\mathrm{Var}(Y_{q_1}) = \\frac{\\pi}{8} (3 - 4e^{-a^2} + e^{-4a^2} - 2 + 4e^{-a^2} - 2e^{-2a^2}) = \\frac{\\pi}{8} (1 - 2e^{-2a^2} + e^{-4a^2})$$\n这可以简化为一个完全平方：\n$$\\mathrm{Var}(Y_{q_1}) = \\frac{\\pi}{8} (1 - e^{-2a^2})^2$$\n样本量为 $N$ 时的标准误是：\n$$\\mathrm{SE}_{q_1}(a, N) = \\frac{\\sqrt{\\mathrm{Var}(Y_{q_1})}}{\\sqrt{N}} = \\frac{1}{\\sqrt{N}} \\sqrt{\\frac{\\pi}{8}} (1-e^{-2a^2})$$\n由于 $a \\ge 0$，项 $1-e^{-2a^2}$ 是非负的。\n\n**情况 2：提议密度 $q_2(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2}$**\n\n二阶矩积分为：\n$$\\mathbb{E}[Y_{q_2}^2] = \\int_{-\\infty}^{\\infty} \\frac{(e^{-x^2} \\sin^2(ax))^2}{\\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2}} dx = \\sqrt{2\\pi} \\int_{-\\infty}^{\\infty} e^{-2x^2} e^{x^2/2} \\sin^4(ax) dx$$\n$$\\mathbb{E}[Y_{q_2}^2] = \\sqrt{2\\pi} \\int_{-\\infty}^{\\infty} e^{-3x^2/2} \\sin^4(ax) dx$$\n再次使用 $\\sin^4(ax) = \\frac{1}{8} (3 - 4\\cos(2ax) + \\cos(4ax))$，我们有：\n$$\\mathbb{E}[Y_{q_2}^2] = \\frac{\\sqrt{2\\pi}}{8} \\int_{-\\infty}^{\\infty} e^{-3x^2/2} (3 - 4\\cos(2ax) + \\cos(4ax)) dx$$\n我们使用 $\\int_{-\\infty}^{\\infty} e^{-bx^2} \\cos(kx) dx = \\sqrt{\\frac{\\pi}{b}} e^{-k^2/(4b)}$，其中 $b=3/2$ 来计算积分：\n$$\n\\begin{align*}\n\\mathbb{E}[Y_{q_2}^2] &= \\frac{\\sqrt{2\\pi}}{8} \\left( 3\\sqrt{\\frac{\\pi}{3/2}} - 4\\sqrt{\\frac{\\pi}{3/2}}e^{-(2a)^2/(4 \\cdot 3/2)} + \\sqrt{\\frac{\\pi}{3/2}}e^{-(4a)^2/(4 \\cdot 3/2)} \\right) \\\\\n&= \\frac{\\sqrt{2\\pi}}{8} \\sqrt{\\frac{2\\pi}{3}} \\left( 3 - 4e^{-4a^2/6} + e^{-16a^2/6} \\right) \\\\\n&= \\frac{2\\pi}{8\\sqrt{3}} \\left( 3 - 4e^{-2a^2/3} + e^{-8a^2/3} \\right) = \\frac{\\pi}{4\\sqrt{3}} \\left( 3 - 4e^{-2a^2/3} + e^{-8a^2/3} \\right)\n\\end{align*}\n$$\n方差为 $\\mathrm{Var}(Y_{q_2}) = \\mathbb{E}[Y_{q_2}^2] - (I(a))^2$：\n$$\\mathrm{Var}(Y_{q_2}) = \\frac{\\pi}{4\\sqrt{3}} \\left( 3 - 4e^{-2a^2/3} + e^{-8a^2/3} \\right) - \\left( \\frac{\\sqrt{\\pi}}{2}(1-e^{-a^2}) \\right)^2$$\n样本量为 $N$ 时的标准误是：\n$$\\mathrm{SE}_{q_2}(a, N) = \\frac{1}{\\sqrt{N}} \\sqrt{\\frac{\\pi}{4\\sqrt{3}} \\left( 3 - 4e^{-2a^2/3} + e^{-8a^2/3} \\right) - \\frac{\\pi}{4}(1-e^{-a^2})^2}$$\n\n**用于计算的公式摘要**\n1.  **精确积分**: $I(a) = \\frac{\\sqrt{\\pi}}{2} (1 - e^{-a^2})$\n2.  **$q_1$ 的标准误**: $\\mathrm{SE}_{q_1}(a, N) = \\frac{1}{\\sqrt{N}} \\sqrt{\\frac{\\pi}{8}} (1-e^{-2a^2})$\n3.  **$q_2$ 的标准误**: $\\mathrm{SE}_{q_2}(a, N) = \\frac{1}{\\sqrt{N}} \\sqrt{\\frac{\\pi}{4\\sqrt{3}} (3 - 4e^{-2a^2/3} + e^{-8a^2/3}) - \\frac{\\pi}{4}(1-e^{-a^2})^2}$\n\n这些公式将被实现，以计算给定测试用例所需的值。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the exact integral value and standard errors for two Monte Carlo\n    estimators for a given set of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (100, 10000),  # Test case 1: (a=100, N=10000)\n        (0.5, 5000),   # Test case 2: (a=0.5, N=5000)\n        (0, 1234),     # Test case 3: (a=0, N=1234)\n    ]\n\n    results = []\n    \n    # Store constants to avoid recomputation\n    PI = np.pi\n    SQRT_PI = np.sqrt(PI)\n\n    for a, N in test_cases:\n        # Task 1: Calculate the exact value of the integral I(a)\n        # I(a) = (sqrt(pi)/2) * (1 - exp(-a^2))\n        a_sq = a**2\n        i_a = (SQRT_PI / 2.0) * (1.0 - np.exp(-a_sq))\n\n        # Task 2: Calculate the standard error for proposal q1(x)\n        # SE_q1(a, N) = (1/sqrt(N)) * sqrt(pi/8) * (1 - exp(-2*a^2))\n        se_q1 = (1.0 / np.sqrt(N)) * np.sqrt(PI / 8.0) * (1.0 - np.exp(-2.0 * a_sq))\n\n        # Task 3: Calculate the standard error for proposal q2(x)\n        # Var(Y_q2) = E[Y_q2^2] - (I(a))^2\n        # E[Y_q2^2] = (pi / (4*sqrt(3))) * (3 - 4*exp(-2*a^2/3) + exp(-8*a^2/3))\n        e_y2_sq_term1 = np.exp(-2.0 * a_sq / 3.0)\n        e_y2_sq_term2 = np.exp(-8.0 * a_sq / 3.0)\n        e_y2_sq = (PI / (4.0 * np.sqrt(3.0))) * (3.0 - 4.0 * e_y2_sq_term1 + e_y2_sq_term2)\n        \n        # (I(a))^2 term\n        i_a_sq = i_a**2\n        \n        var_y_q2 = e_y2_sq - i_a_sq\n        \n        # Ensure variance is non-negative to handle potential floating point inaccuracies\n        if var_y_q2  0:\n            var_y_q2 = 0.0\n            \n        se_q2 = np.sqrt(var_y_q2) / np.sqrt(N)\n        \n        results.extend([i_a, se_q1, se_q2])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2414928"}, {"introduction": "控制变量是另一种强大的方差缩减技术，其策略是构造一个新的、方差更小的被积函数。在此练习中，你将使用一个多项式作为控制变量，通过最小二乘法拟合原始被积函数，以减少估计误差。这个实践巧妙地融合了统计方法与函数逼近理论，让你亲身体验如何显著提升蒙特卡洛积分的计算精度 [@problem_id:2414893]。", "problem": "你的任务是使用蒙特卡洛（MC）积分来近似单位超立方体 $[0,1]^d$ 上的函数积分，并通过使用基于被积函数的低阶多项式近似的控制变量来加速收敛。对于下面测试套件中的每个测试用例，你的程序必须构建一个全次数多项式控制变量，并评估其相对于普通蒙特卡洛方法的精度影响。\n\n定义与设置：\n- 令 $f: [0,1]^d \\to \\mathbb{R}$ 为一个可积函数，目标积分为 $I = \\int_{[0,1]^d} f(\\boldsymbol{x}) \\,\\mathrm{d}\\boldsymbol{x}$。\n- 一个 $d$ 变量中次数至多为 $k$ 的全次数多项式是形如 $p(\\boldsymbol{x}) = \\sum_{\\lvert \\boldsymbol{\\alpha} \\rvert \\le k} c_{\\boldsymbol{\\alpha}} \\,\\boldsymbol{x}^{\\boldsymbol{\\alpha}}$ 的任意多项式，其中 $\\boldsymbol{\\alpha} \\in \\mathbb{N}_0^d$，$\\lvert \\boldsymbol{\\alpha} \\rvert = \\alpha_1 + \\cdots + \\alpha_d$，且 $\\boldsymbol{x}^{\\boldsymbol{\\alpha}} = \\prod_{j=1}^d x_j^{\\alpha_j}$。\n- 单项式在 $[0,1]^d$ 上的精确积分为 $\\int_{[0,1]^d} \\boldsymbol{x}^{\\boldsymbol{\\alpha}} \\,\\mathrm{d}\\boldsymbol{x} = \\prod_{j=1}^d \\frac{1}{\\alpha_j + 1}$，因此对于 $p(\\boldsymbol{x})$，其精确积分为 $\\mu_p = \\int_{[0,1]^d} p(\\boldsymbol{x}) \\,\\mathrm{d}\\boldsymbol{x} = \\sum_{\\lvert \\boldsymbol{\\alpha} \\rvert \\le k} c_{\\boldsymbol{\\alpha}} \\prod_{j=1}^d \\frac{1}{\\alpha_j + 1}$。\n- 三角函数内部使用的角度必须以弧度为单位进行解释。\n\n对于每个测试用例：\n- 使用从 $[0,1]^d$ 上的均匀分布中独立抽取的 $m_{\\text{fit}}$ 个样本 $\\{\\boldsymbol{Z}_j\\}_{j=1}^{m_{\\text{fit}}}$，以最小二乘意义确定能够最佳拟合数据 $\\{(\\boldsymbol{Z}_j, f(\\boldsymbol{Z}_j))\\}$ 的次数至多为 $k$ 的全次数多项式 $p$ 的系数 $\\{c_{\\boldsymbol{\\alpha}}\\}$。\n- 使用一个从 $[0,1]^d$ 上的均匀分布中独立抽取的包含 $n$ 个样本的集合 $\\{\\boldsymbol{Y}_i\\}_{i=1}^n$ 来计算：\n  - 普通蒙特卡洛估计量 $\\hat{I}_{\\mathrm{MC}} = \\frac{1}{n} \\sum_{i=1}^n f(\\boldsymbol{Y}_i)$，\n  - 控制变量估计量 $\\hat{I}_{\\mathrm{CV}} = \\frac{1}{n} \\sum_{i=1}^n \\big(f(\\boldsymbol{Y}_i) - p(\\boldsymbol{Y}_i)\\big) + \\mu_p$。\n- 对于每个用例，使用给定 $f$ 的精确积分 $I$ 计算每个估计量的绝对误差。然后计算比率 $r = \\frac{\\lvert \\hat{I}_{\\mathrm{CV}} - I \\rvert}{\\lvert \\hat{I}_{\\mathrm{MC}} - I \\rvert}$。\n\n被积函数及其精确积分：\n- 在一维（$d = 1$）中：$f_1(x) = e^{-x} \\cos(7x) + x^3$，其精确积分为\n  $$\n  I_1 = \\int_0^1 e^{-x} \\cos(7x)\\,\\mathrm{d}x + \\int_0^1 x^3\\,\\mathrm{d}x = \\Re\\!\\left(\\frac{e^{-1 + i\\,7} - 1}{-1 + i\\,7}\\right) + \\frac{1}{4}.\n  $$\n- 在二维（$d = 2$）中：$f_2(x,y) = \\sin(\\pi x)\\sin(\\pi y) + x\\,y$，其精确积分为\n  $$\n  I_2 = \\left(\\int_0^1 \\sin(\\pi x)\\,\\mathrm{d}x\\right)^2 + \\left(\\int_0^1 x\\,\\mathrm{d}x\\right)\\left(\\int_0^1 y\\,\\mathrm{d}y\\right) = \\frac{4}{\\pi^2} + \\frac{1}{4}.\n  $$\n\n测试套件：\n- 用例 1：$f_1$，$d = 1$，多项式次数 $k = 3$，$m_{\\text{fit}} = 200$，$n = 20000$，种子 $= 123456$。\n- 用例 2：$f_2$，$d = 2$，多项式次数 $k = 2$，$m_{\\text{fit}} = 500$，$n = 30000$，种子 $= 202311$。\n- 用例 3：$f_1$，$d = 1$，多项式次数 $k = 0$，$m_{\\text{fit}} = 30$，$n = 5000$，种子 $= 7777$。\n- 用例 4：$f_2$，$d = 2$，多项式次数 $k = 1$，$m_{\\text{fit}} = 100$，$n = 20000$，种子 $= 8888$。\n\n要求：\n- 对于每个测试用例，使用给定的种子初始化一个伪随机数生成器，并将其用于该测试用例中的所有抽样。\n- 每个测试用例的最终报告值是上面定义的比率 $r$，四舍五入到 6 位小数。\n- 你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的结果按所列用例的顺序排列，例如 $[r_1,r_2,r_3,r_4]$。", "solution": "该问题是有效的，因为它具有科学依据、是适定的、客观的，并为计算工程中的一个标准问题提供了一套完整且一致的要求。该任务旨在评估用于蒙特卡洛积分的控制变量法的有效性，其中控制变量是被积函数的多项式近似。\n\n蒙特卡洛积分背后的基本原理是大数定律。对于在单位超立方体 $[0,1]^d$ 中均匀分布的随机变量 $\\boldsymbol{X}$，函数值 $f(\\boldsymbol{X})$ 的期望值就是我们希望计算的积分：$E[f(\\boldsymbol{X})] = \\int_{[0,1]^d} f(\\boldsymbol{x}) \\, \\mathrm{d}\\boldsymbol{x} = I$。通过从该分布中抽取 $n$ 个独立同分布的样本 $\\{\\boldsymbol{Y}_i\\}_{i=1}^n$，我们可以构成普通蒙特卡洛估计量，即样本均值：\n$$\n\\hat{I}_{\\mathrm{MC}} = \\frac{1}{n} \\sum_{i=1}^n f(\\boldsymbol{Y}_i)\n$$\n中心极限定理指出，该估计量的误差 $\\hat{I}_{\\mathrm{MC}} - I$ 近似服从均值为 $0$、方差为 $\\sigma_f^2/n$ 的正态分布，其中 $\\sigma_f^2 = \\text{Var}(f(\\boldsymbol{X}))$。因此，标准误差以 $n^{-1/2}$ 的速率下降，这可能是一个较慢的收敛速度。\n\n为了加速收敛，我们可以使用方差缩减技术。控制变量法就是这样一种技术。该方法涉及找到一个函数 $p(\\boldsymbol{x})$，它能很好地近似 $f(\\boldsymbol{x})$，并且其积分 $\\mu_p = \\int_{[0,1]^d} p(\\boldsymbol{x}) \\, \\mathrm{d}\\boldsymbol{x}$ 可以被解析地求出。然后我们将积分 $I$ 重写为：\n$$\nI = \\int_{[0,1]^d} (f(\\boldsymbol{x}) - p(\\boldsymbol{x})) \\, \\mathrm{d}\\boldsymbol{x} + \\int_{[0,1]^d} p(\\boldsymbol{x}) \\, \\mathrm{d}\\boldsymbol{x} = \\int_{[0,1]^d} (f(\\boldsymbol{x}) - p(\\boldsymbol{x})) \\, \\mathrm{d}\\boldsymbol{x} + \\mu_p\n$$\n我们可以对新的、有望性状更好的被积函数 $g(\\boldsymbol{x}) = f(\\boldsymbol{x}) - p(\\boldsymbol{x})$ 应用蒙特卡洛积分。这得到了控制变量估计量：\n$$\n\\hat{I}_{\\mathrm{CV}} = \\frac{1}{n} \\sum_{i=1}^n (f(\\boldsymbol{Y}_i) - p(\\boldsymbol{Y}_i)) + \\mu_p\n$$\n与 $\\hat{I}_{\\mathrm{MC}}$ 一样，这也是 $I$ 的一个无偏估计量。其方差为 $\\text{Var}(\\hat{I}_{\\mathrm{CV}}) = \\frac{1}{n}\\text{Var}(f(\\boldsymbol{X}) - p(\\boldsymbol{X}))$。如果 $p(\\boldsymbol{x})$ 与 $f(\\boldsymbol{x})$ 强相关，那么它们差值的方差就会很小，从而在相同样本量 $n$ 的情况下得到一个更精确的估计量。\n\n该问题指定使用一个次数至多为 $k$ 的全次数多项式作为控制变量 $p(\\boldsymbol{x})$。这样的多项式是单项式基函数的线性组合：$p(\\boldsymbol{x}) = \\sum_{|\\boldsymbol{\\alpha}| \\le k} c_{\\boldsymbol{\\alpha}} \\boldsymbol{x}^{\\boldsymbol{\\alpha}}$。这一选择的动机是 Weierstrass 近似定理，该定理保证了多项式可以在像 $[0,1]^d$ 这样的紧致域上近似任何连续函数。系数 $\\{c_{\\boldsymbol{\\alpha}}\\}$ 通过最小二乘拟合确定。我们生成 $m_{\\text{fit}}$ 个样本 $\\{\\boldsymbol{Z}_j\\}_{j=1}^{m_{\\text{fit}}}$，并找到使平方误差和 $\\sum_{j=1}^{m_{\\text{fit}}} (f(\\boldsymbol{Z}_j) - p(\\boldsymbol{Z}_j))^2$ 最小化的系数 $\\boldsymbol{c}$。这是一个标准的线性回归问题，可公式化为最小化 $\\|\\boldsymbol{A}\\boldsymbol{c} - \\boldsymbol{b}\\|_2^2$，其中设计矩阵 $\\boldsymbol{A}$ 的元素为 $A_{j, \\boldsymbol{\\alpha}} = \\boldsymbol{Z}_j^{\\boldsymbol{\\alpha}}$，目标向量 $\\boldsymbol{b}$ 的元素为 $b_j = f(\\boldsymbol{Z}_j)$。该系统使用数值线性代数程序求解 $\\boldsymbol{c}$。\n\n一旦找到系数 $\\boldsymbol{c}$，就使用提供的公式计算多项式的精确积分 $\\mu_p$：\n$$\n\\mu_p = \\sum_{|\\boldsymbol{\\alpha}| \\le k} c_{\\boldsymbol{\\alpha}} \\left( \\int_{[0,1]^d} \\boldsymbol{x}^{\\boldsymbol{\\alpha}} \\, \\mathrm{d}\\boldsymbol{x} \\right) = \\sum_{|\\boldsymbol{\\alpha}| \\le k} c_{\\boldsymbol{\\alpha}} \\prod_{j=1}^d \\frac{1}{\\alpha_j + 1}\n$$\n\n每个测试用例的求解步骤如下：\n1.  使用指定的种子初始化一个伪随机数生成器。\n2.  定义被积函数 $f(\\boldsymbol{x})$、其维度 $d$、其精确积分 $I$、多项式次数 $k$ 以及样本量 $m_{\\text{fit}}$ 和 $n$。\n3.  生成所有满足 $|\\boldsymbol{\\alpha}| \\le k$ 的多重索引 $\\boldsymbol{\\alpha} \\in \\mathbb{N}_0^d$ 的集合。这些索引定义了多项式基。\n4.  从 $U([0,1]^d)$ 中生成 $m_{\\text{fit}}$ 个随机点 $\\{\\boldsymbol{Z}_j\\}_{j=1}^{m_{\\text{fit}}}$。\n5.  通过在每个点 $\\boldsymbol{Z}_j$ 处评估每个基单项式来构建设计矩阵 $\\boldsymbol{A}$。\n6.  通过评估 $f(\\boldsymbol{Z}_j)$ 来构建目标向量 $\\boldsymbol{b}$。\n7.  求解最小二乘问题 $\\boldsymbol{A}\\boldsymbol{c} \\approx \\boldsymbol{b}$ 以找到系数向量 $\\boldsymbol{c}$。\n8.  计算所得多项式 $p(\\boldsymbol{x})$ 的精确积分 $\\mu_p$。\n9.  从 $U([0,1]^d)$ 中生成第二个独立的、包含 $n$ 个随机点的集合 $\\{\\boldsymbol{Y}_i\\}_{i=1}^n$。\n10. 对这个新集合中的所有点评估 $f(\\boldsymbol{Y}_i)$ 和 $p(\\boldsymbol{Y}_i)$。$p(\\boldsymbol{Y}_i)$ 的值通过为点集 $\\boldsymbol{Y}$ 构建一个设计矩阵并乘以系数向量 $\\boldsymbol{c}$ 来求得。\n11. 计算估计量 $\\hat{I}_{\\mathrm{MC}}$ 和 $\\hat{I}_{\\mathrm{CV}}$。\n12. 计算绝对误差 $|\\hat{I}_{\\mathrm{MC}} - I|$ 和 $|\\hat{I}_{\\mathrm{CV}} - I|$。\n13. 计算比率 $r = \\frac{|\\hat{I}_{\\mathrm{CV}} - I|}{|\\hat{I}_{\\mathrm{MC}} - I|}$ 并将其四舍五入到 6 位小数。该比率量化了使用控制变量带来的精度提升。小于 1 的比率表示有所改进。$k=0$ 的情况作为一个对照组，此时 $p(x)$ 是一个常数，比率 $r$ 预计为 1，这确认了估计量的逻辑是正确的。\n\n对每个测试用例都应用此系统性过程，利用数值库进行随机数生成和求解线性最小二乘问题。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport itertools\nfrom typing import List, Tuple, Callable\n\ndef solve():\n    \"\"\"\n    Solves the Monte Carlo integration problem with control variates for all test cases.\n    \"\"\"\n\n    # Define functions and their exact integrals\n    def f1(x: np.ndarray) - np.ndarray:\n        # x is assumed to be a column vector or a 2D array of shape (N, 1)\n        return np.exp(-x[:, 0]) * np.cos(7 * x[:, 0]) + x[:, 0]**3\n\n    # I1 = Re[ (e^(-1+7i) - 1) / (-1+7i) ] + 1/4\n    # Re part = (1 - e^-1*cos(7) + 7*e^-1*sin(7)) / 50\n    I1_re_part = (1 - np.exp(-1) * np.cos(7) + 7 * np.exp(-1) * np.sin(7)) / 50\n    I1 = I1_re_part + 0.25\n\n    def f2(x: np.ndarray) - np.ndarray:\n        # x is assumed to be an array of shape (N, 2)\n        return np.sin(np.pi * x[:, 0]) * np.sin(np.pi * x[:, 1]) + x[:, 0] * x[:, 1]\n    \n    # I2 = (integral sin(pi*x) dx)^2 + (integral x dx)^2 = (2/pi)^2 + (1/2)^2\n    I2 = 4 / (np.pi**2) + 0.25\n\n    def generate_total_degree_exponents(d: int, k: int) - List[Tuple[int, ...]]:\n        \"\"\"\n        Generates all multi-indices alpha for d variables with total degree = k.\n        \"\"\"\n        if d == 1:\n            return [(i,) for i in range(k + 1)]\n        \n        exponents = []\n        for i in range(k + 1):\n            sub_exponents = generate_total_degree_exponents(d - 1, k - i)\n            for sub_exp in sub_exponents:\n                exponents.append((i,) + sub_exp)\n        return exponents\n\n    def evaluate_monomials(points: np.ndarray, exponents: List[Tuple[int, ...]]) - np.ndarray:\n        \"\"\"\n        Evaluates a basis of monomials at a set of points.\n        points: (n_points, d)\n        exponents: list of alpha tuples\n        Returns: design matrix (n_points, n_exponents)\n        \"\"\"\n        n_points, d = points.shape\n        n_exponents = len(exponents)\n        design_matrix = np.zeros((n_points, n_exponents))\n        \n        for i, alpha in enumerate(exponents):\n            # np.prod(points**alpha, axis=1) is a concise way to compute x^alpha\n            design_matrix[:, i] = np.prod(np.power(points, alpha), axis=1)\n            \n        return design_matrix\n\n    test_cases = [\n        {'f': f1, 'I': I1, 'd': 1, 'k': 3, 'm_fit': 200, 'n': 20000, 'seed': 123456},\n        {'f': f2, 'I': I2, 'd': 2, 'k': 2, 'm_fit': 500, 'n': 30000, 'seed': 202311},\n        {'f': f1, 'I': I1, 'd': 1, 'k': 0, 'm_fit': 30, 'n': 5000, 'seed': 7777},\n        {'f': f2, 'I': I2, 'd': 2, 'k': 1, 'm_fit': 100, 'n': 20000, 'seed': 8888},\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        f, I, d, k, m_fit, n, seed = \\\n            case['f'], case['I'], case['d'], case['k'], case['m_fit'], case['n'], case['seed']\n            \n        rng = np.random.default_rng(seed)\n\n        # Step 1: Generate basis and fit the polynomial control variate\n        exponents = generate_total_degree_exponents(d, k)\n        \n        # Generate samples for fitting\n        Z_points = rng.random((m_fit, d))\n        \n        # Build design matrix and target vector for least-squares\n        A_fit = evaluate_monomials(Z_points, exponents)\n        b_fit = f(Z_points)\n        \n        # Solve for polynomial coefficients\n        c_coeffs, _, _, _ = np.linalg.lstsq(A_fit, b_fit, rcond=None)\n\n        # Step 2: Calculate the exact integral of the polynomial\n        integral_of_monomials = np.array([1.0 / np.prod([exp + 1 for exp in alpha]) for alpha in exponents])\n        mu_p = np.dot(c_coeffs, integral_of_monomials)\n\n        # Step 3: Use an independent sample set for MC estimation\n        Y_points = rng.random((n, d))\n        \n        # Evaluate f and p at the new samples\n        f_Y = f(Y_points)\n        A_eval = evaluate_monomials(Y_points, exponents)\n        p_Y = A_eval @ c_coeffs\n\n        # Step 4: Compute estimators and errors\n        I_hat_mc = np.mean(f_Y)\n        I_hat_cv = np.mean(f_Y - p_Y) + mu_p\n        \n        error_mc = np.abs(I_hat_mc - I)\n        error_cv = np.abs(I_hat_cv - I)\n\n        if error_mc == 0:\n            # This edge case is highly unlikely but robust code should handle it.\n            # If plain MC is perfect, the ratio is either 0 (if CV is also perfect) or infinite.\n            # In the context of performance improvement, if the baseline is perfect, \n            # any non-zero error from the new method is a degradation. If CV is also perfect,\n            # it's no better or worse, ratio could be 1. Let's assume non-zero error for CV.\n            # Given the problem's nature, error_mc will not be zero.\n            ratio = float('inf') if error_cv > 0 else 1.0\n        else:\n            ratio = error_cv / error_mc\n        \n        results.append(round(ratio, 6))\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2414893"}]}