{"hands_on_practices": [{"introduction": "在深入研究复杂的数值问题之前，为一个已知精确解的简单情况精确计算局部截断误差（LTE）是很有启发性的。这个练习使用一个二次多项式作为解，来揭示LTE、步长 $h$ 与解的二阶导数之间的直接关系，从而清晰地阐明了为什么LTE的阶为 $O(h^2)$。", "problem": "考虑一个常微分方程 (ODE) 的初值问题 $y^{\\prime}(t)=f(t,y(t))$，其在一个区间上的精确解是二次多项式 $y(t)=a t^{2}+b t+c$，其中 $a$、$b$ 和 $c$ 是实常数。从 $t_{n}$ 到 $t_{n+1}=t_{n}+h$，应用步长为 $h>0$ 的单步前向欧拉法。将第 $n$ 步的局部截断误差 (LTE) 定义为\n$$\\tau_{n+1}=y(t_{n+1})-\\big(y(t_{n})+h\\,f(t_{n},y(t_{n}))\\big).$$\n确定 $\\tau_{n+1}$ 作为 $a$ 和 $h$ 的函数的精确封闭形式表达式。请以单个解析表达式的形式提供最终答案。", "solution": "在尝试求解之前，问题陈述需要进行严格验证。\n\n第 1 步：提取已知条件\n已知条件如下：\n- 该初值问题是针对一个常微分方程 (ODE)：$y^{\\prime}(t)=f(t,y(t))$。\n- 该 ODE 的精确解是一个二次多项式：$y(t)=a t^{2}+b t+c$，其中 $a$、$b$ 和 $c$ 为实常数。\n- 数值方法是步长为 $h>0$ 的单步前向欧拉法，从 $t_{n}$ 到 $t_{n+1}=t_{n}+h$。\n- 局部截断误差 (LTE) 的定义为：$\\tau_{n+1}=y(t_{n+1})-\\big(y(t_{n})+h\\,f(t_{n},y(t_{n}))\\big)$。\n- 目标是求出 $\\tau_{n+1}$ 作为 $a$ 和 $h$ 的函数的精确封闭形式表达式。\n\n第 2 步：使用提取的已知条件进行验证\n对该问题进行验证：\n- **科学依据**：该问题基于常微分方程数值分析的基本概念，特别是前向欧拉法及其局部截断误差。这些是计算科学与工程领域的标准、成熟的课题。问题的前提在事实上是可靠的。\n- **适定性**：该问题提供了所有必要的定义和信息。函数 $f(t,y)$ 由精确解 $y(t)$ 隐式定义，因为条件 $y'(t) = f(t,y(t))$ 必须在区间内对所有 $t$ 成立。目标明确，且预期有唯一解。\n- **客观性**：该问题以精确的数学语言陈述，没有歧义或主观论断。\n\n该问题没有表现出任何科学上不合理、信息缺失或逻辑矛盾等缺陷。这是其领域内一个标准的、适定的问题。\n\n第 3 步：结论与行动\n问题有效。将提供解答。\n\n单步前向欧拉法的局部截断误差 (LTE) 定义为：\n$$\n\\tau_{n+1} = y(t_{n+1}) - \\left( y(t_n) + h f(t_n, y(t_n)) \\right)\n$$\n此处，$y(t)$ 代表常微分方程 $y'(t) = f(t, y(t))$ 的精确解。因此，函数 $f$ 在精确解轨道上一点 $(t_n, y(t_n))$ 的取值，就是精确解在该点的导数 $y'(t_n)$。\n$$\nf(t_n, y(t_n)) = y'(t_n)\n$$\n将此代入 LTE 的定义中，我们得到：\n$$\n\\tau_{n+1} = y(t_{n+1}) - y(t_n) - h y'(t_n)\n$$\n问题陈述精确解为二次多项式：\n$$\ny(t) = a t^2 + b t + c\n$$\n我们必须先计算 $y(t)$ 的导数：\n$$\ny'(t) = \\frac{d}{dt}(a t^2 + b t + c) = 2 a t + b\n$$\n现在，我们用这些表达式计算 $y(t_{n+1})$、$y(t_n)$ 和 $y'(t_n)$ 各项的值。点 $t_{n+1}$ 定义为 $t_{n+1} = t_n + h$。\n精确解在 $t_n$ 处的值是：\n$$\ny(t_n) = a t_n^2 + b t_n + c\n$$\n精确解在 $t_{n+1}$ 处的值是：\n$$\ny(t_{n+1}) = y(t_n + h) = a(t_n + h)^2 + b(t_n + h) + c\n$$\n展开此表达式，我们得到：\n$$\ny(t_{n+1}) = a(t_n^2 + 2 t_n h + h^2) + b t_n + b h + c = a t_n^2 + 2 a t_n h + a h^2 + b t_n + b h + c\n$$\n精确解的导数在 $t_n$ 处的值是：\n$$\ny'(t_n) = 2 a t_n + b\n$$\n现在，我们将这三个表达式代入 $\\tau_{n+1}$ 的公式中：\n$$\n\\tau_{n+1} = (a t_n^2 + 2 a t_n h + a h^2 + b t_n + b h + c) - (a t_n^2 + b t_n + c) - h(2 a t_n + b)\n$$\n我们进行代数化简。首先，分配 $-h$ 项：\n$$\n\\tau_{n+1} = a t_n^2 + 2 a t_n h + a h^2 + b t_n + b h + c - a t_n^2 - b t_n - c - 2 a t_n h - b h\n$$\n接下来，我们合并并消去同类项：\n$$\n\\tau_{n+1} = (a t_n^2 - a t_n^2) + (2 a t_n h - 2 a t_n h) + (b t_n - b t_n) + (b h - b h) + (c - c) + a h^2\n$$\n除 $a h^2$ 外，所有项都消去了。\n$$\n\\tau_{n+1} = a h^2\n$$\n这个结果与 $t_n$、$b$ 和 $c$ 无关，仅取决于二次项的系数 $a$ 和步长 $h$。这就是所要求的局部截断误差的精确封闭形式表达式。这个结果与数值方法的一般理论相符，该理论指出前向欧拉法的局部截断误差为 $O(h^2)$ 阶，具体为 $\\tau_{n+1} = \\frac{h^2}{2} y''(t_n) + O(h^3)$。对于 $y(t) = a t^2 + b t + c$，我们有 $y''(t) = 2a$，且所有更高阶的导数均为零，因此一般公式给出 $\\tau_{n+1} = \\frac{h^2}{2} (2a) = a h^2$，这证实了我们的直接计算。", "answer": "$$\\boxed{a h^{2}}$$", "id": "2395171"}, {"introduction": "在现实世界的场景中，我们通常不知道微分方程的精确解。这个练习介绍了一种强大的计算技术，通过分析“黑箱”求解器在不同步长下的输出，来确定其方法的阶数。这是一种用于验证和比较数值求解器的关键技能，其核心思想是比较单次大步长和两次小步长的计算结果。", "problem": "考虑形式为 $\\dfrac{dy}{dt} = f(t,y)$ 且满足 $y(t_0)=y_0$ 的初值问题，以及一个将 $(t_n,y_n)$ 映射到 $(t_{n+1},y_{n+1})$（其中 $t_{n+1}=t_n+h$）的单步求解器。局部截断误差 (LTE) 定义为从精确状态开始，在单个步骤中产生的误差，即 $t_0+h$ 处的精确解与求解器从 $(t_0,y(t_0))$ 出发得到的单步输出之间的差值。您只能访问求解器在不同步长下的输出，并且必须从第一性原理出发，判断当 $h \\to 0$ 时，LTE 是否按 $O(h^2)$ 的比例缩放，这是前向欧拉法的特征。\n\n您的任务是：\n- 构建一个可观测量，该量只依赖于从 $t_0$ 处的相同初始数据开始、步长分别为 $h$ 和 $h/2$ 时的求解器输出，并能反映在区间 $[t_0,t_0+h]$ 上的单步不精确性。\n- 对于一个步长序列 $(h_j)$（其中 $h_{j+1} = h_j/2$），在 $h \\to 0$ 时，经验性地拟合一个形式为 $\\lVert \\text{observable}(h) \\rVert \\approx C h^r$ 的幂律，并通过在对数尺度上进行最小二乘拟合来估计指数 $r$。对于标量问题，使用绝对值；对于向量值问题，使用欧几里得范数。\n- 当且仅当估计的指数 $r$ 约等于 $2$（在数值容差范围内）时，得出 LTE 为 $O(h^2)$ 的结论。\n\n设计您的程序，对四个测试用例执行此分析。在所有用例中，角度（如果有）均以弧度为单位。\n\n测试套件：\n- 测试 $1$ (标量，线性)：$f(t,y) = -2y$, $t_0=0$, $y_0=1$, 步长 $h \\in \\{0.2, 0.1, 0.05, 0.025, 0.0125\\}$。\n- 测试 $2$ (标量，非线性)：$f(t,y) = y^2 - y$, $t_0=0$, $y_0=0.3$, 步长 $h \\in \\{0.2, 0.1, 0.05, 0.025, 0.0125\\}$。\n- 测试 $3$ (向量，线性旋转)：$f(t,y) = \\begin{bmatrix}-y_2 \\\\ y_1\\end{bmatrix}$ 对于 $y=\\begin{bmatrix}y_1\\\\y_2\\end{bmatrix}$, $t_0=0$, $y_0=\\begin{bmatrix}1\\\\0\\end{bmatrix}$, 步长 $h \\in \\{0.2, 0.1, 0.05, 0.025, 0.0125\\}$。\n- 测试 $4$ (标量，小步长压力测试)：$f(t,y) = -2y$, $t_0=0$, $y_0=1$, 步长 $h \\in \\{2^{-10}, 2^{-11}, 2^{-12}, 2^{-13}, 2^{-14}\\}$。\n\n实现要求：\n- 将求解器视为一个黑箱；对于每个 $h$，您只能使用从 $(t_0,y_0)$ 开始、在指定步长下的单步输出来构建您的可观测量。\n- 对每个测试，通过对所有给定 $h$ 的 $\\log(\\lVert \\text{observable}(h) \\rVert)$ 与 $\\log(h)$ 的关系进行最小二乘拟合来计算估计的指数 $r$。\n- 您的程序必须生成单行输出，该输出为一个逗号分隔的列表，包含四个估计的指数，并用方括号括起来，每个值都四舍五入到三位小数（例如，$[2.000,2.000,2.000,2.000]$）。\n\n您的输出必须是数值且无单位。不提供外部输入；所有计算必须按上述规定在程序内部执行。最终输出格式严格为一行，并使用所述的列表表示法。", "solution": "所述问题是有效的。它在科学上基于常微分方程数值分析的原理，问题提法清晰，目标和方法明确，没有矛盾或含糊之处。我们将着手进行形式化的求解。\n\n目标是设计并实现一个数值程序，用以验证一个单步求解器（假定为前向欧拉法）的局部截断误差 (LTE) 的阶。假设是 LTE 的阶为 $O(h^2)$，其中 $h$ 是步长。\n\n一个初值问题 (IVP) 由微分方程 $\\dfrac{dy}{dt} = f(t,y)$ 和一个初始条件 $y(t_0)=y_0$ 给出。前向欧拉法在离散时间点 $t_n = t_0 + nh$ 上生成一系列对精确解 $y(t_n)$ 的近似值 $y_n$。其更新规则是：\n$$y_{n+1} = y_n + h f(t_n, y_n)$$\n\n局部截断误差，我们记为 $\\tau(h)$，是在假设该步从精确解 $y_n = y(t_n)$ 开始时，单步内产生的误差。其定义为：\n$$\\tau(h) = y(t_n + h) - y_{n+1}$$\n为了确定这个误差的阶，我们对精确解 $y(t_n + h)$ 在 $t_n$ 附近进行泰勒级数展开：\n$$y(t_n + h) = y(t_n) + h y'(t_n) + \\frac{h^2}{2} y''(t_n) + O(h^3)$$\n根据初值问题的定义，$y'(t_n) = f(t_n, y(t_n))$。将此式和 $y_{n+1}$ 的前向欧拉公式代入 LTE 的定义中，我们得到：\n$$ \\tau(h) = \\left( y(t_n) + h f(t_n, y(t_n)) + \\frac{h^2}{2} y''(t_n) + O(h^3) \\right) - \\left( y(t_n) + h f(t_n, y(t_n)) \\right) $$\n$$ \\tau(h) = \\frac{h^2}{2} y''(t_n) + O(h^3) $$\n这证实了前向欧拉法的 LTE 确实是 $O(h^2)$ 阶的。\n\n问题的核心是在无法获得精确解 $y(t_n+h)$ 及其导数的情况下验证这一性质。我们的任务是仅使用“黑箱”求解器的输出来构建一个可观测量。一种标准技术是，从相同的初始状态 $(t_0, y_0)$ 出发，比较步长为 $h$ 的单步结果与步长为 $h/2$ 的两个连续步骤的结果。\n\n我们定义在时间 $t_0+h$ 处解的两种近似：\n$1$. 步长为 $h$ 的单步：\n$$y_h = y_0 + h f(t_0, y_0)$$\n$2$. 步长为 $h/2$ 的两个连续步骤：\n$$y'_{h/2} = y_0 + \\frac{h}{2} f(t_0, y_0)$$\n$$y_{h/2,2} = y'_{h/2} + \\frac{h}{2} f\\left(t_0 + \\frac{h}{2}, y'_{h/2}\\right)$$\n我们的可观测量 $E(h)$ 是这两种近似之间的差值：\n$$E(h) = y_h - y_{h/2,2}$$\n为了求出 $E(h)$ 的阶，我们使用 $f$ 在 $(t_0, y_0)$ 附近的泰勒级数来展开 $y_{h/2,2}$：\n$$f\\left(t_0 + \\frac{h}{2}, y'_{h/2}\\right) = f(t_0, y_0) + \\frac{h}{2} \\frac{\\partial f}{\\partial t} + (y'_{h/2} - y_0) \\frac{\\partial f}{\\partial y} + O(h^2)$$\n代入 $y'_{h/2} - y_0 = \\frac{h}{2} f(t_0, y_0)$ 可得：\n$$f\\left(t_0 + \\frac{h}{2}, y'_{h/2}\\right) = f_0 + \\frac{h}{2} \\left( \\frac{\\partial f}{\\partial t} + f_0 \\frac{\\partial f}{\\partial y} \\right) + O(h^2) = f_0 + \\frac{h}{2} y''(t_0) + O(h^2)$$\n其中 $f_0 = f(t_0, y_0)$。将此式代回 $y_{h/2,2}$ 的表达式中：\n$$y_{h/2,2} = \\left(y_0 + \\frac{h}{2}f_0\\right) + \\frac{h}{2}\\left(f_0 + \\frac{h}{2} y''(t_0) + O(h^2)\\right) = y_0 + h f_0 + \\frac{h^2}{4} y''(t_0) + O(h^3)$$\n现在我们计算可观测量 $E(h)$：\n$$E(h) = (y_0 + h f_0) - \\left(y_0 + h f_0 + \\frac{h^2}{4} y''(t_0) + O(h^3)\\right) = - \\frac{h^2}{4} y''(t_0) + O(h^3)$$\n这表明对于小的 $h$，我们的可观测量的范数与 $h$ 的二次方成比例：\n$$\\lVert E(h) \\rVert \\approx K h^2$$\n其中 $K = \\frac{1}{4} \\lVert y''(t_0) \\rVert$。为了估计我们称之为 $r$ 的指数，我们分析关系 $\\lVert E(h) \\rVert \\approx K h^r$。对两边取自然对数，我们得到一个线性关系：\n$$\\log(\\lVert E(h) \\rVert) \\approx \\log(K) + r \\log(h)$$\n这是一个形式为 $Y = A + rX$ 的方程，其中 $Y = \\log(\\lVert E(h) \\rVert)$，$X = \\log(h)$，以及 $A = \\log(K)$。给定一系列递减步长 $h_j$ 的测量值 $(h_j, \\lVert E(h_j) \\rVert)$，我们可以对转换后的数据点 $(\\log(h_j), \\log(\\lVert E(h_j) \\rVert))$ 进行线性最小二乘回归，以求得斜率 $r$。如果 $r$ 约等于 $2$，我们就可以得出结论：该可观测量按 $h^2$ 比例缩放，这反过来支持了求解器的 LTE 是 $O(h^2)$ 的假设。\n\n程序将对四个指定的测试用例实施此过程。对于每个用例，它将：\n$1$. 遍历给定的步长序列 $h_j$。\n$2$. 对于每个 $h_j$，使用前向欧拉规则计算 $y_{h_j}$ 和 $y_{h_j/2, 2}$。\n$3$. 计算可观测量 $E(h_j) = y_{h_j} - y_{h_j/2, 2}$ 的范数。使用欧几里得范数，对于标量问题，这对应于绝对值。\n$4$. 收集范数的对数和步长的对数。\n$5$. 对对数-对数数据进行一阶多项式（线性）拟合，以求得斜率 $r$。\n$6$. 报告每个测试用例的估计指数 $r$，四舍五入到三位小数。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Performs an analysis to numerically estimate the order of the local\n    truncation error for the forward Euler method on four test cases.\n    \"\"\"\n\n    # Define the right-hand side functions for the ODEs dy/dt = f(t, y)\n    def f_case1(t, y):\n        return -2 * y\n\n    def f_case2(t, y):\n        return y**2 - y\n\n    def f_case3(t, y):\n        # y is expected to be a numpy array [y1, y2]\n        return np.array([-y[1], y[0]])\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"f\": f_case1,\n            \"t0\": 0.0,\n            \"y0\": 1.0,\n            \"h_values\": np.array([0.2, 0.1, 0.05, 0.025, 0.0125]),\n        },\n        {\n            \"f\": f_case2,\n            \"t0\": 0.0,\n            \"y0\": 0.3,\n            \"h_values\": np.array([0.2, 0.1, 0.05, 0.025, 0.0125]),\n        },\n        {\n            \"f\": f_case3,\n            \"t0\": 0.0,\n            \"y0\": np.array([1.0, 0.0]),\n            \"h_values\": np.array([0.2, 0.1, 0.05, 0.025, 0.0125]),\n        },\n        {\n            \"f\": f_case1,  # Same f as Test 1\n            \"t0\": 0.0,\n            \"y0\": 1.0,\n            \"h_values\": np.array([2**-10, 2**-11, 2**-12, 2**-13, 2**-14]),\n        },\n    ]\n\n    estimated_exponents = []\n    for case in test_cases:\n        f = case[\"f\"]\n        t0 = case[\"t0\"]\n        y0 = case[\"y0\"]\n        h_values = case[\"h_values\"]\n        \n        observable_norms = []\n        \n        for h in h_values:\n            # The 'black-box' solver is the forward Euler method. We apply it\n            # once for a step of size h, and twice for steps of size h/2.\n            \n            # 1. One step of size h\n            y_h = y0 + h * f(t0, y0)\n            \n            # 2. Two steps of size h/2\n            h_half = h / 2.0\n            y_h_half_1 = y0 + h_half * f(t0, y0)  # First half-step\n            y_h_half_2 = y_h_half_1 + h_half * f(t0 + h_half, y_h_half_1) # Second half-step\n            \n            # 3. Construct the observable and compute its norm.\n            # The observable is the difference between the two approximations.\n            observable = y_h - y_h_half_2\n            \n            # The norm is the Euclidean norm (absolute value for scalars).\n            norm_obs = np.linalg.norm(observable)\n            observable_norms.append(norm_obs)\n        \n        # 4. Perform least-squares fit on logarithmic scales.\n        # The equation is log(norm) = r * log(h) + log(C).\n        # We find the slope 'r' of this linear relationship.\n        log_h = np.log(h_values)\n        log_err = np.log(np.array(observable_norms))\n        \n        # np.polyfit for a degree 1 polynomial returns [slope, intercept].\n        # The slope is the desired exponent 'r'.\n        slope, _ = np.polyfit(log_h, log_err, 1)\n        \n        estimated_exponents.append(slope)\n\n    # Final print statement in the exact required format.\n    formatted_results = [f\"{r:.3f}\" for r in estimated_exponents]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2395168"}]}