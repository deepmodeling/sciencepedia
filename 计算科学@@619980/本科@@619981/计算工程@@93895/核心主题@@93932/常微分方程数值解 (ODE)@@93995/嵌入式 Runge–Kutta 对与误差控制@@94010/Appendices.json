{"hands_on_practices": [{"introduction": "理论的基石是能够被验证。本练习旨在通过一个精心设计的常微分方程，让你亲手解剖嵌入式龙格-库塔对中的误差估计器，从而揭开其神秘面纱。通过分析一个具有分段多项式精确解的简单问题，我们将能够精确计算出单步积分的真实局部截断误差和求解器给出的嵌入式误差估计值，并直接比较两者，从而深刻理解误差估计器的工作原理及其与真实误差之间的定量关系 [@problem_id:2388725]。", "problem": "考虑一个右端项为分段多项式的常微分方程（ODE）的初值问题：\n$$\n\\frac{dy}{dt} = f(t), \\quad y(0)=0,\n$$\n其中\n$$\nf(t) = \\begin{cases}\nt^{2}, & 0 \\le t \\le \\frac{1}{2} \\\\\n\\frac{1}{4} + \\left(t - \\frac{1}{2}\\right), & \\frac{1}{2} < t \\le 1.\n\\end{cases}\n$$\n该右端项确保了解析解 $y(t)$ 在 $[0,1]$ 上是一个简单的分段多项式。\n\n一个数值求解器采用了一个嵌入式 Runge–Kutta (RK) 对，该方法对由一阶显式 Euler 方法和二阶 Heun 方法组成。对于从 $t_{0}=0$ 到 $t_{1}=h$（其中 $0<h<\\frac{1}{2}$）的单步，该方法对定义如下：\n$$\nk_{1} = f(t_{0}, y_{0}), \\quad k_{2} = f\\!\\left(t_{0}+h,\\, y_{0} + h k_{1}\\right),\n$$\n$$\ny^{[1]}_{1} = y_{0} + h k_{1}, \\quad y^{[2]}_{1} = y_{0} + \\frac{h}{2}\\left(k_{1}+k_{2}\\right),\n$$\n并且求解器的嵌入式局部误差估计为\n$$\n\\hat{e}_{1} = y^{[2]}_{1} - y^{[1]}_{1}.\n$$\n\n使用精确解 $y(t)$（即，从精确值 $y_{0}=y(0)$ 开始单步计算），确定精确比值\n$$\nR = \\frac{y(t_{1}) - y^{[1]}_{1}}{\\hat{e}_{1}},\n$$\n即，一阶更新的真实局部截断误差与该步求解器的嵌入式估计之比。请以单个最简分数的形式给出您的答案。无需四舍五入。", "solution": "问题陈述已经过验证，被认为是具有科学依据、适定且客观的。这是常微分方程数值分析中的一个标准问题，包含了获得唯一解所需的所有信息。其中没有矛盾或歧义。我们将开始推导。\n\n任务是确定精确比值 $R = \\frac{y(t_{1}) - y^{[1]}_{1}}{\\hat{e}_{1}}$，其中 $y(t_{1})$ 是在时间 $t_{1}$ 处的精确解，$y^{[1]}_{1}$ 是由一阶方法得到的数值近似值，而 $\\hat{e}_{1}$ 是嵌入式误差估计。单步计算从 $t_{0}=0$ 到 $t_{1}=h$，约束条件为 $0 < h < \\frac{1}{2}$。初始条件是 $y(0)=0$。\n\n首先，我们确定初值问题（IVP）的精确解 $y(t)$。该IVP由下式给出\n$$\n\\frac{dy}{dt} = f(t), \\quad y(0)=0.\n$$\n对于积分区间 $[0, h]$，由于 $h < \\frac{1}{2}$，右端函数由第一种情况给出：\n$$\nf(t) = t^{2}, \\quad \\text{for } t \\in [0, h].\n$$\n我们通过直接积分来求解这个简化的ODE：\n$$\ny(t) = \\int_{0}^{t} f(s) ds = \\int_{0}^{t} s^{2} ds = \\left[ \\frac{s^{3}}{3} \\right]_{0}^{t} = \\frac{t^{3}}{3}.\n$$\n在步长末端 $t_{1}=h$ 处，解的精确值为\n$$\ny(t_{1}) = y(h) = \\frac{h^{3}}{3}.\n$$\n\n接下来，我们使用给定的嵌入式 Runge–Kutta 对计算数值近似值。该步从 $(t_{0}, y_{0})$ 开始，其中 $t_{0}=0$ 且 $y_{0}=y(0)=0$。\n\n阶段值 $k_{1}$ 和 $k_{2}$ 的计算如下：\n第一阶段值为：\n$$\nk_{1} = f(t_{0}, y_{0}) = f(0, 0) = 0^{2} = 0.\n$$\n注意，对于这个问题，$f$ 只是 $t$ 的函数，所以 $f(t, y) = f(t)$。\n第二阶段值为：\n$$\nk_{2} = f(t_{0}+h, y_{0} + h k_{1}) = f(0+h, 0 + h \\cdot 0) = f(h) = h^{2}.\n$$\n\n现在我们求在 $t_{1}=h$ 处解的两个数值近似值。\n使用显式 Euler 方法得到的一阶近似值 $y^{[1]}_{1}$ 为：\n$$\ny^{[1]}_{1} = y_{0} + h k_{1} = 0 + h(0) = 0.\n$$\n使用 Heun 方法得到的二阶近似值 $y^{[2]}_{1}$ 为：\n$$\ny^{[2]}_{1} = y_{0} + \\frac{h}{2}(k_{1}+k_{2}) = 0 + \\frac{h}{2}(0 + h^{2}) = \\frac{h^{3}}{2}.\n$$\n\n利用这些结果，我们可以计算比值 $R$ 所需的各项。\n分子是一阶（Euler）方法的真实局部截断误差：\n$$\ny(t_{1}) - y^{[1]}_{1} = y(h) - y^{[1]}_{1} = \\frac{h^{3}}{3} - 0 = \\frac{h^{3}}{3}.\n$$\n分母是求解器的嵌入式局部误差估计：\n$$\n\\hat{e}_{1} = y^{[2]}_{1} - y^{[1]}_{1} = \\frac{h^{3}}{2} - 0 = \\frac{h^{3}}{2}.\n$$\n\n最后，我们计算比值 $R$：\n$$\nR = \\frac{y(t_{1}) - y^{[1]}_{1}}{\\hat{e}_{1}} = \\frac{\\frac{h^{3}}{3}}{\\frac{h^{3}}{2}}.\n$$\n由于 $h > 0$，$h^{3}$ 项从分子和分母中消去：\n$$\nR = \\frac{1/3}{1/2} = \\frac{1}{3} \\cdot \\frac{2}{1} = \\frac{2}{3}.\n$$\n这个结果与步长 $h$（在指定范围内）无关，并且是一个最简分数，符合要求。", "answer": "$$\n\\boxed{\\frac{2}{3}}\n$$", "id": "2388725"}, {"introduction": "从理论到实践的飞跃，在于亲手构建和测试。本练习将指导你编写一个完整的自适应步长积分器，并在此过程中通过一个“破坏性实验”来加深理解。你将实现一个标准的自适应控制器，并将其与一个使用了错误误差估计系数的“有缺陷”版本进行对比，从而直观地观察到局部误差估计的微小偏差如何影响最终的全局求解精度 [@problem_id:2388676]。这项实践不仅能锻炼你的编程能力，更能让你切身体会到数值算法中“魔鬼在细节”的道理。", "problem": "设计并实现一个基于嵌入式 Runge–Kutta 方法对的自适应步长积分器，用以研究不正确的局部误差估计如何影响全局误差。纯粹在常微分方程初值问题的数学设定下进行。您必须使用的基本依据是初值问题的定义、局部截断误差以及显式 Runge-Kutta 方法的结构。\n\n问题要求：\n- 考虑由 $y'(t) = f(t,y(t))$ 和 $y(t_{0}) = y_{0}$ 给出的标量常微分方程初值问题。目标是从 $t_{0}$ 推进到最终时间 $T$。\n- 使用一个显式嵌入式 Runge–Kutta 方法对，其中两个不同阶的公式共享相同的内部计算阶段，以在每一步提供两个近似值 $y_{n+1}$ 和 $\\hat{y}_{n+1}$。高阶近似值 $y_{n+1}$ 用作步进结果，其差值 $e_{n+1} = y_{n+1} - \\hat{y}_{n+1}$ 用作步长控制的局部误差估计。\n- 实现一个具体的、广泛使用的阶数为 $p$ 和 $q$（其中 $p > q$）的方法对；为确保具体性和可复现性，请使用 Bogacki–Shampine 方法对，其阶数为 $p=q+1$，即 $p = 3$ 和 $q = 2$。当步长被接受时，使用高阶近似值来推进解。\n- 实现两个版本的自适应控制器：\n  1. 正确的控制器：使用低阶公式的正确嵌入式系数来计算局部误差估计 $e_{n+1}$。\n  2. 有缺陷的控制器：通过故意修改嵌入的低阶权重来计算一个有缺陷的局部误差估计 $\\hat{e}_{n+1}$，具体操作如下：在形成差值之前，交换低阶规则的最后两个权重。换言之，如果低阶权重为 $\\{b_{1}^{(q)}, b_{2}^{(q)}, b_{3}^{(q)}, b_{4}^{(q)}\\}$，有缺陷的控制器在构造 $\\hat{y}_{n+1}$ 时使用 $\\{b_{1}^{(q)}, b_{2}^{(q)}, b_{4}^{(q)}, b_{3}^{(q)}\\}$，因此得到 $\\hat{e}_{n+1} = y_{n+1} - \\hat{y}_{n+1}$。仅将此有缺陷的估计用于步长接受和步长选择，而在接受步长后，仍然使用高阶近似值 $y_{n+1}$ 来推进解。\n- 对于标量状态，使用标准误差范数：\n  $$\\mathrm{err\\_norm} = \\frac{|e_{n+1}|}{\\mathrm{atol} + \\mathrm{rtol} \\cdot \\max(|y_{n}|, |y_{n+1}|)}.$$\n  如果 $\\mathrm{err\\_norm} \\le 1$，则接受该步长。\n- 使用一个源于 p 阶方法局部截断误差缩放的步长控制器。如果一个步长被接受或拒绝，则提出新的步长\n  $$h_{\\mathrm{new}} = h \\cdot s \\cdot \\mathrm{err\\_norm}^{-1/(p+1)},$$\n  其中 $s$ 是一个安全因子。将 $h_{\\mathrm{new}}$ 限制在 $[\\alpha_{\\min} h, \\alpha_{\\max} h]$ 范围内，以避免不稳定的变化。使用 $p = 3$, $s = 0.9$, $\\alpha_{\\min} = 0.2$, 以及 $\\alpha_{\\max} = 5$。\n- 在已接受的步长上，使用 Bogacki–Shampine 方法对的高阶公式来推进解。对两个控制器使用相同的初始步长和控制器参数。\n\n测试问题与精确解：\n- 设 $f(t,y) = \\lambda y$，其中 $\\lambda < 0$，$y(0) = 1$，精确解为 $y(t) = \\exp(\\lambda t)$。\n- 将最终时间 $T$ 的全局误差定义为\n  $$E = |y_{\\mathrm{num}}(T) - y_{\\mathrm{exact}}(T)|.$$\n\n测试套件：\n为以下构成测试套件的参数集提供结果（以下所有数字均为无量纲）：\n- 案例 A（理想路径）：$\\lambda = -1$, $T = 10$, $y_{0} = 1$, $\\mathrm{rtol} = 10^{-3}$, $\\mathrm{atol} = 10^{-12}$。\n- 案例 B（更严格的容差）：$\\lambda = -1$, $T = 10$, $y_{0} = 1$, $\\mathrm{rtol} = 10^{-6}$, $\\mathrm{atol} = 10^{-12}$。\n- 案例 C（更快衰减的动力学）：$\\lambda = -5$, $T = 2$, $y_{0} = 1$, $\\mathrm{rtol} = 10^{-6}$, $\\mathrm{atol} = 10^{-12}$。\n\n每个案例需要计算的内容：\n- 计算两个浮点数：\n  - $E_{\\mathrm{correct}}$：使用正确控制器得到的最终时间绝对误差。\n  - $E_{\\mathrm{flawed}}$：使用有缺陷控制器得到的最终时间绝对误差。\n\n最终输出格式：\n- 您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表。列表中的每个元素对应一个测试案例，并且本身是一个双元素列表 $[E_{\\mathrm{correct}}, E_{\\mathrm{flawed}}]$。例如：[[EcA,EfA],[EcB,EfB],[EcC,EfC]]。以一致、紧凑的小数格式打印数值。", "solution": "所提供的问题经过了严格的验证。\n\n**步骤 1：提取已知条件**\n- **初值问题 (IVP)**：一个标量常微分方程 (ODE) $y'(t) = f(t,y(t))$，其初始条件为 $y(t_{0}) = y_{0}$，将从 $t_{0}$ 积分到最终时间 $T$。\n- **数值方法**：一个显式嵌入式 Runge–Kutta 方法对，阶数为 $p=3$ 和 $q=2$，具体为 Bogacki–Shampine 方法对。高阶 ($p=3$) 近似值 $y_{n+1}$ 用于推进解。\n- **局部误差估计**：高阶近似值 ($y_{n+1}$)与低阶近似值 ($\\hat{y}_{n+1}$) 之间的差值 $e_{n+1} = y_{n+1} - \\hat{y}_{n+1}$，用作局部截断误差的估计。\n- **控制器**：\n    1.  **正确的控制器**：使用标准的局部误差估计 $e_{n+1}$。\n    2.  **有缺陷的控制器**：使用一个有缺陷的估计 $\\hat{e}_{n+1} = y_{n+1} - \\hat{y}_{n+1, \\text{flawed}}$，其中 $\\hat{y}_{n+1, \\text{flawed}}$ 是使用最后两个元素被交换的低阶权重计算得出的。这个有缺陷的估计仅用于步长控制。\n- **误差范数与接受准则**：缩放后的误差范数定义为 $\\mathrm{err\\_norm} = |e_{n+1}| / (\\mathrm{atol} + \\mathrm{rtol} \\cdot \\max(|y_{n}|, |y_{n+1}|))$。如果 $\\mathrm{err\\_norm} \\le 1$，则接受该步长。\n- **步长控制律**：新步长提议为 $h_{\\mathrm{new}} = h \\cdot s \\cdot \\mathrm{err\\_norm}^{-1/(p+1)}$，其中 $s = 0.9$ 且 $p = 3$。结果被限制在 $[\\alpha_{\\min} h, \\alpha_{\\max} h]$ 范围内，其中 $\\alpha_{\\min} = 0.2$ 且 $\\alpha_{\\max} = 5$。\n- **测试问题**：$f(t,y) = \\lambda y$，其中 $y(0) = 1$。精确解为 $y(t) = \\exp(\\lambda t)$。\n- **全局误差度量**：$E = |y_{\\mathrm{num}}(T) - y_{\\mathrm{exact}}(T)|$。\n- **测试案例**：\n    - 案例 A：$\\lambda = -1$, $T = 10$, $y_{0} = 1$, $\\mathrm{rtol} = 10^{-3}$, $\\mathrm{atol} = 10^{-12}$。\n    - 案例 B：$\\lambda = -1$, $T = 10$, $y_{0} = 1$, $\\mathrm{rtol} = 10^{-6}$, $\\mathrm{atol} = 10^{-12}$。\n    - 案例 C：$\\lambda = -5$, $T = 2$, $y_{0} = 1$, $\\mathrm{rtol} = 10^{-6}$, $\\mathrm{atol} = 10^{-12}$。\n- **所需计算**：对于每个案例，计算使用正确控制器 ($E_{\\mathrm{correct}}$) 和有缺陷控制器 ($E_{\\mathrm{flawed}}$) 时的最终时间全局误差。\n\n**步骤 2：使用提取的已知条件进行验证**\n该问题定义明确且科学上合理。它探讨了计算工程中的一个基本主题：常微分方程自适应数值方法的设计与分析。所有参数和程序都以足够的精度进行了规定，可以实现唯一的实施方案。唯一未指定的参数是初始步长 $h_0$。这是一个小小的疏忽。为了在两个控制器之间进行可复现的比较，对两者使用相同的、合理的初始步长就足够了。我将假定所有模拟都使用一个小的、固定的初始步长 $h_0$ 来进行，这是一种标准方法。因此，该问题被视为有效。\n\n**步骤 3：结论与行动**\n该问题是**有效的**。将提供一个完整、合理的解决方案。\n\n**基本原理与方法**\n\n该问题要求对初值问题 (IVP) $y'(t) = f(t,y(t))$, $y(t_0) = y_0$ 进行数值积分。这通过使用自适应步长的 Runge-Kutta 方法来实现。\n\n显式 Runge-Kutta 方法通过一系列中间阶段的求值，从时间 $t_n$ 的解计算出时间 $t_{n+1} = t_n + h_n$ 的解。对于一个 s 级方法，我们有：\n$$k_i = f\\left(t_n + c_i h_n, y_n + h_n \\sum_{j=1}^{i-1} a_{ij} k_j\\right), \\quad i=1, \\dots, s$$\n$$y_{n+1} = y_n + h_n \\sum_{i=1}^s b_i k_i$$\n系数 $c_i$、$a_{ij}$ 和 $b_i$ 定义了具体的方法。\n\n嵌入式方法对使用同一组阶段值 $k_i$ 提供两个解：阶数为 $p$ 的 $y_{n+1}$ 和阶数为 $q < p$ 的 $\\hat{y}_{n+1}$。\n$$y_{n+1} = y_n + h_n \\sum_{i=1}^s b_i k_i \\quad (\\text{阶数 } p)$$\n$$\\hat{y}_{n+1} = y_n + h_n \\sum_{i=1}^s \\hat{b}_i k_i \\quad (\\text{阶数 } q)$$\n其差值 $e_{n+1} = y_{n+1} - \\hat{y}_{n+1} = h_n \\sum_{i=1}^s (b_i - \\hat{b}_i)k_i$ 提供了低阶方法局部截断误差的一个估计。该误差估计用于控制步长 $h_n$。\n\n**Bogacki–Shampine 3(2) 方法对**\n\n所指定的 Bogacki–Shampine 方法是一个 4 级方法，它能产生一个 3 阶解和一个 2 阶解。该方法具有“第一步与上一步最后一步相同 (First Same As Last, FSAL)”的特性，这意味着一步的最终阶段求值可以复用为后续步的第一个阶段，从而提高效率。其结构如下：\n\n1.  计算三个中间阶段：\n    $$k_1 = f(t_n, y_n)$$\n    $$k_2 = f(t_n + \\frac{1}{2}h, y_n + \\frac{1}{2}h k_1)$$\n    $$k_3 = f(t_n + \\frac{3}{4}h, y_n + \\frac{3}{4}h k_2)$$\n2.  计算 3 阶近似值，用于推进解：\n    $$y_{n+1} = y_n + h\\left(\\frac{2}{9}k_1 + \\frac{1}{3}k_2 + \\frac{4}{9}k_3\\right)$$\n3.  使用推进后的解 $y_{n+1}$ 计算第四个阶段。这是 FSAL 阶段。\n    $$k_4 = f(t_n + h, y_{n+1})$$\n4.  计算用于误差估计的 2 阶近似值：\n    $$\\hat{y}_{n+1} = y_n + h\\left(\\frac{7}{24}k_1 + \\frac{1}{4}k_2 + \\frac{1}{3}k_3 + \\frac{1}{8}k_4\\right)$$\n局部误差估计是 $e_{n+1} = y_{n+1} - \\hat{y}_{n+1}$。\n\n**自适应步长控制**\n\n控制器的目标是调整步长 $h$，使局部误差估计满足给定的容差。误差相对于解的量级进行缩放：\n$$\\mathrm{err\\_norm} = \\frac{|e_{n+1}|}{\\mathrm{atol} + \\mathrm{rtol} \\cdot \\max(|y_{n}|, |y_{n+1}|)}$$\n其中 $\\mathrm{atol}$ 和 $\\mathrm{rtol}$ 分别是绝对和相对误差容差。\n\n如果 $\\mathrm{err\\_norm} \\le 1$，则接受该步长。如果接受，则推进解：$t \\leftarrow t_n + h$, $y \\leftarrow y_{n+1}$。如果拒绝，则使用更小的 $h$ 重新尝试该步。\n\n无论哪种情况，都会提出一个新的步长 $h_{\\mathrm{new}}$。基于局部误差行为如同 $C \\cdot h^{p+1}$ 的假设，最优步长可从当前误差中导出：\n$$h_{\\mathrm{new}} = h \\cdot s \\cdot \\left(\\frac{1}{\\mathrm{err\\_norm}}\\right)^{1/(p+1)}$$\n此处，$p=3$ 是用于步长预测的方法阶数，$s=0.9$ 是确保鲁棒性的安全因子。新步长被裁剪以避免过大或过小的变化：$h_{\\mathrm{new}}$ 被约束在 $[\\alpha_{\\min} h, \\alpha_{\\max} h] = [0.2h, 5.0h]$ 范围内。\n\n**有缺陷的控制器**\n\n问题要求对一个有缺陷的控制器进行研究。该缺陷被引入到局部误差估计中。2 阶方法的正确权重为 $\\hat{\\mathbf{b}} = [7/24, 1/4, 1/3, 1/8]$。缺陷在于交换了最后两个权重：\n$$\\hat{\\mathbf{b}}_{\\text{flawed}} = [7/24, 1/4, 1/8, 1/3]$$\n这导致了一个有缺陷的 2 阶近似：\n$$\\hat{y}_{n+1, \\text{flawed}} = y_n + h\\left(\\frac{7}{24}k_1 + \\frac{1}{4}k_2 + \\frac{1}{8}k_3 + \\frac{1}{3}k_4\\right)$$\n有缺陷的误差估计为 $\\hat{e}_{n+1} = y_{n+1} - \\hat{y}_{n+1, \\text{flawed}}$。然后，这个 $\\hat{e}_{n+1}$ 被用于误差范数计算和随后的步长调整。关键要注意的是，即使使用有缺陷的控制器，解的推进仍然使用正确的 3 阶公式 $y_{n+1}$。该缺陷只影响自适应机制，而不影响传播公式本身。\n\n**算法与实现**\n\n实现的核心将是一个 `adaptive_integrator` 函数，它执行以下循环：\n1.  初始化 $t=t_0$，$y=y_0$ 以及一个初始步长 $h=h_0$。我们将使用 $h_0 = 10^{-2}$。计算第一阶段 $k_1 = f(t_0, y_0)$。\n2.  开始主循环，只要 $t < T$ 就继续。\n3.  在循环内部，为步长接受启动一个子循环。\n4.  在子循环中，计算阶段 $k_2, k_3$、3 阶解 $y_{n+1}$ 和最终阶段 $k_4$。\n5.  根据控制器类型（正确的或有缺陷的），计算相应的局部误差估计（$e_{n+1}$ 或 $\\hat{e}_{n+1}$）。\n6.  计算误差范数 $\\mathrm{err\\_norm}$。\n7.  如果 $\\mathrm{err\\_norm} \\le 1$，则步长被接受。推进时间和解（$t \\leftarrow t+h, y \\leftarrow y_{n+1}$）。阶段 $k_4$ 成为下一步的新 $k_1$（FSAL）。退出子循环。\n8.  如果 $\\mathrm{err\\_norm} > 1$，则步长被拒绝。当前的 $y_{n+1}$ 被丢弃。子循环以一个新的、更小的步长 $h$ 继续。\n9.  在接受和拒绝两种情况下，都使用控制律和裁剪规则计算一个新的建议步长 $h_{\\mathrm{new}}$，并更新 $h$。\n10. 当 $t \\ge T$ 时，主循环终止。对最后一步的步长进行一次最终调整，以确保积分恰好在 $T$ 处停止。\n\n该过程将对每个测试案例执行，一次使用正确的控制器，另一次使用有缺陷的控制器。然后计算并报告最终的全局误差 $E = |y_{\\mathrm{num}}(T) - \\exp(\\lambda T)|$。有缺陷控制器的行为（比正确的控制器更激进还是更保守）将决定最终的全局误差是更大还是更小。这个实验展示了全局误差对局部误差估计器正确性的敏感性，而局部误差估计器的正确性是自适应求解器可靠性的基础。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef adaptive_integrator(f, t0, y0, T, rtol, atol, h0, flawed_controller):\n    \"\"\"\n    Integrates an ODE using the adaptive Bogacki-Shampine 3(2) method.\n    \"\"\"\n    # Bogacki-Shampine coefficients and controller parameters\n    # The method structure:\n    # k1 = f(t, y)\n    # k2 = f(t + 1/2 h, y + 1/2 h k1)\n    # k3 = f(t + 3/4 h, y + 3/4 h k2)\n    # y_next = y + h * (2/9 k1 + 1/3 k2 + 4/9 k3)  (order 3 solution)\n    # k4 = f(t + h, y_next)                          (FSAL stage)\n    # error = y_next - y_hat_next, where y_hat_next is the order 2 solution.\n    # The error is computed using a difference of weights for better numerical stability.\n    \n    b3_weights = np.array([2/9, 1/3, 4/9, 0])      # Order 3 weights\n    b2_weights_correct = np.array([7/24, 1/4, 1/3, 1/8]) # Order 2 weights\n    b2_weights_flawed = np.array([7/24, 1/4, 1/8, 1/3])  # Flawed order 2 weights\n\n    if flawed_controller:\n        err_weights = b3_weights - b2_weights_flawed\n    else:\n        err_weights = b3_weights - b2_weights_correct\n\n    s = 0.9\n    p = 3\n    alpha_min = 0.2\n    alpha_max = 5.0\n\n    t = t0\n    y = y0\n    h = h0\n\n    # First stage evaluation (k1) for the first step\n    k1 = f(t, y)\n\n    while t  T:\n        if t + h > T:\n            h = T - t  # Adjust last step to hit T exactly\n\n        step_accepted = False\n        while not step_accepted:\n            # Prevent infinitely small step size\n            if abs(h)  1e-15 * T:\n                raise RuntimeError(\"Step size has become excessively small.\")\n\n            # Compute stages for BS(3,2)\n            k2 = f(t + 0.5 * h, y + 0.5 * h * k1)\n            k3 = f(t + 0.75 * h, y + 0.75 * h * k2)\n            y_next = y + h * (b3_weights[0] * k1 + b3_weights[1] * k2 + b3_weights[2] * k3)\n            k4 = f(t + h, y_next)\n\n            # Calculate local error estimate\n            local_error = h * (err_weights[0] * k1 + err_weights[1] * k2 + \n                               err_weights[2] * k3 + err_weights[3] * k4)\n\n            # Calculate scaled error norm\n            y_scale = atol + rtol * max(abs(y), abs(y_next))\n            err_norm = abs(local_error) / y_scale if y_scale > 0 else 0\n\n            # Step acceptance logic\n            if err_norm = 1.0:\n                step_accepted = True\n                t += h\n                y = y_next\n                # FSAL: k4 of this step is k1 of the next\n                k1 = k4\n                \n                # Update step size for the next step\n                if err_norm == 0:\n                    # Avoid division by zero and propose max increase\n                    h_new = h * alpha_max\n                else:\n                    h_new = h * s * (err_norm ** (-1.0 / (p + 1.0)))\n            else:\n                # Step rejected, reduce step size and retry\n                h_new = h * s * (err_norm ** (-1.0 / (p + 1.0)))\n\n            # Clip the new step size\n            h = max(h * alpha_min, min(h * alpha_max, h_new))\n\n    return y\n\ndef solve():\n    \"\"\"\n    Runs the simulation for the specified test cases and prints the results.\n    \"\"\"\n    test_cases = [\n        # Case A\n        {'lambda': -1.0, 'T': 10.0, 'y0': 1.0, 'rtol': 1e-3, 'atol': 1e-12},\n        # Case B\n        {'lambda': -1.0, 'T': 10.0, 'y0': 1.0, 'rtol': 1e-6, 'atol': 1e-12},\n        # Case C\n        {'lambda': -5.0, 'T': 2.0, 'y0': 1.0, 'rtol': 1e-6, 'atol': 1e-12},\n    ]\n\n    results = []\n    h0 = 1e-2  # Fixed initial step size for all runs for fair comparison\n\n    for case in test_cases:\n        lambda_val = case['lambda']\n        T = case['T']\n        y0 = case['y0']\n        rtol = case['rtol']\n        atol = case['atol']\n\n        # Define the ODE and its exact solution\n        f = lambda t, y: lambda_val * y\n        y_exact_func = lambda t: np.exp(lambda_val * t)\n        \n        y_exact_T = y_exact_func(T)\n\n        # Run with correct controller\n        y_num_correct = adaptive_integrator(f, 0, y0, T, rtol, atol, h0, flawed_controller=False)\n        E_correct = abs(y_num_correct - y_exact_T)\n\n        # Run with flawed controller\n        y_num_flawed = adaptive_integrator(f, 0, y0, T, rtol, atol, h0, flawed_controller=True)\n        E_flawed = abs(y_num_flawed - y_exact_T)\n\n        results.append([E_correct, E_flawed])\n\n    # Format the output string as specified\n    output_str = '[' + ','.join([f'[{r[0]:.5e},{r[1]:.5e}]' for r in results]) + ']'\n    print(output_str)\n\nsolve()\n```", "id": "2388676"}, {"introduction": "在计算工程领域，效率与精度同等重要。本练习将你置于一个真实的优化场景中：在固定的计算资源预算下，如何获得最精确的数值解？你需要针对一系列测试问题，系统地探索初始步长 $h_0$ 和容忍度 $\\mathrm{TOL}$ 的不同组合，以期在不超过函数求值次数上限的前提下，最小化最终的全局误差 [@problem_id:2388727]。这项挑战性的任务将迫使你思考局部误差控制策略与全局精度、计算成本之间的复杂权衡，这是成为一名优秀计算工程师的必经之路。", "problem": "给定一个固定的 $N=10000$ 次函数求值的预算，要求使用带局部误差控制的显式嵌入式 Runge–Kutta 对来近似初值问题的解的最终值。对于下文定义的每个测试用例，从候选集中选择一个初始步长 $h_0$ 和一个标量容差 $\\mathrm{TOL}$，以在函数求值预算的约束下，最小化在终端时间上的最终全局误差。如果出现角度，必须以弧度为单位进行解释。\n\n该数值积分器必须是一种基于一个显式嵌入式 Runge–Kutta 对的单步法，在每个大小为 $h$ 的尝试步中，它会在一系列节点上对右端函数 $f(t,y)$ 求值，并给出在新时间点上解的两个不同阶的近似值 $y^{[p]}$ 和 $y^{[p-1]}$。局部误差估计是差值 $e=y^{[p]}-y^{[p-1]}$，当且仅当 $\\lVert e\\rVert_2 \\le \\mathrm{TOL}$ 时，大小为 $h$ 的步长被接受，其中 $\\lVert\\cdot\\rVert_2$ 表示 $\\mathbb{R}^d$ 中的欧几里得范数，$d$ 等于状态维度。每一次对 $f(t,y)$ 的节点求值都算作 $N$ 预算中的一次函数求值。每一次尝试步，无论被接受还是被拒绝，都会产生所选对的全部节点求值次数。初始步长为 $h_0$。在每次尝试步中，不应超过终端时间 $t_{\\mathrm{end}}$；如果 $t+h$ 会超过 $t_{\\mathrm{end}}$，则在该次尝试中使用 $h=t_{\\mathrm{end}}-t$。\n\n使用以下被称为 $5(4)$ 对的嵌入式 Runge–Kutta 系数，其级数 $s=7$。节点横坐标为\n$$\nc_1=0,\\quad c_2=\\tfrac{1}{5},\\quad c_3=\\tfrac{3}{10},\\quad c_4=\\tfrac{4}{5},\\quad c_5=\\tfrac{8}{9},\\quad c_6=1,\\quad c_7=1.\n$$\n内部系数 $a_{ij}$（其中 $i=2,\\dots,7$ 且 $j=1,\\dots,i-1$）为\n$$\n\\begin{aligned}\na_{21}=\\tfrac{1}{5},\\\\\na_{31}=\\tfrac{3}{40},\\ a_{32}=\\tfrac{9}{40},\\\\\na_{41}=\\tfrac{44}{45},\\ a_{42}=-\\tfrac{56}{15},\\ a_{43}=\\tfrac{32}{9},\\\\\na_{51}=\\tfrac{19372}{6561},\\ a_{52}=-\\tfrac{25360}{2187},\\ a_{53}=\\tfrac{64448}{6561},\\ a_{54}=-\\tfrac{212}{729},\\\\\na_{61}=\\tfrac{9017}{3168},\\ a_{62}=-\\tfrac{355}{33},\\ a_{63}=\\tfrac{46732}{5247},\\ a_{64}=\\tfrac{49}{176},\\ a_{65}=-\\tfrac{5103}{18656},\\\\\na_{71}=\\tfrac{35}{384},\\ a_{72}=0,\\ a_{73}=\\tfrac{500}{1113},\\ a_{74}=\\tfrac{125}{192},\\ a_{75}=-\\tfrac{2187}{6784},\\ a_{76}=\\tfrac{11}{84}.\n\\end{aligned}\n$$\n高阶权重 $b_j$ 和嵌入的低阶权重 $\\widehat{b}_j$ 为\n$$\n\\begin{aligned}\nb=\\Big[\\tfrac{35}{384},\\ 0,\\ \\tfrac{500}{1113},\\ \\tfrac{125}{192},\\ -\\tfrac{2187}{6784},\\ \\tfrac{11}{84},\\ 0\\Big],\\\\\n\\widehat{b}=\\Big[\\tfrac{5179}{57600},\\ 0,\\ \\tfrac{7571}{16695},\\ \\tfrac{393}{640},\\ -\\tfrac{92097}{339200},\\ \\tfrac{187}{2100},\\ \\tfrac{1}{40}\\Big].\n\\end{aligned}\n$$\n在时间 $t$，状态为 $y\\in\\mathbb{R}^d$，步长为 $h$，节点值为 $k_1=f(t,y)$ 及\n$$\nk_i=f\\Big(t+c_i h,\\ y+h\\sum_{j=1}^{i-1} a_{ij}k_j\\Big),\\quad i=2,\\dots,7,\n$$\n两个近似值为\n$$\ny^{[5]}=y+h\\sum_{j=1}^{7} b_j k_j,\\quad y^{[4]}=y+h\\sum_{j=1}^{7} \\widehat{b}_j k_j,\n$$\n局部误差估计为 $e=y^{[5]}-y^{[4]}$。终端时间的最终近似值是通过从初始时间开始，使用被接受的步长不断推进直到达到 $t_{\\mathrm{end}}$ 来获得的。\n\n对于误差控制和步长选择，将 $\\mathrm{TOL}$ 解释为绝对局部误差阈值，并使用接受准则 $\\lVert e\\rVert_2\\le \\mathrm{TOL}$。任何尝试后的下一步长提议 $h_{\\mathrm{new}}$ 必须符合以下形式\n$$\nh_{\\mathrm{new}}=\\alpha\\,h\\,\\max\\!\\Big(\\beta_{\\min},\\ \\min\\big(\\beta_{\\max},\\ (\\tfrac{\\mathrm{TOL}}{\\max(\\lVert e\\rVert_2,\\ \\epsilon)})^{1/5}\\big)\\Big),\n$$\n其中 $\\alpha$ 是一个安全因子，$\\beta_{\\min}$ 和 $\\beta_{\\max}$ 是限制因子，$\\epsilon$ 是一个小的正数以避免除以零。使用 $\\alpha=0.9$，$\\beta_{\\min}=0.2$，$\\beta_{\\max}=5$ 和 $\\epsilon=10^{-16}$。\n\n如果在达到终端时间之前，所有尝试步（包括接受和拒绝的）的总节点求值次数不超过 $N=10000$，则候选 $(h_0,\\mathrm{TOL})$ 是可行的。如果在达到终端时间之前，某个候选耗尽了预算，则它是不可行的。在所有可行的候选中，选择能最小化最终全局误差的对\n$$\nE=\\lVert y(t_{\\mathrm{end}})-y_{\\mathrm{true}}(t_{\\mathrm{end}})\\rVert_2,\n$$\n其中 $y_{\\mathrm{true}}$ 是精确解。如果有多个候选在 $10^{-12}$ 的绝对容差内达到了相同的最小误差，则通过优先选择函数求值总次数较少的那个来打破平局；如果仍然平局，则优先选择较大的 $\\mathrm{TOL}$；如果仍然平局，则优先选择较大的 $h_0$。\n\n使用以下候选集：\n$$\nh_0\\in\\big\\{10^{-3},\\ 5\\cdot 10^{-3},\\ 10^{-2},\\ 5\\cdot 10^{-2},\\ 10^{-1},\\ 5\\cdot 10^{-1}\\big\\},\n$$\n$$\n\\mathrm{TOL}\\in\\big\\{10^{-6},\\ 3\\cdot 10^{-6},\\ 10^{-5},\\ 3\\cdot 10^{-5},\\ 10^{-4},\\ 3\\cdot 10^{-4},\\ 10^{-3},\\ 3\\cdot 10^{-3},\\ 10^{-2}\\big\\}.\n$$\n\n带有精确解和所需定义域的初值问题测试套件：\n- 用例 $\\mathrm{A}$：标量，$y'(t)=-10\\,y(t)$，$y(0)=1$，$t\\in[0,2]$，精确解 $y_{\\mathrm{true}}(t)=e^{-10 t}$。\n- 用例 $\\mathrm{B}$：标量，$y'(t)=y(t)^2-y(t)$，$y(0)=0.1$，$t\\in[0,3]$，精确解 $y_{\\mathrm{true}}(t)=\\dfrac{1}{1+9 e^{t}}$。\n- 用例 $\\mathrm{C}$：标量，$y'(t)=-100\\big(y(t)-\\cos t\\big)-\\sin t$，$y(0)=1$，$t\\in[0,2]$，精确解 $y_{\\mathrm{true}}(t)=\\cos t$。\n- 用例 $\\mathrm{D}$：维度为 $d=2$ 的向量，$y_1'(t)=y_2(t)$，$y_2'(t)=-y_1(t)$，其中 $y_1(0)=1$，$y_2(0)=0$，$t\\in[0,2\\pi]$，精确解 $y_{\\mathrm{true}}(t)=[\\cos t,\\ -\\sin t]^T$。\n\n对于每个用例，你的程序必须在指定的候选集中搜索所有的 $(h_0,\\mathrm{TOL})$ 对，强制执行 $N=10000$ 次节点求值的预算，并报告最优对及其产生的最终全局误差 $E$。\n\n最终输出规范：\n- 对于每个用例，生成一个列表 $[h_0^\\star,\\ \\mathrm{TOL}^\\star,\\ E^\\star]$，其中 $h_0^\\star$ 和 $\\mathrm{TOL}^\\star$ 是从候选集中选择的值，而 $E^\\star$ 是最小最终全局误差，表示为一个四舍五入到8位有效数字的浮点值。\n- 将四个用例的结果汇总到一行输出中，包含一个用方括号括起来的逗号分隔列表，例如 $[[h_0^\\star,\\mathrm{TOL}^\\star,E^\\star],\\ \\dots]$。", "solution": "用户提供了一个具有科学依据、适定、客观且完整的问题陈述。它描述了一项标准的计算工程任务：为自适应 Runge-Kutta 数值积分器寻找最优参数。所有必需的数据，包括特定的 Runge-Kutta 系数、步长控制算法、带精确解的测试问题集、候选参数集以及优化标准，都以清晰明确的方式提供。该问题遵循常微分方程数值分析的既定原则。因此，该问题是有效的，可以构建一个解决方案。\n\n该解决方案框架被设计为对所提供的离散候选参数集进行系统性搜索。对于四个初值问题（IVP）中的每一个，算法都会对所有可能的初始步长 $h_0$ 和局部误差容差 $\\mathrm{TOL}$ 对进行网格搜索。\n\n设计的核心是一个实现自适应步长 Runge-Kutta 积分器的函数。该积分器基于所提供的特定的 $s=7$ 级、$5(4)$ 阶嵌入式对，该对被认为是 Dormand-Prince 对。在每个时间步，该方法计算解的两个近似值：一个五阶精度的解 $y^{[5]}$ 和一个四阶精度的解 $y^{[4]}$。节点值 $k_i$ 计算如下：\n$$\nk_1=f(t_n,y_n)\n$$\n$$\nk_i=f\\Big(t_n+c_i h,\\ y_n+h\\sum_{j=1}^{i-1} a_{ij}k_j\\Big),\\quad i=2,\\dots,7\n$$\n然后构建两个解的近似值：\n$$\ny_n^{[5]}=y_n+h\\sum_{j=1}^{7} b_j k_j\n$$\n$$\ny_n^{[4]}=y_n+h\\sum_{j=1}^{7} \\widehat{b}_j k_j\n$$\n这两个近似值之间的差值 $e = y_n^{[5]} - y_n^{[4]}$，用作局部截断误差的估计。\n\n步长控制逻辑如下进行。如果局部误差估计的欧几里得范数小于或等于指定的容差，即 $\\lVert e\\rVert_2 \\le \\mathrm{TOL}$，则大小为 $h$ 的尝试步被认为是成功的。如果步长被接受，数值解将使用高阶近似进行推进：$y_{n+1} = y_n^{[5]}$ 且 $t_{n+1} = t_n + h$。如果步长被拒绝，解将保持在 $(t_n, y_n)$，并使用一个新的、更小的步长重新尝试该步。\n\n无论一个步长被接受还是被拒绝，都会使用所提供的比例-积分（PI）控制公式计算用于后续尝试的新步长 $h_{\\mathrm{new}}$。这个公式 $h_{\\mathrm{new}}=\\alpha\\,h\\,\\max\\!\\big(\\beta_{\\min},\\ \\min\\big(\\beta_{\\max},\\ (\\frac{\\mathrm{TOL}}{\\max(\\lVert e\\rVert_2,\\ \\epsilon)})^{1/5}\\big)\\big)$，基于目标容差与测量误差的比率来调整步长。安全因子 $\\alpha1$ 提高了稳健性，而限制因子 $\\beta_{\\min}$ 和 $\\beta_{\\max}$ 则防止步长变化过快。\n\n对于每个 $(h_0, \\mathrm{TOL})$ 对，积分器从初始时间 $t_0$ 运行到终端时间 $t_{\\mathrm{end}}$。函数求值总数受到严格监控，且不得超过 $N=10000$ 的预算。每个尝试步，无论成功与否，都会消耗 $s=7$ 次函数求值。如果在到达 $t_{\\mathrm{end}}$ 之前预算耗尽，则该 $(h_0, \\mathrm{TOL})$ 对被标记为不可行。\n\n对于所有可行的对，计算最终全局误差 $E = \\lVert y(t_{\\mathrm{end}}) - y_{\\mathrm{true}}(t_{\\mathrm{end}}) \\rVert_2$。算法识别出最小化该误差 $E$ 的最优 $(h_0^\\star, \\mathrm{TOL}^\\star)$ 对。问题指定了一套严格的平局打破规则：如果多个对产生的误差 $E$ 在最小值的 $10^{-12}$ 绝对容差范围内，则选择函数求值总次数最少的那个。进一步的平局则通过优先选择较大的 $\\mathrm{TOL}$，然后是较大的 $h_0$ 来打破。\n\n对四个指定的初值问题中的每一个都重复此整个过程。最终输出是每个用例的最优参数 $(h_0^\\star, \\mathrm{TOL}^\\star)$ 和相应最小全局误差 $E^\\star$ 的汇总，并按要求格式化。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# A class to hold the test case data for clarity.\nclass TestCase:\n    \"\"\"A container for an initial value problem specification.\"\"\"\n    def __init__(self, f, y0, t_span, y_true):\n        self.f = f\n        self.y0 = np.array(y0, dtype=np.float64)\n        self.t_span = t_span\n        self.y_true = y_true\n\ndef adaptive_rk_solver(case, h0, tol, budget, rk_params):\n    \"\"\"\n    Solves an IVP using an adaptive Runge-Kutta method.\n\n    Returns the final state, total function evaluations, and a feasibility flag.\n    \"\"\"\n    t_start, t_end = case.t_span\n    t = t_start\n    y = case.y0.copy()\n    h = h0\n    fevals = 0\n\n    A, B, B_ERR, C, S, P_ORDER, ALPHA, BETA_MIN, BETA_MAX, EPSILON = rk_params\n\n    while t  t_end:\n        if fevals + S > budget:\n            return None, fevals, False  # Infeasible: budget exceeded\n\n        h = min(h, t_end - t)\n        \n        # Calculate stages for the Runge-Kutta step\n        k_stages = np.zeros((S, y.size), dtype=np.float64)\n        \n        k_stages[0] = case.f(t, y)\n        for i in range(1, S):\n            y_stage = y + h * (A[i, :i] @ k_stages[:i, :])\n            k_stages[i] = case.f(t + C[i] * h, y_stage)\n\n        fevals += S\n        \n        # Calculate local error estimate\n        y_err = h * (B_ERR @ k_stages)\n        err_norm = np.linalg.norm(y_err)\n\n        # Propose new step size based on error\n        factor = (tol / max(err_norm, EPSILON))**(1.0 / P_ORDER)\n        h_new = ALPHA * h * max(BETA_MIN, min(BETA_MAX, factor))\n\n        # Accept or reject the step\n        if err_norm = tol:\n            t += h\n            y += h * (B @ k_stages)  # Advance state with higher-order method\n        \n        h = h_new\n        \n        # Failsafe for persistent rejections with tiny steps\n        if h  1e-16:\n            return None, fevals, False\n\n    return y, fevals, True\n\ndef solve():\n    \"\"\"\n    Main function to run the optimization for all test cases.\n    \"\"\"\n    # Candidate parameter sets\n    h0_candidates = [1e-3, 5e-3, 1e-2, 5e-2, 1e-1, 5e-1]\n    tol_candidates = [1e-6, 3e-6, 1e-5, 3e-5, 1e-4, 3e-4, 1e-3, 3e-3, 1e-2]\n    \n    # RK and step-size control parameter definitions\n    C = np.array([0, 1/5, 3/10, 4/5, 8/9, 1, 1], dtype=np.float64)\n    A = np.array([\n        [0, 0, 0, 0, 0, 0, 0],\n        [1/5, 0, 0, 0, 0, 0, 0],\n        [3/40, 9/40, 0, 0, 0, 0, 0],\n        [44/45, -56/15, 32/9, 0, 0, 0, 0],\n        [19372/6561, -25360/2187, 64448/6561, -212/729, 0, 0, 0],\n        [9017/3168, -355/33, 46732/5247, 49/176, -5103/18656, 0, 0],\n        [35/384, 0, 500/1113, 125/192, -2187/6784, 11/84, 0]\n    ], dtype=np.float64)\n    B = np.array([35/384, 0, 500/1113, 125/192, -2187/6784, 11/84, 0], dtype=np.float64)\n    B_HAT = np.array([5179/57600, 0, 7571/16695, 393/640, -92097/339200, 187/2100, 1/40], dtype=np.float64)\n    B_ERR = B - B_HAT\n    S = 7\n    P_ORDER = 5\n    ALPHA = 0.9\n    BETA_MIN = 0.2\n    BETA_MAX = 5.0\n    EPSILON = 1e-16\n    N_BUDGET = 10000\n    \n    rk_params = (A, B, B_ERR, C, S, P_ORDER, ALPHA, BETA_MIN, BETA_MAX, EPSILON)\n\n    # Test case definitions\n    test_cases = [\n        TestCase(\n            f=lambda t, y: -10 * y,\n            y0=[1.0],\n            t_span=[0.0, 2.0],\n            y_true=lambda t: np.array([np.exp(-10 * t)])\n        ),\n        TestCase(\n            f=lambda t, y: y**2 - y,\n            y0=[0.1],\n            t_span=[0.0, 3.0],\n            y_true=lambda t: np.array([1.0 / (1.0 + 9.0 * np.exp(t))])\n        ),\n        TestCase(\n            f=lambda t, y: -100 * (y - np.cos(t)) - np.sin(t),\n            y0=[1.0],\n            t_span=[0.0, 2.0],\n            y_true=lambda t: np.array([np.cos(t)])\n        ),\n        TestCase(\n            f=lambda t, y: np.array([y[1], -y[0]]),\n            y0=[1.0, 0.0],\n            t_span=[0.0, 2 * np.pi],\n            y_true=lambda t: np.array([np.cos(t), -np.sin(t)])\n        )\n    ]\n    \n    final_results = []\n    for case in test_cases:\n        best_params = {'h0': None, 'tol': None, 'error': np.inf, 'fevals': N_BUDGET + 1}\n        \n        for h0 in h0_candidates:\n            for tol in tol_candidates:\n                y_final, fevals, feasible = adaptive_rk_solver(case, h0, tol, N_BUDGET, rk_params)\n                \n                if feasible:\n                    t_end = case.t_span[1]\n                    y_exact_final = case.y_true(t_end)\n                    error = np.linalg.norm(y_final - y_exact_final)\n                    \n                    is_better = False\n                    if error  best_params['error'] - 1e-12:\n                        is_better = True\n                    elif abs(error - best_params['error']) = 1e-12:\n                        if fevals  best_params['fevals']:\n                            is_better = True\n                        elif fevals == best_params['fevals']:\n                            if tol > best_params.get('tol', -1):\n                                is_better = True\n                            elif tol == best_params.get('tol', -1):\n                                if h0 > best_params.get('h0', -1):\n                                    is_better = True\n                    \n                    if is_better:\n                        best_params['h0'] = h0\n                        best_params['tol'] = tol\n                        best_params['error'] = error\n                        best_params['fevals'] = fevals\n                        \n        rounded_error = float(f\"{best_params['error']:.8g}\")\n        final_results.append([best_params['h0'], best_params['tol'], rounded_error])\n\n    print(f\"[{','.join(str(res).replace(' ', '') for res in final_results)}]\")\n\nsolve()\n```", "id": "2388727"}]}