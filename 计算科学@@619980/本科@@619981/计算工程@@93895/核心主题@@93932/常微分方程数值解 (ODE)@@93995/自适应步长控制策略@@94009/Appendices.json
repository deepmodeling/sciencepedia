{"hands_on_practices": [{"introduction": "自适应求解器的核心在于如何在每一步中可靠地估计局部误差。本实践将探讨两种基本策略：使用专门构建的“嵌入式”方法，以及更通用但计算成本更高的“步长加倍”技术。通过从零开始实现这两种方法，您将直接比较它们在解决不同类型（平滑、振荡、非线性增长）问题时的计算效率，从而深刻理解误差估计策略对求解器性能的决定性影响。[@problem_id:2372273]", "problem": "你需要编写一个完整的程序，比较两种自适应步长策略，用于对一个常微分方程的标量初值问题进行积分。考虑一个形式为 $y'(t)=f(t,y)$，在有限区间 $[t_0,t_f]$ 上，初始条件为 $y(t_0)=y_0$ 的初值问题。对于下面的每个测试用例，从 $t_0$ 到 $t_f$ 进行积分，并生成两份摘要，一份针对嵌入式 Runge–Kutta–Fehlberg $4(5)$ 方法，另一份针对基于经典四阶 Runge–Kutta 方法构建的步长加倍策略。对于每种策略，报告函数求值的总次数以及所接受步长的算术平均值。\n\n两种策略都必须严格遵循以下数学规范：\n- 误差缩放：对于从 $(t,y)$ 开始、步长为 $h$ 的一次试探步，定义标量尺度 $s=\\max\\{|y|,|y_{\\mathrm{trial}}|\\}$，容差 $T=\\text{atol}+\\text{rtol}\\cdot s$，以及由该策略计算出的误差估计 $E\\ge 0$。当且仅当 $E\\le T$ 时，一个试探步被接受。如果接受，则更新 $(t,y)\\leftarrow (t+h,y_{\\mathrm{accept}})$。如果试探步将超过 $t_f$，则在试探前将 $h$ 替换为 $t_f-t$。\n- 步长更新：设方法的有效局部误差阶数为 $q=5$，因此局部误差的行为符合 $\\mathcal{O}(h^q)$。在任何一次试探（无论接受或拒绝）后，定义增长因子\n$$\ng=\n\\begin{cases}\n\\max(g_{\\min},\\min(g_{\\max},\\,\\sigma\\,(T/\\max(E,\\varepsilon))^{1/q} )), & E>0,\\\\\ng_{\\max}, & E=0,\n\\end{cases}\n$$\n其中固定常数 $\\sigma=0.9$，$g_{\\min}=0.2$，$g_{\\max}=5$，以及 $\\varepsilon=10^{-30}$。然后将下一次试探的步长设置为 $h\\leftarrow \\max(h_{\\min},\\min(h_{\\max},g\\,h))$，其中 $h_{\\min}=10^{-12}$，$h_{\\max}=t_f-t_0$。对于所有测试用例，初始步长必须为 $h_0=(t_f-t_0)/50$。\n- 角度单位：所有出现的三角函数均使用弧度制。\n\n嵌入式 Runge–Kutta–Fehlberg $4(5)$ 方法详情：\n- 使用具有 $6$ 个级的经典 Fehlberg 系数。给定 $h$，内部各级计算如下\n$$\n\\begin{aligned}\nk_1&=f(t, y),\\\\\nk_2&=f\\!\\left(t+\\tfrac{1}{4}h,\\,y+h\\left(\\tfrac{1}{4}k_1\\right)\\right),\\\\\nk_3&=f\\!\\left(t+\\tfrac{3}{8}h,\\,y+h\\left(\\tfrac{3}{32}k_1+\\tfrac{9}{32}k_2\\right)\\right),\\\\\nk_4&=f\\!\\left(t+\\tfrac{12}{13}h,\\,y+h\\left(\\tfrac{1932}{2197}k_1-\\tfrac{7200}{2197}k_2+\\tfrac{7296}{2197}k_3\\right)\\right),\\\\\nk_5&=f\\!\\left(t+h,\\,y+h\\left(\\tfrac{439}{216}k_1-8k_2+\\tfrac{3680}{513}k_3-\\tfrac{845}{4104}k_4\\right)\\right),\\\\\nk_6&=f\\!\\left(t+\\tfrac{1}{2}h,\\,y+h\\left(-\\tfrac{8}{27}k_1+2k_2-\\tfrac{3544}{2565}k_3+\\tfrac{1859}{4104}k_4-\\tfrac{11}{40}k_5\\right)\\right).\n\\end{aligned}\n$$\n四阶和五阶的试探解为\n$$\n\\begin{aligned}\ny_4&=y+h\\left(\\tfrac{25}{216}k_1+\\tfrac{1408}{2565}k_3+\\tfrac{2197}{4104}k_4-\\tfrac{1}{5}k_5\\right),\\\\\ny_5&=y+h\\left(\\tfrac{16}{135}k_1+\\tfrac{6656}{12825}k_3+\\tfrac{28561}{56430}k_4-\\tfrac{9}{50}k_5+\\tfrac{2}{55}k_6\\right).\n\\end{aligned}\n$$\n使用 $y_{\\mathrm{trial}}=y_5$，$y_{\\mathrm{accept}}=y_5$，以及误差估计 $E=|y_5-y_4|$。每次试探步（无论是否接受）精确地计为 $6$ 次函数求值。\n\n步长加倍策略（基于经典的四阶 Runge–Kutta 方法）：\n- 步长为 $h$ 的经典四阶 Runge–Kutta 步为\n$$\n\\begin{aligned}\nK_1&=f(t,y),\\quad K_2=f\\!\\left(t+\\tfrac{h}{2},y+\\tfrac{h}{2}K_1\\right),\\quad K_3=f\\!\\left(t+\\tfrac{h}{2},y+\\tfrac{h}{2}K_2\\right),\\\\\nK_4&=f\\!\\left(t+h,y+hK_3\\right),\\quad \\Phi_h(y)=y+\\tfrac{h}{6}\\left(K_1+2K_2+2K_3+K_4\\right).\n\\end{aligned}\n$$\n对于每次试探步，计算 $y^{(1)}=\\Phi_h(y)$ 和 $y^{(2)}=\\Phi_{h/2}(\\Phi_{h/2}(y))$。使用 $y_{\\mathrm{trial}}=y^{(2)}$，$y_{\\mathrm{accept}}=y^{(2)}$，以及 Richardson 误差估计\n$$\nE=\\frac{|\\,y^{(2)}-y^{(1)}\\,|}{2^4-1}=\\frac{|\\,y^{(2)}-y^{(1)}\\,|}{15}.\n$$\n每次试探步（无论是否接受）精确地计为 $12$ 次函数求值（一个全步耗费 $4$ 次求值，加上两个半步耗费 $8$ 次求值）。\n\n测试套件：\n对于下面的每个用例 $i\\in\\{1,2,3\\}$，程序必须使用相同的 $(t_0,t_f,y_0,\\text{rtol},\\text{atol})$ 运行两种策略，并生成“要求的最终输出格式”下指定的输出。\n- 用例 $1$（平滑线性）：$f(t,y)=-2y+t$，$t_0=0$，$t_f=10$，$y_0=1$，$\\text{rtol}=10^{-6}$，$\\text{atol}=10^{-9}$。\n- 用例 $2$（振荡驱动，弧度制）：$f(t,y)=50\\cos(50t)-y$，$t_0=0$，$t_f=2$，$y_0=0$，$\\text{rtol}=10^{-5}$，$\\text{atol}=10^{-7}$。\n- 用例 $3$（逻辑斯谛增长）：$f(t,y)=y(1-y)$，$t_0=0$，$t_f=10$，$y_0=10^{-6}$，$\\text{rtol}=10^{-7}$，$\\text{atol}=10^{-12}$。\n\n要求的最终输出格式：\n你的程序应生成单行输出，其中包含一个有三个条目（每个测试用例一个）的列表，每个条目是如下列表\n$$\n[\\;N_{\\mathrm{RKF45}},\\;N_{\\mathrm{SD}},\\;\\overline{h}_{\\mathrm{RKF45}},\\;\\overline{h}_{\\mathrm{SD}}\\;],\n$$\n其中 $N_{\\mathrm{RKF45}}$ 是嵌入式 Runge–Kutta–Fehlberg 方法使用的函数求值总次数，$N_{\\mathrm{SD}}$ 是步长加倍策略使用的函数求值总次数，$\\overline{h}_{\\mathrm{RKF45}}$ 是嵌入式 Runge–Kutta–Fehlberg 方法在 $[t_0,t_f]$ 上所有被接受步长的算术平均值，$\\overline{h}_{\\mathrm{SD}}$ 是步长加倍策略在 $[t_0,t_f]$ 上所有被接受步长的算术平均值。输出必须以 Python 列表的精确格式作为单行打印，例如：\n[[N1_RKF45,N1_SD,mean_h1_RKF45,mean_h1_SD],[N2_RKF45,N2_SD,mean_h2_RKF45,mean_h2_SD],[N3_RKF45,N3_SD,mean_h3_RKF45,mean_h3_SD]]\n\n不应打印任何额外文本。", "solution": "该任务是实现并比较两种用于求解标量常微分方程（ODE）的自适应步长控制策略。自适应积分的基本原理是动态调整步长 $h$，以确保每步的局部截断误差保持在用户定义的容差范围内。这种方法比使用固定步长要高效得多，因为它允许积分器在解平滑时采用大步长，在解快速变化时采用小步长。\n\n两种策略的控制机制都遵循一个共同的框架。在每个时间 $t$ 处的解为 $y$ 时，尝试一个大小为 $h$ 的试探步。这会产生一个试探解 $y_{\\mathrm{trial}}$ 和一个局部误差的估计值 $E \\ge 0$。如果 $E \\le T$，则该步被认为是可接受的，其中容差 $T$ 定义为相对和绝对容差的组合：$T = \\text{atol} + \\text{rtol} \\cdot s$，尺度因子 $s = \\max\\{|y|, |y_{\\mathrm{trial}}|\\}$。如果步长被接受，解就推进到 $(t+h, y_{\\mathrm{accept}})$。\n\n无论步长被接受还是拒绝，下一次试探的步长 $h_{\\text{new}}$ 都会根据观察到的误差进行计算。题目指定了一个标准的更新规则：\n$$\nh_{\\text{new}} = g \\cdot h_{\\text{old}}\n$$\n其中 $g$ 是一个增长因子。对于一个局部误差估计行为符合 $\\mathcal{O}(h^q)$ 的方法，理想的因子将是 $(T/E)^{1/q}$。为确保稳定性，该因子被加以调节：\n$$\ng =\n\\begin{cases}\n\\max\\left(g_{\\min}, \\min\\left(g_{\\max}, \\sigma \\left(\\frac{T}{\\max(E, \\varepsilon)}\\right)^{1/q}\\right)\\right), & E > 0 \\\\\ng_{\\max}, & E = 0\n\\end{cases}\n$$\n这里，$\\sigma < 1$ 是一个安全因子，$\\varepsilon$ 是一个非常小的数以防止除以零，而 $g_{\\min}, g_{\\max}$ 是防止步长剧烈变化的界限。题目指定了 $q=5$，$\\sigma=0.9$，$g_{\\min}=0.2$，$g_{\\max}=5$ 和 $\\varepsilon=10^{-30}$。新的步长也被限制在 $[h_{\\min}, h_{\\max}]$ 范围内。\n\n这两种策略仅在如何计算试探解和误差估计 $E$ 上有所不同。\n\n**1. 嵌入式 Runge–Kutta–Fehlberg 4(5) 方法 (RKF45)**\n\n这是一种“嵌入式”方法，它使用一对不同阶（$p=4$ 和 $p+1=5$）的 Runge-Kutta 公式，这些公式共享中间的函数求值（级），以最小化计算成本。对于步长 $h$，该方法计算六个级，$k_1, \\dots, k_6$，然后将它们线性组合以产生两个近似解：一个四阶解 $y_4$ 和一个五阶解 $y_5$。\n$$\ny_4 = y + h \\sum_{i=1}^6 b_i k_i, \\quad y_5 = y + h \\sum_{i=1}^6 b_i^* k_i\n$$\n题目指定使用更高阶的解来推进积分，因此 $y_{\\mathrm{trial}} = y_5$ 且 $y_{\\mathrm{accept}} = y_5$。这两个解之间的差异为低阶方法的局部截断误差提供了一个渐近正确的估计：\n$$\nE = |y_5 - y_4| = \\mathcal{O}(h^5)\n$$\n这个误差估计被用于步长控制逻辑中。由于误差估计是 5 阶的，指定的控制器参数 $q=5$ 是合适的。整个过程每次试探步需要 $6$ 次函数求值。\n\n**2. 使用经典四阶 Runge–Kutta (RK4) 的步长加倍法**\n\n该策略基于 Richardson 外推法，使用单一的底层方法（RK4，阶数为 $p=4$）来生成误差估计。对于一个期望的步长 $h$，解从 $t$ 到 $t+h$ 的推进通过两种不同的方式完成：\n- 一次大小为 $h$ 的单步，得到 $y^{(1)} = \\Phi_h(y)$。\n- 两次大小为 $h/2$ 的连续步，得到 $y^{(2)} = \\Phi_{h/2}(\\Phi_{h/2}(y))$。\n\n更精确的解 $y^{(2)}$ 的局部截断误差可以从两个结果之差估计得出：\n$$\nE = \\frac{|y^{(2)} - y^{(1)}|}{2^p - 1} = \\frac{|y^{(2)} - y^{(1)}|}{15}\n$$\n这个误差估计也是 $\\mathcal{O}(h^{p+1}) = \\mathcal{O}(h^5)$ 阶的，使得 $q=5$ 成为步长控制器的正确选择。题目指定使用更精确的结果来推进解，即 $y_{\\text{accept}} = y^{(2)}$。这个技术计算量很大；一次试探需要一个全步（$4$ 次函数求值）和两个半步（$2 \\times 4 = 8$ 次求值），总共 $12$ 次函数求值，因为没有共享任何级的计算。\n\n程序围绕一个实现了主控制回路的通用自适应积分函数构建。该函数接受一个“步进器”函数作为参数，该函数封装了 RKF45 或步长加倍法特有的逻辑。这种设计将控制逻辑与误差估计方法清晰地分离开来。主脚本定义了三个指定的 ODE 问题，并对每一个问题调用两次积分器——一次使用 RKF45 步进器，一次使用步长加倍步进器——以计算和报告所需的性能指标。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\n\n# --- Global constants for step-size control ---\nSIGMA = 0.9\nG_MIN = 0.2\nG_MAX = 5.0\nEPSILON = 1e-30\nH_MIN = 1e-12\nQ_ORDER = 5.0\n\n# --- Stepper implementation for RKF45 ---\ndef rkf45_step(f, t, y, h):\n    \"\"\"\n    Performs one trial step using the Runge-Kutta-Fehlberg 4(5) method.\n    \"\"\"\n    # Fehlberg coefficients\n    k1 = f(t, y)\n    k2 = f(t + 1/4 * h, y + h * (1/4 * k1))\n    k3 = f(t + 3/8 * h, y + h * (3/32 * k1 + 9/32 * k2))\n    k4 = f(t + 12/13 * h, y + h * (1932/2197 * k1 - 7200/2197 * k2 + 7296/2197 * k3))\n    k5 = f(t + h, y + h * (439/216 * k1 - 8 * k2 + 3680/513 * k3 - 845/4104 * k4))\n    k6 = f(t + 1/2 * h, y + h * (-8/27 * k1 + 2 * k2 - 3544/2565 * k3 + 1859/4104 * k4 - 11/40 * k5))\n\n    # 4th and 5th order solutions\n    y4 = y + h * (25/216 * k1 + 1408/2565 * k3 + 2197/4104 * k4 - 1/5 * k5)\n    y5 = y + h * (16/135 * k1 + 6656/12825 * k3 + 28561/56430 * k4 - 9/50 * k5 + 2/55 * k6)\n\n    # Use 5th order for trial and acceptance\n    y_trial = y5\n    y_accept = y5\n\n    # Error estimate is the difference between the two\n    error_est = abs(y5 - y4)\n    \n    # 6 function evaluations per trial step\n    f_evals = 6\n    \n    return y_trial, y_accept, error_est, f_evals\n\n# --- Stepper implementation for Step-Doubling RK4 ---\ndef rk4_single_step(f, t, y, h):\n    \"\"\"\n    Performs a single step of the classical 4th order Runge-Kutta method.\n    \"\"\"\n    k1 = f(t, y)\n    k2 = f(t + h/2.0, y + h/2.0 * k1)\n    k3 = f(t + h/2.0, y + h/2.0 * k2)\n    k4 = f(t + h, y + h * k3)\n    return y + h/6.0 * (k1 + 2*k2 + 2*k3 + k4)\n\ndef sd_rk4_step(f, t, y, h):\n    \"\"\"\n    Performs one trial step using step-doubling with the RK4 method.\n    \"\"\"\n    # One step of size h\n    y1 = rk4_single_step(f, t, y, h)\n    \n    # Two steps of size h/2\n    y_mid = rk4_single_step(f, t, y, h/2.0)\n    y2 = rk4_single_step(f, t + h/2.0, y_mid, h/2.0)\n\n    # Use the more accurate solution for trial and acceptance\n    y_trial = y2\n    y_accept = y2\n    \n    # Richardson error estimate\n    error_est = abs(y2 - y1) / 15.0\n    \n    # 12 function evaluations per trial step (4 for full step, 8 for two half-steps)\n    f_evals = 12\n    \n    return y_trial, y_accept, error_est, f_evals\n\n# --- Generic adaptive ODE integrator ---\ndef integrate(f, t0, tf, y0, rtol, atol, stepper_func):\n    \"\"\"\n    Integrates an ODE using an adaptive step-size strategy.\n    \"\"\"\n    t = float(t0)\n    y = float(y0)\n    \n    h_max = float(tf - t0)\n    h = h_max / 50.0\n\n    total_f_evals = 0\n    accepted_h_sum = 0.0\n    accepted_steps_count = 0\n\n    while t < tf:\n        if t + h > tf:\n            h = tf - t\n\n        y_trial, y_accept, E, f_evals = stepper_func(f, t, y, h)\n        total_f_evals += f_evals\n        \n        s = max(abs(y), abs(y_trial))\n        T = atol + rtol * s\n\n        accepted = (E <= T)\n\n        if accepted:\n            accepted_h_sum += h\n            accepted_steps_count += 1\n            t += h\n            y = y_accept\n\n        # Step-size update logic\n        if E > 0:\n            g = max(G_MIN, min(G_MAX, SIGMA * (T / max(E, EPSILON))**(1.0/Q_ORDER)))\n        else: # E == 0 implies error is smaller than machine precision\n            g = G_MAX\n        \n        h = max(H_MIN, min(h_max, g * h))\n\n    mean_h = accepted_h_sum / accepted_steps_count if accepted_steps_count > 0 else 0.0\n    \n    return total_f_evals, mean_h\n\n# --- Main solution function ---\ndef solve():\n    \"\"\"\n    Defines test cases and runs the comparison, printing the final result.\n    \"\"\"\n    # Define the ODE functions for the test cases\n    def f1(t, y): return -2.0 * y + t\n    def f2(t, y): return 50.0 * math.cos(50.0 * t) - y\n    def f3(t, y): return y * (1.0 - y)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: smooth linear\n        (f1, 0.0, 10.0, 1.0, 1e-6, 1e-9),\n        # Case 2: oscillatory forcing\n        (f2, 0.0, 2.0, 0.0, 1e-5, 1e-7),\n        # Case 3: logistic growth\n        (f3, 0.0, 10.0, 1e-6, 1e-7, 1e-12)\n    ]\n\n    results = []\n    for case in test_cases:\n        f, t0, tf, y0, rtol, atol = case\n        \n        # Run RKF45 strategy\n        n_rkf45, h_avg_rkf45 = integrate(f, t0, tf, y0, rtol, atol, rkf45_step)\n        \n        # Run Step-Doubling RK4 strategy\n        n_sd, h_avg_sd = integrate(f, t0, tf, y0, rtol, atol, sd_rk4_step)\n        \n        results.append([n_rkf45, n_sd, h_avg_rkf45, h_avg_sd])\n\n    # Final print statement in the exact required format.\n    print(str(results))\n\nsolve()\n```", "id": "2372273"}, {"introduction": "真实世界的模型常常包含“开关”、碰撞或其他事件，这些会在系统的控制方程中引入不连续性。标准的自适应算法通常假设函数是光滑的，在这些不连续点上可能会失效或产生严重误差。本实践旨在让您学习如何增强求解器，通过将积分区间在已知的“断点”处切分，来显式处理这些不连续性，这是构建真正稳健的积分器所必需的关键技能。[@problem_id:2370750]", "problem": "给定初始值问题 (IVP)，其形式为 $$\\frac{dy}{dt} = f(t,y), \\quad y(t_0) = y_0,$$ 其中导数函数 $f(t,y)$ 关于 $t$ 仅是分段连续的。对于每个 IVP，积分的时间区间为 $[t_0, T]$。提供一个有限的间断点集合 $\\mathcal{B} = \\{b_1, b_2, \\ldots, b_m\\}$，在这些点上 $f(t, y)$ 可能不连续。您必须设计一个程序，使用自适应步长控制策略计算 $y(T)$ 的近似值，该策略需满足以下基本要求：(i) 每个被接受的步长的局部误差必须通过一个形式为 $$\\mathrm{scale} = \\mathrm{atol} + \\mathrm{rtol} \\cdot \\max\\{|y_{\\text{old}}|, |y_{\\text{new}}|\\},$$ 的标度，相对于绝对容差 $\\mathrm{atol}$ 和相对容差 $\\mathrm{rtol}$ 進行控制，以及 (ii) 任何单个数值步长都不得跨越任何 $b_i \\in \\mathcal{B}$；也就是说，每个 $b_i$ 都必须被视为数值近似的一个子区间的端点。如果 $T \\in \\mathcal{B}$，您必须返回在 $T$ 点的左极限值，即在 $[t_0, T)$ 上积分而不跨越 $T$ 所得到的值。每个 IVP 的输出必须是一个等于 $y(T)$ 近似值的实数，表示为四舍五入到 $10$ 位小数的浮点数。\n\n使用以下 IVP 测试套件，所有数学量均以标准单位表示，无任何物理量纲：\n\n- 测试用例 $1$：\n  - 微分方程：$$f_1(t,y) = -2\\,y + 1.$$\n  - 区间：$$t \\in [0, 1].$$\n  - 初始条件：$$y(0) = 0.$$\n  - 间断点：$$\\mathcal{B} = \\varnothing.$$\n  - 目标时间：$$T = 1.$$\n  - 容差：$$\\mathrm{atol} = 10^{-10}, \\quad \\mathrm{rtol} = 10^{-10}.$$\n\n- 测试用例 $2$：\n  - 微分方程：$$f_2(t,y) = -y + 2\\,H(t - 0.5),$$ 其中 $H(\\tau)$ 是 Heaviside 阶跃函数，定义为当 $\\tau < 0$ 时 $H(\\tau) = 0$，当 $\\tau \\ge 0$ 时 $H(\\tau) = 1$。\n  - 区间：$$t \\in [0, 1].$$\n  - 初始条件：$$y(0) = 0.$$\n  - 间断点：$$\\mathcal{B} = \\{0.5\\}.$$\n  - 目标时间：$$T = 1.$$\n  - 容差：$$\\mathrm{atol} = 10^{-10}, \\quad \\mathrm{rtol} = 10^{-10}.$$\n\n- 测试用例 $3$：\n  - 定义 $$g(t) = \\begin{cases}\n  0, & t < 0.3,\\\\\n  3, & 0.3 \\le t < 0.3001,\\\\\n  0, & 0.3001 \\le t < 0.7,\\\\\n  -1, & t \\ge 0.7,\n  \\end{cases}$$\n  和 $$f_3(t,y) = -y + g(t).$$\n  - 区间：$$t \\in [0, 1].$$\n  - 初始条件：$$y(0) = 0.$$\n  - 间断点：$$\\mathcal{B} = \\{0.3, 0.3001, 0.7\\}.$$\n  - 目标时间：$$T = 1.$$\n  - 容差：$$\\mathrm{atol} = 10^{-10}, \\quad \\mathrm{rtol} = 10^{-10}.$$\n\n- 测试用例 $4$：\n  - 微分方程：$$f_4(t,y) = -y + H(t - 1).$$\n  - 区间：$$t \\in [0, 1].$$\n  - 初始条件：$$y(0) = 1.$$\n  - 间断点：$$\\mathcal{B} = \\{1\\}.$$\n  - 目标时间：$$T = 1.$$ 如果 $T$ 与一个间断点重合，则按上文所述返回在 $T$ 点的左极限值。\n  - 容差：$$\\mathrm{atol} = 10^{-10}, \\quad \\mathrm{rtol} = 10^{-10}.$$\n\n您的程序必须解决所有四个测试用例，并生成一行输出，其中包含一个用方括号括起来的逗号分隔列表，结果按测试用例的顺序排列。列表中的每个条目都必须四舍五入到 $10$ 位小数。例如，输出格式必须严格遵循\n\"[r1,r2,r3,r4]\"\n的形式，其中 $r1$、$r2$、$r3$ 和 $r4$ 是对应于测试用例 1 到 4 的浮点数结果。", "solution": "问题陈述已经过验证，被认为是有效的。它具有科学依据，提法恰当，客观且完整。它描述了计算工程中的一个标准问题：求解带有分段连续强迫项的常微分方程 (ODE) 的数值解。对自适应步长控制策略和不连续点处理的要求有明确规定，构成了一个定义明确的計算任務。\n\n该问题要求设计一个数值积分器，用于求解形式为\n$$\n\\frac{dy}{dt} = f(t,y), \\quad y(t_0) = y_0\n$$\n的初始值问题 (IVP)，积分区间为 $[t_0, T]$，其中函数 $f(t,y)$ 可能在指定的间断点 $\\mathcal{B} = \\{b_1, b_2, \\ldots, b_m\\}$ 处存在有限个关于时间 $t$ 的跳跃间断点。\n\n解决方案的核心在于一个双层策略。在较高层次上，一个驱动程序将总积分区间 $[t_0, T]$ 分割成一系列子区间，这些子区间的端点是初始时间 $t_0$、最终时间 $T$ 以及 $\\mathcal{B}$ 中的间断点。在较低层次上，一个稳健的自适应步长 ODE 求解器在每个连续的子区间上对解进行积分。\n\n对于核心积分器，显式嵌入式 Runge-Kutta 方法是一个合适的选择。我们将使用 Dormand-Prince 5(4) 对，以下简称 DOPRI5(4)。该方法因其出色的稳定性和效率而被广泛使用。对于每个大小为 $h$ 的步长，它会计算解的两种近似：一个五阶精度的解 $y_{n+1}$ 和一个四阶精度的解 $\\hat{y}_{n+1}$。这两者之差提供了局部截断误差的估计，$E_{n+1} = y_{n+1} - \\hat{y}_{n+1}$。\n\n自适应步长控制算法按以下步骤进行。在每个步骤 $n$，从 $(t_n, y_n)$ 开始，步长为 $h_n$：\n1.  使用 DOPRI5(4) 公式计算五阶解 $y_{n+1}$ 和四阶解 $\\hat{y}_{n+1}$。\n2.  计算当前步长所需的容差标度，定义为 $\\mathrm{scale} = \\mathrm{atol} + \\mathrm{rtol} \\cdot \\max(|y_n|, |y_{n+1}|)$，其中 $\\mathrm{atol}$ 和 $\\mathrm{rtol}$ 是预设的绝对和相对容差。\n3.  计算归一化误差，$err = |y_{n+1} - \\hat{y}_{n+1}| / \\mathrm{scale}$。\n4.  如果 $err \\le 1$，则接受该步长。新状态为 $(t_{n+1}, y_{n+1}) = (t_n + h_n, y_{n+1})$。\n5.  如果 $err > 1$，则拒绝该步长。状态保持为 $(t_n, y_n)$。\n6.  下一次尝试（或下一个被接受的步长）的步长使用标准公式进行调整：\n    $$\n    h_{\\text{new}} = h_n \\cdot S \\cdot \\left(\\frac{1}{err}\\right)^{1/(p+1)}\n    $$\n    其中 $p=4$ 是低阶方法的阶数，$S$ 是一个安全因子（通常 $S \\approx 0.9$），用于提高稳定性。步长的变化通常会受到限制，以防止过分激进的调整。\n\n高层驱动程序管理跨越不连续点的积分。它首先通过组合 $\\{t_0, T\\}$ 和间断点集合 $\\mathcal{B}$ 来构建一个唯一的、已排序的时间点列表。设这些点为 $\\tau_0, \\tau_1, \\ldots, \\tau_k$，其中 $\\tau_0 = t_0$ 且 $\\tau_k = T$。然后，驱动程序为每个子区间 $[\\tau_i, \\tau_{i+1}]$ 迭代调用自适应积分器。前一个子积分得到的最终状态 $y(\\tau_i)$ 将作为从 $\\tau_i$ 开始的下一个子积分的初始条件。这确保了沒有数值步长会跨越不连续点，符合要求。\n\n如果最终时间 $T$ 本身就是一个间斷點（如测试用例 4 所示），则适用一个特殊条件。问题要求返回解在 $T$ 点的左极限，记为 $y(T^-)$。这被解释为在最后一个子区间（比如 $[b_k, T]$）上进行积分，使用对 $t < T$ 有效的导数函数 $f(t,y)$ 的定义。对于测试用例 4，$f_4(t,y) = -y + H(t - 1)$ 且 $T=1$，这意味着在整个区间 $[0,1]$ 上对 $y' = -y$ 进行积分，因为对于所有 $t<1$，$H(t-1)=0$。\n\n这种结构化方法针对每个测试用例的实现如下：\n-   **测试用例 1：** $f_1(t,y) = -2y + 1$。没有间断点。在 $[0, 1]$ 上调用一次自适应积分器。\n-   **测试用例 2：** $f_2(t,y) = -y + 2H(t - 0.5)$。间断点在 $t=0.5$。首先，在 $[0, 0.5]$ 上对 $y' = -y$ 进行积分。然后，使用得到的 $y(0.5)$，在 $[0.5, 1]$ 上对 $y' = -y + 2$ 进行积分。\n-   **测试用例 3：** $f_3(t,y) = -y + g(t)$。间断点在 $0.3, 0.3001, 0.7$。积分分四个阶段进行：\n    1.  在 $[0, 0.3]$ 上，使用 $f(t,y) = -y$。\n    2.  在 $[0.3, 0.3001]$ 上，使用 $f(t,y) = -y + 3$。\n    3.  在 $[0.3001, 0.7]$ 上，使用 $f(t,y) = -y$。\n    4.  在 $[0.7, 1]$ 上，使用 $f(t,y) = -y - 1$。\n-   **测试用例 4：** $f_4(t,y) = -y + H(t - 1)$。$T=1$ 是一个间断点。为了求得左极限，我们在区间 $[0, 1]$ 上对 $y' = -y$（即 $f_4$ 在 $t<1$ 时的形式）进行积分。\n\n该方法正确地处理了问题的所有约束，提供了一个精确且稳健的数值解。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves a suite of IVPs with piecewise continuous derivatives using a custom\n    adaptive Runge-Kutta integrator.\n    \"\"\"\n\n    # Dormand-Prince 5(4) Butcher Tableau coefficients\n    C = np.array([0, 1/5, 3/10, 4/5, 8/9, 1, 1], dtype=np.float64)\n    A = np.array([\n        [0, 0, 0, 0, 0, 0, 0],\n        [1/5, 0, 0, 0, 0, 0, 0],\n        [3/40, 9/40, 0, 0, 0, 0, 0],\n        [44/45, -56/15, 32/9, 0, 0, 0, 0],\n        [19372/6561, -25360/2187, 64448/6561, -212/729, 0, 0, 0],\n        [9017/3168, -355/33, 46732/5247, 49/176, -5103/18656, 0, 0],\n        [35/384, 0, 500/1113, 125/192, -2187/6784, 11/84, 0]\n    ], dtype=np.float64)\n    \n    # 5th order solution coefficients\n    B5 = np.array([35/384, 0, 500/1113, 125/192, -2187/6784, 11/84, 0], dtype=np.float64)\n    # 4th order solution coefficients (for error estimation)\n    B4 = np.array([5179/57600, 0, 7571/16695, 393/640, -92097/339200, 187/2100, 1/40], dtype=np.float64)\n    E = B5 - B4\n\n    def adaptive_integrator(f, t_span, y0, atol, rtol):\n        \"\"\"\n        Integrates a single continuous IVP using an adaptive DOPRI5(4) method.\n        \"\"\"\n        t0, t_end = t_span\n        t = t0\n        y = y0\n\n        h = 1e-6  # Initial step size suggestion\n        \n        # Integrator parameters\n        safety_factor = 0.9\n        min_scale = 0.2\n        max_scale = 5.0\n\n        while t < t_end:\n            if t + h > t_end:\n                h = t_end - t\n\n            # Compute stages\n            k = np.zeros(7, dtype=np.float64)\n            for i in range(7):\n                k_sum = np.dot(A[i, :i], k[:i])\n                k[i] = f(t + C[i] * h, y + h * k_sum)\n\n            # Compute 5th order solution and error estimate\n            y_new = y + h * np.dot(B5, k)\n            err_est = h * np.dot(E, k)\n\n            # Error control\n            scale = atol + rtol * max(abs(y), abs(y_new))\n            err_norm = abs(err_est) / scale\n\n            if err_norm <= 1.0: # Step accepted\n                t += h\n                y = y_new\n            \n            # Step size adaptation\n            if err_norm > 1e-15: # Avoid division by zero\n                h_new_factor = safety_factor * (err_norm ** -0.2)\n                h *= min(max_scale, max(min_scale, h_new_factor))\n            else: # Error is very small, can increase step size aggressively\n                h *= max_scale\n\n            if h < 1e-15: # Prevent step size from becoming too small\n                 raise RuntimeError(\"Step size underflow\")\n        \n        return y\n\n    test_cases = [\n        {'id': 1}, {'id': 2}, {'id': 3}, {'id': 4}\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        atol = 1e-10\n        rtol = 1e-10\n\n        if case['id'] == 1:\n            f1 = lambda t, y: -2 * y + 1\n            y0 = 0.0\n            t_span = [0.0, 1.0]\n            result = adaptive_integrator(f1, t_span, y0, atol, rtol)\n        \n        elif case['id'] == 2:\n            f2a = lambda t, y: -y\n            f2b = lambda t, y: -y + 2\n            y0 = 0.0\n            # Interval 1: [0, 0.5]\n            y_mid = adaptive_integrator(f2a, [0.0, 0.5], y0, atol, rtol)\n            # Interval 2: [0.5, 1.0]\n            result = adaptive_integrator(f2b, [0.5, 1.0], y_mid, atol, rtol)\n\n        elif case['id'] == 3:\n            y0 = 0.0\n            # Interval 1: [0, 0.3]\n            f3a = lambda t, y: -y\n            y1 = adaptive_integrator(f3a, [0.0, 0.3], y0, atol, rtol)\n            # Interval 2: [0.3, 0.3001]\n            f3b = lambda t, y: -y + 3\n            y2 = adaptive_integrator(f3b, [0.3, 0.3001], y1, atol, rtol)\n            # Interval 3: [0.3001, 0.7]\n            f3c = lambda t, y: -y\n            y3 = adaptive_integrator(f3c, [0.3001, 0.7], y2, atol, rtol)\n            # Interval 4: [0.7, 1.0]\n            f3d = lambda t, y: -y - 1\n            result = adaptive_integrator(f3d, [0.7, 1.0], y3, atol, rtol)\n\n        elif case['id'] == 4:\n            # Left-limit case: integrate y' = -y for t in [0, 1]\n            f4 = lambda t, y: -y\n            y0 = 1.0\n            t_span = [0.0, 1.0]\n            result = adaptive_integrator(f4, t_span, y0, atol, rtol)\n\n        results.append(round(result, 10))\n\n    # Format the final output string\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2370750"}, {"introduction": "从单个常微分方程（ODE）扩展到方程组是解决工程问题的常态。在处理方程组时，不同分量（如温度和压力）可能具有截然不同的数值尺度和动态特性，因此需要不同的精度要求。本实践将指导您从使用单一的标量误差容限，升级到实现更灵活的、基于分量的向量式容限控制，这是专业级 ODE 求解器的一个标志性特征，对于精确求解多尺度物理系统至关重要。[@problem_id:2370767]", "problem": "要求您设计并实现一种带有分量级误差控制的自适应显式单步法，用于求解形式为 $\\dot{\\mathbf{y}}(t) = \\mathbf{f}(t,\\mathbf{y}(t))$、初始条件为 $\\mathbf{y}(t_0) = \\mathbf{y}_0 \\in \\mathbb{R}^n$ 的常微分方程组。目标是满足一个分量级绝对误差容限向量 $\\mathbf{tol} = [tol_1,\\dots,tol_n]^T$ 的要求，其中每个 $tol_i > 0$ 由用户指定。该方法必须基于一个嵌入式龙格-库塔对，以便在每个试探步中，您能获得两个不同阶的近似解 $\\mathbf{y}^{[high]}$ 和 $\\mathbf{y}^{[low]}$，并估计出局部截断误差向量 $\\mathbf{e} = \\mathbf{y}^{[high]} - \\mathbf{y}^{[low]}$。当且仅当分量级归一化误差的无穷范数满足 $\\max_i \\left( |e_i| / tol_i \\right) \\le 1$ 时，该步长被接受。否则，该步长被拒绝，并以更小的步长重试。您必须根据单步法局部截断误差的基本缩放定律，推导出一个有理论依据的步长控制器：如果局部误差对于某个常数 $C$ 和方法阶数 $p$ 表现为 $C h^{p+1}$，则应调整步长 $h$ 以使归一化误差趋向于 1，同时使用一个严格小于 1 的乘性安全因子，并将 $h$ 的变化限制在最小和最大增长因子之间。您不得使用任何来自外部库的黑箱常微分方程求解器。\n\n您的实现应基于一个具体的、广泛使用的 $(5,4)$ 阶嵌入式龙格-库塔对。请使用 Dormand–Prince $(5,4)$ 对，其布彻表系数如下（所有省略的项均为零）。级节点 $\\{c_j\\}$ 为：$c_2 = \\frac{1}{5}$，$c_3 = \\frac{3}{10}$，$c_4 = \\frac{4}{5}$，$c_5 = \\frac{8}{9}$，$c_6 = 1$，$c_7 = 1$。对于级 $j=2,\\dots,7$ 的内部权重 $\\{a_{j\\ell}\\}$ 为：\n- $a_{21} = \\frac{1}{5}$。\n- $a_{31} = \\frac{3}{40}$，$a_{32} = \\frac{9}{40}$。\n- $a_{41} = \\frac{44}{45}$，$a_{42} = -\\frac{56}{15}$，$a_{43} = \\frac{32}{9}$。\n- $a_{51} = \\frac{19372}{6561}$，$a_{52} = -\\frac{25360}{2187}$，$a_{53} = \\frac{64448}{6561}$，$a_{54} = -\\frac{212}{729}$。\n- $a_{61} = \\frac{9017}{3168}$，$a_{62} = -\\frac{355}{33}$，$a_{63} = \\frac{46732}{5247}$，$a_{64} = \\frac{49}{176}$，$a_{65} = -\\frac{5103}{18656}$。\n- $a_{71} = \\frac{35}{384}$，$a_{72} = 0$，$a_{73} = \\frac{500}{1113}$，$a_{74} = \\frac{125}{192}$，$a_{75} = -\\frac{2187}{6784}$，$a_{76} = \\frac{11}{84}$。\n五阶权重 $\\{b^{[5]}_\\ell\\}$ 为 $b^{[5]}_1 = \\frac{35}{384}$，$b^{[5]}_2 = 0$，$b^{[5]}_3 = \\frac{500}{1113}$，$b^{[5]}_4 = \\frac{125}{192}$，$b^{[5]}_5 = -\\frac{2187}{6784}$，$b^{[5]}_6 = \\frac{11}{84}$，$b^{[5]}_7 = 0$。嵌入式四阶权重 $\\{b^{[4]}_\\ell\\}$ 为 $b^{[4]}_1 = \\frac{5179}{57600}$，$b^{[4]}_2 = 0$，$b^{[4]}_3 = \\frac{7571}{16695}$，$b^{[4]}_4 = \\frac{393}{640}$，$b^{[4]}_5 = -\\frac{92097}{339200}$，$b^{[4]}_6 = \\frac{187}{2100}$，$b^{[4]}_7 = \\frac{1}{40}$。使用这两个公式的差来计算误差估计。\n\n请使用以下常数设计控制器：用于误差缩放的方法阶数 $p = 4$，安全因子 $s = 0.9$，最小和最大增长因子分别为 $g_{\\min} = 0.1$ 和 $g_{\\max} = 5.0$，以及步长的硬性界限 $h_{\\min} = 10^{-12}$ 和 $h_{\\max} = 10^{0}$。您必须从用户提供的初始步长 $h_0$ 开始，并确保步进不会超过最终时间一个步长以上；如果一个提议的步长将越过最终时间，应将其截断以精确地落在最终时间上。如果一个步长被拒绝，且调整后的步长将低于 $h_{\\min}$，您仍必须以 $h = h_{\\min}$ 继续，以保证向前推进。如果归一化误差等于零，为下一步选择最大增长因子。\n\n为进行验证，通过将数值解 $\\mathbf{y}(t_f)$ 与精确解 $\\mathbf{y}_{\\text{exact}}(t_f)$ 进行比较，为每个测试用例计算最终时刻的全局误差诊断。对每个用例，报告单一标量\n$$\nR = \\max_i \\frac{|y_i(t_f) - y_{\\text{exact},i}(t_f)|}{tol_i}.\n$$\n您的程序必须求解所有以下测试用例并输出它们的 $R$ 值：\n\n- 用例 A（理想情况，解耦线性系统）：维度 $n = 3$，时间区间 $[t_0,t_f] = [0,5]$，初始条件 $\\mathbf{y}_0 = [1,1,1]^T$，动力学 $\\dot{y}_1 = -y_1$，$\\dot{y}_2 = -2 y_2$，$\\dot{y}_3 = -3 y_3$，分量级容限 $\\mathbf{tol} = [10^{-8},10^{-9},10^{-10}]^T$，初始步长 $h_0 = 10^{-1}$。精确解为 $y_1(t) = e^{-t}$，$y_2(t) = e^{-2t}$，$y_3(t) = e^{-3t}$。\n- 用例 B（振荡，中等区间）：维度 $n = 2$，时间区间 $[t_0,t_f] = [0,2\\pi]$，初始条件 $\\mathbf{y}_0 = [1,0]^T$，动力学 $\\dot{y}_1 = y_2$，$\\dot{y}_2 = -y_1$，分量级容限 $\\mathbf{tol} = [10^{-8},10^{-8}]^T$，初始步长 $h_0 = 5\\times 10^{-2}$。精确解为 $y_1(t) = \\cos t$，$y_2(t) = -\\sin t$。角度单位使用弧度。\n- 用例 C（分量间混合尺度）：维度 $n = 3$，时间区间 $[t_0,t_f] = [0,2]$，初始条件 $\\mathbf{y}_0 = [10^{3},10^{-3},0]^T$，动力学 $\\dot{y}_1 = -10^{-1} y_1$，$\\dot{y}_2 = -5 y_2$，$\\dot{y}_3 = \\cos t$，分量级容限 $\\mathbf{tol} = [10^{-3},10^{-9},10^{-6}]^T$，初始步长 $h_0 = 10^{-2}$。精确解为 $y_1(t) = 10^{3} e^{-10^{-1} t}$，$y_2(t) = 10^{-3} e^{-5 t}$，$y_3(t) = \\sin t$。\n- 用例 D（带有常数分量的边界情况）：维度 $n = 2$，时间区间 $[t_0,t_f] = [0,5]$，初始条件 $\\mathbf{y}_0 = [1,1]^T$，动力学 $\\dot{y}_1 = 0$，$\\dot{y}_2 = -y_2$，分量级容限 $\\mathbf{tol} = [10^{-12},10^{-8}]^T$，初始步长 $h_0 = 10^{-1}$。精确解为 $y_1(t) = 1$，$y_2(t) = e^{-t}$。\n\n您的程序应产生单行输出，其中包含形如 $[R_A,R_B,R_C,R_D]$ 的值，这是一个用方括号括起来的逗号分隔列表。每个 $R$ 值必须以科学记数法打印，小数点后恰好有 $6$ 位数字（例如，$1.234567e-03$）。", "solution": "问题陈述已经过验证，被认为是有效的。它在计算工程学领域提出了一个良定的、有科学依据的任务，为设计和实现一个自适应常微分方程求解器提供了所有必要的参数和规范。\n\n目标是为具有初始条件 $\\mathbf{y}(t_0) = \\mathbf{y}_0$ 的一阶常微分方程（ODE）系统 $\\dot{\\mathbf{y}}(t) = \\mathbf{f}(t, \\mathbf{y}(t))$ 构建一个自适应步长求解器。该求解器必须使用 Dormand–Prince $(5,4)$ 嵌入式龙格-库塔对和一个有理论依据的步长控制机制，以满足分量级绝对误差容限向量 $\\mathbf{tol}$。\n\n首先，我们构建显式龙格-库塔法的一般结构。给定一个解 $(\\mathbf{y}_k, t_k)$ 和一个步长 $h$，该方法在时间 $t_{k+1} = t_k + h$ 计算出一个近似解 $\\mathbf{y}_{k+1}$。这是通过计算一系列中间级导数 $\\mathbf{k}_j$ 来实现的：\n$$\n\\mathbf{k}_j = \\mathbf{f}\\left(t_k + c_j h, \\mathbf{y}_k + h \\sum_{\\ell=1}^{j-1} a_{j\\ell} \\mathbf{k}_\\ell\\right) \\quad \\text{for } j=1, \\dots, s\n$$\n其中 $s$ 是级数。然后使用这些级的加权和来推进解：\n$$\n\\mathbf{y}_{k+1} = \\mathbf{y}_k + h \\sum_{j=1}^s b_j \\mathbf{k}_j\n$$\n系数 $c_j$、$a_{j\\ell}$ 和 $b_j$ 定义了具体的方法，并由其布彻表给出。\n\n一个嵌入式龙格-库塔对使用两组权重 $\\mathbf{b}^{[high]}$ 和 $\\mathbf{b}^{[low]}$，分别对应于不同阶（比如 $p$ 和 $p-1$）的方法。在我们的例子中，Dormand–Prince $(5,4)$ 对提供了一个五阶方法和一个嵌入式四阶方法。在计算出各级 $\\mathbf{k}_j$ 之后，我们可以形成两个近似解：\n$$\n\\mathbf{y}_{k+1}^{[high]} = \\mathbf{y}_k + h \\sum_{j=1}^7 b_j^{[5]} \\mathbf{k}_j \\quad (\\text{Order } 5)\n$$\n$$\n\\mathbf{y}_{k+1}^{[low]} = \\mathbf{y}_k + h \\sum_{j=1}^7 b_j^{[4]} \\mathbf{k}_j \\quad (\\text{Order } 4)\n$$\n这两个解之间的差值为低阶方法提供了一个局部截断误差的估计：\n$$\n\\mathbf{e}_{k+1} = \\mathbf{y}_{k+1}^{[high]} - \\mathbf{y}_{k+1}^{[low]} = h \\sum_{j=1}^7 (b_j^{[5]} - b_j^{[4]}) \\mathbf{k}_j\n$$\n这个误差估计 $\\mathbf{e}_{k+1}$ 是自适应步长控制的基础。控制器的目标是调整步长 $h$，使这个误差满足指定的容限。遵循局部外推原理，如果步长被接受，则使用更精确的五阶解 $\\mathbf{y}_{k+1}^{[high]}$ 来传播解。\n\n步长控制逻辑基于一个标量归一化误差 $E$，它被定义为各分量误差由其各自的绝对容限归一化后的最大值：\n$$\nE = \\max_i \\left( \\frac{|e_i|}{tol_i} \\right)\n$$\n当且仅当 $E \\le 1$ 时，一个试探步被认为是可接受的。如果一个步长被接受，我们继续到下一个积分区间。如果被拒绝（$E > 1$），当前步被丢弃，并以一个更小的步长 $h$ 重试。\n\n控制器的核心是选择下一步长 $h_{new}$ 的算法。四阶方法的局部截断误差与步长的五次方成比例，即当 $p=4$ 时 $\\|\\mathbf{e}\\| \\propto h^{p+1}$。我们希望找到一个新的步长 $h_{new}$，使得产生的误差 $E_{new}$ 约等于 $1$。这导出了关系式：\n$$\n1 \\approx E \\left( \\frac{h_{new}}{h_{old}} \\right)^{p+1}\n$$\n求解 $h_{new}$ 得出 $h_{new} \\approx h_{old} (1/E)^{1/(p+1)}$。为确保稳定性并避免激进的步长变化，我们引入一个安全因子 $s < 1$（给定为 $s=0.9$），并将步长增长/收缩因子限制在 $g_{min}$ 和 $g_{max}$ 之间（给定为 $g_{min}=0.1$ 和 $g_{max}=5.0$）。因此，提议的步长更新因子为：\n$$\ng = \\min(g_{max}, \\max(g_{min}, s \\cdot E^{-1/(p+1)}))\n$$\n其中 $p=4$。新的步长则为 $h_{new} = h_{old} \\cdot g$。根据问题要求，如果归一化误差 $E$ 恰好为零，我们必须使用最大增长因子，因此 $h_{new} = h_{old} \\cdot g_{max}$。\n\n完整的积分算法如下：\n1.  初始化时间 $t \\leftarrow t_0$，解 $\\mathbf{y} \\leftarrow \\mathbf{y}_0$，以及步长 $h \\leftarrow h_0$。\n2.  当 $t < t_f$ 时循环：\n    a. 确保步长不会超过最终时间：$h \\leftarrow \\min(h, t_f - t)$。\n    b. 进入当前步的循环（以处理拒绝情况）：\n        i. 使用给定的 Dormand–Prince 系数计算七个级 $\\mathbf{k}_1, \\dots, \\mathbf{k}_7$。\n        ii. 计算误差估计向量 $\\mathbf{e} = h \\sum_{j=1}^7 (b_j^{[5]} - b_j^{[4]}) \\mathbf{k}_j$。\n        iii. 计算归一化误差 $E = \\max_i (|e_i| / tol_i)$。\n        iv. 如果 $E \\le 1$，步长被接受。跳出内层循环。\n        v. 如果 $E > 1$，步长被拒绝。计算一个新的、更小的步长 $h_{new} = h \\cdot \\min(g_{max}, \\max(g_{min}, s \\cdot E^{-1/5}))$。我们必须通过确保新步长不低于 $h_{min}=10^{-12}$ 来保证向前推进：设置 $h \\leftarrow \\max(h_{new}, h_{min})$ 并重试该步（继续内层循环）。\n    c. 使用高阶解更新状态：$\\mathbf{y} \\leftarrow \\mathbf{y} + h \\sum_{j=1}^7 b_j^{[5]} \\mathbf{k}_j$ 以及 $t \\leftarrow t + h$。\n    d. 计算下一次迭代的步长。如果 $E = 0$，将增长因子设为 $g_{max}$。否则，使用公式 $g = s \\cdot E^{-1/5}$。将其限制在 $[g_{min}, g_{max}]$ 范围内。设这个最优因子为 $g_{opt}$。\n    e. 提议下一步长 $h_{next} = h \\cdot g_{opt}$。\n    f. 将提议的步长限制在绝对界限 $[h_{min}, h_{max}] = [10^{-12}, 1.0]$ 内。设置 $h \\leftarrow \\min(h_{max}, \\max(h_{min}, h_{next}))$。\n3. 完成后，最终向量 $\\mathbf{y}$ 是在 $t_f$ 时的数值解。然后通过将此数值解与提供的精确解进行比较来计算诊断指标 $R$。\n\n该设计系统地实现了问题陈述中的所有要求，从数值方法的选择到自适应控制器的具体逻辑。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to define, run, and report on all test cases.\n    \"\"\"\n\n    # Dormand-Prince (5,4) Butcher Tableau and controller parameters\n    DP5_C = np.array([0, 1/5, 3/10, 4/5, 8/9, 1, 1], dtype=np.float64)\n    DP5_A = np.array([\n        [0, 0, 0, 0, 0, 0, 0],\n        [1/5, 0, 0, 0, 0, 0, 0],\n        [3/40, 9/40, 0, 0, 0, 0, 0],\n        [44/45, -56/15, 32/9, 0, 0, 0, 0],\n        [19372/6561, -25360/2187, 64448/6561, -212/729, 0, 0, 0],\n        [9017/3168, -355/33, 46732/5247, 49/176, -5103/18656, 0, 0],\n        [35/384, 0, 500/1113, 125/192, -2187/6784, 11/84, 0]\n    ], dtype=np.float64)\n    # Weights for the 5th order solution (higher order)\n    DP5_B5 = np.array([35/384, 0, 500/1113, 125/192, -2187/6784, 11/84, 0], dtype=np.float64)\n    # Weights for the 4th order solution (lower order, for error estimation)\n    DP5_B4 = np.array([5179/57600, 0, 7571/16695, 393/640, -92097/339200, 187/2100, 1/40], dtype=np.float64)\n    # Difference of weights for efficient error calculation\n    DP5_E = DP5_B5 - DP5_B4\n    # Method order for error scaling\n    P = 4\n\n    # Controller parameters\n    params = {\n        'C': DP5_C, 'A': DP5_A, 'B': DP5_B5, 'E': DP5_E, 'P': P,\n        's': 0.9, 'g_min': 0.1, 'g_max': 5.0,\n        'h_min': 1e-12, 'h_max': 1.0\n    }\n\n    # --- Test Case Definitions ---\n\n    # Case A: Decoupled linear system\n    f_A = lambda t, y: np.array([-y[0], -2*y[1], -3*y[2]])\n    y_exact_A = lambda t: np.array([np.exp(-t), np.exp(-2*t), np.exp(-3*t)])\n    case_A = {\n        'f': f_A, 't_span': [0.0, 5.0], 'y0': np.array([1.0, 1.0, 1.0]),\n        'tol': np.array([1e-8, 1e-9, 1e-10]), 'h0': 1e-1,\n        'y_exact': y_exact_A\n    }\n\n    # Case B: Oscillatory system\n    f_B = lambda t, y: np.array([y[1], -y[0]])\n    y_exact_B = lambda t: np.array([np.cos(t), -np.sin(t)])\n    case_B = {\n        'f': f_B, 't_span': [0.0, 2*np.pi], 'y0': np.array([1.0, 0.0]),\n        'tol': np.array([1e-8, 1e-8]), 'h0': 5e-2,\n        'y_exact': y_exact_B\n    }\n\n    # Case C: Mixed scales\n    f_C = lambda t, y: np.array([-0.1*y[0], -5*y[1], np.cos(t)])\n    y_exact_C = lambda t: np.array([1e3 * np.exp(-0.1*t), 1e-3 * np.exp(-5*t), np.sin(t)])\n    case_C = {\n        'f': f_C, 't_span': [0.0, 2.0], 'y0': np.array([1e3, 1e-3, 0.0]),\n        'tol': np.array([1e-3, 1e-9, 1e-6]), 'h0': 1e-2,\n        'y_exact': y_exact_C\n    }\n\n    # Case D: Constant component\n    f_D = lambda t, y: np.array([0.0, -y[1]])\n    y_exact_D = lambda t: np.array([1.0, np.exp(-t)])\n    case_D = {\n        'f': f_D, 't_span': [0.0, 5.0], 'y0': np.array([1.0, 1.0]),\n        'tol': np.array([1e-12, 1e-8]), 'h0': 1e-1,\n        'y_exact': y_exact_D\n    }\n\n    test_cases = [case_A, case_B, case_C, case_D]\n    results = []\n\n    for case in test_cases:\n        y_final = adaptive_rk_solver(case['f'], case['t_span'], case['y0'],\n                                     case['tol'], case['h0'], params)\n        y_exact_final = case['y_exact'](case['t_span'][1])\n        \n        # Calculate the final diagnostic R\n        R = np.max(np.abs(y_final - y_exact_final) / case['tol'])\n        results.append(R)\n\n    # Print results in the specified format\n    print(f\"[{','.join([f'{r:.6e}' for r in results])}]\")\n\ndef adaptive_rk_solver(f, t_span, y0, tol, h0, params):\n    \"\"\"\n    Implements an adaptive step-size Runge-Kutta solver based on the\n    Dormand-Prince (5,4) pair as specified.\n    \"\"\"\n    t0, tf = t_span\n    t = t0\n    y = np.copy(y0)\n    h = h0\n    \n    # Unpack parameters\n    C, A, B, E_w = params['C'], params['A'], params['B'], params['E']\n    p = params['P']\n    s, g_min, g_max = params['s'], params['g_min'], params['g_max']\n    h_min, h_max = params['h_min'], params['h_max']\n    \n    num_stages = len(C)\n    \n    while t < tf:\n        # Clip step size to not overshoot tf\n        if t + h > tf:\n            h = tf - t\n            \n        accepted = False\n        while not accepted:\n            # Compute stages\n            k = np.zeros((num_stages, len(y)), dtype=np.float64)\n            k[0] = f(t, y)\n            for i in range(1, num_stages):\n                y_stage = y + h * A[i, :i] @ k[:i, :]\n                k[i] = f(t + C[i] * h, y_stage)\n\n            # Calculate error estimate\n            error_est = h * (E_w @ k)\n            \n            # Calculate normalized error scalar\n            # Adding a small epsilon to tol to prevent division by zero in theory,\n            # though problem constraints guarantee tol_i > 0\n            err_norm = np.max(np.abs(error_est) / tol)\n            \n            if err_norm <= 1.0:\n                # Step is accepted\n                accepted = True\n                \n                # Update solution and time\n                t = t + h\n                y = y + h * (B @ k)\n                \n                # Calculate step size for the next step\n                if err_norm == 0.0:\n                    growth_factor = g_max\n                else:\n                    growth_factor = s * (err_norm ** (-1.0 / (p + 1.0)))\n                \n                h_opt_factor = min(g_max, max(g_min, growth_factor))\n                h = min(h_max, max(h_min, h * h_opt_factor))\n                \n            else:\n                # Step is rejected\n                growth_factor = s * (err_norm ** (-1.0 / (p + 1.0)))\n                h_opt_factor = max(g_min, growth_factor) # Only shrink\n                h_new = h * h_opt_factor\n                \n                # Enforce minimum step size to guarantee progress\n                h = max(h_min, h_new) \n                \n                # Check for possible stall at tf\n                if t + h == t:\n                    raise RuntimeError(\"Step size underflow at t={t}\")\n\n    return y\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2370767"}]}