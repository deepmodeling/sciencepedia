{"hands_on_practices": [{"introduction": "逆迭代法是一种强大的工具，用于寻找邻近特定值 $\\sigma$ 的特征值。此方法的效率在很大程度上取决于位移 $\\sigma$ 的选择。本练习旨在通过一个理想化的思想实验，让你思考如何选择最佳位移以最有效地分离出目标特征值，从而深化对“位移-反演”策略核心思想的理解。[@problem_id:2427117]", "problem": "一个实对称矩阵 $A \\in \\mathbb{R}^{4 \\times 4}$ 具有不同的特征值 $\\{10,\\, 9.9,\\, 5,\\, 0.1\\}$。您将使用带常数位移 $\\sigma \\in \\mathbb{R}$ 的位移反迭代法来计算与特征值 $9.9$ 相关的特征向量。请确定在理论上能够最有效地分离特征值 $9.9$ 的 $\\sigma$ 值。请以单个实数形式提供您的答案。无需四舍五入。", "solution": "对问题陈述进行验证。\n\n**第一步：提取已知条件**\n- 矩阵 $A$ 是一个实对称矩阵，$A \\in \\mathbb{R}^{4 \\times 4}$。\n- $A$ 的不同特征值集合为 $\\{\\lambda_1, \\lambda_2, \\lambda_3, \\lambda_4\\} = \\{10,\\, 9.9,\\, 5,\\, 0.1\\}$。\n- 将要使用的方法是带常数位移 $\\sigma \\in \\mathbb{R}$ 的位移反迭代法。\n- 目标是计算与特征值 $9.9$ 相关的特征向量。\n- 任务是找到能够“最有效地分离”特征值 $9.9$ 的 $\\sigma$ 值。\n\n**第二步：使用提取的已知条件进行验证**\n该问题具有科学依据，因为它基于计算工程和线性代数中成熟的数值方法——位移反迭代法。该问题是适定的；术语“最有效地分离”在此背景下有标准解释，指的是收敛速率的最大化。该问题是客观的，不含主观或模糊的语言。所有必要的数据（矩阵的全谱）均已提供，且没有矛盾之处。因此，该问题被认为是有效的。\n\n**第三步：结论与行动**\n问题有效。将提供完整解答。\n\n**解题推导**\n我们首先陈述位移反迭代法的原理。该方法是幂迭代算法的一个变体，应用于矩阵 $B = (A - \\sigma I)^{-1}$，其中 $A$ 是原始矩阵，$\\sigma$ 是一个标量位移，$I$ 是单位矩阵。\n\n设矩阵 $A$ 的特征值为 $\\lambda_k$。则矩阵 $(A - \\sigma I)$ 的特征值为 $(\\lambda_k - \\sigma)$。因此，迭代矩阵 $B = (A - \\sigma I)^{-1}$ 的特征值为 $\\mu_k = \\frac{1}{\\lambda_k - \\sigma}$。\n\n当幂迭代法应用于矩阵 $B$ 时，它会收敛到对应于 $B$ 的模最大特征值的特征向量。设 $B$ 的这个主特征值为 $\\mu_{dom}$。为了使位移反迭代法收敛到与 $A$ 的特定特征值 $\\lambda_{target}$ 相关的特征向量，其对应的特征值 $\\mu_{target} = \\frac{1}{\\lambda_{target} - \\sigma}$ 必须是 $B$ 的主特征值。该条件表示为：\n$$|\\mu_{target}| > |\\mu_k| \\quad \\forall k \\text{ s.t. } \\lambda_k \\neq \\lambda_{target}$$\n该不等式等价于：\n$$\\frac{1}{|\\lambda_{target} - \\sigma|} > \\frac{1}{|\\lambda_k - \\sigma|} \\quad \\forall k \\text{ s.t. } \\lambda_k \\neq \\lambda_{target}$$\n这可以简化为条件：$\\sigma$ 必须比任何其他特征值 $\\lambda_k$ 更接近 $\\lambda_{target}$：\n$$|\\lambda_{target} - \\sigma| < |\\lambda_k - \\sigma| \\quad \\forall k \\text{ s.t. } \\lambda_k \\neq \\lambda_{target}$$\n\n问题要求找到能够“最有效地分离”特征值 $\\lambda_{target} = 9.9$ 的位移 $\\sigma$。在迭代法的背景下，“最有效”被解释为实现最快的收敛速率。幂法的收敛速率由迭代矩阵的第二大模特征值（次主特征值，$\\mu_{sub}$）与主特征值 $\\mu_{dom}$ 的模之比决定。收敛因子为 $R = \\frac{|\\mu_{sub}|}{|\\mu_{dom}|}$。为了最大化收敛速率，必须最小化这个比率 $R$。\n\n在我们的问题中，$\\mu_{dom} = \\mu_{target} = \\frac{1}{9.9 - \\sigma}$。次主特征值 $\\mu_{sub}$ 对应于 $A$ 的某个特征值，我们称之为 $\\lambda_{other}$，它是距离位移 $\\sigma$ 第二近的特征值。因此，$\\mu_{sub} = \\frac{1}{\\lambda_{other} - \\sigma}$。\n\n因此，需要最小化的收敛比率为：\n$$R(\\sigma) = \\frac{|\\mu_{sub}|}{|\\mu_{dom}|} = \\frac{\\left| \\frac{1}{\\lambda_{other} - \\sigma} \\right|}{\\left| \\frac{1}{9.9 - \\sigma} \\right|} = \\frac{|9.9 - \\sigma|}{|\\lambda_{other} - \\sigma|}$$\n总体的收敛因子由“最坏情况”的邻近特征值决定，所以我们必须寻求最小化最大可能比率：\n$$\\min_{\\sigma} \\left( \\max_{k \\neq target} \\frac{|9.9 - \\sigma|}{|\\lambda_k - \\sigma|} \\right)$$\n其他特征值的集合为 $\\{10, 5, 0.1\\}$。\n通过简单观察即可发现，当比率 $R(\\sigma)$ 的分子 $|9.9 - \\sigma|$ 最小时，该表达式也取最小值。\n非负量 $|x|$ 的最小值为 $0$，当 $x=0$ 时取得。\n因此，当满足以下条件时，比率 $R(\\sigma)$ 达到其绝对最小值 $0$：\n$$|9.9 - \\sigma| = 0$$\n这意味着最佳位移是 $\\sigma = 9.9$。\n\n选择 $\\sigma = 9.9$ 时，收敛比率 $R$ 变为 $0$，这对应于无限快的收敛速度。这代表了对所需特征向量最有效的可能分离。问题要求找到“在理论上”实现这一点的 $\\sigma$ 值。这一措辞表明，我们关心的是理论上的最优值，而不是数值实现的实际限制。在实践中，选择 $\\sigma$ 精确等于一个特征值会使矩阵 $(A - \\sigma I)$ 奇异，其逆矩阵无定义。实际实现会使用一个极其接近但不等于 $9.9$ 的 $\\sigma$ 值。然而，所提出的问题是一个原则性问题，理论上的最优值明确为 $\\sigma = 9.9$。", "answer": "$$\\boxed{9.9}$$", "id": "2427117"}, {"introduction": "虽然标准的幂迭代法简单直观，但它有其局限性，例如当存在多个模最大的特征值时，该方法会失效。更先进的算法，如瑞利商迭代法 (RQI)，可以通过在每一步自适应地更新位移来克服这些困难。本练习将引导你分析一个幂迭代法失效而 RQI 成功收敛的案例，从而让你深刻理解 RQI 的稳健性以及简单方法可能不适用的具体条件。[@problem_id:2427129]", "problem": "设 $A \\in \\mathbb{R}^{3 \\times 3}$ 是对称矩阵\n$$\nA=\\begin{pmatrix}\n2 & 0 & 0\\\\\n0 & -2 & 0\\\\\n0 & 0 & 1\n\\end{pmatrix},\n$$\n且初始向量为\n$$\nv_{0}=\\begin{pmatrix}1\\\\1\\\\10\\end{pmatrix}.\n$$\n定义标准幂迭代为 $y_{k+1}=A y_{k} / \\|A y_{k}\\|_{2}$，其中 $y_{0}=v_{0}$，并定义瑞利商迭代 (RQI) 为\n$$\n\\mu_{k}=\\frac{x_{k}^{\\top} A x_{k}}{x_{k}^{\\top} x_{k}},\\quad\nx_{k+1}=\\frac{(A-\\mu_{k} I)^{-1} x_{k}}{\\|(A-\\mu_{k} I)^{-1} x_{k}\\|_{2}},\n$$\n初始条件为 $x_{0}=v_{0}$。从第一性原理出发，分析序列 $\\{y_{k}\\}$ 是否在 $k \\to \\infty$ 时收敛到一个单一方向。然后，确定当从 $x_{0}=v_{0}$ 开始时，瑞利商迭代收敛到的特征值。仅提供该特征值作为您的最终答案，以精确形式给出。无需四舍五入。", "solution": "对问题陈述进行验证，认定其有效。该问题在数值线性代数领域具有科学依据，提法完善且提供了所有必要信息，并且其表述是客观的。因此，我们可以着手求解。\n\n该问题需要进行两个独立的分析：一个针对标准幂迭代，另一个针对瑞利商迭代 (RQI)。\n\n首先，我们分析标准幂迭代序列 $\\{y_k\\}$ 的收敛性。给定矩阵 $A$ 为\n$$\nA=\\begin{pmatrix}\n2 & 0 & 0\\\\\n0 & -2 & 0\\\\\n0 & 0 & 1\n\\end{pmatrix}.\n$$\n由于 $A$ 是一个对角矩阵，其特征值是对角线上的元素，相应的特征向量是标准基向量。设特征值为 $\\lambda_1 = 2$，$\\lambda_2 = -2$ 和 $\\lambda_3 = 1$。相应的标准正交特征向量是\n$$\ne_{1}=\\begin{pmatrix}1\\\\0\\\\0\\end{pmatrix}, \\quad e_{2}=\\begin{pmatrix}0\\\\1\\\\0\\end{pmatrix}, \\quad e_{3}=\\begin{pmatrix}0\\\\0\\\\1\\end{pmatrix}.\n$$\n标准幂方法收敛到与最大模值特征值（主特征值）相关联的特征向量，前提是该特征值是唯一的，并且初始向量在该特征向量方向上具有非零分量。这些特征值的模为 $|\\lambda_1| = |2| = 2$、 $|\\lambda_2| = |-2| = 2$ 和 $|\\lambda_3| = |1| = 1$。存在两个特征值 $\\lambda_1$ 和 $\\lambda_2$，它们具有相同的最大模值 $2$。这是幂方法的一个退化情况。\n\n为分析其行为，我们将初始向量 $y_0 = v_0$ 在特征向量基下表示：\n$$\ny_{0} = v_{0} = \\begin{pmatrix}1\\\\1\\\\10\\end{pmatrix} = 1 \\cdot e_{1} + 1 \\cdot e_{2} + 10 \\cdot e_{3}.\n$$\n未归一化的幂方法的第 $k$ 次迭代由 $A^k y_0$ 给出。\n$$\nA^{k} y_{0} = A^{k}(1 \\cdot e_{1} + 1 \\cdot e_{2} + 10 \\cdot e_{3}) = 1 \\cdot A^{k}e_{1} + 1 \\cdot A^{k}e_{2} + 10 \\cdot A^{k}e_{3}.\n$$\n利用属性 $A^k e_i = \\lambda_i^k e_i$，我们得到\n$$\nA^{k} y_{0} = 1 \\cdot \\lambda_{1}^{k} e_{1} + 1 \\cdot \\lambda_{2}^{k} e_{2} + 10 \\cdot \\lambda_{3}^{k} e_{3} = (2)^{k} e_{1} + (-2)^{k} e_{2} + 10 \\cdot (1)^{k} e_{3}.\n$$\n我们可以提出具有最大模值的项 $(2)^k$：\n$$\nA^{k} y_{0} = (2)^{k} \\left( e_{1} + \\frac{(-2)^{k}}{(2)^{k}} e_{2} + 10 \\frac{1^{k}}{2^{k}} e_{3} \\right) = (2)^{k} \\left( e_{1} + (-1)^{k} e_{2} + 10 \\left(\\frac{1}{2}\\right)^{k} e_{3} \\right).\n$$\n归一化后的向量为 $y_k = \\frac{A^k y_0}{\\|A^k y_0\\|_2}$。当 $k \\to \\infty$ 时，项 $10 (\\frac{1}{2})^k e_3$ 趋于零。$A^k y_0$ 的方向由向量 $e_1 + (-1)^k e_2$ 主导。\n当 $k$ 为偶数时，该向量与 $e_1 + e_2 = \\begin{pmatrix}1\\\\1\\\\0\\end{pmatrix}$ 成比例（在极限情况下）。\n当 $k$ 为奇数时，该向量与 $e_1 - e_2 = \\begin{pmatrix}1\\\\-1\\\\0\\end{pmatrix}$ 成比例（在极限情况下）。\n由于向量序列 $\\{y_k\\}$ 在两个不同的方向之间交替，它不收敛到单一方向。\n\n接下来，我们分析瑞利商迭代的收敛性。迭代从 $x_0 = v_0$ 开始。第一步是计算初始瑞利商 $\\mu_0$：\n$$\n\\mu_{0} = \\frac{x_{0}^{\\top} A x_{0}}{x_{0}^{\\top} x_{0}}.\n$$\n对于 $x_0 = \\begin{pmatrix}1\\\\1\\\\10\\end{pmatrix}$，我们计算分子和分母。\n$$\nx_{0}^{\\top} A x_{0} = \\begin{pmatrix}1 & 1 & 10\\end{pmatrix} \\begin{pmatrix} 2 & 0 & 0\\\\ 0 & -2 & 0\\\\ 0 & 0 & 1 \\end{pmatrix} \\begin{pmatrix}1\\\\1\\\\10\\end{pmatrix} = \\begin{pmatrix}1 & 1 & 10\\end{pmatrix} \\begin{pmatrix}2\\\\-2\\\\10\\end{pmatrix} = (1)(2) + (1)(-2) + (10)(10) = 100.\n$$\n$$\nx_{0}^{\\top} x_{0} = 1^{2} + 1^{2} + 10^{2} = 1 + 1 + 100 = 102.\n$$\n因此，初始瑞利商为\n$$\n\\mu_{0} = \\frac{100}{102} = \\frac{50}{51}.\n$$\n对于对称矩阵，瑞利商迭代等价于使用自适应位移 $\\sigma_k = \\mu_k$ 的反幂法。带有固定位移 $\\sigma$ 的反幂法收敛到与最接近 $\\sigma$ 的特征值相对应的特征向量。对于瑞利商迭代 (RQI)，瑞利商序列 $\\{\\mu_k\\}$ 通常会收敛到一个特征值，并且对于对称矩阵，这种收敛非常迅速（通常是三次收敛）。它收敛到的具体特征值是距离初始瑞利商 $\\mu_0$ 最近的那个。\n\n我们必须找出特征值 $\\lambda_1 = 2$、$\\lambda_2 = -2$、$\\lambda_3 = 1$ 中哪一个最接近 $\\mu_0 = \\frac{50}{51}$。我们计算距离：\n$$\n|\\lambda_1 - \\mu_0| = \\left|2 - \\frac{50}{51}\\right| = \\left|\\frac{102 - 50}{51}\\right| = \\frac{52}{51}.\n$$\n$$\n|\\lambda_2 - \\mu_0| = \\left|-2 - \\frac{50}{51}\\right| = \\left|-\\frac{102 + 50}{51}\\right| = \\frac{152}{51}.\n$$\n$$\n|\\lambda_3 - \\mu_0| = \\left|1 - \\frac{50}{51}\\right| = \\left|\\frac{51 - 50}{51}\\right| = \\frac{1}{51}.\n$$\n最小的距离是 $|\\lambda_3 - \\mu_0| = \\frac{1}{51}$。因此，瑞利商 $\\mu_k$ 将收敛到特征值 $\\lambda_3 = 1$。向量序列 $x_k$ 将收敛到相应的特征向量 $e_3$。问题要求的是迭代收敛到的特征值。", "answer": "$$\\boxed{1}$$", "id": "2427129"}, {"introduction": "理论上我们已经讨论了多种特征值迭代算法，但它们在实践中的表现究竟如何？幂迭代法（线性收敛）、固定位移的逆迭代法（线性收敛）和瑞利商迭代法（三次方收敛）的收敛速度差异巨大。这个动手编程练习将理论付诸实践：你将亲手实现这三种算法，并在不同特性的矩阵上比较它们的性能，直观地观察它们在收敛速度上的显著差异。这种实践经验对于培养你为实际计算问题选择合适工具的直觉至关重要。[@problem_id:2427128]", "problem": "实现一个算法，使用以 Rayleigh 商作为可变位移的反迭代法来近似实对称矩阵的特征对。设非零向量 $x \\in \\mathbb{R}^n$ 的 Rayleigh 商定义为 $R(x) = \\dfrac{x^\\mathsf{T} A x}{x^\\mathsf{T} x}$。考虑将以下三种迭代格式应用于实对称矩阵 $A \\in \\mathbb{R}^{n \\times n}$，给定非零初始向量 $x_0 \\in \\mathbb{R}^n$ 和容差 $\\varepsilon > 0$：\n\n- 幂迭代：$x_{k+1} \\leftarrow \\dfrac{A x_k}{\\lVert A x_k \\rVert_2}$，其中残差范数使用 $\\lambda_k = R(x_k)$ 定义为 $\\lVert A x_k - \\lambda_k x_k \\rVert_2$。\n- 定位移反迭代：固定 $\\sigma_0 = R(x_0)$，通过求解 $(A - \\sigma_0 I) y = x_k$ 并设置 $x_{k+1} \\leftarrow \\dfrac{y}{\\lVert y \\rVert_2}$ 来计算 $x_{k+1}$，其中残差范数使用 $\\lambda_k = R(x_k)$ 定义为 $\\lVert A x_k - \\lambda_k x_k \\rVert_2$。\n- 以 Rayleigh 商为可变位移的反迭代（Rayleigh 商迭代）：在每次迭代中，计算 $\\sigma_k = R(x_k)$，求解 $(A - \\sigma_k I) y = x_k$，并设置 $x_{k+1} \\leftarrow \\dfrac{y}{\\lVert y \\rVert_2}$，其中残差范数使用 $\\lambda_k = R(x_k)$ 定义为 $\\lVert A x_k - \\lambda_k x_k \\rVert_2$。\n\n对于每种格式，当残差范数首次满足 $\\lVert A x_k - \\lambda_k x_k \\rVert_2 \\le \\varepsilon$ 或达到预设的最大迭代次数时停止。所有向量范数均为欧几里得范数，$I$ 表示大小为 $n$ 的单位矩阵。\n\n使用以下测试套件。在每种情况下，设置 $n = 5$，容差 $\\varepsilon = 10^{-10}$，最大迭代次数为 $1000$。\n\n- 测试用例 $\\#1$ (三对角对称正定矩阵):\n  - 矩阵 $A_1 \\in \\mathbb{R}^{5 \\times 5}$:\n    $$\n    A_1 =\n    \\begin{bmatrix}\n    6 & 2 & 0 & 0 & 0 \\\\\n    2 & 5 & 2 & 0 & 0 \\\\\n    0 & 2 & 4 & 2 & 0 \\\\\n    0 & 0 & 2 & 3 & 2 \\\\\n    0 & 0 & 0 & 2 & 2\n    \\end{bmatrix}.\n    $$\n  - 初始向量 $x_0^{(1)} = \\dfrac{1}{\\sqrt{5}} [1, 1, 1, 1, 1]^\\mathsf{T}$。\n\n- 测试用例 $\\#2$ (具有两个非常接近的特征值的对称矩阵):\n  - 定义对角矩阵 $D = \\mathrm{diag}(1, 1 + 10^{-6}, 2, 3, 4)$。\n  - 定义平面旋转，角度为 $\\theta$，使得 $\\cos \\theta = \\dfrac{4}{5}$ 且 $\\sin \\theta = \\dfrac{3}{5}$，并设置\n    $$\n    Q = \\begin{bmatrix}\n    \\cos \\theta & -\\sin \\theta & 0 & 0 & 0 \\\\\n    \\sin \\theta & \\phantom{-}\\cos \\theta & 0 & 0 & 0 \\\\\n    0 & 0 & 1 & 0 & 0 \\\\\n    0 & 0 & 0 & 1 & 0 \\\\\n    0 & 0 & 0 & 0 & 1\n    \\end{bmatrix}.\n    $$\n  - 矩阵 $A_2 = Q^\\mathsf{T} D Q$。\n  - 初始向量 $x_0^{(2)} = [1, 0, 0, 0, 0]^\\mathsf{T}$。\n\n- 测试用例 $\\#3$ (Hilbert 矩阵):\n  - 矩阵 $A_3 \\in \\mathbb{R}^{5 \\times 5}$，其元素为 $(A_3)_{ij} = \\dfrac{1}{i + j - 1}$，其中 $i,j \\in \\{1, 2, 3, 4, 5\\}$。\n  - 初始向量 $x_0^{(3)} = \\dfrac{1}{\\sqrt{5}} [1, -1, 1, -1, 1]^\\mathsf{T}$。\n\n对于每个测试用例，使用相同的 $A$ 和 $x_0$ 独立运行三种格式，并记录残差范数首次满足 $\\lVert A x_k - \\lambda_k x_k \\rVert_2 \\le \\varepsilon$ 时的最小迭代次数 $k$。如果在最大迭代次数内未能收敛，则记录最大迭代次数。\n\n你的程序必须输出单行，其中包含一个由方括号括起来的、包含 $9$ 个整数的逗号分隔列表，顺序如下：\n$[k_{\\mathrm{RQI}}^{(1)}, k_{\\mathrm{fixed}}^{(1)}, k_{\\mathrm{power}}^{(1)}, k_{\\mathrm{RQI}}^{(2)}, k_{\\mathrm{fixed}}^{(2)}, k_{\\mathrm{power}}^{(2)}, k_{\\mathrm{RQI}}^{(3)}, k_{\\mathrm{fixed}}^{(3)}, k_{\\mathrm{power}}^{(3)}]$，其中 $k_{\\mathrm{RQI}}^{(i)}$ 是 Rayleigh 商迭代在测试用例 $i$ 上的迭代次数，$k_{\\mathrm{fixed}}^{(i)}$ 是定位移 $\\sigma_0 = R(x_0^{(i)})$ 的反迭代在测试用例 $i$ 上的迭代次数，而 $k_{\\mathrm{power}}^{(i)}$ 是幂迭代的迭代次数。输出必须是严格符合此格式的单行，除了列表表示结构上所需的字符外，不得包含任何其他字符或空白。", "solution": "问题陈述经评估有效。它在科学上基于数值线性代数的既定原则，特别是特征值问题的迭代方法。该问题是适定的，所有必要的参数、矩阵、初始条件和停止准则都有明确且无歧义的定义。语言客观而正式。因此，将提供一个解决方案。\n\n问题要求实现并比较三种迭代算法，以近似实对称矩阵 $A$ 的一个特征对 $(\\lambda, v)$，其中 $A v = \\lambda v$。一个特征对由一个特征值 $\\lambda$ 及其对应的特征向量 $v$ 组成。所考虑的方法是幂迭代、定位移反迭代和可变位移反迭代（也称为 Rayleigh 商迭代，RQI）。对于一个实对称矩阵 $A \\in \\mathbb{R}^{n \\times n}$，其所有特征值都是实数，并且存在一个由特征向量构成的标准正交基。对于非零向量 $x \\in \\mathbb{R}^n$，定义为 $R(x) = \\frac{x^\\mathsf{T} A x}{x^\\mathsf{T} x}$ 的 Rayleigh 商提供了对特征值的估计。如果 $x$ 是一个特征向量，那么 $R(x)$ 就是对应的精确特征值。对于所有算法，我们从一个初始向量 $x_0$ 开始，生成一个收敛到某个特征向量的向量序列 $\\{x_k\\}$，以及一个收敛到对应特征值的 Rayleigh 商序列 $\\{\\lambda_k = R(x_k)\\}$。\n\n1.  **幂迭代**\n\n    幂迭代法是找到矩阵主特征对（即特征值 $|\\lambda_1|$ 在所有特征值中模最大的特征对 $(\\lambda_1, v_1)$）的最简单算法。迭代步骤定义为：\n    $$\n    x_{k+1} = \\frac{A x_k}{\\lVert A x_k \\rVert_2}\n    $$\n    从一个在主特征向量 $v_1$ 方向上有非零分量的初始向量 $x_0$ 开始，序列 $x_k$ 会收敛到 $v_1$。收敛是线性的，收敛率由比值 $|\\lambda_2 / \\lambda_1|$ 决定，其中 $\\lambda_2$ 是模第二大的特征值。如果这个比值接近 $1$，收敛可能会非常慢。每一步的特征值由 Rayleigh 商 $\\lambda_k = R(x_k)$ 来近似。\n\n2.  **定位移反迭代**\n\n    反迭代是一种寻找与给定偏移量 $\\sigma$ 最接近的特征值所对应的特征对的方法。它将幂法应用于矩阵 $(A - \\sigma I)^{-1}$。$(A - \\sigma I)^{-1}$ 的特征值为 $(\\lambda_i - \\sigma)^{-1}$，其中 $\\lambda_i$ 是 $A$ 的特征值。$(A - \\sigma I)^{-1}$ 的主特征值对应于 $|\\lambda_i - \\sigma|$ 的最小值，这意味着 $\\lambda_i$ 是 $A$ 的最接近 $\\sigma$ 的特征值。迭代步骤为：\n    $$\n    x_{k+1} = \\frac{(A - \\sigma I)^{-1} x_k}{\\lVert (A - \\sigma I)^{-1} x_k \\rVert_2}\n    $$\n    在实践中，我们避免计算矩阵的逆。而是求解线性方程组 $(A - \\sigma I) y_k = x_k$ 得到 $y_k$，然后进行归一化：\n    $$\n    x_{k+1} = \\frac{y_k}{\\lVert y_k \\rVert_2}\n    $$\n    在本题中，整个过程都使用一个固定的位移 $\\sigma_0 = R(x_0)$。收敛是线性的，但收敛率由 $(A-\\sigma_0 I)^{-1}$ 的两个最大模特征值的比值决定。如果 $\\sigma_0$ 比其他任何特征值都更接近某个特征值 $\\lambda_j$，那么向特征向量 $v_j$ 的收敛会非常迅速。\n\n3.  **Rayleigh 商迭代 (RQI)**\n\n    Rayleigh 商迭代是反迭代的一种强大改进，其中位移在每一步都使用对特征值的最佳当前估计——Rayleigh 商进行更新。迭代过程定义如下：\n    1.  计算位移：$\\sigma_k = R(x_k) = \\frac{x_k^\\mathsf{T} A x_k}{x_k^\\mathsf{T} x_k}$。\n    2.  求解 $y_{k+1}$：$(A - \\sigma_k I) y_{k+1} = x_k$。\n    3.  归一化：$x_{k+1} = \\frac{y_{k+1}}{\\lVert y_{k+1} \\rVert_2}$。\n\n    对于对称矩阵，一旦迭代 $x_k$ 足够接近一个特征向量，RQI 就表现出三次方收敛。这意味着近似值的正确位数在每次迭代中大约增加三倍，从而导致极快的收敛速度。\n\n**停止准则**\n\n对于所有三种方法，当残差向量的范数 $\\lVert A x_k - \\lambda_k x_k \\rVert_2$ 小于指定的容差 $\\varepsilon$ 时，迭代终止，其中 $\\lambda_k = R(x_k)$。这个残差衡量了当前的近似对 $( \\lambda_k, x_k )$ 满足特征值方程的程度。首次满足此条件的迭代次数 $k$ 是所需的输出。如果在最大迭代次数内未滿足该条件，则记录最大迭代次数。\n\n实现将通过为每种算法定义一个函数来进行。每个函数将迭代生成向量序列，并在每一步检查停止准则，返回迭代次数。然后，这些函数将被应用于三个指定的测试用例。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef power_iteration(A, x0, tol, max_iter):\n    \"\"\"\n    Approximates a dominant eigenpair using Power Iteration.\n    \"\"\"\n    x = x0 / np.linalg.norm(x0)\n    for k in range(1, max_iter + 1):\n        # Calculate x_k\n        v = A @ x\n        x_k = v / np.linalg.norm(v)\n\n        # Check residual for x_k\n        # Since x_k is normalized, its L2 norm squared is 1.\n        lam_k = x_k.T @ A @ x_k\n        residual_norm = np.linalg.norm(A @ x_k - lam_k * x_k)\n\n        if residual_norm = tol:\n            return k\n\n        # Prepare for the next iteration\n        x = x_k\n\n    return max_iter\n\ndef inverse_iteration_fixed_shift(A, x0, tol, max_iter):\n    \"\"\"\n    Approximates an eigenpair using inverse iteration with a fixed shift.\n    The shift is the Rayleigh quotient of the initial vector.\n    \"\"\"\n    # Normalize initial vector for stability, although given vectors are normalized.\n    # The problem specifies sigma0 = R(x0), where x0 is the given initial vector.\n    # Since all given x0 are unit norm, x0.T @ x0 = 1.\n    sigma0 = x0.T @ A @ x0\n    \n    try:\n        M = A - sigma0 * np.eye(A.shape[0])\n    except np.linalg.LinAlgError:\n        return max_iter # Fails if shift is an exact eigenvalue\n\n    x = x0 / np.linalg.norm(x0) # Start iteration with normalized vector\n\n    for k in range(1, max_iter + 1):\n        try:\n            # Solve (A - sigma0*I) y = x_{k-1}\n            y = np.linalg.solve(M, x)\n        except np.linalg.LinAlgError:\n            # Shift is an eigenvalue or matrix is numerically singular\n            return max_iter\n\n        x_k = y / np.linalg.norm(y)\n\n        # Check residual for x_k\n        lam_k = x_k.T @ A @ x_k\n        residual_norm = np.linalg.norm(A @ x_k - lam_k * x_k)\n\n        if residual_norm = tol:\n            return k\n\n        x = x_k\n\n    return max_iter\n\ndef rayleigh_quotient_iteration(A, x0, tol, max_iter):\n    \"\"\"\n    Approximates an eigenpair using Rayleigh Quotient Iteration.\n    \"\"\"\n    x = x0 / np.linalg.norm(x0)\n    \n    for k in range(1, max_iter + 1):\n        # Update shift at each step using the Rayleigh quotient of x_{k-1}\n        sigma = x.T @ A @ x\n\n        try:\n            M = A - sigma * np.eye(A.shape[0])\n            # Solve (A - sigma_{k-1}*I) y = x_{k-1}\n            y = np.linalg.solve(M, x)\n        except np.linalg.LinAlgError:\n            # If the shift is an eigenvalue, the previous iterate was the eigenvector.\n            # Its residual should be zero or very small.\n            # The loop condition will have caught it in the previous iteration.\n            # This indicates a numerical breakdown or an exact hit.\n            return k-1 if k > 1 else max_iter\n\n        x_k = y / np.linalg.norm(y)\n\n        # Check residual for x_k\n        lam_k = x_k.T @ A @ x_k\n        residual_norm = np.linalg.norm(A @ x_k - lam_k * x_k)\n        \n        if residual_norm = tol:\n            return k\n\n        x = x_k\n\n    return max_iter\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    n = 5\n    tol = 1e-10\n    max_iter = 1000\n\n    # Test Case 1\n    A1 = np.array([\n        [6, 2, 0, 0, 0],\n        [2, 5, 2, 0, 0],\n        [0, 2, 4, 2, 0],\n        [0, 0, 2, 3, 2],\n        [0, 0, 0, 2, 2]\n    ], dtype=float)\n    x0_1 = np.ones(n) / np.sqrt(n)\n\n    # Test Case 2\n    D = np.diag([1.0, 1.0 + 1e-6, 2.0, 3.0, 4.0])\n    cos_theta = 4.0 / 5.0\n    sin_theta = 3.0 / 5.0\n    Q = np.eye(n)\n    Q[0, 0] = cos_theta\n    Q[0, 1] = -sin_theta\n    Q[1, 0] = sin_theta\n    Q[1, 1] = cos_theta\n    A2 = Q.T @ D @ Q\n    x0_2 = np.zeros(n)\n    x0_2[0] = 1.0\n\n    # Test Case 3\n    A3 = np.fromfunction(lambda i, j: 1 / (i + j + 1), (n, n), dtype=int)\n    x0_3 = np.array([1, -1, 1, -1, 1]) / np.sqrt(n)\n    \n    test_cases = [\n        (A1, x0_1),\n        (A2, x0_2),\n        (A3, x0_3)\n    ]\n\n    results = []\n    for A, x0 in test_cases:\n        k_rqi = rayleigh_quotient_iteration(A, x0, tol, max_iter)\n        k_fixed = inverse_iteration_fixed_shift(A, x0, tol, max_iter)\n        k_power = power_iteration(A, x0, tol, max_iter)\n        \n        results.extend([k_rqi, k_fixed, k_power])\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "2427128"}]}