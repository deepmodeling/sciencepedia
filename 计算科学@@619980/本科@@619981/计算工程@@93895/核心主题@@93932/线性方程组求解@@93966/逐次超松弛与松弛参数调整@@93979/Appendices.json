{"hands_on_practices": [{"introduction": "深入理解算法的理论基础至关重要。本练习将引导你从第一性原理出发，分析连续超松弛（SOR）方法的收敛性。你将亲身推导松弛参数 $ \\omega $ 如何直接影响迭代矩阵及其谱半径，并探索一个高斯-赛德尔方法（$ \\omega=1 $）发散，而精心选择的 $ \\omega < 1 $（欠松弛）却能收敛的案例。这是培养对 SOR 方法工作原理深刻理解的基础性实践。[@problem_id:2441046]", "problem": "考虑线性系统 $A x = b$，其中\n$$\nA \\;=\\; \\begin{pmatrix} 1 & 2 \\\\ -1 & 1 \\end{pmatrix}, \n\\qquad\nb \\;=\\; \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}.\n$$\n仅使用高斯-赛德尔（GS）方法和逐次超松弛（SOR）方法的定义来分析收敛性。\n\n任务：\n1. 从一般松弛参数 $\\omega \\in (0,1]$ 的分量形式 SOR 更新定义出发，为此系统推导 $2 \\times 2$ 线性误差传播映射 $T_{\\omega}$。然后将您的表达式特化为 $\\omega = 1$ 的情况，以恢复 GS 误差传播映射 $T_{1}$。\n2. 通过计算 $T_{1}$ 的谱半径来判断 GS 方法是否收敛，并为您的结论提供理由。\n3. 对于 $\\omega \\in (0,1)$，确定使 $T_{\\omega}$ 的谱半径最小化的值 $\\omega^{\\star}$，并说明相应的 SOR 迭代是否收敛。报告 $\\omega^{\\star}$ 的值，四舍五入到四位有效数字。\n\n您的最终答案必须是 $\\omega^{\\star}$ 四舍五入到四位有效数字的单一数值。无需单位。", "solution": "对所提供的问题进行验证。\n\n**第1步：提取已知条件**\n- 线性系统：$A x = b$\n- 矩阵 $A$：$A = \\begin{pmatrix} 1 & 2 \\\\ -1 & 1 \\end{pmatrix}$\n- 向量 $b$：$b = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$\n- 方法：逐次超松弛（SOR）和作为其特例的高斯-赛德尔（GS）。\n- 参数：松弛参数 $\\omega \\in (0, 1]$。优化针对 $\\omega \\in (0, 1)$。\n\n**第2步：使用提取的已知条件进行验证**\n- **科学性：** 该问题是数值线性代数中的一个标准练习，重点是 SOR 迭代法的收敛性分析。误差传播映射和谱半径的概念是基础性的，并且应用正确。\n- **适定性：** 问题陈述清晰，包含三个不同的任务。寻找最小化谱半径的最优松弛参数的目标是一个定义明确的数学优化问题。\n- **客观性：** 问题以精确的数学语言表述，没有歧义或主观内容。\n- **完整性和一致性：** 分析迭代法收敛性所需的所有必要信息（矩阵 $A$）均已提供。向量 $b$ 对于收敛性分析不是必需的（收敛性仅取决于迭代矩阵），但它的存在并未引入任何矛盾。该问题是自洽的。\n\n**第3步：结论与操作**\n该问题有效。将提供完整解答。\n\n分析始于 SOR 迭代的定义。对于线性系统 $A x = b$，矩阵 $A$ 分解为 $A = D - L - U$，其中 $D$ 是 $A$ 的对角部分，$-L$ 是 $A$ 的严格下三角部分，$-U$ 是 $A$ 的严格上三角部分。SOR 迭代由以下更新规则定义：\n$$x^{(k+1)} = (D - \\omega L)^{-1} \\left( ((1-\\omega)D + \\omega U) x^{(k)} + \\omega b \\right)$$\n该方法的收敛性由 SOR 迭代矩阵 $T_{\\omega}$ 的谱半径决定，其定义为：\n$$T_{\\omega} = (D - \\omega L)^{-1} ((1-\\omega)D + \\omega U)$$\n误差向量 $e^{(k)} = x^{(k)} - x^*$（其中 $x^*$ 是精确解）根据 $e^{(k+1)} = T_{\\omega} e^{(k)}$ 进行传播。\n\n**1. 误差传播映射 $T_{\\omega}$ 的推导**\n\n对于给定的矩阵 $A = \\begin{pmatrix} 1 & 2 \\\\ -1 & 1 \\end{pmatrix}$，其分解为：\n$$D = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}, \\quad L = \\begin{pmatrix} 0 & 0 \\\\ -(-1) & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix}, \\quad U = \\begin{pmatrix} 0 & -2 \\\\ 0 & 0 \\end{pmatrix}$$\n首先，我们计算矩阵 $(D - \\omega L)$：\n$$D - \\omega L = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} - \\omega \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ -\\omega & 1 \\end{pmatrix}$$\n其逆矩阵为：\n$$(D - \\omega L)^{-1} = \\frac{1}{(1)(1) - (0)(-\\omega)} \\begin{pmatrix} 1 & 0 \\\\ \\omega & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ \\omega & 1 \\end{pmatrix}$$\n接下来，我们计算矩阵 $((1-\\omega)D + \\omega U)$：\n$$(1-\\omega)D + \\omega U = (1-\\omega) \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} + \\omega \\begin{pmatrix} 0 & -2 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 1-\\omega & -2\\omega \\\\ 0 & 1-\\omega \\end{pmatrix}$$\n现在，我们将这两个矩阵相乘以求得 $T_{\\omega}$：\n$$T_{\\omega} = (D - \\omega L)^{-1} ((1-\\omega)D + \\omega U) = \\begin{pmatrix} 1 & 0 \\\\ \\omega & 1 \\end{pmatrix} \\begin{pmatrix} 1-\\omega & -2\\omega \\\\ 0 & 1-\\omega \\end{pmatrix}$$\n$$T_{\\omega} = \\begin{pmatrix} (1)(1-\\omega) + (0)(0) & (1)(-2\\omega) + (0)(1-\\omega) \\\\ (\\omega)(1-\\omega) + (1)(0) & (\\omega)(-2\\omega) + (1)(1-\\omega) \\end{pmatrix} = \\begin{pmatrix} 1-\\omega & -2\\omega \\\\ \\omega(1-\\omega) & 1-\\omega - 2\\omega^2 \\end{pmatrix}$$\n高斯-赛德尔（GS）方法是 SOR 在 $\\omega = 1$ 时的特例。将 $\\omega=1$ 代入 $T_{\\omega}$ 的表达式，可得到 GS 误差传播映射 $T_1$：\n$$T_{1} = \\begin{pmatrix} 1-1 & -2(1) \\\\ 1(1-1) & 1-1 - 2(1)^2 \\end{pmatrix} = \\begin{pmatrix} 0 & -2 \\\\ 0 & -2 \\end{pmatrix}$$\n\n**2. 高斯-赛德尔方法的收敛性分析**\n\n当且仅当迭代矩阵的谱半径 $\\rho$ 严格小于1时，迭代法的收敛性才能得到保证。我们通过求解特征方程 $\\det(T_1 - \\lambda I) = 0$ 来计算 $T_1$ 的特征值。\n$$\\det \\begin{pmatrix} 0 - \\lambda & -2 \\\\ 0 & -2 - \\lambda \\end{pmatrix} = (-\\lambda)(-2-\\lambda) - (0)(-2) = \\lambda(2+\\lambda) = 0$$\n特征值为 $\\lambda_1 = 0$ 和 $\\lambda_2 = -2$。\n$T_1$ 的谱半径是其特征值绝对值的最大值：\n$$\\rho(T_1) = \\max(|\\lambda_1|, |\\lambda_2|) = \\max(|0|, |-2|) = 2$$\n由于 $\\rho(T_1) = 2 > 1$，因此高斯-赛德尔方法对于此系统不收敛。\n\n**3. 最优松弛参数 $\\omega^{\\star}$**\n\n为了在范围 $\\omega \\in (0, 1)$ 内找到最优松弛参数 $\\omega^{\\star}$，我们必须找到使谱半径 $\\rho(T_{\\omega})$ 最小化的 $\\omega$ 值。我们首先从其特征方程 $\\det(T_{\\omega} - \\lambda I) = 0$ 中找出 $T_{\\omega}$ 的特征值：\n$$\\det \\begin{pmatrix} 1-\\omega - \\lambda & -2\\omega \\\\ \\omega(1-\\omega) & 1-\\omega - 2\\omega^2 - \\lambda \\end{pmatrix} = 0$$\n$$(1-\\omega - \\lambda)(1-\\omega - 2\\omega^2 - \\lambda) + 2\\omega^2(1-\\omega) = 0$$\n$$\\lambda^2 - (1-\\omega - 2\\omega^2 + 1-\\omega)\\lambda + (1-\\omega)(1-\\omega - 2\\omega^2) + 2\\omega^2(1-\\omega) = 0$$\n$$\\lambda^2 - (2 - 2\\omega - 2\\omega^2)\\lambda + (1-\\omega)(1-\\omega - 2\\omega^2 + 2\\omega^2) = 0$$\n$$\\lambda^2 - 2(1 - \\omega - \\omega^2)\\lambda + (1-\\omega)^2 = 0$$\n使用二次公式，特征值为：\n$$\\lambda = \\frac{2(1 - \\omega - \\omega^2) \\pm \\sqrt{4(1 - \\omega - \\omega^2)^2 - 4(1-\\omega)^2}}{2} = (1 - \\omega - \\omega^2) \\pm \\sqrt{(1 - \\omega - \\omega^2)^2 - (1-\\omega)^2}$$\n特征值的性质取决于判别式 $\\Delta_p = (1 - \\omega - \\omega^2)^2 - (1-\\omega)^2$ 的符号。\n$$\\Delta_p = [(1 - \\omega - \\omega^2) - (1-\\omega)][(1 - \\omega - \\omega^2) + (1-\\omega)] = (-\\omega^2)(2 - 2\\omega - \\omega^2)$$\n对于 $\\omega \\in (0, 1)$，$-\\omega^2$ 为负。 $\\Delta_p$ 的符号与 $f(\\omega) = 2 - 2\\omega - \\omega^2$ 的符号相反。$f(\\omega) = 0$ 的根是 $\\omega = -1 \\pm \\sqrt{3}$。由于我们在区间 $\\omega \\in (0, 1)$ 内，临界点是 $\\omega = \\sqrt{3} - 1 \\approx 0.732$。\n\n情况1：$0 < \\omega \\le \\sqrt{3}-1$。\n在此区间内，$f(\\omega) \\ge 0$，因此 $\\Delta_p \\le 0$。特征值为一对共轭复数（或在边界处为相等实数）。\n$$\\lambda = (1 - \\omega - \\omega^2) \\pm i\\omega \\sqrt{2 - 2\\omega - \\omega^2}$$\n谱半径是这些特征值的模。对于复数 $z=a+ib$, $|z|^2=a^2+b^2$。共轭复根的乘积为 $\\lambda \\bar{\\lambda} = (1-\\omega)^2$，这是特征多项式中的常数项。\n$$\\rho(T_{\\omega})^2 = |\\lambda|^2 = (1-\\omega)^2$$\n由于 $\\omega \\in (0, 1)$，$1-\\omega > 0$，因此 $\\rho(T_{\\omega}) = 1-\\omega$。这是一个关于 $\\omega$ 的线性递减函数。\n\n情况2：$\\sqrt{3}-1 < \\omega < 1$。\n在此区间内，$f(\\omega) < 0$，因此 $\\Delta_p > 0$。特征值为两个不相等的实数。\n$$\\lambda_{1,2} = (1 - \\omega - \\omega^2) \\pm \\omega\\sqrt{\\omega^2 + 2\\omega - 2}$$\n根的乘积 $\\lambda_1\\lambda_2 = (1-\\omega)^2 > 0$，所以它们符号相同。它们的和是 $\\lambda_1+\\lambda_2 = 2(1-\\omega-\\omega^2)$。$1-\\omega-\\omega^2=0$ 的根是 $\\omega = \\frac{\\sqrt{5}-1}{2} \\approx 0.618$ 和一个负根。由于 $\\sqrt{3}-1 > \\frac{\\sqrt{5}-1}{2}$，对于此情况下的任何 $\\omega$，都有 $1-\\omega-\\omega^2 < 0$。因此，两个特征值都为负。\n谱半径是它们绝对值的最大值，也就是更负的那个根（$\\lambda_2$）的绝对值。\n$$\\rho(T_{\\omega}) = |\\lambda_2| = |(1 - \\omega - \\omega^2) - \\omega\\sqrt{\\omega^2 + 2\\omega - 2}| = -(1 - \\omega - \\omega^2) + \\omega\\sqrt{\\omega^2 + 2\\omega - 2}$$\n$$\\rho(T_{\\omega}) = \\omega^2 + \\omega - 1 + \\omega\\sqrt{\\omega^2 + 2\\omega - 2}$$\n为了找到该函数的最小值，我们考察它关于 $\\omega$ 的导数：\n$$\\frac{d\\rho}{d\\omega} = 2\\omega + 1 + \\sqrt{\\omega^2 + 2\\omega - 2} + \\frac{\\omega(2\\omega+2)}{2\\sqrt{\\omega^2+2\\omega-2}} = 2\\omega + 1 + \\frac{(\\omega^2+2\\omega-2) + (\\omega^2+\\omega)}{\\sqrt{\\omega^2+2\\omega-2}}$$\n$$\\frac{d\\rho}{d\\omega} = 2\\omega + 1 + \\frac{2\\omega^2+3\\omega-2}{\\sqrt{\\omega^2+2\\omega-2}}$$\n对于 $\\omega \\in (\\sqrt{3}-1, 1)$，所有项均为正：\n- $2\\omega+1 > 0$。\n- $\\sqrt{\\omega^2+2\\omega-2} > 0$。\n- 分子 $2\\omega^2+3\\omega-2$ 的根在 $\\omega=1/2$ 和 $\\omega=-2$。当 $\\omega > 1/2$ 时，它为正。由于 $\\sqrt{3}-1 \\approx 0.732 > 1/2$，该项为正。\n因此，对于 $\\omega \\in (\\sqrt{3}-1, 1)$，$\\frac{d\\rho}{d\\omega} > 0$，这意味着 $\\rho(T_{\\omega})$ 在此区间内是增函数。\n\n结合这两种情况，$\\rho(T_{\\omega})$ 在 $\\omega \\in (0, \\sqrt{3}-1]$ 上线性递减，在 $\\omega \\in (\\sqrt{3}-1, 1)$ 上递增。谱半径的最小值必定出现在连接这两个区域的点，即 $\\omega^{\\star} = \\sqrt{3}-1$。\n\n在此最优值处，谱半径为 $\\rho(T_{\\omega^\\star}) = 1 - \\omega^{\\star} = 1 - (\\sqrt{3}-1) = 2 - \\sqrt{3}$。由于 $1 < \\sqrt{3} < 2$，我们有 $0 < 2-\\sqrt{3} < 1$。具体来说，$2-\\sqrt{3} \\approx 0.268$，小于 $1$。因此，使用 $\\omega = \\omega^{\\star}$ 的 SOR 迭代是收敛的。\n\n问题要求 $\\omega^{\\star}$ 的数值四舍五入到四位有效数字。\n$\\omega^{\\star} = \\sqrt{3}-1 \\approx 1.7320508... - 1 = 0.7320508...$\n四舍五入到四位有效数字得到 $0.7321$。", "answer": "$$\\boxed{0.7321}$$", "id": "2441046"}, {"introduction": "在掌握了理论分析之后，我们将探讨一个更深刻的问题：理论与实践之间的差距。虽然理论上存在一个“最优”的 $ \\omega $，但本问题将通过一个关键的思想实验，揭示精确算术与真实世界计算之间的鸿沟。我们将构建一个场景，在该场景中，由于浮点表示的限制，理论上的最优 $ \\omega $ 的性能反而劣于简单的高斯-赛德尔方法。这个练习旨在强调一个核心教训：计算科学家必须警惕机器精度如何影响算法的实际行为。[@problem_id:2441049]", "problem": "你的任务是构建并分析一个线性系统，在该系统中，逐次超松弛（SOR）方法的理论最优松弛参数在实际的浮点计算中的表现比未松弛的高斯-赛德尔（Gauss–Seidel）方法更差。考虑对称正定矩阵族\n$$\nA_M \\;=\\; \\begin{pmatrix}\nM & -(M-1) \\\\\n-(M-1) & M\n\\end{pmatrix},\n$$\n右端项为\n$$\nb \\;=\\; \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix},\n$$\n初始猜测值为\n$$\nx^{(0)} \\;=\\; \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}.\n$$\n假设如下。\n\n- 在精确实数算术中，分析与 $A_M$ 相关的雅可比（Jacobi）迭代矩阵的谱性质。仅使用雅可比和 SOR 迭代及其谱半径的核心定义，从第一性原理出发推导理论最优松弛参数 $\\,\\omega_{\\mathrm{opt}}(M)\\,$，该参数能最小化 SOR 谱半径，并需以 $M$ 的闭式解函数形式表示。\n\n- 然后，考虑在电气与电子工程师协会（IEEE）浮点算术标准（IEEE 754）双精度格式下，采用四舍五入到最近值的实际计算。假定在任何迭代开始之前，矩阵元素首先以此格式存储。利用 $M$ 附近的浮点数标准间距，论证所存储的矩阵实际上是\n$$\n\\widetilde{A}_M \\;=\\; \\begin{pmatrix} M & -M \\\\ -M & M \\end{pmatrix}.\n$$\n将精确的 SOR 更新方程应用于存储的矩阵 $\\widetilde{A}_M$ 以及给定的 $b$ 和 $x^{(0)}$，计算并比较对于 $\\,\\omega = 1\\,$ 和在精确算术分析中得到的 $\\,\\omega = \\omega_{\\mathrm{opt}}(M)\\,$ 的第一步残差 $\\,r^{(1)}(\\omega) \\,=\\, b - \\widetilde{A}_M x^{(1)}(\\omega)\\,$。解释为什么仅仅由于 $A_M$ 的浮点表示，理论最优的 $\\,\\omega_{\\mathrm{opt}}(M)\\,$ 在处理存储问题时比 $\\,\\omega=1\\,$ 表现更差。\n\n你的最终答案必须是 $\\,\\omega_{\\mathrm{opt}}(M)\\,$ 作为 $M$ 的函数的闭式表达式，无需进行数值计算。将最终答案表示为无单位的单一解析表达式。最终答案中不要包含任何额外评论。", "solution": "所述问题具有科学依据，提法恰当且客观。不存在矛盾或信息缺失。我们可以开始求解。分析分为两部分：首先是在精确算术下的推导，其次是在实际浮点计算下的分析。\n\n第一部分：精确算术分析与 $\\omega_{\\mathrm{opt}}(M)$ 的推导\n\n给定线性系统 $A_M x = b$，其中矩阵为\n$$\nA_M = \\begin{pmatrix}\nM & -(M-1) \\\\\n-(M-1) & M\n\\end{pmatrix}\n$$\n逐次超松弛（SOR）法是求解此类系统的一种迭代方法。SOR 的收敛速度取决于其迭代矩阵的谱半径，而该谱半径又与雅可比（Jacobi）迭代矩阵的谱半径相关。我们首先推导雅可比矩阵 $T_J$。\n\n$A_M$ 矩阵分解为 $A_M = D_M - L_M - U_M$，其中 $D_M$ 是 $A_M$ 的对角部分，$-L_M$ 是其严格下三角部分，$-U_M$ 是其严格上三角部分。\n$$\nD_M = \\begin{pmatrix} M & 0 \\\\ 0 & M \\end{pmatrix}, \\quad L_M = \\begin{pmatrix} 0 & 0 \\\\ M-1 & 0 \\end{pmatrix}, \\quad U_M = \\begin{pmatrix} 0 & M-1 \\\\ 0 & 0 \\end{pmatrix}\n$$\n雅可比迭代矩阵定义为 $T_J = D_M^{-1}(L_M + U_M)$。\n$$\nD_M^{-1} = \\begin{pmatrix} \\frac{1}{M} & 0 \\\\ 0 & \\frac{1}{M} \\end{pmatrix}\n$$\n$$\nL_M + U_M = \\begin{pmatrix} 0 & M-1 \\\\ M-1 & 0 \\end{pmatrix}\n$$\n因此，\n$$\nT_J = \\begin{pmatrix} \\frac{1}{M} & 0 \\\\ 0 & \\frac{1}{M} \\end{pmatrix} \\begin{pmatrix} 0 & M-1 \\\\ M-1 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & \\frac{M-1}{M} \\\\ \\frac{M-1}{M} & 0 \\end{pmatrix}\n$$\n为了找到最优松弛参数 $\\omega_{\\mathrm{opt}}$，我们必须首先求出 $T_J$ 的谱半径，记为 $\\mu = \\rho(T_J)$。谱半径是 $T_J$ 特征值绝对值的最大值。$T_J$ 的特征值 $\\lambda_J$ 是特征方程 $\\det(T_J - \\lambda_J I) = 0$ 的根。\n$$\n\\det\\begin{pmatrix} -\\lambda_J & \\frac{M-1}{M} \\\\ \\frac{M-1}{M} & -\\lambda_J \\end{pmatrix} = (-\\lambda_J)^2 - \\left(\\frac{M-1}{M}\\right)^2 = 0\n$$\n这得到 $\\lambda_J^2 = \\left(\\frac{M-1}{M}\\right)^2$，因此特征值为 $\\lambda_J = \\pm \\frac{M-1}{M}$。\n假设 $M>1$，谱半径为\n$$\n\\mu = \\rho(T_J) = \\max\\left|\\pm \\frac{M-1}{M}\\right| = \\frac{M-1}{M}\n$$\n$A_M$ 矩阵是对称的，并具有“性质 A”（Property A）结构（更具体地说，它是相容排序的），这是应用标准的最优 SOR 松弛理论的必要条件。能够最小化 SOR 迭代矩阵谱半径的理论最优松弛参数 $\\omega_{\\mathrm{opt}}$ 由以下公式给出：\n$$\n\\omega_{\\mathrm{opt}} = \\frac{2}{1 + \\sqrt{1 - \\mu^2}}\n$$\n我们将 $\\mu$ 的表达式代入：\n$$\n1 - \\mu^2 = 1 - \\left(\\frac{M-1}{M}\\right)^2 = \\frac{M^2 - (M^2 - 2M + 1)}{M^2} = \\frac{2M - 1}{M^2}\n$$\n取平方根，我们得到：\n$$\n\\sqrt{1 - \\mu^2} = \\sqrt{\\frac{2M-1}{M^2}} = \\frac{\\sqrt{2M-1}}{M}\n$$\n（我们假设 $M > \\frac{1}{2}$ 以使该项为实数，这与大 $M$ 的前提相符）。\n将此结果代回 $\\omega_{\\mathrm{opt}}$ 的公式中：\n$$\n\\omega_{\\mathrm{opt}}(M) = \\frac{2}{1 + \\frac{\\sqrt{2M-1}}{M}} = \\frac{2M}{M + \\sqrt{2M-1}}\n$$\n这就是基于精确算术的理论最优松弛参数的闭式表达式。\n\n第二部分：浮点算术分析\n\n问题假定对于一个非常大的 $M$ 值，由于 IEEE 754 双精度浮点表示的限制，数值 $-(M-1)$ 与 $-M$ 无法区分，并因此存储为后者。这使得矩阵 $A_M$ 在计算机内存中转变为一个不同的矩阵 $\\widetilde{A}_M$：\n$$\nA_M = \\begin{pmatrix} M & -(M-1) \\\\ -(M-1) & M \\end{pmatrix} \\quad \\xrightarrow{\\text{storage}} \\quad \\widetilde{A}_M = \\begin{pmatrix} M & -M \\\\ -M & M \\end{pmatrix}\n$$\n因此，计算任务是从 $x^{(0)} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$ 开始求解系统 $\\widetilde{A}_M x = b$。注意 $\\det(\\widetilde{A}_M) = M^2 - (-M)(-M) = 0$，因此存储的矩阵是奇异的。该系统是相容的，因为 $b = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$ 位于 $\\widetilde{A}_M$ 的列空间中，该列空间由向量 $\\begin{pmatrix} M \\\\ -M \\end{pmatrix}$ 生成。\n\n现在我们对这个存储的系统应用一步 SOR 迭代。分量形式的 SOR 更新公式为：\n$$\nx_i^{(k+1)} = (1-\\omega)x_i^{(k)} + \\frac{\\omega}{a_{ii}} \\left( b_i - \\sum_{j<i} a_{ij}x_j^{(k+1)} - \\sum_{j>i} a_{ij}x_j^{(k)} \\right)\n$$\n使用 $\\widetilde{A}_M$、$b = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$ 和 $x^{(0)} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$，我们计算 $x^{(1)}(\\omega) = \\begin{pmatrix} x_1^{(1)} \\\\ x_2^{(1)} \\end{pmatrix}$。\n\n对于 $i=1$：\n$$\nx_1^{(1)} = (1-\\omega)x_1^{(0)} + \\frac{\\omega}{\\widetilde{a}_{11}} \\left( b_1 - \\widetilde{a}_{12}x_2^{(0)} \\right) = (1-\\omega)(0) + \\frac{\\omega}{M} \\left( 1 - (-M)(0) \\right) = \\frac{\\omega}{M}\n$$\n对于 $i=2$：\n$$\nx_2^{(1)} = (1-\\omega)x_2^{(0)} + \\frac{\\omega}{\\widetilde{a}_{22}} \\left( b_2 - \\widetilde{a}_{21}x_1^{(1)} \\right) = (1-\\omega)(0) + \\frac{\\omega}{M} \\left( -1 - (-M)x_1^{(1)} \\right)\n$$\n代入 $x_1^{(1)}$ 的值：\n$$\nx_2^{(1)} = \\frac{\\omega}{M} \\left( -1 + M\\left(\\frac{\\omega}{M}\\right) \\right) = \\frac{\\omega}{M}(-1 + \\omega) = \\frac{\\omega(\\omega-1)}{M}\n$$\n所以，第一次迭代的结果是 $x^{(1)}(\\omega) = \\frac{1}{M}\\begin{pmatrix} \\omega \\\\ \\omega(\\omega-1) \\end{pmatrix}$。\n\n接下来，我们计算第一步后的残差 $r^{(1)}(\\omega) = b - \\widetilde{A}_M x^{(1)}(\\omega)$。\n$$\n\\widetilde{A}_M x^{(1)}(\\omega) = \\begin{pmatrix} M & -M \\\\ -M & M \\end{pmatrix} \\frac{1}{M} \\begin{pmatrix} \\omega \\\\ \\omega(\\omega-1) \\end{pmatrix} = \\begin{pmatrix} 1 & -1 \\\\ -1 & 1 \\end{pmatrix} \\begin{pmatrix} \\omega \\\\ \\omega(\\omega-1) \\end{pmatrix}\n$$\n$$\n= \\begin{pmatrix} \\omega - \\omega(\\omega-1) \\\\ -\\omega + \\omega(\\omega-1) \\end{pmatrix} = \\begin{pmatrix} \\omega - \\omega^2 + \\omega \\\\ -\\omega + \\omega^2 - \\omega \\end{pmatrix} = \\begin{pmatrix} 2\\omega - \\omega^2 \\\\ \\omega^2 - 2\\omega \\end{pmatrix}\n$$\n残差为：\n$$\nr^{(1)}(\\omega) = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} - \\begin{pmatrix} 2\\omega - \\omega^2 \\\\ \\omega^2 - 2\\omega \\end{pmatrix} = \\begin{pmatrix} 1 - 2\\omega + \\omega^2 \\\\ -1 - (\\omega^2 - 2\\omega) \\end{pmatrix} = \\begin{pmatrix} (1-\\omega)^2 \\\\ -(1-\\omega)^2 \\end{pmatrix} = (1-\\omega)^2 \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}\n$$\n现在我们比较 $\\omega=1$（高斯-赛德尔法）和 $\\omega=\\omega_{\\mathrm{opt}}(M)$ 时的性能。\n\n情况 $\\omega=1$（高斯-赛德尔法）：\n残差为 $r^{(1)}(1) = (1-1)^2 \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$。高斯-赛德尔法在单次迭代中收敛到存储系统 $\\widetilde{A}_M x = b$ 的一个精确解，得到零残差。\n\n情况 $\\omega=\\omega_{\\mathrm{opt}}(M)$：\n残差为 $r^{(1)}(\\omega_{\\mathrm{opt}}) = (1-\\omega_{\\mathrm{opt}})^2 \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$。\n根据第一部分，$\\omega_{\\mathrm{opt}}(M) = \\frac{2M}{M + \\sqrt{2M-1}}$。对于 $M>1$，$M > \\sqrt{2M-1}$，这意味着 $2M > M + \\sqrt{2M-1}$ 且 $\\omega_{\\mathrm{opt}}(M) > 1$。具体来说，对于 $M>1/2$，$ \\omega_{\\mathrm{opt}}(M)$ 永远不等于 1。因此，$(1-\\omega_{\\mathrm{opt}})^2 \\neq 0$。残差非零。对于大的 $M$，$\\omega_{\\mathrm{opt}}(M) \\to 2$，所以 $(1-\\omega_{\\mathrm{opt}})^2 \\to 1$，这意味着残差范数与初始残差范数相比几乎没有变化。\n\n结论：\n参数 $\\omega_{\\mathrm{opt}}(M)$ 是为矩阵 $A_M$ 计算出的最优值。然而，计算是使用矩阵 $\\widetilde{A}_M$ 进行的。对于这个*实际的*计算问题，选择 $\\omega=1$ 会在一步之后得到零残差，表明收敛到了存储系统的一个精确解。选择 $\\omega = \\omega_{\\mathrm{opt}}(M)$ 会导致非零残差。因此，理论上的最优参数表现明显差于未松弛的高斯-赛德尔法。这种差异的产生，是由于理论优化是基于模型（$A_M$）进行的，而该模型因浮点算术的有限精度与计算的实际情况（$\\widetilde{A}_M$）不符。", "answer": "$$\n\\boxed{\\frac{2M}{M + \\sqrt{2M-1}}}\n$$", "id": "2441049"}, {"introduction": "前两个练习揭示了确定松弛参数的挑战：理论上的 $ \\omega_{\\text{opt}} $ 可能难以计算，而且在真实计算机上也未必真正最优。因此，本实践将介绍一种实用而强大的替代方案：自适应 SOR 方法。你将实现一个求解器，它能根据观测到的收敛速率动态调整 $ \\omega $，这是一种在实际工程软件中常用的技术。通过这个动手编程练习，你将学会如何构建一个更鲁棒、更具实用性的迭代求解器。[@problem_id:2441060]", "problem": "实现一个程序，该程序使用自适应逐次超松弛（SOR）方法求解线性系统，其中松弛参数根据一个数学上定义的收敛速度度量，每隔固定次数的迭代进行更新。考虑形式为 $A x = b$ 的线性系统，其中 $A \\in \\mathbb{R}^{n \\times n}$ 且 $b \\in \\mathbb{R}^{n}$。程序必须实现以下几个部分。\n\n1) 迭代格式。设 $A = D + L + U$ 是矩阵 $A$ 分解为其对角部分 $D$、严格下三角部分 $L$ 和严格上三角部分 $U$。对于给定的松弛参数 $\\omega \\in (0,2)$ 和迭代解 $x^{(k)}$，下一个迭代解 $x^{(k+1)}$ 按分量定义为（对于 $i = 1,\\dots,n$）：\n$x^{(k+1)}_i = (1 - \\omega)\\,x^{(k)}_i + \\frac{\\omega}{a_{ii}}\\left(b_i - \\sum_{j=1}^{i-1} a_{ij}\\,x^{(k+1)}_j - \\sum_{j=i+1}^{n} a_{ij}\\,x^{(k)}_j\\right)$.\n等价地，写成矩阵形式为：\n$$(D + \\omega L) x^{(k+1)} = \\omega b + \\left[(1-\\omega) D - \\omega U\\right] x^{(k)}.$$\n\n2) 残差与收敛性度量。定义第 $k$ 次迭代的残差为 $r^{(k)} = b - A x^{(k)}$，其欧几里得范数（二范数）为 $\\|r^{(k)}\\|_2$。对于一个固定的正整数 $N_{\\text{upd}}$，定义在第 $k$ 次迭代时的窗口收敛因子（仅当 $k$ 是 $N_{\\text{upd}}$ 的正整数倍时）为\n$$q^{(k)} = \\left(\\frac{\\|r^{(k)}\\|_2}{\\|r^{(k - N_{\\text{upd}})}\\|_2}\\right)^{1/N_{\\text{upd}}}.$$\n按照约定，如果 $\\|r^{(k - N_{\\text{upd}})}\\|_2 = 0$，则迭代已经收敛，程序在尝试任何更新之前终止。\n\n3) 自适应更新规则。设 $\\alpha \\in (0,1)$ 是一个增益， $q_{\\text{tgt}} \\in (0,1)$ 是一个目标收敛因子，并设 $\\omega_{\\min}$ 和 $\\omega_{\\max}$ 满足 $0 < \\omega_{\\min} < \\omega_{\\max} < 2$。在 $k$ 是 $N_{\\text{upd}}$ 的正整数倍且 $q^{(k)}$ 有良好定义的迭代中，按如下方式更新松弛参数：\n$$\\omega \\leftarrow \\operatorname{clip}\\!\\left(\\omega \\cdot \\left[1 + \\alpha \\left(q_{\\text{tgt}} - q^{(k)}\\right)\\right],\\; \\omega_{\\min},\\; \\omega_{\\max}\\right),$$\n其中 $\\operatorname{clip}(z, a, b) = \\min\\{\\max\\{z,a\\}, b\\}$。通过将首次更新的参考残差范数设置为 $\\|r^{(0)}\\|_2$ 来初始化更新内存。\n\n4) 初始化与停止条件。设 $x^{(0)}$ 为初始猜测值，$\\omega^{(0)}$ 为初始松弛参数。当满足 $\\|r^{(k)}\\|_2 / \\|r^{(0)}\\|_2 \\le \\varepsilon$ 的最小 $k \\ge 0$ 出现时停止，其中 $\\varepsilon \\in (0,1)$ 是预设的相对容差；或者当达到预设的最大迭代次数 $k_{\\max}$ 时停止。如果 $\\|r^{(0)}\\|_2 = 0$，则定义迭代次数为 $k=0$，程序使用当前的 $\\omega$ 立即终止。\n\n5) 要求输出。对于每个测试用例，您的程序必须输出一个列表 $[k_{\\text{stop}}, \\omega_{\\text{final}}, \\rho_{\\text{rel}}]$，其中 $k_{\\text{stop}}$ 是终止时的整数迭代次数，$\\omega_{\\text{final}}$ 是最终的松弛参数值，$\\rho_{\\text{rel}} = \\|r^{(k_{\\text{stop}})}\\|_2/\\|r^{(0)}\\|_2$ 是最终的相对残差范数。报告的 $\\omega_{\\text{final}}$ 和 $\\rho_{\\text{rel}}$ 值需四舍五入到小数点后六位。\n\n测试套件。在以下四个测试用例上实现并运行您的求解器。所有矩阵通过构造都是对称正定的，并且所有随机量必须使用指定的种子生成以确保可复现性。\n\n- 案例 A（一维泊松问题，中等规模）。设 $n = 50$。定义 $A \\in \\mathbb{R}^{n \\times n}$，其中 $a_{ii} = 2$（对于 $i=1,\\dots,n$），$a_{i,i+1} = a_{i+1,i} = -1$（对于 $i=1,\\dots,n-1$），所有其他元素为 0。设 $b \\in \\mathbb{R}^{n}$ 是全为 1 的向量。设 $x^{(0)}$ 是零向量。使用 $\\omega^{(0)} = 1.0$, $N_{\\text{upd}} = 10$, $\\alpha = 0.3$, $q_{\\text{tgt}} = 0.5$, $\\omega_{\\min} = 0.8$, $\\omega_{\\max} = 1.95$, $\\varepsilon = 1.0 \\times 10^{-8}$, 以及 $k_{\\max} = 20000$。\n\n- 案例 B（稠密随机对称正定矩阵）。设 $n = 40$。使用种子为 $7$ 的伪随机数生成器，抽取一个具有独立标准正态分布元素的矩阵 $R \\in \\mathbb{R}^{n \\times n}$，并定义 $A = R^{\\top} R + \\gamma I$，其中 $\\gamma = 1.0$。使用种子为 $11$ 的伪随机数生成器，抽取一个具有独立标准正态分布元素的向量 $b \\in \\mathbb{R}^{n}$。设 $x^{(0)}$ 是零向量。使用 $\\omega^{(0)} = 1.0$, $N_{\\text{upd}} = 5$, $\\alpha = 0.2$, $q_{\\text{tgt}} = 0.6$, $\\omega_{\\min} = 0.6$, $\\omega_{\\max} = 1.95$, $\\varepsilon = 1.0 \\times 10^{-8}$, 以及 $k_{\\max} = 20000$。\n\n- 案例 C（立即收敛的边界情况）。设 $n = 10$。使用种子为 $3$ 的伪随机数生成器，抽取一个具有独立标准正态分布元素的矩阵 $R \\in \\mathbb{R}^{n \\times n}$，并定义 $A = R^{\\top} R + \\gamma I$，其中 $\\gamma = 1.0$。使用种子为 $5$ 的伪随机数生成器，抽取 $x^{\\star} \\in \\mathbb{R}^{n}$，并设 $b = A x^{\\star}$。初始化 $x^{(0)} = x^{\\star}$。使用 $\\omega^{(0)} = 1.5$, $N_{\\text{upd}} = 3$, $\\alpha = 0.5$, $q_{\\text{tgt}} = 0.5$, $\\omega_{\\min} = 0.5$, $\\omega_{\\max} = 1.95$, $\\varepsilon = 1.0 \\times 10^{-8}$,以及 $k_{\\max} = 20000$。\n\n- 案例 D（一维泊松问题，靠近上界的频繁更新）。设 $n = 20$。像案例 A 那样定义大小为 $n$ 的矩阵 $A$。设 $b$ 是全为 1 的向量。设 $x^{(0)}$ 是零向量。使用 $\\omega^{(0)} = 1.9$, $N_{\\text{upd}} = 1$, $\\alpha = 0.4$, $q_{\\text{tgt}} = 0.4$, $\\omega_{\\min} = 1.0$, $\\omega_{\\max} = 1.95$, $\\varepsilon = 1.0 \\times 10^{-8}$, 以及 $k_{\\max} = 20000$。\n\n最终输出格式。您的程序应生成单行输出，其中包含四个案例的结果，格式为以逗号分隔的列表的列表，顺序为 A、B、C、D。对于每个案例，输出列表 $[k_{\\text{stop}}, \\omega_{\\text{final}}, \\rho_{\\text{rel}}]$，其中 $\\omega_{\\text{final}}$ 和 $\\rho_{\\text{rel}}$ 四舍五入到小数点后六位。例如，一个有效的整体输出格式为\n\"[[k_A,omega_A,rel_A],[k_B,omega_B,rel_B],[k_C,omega_C,rel_D],[k_D,omega_D,rel_D]]\"\n其中每个符号对应于指定案例的相应数值。", "solution": "所提出的问题是计算工程领域中的一个明确定义的任务，特别是在数值线性代数领域。它要求实现一种自适应逐次超松弛（SOR）方法来求解线性方程组 $A x = b$。该问题具有科学依据，内部一致且完整。所有必要的参数、初始条件和测试用例都已指定，从而可以得到唯一且可验证的解。因此，我将着手解决此问题。\n\n问题的核心是 SOR 迭代法。对于线性系统 $A x = b$，其中 $A$ 是一个 $n \\times n$ 矩阵，SOR 方法生成一系列近似解 $x^{(k)}$。从一个迭代解 $x^{(k)}$ 到下一个 $x^{(k+1)}$ 的转换由一个松弛参数 $\\omega \\in (0, 2)$ 控制。每个分量 $x_i^{(k+1)}$ 的更新公式如下：\n$$\nx^{(k+1)}_i = (1 - \\omega)\\,x^{(k)}_i + \\frac{\\omega}{a_{ii}}\\left(b_i - \\sum_{j=1}^{i-1} a_{ij}\\,x^{(k+1)}_j - \\sum_{j=i+1}^{n} a_{ij}\\,x^{(k)}_j\\right)\n$$\n这个公式表明，$x_i^{(k+1)}$ 的计算利用了最新的已更新分量 $x_j^{(k+1)}$（对于 $j < i$）。这种结构是高斯-赛德尔（Gauss-Seidel）类型方法的特征，适合于高效的就地实现，其中解向量是逐步更新的。\n\n这个问题的关键方面是松弛参数 $\\omega$ 的自适应调整。SOR 方法的性能对 $\\omega$ 的选择高度敏感。使迭代次数最小化的最优值 $\\omega_{\\text{opt}}$ 通常是未知的。所规定的自适应策略是一种启发式反馈控制机制，旨在将 $\\omega$ 动态调整到一个更有效的值。这是通过监控收敛速率来实现的。\n\n在 $N_{\\text{upd}}$ 次迭代窗口内的经验收敛因子定义为：\n$$\nq^{(k)} = \\left(\\frac{\\|r^{(k)}\\|_2}{\\|r^{(k - N_{\\text{upd}})}\\|_2}\\right)^{1/N_{\\text{upd}}}\n$$\n其中 $r^{(k)} = b - Ax^{(k)}$ 是第 $k$ 次迭代的残差，$\\|\\cdot\\|_2$ 表示欧几里得范数。这个因子 $q^{(k)}$ 提供了在过去 $N_{\\text{upd}}$ 步中每次迭代残差范数的平均减少量的估计。较小的 $q^{(k)}$ 意味着更快的收敛。\n\n自适应更新规则根据测量的收敛因子 $q^{(k)}$ 与期望的目标因子 $q_{\\text{tgt}}$ 之间的偏差来调整 $\\omega$：\n$$\n\\omega_{\\text{new}} = \\omega_{\\text{old}} \\cdot \\left[1 + \\alpha \\left(q_{\\text{tgt}} - q^{(k)}\\right)\\right]\n$$\n此处，$\\alpha$ 是一个控制调整幅度的增益参数。如果观察到的收敛速度慢于目标（$q^{(k)} > q_{\\text{tgt}}$），则方括号中的项小于 1，从而减小 $\\omega$。相反，如果收敛速度快于目标（$q^{(k)} < q_{\\text{tgt}}$），则 $\\omega$ 会增加。更新后的值随后被裁剪以保持在安全区间 $[\\omega_{\\min}, \\omega_{\\max}]$ 内以维持稳定性，因为只有当 $\\omega \\in (0, 2)$ 时，SOR 方法才能保证对对称正定矩阵收敛。此更新每隔 $N_{\\text{upd}}$ 次迭代定期执行。\n\n整体算法流程如下：\n1. 初始化解向量 $x^{(0)}$、松弛参数 $\\omega^{(0)}$ 和迭代计数器 $k=0$。\n2. 计算初始残差 $r^{(0)} = b - A x^{(0)}$ 及其范数 $\\|r^{(0)}\\|_2$。如果 $\\|r^{(0)}\\|_2 = 0$，则初始猜测即为精确解；以 $k=0$ 终止。此初始范数用作收敛性检查和第一次 $\\omega$ 更新的参考。\n3. 开始主迭代循环，对于 $k = 1, 2, \\ldots, k_{\\max}$。\n4. 在每次迭代中，执行一次完整的 SOR 扫描来更新 $x$ 的所有分量，从 $x^{(k-1)}$ 计算 $x^{(k)}$。这是通过对分量 $i = 1, \\ldots, n$ 进行就地循环来完成的。\n5. 扫描后，计算新的残差 $r^{(k)} = b - A x^{(k)}$ 及其范数 $\\|r^{(k)}\\|_2$。\n6. 通过将相对残差范数 $\\|r^{(k)}\\|_2 / \\|r^{(0)}\\|_2$ 与容差 $\\varepsilon$ 进行比较来检查收敛性。如果满足条件，循环终止，并记录当前状态 $(k, \\omega, \\|r^{(k)}\\|_2/\\|r^{(0)}\\|_2)$。\n7. 如果迭代次数 $k$ 是 $N_{\\text{upd}}$ 的正整数倍，则使用 $q^{(k)}$ 的公式和随后的调整来执行 $\\omega$ 的自适应更新，然后进行裁剪。\n8. 如果循环完成而未收敛，则过程因达到最大迭代次数 $k_{\\max}$ 而终止。\n\n这种结构化的方法，将经典的迭代求解器与现代的自适应控制启发式算法相结合，是计算科学中的一种实用方法。下面的实现将为指定的测试用例精确地遵循这一逻辑。", "answer": "```python\nimport numpy as np\n\ndef adaptive_sor(A, b, x0, omega0, N_upd, alpha, q_tgt, omega_min, omega_max, epsilon, k_max):\n    \"\"\"\n    Solves the linear system Ax = b using an adaptive Successive Over-Relaxation (SOR) method.\n\n    Args:\n        A (np.ndarray): The n x n coefficient matrix.\n        b (np.ndarray): The n-dimensional right-hand side vector.\n        x0 (np.ndarray): The initial guess for the solution vector.\n        omega0 (float): The initial relaxation parameter.\n        N_upd (int): The number of iterations between omega updates.\n        alpha (float): The gain for the omega update rule.\n        q_tgt (float): The target convergence factor.\n        omega_min (float): The minimum allowed value for omega.\n        omega_max (float): The maximum allowed value for omega.\n        epsilon (float): The relative tolerance for the stopping criterion.\n        k_max (int): The maximum number of iterations.\n\n    Returns:\n        list: A list containing [k_stop, omega_final, rho_rel], where\n              k_stop is the final iteration count,\n              omega_final is the final relaxation parameter, and\n              rho_rel is the final relative residual norm.\n    \"\"\"\n    n = A.shape[0]\n    x = x0.copy()\n    omega = omega0\n\n    # Initial state (k=0)\n    r0 = b - A @ x\n    norm_r0 = np.linalg.norm(r0)\n\n    # Handle immediate convergence case\n    if norm_r0 == 0:\n        return [0, omega, 0.0]\n\n    # Initialize memory for adaptive updates\n    norm_r_at_last_update = norm_r0\n    \n    k_stop = 0\n    rho_rel = 1.0\n\n    # Main iteration loop\n    for k in range(1, k_max + 1):\n        # Perform one full SOR sweep (in-place update)\n        for i in range(n):\n            sigma = np.dot(A[i, :i], x[:i]) + np.dot(A[i, i + 1:], x[i + 1:])\n            x[i] = (1 - omega) * x[i] + (omega / A[i, i]) * (b[i] - sigma)\n\n        # Compute residual and its norm for the current iterate\n        r_k = b - A @ x\n        norm_r_k = np.linalg.norm(r_k)\n\n        # Check stopping criterion\n        rho_rel = norm_r_k / norm_r0\n        if rho_rel <= epsilon:\n            k_stop = k\n            return [k_stop, omega, rho_rel]\n\n        # Update omega if it's an update iteration\n        if k > 0 and k % N_upd == 0:\n            if norm_r_at_last_update > 0:\n                q_k = (norm_r_k / norm_r_at_last_update)**(1.0 / N_upd)\n                omega_new = omega * (1 + alpha * (q_tgt - q_k))\n                omega = np.clip(omega_new, omega_min, omega_max)\n            \n            # Store current norm for the next update window\n            norm_r_at_last_update = norm_r_k\n\n    # If loop finishes, max iterations was reached\n    k_stop = k_max\n    final_r = b - A @ x\n    final_norm_r = np.linalg.norm(final_r)\n    rho_rel = final_norm_r / norm_r0\n    \n    return [k_stop, omega, rho_rel]\n\ndef solve():\n    \"\"\"\n    Sets up and runs the test cases for the adaptive SOR solver.\n    \"\"\"\n    test_cases = []\n\n    # Case A\n    n_A = 50\n    A_A = np.diag(np.full(n_A, 2.0)) - np.diag(np.ones(n_A - 1), 1) - np.diag(np.ones(n_A - 1), -1)\n    b_A = np.ones(n_A)\n    x0_A = np.zeros(n_A)\n    params_A = {'x0': x0_A, 'omega0': 1.0, 'N_upd': 10, 'alpha': 0.3, 'q_tgt': 0.5,\n                'omega_min': 0.8, 'omega_max': 1.95, 'epsilon': 1e-8, 'k_max': 20000}\n    test_cases.append(('A', A_A, b_A, params_A))\n\n    # Case B\n    n_B = 40\n    rng_B_A = np.random.default_rng(7)\n    R_B = rng_B_A.standard_normal((n_B, n_B))\n    A_B = R_B.T @ R_B + 1.0 * np.identity(n_B)\n    rng_B_b = np.random.default_rng(11)\n    b_B = rng_B_b.standard_normal(n_B)\n    x0_B = np.zeros(n_B)\n    params_B = {'x0': x0_B, 'omega0': 1.0, 'N_upd': 5, 'alpha': 0.2, 'q_tgt': 0.6,\n                'omega_min': 0.6, 'omega_max': 1.95, 'epsilon': 1e-8, 'k_max': 20000}\n    test_cases.append(('B', A_B, b_B, params_B))\n\n    # Case C\n    n_C = 10\n    rng_C_A = np.random.default_rng(3)\n    R_C = rng_C_A.standard_normal((n_C, n_C))\n    A_C = R_C.T @ R_C + 1.0 * np.identity(n_C)\n    rng_C_x = np.random.default_rng(5)\n    x_star_C = rng_C_x.standard_normal(n_C)\n    b_C = A_C @ x_star_C\n    x0_C = x_star_C\n    params_C = {'x0': x0_C, 'omega0': 1.5, 'N_upd': 3, 'alpha': 0.5, 'q_tgt': 0.5,\n                'omega_min': 0.5, 'omega_max': 1.95, 'epsilon': 1e-8, 'k_max': 20000}\n    test_cases.append(('C', A_C, b_C, params_C))\n\n    # Case D\n    n_D = 20\n    A_D = np.diag(np.full(n_D, 2.0)) - np.diag(np.ones(n_D - 1), 1) - np.diag(np.ones(n_D - 1), -1)\n    b_D = np.ones(n_D)\n    x0_D = np.zeros(n_D)\n    params_D = {'x0': x0_D, 'omega0': 1.9, 'N_upd': 1, 'alpha': 0.4, 'q_tgt': 0.4,\n                'omega_min': 1.0, 'omega_max': 1.95, 'epsilon': 1e-8, 'k_max': 20000}\n    test_cases.append(('D', A_D, b_D, params_D))\n\n    all_results = []\n    for _, A, b, params in test_cases:\n        result = adaptive_sor(A, b, **params)\n        \n        k_stop = result[0]\n        omega_final = result[1]\n        rho_rel = result[2]\n        \n        # Format the numbers for the final output string\n        formatted_result = [k_stop, f\"{omega_final:.6f}\", f\"{rho_rel:.6f}\"]\n        # Convert formatted floats back to string representation needed for a list\n        # This approach builds a list that can be easily converted to a string\n        all_results.append(f\"[{formatted_result[0]},{formatted_result[1]},{formatted_result[2]}]\")\n\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```", "id": "2441060"}]}