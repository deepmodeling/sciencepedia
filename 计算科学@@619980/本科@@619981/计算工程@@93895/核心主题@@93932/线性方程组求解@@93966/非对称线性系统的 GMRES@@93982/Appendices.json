{"hands_on_practices": [{"introduction": "真正理解一个算法的最好方法是亲手实现它。第一个动手实践将指导你从基本构件开始，实现一个完整的非重启 GMRES 方法。你将通过构建克雷洛夫子空间的阿诺尔迪基，并求解相关的最小二乘问题，来找到每一步的最优解 [@problem_id:2397285]。", "problem": "给定一个实方阵 $A \\in \\mathbb{R}^{n \\times n}$，一个右端向量 $b \\in \\mathbb{R}^{n}$，一个初始猜测解 $x_0 \\in \\mathbb{R}^{n}$，以及一个满足 $1 \\le m \\le n$ 的正整数 $m$，考虑广义最小残差(GMRES)近似解 $x_m \\in x_0 + \\mathcal{K}_m(A,r_0)$，它最小化残差的 2-范数。其中 $r_0 = b - A x_0$，$\\mathcal{K}_m(A,r_0) = \\text{span}\\{r_0, A r_0, \\dots, A^{m-1} r_0\\}$。对于下面的每个测试用例，计算求解\n$$\n\\min_{x \\in x_0 + \\mathcal{K}_m(A,r_0)} \\| b - A x \\|_2\n$$\n的向量 $x_m$，并报告以下两个量：(i) 达到的残差范数 $\\| b - A x_m \\|_2$，四舍五入到八位小数；以及(ii) 实际执行的 Krylov 步数 $k$，定义为近似解所用构造子空间的维度，其中 $k \\in \\{0,1,\\dots,m\\}$。$k=0$ 的情况对应于 $\\|r_0\\|_2 = 0$，此时 $x_m = x_0$，残差范数为 $0$。如果在 $m$ 步之前遇到子空间的不变性，则使用所达到的 $k < m$。\n\n测试套件由五个独立的用例组成。每个用例都指定了 $A$、$b$、$x_0$ 和 $m$：\n\n1) 用例 1 (方阵，非对称，完整子空间):\n- $A = \\begin{bmatrix}\n4 & 1 & 0 & 0 \\\\\n2 & 3 & 1 & 0 \\\\\n0 & 1 & 3 & 1 \\\\\n0 & 0 & 1 & 2\n\\end{bmatrix}$,\n$b = \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\\\ 4 \\end{bmatrix}$,\n$x_0 = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix}$,\n$m = 4$.\n\n2) 用例 2 (方阵，非对称，部分子空间):\n- $A = \\begin{bmatrix}\n3 & -1 & 0 & 0 & 0 \\\\\n2 & 4 & 1 & 0 & 0 \\\\\n0 & -2 & 3 & 1 & 0 \\\\\n0 & 0 & -1 & 2 & 1 \\\\\n0 & 0 & 0 & -3 & 1\n\\end{bmatrix}$,\n$b = \\begin{bmatrix} 1 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ 1 \\end{bmatrix}$,\n$x_0 = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix}$,\n$m = 3$.\n\n3) 用例 3 (上三角矩阵，具有大的超对角线元素，完整子空间):\n- $A = \\begin{bmatrix}\n1 & 10 & 0 & 0 & 0 \\\\\n0 & 1 & 10 & 0 & 0 \\\\\n0 & 0 & 1 & 10 & 0 \\\\\n0 & 0 & 0 & 1 & 10 \\\\\n0 & 0 & 0 & 0 & 1\n\\end{bmatrix}$,\n$b = \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{bmatrix}$,\n$x_0 = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix}$,\n$m = 5$.\n\n4) 用例 4 (非零初始猜测，单步 Krylov):\n- $A = \\begin{bmatrix}\n2 & -1 & 0 & 0 \\\\\n1 & 2 & -1 & 0 \\\\\n0 & 1 & 2 & -1 \\\\\n0 & 0 & 1 & 2\n\\end{bmatrix}$,\n$b = \\begin{bmatrix} 1 \\\\ 2 \\\\ 2 \\\\ 1 \\end{bmatrix}$,\n$x_0 = \\begin{bmatrix} 0.5 \\\\ -0.5 \\\\ 0.5 \\\\ -0.5 \\end{bmatrix}$,\n$m = 1$.\n\n5) 用例 5 (在初始猜测解处提前精确收敛):\n- $A = \\begin{bmatrix}\n2 & 1 & 0 \\\\\n0 & 3 & 1 \\\\\n1 & 0 & 2\n\\end{bmatrix}$,\n$x_{\\text{true}} = \\begin{bmatrix} 1 \\\\ -1 \\\\ 2 \\end{bmatrix}$,\n$b = A x_{\\text{true}} = \\begin{bmatrix} 1 \\\\ -1 \\\\ 5 \\end{bmatrix}$,\n$x_0 = x_{\\text{true}} = \\begin{bmatrix} 1 \\\\ -1 \\\\ 2 \\end{bmatrix}$,\n$m = 3$.\n\n您的程序必须按指定顺序处理所有五个用例。对于每个用例，计算 $x_m$，然后计算残差范数 $\\|b - A x_m\\|_2$，将其四舍五入到八位小数，确定 $k$，并将结果汇总到单行输出中，格式如下：\n- 一行内容，包含一个用方括号括起来的逗号分隔列表，其中每个元素是一个双元素列表 $[\\text{residual\\_norm}, \\text{krylov\\_steps}]$。\n- 例如，总输出应类似于 $[[r_1,k_1],[r_2,k_2],[r_3,k_3],[r_4,k_4],[r_5,k_5]]$，其中每个 $r_i$ 是一个四舍五入到八位小数的浮点数，每个 $k_i$ 是一个整数。", "solution": "目标是广义最小残差 (GMRES) 近似解，其定义如下。给定 $A \\in \\mathbb{R}^{n \\times n}$，$b \\in \\mathbb{R}^{n}$，一个初始猜测解 $x_0 \\in \\mathbb{R}^{n}$，以及一个整数 $m$ 且 $1 \\le m \\le n$，定义初始残差 $r_0 = b - A x_0$ 和 $m$ 维 Krylov 子空间 $\\mathcal{K}_m(A,r_0) = \\text{span}\\{ r_0, A r_0, \\dots, A^{m-1} r_0 \\}$。GMRES 近似解 $x_m$ 是仿射空间 $x_0 + \\mathcal{K}_m(A,r_0)$ 中最小化残差 2-范数的唯一向量，即，\n$$\nx_m \\in \\arg\\min_{x \\in x_0 + \\mathcal{K}_m(A,r_0)} \\| b - A x \\|_2.\n$$\n\n计算 $x_m$ 的一种原则性方法依赖于两个基本组成部分：Krylov 子空间的一个标准正交基和一个降维最小二乘问题。使用 Arnoldi 过程构造 $\\mathcal{K}_m(A,r_0)$ 的一个标准正交基。从 $r_0$ 及其范数 $\\beta = \\|r_0\\|_2$ 开始。如果 $\\beta = 0$，则 $x_0$ 已经是解，最小残差范数为 $0$，且不需要 Krylov 步数，因此我们设置 $k = 0$ 且 $x_m = x_0$。\n\n如果 $\\beta > 0$，定义 $v_1 = r_0 / \\beta$。Arnoldi 过程生成标准正交向量 $v_1, v_2, \\dots, v_{k+1}$ (其中 $k \\le m$) 和一个上 Hessenberg 矩阵 $\\bar{H}_k \\in \\mathbb{R}^{(k+1) \\times k}$，使得\n$$\nA V_k = V_{k+1} \\bar{H}_k,\n$$\n其中 $V_k = [v_1,\\dots,v_k] \\in \\mathbb{R}^{n \\times k}$ 且 $V_{k+1} = [v_1,\\dots,v_{k+1}] \\in \\mathbb{R}^{n \\times (k+1)}$。标准的修正 Gram–Schmidt 正交化过程产生 $\\bar{H}_k$ 的系数和标准正交基。如果某个次对角线元素 $h_{j+1,j}$ 对于某个 $j < m$ 变为零，则子空间变为 $A$-不变的，过程提前停止，此时 $k = j+1 \\le m$。\n\n近似解 $x_m$ 可以参数化为 $x = x_0 + V_k y$，其中某个 $y \\in \\mathbb{R}^k$。将其代入残差并使用 Arnoldi 关系式可得\n$$\n\\| b - A (x_0 + V_k y) \\|_2 = \\| r_0 - A V_k y \\|_2 = \\| \\beta v_1 - V_{k+1} \\bar{H}_k y \\|_2 = \\| \\beta e_1 - \\bar{H}_k y \\|_2,\n$$\n其中 $e_1 \\in \\mathbb{R}^{k+1}$ 是第一个标准基向量。因此，系数向量 $y_m$ 求解降维最小二乘问题\n$$\ny_m \\in \\arg\\min_{y \\in \\mathbb{R}^k} \\| \\bar{H}_k y - \\beta e_1 \\|_2.\n$$\n任何数值稳定的最小二乘求解器（例如，基于奇异值分解的求解器）都能得到 $y_m$。然后，最小化近似解可由\n$$\nx_m = x_0 + V_k y_m,\n$$\n获得，最小残差范数为\n$$\n\\| b - A x_m \\|_2 = \\| \\beta e_1 - \\bar{H}_k y_m \\|_2.\n$$\n\n因此，该算法遵循以下基本原理：\n1) 计算 $r_0 = b - A x_0$ 和 $\\beta = \\|r_0\\|_2$。如果 $\\beta = 0$，则设置 $k = 0$，$x_m = x_0$，残差范数 $= 0$。\n2) 否则，通过使用修正 Gram–Schmidt 的 Arnoldi 关系式来构建 $\\mathcal{K}_m(A,r_0)$ 的标准正交基，累积 $\\bar{H}_k$ 的元素，直到完成 $m$ 步或某个次对角线元素在数值上变为零，从而确定 $k$。\n3) 求解降维最小二乘问题以得到 $y_m$，并构造 $x_m = x_0 + V_k y_m$。\n4) 计算残差范数 $\\|b - A x_m\\|_2$ 并将其四舍五入到八位小数。报告实际执行的 Krylov 步数 $k$。\n\n对于提供的测试用例，所有矩阵都是非对称方阵，向量被明确给出，整数 $m$ 满足 $1 \\le m \\le n$。用例 5 展示了在初始猜测解处提前精确收敛的情况，此时 $k = 0$。最终输出必须是包含汇总列表 $[[r_1,k_1],[r_2,k_2],[r_3,k_3],[r_4,k_4],[r_5,k_5]]$ 的单行，其中每个 $r_i$ 是对应其用例四舍五入到八位小数的残差范数，每个 $k_i$ 是一个在 $\\{0,1,\\dots,m\\}$ 中的整数。", "answer": "```python\nimport numpy as np\n\ndef arnoldi_basis(A, r0, m, tol=1e-14):\n    \"\"\"\n    Perform the Arnoldi process with modified Gram-Schmidt to generate\n    an orthonormal basis V and upper Hessenberg matrix H_bar.\n    Returns:\n        V (n x (k+1)) with columns v1..v_{k+1} if k>=1; if k==0, V is empty\n        H ( (k+1) x k ) upper Hessenberg\n        beta (norm of r0)\n        k (number of Krylov steps actually performed, 0<=k<=m)\n    \"\"\"\n    n = A.shape[0]\n    beta = np.linalg.norm(r0)\n    if beta == 0.0:\n        # No steps needed; exact at initial guess\n        return np.zeros((n, 0)), np.zeros((1, 0)), 0.0, 0\n\n    # Preallocate maximum sizes; we'll slice by the actual k\n    V = np.zeros((n, m + 1), dtype=float)\n    H = np.zeros((m + 1, m), dtype=float)\n\n    V[:, 0] = r0 / beta\n    k = 0\n    for j in range(m):\n        w = A @ V[:, j]\n        # Modified Gram-Schmidt\n        for i in range(j + 1):\n            H[i, j] = np.dot(V[:, i], w)\n            w = w - H[i, j] * V[:, i]\n        H[j + 1, j] = np.linalg.norm(w)\n        if H[j + 1, j] <= tol:\n            # Invariant subspace reached; breakdown\n            k = j + 1  # Number of columns in V_k\n            # We cannot form V[:, j+1]; stop here\n            break\n        V[:, j + 1] = w / H[j + 1, j]\n        k = j + 1  # Update number of Krylov steps performed\n    # Slice to actual sizes: V has (k+1) columns if k>=1; H is (k+1) x k\n    V_used = V[:, : (k + 1) ] if k >= 1 else np.zeros((n, 0))\n    H_used = H[: (k + 1), : k] if k >= 1 else np.zeros((1, 0))\n    return V_used, H_used, beta, k\n\ndef gmres_minres(A, b, x0, m, tol=1e-14):\n    \"\"\"\n    Compute x_m in x0 + K_m(A, r0) minimizing ||b - A x||_2 via Arnoldi and least squares.\n    Returns:\n        x_m (approximate solution),\n        res_norm (float residual norm),\n        k (int number of Krylov steps actually performed, 0<=k<=m)\n    \"\"\"\n    r0 = b - A @ x0\n    V, H, beta, k = arnoldi_basis(A, r0, m, tol=tol)\n    if k == 0:\n        # Exact at initial guess\n        return x0.copy(), 0.0, 0\n    # Solve min || H y - beta e1 ||_2\n    e1 = np.zeros((k + 1,), dtype=float)\n    e1[0] = 1.0\n    rhs = beta * e1\n    # Least squares solution using SVD-based solver\n    y, *_ = np.linalg.lstsq(H, rhs, rcond=None)\n    # Form x_m\n    x_m = x0 + V[:, :k] @ y\n    res = b - A @ x_m\n    res_norm = float(np.linalg.norm(res))\n    return x_m, res_norm, k\n\ndef solve():\n    # Define test cases as per the problem statement.\n    tests = []\n\n    # Case 1\n    A1 = np.array([\n        [4.0, 1.0, 0.0, 0.0],\n        [2.0, 3.0, 1.0, 0.0],\n        [0.0, 1.0, 3.0, 1.0],\n        [0.0, 0.0, 1.0, 2.0]\n    ], dtype=float)\n    b1 = np.array([1.0, 2.0, 3.0, 4.0], dtype=float)\n    x01 = np.zeros(4, dtype=float)\n    m1 = 4\n    tests.append((A1, b1, x01, m1))\n\n    # Case 2\n    A2 = np.array([\n        [3.0, -1.0, 0.0, 0.0, 0.0],\n        [2.0,  4.0, 1.0, 0.0, 0.0],\n        [0.0, -2.0, 3.0, 1.0, 0.0],\n        [0.0,  0.0,-1.0, 2.0, 1.0],\n        [0.0,  0.0, 0.0,-3.0, 1.0]\n    ], dtype=float)\n    b2 = np.array([1.0, 0.0, 1.0, 0.0, 1.0], dtype=float)\n    x02 = np.zeros(5, dtype=float)\n    m2 = 3\n    tests.append((A2, b2, x02, m2))\n\n    # Case 3\n    A3 = np.array([\n        [1.0, 10.0,  0.0,  0.0,  0.0],\n        [0.0,  1.0, 10.0,  0.0,  0.0],\n        [0.0,  0.0,  1.0, 10.0,  0.0],\n        [0.0,  0.0,  0.0,  1.0, 10.0],\n        [0.0,  0.0,  0.0,  0.0,  1.0]\n    ], dtype=float)\n    b3 = np.array([1.0, 1.0, 1.0, 1.0, 1.0], dtype=float)\n    x03 = np.zeros(5, dtype=float)\n    m3 = 5\n    tests.append((A3, b3, x03, m3))\n\n    # Case 4\n    A4 = np.array([\n        [2.0, -1.0,  0.0,  0.0],\n        [1.0,  2.0, -1.0,  0.0],\n        [0.0,  1.0,  2.0, -1.0],\n        [0.0,  0.0,  1.0,  2.0]\n    ], dtype=float)\n    b4 = np.array([1.0, 2.0, 2.0, 1.0], dtype=float)\n    x04 = np.array([0.5, -0.5, 0.5, -0.5], dtype=float)\n    m4 = 1\n    tests.append((A4, b4, x04, m4))\n\n    # Case 5\n    A5 = np.array([\n        [2.0, 1.0, 0.0],\n        [0.0, 3.0, 1.0],\n        [1.0, 0.0, 2.0]\n    ], dtype=float)\n    x_true5 = np.array([1.0, -1.0, 2.0], dtype=float)\n    b5 = A5 @ x_true5\n    x05 = x_true5.copy()\n    m5 = 3\n    tests.append((A5, b5, x05, m5))\n\n    results = []\n    for A, b, x0, m in tests:\n        _, res_norm, k = gmres_minres(A, b, x0, m, tol=1e-14)\n        # Round residual norm to eight decimal places as required\n        res_rounded = round(res_norm, 8)\n        results.append([res_rounded, int(k)])\n\n    # Print in the exact required single-line format\n    # Ensure standard Python list formatting\n    print(str(results))\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2397285"}, {"introduction": "GMRES 的收敛速度不仅取决于矩阵 $A$ 的性质，还与初始残差 $r_0$ 有着密切关系。本实践旨在探索这种关系，特别是当 $r_0$ 与 $A$ 的特征向量对齐时，如何显著改变收敛行为 [@problem_id:2397325]。你将亲眼见证这种情况如何导致理想的单步收敛，或是完全的停滞。", "problem": "你将编写一个完整、可运行的程序，实现用于求解非对称线性系统的广义最小残差方法（GMRES），然后用它来通过经验证明初始残差与系数矩阵特征向量的对齐方式如何影响收敛性。你的实现必须仅基于以下基本定义和事实：\n\n- 由矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 和向量 $r_0 \\in \\mathbb{R}^n$ 生成的克里洛夫子空间（Krylov subspace）定义为\n$$\n\\mathcal{K}_k(A,r_0) = \\mathrm{span}\\{r_0, A r_0, A^2 r_0, \\dots, A^{k-1} r_0\\}.\n$$\n- 广义最小残差方法（GMRES）在每次迭代 $k$ 时，在仿射空间 $x_0 + \\mathcal{K}_k(A,r_0)$ 中寻找一个近似解 $x_k$，该解使得残差 $r_k = b - A x_k$ 的欧几里得范数最小化。\n- Arnoldi 过程产生 $\\mathcal{K}_k(A,r_0)$ 的一个标准正交基，以及一个编码了 $A$ 在该基上投影的上Hessenberg矩阵。\n\n你的任务是使用 Arnoldi 过程、修正的Gram-Schmidt正交化以及每次迭代中的一个小型最小二乘问题，来实现一个稠密、双精度、非重启动的GMRES。你的实现必须：\n- 在所有测试中均使用 $x_0 = 0$，因此 $r_0 = b$。\n- 在每次迭代 $k$ 时，构建与 Arnoldi 关系相关的最小二乘问题，并产生最小化解 $x_k \\in x_0 + \\mathcal{K}_k(A,r_0)$。\n- 在每个 $k$ 计算并记录真实残差范数 $\\|b - A x_k\\|_2$，一旦其小于或等于容差，即停止。\n- 检测 Arnoldi 过程中的崩溃（breakdown），即当无法形成新的基向量时（也就是下一个次对角 Arnoldi 系数在数值上为零）。在这种情况下，使用当前的克里洛夫子空间计算当前 $k$ 的 $x_k$ 及其残差范数。如果 Arnoldi 过程无法进一步扩展且尚未达到容差，则声明停滞（stagnation）并指出在允许的迭代次数内未能达到所要求的容差。\n\n你的程序必须在以下测试套件上运行GMRES实现。在每个测试中，使用容差 $\\text{tol} = 10^{-12}$ 和 $\\text{max\\_iter} = 5$。\n\n- 测试用例 1（边界情况：奇异矩阵，初始残差与零特征值对应的特征向量共线，导致停滞）：\n  - $A = \\begin{bmatrix} 0 & 1 \\\\ 0 & 0 \\end{bmatrix}$,\n  - $b = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$,\n  - $x_0 = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$。\n  此 $A$ 矩阵有一个特征值为 $0$，其对应的特征向量为 $\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$。此处 $r_0 = b$ 与该特征向量对齐。报告满足 $\\|b - A x_k\\|_2 \\le \\text{tol}$ 的最小迭代次数 $k$；如果在 $\\text{max\\_iter}$ 内从未达到此条件，或者 Arnoldi 过程在达到容差前发生崩溃，则返回 $-1$。\n\n- 测试用例 2（边界情况：初始残差与非零特征值对应的特征向量共线，在精确算术中可一步求解）：\n  - $A = \\begin{bmatrix} 2 & 1000 \\\\ 0 & 1 \\end{bmatrix}$,\n  - $b = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$,\n  - $x_0 = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$。\n  此 $A$ 矩阵是一个非对称上三角矩阵，有一个特征值为 $2$，其对应的特征向量为 $\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$。报告满足容差的最小迭代次数 $k$，如果未达到则返回 $-1$。\n\n- 测试用例 3（理想情况：对于同一非对称矩阵的通用残差）：\n  - $A = \\begin{bmatrix} 2 & 1000 \\\\ 0 & 1 \\end{bmatrix}$,\n  - $b = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$,\n  - $x_0 = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$。\n  报告满足容差的最小迭代次数 $k$，如果未达到则返回 $-1$。\n\n- 测试用例 4（近边界条件：初始残差与一个非常小的非零特征值对应的特征向量对齐）：\n  - $A = \\begin{bmatrix} 10^{-8} & 1 \\\\ 0 & 1 \\end{bmatrix}$,\n  - $b = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$,\n  - $x_0 = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$。\n  报告满足容差的最小迭代次数 $k$，如果未达到则返回 $-1$。\n\n最终输出格式：\n- 您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，$\\texttt{[result1,result2,result3,result4]}$），其中每个条目是相应测试用例的整数迭代次数，如果未能在限制内达到容差或方法因崩溃而停滞，则为 $-1$。\n\n不应读取任何用户输入；所有数据都应按上述规定硬编码。", "solution": "求解非对称线性系统 $Ax=b$ 的问题（其中给定矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 和向量 $b \\in \\mathbb{R}^n$，求解 $x \\in \\mathbb{R}^n$）将通过实现广义最小残差（GMRES）方法来解决。该解法必须按照概述的基本原理从头构建。\n\nGMRES 的核心原理是在每次迭代 $k$ 时，找到一个近似解 $x_k$，该解能够最小化残差的欧几里得范数 $\\|r_k\\|_2 = \\|b - Ax_k\\|_2$。$x_k$ 的搜索被限制在仿射子空间 $x_0 + \\mathcal{K}_k(A, r_0)$ 中，其中 $x_0$ 是初始猜测值，而 $\\mathcal{K}_k(A, r_0)$ 是由 $A$ 和初始残差 $r_0 = b - Ax_0$ 生成的第 $k$ 个克里洛夫子空间。克里洛夫子空间定义为：\n$$\n\\mathcal{K}_k(A,r_0) = \\mathrm{span}\\{r_0, A r_0, A^2 r_0, \\dots, A^{k-1} r_0\\}\n$$\n该子空间的一个标准正交基通过 Arnoldi 过程构建。设该基为 $V_k = [v_1, v_2, \\dots, v_k]$。带有修正 Gram-Schmidt（MGS）正交化的 Arnoldi 过程按以下步骤进行：\n1. 用 $v_1 = r_0 / \\|r_0\\|_2$ 进行初始化。\n2. 对每个 $j = 1, 2, \\dots, k$：\n    a. 计算新的候选向量 $w = Av_j$。\n    b. 使用 MGS 将 $w$ 与已有的基向量 $\\{v_1, \\dots, v_j\\}$ 正交化。对 $i=1, \\dots, j$，计算 $h_{ij} = v_i^T w$ 并更新 $w \\leftarrow w - h_{ij}v_i$。\n    c. 计算所得向量的范数，$h_{j+1,j} = \\|w\\|_2$。该系数是 Hessenberg 矩阵中的一个次对角线元素。\n    d. 如果 $h_{j+1,j}$ 在数值上为零，则称过程发生崩溃（break down），因为无法生成新的线性无关基向量。这意味着克里洛夫子空间在 $A$ 的作用下是不变的。\n    e. 标准化以找到下一个基向量：$v_{j+1} = w / h_{j+1,j}$。\n\n此过程生成一个标准正交基 $V_{k+1} = [v_1, \\dots, v_{k+1}]$ 和一个上 Hessenberg 矩阵 $\\bar{H}_k \\in \\mathbb{R}^{(k+1) \\times k}$（其元素为 $h_{ij}$），满足 Arnoldi 关系：\n$$\nAV_k = V_{k+1} \\bar{H}_k\n$$\n近似解 $x_k$ 可写作 $x_k = x_0 + z_k$，其中 $z_k \\in \\mathcal{K}_k(A, r_0)$。由于 $V_k$ 是 $\\mathcal{K}_k$ 的一个基，我们可以将 $z_k$ 表示为 $z_k = V_k y_k$，其中 $y_k \\in \\mathbb{R}^k$ 是某个系数向量。GMRES 最小化问题就是找到使残差范数最小的 $y_k$：\n$$\n\\min_{y_k \\in \\mathbb{R}^k} \\|b - A(x_0 + V_k y_k)\\|_2 = \\min_{y_k \\in \\mathbb{R}^k} \\|r_0 - AV_k y_k\\|_2\n$$\n代入 Arnoldi 关系 $AV_k = V_{k+1} \\bar{H}_k$ 并注意到 $r_0 = \\|r_0\\|_2 v_1$，目标函数变为：\n$$\n\\min_{y_k \\in \\mathbb{R}^k} \\| \\|r_0\\|_2 v_1 - V_{k+1} \\bar{H}_k y_k \\|_2\n$$\n由于 $V_{k+1}$ 的列是标准正交的，从左侧乘以 $V_{k+1}^T$ 会保持欧几里得范数不变。注意到 $V_{k+1}^T v_1 = e_1$，其中 $e_1 = [1, 0, \\dots, 0]^T \\in \\mathbb{R}^{k+1}$，我们得到等价的最小二乘问题：\n$$\n\\min_{y_k \\in \\mathbb{R}^k} \\| \\|r_0\\|_2 e_1 - \\bar{H}_k y_k \\|_2\n$$\n这是一个关于未知向量 $y_k$ 的小型 $(k+1) \\times k$ 线性最小二乘问题。它可以使用标准方法高效求解，例如对 $\\bar{H}_k$ 进行 QR 分解。一旦找到 $y_k$，解就更新为 $x_k = x_0 + V_k y_k$。\n该算法迭代进行。在从 $1$ 到 $\\text{max\\_iter}$ 的每一步 $k$ 中，我们扩展克里洛夫基，构建并求解相关的最小二乘问题，并计算得到的真实残差范数 $\\|b - Ax_k\\|_2$。如果此范数低于指定的容差 $\\text{tol}$，算法成功终止，返回迭代次数 $k$。如果在达到容差之前 Arnoldi 过程发生崩溃（$h_{k,k-1} \\approx 0$），则表示停滞，因为搜索空间无法进一步扩展。在这种情况下，或者如果达到最大迭代次数而未收敛，则认为该过程失败。\n所提供的实现遵循此公式，并设置 $x_0 = 0$，因此 $r_0=b$。它使用双精度浮点算术和 `numpy.linalg.lstsq` 在每次迭代中解决最小二乘子问题。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef gmres_solver(A, b, x0, tol, max_iter):\n    \"\"\"\n    Solves the linear system Ax = b using the unrestarted GMRES method.\n\n    Args:\n        A (np.ndarray): The coefficient matrix of size (n, n).\n        b (np.ndarray): The right-hand side vector of size (n,).\n        x0 (np.ndarray): The initial guess for the solution of size (n,).\n        tol (float): The convergence tolerance for the true residual norm.\n        max_iter (int): The maximum number of iterations.\n\n    Returns:\n        int: The number of iterations to converge, or -1 if it fails.\n    \"\"\"\n    n = A.shape[0]\n    r0 = b - A @ x0\n\n    r0_norm = np.linalg.norm(r0)\n    if r0_norm < tol:\n        return 0\n\n    # V stores orthonormal basis vectors of the Krylov subspace.\n    # We allocate for max_iter + 1 vectors.\n    V = np.zeros((n, max_iter + 1), dtype=np.float64)\n    V[:, 0] = r0 / r0_norm\n\n    # H stores the upper Hessenberg matrix from the Arnoldi process.\n    # It has size (max_iter + 1) x max_iter.\n    H = np.zeros((max_iter + 1, max_iter), dtype=np.float64)\n\n    for k in range(1, max_iter + 1):\n        # Arnoldi process using Modified Gram-Schmidt for one step.\n        # This computes the k-th column of H and the (k+1)-th vector in V.\n        # The loop indices are 0-based, so iteration k corresponds to k-1 in array indices.\n        w = A @ V[:, k - 1]\n        for i in range(k):\n            H[i, k - 1] = V[:, i].T @ w\n            w = w - H[i, k - 1] * V[:, i]\n        \n        H[k, k - 1] = np.linalg.norm(w)\n\n        # Form the least-squares problem for the current iteration k.\n        # We need to solve || beta * e1 - H_k * y ||_2 where H_k is (k+1) x k.\n        H_k = H[0:k + 1, 0:k]\n        e1 = np.zeros(k + 1, dtype=np.float64)\n        e1[0] = 1.0\n        rhs = r0_norm * e1\n\n        # Solve the least-squares problem for y.\n        y, _, _, _ = np.linalg.lstsq(H_k, rhs, rcond=None)\n\n        # Compute the solution for the current iteration.\n        x_k = x0 + V[:, 0:k] @ y\n\n        # Check the true residual norm for convergence.\n        true_res_norm = np.linalg.norm(b - A @ x_k)\n\n        if true_res_norm <= tol:\n            return k\n\n        # Check for breakdown. If h_{k+1, k} is near zero, the Krylov\n        # subspace can no longer be expanded. If we have not converged,\n        # it is a stagnation failure.\n        if H[k, k-1] < 1e-15:\n            return -1\n        \n        # Normalize the next basis vector.\n        V[:, k] = w / H[k, k - 1]\n        \n    # Maximum iterations reached without convergence.\n    return -1\n\ndef solve():\n    \"\"\"\n    Runs the GMRES solver on the specified test cases and prints the results.\n    \"\"\"\n    tol = 1e-12\n    max_iter = 5\n    x0 = np.array([0.0, 0.0], dtype=np.float64)\n\n    test_cases = [\n        # Test case 1: Singular matrix, initial residual aligned with null-space eigenvector.\n        {\n            \"A\": np.array([[0.0, 1.0], [0.0, 0.0]], dtype=np.float64),\n            \"b\": np.array([1.0, 0.0], dtype=np.float64),\n        },\n        # Test case 2: Nonsymmetric matrix, initial residual is an eigenvector.\n        {\n            \"A\": np.array([[2.0, 1000.0], [0.0, 1.0]], dtype=np.float64),\n            \"b\": np.array([1.0, 0.0], dtype=np.float64),\n        },\n        # Test case 3: Same matrix, generic initial residual.\n        {\n            \"A\": np.array([[2.0, 1000.0], [0.0, 1.0]], dtype=np.float64),\n            \"b\": np.array([1.0, 1.0], dtype=np.float64),\n        },\n        # Test case 4: Nearly singular matrix, initial residual is an eigenvector.\n        {\n            \"A\": np.array([[1e-8, 1.0], [0.0, 1.0]], dtype=np.float64),\n            \"b\": np.array([1.0, 0.0], dtype=np.float64),\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        A = case[\"A\"]\n        b = case[\"b\"]\n        result = gmres_solver(A, b, x0, tol, max_iter)\n        results.append(result)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2397325"}, {"introduction": "算法的病态行为往往最能揭示其内在局限。这个更进一步的实践将挑战你从观察者转变为设计者：你将亲手构造一个特定的非对称系统，使得 GMRES 方法必然会发生停滞 [@problem_id:2397339]。通过首先从理论上推导停滞发生的条件，然后构建一个满足该条件的矩阵并进行编程验证，你将对这一重要的数值现象获得更深刻的理解。", "problem": "您的任务是构建并验证一个具体示例，在该示例中，广义极小残差方法 (GMRES) 在求解一个非对称线性系统时，在已知迭代次数下表现出停滞现象。请在以下数学上精确的框架内进行。\n\n我们考虑形式为 $A x = b$ 的线性系统，其中 $A \\in \\mathbb{R}^{n \\times n}$ 是非对称矩阵，且 $b \\in \\mathbb{R}^{n}$。设初始猜测为 $x_0 \\in \\mathbb{R}^{n}$，初始残差为 $r_0 = b - A x_0$。对于 $k \\ge 1$，维度为 $k$ 的 Krylov 子空间为\n$$\n\\mathcal{K}_k(A,r_0) = \\operatorname{span}\\{ r_0, A r_0, A^2 r_0, \\dots, A^{k-1} r_0 \\}.\n$$\n广义极小残差方法 (GMRES) 定义了迭代解 $x_k \\in x_0 + \\mathcal{K}_k(A,r_0)$，使得残差 $r_k = b - A x_k$ 在仿射空间 $x_0 + \\mathcal{K}_k(A,r_0)$ 中的所有向量中具有最小的欧几里得范数。如果 $\\|r_k\\|_2 = \\|r_{k-1}\\|_2$，我们称 GMRES 在第 $k$ 次迭代时停滞；这等价于第 $k$ 步的极小残差范数未能比第 $k-1$ 步有所改进。\n\n您必须从以下基本事实出发：\n- GMRES 迭代解 $x_k$ 在 $x \\in x_0 + \\mathcal{K}_k(A,r_0)$ 上最小化 $\\|b - A x\\|_2$。\n- Arnoldi 过程构造了 $\\mathcal{K}_{k+1}(A,r_0)$ 的一个标准正交基 $V_{k+1}$ 和一个满足 $A V_k = V_{k+1} \\bar{H}_k$ 的上海森堡矩阵 $\\bar{H}_k \\in \\mathbb{R}^{(k+1)\\times k}$，其中 $V_k$ 包含 $V_{k+1}$ 的前 $k$ 列。\n- GMRES 的残差范数随 $k$ 非递增。\n\n请仅使用这些基本原理来解决以下设计与验证问题。\n\n1) 构造一个特定的非对称非奇异矩阵 $A \\in \\mathbb{R}^{4 \\times 4}$ 以及一个右端项 $b \\in \\mathbb{R}^{4}$，使得当 $x_0 = 0$ 时，GMRES 在第一次迭代时停滞，即 $\\|r_1\\|_2 = \\|r_0\\|_2$。您的构造必须基于第一性原理进行论证。您的程序必须使用 Arnoldi 过程和 Givens 旋转来实现非重启动的 GMRES，以在每次迭代中追踪残差范数。\n\n2) 从最小化原理出发，解释为什么您构造的 $A$ 和 $b$ 会在迭代 $k = 1$ 时产生停滞，并解释为什么所选的 $A$ 是非对称且非奇异的。\n\n3) 实现一个程序，计算 $k_{\\max} = 4$ 时的残差范数历史 $\\{\\|r_k\\|_2\\}_{k=0}^{k_{\\max}}$，并针对下方的每个测试用例，输出初始停滞序列的长度，该长度定义为满足在指定容差范围内对于所有 $j \\in \\{1,\\dots,s\\}$ 都有 $\\|r_j\\|_2 = \\|r_{j-1}\\|_2$ 的最大整数 $s \\ge 0$。使用绝对容差\n$$\n\\tau = 10^{-12} \\, \\|r_0\\|_2 + 10^{-15}.\n$$\n\n测试套件：\n- 情况 A (设计的停滞)：\n  $$\n  A = \\begin{bmatrix}\n  0 & 1 & 0 & 0\\\\\n  -1 & 0 & 0 & 0\\\\\n  0 & 0 & 0 & 2\\\\\n  0 & 0 & -2 & 0\n  \\end{bmatrix}, \\quad\n  b = \\begin{bmatrix} 1\\\\ 2\\\\ 3\\\\ 4 \\end{bmatrix}, \\quad\n  x_0 = \\begin{bmatrix} 0\\\\ 0\\\\ 0\\\\ 0 \\end{bmatrix}, \\quad\n  k_{\\max} = 4.\n  $$\n- 情况 B (第一步预计不会停滞)：\n  $$\n  A = \\begin{bmatrix}\n  4 & 1 & 0 & 0\\\\\n  0 & 4 & 1 & 0\\\\\n  0 & 0 & 4 & 1\\\\\n  0 & 0 & 0 & 4\n  \\end{bmatrix}, \\quad\n  b = \\begin{bmatrix} 1\\\\ 2\\\\ 3\\\\ 4 \\end{bmatrix}, \\quad\n  x_0 = \\begin{bmatrix} 0\\\\ 0\\\\ 0\\\\ 0 \\end{bmatrix}, \\quad\n  k_{\\max} = 4.\n  $$\n- 情况 C (近停滞扰动)：令 $\\varepsilon = 10^{-6}$ 且\n  $$\n  A = \\begin{bmatrix}\n  0 & 1 & 0 & 0\\\\\n  -1 & 0 & 0 & 0\\\\\n  0 & 0 & 0 & 2\\\\\n  0 & 0 & -2 & 0\n  \\end{bmatrix} + \\varepsilon I_4, \\quad\n  b = \\begin{bmatrix} 1\\\\ 2\\\\ 3\\\\ 4 \\end{bmatrix}, \\quad\n  x_0 = \\begin{bmatrix} 0\\\\ 0\\\\ 0\\\\ 0 \\end{bmatrix}, \\quad\n  k_{\\max} = 4.\n  $$\n\n对于每种情况，将您的 GMRES 实现以上述容差 $\\tau$ 计算出的初始停滞长度 $s \\in \\{0,1,2,3,4\\}$ 定义为整数输出。您的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表 (例如, \"[resultA,resultB,resultC]\")。\n\n不涉及物理单位。所有可能出现的角度都必须以弧度为单位；此处无此要求。所有数值参数均已明确提供。", "solution": "该问题要求构造并验证一个广义极小残差方法 (GMRES) 出现停滞的场景。我们将通过以下步骤解决此问题：首先建立停滞的基本数学条件，然后验证所提供的测试用例满足此条件，最后实现一个数值上稳健的 GMRES 算法以编程方式确认结果。\n\n严谨的分析始于 GMRES 方法的定义。对于线性系统 $A x = b$，其中 $A \\in \\mathbb{R}^{n \\times n}$，第 $k$ 次迭代解 $x_k$ 在仿射子空间 $x_0 + \\mathcal{K}_k(A,r_0)$ 中寻找，其中 $x_0$ 是初始猜测，$r_0 = b - A x_0$ 是初始残差，$\\mathcal{K}_k(A,r_0) = \\operatorname{span}\\{r_0, A r_0, \\dots, A^{k-1} r_0\\}$ 是第 $k$ 个 Krylov 子空间。迭代解 $x_k$ 是使残差的欧几里得范数 $\\|r_k\\|_2 = \\|b - A x_k\\|_2$ 最小化的唯一向量。\n\n在第 $k=1$ 次迭代时的停滞由条件 $\\|r_1\\|_2 = \\|r_0\\|_2$ 定义。GMRES 的残差范数是非递增的，因此这代表第一步完全没有进展。我们推导这种情况发生的条件。\n\n第一次迭代的形式为 $x_1 = x_0 + \\alpha r_0$，其中 $\\alpha \\in \\mathbb{R}$ 是一个标量，因为 $\\mathcal{K}_1(A,r_0) = \\operatorname{span}\\{r_0\\}$。相应的残差为 $r_1 = b - A x_1 = b - A(x_0 + \\alpha r_0) = (b - A x_0) - \\alpha A r_0 = r_0 - \\alpha A r_0$。\n\nGMRES 选择 $\\alpha$ 以最小化函数 $f(\\alpha) = \\|r_1\\|_2^2 = \\|r_0 - \\alpha A r_0\\|_2^2$。展开此表达式可得：\n$$f(\\alpha) = (r_0 - \\alpha A r_0)^T (r_0 - \\alpha A r_0) = r_0^T r_0 - 2\\alpha r_0^T A r_0 + \\alpha^2 (A r_0)^T (A r_0)$$\n为求最小值，我们将关于 $\\alpha$ 的导数设为零：\n$$\\frac{df}{d\\alpha} = -2 r_0^T A r_0 + 2\\alpha (A r_0)^T (A r_0) = 0$$\n假设 $A r_0 \\neq 0$ (否则问题将是平凡的或已解决)，最优的 $\\alpha$ 是：\n$$\\alpha_{\\text{opt}} = \\frac{r_0^T A r_0}{\\|A r_0\\|_2^2}$$\n要在 $k=1$ 时发生停滞，极小残差范数 $\\|r_1\\|_2$ 必须等于 $\\|r_0\\|_2$。这意味着最优校正步长为零，即 $\\alpha_{\\text{opt}} = 0$。从 $\\alpha_{\\text{opt}}$ 的表达式来看，这种情况的发生当且仅当分子为零：\n$$r_0^T A r_0 = 0$$\n这是 GMRES 在第一次迭代时停滞的基本条件。它表示定义了残差校正搜索方向的向量 $A r_0$ 与初始残差 $r_0$ 正交。因此，通过减去 $A r_0$ 的倍数无法消除 $r_0$ 的任何分量，其范数保持不变。\n\n现在，我们验证情况 A 中提供的具体构造。给定：\n$$\nA = \\begin{bmatrix}\n0 & 1 & 0 & 0\\\\\n-1 & 0 & 0 & 0\\\\\n0 & 0 & 0 & 2\\\\\n0 & 0 & -2 & 0\n\\end{bmatrix}, \\quad\nb = \\begin{bmatrix} 1\\\\ 2\\\\ 3\\\\ 4 \\end{bmatrix}, \\quad\nx_0 = \\begin{bmatrix} 0\\\\ 0\\\\ 0\\\\ 0 \\end{bmatrix}\n$$\n当 $x_0 = 0$ 时，初始残差为 $r_0 = b - A x_0 = b$。我们必须检查是否 $b^T A b = 0$。\n首先，我们计算乘积 $A b$：\n$$A b = \\begin{bmatrix}\n0 & 1 & 0 & 0\\\\\n-1 & 0 & 0 & 0\\\\\n0 & 0 & 0 & 2\\\\\n0 & 0 & -2 & 0\n\\end{bmatrix}\n\\begin{bmatrix} 1\\\\ 2\\\\ 3\\\\ 4 \\end{bmatrix} =\n\\begin{bmatrix} 2\\\\ -1\\\\ 8\\\\ -6 \\end{bmatrix}$$\n接下来，我们计算点积 $b^T (A b)$：\n$$b^T A b = \\begin{bmatrix} 1 & 2 & 3 & 4 \\end{bmatrix}\n\\begin{bmatrix} 2\\\\ -1\\\\ 8\\\\ -6 \\end{bmatrix} = (1)(2) + (2)(-1) + (3)(8) + (4)(-6) = 2 - 2 + 24 - 24 = 0$$\n停滞条件得以满足。\n\n该问题还要求论证 $A$ 是非对称且非奇异的。\n非对称性：$A$ 的转置是\n$$A^T = \\begin{bmatrix}\n0 & -1 & 0 & 0\\\\\n1 & 0 & 0 & 0\\\\\n0 & 0 & 0 & -2\\\\\n0 & 0 & 2 & 0\n\\end{bmatrix}$$\n由于 $A^T = -A$ 且 $A \\neq 0$，所以 $A$ 是斜对称的，因此也是非对称的。\n非奇异性：矩阵 $A$ 是块对角矩阵，$A = \\operatorname{diag}(A_1, A_2)$，其中\n$$A_1 = \\begin{bmatrix} 0 & 1\\\\ -1 & 0 \\end{bmatrix} \\quad \\text{和} \\quad A_2 = \\begin{bmatrix} 0 & 2\\\\ -2 & 0 \\end{bmatrix}$$\n行列式为 $\\det(A) = \\det(A_1) \\det(A_2)$。我们有 $\\det(A_1) = (0)(0) - (1)(-1) = 1$ 和 $\\det(A_2) = (0)(0) - (2)(-2) = 4$。\n因此，$\\det(A) = 1 \\cdot 4 = 4$。由于 $\\det(A) \\neq 0$，矩阵 $A$ 是非奇异的，线性系统 $A x = b$ 有唯一解。\n\nGMRES 的实现将基于用于构造 Krylov 子空间标准正交基的 Arnoldi 过程。为了在不显式构造迭代解 $x_k$ 的情况下追踪每一步 $k$ 的残差范数，我们求解关于 $y_k$ 的 $(k+1) \\times k$ 最小二乘问题，该问题最小化 $\\|\\beta e_1 - \\bar{H}_k y_k\\|_2$，其中 $\\beta = \\|r_0\\|_2$，$\\bar{H}_k$ 是由 Arnoldi 过程生成的上海森堡矩阵。通过应用一系列 Givens 旋转将 $\\bar{H}_k$ 转换为上三角形式，并更新相应的右端向量，可以高效地执行此最小化过程。残差范数 $\\|r_k\\|_2$ 随后就是变换后右端向量第 $(k+1)$ 个分量的绝对值。这种方法在数值上是稳定的，在计算上是高效的。然后通过将连续的残差范数与指定的容差 $\\tau = 10^{-12} \\|r_0\\|_2 + 10^{-15}$ 进行比较来确定停滞序列的长度。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_stagnation_streak(A, b, x0, k_max):\n    \"\"\"\n    Computes the initial stagnation streak for GMRES.\n\n    Implements unrestarted GMRES using the Arnoldi process with Modified\n    Gram-Schmidt and Givens rotations to track the residual norm.\n\n    Args:\n        A (np.ndarray): The n x n coefficient matrix.\n        b (np.ndarray): The n-dimensional right-hand side vector.\n        x0 (np.ndarray): The n-dimensional initial guess.\n        k_max (int): The maximum number of iterations.\n\n    Returns:\n        int: The length of the initial stagnation streak.\n    \"\"\"\n    n = A.shape[0]\n    r0 = b - A @ x0\n    r0_norm = np.linalg.norm(r0)\n\n    # If the initial guess is the solution, no iterations are needed.\n    if r0_norm < 1e-15:\n        return 0\n\n    tol = 1e-12 * r0_norm + 1e-15\n\n    V = np.zeros((n, k_max + 1))\n    H = np.zeros((k_max + 1, k_max))\n    \n    res_hist = [r0_norm]\n    \n    # Initialize Arnoldi process\n    V[:, 0] = r0 / r0_norm\n\n    # Initialize Givens rotation data\n    C = np.zeros(k_max)  # Cosines\n    S = np.zeros(k_max)  # Sines\n    g = np.zeros(k_max + 1) # Transformed RHS vector for LS problem\n    g[0] = r0_norm\n\n    for k in range(k_max):\n        # Arnoldi step (Modified Gram-Schmidt)\n        w = A @ V[:, k]\n        for j in range(k + 1):\n            H[j, k] = V[:, j].T @ w\n            w = w - H[j, k] * V[:, j]\n        \n        H[k + 1, k] = np.linalg.norm(w)\n        \n        # Check for lucky breakdown (exact convergence)\n        if H[k + 1, k] < 1e-15:\n            # We don't need to normalize V[:, k+1] if we stop.\n            # Residual is zero, so fill remaining history.\n            for _ in range(k, k_max):\n                res_hist.append(0.0)\n            break\n\n        V[:, k + 1] = w / H[k + 1, k]\n\n        # Apply previous k Givens rotations to the new column of H\n        h_col = H[:k+2, k]\n        for j in range(k):\n            c_j, s_j = C[j], S[j]\n            h_j_k = c_j * h_col[j] + s_j * h_col[j+1]\n            h_jp1_k = -s_j * h_col[j] + c_j * h_col[j+1]\n            h_col[j], h_col[j+1] = h_j_k, h_jp1_k\n        \n        # Compute and store the new Givens rotation\n        # It's meant to zero-out the H[k+1, k] element\n        h_kk, h_kp1k = h_col[k], h_col[k+1]\n        rot_r = np.sqrt(h_kk**2 + h_kp1k**2)\n        if rot_r == 0:\n            c_new, s_new = 1.0, 0.0\n        else:\n            c_new = h_kk / rot_r\n            s_new = h_kp1k / rot_r\n        C[k], S[k] = c_new, s_new\n\n        # Apply the new rotation to the LS right-hand side vector g\n        g_k = g[k]\n        g[k] = c_new * g_k # g[k+1] is 0 before this rotation\n        g[k+1] = -s_new * g_k\n\n        # The new residual norm is the magnitude of the last element of g\n        res_k_norm = np.abs(g[k+1])\n        res_hist.append(res_k_norm)\n\n    # Calculate the initial stagnation streak s\n    s = 0\n    for j in range(1, len(res_hist)):\n        if np.abs(res_hist[j] - res_hist[j-1]) <= tol:\n            s += 1\n        else:\n            break\n            \n    return s\n\n\ndef solve():\n    \"\"\"\n    Defines test cases and runs the GMRES stagnation analysis.\n    \"\"\"\n    x0 = np.array([0., 0., 0., 0.])\n    b = np.array([1., 2., 3., 4.])\n    k_max = 4\n\n    # Case A: Designed stagnation\n    A_A = np.array([\n        [0., 1., 0., 0.],\n        [-1., 0., 0., 0.],\n        [0., 0., 0., 2.],\n        [0., 0.,-2., 0.]\n    ])\n\n    # Case B: No stagnation expected\n    A_B = np.array([\n        [4., 1., 0., 0.],\n        [0., 4., 1., 0.],\n        [0., 0., 4., 1.],\n        [0., 0., 0., 4.]\n    ])\n\n    # Case C: Perturbed stagnation case\n    epsilon = 1e-6\n    A_C = A_A + epsilon * np.eye(4)\n    \n    test_cases = [\n        (A_A, b, x0, k_max),\n        (A_B, b, x0, k_max),\n        (A_C, b, x0, k_max)\n    ]\n\n    results = []\n    for case in test_cases:\n        result = compute_stagnation_streak(*case)\n        results.append(result)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2397339"}]}