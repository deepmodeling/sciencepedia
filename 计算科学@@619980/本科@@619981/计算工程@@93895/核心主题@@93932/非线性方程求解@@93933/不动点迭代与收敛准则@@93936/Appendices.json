{"hands_on_practices": [{"introduction": "本练习聚焦于一种设计快速收敛不动点格式的强大技术。你将学习如何通过调整迭代函数 $g(x)$ 来实现二次收敛，这是一种例如牛顿法等高效算法所特有的收敛速度。通过将松弛形式 $g(x) = x - \\alpha f(x)$ 中的参数 $\\alpha$ 与函数 $f(x)$ 在根处的一阶导数联系起来，你将深刻理解数值算法的构造原理 [@problem_id:2393364]。", "problem": "在计算工程中，不动点迭代是求解源于控制方程离散化所产生的非线性代数方程的基本方法。考虑如下标量非线性方程\n$$\nf(x) = x^{3} - 6x^{2} + 11x - 6 = 0\n$$\n该方程在 $x = 1$、$x = 2$ 和 $x = 3$ 处有三个单实根。对每个根 $r_{k} \\in \\{1, 2, 3\\}$，构造一个松弛形式的不动点迭代\n$$\nx_{n+1} = g_{k}(x_{n}), \\quad g_{k}(x) = x - \\alpha_{k}\\, f(x)\n$$\n其中常数参数 $\\alpha_{k}$ 的选择应使迭代对于目标根 $r_{k}$ 至少具有局部二次收敛阶。然后，确定分别对应于 $r_{1} = 1$、$r_{2} = 2$ 和 $r_{3} = 3$ 的 $\\alpha_{1}$、$\\alpha_{2}$ 和 $\\alpha_{3}$ 的精确值，并计算\n$$\nS = \\alpha_{1} + \\alpha_{2} + \\alpha_{3}\n$$\n请给出 $S$ 的单一精确值。无需四舍五入。", "solution": "在尝试求解之前，需对问题陈述进行验证。\n\n步骤1：提取已知条件。\n提供的已知信息如下：\n- 非线性标量方程为 $f(x) = x^{3} - 6x^{2} + 11x - 6 = 0$。\n- 该方程有三个单实根：$r_{1} = 1$，$r_{2} = 2$ 和 $r_{3} = 3$。\n- 为每个根 $r_{k}$ 给定了一个不动点迭代格式：$x_{n+1} = g_{k}(x_{n})$。\n- 迭代函数以松弛形式定义：$g_{k}(x) = x - \\alpha_{k}\\, f(x)$。\n- 参数 $\\alpha_{k}$ 的选择必须使迭代对相应的根 $r_{k}$ 至少具有局部二次收敛阶。\n- 目标是计算总和 $S = \\alpha_{1} + \\alpha_{2} + \\alpha_{3}$。\n\n步骤2：使用提取的已知条件进行验证。\n评估问题的有效性：\n- **科学依据：** 该问题根植于数值方法的基本理论，特别是不动点迭代及其收敛准则。收敛阶（线性、二次等）的概念是计算科学与工程中的一个标准课题。该问题在科学上是合理的。\n- **适定性：** 该问题提供了明确的目标和充分的信息。“至少二次收敛阶”的条件对迭代函数的导数施加了一个特定的数学约束，这使得每个参数 $\\alpha_{k}$ 都能被唯一确定。该问题是适定的。\n- **客观性：** 该问题使用精确的数学语言陈述，没有歧义、主观性或个人观点。\n\n该问题不存在科学不合理、不完整、矛盾或歧义等任何缺陷。这是一个数值分析中的标准、可形式化的问题。\n\n步骤3：结论与操作。\n问题被判定为有效。将推导其解。\n\n问题的核心在于分析不动点迭代 $x_{n+1} = g(x_{n})$ 的收敛速率。如果根 $r$ 是 $g(x)$ 的一个不动点（即 $g(r) = r$），并且迭代函数在 $r$ 的一个邻域内是压缩映射，则不动点迭代收敛于根 $r$。收敛阶由迭代函数 $g(x)$ 在不动点 $r$ 处的导数值确定。\n\n为使迭代具有至少局部二次收敛阶，迭代函数的一阶导数在不动点处必须为零，即 $g'(r) = 0$。如果此条件得到满足，$g(x)$ 在 $r$ 附近的泰勒级数展开为：\n$$\ng(x) = g(r) + g'(r)(x-r) + \\frac{g''(r)}{2!}(x-r)^{2} + O((x-r)^{3})\n$$\n当 $g(r)=r$ 和 $g'(r)=0$ 时，上式变为：\n$$\ng(x) - r = \\frac{g''(r)}{2}(x-r)^{2} + O((x-r)^{3})\n$$\n令 $e_{n} = x_{n} - r$ 为第 $n$ 次迭代的误差。则 $x_{n} = r + e_{n}$，且 $x_{n+1} = g(x_{n})$。\n$$\ne_{n+1} = x_{n+1} - r = g(x_{n}) - r = g(r + e_{n}) - r = \\frac{g''(r)}{2} e_{n}^{2} + O(e_{n}^{3})\n$$\n这种第 $n+1$ 步的误差与第 $n$ 步误差的平方成正比的关系，即为二次收敛的定义，前提是 $g''(r) \\neq 0$。“至少二次”的条件要求 $g'(r)=0$。\n\n对于每个根 $r_k$，迭代函数为 $g_{k}(x) = x - \\alpha_{k} f(x)$。首先，我们确认每个根 $r_k$ 都是 $g_k(x)$ 的一个不动点。根据定义，$f(r_k) = 0$，因此 $g_{k}(r_{k}) = r_{k} - \\alpha_{k} f(r_{k}) = r_{k} - \\alpha_{k}(0) = r_{k}$。这对任意 $\\alpha_k$ 的选择都成立。\n\n为确保至少二次收敛，我们必须强制执行条件 $g_{k}'(r_{k}) = 0$。我们首先计算 $g_{k}(x)$ 的导数：\n$$\ng_{k}'(x) = \\frac{d}{dx} \\left( x - \\alpha_{k} f(x) \\right) = 1 - \\alpha_{k} f'(x)\n$$\n将该导数在根 $r_{k}$ 处求值并令其等于零，可得：\n$$\ng_{k}'(r_{k}) = 1 - \\alpha_{k} f'(r_{k}) = 0\n$$\n对 $\\alpha_{k}$ 求解，我们发现所需的值为：\n$$\n\\alpha_{k} = \\frac{1}{f'(r_{k})}\n$$\n这假设 $f'(r_k) \\neq 0$，根据题意，对于单根这是成立的。\n\n接下来，我们必须计算给定函数 $f(x) = x^{3} - 6x^{2} + 11x - 6$ 的导数：\n$$\nf'(x) = \\frac{d}{dx} \\left( x^{3} - 6x^{2} + 11x - 6 \\right) = 3x^{2} - 12x + 11\n$$\n现在我们可以为三个根中的每一个计算 $\\alpha_k$ 的值。\n\n对于根 $r_{1} = 1$：\n$$\nf'(1) = 3(1)^{2} - 12(1) + 11 = 3 - 12 + 11 = 2\n$$\n因此，参数 $\\alpha_{1}$ 为：\n$$\n\\alpha_{1} = \\frac{1}{f'(1)} = \\frac{1}{2}\n$$\n\n对于根 $r_{2} = 2$：\n$$\nf'(2) = 3(2)^{2} - 12(2) + 11 = 3(4) - 24 + 11 = 12 - 24 + 11 = -1\n$$\n因此，参数 $\\alpha_{2}$ 为：\n$$\n\\alpha_{2} = \\frac{1}{f'(2)} = \\frac{1}{-1} = -1\n$$\n\n对于根 $r_{3} = 3$：\n$$\nf'(3) = 3(3)^{2} - 12(3) + 11 = 3(9) - 36 + 11 = 27 - 36 + 11 = 2\n$$\n因此，参数 $\\alpha_{3}$ 为：\n$$\n\\alpha_{3} = \\frac{1}{f'(3)} = \\frac{1}{2}\n$$\n\n最后，问题要求计算总和 $S = \\alpha_{1} + \\alpha_{2} + \\alpha_{3}$：\n$$\nS = \\frac{1}{2} + (-1) + \\frac{1}{2} = 1 - 1 = 0\n$$\n$S$ 的值恰好为 $0$。", "answer": "$$\\boxed{0}$$", "id": "2393364"}, {"introduction": "迭代函数 $g(x)$ 的选择不仅影响收敛速度，还决定了哪些初始猜测值能够成功找到解。这个实践性的编程练习将让你探索同一个方程不同不动点重排形式的吸引盆（basins of attraction）概念。通过实现和比较这些格式，你将具体地理解为何某些方法比其他方法更具鲁棒性，以及局部收敛准则如何转化为全局行为 [@problem_id:2393371]。", "problem": "您的任务是编写一个完整的程序，用于比较将标量非线性方程 $e^{x} - 4x = 0$ 变换为不同 $x = g(x)$ 形式后，不动点迭代法的收敛行为和吸引盆。该程序必须是确定性的，并且不得要求任何用户输入。\n\n请基于以下基本概念开始：\n- 函数 $g$ 的不动点定义：一个点 $x^{\\star}$，满足 $x^{\\star} = g(x^{\\star})$。\n- 不动点迭代：给定一个初始猜测值 $x_0$，生成序列 $x_{k+1} = g(x_k)$。\n- 根据 Banach不动点定理（也称为压缩映射原理）的不动点迭代充分局部收敛判据：如果 $g$ 连续可微，并且在不动点 $x^{\\star}$ 的某个邻域内存在 $\\lvert g'(x) \\rvert \\leq q < 1$，那么对于该邻域内的任何初始值 $x_0$，迭代 $x_{k+1} = g(x_k)$ 都会收敛到 $x^{\\star}$。\n\n您的程序需要完成以下任务：\n1. 实现非线性函数 $f(x) = e^{x} - 4x$ 及其导数 $f'(x) = e^{x} - 4$。\n2. 实现以下三个不动点映射 $g$：\n   - $g_{\\mathrm{A}}(x) = \\dfrac{e^{x}}{4}$，定义域为所有实数 $x$。\n   - $g_{\\mathrm{B}}(x) = \\ln(4x)$，仅当 $x > 0$ 时有定义。\n   - $g_{\\mathrm{N}}(x) = x - \\dfrac{f(x)}{f'(x)}$ （写成不动点映射形式的 Newton 法），当 $f'(x) \\neq 0$ 时有定义。\n3. 对于每个不动点映射，实现迭代 $x_{k+1} = g(x_k)$，并遵循以下终止与失败判据：\n   - 如果满足 $\\lvert x_{k+1} - x_k \\rvert \\leq \\varepsilon_x$ 或 $\\lvert f(x_{k+1}) \\rvert \\leq \\varepsilon_f$ 之一，则判定为收敛，其中 $\\varepsilon_x = 10^{-12}$ 且 $\\varepsilon_f = 10^{-12}$。\n   - 如果发生以下任何一种情况，则判定为失败：\n     - 下一个迭代值超出了映射的定义域（例如，对于 $g_{\\mathrm{B}}$，在任何一步中 $x_k \\leq 0$）。\n     - 在任何一步中产生了非有限值（非数字或无穷大）。\n     - 在未收敛的情况下达到了最大迭代次数 $N_{\\max} = 200$。\n     - 对于 $g_{\\mathrm{N}}$，在任何一步中导数的绝对值 $\\lvert f'(x_k) \\rvert$ 低于阈值 $\\tau = 10^{-12}$，导致更新是病态的。\n4. 计算高精度参考根用于分类。方程 $f(x) = 0$ 恰好有两个实数根：一个在区间 $[0, 0.5]$ 内，另一个在区间 $[2, 3]$ 内。使用一种稳健的区间求根方法（例如，二分法或 Brent 法）计算参考值 $r_1 \\in [0, 0.5]$ 和 $r_2 \\in [2, 3]$，绝对精度至少为 $10^{-14}$。\n5. 吸引盆分类：对于一个收敛的迭代值 $x^{\\star}$，根据其与两个参考根的邻近度，按以下规则进行分类：\n   - 如果 $\\lvert x^{\\star} - r_1 \\rvert \\leq 10^{-8}$，则指定整数 $0$。\n   - 如果 $\\lvert x^{\\star} - r_2 \\rvert \\leq 10^{-8}$，则指定整数 $1$。\n   - 否则指定整数 $-1$。\n   - 对于失败的迭代，指定整数 $-1$。\n6. 使用以下 $(g,\\ x_0)$ 对组成的测试套件，以探测不同的吸引盆、边界情况和定义域：\n   - $(g_{\\mathrm{A}},\\ x_0 = -1.0)$\n   - $(g_{\\mathrm{A}},\\ x_0 = 0.1)$\n   - $(g_{\\mathrm{A}},\\ x_0 = 0.6)$\n   - $(g_{\\mathrm{A}},\\ x_0 = 2.5)$\n   - $(g_{\\mathrm{B}},\\ x_0 = 0.2)$\n   - $(g_{\\mathrm{B}},\\ x_0 = 2.5)$\n   - $(g_{\\mathrm{B}},\\ x_0 = 1.0)$\n   - $(g_{\\mathrm{B}},\\ x_0 = -0.5)$\n   - $(g_{\\mathrm{N}},\\ x_0 = -1.0)$\n   - $(g_{\\mathrm{N}},\\ x_0 = 0.5)$\n   - $(g_{\\mathrm{N}},\\ x_0 = 4.0)$\n   - $(g_{\\mathrm{N}},\\ x_0 = \\ln 4)$\n7. 输出规范：您的程序应生成单行输出，其中包含测试套件的分类结果。结果应与上面列出的顺序相同，形式为一个由方括号括起来的、用逗号分隔的整数列表（例如，`[0,0,1,-1]`）。不应打印任何额外文本。\n\n重要说明：\n- 本问题不涉及角度，因此不需要角度单位。\n- 不涉及物理单位。\n- 通过严格应用上述定义域检查和失败判据，确保数值稳健性。", "solution": "该问题陈述已经过严格验证，被认为是合理的。这是一个计算工程领域的适定问题，其基础是数值分析的既定原理，特别是不动点迭代理论和 Newton 法。所有参数、函数和判据都以足够的精度定义，能够得出一个唯一的、确定性的解。我们继续进行解的分析与推导。\n\n目标是分析三种不同的不动点迭代方案在求解非线性方程 $f(x) = e^{x} - 4x = 0$ 的根时的收敛性。\n\n**1. 高精度根的确定**\n\n方程 $f(x) = 0$ 等价于求 $y = e^x$ 和 $y = 4x$ 的交点。图像分析显示存在两个实数根。问题陈述正确地指出了包含这些根的区间。为进行验证，我们在区间边界处计算 $f(x)$ 的值：\n- 对于区间 $[0, 0.5]$：\n  $f(0) = e^{0} - 4(0) = 1 > 0$。\n  $f(0.5) = e^{0.5} - 4(0.5) = \\sqrt{e} - 2 \\approx 1.6487 - 2 = -0.3513 < 0$。\n- 对于区间 $[2, 3]$：\n  $f(2) = e^{2} - 4(2) = e^2 - 8 \\approx 7.3891 - 8 = -0.6109 < 0$。\n  $f(3) = e^{3} - 4(3) = e^3 - 12 \\approx 20.0855 - 12 = 8.0855 > 0$。\n\n由于 $f(x)$ 是连续的，根据介值定理，可以保证每个区间内都存在一个根。我们将这些根记为 $r_1 \\in [0, 0.5]$ 和 $r_2 \\in [2, 3]$。为了作为分类的基准，这些根将使用一种稳健的数值方法（特别是适用于此目的的 Brent 法）计算到高精度（绝对容差至少为 $10^{-14}$）。\n\n**2. 不动点映射的收敛性分析**\n\n不动点迭代 $x_{k+1} = g(x_k)$ 是否收敛到不动点 $x^{\\star}$，取决于迭代映射在不动点处导数的绝对值 $\\lvert g'(x^{\\star}) \\rvert$。对于局部收敛，$\\lvert g'(x^{\\star}) \\rvert < 1$ 是充分条件。如果 $\\lvert g'(x^{\\star}) \\rvert > 1$，则该不动点是排斥的，迭代将会发散。如果 $\\lvert g'(x^{\\star}) \\rvert = 1$，则该判据无定论，需要进行更详细的分析。\n\n根据定义，$f(x)=0$ 的根 $r_1$ 和 $r_2$ 是任何有效变换形式 $x=g(x)$ 的不动点。在这些点上，$e^{x^\\star} = 4x^\\star$。\n\n- **映射 A**：$g_{\\mathrm{A}}(x) = \\dfrac{e^x}{4}$。\n  其导数是 $g'_{\\mathrm{A}}(x) = \\dfrac{e^x}{4}$。\n  - 在第一个根 $r_1$ 处：$g'_{\\mathrm{A}}(r_1) = \\dfrac{e^{r_1}}{4} = \\dfrac{4r_1}{4} = r_1$。从数值上看，$r_1 \\approx 0.3574$。因此，$\\lvert g'_{\\mathrm{A}}(r_1) \\rvert \\approx 0.3574 < 1$。不动点 $r_1$ 是吸引的。\n  - 在第二个根 $r_2$ 处：$g'_{\\mathrm{A}}(r_2) = \\dfrac{e^{r_2}}{4} = \\dfrac{4r_2}{4} = r_2$。从数值上看，$r_2 \\approx 2.1533$。因此，$\\lvert g'_{\\mathrm{A}}(r_2) \\rvert \\approx 2.1533 > 1$。不动点 $r_2$ 是排斥的。\n  因此，如果初始值足够近，$g_{\\mathrm{A}}(x)$ 的迭代预期会收敛到 $r_1$，并从 $r_2$ 的邻域发散。\n\n- **映射 B**：$g_{\\mathrm{B}}(x) = \\ln(4x)$，定义域为 $x > 0$。\n  其导数是 $g'_{\\mathrm{B}}(x) = \\dfrac{1}{4x} \\cdot 4 = \\dfrac{1}{x}$。\n  - 在第一个根 $r_1$ 处：$\\lvert g'_{\\mathrm{B}}(r_1) \\rvert = \\dfrac{1}{r_1} \\approx \\dfrac{1}{0.3574} \\approx 2.798 > 1$。不动点 $r_1$ 是排斥的。\n  - 在第二个根 $r_2$ 处：$\\lvert g'_{\\mathrm{B}}(r_2) \\rvert = \\dfrac{1}{r_2} \\approx \\dfrac{1}{2.1533} \\approx 0.4644 < 1$。不动点 $r_2$ 是吸引的。\n  该映射表现出与 $g_{\\mathrm{A}}(x)$ 互补的行为。迭代预期会收敛到 $r_2$ 并从 $r_1$ 发散。\n\n- **映射 N (Newton 法)**：$g_{\\mathrm{N}}(x) = x - \\dfrac{f(x)}{f'(x)}$。\n  此处，$f(x) = e^x - 4x$ 且 $f'(x) = e^x - 4$。二阶导数是 $f''(x) = e^x$。\n  不动点映射的导数是 $g'_{\\mathrm{N}}(x) = \\dfrac{f(x)f''(x)}{(f'(x))^2}$。\n  在任何单根 $x^{\\star}$ 处（即 $f(x^{\\star}) = 0$ 且 $f'(x^{\\star}) \\neq 0$），其导数为 $g'_{\\mathrm{N}}(x^{\\star}) = 0$。\n  对于我们的问题，$f'(r_1) = e^{r_1} - 4 = 4r_1 - 4 \\neq 0$ 且 $f'(r_2) = e^{r_2} - 4 = 4r_2 - 4 \\neq 0$，所以两个根都是单根。\n  条件 $g'_{\\mathrm{N}}(x^{\\star}) = 0$ 意味着二次收敛，这是非常快的。对于 Newton 法而言，$r_1$ 和 $r_2$ 都是超吸引不动点。如果迭代遇到 $f'(x) = 0$ 的点，即 $x = \\ln(4)$，则会失败。该点对应于 $f(x)$ 的局部极小值点。\n\n**3. 算法实现与执行**\n\n解决方案将通过一个 Python 程序实现，遵循结构化的、确定性的过程。\n1.  **初始化**：定义所有常量：收敛容差 $\\varepsilon_x = 10^{-12}$ 和 $\\varepsilon_f = 10^{-12}$，最大迭代次数 $N_{\\max} = 200$，Newton 法的导数阈值 $\\tau = 10^{-12}$，以及分类容差 $10^{-8}$。\n2.  **参考根计算**：使用 `scipy.optimize.brentq` 计算根 $r_1$ 和 $r_2$，其精度高于问题要求。\n3.  **函数定义**：实现函数 $f(x)$、$f'(x)$、$g_{\\mathrm{A}}(x)$、$g_{\\mathrm{B}}(x)$ 和 $g_{\\mathrm{N}}(x)$。按照规定，$g_{\\mathrm{B}}$ 和 $g_{\\mathrm{N}}$ 的实现包含内部检查，用于在发生定义域违规（对于 $g_{\\mathrm{B}}$，$x_k \\leq 0$）或病态更新（对于 $g_{\\mathrm{N}}$，$\\lvert f'(x_k) \\rvert < \\tau$）时引发异常。\n4.  **迭代求解器**：一个主函数执行不动点迭代 $x_{k+1} = g(x_k)$，针对给定的映射 $g$ 和初始猜测值 $x_0$。此函数最多运行 $N_{\\max}$ 步。在每一步中，它使用判据 $\\lvert x_{k+1} - x_k \\rvert \\leq \\varepsilon_x$ 或 $\\lvert f(x_{k+1}) \\rvert \\leq \\varepsilon_f$ 检查收敛性。它还处理由非有限结果或映射函数引发的异常导致的失败。该函数返回一个状态（'converged' 或 'failed'）和最终迭代值。\n5.  **分类**：一个独立的分类函数接收求解器的输出。如果状态为'failed'，则返回 $-1$。如果为 'converged'，它将最终迭代值 $x^{\\star}$ 与参考根 $r_1$ 和 $r_2$ 进行比较，使用 $\\lvert x^{\\star} - r \\rvert \\leq 10^{-8}$ 判据，并相应地返回 $0$、$1$ 或 $-1$。\n6.  **测试套件执行**：程序遍历所提供的测试用例列表。对于每对 $(g, x_0)$，它调用求解器和分类器，并处理初始猜测值已在映射定义域之外的边界情况（例如，对于 $g_{\\mathrm{B}}$，$x_0 \\leq 0$）。\n7.  **最终输出**：将整数分类结果收集到一个列表中，并以指定格式 `[c_1,c_2,...,c_N]` 打印。\n\n这种系统化的方法确保了所有问题要求都得到精确且稳健的满足。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import brentq\n\ndef solve():\n    \"\"\"\n    Solves the given problem by comparing fixed-point iterations for f(x) = e^x - 4x = 0.\n    \"\"\"\n    # Define problem parameters\n    EPS_X = 1e-12\n    EPS_F = 1e-12\n    MAX_ITER = 200\n    DERIV_THRESHOLD = 1e-12\n    CLASSIFICATION_TOL = 1e-8\n    ROOT_FINDING_TOL = 1e-15\n\n    # Task 1 & 4: Implement f(x) and compute high-accuracy reference roots.\n    # The nonlinear function f(x) = e^x - 4x.\n    def f(x):\n        try:\n            val = np.exp(x) - 4.0 * x\n        except OverflowError:\n            val = np.inf\n        return val\n\n    # Its derivative f'(x) = e^x - 4.\n    def f_prime(x):\n        try:\n            val = np.exp(x) - 4.0\n        except OverflowError:\n            val = np.inf\n        return val\n\n    # Use a robust bracketed method to find reference roots r1 and r2.\n    r1 = brentq(f, 0.0, 0.5, xtol=ROOT_FINDING_TOL)\n    r2 = brentq(f, 2.0, 3.0, xtol=ROOT_FINDING_TOL)\n\n    # Task 2: Implement the three fixed-point maps.\n    # g_A(x) = e^x / 4\n    def g_A(x):\n        return np.exp(x) / 4.0\n\n    # g_B(x) = ln(4x), defined for x > 0.\n    def g_B(x):\n        if x <= 0:\n            raise ValueError(\"Domain error for g_B: x must be > 0.\")\n        return np.log(4.0 * x)\n\n    # g_N(x) = x - f(x)/f'(x) (Newton's method).\n    def g_N(x):\n        f_prime_val = f_prime(x)\n        if abs(f_prime_val) < DERIV_THRESHOLD:\n            raise ValueError(\"Derivative near zero for g_N.\")\n        return x - f(x) / f_prime_val\n\n    g_map = {'A': g_A, 'B': g_B, 'N': g_N}\n\n    # Task 3 & 5: Implement the iteration and classification logic.\n    def run_iteration_and_classify(g_name, x0):\n        # Handle cases where initial guess is invalid.\n        if g_name == 'B' and x0 <= 0:\n            return -1\n        if g_name == 'N' and abs(f_prime(x0)) < DERIV_THRESHOLD:\n            return -1\n\n        g_func = g_map[g_name]\n        x_k = x0\n\n        for _ in range(MAX_ITER):\n            try:\n                x_k_plus_1 = g_func(x_k)\n            except (ValueError, OverflowError):\n                # Catches domain errors from g_B, derivative error from g_N,\n                # and overflow in exp().\n                return -1\n\n            # Check for failure due to non-finite values.\n            if not np.isfinite(x_k_plus_1):\n                return -1\n\n            # Check for convergence.\n            converged_x_step = abs(x_k_plus_1 - x_k) <= EPS_X\n            converged_f_val = abs(f(x_k_plus_1)) <= EPS_F\n            \n            if converged_x_step or converged_f_val:\n                x_star = x_k_plus_1\n                # Classify the converged root.\n                if abs(x_star - r1) <= CLASSIFICATION_TOL:\n                    return 0\n                elif abs(x_star - r2) <= CLASSIFICATION_TOL:\n                    return 1\n                else:\n                    return -1 # Converged to a non-target or with insufficient precision for classification\n            \n            x_k = x_k_plus_1\n\n        # Failure due to reaching max iterations.\n        return -1\n\n    # Task 6: Define and run the test suite.\n    test_cases = [\n        ('A', -1.0),\n        ('A', 0.1),\n        ('A', 0.6),\n        ('A', 2.5),\n        ('B', 0.2),\n        ('B', 2.5),\n        ('B', 1.0),\n        ('B', -0.5), # Fails on initial condition\n        ('N', -1.0),\n        ('N', 0.5),\n        ('N', 4.0),\n        ('N', np.log(4.0)) # Fails on initial condition\n    ]\n\n    results = []\n    for g_name, x0 in test_cases:\n        result = run_iteration_and_classify(g_name, x0)\n        results.append(result)\n\n    # Task 7: Output a single line in the specified format.\n    print(f\"[{','.join(map(str, results))}]\")\n\n# Execute the main function.\nsolve()\n```", "id": "2393371"}, {"introduction": "让我们将所学知识应用于流体力学中的一个经典问题：求解用于计算管道摩擦系数的隐式 Colebrook-White 方程。这项动手编程任务要求你不仅实现标准的不动点迭代，还要实现一种强大的加速技术——Steffensen 方法。通过在一个真实的工程公式上比较它们的性能，你将体会到先进数值方法对计算效率的实际影响 [@problem_id:2393339]。", "problem": "考虑用于圆管内完全湍流的达西摩擦因子，记为 $f$。隐式的 Colebrook-White 关系式为给定的雷诺数 $Re$（无量纲）和相对粗糙度 $k$（无量纲）定义了 $f$，如下所示\n$$\n\\frac{1}{\\sqrt{f}} = -2 \\log_{10}\\!\\left(\\frac{k}{3.7} + \\frac{2.51}{Re \\sqrt{f}}\\right).\n$$\n此处 $\\log_{10}$ 表示以 10 为底的对数，$Re \\ge 4000$ 且 $k \\ge 0$。未知数 $f$ 是无量纲的，且为严格正值。\n\n编写一个完整、可运行的程序，对下文列出的每个测试用例，使用两种方法计算 Colebrook-White 关系式唯一的物理相关根 $f$：\n- 将标准不动点迭代法应用于该隐式方程的一个数学上一致的不动点公式，以及\n- 将 Steffensen 加速法应用于同一不动点映射。\n\n对于每种方法和每个测试用例，都需生成：\n- 收敛的 $f$ 值，四舍五入至 $12$ 位小数，\n- 所用的总迭代步数（整数），以及\n- 执行的不动点映射求值总次数（整数）。\n\n两种方法均采用以下收敛和运行时控制条件：\n- 对连续摩擦因子估计值的绝对差准则：当 $|f_{n+1} - f_n| < \\tau$ 时终止，其中 $\\tau = 10^{-12}$，\n- 对允许的迭代步数设置硬性上限：标准不动点法最多 $N_{\\max}^{(\\mathrm{std})} = 200$ 步，Steffensen 法最多 $N_{\\max}^{(\\mathrm{st})} = 100$ 步。\n\n测试套件（每对为 $(Re,k)$，均为无量纲）：\n- 用例 $1$：$(Re, k) = (4 \\times 10^{3}, 0)$，\n- 用例 $2$：$(Re, k) = (10^{5}, 10^{-4})$，\n- 用例 $3$：$(Re, k) = (10^{6}, 10^{-3})$，\n- 用例 $4$：$(Re, k) = (10^{7}, 5 \\times 10^{-3})$，\n- 用例 $5$：$(Re, k) = (5 \\times 10^{4}, 5 \\times 10^{-5})$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表。每个测试用例的结果应作为嵌套列表，按上述用例顺序排列。\n- 对于每个测试用例，嵌套列表的顺序必须为\n$[f_{\\mathrm{std}}, n_{\\mathrm{std}}, e_{\\mathrm{std}}, f_{\\mathrm{st}}, n_{\\mathrm{st}}, e_{\\mathrm{st}}]$，\n其中 $f_{\\mathrm{std}}$ 和 $f_{\\mathrm{st}}$ 是四舍五入到 12 位小数的摩擦因子，$n_{\\mathrm{std}}$ 和 $n_{\\mathrm{st}}$ 是迭代次数，$e_{\\mathrm{std}}$ 和 $e_{\\mathrm{st}}$ 是不动点映射求值次数。单行输出不得包含任何空白字符。例如：\n\"[ [0.020000000000,12,12,0.020000000000,4,8], ... ]\" （此示例仅为说明）。", "solution": "所述问题是有效的。它涉及 Colebrook-White 方程的数值求解，该方程是流体力学中一个公认的基本关系式，用于确定湍流管流中的摩擦因子。该问题具有科学依据，提法明确，且所有参数和条件都已清晰说明，能够得到唯一且可验证的解。\n\n任务是对于给定的雷诺数 $Re$ 和相对粗糙度 $k$，求解以下隐式方程的根 $f$：\n$$\n\\frac{1}{\\sqrt{f}} = -2 \\log_{10}\\!\\left(\\frac{k}{3.7} + \\frac{2.51}{Re \\sqrt{f}}\\right)\n$$\n这必须通过两种迭代数值方法来完成。\n\n**1. 不动点公式**\n为了应用不动点迭代，必须将方程重排为 $f = g(f)$ 的形式。通过将 $f$ 分离到等式左侧，可以推导出一个稳定且收敛的映射 $g(f)$。设 Colebrook-White 方程的右侧为 $A(f)$。\n$$\nA(f) = -2 \\log_{10}\\!\\left(\\frac{k}{3.7} + \\frac{2.51}{Re \\sqrt{f}}\\right)\n$$\n那么该方程为 $\\frac{1}{\\sqrt{f}} = A(f)$。求解 $f$ 可得：\n$$\n\\sqrt{f} = \\frac{1}{A(f)} \\implies f = \\left(\\frac{1}{A(f)}\\right)^2\n$$\n这给出了不动点映射函数 $g(f)$：\n$$\ng(f) = \\left(\\frac{1}{-2 \\log_{10}\\!\\left(\\frac{k}{3.7} + \\frac{2.51}{Re \\sqrt{f}}\\right)}\\right)^2\n$$\n相应的迭代格式为 $f_{n+1} = g(f_n)$，其中 $f_n$ 是第 $n$ 次迭代时摩擦因子的估计值。\n\n**2. 初始猜测值**\n开始迭代需要一个初始猜测值 $f_0$。一个稳健的 $f_0$ 选择可以从 Colebrook-White 方程的一个显式近似中获得。Haaland 方程提供了这样一个近似：\n$$\n\\frac{1}{\\sqrt{f_0}} \\approx -1.8 \\log_{10}\\!\\left(\\left(\\frac{k}{3.7}\\right)^{1.11} + \\frac{6.9}{Re}\\right)\n$$\n求解 $f_0$ 可以得到一个高质量的初始值，该值接近真实根，从而确保快速收敛。\n\n**3. 数值方案与收敛准则**\n\n**a) 标准不动点迭代**\n标准不动点迭代算法的流程如下：\n1.  从一个初始猜测值 $f_0$ 开始。\n2.  对于 $n = 0, 1, 2, \\ldots$，使用映射计算下一个估计值：$f_{n+1} = g(f_n)$。\n3.  当连续估计值之间的绝对差小于指定的容差 $\\tau = 10^{-12}$，即 $|f_{n+1} - f_n| < \\tau$ 时，过程终止。\n4.  迭代次数 $n_{\\mathrm{std}}$ 是计算映射 $f_{n+1} = g(f_n)$ 的总次数。\n5.  求值次数 $e_{\\mathrm{std}}$ 是调用函数 $g(f)$ 的总次数。对于此方法，$e_{\\mathrm{std}} = n_{\\mathrm{std}}$。该过程的迭代上限也设为 $N_{\\max}^{(\\mathrm{std})} = 200$。\n\n**b) Steffensen 方法**\nSteffensen 方法是一种加速技术，通常将不动点迭代的线性收敛转换为二次收敛。它使用底层不动点序列中的三个点来外推出一个更好的估计值。\n1.  从一个初始猜测值 $f_0$ 开始。\n2.  对于每一步 $n$：\n    a. 设当前估计值为 $p_0 = f_n$。\n    b. 使用映射 $g$ 生成两个中间值：$p_1 = g(p_0)$ 和 $p_2 = g(p_1)$。\n    c. 使用 Aitken's $\\Delta^2$ 公式计算加速后的更新值：\n    $$\n    f_{n+1} = p_0 - \\frac{(p_1 - p_0)^2}{p_2 - 2p_1 + p_0}\n    $$\n3.  终止条件基于相同的准则：$|f_{n+1} - f_n| < \\tau = 10^{-12}$。\n4.  上述一个完整周期构成 Steffensen 方法的一个迭代步。迭代次数为 $n_{\\mathrm{st}}$。\n5.  由于每步需要两次对映射函数 $g(f)$ 的求值，总求值次数为 $e_{\\mathrm{st}} = 2 \\times n_{\\mathrm{st}}$。该过程的迭代上限设为 $N_{\\max}^{(\\mathrm{st})} = 100$。\n\n实现过程将通过定义映射 $g(f)$、初始猜测值和两个迭代求解器的函数来进行。然后将这些函数应用于每个测试用例以生成所需的结果。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Colebrook-White equation for multiple test cases using both\n    standard fixed-point iteration and Steffensen's acceleration.\n    \"\"\"\n\n    # Test suite: each element is a tuple (Reynolds number, relative roughness)\n    test_cases = [\n        (4e3, 0.0),\n        (1e5, 1e-4),\n        (1e6, 1e-3),\n        (1e7, 5e-3),\n        (5e4, 5e-5),\n    ]\n\n    # Convergence and runtime controls\n    TOLERANCE = 1e-12\n    MAX_ITER_STD = 200\n    MAX_ITER_ST = 100\n\n    def g(f, Re, k):\n        \"\"\"\n        The fixed-point mapping function g(f) derived from the Colebrook-White equation.\n        \"\"\"\n        if f <= 0:\n            # Physically, f must be positive. This avoids domain errors.\n            return np.inf\n        \n        log_arg = k / 3.7 + 2.51 / (Re * np.sqrt(f))\n        \n        if log_arg <= 0:\n            # Argument to log10 must be positive.\n            return np.inf\n            \n        return (-2.0 * np.log10(log_arg))**-2.0\n\n    def haaland_initial_guess(Re, k):\n        \"\"\"\n        Calculates an initial guess for f using the Haaland equation.\n        \"\"\"\n        if Re < 4000:\n            # Haaland is for turbulent flow\n            return 64.0 / Re  # Laminar flow friction factor, as a fallback\n        \n        # Note: (k/3.7)**1.11 is safe since k >= 0\n        rhs = -1.8 * np.log10((k / 3.7)**1.11 + 6.9 / Re)\n        f0 = (1.0 / rhs)**2\n        return f0\n\n    def standard_fixed_point(Re, k, f_initial):\n        \"\"\"\n        Performs standard fixed-point iteration.\n        Returns: (converged_f, iteration_count, evaluation_count)\n        \"\"\"\n        f_n = f_initial\n        eval_count = 0\n        for i in range(1, MAX_ITER_STD + 1):\n            f_n_plus_1 = g(f_n, Re, k)\n            eval_count += 1\n            if abs(f_n_plus_1 - f_n) < TOLERANCE:\n                return f_n_plus_1, i, eval_count\n            f_n = f_n_plus_1\n        # Return last value if not converged\n        return f_n, MAX_ITER_STD, eval_count\n\n    def steffensen_method(Re, k, f_initial):\n        \"\"\"\n        Performs Steffensen's accelerated fixed-point iteration.\n        Returns: (converged_f, iteration_count, evaluation_count)\n        \"\"\"\n        f_n = f_initial\n        eval_count = 0\n        for i in range(1, MAX_ITER_ST + 1):\n            p0 = f_n\n            \n            p1 = g(p0, Re, k)\n            p2 = g(p1, Re, k)\n            eval_count += 2\n            \n            denominator = p2 - 2 * p1 + p0\n            \n            if abs(denominator) < 1e-20:  # Avoid division by zero, fallback to a standard step\n                f_n_plus_1 = p2\n            else:\n                f_n_plus_1 = p0 - (p1 - p0)**2 / denominator\n\n            if abs(f_n_plus_1 - f_n) < TOLERANCE:\n                return f_n_plus_1, i, eval_count\n            f_n = f_n_plus_1\n        # Return last value if not converged\n        return f_n, MAX_ITER_ST, eval_count\n\n    all_results_str = []\n    for Re, k in test_cases:\n        f0 = haaland_initial_guess(Re, k)\n        \n        # Standard Fixed-Point Iteration\n        f_std, n_std, e_std = standard_fixed_point(Re, k, f0)\n        \n        # Steffensen's Method\n        f_st, n_st, e_st = steffensen_method(Re, k, f0)\n        \n        # Format results for the current case\n        f_std_str = f\"{f_std:.12f}\"\n        f_st_str = f\"{f_st:.12f}\"\n        \n        case_str = f\"[{f_std_str},{n_std},{e_std},{f_st_str},{n_st},{e_st}]\"\n        all_results_str.append(case_str)\n        \n    # Final output string with no whitespace\n    final_output = f\"[{','.join(all_results_str)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "2393339"}]}