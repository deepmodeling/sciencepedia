{"hands_on_practices": [{"introduction": "理论分析是理解迭代法收敛速度的基础。本练习将引导你通过泰勒级数展开，对一个参数化迭代格式（King 方法族）进行严谨的数学推导，从而确定其收敛阶。这项实践有助于你掌握分析数值方法核心性能的基本技能，并理解高阶方法的设计原理。[@problem_id:2381957]", "problem": "考虑一个标量非线性方程 $f(x)=0$，它在 $x=\\alpha$ 处有一个单根，即 $f(\\alpha)=0$ 且 $f'(\\alpha)\\neq 0$。假设 $f$ 在 $\\alpha$ 的一个邻域内是三阶连续可微的。对于一个足够接近 $\\alpha$ 的初始猜测值 $x_0$，考虑以下单参数迭代法\n$$\nx_{k+1} \\;=\\; x_k \\;-\\; \\frac{f(x_k)}{f'(x_k)} \\;-\\; \\frac{f(x_k)^{2}\\,f''(x_k)}{2\\,f'(x_k)^{3}\\,\\bigl(1 + \\beta\\,f(x_k)/f'(x_k)\\bigr)},\n$$\n其中 $\\beta\\in\\mathbb{R}$ 是一个固定参数，并假设在迭代过程中分母不为零。\n\n使用误差序列 $e_k=x_k-\\alpha$ 的收敛阶 $p$ 的定义，即存在一个有限的非零常数 $C$ 使得 $\\lim_{k\\to\\infty}\\frac{|e_{k+1}|}{|e_k|^{p}}=|C|$，请在上述假设下，确定此方法对任意实数 $\\beta$ 的收敛阶 $p$。请以单个整数形式给出最终答案。无需四舍五入，也无需单位。", "solution": "问题陈述的有效性已得到确认。这是一个数值分析中的适定问题，没有科学或逻辑上的缺陷。\n\n为了确定给定迭代法的收敛阶，我们分析第 $k+1$ 步的误差 $e_{k+1} = x_{k+1} - \\alpha$ 与第 $k$ 步的误差 $e_k = x_k - \\alpha$ 之间的关系。当 $k \\to \\infty$ 时，如果对于某个非零常数 $C$，有 $e_{k+1} = C e_k^p + O(e_k^{p+1})$ 成立，则收敛阶为整数 $p$。\n\n迭代公式由下式给出：\n$$\nx_{k+1} = x_k - \\frac{f(x_k)}{f'(x_k)} - \\frac{f(x_k)^{2}\\,f''(x_k)}{2\\,f'(x_k)^{3}\\,\\bigl(1 + \\beta\\,f(x_k)/f'(x_k)\\bigr)}\n$$\n从两边减去根 $\\alpha$，得到误差递推关系：\n$$\ne_{k+1} = e_k - \\frac{f(x_k)}{f'(x_k)} - \\frac{f(x_k)^{2}\\,f''(x_k)}{2\\,f'(x_k)^{3}\\,\\bigl(1 + \\beta\\,f(x_k)/f'(x_k)\\bigr)}\n$$\n我们的分析依赖于函数 $f(x)$ 及其导数在单根 $\\alpha$ 附近的泰勒级数展开，其中 $f(\\alpha)=0$ 且 $f'(\\alpha)\\neq 0$。我们假设 $f$ 在 $\\alpha$ 的一个邻域内至少三阶连续可微。令 $e_k = x_k - \\alpha$。泰勒展开式为：\n$$\nf(x_k) = f(\\alpha+e_k) = f'(\\alpha)e_k + \\frac{f''(\\alpha)}{2}e_k^2 + \\frac{f'''(\\alpha)}{6}e_k^3 + O(e_k^4)\n$$\n$$\nf'(x_k) = f'(\\alpha+e_k) = f'(\\alpha) + f''(\\alpha)e_k + \\frac{f'''(\\alpha)}{2}e_k^2 + O(e_k^3)\n$$\n$$\nf''(x_k) = f''(\\alpha+e_k) = f''(\\alpha) + f'''(\\alpha)e_k + O(e_k^2)\n$$\n为了简化表达式，我们记 $A=f'(\\alpha)$，$B=f''(\\alpha)$，以及 $C=f'''(\\alpha)$，其中 $A \\neq 0$。\n\n首先，我们分析对应于牛顿法的那一项，$\\frac{f(x_k)}{f'(x_k)}$：\n$$\n\\frac{f(x_k)}{f'(x_k)} = \\frac{A e_k + \\frac{B}{2} e_k^2 + \\frac{C}{6} e_k^3 + O(e_k^4)}{A + B e_k + \\frac{C}{2} e_k^2 + O(e_k^3)}\n$$\n从分子中提出因子 $e_k$，从分母中提出因子 $A$：\n$$\n\\frac{f(x_k)}{f'(x_k)} = \\frac{e_k(A + \\frac{B}{2} e_k + \\frac{C}{6} e_k^2 + \\dots)}{A(1 + \\frac{B}{A} e_k + \\frac{C}{2A} e_k^2 + \\dots)} = e_k \\left(1 + \\frac{B}{2A} e_k + \\frac{C}{6A} e_k^2 + \\dots\\right) \\left(1 - \\frac{B}{A} e_k + \\left(\\frac{B^2}{A^2}-\\frac{C}{2A}\\right)e_k^2 + \\dots\\right)\n$$\n展开并合并到 $O(e_k^3)$ 的项：\n$$\n\\frac{f(x_k)}{f'(x_k)} = e_k \\left(1 + \\left(\\frac{B}{2A} - \\frac{B}{A}\\right)e_k + \\left(\\frac{C}{6A} - \\frac{B^2}{2A^2} + \\frac{B^2}{A^2} - \\frac{C}{2A}\\right)e_k^2 + \\dots\\right)\n$$\n$$\n\\frac{f(x_k)}{f'(x_k)} = e_k - \\frac{B}{2A}e_k^2 + \\left(\\frac{B^2}{2A^2} - \\frac{C}{3A}\\right)e_k^3 + O(e_k^4)\n$$\n误差递推关系的第一部分，即牛顿法的误差，是：\n$$\ne_k - \\frac{f(x_k)}{f'(x_k)} = \\frac{B}{2A}e_k^2 - \\left(\\frac{B^2}{2A^2} - \\frac{C}{3A}\\right)e_k^3 + O(e_k^4)\n$$\n这表明牛顿法本身是二阶收敛的（$p=2$）。\n\n现在，我们分析修正项：\n$$\n\\text{修正项} = \\frac{f(x_k)^{2}\\,f''(x_k)}{2\\,f'(x_k)^{3}\\,\\bigl(1 + \\beta\\,f(x_k)/f'(x_k)\\bigr)}\n$$\n我们将该项的每个组成部分按 $e_k$ 的幂次展开。\n- 分子：\n  $f(x_k)^2 = (A e_k + \\frac{B}{2} e_k^2 + O(e_k^3))^2 = A^2 e_k^2 + A B e_k^3 + O(e_k^4)$\n  $f''(x_k) = B + C e_k + O(e_k^2)$\n  $f(x_k)^2 f''(x_k) = (A^2 e_k^2 + A B e_k^3 + O(e_k^4))(B + C e_k + O(e_k^2)) = A^2 B e_k^2 + (A^2 C + A B^2) e_k^3 + O(e_k^4)$\n- 分母：\n  $f'(x_k)^3 = (A + B e_k + O(e_k^2))^3 = A^3 + 3 A^2 B e_k + O(e_k^2)$\n  $f(x_k)/f'(x_k) = e_k - \\frac{B}{2A}e_k^2 + O(e_k^3)$\n  $1 + \\beta f(x_k)/f'(x_k) = 1 + \\beta e_k - \\frac{\\beta B}{2A} e_k^2 + O(e_k^3)$\n  分母为 $2(A^3 + 3A^2 B e_k + O(e_k^2))(1 + \\beta e_k + O(e_k^2)) = 2A^3(1 + (\\frac{3B}{A} + \\beta)e_k + O(e_k^2))$。\n\n修正项变为：\n$$\n\\frac{A^2 B e_k^2 + (A^2 C + A B^2) e_k^3 + O(e_k^4)}{2A^3(1 + (\\frac{3B}{A} + \\beta)e_k + O(e_k^2))} = \\frac{e_k^2(A^2 B + (A^2 C + A B^2) e_k + \\dots)}{2A^3} \\left(1 - (\\frac{3B}{A} + \\beta)e_k + \\dots\\right)\n$$\n$$\n= \\frac{1}{2A^3} \\left[ A^2 B e_k^2 + \\left(A^2 C + A B^2 - A^2 B(\\frac{3B}{A} + \\beta)\\right)e_k^3 + O(e_k^4) \\right]\n$$\n$$\n= \\frac{B}{2A} e_k^2 + \\frac{1}{2A^3} \\left(A^2 C + A B^2 - 3AB^2 - \\beta A^2 B\\right)e_k^3 + O(e_k^4)\n$$\n$$\n= \\frac{B}{2A} e_k^2 + \\left(\\frac{C}{2A} - \\frac{B^2}{A^2} - \\frac{\\beta B}{2A}\\right)e_k^3 + O(e_k^4)\n$$\n现在，我们将这些展开式代回到 $e_{k+1}$ 的误差递推关系中：\n$$\ne_{k+1} = \\left[ \\frac{B}{2A}e_k^2 - \\left(\\frac{B^2}{2A^2} - \\frac{C}{3A}\\right)e_k^3 \\right] - \\left[ \\frac{B}{2A} e_k^2 + \\left(\\frac{C}{2A} - \\frac{B^2}{A^2} - \\frac{\\beta B}{2A}\\right)e_k^3 \\right] + O(e_k^4)\n$$\n$e_k^2$ 阶的项相互抵消，这是一个关键的观察。这意味着收敛阶至少为 $3$。\n$$\ne_{k+1} = \\left[ -\\frac{B^2}{2A^2} + \\frac{C}{3A} - \\frac{C}{2A} + \\frac{B^2}{A^2} + \\frac{\\beta B}{2A} \\right] e_k^3 + O(e_k^4)\n$$\n合并 $e_k^3$ 项的系数：\n$$\ne_{k+1} = \\left[ \\left(1 - \\frac{1}{2}\\right)\\frac{B^2}{A^2} + \\left(\\frac{1}{3} - \\frac{1}{2}\\right)\\frac{C}{A} + \\frac{\\beta B}{2A} \\right] e_k^3 + O(e_k^4)\n$$\n$$\ne_{k+1} = \\left( \\frac{B^2}{2A^2} - \\frac{C}{6A} + \\frac{\\beta B}{2A} \\right) e_k^3 + O(e_k^4)\n$$\n渐近误差常数为 $C_3 = \\frac{3B^2 - AC + 3\\beta AB}{6A^2}$。用函数在 $\\alpha$ 处的导数来重写：\n$$\nC_3 = \\frac{3(f''(\\alpha))^2 - f'(\\alpha)f'''(\\alpha) + 3\\beta f'(\\alpha)f''(\\alpha)}{6(f'(\\alpha))^2}\n$$\n只要这个常数 $C_3$ 通常不为零，收敛阶就是 $3$。对于任意给定的实数 $\\beta$，我们都可以构造一个函数 $f(x)$ 使得 $C_3 \\neq 0$。例如，对于在 $\\alpha=1$ 处的函数 $f(x)=x^2-1$，我们有 $f'(\\alpha)=2, f''(\\alpha)=2, f'''(\\alpha)=0$，这导致 $C_3 = \\frac{12+12\\beta}{24} = \\frac{1+\\beta}{2}$，除非 $\\beta=-1$，否则该值不为零。如果我们选择在 $\\alpha=0$ 处的函数 $f(x) = \\exp(x)-1$，我们有 $f'(\\alpha)=f''(\\alpha)=f'''(\\alpha)=1$，这导致 $C_3 = \\frac{3-1+3\\beta}{6} = \\frac{2+3\\beta}{6}$，除非 $\\beta=-2/3$，否则该值不为零。\n由于对于任何给定的 $\\beta$，总能找到一个函数 $f(x)$ 使得 $C_3 \\neq 0$，因此不能保证收敛阶高于 $3$。由于已经证明对于任何函数 $f$（其中 $f'(\\alpha)\\neq 0$）和任何 $\\beta$，$e_k^2$ 项都会消失，因此收敛阶至少为 $3$。\n因此，该方法对于任意实数参数 $\\beta$ 的收敛阶是 $3$。", "answer": "$$\\boxed{3}$$", "id": "2381957"}, {"introduction": "在复杂的工程和科学计算中，我们常常需要通过数值实验来验证算法的实际性能。本练习将理论与实践相结合，要求你为一个非线性偏微分方程实现一个“冻结”雅可比牛顿求解器，并根据其迭代输出估计收敛阶。这能让你亲身体验在真实场景中如何评估和确认数值方法的收敛特性。[@problem_id:2381909]", "problem": "考虑空间区间 $[0,1]$ 上的非线性偏微分方程 $u_t = u_{xx} + u^2$，其边界条件为齐次 Dirichlet 边界条件 $u(0,t)=0$ 和 $u(1,t)=0$，初始条件为光滑函数 $u(x,0)=u_0(x)$。使用包含 $m$ 个内部点的均匀网格对空间进行离散化，步长为 $h = \\frac{1}{m+1}$，并令 $u \\in \\mathbb{R}^m$ 表示给定时间的内部点值向量。对空间二阶导数使用二阶中心差分近似，因此离散拉普拉斯算子可由三对角矩阵 $L \\in \\mathbb{R}^{m \\times m}$ 表示，其对角线元素为 $-\\frac{2}{h^2}$，非对角线元素为 $\\frac{1}{h^2}$。使用时间步长为 $\\Delta t > 0$ 的后向欧拉法对时间进行离散化，因此在从 $u^n$ 到 $u^{n+1}$ 的单个时间步内，需求解的非线性系统 $F(u^{n+1})=0$ 定义为\n$$\nF(u) \\equiv u - \\Delta t \\left(Lu + u^{\\circ 2}\\right) - u^n \\in \\mathbb{R}^m,\n$$\n其中 $u^{\\circ 2}$ 表示按元素平方。\n\n将 $F$ 在向量 $w \\in \\mathbb{R}^m$ 处的雅可比矩阵定义为\n$$\nJ(w) \\equiv I - \\Delta t \\left(L + 2\\,\\mathrm{diag}(w)\\right) \\in \\mathbb{R}^{m \\times m},\n$$\n其中 $I$ 是单位矩阵，$\\mathrm{diag}(w)$ 是对角线元素为 $w$ 中各项的对角矩阵。\n\n在每个时间步求解 $F(u)=0$ 的“冻结”雅可比牛顿法定义如下：选择一个固定向量 $w_{\\mathrm{freeze}}$，并通过求解线性系统\n$$\nJ(w_{\\mathrm{freeze}})\\, s^{(k)} = -F\\!\\left(u^{(k)}\\right),\n$$\n来计算类牛顿迭代 $u^{(k+1)} = u^{(k)} + s^{(k)}$，其中雅可比矩阵 $J(w_{\\mathrm{freeze}})$ 在所有内部迭代 $k$ 中保持不变。在本问题中，对于从时间层 $n$ 到 $n+1$ 的单个时间步，取 $w_{\\mathrm{freeze}} = u^n$ 且初始猜测为 $u^{(0)} = u^n$。\n\n令序列 $\\{u^{(k)}\\}_{k \\ge 0}$ 表示单个时间步内冻结雅可比法的内部迭代，并定义步长差 $\\delta_k \\equiv \\lVert u^{(k+1)} - u^{(k)} \\rVert_2$（对于 $k \\ge 0$），其中 $\\lVert \\cdot \\rVert_2$ 是欧几里得范数。迭代求解器的渐近收敛阶 $p$ 定义为：存在一个常数 $C > 0$，使得当误差 $e_k \\equiv \\lVert u^{(k)} - u^\\star \\rVert_2$ 足够小时，关系式 $e_{k+1} \\approx C\\, e_k^p$ 成立，其中 $u^\\star$ 是 $F(u)=0$ 的精确解。一个消除了未知量 $u^\\star$ 的标准 $p$ 估计量使用步长差：\n$$\n\\widehat{p}_k \\equiv \\frac{\\log\\left(\\delta_{k}/\\delta_{k-1}\\right)}{\\log\\left(\\delta_{k-1}/\\delta_{k-2}\\right)}, \\quad \\text{对于 } k \\ge 2,\n$$\n前提是该方法处于渐近区域且 $\\delta_{k-2},\\delta_{k-1},\\delta_k > 0$。\n\n任务：实现一个完整的程序，该程序\n- 如上所述，为单个后向欧拉时间步构建 $L$ 和 $F$。\n- 实现冻结雅可比牛顿法，其中 $w_{\\mathrm{freeze}} = u^n$ 且 $u^{(0)} = u^n$。\n- 迭代直至满足停止准则 $\\lVert s^{(k)} \\rVert_2 \\le \\varepsilon$ 或达到最大迭代次数 $k_{\\max}$。对 $\\lVert s^{(k)} \\rVert_2$ 使用欧几里得范数。\n- 使用最后三个可用的步长差计算 $\\widehat{p}_k$ 来估计渐近收敛阶 $p$。如果可用的步长差少于三个，则返回一个非数值指示符（例如，特殊浮点值 $\\mathrm{NaN}$）。\n- 在网格点 $x_i = i h$（$i=1,2,\\dots,m$）处，使用初始条件 $u^n_i = A \\sin(\\pi x_i)$，其中 $A$ 是给定振幅，$\\pi$ 是常数 $3.14159\\dots$。\n\n对单个时间步使用以下参数集测试套件：\n- 测试 $1$：$m = 100$，$\\Delta t = 10^{-3}$，$A = 1.0$，$\\varepsilon = 10^{-12}$，$k_{\\max} = 100$。\n- 测试 $2$：$m = 100$，$\\Delta t = 5 \\times 10^{-3}$，$A = 2.0$，$\\varepsilon = 10^{-12}$，$k_{\\max} = 100$。\n- 测试 $3$：$m = 50$，$\\Delta t = 10^{-3}$，$A = 0.1$，$\\varepsilon = 10^{-12}$，$k_{\\max} = 100$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。列表中的每个条目都等于相应测试的估计收敛阶 $\\widehat{p}$，并四舍五入到六位小数（例如，$[1.000000,0.998532,1.001247]$）。不涉及物理单位。如果在您自己的辅助计算中出现任何角度，必须以弧度为单位。在输出中，所有小数都应表示为标准十进制数字。", "solution": "首先对问题陈述进行严格验证，以确定其科学和数学上的完整性。\n\n### 问题验证\n\n#### 步骤1：提取的已知条件\n问题提供了以下明确信息：\n-   **控制方程**：非线性偏微分方程 $u_t = u_{xx} + u^2$，定义域为 $x \\in [0,1]$。\n-   **边界条件**：齐次 Dirichlet 条件，$u(0,t)=0$ 和 $u(1,t)=0$。\n-   **空间离散化**：具有 $m$ 个内部点的均匀网格，网格间距为 $h = \\frac{1}{m+1}$。内部点值的向量为 $u \\in \\mathbb{R}^m$。\n-   **离散拉普拉斯算子**：对 $u_{xx}$ 的二阶中心差分近似由一个三对角矩阵 $L \\in \\mathbb{R}^{m \\times m}$ 表示，其对角线元素为 $-\\frac{2}{h^2}$，非对角线元素为 $\\frac{1}{h^2}$。\n-   **时间离散化**：后向欧拉法，时间步长为 $\\Delta t > 0$。\n-   **非线性系统**：对于从 $u^n$ 到 $u^{n+1}$ 的一个时间步，待求解的系统是 $F(u^{n+1})=0$，其中函数 $F: \\mathbb{R}^m \\to \\mathbb{R}^m$ 定义为 $F(u) \\equiv u - \\Delta t \\left(Lu + u^{\\circ 2}\\right) - u^n$。符号 $u^{\\circ 2}$ 表示按元素平方。\n-   **雅可比矩阵**：$F$ 在向量 $w \\in \\mathbb{R}^m$ 处的雅可比矩阵是 $J(w) \\equiv I - \\Delta t \\left(L + 2\\,\\mathrm{diag}(w)\\right)$，其中 $I$ 是单位矩阵。\n-   **迭代求解器**：一种“冻结”雅可比牛顿法，其中雅可比矩阵固定在 $J(w_{\\mathrm{freeze}})$ 处，且 $w_{\\mathrm{freeze}} = u^n$。迭代的初始猜测是 $u^{(0)} = u^n$。迭代更新为 $u^{(k+1)} = u^{(k)} + s^{(k)}$，其中 $s^{(k)}$ 是线性系统 $J(w_{\\mathrm{freeze}})\\, s^{(k)} = -F\\!\\left(u^{(k)}\\right)$的解。\n-   **收敛阶估计**：渐近阶 $p$ 由 $\\widehat{p}_k \\equiv \\frac{\\log\\left(\\delta_{k}/\\delta_{k-1}\\right)}{\\log\\left(\\delta_{k-1}/\\delta_{k-2}\\right)}$（对于 $k \\ge 2$）估计。步长差为 $\\delta_k \\equiv \\lVert u^{(k+1)} - u^{(k)} \\rVert_2 = \\lVert s^{(k)} \\rVert_2$。如果可用的步长差少于三个，结果为非数值（NaN）指示符。\n-   **初始数据**：对于所考虑的单个时间步，状态 $u^n$ 由 $u^n_i = A \\sin(\\pi x_i)$ 在网格点 $x_i = i h$（对于 $i = 1, 2, \\dots, m$）给出。\n-   **求解器参数**：停止准则是 $\\lVert s^{(k)} \\rVert_2 \\le \\varepsilon$ 或达到最大迭代次数 $k_{\\max}$。\n-   **测试用例**：\n    1.  $m = 100$，$\\Delta t = 10^{-3}$，$A = 1.0$，$\\varepsilon = 10^{-12}$，$k_{\\max} = 100$。\n    2.  $m = 100$，$\\Delta t = 5 \\times 10^{-3}$，$A = 2.0$，$\\varepsilon = 10^{-12}$，$k_{\\max} = 100$。\n    3.  $m = 50$，$\\Delta t = 10^{-3}$，$A = 0.1$，$\\varepsilon = 10^{-12}$，$k_{\\max} = 100$。\n\n#### 步骤2：使用提取的已知条件进行验证\n根据科学有效性和适定性的标准对该问题进行评估。\n-   **科学依据**：该问题涉及反应扩散方程的数值解法，这是计算科学中的一个基本课题。所选的数值方法——空间上的有限差分法，时间上的后向欧拉法，以及用于求解所得非线性系统的冻结雅可比牛顿法——都是数值分析领域中的标准且经过严格验证的方法。\n-   **适定性与客观性**：该问题表述精确。所有量、算子和算法都有明确定义。任务是实现一个指定的计算过程并计算一个明确定义的度量。冻结雅可比牛顿法是不动点迭代的一种形式，其收敛特性已得到充分理解。预期它会表现出线性收敛（阶数 $p=1$），而问题要求对此阶数进行数值估计。该问题是明确的，并且其求解过程是唯一且有意义的。\n-   **完整性**：为每个测试用例提供了所有必要的参数（$m, \\Delta t, A, \\varepsilon, k_{\\max}$）、定义和初始条件。该问题是自洽的。\n\n#### 步骤3：结论与行动\n该问题被认为是有效的，因为其在科学上是合理的，在数学上是适定的，并且是完整的。将提供一个解决方案。\n\n### 解决方案\n\n该解决方案要求为单个后向欧拉时间步实现一个数值算法。该算法是冻结雅可比牛顿法。对于每个指定的测试用例，需要估计此方法的收敛阶。\n\n首先，设置离散问题。对于给定的内部网格点数 $m$，空间步长为 $h = \\frac{1}{m+1}$。内部点的空间坐标向量是 $x$，其分量为 $x_i = i \\cdot h$（$i=1, \\dots, m$）。\n\n离散拉普拉斯算子 $L \\in \\mathbb{R}^{m \\times m}$ 是一个对称三对角矩阵，其非零元素定义如下：\n$$\nL_{i,j} = \\frac{1}{h^2} \\begin{cases}\n-2 & \\text{若 } i=j \\\\\n1 & \\text{若 } |i-j|=1 \\\\\n0 & \\text{其他情况}\n\\end{cases}\n$$\n\n时间步的初始向量 $u^n \\in \\mathbb{R}^m$ 使用给定的振幅 $A$ 和空间坐标构建：\n$$\nu^n_i = A \\sin(\\pi x_i)\n$$\n\n求解器的核心是冻结雅可比牛顿迭代。雅可比矩阵只计算一次，使用状态 $u^n$ 作为冻结-点 $w_{\\text{freeze}}$。这产生了一个恒定的迭代矩阵：\n$$\nJ_{\\text{freeze}} = J(u^n) = I - \\Delta t \\left(L + 2\\,\\mathrm{diag}(u^n)\\right)\n$$\n其中 $I$ 是 $m \\times m$ 的单位矩阵，$\\mathrm{diag}(u^n)$ 是对角线元素为向量 $u^n$ 各元素的对角矩阵。\n\n求解 $u^{n+1}$ 的迭代过程从初始猜测 $u^{(0)} = u^n$ 开始。在每次迭代 $k$ 中，执行以下步骤：\n1.  在当前迭代值 $u^{(k)}$ 处，计算残差函数 $F$：\n    $$\n    F(u^{(k)}) = u^{(k)} - \\Delta t (L u^{(k)} + (u^{(k)})^{\\circ 2}) - u^n\n    $$\n2.  求解线性系统以获得牛顿更新步 $s^{(k)}$：\n    $$\n    J_{\\text{freeze}} s^{(k)} = -F(u^{(k)})\n    $$\n3.  更新解向量：$u^{(k+1)} = u^{(k)} + s^{(k)}$。\n4.  计算更新步的欧几里得范数 $\\delta_k = \\lVert s^{(k)} \\rVert_2$，并存储它。\n当 $\\delta_k \\le \\varepsilon$ 或 $k = k_{\\max}$ 时，过程终止。\n\n在 $N$ 次迭代后循环终止（产生步长范数 $\\delta_0, \\dots, \\delta_{N-1}$），然后估计收敛阶。如果 $N < 3$，则没有足够的数据点来应用三点公式，结果为 NaN。否则，使用最后三个可用的步长范数计算估计值 $\\widehat{p}$：\n$$\n\\widehat{p} = \\frac{\\log(\\delta_{N-1}/\\delta_{N-2})}{\\log(\\delta_{N-2}/\\delta_{N-3})}\n$$\n对每个测试用例执行此计算。该方法的预期理论收敛阶为 $p=1$（线性收敛），因此数值估计 $\\widehat{p}$ 应接近 1。\n\n实现将利用 `numpy` 库进行所有数组、向量和矩阵运算，包括使用 `np.linalg.solve` 求解线性系统。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_frozen_newton_solver(m, delta_t, A, epsilon, k_max):\n    \"\"\"\n    Solves the nonlinear system for one backward Euler step using a frozen Jacobian\n    Newton method and estimates the convergence order.\n    \n    Args:\n        m (int): Number of interior spatial grid points.\n        delta_t (float): Time step size.\n        A (float): Amplitude of the initial sine wave profile.\n        epsilon (float): Tolerance for the stopping criterion.\n        k_max (int): Maximum number of iterations.\n        \n    Returns:\n        float: The estimated convergence order p, or np.nan if not computable.\n    \"\"\"\n    # 1. Setup grid and initial condition for the time step\n    h = 1.0 / (m + 1.0)\n    x = np.arange(1, m + 1) * h\n    u_n = A * np.sin(np.pi * x)\n\n    # 2. Construct discrete Laplacian L\n    h_sq_inv = 1.0 / (h**2)\n    main_diag_L = -2.0 * h_sq_inv * np.ones(m)\n    off_diag_L = h_sq_inv * np.ones(m - 1)\n    L = np.diag(main_diag_L) + np.diag(off_diag_L, k=1) + np.diag(off_diag_L, k=-1)\n    \n    # 3. Construct the frozen Jacobian matrix J_freeze\n    I = np.identity(m)\n    J_freeze = I - delta_t * (L + 2.0 * np.diag(u_n))\n    \n    # 4. Perform frozen Jacobian Newton iterations\n    u_k = np.copy(u_n)  # Initial guess u^(0) = u^n\n    step_diffs = []\n\n    for _ in range(k_max):\n        # Calculate the residual F(u_k)\n        Lu_k = L @ u_k\n        u_k_sq = np.square(u_k)\n        F_u_k = u_k - delta_t * (Lu_k + u_k_sq) - u_n\n        \n        # Solve the linear system for the step s_k\n        s_k = np.linalg.solve(J_freeze, -F_u_k)\n        \n        # Calculate the norm of the step (delta_k)\n        delta_k = np.linalg.norm(s_k, 2)\n        step_diffs.append(delta_k)\n        \n        # Update the solution\n        u_k += s_k\n        \n        # Check stopping criterion\n        if delta_k <= epsilon:\n            break\n            \n    # 5. Estimate the convergence order p\n    if len(step_diffs) < 3:\n        return np.nan\n        \n    # Use the last three step differences for estimation\n    # delta_k / delta_{k-1}\n    # delta_{k-1} / delta_{k-2}\n    d_last = step_diffs[-1]\n    d_mid = step_diffs[-2]\n    d_first = step_diffs[-3]\n\n    # Guard against division by zero or log of non-positive numbers\n    if d_mid <= 0 or d_first <= 0:\n        return np.nan\n\n    ratio1 = d_last / d_mid\n    ratio2 = d_mid / d_first\n\n    if ratio1 <= 0 or ratio2 <= 0 or ratio2 == 1.0:\n        return np.nan\n        \n    p_hat = np.log(ratio1) / np.log(ratio2)\n    \n    return p_hat\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (m, delta_t, A, epsilon, k_max)\n        (100, 1e-3, 1.0, 1e-12, 100),\n        (100, 5e-3, 2.0, 1e-12, 100),\n        (50, 1e-3, 0.1, 1e-12, 100),\n    ]\n\n    results = []\n    for case in test_cases:\n        p_estimate = run_frozen_newton_solver(*case)\n        results.append(p_estimate)\n\n    # Format the final output string\n    formatted_results = []\n    for res in results:\n        if np.isnan(res):\n            formatted_results.append('nan')\n        else:\n            # Round to six decimal places\n            formatted_results.append(f'{res:.6f}')\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2381909"}, {"introduction": "收敛阶的概念不仅用于理论分析，更能用于设计更智能、更高效的算法。本练习将指导你设计并实现一个“预测性”停止准则，该准则在迭代过程中动态估计收敛阶，并据此预测下一次迭代的误差。这种方法能有效节省计算资源，展示了如何将收敛理论转化为提升算法效率的实用工具。[@problem_id:2381960]", "problem": "给你一个形式为 $x_{k+1}=\\varphi(x_k)$ 的标量不动点迭代，它收敛到一个实不动点 $r$。将误差记为 $e_k = x_k - r$。假设误差在局部满足形式为 $\\lvert e_{k+1} \\rvert \\approx C \\lvert e_k \\rvert^{p}$ 的模型，其中阶 $p \\ge 1$ 和常数 $C>0$ 未知。你的任务是设计一个实用的停止准则，在每次迭代中，仅使用最近的迭代值来估计阶 $p$，并预测下一次迭代是否会满足用户指定的绝对误差容忍度。你必须实现一个程序，对几个指定的测试用例执行该迭代，应用你的停止准则，并报告停止时刻的估计收敛阶、执行的迭代次数，以及停止决策是否是在当前迭代实际满足容忍度之前预测性地做出的。\n\n定义和要求：\n\n- 对于所有 $k \\ge 0$，令 $e_k = x_k - r$，其中 $r$ 是测试用例的已知不动点。\n- 对于 $k \\ge 2$，将估计的收敛阶定义为\n$$\n\\widehat{p}_k \\;=\\; \\frac{\\ln\\left(\\lvert e_k \\rvert / \\lvert e_{k-1} \\rvert \\right)}{\\ln\\left(\\lvert e_{k-1} \\rvert / \\lvert e_{k-2} \\rvert \\right)}.\n$$\n- 对于 $k \\ge 1$ 和给定的 $\\widehat{p}_k$，定义\n$$\n\\widehat{C}_k \\;=\\; \\frac{\\lvert e_k \\rvert}{\\lvert e_{k-1} \\rvert^{\\widehat{p}_k}},\n\\qquad\n\\widehat{e}_{k+1}^{\\,\\mathrm{pred}} \\;=\\; \\widehat{C}_k \\, \\lvert e_k \\rvert^{\\widehat{p}_k}.\n$$\n- 在迭代索引 $k \\ge 0$ 处的停止准则（$x_k$ 可用）：\n    1. 如果 $\\lvert e_k \\rvert \\le \\text{tol}$，立即停止（非预测性停止）。\n    2. 否则，如果 $k \\ge 2$ 且 $\\widehat{p}_k \\ge 1$ 且 $\\widehat{C}_k$ 是有限正数且 $\\widehat{e}_{k+1}^{\\,\\mathrm{pred}} \\le \\text{tol}$，则停止（预测性停止）。\n    3. 否则，继续迭代直到达到最大迭代次数。\n- 如果方法在迭代索引 $k$ 处停止，并且 $\\widehat{p}_k$ 无法计算（例如，$k<2$ 或分母为零），则报告估计阶为 $-1.0$。\n\n测试套件的迭代模型选择：\n\n你必须根据以下两个模板实现 $\\varphi$：\n\n- 比率为 $q \\in (0,1)$ 的线性模型：\n$$\n\\varphi_{\\mathrm{lin}}(x;r,q) \\;=\\; r \\;+\\; q \\, (x-r).\n$$\n- 参数为 $C>0$ 和 $p>1$ 的保号幂模型：\n$$\n\\varphi_{\\mathrm{pow}}(x;r,C,p) \\;=\\; r \\;+\\; C \\, (x-r) \\, \\lvert x-r \\rvert^{\\,p-1}.\n$$\n\n测试套件：\n\n在以下五个用例上运行你的程序。对于每个用例，使用指定的 $r$、初始值 $x_0$、容忍度 $\\text{tol}$（与 $x$ 单位相同的绝对误差目标）和最大迭代次数 $\\text{max\\_it}$。\n\n- 用例1（类二次）：$\\varphi=\\varphi_{\\mathrm{pow}}$，其中 $r=1.0$, $C=0.75$, $p=2.0$, $x_0=1.1$, $\\text{tol}=10^{-10}$, $\\text{max\\_it}=50$。\n- 用例2（超线性，阶 $p=1.5$）：$\\varphi=\\varphi_{\\mathrm{pow}}$，其中 $r=2.0$, $C=0.9$, $p=1.5$, $x_0=1.9$, $\\text{tol}=10^{-10}$, $\\text{max\\_it}=100$。\n- 用例3（线性，$q=0.5$）：$\\varphi=\\varphi_{\\mathrm{lin}}$，其中 $r=-1.0$, $q=0.5$, $x_0=2.0$, $\\text{tol}=10^{-8}$, $\\text{max\\_it}=200$。\n- 用例4（类三次）：$\\varphi=\\varphi_{\\mathrm{pow}}$，其中 $r=0.0$, $C=0.8$, $p=3.0$, $x_0=0.5$, $\\text{tol}=10^{-12}$, $\\text{max\\_it}=50$。\n- 用例5（近线性，$q=0.95$）：$\\varphi=\\varphi_{\\mathrm{lin}}$，其中 $r=3.0$, $q=0.95$, $x_0=5.0$, $\\text{tol}=10^{-8}$, $\\text{max\\_it}=500$。\n\n程序输入和输出：\n\n- 无外部输入。\n- 你的程序必须按顺序执行所有五个用例，应用上述迭代和停止准则。\n- 对于每个用例，生成一个包含三个条目的列表：停止时刻的估计阶（四舍五入到三位小数，如果未定义则使用 $-1.0$）、执行的迭代次数（包括停止迭代索引，其中 $x_0$ 对应于索引 $0$），以及一个整数标志（如果停止是预测性的则为 $1$，否则为 $0$）。\n- 你的程序应生成单行输出，其中包含所有五个用例的结果，形式为这些列表的逗号分隔列表，并用方括号括起来。例如： $[\\,[p_1,k_1,f_1],[p_2,k_2,f_2],\\ldots,[p_5,k_5,f_5]\\,]$.\n\n所有量都是无量纲的；不涉及物理单位。不使用角度。按规定将所有数值输出表示为实数或整数；不要使用百分比表示法。", "solution": "所提出的问题是计算工程领域中的一个有效练习，特别是在非线性方程的数值分析领域。它要求实现一个增加了实用、预测性停止准则的不动点迭代方案。所有的定义、参数和目标都已明确指定，构成了一个自洽且适定的问题。其中没有科学上的不准确之处或逻辑矛盾。因此，我将提供一个完整的解决方案。\n\n问题的核心在于分析由迭代 $x_{k+1} = \\varphi(x_k)$ 生成的序列 $x_k$ 的收敛性，该序列收敛到一个满足 $r = \\varphi(r)$ 的不动点 $r$。收敛速度由连续误差之间的关系来表征，其中第 $k$ 步的误差定义为 $e_k = x_k - r$。对于许多迭代方法，这种关系可以在局部用以下模型近似：\n$$\n\\lvert e_{k+1} \\rvert \\approx C \\lvert e_k \\rvert^{p}\n$$\n此处，$p$ 是收敛阶，$C$ 是渐进误差常数。如果 $p=1$ 且 $0 < C < 1$，则收敛是线性的。如果 $p > 1$，则收敛是超线性的（例如，如果 $p=2$ 是二次收敛，如果 $p=3$ 是三次收敛）。\n\n任务是实现一个停止准则，它不仅检查当前误差 $\\lvert e_k \\rvert$ 是否低于容忍度 $\\text{tol}$，还尝试预测*下一个*误差 $\\lvert e_{k+1} \\rvert$ 是否会满足容忍度。这种预测性停止可以节省一次可能开销很大的函数评估 $\\varphi(x_k)$。为了做出这个预测，必须首先从至今为止生成的迭代序列中估计未知参数 $p$ 和 $C$。\n\n收敛阶的估计值 $\\widehat{p}_k$ 是从误差模型中推导出来的。假设模型对最近的迭代成立，我们有：\n$$\n\\lvert e_k \\rvert \\approx C \\lvert e_{k-1} \\rvert^{p} \\qquad \\text{和} \\qquad \\lvert e_{k-1} \\rvert \\approx C \\lvert e_{k-2} \\rvert^{p}\n$$\n对两个表达式取自然对数，得到一个关于 $\\ln C$ 和 $p$ 的线性系统：\n$$\n\\ln \\lvert e_k \\rvert \\approx \\ln C + p \\ln \\lvert e_{k-1} \\rvert\n$$\n$$\n\\ln \\lvert e_{k-1} \\rvert \\approx \\ln C + p \\ln \\lvert e_{k-2} \\rvert\n$$\n用第一个方程减去第二个方程可以消去 $\\ln C$：\n$$\n\\ln \\lvert e_k \\rvert - \\ln \\lvert e_{k-1} \\rvert \\approx p (\\ln \\lvert e_{k-1} \\rvert - \\ln \\lvert e_{k-2} \\rvert)\n$$\n解出 $p$ 即可得到问题中指定的估计量，它对 $k \\ge 2$ 有效：\n$$\n\\widehat{p}_k = \\frac{\\ln(\\lvert e_k \\rvert / \\lvert e_{k-1} \\rvert)}{\\ln(\\lvert e_{k-1} \\rvert / \\lvert e_{k-2} \\rvert)}\n$$\n这个公式需要至少三个连续的误差项（$e_k, e_{k-1}, e_{k-2}$），这就是为什么它适用于 $k \\ge 2$ 的原因。\n\n一旦估计值 $\\widehat{p}_k$ 可用，就可以从第 $k$ 步的模型中估计常数 $C$：\n$$\n\\widehat{C}_k = \\frac{\\lvert e_k \\rvert}{\\lvert e_{k-1} \\rvert^{\\widehat{p}_k}}\n$$\n这个估计量也定义在 $k \\ge 2$ 时，因为它依赖于 $\\widehat{p}_k$。最后，有了 $\\widehat{p}_k$ 和 $\\widehat{C}_k$，我们就可以利用模型的结构来预测下一个误差的大小，即 $\\lvert e_{k+1} \\rvert$：\n$$\n\\widehat{e}_{k+1}^{\\,\\mathrm{pred}} = \\widehat{C}_k \\lvert e_k \\rvert^{\\widehat{p}_k}\n$$\n那么，在迭代 $k$ 处的完整停止准则是一系列检查：\n1.  **非预测性停止**：如果 $\\lvert e_k \\rvert \\le \\text{tol}$，过程终止。这是标准准则。\n2.  **预测性停止**：如果第一个检查失败，但 $k \\ge 2$ 且估计参数表现良好（$\\widehat{p}_k \\ge 1$，$\\widehat{C}_k$ 是有限正数），我们检查预测误差 $\\widehat{e}_{k+1}^{\\,\\mathrm{pred}}$ 是否小于或等于 $\\text{tol}$。如果是，我们就停止，这样就节省了一次迭代。\n3.  **继续**：如果两个停止条件都未满足，则计算下一个迭代值 $x_{k+1} = \\varphi(x_k)$，并重复此过程。\n\n实现将包含一个主循环，对每个测试用例执行不动点迭代。在每一步 $k$ 的循环内部，它将计算误差 $e_k$，然后应用两阶段停止准则。数值保护是必要的，特别是在计算 $\\widehat{p}_k$ 时，以处理分母 $\\ln(\\lvert e_{k-1} \\rvert / \\lvert e_{k-2} \\rvert)$ 为零或接近零的情况，这会使估计值未定义。迭代函数 $\\varphi_{\\mathrm{lin}}$ 和 $\\varphi_{\\mathrm{pow}}$ 按照定义实现。每个测试用例的结果——最终的估计阶、迭代次数以及指示预测性停止的标志——被收集并按要求格式化。\n\n幂模型的表达式 $\\varphi_{\\mathrm{pow}}(x;r,C,p) = r + C (x-r) \\lvert x-r \\rvert^{p-1}$ 是 $r + C \\cdot \\text{sgn}(x-r) \\lvert x-r \\rvert^p$ 的一种表示形式。这确保了如果 $C > 0$，误差 $e_{k+1} = x_{k+1} - r$ 的符号与 $e_k = x_k-r$ 的符号相同，这也就是“保号”这个名称的由来。这种构造导致了精确的误差关系 $\\lvert e_{k+1} \\rvert = C \\lvert e_k \\rvert^p$，使得这些测试用例非常适合用于评估估算程序。同样，对于线性模型，$\\lvert e_{k+1} \\rvert = q \\lvert e_k \\rvert$，这使得 $p=1$ 且 $C=q$。", "answer": "```python\nimport numpy as np\n\ndef phi_lin(x, r, q):\n    \"\"\"线性不动点迭代函数。\"\"\"\n    return r + q * (x - r)\n\ndef phi_pow(x, r, C, p):\n    \"\"\"保号幂模型不动点迭代函数。\"\"\"\n    error_term = x - r\n    if error_term == 0:\n        return r\n    return r + C * error_term * (np.abs(error_term)**(p - 1))\n\ndef run_iteration(model_func, model_params, x0, r, tol, max_it):\n    \"\"\"\n    执行带有预测性停止准则的不动点迭代。\n    \"\"\"\n    x_k = x0\n    errors = []\n    \n    for k in range(max_it + 1):\n        e_k = x_k - r\n        errors.append(e_k)\n        \n        # 如果在 p_hat 可计算前停止，则为结果设置默认值\n        p_hat_k = -1.0\n        \n        # 1. 非预测性停止检查\n        if np.abs(e_k) <= tol:\n            if k >= 2:\n                # p_hat_k 的分母\n                log_ratio_denom_val = np.abs(errors[k-1]) / np.abs(errors[k-2])\n                if log_ratio_denom_val > 0 and np.abs(np.log(log_ratio_denom_val)) > 1e-15:\n                    log_ratio_num_val = np.abs(errors[k]) / np.abs(errors[k-1])\n                    if log_ratio_num_val > 0:\n                        p_hat_k = np.log(log_ratio_num_val) / np.log(log_ratio_denom_val)\n\n            return [round(p_hat_k, 3), k, 0]\n\n        # 检查是否达到最大迭代次数\n        if k == max_it:\n            if k >= 2:\n                log_ratio_denom_val = np.abs(errors[k-1]) / np.abs(errors[k-2])\n                if log_ratio_denom_val > 0 and np.abs(np.log(log_ratio_denom_val)) > 1e-15:\n                    log_ratio_num_val = np.abs(errors[k]) / np.abs(errors[k-1])\n                    if log_ratio_num_val > 0:\n                        p_hat_k = np.log(log_ratio_num_val) / np.log(log_ratio_denom_val)\n            return [round(p_hat_k, 3), k, 0]\n\n        # 2. 预测性停止检查（仅在 k >= 2 时可能）\n        if k >= 2:\n            # 计算 p_hat_k\n            abs_ek, abs_ekm1, abs_ekm2 = np.abs(errors[k]), np.abs(errors[k-1]), np.abs(errors[k-2])\n\n            # 确保对数函数的参数为正且分母非零\n            candidate_p_hat = None\n            if abs_ek > 0 and abs_ekm1 > 0 and abs_ekm2 > 0:\n                log_ratio_km1 = np.log(abs_ekm1 / abs_ekm2)\n                if np.abs(log_ratio_km1) > 1e-15: # 避免除以零\n                    log_ratio_k = np.log(abs_ek / abs_ekm1)\n                    candidate_p_hat = log_ratio_k / log_ratio_km1\n            \n            if candidate_p_hat is not None and candidate_p_hat >= 1:\n                # 计算 C_hat_k\n                # 使用 np.power 以安全地处理潜在的大指数\n                denom_c_hat = np.power(abs_ekm1, candidate_p_hat)\n                if np.isfinite(denom_c_hat) and denom_c_hat > 0:\n                    C_hat_k = abs_ek / denom_c_hat\n                    if np.isfinite(C_hat_k) and C_hat_k > 0:\n                        # 计算预测误差\n                        e_hat_pred_kp1 = C_hat_k * np.power(abs_ek, candidate_p_hat)\n                        \n                        if np.isfinite(e_hat_pred_kp1) and e_hat_pred_kp1 <= tol:\n                            p_hat_k = candidate_p_hat\n                            return [round(p_hat_k, 3), k, 1]\n\n        # 3. 继续：计算下一次迭代值\n        x_k = model_func(x_k, **model_params)\n        \n    # 如果在循环内正确处理了 max_it，则不应执行到此部分\n    return [round(p_hat_k, 3), max_it, 0]\n\n\ndef solve():\n    \"\"\"\n    主函数，用于运行测试套件并打印结果。\n    \"\"\"\n    test_cases = [\n        # 情况1（类二次）\n        {'func': phi_pow, 'params': {'r': 1.0, 'C': 0.75, 'p': 2.0}, 'x0': 1.1, 'r': 1.0, 'tol': 1e-10, 'max_it': 50},\n        # 情况2（超线性，p=1.5）\n        {'func': phi_pow, 'params': {'r': 2.0, 'C': 0.9, 'p': 1.5}, 'x0': 1.9, 'r': 2.0, 'tol': 1e-10, 'max_it': 100},\n        # 情况3（线性，q=0.5）\n        {'func': phi_lin, 'params': {'r': -1.0, 'q': 0.5}, 'x0': 2.0, 'r': -1.0, 'tol': 1e-8, 'max_it': 200},\n        # 情况4（类三次）\n        {'func': phi_pow, 'params': {'r': 0.0, 'C': 0.8, 'p': 3.0}, 'x0': 0.5, 'r': 0.0, 'tol': 1e-12, 'max_it': 50},\n        # 情况5（近线性，q=0.95）\n        {'func': phi_lin, 'params': {'r': 3.0, 'q': 0.95}, 'x0': 5.0, 'r': 3.0, 'tol': 1e-8, 'max_it': 500},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_iteration(\n            model_func=case['func'],\n            model_params=case['params'],\n            x0=case['x0'],\n            r=case['r'],\n            tol=case['tol'],\n            max_it=case['max_it']\n        )\n        results.append(result)\n\n    # 格式化最终输出字符串\n    # 对列表使用 str() 可生成所需的 '[p,k,f]' 格式\n    output_str = f\"[{','.join(map(str, results))}]\"\n    print(output_str)\n\nsolve()\n```", "id": "2381960"}]}