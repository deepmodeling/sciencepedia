{"hands_on_practices": [{"introduction": "在信息论中，许多核心量度的性质都根植于凸性。本练习提供了一个绝佳的机会，让您将微积分中的判别方法应用于一个与基本信息度量——二元熵函数 $H_b(p)$ 紧密相关的函数。通过分析函数 $g(p) = \\exp(-H_b(p))$ 的凸性，您不仅能巩固使用二阶导数检验函数形态的技能，还能更深入地理解熵与“确定性”之间的数学关系。[@problem_id:1614169]", "problem": "在信息论中，一个成功概率为 $p$ 的二元随机变量的不确定性由二元熵函数 $H_b(p)$ 来量化，对于 $p \\in (0, 1)$，其定义为：\n$$H_b(p) = -p \\log_{2}(p) - (1-p) \\log_{2}(1-p)$$\n其中对数为以 2 为底的对数。\n\n考虑一个与该二元信源的“确定性”或“纯度”相关的函数 $g(p)$，其定义为：\n$$g(p) = \\exp(-H_b(p))$$\n研究该函数的性质。下列哪个陈述正确地描述了函数 $g(p)$ 在其定义域 $p \\in (0, 1)$ 上的性质？\n\nA. 在区间 $(0, 1)$ 上是严格凸的。\nB. 在区间 $(0, 1)$ 上是严格凹的。\nC. 在区间 $(0, 1)$ 上既是凸的也是凹的。\nD. 在区间 $(0, 1)$ 上既不是严格凸的也不是严格凹的。", "solution": "我们首先用自然对数来重写二元熵。使用换底公式 $\\log_{2}(x) = \\frac{\\ln x}{\\ln 2}$，二元熵为\n$$\nH_{b}(p) = -p \\log_{2}(p) - (1-p) \\log_{2}(1-p) = -\\frac{p \\ln p + (1-p) \\ln(1-p)}{\\ln 2}.\n$$\n因此\n$$\ng(p) = \\exp\\!\\big(-H_{b}(p)\\big) = \\exp\\!\\left(\\frac{p \\ln p + (1-p) \\ln(1-p)}{\\ln 2}\\right).\n$$\n定义 $c = \\frac{1}{\\ln 2} > 0$ 且 $f(p) = p \\ln p + (1-p) \\ln(1-p)$。那么 $g(p) = \\exp\\!\\big(c f(p)\\big)$。\n\n我们计算 $f$ 的导数。求导得，\n$$\nf'(p) = \\frac{d}{dp}\\big(p \\ln p\\big) + \\frac{d}{dp}\\big((1-p)\\ln(1-p)\\big) = (\\ln p + 1) + \\big(-\\ln(1-p) - 1\\big) = \\ln\\!\\left(\\frac{p}{1-p}\\right).\n$$\n再次求导，\n$$\nf''(p) = \\frac{d}{dp}\\left(\\ln p - \\ln(1-p)\\right) = \\frac{1}{p} + \\frac{1}{1-p} = \\frac{1}{p(1-p)}.\n$$\n对于 $p \\in (0,1)$，我们有 $p(1-p) > 0$，因此在 $(0,1)$ 上 $f''(p) > 0$，所以 $f$ 在 $(0,1)$ 上是严格凸的。由于 $c > 0$，函数 $c f$ 在 $(0,1)$ 上也是严格凸的。\n\n现在计算 $g$ 的导数。使用链式法则，\n$$\ng'(p) = \\frac{d}{dp}\\exp\\!\\big(c f(p)\\big) = c f'(p) \\exp\\!\\big(c f(p)\\big) = c f'(p) g(p).\n$$\n再一次求导，\n$$\ng''(p) = c f''(p) g(p) + c f'(p) g'(p) = c f''(p) g(p) + c f'(p)\\big(c f'(p) g(p)\\big) = g(p)\\big(c f''(p) + c^{2} (f'(p))^{2}\\big).\n$$\n对于 $p \\in (0,1)$，我们有 $g(p) > 0$，$c > 0$，以及 $f''(p) = \\frac{1}{p(1-p)} > 0$，同时 $(f'(p))^{2} \\ge 0$。因此，\n$$\ng''(p) = g(p)\\big(c f''(p) + c^{2} (f'(p))^{2}\\big) > 0 \\quad \\text{for all } p \\in (0,1).\n$$\n因此 $g$ 在 $(0,1)$ 上是严格凸的。所以，在给定的选项中，正确的描述是 $g(p)$ 在 $(0,1)$ 上是严格凸的。", "answer": "$$\\boxed{A}$$", "id": "1614169"}, {"introduction": "凸性理论的强大之处不仅在于分析单个函数，更在于它能预测函数组合后的性质。这个实践问题模拟了一个在两种模式下运行的通信系统，其有效信道容量被保守地定义为两种模式容量的最小值。通过确定有效容量 $C_{\\mathrm{eff}}(x)$ 的凹性，您将探索一个关键原则：凹函数的逐点最小值仍然是凹函数，这一性质在资源分配和系统优化问题中至关重要。[@problem_id:1614199]", "problem": "一位通信工程师正在分析一种新的自适应传输协议。该协议可以在两种模式（模式1或模式2）之一中运行，每种模式的理论最大数据速率（信道容量）取决于一个单一的可调功率分配参数 $x$，其中 $x \\ge 0$。\n\n模式1的容量表示为 $C_1(x)$，模式2的容量表示为 $C_2(x)$，由以下函数给出：\n- $C_1(x) = R_1 \\ln(1 + k_1 x)$\n- $C_2(x) = R_2 \\ln(1 + k_2 x)$\n\n其中，$R_1, R_2, k_1,$ 和 $k_2$ 是表征每种模式物理特性的正实数常量。\n\n该协议的一个关键特性是一种故障安全机制。对于给定的功率分配 $x$，系统的保证有效容量 $C_{eff}(x)$ 被保守地定义为两种模式下可实现容量的最小值。\n\n基于此设计，当 $x$ 从0开始增加时，以下哪个陈述正确描述了有效容量 $C_{eff}(x)$ 的边际容量增益（容量相对于功率分配 $x$ 的变化率）的行为？\n\nA. 边际容量增益总是严格递增的。\nB. 边际容量增益总是恒定的。\nC. 边际容量增益是非递增的。\nD. 边际容量增益既可能增加也可能减少，具体取决于 $x$ 的值。\nE. 边际容量增益的行为取决于常量 $R_1, R_2, k_1,$ 和 $k_2$ 的具体值。", "solution": "我们已知两种模式的容量\n$$\nC_{1}(x) = R_{1}\\ln(1 + k_{1} x), \\quad C_{2}(x) = R_{2}\\ln(1 + k_{2} x),\n$$\n其中 $R_{1},R_{2},k_{1},k_{2} > 0$，且有效容量为\n$$\nC_{\\mathrm{eff}}(x) = \\min\\{C_{1}(x),C_{2}(x)\\}, \\quad x \\ge 0.\n$$\n首先，计算每种模式的一阶和二阶导数：\n$$\nC_{i}'(x) = \\frac{R_{i}k_{i}}{1 + k_{i}x} > 0, \\quad C_{i}''(x) = -\\frac{R_{i}k_{i}^{2}}{(1 + k_{i}x)^{2}} < 0, \\quad i \\in \\{1,2\\}.\n$$\n因此，每个 $C_{i}(x)$ 在 $[0,\\infty)$ 上都是递增和凹的，其边际增益 $C_{i}'(x)$ 关于 $x$ 严格递减。\n\n接下来，分析 $C_{\\mathrm{eff}}(x) = \\min\\{C_{1}(x),C_{2}(x)\\}$。由于 $C_{1}$ 和 $C_{2}$ 是凹函数，它们的负数 $-C_{1}$ 和 $-C_{2}$ 是凸函数。凸函数的逐点最大值仍然是凸函数，所以 $\\max\\{-C_{1},-C_{2}\\}$ 是凸的。因此，\n$$\nC_{\\mathrm{eff}}(x) \\;=\\; \\min\\{C_{1}(x),C_{2}(x)\\} \\;=\\; -\\,\\max\\{-C_{1}(x),-C_{2}(x)\\}\n$$\n作为凸函数的负数，在 $[0,\\infty)$ 上是凹的。\n\n一个凹函数具有非递增的边际增益：在可微处，其导数是非递增的；在不可微点（例如，$C_{1}(x) = C_{2}(x)$ 的切换点），左右导数存在且满足 $C_{\\mathrm{eff}}'^{-}(x) \\ge C_{\\mathrm{eff}}'^{+}(x)$。因此，$C_{\\mathrm{eff}}(x)$ 的边际容量增益不会随 $x$ 的增加而增加。\n\n等价地，分段来看，\n$$\nC_{\\mathrm{eff}}'(x)=\n\\begin{cases}\nC_{1}'(x) = \\dfrac{R_{1}k_{1}}{1+k_{1}x}, & \\text{如果 } C_{1}(x) \\le C_{2}(x) \\\\\nC_{2}'(x) = \\dfrac{R_{2}k_{2}}{1+k_{2}x}, & \\text{如果 } C_{2}(x) \\le C_{1}(x)\n\\end{cases}\n$$\n所以在每个区域内它都是严格递减的，并且在任何切换点它都不会向上跳跃。因此，当 $x$ 从0开始增加时，$C_{\\mathrm{eff}}(x)$ 的边际容量增益是非递增的。\n\n因此，正确选项是C。", "answer": "$$\\boxed{C}$$", "id": "1614199"}, {"introduction": "我们最后的练习将带您领略凸性在一个更抽象但极具影响力的领域——估计理论中的应用。当信号的先验分布变化时，我们能达到的最佳估计性能（以最小均方误差 MMSE 来衡量）是如何变化的？本问题揭示了一个深刻的原理：作为优化问题（寻找最佳估计器）结果的 MMSE，其本身是先验分布 $p(x)$ 的一个凹函数。理解这一点对于分析贝叶斯推断和信号处理系统的性能极限至关重要。[@problem_id:1614180]", "problem": "在统计信号处理领域，一个基本问题是在观测到相关随机变量 $Y$ 后，估计一个隐藏随机变量 $X$ 的值。变量 $X$ 和 $Y$ 由一个联合概率分布 $p(x,y)$ 所刻画。一种常见的方法是找到一个估计量，即一个函数 $\\hat{x}(y)$，它能最小化均方误差 (MSE)，其定义为 $MSE(\\hat{x}) = E[(X-\\hat{x}(Y))^2]$。\n\n由最优估计量实现的最小可能均方误差被称为最小均方误差 (MMSE)。MMSE 的值取决于联合分布 $p(x,y)$。让我们考虑一个场景，其中联合分布的形式为 $p(x,y) = p(y|x)p(x)$。我们将条件分布 $p(y|x)$（通常称为“信道”）视为固定的。然而，源的先验分布 $p(x)$ 可以变化。因此，我们可以将 MMSE 视为先验分布的泛函，我们将其记为 $e(p)$。\n\n考虑 $X$ 的两个不同先验分布，记为 $p_1(x)$ 和 $p_2(x)$。我们可以通过对这两个分布进行线性混合来构成一个新的先验分布：\n$$p_\\lambda(x) = \\lambda p_1(x) + (1 - \\lambda) p_2(x)$$\n其中 $\\lambda$ 是一个满足 $0 \\le \\lambda \\le 1$ 的常数。设 $e(p_1)$、$e(p_2)$ 和 $e(p_\\lambda)$ 分别是对于相同的固定信道 $p(y|x)$，与先验 $p_1$、$p_2$ 和 $p_\\lambda$ 相对应的 MMSE 值。\n\n对于 $p_1$、$p_2$、$p(y|x)$ 的任何有效选择以及任何 $\\lambda \\in [0,1]$，以下哪个陈述正确描述了 $e(p_\\lambda)$、$e(p_1)$ 和 $e(p_2)$ 之间的一般关系？\n\nA. $e(p_\\lambda) \\le \\lambda e(p_1) + (1-\\lambda)e(p_2)$\nB. $e(p_\\lambda) \\ge \\lambda e(p_1) + (1-\\lambda)e(p_2)$\nC. $e(p_\\lambda) = \\lambda e(p_1) + (1-\\lambda)e(p_2)$\nD. 这种关系取决于具体的信道 $p(y|x)$，无法一概而论。", "solution": "设信道固定为 $p(y|x)$，并考虑将 $Y$ 映射到 $\\mathbb{R}$ 的估计量 $\\hat{x}$ 的类别。对于给定的先验 $p(x)$，估计量 $\\hat{x}$ 的均方误差（贝叶斯风险）为\n$$\nR(p,\\hat{x}) \\triangleq \\mathbb{E}_{p(x)p(y|x)}\\big[(X-\\hat{x}(Y))^{2}\\big]\n= \\int \\int (x-\\hat{x}(y))^{2} \\, p(y|x)\\, p(x)\\, dx\\, dy.\n$$\n由于积分是线性的，该泛函关于先验 $p(x)$ 是线性的。因此，对于任何 $\\lambda \\in [0,1]$ 和先验 $p_{1},p_{2}$，我们有\n$$\nR(p_{\\lambda},\\hat{x}) = R(\\lambda p_{1} + (1-\\lambda)p_{2},\\hat{x})\n= \\lambda R(p_{1},\\hat{x}) + (1-\\lambda) R(p_{2},\\hat{x}).\n$$\n针对先验 $p$ 的 MMSE 是在所有估计量上取最小的贝叶斯风险，\n$$\ne(p) \\triangleq \\inf_{\\hat{x}} R(p,\\hat{x}).\n$$\n因此，\n$$\ne(p_{\\lambda}) = \\inf_{\\hat{x}} R(p_{\\lambda},\\hat{x})\n= \\inf_{\\hat{x}} \\big[\\lambda R(p_{1},\\hat{x}) + (1-\\lambda) R(p_{2},\\hat{x})\\big].\n$$\n对于任意函数 $f$ 和 $g$ 以及任意 $\\lambda \\in [0,1]$，不等式\n$$\n\\inf_{u} \\big[\\lambda f(u) + (1-\\lambda) g(u)\\big] \\ge \\lambda \\inf_{u} f(u) + (1-\\lambda) \\inf_{u} g(u)\n$$\n成立，因为对于每一个 $u$，都有\n$$\n\\lambda f(u) + (1-\\lambda) g(u) \\ge \\lambda \\inf_{u} f(u) + (1-\\lambda) \\inf_{u} g(u),\n$$\n并且在左侧对 $u$ 取下确界会保留该不等关系。将此结果应用于 $f(\\hat{x})=R(p_{1},\\hat{x})$ 和 $g(\\hat{x})=R(p_{2},\\hat{x})$，可得\n$$\ne(p_{\\lambda}) \\ge \\lambda e(p_{1}) + (1-\\lambda) e(p_{2}).\n$$\n因此，作为先验分布的泛函，MMSE 是凹函数，这与具体的信道 $p(y|x)$ 无关，而正确的关系即为上述不等式。", "answer": "$$\\boxed{B}$$", "id": "1614180"}]}