{"hands_on_practices": [{"introduction": "理论是骨架，实践是血肉。要真正掌握随机变量的期望，最好的方法莫过于亲自动手解决问题。这个练习将带你领略期望线性性的威力，特别是如何巧妙地运用指示随机变量。面对一个看似复杂的组合概率问题，直接计算每种可能结果的概率会非常繁琐，但通过将问题分解为一系列简单的“是/否”事件，我们可以优雅地绕过这些复杂性，直达问题的核心。这个方法不仅高效，更是概率论中一种极为重要的思想工具 [@problem_id:1301081]。", "problem": "在某电视游戏节目中，一位参赛者面前有一堵墙，墙上放有 $N$ 个相同的密封盒子。已知其中正好有 $S$ 个盒子里装有特殊奖品，而剩下的 $N-S$ 个盒子是空的。参赛者被允许选择并打开 $k$ 个不同的盒子，其中 $1 \\le k < S < N$。\n\n参赛者不知道的是，节目制作方增加了一个意外环节。在游戏开始前，他们会秘密地从 $S$ 个有奖的盒子中随机选择一个，并将其指定为“诡雷盒”。来自非诡雷盒的奖品被认为是“安全奖品”。参赛者的策略是从 $N$ 个可用盒子中随机选择 $k$ 个。\n\n设随机变量 $Y$ 表示参赛者在他们选择的 $k$ 个盒子中找到的安全奖品的数量。求 $Y$ 的期望。将你的答案表示为一个关于 $N$、$S$ 和 $k$ 的封闭形式解析表达式。", "solution": "首先，让制作方从 $S$ 个有奖盒子中均匀随机地选择一个作为诡雷盒。选择之后，恰好有 $S-1$ 个盒子包含安全奖品，而剩下的 $N-(S-1)$ 个盒子要么是空的，要么是那个唯一的诡雷盒。\n\n以安全奖品盒子的实现集合 $A$ 为条件。那么 $|A|=S-1$ 是确定性的。参赛者从 $N$ 个盒子中均匀无放回地选择 $k$ 个不同的盒子。对于每个盒子 $i \\in A$，定义指示变量 $I_{i}$，如果盒子 $i$ 被选中，则 $I_{i}$ 等于 $1$，否则等于 $0$。那么\n$$\nY=\\sum_{i \\in A} I_{i}\n$$\n。给定 $A$，在均匀无放回抽样下，每个特定的盒子被选中的概率是 $k/N$，因此对于每个 $i \\in A$，\n$$\n\\mathbb{E}[I_{i}\\mid A]=\\frac{k}{N}\n$$\n。根据期望的线性性，\n$$\n\\mathbb{E}[Y\\mid A]=\\sum_{i \\in A}\\mathbb{E}[I_{i}\\mid A]=(S-1)\\frac{k}{N}\n$$\n。这个条件期望只依赖于 $|A|=S-1$，而与 $A$ 的具体构成无关。应用全期望定律，\n$$\n\\mathbb{E}[Y]=\\mathbb{E}\\big[\\mathbb{E}[Y\\mid A]\\big]=(S-1)\\frac{k}{N}\n$$\n。等价地，$Y$ 服从一个超几何分布，其总体大小为 $N$，成功次数为 $S-1$，抽取次数为 $k$，其均值为 $k(S-1)/N$。", "answer": "$$\\boxed{\\frac{k\\left(S-1\\right)}{N}}$$", "id": "1301081"}, {"introduction": "现在，让我们从离散世界迈向连续领域。许多现实世界的问题，从物理学到工程学，都涉及在某个空间内连续分布的随机变量。这个练习将引导你完成一个典型的建模过程：如何将一个关于几何区域的直观描述（“在圆形晶圆上均匀分布”）转化为一个精确的数学对象——概率密度函数（PDF）。一旦我们获得了PDF，计算期望就变成了一个标准的微积分练习。这个过程训练的关键能力，是从物理直觉出发，构建数学模型来解决实际问题 [@problem_id:1301055]。", "problem": "一个粒子随机落在一个半径为 $R$ 的圆形硅片上。粒子在硅片上的位置是随机的，其位置在整个圆形硅片的面积上服从均匀概率分布。设随机变量 $D$ 表示粒子到硅片中心的距离。求 $D$ 的期望值。将答案表示为关于 $R$ 的解析表达式。", "solution": "设该硅片为平面上一个半径为 $R$ 的圆盘，且粒子的位置在其面积上均匀分布。面积上的均匀分布意味着，在圆盘 $\\{(x,y): x^{2}+y^{2} \\leq R^{2}\\}$ 上的联合概率密度函数为常数 $1/(\\pi R^{2})$，其他地方为零。\n\n定义 $D$ 为到中心的距离，因此 $D = \\sqrt{X^{2}+Y^{2}}$。对于 $0 \\leq d \\leq R$，$D$ 的累积分布函数 $F_{D}(d)$ 是粒子落在半径为 $d$ 的同心圆盘内的概率，该概率等于两个圆盘的面积之比：\n$$\nF_{D}(d) = \\mathbb{P}(D \\leq d) = \\frac{\\pi d^{2}}{\\pi R^{2}} = \\frac{d^{2}}{R^{2}}, \\quad 0 \\leq d \\leq R\n$$\n。对其求导，可得 $D$ 的概率密度函数：\n$$\nf_{D}(d) = \\frac{\\mathrm{d}}{\\mathrm{d}d}F_{D}(d) = \\frac{2d}{R^{2}}, \\quad 0 \\leq d \\leq R\n$$\n。根据连续随机变量的期望定义，计算期望值：\n$$\n\\mathbb{E}[D] = \\int_{0}^{R} d \\, f_{D}(d) \\, \\mathrm{d}d = \\int_{0}^{R} d \\cdot \\frac{2d}{R^{2}} \\, \\mathrm{d}d = \\frac{2}{R^{2}} \\int_{0}^{R} d^{2} \\, \\mathrm{d}d\n$$\n。计算该积分，\n$$\n\\int_{0}^{R} d^{2} \\, \\mathrm{d}d = \\left. \\frac{d^{3}}{3} \\right|_{0}^{R} = \\frac{R^{3}}{3}\n$$\n，所以\n$$\n\\mathbb{E}[D] = \\frac{2}{R^{2}} \\cdot \\frac{R^{3}}{3} = \\frac{2R}{3}\n$$\n。因此，离中心的期望距离为 $\\frac{2R}{3}$。", "answer": "$$\\boxed{\\frac{2R}{3}}$$", "id": "1301055"}, {"introduction": "在掌握了期望的基本计算之后，我们可以进一步探索如何利用期望和方差的深层性质来分析更抽象的系统。本练习以数字信号处理为背景，研究相邻采样点之间的差异。这个练习的精妙之处在于，它展示了我们无需知道随机变量$X_i$的具体分布形式，仅凭其均值$E[X_i] = \\mu$和方差$\\text{Var}(X_i) = \\sigma^2$这两个基本统计量，就能推导出关于信号“粗糙度”的一个重要指标。其结果$2\\sigma^2$简洁而深刻，凸显了期望性质在理论分析中的强大力量 [@problem_id:1622947]。", "problem": "在数字通信系统的设计中，一个信号被建模为一系列测量值，$\\{X_i\\}_{i=1}^{\\infty}$。这些测量值被视为独立同分布（i.i.d.）的随机变量。序列中的每个随机变量 $X_i$ 都有均值 $E[X_i] = \\mu$ 和方差 $\\text{Var}(X_i) = \\sigma^2$。\n\n分析此类信号的高频成分或“粗糙度”的一种常用技术是检验连续样本之间差异的统计特性。这种分析在数据压缩和预测编码等领域是基础性的。\n\n求任意两个相邻样本之间差的平方的期望值，$E[(X_{i+1} - X_i)^2]$。请用 $\\mu$ 和 $\\sigma^2$ 的闭式表达式表示你的答案。", "solution": "我们要求解 $E[(X_{i+1} - X_{i})^{2}]$，其中 $\\{X_{i}\\}$ 是独立同分布的随机变量，且 $E[X_{i}] = \\mu$ 和 $\\text{Var}(X_{i}) = \\sigma^{2}$。展开平方项并求期望：\n$$\nE[(X_{i+1} - X_{i})^{2}] = E[X_{i+1}^{2}] + E[X_{i}^{2}] - 2E[X_{i+1}X_{i}]\n$$\n。使用恒等式 $E[X_{i}^{2}] = \\text{Var}(X_{i}) + (E[X_{i}])^{2} = \\sigma^{2} + \\mu^{2}$，因为变量是同分布的，所以该恒等式对 $X_{i+1}$ 也成立：\n$$\nE[X_{i+1}^{2}] = \\sigma^{2} + \\mu^{2}, \\quad E[X_{i}^{2}] = \\sigma^{2} + \\mu^{2}\n$$\n。因为 $X_{i+1}$ 和 $X_{i}$ 是独立的，所以 $E[X_{i+1}X_{i}] = E[X_{i+1}]E[X_{i}] = \\mu^{2}$。将这些代入展开式中：\n$$\nE[(X_{i+1} - X_{i})^{2}] = (\\sigma^{2} + \\mu^{2}) + (\\sigma^{2} + \\mu^{2}) - 2\\mu^{2} = 2\\sigma^{2}\n$$\n。或者，注意到 $E[X_{i+1} - X_{i}] = \\mu - \\mu = 0$ 且根据独立性 $\\text{Var}(X_{i+1} - X_{i}) = \\text{Var}(X_{i+1}) + \\text{Var}(X_{i}) - 2\\text{Cov}(X_{i+1}, X_{i}) = \\sigma^{2} + \\sigma^{2} - 0 = 2\\sigma^{2}$，因此 $E[(X_{i+1} - X_{i})^{2}] = \\text{Var}(X_{i+1} - X_{i}) + (E[X_{i+1} - X_{i}])^{2} = 2\\sigma^{2}$。", "answer": "$$\\boxed{2\\sigma^{2}}$$", "id": "1622947"}]}