{"hands_on_practices": [{"introduction": "中心极限定理最直接的应用之一，是近似计算独立同分布随机变量之和的概率。本练习将通过一个经典的泊松（Poisson）分布案例，带你实践中心极限定理的基本应用。通过这个练习，你将掌握如何利用正态分布来近似大量随机事件累积效应的分布，这是理解中心极限定理核心思想的坚实一步。[@problem_id:480135]", "problem": "设 $Y_1, Y_2, \\dots$ 是一列独立同分布的随机变量，每个都服从参数为 $\\lambda = 1$ 的泊松分布。对于 $n \\in \\mathbb{N}$，定义部分和 $S_n = \\sum_{k=1}^n Y_k$。使用中心极限定理，近似计算概率 $P(90 \\leq S_{100} \\leq 110)$。给出该近似值的数值，并四舍五入到10位有效数字。", "solution": "1. 对于独立同分布的 $Y_k\\sim\\mathrm{Poisson}(1)$，和 $S_{100}=\\sum_{k=1}^{100}Y_k$ 的均值和方差为\n$$\\mu=\\mathbb{E}[S_{100}]=100\\cdot1=100,\\quad\\sigma^2=\\mathrm{Var}(S_{100})=100\\cdot1=100.$$\n2. 根据中心极限定理，对于 $Z\\sim N(0,1)$，\n$$P(90\\le S_{100}\\le110)\\approx P\\Bigl(\\frac{90-\\mu}{\\sigma}\\le Z\\le\\frac{110-\\mu}{\\sigma}\\Bigr).$$\n3. 计算标准化边界：\n$$\\frac{90-100}{10}=-1,\\quad\\frac{110-100}{10}=1.$$\n4. 因此\n$$P(90\\le S_{100}\\le110)\\approx \\Phi(1)-\\Phi(-1)=2\\Phi(1)-1.$$\n5. 使用 $\\Phi(1)\\approx0.8413447461$ 可得\n$$2\\cdot0.8413447461-1=0.6826894921370859\\approx0.6826894921\\quad(\\text{10 significant digits}).$$", "answer": "$$\\boxed{0.6826894921}$$", "id": "480135"}, {"introduction": "在用连续的正态分布近似离散型随机变量之和时，为了提高近似的精度，我们常常需要进行“连续性校正”。本练习在前一个实践的基础上，引入了这一重要技巧。你将学习如何对一个自定义的离散分布之和进行概率估算，并理解为何连续性校正能够有效减少近似误差，这是进行严谨统计建模的关键一步。[@problem_id:852436]", "problem": "一个离散随机变量 $X$ 的取值集合为 $S = \\{-2, -1, 0, 1, 3\\}$。其概率质量函数 (PMF) 为 $P(X=k) = C(k^2+1)$，其中 $k \\in S$，$C$ 是一个归一化常数。\n\n设 $X_1, X_2, \\dots, X_n$ 是 $n$ 个独立同分布 (i.i.d.) 的随机变量序列，每个变量都与 $X$ 具有相同的分布。考虑它们的和，$S_n = \\sum_{i=1}^n X_i$。\n\n对于 $n=470$，使用带连续性修正的中心极限定理，计算概率 $P(S_{470} > 540)$。\n\n已知对于标准正态随机变量 $Z \\sim N(0,1)$，其在 $z=1.5$ 处的累积分布函数 (CDF) 值为 $\\Phi(1.5) \\approx 0.9331927987$。", "solution": "1. 归一化常数：\n$$\\sum_{k\\in\\{-2,-1,0,1,3\\}}(k^2+1)=5+2+1+2+10=20,\\quad C=\\frac1{20}.$$\n2. 均值：\n$$\\mu=E[X]=C\\sum k\\,(k^2+1)\n=\\frac1{20}(-2\\cdot5-1\\cdot2+0\\cdot1+1\\cdot2+3\\cdot10)\n=\\frac{20}{20}=1.$$\n3. 二阶矩：\n$$E[X^2]=C\\sum k^2\\,(k^2+1)\n=\\frac1{20}(20+2+0+2+90)=\\frac{114}{20}=5.7.$$\n方差：\n$$\\sigma^2=E[X^2]-\\mu^2=5.7-1^2=4.7.$$\n4. 和 $S_{470}$：均值为 $470\\mu=470$，方差为 $470\\sigma^2=470\\cdot4.7=2209$，所以 $\\sigma_{S}=47$。\n5. 连续性修正：\n$$P(S_{470}>540)\\approx P\\bigl(S_{470}>540.5\\bigr)\n= P\\!\\Bigl(Z>\\frac{540.5-470}{47}\\Bigr)\n= P(Z>1.5)=1-\\Phi(1.5)\\approx1-0.9331927987=0.0668072013.$$", "answer": "$$\\boxed{0.0668072013}$$", "id": "852436"}, {"introduction": "中心极限定理的威力远不止于近似求和，它更是统计推断理论的基石。本练习将带你探索中心极限定理的一个强大扩展——德尔塔方法（Delta Method）。我们将运用该方法来分析一个在医学和流行病学研究中至关重要的统计量——对数优势比（log-odds ratio）——的渐近性质，这个实践将揭示中心极限定理如何为评估由数据衍生出的估计量的不确定性提供理论支持。[@problem_id:852421]", "problem": "考虑从两个不同的伯努利总体中抽取的两个独立随机样本，其样本量分别为 $n_1$ 和 $n_2$。第一个总体的成功概率为 $p_1$，第二个总体的成功概率为 $p_2$。设 $X_1$ 和 $X_2$ 分别为在第一个和第二个样本中观测到的成功次数。则样本比例由 $\\hat{p}_1 = \\frac{X_1}{n_1}$ 和 $\\hat{p}_2 = \\frac{X_2}{n_2}$ 给出。\n\n在许多统计分析中，特别是在流行病学和临床试验中，对数优势比是一个具有重要意义的量。真实的对数优势比定义为 $\\theta = \\log\\left(\\frac{p_1/(1-p_1)}{p_2/(1-p_2)}\\right)$。基于样本比例，该量的一个估计量是样本对数优势比：\n$$\n\\hat{\\theta} = \\log\\left(\\frac{\\hat{p}_1/(1-\\hat{p}_1)}{\\hat{p}_2/(1-\\hat{p}_2)}\\right)\n$$\n假设样本量 $n_1$ 和 $n_2$ 足够大，中心极限定理可以通过Delta方法进行扩展，以求出 $\\hat{\\theta}$ 的近似分布。\n\n推导对数优势比估计量 $\\text{Var}(\\hat{\\theta})$ 的渐近方差。", "solution": "问题要求解对数优势比估计量 $\\hat{\\theta}$ 的渐近方差。我们可以使用多元Delta方法来求解。\n\n首先，根据中心极限定理，对于大样本量 $n_1$ 和 $n_2$，样本比例 $\\hat{p}_1$ 和 $\\hat{p}_2$ 近似服从正态分布：\n$$\n\\hat{p}_1 \\approx N\\left(p_1, \\frac{p_1(1-p_1)}{n_1}\\right)\n$$\n$$\n\\hat{p}_2 \\approx N\\left(p_2, \\frac{p_2(1-p_2)}{n_2}\\right)\n$$\n由于两个样本是独立的，随机变量 $\\hat{p}_1$ 和 $\\hat{p}_2$ 也是独立的。因此，样本比例向量 $\\hat{\\mathbf{p}} = (\\hat{p}_1, \\hat{p}_2)^T$ 服从渐近二元正态分布，其均值向量为 $\\boldsymbol{\\mu}$，协方差矩阵为 $\\boldsymbol{\\Sigma}$：\n$$\n\\boldsymbol{\\mu} = E[\\hat{\\mathbf{p}}] = \\begin{pmatrix} p_1 \\\\ p_2 \\end{pmatrix}\n$$\n$$\n\\boldsymbol{\\Sigma} = \\text{Cov}(\\hat{\\mathbf{p}}) = \\begin{pmatrix} \\text{Var}(\\hat{p}_1) & \\text{Cov}(\\hat{p}_1, \\hat{p}_2) \\\\ \\text{Cov}(\\hat{p}_1, \\hat{p}_2) & \\text{Var}(\\hat{p}_2) \\end{pmatrix} = \\begin{pmatrix} \\frac{p_1(1-p_1)}{n_1} & 0 \\\\ 0 & \\frac{p_2(1-p_2)}{n_2} \\end{pmatrix}\n$$\n估计量 $\\hat{\\theta}$ 是 $\\hat{p}_1$ 和 $\\hat{p}_2$ 的函数。设该函数为 $g(x, y)$：\n$$\ng(x, y) = \\log\\left(\\frac{x/(1-x)}{y/(1-y)}\\right) = \\log(x) - \\log(1-x) - \\log(y) + \\log(1-y)\n$$\n多元Delta方法表明，函数 $g(\\hat{\\mathbf{p}})$ 的渐近方差由下式给出：\n$$\n\\text{Var}(g(\\hat{\\mathbf{p}})) \\approx (\\nabla g(\\boldsymbol{\\mu}))^T \\boldsymbol{\\Sigma} (\\nabla g(\\boldsymbol{\\mu}))\n$$\n其中 $\\nabla g(\\boldsymbol{\\mu})$ 是函数 $g$ 在均值向量 $\\boldsymbol{\\mu} = (p_1, p_2)^T$ 处求得的梯度。\n\n首先，我们计算 $g(x, y)$ 的梯度：\n$$\n\\frac{\\partial g}{\\partial x} = \\frac{1}{x} - \\frac{1}{1-x}(-1) = \\frac{1}{x} + \\frac{1}{1-x} = \\frac{1-x+x}{x(1-x)} = \\frac{1}{x(1-x)}\n$$\n$$\n\\frac{\\partial g}{\\partial y} = -\\frac{1}{y} + \\frac{1}{1-y}(-1) = -\\frac{1}{y} - \\frac{1}{1-y} = -\\frac{1-y+y}{y(1-y)} = -\\frac{1}{y(1-y)}\n$$\n所以梯度向量为 $\\nabla g(x,y) = \\left(\\frac{1}{x(1-x)}, -\\frac{1}{y(1-y)}\\right)^T$。\n\n接下来，我们在均值 $\\boldsymbol{\\mu} = (p_1, p_2)^T$ 处计算梯度：\n$$\n\\nabla g(\\boldsymbol{\\mu}) = \\begin{pmatrix} \\frac{1}{p_1(1-p_1)} \\\\ -\\frac{1}{p_2(1-p_2)} \\end{pmatrix}\n$$\n现在，我们可以将梯度和协方差矩阵代入Delta方法的方差公式中：\n$$\n\\text{Var}(\\hat{\\theta}) \\approx \n\\begin{pmatrix} \\frac{1}{p_1(1-p_1)} & -\\frac{1}{p_2(1-p_2)} \\end{pmatrix}\n\\begin{pmatrix} \\frac{p_1(1-p_1)}{n_1} & 0 \\\\ 0 & \\frac{p_2(1-p_2)}{n_2} \\end{pmatrix}\n\\begin{pmatrix} \\frac{1}{p_1(1-p_1)} \\\\ -\\frac{1}{p_2(1-p_2)} \\end{pmatrix}\n$$\n我们从左到右进行矩阵乘法。首先，将行向量（梯度的转置）与协方差矩阵相乘：\n$$\n\\begin{pmatrix} \\frac{1}{p_1(1-p_1)} \\cdot \\frac{p_1(1-p_1)}{n_1} + (-\\frac{1}{p_2(1-p_2)}) \\cdot 0 & \\frac{1}{p_1(1-p_1)} \\cdot 0 + (-\\frac{1}{p_2(1-p_2)}) \\cdot \\frac{p_2(1-p_2)}{n_2} \\end{pmatrix}\n$$\n$$\n= \\begin{pmatrix} \\frac{1}{n_1} & -\\frac{1}{n_2} \\end{pmatrix}\n$$\n最后，将得到的行向量与列向量（梯度）相乘：\n$$\n\\text{Var}(\\hat{\\theta}) \\approx \\begin{pmatrix} \\frac{1}{n_1} & -\\frac{1}{n_2} \\end{pmatrix} \\begin{pmatrix} \\frac{1}{p_1(1-p_1)} \\\\ -\\frac{1}{p_2(1-p_2)} \\end{pmatrix}\n$$\n$$\n= \\left(\\frac{1}{n_1}\\right) \\left(\\frac{1}{p_1(1-p_1)}\\right) + \\left(-\\frac{1}{n_2}\\right) \\left(-\\frac{1}{p_2(1-p_2)}\\right)\n$$\n$$\n= \\frac{1}{n_1 p_1 (1-p_1)} + \\frac{1}{n_2 p_2 (1-p_2)}\n$$\n这就是对数优势比估计量的渐近方差。", "answer": "$$\n\\boxed{\\frac{1}{n_1 p_1 (1-p_1)} + \\frac{1}{n_2 p_2 (1-p_2)}}\n$$", "id": "852421"}]}