{"hands_on_practices": [{"introduction": "理解强大数定律 (SLLN) 的最好方法莫过于亲手实践。这个练习将引导你直接应用该定律的核心思想。通过计算一个具有特定概率密度函数 (PDF) 的独立同分布 (i.i.d.) 随机变量序列的长期平均值，你将能够具体地看到样本均值是如何几乎必然地收敛到其理论期望值的，从而夯实你对这一定理的基本理解 [@problem_id:1460774]。", "problem": "一个研究团队正在研究一种新型信号处理器的输出。处理器每次运行时，都会生成一个归一化值，该值可被建模为一个随机变量。这些值的一个序列，$X_1, X_2, X_3, \\dots$，被记录下来。这些值被认为是独立同分布 (i.i.d.) 的随机变量。任何单个值 $X_i$ 的概率分布的理论模型由以下概率密度函数 (PDF) 描述：\n$$\nf(x) = \\begin{cases} 3x^2 & \\text{对于 } 0 \\le x \\le 1 \\\\ 0 & \\text{其他情况} \\end{cases}\n$$\n经过 $n$ 次试验后，这些测量的长期平均值由样本均值 $S_n = \\frac{1}{n}\\sum_{i=1}^{n} X_i$ 给出。当试验次数 $n$ 趋于无穷大时，$S_n$ 的值将几乎必然地收敛到一个特定的常数。\n\n确定这个常数的值。将你的答案表示为最简分数形式。", "solution": "给定独立同分布的随机变量 $X_{1},X_{2},\\dots$，其共同的密度函数为\n$$\nf(x)=\\begin{cases}\n3x^{2}, & 0\\le x\\le 1,\\\\\n0, & \\text{其他情况。}\n\\end{cases}\n$$\n首先，通过检查其归一性来验证 $f$ 是一个有效的概率密度函数：\n$$\n\\int_{-\\infty}^{\\infty} f(x)\\,dx=\\int_{0}^{1}3x^{2}\\,dx=3\\left[\\frac{x^{3}}{3}\\right]_{0}^{1}=1.\n$$\n根据强大数定律，由于 $X_{i}$ 是独立同分布且具有有限期望 $E[|X_{1}|]<\\infty$（因为 $0\\le X_{1}\\le 1$ 几乎必然成立，所以该条件满足），样本均值\n$$\nS_{n}=\\frac{1}{n}\\sum_{i=1}^{n}X_{i}\n$$\n当 $n\\to\\infty$ 时，几乎必然收敛于 $E[X_{1}]$。\n\n计算期望：\n$$\nE[X_{1}]=\\int_{-\\infty}^{\\infty} x f(x)\\,dx=\\int_{0}^{1} x\\cdot 3x^{2}\\,dx=3\\int_{0}^{1} x^{3}\\,dx=3\\left[\\frac{x^{4}}{4}\\right]_{0}^{1}=\\frac{3}{4}.\n$$\n因此，\n$$\n\\lim_{n\\to\\infty} S_{n}=\\frac{3}{4}\\quad \\text{几乎必然}。\n$$", "answer": "$$\\boxed{\\frac{3}{4}}$$", "id": "1460774"}, {"introduction": "掌握了基本应用后，我们可以探索一些更微妙的场景。强大数定律的威力并不仅限于原始的随机变量序列，它同样适用于这些变量的函数。本练习将探讨如何处理一个由原始数据变换而来的新序列 $Y_i = g(X_i)$，并强调了在应用定律之前，验证新序列满足有限期望值 $E[|Y_1|] < \\infty$ 这一条件的重要性 [@problem_id:1957052]。", "problem": "一个研究团队正在研究一种新发现的微生物所释放的能量。在一个短暂的观察期内，单个微生物释放的能量是一个随机变量。该团队进行了一系列独立实验，每个实验都测量来自一个新的、随机选取的微生物的能量释放 $X_i$。这些测量值 $X_1, X_2, X_3, \\dots$ 可以被建模为一个独立同分布 (i.i.d.) 的正随机变量序列。根据理论模型可知，期望能量释放是有限的，即 $E[X_i] = \\mu$，其中 $\\mu > 0$ 是某个有限常数。\n\n对于一项数据处理任务，一位分析师对能量本身不感兴趣，而是对一个相关的量 $Y_i = \\sqrt{X_i}$ 感兴趣。该分析师计算了这 $n$ 次实验中这些变换后的量的样本均值：\n$$S_n = \\frac{1}{n}\\sum_{i=1}^n Y_i = \\frac{1}{n}\\sum_{i=1}^n \\sqrt{X_i}$$\n当实验次数 $n$ 趋于无穷大时，样本均值 $S_n$ 几乎必然收敛到什么值？请用随机变量 $X_1$ 来表示你的答案。", "solution": "问题要求解当 $n \\to \\infty$ 时，样本均值 $S_n = \\frac{1}{n}\\sum_{i=1}^n \\sqrt{X_i}$ 的几乎必然极限。\n\n我们定义一个新的随机变量序列 $Y_i = \\sqrt{X_i}$，其中 $i=1, 2, 3, \\dots$。因为随机变量 $X_1, X_2, \\dots$ 是独立同分布 (i.i.d.) 的，所以随机变量 $Y_1 = \\sqrt{X_1}, Y_2 = \\sqrt{X_2}, \\dots$ 也是独立同分布的。这是因为独立同分布随机变量的任何函数都会产生一个新的独立同分布随机变量序列。\n\n样本均值可以被重写为用 $Y_i$ 变量表示的形式：\n$$S_n = \\frac{1}{n}\\sum_{i=1}^n Y_i$$\n这就是独立同分布序列 $Y_i$ 的样本均值。\n\n我们可以对序列 $\\{Y_i\\}$ 应用强大数定律 (SLLN)。SLLN 指出，如果 $Y_1, Y_2, \\dots$ 是一个期望值有限的独立同分布随机变量序列，即 $E[|Y_1|] < \\infty$，那么样本均值几乎必然收敛于真实均值：\n$$\\frac{1}{n}\\sum_{i=1}^n Y_i \\xrightarrow{\\text{a.s.}} E[Y_1] \\quad \\text{as } n \\to \\infty$$\n\n为了应用 SLLN，我们必须验证 $E[|Y_1|]$ 是有限的。\n我们有 $Y_1 = \\sqrt{X_1}$。问题中说明 $X_i$ 是正随机变量，因此 $X_1 > 0$。这意味着 $\\sqrt{X_1}$ 是一个正实数，所以 $|Y_1| = |\\sqrt{X_1}| = \\sqrt{X_1}$。我们需要检验 $E[\\sqrt{X_1}]$ 是否有限。\n\n我们可以使用琴生不等式（Jensen's inequality）将 $E[\\sqrt{X_1}]$ 与已知的有限均值 $E[X_1] = \\mu$ 联系起来。对于一个凹函数 $g(x)$ 和一个随机变量 $X$，琴生不等式表明 $E[g(X)] \\le g(E[X])$。\n\n函数 $g(x) = \\sqrt{x}$ 对于 $x > 0$ 是一个凹函数。这可以通过检验其二阶导数来证明：\n$g'(x) = \\frac{1}{2}x^{-1/2}$\n$g''(x) = -\\frac{1}{4}x^{-3/2}$\n由于 $x > 0$，我们有 $g''(x) < 0$，这证实了 $g(x) = \\sqrt{x}$ 是严格凹函数。\n\n对函数 $g(x) = \\sqrt{x}$ 和随机变量 $X_1$ 应用琴生不等式，我们得到：\n$$E[\\sqrt{X_1}] \\le \\sqrt{E[X_1]}$$\n问题中说明 $E[X_1] = \\mu$，且 $\\mu$ 是一个有限的正数。因此，\n$$E[\\sqrt{X_1}] \\le \\sqrt{\\mu}$$\n由于 $\\mu$ 是有限的，$\\sqrt{\\mu}$ 也是有限的。这表明 $E[\\sqrt{X_1}]$ 是有限的。\n因为 $Y_1 = \\sqrt{X_1}$ 是一个正随机变量，我们有 $E[|Y_1|] = E[Y_1] = E[\\sqrt{X_1}]$，这一项是有限的。\n\n序列 $\\{Y_i\\}$ 满足 SLLN 的条件。因此，我们可以得出结论，样本均值 $S_n$ 几乎必然收敛于 $Y_1$ 的期望：\n$$\\lim_{n \\to \\infty} S_n = \\lim_{n \\to \\infty} \\frac{1}{n}\\sum_{i=1}^n Y_i \\xrightarrow{\\text{a.s.}} E[Y_1]$$\n代回 $Y_1 = \\sqrt{X_1}$，我们得到极限：\n$$\\lim_{n \\to \\infty} S_n \\xrightarrow{\\text{a.s.}} E[\\sqrt{X_1}]$$\n问题要求的是 $S_n$ 几乎必然收敛到的值。这个值是 $E[\\sqrt{X_1}]$。", "answer": "$$\\boxed{E[\\sqrt{X_1}]}$$", "id": "1957052"}, {"introduction": "现实世界的数据往往存在某种形式的依赖性，这超出了经典独立同分布的假设。这个练习向我们提出了一个挑战：一个序列中的每一项都与其相邻项相关，这意味着这些变量不再是相互独立的。然而，通过一个巧妙的分解技巧，我们仍然可以利用强大数定律的力量，这展示了一种强大的解决问题的策略，将该定律的应用范围扩展到更复杂的情形中 [@problem_id:1460782]。", "problem": "考虑一个定义在共同概率空间上的独立同分布 (i.i.d.) 随机变量序列 $\\{X_n\\}_{n=1}^{\\infty}$。这些变量的特征是，对于所有 $n \\ge 1$，其均值为 $E[X_n] = 0$，二阶矩为 $E[X_n^2] = 1$。\n\n我们构造一个新的样本均值序列，对于 $n \\ge 2$，定义为\n$$A_n = \\frac{1}{n} \\sum_{i=1}^{n-1} X_i X_{i+1}$$\n\n确定当 $n$ 趋于无穷时，序列 $A_n$ 几乎必然收敛到的值。", "solution": "定义 $Y_{i} = X_{i}X_{i+1}$，其中 $i \\ge 1$。那么对于 $n \\ge 2$，$A_{n} = \\frac{1}{n} \\sum_{i=1}^{n-1} Y_{i}$。根据 $X_{i}$ 的独立性和同分布性，每个 $Y_{i}$ 都具有相同的分布，其中\n$$\nE[Y_{i}] = E[X_{i}X_{i+1}] = E[X_{i}]\\,E[X_{i+1}] = 0,\n$$\n且\n$$\nE[Y_{i}^{2}] = E[X_{i}^{2}X_{i+1}^{2}] = E[X_{i}^{2}]\\,E[X_{i+1}^{2}] = 1.\n$$\n因此，根据 Cauchy–Schwarz 不等式，$E[|Y_{i}|] \\le \\sqrt{E[Y_{i}^{2}]} = 1$，所以 $Y_{i}$ 是可积的。\n\n接下来，观察其相依结构：族 $\\{Y_{i}\\}_{i \\ge 1}$ 是 1-相依的，更具体地说，子序列 $\\{Y_{2j-1}\\}_{j \\ge 1}$ 和 $\\{Y_{2j}\\}_{j \\ge 1}$ 由独立的随机变量组成，因为它们依赖于独立变量 $X_{i}$ 的不相交集合。此外，每个子序列都服从同一分布，其均值为 $0$ 且具有有限二阶矩。根据分别应用于每个子序列的 Kolmogorov 强大数定律，\n$$\n\\frac{1}{k} \\sum_{j=1}^{k} Y_{2j-1} \\to 0 \\quad \\text{a.s.}, \n\\qquad\n\\frac{1}{k} \\sum_{j=1}^{k} Y_{2j} \\to 0 \\quad \\text{a.s.}\n$$\n\n对于每个 $n \\ge 2$，令 $N_{o}(n)$ 为 $\\{1,\\dots,n-1\\}$ 中奇数索引的个数，$N_{e}(n)$ 为 $\\{1,\\dots,n-1\\}$ 中偶数索引的个数。则 $N_{o}(n) + N_{e}(n) = n-1$，其中 $N_{o}(n) = \\lceil (n-1)/2 \\rceil$ 且 $N_{e}(n) = \\lfloor (n-1)/2 \\rfloor$，因此当 $n \\to \\infty$ 时，$N_{o}(n)/n \\to \\frac{1}{2}$ 和 $N_{e}(n)/n \\to \\frac{1}{2}$ 是确定性的。将 $A_{n}$ 分解为\n$$\nA_{n} \n= \\frac{1}{n} \\sum_{i=1}^{n-1} Y_{i}\n= \\frac{N_{o}(n)}{n} \\left( \\frac{1}{N_{o}(n)} \\sum_{j=1}^{N_{o}(n)} Y_{2j-1} \\right)\n+ \\frac{N_{e}(n)}{n} \\left( \\frac{1}{N_{e}(n)} \\sum_{j=1}^{N_{e}(n)} Y_{2j} \\right).\n$$\n当 $n \\to \\infty$ 时，我们有 $N_{o}(n) \\to \\infty$ 和 $N_{e}(n) \\to \\infty$，因此根据子序列平均值的几乎必然极限和权重的确定性极限，可以得出 $A_{n} \\to 0$ 几乎必然成立。\n\n因此，序列 $A_{n}$ 几乎必然收敛到 $0$。", "answer": "$$\\boxed{0}$$", "id": "1460782"}]}