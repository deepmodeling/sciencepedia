{"hands_on_practices": [{"introduction": "我们从一个基础练习开始，这个练习将帮助我们巩固条件熵的定义。想象一个标准的骰子，它的结果是随机的，但我们只能得知结果是奇数还是偶数；此练习要求我们量化在获得这个奇偶性信息后，对于骰子具体点数仍然存在的不确定性 [@problem_id:1612385]。通过这个直接的计算，你将能够亲身体会条件熵是如何衡量“已知部分信息后剩余的不确定性”的。", "problem": "考虑一个标准的、公平的六面骰子。设随机变量 $X$ 表示该骰子单次投掷的结果，因此其可能值的集合为 $\\{1, 2, 3, 4, 5, 6\\}$，每个结果都是等可能的。第二个随机变量 $Y$ 由 $X$ 的奇偶性决定。具体来说，如果结果 $X$ 是偶数，则 $Y$ 取值为0；如果结果 $X$ 是奇数，则 $Y$ 取值为1。\n\n进行一个实验，投掷骰子，但只告知您 $Y$ 的值（即，只告知您结果是偶数还是奇数）。我们关心的是，在揭示了奇偶性信息 $Y$ 之后，关于具体结果 $X$ 仍然存在的不确定性的大小。\n\n计算关于结果 $X$ 的这个剩余平均不确定性。以比特（bit）为单位表示您的答案，这意味着所有熵的计算都使用以2为底的对数。将您的答案表示为单个闭式解析表达式。", "solution": "设 $X$ 在 $\\{1,2,3,4,5,6\\}$ 上均匀分布，因此对每个 $k$，$P(X=k)=\\frac{1}{6}$。设 $Y$ 为 $X$ 的奇偶性，当 $X\\in\\{2,4,6\\}$ 时 $Y=0$，当 $X\\in\\{1,3,5\\}$ 时 $Y=1$。由于三个偶数结果和三个奇数结果都是等可能的，我们有\n$$\nP(Y=0)=\\sum_{x\\in\\{2,4,6\\}}P(X=x)=3\\cdot\\frac{1}{6}=\\frac{1}{2},\\quad P(Y=1)=\\frac{1}{2}.\n$$\n因为 $Y$ 是 $X$ 的一个确定性函数，对于 $y\\in\\{0,1\\}$ 以及与 $y$ 一致的 $x$ 有，\n$$\nP(X=x\\mid Y=y)=\\frac{P(X=x, Y=y)}{P(Y=y)}=\\frac{P(X=x)}{P(Y=y)}=\\frac{\\frac{1}{6}}{\\frac{1}{2}}=\\frac{1}{3},\n$$\n否则 $P(X=x\\mid Y=y)=0$。因此，在给定 $Y=y$ 的条件下，$X$ 在一个包含三个结果的集合上是均匀分布的。\n\n给定 $Y=y$ 的条件熵是\n$$\nH(X\\mid Y=y)=-\\sum_{x}P(X=x\\mid Y=y)\\log_{2}\\bigl(P(X=x\\mid Y=y)\\bigr)\n=-3\\cdot\\frac{1}{3}\\log_{2}\\!\\left(\\frac{1}{3}\\right)=\\log_{2}(3).\n$$\n平均剩余不确定性就是条件熵\n$$\nH(X\\mid Y)=\\sum_{y\\in\\{0,1\\}}P(Y=y)\\,H(X\\mid Y=y)\n=\\frac{1}{2}\\log_{2}(3)+\\frac{1}{2}\\log_{2}(3)=\\log_{2}(3).\n$$\n因此，在观测到 $Y$ 之后，关于 $X$ 的剩余平均不确定性为 $\\log_{2}(3)$ 比特。", "answer": "$$\\boxed{\\log_{2}(3)}$$", "id": "1612385"}, {"introduction": "在下一个练习中，我们将探讨一个稍微复杂但更具启发性的场景。假设我们已知两个独立随机比特的和，但不知道每个比特的具体值，这个练习 [@problem_id:1612398] 的巧妙之处在于，我们收到的信息（即它们的和）在不同情况下提供的信息量是不同的：有时它能完全消除不确定性，而有时则不能。通过解决这个问题，你将深刻理解为何条件熵 $H(X|Y)$ 被定义为一种对所有可能条件下的剩余不确定性的“平均值”。", "problem": "考虑两个独立的二进制信源，信源1和信源2。信源1产生一个随机变量 $X$，信源2产生一个随机变量 $Y$。$X$ 和 $Y$ 都在集合 ${0, 1}$ 中取值，且 $P(X=1) = P(X=0) = \\frac{1}{2}$ 以及 $P(Y=1) = P(Y=0) = \\frac{1}{2}$。\n\n一位观察者无法获取单个输出 $X$ 和 $Y$。该观察者只知道它们的和 $S = X+Y$ 的值。\n\n计算在 $S$ 的值被揭示后，关于 $X$ 的值的平均不确定性。请用单位为比特的单个实数表示你的最终答案。", "solution": "题目要求我们计算在观察到 $S=X+Y$ 后关于 $X$ 的平均不确定性，也就是以比特为单位的条件熵 $H(X|S)$。在整个计算过程中，我们使用以2为底的对数，记作 $\\log_{2}$。\n\n给定 $X,Y \\in \\{0,1\\}$，相互独立且 $P(X=1)=P(X=0)=\\frac{1}{2}$ 及 $P(Y=1)=P(Y=0)=\\frac{1}{2}$，其和 $S=X+Y$ 在集合 $\\{0,1,2\\}$ 中取值，概率分布为\n$$\nP(S=0)=P(X=0,Y=0)=\\frac{1}{4},\\quad P(S=2)=P(X=1,Y=1)=\\frac{1}{4},\\quad P(S=1)=\\frac{1}{2}.\n$$\n我们通过以下公式计算 $H(X|S)$：\n$$\nH(X|S)=\\sum_{s\\in\\{0,1,2\\}} P(S=s)\\,H(X|S=s).\n$$\n对于 $s=0$，事件 $S=0$ 意味着 $(X,Y)=(0,0)$，因此 $P(X=0|S=0)=1$ 且\n$$\nH(X|S=0)=-\\left(1\\cdot \\log_{2}1\\right)=0.\n$$\n对于 $s=2$，事件 $S=2$ 意味着 $(X,Y)=(1,1)$，因此 $P(X=1|S=2)=1$ 且\n$$\nH(X|S=2)=0.\n$$\n对于 $s=1$，事件 $S=1$ 对应 $(X,Y)=(1,0)$ 或 $(0,1)$。利用独立性，\n$$\nP(X=1,S=1)=P(X=1,Y=0)=\\frac{1}{4},\\quad P(S=1)=\\frac{1}{2},\n$$\n所以\n$$\nP(X=1|S=1)=\\frac{P(X=1,S=1)}{P(S=1)}=\\frac{\\frac{1}{4}}{\\frac{1}{2}}=\\frac{1}{2},\\quad P(X=0|S=1)=\\frac{1}{2}.\n$$\n因此\n$$\nH(X|S=1)=-\\left(\\frac{1}{2}\\log_{2}\\frac{1}{2}+\\frac{1}{2}\\log_{2}\\frac{1}{2}\\right)=1.\n$$\n因此，\n$$\nH(X|S)=P(S=0)\\cdot 0+P(S=1)\\cdot 1+P(S=2)\\cdot 0=\\frac{1}{2}\\ \\text{bits}.\n$$", "answer": "$$\\boxed{\\frac{1}{2}}$$", "id": "1612398"}, {"introduction": "最后，让我们将所学知识应用到一个著名的概率谜题——蒙提霍尔问题上。这个问题以其反直觉的结论而闻名，常常使人感到困惑。在这个练习中 [@problem_id:1612388]，我们将运用条件熵的框架，精确地计算当主持人打开一扇藏有山羊的门后，关于汽车位置的剩余不确定性 $H(C|H)$ 是多少。这不仅是一个有趣的挑战，更展示了信息论工具在复杂、不确定的情况下进行严谨推理的强大能力。", "problem": "考虑一个经典的电视游戏节目问题的变体，旨在探讨信息的流动。有三扇相同且关闭的门：1号门、2号门和3号门。一扇门后是一辆昂贵的汽车，另外两扇门后是山羊。汽车的放置是随机的，每扇门后面藏有汽车的概率相等。\n\n您，作为参赛者，做出初始选择并选中1号门。\n\n知道汽车位置的主持人，接着会打开剩下的两扇门（2号门或3号门）中的一扇，露出一只山羊。主持人的策略如下：如果汽车在您选择的门（1号门）后面，主持人会以相等的概率打开另外两扇门（2号门或3号门）中的一扇。如果汽车不在您选择的门后面，主持人则必须打开唯一剩下的那扇藏有山羊的门。\n\n设 $C$ 为表示藏有汽车的门号的随机变量，其可能的结果为 $\\{1, 2, 3\\}$。设 $H$ 为表示主持人打开的门号的随机变量，其可能的结果为 $\\{2, 3\\}$。\n\n计算条件熵 $H(C|H)$，它量化了在您观察到主持人的行为后，关于汽车位置的平均剩余不确定性。请用一个解析表达式以比特为单位表示您的答案。请注意，信息论计算使用以2为底的对数。", "solution": "设 $C \\in \\{1,2,3\\}$ 为汽车所在的门，对于每个 $c$，$P(C=c)=\\frac{1}{3}$，并设 $H \\in \\{2,3\\}$ 为主持人打开的门。主持人的策略意味着以下条件概率：\n$$\nP(H=2 \\mid C=1)=\\frac{1}{2}, \\quad P(H=3 \\mid C=1)=\\frac{1}{2}, \\quad P(H=2 \\mid C=2)=0, \\quad P(H=3 \\mid C=2)=1,\n$$\n$$\nP(H=2 \\mid C=3)=1, \\quad P(H=3 \\mid C=3)=0.\n$$\n根据全概率定律，\n$$\nP(H=2)=\\sum_{c=1}^{3} P(H=2 \\mid C=c)P(C=c)=\\frac{1}{2}\\cdot \\frac{1}{3}+0\\cdot \\frac{1}{3}+1\\cdot \\frac{1}{3}=\\frac{1}{2},\n$$\n同样地，$P(H=3)=\\frac{1}{2}$。\n\n使用贝叶斯法则，对于 $H=2$，\n$$\nP(C=1 \\mid H=2)=\\frac{P(H=2 \\mid C=1)P(C=1)}{P(H=2)}=\\frac{\\frac{1}{2}\\cdot \\frac{1}{3}}{\\frac{1}{2}}=\\frac{1}{3}, \\quad\nP(C=3 \\mid H=2)=\\frac{1\\cdot \\frac{1}{3}}{\\frac{1}{2}}=\\frac{2}{3}, \\quad\nP(C=2 \\mid H=2)=0.\n$$\n根据对称性，对于 $H=3$，\n$$\nP(C=1 \\mid H=3)=\\frac{1}{3}, \\quad P(C=2 \\mid H=3)=\\frac{2}{3}, \\quad P(C=3 \\mid H=3)=0.\n$$\n\n条件熵为\n$$\nH(C \\mid H)=\\sum_{h \\in \\{2,3\\}} P(H=h)\\left(-\\sum_{c \\in \\{1,2,3\\}} P(C=c \\mid H=h)\\log_{2} P(C=c \\mid H=h)\\right),\n$$\n根据约定，由连续性可知 $0\\log_{2} 0=0$。对于每个 $h$， $C$ 的后验概率分布是 $\\left(\\frac{1}{3},\\frac{2}{3},0\\right)$（不考虑排列顺序），因此\n$$\nH(C \\mid H)=\\frac{1}{2}\\left(-\\frac{1}{3}\\log_{2}\\frac{1}{3}-\\frac{2}{3}\\log_{2}\\frac{2}{3}\\right)+\\frac{1}{2}\\left(-\\frac{1}{3}\\log_{2}\\frac{1}{3}-\\frac{2}{3}\\log_{2}\\frac{2}{3}\\right)\n=-\\frac{1}{3}\\log_{2}\\frac{1}{3}-\\frac{2}{3}\\log_{2}\\frac{2}{3}.\n$$\n使用 $\\log_{2}\\left(\\frac{1}{3}\\right)=-\\log_{2} 3$ 和 $\\log_{2}\\left(\\frac{2}{3}\\right)=1-\\log_{2} 3$ 进行简化，\n$$\n-\\frac{1}{3}\\left(-\\log_{2} 3\\right)-\\frac{2}{3}\\left(1-\\log_{2} 3\\right)=\\log_{2} 3-\\frac{2}{3}.\n$$\n因此，以比特为单位的条件熵是 $\\log_{2}(3)-\\frac{2}{3}$。", "answer": "$$\\boxed{\\log_{2}(3)-\\frac{2}{3}}$$", "id": "1612388"}]}