{"hands_on_practices": [{"introduction": "信息率失真理论的核心在于量化压缩的极限。这个练习将带你从最基础、也最重要的例子入手：一个简单的伯努利（Bernoulli）信源，比如抛硬币序列，以及最直观的失真度量——汉明（Hamming）失真，也即误码率。通过解决这个问题[@problem_id:1652137]，你将推导出著名的率失真函数表达式$R(D) = H(p) - H(D)$，这是理解有损压缩理论的基石。", "problem": "考虑一个离散无记忆信源，它从符号集 $\\mathcal{X} = \\{0, 1\\}$ 中产生二元符号 $X$。产生 '1' 的概率为 $P(X=1) = p$，产生 '0' 的概率为 $P(X=0) = 1-p$。为简单起见，假设 $0 < p \\le 1/2$。我们希望压缩该信源的输出，并用来自相同符号集 $\\hat{\\mathcal{X}} = \\{0, 1\\}$ 的符号 $\\hat{X}$ 来表示它。\n\n压缩的质量由单符号汉明失真来衡量，定义为：如果 $x = \\hat{x}$，则 $d(x, \\hat{x}) = 0$；如果 $x \\neq \\hat{x}$，则 $d(x, \\hat{x}) = 1$。平均失真记为 $D = E[d(X, \\hat{X})]$。\n\n率失真函数 $R(D)$ 给出了在给定最大平均失真 $D$ 的条件下，可实现的最小速率（单位：比特/符号）。求此信源在速率非零区域的率失真函数 $R(D)$ 的表达式。你的最终答案应该用二元熵函数 $H(y) = -y \\log_2(y) - (1-y)\\log_2(1-y)$ 来表示，并且可能包含参数 $p$ 和 $D$。", "solution": "率失真函数 $R(D)$ 定义为，在所有满足平均失真 $E[d(X, \\hat{X})] \\le D$ 的联合分布 $p(x, \\hat{x})$ 上，信源 $X$ 和重构 $\\hat{X}$ 之间的最小可能互信息 $I(X; \\hat{X})$。\n$$R(D) = \\min_{p(\\hat{x}|x) : E[d(X,\\hat{X})] \\le D} I(X; \\hat{X})$$\n互信息可以用熵表示为 $I(X; \\hat{X}) = H(X) - H(X|\\hat{X})$。对于给定的伯努利信源，其熵 $H(X)$ 是一个常数，等于 $H(p)$。因此，最小化 $I(X; \\hat{X})$ 等价于最大化条件熵 $H(X|\\hat{X})$。\n\n$$R(D) = H(p) - \\max_{p(\\hat{x}|x) : E[d(X,\\hat{X})] \\le D} H(X|\\hat{X})$$\n\n我们可以使用 Fano 不等式来找到 $H(X|\\hat{X})$ 的一个上界。汉明失真 $d(x, \\hat{x})$ 在 $x \\neq \\hat{x}$ 时为 1，否则为 0。因此，平均失真就是错误概率：$D = E[d(X, \\hat{X})] = P(X \\neq \\hat{X})$。\n\nFano 不等式表明，对于具有相同符号集 $\\mathcal{X}$ 的任意两个随机变量 $X$ 和 $\\hat{X}$，\n$$H(X|\\hat{X}) \\le H(P(X \\neq \\hat{X})) + P(X \\neq \\hat{X}) \\log_2(|\\mathcal{X}|-1)$$\n对于我们的二元信源， $|\\mathcal{X}|=2$，因此 $\\log_2(|\\mathcal{X}|-1) = \\log_2(1) = 0$。使用 $P(X \\neq \\hat{X}) \\le D$，我们得到：\n$$H(X|\\hat{X}) \\le H(D)$$\n这就给出了率失真函数的一个下界：\n$$R(D) \\ge H(p) - H(D)$$\n如果我们能找到一个测试信道（即一个条件分布 $p(\\hat{x}|x)$），它能同时满足失真约束 $E[d(X, \\hat{X})] = D$ 并达到熵界 $H(X|\\hat{X}) = H(D)$，那么这个界就是可达的。\n\n让我们构造这样一个信道。如果给定 $\\hat{X}$ 时 $X$ 的条件分布是一个错误概率为 $D$ 的简单二元分布，那么条件 $H(X|\\hat{X}) = H(D)$ 就得到满足。让我们定义一个*反向*测试信道，其交叉概率为 $D$：\n$$p(X=1|\\hat{X}=0) = D \\quad \\text{and} \\quad p(X=0|\\hat{X}=1) = D$$\n这意味着 $p(X=0|\\hat{X}=0) = 1-D$ 且 $p(X=1|\\hat{X}=1) = 1-D$。\n因此，对于 $\\hat{x}=0$ 和 $\\hat{x}=1$，条件熵 $H(X|\\hat{X}=\\hat{x})$ 均为 $H(D)$。因此，总条件熵为 $H(X|\\hat{X}) = \\sum_{\\hat{x}} p(\\hat{x}) H(X|\\hat{X}=\\hat{x}) = H(D)$。\n\n现在，我们需要定义输出分布 $p(\\hat{x})$，使得信源分布 $p(x)$ 得以恢复，并且满足失真约束。设 $p(\\hat{X}=1) = q$，则 $p(\\hat{X}=0) = 1-q$。边缘概率 $P(X=1)$ 可以计算如下：\n$$P(X=1) = \\sum_{\\hat{x}} P(\\hat{X}=\\hat{x}) P(X=1|\\hat{X}=\\hat{x})$$\n$$p = (1-q) P(X=1|\\hat{X}=0) + q P(X=1|\\hat{X}=1)$$\n$$p = (1-q)D + q(1-D) = D - qD + q - qD = q(1-2D) + D$$\n对 $q$ 求解：\n$$q = \\frac{p-D}{1-2D}$$\n为了使 $q$ 是一个有效的概率，我们需要 $0 \\le q \\le 1$。\n$q \\ge 0$ 的要求意味着 $p-D \\ge 0$，所以 $D \\le p$。\n$q \\le 1$ 的要求意味着 $p-D \\le 1-2D$，所以 $D \\le 1-p$。\n由于给定 $p \\le 1/2$，我们有 $p \\le 1-p$。因此，更严格的条件是 $D \\le p$。所以，这个构造对于 $0 \\le D \\le p$ 是有效的。\n\n最后，我们来验证这个信道的平均失真：\n$$E[d(X, \\hat{X})] = P(X \\neq \\hat{X}) = \\sum_{\\hat{x}} P(\\hat{X}=\\hat{x}) P(X \\neq \\hat{x} | \\hat{X}=\\hat{x})$$\n$$E[d(X, \\hat{X})] = P(\\hat{X}=0) P(X=1|\\hat{X}=0) + P(\\hat{X}=1) P(X=0|\\hat{X}=1)$$\n$$E[d(X, \\hat{X})] = (1-q)D + qD = D$$\n失真约束的等号成立。\n\n由于我们已经构建了一个信道，对于 $0 \\le D \\le p$ 范围内的任何 $D$，该信道都能产生失真 $D$ 且速率为 $I(X;\\hat{X}) = H(p) - H(D)$，因此该下界是可达的。对于 $D > p$ 的情况，我们可以达到零速率。例如，通过始终设置 $\\hat{X}=0$（因为 0 是更可能出现的符号），失真为 $D = P(X=1) = p$，速率为 $I(X; \\text{const}) = 0$。由于 $R(D)$ 是一个非增函数，因此对于所有的 $D \\ge p$，$R(D)=0$。\n\n因此，在非平凡区域（$0 \\le D \\le p$）内，率失真函数的表达式为：\n$$R(D) = H(p) - H(D)$$", "answer": "$$\\boxed{H(p) - H(D)}$$", "id": "1652137"}, {"introduction": "在掌握了基本的二元信源模型后，我们来探讨一个更复杂的情形：一个具有多个符号的信源，并使用在信号处理中非常常见的平方误差作为失真度量。这个问题[@problem_id:1652148]将引导你采用一种不同的、更具构造性的方法，即通过对信源符号进行“量化”或“聚类”来思考。你的目标是理解率失真函数如何作为不同确定性编码方案所产生的（失真-率）点对的下凸包络而出现，这揭示了寻找最优编码的一种实用思路。", "problem": "一个离散无记忆信源从字母表 $\\mathcal{X} = \\{1, 2, 3, 4\\}$ 中发出符号。每个符号都是独立且等概率地生成的。我们希望压缩该信源，并用一个重构字母表 $\\hat{\\mathcal{X}}$ 来表示它，该字母表可以包含任何实数。重构的质量由平方误差失真度量，其定义为 $d(x, \\hat{x}) = (x - \\hat{x})^2$，其中 $x \\in \\mathcal{X}$ 是信源符号，$\\hat{x} \\in \\hat{\\mathcal{X}}$ 是其重构。\n\n确定此信源的率失真函数 $R(D)$，它给出在给定最大平均失真 $D$ 的情况下，可达到的最小速率（以比特/符号为单位）。将您的答案表示为关于 $D$ 的分段函数。", "solution": "设 $X$ 在 $\\mathcal{X}=\\{1,2,3,4\\}$ 上均匀分布，概率为 $p(x)=\\frac{1}{4}$。在平方误差失真下，率失真函数为\n$$\nR(D)=\\inf_{p(\\hat{x}|x):\\,\\mathbb{E}[(X-\\hat{X})^{2}]\\le D} I(X;\\hat{X}),\n$$\n以比特/符号为单位（因此所有对数都以 2 为底）。\n\n使用的关键事实：\n- 对于具有无约束重构字母表的平方误差失真，对于信源字母表的任何确定性划分（量化器）成簇，一个簇的最佳重构值是其条件均值，该簇对总均方误差的贡献是其簇内方差。\n- 可达的 $(D,R)$ 点对集合通过时分（time-sharing）是凸的。因此，$R(D)$ 是来自确定性映射的可达点的下凸包。\n\n计算规范的确定性映射（聚类）、它们的失真和速率。\n\n1) 单簇映射（恒定重构）。\n- 重构值 $\\hat{x}=\\mathbb{E}[X]=\\frac{1+2+3+4}{4}=\\frac{5}{2}$。\n- 失真 $D=\\mathrm{Var}(X)=\\mathbb{E}[X^{2}]-(\\mathbb{E}[X])^{2}=\\frac{30}{4}-\\left(\\frac{5}{2}\\right)^{2}=\\frac{15}{2}-\\frac{25}{4}=\\frac{5}{4}$。\n- 由于 $\\hat{X}$ 是常数，$I(X;\\hat{X})=0$。因此得到点 $\\left(D,R\\right)=\\left(\\frac{5}{4},0\\right)$。\n\n2) 双簇映射。\n- 最佳的 2-均值划分将相邻的点分组：$\\{1,2\\}$ 和 $\\{3,4\\}$，其质心分别为 $\\frac{3}{2}$ 和 $\\frac{7}{2}$。\n- 对于一个两点的相邻簇 $\\{x,x+1\\}$，质心是 $x+\\frac{1}{2}$，每个点的平方偏差为 $\\left(\\frac{1}{2}\\right)^{2}=\\frac{1}{4}$。因此每次出现时的簇失真为 $\\frac{1}{4}$。在簇概率为 $\\frac{2}{4}$ 的情况下，每个簇对总失真 $D$ 的贡献为 $\\frac{2}{4}\\cdot\\frac{1}{4}=\\frac{1}{8}$。对于两个这样的簇，总失真为\n$$\nD=\\frac{1}{8}+\\frac{1}{8}=\\frac{1}{4}.\n$$\n- 簇概率为 $\\frac{1}{2}$ 和 $\\frac{1}{2}$，所以 $H(\\hat{X})=1$，并且由于映射是确定性的，$I(X;\\hat{X})=H(\\hat{X})=1$。因此得到点 $\\left(D,R\\right)=\\left(\\frac{1}{4},1\\right)$。\n- 任何其他的双簇划分（例如，$\\{1,2,3\\}$ vs. $\\{4\\}$ 或非相邻配对）都会产生更大的失真，所以 $\\left(\\frac{1}{4},1\\right)$ 是最佳的双簇点。\n\n3) 三簇映射。\n- 最佳划分合并一对相邻点，并将另外两个点作为单元素簇，例如 $\\{1,2\\}$, $\\{3\\}$, $\\{4\\}$（或任何对称的变体）。如上所述，合并的对对 $D$ 的贡献为 $\\frac{1}{8}$；单元素簇的贡献为 $0$。因此\n$$\nD=\\frac{1}{8}.\n$$\n- 簇概率为 $\\frac{1}{2},\\frac{1}{4},\\frac{1}{4}$，所以\n$$\nI(X;\\hat{X})=H(\\hat{X})=-\\frac{1}{2}\\log_{2}\\left(\\frac{1}{2}\\right)-2\\cdot\\frac{1}{4}\\log_{2}\\left(\\frac{1}{4}\\right)=\\frac{1}{2}+1=\\frac{3}{2}.\n$$\n因此得到点 $\\left(D,R\\right)=\\left(\\frac{1}{8},\\frac{3}{2}\\right)$。\n\n4) 四簇映射（无损重构）。\n- 在信源点处设置质心的恒等映射得到 $D=0$ 和 $R=H(X)=\\log_{2}4=2$。因此得到点 $\\left(D,R\\right)=\\left(0,2\\right)$。\n\n通过时分进行凸化：\n- 可达点包括 $\\left(\\frac{5}{4},0\\right)$、$\\left(\\frac{1}{4},1\\right)$、$\\left(\\frac{1}{8},\\frac{3}{2}\\right)$ 和 $\\left(0,2\\right)$，通过时分，连接它们的线段上的所有点都是可达的。\n- 计算这些点之间的斜率：\n  - 在 $\\left(0,2\\right)$ 和 $\\left(\\frac{1}{4},1\\right)$ 之间：斜率为 $\\frac{1-2}{\\frac{1}{4}-0}=-4$；中间点 $\\left(\\frac{1}{8},\\frac{3}{2}\\right)$ 正好位于这条线上，所以它不会形成新的线段。\n  - 在 $\\left(\\frac{1}{4},1\\right)$ 和 $\\left(\\frac{5}{4},0\\right)$ 之间：斜率为 $\\frac{0-1}{\\frac{5}{4}-\\frac{1}{4}}=-1$。\n\n因此，下凸包是由两段组成的分段线性函数：\n- 对于 $0\\le D\\le\\frac{1}{4}$，过点 $\\left(0,2\\right)$ 和 $\\left(\\frac{1}{4},1\\right)$ 的直线为：\n$$\nR(D)=2-4D.\n$$\n- 对于 $\\frac{1}{4}\\le D\\le\\frac{5}{4}$，过点 $\\left(\\frac{1}{4},1\\right)$ 和 $\\left(\\frac{5}{4},0\\right)$ 的直线为：\n$$\nR(D)=\\frac{5}{4}-D.\n$$\n- 对于 $D\\ge\\frac{5}{4}$，可以使用一个恒定重构的码，并达到 $R(D)=0$。\n\n因此，以比特/符号为单位，\n$$\nR(D)=\n\\begin{cases}\n2-4D, & 0\\le D\\le \\frac{1}{4},\\\\\n\\frac{5}{4}-D, & \\frac{1}{4}\\le D\\le \\frac{5}{4},\\\\\n0, & D\\ge \\frac{5}{4}.\n\\end{cases}\n$$", "answer": "$$\\boxed{R(D)=\\begin{cases}\n2-4D, & 0\\le D\\le \\frac{1}{4},\\\\\n\\frac{5}{4}-D, & \\frac{1}{4}\\le D\\le \\frac{5}{4},\\\\\n0, & D\\ge \\frac{5}{4}.\n\\end{cases}}$$", "id": "1652148"}, {"introduction": "现代数据压缩常常处理的不是单个符号，而是结构化的数据，如图像块或机器学习中的特征向量。这个练习[@problem_id:1652150]将我们对率失真理论的理解从单个符号扩展到高维向量空间。你将为一个在$k$维超立方体顶点上均匀分布的信源计算其率失真函数，这可以看作是第一个练习中伯努利信源向高维的推广。通过这个实践，你将学会如何利用对称性和独立性等原理来解决看似复杂的高维问题，并体会该理论在现代技术中的强大应用价值。", "problem": "考虑一个为机器学习应用生成特征向量的数字系统。每个向量是一个$k$比特的二进制字符串，系统以等概率生成所有$2^k$种可能的向量。为了高效存储，这些向量被压缩然后解压缩，这个过程可能会引入错误。原始向量$X$与其重构版本$\\hat{X}$之间的失真由它们的汉明距离$d(X, \\hat{X})$来衡量，其定义为它们之间不同比特位的数量。\n\n该压缩过程的基本限制由率失真函数$R(D)$描述，它指定了表示信源所需的最小每向量比特数，以使期望失真不超过一个值$D$。\n\n确定该信源的率失真函数$R(D)$。请给出在失真范围$0 \\le D \\le k/2$内有效的$R(D)$的解析表达式。率应以每向量比特数表示。您的最终表达式应以$k$、$D$和以2为底的对数表示。", "solution": "率失真函数$R(D)$定义为，在所有满足期望失真小于或等于$D$的条件分布（测试信道）$p(\\hat{x}|x)$上，互信息$I(X; \\hat{X})$的最小值。\n$$R(D) = \\min_{p(\\hat{x}|x) : \\mathbb{E}[d(X, \\hat{X})] \\le D} I(X; \\hat{X})$$\n互信息可以表示为$I(X; \\hat{X}) = H(X) - H(X|\\hat{X})$。\n\n信源$X$在$k$维超立方体的$2^k$个顶点上均匀分布，这些顶点由长度为$k$的二进制字符串表示。因此，信源的熵为：\n$$H(X) = \\log_2(|\\mathcal{X}|) = \\log_2(2^k) = k \\text{ bits}$$\n所以，最小化$I(X; \\hat{X})$等价于最大化条件熵$H(X|\\hat{X})$。\n$$R(D) = k - \\max_{p(\\hat{x}|x) : \\mathbb{E}[d(X, \\hat{X})] \\le D} H(X|\\hat{X})$$\n\n由于信源分布的对称性（均匀分布）和失真度量（汉明距离，其对于所有向量的比特翻转是不变的）的对称性，最优测试信道$p(\\hat{x}|x)$也将是对称的。这意味着$p(\\hat{x}|x)$仅取决于误差向量$E = X \\oplus \\hat{X}$（其中$\\oplus$是按位异或运算），并且其分布对比特位置的排列是不变的。\n\n我们通过假设信源向量$X$的每个比特以概率$p$独立翻转，从而生成重构向量$\\hat{X}$的相应比特，来对此对称信道建模。这等效于将$k$个并行的二元对称信道（BSC）应用于$X$的各个比特。误差向量$E$的分量$E_i$将是独立同分布的伯努利随机变量，其中$P(E_i=1) = p$且$P(E_i=0) = 1-p$。\n\n对于给定的一对$(x, \\hat{x})$，失真为$d(x, \\hat{x}) = w_H(x \\oplus \\hat{x})$，其中$w_H$是汉明权重（1的数量）。期望失真是误差向量$E$的期望汉明权重。由于翻转的比特数服从二项分布$B(k, p)$，期望失真为：\n$$D(p) = \\mathbb{E}[w_H(E)] = k p$$\n我们关心的是重构向量，因此我们应该选择$p$来最小化错误。翻转概率$p > 0.5$是次优的，因为通过翻转逻辑，可以用相同的率实现更低的失真$k(1-p)$。因此，我们考虑范围$p \\in [0, 0.5]$。这对应于失真范围$D \\in [0, k/2]$。从$D=kp$中，我们可以将参数$p$表示为$p = D/k$。\n\n现在我们计算该信道的率。我们需要最大化$H(X|\\hat{X})$。\n$$H(X|\\hat{X}) = H(X \\oplus \\hat{X} | \\hat{X}) = H(E | \\hat{X})$$\n在此信道模型中，误差向量$E$的生成独立于信源向量$X$。由于该问题的对称性（信源均匀，失真度量对称），可以证明误差向量 $E$ 与重构向量 $\\hat{X}$ 是独立的。因此，$H(E|\\hat{X}) = H(E)$。\n\n误差向量$E$的熵是其独立分量的熵之和：\n$$H(E) = \\sum_{i=1}^k H(E_i) = k H_b(p)$$\n其中$H_b(p)$是二元熵函数：\n$$H_b(p) = -p \\log_2(p) - (1-p) \\log_2(1-p)$$\n因此，互信息为：\n$$I(X; \\hat{X}) = H(X) - H(X|\\hat{X}) = k - k H_b(p) = k(1 - H_b(p))$$\n这个表达式给出了率失真曲线上的一个点$(D(p), R(p))$。为了求得$R(D)$，我们将$p=D/k$代入率的表达式中：\n$$R(D) = k \\left(1 - H_b\\left(\\frac{D}{k}\\right)\\right)$$\n$$R(D) = k \\left(1 - \\left(-\\frac{D}{k}\\log_2\\left(\\frac{D}{k}\\right) - \\left(1-\\frac{D}{k}\\right)\\log_2\\left(1-\\frac{D}{k}\\right)\\right)\\right)$$\n这在$p \\in [0, 0.5]$时有效，对应于$D \\in [0, k/2]$。我们来简化这个表达式：\n$$R(D) = k + k\\left(\\frac{D}{k}\\log_2\\left(\\frac{D}{k}\\right)\\right) + k\\left(\\frac{k-D}{k}\\log_2\\left(\\frac{k-D}{k}\\right)\\right)$$\n$$R(D) = k + D\\log_2\\left(\\frac{D}{k}\\right) + (k-D)\\log_2\\left(\\frac{k-D}{k}\\right)$$\n这也可以写成：\n$$R(D) = k + D\\log_2(D) - D\\log_2(k) + (k-D)\\log_2(k-D) - (k-D)\\log_2(k)$$\n$$R(D) = k - (D + k - D)\\log_2(k) + D\\log_2(D) + (k-D)\\log_2(k-D)$$\n$$R(D) = k - k\\log_2(k) + D\\log_2(D) + (k-D)\\log_2(k-D)$$\n问题要求表达式以$k$、$D$和以2为底的对数表示。第一个推导出的形式更简洁且足够。\n\n对于$D > k/2$，率$R(D)$为0。这是因为无论输入是什么，通过发送一个恒定向量（例如$\\hat{x}_0 = (0, ..., 0)$）可以实现0的率。在这种情况下，期望失真是$\\{0,1\\}^k$中向量的平均汉明权重，即$\\frac{1}{2^k} \\sum_{x} w_H(x) = \\frac{1}{2^k} (k 2^{k-1}) = k/2$。由于该策略以率$R=0$实现了失真$D=k/2$，任何大于$D > k/2$的失真也可以用零率实现。\n\n问题明确要求在范围$0 \\le D \\le k/2$内的表达式。\n最终表达式：\n$$R(D) = k + D\\log_2\\left(\\frac{D}{k}\\right) + (k-D)\\log_2\\left(1-\\frac{D}{k}\\right)$$\n注意$\\log_2\\left(1-\\frac{D}{k}\\right) = \\log_2\\left(\\frac{k-D}{k}\\right)$。\n所以，$R(D) = k + D\\log_2\\left(\\frac{D}{k}\\right) + (k-D)\\log_2\\left(\\frac{k-D}{k}\\right)$。", "answer": "$$\\boxed{k + D \\log_{2}\\left(\\frac{D}{k}\\right) + (k-D) \\log_{2}\\left(1-\\frac{D}{k}\\right)}$$", "id": "1652150"}]}