{"hands_on_practices": [{"introduction": "我们从最简单的情景开始探索：一个完全没有随机性的信源。这个练习旨在阐明率失真理论的一个基本原则，揭示当信源熵为零时，率失真函数 $R(D)$ 的行为。通过分析这个关于“卡住的传感器”的思维实验 [@problem_id:1652578]，你将巩固对信源不确定性与重构所需最小速率之间关系的理解。", "problem": "在数据压缩领域，率失真理论为有损压缩提供了理论极限。考虑一个涉及故障环境传感器的场景。该传感器本应监测一个稳定的化学过程，但它卡住了，持续输出一个单一的、恒定的实数值 $c$。该系统可以建模为一个离散无记忆信源 $X$，其信源字母表为 $\\mathcal{X} = \\{c\\}$，相应的概率质量函数为 $p(X=c) = 1$。\n\n我们希望压缩来自该传感器的信号。压缩并重建后的信号（表示为 $\\hat{X}$）的质量使用一个非负失真度量 $d(x, \\hat{x})$ 来评估。该度量有一个基本属性，即完美重建会产生零失真，即 $d(c, c) = 0$。\n\n率失真函数 $R(D)$ 定义了在给定的最大可容忍平均失真 $D$ 下，可实现的最小数据率（单位为比特/符号）。其形式化定义为：\n$$R(D) = \\min_{p(\\hat{x}|x) : \\mathbb{E}[d(X, \\hat{X})] \\le D} I(X; \\hat{X})$$\n其中 $I(X; \\hat{X})$ 是信源 $X$ 与重建 $\\hat{X}$ 之间的互信息。该最小化是针对所有满足失真约束的条件概率分布 $p(\\hat{x}|x)$ 进行的。\n\n对于这个“卡住”的传感器，请确定在任何非负失真水平 $D \\ge 0$ 下的率失真函数 $R(D)$。请选择正确描述该函数的选项。\n\nA. 对所有 $D \\geq 0$，$R(D) = 0$。\nB. 当 $D = 0$ 时 $R(D) = 1$，当 $D > 0$ 时 $R(D) = 0$。\nC. 对于 $D \\geq 0$，$R(D)$ 是一个严格递减的正函数。\nD. 在不知道对于 $\\hat{x} \\neq c$ 的失真度量 $d(x, \\hat{x})$ 的具体形式的情况下，无法确定该函数。", "solution": "我们将信源建模为 $X=c$，且 $p(X=c)=1$。对于任何条件分布 $p(\\hat{x}|x)$，联合分布为 $p(x,\\hat{x})=\\mathbf{1}\\{x=c\\}\\,p(\\hat{x}|c)$，而 $\\hat{X}$ 的边缘分布为 $p(\\hat{x})=p(\\hat{x}|c)$。\n\n根据互信息的定义（以比特为单位），\n$$\nI(X;\\hat{X})=\\sum_{x,\\hat{x}} p(x,\\hat{x}) \\log_2 \\frac{p(x,\\hat{x})}{p(x)p(\\hat{x})}.\n$$\n由于只有 $x=c$ 的概率为正，\n$$\nI(X;\\hat{X})=\\sum_{\\hat{x}} p(\\hat{x}|c)\\,\\log_2 \\frac{p(\\hat{x}|c)}{p(X=c)\\,p(\\hat{x})}\n=\\sum_{\\hat{x}} p(\\hat{x}|c)\\,\\log_2 \\frac{p(\\hat{x}|c)}{1\\cdot p(\\hat{x})}.\n$$\n但是 $p(\\hat{x})=p(\\hat{x}|c)$，所以对数内的比率为 $1$，因此对于任何 $p(\\hat{x}|x)$ 的选择，都有 $I(X;\\hat{X})=0$。\n\n失真约束为\n$$\n\\mathbb{E}[d(X,\\hat{X})]=\\mathbb{E}[d(c,\\hat{X})].\n$$\n选择 $\\hat{X}=c$ 几乎必然（即 $p(\\hat{x}|c)=\\mathbf{1}\\{\\hat{x}=c\\}$）可得\n$$\n\\mathbb{E}[d(c,\\hat{X})]=d(c,c)=0\\le D\n$$\n这对每个 $D\\ge 0$ 都成立，所以对于所有 $D\\ge 0$，可行集都是非空的。\n\n率失真函数为\n$$\nR(D)=\\min_{p(\\hat{x}|x):\\,\\mathbb{E}[d(X,\\hat{X})]\\le D} I(X;\\hat{X}).\n$$\n由于对于任何 $p(\\hat{x}|x)$ 都有 $I(X;\\hat{X})=0$，并且互信息是非负的，所以在可行集上的最小值对于所有 $D\\ge 0$ 都恰好为 $0$。\n\n因此，正确的描述是对于所有 $D\\ge 0$ 都有 $R(D)=0$，这对应于选项 A。", "answer": "$$\\boxed{A}$$", "id": "1652578"}, {"introduction": "在研究了没有不确定性的信源之后，让我们转向另一个极端：当我们完全不能传输任何信息（即速率 $R=0$）时，我们能做到的最好情况是什么？这个问题探讨了最大失真 $D_{max}$ 的概念，它对应于率失真曲线上的点 $R(D_{max})=0$。它揭示了在最小化平方误差失真的目标下，最佳的零速率策略是始终猜测信源的均值。计算零速率系统下的最小失真 [@problem_id:1652592] 提供了一个关键的参考基准，它定义了有意义失真的上限——任何导致更高失真的压缩方案都比不传输任何信息、让解码器输出一个恒定值还要糟糕。", "problem": "在数据压缩领域，率失真理论为压缩率与重构数据保真度之间的权衡提供了基本限制。\n\n考虑一个生成独立同分布（i.i.d.）随机变量 $X$ 的无记忆连续信源。每个变量服从均值为零、方差为 $\\sigma^2$ 的高斯（正态）分布，记为 $X \\sim \\mathcal{N}(0, \\sigma^2)$。\n\n一个简单的压缩系统被设计用于表示此信源。该系统的性能使用平方误差失真度量进行评估，其中平均失真 $D$ 由原始信号与其重构信号之差的平方的期望值给出：$D = E[(X - \\hat{X})^2]$。\n\n由于极端的带宽限制，该系统被设计为以每源符号零比特的速率运行。这种“零速率”编码意味着关于任何给定样本 $x$ 的具体值的信息都无法传输。因此，对于需要重构的每一个源符号，解码器都必须产生一个相同的恒定估计值，我们称之为 $\\hat{x}_c$。\n\n为了在这种严格的约束下实现最佳性能，必须选择恒定估计值 $\\hat{x}_c$ 以最小化平均失真 $D$。\n\n计算该零速率系统的最小可实现平均失真。将您的最终答案表示为关于信源参数 $\\sigma$ 的解析表达式。", "solution": "该问题要求计算一个零速率编码器的最小平均失真，该编码器对信源 $X \\sim \\mathcal{N}(0, \\sigma^2)$ 使用一个恒定的重构值 $\\hat{x}_c$。失真度量是均方误差，$D = E[(X - \\hat{x}_c)^2]$。我们的目标是找到最小化此失真的最优恒定值 $\\hat{x}_c$，然后计算这个最小失真的值。\n\n首先，我们将平均失真 $D$ 表示为恒定估计值 $\\hat{x}_c$ 的函数。\n$$D(\\hat{x}_c) = E[(X - \\hat{x}_c)^2]$$\n我们可以展开期望内的平方项：\n$$D(\\hat{x}_c) = E[X^2 - 2X\\hat{x}_c + \\hat{x}_c^2]$$\n利用期望算子的线性性质，我们可以写出：\n$$D(\\hat{x}_c) = E[X^2] - E[2X\\hat{x}_c] + E[\\hat{x}_c^2]$$\n由于 $\\hat{x}_c$ 是一个常数，我们可以将其从期望中提出：\n$$D(\\hat{x}_c) = E[X^2] - 2\\hat{x}_c E[X] + \\hat{x}_c^2$$\n为了找到最小化 $D$ 的 $\\hat{x}_c$ 值，我们可以将 $D$ 视为 $\\hat{x}_c$ 的函数，通过对其求关于 $\\hat{x}_c$ 的导数并令其为零来找到其最小值。\n$$\\frac{dD(\\hat{x}_c)}{d\\hat{x}_c} = \\frac{d}{d\\hat{x}_c} (E[X^2] - 2\\hat{x}_c E[X] + \\hat{x}_c^2)$$\n项 $E[X^2]$ 相对于 $\\hat{x}_c$ 是一个常数，因此其导数为零。\n$$\\frac{dD(\\hat{x}_c)}{d\\hat{x}_c} = 0 - 2E[X] + 2\\hat{x}_c$$\n将导数设为零以求最小值：\n$$-2E[X] + 2\\hat{x}_c = 0$$\n$$\\hat{x}_c = E[X]$$\n这表明，最小化均方误差的最优恒定估计值是信源随机变量的均值（期望值）。\n\n对于给定的信源 $X \\sim \\mathcal{N}(0, \\sigma^2)$，其均值为 $E[X] = 0$。因此，最优的恒定重构值为 $\\hat{x}_c = 0$。\n\n现在我们将这个最优值代回失真公式，以求得最小可实现失真：\n$$D_{min} = E[(X - 0)^2] = E[X^2]$$\n我们需要求出 $E[X^2]$ 的值。我们可以使用方差的定义：\n$$\\text{Var}(X) = E[X^2] - (E[X])^2$$\n重新整理此式以求解 $E[X^2]$：\n$$E[X^2] = \\text{Var}(X) + (E[X])^2$$\n对于我们的信源，给定方差为 $\\text{Var}(X) = \\sigma^2$，均值为 $E[X] = 0$。\n代入这些值：\n$$E[X^2] = \\sigma^2 + 0^2 = \\sigma^2$$\n因此，该零速率系统的最小可实现平均失真为 $\\sigma^2$。这个失真是通过始终猜测信源的均值得到的，它代表了信源本身固有的不确定性或方差。任何程度的压缩都不能导致平均失真大于此值，因为不传输任何信息就可以达到这种失真水平。", "answer": "$$\\boxed{\\sigma^{2}}$$", "id": "1652592"}, {"introduction": "我们已经探讨了率失真函数 $R(D)$ 在其两个极值点附近的行为。但是，对于一个给定的信源和失真度量，我们如何计算出完整的权衡曲线呢？本练习将向您介绍 Blahut-Arimoto 算法，这是一种用于计算率失真函数上数据点的迭代方法。通过亲手完成 Blahut-Arimoto 算法的一次完整迭代计算 [@problem_id:1652561]，您将获得率失真理论计算基础的实践经验，从而在抽象理论与实际计算之间架起一座桥梁。", "problem": "考虑一个为离散无记忆信源 $X$ 设计的数据压缩系统。该信源的字母表为 $\\mathcal{X} = \\{0, 1\\}$，并遵循伯努利分布，其中 $P(X=1) = p$ 且 $P(X=0) = 1-p$。压缩后的数据使用再现字母表 $\\mathcal{\\hat{X}} = \\{0, 1, 2\\}$ 来表示。再现质量由一个失真矩阵 $d(x, \\hat{x})$ 衡量，其形式如下：\n$$\nd = \\begin{pmatrix} d(0,0) & d(0,1) & d(0,2) \\\\ d(1,0) & d(1,1) & d(1,2) \\end{pmatrix} = \\begin{pmatrix} 0 & \\delta_1 & \\delta_2 \\\\ \\delta_3 & 0 & \\delta_4 \\end{pmatrix}\n$$\n其中 $\\delta_1, \\delta_2, \\delta_3, \\delta_4$ 是已知的正数。\n\n为了找到压缩率和失真之间的最优权衡，我们采用 Blahut-Arimoto 算法。对于一个固定的斜率参数 $s < 0$，该算法迭代地优化一个条件概率分布（即“测试信道”）$q(\\hat{x}|x)$ 和一个再现概率分布 $q(\\hat{x})$。从步骤 $k$ 到 $k+1$ 的一次迭代的更新规则如下：\n\n1.  更新测试信道：\n    $$q_{k+1}(\\hat{x}|x) = \\frac{q_k(\\hat{x}) \\exp(s \\cdot d(x, \\hat{x}))}{\\sum_{\\hat{x}' \\in \\mathcal{\\hat{X}}} q_k(\\hat{x}') \\exp(s \\cdot d(x, \\hat{x}'))}$$\n\n2.  更新再现分布：\n    $$q_{k+1}(\\hat{x}) = \\sum_{x \\in \\mathcal{X}} P(x) q_{k+1}(\\hat{x}|x)$$\n\n该算法在步骤 $k=0$ 处使用均匀再现分布进行初始化，即对于所有 $\\hat{x} \\in \\mathcal{\\hat{X}}$，有 $q_0(\\hat{x}) = 1/3$。\n\n您的任务是执行该算法的完整一次迭代。确定更新后的再现概率 $q_1(\\hat{x}=0)$ 的显式解析表达式。请用 $p, s, \\delta_1, \\delta_2, \\delta_3,$ 和 $\\delta_4$ 将您的答案表示为单个闭式解析表达式。", "solution": "我们严格遵循给定的 Blahut-Arimoto 更新规则。初始再现分布是均匀的，因此对于所有 $\\hat{x} \\in \\{0,1,2\\}$，我们有 $q_{0}(\\hat{x}) = \\frac{1}{3}$。\n\n首先，为每个信源符号 $x$ 计算测试信道更新公式中的分母：\n对于 $x=0$，使用 $d(0,0)=0$, $d(0,1)=\\delta_{1}$, $d(0,2)=\\delta_{2}$，\n$$\nD_{0}=\\sum_{\\hat{x}\\in\\{0,1,2\\}} q_{0}(\\hat{x}) \\exp\\!\\big(s\\, d(0,\\hat{x})\\big)\n= \\frac{1}{3}\\big( \\exp(0) + \\exp(s \\delta_{1}) + \\exp(s \\delta_{2}) \\big)\n= \\frac{1}{3}\\big( 1 + \\exp(s \\delta_{1}) + \\exp(s \\delta_{2}) \\big).\n$$\n对于 $x=1$，使用 $d(1,0)=\\delta_{3}$, $d(1,1)=0$, $d(1,2)=\\delta_{4}$，\n$$\nD_{1}=\\sum_{\\hat{x}\\in\\{0,1,2\\}} q_{0}(\\hat{x}) \\exp\\!\\big(s\\, d(1,\\hat{x})\\big)\n= \\frac{1}{3}\\big( \\exp(s \\delta_{3}) + \\exp(0) + \\exp(s \\delta_{4}) \\big)\n= \\frac{1}{3}\\big( \\exp(s \\delta_{3}) + 1 + \\exp(s \\delta_{4}) \\big).\n$$\n\n现在更新 $\\hat{x}=0$ 对应的测试信道：\n对于 $x=0$，\n$$\nq_{1}(0 \\mid 0) = \\frac{q_{0}(0)\\exp\\!\\big(s\\, d(0,0)\\big)}{D_{0}}\n= \\frac{\\frac{1}{3}\\exp(0)}{\\frac{1}{3}\\big(1 + \\exp(s \\delta_{1}) + \\exp(s \\delta_{2})\\big)}\n= \\frac{1}{1 + \\exp(s \\delta_{1}) + \\exp(s \\delta_{2})}.\n$$\n对于 $x=1$，\n$$\nq_{1}(0 \\mid 1) = \\frac{q_{0}(0)\\exp\\!\\big(s\\, d(1,0)\\big)}{D_{1}}\n= \\frac{\\frac{1}{3}\\exp(s \\delta_{3})}{\\frac{1}{3}\\big(\\exp(s \\delta_{3}) + 1 + \\exp(s \\delta_{4})\\big)}\n= \\frac{\\exp(s \\delta_{3})}{\\exp(s \\delta_{3}) + 1 + \\exp(s \\delta_{4})}.\n$$\n\n最后，使用信源分布 $P(X=1)=p$，$P(X=0)=1-p$ 来更新再现概率：\n$$\nq_{1}(\\hat{x}=0) = \\sum_{x\\in\\{0,1\\}} P(x)\\, q_{1}(0 \\mid x)\n= (1-p)\\, \\frac{1}{1 + \\exp(s \\delta_{1}) + \\exp(s \\delta_{2})}\n+ p\\, \\frac{\\exp(s \\delta_{3})}{\\exp(s \\delta_{3}) + 1 + \\exp(s \\delta_{4})}.\n$$\n这就是经过一次完整迭代后，符号 $0$ 的更新后再现概率所求的闭式表达式。", "answer": "$$\\boxed{(1-p)\\,\\frac{1}{1+\\exp(s\\delta_{1})+\\exp(s\\delta_{2})}\\;+\\;p\\,\\frac{\\exp(s\\delta_{3})}{\\exp(s\\delta_{3})+1+\\exp(s\\delta_{4})}}$$", "id": "1652561"}]}