{"hands_on_practices": [{"introduction": "掌握了雷尼熵的定义后，一个自然的下一步是探索不同概率分布如何影响其值。这个练习提供了一个基础性的优化问题，要求我们找出一个简单三元离散信源的概率分布，使其碰撞熵 ($H_2$) 最大化 [@problem_id:1655420]。通过解决这个问题，你将练习使用微积分来寻找极值，并直观地理解哪种类型的分布——是更均匀还是更集中的分布——能够最大化熵。", "problem": "在信息论中，$\\alpha$ 阶 Rényi 熵是标准 Shannon 熵的一种推广。对于一个可以取 $n$ 个可能值，其概率为 $\\{p_1, p_2, \\dots, p_n\\}$ 的离散随机变量 $X$，Rényi 熵定义为：\n$$H_\\alpha(X) = \\frac{1}{1-\\alpha} \\ln \\left( \\sum_{i=1}^n p_i^\\alpha \\right)$$\n对任意实数 $\\alpha \\ge 0$ 且 $\\alpha \\ne 1$。一个特别有用的情况是碰撞熵，它对应于 $\\alpha=2$。\n\n考虑一个离散信息源，它会发出三个符号 $\\{s_1, s_2, s_3\\}$ 中的一个。这些符号被发出的概率为 $P(X=s_1) = p$，$P(X=s_2) = p$ 和 $P(X=s_3) = 1-2p$，其中 $p$ 是一个实数参数。为了确保这些概率是有效的（即非负且总和为一），参数 $p$ 被限制在区间 $[0, 1/2]$ 内。\n\n求出此区间内使该信息源的碰撞熵 $H_2(X)$ 达到最大的 $p$ 的具体值。", "solution": "对于二阶，Rényi（碰撞）熵由定义可得\n$$H_{2}(X)=\\frac{1}{1-2}\\ln\\!\\left(\\sum_{i=1}^{n}p_{i}^{2}\\right)=-\\ln\\!\\left(\\sum_{i=1}^{n}p_{i}^{2}\\right).$$\n当概率为 $\\{p,p,1-2p\\}$ 时，其平方和为\n$$S(p)=p^{2}+p^{2}+(1-2p)^{2}=2p^{2}+1-4p+4p^{2}=6p^{2}-4p+1.$$\n由于在 $[0,\\,\\frac{1}{2}]$ 上 $S(p)0$，且 $-\\ln(\\cdot)$ 在 $(0,\\infty)$ 上是严格递减的，因此最大化 $H_{2}(X)=-\\ln(S(p))$ 等价于在 $[0,\\,\\frac{1}{2}]$ 上最小化 $S(p)$。函数 $S(p)$ 是一个凸二次函数，其\n$$S'(p)=12p-4,\\qquad S''(p)=120.$$\n令一阶导数等于零，可得唯一临界点\n$$12p-4=0\\;\\;\\Longrightarrow\\;\\;p=\\frac{1}{3},$$\n该点位于 $[0,\\,\\frac{1}{2}]$ 区间内。根据凸性，该点是 $S(p)$ 在此区间上的全局最小值点，因此它使得 $H_{2}(X)$ 最大化。", "answer": "$$\\boxed{\\frac{1}{3}}$$", "id": "1655420"}, {"introduction": "在许多物理和信息处理系统中，我们不仅关心熵本身，还关心在满足特定物理约束（如固定平均能量）的条件下系统的可能状态。这个练习提出了一个更高级的优化挑战：在给定均值的约束下，找到最小化碰撞熵的概率分布 [@problem_id:1655423]。解决这个问题将揭示一个深刻的原理，即当试图最小化熵（或最大化“纯度”）时，最优分布通常是稀疏的，这在信号处理和机器学习等领域有着重要的应用。", "problem": "一个量子信息处理器基于一个具有 $N=11$ 个不同状态的系统设计，这些状态由整数索引 $k \\in \\{0, 1, \\dots, 10\\}$ 标记。系统处于状态 $k$ 的概率由 $p_k$ 给出。对于某些算法，一个关键的性能指标是状态的“纯度”，它与碰撞熵有关。碰撞熵是Rényi熵的一个特例，定义为 $H_2(X) = -\\ln \\left( \\sum_{k=0}^{10} p_k^2 \\right)$。\n\n系统被制备在某一状态，使得状态索引的均值 $\\mathbb{E}[X] = \\sum_{k=0}^{10} k \\, p_k$ 被精确地约束在非整数值 $\\mu = 3.8$。\n\n你的任务是确定在此约束下最小化碰撞熵 $H_2(X)$ 的完整概率分布 $\\{p_k\\}_{k=0}^{10}$。请找出所有具有非零概率的状态 $k$，并给出它们对应的概率值。设这些状态的索引为 $k_1  k_2  \\dots  k_M$。请以序列形式提供数值 $k_1, p_{k_1}, k_2, p_{k_2}, \\dots, k_M, p_{k_M}$。所有概率值四舍五入到三位有效数字。", "solution": "该问题要求我们找到在特定约束条件下最小化碰撞熵 $H_2(X) = -\\ln \\left( \\sum_{k=0}^{10} p_k^2 \\right)$ 的概率分布 $\\{p_k\\}_{k=0}^{10}$。\n\n步骤1：建立优化问题。\n由于 $-\\ln(x)$ 是一个单调递减函数，最小化 $H_2(X)$ 等价于最大化其对数中的参数。设 $S = \\sum_{k=0}^{10} p_k^2$。因此，问题转化为在以下约束条件下最大化 $S$：\n1. 归一化：$\\sum_{k=0}^{10} p_k = 1$\n2. 均值：$\\sum_{k=0}^{10} k \\, p_k = \\mu = 3.8$\n3. 非负性：对于所有 $k \\in \\{0, 1, \\dots, 10\\}$，有 $p_k \\ge 0$\n\n步骤2：分析解的性质。\n满足这些约束的所有有效概率分布在11维概率空间 $(p_0, p_1, \\dots, p_{10})$ 中构成一个凸集（具体来说，是一个凸多胞体）。目标函数 $S(\\mathbf{p}) = \\sum_{k=0}^{10} p_k^2$ 是一个严格凸函数。$S$ 的Hessian矩阵为 $H_{ij} = \\frac{\\partial^2 S}{\\partial p_i \\partial p_j} = 2\\delta_{ij}$，这是一个所有对角线元素都为正（为2）的对角矩阵，使其成为正定矩阵。\n\n凸优化的一个基本定理指出，一个凸函数在紧凸集上的最大值必须在该集合的一个极点（顶点）处取得。因此，我们必须刻画可行集的顶点。\n\n如果一个分布 $\\mathbf{p}$ 不能表示为集合中其他两个不同分布的凸组合，那么它就是一个顶点。假设一个分布有三个或更多非零概率，比如说在索引 $k_1  k_2  k_3$ 处。我们可以构造一个向量 $\\mathbf{v}$，其非零分量仅在这些索引上，且 $\\mathbf{v}$ 与约束向量正交。也就是说，$\\sum v_k = 0$ 和 $\\sum k v_k = 0$。例如，令 $v_{k_1} = k_2 - k_3$，$v_{k_2} = k_3 - k_1$，$v_{k_3} = k_1 - k_2$。分量之和为零。和 $\\sum k v_k = k_1(k_2-k_3) + k_2(k_3-k_1) + k_3(k_1-k_2) = 0$。\n对于一个足够小的 $\\epsilon  0$，分布 $\\mathbf{p}' = \\mathbf{p} + \\epsilon \\mathbf{v}$ 和 $\\mathbf{p}'' = \\mathbf{p} - \\epsilon \\mathbf{v}$ 也属于可行集。那么 $\\mathbf{p} = \\frac{1}{2}\\mathbf{p}' + \\frac{1}{2}\\mathbf{p}''$，这与 $\\mathbf{p}$ 是一个顶点的假设相矛盾。因此，可行集的任何顶点最多只能有两个非零概率。\n\n步骤3：求解两点分布。\n设具有非零概率的两个状态为 $i$ 和 $j$，其中 $i  j$。约束条件变为：\n1. $p_i + p_j = 1$\n2. $i \\cdot p_i + j \\cdot p_j = \\mu$\n\n由(1)得，$p_j = 1 - p_i$。代入(2)中：\n$i \\cdot p_i + j(1 - p_i) = \\mu$\n$p_i(i - j) = \\mu - j$\n$p_i = \\frac{\\mu - j}{i - j} = \\frac{j - \\mu}{j - i}$\n\n对于 $p_j$：\n$p_j = 1 - p_i = 1 - \\frac{j - \\mu}{j - i} = \\frac{j - i - (j - \\mu)}{j - i} = \\frac{\\mu - i}{j - i}$\n\n为了使这些是有效的概率，我们需要 $p_i \\ge 0$ 和 $p_j \\ge 0$。这意味着 $j - \\mu \\ge 0$ 和 $\\mu - i \\ge 0$，因此我们必须有 $i \\le \\mu \\le j$。\n\n步骤4：寻找最优对 $(i, j)$。\n平方和为 $S(i,j) = p_i^2 + p_j^2 = \\left(\\frac{j - \\mu}{j - i}\\right)^2 + \\left(\\frac{\\mu - i}{j - i}\\right)^2$。我们需要找到满足 $0 \\le i  j \\le 10$ 和 $i \\le 3.8 \\le j$ 的整数对 $(i, j)$，以最大化该量。\n让我们通过对 $j$ 求偏导数来分析 $S(i, j)$ 的行为（暂时将其视为连续变量），并固定 $i$：\n$\\frac{\\partial S}{\\partial j} = \\frac{2(\\mu - i)}{(j - i)^3} (j + i - 2\\mu)$.\n由于 $j  i$ 和 $\\mu  i$，符号由项 $(j + i - 2\\mu)$ 决定。如果 $j  2\\mu - i$，函数随 $j$ 增加；如果 $j  2\\mu - i$，函数随 $j$ 减少。这意味着对于固定的 $i$，$S$ 的最大值必须出现在 $j$ 的允许范围的边界上，即 $j = \\lceil \\mu \\rceil$ 或 $j = 10$。\n类似地，通过分析 $\\frac{\\partial S}{\\partial i}$，可以证明对于固定的 $j$，最大值必须出现在 $i = \\lfloor \\mu \\rfloor$ 或 $i = 0$。\n因此，最优对 $(i, j)$ 必须是由这些边界值组合形成的四个候选对之一：\n$(\\lfloor \\mu \\rfloor, \\lceil \\mu \\rceil)$、$(\\lfloor \\mu \\rfloor, 10)$、$(0, \\lceil \\mu \\rceil)$、$(0, 10)$。\n\n步骤5：对 $\\mu = 3.8$ 测试候选对。\n我们有 $\\lfloor \\mu \\rfloor = 3$ 和 $\\lceil \\mu \\rceil = 4$。候选对为 $(3,4)$、$(3,10)$、$(0,4)$ 和 $(0,10)$。所有这些都满足条件 $i \\le 3.8 \\le j$。\n\n情况1：$(i, j) = (3, 4)$\n$p_3 = \\frac{4 - 3.8}{4 - 3} = 0.2$\n$p_4 = \\frac{3.8 - 3}{4 - 3} = 0.8$\n$S = (0.2)^2 + (0.8)^2 = 0.04 + 0.64 = 0.68$\n\n情况2：$(i, j) = (0, 4)$\n$p_0 = \\frac{4 - 3.8}{4 - 0} = \\frac{0.2}{4} = 0.05$\n$p_4 = \\frac{3.8 - 0}{4 - 0} = \\frac{3.8}{4} = 0.95$\n$S = (0.05)^2 + (0.95)^2 = 0.0025 + 0.9025 = 0.905$\n\n情况3：$(i, j) = (3, 10)$\n$p_3 = \\frac{10 - 3.8}{10 - 3} = \\frac{6.2}{7} \\approx 0.88571$\n$p_{10} = \\frac{3.8 - 3}{10 - 3} = \\frac{0.8}{7} \\approx 0.11429$\n$S \\approx (0.88571)^2 + (0.11429)^2 \\approx 0.7845 + 0.0131 = 0.7976$\n\n情况4：$(i, j) = (0, 10)$\n$p_0 = \\frac{10 - 3.8}{10 - 0} = 0.62$\n$p_{10} = \\frac{3.8 - 0}{10 - 0} = 0.38$\n$S = (0.62)^2 + (0.38)^2 = 0.3844 + 0.1444 = 0.5288$\n\n比较 $S$ 的值，最大值为 $S=0.905$，出现在对 $(i, j) = (0, 4)$ 的情况下。\n\n步骤6：陈述最终分布。\n最小化碰撞熵的分布仅在 $k=0$ 和 $k=4$ 时非零。其概率为：\n$p_0 = 0.05$\n$p_4 = 0.95$\n对于 $k \\notin \\{0, 4\\}$ 的所有其他概率 $p_k$ 均为零。\n四舍五入到三位有效数字，我们得到 $p_0 = 0.0500$ 和 $p_4 = 0.950$。\n按升序排列的索引为 $k_1=0$ 和 $k_2=4$。数值序列为 $k_1, p_{k_1}, k_2, p_{k_2}$。\n这给出 $(0, 0.0500)$ 和 $(4, 0.950)$。", "answer": "$$\\boxed{\\begin{pmatrix} 0  0.0500  4  0.950 \\end{pmatrix}}$$", "id": "1655423"}, {"introduction": "理论概念在应用于实际数据时，常常会遇到意想不到的挑战。这个练习将我们从理想化的理论计算带入数据驱动的现实世界，探讨了从有限样本中估计碰撞熵的实际问题 [@problem_id:1655435]。你将分析最直观的“代入法”估计量是否存在系统性偏差，以及这个偏差是正还是负。这个问题对于任何需要从实验数据中计算熵的研究人员来说都至关重要，因为它揭示了理论与实践之间的一个关键细微差别。", "problem": "在数据科学领域，一个常见的任务是量化一系列事件的不可预测性。考虑一个系统，其中用户从一个包含 $k$ 个不同物品的集合中进行选择。设离散随机变量 $X$ 表示用户的选择，其取值集合为 $\\mathcal{X} = \\{x_1, x_2, \\ldots, x_k\\}$。选择物品 $x_i$ 的概率由概率质量函数 $p(x_i)$ 给出，其中 $\\sum_{i=1}^k p(x_i) = 1$。\n\n衡量用户选择不可预测性的一个指标是2阶Rényi熵，也称为碰撞熵，其定义为：\n$$H_2(X) = -\\ln\\left(\\sum_{i=1}^{k} p(x_i)^2\\right)$$\n\n在实践中，真实的概率 $p(x_i)$ 是未知的，必须从数据中进行估计。假设我们观察到用户选择的 $N$ 个独立同分布（i.i.d.）样本。设 $N_i$ 是在 $N$ 个样本中观察到物品 $x_i$ 的次数，因此有 $\\sum_{i=1}^k N_i = N$。则选择 $x_i$ 的经验概率估计为 $\\hat{p}(x_i) = N_i/N$。\n\n一个直接的熵估计方法是“插入”估计量（plug-in estimator），即将熵公式中的真实概率替换为其经验估计值：\n$$\\hat{H}_2(X) = -\\ln\\left(\\sum_{i=1}^{k} \\hat{p}(x_i)^2\\right)$$\n\n该估计量的偏差定义为 $\\text{Bias}(\\hat{H}_2) = E[\\hat{H}_2(X)] - H_2(X)$，其中期望 $E[\\cdot]$ 是对来自真实分布的所有可能的 $N$ 个样本集计算的。\n\n假设真实分布不是确定性的（即，没有单个 $p(x_i)$ 等于1），并且样本数量是有限的且 $N \\ge 2$，那么插入估计量 $\\hat{H}_2(X)$ 的偏差的符号是什么？\n\nA. 偏差总是正的。\n\nB. 偏差总是负的。\n\nC. 偏差总是零。\n\nD. 偏差的符号取决于具体的概率分布 $p(x_i)$。\n\nE. 偏差的符号取决于样本数量 $N$。", "solution": "设 $S \\equiv \\sum_{i=1}^{k} p(x_{i})^{2}$ 且 $\\hat{S} \\equiv \\sum_{i=1}^{k} \\hat{p}(x_{i})^{2} = \\sum_{i=1}^{k} \\left(\\frac{N_{i}}{N}\\right)^{2}$。于是\n$$\nH_{2}(X) = -\\ln S, \\qquad \\hat{H}_{2}(X) = -\\ln \\hat{S}.\n$$\n我们首先计算 $\\hat{S}$ 的均值。对于多项分布的计数，使用 $E[N_{i}] = N p(x_{i})$ 和 $\\operatorname{Var}(N_{i}) = N p(x_{i})\\left(1 - p(x_{i})\\right)$，\n$$\nE[N_{i}^{2}] = \\operatorname{Var}(N_{i}) + \\left(E[N_{i}]\\right)^{2} = N p(x_{i})(1 - p(x_{i})) + N^{2} p(x_{i})^{2}.\n$$\n因此，\n$$\nE[\\hat{S}] = \\sum_{i=1}^{k} \\frac{E[N_{i}^{2}]}{N^{2}}\n= \\sum_{i=1}^{k} \\left( p(x_{i})^{2} + \\frac{p(x_{i})(1 - p(x_{i}))}{N} \\right)\n= S + \\frac{1 - S}{N}.\n$$\n在所述假设（非确定性分布）下，$S \\in (0,1)$，并且对于任何有限的 $N \\ge 2$，我们有 $E[\\hat{S}] - S = \\frac{1 - S}{N}  0$。因此，碰撞概率的插入估计量 $\\hat{S}$ 是正偏的。\n\n因为熵估计量是 $\\hat{H}_{2} = -\\ln \\hat{S}$，并且函数 $-\\ln(\\cdot)$ 在 $(0,\\infty)$ 上是递减和凸的，所以 $\\hat{S}$ 的正偏直观上会导致 $\\hat{H}_{2}$ 的负偏。我们现在用两种互补的方法来精确地说明这一点。\n\n1) 对 $N=2$ 的精确评估：在这种情况下，两次独立同分布的抽取要么碰撞（抽到相同物品），要么不碰撞。两个样本相同的概率为 $S$，此时 $\\hat{S} = 1$；它们不同的概率为 $1 - S$，此时 $\\hat{S} = \\frac{1}{2}$。因此\n$$\nE[\\hat{H}_{2}] = E[-\\ln \\hat{S}] = S \\cdot 0 + (1 - S)\\ln 2 = (1 - S)\\ln 2.\n$$\n所以偏差为\n$$\n\\text{Bias}(\\hat{H}_{2}) = E[\\hat{H}_{2}] - H_{2} = (1 - S)\\ln 2 + \\ln S.\n$$\n定义 $b(S) \\equiv (1 - S)\\ln 2 + \\ln S$。那么\n$$\n\\frac{d}{dS} b(S) = -\\ln 2 + \\frac{1}{S}  0 \\quad \\text{for } S \\in (0,1],\n$$\n且 $b(1) = 0$。因此对于所有 $S \\in (0,1)$，都有 $b(S)  0$。这表明当 $N=2$ 时，对于所有非确定性分布，偏差都是严格为负的。\n\n2) 对一般 $N$ 的一阶展开：设 $g(x) = -\\ln x$，则 $g'(x) = -\\frac{1}{x}$ 且 $g''(x) = \\frac{1}{x^{2}}$。记 $S_{2} \\equiv \\sum_{i} p(x_{i})^{2} = S$，$S_{3} \\equiv \\sum_{i} p(x_{i})^{3}$，并将 $E[g(\\hat{S})]$ 在 $S$ 附近展开：\n$$\nE[g(\\hat{S})] \\approx g(S) + g'(S)\\big(E[\\hat{S}] - S\\big) + \\frac{1}{2} g''(S)\\operatorname{Var}(\\hat{S}).\n$$\n我们已经得到 $E[\\hat{S}] - S = \\frac{1 - S}{N}$。一个标准的多项分布计算可以得出方差的主项，\n$$\n\\operatorname{Var}(\\hat{S}) = \\frac{4}{N}\\big(S_{3} - S^{2}\\big) + O\\!\\left(\\frac{1}{N^{2}}\\right),\n$$\n并且根据柯西-施瓦茨不等式，$S_{3} \\ge S^{2}$，等号仅在分布在其支撑集上为均匀分布时成立。因此，\n$$\n\\text{Bias}(\\hat{H}_{2}) \\approx g'(S)\\frac{1 - S}{N} + \\frac{1}{2} g''(S)\\frac{4}{N}\\big(S_{3} - S^{2}\\big)\n= \\frac{1}{N}\\left( -\\frac{1 - S}{S} + \\frac{2\\,(S_{3} - S^{2})}{S^{2}} \\right).\n$$\n括号中的表达式化简为\n$$\n-\\frac{1 - S}{S} + \\frac{2(S_{3} - S^{2})}{S^{2}} = \\frac{2 S_{3} - S^{2} - S}{S^{2}}.\n$$\n我们断言，对于所有概率向量，都有 $2 S_{3} - S^{2} - S \\le 0$，并且除非分布是确定性的，否则不等式是严格的。事实上，对于每个 $x \\in [0,1]$，\n$$\n2x^{3} \\le x^{4} + x^{2} \\quad \\text{since } x^{4} - 2x^{3} + x^{2} = x^{2}(x - 1)^{2} \\ge 0.\n$$\n对 $i$ 求和得到 $2 S_{3} \\le \\sum_{i} p(x_{i})^{4} + \\sum_{i} p(x_{i})^{2}$。此外，\n$$\n\\sum_{i} p(x_{i})^{4} \\le \\left(\\sum_{i} p(x_{i})^{2}\\right)^{2} = S^{2}, \\qquad \\sum_{i} p(x_{i})^{2} \\le \\left(\\sum_{i} p(x_{i})\\right)^{2} = 1,\n$$\n因此 $2 S_{3} \\le S^{2} + 1$，即 $2 S_{3} - S^{2} - S \\le 1 - S \\le 0$，等号仅在 $S = 1$（确定性分布）时成立。因此，对于任何非确定性分布，偏差的主项都是严格为负的，并且 $1/N$ 的高阶项在有限的 $N$ 下不会改变其符号。\n\n结合 $N=2$ 的精确情况（对于所有非确定性分布，偏差严格为负）和一般情况的一阶分析（对于任何 $N \\ge 2$ 和任何非确定性分布，主项严格为负），我们得出结论：对于任何有限的 $N \\ge 2$ 和任何非确定性的真实分布，插入估计量 $\\hat{H}_{2}(X)$ 都是负偏的。\n\n因此，正确的选项是偏差总是负的。", "answer": "$$\\boxed{B}$$", "id": "1655435"}]}