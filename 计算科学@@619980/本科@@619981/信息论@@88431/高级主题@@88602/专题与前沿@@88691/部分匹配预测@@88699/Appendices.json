{"hands_on_practices": [{"introduction": "要想真正理解“部分匹配预测”（PPM）算法，我们必须首先了解它如何组织信息。第一个练习将引导您亲手构建 PPM 模型的核心数据结构：上下文频率表 [@problem_id:1647197]。通过解析一个序列并对不同上下文之后出现的符号进行分类统计，您将对该模型如何从数据中“学习”建立起基础的认识。", "problem": "在数据压缩领域，统计模型被用来预测数据流中即将出现的符号。其中一类模型是使用“部分匹配预测”（Prediction by Partial Matching, PPM）算法构建的。PPM 模型会维护特定前导序列（称为“上下文”）之后出现符号的频率计数。\n\n对于给定的上下文阶数 `k`，该模型会构建一个频率表。一个 `k` 阶上下文是一个长度为 `k` 的符号序列。阶数为 `k` 的表记录了在训练序列中找到的每个不同 `k` 阶上下文 `C`，以及紧随 `C` 之后的符号及其出现次数。阶数 `k=0` 的模型是一个特例，其上下文为空，它的表只记录整个序列中每个符号的总频率。\n\n考虑一个正在从左到右对文本序列 `S = \"AGADADAGA\"` 进行训练的 PPM 模型。在模型处理完整个序列后，下列哪个选项正确表示了阶数 `k=2`、`k=1` 和 `k=0` 的完整上下文频率表集合？\n\n表格使用以下表示法：`k=N: {Context1: {Symbol1: Count1, ...}, Context2: {...}, ...}`。\n\nA.\n`k=2`: {`AG`: {`A`: 1}, `GA`: {`D`: 1}, `AD`: {`A`: 1}, `DA`: {`D`: 1, `G`: 1}}\n`k=1`: {`A`: {`G`: 1, `D`: 1}, `G`: {`A`: 1}, `D`: {`A`: 1}}\n`k=0`: {`A`: 5, `G`: 2, `D`: 2}\n\nB.\n`k=2`: {`AG`: {`A`: 2}, `GA`: {`D`: 1}, `AD`: {`A`: 2}, `DA`: {`D`: 1, `G`: 1}}\n`k=1`: {`A`: {`G`: 2, `D`: 2}, `G`: {`A`: 2}, `D`: {`A`: 2}}\n`k=0`: {`A`: 4, `G`: 3, `D`: 2}\n\nC.\n`k=2`: {`AG`: {`A`: 2}, `GA`: {`D`: 1}, `AD`: {`A`: 2}, `DA`: {`D`: 1, `G`: 1}}\n`k=1`: {`A`: {`G`: 2, `D`: 2}, `G`: {`A`: 2}, `D`: {`A`: 2}}\n`k=0`: {`A`: 5, `G`: 2, `D`: 2}\n\nD.\n`k=2`: {`GA`: {`A`: 2}, `AG`: {`A`: 2}, `DA`: {`D`: 1, `G`: 1}}\n`k=1`: {`A`: {`G`: 2, `D`: 2}, `G`: {`A`: 2}, `D`: {`A`: 1, `G`: 1}}\n`k=0`: {`A`: 5, `G`: 2, `D`: 2}", "solution": "给定序列 S = \"AGADADAGA\"，长度为 $n=9$，从左到右处理。对于一个阶数为 $k$ 的 PPM 模型，每个出现情况都来自于位置 $i=k+1$ 到 $n$，其中上下文是长度为 $k$ 的子串 $S_{i-k}\\dots S_{i-1}$，被计数的符号是 $S_{i}$。阶数 $k=0$ 的模型只记录整个序列中符号的总频率。\n\n使用 $i=3$ 到 $9$ 计算 $k=2$ 的表：\n- $i=3$：上下文 \"AG\"，下一个是 \"A\"，得到 \"AG\": {\"A\": 1}。\n- $i=4$：上下文 \"GA\"，下一个是 \"D\"，得到 \"GA\": {\"D\": 1}。\n- $i=5$：上下文 \"AD\"，下一个是 \"A\"，得到 \"AD\": {\"A\": 1}。\n- $i=6$：上下文 \"DA\"，下一个是 \"D\"，得到 \"DA\": {\"D\": 1}。\n- $i=7$：上下文 \"AD\"，下一个是 \"A\"，更新 \"AD\": {\"A\": 2}。\n- $i=8$：上下文 \"DA\"，下一个是 \"G\"，更新 \"DA\": {\"D\": 1, \"G\": 1}。\n- $i=9$：上下文 \"AG\"，下一个是 \"A\"，更新 \"AG\": {\"A\": 2}。\n因此 $k=2$: {\"AG\": {\"A\": 2}, \"GA\": {\"D\": 1}, \"AD\": {\"A\": 2}, \"DA\": {\"D\": 1, \"G\": 1}}。\n\n使用 $i=2$ 到 $9$ 计算 $k=1$ 的表：\n- $i=2$：上下文 \"A\"，下一个是 \"G\"，得到 \"A\": {\"G\": 1}。\n- $i=3$：上下文 \"G\"，下一个是 \"A\"，得到 \"G\": {\"A\": 1}。\n- $i=4$：上下文 \"A\"，下一个是 \"D\"，更新 \"A\": {\"G\": 1, \"D\": 1}。\n- $i=5$：上下文 \"D\"，下一个是 \"A\"，得到 \"D\": {\"A\": 1}。\n- $i=6$：上下文 \"A\"，下一个是 \"D\"，更新 \"A\": {\"G\": 1, \"D\": 2}。\n- $i=7$：上下文 \"D\"，下一个是 \"A\"，更新 \"D\": {\"A\": 2}。\n- $i=8$：上下文 \"A\"，下一个是 \"G\"，更新 \"A\": {\"G\": 2, \"D\": 2}。\n- $i=9$：上下文 \"G\"，下一个是 \"A\"，更新 \"G\": {\"A\": 2}。\n因此 $k=1$: {\"A\": {\"G\": 2, \"D\": 2}, \"G\": {\"A\": 2}, \"D\": {\"A\": 2}}。\n\n通过 S 中的总频率计算 $k=0$ 的表：\n- \"A\" 出现在位置 $1,3,5,7,9$：总共 $5$ 次。\n- \"G\" 出现在位置 $2,8$：总共 $2$ 次。\n- \"D\" 出现在位置 $4,6$：总共 $2$ 次。\n因此 $k=0$: {\"A\": 5, \"G\": 2, \"D\": 2}。\n\n与选项进行比较，这组表完全匹配选项 C。", "answer": "$$\\boxed{C}$$", "id": "1647197"}, {"introduction": "PPM 算法的真正威力在于它通过其分层上下文模型处理新颖模式的能力。这一能力是通过“逃逸”（escape）机制实现的，当特定的长上下文无法提供信息时，该机制允许模型回退到更短、更通用的上下文 [@problem_id:1647198]。本练习将要求您跟踪一个序列的编码过程，仔细计算每一次逃逸事件，从而观察算法如何动态地适应数据流。", "problem": "一个“部分匹配预测”（Prediction by Partial Matching, PPM）压缩模型被用来编码一个符号序列。该模型根据其前面的符号来预测下一个符号，这些前面的符号构成一个“上下文”。所使用的前面符号的数量就是该上下文的“阶”。\n\n考虑一个最大上下文阶为 $k=2$ 的 PPM 模型。在编码一个符号时，该模型首先尝试使用 2 阶上下文（即前面的两个符号）。如果当前符号之前从未在该 2 阶上下文中出现过，模型会生成一个**逃逸事件**，并尝试 1 阶上下文（即前面的单个符号）。这个过程会向下继续，直到 0 阶上下文（它没有上下文，只考虑目前为止序列中符号的整体频率），最后到 -1 阶（它列出目前为止在序列中任何地方出现过的所有唯一符号）。\n\n一个逃逸事件被定义为在上下文层级中向下一步。例如：\n- 在 2 阶失败，导致在 1 阶进行检查，是一个逃逸事件。\n- 随后在 1 阶失败，导致在 0 阶进行检查，是第二个逃逸事件。\n- 在 0 阶失败，导致在 -1 阶进行检查，是第三个逃逸事件。\n- 如果该符号甚至不在 -1 阶模型中（即它是一个全新的符号），则会发生最后一个逃逸事件以表示新符号的出现。\n\n模型的内部符号计数表在每个符号被处理*之后*更新。\n\n计算在编码序列 `XYYXYYXXY` 时发生逃逸事件的总数。", "solution": "我们模拟一个最大上下文阶为 $k=2$ 的 PPM 编码器，它会按 $2 \\to 1 \\to 0 \\to -1$ 的顺序降阶。模型在处理完每个符号后更新其计数。每当当前符号在当前上下文模型中不存在，编码器下降一阶时，就会发生一次逃逸事件；如果该符号甚至在 -1 阶模型中也不存在（即全局新符号），则会发生一次表示新颖性的最终逃逸。当位置 $i$ 处前面的符号数量少于 $j$ 个时，可用的最高起始阶为 $\\min\\{2,i-1\\}$。\n\n我们处理序列 $XYYXYYXXY$，对每个位置 $i$ 跟踪逃逸次数 $e_{i}$，仅使用先前出现过的情况。\n\n初始化所有模型为空。\n\n位置 $1$ ($X$)，从 0 阶开始：\n- 0 阶：$X$ 在全局未见过 $\\Rightarrow$ 逃逸到 -1 阶。\n- -1 阶：$X$ 不在唯一符号列表中 $\\Rightarrow$ 最终的新颖性逃逸。\n因此 $e_{1}=2$。更新：全局已见符号 $\\{X\\}$。\n\n位置 $2$ ($Y$)，从 1 阶开始，上下文为 $X$：\n- 1 阶 (在 $X$ 之后)：未见过 $Y$ $\\Rightarrow$ 逃逸。\n- 0 阶：$Y$ 在全局未见过 (只见过 $X$) $\\Rightarrow$ 逃逸。\n- -1 阶：$Y$ 不在唯一符号列表中 $\\Rightarrow$ 最终的新颖性逃逸。\n因此 $e_{2}=3$。更新：全局已见符号 $\\{X,Y\\}$；$C_{1}[X]$ 包含 $Y$。\n\n位置 $3$ ($Y$)，从 2 阶开始，上下文为 $XY$：\n- 2 阶 ($XY$)：未见过 $Y$ $\\Rightarrow$ 逃逸。\n- 1 阶 ($Y$)：在 $Y$ 之后还未见过 $Y$ $\\Rightarrow$ 逃逸。\n- 0 阶：$Y$ 在全局已见过 $\\Rightarrow$ 成功。\n因此 $e_{3}=2$。更新：$C_{1}[Y]$ 包含 $Y$；$C_{2}[XY]$ 包含 $Y$。\n\n位置 $4$ ($X$)，从 2 阶开始，上下文为 $YY$：\n- 2 阶 ($YY$)：未见过 $X$ $\\Rightarrow$ 逃逸。\n- 1 阶 ($Y$)：在 $Y$ 之后还未见过 $X$ $\\Rightarrow$ 逃逸。\n- 0 阶：$X$ 在全局已见过 $\\Rightarrow$ 成功。\n因此 $e_{4}=2$。更新：$C_{1}[Y]$ 包含 $\\{Y,X\\}$；$C_{2}[YY]$ 包含 $X$。\n\n位置 $5$ ($Y$)，从 2 阶开始，上下文为 $YX$：\n- 2 阶 ($YX$)：未见过 $Y$ $\\Rightarrow$ 逃逸。\n- 1 阶 ($X$)：在 $X$ 之后见过 $Y$ $\\Rightarrow$ 成功。\n因此 $e_{5}=1$。更新：$C_{2}[YX]$ 包含 $Y$。\n\n位置 $6$ ($Y$)，从 2 阶开始，上下文为 $XY$：\n- 2 阶 ($XY$)：见过 $Y$ $\\Rightarrow$ 成功。\n因此 $e_{6}=0$。更新：集合中没有新符号。\n\n位置 $7$ ($X$)，从 2 阶开始，上下文为 $YY$：\n- 2 阶 ($YY$)：见过 $X$ $\\Rightarrow$ 成功。\n因此 $e_{7}=0$。\n\n位置 $8$ ($X$)，从 2 阶开始，上下文为 $YX$：\n- 2 阶 ($YX$)：未见过 $X$ ($C_{2}[YX]=\\{Y\\}$) $\\Rightarrow$ 逃逸。\n- 1 阶 ($X$)：在 $X$ 之后还未见过 $X$ ($C_{1}[X]=\\{Y\\}$) $\\Rightarrow$ 逃逸。\n- 0 阶：$X$ 在全局已见过 $\\Rightarrow$ 成功。\n因此 $e_{8}=2$。更新：$C_{1}[X]$ 包含 $\\{Y,X\\}$；$C_{2}[YX]$ 包含 $\\{Y,X\\}$。\n\n位置 $9$ ($Y$)，从 2 阶开始，上下文为 $XX$：\n- 2 阶 ($XX$)：未见过 $Y$ $\\Rightarrow$ 逃逸。\n- 1 阶 ($X$)：在 $X$ 之后见过 $Y$ $\\Rightarrow$ 成功。\n因此 $e_{9}=1$。\n\n将逃逸次数相加：\n$$E_{\\text{total}}=\\sum_{i=1}^{9} e_{i}=2+3+2+2+1+0+0+2+1=13.$$", "answer": "$$\\boxed{13}$$", "id": "1647198"}, {"introduction": "在学习了如何构建上下文表和追踪逃逸机制之后，现在是时候将所有知识整合起来进行预测了。在最后一个练习中，您将使用一个具有特定概率计算规则的简化 PPM 模型来计算序列中下一个符号的概率 [@problem_id:1647202]。这项任务将巩固您对原始频率计数如何转化为最终预测概率的理解，而这正是 PPM 算法的核心功能。", "problem": "部分匹配预测（Prediction by Partial Matching, PPM）是一种统计数据压缩算法，它根据前面的符号（被称为“上下文”）来预测序列中的下一个符号。本问题探讨该算法的一个特定变体。\n\n考虑一个由以下规则定义的“简化PPM”模型，该模型用于预测给定序列后的符号。\n\n**算法定义：简化PPM**\n\n1.  **初始上下文**：为了预测一个序列后某个符号的概率，模型从最大可能阶数的上下文开始。对于给定的最大阶数 $k_{\\text{max}}$，初始上下文是序列的最后 $k_{\\text{max}}$ 个符号。\n\n2.  **模型统计数据（对于一个$k$阶上下文，$c_k$）**：\n    *   模型的统计数据源自一个训练序列。\n    *   令 $N(c_k)$ 为上下文 $c_k$ 在训练序列中出现的总次数，其中每次出现后都紧跟着至少一个符号。\n    *   令 $N(s|c_k)$ 为在上下文 $c_k$ 之后立即观察到特定符号 $s$ 的次数。\n    *   令 $U(c_k)$ 为在 $c_k$ 之后观察到的所有不同符号的集合。\n\n3.  **$k$阶概率计算**：\n    *   **情况1（符号已见）**：如果待预测的符号 $s$ 在集合 $U(c_k)$ 中，其概率直接计算如下：\n        $$P_k(s | c_k) = \\frac{N(s|c_k)}{N(c_k) + |U(c_k)|}$$\n    *   **情况2（符号未见 - 退避）**：如果符号 $s$ *不*在集合 $U(c_k)$ 中，模型将“退避”到更低阶的模型。此时的概率是退避概率与下一个更低阶模型概率的乘积：\n        $$P_k(s | c_k) = P_{\\text{esc},k} \\times P_{k-1}(s | c_{k-1})$$\n        其中退避概率为 $P_{\\text{esc},k} = \\frac{|U(c_k)|}{N(c_k) + |U(c_k)|}$，而 $c_{k-1}$ 是上下文 $c_k$ 的长度为 $k-1$ 的后缀。\n\n4.  **基本模型**：\n    *   **0阶模型**：上下文为空字符串，$c_0 = \\text{\"\"}$。对于此模型，$N(c_0)$ 是训练序列的总长度，$U(c_0)$ 是整个序列中所有不同符号的集合。\n    *   **-1阶模型**：这是一个均匀先验模型。如果从0阶模型发生退避（当预测一个从未在训练序列中出现过的符号时会发生这种情况），该模型会为任何符号分配 $1/M$ 的概率，其中 $M$ 是字母表的大小。\n\n**问题：**\n\n一个简化PPM模型使用训练序列 `AABABAA` 构建。可能的符号字母表由该序列中出现的所有不同符号组成。最大模型阶数设为 $k_{\\text{max}}=2$。\n\n使用这个特定模型，序列 `AABABAA` 之后紧跟着的符号是 'A' 的概率是多少？你的答案应为最简分数形式。", "solution": "训练序列是 AABABAA，所以字母表是 $\\{A,B\\}$。最大阶数是 $k_{\\text{max}}=2$，因此预测 AABABAA 之后下一个符号的初始上下文是最后两个符号，即 $c_{2}=\\text{\"AA\"}$。\n\n对于一个 $k$ 阶上下文 $c_{k}$，模型使用以下公式：\n$$P_{k}(s\\mid c_{k})=\\begin{cases}\n\\frac{N(s\\mid c_{k})}{N(c_{k})+|U(c_{k})|}, & \\text{if } s\\in U(c_{k}) \\\\[6pt]\nP_{\\text{esc},k}\\,P_{k-1}(s\\mid c_{k-1}), & \\text{if } s\\notin U(c_{k})\n\\end{cases}$$\n其中退避概率为\n$$P_{\\text{esc},k}=\\frac{|U(c_{k})|}{N(c_{k})+|U(c_{k})|}.$$\n\n从训练序列中计算2阶统计数据，方法是计算长度为2且其后紧跟一个符号的上下文。出现的次数如下：\n- $\\text{\"AA\"}\\to\\text{\"B\"}$ （来自位置$1$–$3$），\n- $\\text{\"AB\"}\\to\\text{\"A\"}$ （来自位置$2$–$4$和$4$–$6$），\n- $\\text{\"BA\"}\\to\\text{\"B\"}$ （来自位置$3$–$5$）和 $\\text{\"BA\"}\\to\\text{\"A\"}$ （来自位置$5$–$7$）。\n在位置$6$–$7$的末尾 $\\text{\"AA\"}$ 没有后续符号，因此不计数。\n\n因此，对于 $c_{2}=\\text{\"AA\"}$，\n$$N(\\text{\"AA\"})=1,\\quad U(\\text{\"AA\"})=\\{\\text{\"B\"}\\},\\quad N(A\\mid \\text{\"AA\"})=0.$$\n由于 $A\\notin U(\\text{\"AA\"})$，我们进行退避：\n$$P_{2}(A\\mid \\text{\"AA\"})=P_{\\text{esc},2}\\,P_{1}(A\\mid \\text{\"A\"}),\\quad P_{\\text{esc},2}=\\frac{|U(\\text{\"AA\"})|}{N(\\text{\"AA\"})+|U(\\text{\"AA\"})|}=\\frac{1}{1+1}=\\frac{1}{2}.$$\n\n现在计算1阶上下文 $c_{1}=\\text{\"A\"}$ 的概率，方法是计算长度为1且其后紧跟一个符号的上下文。出现的次数如下：\n- $\\text{\"A\"}\\to\\text{\"A\"}$ （位置$1$–$2$和$6$–$7$），\n- $\\text{\"A\"}\\to\\text{\"B\"}$ （位置$2$–$3$和$4$–$5$）。\n因此，\n$$N(\\text{\"A\"})=4,\\quad U(\\text{\"A\"})=\\{\\text{\"A\"},\\text{\"B\"}\\},\\quad N(A\\mid \\text{\"A\"})=2,$$\n所以\n$$P_{1}(A\\mid \\text{\"A\"})=\\frac{N(A\\mid \\text{\"A\"})}{N(\\text{\"A\"})+|U(\\text{\"A\"})|}=\\frac{2}{4+2}=\\frac{1}{3}.$$\n\n将各因子合并：\n$$P_{2}(A\\mid \\text{\"AA\"})=\\frac{1}{2}\\cdot \\frac{1}{3}=\\frac{1}{6}.$$\n由于 $A\\in U(\\text{\"A\"})$，不需要进一步退避，因此不使用更低的阶数。\n\n因此，在这个简化PPM模型下，AABABAA之后的符号是 $A$ 的概率是 $\\frac{1}{6}$。", "answer": "$$\\boxed{\\frac{1}{6}}$$", "id": "1647202"}]}