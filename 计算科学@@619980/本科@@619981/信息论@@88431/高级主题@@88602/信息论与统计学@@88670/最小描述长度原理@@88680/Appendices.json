{"hands_on_practices": [{"introduction": "动手实践的第一步是应用最小描述长度（MDL）原则来解决一个经典的统计模型选择问题。通过一个天体物理学中粒子发射计数的假设场景，我们将比较两种解释数据的模型：一个简单的单速率泊松过程和一个更复杂的双速率泊松过程。这个练习将清晰地展示MDL如何通过惩罚模型复杂度，在模型的拟合优度与简洁性之间做出权衡 [@problem_id:1641400]。", "problem": "一位天体物理学家正在监测一颗遥远的脉冲星的高能粒子发射。在一个小时的观测窗口内，一个探测器记录了这些发射的时间戳。一个关键问题是，该脉冲星的发射率是恒定的，还是在观测期间发生了变化。\n\n数据总结如下：\n- 在前30分钟内，记录到 $k_1 = 10$ 个事件。\n- 在后30分钟内，记录到 $k_2 = 20$ 个事件。\n\n为了在两个竞争性假设之间做出选择，该天体物理学家使用了最小描述长度（MDL）原则。给定数据 $D$，模型 $M$ 的总描述长度（或称编码长度） $L$ 以奈特（nat，使用自然对数）为单位计算如下：\n$$L(M) = -\\ln P(D|\\hat{\\theta}) + \\frac{d}{2}\\ln N$$\n其中：\n- $\\ln P(D|\\hat{\\theta})$ 是给定模型下数据的最大化对数似然。对于一个描述来自泊松过程的事件计数的模型，若观测到 $k$ 个事件，此项由 $\\ln P(D|\\hat{\\theta}) = k \\ln k - k - \\ln(k!)$ 给出。\n- $d$ 是模型中自由参数的数量。\n- $N$ 是在整个观测窗口内观测到的事件总数。\n\n正在考虑的两个模型是：\n- **模型 $M_1$**：在整个一小时内具有恒定速率的单一泊松过程。该模型有一个自由参数（即速率）。\n- **模型 $M_2$**：两个独立的泊松过程，一个用于第一个30分钟区间，另一个用于第二个区间。该模型有两个自由参数（每个区间一个速率）。对于该模型，总的最大化对数似然是每个区间的对数似然之和。\n\n计算编码长度之差 $\\Delta L = L(M_1) - L(M_2)$。编码长度较小的模型更优。将最终答案四舍五入到三位有效数字。", "solution": "设 $k_{1}=10$，$k_{2}=20$，总计数为 $N=k_{1}+k_{2}=30$。对于泊松计数模型，给定 $k$ 的最大化对数似然如题所述为 $\\ln P(D|\\hat{\\theta})=k\\ln k - k - \\ln(k!)$。\n\n对于模型 $M_{1}$（整个小时内一个泊松速率，$d=1$），编码长度为\n$$\nL(M_{1})=-\\ln P(D|\\hat{\\theta})+\\frac{d}{2}\\ln N\n= -\\big(N\\ln N - N - \\ln(N!)\\big) + \\frac{1}{2}\\ln N\n= -N\\ln N + N + \\ln(N!) + \\frac{1}{2}\\ln N.\n$$\n\n对于模型 $M_{2}$（两个半时段内两个独立的泊松速率，$d=2$），总的最大化对数似然是各个区间的总和，因此\n$$\nL(M_{2})=-\\left[(k_{1}\\ln k_{1} - k_{1} - \\ln(k_{1}!))+(k_{2}\\ln k_{2} - k_{2} - \\ln(k_{2}!))\\right] + \\frac{2}{2}\\ln N\n= -k_{1}\\ln k_{1} + k_{1} + \\ln(k_{1}!) - k_{2}\\ln k_{2} + k_{2} + \\ln(k_{2}!) + \\ln N.\n$$\n\n编码长度的差异是\n$$\n\\Delta L=L(M_{1})-L(M_{2})\n= \\left[-N\\ln N + N + \\ln(N!) + \\frac{1}{2}\\ln N\\right]\n-\\left[-k_{1}\\ln k_{1} + k_{1} + \\ln(k_{1}!) - k_{2}\\ln k_{2} + k_{2} + \\ln(k_{2}!) + \\ln N\\right].\n$$\n使用 $N=k_{1}+k_{2}$，关于 $k$ 的线性项相消，得到\n$$\n\\Delta L=\\left(k_{1}\\ln k_{1} + k_{2}\\ln k_{2} - N\\ln N\\right) - \\frac{1}{2}\\ln N + \\left[\\ln(N!) - \\ln(k_{1}!) - \\ln(k_{2}!)\\right]\n= \\left(k_{1}\\ln k_{1} + k_{2}\\ln k_{2} - N\\ln N\\right) - \\frac{1}{2}\\ln N + \\ln\\!\\binom{N}{k_{1}}.\n$$\n\n代入 $k_{1}=10$，$k_{2}=20$，$N=30$：\n- 计算对数项：\n$$\n10\\ln 10 + 20\\ln 20 - 30\\ln 30 \\approx 23.02585 + 59.91465 - 102.03592 = -19.09542.\n$$\n- 计算惩罚项：\n$$\n-\\frac{1}{2}\\ln N = -\\frac{1}{2}\\ln 30 \\approx -1.70060.\n$$\n- 通过阶乘的对数计算组合项：\n$$\n\\ln\\!\\binom{30}{10}=\\ln(30!) - \\ln(20!) - \\ln(10!) \\approx 74.65824 - 42.33562 - 15.10441 = 17.21821.\n$$\n\n合并所有部分：\n$$\n\\Delta L \\approx (-19.09542) + (-1.70060) + 17.21821 = -3.57781.\n$$\n四舍五入到三位有效数字，得到 $-3.58$。由于 $\\Delta L = L(M_1) - L(M_2) < 0$，这意味着 $L(M_1) < L(M_2)$。因此，模型 $M_{1}$ 的编码长度更小，是更优的模型。", "answer": "$$\\boxed{-3.58}$$", "id": "1641400"}, {"introduction": "在处理真实世界的数据时，我们常常会遇到“异常值”。下一个练习将探讨MDL原则如何帮助我们决定一个数据点是应该被看作随机波动，还是一个需要特别处理的异常。我们将比较两种假设：一种认为所有数据点都来自同一个高斯分布，另一种则认为大部分数据来自一个高斯分布，而有一个异常值被明确地单独编码 [@problem_id:1641424]。这个过程揭示了MDL在构建稳健模型方面的威力，即判断何时为“例外”付出额外的编码代价是值得的。", "problem": "一位分析师正在使用最小描述长度 (MDL) 原则评估一个小型测量数据集 `D = {2.1, 2.9, 3.1, 3.3, 3.5, 10.0}`。目标是确定两个相互竞争的假设中，哪一个能为数据提供更简洁的解释。一个假设的总描述长度 (DL) 是描述模型的成本与给定模型下描述数据的成本之和，即 $DL(\\text{Hypothesis}) = DL(\\text{Model}) + DL(\\text{Data} | \\text{Model})$。所有描述长度均以奈特 (nats) 为单位进行度量。\n\n**假设 H1：** 所有 $N=6$ 个数据点均来自同一个高斯分布 $\\mathcal{N}(\\mu, \\sigma^2)$。\n\n**假设 H2：** $N=6$ 个数据点中的一个是离群值，该离群值被显式描述，而其余 $N-1=5$ 个“内点”来自一个高斯分布 $\\mathcal{N}(\\mu', \\sigma'^2)$。对于此假设，假定离群值是数据点 `10.0`。\n\n成本函数定义如下：\n\n1.  **高斯分布的模型成本：** 对 $n$ 个数据点拟合的高斯模型的参数编码成本由 $DL(\\text{Gaussian Params}) = (k/2) \\ln(n)$ 给出，其中 $k=2$ 是参数（μ 和 σ）的数量。对于所有高斯模型，使用参数的最大似然估计 (MLE)，其中均值 $\\mu$ 是样本均值，方差 $\\sigma^2$ 是根据所建模的 $n$ 个点计算出的样本方差 $(1/n) \\sum(x_i - \\mu)^2$。\n\n2.  **H2 中离群值的模型成本：** 指定 H2 模型的成本有两部分：\n    a. 识别 $N$ 个点中哪个是指定的离群值的成本，即 $\\ln(N)$。\n    b. 显式编码该离群值数值的成本，这是一个常数 $C = 8.0$ 奈特。\n\n3.  **给定高斯模型的数据成本：** 在给定参数为 $\\mu$ 和 $\\sigma$ 的高斯模型的情况下，编码 $n$ 个数据点的成本是负对数似然：\n    $DL(\\text{Data} | \\text{Gaussian}) = n \\ln(\\sigma) + (n/2) \\ln(2\\pi) + (1/(2\\sigma^2)) \\sum(x_i - \\mu)^2$。\n\n在您的计算中，请使用以下近似值：$\\ln(2\\pi) \\approx 1.838$，$\\ln(5) \\approx 1.609$ 和 $\\ln(6) \\approx 1.792$。\n\n计算描述长度的差值 $DL(H1) - DL(H2)$。正值表示假设 H2 提供了更紧凑的描述。将您的最终答案四舍五入到三位有效数字。", "solution": "我们遵循 MDL 原则，有\n$$\nDL(\\text{Hypothesis})=DL(\\text{Model})+DL(\\text{Data}\\mid \\text{Model}).\n$$\n对于具有 $n$ 个点的高斯模型，其模型成本为 $DL(\\text{Gaussian Params})=\\frac{k}{2}\\ln(n)$，其中 $k=2$，因此 $DL=\\ln(n)$。给定一个高斯分布 $\\mathcal{N}(\\mu,\\sigma^{2})$，数据成本为\n$$\nDL(\\text{Data}\\mid \\text{Gaussian})=n\\ln(\\sigma)+\\frac{n}{2}\\ln(2\\pi)+\\frac{1}{2\\sigma^{2}}\\sum_{i=1}^{n}(x_{i}-\\mu)^{2}.\n$$\n在最大似然估计 (MLE) 处，$\\mu$ 是样本均值，$\\sigma^{2}=\\frac{1}{n}\\sum_{i=1}^{n}(x_{i}-\\mu)^{2}$。记 $SS=\\sum_{i=1}^{n}(x_{i}-\\mu)^{2}$。那么 $\\sigma^{2}=SS/n$ 并且\n$$\nDL(\\text{Data}\\mid \\text{Gaussian MLE})=n\\ln(\\sigma)+\\frac{n}{2}\\ln(2\\pi)+\\frac{n}{2}\n=\\frac{n}{2}\\big[\\ln(2\\pi e)+\\ln(SS/n)\\big].\n$$\n我们将使用 $\\ln(2\\pi)\\approx 1.838$，因此 $\\ln(2\\pi e)=\\ln(2\\pi)+1\\approx 2.838$，以及 $\\ln(5)\\approx 1.609$，$\\ln(6)\\approx 1.792$。\n\n假设 H1：所有 $N=6$ 个点来自同一个高斯分布。数据为 $D=\\{2.1,2.9,3.1,3.3,3.5,10.0\\}$，因此 $n=6$，$\\mu_{1}=\\frac{2.1+2.9+3.1+3.3+3.5+10.0}{6}=\\frac{24.9}{6}=4.15$。离差平方为\n$$\n(2.1-4.15)^{2}=4.2025,\\quad (2.9-4.15)^{2}=1.5625,\\quad (3.1-4.15)^{2}=1.1025,\n$$\n$$\n(3.3-4.15)^{2}=0.7225,\\quad (3.5-4.15)^{2}=0.4225,\\quad (10.0-4.15)^{2}=34.2225,\n$$\n所以\n$$\nSS_{1}=4.2025+1.5625+1.1025+0.7225+0.4225+34.2225=42.235,\\quad \\frac{SS_{1}}{n}=\\frac{42.235}{6}\\approx 7.03917\n$$\n因此\n$$\nDL(\\text{Data}\\mid H1)=\\frac{6}{2}\\big[\\,\\ln(2\\pi e)+\\ln(SS_{1}/6)\\,\\big]\n\\approx3\\big[\\,2.838+\\ln(7.03917)\\,\\big].\n$$\n使用 $\\ln(7.03917)\\approx 1.95149$，可得\n$$\nDL(\\text{Data}\\mid H1)\\approx 3\\,(2.838+1.95149)=14.3685.\n$$\n模型成本为 $DL(\\text{Model}\\mid H1)=\\ln(6)\\approx 1.792$。因此\n$$\nDL(H1)\\approx 1.792+14.3685=16.1605.\n$$\n\n假设 H2：一个离群值 (给定为 $10.0$)被显式编码；其余 $n=5$ 个内点服从高斯分布。内点为 $\\{2.1,2.9,3.1,3.3,3.5\\}$，所以\n$$\n\\mu_{2}=\\frac{2.1+2.9+3.1+3.3+3.5}{5}=\\frac{14.9}{5}=2.98,\n$$\n其离差平方为\n$$\n(2.1-2.98)^{2}=0.7744,\\quad (2.9-2.98)^{2}=0.0064,\\quad (3.1-2.98)^{2}=0.0144,\n$$\n$$\n(3.3-2.98)^{2}=0.1024,\\quad (3.5-2.98)^{2}=0.2704,\n$$\n所以\n$$\nSS_{2}=0.7744+0.0064+0.0144+0.1024+0.2704=1.168,\\quad \\frac{SS_{2}}{5}=0.2336.\n$$\n因此\n$$\nDL(\\text{Data}\\mid H2)=\\frac{5}{2}\\big[\\,\\ln(2\\pi e)+\\ln(SS_{2}/5)\\,\\big]\n=\\frac{5}{2}\\big[\\,2.838+\\ln(0.2336)\\,\\big].\n$$\n使用 $\\ln(0.2336)\\approx -1.45414$，我们得到\n$$\nDL(\\text{Data}\\mid H2)\\approx \\frac{5}{2}\\,(2.838-1.45414)=3.45965.\n$$\nH2 的模型成本包括 $5$ 个内点的高斯参数成本、从 $6$ 个点中识别离群值的成本，以及显式编码成本 $C=8.0$：\n$$\nDL(\\text{Model}\\mid H2)=\\ln(5)+\\ln(6)+C \\approx 1.609+1.792+8.0=11.401.\n$$\n因此\n$$\nDL(H2)\\approx 11.401+3.45965=14.86065.\n$$\n\n所求的差值为\n$$\nDL(H1)-DL(H2)\\approx 16.1605-14.86065=1.29985\\approx 1.30\\ \\text{nats},\n$$\n我们按要求四舍五入到三位有效数字。正值表示 H2 提供了更紧凑的描述。", "answer": "$$\\boxed{1.30}$$", "id": "1641424"}, {"introduction": "为了展示MDL原则的普适性，我们最后一个练习将跳出传统的统计框架，进入图论和网络压缩的领域。我们将探索如何利用图的“着色”作为一种模型，来更有效地描述（即压缩）一个网络图的边结构。这个练习 [@problem_id:1641413] 巧妙地诠释了MDL的核心思想：一个更复杂的模型（例如使用更多颜色）可能会增加模型本身的描述成本 $L_{\\text{model}}$，但如果它能显著降低描述数据（即图的边）的成本 $L_{\\text{data}}$，那么这种复杂性就是合理的。", "problem": "一个数据科学团队的任务是压缩大型企业客户网络的网络拓扑，以作归档之用。他们决定将每个网络建模为无向图，并采用一种基于最小描述长度（MDL）原则的压缩策略。该策略通过使用图着色作为一种假设来降低描述图的边结构的成本。\n\n对于一个具有 $N$ 个顶点的图，在给定一个特定的有效 $k$-着色的情况下，其总描述长度 $L$ 定义为模型成本和数据成本之和：$L = L_{\\text{model}} + L_{\\text{data}}$。\n\n1.  **模型成本 ($L_{\\text{model}}$)**：这是以比特为单位，用于指定每个顶点颜色的成本。该团队使用一种高效的渐进编码方案，该成本由颜色划分的香农熵给出：\n    $$L_{\\text{model}} = N \\sum_{i=1}^{k} -p_i \\log_2(p_i)$$\n    其中 $p_i = n_i/N$ 是被赋予颜色 $i$ 的顶点所占的比例，$n_i$ 是具有颜色 $i$ 的顶点的数量。集合 $\\{n_1, n_2, \\dots, n_k\\}$ 构成了对 $N$ 个顶点的一个划分。\n\n2.  **数据成本 ($L_{\\text{data}}$)**：这是在给定着色的情况下，以比特为单位，用于指定图的边的成本。由于有效的着色意味着相同颜色的顶点之间没有边，因此只需要编码*不同*颜色顶点之间潜在边的存在与否。假设每条这样的潜在边以 50% 的概率存在（需要 1 比特进行编码），则数据成本等于不同颜色顶点对的总数：\n    $$L_{\\text{data}} = \\sum_{1 \\le i  j \\le k} n_i n_j$$\n\n该团队分析了一个具有 $N=120$ 个顶点的特定网络图。他们发现该图既是 2-可着色的，也是 3-可着色的。他们发现了一种有效的 2-着色，将顶点划分为两个大小分别为 $n_1=60$ 和 $n_2=60$ 的集合。他们还为*同一个图*找到了一种有效的 3-着色，将顶点划分为三个大小分别为 $n_1=100$、$n_2=10$ 和 $n_3=10$ 的集合。\n\n设使用 2-着色方案的总描述长度为 $L_2$，使用 3-着色方案的总描述长度为 $L_3$。计算差值 $\\Delta L = L_3 - L_2$。请用以 2 为底的对数和整数组成的解析表达式来表示你的答案。", "solution": "问题要求计算同一个图在两种不同着色方案下的总描述长度之差，即 $\\Delta L = L_3 - L_2$。总描述长度由 $L = L_{\\text{model}} + L_{\\text{data}}$ 给出。我们将分别计算 $L_2$ 和 $L_3$，然后求出它们的差值。\n\n**步骤 1：计算 2-着色的总描述长度 ($L_2$)**\n\n该图有 $N=120$ 个顶点。2-着色划分为 $n_1 = 60$ 和 $n_2 = 60$。\n\n首先，我们计算模型成本 $L_{\\text{model}}(2)$。颜色概率为 $p_1 = n_1/N = 60/120 = 1/2$ 和 $p_2 = n_2/N = 60/120 = 1/2$。\n\n使用模型成本的公式：\n$$L_{\\text{model}}(2) = N \\left( -p_1 \\log_2(p_1) - p_2 \\log_2(p_2) \\right)$$\n$$L_{\\text{model}}(2) = 120 \\left( -\\frac{1}{2} \\log_2\\left(\\frac{1}{2}\\right) - \\frac{1}{2} \\log_2\\left(\\frac{1}{2}\\right) \\right)$$\n由于 $\\log_2(1/2) = -1$：\n$$L_{\\text{model}}(2) = 120 \\left( -\\frac{1}{2}(-1) - \\frac{1}{2}(-1) \\right) = 120 \\left( \\frac{1}{2} + \\frac{1}{2} \\right) = 120 \\times 1 = 120 \\text{ 比特。}$$\n\n接下来，我们计算数据成本 $L_{\\text{data}}(2)$。对于 $k=2$，公式简化为：\n$$L_{\\text{data}}(2) = n_1 n_2$$\n$$L_{\\text{data}}(2) = 60 \\times 60 = 3600 \\text{ 比特。}$$\n\n2-着色的总描述长度为：\n$$L_2 = L_{\\text{model}}(2) + L_{\\text{data}}(2) = 120 + 3600 = 3720 \\text{ 比特。}$$\n\n**步骤 2：计算 3-着色的总描述长度 ($L_3$)**\n\n3-着色划分为 $n_1 = 100$，$n_2 = 10$ 和 $n_3 = 10$。\n\n首先，我们计算模型成本 $L_{\\text{model}}(3)$。颜色概率为 $p_1 = n_1/N = 100/120 = 5/6$，$p_2 = n_2/N = 10/120 = 1/12$，以及 $p_3 = n_3/N = 10/120 = 1/12$。\n\n使用模型成本的公式：\n$$L_{\\text{model}}(3) = N \\left( -p_1 \\log_2(p_1) - p_2 \\log_2(p_2) - p_3 \\log_2(p_3) \\right)$$\n$$L_{\\text{model}}(3) = 120 \\left( -\\frac{5}{6} \\log_2\\left(\\frac{5}{6}\\right) - \\frac{1}{12} \\log_2\\left(\\frac{1}{12}\\right) - \\frac{1}{12} \\log_2\\left(\\frac{1}{12}\\right) \\right)$$\n$$L_{\\text{model}}(3) = 120 \\left( -\\frac{5}{6} \\log_2\\left(\\frac{5}{6}\\right) - \\frac{2}{12} \\log_2\\left(\\frac{1}{12}\\right) \\right)$$\n$$L_{\\text{model}}(3) = 120 \\left( -\\frac{5}{6} (\\log_2(5) - \\log_2(6)) - \\frac{1}{6} (-\\log_2(12)) \\right)$$\n$$L_{\\text{model}}(3) = 120 \\left( \\frac{5}{6} (\\log_2(6) - \\log_2(5)) + \\frac{1}{6} \\log_2(12) \\right)$$\n我们展开对数：$\\log_2(6) = \\log_2(2 \\times 3) = \\log_2(2) + \\log_2(3) = 1 + \\log_2(3)$ 以及 $\\log_2(12) = \\log_2(4 \\times 3) = \\log_2(4) + \\log_2(3) = 2 + \\log_2(3)$。\n$$L_{\\text{model}}(3) = 120 \\left( \\frac{5}{6} (1 + \\log_2(3) - \\log_2(5)) + \\frac{1}{6} (2 + \\log_2(3)) \\right)$$\n$$L_{\\text{model}}(3) = 120 \\left( \\frac{5}{6} + \\frac{5}{6}\\log_2(3) - \\frac{5}{6}\\log_2(5) + \\frac{2}{6} + \\frac{1}{6}\\log_2(3) \\right)$$\n$$L_{\\text{model}}(3) = 120 \\left( \\frac{7}{6} + \\frac{6}{6}\\log_2(3) - \\frac{5}{6}\\log_2(5) \\right)$$\n$$L_{\\text{model}}(3) = 120 \\left( \\frac{7}{6} \\right) + 120 \\log_2(3) - 120 \\left( \\frac{5}{6} \\right) \\log_2(5)$$\n$$L_{\\text{model}}(3) = 140 + 120 \\log_2(3) - 100 \\log_2(5) \\text{ 比特。}$$\n\n接下来，我们计算数据成本 $L_{\\text{data}}(3)$。对于 $k=3$：\n$$L_{\\text{data}}(3) = n_1 n_2 + n_1 n_3 + n_2 n_3$$\n$$L_{\\text{data}}(3) = (100)(10) + (100)(10) + (10)(10)$$\n$$L_{\\text{data}}(3) = 1000 + 1000 + 100 = 2100 \\text{ 比特。}$$\n\n3-着色的总描述长度为：\n$$L_3 = L_{\\text{model}}(3) + L_{\\text{data}}(3) = (140 + 120 \\log_2(3) - 100 \\log_2(5)) + 2100$$\n$$L_3 = 2240 + 120 \\log_2(3) - 100 \\log_2(5) \\text{ 比特。}$$\n\n**步骤 3：计算差值 $\\Delta L = L_3 - L_2$**\n$$\\Delta L = L_3 - L_2 = (2240 + 120 \\log_2(3) - 100 \\log_2(5)) - 3720$$\n$$\\Delta L = 120 \\log_2(3) - 100 \\log_2(5) - 1480$$\n这就是描述长度之差的最终解析表达式。", "answer": "$$\\boxed{120 \\log_{2}(3) - 100 \\log_{2}(5) - 1480}$$", "id": "1641413"}]}