{"hands_on_practices": [{"introduction": "本练习将从最基本的情景入手，帮助你掌握连续分布相对熵的计算。我们将探讨当一个概率模型（均匀分布）被一个覆盖范围更广的新模型（另一个均匀分布）所取代时，信息增益如何量化。通过这个简单的例子，你可以直观地理解相对熵是如何与概率区间的“大小”或“范围”相关联的，并为更复杂的计算奠定坚实基础。[@problem_id:1655218]", "problem": "假设一个针对连续随机变量 $X$ 的初始概率模型 $P$ 假定 $X$ 在区间 $[a, b]$ 上服从均匀分布。随后，一个记为 $Q$ 的修正后更精确的模型提出，$X$ 转而是在一个更大的区间 $[c, d]$ 上服从均匀分布。已知初始区间完全包含在修正后的区间内，即 $c \\le a < b \\le d$。\n\nKullback-Leibler (KL) 散度 $D_{KL}(P || Q)$ 是衡量当我们将信念从先验概率分布 $P$ 修正为后验概率分布 $Q$ 时所获得的信息增益的一种度量。请计算从初始模型 $P$ 到修正模型 $Q$ 的 KL 散度 $D_{KL}(P || Q)$。\n\n答案请用包含 $a, b, c,$ 和 $d$ 的符号表达式表示。", "solution": "设 $P$ 为 $\\operatorname{Unif}[a,b]$ 分布，$Q$ 为 $\\operatorname{Unif}[c,d]$ 分布，其中 $c \\le a < b \\le d$。对应的概率密度函数为\n$$\np(x)=\\begin{cases}\n\\frac{1}{b-a}, & x\\in[a,b],\\\\\n0, & \\text{其它},\n\\end{cases}\n\\quad\nq(x)=\\begin{cases}\n\\frac{1}{d-c}, & x\\in[c,d],\\\\\n0, & \\text{其它}.\n\\end{cases}\n$$\n对于连续分布，Kullback-Leibler 散度定义为\n$$\nD_{KL}(P\\|Q)=\\int_{-\\infty}^{\\infty} p(x)\\,\\ln\\!\\left(\\frac{p(x)}{q(x)}\\right)\\,dx.\n$$\n因为 $[a,b]\\subseteq[c,d]$，对于所有 $x\\in[a,b]$，我们有 $q(x)=\\frac{1}{d-c}$，而在区间 $[a,b]$ 之外，$p(x)=0$。因此，\n$$\nD_{KL}(P\\|Q)=\\int_{a}^{b}\\frac{1}{b-a}\\,\\ln\\!\\left(\\frac{\\frac{1}{b-a}}{\\frac{1}{d-c}}\\right)\\,dx\n=\\int_{a}^{b}\\frac{1}{b-a}\\,\\ln\\!\\left(\\frac{d-c}{b-a}\\right)\\,dx.\n$$\n被积函数是常数，所以\n$$\nD_{KL}(P\\|Q)=\\ln\\!\\left(\\frac{d-c}{b-a}\\right)\\int_{a}^{b}\\frac{1}{b-a}\\,dx\n=\\ln\\!\\left(\\frac{d-c}{b-a}\\right)\\cdot\\frac{b-a}{b-a}\n=\\ln\\!\\left(\\frac{d-c}{b-a}\\right).\n$$", "answer": "$$\\boxed{\\ln\\!\\left(\\frac{d-c}{b-a}\\right)}$$", "id": "1655218"}, {"introduction": "在掌握了基本计算后，我们转向应用相对熵来比较参数化分布族中的成员。本练习将探讨两个具有相同方差但均值不同的正态分布之间的差异。由于KL散度本身不具有对称性，我们还将引入杰弗里斯散度（Jeffreys divergence），一种对称化的度量，以更全面地评估两个分布的“距离”。[@problem_id:1655241]", "problem": "在信息论中，衡量两个概率分布之间的“距离”或差异性的一种方法是使用散度度量。考虑定义在实数轴上的随机变量 $x$ 的两个连续概率密度函数 $p(x)$ 和 $q(x)$。从 $q$ 到 $p$ 的 Kullback-Leibler (KL) 散度，又称相对熵，定义为：\n$$D_{KL}(p||q) = \\int_{-\\infty}^{\\infty} p(x) \\ln\\left(\\frac{p(x)}{q(x)}\\right) dx$$\nKL 散度不是对称的，即一般情况下 $D_{KL}(p||q) \\neq D_{KL}(q||p)$。为了创建一个对称的度量，Jeffreys 散度 $J(p, q)$ 被定义为两个 KL 散度之和：\n$$J(p, q) = D_{KL}(p||q) + D_{KL}(q||p)$$\n设 $p(x)$ 为均值为 $\\mu_A$、方差为 $\\sigma^2$ 的单变量正态分布的概率密度函数。设 $q(x)$ 为另一个均值为 $\\mu_B$ 但方差同为 $\\sigma^2$ 的单变量正态分布的概率密度函数。\n\n求这两个正态分布的 Jeffreys 散度 $J(p, q)$。请用 $\\mu_A$、$\\mu_B$ 和 $\\sigma$ 的符号表达式表示你的答案。", "solution": "我们从 Kullback-Leibler 散度的定义开始：\n$$\nD_{KL}(p\\|q)=\\int_{-\\infty}^{\\infty} p(x)\\,\\ln\\!\\left(\\frac{p(x)}{q(x)}\\right)\\,dx=\\mathbb{E}_{p}\\!\\left[\\ln p(X)-\\ln q(X)\\right].\n$$\n设 $p(x)$ 和 $q(x)$ 分别是方差相同（为 $\\sigma^{2}$）而均值不同（分别为 $\\mu_{A}$ 和 $\\mu_{B}$）的单变量正态分布的密度函数：\n$$\np(x)=\\frac{1}{\\sqrt{2\\pi}\\,\\sigma}\\,\\exp\\!\\left(-\\frac{(x-\\mu_{A})^{2}}{2\\sigma^{2}}\\right),\\quad\nq(x)=\\frac{1}{\\sqrt{2\\pi}\\,\\sigma}\\,\\exp\\!\\left(-\\frac{(x-\\mu_{B})^{2}}{2\\sigma^{2}}\\right).\n$$\n取对数，\n$$\n\\ln p(x)=-\\ln(\\sqrt{2\\pi}\\,\\sigma)-\\frac{(x-\\mu_{A})^{2}}{2\\sigma^{2}},\\quad\n\\ln q(x)=-\\ln(\\sqrt{2\\pi}\\,\\sigma)-\\frac{(x-\\mu_{B})^{2}}{2\\sigma^{2}}.\n$$\n因此，\n$$\n\\ln p(x)-\\ln q(x)=-\\frac{(x-\\mu_{A})^{2}-(x-\\mu_{B})^{2}}{2\\sigma^{2}}=\\frac{(x-\\mu_{B})^{2}-(x-\\mu_{A})^{2}}{2\\sigma^{2}}.\n$$\n在概率分布 $p$ 下取期望，\n$$\nD_{KL}(p\\|q)=\\mathbb{E}_{p}\\!\\left[\\frac{(X-\\mu_{B})^{2}-(X-\\mu_{A})^{2}}{2\\sigma^{2}}\\right]\n=\\frac{1}{2\\sigma^{2}}\\left(\\mathbb{E}_{p}[(X-\\mu_{B})^{2}]-\\mathbb{E}_{p}[(X-\\mu_{A})^{2}]\\right).\n$$\n使用 $\\mathbb{E}_{p}[X]=\\mu_{A}$ 和 $\\operatorname{Var}_{p}(X)=\\sigma^{2}$，以及恒等式 $\\mathbb{E}[(X-a)^{2}]=\\operatorname{Var}(X)+(\\mathbb{E}[X]-a)^{2}$，我们得到\n$$\n\\mathbb{E}_{p}[(X-\\mu_{A})^{2}]=\\sigma^{2},\\quad\n\\mathbb{E}_{p}[(X-\\mu_{B})^{2}]=\\sigma^{2}+(\\mu_{A}-\\mu_{B})^{2}.\n$$\n因此，\n$$\nD_{KL}(p\\|q)=\\frac{1}{2\\sigma^{2}}\\left(\\sigma^{2}+(\\mu_{A}-\\mu_{B})^{2}-\\sigma^{2}\\right)\n=\\frac{(\\mu_{A}-\\mu_{B})^{2}}{2\\sigma^{2}}.\n$$\n根据上述推导中 $p$ 和 $q$ 角色的对称性（交换 $\\mu_{A}$ 和 $\\mu_{B}$ 不会改变表达式），我们同样有\n$$\nD_{KL}(q\\|p)=\\frac{(\\mu_{B}-\\mu_{A})^{2}}{2\\sigma^{2}}=\\frac{(\\mu_{A}-\\mu_{B})^{2}}{2\\sigma^{2}}.\n$$\n因此，定义为 $J(p,q)=D_{KL}(p\\|q)+D_{KL}(q\\|p)$ 的 Jeffreys 散度为\n$$\nJ(p,q)=\\frac{(\\mu_{A}-\\mu_{B})^{2}}{2\\sigma^{2}}+\\frac{(\\mu_{A}-\\mu_{B})^{2}}{2\\sigma^{2}}=\\frac{(\\mu_{A}-\\mu_{B})^{2}}{\\sigma^{2}}.\n$$", "answer": "$$\\boxed{\\frac{(\\mu_{A}-\\mu_{B})^{2}}{\\sigma^{2}}}$$", "id": "1655241"}, {"introduction": "相对熵在统计建模中一个关键应用是量化使用一个分布近似另一个分布时所造成的信息损失。本练习提供了一个具体的实例：使用标准拉普拉斯分布来近似标准正态分布。完成这个计算将使你能够亲手衡量这种近似的“代价”，加深对KL散度作为模型选择和评估工具的理解。[@problem_id:1655225]", "problem": "在信息论中，Kullback-Leibler (KL) 散度（也称为相对熵）用于衡量一个概率分布与另一个参考概率分布的差异程度。对于定义在实数上的两个连续概率分布 $P$ 和 $Q$，其对应的概率密度函数 (PDF) 分别为 $p(x)$ 和 $q(x)$，分布 $P$ 相对于分布 $Q$ 的 KL 散度定义为：\n$$D_{\\text{KL}}(P \\| Q) = \\int_{-\\infty}^{\\infty} p(x) \\ln\\left(\\frac{p(x)}{q(x)}\\right) dx$$\n考虑一个随机变量，其真实分布为标准正态分布，我们记为 $P$。其概率密度函数由下式给出：\n$$p(x) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{x^2}{2}\\right)$$\n假设我们使用标准拉普拉斯分布来近似该分布，我们记为 $Q$。其概率密度函数由下式给出：\n$$q(x) = \\frac{1}{2} \\exp(-|x|)$$\n计算 KL 散度 $D_{\\text{KL}}(P \\| Q)$，它量化了使用 $Q$ 近似 $P$ 时的信息损失。请将您的答案表示为单个闭式解析表达式。", "solution": "我们从连续分布的 KL 散度定义开始：\n$$\nD_{\\text{KL}}(P \\| Q) = \\int_{-\\infty}^{\\infty} p(x)\\,\\ln\\!\\left(\\frac{p(x)}{q(x)}\\right)\\,dx\n= \\mathbb{E}_{P}[\\ln p(X)] - \\mathbb{E}_{P}[\\ln q(X)].\n$$\n对于标准正态分布 $P$，其概率密度函数为 $p(x) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\!\\left(-\\frac{x^{2}}{2}\\right)$，计算\n$$\n\\ln p(x) = -\\frac{1}{2}\\ln(2\\pi) - \\frac{x^{2}}{2},\n$$\n所以\n$$\n\\mathbb{E}_{P}[\\ln p(X)] = -\\frac{1}{2}\\ln(2\\pi) - \\frac{1}{2}\\mathbb{E}_{P}[X^{2}] = -\\frac{1}{2}\\ln(2\\pi) - \\frac{1}{2},\n$$\n因为对于标准正态分布，有 $\\mathbb{E}_{P}[X^{2}] = 1$。\n\n对于标准拉普拉斯分布 $Q$，其概率密度函数为 $q(x) = \\frac{1}{2}\\exp(-|x|)$，我们有\n$$\n\\ln q(x) = -\\ln 2 - |x|,\n$$\n因此\n$$\n\\mathbb{E}_{P}[\\ln q(X)] = -\\ln 2 - \\mathbb{E}_{P}[|X|].\n$$\n为了计算当 $X \\sim \\mathcal{N}(0,1)$ 时的 $\\mathbb{E}_{P}[|X|]$，我们利用对称性：\n$$\n\\mathbb{E}_{P}[|X|] = 2\\int_{0}^{\\infty} x\\,\\frac{1}{\\sqrt{2\\pi}}\\exp\\!\\left(-\\frac{x^{2}}{2}\\right)\\,dx.\n$$\n令 $u = \\frac{x^{2}}{2}$，则 $du = x\\,dx$。那么\n$$\n\\mathbb{E}_{P}[|X|] = \\frac{2}{\\sqrt{2\\pi}}\\int_{0}^{\\infty} \\exp(-u)\\,du = \\frac{2}{\\sqrt{2\\pi}}\\cdot 1 = \\sqrt{\\frac{2}{\\pi}}.\n$$\n因此，\n$$\nD_{\\text{KL}}(P \\| Q) = \\left(-\\frac{1}{2}\\ln(2\\pi) - \\frac{1}{2}\\right) - \\left(-\\ln 2 - \\sqrt{\\frac{2}{\\pi}}\\right)\n= \\sqrt{\\frac{2}{\\pi}} + \\ln 2 - \\frac{1}{2}\\ln(2\\pi) - \\frac{1}{2}.\n$$\n化简对数项，\n$$\n\\ln 2 - \\frac{1}{2}\\ln(2\\pi) = \\frac{1}{2}\\ln 4 - \\frac{1}{2}\\ln(2\\pi) = \\frac{1}{2}\\ln\\!\\left(\\frac{4}{2\\pi}\\right) = \\frac{1}{2}\\ln\\!\\left(\\frac{2}{\\pi}\\right) = -\\frac{1}{2}\\ln\\!\\left(\\frac{\\pi}{2}\\right),\n$$\n得到闭式表达式\n$$\nD_{\\text{KL}}(P \\| Q) = \\sqrt{\\frac{2}{\\pi}} - \\frac{1}{2}\\ln\\!\\left(\\frac{\\pi}{2}\\right) - \\frac{1}{2}.\n$$", "answer": "$$\\boxed{\\sqrt{\\frac{2}{\\pi}}-\\frac{1}{2}\\ln\\!\\left(\\frac{\\pi}{2}\\right)-\\frac{1}{2}}$$", "id": "1655225"}]}