{"hands_on_practices": [{"introduction": "为了真正掌握串行抵消（Successive Cancellation, SC）解码，最好的方法莫过于亲手实践一个完整的例子。这个练习将带领你走过一个码长为2的最简单的极化码的完整流程，从编码、理解“冻结”比特的作用，到最后根据解码器的最大似然判决规则计算错误概率。通过这个具体计算，你将对SC解码的内在机制建立一个坚实而直观的理解。[@problem_id:1646943]", "problem": "一个码率为1/2、码长为$N=2$的简单极化码被设计用于在二进制对称信道（BSC）上传输单个信息比特。BSC是一种无记忆信道，它以交叉概率$p$翻转每个传输的比特。该极化码的编码由变换$\\mathbf{x} = \\mathbf{u} G_2$定义，其中$\\mathbf{u} = (u_1, u_2)$是源比特，$\\mathbf{x} = (x_1, x_2)$是信道输入比特，生成矩阵为$G_2 = \\begin{pmatrix} 1 & 0 \\\\ 1 & 1 \\end{pmatrix}$。所有加法都在模2下进行（即异或运算）。\n\n对于该编码方案，为$u_1$合成的比特信道被认为是较不可靠的，并通过将其值固定为$u_1 = 0$来进行“冻结”。信息比特被分配给$u_2$，它对应于一个更可靠的合成信道。\n\n假设我们要传输信息比特$u_2 = 1$。生成的码字通过交叉概率为$p=0.1$的BSC发送。在接收端，一个连续消除译码器进行操作。它首先将估计值$\\hat{u}_1$设置为已知的冻结值0。然后，它使用信道输出$(y_1, y_2)$和$\\hat{u}_1$的值，通过应用最大似然判决规则来产生估计值$\\hat{u}_2$。\n\n计算译码器在估计信息比特时发生错误的确切概率，即求$P(\\hat{u}_2 \\neq u_2)$。将你的最终答案表示为一个四舍五入到四位有效数字的数值。", "solution": "问题要求计算在码长为2的极化码中，译码信息比特$u_2$的错误概率。我们将通过精确遵循编码和译码步骤来解决这个问题。\n\n首先，我们确定传输的码字。源比特由冻结比特$u_1 = 0$和信息比特$u_2 = 1$给出，所以$\\mathbf{u}=(0, 1)$。编码由$\\mathbf{x} = \\mathbf{u} G_2$给出：\n$$ \\mathbf{x} = (x_1, x_2) = (u_1, u_2) \\begin{pmatrix} 1 & 0 \\\\ 1 & 1 \\end{pmatrix} = (u_1 \\oplus u_2, u_2) $$\n其中$\\oplus$表示模2加法。代入$u_1$和$u_2$的值：\n$$ x_1 = 0 \\oplus 1 = 1 $$\n$$ x_2 = 1 $$\n因此，传输的码字是$\\mathbf{x} = (1, 1)$。该码字通过交叉概率为$p=0.1$的BSC发送。接收到的向量是$\\mathbf{y} = (y_1, y_2)$。\n\n接下来，我们分析连续消除（SC）译码器。译码器首先估计$u_1$。由于$u_1$是值为0的已知冻结比特，译码器将其估计值设为$\\hat{u}_1 = 0$。这一步没有不确定性或错误的可能性。\n\n然后，译码器使用接收到的向量$\\mathbf{y}=(y_1, y_2)$及其已知$u_1=0$（或者更正式地说，其估计值$\\hat{u}_1=0$）的知识来估计$u_2$。译码器做出最大似然判决。在给定$u_1=0$的条件下，它比较接收到$\\mathbf{y}$的概率，一种是$u_2=0$的情况，另一种是$u_2=1$的情况。\n如果$P(y_1, y_2|u_1=0, u_2=0) \\ge P(y_1, y_2|u_1=0, u_2=1)$，译码器判决$\\hat{u}_2=0$。\n如果$P(y_1, y_2|u_1=0, u_2=0) < P(y_1, y_2|u_1=0, u_2=1)$，译码器判决$\\hat{u}_2=1$。\n\n由于信道是无记忆的，联合概率是各个概率的乘积：\n$$ P(y_1, y_2|u_1, u_2) = P(y_1|x_1) P(y_2|x_2) = P(y_1|u_1 \\oplus u_2) P(y_2|u_2) $$\n让我们在给定$u_1=0$的情况下，评估译码器用于比较的两个概率：\n如果$u_2=0$：$x_1=0\\oplus0=0, x_2=0$。概率为$P(y_1|x_1=0)P(y_2|x_2=0)$。\n如果$u_2=1$：$x_1=0\\oplus1=1, x_2=1$。概率为$P(y_1|x_1=1)P(y_2|x_2=1)$。\n\n判决规则可以用似然比（LR）表示。设$L(y) = \\frac{P(y|x=0)}{P(y|x=1)}$。如果似然比大于或等于1，译码器判决$\\hat{u}_2=0$：\n$$ \\frac{P(y_1, y_2|u_1=0, u_2=0)}{P(y_1, y_2|u_1=0, u_2=1)} = \\frac{P(y_1|x_1=0)P(y_2|x_2=0)}{P(y_1|x_1=1)P(y_2|x_2=1)} = L(y_1) L(y_2) \\ge 1 $$\n当我们实际传输$u_2=1$时，如果译码器判决$\\hat{u}_2=0$，则发生错误。这种情况发生在$L(y_1)L(y_2) \\ge 1$时。\n\n对于交叉概率为$p$的BSC，我们有$P(y=b|x=a) = 1-p$（如果$a=b$）和$p$（如果$a \\neq b$）。似然值为：\n$L(y=0) = \\frac{P(y=0|x=0)}{P(y=0|x=1)} = \\frac{1-p}{p}$\n$L(y=1) = \\frac{P(y=1|x=0)}{P(y=1|x=1)} = \\frac{p}{1-p}$\n给定$p=0.1$，我们有$1-p=0.9$。所以，$L(0) = \\frac{0.9}{0.1} = 9$ 且 $L(1) = \\frac{0.1}{0.9} = \\frac{1}{9}$。\n\n现在我们对四种可能的接收向量$\\mathbf{y}=(y_1, y_2)$检查$L(y_1)L(y_2) \\ge 1$的条件：\n1. $\\mathbf{y}=(0,0)$: $L(0)L(0) = 9 \\times 9 = 81 \\ge 1$。这导致错误（$\\hat{u}_2=0$）。\n2. $\\mathbf{y}=(0,1)$: $L(0)L(1) = 9 \\times \\frac{1}{9} = 1 \\ge 1$。这导致错误（$\\hat{u}_2=0$）。\n3. $\\mathbf{y}=(1,0)$: $L(1)L(0) = \\frac{1}{9} \\times 9 = 1 \\ge 1$。这导致错误（$\\hat{u}_2=0$）。\n4. $\\mathbf{y}=(1,1)$: $L(1)L(1) = \\frac{1}{9} \\times \\frac{1}{9} = \\frac{1}{81} < 1$。这导致正确判决（$\\hat{u}_2=1$）。\n\n如果接收到的向量是$(0,0)$、$(0,1)$或$(1,0)$，则发生错误。总错误概率是这三个事件的概率之和，条件是传输的码字为$\\mathbf{x}=(1,1)$。\nBSC独立地作用于每个比特。\n$P(\\text{错误}) = P(\\mathbf{y}=(0,0)|\\mathbf{x}=(1,1)) + P(\\mathbf{y}=(0,1)|\\mathbf{x}=(1,1)) + P(\\mathbf{y}=(1,0)|\\mathbf{x}=(1,1))$\n\n1. $P(\\mathbf{y}=(0,0)|\\mathbf{x}=(1,1)) = P(y_1=0|x_1=1) P(y_2=0|x_2=1) = p \\cdot p = p^2$。（两个比特都翻转）。\n2. $P(\\mathbf{y}=(0,1)|\\mathbf{x}=(1,1)) = P(y_1=0|x_1=1) P(y_2=1|x_2=1) = p \\cdot (1-p)$。（第一个比特翻转）。\n3. $P(\\mathbf{y}=(1,0)|\\mathbf{x}=(1,1)) = P(y_1=1|x_1=1) P(y_2=0|x_2=1) = (1-p) \\cdot p$。（第二个比特翻转）。\n\n总错误概率是：\n$P(\\text{错误}) = p^2 + p(1-p) + (1-p)p = p^2 + 2p(1-p) = p^2 + 2p - 2p^2 = 2p - p^2$。\n\n现在，我们代入给定的值$p=0.1$：\n$P(\\text{错误}) = 2(0.1) - (0.1)^2 = 0.2 - 0.01 = 0.19$。\n\n问题要求答案四舍五入到四位有效数字。\n$0.1900$。", "answer": "$$\\boxed{0.1900}$$", "id": "1646943"}, {"introduction": "在了解了SC解码器的操作流程后，一个自然而然的问题是：我们为什么要使用这种看起来有些复杂的编码结构？本练习旨在揭示其背后的核心原理——信道极化。你将为一个二进制删除信道（BEC）计算经过一次极化变换后生成的两个“合成信道”的容量，从而亲眼见证一个普通信道是如何分化成一个“好”信道和一个“坏”信道的。[@problem_id:1661168]", "problem": "信道极化是现代编码理论中的一项基础技术，用于从一个给定的非极端信道的多个实例中构造出接近完美或接近无用的信道。这使得设计高效的纠错码（如极化码）成为可能。\n\n考虑一个无记忆二进制删除信道 (BEC)，记为 $W$。该信道输入符号集为 $\\mathcal{X} = \\{0, 1\\}$，输出符号集为 $\\mathcal{Y} = \\{0, 1, e\\}$，其中 'e' 代表删除。对于任意输入比特 $x \\in \\{0, 1\\}$，信道以 $1-\\epsilon$ 的概率正确传输该比特（即输出为 $y=x$），并以 $\\epsilon$ 的概率删除该比特（即输出为 $y=e$）。该信道的容量为 $I(W) = 1-\\epsilon$。\n\n我们对该信道 $W$ 的两次独立使用进行单步 Arıkan 极化变换。两个信息比特 $u_1$ 和 $u_2$ 从 $\\{0, 1\\}$ 中抽取。它们通过变换 $x_1 = u_1 \\oplus u_2$ 和 $x_2 = u_2$ 被编码为两个信道输入 $x_1$ 和 $x_2$，其中 $\\oplus$ 表示模2加法。然后，它们通过两个信道实例进行传输，产生输出 $y_1$ 和 $y_2$。\n\n这个过程创建了两个新的合成信道 $W^-$ 和 $W^+$，它们被依次解码。\n1. 信道 $W^-$ 用于传输 $u_1$。其输入为 $u_1$，有效输出为对 $(y_1, y_2)$。对 $u_1$ 的解码是在假设不知道 $u_2$ 值的情况下进行的。\n2. 信道 $W^+$ 用于传输 $u_2$。其输入为 $u_2$，有效输出为对 $(y_1, y_2)$。关键在于，假设 $u_2$ 的解码器完全知晓 $u_1$ 的值，就如同它已在第一步中被成功解码一样。\n\n假设信息比特 $u_1$ 和 $u_2$ 是独立且均匀随机选择的，请确定合成信道 $I(W^-)$ 和 $I(W^+)$ 的香农容量。你的最终答案应为一对以删除概率 $\\epsilon$ 表示的解析表达式。", "solution": "设 $W$ 是一个二进制删除信道，其输入 $X \\in \\{0,1\\}$，输出 $Y \\in \\{0,1,e\\}$，删除概率为 $\\epsilon$，因此如果 $y=x$，则 $W(y|x)$ 等于 $1-\\epsilon$；如果 $y=e$，则等于 $\\epsilon$；否则等于 $0$。对输入 $X_{1}$ 和 $X_{2}$ 进行两次独立的 $W$ 信道使用，产生输出 $Y_{1}$ 和 $Y_{2}$，其独立性由无记忆性给出：\n$$\nP_{Y_{1},Y_{2}|X_{1},X_{2}}(y_{1},y_{2}|x_{1},x_{2})=W(y_{1}|x_{1})\\,W(y_{2}|x_{2}).\n$$\nArıkan 变换将独立均匀比特 $U_{1},U_{2}$ 映射到 $X_{1}=U_{1}\\oplus U_{2}$ 和 $X_{2}=U_{2}$。\n\n根据合成信道的定义，\n$$\nI(W^{-})=I(U_{1};Y_{1},Y_{2}),\\qquad I(W^{+})=I(U_{2};Y_{1},Y_{2},U_{1}),\n$$\n其中 $U_{1},U_{2}$ 独立且均匀分布。对于 BEC，方便的做法是通过其等效删除事件来刻画这些合成信道，然后利用删除概率为 $\\delta$ 的 BEC 在均匀输入下的容量为 $1-\\delta$ 这一性质。\n\n首先，考虑 $W^{-}$，它通过有效输出 $(Y_{1},Y_{2})$ 传输 $U_{1}$，而解码器不知道 $U_{2}$。当且仅当可以从输出中得知 $X_{1}$ 和 $X_{2}$ 时，解码器才能确定 $U_{1}$，因为\n$$\nU_{1}=X_{1}\\oplus X_{2}.\n$$\n当且仅当 $Y_{i}\\in\\{0,1\\}$（即未被删除）时，符号 $X_{i}$ 才被确切知晓。因此，当且仅当事件 $\\{Y_{1}\\neq e\\}\\cap\\{Y_{2}\\neq e\\}$ 发生时，$U_{1}$ 才是可恢复的。由于每次信道使用都以概率 $\\epsilon$ 独立地发生删除，\n$$\nP(Y_{1}\\neq e,\\,Y_{2}\\neq e)=(1-\\epsilon)^{2}.\n$$\n因此 $W^{-}$ 的等效删除概率是\n$$\n\\epsilon^{-}=1-(1-\\epsilon)^{2}=2\\epsilon-\\epsilon^{2},\n$$\n所以其容量是\n$$\nI(W^{-})=1-\\epsilon^{-}=1-(2\\epsilon-\\epsilon^{2})=(1-\\epsilon)^{2}.\n$$\n\n接下来，考虑 $W^{+}$，它通过 $(Y_{1},Y_{2})$ 传输 $U_{2}$，且解码器已知 $U_{1}$。有两种不相交的方式来恢复 $U_{2}$：\n1) 如果 $Y_{2}\\neq e$，则 $X_{2}=Y_{2}$ 已知，因此 $U_{2}=X_{2}$ 已知。\n2) 如果 $Y_{2}=e$ 但 $Y_{1}\\neq e$，则 $X_{1}=Y_{1}$ 已知，利用旁路信息 $U_{1}$，可以计算出 $U_{2}=U_{1}\\oplus X_{1}$。\n唯一的失败（删除）情况发生在两个输出都被删除时，即 $Y_{1}=e$ 和 $Y_{2}=e$。根据独立性，\n$$\nP(Y_{1}=e,\\,Y_{2}=e)=\\epsilon^{2}.\n$$\n因此 $W^{+}$ 的等效删除概率是\n$$\n\\epsilon^{+}=\\epsilon^{2},\n$$\n其容量为\n$$\nI(W^{+})=1-\\epsilon^{+}=1-\\epsilon^{2}.\n$$\n\n作为一致性检验，根据链式法则和无记忆结构可得\n$$\nI(W^{-})+I(W^{+})=I(U_{1};Y_{1},Y_{2})+I(U_{2};Y_{1},Y_{2}|U_{1})=I(U_{1},U_{2};Y_{1},Y_{2}),\n$$\n而\n$$\nI(U_{1},U_{2};Y_{1},Y_{2})=I(X_{1},X_{2};Y_{1},Y_{2})=I(X_{1};Y_{1})+I(X_{2};Y_{2})=2(1-\\epsilon),\n$$\n且确实\n$$\n(1-\\epsilon)^{2}+(1-\\epsilon^{2})=2(1-\\epsilon).\n$$\n因此，容量为\n$$\nI(W^{-})=(1-\\epsilon)^{2},\\qquad I(W^{+})=1-\\epsilon^{2}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}(1-\\epsilon)^{2} & 1-\\epsilon^{2}\\end{pmatrix}}$$", "id": "1661168"}, {"introduction": "现实世界中的极化码码长远大于2。当我们从$N=2$扩展到更长的码时，SC解码的“串行”特性变得尤为重要。这个练习通过一个码长为4的例子，让你深入探究解码步骤之间的依赖关系，理解解码后面比特时如何利用前面已解码比特的信息，这正是“串行抵消”解码算法名称的由来。[@problem_id:1661150]", "problem": "考虑一个码块长度为 $N=4$ 的极化码。信息比特向量为 $u = (u_1, u_2, u_3, u_4)$，编码比特向量（码字）为 $x = (x_1, x_2, x_3, x_4)$。编码过程由以下方程组定义，其中 $\\oplus$ 表示模2加：\n$$x_1 = u_1 \\oplus u_2 \\oplus u_3 \\oplus u_4$$\n$$x_2 = u_3 \\oplus u_4$$\n$$x_3 = u_2 \\oplus u_4$$\n$$x_4 = u_4$$\n\n该码使用连续消除（SC）译码器进行译码。SC译码器接收码字 $x$ 的一个带噪版本，并按 $\\hat{u}_1, \\hat{u}_2, \\hat{u}_3, \\hat{u}_4$ 的顺序依次估计信息比特。任何比特 $u_i$ 的对数似然比的计算都依赖于接收到的信道值以及对所有先前信息比特 $(\\hat{u}_1, \\ldots, \\hat{u}_{i-1})$ 所做的硬判决。\n\n译码过程中的依赖关系由该码的因子图结构决定。对于确定估计值 $\\hat{u}_4$ 的最终译码步骤，在计算 $u_4$ 的对数似然比时，根本上需要先前已估计的哪些比特 $(\\hat{u}_1, \\hat{u}_2, \\hat{u}_3)$ 作为输入？\n\nA. 仅 $\\hat{u}_3$\n\nB. 仅 $\\hat{u}_1$ 和 $\\hat{u}_3$\n\nC. 仅 $\\hat{u}_2$ 和 $\\hat{u}_3$\n\nD. 全部 $\\hat{u}_1$、$\\hat{u}_2$ 和 $\\hat{u}_3$\n\nE. 无需任何先前的比特", "solution": "编码在模2加法上是线性的：对于 $u=(u_{1},u_{2},u_{3},u_{4})$，码字 $x=(x_{1},x_{2},x_{3},x_{4})$ 为\n$$\nx_{1}=u_{1}\\oplus u_{2}\\oplus u_{3}\\oplus u_{4},\\quad\nx_{2}=u_{3}\\oplus u_{4},\\quad\nx_{3}=u_{2}\\oplus u_{4},\\quad\nx_{4}=u_{4}.\n$$\n在SC译码下，$u_{4}$ 的对数似然比（LLR）是在已判决比特 $(\\hat{u}_{1},\\hat{u}_{2},\\hat{u}_{3})$ 的条件下计算的：\n$$\nL(u_{4})=\\ln\\frac{P(y\\mid u_{4}=0,\\hat{u}_{1},\\hat{u}_{2},\\hat{u}_{3})}{P(y\\mid u_{4}=1,\\hat{u}_{1},\\hat{u}_{2},\\hat{u}_{3})}.\n$$\n因为信道是无记忆的，\n$$\nP(y\\mid u_{4},\\hat{u}_{1},\\hat{u}_{2},\\hat{u}_{3})=\\prod_{i=1}^{4}W\\!\\left(y_{i}\\mid x_{i}(u_{4},\\hat{u}_{1},\\hat{u}_{2},\\hat{u}_{3})\\right),\n$$\n其中 $W(y_{i}\\mid x_{i})$ 是单次使用的信道转移概率，而 $x_{i}$ 是作为 $u_{4}$ 和固定的 $(\\hat{u}_{1},\\hat{u}_{2},\\hat{u}_{3})$ 的函数的编码比特：\n$$\nx_{1}=\\hat{u}_{1}\\oplus\\hat{u}_{2}\\oplus\\hat{u}_{3}\\oplus u_{4},\\quad\nx_{2}=\\hat{u}_{3}\\oplus u_{4},\\quad\nx_{3}=\\hat{u}_{2}\\oplus u_{4},\\quad\nx_{4}=u_{4}.\n$$\n定义信道LLR为 $L_{i}\\triangleq \\ln\\frac{W(y_{i}\\mid 0)}{W(y_{i}\\mid 1)}$。对于任何二进制输入信道和任何 $c\\in\\{0,1\\}$，\n$$\n\\ln\\frac{W(y\\mid c)}{W(y\\mid \\bar{c})}=(-1)^{c}L,\\quad L=\\ln\\frac{W(y\\mid 0)}{W(y\\mid 1)}.\n$$\n由于翻转 $u_{4}$ 会翻转所有 $x_{i}$，且决定符号的偏移量 $c_{i}$ 为\n$$\nc_{1}=\\hat{u}_{1}\\oplus\\hat{u}_{2}\\oplus\\hat{u}_{3},\\quad c_{2}=\\hat{u}_{3},\\quad c_{3}=\\hat{u}_{2},\\quad c_{4}=0,\n$$\n$u_{4}$ 的LLR为\n$$\nL(u_{4})=(-1)^{\\hat{u}_{1}\\oplus\\hat{u}_{2}\\oplus\\hat{u}_{3}}L_{1}+(-1)^{\\hat{u}_{3}}L_{2}+(-1)^{\\hat{u}_{2}}L_{3}+L_{4}.\n$$\n等价地，在使用 $f$ 和 $g$ 函数的SC消息传递形式中，其中\n$$\nf(L_{a},L_{b})=2\\,\\arctanh\\!\\big(\\tanh(L_{a}/2)\\tanh(L_{b}/2)\\big),\\quad g(L_{a},L_{b},s)=(-1)^{s}L_{a}+L_{b},\n$$\n进入右子树的消息是\n$$\nL_{c3}=g(L_{1},L_{2},\\hat{u}_{1}\\oplus\\hat{u}_{2}),\\quad L_{c4}=g(L_{3},L_{4},\\hat{u}_{2}),\n$$\n那么\n$$\nL(u_{4})=g(L_{c3},L_{c4},\\hat{u}_{3})=(-1)^{\\hat{u}_{3}}L_{c3}+L_{c4}.\n$$\n两种表达式都表明 $L(u_{4})$ 根本上需要 $\\hat{u}_{1}$、$\\hat{u}_{2}$ 和 $\\hat{u}_{3}$ （通过 $\\hat{u}_{1}\\oplus\\hat{u}_{2}$、$\\hat{u}_{2}$ 和 $\\hat{u}_{3}$ 这些组合）。因此，计算 $u_{4}$ 的LLR需要所有先前已估计的比特。", "answer": "$$\\boxed{D}$$", "id": "1661150"}]}