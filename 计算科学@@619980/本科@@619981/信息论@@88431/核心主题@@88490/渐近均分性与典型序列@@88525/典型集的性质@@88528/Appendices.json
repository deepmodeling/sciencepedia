{"hands_on_practices": [{"introduction": "这个基础练习旨在揭示典型集大小与信息熵之间的深刻联系。通过使用斯特林近似来估算特定类型序列（含有 $k=np$ 个'1'）的数量，你将亲手推导出二元信源的熵公式 $H(p)$。这个过程不仅能加深你对渐近均分特性（AEP）中 $|A_\\epsilon^{(n)}| \\approx 2^{nH(X)}$ 这一核心结果的理解，还能让你体会到组合数学是如何与概率信息论交汇的。[@problem_id:1650580]", "problem": "考虑一个从二进制信源传输数据的通信系统。该信源独立地生成“0”和“1”，生成“1”的概率为 $p$，生成“0”的概率为 $1-p$。\n\n对于一个较大的块长度 $n$，绝大多数可能被观测到的序列（即典型序列）所包含的“1”的数量（记为 $k$）非常接近其统计期望值 $np$。\n\n我们将典型序列集建模为所有长度为 $n$ 且恰好包含 $k = np$ 个“1”的二进制序列的集合。这类序列的数量由二项式系数 $\\binom{n}{k}$ 给出。信息论中一个与渐近均分特性（AEP）相关的基本结果指出，对于较大的 $n$，这个集合的大小可以用以下形式的表达式来近似：\n$$ \\binom{n}{np} \\approx 2^{n \\cdot H_{\\text{comb}}(p)} $$\n其中 $H_{\\text{comb}}(p)$ 可以被解释为由组合方法推导出的信源熵。\n\n你的任务是推导出 $H_{\\text{comb}}(p)$ 的解析表达式。为此，请使用阶乘的斯特林近似。对于较大的 $m$，该近似为 $\\ln(m!) \\approx m \\ln m - m$。你应该假设 $n$、$np$ 和 $n(1-p)$ 都足够大，以使此近似足够精确。$H_{\\text{comb}}(p)$ 的最终表达式应以 $p$ 和以 2 为底的对数表示。", "solution": "我们想在近似式\n$$\n\\binom{n}{np} \\approx 2^{n \\cdot H_{\\text{comb}}(p)}\n$$\n中求出 $H_{\\text{comb}}(p)$ 的显式表达式。\n假设 $n$、$np$ 和 $n(1-p)$ 都很大，并且为方便起见，假设 $np$ 是一个整数。首先取自然对数，并应用斯特林近似 $\\ln(m!) \\approx m \\ln m - m$：\n$$\n\\ln \\binom{n}{np} = \\ln(n!) - \\ln((np)!) - \\ln((n(1-p))!) \\approx \\left(n \\ln n - n\\right) - \\left(np \\ln(np) - np\\right) - \\left(n(1-p)\\ln(n(1-p)) - n(1-p)\\right).\n$$\n展开对数项 $\\ln(np) = \\ln n + \\ln p$ 和 $\\ln(n(1-p)) = \\ln n + \\ln(1-p)$：\n$$\n\\ln \\binom{n}{np} \\approx n \\ln n - n - \\left[np(\\ln n + \\ln p) - np\\right] - \\left[n(1-p)(\\ln n + \\ln(1-p)) - n(1-p)\\right].\n$$\n展开并合并同类项：\n$$\n\\ln \\binom{n}{np} \\approx n \\ln n - n - np \\ln n - np \\ln p + np - n(1-p) \\ln n - n(1-p) \\ln(1-p) + n(1-p).\n$$\n将 $\\ln n$ 项和常数项分组：\n- $\\ln n$ 项相消：\n$$\nn \\ln n - np \\ln n - n(1-p) \\ln n = n \\ln n - n \\ln n = 0.\n$$\n- 常数项相消：\n$$\n-n + np + n(1-p) = -n + n = 0.\n$$\n剩下的项是\n$$\n\\ln \\binom{n}{np} \\approx -np \\ln p - n(1-p)\\ln(1-p) = n\\left[-p \\ln p - (1-p)\\ln(1-p)\\right].\n$$\n取指数，并使用 $\\exp(x) = 2^{x / \\ln 2}$ 从自然对数转换为以 2 为底的对数，得到\n$$\n\\binom{n}{np} \\approx \\exp\\!\\left(n\\left[-p \\ln p - (1-p)\\ln(1-p)\\right]\\right)\n= 2^{\\,n\\left[-p \\log_{2} p - (1-p)\\log_{2}(1-p)\\right]}.\n$$\n与 $\\binom{n}{np} \\approx 2^{n \\cdot H_{\\text{comb}}(p)}$ 比较，我们确定\n$$\nH_{\\text{comb}}(p) = -p \\log_{2} p - (1-p)\\log_{2}(1-p).\n$$\n根据约定 $0 \\log_{2} 0 = 0$，此表达式可连续扩展到 $p \\in \\{0,1\\}$ 的情况。", "answer": "$$\\boxed{-p \\log_{2} p - (1-p)\\log_{2}(1-p)}$$", "id": "1650580"}, {"introduction": "在掌握了一般情况后，通过研究极端案例来建立直观理解是十分有效的。本练习将探讨一个确定性信源，即信源输出完全可预测。通过分析这种零随机性场景下熵和典型集的行为，你将检验自己对渐近均分特性（AEP）的理解，并具体计算典型集真实大小与其 AEP 上界之间的关系，从而阐明该上界的含义。[@problem_id:1650606]", "problem": "考虑一个高度可预测的信息源，它被建模为一个离散无记忆信源，其字母表为 $\\mathcal{X} = \\{a_1, a_2, \\dots, a_M\\}$，其中 $M \\geq 2$。该信源是确定性的，发射符号 $a_1$ 的概率为 $P(a_1) = 1$，而所有其他符号的概率均为零，即对于 $i \\in \\{2, 3, \\dots, M\\}$，$P(a_i) = 0$。这些符号是作为独立同分布 (IID) 的随机变量序列生成的。\n\n根据渐近均分特性 (AEP)，对于任意给定的 $\\epsilon > 0$，可以定义长度为 $n$ 的“典型”序列集，记作 $A_{\\epsilon}^{(n)}$。如果一个序列 $x^n = (x_1, \\dots, x_n)$ 的样本熵接近信源熵 $H(X)$，那么它就属于 $A_{\\epsilon}^{(n)}$：\n$$ \\left| -\\frac{1}{n} \\log_2 P(x^n) - H(X) \\right| \\le \\epsilon $$\n其中 $P(x^n)$ 是序列 $x^n$ 的概率。\n\nAEP 还为该典型集的大小提供了一个著名的上界：$|A_{\\epsilon}^{(n)}| \\le 2^{n(H(X) + \\epsilon)}$。\n\n对于这个确定性信源，求典型集的真实大小 $|A_{\\epsilon}^{(n)}|$ 与其 AEP 上界之比 $R$ 的解析表达式。用 $n$ 和 $\\epsilon$ 表示你的答案。", "solution": "该问题要求计算比率 $R = \\frac{|A_{\\epsilon}^{(n)}|}{2^{n(H(X) + \\epsilon)}}$。为了求出这个比率，我们需要确定三个量：信源的熵 $H(X)$，典型集的真实大小 $|A_{\\epsilon}^{(n)}|$，然后将这些值代入给定的表达式中。\n\n首先，我们来计算信源的香农熵 $H(X)$。对于一个字母表为 $\\mathcal{X}$、概率分布为 $P(x)$ 的离散信源，其熵由以下公式给出：\n$$ H(X) = -\\sum_{x \\in \\mathcal{X}} P(x) \\log_2 P(x) $$\n对于给定的确定性信源，概率为 $P(a_1) = 1$ 和 $P(a_i) = 0$（对于 $i \\geq 2$）。将这些代入熵公式：\n$$ H(X) = -\\left( P(a_1) \\log_2 P(a_1) + \\sum_{i=2}^{M} P(a_i) \\log_2 P(a_i) \\right) $$\n$$ H(X) = -\\left( 1 \\cdot \\log_2(1) + \\sum_{i=2}^{M} 0 \\cdot \\log_2(0) \\right) $$\n在信息论中，表达式 $0 \\log_2 0$ 定义为 0（因为 $\\lim_{p\\to 0^+} p \\log p = 0$）。同时，$\\log_2(1) = 0$。因此，熵为：\n$$ H(X) = -(1 \\cdot 0 + 0) = 0 $$\n确定性信源的熵为零，这反映了不确定性的缺失。\n\n接下来，我们必须求出典型集的真实大小 $|A_{\\epsilon}^{(n)}|$。如果一个序列 $x^n$ 满足以下条件，它就在典型集 $A_{\\epsilon}^{(n)}$ 中：\n$$ \\left| -\\frac{1}{n} \\log_2 P(x^n) - H(X) \\right| \\le \\epsilon $$\n代入 $H(X) = 0$，条件简化为：\n$$ \\left| -\\frac{1}{n} \\log_2 P(x^n) \\right| \\le \\epsilon $$\n由于信源是独立同分布的，一个序列 $x^n = (x_1, \\dots, x_n)$ 的概率为 $P(x^n) = \\prod_{k=1}^{n} P(x_k)$。\n我们来考虑序列 $x^n$ 的两种构成情况：\n情况1：序列 $x^n$ 包含至少一个 $a_1$ 以外的符号。\n如果至少存在一个 $x_k = a_i$ 且 $i \\geq 2$，那么 $P(x_k) = 0$。因此，整个序列的概率是 $P(x^n) = 0$。对于这样的序列，$\\log_2 P(x^n) = \\log_2(0) = -\\infty$。其样本熵 $-\\frac{1}{n} \\log_2 P(x^n)$ 变为无穷大。条件 $|\\infty| \\le \\epsilon$ 对于任何有限的正数 $\\epsilon$ 都不成立。因此，任何包含 $a_1$ 以外符号的序列都不在典型集中。\n\n情况2：序列 $x^n$ 仅由符号 $a_1$ 组成。\n只有一个这样的序列：$x_0^n = (a_1, a_1, \\dots, a_1)$。这个序列的概率是：\n$$ P(x_0^n) = \\prod_{k=1}^{n} P(a_1) = 1^n = 1 $$\n让我们通过将其概率代入条件中，来检查该序列是否在典型集内：\n$$ \\left| -\\frac{1}{n} \\log_2(1) - 0 \\right| = \\left| -\\frac{1}{n} \\cdot 0 \\right| = 0 $$\n条件变为 $0 \\le \\epsilon$。由于 $\\epsilon$ 是一个给定的正常数，这个不等式总是成立的。\n因此，典型集中唯一的序列是 $x_0^n$。这意味着典型集的大小恰好为 1。\n$$ |A_{\\epsilon}^{(n)}| = 1 $$\n\n现在我们可以计算比率 $R$。AEP 上界给出为 $2^{n(H(X) + \\epsilon)}$。代入 $H(X) = 0$，该上界为：\n$$ \\text{Upper Bound} = 2^{n(0 + \\epsilon)} = 2^{n\\epsilon} $$\n最后，比率 $R$ 是真实大小除以此上界：\n$$ R = \\frac{|A_{\\epsilon}^{(n)}|}{\\text{Upper Bound}} = \\frac{1}{2^{n\\epsilon}} $$\n这可以改写为使用负指数的形式：\n$$ R = 2^{-n\\epsilon} $$", "answer": "$$\\boxed{2^{-n\\epsilon}}$$", "id": "1650606"}, {"introduction": "最后一个练习旨在解决一个常见而微妙的误解：最可能出现的序列是否一定是“典型”序列？通过分析一个有偏信源，你将发现高概率和高典型性之间的关键区别。这个实践将强化典型集的核心思想：典型序列的统计特性（如经验熵）与整个信源的统计特性相符，但它本身不一定是个体概率最高的序列。[@problem_id:1650620]", "problem": "考虑一个二元离散无记忆信源 (DMS)，它从符号表 $\\mathcal{X} = \\{0, 1\\}$ 中生成符号序列。发出符号 '0' 的概率为 $P(0) = 0.9$，发出符号 '1' 的概率为 $P(1) = 0.1$。该信源的熵记为 $H(X)$。\n\n对于给定的 $\\epsilon > 0$ 和序列长度 $n$，典型集 $A_{\\epsilon}^{(n)}$ 定义为所有满足以下条件的序列 $x^n = (x_1, x_2, \\dots, x_n)$ 的集合：\n$$ \\left| -\\frac{1}{n} \\log_{2} P(x^n) - H(X) \\right| \\le \\epsilon $$\n其中 $P(x^n)$ 是序列 $x^n$ 的概率。\n\n设参数 $\\epsilon = 0.1$。根据所给的信源性质和定义，关于该信源生成的长度为 $n$ 的最可能序列，下列哪个陈述是正确的？\n\nA. 任意长度 $n$ 的最可能序列都是典型集 $A_{0.1}^{(n)}$ 的成员。\n\nB. 任意长度 $n$ 的最可能序列都不是典型集 $A_{0.1}^{(n)}$ 的成员。\n\nC. 最可能序列是否为 $A_{0.1}^{(n)}$ 的成员取决于序列长度 $n$ 的具体值。\n\nD. 典型集的概念及其定义条件不能应用于单个最可能序列。\n\nE. 仅当信源是无偏的，即 $P(0)=P(1)=0.5$ 时，最可能序列才是典型集 $A_{0.1}^{(n)}$ 的成员。", "solution": "一个二元离散无记忆信源产生独立同分布 (i.i.d.) 的符号，因此对于任意长度为 $n$ 的序列 $x^{n}=(x_{1},\\dots,x_{n})$，其概率可分解为\n$$\nP(x^{n})=\\prod_{i=1}^{n}P(x_{i}).\n$$\n由于 $P(0)>P(1)$，单个最可能的序列是在每个位置都使用最可能符号的序列，即 $0^{n}=(0,0,\\dots,0)$。其概率为\n$$\nP(0^{n})=P(0)^{n}.\n$$\n因此，其每个符号的自信息为\n$$\n-\\frac{1}{n}\\log_{2}P(0^{n})=-\\frac{1}{n}\\log_{2}\\big(P(0)^{n}\\big)=-\\log_{2}P(0).\n$$\n信源熵为\n$$\nH(X)=-P(0)\\log_{2}P(0)-P(1)\\log_{2}P(1).\n$$\n因此，定义 $0^{n}$ 是否为典型的偏差为\n$$\n\\left|-\\frac{1}{n}\\log_{2}P(0^{n})-H(X)\\right|=\\left|-\\log_{2}P(0)-H(X)\\right|.\n$$\n代入 $H(X)$ 并化简，\n$$\n\\begin{aligned}\nH(X)-\\big(-\\log_{2}P(0)\\big)\n&=\\big[-P(0)\\log_{2}P(0)-P(1)\\log_{2}P(1)\\big]+\\log_{2}P(0)\\\\\n&=(1-P(0))\\log_{2}P(0)-P(1)\\log_{2}P(1)\\\\\n&=P(1)\\big[\\log_{2}P(0)-\\log_{2}P(1)\\big]\\\\\n&=P(1)\\log_{2}\\!\\left(\\frac{P(0)}{P(1)}\\right).\n\\end{aligned}\n$$\n由于 $P(0)=0.9$ 而 $P(1)=0.1$，\n$$\n\\left|-\\log_{2}P(0)-H(X)\\right|=H(X)+\\log_{2}P(0)=0.1\\,\\log_{2}(9).\n$$\n为了与 $\\epsilon=0.1$ 比较，注意到 $9>8$ 意味着 $\\log_{2}(9)>\\log_{2}(8)=3$，因此\n$$\n0.1\\,\\log_{2}(9)>0.1\\times 3=0.3>0.1.\n$$\n因此，\n$$\n\\left|-\\frac{1}{n}\\log_{2}P(0^{n})-H(X)\\right|>0.1=\\epsilon,\n$$\n所以 $0^{n}$ 不在 $A_{0.1}^{(n)}$ 中。这个偏差与 $n$ 无关，因此该结论对任意序列长度 $n$ 都成立。\n\n因此，对于该信源，任意长度 $n$ 的最可能序列都不是典型集 $A_{0.1}^{(n)}$ 的成员，这对应于选项 B。", "answer": "$$\\boxed{B}$$", "id": "1650620"}]}