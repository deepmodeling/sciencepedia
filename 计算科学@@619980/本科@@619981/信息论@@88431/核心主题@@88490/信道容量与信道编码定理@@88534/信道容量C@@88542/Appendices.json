{"hands_on_practices": [{"introduction": "我们从一个基础但极具启发性的例子开始：确定性信道。在这种信道中，输出完全由输入决定，没有任何随机性或噪声。这个练习将帮助你理解信道容量的核心思想——即通过精心选择输入信号的概率分布，来最大化输出信号的不确定性（熵）。通过计算一个将两位二进制输入相加的简单信道的容量 [@problem_id:1609640]，你将亲手实践如何将互信息 $I(X;Y)$ 的最大化问题转化为输出熵 $H(Y)$ 的最大化问题。", "problem": "考虑一个离散无记忆通信信道，其设计为通过对二进制输入求和来传输信息。该信道的输入是一对比特，用随机变量 $X = (X_1, X_2)$ 表示，其中 $X_1 \\in \\{0, 1\\}$ 且 $X_2 \\in \\{0, 1\\}$。该信道的操作是确定性的：它计算两个输入比特的整数和，以产生单个输出，用随机变量 $Y = X_1 + X_2$ 表示。\n\n计算该信道的容量。所有信息论量均应使用以2为底的对数进行计算。最终答案以比特为单位表示，并四舍五入到四位有效数字。", "solution": "离散无记忆信道的容量 $C$ 定义为在所有可能的输入分布 $p(x)$ 上，输入 $X$ 和输出 $Y$ 之间的最大互信息。\n$$C = \\max_{p(x)} I(X;Y)$$\n互信息 $I(X;Y)$ 由公式 $I(X;Y) = H(Y) - H(Y|X)$ 给出，其中 $H(Y)$ 是输出的熵，$H(Y|X)$ 是给定输入下输出的条件熵。\n\n首先，我们来描述信道的特性。\n$X = (X_1, X_2)$ 的输入字母表为 $\\mathcal{X} = \\{(0,0), (0,1), (1,0), (1,1)\\}$。\n输出 $Y = X_1 + X_2$ 可以取值为 $0+0=0$、$0+1=1$、$1+0=1$ 和 $1+1=2$。因此，输出字母表为 $\\mathcal{Y} = \\{0, 1, 2\\}$。\n\n该信道是确定性的，意味着对于每个输入 $x \\in \\mathcal{X}$，输出 $y \\in \\mathcal{Y}$ 是唯一确定的。\n- 如果 $X = (0,0)$，则 $Y=0$。\n- 如果 $X = (0,1)$，则 $Y=1$。\n- 如果 $X = (1,0)$，则 $Y=1$。\n- 如果 $X = (1,1)$，则 $Y=2$。\n\n我们来计算条件熵 $H(Y|X)$。\n$$H(Y|X) = \\sum_{x \\in \\mathcal{X}} p(x) H(Y|X=x)$$\n在特定输入 $x$ 条件下的输出熵为 $H(Y|X=x) = -\\sum_{y \\in \\mathcal{Y}} p(y|x) \\log_2 p(y|x)$。由于信道是确定性的，对于任何给定的 $x$，存在一个特定的 $y$，其转移概率 $p(y|x)$ 为 1，而对于所有其他的 $y'$，$p(y'|x)=0$。例如，$p(y=0|x=(0,0))=1$。\n这样一个确定性转移的熵项为 $-(1 \\log_2 1 + 0 \\log_2 0 + \\dots) = 0$。（注意：$0 \\log_2 0$ 定义为 0）。\n由于对于所有 $x \\in \\mathcal{X}$ 都有 $H(Y|X=x) = 0$，所以条件熵为 $H(Y|X) = \\sum_{x \\in \\mathcal{X}} p(x) \\cdot 0 = 0$。\n\n当 $H(Y|X)=0$ 时，互信息简化为 $I(X;Y) = H(Y) - 0 = H(Y)$。\n因此，信道容量是输出的最大可能熵：\n$$C = \\max_{p(x)} H(Y)$$\n\n输出的熵由 $H(Y) = -\\sum_{y \\in \\mathcal{Y}} p(y) \\log_2 p(y)$ 给出。设输出符号的概率为 $q_0 = P(Y=0)$，$q_1 = P(Y=1)$ 和 $q_2 = P(Y=2)$。\n则 $H(Y) = -q_0 \\log_2 q_0 - q_1 \\log_2 q_1 - q_2 \\log_2 q_2$。\n\n当概率分布为均匀分布时，即 $q_0 = q_1 = q_2 = 1/3$ 时，具有 $|\\mathcal{Y}| = 3$ 个可能结果的随机变量的熵达到最大值。因此，$H(Y)$ 的最大可能值为 $H_{\\text{max}}(Y) = \\log_2(3)$。\n\n现在，我们必须检查对于某个有效的输入分布 $p(x)$，是否可以实现这种均匀输出分布。设输入概率为：\n- $p_{(0,0)} = P(X=(0,0))$\n- $p_{(0,1)} = P(X=(0,1))$\n- $p_{(1,0)} = P(X=(1,0))$\n- $p_{(1,1)} = P(X=(1,1))$\n其中 $p_{(0,0)} + p_{(0,1)} + p_{(1,0)} + p_{(1,1)} = 1$ 且所有概率均为非负。\n\n输出概率与输入概率的关系如下：\n- $q_0 = P(Y=0) = P(X=(0,0)) = p_{(0,0)}$\n- $q_1 = P(Y=1) = P(X=(0,1)) + P(X=(1,0)) = p_{(0,1)} + p_{(1,0)}$\n- $q_2 = P(Y=2) = P(X=(1,1)) = p_{(1,1)}$\n\n为了实现均匀输出分布，我们需要：\n- $q_0 = p_{(0,0)} = 1/3$\n- $q_1 = p_{(0,1)} + p_{(1,0)} = 1/3$\n- $q_2 = p_{(1,1)} = 1/3$\n\n我们可以检查是否存在一组有效的输入概率。我们设 $p_{(0,0)} = 1/3$ 和 $p_{(1,1)} = 1/3$。对于第二个条件，我们可以选择任意非负的 $p_{(0,1)}$ 和 $p_{(1,0)}$，使它们的和为 $1/3$。例如，我们可以选择 $p_{(0,1)} = 1/6$ 和 $p_{(1,0)} = 1/6$。\n这就给出了一个有效的输入分布：$p(x) = \\{p_{(0,0)}=1/3, p_{(0,1)}=1/6, p_{(1,0)}=1/6, p_{(1,1)}=1/3\\}$。其和为 $1/3 + 1/6 + 1/6 + 1/3 = 2/6 + 1/6 + 1/6 + 2/6 = 6/6 = 1$。由于存在一个能够产生均匀输出分布的有效输入分布，因此最大输出熵是可以实现的。\n\n因此，信道容量为 $C = \\log_2(3)$。\n为了求出数值：\n$$C = \\log_2(3) = \\frac{\\ln(3)}{\\ln(2)} \\approx \\frac{1.09861228867}{0.69314718056} \\approx 1.5849625007 \\text{ bits}$$\n四舍五入到四位有效数字，我们得到 $C \\approx 1.585$ 比特。", "answer": "$$\\boxed{1.585}$$", "id": "1609640"}, {"introduction": "在现实世界中，通信总是伴随着噪声。这个练习引入了一个带噪声的信道模型，但增加了一个关键的假设：接收方拥有关于噪声的“边信息”。这个思想实验旨在揭示信道容量的深刻内涵，即容量不仅取决于噪声本身，更取决于接收方对噪声的了解程度。通过分析这个在接收端噪声已知的二进制加性噪声信道 [@problem_id:1609620]，你将发现，只要噪声可以被完全“消除”，信道的传输潜力就可以达到理论上的最大值。", "problem": "考虑一个二元通信信道，其输入字母表为 $\\mathcal{X} = \\{0, 1\\}$，输出字母表为 $\\mathcal{Y} = \\{0, 1\\}$。该信道受到加性二元噪声的影响。设发送端选择的输入为随机变量 $X$，噪声为随机变量 $Z$。$X$ 和 $Z$ 均可在 $\\{0, 1\\}$ 中取值。信道输出 $Y$ 由关系式 $Y = X \\oplus Z$ 给出，其中 $\\oplus$ 表示模2加法（异或运算）。\n\n噪声变量 $Z$ 与输入 $X$ 统计独立，并服从伯努利分布，其中 $P(Z=1) = q$，$q$ 是一个满足 $0 < q < 1$ 的常数。\n\n此通信设置的一个特殊之处在于，接收端拥有关于噪声的完美旁路信息。这意味着对于每次信道使用，接收端不仅能观测到输出 $Y$，还能观测到噪声实现 $Z$ 的确切值。然而，发送端对 $Z$ 一无所知。\n\n计算在接收端具有旁路信息的情况下，该信道的容量 $C$。答案以“比特/信道使用”（bits per channel use）为单位表示。", "solution": "信道容量定义为输入与输出之间的最大互信息，该最大化是针对所有可能的输入分布而言的。在这个具体问题中，接收端同时观测到信道输出 $Y$ 和噪声值 $Z$。因此，接收端可获得的总信息是随机变量对 $(Y, Z)$。所以，信道容量 $C$ 由输入 $X$ 和随机变量对 $(Y, Z)$ 之间的最大互信息给出。\n\n$$C = \\max_{p(x)} I(X; Y, Z)$$\n\n我们可以使用互信息的链式法则展开互信息项 $I(X; Y, Z)$：\n\n$$I(X; Y, Z) = I(X; Z) + I(X; Y | Z)$$\n\n问题陈述指明输入 $X$ 和噪声 $Z$ 是统计独立的。两个独立随机变量之间的互信息为零。因此：\n\n$$I(X; Z) = 0$$\n\n将此结果代入我们的互信息表达式中，得到：\n\n$$I(X; Y, Z) = 0 + I(X; Y | Z) = I(X; Y | Z)$$\n\n现在我们分析条件互信息项 $I(X; Y | Z)$。我们可以用条件熵来表示它：\n\n$$I(X; Y | Z) = H(X | Z) - H(X | Y, Z)$$\n\n因为 $X$ 和 $Z$ 独立，所以知道 $Z$ 的值并不能提供关于 $X$ 的任何信息。因此，条件熵 $H(X | Z)$ 等于 $X$ 的熵：\n\n$$H(X | Z) = H(X)$$\n\n接下来，我们评估 $H(X | Y, Z)$ 这一项。这表示接收端在观测到输出 $Y$ 和噪声 $Z$ 后，对输入 $X$ 剩余的不确定性。信道关系由 $Y = X \\oplus Z$ 给出。利用异或运算的性质，我们可以解出 $X$：\n\n$$X = Y \\oplus Z$$\n\n由于接收端知道每次传输中 $Y$ 和 $Z$ 的确切值，因此可以完全确定地计算出 $X$。一旦 $Y$ 和 $Z$ 已知，关于 $X$ 就不存在任何不确定性。因此，条件熵 $H(X | Y, Z)$ 为零：\n\n$$H(X | Y, Z) = 0$$\n\n将这些熵的结果代回互信息的表达式中：\n\n$$I(X; Y, Z) = I(X; Y | Z) = H(X|Z) - H(X|Y,Z) = H(X) - 0 = H(X)$$\n\n所以，对于任意给定的输入分布 $p(x)$，互信息就是输入 $X$ 的熵 $H(X)$。为了求得信道容量 $C$，我们必须在所有可能的输入分布上最大化这个互信息。\n\n$$C = \\max_{p(x)} H(X)$$\n\n输入 $X$ 是一个二元随机变量。当二元随机变量的各种取值等概率时，即 $P(X=0) = P(X=1) = 1/2$ 时，其熵达到最大值。熵的最大值为：\n\n$$H_{\\text{max}}(X) = -P(X=0)\\log_2(P(X=0)) - P(X=1)\\log_2(P(X=1))$$\n$$H_{\\text{max}}(X) = -\\frac{1}{2}\\log_2\\left(\\frac{1}{2}\\right) - \\frac{1}{2}\\log_2\\left(\\frac{1}{2}\\right) = - (1)\\log_2\\left(\\frac{1}{2}\\right) = -(-\\log_2(2)) = \\log_2(2) = 1 \\text{ bit}$$\n\n因此，该信道的容量是 1 比特/信道使用。值得注意的是，信道容量与噪声概率 $q$ 无关，这是接收端拥有完美噪声旁路信息的直接结果。", "answer": "$$\\boxed{1}$$", "id": "1609620"}, {"introduction": "最后的这个练习将我们带入一个更接近实际应用的复杂场景。它结合了经典的二进制对称信道（BSC）模型和一个对输入信号的实际约束——不允许连续传输两个“1”。在许多通信系统中，类似的输入约束是常见的。这个挑战要求你不再是选择一个固定的输入分布，而是在一个由参数 $\\alpha$ 控制的输入过程家族中寻找最优解，以最大化信息传输速率 [@problem_id:1609670]。这个练习深刻地揭示了实现信道容量的本质：在信道物理特性和输入信号限制的双重约束下，找到最佳的输入统计特性。", "problem": "一个通信系统设计用于在二元对称信道 (BSC) 上传输数据。该信道的交叉概率为 $p$，其中 $0 < p < 1/2$，意味着在传输过程中一个比特被翻转的概率为 $p$。为减轻某种特定类型的突发错误的影响，该系统采用一种信源编码方案，该方案对输入比特流 $\\{X_t\\}$ 进行约束，使得不能传输两个连续的'1'。\n\n这一约束是通过一个平稳一阶马尔可夫信源生成输入序列来强制执行的。在时间 $t$ 的信源状态是前一个比特的值 $X_{t-1}$。状态转移由概率 $P(X_t=0|X_{t-1}=1) = 1$ (强制执行约束) 和一个可调参数 $\\alpha = P(X_t=1|X_{t-1}=0)$ 决定，其中 $\\alpha$ 可设置为区间 $[0, 1]$ 内的任意值。\n\n当系统达到平稳状态后，令 $X$ 和 $Y$ 分别为输入和输出比特的随机变量。您的任务是通过选择参数 $\\alpha$ 的最优值，来求得互信息 $I(X;Y)$ 的最大可能值。\n\n用二元熵函数 $H_2(p) = -p\\log_2(p) - (1-p)\\log_2(1-p)$ 表示您的最终答案。", "solution": "该信道是一个交叉概率为 $p$ 的二元对称信道，因此对于任意输入比特 $X \\in \\{0,1\\}$，输出为 $Y = X \\oplus Z$，其中 $Z \\sim \\text{Bernoulli}(p)$ 且与 $X$ 独立。因此，条件熵满足\n$$\nH(Y|X) = H_2(p).\n$$\n\n输入 $\\{X_{t}\\}$ 由一个一阶马尔可夫信源生成，其转移概率为\n$$\nP(X_{t}=1 \\mid X_{t-1}=1) = 0,\\quad P(X_{t}=0 \\mid X_{t-1}=1) = 1,\\quad P(X_{t}=1 \\mid X_{t-1}=0) = \\alpha,\\quad P(X_{t}=0 \\mid X_{t-1}=0) = 1-\\alpha,\n$$\n其中 $\\alpha \\in [0,1]$。设平稳分布为 $\\pi_{0} = P(X=0)$ 和 $\\pi_{1} = P(X=1)$。平稳性要求\n$$\n\\begin{aligned}\n\\pi_{0} &= \\pi_{0}(1-\\alpha) + \\pi_{1}(1),\\\\\n\\pi_{1} &= \\pi_{0}\\alpha + \\pi_{1}(0),\\\\\n\\pi_{0} + \\pi_{1} &= 1.\n\\end{aligned}\n$$\n从 $\\pi_{1} = \\pi_{0}\\alpha$ 和 $\\pi_{0} + \\pi_{0}\\alpha = 1$，我们得到\n$$\n\\pi_{0} = \\frac{1}{1+\\alpha},\\qquad \\pi_{1} = \\frac{\\alpha}{1+\\alpha}.\n$$\n\n对于该BSC，输出的边缘概率为\n$$\nP(Y=1) = P(Y=1 \\mid X=1)\\pi_{1} + P(Y=1 \\mid X=0)\\pi_{0} = (1-p)\\pi_{1} + p\\pi_{0} = p + (1-2p)\\pi_{1}.\n$$\n因此\n$$\nH(Y) = H_2\\big(p + (1-2p)\\pi_{1}\\big) = H_2\\!\\left(p + (1-2p)\\frac{\\alpha}{1+\\alpha}\\right).\n$$\n单符号互信息为\n$$\nI(X;Y) = H(Y) - H(Y|X) = H_2\\!\\left(p + (1-2p)\\frac{\\alpha}{1+\\alpha}\\right) - H_2(p).\n$$\n\n因为 $0 < p < \\frac{1}{2}$，所以我们有 $1-2p > 0$。当 $\\alpha$ 在 $[0,1]$ 范围内取值时，$\\pi_{1} = \\frac{\\alpha}{1+\\alpha}$ 在 $[0,\\frac{1}{2}]$ 范围内取值，所以 $P(Y=1) = p + (1-2p)\\pi_{1}$ 在 $[p,\\frac{1}{2}]$ 范围内取值。二元熵函数 $H_2(q)$ 在 $q \\in [0,\\frac{1}{2}]$ 上是严格递增的，因此，$H(Y)$ 以及 $I(X;Y)$ 通过在其可行范围内最大化 $P(Y=1)$ 来实现最大化，即选择 $P(Y=1) = \\frac{1}{2}$。这在 $\\pi_{1} = \\frac{1}{2}$ 时实现，对应于 $\\alpha = 1$，因为\n$$\n\\frac{\\alpha}{1+\\alpha} = \\frac{1}{2} \\quad \\Longleftrightarrow \\quad \\alpha = 1.\n$$\n在这个选择下，$H(Y) = H_2\\!\\left(\\frac{1}{2}\\right) = 1$，所以最大互信息为\n$$\nI_{\\max}(X;Y) = 1 - H_2(p).\n$$\n选择 $\\alpha=1$ 遵守了无连续两个1的约束（输入在0和1之间交替），并且平稳单符号边缘分布满足 $P(X=1)=\\frac{1}{2}$。\n\n因此，在 $\\alpha \\in [0,1]$ 上可实现的最大 $I(X;Y)$ 是 $1 - H_2(p)$。", "answer": "$$\\boxed{1 - H_2(p)}$$", "id": "1609670"}]}