{"hands_on_practices": [{"introduction": "理论联系实际的第一步是掌握使用验证集进行超参数调优的标准流程。本练习将通过一个异常检测的例子，指导你如何利用验证集来确定能够最大化$F_1$分数的最佳决策阈值，并使用测试集来无偏地评估模型的泛化性能。这个过程还将揭示为什么在验证集上取得的最佳性能可能无法完全复现于测试集，从而加深你对模型评估的理解。", "problem": "给定一个二元异常检测场景，其中有三个不相交的数据集：训练集 $\\mathcal{D}_{\\text{train}}$、验证集 $\\mathcal{D}_{\\text{val}}$ 和测试集 $\\mathcal{D}_{\\text{test}}$。每个数据集都包含实值异常分数和真实的二元标签，其中标签 $0$ 表示正常实例，标签 $1$ 表示异常实例。您必须使用的基本依据包括以下被广泛接受的定义和规则。首先，使用仅包含训练集的统计数据通过标准化来归一化分数：对于任意分数 $x$，将标准化分数 $z$ 定义为\n$$\nz = \\frac{x - \\mu_{\\text{train}}}{\\sigma_{\\text{train}}},\n$$\n其中 $\\mu_{\\text{train}}$ 是 $\\mathcal{D}_{\\text{train}}$ 中分数的均值，$\\sigma_{\\text{train}}$ 是 $\\mathcal{D}_{\\text{train}}$ 中分数的标准差。其次，采用由阈值 $\\tau$ 参数化的决策规则：如果 $z \\ge \\tau$ 则预测为异常，否则预测为正常。第三，对于任何固定的 $\\tau$，在一个带标签的数据集上将混淆矩阵计数定义为真正例 (TP)、假正例 (FP)、假反例 (FN) 和真反例 (TN)。根据这些计数，将精确率 $P$ 和召回率 $R$ 定义为\n$$\nP = \\frac{TP}{TP+FP} \\quad \\text{if } TP+FP>0, \\text{ else } P = 0, \\qquad\nR = \\frac{TP}{TP+FN} \\quad \\text{if } TP+FN>0, \\text{ else } R = 0.\n$$\n那么 $F_1$ 分数为\n$$\nF_1 = \\begin{cases}\n\\frac{2PR}{P+R},  \\text{if } P+R>0,\\\\\n0,  \\text{otherwise.}\n\\end{cases}\n$$\n您的任务是按如下方式研究在验证集上进行异常检测的阈值选择。对于每个测试用例，从 $\\mathcal{D}_{\\text{train}}$ 计算 $\\mu_{\\text{train}}$ 和 $\\sigma_{\\text{train}}$，并相应地对 $\\mathcal{D}_{\\text{val}}$ 和 $\\mathcal{D}_{\\text{test}}$ 进行标准化，在一组候选阈值上变动决策阈值 $\\tau$（该组候选阈值由所有不同的标准化验证分数以及 $-\\infty$ 和 $+\\infty$ 组成），并选择在 $\\mathcal{D}_{\\text{val}}$ 上使$F_1$分数最大化的阈值 $\\tau^\\star$。如果出现平局（多个 $\\tau$ 达到相同的最大 $F_1$ 分数），则选择其中最大的 $\\tau$。最后，在 $\\tau^\\star$ 处评估 $\\mathcal{D}_{\\text{test}}$ 上的$F_1$分数，并报告其差值\n$$\ng = F_1(\\mathcal{D}_{\\text{val}};\\tau^\\star) - F_1(\\mathcal{D}_{\\text{test}};\\tau^\\star).\n$$\n这个量 $g$ 是基于验证集对测试性能高估的程度，以小数形式表示。\n\n测试套件规范：\n对于每个用例，训练分数假定为仅包含正常样本。以下所有数字均为实值，必须按其书面形式进行精确解释。\n\n用例 1（分布偏移导致高估）：\n- $\\mathcal{D}_{\\text{train}}$ 分数：$[\\,0.9,\\,1.0,\\,1.1,\\,1.0,\\,0.95,\\,1.05\\,]$\n- $\\mathcal{D}_{\\text{val}}$ 原始分数：$[\\,0.7,\\,0.85,\\,0.95,\\,1.2,\\,2.0,\\,2.1,\\,1.9,\\,0.8\\,]$，标签：$[\\,0,\\,0,\\,0,\\,0,\\,1,\\,1,\\,1,\\,0\\,]$\n- $\\mathcal{D}_{\\text{test}}$ 原始分数：$[\\,0.9,\\,0.98,\\,1.3,\\,1.4,\\,1.5,\\,1.6,\\,1.7,\\,1.8\\,]$，标签：$[\\,0,\\,0,\\,0,\\,0,\\,0,\\,1,\\,1,\\,1\\,]$\n\n用例 2（小验证集过拟合）：\n- $\\mathcal{D}_{\\text{train}}$ 分数：$[\\,0.0,\\,0.1,\\,-0.1,\\,0.15,\\,-0.05\\,]$\n- $\\mathcal{D}_{\\text{val}}$ 原始分数：$[\\,0.0,\\,0.05,\\,-0.05,\\,0.9\\,]$，标签：$[\\,0,\\,0,\\,0,\\,1\\,]$\n- $\\mathcal{D}_{\\text{test}}$ 原始分数：$[\\,0.0,\\,0.1,\\,0.2,\\,-0.1,\\,0.3,\\,0.4,\\,0.85,\\,0.75\\,]$，标签：$[\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,1,\\,1\\,]$\n\n用例 3（验证集中无异常的边界情况）：\n- $\\mathcal{D}_{\\text{train}}$ 分数：$[\\,5.0,\\,5.2,\\,4.8,\\,5.1,\\,4.9\\,]$\n- $\\mathcal{D}_{\\text{val}}$ 原始分数：$[\\,5.0,\\,5.1,\\,5.2,\\,5.3\\,]$，标签：$[\\,0,\\,0,\\,0,\\,0\\,]$\n- $\\mathcal{D}_{\\text{test}}$ 原始分数：$[\\,5.0,\\,5.1,\\,5.2,\\,5.5,\\,6.0,\\,6.5\\,]$，标签：$[\\,0,\\,0,\\,0,\\,1,\\,1,\\,1\\,]$\n\n实现要求：\n- 对于每个用例，完全按照上述规定计算 $g$，使用仅基于 $\\mathcal{D}_{\\text{train}}$ 统计数据的标准化分数。\n- 将每个 $g$ 表示为四舍五入到 4 位小数的小数。\n- 您的程序应生成单行输出，其中包含一个逗号分隔的列表，用方括号括起来，例如 $[\\,g_1, g_2, g_3\\,]$，每个 $g$ 格式化为 4 位小数，不含其他文本。", "solution": "该问题要求我们计算一个性能差距，记为 $g$，它是一个模型在验证集上的性能与在测试集上的性能之间的差异。这是机器学习中评估模型过拟合和超参数调优过程泛化能力的一个标准流程。具体任务涉及一个简单的基于阈值的异常检测器。求解方法是确定性的，包含几个步骤，下文将详细介绍。\n\n首先，对各组成指标进行严格定义至关重要。问题陈述，对于一个包含异常分数 $z$ 和真实二元标签 $y \\in \\{0, 1\\}$ 的数据集，其中 $1$ 表示异常，决策规则是在给定阈值 $\\tau$ 的情况下，如果 $z \\ge \\tau$ 则预测为异常。这将数据集划分为四类：\n- 真正例 ($TP$)：$z \\ge \\tau$ 且 $y=1$ 的实例。\n- 假正例 ($FP$)：$z \\ge \\tau$ 且 $y=0$ 的实例。\n- 假反例 ($FN$)：$z  \\tau$ 且 $y=1$ 的实例。\n- 真反例 ($TN$)：$z  \\tau$ 且 $y=0$ 的实例。\n\n根据这些计数，我们定义精确率 ($P$) 和召回率 ($R$)：\n$$\nP = \\begin{cases} \\frac{TP}{TP+FP}  \\text{if } TP+FP  0 \\\\ 0  \\text{if } TP+FP = 0 \\end{cases}\n$$\n$$\nR = \\begin{cases} \\frac{TP}{TP+FN}  \\text{if } TP+FN  0 \\\\ 0  \\text{if } TP+FN = 0 \\end{cases}\n$$\n$F_1$ 分数是精确率和召回率的调和平均数，其定义如下：\n$$\nF_1 = \\begin{cases} \\frac{2PR}{P+R}  \\text{if } P+R  0 \\\\ 0  \\text{if } P+R = 0 \\end{cases}\n$$\n\n总体算法流程如下：\n\n1.  **数据标准化**：第一步是为异常分数建立一个通用尺度。我们计算训练集 $\\mathcal{D}_{\\text{train}}$ 中分数的均值 $\\mu_{\\text{train}}$ 和总体标准差 $\\sigma_{\\text{train}}$。题目规定 $\\mathcal{D}_{\\text{train}}$ 仅包含正常样本，这是训练某些类型异常检测器的常用做法。然后，验证集 $\\mathcal{D}_{\\text{val}}$ 和测试集 $\\mathcal{D}_{\\text{test}}$ 中的每个原始分数 $x$ 都使用训练统计数据转换为标准化分数 $z$：\n    $$\n    z = \\frac{x - \\mu_{\\text{train}}}{\\sigma_{\\text{train}}}\n    $$\n    这一转换至关重要，因为它*仅*使用来自训练数据的信息，以防止验证集或测试集的信息泄漏到特征工程过程中。\n\n2.  **在验证集上进行阈值优化**：决策阈值 $\\tau$ 是一个超参数。我们通过在标准化验证集 $\\mathcal{D}_{\\text{val}}$ 上评估 $F_1$ 分数来对其进行优化。候选阈值集合 $\\mathcal{T}$ 由 $\\mathcal{D}_{\\text{val}}$ 中所有不同的标准化分数以及 $-\\infty$ 和 $+\\infty$ 构成。对于每个 $\\tau \\in \\mathcal{T}$，我们计算相应的 $F_1$ 分数。最优阈值 $\\tau^\\star$ 是使该 $F_1$ 分数最大化的阈值。如果多个阈值产生相同的最大 $F_1$ 分数，问题规定了一个平局打破规则：在竞争者中选择最大的 $\\tau$ 值。这样就得到了唯一的 $\\tau^\\star$。在验证集上实现的最大 $F_1$ 分数记为 $F_1(\\mathcal{D}_{\\text{val}};\\tau^\\star)$。\n\n3.  **在测试集上进行性能评估**：所选阈值 $\\tau^\\star$ 的泛化性能在未见过的测试集 $\\mathcal{D}_{\\text{test}}$ 上进行评估。我们将决策规则 $z_{\\text{test}} \\ge \\tau^\\star$ 应用于标准化的测试分数，并计算由此产生的$F_1$分数，记为 $F_1(\\mathcal{D}_{\\text{test}};\\tau^\\star)$。\n\n4.  **差距计算**：最后，问题要求计算验证集 $F_1$ 分数与测试集 $F_1$ 分数之差 $g$：\n    $$\n    g = F_1(\\mathcal{D}_{\\text{val}};\\tau^\\star) - F_1(\\mathcal{D}_{\\text{test}};\\tau^\\star)\n    $$\n    这个值 $g$ 量化了基于验证集的性能估计的乐观程度。一个大的正值表示模型和超参数选择对验证集过拟合。\n\n让我们将此过程应用于**用例 1**：\n\n- $\\mathcal{D}_{\\text{train}}$ 分数：$[\\,0.9,\\,1.0,\\,1.1,\\,1.0,\\,0.95,\\,1.05\\,]$\n- $\\mu_{\\text{train}} = 1.0$\n- $\\sigma_{\\text{train}} = \\sqrt{\\frac{1}{6}\\sum(x_i - \\mu_{\\text{train}})^2} = \\sqrt{\\frac{0.025}{6}} \\approx 0.06455$\n\n- 标准化 $\\mathcal{D}_{\\text{val}}$ 分数：$X_{\\text{val}} = [\\,0.7, \\dots, 0.8\\,]$，$Y_{\\text{val}} = [\\,0, \\dots, 0\\,]$\n  标准化分数为 $Z_{\\text{val}} \\approx [\\, -4.648, -2.324, -0.775, 3.098, 15.492, 17.041, 13.943, -3.098 \\,]$。\n  对应的标签为 $[\\,0, 0, 0, 0, 1, 1, 1, 0\\,]$。在 $\\mathcal{D}_{\\text{val}}$ 中，有 $3$ 个异常实例和 $5$ 个正常实例。\n\n- 候选阈值集合 $\\mathcal{T}$ 由 $Z_{\\text{val}}$ 中的 $8$ 个唯一值加上 $\\{-\\infty, +\\infty\\}$ 组成。我们遍历这 $10$ 个候选值。例如，如果我们选择 $\\tau$ 等于原始分数 $1.9$ 的标准化分数（即 $z(1.9) \\approx 13.943$），任何分数大于或等于此值的实例都将被预测为异常。在 $\\mathcal{D}_{\\text{val}}$ 中，分数 $z \\ge 13.943$ 的实例对应于原始分数 $1.9, 2.0, 2.1$。它们的真实标签都是 $1$。因此，对于这个 $\\tau$：\n  - $TP=3$, $FP=0$, $FN=0$, $TN=5$。\n  - $P = 3/(3+0)=1$。$R = 3/(3+0)=1$。\n  - $F_1 = (2 \\cdot 1 \\cdot 1) / (1+1) = 1.0$。\n  全面的搜索显示这是可能的最大 $F_1$ 分数，并且是唯一的。因此，$\\tau^\\star \\approx 13.943$ 且 $F_1(\\mathcal{D}_{\\text{val}};\\tau^\\star) = 1.0$。\n\n- 我们现在使用 $\\tau^\\star$ 在 $\\mathcal{D}_{\\text{test}}$ 上进行评估。$\\mathcal{D}_{\\text{test}}$ 的标准化分数范围从大约 $-1.549$ 到 $12.394$。这些分数中没有一个大于或等于 $\\tau^\\star \\approx 13.943$。因此，所有测试实例都被分类为正常。\n  - $Y_{\\text{test}}$ 包含 $3$ 个异常实例和 $5$ 个正常实例。\n  - 预测结果全为正常，所以 $TP=0$ 且 $FP=0$。这意味着 $FN=3$ 且 $TN=5$。\n  - $P = 0/(0+0)=0$。$R = 0/(0+3)=0$。\n  - $F_1(\\mathcal{D}_{\\text{test}};\\tau^\\star) = 0$。\n\n- 差距为 $g_1 = 1.0 - 0.0 = 1.0$。\n\n其他用例也遵循类似的过程。值得注意的是，在**用例 3**中，验证集 $\\mathcal{D}_{\\text{val}}$ 不含异常（$TP+FN=0$）。根据定义，这意味着对于任何 $\\tau$ 的选择，$R=0$，这又反过来迫使 $F_1=0$。最大$F_1$分数为 $0$，所有候选阈值都能达到。平局打破规则（“选择最大的 $\\tau$”）规定我们必须选择 $\\tau^\\star = +\\infty$。当此阈值应用于测试集时，同样得到$F_1$分数为 $0$，因此差距 $g_3=0$。\n\n实现将为每个提供的用例系统地执行这些步骤。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    It orchestrates the calculation of the performance gap 'g' for each case\n    and prints the final results in the specified format.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"train_scores\": [0.9, 1.0, 1.1, 1.0, 0.95, 1.05],\n            \"val_data\": (\n                [0.7, 0.85, 0.95, 1.2, 2.0, 2.1, 1.9, 0.8],\n                [0, 0, 0, 0, 1, 1, 1, 0]\n            ),\n            \"test_data\": (\n                [0.9, 0.98, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8],\n                [0, 0, 0, 0, 0, 1, 1, 1]\n            )\n        },\n        {\n            \"train_scores\": [0.0, 0.1, -0.1, 0.15, -0.05],\n            \"val_data\": (\n                [0.0, 0.05, -0.05, 0.9],\n                [0, 0, 0, 1]\n            ),\n            \"test_data\": (\n                [0.0, 0.1, 0.2, -0.1, 0.3, 0.4, 0.85, 0.75],\n                [0, 0, 0, 0, 0, 0, 1, 1]\n            )\n        },\n        {\n            \"train_scores\": [5.0, 5.2, 4.8, 5.1, 4.9],\n            \"val_data\": (\n                [5.0, 5.1, 5.2, 5.3],\n                [0, 0, 0, 0]\n            ),\n            \"test_data\": (\n                [5.0, 5.1, 5.2, 5.5, 6.0, 6.5],\n                [0, 0, 0, 1, 1, 1]\n            )\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        g = process_case(case[\"train_scores\"], case[\"val_data\"], case[\"test_data\"])\n        results.append(f\"{g:.4f}\")\n\n    print(f\"[{','.join(results)}]\")\n\ndef calculate_f1(scores_z, labels, tau):\n    \"\"\"\n    Calculates the F1 score for a given dataset and threshold.\n    \n    Args:\n        scores_z (np.array): Standardized anomaly scores.\n        labels (np.array): Ground-truth binary labels (0=normal, 1=anomaly).\n        tau (float): The decision threshold.\n\n    Returns:\n        float: The calculated F1 score.\n    \"\"\"\n    predictions = (scores_z >= tau).astype(int)\n    \n    tp = np.sum((predictions == 1)  (labels == 1))\n    fp = np.sum((predictions == 1)  (labels == 0))\n    fn = np.sum((predictions == 0)  (labels == 1))\n    \n    p_denom = tp + fp\n    r_denom = tp + fn\n    \n    p = tp / p_denom if p_denom > 0 else 0.0\n    r = tp / r_denom if r_denom > 0 else 0.0\n    \n    f1_denom = p + r\n    f1 = (2 * p * r) / f1_denom if f1_denom > 0 else 0.0\n    \n    return f1\n\ndef process_case(train_scores, val_data, test_data):\n    \"\"\"\n    Processes a single test case to compute the performance gap 'g'.\n    \n    Args:\n        train_scores (list): Scores from the training set.\n        val_data (tuple): A tuple of (scores, labels) for the validation set.\n        test_data (tuple): A tuple of (scores, labels) for the test set.\n\n    Returns:\n        float: The performance gap g.\n    \"\"\"\n    train_scores_np = np.array(train_scores, dtype=np.float64)\n    mu_train = np.mean(train_scores_np)\n    sigma_train = np.std(train_scores_np)\n\n    def standardize(scores, mu, sigma):\n        if sigma == 0:\n            # Handle the case where all training scores are identical.\n            # Scores equal to mu get z=0, others +/- inf.\n            scores_np = np.array(scores, dtype=np.float64)\n            z = np.zeros_like(scores_np)\n            z[scores_np > mu] = np.inf\n            z[scores_np  mu] = -np.inf\n            return z\n        return (np.array(scores, dtype=np.float64) - mu) / sigma\n\n    val_scores_raw, val_labels_raw = val_data\n    val_scores_z = standardize(val_scores_raw, mu_train, sigma_train)\n    val_labels = np.array(val_labels_raw)\n\n    test_scores_raw, test_labels_raw = test_data\n    test_scores_z = standardize(test_scores_raw, mu_train, sigma_train)\n    test_labels = np.array(test_labels_raw)\n\n    # Identify candidate thresholds\n    candidate_taus = np.unique(val_scores_z)\n    candidate_taus = np.concatenate((candidate_taus, [-np.inf, np.inf]))\n    \n    # Find the best threshold on the validation set\n    f1_tau_pairs = []\n    for tau in candidate_taus:\n        f1 = calculate_f1(val_scores_z, val_labels, tau)\n        f1_tau_pairs.append((f1, tau))\n    \n    # Sort by F1 (desc) and then tau (desc) to apply tie-breaking rule\n    f1_tau_pairs.sort(key=lambda x: (x[0], x[1]), reverse=True)\n    \n    best_f1_val, tau_star = f1_tau_pairs[0]\n    \n    # Evaluate on the test set with the chosen threshold\n    f1_test = calculate_f1(test_scores_z, test_labels, tau_star)\n    \n    # Compute the gap\n    g = best_f1_val - f1_test\n    \n    return g\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3200874"}, {"introduction": "在机器学习工作流中，一个常见但隐蔽的错误是数据泄露，它会导致模型评估结果过于乐观。本练习聚焦于数据增强与数据集划分不当所引发的泄露问题，你将通过对比“先增强后划分”的错误流程和“先划分后增强”的正确流程，来量化泄露的程度。通过这个实践，你将深刻理解為何必須在所有预处理步骤之前就严格划分数据集，以保证评估的有效性。", "problem": "给定一个场景，其中在将数据集划分为训练集、验证集和测试集之前，会创建独立增强的数据样本。这可能导致同一原始样本的增强近似重复样本分布在不同的数据子集中，这是一种数据泄露形式，会使无偏模型评估失效。你的任务是在一个独立的程序中实现并分析两个流水线：一个是在划分前进行增强的朴素流水线，另一个是先划分原始样本然后在每个子集内进行增强的修正流水线。你将需要在一套固定的测试用例下为这两个流水线计算泄露指标。\n\n使用以下基础概念：\n- 为了进行无偏评估，训练集、验证集和测试集的划分必须近似于独立同分布的样本。如果关于某个测试样本的信息间接存在于训练数据中，就会发生数据泄露。如果同一原始样本的增强近似重复样本出现在不同的数据子集中，独立性假设就被违反了。\n- 将原始样本身份定义为一个组标识符。所有从同一原始样本派生出的增强样本都属于同一个等价类。如果两个增强样本来自相同的原始身份，则称它们为增强孪生样本。\n- 设 $x \\in \\mathbb{R}^d$ 表示一个基础特征向量。一次增强会产生 $x' = (1 + a) x + \\epsilon$，其中 $a$ 是一个小的乘性抖动，$\\epsilon$ 是一个小的加性噪声。对于仅使用特征的近似重复检测，定义两个向量 $u, v \\in \\mathbb{R}^d$ 的余弦相似度为 $\\mathrm{cos}(u,v) = \\dfrac{u^\\top v}{\\lVert u \\rVert_2 \\lVert v \\rVert_2}$。如果对于一个固定的阈值 $\\theta$，有 $\\mathrm{cos}(u,v) \\ge \\theta$，则两个样本是近似重复的。\n- 一个结构良好的划分意味着给定原始身份的所有增强孪生样本必须仅存在于一个数据子集中。如果在不同的子集中发现了孪生样本，就发生了泄露事件。\n\n你的程序必须：\n1. 使用提供的随机种子，为每个测试用例确定性地生成合成基础样本和增强样本。对于每个基础身份，从 $\\mathbb{R}^d$ 的标准正态分布中抽取一个基础向量，并将其归一化为单位长度。对于 $k$ 次增强中的每一次，从区间 $[-0.01, 0.01]$ 中均匀抽取 $a$，并从标准差为 $\\sigma$ 的零均值各向同性高斯分布中抽取 $\\epsilon$，然后构建 $x' = (1 + a)\\, x + \\epsilon$ 并将 $x'$ 归一化为单位长度。\n2. 实现两个流水线：\n   - 朴素流水线：为所有身份创建所有增强样本，然后通过样本级混洗，根据比例 $(r_{\\mathrm{train}}, r_{\\mathrm{val}}, r_{\\mathrm{test}})$（其中 $r_{\\mathrm{train}} + r_{\\mathrm{val}} + r_{\\mathrm{test}} = 1$）将增强后的集合随机划分为训练集、验证集和测试集。设前 $\\lfloor N r_{\\mathrm{train}} \\rfloor$ 个样本为训练集，接下来的 $\\lfloor N r_{\\mathrm{val}} \\rfloor$ 个为验证集，其余为测试集，其中 $N$ 是增强样本的总数。\n   - 修正流水线：首先随机混洗基础身份，并在身份级别上使用相同的比例取整规则，将它们按组划分为训练、验证和测试身份集。然后，为每个身份直接在其分配到的子集中生成 $k$ 个增强样本。\n3. 为每个流水线计算：\n   - 组泄露计数 $G$：其增强样本出现在至少两个不同子集中的基础身份的数量。\n   - 跨子集近似重复对计数 $P$：跨不同子集的样本对中，其余弦相似度严格大于 $\\theta$ 的对数。只计算位于不同子集中的样本对；对三个子集对（训练-验证、训练-测试、验证-测试）求和。在计算余弦相似度之前，所有向量都必须被归一化，以确保点积等于余弦相似度。\n\n使用以下测试套件。每个测试用例提供 $(n_{\\mathrm{base}}, k, d, r_{\\mathrm{train}}, r_{\\mathrm{val}}, r_{\\mathrm{test}}, \\sigma, \\theta, \\text{seed})$：\n- 案例 1：$n_{\\mathrm{base}} = 50$，$k = 3$，$d = 128$，$(r_{\\mathrm{train}}, r_{\\mathrm{val}}, r_{\\mathrm{test}}) = (0.7, 0.15, 0.15)$，$\\sigma = 0.01$，$\\theta = 0.99$，$\\text{seed} = 42$。\n- 案例 2 (边界情况：无增强多重性)：$n_{\\mathrm{base}} = 40$，$k = 1$，$d = 128$，$(r_{\\mathrm{train}}, r_{\\mathrm{val}}, r_{\\mathrm{test}}) = (0.6, 0.2, 0.2)$，$\\sigma = 0.01$，$\\theta = 0.99$，$\\text{seed} = 123$。\n- 案例 3 (更强的增强)：$n_{\\mathrm{base}} = 30$，$k = 10$，$d = 128$，$(r_{\\mathrm{train}}, r_{\\mathrm{val}}, r_{\\mathrm{test}}) = (0.6, 0.2, 0.2)$，$\\sigma = 0.01$，$\\theta = 0.99$，$\\text{seed} = 7$。\n- 案例 4 (不平衡比例与极小的验证集)：$n_{\\mathrm{base}} = 7$，$k = 4$，$d = 128$，$(r_{\\mathrm{train}}, r_{\\mathrm{val}}, r_{\\mathrm{test}}) = (0.8, 0.01, 0.19)$，$\\sigma = 0.01$，$\\theta = 0.99$，$\\text{seed} = 2023$。\n\n对于每个测试用例，按顺序产生以下六个整数：\n- $I_{\\mathrm{naive}}$：指示符，如果 $G_{\\mathrm{naive}}  0$ 则为 $1$，否则为 $0$。\n- $I_{\\mathrm{corr}}$：指示符，如果 $G_{\\mathrm{corr}}  0$ 则为 $1$，否则为 $0$。\n- $G_{\\mathrm{naive}}$：朴素流水线的组泄露计数。\n- $G_{\\mathrm{corr}}$：修正流水线的组泄露计数。\n- $P_{\\mathrm{naive}}$：朴素流水线的跨子集近似重复对计数。\n- $P_{\\mathrm{corr}}$：修正流水线的跨子集近似重复对计数。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含四个测试用例的所有结果，这些结果被展平并打印为用方括号括起来的单个逗号分隔的整数列表。顺序必须是先案例 1 的值，然后是案例 2，接着是案例 3，最后是案例 4，每个案例按上述指定的确切顺序贡献六个整数。例如，一个包含两个假设案例的输出格式为 $[I_1,I_2,G_1,G_2,P_1,P_2,\\dots]$。不应打印任何额外的文本。", "solution": "用户提供了一个关于机器学习工作流中因数据增强和数据集划分顺序不当而导致数据泄露的问题陈述。任务是实现并对比两个流水线：一个在划分前进行增强的“朴素”流水线，以及一个先划分后增强的“修正”流水线。分析过程涉及在一系列测试用例中为每个流水线计算特定的泄露指标。\n\n### 问题验证\n\n**第一步：提取已知信息**\n\n- **核心概念**：当原始样本的增强近似重复样本被分布到训练集、验证集和测试集中时，会发生数据泄露，这违反了无偏模型评估所需的独立同分布（i.i.d.）假设。\n- **定义**：\n    - **原始样本身份**：原始数据样本的组标识符。\n    - **增强孪生样本**：从相同原始身份派生出的样本。\n    - **结构良好的划分**：一种划分，其中给定身份的所有增强孪生样本都位于恰好一个分区（训练集、验证集或测试集）中。\n    - **泄露事件**：来自相同身份的增强孪生样本被发现在不同子集中的情况。\n- **增强过程**：\n    - 增强样本 $x'$ 是从基础特征向量 $x \\in \\mathbb{R}^d$ 通过公式 $x' = (1 + a) x + \\epsilon$ 生成的。\n    - 基础向量 $x$ 被归一化为单位长度。\n    - $a$ 从均匀分布 $U[-0.01, 0.01]$ 中抽取。\n    - $\\epsilon$ 是从标准差为 $\\sigma$ 的零均值各向同性高斯分布中抽取的噪声向量，即 $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2 I_d)$。\n    - 最终的增强向量 $x'$ 也被归一化为单位长度。\n- **近似重复检测**：\n    - 如果两个样本 $u, v$ 的余弦相似度 $\\mathrm{cos}(u,v) = \\frac{u^\\top v}{\\lVert u \\rVert_2 \\lVert v \\rVert_2}$ 大于等于阈值 $\\theta$，则它们是近似重复的。由于所有向量都归一化为单位长度，这简化为 $u^\\top v > \\theta$。问题陈述指定了严格大于：$\\mathrm{cos}(u,v) > \\theta$。\n- **流水线实现**：\n    - **朴素流水线**：生成所有增强样本，然后随机混洗并根据比例 $(r_{\\mathrm{train}}, r_{\\mathrm{val}}, r_{\\mathrm{test}})$ 将整个增强样本集划分为训练/验证/测试集。划分大小为 $\\lfloor N r_{\\mathrm{train}} \\rfloor$、$\\lfloor N r_{\\mathrm{val}} \\rfloor$，其余为测试集，其中 $N$ 是增强样本的总数。\n    - **修正流水线**：随机混洗并划分基础身份到训练/验证/测试集。然后，在每个身份被分配的子集内为其生成增强样本。\n- **待计算指标**：\n    - **组泄露计数 ($G$)**：其增强样本出现在至少两个不同子集中的基础身份的数量。\n    - **跨子集近似重复对计数 ($P$)**：样本对 $(u, v)$ 的数量，其中 $u$ 和 $v$ 位于不同的子集中且 $\\mathrm{cos}(u,v) > \\theta$。计数在训练-验证、训练-测试和验证-测试对之间求和。\n- **测试套件**：提供了四个案例，每个都有参数 $(n_{\\mathrm{base}}, k, d, r_{\\mathrm{train}}, r_{\\mathrm{val}}, r_{\\mathrm{test}}, \\sigma, \\theta, \\text{seed})$。\n    - 案例 1：$(50, 3, 128, 0.7, 0.15, 0.15, 0.01, 0.99, 42)$\n    - 案例 2：$(40, 1, 128, 0.6, 0.2, 0.2, 0.01, 0.99, 123)$\n    - 案例 3：$(30, 10, 128, 0.6, 0.2, 0.2, 0.01, 0.99, 7)$\n    - 案例 4：$(7, 4, 128, 0.8, 0.01, 0.19, 0.01, 0.99, 2023)$\n- **输出**：对于每个案例，需要六个整数值：$I_{\\mathrm{naive}} = (G_{\\mathrm{naive}}  0)$，$I_{\\mathrm{corr}} = (G_{\\mathrm{corr}}  0)$，$G_{\\mathrm{naive}}$，$G_{\\mathrm{corr}}$，$P_{\\mathrm{naive}}$，$P_{\\mathrm{corr}}$。最终输出必须是这些整数的单个展平列表。\n\n**第二步：使用提取的已知信息进行验证**\n\n该问题在科学上和数学上是合理的。它解决了一个在应用机器学习中的真实且关键的问题，即预处理过程中的数据泄露。关于增强、划分和泄露指标（$G$ 和 $P$）的定义是精确且可形式化的。对每个测试用例使用确定性的随机种子确保了问题是适定的（well-posed）并且有一个唯一的、可验证的解。所有必要的参数都为每个测试用例提供了。该问题没有歧义、主观性和事实错误。\n\n**第三步：结论与行动**\n\n问题陈述是**有效的**。我将继续构建解决方案。\n\n### 算法设计与原则\n\n该解决方案需要确定性地实现数据生成、两个不同的数据划分流水线和两个泄露指标。问题的核心是展示样本级划分和组级划分之间的结构性差异，并量化由此产生的数据泄露。\n\n**1. 确定性数据生成**\n\n对于每个测试用例，将使用提供的 `seed` 为随机数生成器设定种子。这确保了可复现性。\n- **基础样本**：对于 $n_{\\mathrm{base}}$ 个身份中的每一个，从标准正态分布 $\\mathcal{N}(0, I_d)$ 中抽取一个基础向量 $x \\in \\mathbb{R}^d$。然后将该向量归一化，使其欧几里得范数为 $1$，即 $x \\leftarrow x / \\lVert x \\rVert_2$。\n- **增强**：对于每个基础样本 $x$，创建 $k$ 个增强样本。对于每次增强 $x'$，从 $U[-0.01, 0.01]$ 中抽取一个乘性抖动项 $a$，并从 $\\mathcal{N}(0, \\sigma^2 I_d)$ 中抽取一个加性噪声向量 $\\epsilon$。增强向量计算为 $x' = (1+a)x + \\epsilon$。关键是，$x'$ 也被归一化为单位长度，$x' \\leftarrow x' / \\lVert x' \\rVert_2$。这种归一化将余弦相似度计算简化为简单的点积，因为对于单位向量 $u$ 和 $v$，$\\mathrm{cos}(u,v) = u^\\top v$。\n\n**2. 朴素流水线：先增强后划分**\n\n该流水线模拟了在划分数据集之前应用增强的错误但常见的做法。\n- 首先，生成总共 $N = n_{\\mathrm{base}} \\times k$ 个增强样本并存储，同时存储它们对应的原始基础身份索引（从 $0$ 到 $n_{\\mathrm{base}}-1$）。\n- 然后，将这 $N$ 个样本的集合进行随机混洗。\n- 混洗后的集合被划分。训练样本的数量为 $N_{\\mathrm{train}} = \\lfloor N \\cdot r_{\\mathrm{train}} \\rfloor$。验证样本的数量为 $N_{\\mathrm{val}} = \\lfloor N \\cdot r_{\\mathrm{val}} \\rfloor$。测试集包含剩余的 $N_{\\mathrm{test}} = N - N_{\\mathrm{train}} - N_{\\mathrm{val}}$ 个样本。\n- 这种随机的、样本级别的分配很可能会将同一原始样本的增强孪生样本分布到不同的子集中，从而导致泄露。\n\n**3. 修正流水线：先划分后增强**\n\n此流水线遵循正确的程序，以防止因增强引起泄露。\n- 首先，对 $n_{\\mathrm{base}}$ 个*基础身份*的集合进行随机混洗。\n- 使用相同的比例逻辑将这些身份划分为训练、验证和测试集。训练身份的数量为 $n_{\\mathrm{train}} = \\lfloor n_{\\mathrm{base}} \\cdot r_{\\mathrm{train}} \\rfloor$，验证身份的数量为 $n_{\\mathrm{val}} = \\lfloor n_{\\mathrm{base}} \\cdot r_{\\mathrm{val}} \\rfloor$，测试身份的数量为 $n_{\\mathrm{test}} = n_{\\mathrm{base}} - n_{\\mathrm{train}} - n_{\\mathrm{val}}$。\n- 在身份被分配到子集后，增强过程在每个子集*内部*执行。对于训练身份集中的每个身份，为其生成 $k$ 个增强并添加到训练数据中。对验证和测试身份集也执行相同的操作。\n- 根据构造，单个原始样本的所有增强版本都保证会处于同一个子集中。\n\n**4. 泄露指标计算**\n\n对于每个流水线产生的划分，我们计算两个指标：\n- **组泄露计数 ($G$)**：我们遍历从 $0$ 到 $n_{\\mathrm{base}}-1$ 的每个基础身份。对于每个身份，我们查找其增强后代所在的子集。如果唯一子集的数量大于 $1$，我们增加 $G$。对于修正流水线，$G$ 将确定性地为 $0$。\n- **近似重复对计数 ($P$)**：我们必须计算跨不同子集的、余弦相似度大于 $\\theta$ 的样本对数量。这是通过计算两两子集的数据矩阵之间的完整点积矩阵来完成的。对于数据为 $X_1 \\in \\mathbb{R}^{N_1 \\times d}$ 和 $X_2 \\in \\mathbb{R}^{N_2 \\times d}$ 的子集，相似度矩阵为 $S = X_1 X_2^\\top \\in \\mathbb{R}^{N_1 \\times N_2}$。相似度大于 $\\theta$ 的对数是 $S$ 中严格大于 $\\theta$ 的元素数量。此计数在训练-验证、训练-测试和验证-测试对之间求和。\n\n每个测试用例的最终输出包括六个整数：$(G_{\\mathrm{naive}}  0)$、$(G_{\\mathrm{corr}}  0)$、$G_{\\mathrm{naive}}$、$G_{\\mathrm{corr}}$、$P_{\\mathrm{naive}}$ 和 $P_{\\mathrm{corr}}$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        # (n_base, k, d, r_train, r_val, r_test, sigma, theta, seed)\n        (50, 3, 128, 0.7, 0.15, 0.15, 0.01, 0.99, 42),\n        (40, 1, 128, 0.6, 0.2, 0.2, 0.01, 0.99, 123),\n        (30, 10, 128, 0.6, 0.2, 0.2, 0.01, 0.99, 7),\n        (7, 4, 128, 0.8, 0.01, 0.19, 0.01, 0.99, 2023),\n    ]\n\n    all_results = []\n    for params in test_cases:\n        n_base, k, d, r_train, r_val, r_test, sigma, theta, seed = params\n        rng = np.random.default_rng(seed)\n\n        # 1. Generate base data\n        base_vectors = rng.standard_normal(size=(n_base, d))\n        base_vectors /= np.linalg.norm(base_vectors, axis=1, keepdims=True)\n\n        # 2. Run both pipelines and compute metrics\n        g_naive, p_naive = run_naive_pipeline(\n            base_vectors, k, d, r_train, r_val, sigma, theta, rng\n        )\n        g_corr, p_corr = run_corrected_pipeline(\n            base_vectors, k, d, r_train, r_val, sigma, theta, rng\n        )\n        \n        i_naive = 1 if g_naive > 0 else 0\n        i_corr = 1 if g_corr > 0 else 0\n\n        all_results.extend([i_naive, i_corr, g_naive, g_corr, p_naive, p_corr])\n\n    print(f\"[{','.join(map(str, all_results))}]\")\n\ndef generate_augmentations(base_vector, k, d, sigma, rng):\n    \"\"\"Generates k augmentations for a single base vector.\"\"\"\n    if k == 0:\n        return np.empty((0, d)), np.array([])\n    \n    a_jitter = rng.uniform(-0.01, 0.01, size=k)\n    noise = rng.normal(0, sigma, size=(k, d))\n    \n    # Broadcasting base_vector and a_jitter\n    augmented_vectors = (1 + a_jitter)[:, np.newaxis] * base_vector + noise\n    \n    norms = np.linalg.norm(augmented_vectors, axis=1, keepdims=True)\n    # Avoid division by zero, although highly unlikely\n    safe_norms = np.where(norms == 0, 1e-9, norms)\n    augmented_vectors /= safe_norms\n    \n    return augmented_vectors\n\ndef compute_metrics(splits_data, splits_ids, n_base, theta):\n    \"\"\"Computes group leakage (G) and near-duplicate pairs (P).\"\"\"\n    # Compute Group Leakage (G)\n    group_split_map = {i: set() for i in range(n_base)}\n    for split_name, ids in splits_ids.items():\n        for group_id in ids:\n            group_split_map[group_id].add(split_name)\n    \n    g_leakage = sum(1 for splits in group_split_map.values() if len(splits) > 1)\n\n    # Compute Near-Duplicate Pairs (P)\n    p_pairs = 0\n    split_names = list(splits_data.keys())\n    \n    for i in range(len(split_names)):\n        for j in range(i + 1, len(split_names)):\n            name1, name2 = split_names[i], split_names[j]\n            data1, data2 = splits_data[name1], splits_data[name2]\n            \n            if data1.shape[0] == 0 or data2.shape[0] == 0:\n                continue\n\n            similarity_matrix = data1 @ data2.T\n            p_pairs += np.sum(similarity_matrix > theta)\n            \n    return g_leakage, p_pairs\n\ndef run_naive_pipeline(base_vectors, k, d, r_train, r_val, sigma, theta, rng):\n    \"\"\"Implements the naive augment-then-split pipeline.\"\"\"\n    n_base = base_vectors.shape[0]\n    total_samples = n_base * k\n\n    if total_samples == 0:\n        return 0, 0\n        \n    all_augmented_data = np.empty((total_samples, d))\n    all_group_ids = np.empty(total_samples, dtype=int)\n\n    for i in range(n_base):\n        start_idx = i * k\n        end_idx = (i + 1) * k\n        all_augmented_data[start_idx:end_idx] = generate_augmentations(base_vectors[i], k, d, sigma, rng)\n        all_group_ids[start_idx:end_idx] = i\n\n    indices = rng.permutation(total_samples)\n    shuffled_data = all_augmented_data[indices]\n    shuffled_ids = all_group_ids[indices]\n\n    train_size = int(np.floor(total_samples * r_train))\n    val_size = int(np.floor(total_samples * r_val))\n\n    train_data = shuffled_data[0:train_size]\n    train_ids = shuffled_ids[0:train_size]\n\n    val_data = shuffled_data[train_size : train_size + val_size]\n    val_ids = shuffled_ids[train_size : train_size + val_size]\n\n    test_data = shuffled_data[train_size + val_size:]\n    test_ids = shuffled_ids[train_size + val_size:]\n\n    splits_data = {'train': train_data, 'val': val_data, 'test': test_data}\n    splits_ids = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n    \n    return compute_metrics(splits_data, splits_ids, n_base, theta)\n\n\ndef run_corrected_pipeline(base_vectors, k, d, r_train, r_val, sigma, theta, rng):\n    \"\"\"Implements the corrected split-then-augment pipeline.\"\"\"\n    n_base = base_vectors.shape[0]\n    \n    if n_base == 0:\n        return 0, 0\n\n    identity_indices = rng.permutation(n_base)\n    \n    train_id_size = int(np.floor(n_base * r_train))\n    val_id_size = int(np.floor(n_base * r_val))\n\n    train_ids = identity_indices[0:train_id_size]\n    val_ids = identity_indices[train_id_size : train_id_size + val_id_size]\n    test_ids = identity_indices[train_id_size + val_id_size:]\n\n    train_data = np.vstack([generate_augmentations(base_vectors[i], k, d, sigma, rng) for i in train_ids]) if len(train_ids) > 0 else np.empty((0, d))\n    val_data = np.vstack([generate_augmentations(base_vectors[i], k, d, sigma, rng) for i in val_ids]) if len(val_ids) > 0 else np.empty((0, d))\n    test_data = np.vstack([generate_augmentations(base_vectors[i], k, d, sigma, rng) for i in test_ids]) if len(test_ids) > 0 else np.empty((0, d))\n    \n    train_group_ids = np.repeat(train_ids, k)\n    val_group_ids = np.repeat(val_ids, k)\n    test_group_ids = np.repeat(test_ids, k)\n    \n    splits_data = {'train': train_data, 'val': val_data, 'test': test_data}\n    splits_ids = {'train': train_group_ids, 'val': val_group_ids, 'test': test_group_ids}\n\n    # By construction, G must be 0, but we compute it for verification.\n    return compute_metrics(splits_data, splits_ids, n_base, theta)\n\nsolve()\n```", "id": "3194804"}, {"introduction": "真实世界的数据很少完美遵循独立同分布（i.i.d.）的假设。本高级练习将处理一种被称为“先验概率偏移”的常见分布偏移问题，即类的比例在训练和测试环境之间发生变化。你将推导并实现一种基于原则的校正方法，利用验证集来估计并补偿这种偏移，从而更准确地预测模型在测试集上的表现。这项练习将使你具备诊断和处理数据集之间不一致性的能力。", "problem": "给定一个二元分类场景，其中模型在一个具有特定类别先验概率的数据集上进行训练，然后在一个从相同分布中采样的留出验证集上进行评估。部署将在一个具有不同类别先验概率的测试分布上进行，而类别条件特征分布保持不变。这就是经典的先验概率偏移设定。您的任务是使用第一性原理推导出对留出估计的正确调整，以便它们能更好地预测在测试分布上的性能，然后实现并评估这些调整。\n\n请将您的推理建立在以下基本定义和经过充分检验的事实之上：\n\n- 类别先验概率的定义：对于一个二元标签随机变量 $Y \\in \\{0,1\\}$，训练先验是 $\\pi_{\\text{train}} = \\mathbb{P}_{\\text{train}}(Y=1)$，测试先验是 $\\pi_{\\text{test}} = \\mathbb{P}_{\\text{test}}(Y=1)$。\n- 贝叶斯定理，关联后验概率、似然和先验概率：对于任何特征向量 $x$，$\\mathbb{P}(Y=1 \\mid X=x) = \\dfrac{\\mathbb{P}(X=x \\mid Y=1)\\,\\mathbb{P}(Y=1)}{\\mathbb{P}(X=x)}$。\n- 先验概率偏移假设：类别条件特征分布在不同域之间是不变的，即对于 $y \\in \\{0,1\\}$，有 $\\mathbb{P}_{\\text{train}}(X \\mid Y=y) = \\mathbb{P}_{\\text{test}}(X \\mid Y=y)$。只有类别先验概率在训练/验证和测试之间有所不同。\n\n基于这些基础，推导：\n1) 一个原则性映射，它将任意后验分数 $s = \\mathbb{P}_{\\text{train}}(Y=1 \\mid X=x)$ 转换为测试先验下的相应后验 $s' = \\mathbb{P}_{\\text{test}}(Y=1 \\mid X=x)$。\n2) 在先验概率偏移下，能正确地对验证样本进行重加权以无偏估计测试分布上平均值的重要性权重。\n\n然后，为下面的测试套件中的每种情况实现以下评估协议：\n\n- 给定一个验证集 $\\{(y_i, s_i)\\}_{i=1}^{n_{\\text{val}}}$，其中 $y_i \\in \\{0,1\\}$，$s_i \\in (0,1)$ 是模型产生的后验 $s_i = \\mathbb{P}_{\\text{train}}(Y=1 \\mid X=x_i)$。该验证集是从具有先验 $\\pi_{\\text{train}}$ 的训练分布中独立同分布采样的。\n- 给定一个测试集 $\\{(y_j^{\\ast}, s_j^{\\ast})\\}_{j=1}^{n_{\\text{test}}}$，其标签和分数以相同方式计算 $s_j^{\\ast} = \\mathbb{P}_{\\text{train}}(Y=1 \\mid X=x_j^{\\ast})$，但它是从具有先验 $\\pi_{\\text{test}}$ 的测试分布中独立同分布采样的。\n- 将部署的分类器定义为在相等错分成本下的贝叶斯决策规则：当且仅当相关分布下的后验概率至少为 $0.5$ 时，预测 $\\hat{y}=1$。因此，在验证集上，对于调整后的估计，您必须首先使用您推导的从 $\\pi_{\\text{train}}$到 $\\pi_{\\text{test}}$ 的映射将 $s_i$ 转换为 $s'_i$，然后将 $s'_i$ 在 $0.5$ 处进行阈值处理。在测试集上，使用相同的映射从 $s_j^{\\ast}$ 计算 $s_j^{*\\prime}$，然后同样在 $0.5$ 处进行阈值处理以获得真实的部署预测。\n- 将性能指标定义为分类准确率。对于朴素留出估计，通过将未经调整的 $s_i$ 在 $0.5$ 处进行阈值处理来计算未加权的验证准确率。对于调整后留出估计，通过将 $s'_i$ 在 $0.5$ 处进行阈值处理并应用根据先验推导出的、能正确反映先验概率偏移的重要性权重，来计算加权验证准确率。对于真实测试准确率，在将 $s_j^{*\\prime}$ 在 $0.5$ 处进行阈值处理后，计算测试集上的未加权准确率。\n\n对于下面的每种情况，计算：\n- 朴素留出估计相对于真实测试准确率的绝对误差。\n- 调整后留出估计相对于真实测试准确率的绝对误差。\n- 提升量，定义为朴素绝对误差减去调整后绝对误差。将此提升量报告为浮点数。\n\n在所有需要对后验概率进行阈值处理以生成类别预测的地方，均使用决策阈值 $0.5$。不涉及物理单位或角度。所有小数都应被视为实数；不要用百分号表示任何答案。\n\n测试套件。每种情况指定了 $(\\pi_{\\text{train}}, \\pi_{\\text{test}})$、一个验证集和一个测试集。\n\n情况 $1$:\n- 先验：$\\pi_{\\text{train}} = 0.5$, $\\pi_{\\text{test}} = 0.2$。\n- 验证集 $\\{(y_i, s_i)\\}_{i=1}^{12}$:\n  [($1$, $0.92$), ($1$, $0.85$), ($1$, $0.78$), ($1$, $0.71$), ($1$, $0.64$), ($1$, $0.57$), ($0$, $0.49$), ($0$, $0.42$), ($0$, $0.35$), ($0$, $0.29$), ($0$, $0.21$), ($0$, $0.13$)]。\n- 测试集 $\\{(y_j^{\\ast}, s_j^{\\ast})\\}_{j=1}^{10}$:\n  [($1$, $0.85$), ($1$, $0.64$), ($0$, $0.49$), ($0$, $0.42$), ($0$, $0.35$), ($0$, $0.29$), ($0$, $0.21$), ($0$, $0.13$), ($0$, $0.27$), ($0$, $0.12$)]。\n\n情况 $2$:\n- 先验：$\\pi_{\\text{train}} = 0.5$, $\\pi_{\\text{test}} = 0.05$。\n- 验证集 $\\{(y_i, s_i)\\}_{i=1}^{12}$:\n  [($1$, $0.92$), ($1$, $0.85$), ($1$, $0.78$), ($1$, $0.71$), ($1$, $0.64$), ($1$, $0.57$), ($0$, $0.49$), ($0$, $0.42$), ($0$, $0.35$), ($0$, $0.29$), ($0$, $0.21$), ($0$, $0.13$)]。\n- 测试集 $\\{(y_j^{\\ast}, s_j^{\\ast})\\}_{j=1}^{20}$:\n  [($1$, $0.78$),\n   ($0$, $0.49$), ($0$, $0.42$), ($0$, $0.36$), ($0$, $0.29$), ($0$, $0.21$), ($0$, $0.13$),\n   ($0$, $0.47$), ($0$, $0.44$), ($0$, $0.39$), ($0$, $0.34$), ($0$, $0.31$), ($0$, $0.26$),\n   ($0$, $0.24$), ($0$, $0.19$), ($0$, $0.17$), ($0$, $0.15$), ($0$, $0.12$), ($0$, $0.10$), ($0$, $0.08$)]。\n\n情况 $3$:\n- 先验：$\\pi_{\\text{train}} = 0.2$, $\\pi_{\\text{test}} = 0.7$。\n- 验证集 $\\{(y_i, s_i)\\}_{i=1}^{10}$:\n  [($1$, $0.85$), ($1$, $0.64$), ($0$, $0.49$), ($0$, $0.42$), ($0$, $0.36$), ($0$, $0.29$), ($0$, $0.21$), ($0$, $0.13$), ($0$, $0.31$), ($0$, $0.25$)]。\n- 测试集 $\\{(y_j^{\\ast}, s_j^{\\ast})\\}_{j=1}^{10}$:\n  [($1$, $0.92$), ($1$, $0.85$), ($1$, $0.78$), ($1$, $0.71$), ($1$, $0.64$), ($1$, $0.57$), ($1$, $0.68$), ($0$, $0.42$), ($0$, $0.29$), ($0$, $0.21$)]。\n\n您的程序必须：\n- 实现从 $s$ 到 $s'$ 的贝叶斯一致先验调整映射，以及由先验概率偏移所蕴含的正确类别重要性权重。\n- 对每种情况，计算：\n  a) 朴素验证准确率（在验证集上对未经调整的 $s$ 在 $0.5$ 处进行阈值处理），\n  b) 调整后验证准确率（使用正确的重要性权重对 $s'$ 在 $0.5$ 处进行阈值处理的加权验证），\n  c) 真实测试准确率（在测试集上对 $s^{\\ast\\prime}$ 在 $0.5$ 处进行阈值处理的未加权准确率），\n  d) 朴素估计和调整后估计相对于真实测试准确率的绝对误差，以及\n  e) 提升量，定义为朴素绝对误差减去调整后绝对误差。\n- 在单行输出中汇总三种情况下的提升量值。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个由方括号括起来的、包含三个提升量值（每个情况一个）的逗号分隔列表，每个值四舍五入到 $6$ 位小数，例如 `[0.012345,0.067890,0.000000]`。", "solution": "本问题探讨了二元分类中的先验概率偏移情景，这是机器学习中一个常见的挑战，即类别分布在训练/验证环境和测试环境之间发生变化。其基本假设是类别条件特征分布 $\\mathbb{P}(X \\mid Y=y)$ 保持不变。我们的任务是推导并实现对验证集上获得的性能估计进行原则性调整，以更好地预测在测试集上的性能。\n\n### **第一部分：后验概率调整的推导**\n\n令 $s = \\mathbb{P}_{\\text{train}}(Y=1 \\mid X=x)$ 为在训练分布下特征向量 $x$ 的正类别后验概率，而 $s' = \\mathbb{P}_{\\text{test}}(Y=1 \\mid X=x)$ 为在测试分布下的相应后验概率。类别先验为 $\\pi_{\\text{train}} = \\mathbb{P}_{\\text{train}}(Y=1)$ 和 $\\pi_{\\text{test}} = \\mathbb{P}_{\\text{test}}(Y=1)$。\n\n根据贝叶斯定理，训练分布下类别 1 和类别 0 的后验概率为：\n$$ s = \\mathbb{P}_{\\text{train}}(Y=1 \\mid X=x) = \\frac{\\mathbb{P}_{\\text{train}}(X=x \\mid Y=1) \\, \\pi_{\\text{train}}}{\\mathbb{P}_{\\text{train}}(X=x)} $$\n$$ 1-s = \\mathbb{P}_{\\text{train}}(Y=0 \\mid X=x) = \\frac{\\mathbb{P}_{\\text{train}}(X=x \\mid Y=0) \\, (1-\\pi_{\\text{train}})}{\\mathbb{P}_{\\text{train}}(X=x)} $$\n\n先验概率偏移假设指出，对于 $y \\in \\{0,1\\}$，$\\mathbb{P}_{\\text{train}}(X=x \\mid Y=y) = \\mathbb{P}_{\\text{test}}(X=x \\mid Y=y)$。我们将这个不变的似然表示为 $\\mathbb{P}(X=x \\mid Y=y)$。\n\n取上述两方程的比值，我们可以用似然比表示后验几率：\n$$ \\frac{s}{1-s} = \\frac{\\mathbb{P}(X=x \\mid Y=1)}{\\mathbb{P}(X=x \\mid Y=0)} \\frac{\\pi_{\\text{train}}}{1-\\pi_{\\text{train}}} $$\n似然比与先验概率无关，可以被分离出来：\n$$ \\frac{\\mathbb{P}(X=x \\mid Y=1)}{\\mathbb{P}(X=x \\mid Y=0)} = \\frac{s}{1-s} \\frac{1-\\pi_{\\text{train}}}{\\pi_{\\text{train}}} $$\n\n现在，我们写出测试分布的后验几率：\n$$ \\frac{s'}{1-s'} = \\frac{\\mathbb{P}(X=x \\mid Y=1)}{\\mathbb{P}(X=x \\mid Y=0)} \\frac{\\pi_{\\text{test}}}{1-\\pi_{\\text{test}}} $$\n代入从训练分布推导出的似然比表达式，得到：\n$$ \\frac{s'}{1-s'} = \\left(\\frac{s}{1-s} \\frac{1-\\pi_{\\text{train}}}{\\pi_{\\text{train}}}\\right) \\frac{\\pi_{\\text{test}}}{1-\\pi_{\\text{test}}} $$\n这个方程表明，后验几率通过先验几率之比进行重新缩放。令这个新的几率为 $O' = \\frac{s'}{1-s'}$。解出 $s'$ 得 $s' = O' / (1+O')$。代入 $O'$ 的完整表达式：\n$$ s' = \\frac{\\frac{s}{1-s} \\frac{1-\\pi_{\\text{train}}}{\\pi_{\\text{train}}} \\frac{\\pi_{\\text{test}}}{1-\\pi_{\\text{test}}}}{1 + \\frac{s}{1-s} \\frac{1-\\pi_{\\text{train}}}{\\pi_{\\text{train}}} \\frac{\\pi_{\\text{test}}}{1-\\pi_{\\text{test}}}} $$\n为简化，分子和分母同乘以 $(1-s)\\pi_{\\text{train}}(1-\\pi_{\\text{test}})$：\n$$ s' = \\frac{s(1-\\pi_{\\text{train}})\\pi_{\\text{test}}}{(1-s)\\pi_{\\text{train}}(1-\\pi_{\\text{test}}) + s(1-\\pi_{\\text{train}})\\pi_{\\text{test}}} $$\n这就是从在 $\\pi_{\\text{train}}$ 下计算的后验分数 $s$ 到在 $\\pi_{\\text{test}}$ 下的相应后验 $s'$ 的原则性映射。\n\n### **第二部分：重要性权重的推导**\n\n为了使用来自训练分布的样本 $\\{(x_i, y_i)\\}$ 来估计测试分布上函数 $f(x,y)$ 的期望，我们使用重要性采样。目标是找到权重 $w(x,y)$，使得 $\\mathbb{E}_{\\text{test}}[f(X,Y)] = \\mathbb{E}_{\\text{train}}[f(X,Y)w(X,Y)]$。\n一个样本 $(x, y)$ 的权重是概率密度之比：\n$$ w(x,y) = \\frac{\\mathbb{P}_{\\text{test}}(x,y)}{\\mathbb{P}_{\\text{train}}(x,y)} $$\n使用概率的链式法则，$\\mathbb{P}(x,y) = \\mathbb{P}(x \\mid y)\\mathbb{P}(y)$：\n$$ w(x,y) = \\frac{\\mathbb{P}_{\\text{test}}(X=x \\mid Y=y)\\mathbb{P}_{\\text{test}}(Y=y)}{\\mathbb{P}_{\\text{train}}(X=x \\mid Y=y)\\mathbb{P}_{\\text{train}}(Y=y)} $$\n在先验概率偏移假设下，似然 $\\mathbb{P}(X=x \\mid Y=y)$ 是相同的，因此可以消去，剩下：\n$$ w(x,y) = \\frac{\\mathbb{P}_{\\text{test}}(Y=y)}{\\mathbb{P}_{\\text{train}}(Y=y)} $$\n权重仅取决于类别标签 $y$。对于 $y=1$ 和 $y=0$，权重分别是：\n$$ w_1 = w(y=1) = \\frac{\\pi_{\\text{test}}}{\\pi_{\\text{train}}} $$\n$$ w_0 = w(y=0) = \\frac{1-\\pi_{\\text{test}}}{1-\\pi_{\\text{train}}} $$\n这些权重使我们能够对验证样本进行重加权，从而对测试分布上的任何期望形成无偏估计。验证集上的调整后准确率是正确性指示函数 $\\mathbb{I}(\\hat{y}'_i = y_i)$ 的加权平均值，其中 $\\hat{y}'_i$ 是从调整后分数 $s'_i$ 得出的预测。调整后准确率计算如下：\n$$ \\text{Acc}_{\\text{adj}} = \\frac{\\sum_{i=1}^{n_{\\text{val}}} w(y_i) \\cdot \\mathbb{I}(\\hat{y}'_i = y_i)}{\\sum_{i=1}^{n_{\\text{val}}} w(y_i)} $$\n\n### **第三部分：评估协议**\n\n我们将实现一个函数，对每个测试用例执行以下步骤：\n1.  **朴素准确率：** 通过将原始分数 $s_i$ 在 $0.5$ 处进行阈值处理，计算验证集上的准确率。\n2.  **真实测试准确率：** 计算测试集上的准确率。首先，使用推导的映射将每个测试分数 $s_j^{\\ast}$ 转换为其调整后的版本 $s_j^{\\ast\\prime}$。然后，通过将 $s_j^{\\ast\\prime}$ 在 $0.5$ 处进行阈值处理来获得预测。\n3.  **调整后准确率：** 计算验证集上的加权准确率。首先，将每个验证分数 $s_i$ 转换为 $s'_i$。然后，通过将 $s'_i$ 在 $0.5$ 处进行阈值处理来获得预测。最后，使用推导的重要性权重 $w_0$ 和 $w_1$ 计算正确性的加权平均值。\n4.  **提升量：** 计算朴素估计的绝对误差（$\\lvert\\text{Acc}_{\\text{naive}} - \\text{Acc}_{\\text{test}}\\rvert$）和调整后估计的绝对误差（$\\lvert\\text{Acc}_{\\text{adj}} - \\text{Acc}_{\\text{test}}\\rvert$）。提升量是这两个误差之差。\n该实现将处理提供的三个测试用例并报告提升量。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    It calculates and prints the improvement in accuracy estimation for each case.\n    \"\"\"\n    \n    # Test suite from the problem statement.\n    test_cases = [\n        {\n            \"priors\": (0.5, 0.2), # (pi_train, pi_test)\n            \"val_set\": [\n                (1, 0.92), (1, 0.85), (1, 0.78), (1, 0.71), (1, 0.64), (1, 0.57),\n                (0, 0.49), (0, 0.42), (0, 0.35), (0, 0.29), (0, 0.21), (0, 0.13)\n            ],\n            \"test_set\": [\n                (1, 0.85), (1, 0.64), (0, 0.49), (0, 0.42), (0, 0.35),\n                (0, 0.29), (0, 0.21), (0, 0.13), (0, 0.27), (0, 0.12)\n            ]\n        },\n        {\n            \"priors\": (0.5, 0.05),\n            \"val_set\": [\n                (1, 0.92), (1, 0.85), (1, 0.78), (1, 0.71), (1, 0.64), (1, 0.57),\n                (0, 0.49), (0, 0.42), (0, 0.35), (0, 0.29), (0, 0.21), (0, 0.13)\n            ],\n            \"test_set\": [\n                (1, 0.78), (0, 0.49), (0, 0.42), (0, 0.36), (0, 0.29), (0, 0.21), (0, 0.13),\n                (0, 0.47), (0, 0.44), (0, 0.39), (0, 0.34), (0, 0.31), (0, 0.26),\n                (0, 0.24), (0, 0.19), (0, 0.17), (0, 0.15), (0, 0.12), (0, 0.10), (0, 0.08)\n            ]\n        },\n        {\n            \"priors\": (0.2, 0.7),\n            \"val_set\": [\n                (1, 0.85), (1, 0.64), (0, 0.49), (0, 0.42), (0, 0.36),\n                (0, 0.29), (0, 0.21), (0, 0.13), (0, 0.31), (0, 0.25)\n            ],\n            \"test_set\": [\n                (1, 0.92), (1, 0.85), (1, 0.78), (1, 0.71), (1, 0.64),\n                (1, 0.57), (1, 0.68), (0, 0.42), (0, 0.29), (0, 0.21)\n            ]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        improvement = solve_case(\n            case[\"priors\"][0], \n            case[\"priors\"][1],\n            case[\"val_set\"],\n            case[\"test_set\"]\n        )\n        results.append(improvement)\n    \n    # Format the output as specified.\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef adjust_score(s, pi_train, pi_test):\n    \"\"\"\n    Adjusts a posterior score from a training prior to a test prior.\n    \n    Args:\n        s (float): The original posterior score P_train(Y=1|X=x).\n        pi_train (float): The training prior probability P_train(Y=1).\n        pi_test (float): The test prior probability P_test(Y=1).\n    \n    Returns:\n        float: The adjusted posterior score P_test(Y=1|X=x).\n    \"\"\"\n    # Numerically stable check for edge cases although problem constraints suggest s in (0,1)\n    if s == 1.0: return 1.0\n    if s == 0.0: return 0.0\n\n    numerator = s * pi_test * (1.0 - pi_train)\n    denominator = (1.0 - s) * pi_train * (1.0 - pi_test) + numerator\n    \n    if denominator == 0.0:\n        # This case is unlikely given the problem constraints but handled for robustness.\n        # It would happen if s=1 and pi_test=0, or s=0 and pi_train=0 etc.\n        # Here we return a posterior consistent with the odds. If test prior is 0, posterior is 0.\n        return 0.0 if pi_test == 0.0 else 1.0\n        \n    return numerator / denominator\n\n\ndef solve_case(pi_train, pi_test, val_set, test_set):\n    \"\"\"\n    Computes naive, adjusted, and test accuracies, and the final improvement metric.\n    \"\"\"\n    decision_threshold = 0.5\n\n    # 1. Naive Holdout Accuracy (unweighted, unadjusted validation)\n    naive_correct_count = 0\n    for y_i, s_i in val_set:\n        prediction = 1 if s_i >= decision_threshold else 0\n        if prediction == y_i:\n            naive_correct_count += 1\n    naive_acc = naive_correct_count / len(val_set) if len(val_set) > 0 else 0\n\n    # 2. True Test Accuracy (unweighted, adjusted test)\n    test_correct_count = 0\n    for y_j, s_j in test_set:\n        s_j_prime = adjust_score(s_j, pi_train, pi_test)\n        prediction_prime = 1 if s_j_prime >= decision_threshold else 0\n        if prediction_prime == y_j:\n            test_correct_count += 1\n    test_acc = test_correct_count / len(test_set) if len(test_set) > 0 else 0\n\n    # 3. Adjusted Holdout Accuracy (weighted, adjusted validation)\n    w1 = pi_test / pi_train if pi_train > 0 else 0\n    w0 = (1.0 - pi_test) / (1.0 - pi_train) if (1.0-pi_train) > 0 else 0\n    \n    total_weighted_correct = 0.0\n    total_weight = 0.0\n    for y_i, s_i in val_set:\n        s_i_prime = adjust_score(s_i, pi_train, pi_test)\n        prediction_prime = 1 if s_i_prime >= decision_threshold else 0\n        \n        weight = w1 if y_i == 1 else w0\n        \n        if prediction_prime == y_i:\n            total_weighted_correct += weight\n        \n        total_weight += weight\n        \n    adj_acc = total_weighted_correct / total_weight if total_weight > 0 else 0\n\n    # 4. Errors and Improvement\n    naive_abs_error = abs(naive_acc - test_acc)\n    adj_abs_error = abs(adj_acc - test_acc)\n    improvement = naive_abs_error - adj_abs_error\n    \n    return improvement\n\n# Execute the main function.\nsolve()\n```", "id": "3200853"}]}