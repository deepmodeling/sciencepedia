{"hands_on_practices": [{"introduction": "在信任任何模拟得出的科学结论之前，我们必须首先验证其底层的数值方法是否被正确实现。这个练习介绍“精度阶验证”，这是一项用于代码验证的基本技术。通过这项实践，你将学习如何通过计算数值解与精确解之间的误差，并观察误差如何随着网格加密而减小，从而凭经验确认代码的行为符合理论预期。[@problem_id:3097495]", "problem": "给定一个在区间 $[0,2\\pi]$ 上定义的周期性标量场 $u(x)$，其中 $u(x)=\\sin(x)$，角度以弧度为单位。考虑使用三种有限差分模板（前向差分、二阶中心差分和四阶中心差分）在均匀周期性网格上近似空间导数 $u'(x)$ 的数值模拟。您的任务是分析多种网格分辨率下的模拟输出，通过计算输出误差的离散 $L^2$ 和 $L^\\infty$ 范数，并在对数-对数尺度上拟合斜率，以验证观测到的精度阶。\n\n使用的基本和核心定义：\n- 均匀网格有 $N$ 个点，间距为 $h=\\frac{2\\pi}{N}$，网格点为 $x_i = i h$，其中 $i=0,1,\\dots,N-1$，并采用周期性边界条件。\n- 精确导数为 $u'(x)=\\cos(x)$。\n- 导数的前向差分模板为 $D_f u_i = \\frac{u_{i+1}-u_i}{h}$，采用周期性环绕，即 $u_{N}\\equiv u_0$。\n- 导数的二阶中心差分模板为 $D_c u_i = \\frac{u_{i+1}-u_{i-1}}{2h}$，采用周期性环绕。\n- 导数的四阶中心差分模板为 $D_4 u_i = \\frac{-u_{i+2}+8u_{i+1}-8u_{i-1}+u_{i-2}}{12h}$，采用周期性环绕。\n- 周期性网格上的离散 $L^2$ 误差范数定义为 $\\lVert e \\rVert_{2,h} = \\sqrt{h \\sum_{i=0}^{N-1} e_i^2}$，对于均匀的 $h$，这能一致地逼近在 $[0,2\\pi]$ 上的连续 $L^2$ 范数。\n- 离散 $L^\\infty$ 误差范数定义为 $\\lVert e \\rVert_{\\infty} = \\max_{0 \\le i \\le N-1} |e_i|$。\n- 如果一个 $p$ 阶方法的误差缩放满足 $E(h) \\approx C h^p$（其中 $C$ 为某个常数），则取自然对数后得到 $\\ln(E(h)) \\approx \\ln(C) + p \\ln(h)$。因此，通过最小二乘法对点集 $\\left(\\ln(h), \\ln(E(h))\\right)$ 拟合一条直线，得到的斜率即为观测到的阶数 $p$。\n\n您的程序必须实现上述三种模板，为周期性网格上的 $u(x)=\\sin(x)$ 生成模拟输出（数值导数），为每个网格计算误差数组 $e_i = D u_i - \\cos(x_i)$，为每个网格分辨率评估 $\\lVert e \\rVert_{2,h}$ 和 $\\lVert e \\rVert_{\\infty}$，然后通过拟合 $\\ln(E)$ 对 $\\ln(h)$ 的斜率来估计阶数 $p$（对两种范数分别进行）。\n\n测试套件：\n- 测试用例 1（理想情况，一阶方法）：前向差分，网格尺寸为 $\\{32,64,128,256\\}$。\n- 测试用例 2（理想情况，二阶方法）：二阶中心差分，网格尺寸为 $\\{16,32,64,128\\}$。\n- 测试用例 3（高阶方法）：四阶中心差分，网格尺寸为 $\\{8,16,32,64,128\\}$。\n- 测试用例 4（用于稳定性分析的细网格覆盖）：二阶中心差分，网格尺寸为 $\\{128,256,512,1024,2048,4096\\}$。\n\n对于每个测试用例，计算两个浮点数：从 $L^2$ 范数得到的估计斜率 $p_{L^2}$ 和从 $L^\\infty$ 范数得到的估计斜率 $p_{L^\\infty}$，两者都通过对给定网格尺寸下的 $\\ln(E)$ 对 $\\ln(h)$ 进行最小二乘拟合获得。角度必须按弧度处理。无需进行物理单位转换。\n\n最终输出格式：\n- 您的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表。每个测试用例的结果必须是一个包含两个浮点数 $[p_{L^2},p_{L^\\infty}]$ 的列表，每个浮点数四舍五入到三位小数。例如，输出应类似于 $[[p_{11},p_{12}],[p_{21},p_{22}],\\dots]$，逗号之间没有空格。\n\n每个测试用例的答案是一个包含两个浮点数的列表。整个程序必须是一个完整的、可运行的程序，能够生成上述单行输出，且无需任何用户输入。", "solution": "该问题要求我们通过经验验证三种用于近似周期函数一阶导数的有限差分模板的精度阶。这是计算科学中验证模拟代码的一个基本流程。该分析涉及在不同分辨率的网格上计算数值导数，计算与精确解的误差，并确定随着网格间距 $h$ 减小，误差的收敛率。\n\n该方法包括四个主要步骤：网格离散化、应用数值模板、误差计算以及通过对数-对数尺度上的线性回归估计精度阶。\n\n**1. 定义域和函数的离散化**\n问题设置在一维周期性定义域 $[0, 2\\pi]$ 上。此定义域被离散化为一个包含 $N$ 个点的均匀网格，索引从 $i=0$ 到 $i=N-1$。网格点位于 $x_i = i h$，其中网格间距（或分辨率）为 $h = \\frac{2\\pi}{N}$。\n给定的标量场是 $u(x) = \\sin(x)$，在每个网格点上进行求值，形成一个离散的函数值向量 $u_i = u(x_i) = \\sin(i h)$。作为我们误差分析基准的解析导数是 $u'(x) = \\cos(x)$，给出精确的离散值 $u'_i = u'(x_i) = \\cos(i h)$。\n\n**2. 一阶导数的有限差分模板**\n我们使用网格上的离散值 $u_i$ 来近似导数 $u'(x_i)$。问题指定了三种模板。通过确保网格索引以环绕方式处理（即，索引 $j$ 被视为 $j \\pmod N$）来强制执行周期性。\n\n- **前向差分 ($D_f$)**：一种单侧、一阶精度的模板。\n$$ D_f u_i = \\frac{u_{i+1} - u_i}{h} $$\n该方法的截断误差主项与 $h$ 成正比，因此其预期精度阶为 $p=1$。\n\n- **二阶中心差分 ($D_c$)**：一种对称、二阶精度的模板。\n$$ D_c u_i = \\frac{u_{i+1} - u_{i-1}}{2h} $$\n其截断误差与 $h^2$ 成正比，因此其预期精度阶为 $p=2$。\n\n- **四阶中心差分 ($D_4$)**：一种更宽的对称、四阶精度的模板。\n$$ D_4 u_i = \\frac{-u_{i+2} + 8u_{i+1} - 8u_{i-1} + u_{i-2}}{12h} $$\n其截断误差与 $h^4$ 成正比，因此其预期精度阶为 $p=4$。\n\n对于每种模板，都为所有点 $i=0, \\dots, N-1$ 计算一个数值导数值向量 $(D u)_i$。\n\n**3. 误差计算和范数**\n数值近似的误差由误差向量 $e$ 捕捉，其中每个分量是数值导数与精确导数之间的逐点差异：\n$$ e_i = (D u)_i - u'(x_i) $$\n为了量化该误差向量的总体大小，我们为每个网格分辨率 $N$ 计算两种不同的范数。\n\n- **离散 $L^2$ 范数 ($\\lVert e \\rVert_{2,h}$)**：此范数是连续 $L^2$ 范数的离散模拟，用于测量整个网格上的均方根误差。其定义为：\n$$ \\lVert e \\rVert_{2,h} = \\sqrt{h \\sum_{i=0}^{N-1} e_i^2} $$\n因子 $\\sqrt{h}$ 确保这个离散范数是连续积分范数 $\\left(\\int_0^{2\\pi} e(x)^2 dx\\right)^{1/2}$ 的一个一致逼近。\n\n- **$L^\\infty$ 范数 ($\\lVert e \\rVert_{\\infty}$)**：也称为最大范数，它测量网格上最坏情况的逐点误差：\n$$ \\lVert e \\rVert_{\\infty} = \\max_{0 \\le i  N} |e_i| $$\n\n**4. 精度阶验证**\n如果一个数值方法的误差 $E$ 与网格间距 $h$ 之间的关系满足 $E(h) \\approx C h^p$（当 $h \\to 0$ 时，C 为某个常数），则该方法具有 $p$ 阶精度。为了从模拟数据中确定 $p$，我们在一系列网格间距 $h_j$ 逐渐减小的模拟中，计算误差 $E$（同时使用 $L^2$ 和 $L^\\infty$ 范数）。\n\n通过对该缩放关系取自然对数，我们得到一个线性方程：\n$$ \\ln(E(h)) \\approx \\ln(C) + p \\ln(h) $$\n这表明 $\\ln(E)$ 对 $\\ln(h)$ 的图像将近似为一条斜率为 $p$ 的直线。因此，我们可以通过对从模拟中生成的数据点集 $(\\ln(h_j), \\ln(E_j))$ 进行线性最小二乘拟合来估计观测到的精度阶。所得最佳拟合线的斜率即为 $p$ 的经验值。\n\n指定的测试用例提供了不同的模板和网格尺寸 $\\{N\\}$ 集合，使我们能够执行此分析，并将观测到的阶数与每种方法的理论预期进行比较。例如，对于测试用例 1（前向差分），我们期望两种范数的斜率都接近 $1$。对于测试用例 3（四阶中心差分），我们期望斜率接近 $4$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the observed order of accuracy for three finite-difference stencils\n    by analyzing simulation error norms on a log-log scale.\n    \"\"\"\n\n    # Define the finite-difference stencil functions\n    def forward_diff(u, h):\n        \"\"\"Computes the derivative using a first-order forward-difference stencil.\"\"\"\n        return (np.roll(u, -1) - u) / h\n\n    def central_diff2(u, h):\n        \"\"\"Computes the derivative using a second-order central-difference stencil.\"\"\"\n        return (np.roll(u, -1) - np.roll(u, 1)) / (2 * h)\n\n    def central_diff4(u, h):\n        \"\"\"Computes the derivative using a fourth-order central-difference stencil.\"\"\"\n        return (-np.roll(u, -2) + 8 * np.roll(u, -1) - 8 * np.roll(u, 1) + np.roll(u, 2)) / (12 * h)\n\n    # Define the test cases as a list of tuples: (stencil_function, list_of_N_values)\n    test_cases = [\n        (forward_diff, [32, 64, 128, 256]),\n        (central_diff2, [16, 32, 64, 128]),\n        (central_diff4, [8, 16, 32, 64, 128]),\n        (central_diff2, [128, 256, 512, 1024, 2048, 4096])\n    ]\n\n    all_results = []\n\n    # Process each test case\n    for stencil_func, N_values in test_cases:\n        h_vals = []\n        l2_errors = []\n        linf_errors = []\n\n        # Run simulation for each grid size N\n        for N in N_values:\n            h = 2 * np.pi / N\n            h_vals.append(h)\n            \n            # Create the grid and evaluate the function and its exact derivative\n            x = np.linspace(0, 2 * np.pi, N, endpoint=False)\n            u = np.sin(x)\n            u_prime_exact = np.cos(x)\n            \n            # Compute the numerical derivative using the specified stencil\n            u_prime_numerical = stencil_func(u, h)\n            \n            # Compute the error vector\n            error_vec = u_prime_numerical - u_prime_exact\n            \n            # Compute and store the L2 and L-infinity error norms\n            l2_error = np.sqrt(h * np.sum(error_vec**2))\n            l2_errors.append(l2_error)\n            \n            linf_error = np.max(np.abs(error_vec))\n            linf_errors.append(linf_error)\n\n        # Convert lists to numpy arrays for vectorized operations\n        h_vals_np = np.array(h_vals)\n        l2_errors_np = np.array(l2_errors)\n        linf_errors_np = np.array(linf_errors)\n\n        # Take the natural log of h and the error norms\n        log_h = np.log(h_vals_np)\n        log_l2_err = np.log(l2_errors_np)\n        log_linf_err = np.log(linf_errors_np)\n\n        # Perform linear regression to find the slope (order of accuracy, p)\n        # np.polyfit(x, y, 1) returns [slope, intercept]\n        p_l2 = np.polyfit(log_h, log_l2_err, 1)[0]\n        p_linf = np.polyfit(log_h, log_linf_err, 1)[0]\n        \n        all_results.append([p_l2, p_linf])\n        \n    # Format the final output string exactly as required\n    formatted_results = []\n    for p_l2, p_linf in all_results:\n        formatted_results.append(f\"[{p_l2:.3f},{p_linf:.3f}]\")\n\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3097495"}, {"introduction": "许多科学模型包含内在的随机性，这导致即使在参数固定的情况下，每次运行也可能产生不同的结果。本练习提供了一个系统的统计框架来量化这种运行间的可变性。你将学习如何应用大数定律和中心极限定理中的概念，以确保从随机模拟中得出的统计结论是稳定且可复现的。[@problem_id:3097442]", "problem": "您正在分析一个随机模拟的输出。对于固定的参数化，该模拟会产生标量观测值，其分布可被假定为独立同分布。为了量化不同随机种子下各次运行间的可变性，并测试关键输出指标的再现性阈值，请实现以下基于大数定律和中心极限定理 (CLT) 的程序。\n\n基本定义：\n- 对于有限集合 $S$ 中的每个随机种子 $s$，模拟会从真实均值为 $\\mu$、真实标准差为 $\\sigma$ 的正态分布中抽取 $K$ 个独立的标量观测值 $x_{s,1}, x_{s,2}, \\dots, x_{s,K}$。用数学符号表示为，$x_{s,i} \\sim \\mathcal{N}(\\mu, \\sigma^2)$，并且对于固定的 $s$，$\\{x_{s,i}\\}_{i=1}^K$ 是独立的。\n- 对每个种子 $s$，将种子级别的样本均值和方差定义为\n  $$ m_s = \\frac{1}{K} \\sum_{i=1}^{K} x_{s,i}, \\quad v_s = \\frac{1}{K-1} \\sum_{i=1}^{K} \\left(x_{s,i} - m_s\\right)^2, \\quad s_s = \\sqrt{v_s}. $$\n- 跨种子定义种子均值的总均值和种子均值的跨种子标准差如下：\n  $$ \\bar{m} = \\frac{1}{|S|} \\sum_{s \\in S} m_s, \\quad sd_m = \\sqrt{\\frac{1}{|S| - 1} \\sum_{s \\in S} \\left(m_s - \\bar{m}\\right)^2}. $$\n- 跨种子定义种子标准差的总均值和种子标准差的跨种子标准差如下：\n  $$ \\bar{s} = \\frac{1}{|S|} \\sum_{s \\in S} s_s, \\quad sd_{sd} = \\sqrt{\\frac{1}{|S| - 1} \\sum_{s \\in S} \\left(s_s - \\bar{s}\\right)^2}. $$\n- 将种子均值的相对跨种子可变性定义为：\n  $$ rv_m = \\begin{cases}\n  \\dfrac{sd_m}{|\\bar{m}|},   \\text{if } |\\bar{m}| \\ge \\varepsilon, \\\\\n  \\dfrac{sd_m}{\\bar{s}},   \\text{if } |\\bar{m}|  \\varepsilon,\n  \\end{cases} $$\n  其中 $\\varepsilon  0$ 是一个指定的小阈值。\n- 将种子标准差的相对跨种子可变性定义为：\n  $$ rv_{sd} = \\frac{sd_{sd}}{\\bar{s}}. $$\n- 将均值和标准差的成对一致性分数分别定义为：\n  $$ f_m = \\frac{1}{\\binom{|S|}{2}} \\left|\\left\\{ \\{s,t\\} \\subset S, s \\ne t : |m_s - m_t| \\le \\Delta_m \\right\\}\\right|, $$\n  $$ f_{sd} = \\frac{1}{\\binom{|S|}{2}} \\left|\\left\\{ \\{s,t\\} \\subset S, s \\ne t : |s_s - s_t| \\le \\Delta_{sd} \\right\\}\\right|. $$\n- 根据中心极限定理 (CLT)，种子级别的样本均值 $m_s$ 近似服从正态分布，其标准误为 $s_s / \\sqrt{K}$。对每个种子 $s$ 使用由下式定义的双边名义 $95\\%$ 置信区间：\n  $$ CI_s = \\left[m_s - z \\cdot \\frac{s_s}{\\sqrt{K}},\\; m_s + z \\cdot \\frac{s_s}{\\sqrt{K}}\\right], $$\n  其中 $z$ 是标准正态分布的第 $97.5$ 百分位数，即 $z \\approx 1.959963984540054$。定义覆盖率分数\n  $$ c = \\frac{1}{|S|} \\left|\\left\\{ s \\in S : \\bar{m} \\in CI_s \\right\\}\\right|. $$\n\n再现性决策规则：\n- 当且仅当 $rv_m \\le \\tau_m$ 且 $f_m \\ge p_m$ 时，均值指标被声明为可再现。\n- 当且仅当 $rv_{sd} \\le \\tau_{sd}$ 且 $f_{sd} \\ge p_{sd}$ 时，可变性指标（每个种子内观测值的标准差）被声明为可再现。\n- 当且仅当 $c \\ge q$ 时，CLT 覆盖率测试通过。\n\n实现要求：\n- 对于每个测试用例，您必须使用由给定的 $s \\in S$ 作为种子的伪随机数生成器，严格按照 $x_{s,i} \\sim \\mathcal{N}(\\mu, \\sigma^2)$ 生成种子级别的观测值，以确保确定性行为。\n- 使用上述公式计算 $m_s, s_s, \\bar{m}, sd_m, \\bar{s}, sd_{sd}, rv_m, rv_{sd}, f_m, f_{sd}$ 和 $c$，然后评估决策规则。\n- 每个测试用例的最终答案必须是一个包含三个整数的列表 $[M, D, C]$，其中如果均值指标可再现，则 $M$ 为 $1$，否则为 $0$；如果可变性指标可再现，则 $D$ 为 $1$，否则为 $0$；如果 CLT 覆盖率测试通过，则 $C$ 为 $1$，否则为 $0$。\n\n测试套件：\n- 测试用例 A (正常路径)：\n  - 参数：$\\mu = 5.0$, $\\sigma = 2.0$, $K = 1000$, $S = \\{0, 1, 2, \\dots, 19\\}$, $\\varepsilon = 10^{-8}$。\n  - 阈值：$\\tau_m = 0.03$, $\\Delta_m = 0.15$, $p_m = 0.9$, $\\tau_{sd} = 0.05$, $\\Delta_{sd} = 0.12$, $p_{sd} = 0.9$, $q = 0.9$。\n- 测试用例 B (小样本，严格阈值)：\n  - 参数：$\\mu = 5.0$, $\\sigma = 2.0$, $K = 30$, $S = \\{0, 1, 2, \\dots, 9\\}$, $\\varepsilon = 10^{-8}$。\n  - 阈值：$\\tau_m = 0.03$, $\\Delta_m = 0.25$, $p_m = 0.9$, $\\tau_{sd} = 0.05$, $\\Delta_{sd} = 0.20$, $p_{sd} = 0.9$, $q = 1.0$。\n- 测试用例 C (均值接近零，必要时启用备用归一化)：\n  - 参数：$\\mu = 0.0$, $\\sigma = 1.0$, $K = 500$, $S = \\{100, 101, 102, \\dots, 114\\}$, $\\varepsilon = 10^{-8}$。\n  - 阈值：$\\tau_m = 0.06$, $\\Delta_m = 0.10$, $p_m = 0.8$, $\\tau_{sd} = 0.06$, $\\Delta_{sd} = 0.10$, $p_{sd} = 0.8$, $q = 0.9$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含按 A、B、C 顺序排列的三个测试用例结果向量的列表，该列表为用方括号括起来的逗号分隔列表。每个测试用例向量本身也必须是用方括号括起来的逗号分隔列表。例如，您的输出必须如下所示：\n  - $[[M_A, D_A, C_A],[M_B, D_B, C_B],[M_C, D_C, C_C]]$,\n  其中每个符号是如上定义的整数 $0$ 或 $1$。", "solution": "该问题要求实现一个统计程序，用以评估一个随机模拟的输出在多次运行（每次运行由不同的随机种子初始化）间的再现性。评估基于三个标准：输出均值的再现性、输出标准差的再现性，以及由中心极限定理 (CLT) 预测的置信区间的一致性。解决方案涉及生成模拟数据、计算一系列统计指标，并应用一组预设的决策规则。\n\n每个测试用例的处理流程如下：\n\n1.  **数据生成**：对于给定的测试用例，其参数包括真实均值 $\\mu$、真实标准差 $\\sigma$、每次运行的观测次数 $K$ 以及一组随机种子 $S$，我们首先生成原始数据。对于每个种子 $s \\in S$，我们从正态分布 $\\mathcal{N}(\\mu, \\sigma^2)$ 中产生 $K$ 个独立同分布 (i.i.d.) 的观测值 $\\{x_{s,1}, x_{s,2}, \\dots, x_{s,K}\\}$。伪随机数生成器必须以 $s$ 为种子，以确保结果的确定性和可再现性。\n\n2.  **种子内统计**：对于与种子 $s$ 对应的每组观测值，我们计算样本均值 $m_s$ 和无偏样本标准差 $s_s$。公式如下：\n    $$ m_s = \\frac{1}{K} \\sum_{i=1}^{K} x_{s,i} $$\n    $$ s_s = \\sqrt{\\frac{1}{K-1} \\sum_{i=1}^{K} \\left(x_{s,i} - m_s\\right)^2} $$\n    此步骤为均值生成 $|S|$ 个值 $\\{m_s\\}_{s \\in S}$，为标准差生成 $|S|$ 个值 $\\{s_s\\}_{s \\in S}$。\n\n3.  **跨种子聚合统计**：使用种子级别的均值和标准差集合，我们计算四个聚合统计量。\n    - 种子均值的总均值 $\\bar{m}$：\n      $$ \\bar{m} = \\frac{1}{|S|} \\sum_{s \\in S} m_s $$\n    - 种子均值的跨种子样本标准差 $sd_m$：\n      $$ sd_m = \\sqrt{\\frac{1}{|S| - 1} \\sum_{s \\in S} \\left(m_s - \\bar{m}\\right)^2} $$\n    - 种子标准差的总均值 $\\bar{s}$：\n      $$ \\bar{s} = \\frac{1}{|S|} \\sum_{s \\in S} s_s $$\n    - 种子标准差的跨种子样本标准差 $sd_{sd}$：\n      $$ sd_{sd} = \\sqrt{\\frac{1}{|S| - 1} \\sum_{s \\in S} \\left(s_s - \\bar{s}\\right)^2} $$\n    $sd_m$ 和 $sd_{sd}$ 分母中使用 $|S|-1$ 对应于对种子级别统计数据计算无偏样本标准差。\n\n4.  **相对可变性指标**：接着，我们量化种子级别统计数据的相对可变性。\n    - 均值的相对可变性 $rv_m$ 定义中带有一个条件归一化，以避免被接近零的均值除。给定一个小的阈值 $\\varepsilon  0$：\n      $$ rv_m = \\begin{cases}\n      \\dfrac{sd_m}{|\\bar{m}|},   \\text{if } |\\bar{m}| \\ge \\varepsilon \\\\\n      \\dfrac{sd_m}{\\bar{s}},   \\text{if } |\\bar{m}|  \\varepsilon\n      \\end{cases} $$\n    - 标准差的相对可变性 $rv_{sd}$ 通过均值标准差进行归一化：\n      $$ rv_{sd} = \\frac{sd_{sd}}{\\bar{s}} $$\n    在此我们可以假定 $\\bar{s}  0$，因为观测值是从 $\\sigma  0$ 的分布中抽取的。\n\n5.  **成对一致性分数**：为衡量不同运行对之间的一致性，我们计算统计量在给定容差内一致的配对所占的比例。\n    - 唯一种子对的总数为 $\\binom{|S|}{2}$。\n    - 均值的一致性分数 $f_m$ 是绝对差 $|m_s - m_t|$ 不超过容差 $\\Delta_m$ 的配对 $\\{s, t\\} \\subset S$ 所占的比例：\n      $$ f_m = \\frac{1}{\\binom{|S|}{2}} \\left|\\left\\{ \\{s,t\\} \\subset S, s \\ne t : |m_s - m_t| \\le \\Delta_m \\right\\}\\right| $$\n    - 类似地，标准差的一致性分数 $f_{sd}$ 使用容差 $\\Delta_{sd}$：\n      $$ f_{sd} = \\frac{1}{\\binom{|S|}{2}} \\left|\\left\\{ \\{s,t\\} \\subset S, s \\ne t : |s_s - s_t| \\le \\Delta_{sd} \\right\\}\\right| $$\n\n6.  **CLT 覆盖率分数**：中心极限定理表明，对于足够大的 $K$，样本均值 $m_s$ 近似服从正态分布。为每个种子 $s$ 构建真实均值的名义 $95\\%$ 置信区间 ($CI_s$)：\n    $$ CI_s = \\left[m_s - z \\cdot \\frac{s_s}{\\sqrt{K}},\\; m_s + z \\cdot \\frac{s_s}{\\sqrt{K}}\\right] $$\n    其中 $z \\approx 1.959963984540054$ 是标准正态分布的第 $97.5$ 百分位数。问题定义了一个覆盖率测试，该测试基于这些区间中有多少个包含了总均值 $\\bar{m}$。覆盖率分数 $c$ 为：\n    $$ c = \\frac{1}{|S|} \\left|\\left\\{ s \\in S : \\bar{m} \\in CI_s \\right\\}\\right| $$\n    这等价于对每个种子 $s$ 检查是否满足 $|\\bar{m} - m_s| \\le z \\cdot \\frac{s_s}{\\sqrt{K}}$。\n\n7.  **再现性决策规则**：最后，我们应用指定的决策规则来确定均值、标准差和 CLT 覆盖率的再现性状态。\n    - 如果 $rv_m \\le \\tau_m$ 且 $f_m \\ge p_m$，则均值是可再现的 ($M=1$) 。否则，$M=0$。\n    - 如果 $rv_{sd} \\le \\tau_{sd}$ 且 $f_{sd} \\ge p_{sd}$，则标准差是可再现的 ($D=1$) 。否则，$D=0$。\n    - 如果 $c \\ge q$，则 CLT 覆盖率测试通过 ($C=1$) 。否则，$C=0$。\n\n对每个测试用例执行这些步骤，并将所得的整数向量 $[M, D, C]$ 收集起来形成最终输出。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom itertools import combinations\n\ndef calculate_reproducibility(params, thresholds):\n    \"\"\"\n    Performs the full reproducibility analysis for a single test case.\n    \"\"\"\n    # Unpack parameters\n    mu, sigma, K, S, epsilon = params\n    \n    # Unpack thresholds\n    tau_m, delta_m, p_m = thresholds['mean']\n    tau_sd, delta_sd, p_sd = thresholds['std_dev']\n    q = thresholds['clt']\n    \n    num_seeds = len(S)\n\n    # Step 1  2: Data Generation and Within-Seed Statistics\n    m_s_list = np.zeros(num_seeds)\n    s_s_list = np.zeros(num_seeds)\n\n    for i, seed in enumerate(S):\n        rng = np.random.default_rng(seed)\n        observations = rng.normal(loc=mu, scale=sigma, size=K)\n        m_s_list[i] = np.mean(observations)\n        # ddof=1 for unbiased sample standard deviation\n        s_s_list[i] = np.std(observations, ddof=1)\n\n    # Step 3: Across-Seed Aggregate Statistics\n    m_bar = np.mean(m_s_list)\n    # ddof=1 as per formula for sd_m\n    sd_m = np.std(m_s_list, ddof=1) if num_seeds > 1 else 0.0\n\n    s_bar = np.mean(s_s_list)\n    # ddof=1 as per formula for sd_sd\n    sd_sd = np.std(s_s_list, ddof=1) if num_seeds > 1 else 0.0\n\n    # Step 4: Relative Variability Metrics\n    if np.abs(m_bar) >= epsilon:\n        rv_m = sd_m / np.abs(m_bar)\n    else:\n        # Fallback normalization\n        rv_m = sd_m / s_bar if s_bar > 0 else np.inf\n    \n    rv_sd = sd_sd / s_bar if s_bar > 0 else np.inf\n\n    # Step 5: Pairwise Agreement Fractions\n    num_pairs = num_seeds * (num_seeds - 1) / 2\n    if num_pairs > 0:\n        agreement_count_m = 0\n        agreement_count_sd = 0\n        \n        for i, j in combinations(range(num_seeds), 2):\n            if np.abs(m_s_list[i] - m_s_list[j]) = delta_m:\n                agreement_count_m += 1\n            if np.abs(s_s_list[i] - s_s_list[j]) = delta_sd:\n                agreement_count_sd += 1\n        \n        f_m = agreement_count_m / num_pairs\n        f_sd = agreement_count_sd / num_pairs\n    else:\n        f_m = 1.0 # Vacuously true for  2 seeds\n        f_sd = 1.0\n\n    # Step 6: CLT Coverage Fraction\n    z = 1.959963984540054\n    # Standard error of the mean for each seed\n    se_m = s_s_list / np.sqrt(K)\n    \n    # Check if m_bar is within the CI for each seed\n    # |m_bar - m_s| = z * se_m\n    is_covered = np.abs(m_bar - m_s_list) = (z * se_m)\n    coverage_count = np.sum(is_covered)\n    c = coverage_count / num_seeds if num_seeds > 0 else 0.0\n\n    # Step 7: Reproducibility Decision Rules\n    M = 1 if rv_m = tau_m and f_m >= p_m else 0\n    D = 1 if rv_sd = tau_sd and f_sd >= p_sd else 0\n    C = 1 if c >= q else 0\n\n    return [M, D, C]\n\ndef solve():\n    \"\"\"\n    Main function to define test cases, run the analysis, and print results.\n    \"\"\"\n    test_cases = [\n        {\n            \"name\": \"Test case A\",\n            \"params\": (5.0, 2.0, 1000, list(range(20)), 1e-8),\n            \"thresholds\": {\n                \"mean\": (0.03, 0.15, 0.9),    # tau_m, delta_m, p_m\n                \"std_dev\": (0.05, 0.12, 0.9), # tau_sd, delta_sd, p_sd\n                \"clt\": 0.9,                  # q\n            }\n        },\n        {\n            \"name\": \"Test case B\",\n            \"params\": (5.0, 2.0, 30, list(range(10)), 1e-8),\n            \"thresholds\": {\n                \"mean\": (0.03, 0.25, 0.9),\n                \"std_dev\": (0.05, 0.20, 0.9),\n                \"clt\": 1.0,\n            }\n        },\n        {\n            \"name\": \"Test case C\",\n            \"params\": (0.0, 1.0, 500, list(range(100, 115)), 1e-8),\n            \"thresholds\": {\n                \"mean\": (0.06, 0.10, 0.8),\n                \"std_dev\": (0.06, 0.10, 0.8),\n                \"clt\": 0.9\n            }\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        result_vector = calculate_reproducibility(case['params'], case['thresholds'])\n        all_results.append(result_vector)\n\n    # Format the final output string exactly as required.\n    inner_strings = [f\"[{','.join(map(str, res))}]\" for res in all_results]\n    final_output = f\"[{','.join(inner_strings)}]\"\n    \n    print(final_output)\n\nsolve()\n```", "id": "3097442"}, {"introduction": "现代科学模拟常常产生复杂的高维输出数据，从中提取有意义的洞见是一项挑战。本练习将引导你应用主成分分析（PCA）这一强大的降维技术。你将学习如何从零开始实施PCA，以识别输出数据中的主导变化模式，并进一步将这些模式与驱动其变化的输入参数关联起来。[@problem_id:3097441]", "problem": "您的任务是使用主成分分析（PCA）来分析重复模拟运行的多元输出。目标是识别输出空间中的主导模式，并解释输入参数如何驱动这些模式。您必须从变异和协方差的核心定义出发实现PCA，而不能调用任何黑盒PCA例程。\n\n您需要设计一个程序，为下述每个测试用例执行以下操作：\n\n1. 从线性模拟器生成数据。\n   - 对于给定的运行次数 $N$、输出数量 $M$ 和参数数量 $K$，从指定的零均值多元正态分布生成参数向量 $p_i \\in \\mathbb{R}^K$（对于 $i \\in \\{1,\\dots,N\\}$），其协方差矩阵为 $\\Sigma \\in \\mathbb{R}^{K \\times K}$。\n   - 令 $B \\in \\mathbb{R}^{M \\times K}$ 为一个固定的输出基矩阵，其列编码了潜在的输出模式。\n   - 对于每次运行 $i$，生成输出 $y_i \\in \\mathbb{R}^M$ 为 $y_i = B p_i + \\varepsilon_i$，其中 $\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2 I_M)$，$I_M$ 是 $M \\times M$ 单位矩阵，$\\sigma \\ge 0$ 是指定的噪声标准差。\n   - 将所有 $y_i^\\top$ 行堆叠成数据矩阵 $X \\in \\mathbb{R}^{N \\times M}$。\n\n2. 对输出进行PCA。\n   - 通过减去样本均值来中心化 $X$ 的每个输出（列），生成中心化矩阵 $X_c$。\n   - 基于 $X_c$ 计算输出空间中的样本协方差。根据协方差结构，使用与“主方向是最大化投影方差的正交方向”这一定义相符的分解方法，计算输出空间中的主方向及相关方差。\n   - 令 $X_c$ 的奇异值分解为 $X_c = U S V^\\top$，其中 $U \\in \\mathbb{R}^{N \\times r}$，$S \\in \\mathbb{R}^{r \\times r}$ 为对角矩阵，其非负元素为 $(s_1,\\dots,s_r)$，$V \\in \\mathbb{R}^{M \\times r}$，且 $r = \\min(N, M)$。输出空间中的第一个主方向是 $V$ 的第一列 $v_1$，第一个主成分得分是 $U S$ 的第一列。\n   - 第一个主成分的方差解释率为 $\\mathrm{EVR}_1 = \\frac{s_1^2}{\\sum_{j=1}^r s_j^2}$。\n\n3. 模式识别与参数解释。\n   - 计算第一个主方向 $v_1$ 与 $B$ 的各列之间的对齐分数（在 $[0,1]$ 区间内）。对于 $B$ 的每一列 $b_j$，定义 $\\hat{b}_j = b_j / \\lVert b_j \\rVert_2$。与 $b_j$ 的对齐度为 $|\\hat{b}_j^\\top v_1|$。报告在 $j \\in \\{0,\\dots,K-1\\}$ 上的最大对齐度。\n   - 计算第一个主成分得分（一个 $N$ 维向量）与每次运行的各参数序列（每个都是一个 $N$ 维向量）之间的绝对皮尔逊相关系数。报告具有最大绝对相关系数的参数索引 $j \\in \\{0,\\dots,K-1\\}$（若存在平局，则选择最小的索引）。\n\n4. 每个测试用例的数值输出。\n   - 为每个测试用例生成一个包含三个条目的列表：$[\\mathrm{EVR}_1, \\mathrm{Alignment}, \\mathrm{DominantIndex}]$。\n   - 将所有浮点输出（$\\mathrm{EVR}_1$ 和 $\\mathrm{Alignment}$）四舍五入到恰好 $6$ 位小数。主导索引是一个整数，无需四舍五入。\n\n5. 最终输出格式。\n   - 您的程序应生成单行输出，其中包含所有测试用例的结果，格式为由逗号分隔的各测试列表组成的列表，不含空格，并用方括号括起来。例如，两个测试用例的有效输出形式为 $[[0.912345,0.998765,0],[0.673210,0.812345,1]]$。\n\n您解决方案中需遵循的推导基本原理：\n- 多元数据的样本中心化和样本协方差。\n- 主成分的定义：最大化投影样本方差的正交方向，这些方向由样本协方差的特征向量给出，并可通过奇异值分解（SVD）计算。\n\n定义和约定：\n- 对于向量 $v$，$\\lVert v \\rVert_2 = \\sqrt{\\sum_i v_i^2}$。\n- 归一化算子为 $\\mathrm{normalize}(v) = v / \\lVert v \\rVert_2$，其中 $\\lVert v \\rVert_2 \\ne 0$。\n- 两个长度为 $N$ 的向量 $x$ 和 $y$ 之间的皮尔逊相关系数为 $\\frac{\\sum_{i=1}^N (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^N (x_i - \\bar{x})^2} \\sqrt{\\sum_{i=1}^N (y_i - \\bar{y})^2}}$。\n\n角度单位不适用。本问题中没有物理单位。所有答案必须是实数（前两个条目）和整数（第三个条目）。\n\n测试套件：\n- 所有用例的通用约定：\n  - 令 $\\mathrm{rng}$ 为使用给定种子初始化的 NumPy 默认随机数生成器。参数抽样为 $P \\sim \\mathcal{N}(0, \\Sigma)$，其中 $P \\in \\mathbb{R}^{N \\times K}$ 的行是独立的。令噪声 $E \\in \\mathbb{R}^{N \\times M}$ 的条目是独立的，服从 $\\mathcal{N}(0, \\sigma^2)$。构造 $X = P B^\\top + E$。\n  - 对下面的原始整数向量应用 $\\mathrm{normalize}$ 以构成 $B$ 的列。\n\n- 测试用例 1（顺利路径，单一主导模式）：\n  - $N = 200$, $M = 6$, $K = 3$, 种子 $= 12345$。\n  - $B$ 的列：\n    - $b_0 = \\mathrm{normalize}([2,1,0,0,0,0])$,\n    - $b_1 = \\mathrm{normalize}([0,1,2,0,0,0])$,\n    - $b_2 = \\mathrm{normalize}([0,0,0,1,-1,0])$.\n  - 协方差 $\\Sigma = \\mathrm{diag}([2.0, 0.7, 0.3])$。\n  - 噪声标准差 $\\sigma = 0.1$。\n\n- 测试用例 2（两个可比较的输出模式，参数相关）：\n  - $N = 150$, $M = 6$, $K = 3$, 种子 $= 2021$。\n  - $B$ 的列：\n    - $b_0 = \\mathrm{normalize}([1,1,0,0,0,0])$,\n    - $b_1 = \\mathrm{normalize}([-1,1,0,0,0,0])$,\n    - $b_2 = 0.5 \\times \\mathrm{normalize}([0,0,0,1,1,1])$。\n  - 协方差 $$ \\Sigma = \\begin{bmatrix} 1.5  0.9  0 \\\\ 0.9  1.5  0 \\\\ 0  0  0.1 \\end{bmatrix} $$。\n  - 噪声标准差 $\\sigma = 0.2$。\n\n- 测试用例 3（近乎无噪声，清晰的第一模式）：\n  - $N = 60$, $M = 5$, $K = 2$, 种子 $= 7$。\n  - $B$ 的列：\n    - $b_0 = \\mathrm{normalize}([1,2,0,0,0])$,\n    - $b_1 = \\mathrm{normalize}([0,0,1,1,0])$。\n  - 协方差 $\\Sigma = \\mathrm{diag}([3.0, 0.1])$。\n  - 噪声标准差 $\\sigma = 0.01$。\n\n您的程序必须为每个测试用例实现以下计算：\n- 从中心化数据矩阵的奇异值计算 $\\mathrm{EVR}_1$。\n- 计算最大对齐度 $ \\max_j |\\hat{b}_j^\\top v_1| $，其中 $\\hat{b}_j$ 是 $B$ 的归一化列，$v_1$ 是中心化数据矩阵的第一个右奇异向量。\n- 计算与第一个主成分得分具有最大绝对皮尔逊相关系数的参数索引，若存在平局，则选择最小的索引。\n\n最终输出格式：\n- 生成恰好一行，包含一个单一列表，每个测试用例对应一个三元组，按上述测试用例的顺序排列。\n- 每个三元组必须是 $[\\mathrm{EVR}_1,\\mathrm{Alignment},\\mathrm{DominantIndex}]$ 的形式，不含空格，浮点值四舍五入到恰好 $6$ 位小数。", "solution": "我们从变异、协方差和正交分解的基本定义出发。给定 $N$ 次运行和 $M$ 个输出，数据矩阵 $X \\in \\mathbb{R}^{N \\times M}$ 通过行堆叠输出向量 $y_i^\\top$ 形成。输出的样本均值向量为 $\\bar{x} \\in \\mathbb{R}^M$，其分量为 $\\bar{x}_j = \\frac{1}{N} \\sum_{i=1}^N X_{ij}$。中心化数据为 $X_c = X - \\mathbf{1} \\bar{x}^\\top$，其中 $\\mathbf{1} \\in \\mathbb{R}^N$ 是全为1的向量。输出空间中的样本协方差为 $S = \\frac{1}{N-1} X_c^\\top X_c \\in \\mathbb{R}^{M \\times M}$。\n\n根据主成分分析（PCA）的定义，主方向是输出空间中使投影数据的样本方差最大化的正交方向。这些方向由与降序特征值相关联的 $S$ 的特征向量给出。在数值上，这些特征向量可以通过对 $X_c$ 进行奇异值分解（SVD）等效地获得，$X_c = U S_V V^\\top$，其中 $S_V$ 是一个对角矩阵，其非负奇异值为 $(s_1, s_2, \\dots, s_r)$，$r = \\min(N, M)$。右奇异向量（$V$ 的列）是输出空间中的主方向，而左奇异向量乘以奇异值（$U S_V$）则得到主成分得分。由分量 $j$ 解释的方差为 $\\lambda_j = \\frac{s_j^2}{N-1}$，因此分量 $j$ 的方差解释率为\n$$\n\\mathrm{EVR}_j = \\frac{\\lambda_j}{\\sum_{k=1}^r \\lambda_k} = \\frac{s_j^2}{\\sum_{k=1}^r s_k^2}.\n$$\n这可以从样本协方差的定义和谱定理推导出来。\n\n为了根据模拟器已知的潜在输出模式（$B$ 的列）来解释第一个主方向，我们考虑第一个主方向 $v_1$ 与每个归一化的模拟器列 $\\hat{b}_j = b_j / \\lVert b_j \\rVert_2$ 之间夹角的余弦：\n$$\n\\text{alignment}_j = |\\hat{b}_j^\\top v_1| \\in [0,1].\n$$\n因为 $v_1$ 和 $\\hat{b}_j$ 都是单位向量，所以这个值等于它们之间夹角的余弦绝对值，其中 $1$ 表示完全对齐（或完全反对齐，但我们使用绝对值来消除特征向量固有的符号模糊性）。\n\n为了将第一个主成分与输入参数关联起来，令 $z \\in \\mathbb{R}^N$ 为第一个主成分得分的向量，即 $U S_V$ 的第一列。对于每个参数 $j \\in \\{0, \\dots, K-1\\}$，考虑由历次运行的参数向量的第 $j$ 个分量形成的序列 $p^{(j)} \\in \\mathbb{R}^N$。$z$ 和 $p^{(j)}$ 之间的皮尔逊相关系数为\n$$\nr_j = \\frac{\\sum_{i=1}^N (z_i - \\bar{z})(p^{(j)}_i - \\overline{p}^{(j)})}{\\sqrt{\\sum_{i=1}^N (z_i - \\bar{z})^2} \\sqrt{\\sum_{i=1}^N (p^{(j)}_i - \\overline{p}^{(j)})^2}},\n$$\n其中 $\\bar{z}$ 和 $\\overline{p}^{(j)}$ 表示样本均值。我们报告 $\\arg\\max_j |r_j|$ 作为主导参数索引，若存在平局则选择最小的索引。这种解释与以下概念相符：PCA得分捕捉了输出空间中方差最大的方向，而与这些得分线性关联最强的参数是最具影响力的驱动因素。\n\n每个测试用例的算法流程：\n1. 通过将提供的整数向量归一化为单位长度以获得列 $b_j$，并应用任何指定的标量乘数来构造 $B$。\n2. 使用指定的种子初始化一个随机数生成器。从指定的协方差为 $\\Sigma$ 的多元正态分布中抽取 $N$ 个独立的参数向量，形成 $P \\in \\mathbb{R}^{N \\times K}$。\n3. 从 $\\mathcal{N}(0, \\sigma^2)$ 中抽取具有独立条目的噪声 $E \\in \\mathbb{R}^{N \\times M}$。\n4. 构造 $X = P B^\\top + E$ 并中心化其列以获得 $X_c$。\n5. 计算 $X_c$ 的SVD为 $X_c = U S_V V^\\top$，其中 $V \\in \\mathbb{R}^{M \\times r}$，奇异值为 $(s_1, \\dots, s_r)$。\n6. 计算 $\\mathrm{EVR}_1 = s_1^2 / \\sum_{k=1}^r s_k^2$。\n7. 提取 $V$ 的第一列 $v_1$。计算 $\\mathrm{Alignment} = \\max_j |\\hat{b}_j^\\top v_1|$，其中 $\\hat{b}_j = b_j / \\lVert b_j \\rVert_2$ 是 $B$ 的每一列。\n8. 计算得分 $z$ 作为 $U S_V$ 的第一列（即 $z = U[:,0] \\cdot s_1$）。对于每个参数列 $P[:, j]$，计算 $z$ 和 $P[:, j]$ 之间的绝对皮尔逊相关系数。使用最小索引破平法确定 $\\mathrm{DominantIndex} = \\arg\\max_j |r_j|$。\n9. 将 $\\mathrm{EVR}_1$ 和 $\\mathrm{Alignment}$ 四舍五入到恰好 $6$ 位小数。将 $\\mathrm{DominantIndex}$ 保持为整数。\n10. 按规定将所有测试用例的结果输出为不含空格的单个三元组列表。\n\n正确性论证：\n- 中心化确保了协方差捕捉的是围绕均值的变异。\n- 基于SVD的计算可以得出输出空间中的主方向（$V$ 的列）和奇异值，根据SVD与样本协方差 $S$ 的特征分解之间的等价性，奇异值的平方与沿这些方向的样本方差成正比。\n- 对齐度量使用了余弦相似度，这是欧几里得空间中方向相似性的自然度量，并且它对于 $b_j$ 的缩放和 $v_1$ 的符号模糊性具有不变性。\n- 基于相关的解释反映了潜在驱动因素（得分）和参数之间的线性关联，这是在已知协变量的情况下解释PCA的标准方法。\n\n该实现遵循上述定义，并为三个指定的测试用例计算了所要求的量。最终输出按要求汇总结果，浮点值四舍五入到六位小数，并采用不含空格的精确格式。", "answer": "```python\nimport numpy as np\n\ndef normalize(v):\n    v = np.asarray(v, dtype=float)\n    n = np.linalg.norm(v)\n    if n == 0.0:\n        return v.copy()\n    return v / n\n\ndef build_B(columns, scales=None):\n    \"\"\"\n    columns: list of 1D arrays/lists to be normalized\n    scales: optional list of scalars to multiply each normalized column\n    \"\"\"\n    cols = []\n    for i, c in enumerate(columns):\n        vc = normalize(np.array(c, dtype=float))\n        if scales is not None:\n            vc = vc * float(scales[i])\n        cols.append(vc)\n    return np.column_stack(cols)\n\ndef generate_data(N, M, K, B, Sigma, sigma_noise, seed):\n    rng = np.random.default_rng(seed)\n    # Parameters: N x K from multivariate normal\n    P = rng.multivariate_normal(mean=np.zeros(K), cov=Sigma, size=N)\n    # Noise: N x M\n    E = rng.normal(loc=0.0, scale=sigma_noise, size=(N, M))\n    # Outputs: X = P @ B.T + E\n    X = P @ B.T + E\n    return X, P\n\ndef center_columns(X):\n    mean = X.mean(axis=0, keepdims=True)\n    return X - mean, mean.ravel()\n\ndef pca_first_component(Xc):\n    # SVD of centered data matrix\n    U, S, VT = np.linalg.svd(Xc, full_matrices=False)\n    # First right singular vector (principal direction in output space)\n    v1 = VT.T[:, 0]\n    # Explained variance ratio of first component\n    S2 = S**2\n    evr1 = float(S2[0] / S2.sum()) if S2.sum() > 0 else 0.0\n    # First principal component scores: first column of U*S\n    scores1 = U[:, 0] * S[0] if S.size > 0 else np.zeros(Xc.shape[0])\n    return v1, evr1, scores1\n\ndef max_alignment_with_B(v1, B):\n    # Normalize columns of B\n    norms = np.linalg.norm(B, axis=0)\n    # Avoid division by zero\n    norms[norms == 0.0] = 1.0\n    Bn = B / norms\n    # v1 should already be unit norm from SVD, but ensure stability\n    v1n = v1 / (np.linalg.norm(v1) if np.linalg.norm(v1) > 0 else 1.0)\n    dots = np.abs(Bn.T @ v1n)\n    return float(dots.max())\n\ndef pearson_abs_correlations(z, P):\n    # z: N-vector of scores\n    # P: N x K matrix of parameters\n    zc = z - z.mean()\n    z_norm = np.linalg.norm(zc)\n    K = P.shape[1]\n    abs_rs = np.zeros(K, dtype=float)\n    for j in range(K):\n        pj = P[:, j]\n        pjc = pj - pj.mean()\n        pj_norm = np.linalg.norm(pjc)\n        if z_norm == 0.0 or pj_norm == 0.0:\n            r = 0.0\n        else:\n            r = float((zc @ pjc) / (z_norm * pj_norm))\n        abs_rs[j] = abs(r)\n    return abs_rs\n\ndef format_results_no_spaces(results):\n    # results: list of [float, float, int]\n    parts = []\n    for triple in results:\n        f1, f2, idx = triple\n        # Ensure proper formatting for floats and ints\n        if isinstance(f1, (np.floating,)):\n            f1 = float(f1)\n        if isinstance(f2, (np.floating,)):\n            f2 = float(f2)\n        s = f\"[{format(f1, '.6f')},{format(f2, '.6f')},{int(idx)}]\"\n        parts.append(s)\n    return \"[\" + \",\".join(parts) + \"]\"\n\ndef solve():\n    test_cases = []\n\n    # Test case 1\n    # N=200, M=6, K=3, seed=12345\n    N1, M1, K1, seed1 = 200, 6, 3, 12345\n    cols1 = [\n        [2, 1, 0, 0, 0, 0],\n        [0, 1, 2, 0, 0, 0],\n        [0, 0, 0, 1, -1, 0],\n    ]\n    B1 = build_B(cols1)  # unit-norm columns\n    Sigma1 = np.diag([2.0, 0.7, 0.3])\n    sigma_noise1 = 0.1\n    test_cases.append((N1, M1, K1, B1, Sigma1, sigma_noise1, seed1))\n\n    # Test case 2\n    # N=150, M=6, K=3, seed=2021\n    N2, M2, K2, seed2 = 150, 6, 3, 2021\n    cols2 = [\n        [1, 1, 0, 0, 0, 0],\n        [-1, 1, 0, 0, 0, 0],\n        [0, 0, 0, 1, 1, 1],\n    ]\n    scales2 = [1.0, 1.0, 0.5]\n    B2 = build_B(cols2, scales=scales2)\n    Sigma2 = np.array([[1.5, 0.9, 0.0],\n                       [0.9, 1.5, 0.0],\n                       [0.0, 0.0, 0.1]])\n    sigma_noise2 = 0.2\n    test_cases.append((N2, M2, K2, B2, Sigma2, sigma_noise2, seed2))\n\n    # Test case 3\n    # N=60, M=5, K=2, seed=7\n    N3, M3, K3, seed3 = 60, 5, 2, 7\n    cols3 = [\n        [1, 2, 0, 0, 0],\n        [0, 0, 1, 1, 0],\n    ]\n    B3 = build_B(cols3)\n    Sigma3 = np.diag([3.0, 0.1])\n    sigma_noise3 = 0.01\n    test_cases.append((N3, M3, K3, B3, Sigma3, sigma_noise3, seed3))\n\n    results = []\n    for (N, M, K, B, Sigma, sigma_noise, seed) in test_cases:\n        X, P = generate_data(N, M, K, B, Sigma, sigma_noise, seed)\n        Xc, _ = center_columns(X)\n        v1, evr1, scores1 = pca_first_component(Xc)\n        alignment = max_alignment_with_B(v1, B)\n        abs_rs = pearson_abs_correlations(scores1, P)\n        dominant_idx = int(np.argmax(abs_rs))\n        # Round floats to 6 decimals for final output\n        results.append([round(evr1, 6), round(alignment, 6), dominant_idx])\n\n    print(format_results_no_spaces(results))\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3097441"}]}