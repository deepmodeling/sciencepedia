{"hands_on_practices": [{"introduction": "为了开启我们的动手实践之旅，我们首先来解决分层抽样的理论核心：最优分配。这项练习将指导您推导出在不同层之间分配固定数量样本的规则，以获得尽可能精确的估计。通过理解如何通过分配来最小化方差，您将为设计任何有效的分层抽样研究打下坚实的基础。", "problem": "考虑一个计算实验，旨在估计一个二元属性的直方图。该直方图基于将定义域划分为 $3$ 个由 $k \\in \\{1,2,3\\}$ 索引的不相交的箱（bin）。在第 $k$ 个箱中，每个抽样项产生一个独立的伯努利结果，其成功概率为 $p_{k} \\in (0,1)$，并且每个样本的成本在所有箱中都相同。您计划在第 $k$ 个箱中收集 $n_{k}$ 个样本，总样本量受限于 $\\sum_{k=1}^{3} n_{k} = N$，其中 $N$ 是一个固定的正整数。对于每个箱 $k$，您通过在该箱中收集的伯努利结果的样本均值 $\\hat{p}_{k}$ 来估计该箱的成功概率 $p_{k}$。您的目标是选择分配方案 $(n_{1}, n_{2}, n_{3})$，以最小化所有箱上估计量 $\\hat{p}_{k}$ 的均方误差 (MSE) 之和。\n\n从伯努利抽样的基本性质和均方误差 (MSE) 的定义出发，推导出在约束条件 $\\sum_{k=1}^{3} n_{k} = N$ 下最小化总 MSE 的分配方案。然后，用 $N$、$p_{1}$、$p_{2}$ 和 $p_{3}$ 表示第 $2$ 个箱的最优分配，即 $n_{2}$ 的闭式表达式。请以精确形式给出 $n_{2}$ 的最终表达式。无需进行四舍五入。", "solution": "问题是在 $3$ 个由索引 $k \\in \\{1, 2, 3\\}$ 表示的不相交的箱中，找到总样本量 $N$ 的最优分配，以最小化对各箱成功概率 $p_k$ 的估计量的总均方误差 (MSE)。这个问题是适定的，并且在科学上基于统计学和优化的原理。我们将进行完整的推导。\n\n首先，我们来定义第 $k$ 个箱中成功概率 $p_k$ 的估计量。我们收集 $n_k$ 个样本，其中每个样本都是一次独立的伯努利试验。令 $X_{k,i}$（$i=1, \\dots, n_k$）为第 $k$ 个箱中第 $i$ 次试验结果的随机变量，其中 $X_{k,i}=1$ 表示成功，$X_{k,i}=0$ 表示失败。成功的概率为 $P(X_{k,i}=1) = p_k$。$p_k$ 的估计量，记作 $\\hat{p}_k$，是样本均值：\n$$\n\\hat{p}_k = \\frac{1}{n_k} \\sum_{i=1}^{n_k} X_{k,i}\n$$\n目标是最小化这些估计量各自的均方误差之和。一个参数 $\\theta$ 的估计量 $\\hat{\\theta}$ 的 MSE 定义为 $\\text{MSE}(\\hat{\\theta}) = E[(\\hat{\\theta} - \\theta)^2]$。MSE 也可以表示为估计量的方差和偏差平方之和：$\\text{MSE}(\\hat{\\theta}) = \\text{Var}(\\hat{\\theta}) + (\\text{Bias}(\\hat{\\theta}))^2$。\n\n让我们首先确定 $\\hat{p}_k$ 的 MSE。我们先计算其期望值来求得偏差。\n$$\nE[\\hat{p}_k] = E\\left[\\frac{1}{n_k} \\sum_{i=1}^{n_k} X_{k,i}\\right] = \\frac{1}{n_k} \\sum_{i=1}^{n_k} E[X_{k,i}]\n$$\n由于每个 $X_{k,i}$ 是参数为 $p_k$ 的伯努利随机变量，其期望值为 $E[X_{k,i}] = p_k$。\n$$\nE[\\hat{p}_k] = \\frac{1}{n_k} \\sum_{i=1}^{n_k} p_k = \\frac{1}{n_k} (n_k p_k) = p_k\n$$\n该估计量的偏差为 $\\text{Bias}(\\hat{p}_k) = E[\\hat{p}_k] - p_k = p_k - p_k = 0$。估计量 $\\hat{p}_k$ 是无偏的。\n由于偏差为零，MSE 等于估计量的方差：\n$$\n\\text{MSE}(\\hat{p}_k) = \\text{Var}(\\hat{p}_k)\n$$\n现在，我们计算 $\\hat{p}_k$ 的方差。由于样本 $X_{k,i}$ 是独立的，它们和的方差等于它们方差的和。\n$$\n\\text{Var}(\\hat{p}_k) = \\text{Var}\\left(\\frac{1}{n_k} \\sum_{i=1}^{n_k} X_{k,i}\\right) = \\frac{1}{n_k^2} \\text{Var}\\left(\\sum_{i=1}^{n_k} X_{k,i}\\right) = \\frac{1}{n_k^2} \\sum_{i=1}^{n_k} \\text{Var}(X_{k,i})\n$$\n参数为 $p_k$ 的伯努利随机变量的方差是 $\\text{Var}(X_{k,i}) = p_k(1-p_k)$。\n$$\n\\text{Var}(\\hat{p}_k) = \\frac{1}{n_k^2} \\sum_{i=1}^{n_k} p_k(1-p_k) = \\frac{1}{n_k^2} n_k p_k(1-p_k) = \\frac{p_k(1-p_k)}{n_k}\n$$\n所以，第 $k$ 个箱中估计量的 MSE 为：\n$$\n\\text{MSE}(\\hat{p}_k) = \\frac{p_k(1-p_k)}{n_k}\n$$\n我们要最小化的总 MSE 是所有箱的 MSE 之和：\n$$\nL(n_1, n_2, n_3) = \\sum_{k=1}^{3} \\text{MSE}(\\hat{p}_k) = \\sum_{k=1}^{3} \\frac{p_k(1-p_k)}{n_k}\n$$\n这个最小化问题受限于总样本量的约束：\n$$\n\\sum_{k=1}^{3} n_k = N\n$$\n这是一个约束优化问题。我们可以使用拉格朗日乘数法来解决。我们将样本量 $n_k$ 视为连续的正实数变量。拉格朗日函数 $\\mathcal{L}$ 为：\n$$\n\\mathcal{L}(n_1, n_2, n_3, \\lambda) = \\sum_{k=1}^{3} \\frac{p_k(1-p_k)}{n_k} + \\lambda \\left(\\sum_{k=1}^{3} n_k - N\\right)\n$$\n为了找到最小值，我们对 $\\mathcal{L}$ 关于每个 $n_k$ 求偏导数，并令其为零。对于每个 $k \\in \\{1, 2, 3\\}$：\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial n_k} = -\\frac{p_k(1-p_k)}{n_k^2} + \\lambda = 0\n$$\n这意味着：\n$$\n\\lambda = \\frac{p_k(1-p_k)}{n_k^2}\n$$\n由此，我们可以用 $\\lambda$ 表示 $n_k$：\n$$\nn_k^2 = \\frac{p_k(1-p_k)}{\\lambda} \\implies n_k = \\frac{\\sqrt{p_k(1-p_k)}}{\\sqrt{\\lambda}}\n$$\n我们取正平方根，因为 $n_k$ 必须是正数。这个结果表明，给定箱的最优样本量 $n_k$ 与该箱中伯努利过程的标准差 $\\sigma_k = \\sqrt{p_k(1-p_k)}$ 成正比。\n\n现在，我们使用约束 $\\sum_{k=1}^{3} n_k = N$ 来确定拉格朗日乘子 $\\lambda$ 的值。\n$$\n\\sum_{k=1}^{3} \\frac{\\sqrt{p_k(1-p_k)}}{\\sqrt{\\lambda}} = N\n$$\n$$\n\\frac{1}{\\sqrt{\\lambda}} \\sum_{k=1}^{3} \\sqrt{p_k(1-p_k)} = N\n$$\n解出 $\\frac{1}{\\sqrt{\\lambda}}$：\n$$\n\\frac{1}{\\sqrt{\\lambda}} = \\frac{N}{\\sum_{j=1}^{3} \\sqrt{p_j(1-p_j)}}\n$$\n现在将此结果代回 $n_k$ 的表达式中：\n$$\nn_k = \\sqrt{p_k(1-p_k)} \\left( \\frac{1}{\\sqrt{\\lambda}} \\right) = \\sqrt{p_k(1-p_k)} \\left( \\frac{N}{\\sum_{j=1}^{3} \\sqrt{p_j(1-p_j)}} \\right)\n$$\n这就得到了最优分配 $n_k$ 的通用公式：\n$$\nn_k = N \\frac{\\sqrt{p_k(1-p_k)}}{\\sum_{j=1}^{3} \\sqrt{p_j(1-p_j)}}\n$$\n题目特别要求的是第 2 个箱的最优分配 $n_2$ 的闭式表达式。在通用公式中令 $k=2$，可得：\n$$\nn_2 = N \\frac{\\sqrt{p_2(1-p_2)}}{\\sqrt{p_1(1-p_1)} + \\sqrt{p_2(1-p_2)} + \\sqrt{p_3(1-p_3)}}\n$$\n这就是用总样本量 $N$ 和各箱成功概率 $p_1, p_2, p_3$ 表示的第 2 个箱的最优样本数的最终表达式。这种分配策略是分层抽样中奈曼分配的一种变体。", "answer": "$$\n\\boxed{N \\frac{\\sqrt{p_2(1-p_2)}}{\\sqrt{p_1(1-p_1)} + \\sqrt{p_2(1-p_2)} + \\sqrt{p_3(1-p_3)}}}\n$$", "id": "3198743"}, {"introduction": "掌握了最优分配的理论后，我们现在转向一个实际的编程练习，来观察分层抽样的实际效果。您将实现一个蒙特卡洛积分，并比较一个基本的等宽分层方案与一个基于函数导数的更复杂方案。这项练习提供了一个具体的证明，表明在数值最均匀的地方创建分层是减少估计误差的强大技术。", "problem": "您需要设计并实现一个完整的、可运行的程序，该程序使用分层抽样进行蒙特卡洛积分，以估计函数 $f(x)=\\exp(x)$ 在区间 $[0,1]$ 上的积分，并比较两种分层方案：等宽分层和由导数大小决定的非等宽分层。该程序必须遵循一个从积分和概率的基本原理推导出的、有原则的算法。计算框架如下。\n\n从黎曼积分与均匀分布下的期望之间的基本等价性开始：对于 $[a,b]$ 上的任何可积函数 $f$，其积分满足\n$$\n\\int_a^b f(x)\\,dx \\;=\\; (b-a)\\,\\mathbb{E}\\big[f(U)\\big],\n$$\n其中 $U$ 是在 $[a,b]$ 上均匀分布的随机变量。该恒等式证明了通过函数在均匀分布下的期望值来对积分进行蒙特卡洛（随机化）估计的合理性。分层抽样将区间划分为多个子区间（层），并分别估计每一层的贡献，然后将这些贡献作为加权和进行组合。其关键思想是，当分层的构建能够捕捉被积函数的异质性时，这种划分可以减少方差。\n\n您的实现必须：\n- 使用 $K$ 个层，根据两种方案对 $[0,1]$ 进行划分：\n  1. **等宽方案**：选择边界 $0=b_0  b_1  \\dots  b_K = 1$，使得 $b_i = i/K$。\n  2. **导数加权方案**：选择边界 $0=b'_0  b'_1  \\dots  b'_K = 1$，使得对于所有 $i=1,\\dots,K$，积分 $\\int_{b'_{i-1}}^{b'_i} |f'(x)| \\, dx$ 的值是恒定的。对于本题中的 $f(x)=\\exp(x)$，这等价于 $\\int_{b'_{i-1}}^{b'_i} \\exp(x) \\, dx$ 是恒定的。\n- 对于给定的总样本量 $N$，将样本尽可能均匀地分配到 $K$ 个层中。\n- 对于给定的几个 $(N, K)$ 测试用例，计算两种方案下的积分估计，并确定它们的绝对误差。\n- 生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。列表中的每个元素本身也是一个列表，格式为 `[error_eq, error_dw, is_dw_better]`，其中 `error_eq` 和 `error_dw` 分别是两种方案的绝对误差（四舍五入到八位小数），`is_dw_better` 是一个布尔值，当且仅当导数加权方案的误差严格小于等宽方案的误差时为 `True`。输出格式为 `[[e1,d1,t1],[e2,d2,t2],...]`。\n\n使用以下测试用例：\n- $(N, K) = (1000, 5)$\n- $(N, K) = (1000, 1)$\n- $(N, K) = (100, 10)$\n- $(N, K) = (5000, 50)$\n- $(N, K) = (1024, 7)$", "solution": "该问题要求使用分层蒙特卡洛方法估计积分 $\\int_0^1 e^x dx$，并比较两种分层策略的性能：等宽分层和导数加权分层。该问题是适定的，并且在计算科学和统计学原理上是合理的。\n\n### 算法推导与实现\n\n**1. 分层蒙特卡洛积分**\n\n分层估计量是各层估计值的加权和。对于区间 $[0,1]$ 上的 $K$ 个层，第 $i$ 层的边界为 $[b_{i-1}, b_i]$，宽度为 $w_i = b_i - b_{i-1}$。该层对总积分的贡献为 $\\int_{b_{i-1}}^{b_i} f(x) dx = w_i \\mathbb{E}[f(U_i)]$，其中 $U_i \\sim \\text{Uniform}(b_{i-1}, b_i)$。我们通过在该层内抽取 $n_i$ 个样本 $\\{x_{i,j}\\}_{j=1}^{n_i}$ 来估计这个期望值。\n第 $i$ 层的积分估计为：\n$$\n\\hat{I}_i = w_i \\frac{1}{n_i} \\sum_{j=1}^{n_i} f(x_{i,j})\n$$\n总积分的估计为：\n$$\n\\hat{I} = \\sum_{i=1}^{K} \\hat{I}_i\n$$\n在我们的实现中，我们通过在 $[0,1]$ 中生成均匀样本 $u_j$，然后将其映射到第 $i$ 层：$x_{i,j} = b_{i-1} + u_j \\cdot w_i$。\n\n**2. 样本分配**\n\n总样本量 $N$ 需尽可能均匀地分配给 $K$ 个层。这可以通过整数除法和取余来实现。每个层至少获得 $n_{\\text{base}} = N // K$ 个样本，前 $N \\% K$ 个层额外获得一个样本。\n\n**3. 边界方案**\n\n- **方案 1 (等宽)**：这是最直接的方案。区间 $[0,1]$ 被划分为 $K$ 个等宽的子区间。边界点由下式给出：\n  $$\n  b_i = \\frac{i}{K} \\quad \\text{for } i = 0, 1, \\dots, K\n  $$\n\n- **方案 2 (导数加权)**：此方案旨在在函数变化剧烈的地方创建更窄的层（从而更密集地采样）。我们选择边界 $b'_i$ 使得 $\\int_{b'_{i-1}}^{b'_i} |f'(x)| dx$ 的值对所有层都是恒定的。对于 $f(x) = e^x$，我们有 $f'(x) = e^x$，在 $[0,1]$ 上恒为正。我们需要 $\\int_{b'_{i-1}}^{b'_i} e^x dx = C$。\n  $|f'(x)|$ 在 $[0,1]$ 上的总积分为 $\\int_0^1 e^x dx = e - 1$。因此，每个层的积分为 $(e-1)/K$。\n  第 $i$ 个边界点 $b'_i$ 满足：\n  $$\n  \\int_0^{b'_i} e^x dx = i \\cdot \\frac{e-1}{K}\n  $$\n  计算积分得到 $e^{b'_i} - e^0 = i \\frac{e-1}{K}$，即 $e^{b'_i} - 1 = i \\frac{e-1}{K}$。\n  解出 $b'_i$：\n  $$\n  b'_i = \\ln\\left(1 + i \\frac{e-1}{K}\\right) \\quad \\text{for } i = 0, 1, \\dots, K\n  $$\n\n**4. 误差计算与比较**\n\n对于每个测试用例 $(N,K)$，程序将：\na. 计算两种方案的边界。\nb. 分配样本量。\nc. 调用分层蒙特卡洛函数计算积分估计值 $\\hat{I}_{\\text{eq}}$ 和 $\\hat{I}_{\\text{dw}}$。\nd. 计算与真实积分值 $I_{\\text{true}} = e^1 - e^0 = e - 1$ 的绝对误差：$e_{\\text{eq}} = |\\hat{I}_{\\text{eq}} - I_{\\text{true}}|$ 和 $e_{\\text{dw}} = |\\hat{I}_{\\text{dw}} - I_{\\text{true}}|$。\ne. 比较误差并格式化输出。\n\n由于 $f(x)=e^x$ 在 $[0,1]$ 上是单调递增的凸函数，其导数也是单调递增的，因此导数加权方案在函数变化更快处（$x$ 接近 1）的层更窄，预计会比等宽方案产生更低的方差和误差。", "answer": "```python\nimport numpy as np\n\ndef stratified_monte_carlo(f, boundaries, sample_counts, rng):\n    \"\"\"\n    Performs stratified Monte Carlo integration.\n\n    Args:\n        f (callable): The function to integrate.\n        boundaries (np.ndarray): An array of stratum boundaries, size K+1.\n        sample_counts (list): A list of sample counts per stratum, size K.\n        rng (np.random.Generator): The random number generator instance.\n\n    Returns:\n        float: The estimated value of the integral.\n    \"\"\"\n    total_integral_estimate = 0.0\n    num_strata = len(sample_counts)\n    \n    for i in range(num_strata):\n        b_lower = boundaries[i]\n        b_upper = boundaries[i+1]\n        width = b_upper - b_lower\n        n_samples = sample_counts[i]\n        \n        if n_samples == 0:\n            continue\n            \n        # Generate n_samples uniform samples in [0, 1]\n        u_samples = rng.uniform(size=n_samples)\n        \n        # Transform samples to the stratum interval [b_lower, b_upper]\n        x_samples = b_lower + u_samples * width\n        \n        # Evaluate the function at the sample points\n        y_samples = f(x_samples)\n        \n        # Estimate the integral for the current stratum and add to total\n        total_integral_estimate += width * np.mean(y_samples)\n        \n    return total_integral_estimate\n\ndef solve():\n    \"\"\"\n    Main function to run the Monte Carlo integration comparison.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1000, 5),\n        (1000, 1),\n        (100, 10),\n        (5000, 50),\n        (1024, 7),\n    ]\n\n    # Initialize the random number generator with the specified seed for reproducibility.\n    rng = np.random.default_rng(12345)\n\n    # Define the function to integrate, f(x) = exp(x).\n    f = lambda x: np.exp(x)\n\n    # Analytically compute the true value of the integral from 0 to 1.\n    true_integral = np.exp(1.0) - 1.0\n\n    # Store formatted results for all test cases.\n    all_results_str = []\n\n    for N, K in test_cases:\n        # Step 1: Determine sample allocation per stratum.\n        if K > 0:\n            n_base = N // K\n            remainder = N % K\n            sample_counts = [n_base + 1] * remainder + [n_base] * (K - remainder)\n        else: # Handles K=0 case, though not in tests.\n            sample_counts = []\n\n        # -- Scheme 1: Equal-width stratification --\n        if K > 0:\n            boundaries_eq = np.linspace(0.0, 1.0, K + 1)\n            integral_eq = stratified_monte_carlo(f, boundaries_eq, sample_counts, rng)\n        else: # For K=0 or K=1, it is standard Monte Carlo\n            integral_eq = stratified_monte_carlo(f, np.array([0.0, 1.0]), [N], rng) if N > 0 else 0\n        \n        error_eq = np.abs(integral_eq - true_integral)\n\n        # -- Scheme 2: Derivative-weighted stratification --\n        if K > 1:\n            integral_of_g = true_integral\n            const = integral_of_g / K\n            i_vals = np.arange(K + 1)\n            boundaries_dw = np.log(1.0 + i_vals * const)\n            integral_dw = stratified_monte_carlo(f, boundaries_dw, sample_counts, rng)\n        else: # For K=1, this scheme is identical to equal-width\n            integral_dw = integral_eq\n        \n        error_dw = np.abs(integral_dw - true_integral)\n\n        # -- Step 3: Comparison and Formatting --\n        is_dw_better = error_dw  error_eq\n        \n        error_eq_rounded = f\"{error_eq:.8f}\"\n        error_dw_rounded = f\"{error_dw:.8f}\"\n        \n        # Build the result string for the current test case in the format [e,d,t].\n        case_result_str = f\"[{error_eq_rounded},{error_dw_rounded},{is_dw_better}]\"\n        all_results_str.append(case_result_str)\n\n    # Final print statement in the exact required format [[...],[...],...].\n    print(f\"[{','.join(all_results_str)}]\")\n\nsolve()\n```", "id": "3198834"}, {"introduction": "我们的最后一项实践探讨了一个更动态、更现实的场景，其中初步抽样显示我们的分层可能不是最优的。您将实现一个自适应协议，如果发现某个层的内部方差过高，则将其拆分。这个问题表明，分层可以是一个迭代过程，允许我们动态调整抽样策略，以提高结果的效率和准确性。", "problem": "考虑一个划分为 $K$ 个层的有限总体。设第 $k$ 层的总体比例为 $p_k$，层内总体标准差为 $\\sigma_k$。假设总体均值的估计量定义为层样本均值的加权平均，其中第 $k$ 层的权重为 $p_k$。在第 $k$ 层内，抽取一个大小为 $n_k$ 的简单随机样本，并计算第 $k$ 层的样本均值。\n\n从方差、独立性的定义以及大总体简单随机抽样下样本均值的方差（因此忽略有限总体校正（FPC））出发，推导加权估计量方差的表达式，用 $p_k$、$\\sigma_k$ 和 $n_k$ 表示。\n\n对任何表现出较高层内估计标准差 $\\hat{\\sigma}_k$ 的层 $k$ 应用一个自适应拆分协议。该协议如下：\n- 如果 $\\hat{\\sigma}_k$ 超过阈值 $T$ 且 $n_k \\geq 2$，则将层 $k$ 拆分为两个子层 $k_1$ 和 $k_2$，其总体比例分别为 $p_{k_1} = r_k \\, p_k$ 和 $p_{k_2} = (1 - r_k) \\, p_k$，其中 $r_k \\in (0,1)$ 是给定的。使用测试用例中提供的子层内总体标准差 $\\sigma_{k_1}$ 和 $\\sigma_{k_2}$。\n- 根据规则 $n_{k_1} = \\max\\{1, \\lfloor r_k \\, n_k \\rfloor\\}$ 和 $n_{k_2} = n_k - n_{k_1}$，在两个子层之间重新分配层样本量 $n_k$。如果在向下取整运算后 $n_{k_1} \\geq n_k$，则设置 $n_{k_1} = n_k - 1$ 和 $n_{k_2} = 1$ 以确保两者都至少为 1。\n- 如果 $\\hat{\\sigma}_k \\leq T$ 或 $n_k  2$，则不拆分层 $k$。\n\n使用您推导出的加权估计量方差表达式，通过计算差值\n$$\n\\Delta = V_{\\text{post}} - V_{\\text{pre}},\n$$\n来计算这种自适应拆分对方差的影响，其中 $V_{\\text{pre}}$ 是拆分前的方差，$V_{\\text{post}}$ 是应用拆分协议后的方差。\n\n实现一个程序，对下面的每个测试用例，应用该协议，计算 $V_{\\text{pre}}$ 和 $V_{\\text{post}}$，并返回 $\\Delta$。\n\n使用以下测试套件。每个测试用例提供 $K$、数组 $p_k$、$\\sigma_k$、$\\hat{\\sigma}_k$、$n_k$、阈值 $T$，以及对于可能拆分的层，提供元组 $(r_k, \\sigma_{k_1}, \\sigma_{k_2})$。\n\n- 测试用例 1 (一般情况，一次拆分):\n  - $K = 3$\n  - $p = [\\,0.5,\\,0.3,\\,0.2\\,]$\n  - $\\sigma = [\\,3.0,\\,5.0,\\,2.0\\,]$\n  - $\\hat{\\sigma} = [\\,2.8,\\,5.4,\\,1.9\\,]$\n  - $n = [\\,50,\\,30,\\,20\\,]$\n  - $T = 4.0$\n  - 每层的拆分信息: $[\\,\\text{无},\\,(0.6,\\,3.0,\\,6.0),\\,\\text{无}\\,]$\n\n- 测试用例 2 (因阈值过高而未拆分):\n  - $K = 3$\n  - $p = [\\,0.5,\\,0.3,\\,0.2\\,]$\n  - $\\sigma = [\\,3.0,\\,5.0,\\,2.0\\,]$\n  - $\\hat{\\sigma} = [\\,2.8,\\,5.4,\\,1.9\\,]$\n  - $n = [\\,50,\\,30,\\,20\\,]$\n  - $T = 6.0$\n  - 每层的拆分信息: $[\\,\\text{无},\\,(0.6,\\,3.0,\\,6.0),\\,\\text{无}\\,]$\n\n- 测试用例 3 (因层内样本量不足而阻止拆分):\n  - $K = 2$\n  - $p = [\\,0.7,\\,0.3\\,]$\n  - $\\sigma = [\\,8.0,\\,1.0\\,]$\n  - $\\hat{\\sigma} = [\\,8.2,\\,0.9\\,]$\n  - $n = [\\,1,\\,10\\,]$\n  - $T = 5.0$\n  - 每层的拆分信息: $[\\, (0.5,\\,6.0,\\,10.0),\\,\\text{无}\\,]$\n\n- 测试用例 4 (极端分配的拆分，产生一个样本量最小的子层):\n  - $K = 2$\n  - $p = [\\,0.4,\\,0.6\\,]$\n  - $\\sigma = [\\,4.0,\\,9.0\\,]$\n  - $\\hat{\\sigma} = [\\,4.1,\\,9.2\\,]$\n  - $n = [\\,3,\\,7\\,]$\n  - $T = 4.5$\n  - 每层的拆分信息: $[\\,\\text{无},\\,(0.9,\\,5.0,\\,12.0)\\,]$\n\n- 测试用例 5 (单层总体，拆分导致方差显著增加):\n  - $K = 1$\n  - $p = [\\,1.0\\,]$\n  - $\\sigma = [\\,2.0\\,]$\n  - $\\hat{\\sigma} = [\\,10.0\\,]$\n  - $n = [\\,10\\,]$\n  - $T = 5.0$\n  - 每层的拆分信息: $[\\, (0.1,\\,1.0,\\,10.0) \\,]$\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，每个 $\\Delta$ 值四舍五入到六位小数（例如，$[\\,\\delta_1,\\,\\delta_2,\\,\\delta_3,\\,\\delta_4,\\,\\delta_5\\,]$ 的形式为 $[\\,0.123456,\\,0.000000,\\,\\ldots\\,]$）。", "solution": "该问题陈述经评估有效。它在科学上基于调查抽样，特别是分层抽样的原理。其定义和约束是自洽、一致且适定的，从而可以为每个测试用例推导和计算出唯一且有意义的解。该问题是可形式化的，并与指定主题直接相关。\n\n### 分层估计量方差的推导\n\n目标是推导总体均值估计量的方差表达式。该估计量，我们称之为 $\\hat{\\mu}_{\\text{strat}}$，由层样本均值 $\\bar{y}_k$ 的加权平均给出：\n$$\n\\hat{\\mu}_{\\text{strat}} = \\sum_{k=1}^{K} p_k \\bar{y}_k\n$$\n其中 $K$ 是层的数量，$p_k$ 是第 $k$ 层的总体比例，$\\bar{y}_k$ 是从第 $k$ 层抽取的样本量为 $n_k$ 的简单随机样本的样本均值。\n\n该估计量的方差由下式给出：\n$$\nV(\\hat{\\mu}_{\\text{strat}}) = V\\left(\\sum_{k=1}^{K} p_k \\bar{y}_k\\right)\n$$\n分层抽样的一个核心原则是，从不同层抽取的样本是相互独立的。这意味着对于 $k = 1, \\dots, K$，样本均值 $\\bar{y}_k$ 是独立的随机变量。对于独立随机变量之和，其和的方差等于方差之和。因此：\n$$\nV(\\hat{\\mu}_{\\text{strat}}) = \\sum_{k=1}^{K} V(p_k \\bar{y}_k)\n$$\n总体比例 $p_k$ 是已知常数。使用方差属性 $V(aX) = a^2 V(X)$（其中 $a$ 是常数），我们得到：\n$$\nV(\\hat{\\mu}_{\\text{strat}}) = \\sum_{k=1}^{K} p_k^2 V(\\bar{y}_k)\n$$\n问题指定使用大总体简单随机抽样下样本均值的方差，这意味着我们忽略有限总体校正（FPC）。对于从标准差为 $\\sigma_k$ 的总体（或层）中抽取的样本量为 $n_k$ 的样本，其样本均值 $\\bar{y}_k$ 的方差为：\n$$\nV(\\bar{y}_k) = \\frac{\\sigma_k^2}{n_k}\n$$\n将此表达式代入我们的 $V(\\hat{\\mu}_{\\text{strat}})$ 方程，得到分层估计量方差的最终公式：\n$$\nV(\\hat{\\mu}_{\\text{strat}}) = \\sum_{k=1}^{K} \\frac{p_k^2 \\sigma_k^2}{n_k}\n$$\n这个表达式将用于计算 $V_{\\text{pre}}$ 和 $V_{\\text{post}}$。\n\n### 计算方差变化 $\\Delta$ 的算法\n\n方差变化 $\\Delta$ 定义为 $\\Delta = V_{\\text{post}} - V_{\\text{pre}}$。对于每个测试用例，算法按以下步骤进行。\n\n1.  **计算拆分前方差 ($V_{\\text{pre}}$)**:\n    使用推导出的公式，利用给定的参数 $p$、$\\sigma$ 和 $n$ 计算初始方差：\n    $$\n    V_{\\text{pre}} = \\sum_{k=1}^{K} \\frac{p_k^2 \\sigma_k^2}{n_k}\n    $$\n\n2.  **应用自适应拆分协议**:\n    生成一组新的参数（我们用撇号表示：$p'$、$\\sigma'$、$n'$），代表应用协议后各层的状态。我们遍历初始的 $K$ 个层中的每一个。对于每个层 $k \\in \\{1, \\dots, K\\}$：\n    \n    *   **检查拆分条件**: 当且仅当其估计标准差 $\\hat{\\sigma}_k$ 超过阈值 $T$ 并且其样本量 $n_k$ 至少为 2 时，该层才会被拆分。\n        $$\n        (\\hat{\\sigma}_k > T) \\land (n_k \\geq 2)\n        $$\n    *   **如果层不拆分**: 其参数直接沿用至拆分后的集合中。一个新的层被添加到拆分后的配置中，其参数为 $p'_{new} = p_k$、$\\sigma'_{new} = \\sigma_k$ 和 $n'_{new} = n_k$。\n    *   **如果层拆分**: 它被两个新的子层（标记为 $k_1$ 和 $k_2$）所取代。这些子层的参数根据协议计算：\n        *   **比例**: 原始比例 $p_k$ 根据给定的比率 $r_k$ 进行划分：\n            $$\n            p'_{k_1} = r_k \\, p_k \\quad \\text{和} \\quad p'_{k_2} = (1 - r_k) \\, p_k\n            $$\n        *   **标准差**: 新的标准差 $\\sigma_{k_1}$ 和 $\\sigma_{k_2}$ 在测试用例的拆分信息中直接提供。\n        *   **样本量**: 原始样本量 $n_k$ 被重新分配：\n            $$\n            n'_{k_1} = \\max\\{1, \\lfloor r_k \\, n_k \\rfloor\\}\n            $$\n            $$\n            n'_{k_2} = n_k - n'_{k_1}\n            $$\n            对于任何 $n_k \\ge 2$ 和 $r_k \\in (0,1)$，`确保两者都至少为 1` 的条件会被此规则自动满足，因为 $\\lfloor r_k n_k \\rfloor \\le n_k - 1$，所以 $n'_{k_1} \\le n_k - 1$，因此 $n'_{k_2} = n_k - n'_{k_1} \\ge 1$。规则 $n'_{k_1} = \\max\\{1, \\dots\\}$ 确保了 $n'_{k_1} \\ge 1$。在问题约束下，多余的条件 `如果 n_{k_1} >= n_k...` 永远不会触发，因此可以忽略。\n\n3.  **计算拆分后方差 ($V_{\\text{post}}$)**:\n    处理完所有初始层后，我们得到一组新的、具有参数 $p'$、$\\sigma'$ 和 $n'$ 的拆分后层。通过将方差公式应用于这个新配置来计算拆分后方差：\n    $$\n    V_{\\text{post}} = \\sum_{j=1}^{K'} \\frac{(p'_j)^2 (\\sigma'_j)^2}{n'_j}\n    $$\n    其中 $K'$ 是拆分后的新层总数。\n\n4.  **计算差值 ($\\Delta$)**:\n    最终值是拆分后方差与拆分前方差之间的差值：\n    $$\n    \\Delta = V_{\\text{post}} - V_{\\text{pre}}\n    $$\n    然后将此值四舍五入到六位小数作为最终输出。", "answer": "```python\nimport numpy as np\nimport math\n\ndef solve():\n    \"\"\"\n    Solves the stratified sampling variance problem for a suite of test cases.\n    \"\"\"\n    \n    test_cases = [\n        # Test case 1\n        {\n            \"K\": 3, \"p\": [0.5, 0.3, 0.2], \"sigma\": [3.0, 5.0, 2.0],\n            \"hat_sigma\": [2.8, 5.4, 1.9], \"n\": [50, 30, 20], \"T\": 4.0,\n            \"split_info\": [None, (0.6, 3.0, 6.0), None]\n        },\n        # Test case 2\n        {\n            \"K\": 3, \"p\": [0.5, 0.3, 0.2], \"sigma\": [3.0, 5.0, 2.0],\n            \"hat_sigma\": [2.8, 5.4, 1.9], \"n\": [50, 30, 20], \"T\": 6.0,\n            \"split_info\": [None, (0.6, 3.0, 6.0), None]\n        },\n        # Test case 3\n        {\n            \"K\": 2, \"p\": [0.7, 0.3], \"sigma\": [8.0, 1.0],\n            \"hat_sigma\": [8.2, 0.9], \"n\": [1, 10], \"T\": 5.0,\n            \"split_info\": [(0.5, 6.0, 10.0), None]\n        },\n        # Test case 4\n        {\n            \"K\": 2, \"p\": [0.4, 0.6], \"sigma\": [4.0, 9.0],\n            \"hat_sigma\": [4.1, 9.2], \"n\": [3, 7], \"T\": 4.5,\n            \"split_info\": [None, (0.9, 5.0, 12.0)]\n        },\n        # Test case 5\n        {\n            \"K\": 1, \"p\": [1.0], \"sigma\": [2.0], \"hat_sigma\": [10.0],\n            \"n\": [10], \"T\": 5.0,\n            \"split_info\": [(0.1, 1.0, 10.0)]\n        }\n    ]\n\n    results = []\n\n    def calculate_variance(p_vec, sigma_vec, n_vec):\n        \"\"\"Calculates the variance of the stratified estimator.\"\"\"\n        variance = 0.0\n        for i in range(len(p_vec)):\n            if n_vec[i] > 0:\n                variance += (p_vec[i]**2 * sigma_vec[i]**2) / n_vec[i]\n        return variance\n\n    for case in test_cases:\n        p, sigma, hat_sigma, n, T, split_info, K = \\\n            case[\"p\"], case[\"sigma\"], case[\"hat_sigma\"], case[\"n\"], case[\"T\"], case[\"split_info\"], case[\"K\"]\n        \n        # 1. Calculate pre-split variance\n        v_pre = calculate_variance(p, sigma, n)\n        \n        # 2. Apply adaptive splitting protocol\n        p_post, sigma_post, n_post = [], [], []\n        \n        for k in range(K):\n            # Check split condition: excess stdev and sufficient sample size\n            if hat_sigma[k] > T and n[k] >= 2:\n                # Stratum k splits\n                r_k, sigma_k1, sigma_k2 = split_info[k]\n                \n                # Proportions for sub-strata\n                p_k = p[k]\n                p_post.extend([r_k * p_k, (1 - r_k) * p_k])\n                \n                # Standard deviations for sub-strata\n                sigma_post.extend([sigma_k1, sigma_k2])\n                \n                # Sample sizes for sub-strata\n                n_k = n[k]\n                n_k1 = max(1, math.floor(r_k * n_k))\n                n_k2 = n_k - n_k1\n                n_post.extend([n_k1, n_k2])\n            else:\n                # Stratum k does not split\n                p_post.append(p[k])\n                sigma_post.append(sigma[k])\n                n_post.append(n[k])\n        \n        # 3. Calculate post-split variance\n        v_post = calculate_variance(p_post, sigma_post, n_post)\n        \n        # 4. Compute Delta\n        delta = v_post - v_pre\n        results.append(f\"{delta:.6f}\")\n        \n    # Final print statement in the exact required format\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3198787"}]}