{"hands_on_practices": [{"introduction": "GPU通过同时执行大量线程来隐藏内存访问延迟，从而实现卓越的性能。然而，硬件资源（如寄存器和共享内存）是有限的，这限制了可以同时驻留在流式多处理器（SM）上的线程块数量。本练习将指导您计算“占用率”——一个衡量SM资源利用率的关键指标，并通过一个具体的例子，展示如何根据内核的资源需求来预测其性能瓶颈。[@problem_id:3139038]", "problem": "考虑一个由相同的流式多处理器（SM）组成的图形处理器（GPU）。每个SM拥有有限的硬件资源：容量为 $R_{\\mathrm{SM}}$ 的寄存器文件（以32位寄存器的数量计算），容量为 $S_{\\mathrm{SM}}$ 字节的共享内存，容量为 $T_{\\mathrm{SM}}$ 线程的线程槽，以及在任何时候最多驻留 $B_{\\max}$ 个线程块的架构限制。一个包含 $b$ 个线程的线程块会消耗寄存器，因为每个线程使用 $r$ 个寄存器；它也会消耗共享内存，因为每个线程块在共享内存中分配 $s$ 字节。基本约束条件是：一个SM上所有驻留线程块使用的总寄存器数不能超过 $R_{\\mathrm{SM}}$，使用的总共享内存不能超过 $S_{\\mathrm{SM}}$，总线程数不能超过 $T_{\\mathrm{SM}}$，并且线程块的数量不能超过 $B_{\\max}$。所有计数都是整数，并且一个SM只调度完整的线程块。占用率（Occupancy）是一个SM上被驻留线程占满的线程槽的比例，定义为驻留线程数除以 $T_{\\mathrm{SM}}$，且其值不能超过1。\n\n给定一个具体的GPU，其参数为：$R_{\\mathrm{SM}}=65536$，$S_{\\mathrm{SM}}=98304\\,\\mathrm{bytes}$，$T_{\\mathrm{SM}}=2048$，$B_{\\max}=16$。考虑两个内核（kernel）：\n\n- 内核A：每个线程使用 $r=64$ 个寄存器，每个线程块使用 $s=12288\\,\\mathrm{bytes}$ 的共享内存，每个线程块有 $b=256$ 个线程。\n- 内核B（基准）：每个线程使用 $r_{0}=32$ 个寄存器，每个线程块使用 $s_{0}=8192\\,\\mathrm{bytes}$ 的共享内存，每个线程块有 $b_{0}=128$ 个线程。\n\n使用第一性原理和上述资源限制，确定每个内核在单个SM上可以并发调度的最大驻留线程块数量。由此，计算每个内核在单个SM上的占用率。最后，假设一个简化的性能模型，其中吞吐量与占用率成正比，运行时间与吞吐量成反比。在此模型下，计算内核A的运行时间与内核B的运行时间之比（即 $\\text{runtime}_{A}/\\text{runtime}_{B}$）。将您的最终答案四舍五入到四位有效数字，并以无量纲的小数形式表示。", "solution": "### 求解推导\n\n问题的核心是确定每个内核在单个SM上可以并发驻留的最大线程块数 $N$。这个数字受到SM有限资源的约束。由于一个SM只能调度完整的线程块，因此每个资源限制所支持的最大线程块数是总资源容量与每个线程块资源消耗量之比的向下取整。驻留线程块的总最大数量 $N$ 是这些单个限制中的最小值。\n\n对于一个每个线程块有 $b$ 个线程、每个线程使用 $r$ 个寄存器、每个线程块使用 $s$ 字节共享内存的内核，最大线程块数 $N$ 由以下公式给出：\n$N = \\min( N_{\\text{reg}}, N_{\\text{smem}}, N_{\\text{thread}}, N_{\\text{block}} )$\n其中：\n- $N_{\\text{reg}} = \\lfloor \\frac{R_{\\mathrm{SM}}}{b \\times r} \\rfloor$ (来自寄存器的限制)\n- $N_{\\text{smem}} = \\lfloor \\frac{S_{\\mathrm{SM}}}{s} \\rfloor$ (来自共享内存的限制)\n- $N_{\\text{thread}} = \\lfloor \\frac{T_{\\mathrm{SM}}}{b} \\rfloor$ (来自线程槽的限制)\n- $N_{\\text{block}} = B_{\\max}$ (架构对线程块的限制)\n\n一旦为每个内核找到了 $N$，就可以计算占用率。驻留线程的数量是 $N \\times b$。那么占用率 $O$ 为：\n$O = \\frac{N \\times b}{T_{\\mathrm{SM}}}$\n\n最后，根据性能模型推导出运行时间比率。\n运行时间 $\\propto \\frac{1}{\\text{吞吐量}}$ 且 吞吐量 $\\propto O$。\n因此，运行时间 $\\propto \\frac{1}{O}$。\n运行时间的比率为 $\\frac{\\text{runtime}_A}{\\text{runtime}_B} = \\frac{1/O_A}{1/O_B} = \\frac{O_B}{O_A}$。\n\n**内核A分析**\n- 参数：$r_A=64$，$s_A=12288$，$b_A=256$。\n- SM限制：$R_{\\mathrm{SM}}=65536$，$S_{\\mathrm{SM}}=98304$，$T_{\\mathrm{SM}}=2048$，$B_{\\max}=16$。\n\n1.  计算内核A的各个线程块限制：\n    - 寄存器限制：$N_{A, \\text{reg}} = \\lfloor \\frac{65536}{256 \\times 64} \\rfloor = \\lfloor \\frac{65536}{16384} \\rfloor = \\lfloor 4 \\rfloor = 4$。\n    - 共享内存限制：$N_{A, \\text{smem}} = \\lfloor \\frac{98304}{12288} \\rfloor = \\lfloor 8 \\rfloor = 8$。\n    - 线程限制：$N_{A, \\text{thread}} = \\lfloor \\frac{2048}{256} \\rfloor = \\lfloor 8 \\rfloor = 8$。\n    - 架构线程块限制：$N_{A, \\text{block}} = 16$。\n\n2.  确定内核A的最大驻留线程块数：\n    $N_A = \\min(4, 8, 8, 16) = 4$ 个线程块。\n    内核A的限制因素是寄存器文件容量。\n\n3.  计算内核A的占用率：\n    驻留线程数 = $N_A \\times b_A = 4 \\times 256 = 1024$。\n    $O_A = \\frac{1024}{T_{\\mathrm{SM}}} = \\frac{1024}{2048} = 0.5$。\n\n**内核B分析**\n- 参数：$r_B=32$，$s_B=8192$，$b_B=128$。\n- SM限制相同。\n\n1.  计算内核B的各个线程块限制：\n    - 寄存器限制：$N_{B, \\text{reg}} = \\lfloor \\frac{65536}{128 \\times 32} \\rfloor = \\lfloor \\frac{65536}{4096} \\rfloor = \\lfloor 16 \\rfloor = 16$。\n    - 共享内存限制：$N_{B, \\text{smem}} = \\lfloor \\frac{98304}{8192} \\rfloor = \\lfloor 12 \\rfloor = 12$。\n    - 线程限制：$N_{B, \\text{thread}} = \\lfloor \\frac{2048}{128} \\rfloor = \\lfloor 16 \\rfloor = 16$。\n    - 架构线程块限制：$N_{B, \\text{block}} = 16$。\n\n2.  确定内核B的最大驻留线程块数：\n    $N_B = \\min(16, 12, 16, 16) = 12$ 个线程块。\n    内核B的限制因素是共享内存容量。\n\n3.  计算内核B的占用率：\n    驻留线程数 = $N_B \\times b_B = 12 \\times 128 = 1536$。\n    $O_B = \\frac{1536}{T_{\\mathrm{SM}}} = \\frac{1536}{2048} = \\frac{3}{4} = 0.75$。\n\n**运行时间比率计算**\n内核A的运行时间与内核B的运行时间之比为：\n$\\frac{\\text{runtime}_A}{\\text{runtime}_B} = \\frac{O_B}{O_A} = \\frac{0.75}{0.5} = 1.5$。\n\n问题要求答案四舍五入到四位有效数字。\n$1.5$ 表示为 $1.500$。", "answer": "$$\\boxed{1.500}$$", "id": "3139038"}, {"introduction": "在了解了如何通过高占用率使GPU保持繁忙之后，下一步是确保这些活跃的线程能够高效地访问数据。本练习将深入探讨“内存合并”这一核心概念，因为非合并的内存访问会严重降低带宽利用率，形成性能瓶颈。通过计算一个线程束（warp）访问非对齐数据所需的内存事务数量，您将具体地理解数据布局和对齐对GPU性能的决定性影响。[@problem_id:3138937]", "problem": "图形处理单元（GPU）以包含 $32$ 个线程的线程束（warp）为单位执行内存操作。全局内存以 $128$ 字节的固定大小段（segment）提供服务，一个线程束对其请求的字（word）所包含的任何字节所在的每一个不同的 $128$ 字节段，都会生成一次内存事务（transaction）。考虑一个内核（kernel），其中一个线程束中的每个线程从全局内存中的一个数组加载一个 $4$ 字节的浮点值。线程 $t \\in \\{0,1,\\ldots,31\\}$ 访问的地址是\n$$\nA(t) \\;=\\; A_{0} \\;+\\; \\delta \\;+\\; t \\, s \\, b,\n$$\n其中 $A_{0}$ 与一个 $128$ 字节边界对齐，$\\delta$ 是与该边界的字节偏移量，$s$ 是连续线程之间以元素为单位的步幅（stride），$b=4$ 字节是元素大小。假设对于以下参数，单个 $4$ 字节的访问不会跨越 $128$ 字节的边界。\n\n假设 $s=3$ 且 $\\delta=44$ 字节。\n\n仅使用上述定义和基本整数算术，确定一个线程束在这些参数下生成的 $128$ 字节事务的数量。然后，确定必须添加到基地址的最小非负填充量 $p$（以字节为单位）（即，用 $\\delta+p$ 替换 $\\delta$），以使第一个访问的地址与一个 $128$ 字节的段边界对齐，并重新计算在此填充下的 $128$ 字节事务数量。\n\n请完整报告您的推理过程，但为了评分，请仅提供最终的最小填充量 $p$ 作为您的答案。最终填充量以字节表示。无需四舍五入。", "solution": "问题要求计算将内存访问模式的起始地址对齐到 $128$ 字节段边界所需的最小非负填充量 $p$，并确定在有和没有此填充两种情况下的内存事务数量。\n\n首先，我们来形式化给定的信息。一个线程束包含 $32$ 个线程，索引为 $t \\in \\{0,\n1, \\ldots, 31\\}$。每个线程访问一个 $4$ 字节的字。内存段大小为 $128$ 字节。线程 $t$ 访问的起始字节地址由以下函数给出：\n$$A(t) = A_0 + \\delta + t \\cdot s \\cdot b$$\n其中 $A_0$ 是一个与 $128$ 字节边界对齐的基地址（即，$A_0 \\pmod{128} = 0$），$\\delta$ 是初始字节偏移量，$s$ 是以元素为单位的步幅，$b=4$ 字节是一个元素的大小。对于线程束中任何线程访问的每一个唯一的 $128$ 字节段，都会生成一个内存事务。包含地址 $A$ 处字节的段由索引 $\\lfloor A / 128 \\rfloor$ 标识。\n\n初始情况的具体参数是 $s=3$ 和 $\\delta=44$ 字节。因此，线程 $t$ 访问的地址是：\n$$A(t) = A_0 + 44 + t \\cdot 3 \\cdot 4 = A_0 + 44 + 12t$$\n由于 $A_0$ 与 $128$ 字节边界对齐，地址 $A(t)$ 的段索引为 $\\lfloor (A_0 + 44 + 12t) / 128 \\rfloor = A_0/128 + \\lfloor (44 + 12t) / 128 \\rfloor$。常数项 $A_0/128$ 只是将所有段索引移动一个整数值，不影响访问的唯一段的数量。因此，我们可以通过考虑相对于 $A_0$ 的地址来分析内存访问模式，我们将其表示为 $A_{rel}(t) = 44 + 12t$。\n\n为了找到事务的数量，我们必须确定对于 $t \\in \\{0, 1, \\ldots, 31\\}$，唯一的段索引 $\\lfloor A_{rel}(t) / 128 \\rfloor$ 的数量。\n第一个线程（$t=0$）访问的地址是 $A_{rel}(0) = 44 + 12(0) = 44$。\n此访问的段索引是 $\\lfloor 44 / 128 \\rfloor = 0$。\n\n最后一个线程（$t=31$）访问的地址是 $A_{rel}(31) = 44 + 12(31) = 44 + 372 = 416$。\n此访问的段索引是 $\\lfloor 416 / 128 \\rfloor = 3$。\n\n线程束访问的地址是单调的，从 $44$ 开始，连续线程之间以 $12$ 字节的步长递增。由于步幅（$12$ 字节）小于段大小（$128$ 字节），线程将访问第一个段和最后一个段之间的所有中间段。因此，访问的唯一段的总数是最后一个段索引与第一个段索引之差再加一。\n事务数量 = $(\\text{最后一个段索引}) - (\\text{第一个段索引}) + 1 = 3 - 0 + 1 = 4$。\n因此，对于初始参数，该线程束生成 $4$ 次内存事务。\n\n接下来，我们必须确定需要添加到基地址的最小非负填充量 $p$（以字节为单位），以使第一个访问的地址与 $128$ 字节的段边界对齐。对于线程 $t=0$，新的起始地址将是 $A'(0) = A_0 + \\delta + p$。\n给定 $\\delta = 44$，新的起始地址是 $A'(0) = A_0 + 44 + p$。\n为了使 $A'(0)$ 与 $128$ 字节边界对齐，它必须是 $128$ 的倍数。\n$$A_0 + 44 + p = k \\cdot 128$$\n对于某个整数 $k$。由于 $A_0$ 已经是 $128$ 的倍数，我们可以写成 $A_0 = m \\cdot 128$，其中 $m$ 是某个整数。\n$$m \\cdot 128 + 44 + p = k \\cdot 128$$\n$$44 + p = (k-m) \\cdot 128$$\n令 $k' = k-m$。我们需要找到最小的非负整数 $p$，使得对于某个整数 $k'$，有 $44 + p = k' \\cdot 128$。\n为确保 $p \\ge 0$，我们需要 $k' \\cdot 128 \\ge 44$。由于 $k'$ 必须是整数，因此 $k'$ 的最小可能值为 $1$。\n当 $k' = 1$ 时，我们有：\n$$44 + p = 128 \\implies p = 128 - 44 = 84$$\n所需的最小非负填充量是 $p=84$ 字节。\n\n最后，我们重新计算使用此填充后的内存事务数量。新的偏移量是 $\\delta' = \\delta + p = 44 + 84 = 128$。\n相对于 $A_0$ 的新地址函数是：\n$$A'_{rel}(t) = \\delta' + t \\cdot s \\cdot b = 128 + t \\cdot 3 \\cdot 4 = 128 + 12t$$\n第一个线程（$t=0$）现在访问 $A'_{rel}(0) = 128$。段索引为 $\\lfloor 128 / 128 \\rfloor = 1$。\n最后一个线程（$t=31$）访问 $A'_{rel}(31) = 128 + 12(31) = 128 + 372 = 500$。段索引为 $\\lfloor 500 / 128 \\rfloor = 3$。\n事务数量同样是段索引之差再加一：\n事务数量 = $3 - 1 + 1 = 3$。\n通过增加 $84$ 字节的填充，内存事务的数量从 $4$ 次减少到 $3$ 次，提高了内存访问效率。\n\n问题要求的是最小填充量 $p$。根据我们的计算，这个值是 $84$。", "answer": "$$\n\\boxed{84}\n$$", "id": "3138937"}, {"introduction": "高效的GPU编程不仅仅是管理资源和优化内存访问，更在于设计与硬件架构相契合的并行算法。本练习通过分析和比较两种并行“规约”（reduction）算法，将前面的概念融会贯通。您将使用工作-跨度（work-span）模型来量化一个通用并行策略与一个专为GPU优化的“线程束中心”（warp-centric）策略之间的性能差异，从而揭示最小化昂贵的块级同步对于发掘GPU潜力的重要性。[@problem_id:3138934]", "problem": "图形处理单元（GPU）以单指令多线程（SIMT）的方式执行线程：一个 warp 内的线程以锁步方式执行，而块级屏障同步（例如，Compute Unified Device Architecture (CUDA) 的函数 `__syncthreads()`）确保块内所有线程在继续执行前都到达同一点。在并行算法分析中，总功是原始操作的总数，而跨度（也称为关键路径长度）是必须顺序执行的最长依赖步骤链的长度。考虑在一个块内使用共享内存将 $B$ 个浮点值归约为单个总和。假设每次浮点加法耗费 $T_{\\text{add}}$ 个周期，每次块级屏障耗费 $T_{\\text{sync}}$ 个周期，并且可以忽略全局内存传输成本以及除这两种成本之外的任何指令级开销。\n\n您将比较两种块内归约策略，其中线程数为 $B=256$，warp 大小为 $W=32$：\n\n1. 完全在共享内存中实现的二叉树归约。在每个归约层级，活动线程对共享内存中的元素对执行加法，并使用块级屏障以确保线程在进入下一层级前重新汇合。假设在初始写入共享内存后有一次屏障，随后每个归约层级有一次屏障。\n\n2. 以 warp 为中心的归约。每个 warp 首先仅使用 warp 同步指令（在 warp 内无需块级屏障）归约其 $W$ 个值，然后每个 warp 的 0 号通道线程将其部分和写入共享内存，单个块级屏障确保这些部分和的可见性，最后由单个 warp 使用 warp 同步指令归约 $B/W$ 个部分和，无需进一步的块级屏障。\n\n从功和跨度的核心定义以及上述 SIMT 执行模型出发，完成以下任务：\n\n- 推导每种策略的功和跨度，作为 $B$、$W$、$T_{\\text{add}}$ 和 $T_{\\text{sync}}$ 的函数。\n- 根据这些推导，确定每种策略执行的块级屏障同步次数，以及在内存最密集步骤中由部分和同时占用的以 4 字节槽位数量衡量的峰值共享内存占用。\n- 使用您的跨度表达式，计算在 $B=256$、$W=32$、$T_{\\text{add}}=4$ 周期和 $T_{\\text{sync}}=80$ 周期的情况下，二叉树策略的预测跨度时间与以 warp 为中心的策略的预测跨度时间之比 $R$。\n\n将最终比率 $R$ 四舍五入到四位有效数字。报告 $R$ 为一个纯数字（无单位）。", "solution": "### 解题推导\n\n我们首先为每种策略推导功、跨度、屏障数量和共享内存占用的符号表达式。\n\n将 $B$ 个数归约为单个总和的总功是所需加法的次数，即 $B-1$。因此，对于两种策略，功都是 $(B-1)T_{\\text{add}}$。我们将重点关注显著不同的跨度。\n\n**策略 1：二叉树归约**\n\n1.  **功 ($W_1$)**：总加法次数为 $B-1$。总功为 $W_1 = (B-1) T_{\\text{add}}$。\n\n2.  **跨度 ($S_1$)**：$B$ 个元素的归约分 $\\log_2(B)$ 个层级进行。根据问题陈述，数据加载到共享内存后有一次初始屏障，然后每个归约层级后有一次屏障。关键路径包括一系列加法和屏障同步。\n    - 关键路径上的线程首先在初始屏障处等待：成本 $T_{\\text{sync}}$。\n    - 然后它参与 $\\log_2(B)$ 个层级的归约。每个层级涉及一次加法，然后是一次屏障。关键路径上线程的每个层级成本为 $T_{\\text{add}} + T_{\\text{sync}}$。\n    总跨度是这些顺序成本的总和：\n    $$S_1 = T_{\\text{sync}} (\\text{初始}) + \\sum_{i=1}^{\\log_2(B)} (T_{\\text{add}} + T_{\\text{sync}})$$\n    $$S_1 = T_{\\text{sync}} + \\log_2(B) \\cdot (T_{\\text{add}} + T_{\\text{sync}})$$\n    $$S_1 = (\\log_2(B)) T_{\\text{add}} + (1 + \\log_2(B)) T_{\\text{sync}}$$\n\n3.  **块级屏障数量 ($N_{\\text{sync},1}$)**：根据推导，有一次初始屏障和 $\\log_2(B)$ 个归约层级的每一次屏障。\n    $$N_{\\text{sync},1} = 1 + \\log_2(B)$$\n\n4.  **峰值共享内存占用 ($M_1$)**：该策略要求在归约开始时将所有 $B$ 个初始值存储在共享内存中。这是内存使用量最大的点。\n    $$M_1 = B \\text{ 槽位}$$\n\n**策略 2：以 warp 为中心的归约**\n\n1.  **功 ($W_2$)**：总加法次数仍然是 $B-1$。功为 $W_2 = (B-1) T_{\\text{add}}$。\n\n2.  **跨度 ($S_2$)**：跨度是其三个顺序阶段的跨度之和。\n    - **阶段 1：Warp 内归约。** 所有 $B/W$ 个 warp 并行操作。每个 warp 将 $W$ 个值归约为一个部分和。这需要 $\\log_2(W)$ 次使用 warp 同步操作（例如，shuffles）的顺序加法，这些操作不会产生 $T_{\\text{sync}}$ 成本。此阶段的跨度由单个 warp 的归约时间决定。\n      跨度 (阶段 1) = $(\\log_2(W)) T_{\\text{add}}$。\n    - **阶段 2：块级同步。** $B/W$ 个部分和被写入共享内存。然后调用单个块级屏障以确保所有这些写入对所有线程都可见。\n      跨度 (阶段 2) = $T_{\\text{sync}}$。\n    - **阶段 3：最终归约。** 单个 warp 从共享内存中读取 $B/W$ 个部分和，并将它们归约为最终值。此归约使用 warp 同步操作，需要 $\\log_2(B/W)$ 个顺序步骤。\n      跨度 (阶段 3) = $(\\log_2(B/W)) T_{\\text{add}}$。\n    总跨度 $S_2$ 是这三个阶段的跨度之和：\n    $$S_2 = (\\log_2(W)) T_{\\text{add}} + T_{\\text{sync}} + (\\log_2(B/W)) T_{\\text{add}}$$\n    使用对数性质 $\\log(a) + \\log(b) = \\log(ab)$，我们简化：\n    $$S_2 = (\\log_2(W) + \\log_2(B/W)) T_{\\text{add}} + T_{\\text{sync}}$$\n    $$S_2 = (\\log_2(B)) T_{\\text{add}} + T_{\\text{sync}}$$\n\n3.  **块级屏障数量 ($N_{\\text{sync},2}$)**：该策略明确只使用一个这样的屏障。\n    $$N_{\\text{sync},2} = 1$$\n\n4.  **峰值共享内存占用 ($M_2$)**：共享内存仅用于存储每个 warp 的中间部分和。有 $B/W$ 个这样的和。\n    $$M_2 = B/W \\text{ 槽位}$$\n\n### 数值计算\n\n现在我们代入给定值：$B=256$，$W=32$，$T_{\\text{add}}=4$ 周期，以及 $T_{\\text{sync}}=80$ 周期。\n\n首先，我们计算对数值：\n- $\\log_2(B) = \\log_2(256) = \\log_2(2^8) = 8$。\n- $\\log_2(W) = \\log_2(32) = \\log_2(2^5) = 5$。\n- $\\log_2(B/W) = \\log_2(256/32) = \\log_2(8) = 3$。\n\n**推导量总结：**\n\n| 指标 | 策略 1 (符号) | 策略 1 (数值) | 策略 2 (符号) | 策略 2 (数值) |\n|---|---|---|---|---|\n| 跨度 | $(\\log_2 B) T_{\\text{add}} + (1+\\log_2 B) T_{\\text{sync}}$ | $8 \\cdot 4 + (1+8) \\cdot 80 = 752$ 周期 | $(\\log_2 B) T_{\\text{add}} + T_{\\text{sync}}$ | $8 \\cdot 4 + 80 = 112$ 周期 |\n| 屏障数量 | $1 + \\log_2 B$ | $1+8=9$ | $1$ | $1$ |\n| 共享内存占用 | $B$ 槽位 | $256$ 槽位 | $B/W$ 槽位 | $256/32 = 8$ 槽位 |\n\n**计算比率 $R$**\n\n问题要求计算二叉树策略的跨度 ($S_1$) 与以 warp 为中心的策略的跨度 ($S_2$) 之比 $R$。\n\n$$R = \\frac{S_1}{S_2} = \\frac{(\\log_2(B)) T_{\\text{add}} + (1 + \\log_2(B)) T_{\\text{sync}}}{(\\log_2(B)) T_{\\text{add}} + T_{\\text{sync}}}$$\n\n使用计算出的跨度数值：\n\n$$R = \\frac{752}{112}$$\n\n简化分数：\n$$R = \\frac{376}{56} = \\frac{188}{28} = \\frac{94}{14} = \\frac{47}{7}$$\n\n现在，我们计算小数值并四舍五入到四位有效数字：\n$$R = \\frac{47}{7} \\approx 6.7142857...$$\n四舍五入到四位有效数字得到 $6.714$。", "answer": "$$\\boxed{6.714}$$", "id": "3138934"}]}