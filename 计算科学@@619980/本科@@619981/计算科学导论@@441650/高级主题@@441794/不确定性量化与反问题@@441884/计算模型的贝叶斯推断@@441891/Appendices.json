{"hands_on_practices": [{"introduction": "贝叶斯推断的核心在于利用数据更新我们对未知参数的信念。本练习通过一个经典的泊松-伽马共轭模型，为你提供了一个绝佳的实践机会。你将从头推导后验分布和后验预测分布，并深入理解“收缩效应”——即后验估计是如何在先验信念和数据证据之间取得平衡的 [@problem_id:3101554]。", "problem": "一个研究团队使用泊松过程来建模每个固定时间窗口内离散事件的计数。令 $y \\mid \\lambda \\sim \\mathrm{Poisson}(\\lambda)$，其中 $\\lambda$ 是该窗口的泊松率，并令 $\\lambda$ 的先验为 $\\lambda \\sim \\mathrm{Gamma}(a,b)$，其形状参数为 $a$，率参数为 $b$，当 $\\lambda > 0$ 时，其密度为 $p(\\lambda) = \\frac{b^{a}}{\\Gamma(a)} \\lambda^{a-1} \\exp(-b \\lambda)$。该团队在给定 $\\lambda$ 的情况下，收集了 $n$ 个独立同分布 (IID) 的观测值 $y_1, \\dots, y_n$，其联合似然基于泊松模型。\n\n从贝叶斯法则和上述定义出发，推导后验分布 $p(\\lambda \\mid y_1,\\dots,y_n)$ 及其均值，并简要解释后验均值如何在先验均值和样本均值之间表现出收缩效应。然后，通过对 $\\lambda$ 进行积分，推导给定观测数据时未来观测值 $y_{\\mathrm{new}}$ 的后验预测分布。\n\n最后，对于 $a = 3$，$b = 4$，$n = 5$ 且 $\\sum_{i=1}^{n} y_i = 12$ 的情况，计算 $y_{\\mathrm{new}} = 7$ 的后验预测概率。将最终概率表示为小数，并四舍五入到四位有效数字。没有物理单位；报告一个无单位的概率。", "solution": "该问题陈述被评估为具有科学依据、问题设定良好且客观。这是一个贝叶斯推断中的标准练习，具体涉及共轭先验对（伽马先验和泊松似然），这是计算科学和统计学中的一个核心概念。所有必要信息都已提供，任务定义明确。该问题是有效的。\n\n解答过程分为四个阶段：\n1.  泊松率 $\\lambda$ 的后验分布的推导。\n2.  后验均值的推导及收缩效应的解释。\n3.  新观测值 $y_{\\mathrm{new}}$ 的后验预测分布的推导。\n4.  使用推导出的分布对所需概率进行数值计算。\n\n**1. $\\lambda$ 的后验分布**\n\n根据贝叶斯法则，给定数据 $y_1, \\dots, y_n$（记为 $\\mathbf{y}$）的参数 $\\lambda$ 的后验分布与似然和先验的乘积成正比：\n$$p(\\lambda \\mid \\mathbf{y}) \\propto p(\\mathbf{y} \\mid \\lambda) \\, p(\\lambda)$$\n观测值 $y_1, \\dots, y_n$ 在给定 $\\lambda$ 的情况下是独立同分布 (IID) 的，服从泊松分布，$y_i \\mid \\lambda \\sim \\mathrm{Poisson}(\\lambda)$。联合似然函数是各个概率质量函数的乘积：\n$$p(\\mathbf{y} \\mid \\lambda) = \\prod_{i=1}^{n} p(y_i \\mid \\lambda) = \\prod_{i=1}^{n} \\frac{\\lambda^{y_i} \\exp(-\\lambda)}{y_i!} = \\frac{\\lambda^{\\sum_{i=1}^{n} y_i} \\exp(-n\\lambda)}{\\prod_{i=1}^{n} y_i!}$$\n在寻找 $\\lambda$ 的后验分布时，我们可以将任何不依赖于 $\\lambda$ 的项视为比例常数的一部分。因此，似然函数正比于：\n$$p(\\mathbf{y} \\mid \\lambda) \\propto \\lambda^{\\sum_{i=1}^{n} y_i} \\exp(-n\\lambda)$$\n$\\lambda$ 的先验分布是伽马分布，$\\lambda \\sim \\mathrm{Gamma}(a,b)$，其概率密度函数 (PDF) 为：\n$$p(\\lambda) = \\frac{b^a}{\\Gamma(a)} \\lambda^{a-1} \\exp(-b\\lambda) \\propto \\lambda^{a-1} \\exp(-b\\lambda)$$\n现在，我们将似然与先验相乘：\n$$p(\\lambda \\mid \\mathbf{y}) \\propto \\left( \\lambda^{\\sum y_i} \\exp(-n\\lambda) \\right) \\cdot \\left( \\lambda^{a-1} \\exp(-b\\lambda) \\right)$$\n合并与 $\\lambda$ 相关的项：\n$$p(\\lambda \\mid \\mathbf{y}) \\propto \\lambda^{a + \\sum y_i - 1} \\exp(-(b+n)\\lambda)$$\n这是伽马分布的核。我们可以识别出这个后验分布的参数。后验分布是 $\\lambda \\mid \\mathbf{y} \\sim \\mathrm{Gamma}(a', b')$，其中更新后的参数为：\n$$a' = a + \\sum_{i=1}^{n} y_i$$\n$$b' = b + n$$\n完整的后验 PDF 是 $p(\\lambda \\mid \\mathbf{y}) = \\frac{(b')^{a'}}{\\Gamma(a')} \\lambda^{a'-1} \\exp(-b'\\lambda)$。\n\n**2. 后验均值与收缩效应**\n\n形状参数为 $\\alpha$、率参数为 $\\beta$ 的伽马分布的均值为 $E[X] = \\frac{\\alpha}{\\beta}$。\n因此，$\\lambda$ 的后验均值是后验分布 $\\mathrm{Gamma}(a', b')$ 的均值：\n$$E[\\lambda \\mid \\mathbf{y}] = \\frac{a'}{b'} = \\frac{a + \\sum_{i=1}^{n} y_i}{b + n}$$\n为了解释收缩效应，我们可以重写这个表达式。$\\lambda$ 的先验均值是 $E[\\lambda] = \\frac{a}{b}$。观测值的样本均值是 $\\bar{y} = \\frac{1}{n} \\sum_{i=1}^{n} y_i$，这是 $\\lambda$ 的最大似然估计。\n后验均值可以表示为先验均值和样本均值的加权平均：\n$$E[\\lambda \\mid \\mathbf{y}] = \\frac{a + n\\bar{y}}{b + n} = \\frac{b(a/b) + n\\bar{y}}{b+n} = \\frac{b}{b+n} E[\\lambda] + \\frac{n}{b+n} \\bar{y}$$\n令 $w = \\frac{b}{b+n}$。那么 $1-w = \\frac{n}{b+n}$，后验均值为：\n$$E[\\lambda \\mid \\mathbf{y}] = w E[\\lambda] + (1-w) \\bar{y}$$\n由于 $b > 0$ 且 $n > 0$，权重 $w$ 在 $0$ 和 $1$ 之间。后验均值是先验均值和样本均值的加权平均。这展示了收缩效应：后验估计被从样本均值 $\\bar{y}$“拉向”先验均值 $E[\\lambda]$。收缩的程度由 $b$（代表先验的“强度”或“伪样本量”）和 $n$（数据的样本量）的相对值决定。\n\n**3. 后验预测分布**\n\n新观测值 $y_{\\mathrm{new}}$ 的后验预测分布是通过将新观测值的似然在参数 $\\lambda$ 的后验分布上进行边缘化（积分）得到的：\n$$p(y_{\\mathrm{new}} \\mid \\mathbf{y}) = \\int_{0}^{\\infty} p(y_{\\mathrm{new}} \\mid \\lambda) \\, p(\\lambda \\mid \\mathbf{y}) \\, d\\lambda$$\n我们代入 $y_{\\mathrm{new}}$ 的泊松似然和 $\\lambda$ 的伽马后验分布：\n$$p(y_{\\mathrm{new}} \\mid \\mathbf{y}) = \\int_{0}^{\\infty} \\left( \\frac{\\lambda^{y_{\\mathrm{new}}} \\exp(-\\lambda)}{y_{\\mathrm{new}}!} \\right) \\left( \\frac{(b')^{a'}}{\\Gamma(a')} \\lambda^{a'-1} \\exp(-b'\\lambda) \\right) d\\lambda$$\n我们将不依赖于 $\\lambda$ 的项移到积分外：\n$$p(y_{\\mathrm{new}} \\mid \\mathbf{y}) = \\frac{(b')^{a'}}{y_{\\mathrm{new}}! \\, \\Gamma(a')} \\int_{0}^{\\infty} \\lambda^{y_{\\mathrm{new}} + a' - 1} \\exp(-(b'+1)\\lambda) \\, d\\lambda$$\n该积分的形式为 $\\int_{0}^{\\infty} x^{\\alpha-1} \\exp(-\\beta x) dx$，其计算结果为 $\\frac{\\Gamma(\\alpha)}{\\beta^{\\alpha}}$。对于我们的积分，$\\alpha = a' + y_{\\mathrm{new}}$ 且 $\\beta = b' + 1$。\n$$p(y_{\\mathrm{new}} \\mid \\mathbf{y}) = \\frac{(b')^{a'}}{y_{\\mathrm{new}}! \\, \\Gamma(a')} \\frac{\\Gamma(a' + y_{\\mathrm{new}})}{(b'+1)^{a' + y_{\\mathrm{new}}}}$$\n重新整理这些项得到：\n$$p(y_{\\mathrm{new}} \\mid \\mathbf{y}) = \\frac{\\Gamma(a' + y_{\\mathrm{new}})}{y_{\\mathrm{new}}! \\, \\Gamma(a')} \\frac{(b')^{a'}}{(b'+1)^{a'}} \\frac{1}{(b'+1)^{y_{\\mathrm{new}}}}$$\n$$p(y_{\\mathrm{new}} \\mid \\mathbf{y}) = \\frac{\\Gamma(a' + y_{\\mathrm{new}})}{y_{\\mathrm{new}}! \\, \\Gamma(a')} \\left( \\frac{b'}{b'+1} \\right)^{a'} \\left( \\frac{1}{b'+1} \\right)^{y_{\\mathrm{new}}}$$\n使用广义二项式系数的恒等式 $\\binom{n}{k} = \\frac{\\Gamma(n+1)}{k! \\Gamma(n-k+1)}$，我们可以写出 $\\frac{\\Gamma(r+k)}{k! \\Gamma(r)} = \\binom{r+k-1}{k}$。这里，$r=a'$ 且 $k=y_{\\mathrm{new}}$：\n$$p(y_{\\mathrm{new}} \\mid \\mathbf{y}) = \\binom{a' + y_{\\mathrm{new}} - 1}{y_{\\mathrm{new}}} \\left( \\frac{b'}{b'+1} \\right)^{a'} \\left( \\frac{1}{b'+1} \\right)^{y_{\\mathrm{new}}}$$\n这是负二项分布的概率质量函数，$y_{\\mathrm{new}} \\mid \\mathbf{y} \\sim \\mathrm{NB}(r=a', p=\\frac{b'}{b'+1})$。\n\n**4. 数值计算**\n\n给定以下值：\n- 先验参数：$a=3$, $b=4$\n- 数据摘要：$n=5$, $\\sum_{i=1}^{n} y_i = 12$\n首先，我们计算后验分布的参数 $a'$ 和 $b'$：\n$$a' = a + \\sum_{i=1}^{n} y_i = 3 + 12 = 15$$\n$$b' = b + n = 4 + 5 = 9$$\n我们需要计算新观测值 $y_{\\mathrm{new}} = 7$ 的后验预测概率。使用推导出的 PMF：\n$$P(y_{\\mathrm{new}} = 7 \\mid \\mathbf{y}) = \\binom{15 + 7 - 1}{7} \\left( \\frac{9}{9+1} \\right)^{15} \\left( \\frac{1}{9+1} \\right)^{7}$$\n$$P(y_{\\mathrm{new}} = 7 \\mid \\mathbf{y}) = \\binom{21}{7} \\left( \\frac{9}{10} \\right)^{15} \\left( \\frac{1}{10} \\right)^{7}$$\n首先，计算二项式系数：\n$$\\binom{21}{7} = \\frac{21!}{7!(21-7)!} = \\frac{21!}{7!14!} = \\frac{21 \\times 20 \\times 19 \\times 18 \\times 17 \\times 16 \\times 15}{7 \\times 6 \\times 5 \\times 4 \\times 3 \\times 2 \\times 1} = 116280$$\n现在，将此值代入概率表达式：\n$$P(y_{\\mathrm{new}} = 7 \\mid \\mathbf{y}) = 116280 \\times (0.9)^{15} \\times (0.1)^7$$\n使用计算器计算幂：\n$$(0.9)^{15} \\approx 0.205891132$$\n$$(0.1)^7 = 10^{-7}$$\n所以，概率为：\n$$P(y_{\\mathrm{new}} = 7 \\mid \\mathbf{y}) = 116280 \\times 0.205891132 \\times 10^{-7} \\approx 23941.59 \\times 10^{-7} \\approx 0.002394159$$\n将结果四舍五入到四位有效数字，得到 $0.002394$。", "answer": "$$\\boxed{0.002394}$$", "id": "3101554"}, {"introduction": "将贝叶斯方法应用于实际的科学计算模型是本课程的关键一环。在本练习中，你将为一个由热传导方程描述的物理系统校准其关键参数——热扩散系数 $k$ [@problem_id:3101556]。这项实践不仅能让你掌握如何使用观测数据来推断模型的未知参数，还能让你直观地感受到观测噪声和模型离散化误差是如何共同影响推断结果的不确定性的。", "problem": "要求您为一个一维热传导模型实现贝叶斯校准，以使用高斯观测模型推断热扩散系数参数 $k$，并研究后验分布如何随观测噪声和计算模型不同时间离散化的变化而变化。所有量均为无量纲，因此不使用物理单位。\n\n正向模型说明：\n- 一维热方程为\n$$\n\\frac{\\partial u}{\\partial t}(x,t) = k \\frac{\\partial^2 u}{\\partial x^2}(x,t), \\quad x \\in (0,1), \\ t \\ge 0,\n$$\n具有齐次狄利克雷边界条件 $u(0,t)=0$ 和 $u(1,t)=0$，以及初始条件 $u(x,0)=\\sin(\\pi x)$。\n- 对于此初边值问题，分离变量法意味着解保持在第一本征模。通过 $u(x,t)=a(t)\\sin(\\pi x)$ 定义振幅 $a(t)$。该振幅满足线性常微分方程\n$$\n\\frac{da}{dt}(t) = -\\lambda a(t), \\quad \\text{with} \\ \\lambda = k\\pi^2, \\quad a(0)=1.\n$$\n- 精确解为 $a_{\\text{exact}}(t) = \\exp(-\\lambda t)$，因此 $u(\\tfrac{1}{2},t)=a_{\\text{exact}}(t)$ 因为 $\\sin(\\pi/2)=1$。\n\n观测模型：\n- 我们在单一空间位置 $x=\\tfrac{1}{2}$ 和三个时间点 $t \\in \\{0.02, 0.05, 0.1\\}$ 观测温度。将这些观测值堆叠成一个长度为3的向量 $y=[u(\\tfrac{1}{2},0.02), u(\\tfrac{1}{2},0.05), u(\\tfrac{1}{2},0.1)]^\\top$。\n- 观测模型是高斯的：$y \\sim \\mathcal{N}(u(k), \\sigma^2 I)$，其中 $u(k)$ 是给定 $k$ 的模型预测向量，$\\sigma>0$ 是观测噪声的标准差，$I$ 是大小为3的单位矩阵。\n- 合成数据由真实参数 $k_{\\text{true}}=0.12$ 下的精确模型生成，且不添加噪声，即 $y = [\\exp(-\\pi^2 k_{\\text{true}} \\cdot 0.02), \\exp(-\\pi^2 k_{\\text{true}} \\cdot 0.05), \\exp(-\\pi^2 k_{\\text{true}} \\cdot 0.1)]^\\top$。\n\n计算模型离散化：\n- 不使用精确振幅，而是通过应用于线性常微分方程 $da/dt = -\\lambda a$（其中 $\\lambda = k\\pi^2$）的时间步进格式来近似 $a(t)$，使用基本步长 $\\Delta t = T/N_{\\text{base}}$（其中 $T=0.1$，$N_{\\text{base}} \\in \\mathbb{N}$）从 $t=0$ 积分到目标时间。对于每个观测时间 $t_j \\in \\{0.02,0.05,0.1\\}$，使用 $N_j = t_j/\\Delta t$ 步（对于此处指定的值，这些是整数）。\n- 考虑两种时间离散化方法：\n    - 离散化 $\\mathcal{D}_{\\text{EE},10}$：使用 $N_{\\text{base}}=10$ 的 explicit Euler 方法，更新规则为 $a_{n+1} = a_n - \\Delta t \\lambda a_n$。\n    - 离散化 $\\mathcal{D}_{\\text{CN},100}$：使用 $N_{\\text{base}}=100$ 的 Crank–Nicolson 方法，更新规则为 $a_{n+1} = a_n \\frac{1 - \\tfrac{1}{2}\\Delta t \\lambda}{1 + \\tfrac{1}{2}\\Delta t \\lambda}$。\n- 对于每种离散化方法和每个 $k$，通过从 $a(0)=1$ 步进到每个 $t_j \\in \\{0.02,0.05,0.1\\}$ 对应的 $a(t_j)$，并计算 $u(\\tfrac{1}{2},t_j)=a(t_j)$，来获得预测的观测向量 $u(k)$。\n\n贝叶斯校准：\n- 对 $k$ 使用在区间 $[k_{\\min}, k_{\\max}] = [0.05, 0.25]$ 上的均匀先验，在该区间外为零。\n- 给定数据 $y$ 和选定的 $\\sigma>0$，后验密度（在忽略归一化常数的情况下）为，当 $k \\in [0.05, 0.25]$ 时，$p(k\\mid y) \\propto \\exp\\left(-\\frac{1}{2\\sigma^2}\\|y - u(k)\\|_2^2\\right)$，否则为 $0$。\n- 通过在 $[0.05,0.25]$ 上包含 $N_k = 2001$ 个等距点的均匀 $k$ 值网格上进行数值积分，来近似后验期望。具体来说，使用从未归一化后验导出的归一化积分权重，计算后验均值 $\\mathbb{E}[k\\mid y]$ 和后验标准差 $\\sqrt{\\mathbb{V}[k\\mid y]}$。\n\n测试套件：\n- 使用以下六个测试用例来研究后验对观测噪声水平 $\\sigma$ 和计算离散化的敏感性：\n    1. 用例1：离散化 $\\mathcal{D}_{\\text{EE},10}$，$\\sigma=0.005$。\n    2. 用例2：离散化 $\\mathcal{D}_{\\text{EE},10}$，$\\sigma=0.02$。\n    3. 用例3：离散化 $\\mathcal{D}_{\\text{EE},10}$，$\\sigma=0.1$。\n    4. 用例4：离散化 $\\mathcal{D}_{\\text{CN},100}$，$\\sigma=0.005$。\n    5. 用例5：离散化 $\\mathcal{D}_{\\text{CN},100}$，$\\sigma=0.02$。\n    6. 用例6：离散化 $\\mathcal{D}_{\\text{CN},100}$，$\\sigma=0.1$。\n\n要求输出：\n- 对于每个测试用例，使用指定的先验、数据、离散化和 $\\sigma$ 计算 $k$ 的后验均值和后验标准差。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。该列表应按 $[\\mu_1, s_1, \\mu_2, s_2, \\mu_3, s_3, \\mu_4, s_4, \\mu_5, s_5, \\mu_6, s_6]$ 的顺序排列，其中 $\\mu_i$ 和 $s_i$ 分别是用例 $i$ 的后验均值和后验标准差，每个值都四舍五入到6位小数。", "solution": "我们从单位区间上的齐次狄利克雷边界条件和初始条件 $u(x,0)=\\sin(\\pi x)$ 的一维热方程 $\\frac{\\partial u}{\\partial t} = k \\frac{\\partial^2 u}{\\partial x^2}$ 开始。通过分离变量法和带狄利克雷条件的拉普拉斯算子的本征函数展开，解可以表示为空间正弦模态的和。鉴于特定的初始条件，只有第一本征模存在，所以\n$$\nu(x,t) = a(t)\\sin(\\pi x),\n$$\n其振幅 $a(t)$ 满足\n$$\n\\frac{da}{dt}(t) = -\\lambda a(t), \\quad \\lambda = k\\pi^2, \\quad a(0)=1.\n$$\n这是一个线性常微分方程，其精确解为 $a_{\\text{exact}}(t) = \\exp(-\\lambda t)$。在 $x=\\tfrac{1}{2}$ 处，$\\sin(\\pi/2)=1$，因此 $u(\\tfrac{1}{2},t)=a(t)$。\n\n观测模型规定，在时间 $t \\in \\{0.02,0.05,0.1\\}$ 处的观测向量 $y \\in \\mathbb{R}^3$ 满足高斯似然\n$$\ny \\sim \\mathcal{N}(u(k), \\sigma^2 I),\n$$\n其中 $u(k) \\in \\mathbb{R}^3$ 堆叠了 $t_j \\in \\{0.02,0.05,0.1\\}$ 时的模型输出 $u(\\tfrac{1}{2}, t_j)$。合成数据由 $k_{\\text{true}}=0.12$ 时的精确模型生成，且不含噪声：\n$$\ny = \\left[\\exp(-\\pi^2 \\cdot 0.12 \\cdot 0.02), \\ \\exp(-\\pi^2 \\cdot 0.12 \\cdot 0.05), \\ \\exp(-\\pi^2 \\cdot 0.12 \\cdot 0.1)\\right]^\\top.\n$$\n\n对于不同离散化下的计算建模，我们使用单步格式积分振幅常微分方程，基本步长为 $\\Delta t = T/N_{\\text{base}}$ 且 $T=0.1$。对于每个观测时间 $t_j$，步数为 $N_j = t_j/\\Delta t$（对于给定的时间和基本步长，这些都是整数）。所用格式为：\n- explicit Euler（记作 $\\mathcal{D}_{\\text{EE},10}$）：$a_{n+1} = a_n - \\Delta t \\lambda a_n$。经过 $N_j$ 步后，$a(t_j)$ 通过从 $a(0)=1$ 开始重复应用因子 $(1-\\Delta t \\lambda)$ 来近似。\n- Crank–Nicolson（记作 $\\mathcal{D}_{\\text{CN},100}$）：$a_{n+1} = a_n \\frac{1 - \\tfrac{1}{2}\\Delta t \\lambda}{1 + \\tfrac{1}{2}\\Delta t \\lambda}$。经过 $N_j$ 步后，$a(t_j)$ 通过从 $a(0)=1$ 开始重复应用因子 $\\frac{1 - \\tfrac{1}{2}\\Delta t \\lambda}{1 + \\tfrac{1}{2}\\Delta t \\lambda}$ 来近似。\n\n贝叶斯推断根据贝叶斯定理进行。在 $[k_{\\min}, k_{\\max}] = [0.05, 0.25]$ 上使用均匀先验，后验密度为\n$$\np(k\\mid y) = \\frac{p(y\\mid k) p(k)}{\\int_{k_{\\min}}^{k_{\\max}} p(y\\mid \\kappa) p(\\kappa)\\, d\\kappa}\n\\propto \\exp\\left(-\\frac{1}{2\\sigma^2}\\|y - u(k)\\|_2^2\\right) \\ \\mathbf{1}_{[0.05,0.25]}(k),\n$$\n其中 $\\mathbf{1}_{[0.05,0.25]}$ 是指示函数。为了计算后验期望（如均值和方差），我们通过在 $[0.05,0.25]$ 上包含 $N_k=2001$ 个点的均匀网格上进行数值积分来近似积分。设网格为 $\\{k_i\\}_{i=1}^{N_k}$，并定义未归一化权重\n$$\nw_i = \\exp\\left(-\\frac{1}{2\\sigma^2}\\|y - u(k_i)\\|_2^2\\right).\n$$\n为避免在 $\\sigma$ 很小时出现数值下溢，我们在进行指数化之前通过减去 $\\max_i \\log w_i$ 来执行 log-sum-exp 稳定化；这不会改变归一化的后验权重，因为它将所有权重乘以同一个常数。将归一化权重记为 $\\tilde{w}_i = w_i / \\sum_{j=1}^{N_k} w_j$。那么后验均值和方差可近似为\n$$\n\\mathbb{E}[k\\mid y] \\approx \\sum_{i=1}^{N_k} k_i \\tilde{w}_i, \\quad\n\\mathbb{V}[k\\mid y] \\approx \\sum_{i=1}^{N_k} (k_i - \\mathbb{E}[k\\mid y])^2 \\tilde{w}_i,\n$$\n后验标准差为 $\\sqrt{\\mathbb{V}[k\\mid y]}$。\n\n每个测试用例的算法步骤：\n1. 固定离散化格式和 $N_{\\text{base}}$ 以确定 $\\Delta t = 0.1/N_{\\text{base}}$ 以及对于 $t_j \\in \\{0.02,0.05,0.1\\}$ 的步数 $N_j$。\n2. 在 $[0.05,0.25]$ 上构建网格 $\\{k_i\\}_{i=1}^{2001}$。\n3. 对于每个 $k_i$，计算 $\\lambda_i = \\pi^2 k_i$，并使用所选格式将振幅从 $a(0)=1$ 步进到每个 $t_j$ 对应的 $a(t_j)$，从而得到模型预测值 $u(k_i) \\in \\mathbb{R}^3$。\n4. 形成残差 $r_i = y - u(k_i)$，计算 $e_i = \\|r_i\\|_2^2$，然后计算稳定化的未归一化对数权重 $\\ell_i = -\\frac{1}{2\\sigma^2} e_i$，通过减去 $\\max_i \\ell_i$ 进行移位，取指数得到 $w_i$，并归一化以获得 $\\tilde{w}_i$。\n5. 使用归一化权重计算后验均值和标准差。\n\n敏感性预期：\n- 对于较小的 $\\sigma$（例如 $\\sigma=0.005$），似然函数呈尖锐峰值，并且使用高精度离散化（$N_{\\text{base}}=100$ 的 Crank-Nicolson），后验均值应非常接近 $k_{\\text{true}}=0.12$，且后验标准差很小。而对于更粗糙、偏差更大的离散化（$N_{\\text{base}}=10$ 的 explicit Euler），模型差异将使后验均值偏离 $0.12$，但由于似然函数很尖锐，后验标准差仍然会很小。\n- 对于较大的 $\\sigma$（例如 $\\sigma=0.1$），似然函数较为平坦，因此后验分布趋近于先验分布；后验均值向先验中心 $(0.05+0.25)/2 = 0.15$ 移动，后验标准差则向 $[0.05,0.25]$ 上均匀先验的标准差增大。\n\n该程序完全按照规定实现了上述步骤，按给定顺序评估六个测试用例，并打印单行输出，其中包含扁平化列表 $[\\mu_1, s_1, \\mu_2, s_2, \\mu_3, s_3, \\mu_4, s_4, \\mu_5, s_5, \\mu_6, s_6]$，每个值都四舍五入到6位小数。", "answer": "```python\nimport numpy as np\n\ndef generate_synthetic_data(k_true, times):\n    lam_true = (np.pi ** 2) * k_true\n    return np.exp(-lam_true * times)\n\ndef forward_amplitudes(k_vals, times, scheme, n_base):\n    \"\"\"\n    Compute model predictions u(1/2, t_j) = a(t_j) for each k in k_vals and each t in times,\n    using time-stepping schemes for the ODE a' = -lambda a, a(0)=1, lambda = pi^2 * k.\n    \n    Parameters:\n        k_vals: array of shape (nk,)\n        times: array of shape (nt,)\n        scheme: 'EE' for explicit Euler, 'CN' for Crank-Nicolson\n        n_base: number of base steps to reach T = max(times)\n    Returns:\n        preds: array of shape (nk, nt)\n    \"\"\"\n    T = np.max(times)\n    dt = T / n_base\n    # Ensure times are integer multiples of dt per problem setup\n    steps_per_time = np.round(times / dt).astype(int)\n    lam = (np.pi ** 2) * k_vals[:, None]  # shape (nk,1) for broadcasting\n    preds = np.empty((k_vals.shape[0], times.shape[0]), dtype=float)\n    if scheme == 'EE':\n        # factor = (1 - dt * lambda)\n        factor = (1.0 - dt * lam)\n        # For each time, raise to the power N_j\n        for j, Nj in enumerate(steps_per_time):\n            preds[:, j] = np.power(factor[:, 0], Nj)\n    elif scheme == 'CN':\n        # factor = (1 - 0.5 dt lambda) / (1 + 0.5 dt lambda)\n        num = (1.0 - 0.5 * dt * lam)\n        den = (1.0 + 0.5 * dt * lam)\n        factor = num / den\n        for j, Nj in enumerate(steps_per_time):\n            preds[:, j] = np.power(factor[:, 0], Nj)\n    else:\n        raise ValueError(\"Unknown scheme. Use 'EE' or 'CN'.\")\n    return preds\n\ndef posterior_stats(y, times, scheme, n_base, sigma, k_min=0.05, k_max=0.25, nk=2001):\n    \"\"\"\n    Compute posterior mean and std of k given data y, model discretization, and sigma.\n    Uniform prior on [k_min, k_max], quadrature over equally spaced grid nk.\n    \"\"\"\n    k_grid = np.linspace(k_min, k_max, nk)\n    preds = forward_amplitudes(k_grid, times, scheme, n_base)  # (nk, nobs)\n    # residuals: (nk, nobs)\n    residuals = preds - y[None, :]\n    err2 = np.sum(residuals ** 2, axis=1)  # (nk,)\n    # Stabilized log-weights\n    logw = -0.5 * err2 / (sigma ** 2)\n    logw -= np.max(logw)\n    w = np.exp(logw)\n    w_sum = np.sum(w)\n    if w_sum == 0.0 or not np.isfinite(w_sum):\n        # Fallback to near-uniform if under/overflow occurs\n        w = np.ones_like(w) / w.size\n        w_sum = 1.0\n    # Normalize\n    w /= w_sum\n    mean = np.sum(k_grid * w)\n    var = np.sum(((k_grid - mean) ** 2) * w)\n    std = np.sqrt(max(var, 0.0))\n    return mean, std\n\ndef solve():\n    # Problem parameters\n    times = np.array([0.02, 0.05, 0.1], dtype=float)\n    k_true = 0.12\n    y = generate_synthetic_data(k_true, times)\n\n    # Test cases: (scheme, n_base, sigma)\n    test_cases = [\n        ('EE', 10, 0.005),\n        ('EE', 10, 0.02),\n        ('EE', 10, 0.1),\n        ('CN', 100, 0.005),\n        ('CN', 100, 0.02),\n        ('CN', 100, 0.1),\n    ]\n\n    results = []\n    for scheme, n_base, sigma in test_cases:\n        mean, std = posterior_stats(y, times, scheme, n_base, sigma)\n        results.append(f\"{mean:.6f}\")\n        results.append(f\"{std:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3101556"}, {"introduction": "一个负责任的建模者不仅要构建模型，还要理解其局限性。本练习引入了灵敏度分析 (sensitivity analysis)，这是一种评估模型结论对先验假设依赖程度的强大技术。通过推导并计算后验期望对先验超参数 $\\eta$ 的导数，你将学会量化模型的稳健性，这是建立可信计算模型过程中至关重要的一步 [@problem_id:3101531]。", "problem": "考虑一个标量贝叶斯参数估计问题，其中有单一潜参数 $\\theta$ 和观测值 $y_1,\\dots,y_n$，这些观测值是独立同分布 (i.i.d.) 的。数据生成模型为 $$y_i \\mid \\theta \\sim \\mathcal{N}(\\theta, \\sigma^2) \\text{ for } i=1,\\dots,n,$$ 其中 $\\sigma^2$ 已知且严格为正。$\\theta$ 的先验分布为 $$\\theta \\mid \\eta \\sim \\mathcal{N}(\\mu_0, \\tau^2(\\eta)),$$ 其中超参数 $\\eta \\in \\mathbb{R}$ 通过 $$\\tau^2(\\eta) = \\exp(\\eta)$$ 控制先验方差。令 $\\bar{y} = \\frac{1}{n}\\sum_{i=1}^n y_i$ 表示样本均值。您需要通过计算导数 $$\\frac{\\partial}{\\partial \\eta}\\,\\mathbb{E}[\\theta \\mid y]$$ 来分析后验期望 $\\mathbb{E}[\\theta \\mid y]$ 相对于超参数 $\\eta$ 的敏感性。请从上面给出的似然和先验的基本定义出发。使用贝叶斯法则和正态分布的标准性质，推导出 $\\mathbb{E}[\\theta \\mid y]$ 作为 $\\eta$ 函数的显式表达式，然后使用链式法则对其关于 $\\eta$ 求导。不要在未推导的情况下假定任何关于共轭性的结论；请通过对 $\\theta$ 和 $y$ 的联合密度的指数部分进行配方来确定后验分布及其期望。一旦您获得了导数的闭式表达式（用 $n$, $\\sigma^2$, $\\mu_0$, $\\bar{y}$ 和 $\\eta$ 表示），请实现一个程序，为以下参数设置的测试套件计算该导数。所有计算均为纯数值计算；不涉及物理单位。您的程序必须输出四舍五入到六位小数的浮点值。\n\n测试套件（每个案例指定 $y$ 为一个列表，以及 $\\sigma^2$, $\\mu_0$ 和 $\\eta$）：\n1. $y = [\\,1.2,\\,0.7,\\,1.0,\\,0.9,\\,1.1\\,],\\ \\sigma^2 = 0.25,\\ \\mu_0 = 0.0,\\ \\eta = 0.0.$\n2. $y = [\\,1.2,\\,0.7,\\,1.0,\\,0.9,\\,1.1\\,],\\ \\sigma^2 = 0.25,\\ \\mu_0 = 1.5,\\ \\eta = 0.0.$\n3. $y = [\\,1.2,\\,0.7,\\,1.0,\\,0.9,\\,1.1\\,],\\ \\sigma^2 = 0.25,\\ \\mu_0 = 0.0,\\ \\eta = 5.0.$\n4. $y = [\\,1.2,\\,0.7,\\,1.0,\\,0.9,\\,1.1\\,],\\ \\sigma^2 = 0.25,\\ \\mu_0 = 0.0,\\ \\eta = -5.0.$\n5. $y = [\\,2.0,\\,2.0,\\,2.0\\,],\\ \\sigma^2 = 1.0,\\ \\mu_0 = 2.0,\\ \\eta = 1.0.$\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，其顺序与测试套件中的顺序相同。例如，输出格式必须与 `[result1,result2,result3,result4,result5]` 完全一样，其中每个结果都是一个四舍五入到六位小数的浮点数（例如 `0.123456` 或 `-0.000314`）。", "solution": "问题陈述被评估为有效。它在贝叶斯统计理论中有科学依据，是适定的、客观的，并包含了唯一解所需的所有必要信息。因此，我们可以继续进行推导和实现。\n\n目标是计算导数 $\\frac{\\partial}{\\partial \\eta}\\,\\mathbb{E}[\\theta \\mid y]$，它量化了参数 $\\theta$ 的后验期望相对于超参数 $\\eta$ 的敏感性。推导过程分为四个步骤：1. 构建似然和先验分布。2. 使用贝叶斯法则求 $\\theta$ 的后验分布。3. 确定后验期望 $\\mathbb{E}[\\theta \\mid y]$。4. 对该期望关于 $\\eta$ 求导。\n\n**1. 似然与先验**\n\n数据生成模型指定观测值 $y_1, \\dots, y_n$ 在给定 $\\theta$ 的条件下是独立同分布 (i.i.d.) 的，遵循正态分布 $y_i \\mid \\theta \\sim \\mathcal{N}(\\theta, \\sigma^2)$。完整数据集 $y = (y_1, \\dots, y_n)$ 的似然函数 $p(y \\mid \\theta)$ 是各个概率密度的乘积：\n$$p(y \\mid \\theta) = \\prod_{i=1}^n p(y_i \\mid \\theta) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_i - \\theta)^2}{2\\sigma^2}\\right)$$\n为了确定 $\\theta$ 的后验分布，我们可以忽略常数因子，只关注依赖于 $\\theta$ 的项。因此，似然函数正比于：\n$$p(y \\mid \\theta) \\propto \\exp\\left(-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n (y_i - \\theta)^2\\right)$$\n指数中的和式可以用样本均值 $\\bar{y} = \\frac{1}{n}\\sum_{i=1}^n y_i$ 来重新表示：\n$$\\sum_{i=1}^n (y_i - \\theta)^2 = \\sum_{i=1}^n ((y_i - \\bar{y}) - (\\theta - \\bar{y}))^2 = \\sum_{i=1}^n (y_i - \\bar{y})^2 + n(\\theta - \\bar{y})^2$$\n其中交叉项因为 $\\sum_{i=1}^n (y_i - \\bar{y}) = 0$ 而消失。由于 $\\sum_{i=1}^n(y_i - \\bar{y})^2$ 不依赖于 $\\theta$，似然函数简化为：\n$$p(y \\mid \\theta) \\propto \\exp\\left(-\\frac{n(\\theta - \\bar{y})^2}{2\\sigma^2}\\right) = \\exp\\left(-\\frac{(\\theta - \\bar{y})^2}{2(\\sigma^2/n)}\\right)$$\n\n$\\theta$ 的先验分布给定为 $\\theta \\mid \\eta \\sim \\mathcal{N}(\\mu_0, \\tau^2(\\eta))$，其中 $\\tau^2(\\eta) = \\exp(\\eta)$。先验密度为：\n$$p(\\theta \\mid \\eta) \\propto \\exp\\left(-\\frac{(\\theta - \\mu_0)^2}{2\\tau^2(\\eta)}\\right)$$\n\n**2. 后验分布**\n\n根据贝叶斯法则，后验密度 $p(\\theta \\mid y, \\eta)$ 正比于似然与先验的乘积：\n$$p(\\theta \\mid y, \\eta) \\propto p(y \\mid \\theta) \\cdot p(\\theta \\mid \\eta)$$\n$$p(\\theta \\mid y, \\eta) \\propto \\exp\\left(-\\frac{(\\theta - \\bar{y})^2}{2(\\sigma^2/n)}\\right) \\exp\\left(-\\frac{(\\theta - \\mu_0)^2}{2\\tau^2(\\eta)}\\right)$$\n合并指数，我们得到：\n$$p(\\theta \\mid y, \\eta) \\propto \\exp\\left( -\\frac{1}{2} \\left[ \\frac{(\\theta - \\bar{y})^2}{\\sigma^2/n} + \\frac{(\\theta - \\mu_0)^2}{\\tau^2(\\eta)} \\right] \\right)$$\n为了确定后验分布的形式，我们对指数中的 $\\theta$ 进行配方。令方括号中的表达式为 $Q(\\theta)$：\n$$Q(\\theta) = \\frac{n}{\\sigma^2}(\\theta^2 - 2\\bar{y}\\theta + \\bar{y}^2) + \\frac{1}{\\tau^2(\\eta)}(\\theta^2 - 2\\mu_0\\theta + \\mu_0^2)$$\n合并关于 $\\theta^2$ 和 $\\theta$ 的项：\n$$Q(\\theta) = \\left(\\frac{n}{\\sigma^2} + \\frac{1}{\\tau^2(\\eta)}\\right)\\theta^2 - 2\\left(\\frac{n\\bar{y}}{\\sigma^2} + \\frac{\\mu_0}{\\tau^2(\\eta)}\\right)\\theta + C$$\n其中 C 包含不依赖于 $\\theta$ 的项。这个关于 $\\theta$ 的二次型意味着后验分布也是正态分布，记为 $\\mathcal{N}(\\mu_n, \\sigma_n^2)$。这种分布的密度正比于 $\\exp\\left(-\\frac{(\\theta - \\mu_n)^2}{2\\sigma_n^2}\\right)$，展开后为 $\\exp\\left(-\\frac{1}{2\\sigma_n^2}(\\theta^2 - 2\\mu_n\\theta + \\mu_n^2)\\right)$。\n通过将 $\\theta^2$ 和 $\\theta$ 的系数与我们 $Q(\\theta)$ 的表达式进行比较，我们找到了后验方差 $\\sigma_n^2$ 和后验均值 $\\mu_n$：\n$$\\frac{1}{\\sigma_n^2} = \\frac{n}{\\sigma^2} + \\frac{1}{\\tau^2(\\eta)}$$\n$$\\frac{\\mu_n}{\\sigma_n^2} = \\frac{n\\bar{y}}{\\sigma^2} + \\frac{\\mu_0}{\\tau^2(\\eta)}$$\n\n**3. 后验期望**\n\n后验分布的期望 $\\mathbb{E}[\\theta \\mid y]$ 是其均值 $\\mu_n$。解出 $\\mu_n$ 得到：\n$$\\mu_n = \\sigma_n^2 \\left(\\frac{n\\bar{y}}{\\sigma^2} + \\frac{\\mu_0}{\\tau^2(\\eta)}\\right) = \\frac{\\frac{n\\bar{y}}{\\sigma^2} + \\frac{\\mu_0}{\\tau^2(\\eta)}}{\\frac{n}{\\sigma^2} + \\frac{1}{\\tau^2(\\eta)}}$$\n代入 $\\tau^2(\\eta) = \\exp(\\eta)$，我们得到作为 $\\eta$ 函数的后验期望：\n$$\\mathbb{E}[\\theta \\mid y] = \\mu_n(\\eta) = \\frac{\\frac{n\\bar{y}}{\\sigma^2} + \\mu_0 \\exp(-\\eta)}{\\frac{n}{\\sigma^2} + \\exp(-\\eta)}$$\n\n**4. 微分**\n\n最后，我们使用商法则 $(\\frac{f}{g})' = \\frac{f'g - fg'}{g^2}$，对 $\\mu_n(\\eta)$ 关于 $\\eta$ 求导。令 $f(\\eta) = \\frac{n\\bar{y}}{\\sigma^2} + \\mu_0 e^{-\\eta}$ 和 $g(\\eta) = \\frac{n}{\\sigma^2} + e^{-\\eta}$。它们的导数是：\n$$f'(\\eta) = -\\mu_0 e^{-\\eta}$$\n$$g'(\\eta) = -e^{-\\eta}$$\n应用商法则：\n$$\\frac{\\partial \\mu_n}{\\partial \\eta} = \\frac{(-\\mu_0 e^{-\\eta})\\left(\\frac{n}{\\sigma^2} + e^{-\\eta}\\right) - \\left(\\frac{n\\bar{y}}{\\sigma^2} + \\mu_0 e^{-\\eta}\\right)(-e^{-\\eta})}{\\left(\\frac{n}{\\sigma^2} + e^{-\\eta}\\right)^2}$$\n化简分子：\n$$\\text{Numerator} = -\\frac{n\\mu_0}{\\sigma^2}e^{-\\eta} - \\mu_0 e^{-2\\eta} + \\frac{n\\bar{y}}{\\sigma^2}e^{-\\eta} + \\mu_0 e^{-2\\eta}$$\n$$\\text{Numerator} = \\frac{n}{\\sigma^2}e^{-\\eta}(\\bar{y} - \\mu_0)$$\n因此，导数的最终表达式为：\n$$\\frac{\\partial}{\\partial \\eta}\\,\\mathbb{E}[\\theta \\mid y] = \\frac{\\frac{n}{\\sigma^2} \\exp(-\\eta) (\\bar{y} - \\mu_0)}{\\left(\\frac{n}{\\sigma^2} + \\exp(-\\eta)\\right)^2}$$\n我们将实现此公式来评估给定测试用例的敏感性。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the derivative of the posterior expectation with respect to a hyperparameter\n    for a series of test cases.\n    \"\"\"\n    # Test suite (each case specifies y as a list, sigma^2, mu_0, and eta)\n    test_cases = [\n        # 1. \n        {'y': [1.2, 0.7, 1.0, 0.9, 1.1], 'sigma2': 0.25, 'mu0': 0.0, 'eta': 0.0},\n        # 2. \n        {'y': [1.2, 0.7, 1.0, 0.9, 1.1], 'sigma2': 0.25, 'mu0': 1.5, 'eta': 0.0},\n        # 3. \n        {'y': [1.2, 0.7, 1.0, 0.9, 1.1], 'sigma2': 0.25, 'mu0': 0.0, 'eta': 5.0},\n        # 4. \n        {'y': [1.2, 0.7, 1.0, 0.9, 1.1], 'sigma2': 0.25, 'mu0': 0.0, 'eta': -5.0},\n        # 5. \n        {'y': [2.0, 2.0, 2.0], 'sigma2': 1.0, 'mu0': 2.0, 'eta': 1.0},\n    ]\n\n    results = []\n    \n    # The derived formula for the derivative\n    # D = ( (n/sigma^2) * exp(-eta) * (y_bar - mu0) ) / ( (n/sigma^2) + exp(-eta) )^2\n    def calculate_derivative(y_list, sigma2, mu0, eta):\n        \"\"\"\n        Calculates the derivative based on the derived formula.\n        \n        Args:\n            y_list (list): List of observations.\n            sigma2 (float): Known variance of the observations.\n            mu0 (float): Mean of the prior distribution.\n            eta (float): Hyperparameter for the prior variance.\n            \n        Returns:\n            float: The calculated derivative.\n        \"\"\"\n        n = len(y_list)\n        y_bar = np.mean(y_list)\n        \n        # To avoid re-calculation\n        exp_neg_eta = np.exp(-eta)\n        n_over_sigma2 = n / sigma2\n        \n        numerator = n_over_sigma2 * exp_neg_eta * (y_bar - mu0)\n        denominator = (n_over_sigma2 + exp_neg_eta)**2\n        \n        # Handle case where denominator is zero, although unlikely with sigma2 > 0 and n > 0.\n        if denominator == 0:\n            return 0.0\n            \n        return numerator / denominator\n\n    for case in test_cases:\n        derivative = calculate_derivative(case['y'], case['sigma2'], case['mu0'], case['eta'])\n        # Format the result to six decimal places as a string\n        results.append(f\"{derivative:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3101531"}]}