{"hands_on_practices": [{"introduction": "截断奇异值分解 (TSVD) 的核心在于一种微妙的权衡。通过截断（即忽略）与小奇异值相关的分量，我们减少了噪声的放大，从而降低了解的方差。然而，这种截断也可能丢弃真实信号的一部分，从而引入了偏见。这个实践 [@problem_id:3201027] 将通过一个具体的数值微分问题，指导你使用蒙特卡洛模拟来量化和观察解的偏见与方差如何随截断参数 $k$ 的变化而变化，并最终找到最小化均方误差 (MSE) 的最佳 $k$ 值。这个练习是理解所有正则化方法背后基本原理的基石。", "problem": "考虑一个线性反问题，其正向算子由一阶导数的有限差分近似构造。设 $n$ 为区间 $[0,1]$ 上的网格点数，其均匀间距为 $h = 1/(n-1)$，网格位置为 $t_i = (i-1)h$，其中 $i = 1,2,\\dots,n$。通过离散一阶导数模板定义 $(n-1) \\times n$ 矩阵 $A$：\n$$\nA_{i,i} = -\\frac{1}{h}, \\quad A_{i,i+1} = \\frac{1}{h}, \\quad \\text{for } i=1,2,\\dots,n-1,\n$$\n其余所有元素均为零。设真实信号为向量 $x_{\\text{true}} \\in \\mathbb{R}^n$，其分量为\n$$\nx_{\\text{true},i} = \\sin(2\\pi t_i) + 0.1\\, t_i,\n$$\n其中正弦函数使用弧度作为角度单位。观测值由以下公式建模：\n$$\nb = A x_{\\text{true}} + \\varepsilon,\n$$\n其中 $\\varepsilon \\in \\mathbb{R}^{n-1}$ 是加性观测噪声，其分量独立同分布，均值为零，并具有指定的标准差。\n\n设 $A$ 可进行奇异值分解（singular value decomposition, SVD）$A = U \\Sigma V^T$，其中 $U \\in \\mathbb{R}^{(n-1)\\times(n-1)}$，$V \\in \\mathbb{R}^{n\\times(n-1)}$ 具有标准正交列，$\\Sigma \\in \\mathbb{R}^{(n-1)\\times(n-1)}$ 是对角矩阵，对角线上为非负奇异值。考虑截断奇异值分解（truncated singular value decomposition, TSVD）估计量 $x_k$，该估计量通过仅使用前 $k$ 个奇异三元组获得，其中 $k \\in \\{0,1,\\dots,n-1\\}$。\n\n你的任务是实现一个程序，对于下面指定的每个测试用例，构造 $A$ 和 $x_{\\text{true}}$，从具有给定标准差的零均值高斯分布中抽取 $L$ 个独立的噪声实现 $\\varepsilon$，并为每个指定的截断水平 $k$ 计算 TSVD 解 $x_k$。使用对 $L$ 个实现的蒙特卡罗采样，估计：\n1. 由下式定义的偏差平方：\n$$\n\\| \\mathbb{E}[x_k] - x_{\\text{true}} \\|_2^2,\n$$\n其中期望是针对噪声分布计算的。\n2. 由下式定义的方差：\n$$\n\\mathbb{E}\\left[ \\| x_k - \\mathbb{E}[x_k] \\|_2^2 \\right].\n$$\n3. 由偏差平方和方差之和定义的均方误差（mean squared error, MSE）。\n\n对于每个测试用例，找出并报告使从蒙特卡罗样本计算出的经验均方误差最小的截断水平 $k$（一个整数）。如果存在多个 $k$ 值使均方误差同为最小值，则选择其中最小的 $k$。为确保可复现性，在为每个测试用例生成噪声之前，使用固定的种子 $0$ 初始化随机数生成器。\n\n测试套件：\n- 用例 1（一般情况）：$n = 50$，噪声标准差 $= 10^{-2}$，样本数量 $L = 400$，候选截断水平 $k \\in \\{0,1,5,10,20,49\\}$。\n- 用例 2（低噪声情况）：$n = 50$，噪声标准差 $= 10^{-6}$，样本数量 $L = 400$，候选截断水平 $k \\in \\{0,1,5,10,20,49\\}$。\n- 用例 3（高噪声情况）：$n = 50$，噪声标准差 $= 5\\times 10^{-2}$，样本数量 $L = 400$，候选截断水平 $k \\in \\{0,1,5,10,20,49\\}$。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含三个测试用例的最佳截断水平，形式为用方括号括起来的逗号分隔列表，例如 $[k_1,k_2,k_3]$，其中每个 $k_i$ 是相应情况下经验均方误差的整数最小化值。", "solution": "我们从线性反问题 $b = A x_{\\text{true}} + \\varepsilon$ 开始，其中 $A$ 是一个基于均匀网格构建的离散一阶导数算子。奇异值分解（SVD）将 $A$ 分解为 $A = U \\Sigma V^T$，其中 $U$ 和 $V$ 的列是标准正交的，$\\Sigma$ 是对角矩阵，其对角线元素为非负奇异值 $\\sigma_i$，其中 $i=1,\\dots,n-1$。Moore–Penrose 伪逆对应于使用所有非零奇异值，但当存在较小的奇异值时，这会显著放大噪声。截断奇异值分解（TSVD）正则化将逆运算限制在前 $k$ 个奇异分量上，以引入偏差为代价换取方差的减小。\n\n根据 SVD，限制在前 $k$ 个右奇异向量的张成空间中的最小二乘解，是通过将数据投影到前 $k$ 个左奇异向量上，并按相应奇异值的倒数进行缩放来构造的。具体来说，记 $U_k \\in \\mathbb{R}^{(n-1)\\times k}$ 为 $U$ 的前 $k$ 列，$V_k \\in \\mathbb{R}^{n\\times k}$ 为 $V$ 的前 $k$ 列，$\\Sigma_k \\in \\mathbb{R}^{k \\times k}$ 为前 $k$ 个奇异值构成的对角矩阵，则 TSVD 估计量可以写为\n$$\nx_k = V_k \\Sigma_k^{-1} U_k^T b.\n$$\n代入 $b = A x_{\\text{true}} + \\varepsilon$ 并使用 $A = U \\Sigma V^T$，则 $x_k$ 关于噪声的期望值（其中 $\\mathbb{E}[\\varepsilon] = 0$）为\n$$\n\\mathbb{E}[x_k] = V_k \\Sigma_k^{-1} U_k^T A x_{\\text{true}} = V_k \\Sigma_k^{-1} U_k^T U \\Sigma V^T x_{\\text{true}} = V_k V_k^T x_{\\text{true}}.\n$$\n因此，$\\mathbb{E}[x_k]$ 是 $x_{\\text{true}}$ 在前 $k$ 个右奇异向量的张成空间上的正交投影。偏差平方则为\n$$\n\\| \\mathbb{E}[x_k] - x_{\\text{true}} \\|_2^2 = \\| (I - V_k V_k^T) x_{\\text{true}} \\|_2^2,\n$$\n该值随着更多分量被截断（即 $k$ 越小）而增大。\n\n对于方差，当 $\\varepsilon$ 建模为协方差为 $\\sigma^2 I$ 的独立同分布零均值高斯噪声时，我们有波动\n$$\nx_k - \\mathbb{E}[x_k] = V_k \\Sigma_k^{-1} U_k^T \\varepsilon,\n$$\n$x_k$ 的协方差为\n$$\n\\operatorname{Cov}(x_k) = V_k \\Sigma_k^{-1} U_k^T (\\sigma^2 I) U_k \\Sigma_k^{-1} V_k^T = \\sigma^2\\, V_k \\Sigma_k^{-2} V_k^T.\n$$\n波动的期望平方范数是该协方差矩阵的迹：\n$$\n\\mathbb{E}\\left[ \\| x_k - \\mathbb{E}[x_k] \\|_2^2 \\right] = \\operatorname{trace}\\left( \\operatorname{Cov}(x_k) \\right) = \\sigma^2 \\sum_{i=1}^k \\frac{1}{\\sigma_i^2}.\n$$\n该方差随 $k$ 的增大而增大，因为更多的奇异分量，特别是那些 $\\sigma_i$ 较小的分量，会导致噪声放大。\n\n均方误差（MSE）可加性地分解为\n$$\n\\operatorname{MSE}(k) = \\| \\mathbb{E}[x_k] - x_{\\text{true}} \\|_2^2 + \\mathbb{E}\\left[ \\| x_k - \\mathbb{E}[x_k] \\|_2^2 \\right].\n$$\n最优截断水平 $k$ 在偏差（随 $k$ 增大而减小）和方差（随 $k$ 增大而增大）之间取得平衡。\n\n为实现每个测试用例的计算，算法步骤如下：\n1. 构造网格 $t_i = (i-1)/(n-1)$，其中 $i=1,\\dots,n$，间距为 $h = 1/(n-1)$。\n2. 使用一阶导数模板元素 $A_{i,i}=-1/h$ 和 $A_{i,i+1}=1/h$ 构建矩阵 $A \\in \\mathbb{R}^{(n-1)\\times n}$。\n3. 定义真实信号 $x_{\\text{true}} \\in \\mathbb{R}^n$，其分量为 $x_{\\text{true},i}=\\sin(2\\pi t_i) + 0.1 t_i$，其中正弦函数的参数使用弧度。\n4. 计算奇异值分解 $A = U \\Sigma V^T$，其中 $U \\in \\mathbb{R}^{(n-1)\\times(n-1)}$，$\\Sigma$ 中为对角奇异值 $\\sigma_i$，$V \\in \\mathbb{R}^{n\\times(n-1)}$。\n5. 对于每个候选截断水平 $k$，预计算线性算子 $M_k = V_k \\Sigma_k^{-1} U_k^T$，以便每个 TSVD 解可以通过 $x_k = M_k b$ 获得。\n6. 将随机数生成器初始化为固定种子 $0$。进行 $L$ 次独立试验，每次抽取高斯噪声 $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^2 I)$，构成 $b = A x_{\\text{true}} + \\varepsilon$，并为每个 $k$ 计算 $x_k^{(\\ell)} = M_k b$。\n7. 通过计算 $\\| \\bar{x}_k - x_{\\text{true}} \\|_2^2$ 来估计偏差平方，其中 $\\bar{x}_k$ 是样本均值 $\\bar{x}_k = \\frac{1}{L}\\sum_{\\ell=1}^L x_k^{(\\ell)}$。\n8. 通过计算样本平均值 $\\frac{1}{L} \\sum_{\\ell=1}^L \\| x_k^{(\\ell)} - \\bar{x}_k \\|_2^2$ 来估计方差。\n9. 对每个 $k$，将估计的偏差平方和方差相加，得到经验均方误差。\n10. 选择使经验均方误差最小的 $k$；如果多个 $k$ 值并列最小，则选择最小的那个 $k$。\n\n程序为三个指定的测试用例执行这些步骤。最后，它打印一行包含三个选定截断水平的输出，格式为 $[k_1,k_2,k_3]$。这个计算演示了截断奇异值分解中固有的偏差-方差权衡：较低的截断水平通过滤除噪声放大分量来降低方差，但代价是引入偏差；而较高的截断水平会减少偏差，但可能由于通过小奇异值放大噪声而增加方差。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef construct_derivative_matrix(n: int) - np.ndarray:\n    \"\"\"\n    Construct (n-1) x n first-derivative finite-difference matrix with uniform spacing h.\n    A[i, i] = -1/h, A[i, i+1] = 1/h\n    \"\"\"\n    m = n - 1\n    h = 1.0 / (n - 1)\n    A = np.zeros((m, n), dtype=float)\n    idx = np.arange(m)\n    A[idx, idx] = -1.0 / h\n    A[idx, idx + 1] = 1.0 / h\n    return A\n\ndef construct_true_signal(n: int) - np.ndarray:\n    \"\"\"\n    Construct x_true on [0,1]: x_true[i] = sin(2*pi*t_i) + 0.1*t_i, radians.\n    \"\"\"\n    t = np.linspace(0.0, 1.0, n)\n    x_true = np.sin(2.0 * np.pi * t) + 0.1 * t\n    return x_true\n\ndef precompute_tsvd_operators(A: np.ndarray, k_list: list[int]):\n    \"\"\"\n    Compute SVD of A and precompute M_k = V_k * Sigma_k^{-1} * U_k^T for all k in k_list.\n    Returns dict mapping k - M_k.\n    \"\"\"\n    # Economy SVD\n    U, s, Vt = np.linalg.svd(A, full_matrices=False)\n    # Shapes: U (m x m), s (m,), Vt (m x n)\n    U_T = U.T  # (m x m)\n    n = Vt.shape[1]\n    M_ops = {}\n    for k in k_list:\n        if k == 0:\n            # M_0 is the zero operator (n x m)\n            M_ops[k] = np.zeros((n, A.shape[0]), dtype=float)\n            continue\n        # U_k^T: first k rows of U^T (k x m)\n        U_k_T = U_T[:k, :]\n        # V_k: first k rows of Vt, transposed - (n x k)\n        V_k = Vt[:k, :].T\n        inv_s_k = 1.0 / s[:k]  # (k,)\n        # M_k = V_k @ diag(inv_s_k) @ U_k_T\n        # Implement diag(inv_s_k) @ U_k_T as (inv_s_k[:, None] * U_k_T)\n        M_k = V_k @ (inv_s_k[:, None] * U_k_T)\n        M_ops[k] = M_k\n    return M_ops\n\ndef empirical_bias_variance_mse(A: np.ndarray, x_true: np.ndarray, sigma: float, L: int, k_list: list[int], seed: int = 0):\n    \"\"\"\n    For given A, x_true, noise std sigma, number of samples L, and k_list,\n    compute empirical squared bias, squared variance, and MSE for each k using Monte Carlo.\n    Returns dict k - (bias_sq, var_sq, mse) and the k minimizing mse (smallest k in case of tie).\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    M_ops = precompute_tsvd_operators(A, k_list)\n    m = A.shape[0]\n    # Precompute b0 = A @ x_true\n    b0 = A @ x_true\n\n    # For each k, collect samples of x_k to compute mean and variance efficiently\n    stats = {}\n    # We will store sample means and second moments to avoid keeping all samples\n    # Welford's algorithm for vector means and sum of squared deviations\n    for k in k_list:\n        M_k = M_ops[k]\n        mean = np.zeros_like(x_true)\n        # sum of squared deviations for variance norm (E[||x - mean||^2]) estimation\n        # We'll accumulate sum of ||x - mean||^2 online\n        ssd = 0.0\n        count = 0\n        for _ in range(L):\n            eps = rng.normal(loc=0.0, scale=sigma, size=m)\n            b = b0 + eps\n            x_k = M_k @ b\n            count += 1\n            # Online mean update\n            delta = x_k - mean\n            mean += delta / count\n            # Online sum of squared deviations (Chan's update for sum of squares of deviations)\n            ssd += np.dot(x_k - mean, x_k - mean)\n        # Bias squared\n        bias_sq = float(np.dot(mean - x_true, mean - x_true))\n        # Variance squared: average squared deviation norm\n        var_sq = float(ssd / L)\n        mse = bias_sq + var_sq\n        stats[k] = (bias_sq, var_sq, mse)\n\n    # Find k minimizing mse, tie-breaking by smallest k\n    best_k = None\n    best_mse = None\n    for k in sorted(k_list):\n        _, _, mse = stats[k]\n        if best_mse is None or mse  best_mse or (mse == best_mse and k  best_k):\n            best_mse = mse\n            best_k = k\n\n    return stats, best_k\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Each case: (n, noise_sigma, L, k_list)\n        (50, 1e-2, 400, [0, 1, 5, 10, 20, 49]),\n        (50, 1e-6, 400, [0, 1, 5, 10, 20, 49]),\n        (50, 5e-2, 400, [0, 1, 5, 10, 20, 49]),\n    ]\n\n    results = []\n    for n, sigma, L, k_list in test_cases:\n        A = construct_derivative_matrix(n)\n        x_true = construct_true_signal(n)\n        # Use fixed seed per case for reproducibility as instructed\n        _, best_k = empirical_bias_variance_mse(A, x_true, sigma, L, k_list, seed=0)\n        results.append(best_k)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3201027"}, {"introduction": "在实践中，我们通常无法获取“真实解”，因此不能像上一个练习那样直接计算均方误差来选择最佳的截断参数 $k$。因此，我们需要一种诊断工具来帮助我们判断截断到何处是合适的。这个练习 [@problem_id:3201000] 介绍了一种实用的启发式方法：通过追踪 TSVD 解的系数在 $V$ 基下的变化，我们可以观察到当包含的奇异值 $\\sigma_i$ 过小时，解的系数会如何因噪声放大而出现“尖峰”。你将实现一个算法来自动检测这种不稳定性的出现，从而为选择正则化参数提供一个无需真实解的替代方案。", "problem": "给定一个线性反问题族，其模型为 $A x \\approx b$，其中 $A \\in \\mathbb{R}^{m \\times n}$ 是病态的，而 $b \\in \\mathbb{R}^{m}$ 可能被加性噪声污染。考虑使用截断奇异值分解（truncated SVD）作为一种正则化策略。$A$ 的奇异值分解定义为 $A = U \\Sigma V^{\\top}$，其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 的对角元（奇异值）为非负数，满足 $\\sigma_1 \\ge \\sigma_2 \\ge \\cdots \\ge \\sigma_n  0$。对于一个截断水平 $k \\in \\{1,2,\\dots,n\\}$，定义截断子空间 $\\mathcal{S}_k = \\mathrm{span}\\{v_1,\\dots,v_k\\}$，其中 $v_i$ 是右奇异向量（$V$ 的列向量）。令 $x_k$ 为 $\\mathcal{S}_k$ 中使残差范数 $\\|A x - b\\|_2$ 在 $x \\in \\mathcal{S}_k$ 上最小化的元素。\n\n您的任务是分析当 $k$ 增加时解的路径 $x_k$，特别关注具有大系数的、沿着 $v_i$ 的分量何时进入解中。$x_k$ 中 $v_i$ 的系数是 $x_k$ 在基 $\\{v_i\\}$ 下展开式的第 $i$ 项。对于每个 $i$，将系数大小序列定义为当 $k$ 增长时这些系数的绝对值。在实践中，当 $b$ 包含噪声时，与小奇异值对应的系数可能会变得很大，因为残差分量会与左奇异向量对齐，并被 $1/\\sigma_i$ 放大。这种现象与不稳定性的出现有关，并通常在系数序列中表现为“系数尖峰”。\n\n按如下方式以纯粹的算法术语定义一个尖峰检测规则。令 $c_i$ 表示当截断从 $k=i-1$ 扩展到 $k=i$ 时出现的、与 $v_i$ 相关联的系数（因此 $c_i$ 是 $x_i$ 中乘以 $v_i$ 的系数）。设 $p=5$，$\\alpha=3$ 和 $\\beta=2$。令基线为前 $p$ 个系数绝对值的平均值，即 $\\mathrm{baseline} = \\frac{1}{p} \\sum_{i=1}^{p} |c_i|$。在第一个满足 $|c_i|  \\alpha \\cdot \\mathrm{baseline}$ 和 $|c_i|  \\beta \\cdot |c_{i-1}|$ 两个条件的索引 $ip$ 处宣告一个尖峰。如果不存在这样的索引，则报告 $-1$。\n\n您的程序必须仅从奇异值分解和限制在子空间上的最小二乘最小化的定义出发：\n- 通过利用 $U$ 和 $V$ 的正交性求解在 $\\mathcal{S}_k$ 上的约束最小二乘问题，推导出当 $k$ 增加时进入 $x_k$ 的系数 $c_i$ 的形式。\n- 实现上述尖峰检测规则以确定第一个尖峰索引 $k_{\\star}$。\n\n测试套件。实现以下 3 个测试用例，每个用例都由确定性的伪随机构造完全指定。在每个用例中，奇异值都是严格递减的，并根据一个确保病态性的方案生成。通过显式奇异值分解构造 $A$：通过对具有给定随机种子的标准正态矩阵应用 QR 分解，生成独立的 Haar-like 正交矩阵 $U$ 和 $V$；定义 $\\Sigma$ 使其对角线上具有指定的奇异值；然后设置 $A = U_{[:,1:n]} \\Sigma V^{\\top}$。通过指定系数 $\\hat{x}_i$ 并在右奇异向量基中构造真实解 $x_{\\mathrm{true}} = V \\hat{x}$，其中 $\\hat{x} = (\\hat{x}_1,\\dots,\\hat{x}_n)^{\\top}$。然后设置 $b = A x_{\\mathrm{true}} + \\varepsilon$，其中噪声向量 $\\varepsilon$ 的元素是独立的、均值为零、标准差为 $\\sigma_{\\mathrm{noise}}$ 的正态分布项；定义 $\\sigma_{\\mathrm{noise}} = \\mathrm{level} \\cdot \\|A x_{\\mathrm{true}}\\|_2 / \\sqrt{m}$，因此噪声相对于干净数据进行缩放。本问题不使用角度，也不涉及物理单位。\n\n- 用例 1 (理想情况): $m=50$, $n=40$, 随机种子 $1234$, 奇异值 $\\sigma_i = 10^{-(i-1)/8}$ (对于 $i=1,\\dots,n$), 系数 $\\hat{x}_i = \\exp(-(i-1)/7)$ (对于 $i=1,\\dots,n$), 噪声水平 $\\mathrm{level} = 10^{-3}$。\n- 用例 2 (边界情况，无噪声): $m=50$, $n=40$, 随机种子 $2021$, 奇异值 $\\sigma_i = 10^{-(i-1)/8}$, 系数 $\\hat{x}_i = \\exp(-(i-1)/7)$, 噪声水平 $\\mathrm{level} = 0$。\n- 用例 3 (边缘情况，更强的病态性和更多噪声): $m=80$, $n=60$, 随机种子 $999$, 奇异值 $\\sigma_i = 10^{-(i-1)/6}$, 系数 $\\hat{x}_i = \\exp(-(i-1)/10)$, 噪声水平 $\\mathrm{level} = 2 \\cdot 10^{-2}$。\n\n对于每个用例，计算与逐步包含 $v_i$ 相关联的系数序列 $c_i$，并应用 $p=5, \\alpha=3, \\beta=2$ 的尖峰检测规则。每个用例所需的输出是第一个尖峰出现的整数索引 $k_{\\star}$（对 $i$ 使用基于 1 的索引）；如果未检测到尖峰，则该用例输出 $-1$。\n\n最终输出格式。您的程序应生成单行输出，其中包含三个用例按顺序排列的结果，形式为逗号分隔的列表并用方括号括起来，例如 $[k_1,k_2,k_3]$。不应打印任何其他文本。", "solution": "所提出的问题是有效的。这是一个计算科学中明确定义的任务，其基础是线性反问题和使用截断奇异值分解（TSVD）进行正则化的既定理论。该问题在科学上是合理的，自成体系，客观，并为获得唯一解提供了所有必要的数据和算法定义。\n\n问题的核心是确定 TSVD 解的系数，然后应用特定的算法规则来检测由噪声引起的不稳定性。我们首先从第一性原理推导这些系数的公式。\n\n问题是在给定的截断水平 $k$ 下，找到最小化残差范数的解 $x_k$。解 $x_k$ 被约束在子空间 $\\mathcal{S}_k = \\mathrm{span}\\{v_1, \\dots, v_k\\}$ 内，其中 $v_i$ 是矩阵 $A$ 的右奇异向量。\n$$\nx_k = \\arg\\min_{x \\in \\mathcal{S}_k} \\|A x - b\\|_2^2\n$$\n任何向量 $x \\in \\mathcal{S}_k$ 都可以唯一地表示为标准正交基向量 $\\{v_1, \\dots, v_k\\}$ 的线性组合：\n$$\nx = \\sum_{i=1}^k c_i v_i\n$$\n其中 $c_i$ 是我们需要确定的系数。将此表示代入目标函数，我们寻求最小化：\n$$\n\\left\\| A \\left(\\sum_{i=1}^k c_i v_i\\right) - b \\right\\|_2^2 = \\left\\| \\left(\\sum_{i=1}^k c_i A v_i\\right) - b \\right\\|_2^2\n$$\n根据奇异值分解的定义 $A = U \\Sigma V^{\\top}$，我们有基本关系 $A v_i = \\sigma_i u_i$（对于 $i=1, \\dots, n$），其中 $u_i$ 是左奇异向量，$\\sigma_i$ 是奇异值。将此代入表达式得到：\n$$\n\\left\\| \\left(\\sum_{i=1}^k c_i \\sigma_i u_i\\right) - b \\right\\|_2^2\n$$\n左奇异向量 $\\{u_i\\}_{i=1}^m$ 构成 $\\mathbb{R}^m$ 的一个标准正交基。一个向量的欧几里得范数的平方是其在任何标准正交基中坐标的平方和。我们可以将范数内的向量 $r = (\\sum_{i=1}^k c_i \\sigma_i u_i) - b$ 在左奇异向量基中表示。$r$ 沿着 $u_j$ 的坐标是 $u_j^{\\top} r$。\n因此，范数的平方为：\n$$\n\\|r\\|_2^2 = \\sum_{j=1}^m (u_j^{\\top} r)^2 = \\sum_{j=1}^m \\left( u_j^{\\top} \\left( \\sum_{i=1}^k c_i \\sigma_i u_i \\right) - u_j^{\\top} b \\right)^2\n$$\n利用标准正交性 $u_j^{\\top} u_i = \\delta_{ij}$（克罗内克 δ），表达式得以简化。\n对于 $j \\in \\{1, \\dots, k\\}$，项 $u_j^{\\top} (\\sum_{i=1}^k c_i \\sigma_i u_i)$ 变为 $c_j \\sigma_j$。\n对于 $j \\in \\{k+1, \\dots, m\\}$，项 $u_j^{\\top} (\\sum_{i=1}^k c_i \\sigma_i u_i)$ 变为 $0$。\n这使我们可以将关于 $j$ 的和式拆分：\n$$\n\\|r\\|_2^2 = \\sum_{j=1}^k (c_j \\sigma_j - u_j^{\\top} b)^2 + \\sum_{j=k+1}^m (- u_j^{\\top} b)^2\n$$\n为了关于系数 $\\{c_1, \\dots, c_k\\}$ 最小化此表达式，我们只需考虑第一个和式，因为第二个和式与这些系数无关。第一个和式是非负项之和。当每一项都为零时，该和式达到其最小值 $0$。因此，对于每个 $j \\in \\{1, \\dots, k\\}$，我们必须有：\n$$\nc_j \\sigma_j - u_j^{\\top} b = 0\n$$\n解出 $c_j$ 可得到 TSVD 解系数的著名公式：\n$$\nc_j = \\frac{u_j^{\\top} b}{\\sigma_j}\n$$\n问题将 $c_i$ 定义为当截断水平从 $i-1$ 增加到 $i$ 时进入解的系数。我们的推导表明，基向量 $v_i$ 的系数由上述公式给出，并且不依赖于总的截断水平 $k$（只要 $k \\ge i$）。因此，需要分析的系数序列就是 $\\{c_i\\}_{i=1}^n$。\n\n在确定了系数的形式后，问题的其余部分就是算法性的。\n1.  对每个测试用例，我们从其指定的奇异值分解构造矩阵 $A$。这包括生成随机正交矩阵 $U$ 和 $V$ 以及一个具有指定奇异值的对角矩阵 $\\Sigma$。矩阵 $A$ 的形式为 $A = U_{econ} \\Sigma_{n \\times n} V^{\\top}$，其中 $U_{econ}$ 由 $U$ 的前 $n$ 列组成。\n2.  在右奇异向量基中构造“真实”解 $x_{\\mathrm{true}}$，并计算“干净”数据向量 $b_{\\mathrm{clean}} = A x_{\\mathrm{true}}$。\n3.  添加噪声以获得最终数据向量 $b = b_{\\mathrm{clean}} + \\varepsilon$，其中噪声标准差相对于干净信号的范数进行缩放。\n4.  使用推导出的公式 $c_i = (u_i^{\\top} b)/\\sigma_i$ 计算系数 $c_i$（对于 $i=1, \\dots, n$）。\n5.  将指定的尖峰检测规则应用于系数绝对值序列 $|c_i|$。使用参数 $p=5$, $\\alpha=3$ 和 $\\beta=2$，我们从前 $p$ 个系数计算基线：$\\mathrm{baseline} = \\frac{1}{p} \\sum_{i=1}^{p} |c_i|$。然后我们搜索第一个满足 $|c_i|  \\alpha \\cdot \\mathrm{baseline}$ 和 $|c_i|  \\beta \\cdot |c_{i-1}|$ 两个条件的索引 $i  p$。首次出现该情况的基于 1 的索引即为结果。如果未找到这样的索引，结果为 -1。\n\n对问题陈述中指定的三个测试用例均执行此程序。", "answer": "```python\nimport numpy as np\n\ndef run_case(m, n, seed, sigma_denominator, x_hat_denominator, level, p, alpha, beta):\n    \"\"\"\n    Runs a single test case for spike detection in TSVD.\n\n    Args:\n        m (int): Number of rows for matrix A.\n        n (int): Number of columns for matrix A.\n        seed (int): Random seed for reproducibility.\n        sigma_denominator (float): Denominator in the exponent for singular values.\n        x_hat_denominator (float): Denominator in the exponent for true coefficients.\n        level (float): Relative noise level.\n        p (int): Number of initial coefficients for baseline calculation.\n        alpha (float): Multiplier for the baseline threshold.\n        beta (float): Multiplier for the previous coefficient threshold.\n\n    Returns:\n        int: The 1-based index of the first detected spike, or -1 if no spike is found.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n\n    # 1. Construct matrices U, Sigma, V\n    # Generate Haar-like orthogonal matrices from QR of standard normal matrices\n    U_full, _ = np.linalg.qr(rng.standard_normal((m, m)))\n    V, _ = np.linalg.qr(rng.standard_normal((n, n)))\n    \n    # Use the economy-size U, which has orthonormal columns\n    U_econ = U_full[:, :n]\n\n    # Singular values (sigma_i = 10**(-(i-1)/C))\n    indices = np.arange(1, n + 1)\n    s_vals = 10.0**(-(indices - 1) / sigma_denominator)\n    Sigma_n = np.diag(s_vals)\n\n    # 2. Construct A, x_true, and b\n    A = U_econ @ Sigma_n @ V.T\n\n    # True solution coefficients in the V basis (x_hat_i = exp(-(i-1)/C))\n    x_hat = np.exp(-(indices - 1) / x_hat_denominator)\n    \n    # True solution vector\n    x_true = V @ x_hat\n\n    # Clean data vector b\n    b_clean = A @ x_true\n\n    # Additive noise\n    if level  0.0:\n        norm_b_clean = np.linalg.norm(b_clean)\n        sigma_noise = level * norm_b_clean / np.sqrt(m)\n        noise = rng.normal(0.0, sigma_noise, size=m)\n        b = b_clean + noise\n    else:\n        b = b_clean\n\n    # 3. Compute TSVD solution coefficients\n    # c_i = (u_i^T b) / sigma_i\n    uT_b = U_econ.T @ b\n    c = uT_b / s_vals\n    c_abs = np.abs(c)\n\n    # 4. Apply spike detection rule\n    if n = p:\n        return -1\n\n    # Baseline using the first p coefficients (0-indexed to p-1)\n    baseline = np.mean(c_abs[0:p])\n\n    # Search for spike for indices i  p (1-based), which is i = p (0-based)\n    for i in range(p, n):\n        cond1 = c_abs[i]  alpha * baseline\n        cond2 = c_abs[i]  beta * c_abs[i-1]\n        \n        if cond1 and cond2:\n            return i + 1  # Return 1-based index\n\n    return -1\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    \"\"\"\n    # Define spike detection parameters\n    p = 5\n    alpha = 3.0\n    beta = 2.0\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: m=50, n=40, seed=1234, sigma_i=10^-(i-1)/8, x_hat_i=exp(-(i-1)/7), level=1e-3\n        {\"m\": 50, \"n\": 40, \"seed\": 1234, \"sigma_denom\": 8.0, \"x_hat_denom\": 7.0, \"level\": 1e-3},\n        # Case 2: m=50, n=40, seed=2021, sigma_i=10^-(i-1)/8, x_hat_i=exp(-(i-1)/7), level=0\n        {\"m\": 50, \"n\": 40, \"seed\": 2021, \"sigma_denom\": 8.0, \"x_hat_denom\": 7.0, \"level\": 0.0},\n        # Case 3: m=80, n=60, seed=999, sigma_i=10^-(i-1)/6, x_hat_i=exp(-(i-1)/10), level=2e-2\n        {\"m\": 80, \"n\": 60, \"seed\": 999, \"sigma_denom\": 6.0, \"x_hat_denom\": 10.0, \"level\": 2e-2},\n    ]\n\n    results = []\n    for case in test_cases:\n        k_star = run_case(\n            m=case[\"m\"],\n            n=case[\"n\"],\n            seed=case[\"seed\"],\n            sigma_denominator=case[\"sigma_denom\"],\n            x_hat_denominator=case[\"x_hat_denom\"],\n            level=case[\"level\"],\n            p=p,\n            alpha=alpha,\n            beta=beta\n        )\n        results.append(k_star)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3201000"}, {"introduction": "除了在求解过程中应用正则化，我们有时还可以通过预处理来改善问题本身的性质。如果一个矩阵 $A$ 的列向量尺度差异巨大，这本身就可能导致病态问题，使得正则化更加困难。这个实践 [@problem_id:3201033] 探讨了列规范化作为一种预处理技术，如何影响矩阵的奇异谱和 TSVD 解的质量。你将通过比较预处理前后矩阵的条件数和解的相对误差，亲身体会到一个良好设计的预处理步骤如何能与正则化方法相辅相成，从而获得更稳定、更准确的解。", "problem": "给定一系列形式为 $A x \\approx b$ 的线性反问题，其中 $A \\in \\mathbb{R}^{m \\times n}$ 且 $m \\geq n$，$b \\in \\mathbb{R}^{m}$。任务是研究缩放矩阵 $A$ 的列如何改变其奇异谱，以及这如何影响通过截断奇异值分解 (TSVD) 获得的解，并提出一个能够改善数值稳定性的预处理步骤。你的程序必须仅从核心定义出发，实现以下内容。\n\n允许的基础知识：\n- 奇异值分解 (SVD) 的定义：任何实矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 都允许分解为 $A = U \\Sigma V^{\\top}$，其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 是对角矩阵，其非负对角线元素（奇异值）按非递增顺序排列。\n- 最小二乘目标 $\\min_{x} \\|A x - b\\|_{2}$ 及其在 $A$ 具有满列秩时通过 $A$ 的伪逆得到的解。\n- 带噪声的小奇异值在求逆时会放大 $b$ 中的噪声，这一概念是截断法的动机。\n\n要求的方法：\n1. 实现一个 TSVD 求解器，在给定 $A$、$b$ 和截断索引 $k$ 的情况下，通过将解限制在 $A$ 的前 $k$ 个右奇异向量张成的空间中来计算近似解。除上述定义外，不要假设任何预先推导的公式。\n2. 实现 $A$ 的列缩放预处理，使用对角矩阵 $D = \\mathrm{diag}(d_{1},\\dots,d_{n})$，其中 $d_{j} = \\max\\{\\|A_{:,j}\\|_{2}, \\delta\\}$，$\\delta  0$ 是一个小的下限参数，以避免除以零。将缩放后的系统定义为 $\\bar{A} = A D^{-1}$，变量变换为 $y = D x$，从而得到 $\\bar{A} y \\approx b$。通过 TSVD 求解 $y$，然后通过 $x = D^{-1} y$ 恢复 $x$。\n3. 通过谱条件数 $\\kappa(A) = \\sigma_{\\max}(A) / \\sigma_{\\min}(A)$ 量化缩放对奇异谱的影响，并报告改善因子 $\\kappa(A)/\\kappa(\\bar{A})$。\n4. 通过相对误差 $\\|x_{k} - x_{\\mathrm{true}}\\|_{2} / \\|x_{\\mathrm{true}}\\|_{2}$ 量化缩放对 TSVD 解质量的影响，包括不使用缩放和使用所提出的缩放两种情况，并报告缩放是否改善了误差。\n\n测试套件：\n对于下面的每个测试用例，将 $b$ 构造为 $b = A x_{\\mathrm{true}} + \\eta$，其中 $\\eta$ 是给定的固定噪声向量。使用指定的截断索引 $k$。所有情况均使用下限参数 $\\delta = 10^{-12}$。\n\n- 案例 1 (良好缩放的基准)：\n  - $m = 4$, $n = 3$, $k = 2$。\n  - $A_{1}$ 的行是 $(1.0, 0.9, -0.3)$, $(0.4, -1.2, 0.5)$, $(-0.7, 0.3, 1.1)$, $(0.6, -0.8, 0.2)$。\n  - $x_{\\mathrm{true},1} = (0.5, -1.0, 0.3)$。\n  - $\\eta_{1} = (10^{-4}, -2 \\cdot 10^{-4}, 1.5 \\cdot 10^{-4}, -10^{-4})$。\n\n- 案例 2 (列尺度严重不平衡)：\n  - $m = 4$, $n = 3$, $k = 2$。\n  - 基础矩阵 $A_{2}^{\\mathrm{base}}$ 的行是 $(1.0, 0.0, 0.001)$, $(0.0, 1.0, 0.002)$, $(0.001, 0.002, 1.0)$, $(1.0, -1.0, 0.5)$。\n  - 列缩放向量 $s = (1.0, 10^{-3}, 10^{3})$；构造 $A_{2} = A_{2}^{\\mathrm{base}} \\cdot \\mathrm{diag}(s)$ (即，将每列 $j$ 乘以 $s_{j}$)。\n  - $x_{\\mathrm{true},2} = (0.5, -0.3, 0.2)$。\n  - $\\eta_{2} = (0.1, -0.2, 0.15, -0.1)$。\n\n- 案例 3 (近乎共线的列)：\n  - $m = 4$, $n = 3$, $k = 2$。\n  - $A_{3}$ 的行是 $(1.0, 1.0001, 0.0)$, $(2.0, 2.0002, 0.001)$, $(-1.0, -1.0001, -0.002)$, $(0.5, 0.50005, 0.0005)$。\n  - $x_{\\mathrm{true},3} = (1.0, -1.0, 2.0)$。\n  - $\\eta_{3} = (10^{-4}, -5 \\cdot 10^{-5}, 2 \\cdot 10^{-4}, -1.5 \\cdot 10^{-4})$。\n\n- 案例 4 (近乎零的列)：\n  - $m = 4$, $n = 3$, $k = 2$。\n  - $A_{4}$ 的行是 $(10^{-8}, 1.0, 0.0)$, $(2 \\cdot 10^{-8}, 0.0, 1.0)$, $(-10^{-8}, -1.0, -1.0)$, $(0.0, 0.5, 0.5)$。\n  - $x_{\\mathrm{true},4} = (1.0, 1.0, -1.0)$。\n  - $\\eta_{4} = (10^{-5}, -10^{-5}, 2 \\cdot 10^{-5}, -2 \\cdot 10^{-5})$。\n\n对于每个案例，按顺序计算并汇总以下四个量：\n- 不使用缩放的相对误差，$\\|x_{k}^{\\mathrm{unscaled}} - x_{\\mathrm{true}}\\|_{2} / \\|x_{\\mathrm{true}}\\|_{2}$，作为浮点数。\n- 使用缩放的相对误差，$\\|x_{k}^{\\mathrm{scaled}} - x_{\\mathrm{true}}\\|_{2} / \\|x_{\\mathrm{true}}\\|_{2}$，作为浮点数。\n- 一个布尔标志，如果缩放后的相对误差严格小于未缩放的相对误差，则为 true，否则为 false。\n- 条件数改善因子 $\\kappa(A)/\\kappa(\\bar{A})$，作为浮点数。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含一个扁平列表，按顺序连接所有四个案例的结果，用方括号括起来，并用逗号分隔，即：\n$[e_{1}^{\\mathrm{un}}, e_{1}^{\\mathrm{sc}}, \\mathrm{improve}_{1}, r_{1}, e_{2}^{\\mathrm{un}}, e_{2}^{\\mathrm{sc}}, \\mathrm{improve}_{2}, r_{2}, e_{3}^{\\mathrm{un}}, e_{3}^{\\mathrm{sc}}, \\mathrm{improve}_{3}, r_{3}, e_{4}^{\\mathrm{un}}, e_{4}^{\\mathrm{sc}}, \\mathrm{improve}_{4}, r_{4}]$,\n其中 $e_{i}^{\\mathrm{un}}$ 和 $e_{i}^{\\mathrm{sc}}$ 是浮点数，$\\mathrm{improve}_{i}$ 是布尔值，$r_{i}$ 是浮点数。在打印前将所有浮点数四舍五入到 $6$ 位小数。", "solution": "该问题要求为形式为 $A x \\approx b$ 的线性反问题实现并分析一个截断奇异值分解 (TSVD) 求解器，并评估一种列缩放预处理技术。分析将在几个旨在突出不同数值病态来源的测试用例上进行。\n\n### 1. 截断奇异值分解 (TSVD)\n\n问题是找到一个解 $x \\in \\mathbb{R}^{n}$，以最小化最小二乘目标函数：\n$$ \\min_{x} \\|A x - b\\|_{2}^{2} $$\n其中 $A \\in \\mathbb{R}^{m \\times n}$ 且 $m \\ge n$，$b \\in \\mathbb{R}^{m}$。$A$ 的奇异值分解 (SVD) 为分析和解决此问题提供了强大的工具。$A$ 的 SVD 形式如下：\n$$ A = U \\Sigma V^{\\top} $$\n其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 是一个矩形对角矩阵，其对角线上的非负实数 $\\sigma_{1} \\ge \\sigma_{2} \\ge \\dots \\ge \\sigma_{n} \\ge 0$ 是 $A$ 的奇异值。$U$ 的列（表示为 $\\{u_i\\}_{i=1}^m$）和 $V$ 的列（表示为 $\\{v_i\\}_{i=1}^n$）分别是左奇异向量和右奇异向量。\n\n将 SVD 代入目标函数：\n$$ \\|U \\Sigma V^{\\top} x - b\\|_{2}^{2} $$\n由于 $U$ 是正交矩阵，左乘 $U^{\\top}$ 不改变欧几里得范数，即 $\\|z\\|_2 = \\|U^{\\top}z\\|_2$。因此我们可以变换目标函数：\n$$ \\|U^{\\top}(U \\Sigma V^{\\top} x - b)\\|_{2}^{2} = \\|\\Sigma V^{\\top} x - U^{\\top} b\\|_{2}^{2} $$\n我们引入变量替换 $z = V^{\\top} x$。由于 $V$ 是正交的，因此 $x = Vz$。向量 $z$ 代表 $x$ 在由右奇异向量 $\\{v_i\\}$ 构成的基中的坐标。目标函数变为：\n$$ \\|\\Sigma z - c\\|_{2}^{2}, \\quad \\text{其中 } c = U^{\\top} b $$\n将此表达式按分量展开可得：\n$$ \\sum_{i=1}^{n} (\\sigma_{i} z_{i} - c_{i})^{2} + \\sum_{i=n+1}^{m} c_{i}^{2} $$\n第二项是残差中不可改变的部分。为了最小化总和，我们必须选择 $z_i$ 来最小化第一项总和中的每一项。对于非零奇异值 $\\sigma_i  0$，在 $z_{i} = c_{i} / \\sigma_{i}$ 处达到最小值。对于 $\\sigma_i = 0$，任何 $z_i$ 都是极小值点，但通常选择 $z_i=0$ 以获得最小范数解。这就得到了著名的伪逆解：\n$$ x = Vz = \\sum_{i=1}^{n} \\frac{c_i}{\\sigma_i} v_i = \\sum_{i=1}^{n} \\frac{u_{i}^{\\top} b}{\\sigma_{i}} v_{i} $$\n其中求和仅限于 $\\sigma_i  0$ 的索引。在病态问题中，一些奇异值 $\\sigma_i$ 非常小（但非零），导致项 $(u_i^\\top b)/\\sigma_i$ 变得非常大。如果数据向量 $b$ 包含噪声，这个小的 $\\sigma_i$ 将会放大 $u_i$ 方向上的噪声分量，从而破坏解的准确性。\n\nTSVD 是一种正则化方法，通过截断求和来解决这个问题，从而滤除来自小奇异值的贡献。解被限制在由前 $k$ 个右奇异向量张成的子空间中，其中 $k$ 是截断索引。TSVD 解 $x_k$ 定义为：\n$$ x_{k} = \\sum_{i=1}^{k} \\frac{u_{i}^{\\top} b}{\\sigma_{i}} v_{i} $$\n这等价于计算 $x_k = A_k^\\dagger b$，其中 $A_k = U_k \\Sigma_k V_k^\\top$ 是 $A$ 的最佳秩 $k$ 近似。\n\n### 2. 列缩放预处理\n\n如果矩阵 $A$ 的列范数差异很大，该矩阵可能就是病态的。列缩放是一种旨在缓解此问题的预处理形式。我们定义一个对角缩放矩阵 $D \\in \\mathbb{R}^{n \\times n}$，其对角线元素基于 $A$ 的列范数：\n$$ D = \\mathrm{diag}(d_{1}, d_{2}, \\dots, d_{n}) \\quad \\text{其中} \\quad d_{j} = \\max\\{\\|A_{:,j}\\|_{2}, \\delta\\} $$\n这里，$A_{:,j}$ 是 $A$ 的第 $j$ 列，$\\delta  0$ 是一个小的下限参数，以防止对任何零列进行除零操作。\n\n然后我们定义一个缩放后的矩阵 $\\bar{A} = A D^{-1}$。原始问题 $Ax \\approx b$ 通过变量替换 $y = D x$ 进行变换，这意味着 $x = D^{-1} y$。将此代入问题可得：\n$$ A(D^{-1} y) \\approx b \\implies (A D^{-1}) y \\approx b \\implies \\bar{A} y \\approx b $$\n现在 $\\bar{A}$ 的列已被归一化（其 L2-范数约等于 1），这通常会改善系统的条件数。求解缩放后问题的步骤如下：\n1.  计算缩放矩阵 $D$ 和缩放后的矩阵 $\\bar{A} = A D^{-1}$。\n2.  使用带截断参数 $k$ 的 TSVD 求解缩放后的系统 $\\bar{A} y \\approx b$ 以获得 $y_k$。\n$$ y_k = \\sum_{i=1}^{k} \\frac{\\bar{u}_{i}^{\\top} b}{\\bar{\\sigma}_{i}} \\bar{v}_{i} $$\n其中 $\\bar{A} = \\bar{U} \\bar{\\Sigma} \\bar{V}^\\top$ 是缩放后矩阵的 SVD。\n3.  通过逆向变量替换恢复原始变量 $x$ 的解：$x_{k}^{\\mathrm{scaled}} = D^{-1} y_k$。\n\n### 3. 分析指标\n\n为了评估这种缩放策略的有效性，我们使用两个主要指标：\n\n1.  **谱条件数**：对于一个秩为 $n$ 的 $m \\times n$ 矩阵 $A$，条件数为 $\\kappa(A) = \\sigma_{1}(A) / \\sigma_{n}(A)$。大的条件数表明问题是病态的。我们通过比率 $\\kappa(A)/\\kappa(\\bar{A})$ 来衡量缩放带来的改善。大于 1 的比率表示条件数的改善。\n\n2.  **相对解误差**：给定真实解 $x_{\\mathrm{true}}$，我们可以使用相对误差来衡量计算解 $x_k$ 的准确性：\n$$ E_{\\mathrm{rel}} = \\frac{\\|x_{k} - x_{\\mathrm{true}}\\|_{2}}{\\|x_{\\mathrm{true}}\\|_{2}} $$\n我们将为未缩放的 TSVD 解 ($x_k^{\\mathrm{unscaled}}$) 和来自缩放系统的解 ($x_k^{\\mathrm{scaled}}$) 计算此误差，并进行比较。\n\n通过将此方法应用于指定的测试用例，我们可以系统地研究在不同类型的病态条件下，列缩放如何影响奇异值谱和正则化解的质量。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the analysis for all test cases and print the results.\n    \"\"\"\n\n    # --- Test Case Definitions ---\n    delta = 1e-12\n\n    # Case 1: Well-scaled baseline\n    A1 = np.array([\n        [1.0, 0.9, -0.3],\n        [0.4, -1.2, 0.5],\n        [-0.7, 0.3, 1.1],\n        [0.6, -0.8, 0.2]\n    ])\n    xtrue1 = np.array([0.5, -1.0, 0.3])\n    eta1 = np.array([1e-4, -2e-4, 1.5e-4, -1e-4])\n    k1 = 2\n\n    # Case 2: Severely unbalanced column scales\n    A2_base = np.array([\n        [1.0, 0.0, 0.001],\n        [0.0, 1.0, 0.002],\n        [0.001, 0.002, 1.0],\n        [1.0, -1.0, 0.5]\n    ])\n    s2 = np.array([1.0, 1e-3, 1e3])\n    A2 = A2_base @ np.diag(s2)\n    xtrue2 = np.array([0.5, -0.3, 0.2])\n    eta2 = np.array([0.1, -0.2, 0.15, -0.1])\n    k2 = 2\n\n    # Case 3: Nearly collinear columns\n    A3 = np.array([\n        [1.0, 1.0001, 0.0],\n        [2.0, 2.0002, 0.001],\n        [-1.0, -1.0001, -0.002],\n        [0.5, 0.50005, 0.0005]\n    ])\n    xtrue3 = np.array([1.0, -1.0, 2.0])\n    eta3 = np.array([1e-4, -5e-5, 2e-4, -1.5e-4])\n    k3 = 2\n\n    # Case 4: Nearly zero column\n    A4 = np.array([\n        [1e-8, 1.0, 0.0],\n        [2e-8, 0.0, 1.0],\n        [-1e-8, -1.0, -1.0],\n        [0.0, 0.5, 0.5]\n    ])\n    xtrue4 = np.array([1.0, 1.0, -1.0])\n    eta4 = np.array([1e-5, -1e-5, 2e-5, -2e-5])\n    k4 = 2\n\n    test_cases = [\n        (A1, xtrue1, eta1, k1),\n        (A2, xtrue2, eta2, k2),\n        (A3, xtrue3, eta3, k3),\n        (A4, xtrue4, eta4, k4),\n    ]\n\n    results = []\n\n    def tsvd_solver(A, b, k):\n        \"\"\"\n        Computes the TSVD solution x_k for A*x = b.\n        x_k = sum_{i=1 to k} (u_i^T * b / s_i) * v_i\n        \"\"\"\n        # We need the \"economy\" SVD where U is m x n\n        U, s, Vt = np.linalg.svd(A, full_matrices=False)\n        \n        # Truncate to k\n        Uk = U[:, :k]\n        sk = s[:k]\n        Vtk = Vt[:k, :]\n\n        # Calculate solution for x_k\n        # compute alpha_i = u_i^T * b / s_i\n        # then x_k = V_k * alpha\n        # V_k = Vtk.T\n        alpha = (Uk.T @ b) / sk\n        x_k = Vtk.T @ alpha\n        return x_k\n\n    for A, xtrue, eta, k in test_cases:\n        m, n = A.shape\n        b = A @ xtrue + eta\n        \n        # --- Unscaled Analysis ---\n        x_unscaled = tsvd_solver(A, b, k)\n        err_unscaled = np.linalg.norm(x_unscaled - xtrue) / np.linalg.norm(xtrue)\n        \n        s_unscaled = np.linalg.svd(A, compute_uv=False)\n        # Assuming rank n, use sigma_n\n        cond_A = s_unscaled[0] / s_unscaled[n-1] if s_unscaled[n-1]  0 else np.inf\n\n        # --- Scaled Analysis ---\n        col_norms = np.linalg.norm(A, axis=0)\n        d = np.maximum(col_norms, delta)\n        D_inv = np.diag(1.0 / d)\n        \n        A_bar = A @ D_inv\n        \n        y_scaled = tsvd_solver(A_bar, b, k)\n        x_scaled = D_inv @ y_scaled\n        \n        err_scaled = np.linalg.norm(x_scaled - xtrue) / np.linalg.norm(xtrue)\n        \n        s_scaled = np.linalg.svd(A_bar, compute_uv=False)\n        cond_A_bar = s_scaled[0] / s_scaled[n-1] if s_scaled[n-1]  0 else np.inf\n        \n        # --- Collect Results ---\n        improvement_flag = err_scaled  err_unscaled\n        cond_improvement_factor = cond_A / cond_A_bar if cond_A_bar > 0 else np.inf\n\n        results.extend([\n            round(err_unscaled, 6),\n            round(err_scaled, 6),\n            improvement_flag,\n            round(cond_improvement_factor, 6)\n        ])\n\n    # Final print statement in the exact required format.\n    # Convert boolean to lowercase 'true'/'false' for JSON-like output\n    final_results_str = [str(r).lower() if isinstance(r, bool) else str(r) for r in results]\n    print(f\"[{','.join(final_results_str)}]\")\n\nsolve()\n```", "id": "3201033"}]}