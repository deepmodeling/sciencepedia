{"hands_on_practices": [{"introduction": "要真正理解卡尔曼滤波，最好的方法是从最简单的一维标量情况入手。这个练习将引导你从基本原理出发，推导出卡尔曼增益 $K_k$ 的解析表达式，并揭示其核心思想：后验估计是先验估计和新测量值之间的一个加权平均。通过分析稳态增益与噪声比的关系，你将直观地感受到滤波器是如何根据不确定性来动态调整权重，从而实现最优估计的 [@problem_id:3149123]。", "problem": "一个标量状态 $x_{k}$ 根据随机游走模型 $x_{k} = x_{k-1} + w_{k-1}$ 按离散时间演化，其中过程噪声 $w_{k-1}$ 是均值为零、方差为 $Q > 0$ 的高斯噪声。在时刻 $k$，通过 $z_{k} = x_{k} + v_{k}$ 获得状态的测量值 $z_{k}$，其中测量噪声 $v_{k}$ 是均值为零、方差为 $R > 0$ 的高斯噪声。假设 $w_{k-1}$ 和 $v_{k}$ 相互独立，并且与过去的状态和测量值无关。设先验估计为 $\\hat{x}_{k|k-1}$，其先验误差方差为 $P_{k|k-1}$，并考虑标量线性高斯情况下的最小均方误差 (MMSE) 估计器。\n\n任务：\n- 从模型定义和 MMSE 原理出发，推导使时刻 $k$ 的期望平方估计误差最小化的标量卡尔曼增益 $K_{k}$ 的解析表达式。然后证明后验估计 $\\hat{x}_{k|k}$ 可以写成先验估计 $\\hat{x}_{k|k-1}$ 和测量值 $z_{k}$ 的加权平均。\n- 对于上述随机游走模型，分析方差递推关系，并推导在 $Q$ 和 $R$ 恒定时，当 $k \\to \\infty$ 时出现的稳态增益 $K_{\\infty}$。将此稳态增益仅表示为比率 $r = Q/R$ 的函数。\n\n答案规格：\n- 以关于 $K_{\\infty}(r)$ 的单个闭式解析表达式的形式提供最终答案。\n- 无需四舍五入，也无需物理单位。", "solution": "该问题背景为标量线性高斯估计问题。我们利用最小均方误差 (MMSE) 原理，该原理指出，在所有无偏估计器中，条件均值是最小化期望平方误差的估计器。对于线性高斯系统，最优 MMSE 估计器具有线性新息形式。\n\n我们从模型定义开始：\n- 状态演化：$x_{k} = x_{k-1} + w_{k-1}$，其中 $w_{k-1} \\sim \\mathcal{N}(0, Q)$。\n- 测量：$z_{k} = x_{k} + v_{k}$，其中 $v_{k} \\sim \\mathcal{N}(0, R)$。\n- 独立性：$w_{k-1}$ 和 $v_{k}$ 相互独立，且与过去的状态和测量值无关。\n\n设 $\\hat{x}_{k|k-1}$ 为时刻 $k$ 的先验估计，$P_{k|k-1}$ 为其先验误差方差。考虑形式如下的估计器：\n$$\n\\hat{x}_{k|k} = \\hat{x}_{k|k-1} + K_{k} \\left( z_{k} - \\hat{x}_{k|k-1} \\right),\n$$\n其中 $K_{k}$ 是一个标量增益，其选择旨在最小化期望平方估计误差。定义更新后的估计误差为\n$$\ne_{k|k} = x_{k} - \\hat{x}_{k|k} = x_{k} - \\hat{x}_{k|k-1} - K_{k} \\left( z_{k} - \\hat{x}_{k|k-1} \\right).\n$$\n使用测量模型 $z_{k} = x_{k} + v_{k}$，新息变为\n$$\nz_{k} - \\hat{x}_{k|k-1} = \\left( x_{k} - \\hat{x}_{k|k-1} \\right) + v_{k}.\n$$\n因此，\n$$\ne_{k|k} = \\left( x_{k} - \\hat{x}_{k|k-1} \\right) - K_{k} \\left( \\left( x_{k} - \\hat{x}_{k|k-1} \\right) + v_{k} \\right) = (1 - K_{k}) \\left( x_{k} - \\hat{x}_{k|k-1} \\right) - K_{k} v_{k}.\n$$\n根据误差项的独立性和零均值特性，后验均方误差为\n$$\n\\mathbb{E}\\!\\left[ e_{k|k}^{2} \\right] = (1 - K_{k})^{2} \\, \\mathbb{V}\\mathrm{ar}\\!\\left( x_{k} - \\hat{x}_{k|k-1} \\right) + K_{k}^{2} \\, \\mathbb{V}\\mathrm{ar}(v_{k}) = (1 - K_{k})^{2} P_{k|k-1} + K_{k}^{2} R.\n$$\n我们通过对 $K_{k}$ 求导来最小化这个二次函数：\n$$\n\\frac{d}{dK_{k}} \\left[ (1 - K_{k})^{2} P_{k|k-1} + K_{k}^{2} R \\right] = -2(1 - K_{k}) P_{k|k-1} + 2 K_{k} R.\n$$\n将导数设为零，可得\n$$\n-2(1 - K_{k}) P_{k|k-1} + 2 K_{k} R = 0 \\quad \\Rightarrow \\quad K_{k} R = (1 - K_{k}) P_{k|k-1}.\n$$\n解出 $K_{k}$，得到标量最优卡尔曼增益\n$$\nK_{k} = \\frac{P_{k|k-1}}{P_{k|k-1} + R}.\n$$\n将此结果代入估计器形式，可以展示其加权平均的解释：\n$$\n\\hat{x}_{k|k} = \\hat{x}_{k|k-1} + K_{k} \\left( z_{k} - \\hat{x}_{k|k-1} \\right) = (1 - K_{k}) \\, \\hat{x}_{k|k-1} + K_{k} \\, z_{k},\n$$\n当 $P_{k|k-1} > 0$ 且 $R > 0$ 时，$K_{k} \\in (0, 1)$，因此后验估计是先验估计和测量值的凸组合。权重根据相对置信度进行自适应调整：较大的 $P_{k|k-1}$（对先验的置信度较低）会增大 $K_{k}$，而较大的 $R$（对测量的置信度较低）会减小 $K_{k}$。\n\n接下来，我们分析随机游走模型的方差递推关系，以获得当 $k \\to \\infty$ 时的稳态增益。方差的预测步骤为\n$$\nP_{k|k-1} = P_{k-1|k-1} + Q.\n$$\n使用上面最小化均方误差的表达式，更新后的后验方差为\n$$\nP_{k|k} = (1 - K_{k})^{2} P_{k|k-1} + K_{k}^{2} R.\n$$\n代入最优的 $K_{k} = \\frac{P_{k|k-1}}{P_{k|k-1} + R}$ 可以得到一个众所周知的等价闭式形式，我们可以直接计算：\n\n$$\nP_{k|k} = (1 - K_{k}) P_{k|k-1} = \\left( 1 - \\frac{P_{k|k-1}}{P_{k|k-1} + R} \\right) P_{k|k-1} = \\frac{R \\, P_{k|k-1}}{P_{k|k-1} + R}.\n$$\n\n在稳态下，记 $P_{k|k} \\to P$ 且 $P_{k|k-1} \\to P + Q$。关于 $P$ 的稳态代数方程变为\n$$\nP = \\frac{R \\, (P + Q)}{(P + Q) + R}.\n$$\n两边同乘以 $(P + Q + R)$ 并化简：\n\n$$\nP (P + Q + R) = R (P + Q) \\quad \\Rightarrow \\quad P^{2} + P Q + P R = R P + R Q.\n$$\n\n消去两边的 $R P$：\n\n$$\nP^{2} + P Q - R Q = 0.\n$$\n\n这是一个关于 $P$ 的二次方程，其中系数 $Q > 0, R > 0$。物理上有意义的（正）解是\n\n$$\nP = \\frac{-Q + \\sqrt{Q^{2} + 4 R Q}}{2}.\n$$\n\n相应的稳态预测方差为\n\n$$\nP_{k|k-1} \\to P + Q = \\frac{Q + \\sqrt{Q^{2} + 4 R Q}}{2}.\n$$\n\n因此，稳态增益 $K_{\\infty}$ 为\n\n$$\nK_{\\infty} = \\frac{P + Q}{(P + Q) + R} = \\frac{\\frac{Q + \\sqrt{Q^{2} + 4 R Q}}{2}}{\\frac{Q + \\sqrt{Q^{2} + 4 R Q}}{2} + R} = \\frac{Q + \\sqrt{Q^{2} + 4 R Q}}{Q + \\sqrt{Q^{2} + 4 R Q} + 2 R}.\n$$\n\n将 $K_{\\infty}$ 仅表示为比率 $r = Q / R$ 的函数。代入 $Q = r R$ 可得\n\n$$\nK_{\\infty}(r) = \\frac{r R + \\sqrt{r^{2} R^{2} + 4 r R^{2}}}{r R + \\sqrt{r^{2} R^{2} + 4 r R^{2}} + 2 R} = \\frac{r + \\sqrt{r^{2} + 4 r}}{r + \\sqrt{r^{2} + 4 r} + 2}.\n$$\n\n这个闭式表达式揭示了其对比率 $r = Q / R$ 的依赖关系，并且在不同比率下均符合直觉：\n- 当 $r \\to 0$ 时（过程噪声相对于测量噪声可忽略不计），$\\sqrt{r^{2} + 4 r} \\to 0$，因此 $K_{\\infty}(r) \\to 0$，几乎将全部权重放在先验估计上。\n- 当 $r \\to \\infty$ 时（过程噪声相对于测量噪声占主导地位），$\\sqrt{r^{2} + 4 r} \\sim r$，因此 $K_{\\infty}(r) \\to 1$，几乎将全部权重放在测量值上。\n- 对于中间的 $r$ 值，$K_{\\infty}(r)$ 随 $r$ 单调增加，根据先验和测量的相对不确定性平滑地平衡二者。\n\n所要求的最终答案是闭式函数 $K_{\\infty}(r)$。", "answer": "$$\\boxed{\\frac{r+\\sqrt{r^{2}+4r}}{r+\\sqrt{r^{2}+4r}+2}}$$", "id": "3149123"}, {"introduction": "在实际应用中，我们如何判断卡尔曼滤波器是否工作正常？一个关键的诊断工具是检验“新息序列”的白度。新息（innovation）是实际测量值与滤波器预测值之差，对于一个模型正确、运行最优的滤波器，其新息序列理论上应为白噪声。本练习将通过一个编码任务，教你如何实现新息白度检验，并通过三个精心设计的案例（模型匹配、模型失配）来诊断滤波器的性能 [@problem_id:3149135]。", "problem": "您将实现并使用卡尔曼滤波器（KF），通过计算其样本自相关来检验新息序列的白性。工作将在纯离散时间、线性、时不变、高斯状态空间设置下进行。使用的基本原理是：线性高斯模型、作为最小均方误差估计量的条件期望，以及最小二乘法的正交性原理。不要使用任何无法从这些基本原理推导出的简化公式；相反，您应从高斯随机变量和线性映射的预测与校正的定义出发来设计卡尔曼滤波器算法。\n\n模型假设与定义：\n- 在时间步 $k$ 的隐藏状态为 $x_k \\in \\mathbb{R}^2$，表示位置和速度，形式为 $x_k = \\begin{bmatrix}x^{(p)}_k \\\\ x^{(v)}_k\\end{bmatrix}$。\n- 真实动态是线性的：$x_k = F x_{k-1} + B u + w_k$，其中 $F \\in \\mathbb{R}^{2 \\times 2}$，$B \\in \\mathbb{R}^{2 \\times 1}$，常数输入 $u \\in \\mathbb{R}$，以及过程噪声 $w_k \\sim \\mathcal{N}(0, Q_{\\text{true}})$，其在时间 $k$ 上是独立同分布（i.i.d.）的。\n- 观测是标量：$y_k = H x_k + v_k$，其中 $H \\in \\mathbb{R}^{1 \\times 2}$，测量噪声 $v_k \\sim \\mathcal{N}(0, R_{\\text{true}})$，其在时间 $k$ 上是独立同分布的，并且与 $\\{w_j\\}_{j}$ 及初始状态 $x_0$ 无关。\n- 新息序列定义为 $e_k = y_k - H \\hat{x}_{k|k-1}$，其中 $\\hat{x}_{k|k-1}$ 是给定截至时间 $k-1$ 的数据时，卡尔曼滤波器对状态的一步向前预测。在模型被正确指定且卡尔曼滤波器为最优的情况下，新息 $\\{e_k\\}$ 是零均值、不相关的（即白的）高斯随机变量。\n\n需要实现的白性检验：\n- 给定一个有限序列 $\\{e_k\\}_{k=1}^{N}$，计算在滞后量 $\\ell = 1, 2, \\dots, L$ 处的样本自相关：\n  1. 计算样本均值 $\\bar{e} = \\frac{1}{N} \\sum_{k=1}^{N} e_k$。\n  2. 定义去均值序列 $d_k = e_k - \\bar{e}$。\n  3. 对于每个滞后量 $\\ell$，计算归一化样本自相关\n     $$r[\\ell] = \\frac{\\sum_{k=\\ell+1}^{N} d_k \\, d_{k-\\ell}}{\\sum_{k=1}^{N} d_k^2}.$$\n- 在白性零假设下，对于大样本，每个 $r[\\ell]$ 近似服从均值为零、标准差为 $1/\\sqrt{N}$ 的分布。使用双边 $95\\%$ 准则 $|r[\\ell]| \\leq \\frac{1.96}{\\sqrt{N}}$（对于所有 $\\ell \\in \\{1,\\dots,L\\}$）来接受白性。实现该检验，若接受白性则返回布尔值 true，否则返回 false。\n\n需要遵守的实现细节：\n- 使用从线性高斯预测和校正设计的卡尔曼滤波器：在每一步中，使用假设的 $(F, Q)$ 进行预测，并使用 $(H, R)$ 进行更新，在更新前形成 $e_k$。\n- 使用初始高斯先验 $\\hat{x}_{0|0} \\in \\mathbb{R}^2$ 和协方差 $P_{0|0} \\in \\mathbb{R}^{2 \\times 2}$。\n- 使用固定的随机种子以确保结果可复现。\n\n测试套件与参数：\n使用时间步长 $\\Delta t = 1.0$，时间范围 $N = 500$，以及滞后量 $L = 10$。使用\n$$F = \\begin{bmatrix} 1  \\Delta t \\\\ 0  1 \\end{bmatrix}, \\quad H = \\begin{bmatrix} 1  0 \\end{bmatrix}, \\quad B = \\begin{bmatrix} 0.5 \\\\ 1.0 \\end{bmatrix}.$$\n使用真实的过程噪声协方差和测量噪声方差\n$$Q_{\\text{true}} = \\mathrm{diag}(10^{-4}, 10^{-5}), \\quad R_{\\text{true}} = 10^{-2}.$$\n使用先验\n$$\\hat{x}_{0|0} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}, \\quad P_{0|0} = I_{2}.$$\n将随机种子设置为 $0$。\n\n提供三个测试用例以检验不同行为：\n\n1) 匹配模型（理想情况）：\n- 真实输入 $u = 0$。\n- KF 中的假设模型：$(F, Q, H, R)$ 等于 $(F, Q_{\\text{true}}, H, R_{\\text{true}})$，且未对输入建模。\n- 预期结果：新息应为白噪声。\n\n2) 模型失配：未建模的恒定加速度（有色新息）：\n- 真实输入 $u = a_0$，其中 $a_0 = 0.2$（在所有时间内为常数）。\n- 真实状态通过 $B u$ 随非零输入演化。\n- KF 假设没有输入（使用与上述相同的 $(F, H)$，但不包含 $B u$ 项），并使用 $(Q, R) = (Q_{\\text{true}}, R_{\\text{true}})$。\n- 预期结果：新息应为有色噪声，白性检验应失败。\n\n3) 模型失配：严重低估的过程噪声（有色新息）：\n- 真实输入 $u = 0$。\n- KF 使用与上述相同的 $(F, H)$，并使用 $(Q, R) = (Q_{\\text{assumed}}, R_{\\text{true}})$，其中\n  $$Q_{\\text{assumed}} = \\mathrm{diag}(10^{-8}, 10^{-9}).$$\n- 预期结果：新息应为有色噪声，白性检验应失败。\n\n编程任务与要求输出：\n- 实现一个程序，为每个测试用例模拟真实系统，使用指定的假设参数运行 KF，计算新息序列 $\\{e_k\\}$，使用 $L$ 和 $|r[\\ell]| \\le \\frac{1.96}{\\sqrt{N}}$ 准则评估白性检验，并为每个用例记录一个布尔结果。\n- 您的程序应生成单行输出，其中包含按上述三个测试用例顺序排列的结果，形式为方括号内以逗号分隔的列表。例如，类似 $[ \\text{true}, \\text{false}, \\text{false} ]$ 的输出，但使用精确的 Python 布尔字面量且无空格，即 $[\\text{True},\\text{False},\\text{False}]$。", "solution": "该问题要求从基本原理出发实现卡尔曼滤波器（KF），以检验其新息序列的白性。此检验可作为诊断滤波器性能和底层状态空间模型正确性的工具。解决方案将首先在线性高斯框架内建立 KF 的理论基础，然后详细说明白性检验，最后将这些应用于指定的测试用例。\n\n### 线性高斯状态空间模型\n\n系统由一个离散时间、线性、时不变的状态空间模型描述。隐藏状态的演化和观测值的生成由两个方程控制：\n\n1.  **状态方程**：系统在时间步 $k$ 的真实状态，用向量 $x_k \\in \\mathbb{R}^2$ 表示，根据一个线性随机差分方程演化：\n    $$x_k = F x_{k-1} + B u + w_k$$\n    在这里，$F \\in \\mathbb{R}^{2 \\times 2}$ 是状态转移矩阵，$B \\in \\mathbb{R}^{2 \\times 1}$ 是输入矩阵，$u \\in \\mathbb{R}$ 是一个常数控制输入，$w_k$ 是过程噪声。过程噪声被假设为独立同分布（i.i.d.）的零均值高斯随机向量序列，其协方差矩阵为 $Q_{\\text{true}}$，即 $w_k \\sim \\mathcal{N}(0, Q_{\\text{true}})$。\n\n2.  **测量方程**：在时间步 $k$ 的观测值，一个标量 $y_k \\in \\mathbb{R}$，是受噪声污染的真实状态的线性投影：\n    $$y_k = H x_k + v_k$$\n    在这里，$H \\in \\mathbb{R}^{1 \\times 2}$ 是观测矩阵，$v_k$ 是测量噪声。测量噪声被假设为独立同分布（i.i.d.）的零均值高斯随机变量序列，其方差为 $R_{\\text{true}}$，即 $v_k \\sim \\mathcal{N}(0, R_{\\text{true}})$。噪声序列 $\\{w_k\\}$ 和 $\\{v_k\\}$ 相互独立。\n\n估计问题的核心是，在给定带噪声的测量序列 $\\{y_k\\}$ 的情况下，推断隐藏状态序列 $\\{x_k\\}$。\n\n### 从第一性原理出发的卡尔曼滤波器\n\n在最小化状态估计的均方误差（MMSE）意义上，卡尔曼滤波器是线性高斯系统的最优估计器。该滤波器以递归方式运行，一次处理一个测量值。其推导依赖于一个性质：对于联合高斯随机变量，其条件分布仍然是高斯的。\n\n设给定截至时间 $j$ 的所有测量值时状态 $x_k$ 的条件概率密度表示为 $p(x_k | y_{1:j})$。卡尔曼滤波器在每一步计算精确的后验分布 $p(x_k | y_{1:k})$，该分布由其均值（状态估计）和协方差完全表征。递归过程包括两个阶段：预测和校正。\n\n假设在步骤 $k-1$ 结束时，我们有状态 $x_{k-1}$ 的后验（滤波后）分布：\n$$x_{k-1} | y_{1:k-1} \\sim \\mathcal{N}(\\hat{x}_{k-1|k-1}, P_{k-1|k-1})$$\n其中 $\\hat{x}_{k-1|k-1}$ 是状态估计，$P_{k-1|k-1}$ 是误差协方差矩阵。\n\n#### 1. 预测（时间更新）\n\n预测步骤在融合测量值 $y_k$ 之前，将状态和协方差估计从时间 $k-1$ 向前投影到时间 $k$。目标是计算步骤 $k$ 的先验分布 $p(x_k | y_{1:k-1})$。\n\n-   **预测状态均值**：对状态方程使用期望算子的线性性质（这里使用的是卡尔曼滤波器的动力学模型，它可能与真实动力学不同）：\n    $$\\hat{x}_{k|k-1} = \\mathbb{E}[F x_{k-1} + w_k | y_{1:k-1}] = F \\mathbb{E}[x_{k-1} | y_{1:k-1}] + \\mathbb{E}[w_k]$$\n    给定 $\\mathbb{E}[x_{k-1} | y_{1:k-1}] = \\hat{x}_{k-1|k-1}$ 和 $\\mathbb{E}[w_k] = 0$，预测的状态均值为：\n    $$\\hat{x}_{k|k-1} = F \\hat{x}_{k-1|k-1}$$\n    请注意，根据问题规范，在所有测试用例中 KF 的假设模型均不包含控制输入项 $B u$，因此此处省略了该项。\n\n-   **预测误差协方差**：预测状态的协方差是通过将上一步的协方差通过动力学模型传播得到的。状态预测误差为 $x_k - \\hat{x}_{k|k-1} = F(x_{k-1} - \\hat{x}_{k-1|k-1}) + w_k$。\n    $$P_{k|k-1} = \\text{Cov}(x_k | y_{1:k-1}) = \\mathbb{E}[(x_k - \\hat{x}_{k|k-1})(x_k - \\hat{x}_{k|k-1})^T | y_{1:k-1}]$$\n    由于前一估计的误差 $(x_{k-1} - \\hat{x}_{k-1|k-1})$ 与过程噪声 $w_k$ 无关，协方差为：\n    $$P_{k|k-1} = \\text{Cov}(F(x_{k-1} - \\hat{x}_{k-1|k-1})) + \\text{Cov}(w_k) = F P_{k-1|k-1} F^T + Q$$\n    其中 $Q$ 是滤波器假设的过程噪声协方差矩阵。\n\n因此，预测分布为 $x_k | y_{1:k-1} \\sim \\mathcal{N}(\\hat{x}_{k|k-1}, P_{k|k-1})$。\n\n#### 2. 校正（测量更新）\n\n校正步骤通过融合新的测量值 $y_k$ 来优化预测估计。这是一个贝叶斯更新。我们有关于 $x_k$ 的先验和来自测量模型的似然。\n\n-   **新息**：新息，或称测量残差，$e_k$，是实际测量值 $y_k$ 与基于模型和先验状态估计的预测值之间的差值：\n    $$e_k = y_k - \\mathbb{E}[y_k | y_{1:k-1}] = y_k - \\mathbb{E}[H x_k + v_k | y_{1:k-1}] = y_k - H \\hat{x}_{k|k-1}$$\n\n-   **新息协方差**：新息的协方差 $S_k$ 为：\n    $$S_k = \\text{Cov}(e_k) = \\text{Cov}(H(x_k - \\hat{x}_{k|k-1}) + v_k)$$\n    由于状态预测误差和测量噪声 $v_k$ 是独立的：\n    $$S_k = H \\text{Cov}(x_k - \\hat{x}_{k|k-1}) H^T + \\text{Cov}(v_k) = H P_{k|k-1} H^T + R$$\n    其中 $R$ 是滤波器假设的测量噪声协方差。\n\n-   **最优卡尔曼增益**：更新后的状态估计是预测估计和新息的线性组合。最小化后验误差协方差的加权因子是卡尔曼增益 $K_k$。它由状态和测量值之间的互协方差导出。\n    $$K_k = \\text{Cov}(x_k, y_k | y_{1:k-1}) S_k^{-1} = \\text{Cov}(x_k, H x_k + v_k) S_k^{-1}$$\n    $$K_k = \\text{Cov}(x_k, x_k H^T) S_k^{-1} = P_{k|k-1} H^T S_k^{-1}$$\n\n-   **更新状态均值**：后验状态估计是经新息校正的先验估计，并由卡尔曼增益加权：\n    $$\\hat{x}_{k|k} = \\hat{x}_{k|k-1} + K_k e_k$$\n\n-   **更新误差协方差**：后验误差协方差从先验协方差减小：\n    $$P_{k|k} = P_{k|k-1} - K_k S_k K_k^T = (I - K_k H) P_{k|k-1}$$\n    后一种形式，被称为约瑟夫形式（Joseph form），因其数值稳定性而常被优先选用。\n\n校正（滤波）后的分布为 $x_k | y_{1:k} \\sim \\mathcal{N}(\\hat{x}_{k|k}, P_{k|k})$，从而完成递归循环。\n\n### 新息白性检验\n\n最优卡尔曼滤波器的一个基本特性是，如果模型参数 $(F, H, Q, R)$ 被正确指定，并且噪声过程确实是高斯的和白的，那么所得的新息序列 $\\{e_k\\}$ 就是一个零均值、不相关（白）的高斯序列。任何偏离此特性的情况，如非零均值或时间相关性，都表明滤波器的模型与真实的底层过程之间存在失配。\n\n该问题要求对一个有限的新息序列 $\\{e_k\\}_{k=1}^{N}$ 进行白性统计检验。这通过检查其样本自相关函数来完成。\n\n1.  首先，计算样本均值：$\\bar{e} = \\frac{1}{N} \\sum_{k=1}^{N} e_k$。\n2.  对序列进行去均值处理：$d_k = e_k - \\bar{e}$。\n3.  对于时间滞后量 $\\ell \\in \\{1, 2, \\dots, L\\}$，归一化样本自相关计算如下：\n    $$r[\\ell] = \\frac{\\sum_{k=\\ell+1}^{N} d_k \\, d_{k-\\ell}}{\\sum_{k=1}^{N} d_k^2}$$\n4.  在序列为白噪声的零假设下，对于大样本容量 $N$，每个 $r[\\ell]$ 近似服从 $\\mathcal{N}(0, 1/N)$ 分布。一种常见的统计检验方法是，如果任何自相关系数落在置信区间之外，则拒绝白性假设。使用 $95\\%$ 的置信水平，检验准则为：如果对所有 $\\ell = 1, \\dots, L$ 都有 $|r[\\ell]| \\le \\frac{1.96}{\\sqrt{N}}$，则接受白性。否则，拒绝白性。\n\n### 测试用例分析\n\n这三个测试用例旨在探究滤波器在不同条件下的性能：\n\n1.  **匹配模型**：KF 使用真实模型参数 $(F, Q_{\\text{true}}, H, R_{\\text{true}})$，并且真实系统没有输入（$u=0$）。在这种“理想情况”下，KF 理论上是最优的。新息序列 $\\{e_k\\}$ 预计是白的，白性检验应该通过。\n\n2.  **未建模的恒定加速度**：真实系统受到一个恒定输入 $u=a_0=0.2$ 的影响，这代表一个恒定的加速度。然而，KF 并未配置以考虑此输入。这种模型失配将在状态预测中引入系统性偏差。误差会随时间增长，导致新息具有非零均值和高度相关性。白性检验预计会失败。\n\n3.  **严重低估的过程噪声**：KF 使用的过程噪声协方差 $Q_{\\text{assumed}}$ 比真实的 $Q_{\\text{true}}$ 小几个数量级。这使得滤波器对其基于动力学模型的预测过于自信。它将对真实状态的随机扰动反应迟缓，因为它会将大部分新息归因于测量噪声而非状态误差。这种迟滞的响应导致误差在多个时间步内持续存在，从而产生一个强自相关的新息序列。白性检验预计会失败。\n\n程序将执行这三种情景，收集每种情景下的新息，并应用白性检验以产生一个布尔结果。", "answer": "```python\nimport numpy as np\n\ndef simulate_system(F, B, H, Q_true, R_true, x0_true, u_true, N):\n    \"\"\"\n    Simulates the true linear state-space system.\n    \"\"\"\n    n_states = F.shape[0]\n    x_true = np.zeros((N + 1, n_states, 1))\n    y_obs = np.zeros((N, 1))\n    x_true[0] = x0_true\n\n    # Generate all noise terms at once for efficiency\n    process_noise = np.random.multivariate_normal(np.zeros(n_states), Q_true, size=N)\n    measurement_noise = np.random.normal(0, np.sqrt(R_true), size=N)\n\n    for k in range(N):\n        # State evolution: x_k = F @ x_{k-1} + B @ u + w_k\n        w_k = process_noise[k].reshape(n_states, 1)\n        x_true[k + 1] = F @ x_true[k] + B * u_true + w_k\n        \n        # Observation: y_k = H @ x_k + v_k\n        v_k = measurement_noise[k]\n        y_obs[k] = H @ x_true[k + 1] + v_k\n\n    return y_obs\n\ndef kalman_filter(y_obs, F, H, Q_kf, R_kf, x0_hat, P0):\n    \"\"\"\n    Runs the Kalman Filter and returns the innovations sequence.\n    \"\"\"\n    N = len(y_obs)\n    n_states = F.shape[0]\n    \n    x_hat = x0_hat\n    P = P0\n    \n    innovations = np.zeros(N)\n\n    for k in range(N):\n        # --- Prediction (Time Update) ---\n        # x_hat_{k|k-1} = F @ x_hat_{k-1|k-1}\n        x_hat_pred = F @ x_hat\n        # P_{k|k-1} = F @ P_{k-1|k-1} @ F.T + Q\n        P_pred = F @ P @ F.T + Q_kf\n        \n        # --- Innovation Calculation ---\n        # e_k = y_k - H @ x_hat_{k|k-1}\n        y_k = y_obs[k]\n        e_k = y_k - (H @ x_hat_pred)\n        innovations[k] = e_k.item()\n\n        # --- Correction (Measurement Update) ---\n        # S_k = H @ P_{k|k-1} @ H.T + R\n        S_k = H @ P_pred @ H.T + R_kf\n        # K_k = P_{k|k-1} @ H.T @ S_k^-1\n        K_k = P_pred @ H.T / S_k # S_k is scalar\n        \n        # x_hat_{k|k} = x_hat_{k|k-1} + K_k @ e_k\n        x_hat = x_hat_pred + K_k * e_k\n        # P_{k|k} = (I - K_k @ H) @ P_{k|k-1}\n        I = np.eye(n_states)\n        P = (I - K_k @ H) @ P_pred\n        \n    return innovations\n\ndef whiteness_test(innovations, L, N):\n    \"\"\"\n    Performs the whiteness test on the innovations sequence.\n    \"\"\"\n    # 1. Compute sample mean\n    e_bar = np.mean(innovations)\n    \n    # 2. Demean the sequence\n    d = innovations - e_bar\n    \n    # Denominator for normalization\n    denom = np.sum(d**2)\n    if denom == 0:\n        return True # Avoid division by zero; no variance means white\n\n    # 3. Compute normalized sample autocorrelation for lags l = 1..L\n    threshold = 1.96 / np.sqrt(N)\n    \n    for l in range(1, L + 1):\n        # Numerator: sum_{k=l+1 to N} d_k * d_{k-l}\n        # Using numpy slicing for efficiency: d[l:] corresponds to d_k for k>l\n        # d[:-l] corresponds to d_{k-l}\n        num = np.sum(d[l:] * d[:-l])\n        \n        r_l = num / denom\n        \n        # 4. Check against threshold\n        if np.abs(r_l) > threshold:\n            return False # Whiteness test fails\n            \n    return True # Whiteness test passes for all lags\n\ndef solve():\n    \"\"\"\n    Main function to run the three test cases and print results.\n    \"\"\"\n    # --- Global Parameters ---\n    np.random.seed(0)\n    \n    dt = 1.0\n    N = 500\n    L = 10\n    \n    F = np.array([[1.0, dt], [0.0, 1.0]])\n    H = np.array([[1.0, 0.0]])\n    B = np.array([[0.5 * dt**2], [dt]]) # Problem states B=[0.5, 1.0], constant vel model implies this form for acceleration input\n    \n    Q_true = np.diag([1e-4, 1e-5])\n    R_true = 1e-2\n    \n    x0_hat = np.array([[0.0], [1.0]])\n    P0 = np.eye(2)\n    x0_true = np.array([[0.0], [1.0]])\n    \n    # --- Test Cases Configuration ---\n    test_cases = [\n        # Case 1: Matched model\n        {\n            \"name\": \"Matched\",\n            \"u_true\": 0.0,\n            \"Q_kf\": Q_true,\n            \"R_kf\": R_true\n        },\n        # Case 2: Unmodeled constant acceleration\n        {\n            \"name\": \"Unmodeled Input\",\n            \"u_true\": 0.2,\n            \"Q_kf\": Q_true,\n            \"R_kf\": R_true\n        },\n        # Case 3: Underestimated process noise\n        {\n            \"name\": \"Underestimated Noise\",\n            \"u_true\": 0.0,\n            \"Q_kf\": np.diag([1e-8, 1e-9]),\n            \"R_kf\": R_true\n        }\n    ]\n    \n    results = []\n\n    # Pre-simulate the true trajectories for each case\n    # Note: Using the same initial seed for each simulation would yield the same true trajectory.\n    # The problem asks to set the seed to 0, which is done once.\n    # So the SAME random noise sequence will be used to generate the system evolution\n    # for each scenario that requires simulation (which is all of them).\n    \n    # Simulate true observations for Case 1  3 (u_true=0)\n    y_obs_u0 = simulate_system(F, B, H, Q_true, R_true, x0_true, u_true=0.0, N=N)\n    \n    # Simulate true observations for Case 2 (u_true=0.2)\n    y_obs_u_const = simulate_system(F, B, H, Q_true, R_true, x0_true, u_true=0.2, N=N)\n\n    # --- Run KF and Whiteness Test for each case ---\n    \n    # Case 1\n    case1_params = test_cases[0]\n    innovations_1 = kalman_filter(y_obs_u0, F, H, case1_params[\"Q_kf\"], case1_params[\"R_kf\"], x0_hat, P0)\n    result_1 = whiteness_test(innovations_1, L, N)\n    results.append(result_1)\n\n    # Case 2\n    case2_params = test_cases[1]\n    innovations_2 = kalman_filter(y_obs_u_const, F, H, case2_params[\"Q_kf\"], case2_params[\"R_kf\"], x0_hat, P0)\n    result_2 = whiteness_test(innovations_2, L, N)\n    results.append(result_2)\n\n    # Case 3\n    case3_params = test_cases[2]\n    innovations_3 = kalman_filter(y_obs_u0, F, H, case3_params[\"Q_kf\"], case3_params[\"R_kf\"], x0_hat, P0)\n    result_3 = whiteness_test(innovations_3, L, N)\n    results.append(result_3)\n    \n    # --- Final Output ---\n    # Convert Python booleans to lowercase strings as per typical JSON/list format,\n    # then join without spaces.\n    # The requirement is `[True,False,False]`. Python's `str(bool)` gives 'True'/'False'.\n    output_str = f\"[{','.join(map(str, results))}]\"\n    print(output_str)\n\nsolve()\n```", "id": "3149135"}, {"introduction": "在许多现实场景中，我们无法直接测量状态向量的所有分量，例如我们可能只能测量一个运动物体的位置，而无法直接测量其速度。这个练习探讨了当测量信息不完整（即测量矩阵秩亏）时，系统不确定性是如何演化的。通过一个编码实践，你将研究系统动力学模型（由状态转移矩阵 $A$ 描述）如何将信息从可测量的状态传播到不可测量的状态，从而揭示“可观测性”这一深刻概念的实际意义 [@problem_id:3149199]。", "problem": "考虑一个离散时间、线性、时不变的高斯状态空间模型，其状态向量 $x_k \\in \\mathbb{R}^n$ 和测量值 $y_k \\in \\mathbb{R}^m$ 由以下关系式给出\n$$\nx_{k+1} = A x_k + w_k, \\quad y_k = C x_k + v_k,\n$$\n其中 $A \\in \\mathbb{R}^{n \\times n}$ 是状态转移矩阵，$C \\in \\mathbb{R}^{m \\times n}$ 是测量矩阵，$w_k \\sim \\mathcal{N}(0,Q)$ 是过程噪声，其协方差为 $Q \\in \\mathbb{R}^{n \\times n}$，$v_k \\sim \\mathcal{N}(0,R)$ 是测量噪声，其协方差为 $R \\in \\mathbb{R}^{m \\times m}$。假设 $w_k$ 和 $v_k$ 相互独立且在时间上独立，初始状态具有高斯先验 $x_0 \\sim \\mathcal{N}(\\mu_0,P_0)$，其均值为 $\\mu_0 \\in \\mathbb{R}^n$，协方差为半正定矩阵 $P_0 \\in \\mathbb{R}^{n \\times n}$。\n\n你的任务是分析当测量矩阵 $C$ 是秩亏的（非可逆的）时，不确定性在未被直接测量的子空间中如何演化，特别是当动态矩阵 $A$ 是临界稳定的（所有特征值都在单位圆上，且没有特征值的模严格大于一）。具体要求如下：\n\n- 从线性高斯模型的基本定义和联合高斯分布的条件化法则出发，推导在顺序处理测量值时状态均值和协方差的递归更新公式。不要假设或引用任何预先推导好的递归公式；相反，应从多元高斯条件化以及全期望和全方差定律等第一性原理出发进行构建。\n- 将时间索引 $k$ 的未测量子空间定义为 $C$ 的零空间，即所有满足 $C u = 0$ 的 $u \\in \\mathbb{R}^n$ 的集合。使用该子空间的一组标准正交基 $W \\in \\mathbb{R}^{n \\times r}$，其中 $r = n - \\mathrm{rank}(C)$。将每次测量后“局限于”未测量子空间的后验不确定性量化为标量\n$$\n\\sigma_{k}^2 = \\mathrm{trace}\\!\\left(W^\\top P_{k|k} W\\right),\n$$\n其中 $P_{k|k}$ 是融合时刻 $k$ 的测量值之后的状态协方差。\n- 使用推导出的递归公式，实现一个程序，对每个提供的测试用例，将滤波器迭代指定的步数，并返回第 $N$ 步的最终子空间不确定性 $\\sigma_{N}^2$。\n\n所有量均为无量纲量；不涉及物理单位。\n\n用于实现和评估的测试套件：\n\n- 情况1（秩亏测量和单位动态矩阵的理想情况）：\n  - $n = 2$, $m = 1$,\n  - $A = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix}$,\n  - $C = \\begin{bmatrix} 1  0 \\end{bmatrix}$,\n  - $Q = \\begin{bmatrix} 0.01  0 \\\\ 0  0.01 \\end{bmatrix}$,\n  - $R = \\begin{bmatrix} 0.04 \\end{bmatrix}$,\n  - $\\mu_0 = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$,\n  - $P_0 = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix}$,\n  - $N = 50$。\n- 情况2（秩亏测量和临界稳定的旋转动态矩阵，随时间耦合已测和未测方向）：\n  - $n = 2$, $m = 1$,\n  - $A = \\begin{bmatrix} 0  -1 \\\\ 1  0 \\end{bmatrix}$,\n  - $C = \\begin{bmatrix} 1  0 \\end{bmatrix}$,\n  - $Q = \\begin{bmatrix} 0.01  0 \\\\ 0  0.01 \\end{bmatrix}$,\n  - $R = \\begin{bmatrix} 0.04 \\end{bmatrix}$,\n  - $\\mu_0 = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$,\n  - $P_0 = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix}$,\n  - $N = 200$。\n- 情况3（未测方向上没有过程噪声的边界情况）：\n  - $n = 2$, $m = 1$,\n  - $A = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix}$,\n  - $C = \\begin{bmatrix} 1  0 \\end{bmatrix}$,\n  - $Q = \\begin{bmatrix} 0.01  0 \\\\ 0  0 \\end{bmatrix}$,\n  - $R = \\begin{bmatrix} 0.04 \\end{bmatrix}$,\n  - $\\mu_0 = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$,\n  - $P_0 = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix}$,\n  - $N = 50$。\n\n程序要求：\n\n- 实现从基本高斯条件化原理推导出的序贯滤波递归。在适当之处使用数值稳定的线性代数方法。\n- 对每个测试用例，计算最终的后验协方差 $P_{N|N}$，然后计算 $\\sigma_{N}^2 = \\mathrm{trace}\\!\\left(W^\\top P_{N|N} W\\right)$，其中 $W$ 是 $\\mathrm{null}(C)$ 的任意一组标准正交基。\n- 最终输出格式：你的程序应生成单行输出，其中包含按测试用例顺序排列的结果，形式为方括号括起来的逗号分隔列表，每个元素是四舍五入到六位小数的 $\\sigma_{N}^2$，即 $[\\sigma_{N,1}^2,\\sigma_{N,2}^2,\\sigma_{N,3}^2]$。", "solution": "该问题要求从第一性原理出发，为线性高斯状态空间模型推导递归状态估计算法，并应用此递归公式计算状态的未测量子空间中不确定性的演化。\n\n### 第1步：问题陈述的验证\n\n所提供的问题是计算科学与控制理论中一个定义明确的标准练习，具体涉及卡尔曼滤波器。\n\n**已知条件：**\n- 状态演化模型：$x_{k+1} = A x_k + w_k$，其中 $x_k \\in \\mathbb{R}^n$。\n- 测量模型：$y_k = C x_k + v_k$，其中 $y_k \\in \\mathbb{R}^m$。\n- 状态转移矩阵：$A \\in \\mathbb{R}^{n \\times n}$。\n- 测量矩阵：$C \\in \\mathbb{R}^{m \\times n}$。\n- 过程噪声：$w_k \\sim \\mathcal{N}(0,Q)$，协方差为 $Q \\in \\mathbb{R}^{n \\times n}$。\n- 测量噪声：$v_k \\sim \\mathcal{N}(0,R)$，协方差为 $R \\in \\mathbb{R}^{m \\times m}$。\n- 初始状态分布：$x_0 \\sim \\mathcal{N}(\\mu_0, P_0)$。\n- 噪声过程 $w_k$ 和 $v_k$ 彼此独立且为白噪声（跨时间独立）。\n- 未测量子空间不确定性度量：$\\sigma_{k}^2 = \\mathrm{trace}\\!\\left(W^\\top P_{k|k} W\\right)$，其中 $W$ 是 $\\mathrm{null}(C)$ 的一组标准正交基。\n- 提供了三个具体的测试用例，包含了所有参数（$A, C, Q, R, \\mu_0, P_0, N$）。\n\n**验证：**\n1.  **科学上成立**：该问题基于概率论的基本原理（特别是多元高斯分布的性质）和线性系统理论。所描述的模型是标准的离散时间线性高斯状态空间模型，所要求的推导即卡尔曼滤波器的推导，它是现代估计理论的基石。所有概念都经过严格建立。\n2.  **定义明确**：问题结构清晰。它要求进行推导，然后对具体、完全定义的测试用例进行数值计算。所要求的输出 $\\sigma_N^2$ 是一个可以从给定输入计算出的唯一且有意义的量。\n3.  **客观性**：语言精确、数学化，没有任何主观或模糊的术语。\n4.  **完整且一致**：为每个测试用例提供了所有必要的参数、初始条件和定义。设置中没有矛盾之处。\n5.  **可形式化且相关**：问题本质上是形式化和数学化的，它直接涉及卡尔曼滤波这一主题，这是计算科学中用于信号处理、控制和数据同化的关键算法。\n\n**结论：** 该问题有效。\n\n### 第2步：递归估计算法的推导\n\n我们从高斯分布的性质推导卡尔曼滤波器递归。该过程在每个时间索引 $k$ 包含两个步骤：预测步（将状态在时间上向前投影）和更新步（用新的测量值校正状态估计）。我们将截至时间 $k$ 的所有测量值的信息集表示为 $Y_k = \\{y_1, \\dots, y_k\\}$。状态估计由其条件均值和协方差来表征。\n\n设在给定截至时间 $k-1$ 的所有测量值的条件下，时间 $k-1$ 的状态后验分布为高斯分布：\n$$x_{k-1} | Y_{k-1} \\sim \\mathcal{N}(\\mu_{k-1|k-1}, P_{k-1|k-1})$$\n\n**1. 预测步**\n目标是确定在给定截至时间 $k-1$ 的测量值的条件下，时间 $k$ 的状态 $x_k$ 的分布。这是时间步 $k$ 的先验分布。状态根据 $x_k = A x_{k-1} + w_{k-1}$ 演化。\n预测状态的均值使用全期望定律求得：\n$$\n\\mu_{k|k-1} = \\mathbb{E}[x_k | Y_{k-1}] = \\mathbb{E}[A x_{k-1} + w_{k-1} | Y_{k-1}]\n$$\n根据期望的线性性质，并且由于 $w_{k-1}$ 是零均值且独立于过去的状态和测量值：\n$$\n\\mu_{k|k-1} = A \\mathbb{E}[x_{k-1} | Y_{k-1}] + \\mathbb{E}[w_{k-1} | Y_{k-1}] = A \\mu_{k-1|k-1} + 0 = A \\mu_{k-1|k-1}\n$$\n预测状态的协方差使用全方差定律求得：\n$$\nP_{k|k-1} = \\mathrm{Cov}(x_k | Y_{k-1}) = \\mathrm{Cov}(A x_{k-1} + w_{k-1} | Y_{k-1})\n$$\n由于状态 $x_{k-1}$（在给定 $Y_{k-1}$ 的条件下）和过程噪声 $w_{k-1}$ 是独立的：\n$$\nP_{k|k-1} = \\mathrm{Cov}(A x_{k-1} | Y_{k-1}) + \\mathrm{Cov}(w_{k-1} | Y_{k-1}) = A \\mathrm{Cov}(x_{k-1} | Y_{k-1}) A^\\top + \\mathrm{Cov}(w_{k-1})\n$$\n这给出了预测状态协方差：\n$$\nP_{k|k-1} = A P_{k-1|k-1} A^\\top + Q\n$$\n因此，预测的状态分布为 $x_k | Y_{k-1} \\sim \\mathcal{N}(\\mu_{k|k-1}, P_{k|k-1})$。\n\n**2. 更新步**\n目标是使用新的测量值 $y_k$ 更新 $x_k$ 的预测（先验）分布，以获得后验分布 $p(x_k | Y_k)$。这是一个贝叶斯更新。由于所有分布都是高斯的，我们可以通过分析在 $Y_{k-1}$ 条件下 $(x_k, y_k)$ 的联合分布来找到后验分布。\n首先，我们构造联合向量 $\\begin{pmatrix} x_k \\\\ y_k \\end{pmatrix}$ 并求其在给定 $Y_{k-1}$ 下的条件分布。\n均值为：\n$$\n\\mathbb{E}\\left[\\begin{pmatrix} x_k \\\\ y_k \\end{pmatrix} \\Big| Y_{k-1}\\right] = \\begin{pmatrix} \\mathbb{E}[x_k | Y_{k-1}] \\\\ \\mathbb{E}[C x_k + v_k | Y_{k-1}] \\end{pmatrix} = \\begin{pmatrix} \\mu_{k|k-1} \\\\ C \\mu_{k|k-1} \\end{pmatrix}\n$$\n协方差矩阵为：\n$$\n\\mathrm{Cov}\\left(\\begin{pmatrix} x_k \\\\ y_k \\end{pmatrix} \\Big| Y_{k-1}\\right) = \\begin{pmatrix} \\mathrm{Cov}(x_k | Y_{k-1})  \\mathrm{Cov}(x_k, y_k | Y_{k-1}) \\\\ \\mathrm{Cov}(y_k, x_k | Y_{k-1})  \\mathrm{Cov}(y_k | Y_{k-1}) \\end{pmatrix}\n$$\n对角块为：\n- $\\mathrm{Cov}(x_k | Y_{k-1}) = P_{k|k-1}$ （来自预测步）。\n- $\\mathrm{Cov}(y_k | Y_{k-1}) = \\mathrm{Cov}(C x_k + v_k | Y_{k-1}) = C \\mathrm{Cov}(x_k | Y_{k-1}) C^\\top + \\mathrm{Cov}(v_k) = C P_{k|k-1} C^\\top + R$。这是新息协方差，记为 $S_k$。\n非对角块为：\n- $\\mathrm{Cov}(x_k, y_k | Y_{k-1}) = \\mathrm{Cov}(x_k, C x_k + v_k | Y_{k-1})$。由于 $x_k$（在给定 $Y_{k-1}$ 的条件下）和 $v_k$ 是独立的，这简化为 $\\mathrm{Cov}(x_k, C x_k | Y_{k-1}) = \\mathrm{Cov}(x_k | Y_{k-1}) C^\\top = P_{k|k-1} C^\\top$。\n因此，联合分布为：\n$$\n\\begin{pmatrix} x_k \\\\ y_k \\end{pmatrix} \\Big| Y_{k-1} \\sim \\mathcal{N}\\left( \\begin{pmatrix} \\mu_{k|k-1} \\\\ C \\mu_{k|k-1} \\end{pmatrix}, \\begin{pmatrix} P_{k|k-1}  P_{k|k-1} C^\\top \\\\ C P_{k|k-1}  S_k \\end{pmatrix} \\right)\n$$\n我们现在使用分块高斯变量的条件分布公式。如果 $\\begin{pmatrix} z_1 \\\\ z_2 \\end{pmatrix} \\sim \\mathcal{N}(\\begin{pmatrix} \\mu_1 \\\\ \\mu_2 \\end{pmatrix}, \\begin{pmatrix} \\Sigma_{11}  \\Sigma_{12} \\\\ \\Sigma_{21}  \\Sigma_{22} \\end{pmatrix})$，那么在给定 $z_2$ 的观测值时，$z_1$ 的分布是高斯的，其参数为：\n$$\n\\mathbb{E}[z_1 | z_2] = \\mu_1 + \\Sigma_{12} \\Sigma_{22}^{-1} (z_2 - \\mu_2)\n$$\n$$\n\\mathrm{Cov}(z_1 | z_2) = \\Sigma_{11} - \\Sigma_{12} \\Sigma_{22}^{-1} \\Sigma_{21}\n$$\n将此应用于我们的问题，令 $z_1 = x_k$ 和 $z_2 = y_k$，我们得到后验均值 $\\mu_{k|k}$ 和协方差 $P_{k|k}$：\n$$\n\\mu_{k|k} = \\mu_{k|k-1} + (P_{k|k-1} C^\\top) S_k^{-1} (y_k - C \\mu_{k|k-1})\n$$\n$$\nP_{k|k} = P_{k|k-1} - (P_{k|k-1} C^\\top) S_k^{-1} (C P_{k|k-1})\n$$\n通过将卡尔曼增益定义为 $K_k = P_{k|k-1} C^\\top S_k^{-1}$，更新方程变为：\n$$\n\\mu_{k|k} = \\mu_{k|k-1} + K_k (y_k - C \\mu_{k|k-1})\n$$\n$$\nP_{k|k} = P_{k|k-1} - K_k C P_{k|k-1} = (I - K_k C) P_{k|k-1}\n$$\n$P_{k|k}$ 的第二种形式是Joseph形式，由于其有助于保持协方差矩阵的对称性和半正定性，因此因其数值稳定性而通常被优先选用。\n\n### 第3步：子空间不确定性计算算法\n\n问题要求计算后验协方差 $P_{k|k}$ 的演化。推导出的 $P_{k|k}$ 更新方程不依赖于具体的测量值 $y_k$，而仅依赖于系统矩阵（$A, C, Q, R$）。因此，我们可以确定性地迭代协方差递归。\n\n**算法：**\n1.  **初始化**：将时间 $k=0$ 的后验协方差设为 $P_{0|0} = P_0$。\n2.  **迭代**：对于 $k=1, \\dots, N$：\n    a. **预测步**：计算第 $k$ 步的先验协方差：\n       $$P_{k|k-1} = A P_{k-1|k-1} A^\\top + Q$$\n    b. **更新步**：计算第 $k$ 步的后验协方差：\n       i. 新息协方差：$S_k = C P_{k|k-1} C^\\top + R$。\n       ii. 卡尔曼增益：$K_k = P_{k|k-1} C^\\top S_k^{-1}$。\n       iii. 后验协方差：$P_{k|k} = (I - K_k C) P_{k|k-1}$。\n3.  **子空间不确定性**：经过 $N$ 次迭代后，我们得到最终的后验协方差 $P_{N|N}$。\n    a. 确定测量矩阵 $C$ 的零空间的一组标准正交基 $W$，即 $\\mathrm{null}(C) = \\{u \\in \\mathbb{R}^n | Cu = 0\\}$。这可以使用 $C$ 的奇异值分解（SVD）来计算。\n    b. 局限于该子空间的不确定性计算如下：\n       $$\\sigma_{N}^2 = \\mathrm{trace}(W^\\top P_{N|N} W)$$\n\n**测试用例分析：**\n- **情况1**：$A=I$。动态不混合状态分量。由于 $C=[1, 0]$，只有第一个分量被测量。第二个分量的不确定性不会因测量而减少，并且会由于过程噪声 $Q$ 而线性增长。我们预期 $\\sigma_N^2 = (P_0)_{22} + N \\cdot Q_{22}$。\n- **情况2**：$A$ 是一个旋转矩阵。动态混合了状态分量。在第 $k$ 步未被测量的分量将在未来的某个步骤被旋转到已测量的子空间中。这使得系统完全可观测。协方差 $P_{k|k}$ 预计将收敛到一个稳态值，$\\sigma_k^2$ 也是如此。\n- **情况3**：$A=I$ 且过程噪声 $Q$ 对于未测量的分量为零。未测量方向上的不确定性既不因测量而减少，也不因过程噪声而增加。因此，它应保持其初始值不变。我们预期 $\\sigma_N^2 = (P_0)_{22}$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import linalg\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    It iterates through each case, simulates the Kalman filter covariance evolution,\n    and computes the final uncertainty in the unmeasured subspace.\n    \"\"\"\n\n    # Test cases defined in the problem statement.\n    test_cases = [\n        {\n            # Case 1: Identity dynamics, rank-deficient measurement\n            \"n\": 2, \"m\": 1,\n            \"A\": np.array([[1.0, 0.0], [0.0, 1.0]]),\n            \"C\": np.array([[1.0, 0.0]]),\n            \"Q\": np.array([[0.01, 0.0], [0.0, 0.01]]),\n            \"R\": np.array([[0.04]]),\n            \"P0\": np.array([[1.0, 0.0], [0.0, 1.0]]),\n            \"N\": 50,\n        },\n        {\n            # Case 2: Rotation dynamics, coupling measured/unmeasured states\n            \"n\": 2, \"m\": 1,\n            \"A\": np.array([[0.0, -1.0], [1.0, 0.0]]),\n            \"C\": np.array([[1.0, 0.0]]),\n            \"Q\": np.array([[0.01, 0.0], [0.0, 0.01]]),\n            \"R\": np.array([[0.04]]),\n            \"P0\": np.array([[1.0, 0.0], [0.0, 1.0]]),\n            \"N\": 200,\n        },\n        {\n            # Case 3: Identity dynamics, no process noise in unmeasured direction\n            \"n\": 2, \"m\": 1,\n            \"A\": np.array([[1.0, 0.0], [0.0, 1.0]]),\n            \"C\": np.array([[1.0, 0.0]]),\n            \"Q\": np.array([[0.01, 0.0], [0.0, 0.0]]),\n            \"R\": np.array([[0.04]]),\n            \"P0\": np.array([[1.0, 0.0], [0.0, 1.0]]),\n            \"N\": 50,\n        }\n    ]\n\n    def run_filter_covariance(A, C, Q, R, P0, N):\n        \"\"\"\n        Iterates the Kalman filter covariance equations for N steps.\n\n        Args:\n            A (np.ndarray): State transition matrix.\n            C (np.ndarray): Measurement matrix.\n            Q (np.ndarray): Process noise covariance.\n            R (np.ndarray): Measurement noise covariance.\n            P0 (np.ndarray): Initial state covariance.\n            N (int): Number of steps to iterate.\n\n        Returns:\n            np.ndarray: The final posterior covariance P_N|N.\n        \"\"\"\n        n = A.shape[0]\n        I = np.eye(n)\n        P_kk = P0\n        \n        for _ in range(N):\n            # Prediction step for covariance\n            P_k_km1 = A @ P_kk @ A.T + Q\n            \n            # Update step for covariance\n            # Innovation covariance\n            S_k = C @ P_k_km1 @ C.T + R\n            # Kalman gain\n            K_k = P_k_km1 @ C.T @ np.linalg.inv(S_k)\n            # Posterior covariance update (Joseph form for stability)\n            P_kk = (I - K_k @ C) @ P_k_km1\n            \n        return P_kk\n\n    results = []\n    for case in test_cases:\n        # Unpack parameters for the current case\n        A, C, Q, R, P0, N = case[\"A\"], case[\"C\"], case[\"Q\"], case[\"R\"], case[\"P0\"], case[\"N\"]\n        \n        # 1. Run the covariance filter to get the final posterior covariance P_N|N\n        P_NN = run_filter_covariance(A, C, Q, R, P0, N)\n        \n        # 2. Find an orthonormal basis for the null space of C\n        # The columns of W form the basis.\n        W = linalg.null_space(C)\n        \n        # 3. Compute the uncertainty in the unmeasured subspace\n        # This is trace(W^T * P_NN * W)\n        if W.shape[1] == 0: # Check if null space is empty\n             sigma_N_sq = 0.0\n        else:\n             sigma_N_sq = np.trace(W.T @ P_NN @ W)\n        \n        results.append(sigma_N_sq)\n    \n    # Format the final output as specified\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3149199"}]}