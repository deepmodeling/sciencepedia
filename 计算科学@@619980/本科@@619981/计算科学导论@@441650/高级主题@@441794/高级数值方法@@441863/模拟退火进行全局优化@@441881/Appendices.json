{"hands_on_practices": [{"introduction": "要想真正掌握模拟退火算法，没有什么比从头开始构建一个求解器更好的方法了。第一个练习将指导您为Rastrigin函数实现一个完整的模拟退火求解器，这是一个经典的优化基准问题，以其大量的局部最小值而闻名，这使得简单的优化方法难以求解。通过完成这个练习 [@problem_id:3193392]，您将获得关于模拟退火所有核心组件的实践经验，包括定义能量函数、生成候选解、实现Metropolis接受准则以及管理降温过程。", "problem": "实现一个完整的模拟退火（SA）求解器，以在有界连续域上近似最小化多元Rastrigin能量函数，并凭经验研究收敛质量如何随维度扩展。您的程序必须是自包含的，并为下面指定的固定测试套件生成结果。\n\n基本基础：基于以下基石构建您的算法。\n- $n$维Rastrigin能量由下式给出\n$$E(\\mathbf{x}) = A n + \\sum_{i=1}^{n} \\left(x_i^2 - A \\cos(2\\pi x_i)\\right),$$\n域约束为$\\mathbf{x} \\in [-B,B]^n$。使用$A = 10$和$B = 5.12$。所有三角函数参数均以弧度为单位。\n- 在温度$T$下，构型$\\mathbf{x}$的目标稳态分布（玻尔兹曼形式）正比于$\\exp\\!\\left(-E(\\mathbf{x})/T\\right)$。\n- 当提议分布对称时，Metropolis机制必须强制执行关于稳态分布的细致平衡。\n- 使用几何降温方案$T_{k+1} = \\alpha T_k$，其中 $0  \\alpha  1$，且$T_0 > 0$。\n- 在$\\mathbb{R}^n$中使用对称高斯提议机制。\n\n设计约束和要求：\n1. 提议和域处理。\n   - 从当前状态$\\mathbf{x}$，提议$\\mathbf{y} = \\mathbf{x} + \\boldsymbol{\\eta}$，其中$\\boldsymbol{\\eta} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma^2 \\mathbf{I})$，$\\sigma$是一个依赖于迭代的标量。\n   - 通过在边界处进行镜面反射来强制执行边界$\\mathbf{y} \\in [-B,B]^n$，而不是通过拒绝或钳位。也就是说，如果任何坐标超出区间，通过镜像对称将其反射回区间内；根据需要重复此过程，直到所有坐标都在$[-B,B]$内。\n   - 为保持与维度无关的步长，将名义步长参数$s_0$在每次迭代时按$\\sigma = \\left(s_0/\\sqrt{n}\\right)\\sqrt{T/T_0}$进行缩放。\n2. 接受规则。\n   - 从对称提议分布和玻尔兹曼稳态分布的细致平衡要求出发，推导一个接受规则。不要假设任何捷径公式；明确证明您的规则如何强制执行细致平衡。\n3. 降温方案和停止条件。\n   - 使用给定的$\\alpha$和$T_0$的几何方案。\n   - 每个测试用例使用固定的评估预算，等于指定的提议移动次数。每次提议计为一次目标函数评估。\n4. 性能指标。\n   - 对于每个测试用例，仅报告SA运行找到的最终最佳能量，四舍五入到六位小数。不涉及物理单位。\n5. 角度单位。\n   - 所有三角计算必须使用弧度。\n\n测试套件和参数：\n- 对所有用例使用$A = 10$和$B = 5.12$。\n- 在以下用例上运行算法，每个用例指定为一个元组$(n, \\text{seed}, \\text{evals}, T_0, \\alpha, s_0)$:\n  - 用例 1: $(1, 1, 4000, 5.0, 0.995, 0.5)$\n  - 用例 2: $(2, 2, 6000, 5.0, 0.995, 0.5)$\n  - 用例 3: $(5, 3, 10000, 5.0, 0.995, 0.5)$\n  - 用例 4: $(10, 4, 15000, 5.0, 0.995, 0.5)$\n  - 用例 5: $(20, 5, 20000, 5.0, 0.995, 0.5)$\n  - 用例 6 (固定维度下的降温方案敏感性): $(10, 6, 15000, 5.0, 0.999, 0.5)$\n\n您的程序必须做什么：\n- 按规定实现SA，包括反射处理、高斯对称提议、与玻尔兹曼一致的接受规则和几何降温。\n- 对于每个测试用例，使用提供的伪随机种子（以实现确定性可复现性），从$[-B,B]^n$上均匀采样的初始点开始。\n- 在恰好给定的评估次数后，返回找到的最终最佳能量。\n\n最终输出格式：\n- 您的程序应生成一行输出，其中包含一个逗号分隔的浮点数列表，四舍五入到六位小数，用方括号括起来，不含空格。第$i$个条目对应于上面列出的顺序中的用例$i$。例如，一个语法正确的输出看起来像\n$[\\text{r}_1,\\text{r}_2,\\text{r}_3,\\text{r}_4,\\text{r}_5,\\text{r}_6]$\n其中每个$\\text{r}_i$是小数点后恰好有六位数字的十进制数。", "solution": "问题陈述经评估为有效。它具有科学依据，提法恰当，客观，并包含构建唯一、可验证解决方案所需的所有必要信息。任务是实现一个模拟退火（SA）算法，以找到多元Rastrigin函数的近似全局最小值，其中所有算法组件和参数都已精确指定。\n\n该解决方案是基于统计力学和随机优化的基本原理开发的。\n\n1.  **目标函数**\n    需要最小化的能量函数是$n$维Rastrigin函数，定义为：\n    $$E(\\mathbf{x}) = A n + \\sum_{i=1}^{n} \\left(x_i^2 - A \\cos(2\\pi x_i)\\right)$$\n    指定的常数是$A = 10$和$B = 5.12$。任何状态向量$\\mathbf{x} = (x_1, x_2, \\ldots, x_n)$的定义域是超立方体$\\mathbf{x} \\in [-B, B]^n$。此函数的全局最小值是在$\\mathbf{x} = \\mathbf{0}$处的$E(\\mathbf{0}) = 0$。\n\n2.  **模拟退火与Metropolis-Hastings算法**\n    模拟退火是一种概率性元启发式算法，其灵感来源于冶金学中的物理退火过程。系统状态通过迭代演化，并逐渐降低一个称为温度$T$的控制参数。在高温$T$下，系统广泛地探索状态空间。随着$T$的降低，系统被引导进入一个低能量状态。\n\n    系统状态的演化由一个马尔可夫链控制，该链旨在在任何给定温度$T$下收敛到稳态玻尔兹曼分布：\n    $$P(\\mathbf{x}; T) = \\frac{1}{Z(T)} \\exp\\left(-\\frac{E(\\mathbf{x})}{T}\\right)$$\n    其中$Z(T)$是配分函数。该分布赋予低能量状态更高的概率。\n\n    为确保收敛到$P(\\mathbf{x}; T)$，转移机制必须满足细致平衡条件。设$W(\\mathbf{x} \\to \\mathbf{y})$是从状态$\\mathbf{x}$到状态$\\mathbf{y}$的转移概率。细致平衡要求：\n    $$P(\\mathbf{x}) W(\\mathbf{x} \\to \\mathbf{y}) = P(\\mathbf{y}) W(\\mathbf{y} \\to \\mathbf{x})$$\n    转移概率可以分解为提议概率$g(\\mathbf{y}|\\mathbf{x})$和接受概率$A(\\mathbf{y}|\\mathbf{x})$，使得$W(\\mathbf{x} \\to \\mathbf{y}) = g(\\mathbf{y}|\\mathbf{x}) A(\\mathbf{y}|\\mathbf{x})$。将此式和玻尔兹曼分布代入细致平衡方程，得到：\n    $$e^{-E(\\mathbf{x})/T} g(\\mathbf{y}|\\mathbf{x}) A(\\mathbf{y}|\\mathbf{x}) = e^{-E(\\mathbf{y})/T} g(\\mathbf{x}|\\mathbf{y}) A(\\mathbf{x}|\\mathbf{y})$$\n    问题指定了一个对称的提议分布，$g(\\mathbf{y}|\\mathbf{x}) = g(\\mathbf{x}|\\mathbf{y})$，基于各向同性高斯步长。这将条件简化为：\n    $$\\frac{A(\\mathbf{y}|\\mathbf{x})}{A(\\mathbf{x}|\\mathbf{y})} = \\frac{e^{-E(\\mathbf{y})/T}}{e^{-E(\\mathbf{x})/T}} = \\exp\\left(-\\frac{E(\\mathbf{y}) - E(\\mathbf{x})}{T}\\right)$$\n    满足此比率的标准Metropolis接受概率选择是：\n    $$A(\\mathbf{y}|\\mathbf{x}) = \\min\\left(1, \\exp\\left(-\\frac{\\Delta E}{T}\\right)\\right)$$\n    其中$\\Delta E = E(\\mathbf{y}) - E(\\mathbf{x})$。这就是实现的接受规则。如果新状态能量更低($\\Delta E \\le 0$)，则总是接受。如果能量更高($\\Delta E > 0$)，则以一定概率接受，该概率随着能量增量变大或温度变低而减小。这使得算法能够逃离局部最小值。\n\n3.  **算法实现**\n    SA求解器通过遵守指定的设计约束来实现。\n\n    _初始化_：\n    - 初始温度设置为$T_0$。\n    - 为可复现性设置伪随机数生成器的种子。\n    - 从定义域$[-B, B]^n$上的均匀分布中抽取一个初始状态$\\mathbf{x}_{\\text{current}}$。\n    - 计算能量$E_{\\text{current}} = E(\\mathbf{x}_{\\text{current}})$。\n    - 初始化找到的最佳状态和能量：$\\mathbf{x}_{\\text{best}} = \\mathbf{x}_{\\text{current}}$ 和 $E_{\\text{best}} = E_{\\text{current}}$。\n\n    _迭代循环_：算法进行固定次数（`evals`）的评估。\n    1.  **提议生成**：从当前状态$\\mathbf{x}_{\\text{current}}$生成一个新的候选状态$\\mathbf{y}_{\\text{new}}$。从一个$n$维正态分布$\\mathcal{N}(\\mathbf{0}, \\sigma^2 \\mathbf{I})$中抽取一个随机步长向量$\\boldsymbol{\\eta}$。提议方差$\\sigma^2$与温度相关，以适应搜索尺度：\n        $$\\sigma(T) = \\frac{s_0}{\\sqrt{n}}\\sqrt{\\frac{T}{T_0}}$$\n        其中$s_0$是一个名义步长参数。按$1/\\sqrt{n}$进行缩放可确保步长向量$\\|\\boldsymbol{\\eta}\\|$的期望幅度大致与维度$n$无关。原始提议是$\\mathbf{y}_{\\text{raw}} = \\mathbf{x}_{\\text{current}} + \\boldsymbol{\\eta}$。\n\n    2.  **边界处理**：定义域约束$\\mathbf{x} \\in [-B, B]^n$通过镜面反射来强制执行。$\\mathbf{y}_{\\text{raw}}$的任何坐标如果落在区间$[-B, B]$之外，就会被反射回区间内。重复此过程，直到该点位于定义域内。对于单个坐标$y_i$和宽度为$W=2B$的区间$[-B, B]$，此映射通过考虑在区间$[0, W]$上的移位坐标$y'_i = y_i + B$来实现。遍历的完整区间宽度的次数是$k = \\lfloor y'_i / W \\rfloor$。在$[0, W]$段内的位置是$y''_i = y'_i \\pmod{W}$。如果$k$是偶数，最终位置是$y_i''-B$。如果$k$是奇数，粒子被反射了奇数次，其位置是$(W-y_i'')-B$。最终的状态是$\\mathbf{y}_{\\text{new}}$。在实践意义上，这种确定性映射保留了Metropolis规则的对称性假设，正如在SA实现中通常所假设的那样。\n\n    3.  **接受**：计算能量$E_{\\text{new}} = E(\\mathbf{y}_{\\text{new}})$。能量变化为$\\Delta E = E_{\\text{new}} - E_{\\text{current}}$。新状态被接受，即$\\mathbf{x}_{\\text{current}} \\leftarrow \\mathbf{y}_{\\text{new}}$，其概率为上面定义的Metropolis概率$A(\\mathbf{y}_{\\text{new}}|\\mathbf{x}_{\\text{current}})$。\n\n    4.  **最佳状态跟踪**：在$\\mathbf{x}_{\\text{current}}$可能更新后，其能量与迄今为止找到的最佳能量$E_{\\text{best}}$进行比较。如果$E_{\\text{current}}  E_{\\text{best}}$，则我们设置$E_{\\text{best}} = E_{\\text{current}}$。\n\n    5.  **降温**：根据几何降温方案降低温度：$T_{k+1} = \\alpha T_k$。\n\n    _终止_：循环在`evals`次提议后终止。$E_{\\text{best}}$的最终值作为结果报告。\n\n4.  **测试套件执行**\n    该算法针对六个指定的测试用例执行，每个用例都有自己的一组参数$(n, \\text{seed}, \\text{evals}, T_0, \\alpha, s_0)$。每个用例的最终优化能量四舍五入到六位小数，并按要求格式化。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and runs a Simulated Annealing solver for the Rastrigin function\n    as per the problem specification.\n    \"\"\"\n\n    # --- Constants specified in the problem ---\n    A = 10.0\n    B = 5.12\n\n    def rastrigin(x: np.ndarray, n: int) - float:\n        \"\"\"\n        Calculates the Rastrigin energy function for a given vector x.\n        E(x) = An + sum(x_i^2 - A*cos(2*pi*x_i))\n        \"\"\"\n        if n == 0:\n            return 0.0\n        return A * n + np.sum(x**2 - A * np.cos(2 * np.pi * x))\n\n    def reflect_bounds(y: np.ndarray, B_val: float) - np.ndarray:\n        \"\"\"\n        Enforces domain bounds [-B_val, B_val]^n by specular reflection.\n        Handles proposals that may be far outside the boundaries by repeated\n        reflection until the point is inside.\n        \"\"\"\n        min_val = -B_val\n        max_val = B_val\n        width = max_val - min_val\n\n        y_shifted = y - min_val\n        \n        # Calculate how many times the point has \"wrapped\" around the interval\n        num_wraps = np.floor(y_shifted / width)\n        \n        # The position within the base interval [0, width]\n        y_wrapped = y_shifted % width\n        \n        # Create masks for even and odd numbers of wraps\n        even_mask = num_wraps % 2 == 0\n        odd_mask = ~even_mask\n        \n        y_reflected = np.zeros_like(y)\n        \n        # If even wraps, position is relative to min_val\n        y_reflected[even_mask] = min_val + y_wrapped[even_mask]\n        \n        # If odd wraps, position is reflected relative to max_val\n        y_reflected[odd_mask] = max_val - y_wrapped[odd_mask]\n        \n        return y_reflected\n\n    def run_simulated_annealing(n: int, seed: int, evals: int, T0: float, alpha: float, s0: float) - float:\n        \"\"\"\n        Executes a single run of the Simulated Annealing algorithm.\n        \"\"\"\n        # 1. Initialization\n        rng = np.random.default_rng(seed)\n        \n        T = T0\n        \n        # Initial point sampled uniformly from the domain\n        x_current = rng.uniform(-B, B, size=n)\n        E_current = rastrigin(x_current, n)\n        \n        E_best = E_current\n\n        # 2. Main Loop\n        for _ in range(evals):\n            # Propose a new state\n            sigma = (s0 / np.sqrt(n)) * np.sqrt(T / T0)\n            eta = rng.normal(loc=0.0, scale=sigma, size=n)\n            y_raw = x_current + eta\n            \n            # Enforce boundary conditions via reflection\n            y_new = reflect_bounds(y_raw, B)\n            \n            # Evaluate the new state\n            E_new = rastrigin(y_new, n)\n            \n            # Metropolis acceptance criterion\n            delta_E = E_new - E_current\n            \n            # Accept if better or with probability exp(-delta_E / T)\n            if delta_E  0 or rng.random()  np.exp(-delta_E / T):\n                x_current = y_new\n                E_current = E_new\n            \n            # Update the best energy found so far (from accepted states)\n            if E_current  E_best:\n                E_best = E_current\n                \n            # Cool down the temperature\n            T *= alpha\n            \n        return E_best\n\n    # --- Test Suite ---\n    test_cases = [\n        # (n, seed, evals, T0, alpha, s0)\n        (1, 1, 4000, 5.0, 0.995, 0.5),\n        (2, 2, 6000, 5.0, 0.995, 0.5),\n        (5, 3, 10000, 5.0, 0.995, 0.5),\n        (10, 4, 15000, 5.0, 0.995, 0.5),\n        (20, 5, 20000, 5.0, 0.995, 0.5),\n        (10, 6, 15000, 5.0, 0.999, 0.5),\n    ]\n\n    results = []\n    for case in test_cases:\n        best_energy = run_simulated_annealing(*case)\n        # Round to 6 decimal places and format to ensure trailing zeros\n        results.append(f\"{round(best_energy, 6):.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3193392"}, {"introduction": "在掌握了基本的模拟退火求解器之后，我们现在转向一个能够展示其独特优势的实际应用。这个练习 [@problem_id:3193389] 旨在解决稀疏信号恢复问题，其目标是从一组有限的测量数据中找到一个简单的底层信号——这是压缩感知和机器学习领域的一项核心任务。您会将其构建为一个组合优化问题，并发现模拟退火算法通过概率性地接受“上坡”移动，能够如何逃离那些会困住简单贪心算法的局部最优点，从而实现更精确的信号重建。", "problem": "给定一个稀疏信号重构任务，该任务被构建为一个带有非凸稀疏性惩罚的全局优化问题。设 $A \\in \\mathbb{R}^{m \\times n}$ 是一个测量矩阵，其列向量被归一化为单位 $\\ell_2$ 范数，$y \\in \\mathbb{R}^{m}$ 是观测数据向量，$x \\in \\mathbb{R}^{n}$ 是未知的 $K$-稀疏系数向量。考虑以下目标函数\n$$\nf(x) \\;=\\; \\lVert A x - y \\rVert_2^2 \\;+\\; \\lambda \\sum_{i=1}^n \\phi\\!\\left(\\lvert x_i \\rvert\\right),\n\\quad\\text{其中}\\quad\n\\phi(t) \\;=\\; \\log\\!\\left(1 + \\gamma t\\right),\n$$\n其中 $\\lambda  0$ 且 $\\gamma  0$。惩罚项 $\\phi(\\cdot)$ 在 $x$ 中是非凸的，这使得 $f(\\cdot)$ 通常也是非凸的。\n\n你必须基于统计力学中的正则系综来实现模拟退火 (SA)。将目标函数 $f(\\cdot)$ 视为能量函数，并使用源自玻尔兹曼分布的 Metropolis 接受概率。具体来说，当从当前状态向候选状态提议一个移动时，以如下概率接受候选状态\n$$\np_{\\text{accept}} \\;=\\; \\min\\!\\left(1, \\exp\\!\\left(-\\frac{\\Delta f}{T}\\right)\\right),\n$$\n其中 $\\Delta f$ 是目标函数的变化量，$T$ 是当前温度。使用指数冷却策略 $T_k = T_0 \\, r^k$，其中指定了初始温度 $T_0  0$ 和冷却速率 $0  r  1$。将 SA 状态定义为一个大小固定为 $\\lvert S \\rvert = K$ 的支撑集 $S \\subset \\{1,2,\\dots,n\\}$，并通过将一个索引 $i \\in S$ 与一个索引 $j \\notin S$ 交换来定义单步邻域。对于任何支撑集 $S$，令 $x^\\star(S)$ 表示限制在 $S$ 上的最小二乘 (LS) 解，即 $\\lVert A_S x_S - y \\rVert_2^2$ 在 $x_S \\in \\mathbb{R}^{K}$ 上的最小化子，且对于所有 $i \\notin S$，$x_i = 0$。通过将 $x^\\star(S)$ 代入 $f(\\cdot)$ 来评估支撑集 $S$ 的 $f$ 值：\n$$\nf\\big(x^\\star(S)\\big) \\;=\\; \\left\\| A_S x^\\star_S - y \\right\\|_2^2 \\;+\\; \\lambda \\sum_{i \\in S} \\log\\!\\left(1 + \\gamma \\left|x^\\star_i\\right|\\right).\n$$\n\n作为一种基准的“贪婪阈值法”，通过选取具有最大绝对相关性 $\\lvert (A^\\top y)_i \\rvert$ 的 $K$ 个索引来构造 $S_{\\text{greedy}}$，然后计算 LS 系数 $x^\\star(S_{\\text{greedy}})$ 及其目标值。\n\n你的任务是编写一个完整的、可运行的程序，该程序能够：\n- 构建指定的测试套件实例，\n- 运行贪婪阈值基线以获得 $f\\big(x^\\star(S_{\\text{greedy}})\\big)$，\n- 从 $S_{\\text{greedy}}$ 开始，使用指定的 $(T_0, r)$ 和固定的迭代次数，在支撑集上运行模拟退火，以获得最终的支撑集 $S_{\\text{SA}}$ 和 $f\\big(x^\\star(S_{\\text{SA}})\\big)$，\n- 对每个测试用例，输出一个布尔值，指示 SA 是否严格改进了目标函数，即 $f\\big(x^\\star(S_{\\text{SA}})\\big)  f\\big(x^\\star(S_{\\text{greedy}})\\big)$ 是否成立。\n\n测试套件必须按如下方式构建。对于每种情况，所有随机抽样都使用提供的种子以保证可复现性，并且 $A$ 的列必须归一化为单位 $\\ell_2$ 范数：\n\n1.  具有中等稀疏度和噪声的正常路径情况：\n    - 参数：$m=32$, $n=64$, $K=5$, $\\lambda=0.10$, $\\gamma=10$, 噪声标准差 $\\sigma=0.05$。\n    - 种子：$12345$。\n    - 构建：抽取具有独立标准正态分布条目的 $A$ 并归一化其列；抽取一个 $K$-稀疏的真实值 (ground-truth) $x_{\\text{true}}$，其非零项从标准正态分布中抽取；设置 $y = A x_{\\text{true}} + \\sigma \\cdot \\varepsilon$，其中 $\\varepsilon \\sim \\mathcal{N}(0, I_m)$。\n    - SA 策略：$T_0 = 1.0$, $r = 0.995$, 迭代次数 $N_{\\text{SA}} = 3000$。\n\n2.  用于挑战贪婪阈值法的对抗性相关性情况：\n    - 参数：$m=32$, $n=64$, $K=5$, $\\lambda=0.10$, $\\gamma=10$, 噪声标准差 $\\sigma=0.05$。\n    - 种子：$54321$。\n    - 构建：如情况 1 中那样抽取 $A$ 和 $x_{\\text{true}}$，并类似地构成 $y$；然后选择一个随机索引 $j_{\\text{bad}} \\notin \\operatorname{supp}(x_{\\text{true}})$，并将 $A$ 的第 $j_{\\text{bad}}$ 列替换为与 $y$ 成比例并加上一个小的扰动的归一化向量，即设置 $A_{\\cdot j_{\\text{bad}}} \\leftarrow \\frac{y + 0.01 \\eta}{\\lVert y + 0.01 \\eta \\rVert_2}$，其中 $\\eta \\sim \\mathcal{N}(0, I_m)$，并重新归一化该列。这使得 $\\lvert (A^\\top y)_{j_{\\text{bad}}} \\rvert$ 非常大，从而误导贪婪阈值法。\n    - SA 策略：$T_0 = 1.0$, $r = 0.995$, 迭代次数 $N_{\\text{SA}} = 4000$。\n\n3.  高噪声情况：\n    - 参数：$m=24$, $n=48$, $K=4$, $\\lambda=0.20$, $\\gamma=8$, 噪声标准差 $\\sigma=0.20$。\n    - 种子：$111$。\n    - 构建：如情况 1。\n    - SA 策略：$T_0 = 1.0$, $r = 0.995$, 迭代次数 $N_{\\text{SA}} = 3500$。\n\n4.  边界稀疏性情况 ($K=1$) 且噪声较低：\n    - 参数：$m=16$, $n=32$, $K=1$, $\\lambda=0.05$, $\\gamma=12$, 噪声标准差 $\\sigma=0.01$。\n    - 种子：$222$。\n    - 构建：如情况 1。\n    - SA 策略：$T_0 = 1.0$, $r = 0.995$, 迭代次数 $N_{\\text{SA}} = 2500$。\n\n你的程序必须生成一行输出，其中包含四个测试用例的结果，格式为用方括号括起来的逗号分隔列表，例如 `[true,false,true,true]`，但使用 Python 的布尔值格式。不涉及物理单位、角度或百分比；所有量都是无单位的实数值。最终输出必须严格遵循所述格式。", "solution": "该问题要求通过最小化一个非凸目标函数，来实现和比较两种稀疏信号重构的方法。目标是找到一个 $K$-稀疏向量 $x \\in \\mathbb{R}^{n}$，以最小化\n$$\nf(x) \\;=\\; \\lVert A x - y \\rVert_2^2 \\;+\\; \\lambda \\sum_{i=1}^n \\phi\\!\\left(\\lvert x_i \\rvert\\right),\n\\quad\\text{其中}\\quad\n\\phi(t) \\;=\\; \\log\\!\\left(1 + \\gamma t\\right).\n$$\n第一项 $\\lVert A x - y \\rVert_2^2$ 是一个标准的最小二乘数据保真项，用于衡量模型 $A x$ 对观测值 $y$ 的拟合程度。第二项是一个促进稀疏性的惩罚项，其中 $\\lambda  0$ 控制着两者之间的权衡。函数 $\\phi(t) = \\log(1 + \\gamma t)$ 是一个非凸惩罚项，这使得整个目标函数 $f(x)$ 也是非凸的，从而导致多个局部最小值的存在。这种非凸性是主要的挑战，因为简单的基于梯度的方法容易陷入次优解。\n\n该问题将其构建为在支撑集上的组合优化。我们搜索空间中的一个状态是一个基数固定为 $\\lvert S \\rvert = K$ 的支撑集 $S \\subset \\{1, 2, \\dots, n\\}$。对于任何给定的支撑集 $S$，最优系数通过解决一个限制在由 $S$ 索引的 $A$ 的列上的标准最小二乘问题来找到。设 $A_S$ 是包含这些列的 $A$ 的子矩阵。此支撑集上的最优系数，表示为 $x^\\star_S$，是 $\\min_{z_S \\in \\mathbb{R}^K} \\lVert A_S z_S - y \\rVert_2^2$ 的解。该解可以使用标准的线性最小二乘求解器计算，得到 $x^\\star_S = (A_S^\\top A_S)^{-1} A_S^\\top y$。然后，通过将不在 $S$ 中的分量设置为零来构造完整的向量 $x^\\star(S)$。状态 $S$ 的“能量”是在此 $x^\\star(S)$ 处评估的目标函数：\n$$\nE(S) \\;=\\; f\\big(x^\\star(S)\\big) \\;=\\; \\left\\| A_S x^\\star_S - y \\right\\|_2^2 \\;+\\; \\lambda \\sum_{i \\in S} \\log\\!\\left(1 + \\gamma \\left|x^\\star_i\\right|\\right).\n$$\n\n一个基准的“贪婪阈值法”被用于比较。这种启发式方法通过选择与相关向量 $c = A^\\top y$ 的最大绝对值相对应的 $K$ 个索引来构造初始支撑集 $S_{\\text{greedy}}$。该方法计算成本低但比较短视，因为它没有考虑所选列之间的相互作用，并且很容易被误导，例如，被那些与测量向量 $y$ 高度相关但并非真实底层支撑集一部分的列所误导。\n\n模拟退火 (SA) 被用作一种更复杂的全局优化元启发式算法，以克服贪婪方法的局限性。SA 借鉴了冶金学中的退火过程，即材料被加热然后缓慢冷却以增大晶体尺寸并减少缺陷。\n1.  **初始化**：搜索从贪婪法提供的支撑集 $S_{\\text{current}} = S_{\\text{greedy}}$ 开始。这提供了一个合理的起点。\n2.  **邻域**：一个支撑集 $S$ 的邻域被定义为所有可以通过将单个索引 $i \\in S$ 与单个索引 $j \\notin S$ 交换而达到的支撑集。在每次迭代中，从当前支撑集 $S_{\\text{current}}$ 生成一个随机邻居 $S_{\\text{candidate}}$。\n3.  **Metropolis 接受准则**：算法评估能量的变化，$\\Delta E = E(S_{\\text{candidate}}) - E(S_{\\text{current}})$。如果 $\\Delta E  0$，则候选状态更好，该移动总是被接受。如果 $\\Delta E \\ge 0$，则移动到一个更差的状态，但它仍可能以玻尔兹曼因子给出的概率 $p_{\\text{accept}} = \\exp(-\\Delta E/T)$ 被接受。这种进行“上坡”移动的能力对于跳出局部最小值至关重要。参数 $T$ 是“温度”，它调节这个概率。\n4.  **冷却策略**：在整个搜索过程中，温度 $T$ 逐渐降低。指定的指数冷却策略是 $T_k = T_0 r^k$，其中 $T_0$ 是初始温度，$r \\in (0, 1)$ 是冷却速率，$k$ 是迭代次数。在高温下，算法广泛地探索搜索空间，容易接受更差的解。随着 $T$ 的降低，算法变得更具选择性，主要接受更好的解，并最终收敛到一个低能量状态。\n\n对于每个测试用例，我们根据指定的参数和随机种子生成问题数据 $(A, y)$。我们计算贪婪解 $S_{\\text{greedy}}$ 及其目标值 $f_{\\text{greedy}}$。然后，我们从 $S_{\\text{greedy}}$ 开始，运行 SA 算法固定次数的迭代。记录在整个 SA 运行期间找到的最佳支撑集 $S_{\\text{SA}}$ 及其对应的目标值 $f_{\\text{SA}}$。最后，我们通过检查是否 $f_{\\text{SA}}  f_{\\text{greedy}}$ 来确定 SA 算法是否找到了一个严格更优的解。报告每个用例的此比较的布尔结果。特别地，对抗性情况的构建是为了展示一个 $S_{\\text{greedy}}$ 被故意设计为次优的场景，从而为 SA 展示其卓越的全局搜索能力提供了明确的机会。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the specified test cases and print the results.\n    \"\"\"\n    test_cases = [\n        # Case 1: Happy-path\n        {\n            'm': 32, 'n': 64, 'K': 5, 'lam': 0.10, 'gam': 10, 'sigma': 0.05,\n            'seed': 12345, 'T0': 1.0, 'r': 0.995, 'iters': 3000, 'adversarial': False\n        },\n        # Case 2: Adversarial correlation\n        {\n            'm': 32, 'n': 64, 'K': 5, 'lam': 0.10, 'gam': 10, 'sigma': 0.05,\n            'seed': 54321, 'T0': 1.0, 'r': 0.995, 'iters': 4000, 'adversarial': True\n        },\n        # Case 3: High-noise\n        {\n            'm': 24, 'n': 48, 'K': 4, 'lam': 0.20, 'gam': 8, 'sigma': 0.20,\n            'seed': 111, 'T0': 1.0, 'r': 0.995, 'iters': 3500, 'adversarial': False\n        },\n        # Case 4: Boundary sparsity (K=1)\n        {\n            'm': 16, 'n': 32, 'K': 1, 'lam': 0.05, 'gam': 12, 'sigma': 0.01,\n            'seed': 222, 'T0': 1.0, 'r': 0.995, 'iters': 2500, 'adversarial': False\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_case(**case)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # Booleans are converted to lowercase strings to match the example.\n    print(f\"[{','.join(str(r).lower() for r in results)}]\")\n\ndef run_case(m, n, K, lam, gam, sigma, seed, T0, r, iters, adversarial):\n    \"\"\"\n    Runs a single test case for the sparse reconstruction problem.\n    \"\"\"\n    np.random.seed(seed)\n\n    # Generate data\n    A = np.random.randn(m, n)\n    A /= np.linalg.norm(A, axis=0)\n\n    x_true = np.zeros(n)\n    true_support_indices = np.random.choice(n, K, replace=False)\n    x_true[true_support_indices] = np.random.randn(K)\n\n    noise = np.random.randn(m)\n    y = A @ x_true + sigma * noise\n\n    if adversarial:\n        all_indices = set(range(n))\n        true_support_set = set(true_support_indices)\n        outside_support = list(all_indices - true_support_set)\n        j_bad = np.random.choice(outside_support)\n        \n        eta = np.random.randn(m)\n        new_col = y + 0.01 * eta\n        new_col /= np.linalg.norm(new_col)\n        A[:, j_bad] = new_col\n\n    def evaluate_objective(support_indices, A_mat, y_vec, lam_param, gam_param):\n        \"\"\"\n        Calculates the objective function for a given support set.\n        \"\"\"\n        S_list = sorted(list(support_indices))\n        if not S_list:\n            resid_norm_sq = np.linalg.norm(y_vec)**2\n            penalty = 0.0\n        else:\n            A_S = A_mat[:, S_list]\n            # Solve the least squares problem: A_S x_S = y\n            x_S = np.linalg.lstsq(A_S, y_vec, rcond=None)[0]\n            \n            resid_norm_sq = np.linalg.norm(A_S @ x_S - y_vec)**2\n            \n            penalty = lam_param * np.sum(np.log(1 + gam_param * np.abs(x_S)))\n            \n        return resid_norm_sq + penalty\n\n    # Greedy Thresholding Baseline\n    correlations = np.abs(A.T @ y)\n    S_greedy = set(np.argsort(correlations)[-K:])\n    f_greedy = evaluate_objective(S_greedy, A, y, lam, gam)\n\n    # Simulated Annealing\n    S_current = S_greedy\n    f_current = f_greedy\n    S_best = S_current\n    f_best = f_greedy\n\n    all_indices = set(range(n))\n    T = T0\n\n    for _ in range(iters):\n        # Generate a neighbor by swapping one index\n        S_outside = all_indices - S_current\n        if not list(S_current) or not list(S_outside): # Handles K=0 or K=n case\n            continue\n        idx_to_remove = np.random.choice(list(S_current))\n        idx_to_add = np.random.choice(list(S_outside))\n\n        S_candidate = S_current.copy()\n        S_candidate.remove(idx_to_remove)\n        S_candidate.add(idx_to_add)\n\n        f_candidate = evaluate_objective(S_candidate, A, y, lam, gam)\n        delta_f = f_candidate - f_current\n\n        # Metropolis acceptance criterion\n        if delta_f  0:\n            accept = True\n        else:\n            prob = np.exp(-delta_f / T)\n            if np.random.rand()  prob:\n                accept = True\n            else:\n                accept = False\n        \n        if accept:\n            S_current = S_candidate\n            f_current = f_candidate\n\n        if f_current  f_best:\n            S_best = S_current\n            f_best = f_current\n            \n        # Exponential cooling\n        T *= r\n        \n    f_SA = f_best\n\n    return f_SA  f_greedy\n\nif __name__ == '__main__':\n    solve()\n\n```", "id": "3193389"}, {"introduction": "我们最后的练习将探索一种提高搜索过程效率的高级技巧。我们将设计一种自适应的提议机制，它能根据能量景观的局部曲率智能地调整步长，在平坦区域迈出大的探索性步伐，而在接近最小值时则采取精确的小步。这个练习 [@problem_id:3193403] 将加深您对马尔可夫链蒙特卡洛方法理论基础的理解，因为您需要使用完整的Metropolis-Hastings准则来处理由此产生的非对称提议，并严格地维持细致平衡条件。", "problem": "要求您设计、分析并测试一个模拟退火转移核，该转移核使用一个根据局部曲率自适应调整步长的邻域函数来提议新状态。目标是从第一性原理出发进行推理，并验证两个属性：全局探索能力的提升和在固定温度下对细致平衡的保持。\n\n考虑一个一维能量景观，其坐标为 $x \\in \\mathbb{R}$，能量函数为\n$$\nE(x) = \\frac{x^2}{50} - \\sum_{i=1}^{3} a_i \\exp\\left(-\\frac{(x - b_i)^2}{2 c_i^2}\\right),\n$$\n参数为 $a_1 = 3.5$，$a_2 = 4.0$，$a_3 = 3.0$，$b_1 = -6.0$，$b_2 = 0.0$，$b_3 = 5.0$，$c_1 = 1.0$，$c_2 = 0.7$，$c_3 = 1.5$。函数 $E(x)$ 具有由负高斯势阱引导的多个局部极小值，以及一个限制了该景观范围的弱二次项。令 $E''(x)$ 表示 $E(x)$ 的二阶导数，在一维情况下，它与拉普拉斯算子 $\\nabla^2 E(x)$ 一致。\n\n推理必须基于以下经过充分检验的定义和原则：\n- 在固定温度 $T$ 下，玻尔兹曼平稳分布正比于 $\\exp(-E(x)/T)$。\n- 如果一个马尔可夫链蒙特卡洛（MCMC）方法的转移核相对于目标分布满足细致平衡条件，则该方法可以保持细致平衡。\n- 对于可能非对称的提议分布，Metropolis-Hastings (MH) 接受准则通过使用提议密度的比率进行校正来强制实现细致平衡。\n\n您必须构建两种用于生成候选状态的提议机制 $q(\\cdot \\mid x)$：\n- 基线提议：一个高斯提议 $y \\sim \\mathcal{N}(x, \\sigma_0^2)$，其步长 $\\sigma_0$ 为常数（与 $x$ 无关）。\n- 曲率感知提议：一个高斯提议 $y \\sim \\mathcal{N}(x, \\sigma(x)^2)$，其标准差根据局部曲率自适应调整，具体如下\n$$\n\\sigma(x) = \\mathrm{clip}\\left(\\frac{s_0}{\\sqrt{1 + \\alpha \\, |E''(x)|}}, \\ \\sigma_{\\min}, \\ \\sigma_{\\max}\\right),\n$$\n其中 $s_0  0$ 是一个基础尺度，$\\alpha \\ge 0$ 控制对曲率大小 $|E''(x)|$ 的敏感度，$\\mathrm{clip}(u, \\ell, r)$ 表示将 $u$ 的值限制在区间 $[\\ell, r]$ 内。\n\n对于这两种提议，通过实现 Metropolis-Hastings 接受概率来在固定温度 $T$ 下强制实现细致平衡\n$$\na(x,y) = \\min\\left(1,\\ \\exp\\left(-\\frac{E(y)-E(x)}{T}\\right)\\ \\frac{q(x \\mid y)}{q(y \\mid x)}\\right),\n$$\n其中 $q(y \\mid x)$ 是给定 $x$ 时提议 $y$ 的密度。对于基线提议，$q$ 是对称的，因此比率得以简化；对于曲率感知提议，$q$ 通常是非对称的，必须显式地计算该比率。\n\n根据位于 $b_1 = -6$、$b_2 = 0$ 和 $b_3 = 5$ 的高斯势阱定义三个盆地中心。当链的状态 $x$ 满足 $|x - b_i| \\le c_i$ 时，记录为访问了盆地 $i$。全局探索分数是在一次运行中至少访问过一次的不同盆地的数量。\n\n您的程序必须实现以下测试套件。此处不存在任何角度，也没有物理单位。所有参数和输出都是纯数字。\n\n测试套件规范：\n- 测试 1 (基线，正常路径)：使用基线提议，恒定步长 $\\sigma_0 = 1.0$，温度 $T = 0.6$，总步数 $N = 5000$，初始状态 $x_0 = 0.0$，随机种子 $42$。输出如上所述的整数全局探索分数。\n- 测试 2 (曲率感知，正常路径)：使用曲率感知提议，参数为 $s_0 = 1.0$，$\\alpha = 5.0$，$\\sigma_{\\min} = 0.05$，$\\sigma_{\\max} = 2.0$，温度 $T = 0.6$，总步数 $N = 5000$，初始状态 $x_0 = 0.0$，随机种子 $42$。输出整数全局探索分数。\n- 测试 3 (固定 $T$ 下的数值细致平衡检查)：使用曲率感知参数 $s_0 = 1.0$，$\\alpha = 5.0$，$\\sigma_{\\min} = 0.05$，$\\sigma_{\\max} = 2.0$，温度 $T = 0.6$，通过计算以下公式来评估两个特定状态 $x = 0.5$ 和 $y = -2.1$ 之间的细致平衡等式\n$$\nL = \\exp\\left(-\\frac{E(x)}{T}\\right)\\ q(y \\mid x)\\ a(x,y), \\quad R = \\exp\\left(-\\frac{E(y)}{T}\\right)\\ q(x \\mid y)\\ a(y,x),\n$$\n其中 $a(\\cdot,\\cdot)$ 如上所定义。返回一个布尔值，表示绝对相对差异\n$$\n\\delta = \\frac{|L - R|}{\\max\\left(|L|, |R|, 10^{-12}\\right)}\n$$\n是否小于 $10^{-6}$ 的容差。\n- 测试 4 (敏感度和裁剪的边缘情况)：使用曲率感知提议，参数为 $s_0 = 1.0$，$\\alpha = 100.0$，$\\sigma_{\\min} = 0.05$，$\\sigma_{\\max} = 2.0$，温度 $T = 0.6$，总步数 $N = 5000$，初始状态 $x_0 = 0.0$，随机种子 $7$。输出整数全局探索分数。\n\n最终输出格式要求：您的程序应生成单行输出，其中包含四个测试的结果，格式为方括号内的逗号分隔列表，例如 $[r_1,r_2,r_3,r_4]$，其中 $r_1$、$r_2$ 和 $r_4$ 是整数，$r_3$ 是布尔值。不应打印任何其他文本。", "solution": "问题陈述已经过严格验证，被确定为是合理的、良定的，并具有科学依据。它提出了一个适合分析和实现的正式计算科学问题。所有必要的函数、参数和测试条件都已明确定义，从而可以得到唯一且可验证的解。\n\n问题的核心是设计和分析一个基于 Metropolis-Hastings 算法的马尔可夫链蒙特卡洛（MCMC）模拟，以便从目标概率分布中采样。目标分布是在固定温度 $T$ 下，一维能量景观 $E(x)$ 的玻尔兹曼分布。系统处于状态 $x$ 的平稳概率由 $P(x) \\propto \\exp(-E(x)/T)$ 给出。\n\n给定的能量景观定义为：\n$$\nE(x) = \\frac{x^2}{50} - \\sum_{i=1}^{3} a_i \\exp\\left(-\\frac{(x - b_i)^2}{2 c_i^2}\\right)\n$$\n该函数由一个宽广的二次势构成，这确保了能量景观是约束的（当 $|x| \\to \\infty$ 时，$E(x) \\to \\infty$），以及三个产生局部能量极小值的高斯势阱。\n\n所提议的自适应算法的一个关键组成部分是能量景观的局部曲率，由其二阶导数 $E''(x)$ 给出。我们首先推导这个量。一阶导数是：\n$$\nE'(x) = \\frac{d}{dx} \\left[ \\frac{x^2}{50} - \\sum_{i=1}^{3} a_i \\exp\\left(-\\frac{(x - b_i)^2}{2 c_i^2}\\right) \\right] = \\frac{x}{25} - \\sum_{i=1}^{3} a_i \\exp\\left(-\\frac{(x - b_i)^2}{2 c_i^2}\\right) \\left(-\\frac{x - b_i}{c_i^2}\\right)\n$$\n$$\nE'(x) = \\frac{x}{25} + \\sum_{i=1}^{3} \\frac{a_i(x - b_i)}{c_i^2} \\exp\\left(-\\frac{(x - b_i)^2}{2 c_i^2}\\right)\n$$\n进行二次微分可得：\n$$\nE''(x) = \\frac{d}{dx} E'(x) = \\frac{1}{25} + \\sum_{i=1}^{3} \\frac{a_i}{c_i^2} \\frac{d}{dx} \\left[ (x - b_i) \\exp\\left(-\\frac{(x - b_i)^2}{2 c_i^2}\\right) \\right]\n$$\n使用乘法法则，我们得到：\n$$\nE''(x) = \\frac{1}{25} + \\sum_{i=1}^{3} \\frac{a_i}{c_i^2} \\left[ 1 \\cdot \\exp\\left(-\\frac{(x - b_i)^2}{2 c_i^2}\\right) + (x - b_i) \\left( \\exp\\left(-\\frac{(x - b_i)^2}{2 c_i^2}\\right) \\left(-\\frac{x - b_i}{c_i^2}\\right) \\right) \\right]\n$$\n$$\nE''(x) = \\frac{1}{25} + \\sum_{i=1}^{3} \\frac{a_i}{c_i^2} \\exp\\left(-\\frac{(x - b_i)^2}{2 c_i^2}\\right) \\left[ 1 - \\frac{(x-b_i)^2}{c_i^2} \\right]\n$$\n这个 $E''(x)$ 的表达式对于曲率感知提议核是至关重要的。\n\nMetropolis-Hastings 算法生成一个状态序列，其中每个新状态 $y$ 都是根据提议分布 $q(y|x)$ 从当前状态 $x$ 中提议的，并以概率 $a(x,y)$ 被接受：\n$$\na(x,y) = \\min\\left(1, \\frac{P(y)q(x \\mid y)}{P(x)q(y \\mid x)}\\right) = \\min\\left(1, \\exp\\left(-\\frac{E(y)-E(x)}{T}\\right) \\frac{q(x \\mid y)}{q(y \\mid x)}\\right)\n$$\n这种构造确保了最终的马尔可夫链满足相对于 $P(x)$ 的细致平衡条件，从而保证了该链的平稳分布确实是 $P(x)$。\n\n我们分析两种提议核：\n\n1.  **基线提议**：一个以当前状态为中心的高斯分布，$y \\sim \\mathcal{N}(x, \\sigma_0^2)$。提议概率密度为 $q(y|x) = (2\\pi\\sigma_0^2)^{-1/2} \\exp(-(y-x)^2/(2\\sigma_0^2))$。该核是对称的，意味着 $q(y|x) = q(x|y)$，因为步长 $\\sigma_0$ 是常数。提议密度的比率为 $\\frac{q(x|y)}{q(y|x)} = 1$。接受概率简化为 Metropolis 形式：\n    $$\n    a_{\\text{baseline}}(x,y) = \\min\\left(1, \\exp\\left(-\\frac{E(y)-E(x)}{T}\\right)\\right)\n    $$\n    一个固定的步长 $\\sigma_0$ 存在一个权衡：如果它很大，在陡峭区域（极小值处）的接受率会很低；如果它很小，链混合会很慢，并且难以穿越极小值之间的平坦区域。\n\n2.  **曲率感知提议**：一个具有状态依赖步长的高斯分布，$y \\sim \\mathcal{N}(x, \\sigma(x)^2)$。步长 $\\sigma(x)$ 定义为：\n    $$\n    \\sigma(x) = \\mathrm{clip}\\left(\\frac{s_0}{\\sqrt{1 + \\alpha \\, |E''(x)|}}, \\ \\sigma_{\\min}, \\ \\sigma_{\\max}\\right)\n    $$\n    该设计旨在提高采样效率。在高曲率区域（大的 $|E''(x)|$），例如能量阱内部，$\\sigma(x)$ 很小，促进细粒度的局部探索。在低曲率区域（小的 $|E''(x)|$），例如势阱之间的平台区，$\\sigma(x)$ 很大，有助于能够跨越能量壁垒的大跳跃。\n    由于 $\\sigma(x)$ 依赖于状态，该提议核通常是非对称的：如果 $\\sigma(x) \\neq \\sigma(y)$，则 $q(y|x) \\neq q(x|y)$。因此，我们必须计算完整的提议密度比：\n    $$\n    q(y|x) = \\frac{1}{\\sqrt{2\\pi\\sigma(x)^2}} \\exp\\left(-\\frac{(y-x)^2}{2\\sigma(x)^2}\\right)\n    $$\n    $$\n    \\frac{q(x|y)}{q(y|x)} = \\frac{\\frac{1}{\\sqrt{2\\pi\\sigma(y)^2}} \\exp\\left(-\\frac{(x-y)^2}{2\\sigma(y)^2}\\right)}{\\frac{1}{\\sqrt{2\\pi\\sigma(x)^2}} \\exp\\left(-\\frac{(y-x)^2}{2\\sigma(x)^2}\\right)} = \\frac{\\sigma(x)}{\\sigma(y)} \\exp\\left(\\frac{(x-y)^2}{2} \\left[ \\frac{1}{\\sigma(x)^2} - \\frac{1}{\\sigma(y)^2} \\right] \\right)\n    $$\n    该比率正确地解释了非对称性，并且必须包含在接受概率的计算中以保持细致平衡。\n\n第三个测试用例提供了细致平衡条件的数值验证。该条件指出，对于任意两个状态 $x$ 和 $y$，在平稳分布中，从 $x$ 到 $y$ 的流率等于从 $y$ 到 $x$ 的流率：$P(x) K(y|x) = P(y) K(x|y)$，其中 $K(y|x) = q(y|x)a(x,y)$ 是全转移概率。代入定义，我们必须验证：\n$$\n\\exp(-E(x)/T) \\cdot q(y|x) \\cdot a(x,y) = \\exp(-E(y)/T) \\cdot q(x|y) \\cdot a(y,x)\n$$\n问题陈述中的量 $L$ 和 $R$ 正是该等式的左侧和右侧（相差一个可约去的全局归一化常数）。细致平衡属性意味着 $L=R$。该测试确认了此等式在数值浮点精度范围内成立。\n\n实现将首先定义能量 $E(x)$ 及其二阶导数 $E''(x)$。然后，将构建一个通用的 MCMC 模拟函数来处理两种提议类型。对于曲率感知的情况，它将计算 $\\sigma(x)$ 和非对称提议比率。全局探索分数是在模拟后通过检查 MCMC 轨迹与定义的盆地区域 $|x - b_i| \\le c_i$ 来计算的。细致平衡测试将是一个单独的函数，直接计算 $L$ 和 $R$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# from scipy import ... # No scipy is needed for this problem\n\ndef solve():\n    # Define global parameters for the energy function\n    A = np.array([3.5, 4.0, 3.0])\n    B = np.array([-6.0, 0.0, 5.0])\n    C = np.array([1.0, 0.7, 1.5])\n\n    def E(x):\n        \"\"\"Computes the energy E(x).\"\"\"\n        gauss_term = A * np.exp(-(x - B)**2 / (2 * C**2))\n        return x**2 / 50 - np.sum(gauss_term)\n\n    def E_ddot(x):\n        \"\"\"Computes the second derivative E''(x).\"\"\"\n        term = (A / C**2) * (1 - (x - B)**2 / C**2) * np.exp(-(x - B)**2 / (2 * C**2))\n        return 1/25 + np.sum(term)\n\n    def sigma_x(x, s0, alpha, s_min, s_max):\n        \"\"\"Computes the adaptive step size sigma(x).\"\"\"\n        val = s0 / np.sqrt(1 + alpha * np.abs(E_ddot(x)))\n        return np.clip(val, s_min, s_max)\n\n    def run_mcmc(params):\n        \"\"\"Runs a single MCMC simulation and returns the exploration score.\"\"\"\n        np.random.seed(params['seed'])\n        \n        T = params['T']\n        N = params['N']\n        x0 = params['x0']\n        \n        x_chain = np.zeros(N)\n        x_chain[0] = x0\n        x_current = x0\n        \n        is_baseline = params['type'] == 'baseline'\n\n        for i in range(1, N):\n            # 1. Propose a new state y\n            if is_baseline:\n                sigma_0 = params['sigma0']\n                y = np.random.normal(x_current, sigma_0)\n                sigma_current = sigma_y = sigma_0  # For consistency in ratio calc\n            else: # Curvature-aware\n                s0, alpha, s_min, s_max = params['s0'], params['alpha'], params['s_min'], params['s_max']\n                sigma_current = sigma_x(x_current, s0, alpha, s_min, s_max)\n                y = np.random.normal(x_current, sigma_current)\n                sigma_y = sigma_x(y, s0, alpha, s_min, s_max)\n\n            # 2. Calculate acceptance probability\n            delta_E = E(y) - E(x_current)\n\n            # For asymmetric proposal, calculate q(x|y)/q(y|x)\n            if is_baseline:\n                q_ratio = 1.0\n            else:\n                # Handle potential division by zero if sigma is clipped to a very small value\n                if sigma_y == 0:\n                    q_ratio = np.inf if sigma_current > 0 else 1.0\n                else:\n                    log_q_ratio = np.log(sigma_current) - np.log(sigma_y) + \\\n                                  0.5 * (y - x_current)**2 * (1/sigma_current**2 - 1/sigma_y**2)\n                    q_ratio = np.exp(log_q_ratio)\n            \n            acceptance_prob = min(1.0, np.exp(-delta_E / T) * q_ratio)\n\n            # 3. Accept or reject\n            if np.random.rand()  acceptance_prob:\n                x_current = y\n            \n            x_chain[i] = x_current\n\n        # Calculate exploration score\n        visited_basins = set()\n        for i, b_i in enumerate(B):\n            c_i = C[i]\n            if np.any(np.abs(x_chain - b_i) = c_i):\n                visited_basins.add(i)\n        \n        return len(visited_basins)\n\n    def check_detailed_balance(params):\n        \"\"\"Numerically verifies the detailed balance condition for two states.\"\"\"\n        x, y, T = params['x'], params['y'], params['T']\n        s0, alpha, s_min, s_max = params['s0'], params['alpha'], params['s_min'], params['s_max']\n\n        # Proposal densities q(y|x) and q(x|y)\n        sigma_at_x = sigma_x(x, s0, alpha, s_min, s_max)\n        sigma_at_y = sigma_x(y, s0, alpha, s_min, s_max)\n\n        # Using log densities to avoid underflow/overflow of exp\n        log_q_yx = -0.5 * np.log(2 * np.pi * sigma_at_x**2) - (y - x)**2 / (2 * sigma_at_x**2)\n        log_q_xy = -0.5 * np.log(2 * np.pi * sigma_at_y**2) - (x - y)**2 / (2 * sigma_at_y**2)\n        q_yx = np.exp(log_q_yx)\n        q_xy = np.exp(log_q_xy)\n\n        # Acceptance probabilities a(x,y) and a(y,x)\n        p_ratio_xy = np.exp(-(E(y) - E(x)) / T) * (q_xy / q_yx) if q_yx != 0 else np.inf\n        a_xy = min(1.0, p_ratio_xy)\n\n        p_ratio_yx = np.exp(-(E(x) - E(y)) / T) * (q_yx / q_xy) if q_xy != 0 else np.inf\n        a_yx = min(1.0, p_ratio_yx)\n\n        # LHS and RHS of detailed balance equation\n        L = np.exp(-E(x) / T) * q_yx * a_xy\n        R = np.exp(-E(y) / T) * q_xy * a_yx\n        \n        # Relative difference check\n        abs_diff = np.abs(L - R)\n        norm = max(np.abs(L), np.abs(R), 1e-12)\n        delta = abs_diff / norm\n        \n        return delta  1e-6\n\n    # Test cases from the problem statement\n    test_cases = [\n        # Test 1: Baseline\n        {'type': 'baseline', 'sigma0': 1.0, 'T': 0.6, 'N': 5000, 'x0': 0.0, 'seed': 42},\n        # Test 2: Curvature-aware\n        {'type': 'curvature', 's0': 1.0, 'alpha': 5.0, 's_min': 0.05, 's_max': 2.0, 'T': 0.6, 'N': 5000, 'x0': 0.0, 'seed': 42},\n        # Test 3: Detailed Balance Check\n        {'type': 'db_check', 's0': 1.0, 'alpha': 5.0, 's_min': 0.05, 's_max': 2.0, 'T': 0.6, 'x': 0.5, 'y': -2.1},\n        # Test 4: Curvature-aware (high alpha)\n        {'type': 'curvature', 's0': 1.0, 'alpha': 100.0, 's_min': 0.05, 's_max': 2.0, 'T': 0.6, 'N': 5000, 'x0': 0.0, 'seed': 7}\n    ]\n\n    results = []\n    for case in test_cases:\n        if case['type'] == 'db_check':\n            result = check_detailed_balance(case)\n        else:\n            result = run_mcmc(case)\n        results.append(result)\n\n    # Format boolean as lowercase for final output\n    formatted_results = [str(r).lower() if isinstance(r, bool) else str(r) for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3193403"}]}