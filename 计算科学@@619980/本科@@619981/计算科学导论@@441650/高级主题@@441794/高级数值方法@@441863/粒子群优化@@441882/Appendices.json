{"hands_on_practices": [{"introduction": "任何优化算法面临的一个核心问题是其性能如何随问题规模（即维度）的增加而变化。这个实践练习将引导你通过一个标准的数值基准测试，亲手探究粒子群优化（PSO）在面对高维问题时所遭遇的“维度灾难”。你将通过在一个简单的球形函数上测量算法达到预设精度所需的迭代次数，来量化分析维度对PSO收敛速度的影响，从而对这一基本挑战建立直观且深刻的认识。", "problem": "您的任务是设计并实现一个受控的数值基准测试，以研究搜索空间维度如何影响粒子群优化 (PSO) 算法在光滑凸测试函数上的性能。请仅使用定义、广为接受的公式和可复现的随机化方法。您的程序必须是一个完整、可运行的程序，能够计算并报告每个测试维度下的单一汇总性能指标。\n\n任务。使用粒子群优化 (PSO) 算法，在超立方体 $[-b,b]^d$（其中 $b = 5$）上最小化函数 $f(\\mathbf{x}) = \\sum_{j=1}^{d} x_j^2$。该算法使用固定的惯性权重 $w$，以及固定的认知加速度 $c_1$ 和社会加速度 $c_2$。使用规范的、被广泛采用的 PSO 速度-位置更新规则，其中每个粒子和每个坐标使用独立的均匀随机因子：\n- 速度更新：在迭代 $t$ 时，对于每个粒子 $i$ 和维度 $j$，\n$$v_{i,j}^{(t+1)} = w \\, v_{i,j}^{(t)} + c_1 \\, r_{i,j}^{(t,1)} \\left(pbest_{i,j}^{(t)} - x_{i,j}^{(t)}\\right) + c_2 \\, r_{i,j}^{(t,2)} \\left(gbest_{j}^{(t)} - x_{i,j}^{(t)}\\right),$$\n其中 $r_{i,j}^{(t,1)}$ 和 $r_{i,j}^{(t,2)}$ 是从 $[0,1]$ 上的均匀分布中采样的独立随机变量。\n- 速度限制：按分量强制 $v_{i,j}^{(t+1)} \\in [-v_{\\max}, v_{\\max}]$，其中 $v_{\\max} = 0.2 \\times 2b$。\n- 位置更新：\n$$x_{i,j}^{(t+1)} = \\mathrm{clip}\\left(x_{i,j}^{(t)} + v_{i,j}^{(t+1)}, -b, b\\right)。$$\n\n初始化。对于给定的维度 $d$，使用 $m(d)$ 个粒子，其位置从 $[-b,b]^d$ 上的均匀分布中独立采样，速度从 $[-v_{\\max}, v_{\\max}]^d$ 上的均匀分布中独立采样。将每个粒子的个体最优值 $pbest_i$ 初始化为其起始位置，并将全局最优值 $gbest$ 设置为所有初始 $pbest_i$ 中的最优值。\n\n终止条件与度量。固定一个目标容差 $\\varepsilon > 0$ 和一个最大迭代预算 $T_{\\max}$。将“达到-$\\varepsilon$时间”（time-to-$\\varepsilon$）定义为满足当前迄今为止最优目标值 $f(gbest^{(T)}) \\le \\varepsilon$ 的最小迭代次数 $T$。该评估在完成第 $T$ 次迭代的位置更新后进行。如果在 $T_{\\max}$ 次迭代内从未满足此条件，则将“达到-$\\varepsilon$时间”定义为 $T_{\\max}$。\n\n基准测试协议。对于给定测试套件中的每个维度 $d$，运行 PSO 算法 $R$ 次独立试验（每次使用不同的随机种子），并报告这 $R$ 次试验中“达到-$\\varepsilon$时间”的算术平均值。\n\n使用以下固定参数：\n- 惯性权重 $w = 0.7298$。\n- 认知加速度 $c_1 = 1.49618$。\n- 社会加速度 $c_2 = 1.49618$。\n- 边界参数 $b = 5$，因此 $v_{\\max} = 0.2 \\times 2b = 2$。\n- 迭代次数预算 $T_{\\max} = 500$。\n- 容差 $\\varepsilon = 10^{-6}$。\n- 试验次数 $R = 3$。\n- 粒子群大小安排 $m(d) = \\min(10d, 200)$。\n- 随机化：使用固定的基础种子 $s_0 = 1337$；对于维度 $d$ 和试验索引 $r \\in \\{0,1,\\dots,R-1\\}$，使用种子 $s(d,r) = s_0 + 100d + r$。\n\n测试套件。您必须在以下维度上评估基准测试：\n- $d \\in \\{1, 5, 20, 50\\}$。\n\n输出规范。您的程序应生成单行输出，其中包含按上述顺序排列的每个 $d$ 的平均“达到-$\\varepsilon$时间”，格式为一个逗号分隔的十进制数列表，每个数字小数点后精确到三位，并用方括号括起来。例如，输出必须类似于 $[a_1,a_2,a_3,a_4]$，其中每个 $a_k$ 是一个小数点后精确到三位的浮点数。\n\n单位。“达到-$\\varepsilon$时间”是迭代次数的计数，因此是无量纲的；请将其报告为实数（十进制数），以便在各次试验中进行平均。\n\n您的程序必须是自包含的，不需要任何输入，并严格遵守指定的输出格式。", "solution": "问题陈述已经过分析，并被确定为**有效**。它在计算优化领域提出了一个定义明确且科学上合理的数值实验。所有必要的参数、方程和评估协议都得到了清晰而精确的规定，从而可以进行可复现的实现。该任务是客观、自包含的，并基于粒子群优化 (PSO) 的既定原则。\n\n目标是在超立方体域 $\\mathbf{x} \\in [-b, b]^d$ 内最小化球函数，该函数定义为 $f(\\mathbf{x}) = \\sum_{j=1}^{d} x_j^2$，其中 $d$ 是搜索空间的维度，边界参数为 $b=5$。该基准测试旨在分析 PSO 算法的性能如何随维度的增加而变化。\n\n解决方案的核心在于实现规范的 PSO 算法。一个包含 $m(d)$ 个粒子的粒子群状态由它们的位置 $\\mathbf{x}_i$ 和速度 $\\mathbf{v}_i$（其中 $i=1, \\dots, m(d)$）来描述。在每次迭代 $t$ 中，每个粒子的速度和位置都会根据以下针对每个维度 $j$ 的规则进行更新：\n\n1.  **速度更新**：粒子 $i$ 的速度根据其先前的速度、其个体已知的最佳位置 ($\\mathbf{pbest}_i$) 以及整个粒子群发现的全局最佳位置 ($\\mathbf{gbest}$) 进行更新。\n    $$v_{i,j}^{(t+1)} = w \\, v_{i,j}^{(t)} + c_1 \\, r_{i,j}^{(t,1)} \\left(pbest_{i,j}^{(t)} - x_{i,j}^{(t)}\\right) + c_2 \\, r_{i,j}^{(t,2)} \\left(gbest_{j}^{(t)} - x_{i,j}^{(t)}\\right)$$\n    参数是固定的：惯性权重 $w = 0.7298$，认知加速度 $c_1 = 1.49618$，社会加速度 $c_2 = 1.49618$。项 $r_{i,j}^{(t,1)}$ 和 $r_{i,j}^{(t,2)}$ 是在每次迭代中为每个粒子和维度从 $[0,1]$ 上的均匀分布中独立采样的随机数。\n\n2.  **速度限制**：为防止粒子速度过大而导致粒子群不稳定，每个速度分量都被限制在范围 $[-v_{\\max}, v_{\\max}]$ 内，其中 $v_{\\max} = 0.2 \\times (2b) = 2$。\n\n3.  **位置更新**：通过将更新后的速度加到当前位置上来计算粒子 $i$ 的新位置。然后对位置进行硬性裁剪，以确保其保持在搜索边界 $[-b, b]$ 内。\n    $$x_{i,j}^{(t+1)} = \\mathrm{clip}\\left(x_{i,j}^{(t)} + v_{i,j}^{(t+1)}, -b, b\\right)$$\n\n对测试套件 $\\{1, 5, 20, 50\\}$ 中的每个维度 $d$ 执行基准测试协议。对每个 $d$，执行以下步骤：\n-   粒子群大小设置为 $m(d) = \\min(10d, 200)$。\n-   为考虑 PSO 的随机性，算法运行 $R=3$ 次独立试验。\n-   通过使用确定性种子策略来确保可复现性：对于维度 $d$ 中的试验 $r \\in \\{0, 1, 2\\}$，随机数生成器使用种子 $s(d,r) = 1337 + 100d + r$ 进行初始化。\n-   在每次试验中，粒子的位置从 $[-5, 5]^d$ 中均匀采样进行初始化，速度从 $[-2, 2]^d$ 中均匀采样进行初始化。\n-   单次试验的性能度量是“达到-$\\varepsilon$时间”，定义为全局最优目标值 $f(\\mathbf{gbest}^{(T)})$ 降至或低于容差 $\\varepsilon = 10^{-6}$ 的首次迭代次数 $T$。如果在最大迭代预算 $T_{\\max} = 500$ 内未能达到此容差，则“达到-$\\varepsilon$时间”设为 $T_{\\max}$。\n-   每个维度 $d$ 的最终报告值是在 $R=3$ 次试验中获得的“达到-$\\varepsilon$时间”值的算术平均值。\n\n实现是用 Python 编写的，利用 `numpy` 库进行高效的向量化计算。这种方法避免了对粒子和维度的显式循环，使代码既简洁又高效。该程序精确遵循规定的协议，计算平均性能指标，并按规定格式化最终输出。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to orchestrate the PSO benchmark study.\n    It iterates through the specified dimensions, runs multiple trials for each,\n    computes the mean performance, and prints the final formatted result.\n    \"\"\"\n    \n    def run_pso_trial(d: int, seed: int) -> int:\n        \"\"\"\n        Executes a single trial of the Particle Swarm Optimization algorithm.\n\n        Args:\n            d: The dimension of the search space.\n            seed: The seed for the random number generator.\n\n        Returns:\n            The number of iterations to reach the target tolerance (\"time-to-epsilon\").\n        \"\"\"\n        rng = np.random.default_rng(seed)\n\n        # Fixed parameters from the problem statement\n        w = 0.7298\n        c1 = 1.49618\n        c2 = 1.49618\n        b = 5.0\n        v_max = 2.0\n        T_max = 500\n        eps = 1e-6\n        m = min(10 * d, 200)\n\n        # Initialization\n        # (m, d) array of particle positions\n        positions = rng.uniform(-b, b, size=(m, d))\n        # (m, d) array of particle velocities\n        velocities = rng.uniform(-v_max, v_max, size=(m, d))\n\n        # Personal best positions are initialized to the starting positions\n        pbest_positions = np.copy(positions)\n        # Objective function f(x) = sum(x_j^2)\n        pbest_values = np.sum(pbest_positions**2, axis=1)\n\n        # Global best initialization\n        gbest_idx = np.argmin(pbest_values)\n        gbest_value = pbest_values[gbest_idx]\n        gbest_position = np.copy(pbest_positions[gbest_idx])\n        \n        # If the solution is found at initialization (iteration 0)\n        if gbest_value = eps:\n            return 0\n\n        # Main optimization loop\n        for t in range(1, T_max + 1):\n            # Generate random factors for velocity update\n            r1 = rng.random(size=(m, d))\n            r2 = rng.random(size=(m, d))\n\n            # Update velocities (vectorized for all particles)\n            velocities = w * velocities + \\\n                         c1 * r1 * (pbest_positions - positions) + \\\n                         c2 * r2 * (gbest_position - positions)\n            \n            # Clamp velocities\n            velocities = np.clip(velocities, -v_max, v_max)\n\n            # Update positions\n            positions = positions + velocities\n            # Clip positions to stay within the search space\n            positions = np.clip(positions, -b, b)\n\n            # Evaluate objective function for all particles\n            current_values = np.sum(positions**2, axis=1)\n\n            # Update personal bests\n            improved_mask = current_values  pbest_values\n            pbest_values[improved_mask] = current_values[improved_mask]\n            pbest_positions[improved_mask] = positions[improved_mask]\n\n            # Update global best\n            min_pbest_idx = np.argmin(pbest_values)\n            if pbest_values[min_pbest_idx]  gbest_value:\n                gbest_value = pbest_values[min_pbest_idx]\n                gbest_position = pbest_positions[min_pbest_idx]\n\n            # Check for termination\n            if gbest_value = eps:\n                return t\n\n        # Return T_max if tolerance was not met\n        return T_max\n\n    # Benchmark protocol parameters\n    test_dims = [1, 5, 20, 50]\n    R = 3  # Number of trials\n    s0 = 1337  # Base seed\n\n    mean_results = []\n    for d in test_dims:\n        trial_times = []\n        for r in range(R):\n            # Calculate the deterministic seed for the trial\n            seed = s0 + 100 * d + r\n            time_to_eps = run_pso_trial(d, seed)\n            trial_times.append(time_to_eps)\n        \n        # Calculate the arithmetic mean of the time-to-epsilon\n        mean_time = np.mean(trial_times)\n        mean_results.append(mean_time)\n\n    # Format and print the final output as specified\n    formatted_results = [f'{res:.3f}' for res in mean_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n\n```", "id": "3161040"}, {"introduction": "在了解了维度对性能的影响之后，我们将探讨另一个常见的陷阱：过早收敛。这个实践将生动地展示，即便是在简单的一维问题中，不当的初始化也可能使整个粒子群陷入局部最优解的“陷阱”中无法自拔。你将首先复现这一失效场景，然后通过引入一种动态的随机跳转策略来增加种群的多样性，并亲自验证这种探索机制如何帮助粒子群成功逃逸局部最优，最终找到全局最优解。", "problem": "您需要设计并实现一个一维粒子群优化（PSO）实验，该实验将展示一种最坏情况下的初始化，它会将粒子群陷入一个严格的局部吸引盆地，然后通过引入带有时间相关概率的随机跳转来实现多样化，以缓解这种失效模式。您的程序必须模拟经典的PSO动态过程，并报告一个小型测试套件的量化结果。\n\n其基本依据是此处重现的经典PSO状态更新。设在一维空间中有$N$个粒子，粒子$i$在时间$t$的状态由其位置$x_{i,t} \\in \\mathbb{R}$和速度$v_{i,t} \\in \\mathbb{R}$给出。每个粒子都维持其个体最优位置$p_{i,t}$，而整个粒子群则维持一个全局最优位置$g_t$。经典更新规则如下\n$$\nv_{i,t+1} \\leftarrow \\omega\\, v_{i,t} \\;+\\; c_1\\, r_{1,i,t}\\, \\big(p_{i,t} - x_{i,t}\\big) \\;+\\; c_2\\, r_{2,i,t}\\, \\big(g_t - x_{i,t}\\big),\n$$\n$$\nx_{i,t+1} \\leftarrow x_{i,t} + v_{i,t+1},\n$$\n其中$r_{1,i,t}, r_{2,i,t} \\sim \\mathrm{Uniform}([0,1])$是独立的随机变量。在更新$x_{i,t+1}$后，评估目标函数$f(x_{i,t+1})$以标准方式更新$p_{i,t+1}$和$g_{t+1}$：当且仅当$f(x_{i,t+1})  f(p_{i,t})$时，$p_{i,t+1}$替换$p_{i,t}$；而$g_{t+1}$是集合$\\{p_{i,t+1}\\}_{i=1}^N$中的最优值。\n\n目标函数是一个光滑的多峰函数\n$$\nf(x) \\;=\\; x^2 \\;-\\; b \\exp\\!\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right),\n$$\n参数为$b = 12$，$\\mu = 4$和$\\sigma = 0.5$。搜索域是闭区间$\\mathcal{D} = [-L,L]$，其中$L = 6$。每次更新后，位置必须被限制在$\\mathcal{D}$内。\n\n导致陷阱的最坏情况初始化：将所有粒子的位置初始化在$x \\approx \\mu$附近的浅层局部吸引盆地内。具体来说，对于某个$\\delta > 0$，独立地从$\\mathrm{Uniform}([\\mu - \\delta, \\mu + \\delta])$中采样$x_{i,0}$，并设置$v_{i,0} = 0$，$p_{i,0} = x_{i,0}$，以及将$g_0$设为$\\{p_{i,0}\\}$中的最优值。使用$\\delta = 0.2$。这种构造确保了初始时对所有$i$都有$p_{i,0} - x_{i,0} = 0$，并且$g_0$也位于同一个浅层吸引盆地中。\n\n通过随机跳转实现多样化：在根据经典更新计算出$x_{i,t+1}$之后、评估$f(x_{i,t+1})$之前，对每个粒子$i$独立地应用以下规则。以概率$\\pi(t)$，从$\\mathrm{Uniform}(\\mathcal{D})$中抽取一个新位置$\\tilde{x}_{i,t+1}$，并设置$x_{i,t+1} \\leftarrow \\tilde{x}_{i,t+1}$和$v_{i,t+1} \\leftarrow 0$。否则，保持$x_{i,t+1}$和$v_{i,t+1}$不变。然后如上所述评估$f(x_{i,t+1})$并更新$p_{i,t+1}$和$g_{t+1}$。即使粒子群先前处于停滞状态，这种多样化方法通过使$p_{i,t} - x_{i,t}$和$g_t - x_{i,t}$在跳转后非零，从而注入了探索能力。\n\n算法要求：\n- 使用经典的PSO更新，其参数$\\omega$、$c_1$和$c_2$按每个测试用例的规定设置。\n- 对所有测试用例使用上述相同的初始化机制，但使用所提供的不同随机种子。\n- 所有随机数，包括初始位置、$r_{1,i,t}$、$r_{2,i,t}$以及随机跳转，都必须由一个按规定播种的可复现伪随机数生成器生成。\n- 每次位置更新和任何应用的跳转之后，将位置限制在$\\mathcal{D}$内。\n- 目标函数$f(x)$必须按照定义精确评估。本问题不涉及任何物理单位或角度。\n\n测试套件：实现五个测试用例，每个用例由一个元组$(N, T, \\omega, c_1, c_2, \\pi(\\cdot), \\text{seed})$定义。概率调度$\\pi(t)$是离散迭代索引$t \\in \\{0,1,\\dots,T-1\\}$的函数。\n\n- 案例A（无多样化，多粒子）：$N = 20$, $T = 80$, $\\omega = 0.6$, $c_1 = 1.7$, $c_2 = 1.7$, $\\pi(t) \\equiv 0$, $\\text{seed} = 123$。\n- 案例B（恒定多样化，多粒子）：$N = 20$, $T = 80$, $\\omega = 0.6$, $c_1 = 1.7$, $c_2 = 1.7$, $\\pi(t) \\equiv 0.05$, $\\text{seed} = 123$。\n- 案例C（退火多样化）：$N = 10$, $T = 120$, $\\omega = 0.7$, $c_1 = 1.5$, $c_2 = 1.5$, $\\pi(t) = 0.3 \\cdot \\big(1 - \\frac{t}{T}\\big)$, $\\text{seed} = 456$。\n- 案例D（边缘情况，单粒子，无多样化）：$N = 1$, $T = 120$, $\\omega = 0.7$, $c_1 = 1.5$, $c_2 = 1.5$, $\\pi(t) \\equiv 0$, $\\text{seed} = 789$。\n- 案例E（边缘情况，单粒子，恒定多样化）：$N = 1$, $T = 120$, $\\omega = 0.7$, $c_1 = 1.5$, $c_2 = 1.5$, $\\pi(t) \\equiv 0.2$, $\\text{seed} = 789$。\n\n对于所有案例，使用相同的目标函数参数$b = 12$，$\\mu = 4$，$\\sigma = 0.5$，搜索域半宽$L = 6$，以及初始化宽度$\\delta = 0.2$。\n\n要求输出：\n- 对每个测试用例，运行PSO $T$次迭代，并报告最终的最优目标值$\\min_{i} f(p_{i,T})$，结果为浮点数，四舍五入到四位小数。\n- 您的程序应产生单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$\\,[\\text{result}_1,\\text{result}_2,\\dots]$）。顺序必须是$[\\text{案例 A}, \\text{案例 B}, \\text{案例 C}, \\text{案例 D}, \\text{案例 E}]$。", "solution": "该问题在优化方法领域，特别是粒子群优化（PSO）方面，提出了一个定义明确且可通过计算验证的任务。所有参数、方程和实验条件都已明确定义，使得该问题有效且无科学或逻辑上的不一致之处。该设置旨在演示PSO的一种常见失效模式——过早收敛到局部最优值——以及一种使用概率性多样化机制的缓解策略。\n\n问题的核心是在几种参数配置下模拟一维PSO算法。该算法的目标是找到函数$f(x)$的全局最小值：\n$$\nf(x) = x^2 - b \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)\n$$\n参数为$b = 12$，$\\mu = 4$和$\\sigma = 0.5$，搜索域为$\\mathcal{D} = [-6, 6]$。该函数在$x=0$附近有一个全局最小值，其值$f(x) \\approx 0$；在$x \\approx 3.818$附近有一个显著的局部最小值，其值$f(x) \\approx 3.361$。\n\n算法过程将按如下方式实现，并遵循矢量化原则以提高计算效率。\n\n**1. 系统状态与初始化**\n\n$N$个粒子组成的粒子群的状态由它们的位置$x \\in \\mathbb{R}^N$和速度$v \\in \\mathbb{R}^N$定义。每个粒子还记录其迄今为止发现的个体最优位置$p_{best} \\in \\mathbb{R}^N$以及相应的目标函数值$f_{p_{best}} \\in \\mathbb{R}^N$。粒子群共同维护全局最优位置$g_{best} \\in \\mathbb{R}$，它是所有$f_{p_{best}}$中最小值所对应的个体最优位置。\n\n初始化被专门设计用来困住粒子群。所有粒子位置$x_i$（其中$i=1, \\dots, N$）均从均匀分布$\\mathrm{Uniform}([\\mu - \\delta, \\mu + \\delta])$（即$[3.8, 4.2]$）中抽取。该区域构成了局部最小值的吸引盆地。初始速度设为零，$v_{i,0}=0$。初始个体最优位置设为初始位置，$p_{best; i,0} = x_{i,0}$，初始全局最优值$g_{best,0}$则通过在这些初始位置上寻找$f(x)$的最小值来确定。每个案例都按规定播种一个可复现的伪随机数生成器，以确保结果的确定性。\n\n**2. 迭代动力学**\n\n模拟进行$T$个离散时间步（迭代）。在每个时间步$t$，状态更新到$t+1$。\n\n**2.1. 速度与位置更新**\n\n经典PSO算法的核心是更新每个粒子的速度和位置。使用矢量化表示，从时间$t$到$t+1$的更新如下：\n$$\nv_{t+1} \\leftarrow \\omega v_t + c_1 r_{1,t} \\odot (p_{best,t} - x_t) + c_2 r_{2,t} \\odot (g_{best,t} - x_t)\n$$\n$$\nx_{t+1} \\leftarrow x_t + v_{t+1}\n$$\n其中$\\omega$、$c_1$和$c_2$分别是惯性权重、认知系数和社会系数。符号$r_{1,t}, r_{2,t} \\in \\mathbb{R}^N$表示从$\\mathrm{Uniform}([0,1])$中独立抽取的随机数向量。运算符$\\odot$表示逐元素相乘。\n\n**2.2. 通过随机跳转实现多样化**\n\n为对抗过早收敛，引入了随机跳转机制。在位置更新后，对每个粒子$i$进行一次随机决策。以随时间变化的概率$\\pi(t)$，重置粒子的状态：其位置$x_{i,t+1}$被一个从整个搜索域$\\mathcal{D}$中均匀抽取的新位置替换，其速度$v_{i,t+1}$被重置为0。此操作使粒子脱离粒子群的共识，并强制其探索新区域。\n\n**2.3. 边界强制执行**\n\n在位置更新和任何可能的随机跳转之后，所有粒子位置必须被限制在搜索域$\\mathcal{D} = [-L, L]$内。这通过将位置向量$x_{t+1}$中的值裁剪到范围$[-6, 6]$来实现。\n\n**2.4. 适应度评估与最优位置更新**\n\n对所有新的粒子位置$x_{t+1}$评估目标函数$f(x)$，以获得当前适应度值的向量$f_{current}$。对于每个粒子$i$，如果其新的适应度$f_{current, i}$优于（即小于）其先前的个体最优适应度$f_{p_{best}, i}$，则更新其个体最优值：$p_{best, i, t+1} \\leftarrow x_{i,t+1}$且$f_{p_{best}, i, t+1} \\leftarrow f_{current, i}$。否则，它们保持不变。\n\n在更新所有个体最优值之后，通过在更新后的集合$\\{f_{p_{best}, i, t+1}\\}$中找到具有全局最小个体最优值的粒子，来确定新的全局最优位置$g_{best,t+1}$。\n\n**3. 模拟执行与输出**\n\n对问题陈述中定义的五个测试用例中的每一个，都执行这整个迭代过程。每个案例都指定了参数$(N, T, \\omega, c_1, c_2, \\pi(t), \\text{seed})$的唯一组合。在$T$次迭代之后，记录粒子群找到的最终最优目标值，即$\\min_{i} f(p_{best, i, T})$。最终输出是这些值的列表，每个测试用例一个值，格式化为四位小数。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the PSO simulation for all test cases and print results.\n    \"\"\"\n    # Fixed parameters from the problem statement\n    B_PARAM = 12.0\n    MU_PARAM = 4.0\n    SIGMA_PARAM = 0.5\n    L_PARAM = 6.0\n    DELTA_PARAM = 0.2\n\n    def objective_function(x, b=B_PARAM, mu=MU_PARAM, sigma=SIGMA_PARAM):\n        \"\"\"\n        Calculates the value of the objective function f(x).\n        \"\"\"\n        return x**2 - b * np.exp(-((x - mu)**2) / (2 * sigma**2))\n\n    def run_pso_simulation(N, T, omega, c1, c2, pi_func, seed):\n        \"\"\"\n        Runs a single PSO simulation with the given parameters.\n        \n        Args:\n            N (int): Number of particles.\n            T (int): Number of iterations.\n            omega (float): Inertia weight.\n            c1 (float): Cognitive coefficient.\n            c2 (float): Social coefficient.\n            pi_func (callable): Function pi(t, T) for jump probability.\n            seed (int): Seed for the random number generator.\n            \n        Returns:\n            float: The best objective value found after T iterations.\n        \"\"\"\n        # Initialize the pseudo-random number generator for reproducibility\n        rng = np.random.default_rng(seed)\n\n        # 1. Initialization\n        # Initial positions are sampled near the local minimum trap\n        x = rng.uniform(MU_PARAM - DELTA_PARAM, MU_PARAM + DELTA_PARAM, size=N)\n        \n        # Initial velocities are zero\n        v = np.zeros(N)\n        \n        # Personal best positions initialized to starting positions\n        p_best_pos = np.copy(x)\n        \n        # Personal best values are f(p_best_pos)\n        p_best_val = objective_function(p_best_pos)\n        \n        # Global best position is the one with the minimum initial value\n        g_best_idx = np.argmin(p_best_val)\n        g_best_pos = p_best_pos[g_best_idx]\n        \n        # 2. Main PSO loop\n        for t in range(T):\n            # Generate random numbers for this iteration's updates\n            r1 = rng.random(size=N)\n            r2 = rng.random(size=N)\n            \n            # Canonical PSO updates (vectorized for efficiency)\n            # Velocity update\n            v = omega * v + c1 * r1 * (p_best_pos - x) + c2 * r2 * (g_best_pos - x)\n            \n            # Position update\n            x = x + v\n            \n            # Diversification via random jumps\n            pi_t = pi_func(t, T)\n            if pi_t > 0:\n                jump_rand = rng.random(size=N)\n                jump_mask = jump_rand  pi_t\n                \n                if np.any(jump_mask):\n                    num_jumps = np.sum(jump_mask)\n                    # Draw new positions for jumping particles\n                    x[jump_mask] = rng.uniform(-L_PARAM, L_PARAM, size=num_jumps)\n                    # Reset velocity for jumping particles\n                    v[jump_mask] = 0.0\n\n            # Clipping positions to the search domain [-L, L]\n            x = np.clip(x, -L_PARAM, L_PARAM)\n            \n            # Evaluate objective function for new positions\n            f_x = objective_function(x)\n            \n            # Update personal bests\n            improvement_mask = f_x  p_best_val\n            p_best_pos[improvement_mask] = x[improvement_mask]\n            p_best_val[improvement_mask] = f_x[improvement_mask]\n            \n            # Update global best\n            g_best_idx = np.argmin(p_best_val)\n            g_best_pos = p_best_pos[g_best_idx]\n            \n        # After T iterations, return the best objective value found by any particle,\n        # which is the minimum of the final personal best values.\n        return np.min(p_best_val)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A: (N, T, omega, c1, c2, pi_func, seed) - No diversification\n        {'N': 20, 'T': 80, 'omega': 0.6, 'c1': 1.7, 'c2': 1.7, 'pi_func': lambda t, T_max: 0.0, 'seed': 123},\n        # Case B: Constant diversification\n        {'N': 20, 'T': 80, 'omega': 0.6, 'c1': 1.7, 'c2': 1.7, 'pi_func': lambda t, T_max: 0.05, 'seed': 123},\n        # Case C: Annealed diversification\n        {'N': 10, 'T': 120, 'omega': 0.7, 'c1': 1.5, 'c2': 1.5, 'pi_func': lambda t, T_max: 0.3 * (1 - t / T_max), 'seed': 456},\n        # Case D: Single particle, no diversification\n        {'N': 1, 'T': 120, 'omega': 0.7, 'c1': 1.5, 'c2': 1.5, 'pi_func': lambda t, T_max: 0.0, 'seed': 789},\n        # Case E: Single particle, constant diversification\n        {'N': 1, 'T': 120, 'omega': 0.7, 'c1': 1.5, 'c2': 1.5, 'pi_func': lambda t, T_max: 0.2, 'seed': 789},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_pso_simulation(**case)\n        results.append(f\"{result:.4f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3160999"}, {"introduction": "现实世界中的优化问题大多带有约束条件，解决方案必须在规定的可行域内。作为本章的收尾，这个实践聚焦于一个非常实际的问题：如何在PSO中处理边界约束，确保粒子始终在预定义的超矩形搜索空间 $[l, u]^d$ 内活动。你将实现并比较三种经典的边界处理策略——反射、吸收和随机重置，通过观察它们对粒子行为、可行性以及最终收敛性的不同影响，为你将来解决带约束的优化问题打下坚实的基础。", "problem": "考虑在超矩形上对移位的球形目标函数进行有界最小化。设 $d \\in \\mathbb{N}$，下界和上界分别为 $l \\in \\mathbb{R}$ 和 $u \\in \\mathbb{R}$ 且 $l  u$，以及一个移位向量 $a \\in \\mathbb{R}^d$。定义目标函数 $$f(x) = \\sum_{j=1}^{d} (x_j - a_j)^2,$$ 以及可行集 $$\\Omega = [l,u]^d = \\{x \\in \\mathbb{R}^d \\mid \\forall j \\in \\{1,\\dots,d\\}, \\, l \\le x_j \\le u\\}.$$ 无约束最小化器是 $x^\\star = a$，其函数值为 $f(x^\\star) = 0$。在箱式约束下，最小化器是 $a$ 在 $\\Omega$ 上的分量投影，即对每个 $j$，$\\tilde{a}_j = \\min(\\max(a_j, l), u)$，得到 $x^\\star_\\Omega = \\tilde{a}$。\n\n您的任务是实现一个完整、可运行的程序，使用粒子群优化 (PSO) 算法在 $\\Omega$ 上最小化 $f(x)$，并研究三种边界处理方案对可行性和收敛性的影响。粒子群优化 (PSO) 维护一个包含 $N$ 个粒子的群体，在第 $t$ 次迭代时，每个粒子的位置为 $x_i(t) \\in \\mathbb{R}^d$，速度为 $v_i(t) \\in \\mathbb{R}^d$。每个粒子跟踪其个体最佳位置 $p_i(t)$，整个粒子群跟踪全局最佳位置 $g(t)$。在每次迭代 $t$ 中，速度和位置根据典型的惯性 PSO 更新规则演化，其中 $$v_i(t+1) = w \\, v_i(t) + c_1 \\, r_1(t) \\odot (p_i(t) - x_i(t)) + c_2 \\, r_2(t) \\odot (g(t) - x_i(t)),$$ $$x_i(t+1) = x_i(t) + v_i(t+1),$$ 其中 $w \\in \\mathbb{R}$ 为惯性权重，$c_1 \\in \\mathbb{R}$ 和 $c_2 \\in \\mathbb{R}$ 为认知和社会系数，$r_1(t), r_2(t) \\in [0,1]^d$ 为从均匀分布中分量独立抽取的随机向量。算子 $\\odot$ 表示分量乘积。速度被逐分量地限制在 $[-v_{\\max}, v_{\\max}]$ 范围内，其中给定的 $v_{\\max} \\in \\mathbb{R}_{>0}$。初始位置在 $\\Omega$ 内均匀抽取，初始速度在 $[-v_{\\max}, v_{\\max}]^d$ 内均匀抽取。只有当观察到严格更小的目标函数值时，个体最佳和全局最佳位置才会更新。\n\n当尝试更新的位置 $x_i^{\\mathrm{prop}}(t+1) = x_i(t) + v_i(t+1)$ 落在 $\\Omega$ 之外时，需要进行边界处理。实现以下三种方案，每种方案对每个分量 $j$ 独立作用：\n\n- 反射 (Reflect)：如果 $x_{ij}^{\\mathrm{prop}} \\notin [l,u]$，则通过计算 $$z = \\frac{x_{ij}^{\\mathrm{prop}} - l}{u - l}, \\quad k = \\left\\lfloor z \\right\\rfloor, \\quad z_{\\mathrm{frac}} = z - k$$ 在区间 $[l,u]$ 上使用反射映射。设置 $$x_{ij}(t+1) = \\begin{cases} l + z_{\\mathrm{frac}}(u - l)  \\text{若 } k \\text{ 为偶数}, \\\\ u - z_{\\mathrm{frac}}(u - l)  \\text{若 } k \\text{ 为奇数}, \\end{cases}$$ 并且当 $k$ 为奇数时，翻转速度分量，即 $$v_{ij}(t+1) = \\begin{cases} v_{ij}(t+1)  \\text{若 } k \\text{ 为偶数}, \\\\ -v_{ij}(t+1)  \\text{若 } k \\text{ 为奇数}。 \\end{cases}$$ 如果 $x_{ij}^{\\mathrm{prop}} \\in [l,u]$，则保持 $x_{ij}(t+1) = x_{ij}^{\\mathrm{prop}}$ 和 $v_{ij}(t+1)$ 不变。\n\n- 吸收 (Absorb)：如果 $x_{ij}^{\\mathrm{prop}}  l$，设置 $x_{ij}(t+1) = l$ 和 $v_{ij}(t+1) = 0$。如果 $x_{ij}^{\\mathrm{prop}} > u$，设置 $x_{ij}(t+1) = u$ 和 $v_{ij}(t+1) = 0$。如果 $x_{ij}^{\\mathrm{prop}} \\in [l,u]$，则保持 $x_{ij}(t+1) = x_{ij}^{\\mathrm{prop}}$ 和 $v_{ij}(t+1)$ 不变。\n\n- 随机重启 (Random restart)：如果 $x_{ij}^{\\mathrm{prop}} \\notin [l,u]$，将 $x_{ij}(t+1)$ 设置为从 $[l,u]$ 中均匀抽取的一个新值，并设置 $v_{ij}(t+1) = 0$。如果 $x_{ij}^{\\mathrm{prop}} \\in [l,u]$，则保持 $x_{ij}(t+1) = x_{ij}^{\\mathrm{prop}}$ 和 $v_{ij}(t+1)$ 不变。\n\n将可行性度量定义为运行过程中的尝试可行率，即 $$r_{\\mathrm{feasible}} = \\frac{\\text{属于 } \\Omega \\text{ 的提议位置 } x_i^{\\mathrm{prop}}(t+1) \\text{ 的数量}}{\\text{提议总数}} = \\frac{\\#\\{(i,t) \\mid x_i(t) + v_i(t+1) \\in \\Omega\\}}{N \\cdot T},$$ 其中 $T \\in \\mathbb{N}$ 是总迭代次数。\n\n通过容差 $\\varepsilon \\in \\mathbb{R}_{>0}$ 定义收敛条件：如果在迭代 $t^\\star$ 时满足 $$\\min_{i} f(p_i(t^\\star)) \\le \\varepsilon$$ 则称运行已在 $t^\\star$ 收敛。记录此条件是否满足以及满足条件的最早 $t^\\star$（如果从未满足，则 $t^\\star = -1$）。同时记录最终的最优目标值 $$f^\\star = \\min_{i} f(p_i(T))。$$\n\n根据上述描述实现带有边界处理和度量指标的 PSO 算法。在每个测试用例中为随机数生成器使用独立且固定的种子，以确保可复现性。不涉及物理单位。所有角度（如有）均不适用。\n\n需要实现的测试套件和参数：\n\n- 案例1（理想情况，反射）：$d=5$, $l=-5$, $u=5$, $a = [1.5, -2.0, 0.5, -1.0, 2.0]$, $N=30$, $T=200$, $w=0.7$, $c_1=1.5$, $c_2=1.5$, $v_{\\max}=5$, 边界方案 = reflect, 种子 $=42$, $\\varepsilon = 10^{-6}$。\n\n- 案例2（靠近上边界，吸收）：$d=5$, $l=-5$, $u=5$, $a = [4.9, 4.8, 4.7, 4.6, 4.5]$, $N=30$, $T=200$, $w=0.7$, $c_1=1.5$, $c_2=1.5$, $v_{\\max}=5$, 边界方案 = absorb, 种子 $=123$, $\\varepsilon = 10^{-6}$。\n\n- 案例3（定义域内无法达到零点，随机重启）：$d=5$, $l=-2$, $u=2$, $a = [10.0, 10.0, 10.0, 10.0, 10.0]$, $N=40$, $T=300$, $w=0.8$, $c_1=1.7$, $c_2=1.7$, $v_{\\max}=4$, 边界方案 = random restart, 种子 $=7$, $\\varepsilon = 10^{-6}$。\n\n- 案例4（低维度，超调，反射）：$d=2$, $l=-1$, $u=1$, $a = [0.99, -0.99]$, $N=10$, $T=150$, $w=0.9$, $c_1=2.05$, $c_2=2.05$, $v_{\\max}=2$, 边界方案 = reflect, 种子 $=999$, $\\varepsilon = 10^{-6}$。\n\n- 案例5（小定义域，吸收）：$d=3$, $l=0$, $u=1$, $a = [0.9, 0.1, 0.5]$, $N=12$, $T=150$, $w=0.6$, $c_1=1.4$, $c_2=1.4$, $v_{\\max}=1$, 边界方案 = absorb, 种子 $=2024$, $\\varepsilon = 10^{-6}$。\n\n最终输出格式：\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的每个结果本身都是一个列表 $[f^\\star, r_{\\mathrm{feasible}}, \\text{converged}, t^\\star]$，按上述测试用例的顺序排列。例如，输出应类似于 $$[[f^\\star_1, r_{\\mathrm{feasible},1}, \\text{converged}_1, t^\\star_1], [f^\\star_2, r_{\\mathrm{feasible},2}, \\text{converged}_2, t^\\star_2], \\dots].$$ 类型必须如下：$f^\\star$ 是一个实数（浮点数），$r_{\\mathrm{feasible}}$ 是一个在 $[0,1]$ 内的实数（浮点数），$\\text{converged}$ 是一个布尔值，$t^\\star$ 是一个整数，其中 $-1$ 表示在 $T$ 次迭代内未收敛。", "solution": "我们要最小化移位的球形函数 $$f(x) = \\sum_{j=1}^{d} (x_j - a_j)^2$$ 受箱式约束 $x \\in \\Omega = [l,u]^d$ 约束。移位的球形函数是严格凸函数，在 $x^\\star = a$ 处有唯一的无约束最小化器。在箱式约束下，最小化器是 $a$ 在 $\\Omega$ 上的投影，因此约束下的最小化器是 $x^\\star_\\Omega = \\tilde{a}$，其中对每个 $j$ 有 $\\tilde{a}_j = \\min(\\max(a_j, l), u)$，最小目标值为 $$f(x^\\star_\\Omega) = \\sum_{j=1}^{d} (\\tilde{a}_j - a_j)^2.$$ 如果 $a \\in \\Omega$，则 $x^\\star_\\Omega = a$ 且 $f(x^\\star_\\Omega) = 0$；如果 $a$ 的任何分量位于边界之外，则 $\\Omega$ 内的最小值严格为正。\n\n粒子群优化 (PSO) 是一种基于群体的随机优化方法。它维护一个包含 $N$ 个粒子的集合，在第 $t$ 次迭代时，每个粒子都有其位置 $x_i(t) \\in \\mathbb{R}^d$ 和速度 $v_i(t) \\in \\mathbb{R}^d$。更新规则融合了惯性、对粒子个体最佳位置 $p_i(t)$ 的吸引力以及对全局最佳位置 $g(t)$ 的吸引力。这种设计体现了两个基本原则：通过惯性和随机性进行探索，以及通过吸引到已知的良好解来进行利用。典型的惯性 PSO 更新规则由下式给出 $$v_i(t+1) = w \\, v_i(t) + c_1 \\, r_1(t) \\odot (p_i(t) - x_i(t)) + c_2 \\, r_2(t) \\odot (g(t) - x_i(t)),$$ $$x_i(t+1) = x_i(t) + v_i(t+1),$$ 其中 $r_1(t), r_2(t) \\in [0,1]^d$ 是独立的均匀随机向量。速度限制确保了步长的有界性：$$v_{ij}(t+1) \\leftarrow \\operatorname{clip}(v_{ij}(t+1), -v_{\\max}, v_{\\max})。$$ 初始位置 $x_i(0)$ 在 $\\Omega$ 内均匀抽取，初始速度 $v_i(0)$ 在 $[-v_{\\max}, v_{\\max}]^d$ 内均匀抽取。每次位置更新后，我们评估 $f(x_i(t+1))$，并在出现改进时更新个体最佳 $p_i(t+1)$ 和全局最佳 $g(t+1)$。\n\n由于约束的存在，当尝试更新的位置 $x_i^{\\mathrm{prop}}(t+1) = x_i(t) + v_i(t+1)$ 离开 $\\Omega$ 时，需要进行边界处理。我们研究三种方案：\n\n1. 反射 (Reflect)：反射映射强制执行一个镜像边界，它在防止粒子离开定义域的同时保留了探索能力。对于单个分量 $j$，令 $$z = \\frac{x_{ij}^{\\mathrm{prop}} - l}{u - l}, \\quad k = \\left\\lfloor z \\right\\rfloor, \\quad z_{\\mathrm{frac}} = z - k.$$ 如果 $k$ 为偶数，我们设置 $$x_{ij}(t+1) = l + z_{\\mathrm{frac}}(u - l);$$ 如果 $k$ 为奇数，我们设置 $$x_{ij}(t+1) = u - z_{\\mathrm{frac}}(u - l).$$ $k$ 的奇偶性计算了穿越区间的次数；当 $k$ 为奇数时，该分量反弹了奇数次，因此我们翻转速度符号：$$v_{ij}(t+1) \\leftarrow -v_{ij}(t+1)。$$ 这种映射能正确处理任意大小的超调，包括那些大于区间宽度 $u-l$ 的情况。\n\n2. 吸收 (Absorb)：吸收边界在发生越界时将位置钳制到最近的边界，并将相应的速度分量重置为零：$$x_{ij}(t+1) = \\begin{cases} l  \\text{若 } x_{ij}^{\\mathrm{prop}}  l, \\\\ u  \\text{若 } x_{ij}^{\\mathrm{prop}} > u, \\\\ x_{ij}^{\\mathrm{prop}}  \\text{其他情况}, \\end{cases} \\quad v_{ij}(t+1) = \\begin{cases} 0  \\text{若 } x_{ij}^{\\mathrm{prop}} \\notin [l,u], \\\\ v_{ij}(t+1)  \\text{其他情况}。 \\end{cases}$$ 这种方案通过在撞击时抑制运动来阻止越界行为，这可能会减少振荡，但也削弱了边界附近的探索能力。\n\n3. 随机重启 (Random restart)：随机重启边界将越界的分量替换为从 $[l,u]$ 中均匀抽取的新随机值，并将其速度设置为零：$$x_{ij}(t+1) \\sim \\mathcal{U}(l,u) \\quad \\text{若 } x_{ij}^{\\mathrm{prop}} \\notin [l,u], \\quad v_{ij}(t+1) \\leftarrow 0。$$ 这种方案通过在发生越界时重新引入多样性来促进探索，这有助于逃离停滞，但可能会减慢在精确边界最优解附近的收敛速度。\n\n为了量化每种方案的效果，我们测量两个度量指标：\n\n- 尝试可行率 $$r_{\\mathrm{feasible}} = \\frac{\\#\\{(i,t) \\mid x_i(t) + v_i(t+1) \\in \\Omega\\}}{N \\cdot T},$$ 它在修正前计算提议位置，反映了在每种边界规则引起的动力学下，粒子尝试位于 $\\Omega$ 内部的频率。\n\n- 收敛行为：一个布尔值，指示全局最优值是否在任何迭代中达到阈值 $\\varepsilon$，以及满足 $$\\min_i f(p_i(t^\\star)) \\le \\varepsilon$$ 的最早迭代次数 $t^\\star$。我们还报告最终的最优目标值 $$f^\\star = \\min_i f(p_i(T))。$$\n\n实现细节：\n\n- 每个测试用例通过使用伪随机数生成器的固定种子来控制随机性，以确保结果可复现。\n\n- 个体最佳位置 $p_i(t)$ 仅在 $f(x)$ 严格改善时更新，确保个体最佳值单调非增。\n\n- 全局最佳位置 $g(t)$ 跟踪每次迭代中个体最佳位置中的最优者。\n\n- 在计算 $v_i(t+1)$ 之后、提议位置之前，速度会逐分量地限制在 $[-v_{\\max}, v_{\\max}]$ 范围内，以防止过度超调。\n\n- 边界处理方案逐分量地应用于 $x_i^{\\mathrm{prop}}(t+1)$，以产生最终的 $x_i(t+1)$ 和修正后的 $v_i(t+1)$，确保 $x_i(t+1) \\in \\Omega$。\n\n设计理念：\n\n- 移位球形函数的二次结构提供了一个具有唯一最小值的平滑景观，使其成为观察 PSO 动力学以及探索与利用之间相互作用的理想选择。\n\n- 反射在保持可行性的同时保留了动量，通过减少长时间的偏离通常能提高 $r_{\\mathrm{feasible}}$，并且当最优解位于边界附近时可以加速收敛。\n\n- 吸收通过在边界处将速度置零来减少振荡，这可能会减少边界穿越，从而增加 $r_{\\mathrm{feasible}}$，但由于动量损失，可能会减慢在边界最优解附近的收敛速度。\n\n- 随机重启在发生越界时增加了多样性，通常在运行初期会增加尝试的越界次数，但可能有助于在多峰问题中收敛；对于凸的移位球形函数，它可能会减慢在边界附近的精确收敛，但当无约束最小化器位于 $\\Omega$ 之外时，它能有效鼓励在约束最小化器 $x^\\star_\\Omega$ 附近的探索。\n\n计算考虑：\n\n- 每次更新的成本为 $O(N d)$ 操作，每个测试用例的总运行时间为 $O(N d T)$。\n\n- 使用给定的参数，程序在计算上是轻量级的且完全确定性的。\n\n程序处理五个指定的测试用例，计算 $f^\\star$、$r_{\\mathrm{feasible}}$、收敛布尔值和 $t^\\star$，并按顺序为每个案例输出包含这些四元组结果列表的单行文本。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\n\ndef sphere_shifted(x, a):\n    # f(x) = sum_j (x_j - a_j)^2\n    diff = x - a\n    return np.dot(diff, diff)\n\ndef reflect_component(x_prop, v_comp, l, u):\n    # Reflective mapping with parity-based velocity flip\n    if l = x_prop = u:\n        return x_prop, v_comp\n    width = u - l\n    # Compute z, k = floor(z), z_frac = z - k\n    z = (x_prop - l) / width\n    k = math.floor(z)\n    z_frac = z - k\n    if k % 2 == 0:\n        x_new = l + z_frac * width\n        v_new = v_comp\n    else:\n        x_new = u - z_frac * width\n        v_new = -v_comp\n    # Numerical guard to ensure bounds inclusion\n    if x_new  l:\n        x_new = l\n    elif x_new > u:\n        x_new = u\n    return x_new, v_new\n\ndef absorb_component(x_prop, v_comp, l, u):\n    if x_prop  l:\n        return l, 0.0\n    elif x_prop > u:\n        return u, 0.0\n    else:\n        return x_prop, v_comp\n\ndef restart_component(x_prop, v_comp, l, u, rng):\n    if l = x_prop = u:\n        return x_prop, v_comp\n    else:\n        return rng.uniform(l, u), 0.0\n\ndef pso_run(d, l, u, a, N, T, w, c1, c2, vmax, scheme, seed, eps):\n    rng = np.random.default_rng(seed)\n    # Initialize positions uniformly in [l, u]^d\n    X = rng.uniform(l, u, size=(N, d))\n    # Initialize velocities uniformly in [-vmax, vmax]^d\n    V = rng.uniform(-vmax, vmax, size=(N, d))\n    # Personal bests and fitnesses\n    P = X.copy()\n    P_fit = np.array([sphere_shifted(P[i], a) for i in range(N)])\n    # Global best\n    g_idx = int(np.argmin(P_fit))\n    G = P[g_idx].copy()\n    G_fit = P_fit[g_idx]\n    # Metrics\n    total_props = N * T\n    feasible_props = 0\n    converged = False\n    t_star = -1\n\n    for t in range(1, T + 1):\n        for i in range(N):\n            # Random coefficients per particle and dimension\n            r1 = rng.uniform(0.0, 1.0, size=d)\n            r2 = rng.uniform(0.0, 1.0, size=d)\n            # Velocity update\n            V[i] = w * V[i] + c1 * r1 * (P[i] - X[i]) + c2 * r2 * (G - X[i])\n            # Clamp velocity\n            V[i] = np.clip(V[i], -vmax, vmax)\n            # Proposed position\n            X_prop = X[i] + V[i]\n            # Feasibility check before correction (attempted feasibility)\n            inside = (X_prop >= l)  (X_prop = u)\n            if np.all(inside):\n                feasible_props += 1\n            # Apply boundary handling per component\n            for j in range(d):\n                xpj = X_prop[j]\n                vj = V[i, j]\n                if scheme == 'reflect':\n                    x_new, v_new = reflect_component(xpj, vj, l, u)\n                elif scheme == 'absorb':\n                    x_new, v_new = absorb_component(xpj, vj, l, u)\n                elif scheme == 'restart':\n                    x_new, v_new = restart_component(xpj, vj, l, u, rng)\n                else:\n                    # Default: clamp (should not happen in provided tests)\n                    x_new = min(max(xpj, l), u)\n                    v_new = vj\n                X[i, j] = x_new\n                V[i, j] = v_new\n            # Evaluate and update personal best\n            f_val = sphere_shifted(X[i], a)\n            if f_val  P_fit[i]:\n                P[i] = X[i].copy()\n                P_fit[i] = f_val\n        # Update global best\n        g_idx = int(np.argmin(P_fit))\n        if P_fit[g_idx]  G_fit:\n            G_fit = P_fit[g_idx]\n            G = P[g_idx].copy()\n        # Convergence check\n        if (not converged) and (G_fit = eps):\n            converged = True\n            t_star = t\n\n    r_feasible = feasible_props / total_props\n    f_star = G_fit\n    return [f_star, r_feasible, converged, t_star]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: happy path, reflect\n        {\n            \"d\": 5, \"l\": -5.0, \"u\": 5.0,\n            \"a\": np.array([1.5, -2.0, 0.5, -1.0, 2.0], dtype=float),\n            \"N\": 30, \"T\": 200,\n            \"w\": 0.7, \"c1\": 1.5, \"c2\": 1.5,\n            \"vmax\": 5.0, \"scheme\": \"reflect\",\n            \"seed\": 42, \"eps\": 1e-6\n        },\n        # Case 2: near upper boundary, absorb\n        {\n            \"d\": 5, \"l\": -5.0, \"u\": 5.0,\n            \"a\": np.array([4.9, 4.8, 4.7, 4.6, 4.5], dtype=float),\n            \"N\": 30, \"T\": 200,\n            \"w\": 0.7, \"c1\": 1.5, \"c2\": 1.5,\n            \"vmax\": 5.0, \"scheme\": \"absorb\",\n            \"seed\": 123, \"eps\": 1e-6\n        },\n        # Case 3: unattainable zero within domain, random restart\n        {\n            \"d\": 5, \"l\": -2.0, \"u\": 2.0,\n            \"a\": np.array([10.0, 10.0, 10.0, 10.0, 10.0], dtype=float),\n            \"N\": 40, \"T\": 300,\n            \"w\": 0.8, \"c1\": 1.7, \"c2\": 1.7,\n            \"vmax\": 4.0, \"scheme\": \"restart\",\n            \"seed\": 7, \"eps\": 1e-6\n        },\n        # Case 4: low dimension, overshoot, reflect\n        {\n            \"d\": 2, \"l\": -1.0, \"u\": 1.0,\n            \"a\": np.array([0.99, -0.99], dtype=float),\n            \"N\": 10, \"T\": 150,\n            \"w\": 0.9, \"c1\": 2.05, \"c2\": 2.05,\n            \"vmax\": 2.0, \"scheme\": \"reflect\",\n            \"seed\": 999, \"eps\": 1e-6\n        },\n        # Case 5: small domain, absorb\n        {\n            \"d\": 3, \"l\": 0.0, \"u\": 1.0,\n            \"a\": np.array([0.9, 0.1, 0.5], dtype=float),\n            \"N\": 12, \"T\": 150,\n            \"w\": 0.6, \"c1\": 1.4, \"c2\": 1.4,\n            \"vmax\": 1.0, \"scheme\": \"absorb\",\n            \"seed\": 2024, \"eps\": 1e-6\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        res = pso_run(\n            d=case[\"d\"], l=case[\"l\"], u=case[\"u\"], a=case[\"a\"], N=case[\"N\"], T=case[\"T\"],\n            w=case[\"w\"], c1=case[\"c1\"], c2=case[\"c2\"], vmax=case[\"vmax\"],\n            scheme=case[\"scheme\"], seed=case[\"seed\"], eps=case[\"eps\"]\n        )\n        results.append(res)\n\n    # Final print statement in the exact required format (single line, no spaces).\n    # Convert to string and remove spaces for a compact bracketed list.\n    out = str(results).replace(\" \", \"\")\n    print(out)\n\nsolve()\n```", "id": "3161093"}]}