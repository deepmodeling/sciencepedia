{"hands_on_practices": [{"introduction": "选择是遗传算法（GA）中推动种群进化的核心引擎。为了深入理解其力量，我们可以暂时剥离交叉和变异等其他算子，在一个简化的模型中单独研究选择的动态。这个练习 ([@problem_id:3137411]) 将指导你通过编写一个模拟程序，观察一个具有微弱优势的“最佳”个体如何在纯粹的选择压力下逐渐“接管”整个种群。通过将随机模拟的结果与一个简化的确定性数学模型 $T \\approx \\frac{\\ln N}{\\ln s}$ 进行比较，你将亲身体会到选择强度（selection pressure）和遗传漂变（genetic drift）之间复杂的相互作用，这是理解进化计算基本原理的关键一步。", "problem": "考虑一个仅选择的遗传算法（GA）模型，此处定义为一种遗传算法（GA），它仅通过适应度比例选择来生成每一代，而没有交叉、变异或其他算子。种群由两种类型组成：一个最优个体和所有其他个体。设种群大小为 $N$，最优个体的选择强度为 $s$，意味着最优个体的适应度为 $s$，而所有其他个体的适应度为 $1$。初始种群包含 $1$ 个最优个体和 $N-1$ 个其他个体。\n\n在第 $t$ 代，令 $k_t$ 表示最优个体的数量。在适应度比例选择下，随机选择的后代来自最优类型的概率 $p_t$ 由最优类型的总适应度贡献除以种群总适应度得出。下一代是通过从上一代进行有放回抽样产生的 $N$ 个个体，因此最优个体的数量 $k_{t+1}$ 是一个随机变量，服从试验次数为 $N$、成功概率为 $p_t$ 的二项分布。\n\n将接管时间 $T$ 定义为满足 $k_t = N$ 的最小非负整数 $t$（即，整个种群都由最优个体组成）。由于随机抽样，最优个体可能会灭绝，这意味着对于所有后续代，$k_t = 0$；在这种情况下，接管时间未定义。对于本问题，将估计的接管时间定义为在接管发生条件下的 $T$ 的条件期望，并通过蒙特卡洛模拟来近似。\n\n您的任务是：\n- 实现一个模拟，对于给定的 $(N,s)$，执行 $R$ 次独立运行。每次运行从 $k_0 = 1$ 开始，通过重复的适应度比例抽样进行演化，直到 $k_t = N$（接管）、$k_t = 0$（灭绝）或达到预设的最大代数限制。对于每次达到接管的运行，记录其接管时间。通过对成功运行的接管时间取平均值，来估计条件期望接管时间。\n- 计算接管时间的确定性近似值，该近似值源于假设在最优个体比例较小时，最优个体的期望数量呈乘法增长。\n- 对于每个测试用例，报告蒙特卡洛估计值与确定性近似值之间的绝对差，四舍五入到三位小数。\n\n使用以下测试套件：\n1. $(N,s,R,\\text{max\\_gen},\\text{seed}) = (100, 1.5, 500, 1000, 42)$\n2. $(N,s,R,\\text{max\\_gen},\\text{seed}) = (100, 1.01, 500, 10000, 43)$\n3. $(N,s,R,\\text{max\\_gen},\\text{seed}) = (50, 2.0, 300, 200, 44)$\n4. $(N,s,R,\\text{max\\_gen},\\text{seed}) = (10, 1.5, 1000, 200, 45)$\n5. $(N,s,R,\\text{max\\_gen},\\text{seed}) = (200, 1.2, 300, 3000, 46)$\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果，每个元素是对应测试用例的绝对误差。如果某个测试用例中没有一次运行在最大代数限制内实现接管，则该用例输出浮点值 $\\mathrm{nan}$。例如，最终输出应类似于 $[e_1,e_2,e_3,e_4,e_5]$，其中每个 $e_i$ 是一个四舍五入到三位小数的浮点数。", "solution": "用户的问题陈述已经过验证，并被确定是合理的。它在科学上基于种群遗传学和计算科学的原理，特别是带有选择的 Wright-Fisher 模型。该问题是良置的，为蒙特卡洛模拟和确定性近似提供了所有必要的参数和定义。目标明确且形式化。因此，我现在将提供一个完整的解决方案。\n\n该问题要求比较一个演化过程的随机模拟与同一过程的简化确定性模型。目标是计算通过蒙特卡洛模拟估计的接管时间与通过确定性近似预测的接管时间之间的绝对差。\n\n让我们定义给定的参数和变量：\n- $N$：总种群大小。\n- $s$：“最优”个体类型的适应度，其中 $s > 1$。所有其他个体的适应度为 $1$。\n- $k_t$：在第 $t$ 代种群中最优个体的数量。初始状态为 $k_0 = 1$。\n- $p_t$：在第 $t$ 代从最优类型中选择一个后代的概率。\n\n该模型的核心在于从第 $t$ 代到第 $t+1$ 代的转换。概率 $p_t$ 由 $k_t$ 个最优个体贡献的总适应度比例确定：\n$$\np_t = \\frac{k_t \\cdot s}{k_t \\cdot s + (N - k_t) \\cdot 1} = \\frac{s k_t}{s k_t + N - k_t}\n$$\n下一代是由从当前代进行 $N$ 次独立有放回抽样形成的。因此，下一代中最优个体的数量 $k_{t+1}$ 服从试验次数为 $N$、成功概率为 $p_t$ 的二项分布：\n$$\nk_{t+1} \\sim \\text{Binomial}(N, p_t)\n$$\n\n解决方案涉及三个主要步骤：推导确定性近似，概述蒙特卡洛模拟，以及计算最终误差。\n\n**1. 确定性近似 ($T_{det}$)**\n\n确定性模型通过追踪个体数量的期望值 $E[k_t]$ 来近似随机过程。给定 $k_t$ 时，$k_{t+1}$ 的期望值为 $E[k_{t+1} | k_t] = N p_t$。\n$$\nE[k_{t+1} | k_t] = N \\left( \\frac{s k_t}{s k_t + N - k_t} \\right)\n$$\n问题指明，当最优个体的比例 $x_t = k_t/N$ 很小时，该近似应假设乘法增长。当 $x_t \\ll 1$ 时，我们可以近似分母：\n$$\ns k_t + N - k_t = N(1 + (s-1)\\frac{k_t}{N}) \\approx N\n$$\n将此代入期望值，我们得到一个关于期望数量的简化递推关系，我们将其表示为 $\\bar{k}_t$：\n$$\n\\bar{k}_{t+1} \\approx N \\left( \\frac{s \\bar{k}_t}{N} \\right) = s \\bar{k}_t\n$$\n这是一个几何级数。从初始条件 $k_0 = 1$ 开始，第 $t$ 代的最优个体期望数量呈指数级增长：\n$$\n\\bar{k}_t \\approx k_0 s^t = s^t\n$$\n接管被定义为整个种群由最优个体组成的时间点，即当数量达到 $N$ 时。我们在我们的连续近似中求解满足此条件所需的时间 $t$：\n$$\ns^t = N\n$$\n对两边取自然对数，得到：\n$$\nt \\ln(s) = \\ln(N)\n$$\n这给出了确定性接管时间 $T_{det}$：\n$$\nT_{det} = \\frac{\\ln(N)}{\\ln(s)}\n$$\n这种近似忽略了随机抽样（遗传漂变）的随机效应，这些效应可能导致灭绝（尤其是在 $k_t$ 很小时），或以其他方式导致偏离平滑的指数增长。\n\n**2. 蒙特卡洛模拟估计 ($T_{MC}$)**\n\n为了捕捉过程的随机性，我们执行蒙特卡洛模拟。对于每组参数 $(N, s, R, \\text{max\\_gen}, \\text{seed})$，我们进行 $R$ 次独立运行。\n每次运行按以下步骤进行：\n1.  初始化状态：代数计数 $t=0$ 和最优个体数量 $k_0=1$。\n2.  迭代各代：对于每一代，增加 $t$。\n3.  基于当前数量 $k_t$ 计算选择概率 $p_t$。\n4.  从二项分布中抽样下一代的最优个体数量 $k_{t+1}$：$k_{t+1} = \\text{rng.binomial}(N, p_t)$，其中 `rng` 是一个设定了种子的随机数生成器。\n5.  检查终止条件：\n    - 如果 $k_{t+1} = N$（接管），则将当前代数计数 $t+1$ 记录为本次运行的接管时间，并停止运行。\n    - 如果 $k_{t+1} = 0$（灭绝），则停止运行，不记录时间。\n    - 如果 $t$ 达到最大代数限制 `max_gen`，则停止运行。这是防止运行时间过长的保障措施。\n在所有 $R$ 次运行完成后，我们将得到一个来自成功运行的接管时间列表。估计的条件期望接管时间 $T_{MC}$ 是这些记录时间的算术平均值。如果没有运行导致接管，则 $T_{MC}$ 被视为未定义，表示为 $\\mathrm{nan}$。\n\n**3. 误差计算**\n\n对于每个测试用例，最终结果是蒙特卡洛估计值与确定性近似值之间的绝对差，四舍五入到三位小数：\n$$\n\\Delta T = |T_{MC} - T_{det}|\n$$\n如果 $T_{MC}$ 是 $\\mathrm{nan}$，则差值 $\\Delta T$ 也是 $\\mathrm{nan}$。该实现将为五个提供的测试用例中的每一个计算此值。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the absolute difference between a Monte Carlo estimate and a\n    deterministic approximation for the takeover time in a selection-only\n    genetic algorithm model.\n    \"\"\"\n    test_cases = [\n        # (N, s, R, max_gen, seed)\n        (100, 1.5, 500, 1000, 42),\n        (100, 1.01, 500, 10000, 43),\n        (50, 2.0, 300, 200, 44),\n        (10, 1.5, 1000, 200, 45),\n        (200, 1.2, 300, 3000, 46),\n    ]\n\n    results = []\n    for case in test_cases:\n        N, s, R, max_gen, seed = case\n\n        # Initialize random number generator for reproducibility\n        rng = np.random.default_rng(seed)\n\n        # --- Monte Carlo Simulation ---\n        takeover_times = []\n        for _ in range(R):\n            k = 1  # Initial number of best individuals\n            for t in range(1, max_gen + 1):\n                # Check for termination conditions from the previous state\n                if k == N:\n                    takeover_times.append(t - 1)\n                    break\n                if k == 0:\n                    break\n\n                # Calculate selection probability\n                total_fitness_best = k * s\n                total_fitness_other = (N - k) * 1.0\n                total_fitness = total_fitness_best + total_fitness_other\n                \n                # Handle potential division by zero if population empties, though k=0 check prevents this\n                if total_fitness == 0:\n                    p = 0.0\n                else:\n                    p = total_fitness_best / total_fitness\n\n                # Sample the next generation\n                k = rng.binomial(N, p)\n            \n            # Check for takeover at the end of the loop (if max_gen is reached exactly)\n            else: # This 'else' belongs to the 'for t' loop\n                if k == N:\n                    takeover_times.append(max_gen)\n\n\n        # Calculate the MC estimate\n        if not takeover_times:\n            mc_estimate = np.nan\n        else:\n            mc_estimate = np.mean(takeover_times)\n\n        # --- Deterministic Approximation ---\n        # T_det = log(N) / log(s)\n        det_approx = np.log(N) / np.log(s)\n\n        # --- Calculate Absolute Difference ---\n        if np.isnan(mc_estimate):\n            diff = np.nan\n            results.append('nan')\n        else:\n            diff = np.abs(mc_estimate - det_approx)\n            results.append(f\"{diff:.3f}\")\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n\n```", "id": "3137411"}, {"introduction": "在掌握了选择机制之后，一个自然而然的问题是：我们应该如何表示问题的解？基因型到表现型的映射，即编码方案，是遗传算法设计中至关重要的一环，它直接决定了搜索算子的效率。一个优秀的编码方案应具备良好的“局部性”（locality），即基因型上的微小变动应对应表现型上的微小变化。这个练习 ([@problem_id:3132789]) 旨在让你通过精确的分析而非模拟，来量化比较两种常用编码方式——标准二进制编码和格雷码——的性能差异。你将计算由编码所产生的离散化误差，并分析不同编码下单位变异操作（单比特翻转）导致性能提升的概率，从而深刻理解编码选择如何影响算法的搜索偏好和在优化过程中的“可进化性”。", "problem": "你需要编写一个完整、可运行的程序，用于在优化球函数时，比较遗传算法（Genetic Algorithm, GA）中使用的两种基因型编码方式：标准二进制编码和格雷码。目标函数为球函数 $f(\\mathbf{x}) = \\sum_{i=1}^{n} x_i^2$，其定义域为一个有界超矩形 $[L, U]^n$，其中 $L < 0 < U$。每个决策变量 $x_i$ 由 $b$ 个比特表示，并通过均匀线性量化解码为一个实数值。\n\n使用的基本原理和定义如下：\n- 球函数 $f(\\mathbf{x}) = \\sum_{i=1}^{n} x_i^2$ 是坐标可分的。\n- 基因型到表现型的映射是一个线性量化器：对于每个坐标，一个 $b$ 比特的码字代表一个整数 $k \\in \\{0,1,\\dots,2^b - 1\\}$，该整数映射到一个实数值 $x = L + \\dfrac{U - L}{2^b - 1}\\,k$。这会在每个坐标上产生一个由 $2^b$ 个点组成的均匀网格，该网格包含端点 $L$ 和 $U$。\n- 对于二进制编码，码字是 $k$ 的标准二进制表示。对于格雷码，码字是 $k$ 的格雷码表示，并且在解码时，会先通过格雷码到二进制的转换恢复整数 $k$，然后再进行到 $x$ 的线性映射。\n- 单比特突变定义为从所有 $nb$ 个基因型比特中均匀随机地选择一个比特并将其翻转。\n\n为每个测试用例计算并报告以下内容：\n1) 离散化误差。将离散化误差定义为：在由所选 $b$ 产生的离散网格上（两种编码方式相同，因为它们产生相同的表现型网格点集），$f(\\mathbf{x})$ 可达到的最小值与 $f(\\mathbf{x})$ 在 $[L, U]^n$ 上的连续最优值之差。你必须精确计算此值，而非通过采样。\n2) 通过单步改进概率衡量的搜索偏好。将一种编码的单步改进概率 $P_{\\mathrm{improve}}$ 定义为：在基因型服从均匀分布且在 $nb$ 个比特位置中均匀选择的条件下，一次单比特翻转能够严格减小 $f(\\mathbf{x})$ 值的概率。你必须通过枚举精确计算此概率，而非通过模拟。形式上，\n$$\nP_{\\mathrm{improve}} = \\frac{1}{(2^b)^n \\cdot nb} \\sum_{\\text{genotypes } g} \\sum_{p=1}^{nb} \\mathbf{1}\\big(f(g^{(p)}) < f(g)\\big),\n$$\n其中 $g^{(p)}$ 是指基因型 $g$ 在第 $p$ 位比特翻转后的结果，$\\mathbf{1}(\\cdot)$ 是指示函数。利用 $f$ 的可分性以及比特翻转仅影响一个坐标这一事实，将此计算简化为对单个 $b$ 比特坐标的等价精确枚举。\n\n你的程序必须：\n- 对任意整数 $b \\ge 1$，精确实现两种编码（二进制和格雷码）。\n- 使用精确逻辑而非浮点数比较来测试比特翻转是否改善了单个坐标的贡献值 $x^2$。具体方法是观察到：对于对称边界 $L = -U$ 和步长为 $\\Delta = \\dfrac{U - L}{2^b - 1}$ 的均匀量化，每个坐标的值等于 $x = \\Delta\\,(k - m)$，其中 $m = \\dfrac{2^b - 1}{2}$。因此，当且仅当 $\\lvert k' - m \\rvert < \\lvert k - m \\rvert$ 时，一次翻转会改善目标函数，这等价于 $\\lvert 2k' - (2^b - 1) \\rvert < \\lvert 2k - (2^b - 1) \\rvert$。\n- 从第一性原理出发精确计算离散化误差，而不是通过数值搜索网格。如果 $0 \\in [L, U]$，则连续最小值为 $0$，在 $\\mathbf{x} = \\mathbf{0}$ 处取得；否则，它是在每个坐标上离 $0$ 最近的边界点处的值。\n- 对每个测试用例，输出一个包含四个数字的列表：二进制编码下的离散化误差、格雷码下的离散化误差、二进制编码下的单步改进概率、以及格雷码下的单步改进概率。所有数字必须打印为保留12位小数的十进制数。\n\n测试套件：\n使用以下五个测试用例，每个用例以元组 $(n, b, L, U)$ 的形式指定，其中 $n$ 是维度，$b$ 是每个坐标的比特长度，$[L, U]$ 是边界区间：\n- $(\\,1,\\,3,\\,-1.0,\\,1.0\\,)$\n- $(\\,5,\\,4,\\,-1.0,\\,1.0\\,)$\n- $(\\,10,\\,8,\\,-1.0,\\,1.0\\,)$\n- $(\\,3,\\,1,\\,-1.0,\\,1.0\\,)$\n- $(\\,2,\\,12,\\,-1.0,\\,1.0\\,)$\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含五个测试用例的结果，形式为一个长度为五、以逗号分隔的列表。该列表的每个元素本身又是一个包含四个十进制数的、以逗号分隔的列表，顺序如上所述，并且每个十进制数都四舍五入到12位小数。例如，一个有效的格式为\n$$\n[\\,[d_1^{\\text{bin}}, d_1^{\\text{gray}}, p_1^{\\text{bin}}, p_1^{\\text{gray}}],\\dots,[d_5^{\\text{bin}}, d_5^{\\text{gray}}, p_5^{\\text{bin}}, p_5^{\\text{gray}}]\\,].\n$$\n不应打印任何额外文本。", "solution": "用户提供的问题已经过分析和验证。该问题具有科学依据，定义明确，且所有定义和约束都是自洽和一致的。任务是计算在遗传算法优化球函数时，二进制编码和格雷码的两个度量指标：离散化误差和单步改进概率。\n\n### 1. 离散化误差\n\n目标函数是球函数 $f(\\mathbf{x}) = \\sum_{i=1}^{n} x_i^2$，定义域为 $\\mathbf{x} \\in [L, U]^n$。对于所有测试用例，$L = -1.0$ 且 $U = 1.0$，因此 $L < 0 < U$。$f(\\mathbf{x})$ 的连续最小值为 $f(\\mathbf{0}) = 0$，在 $\\mathbf{x} = \\mathbf{0}$ 处取得。\n\n问题描述了一种均匀线性量化方案，其中每个坐标 $x_i$ 从一个 $b$ 比特码字映射而来。该码字对应一个整数 $k \\in \\{0, 1, \\dots, 2^b-1\\}$，而该整数又映射到一个实数值 $x_k = L + \\frac{U-L}{2^b-1}k$。每个坐标所有可能的实数值（即网格点）的集合由 $k$ 的取值范围决定。\n\n二进制编码和格雷码都提供了从 $b$ 比特字符串集合到整数集合 $\\{0, 1, \\dots, 2^b-1\\}$ 的双射。因此，两种编码的可实现表现型值（网格点）的集合是相同的。离散化误差被定义为网格上的最小值与连续最小值之差，所以它与选择二进制编码还是格雷码无关。\n\n要找到 $f(\\mathbf{x})$ 在网格上的最小值，我们必须为每个坐标找到最接近 $0$ 的网格点 $x_k$。使 $x_k$ 最接近 $0$ 的 $k$ 值，是与实数值 $k_{\\text{real}} = -L \\frac{2^b-1}{U-L}$ 最接近的整数。\n在给定 $L=-1.0$ 和 $U=1.0$ 的情况下，该值变为 $k_{\\text{real}} = -(-1.0) \\frac{2^b-1}{1.0 - (-1.0)} = \\frac{2^b-1}{2}$。\n由于 $b \\ge 1$，$2^b-1$ 总是奇数，所以 $k_{\\text{real}}$ 永远不是整数。与 $k_{\\text{real}}$ 最接近的两个整数是 $k_1 = \\lfloor \\frac{2^b-1}{2} \\rfloor = 2^{b-1}-1$ 和 $k_2 = \\lceil \\frac{2^b-1}{2} \\rceil = 2^{b-1}$。\n对应的表现型值为：\n$x_{k_1} = -1.0 + \\frac{2.0}{2^b-1}(2^{b-1}-1) = \\frac{-(2^b-1) + 2^b-2}{2^b-1} = \\frac{-1}{2^b-1}$。\n$x_{k_2} = -1.0 + \\frac{2.0}{2^b-1}(2^{b-1}) = \\frac{-(2^b-1) + 2^b}{2^b-1} = \\frac{1}{2^b-1}$。\n每个坐标可能的最小绝对值为 $|x^*| = \\frac{1}{2^b-1}$。\n当每个 $|x_i| = |x^*|$ 时，在离散网格上可取得 $f(\\mathbf{x})$ 的最小值，所以 $\\min_{\\text{grid}} f(\\mathbf{x}) = \\sum_{i=1}^{n} (x^*)^2 = n \\left(\\frac{1}{2^b-1}\\right)^2$。\n因此，离散化误差 $D$ 为：\n$$ D = \\min_{\\text{grid}} f(\\mathbf{x}) - \\min_{\\text{continuous}} f(\\mathbf{x}) = \\frac{n}{(2^b-1)^2} - 0 = \\frac{n}{(2^b-1)^2} $$\n这个值对于二进制编码和格雷码是相同的，所以 $D_{\\text{binary}} = D_{\\text{Gray}}$。\n\n### 2. 单步改进概率 ($P_{\\mathrm{improve}}$)\n\n单步改进概率定义为：\n$$ P_{\\mathrm{improve}} = \\frac{1}{(2^b)^n \\cdot nb} \\sum_{\\text{genotypes } g} \\sum_{p=1}^{nb} \\mathbf{1}\\big(f(g^{(p)}) < f(g)\\big) $$\n由于球函数 $f(\\mathbf{x}) = \\sum_{i=1}^n x_i^2$ 的可分性，基因型中的单比特翻转只影响一个坐标，例如 $x_i \\to x_i'$。改进的条件 $f(g^{(p)}) < f(g)$ 简化为 $(x_i')^2 < x_i^2$，这等价于 $|x_i'| < |x_i|$。\n改进移动的总数可以对每个坐标独立求和。设 $S$ 为对于单个 $b$ 比特坐标，在其所有 $2^b$ 种可能状态下，能够带来改进的单比特翻转的总次数。\n$$ S = \\sum_{c \\in \\{0,1\\}^b} \\sum_{j=1}^{b} \\mathbf{1}\\big( |x'(c^{(j)})| < |x(c)| \\big) $$\n其中 $c$ 是一个 $b$ 比特码字，$c^{(j)}$ 是 $c$ 将第 $j$ 位比特翻转后的码字，$x(c)$ 是对应于 $c$ 的表现型值。\n在所有 $n$ 个坐标和所有 $(2^b)^n$ 个基因型中，能够带来改进的移动总数为 $n \\cdot (2^b)^{n-1} \\cdot S$。\n将此代入概率公式可显著简化：\n$$ P_{\\mathrm{improve}} = \\frac{n \\cdot (2^b)^{n-1} \\cdot S}{(2^b)^n \\cdot nb} = \\frac{S}{2^b \\cdot b} $$\n这意味着我们只需要分析一个 $b$ 比特的坐标就能求出概率。$S$ 的值在二进制编码和格雷码之间会有所不同，因为从码字 $c$ 到整数 $k$（并因此到表现型值 $x$）的映射是不同的。\n\n为避免浮点数不精确的问题，我们使用建议的基于整数的比较。对于 $L=-U$，条件 $|x'| < |x|$ 等价于 $|k' - m| < |k - m|$，其中 $m = (2^b-1)/2$。两边乘以 $2$ 后，这可以重写为 $|2k' - (2^b-1)| < |2k - (2^b-1)|$。\n\n计算每种编码的 $S$ 的算法如下：\n1.  初始化一个改进移动计数器 `improvements` 为 $0$。令 $M = 2^b - 1$。\n2.  遍历每个可能的 $b$ 比特码字 $c$，表示为从 $0$ 到 $2^b-1$ 的整数。\n3.  对于每个 $c$，确定其在给定编码（二进制或格雷码）下的整数值 $k$。\n    - 对于二进制编码，$k_{\\text{bin}}$ 是 $c$ 的整数值。\n    - 对于格雷码，$k_{\\text{gray}}$ 是通过对 $c$ 进行格雷码到二进制的转换得到的。\n4.  计算当前状态下与适应度相关的项：$V_{\\text{bin}} = |2k_{\\text{bin}} - M|$ 和 $V_{\\text{gray}} = |2k_{\\text{gray}} - M|$。\n5.  遍历每个比特位置 $j$（从 $0$ 到 $b-1$）。\n    a. 通过翻转 $c$ 的第 $j$ 位比特来确定新的码字 $c'$。\n    b. 解码 $c'$ 以获得新的整数值 $k'_{\\text{bin}}$ 和 $k'_{\\text{gray}}$。\n    c. 计算新的适应度项 $V'_{\\text{bin}} = |2k'_{\\text{bin}} - M|$ 和 $V'_{\\text{gray}} = |2k'_{\\text{gray}} - M|$。\n    d. 如果 $V'_{\\text{bin}} < V_{\\text{bin}}$，则增加二进制编码的计数器。\n    e. 如果 $V'_{\\text{gray}} < V_{\\text{gray}}$，则增加格雷码的计数器。\n6.  遍历完所有码字和比特翻转后，得到总计数 $S_{\\text{bin}}$ 和 $S_{\\text{gray}}$。\n7.  然后，概率为 $P_{\\mathrm{improve}}^{\\text{bin}} = S_{\\text{bin}} / (2^b \\cdot b)$ 和 $P_{\\mathrm{improve}}^{\\text{gray}} = S_{\\text{gray}} / (2^b \\cdot b)$。\n\n此过程在所提供的代码中得到了精确实现。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes discretization error and one-step improvement probability for\n    binary and Gray encodings on the sphere function.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (n, b, L, U)\n        (1, 3, -1.0, 1.0),\n        (5, 4, -1.0, 1.0),\n        (10, 8, -1.0, 1.0),\n        (3, 1, -1.0, 1.0),\n        (2, 12, -1.0, 1.0),\n    ]\n\n    def gray_to_bin_int(g: int) -> int:\n        \"\"\"\n        Converts a Gray-coded integer to its corresponding binary integer value.\n        \"\"\"\n        b = g\n        mask = g >> 1\n        while mask > 0:\n            b ^= mask\n            mask >>= 1\n        return b\n\n    # Store results as formatted strings to match output specification.\n    formatted_results = []\n\n    for n, b, L, U in test_cases:\n        # 1. Discretization Error Calculation\n        # For L = -U, the continuous minimum is 0. The discrete grid point closest to 0\n        # for a coordinate is at |U|/(2^b - 1). The minimum of sum(x_i^2) is n * (|U|/(2^b - 1))^2.\n        # Since all test cases have U=1.0, this simplifies.\n        if (2**b - 1) == 0: # a_val is denominator\n             disc_error = float('inf') if n > 0 else 0.0 # handle b=0 case, though not in tests\n        else:\n             disc_error = n * (U / (2**b - 1))**2\n        \n        # Discretization error is independent of the encoding strategy, as both\n        # cover the same set of phenotype points.\n        d_bin = disc_error\n        d_gray = disc_error\n\n        # 2. One-Step Improvement Probability Calculation\n        improvements_bin = 0\n        improvements_gray = 0\n        num_states = 2**b\n        # Precompute a map from Gray coded integers to binary integers for efficiency.\n        gray_map = {g: gray_to_bin_int(g) for g in range(num_states)}\n        \n        # This value is used for the integer-based fitness comparison\n        # |2k' - M|  |2k - M| to avoid floating point issues.\n        M = num_states - 1\n\n        # Iterate over all possible b-bit codewords (represented as integers 0..2^b-1)\n        for c_int in range(num_states):\n            # For binary encoding, the integer value k is the codeword itself.\n            k_bin = c_int\n            # For Gray encoding, the codeword c_int must be converted to find k.\n            k_gray = gray_map[c_int]\n\n            # Objective value proxy for the current state for each encoding\n            val_bin = abs(2 * k_bin - M)\n            val_gray = abs(2 * k_gray - M)\n\n            # Iterate over all possible single-bit flips\n            for j in range(b):\n                # Flipping the j-th bit is equivalent to XOR with 2^j\n                c_prime_int = c_int ^ (1  j)\n\n                # --- Binary Encoding ---\n                k_prime_bin = c_prime_int\n                val_prime_bin = abs(2 * k_prime_bin - M)\n                if val_prime_bin  val_bin:\n                    improvements_bin += 1\n\n                # --- Gray Encoding ---\n                k_prime_gray = gray_map[c_prime_int]\n                val_prime_gray = abs(2 * k_prime_gray - M)\n                if val_prime_gray  val_gray:\n                    improvements_gray += 1\n\n        # The total number of possible one-bit mutations for a single coordinate\n        # is the number of states times the number of bits.\n        total_mutations = num_states * b\n        \n        p_bin = improvements_bin / total_mutations if total_mutations  0 else 0.0\n        p_gray = improvements_gray / total_mutations if total_mutations  0 else 0.0\n\n        sub_result = [d_bin, d_gray, p_bin, p_gray]\n        result_str = f\"[{','.join(f'{x:.12f}' for x in sub_result)}]\"\n        formatted_results.append(result_str)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3132789"}, {"introduction": "标准遗传算法在寻找单个最优解方面表现出色，但在许多现实世界的设计问题中，我们往往希望找到多个同样优秀的解决方案。面对具有多个峰值的“多模态”（multimodal）函数，简单的遗传算法容易过早收敛到其中一个峰值，而忽略了其他可能。为了克服这一局限性，研究者们开发了多种“生境”（niching）技术来保护种群的多样性。这个实践 ([@problem_id:3132784]) 将引导你实现一种经典的生境技术——适应度共享（fitness sharing）。你将通过在一个定义好的多峰函数上运行带有和不带适应度共享的遗传算法，并量化比较它们发现并维持多个最优解的能力，从而掌握如何扩展遗传算法以解决更复杂的发现型（discovery-oriented）优化任务。", "problem": "您被要求设计并实现一个用于一维连续优化问题的遗传算法（GA），该算法包含显式适应度共享。其目的是量化在优化多峰目标函数时，适应度共享对保护多个生态位（niche）的影响。以下定义和事实构成了此任务的基础，您的解决方案必须由此推导而出。\n\n遗传算法（GA）维护一个候选解的种群，并迭代地应用选择、重组（交叉）和变异来使种群向更高适应度的方向进化。标准遗传算法使用原始适应度值来确定选择概率或锦标赛结果，这可能导致在多峰景观中过早收敛到单个峰值。适应度共享是一种多样化方法，它通过修改有效适应度来惩罚拥挤区域，从而能够在对应不同峰值的多个生态位中维持多样性。\n\n考虑一个在标量决策变量 $x \\in [L, U] = [-5, 5]$ 上的实数编码遗传算法。多峰目标定义为高斯峰的总和：\n$$\nf(x) = \\sum_{k=1}^{K} a_k \\exp\\left(-\\frac{(x - c_k)^2}{2 w_k^2}\\right),\n$$\n其中 $K$ 表示峰的数量，$a_k$ 表示峰的振幅，$c_k$ 表示峰的中心，$w_k$ 表示峰的宽度。对于此问题，使用 $K = 4$ 及以下参数：\n$$\nc = [-3.5, -0.5, 1.8, 3.2], \\quad a = [1.0, 0.8, 0.9, 1.2], \\quad w = [0.28, 0.35, 0.25, 0.30].\n$$\n\n适应度共享根据个体 $x_i$ 与种群中所有其他个体 $x_j$ 的距离来调整其有效适应度 $f'_i$：\n$$\nf'_i = \\frac{f(x_i)}{\\sum_{j=1}^{N} s\\left(d_{ij}\\right)},\n$$\n其中 $N$ 是种群大小，$d_{ij} = |x_i - x_j|$ 是决策空间中的欧氏距离，共享函数为：\n$$\ns(d) = \\frac{1}{1 + \\left(\\frac{d}{\\sigma}\\right)^{\\alpha}},\n$$\n其中生态位半径 $\\sigma  0$，形状参数 $\\alpha  0$。当禁用适应度共享时，选择必须直接使用原始适应度 $f(x)$。\n\n您的遗传算法必须采用以下根据标准遗传算法原则设计的通用组件：\n- 初始化：在 $[L, U]$ 内均匀采样 $x$。\n- 选择：使用相关适应度（共享或原始）应用大小为 $\\kappa$ 的锦标赛选择。\n- 交叉：给定两个父代 $x_p$ 和 $x_q$，通过算术重组生成一个子代 $x_c = \\lambda x_p + (1 - \\lambda) x_q$，其中 $\\lambda \\in [0, 1]$ 均匀随机选取，以概率 $\\rho$ 应用。\n- 变异：添加高斯噪声 $\\epsilon \\sim \\mathcal{N}(0, \\mu^2)$ 并裁剪到 $[L, U]$ 范围内。\n- 精英保留：根据原始适应度保留排名前 $e$ 的个体。\n- 终止：在 $G$ 代后停止。\n\n为了量化多峰保留情况，定义一个峰发现准则：如果在运行结束时，最终种群中至少有 $n_{\\min}$ 个个体与以 $c_k$ 为中心的峰的距离小于 $r_{\\mathrm{detect}}$，则认为该峰被发现。使用 $r_{\\mathrm{detect}} = 0.3$ 和 $n_{\\min} = 3$。已发现峰计数是满足此准则的不同 $k \\in \\{1, 2, 3, 4\\}$ 的数量。\n\n为每个测试配置实现两个版本：一个使用适应度共享（使用给定的 $\\sigma$ 和 $\\alpha$），另一个是不使用适应度共享的基准版本。对于每个配置，报告一个整数对 $[\\text{with\\_sharing}, \\text{without\\_sharing}]$，表示在终止时发现的峰的数量。\n\n测试套件：\n为以下参数集运行遗传算法（每个配置是一个独立的测试用例）。为保证可复现性，将每个用例的随机种子固定为 $s_i$，其中 $s_1 = 123$, $s_2 = 124$, $s_3 = 125$, $s_4 = 126$, $s_5 = 127$；在每个用例中，共享版本和基准版本的运行使用相同的种子。\n\n- 用例 1：$N = 60$, $G = 120$, $\\sigma = 0.6$, $\\alpha = 2$, $\\mu = 0.15$, $\\kappa = 3$, $\\rho = 0.9$, $e = \\lfloor 0.1 N \\rfloor$。\n- 用例 2：$N = 60$, $G = 120$, $\\sigma = 10^{-9}$, $\\alpha = 2$, $\\mu = 0.15$, $\\kappa = 3$, $\\rho = 0.9$, $e = \\lfloor 0.1 N \\rfloor$。\n- 用例 3：$N = 60$, $G = 120$, $\\sigma = 3.0$, $\\alpha = 2$, $\\mu = 0.15$, $\\kappa = 3$, $\\rho = 0.9$, $e = \\lfloor 0.1 N \\rfloor$。\n- 用例 4：$N = 30$, $G = 150$, $\\sigma = 0.6$, $\\alpha = 2$, $\\mu = 0.20$, $\\kappa = 3$, $\\rho = 0.9$, $e = \\lfloor 0.1 N \\rfloor$。\n- 用例 5：$N = 60$, $G = 120$, $\\sigma = 0.6$, $\\alpha = 4$, $\\mu = 0.15$, $\\kappa = 3$, $\\rho = 0.9$, $e = \\lfloor 0.1 N \\rfloor$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的每个元素对应一个测试用例，并且本身是一个双元素列表 $[\\text{with\\_sharing}, \\text{without\\_sharing}]$。例如，对于 $i \\in \\{1,2,3,4,5\\}$，结果为 $[[a_1,b_1],[a_2,b_2],\\dots]$，其中 $a_i$ 和 $b_i$ 是整数。", "solution": "该设计源于标准的遗传算法（GA）原则和适应度共享机制。遗传算法通过维护一个候选解种群，评估适应度，并在多代中应用选择、交叉和变异来探索和利用搜索空间。选择会放大具有较高适应度的个体，这在多峰目标中往往会导致大多数个体聚集在最高的峰上，从而降低多样性并抑制对其他峰的发现。\n\n适应度共享通过考虑种群密度来修改有效适应度。对于位于位置 $x_i$ 且原始适应度为 $f(x_i)$ 的个体，其共享适应度定义为：\n$$\nf'_i = \\frac{f(x_i)}{\\sum_{j=1}^{N} s(d_{ij})}, \\quad d_{ij} = |x_i - x_j|,\n$$\n其中共享函数 $s(d)$ 随距离平滑衰减，其公式为：\n$$\ns(d) = \\frac{1}{1 + \\left(\\frac{d}{\\sigma}\\right)^{\\alpha}}.\n$$\n当许多个体位于 $x_i$ 的距离尺度 $\\sigma$ 内时，此分母会增大，从而降低拥挤区域中个体的有效适应度。在选择中，使用 $f'_i$ 而不是 $f(x_i)$ 会惩罚过度拥挤，使个体较少的生态位更具竞争力。两个极限情况揭示了与遗传算法基本原理一致的行为：\n- 当 $\\sigma \\to 0^+$ 时，对于 $d  0$，$\\left(\\frac{d}{\\sigma}\\right)^{\\alpha} \\to \\infty$ 且 $s(d  0) \\to 0$，而 $s(0) = 1$。此时 $\\sum_j s(d_{ij}) \\approx 1$ 且 $f'_i \\approx f(x_i)$，恢复到基准遗传算法。\n- 当 $\\sigma$ 相对于域直径变得非常大时，对于所有 $d$，$s(d) \\approx \\frac{1}{1 + 0} = 1$，因此 $\\sum_j s(d_{ij}) \\approx N$，得到 $f'_i \\approx \\frac{f(x_i)}{N}$。这会使整个种群的选择压力趋于平坦，可能减慢收敛速度，并且如果变异和交叉不能弥补，会降低在多个峰周围形成集中聚类的能力。\n\n多峰目标定义为高斯峰的总和：\n$$\nf(x) = \\sum_{k=1}^{K} a_k \\exp\\left(-\\frac{(x - c_k)^2}{2 w_k^2}\\right),\n$$\n其中 $K = 4$，中心 $c = [-3.5, -0.5, 1.8, 3.2]$，振幅 $a = [1.0, 0.8, 0.9, 1.2]$，宽度 $w = [0.28, 0.35, 0.25, 0.30]$。这些参数在 $[L, U] = [-5, 5]$ 内产生了不同的峰，创建了一个真实且科学合理的多峰景观。\n\n遗传算法的组件被指定以确保有原则的实现：\n- 初始化在 $[L, U]$ 中均匀采样 $x$，提供无偏的初始多样性。\n- 通过大小为 $\\kappa$ 的锦标赛进行选择，使用所选的适应度（共享或原始）。锦标赛选择基于这样的原则：较高的适应度会增加赢得锦标赛的概率，从而传播有利的性状。\n- 算术交叉 $x_c = \\lambda x_p + (1 - \\lambda) x_q$，其中 $\\lambda \\sim \\mathcal{U}[0, 1]$，适用于实数编码遗传算法并尊重搜索空间的连续性。\n- 变异添加高斯噪声 $\\epsilon \\sim \\mathcal{N}(0, \\mu^2)$ 并裁剪到边界，确保有界的探索。\n- 精英保留根据原始适应度保留排名前 $e$ 的个体，以避免突然失去高质量的解，这与遗传算法的利用方面相一致。\n\n为了量化多峰保留情况，将已发现峰计数定义为在终止时，至少有 $n_{\\min}$ 个个体与峰中心 $c_k$ 的距离在 $r_{\\mathrm{detect}}$ 内的峰的数量。使用 $r_{\\mathrm{detect}} = 0.3$ 和 $n_{\\min} = 3$ 确保检测需要一个非平凡的聚类，而不是单个偶然的个体，这与维持生态位的目标一致。\n\n适应度共享的效果通过一个包含不同 $\\sigma$, $\\alpha$, $N$ 和 $G$ 的测试套件进行评估：\n- 适中的 $\\sigma$（例如 $\\sigma = 0.6$）和 $\\alpha = 2$ 通过惩罚大致在峰间距尺度上的拥挤峰来促进多个生态位的形成，使得多个峰能够持续存在。\n- 接近零的 $\\sigma$ 近似于基准情况，说明当生态位无穷小时，共享几乎没有影响。\n- 大的 $\\sigma$（例如 $\\sigma = 3.0$）对所有个体都施加了相似的过度惩罚，使有效适应度趋于平坦，并降低了围绕任何峰进行巩固的选择压力，如果变异不能产生足够的收敛，这可能会减少持续聚类的数量。\n- 增加 $\\alpha$ 会使共享函数变得更陡峭，使得惩罚随距离下降得更快，并调节生态位分离的锐度。\n\n通过在每个用例中使用相同的种子运行共享版本和基准版本，我们分离出适应度共享对最终发现峰数的影响。最终输出包含每个用例的配对 $[\\text{with\\_sharing}, \\text{without\\_sharing}]$。这直接量化了适应度共享如何改变遗传算法在多峰景观中维持多个生态位的能力，这一结论是一致地从遗传算法的基本原理和指定的共享函数推导出来的。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# Multimodal function: sum of Gaussians with specified parameters.\ndef f(x):\n    centers = np.array([-3.5, -0.5, 1.8, 3.2])\n    amplitudes = np.array([1.0, 0.8, 0.9, 1.2])\n    widths = np.array([0.28, 0.35, 0.25, 0.30])\n    # Ensure x is array-like\n    xv = np.atleast_1d(x)\n    total = np.zeros_like(xv, dtype=float)\n    for c, a, w in zip(centers, amplitudes, widths):\n        total += a * np.exp(-((xv - c) ** 2) / (2.0 * (w ** 2)))\n    return total\n\ndef sharing_denominator(pop, sigma_share, alpha):\n    \"\"\"\n    Compute the sharing denominator for each individual:\n    denom[i] = sum_j s(d_ij), where s(d) = 1 / (1 + (d/sigma)^alpha).\n    If sigma_share is None or = 0, return ones (no sharing).\n    \"\"\"\n    n = pop.shape[0]\n    if sigma_share is None or sigma_share == 0.0:\n        return np.ones(n, dtype=float)\n    # Compute pairwise distances in 1D\n    dists = np.abs(pop.reshape(-1, 1) - pop.reshape(1, -1))\n    # Avoid numerical issues when sigma is extremely small by safe division\n    scaled = (dists / sigma_share) ** alpha\n    s = 1.0 / (1.0 + scaled)\n    denom = np.sum(s, axis=1)\n    # Ensure denom is at least 1 (it includes self s(0)=1)\n    return denom\n\ndef tournament_select(pop, fitness, k, rng):\n    \"\"\"\n    Tournament selection: returns index of selected individual.\n    \"\"\"\n    n = pop.shape[0]\n    # Sample k competitors without replacement\n    idxs = rng.choice(n, size=k, replace=False)\n    # Winner is the one with highest fitness\n    winner_idx = idxs[np.argmax(fitness[idxs])]\n    return winner_idx\n\ndef make_child(p1, p2, crossover_rate, mutation_sigma, bounds, rng):\n    \"\"\"\n    Produce one child from parents p1, p2 with arithmetic crossover and Gaussian mutation.\n    \"\"\"\n    L, U = bounds\n    if rng.random()  crossover_rate:\n        lam = rng.random()\n        child = lam * p1 + (1.0 - lam) * p2\n    else:\n        # Clone one parent randomly\n        child = p1 if rng.random()  0.5 else p2\n    # Mutation\n    child += rng.normal(loc=0.0, scale=mutation_sigma)\n    # Clip to bounds\n    child = np.clip(child, L, U)\n    return child\n\ndef count_discovered_peaks(pop, r_detect=0.3, n_min=3):\n    centers = np.array([-3.5, -0.5, 1.8, 3.2])\n    counts = []\n    for c in centers:\n        num_near = np.sum(np.abs(pop - c)  r_detect)\n        counts.append(num_near >= n_min)\n    return int(np.sum(counts))\n\ndef run_ga_case(seed, pop_size, generations, sigma_share, alpha, mutation_sigma, tournament_k, crossover_rate, elite_count):\n    rng = np.random.default_rng(seed)\n    L, U = -5.0, 5.0\n    # Initialize population uniformly\n    pop = rng.uniform(L, U, size=pop_size)\n    # Run GA loop with sharing enabled\n    for _ in range(generations):\n        raw_fit = f(pop)\n        denom = sharing_denominator(pop, sigma_share, alpha)\n        shared_fit = raw_fit / denom\n        # Elites based on raw fitness\n        elite_idx = np.argsort(raw_fit)[-elite_count:]\n        elites = pop[elite_idx]\n        # Create offspring\n        offspring = []\n        needed = pop_size - elite_count\n        for _ in range(needed):\n            i1 = tournament_select(pop, shared_fit, tournament_k, rng)\n            i2 = tournament_select(pop, shared_fit, tournament_k, rng)\n            child = make_child(pop[i1], pop[i2], crossover_rate, mutation_sigma, (L, U), rng)\n            offspring.append(child)\n        pop = np.concatenate([elites, np.array(offspring)])\n    discovered = count_discovered_peaks(pop, r_detect=0.3, n_min=3)\n    return discovered\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (seed, N, G, sigma, alpha, mu, k, rho, elite_count)\n        (123, 60, 120, 0.6, 2.0, 0.15, 3, 0.9, int(0.1 * 60)),\n        (124, 60, 120, 1e-9, 2.0, 0.15, 3, 0.9, int(0.1 * 60)),\n        (125, 60, 120, 3.0, 2.0, 0.15, 3, 0.9, int(0.1 * 60)),\n        (126, 30, 150, 0.6, 2.0, 0.20, 3, 0.9, int(0.1 * 30)),\n        (127, 60, 120, 0.6, 4.0, 0.15, 3, 0.9, int(0.1 * 60)),\n    ]\n\n    results = []\n    for seed, N, G, sigma, alpha, mu, k, rho, e in test_cases:\n        # With sharing\n        with_sharing = run_ga_case(seed, N, G, sigma, alpha, mu, k, rho, e)\n        # Without sharing: same seed, sigma_share = None\n        without_sharing = run_ga_case(seed, N, G, None, alpha, mu, k, rho, e)\n        results.append([with_sharing, without_sharing])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3132784"}]}