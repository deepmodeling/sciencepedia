{"hands_on_practices": [{"introduction": "渐进符号（如 $O(n^2)$）是一个强大的工具，但它隐藏了在实践中至关重要的常数因子。本练习将演示如何找到“交叉点”，即一个渐进更优的算法（如基于FFT的方法）在实际中超越更简单算法（如教科书式的乘法）的临界点。通过使用包含这些常数的实际性能模型，您将对算法选择形成更细致的理解。[@problem_id:3190117]", "problem": "您正在比较三种大整数乘法算法：逐位相乘的“小学”方法、分治的 Karatsuba 方法以及基于快速傅里叶变换 (FFT) 的方法。目标是在包含显式常数因子的实际缩放律模型下，确定一个最小的整数规模，使得基于 FFT 的方法开始比两种竞争方法都更快。\n\n建模的基本依据：\n- “小学”方法的渐近增长率与 $n^2$ 成正比。\n- Karatsuba 方法的渐近增长率与 $n^{\\log_2 3}$ 成正比。\n- 基于 FFT 的方法的渐近增长率与 $n \\log_2 n$ 成正比。\n- 为符合经验实际，模型中必须包含常数因子和低阶线性项。\n\n假设以下时间模型，其成本单位是任意但一致的：\n- “小学”方法：$$T_{\\mathrm{S}}(n) = a_{\\mathrm{S}} \\, n^2.$$\n- Karatsuba 方法：$$T_{\\mathrm{K}}(n) = a_{\\mathrm{K}} \\, n^{\\alpha} + b_{\\mathrm{K}} \\, n,$$ 其中 $\\alpha = \\log_2 3$。\n- 基于 FFT 的方法：$$T_{\\mathrm{F}}(n) = a_{\\mathrm{F}} \\, n \\log_2 n + b_{\\mathrm{F}} \\, n.$$\n\n任务：\n- 对于测试套件中的每一组参数，计算闭区间 $[n_{\\min}, n_{\\max}]$ 内使以下两个不等式同时成立的最小整数 $n$：\n  $$T_{\\mathrm{F}}(n) \\le T_{\\mathrm{S}}(n) \\quad \\text{and} \\quad T_{\\mathrm{F}}(n) \\le T_{\\mathrm{K}}(n).$$\n- 如果在给定参数集的指定范围内不存在这样的整数，则对该参数集输出 $-1$。\n\n要求与约定：\n- 所有 $\\log_2$ 均使用以 2 为底的对数。\n- 将 $n$ 视为表示操作数长度（例如，位数或机器字）的无量纲整数。不涉及任何物理单位。\n- 在 $n = 1$ 时，定义 $\\log_2 1 = 0$ 并直接评估模型。\n- 每个测试用例的输出是一个整数。\n- 您的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表，例如，$$[n_1,n_2,n_3,n_4,n_5].$$\n\n测试套件：\n请为以下参数集提供结果，每组参数均以 $(a_{\\mathrm{S}}, a_{\\mathrm{K}}, a_{\\mathrm{F}}, b_{\\mathrm{K}}, b_{\\mathrm{F}}, n_{\\min}, n_{\\max})$ 的形式给出。\n\n1. $ (\\,1,\\,5,\\,200,\\,0,\\,1000,\\,1,\\,10^9\\,) $\n2. $ (\\,1000,\\,1000,\\,1,\\,0,\\,0,\\,1,\\,10^6\\,) $\n3. $ (\\,1,\\,1,\\,10^7,\\,0,\\,0,\\,1,\\,10^6\\,) $\n4. 选择常数以在 $n = 64$ 处创建一个边界交点：\n   - $ a_{\\mathrm{F}} = 1 $, $ b_{\\mathrm{F}} = 0 $,\n   - $ a_{\\mathrm{S}} = \\dfrac{\\log_2 64}{64} $,\n   - $ a_{\\mathrm{K}} = 64^{\\,1 - \\log_2 3} \\cdot \\log_2 64 $,\n   - $ b_{\\mathrm{K}} = 0 $,\n   - $ n_{\\min} = 1 $, $ n_{\\max} = 10^6 $.\n   因此，元组为 $ \\left(\\,\\dfrac{\\log_2 64}{64},\\,64^{\\,1 - \\log_2 3} \\cdot \\log_2 64,\\,1,\\,0,\\,0,\\,1,\\,10^6\\,\\right) $。\n5. $ (\\,0.5,\\,0.2,\\,10,\\,10000,\\,5000,\\,1,\\,10^7\\,) $\n\n您的程序必须实现一个稳健的方法来找到满足这两个不等式的最小整数 $n$，如果指定范围内不存在这样的整数，则返回 $-1$。最终输出必须是如上所述格式的单行文本，汇总所有五个案例的结果。", "solution": "所提出的问题是计算科学领域一个适定性良好的练习，具体涉及算法缩放律的分析。它具有科学依据、客观，并包含了得出严谨解所需的所有信息。该问题被认为是有效的。\n\n核心任务是确定一个交叉点，在该点上，基于 FFT 的整数乘法算法的效率开始超过“小学”乘法算法和 Karatsuba 乘法算法。该点被定义为在给定范围 $[n_{\\min}, n_{\\max}]$ 内的最小整数操作数规模 $n$，使得基于 FFT 方法的计算成本小于或等于其竞争者的成本。\n\n每种算法的时间复杂度由以下函数建模，其中 $n$ 代表操作数规模（例如，位数或机器字）：\n\n1.  “小学”方法：$T_{\\mathrm{S}}(n) = a_{\\mathrm{S}} \\, n^2$\n2.  Karatsuba 方法：$T_{\\mathrm{K}}(n) = a_{\\mathrm{K}} \\, n^{\\alpha} + b_{\\mathrm{K}} \\, n$，其中指数 $\\alpha = \\log_2 3 \\approx 1.585$。\n3.  基于 FFT 的方法：$T_{\\mathrm{F}}(n) = a_{\\mathrm{F}} \\, n \\log_2 n + b_{\\mathrm{F}} \\, n$。注意，对于 $n=1$，我们遵循约定 $\\log_2 1 = 0$。\n\n我们寻求在 $[n_{\\min}, n_{\\max}]$ 区间内满足以下不等式组的最小整数 $n$：\n$$\n\\begin{cases} \nT_{\\mathrm{F}}(n) \\le T_{\\mathrm{S}}(n) \\\\\nT_{\\mathrm{F}}(n) \\le T_{\\mathrm{K}}(n) \n\\end{cases}\n$$\n如果在指定范围内不存在这样的整数，则该参数集的结果定义为 $-1$。\n\n为了分析这个系统，我们可以定义两个差函数：\n$$D_{\\mathrm{S}}(n) = T_{\\mathrm{S}}(n) - T_{\\mathrm{F}}(n) = a_{\\mathrm{S}} n^2 - (a_{\\mathrm{F}} n \\log_2 n + b_{\\mathrm{F}} n)$$\n$$D_{\\mathrm{K}}(n) = T_{\\mathrm{K}}(n) - T_{\\mathrm{F}}(n) = (a_{\\mathrm{K}} n^{\\alpha} + b_{\\mathrm{K}} n) - (a_{\\mathrm{F}} n \\log_2 n + b_{\\mathrm{F}} n)$$\n问题现在变为找到在 $[n_{\\min}, n_{\\max}]$ 区间内使 $D_{\\mathrm{S}}(n) \\ge 0$ 和 $D_{\\mathrm{K}}(n) \\ge 0$ 同时成立的最小整数 $n$。\n\n让我们考察这些函数的渐近行为。$D_{\\mathrm{S}}(n)$ 中的主导项是 $a_{\\mathrm{S}} n^2$，$D_{\\mathrm{K}}(n)$ 中的主导项是 $a_{\\mathrm{K}} n^{\\alpha}$。由于指数 $2$ 和 $\\alpha \\approx 1.585$ 都大于 $1$，因此 $n^2$ 和 $n^{\\alpha}$ 项的渐近增长速度快于来自 $T_{\\mathrm{F}}(n)$ 的 $n \\log_2 n$ 项。假设首项系数 $a_{\\mathrm{S}}$ 和 $a_{\\mathrm{K}}$ 为正，那么两个差函数 $D_{\\mathrm{S}}(n)$ 和 $D_{\\mathrm{K}}(n)$ 最终都将变为正数，并对所有更大的 $n$ 保持为正。\n\n这种行为意味着布尔条件 $C(n) \\equiv (T_{\\mathrm{F}}(n) \\le T_{\\mathrm{S}}(n) \\land T_{\\mathrm{F}}(n) \\le T_{\\mathrm{K}}(n))$ 通常会在一个特定的交叉点从假（false）转变为真（true）。对于小于此点的 $n$，与基于 FFT 的方法相关联的较大常数因子或线性项使其效率较低。当 $n$ 达到或超过此点时，其优越的渐近伸缩性将占主导地位。\n\n寻找这个最小整数 $n$ 的过程必须是高效的，因为范围 $[n_{\\min}, n_{\\max}]$ 可能大至 $[1, 10^9]$。从 $n_{\\min}$ 开始对每个 $n$ 评估 $C(n)$ 的线性搜索在计算上是不可行的。\n\n考虑到解空间预期的单调性（即，如果 $C(k)$ 为真，那么对于所有 $j > k$，$C(j)$ 很可能也为真），二分搜索算法是找到第一个使 $C(n)$ 为真的整数 $n$ 的合适且高效的方法。\n\n对于每个参数集，算法按以下步骤进行：\n1.  定义一个用于评估 $C(n)$ 的布尔函数 `check(n)`。所有模型计算都使用浮点运算来确保处理实值系数和函数输出时的精度。\n2.  在 $n=n_{\\max}$ 处进行初始检查。如果 `check(n_max)` 为假，则意味着（在单调性假设下）在该范围内不存在解，结果为 $-1$。\n3.  在 $n=n_{\\min}$ 处进行第二次检查。如果 `check(n_min)` 为真，则 $n_{\\min}$ 是满足条件的最小整数，即为答案。\n4.  如果以上条件均不满足，则在整数范围 $[n_{\\min}, n_{\\max}]$ 上启动二分搜索。设搜索区间为 $[L, R]$。\n5.  在搜索的每一步中，选择一个中点 $M = L + \\lfloor(R-L)/2\\rfloor$。\n    - 如果 `check(M)` 为真，表示 $M$ 是一个潜在解。我们将 $M$ 记录为当前最佳答案，并通过设置 $R = M-1$ 在区间的下半部分继续搜索更小的解。\n    - 如果 `check(M)` 为假，表示 $M$ 太小，基于 FFT 的方法尚不具备优势。必须通过设置 $L = M+1$ 在区间的上半部分继续搜索。\n6.  当 $L > R$ 时，搜索终止。最后记录的答案即为该范围内满足条件的最小整数 $n$。如果循环完成而从未找到有效的 $n$（这种情况已被在 $n_{\\max}$ 处的初始检查所排除），则结果将保持为 $-1$。\n\n这种二分搜索方法能够稳健且高效地定位精确的整数交叉点，以对数方式缩减搜索空间。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the smallest integer n where an FFT-based multiplication algorithm\n    outperforms Schoolbook and Karatsuba methods for several parameter sets.\n    \"\"\"\n\n    # Define the exponent for the Karatsuba algorithm\n    alpha = np.log2(3)\n\n    # Test suite: (a_S, a_K, a_F, b_K, b_F, n_min, n_max)\n    test_cases = [\n        (1, 5, 200, 0, 1000, 1, 10**9),\n        (1000, 1000, 1, 0, 0, 1, 10**6),\n        (1, 1, 10**7, 0, 0, 1, 10**6),\n        (\n            np.log2(64) / 64,\n            64**(1 - np.log2(3)) * np.log2(64),\n            1,\n            0,\n            0,\n            1,\n            10**6\n        ),\n        (0.5, 0.2, 10, 10000, 5000, 1, 10**7),\n    ]\n\n    def find_crossover(params):\n        \"\"\"\n        Finds the smallest integer n in the given range [n_min, n_max]\n        that satisfies the crossover conditions, using binary search.\n        \"\"\"\n        a_S, a_K, a_F, b_K, b_F, n_min, n_max = params\n\n        def check(n):\n            \"\"\"\n            Checks if T_F(n) = T_S(n) and T_F(n) = T_K(n).\n            n is an integer, but calculations use floats for precision.\n            \"\"\"\n            if n == 0:\n                return False\n            \n            n_float = float(n)\n            \n            # Handle log2(1) = 0 case\n            log2_n = 0.0 if n == 1 else np.log2(n_float)\n\n            # Calculate the cost for each algorithm\n            t_s = a_S * n_float**2\n            t_k = a_K * n_float**alpha + b_K * n_float\n            t_f = a_F * n_float * log2_n + b_F * n_float\n            \n            return t_f = t_s and t_f = t_k\n\n        # Optimization: If the condition is met at n_min, it's the answer.\n        # This also handles the n_min=1 case correctly.\n        if check(n_min):\n            return n_min\n            \n        # Optimization: If the condition is not met at n_max and the crossover\n        # function is monotonic, no solution exists in the range.\n        if not check(n_max):\n            return -1\n\n        low = n_min\n        high = n_max\n        ans = -1\n\n        while low = high:\n            mid = low + (high - low) // 2\n            \n            # This check is for safety, though n_min >= 1 should prevent mid=0.\n            if mid == 0:\n                low = 1\n                continue\n\n            if check(mid):\n                # mid is a potential answer, try to find a smaller one\n                ans = mid\n                high = mid - 1\n            else:\n                # mid is too small, need to search in the upper half\n                low = mid + 1\n        \n        return ans\n\n    results = []\n    for case in test_cases:\n        result = find_crossover(case)\n        results.append(result)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3190117"}, {"introduction": "当我们将计算并行化时，性能不仅仅取决于处理器的数量，它更是一场计算与通信之间的博弈。本练习通过为一个并行热方程求解器建模通信与计算时间的比率，在两种关键场景下探索了这种权衡：强扩展（固定问题规模）和弱扩展（每个处理器的工作量固定）。分析这个比率是预测应用程序在超级计算机上表现如何以及理解并行化极限的基础。[@problem_id:3190082]", "problem": "给定一个简化的性能模型，用于一个二维显式有限差分热方程求解器，该求解器使用五点模板在均匀网格上执行一个时间步。计算域被划分到二维进程网格的各个进程上。目标是推导并计算在强扩展和弱扩展两种情况下，单个时间步的通信与计算时间比。计算基于每个进程的平均成本。每个测试用例的最终结果必须是一个无量纲的比率，四舍五入到六位小数。\n\n建模假设与基本原理：\n- 对于强扩展，全局网格大小为 $N_x \\times N_y$ 个网格点。对于弱扩展，每个进程的局部子域具有固定大小 $n_x^{\\mathrm{loc}} \\times n_y^{\\mathrm{loc}}$，与进程数无关。\n- 进程数为 $P$，进程排列在一个方形网格上，其中 $p_x=p_y=\\sqrt{P}$，$P$ 是一个完全平方数。通信和计算之间没有重叠。\n- 每个进程使用五点模板更新其所有局部网格点。每个网格点更新的计算时间为 $\\gamma$ 秒，因此每个进程的计算时间为 $T_{\\mathrm{comp}}=\\gamma \\, n_x^{\\mathrm{loc}} n_y^{\\mathrm{loc}}$。\n- 与最多四个面邻居发生光环交换。每次接口交换的宽度为一个单元，并精确地携带该面上的边界网格点。没有周期性边界；如果邻居不存在，则不在该面上发送消息。\n- 通信遵循延迟-带宽模型（也称为 Hockney 模型）：每条消息产生 $\\alpha$ 秒的延迟成本和每个网格点 $\\beta$ 秒的单位元素传输成本。一个时间步中的所有消息的大小等于交换边界的长度（以网格点计）。\n- 一个时间步内每个进程的通信时间被建模为所有进程的平均值。设一个时间步内所有进程间交换的点对点消息总数为 $M_{\\mathrm{tot}}$，所有消息中通信的网格点总数为 $E_{\\mathrm{tot}}$。那么，每个进程的平均通信时间为 $T_{\\mathrm{comm}}=\\alpha \\, \\frac{M_{\\mathrm{tot}}}{P} + \\beta \\, \\frac{E_{\\mathrm{tot}}}{P}$。对于一个具有非周期性边界的 $p_x \\times p_y$ 进程网格：\n  - 垂直邻居对的数量为 $p_x (p_y-1)$；水平邻居对的数量为 $(p_x-1) p_y$。每对邻居在每个时间步交换两条消息（每个方向一条）。\n  - 每条垂直邻居消息携带 $n_x^{\\mathrm{loc}}$ 个元素；每条水平邻居消息携带 $n_y^{\\mathrm{loc}}$ 个元素。\n- 在强扩展下，$n_x^{\\mathrm{loc}}=N_x/p_x$ 且 $n_y^{\\mathrm{loc}}=N_y/p_y$。在弱扩展下，$n_x^{\\mathrm{loc}}$ 和 $n_y^{\\mathrm{loc}}$ 是给定的固定值，不随 $P$ 的变化而变化。\n\n目标量：\n- 通信计算比为 $R = \\dfrac{T_{\\mathrm{comm}}}{T_{\\mathrm{comp}}}$，这是一个无量纲数。\n\n你的任务：\n- 对于下面的每个测试用例，使用上述模型计算 $R$。假设所有除法都能如指定的那样整除。精确使用 $p_x=p_y=\\sqrt{P}$。本问题不涉及角度。\n- 输出每个比率，四舍五入到六位小数。\n\n测试套件（六个案例）：\n1. 强扩展基线：\n   - 模式：强扩展\n   - $N_x=8192$，$N_y=8192$，$P=16$\n   - $\\alpha=2\\times 10^{-6}$ 秒，$\\beta=5\\times 10^{-9}$ 秒/元素，$\\gamma=3\\times 10^{-9}$ 秒/每网格点更新\n2. 强扩展边界情况（单进程）：\n   - 模式：强扩展\n   - $N_x=8192$，$N_y=8192$，$P=1$\n   - $\\alpha=2\\times 10^{-6}$ 秒，$\\beta=5\\times 10^{-9}$ 秒/元素，$\\gamma=3\\times 10^{-9}$ 秒/每网格点更新\n3. 强扩展多进程：\n   - 模式：强扩展\n   - $N_x=8192$，$N_y=8192$，$P=256$\n   - $\\alpha=2\\times 10^{-6}$ 秒，$\\beta=5\\times 10^{-9}$ 秒/元素，$\\gamma=3\\times 10^{-9}$ 秒/每网格点更新\n4. 弱扩展基线：\n   - 模式：弱扩展\n   - $n_x^{\\mathrm{loc}}=1024$，$n_y^{\\mathrm{loc}}=1024$，$P=16$\n   - $\\alpha=2\\times 10^{-6}$ 秒，$\\beta=5\\times 10^{-9}$ 秒/元素，$\\gamma=3\\times 10^{-9}$ 秒/每网格点更新\n5. 弱扩展，延迟主导的小子域：\n   - 模式：弱扩展\n   - $n_x^{\\mathrm{loc}}=64$，$n_y^{\\mathrm{loc}}=64$，$P=256$\n   - $\\alpha=5\\times 10^{-6}$ 秒，$\\beta=5\\times 10^{-9}$ 秒/元素，$\\gamma=3\\times 10^{-9}$ 秒/每网格点更新\n6. 弱扩展，带宽敏感的各向异性局部尺寸：\n   - 模式：弱扩展\n   - $n_x^{\\mathrm{loc}}=1024$，$n_y^{\\mathrm{loc}}=256$，$P=64$\n   - $\\alpha=1\\times 10^{-6}$ 秒，$\\beta=2\\times 10^{-8}$ 秒/元素，$\\gamma=2\\times 10^{-9}$ 秒/每网格点更新\n\n最终输出格式：\n- 你的程序必须生成单行输出，其中包含六个比率，顺序与上述测试用例相同，形式为用方括号括起来的逗号分隔列表。每个比率必须精确到小数点后六位。例如，格式为 [result1,result2,result3,...]，其中每个结果都是一个有六位小数的十进制数。", "solution": "该问题被评估为有效。它在并行计算的标准性能建模方面有科学依据，是适定的，提供了所有必要信息，并使用客观、正式的语言陈述。\n\n该模型虽然经过简化，却是分析并行算法中通信成本的标准工具（Hockney 模型）。所有参数在物理上都是合理的，并且设置是内部一致的。\n\n目标是计算二维有限差分求解器单个时间步的通信与计算时间比，$R = \\frac{T_{\\mathrm{comm}}}{T_{\\mathrm{comp}}}$。\n\n首先，我们形式化计算时间 $T_{\\mathrm{comp}}$ 和通信时间 $T_{\\mathrm{comm}}$ 的表达式。\n\n每个进程的计算时间定义为更新所有局部网格点所需的时间。对于大小为 $n_x^{\\mathrm{loc}} \\times n_y^{\\mathrm{loc}}$ 的局部子域和每点 $\\gamma$ 的计算成本，计算时间为：\n$$T_{\\mathrm{comp}} = \\gamma \\, n_x^{\\mathrm{loc}} n_y^{\\mathrm{loc}}$$\n\n每个进程的通信时间 $T_{\\mathrm{comm}}$ 被建模为所有 $P$ 个进程的平均成本。\n$$T_{\\mathrm{comm}} = \\alpha \\frac{M_{\\mathrm{tot}}}{P} + \\beta \\frac{E_{\\mathrm{tot}}}{P}$$\n其中 $\\alpha$ 是消息延迟，$\\beta$ 是每元素传输成本，$M_{\\mathrm{tot}}$ 是交换的消息总数，$E_{\\mathrm{tot}}$ 是传输的网格点总数。\n\n我们必须确定 $M_{\\mathrm{tot}}$ 和 $E_{\\mathrm{tot}}$。进程排列在一个 $p_x \\times p_y$ 的网格上，其中 $p_x = p_y = \\sqrt{P}$。边界是非周期性的。\n内部水平接口的数量为 $p_y(p_x-1)$。\n内部垂直接口的数量为 $p_x(p_y-1)$。\n每个接口涉及交换两条消息（每个方向一条）。\n因此，消息总数 $M_{\\mathrm{tot}}$ 为：\n$$M_{\\mathrm{tot}} = 2 \\cdot p_x(p_y-1) + 2 \\cdot p_y(p_x-1)$$\n代入 $p_x = p_y = \\sqrt{P}$：\n$$M_{\\mathrm{tot}} = 2\\sqrt{P}(\\sqrt{P}-1) + 2\\sqrt{P}(\\sqrt{P}-1) = 4\\sqrt{P}(\\sqrt{P}-1)$$\n每个进程的平均消息数为：\n$$\\frac{M_{\\mathrm{tot}}}{P} = \\frac{4\\sqrt{P}(\\sqrt{P}-1)}{P} = \\frac{4(\\sqrt{P}-1)}{\\sqrt{P}} = 4\\left(1 - \\frac{1}{\\sqrt{P}}\\right)$$\n请注意，如果 $P=1$，则 $M_{\\mathrm{tot}}=0$，这是正确的，因为没有通信。\n\n接下来，我们确定通信的元素总数 $E_{\\mathrm{tot}}$。\n跨越垂直接口（进程列之间）的消息包含一行 $n_x^{\\mathrm{loc}}$ 个点。\n跨越水平接口（进程行之间）的消息包含一列 $n_y^{\\mathrm{loc}}$ 个点。\n通信的元素总数为：\n$$E_{\\mathrm{tot}} = 2 \\cdot p_x(p_y-1) \\cdot n_x^{\\mathrm{loc}} + 2 \\cdot p_y(p_x-1) \\cdot n_y^{\\mathrm{loc}}$$\n代入 $p_x = p_y = \\sqrt{P}$：\n$$E_{\\mathrm{tot}} = 2\\sqrt{P}(\\sqrt{P}-1)n_x^{\\mathrm{loc}} + 2\\sqrt{P}(\\sqrt{P}-1)n_y^{\\mathrm{loc}} = 2\\sqrt{P}(\\sqrt{P}-1)(n_x^{\\mathrm{loc}} + n_y^{\\mathrm{loc}})$$\n每个进程平均通信的元素数量为：\n$$\\frac{E_{\\mathrm{tot}}}{P} = \\frac{2\\sqrt{P}(\\sqrt{P}-1)(n_x^{\\mathrm{loc}} + n_y^{\\mathrm{loc}})}{P} = \\frac{2(\\sqrt{P}-1)(n_x^{\\mathrm{loc}} + n_y^{\\mathrm{loc}})}{\\sqrt{P}} = 2\\left(1 - \\frac{1}{\\sqrt{P}}\\right)(n_x^{\\mathrm{loc}} + n_y^{\\mathrm{loc}})$$\n\n现在我们可以写出 $T_{\\mathrm{comm}}$ 的完整表达式：\n$$T_{\\mathrm{comm}} = \\alpha \\cdot 4\\left(1 - \\frac{1}{\\sqrt{P}}\\right) + \\beta \\cdot 2\\left(1 - \\frac{1}{\\sqrt{P}}\\right)(n_x^{\\mathrm{loc}} + n_y^{\\mathrm{loc}})$$\n$$T_{\\mathrm{comm}} = 2\\left(1 - \\frac{1}{\\sqrt{P}}\\right) \\left[ 2\\alpha + \\beta(n_x^{\\mathrm{loc}} + n_y^{\\mathrm{loc}}) \\right]$$\n\n因此，通信计算比 $R$ 为：\n$$R = \\frac{T_{\\mathrm{comm}}}{T_{\\mathrm{comp}}} = \\frac{2\\left(1 - \\frac{1}{\\sqrt{P}}\\right) \\left[ 2\\alpha + \\beta(n_x^{\\mathrm{loc}} + n_y^{\\mathrm{loc}}) \\right]}{\\gamma \\, n_x^{\\mathrm{loc}} n_y^{\\mathrm{loc}}}$$\n这个通用公式适用于两种扩展场景。区别在于如何确定 $n_x^{\\mathrm{loc}}$ 和 $n_y^{\\mathrm{loc}}$。\n\n对于强扩展，全局问题大小 $N_x \\times N_y$ 是固定的。随着 $P$ 的增加，每个进程的局部大小会缩小：\n$n_x^{\\mathrm{loc}} = N_x / p_x = N_x / \\sqrt{P}$\n$n_y^{\\mathrm{loc}} = N_y / p_y = N_y / \\sqrt{P}$\n\n对于弱扩展，局部问题大小 $n_x^{\\mathrm{loc}} \\times n_y^{\\mathrm{loc}}$ 是固定的。全局问题大小随 $P$ 的增加而增长。\n\n我们现在将此框架应用于每个测试用例。\n\n**案例1：强扩展基线**\n- 模式：强扩展\n- $N_x=8192$, $N_y=8192$, $P=16$ ($\\sqrt{P}=4$)\n- $\\alpha=2 \\times 10^{-6}$ s, $\\beta=5 \\times 10^{-9}$ s/元素, $\\gamma=3 \\times 10^{-9}$ s/更新\n- $n_x^{\\mathrm{loc}} = 8192/4 = 2048$, $n_y^{\\mathrm{loc}} = 8192/4 = 2048$\n- $R = \\frac{2(1 - 1/4)[2(2 \\times 10^{-6}) + (5 \\times 10^{-9})(2048+2048)]}{(3 \\times 10^{-9})(2048)(2048)} = \\frac{1.5[4 \\times 10^{-6} + 2.048 \\times 10^{-5}]}{0.012582912} = \\frac{3.672 \\times 10^{-5}}{0.012582912} \\approx 0.002918$\n\n**案例2：强扩展边界情况（单进程）**\n- 模式：强扩展\n- $N_x=8192$, $N_y=8192$, $P=1$ ($\\sqrt{P}=1$)\n- $\\alpha, \\beta, \\gamma$ 与案例1相同。\n- 项 $(1 - 1/\\sqrt{P}) = (1-1/1) = 0$。因此，$T_{\\mathrm{comm}}=0$ 且 $R=0$。\n- $R=0.000000$\n\n**案例3：强扩展多进程**\n- 模式：强扩展\n- $N_x=8192$, $N_y=8192$, $P=256$ ($\\sqrt{P}=16$)\n- $\\alpha=2 \\times 10^{-6}$ s, $\\beta=5 \\times 10^{-9}$ s/元素, $\\gamma=3 \\times 10^{-9}$ s/更新\n- $n_x^{\\mathrm{loc}} = 8192/16 = 512$, $n_y^{\\mathrm{loc}} = 8192/16 = 512$\n- $R = \\frac{2(1 - 1/16)[2(2 \\times 10^{-6}) + (5 \\times 10^{-9})(512+512)]}{(3 \\times 10^{-9})(512)(512)} = \\frac{1.875[4 \\times 10^{-6} + 5.12 \\times 10^{-6}]}{0.000786432} = \\frac{1.71 \\times 10^{-5}}{0.000786432} \\approx 0.021742$\n\n**案例4：弱扩展基线**\n- 模式：弱扩展\n- $n_x^{\\mathrm{loc}}=1024$, $n_y^{\\mathrm{loc}}=1024$, $P=16$ ($\\sqrt{P}=4$)\n- $\\alpha=2 \\times 10^{-6}$ s, $\\beta=5 \\times 10^{-9}$ s/元素, $\\gamma=3 \\times 10^{-9}$ s/更新\n- $R = \\frac{2(1 - 1/4)[2(2 \\times 10^{-6}) + (5 \\times 10^{-9})(1024+1024)]}{(3 \\times 10^{-9})(1024)(1024)} = \\frac{1.5[4 \\times 10^{-6} + 1.024 \\times 10^{-5}]}{0.003145728} = \\frac{2.136 \\times 10^{-5}}{0.003145728} \\approx 0.006790$\n\n**案例5：弱扩展，延迟主导的小子域**\n- 模式：弱扩展\n- $n_x^{\\mathrm{loc}}=64$, $n_y^{\\mathrm{loc}}=64$, $P=256$ ($\\sqrt{P}=16$)\n- $\\alpha=5 \\times 10^{-6}$ s, $\\beta=5 \\times 10^{-9}$ s/元素, $\\gamma=3 \\times 10^{-9}$ s/更新\n- $R = \\frac{2(1 - 1/16)[2(5 \\times 10^{-6}) + (5 \\times 10^{-9})(64+64)]}{(3 \\times 10^{-9})(64)(64)} = \\frac{1.875[10^{-5} + 6.4 \\times 10^{-7}]}{1.2288 \\times 10^{-5}} = \\frac{1.995 \\times 10^{-5}}{1.2288 \\times 10^{-5}} \\approx 1.623535$\n\n**案例6：弱扩展，带宽敏感的各向异性局部尺寸**\n- 模式：弱扩展\n- $n_x^{\\mathrm{loc}}=1024$, $n_y^{\\mathrm{loc}}=256$, $P=64$ ($\\sqrt{P}=8$)\n- $\\alpha=1 \\times 10^{-6}$ s, $\\beta=2 \\times 10^{-8}$ s/元素, $\\gamma=2 \\times 10^{-9}$ s/更新\n- $R = \\frac{2(1 - 1/8)[2(1 \\times 10^{-6}) + (2 \\times 10^{-8})(1024+256)]}{(2 \\times 10^{-9})(1024)(256)} = \\frac{1.75[2 \\times 10^{-6} + 2.56 \\times 10^{-5}]}{0.000524288} = \\frac{4.83 \\times 10^{-5}}{0.000524288} \\approx 0.092125$", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Calculates the communication-to-computation time ratio for a\n    2D finite-difference solver under different scaling scenarios.\n    \"\"\"\n    test_cases = [\n        # Case 1: Strong scaling baseline\n        {\n            \"mode\": \"strong\",\n            \"Nx\": 8192, \"Ny\": 8192, \"P\": 16,\n            \"alpha\": 2e-6, \"beta\": 5e-9, \"gamma\": 3e-9\n        },\n        # Case 2: Strong scaling boundary case (single process)\n        {\n            \"mode\": \"strong\",\n            \"Nx\": 8192, \"Ny\": 8192, \"P\": 1,\n            \"alpha\": 2e-6, \"beta\": 5e-9, \"gamma\": 3e-9\n        },\n        # Case 3: Strong scaling many processes\n        {\n            \"mode\": \"strong\",\n            \"Nx\": 8192, \"Ny\": 8192, \"P\": 256,\n            \"alpha\": 2e-6, \"beta\": 5e-9, \"gamma\": 3e-9\n        },\n        # Case 4: Weak scaling baseline\n        {\n            \"mode\": \"weak\",\n            \"nx_loc\": 1024, \"ny_loc\": 1024, \"P\": 16,\n            \"alpha\": 2e-6, \"beta\": 5e-9, \"gamma\": 3e-9\n        },\n        # Case 5: Weak scaling, latency-dominated small subdomains\n        {\n            \"mode\": \"weak\",\n            \"nx_loc\": 64, \"ny_loc\": 64, \"P\": 256,\n            \"alpha\": 5e-6, \"beta\": 5e-9, \"gamma\": 3e-9\n        },\n        # Case 6: Weak scaling, bandwidth-sensitive anisotropic local size\n        {\n            \"mode\": \"weak\",\n            \"nx_loc\": 1024, \"ny_loc\": 256, \"P\": 64,\n            \"alpha\": 1e-6, \"beta\": 2e-8, \"gamma\": 2e-9\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        p = case[\"P\"]\n        alpha = case[\"alpha\"]\n        beta = case[\"beta\"]\n        gamma = case[\"gamma\"]\n\n        if p == 1:\n            # A single process has no communication.\n            results.append(0.0)\n            continue\n\n        sqrt_p = np.sqrt(p)\n        \n        if case[\"mode\"] == \"strong\":\n            nx_loc = case[\"Nx\"] / sqrt_p\n            ny_loc = case[\"Ny\"] / sqrt_p\n        elif case[\"mode\"] == \"weak\":\n            nx_loc = case[\"nx_loc\"]\n            ny_loc = case[\"ny_loc\"]\n        \n        # Compute time per process\n        t_comp = gamma * nx_loc * ny_loc\n\n        # Average communication time per process\n        # T_comm = 2 * (1 - 1/sqrt(P)) * [2*alpha + beta*(nx_loc + ny_loc)]\n        t_comm = 2.0 * (1.0 - 1.0 / sqrt_p) * (2.0 * alpha + beta * (nx_loc + ny_loc))\n        \n        # Communication-to-computation ratio\n        ratio = t_comm / t_comp\n        results.append(ratio)\n\n    # Format the final output as specified\n    formatted_results = [f'{r:.6f}' for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n\n```", "id": "3190082"}, {"introduction": "数值方法的理论标度律，例如随机微分方程求解器的收敛率，需要通过严谨的计算实验来证实。本练习将指导您完成经验性地验证欧拉-丸山方法的不同强收敛阶和弱收敛阶的过程。您将学习如何设计数值实验，使用蒙特卡洛模拟处理随机性，并分析结果数据以测量标度指数——这是计算科学中的一项核心技能。[@problem_id:3190151]", "problem": "考虑一个一维随机微分方程 (SDE)，其定义为 $dX_t = a(X_t)\\,dt + b(X_t)\\,dW_t$，初始条件为 $X_0 = x_0$，其中 $W_t$ 是一个具有独立增量的标准维纳过程，$a(\\cdot)$ 和 $b(\\cdot)$ 是全局 Lipschitz 连续且呈线性增长的函数。Euler–Maruyama 时间步进格式在终端时间 $T$ 上使用步长 $\\Delta t$ 更新离散近似 $X_n^{\\mathrm{EM}}$，其公式为 $X_{n+1}^{\\mathrm{EM}} = X_n^{\\mathrm{EM}} + a(X_n^{\\mathrm{EM}})\\,\\Delta t + b(X_n^{\\mathrm{EM}})\\,\\Delta W_n$，其中 $\\Delta W_n$ 是服从 $\\mathcal{N}(0,\\Delta t)$ 分布的独立正态增量，且 $n=0,1,\\dots,N-1$，其中 $N = T/\\Delta t$。在终端时间考虑两种误差概念：强误差，定义为期望 $\\mathbb{E}\\left[\\lvert X_T - X_T^{\\mathrm{EM}}\\rvert\\right]$；以及对于标量可观测函数 $f$ 定义的弱误差，即 $\\lvert \\mathbb{E}[f(X_T)] - \\mathbb{E}[f(X_T^{\\mathrm{EM}})]\\rvert$。您的任务是通过系统性的细化，根据经验确定这些误差相对于时间步长 $\\Delta t$ 的标度律。\n\n验证方法必须使用一系列细化过程，在保持终端时间 $T$ 固定的同时，将步长 $\\Delta t$ 减半。对于每个 $\\Delta t$，通过蒙特卡洛抽样（使用固定数量的路径）来估计强误差和弱误差，然后通过对 $\\log(\\text{error})$ 与 $\\log(\\Delta t)$ 进行线性回归来计算经验标度指数。计算实验必须基于具有已知精确终端解的过程，以便可以无偏地计算参考值。使用以下过程和参数集，并采用 $f(x)=x$ 进行弱误差评估。所有数值必须严格按照规定处理。\n\n- 几何布朗运动 (GBM)：$dX_t = \\mu X_t\\,dt + \\sigma X_t\\,dW_t$，初始条件为 $X_0 = x_0$。\n- GBM 的确定性极限：$dX_t = \\mu X_t\\,dt$（即 $\\sigma = 0$），初始条件为 $X_0 = x_0$。\n\n对于 GBM，必须通过生成独立的高斯增量并应用 Euler–Maruyama 更新来进行模拟。强误差的计算必须通过将数值近似与沿同一布朗路径的精确解耦合起来，使用终端总增量。弱误差的计算必须通过将蒙特卡洛估计量 $\\mathbb{E}[X_T^{\\mathrm{EM}}]$ 与给定过程的精确终端期望进行比较。\n\n除非明确说明，所有测试均使用以下全局定义参数：\n- 终端时间 $T = 1.0$。\n- 细化水平 $N \\in \\{32,64,128,256\\}$，因此 $\\Delta t = T/N$。\n- 每个水平的独立蒙特卡洛路径数 $M_{\\text{paths}} = 16000$。\n- 随机数生成器必须使用确定性种子，以确保结果可复现。\n\n定义以下具有明确参数值的测试套件：\n\n- 测试 $1\\mathrm{W}$ (GBM 弱标度)：$x_0 = 1.0$, $\\mu = 0.2$, $\\sigma = 0.5$。从回归中确定弱标度指数 $p_{\\mathrm{w}}$；程序必须返回一个布尔值，指示 $p_{\\mathrm{w}}$ 是否位于 $1.0$ 周围 $\\pm 0.25$ 的容差范围内。\n\n- 测试 $1\\mathrm{S}$ (GBM 强标度)：$x_0 = 1.0$, $\\mu = 0.2$, $\\sigma = 0.5$。从回归中确定强标度指数 $p_{\\mathrm{s}}$；程序必须返回一个布尔值，指示 $p_{\\mathrm{s}}$ 是否位于 $0.5$ 周围 $\\pm 0.25$ 的容差范围内。\n\n- 测试 $2\\mathrm{W}$ (确定性弱标度)：$x_0 = 1.0$, $\\mu = 0.2$, $\\sigma = 0.0$。确定 $p_{\\mathrm{w}}$；程序必须返回一个布尔值，指示 $p_{\\mathrm{w}}$ 是否位于 $1.0$ 周围 $\\pm 0.25$ 的容差范围内。\n\n- 测试 $2\\mathrm{S}$ (确定性强标度)：$x_0 = 1.0$, $\\mu = 0.2$, $\\sigma = 0.0$。确定 $p_{\\mathrm{s}}$；程序必须返回一个布尔值，指示 $p_{\\mathrm{s}}$ 是否位于 $1.0$ 周围 $\\pm 0.25$ 的容差范围内。\n\n- 测试 $3$ (退化的 GBM)：$x_0 = 0.0$, $\\mu = 0.2$, $\\sigma = 0.5$。在这种情况下，对于任何 $\\Delta t$，精确和数值的终端值都恒为零。程序必须返回一个布尔值，指示对于所有细化水平，强误差和弱误差的估计值是否在数值上都低于 $10^{-12}$ 的阈值。\n\n参考计算所需的精确值必须从指定过程的闭式终端解中获得。对于参数为 $(x_0,\\mu,\\sigma)$ 和终端时间 $T$ 的 GBM，沿具有终端增量 $W_T$ 的布朗路径的精确终端值为 $X_T = x_0 \\exp\\left((\\mu - \\tfrac{1}{2}\\sigma^2)T + \\sigma W_T\\right)$，精确终端期望为 $\\mathbb{E}[X_T] = x_0 \\exp(\\mu T)$。对于 $\\sigma = 0$ 的确定性极限，精确终端值为 $X_T = x_0 \\exp(\\mu T)$，且精确终端期望与此值一致。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，顺序为 $[1\\mathrm{W},1\\mathrm{S},2\\mathrm{W},2\\mathrm{S},3]$，其中每个条目是根据上述规范评估的布尔值。例如，如果所有验证都成功，一个有效的输出是 $[{\\tt True},{\\tt True},{\\tt True},{\\tt True},{\\tt True}]$。", "solution": "用户提供的问题是随机数值方法领域中一个有效且适定的计算任务。它要求对应用于特定随机微分方程 (SDE) 的 Euler-Maruyama 格式的收敛率进行经验验证。该问题具有科学依据、内容自洽，并且所有参数和过程都已明确指定。\n\n### 理论框架\n\n该问题围绕一维 Itô SDE 的数值近似展开：\n$$dX_t = a(X_t)\\,dt + b(X_t)\\,dW_t, \\quad X_0 = x_0$$\n其中 $W_t$ 是一个标准维纳过程。Euler-Maruyama 格式通过递推关系在时间点 $t_n = n \\Delta t$ 提供离散时间近似 $X^{\\mathrm{EM}}$：\n$$X_{n+1}^{\\mathrm{EM}} = X_n^{\\mathrm{EM}} + a(X_n^{\\mathrm{EM}})\\,\\Delta t + b(X_n^{\\mathrm{EM}})\\,\\Delta W_n$$\n这里，$\\Delta t = T/N$ 是终端时间 $T$ 和 $N$ 个步骤的时间步长，而 $\\Delta W_n = W_{t_{n+1}} - W_{t_n}$ 是独立同分布的正态随机变量，均值为 0，方差为 $\\Delta t$，即 $\\Delta W_n \\sim \\mathcal{N}(0, \\Delta t)$。\n\n两个主要的收敛概念是相关的：\n1.  **强收敛**：这衡量了数值近似与真实解在路径上的接近程度。在终端时间 $T$ 的强误差定义为 $\\mathbb{E}\\left[\\lvert X_T - X_T^{\\mathrm{EM}}\\rvert\\right]$。对于具有全局 Lipschitz 系数的 SDE，Euler-Maruyama 格式的强收敛阶为 $p_{\\mathrm{s}} = 0.5$。这意味着误差的标度为 $\\mathcal{O}((\\Delta t)^{0.5})$。\n2.  **弱收敛**：这衡量了解的函数期望的接近程度。对于给定的可观测函数 $f$，弱误差为 $\\lvert \\mathbb{E}[f(X_T)] - \\mathbb{E}[f(X_T^{\\mathrm{EM}})]\\rvert$。Euler-Maruyama 格式通常具有 $p_{\\mathrm{w}} = 1.0$ 的弱收敛阶，意味着误差的标度为 $\\mathcal{O}(\\Delta t)$。\n\n该问题要求通过观察来经验性地确定标度指数 $p_{\\mathrm{s}}$ 和 $p_{\\mathrm{w}}$。如果误差 $\\epsilon$ 的标度为 $\\epsilon(\\Delta t) \\approx C (\\Delta t)^p$，那么 $\\log(\\epsilon)$ 对 $\\log(\\Delta t)$ 的图将近似为一条斜率为 $p$ 的直线：\n$$\\log(\\epsilon(\\Delta t)) \\approx \\log(C) + p \\log(\\Delta t)$$\n因此，可以通过对从不同步长 $\\Delta t$ 的模拟中获得的对数-对数数据进行线性回归来估计指数 $p$。\n\n### 方法论与实现策略\n\n解决方案涉及对指定的测试用例进行一系列计算实验。实现的核心将是使用 `numpy` 对 Euler-Maruyama 格式进行向量化的蒙特卡洛模拟。\n\n**1. 几何布朗运动 (GBM) 的模拟：**\nGBM 过程由 $dX_t = \\mu X_t\\,dt + \\sigma X_t\\,dW_t$ 给出。这对应于 $a(x) = \\mu x$ 和 $b(x) = \\sigma x$。Euler-Maruyama 更新规则为：\n$$X_{n+1}^{\\mathrm{EM}} = X_n^{\\mathrm{EM}} + \\mu X_n^{\\mathrm{EM}}\\,\\Delta t + \\sigma X_n^{\\mathrm{EM}}\\,\\Delta W_n = X_n^{\\mathrm{EM}}(1 + \\mu\\,\\Delta t + \\sigma\\,\\Delta W_n)$$\n对于每个细化水平 $N \\in \\{32, 64, 128, 256\\}$，我们将执行以下步骤：\n- 用 $\\Delta t = T/N$ 离散化时间。\n- 模拟从 $t=0$ 到 $t=T$ 的 $M_{\\text{paths}} = 16000$ 条独立路径。对于每条路径，我们生成 $N$ 个随机增量 $\\Delta W_n \\sim \\mathcal{N}(0, \\Delta t)$ 并迭代地应用更新规则。\n- 对于每条路径，我们跟踪累积维纳增量 $W_T = \\sum_{n=0}^{N-1} \\Delta W_n$。\n- 在终端时间 $T$，我们将得到一组数值解 $\\{X_{T,i}^{\\mathrm{EM}}\\}_{i=1}^{M_{\\text{paths}}}$。\n\n**2. GBM 的误差计算：**\n- **强误差**：对于由总增量 $W_T$ 驱动的路径，GBM 在时间 $T$ 的精确解是 $X_T = x_0 \\exp\\left((\\mu - \\frac{1}{2}\\sigma^2)T + \\sigma W_T\\right)$。我们为 $M_{\\text{paths}}$ 条模拟的维纳路径中的每一条计算这个值。然后通过样本均值估计强误差：\n$$\\epsilon_{\\mathrm{strong}} \\approx \\frac{1}{M_{\\text{paths}}} \\sum_{i=1}^{M_{\\text{paths}}} \\lvert X_{T,i} - X_{T,i}^{\\mathrm{EM}}\\rvert$$\n- **弱误差**：可观测函数是 $f(x)=x$。精确的终端期望是 $\\mathbb{E}[X_T] = x_0 \\exp(\\mu T)$。数值期望通过样本均值估计 $\\mathbb{E}[X_T^{\\mathrm{EM}}] \\approx \\frac{1}{M_{\\text{paths}}} \\sum_{i=1}^{M_{\\text{paths}}} X_{T,i}^{\\mathrm{EM}}$。因此，弱误差是：\n$$\\epsilon_{\\mathrm{weak}} \\approx \\left\\lvert x_0 e^{\\mu T} - \\frac{1}{M_{\\text{paths}}} \\sum_{i=1}^{M_{\\text{paths}}} X_{T,i}^{\\mathrm{EM}} \\right\\rvert$$\n\n**3. 确定性情况 ($\\sigma=0$):**\n当 $\\sigma=0$ 时，SDE 简化为常微分方程 (ODE) $dX_t = \\mu X_t\\,dt$。Euler-Maruyama 格式变为前向欧拉法：$X_{n+1}^{\\mathrm{EM}} = X_n^{\\mathrm{EM}}(1 + \\mu \\Delta t)$。在时间 $T$ 的数值解是确定性的：$X_T^{\\mathrm{EM}} = x_0(1 + \\mu \\Delta t)^N$。精确解是 $X_T = x_0 \\exp(\\mu T)$。由于没有随机性，蒙特卡洛模拟是不必要的（$M_{\\text{paths}}=1$）。强误差和弱误差是相同的：\n$$\\epsilon_{\\mathrm{strong}} = \\epsilon_{\\mathrm{weak}} = \\lvert X_T - X_T^{\\mathrm{EM}}\\rvert = \\lvert x_0 e^{\\mu T} - x_0(1 + \\mu \\frac{T}{N})^N \\rvert$$\n前向欧拉法的理论收敛阶为 $p=1.0$。\n\n**4. 退化情况 ($x_0=0$):**\n对于 $x_0=0$ 的 GBM，初始条件是一个吸收态。更新规则 $X_{n+1}^{\\mathrm{EM}} = X_n^{\\mathrm{EM}}(1 + \\mu \\Delta t + \\sigma \\Delta W_n)$ 表明，如果 $X_n^{\\mathrm{EM}}=0$，那么 $X_{n+1}^{\\mathrm{EM}}=0$。通过归纳法，$X_n^{\\mathrm{EM}}=0$ 对所有 $n$ 成立。同样，精确解是 $X_t=0$ 对所有 $t$ 成立。因此，强误差和弱误差在理论上都为零。该测试验证数值实现产生的误差是否低于一个小的浮点容差 ($10^{-12}$)。\n\n**5. 标度指数估计：**\n对于每个需要标度指数的测试套件（测试 $1\\mathrm{S}, 1\\mathrm{W}, 2\\mathrm{S}, 2\\mathrm{W}$），我们计算每个 $\\Delta t = T/N$ 的误差。然后我们使用 `numpy.polyfit` 来找到 $\\log(\\text{error})$ 对 $\\log(\\Delta t)$ 的最佳拟合线的斜率。这个斜率就是我们对收敛阶 $p$ 的经验估计。\n\n最终的 Python 实现将封装此逻辑，按顺序执行每个测试用例，并根据指定的标准生成所需的布尔输出。为随机数生成器使用确定性种子可确保可复现性。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Empirically determines the scaling laws for the Euler-Maruyama scheme\n    applied to Geometric Brownian Motion and its deterministic limit.\n    \"\"\"\n    \n    # Global parameters\n    T = 1.0\n    N_VALUES = np.array([32, 64, 128, 256])\n    M_PATHS = 16000\n    RNG_SEED = 42\n\n    def get_scaling_exponent(delta_ts, errors):\n        \"\"\"\n        Performs a linear regression on log-log data to find the scaling exponent.\n        \"\"\"\n        # Filter out zero or negative errors before taking log\n        valid_indices = errors > 0\n        if np.sum(valid_indices)  2:\n            return np.nan # Not enough data for regression\n\n        log_delta_ts = np.log(delta_ts[valid_indices])\n        log_errors = np.log(errors[valid_indices])\n        \n        # Fit a line: log(error) = p * log(dt) + C\n        p, _ = np.polyfit(log_delta_ts, log_errors, 1)\n        return p\n\n    def run_stochastic_simulation(params, n_values, T_val, m_paths, seed):\n        \"\"\"\n        Runs the Euler-Maruyama simulation for a stochastic process.\n        \"\"\"\n        x0, mu, sigma = params\n        \n        delta_ts = T_val / n_values\n        strong_errors = []\n        weak_errors = []\n        \n        rng = np.random.default_rng(seed)\n\n        for N in n_values:\n            dt = T_val / N\n            sqrt_dt = np.sqrt(dt)\n\n            # Initialize paths\n            X_em = np.full(m_paths, x0, dtype=float)\n            \n            # If x0 is 0, the solution is always 0.\n            if x0 == 0.0:\n                X_T_em = np.zeros(m_paths)\n                total_dW = np.zeros(m_paths)\n            else:\n                total_dW = np.zeros(m_paths)\n                for _ in range(N):\n                    dW = rng.normal(0.0, sqrt_dt, m_paths)\n                    X_em += mu * X_em * dt + sigma * X_em * dW\n                    total_dW += dW\n                X_T_em = X_em\n\n            # Weak Error Calculation\n            E_X_T_exact = x0 * np.exp(mu * T_val)\n            E_X_T_em = np.mean(X_T_em)\n            weak_err = np.abs(E_X_T_exact - E_X_T_em)\n            weak_errors.append(weak_err)\n\n            # Strong Error Calculation\n            W_T = total_dW\n            X_T_exact = x0 * np.exp((mu - 0.5 * sigma**2) * T_val + sigma * W_T)\n            strong_err = np.mean(np.abs(X_T_exact - X_T_em))\n            strong_errors.append(strong_err)\n            \n        return delta_ts, np.array(strong_errors), np.array(weak_errors)\n        \n    def run_deterministic_simulation(params, n_values, T_val):\n        \"\"\"\n        Computes the error for the deterministic ODE case.\n        \"\"\"\n        x0, mu, _ = params\n        \n        delta_ts = T_val / n_values\n        errors = []\n        \n        X_T_exact = x0 * np.exp(mu * T_val)\n        \n        for i, N in enumerate(n_values):\n            X_T_em = x0 * (1 + mu * delta_ts[i])**N\n            errors.append(np.abs(X_T_exact - X_T_em))\n            \n        return delta_ts, np.array(errors)\n\n    results = []\n\n    # Test 1W  1S: GBM weak and strong scaling\n    params_1 = (1.0, 0.2, 0.5)\n    dts_1, s_err_1, w_err_1 = run_stochastic_simulation(params_1, N_VALUES, T, M_PATHS, RNG_SEED)\n    p_w1 = get_scaling_exponent(dts_1, w_err_1)\n    p_s1 = get_scaling_exponent(dts_1, s_err_1)\n    \n    # Test 1W\n    results.append(abs(p_w1 - 1.0) = 0.25)\n    # Test 1S\n    results.append(abs(p_s1 - 0.5) = 0.25)\n    \n    # Test 2W  2S: Deterministic weak and strong scaling\n    params_2 = (1.0, 0.2, 0.0)\n    dts_2, err_2 = run_deterministic_simulation(params_2, N_VALUES, T)\n    p_2 = get_scaling_exponent(dts_2, err_2)\n    \n    # Test 2W\n    results.append(abs(p_2 - 1.0) = 0.25)\n    # Test 2S\n    results.append(abs(p_2 - 1.0) = 0.25)\n    \n    # Test 3: Degenerate GBM\n    params_3 = (0.0, 0.2, 0.5)\n    _, s_err_3, w_err_3 = run_stochastic_simulation(params_3, N_VALUES, T, M_PATHS, RNG_SEED)\n    \n    threshold = 1e-12\n    all_errors_small = np.all(s_err_3  threshold) and np.all(w_err_3  threshold)\n    results.append(all_errors_small)\n    \n    # Format and print final output\n    # Boolean values in Python are \"True\", not \"true\". The problem asks for \"true\", but let's stick to Python standard output.\n    # Re-reading problem spec: \"[True,True,True,True,True]\". The output should be Python's boolean representation.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3190151"}]}