{"hands_on_practices": [{"introduction": "本练习通过一个理想气体混合的经典物理场景，引导我们从统计力学的基本假设——等概率原理——出发，推导出二项分布。这个过程清晰地展示了基本的离散概率分布是如何从一个简单的、理想化的物理系统中自然产生的[@problem_id:1961995]。通过计算在特定区域内找到特定数量粒子的概率，我们可以加深对微观状态和宏观概率之间联系的理解。", "problem": "一个总容积为 $V$ 的刚性绝热容器被一个可移除的隔板分成两个子体积 $V_1$ 和 $V_2$。体积 $V_1$ 中含有 $N_A$ 个理想气体 A 的粒子，而体积 $V_2$ 中含有 $N_B$ 个另一种理想气体 B 的粒子。气体 A 所占的体积分数为 $\\alpha$，使得 $V_1 = \\alpha V$ 且 $V_2 = (1-\\alpha)V$，其中 $0  \\alpha  1$。\n\n最初，两种气体都处于热平衡状态。随后移除隔板，两种气体得以混合，组合系统达到新的热力学平衡状态。基于统计力学的基本假设，推导一个表达式，用于计算在最初为体积 $V_2$ 的空间区域内恰好找到 $n$ 个气体 A 粒子的概率 $P(n)$。变量 $n$ 是一个整数，其取值范围为从 $0$ 到 $N_A$。", "solution": "移除隔板后，组合系统演化至平衡态。根据统计力学的基本假设（等概率先验原理），微正则系综测度在相空间的可及区域上是均匀的。对于一个没有粒子间相互作用并被硬壁限制在体积 $V$ 内的理想气体混合物，其哈密顿量可分离为\n$$\nH=\\sum_{i=1}^{N_{A}} \\frac{|\\mathbf{p}_{i}|^{2}}{2 m_{A}}+\\sum_{j=1}^{N_{B}} \\frac{|\\mathbf{p}'_{j}|^{2}}{2 m_{B}},\n$$\n且所有位置都被限制在 $V$ 内部。因此，在总能量固定的微正则系综中，动量和位置变量是可因子分解的。对于任何只约束空间位置的事件（例如，位于指定子体积内的气体 A 粒子数），其概率由相应的组态空间体积之比给出；动量积分是公共因子并会相消。\n\n令 $V_{1}=\\alpha V$ 和 $V_{2}=(1-\\alpha) V$ 表示原始的子体积。在平衡状态下，每个气体 A 粒子的位置的边缘分布在整个体积 $V$ 上是均匀的。因此，任意一个 A 粒子位于 $V_{2}$ 内的概率是 $V_{2}/V=1-\\alpha$，位于 $V_{1}$ 内的概率是 $V_{1}/V=\\alpha$。因为粒子是无相互作用的，所以对 $N_{A}$ 个位置的联合分布是可因子分解的，并且可以等效地通过计算组态空间体积来计算概率。\n\n将 $P(n)$ 计算为组态空间测度之比。为明确起见，在计数过程中将气体 A 粒子视为可分辨的（不可分辨性吉布斯因子在最终的比率中会相消）。这 $N_{A}$ 个位置的总组态空间体积为 $V^{N_{A}}$。对应于 $N_{A}$ 个 A 粒子中恰好有 $n$ 个位于 $V_2$ 内，而其余 $N_{A}-n$ 个位于 $V_1$ 内的组态空间体积是\n$$\n\\binom{N_{A}}{n} V_{2}^{n} V_{1}^{N_{A}-n},\n$$\n其中二项式系数计算了选择哪 $n$ 个粒子位于 $V_{2}$ 内的方式数量。因此，\n$$\nP(n)=\\frac{\\binom{N_{A}}{n} V_{2}^{n} V_{1}^{N_{A}-n}}{V^{N_{A}}}\n=\\binom{N_{A}}{n} \\left(\\frac{V_{2}}{V}\\right)^{n} \\left(\\frac{V_{1}}{V}\\right)^{N_{A}-n}.\n$$\n代入 $V_{1}=\\alpha V$ 和 $V_{2}=(1-\\alpha) V$ 可得\n$$\nP(n)=\\binom{N_{A}}{n} (1-\\alpha)^{n} \\alpha^{N_{A}-n},\n$$\n此式对所有满足 $0 \\leq n \\leq N_{A}$ 的整数 $n$ 成立。气体 B 的存在只对相空间体积贡献一个乘法因子，该因子在概率比中被消去，因此对于理想混合物，$P(n)$ 与 $N_{B}$ 无关。", "answer": "$$\\boxed{\\binom{N_{A}}{n} (1-\\alpha)^{n} \\alpha^{N_{A}-n}}$$", "id": "1961995"}, {"introduction": "本练习以天体物理学中光子计数的场景为例，探讨了从离散概率模型到连续概率模型的关键过渡。我们将分析在何种条件下，描述稀有事件的离散泊松分布可以用计算上更便捷的连续高斯分布来近似[@problem_id:1896384]。通过确定高斯近似的相对误差小于特定阈值的条件，你将对这类近似方法的适用范围和局限性获得切实的理解。", "problem": "一位天体物理学家正在分析来自空间望远镜的图像。在一段固定的短曝光时间内，望远镜的电荷耦合器件 (CCD) 的单个像素收集到的光子数 $k$ 服从泊松分布 $P(k;\\lambda) = \\frac{\\lambda^k e^{-\\lambda}}{k!}$，其中 $\\lambda$ 是曝光期间期望的光子平均数。\n\n当计划进行 $\\lambda$ 预期值较大的长时间观测时，为了计算上的便利，通常使用均值为 $\\mu = \\lambda$、方差为 $\\sigma^2 = \\lambda$ 的连续高斯（正态）分布来近似离散的泊松分布。检验这种近似有效性的一个常用快速方法是比较最可能事件的概率。对于整数均值 $\\lambda$，最可能探测到的光子数是 $k=\\lambda$。来自连续模型的相应近似值由高斯分布在其峰值 $f(x=\\lambda)$ 处的概率密度导出，其表达式为 $f(\\lambda) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} = \\frac{1}{\\sqrt{2\\pi\\lambda}}$。这个值近似于观测到恰好 $k=\\lambda$ 个光子的概率。\n\n请确定平均光子数 $\\lambda$ 的最小整数值，使得 $P(k=\\lambda; \\lambda)$ 的高斯峰值近似的相对误差小于 1.0%。相对误差定义为 $\\frac{|P_{approx} - P_{exact}|}{P_{exact}}$，其中 $P_{exact} = P(k=\\lambda; \\lambda)$ 且 $P_{approx} = \\frac{1}{\\sqrt{2\\pi\\lambda}}$。", "solution": "我们需要找到最小的整数 $\\lambda$，使得相对误差 $\\frac{|P_{\\text{approx}} - P_{\\text{exact}}|}{P_{\\text{exact}}}  0.01$。\n精确概率为 $P_{\\text{exact}} = \\frac{\\lambda^\\lambda e^{-\\lambda}}{\\lambda!}$。近似值为 $P_{\\text{approx}} = \\frac{1}{\\sqrt{2\\pi\\lambda}}$。\n使用斯特林公式的精确形式 $n! = \\sqrt{2\\pi n} (\\frac{n}{e})^n e^{r_n}$，其中余项 $r_n$ 满足 $\\frac{1}{12n+1}  r_n  \\frac{1}{12n}$。\n代入后可得 $P_{\\text{exact}} = \\frac{1}{\\sqrt{2\\pi\\lambda}} e^{-r_\\lambda}$。\n相对误差为 $|e^{r_\\lambda} - 1|$。\n我们需要 $e^{r_\\lambda} - 1  0.01$，即 $r_\\lambda  \\ln(1.01) \\approx 0.00995$。\n使用 $r_\\lambda$ 的上界 $r_\\lambda  \\frac{1}{12\\lambda}$，我们得到 $\\frac{1}{12\\lambda}  0.00995$，这给出 $\\lambda > \\frac{1}{12 \\times 0.00995} \\approx 8.37$。\n因此，最小的整数 $\\lambda$ 是 9。", "answer": "$$\\boxed{9}$$", "id": "1896384"}, {"introduction": "这个实践练习将理论付诸实践，要求你通过编程来验证中心极限定理的一个关键应用：使用正态分布来近似二项分布。你将实现并对比精确的二项概率与两种正态近似（包含和不包含连续性校正）的结果，从而加深对离散向连续过渡的理解[@problem_id:3119292]。这项练习不仅巩固了理论知识，还锻炼了评估和改进统计模型近似度的实用计算技能。", "problem": "给定独立同分布的伯努利随机变量 $Y_1, Y_2, \\dots, Y_n$，参数为 $p$，即 $Y_i \\in \\{0,1\\}$ 且 $\\mathbb{P}(Y_i = 1) = p$。定义二项计数 $X = \\sum_{i=1}^{n} Y_i$。从核心定义 $\\mathbb{E}[Y_i] = p$、$\\mathrm{Var}(Y_i) = p(1-p)$ 和中心极限定理 (CLT) 出发，用文字推导使用正态分布对累积分布函数 $\\mathbb{P}(X \\leq k)$ 进行连续近似的方法，包括不使用和使用连续性校正两种情况。实现一个程序，对这些近似值与精确的二项累积分布函数进行数值验证。\n\n你的程序必须：\n\n1. 使用二项分布的解析精确方法计算确切的累积概率 $\\mathbb{P}(X \\leq k)$。\n2. 计算 $\\mathbb{P}(X \\leq k)$ 的两种正态近似：\n   - 基于中心极限定理（CLT）且不带连续性校正的直接近似。\n   - 在应用连续模型之前，通过将离散阈值移动到半整数来进行连续性校正的近似。\n3. 使用固定的随机种子和固定次数的蒙特卡洛试验，通过模拟二项计数来经验性地估计 $\\mathbb{P}(X \\leq k)$。使用 $N_{\\text{sim}} = 100000$ 次试验和种子 $12345$ 以确保模拟是可复现的。此模拟仅用于说明；下面的验收检查必须将近似值与精确的解析二项概率进行比较。\n4. 对于每个测试用例，计算两种正态近似相对于精确二项累积概率的绝对误差。设容差为 $\\tau = 0.02$。为每个用例生成三个布尔值：\n   - 未进行连续性校正的误差是否最多为 $\\tau$。\n   - 进行了连续性校正的误差是否最多为 $\\tau$。\n   - 进行了连续性校正的误差是否小于或等于未进行连续性校正的误差。\n\n测试套件：\n使用以下 $(n,p,k)$ 用例来测试一系列情况（大 $n$ 和小 $p$、接近均值的阈值以及边界条件）：\n- 案例 1: $(n=1000,\\; p=0.01,\\; k=0)$。\n- 案例 2: $(n=1000,\\; p=0.01,\\; k=12)$。\n- 案例 3: $(n=10000,\\; p=0.001,\\; k=20)$。\n- 案例 4: $(n=500,\\; p=0.02,\\; k=15)$。\n- 案例 5: $(n=200,\\; p=0.001,\\; k=0)$。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。该列表必须是按测试用例顺序，每个用例三个布尔值的扁平化串联：案例1的 $[$无校正通过, 连续性校正通过, 改进$]$，然后是案例2的相同三元组，依此类推。例如，一个五案例的运行看起来会像\n$[$b$_{1,1}$, b$_{1,2}$, b$_{1,3}$, b$_{2,1}$, b$_{2,2}$, b$_{2,3}$, \\dots, b$_{5,1}$, b$_{5,2}$, b$_{5,3}]$，\n其中每个 $b_{i,j}$ 都是一个布尔值。", "solution": "该问题要求推导二项分布的正态近似（包括使用和不使用连续性校正），并对这些近似值与精确值进行数值验证。推导将从伯努利变量的基本性质和中心极限定理（CLT）开始。\n\n一个二项随机变量 $X$ 表示在 $n$ 次独立试验中成功的总次数，其中每次试验的成功概率为 $p$。它被定义为 $n$ 个独立同分布（i.i.d.）的伯努利随机变量 $Y_1, Y_2, \\dots, Y_n$ 的和。\n$$X = \\sum_{i=1}^{n} Y_i$$\n每个 $Y_i$ 以概率 $p$ 取值 $1$（成功）或以概率 $1-p$ 取值 $0$（失败）。问题给出了单次伯努利试验的期望和方差：\n- 期望: $\\mathbb{E}[Y_i] = 1 \\cdot p + 0 \\cdot (1-p) = p$\n- 方差: $\\mathrm{Var}(Y_i) = \\mathbb{E}[Y_i^2] - (\\mathbb{E}[Y_i])^2 = (1^2 \\cdot p + 0^2 \\cdot (1-p)) - p^2 = p - p^2 = p(1-p)$\n\n由于期望的线性性质以及方差求和时变量的独立性，二项随机变量 $X$ 的期望和方差为：\n- $X$ 的期望: $\\mu = \\mathbb{E}[X] = \\mathbb{E}\\left[\\sum_{i=1}^{n} Y_i\\right] = \\sum_{i=1}^{n} \\mathbb{E}[Y_i] = \\sum_{i=1}^{n} p = np$\n- $X$ 的方差: $\\sigma^2 = \\mathrm{Var}(X) = \\mathrm{Var}\\left(\\sum_{i=1}^{n} Y_i\\right) = \\sum_{i=1}^{n} \\mathrm{Var}(Y_i) = \\sum_{i=1}^{n} p(1-p) = np(1-p)$\n\n中心极限定理（CLT）指出，对于足够大量的独立同分布随机变量，它们的和（或平均值）将近似服从正态分布。将中心极限定理应用于 $X$，我们可以用一个具有相同均值 $\\mu = np$ 和方差 $\\sigma^2 = np(1-p)$ 的正态分布来近似它的分布。设这个近似的正态变量为 $X_{norm} \\sim \\mathcal{N}(np, np(1-p))$。$X$ 的标准化版本是 $Z = \\frac{X - \\mu}{\\sigma} = \\frac{X - np}{\\sqrt{np(1-p)}}$，当 $n \\to \\infty$ 时，它在分布上收敛于标准正态分布 $\\mathcal{N}(0,1)$。\n\n我们希望近似二项分布的累积分布函数（CDF），即 $\\mathbb{P}(X \\leq k) = \\sum_{j=0}^{k} \\mathbb{P}(X=j)$。\n\n**1. 不带连续性校正的正态近似**\n\n这是中心极限定理最直接的应用。我们用连续的正态变量 $X_{norm}$ 来近似离散的二项变量 $X$。概率 $\\mathbb{P}(X \\leq k)$ 由 $\\mathbb{P}(X_{norm} \\leq k)$ 来近似。为了计算这个概率，我们对变量进行标准化：\n$$ \\mathbb{P}(X \\leq k) \\approx \\mathbb{P}(X_{norm} \\leq k) = \\mathbb{P}\\left(\\frac{X_{norm} - \\mu}{\\sigma} \\leq \\frac{k - \\mu}{\\sigma}\\right) = \\mathbb{P}\\left(Z \\leq \\frac{k - np}{\\sqrt{np(1-p)}}\\right) $$\n这个概率由标准正态分布的累积分布函数给出，记为 $\\Phi(z)$。\n$$ \\mathbb{P}(X \\leq k) \\approx \\Phi\\left(\\frac{k - np}{\\sqrt{np(1-p)}}\\right) $$\n\n**2. 带连续性校正的正态近似**\n\n这种方法通过考虑我们正在使用连续分布来建模离散分布这一事实，提供了一种更精确的近似。二项分布的概率质量函数（PMF）仅在整数值上有定义。一个常见的可视化方法是使用直方图，其中概率 $\\mathbb{P}(X=j)$ 由一个以整数 $j$ 为中心、宽度为 $1$ 的条形表示。这个条形覆盖了区间 $[j-0.5, j+0.5]$。\n累积概率 $\\mathbb{P}(X \\leq k)$ 是从 $0$ 到 $k$ 的所有整数的概率之和。在直方图表示中，这对应于 $j=0, 1, \\dots, k$ 的条形的总面积。这些条形覆盖的总区域在连续轴上延伸到 $k+0.5$。\n因此，为了更好地近似这个和，我们将正态概率密度函数积分到 $k+0.5$。\n$$ \\mathbb{P}(X \\leq k) = \\sum_{j=0}^{k} \\mathbb{P}(X=j) \\approx \\mathbb{P}(X_{norm} \\leq k+0.5) $$\n对这个校正后的值进行标准化，得到带连续性校正的近似值：\n$$ \\mathbb{P}(X \\leq k) \\approx \\mathbb{P}\\left(Z \\leq \\frac{(k+0.5) - np}{\\sqrt{np(1-p)}}\\right) = \\Phi\\left(\\frac{k+0.5 - np}{\\sqrt{np(1-p)}}\\right) $$\n这种校正通常能提高正态近似的准确性，特别是当 $n$ 不是特别大或 $p$ 接近 $0$ 或 $1$ 时。\n\n**3. 数值验证**\n\n程序将为每个测试用例 $(n,p,k)$ 实现以下计算：\n- **精确二项CDF**: $\\mathbb{P}(X \\leq k) = \\sum_{j=0}^{k} \\binom{n}{j} p^j (1-p)^{n-j}$，使用 `scipy.stats.binom.cdf` 计算。\n- **正态近似（无CC）**: $\\Phi\\left(\\frac{k - np}{\\sqrt{np(1-p)}}\\right)$，使用 `scipy.stats.norm.cdf` 计算。\n- **正态近似（带CC）**: $\\Phi\\left(\\frac{k+0.5 - np}{\\sqrt{np(1-p)}}\\right)$，使用 `scipy.stats.norm.cdf` 计算。\n- **蒙特卡洛模拟**: 通过从参数为 $n$ 和 $p$ 的二项分布中生成 $N_{\\text{sim}} = 100000$ 个样本，然后计算小于或等于 $k$ 的样本比例，来获得经验估计。这仅用于说明目的。\n- **误差分析**: 计算两种正态近似相对于精确二项CDF的绝对误差。将这些误差与容差 $\\tau = 0.02$ 进行比较，以确定每种近似是否可接受。同时检查连续性校正是否提供了改进（即误差更小或相等）。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import binom, norm\n\ndef solve():\n    \"\"\"\n    Validates normal approximations to the binomial distribution.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (n, p, k)\n        (1000, 0.01, 0),\n        (1000, 0.01, 12),\n        (10000, 0.001, 20),\n        (500, 0.02, 15),\n        (200, 0.001, 0),\n    ]\n\n    # Constants for simulation and validation\n    N_sim = 100000\n    seed = 12345\n    tau = 0.02\n    \n    # Initialize a random number generator for reproducibility\n    rng = np.random.default_rng(seed)\n    \n    results = []\n    for case in test_cases:\n        n, p, k = case\n        \n        # Calculate mean and standard deviation of the binomial distribution\n        mu = n * p\n        sigma_sq = n * p * (1 - p)\n\n        # 1. Compute the exact cumulative probability P(X = k)\n        exact_prob = binom.cdf(k, n, p)\n\n        # 2. Compute normal approximations\n        # Handle the edge case where variance is zero (p=0 or p=1),\n        # though not present in the test suite.\n        if sigma_sq  0:\n            sigma = np.sqrt(sigma_sq)\n            \n            # 2a. Direct approximation without continuity correction\n            z_no_cc = (k - mu) / sigma\n            approx_no_cc = norm.cdf(z_no_cc)\n            \n            # 2b. Approximation with continuity correction\n            z_cc = (k + 0.5 - mu) / sigma\n            approx_cc = norm.cdf(z_cc)\n        else:\n            # If sigma is 0, the distribution is deterministic.\n            # X = mu with probability 1. The CDF is a step function.\n            approx_no_cc = 1.0 if k = mu else 0.0\n            approx_cc = 1.0 if k + 0.5 = mu else 0.0\n        \n        # 3. Simulate binomial counts to estimate P(X = k) empirically (for illustration)\n        # This part is required by the prompt but its result is not used in the final checks.\n        sim_samples = rng.binomial(n, p, size=N_sim)\n        mc_prob = np.mean(sim_samples = k)\n\n        # 4. Compute absolute errors and perform validation checks.\n        # The checks compare the approximations against the exact analytical probability.\n        err_no_cc = abs(approx_no_cc - exact_prob)\n        err_cc = abs(approx_cc - exact_prob)\n        \n        # Boolean check 1: Is error without correction within tolerance?\n        no_cc_pass = err_no_cc = tau\n        \n        # Boolean check 2: Is error with correction within tolerance?\n        cc_pass = err_cc = tau\n        \n        # Boolean check 3: Is continuity correction an improvement?\n        cc_improves = err_cc = err_no_cc\n        \n        results.extend([no_cc_pass, cc_pass, cc_improves])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3119292"}]}