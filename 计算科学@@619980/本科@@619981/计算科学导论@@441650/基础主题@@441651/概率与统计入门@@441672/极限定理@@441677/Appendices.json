{"hands_on_practices": [{"introduction": "理论的生命力在于实践，这些动手练习旨在通过解决具体问题来巩固你对极限定理的理解。在实时控制系统中，决策既要快速又要准确，这是一个根本性的权衡。这个练习 ([@problem_id:3153047]) 运用中心极限定理来寻找传感器读数的最佳数量 $n$，它必须同时满足误差容限和严格的时间期限，这清晰地展示了如何量化不确定性以指导工程设计。", "problem": "一个实时控制器必须在发出致动指令前，通过对 $n$ 个独立同分布的传感器读数进行平均来估计一个恒定信号。每次读数被建模为 $X_{i}=\\theta+\\eta_{i}$，其中 $\\theta$ 是平均窗口内的恒定信号，$\\eta_{i}$ 是均值为 $0$、标准差为 $\\sigma$ 的独立噪声项。控制器使用样本均值 $\\bar{X}_{n}=\\frac{1}{n}\\sum_{i=1}^{n}X_{i}$作为估计值。采集每次读数需要固定的时间 $\\Delta t$，因此传感到致动的延迟等于 $n\\Delta t$。控制器必须遵守一个硬性截止时间 $T_{\\max}$，因此 $n\\Delta t\\leq T_{\\max}$。设计要求是，在致动时刻，绝对估计误差满足 $|\\bar{X}_{n}-\\theta|\\leq \\varepsilon$ 的概率至少为 $p_{0}$，这一要求由大数定律 (LLN) 证明其合理性，并使用中心极限定理 (CLT) 对大 $n$ 的近似进行量化。\n\n给定：\n- 噪声标准差 $\\sigma=0.8$。\n- 容差 $\\varepsilon=0.10$。\n- 目标置信度 $p_{0}=0.95$。\n- 单样本时间 $\\Delta t=2\\times 10^{-3}$ 秒。\n- 最大允许延迟 $T_{\\max}=0.50$ 秒。\n\n从样本均值和方差的定义出发，并调用中心极限定理来近似 $\\bar{X}_{n}$ 的分布，推导出同时满足概率要求和延迟约束的最小整数 $n$。仅报告 $n$ 的整数值。", "solution": "首先验证问题，确保其科学基础扎实、问题良构且所有必要信息均已提供。该问题是中心极限定理 (CLT) 在一个估计问题中的标准应用，用于确定在有延迟约束的情况下所需的样本量。所有参数都已给出并且物理上是一致的。该问题被认定为有效。\n\n求解过程如下。每次传感器读数 $X_i$ 是一个随机变量，由 $X_{i}=\\theta+\\eta_{i}$ 给出，其中 $\\theta$ 是一个恒定信号，$\\eta_{i}$ 是均值为 $E[\\eta_i] = 0$、标准差为 $\\sigma$ 的独立同分布 (i.i.d.) 噪声项。\n\n首先，我们确定单次读数 $X_i$ 的统计特性：\n$X_i$ 的期望值为 $E[X_i] = E[\\theta + \\eta_i] = \\theta + E[\\eta_i] = \\theta + 0 = \\theta$。\n$X_i$ 的方差为 $Var(X_i) = Var(\\theta + \\eta_i) = Var(\\eta_i) = \\sigma^2$。\n\n$\\theta$ 的估计值是 $n$ 次读数的样本均值 $\\bar{X}_{n}=\\frac{1}{n}\\sum_{i=1}^{n}X_{i}$。我们确定这个估计量的统计特性。\n样本均值的期望值为 $E[\\bar{X}_n] = E\\left[\\frac{1}{n}\\sum_{i=1}^{n}X_{i}\\right] = \\frac{1}{n}\\sum_{i=1}^{n}E[X_i] = \\frac{1}{n}(n\\theta) = \\theta$。这证实了样本均值是 $\\theta$ 的一个无偏估计量。\n\n鉴于 $X_i$ 是独立的，样本均值的方差为：\n$$Var(\\bar{X}_n) = Var\\left(\\frac{1}{n}\\sum_{i=1}^{n}X_{i}\\right) = \\frac{1}{n^2}\\sum_{i=1}^{n}Var(X_i) = \\frac{1}{n^2}(n\\sigma^2) = \\frac{\\sigma^2}{n}$$\n因此，样本均值的标准差为 $SD(\\bar{X}_n) = \\sqrt{\\frac{\\sigma^2}{n}} = \\frac{\\sigma}{\\sqrt{n}}$。\n\n根据中心极限定理，对于足够大的样本量 $n$，样本均值 $\\bar{X}_n$ 的分布近似为正态分布，其均值为 $\\theta$，方差为 $\\frac{\\sigma^2}{n}$。我们可以将其写为 $\\bar{X}_n \\sim \\mathcal{N}\\left(\\theta, \\frac{\\sigma^2}{n}\\right)$。\n为了分析概率要求，我们将随机变量 $\\bar{X}_n$ 标准化以获得一个标准正态变量 $Z$：\n$$Z = \\frac{\\bar{X}_n - E[\\bar{X}_n]}{SD(\\bar{X}_n)} = \\frac{\\bar{X}_n - \\theta}{\\sigma/\\sqrt{n}}$$\n变量 $Z$ 近似服从标准正态分布，$Z \\sim \\mathcal{N}(0,1)$。\n\n设计要求是绝对估计误差 $|\\bar{X}_n - \\theta|$ 不超过 $\\varepsilon$ 的概率至少为 $p_0$。这可以表示为：\n$$P(|\\bar{X}_n - \\theta| \\leq \\varepsilon) \\geq p_0$$\n我们可以将概率内的不等式重写为 $-\\varepsilon \\leq \\bar{X}_n - \\theta \\leq \\varepsilon$。将不等式的所有部分除以 $\\bar{X}_n$ 的标准差，得到：\n$$-\\frac{\\varepsilon}{\\sigma/\\sqrt{n}} \\leq \\frac{\\bar{X}_n - \\theta}{\\sigma/\\sqrt{n}} \\leq \\frac{\\varepsilon}{\\sigma/\\sqrt{n}}$$\n这等价于 $-\\frac{\\varepsilon\\sqrt{n}}{\\sigma} \\leq Z \\leq \\frac{\\varepsilon\\sqrt{n}}{\\sigma}$。概率要求变为：\n$$P\\left(-\\frac{\\varepsilon\\sqrt{n}}{\\sigma} \\leq Z \\leq \\frac{\\varepsilon\\sqrt{n}}{\\sigma}\\right) \\geq p_0$$\n设 $\\Phi(z)$ 为标准正态分布的累积分布函数 (CDF)。该概率由 $\\Phi\\left(\\frac{\\varepsilon\\sqrt{n}}{\\sigma}\\right) - \\Phi\\left(-\\frac{\\varepsilon\\sqrt{n}}{\\sigma}\\right)$ 给出。由于正态分布的对称性，$\\Phi(-z) = 1 - \\Phi(z)$，因此概率为 $2\\Phi\\left(\\frac{\\varepsilon\\sqrt{n}}{\\sigma}\\right) - 1$。\n不等式为 $2\\Phi\\left(\\frac{\\varepsilon\\sqrt{n}}{\\sigma}\\right) - 1 \\geq p_0$，可以重新整理为：\n$$\\Phi\\left(\\frac{\\varepsilon\\sqrt{n}}{\\sigma}\\right) \\geq \\frac{1+p_0}{2}$$\n给定 $p_0 = 0.95$，因此我们需要 $\\Phi\\left(\\frac{\\varepsilon\\sqrt{n}}{\\sigma}\\right) \\geq \\frac{1+0.95}{2} = 0.975$。\n设 $z_c$ 为标准正态分布的临界值，使得 $\\Phi(z_c) = 0.975$。通过标准查表可得 $z_c \\approx 1.96$。\n因此，我们需要 $\\frac{\\varepsilon\\sqrt{n}}{\\sigma} \\geq z_c$。解出 $n$：\n$$\\sqrt{n} \\geq \\frac{\\sigma z_c}{\\varepsilon} \\implies n \\geq \\left(\\frac{\\sigma z_c}{\\varepsilon}\\right)^2$$\n代入给定值 $\\sigma=0.8$，$\\varepsilon=0.10$ 和 $z_c \\approx 1.96$：\n$$n \\geq \\left(\\frac{0.8 \\times 1.96}{0.10}\\right)^2 = \\left(\\frac{1.568}{0.10}\\right)^2 = (15.68)^2 = 245.8624$$\n由于 $n$ 必须是整数，满足概率要求的最小样本数是 $n = 246$。\n\n接下来，我们评估延迟约束。总传感时间为 $n\\Delta t$，该时间不得超过截止时间 $T_{\\max}$：\n$$n\\Delta t \\leq T_{\\max}$$\n这对 $n$ 施加了一个上限：\n$$n \\leq \\frac{T_{\\max}}{\\Delta t}$$\n代入给定值 $\\Delta t=2\\times 10^{-3}$ 秒和 $T_{\\max}=0.50$ 秒：\n$$n \\leq \\frac{0.50}{2 \\times 10^{-3}} = \\frac{0.50}{0.002} = 250$$\n所以，$n$ 必须是小于或等于 $250$ 的整数。\n\n我们必须找到同时满足这两个条件的最小整数 $n$：\n1. $n \\geq 246$ (来自概率要求)\n2. $n \\leq 250$ (来自延迟约束)\n\n$n$ 的可能整数值范围是 $[246, 250]$。问题要求的是此范围内的最小整数 $n$。\n因此，$n$ 的最小有效值为 $246$。\n我们来检查这个值：\n对于 $n=246$，延迟为 $246 \\times (2 \\times 10^{-3}) = 0.492$ 秒，小于 $T_{\\max}=0.50$ 秒。\n对于 $n=246$，条件 $n \\geq 245.8624$ 得到满足，符合概率要求。\n对于 $n=245$，概率要求将不被满足。\n因此，最小整数 $n$ 是 $246$。", "answer": "$$\\boxed{246}$$", "id": "3153047"}, {"introduction": "中心极限定理（CLT）功能强大，但它的成立依赖于一些关键假设，例如随机变量具有有限的方差。这个计算练习 ([@problem_id:3153023]) 将通过模拟一个接近临界点的 Galton-Watson 分支过程，深入探究当这些假设不被满足时会发生什么。通过这个实践，你将观察到经典中心极限定理的失效，并对更广泛的稳定分布理论建立初步的直观认识。", "problem": "您将编写一个完整的、可运行的程序，使用蒙特卡洛模拟来探讨临界点附近的 Galton–Watson 分支过程背景下的大数定律 (LLN) 和中心极限定理 (CLT)。考虑一个 Galton–Watson 过程，其中每个个体独立产生的后代数量服从均值为 $m$ 的泊松随机变量分布，且该过程从恰好 $1$ 个祖先开始。令 $T$ 表示总种群规模（直到灭绝为止的所有代际规模之和，包括初始祖先）。请在纯数学术语下进行操作：没有物理单位。所有角度（如有）都必须以弧度处理，但此处不需要角度。\n\n基本基础和定义：\n- Galton–Watson 过程由每个个体的独立同分布后代计数定义，其均值为 $m$，概率生成函数为 $f(s)$。\n- 大数定律指出，对于具有有限均值的独立同分布随机变量，其经验平均值收敛于均值。\n- 中心极限定理指出，对于具有有限非零方差的独立同分布随机变量，其标准化和在分布上收敛于标准正态分布。\n- 稳定律（也称为 $\\alpha$-稳定分布）是当适当的归一化可能不同于中心极限定理的 $\\sqrt{n}$ 缩放时，独立同分布随机变量之和的极限定律，通常在矩为无穷大时出现。\n\n您的任务是：\n1. 实现一个模拟器，通过模拟 Galton–Watson 过程直至灭绝，为给定的 $m$ 生成 $T$ 的样本。利用独立泊松随机变量之和仍为泊松分布的性质，从一个参数等于当前代际规模乘以 $m$ 的泊松分布中模拟下一代的规模。重复此过程直到种群数量变为 $0$。\n2. 使用此模拟器测试亚临界情况 $m=0.9$ 下的 LLN 和 CLT 行为，并展示临界点附近 $m=1.0$ 时的非高斯缩放，此时总种群规模表现出重尾行为，并使经典的 $\\sqrt{n}$ 缩放失效。\n3. 对于亚临界泊松情况 $m1$，您可以依赖已知事实，即总规模 $T$ 具有有限的均值和方差；您必须计算理论均值和方差以用于标准化。对于临界情况 $m=1$，您不应在任何标准化中使用不存在的有限矩。\n\n测试套件和要求的输出：\n您的程序必须执行以下四个测试用例，并输出一行包含四个布尔值的列表，顺序如下所述。\n\n- 测试用例 $1$（$m=0.9$ 时的 CLT 标准化）：\n  - 参数：$m=0.9$，块大小 $n=400$，块数量 $B=400$。\n  - 构建 $B$ 个独立的块和，每个块和是 $n$ 个独立 $T$ 副本的和。\n  - 使用亚临界泊松情况下 $T$ 的正确有限均值 $\\mu$ 和方差 $\\sigma^2$，形成标准化块和 $Z_j = \\dfrac{S_j - n\\mu}{\\sqrt{n\\sigma^2}}$，其中 $S_j$ 是第 $j$ 个块和。\n  - 计算 $B$ 个标准化块和的经验均值 $\\overline{Z}$ 和经验方差 $s_Z^2$。\n  - 如果 $|\\overline{Z}| \\le 0.15$ 和 $|s_Z^2 - 1| \\le 0.2$ 都成立，则输出布尔值 $\\mathrm{result}_1$ 为 true，否则为 false。\n\n- 测试用例 $2$（$m=0.9$ 时的 CLT 缩放一致性）：\n  - 参数：$m=0.9$，块大小 $n_1=200$ 和 $n_2=800$，每个 $n$ 有 $B=300$ 个块。\n  - 对于每个 $n \\in \\{n_1,n_2\\}$，计算 $B$ 个块和，并令 $s_n$ 为块和的经验标准差除以 $\\sqrt{n}$。\n  - 如果两个估计值在 $10\\%$ 内一致，即 $\\left| s_{n_1} - s_{n_2} \\right| \\le 0.1 \\times s_{n_1}$，则输出布尔值 $\\mathrm{result}_2$ 为 true，否则为 false。\n\n- 测试用例 $3$（$m=1.0$ 时的非高斯缩放增长）：\n  - 参数：$m=1.0$，块大小 $n_1=200$ 和 $n_2=600$，每个 $n$ 有 $B=200$ 个块。\n  - 对于每个 $n \\in \\{n_1,n_2\\}$，计算 $B$ 个块和，并定义 $g_n$ 为块和的经验标准差除以 $\\sqrt{n}$。\n  - 如果 $g_{n_2} > 1.5 \\times g_{n_1}$，则输出布尔值 $\\mathrm{result}_3$ 为 true，这表明增长与经典的 $\\sqrt{n}$ 缩放不一致，否则为 false。\n\n- 测试用例 $4$（$m=1.0$ 时的极端集中诊断）：\n  - 参数：$m=1.0$，独立爆发次数 $K=15000$，顶部比例 $q=0.01$。\n  - 生成 $K$ 个独立样本 $T_1,\\dots,T_K$。令 $S=\\sum_{i=1}^K T_i$，并令 $S_{\\mathrm{top}}$ 为 $\\{T_i\\}$ 中最大的 $\\lceil qK \\rceil$ 个值的和。\n  - 如果集中份额 $C = S_{\\mathrm{top}} / S \\ge 0.5$，则输出布尔值 $\\mathrm{result}_4$ 为 true，否则为 false。\n\n实现要求：\n- 使用等于 $42$ 的固定随机种子以确保可复现性。\n- 您的程序应精确打印一行，其中包含按 $[\\mathrm{result}_1,\\mathrm{result}_2,\\mathrm{result}_3,\\mathrm{result}_4]$ 顺序排列的、用方括号括起来的四个布尔值的逗号分隔列表。\n- 不允许用户输入或使用外部文件。\n\n禁止提供提示。您不得包含任何直接解决此问题陈述中核心推导的公式或中间结果。上述科学设定对于分支过程和极限定理是现实且标准的。请确保您的实现使用指定的参数作为内置测试套件，并以要求的单行格式生成可量化的布尔输出。", "solution": "该问题是有效的。它在科学上植根于随机过程理论，特别是 Galton-Watson 分支过程，及其与概率论中基本极限定理的联系。问题陈述清晰，为唯一的计算解提供了所有必要的参数和定义。语言客观，任务可通过模拟进行验证。\n\n目标是使用蒙特卡洛模拟来探究 Galton-Watson 过程的总种群规模 $T$ 的大数定律 (LLN) 和中心极限定理 (CLT)。我们将对比亚临界过程（$m=0.9$，经典极限定理适用）与临界过程（$m=1.0$，经典极限定理不适用，导致稳定律典型的非高斯缩放）的行为。\n\n该过程从单个祖先 $Z_0=1$ 开始。第 $k$ 代大小为 $Z_k$ 的每个个体独立产生的后代数量服从均值为 $m$ 的泊松分布。下一代的大小 $Z_{k+1}$ 是所有 $Z_k$ 个体后代的总和。由于泊松分布的可加性，$Z_{k+1}$ 服从均值为 $m \\cdot Z_k$ 的泊松分布。该过程一直持续到种群灭绝，即对于某个 $k$，$Z_k=0$。总种群规模为 $T = \\sum_{k=0}^{\\infty} Z_k$。\n\n在后代平均数 $m1$ 的亚临界情况下，该过程保证会灭绝。总种群规模 $T$ 是一个具有有限均值 $\\mu$ 和有限方差 $\\sigma^2$ 的随机变量。对于泊松后代分布，这些值由以下公式给出：\n$$ \\mu = E[T] = \\frac{1}{1-m} $$\n$$ \\sigma^2 = \\mathrm{Var}(T) = \\frac{m}{(1-m)^3} $$\n对于 $m=0.9$，我们有 $\\mu = \\frac{1}{1-0.9} = 10$ 和 $\\sigma^2 = \\frac{0.9}{(1-0.9)^3} = 900$。因为这些矩是有限的，所以大量 $n$ 个独立同分布 (i.i.d.) 的 $T$ 的副本之和将遵循经典的 LLN 和 CLT。\n\n在临界情况 $m=1$ 下，该过程也保证会灭绝，但预期灭绝时间是无限的。总种群规模 $T$ 的分布是重尾的，特别是具有幂律尾部，因此其均值 $E[T]$ 是无限的。因此，其方差也是无限的。需要有限均值和方差的经典 LLN 和 CLT 在此不适用。此类随机变量的和由不同的极限定理支配，通常涉及 $\\alpha$-稳定分布和不同于经典 $\\sqrt{n}$ 的缩放因子。\n\n实现了一个模拟函数来生成 $T$ 的单个样本。该函数将总种群和当前代际规模初始化为 $1$。然后进入一个循环，在每一步中，它通过从参数为 $\\lambda = m \\times (\\text{当前代际规模})$ 的泊松分布中抽样来计算下一代的规模。循环一直持续到代际规模变为零，此时返回累积的总种群。\n\n这四个测试用例旨在探究这些理论性质：\n\n测试用例 1 验证了亚临界情况（$m=0.9$）下的 CLT。我们构建了 $B=400$ 个块和 $S_j = \\sum_{i=1}^{n} T_i$，块大小为 $n=400$。然后我们将这些和标准化为 $Z_j = \\frac{S_j - n\\mu}{\\sqrt{n\\sigma^2}}$。根据 CLT， $Z_j$ 的分布应近似于标准正态分布 $\\mathcal{N}(0, 1)$。我们通过计算样本 $\\{Z_j\\}$ 的经验均值 $\\overline{Z}$ 和方差 $s_Z^2$ 并检查它们是否分别接近 $0$ 和 $1$ 来进行测试。\n\n测试用例 2 进一步检验了亚临界情况（$m=0.9$）下的缩放性质。CLT 意味着块和 $S_n$ 的标准差为 $\\mathrm{StdDev}(S_n) = \\sigma \\sqrt{n}$。因此，定义为块和的经验标准差除以 $\\sqrt{n}$ 的量 $s_n$ 应该提供一个与块大小 $n$ 无关的 $\\sigma$ 的一致估计。我们通过比较两个不同块大小 $n_1=200$ 和 $n_2=800$ 的估计值 $s_{n_1}$ 和 $s_{n_2}$ 来验证这一点。\n\n测试用例 3 展示了在临界点（$m=1.0$）经典 CLT 缩放的失效。由于 $T$ 的方差是无限的，和 $S_n$ 的标准差的缩放不再与 $\\sqrt{n}$ 成正比。我们为两个不同的块大小 $n_1=200$ 和 $n_2=600$ 计算量 $g_n = \\mathrm{StdDev}(S_n) / \\sqrt{n}$。如果经典缩放成立，$g_{n_1}$ 和 $g_{n_2}$ 将是可比的。测试期望 $g_{n_2}$ 显著大于 $g_{n_1}$，这表明标准化偏差随 $n$ 增长，这是吸引到一个指数 $\\alpha  2$ 的稳定律的标志。\n\n测试用例 4 为临界点（$m=1.0$）时 $T$ 的重尾性质提供了直接诊断。重尾分布的一个关键特征是，许多独立同分布样本的和通常由少数几个极大的值主导。我们生成 $K=15000$ 个 $T$ 的样本，并计算总和中由前 $q=1\\%$ 的样本贡献的比例。测试检查该比例是否超过 $50\\%$，这是极端值集中的一个强有力指标。\n\n该程序使用 Python 的 `numpy` 库实现，用于数值计算和随机数生成。使用固定的随机种子来确保蒙特卡洛模拟结果的可复现性。辅助函数封装了模拟 $T$ 和生成块和的逻辑，提高了代码结构和可读性。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\n\ndef solve():\n    \"\"\"\n    Runs a series of Monte Carlo simulations to test limit theorems\n    for Galton-Watson branching processes.\n    \"\"\"\n    SEED = 42\n    rng = np.random.default_rng(SEED)\n\n    def simulate_T(m, rng_instance):\n        \"\"\"\n        Simulates one instance of a Galton-Watson process and returns the total size T.\n        Offspring distribution is Poisson(m). Process starts with 1 ancestor.\n        \"\"\"\n        total_pop = 1\n        current_gen_size = 1\n        while current_gen_size > 0:\n            # The sum of N Poisson(m) is Poisson(N*m)\n            lam = m * current_gen_size\n            next_gen_size = rng_instance.poisson(lam=lam)\n            total_pop += next_gen_size\n            current_gen_size = next_gen_size\n        return total_pop\n\n    def get_block_sums(m, n, B, rng_instance):\n        \"\"\"\n        Generates B block sums, where each block is the sum of n samples of T.\n        \"\"\"\n        block_sums_arr = np.zeros(B)\n        for j in range(B):\n            s_j = 0\n            for _ in range(n):\n                s_j += simulate_T(m, rng_instance)\n            block_sums_arr[j] = s_j\n        return block_sums_arr\n\n    results = []\n\n    # Test case 1: CLT standardization at m=0.9\n    m1 = 0.9\n    n1 = 400\n    B1 = 400\n    # Theoretical mean and variance for subcritical GW process with Poisson offspring\n    mu1 = 1 / (1 - m1)\n    sigma2_1 = m1 / (1 - m1)**3\n    \n    block_sums1 = get_block_sums(m1, n1, B1, rng)\n    Z = (block_sums1 - n1 * mu1) / np.sqrt(n1 * sigma2_1)\n    \n    Z_mean = np.mean(Z)\n    Z_var = np.var(Z, ddof=1) # Sample variance\n    \n    result1 = abs(Z_mean) = 0.15 and abs(Z_var - 1) = 0.2\n    results.append(result1)\n\n    # Test case 2: CLT scaling consistency at m=0.9\n    m2 = 0.9\n    n2_1, n2_2 = 200, 800\n    B2 = 300\n    \n    block_sums2_1 = get_block_sums(m2, n2_1, B2, rng)\n    std_dev_s1 = np.std(block_sums2_1, ddof=1)\n    s_n1 = std_dev_s1 / np.sqrt(n2_1)\n    \n    block_sums2_2 = get_block_sums(m2, n2_2, B2, rng)\n    std_dev_s2 = np.std(block_sums2_2, ddof=1)\n    s_n2 = std_dev_s2 / np.sqrt(n2_2)\n\n    result2 = abs(s_n1 - s_n2) = 0.1 * s_n1\n    results.append(result2)\n\n    # Test case 3: non-Gaussian scaling growth at m=1.0\n    m3 = 1.0\n    n3_1, n3_2 = 200, 600\n    B3 = 200\n\n    block_sums3_1 = get_block_sums(m3, n3_1, B3, rng)\n    std_dev_g1 = np.std(block_sums3_1, ddof=1)\n    g_n1 = std_dev_g1 / np.sqrt(n3_1)\n\n    block_sums3_2 = get_block_sums(m3, n3_2, B3, rng)\n    std_dev_g2 = np.std(block_sums3_2, ddof=1)\n    g_n2 = std_dev_g2 / np.sqrt(n3_2)\n    \n    result3 = g_n2 > 1.5 * g_n1\n    results.append(result3)\n\n    # Test case 4: extreme-concentration diagnostic at m=1.0\n    m4 = 1.0\n    K4 = 15000\n    q4 = 0.01\n\n    T_samples = np.array([simulate_T(m4, rng) for _ in range(K4)])\n    \n    S_total = np.sum(T_samples)\n    num_top = math.ceil(q4 * K4)\n    \n    T_samples.sort()\n    S_top = np.sum(T_samples[-int(num_top):])\n    \n    C = S_top / S_total if S_total > 0 else 0\n    \n    result4 = C >= 0.5\n    results.append(result4)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, [r.item() for r in results]))}]\")\n\nsolve()\n```", "id": "3153023"}, {"introduction": "极限定理不仅是用于事后分析的工具，更是设计前瞻性智能算法的强大基石。这个练习 ([@problem_id:3153099]) 将让你扮演一名图形工程师，去优化一个蒙特卡洛渲染器。你将利用基于中心极限定理的误差模型，推导出一个最优策略，将固定的计算预算（总样本数）自适应地分配给不同像素以最小化图像噪声，这完美地诠释了理论如何直接指导实践中的优化问题。", "problem": "考虑一个计算成像任务，其中每个像素对应一个随机亮度变量，其样本是独立同分布的。对于像素索引 $i \\in \\{1,\\dots,P\\}$，设亮度样本是实值随机变量 $L_i$ 的独立抽取，其均值 $\\mu_i$ 未知，方差 $\\sigma_i^2$ 有限。每个像素亮度的蒙特卡洛估计是根据 $n_i$ 个样本计算出的样本均值 $\\bar{L}_{i,n_i}$。假设一个初始的引导性渲染（pilot pass）为每个像素提供了 $n_{0,i}$ 个样本，并从这些引导性样本中得到了 $\\sigma_i^2$ 的一个无偏方差估计 $s_i^2$。同时，我们用于最终渲染过程的总样本预算为 $N_{\\text{total}}$，使得 $\\sum_{i=1}^P n_i = N_{\\text{total}}$ 且对所有 $i$ 都有 $n_i \\ge n_{0,i}$。\n\n仅使用大数定律 (LLN) 和中心极限定理 (CLT) 作为概率基础，设计一个整数样本数 $\\{n_i\\}_{i=1}^P$ 的分配规则，在给定置信水平 $1-\\alpha$ 以及约束条件 $\\sum_{i=1}^P n_i = N_{\\text{total}}$ 和 $n_i \\ge n_{0,i}$ 下，最小化所有像素中预测的双侧置信区间半宽度的最大值。具体来说：\n\n- 根据中心极限定理，对于较大的 $n_i$，$\\bar{L}_{i,n_i}$ 的分布可以近似为均值为 $\\mu_i$、方差为 $\\sigma_i^2/n_i$ 的正态分布。因此，$\\mu_i$ 的双侧 $(1-\\alpha)$ 置信区间半宽度约等于 $z_{1-\\alpha/2}\\sqrt{\\sigma_i^2/n_i}$，其中 $z_{1-\\alpha/2}$ 是标准正态分布的 $(1-\\alpha/2)$ 分位数。\n- 使用 $s_i^2$ 作为 $\\sigma_i^2$ 的代入估计值，并且只使用仅由 LLN 和 CLT 证明的算法决策（例如，像素间的可分离性、凸性论证以及边际方差缩减相对于 $n_i$ 的单调性都是可以使用的推论）。\n\n你的程序必须：\n1. 从第一性原理出发，推导如何选择整数 $\\{n_i\\}$，以在满足约束条件 $\\sum_{i=1}^P n_i = N_{\\text{total}}$ 和 $n_i \\ge n_{0,i}$ 的情况下，最小化所有像素中预测的半宽度的最大值。\n2. 使用推导出的分配方案 $\\{n_i\\}$，计算预测的最大半宽度值\n   $$H_{\\max} \\equiv \\max_{1 \\le i \\le P} \\left( z_{1-\\alpha/2}\\sqrt{\\frac{s_i^2}{n_i}} \\right),$$\n3. 为实现整数可行性，如果推导出的最优分配方案包含非整数值，需将其转换为整数，同时保持约束条件，并确保任何单一样本的重新分配都不会使目标恶化。你的方法必须基于一个有原则的、由基于 CLT 的目标所证明的边际改进论证。\n\n输入通过固定的测试套件嵌入在代码中。对于每个测试用例 $t$，你会得到：每个像素的方差估计值 $(s_1^2,\\dots,s_P^2)$、引导性样本数 $(n_{0,1},\\dots,n_{0,P})$、总预算 $N_{\\text{total}}$ 和显著性水平 $\\alpha$。你的程序必须为每个测试用例输出标量 $H_{\\max}$，并四舍五入到六位小数。\n\n测试套件（五个用例）：\n- 用例 A: $P=1$, $(s_1^2) = (4.0)$, $(n_{0,1}) = (0)$, $N_{\\text{total}} = 100$, $\\alpha = 0.05$。\n- 用例 B: $P=2$, $(s_1^2,s_2^2) = (1.0,1.0)$, $(n_{0,1},n_{0,2}) = (0,0)$, $N_{\\text{total}} = 100$, $\\alpha = 0.05$。\n- 用例 C: $P=2$, $(s_1^2,s_2^2) = (4.0,1.0)$, $(n_{0,1},n_{0,2}) = (0,0)$, $N_{\\text{total}} = 100$, $\\alpha = 0.05$。\n- 用例 D: $P=3$, $(s_1^2,s_2^2,s_3^2) = (4.0,1.0,0.25)$, $(n_{0,1},n_{0,2},n_{0,3}) = (5,5,5)$, $N_{\\text{total}} = 30$, $\\alpha = 0.10$。\n- 用例 E: $P=3$, $(s_1^2,s_2^2,s_3^2) = (0.0,2.25,0.25)$, $(n_{0,1},n_{0,2},n_{0,3}) = (2,2,2)$, $N_{\\text{total}} = 12$, $\\alpha = 0.01$。\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含一个逗号分隔的 Python 风格的浮点数列表，按 A 到 E 的用例顺序排列，每个数字都四舍五入到六位小数并用方括号括起来。例如，一个有效的输出行格式为 $[\\text{A},\\text{B},\\text{C},\\text{D},\\text{E}]$，其中每个符号代表该用例的四舍五入值。", "solution": "该问题要求找到一个整数样本分配方案 $\\{n_i\\}_{i=1}^P$，用于在一组 $P$ 个像素上最小化预测的置信区间半宽度的最大值，同时受限于总样本预算 $N_{\\text{total}}$ 和每个像素的最小样本数 $\\{n_{0,i}\\}$。这是一个基于中心极限定理 (CLT) 和大数定律 (LLN) 的极小化极大（minimax）优化问题。\n\n### 步骤 1：优化问题的构建\n\n问题是确定整数样本数 $n_1, n_2, \\dots, n_P$ 以解决以下问题：\n$$\n\\begin{aligned}\n \\underset{\\{n_i\\}}{\\text{最小化}}   \\max_{1 \\le i \\le P} H_i \\\\\n \\text{约束条件}   \\sum_{i=1}^P n_i = N_{\\text{total}} \\\\\n   n_i \\ge n_{0,i} \\quad \\text{对所有 } i \\in \\{1, \\dots, P\\} \\\\\n   n_i \\in \\mathbb{Z}^+\n\\end{aligned}\n$$\n其中 $H_i$ 是像素 $i$ 的置信区间半宽度。对于大的 $n_i$，CLT 提供了以下近似：\n$$H_i = z_{1-\\alpha/2}\\sqrt{\\frac{\\sigma_i^2}{n_i}}$$\n我们使用引导性渲染过程得到的无偏方差估计 $s_i^2$ 作为真实未知方差 $\\sigma_i^2$ 的代入估计量，这一替代由 LLN 证明是合理的。因此，目标函数变为：\n$$\\text{最小化} \\max_{1 \\le i \\le P} \\left( z_{1-\\alpha/2}\\sqrt{\\frac{s_i^2}{n_i}} \\right)$$\n由于对于给定的置信水平 $1-\\alpha$，$z_{1-\\alpha/2}$ 是一个正常数，最小化最大半宽度等价于最小化项 $\\sqrt{s_i^2/n_i}$ 的最大值，这又等价于最小化：\n$$\\max_{1 \\le i \\le P} \\left( \\frac{s_i^2}{n_i} \\right)$$\n这个项 $s_i^2/n_i$ 代表样本均值 $\\bar{L}_{i,n_i}$ 的估计方差。\n\n### 步骤 2：实数值 $n_i$ 的最优分配策略\n\n解决这种形式的极小化极大问题的核心原则是使被最大化的各项相等。为了最小化 $\\max_i(E_i)$，其中 $E_i = s_i^2/n_i$ 是资源 $n_i$ 的递减函数，当所有非零误差项相等时，可以达到最优解：\n$$\\frac{s_1^2}{n_1} = \\frac{s_2^2}{n_2} = \\dots = \\frac{s_P^2}{n_P} = C$$\n对于某个常数 $C$（适用于所有 $s_i^2 > 0$ 的像素）。这给出了最优（实数值）分配的关系：\n$$n_i = \\frac{s_i^2}{C}$$\n这表明最优样本数 $n_i$ 与方差 $s_i^2$ 成正比。我们可以使用总预算约束 $\\sum n_i = N_{\\text{total}}$ 来找到比例常数：\n$$\\sum_{i=1}^P \\frac{s_i^2}{C} = N_{\\text{total}} \\implies \\frac{1}{C} \\sum_{i=1}^P s_j^2 = N_{\\text{total}} \\implies \\frac{1}{C} = \\frac{N_{\\text{total}}}{\\sum_{j=1}^P s_j^2}$$\n将其代回，我们得到理想的实数值分配（暂时忽略 $n_i \\ge n_{0,i}$ 约束）：\n$$n_i^* = N_{\\text{total}} \\frac{s_i^2}{\\sum_{j=1}^P s_j^2}$$\n\n### 步骤 3：纳入最小样本约束\n\n必须纳入约束条件 $n_i \\ge n_{0,i}$。分配方案 $n_i^*$ 可能会对某些像素违反此约束。如果对于像素 $i$ 有 $n_i^*  n_{0,i}$，我们必须为其分配至少 $n_{0,i}$ 个样本。对于这样的像素，我们将其样本数“锁定”在 $n_i = n_{0,i}$。然后，剩余的预算将根据相同原则在其余“活动”像素中进行最优重新分配。这引出了一个迭代算法：\n1. 初始化活动像素集 $A = \\{1, \\dots, P\\}$ 和预算 $N = N_{\\text{total}}$。\n2. 在一个循环中，为所有 $i \\in A$ 计算理想分配 $n_i^{\\text{ideal}} = N \\frac{s_i^2}{\\sum_{j \\in A} s_j^2}$。\n3. 识别出 $n_i^{\\text{ideal}}  n_{0,i}$ 的像素集合 $V \\subseteq A$。\n4. 如果 $V$ 为空，则当前对 $i \\in A$ 的分配 $n_i^{\\text{ideal}}$ 是最优的，并且满足所有最小值要求。最终的实数值分配方案已经找到。\n5. 如果 $V$ 不为空，则对每个 $i \\in V$，将其分配固定为 $n_i = n_{0,i}$。将这些像素从 $A$ 中移除，并将预算 $N$ 减少 $\\sum_{i \\in V} n_{0,i}$。使用较小的活动集和减少后的预算重复此循环。\n\n这个迭代过程产生一个满足所有约束的实数值分配方案 $\\{n_i^{\\text{real}}\\}$。\n\n### 步骤 4：整数样本分配\n\n推导出的实数值分配方案 $\\{n_i^{\\text{real}}\\}$ 必须转换为总和为 $N_{\\text{total}}$ 的整数分配方案 $\\{n_i\\}$。一种与最小化最大误差目标一致的有原则的方法如下：\n1. 通过对实数解取整来初始化整数分配：$n_i' = \\lfloor n_i^{\\text{real}} \\rfloor$。由于 $n_i^{\\text{real}} \\ge n_{0,i}$ 且 $n_{0,i}$ 是整数，此操作满足 $n_i' \\ge n_{0,i}$。\n2. 计算待分配的剩余样本数：$R = N_{\\text{total}} - \\sum_{i=1}^P n_i'$。\n3. 将这 $R$ 个样本逐一分配。在 $R$ 个步骤中的每一步，将一个样本添加给当前具有最大误差项 $s_i^2/n_i'$ 的像素。这是一种贪婪方法，在每一步都直接针对极小化极大目标。如果某个 $s_i^2>0$ 的像素的 $n_i'=0$，其误差为无穷大，确保它会首先获得样本。\n\n### 步骤 5：最终计算\n\n一旦确定了最终的整数分配方案 $\\{n_i\\}$，就可以通过找到所有像素中的最大误差项，并乘以相应的正态分位数来计算最大半宽度：\n$$ H_{\\max} = \\max_{1 \\le i \\le P} \\left( z_{1-\\alpha/2}\\sqrt{\\frac{s_i^2}{n_i}} \\right) = z_{1-\\alpha/2} \\sqrt{\\max_{1 \\le i \\le P} \\left(\\frac{s_i^2}{n_i}\\right)} $$\n其中 $z_{1-\\alpha/2}$ 是标准正态分布的 $(1-\\alpha/2)$ 分位数，可以使用 `scipy.stats.norm.ppf(1 - \\alpha/2)` 找到。如果一个 $s_i^2>0$ 的像素的样本数 $n_i$ 为零，其半宽度将被视为无穷大；但是，如果 $N_{\\text{total}}$ 足够，分配算法会防止这种情况发生。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Main solver function to process all test cases and print the results.\n    \"\"\"\n    # Test suite (five cases): P, s^2, n_0, N_total, alpha\n    test_cases = [\n        # Case A: P=1, (s_1^2)=(4.0), (n_0,1)=(0), N_total=100, alpha=0.05\n        (1, np.array([4.0]), np.array([0]), 100, 0.05),\n        # Case B: P=2, (s_1^2,s_2^2)=(1.0,1.0), (n_0,1,n_0,2)=(0,0), N_total=100, alpha=0.05\n        (2, np.array([1.0, 1.0]), np.array([0, 0]), 100, 0.05),\n        # Case C: P=2, (s_1^2,s_2^2)=(4.0,1.0), (n_0,1,n_0,2)=(0,0), N_total=100, alpha=0.05\n        (2, np.array([4.0, 1.0]), np.array([0, 0]), 100, 0.05),\n        # Case D: P=3, (s_1^2,s_2^2,s_3^2)=(4.0,1.0,0.25), (n_0,...)=(5,5,5), N_total=30, alpha=0.10\n        (3, np.array([4.0, 1.0, 0.25]), np.array([5, 5, 5]), 30, 0.10),\n        # Case E: P=3, (s_1^2,s_2^2,s_3^2)=(0.0,2.25,0.25), (n_0,...)=(2,2,2), N_total=12, alpha=0.01\n        (3, np.array([0.0, 2.25, 0.25]), np.array([2, 2, 2]), 12, 0.01),\n    ]\n\n    results = []\n    for P, s2_vals, n0_vals, N_total, alpha in test_cases:\n        result = _calculate_max_half_width(P, s2_vals, n0_vals, N_total, alpha)\n        results.append(result)\n\n    # Format the final output string\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef _calculate_max_half_width(P, s2_vals, n0_vals, N_total, alpha):\n    \"\"\"\n    Calculates the maximum confidence interval half-width for a single test case.\n    \"\"\"\n    \n    # --- Step 1: Real-valued allocation with constraints ---\n    n_real = np.zeros(P)\n    active_indices = list(range(P))\n    budget = float(N_total)\n    \n    # Iteratively lock pixels that don't meet their minimum sample count n_0\n    for _ in range(P + 1):  # Loop guard to prevent infinite loops\n        if not active_indices:\n            break\n            \n        sum_s2_active = sum(s2_vals[i] for i in active_indices)\n        \n        # If all remaining active pixels have zero variance, their allocation is minimal.\n        if sum_s2_active == 0:\n            for i in active_indices:\n                n_real[i] = n0_vals[i]\n                budget -= n_real[i]\n            # Remaining budget for zero-variance pixels can be distributed arbitrarily.\n            # To be deterministic, we add it to the first such pixel.\n            if len(active_indices) > 0 and budget > 0:\n                n_real[active_indices[0]] += budget\n            break\n\n        n_ideal = {i: budget * s2_vals[i] / sum_s2_active for i in active_indices}\n        \n        violators = {i for i in active_indices if n_ideal[i]  n0_vals[i]}\n\n        if not violators:\n            for i in active_indices:\n                n_real[i] = n_ideal[i]\n            break\n        \n        newly_locked_indices = []\n        for i in violators:\n            n_real[i] = float(n0_vals[i])\n            budget -= n_real[i]\n            newly_locked_indices.append(i)\n        \n        active_indices = [i for i in active_indices if i not in newly_locked_indices]\n        \n    # --- Step 2: Convert real allocation to integer allocation ---\n    n_alloc = np.floor(n_real).astype(int)\n    \n    # Distribute remainder samples using a greedy approach\n    remainder_samples = N_total - np.sum(n_alloc)\n    \n    for _ in range(remainder_samples):\n        errors = np.zeros(P)\n        for i in range(P):\n            if s2_vals[i] > 0:\n                if n_alloc[i] == 0:\n                    errors[i] = np.inf\n                else:\n                    errors[i] = s2_vals[i] / n_alloc[i]\n            else:\n                errors[i] = -np.inf # Ensure zero-variance pixels are never chosen\n\n        # Find pixel with max error to give the next sample\n        idx_to_increment = np.argmax(errors)\n        n_alloc[idx_to_increment] += 1\n        \n    # --- Step 3: Calculate the maximum half-width ---\n    z_val = norm.ppf(1 - alpha / 2.0)\n    \n    max_error_term = 0.0\n    for i in range(P):\n        # A pixel with no samples and non-zero variance would have infinite error,\n        # but the algorithm ensures this doesn't happen if N_total is sufficient.\n        if n_alloc[i] > 0:\n            error_term = s2_vals[i] / n_alloc[i]\n            if error_term > max_error_term:\n                max_error_term = error_term\n    \n    h_max = z_val * np.sqrt(max_error_term)\n    return h_max\n\nsolve()\n```", "id": "3153099"}]}