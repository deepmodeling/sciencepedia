{"hands_on_practices": [{"introduction": "理论与实践的结合是计算科学的基石。这个练习旨在通过一个经典的组合概率问题——随机排列中的不动点——来巩固这一思想。你将首先从期望和方差的基本定义出发，使用指示变量来推导不动点数量的精确矩，然后通过编写蒙特卡洛模拟来凭经验验证你的理论结果[@problem_id:3126339]。这个过程不仅能加深你对矩的理解，还能让你亲身体验理论预测与计算实验之间是如何相互印证的。", "problem": "给定一个由均匀随机排列中不动点数量定义的随机变量族。设 $n$ 是一个正整数，并考虑集合 $\\{1,2,\\dots,n\\}$ 的一个均匀随机排列。定义随机变量 $F$ 为该排列中的不动点数量，即索引 $i \\in \\{1,2,\\dots,n\\}$ 中使得排列将 $i$ 映射到自身的数量。本题要求您从期望、方差和矩的核心定义出发进行推理，并将其与估算这些量的计算模拟联系起来。\n\n您的任务是：\n- 从期望和方差的基本定义出发，推导 $F$ 的一阶矩和二阶矩关于 $n$ 的精确表达式。不要使用快捷公式。使用不动点的指示变量和排列的均匀性来证明每一步。\n- 定义整数 $k \\geq 1$ 的下降阶乘 $(F)_k = F(F-1)\\cdots(F-k+1)$，并用阶乘矩 $E[(F)_j]$ 和组合系数表示 $k \\in \\{1,2,3,4\\}$ 的原点矩 $E[F^k]$。在不使用高阶极限定理的情况下，推导有限 $n$ 的三阶中心矩 $\\mu_3 = E[(F - E[F])^3]$ 和四阶中心矩 $\\mu_4 = E[(F - E[F])^4]$。\n- 编写一个完整的、可运行的程序，对每个指定的测试用例，模拟 $M$ 次独立试验，每次试验都是 $\\{1,\\dots,n\\}$ 的一个均匀随机排列，计算每次试验中的不动点数 $F$，并生成均值、方差、三阶中心矩和四阶中心矩的经验估计值。将这些经验估计值与您推导出的精确的、有限 $n$ 的理论值进行比较。\n\n在推导中，请使用以下定义作为基础：\n- 期望：$E[X] = \\sum_{x} x \\, \\mathbb{P}(X=x)$。\n- 方差：$\\mathrm{Var}(X) = E[X^2] - (E[X])^2$。\n- 期望的线性性：$E[X+Y] = E[X] + E[Y]$。\n- 协方差：$\\mathrm{Cov}(X,Y) = E[XY] - E[X]E[Y]$。\n- 下降阶乘矩：$(X)_k = X(X-1)\\cdots(X-k+1)$，对于整数 $k \\geq 1$。\n\n程序要求：\n- 对于每个测试用例，输出三个布尔值检查：\n  1. 经验均值 $\\hat{\\mu}$ 与精确均值之差在固定容差 $\\tau_\\mu$ 内。\n  2. 经验方差 $\\hat{v}$ 与精确方差之差在固定容差 $\\tau_v$ 内。\n  3. 两个经验高阶中心矩都接近其精确值：$|\\hat{\\mu}_3 - \\mu_3| \\le \\tau_3$ 且 $|\\hat{\\mu}_4 - \\mu_4| \\le \\tau_4$。\n\n模拟细节：\n- 每次试验必须生成一个 $\\{1,\\dots,n\\}$ 的均匀随机排列，并通过比较位置直接计算不动点数 $F$。\n- 使用固定的随机种子以确保可复现性。\n\n测试套件：\n- 使用以下五个参数集 $(n,M)$：\n  1. $(n,M) = (1,5000)$\n  2. $(n,M) = (2,5000)$\n  3. $(n,M) = (20,20000)$\n  4. $(n,M) = (100,15000)$\n  5. $(n,M) = (200,10000)$\n- 使用固定的容差：\n  - 均值容差：$\\tau_\\mu = 0.02$\n  - 方差容差：$\\tau_v = 0.05$\n  - 三阶中心矩容差：$\\tau_3 = 0.15$\n  - 四阶中心矩容差：$\\tau_4 = 0.30$\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。该列表必须包含对应于五个测试用例的 $15$ 个布尔值，每个测试用例按顺序贡献三个布尔值：均值检查、方差检查、高阶矩检查。例如，格式必须是 $[b_1,b_2,b_3,b_4,\\dots,b_{15}]$，其中每个 $b_i$ 均为 $True$ 或 $False$。", "solution": "该问题在数学上是良定义的且内部一致，允许进行严格的推导和计算验证。我们着手进行求解。\n\n设 $S_n$ 是 $\\{1, 2, \\dots, n\\}$ 的所有排列的集合。从 $S_n$ 中均匀随机地选择一个排列 $\\pi$，对于任何 $\\pi \\in S_n$，有 $\\mathbb{P}(\\pi) = 1/n!$。随机变量 $F$ 表示不动点的数量，即满足 $\\pi(i) = i$ 的索引 $i$ 的数量。我们可以将 $F$ 表示为指示随机变量的和：\n$$F = \\sum_{i=1}^{n} X_i$$\n其中 $X_i = \\mathbb{I}(\\pi(i)=i)$ 是一个指示变量，如果 $i$ 是一个不动点，则为 $1$，否则为 $0$。\n\n**F 的一阶矩（期望）**\n\n$F$ 的期望是使用期望的线性性推导出来的。\n$$E[F] = E\\left[\\sum_{i=1}^{n} X_i\\right] = \\sum_{i=1}^{n} E[X_i]$$\n指示变量的期望是它所指示事件的概率。因此，我们需要计算 $\\mathbb{P}(\\pi(i)=i)$。\n$$E[X_i] = \\mathbb{P}(X_i = 1) = \\mathbb{P}(\\pi(i)=i)$$\n为了计算这个概率，我们计算 $i$ 是一个不动点的排列数量。如果 $\\pi(i)=i$，剩下的 $n-1$ 个元素可以在剩下的 $n-1$ 个位置上以 $(n-1)!$ 种方式排列。总排列数为 $n!$。因此，\n$$\\mathbb{P}(\\pi(i)=i) = \\frac{(n-1)!}{n!} = \\frac{1}{n}$$\n这个概率对于所有 $i \\in \\{1, 2, \\dots, n\\}$ 都是相同的。将此代回 $E[F]$ 的表达式中：\n$$E[F] = \\sum_{i=1}^{n} \\frac{1}{n} = n \\cdot \\frac{1}{n} = 1$$\n这个结果对任何整数 $n \\ge 1$ 都成立。\n\n**F 的二阶矩和方差**\n\n$F$ 的方差定义为 $\\mathrm{Var}(F) = E[F^2] - (E[F])^2$。我们已经求出 $E[F]=1$，所以需要计算二阶原点矩 $E[F^2]$。\n$$F^2 = \\left(\\sum_{i=1}^{n} X_i\\right)^2 = \\sum_{i=1}^{n} X_i^2 + \\sum_{i=1}^{n}\\sum_{j=1, j\\neq i}^{n} X_i X_j$$\n根据期望的线性性：\n$$E[F^2] = E\\left[\\sum_{i=1}^{n} X_i^2\\right] + E\\left[\\sum_{i \\neq j} X_i X_j\\right] = \\sum_{i=1}^{n} E[X_i^2] + \\sum_{i \\neq j} E[X_i X_j]$$\n对于指示变量，$X_i^2 = X_i$ 因为 $X_i$ 只取值 $0$ 或 $1$。因此，$E[X_i^2] = E[X_i] = 1/n$。第一个和是：\n$$\\sum_{i=1}^{n} E[X_i^2] = \\sum_{i=1}^{n} \\frac{1}{n} = n \\cdot \\frac{1}{n} = 1$$\n接下来，我们考虑对于任何不同索引对 $i \\neq j$ 的项 $E[X_i X_j]$。乘积 $X_i X_j$ 是 $i$ 和 $j$ 都是不动点这一事件的指示变量。\n$$E[X_i X_j] = \\mathbb{P}(X_i=1 \\text{ and } X_j=1) = \\mathbb{P}(\\pi(i)=i \\text{ and } \\pi(j)=j)$$\n$i$ 和 $j$ 都是不动点的排列数量是排列剩下 $n-2$ 个元素的方式数，即 $(n-2)!$。此推导假设 $n \\ge 2$。\n$$\\mathbb{P}(\\pi(i)=i \\text{ and } \\pi(j)=j) = \\frac{(n-2)!}{n!} = \\frac{1}{n(n-1)}$$\n满足 $i \\neq j$ 的有序对 $(i,j)$ 的数量是 $n(n-1)$。第二个和是：\n$$\\sum_{i \\neq j} E[X_i X_j] = n(n-1) \\cdot \\frac{1}{n(n-1)} = 1$$\n这对 $n \\ge 2$ 有效。对于 $n=1$，对 $i \\neq j$ 的求和是空的，等于 $0$。\n结合这些项：\n- 对于 $n=1$：$E[F^2] = \\sum_{i=1}^1 E[X_1^2] = E[X_1] = 1/1 = 1$。\n- 对于 $n \\ge 2$：$E[F^2] = 1 + 1 = 2$。\n\n现在我们可以计算方差：\n- 对于 $n=1$：$\\mathrm{Var}(F) = E[F^2] - (E[F])^2 = 1 - 1^2 = 0$。这是意料之中的，因为对于 $n=1$，$F$ 是一个常数（$F=1$）。\n- 对于 $n \\ge 2$：$\\mathrm{Var}(F) = E[F^2] - (E[F])^2 = 2 - 1^2 = 1$。\n\n**F 的高阶矩**\n\n为了推导高阶矩，首先计算阶乘矩 $E[(F)_k]$ 会很方便，其中 $(F)_k = F(F-1)\\cdots(F-k+1)$。第 $k$ 阶乘矩计算的是不同不动点的有序 $k$ 元组的期望数量。\n$$(F)_k = \\sum_{i_1 \\neq i_2 \\neq \\dots \\neq i_k} X_{i_1} X_{i_2} \\cdots X_{i_k}$$\n其中求和遍及所有不同索引的有序 $k$ 元组。根据期望的线性性：\n$$E[(F)_k] = \\sum_{i_1 \\neq i_2 \\neq \\dots \\neq i_k} E[X_{i_1} X_{i_2} \\cdots X_{i_k}]$$\n项 $E[X_{i_1} \\cdots X_{i_k}]$ 是 $i_1, \\dots, i_k$ 都是不动点的概率。这要求 $k \\le n$。如果 $k > n$，这个概率是 $0$。\n对于 $k \\le n$，固定 $k$ 个指定元素的排列数为 $(n-k)!$。\n$$\\mathbb{P}(\\pi(i_1)=i_1, \\dots, \\pi(i_k)=i_k) = \\frac{(n-k)!}{n!} = \\frac{1}{(n)_k}$$\n不同索引的有序 $k$ 元组的数量是 $(n)_k = n(n-1)\\cdots(n-k+1)$。\n因此，对于 $1 \\le k \\le n$：\n$$E[(F)_k] = (n)_k \\cdot \\frac{1}{(n)_k} = 1$$\n如果 $k > n$，不可能有 $k$ 个不动点，所以 $(F)_k$ 总是 $0$，且 $E[(F)_k] = 0$。\n\n原点矩 $E[F^k]$ 可以用第二类斯特林数（表示为 $S(k,j)$ 或 $\\{{k \\atop j}\\}$）来表示阶乘矩。\n$$F^k = \\sum_{j=0}^{k} S(k,j) (F)_j$$\n对两边取期望：\n$$E[F^k] = \\sum_{j=0}^{k} S(k,j) E[(F)_j]$$\n根据定义 $E[(F)_0]=1$，并且当 $1 \\le j \\le n$ 时 $E[(F)_j]=1$，当 $j>n$ 时 $E[(F)_j]=0$：\n$$E[F^k] = S(k,0) + \\sum_{j=1}^{\\min(k,n)} S(k,j)$$\n由于当 $k \\ge 1$ 时 $S(k,0)=0$，我们有 $E[F^k] = \\sum_{j=1}^{\\min(k,n)} S(k,j)$。\n所需的斯特林数是：\n- $S(1,1)=1$\n- $S(2,1)=1, S(2,2)=1$\n- $S(3,1)=1, S(3,2)=3, S(3,3)=1$\n- $S(4,1)=1, S(4,2)=7, S(4,3)=6, S(4,4)=1$\n\n使用这些，我们可以为不同的 $n$ 列出原点矩的表格：\n- 对于 $n=1$：\n  $E[F] = S(1,1) = 1$\n  $E[F^2] = S(2,1) = 1$\n  $E[F^3] = S(3,1) = 1$\n  $E[F^4] = S(4,1) = 1$\n- 对于 $n=2$：\n  $E[F] = S(1,1) = 1$\n  $E[F^2] = S(2,1)+S(2,2) = 1+1=2$\n  $E[F^3] = S(3,1)+S(3,2) = 1+3=4$\n  $E[F^4] = S(4,1)+S(4,2) = 1+7=8$\n- 对于 $n=3$：\n  $E[F^3] = S(3,1)+S(3,2)+S(3,3) = 1+3+1=5$\n  $E[F^4] = S(4,1)+S(4,2)+S(4,3) = 1+7+6=14$\n- 对于 $n \\ge 4$：\n  $E[F^3] = 1+3+1=5$\n  $E[F^4] = 1+7+6+1=15$\n\n中心矩 $\\mu_k=E[(F-E[F])^k]=E[(F-1)^k]$ 是从原点矩推导出来的：\n$\\mu_3 = E[(F-1)^3] = E[F^3] - 3E[F^2] + 3E[F] - 1$\n$\\mu_4 = E[(F-1)^4] = E[F^4] - 4E[F^3] + 6E[F^2] - 4E[F] + 1$\n\n**用于模拟的理论矩总结**\n\n| $n$ | $E[F]=\\mu$ | $\\mathrm{Var}(F)=\\mu_2$ | $\\mu_3$ | $\\mu_4$ |\n|:---:|:----------:|:-----------------------:|:-------:|:-------:|\n| 1   | $1$        | $0$                     | $0$     | $0$     |\n| 2   | $1$        | $1$                     | $0$     | $1$     |\n| 3   | $1$        | $1$                     | $1$     | $3$     |\n| $\\ge 4$ | $1$    | $1$                     | $1$     | $4$     |\n\n对于指定的测试用例 $(n=1, 2, 20, 100, 200)$，理论矩为：\n- $n=1$: $(\\mu, \\mu_2, \\mu_3, \\mu_4) = (1, 0, 0, 0)$\n- $n=2$: $(\\mu, \\mu_2, \\mu_3, \\mu_4) = (1, 1, 0, 1)$\n- $n=20$: $(\\mu, \\mu_2, \\mu_3, \\mu_4) = (1, 1, 1, 4)$\n- $n=100$: $(\\mu, \\mu_2, \\mu_3, \\mu_4) = (1, 1, 1, 4)$\n- $n=200$: $(\\mu, \\mu_2, \\mu_3, \\mu_4) = (1, 1, 1, 4)$\n\n这些理论值将与计算模拟得出的经验估计值进行比较。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\n\ndef get_theoretical_moments(n):\n    \"\"\"\n    Computes the exact theoretical moments for the number of fixed points F\n    in a random permutation of n elements.\n\n    Returns:\n        A tuple (mu, mu2, mu3, mu4) containing the mean, variance,\n        3rd central moment, and 4th central moment.\n    \"\"\"\n    if not isinstance(n, int) or n  1:\n        raise ValueError(\"n must be a positive integer.\")\n\n    mu = 1.0\n\n    if n == 1:\n        # F is deterministically 1. All central moments are 0.\n        mu2 = 0.0\n        mu3 = 0.0\n        mu4 = 0.0\n    elif n == 2:\n        # F is 0 or 2 with probability 1/2 each. E[F]=1.\n        # Var(F) = E[(F-1)^2] = (0-1)^2 * 0.5 + (2-1)^2 * 0.5 = 1.\n        # mu3 = E[(F-1)^3] = (-1)^3 * 0.5 + (1)^3 * 0.5 = 0.\n        # mu4 = E[(F-1)^4] = (-1)^4 * 0.5 + (1)^4 * 0.5 = 1.\n        mu2 = 1.0\n        mu3 = 0.0\n        mu4 = 1.0\n    elif n == 3:\n        # E[F]=1, E[F^2]=2, E[F^3]=5, E[F^4]=14.\n        mu2 = 2.0 - 1.0**2  # Var = E[F^2] - E[F]^2\n        mu3 = 5.0 - 3 * 2.0 + 3 * 1.0 - 1.0\n        mu4 = 14.0 - 4 * 5.0 + 6 * 2.0 - 4 * 1.0 + 1.0\n    else: # n >= 4\n        # E[F]=1, E[F^2]=2, E[F^3]=5, E[F^4]=15.\n        mu2 = 2.0 - 1.0**2\n        mu3 = 5.0 - 3 * 2.0 + 3 * 1.0 - 1.0\n        mu4 = 15.0 - 4 * 5.0 + 6 * 2.0 - 4 * 1.0 + 1.0\n    \n    return mu, mu2, mu3, mu4\n\ndef solve():\n    \"\"\"\n    Runs simulations to estimate moments of the number of fixed points\n    in random permutations and compares them to theoretical values.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1, 5000),\n        (2, 5000),\n        (20, 20000),\n        (100, 15000),\n        (200, 10000)\n    ]\n\n    # Define the tolerances from the problem statement.\n    tau_mu = 0.02\n    tau_v = 0.05\n    tau_3 = 0.15\n    tau_4 = 0.30\n    \n    # Use a fixed random seed for reproducibility.\n    seed = 42\n    rng = np.random.default_rng(seed)\n\n    results = []\n    \n    for n, M in test_cases:\n        # Get exact theoretical values for the current n.\n        th_mu, th_mu2, th_mu3, th_mu4 = get_theoretical_moments(n)\n        \n        # Run M trials to collect samples of F.\n        fixed_points_samples = np.zeros(M, dtype=int)\n        indices = np.arange(n)\n        for i in range(M):\n            # Generate a uniformly random permutation.\n            perm = rng.permutation(n)\n            # Count the number of fixed points.\n            fixed_points = np.sum(perm == indices)\n            fixed_points_samples[i] = fixed_points\n            \n        # Calculate empirical estimates of the moments.\n        emp_mu = np.mean(fixed_points_samples)\n        \n        # Note: np.var computes E[(X-E[X])^2] using the sample mean, which is correct\n        # for estimating the variance as a central moment.\n        # ddof=0 (default) uses 1/M, not 1/(M-1).\n        emp_mu2 = np.var(fixed_points_samples)\n        \n        # scipy.stats.moment calculates sample central moments.\n        emp_mu3 = stats.moment(fixed_points_samples, moment=3)\n        emp_mu4 = stats.moment(fixed_points_samples, moment=4)\n        \n        # Perform the three boolean checks.\n        mean_check = abs(emp_mu - th_mu) = tau_mu\n        var_check = abs(emp_mu2 - th_mu2) = tau_v\n        \n        higher_moments_check = (abs(emp_mu3 - th_mu3) = tau_3 and\n                                abs(emp_mu4 - th_mu4) = tau_4)\n        \n        results.extend([mean_check, var_check, higher_moments_check])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3126339"}, {"introduction": "在许多真实世界的模型中，随机性表现为多层次结构。为了理解这种系统的总变异，我们需要一个强大的工具：全方差公式。本练习通过一个分层蒙特卡洛模拟，让你直观地探索和验证全方差公式[@problem_id:3126385]。你将模拟一个变量 $X$，其分布依赖于另一个随机变量 $Y$，并经验性地证明 $X$ 的总方差可以被精确地分解为两部分：给定 $Y$ 时 $X$ 的方差的期望，加上给定 $Y$ 时 $X$ 的期望的方差。", "problem": "你需要实现一个完整的、可运行的程序，该程序使用分层蒙特卡洛（MC, Monte Carlo）模拟来探索由两层生成过程定义的随机变量的方差分解。该模型由条件分布和先验分布指定：对于一个潜变量 $Y$ 和一个观测变量 $X$，条件分布为 $X \\mid Y \\sim \\mathcal{N}(Y, 1)$，先验分布为 $Y \\sim \\mathrm{Uniform}(0,1)$。你的程序必须使用期望和方差的第一性原理，计算 $E[X]$、$\\mathrm{Var}(X)$ 以及分解量 $E[\\mathrm{Var}(X \\mid Y)] + \\mathrm{Var}(E[X \\mid Y])$ 的数值近似值，计算过程仅依赖于模拟样本上的经验期望和经验方差的定义。\n\n实现以下分层蒙特卡洛近似的步骤：\n- 从 $\\mathrm{Uniform}(0,1)$ 中抽取 $N_{\\text{outer}}$ 个独立样本 $Y_i$。\n- 对于每个 $i$，从 $\\mathcal{N}(Y_i, 1)$ 中抽取 $N_{\\text{inner}}$ 个独立样本 $X_{i,j}$。\n- 将经验均值定义为\n$$\n\\widehat{m} \\;=\\; \\frac{1}{N_{\\text{outer}} N_{\\text{inner}}} \\sum_{i=1}^{N_{\\text{outer}}} \\sum_{j=1}^{N_{\\text{inner}}} X_{i,j}.\n$$\n- 将所有 $X_{i,j}$ 的经验（总体）方差定义为\n$$\n\\widehat{v} \\;=\\; \\frac{1}{N_{\\text{outer}} N_{\\text{inner}}} \\sum_{i=1}^{N_{\\text{outer}}} \\sum_{j=1}^{N_{\\text{inner}}} \\left(X_{i,j} - \\widehat{m}\\right)^2.\n$$\n- 对于每个 $i$，定义组均值\n$$\n\\widehat{m}_i \\;=\\; \\frac{1}{N_{\\text{inner}}} \\sum_{j=1}^{N_{\\text{inner}}} X_{i,j},\n$$\n和组（总体）方差\n$$\n\\widehat{v}_i \\;=\\; \\frac{1}{N_{\\text{inner}}} \\sum_{j=1}^{N_{\\text{inner}}} \\left(X_{i,j} - \\widehat{m}_i\\right)^2.\n$$\n- 将分层分量定义为\n$$\n\\widehat{E[\\mathrm{Var}(X \\mid Y)]} \\;=\\; \\frac{1}{N_{\\text{outer}}} \\sum_{i=1}^{N_{\\text{outer}}} \\widehat{v}_i,\n\\qquad\n\\widehat{\\mathrm{Var}(E[X \\mid Y])} \\;=\\; \\frac{1}{N_{\\text{outer}}} \\sum_{i=1}^{N_{\\text{outer}}} \\left(\\widehat{m}_i - \\widehat{m}\\right)^2.\n$$\n使用这些定义，其中分母等于项数（即总体二阶中心矩），对于任何有限的 $N_{\\text{outer}}$ 和 $N_{\\text{inner}}$，精确的经验恒等式\n$$\n\\widehat{v} \\;=\\; \\widehat{E[\\mathrm{Var}(X \\mid Y)]} \\;+\\; \\widehat{\\mathrm{Var}(E[X \\mid Y])}\n$$\n在数值舍入误差范围内成立。\n\n你的任务：\n1. 完全按照上述描述实现分层蒙特卡洛模拟，为保证可复现性，使用固定的随机种子 $s = 123456789$。\n2. 对于每个指定的测试用例 $(N_{\\text{outer}}, N_{\\text{inner}})$，按顺序计算四个量：\n   - 经验均值 $\\widehat{m}$，\n   - 经验方差 $\\widehat{v}$，\n   - 和 $\\widehat{E[\\mathrm{Var}(X \\mid Y)]} + \\widehat{\\mathrm{Var}(E[X \\mid Y])}$，\n   - 绝对差 $\\left|\\widehat{v} - \\left(\\widehat{E[\\mathrm{Var}(X \\mid Y)]} + \\widehat{\\mathrm{Var}(E[X \\mid Y])}\\right)\\right|$。\n3. 使用以下参数对 $(N_{\\text{outer}}, N_{\\text{inner}})$ 的测试套件：\n   - 用例 $1$：$(50000, 5)$，\n   - 用例 $2$：$(5, 50000)$，\n   - 用例 $3$：$(10000, 100)$，\n   - 用例 $4$：$(2, 2)$。\n\n最终输出格式：\n- 你的程序应生成一行输出，其中包含一个用方括号括起来的、逗号分隔的列表。\n- 该列表必须按顺序包含用例 $1$ 的四个结果，接着是用例 $2$ 的四个结果，接着是用例 $3$ 的四个结果，最后是用例 $4$ 的四个结果。即，扁平化列表\n$$\n[\\widehat{m}_1, \\widehat{v}_1, \\widehat{t}_1, \\widehat{d}_1, \\widehat{m}_2, \\widehat{v}_2, \\widehat{t}_2, \\widehat{d}_2, \\widehat{m}_3, \\widehat{v}_3, \\widehat{t}_3, \\widehat{d}_3, \\widehat{m}_4, \\widehat{v}_4, \\widehat{t}_4, \\widehat{d}_4],\n$$\n其中，$\\widehat{t}_k = \\widehat{E[\\mathrm{Var}(X \\mid Y)]} + \\widehat{\\mathrm{Var}(E[X \\mid Y])}$ 且 $\\widehat{d}_k = \\left|\\widehat{v}_k - \\widehat{t}_k\\right|$ 是用例 $k \\in \\{1,2,3,4\\}$ 的结果。每个条目必须是一个实数。", "solution": "用户提供的问题是计算科学和统计学中一个有效的练习。它具有科学依据，问题定义明确，客观且完整。它要求实现一个分层蒙特卡洛模拟，以数值方式验证一个特定生成模型的全方差定律。该问题是合理的，我将提供一个完整的解决方案。\n\n问题的核心是一个分层模型，其中随机变量 $X$ 依赖于潜变量 $Y$。分布给定如下：\n1.  潜变量的先验分布：$Y \\sim \\mathrm{Uniform}(0, 1)$\n2.  观测变量的条件分布：$X \\mid Y \\sim \\mathcal{N}(Y, 1)$，一个均值为 $Y$、方差为 $1$ 的正态分布。\n\n主要目标是计算期望 $E[X]$、方差 $\\mathrm{Var}(X)$ 的数值估计，并验证全方差定律，其表述如下：\n$$\n\\mathrm{Var}(X) = E[\\mathrm{Var}(X \\mid Y)] + \\mathrm{Var}(E[X \\mid Y])\n$$\n我们可以首先确定这些量的理论值。\n\n**理论分析**\n\n1.  **$X$ 的期望**：根据全期望定律，$E[X] = E[E[X \\mid Y]]$。\n    条件期望 $E[X \\mid Y]$ 是正态分布 $\\mathcal{N}(Y, 1)$ 的均值，即为 $Y$。\n    因此，$E[X] = E[Y]$。由于 $Y$ 从 $\\mathrm{Uniform}(0, 1)$ 分布中抽取，其期望为 $E[Y] = \\frac{0+1}{2} = \\frac{1}{2}$。\n    因此，$X$ 的理论期望是 $E[X] = 0.5$。\n\n2.  **$X$ 的方差**：根据全方差定律，我们计算它的两个分量。\n    *   **内部方差项**：$E[\\mathrm{Var}(X \\mid Y)]$。\n        条件方差 $\\mathrm{Var}(X \\mid Y)$ 是正态分布 $\\mathcal{N}(Y, 1)$ 的方差，它是一个常数 $1$，与 $Y$ 的值无关。\n        因此，这个常数的期望是 $E[\\mathrm{Var}(X \\mid Y)] = E[1] = 1$。\n    *   **外部方差项**：$\\mathrm{Var}(E[X \\mid Y])$。\n        我们已经确定 $E[X \\mid Y] = Y$。所以，该项变为 $\\mathrm{Var}(Y)$。\n        对于一个 $\\mathrm{Uniform}(a, b)$ 分布，其方差为 $\\frac{(b-a)^2}{12}$。对于 $Y \\sim \\mathrm{Uniform}(0, 1)$，其方差为 $\\mathrm{Var}(Y) = \\frac{(1-0)^2}{12} = \\frac{1}{12}$。\n    *   **总方差**：将这两个分量相加，得到 $X$ 的总方差：\n        $$\n        \\mathrm{Var}(X) = 1 + \\frac{1}{12} = \\frac{13}{12} \\approx 1.08333...\n        $$\n\n**分层蒙特卡洛模拟**\n\n模拟过程通过从指定分布中生成大量样本来近似这些理论量。模型两层结构反映在模拟设计中：\n\n1.  **外层循环**：从 $Y \\sim \\mathrm{Uniform}(0, 1)$ 中抽取 $N_{\\text{outer}}$ 个独立的潜变量样本 $Y_1, Y_2, \\ldots, Y_{N_{\\text{outer}}}$。\n2.  **内层循环**：对于每个样本值 $Y_i$，从条件分布 $X \\mid Y=Y_i \\sim \\mathcal{N}(Y_i, 1)$ 中抽取一组 $N_{\\text{inner}}$ 个独立的观测变量样本 $X_{i,1}, X_{i,2}, \\ldots, X_{i,N_{\\text{inner}}}$。\n\n这个过程总共产生 $N_{\\text{outer}} \\times N_{\\text{inner}}$ 个 $X$ 的样本。我们从这个数据集中计算感兴趣的量的经验估计值。\n\n**经验估计量**\n\n问题为估计量提供了明确的公式，这些估计量被定义为总体矩（即使用分母 $N$，而不是 $N-1$）。\n\n*   总体经验均值 $\\widehat{m}$ 估计 $E[X]$：\n    $$\n    \\widehat{m} = \\frac{1}{N_{\\text{outer}} N_{\\text{inner}}} \\sum_{i=1}^{N_{\\text{outer}}} \\sum_{j=1}^{N_{\\text{inner}}} X_{i,j}\n    $$\n*   总体经验方差 $\\widehat{v}$ 估计 $\\mathrm{Var}(X)$：\n    $$\n    \\widehat{v} = \\frac{1}{N_{\\text{outer}} N_{\\text{inner}}} \\sum_{i=1}^{N_{\\text{outer}}} \\sum_{j=1}^{N_{\\text{inner}}} (X_{i,j} - \\widehat{m})^2\n    $$\n*   为了估计总方差的分量，我们首先计算每个组 $i$ 的统计量：\n    *   组均值：$\\widehat{m}_i = \\frac{1}{N_{\\text{inner}}} \\sum_{j=1}^{N_{\\text{inner}}} X_{i,j}$，它估计 $E[X \\mid Y=Y_i]$。\n    *   组方差：$\\widehat{v}_i = \\frac{1}{N_{\\text{inner}}} \\sum_{j=1}^{N_{\\text{inner}}} (X_{i,j} - \\widehat{m}_i)^2$，它估计 $\\mathrm{Var}(X \\mid Y=Y_i)$。\n*   然后通过对这 $N_{\\text{outer}}$ 个样本的组统计量进行平均来估计全方差定律中的各项：\n    *   $E[\\mathrm{Var}(X \\mid Y)]$ 的估计：$\\widehat{E[\\mathrm{Var}(X \\mid Y)]} = \\frac{1}{N_{\\text{outer}}} \\sum_{i=1}^{N_{\\text{outer}}} \\widehat{v}_i$\n    *   $\\mathrm{Var}(E[X \\mid Y))]$ 的估计：$\\widehat{\\mathrm{Var}(E[X \\mid Y])} = \\frac{1}{N_{\\text{outer}}} \\sum_{i=1}^{N_{\\text{outer}}} (\\widehat{m}_i - \\widehat{m})^2$\n    注意，组均值的均值 $\\frac{1}{N_{\\text{outer}}} \\sum_{i=1}^{N_{\\text{outer}}} \\widehat{m}_i$ 在代数上等价于总体均值 $\\widehat{m}$。\n\n**经验恒等式**\n\n该问题的一个关键特征是，由于经验估计量被特别定义为总体方差，全方差定律对于有限样本作为一个*精确的代数恒等式*成立，而不仅仅是一个渐近极限。我们可以通过分解总平方和来证明这一点：\n$$\n\\sum_{i,j} (X_{i,j} - \\widehat{m})^2 = \\sum_{i,j} (X_{i,j} - \\widehat{m}_i + \\widehat{m}_i - \\widehat{m})^2\n$$\n展开平方项并注意到交叉项 $\\sum_{i,j} 2(X_{i,j} - \\widehat{m}_i)(\\widehat{m}_i - \\widehat{m})$ 为零，因为对于每个 $i$ 都有 $\\sum_{j} (X_{i,j} - \\widehat{m}_i) = 0$，我们得到：\n$$\n\\sum_{i,j} (X_{i,j} - \\widehat{m})^2 = \\sum_{i,j} (X_{i,j} - \\widehat{m}_i)^2 + \\sum_{i,j} (\\widehat{m}_i - \\widehat{m})^2\n$$\n$$\n\\sum_{i,j} (X_{i,j} - \\widehat{m})^2 = \\sum_i \\left( N_{\\text{inner}} \\widehat{v}_i \\right) + \\sum_i \\left( N_{\\text{inner}} (\\widehat{m}_i - \\widehat{m})^2 \\right)\n$$\n除以总样本数 $N_{\\text{outer}}N_{\\text{inner}}$，得到恒等式：\n$$\n\\widehat{v} = \\frac{1}{N_{\\text{outer}}} \\sum_i \\widehat{v}_i + \\frac{1}{N_{\\text{outer}}} \\sum_i (\\widehat{m}_i - \\widehat{m})^2 = \\widehat{E[\\mathrm{Var}(X \\mid Y)]} + \\widehat{\\mathrm{Var}(E[X \\mid Y])}\n$$\n因此，计算出的绝对差 $\\left|\\widehat{v} - \\left(\\widehat{E[\\mathrm{Var}(X \\mid Y)]} + \\widehat{\\mathrm{Var}(E[X \\mid Y])}\\right)\\right|$ 应该为零，仅受浮点精度限制的影响。\n\n**实现细节**\n\n实现使用 `numpy` 库进行高效的向量化运算。\n1.  为了可复现性，使用指定的种子 $s=123456789$ 初始化一个随机数生成器。\n2.  对于每个测试用例 $(N_{\\text{outer}}, N_{\\text{inner}})$，使用 `rng.uniform` 生成一个 $Y_i$ 样本数组。\n3.  相应的 $X_{i,j}$ 样本使用 `rng.normal` 生成。`numpy` 的广播功能允许我们将 $Y_i$值的数组作为均值提供，从而通过一次高效的调用创建 `(N_outer, N_inner)` 形状的 $X$ 样本数组。\n4.  估计量 $\\widehat{m}$、$\\widehat{v}$、$\\widehat{m}_i$ 和 $\\widehat{v}_i$ 使用 `numpy.mean` 和 `numpy.var` 计算。`axis=1` 参数对于跨 $X$ 样本矩阵的行计算组统计量至关重要。`numpy.var` 默认计算总体方差（分母为 $N$），这与问题的定义完全一致。\n5.  每个测试用例的最终量——经验均值 $\\widehat{m}$、经验方差 $\\widehat{v}$、其分解分量的和 $\\widehat{t}$ 以及它们的绝对差 $\\widehat{d}$——被计算并存储。\n\n对所有指定的测试用例重复此过程，并将结果汇总到一个列表中以供输出。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport scipy  # Imported to adhere to the specified environment, but not used.\n\ndef solve():\n    \"\"\"\n    Implements a hierarchical Monte Carlo simulation to verify the law of total variance.\n    \"\"\"\n    # Use a fixed random seed for reproducibility.\n    s = 123456789\n    rng = np.random.default_rng(s)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (50000, 5),     # Case 1\n        (5, 50000),     # Case 2\n        (10000, 100),   # Case 3\n        (2, 2)          # Case 4\n    ]\n\n    results = []\n    for N_outer, N_inner in test_cases:\n        # Step 1: Draw N_outer independent samples from Uniform(0,1) for the latent variable Y.\n        # These will serve as the means for the normal distributions.\n        y_samples = rng.uniform(low=0.0, high=1.0, size=N_outer)\n\n        # Step 2: For each Y_i, draw N_inner samples from Normal(Y_i, 1).\n        # We use numpy broadcasting: y_samples is (N_outer,), we make it (N_outer, 1)\n        # so it broadcasts across the N_inner dimension.\n        # The scale (standard deviation) is sqrt(1) = 1.\n        x_samples = rng.normal(loc=y_samples[:, np.newaxis], scale=1.0, size=(N_outer, N_inner))\n\n        # Step 3: Compute the overall empirical mean and variance of all X samples.\n        # numpy.mean and numpy.var (with default ddof=0) compute the population statistics\n        # as required by the problem statement.\n        m_hat = np.mean(x_samples)\n        v_hat = np.var(x_samples)\n\n        # Step 4: Compute the group-wise statistics.\n        # m_i_hat: mean of each group i (mean of each row).\n        # v_i_hat: variance of each group i (variance of each row).\n        # The `axis=1` argument performs the calculation along each row.\n        m_i_hat = np.mean(x_samples, axis=1)  # Resulting shape: (N_outer,)\n        v_i_hat = np.var(x_samples, axis=1)   # Resulting shape: (N_outer,)\n\n        # Step 5: Compute the hierarchical components based on the problem definitions.\n        # E[Var(X|Y)] is estimated by the mean of the group variances.\n        E_var_hat = np.mean(v_i_hat)\n        \n        # Var(E[X|Y]) is estimated by the variance of the group means.\n        # The mean of m_i_hat is algebraically identical to the overall mean m_hat.\n        # Thus, np.var(m_i_hat) correctly computes the required quantity.\n        var_E_hat = np.var(m_i_hat)\n\n        # Step 6: Compute the sum of the components (t_hat) and the absolute difference (d_hat).\n        # This verifies the empirical identity.\n        t_hat = E_var_hat + var_E_hat\n        d_hat = np.abs(v_hat - t_hat)\n\n        # Append the four required quantities for this test case to the results list.\n        results.extend([m_hat, v_hat, t_hat, d_hat])\n\n    # Final print statement in the exact required format.\n    # map(str, results) ensures default float-to-string conversion.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3126385"}, {"introduction": "在复杂的计算问题中，我们常常无法直接从我们感兴趣的目标分布中进行抽样。重要性抽样提供了一种优雅而强大的解决方案，允许我们利用来自“提议分布”的样本来估计目标分布的矩。本练习将引导你从第一性原理出发，推导并实现用于均值和方差的无偏重要性抽样估计器[@problem_id:3126332]。通过处理具体的数值案例，你将掌握如何通过为每个样本分配适当的“权重”来校正抽样偏差，这是蒙特卡洛方法工具箱中的一项核心技能。", "problem": "考虑一个受自适应网格加密（AMR）启发的计算环境，其中样本从非均匀采样密度中抽取，但我们感兴趣的量是关于有界域上均匀目标密度的期望和方差。目标是为在采样点上评估的标量值函数的前两阶矩设计无偏估计量，并在一个程序中实现这些估计量。请在以下纯数学框架中进行，并假设三角函数的角度以弧度为单位。\n\n仅从核心定义出发。设 $D$ 是一个单位体积的可测域，目标密度为 $p(\\mathbf{u}) = 1$，其中 $\\mathbf{u} \\in D$。设 $\\{ \\mathbf{U}_i \\}_{i=1}^n$ 是从在 $D$ 上严格为正的提议密度 $q(\\mathbf{u})$ 中抽取的独立同分布样本。设 $g: D \\to \\mathbb{R}$ 是一个可测函数。目标期望和方差定义为\n$$\\mu = \\mathbb{E}_p[g(\\mathbf{U})], \\quad \\sigma^2 = \\mathrm{Var}_p(g(\\mathbf{U})).$$\n仅使用期望作为积分的基本定义以及在 $p$ 和 $q$ 之间进行测度变换的原理，从第一性原理推导：\n- 一个基于样本 $\\{ \\mathbf{U}_i \\}_{i=1}^n$ 和逐点值 $\\{ q(\\mathbf{U}_i) \\}_{i=1}^n$ 的 $\\mu$ 的无偏估计量。\n- 一个 $\\sigma^2$ 的无偏估计量，它不依赖于矩估计量的插入式差异，而是利用独立性以及方差的一种等价表示，即利用随机变量两个独立副本之间的差异来表达。\n\n然后，在一个程序中实现这些估计量，该程序为以下每个测试案例计算无偏估计。在以下所有案例中，域 $D$ 的体积为单位体积，因此在 $D$ 上的任何地方都有 $p(\\mathbf{u}) = 1$，因此 $w(\\mathbf{u}) = \\frac{p(\\mathbf{u})}{q(\\mathbf{u})} = \\frac{1}{q(\\mathbf{u})}$。\n\n测试套件：\n- 案例 A（一维域）：$D = [0,1]$，$g(x) = x^2$。采样密度是分段常数：当 $x \\in [0,0.5]$ 时，$q(x) = 1.6$；当 $x \\in (0.5,1]$ 时，$q(x) = 0.4$。样本点为 $x \\in \\{ 0.25, 0.5, 0.75, 1.0 \\}$。\n- 案例 B（二维域）：$D = [0,1]^2$，$g(x,y) = \\sin(\\pi x)\\sin(\\pi y)$。采样密度在 $x$ 方向上是分段常数：如果 $x \\in [0,0.25]$，则 $q(x,y) = 2$；如果 $x \\in (0.25,1]$，则 $q(x,y) = \\frac{2}{3}$。样本点为 $(x,y) \\in \\{ (0.5, 0.5), (0.75, 0.5), (0.125, 0.5) \\}$。\n- 案例 C（一维域，方差所需最小样本数的边缘情况）：$D = [0,1]$，$g(x) = e^x$。采样密度为 $q(x) = 0.4\\,(1 + 3x)$，其中 $x \\in [0,1]$。样本点为 $x \\in \\{ 0, 1 \\}$。\n\n对于每种情况，使用你推导的估计量计算 $\\mu$ 和 $\\sigma^2$ 的无偏估计。将每个报告的数字四舍五入到 6 位小数。\n\n最终输出格式：\n你的程序应该生成单行输出，其中包含案例 A、B 和 C 的结果，形式为一个包含三个子列表的逗号分隔列表，每个子列表包含该案例的两个四舍五入的浮点数 $[\\widehat{\\mu},\\widehat{\\sigma^2}]$。例如，你的输出应该看起来完全像\n$$\\big[ [\\widehat{\\mu}_A,\\widehat{\\sigma^2}_A], [\\widehat{\\mu}_B,\\widehat{\\sigma^2}_B], [\\widehat{\\mu}_C,\\widehat{\\sigma^2}_C] \\big],$$\n所有数字都四舍五入到 6 位小数，除了逗号和括号所必需的空格外，没有额外的空格。三角函数的角度以弧度为单位。", "solution": "该问题要求推导并实现函数 $g(\\mathbf{U})$ 关于均匀概率密度 $p(\\mathbf{u})$ 的均值和方差的无偏估计量，并使用从不同的提议密度 $q(\\mathbf{u})$ 中抽取的样本。这是一个经典的重点采样场景。\n\n设域为 $D \\subset \\mathbb{R}^d$，其单位体积为 $\\int_D d\\mathbf{u} = 1$。目标概率密度函数为 $p(\\mathbf{u}) = 1$（当 $\\mathbf{u} \\in D$ 时）否则为 $0$。采样（或提议）密度为 $q(\\mathbf{u})$，它在 $D$ 上严格为正。我们有从 $q(\\mathbf{u})$ 中抽取的 $n$ 个独立同分布（i.i.d.）样本 $\\{\\mathbf{U}_i\\}_{i=1}^n$。\n\n目标期望（均值）和方差为：\n$$\n\\mu = \\mathbb{E}_p[g(\\mathbf{U})] = \\int_D g(\\mathbf{u}) p(\\mathbf{u}) d\\mathbf{u}\n$$\n$$\n\\sigma^2 = \\mathrm{Var}_p(g(\\mathbf{U})) = \\mathbb{E}_p[(g(\\mathbf{U}) - \\mu)^2]\n$$\n\n我们现在将从第一性原理推导 $\\mu$ 和 $\\sigma^2$ 的无偏估计量。\n\n### 均值（$\\mu$）的无偏估计量推导\n\n均值 $\\mu$ 是相对于目标密度 $p$ 定义的。由于在 $D$ 上 $p(\\mathbf{u}) = 1$，定义变为：\n$$\n\\mu = \\int_D g(\\mathbf{u}) \\, d\\mathbf{u}\n$$\n为了使用从 $q(\\mathbf{u})$ 中抽取的样本来评估此积分，我们采用测度变换。我们将被积函数同乘同除以 $q(\\mathbf{u})$，这是允许的，因为在 $D$ 上 $q(\\mathbf{u})  0$：\n$$\n\\mu = \\int_D g(\\mathbf{u}) \\frac{q(\\mathbf{u})}{q(\\mathbf{u})} \\, d\\mathbf{u} = \\int_D \\left( \\frac{g(\\mathbf{u})}{q(\\mathbf{u})} \\right) q(\\mathbf{u}) \\, d\\mathbf{u}\n$$\n这个表达式是量 $g(\\mathbf{U})/q(\\mathbf{U})$ 关于采样密度 $q(\\mathbf{u})$ 的期望的定义。让我们将重要性权重定义为 $w(\\mathbf{u}) = p(\\mathbf{u})/q(\\mathbf{u}) = 1/q(\\mathbf{u})$。那么：\n$$\n\\mu = \\mathbb{E}_q\\left[ \\frac{g(\\mathbf{U})}{q(\\mathbf{U})} \\right] = \\mathbb{E}_q[g(\\mathbf{U})w(\\mathbf{U})]\n$$\n根据大数定律，我们可以使用 $g(\\mathbf{U}_i)w(\\mathbf{U}_i)$ 在 $n$ 个 i.i.d. 样本 $\\{\\mathbf{U}_i\\}_{i=1}^n$ 上的样本均值来估计这个期望。这得出了均值的重点采样估计量，记作 $\\widehat{\\mu}$：\n$$\n\\widehat{\\mu} = \\frac{1}{n} \\sum_{i=1}^n g(\\mathbf{U}_i)w(\\mathbf{U}_i) = \\frac{1}{n} \\sum_{i=1}^n \\frac{g(\\mathbf{U}_i)}{q(\\mathbf{U}_i)}\n$$\n这个估计量是无偏的，因为它在采样分布 $q$ 下的期望是 $\\mu$：\n$$\n\\mathbb{E}_q[\\widehat{\\mu}] = \\mathbb{E}_q\\left[ \\frac{1}{n} \\sum_{i=1}^n \\frac{g(\\mathbf{U}_i)}{q(\\mathbf{U}_i)} \\right] = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{E}_q\\left[ \\frac{g(\\mathbf{U}_i)}{q(\\mathbf{U}_i)} \\right] = \\frac{n}{n} \\mathbb{E}_q\\left[ \\frac{g(\\mathbf{U})}{q(\\mathbf{U})} \\right] = \\mu\n$$\n\n### 方差（$\\sigma^2$）的无偏估计量推导\n\n问题要求一个特定的推导路径，从将方差与随机变量的两个独立副本的平方差的期望联系起来的恒等式开始。对于一个随机变量 $X$，其均值为 $\\mathbb{E}[X] = \\mu_X$，如果 $X_1$ 和 $X_2$ 是 $X$ 的 i.i.d. 副本，那么：\n$$\n\\mathrm{Var}(X) = \\mathbb{E}[(X - \\mu_X)^2] = \\mathbb{E}[X^2] - \\mu_X^2 = \\frac{1}{2}(\\mathbb{E}[X_1^2] - 2\\mathbb{E}[X_1]\\mathbb{E}[X_2] + \\mathbb{E}[X_2^2]) = \\frac{1}{2}\\mathbb{E}[(X_1 - X_2)^2]\n$$\n我们将此恒等式应用于 $g(\\mathbf{U})$，其中 $\\mathbf{U} \\sim p(\\mathbf{u})$。设 $\\mathbf{U}_1$ 和 $\\mathbf{U}_2$ 是从目标密度 $p$ 中抽取的两个独立随机变量。那么目标方差是：\n$$\n\\sigma^2 = \\frac{1}{2} \\mathbb{E}_{p,p}[(g(\\mathbf{U}_1) - g(\\mathbf{U}_2))^2]\n$$\n期望是关于联合密度 $p(\\mathbf{u}_1)p(\\mathbf{u}_2)$ 的。我们可以将其写成一个积分：\n$$\n\\sigma^2 = \\frac{1}{2} \\int_D \\int_D (g(\\mathbf{u}_1) - g(\\mathbf{u}_2))^2 p(\\mathbf{u}_1)p(\\mathbf{u}_2) \\, d\\mathbf{u}_1 d\\mathbf{u}_2\n$$\n再次，我们使用重要性权重 $w(\\mathbf{u}) = 1/q(\\mathbf{u})$ 从 $p$ 到 $q$ 进行测度变换：\n$$\n\\sigma^2 = \\frac{1}{2} \\int_D \\int_D (g(\\mathbf{u}_1) - g(\\mathbf{u}_2))^2 w(\\mathbf{u}_1)q(\\mathbf{u}_1) w(\\mathbf{u}_2)q(\\mathbf{u}_2) \\, d\\mathbf{u}_1 d\\mathbf{u}_2\n$$\n这个表达式是关于联合采样密度 $q(\\mathbf{u}_1)q(\\mathbf{u}_2)$ 的期望：\n$$\n\\sigma^2 = \\mathbb{E}_{q,q}\\left[ \\frac{1}{2}(g(\\mathbf{U}_1) - g(\\mathbf{U}_2))^2 w(\\mathbf{U}_1)w(\\mathbf{U}_2) \\right]\n$$\n这表明 $\\sigma^2$ 是核函数 $h(\\mathbf{u}_1, \\mathbf{u}_2) = \\frac{1}{2}(g(\\mathbf{u}_1) - g(\\mathbf{u}_2))^2 w(\\mathbf{u}_1)w(\\mathbf{u}_2)$ 的期望，其中 $\\mathbf{U}_1, \\mathbf{U}_2$ 是从 $q$ 中抽取的 i.i.d. 样本。\n\n为了从一组 $n$ 个样本 $\\{\\mathbf{U}_i\\}_{i=1}^n$ 中估计这个期望，我们可以通过对所有唯一样本对的核函数求平均来构造一个无偏估计量。这定义了一个2阶U-统计量。对于 $n \\ge 2$，有 $\\binom{n}{2}$ 个唯一的对 $(\\mathbf{U}_i, \\mathbf{U}_j)$，其中 $i  j$。$\\sigma^2$ 的U-统计量估计量是：\n$$\n\\widehat{\\sigma^2} = \\frac{1}{\\binom{n}{2}} \\sum_{1 \\le i  j \\le n} h(\\mathbf{U}_i, \\mathbf{U}_j) = \\frac{1}{\\frac{n(n-1)}{2}} \\sum_{1 \\le i  j \\le n} \\frac{1}{2} (g(\\mathbf{U}_i) - g(\\mathbf{U}_j))^2 w(\\mathbf{U}_i)w(\\mathbf{U}_j)\n$$\n简化表达式得到估计量的最终形式：\n$$\n\\widehat{\\sigma^2} = \\frac{1}{n(n-1)} \\sum_{1 \\le i  j \\le n} (g(\\mathbf{U}_i) - g(\\mathbf{U}_j))^2 w(\\mathbf{U}_i)w(\\mathbf{U}_j)\n$$\n代入 $w(\\mathbf{U}_i) = 1/q(\\mathbf{U}_i)$，我们得到用于计算的公式：\n$$\n\\widehat{\\sigma^2} = \\frac{1}{n(n-1)} \\sum_{1 \\le i  j \\le n} \\frac{(g(\\mathbf{U}_i) - g(\\mathbf{U}_j))^2}{q(\\mathbf{U}_i)q(\\mathbf{U}_j)}\n$$\n根据构造，这个估计量是无偏的，并且对于任何样本大小 $n \\ge 2$ 都有效。\n\n最终答案中的程序实现了这两个推导出的估计量 $\\widehat{\\mu}$ 和 $\\widehat{\\sigma^2}$，并将它们应用于所提供的三个测试案例。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom itertools import combinations\nimport math\n\ndef solve():\n    \"\"\"\n    Solves the problem by computing unbiased estimates for the mean and variance\n    for three distinct test cases using importance sampling.\n    \"\"\"\n\n    results = []\n\n    # Case A\n    samples_A = np.array([0.25, 0.5, 0.75, 1.0])\n    g_A = lambda x: x**2\n    def q_A(x):\n        return 1.6 if x = 0.5 else 0.4\n    \n    # Case B\n    samples_B = np.array([(0.5, 0.5), (0.75, 0.5), (0.125, 0.5)])\n    g_B = lambda u: math.sin(math.pi * u[0]) * math.sin(math.pi * u[1])\n    def q_B(u):\n        return 2.0 if u[0] = 0.25 else 2.0/3.0\n    \n    # Case C\n    samples_C = np.array([0.0, 1.0])\n    g_C = lambda x: math.exp(x)\n    q_C = lambda x: 0.4 * (1.0 + 3.0 * x)\n    \n    test_cases = [\n        {\"samples\": samples_A, \"g_func\": g_A, \"q_func\": q_A},\n        {\"samples\": samples_B, \"g_func\": g_B, \"q_func\": q_B},\n        {\"samples\": samples_C, \"g_func\": g_C, \"q_func\": q_C},\n    ]\n\n    def compute_estimates(samples, g_func, q_func):\n        \"\"\"\n        Computes the unbiased estimates for mean and variance.\n        \"\"\"\n        n = len(samples)\n        \n        g_vals = np.array([g_func(s) for s in samples])\n        q_vals = np.array([q_func(s) for s in samples])\n        w_vals = 1.0 / q_vals\n        \n        # Unbiased estimator for the mean\n        mu_hat = np.mean(g_vals * w_vals)\n        \n        # Unbiased estimator for the variance\n        if n  2:\n            sigma2_hat = float('nan')\n        else:\n            sigma2_hat_sum = 0.0\n            # Sum over unique pairs (i, j) where i  j\n            indices = range(n)\n            for i, j in combinations(indices, 2):\n                term = (g_vals[i] - g_vals[j])**2 * w_vals[i] * w_vals[j]\n                sigma2_hat_sum += term\n            \n            sigma2_hat = sigma2_hat_sum / (n * (n - 1))\n            \n        return [mu_hat, sigma2_hat]\n\n    for case in test_cases:\n        estimates = compute_estimates(case[\"samples\"], case[\"g_func\"], case[\"q_func\"])\n        results.append(estimates)\n    \n    # Format the output string as per problem specification\n    # [[mu_A,sigma2_A],[mu_B,sigma2_B],[mu_C,sigma2_C]]\n    # with 6 decimal places and no extra spaces.\n    formatted_sublists = []\n    for sublist in results:\n        mu_str = f\"{sublist[0]:.6f}\"\n        sigma2_str = f\"{sublist[1]:.6f}\"\n        formatted_sublists.append(f\"[{mu_str},{sigma2_str}]\")\n    \n    final_output_string = f\"[{','.join(formatted_sublists)}]\"\n    \n    print(final_output_string)\n\nsolve()\n```", "id": "3126332"}]}