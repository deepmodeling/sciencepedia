{"hands_on_practices": [{"introduction": "理论上，病态矩阵会放大微小的扰动。这个练习将让你通过编程实践，亲眼见证这一效应。通过使用著名的希尔伯特矩阵作为测试案例[@problem_id:3141607]，你将比较单精度（32位）和双精度（64位）浮点运算在求解同一个病态线性系统时的巨大差异。这个练习旨在将条件数的抽象概念与有限精度计算中实实在在的精度损失联系起来，让你深刻理解为何在处理病态问题时，计算精度至关重要。", "problem": "你需要编写一个完整的程序，通过比较单精度和双精度计算出的解，来实证研究求解病态线性系统 $A x = b$ 时的数值行为。目标是为每个测试用例确定达到解 $x$ 的指定目标相对误差所需的最小精度。你的研究必须基于以下基础：\n\n- 线性系统 $A x = b$ 的定义，其中 $A$ 是一个方阵，$x$ 是未知数向量，$b$ 是一个已知的右端向量。\n- 浮点运算及其舍入行为的概念，其运算模型为 $\\mathrm{fl}(a \\,\\circ\\, b) = (a \\,\\circ\\, b) (1 + \\delta)$，其中 $|\\delta| \\leq u$，$u$ 是浮点格式的单位舍入误差。\n- 给定范数下矩阵条件数的定义，$\\kappa(A) = \\|A\\| \\cdot \\|A^{-1}\\|$，以及对较大 $\\kappa(A)$ 意味着解 $x$ 对 $A$ 和 $b$ 的扰动更敏感的理解。\n\n你的程序必须实现以下任务，这些任务纯粹以数学和算法术语表述：\n\n1. 对于每个维度为 $n$、目标容差为 $\\tau$ 的测试用例，构建由 $A_{ij} = \\frac{1}{i + j - 1}$（$1 \\leq i,j \\leq n$）定义的希尔伯特矩阵 $A \\in \\mathbb{R}^{n \\times n}$。希尔伯特矩阵是病态矩阵的一个经典例子。\n2. 选择一个基准解 $x^\\star \\in \\mathbb{R}^n$ 作为全1向量，即 $x^\\star = (1,1,\\dots,1)^\\top$。在双精度下计算 $b = A x^\\star$ 以建立一个参考右端项。\n3. 求解 $A x = b$ 两次：\n   - 一次在单精度（32位浮点数）下，通过将 $A$ 和 $b$ 转换为单精度并使用一个标准的直接求解器。\n   - 一次在双精度（64位浮点数）下，通过将 $A$ 和 $b$ 转换为双精度并使用相同的求解器。\n4. 对于每种精度，计算解的相对前向误差，\n   $$\n   e_{\\mathrm{rel}} = \\frac{\\|x_{\\mathrm{computed}} - x^\\star\\|_2}{\\|x^\\star\\|_2}.\n   $$\n5. 确定达到目标容差 $\\tau$ 所需的最小精度：如果单精度相对误差小于或等于 $\\tau$，则选择 $32$；否则，如果双精度相对误差小于或等于 $\\tau$，则选择 $64$；否则，如果两者都不能满足容差，则输出 $-1$ 以表示在给定的病态条件下，两种测试的精度都未能达到所需的准确度。\n\n你的程序必须使用以下参数值 $(n, \\tau)$ 的测试套件，该套件旨在探究数值稳定性的不同方面：\n\n- 单精度足够的一般情况：$(n, \\tau) = (3, 10^{-4})$。\n- 单精度失败但双精度成功的情况：$(n, \\tau) = (8, 10^{-5})$。\n- 即使双精度也无法满足严格容差的强病态情况：$(n, \\tau) = (12, 10^{-8})$。\n- 病态程度中等但容差极严的边界情况：$(n, \\tau) = (5, 10^{-12})$。\n\n本问题不涉及物理单位或角度单位。所有数值容差、维度和输出均为无量纲实数。\n\n最终输出格式规范：\n- 你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的结果与上述测试用例的顺序相同。每个结果必须是 $\\{32, 64, -1\\}$ 中的一个整数，表示所需的最小精度。\n- 例如，输出可能看起来像 $\\left[32,64,-1,-1\\right]$，但必须反映你的程序对指定测试用例计算出的实际结果。", "solution": "该问题要求对浮点精度在求解病态线性系统时的影响进行实证研究。具体来说，我们的任务是确定求解系统 $A x = b$ 所需的最小浮点精度——32位（单精度）或64位（双精度）——以使其解在指定的相对误差容差 $\\tau$ 内，其中 $A$ 是一个希尔伯特矩阵。\n\n对于由维度 $n$ 和容差 $\\tau$ 定义的每个测试用例，其过程如下。\n\n**步骤 1：系统构建**\n首先，我们构建线性系统 $A x = b$ 的各个组成部分。矩阵 $A$ 是一个 $n \\times n$ 的希尔伯特矩阵，其元素由以下公式定义：\n$$\nA_{ij} = \\frac{1}{i + j - 1} \\quad \\text{for } 1 \\leq i, j \\leq n\n$$\n希尔伯特矩阵是出了名的病态矩阵，这意味着它们的条件数 $\\kappa(A) = \\|A\\| \\|A^{-1}\\|$ 随维度 $n$ 的增加而迅速增长。这一特性使其成为研究数值不稳定性的绝佳对象。\n\n基准解，记为 $x^\\star$，被定义为维度为 $n$ 的全1向量：\n$$\nx^\\star = (1, 1, \\dots, 1)^\\top \\in \\mathbb{R}^n\n$$\n该向量的所有元素在标准浮点格式中都可以精确表示。\n\n**步骤 2：右端向量计算**\n使用已定义的 $A$ 和 $x^\\star$，我们计算右端向量 $b = A x^\\star$。为确保 $b$ 尽可能精确并作为一个可靠的参考，此计算在双精度（64位浮点运算）下执行。这最大限度地减少了问题设置本身引入的误差；之后观察到的任何显著误差都可以更有把握地归因于后续的求解过程。我们将双精度矩阵记为 $A_{64}$，得到的向量记为 $b_{64}$。\n\n**步骤 3：单精度求解**\n为了模拟一个较低精度的计算，我们首先将双精度矩阵 $A_{64}$ 和向量 $b_{64}$ 转换为单精度（32位）格式。记它们为 $A_{32}$ 和 $b_{32}$。转换过程本身可能会引入舍入误差，特别是对于作为分数的希尔伯特矩阵的元素。\n\n然后我们使用一个标准的数值求解器求解线性系统 $A_{32} x_{32} = b_{32}$，得到未知向量 $x_{32}$。得到的向量 $x_{32}$ 就是在单精度下计算出的解。\n\n接下来，我们通过计算相对前向误差 $e_{32}$ 来评估该解的准确性。误差是相对于已知的基准解 $x^\\star$ 使用欧几里得（$L_2$）范数来度量的：\n$$\ne_{32} = \\frac{\\|x_{32} - x^\\star\\|_2}{\\|x^\\star\\|_2}\n$$\n真实解的范数 $\\|x^\\star\\|_2$ 仅为 $\\sqrt{n}$，因为它的所有分量都是 $1$。\n\n**步骤 4：双精度求解**\n我们重复求解过程，但这次完全在双精度下进行。我们求解系统 $A_{64} x_{64} = b_{64}$ 以得到向量 $x_{64}$。与单精度情况相比，此计算受益于更大的尾数和更小的单位舍入误差，预计会为病态系统产生更准确的结果。\n\n同样，我们计算双精度解的相对前向误差：\n$$\ne_{64} = \\frac{\\|x_{64} - x^\\star\\|_2}{\\|x^\\star\\|_2}\n$$\n\n**步骤 5：最小精度确定**\n最后一步是将计算出的误差 $e_{32}$ 和 $e_{64}$ 与用户指定的容差 $\\tau$ 进行比较。决策逻辑如下：\n- 如果 $e_{32} \\leq \\tau$，则认为单精度足够。该测试用例的结果为 $32$。\n- 如果 $e_{32} > \\tau$ 但 $e_{64} \\leq \\tau$，则单精度失败而双精度成功。结果为 $64$。\n- 如果两种精度都未达到目标容差（即 $e_{32} > \\tau$ 且 $e_{64} > \\tau$），则对于给定的病态程度和容差的严格性，两种测试的精度都不足。结果为 $-1$。\n\n该过程被系统地应用于所提供的测试套件中的每个 $(n, \\tau)$ 对，并报告结果序列。这些测试用例经过专门选择，旨在探究 $n \\times n$ 希尔伯特矩阵的条件数在不同场景下的表现：条件数低到单精度足以胜任，高到需要双精度，或者高到即使双精度也无法满足严格容差。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Empirically studies the numerical behavior of solving ill-conditioned\n    linear systems by comparing single and double precision results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (3, 1e-4),    # General case, single precision should suffice.\n        (8, 1e-5),    # Single precision fails, double precision succeeds.\n        (12, 1e-8),   # Strongly ill-conditioned, even double precision fails.\n        (5, 1e-12),   # Moderate ill-conditioning, very tight tolerance.\n    ]\n\n    results = []\n    for n, tau in test_cases:\n        # Step 1: Construct the n x n Hilbert matrix A and ground-truth solution x_star.\n        # All initial constructions are done in double precision (float64) to maintain accuracy.\n        \n        # Create the ground-truth solution vector x_star = [1, 1, ..., 1]^T.\n        x_star = np.ones(n, dtype='float64')\n\n        # Construct the Hilbert matrix A_ij = 1 / (i + j - 1).\n        # We use 'i' and 'j' indices from 1 to n.\n        i = np.arange(1, n + 1, dtype='float64').reshape(-1, 1)\n        j = np.arange(1, n + 1, dtype='float64').reshape(1, -1)\n        A_64 = 1.0 / (i + j - 1)\n\n        # Step 2: Compute the right-hand side b = A * x_star in double precision.\n        b_64 = A_64 @ x_star\n\n        # Step 3: Solve in single precision (32-bit).\n        # Cast the matrix and vector to float32.\n        A_32 = A_64.astype('float32')\n        b_32 = b_64.astype('float32')\n        \n        # Solve the system Ax = b.\n        x_32_computed = np.linalg.solve(A_32, b_32)\n        \n        # Compute the relative forward error for the single-precision solution.\n        # The norm of x_star is sqrt(n).\n        norm_x_star = np.linalg.norm(x_star)\n        err_32 = np.linalg.norm(x_32_computed - x_star) / norm_x_star\n\n        # Step 4: Solve in double precision (64-bit).\n        # The matrix and vector are already in float64.\n        x_64_computed = np.linalg.solve(A_64, b_64)\n\n        # Compute the relative forward error for the double-precision solution.\n        err_64 = np.linalg.norm(x_64_computed - x_star) / norm_x_star\n        \n        # Step 5: Determine the minimal precision needed.\n        if err_32 = tau:\n            results.append(32)\n        elif err_64 = tau:\n            results.append(64)\n        else:\n            results.append(-1)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3141607"}, {"introduction": "既然我们已经看到直接求解病态系统是多么脆弱，那么我们如何才能得到一个稳定且有意义的近似解呢？本练习将引导你探索一种强大的技术——吉洪诺夫正则化（Tikhonov regularization）。我们将不再寻求一个“完美”的解，而是通过引入一个惩罚项来找到一个在拟合数据和保持解的稳定性之间取得平衡的解。你将通过计算“正则化路径”[@problem_id:3141589]，即解 $x(\\lambda)$ 如何随着正则化强度参数 $\\lambda$ 的变化而演变，来直观地理解正则化是如何“驯服”病态问题并稳定解的。", "problem": "考虑形如 $A x \\approx b$ 的线性方程组，其中 $A \\in \\mathbb{R}^{n \\times m}$ 且 $b \\in \\mathbb{R}^{n}$。为了在病态（ill-conditioned）设置下分析灵敏度，我们研究正则化最小二乘极小化子 $x(\\lambda)$，它被定义为目标函数 $J(x;\\lambda) = \\lVert A x - b \\rVert_2^2 + \\lambda \\lVert x \\rVert_2^2$ 的极小化子，其中正则化参数 $\\lambda  0$。目标是计算并比较在跨越多个数量级的 $\\lambda$ 上的正则化路径 $x(\\lambda)$，并识别出系统条件数主导解的行为的区域。\n\n仅使用基本定义：2-范数 $\\lVert \\cdot \\rVert_2$、矩阵转置 $A^\\top$、单位矩阵 $I$，以及矩阵 $M$ 的 2-范数条件数 $\\kappa_2(M) = \\sigma_{\\max}(M)/\\sigma_{\\min}(M)$ 的定义，其中 $\\sigma_{\\max}$ 和 $\\sigma_{\\min}$ 分别是最大和最小奇异值。不要从任何 $x(\\lambda)$ 的闭式解公式开始；相反，应从第一性原理出发，推导并实现极小化子的计算。\n\n你的程序必须：\n- 构建三个测试用例 $(A,b)$，以探测不同的条件数行为。\n- 对每个测试用例，为跨越多个数量级的 $\\lambda$ 值评估路径 $x(\\lambda)$。\n- 使用条件数和相对路径变化来量化条件数如何影响路径。\n- 为每个测试用例报告数值指标，这些指标总结了条件数主导的区域和稳定区域的开始，以及解的范数沿路径的总体单调性得分。\n\n需要计算的定义和量：\n1. 对于给定的测试用例和规定集合中的每个 $\\lambda$，计算 $J(x;\\lambda)$ 的极小化子 $x(\\lambda)$、$M(\\lambda) = A^\\top A + \\lambda I$ 的条件数 $\\kappa_2\\!\\left(M(\\lambda)\\right)$，以及欧几里得范数 $\\lVert x(\\lambda) \\rVert_2$。\n2. 对于连续的 $\\lambda$ 值 $\\lambda_k$ 和 $\\lambda_{k+1}$，定义相对路径变化\n   $$ s_k = \\frac{\\lVert x(\\lambda_{k+1}) - x(\\lambda_{k}) \\rVert_2}{\\max\\!\\big(\\lVert x(\\lambda_k) \\rVert_2, \\, 10^{-300}\\big)}. $$\n3. 定义用于区域识别的阈值：\n   - 条件数主导阈值：$\\kappa_{\\text{dom}} = 10^{12}$ 和 $\\tau_{\\text{dom}} = 0.5$。\n   - 稳定区域阈值：$\\kappa_{\\text{stab}} = 10^{6}$ 和 $\\tau_{\\text{stab}} = 0.05$。\n4. 为每个测试用例定义区域指标：\n   - 主导区域范围（以单个 $\\lambda$ 表示）：\n     $$ \\lambda_{\\text{dom}} = \\max \\left\\{ \\lambda_k \\,\\middle|\\, \\kappa_2\\!\\left(M(\\lambda_k)\\right) \\ge \\kappa_{\\text{dom}} \\text{ and } s_k \\ge \\tau_{\\text{dom}} \\right\\}. $$\n     如果该集合为空，则取 $\\lambda_{\\text{dom}} = 0$。\n   - 稳定区域起始点（以单个 $\\lambda$ 表示）：\n     $$ \\lambda_{\\text{stab}} = \\min \\left\\{ \\lambda_{k+1} \\,\\middle|\\, \\kappa_2\\!\\left(M(\\lambda_{k+1})\\right) \\le \\kappa_{\\text{stab}} \\text{ and } s_k \\le \\tau_{\\text{stab}} \\right\\}. $$\n     如果该集合为空，则取 $\\lambda_{\\text{stab}}$ 为网格中最大的 $\\lambda$。\n   - 解的范数沿路径的单调性得分：\n     $$ \\mu = \\frac{\\#\\left\\{ k \\,\\middle|\\, \\lVert x(\\lambda_{k+1}) \\rVert_2 \\le \\lVert x(\\lambda_{k}) \\rVert_2 \\right\\}}{|\\Lambda|-1}, $$\n     其中 $\\Lambda$ 是采样的 $\\lambda$ 值集合， $|\\Lambda|$ 是其基数。\n\n测试套件和数据规范：\n- 使用以下 $\\lambda$ 网格：\n  $$ \\Lambda = \\left[10^{-12},\\,10^{-10},\\,10^{-8},\\,10^{-6},\\,10^{-4},\\,10^{-2},\\,10^{0},\\,10^{2}\\right]. $$\n- 测试用例 1（经典的病态方阵系统）：令 $n=m=6$。令 $A$ 为 $6 \\times 6$ 的希尔伯特矩阵，其元素为 $A_{ij} = \\frac{1}{i + j + 1}$，其中 $i,j \\in \\{0,1,2,3,4,5\\}$（从零开始的索引），并令 $b$ 为 $\\mathbb{R}^6$ 中的全一向量。\n- 测试用例 2（超定系统中具有近似共线列的严重病态情况）：令 $n=60$ 且 $m=10$。用种子 $0$ 初始化一个伪随机数生成器 (PRNG)。抽取一个 $u \\in \\mathbb{R}^{60}$，其元素为独立的标准正态分布。对于每个列索引 $j \\in \\{0,\\dots,9\\}$，抽取一个 $\\eta_j \\in \\mathbb{R}^{60}$，其元素为独立的标准正态分布，并设置 $A_{:,j} = u + \\epsilon \\eta_j$，其中 $\\epsilon = 10^{-8}$。使用相同的 PRNG 抽取一个 $b \\in \\mathbb{R}^{60}$，其元素为独立的标准正态分布。\n- 测试用例 3（超定系统中的精确秩亏）：令 $n=30$ 且 $m=6$。使用相同的 PRNG（从其当前状态继续），抽取一个 $A \\in \\mathbb{R}^{30 \\times 6}$，其元素为独立的标准正态分布，然后将最后一列设置为前两列之和，$A_{:,5} = A_{:,0} + A_{:,1}$，从而产生精确的线性相关性。抽取一个 $b \\in \\mathbb{R}^{30}$，其元素为独立的标准正态分布。\n\n计算和输出要求：\n- 对每个测试用例，为每个 $\\lambda \\in \\Lambda$ 计算 $x(\\lambda)$，然后计算如上定义的 $\\kappa_2\\!\\left(M(\\lambda)\\right)$、$s_k$ 和 $\\mu$。使用阈值计算指定的 $\\lambda_{\\text{dom}}$ 和 $\\lambda_{\\text{stab}}$。\n- 你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。每个测试用例的结果必须是按 $[\\lambda_{\\text{dom}}, \\lambda_{\\text{stab}}, \\mu]$ 顺序排列的三个浮点数列表。最终结构必须是\n  $$ [[\\lambda_{\\text{dom}}^{(1)}, \\lambda_{\\text{stab}}^{(1)}, \\mu^{(1)}],[\\lambda_{\\text{dom}}^{(2)}, \\lambda_{\\text{stab}}^{(2)}, \\mu^{(2)}],[\\lambda_{\\text{dom}}^{(3)}, \\lambda_{\\text{stab}}^{(3)}, \\mu^{(3)}]] $$\n  以单行打印，不含任何空白字符。", "solution": "我们从正则化最小二乘目标函数 $J(x;\\lambda) = \\lVert A x - b \\rVert_2^2 + \\lambda \\lVert x \\rVert_2^2$（其中 $\\lambda  0$）的定义开始。该目标函数在 $x$ 上是严格凸的，因为二次型 $\\lVert A x - b \\rVert_2^2$ 是凸的，而项 $\\lambda \\lVert x \\rVert_2^2$ 增加了一个严格凸的惩罚项。因此，对于每个 $\\lambda  0$，存在一个唯一的极小化子 $x(\\lambda)$。\n\n为了从第一性原理计算 $x(\\lambda)$，我们通过将 $J$ 关于 $x$ 的梯度设为零来推导一阶最优性条件。使用法则 $\\nabla_x \\lVert A x - b \\rVert_2^2 = 2 A^\\top (A x - b)$ 和 $\\nabla_x \\lVert x \\rVert_2^2 = 2 x$， $J$ 的梯度为\n$$\n\\nabla_x J(x;\\lambda) = 2 A^\\top (A x - b) + 2 \\lambda x.\n$$\n将 $\\nabla_x J(x;\\lambda)$ 设为零，得到正规方程\n$$\nA^\\top A x + \\lambda x = A^\\top b,\n$$\n可以写成\n$$\n\\left(A^\\top A + \\lambda I\\right) x = A^\\top b.\n$$\n因此，对于每个 $\\lambda  0$，极小化子 $x(\\lambda)$ 是以系数矩阵 $M(\\lambda) = A^\\top A + \\lambda I$ 的线性方程组的唯一解。对于 $\\lambda  0$，矩阵 $M(\\lambda)$ 是对称正定的，这确保了唯一解的存在并排除了奇异性。\n\n我们使用 2-范数条件数 $\\kappa_2(M) = \\sigma_{\\max}(M)/\\sigma_{\\min}(M)$ 来量化系统矩阵 $M(\\lambda)$ 的条件数。矩阵的奇异值分解 (SVD) 提供了其奇异值，并是条件数的基础。高的 $\\kappa_2(M)$ 意味着当数据或计算受到扰动时，解可能存在较大的相对误差。对于正则化的正规矩阵 $M(\\lambda) = A^\\top A + \\lambda I$， $M(\\lambda)$ 的奇异值等于 $M(\\lambda)$ 的特征值，并且可以用 $A$ 的奇异值来表示：如果 $\\sigma_i(A)$ 是 $A$ 的奇异值，那么 $A^\\top A$ 的特征值是 $\\sigma_i(A)^2$，而 $M(\\lambda)$ 的特征值是 $\\sigma_i(A)^2 + \\lambda$。因此，\n$$\n\\kappa_2\\!\\left(M(\\lambda)\\right) = \\frac{\\max_i \\left(\\sigma_i(A)^2 + \\lambda\\right)}{\\min_i \\left(\\sigma_i(A)^2 + \\lambda\\right)}.\n$$\n这个表达式表明，随着 $\\lambda$ 的增加，分母增加，比率收缩至 $1$，从而降低了病态性。当 $\\lambda$ 相对于最小的非零 $\\sigma_i(A)^2$ 很小时，$M(\\lambda)$ 继承了 $A^\\top A$ 的病态性（如果某个 $\\sigma_i(A)=0$，则为奇异性）；随着 $\\lambda$ 的增长，谱被提升，从而改善了条件数。\n\n为评估条件数如何影响解的路径 $x(\\lambda)$，我们为 $\\lambda$ 值的网格 $\\Lambda$ 计算：\n- 从 $\\left(A^\\top A + \\lambda I\\right) x = A^\\top b$ 得到的最小范数解向量 $x(\\lambda)$，\n- 通过奇异值比率计算的条件数 $\\kappa_2\\!\\left(M(\\lambda)\\right)$，\n- 连续 $\\lambda$ 值之间的相对路径变化 $s_k = \\frac{\\lVert x(\\lambda_{k+1}) - x(\\lambda_{k}) \\rVert_2}{\\max(\\lVert x(\\lambda_k) \\rVert_2, 10^{-300})}$，\n- 单调性得分 $\\mu$，它衡量解的范数随着 $\\lambda$ 增大而减小的频率，反映了正则化效应，即通常随着 $\\lambda$ 增大而缩小 $\\lVert x(\\lambda) \\rVert_2$。\n\n然后我们使用阈值参数识别两个区域：\n- 条件数主导区域：我们标记同时满足 $\\kappa_2\\!\\left(M(\\lambda_k)\\right) \\ge \\kappa_{\\text{dom}}$ 和 $s_k \\ge \\tau_{\\text{dom}}$ 的步骤；选择 $\\kappa_{\\text{dom}} = 10^{12}$ 标记了极端的病态条件，而 $\\tau_{\\text{dom}} = 0.5$ 表示 $x(\\lambda)$ 有显著的相对变化。满足这两个条件的最大 $\\lambda_k$ 被报告为 $\\lambda_{\\text{dom}}$；如果没有满足的，我们报告 $0$ 来表示没有强烈的条件数主导步骤。\n- 稳定区域起始点：我们找到第一个后续的 $\\lambda_{k+1}$，使得 $\\kappa_2\\!\\left(M(\\lambda_{k+1})\\right) \\le \\kappa_{\\text{stab}}$ 且 $s_k \\le \\tau_{\\text{stab}}$，其中 $\\kappa_{\\text{stab}} = 10^{6}$ 标志着系统是良态的，而 $\\tau_{\\text{stab}} = 0.05$ 表示路径的增量变化很小。如果找不到这样的步骤，我们取采样的最大 $\\lambda$ 作为 $\\lambda_{\\text{stab}}$。\n\n测试套件旨在覆盖：\n- 经典的病态方阵系统（希尔伯特矩阵），它在小的 $\\lambda$ 值下表现出大的条件数和灵敏度。\n- 具有近似共线列的严重病态超定系统，其中 $A^\\top A$ 近似为秩 1，导致极端的病态性，这种病态性随着 $\\lambda$ 的增加而逐渐被抑制。\n- 精确秩亏的超定系统，其中 $A^\\top A$ 是奇异的，使得正则化不可或缺；这里对于任何 $\\lambda  0$，$M(\\lambda)$ 都变得正定，而路径 $x(\\lambda)$ 揭示了随着 $\\lambda$ 增长的稳定化趋势。\n\n每个测试用例的算法步骤：\n1. 根据规范构建 $(A,b)$；用种子 $0$ 初始化伪随机数生成器 (PRNG) 并一致地使用它。\n2. 对于每个 $\\lambda \\in \\Lambda$，构建 $M(\\lambda) = A^\\top A + \\lambda I$ 和 $y = A^\\top b$，使用数值稳定的对称正定矩阵求解器求解 $M(\\lambda) x(\\lambda) = y$（这里通用求解器即可，因为 $\\lambda  0$）。\n3. 通过奇异值计算 $\\kappa_2\\!\\left(M(\\lambda)\\right)$ 并记录 $\\lVert x(\\lambda) \\rVert_2$。\n4. 使用给定公式和 $10^{-300}$ 保护措施（以避免除以零）为连续的 $\\lambda$ 对计算 $s_k$。\n5. 使用阈值标准确定 $\\lambda_{\\text{dom}}$ 和 $\\lambda_{\\text{stab}}$，并计算 $\\mu$。\n6. 为每个测试用例输出列表 $[\\lambda_{\\text{dom}}, \\lambda_{\\text{stab}}, \\mu]$。\n7. 将三个测试用例的最终聚合列表打印在单行上，格式如指定，不含任何空白字符。\n\n这种基于第一性原理的方法仅使用核心定义和最优性条件，同时揭示了系统矩阵的条件数如何控制正则化路径在 $\\lambda$ 跨越多个数量级时的行为。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef hilbert_matrix(n: int) - np.ndarray:\n    # Zero-based indices: H[i,j] = 1 / (i + j + 1)\n    i = np.arange(n).reshape(-1, 1)\n    j = np.arange(n).reshape(1, -1)\n    return 1.0 / (i + j + 1.0)\n\ndef compute_regularization_path_metrics(A: np.ndarray, b: np.ndarray, lambdas: list,\n                                        kappa_dom: float, tau_dom: float,\n                                        kappa_stab: float, tau_stab: float) - list:\n    # Precompute\n    AtA = A.T @ A\n    Atb = A.T @ b\n    m = AtA.shape[0]\n    x_list = []\n    kappa_list = []\n    # Compute x(lambda) and condition numbers\n    for lam in lambdas:\n        M = AtA + lam * np.eye(m)\n        # Solve M x = Atb\n        x = np.linalg.solve(M, Atb)\n        x_list.append(x)\n        # 2-norm condition number via SVD ratio\n        svals = np.linalg.svd(M, compute_uv=False)\n        # Guard against zero singular values (shouldn't occur due to lam  0)\n        smax = svals[0]\n        smin = svals[-1]\n        kappa = smax / smin if smin  0 else np.inf\n        kappa_list.append(kappa)\n    # Relative path changes s_k\n    s_list = []\n    norms = [np.linalg.norm(x) for x in x_list]\n    tiny_guard = 1e-300\n    for k in range(len(lambdas) - 1):\n        diff = np.linalg.norm(x_list[k+1] - x_list[k])\n        denom = max(norms[k], tiny_guard)\n        s_list.append(diff / denom)\n    # Dominated regime: largest lambda_k with both conditions true at step k\n    dominated_indices = [\n        k for k in range(len(lambdas) - 1)\n        if (kappa_list[k] = kappa_dom and s_list[k] = tau_dom)\n    ]\n    lambda_dom = lambdas[max(dominated_indices)] if dominated_indices else 0.0\n    # Stable regime onset: first lambda_{k+1} with both conditions true for step k\n    stable_index = None\n    for k in range(len(lambdas) - 1):\n        if (kappa_list[k+1] = kappa_stab) and (s_list[k] = tau_stab):\n            stable_index = k + 1\n            break\n    lambda_stab = lambdas[stable_index] if stable_index is not None else lambdas[-1]\n    # Monotonicity score: fraction of steps where ||x_{k+1}|| = ||x_k||\n    monotone_count = sum(1 for k in range(len(lambdas) - 1) if norms[k+1] = norms[k])\n    monotonicity_score = monotone_count / (len(lambdas) - 1)\n    return [lambda_dom, lambda_stab, monotonicity_score]\n\ndef format_results_no_whitespace(results: list) - str:\n    def fmt_val(v):\n        # Use default str to preserve scientific notation, ensure no spaces via manual joining\n        return str(v)\n    def fmt_list(lst):\n        return \"[\" + \",\".join(fmt_val(x) for x in lst) + \"]\"\n    return \"[\" + \",\".join(fmt_list(r) for r in results) + \"]\"\n\ndef solve():\n    # Lambda grid spanning orders of magnitude\n    lambdas = [1e-12,1e-10,1e-8,1e-6,1e-4,1e-2,1.0,1e2]\n    # Thresholds\n    kappa_dom = 1e12\n    tau_dom = 0.5\n    kappa_stab = 1e6\n    tau_stab = 0.05\n\n    results = []\n\n    # Test Case 1: Hilbert matrix (n=m=6), b=ones\n    n1 = 6\n    A1 = hilbert_matrix(n1)\n    b1 = np.ones(n1)\n    res1 = compute_regularization_path_metrics(A1, b1, lambdas, kappa_dom, tau_dom, kappa_stab, tau_stab)\n    results.append(res1)\n\n    # Initialize PRNG\n    rng = np.random.default_rng(0)\n\n    # Test Case 2: Near-collinear columns, overdetermined (n=60, m=10)\n    n2, m2 = 60, 10\n    u = rng.standard_normal(n2)\n    epsilon = 1e-8\n    A2 = np.empty((n2, m2))\n    for j in range(m2):\n        eta_j = rng.standard_normal(n2)\n        A2[:, j] = u + epsilon * eta_j\n    b2 = rng.standard_normal(n2)\n    res2 = compute_regularization_path_metrics(A2, b2, lambdas, kappa_dom, tau_dom, kappa_stab, tau_stab)\n    results.append(res2)\n\n    # Test Case 3: Rank-deficient, overdetermined (n=30, m=6), last col = sum of first two\n    n3, m3 = 30, 6\n    A3 = rng.standard_normal((n3, m3))\n    A3[:, 5] = A3[:, 0] + A3[:, 1]\n    b3 = rng.standard_normal(n3)\n    res3 = compute_regularization_path_metrics(A3, b3, lambdas, kappa_dom, tau_dom, kappa_stab, tau_stab)\n    results.append(res3)\n\n    # Final print statement in the exact required format: single line, no whitespace\n    print(format_results_no_whitespace(results))\n\nsolve()\n```", "id": "3141589"}, {"introduction": "正则化为何有效？它并非没有代价，其核心在于一种深刻的统计学权衡。本练习将使用截断奇异值分解（Truncated SVD）这一正则化方法[@problem_id:3141620]，带你深入剖析这一被称为偏差-方差权衡（bias-variance trade-off）的核心机制。通过显式地计算偏差和方差项，你将量化地看到，有选择地忽略那些与微小奇异值相关、会导致解不稳定的信息，会如何引入一个可控的系统性误差（偏差），但作为交换，能够极大地降低解对数据噪声的敏感度（方差）。", "problem": "考虑线性模型 $y = A x_{\\mathrm{true}} + \\varepsilon$，其中 $A \\in \\mathbb{R}^{n \\times n}$，$x_{\\mathrm{true}} \\in \\mathbb{R}^{n}$ 是一个未知向量，$\\varepsilon \\in \\mathbb{R}^{n}$ 表示测量噪声，其分量是独立同分布的，均值为零，方差为 $\\sigma_{\\varepsilon}^2$。设矩阵 $A$ 通过奇异值分解（SVD）进行因式分解，即奇异值分解（SVD）表示为 $A = U \\Sigma V^{\\top}$，其中 $U \\in \\mathbb{R}^{n \\times n}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{n \\times n}$ 是对角矩阵，其非负对角元为 $\\sigma_1 \\ge \\sigma_2 \\ge \\cdots \\ge \\sigma_n \\ge 0$。\n\n当存在小的奇异值时，由于噪声放大效应，直接求逆来求解 $x_{\\mathrm{true}}$ 的估计值可能是病态的。一种常见的稳定化方法是截断SVD估计量，它只保留前 $k$ 个奇异分量。使用统计估计中偏差和方差的定义，其中估计量 $\\hat{x}$ 的偏差定义为 $\\mathrm{bias}(\\hat{x}) = \\mathbb{E}[\\hat{x}] - x_{\\mathrm{true}}$，估计量 $\\hat{x}$ 的方差由其与其均值的平方偏差的期望来量化，推导截断小奇异值如何影响解的偏差和方差，并实现一个程序，对于给定的 $k$ 和 $\\sigma_{\\varepsilon}^2$ 值，计算截断SVD估计量的偏差的平方范数和方差项。\n\n使用以下实例进行计算：\n- 设 $n = 6$，并设 $A$ 为对角矩阵，其对角元为 $\\sigma_1 = 10^{0}$，$\\sigma_2 = 10^{-1}$，$\\sigma_3 = 10^{-2}$，$\\sigma_4 = 10^{-3}$，$\\sigma_5 = 10^{-4}$，$\\sigma_6 = 10^{-5}$，因此 $A = \\mathrm{diag}(10^{0}, 10^{-1}, 10^{-2}, 10^{-3}, 10^{-4}, 10^{-5})$。\n- 设 $x_{\\mathrm{true}} = [\\,1,\\,0.5,\\,0.25,\\,0.125,\\,0.0625,\\,0.03125\\,]^{\\top}$。\n- 假设噪声向量 $\\varepsilon$ 的分量服从均值为零、方差为 $\\sigma_{\\varepsilon}^2$ 的分布，并且与 $x_{\\mathrm{true}}$ 无关。\n\n从基本定义和SVD结构出发，程序必须：\n- 计算 $A$ 的SVD以获得 $(U,\\Sigma,V)$。\n- 构建保留前 $k$ 个奇异值的截断SVD估计量。\n- 使用该估计量以及偏差和方差的定义，根据给定的噪声模型，计算偏差的平方$\\ell_2$范数 $\\|\\mathrm{bias}(\\hat{x}_k)\\|_2^2$ 和 $\\hat{x}_k$ 的方差项，并用从SVD获得的奇异值和奇异向量表示。\n\n测试套件：\n对以下参数值 $(k, \\sigma_{\\varepsilon}^2)$ 进行计算评估：\n1. $(k, \\sigma_{\\varepsilon}^2) = (3, 10^{-6})$。\n2. $(k, \\sigma_{\\varepsilon}^2) = (0, 10^{-6})$。\n3. $(k, \\sigma_{\\varepsilon}^2) = (6, 10^{-6})$。\n4. $(k, \\sigma_{\\varepsilon}^2) = (2, 10^{-10})$。\n5. $(k, \\sigma_{\\varepsilon}^2) = (4, 10^{-4})$。\n\n要求的最终输出格式：\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。每个测试用例对应一个内部列表，包含两个浮点数，顺序为 $[\\|\\mathrm{bias}(\\hat{x}_k)\\|_2^2, \\mathrm{variance\\ term}]$。例如，输出应类似于 $[[b_1,v_1],[b_2,v_2],\\dots]$，五个内部列表的顺序与上述测试套件完全一致。", "solution": "目标是推导并计算一个线性方程组的截断奇异值分解（SVD）估计量的偏差的平方范数和方差。线性模型由 $y = A x_{\\mathrm{true}} + \\varepsilon$ 给出，其中 $A \\in \\mathbb{R}^{n \\times n}$，$x_{\\mathrm{true}} \\in \\mathbb{R}^{n}$ 是真实解向量，$\\varepsilon \\in \\mathbb{R}^{n}$ 是一个噪声向量，其分量是独立同分布的，均值为 $0$，方差为 $\\sigma_{\\varepsilon}^2$。\n\n矩阵 $A$ 的SVD为 $A = U \\Sigma V^{\\top}$，其中 $U$ 和 $V$ 是正交矩阵，$\\Sigma$ 是由奇异值 $\\sigma_1 \\ge \\dots \\ge \\sigma_n \\ge 0$ 构成的对角矩阵。当某些 $\\sigma_i$ 很小时，标准的最小二乘解 $\\hat{x} = A^{-1}y = V \\Sigma^{-1} U^{\\top} y$ 容易受到噪声放大的影响。\n\n截断SVD估计量 $\\hat{x}_k$ 通过使用一个截断伪逆 $A_k^\\dagger$ 来缓解这个问题，该伪逆只对前 $k$ 个最大的奇异值求逆。\n截断伪逆定义为 $A_k^\\dagger = V \\Sigma_k^\\dagger U^{\\top}$，其中 $\\Sigma_k^\\dagger$ 是一个对角矩阵，其对角元为：\n$$\n(\\Sigma_k^\\dagger)_{ii} =\n\\begin{cases}\n1/\\sigma_i  \\text{if } i \\le k \\\\\n0  \\text{if } i  k\n\\end{cases}\n$$\n于是估计量为 $\\hat{x}_k = A_k^\\dagger y$。代入 $y = A x_{\\mathrm{true}} + \\varepsilon$：\n$$\n\\hat{x}_k = A_k^\\dagger (A x_{\\mathrm{true}} + \\varepsilon) = (V \\Sigma_k^\\dagger U^{\\top}) (U \\Sigma V^{\\top} x_{\\mathrm{true}} + \\varepsilon)\n$$\n利用 $U$ 的正交性（$U^{\\top}U = I$），我们得到：\n$$\n\\hat{x}_k = V \\Sigma_k^\\dagger \\Sigma V^{\\top} x_{\\mathrm{true}} + V \\Sigma_k^\\dagger U^{\\top} \\varepsilon\n$$\n乘积 $\\Sigma_k^\\dagger \\Sigma$ 是一个对角矩阵，我们称之为 $P_k$，其对角元当 $i \\le k$ 时为 $(P_k)_{ii} = 1$，当 $i  k$ 时为 $0$。因此，$\\hat{x}_k$ 简化为：\n$$\n\\hat{x}_k = V P_k V^{\\top} x_{\\mathrm{true}} + V \\Sigma_k^\\dagger U^{\\top} \\varepsilon\n$$\n\n**1. 偏差的推导**\n\n估计量 $\\hat{x}_k$ 的偏差定义为 $\\mathrm{bias}(\\hat{x}_k) = \\mathbb{E}[\\hat{x}_k] - x_{\\mathrm{true}}$。我们首先计算 $\\hat{x}_k$ 的期望值。由于 $\\mathbb{E}[\\varepsilon] = 0$，第二项的期望为零：\n$$\n\\mathbb{E}[\\hat{x}_k] = \\mathbb{E}[V P_k V^{\\top} x_{\\mathrm{true}} + V \\Sigma_k^\\dagger U^{\\top} \\varepsilon] = V P_k V^{\\top} x_{\\mathrm{true}} + V \\Sigma_k^\\dagger U^{\\top} \\mathbb{E}[\\varepsilon] = V P_k V^{\\top} x_{\\mathrm{true}}\n$$\n因此，偏差为：\n$$\n\\mathrm{bias}(\\hat{x}_k) = V P_k V^{\\top} x_{\\mathrm{true}} - x_{\\mathrm{true}}\n$$\n使用恒等式 $I = V V^{\\top}$，我们可以将 $x_{\\mathrm{true}}$ 写为 $x_{\\mathrm{true}} = V V^{\\top} x_{\\mathrm{true}}$：\n$$\n\\mathrm{bias}(\\hat{x}_k) = V P_k V^{\\top} x_{\\mathrm{true}} - V V^{\\top} x_{\\mathrm{true}} = V (P_k - I) V^{\\top} x_{\\mathrm{true}}\n$$\n矩阵 $(P_k - I)$ 是对角矩阵，其对角元当 $i \\le k$ 时为 $(P_k-I)_{ii} = 0$，当 $i  k$ 时为 $(P_k-I)_{ii} = -1$。\n偏差的平方$\\ell_2$范数为 $\\|\\mathrm{bias}(\\hat{x}_k)\\|_2^2$。由于 $V$ 是一个正交矩阵，它保持$\\ell_2$范数不变，即对于任意向量 $z$，都有 $\\|Vz\\|_2 = \\|z\\|_2$。\n$$\n\\|\\mathrm{bias}(\\hat{x}_k)\\|_2^2 = \\|V (P_k - I) V^{\\top} x_{\\mathrm{true}}\\|_2^2 = \\|(P_k - I) V^{\\top} x_{\\mathrm{true}}\\|_2^2\n$$\n设 $z = V^{\\top} x_{\\mathrm{true}}$。$z$ 的分量为 $z_i = v_i^{\\top} x_{\\mathrm{true}}$，其中 $v_i$ 是 $V$ 的第 $i$ 列。向量 $(P_k - I)z$ 的分量在 $i \\le k$ 时为 $0$，在 $i  k$ 时为 $-z_i$。其平方范数为：\n$$\n\\|\\mathrm{bias}(\\hat{x}_k)\\|_2^2 = \\sum_{i=k+1}^{n} (-z_i)^2 = \\sum_{i=k+1}^{n} (v_i^{\\top} x_{\\mathrm{true}})^2\n$$\n这表明偏差来源于丢弃 $x_{\\mathrm{true}}$ 在对应于被截断奇异值的右奇异向量上的投影分量。\n\n**2. 方差的推导**\n\n方差项定义为与均值的平方偏差的期望：$\\mathrm{Var}(\\hat{x}_k) = \\mathbb{E}[\\|\\hat{x}_k - \\mathbb{E}[\\hat{x}_k]\\|_2^2]$。\n根据我们之前的表达式：\n$$\n\\hat{x}_k - \\mathbb{E}[\\hat{x}_k] = V \\Sigma_k^\\dagger U^{\\top} \\varepsilon\n$$\n那么方差项为：\n$$\n\\mathrm{Var}(\\hat{x}_k) = \\mathbb{E}[\\|V \\Sigma_k^\\dagger U^{\\top} \\varepsilon\\|_2^2]\n$$\n同样，由于 $V$ 是一个等距同构，这可以简化为：\n$$\n\\mathrm{Var}(\\hat{x}_k) = \\mathbb{E}[\\|\\Sigma_k^\\dagger U^{\\top} \\varepsilon\\|_2^2]\n$$\n我们定义一个新的随机向量 $\\eta = U^{\\top} \\varepsilon$。$\\eta$ 的协方差为 $\\mathrm{Cov}(\\eta) = U^{\\top} \\mathrm{Cov}(\\varepsilon) U$。鉴于 $\\varepsilon$ 的分量是独立同分布的，方差为 $\\sigma_{\\varepsilon}^2$，其协方差矩阵为 $\\mathrm{Cov}(\\varepsilon) = \\sigma_{\\varepsilon}^2 I$。因此：\n$$\n\\mathrm{Cov}(\\eta) = U^{\\top} (\\sigma_{\\varepsilon}^2 I) U = \\sigma_{\\varepsilon}^2 U^{\\top} U = \\sigma_{\\varepsilon}^2 I\n$$\n这意味着分量 $\\eta_i$ 也是不相关的，均值为 $0$，方差为 $\\sigma_{\\varepsilon}^2$。\n向量 $\\Sigma_k^\\dagger \\eta$ 的分量在 $i \\le k$ 时为 $(\\Sigma_k^\\dagger \\eta)_i = (1/\\sigma_i)\\eta_i$，在 $i  k$ 时为 $0$。其平方范数为 $\\sum_{i=1}^{k} (\\eta_i/\\sigma_i)^2$。\n取期望：\n$$\n\\mathrm{Var}(\\hat{x}_k) = \\mathbb{E}\\left[\\sum_{i=1}^{k} \\frac{\\eta_i^2}{\\sigma_i^2}\\right] = \\sum_{i=1}^{k} \\frac{\\mathbb{E}[\\eta_i^2]}{\\sigma_i^2}\n$$\n由于 $\\eta_i$ 的均值为 $0$，方差为 $\\sigma_{\\varepsilon}^2$，我们有 $\\mathbb{E}[\\eta_i^2] = \\mathrm{Var}(\\eta_i) + (\\mathbb{E}[\\eta_i])^2 = \\sigma_{\\varepsilon}^2 + 0 = \\sigma_{\\varepsilon}^2$。\n方差项的最终表达式为：\n$$\n\\mathrm{Var}(\\hat{x}_k) = \\sum_{i=1}^{k} \\frac{\\sigma_{\\varepsilon}^2}{\\sigma_i^2} = \\sigma_{\\varepsilon}^2 \\sum_{i=1}^{k} \\frac{1}{\\sigma_i^2}\n$$\n这表明方差是由于保留下来的奇异值的倒数对噪声的放大作用所致。\n\n**3. 对特定问题实例的应用**\n\n对于给定的问题，矩阵 $A$ 是对角矩阵：$A = \\mathrm{diag}(10^{0}, 10^{-1}, \\dots, 10^{-5})$。对于一个非负对角矩阵，其SVD是平凡的：$U=I$，$V=I$，且 $\\Sigma=A$。奇异值 $\\sigma_i$ 是 $A$ 的对角元，右奇异向量 $v_i$ 是标准基向量 $e_i$。\n\n通过这些简化，我们的公式变为：\n- **偏差的平方范数**：由于 $v_i = e_i$，投影 $v_i^{\\top} x_{\\mathrm{true}}$ 就是 $x_{\\mathrm{true}}$ 的第 $i$ 个分量，记为 $x_{\\mathrm{true},i}$。\n  $$\n  \\|\\mathrm{bias}(\\hat{x}_k)\\|_2^2 = \\sum_{i=k+1}^{n} (x_{\\mathrm{true},i})^2\n  $$\n- **方差项**：公式保持不变，但我们使用特定的奇异值。\n  $$\n  \\mathrm{Var}(\\hat{x}_k) = \\sigma_{\\varepsilon}^2 \\sum_{i=1}^{k} \\frac{1}{\\sigma_i^2}\n  $$\n\n具体值为：\n- $n=6$\n- $\\sigma_i = 10^{-(i-1)}$ for $i=1, \\dots, 6$。\n- $x_{\\mathrm{true}} = [1, 0.5, 0.25, 0.125, 0.0625, 0.03125]^{\\top} = [2^{0}, 2^{-1}, 2^{-2}, 2^{-3}, 2^{-4}, 2^{-5}]^{\\top}$。\n\n现在我们可以通过应用这些公式为每个测试用例计算所需的量。对于给定的 $k$ 和 $\\sigma_{\\varepsilon}^2$，我们对偏差，将 $x_{\\mathrm{true}}$ 从索引 $k$ 到 $n-1$ 的分量的平方求和（在实现中使用基于0的索引）；对于方差，我们计算直到索引 $k-1$ 的逆奇异值平方的加权和。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the squared bias norm and variance for the truncated SVD estimator\n    for a given linear system and a set of test cases.\n    \"\"\"\n    # Define the parameters of the problem instance.\n    n = 6\n    # Singular values: sigma_i = 10^-(i-1) for i=1,...,6\n    sigmas = np.array([10.0**(-i) for i in range(n)])\n    \n    # True solution vector: x_true_i = (1/2)^(i-1) for i=1,...,6\n    # using 0-based indexing for numpy array\n    x_true = np.array([0.5**i for i in range(n)])\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (k, sigma_epsilon_squared)\n        (3, 10**-6),\n        (0, 10**-6),\n        (6, 10**-6),\n        (2, 10**-10),\n        (4, 10**-4),\n    ]\n\n    results = []\n    for k, sigma_eps_sq in test_cases:\n        # Calculate the squared L2 norm of the bias.\n        # Bias is due to truncating components from k to n.\n        # In 0-based indexing, this corresponds to components from index k to n-1.\n        # If k=n, the slice x_true[n:] is empty, and the sum is correctly 0.\n        # If k=0, the slice x_true[0:] is the whole array, giving ||x_true||^2.\n        bias_sq_norm = np.sum(x_true[k:]**2)\n\n        # Calculate the variance term.\n        # Variance is due to noise amplification by the kept singular values (1 to k).\n        # In 0-based indexing, this corresponds to sigmas from index 0 to k-1.\n        # If k=0, the slice sigmas[:0] is empty, and the sum is correctly 0.\n        if k > 0:\n            variance_term = sigma_eps_sq * np.sum(1.0 / sigmas[:k]**2)\n        else:\n            variance_term = 0.0\n        \n        results.append([bias_sq_norm, variance_term])\n\n    # Format the output string to exactly match the required format:\n    # [[b_1,v_1],[b_2,v_2],...] with no spaces.\n    inner_strings = [f\"[{b},{v}]\" for b, v in results]\n    output_string = f\"[{','.join(inner_strings)}]\"\n    \n    # Final print statement in the exact required format.\n    print(output_string)\n\nsolve()\n```", "id": "3141620"}]}