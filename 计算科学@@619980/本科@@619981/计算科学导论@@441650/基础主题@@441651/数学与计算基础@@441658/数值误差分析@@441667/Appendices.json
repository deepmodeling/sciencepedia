{"hands_on_practices": [{"introduction": "在数值计算中，两个相近的数相减会导致灾难性的精度损失，即“灾难性抵消”。然而，有时通过巧妙的代数变换，我们可以完全避免这种问题。本练习将引导你推导一个双指数函数的稳定计算公式，这是一种在物理和工程领域常见的模式，并在这个过程中了解一个重要的数值稳定工具：`expm1` 函数。[@problem_id:3165829]", "problem": "考虑计算双指数差 $S(t;\\tau_1,\\tau_2) = \\exp(-t/\\tau_1) - \\exp(-t/\\tau_2)$，其中 $t \\ge 0$，时间常数 $\\tau_1 > 0$ 和 $\\tau_2 > 0$ 严格为正且可能非常接近，即 $\\tau_1 \\approx \\tau_2$。在电气和电子工程师协会（IEEE）$754$ binary64 算术（通常称为双精度）的标准浮点舍入模型中进行计算，其中每个基本运算都建模为 $\\mathrm{fl}(z) = z(1+\\delta)$，对于机器ε $\\epsilon_{\\mathrm{mach}}$，有 $|\\delta| \\le \\epsilon_{\\mathrm{mach}}$。使用绝对误差 $|x - \\hat{x}|$ 和相对误差 $|x - \\hat{x}|/|x|$ 的核心定义，以及在减去近似相等的量时发生灾难性抵消的概念。\n\n从这些基础出发，分析通过分别计算两个指数函数然后相减的方式在浮点数中计算 $S(t;\\tau_1,\\tau_2)$ 的朴素减法的数值稳定性。推导朴素减法相对误差的一个界，该界用 $\\epsilon_{\\mathrm{mach}}$、 $|\\exp(-t/\\tau_1)|$、 $|\\exp(-t/\\tau_2)|$ 和 $|S(t;\\tau_1,\\tau_2)|$ 表示，并解释为什么当 $\\tau_1 \\to \\tau_2$ 时该界会变大（灾难性抵消）。然后，通过基于指数函数性质的精确代数变换，并利用特殊函数 `expm1(x)`（该函数在 $|x|$ 很小时能以高相对精度计算 $\\exp(x) - 1$），推导出一个 $S(t;\\tau_1,\\tau_2)$ 的代数等价表达式，该表达式通过在 $\\tau_1 \\approx \\tau_2$ 时将差值表示为对一个小参数的单个缩放后的 `expm1` 调用，从而避免了近似相等数的减法。\n\n仅报告用 $t$、$\\tau_1$、$\\tau_2$ 和 `expm1(·)` 表示的 $S(t;\\tau_1,\\tau_2)$ 的最终闭式稳定表达式。无需进行数值计算。", "solution": "问题要求分析计算双指数差 $S(t;\\tau_1,\\tau_2) = \\exp(-t/\\tau_1) - \\exp(-t/\\tau_2)$ 的数值稳定性，并推导一个数值稳定的替代表达式。根据要求，分析将分两部分进行：首先，对朴素计算方法进行误差分析；其次，使用代数重构推导一个稳定公式。\n\n我们从误差分析开始。问题设定为 $t \\ge 0$、$\\tau_1 > 0$ 和 $\\tau_2 > 0$，重点关注 $\\tau_1 \\approx \\tau_2$ 的情况。设各项的真实值为 $x_1 = \\exp(-t/\\tau_1)$ 和 $x_2 = \\exp(-t/\\tau_2)$。精确差值为 $S = x_1 - x_2$。\n\n在浮点算术中，朴素计算首先计算两个指数项，然后将它们相减。设 $\\hat{x}_1$ 和 $\\hat{x}_2$ 为 $x_1$ 和 $x_2$ 计算得到的浮点表示。我们使用浮点算术的标准模型，其中像 $\\exp$ 这样的函数求值和基本算术运算会引入一个小的相对误差。因此，我们可以将计算值建模为：\n$$ \\hat{x}_1 = \\mathrm{fl}(\\exp(-t/\\tau_1)) = x_1(1+\\delta_1), \\quad |\\delta_1| \\le \\epsilon_{\\mathrm{mach}} $$\n$$ \\hat{x}_2 = \\mathrm{fl}(\\exp(-t/\\tau_2)) = x_2(1+\\delta_2), \\quad |\\delta_2| \\le \\epsilon_{\\mathrm{mach}} $$\n这里，$\\epsilon_{\\mathrm{mach}}$ 是机器ε，我们假设计算参数 $-t/\\tau_1$ 和 $-t/\\tau_2$ 的误差被包含在计算指数函数的总误差中，这对于此级别的分析来说是一个标准的简化。最终计算值 $\\hat{S}$ 是在浮点算术中将这两个计算值相减的结果：\n$$ \\hat{S} = \\mathrm{fl}(\\hat{x}_1 - \\hat{x}_2) = (\\hat{x}_1 - \\hat{x}_2)(1+\\delta_3), \\quad |\\delta_3| \\le \\epsilon_{\\mathrm{mach}} $$\n为了分析误差，我们求计算值 $\\hat{S}$ 和真实值 $S$ 之间的差值。\n$$ \\hat{S} = (x_1(1+\\delta_1) - x_2(1+\\delta_2))(1+\\delta_3) $$\n$$ \\hat{S} = (x_1 - x_2 + x_1\\delta_1 - x_2\\delta_2)(1+\\delta_3) $$\n由于 $S = x_1 - x_2$，我们有：\n$$ \\hat{S} = (S + x_1\\delta_1 - x_2\\delta_2)(1+\\delta_3) $$\n展开此表达式得到：\n$$ \\hat{S} = S + S\\delta_3 + x_1\\delta_1 - x_2\\delta_2 + (x_1\\delta_1 - x_2\\delta_2)\\delta_3 $$\n绝对误差为 $\\hat{S} - S$：\n$$ \\hat{S} - S = S\\delta_3 + x_1\\delta_1 - x_2\\delta_2 + (x_1\\delta_1 - x_2\\delta_2)\\delta_3 $$\n忽略与 $\\epsilon_{\\mathrm{mach}}^2$ 成正比的高阶项 $(x_1\\delta_1 - x_2\\delta_2)\\delta_3$，绝对误差近似为：\n$$ \\hat{S} - S \\approx x_1\\delta_1 - x_2\\delta_2 + S\\delta_3 $$\n相对误差为 $\\frac{|\\hat{S} - S|}{|S|}$。对绝对误差的近似值使用三角不等式，我们可以建立一个界：\n$$ |\\hat{S} - S| \\lesssim |x_1\\delta_1| + |x_2\\delta_2| + |S\\delta_3| $$\n$$ |\\hat{S} - S| \\lesssim |x_1||\\delta_1| + |x_2||\\delta_2| + |S||\\delta_3| $$\n将每个 $\\delta_i$ 的界 $|\\delta_i| \\le \\epsilon_{\\mathrm{mach}}$ 代入：\n$$ |\\hat{S} - S| \\lesssim (|x_1| + |x_2| + |S|) \\epsilon_{\\mathrm{mach}} $$\n因此，相对误差的界为：\n$$ \\frac{|\\hat{S} - S|}{|S|} \\lesssim \\frac{|x_1| + |x_2| + |S|}{|S|} \\epsilon_{\\mathrm{mach}} = \\left(1 + \\frac{|x_1| + |x_2|}{|S|}\\right) \\epsilon_{\\mathrm{mach}} $$\n代入 $x_1$、$x_2$ 和 $S$ 的原始表达式：\n$$ \\frac{|\\hat{S} - S|}{|S|} \\lesssim \\left(1 + \\frac{|\\exp(-t/\\tau_1)| + |\\exp(-t/\\tau_2)|}{|\\exp(-t/\\tau_1) - \\exp(-t/\\tau_2)|}\\right) \\epsilon_{\\mathrm{mach}} $$\n这个界解释了数值不稳定性。当 $\\tau_1 \\to \\tau_2$ 时，指数函数的参数变得近似相等，即 $-t/\\tau_1 \\approx -t/\\tau_2$。因此，它们的值也变得近似相等：$\\exp(-t/\\tau_1) \\approx \\exp(-t/\\tau_2)$。误差界中分数的分母 $|S| = |\\exp(-t/\\tau_1) - \\exp(-t/\\tau_2)|$ 趋近于 $0$。然而，对于 $t>0$，分子 $|\\exp(-t/\\tau_1)| + |\\exp(-t/\\tau_2)|$ 趋近于 $2\\exp(-t/\\tau)$，其中 $\\tau$ 是 $\\tau_1$ 和 $\\tau_2$ 的共同极限。因此，比率 $\\frac{|\\exp(-t/\\tau_1)| + |\\exp(-t/\\tau_2)|}{|S|}$ 无界增长。这个大因子乘以机器ε，导致计算结果 $\\hat{S}$ 中可能出现大的相对误差。这种两个近似相等的数相减导致相对精度损失的现象，被称为灾难性抵消。\n\n为避免这种数值不稳定性，我们必须对表达式 $S(t;\\tau_1,\\tau_2)$ 进行代数重构。目标是避免近似相等量的直接减法。问题建议使用函数 `expm1(x)`，其定义为 $\\mathrm{expm1}(x) = \\exp(x) - 1$，并且它的实现即使在 $|x|$ 很小时也能返回具有高相对精度的结果。\n\n我们从原始表达式开始：\n$$ S(t;\\tau_1,\\tau_2) = \\exp(-t/\\tau_1) - \\exp(-t/\\tau_2) $$\n我们可以提出一个指数项作为公因子。让我们提出 $\\exp(-t/\\tau_2)$：\n$$ S = \\exp(-t/\\tau_2) \\left[ \\frac{\\exp(-t/\\tau_1)}{\\exp(-t/\\tau_2)} - 1 \\right] $$\n使用性质 $\\exp(a)/\\exp(b) = \\exp(a-b)$，我们简化方括号内的项：\n$$ S = \\exp(-t/\\tau_2) \\left[ \\exp\\left(-\\frac{t}{\\tau_1} - \\left(-\\frac{t}{\\tau_2}\\right)\\right) - 1 \\right] $$\n$$ S = \\exp(-t/\\tau_2) \\left[ \\exp\\left(-\\frac{t}{\\tau_1} + \\frac{t}{\\tau_2}\\right) - 1 \\right] $$\n我们可以从指数中提出 $t$ 并将分数合并：\n$$ -\\frac{t}{\\tau_1} + \\frac{t}{\\tau_2} = t \\left(\\frac{1}{\\tau_2} - \\frac{1}{\\tau_1}\\right) = t \\left(\\frac{\\tau_1 - \\tau_2}{\\tau_1 \\tau_2}\\right) $$\n将此代回 $S$ 的表达式中：\n$$ S = \\exp(-t/\\tau_2) \\left[ \\exp\\left(t \\frac{\\tau_1 - \\tau_2}{\\tau_1 \\tau_2}\\right) - 1 \\right] $$\n现在方括号内的项具有 $\\exp(x) - 1$ 的形式，其中 $x = t \\frac{\\tau_1 - \\tau_2}{\\tau_1 \\tau_2}$。因此，我们可以使用 `expm1` 函数来表示它：\n$$ S = \\exp(-t/\\tau_2) \\cdot \\mathrm{expm1}\\left(t \\frac{\\tau_1 - \\tau_2}{\\tau_1 \\tau_2}\\right) $$\n这个表达式是数值稳定的。当 $\\tau_1 \\approx \\tau_2$ 时，`expm1` 函数的参数 $x$ 变得很小。`expm1` 函数是专门设计用来以高相对精度处理小参数的。减法 $\\tau_1 - \\tau_2$ 是对输入数据进行的，这些数据通常是精确的浮点数；根据 Sterbenz 引理，这个减法本身通常是精确的。余下的运算是乘法和除法，它们在数值上是表现良好的。这个重构的表达式避免了朴素方法中的灾难性抵消，即使在 $\\tau_1$ 和 $\\tau_2$ 很接近时也能提供准确的结果。", "answer": "$$\\boxed{\\exp\\left(-\\frac{t}{\\tau_2}\\right) \\mathrm{expm1}\\left(t\\frac{\\tau_1 - \\tau_2}{\\tau_1 \\tau_2}\\right)}$$", "id": "3165829"}, {"introduction": "当简单的代数技巧不足以解决问题时，我们该怎么办？本练习在前一个概念的基础上，探讨了另一种强大的技术：针对小输入值使用泰勒级数展开。你将分析计算标准 $\\mathrm{sinc}$ 函数 $\\frac{\\sin x}{x}$ 时发生的数值崩溃，利用其级数形式实现一个更稳健的版本，并通过编程实验来验证其改进效果。[@problem_id:3212241]", "problem": "考虑函数 $$f(x) = \\begin{cases}\\dfrac{\\sin x}{x},  x \\neq 0, \\\\ 1,  x = 0.\\end{cases}$$ 其中角度以弧度为单位。本题旨在研究当 $x$ 很小时，使用标准浮点运算计算 $f(x)$ 所产生的有效数字损失问题，并设计一种数值稳定的替代方法，以精确捕捉微小的减量 $d(x) = 1 - f(x)$。\n\n从以下基本依据出发：\n- 关于 $x = 0$ 的正弦函数的泰勒级数：$\\sin x = x - \\dfrac{x^{3}}{3!} + \\dfrac{x^{5}}{5!} - \\cdots$。\n- 由 $f(x)$ 导出的级数及其相关的减量 $d(x)$：\n$$f(x) = 1 - \\dfrac{x^{2}}{3!} + \\dfrac{x^{4}}{5!} - \\cdots,\\quad d(x) = 1 - f(x) = \\dfrac{x^{2}}{3!} - \\dfrac{x^{4}}{5!} + \\dfrac{x^{6}}{7!} - \\cdots.$$\n- 标准浮点模型：对于基本运算 $\\circ \\in \\{+,-,\\times,\\div\\}$，$\\operatorname{fl}(a \\circ b) = (a \\circ b)(1 + \\delta)$，其中 $|\\delta| \\le u$，$u$ 是工作精度的单位舍入误差。\n\n任务：\n1. 基于上述依据，论证为何当 $x$ 很小时，直接计算 $\\operatorname{fl}(\\sin x)/\\operatorname{fl}(x)$ 对于 $f(x)$ 具有较小的相对误差，但在形成 $1 - \\operatorname{fl}(\\sin x)/\\operatorname{fl}(x)$ 时，会由于相减抵消而完全丢失关于减量 $d(x)$ 的信息。推导出一个用 $u$ 表示的阈值尺度，在该尺度下，朴素计算法无法可靠地解析 $d(x)$（以 $u$ 的渐近形式表示该阈值）。\n2. 设计一种稳定的、基于级数的求值方法，该方法：\n   - 对于 $|x|$ 小于一个基于 $u$ 的阈值 $\\,\\tau\\,$ 的情况，通过其交错级数计算 $d(x)$，然后仅在最后一步使用数值稳定的求和策略形成 $f(x) = 1 - d(x)$。\n   - 对于 $|x| \\ge \\tau$ 的情况，使用直接求值 $f(x) = \\sin(x)/x$。\n   - 通过返回 $f(0) = 1$ 来处理 $x = 0$ 处的可去奇点。\n3. 实现一个完整的、可运行的程序，该程序：\n   - 主要计算使用标准双精度浮点运算。\n   - 使用一个基于截断级数的高精度参考值，该级数通过任意精度算术计算，以近似得到具有多位正确数字的 $f(x)$ 和 $d(x)$ 的真实值。\n   - 对于每个测试输入 $x$，计算三个误差度量：\n     - 朴素 $f(x)$ 的相对误差：$\\left|\\dfrac{f_{\\text{naive}} - f_{\\text{ref}}}{f_{\\text{ref}}}\\right|$。\n     - 朴素减量 $d_{\\text{naive}} = 1 - f_{\\text{naive}}$ 相对于 $d_{\\text{ref}}$ 的相对误差：$\\left|\\dfrac{d_{\\text{naive}} - d_{\\text{ref}}}{d_{\\text{ref}}}\\right|$（如果 $d_{\\text{ref}} = 0$，则定义此值为 $0$）。\n     - 稳定级数减量 $d_{\\text{stable}}$ 相对于 $d_{\\text{ref}}$ 的相对误差：$\\left|\\dfrac{d_{\\text{stable}} - d_{\\text{ref}}}{d_{\\text{ref}}}\\right|$（如果 $d_{\\text{ref}} = 0$，则定义此值为 $0$）。\n   - 使用弧度，不涉及物理单位。\n\n测试集：\n- 对输入 $x \\in \\{0,\\;10^{-12},\\;10^{-10},\\;10^{-8},\\;-10^{-7},\\;10^{-7},\\;10^{-4},\\;10^{-1}\\}$ 评估程序。\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含一个以逗号分隔的列表的列表形式的结果，每个内部列表对应一个测试输入，并按上述顺序包含三个误差度量。例如：\"[[e11,e12,e13],[e21,e22,e23],...]\"，所有条目均为浮点数。角度单位为弧度，在计算或输出的任何地方都不得使用百分号。", "solution": "根据既定标准对问题进行验证。\n\n### 步骤1：提取已知条件\n- **函数定义**：$$f(x) = \\begin{cases}\\dfrac{\\sin x}{x},  x \\neq 0, \\\\ 1,  x = 0.\\end{cases}$$，以弧度为单位计算。\n- **减量定义**：$d(x) = 1 - f(x)$。\n- **正弦的泰勒级数**：$\\sin x = x - \\dfrac{x^{3}}{3!} + \\dfrac{x^{5}}{5!} - \\cdots$。\n- **$f(x)$ 和 $d(x)$ 的级数**：$f(x) = 1 - \\dfrac{x^{2}}{3!} + \\dfrac{x^{4}}{5!} - \\cdots$，以及 $d(x) = \\dfrac{x^{2}}{3!} - \\dfrac{x^{4}}{5!} + \\dfrac{x^{6}}{7!} - \\cdots$。\n- **浮点模型**：$\\operatorname{fl}(a \\circ b) = (a \\circ b)(1 + \\delta)$，其中 $|\\delta| \\le u$，$u$ 是单位舍入误差。\n- **任务1**：分析为何直接计算 $f(x)$ 具有较小的相对误差，但通过 $1 - f(x)$ 计算 $d(x)$ 时，对于小 $x$ 会遭受灾难性抵消。推导以 $u$ 表示的阈值尺度。\n- **任务2**：设计一种稳定的混合算法，当 $|x|  \\tau$ 时使用级数展开，当 $|x| \\ge \\tau$ 时使用直接求值。\n- **任务3**：实现一个程序，针对给定的测试集，计算三个指定的误差度量（朴素 $f(x)$ 的相对误差、朴素 $d(x)$ 的相对误差和稳定 $d(x)$ 的相对误差），并与高精度参考值进行比较。\n- **执行环境与精度**：主要计算使用双精度，参考值使用任意精度。\n- **测试集**：$x \\in \\{0,\\;10^{-12},\\;10^{-10},\\;10^{-8},\\;-10^{-7},\\;10^{-7},\\;10^{-4},\\;10^{-1}\\}$。\n- **输出格式**：表示误差度量列表的列表的单行字符串：`[[e11,e12,e13],[e21,e22,e23],...]`。\n\n### 步骤2：使用提取的已知条件进行验证\n该问题是数值分析中的一个标准练习，重点关注灾难性抵消，这是科学计算中的一个核心概念。\n- **科学基础（关键）**：该问题从根本上基于泰勒级数展开和标准浮点运算模型，这些都是数值方法的基石。它是科学合理的。\n- **适定性**：该问题是适定的。它清晰地定义了函数、待计算的量、要分析的方法以及预期的输出。存在唯一且有意义的解。\n- **客观性（关键）**：语言精确且数学化。没有主观或基于观点的陈述。\n该问题是自包含且一致的。关于“任意精度”参考值的要求可以通过使用 Python 标准库中的 `decimal` 模块来满足，这是允许的。所有其他标准均已满足。\n\n### 步骤3：结论与行动\n问题有效。将提供完整的解决方案。\n\n---\n\n### 数值误差分析与算法设计\n\n本解决方案解决了问题陈述中列出的三个任务：分析数值不稳定性、设计稳定算法以及实现并验证该算法。\n\n#### 1. 朴素计算中的数值误差分析\n\n我们使用标准浮点运算来分析在 $x$ 值很小时计算 $f(x)$ 和 $d(x)$ 的误差。\n\n**计算 $f(x)$ 的误差：**\n对于 $x \\neq 0$，$f(x)$ 的“朴素”计算是 $f_{\\text{naive}}(x) = \\operatorname{fl}(\\sin(x) / x)$。我们来对浮点误差建模。正弦函数的求值和除法运算会引入相对误差，其上界为单位舍入误差 $u$。\n首先，计算正弦函数：$\\operatorname{fl}(\\sin x) = (\\sin x)(1 + \\delta_1)$，其中 $|\\delta_1| \\le u$。\n然后，执行除法运算：\n$$ \\operatorname{fl}\\left(\\frac{\\operatorname{fl}(\\sin x)}{x}\\right) = \\left(\\frac{(\\sin x)(1 + \\delta_1)}{x}\\right)(1 + \\delta_2) = \\frac{\\sin x}{x}(1 + \\delta_1)(1 + \\delta_2) $$\n其中 $|\\delta_2| \\le u$。假设 $x$ 是一个精确的浮点数。\n令 $\\hat{f}(x)$ 表示计算值。展开误差项，我们得到：\n$$ \\hat{f}(x) = f(x)(1 + \\delta_1 + \\delta_2 + \\delta_1\\delta_2) \\approx f(x)(1 + \\delta_{\\text{f}}) $$\n其中 $\\delta_{\\text{f}} = \\delta_1 + \\delta_2$。计算 $f(x)$ 的总相对误差为：\n$$ \\left|\\frac{\\hat{f}(x) - f(x)}{f(x)}\\right| \\approx |\\delta_{\\text{f}}| \\le |\\delta_1| + |\\delta_2| \\le 2u $$\n这个相对误差很小，量级与单位舍入误差 $u$ 相当。因此，直接计算 $f(x)$ 在其整个定义域内都是数值稳定的。\n\n**计算 $d(x) = 1 - f(x)$ 的误差：**\n减量的朴素计算是 $\\hat{d}(x) = \\operatorname{fl}(1 - \\hat{f}(x))$。对于小 $x$，从泰勒级数我们知道 $f(x) = 1 - \\frac{x^2}{6} + O(x^4)$，这个值非常接近 1。减法 $1 - \\hat{f}(x)$ 是灾难性抵消的一个典型例子，即两个几乎相等的数相减，导致相对精度的潜在损失。\n\n我们来更形式化地分析这个问题。计算出的减量是：\n$$ \\hat{d}(x) = \\operatorname{fl}(1 - \\hat{f}(x)) = (1 - \\hat{f}(x))(1 + \\delta_3) \\quad \\text{with } |\\delta_3| \\le u $$\n代入 $\\hat{f}(x)$ 的表达式：\n$$ \\hat{d}(x) = (1 - f(x)(1 + \\delta_{\\text{f}}))(1 + \\delta_3) = (1 - f(x) - f(x)\\delta_{\\text{f}})(1 + \\delta_3) $$\n因为 $d(x) = 1 - f(x)$，上式变为：\n$$ \\hat{d}(x) = (d(x) - f(x)\\delta_{\\text{f}})(1 + \\delta_3) = d(x) - f(x)\\delta_{\\text{f}} + d(x)\\delta_3 - f(x)\\delta_{\\text{f}}\\delta_3 $$\n绝对误差为 $\\hat{d}(x) - d(x) \\approx -f(x)\\delta_{\\text{f}} + d(x)\\delta_3$。\n$d(x)$ 的相对误差为：\n$$ \\frac{\\hat{d}(x) - d(x)}{d(x)} \\approx \\frac{-f(x)\\delta_{\\text{f}} + d(x)\\delta_3}{d(x)} = -\\frac{f(x)}{d(x)}\\delta_{\\text{f}} + \\delta_3 $$\n对于小 $x$，我们有 $f(x) \\approx 1$ 和 $d(x) \\approx x^2/6$。误差由第一项主导：\n$$ \\left|\\frac{\\hat{d}(x) - d(x)}{d(x)}\\right| \\approx \\left|-\\frac{f(x)}{d(x)}\\delta_{\\text{f}}\\right| \\approx \\frac{1}{x^2/6}|\\delta_{\\text{f}}| = \\frac{6|\\delta_{\\text{f}}|}{x^2} $$\n使用界 $|\\delta_{\\text{f}}| \\le 2u$，相对误差的界为：\n$$ \\left|\\frac{\\hat{d}(x) - d(x)}{d(x)}\\right| \\lesssim \\frac{12u}{x^2} $$\n当这个相对误差达到 1 的量级或更大时，朴素计算变得不可靠。这种情况发生在 $12u/x^2 \\approx 1$ 时，这给出了阈值：\n$$ |x| \\approx \\sqrt{12u} $$\n对于双精度运算，$u = 2^{-53} \\approx 1.11 \\times 10^{-16}$。阈值是 $|x| \\approx \\sqrt{12 \\times 1.11 \\times 10^{-16}} \\approx 3.65 \\times 10^{-8}$。对于等于或小于此尺度的 $|x|$ 值，$d(x)$ 的朴素计算会丢失其大部分或全部有效数字。该阈值的渐近量级为 $O(\\sqrt{u})$。\n\n#### 2. 稳定算法的设计\n\n为了克服灾难性抵消，我们设计了一种混合算法，以避免在 $|x|$ 很小时出现有问题的减法运算。\n该算法如下：\n- 根据误差分析选择一个阈值 $\\tau$。对于双精度，一个实用的选择是 $\\tau = 10^{-7}$，它比完全有效数字损失的理论起点（$\\approx 3.65 \\times 10^{-8}$）稍大，从而提供了一个安全边际。\n- **对于 $|x|  \\tau$**：我们不先计算 $f(x)$，而是直接使用其泰勒级数展开来计算减量 $d(x)$：\n  $$ d(x) = \\frac{x^{2}}{3!} - \\frac{x^{4}}{5!} + \\frac{x^{6}}{7!} - \\cdots = \\sum_{k=1}^{\\infty} (-1)^{k-1} \\frac{x^{2k}}{(2k+1)!} $$\n  这是一个交错级数，对于 $|x|  1$，其项的绝对值会迅速减小。我们可以通过对少数几项求和来精确地计算 $d(x)$。这种方法是稳定的，因为它通过对其他小的、精确表示的值求和来构造小值 $d(x)$，而不是通过两个大的、几乎相等的数的差来得到。一旦找到了 $d_{\\text{stable}}(x)$ 的精确值，$f(x)$ 就可以计算为 $f_{\\text{stable}}(x) = 1 - d_{\\text{stable}}(x)$。这最后的减法不会遭受灾难性抵消，因为 $d_{\\text{stable}}(x)$ 是一个小的、被精确计算出的数。\n- **对于 $|x| \\ge \\tau$**：使用朴素计算 $f(x) = \\sin(x)/x$。在这个范围内，$f(x)$ 的值没有足够接近 1，因此在双精度数的背景下，减法 $1-f(x)$ 不会引起灾难性的精度损失。级数求值也会变得效率更低，并且可能因为需要更多项才能收敛而变得不那么准确。\n- **对于 $x=0$**：将函数作为特殊情况处理，根据定义返回 $f(0) = 1$ 和 $d(0)=0$。\n\n#### 3. 实现与验证\n\n实现将包括三个主要部分：\n1.  使用 Python 的 `decimal` 模块对 $f_{\\text{ref}}$ 和 $d_{\\text{ref}}$ 进行高精度参考计算。$d(x)$ 的级数非常适合此目的，通过对大量项求和以确保收敛到 50 位的精度。\n2.  朴素计算函数，$f_{\\text{naive}}(x) = \\sin(x)/x$ 和 $d_{\\text{naive}}(x) = 1 - f_{\\text{naive}}(x)$。\n3.  稳定计算函数，该函数实现上述混合算法以找到 $d_{\\text{stable}}(x)$。\n\n对于测试集中的每个输入 $x$，我们将计算所要求的三个相对误差：\n- $\\epsilon_1 = \\left|\\dfrac{f_{\\text{naive}} - f_{\\text{ref}}}{f_{\\text{ref}}}\\right|$\n- $\\epsilon_2 = \\left|\\dfrac{d_{\\text{naive}} - d_{\\text{ref}}}{d_{\\text{ref}}}\\right|$\n- $\\epsilon_3 = \\left|\\dfrac{d_{\\text{stable}} - d_{\\text{ref}}}{d_{\\text{ref}}}\\right|$\n\n对于 $x=0$ 的情况，$d_{\\text{ref}}=0$，误差度量 $\\epsilon_2$ 和 $\\epsilon_3$ 定义为 $0$。", "answer": "```python\nimport numpy as np\nfrom decimal import Decimal, getcontext\n\ndef solve():\n    \"\"\"\n    Solves the numerical analysis problem of computing f(x) = sin(x)/x and d(x) = 1-f(x).\n    It compares a naive method with a stable, series-based method against a high-precision reference.\n    \"\"\"\n\n    # Set precision for the high-precision reference calculation. 50 digits is sufficient.\n    getcontext().prec = 50\n\n    def reference_d(x_str: str) - Decimal:\n        \"\"\"Computes d(x) to high precision using its Taylor series.\"\"\"\n        if x_str == '0':\n            return Decimal(0)\n\n        x = Decimal(x_str)\n        x_sq = x * x\n        \n        # d(x) = sum_{k=1 to inf} (-1)^(k-1) * x^(2k) / (2k+1)!\n        # term_{k} = (-1)^(k-1) * x^(2k) / (2k+1)!\n        # The ratio term_{k+1} / term_{k} = -x^2 / ((2k+2)(2k+3))\n\n        k = 1\n        term = x_sq / Decimal(6)  # First term (k=1)\n        d_val = term\n        \n        # Sum until the next term is smaller than the context precision\n        while abs(term)  Decimal('1e-50'):\n            k += 1\n            term *= -x_sq / Decimal((2 * k) * (2 * k + 1))\n            d_val += term\n        \n        return d_val\n\n    def naive_f(x: float) - float:\n        \"\"\"Computes f(x) = sin(x)/x naively.\"\"\"\n        if x == 0.0:\n            return 1.0\n        return np.sin(x) / x\n\n    def stable_d(x: float, threshold: float) - float:\n        \"\"\"\n        Computes d(x) using a stable hybrid algorithm.\n        \"\"\"\n        if x == 0.0:\n            return 0.0\n        \n        if abs(x)  threshold:\n            # For small |x|, use the Taylor series for d(x) to avoid cancellation.\n            # d(x) = x^2/6 - x^4/120 + x^6/5040 - ...\n            x_sq = x * x\n            \n            # term_{k+1} = term_{k} * (-x^2) / ((2k+2)(2k+3))\n            k = 1\n            term = x_sq / 6.0  # First term (k=1)\n            d_val = term\n            \n            # Sum until convergence at double precision\n            for k_iter in range(2, 15): # 15 iterations is more than enough\n                term *= -x_sq / ((2 * k_iter) * (2 * k_iter + 1))\n                d_val_prev = d_val\n                d_val += term\n                if d_val == d_val_prev:\n                    break\n            return d_val\n        else:\n            # For larger |x|, direct computation is stable enough.\n            f_val = np.sin(x) / x\n            return 1.0 - f_val\n\n    # Define test cases from the problem statement\n    test_cases_str = ['0', '1e-12', '1e-10', '1e-8', '-1e-7', '1e-7', '1e-4', '1e-1']\n    test_cases_float = [float(x) for x in test_cases_str]\n    \n    # Threshold for switching to series expansion, based on O(sqrt(u)) analysis\n    # For double precision, u ~ 10^-16, sqrt(u) ~ 10^-8. 10^-7 is a safe choice.\n    threshold = 1e-7\n\n    all_results = []\n    for x_str, x_float in zip(test_cases_str, test_cases_float):\n        # 1. High-precision reference calculation\n        d_ref_dec = reference_d(x_str)\n        f_ref_dec = Decimal(1) - d_ref_dec\n        d_ref = float(d_ref_dec)\n        f_ref = float(f_ref_dec)\n\n        # 2. Naive computation\n        f_naive_val = naive_f(x_float)\n        d_naive_val = 1.0 - f_naive_val\n\n        # 3. Stable computation for the decrement\n        d_stable_val = stable_d(x_float, threshold)\n\n        # 4. Compute error metrics\n        if x_float == 0.0:\n            err_f_naive = 0.0\n            err_d_naive = 0.0\n            err_d_stable = 0.0\n        else:\n            # Relative error of naive f(x)\n            err_f_naive = abs((f_naive_val - f_ref) / f_ref) if f_ref != 0 else 0.0\n            \n            if d_ref == 0.0:\n                # This branch should not be taken for x != 0\n                err_d_naive = 0.0 if d_naive_val == 0.0 else float('inf')\n                err_d_stable = 0.0 if d_stable_val == 0.0 else float('inf')\n            else:\n                # Relative error of naive d(x)\n                err_d_naive = abs((d_naive_val - d_ref) / d_ref)\n                # Relative error of stable d(x)\n                err_d_stable = abs((d_stable_val - d_ref) / d_ref)\n        \n        all_results.append([err_f_naive, err_d_naive, err_d_stable])\n\n    # Format output as a string representing a list of lists, without spaces.\n    formatted_results = [f\"[{r[0]},{r[1]},{r[2]}]\" for r in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3212241"}, {"introduction": "最后，我们来探讨现代计算机体系结构如何为数值精度问题提供硬件层面的解决方案。本练习将介绍融合乘加（Fused Multiply-Add, FMA）指令，并展示其在缓解基本运算（如多项式求值和点积）中的舍入误差和灾难性抵消方面的强大能力。通过这个实践，你将把对数值误差的理解从软件算法层面扩展到硬件实现层面。[@problem_id:3165813]", "problem": "考虑在支持积和熔加（Fused Multiply-Add, FMA）的现代处理器中进行浮点计算。使用标准舍入模型来处理浮点运算：每个基本算术运算返回精确实数结果乘以一个形式为 $1 + \\delta$ 的因子，其中 $\\delta$ 是一个小量，其绝对值受机器精度 $\\epsilon$ 的限制。在没有 FMA 的情况下，像 $a \\times b + c$ 这样的复合运算在乘法和加法时会经历独立的舍入。使用 FMA 时，$a \\times b + c$ 作为单次操作执行，只有一次舍入。当两个数量级相近、符号相反的数相加时，会发生灾难性抵消，导致有效数字的严重损失。舍入误差源于算术运算中的有限精度舍入，而截断误差源于对连续或无限过程的近似；在本问题中，不出现截断误差，但会出现舍入误差和抵消现象。\n\n你需要评估特定的多项式和点积，在使用和不使用 FMA 的情况下测量数值误差，并量化 FMA 如何减轻抵消效应。将绝对误差定义为 $E_{\\text{abs}} = \\lvert \\hat{y} - y \\rvert$，相对误差定义为 $E_{\\text{rel}} = \\frac{\\lvert \\hat{y} - y \\rvert}{\\lvert y \\rvert}$，其中 $\\hat{y}$ 是计算值，$y$ 是高精度参考值。当 $y = 0$ 时，使用绝对误差；否则，使用相对误差。\n\n任务是：\n\n1. 对给定的输入，使用 Horner 方案，分别通过标准乘加运算和 FMA 来评估多项式。多项式为 $p_1(x) = (x - 1)^8$ 和 $p_2(x) = (x - 1)^{12}$。同时，对 $p_3(x) = (x - 1)^8$ 在一个远离抵消点的值上进行基准评估。\n\n2. 计算指定向量对的点积，分别使用和不使用 FMA 累加。\n\n3. 对每个测试用例，计算改进因子 $I = \\frac{E_{\\text{noFMA}}}{E_{\\text{FMA}}}$，当 $y \\neq 0$ 时使用相对误差，当 $y = 0$ 时使用绝对误差。\n\n使用通过任意精度算术计算的高精度参考值 $y$ 来近似精确的实数算术结果，以供比较。然后为每个测试用例计算改进因子。\n\n测试套件：\n- 通过 Horner 方法进行多项式测试：\n  - $T_1$：$p_1(x)$ 于 $x = 1 + 10^{-8}$。\n  - $T_2$：$p_2(x)$ 于 $x = 1 + 10^{-10}$。\n  - $T_3$：$p_3(x)$ 于 $x = 2$。\n- 点积测试：\n  - $T_4$：$v^{(A)} = [10^8, 10^8, 10^8, 10^8, 10^8, 10^8, 10^8, 10^8]$ 和 $w^{(A)} = [10^{-8}, -10^{-8}, 10^{-8}, -10^{-8}, 10^{-8}, -10^{-8}, 10^{-8}, -10^{-8}]$。\n  - $T_5$：$v^{(B)} = [10^{16}, 1, -10^{16}, 1, 10^{16}, -1]$ 和 $w^{(B)} = [10^{-16}, 1, 10^{-16}, 1, -10^{-16}, 1]$。\n  - $T_6$：长度为 $100$ 的 $v^{(C)}$，其元素为 $v_i = (-1)^i \\cdot 10^8$，以及长度为 $100$ 的 $w^{(C)}$，其元素为 $w_i = 10^{-8}$，其中 $i = 1, \\dots, 100$。\n\n实现要求：\n- 使用 Horner 方案以 $y \\leftarrow y \\cdot x + a_i$ 的形式评估多项式，其中 $a_i$ 是从最高次项到常数项排序的系数。FMA 变体应使用单个熔加操作 $y \\leftarrow \\mathrm{fma}(y, x, a_i)$ 来实现此更新，即 $y \\leftarrow (y \\cdot x + a_i)$ 并进行一次舍入。\n- 将点积评估为 $\\sum_{i=1}^{n} v_i w_i$；FMA 变体应使用 $y \\leftarrow \\mathrm{fma}(v_i, w_i, y)$ 进行累加。\n\n参考值：\n- 使用任意精度算术对相同的数学表达式进行计算以获得 $y$，其中数字以十进制形式指定（例如 $10^{-8}$），从而使参考值能紧密近似精确的实数算术结果。\n\n最终输出：\n- 你的程序应生成单行输出，其中包含 $T_1$ 到 $T_6$ 的六个改进因子，以逗号分隔的列表形式包含在方括号内，顺序为 $[I_{T_1}, I_{T_2}, I_{T_3}, I_{T_4}, I_{T_5}, I_{T_6}]$，每个因子格式化为 $12$ 位有效数字（例如 $[1.23456789012,2.0,3.14159265359, ...]$）。", "solution": "用户的请求是解决一个数值分析问题，该问题涉及将标准浮点运算与使用积和熔加（FMA）能力的运算进行比较。目标是量化 FMA 在减轻数值误差方面的改进，特别是舍入误差和灾难性抵消。\n\n### 问题验证\n\n首先，我将根据所需程序验证问题陈述。\n\n#### 步骤 1：提取给定信息\n\n-   **浮点模型**：每个基本算术运算都受舍入影响，建模为乘以一个因子 $(1 + \\delta)$，其中 $|\\delta| \\le \\epsilon$（$\\epsilon$ 是机器精度）。\n-   **标准计算**：像 $a \\times b + c$ 这样的运算涉及两个舍入步骤：一个用于乘法，一个用于加法，即 $fl(fl(a \\times b) + c)$。\n-   **FMA 计算**：像 $a \\times b + c$ 这样的运算作为单个单元执行，只有一个舍入步骤，即 $fl(a \\times b + c)$。\n-   **误差度量**：绝对误差 $E_{\\text{abs}} = |\\hat{y} - y|$ 和相对误差 $E_{\\text{rel}} = \\frac{|\\hat{y} - y|}{|y|}$。除非真值 $y=0$，否则使用相对误差；在这种情况下，使用绝对误差。\n-   **改进因子**：$I = \\frac{E_{\\text{noFMA}}}{E_{\\text{FMA}}}$，其中 $E$ 是误差（根据情况为相对或绝对误差）。\n-   **参考值 ($y$)**：使用任意精度算术计算的高精度值，用作精确实数结果的代理。\n-   **任务**：\n    1.  使用 Horner 方案，在有和没有 FMA 的情况下评估多项式 $p_1(x) = (x - 1)^8$ 和 $p_2(x) = (x - 1)^{12}$。还测试了一个基准案例 $p_3(x) = (x-1)^8$。\n    2.  在有和没有 FMA 累加的情况下，计算指定向量对的点积。\n-   **实现**：\n    -   Horner 方案更新：`y = y * x + a_i`（标准）和 `y = fma(y, x, a_i)` (FMA)。\n    -   点积累加：`y = y + v_i * w_i`（标准循环）和 `y = fma(v_i, w_i, y)` (FMA 循环)。\n-   **测试套件**：\n    -   $T_1$: $p_1(x) = (x - 1)^8$ 于 $x = 1 + 10^{-8}$。\n    -   $T_2$: $p_2(x) = (x - 1)^{12}$ 于 $x = 1 + 10^{-10}$。\n    -   $T_3$: $p_3(x) = (x - 1)^8$ 于 $x = 2$。\n    -   $T_4$: $v^{(A)} = [10^8, \\dots, 10^8]$ (8 个元素), $w^{(A)} = [10^{-8}, -10^{-8}, \\dots]$。\n    -   $T_5$: $v^{(B)} = [10^{16}, 1, -10^{16}, 1, 10^{16}, -1]$, $w^{(B)} = [10^{-16}, 1, 10^{-16}, 1, -10^{-16}, 1]$。\n    -   $T_6$: $v_i = (-1)^i \\cdot 10^8$, $w_i = 10^{-8}$ 对于 $i=1, \\dots, 100$。\n-   **输出格式**：一个包含六个改进因子的单行列表 `[I_T1, ..., I_T6]`，格式化为 $12$ 位有效数字。\n\n#### 步骤 2：使用提取的给定信息进行验证\n\n-   **科学依据**：该问题在根本上是合理的。它涉及数值分析的核心概念：浮点运算、舍入误差、灾难性抵消、Horner 方法和 FMA 指令。误差模型和定义都是标准的。\n-   **适定性**：该问题是适定的。输入、所需计算和期望输出都已明确定义。这些任务会导向一组唯一且有意义的数值结果。从 $(x-1)^n$ 推导多项式系数是二项式定理的标准应用，而不是缺失信息。\n-   **客观性**：该问题以精确、客观和技术性的语言陈述，没有歧义或主观声明。\n\n该问题没有任何无效性缺陷。这是一个在计算科学或数值分析入门课程中常见的、表述良好的标准问题。\n\n#### 步骤 3：结论与行动\n\n该问题是**有效的**。将提供一个解决方案。\n\n### 基于原理的解决方案设计\n\n这个问题的核心在于熔加计算和非熔加计算之间的差异。\n\n1.  **基本原理**：像 $z = a \\times b + c$ 这样的标准浮点运算是作为两个独立的操作执行的：一个乘法后跟一个加法。每个操作都会产生舍入误差。\n    -   $\\hat{p} = fl(a \\times b) = (a \\times b)(1+\\delta_1)$\n    -   $\\hat{z} = fl(\\hat{p} + c) = (\\hat{p} + c)(1+\\delta_2)$\n    在现代处理器上可用的积和熔加（FMA）指令以单次舍入执行这整个操作：\n    -   $\\hat{z}_{\\text{FMA}} = fl(a \\times b + c) = (a \\times b + c)(1+\\delta_3)$\n    FMA 在加上 $c$ 之前，以更高的中间精度计算乘积 $a \\times b$，从而减少了总的舍入误差。这在两种情况下尤其有效：\n    a.  当乘积 $a \\times b$ 本身不能精确表示为标准浮点数时，FMA 可以防止在加法前对其进行舍入而导致的信息损失。\n    b.  当 $fl(a \\times b)$ 和 $c$ 的数量级几乎相等且符号相反时，它们的和会遭受灾难性抵消。FMA 可以通过将 $c$ 加到未舍入的高精度乘积 $a \\times b$ 上来缓解这种情况。\n\n2.  **多项式求值（Horner 方法）**：对于多项式 $P(x) = \\sum_{i=0}^{n} c_i x^i$，Horner 方法是一种高效的求值算法，由递推关系定义：$y_n = c_n$，$y_k = y_{k+1} \\cdot x + c_k$，对于 $k = n-1, \\dots, 0$。\n    多项式 $(x-1)^n$ 展开后具有大的、正负交替的二项式系数。例如，$(x-1)^8 = x^8 - 8x^7 + 28x^6 - \\dots$。当在 $x=1$ 附近求值时，Horner 方法中的中间项会变得很大，它们的加减法会导致显著的灾难性抵消。FMA 以更高的精度执行每一步 $y \\cdot x + c_k$，保留了有效数字，从而产生更精确的结果。测试用例 $T_3$ 在 $x=2$ 处，作为没有此类抵消发生的基准。\n\n3.  **点积求值**：点积 $\\sum_{i=1}^{n} v_i w_i$ 是乘积之和。一个简单的实现是使用循环来累加和。\n    -   _不使用 FMA_：`sum = sum + (v_i * w_i)`。这涉及在乘积 `v_i * w_i` 之后进行一次舍入，在与 `sum` 相加之后又进行一次舍入。\n    -   _使用 FMA_：`sum = fma(v_i, w_i, sum)`。这里，会计算 `v_i` 和 `w_i` 的完整高精度乘积，然后将其加到 `sum`上，最后只进行一次舍入。\n    测试用例 $T_4, T_5, T_6$ 被设计成精确和为零，但单个项不为零。这是求和中灾难性抵消的典型场景，其中 FMA 避免对乘积进行中间舍入的能力对于精度至关重要。\n\n4.  **处理边界情况**：在计算改进因子 $I = E_{\\text{noFMA}} / E_{\\text{FMA}}$ 时，如果 $E_{\\text{FMA}} = 0$，可能会发生除以零的情况。\n    -   如果 $E_{\\text{noFMA}}$ 和 $E_{\\text{FMA}}$ 均为零（如 $T_3$ 中），则两种方法的精度相同，改进因子在逻辑上为 $1$。\n    -   如果 $E_{\\text{FMA}}=0$ 但 $E_{\\text{noFMA}} > 0$（如 $T_5$ 中），则改进理论上是无限的。为了按要求提供数值输出，我们可以使用一个 FMA 误差的代理。一个合理的选择是最小的正规格化浮点数 `numpy.finfo(float).tiny`，它代表了浮点分辨率的极限。这将为改进因子产生一个非常大的有限数。\n    -   如果 $E_{\\text{noFMA}}=0$ 但 $E_{\\text{FMA}} > 0$（如 $T_4, T_6$ 中），这表明标准方法偶然地产生了精确答案，而 FMA 方法累积了一个小误差。在这种情况下，改进因子被正确地计算为 $0$。\n\n该实现将使用 Python 的 `math` 模块进行标准运算，使用 `math.fma` 进行熔加运算。高精度参考值将使用 `decimal` 模块计算。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport math\nimport decimal\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes numerical errors with and without Fused Multiply-Add (FMA)\n    and calculates the improvement factor for a suite of test cases.\n    \"\"\"\n    # Set precision for high-accuracy reference calculations.\n    decimal.getcontext().prec = 100\n\n    # --- Helper Functions ---\n\n    def get_poly_coeffs(n):\n        \"\"\"Computes coefficients for the expanded form of (x-1)^n.\"\"\"\n        coeffs = []\n        # Horner's method requires coefficients from highest degree (c_n) down to c_0.\n        # The coefficient of x^k in (x-1)^n is C(n, n-k) * (-1)^(n-k).\n        # We order them for c_n, c_{n-1}, ..., c_0\n        for i in range(n, -1, -1):\n            k = n - i\n            coeff = math.comb(n, k) * ((-1)**k)\n            coeffs.append(float(coeff))\n        return coeffs\n\n    def horner_nofma(coeffs, x):\n        \"\"\"Evaluates a polynomial using Horner's scheme with standard operators.\"\"\"\n        y = 0.0\n        for c in coeffs:\n            y = y * x + c\n        return y\n\n    def horner_fma(coeffs, x):\n        \"\"\"Evaluates a polynomial using Horner's scheme with FMA.\"\"\"\n        y = 0.0\n        for c in coeffs:\n            y = math.fma(y, x, c)\n        return y\n\n    def dot_nofma(v, w):\n        \"\"\"Computes a dot product with standard operators.\"\"\"\n        s = 0.0\n        for i in range(len(v)):\n            s += v[i] * w[i]\n        return s\n\n    def dot_fma(v, w):\n        \"\"\"Computes a dot product using FMA for accumulation.\"\"\"\n        s = 0.0\n        for i in range(len(v)):\n            s = math.fma(v[i], w[i], s)\n        return s\n\n    def get_improvement(y_ref, y_nofma, y_fma):\n        \"\"\"\n        Calculates the improvement factor I = E_noFMA / E_FMA.\n        Handles edge cases like division by zero.\n        \"\"\"\n        y_ref_f = float(y_ref)\n\n        if y_ref_f == 0.0:\n            err_nofma = abs(y_nofma)\n            err_fma = abs(y_fma)\n        else:\n            err_nofma = abs(y_nofma - y_ref_f) / abs(y_ref_f)\n            err_fma = abs(y_fma - y_ref_f) / abs(y_ref_f)\n\n        if err_fma == err_nofma:\n            return 1.0\n        \n        if err_fma == 0.0:\n            # Improvement is theoretically infinite. Use a very large number\n            # by dividing by the smallest possible float value as a proxy for error.\n            if y_ref_f == 0.0:\n                err_fma_proxy = np.finfo(float).tiny\n            else:\n                err_fma_proxy = np.finfo(float).tiny / abs(y_ref_f)\n            \n            if err_fma_proxy == 0.0: # Avoid division by zero if y_ref is huge\n                return np.inf\n\n            return err_nofma / err_fma_proxy\n\n        return err_nofma / err_fma\n\n    # --- Test Case Definitions ---\n\n    test_cases = [\n        # T1: p1(x) = (x-1)^8 at x = 1 + 1e-8\n        {\n            'eval_func_nofma': lambda: horner_nofma(get_poly_coeffs(8), 1.0 + 1e-8),\n            'eval_func_fma': lambda: horner_fma(get_poly_coeffs(8), 1.0 + 1e-8),\n            'ref_val': (decimal.Decimal('1') + decimal.Decimal('1e-8') - decimal.Decimal('1'))**8\n        },\n        # T2: p2(x) = (x-1)^12 at x = 1 + 1e-10\n        {\n            'eval_func_nofma': lambda: horner_nofma(get_poly_coeffs(12), 1.0 + 1e-10),\n            'eval_func_fma': lambda: horner_fma(get_poly_coeffs(12), 1.0 + 1e-10),\n            'ref_val': (decimal.Decimal('1') + decimal.Decimal('1e-10') - decimal.Decimal('1'))**12\n        },\n        # T3: p3(x) = (x-1)^8 at x = 2\n        {\n            'eval_func_nofma': lambda: horner_nofma(get_poly_coeffs(8), 2.0),\n            'eval_func_fma': lambda: horner_fma(get_poly_coeffs(8), 2.0),\n            'ref_val': (decimal.Decimal('2') - decimal.Decimal('1'))**8\n        },\n        # T4: Dot product vA . wA\n        {\n            'eval_func_nofma': lambda: dot_nofma([1e8] * 8, [1e-8, -1e-8] * 4),\n            'eval_func_fma': lambda: dot_fma([1e8] * 8, [1e-8, -1e-8] * 4),\n            'ref_val': decimal.Decimal('0')\n        },\n        # T5: Dot product vB . wB\n        {\n            'v': [1e16, 1.0, -1e16, 1.0, 1e16, -1.0],\n            'w': [1e-16, 1.0, 1e-16, 1.0, -1e-16, 1.0],\n            'eval_func_nofma': lambda: dot_nofma([1e16, 1.0, -1e16, 1.0, 1e16, -1.0], [1e-16, 1.0, 1e-16, 1.0, -1e-16, 1.0]),\n            'eval_func_fma': lambda: dot_fma([1e16, 1.0, -1e16, 1.0, 1e16, -1.0], [1e-16, 1.0, 1e-16, 1.0, -1e-16, 1.0]),\n            'ref_val': decimal.Decimal('0')\n        },\n        # T6: Dot product vC . wC\n        {\n            'v': [(-1.0)**i * 1e8 for i in range(1, 101)],\n            'w': [1e-8] * 100,\n            'eval_func_nofma': lambda: dot_nofma([(-1.0)**i * 1e8 for i in range(1, 101)], [1e-8] * 100),\n            'eval_func_fma': lambda: dot_fma([(-1.0)**i * 1e8 for i in range(1, 101)], [1e-8] * 100),\n            'ref_val': decimal.Decimal('0')\n        }\n    ]\n\n    # --- Main Execution Loop ---\n\n    results = []\n    for case in test_cases:\n        y_ref = case['ref_val']\n        y_nofma = case['eval_func_nofma']()\n        y_fma = case['eval_func_fma']()\n        \n        improvement = get_improvement(y_ref, y_nofma, y_fma)\n        results.append(improvement)\n\n    # Final print statement in the exact required format.\n    # The spec asks for 12 significant digits. Using .12g is robust.\n    result_str = ','.join(format(res, '.12g') for res in results)\n    print(f\"[{result_str}]\")\n\nsolve()\n```", "id": "3165813"}]}