{"hands_on_practices": [{"introduction": "在开始探索计算问题的敏感性时，最基本的一步是分析一个简单函数求值的过程。这个练习将帮助你区分一个问题本身的“病态”（即其固有的敏感性）与解决该问题的特定算法所引入的“误差”。通过从第一性原理推导指数函数 $f(x) = e^{x}$ 的条件数，你将亲手实践如何量化问题对输入的微小扰动的反应，并将其与泰勒级数逼近产生的算法误差进行对比[@problem_id:3110304]。", "problem": "你需要分析使用截断泰勒级数计算指数函数的数值条件，并量化值域大小与相对误差放大之间的关系。考虑函数 $f(x) = e^{x}$ 以及通过 $x=0$ 处的 $n$ 阶泰勒多项式 $T_{n}(x) = \\sum_{k=0}^{n} \\frac{x^{k}}{k!}$ 来近似 $f(x)$ 的算法。你的任务是将计算 $f(x)$ 问题的条件与该截断级数在不同 $x$ 值下观测到的前向相对误差联系起来。\n\n仅使用以下基本依据：\n- 可微标量函数 $f$ 的相对条件数的定义：在点 $x$ 处的相对条件数是当输入扰动趋于零时，相对输出变化与相对输入变化之比的极限。\n- 光滑函数在 $x=0$ 处带有拉格朗日余项形式的泰勒多项式。\n- 指数函数的标准性质。\n\n任务：\n1) 从相对条件数的定义出发，推导函数 $f(x)=e^{x}$ 在点 $x$（其中 $f(x) \\neq 0$）的相对条件数 $\\kappa_{f}(x)$。不要使用任何预先记忆的快捷公式；从零扰动极限中的相对条件数定义开始。\n2) 对于 $x \\ge 0$，使用泰勒余项的拉格朗日形式，推导前向相对误差 $\\frac{|e^{x} - T_{n}(x)|}{|e^{x}|}$ 的一个可计算上界 $B(x,n)$。\n3) 实现一个程序，对于下面测试套件中的每个测试用例 $(x,n)$，计算：\n   - 推导出的相对条件数 $\\kappa_{f}(x)$。\n   - 使用浮点数运算观测到的前向相对误差 $r(x,n) = \\frac{|T_{n}(x) - e^{x}|}{|e^{x}|}$。\n   - 一个布尔值 $\\mathrm{BoundOK}(x,n)$，当且仅当 $r(x,n) \\le B(x,n)$ 时为 $\\mathrm{True}$。\n4) 程序不得读取任何输入。它必须计算测试套件的值，并按以下确切格式打印单行输出：一个由方括号括起来的、逗号分隔的、每个用例一个三元组的列表，其中每个三元组的形式为 $[\\kappa_{f}(x),r(x,n),\\mathrm{BoundOK}(x,n)]$。该列表不得包含空格，浮点数必须四舍五入到小数点后恰好 $10$ 位，布尔值必须打印为 $\\mathrm{True}$ 或 $\\mathrm{False}$。\n\n测试套件（每对 $(x,n)$ 是一个测试用例）：\n- $(x,n) = (0,0)$\n- $(x,n) = (0.1,3)$\n- $(x,n) = (1,5)$\n- $(x,n) = (5,10)$\n- $(x,n) = (10,10)$\n- $(x,n) = (20,10)$\n\n注意：\n- 不涉及物理单位。\n- 不涉及角度。\n- 输出应为单行，包含六个测试用例结果的列表，格式完全符合规定，例如 $[[a,b,c],[d,e,f],\\dots]$，但要替换为数值和指定的布尔值。\n- 测试套件的设计包括一个在 $x=0$ 的边界情况、一些中等值以及一个大值 $x=20$，以探究值域大小与相对误差放大之间的联系。\n\n你的程序应生成单行输出，包含一个由六个三元组组成的逗号分隔列表，并用方括号括起来，不含空格，例如：$[[\\kappa_{1},r_{1},\\mathrm{BoundOK}_{1}],[\\kappa_{2},r_{2},\\mathrm{BoundOK}_{2}],\\dots,[\\kappa_{6},r_{6},\\mathrm{BoundOK}_{6}]]$.", "solution": "该问题被评估为有效。\n\n1.  **已知条件提取**：\n    *   函数：$f(x) = e^{x}$。\n    *   近似算法：在 $x=0$ 处截断的 $n$ 阶泰勒级数，$T_{n}(x) = \\sum_{k=0}^{n} \\frac{x^{k}}{k!}$。\n    *   相对条件数 $\\kappa_{f}(x)$ 的定义：当输入扰动趋于零时，相对输出变化与相对输入变化之比的极限。\n    *   误差界限工具：带拉格朗日余项形式的泰勒多项式。\n    *   误差界限约束：$x \\ge 0$。\n    *   任务：\n        1.  从定义推导 $f(x)=e^{x}$ 的 $\\kappa_{f}(x)$。\n        2.  对于 $x \\ge 0$，推导前向相对误差 $\\frac{|e^{x} - T_{n}(x)|}{|e^{x}|}$ 的一个可计算上界 $B(x,n)$。\n        3.  实现一个程序来计算 $\\kappa_{f}(x)$、观测到的前向相对误差 $r(x,n)$ 和一个布尔值 $\\mathrm{BoundOK}(x,n)$（表示 $r(x,n) \\le B(x,n)$ 是否成立）。\n        4.  按指定格式为特定测试套件打印结果。\n    *   测试套件：$(x,n) \\in \\{(0,0), (0.1,3), (1,5), (5,10), (10,10), (20,10)\\}$。\n\n2.  **有效性分析**：\n    *   **科学依据**：该问题植根于数值分析的基本概念，包括泰勒级数近似、误差分析和函数条件。这些都是计算数学和科学中的标准课题。\n    *   **适定性**：问题陈述清晰，包含所有必要的定义和约束。每个任务都导向一个唯一的、明确定义的数学或计算结果。\n    *   **客观性**：问题陈述精确、量化，没有主观或含糊的语言。\n    *   相对条件数的定义涉及相对输入变化，通常是 $|\\delta x / x|$。这个项在 $x=0$ 处是奇异的。然而，对于函数 $f(x)=e^x$，得到的标准条件数公式 $\\kappa_f(x) = |x f'(x) / f(x)|$ 在 $x=0$ 处有一个可去奇点，其值为 $0$。这是条件数分析中一个标准且被充分理解的方面。因此，该问题被认为是完全有效的。\n\n3.  **结论**：问题有效，将提供解决方案。\n\n***\n\n**1. 相对条件数 $\\kappa_{f}(x)$ 的推导**\n\n相对条件数 $\\kappa_{f}(x)$ 量化了函数相对输出变化对相对输入变化的敏感度。根据定义，对于输入 $x$（其中 $x \\neq 0$）的一个小扰动 $\\delta x$，它由以下极限给出：\n$$ \\kappa_{f}(x) = \\lim_{\\delta x \\to 0} \\left| \\frac{\\text{f(x)的相对变化}}{\\text{x的相对变化}} \\right| = \\lim_{\\delta x \\to 0} \\left| \\frac{(f(x+\\delta x) - f(x))/f(x)}{(\\delta x)/x} \\right| $$\n我们可以重新整理极限内的表达式：\n$$ \\kappa_{f}(x) = \\lim_{\\delta x \\to 0} \\left| \\frac{x}{f(x)} \\cdot \\frac{f(x+\\delta x) - f(x)}{\\delta x} \\right| $$\n根据极限的性质，我们可以将不依赖于 $\\delta x$ 的项移到外面：\n$$ \\kappa_{f}(x) = \\left| \\frac{x}{f(x)} \\right| \\lim_{\\delta x \\to 0} \\left| \\frac{f(x+\\delta x) - f(x)}{\\delta x} \\right| $$\n极限项是 $f$ 在 $x$ 处导数的绝对值的定义，即 $|f'(x)|$。\n$$ \\kappa_{f}(x) = \\left| \\frac{x f'(x)}{f(x)} \\right| $$\n对于特定函数 $f(x) = e^{x}$，其导数为 $f'(x) = e^{x}$。将这些代入公式中得到：\n$$ \\kappa_{f}(x) = \\left| \\frac{x \\cdot e^{x}}{e^{x}} \\right| = |x| $$\n此公式是为 $x \\neq 0$ 推导的。然而，它在 $x=0$ 处是良定义的，此时 $\\kappa_{f}(0) = |0| = 0$。这表明计算 $e^{0}$ 的问题是完全良态的。我们将对所有 $x$ 使用公式 $\\kappa_{f}(x) = |x|$。\n\n**2. 相对误差上界 $B(x,n)$ 的推导**\n\n我们的任务是对于 $x \\ge 0$，找到用泰勒多项式 $T_n(x)$ 近似 $f(x)=e^x$ 的前向相对误差的一个上界。前向相对误差定义为：\n$$ r(x,n) = \\frac{|f(x) - T_{n}(x)|}{|f(x)|} = \\frac{|e^{x} - T_{n}(x)|}{|e^{x}|} $$\n绝对误差 $|e^{x} - T_{n}(x)|$ 由泰勒展开的余项给出。使用拉格朗日形式的余项 $R_n(x) = f(x) - T_n(x)$，我们有：\n$$ R_n(x) = \\frac{f^{(n+1)}(c)}{(n+1)!} x^{n+1} $$\n其中某个值 $c$ 介于 $0$ 和 $x$ 之间。对于 $f(x)=e^x$，它的所有阶导数也都是 $e^x$，所以 $f^{(n+1)}(c) = e^c$。因此，绝对误差为：\n$$ e^x - T_n(x) = \\frac{e^c}{(n+1)!} x^{n+1} $$\n将此代入相对误差公式：\n$$ r(x,n) = \\frac{\\left| \\frac{e^c}{(n+1)!} x^{n+1} \\right|}{|e^x|} $$\n问题指定 $x \\ge 0$。这意味着 $x^{n+1} \\ge 0$ 且 $e^x > 0$。值 $c$ 在区间 $[0, x]$ 内。\n$$ r(x,n) = \\frac{e^c x^{n+1}}{(n+1)! e^x} = e^{c-x} \\frac{x^{n+1}}{(n+1)!} $$\n为了找到 $r(x,n)$ 的上界，我们需要找到项 $e^{c-x}$ 的最大可能值。由于 $c \\in [0, x]$，指数 $c-x$ 在区间 $[-x, 0]$ 内。指数函数是单调递增的，所以它在此区间上的最大值出现在右端点，即 $c-x=0$（对应于 $c=x$）。\n$$ e^{c-x} \\le e^0 = 1 $$\n通过应用这个不等式，我们得到了相对误差的一个上界 $B(x,n)$：\n$$ r(x,n) \\le 1 \\cdot \\frac{x^{n+1}}{(n+1)!} $$\n因此，一个可计算的上界是：\n$$ B(x,n) = \\frac{x^{n+1}}{(n+1)!} $$\n\n**3. 算法实现**\n\n程序将遍历测试套件中的每个 $(x,n)$ 对，并执行以下计算：\n\n*   **相对条件数 $\\kappa_f(x)$**：使用推导出的公式 $\\kappa_f(x) = |x|$ 直接计算。\n*   **观测到的前向相对误差 $r(x,n)$**：这需要计算 $e^x$ 和 $T_n(x) = \\sum_{k=0}^{n} \\frac{x^k}{k!}$。$T_n(x)$ 的和将迭代计算，以保持数值稳定性并避免单独计算大的幂和阶乘。过程如下：\n    1. 初始化 `total = 1.0`（对于 $k=0$ 项）和 `term = 1.0`。\n    2. 对于从 $1$ 到 $n$ 的 $k$ 进行循环：将项更新为 `term = term * x / k` 并将其加到总和中：`total = total + term`。\n    3. 计算 `exp_x = numpy.exp(x)`。\n    4. 计算相对误差 $r(x,n) = \\frac{|total - exp\\_x|}{|exp\\_x|}$。\n*   **上界 $B(x,n)$**：使用推导出的公式 $B(x,n) = \\frac{x^{n+1}}{(n+1)!}$ 计算。幂将使用 `numpy.power` 计算，阶乘将使用 `scipy.special.factorial` 计算，后者可以处理非整数参数并返回浮点结果，从而防止大 $n$ 值的溢出。\n*   **界限检查 $\\mathrm{BoundOK}(x,n)$**：这是一个布尔值，由逻辑比较 $r(x,n) \\le B(x,n)$ 确定。\n\n每个测试用例的结果——$\\kappa_f(x)$、$r(x,n)$ 和 $\\mathrm{BoundOK}(x,n)$——将被格式化为字符串 `[k,r,b]`，其中浮点数四舍五入到小数点后 $10$ 位。然后这些字符串将用逗号连接并用方括号括起来，以生成最终的输出行。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import factorial\n\ndef solve():\n    \"\"\"\n    Analyzes the numerical conditioning of evaluating e^x using a truncated\n    Taylor series for a given set of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (0.0, 0),\n        (0.1, 3),\n        (1.0, 5),\n        (5.0, 10),\n        (10.0, 10),\n        (20.0, 10),\n    ]\n\n    all_results_str = []\n    \n    for x, n in test_cases:\n        # 1. Compute the relative condition number kappa_f(x) = |x|\n        kappa_fx = np.abs(x)\n\n        # 2. Compute the observed forward relative error r(x,n)\n        # 2a. Compute T_n(x) = sum_{k=0 to n} x^k/k!\n        # An iterative method is used for better numerical stability.\n        # term_{k} = term_{k-1} * x / k\n        tn_x = 0.0\n        term = 1.0  # k=0 term: x^0/0! = 1\n        tn_x += term\n        for k in range(1, n + 1):\n            term = term * x / k\n            tn_x += term\n        \n        # 2b. Compute e^x\n        exp_x = np.exp(x)\n\n        # 2c. Compute the relative error r(x,n) = |T_n(x) - e^x| / |e^x|\n        # The denominator |e^x| is never zero for real x.\n        if exp_x == 0:\n            # This case is physically impossible for f(x)=e^x and real x,\n            # but included for robustness.\n            r_xn = np.inf if tn_x != 0 else 0.0\n        else:\n            r_xn = np.abs(tn_x - exp_x) / np.abs(exp_x)\n\n        # 3. Compute the upper bound B(x,n) on the relative error\n        # B(x,n) = x^(n+1) / (n+1)! for x >= 0\n        # Use exact=False to get a float result from factorial and avoid overflow.\n        b_xn = np.power(x, n + 1) / factorial(n + 1, exact=False)\n\n        # 4. Check if the observed error is within the derived bound\n        # A small tolerance could be used for floating point comparisons,\n        # but for this problem, direct comparison is sufficient.\n        bound_ok = r_xn = b_xn\n        \n        # Format the results for this case according to the problem specification\n        case_result_str = (\n            f\"[{kappa_fx:.10f},\"\n            f\"{r_xn:.10f},\"\n            f\"{'True' if bound_ok else 'False'}]\"\n        )\n        all_results_str.append(case_result_str)\n\n    # Print the final result string in the exact required format.\n    print(f\"[{','.join(all_results_str)}]\")\n\nsolve()\n```", "id": "3110304"}, {"introduction": "在掌握了单个函数求值的条件数之后，我们来研究一个更复杂的计算任务：非线性方程求根。对于问题 $f(x)=0$，其“输入”是函数 $f$ 本身，而“输出”是其根 $x^{\\star}$。这个练习将引导你探讨求根问题的适定性，并通过对函数施加微小扰动，经验性地验证根的敏感性如何依赖于函数在根附近的导数大小 [@problem_id:3110311]。这揭示了一个深刻的原理：即使一个问题是适定的，如果它处于“病态”条件下，其解也可能对数据中的微小噪声极为敏感。", "problem": "考虑非线性方程 $f(x) = x^3 - 3x + 1 = 0$。任务是分析计算出的根对于函数和（对于需要初始猜测值的迭代方法而言）初始猜测值的微小扰动的敏感性。该分析应基于数值分析中的基本定义：算法的稳定性、问题的适定性，以及通过解映射的敏感性来衡量的条件数。\n\n定义扰动函数族 $f_\\varepsilon(x) = f(x) + \\varepsilon\\,g(x)$，其中 $\\varepsilon$ 是一个小的实数参数，$g(x)$ 是一个光滑函数。您将比较两种求根方法的行为：\n- 牛顿-拉弗森法（牛顿法），该方法需要一个可微函数和一个初始猜测值。\n- 二分法，该方法需要一个有符号变化的括号区间，并且不需要导数。\n\n分析必须讨论在单根处根映射 $f \\mapsto x^\\star$ 的适定性，并根据函数的加性扰动凭经验估计根的绝对条件数。您不能使用三次方程的任何闭式解来获得根；相反，您必须实现这两种求根方法来计算数值近似值。三角函数中的角度量必须以弧度为单位进行解释。\n\n您的程序必须实现：\n- 针对 $f_\\varepsilon$ 的牛顿法，使用 $f_\\varepsilon$ 的导数。\n- 针对 $f_\\varepsilon$ 的二分法，在表现出符号变化的指定区间上使用。\n\n使用以下测试套件，其中每个案例指定了方法、扰动 $\\varepsilon$、扰动函数 $g(x)$，以及牛顿法的初始猜测值或二分法的括号区间 $[a,b]$。所有三角函数求值必须以弧度为单位。对于每个案例，计算指定的输出，并遵守以下定义。\n\n输出定义：\n- 对于 $\\varepsilon$ 非零的案例，计算观测到的位移 $\\Delta x_{\\text{obs}} = \\lvert x_\\varepsilon - x_0 \\rvert$，其中 $x_\\varepsilon$ 是由指定方法计算的 $f_\\varepsilon$ 的根，$x_0$ 是由相同选择规则（相同方法和括号区间，或由初始猜测值决定的相同吸引盆）计算的对应基准根 $f$ 的根。\n- 对于 $\\varepsilon$ 非零的案例，计算预测的一阶位移大小 $\\Delta x_{\\text{pred}} = \\left| \\dfrac{\\varepsilon\\,g(x_0)}{f'(x_0)} \\right|$，其中 $f'(x) = 3x^2 - 3$ 是在基准根 $x_0$ 处求值的未扰动函数的导数。\n- 对于 $\\varepsilon$ 为零的案例，计算返回的根相对于相应基准根的绝对差，并报告该方法所用的迭代次数。\n\n测试套件包含以下七个案例：\n\n1.  在 $[1, 2]$ 上使用二分法，其中 $\\varepsilon = 10^{-6}$ 且 $g(x) = x$。输出：对于区间 $[1,2]$ 内的根，输出 $\\Delta x_{\\text{obs}}$ 和 $\\Delta x_{\\text{pred}}$。\n2.  使用牛顿法，初始猜测值为 $x_{\\text{init}} = 1.3$，其中 $\\varepsilon = 10^{-6}$ 且 $g(x) = x$。输出：对于从此初始猜测值收敛得到的根，输出 $\\Delta x_{\\text{obs}}$ 和 $\\Delta x_{\\text{pred}}$。\n3.  使用牛顿法，初始猜测值为 $x_{\\text{init}} = 0.2$，其中 $\\varepsilon = 0$ 且 $g$ 无关。输出：相对于案例2（其中 $\\varepsilon=0$）的基准牛顿根的绝对差，以及所用的迭代次数。\n4.  在 $[1.1, 2.0]$ 上使用二分法，其中 $\\varepsilon = 0$ 且 $g$ 无关。输出：相对于案例1（其中 $\\varepsilon=0$）的基准二分法根的绝对差，以及所用的迭代次数。\n5.  在 $[0, 1]$ 上使用二分法，其中 $\\varepsilon = 10^{-6}$ 且 $g(x) = x$。输出：对于区间 $[0,1]$ 内的根，输出 $\\Delta x_{\\text{obs}}$ 和 $\\Delta x_{\\text{pred}}$。\n6.  在 $[-2, -1]$ 上使用二分法，其中 $\\varepsilon = 10^{-6}$ 且 $g(x) = x$。输出：对于区间 $[-2,-1]$ 内的根，输出 $\\Delta x_{\\text{obs}}$ 和 $\\Delta x_{\\text{pred}}$。\n7.  使用牛顿法，初始猜测值为 $x_{\\text{init}} = 0.3$，其中 $\\varepsilon = 10^{-12}$ 且 $g(x) = \\sin(x)$（弧度）。输出：对于从此初始猜测值收敛得到的根，输出 $\\Delta x_{\\text{obs}}$ 和 $\\Delta x_{\\text{pred}}$。\n\n算法要求：\n- 对于二分法，当区间宽度小于 $10^{-14}$ 或达到最大迭代次数 $200$ 次时终止。\n- 对于牛顿法，当绝对步长小于 $10^{-14}$ 或达到最大迭代次数 $200$ 次时终止。如果某次迭代中导数的绝对值降至 $10^{-14}$ 以下，则继续迭代，无需特殊处理；该方法在此类条件下的行为是分析的一部分。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，顺序如下：\n$[\\Delta x_{\\text{obs}}^{(1)}, \\Delta x_{\\text{pred}}^{(1)}, \\Delta x_{\\text{obs}}^{(2)}, \\Delta x_{\\text{pred}}^{(2)}, \\Delta x^{(3)}, N^{(3)}, \\Delta x^{(4)}, N^{(4)}, \\Delta x_{\\text{obs}}^{(5)}, \\Delta x_{\\text{pred}}^{(5)}, \\Delta x_{\\text{obs}}^{(6)}, \\Delta x_{\\text{pred}}^{(6)}, \\Delta x_{\\text{obs}}^{(7)}, \\Delta x_{\\text{pred}}^{(7)}]$，其中上标表示案例编号，$N^{(k)}$ 是案例 $k$ 在 $\\varepsilon = 0$ 时的迭代次数。\n\n所有输出必须是实数或整数。此问题不涉及物理单位，并且 $g(x) = \\sin(x)$ 的所有角度量必须以弧度为单位解释。", "solution": "该问题要求分析非线性方程 $f(x) = x^3 - 3x + 1 = 0$ 的根对微小扰动的敏感性。此分析涉及适定性、条件数以及数值算法（特别是牛顿-拉弗森法和二分法）的稳定性等概念。\n\n### 1. 理论基础：适定性与条件数\n\n如果一个数学问题的解存在、唯一，并且连续依赖于输入数据，则该问题被认为是**适定的**（well-posed）。对于求根问题 $f(x) = 0$，“输入数据”是函数 $f$ 本身。我们关心的是当 $f$ 受到扰动时，根 $x^\\star$ 如何变化。求单根（其中 $f'(x^\\star) \\neq 0$）的问题是适定的。\n\n问题的**条件数**（conditioning）量化了这种敏感性。我们分析扰动函数族 $f_\\varepsilon(x) = f(x) + \\varepsilon g(x)$，其中 $\\varepsilon$ 是一个小参数。设 $x(\\varepsilon)$ 是 $f_\\varepsilon(x) = 0$ 的根。根据定义，$x(0) = x^\\star$ 是未扰动问题 $f(x)=0$ 的根。\n\n为了确定一阶敏感性，我们可以使用隐函数定理。由于 $x^\\star$ 是一个单根，$f'(x^\\star) \\neq 0$。这确保了在 $\\varepsilon=0$ 附近，$x(\\varepsilon)$ 是 $\\varepsilon$ 的一个可微函数。我们对恒等式 $f(x(\\varepsilon)) + \\varepsilon g(x(\\varepsilon)) = 0$ 关于 $\\varepsilon$求导：\n$$\n\\frac{d}{d\\varepsilon} \\left[ f(x(\\varepsilon)) + \\varepsilon g(x(\\varepsilon)) \\right] = 0\n$$\n应用链式法则，我们得到：\n$$\nf'(x(\\varepsilon)) \\frac{dx}{d\\varepsilon} + g(x(\\varepsilon)) + \\varepsilon g'(x(\\varepsilon)) \\frac{dx}{d\\varepsilon} = 0\n$$\n在 $\\varepsilon = 0$ 处求值，并注意到 $x(0) = x^\\star$，方程简化为：\n$$\nf'(x^\\star) \\frac{dx}{d\\varepsilon}\\bigg|_{\\varepsilon=0} + g(x^\\star) = 0\n$$\n解出这个代表根对扰动敏感性的导数，得到：\n$$\n\\frac{dx}{d\\varepsilon}\\bigg|_{\\varepsilon=0} = - \\frac{g(x^\\star)}{f'(x^\\star)}\n$$\n对于一个小的非零 $\\varepsilon$，根的变化量 $\\Delta x = x(\\varepsilon) - x^\\star$ 可以通过一阶泰勒展开来近似：\n$$\n\\Delta x \\approx \\varepsilon \\frac{dx}{d\\varepsilon}\\bigg|_{\\varepsilon=0} = -\\varepsilon \\frac{g(x^\\star)}{f'(x^\\star)}\n$$\n因此，这个预测位移的大小是：\n$$\n\\Delta x_{\\text{pred}} = |\\Delta x| \\approx \\left| \\frac{\\varepsilon g(x^\\star)}{f'(x^\\star)} \\right|\n$$\n在我们的数值实现中，确切的根 $x^\\star$ 是未知的。我们用其数值近似值 $x_0$ 来代替它，该近似值由未扰动方程（$\\varepsilon=0$）计算得出。这就得到了问题中指定的公式：$\\Delta x_{\\text{pred}} = \\left| \\dfrac{\\varepsilon\\,g(x_0)}{f'(x_0)} \\right|$。项 $\\left| \\frac{g(x_0)}{f'(x_0)} \\right|$ 是根相对于扰动 $g(x)$ 的估计绝对条件数。一个大的值表示一个病态问题，其中函数中的小扰动可能导致根的巨大变化。\n\n### 2. 数值算法\n\n我们将实现两种标准的求根算法。\n\n**二分法**：对于一个连续函数 $h(x)$，如果在区间 $[a, b]$ 上 $h(a)$ 和 $h(b)$ 异号，该方法保证收敛。它通过迭代地将区间减半，同时保持根被包围在区间内。在每一步，计算中点 $c = (a+b)/2$。如果 $h(a)h(c)  0$，新区间变为 $[a, c]$，否则变为 $[c, b]$。当区间宽度 $b-a$ 小于容差 $10^{-14}$ 时，我们将终止。\n\n**牛顿法**：这种迭代方法可以找到实值函数 $h(x)$ 根的越来越好的近似值。迭代由以下公式定义：\n$$\nx_{k+1} = x_k - \\frac{h(x_k)}{h'(x_k)}\n$$\n如果初始猜测值 $x_0$ 足够接近一个单根，该方法会二次收敛。我们将把这个方法应用于扰动函数 $h(x) = f_\\varepsilon(x) = x^3 - 3x + 1 + \\varepsilon g(x)$，使用其导数 $h'(x) = f'_\\varepsilon(x) = 3x^2 - 3 + \\varepsilon g'(x)$。当绝对步长 $|x_{k+1} - x_k|$ 小于容差 $10^{-14}$ 时，我们将终止。\n\n### 3. 测试案例的分步执行\n\n对于每个测试案例，我们通过实现这些算法并应用推导出的敏感性公式来计算所需的输出。\n\n未扰动的函数是 $f(x) = x^3 - 3x + 1$，其导数为 $f'(x) = 3x^2 - 3$。该函数有三个不同的实根，分别位于区间 $[-2, -1]$, $[0, 1]$ 和 $[1, 2]$ 中。\n\n- **案例 1, 4**：在 $[1, 2]$ 和 $[1.1, 2.0]$ 上使用二分法。\n  对于案例1，我们首先找到 $f(x)=0$ 在 $[1, 2]$ 上的基准根 $x_0$。然后，我们找到扰动函数 $f_\\varepsilon(x) = f(x) + 10^{-6}x$ 在同一区间上的扰动根 $x_\\varepsilon$。我们计算 $\\Delta x_{\\text{obs}} = |x_\\varepsilon - x_0|$ 和 $\\Delta x_{\\text{pred}} = |\\varepsilon x_0 / f'(x_0)|$。\n  对于案例4，我们计算 $f(x)=0$ 在 $[1.1, 2.0]$ 上的根，并找出它与案例1基准根的绝对差，以及迭代次数。这测试了二分法对初始包围区间的鲁棒性。\n\n- **案例 2, 3**：使用初始猜测值的牛顿法。\n  对于案例2，使用 $x_{\\text{init}} = 1.3$，我们找到 $f(x)=0$ 的基准根 $x_0$ 和 $f_\\varepsilon(x) = f(x) + 10^{-6}x$ 的扰动根 $x_\\varepsilon$。用于牛顿法的导数是 $f'_\\varepsilon(x) = 3x^2 - 3 + 10^{-6}$。然后我们计算 $\\Delta x_{\\text{obs}}$ 和 $\\Delta x_{\\text{pred}}$。\n  对于案例3，我们对 $f(x)=0$ 使用 $x_{\\text{init}} = 0.2$。这个初始猜测值位于一个与案例2中找到的根不同的根的吸引盆中。我们报告迭代次数以及这个根与案例2基准根之间的绝对差。\n\n- **案例 5**：在 $[0, 1]$ 上使用二分法。\n  类似于案例1，但针对位于区间 $[0, 1]$ 内的根。我们找到基准根 $x_0$ 和 $f_\\varepsilon(x) = f(x) + 10^{-6}x$ 的扰动根 $x_\\varepsilon$，然后计算 $\\Delta x_{\\text{obs}}$ 和 $\\Delta x_{\\text{pred}}$。\n\n- **案例 6**：在 $[-2, -1]$ 上使用二分法。\n  类似于案例1和5，但针对位于区间 $[-2, -1]$ 内的根。我们找到 $f_\\varepsilon(x) = f(x) + 10^{-6}x$ 的 $x_0$ 和 $x_\\varepsilon$，然后计算 $\\Delta x_{\\text{obs}}$ 和 $\\Delta x_{\\text{pred}}$。\n\n- **案例 7**：使用不同扰动的牛顿法。\n  使用 $x_{\\text{init}} = 0.3$，我们找到基准根 $x_0$。然后我们找到 $f_\\varepsilon(x) = f(x) + 10^{-12}\\sin(x)$ 的扰动根 $x_\\varepsilon$，使用导数 $f'_\\varepsilon(x) = 3x^2 - 3 + 10^{-12}\\cos(x)$。最后，我们计算 $\\Delta x_{\\text{obs}}$ 和 $\\Delta x_{\\text{pred}} = |\\varepsilon \\sin(x_0) / f'(x_0)|$。\n\n对于小的 $\\varepsilon$，$\\Delta x_{\\text{obs}}$ 和 $\\Delta x_{\\text{pred}}$ 之间的一致性为我们的一阶敏感性分析提供了经验验证。条件数的大小由 $|f'(x_0)|$ 决定，当 $|f'(x_0)|$ 小时条件数大，它决定了对于给定的扰动，根位移的大小。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the root-finding algorithms and computes the required outputs for the seven test cases.\n    \"\"\"\n    # Define global parameters for algorithms\n    TOL = 1e-14\n    MAX_ITER = 200\n\n    # Define the base function and its derivative\n    def f(x):\n        return x**3 - 3*x + 1\n\n    def f_prime(x):\n        return 3*x**2 - 3\n\n    # Define perturbation functions and their derivatives\n    def g_x(x): return x\n    def g_x_prime(x): return 1.0\n    def g_sin(x): return np.sin(x)\n    def g_sin_prime(x): return np.cos(x)\n\n    # --- Numerical Method Implementations ---\n\n    def bisection(func, a, b, tol=TOL, max_iter=MAX_ITER):\n        \"\"\"\n        Bisection method for root finding.\n        Returns the root and the number of iterations.\n        \"\"\"\n        fa = func(a)\n        if fa * func(b) = 0:\n            # This should not happen with the given problem setup.\n            raise ValueError(\"Function has the same sign at interval endpoints.\")\n        \n        iterations = 0\n        while (b - a)  tol and iterations  max_iter:\n            iterations += 1\n            c = a + (b - a) / 2.0\n            fc = func(c)\n            if fc == 0.0:\n                break\n            if fa * fc  0:\n                b = c\n            else:\n                a = c\n                fa = fc\n        return a + (b - a) / 2.0, iterations\n\n    def newton(func, func_prime, x0, tol=TOL, max_iter=MAX_ITER):\n        \"\"\"\n        Newton-Raphson method for root finding.\n        Returns the root and the number of iterations.\n        \"\"\"\n        xk = x0\n        iterations = 0\n        while iterations  max_iter:\n            iterations += 1\n            f_val = func(xk)\n            fp_val = func_prime(xk)\n            \n            # The problem specifies to proceed even if fp_val is very small.\n            if fp_val == 0.0:\n                # This would cause a division by zero.\n                # A robust solver might stop, but we follow instructions.\n                # In this specific problem, it doesn't happen at relevant points.\n                break \n\n            step = f_val / fp_val\n            xk_next = xk - step\n            \n            if abs(step)  tol:\n                return xk_next, iterations\n            \n            xk = xk_next\n        return xk, iterations\n\n    # --- Test Case Execution ---\n\n    results = []\n\n    # Case 1: Bisection on [1, 2], eps=1e-6, g(x)=x\n    eps1 = 1e-6\n    g1, _ = g_x, g_x_prime\n    f_eps1 = lambda x: f(x) + eps1 * g1(x)\n    \n    x0_c1, _ = bisection(f, 1.0, 2.0)\n    xe_c1, _ = bisection(f_eps1, 1.0, 2.0)\n    \n    dx_obs1 = abs(xe_c1 - x0_c1)\n    dx_pred1 = abs((eps1 * g1(x0_c1)) / f_prime(x0_c1))\n    results.extend([dx_obs1, dx_pred1])\n    \n    # Stash baseline root for Case 4\n    baseline_bisection_root_from_c1 = x0_c1\n\n    # Case 2: Newton, x_init=1.3, eps=1e-6, g(x)=x\n    eps2 = 1e-6\n    g2, g2_prime = g_x, g_x_prime\n    f_eps2 = lambda x: f(x) + eps2 * g2(x)\n    fp_eps2 = lambda x: f_prime(x) + eps2 * g2_prime(x)\n\n    x0_c2, _ = newton(f, f_prime, 1.3)\n    xe_c2, _ = newton(f_eps2, fp_eps2, 1.3)\n\n    dx_obs2 = abs(xe_c2 - x0_c2)\n    dx_pred2 = abs((eps2 * g2(x0_c2)) / f_prime(x0_c2))\n    results.extend([dx_obs2, dx_pred2])\n\n    # Stash baseline root for Case 3\n    baseline_newton_root_from_c2 = x0_c2\n\n    # Case 3: Newton, x_init=0.2, eps=0\n    x_c3, n_c3 = newton(f, f_prime, 0.2)\n    dx_c3 = abs(x_c3 - baseline_newton_root_from_c2)\n    results.extend([dx_c3, n_c3])\n\n    # Case 4: Bisection, [1.1, 2.0], eps=0\n    x_c4, n_c4 = bisection(f, 1.1, 2.0)\n    dx_c4 = abs(x_c4 - baseline_bisection_root_from_c1)\n    results.extend([dx_c4, n_c4])\n\n    # Case 5: Bisection on [0, 1], eps=1e-6, g(x)=x\n    eps5 = 1e-6\n    g5, _ = g_x, g_x_prime\n    f_eps5 = lambda x: f(x) + eps5 * g5(x)\n\n    x0_c5, _ = bisection(f, 0.0, 1.0)\n    xe_c5, _ = bisection(f_eps5, 0.0, 1.0)\n\n    dx_obs5 = abs(xe_c5 - x0_c5)\n    dx_pred5 = abs((eps5 * g5(x0_c5)) / f_prime(x0_c5))\n    results.extend([dx_obs5, dx_pred5])\n\n    # Case 6: Bisection on [-2, -1], eps=1e-6, g(x)=x\n    eps6 = 1e-6\n    g6, _ = g_x, g_x_prime\n    f_eps6 = lambda x: f(x) + eps6 * g6(x)\n\n    x0_c6, _ = bisection(f, -2.0, -1.0)\n    xe_c6, _ = bisection(f_eps6, -2.0, -1.0)\n\n    dx_obs6 = abs(xe_c6 - x0_c6)\n    dx_pred6 = abs((eps6 * g6(x0_c6)) / f_prime(x0_c6))\n    results.extend([dx_obs6, dx_pred6])\n\n    # Case 7: Newton, x_init=0.3, eps=1e-12, g(x)=sin(x)\n    eps7 = 1e-12\n    g7, g7_prime = g_sin, g_sin_prime\n    f_eps7 = lambda x: f(x) + eps7 * g7(x)\n    fp_eps7 = lambda x: f_prime(x) + eps7 * g7_prime(x)\n\n    x0_c7, _ = newton(f, f_prime, 0.3)\n    xe_c7, _ = newton(f_eps7, fp_eps7, 0.3)\n\n    dx_obs7 = abs(xe_c7 - x0_c7)\n    dx_pred7 = abs((eps7 * g7(x0_c7)) / f_prime(x0_c7))\n    results.extend([dx_obs7, dx_pred7])\n\n    # --- Final Output ---\n    # Convert all results to string, join with commas, and enclose in brackets.\n    output_str = f\"[{','.join(map(str, results))}]\"\n    print(output_str)\n\nsolve()\n```", "id": "3110311"}, {"introduction": "最后，我们将把条件数的概念应用到计算科学的核心领域——线性代数中的特征值问题。这个练习旨在揭示一个惊人但至关重要的现象：问题的条件数很大程度上取决于输入的数学结构。你将通过具体的数值实验，对比对称矩阵和非正规矩阵在微小扰动下特征值和特征向量的稳定性差异，从而深刻理解为什么对称矩阵的特征值问题是“良态”的，而非正规矩阵则可能表现出极端的敏感性 [@problem_id:3110268]。", "problem": "考虑有限维实矩阵在微小加性变化下的特征值和特征向量的扰动。使用以下基本知识：矩阵的特征值和特征向量的定义、矩阵的诱导算子 $2$-范数、实对称矩阵的谱定理，以及非对称可对角化矩阵的左、右特征向量的概念。您的程序必须使用两个互补的思想来量化敏感度：对称矩阵的特征向量旋转的几何学，以及基于非正规矩阵的左、右特征向量的特征值条件数。\n\n在推理和实现中使用的定义：\n- 对于实矩阵 $M$，其诱导算子 $2$-范数是 $\\|M\\|_{2}$，定义为 $M$ 的最大奇异值。\n- 对于实对称矩阵 $A$，令 $\\lambda_{i}(A)$ 表示其特征值， $u_{i}(A)$ 表示相应的单位范数特征向量。\n- 对于可对角化的实矩阵（可能非对称）$B$，令 $x_{i}(B)$ 表示右特征向量，$y_{i}(B)$ 表示与同一（单）特征值 $\\lambda_{i}(B)$ 相关联的左特征向量，满足 $B x_{i}(B) = \\lambda_{i}(B) x_{i}(B)$ 和 $y_{i}(B)^{\\mathsf{T}} B = \\lambda_{i}(B) y_{i}(B)^{\\mathsf{T}}$。特征值条件数定义为\n$$\n\\kappa_{i}(B) = \\frac{\\|x_{i}(B)\\|_{2}\\,\\|y_{i}(B)\\|_{2}}{\\left|y_{i}(B)^{\\mathsf{T}} x_{i}(B)\\right|},\n$$\n该值与 $x_{i}(B)$ 和 $y_{i}(B)$ 的缩放无关。\n- 对于目标单特征向量 $u_{i}(A)$ 和扰动矩阵 $A + \\Delta$，定义 $u_{i}(A)$ 与匹配的扰动单位特征向量 $u_{i}(A+\\Delta)$ 之间主角 $\\theta_{i}$ 为 $\\cos(\\theta_{i}) = \\left|u_{i}(A)^{\\mathsf{T}} u_{i}(A+\\Delta)\\right|$ 和 $\\sin(\\theta_{i}) = \\sqrt{1 - \\cos^{2}(\\theta_{i})}$。$\\lambda_{i}(A)$ 的谱隙为 $\\mathrm{gap}_{i} = \\min_{j \\neq i} \\left|\\lambda_{i}(A) - \\lambda_{j}(A)\\right|$。\n\n您的任务是实现一个程序，为指定的测试套件计算以下敏感度比率：\n- 对称特征值敏感度比率：\n$$\nr_{\\text{sym-eig}} = \\frac{\\max_{i} \\left|\\lambda_{i}(A+\\Delta) - \\lambda_{i}(A)\\right|}{\\|\\Delta\\|_{2}}.\n$$\n比较 $A$ 和 $A+\\Delta$ 时，应通过邻近性匹配特征值。\n- 具有 Davis–Kahan 型上界的对称特征向量旋转比率：\n$$\nr_{\\text{DK}} = \\frac{\\sin(\\theta_{i})}{\\min\\left(1, \\|\\Delta\\|_{2} / \\mathrm{gap}_{i}\\right)},\n$$\n为达到最小谱隙的索引 $i$ 计算。\n- 由特征值条件数归一化的非正规特征值敏感度比率：\n$$\nr_{\\text{non-normal}} = \\max_{i} \\frac{\\left|\\lambda_{i}(B+\\Delta) - \\lambda_{i}(B)\\right|}{\\kappa_{i}(B)\\,\\|\\Delta\\|_{2}},\n$$\n其中 $\\kappa_{i}(B)$ 使用通过特征值邻近性匹配的 $B$ 的左、右特征向量计算。同时报告 $\\kappa_{\\max}(B) = \\max_{i} \\kappa_{i}(B)$。\n\n测试套件矩阵和扰动：\n1. 对称、谱分离良好（理想情况）：\n$$\nA_{1} = \\begin{bmatrix}\n2  0.1  0 \\\\\n0.1  3  0.2 \\\\\n0  0.2  5\n\\end{bmatrix},\\quad\n\\Delta_{1} = 10^{-8}\\begin{bmatrix}\n0.5  0.1  -0.05 \\\\\n0.1  -0.2  0.02 \\\\\n-0.05  0.02  0.3\n\\end{bmatrix}.\n$$\n计算 $(A_{1}, \\Delta_{1})$ 的 $r_{\\text{sym-eig}}$。\n2. 对称、小谱隙（特征向量敏感度的边界条件）：\n$$\nA_{2} = \\begin{bmatrix}\n1  10^{-3}  0 \\\\\n10^{-3}  1  0 \\\\\n0  0  4\n\\end{bmatrix},\\quad\n\\Delta_{2} = 10^{-6}\\begin{bmatrix}\n0.3  -0.1  0 \\\\\n-0.1  0.2  0 \\\\\n0  0  -0.4\n\\end{bmatrix}.\n$$\n在 $A_{2}$ 中识别具有最小谱隙的索引 $i$，通过特征值邻近性匹配其在 $A_{2} + \\Delta_{2}$ 中的特征向量，并计算 $(A_{2}, \\Delta_{2})$ 的 $r_{\\text{DK}}$。\n3. 强非正规、近乎亏损的行为（特征值敏感度的边缘情况）：\n$$\nB_{1} = \\begin{bmatrix}\n1  1000 \\\\\n0  1.0001\n\\end{bmatrix},\\quad\n\\Delta_{3} = 10^{-8}\\begin{bmatrix}\n0  1 \\\\\n0  0\n\\end{bmatrix}.\n$$\n计算 $(B_{1}, \\Delta_{3})$ 的 $r_{\\text{non-normal}}$，并计算 $\\kappa_{\\max}(B_{1})$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含四个结果\n$$\n[r_{\\text{sym-eig}}, r_{\\text{DK}}, r_{\\text{non-normal}}, \\kappa_{\\max}(B_{1})]\n$$\n以方括号括起的逗号分隔列表形式，顺序需与所示完全一致，并使用标准十进制表示法表示实数（无百分号）。\n\n不需要用户输入；所有数据均已在上方提供。程序必须能在 modern 环境中按原样运行。", "solution": "该问题要求计算矩阵在微小加性扰动下特征值和特征向量的几个敏感度指标。分析分为三种情况，每种情况都旨在探究矩阵扰动理论的特定方面。计算依赖于数值线性代数的基本原理，包括对称矩阵的谱定理以及左、右特征向量在表征非对称矩阵特征值问题条件数方面的作用。所有数学实体均按要求使用 LaTeX 渲染。\n\n首先，我们讨论实对称矩阵特征值的敏感度。对于对称矩阵 $A$ 和对称扰动 $\\Delta$，Weyl 不等式为特征值的扰动提供了一个严格的界限：\n$$\n\\max_{i} \\left|\\lambda_{i}(A+\\Delta) - \\lambda_{i}(A)\\right| \\le \\|\\Delta\\|_{2}.\n$$\n这意味着实对称矩阵的特征值问题总是良态的，其条件数为 $1$。量 $r_{\\text{sym-eig}}$ 直接衡量了这种关系。对于第一个测试用例，我们有：\n$$\nA_{1} = \\begin{bmatrix}\n2  0.1  0 \\\\\n0.1  3  0.2 \\\\\n0  0.2  5\n\\end{bmatrix},\\quad\n\\Delta_{1} = 10^{-8}\\begin{bmatrix}\n0.5  0.1  -0.05 \\\\\n0.1  -0.2  0.02 \\\\\n-0.05  0.02  0.3\n\\end{bmatrix}.\n$$\n为计算 $r_{\\text{sym-eig}}$，我们执行以下步骤：\n$1$. 计算 $A_1$ 和 $A_1 + \\Delta_1$ 的特征值。由于它们是对称矩阵，我们使用一个返回已排序实特征值的数值稳定算法。让这些特征值分别为 $\\{\\lambda_{i}(A_1)\\}$ 和 $\\{\\lambda_{i}(A_1+\\Delta_1)\\}$，按非降序排列。\n$2$. 计算相应特征值之间的最大绝对差：$\\max_{i} |\\lambda_{i}(A_1+\\Delta_1) - \\lambda_{i}(A_1)|$。\n$3$. 计算扰动的诱导 $2$-范数 $\\|\\Delta_1\\|_2$，即其最大奇异值。对于对称矩阵，这等于 $\\Delta_1$ 的最大绝对特征值。\n$4$. 于是，比率为 $r_{\\text{sym-eig}} = (\\max_{i} |\\lambda_{i}(A_1+\\Delta_1) - \\lambda_{i}(A_1)|) / \\|\\Delta_1\\|_2$。根据 Weyl 不等式，我们预期 $r_{\\text{sym-eig}} \\le 1$。\n\n其次，我们研究对称矩阵特征向量的敏感度，与特征值不同，如果相应的特征值很接近，特征向量可能高度敏感。Davis-Kahan 定理给出了原始特征向量 $u_i(A)$ 与其扰动对应向量之间角度 $\\theta_i$ 的界。该界的一个简化版本是 $\\sin(\\theta_i) \\lesssim \\|\\Delta\\|_2 / \\mathrm{gap}_i$，其中 $\\mathrm{gap}_i = \\min_{j \\neq i} |\\lambda_i(A) - \\lambda_j(A)|$。比率 $r_{\\text{DK}}$ 旨在测试该界的紧密程度。我们有第二个测试用例：\n$$\nA_{2} = \\begin{bmatrix}\n1  10^{-3}  0 \\\\\n10^{-3}  1  0 \\\\\n0  0  4\n\\end{bmatrix},\\quad\n\\Delta_{2} = 10^{-6}\\begin{bmatrix}\n0.3  -0.1  0 \\\\\n-0.1  0.2  0 \\\\\n0  0  -0.4\n\\end{bmatrix}.\n$$\n$A_2$ 的特征值为 $\\lambda_1 = 1 - 10^{-3} = 0.999$, $\\lambda_2 = 1 + 10^{-3} = 1.001$ 和 $\\lambda_3 = 4$。谱隙为 $\\mathrm{gap}_1 = \\lambda_2 - \\lambda_1 = 0.002$, $\\mathrm{gap}_2 = \\lambda_2 - \\lambda_1 = 0.002$ 和 $\\mathrm{gap}_3 = \\lambda_3 - \\lambda_2 = 2.999$。最小谱隙为 $0.002$，与 $\\lambda_1$ 和 $\\lambda_2$ 相关联。我们选择与 $\\lambda_1$ 对应的特征向量（假设基于 1 的索引，则索引为 $i=1$，若基于 0，则为 $i=0$）。\n计算 $r_{\\text{DK}}$ 的步骤如下：\n$1$. 计算 $A_2$ 的特征值和特征向量。识别具有最小谱隙的索引 $i$，以及相应的特征向量 $u_i(A_2)$ 和谱隙 $\\mathrm{gap}_i$。\n$2$. 计算扰动矩阵 $A_2 + \\Delta_2$ 的特征值和特征向量。\n$3$. 通过找到其对应特征值最接近 $\\lambda_i(A_2)$ 的特征向量来识别扰动特征向量 $u_i(A_2 + \\Delta_2)$。\n$4$. 计算两个单位范数特征向量之间主角的正弦值：$\\sin(\\theta_i) = \\sqrt{1 - (u_i(A_2)^{\\mathsf{T}} u_i(A_2+\\Delta_2))^2}$。请注意，问题中余弦的定义使用了绝对值，以处理特征向量的符号模糊性。\n$5$. 计算 $2$-范数 $\\|\\Delta_2\\|_2$。\n$6$. 计算比率 $r_{\\text{DK}} = \\sin(\\theta_i) / \\min(1, \\|\\Delta_2\\|_2 / \\mathrm{gap}_i)$。我们预期此比率的数量级为 $1$。\n\n第三，我们研究非对称（且非正规）矩阵的特征值敏感度。对于可对角化矩阵 $B$，单特征值 $\\lambda_i$ 的敏感度由其条件数 $\\kappa_i(B) = (\\|x_i\\|_2\\|y_i\\|_2) / |y_i^{\\mathsf{T}}x_i|$ 决定，其中 $x_i$ 和 $y_i$ 是相应的右、左特征向量。一阶扰动界为 $|\\lambda_i(B+\\Delta) - \\lambda_i(B)| \\lesssim \\kappa_i(B)\\|\\Delta\\|_2$。第三个测试用例使用了一个已知为强非正规的矩阵：\n$$\nB_{1} = \\begin{bmatrix}\n1  1000 \\\\\n0  1.0001\n\\end{bmatrix},\\quad\n\\Delta_{3} = 10^{-8}\\begin{bmatrix}\n0  1 \\\\\n0  0\n\\end{bmatrix}.\n$$\n$B_1$ 的特征值是其对角线元素，$\\lambda_1=1$ 和 $\\lambda_2=1.0001$。它们非常接近。\n计算需要两部分：求 $\\kappa_{\\max}(B_1)$ 和 $r_{\\text{non-normal}}$。\n求 $\\kappa_i(B_1)$ 的步骤：\n$1$. 对 $B_1$ 的每个特征值 $\\lambda_i$，从 $B_1 x_i = \\lambda_i x_i$ 计算右特征向量 $x_i$，从 $y_i^{\\mathsf{T}} B_1 = \\lambda_i y_i^{\\mathsf{T}}$ (或 $B_1^{\\mathsf{T}} y_i = \\lambda_i y_i$) 计算左特征向量 $y_i$。\n$2$. 标准数值库提供单位范数的特征向量，因此 $\\|x_i\\|_2 = 1$ 且 $\\|y_i\\|_2 = 1$。公式简化为 $\\kappa_i(B_1) = 1/|y_i^{\\mathsf{T}}x_i|$。必须注意正确配对左、右特征向量。\n$3$. $\\kappa_{\\max}(B_1)$ 是计算出的 $\\kappa_i(B_1)$ 的最大值。\n求 $r_{\\text{non-normal}}$ 的步骤：\n$1$. 计算 $B_1$ 和扰动矩阵 $B_1 + \\Delta_3$ 的特征值。\n$2$. 上三角矩阵的特征值是其对角线元素。对于 $B_1 + \\Delta_3 = \\begin{bmatrix} 1  1000+10^{-8} \\\\ 0  1.0001 \\end{bmatrix}$，特征值仍然是 $1$ 和 $1.0001$。\n$3$. 在这个特定情况下，对于两个特征值，特征值差 $|\\lambda_i(B_1+\\Delta_3) - \\lambda_i(B_1)|$ 恰好为 $0$。\n$4$. 计算 $\\|\\Delta_3\\|_2$。\n$5$. 比率项为 $\\frac{|\\lambda_i(B+\\Delta) - \\lambda_i(B)|}{\\kappa_{i}(B)\\,\\|\\Delta\\|_{2}} = \\frac{0}{\\kappa_{i}(B)\\,\\|\\Delta\\|_{2}} = 0$。\n$6$. 因此，$r_{\\text{non-normal}} = \\max_i(0) = 0$。尽管条件数很大，但这种特定的扰动不会改变特征值，这说明该界并不总是紧密的，且敏感度是具有方向性的。\n我们现在着手进行这些步骤的数值实现。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes sensitivity ratios for eigenvalues and eigenvectors for three test cases.\n    \"\"\"\n    \n    # --- Case 1: Symmetric eigenvalue sensitivity ---\n    A1 = np.array([\n        [2.0, 0.1, 0.0],\n        [0.1, 3.0, 0.2],\n        [0.0, 0.2, 5.0]\n    ])\n    Delta1 = 1e-8 * np.array([\n        [0.5, 0.1, -0.05],\n        [0.1, -0.2, 0.02],\n        [-0.05, 0.02, 0.3]\n    ])\n\n    A1_pert = A1 + Delta1\n    \n    # numpy.linalg.eigh returns sorted eigenvalues for symmetric matrices\n    e_vals_A1, _ = np.linalg.eigh(A1)\n    e_vals_A1_pert, _ = np.linalg.eigh(A1_pert)\n    \n    max_eig_diff_A1 = np.max(np.abs(e_vals_A1_pert - e_vals_A1))\n    norm_Delta1 = np.linalg.norm(Delta1, ord=2)\n    \n    r_sym_eig = max_eig_diff_A1 / norm_Delta1\n\n    # --- Case 2: Symmetric eigenvector rotation ---\n    A2 = np.array([\n        [1.0, 1e-3, 0.0],\n        [1e-3, 1.0, 0.0],\n        [0.0, 0.0, 4.0]\n    ])\n    Delta2 = 1e-6 * np.array([\n        [0.3, -0.1, 0.0],\n        [-0.1, 0.2, 0.0],\n        [0.0, 0.0, -0.4]\n    ])\n\n    A2_pert = A2 + Delta2\n    \n    e_vals_A2, e_vecs_A2 = np.linalg.eigh(A2)\n    e_vals_A2_pert, e_vecs_A2_pert = np.linalg.eigh(A2_pert)\n\n    # Identify index `i` with the minimum spectral gap.\n    # eigh sorts eigenvalues, so the smallest gap is between adjacent eigenvalues.\n    gaps = np.diff(e_vals_A2)\n    min_gap = np.min(gaps)\n    # The minimum gap is between the first two eigenvalues. We select i=0.\n    i_min_gap = np.argmin(gaps)\n    \n    gap_i = min_gap\n    u_i = e_vecs_A2[:, i_min_gap]\n    \n    # The perturbed eigenvector is also at index 0 because the perturbation is small.\n    u_i_pert = e_vecs_A2_pert[:, i_min_gap]\n    \n    # Calculate sin(theta)\n    cos_theta = np.abs(u_i.T @ u_i_pert)\n    # Clamp to 1.0 to avoid domain errors with sqrt due to floating point inaccuracies\n    if cos_theta  1.0:\n        cos_theta = 1.0\n    sin_theta = np.sqrt(1.0 - cos_theta**2)\n\n    norm_Delta2 = np.linalg.norm(Delta2, ord=2)\n    \n    r_DK_denominator = min(1.0, norm_Delta2 / gap_i)\n    r_DK = sin_theta / r_DK_denominator if r_DK_denominator  0 else 0.0\n    \n    # --- Case 3: Non-normal eigenvalue sensitivity ---\n    B1 = np.array([\n        [1.0, 1000.0],\n        [0.0, 1.0001]\n    ])\n    Delta3 = 1e-8 * np.array([\n        [0.0, 1.0],\n        [0.0, 0.0]\n    ])\n\n    # Eigenvalues and right eigenvectors of B1\n    e_vals_B1, r_vecs_B1 = np.linalg.eig(B1)\n\n    # Eigenvalues and left eigenvectors of B1 (eigenvectors of B1.T)\n    # The eigenvalues are complex-typed by default, so we sort on the real part\n    e_vals_B1T, l_vecs_B1_raw = np.linalg.eig(B1.T)\n\n    # Sort eigenvalues and eigenvectors to ensure correct pairing\n    sort_idx_r = np.argsort(e_vals_B1.real)\n    e_vals_B1_s = e_vals_B1[sort_idx_r]\n    r_vecs_B1_s = r_vecs_B1[:, sort_idx_r]\n\n    sort_idx_l = np.argsort(e_vals_B1T.real)\n    l_vecs_B1_s = l_vecs_B1_raw[:, sort_idx_l]\n    \n    # Calculate eigenvalue condition numbers kappa_i\n    kappas = np.zeros_like(e_vals_B1_s, dtype=float)\n    for i in range(len(e_vals_B1_s)):\n        # Eigenvectors from np.linalg.eig are already normalized to unit 2-norm\n        # kappa_i = ||x||*||y|| / |y.T @ x| simplifies to 1 / |y.T @ x|\n        # Use .conj() for robustness, though not strictly needed for real matrices\n        denom = np.abs(np.dot(l_vecs_B1_s[:, i].conj(), r_vecs_B1_s[:, i]))\n        kappas[i] = 1.0 / denom if denom  0 else np.inf\n    \n    kappa_max_B1 = np.max(kappas)\n    \n    # Calculate r_non_normal\n    B1_pert = B1 + Delta3\n    e_vals_B1_pert, _ = np.linalg.eig(B1_pert)\n    e_vals_B1_pert_s = np.sort(e_vals_B1_pert.real) # Sort for matching\n\n    max_eig_diff_B1 = np.abs(e_vals_B1_pert_s - e_vals_B1_s)\n    \n    norm_Delta3 = np.linalg.norm(Delta3, ord=2)\n    \n    # Denominator for the ratio\n    sens_denom = kappas * norm_Delta3\n    r_non_normal_terms = np.zeros_like(sens_denom)\n    # Avoid division by zero if sensitivity denominator is zero\n    non_zero_idx = sens_denom  0\n    r_non_normal_terms[non_zero_idx] = max_eig_diff_B1[non_zero_idx] / sens_denom[non_zero_idx]\n    \n    r_non_normal = np.max(r_non_normal_terms)\n\n    # --- Final Output ---\n    results = [r_sym_eig, r_DK, r_non_normal, kappa_max_B1]\n    \n    # Print in the required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3110268"}]}