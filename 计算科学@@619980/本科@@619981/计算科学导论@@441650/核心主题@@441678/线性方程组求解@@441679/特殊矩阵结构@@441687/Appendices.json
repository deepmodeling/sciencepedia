{"hands_on_practices": [{"introduction": "首先，我们将从一个基础但至关重要的概念开始：矩阵的条件数，它是衡量数值问题敏感性的关键指标。本练习将引导你推导对角矩阵条件数的简洁表达式，并设计一个高效的流式算法，在单次遍历和常数内存使用下完成计算。通过这个实践，你将体会到利用特殊矩阵结构（如此处的对角结构）如何在算法设计中带来巨大的计算优势。[@problem_id:3195472]", "problem": "给定一个实对角矩阵 $D \\in \\mathbb{R}^{n \\times n}$，您可以流式访问其对角线元素，即您一次接收一个序列 $(d_1,d_2,\\dots,d_n)$ 中的元素。目标是设计一个算法，在单次遍历中估计 2-范数条件数 $\\kappa_2(D)$，而无需存储整个序列。您必须根据第一性原理推导出的精确值来验证该估计值。\n\n基本原理：\n- 对于一个非奇异矩阵 $A$，矩阵 2-范数条件数定义为 $\\kappa_2(A) = \\|A\\|_2 \\,\\|A^{-1}\\|_2$，如果 $A$ 是奇异矩阵，则 $\\kappa_2(A) = +\\infty$。\n- 对于一个对角矩阵 $D = \\mathrm{diag}(d_1,\\dots,d_n)$，其奇异值为 $|d_1|,\\dots,|d_n|$。\n\n任务：\n1. 根据上述定义，推导 $\\kappa_2(D)$ 关于对角线元素 $\\{d_i\\}_{i=1}^n$ 的精确表达式。\n2. 设计一个流式算法，该算法对每个 $d_i$ 处理一次，并使用 $\\mathcal{O}(1)$ 的内存，在处理完最后一个元素后，生成一个估计值 $\\widehat{\\kappa}_2(D)$。您的算法应对任何实数 $d_i$ 都正确，包括存在 $d_i=0$ 的情况。\n3. 实现流式估计器和精确计算，在一个固定的测试套件上验证前者相对于后者的正确性。请按此确切顺序使用以下测试用例，每个用例由其对角线序列指定：\n   - 情况 A (常规混合大小和符号): $[\\,3,-1,2,0.5\\,]$。\n   - 情况 B (所有元素大小相等): $[\\,-5,5,-5\\,]$。\n   - 情况 C (包含零，因此是奇异矩阵): $[\\,2,0,-7\\,]$。\n   - 情况 D (单元素对角线): $[\\,-4.2\\,]$。\n   - 情况 E (宽动态范围): $[\\,1\\times 10^{-12},-3.5,2\\times 10^{9},-4\\times 10^{-3}\\,]$。\n   - 情况 F (所有元素为零，奇异矩阵): $[\\,0,0\\,]$。\n\n验证指标和输出：\n- 对于每个用例，计算流式估计值 $\\widehat{\\kappa}_2$ 和精确值 $\\kappa_2$ 之间的绝对相对误差，公式如下\n  $$\n  \\mathrm{err} =\n  \\begin{cases}\n  0,  \\text{if both } \\widehat{\\kappa}_2 \\text{ and } \\kappa_2 \\text{ are } +\\infty,\\\\\n  \\dfrac{\\left|\\,\\widehat{\\kappa}_2 - \\kappa_2\\,\\right|}{\\kappa_2},  \\text{if } \\kappa_2 \\text{ is finite},\\\\\n  +\\infty,  \\text{if } \\kappa_2 \\text{ is } +\\infty \\text{ but } \\widehat{\\kappa}_2 \\text{ is finite}.\n  \\end{cases}\n  $$\n- 您的程序必须输出单行，其中包含一个列表，内有六个浮点数，每个测试用例一个，等于从 A 到 F 的六个误差值，用方括号括起来并用逗号分隔，例如：$[\\,0.0,0.0,0.0,0.0,0.0,0.0\\,]$。如果任何误差为 $+\\infty$，请将其打印为标准的浮点无穷大。\n\n约束和注意事项：\n- 除了对角性之外，不要假设任何先验结构；元素可以是负数，也可以是零。\n- 不涉及物理单位。\n- 不使用角度。\n- 实现不得读取输入，且必须完全按照规定打印一行。", "solution": "所述问题具有科学依据，是适定的，并且内部一致。它提出了计算科学入门中的一个标准任务：将数学定义转化为一个内存高效的算法。所有前提、定义和约束都是标准的且无歧义的。因此，该问题被认为是有效的，并将提供一个解决方案。\n\n任务是推导对角矩阵 $D$ 的 2-范数条件数 $\\kappa_2(D)$ 的精确公式，设计一个单次遍历、常数内存的流式算法来计算它，并使用提供的测试套件与精确计算进行比较以验证此算法。\n\n_1. $\\kappa_2(D)$ 精确表达式的推导_\n\n一个非奇异矩阵 $A$ 的 2-范数条件数定义为 $\\kappa_2(A) = \\|A\\|_2 \\|A^{-1}\\|_2$。如果 $A$ 是奇异矩阵，其条件数定义为 $\\kappa_2(A) = +\\infty$。\n\n矩阵的 2-范数 $\\|A\\|_2$ 等于其最大的奇异值 $\\sigma_{\\max}(A)$。对于一个非奇异矩阵，其逆矩阵的 2-范数 $\\|A^{-1}\\|_2$ 是 $A$ 的最小奇异值的倒数，即 $1/\\sigma_{\\min}(A)$。因此，对于一个非奇异矩阵 $A$，条件数可以表示为其最大奇异值与最小奇异值的比率：\n$$ \\kappa_2(A) = \\frac{\\sigma_{\\max}(A)}{\\sigma_{\\min}(A)} $$\n问题指出，对于一个对角矩阵 $D = \\mathrm{diag}(d_1, d_2, \\dots, d_n)$ 且 $D \\in \\mathbb{R}^{n \\times n}$，其奇异值为其对角线元素的绝对值，即 $\\{|d_1|, |d_2|, \\dots, |d_n|\\}$。\n\n由此可知，$D$ 的最大奇异值为 $\\sigma_{\\max}(D) = \\max_{i} \\{|d_i|\\}$，最小奇异值为 $\\sigma_{\\min}(D) = \\min_{i} \\{|d_i|\\}$。\n\n我们必须考虑两种情况：\n情况 1：矩阵 $D$ 是非奇异的。这当且仅当所有对角线元素 $d_i$ 都非零时发生。在这种情况下，$\\sigma_{\\min}(D) = \\min_{i} \\{|d_i|\\} > 0$。条件数是有限的，由下式给出：\n$$ \\kappa_2(D) = \\frac{\\max_{i} \\{|d_i|\\}}{\\min_{i} \\{|d_i|\\}} $$\n情况 2：矩阵 $D$ 是奇异的。这当且仅当至少有一个对角线元素 $d_i$ 为零时发生。在这种情况下，$\\sigma_{\\min}(D) = \\min_{i} \\{|d_i|\\} = 0$。根据定义，奇异矩阵的条件数是无穷大。这与公式一致，因为除以零会得到无穷大（假设矩阵不是零矩阵，对于零矩阵 $\\sigma_{\\max}(D)$ 也将为 0）。对于任何奇异矩阵，包括零矩阵，我们取 $\\kappa_2(D) = +\\infty$。\n\n综合这两种情况，我们得到对角矩阵条件数的完整表达式：\n$$\n\\kappa_2(D) =\n\\begin{cases}\n\\dfrac{\\max_{i} \\{|d_i|\\}}{\\min_{i} \\{|d_i|\\}},  \\text{if } \\min_{i} \\{|d_i|\\} > 0 \\\\\n+\\infty,  \\text{if } \\min_{i} \\{|d_i|\\} = 0\n\\end{cases}\n$$\n\n_2. 流式算法的设计_\n\n目标是在单次遍历对角线元素 $(d_1, d_2, \\dots, d_n)$ 的过程中，使用常数（即 $\\mathcal{O}(1)$）内存来计算 $\\kappa_2(D)$。这意味着我们不能存储整个元素序列。\n\n根据推导出的公式，计算只需要对角线元素绝对值集合 $\\{|d_i|\\}$ 中的两个值：最大值和最小值。这两个值都可以在单次遍历中用常数内存计算出来。\n\n该算法流程如下：\n1.  初始化两个变量：一个用于跟踪到目前为止所见的最大绝对值 `max_abs_d`，另一个用于跟踪最小值 `min_abs_d`。一个稳健的初始化方法是将 `max_abs_d` 设置为 $0$，将 `min_abs_d` 设置为 $+\\infty$。\n2.  逐个处理对角线元素 $d_i$ 的数据流。\n3.  对于每个元素 $d_i$：\n    a. 计算其绝对值 $|d_i|$。\n    b. 更新最大值：`max_abs_d = max(max_abs_d, |d_i|)`。\n    c. 更新最小值：`min_abs_d = min(min_abs_d, |d_i|)`。\n4.  在处理完整个数据流后，计算最终的条件数：\n    a. 如果 `min_abs_d` 为 $0$，则矩阵是奇异的，结果为 $+\\infty$。\n    b. 如果 `min_abs_d` 大于 $0$，则矩阵是非奇异的，结果为比率 `max_abs_d / min_abs_d`。\n\n该算法无论矩阵大小 $n$ 如何，都只需要存储两个浮点数（`max_abs_d` 和 `min_abs_d`），从而满足 $\\mathcal{O}(1)$ 的内存约束。\n\n_3. 验证_\n\n问题将流式算法的输出称为“估计值”$\\widehat{\\kappa}_2(D)$。然而，根据设计，该算法计算的是对角线元素绝对值的精确最大值和最小值。因此，其结果不是一个近似值，而是在数学上与先存储所有元素再计算的“批处理”算法所得的值完全相同。因此，在假设完美算术的情况下，将流式结果与精确结果进行比较的验证步骤，预计将对所有测试用例产生0的绝对相对误差。所提供的测试用例不包含会用标准双精度浮点数引起精度问题的值。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of estimating the condition number of a diagonal matrix\n    from a stream of its diagonal entries and validating the result.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A (general mixed magnitudes and signs)\n        [3.0, -1.0, 2.0, 0.5],\n        # Case B (all equal magnitude)\n        [-5.0, 5.0, -5.0],\n        # Case C (contains zero, hence singular)\n        [2.0, 0.0, -7.0],\n        # Case D (single-element diagonal)\n        [-4.2],\n        # Case E (wide dynamic range)\n        [1e-12, -3.5, 2e9, -4e-3],\n        # Case F (all zeros, singular)\n        [0.0, 0.0]\n    ]\n\n    def compute_exact_kappa(diag_entries):\n        \"\"\"\n        Computes the exact condition number by storing all entries.\n        This serves as the ground truth for validation.\n        \"\"\"\n        if not diag_entries:\n            # The condition number of a 0x0 matrix is conventionally 1.\n            # This case is not in the test suite.\n            return 1.0\n\n        abs_vals = np.abs(np.array(diag_entries))\n        min_abs_val = np.min(abs_vals)\n\n        if min_abs_val == 0:\n            return np.inf\n\n        max_abs_val = np.max(abs_vals)\n        return max_abs_val / min_abs_val\n\n    def compute_streaming_kappa(diag_stream):\n        \"\"\"\n        Computes the condition number in a single pass with O(1) memory.\n        This is the \"estimator\" to be validated.\n        \"\"\"\n        if not diag_stream:\n            # Match the exact computation for the empty case.\n            return 1.0\n\n        # Initialize max_abs_d to 0 and min_abs_d to +infinity.\n        # This handles all cases, including first element, correctly.\n        max_abs_d = 0.0\n        min_abs_d = np.inf\n\n        for d in diag_stream:\n            current_abs_d = abs(d)\n            if current_abs_d > max_abs_d:\n                max_abs_d = current_abs_d\n            if current_abs_d  min_abs_d:\n                min_abs_d = current_abs_d\n        \n        # After the loop, if min_abs_d is 0, the matrix is singular.\n        if min_abs_d == 0:\n            return np.inf\n        \n        # Otherwise, the matrix is nonsingular.\n        return max_abs_d / min_abs_d\n\n    error_results = []\n    for case in test_cases:\n        kappa_2 = compute_exact_kappa(case)\n        kappa_2_hat = compute_streaming_kappa(case)\n\n        # Calculate the absolute relative error based on the problem's definition.\n        err = 0.0\n        if kappa_2 == np.inf and kappa_2_hat == np.inf:\n            err = 0.0\n        elif kappa_2 == np.inf:  # Implies kappa_2_hat is finite\n            err = np.inf \n        elif kappa_2 > 0: # kappa_2 is finite and positive\n            err = abs(kappa_2_hat - kappa_2) / kappa_2\n        # The remaining case is kappa_2 = 0, which is impossible for a condition number.\n        \n        error_results.append(err)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, error_results))}]\")\n\nsolve()\n```", "id": "3195472"}, {"introduction": "接下来，我们将探讨算法与矩阵结构之间的动态交互。高斯消去法（LU分解）是求解线性系统的基石，但为了保证数值稳定性，通常需要采用部分主元法，这可能会改变矩阵原有的特殊结构。这个练习将模拟这一过程，研究当LU分解应用于三角矩阵和对角矩阵时，行交换如何导致“填充”（fill-in）现象，即原本为零的元素变为非零值。通过这个动手实验，你将量化结构的破坏程度，并深刻理解数值算法在实践中的复杂性。[@problem_id:3195468]", "problem": "您的任务是研究高斯消元过程中的浮点舍入和行主元选择如何破坏或改变特殊的三角结构并产生填充（fill-in）。该研究将基于以下基本定义和模型：\n\n- 一个矩阵 $T \\in \\mathbb{R}^{n \\times n}$，如果对所有 $i > j$ 都有 $T_{ij} = 0$，则为上三角矩阵；如果对所有 $i  j$ 都有 $T_{ij} = 0$，则为下三角矩阵；如果对所有 $i \\neq j$ 都有 $T_{ij} = 0$，则为对角矩阵。\n- 带部分行主元选择的高斯消元法是一个过程，对于一个矩阵 $A$，它计算出一个置换矩阵 $P$、一个单位下三角矩阵 $L$ 和一个上三角矩阵 $U$，使得 $P A = L U$ 成立。这被称为 LU 分解（Lower-Upper factorization, LU）。\n- 在浮点运算中，我们通过关系式 $\\mathrm{fl}(x \\,\\mathrm{op}\\, y) = (x \\,\\mathrm{op}\\, y)(1 + \\delta)$ 来模拟每次运算的舍入效应，其中 $\\mathrm{op}$ 表示一个基本算术运算，且 $|\\delta| \\le \\epsilon_{\\mathrm{mach}}$，$\\epsilon_{\\mathrm{mach}}$ 为一个小的单位舍入误差。\n\n您的程序必须为每个测试用例构建一个指定的特殊结构矩阵 $T$，计算对 $T$ 应用带部分主元选择的 LU 分解所产生的上三角因子 $U$，然后量化结构变化和数值差异。请使用以下定义和步骤：\n\n- 定义一个容差 $\\tau = 10^{-12}$，用于在浮点运算下将数值分类为有效零。\n- 定义填充计数 $f$ 为满足 $|T_{ij}| \\le \\tau$ 且 $|U_{ij}| > \\tau$ 的索引 $(i,j)$ 的数量。\n- 定义弗罗贝尼乌斯范数差 $d_F$ 为 $d_F = \\|U - T\\|_F = \\left(\\sum_{i=1}^{n}\\sum_{j=1}^{n} (U_{ij} - T_{ij})^2\\right)^{1/2}$。\n- 定义最大绝对逐元差 $d_{\\max}$ 为 $d_{\\max} = \\max_{1 \\le i,j \\le n} |U_{ij} - T_{ij}|$。\n\n构建以下矩阵测试套件，每个矩阵都由 $n$ 和元素公式精确定义：\n\n- 测试用例 1（下三角，稠密次对角线）：$n = 4$，其中\n  $$\n  T_{ij} =\n  \\begin{cases}\n  1  \\text{if } i = j, \\\\\n  2  \\text{if } i > j, \\\\\n  0  \\text{if } i  j.\n  \\end{cases}\n  $$\n- 测试用例 2（上三角，稠密超对角线）：$n = 4$，其中\n  $$\n  T_{ij} =\n  \\begin{cases}\n  1  \\text{if } i = j, \\\\\n  \\frac{1}{2}  \\text{if } i  j, \\\\\n  0  \\text{if } i > j.\n  \\end{cases}\n  $$\n- 测试用例 3（下三角，微小对角线）：$n = 5$，其中\n  $$\n  T_{ij} =\n  \\begin{cases}\n  10^{-16}  \\text{if } i = j, \\\\\n  1  \\text{if } i > j, \\\\\n  0  \\text{if } i  j.\n  \\end{cases}\n  $$\n- 测试用例 4（对角，数量级差异大）：$n = 5$，对角线元素为\n  $$\n  \\operatorname{diag}(T) = [10^{-16},\\, 10^{-8},\\, 1,\\, 10^{8},\\, 10^{16}],\n  $$\n  且对于所有 $i \\neq j$ 都有 $T_{ij} = 0$。\n\n对于每个测试用例：\n- 通过带部分主元选择的 LU 分解计算 $U$。\n- 计算如上定义的 $f$、$d_F$ 和 $d_{\\max}$。\n- 将浮点输出 $d_F$ 和 $d_{\\max}$ 四舍五入到 $10$ 位小数。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。每个测试用例的结果本身必须是按 $[f, d_F, d_{\\max}]$ 顺序排列、用方括号括起来的逗号分隔列表，并且整个输出不得包含空格。例如，对于两个假设的用例，输出应如下所示：$[[f_1,d_{F,1},d_{\\max,1}],[f_2,d_{F,2},d_{\\max,2}]]$。\n\n您的程序必须是自包含的，不需要用户输入，并严格遵守指定的输出格式。", "solution": "该问题陈述经评估有效。它提出了一个定义明确的计算任务，该任务基于数值线性代数的既定原则。所涉及的矩阵、算法和度量标准都是计算科学中的标准概念。该问题是自包含的、客观的且科学上合理的。\n\n### 方法论简介\n\n这个问题的核心是研究矩阵结构、数值稳定性算法和浮点运算之间的相互作用。具体来说，我们分析带部分主元选择的 LU 分解（一种求解线性系统的基本算法）如何影响具有三角或对角形式等特殊结构的矩阵。该过程涉及计算分解 $PA = LU$，其中 $P$ 是一个置换矩阵，$L$ 是一个单位下三角矩阵，$U$ 是一个上三角矩阵。然后，我们将量化所得因子 $U$ 与原始矩阵 $T$ 相比在结构或数值上的任何偏差。\n\n### 原理 1：带部分主元选择的 LU 分解\n\n高斯消元法通过应用一系列初等行变换，将矩阵 $A$ 转换为一个上三角矩阵 $U$。这些操作可以用一个单位下三角矩阵 $L$ 来表示，使得 $A=LU$。为确保数值稳定性，采用了一种称为部分主元选择的策略。在消元的每一步 $k$，算法会检查当前主元列 $k$ 中对角线及其下方的元素，即对于 $i \\ge k$ 的 $A_{ik}^{(k-1)}$。它会找出绝对值最大的元素所在的行，并将该行与当前主元行 $k$ 进行交换。这个过程被记录在一个置换矩阵 $P$ 中。最终得到的分解是 $PA = LU$。\n\n主元选择的目的是使乘数 $L_{ik} = A_{ik}^{(k-1)}/A_{kk}^{(k-1)}$（对于 $i>k$）的量级变小（具体来说，是 $|L_{ik}| \\le 1$）。这有助于在消元过程中控制矩阵元素的增长，从而减轻浮点运算中固有的舍入误差的传播。\n\n### 原理 2：与特殊矩阵结构的相互作用\n\n主元选择的有效性和后果在很大程度上取决于矩阵 $T$ 的初始结构。\n\n- **上三角矩阵**：如果 $T$ 已经是上三角矩阵，则无需进行消元。如果对于每一列 $j$，对角主元候选 $T_{jj}$ 的量级大于或等于所有次对角线元素（均为零），则不会发生行交换。在这种理想情况下，$P$ 将是单位矩阵 $I$，$L$ 也将是 $I$，得到的上三角因子就是原始矩阵本身，即 $U=T$。\n- **下三角矩阵**：对于下三角矩阵 $T$，非零元素位于对角线及其下方。如果一个次对角线元素 $|T_{ij}|$（其中 $i > j$）大于对角线元素 $|T_{jj}|$，部分主元选择将强制进行行交换。这种应用于 $T$ 的置换操作会将非零元素从下三角区域移动到正在处理的矩阵的严格上三角区域。对这些新的非零元素进行的后续消元步骤将导致最终的 $U$ 矩阵的严格上三角区域出现非零值。这种 $T$ 中的零元素在 $U$ 中变为非零元素的现象称为**填充（fill-in）**。\n- **对角矩阵**：对角矩阵是上三角矩阵的一种特殊情况，其所有非对角线元素都为零。不需要进行消元，并且由于没有非零的次对角线元素与对角主元竞争，因此不会发生主元选择。其分解是平凡的：$P=I$，$L=I$，$U=T$。\n\n### 原理 3：量化结构和数值变化\n\n为衡量分解过程的影响，我们使用三个度量标准：\n\n1.  **填充计数 ($f$)**：定义为原始矩阵中条目接近于零（$|T_{ij}| \\le \\tau$），但计算出的因子中对应条目为显著非零（$|U_{ij}| > \\tau$）的索引 $(i,j)$ 的数量。该度量标准量化了零结构的破坏程度。容差 $\\tau = 10^{-12}$ 用于区分数值上显著的条目和浮点伪影。\n2.  **弗罗贝尼乌斯范数差 ($d_F$)**：$d_F = \\|U - T\\|_F$ 衡量 $U$ 和 $T$ 在所有条目上的总数值偏差。\n3.  **最大绝对差 ($d_{\\max}$)**：$d_{\\max} = \\max_{i,j} |U_{ij} - T_{ij}|$ 标识出单个最大的偏差点，突显了最坏情况下的数值变化。\n\n### 测试用例分析\n\n-   **测试用例 1（下三角）**：矩阵为 $T_{ij} = \\{1 \\text{ if } i=j; 2 \\text{ if } i>j; 0 \\text{ if } i  j\\}$。由于次对角线元素（值为2）大于对角线元素（值为1），主元选择将导致行交换，从而产生显著的填充和数值变化。\n-   **测试用例 2（上三角）**：由于矩阵已经是上三角，并且对角线元素（值为1）是每列中最大的（因为次对角线元素都为零），因此不会发生主元选择。分解将是平凡的，预计填充和数值差均为零。\n-   **测试用例 3（下三角，微小对角线）**：与测试用例1类似，但对角线元素非常小 ($10^{-16}$)，而次对角线元素为1。主元选择将是激进的，导致几乎完全的填充。\n-   **测试用例 4（对角）**：这是一个对角矩阵。由于所有非对角线元素都为零，因此不需要消元，也不会有主元选择。预计分解是平凡的，$U=T$，因此没有填充或数值差。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import lu\n\ndef solve():\n    \"\"\"\n    Analyzes the effect of LU factorization with partial pivoting on\n    special matrix structures.\n    \"\"\"\n    \n    # Define the tolerance for considering a value to be zero.\n    tau = 1e-12\n\n    # Container for all test case results\n    all_results = []\n\n    # --- Test Case 1: Lower triangular, dense subdiagonal ---\n    n1 = 4\n    T1 = np.zeros((n1, n1), dtype=float)\n    T1[np.tril_indices(n1, k=-1)] = 2.0\n    np.fill_diagonal(T1, 1.0)\n\n    # --- Test Case 2: Upper triangular, dense superdiagonal ---\n    n2 = 4\n    T2 = np.zeros((n2, n2), dtype=float)\n    T2[np.triu_indices(n2, k=1)] = 0.5\n    np.fill_diagonal(T2, 1.0)\n    \n    # --- Test Case 3: Lower triangular, tiny diagonal ---\n    n3 = 5\n    T3 = np.zeros((n3, n3), dtype=float)\n    T3[np.tril_indices(n3, k=-1)] = 1.0\n    np.fill_diagonal(T3, 1e-16)\n\n    # --- Test Case 4: Diagonal, widely varying magnitudes ---\n    T4 = np.diag([1e-16, 1e-8, 1.0, 1e8, 1e16])\n    \n    test_cases = [T1, T2, T3, T4]\n\n    for T in test_cases:\n        # Perform LU factorization with partial pivoting\n        # scipy.linalg.lu computes P, L, U such that P @ A = L @ U\n        # This matches the problem description.\n        _, _, U = lu(T)\n\n        # Calculate fill-in count f\n        # f is the number of indices (i,j) where |T_ij| = tau and |U_ij| > tau\n        originally_zero = np.abs(T) = tau\n        u_is_nonzero = np.abs(U) > tau\n        fill_in_mask = np.logical_and(originally_zero, u_is_nonzero)\n        f = int(np.sum(fill_in_mask))\n\n        # Calculate Frobenius norm difference d_F\n        # d_F = ||U - T||_F\n        diff = U - T\n        d_F = np.linalg.norm(diff, 'fro')\n\n        # Calculate maximum absolute entrywise difference d_max\n        # d_max = max |U_ij - T_ij|\n        d_max = np.max(np.abs(diff))\n\n        # Round results to 10 decimal places as required\n        d_F_rounded = round(d_F, 10)\n        d_max_rounded = round(d_max, 10)\n        \n        all_results.append([f, d_F_rounded, d_max_rounded])\n\n    # Format the final output string exactly as specified.\n    # e.g., [[f1,dF1,dmax1],[f2,dF2,dmax2]] with no spaces.\n    case_strings = [f\"[{r[0]},{r[1]},{r[2]}]\" for r in all_results]\n    final_output = f\"[{','.join(case_strings)}]\"\n    \n    print(final_output)\n\nsolve()\n```", "id": "3195468"}, {"introduction": "最后，我们将转向迭代法，并展示如何利用矩阵结构来*加速*而非破坏计算过程。对称正定（SPD）矩阵在科学与工程领域中无处不在，本练习将聚焦于求解这类系统的两种关键迭代方法：最速下降法和共轭梯度法。更重要的是，你将亲手实现对角预条件技术，并观察它如何通过利用矩阵的对角线信息，显著提升求解器在处理病态问题时的收敛速度。这个对比实验将清晰地揭示高级算法和预条件策略在现代计算科学中的强大威力。[@problem_id:3195493]", "problem": "您需要从第一性原理出发，实现求解对称正定（SPD）矩阵线性系统的迭代求解器，并比较对角预处理对收敛性的影响。重点在于特殊的矩阵结构，包括对称矩阵和对角矩阵。考虑使用迭代法求解 SPD 矩阵 $A$ 和向量 $b$ 的系统 $A x = b$。您将实现四种方法：无预处理的最速下降法（SD）、使用 $M=\\operatorname{diag}(A)$ 的对角预处理最速下降法（PSD）、无预处理的共轭梯度法（CG）以及使用相同 $M=\\operatorname{diag}(A)$ 的对角预处理共轭梯度法（PCG）。在所有情况下，使用零向量 $x_0=\\mathbf{0}$作为初始猜测，在 SD 和 PSD 中使用精确线搜索，并且当相对残差范数满足 $\\lVert r_k \\rVert_2 / \\lVert b \\rVert_2 \\leq 10^{-8}$ 或达到 $5n$ 次迭代的最大上限（其中 $n$ 是 $A$ 的维度）时终止每种方法，以先到者为准。不要使用任何外部库中的线性系统或 Krylov 子空间求解器；直接根据核心定义实现算法。\n\n设计的基本原理：\n- 一个 SPD 矩阵 $A$ 是对称的（$A=A^\\top$），并且对于所有非零 $x$ 满足 $x^\\top A x > 0$。\n- 求解 SPD 矩阵 $A$ 的方程 $A x=b$ 等价于最小化严格凸的二次函数 $f(x)=\\tfrac{1}{2} x^\\top A x - b^\\top x$。\n- 最速下降法在每次迭代中沿着 $f(x)$ 的负梯度方向进行，并采用精确线搜索。\n- 共轭梯度法构造 $A$-共轭方向，在 Krylov 子空间中最小化 $f(x)$。\n- 使用 $M=\\operatorname{diag}(A)$ 的对角预处理可对问题进行重新缩放，以在许多情况下改善条件数。\n\n测试套件：\n- 测试用例 1（对角 SPD，基线）：$A_1=\\operatorname{diag}(1,2,3,4)$ 且 $b_1=\\mathbf{1}$，长度为 4。\n- 测试用例 2（结构化 SPD，三对角泊松矩阵）：$A_2 \\in \\mathbb{R}^{50\\times 50}$ 是一个三对角矩阵，主对角线元素为 2，第一副对角线和第一超对角线元素为 -1。设 $b_2=\\mathbf{1}$，长度为 50。\n- 测试用例 3（随机 SPD，中等条件数）：使用固定的伪随机种子，设 $R \\in \\mathbb{R}^{20\\times 20}$ 的元素为独立的标准正态分布，定义 $A_3=R^\\top R + 0.1 I$，并设 $b_3 \\in \\mathbb{R}^{20}$ 的元素为使用相同种子生成的独立标准正态分布。\n- 测试用例 4（对角 SPD，高度病态）：$A_4=\\operatorname{diag}(10^{-6},10^{-3},1,10^{3},10^{6})$ 且 $b_4=\\mathbf{1}$，长度为 5。\n\n对于每个测试用例，按固定顺序（SD, PSD, CG, PCG）计算并记录四种方法达到终止标准所需的迭代次数。您必须为 PSD 和 PCG 使用对角预处理器 $M=\\operatorname{diag}(A)$，并将 $M^{-1}$ 解释为 $A$ 对角线元素逐元素的倒数。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含所有测试用例的汇总结果，格式为逗号分隔的列表的列表。每个内部列表包含四个整数，按此顺序对应 SD、PSD、CG 和 PCG 的迭代次数。输出中不得有空格，且整个输出必须用方括号括起来。例如，对于三个测试用例，您的程序将打印形如 $[[a_{11},a_{12},a_{13},a_{14}],[a_{21},a_{22},a_{23},a_{24}],[a_{31},a_{32},a_{33},a_{34}]]$ 的单行，其中每个 $a_{ij}$ 是一个整数。", "solution": "求解线性系统 $A\\mathbf{x} = \\mathbf{b}$（其中 $A$ 是对称正定（SPD）矩阵）的问题在数学上等价于找到唯一的向量 $\\mathbf{x}$，该向量能最小化严格凸的二次函数 $f(\\mathbf{x}) = \\frac{1}{2}\\mathbf{x}^\\top A \\mathbf{x} - \\mathbf{b}^\\top \\mathbf{x}$。该函数的梯度为 $\\nabla f(\\mathbf{x}) = A\\mathbf{x} - \\mathbf{b}$，即残差 $\\mathbf{r}(\\mathbf{x}) = \\mathbf{b} - A\\mathbf{x}$ 的负值。\n\n针对此问题的迭代法会生成一个逼近解的序列 $\\{\\mathbf{x}_k\\}$，该序列收敛于真实解。从初始猜测 $\\mathbf{x}_0$ 开始，后续的迭代解通过 $\\mathbf{x}_{k+1} = \\mathbf{x}_k + \\alpha_k \\mathbf{p}_k$ 计算，其中 $\\mathbf{p}_k$ 是搜索方向，$\\alpha_k$ 是标量步长。$\\mathbf{p}_k$ 和 $\\alpha_k$ 的选择定义了具体的算法。本实现将探讨四种此类算法。\n\n**1. 最速下降法 (SD)**\n\n最速下降法采用最直观的搜索方向：当前迭代点 $\\mathbf{x}_k$ 处 $f$ 的负梯度方向。该方向对应于目标函数的最大下降方向。\n因此，搜索方向为 $\\mathbf{p}_k = - \\nabla f(\\mathbf{x}_k) = \\mathbf{r}_k$。\n步长 $\\alpha_k$ 通过精确线搜索确定，即找到使 $f(\\mathbf{x}_k + \\alpha \\mathbf{p}_k)$ 最小化的 $\\alpha$。$f(\\mathbf{x}_k + \\alpha \\mathbf{p}_k)$ 关于 $\\alpha$ 的导数在最小值处为零：\n$$ \\frac{d}{d\\alpha} f(\\mathbf{x}_k + \\alpha \\mathbf{p}_k) = \\nabla f(\\mathbf{x}_k + \\alpha \\mathbf{p}_k)^\\top \\mathbf{p}_k = (A(\\mathbf{x}_k + \\alpha \\mathbf{p}_k) - \\mathbf{b})^\\top \\mathbf{p}_k = (A\\mathbf{x}_k - \\mathbf{b} + \\alpha A\\mathbf{p}_k)^\\top \\mathbf{p}_k = (-\\mathbf{r}_k + \\alpha A\\mathbf{p}_k)^\\top \\mathbf{p}_k = 0 $$\n求解 $\\alpha$ 可得最优步长：$\\alpha_k = \\frac{\\mathbf{r}_k^\\top \\mathbf{p}_k}{\\mathbf{p}_k^\\top A \\mathbf{p}_k}$。代入 $\\mathbf{p}_k = \\mathbf{r}_k$，我们得到：\n$$ \\alpha_k = \\frac{\\mathbf{r}_k^\\top \\mathbf{r}_k}{\\mathbf{r}_k^\\top A \\mathbf{r}_k} $$\nSD 算法在每一步 $k$ 更新解和残差：\n$\\mathbf{x}_{k+1} = \\mathbf{x}_k + \\alpha_k \\mathbf{r}_k$\n$\\mathbf{r}_{k+1} = \\mathbf{b} - A\\mathbf{x}_{k+1} = \\mathbf{b} - A(\\mathbf{x}_k + \\alpha_k \\mathbf{r}_k) = (\\mathbf{b} - A\\mathbf{x}_k) - \\alpha_k A\\mathbf{r}_k = \\mathbf{r}_k - \\alpha_k A\\mathbf{r}_k$。\n\n**2. 共轭梯度法 (CG)**\n\n对于病态矩阵，SD 的收敛速度可能很慢。共轭梯度法通过选择 A-正交（或共轭）的搜索方向 $\\mathbf{p}_k$ 来加速收敛，即对于所有 $i \\neq j$ 都有 $\\mathbf{p}_i^\\top A \\mathbf{p}_j = 0$。这一性质确保了沿着新方向 $\\mathbf{p}_k$ 进行的最小化不会破坏在由先前方向 $\\{\\mathbf{p}_0, \\dots, \\mathbf{p}_{k-1}\\}$ 张成的子空间中已达到的最优性。\n\n搜索方向是迭代构造的。从 $\\mathbf{p}_0 = \\mathbf{r}_0$ 开始，后续方向是当前残差和前一个搜索方向的组合：\n$$ \\mathbf{p}_{k+1} = \\mathbf{r}_{k+1} + \\beta_{k+1} \\mathbf{p}_k $$\n选择系数 $\\beta_{k+1}$ 以强制实现 A-正交性。一个常用且高效的选择是：\n$$ \\beta_{k+1} = \\frac{\\mathbf{r}_{k+1}^\\top \\mathbf{r}_{k+1}}{\\mathbf{r}_k^\\top \\mathbf{r}_k} $$\n步长 $\\alpha_k$ 也通过沿 $\\mathbf{p}_k$ 的精确线搜索找到：\n$$ \\alpha_k = \\frac{\\mathbf{r}_k^\\top \\mathbf{p}_k}{\\mathbf{p}_k^\\top A \\mathbf{p}_k} = \\frac{\\mathbf{r}_k^\\top \\mathbf{r}_k}{\\mathbf{p}_k^\\top A \\mathbf{p}_k} $$\n最后一个等式成立是因为 $\\mathbf{p}_k$ 是由 $\\mathbf{r}_k$ 和先前的方向构造的。\n\n**3. 预处理**\n\n迭代求解器的收敛速度与矩阵 $A$ 的条件数 $\\kappa(A)$ 密切相关。预处理是一种技术，用于将线性系统转换为一个等价的、条件数更好且因此更容易求解的系统。我们不求解 $A\\mathbf{x}=\\mathbf{b}$，而是求解预处理后的系统，例如 $M^{-1}A\\mathbf{x} = M^{-1}\\mathbf{b}$，其中 $M$ 是一个预处理器。一个好的预处理器 $M$ 应该近似于 $A$（使得 $M^{-1}A$ 接近单位矩阵 $I$），其本身是 SPD 矩阵，并且能够高效求解形如 $M\\mathbf{z}=\\mathbf{r}$ 的系统。\n\n本问题使用对角预处理，其中 $M$ 是仅包含 $A$ 对角线元素的矩阵：$M = \\operatorname{diag}(A)$。对于一个具有正对角线元素的 SPD 矩阵 $A$，$M$ 也是 SPD 的。求解 $M\\mathbf{z}=\\mathbf{r}$ 在计算上非常简单，仅需要逐元素相除：$\\mathbf{z}_i = \\mathbf{r}_i / M_{ii}$。\n\n**4. 预处理最速下降法 (PSD)**\n\n该方法将最速下降算法应用于预处理问题。等价的二次型基于算子 $M^{-1/2} A M^{-1/2}$。原始变量中的梯度方向对应于预处理后的残差 $\\mathbf{z}_k = M^{-1}\\mathbf{r}_k$。这被用作搜索方向，即 $\\mathbf{p}_k = \\mathbf{z}_k$。\n最小化 $f(\\mathbf{x}_k + \\alpha \\mathbf{z}_k)$ 的精确线搜索步长为：\n$$ \\alpha_k = \\frac{\\mathbf{r}_k^\\top \\mathbf{z}_k}{\\mathbf{z}_k^\\top A \\mathbf{z}_k} $$\n\n**5. 预处理共轭梯度法 (PCG)**\n\nPCG 是将共轭梯度法应用于预处理系统。这是四种方法中最有效的一种。该算法经过修改，以保持相对于预处理矩阵 $M^{-1}A$ 的共轭性。这是通过在每次迭代中加入一个用 $M$ 求解的步骤来实现的。算法如下：\n初始化 $\\mathbf{x}_0 = \\mathbf{0}$，$\\mathbf{r}_0 = \\mathbf{b}$，求解 $M\\mathbf{z}_0 = \\mathbf{r}_0$，设置 $\\mathbf{p}_0 = \\mathbf{z}_0$。\n对于每次迭代 $k$：\n$$ \\alpha_k = \\frac{\\mathbf{r}_k^\\top \\mathbf{z}_k}{\\mathbf{p}_k^\\top A \\mathbf{p}_k} $$\n$$ \\mathbf{x}_{k+1} = \\mathbf{x}_k + \\alpha_k \\mathbf{p}_k $$\n$$ \\mathbf{r}_{k+1} = \\mathbf{r}_k - \\alpha_k A\\mathbf{p}_k $$\n求解 $M\\mathbf{z}_{k+1} = \\mathbf{r}_{k+1}$。\n$$ \\beta_{k+1} = \\frac{\\mathbf{r}_{k+1}^\\top \\mathbf{z}_{k+1}}{\\mathbf{r}_k^\\top \\mathbf{z}_k} $$\n$$ \\mathbf{p}_{k+1} = \\mathbf{z}_{k+1} + \\beta_{k+1} \\mathbf{p}_k $$\n\n**实现与终止条件**\n\n所有四种算法都基于这些第一性原理实现。初始猜测设置为零向量 $\\mathbf{x}_0 = \\mathbf{0}$。迭代将持续进行，直到相对残差范数降至指定容差以下，即 $\\lVert \\mathbf{r}_k \\rVert_2 / \\lVert \\mathbf{b} \\rVert_2 \\leq 10^{-8}$，或直到完成最多 $5n$ 次迭代（其中 $n$ 是矩阵 $A$ 的维度）。对于每种方法和每个测试用例，记录满足该标准所需的迭代次数。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# from scipy import ...\n\ndef solve_sd(A, b):\n    \"\"\"\n    Implements the unpreconditioned Steepest Descent (SD) method.\n    \"\"\"\n    n = A.shape[0]\n    max_iter = 5 * n\n    tol = 1e-8\n    \n    x = np.zeros(n, dtype=np.float64)\n    r = b.copy()\n    norm_b = np.linalg.norm(b)\n\n    if norm_b == 0:\n        return 0\n\n    for k in range(max_iter):\n        r_sq_norm = r @ r\n        Ar = A @ r\n        r_Ar_dot = r @ Ar\n\n        # Avoid division by zero if r is in the null space of A\n        if r_Ar_dot == 0:\n            break\n\n        alpha = r_sq_norm / r_Ar_dot\n        x += alpha * r\n        r -= alpha * Ar\n        \n        if np.linalg.norm(r) / norm_b = tol:\n            return k + 1\n            \n    return max_iter\n\ndef solve_psd(A, b):\n    \"\"\"\n    Implements the diagonally preconditioned Steepest Descent (PSD) method.\n    \"\"\"\n    n = A.shape[0]\n    max_iter = 5 * n\n    tol = 1e-8\n\n    x = np.zeros(n, dtype=np.float64)\n    r = b.copy()\n    norm_b = np.linalg.norm(b)\n\n    if norm_b == 0:\n        return 0\n    \n    M_inv_diag = 1.0 / np.diag(A)\n    \n    for k in range(max_iter):\n        z = M_inv_diag * r\n        r_z_dot = r @ z\n        Az = A @ z\n        z_Az_dot = z @ Az\n\n        if z_Az_dot == 0:\n            break\n\n        alpha = r_z_dot / z_Az_dot\n        x += alpha * z\n        r -= alpha * Az\n\n        if np.linalg.norm(r) / norm_b = tol:\n            return k + 1\n\n    return max_iter\n\ndef solve_cg(A, b):\n    \"\"\"\n    Implements the unpreconditioned Conjugate Gradient (CG) method.\n    \"\"\"\n    n = A.shape[0]\n    max_iter = 5 * n\n    tol = 1e-8\n    \n    x = np.zeros(n, dtype=np.float64)\n    r = b.copy()\n    p = r.copy()\n    norm_b = np.linalg.norm(b)\n\n    if norm_b == 0:\n        return 0\n\n    r_sq_norm_old = r @ r\n\n    for k in range(max_iter):\n        Ap = A @ p\n        p_Ap_dot = p @ Ap\n\n        if p_Ap_dot == 0:\n            break\n        \n        alpha = r_sq_norm_old / p_Ap_dot\n        x += alpha * p\n        r -= alpha * Ap\n        \n        if np.linalg.norm(r) / norm_b = tol:\n            return k + 1\n        \n        r_sq_norm_new = r @ r\n        beta = r_sq_norm_new / r_sq_norm_old\n        p = r + beta * p\n        r_sq_norm_old = r_sq_norm_new\n\n    return max_iter\n    \ndef solve_pcg(A, b):\n    \"\"\"\n    Implements the diagonally preconditioned Conjugate Gradient (PCG) method.\n    \"\"\"\n    n = A.shape[0]\n    max_iter = 5 * n\n    tol = 1e-8\n\n    x = np.zeros(n, dtype=np.float64)\n    r = b.copy()\n    norm_b = np.linalg.norm(b)\n\n    if norm_b == 0:\n        return 0\n\n    M_inv_diag = 1.0 / np.diag(A)\n    z = M_inv_diag * r\n    p = z.copy()\n    r_z_dot_old = r @ z\n\n    for k in range(max_iter):\n        Ap = A @ p\n        p_Ap_dot = p @ Ap\n\n        if p_Ap_dot == 0:\n            break\n\n        alpha = r_z_dot_old / p_Ap_dot\n        x += alpha * p\n        r -= alpha * Ap\n\n        if np.linalg.norm(r) / norm_b = tol:\n            return k + 1\n\n        z = M_inv_diag * r\n        r_z_dot_new = r @ z\n        beta = r_z_dot_new / r_z_dot_old\n        p = z + beta * p\n        r_z_dot_old = r_z_dot_new\n\n    return max_iter\n\ndef solve():\n    # Define the test cases from the problem statement.\n    \n    # Test case 1: diagonal SPD, baseline\n    A1 = np.diag([1.0, 2.0, 3.0, 4.0])\n    b1 = np.ones(4, dtype=np.float64)\n    \n    # Test case 2: structured SPD, tridiagonal Poisson\n    n2 = 50\n    A2 = np.diag(2.0 * np.ones(n2)) + np.diag(-1.0 * np.ones(n2 - 1), 1) + np.diag(-1.0 * np.ones(n2 - 1), -1)\n    b2 = np.ones(n2, dtype=np.float64)\n    \n    # Test case 3: random SPD, moderate conditioning\n    n3 = 20\n    seed = 42\n    rng = np.random.default_rng(seed)\n    R = rng.standard_normal((n3, n3), dtype=np.float64)\n    A3 = R.T @ R + 0.1 * np.identity(n3, dtype=np.float64)\n    b3 = rng.standard_normal(n3, dtype=np.float64)\n\n    # Test case 4: diagonal SPD, highly ill-conditioned\n    A4 = np.diag([1e-6, 1e-3, 1.0, 1e3, 1e6])\n    b4 = np.ones(5, dtype=np.float64)\n\n    test_cases = [\n        (A1, b1),\n        (A2, b2),\n        (A3, b3),\n        (A4, b4),\n    ]\n\n    solvers = [solve_sd, solve_psd, solve_cg, solve_pcg]\n    \n    all_results = []\n    for A, b in test_cases:\n        case_results = []\n        for solver in solvers:\n            iterations = solver(A, b)\n            case_results.append(iterations)\n        all_results.append(case_results)\n\n    # Final print statement in the exact required format.\n    print(str(all_results).replace(\" \", \"\"))\n\nsolve()\n```", "id": "3195493"}]}