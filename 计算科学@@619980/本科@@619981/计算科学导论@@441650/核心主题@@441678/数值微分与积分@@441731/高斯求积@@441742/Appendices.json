{"hands_on_practices": [{"introduction": "高斯求积法中的节点和权重看似神秘，但它们实际上源于一个深刻的数学原理：正交多项式。本练习将引导您从第一性原理出发，推导包含三个节点 ($n=3$) 的高斯-勒让德求积法则，从而揭开其神秘面纱。通过亲手构建求积节点和权重，您将深入理解该方法为何能达到如此高的积分精度 [@problem_id:3136381]。", "problem": "考虑区间 $[-1,1]$上权函数为 $w(x)=1$ 的积分算子，并令 $\\{P_{n}(x)\\}_{n\\geq 0}$ 表示勒让德多项式。这些多项式关于内积 $\\langle f,g\\rangle=\\int_{-1}^{1} f(x)\\,g(x)\\,dx$ 正交，并归一化使得 $P_{n}(1)=1$。一个具有 $n$ 个节点的高斯求积法则是形如 $\\int_{-1}^{1} f(x)\\,dx\\approx \\sum_{i=1}^{n} w_{i}\\,f(\\xi_{i})$ 的近似，其中节点 $\\xi_{i}$ 和权重 $w_{i}$ 是经过适当选择的。\n\n你的任务是直接从正交性出发，构建 $n=3$ 的高斯-勒让德法则，然后验证其代数精度。请基于以下基本原理进行：勒让德多项式在 $[-1,1]$上关于 $w(x)=1$ 的正交性，多项式次数的定义，以及存在唯一的（在缩放意义下）与所有次数小于 $n$ 的多项式正交的 $n$ 次多项式 $P_{n}(x)$。\n\n任务：\n- 仅使用上述正交性结构，论证如果一个 3 节点法则对所有次数至多为 5 的多项式都精确，那么其节点多项式 $Q(x)=\\prod_{i=1}^{3}(x-\\xi_{i})$ 必须与每个次数至多为 2 的多项式正交。由此推断出 $Q(x)$ 与 $P_{3}(x)$ 成比例，并通过确定 $P_{3}(x)$，求出节点 $\\xi_{1}\\xi_{2}\\xi_{3}$ 的显式表达式。\n- 通过对一个合适的多项式集合强制精确性来确定相应的权重 $w_{1},w_{2},w_{3}$，并利用正交性解释为什么得到的法则对每个次数至多为 5 的多项式都精确。\n- 以精确解析表达式的形式，按照单行顺序 $(\\xi_{1},\\,\\xi_{2},\\,\\xi_{3},\\,w_{1},\\,w_{2},\\,w_{3})$ 列出节点和权重，报告最终结果。无需四舍五入。\n\n你的最终答案必须是一个单一的解析表达式。请按上述指定顺序将其表示为一个行矩阵。不涉及单位。", "solution": "该问题要求从勒让德多项式 $\\{P_n(x)\\}$ 在区间 $[-1, 1]$ 上关于权函数 $w(x)=1$ 的正交性原理出发，构建并验证 $n=3$ 的高斯-勒让德求积法则。\n\n### 步骤 1：求积节点的推导\n\n高斯求积的基本定理指出，一个 $n$ 点法则对所有次数至多为 $2n-1$ 的多项式都精确，当且仅当节点 $\\{\\xi_i\\}_{i=1}^n$ 是 $n$ 次勒让德多项式 $P_n(x)$ 的根。我们将按要求针对 $n=3$ 的特定情况推导此结果。\n\n设求积法则记为 $Q_3(f) = \\sum_{i=1}^{3} w_i f(\\xi_i)$，它近似于积分 $I(f) = \\int_{-1}^{1} f(x) dx$。我们假设此法则对所有次数至多为 $2n-1 = 2(3)-1=5$ 的多项式都精确。\n\n设节点多项式为 $Q(x) = \\prod_{i=1}^{3} (x-\\xi_i)$。这是一个 3 次的首一多项式。设 $p(x)$ 是一个次数至多为 2 的任意多项式。考虑多项式 $f(x) = p(x)Q(x)$。$f(x)$ 的次数为 $\\text{deg}(p) + \\text{deg}(Q) \\leq 2 + 3 = 5$。\n\n根据我们的假设，该求积法则对 $f(x)$ 是精确的，因此 $I(f) = Q_3(f)$。\n我们来计算等式两边。\n积分值为：\n$$I(f) = \\int_{-1}^{1} p(x)Q(x) dx = \\langle p, Q \\rangle$$\n求积和为：\n$$Q_3(f) = \\sum_{i=1}^{3} w_i f(\\xi_i) = \\sum_{i=1}^{3} w_i p(\\xi_i) Q(\\xi_i)$$\n根据节点多项式 $Q(x)$ 的定义，其根是节点 $\\xi_i$。因此，对于 $i=1, 2, 3$，$Q(\\xi_i) = 0$。这导致：\n$$Q_3(f) = \\sum_{i=1}^{3} w_i p(\\xi_i) \\cdot 0 = 0$$\n令积分与求积和相等，我们得到：\n$$\\langle p, Q \\rangle = \\int_{-1}^{1} p(x)Q(x) dx = 0$$\n此式对任何次数至多为 2 的多项式 $p(x)$ 都成立。这正是 $Q(x)$ 与所有次数小于 3 的多项式组成的空间正交的定义。\n\n根据定义，勒让德多项式 $P_3(x)$ 是一个 3 次多项式，它与所有次数小于 3 的多项式正交。与所有次数 $\\le 2$ 的多项式正交的 3 次多项式空间是一维的。因此，$Q(x)$ 必须与 $P_3(x)$ 成比例，即对于某个非零常数 $c$，$Q(x) = c P_3(x)$。由于 $Q(x)$ 的根是求积节点，这些节点必须是 $P_3(x)$ 的根。\n\n为了找到节点，我们必须首先构造 $P_3(x)$。我们可以对单项式基 $\\{1, x, x^2, x^3\\}$ 使用 Gram-Schmidt 正交化过程，其内积为 $\\langle f,g \\rangle = \\int_{-1}^{1} f(x)g(x)dx$。\n设 $\\tilde{P}_n(x)$ 为未归一化的多项式。\n$\\tilde{P}_0(x) = 1$。\n$\\tilde{P}_1(x) = x - \\frac{\\langle x, 1 \\rangle}{\\langle 1, 1 \\rangle} \\cdot 1 = x - \\frac{0}{2} = x$。\n$\\tilde{P}_2(x) = x^2 - \\frac{\\langle x^2, 1 \\rangle}{\\langle 1, 1 \\rangle} \\cdot 1 - \\frac{\\langle x^2, x \\rangle}{\\langle x, x \\rangle} \\cdot x = x^2 - \\frac{2/3}{2} - \\frac{0}{2/3}x = x^2 - \\frac{1}{3}$。\n$\\tilde{P}_3(x) = x^3 - \\frac{\\langle x^3, 1 \\rangle}{\\langle 1, 1 \\rangle} \\cdot 1 - \\frac{\\langle x^3, x \\rangle}{\\langle x, x \\rangle} \\cdot x - \\frac{\\langle x^3, x^2 - 1/3 \\rangle}{\\langle x^2 - 1/3, x^2 - 1/3 \\rangle} \\cdot (x^2 - \\frac{1}{3})$。\n在 $[-1, 1]$ 上涉及 $x$ 的奇次幂的积分都为零，因此 $\\langle x^3, 1 \\rangle=0$ 且 $\\langle x^3, x^2-1/3 \\rangle=0$。\n我们需要 $\\langle x^3, x \\rangle = \\int_{-1}^{1} x^4 dx = \\frac{2}{5}$ 和 $\\langle x, x \\rangle = \\int_{-1}^{1} x^2 dx = \\frac{2}{3}$。\n所以，$\\tilde{P}_3(x) = x^3 - \\frac{2/5}{2/3} x = x^3 - \\frac{3}{5}x$。\n\n节点 $\\xi_i$ 是 $\\tilde{P}_3(x)=0$ 的根：\n$$x^3 - \\frac{3}{5}x = x\\left(x^2 - \\frac{3}{5}\\right) = 0$$\n根是 $x=0$ 和 $x=\\pm\\sqrt{\\frac{3}{5}}$。\n按升序排列，节点为：\n$\\xi_1 = -\\sqrt{\\frac{3}{5}}$，$\\xi_2 = 0$，$\\xi_3 = \\sqrt{\\frac{3}{5}}$。\n\n### 步骤 2：求积权重的推导\n\n在确定节点后，我们通过强制法则对一个低次多项式的基精确来求得权重 $w_1, w_2, w_3$。次数 $\\le 2$ 的多项式的一个基是 $\\{1, x, x^2\\}$。该法则必须对这些多项式精确。\n\n对于 $f(x)=1$ (0 次)：\n$$\\int_{-1}^{1} 1 \\,dx = 2 \\implies w_1 f(\\xi_1) + w_2 f(\\xi_2) + w_3 f(\\xi_3) = w_1+w_2+w_3 = 2$$\n\n对于 $f(x)=x$ (1 次)：\n$$\\int_{-1}^{1} x \\,dx = 0 \\implies w_1 \\left(-\\sqrt{\\frac{3}{5}}\\right) + w_2(0) + w_3 \\left(\\sqrt{\\frac{3}{5}}\\right) = \\sqrt{\\frac{3}{5}}(-w_1+w_3) = 0$$\n这表示 $w_1 = w_3$。\n\n对于 $f(x)=x^2$ (2 次)：\n$$\\int_{-1}^{1} x^2 \\,dx = \\frac{2}{3} \\implies w_1 \\left(-\\sqrt{\\frac{3}{5}}\\right)^2 + w_2(0)^2 + w_3 \\left(\\sqrt{\\frac{3}{5}}\\right)^2 = w_1\\left(\\frac{3}{5}\\right) + w_3\\left(\\frac{3}{5}\\right) = \\frac{2}{3}$$\n这得到 $\\frac{3}{5}(w_1+w_3) = \\frac{2}{3}$。\n\n我们现在求解关于权重的线性方程组：\n1. $w_1 + w_2 + w_3 = 2$\n2. $w_1 = w_3$\n3. $\\frac{3}{5}(w_1+w_3) = \\frac{2}{3}$\n\n将 (2) 代入 (3)：\n$\\frac{3}{5}(w_1+w_1) = \\frac{2}{3} \\implies \\frac{6}{5}w_1 = \\frac{2}{3} \\implies w_1 = \\frac{2}{3} \\cdot \\frac{5}{6} = \\frac{10}{18} = \\frac{5}{9}$。\n由 (2) 得，$w_3 = w_1 = \\frac{5}{9}$。\n将 $w_1$ 和 $w_3$ 代入 (1)：\n$\\frac{5}{9} + w_2 + \\frac{5}{9} = 2 \\implies w_2 + \\frac{10}{9} = 2 \\implies w_2 = 2 - \\frac{10}{9} = \\frac{18-10}{9} = \\frac{8}{9}$。\n\n权重为 $w_1 = \\frac{5}{9}$，$w_2 = \\frac{8}{9}$，$w_3 = \\frac{5}{9}$。\n\n### 步骤 3：代数精度的验证\n\n我们必须解释为什么这个被构造成对次数至多为 2 的多项式精确的法则，实际上对所有次数至多为 5 的多项式都精确。\n设 $f(x)$ 为任意次数至多为 5 的多项式。我们可以用 3 次节点多项式 $Q(x) = \\prod_{i=1}^3(x-\\xi_i) \\propto P_3(x)$ 对 $f(x)$ 做多项式除法。这得到：\n$$f(x) = d(x)Q(x) + r(x)$$\n其中商式 $d(x)$ 是一个次数至多为 $5-3=2$ 的多项式，余式 $r(x)$ 是一个次数至多为 2 的多项式。\n\n将积分算子 $I$ 应用于 $f(x)$：\n$$I(f) = \\int_{-1}^{1} f(x) dx = \\int_{-1}^{1} \\left( d(x)Q(x) + r(x) \\right) dx = \\int_{-1}^{1} d(x)Q(x) dx + \\int_{-1}^{1} r(x) dx$$\n由于 $Q(x)$ 与 $P_3(x)$ 成比例，且 $d(x)$ 是一个次数至多为 2 的多项式，勒让德多项式的正交性保证了 $\\int_{-1}^{1} d(x)Q(x) dx = 0$。\n因此，$I(f) = \\int_{-1}^{1} r(x) dx = I(r)$。\n\n现在，将求积法则 $Q_3$ 应用于 $f(x)$：\n$$Q_3(f) = \\sum_{i=1}^{3} w_i f(\\xi_i) = \\sum_{i=1}^{3} w_i \\left( d(\\xi_i)Q(\\xi_i) + r(\\xi_i) \\right)$$\n由于 $\\xi_i$ 是 $Q(x)$ 的根，对每个节点都有 $Q(\\xi_i)=0$。该表达式简化为：\n$$Q_3(f) = \\sum_{i=1}^{3} w_i r(\\xi_i) = Q_3(r)$$\n\n我们已经证明了 $I(f) = I(r)$ 和 $Q_3(f) = Q_3(r)$。余式 $r(x)$ 是一个次数至多为 2 的多项式。根据我们构造权重的方式，该求积法则对所有次数至多为 2 的多项式都是精确的。因此，$I(r) = Q_3(r)$。\n综合这些结果，我们得出结论：对于任何次数至多为 5 的多项式 $f(x)$，都有 $I(f)=Q_3(f)$。其代数精度为 5。\n\n最终结果是节点和权重的集合。\n节点：$\\xi_1 = -\\sqrt{\\frac{3}{5}}$，$\\xi_2 = 0$，$\\xi_3 = \\sqrt{\\frac{3}{5}}$。\n权重：$w_1 = \\frac{5}{9}$，$w_2 = \\frac{8}{9}$，$w_3 = \\frac{5}{9}$。\n按要求的顺序 $(\\xi_1, \\xi_2, \\xi_3, w_1, w_2, w_3)$：\n$\\left( -\\sqrt{\\frac{3}{5}}, 0, \\sqrt{\\frac{3}{5}}, \\frac{5}{9}, \\frac{8}{9}, \\frac{5}{9} \\right)$。", "answer": "$$\\boxed{\\begin{pmatrix} -\\sqrt{\\frac{3}{5}} & 0 & \\sqrt{\\frac{3}{5}} & \\frac{5}{9} & \\frac{8}{9} & \\frac{5}{9} \\end{pmatrix}}$$", "id": "3136381"}, {"introduction": "理解了高斯求积法则的构造原理后，下一步便是将其应用于实际问题。许多物理和工程问题，如计算复杂路径的长度，最终会归结为一个难以解析求解的积分。本练习将带您使用两点高斯-勒让德求积法来近似计算一段曲线的弧长，这需要您完成从建立积分、变换区间到最终应用求积公式的完整流程 [@problem_id:2175478]。", "problem": "一个粒子在二维平面上的轨迹由函数 $y(x) = x \\sin(x)$ 描述，其中位置坐标 $x$ 和 $y$ 均以米为单位。该粒子从 $x=0$ 处的点运动到 $x=\\pi/2$ 处的点。\n\n您的任务是计算这条路径的总长度。为此，您必须使用两点高斯-勒让德求积法来近似弧长积分的值。\n\n为您的计算提供了以下信息：\n1.  曲线 $y=f(x)$ 从 $x=a$ 到 $x=b$ 的弧长 $L$ 由积分 $L = \\int_a^b \\sqrt{1 + [f'(x)]^2} dx$ 给出。\n2.  两点高斯-勒让德求积公式将标准区间 $[-1, 1]$ 上的积分近似为 $\\int_{-1}^1 g(t) dt \\approx w_1 g(t_1) + w_2 g(t_2)$。所需的节点为 $t_1 = -1/\\sqrt{3}$ 和 $t_2 = 1/\\sqrt{3}$，相应的权重为 $w_1 = 1$ 和 $w_2 = 1$。\n3.  为了使用定义在 $[-1, 1]$ 上的方法来计算一般区间 $[a, b]$ 上的积分，例如 $\\int_a^b f(x)dx$，需要进行变量代换 $x = \\frac{b-a}{2}t + \\frac{a+b}{2}$。\n\n以米为单位表示您的答案，并四舍五入到四位有效数字。", "solution": "我们已知在 $x \\in [0,\\frac{\\pi}{2}]$ 上，$y(x) = x \\sin(x)$。曲线 $y=f(x)$ 的弧长公式为\n$$\nL=\\int_{0}^{\\frac{\\pi}{2}} \\sqrt{1+\\left[f'(x)\\right]^{2}}\\,dx.\n$$\n首先使用乘法法则计算导数：\n$$\nf'(x)=\\sin(x)+x\\cos(x).\n$$\n因此，弧长积分变为\n$$\nL=\\int_{0}^{\\frac{\\pi}{2}} \\sqrt{1+\\left(\\sin(x)+x\\cos(x)\\right)^{2}}\\,dx.\n$$\n为了在 $[-1,1]$ 上应用两点高斯-勒让德求积法，使用变量代换\n$$\nx=\\frac{b-a}{2}\\,t+\\frac{a+b}{2},\\quad a=0,\\;b=\\frac{\\pi}{2}\\;\\Rightarrow\\;x=\\frac{\\pi}{4}(t+1),\\quad dx=\\frac{\\pi}{4}\\,dt.\n$$\n定义\n$$\ng(t)=\\sqrt{1+\\left(\\sin\\!\\left(\\tfrac{\\pi}{4}(t+1)\\right)+\\tfrac{\\pi}{4}(t+1)\\cos\\!\\left(\\tfrac{\\pi}{4}(t+1)\\right)\\right)^{2}}.\n$$\n则\n$$\nL=\\frac{\\pi}{4}\\int_{-1}^{1} g(t)\\,dt\\approx \\frac{\\pi}{4}\\left[g(t_{1})+g(t_{2})\\right],\n$$\n其中两点高斯-勒让德节点和权重为 $t_{1}=-\\frac{1}{\\sqrt{3}}$，$t_{2}=\\frac{1}{\\sqrt{3}}$，$w_{1}=w_{2}=1$。\n\n将这些节点映射到 $x$：\n$$\nx_{1}=\\frac{\\pi}{4}\\left(1-\\frac{1}{\\sqrt{3}}\\right),\\qquad x_{2}=\\frac{\\pi}{4}\\left(1+\\frac{1}{\\sqrt{3}}\\right).\n$$\n在 $x_{1}$ 和 $x_{2}$ 处计算被积函数 $\\phi(x)=\\sqrt{1+\\left(\\sin x + x\\cos x\\right)^{2}}$ 的值：\n- 在 $x_{1}=\\frac{\\pi}{4}\\left(1-\\frac{1}{\\sqrt{3}}\\right)\\approx 0.3319483223$ 处，我们有\n$$\n\\sin(x_{1})\\approx 0.325885641,\\quad \\cos(x_{1})\\approx 0.945408713,\n$$\n$$\n\\sin(x_{1})+x_{1}\\cos(x_{1})\\approx 0.325885641+0.3319483223\\cdot 0.945408713\\approx 0.639712477,\n$$\n$$\ng(t_{1})=\\phi(x_{1})\\approx \\sqrt{1+0.639712477^{2}}\\approx 1.187111.\n$$\n- 在 $x_{2}=\\frac{\\pi}{4}\\left(1+\\frac{1}{\\sqrt{3}}\\right)\\approx 1.2388480045$ 处，我们有\n$$\n\\sin(x_{2})\\approx 0.945409184,\\quad \\cos(x_{2})\\approx 0.325885578,\n$$\n$$\n\\sin(x_{2})+x_{2}\\cos(x_{2})\\approx 0.945409184+1.2388480045\\cdot 0.325885578\\approx 1.349131882,\n$$\n$$\ng(t_{2})=\\phi(x_{2})\\approx \\sqrt{1+1.349131882^{2}}\\approx 1.679333.\n$$\n因此，两点高斯-勒让德近似给出\n$$\nL\\approx \\frac{\\pi}{4}\\left(g(t_{1})+g(t_{2})\\right)\\approx \\frac{\\pi}{4}\\left(1.187111+1.679333\\right)=\\frac{\\pi}{4}\\cdot 2.866444\\approx 2.251299460\\ \\text{m}.\n$$\n四舍五入到四位有效数字，路径长度为 $2.251$ 米。", "answer": "$$\\boxed{2.251}$$", "id": "2175478"}, {"introduction": "在众多数值积分方法中，为何高斯求积法备受青睐？与辛普森法则等基于等距节点的牛顿-柯特斯方法相比，它的优势在何处？本练习将通过一个编程任务，让您对这两类方法的收敛性能进行定量比较。您将处理一个在积分区间端点处导数存在奇点的函数——这是一个在科学计算中颇具挑战性的典型情况，而高斯求积法通过其巧妙的节点选择，展现出卓越的性能 [@problem_id:2397782]。", "problem": "考虑函数 $f(x) = \\sqrt{1 - x^2}$ 在区间 $[-1,1]$ 上的定积分。该积分的精确值是半径为 $1$ 的半圆面积，即\n$$\nI = \\int_{-1}^{1} \\sqrt{1 - x^2} \\, dx = \\frac{\\pi}{2}.\n$$\n该被积函数在 $x = \\pm 1$ 处有端点导数奇点，即当 $x \\to \\pm 1$ 时，其导数是发散的。\n\n你的任务是定量比较两种求积方法族在逼近 $I$ 时的收敛行为：\n- 在 $[-1,1]$ 上的 $n$ 点 Gauss–Legendre 求积，其节点是 Legendre 多项式 $P_n(x)$ 的根，相关的权重能对最高 $2n-1$ 次的多项式进行精确积分。\n- 在 $[-1,1]$ 上使用 $m$ 个等长子区间的 2 次复合闭式 Newton–Cotes 法则（Simpson 法则），其中 $m$ 为偶数。函数求值的总次数为 $m+1$。\n\n对于由函数求值次数所量化的共同资源预算，使用预算测试集\n$$\n\\mathcal{B} = \\{\\,3,5,9,17,33\\,\\},\n$$\n其中对于每个 $n \\in \\mathcal{B}$，你必须：\n- 使用 $n$ 点 Gauss–Legendre 求积法得到 $I$ 的一个近似值 $Q_{\\mathrm{GL}}(n)$。\n- 使用复合 Simpson 法则，取 $m = n-1$ 个子区间（注意对于所有 $n \\in \\mathcal{B}$，$m$ 都是偶数），得到 $I$ 的一个近似值 $Q_{\\mathrm{S}}(n)$。\n\n对于每个 $n \\in \\mathcal{B}$，计算绝对误差\n$$\nE_{\\mathrm{GL}}(n) = \\bigl|Q_{\\mathrm{GL}}(n) - I\\bigr|,\\quad\nE_{\\mathrm{S}}(n) = \\bigl|Q_{\\mathrm{S}}(n) - I\\bigr|.\n$$\n然后，在整个集合 $\\mathcal{B}$ 上，通过对 $\\log E$ 与 $\\log n$ 进行普通最小二乘 (OLS) 拟合，来为每个方法族估计经验代数收敛率：\n$$\n\\log E_{\\mathrm{GL}}(n) \\approx \\alpha_{\\mathrm{GL}} + s_{\\mathrm{GL}} \\log n,\\quad\n\\log E_{\\mathrm{S}}(n) \\approx \\alpha_{\\mathrm{S}} + s_{\\mathrm{S}} \\log n,\n$$\n并将经验收敛指数定义为\n$$\np_{\\mathrm{GL}} = -s_{\\mathrm{GL}},\\quad p_{\\mathrm{S}} = -s_{\\mathrm{S}}.\n$$\n\n你的程序必须输出一个单行，其中包含一个用方括号括起来的逗号分隔列表，列表包含以下条目，且必须遵循此确切顺序：\n$$\n\\bigl[E_{\\mathrm{GL}}(3),\\,E_{\\mathrm{S}}(3),\\,E_{\\mathrm{GL}}(5),\\,E_{\\mathrm{S}}(5),\\,E_{\\mathrm{GL}}(9),\\,E_{\\mathrm{S}}(9),\\,E_{\\mathrm{GL}}(17),\\,E_{\\mathrm{S}}(17),\\,E_{\\mathrm{GL}}(33),\\,E_{\\mathrm{S}}(33),\\,p_{\\mathrm{GL}},\\,p_{\\mathrm{S}}\\bigr].\n$$\n所有数值都必须报告为不带单位的实数。角度单位不相关。你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，$[r_1,r_2,\\dots]$）。", "solution": "所提出的问题是数值分析中的一个明确定义的练习，数值分析是计算科学的一个核心课题。它要求对两种标准求积方法应用于一个连续但不光滑、特别是具有端点导数奇点的被积函数时的情况进行定量比较。该问题具有科学依据，是客观的，并包含了得出唯一解所需的所有必要信息。因此，该问题被认为是有效的，我们将继续进行推导。\n\n目标是逼近定积分\n$$\nI = \\int_{-1}^{1} f(x) \\, dx = \\int_{-1}^{1} \\sqrt{1 - x^2} \\, dx.\n$$\n从几何上看，这个积分代表了半径为 $r=1$ 的半圆面积，因此其精确值已知为 $I = \\frac{\\pi r^2}{2} = \\frac{\\pi}{2}$。被积函数 $f(x) = \\sqrt{1 - x^2}$ 在闭区间 $[-1, 1]$ 上是连续的。然而，其导数在端点 $x = \\pm 1$ 处是奇异的。其一阶导数为 $f'(x) = -x(1-x^2)^{-1/2}$，当 $x \\to \\pm 1$ 时发散。由于数值求积法则的标准误差界依赖于被积函数在积分区间上的高阶导数的有界性，因此这些奇点的存在预计会降低所考虑的两种方法的收敛性能。\n\n我们将比较两类求积法则：$n$ 点 Gauss–Legendre 求积和复合 Simpson 法则。为公平起见，两种方法的函数求值次数 $n$ 将是相同的，均从集合 $\\mathcal{B} = \\{3, 5, 9, 17, 33\\}$ 中选取。\n\n首先，我们来定义 Gauss-Legendre 求积。$n$ 点法则将函数 $g(x)$ 在 $[-1, 1]$ 上的积分近似为在特定节点处函数值的加权和：\n$$\n\\int_{-1}^{1} g(x) \\, dx \\approx \\sum_{i=1}^{n} w_i g(x_i) = Q_{\\mathrm{GL}}(n).\n$$\n节点 $\\{x_i\\}_{i=1}^n$ 是 $n$ 次 Legendre 多项式 $P_n(x)$ 的根，权重 $\\{w_i\\}_{i=1}^n$ 的选择使得该法则对所有次数最高为 $2n-1$ 的多项式都是精确的。Gauss-Legendre 求积的一个关键特征是其节点总是位于开区间 $(-1, 1)$ 内，从而避免了在问题的奇异端点上直接进行函数求值。对于解析函数，此方法表现出指数收敛性。对于具有 $(1 \\mp x)^\\alpha$（其中 $\\alpha > -1$）形式的端点奇点的函数，已知误差行为为 $E_{\\mathrm{GL}}(n) = O(n^{-2(\\alpha+1)})$。在我们的情况下，$\\alpha = 1/2$，因此我们预期代数收敛率的指数为 $p_{\\mathrm{GL}} \\approx 2(1/2 + 1) = 3$。\n\n其次，我们考虑复合 Simpson 法则。该法则源于 2 次闭式 Newton–Cotes 公式。区间 $[-1, 1]$ 被划分为 $m$ 个宽度为 $h = 2/m$ 的等长子区间。问题指定总共使用 $n$ 次函数求值，对于复合 Simpson 法则，这对应于 $m = n-1$ 个子区间。节点均匀分布在 $x_j = -1 + j \\cdot h$ 处，其中 $j \\in \\{0, 1, \\dots, m\\}$。近似值由下式给出：\n$$\n\\int_{-1}^{1} g(x) \\, dx \\approx \\frac{h}{3} \\left[ g(x_0) + 4\\sum_{j=1}^{m/2} g(x_{2j-1}) + 2\\sum_{j=1}^{m/2-1} g(x_{2j}) + g(x_m) \\right] = Q_{\\mathrm{S}}(n).\n$$\n与 Gauss-Legendre 求积不同，该方法显式地在端点 $x_0 = -1$ 和 $x_m = 1$ 处计算函数值。对于一个足够光滑的函数（$g \\in C^4([-1, 1])$），误差为 $O(h^4) = O(m^{-4}) = O(n^{-4})$。然而，由于端点奇点，这个收敛率将无法达到。对于应用于具有奇点 $(1 \\mp x)^\\alpha$ 的被积函数的 Newton-Cotes 法则，其误差通常为 $O(m^{-(\\alpha+k)})$，其中 $k$ 取决于该法则的次数。对于 Simpson 法则，理论表明对于单侧奇点，误差行为为 $E_{\\mathrm{S}}(n) = O(m^{-(\\alpha+1.5)})$。在此，由于有两个端点且 $\\alpha=1/2$，预期的收敛指数为 $p_{\\mathrm{S}} \\approx 1.5$。\n\n计算步骤如下：\n1. 对于每个预算 $n \\in \\mathcal{B}$，我们计算近似值 $Q_{\\mathrm{GL}}(n)$ 和 $Q_{\\mathrm{S}}(n)$。对于 $Q_{\\mathrm{GL}}(n)$，需要 Legendre 多项式的节点和权重。对于 $Q_{\\mathrm{S}}(n)$，我们使用 $m = n-1$ 个子区间。\n2. 对每个 $n$ 计算绝对误差 $E_{\\mathrm{GL}}(n) = |Q_{\\mathrm{GL}}(n) - \\pi/2|$ 和 $E_{\\mathrm{S}}(n) = |Q_{\\mathrm{S}}(n) - \\pi/2|$。\n3. 为了估计经验收敛指数，我们对误差的对数与点数的对数进行线性回归。我们拟合以下模型：\n$$\n\\log E(n) \\approx \\alpha + s \\log n.\n$$\n斜率 $s$ 通过普通最小二乘 (OLS) 拟合确定。根据代数收敛的定义，$E(n) \\approx C n^{-p}$，取对数得到 $\\log E(n) \\approx \\log C - p \\log n$。与线性模型进行比较，经验收敛指数为 $p = -s$。我们将计算 $p_{\\mathrm{GL}} = -s_{\\mathrm{GL}}$ 和 $p_{\\mathrm{S}} = -s_{\\mathrm{S}}$。\n\n这种系统性的比较将揭示端点奇点对高阶（Gauss-Legendre）和低阶（Simpson）求积法则收敛性的实际影响，从而为它们相对于理想光滑函数情况下的性能下降提供一个清晰的定量度量。整个过程将通过一个程序来实现，以生成所需的数值结果。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import special\nfrom scipy import integrate\n\ndef solve():\n    \"\"\"\n    Compares the convergence of Gauss-Legendre and composite Simpson's rule\n    for the integral of sqrt(1-x^2) on [-1, 1], which has endpoint singularities.\n    \"\"\"\n\n    # Define the integrand and the exact value of the integral.\n    def f(x):\n        # Use np.maximum to avoid domain errors from floating-point inaccuracies near +/-1.\n        return np.sqrt(np.maximum(0.0, 1.0 - x**2))\n\n    I_exact = np.pi / 2.0\n\n    # Test suite of budgets for the number of function evaluations.\n    budgets = np.array([3, 5, 9, 17, 33])\n\n    errors_gl = []\n    errors_s = []\n    results_list = []\n\n    for n in budgets:\n        # --- Gauss-Legendre Quadrature ---\n        # Get n-point Gauss-Legendre nodes and weights on [-1, 1].\n        # scipy.special.roots_legendre is the standard function for this.\n        nodes, weights = special.roots_legendre(n)\n        \n        # Calculate the approximation Q_GL(n).\n        q_gl = np.sum(weights * f(nodes))\n        \n        # Calculate the absolute error E_GL(n).\n        e_gl = np.abs(q_gl - I_exact)\n        errors_gl.append(e_gl)\n\n        # --- Composite Simpson's Rule ---\n        # Number of subintervals m = n - 1. This ensures a total of n function evaluations.\n        # The number of points is m+1 = n, which is always odd for the given budgets.\n        m = n - 1\n        \n        # Generate n equally spaced points from -1 to 1.\n        x_simpson = np.linspace(-1.0, 1.0, n)\n        y_simpson = f(x_simpson)\n        \n        # Calculate the approximation Q_S(n) using scipy's Simpson's rule implementation.\n        q_s = integrate.simpson(y_simpson, x_simpson)\n        \n        # Calculate the absolute error E_S(n).\n        e_s = np.abs(q_s - I_exact)\n        errors_s.append(e_s)\n\n        # Append the pair of errors for this budget to the results list.\n        results_list.extend([e_gl, e_s])\n\n    # --- Empirical Convergence Rate Calculation ---\n    # We fit a line to log(E) vs log(n) to find the slope s.\n    # The convergence rate p is then -s.\n\n    log_n = np.log(budgets)\n    log_e_gl = np.log(errors_gl)\n    log_e_s = np.log(errors_s)\n\n    # Use np.polyfit for Ordinary Least Squares linear regression.\n    # It returns [slope, intercept]. We only need the slope.\n    s_gl = np.polyfit(log_n, log_e_gl, 1)[0]\n    s_s = np.polyfit(log_n, log_e_s, 1)[0]\n\n    p_gl = -s_gl\n    p_s = -s_s\n\n    # Append the calculated convergence exponents to the results list.\n    results_list.extend([p_gl, p_s])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results_list))}]\")\n\nsolve()\n```", "id": "2397782"}]}