{"hands_on_practices": [{"introduction": "理论是实践的基石。在构建任何高阶导数近似之前，我们必须首先掌握如何从基本原理——泰勒级数展开——出发，推导出有限差分公式的系数。这个练习 [@problem_id:3238868] 将带你亲手构建一个用于三阶导数的高阶中心差分格式，让你深入理解截断误差和模板对称性在公式设计中的核心作用。", "problem": "设 $f$ 是一个标量函数，在点 $x \\in \\mathbb{R}$ 的一个邻域内至少有 $7$ 阶连续导数。考虑一个间距为 $h > 0$ 的均匀网格。仅从关于点 $x$ 的带余项的泰勒定理出发，构造一个三阶导数 $f^{(3)}(x)$ 的中心有限差分近似，其截断误差为 $h^{4}$ 阶。使用一个在点 $\\{x \\pm h, x \\pm 2h, x \\pm 3h\\}$ 上采样 $f$ 的对称模板，并通过施加由泰勒展开式得出的所需阶数条件来确定系数。\n\n你的最终答案必须是关于样本 $f(x \\pm h)$、$f(x \\pm 2h)$、$f(x \\pm 3h)$ 和网格间距 $h$ 的模板的单个闭式解析表达式。最终答案中不要包含误差项。无需四舍五入。", "solution": "用户想要构造一个三阶导数 $f^{(3)}(x)$ 的中心有限差分近似，其截断误差为 $O(h^4)$ 阶，使用点集 $\\{x \\pm h, x \\pm 2h, x \\pm 3h\\}$ 上的对称模板。推导必须基于泰勒定理。\n\n首先，我们对问题陈述进行验证。\n\n### 步骤 1：提取已知条件\n- 函数 $f$ 是一个标量函数，在 $x \\in \\mathbb{R}$ 附近至少有 $7$ 阶连续导数。\n- 网格是均匀的，间距为 $h > 0$。\n- 目标是三阶导数 $f^{(3)}(x)$ 的一个近似。\n- 近似方法是中心有限差分格式。\n- 要求的截断误差为 $O(h^4)$ 阶。\n- 模板是对称的，并使用采样点 $\\{x \\pm h, x \\pm 2h, x \\pm 3h\\}$。\n- 推导必须从泰勒定理开始。\n\n### 步骤 2：使用提取的已知条件进行验证\n- **科学依据**：该问题是数值分析中的一个标准练习，涉及有限差分公式的推导。所有概念在数学和科学计算中都已成熟。要求 $f$ 至少有 $7$ 阶连续导数对于三阶导数的 $O(h^4)$ 误差近似是合适的，因为预期的主误差项将涉及 $f^{(3+4)}(x) = f^{(7)}(x)$。\n- **适定性**：该问题是适定的。它指明了函数的光滑性、模板中的点、所求导数、格式类型（中心）以及精度阶数。这些信息足以唯一确定有限差分公式的系数。\n- **客观性**：问题使用精确的数学语言陈述，没有歧义或主观论断。\n\n### 步骤 3：结论与行动\n该问题是有效的，因为它具有科学依据、适定且客观。我们可以继续进行求解。\n\n我们寻求在指定模板点上的函数值的线性组合来近似 $f^{(3)}(x)$。对于奇数阶导数的中心差分近似，模板必须是反对称的。也就是说，$f(x+kh)$ 的系数必须是 $f(x-kh)$ 系数的相反数。点 $f(x)$ 本身不包括在内。近似的一般形式是：\n$$\nf^{(3)}(x) \\approx D_h[f](x) = c_1(f(x+h) - f(x-h)) + c_2(f(x+2h) - f(x-2h)) + c_3(f(x+3h) - f(x-3h))\n$$\n系数 $c_1$、$c_2$ 和 $c_3$ 必须被确定。我们使用泰勒定理将函数值在点 $x$ 附近展开。假设函数 $f$ 至少有 $7$ 阶连续导数，所以我们可以写出带余项的泰勒级数。对于一个整数 $k$，展开式为：\n$$\nf(x+kh) = f(x) + (kh)f'(x) + \\frac{(kh)^2}{2!}f''(x) + \\frac{(kh)^3}{3!}f^{(3)}(x) + \\frac{(kh)^4}{4!}f^{(4)}(x) + \\frac{(kh)^5}{5!}f^{(5)}(x) + \\frac{(kh)^6}{6!}f^{(6)}(x) + \\frac{(kh)^7}{7!}f^{(7)}(x) + O(h^8)\n$$\n$$\nf(x-kh) = f(x) - (kh)f'(x) + \\frac{(kh)^2}{2!}f''(x) - \\frac{(kh)^3}{3!}f^{(3)}(x) + \\frac{(kh)^4}{4!}f^{(4)}(x) - \\frac{(kh)^5}{5!}f^{(5)}(x) + \\frac{(kh)^6}{6!}f^{(6)}(x) - \\frac{(kh)^7}{7!}f^{(7)}(x) + O(h^8)\n$$\n将第二个展开式从第一个展开式中减去，我们得到差分项的表达式：\n$$\nf(x+kh) - f(x-kh) = 2(kh)f'(x) + 2\\frac{(kh)^3}{3!}f^{(3)}(x) + 2\\frac{(kh)^5}{5!}f^{(5)}(x) + 2\\frac{(kh)^7}{7!}f^{(7)}(x) + O(h^9)\n$$\n将此代入我们的近似 $D_h[f](x)$ 的一般形式中：\n\\begin{align*}\nD_h[f](x) =  c_1 \\left( 2h f'(x) + \\frac{2h^3}{6}f^{(3)}(x) + \\frac{2h^5}{120}f^{(5)}(x) + \\frac{2h^7}{5040}f^{(7)}(x) + \\dots \\right) \\\\\n+  c_2 \\left( 2(2h)f'(x) + \\frac{2(2h)^3}{6}f^{(3)}(x) + \\frac{2(2h)^5}{120}f^{(5)}(x) + \\frac{2(2h)^7}{5040}f^{(7)}(x) + \\dots \\right) \\\\\n+  c_3 \\left( 2(3h)f'(x) + \\frac{2(3h)^3}{6}f^{(3)}(x) + \\frac{2(3h)^5}{120}f^{(5)}(x) + \\frac{2(3h)^7}{5040}f^{(7)}(x) + \\dots \\right)\n\\end{align*}\n现在，我们按 $f(x)$ 的导数对各项进行分组：\n\\begin{align*}\nD_h[f](x) =  f'(x) \\cdot \\left( 2h(c_1 + 2c_2 + 3c_3) \\right) \\\\\n+  f^{(3)}(x) \\cdot \\left( \\frac{h^3}{3}(c_1 + 8c_2 + 27c_3) \\right) \\\\\n+  f^{(5)}(x) \\cdot \\left( \\frac{h^5}{60}(c_1 + 32c_2 + 243c_3) \\right) \\\\\n+  f^{(7)}(x) \\cdot \\left( \\frac{h^7}{2520}(c_1 + 128c_2 + 2187c_3) \\right) + \\dots\n\\end{align*}\n我们希望近似 $D_h[f](x)$ 等于 $f^{(3)}(x)$，且截断误差为 $O(h^4)$ 阶。这需要设置 $D_h[f](x)$ 展开式中导数项的系数，以匹配 $f^{(3)}(x)$ 的系数。具体来说：\n1. $f'(x)$ 的系数必须为 $0$。\n2. $f^{(3)}(x)$ 的系数必须为 $1$。\n3. 为了达到 $O(h^4)$ 的误差，由 $h^5$ 缩放的 $f^{(5)}(x)$ 的系数必须为 $0$。注意，一般形式 $D_h[f]$ 具有导数的单位，因此误差项 $E(h) = D_h[f] - f^{(3)}(x)$ 将以 $h$ 的幂次开始。含有 $f^{(5)}(x)$ 的项贡献了 $h^5$ 阶的误差。该公式的形式为 $f^{(3)}(x) \\approx (\\dots)/h^3$。因此，误差项将是 $(\\dots)h^2/h^3 = (\\dots)/h$。我目前的公式 $D_h[f]$ 没有分母 $h^3$。我们把近似定义为\n$$\nD_h[f](x) = \\frac{a_1(f(x+h) - f(x-h)) + a_2(f(x+2h) - f(x-2h)) + a_3(f(x+3h) - f(x-3h))}{h^3}\n$$\n那么展开式是：\n\\begin{align*}\nD_h[f](x) =  \\frac{1}{h^3} \\left[ f'(x) \\cdot 2h \\sum_{k=1}^3 k a_k + f^{(3)}(x) \\cdot \\frac{h^3}{3} \\sum_{k=1}^3 k^3 a_k + f^{(5)}(x) \\cdot \\frac{h^5}{60} \\sum_{k=1}^3 k^5 a_k + \\dots \\right] \\\\\n=  f'(x) \\cdot \\frac{2}{h^2} \\sum_{k=1}^3 k a_k + f^{(3)}(x) \\cdot \\frac{1}{3} \\sum_{k=1}^3 k^3 a_k + f^{(5)}(x) \\cdot \\frac{h^2}{60} \\sum_{k=1}^3 k^5 a_k + O(h^4)\n\\end{align*}\n为了使其近似 $f^{(3)}(x)$，我们要求：\n1. $f'(x)$ 的系数必须为 $0$：$a_1 + 2a_2 + 3a_3 = 0$。\n2. $f^{(3)}(x)$ 的系数必须为 $1$：$\\frac{1}{3}(a_1 + 8a_2 + 27a_3) = 1 \\implies a_1 + 8a_2 + 27a_3 = 3$。\n3. 为了得到 $O(h^4)$ 的误差，主误差项的系数（即 $O(h^2)$ 项的系数）必须为 $0$：$a_1 + 32a_2 + 243a_3 = 0$。\n\n这给出了一个关于系数 $a_1, a_2, a_3$ 的三元线性方程组：\n$$\n\\begin{pmatrix} 1 & 2 & 3 \\\\ 1 & 8 & 27 \\\\ 1 & 32 & 243 \\end{pmatrix}\n\\begin{pmatrix} a_1 \\\\ a_2 \\\\ a_3 \\end{pmatrix}\n=\n\\begin{pmatrix} 0 \\\\ 3 \\\\ 0 \\end{pmatrix}\n$$\n我们使用增广矩阵的行化简来解这个方程组：\n$$\n\\left[ \\begin{array}{ccc|c}\n1 & 2 & 3 & 0 \\\\\n1 & 8 & 27 & 3 \\\\\n1 & 32 & 243 & 0\n\\end{array} \\right]\n\\xrightarrow[R_3 \\to R_3 - R_1]{R_2 \\to R_2 - R_1}\n\\left[ \\begin{array}{ccc|c}\n1 & 2 & 3 & 0 \\\\\n0 & 6 & 24 & 3 \\\\\n0 & 30 & 240 & 0\n\\end{array} \\right]\n$$\n将第二行除以 $3$，第三行除以 $30$ 来简化：\n$$\n\\left[ \\begin{array}{ccc|c}\n1 & 2 & 3 & 0 \\\\\n0 & 2 & 8 & 1 \\\\\n0 & 1 & 8 & 0\n\\end{array} \\right]\n$$\n从最后一行，我们得到 $a_2 + 8a_3 = 0$，所以 $a_2 = -8a_3$。\n将此代入第二行：$2(-8a_3) + 8a_3 = 1 \\implies -16a_3 + 8a_3 = 1 \\implies -8a_3 = 1$，得到 $a_3 = -1/8$。\n现在我们求 $a_2$：$a_2 = -8(-1/8) = 1$。\n最后，从第一行：$a_1 + 2a_2 + 3a_3 = 0 \\implies a_1 = -2a_2 - 3a_3$。\n$a_1 = -2(1) - 3(-1/8) = -2 + 3/8 = -16/8 + 3/8 = -13/8$。\n\n系数为 $a_1 = -13/8$，$a_2 = 1$，以及 $a_3 = -1/8$。\n将这些系数代回 $D_h[f](x)$ 的公式中：\n$$\nf^{(3)}(x) \\approx \\frac{1}{h^3} \\left[ -\\frac{13}{8}(f(x+h) - f(x-h)) + 1(f(x+2h) - f(x-2h)) - \\frac{1}{8}(f(x+3h) - f(x-3h)) \\right]\n$$\n为了得到更简洁的表达式，我们提出因子 $1/8$：\n$$\nf^{(3)}(x) \\approx \\frac{1}{8h^3} \\left[ -13(f(x+h) - f(x-h)) + 8(f(x+2h) - f(x-2h)) - (f(x+3h) - f(x-3h)) \\right]\n$$\n根据各项与 $x$ 的位移展开并合并同类项：\n$$\nf^{(3)}(x) \\approx \\frac{1}{8h^3} [-f(x+3h) + 8f(x+2h) - 13f(x+h) + 13f(x-h) - 8f(x-2h) + f(x-3h)]\n$$\n这就是所求的有限差分公式。主误差项由 $D_h[f](x)$ 展开式中 $f^{(7)}(x)$ 的系数给出，该项为 $O(h^4)$ 阶，符合要求。\n误差项为 $E(h) = f^{(7)}(x) \\cdot \\frac{h^4}{2520} \\sum_{k=1}^3 k^7 a_k = \\frac{h^4 f^{(7)}(x)}{2520} (1^7 a_1 + 2^7 a_2 + 3^7 a_3) = \\frac{h^4 f^{(7)}(x)}{2520} (-\\frac{13}{8} + 128 - \\frac{2187}{8}) = \\frac{h^4 f^{(7)}(x)}{2520} (\\frac{-13+1024-2187}{8}) = \\frac{-1176}{20160}h^4 f^{(7)}(x) = -\\frac{7}{120}h^4 f^{(7)}(x)$。误差确实是 $O(h^4)$ 阶的。\n最终答案就是这个近似公式本身。", "answer": "$$\\boxed{\\frac{-f(x+3h) + 8 f(x+2h) - 13 f(x+h) + 13 f(x-h) - 8 f(x-2h) + f(x-3h)}{8h^3}}$$", "id": "3238868"}, {"introduction": "一个理论上精确的公式在实际计算中是否同样有效？本练习 [@problem_id:3238903] 将理论与实践相结合，要求你将推导出的差分格式编写成代码，并设计一个数值实验来验证其收敛阶。通过将数值近似与一个已知解析解的函数进行比较，你将学会如何通过计算“观测收敛阶”来确认你的实现是否正确，以及公式是否达到了其理论精度。", "problem": "考虑函数 $f(x) = \\exp(-x^2)$。您的任务是使用中心有限差分模板来近似高阶导数，从第一性原理推导截断误差阶数，并与解析导数进行比较，以验证观察到的收敛率。\n\n您必须基于以下基础进行操作：\n- 使用 $f(x \\pm kh)$ 在点 $x = x_0$ 处的泰勒级数展开，其中 $k \\in \\mathbb{Z}$ 且 $h > 0$ 是一个小数，来构建一致的导数中心有限差分近似。具体来说，使用泰勒展开式\n$$\nf(x_0 \\pm kh) = \\sum_{n=0}^{\\infty} \\frac{(\\pm kh)^n}{n!} f^{(n)}(x_0).\n$$\n- 使用截断误差阶数的定义：如果量 $Q$ 的一个近似 $A_h$ 满足 $A_h = Q + C h^p + \\mathcal{O}(h^{p+1})$，其中常数 $C \\neq 0$，那么我们称该近似为 $p$ 阶。\n- 对于误差 $E(h_1)$ 和 $E(h_2)$，使用两个步长 $h_1$ 和 $h_2$ 之间的观察阶数的定义为\n$$\np_{\\mathrm{obs}} = \\frac{\\log\\big(E(h_1)/E(h_2)\\big)}{\\log(h_1/h_2)}.\n$$\n\n任务：\n1. 通过直接微分，推导 $f(x) = \\exp(-x^2)$ 的解析二阶和四阶导数 $f^{(2)}(x)$ 和 $f^{(4)}(x)$ 的符号表达式。\n2. 使用泰勒级数，推导以下各项的中心有限差分模板及其主截断误差：\n   - $f^{(2)}(x_0)$ 的标准中心 $3$ 点近似，\n   - 比 $3$ 点模板精度更高的 $f^{(2)}(x_0)$ 的中心 $5$ 点近似，\n   - $f^{(4)}(x_0)$ 的中心 $5$ 点近似。\n   不要假设任何预先已知的系数；通过匹配在 $x_0$ 处的泰勒级数项来推导它们。\n3. 实现一个程序，该程序在特定点评估近似值，并通过计算与任务1中的解析导数的误差以及当 $h$ 减半时的误差比率得到的观察阶数来验证收敛阶数。\n\n测试套件：\n- 使用网格间距序列 $h_k = 0.2 \\cdot 2^{-k}$，其中 $k \\in \\{0,1,2,3,4,5\\}$。\n- 对于以下每种情况，计算误差 $E(h_k)$，即数值近似与在 $x_0$ 处的解析导数之间的绝对差，然后使用连续的对 $(h_{k-1}, h_k)$ 计算观察阶数 $p_k$，其中 $k \\in \\{1,2,3,4,5\\}$。\n- 为了稳健性，将每种情况报告的观察阶数定义为最后三个值 $\\{p_3, p_4, p_5\\}$ 的中位数。\n- 验证以下四种情况及其预期阶数和点：\n  - 情况 A：在 $x_0 = 0.7$ 处对 $f^{(2)}(x_0)$ 使用中心 $3$ 点模板，预期阶数为 $2$。\n  - 情况 B：在 $x_0 = 1.3$ 处对 $f^{(2)}(x_0)$ 使用中心 $5$ 点模板，预期阶数为 $4$。\n  - 情况 C：在 $x_0 = 0.0$ 处对 $f^{(4)}(x_0)$ 使用中心 $5$ 点模板，预期阶数为 $2$。\n  - 情况 D（边缘数值情况）：在 $x_0 = 2.0$ 处对 $f^{(2)}(x_0)$ 使用中心 $5$ 点模板，预期阶数为 $4$。\n\n每种情况的通过-失败准则：\n- 设 $\\tilde{p}$ 为报告的观察阶数（$\\{p_3, p_4, p_5\\}$ 的中位数）。如果 $|\\tilde{p} - p_{\\mathrm{expected}}| \\le 0.3$，则该情况通过，否则失败，其中 $p_{\\mathrm{expected}}$ 是该情况的预期阶数。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，顺序为 [情况 A, 情况 B, 情况 C, 情况 D]，其中每个条目是该情况的布尔结果，例如，\"[True,True,False,True]\"。\n- 此问题无需用户输入，也不涉及物理单位或角度单位。所有数值都是无量纲的。", "solution": "该问题被评估为有效，因为它在数值分析方面有科学依据，问题设定良好，目标明确，并且没有不一致或含糊之处。我们接下来提供一个完整的解决方案。\n\n解决方案分三部分呈现，对应于问题陈述中概述的任务。首先，我们推导所需导数的解析表达式。其次，我们使用泰勒级数推导有限差分模板及其截断误差。第三，我们概述将在最终代码中实现的数值验证过程。\n\n### 第 1 部分：解析导数\n\n给定函数 $f(x) = \\exp(-x^2)$。我们将通过直接微分计算其二阶和四阶导数 $f^{(2)}(x)$ 和 $f^{(4)}(x)$。为了在中间步骤中简洁起见，我们使用撇号表示法来表示对 $x$ 的导数，即 $f'(x)$、$f''(x)$ 等。\n\n一阶导数为：\n$$\nf'(x) = \\frac{d}{dx} \\exp(-x^2) = -2x \\exp(-x^2) = -2x f(x)\n$$\n\n使用乘法法则求二阶导数：\n$$\nf''(x) = \\frac{d}{dx} (-2x f(x)) = -2 f(x) - 2x f'(x)\n$$\n代入 $f'(x) = -2x f(x)$：\n$$\nf''(x) = -2 f(x) - 2x (-2x f(x)) = (-2 + 4x^2) f(x)\n$$\n因此，二阶导数的解析表达式为：\n$$\nf^{(2)}(x) = (4x^2 - 2) \\exp(-x^2)\n$$\n\n为了求四阶导数，我们首先计算三阶导数：\n$$\nf'''(x) = \\frac{d}{dx} \\left( (4x^2 - 2) f(x) \\right) = (8x) f(x) + (4x^2 - 2) f'(x)\n$$\n代入 $f'(x) = -2x f(x)$：\n$$\nf'''(x) = 8x f(x) + (4x^2 - 2) (-2x f(x)) = (8x - 8x^3 + 4x) f(x) = (-8x^3 + 12x) f(x)\n$$\n\n最后，通过对 $f'''(x)$ 微分来计算四阶导数：\n$$\nf^{(4)}(x) = \\frac{d}{dx} \\left( (-8x^3 + 12x) f(x) \\right) = (-24x^2 + 12) f(x) + (-8x^3 + 12x) f'(x)\n$$\n代入 $f'(x) = -2x f(x)$：\n$$\nf^{(4)}(x) = (-24x^2 + 12) f(x) + (-8x^3 + 12x) (-2x f(x)) = (-24x^2 + 12 + 16x^4 - 24x^2) f(x)\n$$\n因此，四阶导数的解析表达式为：\n$$\nf^{(4)}(x) = (16x^4 - 48x^2 + 12) \\exp(-x^2)\n$$\n\n### 第 2 部分：有限差分模板和截断误差\n\n我们通过构建在点 $x_0$ 附近的泰勒级数展开的线性组合，来推导中心有限差分公式及其主截断误差项。设 $f_0^{(n)}$ 表示 $f^{(n)}(x_0)$。相关的展开式为：\n$$\nf(x_0 \\pm h) = f_0 \\pm h f_0' + \\frac{h^2}{2} f_0'' + \\frac{\\pm h^3}{6} f_0''' + \\frac{h^4}{24} f_0^{(4)} + \\frac{\\pm h^5}{120} f_0^{(5)} + \\frac{h^6}{720} f_0^{(6)} + \\mathcal{O}(h^7)\n$$\n$$\nf(x_0 \\pm 2h) = f_0 \\pm 2h f_0' + \\frac{(2h)^2}{2} f_0'' + \\frac{\\pm (2h)^3}{6} f_0''' + \\frac{(2h)^4}{24} f_0^{(4)} + \\frac{\\pm (2h)^5}{120} f_0^{(5)} + \\frac{(2h)^6}{720} f_0^{(6)} + \\mathcal{O}(h^7)\n$$\n\n**2a. $f^{(2)}(x_0)$ 的 $3$ 点中心模板**\n我们寻求一个形式为 $f_0'' \\approx \\frac{c_{-1}f(x_0-h) + c_0 f(x_0) + c_1 f(x_0+h)}{h^2}$ 的近似。对于中心模板，对称性要求 $c_{-1}=c_1$。\n考虑组合 $f(x_0+h) - 2f(x_0) + f(x_0-h)$：\n$$\n(f_0 + h f_0' + \\frac{h^2}{2} f_0'' + \\frac{h^3}{6} f_0''' + \\frac{h^4}{24} f_0^{(4)} + \\mathcal{O}(h^6)) - 2f_0 + (f_0 - h f_0' + \\frac{h^2}{2} f_0'' - \\frac{h^3}{6} f_0''' + \\frac{h^4}{24} f_0^{(4)} + \\mathcal{O}(h^6))\n$$\n合并各项，奇数次幂的导数项相互抵消：\n$$\n= (1-2+1)f_0 + (1-1)h f_0' + (\\frac{1}{2}+\\frac{1}{2})h^2 f_0'' + (\\frac{1}{6}-\\frac{1}{6})h^3 f_0''' + (\\frac{1}{24}+\\frac{1}{24})h^4 f_0^{(4)} + \\mathcal{O}(h^6)\n$$\n$$\n= h^2 f_0'' + \\frac{h^4}{12} f_0^{(4)} + \\mathcal{O}(h^6)\n$$\n除以 $h^2$，我们得到近似式：\n$$\n\\frac{f(x_0-h) - 2f(x_0) + f(x_0+h)}{h^2} = f_0'' + \\frac{h^2}{12} f_0^{(4)} + \\mathcal{O}(h^4)\n$$\n该模板为 $\\frac{1}{h^2}[f(x_0-h) - 2f(x_0) + f(x_0+h)]$。主截断误差为 $E_T = \\frac{h^2}{12} f_0^{(4)}$，因此该方法的阶数为 $p=2$。\n\n**2b. $f^{(2)}(x_0)$ 的 $5$ 点中心模板**\n我们寻求一个形式为 $\\frac{1}{h^2} \\sum_{j=-2}^{2} c_j f(x_0+jh)$ 的更精确的近似。对称性意味着 $c_{-j}=c_j$。线性组合为 $c_2(f(x_0-2h)+f(x_0+2h)) + c_1(f(x_0-h)+f(x_0+h)) + c_0 f(x_0)$。我们使用求和后的展开式：\n$$\nf(x_0-h) + f(x_0+h) = 2f_0 + h^2 f_0'' + \\frac{h^4}{12} f_0^{(4)} + \\frac{h^6}{360}f_0^{(6)} + \\mathcal{O}(h^8)\n$$\n$$\nf(x_0-2h)+f(x_0+2h) = 2f_0 + 4h^2 f_0'' + \\frac{4h^4}{3} f_0^{(4)} + \\frac{8h^6}{45}f_0^{(6)} + \\mathcal{O}(h^8)\n$$\n我们通过匹配导数的系数，建立一个方程组来确定 $c_0, c_1, c_2$：\n$$\n\\text{分子} = (2c_2 + 2c_1 + c_0)f_0 + (4c_2 + c_1)h^2 f_0'' + (\\frac{4}{3}c_2 + \\frac{1}{12}c_1)h^4 f_0^{(4)} + \\dots\n$$\n为了近似 $h^2 f_0''$，我们需要满足：\n\\begin{enumerate}\n    \\item $f_0$ 的系数：$2c_2 + 2c_1 + c_0 = 0$\n    \\item $f_0''$ 的系数：$4c_2 + c_1 = 1$\n    \\item 为达到更高阶精度，我们消去下一个误差项 ($f_0^{(4)}$)：$\\frac{4}{3}c_2 + \\frac{1}{12}c_1 = 0$\n\\end{enumerate}\n从(3)式，可得 $16c_2 + c_1 = 0 \\implies c_1 = -16c_2$。\n代入(2)式：$4c_2 + (-16c_2) = 1 \\implies -12c_2 = 1 \\implies c_2 = -1/12$。\n则 $c_1 = -16(-1/12) = 4/3$。\n从(1)式：$c_0 = -2c_1 - 2c_2 = -2(4/3) - 2(-1/12) = -8/3 + 1/6 = -16/6 + 1/6 = -15/6 = -5/2$。\n系数为 $c_2=-1/12, c_1=4/3, c_0=-5/2$。模板为：\n$$\n\\frac{-\\frac{1}{12}f(x_0-2h) + \\frac{4}{3}f(x_0-h) - \\frac{5}{2}f(x_0) + \\frac{4}{3}f(x_0+h) - \\frac{1}{12}f(x_0+2h)}{h^2}\n$$\n分子展开式中的下一项涉及 $f_0^{(6)}$：$(\\frac{8}{45}c_2 + \\frac{1}{360}c_1)h^6 f_0^{(6)}$。\n代入数值：$(\\frac{8}{45}(-\\frac{1}{12}) + \\frac{1}{360}(\\frac{4}{3})) h^6 f_0^{(6)} = (-\\frac{2}{135} + \\frac{1}{270})h^6 f_0^{(6)} = -\\frac{3}{270}h^6 f_0^{(6)} = -\\frac{1}{90}h^6 f_0^{(6)}$。\n该近似为 $f_0'' - \\frac{h^4}{90}f_0^{(6)} + \\mathcal{O}(h^6)$。截断误差为 $E_T = -\\frac{h^4}{90}f_0^{(6)}$，因此该方法的阶数为 $p=4$。\n\n**2c. $f^{(4)}(x_0)$ 的 $5$ 点中心模板**\n我们寻求一个形式为 $\\frac{1}{h^4} \\sum_{j=-2}^{2} c_j f(x_0+jh)$ 的 $f_0^{(4)}$ 近似。我们使用与 2b 中相同的分子展开式，但以不同的方式匹配系数来分离出 $f_0^{(4)}$：\n$$\n\\text{分子} = (2c_2 + 2c_1 + c_0)f_0 + (4c_2 + c_1)h^2 f_0'' + (\\frac{4}{3}c_2 + \\frac{1}{12}c_1)h^4 f_0^{(4)} + \\dots\n$$\n为了近似 $h^4 f_0^{(4)}$，我们需要满足：\n\\begin{enumerate}\n    \\item $f_0$ 的系数：$2c_2 + 2c_1 + c_0 = 0$\n    \\item $f_0''$ 的系数：$4c_2 + c_1 = 0 \\implies c_1 = -4c_2$\n    \\item $f_0^{(4)}$ 的系数：$\\frac{4}{3}c_2 + \\frac{1}{12}c_1 = 1$\n\\end{enumerate}\n从(2)式，将 $c_1 = -4c_2$ 代入(3)式：$\\frac{4}{3}c_2 + \\frac{1}{12}(-4c_2) = 1 \\implies \\frac{4}{3}c_2 - \\frac{1}{3}c_2 = 1 \\implies c_2 = 1$。\n则 $c_1 = -4(1) = -4$。\n从(1)式：$c_0 = -2c_1 - 2c_2 = -2(-4) - 2(1) = 8 - 2 = 6$。\n系数为 $c_2=1, c_1=-4, c_0=6$。模板为：\n$$\n\\frac{f(x_0-2h) - 4f(x_0-h) + 6f(x_0) - 4f(x_0+h) + f(x_0+2h)}{h^4}\n$$\n分子展开式中的下一项涉及 $f_0^{(6)}$：$(\\frac{8}{45}c_2 + \\frac{1}{360}c_1)h^6 f_0^{(6)}$。\n代入数值：$(\\frac{8}{45}(1) + \\frac{1}{360}(-4))h^6 f_0^{(6)} = (\\frac{64}{360} - \\frac{4}{360})h^6 f_0^{(6)} = \\frac{60}{360}h^6 f_0^{(6)} = \\frac{1}{6}h^6 f_0^{(6)}$。\n该近似为 $f_0^{(4)} + \\frac{h^2}{6}f_0^{(6)} + \\mathcal{O}(h^4)$。截断误差为 $E_T = \\frac{h^2}{6}f_0^{(6)}$，因此该方法的阶数为 $p=2$。\n\n### 第 3 部分：数值验证策略\n\n理论推导将通过计算进行验证。对于指定的四个测试用例中的每一个：\n\\begin{enumerate}\n    \\item 使用一个步长序列 $h_k = 0.2 \\cdot 2^{-k}$，其中 $k \\in \\{0, 1, 2, 3, 4, 5\\}$。\n    \\item 对于每个 $h_k$，在指定的点 $x_0$ 计算相应的有限差分近似值。\n    \\item 使用第 1 部分的解析公式计算在 $x_0$ 处的导数的真实值。\n    \\item 绝对误差 $E(h_k)$ 计算为数值近似值和解析值之间的绝对差。\n    \\item 对于 $k \\in \\{1, 2, 3, 4, 5\\}$，使用连续的误差对计算观察到的收敛阶数 $p_k$：\n    $$\n    p_k = \\frac{\\log(E(h_{k-1})/E(h_k))}{\\log(h_{k-1}/h_k)} = \\frac{\\log(E(h_{k-1})/E(h_k))}{\\log(2)}\n    $$\n    \\item 每种情况报告的观察阶数 $\\tilde{p}$ 定义为最后三个计算出的阶数 $\\{p_3, p_4, p_5\\}$ 的中位数。这提供了当 $h \\to 0$ 时渐近收敛率的稳定估计。\n    \\item 最后，使用准则 $|\\tilde{p} - p_{\\mathrm{expected}}| \\le 0.3$ 将每个案例与其预期的理论阶数 $p_{\\mathrm{expected}}$ 进行验证。\n\\end{enumerate}\n此过程将被封装在一个 Python 程序中，以生成最终的布尔结果。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of approximating higher derivatives and verifying convergence orders.\n    \"\"\"\n\n    # Part 1: Analytic Functions\n    def f(x: float) -> float:\n        \"\"\"The base function f(x) = exp(-x^2).\"\"\"\n        return np.exp(-x**2)\n\n    def f_d2(x: float) -> float:\n        \"\"\"The analytic second derivative of f(x).\"\"\"\n        return (4 * x**2 - 2) * np.exp(-x**2)\n\n    def f_d4(x: float) -> float:\n        \"\"\"The analytic fourth derivative of f(x).\"\"\"\n        return (16 * x**4 - 48 * x**2 + 12) * np.exp(-x**2)\n\n    # Part 2: Finite Difference Stencils\n    def approx_d2_3pt(func, x0: float, h: float) -> float:\n        \"\"\"3-point centered difference approximation for the 2nd derivative.\"\"\"\n        return (func(x0 - h) - 2 * func(x0) + func(x0 + h)) / h**2\n\n    def approx_d2_5pt(func, x0: float, h: float) -> float:\n        \"\"\"5-point centered difference approximation for the 2nd derivative (order 4).\"\"\"\n        return (-func(x0 - 2 * h) + 16 * func(x0 - h) - 30 * func(x0) + 16 * func(x0 + h) - func(x0 + 2 * h)) / (12 * h**2)\n\n    def approx_d4_5pt(func, x0: float, h: float) -> float:\n        \"\"\"5-point centered difference approximation for the 4th derivative (order 2).\"\"\"\n        return (func(x0 - 2 * h) - 4 * func(x0 - h) + 6 * func(x0) - 4 * func(x0 + h) + func(x0 + 2 * h)) / h**4\n\n    # Part 3: Numerical Verification\n    h_values = [0.2 * (2**-k) for k in range(6)]\n    \n    # Test cases: (approximation_function, analytic_function, evaluation_point_x0, expected_order)\n    test_cases = [\n        # Case A: 3-point f''(0.7), expected order 2\n        (approx_d2_3pt, f_d2, 0.7, 2),\n        # Case B: 5-point f''(1.3), expected order 4\n        (approx_d2_5pt, f_d2, 1.3, 4),\n        # Case C: 5-point f^(4)(0.0), expected order 2\n        (approx_d4_5pt, f_d4, 0.0, 2),\n        # Case D: 5-point f''(2.0) edge case, expected order 4\n        (approx_d2_5pt, f_d2, 2.0, 4),\n    ]\n\n    final_results = []\n    for approx_func, analytic_func, x0, p_expected in test_cases:\n        errors = []\n        for h in h_values:\n            approx_val = approx_func(f, x0, h)\n            analytic_val = analytic_func(x0)\n            error = np.abs(approx_val - analytic_val)\n            errors.append(error)\n\n        observed_orders = []\n        # Calculate observed orders p_k for k in {1,2,3,4,5}\n        for k in range(1, len(h_values)):\n            # Ratio of step sizes is 2\n            h_ratio = h_values[k-1] / h_values[k]\n            \n            # Avoid division by zero if error becomes numerically zero\n            if errors[k] > 0 and errors[k-1] > 0:\n                error_ratio = errors[k-1] / errors[k]\n                order = np.log(error_ratio) / np.log(h_ratio)\n                observed_orders.append(order)\n            else:\n                # If error is zero, convergence is perfect/infinite.\n                # This case isn't expected to be hit, but we handle it.\n                observed_orders.append(np.inf)\n\n        # Per problem, use median of last three observed orders {p_3, p_4, p_5}\n        # These correspond to indices 2, 3, 4 of observed_orders list\n        # which has 5 elements (p_1 to p_5).\n        if len(observed_orders) >= 5:\n            last_three_orders = observed_orders[2:5]\n            reported_order = np.median(last_three_orders)\n            \n            # Apply pass-fail criterion\n            passed = np.abs(reported_order - p_expected) <= 0.3\n            final_results.append(passed)\n        else:\n            # This path should not be taken given the problem setup\n            final_results.append(False)\n\n    # Format the final output as specified\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```", "id": "3238903"}, {"introduction": "在拥有了一个基础的近似公式后，我们能否用一种系统性的方法来进一步提升其精度，而无需推导更复杂的差分格式？理查森外推法（Richardson extrapolation）为此提供了一个优雅的解决方案。本练习 [@problem_id:3238865] 旨在通过一个对比实验，展示当近似误差具有特定结构（如中心差分格式的偶次幂项）时，理查森外推法如何有效地消除主导误差项，从而显著提高收敛阶。", "problem": "考虑一个光滑标量函数 $f:\\mathbb{R}\\to\\mathbb{R}$，其至少具有五阶连续导数。目标是设计并实现一个数值实验，以展示当理查森外推法应用于二阶导数 $f''(x)$ 时，在使用两种有限差分格式的情况下的表现。从基本原理出发：函数 $f$ 在点 $x$ 附近的泰勒级数展开表明，对于任何足够小的步长 $h$，存在包含 $f$ 的导数的系数，使得离散模板组合能够逼近 $f''(x)$，其主截断误差可以表示为 $h$ 的幂次。该原理是理查森外推法所使用的渐近误差模型分析的基础。\n\n在所有涉及三角函数的计算中，请使用弧度制角度。\n\n您的任务是编写一个程序，对下面列出的每个测试用例执行以下步骤。\n\n1. 使用定义在点 $x-h$、$x$ 和 $x+h$ 上的对称中心差分模板，实现二阶导数的近似计算。已知对于光滑函数 $f$，该模板的主截断误差是 $h$ 的偶数次幂。\n\n2. 使用定义在点 $x$、$x+h$ 和 $x+2h$ 上的向前差分模板，实现二阶导数的近似计算。已知对于光滑函数 $f$，该模板的主截断误差是 $h$ 的奇数次幂。\n\n3. 对于两种模板，均使用步长为 $h$ 和 $h/2$ 时的值构造一个双层理查森外推。此过程假设主误差项按 $h^p$（其中 $p=2$）的规律缩放，该假设继承自中心差分模板的对称性。将这同一个 $p=2$ 的假设不做任何修改地应用于向前差分模板。使用此假设计算外推估计值。\n\n4. 对于每个模板及其对应的外推估计值，针对一个几何步长序列 $\\{h,\\,h/2,\\,h/4,\\,\\dots\\}$，测量其绝对误差 $|A(h)-f''(x)|$，并通过对 $(\\log h, \\log\\text{误差})$ 数据点对进行直线拟合来计算经验精度阶。经验阶是最佳拟合线的斜率，它量化了误差随 $h$ 变化的规律。\n\n5. 对于每个测试用例，报告四个浮点数（保留两位小数）：基础中心差分估计的经验阶、其外推估计的经验阶、基础向前差分估计的经验阶，以及在直接使用 $p=2$ 假设下构造的外推估计的经验阶。数值实验应表明，理查森外推法显著改善了中心差分（提高了阶数），但当使用未经修改的相同 $p=2$ 假设时，未能对向前差分产生同样地改进效果。\n\n测试套件：\n- 用例 1：$f(x)=e^x$，$x_0=0.3$，初始步长 $h_0=0.2$，细化级别 $5$。\n- 用例 2：$f(x)=\\sin(x)$（角度为弧度制），$x_0=1.0$，初始步長 $h_0=0.3$，细化级别 $5$。\n- 用例 3：$f(x)=x^7-3x^3+2$，$x_0=0.1$，初始步長 $h_0=0.2$，细化级别 $5$。\n\n对于每个用例，构造几何步长序列 $\\{h_k\\}_{k=0}^{L-1}$，其中 $h_k=h_0/2^k$ 且 $L=5$。对于外推估计，将每个 $h_k$ 与 $h_{k+1}=h_k/2$ 配对；使用所有可用的数据对报告阶数。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含所有结果，形式为一个用方括号括起来的逗号分隔列表。列表必须按用例逐个排序，每个用例内部按以下顺序排列：中心差分基础阶、中心差分外推阶、向前差分基础阶、向前差分外推阶。例如，输出格式必须为\n$[o_{1,\\text{c-base}},o_{1,\\text{c-extrap}},o_{1,\\text{f-base}},o_{1,\\text{f-extrap}},o_{2,\\text{c-base}},\\dots,o_{3,\\text{f-extrap}}]$，\n其中每个 $o$ 是一个保留两位小数的浮点数。", "solution": "该问题陈述是数值分析中的一个有效练习。它在科学上是合理的、适定的和客观的。它要求实现和分析一个涉及有限差分近似和理查森外推法的标准数值实验。所有必需的参数，包括函数、求值点和数值参数（$h_0, L$），都已明确提供。预期的结果——即假设误差阶 $p=2$ 的理查森外推法能改进中心差分格式，但不能改进向前差分格式——与已建立的数值方法理论是一致的。\n\n该问题的理论基础是足够光滑的函数 $f(x)$ 在点 $x$ 附近的泰勒级数展开。对于步长 $h$，我们有：\n$$f(x \\pm h) = f(x) \\pm hf'(x) + \\frac{h^2}{2!}f''(x) \\pm \\frac{h^3}{3!}f'''(x) + \\frac{h^4}{4!}f^{(4)}(x) \\pm \\dots$$\n\n**1. 有限差分格式**\n\n通过组合不同模板点的这些展开式，我们可以推导出二阶导数 $f''(x)$ 的近似值。\n\n**中心差分模板：**\n使用 $f(x+h)$ 和 $f(x-h)$ 的展开式：\n$$f(x+h) + f(x-h) = 2f(x) + h^2f''(x) + \\frac{h^4}{12}f^{(4)}(x) + O(h^6)$$\n求解 $f''(x)$ 可得：\n$$f''(x) = \\frac{f(x+h) - 2f(x) + f(x-h)}{h^2} - \\frac{h^2}{12}f^{(4)}(x) - O(h^4)$$\n因此，中心差分近似 $D_C(h)$ 为：\n$$D_C(h) = \\frac{f(x+h) - 2f(x) + f(x-h)}{h^2}$$\n误差 $E_C(h) = D_C(h) - f''(x)$ 具有一个关于 $h$ 的偶数次幂的渐近展开：\n$$E_C(h) = C_2h^2 + C_4h^4 + C_6h^6 + \\dots$$\n其中 $C_2 = -\\frac{1}{12}f^{(4)}(x)$。主误差项为 $O(h^2)$，因此该方法是二阶精度的。\n\n**向前差分模板：**\n使用 $f(x+h)$ 和 $f(x+2h)$ 的展开式：\n$$f(x+h) = f(x) + hf'(x) + \\frac{h^2}{2}f''(x) + \\frac{h^3}{6}f'''(x) + O(h^4)$$\n$$f(x+2h) = f(x) + 2hf'(x) + 2h^2f''(x) + \\frac{4h^3}{3}f'''(x) + O(h^4)$$\n为了近似 $f''(x)$，我们可以构造线性组合 $f(x+2h) - 2f(x+h) + f(x)$，得到：\n$$f(x+2h) - 2f(x+h) + f(x) = h^2f''(x) + h^3f'''(x) + O(h^4)$$\n求解 $f''(x)$ 可得：\n$$f''(x) = \\frac{f(x+2h) - 2f(x+h) + f(x)}{h^2} - hf'''(x) - O(h^2)$$\n向前差分近似 $D_F(h)$ 为：\n$$D_F(h) = \\frac{f(x+2h) - 2f(x+h) + f(x)}{h^2}$$\n误差 $E_F(h) = D_F(h) - f''(x)$ 具有一个关于 $h$ 的所有幂次的渐近展开：\n$$E_F(h) = C_1h + C_2h^2 + C_3h^3 \\dots$$\n其中 $C_1 = f'''(x)$。主误差项为 $O(h)$，因此该方法是一阶精度的。\n\n**2. 理查森外推法**\n\n设 $A(h)$ 是真实值 $A_{true}$ 的一个近似，其主误差项为 $p$ 阶，即 $A(h) = A_{true} + Ch^p + O(h^q)$，其中 $q>p$。我们可以通过组合在两个不同步长 $h$ 和 $h/2$ 下的近似值来计算一个更精确的估计：\n$$A_{true} \\approx A(h) - Ch^p$$\n$$A_{true} \\approx A(h/2) - C(h/2)^p$$\n消去未知常数 $C$ 可得到外推值 $A_{extrap}$：\n$$A_{extrap} = \\frac{2^p A(h/2) - A(h)}{2^p-1}$$\n问题指定对两种格式都使用假定的阶 $p=2$。公式为：\n$$A_{extrap}(h) = \\frac{4A(h/2) - A(h)}{3}$$\n\n- **应用于中心差分：** 误差结构为 $E_C(h) = C_2h^2 + C_4h^4 + \\dots$。使用 $p=2$ 的外推公式与主误差项正确匹配。$O(h^2)$ 项被消除，新的主误差项为 $O(h^4)$。精度阶预计会从 $2$ 提高到 $4$。\n\n- **应用于向前差分：** 误差结构为 $E_F(h) = C_1h + C_2h^2 + \\dots$。应用带有不正确的 $p=2$ 假设的外推公式：\n$$D_{F,extrap}(h) = \\frac{4 D_F(h/2) - D_F(h)}{3} = \\frac{4(f''(x) + C_1\\frac{h}{2} + \\dots) - (f''(x) + C_1h + \\dots)}{3}$$\n$$D_{F,extrap}(h) = \\frac{3f''(x) + (2C_1h - C_1h) + \\dots}{3} = f''(x) + \\frac{C_1}{3}h + \\dots$$\n$O(h)$ 项没有被消除。该方法仍然是一阶精度，外推法未能提高其阶数。\n\n**3. 经验精度阶**\n\n如果一个近似的误差 $E(h)$ 在 $h$ 较小时表现为 $E(h) \\approx Kh^p$，我们可以通过经验方法确定阶数 $p$。对两边取对数得到：\n$$\\log|E(h)| \\approx \\log|K| + p \\log h$$\n这表明 $\\log|E(h)|$ 和 $\\log h$ 之间存在线性关系。这条线的斜率就是精度阶 $p$。我们通过对点集 $\\{(\\log h_k, \\log|E(h_k)|)\\}_{k=0}^{L-1}$ 进行线性回归（最小二乘拟合）来计算这个斜率。\n\n程序将对每个测试用例执行以下步骤：\n1. 定义函数 $f$ 及其精确的二阶导数 $f''$。\n2. 生成一个包含 $L=5$ 个步长的几何序列 $h_k = h_0/2^k$。\n3. 对于每个 $h_k$，计算基础近似值 $D_C(h_k)$ 和 $D_F(h_k)$ 及其绝对误差。\n4. 使用数据对 $(h_k, h_{k+1})$ 计算两种格式的外推值及其对应的绝对误差。这将为每个外推序列生成 $L-1=4$ 个数据点。\n5. 对于四组误差数据（中心差分基础、中心差分外推、向前差分基础、向前差分外推），通过求解对数-对数误差数据的最佳拟合线的斜率来计算经验精度阶。\n6. 收集并格式化每个测试用例的四个结果阶数，如规范所示。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the numerical experiment problem for Richardson extrapolation.\n    \"\"\"\n\n    def linear_regression_slope(x_data, y_data):\n        \"\"\"\n        Calculates the slope of the best-fit line for (x, y) data.\n        This is equivalent to fitting y = m*x + c.\n        \"\"\"\n        # np.polyfit is a robust way to perform linear regression.\n        # It fits a polynomial of degree 1 and returns [slope, intercept].\n        slope, _ = np.polyfit(x_data, y_data, 1)\n        return slope\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"f\": lambda x: np.exp(x),\n            \"f_pp\": lambda x: np.exp(x), # f''(x)\n            \"x0\": 0.3,\n            \"h0\": 0.2,\n            \"L\": 5,\n        },\n        {\n            \"f\": lambda x: np.sin(x),\n            \"f_pp\": lambda x: -np.sin(x), # f''(x)\n            \"x0\": 1.0,\n            \"h0\": 0.3,\n            \"L\": 5,\n        },\n        {\n            \"f\": lambda x: x**7 - 3 * x**3 + 2,\n            \"f_pp\": lambda x: 42 * x**5 - 18 * x, # f''(x)\n            \"x0\": 0.1,\n            \"h0\": 0.2,\n            \"L\": 5,\n        }\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        f = case[\"f\"]\n        f_pp = case[\"f_pp\"]\n        x0 = case[\"x0\"]\n        h0 = case[\"h0\"]\n        L = case[\"L\"]\n\n        # Generate geometric sequence of step sizes\n        h_values = np.array([h0 / (2**k) for k in range(L)])\n        true_val = f_pp(x0)\n\n        # --- Central Difference Calculations ---\n        \n        # Base approximation\n        dc_base_vals = (f(x0 + h_values) - 2 * f(x0) + f(x0 - h_values)) / h_values**2\n        errors_c_base = np.abs(dc_base_vals - true_val)\n        order_c_base = linear_regression_slope(np.log(h_values), np.log(errors_c_base))\n\n        # Extrapolated approximation\n        # Uses L-1 pairs of (h, h/2), corresponding to h_k and h_{k+1}\n        h_extrap = h_values[:-1] # The larger step size in each pair\n        dc_base_h = dc_base_vals[:-1] # A(h)\n        dc_base_h_half = dc_base_vals[1:] # A(h/2)\n        \n        # Richardson formula for p=2: (4*A(h/2) - A(h))/3\n        dc_extrap_vals = (4 * dc_base_h_half - dc_base_h) / 3\n        errors_c_extrap = np.abs(dc_extrap_vals - true_val)\n        order_c_extrap = linear_regression_slope(np.log(h_extrap), np.log(errors_c_extrap))\n\n        # --- Forward Difference Calculations ---\n\n        # Base approximation\n        df_base_vals = (f(x0 + 2 * h_values) - 2 * f(x0 + h_values) + f(x0)) / h_values**2\n        errors_f_base = np.abs(df_base_vals - true_val)\n        order_f_base = linear_regression_slope(np.log(h_values), np.log(errors_f_base))\n        \n        # Extrapolated approximation (naively using p=2)\n        df_base_h = df_base_vals[:-1] # A(h)\n        df_base_h_half = df_base_vals[1:] # A(h/2)\n        \n        df_extrap_vals = (4 * df_base_h_half - df_base_h) / 3\n        errors_f_extrap = np.abs(df_extrap_vals - true_val)\n        order_f_extrap = linear_regression_slope(np.log(h_extrap), np.log(errors_f_extrap))\n\n        # Append results for the current case, rounded to two decimal places\n        all_results.extend([\n            order_c_base,\n            order_c_extrap,\n            order_f_base,\n            order_f_extrap\n        ])\n\n    # Format the final output string\n    formatted_results = [f\"{x:.2f}\" for x in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3238865"}]}