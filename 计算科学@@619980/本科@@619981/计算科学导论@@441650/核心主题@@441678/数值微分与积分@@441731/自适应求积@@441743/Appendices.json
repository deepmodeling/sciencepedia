{"hands_on_practices": [{"introduction": "为了真正掌握自适应求积的精髓，最好的方法莫过于亲手从头构建一个。这项实践 [@problem_id:3284319] 将指导你基于最基本的梯形法则，实现一个简单的自适应求积方案。其核心挑战在于，你需要从第一性原理出发，通过比较粗略估算和精细估算之间的差异来推导局部误差估计器，这是理解所有自适应方法工作原理的关键一步。", "problem": "您的任务是构建一个基于第一性原理的、自洽的程序，该程序为梯形法则实现一个自适应数值积分方案。核心目标是使用一种自适应细化策略来近似一系列测试函数的定积分 $\\int_{a}^{b} f(x)\\,dx$。该策略通过比较整个区间上的梯形近似值与其两个子区间上的梯形近似值之和来估计局部误差。\n\n从定积分作为 Riemann 和的极限的定义以及在 $x=a$ 和 $x=b$ 之间构建 $f(x)$ 的线性插值函数开始。单个区间的梯形法则是通过在 $[a,b]$ 上对这个线性插值函数进行积分得出的。您的算法必须：\n- 在任何宽度为 $h=b-a$ 的子区间 $[a,b]$ 上，计算整个区间上的梯形近似值，以及其两个子区间 $[a,m]$ 和 $[m,b]$（其中 $m=(a+b)/2$）上的组合梯形近似值。\n- 仅使用这两种近似值（整个区间与两个子区间之和）之间的比较来设计一个局部误差估计器。该估计器需从关于当区间减半时局部截断误差如何随区间宽度变化的合理推论中得出。不要假设或使用任何非从此误差缩放推论中导出的快捷公式。\n- 如果估计的局部误差低于预设的容差，则接受该子区间，并可选择性地使用源自相同误差缩放原理的偏差校正估计值；否则，将该区间一分为二，并在每个子区间上进行递归。\n- 通过最大递归深度参数 $D_{\\max}$ 确保终止，并正确处理 $a=b$ 的退化区间。\n\n任何三角函数的角度单位必须是弧度。此问题中没有物理单位。测试套件中的所有数值容差均为绝对容差。\n\n实现您的程序以评估以下测试套件。对于每个测试用例，使用您的自适应梯形方案和给定的容差计算积分近似值，并将结果汇总到指定格式的单行输出中。\n\n测试套件：\n1. $f(x)=\\sin(x)$ 在 $[0,\\pi]$ 上，容差为 $10^{-12}$。\n2. $f(x)=e^{-x^{2}}$ 在 $[0,1]$ 上，容差为 $10^{-12}$。\n3. $f(x)=\\dfrac{1}{1+x^{2}}$ 在 $[-5,5]$ 上，容差为 $10^{-10}$。\n4. $f(x)=|x|$ 在 $[-1,1]$ 上，容差为 $10^{-10}$。\n5. $f(x)=\\dfrac{\\sin(100x)}{1+x^{2}}$ 在 $[0,1]$ 上，容差为 $10^{-8}$。\n6. $f(x)=5$ 在 $[2,5]$ 上，容差为 $10^{-12}$。\n7. $f(x)=\\sin(x)$ 在 $[1,1]$ 上（零长度区间），容差为 $10^{-12}$。\n\n覆盖设计：\n- 第一个用例是一个光滑周期函数在一个完整周期上的积分。\n- 第二个用例的被积函数呈钟形，在区间内具有快速衰减的尾部。\n- 第三个用例测试有理被积函数在一个对称大区间上的积分。\n- 第四个用例测试在中断点不可微的被积函数。\n- 第五个用例是具有中等阻尼的振荡函数。\n- 第六个用例是常数函数，应立即终止。\n- 第七个用例是零长度区间的边界情况。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表，不含额外的空格或文本。例如：“[r1,r2,r3,r4,r5,r6,r7]”。每个 $r_{i}$ 都必须是一个浮点数，代表相应测试用例的积分近似值，由您的自适应梯形法计算得出。", "solution": "该问题要求开发一种基于梯形法则的自适应数值积分方案。任务的核心是从第一性原理出发，通过比较一个区间上的粗略近似和更精细的近似，来推导误差估计和细化策略。\n\n### 基于原理的推导\n\n设待近似的定积分为 $I = \\int_{a}^{b} f(x)\\,dx$。\n\n**1. 从第一性原理推导梯形法则**\n\n梯形法则用一个线性多项式 $p_1(x)$ 来近似被积函数 $f(x)$，该多项式在区间 $[a, b]$ 的端点处对函数进行插值。这些点的坐标是 $(a, f(a))$ 和 $(b, f(b))$。线性插值函数由下式给出：\n$$p_1(x) = f(a) + \\frac{f(b) - f(a)}{b-a}(x - a)$$\n这个线性多项式在区间 $[a, b]$ 上的积分提供了梯形近似值，记为 $T(a,b)$。设 $h = b - a$ 为区间的宽度。\n$$T(a,b) = \\int_{a}^{b} p_1(x) \\,dx = \\int_{a}^{b} \\left( f(a) + \\frac{f(b) - f(a)}{h}(x - a) \\right) \\,dx$$\n$$= \\left[ f(a)x + \\frac{f(b) - f(a)}{h} \\left( \\frac{x^2}{2} - ax \\right) \\right]_{a}^{b}$$\n$$= f(a)(b-a) + \\frac{f(b) - f(a)}{h} \\left( \\left(\\frac{b^2}{2} - ab\\right) - \\left(\\frac{a^2}{2} - a^2\\right) \\right)$$\n$$= f(a)h + \\frac{f(b) - f(a)}{h} \\left( \\frac{b^2 - 2ab + a^2}{2} \\right) = f(a)h + \\frac{f(b) - f(a)}{h} \\frac{(b-a)^2}{2}$$\n$$= f(a)h + (f(b) - f(a))\\frac{h}{2} = \\frac{h}{2}(2f(a) + f(b) - f(a)) = \\frac{h}{2}(f(a) + f(b))$$\n这就是单区间的梯形法则。我们称这个粗略近似为 $S_1$。\n$$S_1 = \\frac{h}{2}(f(a) + f(b))$$\n\n**2. 通过细化进行误差估计**\n\n为了估计误差，我们将 $S_1$ 与一个更精确的近似值 $S_2$ 进行比较，$S_2$ 是通过将区间 $[a, b]$ 分割成两个等宽的子区间 $[a, m]$ 和 $[m, b]$（其中 $m = (a+b)/2$）得到的。每个子区间的宽度是 $h/2$。近似值 $S_2$ 是对每个子区间应用梯形法则后的和：\n$$S_2 = T(a, m) + T(m, b) = \\frac{h/2}{2}(f(a) + f(m)) + \\frac{h/2}{2}(f(m) + f(b))$$\n$$S_2 = \\frac{h}{4}(f(a) + 2f(m) + f(b))$$\n\n对于宽度为 $w$ 的区间，梯形法则的局部截断误差由 $E(w) = -\\frac{w^3}{12}f''(\\xi)$ 给出，其中 $\\xi$ 在该区间内，并假设 $f$ 是二阶连续可微的。这表明误差与区间宽度的三次方成正比，即 $E(w) \\approx Cw^3$。\n\n真实积分 $I$ 可以与我们的近似值 $S_1$ 和 $S_2$ 关联如下：\n$I = S_1 + E(h) \\approx S_1 + Ch^3$\n$I = S_2 + E(h/2) + E(h/2) \\approx S_2 + 2C(h/2)^3 = S_2 + \\frac{Ch^3}{4}$\n\n我们现在有一个包含两个未知数 $I$ 和 $C$ 的方程组：\n$I - S_1 \\approx Ch^3$\n$I - S_2 \\approx \\frac{Ch^3}{4}$\n\n用第一个方程减去第二个方程，得到：\n$(I - S_2) - (I - S_1) \\approx \\frac{Ch^3}{4} - Ch^3 \\implies S_1 - S_2 \\approx -\\frac{3}{4}Ch^3$\n\n这使我们能够用我们计算出的量 $S_1$ 和 $S_2$ 来表示未知项 $Ch^3$：\n$Ch^3 \\approx \\frac{4}{3}(S_2 - S_1)$\n\n现在可以估计更精确近似值中的误差 $E_2 = I - S_2$。\n$E_2 \\approx \\frac{Ch^3}{4} \\approx \\frac{1}{4} \\left( \\frac{4}{3}(S_2 - S_1) \\right) = \\frac{1}{3}(S_2 - S_1)$\n\n因此，精细近似值 $S_2$ 的绝对局部误差可以估计为：\n$$\\text{err} \\approx \\frac{1}{3}|S_2 - S_1|$$\n该估计器完全是根据两个近似值的比较以及局部误差的缩放性质推导出来的，符合要求。\n\n**3. 自适应算法与偏差校正**\n\n自适应算法以递归方式进行。对于给定的区间 $[a, b]$ 和绝对容差 $\\tau$：\n1.  计算 $S_1$、$S_2$ 和误差估计 $\\text{err} = \\frac{1}{3}|S_2 - S_1|$。\n2.  如果 $\\text{err} < \\tau$，则认为该区间的近似已足够精确。此分支的过程终止。\n3.  如果 $\\text{err} \\ge \\tau$，则将区间分割为 $[a, m]$ 和 $[m, b]$。然后在每个子区间上递归调用该算法，并将容差预算相应地分配，通常每个子区间为 $\\tau/2$。递归调用的结果相加。\n\n问题提到了使用“偏差校正的估计值”。这是 Richardson 外推法的一个应用。通过用我们的误差估计 $E_2$ 来校正 $S_2$，可以得到对真实积分 $I$ 的更好估计：\n$$I \\approx S_2 + E_2 \\approx S_2 + \\frac{1}{3}(S_2 - S_1) = \\frac{4S_2 - S_1}{3}$$\n这个校正后的值实际上就是区间 $[a,b]$ 上的 Simpson 法则：\n$$\\frac{4}{3} \\left( \\frac{h}{4}(f(a) + 2f(m) + f(b)) \\right) - \\frac{1}{3} \\left( \\frac{h}{2}(f(a) + f(b)) \\right) = \\frac{h}{3}(f(a) + 2f(m) + f(b)) - \\frac{h}{6}(f(a) + f(b))$$\n$$= \\frac{h}{6} (2f(a) + 4f(m) + 2f(b) - f(a) - f(b)) = \\frac{h}{6}(f(a) + 4f(m) + f(b))$$\n当一个区间被接受时（即 $\\text{err} < \\tau$），返回这个高阶的 Simpson 法则近似值，可以在函数求值次数相同的情况下提供更精确的结果。\n\n**4. 实现结构与终止条件**\n\n该算法实现为一个递归函数。一个包装函数负责初始化整个过程。\n- **递归的基准情形：**\n    1.  如果 $a = b$，积分为 $0$。\n    2.  设置一个最大递归深度 $D_{\\max}$，以保证算法终止，即使在容差标准永远无法满足的情况下（例如，对于某些病态函数或浮点精度不足）。如果达到此深度，则返回当前子区间的最佳估计值。\n\n- **递归步骤：**\n    一个内部函数 `_adaptive_trapezoid(f, a, b, tol, fa, fb, depth)` 将执行主要逻辑。将 `fa=f(a)` 和 `fb=f(b)` 作为参数传递，可以避免在父区间和子区间的共享端点上进行重复的函数求值。如果误差标准未满足，它会进行两次递归调用：\n    `_adaptive_trapezoid(f, a, m, tol/2, fa, fm, depth+1) + _adaptive_trapezoid(f, m, b, tol/2, fm, fb, depth+1)`\n    其中 $m=(a+b)/2$ 且 $fm=f(m)$。这种结构高效且稳健地实现了自适应积分方案。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the adaptive integration problem for the given test suite.\n    \"\"\"\n\n    MAX_DEPTH = 50\n\n    def _adaptive_trapezoid(f, a, b, tol, fa, fb, depth):\n        \"\"\"\n        Recursive helper function for adaptive trapezoidal integration.\n\n        This function approximates the integral of f(x) from a to b. It estimates\n        the error by comparing a one-panel trapezoid rule with a two-panel rule.\n        If the error is too large, it recursively calls itself on the two halves\n        of the interval.\n\n        Args:\n            f (callable): The function to integrate.\n            a (float): The start of the integration interval.\n            b (float): The end of the integration interval.\n            tol (float): The absolute tolerance for this subinterval.\n            fa (float): The value of f(a), passed to avoid re-computation.\n            fb (float): The value of f(b), passed to avoid re-computation.\n            depth (int): The current recursion depth.\n\n        Returns:\n            float: The approximated integral value for the interval [a, b].\n        \"\"\"\n        # Base case 1: Zero-length interval\n        if a == b:\n            return 0.0\n\n        # Base case 2: Maximum recursion depth reached\n        if depth > MAX_DEPTH:\n            # Reached depth limit, return best available coarse estimate.\n            # A warning could be printed here in a real application.\n            h = b - a\n            return (h / 2.0) * (fa + fb)\n\n        h = b - a\n        m = (a + b) / 2.0\n        fm = f(m)\n\n        # S1: Coarse approximation (1 trapezoid over [a,b])\n        s1 = (h / 2.0) * (fa + fb)\n\n        # S2: Finer approximation (2 trapezoids over [a,m] and [m,b])\n        s2 = (h / 4.0) * (fa + 2.0 * fm + fb)\n\n        # Estimate the error of the more accurate approximation, S2.\n        # This is derived from Richardson extrapolation, where error(S2) ~ (S2-S1)/3\n        error_estimate = abs(s2 - s1) / 3.0\n\n        if error_estimate < tol:\n            # Error is within tolerance. Return the bias-reduced (Simpson's rule) value.\n            # This is S2 + error_estimate, which is more accurate.\n            return s2 + (s2 - s1) / 3.0\n        else:\n            # Error is too large. Split the interval and recurse.\n            # The tolerance is split between the two sub-intervals.\n            left_integral = _adaptive_trapezoid(f, a, m, tol / 2.0, fa, fm, depth + 1)\n            right_integral = _adaptive_trapezoid(f, m, b, tol / 2.0, fm, fb, depth + 1)\n            return left_integral + right_integral\n\n    def adaptive_integrator(f, a, b, tol):\n        \"\"\"\n        Wrapper function to start the adaptive integration process.\n        \"\"\"\n        # Initial call to the recursive helper function.\n        # Pre-calculates f(a) and f(b) for efficiency.\n        return _adaptive_trapezoid(f, a, b, tol, f(a), f(b), 0)\n\n    # Test Suite Definition\n    test_cases = [\n        {'func': lambda x: np.sin(x), 'interval': (0, np.pi), 'tol': 1e-12},\n        {'func': lambda x: np.exp(-x**2), 'interval': (0, 1), 'tol': 1e-12},\n        {'func': lambda x: 1.0 / (1.0 + x**2), 'interval': (-5, 5), 'tol': 1e-10},\n        {'func': lambda x: np.abs(x), 'interval': (-1, 1), 'tol': 1e-10},\n        {'func': lambda x: np.sin(100 * x) / (1.0 + x**2), 'interval': (0, 1), 'tol': 1e-8},\n        {'func': lambda x: 5.0, 'interval': (2, 5), 'tol': 1e-12}, # Use 5.0 to ensure float\n        {'func': lambda x: np.sin(x), 'interval': (1, 1), 'tol': 1e-12},\n    ]\n\n    results = []\n    for case in test_cases:\n        f = case['func']\n        a, b = case['interval']\n        tol = case['tol']\n        \n        # Handle the zero-length interval case explicitly in the wrapper for clarity,\n        # although the recursion also handles it.\n        if a == b:\n            result = 0.0\n        else:\n            result = adaptive_integrator(f, a, b, tol)\n        \n        results.append(result)\n\n    # Format the final output string exactly as required.\n    # The repr() function provides a high-precision string representation of floats.\n    print(f\"[{','.join(map(repr, results))}]\")\n\nsolve()\n\n```", "id": "3284319"}, {"introduction": "标准的自适应算法在处理含有跳跃间断点的函数时可能会“卡住”，陷入无限递归的陷阱。这项实践旨在解决这一关键的实际问题 [@problem_id:3203393]，你将学习如何通过引入一个基于计算机浮点数精度（机器 epsilon, $\\varepsilon_{\\mathrm{mach}}$）的鲁棒停止准则来增强你的算法。这不仅能让你的程序处理更广泛的函数类型，更重要的是，它教会了你编写能应对“病态”情况的稳健数值代码的核心技巧。", "problem": "您需要设计并实现一个误差控制的自适应求积算法，该算法通过引入一个与浮点分辨率相关的有原则的停止准则，在存在跳跃间断点时能够保持稳健。其背景是计算一个有界函数在闭区间上的定积分的数值近似。此任务的基础包括：(i) 黎曼积分的定义，即有界函数在闭区间上黎曼和的极限；(ii) 基于在等距节点上进行多项式插值的复合求积法则；(iii) 双精度浮点运算的性质，特别是机器ε（machine epsilon）的概念。\n\n任务要求：\n- 实现一个基于在每个区间上使用三个节点进行多项式插值的自适应区间细分求积。您的递归必须由一个通过比较单个区间与其两个子区间的计算结果得出的误差指示器来引导。不要硬编码最大递归深度；您的方法必须由数值误差容限和下述的稳健停止准则控制。\n- 构建并使用一个稳健的停止准则，通过强制设定一个与双精度机器ε相关的最小区间宽度，来防止在间断点附近的无限细分。设双精度机器ε由$\\varepsilon_{\\mathrm{mach}}$表示，通过编程方式获取。将最小区间宽度定义为\n$$\nh_{\\min} \\;=\\; \\beta \\cdot \\max\\!\\big(1,\\lvert a \\rvert,\\lvert b \\rvert\\big) \\cdot \\varepsilon_{\\mathrm{mach}},\n$$\n其中 $\\beta = 256$，$a,b$是当前区间的端点。如果一个宽度为 $h$ 的区间满足 $h \\le h_{\\min}$，您必须终止在该区间上的细分，并接受子区间的近似值，不再进行细分。此外，如果由于浮点分辨率导致中点等于任一端点，也必须终止在该区间上的细分。\n- 被积函数：使用平移至间断点 $x=\\frac{1}{2}$ 的亥维赛德阶跃函数（Heaviside step function），\n$$\nf(x) \\;=\\; H(x - 0.5) \\;=\\; \n\\begin{cases}\n0, & x < 0.5,\\\\\n0, & x = 0.5,\\\\\n1, & x > 0.5,\n\\end{cases}\n$$\n其中间断点处的值设为 $0$，以强制产生非平凡的细分行为。\n- 误差容限：用 $\\tau$ 表示用户指定的容限，并通过父子区间的比较在自适应递归中强制执行。您的算法应返回数值积分近似值和一个布尔指示器，该指示器说明在该积分评估的递归过程中，最小宽度上限是否至少被触发过一次。\n\n测试套件：\n在以下每个区间和容限下评估 $f(x)$ 的积分：\n1. $[0,1]$，$\\tau = 10^{-8}$。\n2. $[0,1]$，$\\tau = 10^{-20}$。\n3. $[0,0.49]$，$\\tau = 10^{-8}$。\n4. $[0.51,1]$，$\\tau = 10^{-8}$。\n\n答案规格：\n- 对每个测试用例，返回两个输出：积分近似值（浮点数）和布尔指示器（如果触发了最小宽度上限则为真，否则为假）。\n- 您的程序应生成单行输出，其中包含一个逗号分隔的列表，用方括号括起来，顺序如下：\n$$\n[\\text{I}_1,\\text{C}_1,\\text{I}_2,\\text{C}_2,\\text{I}_3,\\text{C}_3,\\text{I}_4,\\text{C}_4],\n$$\n其中 $\\text{I}_k$ 是测试用例 $k$ 的积分近似值（浮点数），$\\text{C}_k$ 是上限触发指示器（布尔值）。\n不涉及物理单位，也没有出现角度；所有量都是无量纲的。", "solution": "问题陈述经评估有效。这是一个在数值分析领域内定义明确、具有科学依据的问题。它为设计和实现一个带有稳健停止准则的自适应求积算法以处理含跳跃间断点的函数，提供了一套完整且一致的要求。所有参数、待积函数以及测试用例都得到了明确的规定。\n\n该解决方案是通过综合数值积分、误差估计和浮点运算的原理来开发的。该算法是一种基于辛普森法则的递归自适应求积方法，并增加了一个停止准则，通过尊重双精度浮点分辨率的限制来确保在存在间断点时能够终止。\n\n该算法的核心组成部分如下：\n\n1.  **基础求积法则：辛普森法则 (Simpson's Rule)**\n    问题指定了一个基于在每个区间上使用三个节点进行多项式插值的求积法则。对于一个区间 $[a, b]$，节点的标准选择是端点 $a$、$b$ 以及中点 $m = (a+b)/2$。对在这些点 $(a, f(a))$、$(m, f(m))$ 和 $(b, f(b))$ 上插值函数 $f(x)$ 的唯一二次多项式进行精确积分，即可得到辛普森法则。$f(x)$ 在 $[a, b]$ 上积分的近似值，记为 $S(a,b)$，由以下公式给出：\n    $$\n    S(a, b) = \\frac{b-a}{6} \\left( f(a) + 4f\\left(\\frac{a+b}{2}\\right) + f(b) \\right)\n    $$\n    辛普森法则对于最高为3次的多项式是精确的。\n\n2.  **带误差估计的自适应细分**\n    自适应求积的原理是只在函数“难以”积分的区间进行细分，即在估计的积分误差较大的地方。这是通过一个递归过程实现的。对于一个给定的区间 $[a, b]$，我们计算一个粗略的近似值 $I_{parent} = S(a, b)$。然后，我们在其中点 $m = (a+b)/2$ 处将该区间细分为两个子区间 $[a, m]$ 和 $[m, b]$。通过对每个子区间上的辛普森法则结果求和，计算出一个更精确的近似值 $I_{children}$：\n    $$\n    I_{children} = S(a, m) + S(m, b)\n    $$\n    粗略近似值 $S(a,b)$ 的误差阶为 $\\mathcal{O}((b-a)^5)$，而精确近似值 $I_{children}$ 的误差阶为 $\\mathcal{O}((m-a)^5 + (b-m)^5) = \\mathcal{O}(2 \\cdot (\\frac{b-a}{2})^5) = \\frac{1}{16}\\mathcal{O}((b-a)^5)$。这意味着精确近似值的误差大约是粗略近似值误差的 $1/16$。因此，两个计算值之间的差可以用来估计更精确近似值 $I_{children}$ 的误差：\n    $$\n    E_{children} \\approx \\frac{1}{15} |I_{children} - I_{parent}|\n    $$\n    如果这个估计误差在指定的容限 $\\tau_{panel}$ 之内，则终止对区间 $[a,b]$ 的细分。我们采用一种常用策略，即检查是否 $|I_{children} - I_{parent}| < 15 \\cdot \\tau_{panel}$。整个积分域的全局容限，记为 $\\tau$，被分配到各个子区间。对于二分法，一个简单而有效的方法是为每个子区间分配其父区间容限的一半，因此在每一级递归中，区间的容限会为其子区间减半。\n\n3.  **针对间断点的稳健停止准则**\n    对于具有跳跃间断点的函数，如指定的亥维赛德函数 $f(x) = H(x - 0.5)$，在间断点 $x=0.5$ 附近的误差不会随着区间细分而以预期的速率减小。误差估计将持续无法通过容限检查，导致算法在试图解决跳跃时出现无限递归。为了保证终止，必须有一个基于浮点运算限制的稳健停止准则。指定的准则有两个组成部分，在对一个宽度为 $h=b-a$ 的区间 $[a, b]$ 进行每个递归步骤开始时进行检查：\n    \n    a. **最小区间宽度 ($h_{min}$)**：如果区间宽度 $h$ 变得小于预设的最小值 $h_{min}$，则停止细分。这个最小值是相对于区间端点的尺度和机器精度 $\\varepsilon_{\\mathrm{mach}}$（在浮点运算中使 $1.0 + \\varepsilon_{\\mathrm{mach}} > 1.0$ 成立的最小数）来定义的。\n    $$\n    h_{\\min} = \\beta \\cdot \\max(1, |a|, |b|) \\cdot \\varepsilon_{\\mathrm{mach}}\n    $$\n    给定参数 $\\beta=256$，这就为区间宽度设定了一个下限，防止无限细分。如果 $h \\le h_{\\min}$，我们停止递归。\n\n    b. **浮点分辨率限制**：当 $a$ 和 $b$ 变得非常接近时，它们的中点 $m = (a+b)/2$ 在计算上可能与 $a$ 或 $b$ 无法区分。如果 $m=a$ 或 $m=b$，在给定的浮点系统中，进一步的细分在数学上是不可能的。这个条件作为一个基本的保障。\n\n    如果满足这些条件中的任何一个，当前区间的细分将被终止，并且精确近似值 $I_{children}$ 将被接受为该区间的结果。返回一个布尔标志以指示触发了此特殊终止。\n\n4.  **算法综合**\n    完整的算法被实现为一个递归函数。一个主入口函数 `adaptive_quadrature(func, a, b, tol)` 设置初始区间和容限，并调用一个递归辅助函数。\n    递归辅助函数 `_recursive_quad(func, a, b, tol_sub, ...)` 对其给定的区间执行以下步骤：\n    i. 检查稳健停止准则。如果满足，返回子区间的近似值 $I_{children}$ 和一个 `true` 标志。\n    ii. 计算父区间的近似值 $I_{parent}$ 和子区间的近似值 $I_{children}$。\n    iii. 计算误差估计 $|I_{children} - I_{parent}|$。\n    iv. 如果误差在该区间的容限之内（$< 15 \\cdot \\tau_{sub}$），返回 $I_{children}$ 和一个 `false` 标志。\n    v. 否则，对两个子区间 $[a, m]$ 和 $[m, b]$ 进行递归调用，每个子区间的容限为一半，即 $\\tau_{sub}/2$。\n    vi. 将两个子调用的积分结果相加。`cap_triggered` 状态是子调用状态的逻辑或，确保如果在任何子问题中触发了上限，最终结果会反映这一点。\n\n该设计正确地实现了所有要求，提供了一个稳健的数值积分器，能够处理指定的测试用例，包括在一个包含间断点的区间上使用非常小的容限这一具有挑战性的场景，该场景专门用于测试停止准则。", "answer": "```python\nimport numpy as np\n\n# A global constant for double-precision machine epsilon is defined for convenience.\n_EPS = np.finfo(float).eps\n\ndef f(x: float) -> float:\n    \"\"\"\n    Implements the integrand f(x) = H(x - 0.5), a Heaviside step function.\n    The value at the discontinuity x=0.5 is explicitly defined as 0.\n    \"\"\"\n    if x < 0.5:\n        return 0.0\n    elif x > 0.5:\n        return 1.0\n    else:  # x == 0.5\n        return 0.0\n\ndef _recursive_quad(func, a, b, tol, fa, fm, fb, I_panel):\n    \"\"\"\n    Recursive helper function for the adaptive quadrature algorithm.\n\n    This function performs one step of the adaptive refinement. It checks stopping criteria,\n    estimates error, and decides whether to accept the current approximation or to\n    recurse on sub-panels.\n\n    Args:\n        func: The function to integrate.\n        a, b: The endpoints of the current panel.\n        tol: The error tolerance for the current panel.\n        fa, fm, fb: Pre-computed function values at a, m=(a+b)/2, and b.\n        I_panel: The Simpson's rule approximation on the parent panel [a, b].\n\n    Returns:\n        A tuple (integral_value, cap_triggered), where integral_value is the\n        numerical approximation of the integral on [a, b], and cap_triggered\n        is a boolean indicating if the robust stopping criterion was met.\n    \"\"\"\n    h = b - a\n    m = (a + b) / 2.0\n\n    # 1. Robust Stopping Criterion\n    # This prevents unbounded recursion near discontinuities.\n    h_min = 256.0 * max(1.0, abs(a), abs(b)) * _EPS\n    cap_triggered_this_level = (h <= h_min) or (m == a) or (m == b)\n\n    # 2. Compute Refined Approximation\n    # Subdivide the panel and apply Simpson's rule to each child.\n    ml = (a + m) / 2.0\n    mr = (m + b) / 2.0\n    fml = func(ml)\n    fmr = func(mr)\n\n    # Simpson's rule over child panels [a, m] and [m, b]\n    # Note: width of each child panel is h/2. The (h/2)/6 factor is (b-a)/12.\n    I_left = (h / 12.0) * (fa + 4.0 * fml + fm)\n    I_right = (h / 12.0) * (fm + 4.0 * fmr + fb)\n    I_children = I_left + I_right\n\n    if cap_triggered_this_level:\n        # If the panel is too small, accept the child approximation and terminate.\n        return I_children, True\n\n    # 3. Error Estimation and Recursion Decision\n    error_est = abs(I_children - I_panel)\n\n    # The error in the refined sum (I_children) is approx. 1/15 of the difference.\n    # We stop if the estimated error is less than the allocated tolerance.\n    # The check is written as `error_est  15 * tol` for numerical stability.\n    if error_est  15.0 * tol:\n        # The problem asks to accept the child-panel approximation.\n        # A more advanced version would add a correction term: I_children + error_est / 15.0\n        return I_children, False\n    else:\n        # If error is too large, recurse on the two child panels.\n        # The tolerance is distributed (halved for each child).\n        tol_sub = tol / 2.0\n        integral_left, cap_left = _recursive_quad(func, a, m, tol_sub, fa, fml, fm, I_left)\n        integral_right, cap_right = _recursive_quad(func, m, b, tol_sub, fm, fmr, fb, I_right)\n\n        # Combine results and propagate the cap_triggered flag.\n        return integral_left + integral_right, cap_left or cap_right\n\ndef adaptive_quadrature(func, a, b, tol):\n    \"\"\"\n    Top-level function for error-controlled adaptive quadrature.\n\n    Args:\n        func: The function to integrate.\n        a, b: The overall integration interval [a, b].\n        tol: The absolute error tolerance for the entire interval.\n\n    Returns:\n        A tuple (integral_value, cap_triggered).\n    \"\"\"\n    h = b - a\n    if h == 0.0:\n        return 0.0, False\n    \n    m = (a + b) / 2.0\n    fa, fm, fb = func(a), func(m), func(b)\n\n    # Initial Simpson's rule approximation over the whole interval [a, b]\n    I_panel = h / 6.0 * (fa + 4.0 * fm + fb)\n\n    return _recursive_quad(func, a, b, tol, fa, fm, fb, I_panel)\n\ndef solve():\n    \"\"\"\n    Executes the test suite and prints the final answer in the specified format.\n    \"\"\"\n    test_cases = [\n        (0.0, 1.0, 1e-8),    # Case 1: Standard run with discontinuity\n        (0.0, 1.0, 1e-20),   # Case 2: Tiny tolerance, should trigger h_min cap\n        (0.0, 0.49, 1e-8),   # Case 3: Smooth region (f(x)=0)\n        (0.51, 1.0, 1e-8)    # Case 4: Smooth region (f(x)=1)\n    ]\n\n    results = []\n    for a, b, tol in test_cases:\n        integral, cap_triggered = adaptive_quadrature(f, a, b, tol)\n        results.append(integral)\n        # Format boolean as lowercase 'true'/'false' string as per problem implications\n        results.append(str(cap_triggered).lower())\n\n    # Format the final output as a single comma-separated list in brackets.\n    output_str = \",\".join(map(str, results))\n    print(f\"[{output_str}]\")\n\nsolve()\n```", "id": "3203393"}, {"introduction": "“自适应”思想的魅力不仅在于加密网格，还在于调整算法本身的复杂度。这项高级实践 [@problem_id:3203569] 将带你探索一种截然不同的自适应策略：在固定的子区间上，动态地改变求积法则的“阶数”。通过使用高斯-勒让德求积法，你将学习如何让算法在平滑区域使用低阶规则以提高效率，在剧烈变化的区域自动切换到高阶规则以保证精度，从而领略自适应思想的灵活性与强大威力。", "problem": "您需要设计并实现一种自适应阶数求积算法，该算法通过改变求积法则在子区间上的多项式阶数来计算定积分。在被积函数近似线性的地方使用低阶，在被积函数高度弯曲的地方使用高阶。该方法必须基于数值积分的基本原理，并为一套测试函数生成结果。\n\n需要采用的基本原理和定义：函数 $f$ 在区间 $[a,b]$ 上的定积分定义为黎曼和的极限，\n$$\n\\int_a^b f(x)\\,dx = \\lim_{n\\to\\infty} \\sum_{k=1}^n f(x_k^\\ast)\\,\\Delta x_k,\n$$\n其中 $[a,b]$ 被划分为长度为 $\\Delta x_k$ 的子区间，并在每个子区间内取样本点 $x_k^\\ast$。对 $f$ 进行多项式插值可以得到求积法则，这些法则通过精确积分直到某个阶数的多项式来近似该积分。高斯求积 (Gaussian Quadrature, GQ)，特别是高斯-勒让德求积 (Gauss–Legendre Quadrature, GLQ)，使用正交多项式来选择 $[-1,1]$ 上的节点和权重，使得 $n$ 点法则能精确积分最高为 $2n-1$ 阶的多项式；应用仿射变量变换可将该法则映射到任意区间 $[a,b]$。\n\n目标：实现一个算法，对于 $[a,b]$ 的每个子区间，调整高斯-勒让德求积法则的阶数 $n$ 以满足指定的局部误差容限。在近似线性的区域使用低阶，在曲率高的区域使用高阶。全局容限 $T$ 被分配到各个子区间，以使局部误差之和不超过 $T$。\n\n需遵循的算法规范：\n- 将 $[a,b]$ 划分为 $m$ 个宽度为 $\\Delta = (b-a)/m$ 的均匀子区间。\n- 在每个子区间 $[x_\\ell, x_r]$ 上，使用高斯-勒让德求积计算两个嵌套的求积近似值：\n  - 一个使用 $n$ 个点的低阶近似（从一个小的初始阶数开始）。\n  - 一个使用 $2n$ 个点的高阶近似。\n- 使用这两个近似值之间的绝对差，记为 $E = \\left| I_{2n} - I_n \\right|$，作为局部误差估计量。如果 $E$ 小于或等于局部容限 $T_{\\text{local}}$，则接受该子区间的高阶近似值 $I_{2n}$；否则，将 $n$ 加倍并重复此过程，直到达到指定的最大阶数。\n- 局部容限必须设置为与子区间宽度成正比，以使 $\\sum E \\le T$。一个简单的选择是 $T_{\\text{local}} = T \\cdot \\frac{\\Delta}{b-a}$。\n\n约束和要求：\n- 所有子区间的近似计算均使用高斯-勒让德求积。\n- 使用仿射变换将节点从 $[-1,1]$ 映射到 $[x_\\ell, x_r]$，并相应地缩放权重。\n- 从一个小的初始阶数（例如，$n=2$）开始，并根据需要向上调整，最高可达最大阶数（例如，$n=64$），以满足局部容限。\n- 实现必须假定在出现三角函数时，角度以弧度为单位。\n- 没有外部输入；所有参数和函数都嵌入在程序中。\n\n测试套件：\n使用给定的全局容限 $T$ 计算以下积分：\n1. $f_1(x) = x$ 在 $[0,1]$ 上， $T = 10^{-12}$。精确值为 $\\int_0^1 x\\,dx = \\frac{1}{2}$。\n2. $f_2(x) = \\sin(50 x)$ 在 $[0,1]$ 上， $T = 10^{-8}$。角度以弧度为单位。精确值为 $\\int_0^1 \\sin(50x)\\,dx = \\frac{1 - \\cos(50)}{50}$。\n3. $f_3(x) = e^{-x^2}$ 在 $[-2,2]$ 上， $T = 10^{-8}$。精确值为 $\\int_{-2}^{2} e^{-x^2}\\,dx = \\sqrt{\\pi}\\,\\mathrm{erf}(2)$，其中 $\\mathrm{erf}$ 表示误差函数。\n4. $f_4(x) = |x|$ 在 $[-1,1]$ 上， $T = 10^{-10}$。精确值为 $\\int_{-1}^{1} |x|\\,dx = 1$。\n5. $f_5(x) = \\max(0, x - 0.5)$ 在 $[0,1]$ 上， $T = 10^{-12}$。精确值为 $\\int_0^1 \\max(0, x - 0.5)\\,dx = \\frac{1}{8}$。\n\n实现细节：\n- 对所有测试用例使用 $m$ 个均匀子区间；选择足够大的 $m$ 以便在不同被积函数上实现精确的自适应。在您的实现中将 $m$ 设置为一个固定值。\n- 使用 $[-1,1]$ 上的高斯-勒让德节点和权重，并通过 $x = \\frac{x_r - x_\\ell}{2}\\xi + \\frac{x_r + x_\\ell}{2}$ 将它们映射到每个子区间 $[x_\\ell,x_r]$，权重缩放因子为 $\\frac{x_r - x_\\ell}{2}$。\n- 对于每个子区间，从 $n = 2$ 开始，并将其加倍，直到局部误差估计值低于 $T_{\\text{local}}$ 或达到最大阶数。\n- 将每个函数接受的子区间贡献值相加，以生成积分估计值。\n\n要求的最终输出格式：\n您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔的结果列表。结果必须按 $[I_1, I_2, I_3, I_4, I_5]$ 的顺序排列，对应于上述五个测试用例。每个 $I_k$ 必须打印为四舍五入到十位小数的浮点数。例如，一个有效的输出格式是 $[0.5000000000,0.1234567890,0.9876543210,1.0000000000,0.1250000000]$。", "solution": "该问题要求设计并实现一种自适应阶数数值求积算法。该方法的核心是通过划分定义域，并为每个分段动态选择高斯-勒让德求积 (Gauss-Legendre Quadrature, GLQ) 法则的阶数以满足局部误差容限，来近似一个定积分。这种方法是高效的，因为它仅在被积函数表现出复杂行为（如高曲率）的区域分配更多的计算精力（更高阶的法则），而在被积函数平滑或近似线性的区域使用较少的精力（更低阶的法则）。\n\n函数 $f(x)$ 在区间 $[a,b]$ 上的定积分为\n$$\nI = \\int_a^b f(x)\\,dx\n$$\n我们通过首先将区间 $[a,b]$ 划分为 $m$ 个更小的、均匀的子区间 $[x_{j-1}, x_j]$（其中 $j=1, 2, \\dots, m$，$x_j = a + j \\cdot \\Delta$，且每个子区间的宽度为 $\\Delta = (b-a)/m$）来近似此积分。总积分是这些子区间上积分的总和：\n$$\nI = \\sum_{j=1}^{m} \\int_{x_{j-1}}^{x_j} f(x)\\,dx\n$$\n在实现中，我们将选择一个固定的值 $m=100$，这个值足够大，可以解析测试被积函数的特征。\n\n对于每个子区间，我们使用高斯-勒让德求积来近似积分。一个 $n$ 点GLQ法则将函数 $g(\\xi)$ 在规范区间 $[-1,1]$ 上的积分近似为在特定点（称为节点）处的函数值的加权和：\n$$\n\\int_{-1}^1 g(\\xi)\\,d\\xi \\approx \\sum_{i=1}^n w_i g(\\xi_i)\n$$\n这里，$\\xi_i$ 是 $n$ 阶勒让德多项式 $P_n(\\xi)$ 的 $n$ 个根，而 $w_i$ 是相应的权重。此法则对于最高为 $2n-1$ 阶的所有多项式都是精确的。\n\n要将此法则应用于任意子区间 $[x_\\ell, x_r]$，我们使用一个仿射变换，将 $\\xi \\in [-1,1]$ 映射到 $x \\in [x_\\ell, x_r]$：\n$$\nx(\\xi) = \\frac{x_r - x_\\ell}{2}\\xi + \\frac{x_r + x_\\ell}{2}\n$$\n微分元变换为 $dx = \\frac{x_r - x_\\ell}{2} d\\xi$。在 $[x_\\ell, x_r]$ 上的积分变为：\n$$\n\\int_{x_\\ell}^{x_r} f(x)\\,dx = \\frac{x_r - x_\\ell}{2} \\int_{-1}^1 f\\left(\\frac{x_r - x_\\ell}{2}\\xi + \\frac{x_r + x_\\ell}{2}\\right) d\\xi\n$$\n应用 $n$ 点GLQ法则得到近似值：\n$$\nI_n(f; x_\\ell, x_r) = \\frac{x_r - x_\\ell}{2} \\sum_{i=1}^n w_i^{(n)} f\\left(\\frac{x_r - x_\\ell}{2}\\xi_i^{(n)} + \\frac{x_r + x_\\ell}{2}\\right)\n$$\n其中，权重 $w_i^{(n)}$ 和节点 $\\xi_i^{(n)}$ 上的上标明确表示它们对阶数 $n$ 的依赖性。\n\n自适应阶数算法的核心在于每个子区间的误差估计和阶数选择过程。为整个积分 $\\int_a^b f(x)\\,dx$ 提供一个全局误差容限 $T$。此容限被分配到 $m$ 个子区间。我们使用一种简单的分配方式，为每个子区间分配一个局部容限 $T_{\\text{local}} = T \\cdot \\frac{\\Delta}{b-a} = T/m$。\n\n在给定的子区间 $[x_\\ell, x_r]$ 上，算法按以下步骤进行：\n1. 将基础求积阶数 $n$ 初始化为一个较小的值，按规定为 $n=2$。\n2. 计算两个近似值：一个低阶近似 $I_n$ 和一个高阶近似 $I_{2n}$。这些法则在精度上是嵌套的，$I_{2n}$ 通常比 $I_n$ 精确得多。\n3. 将两个结果之间的绝对差作为低阶近似的局部误差估计：$E = |I_{2n} - I_n|$。这个启发式方法基于一个假设，即 $I_{2n}$ 是对真实积分值更好的近似，因此这个差值主要反映了 $I_n$ 的误差。\n4. 将误差估计 $E$ 与局部容限 $T_{\\text{local}}$ 进行比较。\n    - 如果 $E \\le T_{\\text{local}}$，则认为近似足够精确。我们接受更精确的结果 $I_{2n}$ 作为该子区间积分的值，并终止该子区间的处理。\n    - 如果 $E > T_{\\text{local}}$，则误差过大。我们将基础阶数加倍 ($n \\to 2n$) 并从步骤2重复。此过程持续进行，直到满足容限或达到指定的最大基础阶数。在我们的实现中，基础阶数的序列将是 $n \\in \\{2, 4, 8, 16, 32, 64\\}$。最大基础阶数为 $n=64$。如果使用 $(I_{64}, I_{128})$ 对仍未满足容限，我们接受当前可用的最佳估计 $I_{128}$ 作为该子区间的值。\n\n最后，通过将所有 $m$ 个子区间的已接受积分值相加来计算总积分 $I$：\n$$\nI_{\\text{approx}} = \\sum_{j=1}^{m} I^{(j)}\n$$\n其中 $I^{(j)}$ 是第 $j$ 个子区间 $[x_{j-1}, x_j]$ 的已接受积分值。此过程确保了计算资源被自适应地集中在被积函数最难进行数值积分的部分。对于具有奇点或尖锐特征的函数，例如 $f_4(x)=|x|$ 或 $f_5(x)=\\max(0, x-0.5)$，使用 $m=100$ 的固定网格划分可以方便地将不可微点置于子区间的边界上，使得被积函数在每个子区间内部是平滑的，因此非常适合GLQ。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main execution function to run the test suite and print results.\n    \"\"\"\n\n    # Pre-compute Gauss-Legendre nodes and weights to avoid redundant calculations.\n    # The adaptive algorithm uses orders n and 2n.\n    # Base orders n are {2, 4, 8, 16, 32, 64}.\n    # This requires nodes/weights for {2, 4, 8, 16, 32, 64, 128}.\n    gl_orders = [2, 4, 8, 16, 32, 64, 128]\n    gl_cache = {n: np.polynomial.legendre.leggauss(n) for n in gl_orders}\n    \n    # --- Test Suite Definition ---\n    # Each test case is a dictionary containing the integrand, interval, and tolerance.\n    test_cases = [\n        {\n            \"func\": lambda x: x,\n            \"interval\": (0, 1),\n            \"tolerance\": 1e-12\n        },\n        {\n            \"func\": lambda x: np.sin(50 * x),\n            \"interval\": (0, 1),\n            \"tolerance\": 1e-8\n        },\n        {\n            \"func\": lambda x: np.exp(-x**2),\n            \"interval\": (-2, 2),\n            \"tolerance\": 1e-8\n        },\n        {\n            \"func\": lambda x: np.abs(x),\n            \"interval\": (-1, 1),\n            \"tolerance\": 1e-10\n        },\n        {\n            \"func\": lambda x: np.maximum(0, x - 0.5),\n            \"interval\": (0, 1),\n            \"tolerance\": 1e-12\n        }\n    ]\n\n    results = []\n    # Number of uniform subintervals to partition the main interval.\n    m_subintervals = 100\n\n    for case in test_cases:\n        integral_value = adaptive_order_quadrature(\n            f=case[\"func\"],\n            a=case[\"interval\"][0],\n            b=case[\"interval\"][1],\n            T=case[\"tolerance\"],\n            m=m_subintervals,\n            gl_cache=gl_cache\n        )\n        results.append(f\"{integral_value:.10f}\")\n\n    print(f\"[{','.join(results)}]\")\n\n\ndef _apply_gl_quad(f, a, b, n, gl_cache):\n    \"\"\"\n    Applies n-point Gauss-Legendre quadrature for f over [a, b].\n    \"\"\"\n    nodes, weights = gl_cache[n]\n    \n    # Affine transformation from [-1, 1] to [a, b]\n    mapped_nodes = 0.5 * (b - a) * nodes + 0.5 * (b + a)\n    mapped_weights_factor = 0.5 * (b - a)\n    \n    return mapped_weights_factor * np.sum(weights * f(mapped_nodes))\n\ndef _integrate_subinterval(f, xl, xr, T_local, gl_cache):\n    \"\"\"\n    Integrates over a single subinterval [xl, xr] using adaptive order.\n    \"\"\"\n    n = 2  # Initial base order\n    max_base_order = 64\n\n    while n = max_base_order:\n        # Compute low and high order approximations\n        I_n = _apply_gl_quad(f, xl, xr, n, gl_cache)\n        I_2n = _apply_gl_quad(f, xl, xr, 2 * n, gl_cache)\n\n        # Estimate error\n        error_est = np.abs(I_2n - I_n)\n\n        if error_est = T_local:\n            return I_2n  # Accept the higher-order approximation\n\n        # If error is too large, increase order\n        n *= 2\n\n    # If max order is reached and tolerance is not met, return the best estimate.\n    # The last computation was with n = max_base_order, so we return I_2n.\n    return _apply_gl_quad(f, xl, xr, 2 * max_base_order, gl_cache)\n\ndef adaptive_order_quadrature(f, a, b, T, m, gl_cache):\n    \"\"\"\n    Computes the definite integral of f from a to b using an adaptive-order\n    Gauss-Legendre quadrature on a fixed grid of m subintervals.\n\n    Args:\n        f: The integrand function.\n        a: The lower limit of integration.\n        b: The upper limit of integration.\n        T: The global error tolerance.\n        m: The number of uniform subintervals.\n        gl_cache: A dictionary with pre-computed GL nodes and weights.\n\n    Returns:\n        The approximate value of the integral.\n    \"\"\"\n    if a == b:\n        return 0.0\n\n    total_integral = 0.0\n    \n    # Apportion global tolerance across subintervals\n    T_local = T / m\n    \n    # Create the grid of subintervals\n    subinterval_bounds = np.linspace(a, b, m + 1)\n\n    for i in range(m):\n        xl, xr = subinterval_bounds[i], subinterval_bounds[i+1]\n        \n        sub_integral = _integrate_subinterval(f, xl, xr, T_local, gl_cache)\n        total_integral += sub_integral\n        \n    return total_integral\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3203569"}]}