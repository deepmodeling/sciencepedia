{"hands_on_practices": [{"introduction": "要掌握求解非线性方程组的牛顿法，最好的起点是亲手实践其核心迭代步骤。这个练习将复杂的算法分解为一个单一、可控的计算过程，帮助你打下坚实的基础。通过完成这个任务 [@problem_id:2207863]，你将练习计算雅可比矩阵 $\\mathbf{J}$，求解线性系统 $\\mathbf{J}(\\mathbf{x}_k)\\mathbf{s}_k = -\\mathbf{F}(\\mathbf{x}_k)$ 以获得牛顿步长 $\\mathbf{s}_k$，并最终更新你的近似解。", "problem": "考虑以下二元非线性方程组：\n$$\n\\begin{cases}\n2x^2 + y = 11 \\\\\nx + 2y^2 = 10\n\\end{cases}\n$$\n我们希望使用系统牛顿法求该方程组的一个近似解。从初始猜测 $(x_0, y_0) = (3, 1)$ 开始，执行一次迭代以找到下一个近似值 $(x_1, y_1)$。\n\n求 $(x_1, y_1)$ 的坐标。将每个坐标表示为其最简分数形式的有理数。", "solution": "定义向量函数 $\\mathbf{F}(x,y)$ 及其雅可比矩阵 $J(x,y)$ 如下：\n$$\n\\mathbf{F}(x,y)=\\begin{pmatrix} 2x^{2}+y-11 \\\\ x+2y^{2}-10 \\end{pmatrix}, \n\\quad\nJ(x,y)=\\begin{pmatrix} \\frac{\\partial}{\\partial x}(2x^{2}+y-11) & \\frac{\\partial}{\\partial y}(2x^{2}+y-11) \\\\ \\frac{\\partial}{\\partial x}(x+2y^{2}-10) & \\frac{\\partial}{\\partial y}(x+2y^{2}-10) \\end{pmatrix}\n=\\begin{pmatrix} 4x & 1 \\\\ 1 & 4y \\end{pmatrix}.\n$$\n系统牛顿法通过求解以下方程来计算更新量 $\\mathbf{s}=(s_{x},s_{y})^{T}$：\n$$\nJ(x_{0},y_{0})\\,\\mathbf{s}=-\\mathbf{F}(x_{0},y_{0}),\n$$\n然后令 $(x_{1},y_{1})=(x_{0},y_{0})+\\mathbf{s}$。\n\n在点 $(x_{0},y_{0})=(3,1)$ 处，计算：\n$$\n\\mathbf{F}(3,1)=\\begin{pmatrix} 2\\cdot 3^{2}+1-11 \\\\ 3+2\\cdot 1^{2}-10 \\end{pmatrix}\n=\\begin{pmatrix} 8 \\\\ -5 \\end{pmatrix},\n\\quad\nJ(3,1)=\\begin{pmatrix} 4\\cdot 3 & 1 \\\\ 1 & 4\\cdot 1 \\end{pmatrix}\n=\\begin{pmatrix} 12 & 1 \\\\ 1 & 4 \\end{pmatrix}.\n$$\n求解 $\\mathbf{s}$：\n$$\n\\begin{pmatrix} 12 & 1 \\\\ 1 & 4 \\end{pmatrix}\\begin{pmatrix} s_{x} \\\\ s_{y} \\end{pmatrix}\n=-\\begin{pmatrix} 8 \\\\ -5 \\end{pmatrix}\n=\\begin{pmatrix} -8 \\\\ 5 \\end{pmatrix},\n$$\n即线性方程组：\n$$\n\\begin{cases}\n12s_{x}+s_{y}=-8, \\\\\ns_{x}+4s_{y}=5.\n\\end{cases}\n$$\n由 $s_{x}=5-4s_{y}$ 并代入第一个方程，可得：\n$$\n12(5-4s_{y})+s_{y}=-8\n\\;\\Rightarrow\\;\n60-48s_{y}+s_{y}=-8\n\\;\\Rightarrow\\;\n-47s_{y}=-68\n\\;\\Rightarrow\\;\ns_{y}=\\frac{68}{47}.\n$$\n则\n$$\ns_{x}=5-4\\cdot \\frac{68}{47}\n=\\frac{235}{47}-\\frac{272}{47}\n=-\\frac{37}{47}.\n$$\n更新近似值：\n$$\nx_{1}=x_{0}+s_{x}=3-\\frac{37}{47}=\\frac{141}{47}-\\frac{37}{47}=\\frac{104}{47}, \n\\quad\ny_{1}=y_{0}+s_{y}=1+\\frac{68}{47}=\\frac{47}{47}+\\frac{68}{47}=\\frac{115}{47}.\n$$\n因此，下一个牛顿迭代点是 $\\left(\\frac{104}{47}, \\frac{115}{47}\\right)$，两个坐标均为最简有理数形式。", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{104}{47} & \\frac{115}{47}\\end{pmatrix}}$$", "id": "2207863"}, {"introduction": "仅仅掌握计算步骤是不够的，理解牛顿法为何以及何时能够成功收敛同样关键。本练习 [@problem_id:2207871] 引导我们探索一个经典的“失效点”：当初始猜测使得雅可比矩阵奇异或接近奇异时，算法将如何表现。通过这个思辨过程，你将对选择合适的初始值以及诊断收敛问题建立起深刻的直觉。", "problem": "一位工程师的任务是为一个模拟稳态物理系统的非线性方程组寻找数值解。该方程组由以下公式给出：\n$$f_1(x, y) = x^2 - y^2 - 4 = 0$$\n$$f_2(x, y) = xy - 3 = 0$$\n该工程师决定使用针对方程组的牛顿法。该方法的迭代公式为 $\\mathbf{x}_{k+1} = \\mathbf{x}_k - [J(\\mathbf{x}_k)]^{-1} \\mathbf{F}(\\mathbf{x}_k)$，其中 $\\mathbf{x} = (x, y)^T$，$\\mathbf{F} = (f_1, f_2)^T$，而 $J(\\mathbf{x})$ 是 $\\mathbf{F}$ 的雅可比矩阵。\n\n经过一些尝试，工程师观察到，对于这个特定系统，选择位于 x 轴（$y_0 = 0$）或 y 轴（$x_0 = 0$）上的初始猜测值 $\\mathbf{x}_0 = (x_0, y_0)$ 是一个糟糕的策略。以下哪个陈述为这种糟糕表现提供了最准确和最根本的原因？\n\nA. 对于轴上的任何初始猜测，牛顿法的第一步迭代产生的点也位于轴上，从而阻止算法向解移动，因为解并不在轴上。\nB. 对于轴上的任何初始猜测，函数向量 $\\mathbf{F}(\\mathbf{x}_0)$ 是一个零向量，这会错误地向算法发出已找到解的信号。\nC. 对于 x 轴或 y 轴上的任何点，雅可比矩阵都是奇异的，导致该方法因无法计算矩阵的逆而立即失败。\nD. 点 $(0,0)$ 是雅可比矩阵奇异的唯一位置。在轴上选择接近原点的初始猜测会导致雅可比矩阵接近奇异，从而使得后续迭代产生的点离真实解非常远，表现出糟糕的收敛行为。\nE. 该方程组没有实数解，因此无论初始猜测如何，牛顿法都将无法收敛。", "solution": "我们给定的系统是\n$$\nf_{1}(x,y)=x^{2}-y^{2}-4,\\qquad f_{2}(x,y)=xy-3,\n$$\n其向量函数为 $\\mathbf{F}(x,y)=(f_{1}(x,y),f_{2}(x,y))^{T}$，雅可比矩阵为\n$$\nJ(x,y)=\\begin{pmatrix}\n\\frac{\\partial f_{1}}{\\partial x} & \\frac{\\partial f_{1}}{\\partial y}\\\\\n\\frac{\\partial f_{2}}{\\partial x} & \\frac{\\partial f_{2}}{\\partial y}\n\\end{pmatrix}\n=\\begin{pmatrix}\n2x & -2y\\\\\ny & x\n\\end{pmatrix}.\n$$\n牛顿法的更新公式为 $\\mathbf{x}_{k+1}=\\mathbf{x}_{k}-J(\\mathbf{x}_{k})^{-1}\\mathbf{F}(\\mathbf{x}_{k})$，这要求 $J$ 在迭代点上是可逆的。\n\n首先，计算雅可比矩阵的行列式：\n$$\n\\det J(x,y)=(2x)(x)-(-2y)(y)=2x^{2}+2y^{2}=2(x^{2}+y^{2}).\n$$\n因此，$J(x,y)$ 是奇异的当且仅当 $(x,y)=(0,0)$。特别地，$J$ 在坐标轴上的一般点（原点除外）不是奇异的。这立即表明选项 C 是错误的。\n\n接下来，在坐标轴上计算 $\\mathbf{F}$。在 x 轴上，$y=0$ 时，\n$$\n\\mathbf{F}(x,0)=\\bigl(x^{2}-4,\\,-3\\bigr),\n$$\n它永远不是零向量。在 y 轴上，$x=0$ 时，\n$$\n\\mathbf{F}(0,y)=\\bigl(-y^{2}-4,\\,-3\\bigr),\n$$\n它也永远不是零向量。因此选项 B 是错误的。\n\n现在检查牛顿法在一次迭代后是否仍停留在坐标轴上。使用由 $J\\mathbf{s}=-\\mathbf{F}$ 定义的牛顿步长 $\\mathbf{s}$。在 x 轴上（$y=0$），我们有\n$$\nJ(x,0)=\\begin{pmatrix}2x & 0\\\\ 0 & x\\end{pmatrix},\\qquad \\mathbf{F}(x,0)=\\begin{pmatrix}x^{2}-4\\\\ -3\\end{pmatrix}.\n$$\n那么\n$$\n\\mathbf{s}=-J^{-1}\\mathbf{F}=-\\begin{pmatrix}\\frac{1}{2x} & 0\\\\ 0 & \\frac{1}{x}\\end{pmatrix}\\begin{pmatrix}x^{2}-4\\\\ -3\\end{pmatrix}\n=\\begin{pmatrix}-\\frac{x^{2}-4}{2x}\\\\ \\frac{3}{x}\\end{pmatrix},\n$$\n所以下一个迭代点是\n$$\nx_{1}=x-\\frac{x^{2}-4}{2x}=\\frac{x}{2}+\\frac{2}{x},\\qquad y_{1}=0+\\frac{3}{x}=\\frac{3}{x}.\n$$\n由于对于任何有限的 $x$，$y_{1}=\\frac{3}{x}\\neq 0$，迭代点立即离开坐标轴。在 y 轴上（$x=0$）进行类似的计算，求解\n$$\n\\begin{pmatrix}0 & -2y\\\\ y & 0\\end{pmatrix}\\begin{pmatrix}s_{x}\\\\ s_{y}\\end{pmatrix}=-\\begin{pmatrix}-y^{2}-4\\\\ -3\\end{pmatrix}=\\begin{pmatrix}y^{2}+4\\\\ 3\\end{pmatrix},\n$$\n得到 $s_{x}=\\frac{3}{y}$ 和 $s_{y}=-\\frac{y^{2}+4}{2y}$，所以\n$$\nx_{1}=0+\\frac{3}{y}=\\frac{3}{y},\\qquad y_{1}=y-\\frac{y^{2}+4}{2y}=\\frac{y}{2}-\\frac{2}{y}.\n$$\n同样，迭代点立即离开坐标轴。因此选项 A 是错误的。\n\n为了排除选项 E，我们检查是否存在实数解。从 $xy=3$ 我们得到 $y=\\frac{3}{x}$，代入 $x^{2}-y^{2}=4$ 得\n$$\nx^{2}-\\frac{9}{x^{2}}=4\\;\\;\\Longrightarrow\\;\\; x^{4}-4x^{2}-9=0.\n$$\n令 $t=x^{2}$。则 $t^{2}-4t-9=0$，所以 $t=2\\pm\\sqrt{13}$。可接受的根是 $t=2+\\sqrt{13}>0$，因此\n$$\nx=\\pm\\sqrt{2+\\sqrt{13}},\\qquad y=\\frac{3}{x}=\\pm\\frac{3}{\\sqrt{2+\\sqrt{13}}},\n$$\n这表明存在两个实数解。因此选项 E 是错误的。\n\n剩下的就是找出为什么坐标轴是初始猜测的糟糕选择的根本原因。由于\n$$\n\\det J(x,y)=2(x^{2}+y^{2}),\n$$\n雅可比矩阵在 $(0,0)$ 处是奇异的，并且当 $(x,y)$ 接近原点时会变得病态。其显式逆矩阵为\n$$\nJ(x,y)^{-1}=\\frac{1}{2(x^{2}+y^{2})}\\begin{pmatrix}x & 2y\\\\ -y & 2x\\end{pmatrix},\n$$\n其元素与 $\\frac{1}{x^{2}+y^{2}}$ 乘以 $x$ 和 $y$ 的线性函数成比例。在原点附近，这会产生很大的牛顿步长。特别是在坐标轴上，上面推导出的牛顿更新项包含诸如 $\\frac{3}{x}$ 或 $\\frac{3}{y}$ 的项，当初始猜测位于坐标轴上且接近原点时，这些项的绝对值会变得非常大。这种病态性质解释了观察到的糟糕表现，并被选项 D 精确地描述。\n\n因此，最准确和最根本的原因是，雅可比矩阵在原点是奇异的，对于靠近原点的坐标轴对齐的初始猜测是接近奇异的，这导致了不稳定性和糟糕的收敛性。", "answer": "$$\\boxed{D}$$", "id": "2207871"}, {"introduction": "在真实的科研和工程问题中，我们往往无法轻易得到雅可比矩阵的解析表达式。本练习 [@problem_id:2441924] 将带你从理论走向实践，学习如何使用有限差分来近似雅可比矩阵，这是一种强大的“拟牛顿法”。通过编程实现并比较精确雅可比与近似雅可比两种方法的表现，你将直观地理解在牺牲二次收敛速度与获得巨大便利性之间的重要权衡。", "problem": "考虑由向量值函数 $\\mathbf{F}:\\mathbb{R}^2\\to\\mathbb{R}^2$ 定义的非线性方程组，该函数由下式给出\n$$\n\\mathbf{F}(\\mathbf{x})=\n\\begin{bmatrix}\nf_1(x_1,x_2)\\\\\nf_2(x_1,x_2)\n\\end{bmatrix}\n=\n\\begin{bmatrix}\nx_1-\\cos(x_2)\\\\\nx_2-\\sin(x_1)\n\\end{bmatrix},\n$$\n其中 $\\mathbf{x}=\\begin{bmatrix}x_1\\\\x_2\\end{bmatrix}$，且三角函数使用以弧度为单位的角度。$\\mathbf{F}$ 的精确雅可比矩阵 $\\mathbf{J}(\\mathbf{x})$ 为\n$$\n\\mathbf{J}(\\mathbf{x})=\n\\begin{bmatrix}\n\\dfrac{\\partial f_1}{\\partial x_1} & \\dfrac{\\partial f_1}{\\partial x_2}\\\\\n\\dfrac{\\partial f_2}{\\partial x_1} & \\dfrac{\\partial f_2}{\\partial x_2}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1 & \\sin(x_2)\\\\\n-\\cos(x_1) & 1\n\\end{bmatrix}.\n$$\n\n对于给定的扰动大小 $h>0$，定义前向有限差分雅可比近似 $\\mathbf{J}_h(\\mathbf{x})$ 为\n$$\n\\mathbf{J}_h(\\mathbf{x})=\\begin{bmatrix}\n\\displaystyle\\frac{f_1(\\mathbf{x}+h\\,\\mathbf{e}_1)-f_1(\\mathbf{x})}{h} & \\displaystyle\\frac{f_1(\\mathbf{x}+h\\,\\mathbf{e}_2)-f_1(\\mathbf{x})}{h}\\\\\n\\displaystyle\\frac{f_2(\\mathbf{x}+h\\,\\mathbf{e}_1)-f_2(\\mathbf{x})}{h} & \\displaystyle\\frac{f_2(\\mathbf{x}+h\\,\\mathbf{e}_2)-f_2(\\mathbf{x})}{h}\n\\end{bmatrix},\n$$\n其中 $\\mathbf{e}_1=\\begin{bmatrix}1\\\\0\\end{bmatrix}$ 且 $\\mathbf{e}_2=\\begin{bmatrix}0\\\\1\\end{bmatrix}$。\n\n对于初始猜测值 $\\mathbf{x}^{(0)}\\in\\mathbb{R}^2$，递归定义序列 $\\{\\mathbf{x}^{(k)}\\}_{k\\ge 0}$ 如下\n$$\n\\mathbf{J}_\\star\\big(\\mathbf{x}^{(k)}\\big)\\,\\mathbf{s}^{(k)}=-\\mathbf{F}\\big(\\mathbf{x}^{(k)}\\big),\\qquad \\mathbf{x}^{(k+1)}=\\mathbf{x}^{(k)}+\\mathbf{s}^{(k)},\n$$\n其中 $\\mathbf{J}_\\star$ 表示精确雅可比矩阵 $\\mathbf{J}$ 或有限差分雅可比矩阵 $\\mathbf{J}_h$，更新量 $\\mathbf{s}^{(k)}$ 是该线性系统的任意解。令残差范数为 $\\|\\mathbf{F}(\\mathbf{x}^{(k)})\\|_2$，当满足 $\\|\\mathbf{F}(\\mathbf{x}^{(k)})\\|_2 \\le \\varepsilon$ 的最小索引 $k$ 出现时，迭代终止，其中容差 $\\varepsilon=10^{-10}$；或者在 $k_{\\max}=50$ 次迭代后终止，以先发生者为准。\n\n对于下方的每个测试用例，从给定的初始猜测值 $\\mathbf{x}^{(0)}$ 开始执行两次运行：\n- 运行 A 使用 $\\mathbf{J}_\\star=\\mathbf{J}$。\n- 运行 B 使用 $\\mathbf{J}_\\star=\\mathbf{J}_h$ 及指定的 $h$。\n\n对于每次运行，记录：\n- 满足 $\\|\\mathbf{F}(\\mathbf{x}^{(n)})\\|_2 \\le \\varepsilon$ 所需的迭代次数 $n$（如果未达到容差，则 $n=k_{\\max}$）。\n- 通过最后三个可用的残差范数 $\\{e_{m-2},e_{m-1},e_m\\}$ 计算的局部收敛阶估计值 $\\hat{p}$\n$$\n\\hat{p}=\\frac{\\ln\\left(\\dfrac{e_m}{e_{m-1}}\\right)}{\\ln\\left(\\dfrac{e_{m-1}}{e_{m-2}}\\right)},\n$$\n其中 $e_j=\\|\\mathbf{F}(\\mathbf{x}^{(j)})\\|_2$，且 $m$ 是运行中使用的最终迭代索引（使用终止时可用的最后三个残差；所有对数均为自然对数）。三角函数中的所有角度均以弧度为单位。\n\n使用以下测试套件，其中每个用例都是一对 $(\\mathbf{x}^{(0)},h)$：\n- 用例 1：$\\mathbf{x}^{(0)}=\\begin{bmatrix}0.5\\\\0.5\\end{bmatrix}$, $h=10^{-6}$。\n- 用例 2：$\\mathbf{x}^{(0)}=\\begin{bmatrix}0.5\\\\0.5\\end{bmatrix}$, $h=10^{-3}$。\n- 用例 3：$\\mathbf{x}^{(0)}=\\begin{bmatrix}1.0\\\\1.0\\end{bmatrix}$, $h=10^{-6}$。\n- 用例 4：$\\mathbf{x}^{(0)}=\\begin{bmatrix}1.0\\\\1.0\\end{bmatrix}$, $h=10^{-2}$。\n\n您的程序必须输出单行，其中包含一个结果列表，每个测试用例一个结果，并按所列顺序排列。每个测试用例的结果必须是一个包含四个条目的列表 $[n_{\\text{exact}},n_{\\text{fd}},\\hat{p}_{\\text{exact}},\\hat{p}_{\\text{fd}}]$，其中 $n_{\\text{exact}}$ 和 $\\hat{p}_{\\text{exact}}$ 对应于运行 A，$n_{\\text{fd}}$ 和 $\\hat{p}_{\\text{fd}}$ 对应于运行 B。最终输出格式必须是单行，形式为由方括号括起来的、以逗号分隔的各用例列表，例如 $[[a_1,a_2,a_3,a_4],[b_1,b_2,b_3,b_4],\\dots]$。", "solution": "此问题已经过验证。\n\n### 步骤 1：提取已知条件\n- **非线性系统**：定义函数 $\\mathbf{F}:\\mathbb{R}^2\\to\\mathbb{R}^2$ 为 $\\mathbf{F}(\\mathbf{x})= \\begin{bmatrix} f_1(x_1,x_2)\\\\ f_2(x_1,x_2) \\end{bmatrix} = \\begin{bmatrix} x_1-\\cos(x_2)\\\\ x_2-\\sin(x_1) \\end{bmatrix}$，对于 $\\mathbf{x}=\\begin{bmatrix}x_1\\\\x_2\\end{bmatrix}$。三角函数使用弧度。\n- **精确雅可比矩阵**：$\\mathbf{F}$ 的雅可比矩阵由 $\\mathbf{J}(\\mathbf{x}) = \\begin{bmatrix} 1 & \\sin(x_2)\\\\ -\\cos(x_1) & 1 \\end{bmatrix}$ 给出。\n- **有限差分雅可比矩阵**：对于扰动 $h>0$，通过其列向量定义近似 $\\mathbf{J}_h(\\mathbf{x})$：第 $j$ 列是 $\\frac{\\mathbf{F}(\\mathbf{x}+h\\,\\mathbf{e}_j)-\\mathbf{F}(\\mathbf{x})}{h}$，其中 $\\mathbf{e}_j$ 是标准基向量。\n- **迭代方案**：从初始猜测值 $\\mathbf{x}^{(0)}$ 开始，通过求解 $\\mathbf{J}_\\star\\big(\\mathbf{x}^{(k)}\\big)\\,\\mathbf{s}^{(k)}=-\\mathbf{F}\\big(\\mathbf{x}^{(k)}\\big)$ 并设置 $\\mathbf{x}^{(k+1)}=\\mathbf{x}^{(k)}+\\mathbf{s}^{(k)}$ 来生成序列 $\\{\\mathbf{x}^{(k)}\\}_{k\\ge 0}$。此处，$\\mathbf{J}_\\star$ 是精确雅可比矩阵 $\\mathbf{J}$ 或近似 $\\mathbf{J}_h$。\n- **终止准则**：迭代在残差范数 $\\|\\mathbf{F}(\\mathbf{x}^{(k)})\\|_2 \\le \\varepsilon = 10^{-10}$ 的最小索引 $k$ 处停止，或在 $k_{\\max}=50$ 次迭代后停止。\n- **任务**：对每个测试用例，执行两次运行：运行 A 使用 $\\mathbf{J}_\\star=\\mathbf{J}$，运行 B 使用 $\\mathbf{J}_\\star=\\mathbf{J}_h$。对每次运行，需记录两个量：\n    1. 迭代次数 $n$。\n    2. 收敛阶的估计值 $\\hat{p}=\\frac{\\ln(e_m/e_{m-1})}{\\ln(e_{m-1}/e_{m-2})}$，其中 $e_j=\\|\\mathbf{F}(\\mathbf{x}^{(j)})\\|_2$ 且 $m$ 是最终迭代索引。\n- **测试用例**：\n    - 用例 1：$\\mathbf{x}^{(0)}=\\begin{bmatrix}0.5\\\\0.5\\end{bmatrix}$, $h=10^{-6}$。\n    - 用例 2：$\\mathbf{x}^{(0)}=\\begin{bmatrix}0.5\\\\0.5\\end{bmatrix}$, $h=10^{-3}$。\n    - 用例 3：$\\mathbf{x}^{(0)}=\\begin{bmatrix}1.0\\\\1.0\\end{bmatrix}$, $h=10^{-6}$。\n    - 用例 4：$\\mathbf{x}^{(0)}=\\begin{bmatrix}1.0\\\\1.0\\end{bmatrix}$, $h=10^{-2}$。\n- **输出格式**：一个单行的列表之列表：$[[n_{\\text{exact}},n_{\\text{fd}},\\hat{p}_{\\text{exact}},\\hat{p}_{\\text{fd}}], \\dots]$。\n\n### 步骤 2：使用提取的已知条件进行验证\n评估问题的有效性。\n- **科学依据**：该问题是数值分析中的一个标准练习，特别是在求解非线性方程组的计算方法领域。Newton 法及其拟 Newton 变体（使用有限差分雅可比矩阵）是基础且成熟的算法。数学公式是正确的。\n- **适定性**：问题定义清晰。函数、雅可比矩阵、迭代方案、终止条件和所需输出都已明确规定。给定的方程组在相关域内有唯一解，并且雅可比矩阵在该解附近非奇异，确保了待求解的线性系统是适定的。例如，雅可比矩阵的行列式为 $\\det(\\mathbf{J}) = 1 + \\cos(x_1)\\sin(x_2)$。对于像 $(0.5, 0.5)$ 或 $(1.0, 1.0)$ 这样的初始猜测值，行列式远不为零，这表明局部收敛是可以实现的。\n- **客观性**：语言正式、客观，不含主观或非科学内容。\n\n该问题没有表现出任何科学上不健全、不完整、矛盾或模棱两可的缺陷。$\\hat{p}$ 的计算至少需要三个残差范数，对应于至少两次迭代（$n\\ge 2$）。鉴于初始条件和 Newton 法的性质，这是一个合理的期望。\n\n### 步骤 3：结论与行动\n此问题是 **有效的**。将提供一个解法。\n\n---\n\n该问题要求实现 Newton 法的两种变体来求解非线性系统 $\\mathbf{F}(\\mathbf{x}) = \\mathbf{0}$。第一种变体是经典的 Newton-Raphson 方法，它使用 $\\mathbf{F}$ 的精确解析雅可比矩阵。第二种是拟 Newton 方法，其中雅可比矩阵使用前向有限差分格式进行近似。我们将比较这两种方法在收敛所需的迭代次数和估计的局部收敛阶方面的性能。\n\n该方法的核心是迭代更新规则。在每一步 $k$，我们用当前迭代点 $\\mathbf{x}^{(k)}$ 附近的线性泰勒展开来近似非线性函数 $\\mathbf{F}$：\n$$\n\\mathbf{F}(\\mathbf{x}) \\approx \\mathbf{F}(\\mathbf{x}^{(k)}) + \\mathbf{J}_\\star(\\mathbf{x}^{(k)})(\\mathbf{x} - \\mathbf{x}^{(k)})\n$$\n我们通过将此近似值设为零来寻找下一个迭代点 $\\mathbf{x}^{(k+1)}$，即 $\\mathbf{F}(\\mathbf{x}^{(k+1)}) = \\mathbf{0}$。将更新步长定义为 $\\mathbf{s}^{(k)} = \\mathbf{x}^{(k+1)} - \\mathbf{x}^{(k)}$，我们得到用于更新的线性系统：\n$$\n\\mathbf{J}_\\star(\\mathbf{x}^{(k)}) \\mathbf{s}^{(k)} = -\\mathbf{F}(\\mathbf{x}^{(k)})\n$$\n一旦通过求解该系统找到 $\\mathbf{s}^{(k)}$，下一个迭代点就计算为 $\\mathbf{x}^{(k+1)} = \\mathbf{x}^{(k)} + \\mathbf{s}^{(k)}$。重复此过程，直到残差向量的范数 $\\|\\mathbf{F}(\\mathbf{x}^{(k)})\\|_2$ 低于指定的容差 $\\varepsilon = 10^{-10}$。\n\n**运行 A：精确雅可比矩阵 (Newton-Raphson Method)**\n在此运行中，$\\mathbf{J}_\\star$ 是精确的雅可比矩阵 $\\mathbf{J}(\\mathbf{x})$：\n$$\n\\mathbf{J}(\\mathbf{x}) =\n\\begin{bmatrix}\n1 & \\sin(x_2)\\\\\n-\\cos(x_1) & 1\n\\end{bmatrix}\n$$\n已知当初始猜测值足够接近解且雅可比矩阵在解处非奇异时，该方法表现出二次收敛性（即收敛阶 $p=2$）。这意味着解的正确位数在每次迭代中大致翻倍。因此，估计的阶 $\\hat{p}$ 应接近于 2。\n\n**运行 B：有限差分雅可比矩阵 (Quasi-Newton Method)**\n在此运行中，雅可比矩阵使用前向有限差分公式进行近似。近似雅可比矩阵 $\\mathbf{J}_h(\\mathbf{x})$ 的第 $j$ 列由下式给出：\n$$\n[\\mathbf{J}_h(\\mathbf{x})]_{:,j} = \\frac{\\mathbf{F}(\\mathbf{x} + h\\mathbf{e}_j) - \\mathbf{F}(\\mathbf{x})}{h}\n$$\n其中 $\\mathbf{e}_j$ 是第 $j$ 个标准基向量，$h$ 是一个小扰动参数。对于给定的 $2 \\times 2$ 系统，这得到：\n$$\n\\mathbf{J}_h(\\mathbf{x}) = \\begin{bmatrix}\n\\frac{f_1(x_1+h, x_2) - f_1(x_1, x_2)}{h} & \\frac{f_1(x_1, x_2+h) - f_1(x_1, x_2)}{h} \\\\\n\\frac{f_2(x_1+h, x_2) - f_2(x_1, x_2)}{h} & \\frac{f_2(x_1, x_2+h) - f_2(x_1, x_2)}{h}\n\\end{bmatrix}\n$$\n这种方法避免了对雅可比矩阵进行解析推导的需要，对于某些函数而言，这可能很复杂或不可能。然而，它引入了近似误差。$\\mathbf{J}_h$ 中每个元素的误差约为 $O(h)$。此误差会扰动 Newton 步长，影响收敛速度。对于非常小的 $h$（例如，$10^{-6}$），近似是准确的，收敛应接近二次。随着 $h$ 的增大（例如，$10^{-3}$ 或 $10^{-2}$），近似变差，预计收敛速度会下降，可能变为线性（$p=1$），并需要更多迭代。\n\n**算法与实现**\n对于每个测试用例 $(\\mathbf{x}^{(0)}, h)$，我们为运行 A 和运行 B 执行以下步骤：\n1. 初始化 $k=0$ 和当前解 $\\mathbf{x} = \\mathbf{x}^{(0)}$。创建一个列表来存储残差范数。\n2. 开始一个循环，只要 $k \\le k_{\\max} = 50$ 就继续。\n3. 计算残差向量 $\\mathbf{F}(\\mathbf{x})$ 及其欧几里得范数 $e_k = \\|\\mathbf{F}(\\mathbf{x})\\|_2$。存储 $e_k$。\n4. 检查终止条件：如果 $e_k \\le \\varepsilon=10^{-10}$，设置最终迭代次数 $n=k$ 并退出循环。\n5. 如果循环继续（即 $k  k_{\\max}$），计算适当的雅可比矩阵 $\\mathbf{J}_\\star(\\mathbf{x})$（精确的或有限差分的）。\n6. 求解线性系统 $\\mathbf{J}_\\star(\\mathbf{x})\\mathbf{s} = -\\mathbf{F}(\\mathbf{x})$ 以获得步长 $\\mathbf{s}$。\n7. 更新解：$\\mathbf{x} \\leftarrow \\mathbf{x} + \\mathbf{s}$。\n8. 增加迭代计数器：$k \\leftarrow k+1$。\n9. 如果循环因 $k$ 达到 $k_{\\max}$ 而完成，则设置 $n=k_{\\max}$。\n10. 循环终止后，使用最后三个可用的残差范数 $e_{n-2}, e_{n-1}, e_{n}$ 计算估计的收敛阶 $\\hat{p}$。如果可用的范数少于三个（即 $n2$），则认为 $\\hat{p}$ 不可计算。\n将两次运行的结果 $(n, \\hat{p})$ 收集起来，为每个测试用例形成最终输出。此过程将在实际计算环境中展示 Newton 族方法的理论特性。", "answer": "```python\nimport numpy as np\n\n# Global constants as specified in the problem\nTOLERANCE = 1e-10\nK_MAX = 50\n\ndef F(x):\n    \"\"\"\n    Computes the vector-valued function F(x).\n    x must be a NumPy array [x1, x2].\n    \"\"\"\n    return np.array([\n        x[0] - np.cos(x[1]),\n        x[1] - np.sin(x[0])\n    ])\n\ndef J_exact(x):\n    \"\"\"\n    Computes the exact Jacobian matrix J(x).\n    x must be a NumPy array [x1, x2].\n    \"\"\"\n    return np.array([\n        [1.0, np.sin(x[1])],\n        [-np.cos(x[0]), 1.0]\n    ])\n\ndef J_fd(x, h):\n    \"\"\"\n    Computes the forward finite-difference approximation of the Jacobian.\n    x must be a NumPy array [x1, x2].\n    h is the perturbation size.\n    \"\"\"\n    n = len(x)\n    jac = np.zeros((n, n), dtype=float)\n    fx = F(x)\n    for j in range(n):\n        x_plus_h = x.copy()\n        x_plus_h[j] += h\n        fx_plus_h = F(x_plus_h)\n        jac[:, j] = (fx_plus_h - fx) / h\n    return jac\n\ndef newton_solver(x0, h, use_exact_jacobian):\n    \"\"\"\n    Solves the nonlinear system F(x)=0 using a Newton-like method.\n    \n    Args:\n        x0 (list or np.ndarray): The initial guess.\n        h (float): The perturbation size for the finite-difference Jacobian.\n        use_exact_jacobian (bool): If True, use the exact Jacobian. \n                                  If False, use the finite-difference approximation.\n\n    Returns:\n        tuple: (n_iter, p_hat) where n_iter is the number of iterations and\n               p_hat is the estimated convergence order.\n    \"\"\"\n    x = np.array(x0, dtype=float)\n    k = 0\n    residuals = []\n    n_iter = K_MAX\n\n    while k = K_MAX:\n        F_val = F(x)\n        norm = np.linalg.norm(F_val)\n        residuals.append(norm)\n\n        if norm = TOLERANCE:\n            n_iter = k\n            break\n        \n        if k == K_MAX:\n            break\n\n        if use_exact_jacobian:\n            Jacobian = J_exact(x)\n        else:\n            Jacobian = J_fd(x, h)\n\n        try:\n            # Solve the linear system J*s = -F\n            s = np.linalg.solve(Jacobian, -F_val)\n            x += s\n        except np.linalg.LinAlgError:\n            # If Jacobian is singular, the solver fails.\n            n_iter = K_MAX\n            break\n        \n        k += 1\n    \n    # Estimate convergence order p_hat from the last three residuals\n    p_hat = np.nan\n    if len(residuals) >= 3:\n        # Use residuals e_n, e_{n-1}, e_{n-2}\n        e_m, e_m1, e_m2 = residuals[-1], residuals[-2], residuals[-3]\n        \n        # Avoid division by zero or log of non-positive numbers.\n        # Ratios must be  1 for convergence.\n        ratio1 = e_m / e_m1 if e_m1 != 0 else 0\n        ratio2 = e_m1 / e_m2 if e_m2 != 0 else 0\n\n        if 0  ratio1  1 and 0  ratio2  1:\n            p_hat = np.log(ratio1) / np.log(ratio2)\n            \n    return n_iter, p_hat\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = [\n        ([0.5, 0.5], 1e-6),\n        ([0.5, 0.5], 1e-3),\n        ([1.0, 1.0], 1e-6),\n        ([1.0, 1.0], 1e-2)\n    ]\n\n    all_results = []\n    for x0, h in test_cases:\n        # Run A: Exact Jacobian\n        n_exact, p_exact = newton_solver(x0, h, use_exact_jacobian=True)\n        \n        # Run B: Finite-Difference Jacobian\n        n_fd, p_fd = newton_solver(x0, h, use_exact_jacobian=False)\n        \n        # Assemble results for the current test case\n        case_result = [n_exact, n_fd, p_exact, p_fd]\n        all_results.append(case_result)\n\n    # The final print statement must match the format exactly.\n    # The default string representation of a list of lists is \"[...], [...]\"\n    # and the default representation of a float is what we need.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\n# Execute the main function\nsolve()\n```", "id": "2441924"}]}