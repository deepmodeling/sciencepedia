{"hands_on_practices": [{"introduction": "要掌握共轭梯度法，我们首先必须理解其基本步骤。第一个练习将引导你完成一个完整的初始迭代，从一个初始猜测点开始。你将计算梯度、确定搜索方向、找到最优步长，并计算出新的、更优的位置，从而巩固你对该算法核心机制的理解。", "problem": "在数值优化中，共轭梯度法是一种用于寻找函数局部最小值的迭代算法。对于二次函数，它可以在有限步内找到精确的最小值。\n\n考虑一个包含两个变量 $x_1$ 和 $x_2$ 的二次目标函数 $f(x)$，其中 $x = [x_1, x_2]^T$：\n$$\nf(x_1, x_2) = (x_1 - 2)^2 + 2(x_2 - 1)^2\n$$\n从初始点 $x_0 = [0, 0]^T$ 开始，执行一次完整的共轭梯度算法迭代。这包括计算初始搜索方向，找到最优步长，并更新位置以找到下一个点 $x_1$。\n\n确定点 $x_1$ 的坐标。将 $x_1$ 的答案表示为一个具有精确分数分量的列向量。", "solution": "我们使用共轭梯度法，从 $x_{0} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$ 开始，最小化二次函数 $f(x) = (x_{1}-2)^{2} + 2(x_{2}-1)^{2}$。其梯度和Hessian矩阵为\n$$\n\\nabla f(x) = \\begin{pmatrix} 2(x_{1}-2) \\\\ 4(x_{2}-1) \\end{pmatrix}, \\quad H = \\begin{pmatrix} 2 & 0 \\\\ 0 & 4 \\end{pmatrix}.\n$$\n在 $x_{0}$ 处，梯度为\n$$\ng_{0} = \\nabla f(x_{0}) = \\begin{pmatrix} -4 \\\\ -4 \\end{pmatrix}.\n$$\n共轭梯度法的初始搜索方向是最速下降方向\n$$\nd_{0} = -g_{0} = \\begin{pmatrix} 4 \\\\ 4 \\end{pmatrix}.\n$$\n沿着 $d_{0}$ 进行精确线搜索，定义 $\\phi(\\alpha) = f(x_{0} + \\alpha d_{0})$。对于具有常数Hessian矩阵的二次函数，其导数为\n$$\n\\phi'(\\alpha) = d_{0}^{T}\\left(g_{0} + \\alpha H d_{0}\\right).\n$$\n令 $\\phi'(\\alpha) = 0$ 可得\n$$\nd_{0}^{T} g_{0} + \\alpha_{0}\\, d_{0}^{T} H d_{0} = 0 \\quad \\Longrightarrow \\quad \\alpha_{0} = -\\frac{d_{0}^{T} g_{0}}{d_{0}^{T} H d_{0}}.\n$$\n计算所需的量：\n$$\nd_{0}^{T} g_{0} = \\begin{pmatrix} 4 & 4 \\end{pmatrix} \\begin{pmatrix} -4 \\\\ -4 \\end{pmatrix} = -32, \\quad H d_{0} = \\begin{pmatrix} 2 & 0 \\\\ 0 & 4 \\end{pmatrix} \\begin{pmatrix} 4 \\\\ 4 \\end{pmatrix} = \\begin{pmatrix} 8 \\\\ 16 \\end{pmatrix},\n$$\n$$\nd_{0}^{T} H d_{0} = \\begin{pmatrix} 4 & 4 \\end{pmatrix} \\begin{pmatrix} 8 \\\\ 16 \\end{pmatrix} = 96.\n$$\n因此，\n$$\n\\alpha_{0} = -\\frac{-32}{96} = \\frac{1}{3}.\n$$\n更新以获得 $x_{1}$：\n$$\nx_{1} = x_{0} + \\alpha_{0} d_{0} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} + \\frac{1}{3} \\begin{pmatrix} 4 \\\\ 4 \\end{pmatrix} = \\begin{pmatrix} \\frac{4}{3} \\\\ \\frac{4}{3} \\end{pmatrix}.\n$$\n因此，经过一次迭代后，下一个点是如上所示的具有精确分数分量的列向量。", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{4}{3} \\\\ \\frac{4}{3} \\end{pmatrix}}$$", "id": "2211319"}, {"introduction": "搜索方向的“共轭”特性是共轭梯度法强大和高效的根源。这个练习提供了一个动手验证这一关键属性的机会。通过明确计算前两个搜索方向并证明它们相对于黑塞矩阵 $A$ 是共轭的，你将对该算法的几何基础有更深刻的认识。", "problem": "考虑最小化二维二次函数 $f(\\mathbf{x})$ 的无约束优化问题，其中 $\\mathbf{x} = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}$。该函数定义为 $f(\\mathbf{x}) = \\frac{1}{2}\\mathbf{x}^T A \\mathbf{x} - \\mathbf{b}^T \\mathbf{x}$，其中对称正定矩阵 $A$ 和向量 $\\mathbf{b}$ 由下式给出：\n$$\nA = \\begin{pmatrix} 5 & 2 \\\\ 2 & 1 \\end{pmatrix}, \\quad \\mathbf{b} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\n$$\n我们将使用共轭梯度（CG）法的 Fletcher-Reeves 变体来寻找该函数的最小值。该函数的梯度为 $\\nabla f(\\mathbf{x}) = A\\mathbf{x} - \\mathbf{b}$。从点 $\\mathbf{x}_k$ 开始，CG 方法的迭代步骤如下：\n\n1.  令 $g_k = \\nabla f(\\mathbf{x}_k)$ 为当前点的梯度。\n2.  搜索方向 $\\mathbf{p}_k$ 由以下规则确定：\n    -   对于第一次迭代（$k=0$）：$\\mathbf{p}_0 = -g_0$。\n    -   对于后续迭代（$k > 0$）：$\\mathbf{p}_k = -g_k + \\beta_k \\mathbf{p}_{k-1}$，其中 $\\beta_k = \\frac{g_k^T g_k}{g_{k-1}^T g_{k-1}}$。\n3.  步长 $\\alpha_k$ 计算为 $\\alpha_k = \\frac{g_k^T g_k}{\\mathbf{p}_k^T A \\mathbf{p}_k}$。\n4.  位置更新为 $\\mathbf{x}_{k+1} = \\mathbf{x}_k + \\alpha_k \\mathbf{p}_k$。\n5.  下一次迭代的梯度使用高效公式更新：$g_{k+1} = g_k + \\alpha_k A \\mathbf{p}_k$。\n\n如果数量 $\\mathbf{u}^T A \\mathbf{v}$ 等于零，则称两个向量 $\\mathbf{u}$ 和 $\\mathbf{v}$ 关于矩阵 $A$ 是共轭的。CG 方法的一个关键性质是它生成一系列相互共轭的搜索方向。\n\n你的任务是应用 CG 方法，从点 $\\mathbf{x}_0 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$ 开始，生成前两个搜索方向 $\\mathbf{p}_0$ 和 $\\mathbf{p}_1$。然后，计算表达式 $\\mathbf{p}_0^T A \\mathbf{p}_1$ 的值。", "solution": "我们最小化函数 $f(\\mathbf{x})=\\frac{1}{2}\\mathbf{x}^{T}A\\mathbf{x}-\\mathbf{b}^{T}\\mathbf{x}$，其中 $A=\\begin{pmatrix}5 & 2\\\\2 & 1\\end{pmatrix}$，$\\mathbf{b}=\\begin{pmatrix}1\\\\1\\end{pmatrix}$，起始点为 $\\mathbf{x}_{0}=\\begin{pmatrix}0\\\\0\\end{pmatrix}$。梯度为 $\\nabla f(\\mathbf{x})=A\\mathbf{x}-\\mathbf{b}$。\n\n计算初始梯度：\n$$\n\\mathbf{g}_{0}=\\nabla f(\\mathbf{x}_{0})=A\\mathbf{x}_{0}-\\mathbf{b}=\\begin{pmatrix}0\\\\0\\end{pmatrix}-\\begin{pmatrix}1\\\\1\\end{pmatrix}=\\begin{pmatrix}-1\\\\-1\\end{pmatrix}.\n$$\n第一个搜索方向：\n$$\n\\mathbf{p}_{0}=-\\mathbf{g}_{0}=\\begin{pmatrix}1\\\\1\\end{pmatrix}.\n$$\n步长 $\\alpha_{0}$：\n$$\n\\alpha_{0}=\\frac{\\mathbf{g}_{0}^{T}\\mathbf{g}_{0}}{\\mathbf{p}_{0}^{T}A\\mathbf{p}_{0}},\\quad \\mathbf{g}_{0}^{T}\\mathbf{g}_{0}=(-1)^{2}+(-1)^{2}=2,\n$$\n$$\nA\\mathbf{p}_{0}=\\begin{pmatrix}5 & 2\\\\2 & 1\\end{pmatrix}\\begin{pmatrix}1\\\\1\\end{pmatrix}=\\begin{pmatrix}7\\\\3\\end{pmatrix},\\quad \\mathbf{p}_{0}^{T}A\\mathbf{p}_{0}=\\begin{pmatrix}1 & 1\\end{pmatrix}\\begin{pmatrix}7\\\\3\\end{pmatrix}=10,\n$$\n$$\n\\alpha_{0}=\\frac{2}{10}=\\frac{1}{5}.\n$$\n更新位置和梯度：\n$$\n\\mathbf{x}_{1}=\\mathbf{x}_{0}+\\alpha_{0}\\mathbf{p}_{0}=\\begin{pmatrix}0\\\\0\\end{pmatrix}+\\frac{1}{5}\\begin{pmatrix}1\\\\1\\end{pmatrix}=\\begin{pmatrix}\\frac{1}{5}\\\\\\frac{1}{5}\\end{pmatrix},\n$$\n$$\n\\mathbf{g}_{1}=\\mathbf{g}_{0}+\\alpha_{0}A\\mathbf{p}_{0}=\\begin{pmatrix}-1\\\\-1\\end{pmatrix}+\\frac{1}{5}\\begin{pmatrix}7\\\\3\\end{pmatrix}=\\begin{pmatrix}\\frac{2}{5}\\\\-\\frac{2}{5}\\end{pmatrix}.\n$$\n计算 $\\beta_{1}$ 和第二个搜索方向 $\\mathbf{p}_{1}$：\n$$\n\\beta_{1}=\\frac{\\mathbf{g}_{1}^{T}\\mathbf{g}_{1}}{\\mathbf{g}_{0}^{T}\\mathbf{g}_{0}}=\\frac{\\left(\\frac{2}{5}\\right)^{2}+\\left(-\\frac{2}{5}\\right)^{2}}{2}=\\frac{\\frac{8}{25}}{2}=\\frac{4}{25},\n$$\n$$\n\\mathbf{p}_{1}=-\\mathbf{g}_{1}+\\beta_{1}\\mathbf{p}_{0}=-\\begin{pmatrix}\\frac{2}{5}\\\\-\\frac{2}{5}\\end{pmatrix}+\\frac{4}{25}\\begin{pmatrix}1\\\\1\\end{pmatrix}=\\begin{pmatrix}-\\frac{6}{25}\\\\\\frac{14}{25}\\end{pmatrix}.\n$$\n最后，计算 $\\mathbf{p}_{0}^{T}A\\mathbf{p}_{1}$：\n$$\nA\\mathbf{p}_{1}=\\begin{pmatrix}5 & 2\\\\2 & 1\\end{pmatrix}\\begin{pmatrix}-\\frac{6}{25}\\\\\\frac{14}{25}\\end{pmatrix}=\\begin{pmatrix}-\\frac{2}{25}\\\\\\frac{2}{25}\\end{pmatrix},\n$$\n$$\n\\mathbf{p}_{0}^{T}A\\mathbf{p}_{1}=\\begin{pmatrix}1 & 1\\end{pmatrix}\\begin{pmatrix}-\\frac{2}{25}\\\\\\frac{2}{25}\\end{pmatrix}=0.\n$$\n这证实了前两个 CG 搜索方向是 A-共轭的。", "answer": "$$\\boxed{0}$$", "id": "2211315"}, {"introduction": "共轭梯度法的真正威力在于解决科学与工程领域中出现的大规模问题。这个高级练习将应用 CG 方法求解一个质点-弹簧系统的平衡状态，这是一个物理学中的常见模型。你将探索变化的物理属性如何影响问题的条件数，并发现一种称为“预处理”的技术如何能显著加速收敛，这是实际应用中的一个至关重要的概念。", "problem": "给定一个一维线性弹簧链，其两端连接到固定支座上。设 $n$ 为内部节点的数量，其位移未知，索引为 $i \\in \\{1,2,\\dots,n\\}$。边界节点索引为 $0$ 和 $n+1$，并固定在零位移处。对于 $i \\in \\{0,1,\\dots,n\\}$，连接节点 $i$ 和节点 $i+1$ 的弹簧的刚度为 $k_i > 0$。在由 Hooke 定律和力平衡决定的静态平衡条件下，位移 $u \\in \\mathbb{R}^n$ 满足线性系统\n$$\nK u = f,\n$$\n其中 $K \\in \\mathbb{R}^{n \\times n}$ 是对称正定 (SPD) 矩阵，其元素为\n$$\nK_{i,i} = k_{i-1} + k_i \\quad \\text{for} \\; i=1,\\dots,n,\n$$\n$$\nK_{i,i+1} = -k_i \\quad \\text{for} \\; i=1,\\dots,n-1,\n$$\n$$\nK_{i,i-1} = -k_{i-1} \\quad \\text{for} \\; i=2,\\dots,n,\n$$\n而 $f \\in \\mathbb{R}^n$ 是施加在内部节点上的外力向量。共轭梯度 (CG) 法是一种求解 SPD 系统的 Krylov 子空间方法，可以解释为最小化二次能量泛函\n$$\n\\Phi(u) = \\tfrac{1}{2} u^\\top K u - f^\\top u,\n$$\n其搜索方向相对于 $K$-内积是相互共轭的。\n\n您的任务是编写一个完整的程序，该程序：\n- 根据给定的刚度 $k_i$，通过其三对角结构隐式地构造 $K$，而不形成稠密矩阵。\n- 使用共轭梯度法从零向量开始求解 $K u = f$，当相对残差范数 $\\|r_k\\|_2/\\|f\\|_2 \\leq \\varepsilon$ 或迭代次数达到指定的最大值时停止。这里 $r_k = f - K u_k$ 是第 $k$ 次迭代的残差。\n- 使用简单的对角 (Jacobi) 预条件子重复求解，该预条件子使用 $M = \\mathrm{diag}(K)$，因此预处理后的系统是 $M^{-1} K u = M^{-1} f$。\n- 对于每个测试用例和每种求解器变体，报告所用的整数迭代次数和最终的相对残差 $\\|r_k\\|_2/\\|f\\|_2$（浮点数）。\n\n对所有运行使用以下固定的容差和迭代上限：\n- 容差：$\\varepsilon = 10^{-8}$。\n- 最大迭代次数：$n$。\n\n将力向量设置为在最后一个内部节点上的单位载荷，\n$$\nf = [0, 0, \\dots, 0, 1]^\\top \\in \\mathbb{R}^n.\n$$\n\n测试套件。使用 $n=200$ 和以下四种刚度模式；在每种情况下，确保所有的 $k_i$ 都严格为正：\n1. 均匀刚度 (理想情况)：对于所有 $i \\in \\{0,1,\\dots,n\\}$，$k_i = 1$。\n2. 块状对比 (中等异质性)：对于所有 $i$，$k_i=1$，除了索引 $i \\in \\{80,81,\\dots,120\\}$ 的 $k_i=10$。\n3. 对数正态变异性 (强异质性)：对于所有 $i$，$k_i = \\exp(Z_i)$，其中 $Z_i$ 是均值为 $0$、标准差为 $1$ 的独立同分布正态随机变量，使用固定的种子 $42$ 进行确定性生成。也就是说，对于所有 $i$，$Z_i \\sim \\mathcal{N}(0,1)$，并且必须将随机数生成器初始化为 $42$ 以使结果可复现。\n4. 近奇异瓶颈 (边缘情况)：对于所有 $i$，$k_i=1$，除了 $k_{100} = 10^{-6}$。\n\n输出规范。对于每个测试用例，运行无预处理的共轭梯度法和 Jacobi 预处理的共轭梯度法。记录：\n- 方法所用的整数迭代次数（等于满足停止准则时的迭代次数，如果未满足准则，则为最大迭代次数 $n$）。\n- 最终的相对残差（浮点数）。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。该列表必须按以下顺序包含所有测试用例的扁平化结果：\n$$\n[\\text{it}_1^\\text{none}, \\text{it}_1^\\text{jac}, \\text{rel}_1^\\text{none}, \\text{rel}_1^\\text{jac}, \\text{it}_2^\\text{none}, \\text{it}_2^\\text{jac}, \\text{rel}_2^\\text{none}, \\text{rel}_2^\\text{jac}, \\text{it}_3^\\text{none}, \\text{it}_3^\\text{jac}, \\text{rel}_3^\\text{none}, \\text{rel}_3^\\text{jac}, \\text{it}_4^\\text{none}, \\text{it}_4^\\text{jac}, \\text{rel}_4^\\text{none}, \\text{rel}_4^\\text{jac}],\n$$\n其中 $\\text{it}_j^\\cdot$ 是整数，$\\text{rel}_j^\\cdot$ 是浮点数，对应于测试用例 $j \\in \\{1,2,3,4\\}$ 和由上标指示的求解器变体。输出中不需要物理单位，因为报告的量是无量纲的计数和范数。程序必须是自包含的，并且在重复运行时产生相同的结果。", "solution": "我们从线性弹簧的 Hooke 定律开始，该定律指出弹簧中的力与其伸长量成正比，$F = k \\Delta$，其中 $k$ 是刚度，$\\Delta$ 是长度变化量。在一个由弹簧连接且端点固定的节点组成的一维链中，当每个内部节点上的合力等于所施加的外力时，达到静态平衡。记 $u_i$ 为内部节点 $i$ 的位移，其左侧弹簧施加在节点 $i$ 上的力为 $k_{i-1}(u_{i-1} - u_i)$（由于左边界固定，因此 $u_0 = 0$），其右侧弹簧施加的力为 $k_{i}(u_{i+1} - u_i)$（由于右边界固定，因此 $u_{n+1} = 0$）。将这些力相加并使其等于外力 $f_i$，得到平衡方程\n$$\nk_{i-1}(u_{i-1} - u_i) + k_{i}(u_{i+1} - u_i) = f_i, \\quad i=1,\\dots,n.\n$$\n重新整理各项，得到线性系统 $K u = f$，其中\n$$\nK_{i,i} = k_{i-1} + k_{i}, \\quad K_{i,i-1} = -k_{i-1}, \\quad K_{i,i+1} = -k_i,\n$$\n其它项为零，这证实了 $K$ 是三对角且对称的。此外，$K$ 是对称正定 (SPD) 的，因为它来自于严格凸二次能量泛函的二阶导数 (Hessian 矩阵)\n$$\n\\Phi(u) = \\tfrac{1}{2} \\sum_{i=0}^{n} k_i (u_{i+1} - u_i)^2 - \\sum_{i=1}^{n} f_i u_i,\n$$\n其中 $u_0 = u_{n+1} = 0$。由于对所有 $i$ 都有 $k_i > 0$，二次型 $u^\\top K u$ 对所有非零 $u$ 均为正，这意味着正定性。\n\n共轭梯度 (CG) 法通过在不断扩大的 Krylov 子空间上最小化 $\\Phi(u)$ 来求解 SPD 系统。它构造了 $K$-共轭的搜索方向 $\\{p_k\\}$（即对于 $i \\neq j$ 有 $p_i^\\top K p_j = 0$），并沿着这些方向执行线搜索。从 $u_0 = 0$ 开始，残差 $r_0 = f - K u_0 = f$，并设置 $p_0 = r_0$，算法迭代更新\n$$\n\\alpha_k = \\frac{r_k^\\top r_k}{p_k^\\top K p_k}, \\quad u_{k+1} = u_k + \\alpha_k p_k, \\quad r_{k+1} = r_k - \\alpha_k K p_k,\n$$\n并计算\n$$\n\\beta_{k+1} = \\frac{r_{k+1}^\\top r_{k+1}}{r_k^\\top r_k}, \\quad p_{k+1} = r_{k+1} + \\beta_{k+1} p_k.\n$$\n一种等效且通常更稳健的变体使用预处理残差 $z_k = M^{-1} r_k$，其中预条件子 $M$ 在某种意义上近似于 $K$。预处理共轭梯度 (PCG) 法的递推关系变为\n$$\n\\alpha_k = \\frac{r_k^\\top z_k}{p_k^\\top K p_k}, \\quad u_{k+1} = u_k + \\alpha_k p_k, \\quad r_{k+1} = r_k - \\alpha_k K p_k,\n$$\n$$\nz_{k+1} = M^{-1} r_{k+1}, \\quad \\beta_{k+1} = \\frac{r_{k+1}^\\top z_{k+1}}{r_k^\\top z_k}, \\quad p_{k+1} = z_{k+1} + \\beta_{k+1} p_k.\n$$\n一个简单且广泛使用的选择是 Jacobi 预条件子，$M = \\mathrm{diag}(K)$，它的应用成本低廉，并且可以减小特征值的分布范围。\n\nCG 的收敛速度由条件数 $\\kappa(K) = \\lambda_{\\max}(K)/\\lambda_{\\min}(K)$ 决定。一个经典的能量范数界为\n$$\n\\frac{\\|e_k\\|_K}{\\|e_0\\|_K} \\leq 2 \\left( \\frac{\\sqrt{\\kappa(K)} - 1}{\\sqrt{\\kappa(K)} + 1} \\right)^k,\n$$\n其中 $e_k = u^\\star - u_k$ 且 $u^\\star$ 是精确解。当刚度值在整个链上变化很大时，$K$ 的特征值会散开，$\\kappa(K)$ 增大，从而减慢 CG 的速度。预处理旨在减小 $\\kappa(M^{-1}K)$，使特征值聚集，从而加速收敛。\n\n此问题的算法设计：\n- 使用刚度边列表 $\\{k_i\\}_{i=0}^{n}$，通过其三对角元素隐式地构造 $K$。对角元素为 $d_i = k_{i-1} + k_i$（对于 $i=1,\\dots,n$），非对角元素为 $o_i = -k_i$（对于 $i=1,\\dots,n-1$）。为了高效地计算乘法 $y = K x$，计算\n$$\ny_i = d_i x_i + o_i x_{i+1} + o_{i-1} x_{i-1},\n$$\n并对末端索引进行适当处理。\n- 实现 CG 和 PCG，使用零向量作为初始猜测。停止准则是 $\\|r_k\\|_2 / \\|f\\|_2 \\leq 10^{-8}$ 或 $k$ 达到 $n$。\n- 对于 Jacobi 预条件子，设置 $M = \\mathrm{diag}(K)$，因此 $M^{-1}$ 的作用是将每个分量除以相应的对角元素 $d_i$。\n- 准备指定的四个测试用例。第三个测试用例必须使用固定的种子为正态随机数进行确定性生成，然后转换为 $k_i = \\exp(Z_i)$，以确保 $k_i > 0$。\n- 对于每个测试用例，运行两种求解器，记录迭代次数和最终相对残差，并以规定的单行列表格式打印汇总结果。\n\n结果解释：\n- 在均匀情况下，特征值表现良好，CG 应该在相对较少的迭代次数内收敛；Jacobi 预条件子可能会提供适度的改进。\n- 在块状对比情况下，某一段刚度的增加会产生局部高频模式，从而增大了条件数。与无预处理的 CG 相比，Jacobi 预处理通常会减少迭代次数。\n- 在对数正态情况下，$k_i$ 的巨大变异性导致了强烈的异质性和更宽的特征值谱；预处理应该会有更显著的效果。\n- 在近奇异瓶颈情况下，一个非常小的刚度会产生一个近乎断开的系统，它具有极小的特征值和巨大的条件数；无预处理的 CG 可能会接近迭代上限，即使是 Jacobi 预处理也可能只能部分缓解这个困难。\n\n最终的程序清晰且确定地实现了这些步骤，并以整数和浮点数的有序列表形式，输出了所要求的单行结果。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef build_tridiag_from_edges(k_edges: np.ndarray):\n    \"\"\"\n    Given spring stiffnesses between consecutive nodes k_edges of length n+1\n    (including boundary-to-node springs), construct the tridiagonal representation\n    of the SPD stiffness matrix K for n interior unknowns.\n\n    Returns:\n        diag: length-n diagonal entries of K\n        off:  length-(n-1) off-diagonal entries (both upper and lower, symmetric)\n    \"\"\"\n    # k_edges shape: (n+1,)\n    n = k_edges.shape[0] - 1\n    # Diagonal: d_i = k_{i-1} + k_i for i = 1..n, but using 0-based indexing\n    diag = k_edges[:-1] + k_edges[1:]\n    # Off-diagonal entries correspond to interior springs between nodes i and i+1: -k_i for i=1..n-1\n    off = -k_edges[1:-1]\n    return diag, off\n\ndef matvec_tridiag(diag: np.ndarray, off: np.ndarray, x: np.ndarray):\n    \"\"\"\n    Multiply y = K x for a symmetric tridiagonal K specified by diag and off.\n    diag length n, off length n-1.\n    \"\"\"\n    n = diag.shape[0]\n    y = diag * x\n    if n > 1:\n        y[:-1] += off * x[1:]\n        y[1:] += off * x[:-1]\n    return y\n\ndef pcg_tridiag(diag: np.ndarray, off: np.ndarray, b: np.ndarray, M_inv: np.ndarray | None,\n                tol: float, max_iter: int):\n    \"\"\"\n    Preconditioned Conjugate Gradient for symmetric positive definite tridiagonal system.\n    If M_inv is None, performs unpreconditioned CG.\n\n    Returns:\n        x: solution vector\n        iters: iteration count used (int)\n        rel_res: final relative residual ||r|| / ||b|| (float)\n    \"\"\"\n    n = diag.shape[0]\n    x = np.zeros(n, dtype=float)\n    r = b.copy()  # since A x0 = 0 for x0 = 0\n    b_norm = np.linalg.norm(b)\n    # Handle the trivial case b == 0 to avoid division by zero in relative residual\n    if b_norm == 0.0:\n        return x, 0, 0.0\n\n    # Apply preconditioner\n    if M_inv is None:\n        z = r.copy()\n    else:\n        z = M_inv * r\n\n    p = z.copy()\n    rz_old = float(np.dot(r, z))\n\n    rel_res = np.linalg.norm(r) / b_norm\n    if rel_res <= tol:\n        return x, 0, rel_res\n\n    iters = 0\n    for k in range(max_iter):\n        Ap = matvec_tridiag(diag, off, p)\n        pAp = float(np.dot(p, Ap))\n        # Guard against breakdown (should not occur for SPD and proper preconditioning)\n        if pAp <= 0.0:\n            iters = k\n            rel_res = np.linalg.norm(r) / b_norm\n            return x, iters, rel_res\n        alpha = rz_old / pAp\n        x += alpha * p\n        r -= alpha * Ap\n        rel_res = np.linalg.norm(r) / b_norm\n        iters = k + 1\n        if rel_res <= tol:\n            break\n        if M_inv is None:\n            z = r.copy()\n        else:\n            z = M_inv * r\n        rz_new = float(np.dot(r, z))\n        # Guard against breakdown\n        if rz_old == 0.0:\n            break\n        beta = rz_new / rz_old\n        p = z + beta * p\n        rz_old = rz_new\n\n    # Return final values\n    return x, iters, rel_res\n\ndef make_test_cases(n: int):\n    \"\"\"\n    Create the four test cases as specified:\n      1) Uniform stiffness: k_i = 1\n      2) Block contrast: k_i = 1 except k_i = 10 for i in [80, 120]\n      3) Log-normal: k_i = exp(Z_i), Z_i ~ N(0,1) with seed 42\n      4) Bottleneck: k_i = 1 except k_100 = 1e-6\n    Returns a list of k_edges arrays.\n    \"\"\"\n    cases = []\n\n    # Case 1: Uniform\n    k_uniform = np.ones(n + 1, dtype=float)\n    cases.append(k_uniform)\n\n    # Case 2: Block contrast\n    k_block = np.ones(n + 1, dtype=float)\n    # Indices 80..120 inclusive (safe within 0..n)\n    low = 80\n    high = min(120, n)  # ensure bound for n=200\n    k_block[low:high + 1] = 10.0\n    cases.append(k_block)\n\n    # Case 3: Log-normal with seed 42\n    rng = np.random.default_rng(42)\n    Z = rng.normal(loc=0.0, scale=1.0, size=n + 1)\n    k_logn = np.exp(Z)\n    cases.append(k_logn)\n\n    # Case 4: Near-singular bottleneck\n    k_bottle = np.ones(n + 1, dtype=float)\n    bottleneck_index = 100\n    if 0 <= bottleneck_index <= n:\n        k_bottle[bottleneck_index] = 1e-6\n    cases.append(k_bottle)\n\n    return cases\n\ndef run_case(k_edges: np.ndarray, tol: float):\n    \"\"\"\n    Build K from k_edges, run CG and Jacobi-PCG, return iteration counts and final relative residuals.\n    \"\"\"\n    diag, off = build_tridiag_from_edges(k_edges)\n    n = diag.shape[0]\n    b = np.zeros(n, dtype=float)\n    b[-1] = 1.0  # unit load at the last interior node\n    max_iter = n\n\n    # Unpreconditioned CG\n    x_none, it_none, rel_none = pcg_tridiag(diag, off, b, M_inv=None, tol=tol, max_iter=max_iter)\n\n    # Jacobi preconditioner M = diag(K)\n    M_inv = 1.0 / diag\n    x_jac, it_jac, rel_jac = pcg_tridiag(diag, off, b, M_inv=M_inv, tol=tol, max_iter=max_iter)\n\n    return it_none, it_jac, rel_none, rel_jac\n\ndef solve():\n    # Define the test cases from the problem statement.\n    n = 200\n    tol = 1e-8\n    k_cases = make_test_cases(n)\n\n    results = []\n    for k_edges in k_cases:\n        it_none, it_jac, rel_none, rel_jac = run_case(k_edges, tol)\n        # Append in the specified flattened order: it_none, it_jac, rel_none, rel_jac\n        results.extend([it_none, it_jac, rel_none, rel_jac])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3110688"}]}