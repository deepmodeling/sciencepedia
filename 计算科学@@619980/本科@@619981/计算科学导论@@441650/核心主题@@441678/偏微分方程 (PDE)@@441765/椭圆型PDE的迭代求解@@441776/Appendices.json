{"hands_on_practices": [{"introduction": "为了深入理解迭代法的收敛性，我们首先从理论分析入手。本练习将引导你使用局部傅里叶分析（LFA）这一强大工具，推导经典迭代法（如雅可比法、高斯-赛德尔法和逐次超松弛法）的误差放大因子，从而揭示它们收敛速度和高频误差阻尼能力的差异。通过这个推导过程，你将掌握评估和优化迭代格式性能的核心原理。[@problem_id:3148203]", "problem": "考虑在区间 $(0,1)$ 上的一维泊松方程 $-u''(x) = f(x)$，其狄利克雷边界条件为 $u(0) = 0$ 和 $u(1) = 0$。将该区间离散化为 $N$ 个内部点，均匀间距为 $h = \\frac{1}{N+1}$，并使用二阶中心有限差分格式近似 $-u''(x)$，从而得到线性系统 $A \\mathbf{u} = \\mathbf{b}$。其中，$A$ 是一个三对角矩阵，其主对角线元素为 $\\frac{2}{h^2}$，次对角线和超对角线元素为 $-\\frac{1}{h^2}$。考虑由标准矩阵分裂定义的定常迭代方法：雅可比（Jacobi）法、前向字典序的高斯-赛德尔（Gauss–Seidel）法，以及带有松弛因子 $\\omega \\in (0,2)$ 的逐次超松弛（Successive Over-Relaxation, SOR）法。\n\n使用局部傅里叶分析（Local Fourier Analysis, LFA）对误差模式 $e^{\\mathrm{i} j \\theta}$（其中 $j$ 为整数网格索引，$\\theta \\in (0,\\pi)$ 为与狄利克雷边界条件一致的离散频率）进行分析，推导雅可比迭代和高斯-赛德尔迭代在该网格上的误差放大因子。基于这些因子，求出它们迭代算子的谱半径（以 $N$ 表示），并解释哪种方法能更有效地衰减高频误差分量。\n\n然后，在应用于 SOR 误差更新的相同 LFA 框架下，确定使 SOR 迭代算子谱半径最小化的松弛因子 $\\omega$ 的值。将你的最终答案表示为仅依赖于 $N$ 的封闭形式解析表达式。无需四舍五入。松弛因子是无量纲的，不要包含单位。", "solution": "用户需要对一维泊松问题的定常迭代方法进行详细分析。我将首先验证问题陈述，然后按要求进行推导。\n\n### 问题验证\n\n**步骤 1：提取已知条件**\n-   **方程：** 在区间 $(0,1)$ 上的一维泊松方程 $-u''(x) = f(x)$。\n-   **边界条件：** 狄利克雷边界条件 $u(0) = 0$ 和 $u(1) = 0$。\n-   **离散化：** 将区间离散化为 $N$ 个内部点，均匀间距为 $h = \\frac{1}{N+1}$。\n-   **数值格式：** 用于 $-u''(x)$ 的二阶中心有限差分。\n-   **线性系统：** $A \\mathbf{u} = \\mathbf{b}$，其中 $A$ 是一个三对角矩阵，主对角线元素为 $\\frac{2}{h^2}$，次对角线和超对角线元素为 $-\\frac{1}{h^2}$。\n-   **迭代方法：** 雅可比法、高斯-赛德尔法（前向字典序）和逐次超松弛（SOR）法（参数 $\\omega \\in (0,2)$）。\n-   **分析方法：** 对误差模式 $e^{\\mathrm{i} j \\theta}$ 进行局部傅里叶分析（LFA），其中 $j$ 为整数网格索引，$\\theta \\in (0,\\pi)$ 为与狄利克雷边界条件一致的离散频率。\n-   **任务：**\n    1.  使用 LFA 推导雅可比法和高斯-赛德尔法的误差放大因子。\n    2.  求出它们迭代算子的谱半径（以 $N$ 表示）。\n    3.  解释哪种方法能更有效地衰减高频误差分量。\n    4.  使用 LFA 框架分析 SOR 误差更新，确定使 SOR 谱半径最小化的最优松弛因子 $\\omega$。\n    5.  将 $\\omega$ 的最终答案表示为仅依赖于 $N$ 的封闭形式表达式。\n\n**步骤 2：使用提取的已知条件进行验证**\n-   **科学基础：** 该问题是数值分析和计算科学中的一个经典教科书示例。它涉及泊松方程的有限差分離散化以及标准迭代求解器（雅可比法、高斯-赛德尔法、SOR法）的分析。使用局部傅里叶分析（也称为冯·诺依曼稳定性分析）是分析此类方法的标准技术。所有概念都已成熟且科学合理。\n-   **适定性：** 问题定义明确。它要求进行特定的推导（放大因子、谱半径）和一个优化问题（找到最优的 $\\omega$）。所有必要的信息和背景都已提供。迭代方法理论保证了结果的存在性和唯一性。\n-   **客观性：** 问题以精确、形式化的数学语言陈述，没有任何主观性、模糊性或个人观点。\n\n**步骤 3：结论与行动**\n问题有效。这是计算科学领域一个标准的、适定的问题。我现在开始进行求解。\n\n### 求解推导\n\n给定的偏微分方程为 $-u''(x) = f(x)$，且 $u(0)=u(1)=0$。\n设网格点为 $x_j = jh$，其中 $j=0, 1, \\dots, N+1$，且 $h = \\frac{1}{N+1}$。在内部网格点 $x_j$ 处，使用二阶中心有限差分格式得到的离散方程为：\n$$-\\frac{u(x_{j-1}) - 2u(x_j) + u(x_{j+1})}{h^2} \\approx f(x_j)$$\n设 $u_j$ 是 $u(x_j)$ 的数值近似解。线性方程组为 $A \\mathbf{u} = \\mathbf{b}$，其中第 $j$ 行的方程为：\n$$\\frac{1}{h^2}(2u_j - u_{j-1} - u_{j+1}) = f_j$$\n第 $k$ 次迭代的误差定义为 $e_j^{(k)} = u_j - u_j^{(k)}$，其中 $u_j$ 是离散系统的精确解。误差根据迭代格式的齐次形式进行传播。\n\n**雅可比法**\n雅可比迭代同时更新解向量的所有分量，使用的是上一次迭代 $k$ 的值：\n$$u_j^{(k+1)} = \\frac{1}{2}(u_{j-1}^{(k)} + u_{j+1}^{(k)}) + \\frac{h^2}{2}f_j$$\n精确解 $u_j$ 满足 $u_j = \\frac{1}{2}(u_{j-1} + u_{j+1}) + \\frac{h^2}{2}f_j$。从此式中减去迭代方程，得到误差传播方程：\n$$e_j^{(k+1)} = \\frac{1}{2}(e_{j-1}^{(k)} + e_{j+1}^{(k)})$$\n我们通过代入单个误差模式 $e_j^{(k)} = (\\lambda_J(\\theta))^k e^{\\mathrm{i} j \\theta}$ 来进行局部傅里叶分析，其中 $\\lambda_J(\\theta)$ 是放大因子。\n$$(\\lambda_J(\\theta))^{k+1} e^{\\mathrm{i} j \\theta} = \\frac{1}{2} \\left( (\\lambda_J(\\theta))^k e^{\\mathrm{i} (j-1) \\theta} + (\\lambda_J(\\theta))^k e^{\\mathrm{i} (j+1) \\theta} \\right)$$\n两边同除以 $(\\lambda_J(\\theta))^k e^{\\mathrm{i} j \\theta}$ 得到放大因子：\n$$\\lambda_J(\\theta) = \\frac{1}{2} (e^{-\\mathrm{i} \\theta} + e^{\\mathrm{i} \\theta}) = \\cos(\\theta)$$\n\n**高斯-赛德尔法**\n采用前向字典序的高斯-赛德尔法在当前迭代中使用最新的可用值：\n$$u_j^{(k+1)} = \\frac{1}{2}(u_{j-1}^{(k+1)} + u_{j+1}^{(k)}) + \\frac{h^2}{2}f_j$$\n误差传播方程为：\n$$e_j^{(k+1)} = \\frac{1}{2}(e_{j-1}^{(k+1)} + e_{j+1}^{(k)})$$\n对于像高斯-赛德尔法这样具有优先扫描方向的方法，单个傅里叶模式 $e^{\\mathrm{i} j\\theta}$ 并不是迭代算子的特征向量。严格的 LFA 会更复杂。然而，LFA 仍然可以用来推导算子的“符号”（symbol），它描述了单个傅里叶模式如何变换，这对于分析光滑特性至关重要。将 $e_j^{(k)} = (\\lambda_{GS}(\\theta))^k e^{\\mathrm{i}j\\theta}$ 代入误差更新方程：\n$$(\\lambda_{GS}(\\theta))^{k+1} e^{\\mathrm{i} j \\theta} = \\frac{1}{2} \\left( (\\lambda_{GS}(\\theta))^{k+1} e^{\\mathrm{i} (j-1) \\theta} + (\\lambda_{GS}(\\theta))^k e^{\\mathrm{i} (j+1) \\theta} \\right)$$\n$$\\lambda_{GS}(\\theta) e^{\\mathrm{i} j \\theta} = \\frac{1}{2} \\left( \\lambda_{GS}(\\theta) e^{\\mathrm{i} (j-1) \\theta} + e^{\\mathrm{i} (j+1) \\theta} \\right)$$\n$$\\lambda_{GS}(\\theta) (1 - \\frac{1}{2} e^{-\\mathrm{i} \\theta}) = \\frac{1}{2} e^{\\mathrm{i} \\theta}$$\n$$\\lambda_{GS}(\\theta) = \\frac{e^{\\mathrm{i} \\theta}}{2 - e^{-\\mathrm{i} \\theta}}$$\n这个复数量是高斯-赛德尔法的 LFA 符号。虽然它不是一个真正的特征值，但其模决定了模式 $\\theta$ 的衰减情况。\n\n**谱半径与高频衰减**\n狄利克雷边界条件 $u_0 = u_{N+1} = 0$ 意味着误差在边界处也为零。相应的离散傅里叶模式是正弦函数，它们是复指数 $e^{\\mathrm{i}j\\theta}$ 的组合。允许的离散频率为 $\\theta_m = \\frac{m\\pi}{N+1}$，其中 $m = 1, 2, \\dots, N$。\n迭代算子的谱半径是其特征值模的最大值。对于应用于此问题的雅可比法，傅里叶模式是其特征向量，因此迭代矩阵 $T_J$ 的特征值为 $\\mu_m = \\lambda_J(\\theta_m) = \\cos(\\frac{m\\pi}{N+1})$。谱半径为：\n$$\\rho(T_J) = \\max_{m=1, \\dots, N} \\left| \\cos\\left(\\frac{m\\pi}{N+1}\\right) \\right| = \\cos\\left(\\frac{\\pi}{N+1}\\right)$$\n\n对于高斯-赛德尔法的谱半径，我们不能简单地取 $|\\lambda_{GS}(\\theta_m)|$ 的最大值。相反，我们使用一个关于“一致有序”矩阵的基本定理，本问题中的矩阵 $A$ 就是这种矩阵。该定理指出，高斯-赛德尔算子的谱半径是雅可比算子谱半径的平方：\n$$\\rho(T_{GS}) = (\\rho(T_J))^2 = \\cos^2\\left(\\frac{\\pi}{N+1}\\right)$$\n\n为了比较对高频误差分量的衰减效果，我们考察 $\\theta \\in [\\pi/2, \\pi]$ 时放大因子的模。\n对于雅可比法：$|\\lambda_J(\\theta)| = |\\cos(\\theta)|$。当 $\\theta \\to \\pi$ 时，$|\\lambda_J(\\theta)| \\to 1$。因此，雅可比法在衰减高频误差方面效率很低（它是一个差的光滑子）。\n对于高斯-赛德尔法，我们使用 LFA 符号的模：\n$$|\\lambda_{GS}(\\theta)| = \\left| \\frac{e^{\\mathrm{i} \\theta}}{2 - e^{-\\mathrm{i} \\theta}} \\right| = \\frac{1}{|2 - \\cos\\theta + \\mathrm{i}\\sin\\theta|} = \\frac{1}{\\sqrt{(2-\\cos\\theta)^2 + \\sin^2\\theta}} = \\frac{1}{\\sqrt{5-4\\cos\\theta}}$$\n对于高频 $\\theta \\in [\\pi/2, \\pi]$，$\\cos\\theta$ 的范围是从 $0$到 $-1$。在此范围内，$|\\lambda_{GS}(\\theta)|$ 的最大值出现在 $\\theta=\\pi/2$ 处，其值为 $1/\\sqrt{5} \\approx 0.447$。在 $\\theta=\\pi$ 处，值为 $1/3$。由于高频的放大因子被限制在远小于 $1$ 的范围内，高斯-赛德尔法能有效衰减高频误差，是一个好的光滑子。显然，为此目的，高斯-赛德尔法比雅可比法更有效。\n\n**最优 SOR 参数**\nSOR 方法是高斯-赛德尔法的一种外推：$u_j^{(k+1)} = (1-\\omega)u_j^{(k)} + \\omega u_j^{GS}$。其误差传播方程为：\n$$e_j^{(k+1)} = (1-\\omega)e_j^{(k)} + \\frac{\\omega}{2}(e_{j-1}^{(k+1)} + e_{j+1}^{(k)})$$\n应用类似的 LFA 过程是可能的，但在代数上很复杂。一种更稳健的方法依赖于关于一致有序矩阵的既定理论，该理论将 SOR 迭代矩阵 $T_{SOR}$ 的特征值 $\\lambda$ 与雅可比矩阵 $T_J$ 的特征值 $\\mu$ 联系起来：\n$$(\\lambda + \\omega - 1)^2 = \\lambda \\omega^2 \\mu^2$$\n$T_J$ 的特征值 $\\mu$ 是实数，且位于 $(-\\rho_J, \\rho_J)$ 内，其中 $\\rho_J = \\cos(\\frac{\\pi}{N+1})$。我们希望选择 $\\omega$ 来最小化 $\\rho(T_{SOR}) = \\max_{\\mu} |\\lambda(\\mu, \\omega)|$。\n\n对上述关系的分析得出了 $\\lambda$ 的模的两种情况：\n1. 如果 $\\omega^2\\mu^2  4(\\omega-1)$（这要求 $\\omega > 1$），则 $\\sqrt{\\lambda}$ 的根是共轭复数，且 $|\\lambda| = \\omega-1$。\n2. 如果 $\\omega^2\\mu^2 \\ge 4(\\omega-1)$，则根是实数，其模由 $|\\lambda| = \\left( \\frac{\\omega|\\mu| + \\sqrt{\\omega^2\\mu^2 - 4(\\omega-1)}}{2} \\right)^2$ 给出。这是 $|\\mu|$ 的一个增函数。\n\n$\\omega$ 的最优选择（记为 $\\omega_{opt}$）发生在两种情况下最大特征值模相等时。这发生在使判别式为零的 $\\mu$ 的临界值与最大的雅可比特征值 $\\rho_J$ 重合时。\n$$\\omega_{opt}^2 \\rho_J^2 = 4(\\omega_{opt} - 1)$$\n整理后得到一个关于 $\\omega_{opt}$ 的二次方程：\n$$\\rho_J^2 \\omega_{opt}^2 - 4\\omega_{opt} + 4 = 0$$\n解为：\n$$\\omega_{opt} = \\frac{4 \\pm \\sqrt{16 - 16\\rho_J^2}}{2\\rho_J^2} = \\frac{2(1 \\pm \\sqrt{1-\\rho_J^2})}{\\rho_J^2}$$\n代入 $\\rho_J = \\cos(\\frac{\\pi}{N+1})$，并注意到对于给定的参数范围，有 $\\sqrt{1-\\rho_J^2} = \\sin(\\frac{\\pi}{N+1})$：\n$$\\omega_{opt} = \\frac{2 \\left( 1 \\pm \\sin\\left(\\frac{\\pi}{N+1}\\right) \\right)}{\\cos^2\\left(\\frac{\\pi}{N+1}\\right)} = \\frac{2 \\left( 1 \\pm \\sin\\left(\\frac{\\pi}{N+1}\\right) \\right)}{1 - \\sin^2\\left(\\frac{\\pi}{N+1}\\right)} = \\frac{2 \\left( 1 \\pm \\sin\\left(\\frac{\\pi}{N+1}\\right) \\right)}{\\left(1 - \\sin\\left(\\frac{\\pi}{N+1}\\right)\\right)\\left(1 + \\sin\\left(\\frac{\\pi}{N+1}\\right)\\right)}$$\n这给出了两个可能的解：\n$$\\omega_1 = \\frac{2}{1 + \\sin\\left(\\frac{\\pi}{N+1}\\right)} \\quad \\text{和} \\quad \\omega_2 = \\frac{2}{1 - \\sin\\left(\\frac{\\pi}{N+1}\\right)}$$\n由于 SOR 的收敛性仅在 $\\omega \\in (0,2)$ 时得到保证，并且对于 $N \\ge 1$，有 $\\sin(\\frac{\\pi}{N+1}) > 0$，因此我们有 $\\omega_1 \\in (1,2)$ 且 $\\omega_2 > 2$。所以，最优松弛因子是第一个解。\n$$\\omega_{opt} = \\frac{2}{1 + \\sin\\left(\\frac{\\pi}{N+1}\\right)}$$", "answer": "$$ \\boxed{ \\frac{2}{1 + \\sin\\left(\\frac{\\pi}{N+1}\\right)} } $$", "id": "3148203"}, {"introduction": "理论分析为我们提供了基础，但实际问题的复杂性常常要求我们设计更具针对性的求解器。本练习将带你处理一个具有强各向异性的扩散问题，并通过编程实践对比沿不同方向的线松弛法。你将亲手实现并验证一个重要结论：当物理耦合强度在不同方向上存在巨大差异时，将强耦合方向上的未知数进行隐式处理（成组求解）能显著加速收敛。[@problem_id:3148150]", "problem": "实现并比较沿$x$方向与沿$y$方向的行松弛法，用于求解由以下线性二阶椭圆型偏微分方程（PDE）给出的各向异性扩散模型问题：\n$$\n-\\partial_x\\big(\\alpha \\, \\partial_x u\\big) - \\partial_y\\big(\\beta \\, \\partial_y u\\big) = f \\quad \\text{in} \\quad \\Omega=(0,1)\\times(0,1),\n$$\n在$\\partial\\Omega$上具有齐次狄利克雷边界条件$u=0$。假设系数为常数，$\\alpha = r$且$\\beta = 1$，其中$r \\gg 1$模拟了与$x$方向对齐的各向异性。在一个均匀的笛卡尔网格上对$\\Omega$进行离散化，该网格在$x$和$y$方向上分别有$n_x$和$n_y$个内部点，网格间距分别为$h_x = 1/(n_x+1)$和$h_y = 1/(n_y+1)$。对每个内部节点$(i,j)$（其中$1 \\le i \\le n_x$和$1 \\le j \\le n_y$），使用标准的二阶中心差分离散：\n$$\n-\\frac{\\alpha}{h_x^2}\\big(u_{i+1,j}-2u_{i,j}+u_{i-1,j}\\big) \\;-\\; \\frac{\\beta}{h_y^2}\\big(u_{i,j+1}-2u_{i,j}+u_{i,j-1}\\big) \\;=\\; f_{i,j},\n$$\n并在边界虚拟层上设$u=0$。设$f(x,y)=\\sin(\\pi x)\\sin(\\pi y)$。在内部以$u=0$进行初始化。\n\n从以下基本基础出发：(i) 将椭圆算子定义为散度形式的扩散算子，(ii) 二阶导数的有限差分近似，以及 (iii) 高斯-赛德尔（Gauss–Seidel）迭代原理，推导两种行松弛方案：\n\n- $x$-行松弛（沿固定的$y$求解三对角系统）：对于每个固定的$j$，求解关于$i$的三对角系统，该系统隐式处理$x$方向的耦合，并使用最新可用的值以$j$的字典正序显式处理$y$方向的耦合。\n\n- $y$-行松弛（沿固定的$x$求解三对角系统）：对于每个固定的$i$，求解关于$j$的三对角系统，该系统隐式处理$y$方向的耦合，并使用最新可用的值以$i$的字典正序显式处理$x$方向的耦合。\n\n对于每种方案，测量残差$r = f - A u$的离散$L^2$范数\n$$\n\\|r\\|_2 \\;=\\; \\Big(h_x h_y \\sum_{i=1}^{n_x}\\sum_{j=1}^{n_y} r_{i,j}^2\\Big)^{1/2}.\n$$\n通过几何平均值定义经过$N$次行松弛扫描的经验平均每次扫描收敛因子\n$$\n\\rho \\;=\\; \\Bigg(\\frac{\\|r^{(N)}\\|_2}{\\|r^{(0)}\\|_2}\\Bigg)^{1/N},\n$$\n其中$\\|r^{(k)}\\|_2$是经过$k$次完整行松弛扫描后的残差范数。计算$x$-行松弛的$\\rho_x$和$y$-行松弛的$\\rho_y$，然后报告其比率\n$$\n\\gamma \\;=\\; \\frac{\\rho_y}{\\rho_x}.\n$$\n$\\gamma1$的值表示$x$-行松弛每次扫描比$y$-行松弛更快地减少残差。\n\n您的程序必须实现两种行松弛方案，并沿行进行精确的三对角求解（Thomas算法），从相同的初始猜测$u=0$独立应用它们，并按规定计算$\\gamma$。此问题中没有物理单位。由于$\\sin$的标准数学定义，源项中的角度使用弧度。\n\n测试套件：\n- 情况1：$n_x=64$, $n_y=64$, $r=10^3$, $N=8$。\n- 情况2：$n_x=64$, $n_y=64$, $r=10$, $N=8$。\n- 情况3：$n_x=64$, $n_y=64$, $r=1$, $N=8$。\n\n对于每种情况，计算单个浮点数$\\gamma$并四舍五入到$6$位小数。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，\"[result1,result2,result3]\"）。在此问题中，输出必须是对应于上述三个测试用例的列表$[\\gamma_1,\\gamma_2,\\gamma_3]$，按所列顺序排列，每个都四舍五入到$6$位小数。", "solution": "该问题是有效的。这是一个结构良好的数值分析问题，基于椭圆型偏微分方程迭代方法的标准理论。所有参数、条件和要求的输出都得到了明确的规定。\n\n该问题要求实现并比较两种用于求解各向异性扩散方程的行松弛方案。任务的核心在于从基本原理推导每种方案的迭代更新规则。\n\n控制性偏微分方程（PDE）为：\n$$\n-\\partial_x\\big(\\alpha \\, \\partial_x u\\big) - \\partial_y\\big(\\beta \\, \\partial_y u\\big) = f\n$$\n在单位正方形$\\Omega=(0,1)\\times(0,1)$上，边界条件为齐次狄利克雷条件$u=0$ on $\\partial\\Omega$。系数为常数，$\\alpha = r$和$\\beta = 1$，其中$r \\ge 1$。源项为$f(x,y)=\\sin(\\pi x)\\sin(\\pi y)$。\n\n我们首先对区域和PDE进行离散化。使用一个具有$n_x$和$n_y$个内部点的均匀网格，网格间距为$h_x = 1/(n_x+1)$和$h_y = 1/(n_y+1)$。在内部网格节点$(i,j)$（其中$1 \\le i \\le n_x$和$1 \\le j \\le n_y$）处，对导数使用二阶中心差分近似，得到离散方程：\n$$\n-\\frac{\\alpha}{h_x^2}\\big(u_{i+1,j}-2u_{i,j}+u_{i-1,j}\\big) - \\frac{\\beta}{h_y^2}\\big(u_{i,j+1}-2u_{i,j}+u_{i,j-1}\\big) = f_{i,j}\n$$\n边界条件$u=0$意味着对于任何与边界相邻的节点，其在区域外的相应“虚拟”点上的$u$值为零。例如，对于$i=1$，有$u_{0,j}=0$；对于$j=n_y$，有$u_{i,n_y+1}=0$。\n\n让我们重新整理离散方程以分离出项$u_{i,j}$并识别耦合关系。设$C_x = \\alpha/h_x^2$和$C_y = \\beta/h_y^2$。方程变为：\n$$\n(2C_x + 2C_y)u_{i,j} - C_x(u_{i-1,j} + u_{i+1,j}) - C_y(u_{i,j-1} + u_{i,j+1}) = f_{i,j}\n$$\n这代表了大型线性方程组$Au=f$中的一个方程，该方程组用于求解网格内部所有未知值$u_{i,j}$。行松弛是一种用于构造高斯-赛德尔（Gauss-Seidel）型迭代以求解此系统的特定策略。\n\n**1. $x$-行松弛方案**\n\n在$x$-行松弛中，我们逐行扫描网格进行迭代，此例中是沿着水平线（固定的$j$）进行。扫描按字典正序从$j=1$到$n_y$进行。对于每一行$j$，我们同时求解所有未知数$u_{i,j}$（对于$i=1, \\dots, n_x$）。这意味着$x$方向的耦合（与$u_{i-1,j}$和$u_{i+1,j}$）被隐式处理。$y$方向的耦合（与$u_{i,j-1}$和$u_{i,j+1}$）则被显式处理，使用最新更新的值，这是高斯-赛德尔方法的核心。\n\n设$k$为完整扫描的迭代指数。对于固定的行$j$，我们正在计算未知量向量$u_{*,j}^{(k+1)}$。来自下一行$u_{*,j-1}$的值已在当前扫描中计算，因此我们使用$u_{*,j-1}^{(k+1)}$。来自上一行$u_{*,j+1}$的值来自前一次扫描，因此我们使用$u_{*,j+1}^{(k)}$。行$j$上未知数的方程组为：\n$$\n(2C_x + 2C_y)u_{i,j}^{(k+1)} - C_x u_{i-1,j}^{(k+1)} - C_x u_{i+1,j}^{(k+1)} = f_{i,j} + C_y u_{i,j-1}^{(k+1)} + C_y u_{i,j+1}^{(k)}\n$$\n对于$i=1, \\dots, n_x$。这是一个包含$n_x$个方程的三对角系统，用于求解$n_x$个未知数$u_{1,j}^{(k+1)}, \\dots, u_{n_x,j}^{(k+1)}$。该系统可以写成$T_x U_j^{(k+1)} = d_j$，其中$U_j^{(k+1)}$是行$j$上的未知数向量。三对角矩阵$T_x$具有：\n- 对角线元素：$2(C_x + C_y) = 2(\\alpha/h_x^2 + \\beta/h_y^2)$\n- 次对角线和超对角线元素：$-C_x = -\\alpha/h_x^2$\n\n右侧向量$d_j$的元素为：\n$$\n(d_j)_i = f_{i,j} + C_y\\left(u_{i,j-1}^{(k+1)} + u_{i,j+1}^{(k)}\\right)\n$$\n边界条件$u_{0,j}=0$和$u_{n_x+1,j}=0$被隐式地包含在内。对于从$1$到$n_y$的每个$j$，使用像Thomas算法这样的精确求解器来求解这个三对角系统。\n\n**2. $y$-行松弛方案**\n\n其推导与$x$-行的情况对称。我们沿垂直线（固定的$i$）从$i=1$到$n_x$扫描网格。对于每一行$i$，我们隐式求解未知数$u_{i,j}$（对于$j=1, \\dots, n_y$）。根据高斯-赛德尔原理，使用最新的值显式处理$x$方向的耦合。\n\n对于固定的行$i$，未知数$u_{i,*}^{(k+1)}$的系统为：\n$$\n(2C_x + 2C_y)u_{i,j}^{(k+1)} - C_y u_{i,j-1}^{(k+1)} - C_y u_{i,j+1}^{(k+1)} = f_{i,j} + C_x u_{i-1,j}^{(k+1)} + C_x u_{i+1,j}^{(k)}\n$$\n对于$j=1, \\dots, n_y$。这构成了一个三对角系统$T_y U_i^{(k+1)} = d_i$，用于求解行$i$上的未知数向量$U_i^{(k+1)}$。矩阵$T_y$具有：\n- 对角线元素：$2(C_x + C_y) = 2(\\alpha/h_x^2 + \\beta/h_y^2)$\n- 次对角线和超对角线元素：$-C_y = -\\beta/h_y^2$\n\n右侧向量$d_i$的元素为：\n$$\n(d_i)_j = f_{i,j} + C_x\\left(u_{i-1,j}^{(k+1)} + u_{i+1,j}^{(k)}\\right)\n$$\n对于从$1$到$n_x$的每个$i$，求解该系统。\n\n**3. 性能分析**\n\n该问题的特点是由$r = \\alpha/\\beta$控制的各向异性。当$r \\gg 1$时，$x$方向的耦合强度（与$C_x = r/h_x^2$成正比）远强于$y$方向的耦合强度（与$C_y = 1/h_y^2$成正比）。行松弛方法在隐式处理最强耦合时最为有效。因此，对于$r \\gg 1$的情况，预计$x$-行松弛（沿强耦合方向隐式求解）的收敛速度将远快于$y$-行松弛。当$r \\to 1$时，问题变为各向同性，两种方法的性能应该变得相同。\n\n收敛率由经验平均收敛因子$\\rho$量化，定义为：\n$$\n\\rho = \\left(\\frac{\\|r^{(N)}\\|_2}{\\|r^{(0)}\\|_2}\\right)^{1/N}\n$$\n这里，$r^{(k)} = f - Au^{(k)}$是$k$次扫描后的残差，范数是离散$L^2$范数：\n$$\n\\|r\\|_2 = \\left(h_x h_y \\sum_{i=1}^{n_x}\\sum_{j=1}^{n_y} r_{i,j}^2\\right)^{1/2}\n$$\n$\\rho$值越小，表示收敛越快。我们计算$x$-行松弛的$\\rho_x$和$y$-行松弛的$\\rho_y$，然后计算它们的比率$\\gamma = \\rho_y / \\rho_x$。根据上述推理，我们预期对于$r > 1$有$\\gamma > 1$，对于$r=1$有$\\gamma \\approx 1$。\n\n该算法包括初始化解$u^{(0)}=0$，计算初始残差范数$\\|r^{(0)}\\|_2$，然后对每种松弛方案运行$N$次迭代以找到$u^{(N)}$。然后使用最终残差范数$\\|r^{(N)}\\|_2$来计算$\\rho$，进而计算$\\gamma$。每次扫描内的三对角系统使用`scipy.linalg`中的`solve_banded`函数求解，这是一个高效且数值稳定的实现，等同于Thomas算法。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import solve_banded\n\ndef calculate_residual_norm(u_padded, f_interior, alpha, beta, hx, hy):\n    \"\"\"\n    Calculates the discrete L2-norm of the residual r = f - A*u.\n    \n    Args:\n        u_padded (np.ndarray): Solution array of size (nx+2, ny+2) with boundaries.\n        f_interior (np.ndarray): Source term array of size (nx, ny).\n        alpha, beta (float): Diffusion coefficients.\n        hx, hy (float): Grid spacings.\n\n    Returns:\n        float: The discrete L2-norm of the residual.\n    \"\"\"\n    nx, ny = f_interior.shape\n    u_int = u_padded[1:-1, 1:-1]\n    \n    # Central difference approximation of the operator A*u using slicing on the padded array\n    u_ip1 = u_padded[2:, 1:-1]\n    u_im1 = u_padded[:-2, 1:-1]\n    u_jp1 = u_padded[1:-1, 2:]\n    u_jm1 = u_padded[1:-1, :-2]\n\n    # Note the negative sign in the PDE definition\n    Au = -alpha * (u_ip1 - 2 * u_int + u_im1) / hx**2 \\\n         -beta  * (u_jp1 - 2 * u_int + u_jm1) / hy**2\n    \n    r_interior = f_interior - Au\n    \n    # Discrete L2 norm: sqrt(hx*hy * sum(r_ij^2))\n    norm = np.linalg.norm(r_interior) * np.sqrt(hx * hy)\n    return norm\n\n\ndef solve_x_line(nx, ny, hx, hy, alpha, beta, f_interior, N):\n    \"\"\"\n    Solves the system using x-line relaxation for N sweeps.\n    \"\"\"\n    u = np.zeros((nx + 2, ny + 2))\n    \n    Cx = alpha / hx**2\n    Cy = beta / hy**2\n    \n    # Pre-assemble the constant tridiagonal matrix for all x-lines\n    diag_x = np.full(nx, 2 * Cx + 2 * Cy)\n    off_diag_x = np.full(nx - 1, -Cx)\n    A_x_banded = np.zeros((3, nx))\n    A_x_banded[0, 1:] = off_diag_x\n    A_x_banded[1, :] = diag_x\n    A_x_banded[2, :-1] = off_diag_x\n    \n    for _ in range(N):\n        u_prev_sweep = u.copy()\n        # Sweep along y-direction (fixed j), solving for lines in x\n        for j_pad in range(1, ny + 1):\n            j_py = j_pad - 1\n            # RHS: f_ij + C_y * (u_{i,j-1}^{(k+1)} + u_{i,j+1}^{(k)})\n            # u values from line j-1 are from the current sweep (u).\n            # u values from line j+1 are from the previous sweep (u_prev_sweep).\n            rhs = f_interior[:, j_py] + Cy * (u[1:-1, j_pad - 1] + u_prev_sweep[1:-1, j_pad + 1])\n            \n            line_solution = solve_banded((1, 1), A_x_banded, rhs)\n            u[1:-1, j_pad] = line_solution\n            \n    return u\n\n\ndef solve_y_line(nx, ny, hx, hy, alpha, beta, f_interior, N):\n    \"\"\"\n    Solves the system using y-line relaxation for N sweeps.\n    \"\"\"\n    u = np.zeros((nx + 2, ny + 2))\n    \n    Cx = alpha / hx**2\n    Cy = beta / hy**2\n    \n    # Pre-assemble the constant tridiagonal matrix for all y-lines\n    diag_y = np.full(ny, 2 * Cx + 2 * Cy)\n    off_diag_y = np.full(ny-1, -Cy)\n    A_y_banded = np.zeros((3, ny))\n    A_y_banded[0, 1:] = off_diag_y\n    A_y_banded[1, :] = diag_y\n    A_y_banded[2, :-1] = off_diag_y\n\n    for _ in range(N):\n        u_prev_sweep = u.copy()\n        # Sweep along x-direction (fixed i), solving for lines in y\n        for i_pad in range(1, nx + 1):\n            i_py = i_pad - 1\n            # RHS: f_ij + C_x * (u_{i-1,j}^{(k+1)} + u_{i+1,j}^{(k)})\n            # u values from line i-1 are from the current sweep (u).\n            # u values from line i+1 are from the previous sweep (u_prev_sweep).\n            rhs = f_interior[i_py, :] + Cx * (u[i_pad - 1, 1:-1] + u_prev_sweep[i_pad + 1, 1:-1])\n\n            line_solution = solve_banded((1, 1), A_y_banded, rhs)\n            u[i_pad, 1:-1] = line_solution\n            \n    return u\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (64, 64, 1000.0, 8),\n        (64, 64, 10.0, 8),\n        (64, 64, 1.0, 8),\n    ]\n\n    results = []\n    for case in test_cases:\n        nx, ny, r, N = case\n        \n        # Setup grid and problem parameters\n        alpha = r\n        beta = 1.0\n        hx = 1.0 / (nx + 1)\n        hy = 1.0 / (ny + 1)\n        \n        # Create grid coordinates for interior points\n        x_coords = np.linspace(hx, 1.0 - hx, nx)\n        y_coords = np.linspace(hy, 1.0 - hy, ny)\n        X, Y = np.meshgrid(x_coords, y_coords, indexing='ij')\n        \n        # Source term f(x,y)\n        f_interior = np.sin(np.pi * X) * np.sin(np.pi * Y)\n        \n        # Initial condition u=0 and initial residual\n        u0_padded = np.zeros((nx + 2, ny + 2))\n        r0_norm = calculate_residual_norm(u0_padded, f_interior, alpha, beta, hx, hy)\n\n        # X-line relaxation\n        uN_x = solve_x_line(nx, ny, hx, hy, alpha, beta, f_interior, N)\n        rN_x_norm = calculate_residual_norm(uN_x, f_interior, alpha, beta, hx, hy)\n        rho_x = (rN_x_norm / r0_norm)**(1.0 / N)\n        \n        # Y-line relaxation\n        uN_y = solve_y_line(nx, ny, hx, hy, alpha, beta, f_interior, N)\n        rN_y_norm = calculate_residual_norm(uN_y, f_interior, alpha, beta, hx, hy)\n        rho_y = (rN_y_norm / r0_norm)**(1.0 / N)\n        \n        # Compute the ratio gamma\n        gamma = rho_y / rho_x\n        results.append(round(gamma, 6))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3148150"}, {"introduction": "除了改进现有的迭代格式，我们还可以构造全新的、更高效的迭代方法。本练习将向你介绍一种基于多项式逼近理论的强大技术——切比雪夫半迭代法。你将从第一性原理出发，推导如何利用切比雪夫多项式的极小极大性质来选择最优的迭代步长序列，并通过一个矩阵无关的实现来加速求解泊松方程。这个过程将让你体会到谱方法思想在设计迭代求解器中的巨大威力。[@problem_id:3148184]", "problem": "您被要求设计并实现一个完整的数值实验，将切比雪夫半迭代应用于一个由椭圆偏微分方程（PDE）的标准有限差分格式离散化产生的对称正定（SPD）线性系统。该 SPD 系统为 $A u = b$，通过在单位正方形 $[0,1]\\times[0,1]$ 上对泊松方程 $-\\nabla^2 u = f$ 施加齐次狄利克雷边界条件进行离散化得到。您的任务是推导、实现并评估一种切比雪夫半迭代方法，该方法使用对 $A$ 的特征值极值界的估计来选择步长。推导必须从拉普拉斯算子的基本有限差分近似和切比雪夫多项式的极小极大性质开始，且不应预先假设任何迭代公式。\n\n背景与设置：\n- 在一个均匀网格上离散化 $-\\nabla^2 u = f$，每个坐标方向有 $N$ 个内部点，网格间距为 $h = 1/(N+1)$，边界上施加齐次狄利克雷边界数据 $u=0$。使用标准的 $5$ 点格式来近似 $-\\nabla^2$：在一个内部网格节点 $(i,j)$ 处，\n  $$\n  \\left(-\\nabla^2 u\\right)_{i,j} \\approx \\frac{4 u_{i,j} - u_{i-1,j} - u_{i+1,j} - u_{i,j-1} - u_{i,j+1}}{h^2}.\n  $$\n  通过一个无矩阵算子隐式地构建相关的 SPD 矩阵 $A$，并通过在内部网格点上对 $f$ 进行采样来形成 $b$。使用 $f(x,y) = 2\\pi^2 \\sin(\\pi x)\\sin(\\pi y)$，这样连续问题对应的光滑解析解为 $u(x,y) = \\sin(\\pi x)\\sin(\\pi y)$。\n\n- 将切比雪夫半迭代实现为形式为 $x^{(k+1)} = x^{(k)} + \\omega_k r^{(k)}$ 的定常迭代，其中 $r^{(k)} = b - A x^{(k)}$，步长 $\\omega_k$ 使用 $A$ 的特征值极值界来选择。您必须：\n  1. 从切比雪夫多项式的定义及其在 $[-1,1]$ 上的极小极大性质开始。\n  2. 将谱区间 $[\\lambda_{\\min}, \\lambda_{\\max}]$ 映射到 $[-1,1]$，并推导出在预设的多项式次数 $m$ 后，使区间内残差放大最大值最小化的步长序列 $\\{\\omega_k\\}_{k=1}^m$。\n  3. 实现使用这些 $\\omega_k$ 的 $m$ 步切比雪夫半迭代，而不显式地构造 $A$。\n\n- 谱界：对于在 $N \\times N$ 内部网格上具有齐次狄利克雷边界的 $5$ 点拉普拉斯算子，一个经过充分检验的事实是，$A$ 的特征值位于一个区间 $[\\lambda_{\\min}^{\\mathrm{ex}}, \\lambda_{\\max}^{\\mathrm{ex}}]$ 内，该区间可以从一维特征值计算得出。具体来说，对于 $h = 1/(N+1)$ 和索引 $p,q \\in \\{1,2,\\dots,N\\}$，\n  $$\n  \\lambda_{p,q} = \\frac{4}{h^2}\\sin^2\\left(\\frac{\\pi p}{2(N+1)}\\right) + \\frac{4}{h^2}\\sin^2\\left(\\frac{\\pi q}{2(N+1)}\\right),\n  $$\n  因此，$\\lambda_{\\min}^{\\mathrm{ex}}$ 和 $\\lambda_{\\max}^{\\mathrm{ex}}$ 分别在 $(p,q)=(1,1)$ 和 $(p,q)=(N,N)$ 处取得。在本作业中，您必须使用估计值\n  $$\n  \\lambda_{\\min} = s_{\\ell}\\,\\lambda_{\\min}^{\\mathrm{ex}}, \\quad \\lambda_{\\max} = s_{u}\\,\\lambda_{\\max}^{\\mathrm{ex}},\n  $$\n  其中 $s_{\\ell}0$ 和 $s_u0$是为每个测试用例给定的缩放因子，用以模拟不完美的先验知识。这些界的质量将影响迭代的有效性。所有三角函数计算必须使用以弧度为单位的角度。\n\n- 您的程序必须：\n  1. 通过在内部网格点 $(x_i,y_j)=(ih,jh)$（其中 $i,j\\in\\{1,\\dots,N\\}$）对 $f$ 进行采样来构建 $b$。\n  2. 使用 $x^{(0)}=0$ 进行初始化。\n  3. 运行恰好 $m$ 步的切比雪夫半迭代，步长由您对区间 $[\\lambda_{\\min},\\lambda_{\\max}]$ 的分析推导得出。\n  4. 对每个测试用例，返回相对残差范数 $\\|r^{(m)}\\|_2/\\|b\\|_2$ 作为一个浮点数，其中 $r^{(m)}=b-Ax^{(m)}$。\n  5. 不要显式地构建 $A$；通过 $5$ 点格式应用 $A$ 于向量。\n\n测试套件：\n- 使用以下四个测试用例，每个由 $(N, m, s_{\\ell}, s_u)$ 指定：\n  1. $(N, m, s_{\\ell}, s_u) = (\\,31,\\,10,\\,1.0,\\,1.0\\,)$.\n  2. $(N, m, s_{\\ell}, s_u) = (\\,31,\\,10,\\,0.8,\\,1.2\\,)$.\n  3. $(N, m, s_{\\ell}, s_u) = (\\,63,\\,20,\\,1.0,\\,1.0\\,)$.\n  4. $(N, m, s_{\\ell}, s_u) = (\\,7,\\,4,\\,0.6,\\,1.4\\,)$.\n\n可量化的输出：\n- 对于每个测试用例，计算标量值 $q = \\|r^{(m)}\\|_2/\\|b\\|_2$ 并将其四舍五入到 $8$ 位小数。\n- 您的程序应产生单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，顺序与上面显示的测试用例相同，例如 $[q_1,q_2,q_3,q_4]$。\n\n约束和说明：\n- 实现必须是无矩阵的，不得形成稠密矩阵。使用 $5$ 点格式算子来应用 $A$。\n- 通过使用您从切比雪夫推导中获得的步长来确保数值稳定性。\n- 所有计算必须在无量纲单位中进行，所有角度必须以弧度为单位。", "solution": "任务是设计、推导和实现一个切比雪夫半迭代方法，以求解对称正定（SPD）线性系统 $Ax=b$。该系统源于单位正方形上泊松方程的有限差分离散化。推导必须从基本原理开始，实现必须是无矩阵的。\n\n### 1. 离散化问题\n\n泊松方程 $-\\nabla^2 u = f$ 在域 $[0,1]\\times[0,1]$ 上使用均匀网格进行离散化，边界条件为齐次狄利克雷条件（即边界上 $u=0$）。网格在每个坐标方向上有 $N$ 个内部点，网格间距为 $h = 1/(N+1)$。负拉普拉斯算子在内部网格节点 $(i,j)$ 处的标准 $5$ 点有限差分格式为\n$$\n(-\\nabla^2 u)_{i,j} \\approx \\frac{4 u_{i,j} - u_{i-1,j} - u_{i+1,j} - u_{i,j-1} - u_{i,j+1}}{h^2}\n$$\n这种离散化产生一个大小为 $N^2 \\times N^2$ 的稀疏、SPD 线性方程组 $Ax=b$，其中 $x$ 是一个表示 $N^2$ 个内部网格点上 $u$ 值的向量。矩阵 $A$ 是离散拉普拉斯算子，向量 $b$ 是通过在内部网格点上评估源函数 $f(x,y) = 2\\pi^2 \\sin(\\pi x)\\sin(\\pi y)$ 得到的。我们被要求将算子 A 应用于向量，而无需显式构建矩阵 A。\n\n### 2. 切比雪夫半迭代\n\n问题指定了一种迭代方法，形式如下：\n$$\nx^{(k+1)} = x^{(k)} + \\omega_k r^{(k)}, \\quad \\text{其中 } r^{(k)} = b - Ax^{(k)}\n$$\n这是一种非定常理查森迭代。我们来分析残差的传播。\n$$\nr^{(k+1)} = b - Ax^{(k+1)} = b - A(x^{(k)} + \\omega_k r^{(k)}) = (b - Ax^{(k)}) - \\omega_k A r^{(k)} = r^{(k)} - \\omega_k A r^{(k)} = (I - \\omega_k A)r^{(k)}\n$$\n从初始猜测 $x^{(0)}$ 及其残差 $r^{(0)} = b - Ax^{(0)}$ 开始，经过 $m$ 步迭代后，残差变为：\n$$\nr^{(m)} = \\left( \\prod_{k=0}^{m-1} (I - \\omega_k A) \\right) r^{(0)}\n$$\n令 $R_m(\\lambda) = \\prod_{k=0}^{m-1} (1-\\omega_k \\lambda)$。这是一个关于 $\\lambda$ 的 $m$ 次多项式。我们可以将残差关系写为 $r^{(m)} = R_m(A)r^{(0)}$。这个多项式的一个关键性质是 $R_m(0) = \\prod_{k=0}^{m-1} (1-0)=1$。\n\n我们的目标是在 $m$ 步后最小化误差。由于 $A$ 是 SPD 矩阵，它的特征向量构成一组基。最小化残差 $r^{(m)}$ 的范数，可以通过找到一个在 $A$ 的谱上幅度最小的多项式 $R_m(\\lambda)$ 来实现，同时要满足约束条件 $R_m(0)=1$。$A$ 的谱，记作 $\\sigma(A)$，位于区间 $[\\lambda_{\\min}^{\\mathrm{ex}}, \\lambda_{\\max}^{\\mathrm{ex}}]$ 内。我们已知这些界的估计值 $[\\lambda_{\\min}, \\lambda_{\\max}]$。因此，问题变成了一个约束极小极大问题：\n$$\n\\min_{R_m} \\max_{\\lambda \\in [\\lambda_{\\min}, \\lambda_{\\max}]} |R_m(\\lambda)| \\quad \\text{满足 } R_m(0)=1 \\text{ 且 } \\deg(R_m) \\le m\n$$\n\n### 3. 最优参数的推导\n\n这个极小极大问题由切比雪夫多项式解决。第一类切比雪夫多项式 $T_m(z)$ 是在所有同次数的首一多项式中，在 $[-1,1]$ 上最大绝对值最小的唯一多项式。一个相关的性质是，对于任何点 $z_0 \\notin [-1,1]$，满足 $P_m(z_0)=1$ 且最小化 $\\max_{z \\in [-1,1]} |P_m(z)|$ 的 $m$ 次多项式 $P_m(z)$ 由 $P_m(z) = T_m(z)/T_m(z_0)$ 给出。\n\n我们首先使用线性变换将谱区间 $[\\lambda_{\\min}, \\lambda_{\\max}]$ 映射到区间 $[-1,1]$：\n$$\nz(\\lambda) = \\frac{2\\lambda - (\\lambda_{\\max}+\\lambda_{\\min})}{\\lambda_{\\max}-\\lambda_{\\min}}\n$$\n我们的约束是 $R_m(0)=1$。我们在 $z$ 域中找到对应于 $\\lambda=0$ 的点：\n$$\nz_0 = z(0) = -\\frac{\\lambda_{\\max}+\\lambda_{\\min}}{\\lambda_{\\max}-\\lambda_{\\min}}\n$$\n由于 $A$ 是 SPD 的，所以 $0  \\lambda_{\\min} \\le \\lambda_{\\max}$，这意味着 $z_0  -1$。\n最优残差多项式 $R_m(\\lambda)$ 于是由下式给出：\n$$\nR_m(\\lambda) = \\frac{T_m(z(\\lambda))}{T_m(z_0)} = \\frac{T_m\\left(\\frac{2\\lambda - \\lambda_{\\max} - \\lambda_{\\min}}{\\lambda_{\\max}-\\lambda_{\\min}}\\right)}{T_m\\left(-\\frac{\\lambda_{\\max}+\\lambda_{\\min}}{\\lambda_{\\max}-\\lambda_{\\min}}\\right)}\n$$\n迭代参数 $\\omega_k$ 由 $R_m(\\lambda)$ 的根确定。$R_m(\\lambda)$ 的根是使得 $T_m(z(\\lambda))=0$ 的 $\\lambda$ 值。$T_m(z)$ 的根由下式给出：\n$$\n\\hat{z}_k = \\cos\\left(\\frac{(2k-1)\\pi}{2m}\\right), \\quad k=1, 2, \\dots, m\n$$\n我们通过对线性映射 $z(\\lambda)$ 求逆来找到 $R_m(\\lambda)$ 对应的根 $\\lambda_k^*$：\n$$\n\\lambda_k^* = \\frac{\\lambda_{\\max}+\\lambda_{\\min}}{2} + \\frac{\\lambda_{\\max}-\\lambda_{\\min}}{2} \\hat{z}_k = \\frac{\\lambda_{\\max}+\\lambda_{\\min}}{2} + \\frac{\\lambda_{\\max}-\\lambda_{\\min}}{2}\\cos\\left(\\frac{(2k-1)\\pi}{2m}\\right)\n$$\n残差多项式是 $R_m(\\lambda) = \\prod (1-\\omega_k \\lambda)$，所以它的根是 $1/\\omega_k$。因此，最优步长是根 $\\lambda_k^*$ 的倒数：\n$$\n\\omega_k = \\frac{1}{\\lambda_k^*} = \\left( \\frac{\\lambda_{\\max}+\\lambda_{\\min}}{2} + \\frac{\\lambda_{\\max}-\\lambda_{\\min}}{2}\\cos\\left(\\frac{(2k-1)\\pi}{2m}\\right) \\right)^{-1}, \\quad k=1, 2, \\dots, m\n$$\n$R_m(A)$ 中的乘积是可交换的，所以使用这 $m$ 个步长的顺序不影响 $m$ 次迭代后的最终结果。\n\n### 4. 算法总结\n\n对于每个测试用例 $(N, m, s_{\\ell}, s_u)$：\n1.  计算网格间距 $h=1/(N+1)$。\n2.  通过在 $N^2$ 个内部网格点上采样 $f(x,y)$ 来构建大小为 $N^2$ 的右端向量 $b$。\n3.  计算离散算子 $A$ 的精确特征值界：\n    $$\n    \\lambda_{\\min}^{\\mathrm{ex}} = \\frac{8}{h^2}\\sin^2\\left(\\frac{\\pi}{2(N+1)}\\right), \\quad \\lambda_{\\max}^{\\mathrm{ex}} = \\frac{8}{h^2}\\cos^2\\left(\\frac{\\pi}{2(N+1)}\\right)\n    $$\n4.  应用缩放因子得到迭代的估计界：$\\lambda_{\\min} = s_{\\ell} \\lambda_{\\min}^{\\mathrm{ex}}$ 和 $\\lambda_{\\max} = s_{u} \\lambda_{\\max}^{\\mathrm{ex}}$。\n5.  使用上面推导的公式计算 $m$ 个切比雪夫步长 $\\{\\omega_k\\}_{k=1}^m$。\n6.  初始化解向量 $x^{(0)} = 0$。\n7.  迭代 $k$ 从 $0$ 到 $m-1$：\n    a. 使用一个用于表示 A 作用的无矩阵函数计算残差 $r^{(k)} = b - Ax^{(k)}$。\n    b. 更新解 $x^{(k+1)} = x^{(k)} + \\omega_{k+1} r^{(k)}$。\n8.  $m$ 步之后，计算最终残差 $r^{(m)} = b - Ax^{(m)}$。\n9.  最终输出是相对残差范数 $q = \\|r^{(m)}\\|_2 / \\|b\\|_2$。", "answer": "```python\n# 完整的、可运行的 Python 3 代码如下。\n# 导入必须遵守指定的执行环境。\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    解决对一组预定义的测试用例，将切比雪夫半迭代应用于离散化泊松方程的问题。\n    \"\"\"\n    \n    # 定义问题描述中的测试用例。\n    test_cases = [\n        (31, 10, 1.0, 1.0),\n        (31, 10, 0.8, 1.2),\n        (63, 20, 1.0, 1.0),\n        (7, 4, 0.6, 1.4),\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        N, m, s_ell, s_u = case\n        \n        # 1. 设置\n        h = 1.0 / (N + 1)\n        \n        # 用于评估源函数 f(x,y) 的网格点\n        grid_pts = np.linspace(h, 1.0 - h, N)\n        X, Y = np.meshgrid(grid_pts, grid_pts)\n        \n        # 通过对 f 采样来构建右端向量 b\n        f_vals = 2 * np.pi**2 * np.sin(np.pi * X) * np.sin(np.pi * Y)\n        b = f_vals.flatten()\n        b_norm = np.linalg.norm(b)\n\n        # 2. 谱界计算\n        # 5点离散拉普拉斯算子的精确极值特征值\n        lambda_min_ex = (8.0 / h**2) * (np.sin(np.pi / (2.0 * (N + 1))))**2\n        lambda_max_ex = (8.0 / h**2) * (np.cos(np.pi / (2.0 * (N + 1))))**2\n        \n        # 用于切比雪夫迭代的估计界\n        lambda_min = s_ell * lambda_min_ex\n        lambda_max = s_u * lambda_max_ex\n\n        # 3. 切比雪夫步长 (omegas) 推导\n        omegas = np.zeros(m)\n        center = (lambda_max + lambda_min) / 2.0\n        radius = (lambda_max - lambda_min) / 2.0\n        \n        for k in range(1, m + 1):\n            chebyshev_root = np.cos((2.0 * k - 1.0) * np.pi / (2.0 * m))\n            polynomial_root = center + radius * chebyshev_root\n            omegas[k-1] = 1.0 / polynomial_root\n\n        # 4. 无矩阵算子 A (离散拉普拉斯算子)\n        def apply_A(x_vec):\n            \"\"\"将 5 点格式算子 A 应用于向量 x_vec。\"\"\"\n            x_grid = x_vec.reshape((N, N))\n            \n            # 从 4*u_ij 开始\n            Ax_grid = 4.0 * x_grid\n            \n            # 减去邻居 (u_i-1,j, u_i+1,j, u_i,j-1, u_i,j+1)\n            # 这些切片操作正确处理了边界条件，\n            # 因为缺失的邻居被隐式地视为零 (不进行减法)。\n            if N > 1:\n                Ax_grid[1:, :] -= x_grid[:-1, :]  # u_i-1,j\n                Ax_grid[:-1, :] -= x_grid[1:, :]  # u_i+1,j\n                Ax_grid[:, 1:] -= x_grid[:, :-1]  # u_i,j-1\n                Ax_grid[:, :-1] -= x_grid[:, 1:]  # u_i,j+1\n\n            return Ax_grid.flatten() / h**2\n\n        # 5. 切比雪夫迭代\n        # 初始化解向量 x^(0) = 0\n        x = np.zeros(N * N)\n        \n        # 运行 m 步迭代：x^(k+1) = x^(k) + omega_k * r^(k)\n        for k in range(m):\n            residual = b - apply_A(x)\n            x = x + omegas[k] * residual\n\n        # 6. 最终评估\n        # 计算最终残差 r^(m) = b - A*x^(m)\n        final_residual = b - apply_A(x)\n        \n        # 计算相对残差范数并四舍五入到 8 位小数\n        q = np.linalg.norm(final_residual) / b_norm\n        results.append(round(q, 8))\n\n    # 最终的打印语句采用确切的所需格式。\n    # f-string 中的格式说明符处理了像 '0.1' 而不是 '0.10000000' 的情况\n    # 因此我们需要正确地格式化它。使用 map(str,...) 是可以的，因为 round() 已经固定了精度。\n    formatted_results = [f\"{r:.8f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3148184"}]}