{"hands_on_practices": [{"introduction": "在深入掌握整个迭代过程之前，理解算法的单次迭代至关重要。本练习将逆幂法分解为其最基本的组成部分：求解移位的线性系统。通过完成这一计算，您将亲身体验驱动整个算法的核心数学运算，为后续更复杂的应用打下坚实的基础。[@problem_id:1395843]", "problem": "在一个数值算法中，从一个初始向量 $x_0$ 开始生成一个向量序列。该序列中的第一个非归一化向量（记为 $y_1$）是通过求解线性系统 $(A-\\sigma I)y_1 = x_0$ 得到的，其中 $A$ 是一个方阵，$\\sigma$ 是一个标量位移，$I$ 是与 $A$ 相同维度的单位矩阵。\n\n给定矩阵 $A = \\begin{pmatrix} 3  -1 \\\\ -1  3 \\end{pmatrix}$，位移 $\\sigma = 1.5$ 和初始向量 $x_0 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$，请确定向量 $y_1$ 的分量。请将答案表示为一个行矩阵，其中每个分量都以精确的分数或小数形式给出。", "solution": "我们要求解关于 $y_{1}$ 的线性系统 $(A-\\sigma I) y_{1} = x_{0}$，其中 $A = \\begin{pmatrix} 3  -1 \\\\ -1  3 \\end{pmatrix}$，$\\sigma = \\frac{3}{2}$，以及 $x_{0} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$。\n\n首先计算位移后的矩阵：\n$$\nA - \\sigma I = \\begin{pmatrix} 3  -1 \\\\ -1  3 \\end{pmatrix} - \\frac{3}{2} \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} \\frac{3}{2}  -1 \\\\ -1  \\frac{3}{2} \\end{pmatrix}.\n$$\n记 $M = A - \\sigma I$。则 $y_{1} = M^{-1} x_{0}$。对于一个 $2 \\times 2$ 矩阵 $M = \\begin{pmatrix} a  b \\\\ c  d \\end{pmatrix}$，我们使用 $M^{-1} = \\frac{1}{\\det(M)} \\begin{pmatrix} d  -b \\\\ -c  a \\end{pmatrix}$。此处 $a = d = \\frac{3}{2}$ 且 $b = c = -1$，所以\n$$\n\\det(M) = \\left(\\frac{3}{2}\\right)\\left(\\frac{3}{2}\\right) - (-1)(-1) = \\frac{9}{4} - 1 = \\frac{5}{4},\n$$\n以及\n$$\n\\operatorname{adj}(M) = \\begin{pmatrix} \\frac{3}{2}  1 \\\\ 1  \\frac{3}{2} \\end{pmatrix}.\n$$\n因此，\n$$\nM^{-1} = \\frac{1}{\\frac{5}{4}} \\begin{pmatrix} \\frac{3}{2}  1 \\\\ 1  \\frac{3}{2} \\end{pmatrix} = \\frac{4}{5} \\begin{pmatrix} \\frac{3}{2}  1 \\\\ 1  \\frac{3}{2} \\end{pmatrix}.\n$$\n乘以 $x_{0}$，\n$$\ny_{1} = M^{-1} x_{0} = \\frac{4}{5} \\begin{pmatrix} \\frac{3}{2}  1 \\\\ 1  \\frac{3}{2} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\frac{4}{5} \\begin{pmatrix} \\frac{3}{2} \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} \\frac{6}{5} \\\\ \\frac{4}{5} \\end{pmatrix}.\n$$\n因此，$y_{1}$ 的分量是 $\\frac{6}{5}$ 和 $\\frac{4}{5}$，我们将其表示为一个行矩阵。", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{6}{5}  \\frac{4}{5} \\end{pmatrix}}$$", "id": "1395843"}, {"introduction": "逆幂法是寻找特定特征值-特征向量对的有力工具。这个思想实验将帮助您弄清楚标准（无移位）逆幂法会自然地收敛到哪个特征值和对应的特征向量。理解这一原理对于有效运用该方法并预测其结果至关重要，它揭示了该算法在没有指定目标时默认会寻找“最小”的特征值。[@problem_id:1395849]", "problem": "一位计算物理学家正在为一个量子系统稳定性进行建模。该系统的哈密顿量由一个大型复矩阵 $H$ 表示。虽然完整的矩阵难以处理，但一项理论分析表明，其四个不同的能量特征值为 $\\{-6.5, -1.2, 0.9, 4.8\\}$，单位为某个任意的能量单位。\n\n为了找到该系统的基态特征向量（对应于能量最低的特征值），这位物理学家考虑使用一种迭代数值方法。然而，由于一个误解，他们对矩阵 $H$ 实施了标准的（无位移的）反幂法。他们使用了一个随机生成的初始向量，该向量在每个特征向量的方向上都有非零分量。\n\n假设该数值方法在没有精度或浮点误差问题的情况下收敛，它找到的特征向量将对应于给定的哪个特征值？\n\nA. $-6.5$\n\nB. $-1.2$\n\nC. $0.9$\n\nD. $4.8$", "solution": "设 $H$ 是可对角化的，具有不同的特征值 $\\{\\lambda_{i}\\}$ 和相应的特征向量 $\\{v_{i}\\}$。设初始向量为 $x_{0}=\\sum_{i} c_{i} v_{i}$，其中对于所有 $i$ 都有 $c_{i} \\neq 0$。\n\n应用于矩阵 $A$ 的标准幂法（在通常的非亏损和分离假设下）收敛到与 $A$ 的模最大特征值相关联的特征向量。在 $H$ 上应用反幂法，恰好等同于在 $H^{-1}$ 上应用幂法。\n\n如果 $\\lambda_{i}$ 是 $H$ 的特征值，那么 $H^{-1}$ 的特征值为\n$$\n\\mu_{i}=\\frac{1}{\\lambda_{i}},\n$$\n其特征向量与 $H$ 的特征向量 $v_{i}$ 相同。经过 $k$ 步反向迭代（为清晰起见，忽略归一化），可得\n$$\n(H^{-1})^{k} x_{0}=(H^{-1})^{k} \\sum_{i} c_{i} v_{i}=\\sum_{i} c_{i} \\left(\\frac{1}{\\lambda_{i}}\\right)^{k} v_{i}.\n$$\n当 $k \\to \\infty$ 时，具有最大 $|\\mu_{i}|=|1/\\lambda_{i}|$ 的项占主导地位，即具有最小 $|\\lambda_{i}|$ 的项。因此，无位移的反幂法收敛到与 $H$ 的绝对值最小的特征值相对应的特征向量。\n\n给定特征值 $\\{-6.5, -1.2, 0.9, 4.8\\}$，它们的绝对值为 $\\{6.5, 1.2, 0.9, 4.8\\}$。最小的绝对值是 $0.9$，因此该方法收敛到与 $\\lambda=0.9$ 相关联的特征向量。\n\n因此，在提供的选项中，正确的是 C。", "answer": "$$\\boxed{C}$$", "id": "1395849"}, {"introduction": "虽然带移位的逆幂法通常会收敛到其特征值最接近移位量 $\\sigma$ 的特征向量，但这并非绝对的保证。本问题探讨了一个有趣的例外情况，揭示了初始向量的关键作用。通过分析这个特殊场景，您将看到初始向量的构成如何能够引导算法收敛到另一个“意想不到”的特征向量，从而深化对算法收敛行为的理解。[@problem_id:1395866]", "problem": "考虑如下给出的实值矩阵 $A$：\n$$A = \\begin{pmatrix} 2.5  -1.5  0 \\\\ -1.5  2.5  0 \\\\ 0  0  5 \\end{pmatrix}$$\n该矩阵的特征值为 $\\lambda_1 = 1$，$\\lambda_2 = 4$ 和 $\\lambda_3 = 5$。对应的未归一化特征向量分别为 $v_1 = [1, 1, 0]^T$，$v_2 = [1, -1, 0]^T$ 和 $v_3 = [0, 0, 1]^T$。\n\n使用反幂法来寻找矩阵 $A$ 的一个特征值-特征向量对。该方法从一个初始向量 $x_0$ 开始，并使用一个位移 $\\sigma$。迭代步骤定义为：求解 $(A - \\sigma I) y_{k+1} = x_k$ 得到 $y_{k+1}$，然后进行归一化以获得下一个向量 $x_{k+1} = y_{k+1} / \\|y_{k+1}\\|$。当 $k \\to \\infty$ 时，向量 $x_k$ 收敛到 $A$ 的一个特征向量。\n\n假设该方法以位移 $\\sigma = 0.9$ 和初始向量 $x_0 = [1, -1, 1]^T$ 执行。向量序列 $\\{x_k\\}$ 将收敛到 $A$ 的一个特征向量。确定与此特征向量对应的特征值。", "solution": "带位移 $\\sigma$ 的反幂法应用以下迭代：\n$$ (A-\\sigma I) y_{k+1} = x_{k}, \\quad x_{k+1} = \\frac{y_{k+1}}{\\|y_{k+1}\\|}. $$\n设 $A$ 的特征对为 $(\\lambda_{i}, v_{i})$，其中 $i \\in \\{1,2,3\\}$，且 $\\lambda_{1}=1$，$\\lambda_{2}=4$，$\\lambda_{3}=5$ 以及 $v_{1} = [1, 1, 0]^{T}$，$v_{2} = [1, -1, 0]^{T}$，$v_{3} = [0, 0, 1]^{T}$。\n\n将初始向量在特征基上分解：\n$$\nx_{0} = \\alpha_{1} v_{1} + \\alpha_{2} v_{2} + \\alpha_{3} v_{3}.\n$$\n匹配分量，对于前两个分量，我们求解\n$$\n\\alpha_{1} + \\alpha_{2} = 1, \\quad \\alpha_{1} - \\alpha_{2} = -1,\n$$\n解得 $\\alpha_{1} = 0$，$\\alpha_{2} = 1$。对于第三个分量，我们有 $\\alpha_{3} = 1$。因此\n$$\nx_{0} = 0 \\cdot v_{1} + 1 \\cdot v_{2} + 1 \\cdot v_{3}.\n$$\n\n因为 $(A-\\sigma I) v_{i} = (\\lambda_{i} - \\sigma) v_{i}$，所以\n$$\n(A-\\sigma I)^{-1} v_{i} = \\frac{1}{\\lambda_{i} - \\sigma} \\, v_{i}.\n$$\n经过 $k$ 次反幂迭代（归一化之前），向量与下式成比例\n$$\n\\sum_{i=1}^{3} \\alpha_{i} (\\lambda_{i} - \\sigma)^{-k} v_{i}.\n$$\n因此，当 $k \\to \\infty$ 时，在所有 $\\alpha_{i} \\neq 0$ 的分量中，具有最大因子 $\\left|(\\lambda_{i} - \\sigma)^{-1}\\right|$ 的分量将占主导地位。\n\n当 $\\sigma = 0.9$ 时，我们有\n$$\n\\left|\\frac{1}{\\lambda_{2} - \\sigma}\\right| = \\frac{1}{|4 - 0.9|} = \\frac{1}{3.1}, \\qquad\n\\left|\\frac{1}{\\lambda_{3} - \\sigma}\\right| = \\frac{1}{|5 - 0.9|} = \\frac{1}{4.1}.\n$$\n由于 $\\frac{1}{3.1} > \\frac{1}{4.1}$ 且 $\\alpha_{2}, \\alpha_{3} \\neq 0$ 但 $\\alpha_{1} = 0$，序列 $\\{x_{k}\\}$ 收敛到对应于 $\\lambda_{2} = 4$ 的特征向量 $v_{2}$。\n\n因此，与极限特征向量对应的特征值是 $4$。", "answer": "$$\\boxed{4}$$", "id": "1395866"}]}