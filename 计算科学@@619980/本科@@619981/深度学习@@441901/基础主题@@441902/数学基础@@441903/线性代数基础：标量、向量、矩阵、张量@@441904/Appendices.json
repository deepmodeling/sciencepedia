{"hands_on_practices": [{"introduction": "这个练习着重于张量操作的基本性质，超越了简单的数值检查。通过设计基于数学不变性的单元测试，你将对线性变换的定义有更深刻的理解，并学会如何确保代码在语义上是正确的。这对于调试复杂模型来说是一项至关重要的技能 [@problem_id:3143508]。", "problem": "一位数据科学家使用张量收缩在序列模型中实现一个线性层。设 $X \\in \\mathbb{R}^{B \\times T \\times D}$ 表示一个小批量（$B$）序列，包含 $T$ 个时间步，每个时间步有 $D$ 个特征通道；并设 $W \\in \\mathbb{R}^{D \\times K}$ 是一个将特征映射到 $K$ 个输出的权重矩阵。预期的操作是通过将 $X$ 的最后一个轴与 $W$ 的第一个轴进行收缩来生成 $Y \\in \\mathbb{R}^{B \\times T \\times K}$，即对于每个 $b$、$t$ 和 $k$，$Y_{b,t,k}$ 应等于 $X_{b,t,i} W_{i,k}$ 对特征索引 $i$ 的求和。假设一个错误导致沿错误的轴（例如，时间轴）进行收缩，当 $T=D$ 时，这可以悄无声息地通过形状检查，但会产生不正确的语义。\n\n您的任务是基于不变性和等变性，选择一个最小的单元测试集，以便可靠地检测轴错位，无论具体的数值如何，甚至在 $T=D$ 使得形状具有欺骗性兼容的情况下也是如此。您的选择应基于张量收缩、单位矩阵、置换矩阵和正交基变换的基本性质。\n\n在当前场景下，哪个选项描述了能够检测轴错位的最小单元测试集？\n\nA. 两个测试：\n- 单位权重测试：选择 $D=K$ 并设置 $W = I_{D}$；断言 $f(X,W) = X$ 精确成立。\n- 时间置换等变性：设 $\\Pi \\in \\mathbb{R}^{T \\times T}$ 是一个置换矩阵；断言 $f(X \\Pi^{\\top}, W) = (f(X,W)) \\Pi^{\\top}$。\n\nB. 单个测试：\n- 特征轴基变换不变性：选择一个随机正交矩阵 $Q \\in \\mathbb{R}^{D \\times D}$ 满足 $Q^{\\top} Q = I_{D}$，并设置 $W' = Q^{-1} W$；断言 $f(X Q, W') = f(X, W)$。\n\nC. 单个测试：\n- 对 $X$ 的线性：选择 $X_{1}, X_{2} \\in \\mathbb{R}^{B \\times T \\times D}$；断言 $f(X_{1}+X_{2}, W) = f(X_{1}, W) + f(X_{2}, W)$。\n\nD. 两个测试：\n- 批量置换等变性：设 $P \\in \\mathbb{R}^{B \\times B}$ 是一个置换矩阵；断言 $f(P X, W) = P f(X, W)$。\n- 正齐次性：对于任意 $\\alpha \\in \\mathbb{R}$，断言 $f(\\alpha X, W) = \\alpha f(X, W)$。\n\n这里 $f$ 表示为实现所述层而实现的张量收缩。选择能稳健地检测错位且不包含冗余检查的最小测试集的选项。", "solution": "用户要求对一个应用于深度学习的线性代数问题进行严谨的、教授级别的验证和解答。\n\n### 问题验证\n\n我将首先按照要求的协议验证问题陈述。\n\n#### 第1步：提取已知条件\n-   **输入张量 `X`**：$X \\in \\mathbb{R}^{B \\times T \\times D}$，表示一个包含 $B$ 个序列的小批量，每个序列有 $T$ 个时间步和 $D$ 个特征。\n-   **权重矩阵 `W`**：$W \\in \\mathbb{R}^{D \\times K}$，一个将 $D$ 个输入特征映射到 $K$ 个输出特征的权重矩阵。\n-   **输出张量 `Y`**：$Y \\in \\mathbb{R}^{B \\times T \\times K}$。\n-   **预期操作 `f_correct`**：输出张量的分量由 $Y_{b,t,k} = \\sum_{i=1}^{D} X_{b,t,i} W_{i,k}$ 给出。这对应于 $X$ 的最后一个轴（维度 $D$）与 $W$ 的第一个轴（维度 $D$）的张量收缩。此操作对每个批次元素 $b \\in \\{1, ..., B\\}$ 和每个时间步 $t \\in \\{1, ..., T\\}$ 独立应用。\n-   **错误**：所实现的函数，记为 $f(X, W)$，沿一个不正确的轴进行收缩。给出的例子是 $X$ 的时间轴（维度 $T$）与 $W$ 的特征轴（维度 $D$）进行收缩。如果 $T=D$，这是可能的，并且该错误可以“悄无声息地通过形状检查”，意味着输出张量具有预期的形状 $\\mathbb{R}^{B \\times T \\times K}$。\n-   **目标**：基于不变性和等变性等基本性质，选择一个最小的单元测试集，以可靠地检测这种轴错位。\n\n#### 第2步：使用提取的已知条件进行验证\n1.  **科学依据**：该问题设置在深度学习的背景下，使用了线性代数的基本概念，特别是张量收缩。等变性、不变性、置换矩阵和正交基变换的概念都是标准的、严谨的数学概念。在数值计算库中出现索引错误的场景既真实又常见。该问题在科学上和数学上都是合理的。\n2.  **适定性**：该问题是适定的。它清楚地定义了正确的行为和要检测的错误的性质。它要求从给定的选项列表中选择一个“最小集”的测试，这是一个明确的目标。通过逻辑推导和对操作的数学性质的分析，可以在选项中确定唯一的最佳答案。\n3.  **客观性**：语言精确、正式，没有主观性。所有术语在数学和计算机科学中都是标准的。\n4.  **完整性**：问题陈述是自包含的。它提供了所有必要的定义，包括张量、它们的维度、正确的操作以及要检测的错误类别。\n5.  **无其他缺陷**：该问题并非微不足道，因为它需要理解与不同张量轴相关的特定属性（等变性/不变性）。它不是不适定的、矛盾的，也不是基于有缺陷的前提。\n\n#### 第3步：结论和行动\n问题陈述是 **有效的**。我现在将进行完整的解答和分析。\n\n### 推导与选项分析\n\n设 $f_{correct}(X, W)$ 为预期操作，$f_{bug}(X, W)$ 为有错误的实现。\n\n正确的操作由以下公式给出：\n$$ (f_{correct}(X, W))_{b,t,k} = \\sum_{i=1}^{D} X_{b,t,i} W_{i,k} $$\n此操作是一个由 $W$ 定义的线性变换，应用于每个批次 $b$ 和时间步 $t$ 的 $D$ 维特征向量 $X_{b,t,:}$。\n\n如前所述，错误的操作将 $X$ 的时间轴（轴1，维度 $T$）与 $W$ 的特征轴（轴0，维度 $D$）进行收缩。这仅在 $T=D$ 时在计算上是可能的。为确保输出形状为 $B \\times T \\times K$，实现必须适当地映射剩余的轴。当 $T=D$ 时，错误操作的一种可能形式是：\n$$ (f_{bug}(X, W))_{b,i,k} = \\sum_{t=1}^{T} X_{b,t,i} W_{t,k} $$\n注意索引 $t$ 和 $i$ 的角色互换。求和是针对时间步 $t$ 进行的，输出的第二个索引对应于特征通道 $i$。为了使形状与预期的 $B \\times T \\times K$ 匹配，实现可能会隐式地置换输出轴，例如，将输出 $Y$ 定义为 $Y_{b,t,k} = (f_{bug}(X, W))_{b,k,t}$。然而，根本的错误计算仍然是沿时间轴的求和。我们将基于核心计算来分析其性质。\n\n我们必须找到一个 $f_{correct}$ 通过但 $f_{bug}$ 失败的测试。该测试集还必须是最小的。\n\n#### 选项C的评估\n**C. 单个测试：对 $X$ 的线性。** 该测试断言 $f(X_{1}+X_{2}, W) = f(X_{1}, W) + f(X_{2}, W)$。\n-   对于 $f_{correct}$：\n    $$ \\sum_{i} (X_{1,b,t,i} + X_{2,b,t,i}) W_{i,k} = \\sum_{i} X_{1,b,t,i} W_{i,k} + \\sum_{i} X_{2,b,t,i} W_{i,k} $$\n    此性质成立。\n-   对于 $f_{bug}$：\n    $$ \\sum_{t} (X_{1,b,t,i} + X_{2,b,t,i}) W_{t,k} = \\sum_{t} X_{1,b,t,i} W_{t,k} + \\sum_{t} X_{2,b,t,i} W_{t,k} $$\n    此性质也成立。\n正确和错误的操作都是张量收缩，它们本质上是线性操作（或者更准确地说是多线性操作）。此测试检查的是线性，两种实现都具备此性质。因此，它无法区分它们。\n**结论：不正确。**\n\n#### 选项D的评估\n**D. 两个测试：批量置换等变性和正齐次性。**\n-   **正齐次性**：$f(\\alpha X, W) = \\alpha f(X, W)$。这是线性的直接结果，我们在C中已经确定两种实现都满足线性。因此，此测试不具有区分性。\n-   **批量置换等变性**：$f(P X, W) = P f(X, W)$，其中 $P \\in \\mathbb{R}^{B \\times B}$ 是作用于批量轴的置换矩阵。无论操作正确与否，它都独立应用于批次中的每个元素。沿批量轴置换输入元素将简单地导致输出元素的相应置换。$f_{correct}$ 和 $f_{bug}$ 都关于批量轴上的置换是等变的。\n此选项中的两个测试检查的属性都过于通用，正确和错误的实现都共享这些属性。\n**结论：不正确。**\n\n#### 选项A的评估\n**A. 两个测试：单位权重测试和时间置换等变性。**\n1.  **单位权重测试**：对于 $D=K$，设置 $W=I_D$。断言 $f(X, W) = X$。\n    -   对于 $f_{correct}$：$(f_{correct}(X, I_D))_{b,t,k} = \\sum_{i} X_{b,t,i} (I_D)_{i,k} = \\sum_{i} X_{b,t,i} \\delta_{ik} = X_{b,t,k}$。测试通过。\n    -   对于 $f_{bug}$（要求 $T=D=K$）：$(f_{bug}(X, I_D))_{b,i,k} = \\sum_{t} X_{b,t,i} (I_D)_{t,k} = \\sum_{t} X_{b,t,i} \\delta_{tk} = X_{b,k,i}$。测试断言输出为 $X$，即 $(f(X,I_D))_{b,t,k} = X_{b,t,k}$。错误的实现产生的输出中，时间和特征轴被交换了：$X_{b,k,t}$。除非 $X$ 在其最后两个维度上是对称的（即 $X_{b,k,t} = X_{b,t,k}$），否则此测试将失败。此测试是有效的。\n2.  **时间置换等变性**：设 $\\Pi \\in \\mathbb{R}^{T \\times T}$ 是一个置换矩阵。断言 $f(X \\Pi^{\\top}, W) = (f(X,W)) \\Pi^{\\top}$。此表示法意味着 $\\Pi^{\\top}$ 对其所乘张量的时间轴进行置换。\n    -   对于 $f_{correct}$：操作独立地应用于每个时间片 $X_{b,t,:}$。在操作前置换时间片等同于先应用操作然后置换结果的时间片。此等变性成立。\n    -   对于 $f_{bug}$：操作涉及对时间轴求和（$\\sum_t$）。这个求和打破了时间步之间的独立性。如果输入的时间步被置换，结果的总和将以一种不等同于简单置换原始操作输出的方式改变。错误的实现关于时间轴置换不是等变的。此测试也是有效的。\n\n两个测试都能检测到这个错误。然而，问题要求的是一个 **最小集**。由于任一测试本身就足够了，包含两个测试的集合不是最小的。因此，这个选项不是最优的。\n**结论：不正确。**\n\n#### 选项B的评估\n**B. 单个测试：特征轴基变换不变性。** 此测试断言对于任何正交矩阵 $Q \\in \\mathbb{R}^{D \\times D}$，$f(X Q, Q^{\\top} W) = f(X, W)$。\n-   对于 $f_{correct}$：此性质描述了线性映射在基变换下的行为。我们对输入向量（$X$ 的 $D$ 轴上的特征向量）应用一个基变换 $Q$，并对线性映射的矩阵 $W$ 应用相应的逆变换 $Q^{-1}=Q^{\\top}$。整个变换的结果必须是不变的。我们来验证一下：\n    $$ (f_{correct}(XQ, Q^{\\top}W))_{b,t,k} = \\sum_{i} (XQ)_{b,t,i} (Q^{\\top}W)_{i,k} $$\n    $$ = \\sum_{i} \\left(\\sum_{j} X_{b,t,j} Q_{j,i}\\right) \\left(\\sum_{l} (Q^{\\top})_{i,l} W_{l,k}\\right) $$\n    $$ = \\sum_{j,l} X_{b,t,j} W_{l,k} \\left(\\sum_{i} Q_{j,i} (Q^{\\top})_{i,l}\\right) $$\n    项 $\\sum_{i} Q_{j,i} (Q^{\\top})_{i,l}$ 是矩阵乘积 $Q Q^{\\top}$ 的第 $(j,l)$ 个元素。因为 $Q$ 是正交的，$Q Q^{\\top} = I_D$，所以这个和是 $\\delta_{jl}$。\n    $$ = \\sum_{j,l} X_{b,t,j} W_{l,k} \\delta_{jl} = \\sum_{j} X_{b,t,j} W_{j,k} = (f_{correct}(X,W))_{b,t,k} $$\n    测试通过。\n-   对于 $f_{bug}$（要求 $T=D$）：基变换 $Q$ 应用于 $X$ 的特征轴（索引 $i$）。然而，错误的实现是在时间轴（索引 $t$）上进行收缩。变换 $Q$ 及其逆 $Q^{\\top}$ 应用于没有被一起收缩的轴上。\n    $$ (f_{bug}(XQ, Q^{\\top}W))_{b,i,k} = \\sum_{t} (XQ)_{b,t,i} (Q^{\\top}W)_{t,k} $$\n    $$ = \\sum_{t} \\left(\\sum_{j} X_{b,t,j} Q_{j,i}\\right) \\left(\\sum_{l} (Q^{\\top})_{t,l} W_{l,k}\\right) $$\n    这个表达式不能简化为 $(f_{bug}(X, W))_{b,i,k} = \\sum_{t} X_{b,t,i} W_{t,k}$。矩阵 $Q$ 和 $Q^\\top$ 不会抵消。对于一般的输入选择，此测试将失败。\n\n这一个测试足以检测轴错位。它正确地探查了预期操作的核心属性：即它是一个作用于 $D$ 维特征空间上的线性映射。因为它是一个单一且充分的测试，所以只包含此测试的集合是最小的。\n**结论：正确。**", "answer": "$$\\boxed{B}$$", "id": "3143508"}, {"introduction": "深度学习模型的速度在很大程度上取决于它们执行矩阵乘法等基本运算的效率。这个问题挑战你超越张量收缩的数学定义，去思考它在物理硬件上的实现方式 [@problem_id:3143504]。通过分析张量在内存中的布局和步长（stride），你将学习如何通过最大化内存局部性来优化代码，以获得更好的性能。", "problem": "一个深度学习模型执行批量线性变换，其中对于每个批次索引 $b$，形状为 $(n \\times k)$ 的矩阵 $\\mathbf{A}^{(b)}$ 与形状为 $(k \\times m)$ 的矩阵 $\\mathbf{B}^{(b)}$ 相乘以产生形状为 $(n \\times m)$ 的矩阵 $\\mathbf{C}^{(b)}$。以张量形式表示，输入为 $\\mathbf{A} \\in \\mathbb{R}^{b \\times n \\times k}$ 和 $\\mathbf{B} \\in \\mathbb{R}^{b \\times k \\times m}$，输出为 $\\mathbf{C} \\in \\mathbb{R}^{b \\times n \\times m}$。矩阵以行主序（C-连续）布局存储，元素为 32 位浮点数（即每个元素 4 字节）。硬件以大小为 64 字节的缓存行获取内存。您必须通过函数 $\\mathrm{einsum}$ 将批量操作表示为爱因斯坦求和约定收缩，并提出一种通过张量步幅算术证明的、重新排序轴以通过改善空间局部性来增加算术强度（每移动字节的浮点运算次数（FLOPs））的优化方案。\n\n从第一性原理出发：\n- 使用矩阵乘法的核心定义 $C_{b,i,j} = \\sum_{t=1}^{k} A_{b,i,t}\\,B_{b,t,j}$，以及爱因斯坦求和约定的定义，其中重复的索引表示求和。\n- 使用行主序步幅的定义：对于形状为 $(d_0, d_1, d_2)$ 的张量，沿轴 0 的元素步幅为 $d_1 d_2$，沿轴 1 的元素步幅为 $d_2$，沿轴 2 的元素步幅为 $1$。字节步幅等于元素步幅乘以 $4$。\n- 假设内核通过在最内层循环中对归约维度 $k$进行累加来计算每个输出元素 $C_{b,i,j}$。对于空间局部性，沿最内层循环的连续访问（元素步幅为 1）会完全利用每个缓存行，而至少 16 个元素（因为每行 64 字节，每个元素 4 字节）的步幅会导致每次访问很可能落在不同的缓存行上，重用率极低。\n\n设具体尺寸为 $b=32, n=64, k=128, m=64$。选择同时满足以下两个条件的选项：\n(i) 提供一个正确的 $\\mathrm{einsum}$ 收缩字符串，用于从 $\\mathbf{A}$ 和 $\\mathbf{B}$ 计算 $\\mathbf{C}$，以及\n(ii) 提出一种轴重排方案，该方案通过使归约维度 $k$ 在两个输入中内存连续，并使输出写入在最内层生成的维度上连续，从而最大化算术强度。\n\n在所述模型下，哪个选项满足上述条件并实现最佳的 FLOP 与内存比率？\n\nA. 将 $\\mathbf{B}$ 转置为形状 $(b,m,k)$ 后，使用 $\\mathrm{einsum}(\\texttt{'bnk,bmk->bnm'})$，保持 $\\mathbf{A}$ 为 $(b,n,k)$，并将 $\\mathbf{C}$ 写入为 $(b,n,m)$。\n\nB. 使用原始形状的 $\\mathbf{A}$（$(b,n,k)$）和 $\\mathbf{B}$（$(b,k,m)$），使用 $\\mathrm{einsum}(\\texttt{'bnk,bkm->bnm'})$，并将 $\\mathbf{C}$ 写入为 $(b,n,m)$。\n\nC. 将 $\\mathbf{A}$ 转置为 $(b,k,n)$ 后，使用 $\\mathrm{einsum}(\\texttt{'bkn,bkm->bmn'})$，保持 $\\mathbf{B}$ 为 $(b,k,m)$，并将 $\\mathbf{C}$ 写入为 $(b,m,n)$。\n\nD. 将 $\\mathbf{B}$ 转置为 $(b,m,k)$ 后，使用 $\\mathrm{einsum}(\\texttt{'bnk,bmk->bmn'})$，保持 $\\mathbf{A}$ 为 $(b,n,k)$，并将 $\\mathbf{C}$ 写入为 $(b,m,n)$。", "solution": "用户希望确定批量矩阵乘法 $\\mathbf{C} = \\mathbf{A} \\mathbf{B}$ 的最佳策略，重点是通过内存访问模式进行性能优化。\n\n### 问题陈述验证\n\n**步骤1：提取已知条件**\n- 批量矩阵乘法：对于每个批次索引 $b$，$\\mathbf{C}^{(b)} = \\mathbf{A}^{(b)} \\mathbf{B}^{(b)}$。\n- 输入张量：$\\mathbf{A} \\in \\mathbb{R}^{b \\times n \\times k}$ 和 $\\mathbf{B} \\in \\mathbb{R}^{b \\times k \\times m}$。\n- 输出张量：$\\mathbf{C} \\in \\mathbb{R}^{b \\times n \\times m}$。\n- 逐元素公式：$C_{b,i,j} = \\sum_{t=1}^{k} A_{b,i,t}\\,B_{b,t,j}$。\n- 数据表示：行主序（C-连续）布局，32位浮点元素（4字节/元素）。\n- 硬件约束：缓存行大小为64字节。\n- 内核执行模型：最内层循环是归约维度 $k$。\n- 空间局部性模型：元素步幅为1的访问是连续且高效的。步幅为16个元素（即 $16 \\times 4 = 64$ 字节）或更大的访问效率低下。\n- 具体维度：$b=32, n=64, k=128, m=64$。\n- 任务：找到具有正确爱因斯坦求和（`einsum`）字符串和轴重排的选项，该选项通过（1）使归约维度 $k$ 在两个输入中内存连续，以及（2）使输出写入连续，来最大化算术强度。\n\n**步骤2：使用提取的已知条件进行验证**\n- **科学性：** 问题基于线性代数（矩阵乘法）、计算机科学（张量表示、数据布局）和计算机体系结构（缓存局部性、内存步幅、算术强度）的基本原理。这些是高性能计算和深度学习中的标准和关键概念。\n- **合理性（Well-Posed）：** 问题提供了明确的目标（找到最佳选项）和一套用于评估的量化标准（步幅算术、`einsum` 的正确性）。缓存行为的简化模型允许进行确定性分析，从而在选项中找到唯一的最佳答案。\n- **客观性：** 问题使用精确的技术语言陈述，没有主观或模棱两可的术语。\n\n**步骤3：结论和行动**\n问题陈述是有效的。它在科学上是合理的，问题定义清晰，客观，并包含了进行严谨分析所需的所有信息。我现在将继续进行解题推导。\n\n### 推导与选项分析\n\n**1. 第一性原理：步幅和基线性能**\n\n问题使用行主序内存布局。对于形状为 $(d_0, d_1, ..., d_{N-1})$ 的张量，轴 $i$ 的元素步幅由 $S_i = \\prod_{j=i+1}^{N-1} d_j$ 给出，其中 $S_{N-1} = 1$。字节步幅为 $4 \\times S_i$。\n\n操作是批量矩阵乘法 $C_{b,i,j} = \\sum_{t=1}^{k} A_{b,i,t}\\,B_{b,t,j}$。索引 $t$ 对应于大小为 $k$ 的维度。\n对此的标准 `einsum` 表示是 `'bnk,bkm->bnm'`。这对应于选项B，我们将作为基线进行分析。\n\n**基线分析（原始布局）：**\n- $\\mathbf{A}$ 的形状为 $(b, n, k) = (32, 64, 128)$。其元素步幅为 $(n \\times k, k, 1) = (64 \\times 128, 128, 1) = (8192, 128, 1)$。\n- $\\mathbf{B}$ 的形状为 $(b, k, m) = (32, 128, 64)$。其元素步幅为 $(k \\times m, m, 1) = (128 \\times 64, 64, 1) = (8192, 64, 1)$。\n\n内核的最内层循环遍历归约维度 $k$。\n- 访问 $A_{b,i,t}$：随着 $t$ 的递增，我们沿着 $\\mathbf{A}$ 的最后一个维度访问元素。步幅为 $1$。这是连续的，表现出极佳的空间局部性。\n- 访问 $B_{b,t,j}$：随着 $t$ 的递增，我们沿着 $\\mathbf{B}$ 的中间维度访问元素。步幅是 $k$ 维度的步幅，即 $m=64$ 个元素。由于 $64 > 16$（每个缓存行的元素数量），每次内存访问很可能位于不同的缓存行中，导致缓存利用率非常低。这是性能瓶颈。\n\n**2. 优化策略**\n\n为了满足优化目标，归约维度 $k$ 必须是两个输入张量的最后一个维度（步幅为 $1$）。\n- $\\mathbf{A}$ 的形状已经是 $(b,n,k)$，因此其 'k' 维度已经是最后一个。我们保持原样。\n- $\\mathbf{B}$ 的形状为 $(b,k,m)$。为了使 'k' 成为最后一个维度，我们必须转置最后两个轴，创建一个形状为 $(b,m,k)$ 的新张量 $\\mathbf{B'}$。这个新张量将与其新形状C-连续。\n- $\\mathbf{B'}$ 的元素与 $\\mathbf{B}$ 的关系为 $B'_{b,j,t} = B_{b,t,j}$，其中 $j$ 是维度 $m$ 的索引，$t$ 是维度 $k$ 的索引。\n- 乘法公式变为：$C_{b,i,j} = \\sum_{t=1}^{k} A_{b,i,t}\\,B'_{b,j,t}$。\n\n这个新操作的 `einsum` 字符串涉及的输入，其索引对应于 $\\mathbf{A}$ 的 `bnk` 和 $\\mathbf{B'}$ 的 `bmk`。求和是针对 `k`，输出索引是 `b`、`n`、`m`。这得出了字符串 `'bnk,bmk->bnm'`。\n\n**3. 逐个选项分析**\n\n**A. 将 $\\mathbf{B}$ 转置为形状 $(b,m,k)$ 后，使用 $\\mathrm{einsum}(\\texttt{'bnk,bmk->bnm'})$，保持 $\\mathbf{A}$ 为 $(b,n,k)$，并将 $\\mathbf{C}$ 写入为 $(b,n,m)$。**\n- **正确性：** 如上推导，将 $\\mathbf{B}$ 转置为形状为 $(b,m,k)$ 的 $\\mathbf{B'}$，并使用 `einsum` 字符串 `'bnk,bmk->bnm'` 可以正确计算 $C_{b,i,j} = \\sum_{t} A_{b,i,t}B'_{b,j,t} = \\sum_{t} A_{b,i,t}B_{b,t,j}$。输出形状 $(b,n,m)$ 也是正确的。\n- **性能：**\n    - 输入 $\\mathbf{A}$（形状 $(b,n,k)$）：在 `k` 上访问的步幅为 $1$。最优。\n    - 输入 $\\mathbf{B'}$（形状 $(b,m,k)$）：在 `k` 上访问的步幅为 $1$。最优。\n    - 输出 $\\mathbf{C}$（形状 $(b,n,m)$）：一个 `for b, for n, for m, ...` 的循环嵌套将计算输出。在递增 $m$ 的同时写入 $C_{b,n,m}$ 意味着以步幅 $1$ 访问内存。最优。\n- **结论：** **正确**。此选项满足所有规定要求并实现了期望的优化。\n\n**B. 使用原始形状的 $\\mathbf{A}$（$(b,n,k)$）和 $\\mathbf{B}$（$(b,k,m)$），使用 $\\mathrm{einsum}(\\texttt{'bnk,bkm->bnm'})$，并将 $\\mathbf{C}$ 写入为 $(b,n,m)$。**\n- **正确性：** `einsum` 字符串对于原始张量形状在数学上是正确的。\n- **性能：** 这是前面分析的基线情况。对 $\\mathbf{B}$ 的访问模式涉及 $m=64$ 的大步幅，效率极低。它不符合优化目标。\n- **结论：** **不正确**。未能执行优化。\n\n**C. 将 $\\mathbf{A}$ 转置为 $(b,k,n)$ 后，使用 $\\mathrm{einsum}(\\texttt{'bkn,bkm->bmn'})$，保持 $\\mathbf{B}$ 为 $(b,k,m)$，并将 $\\mathbf{C}$ 写入为 $(b,m,n)$。**\n- **正确性：** 此选项计算 $C'_{b,j,i} = \\sum_t A'_{b,t,i} B_{b,t,j}$。由于 $A'_{b,t,i} = A_{b,i,t}$，这变为 $C'_{b,j,i} = \\sum_t A_{b,i,t} B_{b,t,j} = C_{b,i,j}$。该操作计算所需矩阵的转置 $\\mathbf{C}^T$。这是一个有效的计算路径。\n- **性能：**\n    - 输入 $\\mathbf{A'}$（形状 $(b,k,n)$）：步幅为 $(k \\times n, n, 1)$。访问归约维度 'k'（中间维度）的步幅为 $n=64$。效率低下。\n    - 输入 $\\mathbf{B}$（形状 $(b,k,m)$）：步幅为 $(k \\times m, m, 1)$。访问 'k' 的步幅为 $m=64$。效率低下。\n- **结论：** **不正确**。建议的重排导致两个输入的内存访问模式都很差。\n\n**D. 将 $\\mathbf{B}$ 转置为 $(b,m,k)$ 后，使用 $\\mathrm{einsum}(\\texttt{'bnk,bmk->bmn'})$，保持 $\\mathbf{A}$ 为 $(b,n,k)$，并将 $\\mathbf{C}$ 写入为 $(b,m,n)$。**\n- **正确性：** 这使用了与选项 A 相同的优化输入。`einsum` 计算 $C'_{b,j,i} = \\sum_t A_{b,i,t}B'_{b,j,t} = C_{b,i,j}$。输出形状 $(b,m,n)$ 表明它产生所需矩阵的转置 $\\mathbf{C}^T$。\n- **性能：**\n    - 对 $\\mathbf{A}$ 和 $\\mathbf{B'}$ 的输入访问是最优的（步幅 $1$），与选项 A 中相同。\n    - 对于一个 `for m, for n, ...` 循环结构，对 $\\mathbf{C'}$（形状 $(b,m,n)$）的输出访问也是最优的（步幅 $1$）。\n- **与 A 的比较：** A 和 D 在计算内核内都具有最优的内存访问模式。然而，问题将最终输出定义为 $\\mathbf{C} \\in \\mathbb{R}^{b \\times n \\times m}$。选项 A 直接生成此结果张量。选项 D 生成 $\\mathbf{C}^T$，这将需要额外的转置操作才能获得指定的输出格式，从而产生额外成本。因此，选项 A 是更直接、更高效的端到端解决方案。\n- **结论：** **不正确**。虽然核心计算被优化了，但它没有以其指定的原生形状产生最终输出，使其成为比选项 A 差的策略。\n\n### 结论\n\n选项 A 为优化后的内存布局提供了正确的 `einsum` 字符串，该布局直接以其指定的形状 $(b,n,m)$ 生成输出张量 $\\mathbf{C}$。它为输入读取（在归约维度上步幅为 1）和输出写入（在最内层生成的维度上步幅为 1）都实现了最优的空间局部性。", "answer": "$$\\boxed{A}$$", "id": "3143504"}]}