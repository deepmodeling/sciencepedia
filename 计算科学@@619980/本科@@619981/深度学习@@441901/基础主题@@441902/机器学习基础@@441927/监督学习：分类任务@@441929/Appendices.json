{"hands_on_practices": [{"introduction": "分类器输出的原始分数必须通过设定一个决策阈值来转化为最终的类别判断。本练习 [@problem_id:3178377] 将深入探讨如何优化这一阈值以最大化F1分数，这是一个平衡了精确率和召回率的关键指标。你将进一步探索当现实世界中常见的“先验漂移”（即类别频率发生变化）发生时，如何在不重新训练模型的情况下，通过动态调整阈值来维持模型的最优性能。", "problem": "给定一个多标签分类场景，其中每个类别的决策是相互独立的。对于每个类别标签 $y \\in \\{0,1,2\\}$，一个模型会生成一个校准过的分数 $s \\in [0,1]$，该分数可以被解释为后验概率 $p(y=1 \\mid x)$。一个逐类别的决策规则在一个实例上将类别 $y$ 预测为正类，当且仅当 $s \\ge \\tau_y$，其中 $\\tau_y \\in [0,1]$ 是一个为最大化F1分数而选择的阈值。F1分数是精确率（precision）和召回率（recall）的调和平均数，对于一个固定的类别，其定义如下\n$$\n\\text{precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}, \\quad \\text{recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}, \\quad \\text{F1} = \\frac{2 \\cdot \\text{precision} \\cdot \\text{recall}}{\\text{precision} + \\text{recall}} = \\frac{2 \\cdot \\text{TP}}{2 \\cdot \\text{TP} + \\text{FP} + \\text{FN}},\n$$\n其中 $\\text{TP}$、$\\text{FP}$ 和 $\\text{FN}$ 分别表示真正例（true positives）、假正例（false positives）和假反例（false negatives），所有这些值都是相对于阈值 $\\tau_y$ 计算的。\n\n您将分析在先验漂移（prior shift）（也称为标签漂移, label shift）下阈值校准的稳定性，其中类别先验 $\\pi_y = p(y=1)$ 变为一个新值 $\\pi_y'$，而类别条件分数分布 $p(s \\mid y)$ 保持不变。在此假设下，可以通过对每个正实例赋予权重 $w_{+} = \\pi_y' / \\pi_y$ 和对每个负实例赋予权重 $w_{-} = (1-\\pi_y')/(1-\\pi_y)$ 的重要性加权方法，来获得新先验下的预期混淆计数。对于一个候选阈值 $\\tau$，加权计数为\n$$\n\\text{TP}_w(\\tau) = \\sum_{i} w_{+} \\cdot \\mathbf{1}\\{y_i=1\\} \\cdot \\mathbf{1}\\{s_i \\ge \\tau\\}, \\quad\n\\text{FP}_w(\\tau) = \\sum_{i} w_{-} \\cdot \\mathbf{1}\\{y_i=0\\} \\cdot \\mathbf{1}\\{s_i \\ge \\tau\\},\n$$\n$$\n\\text{FN}_w(\\tau) = \\sum_{i} w_{+} \\cdot \\mathbf{1}\\{y_i=1\\} \\cdot \\mathbf{1}\\{s_i  \\tau\\},\n$$\n加权的F1分数为\n$$\n\\text{F1}_w(\\tau) = \\frac{2 \\cdot \\text{TP}_w(\\tau)}{2 \\cdot \\text{TP}_w(\\tau) + \\text{FP}_w(\\tau) + \\text{FN}_w(\\tau)}.\n$$\n\n任务：编写一个程序，对于每个类别 $y \\in \\{0,1,2\\}$，在验证集上计算F1最优阈值，然后使用重要性加权计算指定先验漂移下的F1最优阈值，最后量化漂移下的稳定性和性能。\n\n在您的推理和实现中使用的基本原理：精确率、召回率、F1的定义；指示函数 $\\mathbf{1}\\{\\cdot\\}$；以及标签漂移假设，即 $p(s \\mid y)$ 不变而 $\\pi_y$ 改变，从而允许使用 $w_{+} = \\pi_y'/\\pi_y$ 和 $w_{-} = (1-\\pi_y')/(1-\\pi_y)$ 进行重要性加权。\n\n验证数据（每个类别 $y$）是固定的，并如下给出。对于类别 $y=0$，\n$$\n\\mathbf{s}^{(0)} = [0.95, 0.80, 0.60, 0.55, 0.52, 0.50, 0.40, 0.30, 0.20, 0.10, 0.05, 0.01], \\\\\n\\mathbf{y}^{(0)} = [1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0].\n$$\n对于类别 $y=1$，\n$$\n\\mathbf{s}^{(1)} = [0.90, 0.88, 0.70, 0.65, 0.60, 0.55, 0.50, 0.49, 0.35, 0.33, 0.25, 0.15], \\\\\n\\mathbf{y}^{(1)} = [1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0].\n$$\n对于类别 $y=2$，\n$$\n\\mathbf{s}^{(2)} = [0.99, 0.85, 0.75, 0.60, 0.45, 0.40, 0.35, 0.32, 0.20, 0.18, 0.10, 0.02], \\\\\n\\mathbf{y}^{(2)} = [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0].\n$$\n\n设类别 $y$ 的经验先验是验证集中的分数 $\\pi_y = \\frac{1}{n}\\sum_{i=1}^{n} \\mathbf{1}\\{y_i=1\\}$。给定漂移环境下的目标先验 $\\pi_y'$ 如下\n$$\n\\pi_0' = 0.70, \\quad \\pi_1' = 0.20, \\quad \\pi_2' = \\frac{1}{6}.\n$$\n\n每个类别 $y$ 的计算要求：\n- 从验证标签中计算 $\\pi_y$。\n- 通过搜索有限的候选阈值集合，找到未加权的F1最优阈值 $\\tau_y$。使用 $\\mathbf{s}^{(y)}$ 中所有唯一值以及 $0$ 和一个严格大于最大分数的值（例如 $\\max(\\mathbf{s}^{(y)}) + 10^{-12}$）作为候选阈值。当 $s \\ge \\tau$ 时预测为正类。如果多个阈值得出相同的最大F1值，则选择最大化F1值的阈值中最小的一个来打破平局。\n- 在漂移后的先验 $\\pi_y'$ 下，计算 $w_{+} = \\pi_y'/\\pi_y$ 和 $w_{-} = (1-\\pi_y')/(1-\\pi_y)$。使用相同的候选集合和打破平局的规则，找到最大化 $\\text{F1}_w(\\tau)$ 的加权F1最优阈值 $\\tau_y^{\\text{shift}}$。\n- 计算绝对阈值变化 $\\Delta \\tau_y = |\\tau_y^{\\text{shift}} - \\tau_y|$。\n- 计算在漂移后的先验下，分别使用原始阈值 $\\text{F1}_w(\\tau_y)$ 和漂移后最优阈值 $\\text{F1}_w(\\tau_y^{\\text{shift}})$ 时的加权F1分数。\n\n测试套件：使用上面指定的三个类别及其各自的 $\\pi_y'$ 值。您的程序必须输出单行，其中包含按 $y=0$、$y=1$、$y=2$ 顺序排列的跨类别扁平化结果列表，每个类别的五个指标按以下顺序排列：\n$$\n[\\tau_0, \\ \\tau_0^{\\text{shift}}, \\ \\Delta \\tau_0, \\ \\text{F1}_w(\\tau_0), \\ \\text{F1}_w(\\tau_0^{\\text{shift}}), \\ \\tau_1, \\ \\tau_1^{\\text{shift}}, \\ \\Delta \\tau_1, \\ \\text{F1}_w(\\tau_1), \\ \\text{F1}_w(\\tau_1^{\\text{shift}}), \\ \\tau_2, \\ \\tau_2^{\\text{shift}}, \\ \\Delta \\tau_2, \\ \\text{F1}_w(\\tau_2), \\ \\text{F1}_w(\\tau_2^{\\text{shift}})].\n$$\n\n最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个数字四舍五入到恰好 $6$ 位小数。例如，输出应类似于 $[0.123456,0.234567, \\dots]$，不含多余的空格或文本。不应读取用户输入；所有数据均如上所述并嵌入程序中。此问题不涉及物理单位或角度，因此无需进行单位转换。", "solution": "该问题定义明确，科学上合理，并为获得唯一解提供了所有必要信息。这是分类器评估和适应标签分布漂移的一个标准练习，也是应用机器学习中的一个核心课题。因此，我们可以着手解决该问题。\n\n任务是分析二元分类器的 F1 最优决策阈值在类别先验概率发生特定变化（即先验漂移或标签漂移）时的稳定性。对于三个类别中的每一个，我们将首先在验证集上确定最优阈值 $\\tau_y$。然后，我们将模拟先验从经验先验 $\\pi_y$ 到目标先验 $\\pi_y'$ 的漂移，并通过最大化重要性加权 F1 分数 $\\text{F1}_w(\\tau)$ 来找到新的最优阈值 $\\tau_y^{\\text{shift}}$。最后，我们将量化阈值的不稳定性和对性能的影响。\n\n基本原理是 F1 分数，定义为 $\\text{F1} = \\frac{2 \\cdot \\text{TP}}{2 \\cdot \\text{TP} + \\text{FP} + \\text{FN}}$，它平衡了精确率和召回率的考量。最优阈值 $\\tau_y$ 代表了在给定分数分布和类别先验下，这种平衡达到最大化的点。当先验 $\\pi_y = p(y=1)$ 改变时，假正例（$\\text{FP}$）与假反例（$\\text{FN}$）的相对成本也随之改变。重要性加权是一种无需重新训练模型或重新收集标注数据即可估计分类器在新先验下性能的技术。每个原始的正实例被赋予权重 $w_{+} = \\pi_y' / \\pi_y$，每个负实例被赋予权重 $w_{-} = (1-\\pi_y') / (1-\\pi_y)$。这重新加权了混淆矩阵的计数，以反映它们在目标分布中的预期频率。\n\n加权 F1 分数由以下公式给出：\n$$\n\\text{F1}_w(\\tau) = \\frac{2 \\cdot \\text{TP}_w(\\tau)}{2 \\cdot \\text{TP}_w(\\tau) + \\text{FP}_w(\\tau) + \\text{FN}_w(\\tau)}\n$$\n其中 $\\text{TP}_w(\\tau) = w_{+} \\cdot \\text{TP}(\\tau)$，$\\text{FP}_w(\\tau) = w_{-} \\cdot \\text{FP}(\\tau)$，以及 $\\text{FN}_w(\\tau) = w_{+} \\cdot \\text{FN}(\\tau)$。未加权的计数 $\\text{TP}(\\tau)$、$\\text{FP}(\\tau)$ 和 $\\text{FN}(\\tau)$ 是在原始验证数据上针对给定阈值 $\\tau$ 计算的。\n\n对最优阈值 $\\tau_y$ 和 $\\tau_y^{\\text{shift}}$ 的搜索是在一个候选集上进行的，该候选集由验证数据中的所有唯一分数，加上 $0$ 和一个略大于最大分数的值组成。这确保了我们评估了数据的所有可能划分，以及预测全为负类或全为正类的平凡分类器。\n\n我们现在将对每个类别执行此过程。\n\n**类别 $y=0$**\n\n给定的数据是：\n$\\mathbf{s}^{(0)} = [0.95, 0.80, 0.60, 0.55, 0.52, 0.50, 0.40, 0.30, 0.20, 0.10, 0.05, 0.01]$\n$\\mathbf{y}^{(0)} = [1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0]$\n\n1.  **计算经验先验 $\\pi_0$**：在 $n=12$ 个实例中，有 $P=5$ 个正实例和 $N=7$ 个负实例。\n    经验先验为 $\\pi_0 = P/n = 5/12$。\n\n2.  **找到未加权的F1最优阈值 $\\tau_0$**：我们遍历所有候选阈值 $\\tau$ 并计算 $\\text{F1}(\\tau) = \\frac{2 \\cdot \\text{TP}(\\tau)}{2 \\cdot \\text{TP}(\\tau) + \\text{FP}(\\tau) + \\text{FN}(\\tau)}$。发现最大 F1 分数在 $\\tau = 0.52$ 时约为 $0.8$。在此阈值下，$\\text{TP}=4$，$\\text{FP}=1$，$\\text{FN}=1$，得出 $\\text{F1} = (2 \\cdot 4)/(2 \\cdot 4 + 1 + 1) = 8/10 = 0.8$。\n    因此，$\\tau_0 = 0.52$。\n\n3.  **计算重要性权重**：给定的目标先验为 $\\pi_0' = 0.70$。\n    $w_{+} = \\frac{\\pi_0'}{\\pi_0} = \\frac{0.70}{5/12} = \\frac{7/10}{5/12} = \\frac{84}{50} = 1.68$。\n    $w_{-} = \\frac{1-\\pi_0'}{1-\\pi_0} = \\frac{0.30}{7/12} = \\frac{3/10}{7/12} = \\frac{36}{70} \\approx 0.514286$。\n    由于 $\\pi_0'  \\pi_0$，正样本变得更重要（$w_+  1$），而负样本则不那么重要（$w_-  1$）。这将倾向于一个更低的阈值以提高召回率。\n\n4.  **找到加权的F1最优阈值 $\\tau_0^{\\text{shift}}$**：我们遍历相同的候选阈值，这次是最大化 $\\text{F1}_w(\\tau)$。发现最大加权 F1 分数约为 $0.890909$。这发生在 $\\tau=0.20$。在此阈值下，我们有 $\\text{TP}=5$ 和 $\\text{FP}=4$。加权计数为 $\\text{TP}_w = 1.68 \\cdot 5 = 8.4$，$\\text{FP}_w = (36/70) \\cdot 4 \\approx 2.057143$，以及 $\\text{FN}_w = 1.68 \\cdot 0 = 0$。这得出 $\\text{F1}_w = (2 \\cdot 8.4) / (2 \\cdot 8.4 + 2.057143 + 0) \\approx 0.890909$。\n    因此，$\\tau_0^{\\text{shift}} = 0.20$。\n\n5.  **计算类别0的最终指标**：\n    - $\\tau_0 = 0.52$\n    - $\\tau_0^{\\text{shift}} = 0.20$\n    - $\\Delta \\tau_0 = |\\tau_0^{\\text{shift}} - \\tau_0| = |0.20 - 0.52| = 0.32$\n    - $\\text{F1}_w(\\tau_0) = \\text{F1}_w(0.52)$：当 $\\text{TP}=4, \\text{FP}=1, \\text{FN}=1$ 时，加权 F1 为 $\\text{F1}_w = (2 \\cdot 1.68 \\cdot 4) / (2 \\cdot 1.68 \\cdot 4 + (36/70) \\cdot 1 + 1.68 \\cdot 1) \\approx 0.859654$。\n    - $\\text{F1}_w(\\tau_0^{\\text{shift}}) = \\text{F1}_w(0.20) \\approx 0.890909$。调整阈值提高了新先验下的 F1 分数。\n\n**类别 $y=1$**\n\n对类别 $y=1$ 的数据遵循相同的过程：\n$\\mathbf{s}^{(1)} = [0.90, ..., 0.15]$, $\\mathbf{y}^{(1)} = [1, ..., 0]$\n$\\pi_1 = 5/12$，目标 $\\pi_1' = 0.20$。\n$w_{+} = \\frac{0.20}{5/12} = 0.48$。\n$w_{-} = \\frac{0.80}{7/12} \\approx 1.371429$。\n在这里，正类的先验降低，使得假正例的代价相对更高。我们预计最优阈值会增加。\n- 未加权优化得出的最大 F1 分数为 $2/3 \\approx 0.666667$，这发生在阈值 $\\tau \\in \\{0.33, 0.50, 0.65\\}$。应用打破平局的规则（最小阈值），我们得到 $\\tau_1 = 0.33$。\n- 加权优化在 $\\tau=0.65$ 时得出最大加权 F1 分数约为 $0.552632$。因此，$\\tau_1^{\\text{shift}} = 0.65$。\n- 最终指标为：$\\tau_1 = 0.33$，$\\tau_1^{\\text{shift}} = 0.65$，$\\Delta \\tau_1 = 0.32$，$\\text{F1}_w(\\tau_1) \\approx 0.411765$，以及 $\\text{F1}_w(\\tau_1^{\\text{shift}}) \\approx 0.552632$。\n\n**类别 $y=2$**\n\n对类别 $y=2$ 的数据遵循相同的过程：\n$\\mathbf{s}^{(2)} = [0.99, ..., 0.02]$, $\\mathbf{y}^{(2)} = [1, ..., 0]$\n$\\pi_2 = 2/12 = 1/6$，目标 $\\pi_2' = 1/6$。\n在这种特殊情况下，先验没有改变，$\\pi_2' = \\pi_2$。\n这意味着重要性权重为 $w_{+} = 1$ 和 $w_{-} = 1$。加权 F1 分数与未加权 F1 分数相同，即对于所有 $\\tau$，$\\text{F1}_w(\\tau) = \\text{F1}(\\tau)$。因此，优化问题没有改变。\n- 未加权优化得出的最大 F1 分数为 $2/3 \\approx 0.666667$，这发生在阈值 $\\tau \\in \\{0.60, 0.99\\}$。应用打破平局的规则，我们得到 $\\tau_2 = 0.60$。\n- 由于问题未变，$\\tau_2^{\\text{shift}} = \\tau_2 = 0.60$。\n- 最终指标为：$\\tau_2 = 0.60$，$\\tau_2^{\\text{shift}} = 0.60$，$\\Delta \\tau_2 = 0.0$，$\\text{F1}_w(\\tau_2) \\approx 0.666667$，以及 $\\text{F1}_w(\\tau_2^{\\text{shift}}) \\approx 0.666667$。\n\n这些计算出的值将通过编程计算并按要求格式化。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to perform the analysis for all three classes and print the final results.\n    \"\"\"\n    \n    # Define the datasets and target priors for each class as per the problem statement.\n    problem_data = [\n        {\n            \"class_id\": 0,\n            \"scores\": np.array([0.95, 0.80, 0.60, 0.55, 0.52, 0.50, 0.40, 0.30, 0.20, 0.10, 0.05, 0.01]),\n            \"labels\": np.array([1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0]),\n            \"pi_prime\": 0.70\n        },\n        {\n            \"class_id\": 1,\n            \"scores\": np.array([0.90, 0.88, 0.70, 0.65, 0.60, 0.55, 0.50, 0.49, 0.35, 0.33, 0.25, 0.15]),\n            \"labels\": np.array([1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0]),\n            \"pi_prime\": 0.20\n        },\n        {\n            \"class_id\": 2,\n            \"scores\": np.array([0.99, 0.85, 0.75, 0.60, 0.45, 0.40, 0.35, 0.32, 0.20, 0.18, 0.10, 0.02]),\n            \"labels\": np.array([1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]),\n            \"pi_prime\": 1/6\n        }\n    ]\n\n    all_results = []\n\n    for data in problem_data:\n        scores = data[\"scores\"]\n        labels = data[\"labels\"]\n        pi_y_prime = data[\"pi_prime\"]\n\n        n = len(labels)\n        positives_count = np.sum(labels)\n        \n        # Guard against zero positive instances\n        if positives_count == 0:\n            pi_y = 0.0\n        else:\n            pi_y = positives_count / n\n\n        # Define candidate thresholds according to the problem specification\n        candidate_thresholds = np.unique(scores)\n        candidate_thresholds = np.append(candidate_thresholds, 0)\n        candidate_thresholds = np.append(candidate_thresholds, np.max(scores) + 1e-12)\n        candidate_thresholds = np.unique(candidate_thresholds) # Ensure no duplicates\n\n        # Calculate importance weights, handle edge case if pi_y is 0 or 1\n        w_plus, w_minus = 1.0, 1.0\n        if pi_y > 0 and pi_y  1:\n            w_plus = pi_y_prime / pi_y\n            w_minus = (1 - pi_y_prime) / (1 - pi_y)\n        elif pi_y == 0 and pi_y_prime > 0:\n            # Undefined case, but won't happen with given data\n            pass\n        elif pi_y == 1 and pi_y_prime  1:\n            # Undefined case, but won't happen with given data\n            pass\n\n        unweighted_f1_results = []\n        weighted_f1_results = []\n\n        for tau in candidate_thresholds:\n            predictions = (scores >= tau).astype(int)\n            \n            tp = np.sum((predictions == 1)  (labels == 1))\n            fp = np.sum((predictions == 1)  (labels == 0))\n            fn = positives_count - tp\n\n            # Calculate unweighted F1\n            f1_denom = 2 * tp + fp + fn\n            f1 = (2 * tp) / f1_denom if f1_denom > 0 else 0.0\n            unweighted_f1_results.append((f1, tau))\n\n            # Calculate weighted F1\n            tp_w = w_plus * tp\n            fp_w = w_minus * fp\n            fn_w = w_plus * fn\n            \n            f1_w_denom = 2 * tp_w + fp_w + fn_w\n            f1_w = (2 * tp_w) / f1_w_denom if f1_w_denom > 0 else 0.0\n            weighted_f1_results.append((f1_w, tau))\n\n        # Find optimal thresholds by sorting.\n        # Primary sort key: F1 score (descending), Secondary sort key: threshold (ascending)\n        unweighted_f1_results.sort(key=lambda x: (-x[0], x[1]))\n        weighted_f1_results.sort(key=lambda x: (-x[0], x[1]))\n\n        tau_y = unweighted_f1_results[0][1]\n        tau_y_shift = weighted_f1_results[0][1]\n        max_weighted_f1 = weighted_f1_results[0][0]\n\n        # Find the weighted F1 at the original optimal threshold\n        f1_w_at_tau_y = 0.0\n        for f1_w, tau in weighted_f1_results:\n            if np.isclose(tau, tau_y):\n                f1_w_at_tau_y = f1_w\n                break\n        \n        delta_tau_y = np.abs(tau_y_shift - tau_y)\n\n        class_results = [\n            tau_y,\n            tau_y_shift,\n            delta_tau_y,\n            f1_w_at_tau_y,\n            max_weighted_f1\n        ]\n        all_results.extend(class_results)\n    \n    # Format the final output string\n    formatted_results = [f\"{x:.6f}\" for x in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3178377"}, {"introduction": "标准的训练流程通常将所有数据点一视同仁，但这是否是最高效的学习方式？本练习 [@problem_id:3178388] 将介绍“课程学习”这一受人类教育启发的策略，即让模型先学习简单的样本，再逐步接触复杂的样本。你将基于条件熵来设计并实现一个课程，并通过实验量化这种智能训练策略相比于传统随机混洗方法在模型收敛速度上的优势。", "problem": "在深度学习的监督式多类别分类场景中，给定一个学生模型，该模型是一个由权重 $\\theta$ 参数化的线性 softmax 分类器，实现一个函数 $f_{\\theta}$，它将输入 $\\mathbf{x} \\in \\mathbb{R}^d$ 映射到 $K$ 个类别上的分类分布。一个教师模型为每个训练样本提供概率性评估 $p_T(y \\mid \\mathbf{x})$，该评估仅用于通过条件标签熵来定义课程顺序。您的任务是实现并比较两种针对学生模型的训练计划：一种是使用标准训练样本随机洗牌的基线计划，另一种是根据教师评估的低条件熵 $H(y \\mid \\mathbf{x})$ 对训练样本进行排序的课程计划。\n\n基本假设和定义如下：\n\n- 监督学习的目标是在训练集上进行经验风险最小化，使用学生模型的预测分布与真实标签之间的交叉熵损失。\n- 教师通过一个明确定义的概率机制生成 $p_T(y \\mid \\mathbf{x})$；这不用于监督，而仅用于通过条件熵构建训练计划。\n- 条件标签熵由教师分布的香农熵定义，并用于对样本进行排序。\n- 优化通过在学生 softmax 分类器上使用固定学习率的小批量梯度下降来执行。\n\n按以下纯数学和逻辑术语构建一个合成数据集和训练过程：\n\n- 设类别数为 $K = 3$，特征维度为 $d = 2$。固定类别均值 $\\boldsymbol{\\mu}_0 = (-2, 0)$、$\\boldsymbol{\\mu}_1 = (2, 0)$ 和 $\\boldsymbol{\\mu}_2 = (0, 2)$。对于每个类别 $k \\in \\{0, 1, 2\\}$，从均值为 $\\boldsymbol{\\mu}_k$、协方差为 $\\sigma_{\\text{data}}^2 \\mathbf{I}_2$ 的高斯分布中独立生成训练点和验证点，其中 $\\sigma_{\\text{data}}  0$ 且 $\\mathbf{I}_2$ 是 $2 \\times 2$ 的单位矩阵。\n- 通过减去经验训练均值并除以每个特征维度的经验训练标准差来标准化特征。将相同的仿射变换应用于验证集和类别均值。\n- 设教师分布由一个径向基函数机制定义：对于每个标准化输入 $\\mathbf{x}$，计算 logits $\\ell_k(\\mathbf{x}) = -\\lVert \\mathbf{x} - \\boldsymbol{\\mu}_k \\rVert^2 / (2 \\tau_T^2)$，其中 $k \\in \\{0, 1, 2\\}$，并将 $p_T(y = k \\mid \\mathbf{x})$ 设置为 $\\ell_k(\\mathbf{x})$ 的 softmax 值，其中 $\\tau_T  0$ 控制教师的置信度。\n- 定义教师评估的条件标签熵 $H_T(\\mathbf{x}) = -\\sum_{k=0}^{2} p_T(y = k \\mid \\mathbf{x}) \\log p_T(y = k \\mid \\mathbf{x})$，并通过按 $H_T(\\mathbf{x})$ 的升序对训练样本进行排序来构建课程。\n- 将训练标签中的一部分（比例为 $\\rho \\in [0, 1)$）在不正确的类别中进行均匀随机损坏，损坏率 $\\rho$ 由每个测试用例指定。验证标签不被损坏。\n- 使用梯度下降法，在真实标签的经验交叉熵上，以大小为 $B$ 的小批量数据训练学生线性 softmax 分类器 $f_{\\theta}$。用小的随机权重初始化 $\\theta$，并通过用一个常数分量增强输入来包含偏置项。使用固定的学习率 $\\eta  0$。\n- 将收敛速度定义为验证准确率（正确预测标签的比例）达到或超过目标阈值 $\\alpha \\in (0, 1)$ 所需的参数更新步数，如果未达到阈值，则为最大步数 $S_{\\max}$。\n\n实现两种计划：\n- 基线计划：在每个 epoch 中，根据训练样本的全新随机洗牌来处理小批量数据。\n- 课程计划：在每个 epoch 中，按照 $H_T(\\mathbf{x})$ 升序排列的固定顺序处理小批量数据。\n\n对于下面的每个测试用例，从相同的初始化开始运行两种计划，并报告收敛步数的整数差异，定义为 $\\text{difference} = \\text{baseline\\_steps} - \\text{curriculum\\_steps}$。\n\n测试套件规格（每个元组指定 $(\\text{seed}, N_{\\text{train}}, N_{\\text{val}}, \\sigma_{\\text{data}}, \\tau_T, \\rho, \\alpha, B, S_{\\max})$）：\n\n- 案例 1 (常规顺利路径): $(42, 360, 240, 0.7, 1.0, 0.0, 0.85, 32, 4000)$。\n- 案例 2 (边界情况，近乎均匀的教师): $(7, 360, 240, 0.7, 10.0, 0.0, 0.85, 32, 4000)$。\n- 案例 3 (边缘情况，标签噪声): $(13, 360, 240, 0.9, 1.0, 0.3, 0.70, 32, 5000)$。\n- 案例 4 (边缘情况，小数据集): $(123, 60, 60, 0.6, 0.8, 0.0, 0.85, 16, 3000)$。\n\n最终输出格式要求：\n- 您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。具体来说，打印列表 $[\\Delta_1, \\Delta_2, \\Delta_3, \\Delta_4]$，其中每个 $\\Delta_i$ 是上述测试用例按顺序列出的相应步数差异的整数值 $\\text{baseline\\_steps} - \\text{curriculum\\_steps}$。", "solution": "该问题是有效的。它在机器学习的课程学习领域内，提出了一个定义明确、有科学依据且客观的计算实验。所有参数、模型和过程都得到了充分清晰的说明，足以得出一个唯一且可复现的解。其目标是比较一个线性 softmax 分类器在两种不同训练计划下的收敛速度：一种是带随机洗牌的标准基线计划，另一种是基于教师评估的条件标签熵的课程计划。必须为未指定的学习率 $\\eta$ 选择一个合理的值；将使用标准值 $\\eta=0.1$，因为它适用于此类梯度下降问题，并且分析的比较性质取决于一致性，而非特定的最优值。\n\n### 1. 数学和算法公式化\n\n#### 1.1. 数据生成和预处理\n数据集由训练样本和验证样本组成。对于每个类别 $k \\in \\{0, 1, 2\\}$，特征向量 $\\mathbf{x} \\in \\mathbb{R}^2$ 从一个各向同性的高斯分布 $\\mathcal{N}(\\boldsymbol{\\mu}_k, \\sigma_{\\text{data}}^2 \\mathbf{I}_2)$ 中抽取，其中 $\\mathbf{I}_2$ 是 $2 \\times 2$ 的单位矩阵，类别均值为 $\\boldsymbol{\\mu}_0 = (-2, 0)$、$\\boldsymbol{\\mu}_1 = (2, 0)$ 和 $\\boldsymbol{\\mu}_2 = (0, 2)$。\n\n特征基于训练数据进行标准化。设训练集特征为 $\\{\\mathbf{x}_i^{\\text{train}}\\}_{i=1}^{N_{\\text{train}}}$。计算每个特征维度的经验均值 $\\boldsymbol{\\mu}_{\\text{emp}}$ 和标准差 $\\boldsymbol{\\sigma}_{\\text{emp}}$：\n$$ \\boldsymbol{\\mu}_{\\text{emp}} = \\frac{1}{N_{\\text{train}}} \\sum_{i=1}^{N_{\\text{train}}} \\mathbf{x}_i^{\\text{train}} \\quad \\text{以及} \\quad \\boldsymbol{\\sigma}_{\\text{emp}} = \\sqrt{\\frac{1}{N_{\\text{train}}} \\sum_{i=1}^{N_{\\text{train}}} (\\mathbf{x}_i^{\\text{train}} - \\boldsymbol{\\mu}_{\\text{emp}})^2} $$\n然后通过仿射变换获得标准化特征向量 $\\mathbf{x}_{\\text{std}}$：\n$$ \\mathbf{x}_{\\text{std}} = (\\mathbf{x} - \\boldsymbol{\\mu}_{\\text{emp}}) / \\boldsymbol{\\sigma}_{\\text{emp}} $$\n同样的变换也应用于训练特征、验证特征和类别均值 $\\boldsymbol{\\mu}_k$。\n\n#### 1.2. 教师模型和课程排序\n教师模型提供一个概率性评估 $p_T(y | \\mathbf{x})$，仅用于对训练样本进行排序。对于一个标准化的输入 $\\mathbf{x}_{\\text{std}}$，教师使用以标准化类别均值 $\\boldsymbol{\\mu}_{k, \\text{std}}$ 为中心的径向基函数 (RBF) 核为每个类别 $k$ 计算 logits $\\ell_k(\\mathbf{x}_{\\text{std}})$：\n$$ \\ell_k(\\mathbf{x}_{\\text{std}}) = -\\frac{\\lVert \\mathbf{x}_{\\text{std}} - \\boldsymbol{\\mu}_{k, \\text{std}} \\rVert^2}{2 \\tau_T^2} $$\n其中 $\\tau_T$ 是一个控制教师置信度的温度参数。教师的概率分布是这些 logits 的 softmax：\n$$ p_T(y=k \\mid \\mathbf{x}_{\\text{std}}) = \\frac{\\exp(\\ell_k(\\mathbf{x}_{\\text{std}}))}{\\sum_{j=0}^{K-1} \\exp(\\ell_j(\\mathbf{x}_{\\text{std}}))} $$\n样本的难度由从教师分布中导出的条件标签熵 $H_T(\\mathbf{x}_{\\text{std}})$ 来量化：\n$$ H_T(\\mathbf{x}_{\\text{std}}) = - \\sum_{k=0}^{K-1} p_T(y=k \\mid \\mathbf{x}_{\\text{std}}) \\log p_T(y=k \\mid \\mathbf{x}_{\\text{std}}) $$\n课程计划通过按熵 $H_T$ 的升序对训练样本进行排序来构建。熵低的样本被认为是“更容易的”，并首先呈现给学生模型。\n\n#### 1.3. 标签噪声\n为了模拟更具挑战性的学习环境，训练标签中的一部分（比例为 $\\rho$）会被损坏。对于每个选定的样本，其真实标签将被一个从不正确类别集合中均匀随机选择的标签所取代。\n\n#### 1.4. 学生模型：线性 Softmax 分类器\n学生模型是一个线性分类器。为了引入偏置项，每个标准化输入 $\\mathbf{x}_{\\text{std}} \\in \\mathbb{R}^d$ 被增广为 $\\mathbf{x}' = [\\mathbf{x}_{\\text{std}}^T, 1]^T \\in \\mathbb{R}^{d+1}$。该模型由一个权重矩阵 $\\theta \\in \\mathbb{R}^{K \\times (d+1)}$ 参数化，其中 $K=3$ 且 $d=2$。权重通过从正态分布 $\\mathcal{N}(0, 0.01^2)$ 中抽样的小随机值进行初始化。\n\n对于一个输入 $\\mathbf{x}'$，学生模型计算 logits $\\mathbf{z} \\in \\mathbb{R}^K$ 如下：\n$$ \\mathbf{z} = \\theta \\mathbf{x}' $$\n学生模型在类别上的预测分布 $\\hat{\\mathbf{y}}$ 由 softmax 函数给出：\n$$ \\hat{y}_k = \\frac{\\exp(z_k)}{\\sum_{j=0}^{K-1} \\exp(z_j)} $$\n\n#### 1.5. 训练与优化\n该模型通过最小化训练数据上的经验交叉熵损失来进行训练。对于一个大小为 $B$ 的小批量 $\\mathcal{B}$，损失 $\\mathcal{L}_{\\mathcal{B}}$ 为：\n$$ \\mathcal{L}_{\\mathcal{B}}(\\theta) = -\\frac{1}{B} \\sum_{(\\mathbf{x}'_i, y_i) \\in \\mathcal{B}} \\log(\\hat{y}_{i, y_i}) $$\n其中 $y_i$ 是第 $i$ 个样本的（可能被损坏的）真实标签，而 $\\hat{y}_{i, y_i}$ 是模型对该真实类别预测的概率。\n\n参数 $\\theta$ 使用小批量梯度下降进行更新。损失函数关于 $\\theta$ 的小批量梯度为：\n$$ \\nabla_{\\theta} \\mathcal{L}_{\\mathcal{B}} = \\frac{1}{B} \\sum_{i=1}^{B} (\\hat{\\mathbf{y}}_i - \\mathbf{y}_{\\text{one-hot}, i}) (\\mathbf{x}'_i)^T $$\n其中 $\\mathbf{y}_{\\text{one-hot}, i}$ 是真实标签 $y_i$ 的独热编码向量。参数更新规则是：\n$$ \\theta_{t+1} = \\theta_t - \\eta \\nabla_{\\theta} \\mathcal{L}_{\\mathcal{B}}(\\theta_t) $$\n其中 $t$ 是更新步骤，$\\eta=0.1$ 是固定的学习率。\n\n#### 1.6. 评估\n比较两种计划：\n1.  **基线计划**：在每个 epoch 中，训练数据以全新的、随机洗牌的顺序进行处理。\n2.  **课程计划**：在每个 epoch 中，训练数据按照教师评估的熵值升序确定的固定顺序进行处理。\n\n对于每个计划，训练最多进行 $S_{\\max}$ 个参数更新步骤。每一步之后，在未损坏的验证集上评估模型的准确率。收敛速度以首次达到或超过目标验证准确率 $\\alpha$ 所需的步数来衡量。如果在 $S_{\\max}$ 步内未达到目标，则步数记为 $S_{\\max}$。\n\n每个测试用例最终报告的指标是收敛步数的差异：$\\Delta = \\text{steps}_{\\text{baseline}} - \\text{steps}_{\\text{curriculum}}$。正值表示课程计划收敛得更快。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the specified test cases and print the results.\n    \"\"\"\n\n    test_cases = [\n        # (seed, N_train, N_val, sigma_data, tau_T, rho, alpha, B, S_max)\n        (42, 360, 240, 0.7, 1.0, 0.0, 0.85, 32, 4000),\n        (7, 360, 240, 0.7, 10.0, 0.0, 0.85, 32, 4000),\n        (13, 360, 240, 0.9, 1.0, 0.3, 0.70, 32, 5000),\n        (123, 60, 60, 0.6, 0.8, 0.0, 0.85, 16, 3000),\n    ]\n\n    results = []\n    for case in test_cases:\n        diff = run_single_case(*case)\n        results.append(diff)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef run_single_case(seed, N_train, N_val, sigma_data, tau_T, rho, alpha, B, S_max, eta=0.1):\n    \"\"\"\n    Executes one complete test case for both baseline and curriculum schedules.\n    \"\"\"\n    K = 3\n    d = 2\n    \n    rng = np.random.default_rng(seed)\n    \n    # 1. Data Generation\n    mus = np.array([[-2.0, 0.0], [2.0, 0.0], [0.0, 2.0]])\n    n_train_per_class = N_train // K\n    n_val_per_class = N_val // K\n    \n    X_train_list, y_train_list = [], []\n    X_val_list, y_val_list = [], []\n    for k in range(K):\n        cov = np.eye(d) * sigma_data**2\n        X_train_list.append(rng.multivariate_normal(mus[k], cov, n_train_per_class))\n        y_train_list.append(np.full(n_train_per_class, k, dtype=int))\n        X_val_list.append(rng.multivariate_normal(mus[k], cov, n_val_per_class))\n        y_val_list.append(np.full(n_val_per_class, k, dtype=int))\n        \n    X_train = np.vstack(X_train_list)\n    y_train = np.hstack(y_train_list)\n    X_val = np.vstack(X_val_list)\n    y_val = np.hstack(y_val_list)\n\n    # 2. Feature Standardization\n    train_mean = X_train.mean(axis=0)\n    train_std = X_train.std(axis=0)\n    # Prevent division by zero if a feature has zero variance\n    train_std[train_std == 0] = 1.0\n    \n    X_train_std = (X_train - train_mean) / train_std\n    X_val_std = (X_val - train_mean) / train_std\n    mus_std = (mus - train_mean) / train_std\n\n    X_train_aug = np.hstack([X_train_std, np.ones((N_train, 1))])\n    X_val_aug = np.hstack([X_val_std, np.ones((N_val, 1))])\n\n    # 3. Teacher Model and Curriculum Ordering\n    dists_sq = np.sum((X_train_std[:, np.newaxis, :] - mus_std[np.newaxis, :, :])**2, axis=2)\n    teacher_logits = -dists_sq / (2 * tau_T**2)\n    # Stable softmax\n    teacher_logits_max = np.max(teacher_logits, axis=1, keepdims=True)\n    teacher_exp_logits = np.exp(teacher_logits - teacher_logits_max)\n    teacher_probs = teacher_exp_logits / np.sum(teacher_exp_logits, axis=1, keepdims=True)\n    # Add a small epsilon to avoid log(0)\n    entropies = -np.sum(teacher_probs * np.log(teacher_probs + 1e-12), axis=1)\n    curriculum_indices = np.argsort(entropies)\n\n    # 4. Label Corruption\n    if rho > 0:\n        n_corrupt = int(rho * N_train)\n        corrupt_indices = rng.choice(N_train, n_corrupt, replace=False)\n        for i in corrupt_indices:\n            original_label = y_train[i]\n            possible_new_labels = [l for l in range(K) if l != original_label]\n            y_train[i] = rng.choice(possible_new_labels)\n            \n    # 5. Define initial weights for reproducibility\n    theta_init = rng.normal(0, 0.01, size=(K, d + 1))\n\n    # 6. Training and Evaluation Function\n    def train_and_evaluate(schedule_type):\n        theta = theta_init.copy()\n        num_batches = N_train // B\n        \n        indices = None\n        if schedule_type == 'curriculum':\n            # Fixed order for all epochs\n            indices = curriculum_indices\n        \n        for step in range(S_max):\n            epoch = step // num_batches\n            batch_in_epoch = step % num_batches\n            \n            if batch_in_epoch == 0:\n                if schedule_type == 'baseline':\n                    indices = rng.permutation(N_train)\n            \n            start_idx = batch_in_epoch * B\n            end_idx = start_idx + B\n            batch_indices = indices[start_idx:end_idx]\n\n            if len(batch_indices) == 0:\n                continue\n\n            X_batch = X_train_aug[batch_indices]\n            y_batch = y_train[batch_indices]\n\n            # Forward pass\n            logits = X_batch @ theta.T\n            \n            # Stable Softmax\n            logits_max = np.max(logits, axis=1, keepdims=True)\n            exp_logits = np.exp(logits - logits_max)\n            probs = exp_logits / np.sum(exp_logits, axis=1, keepdims=True)\n\n            # Gradient calculation\n            grad_z = probs\n            grad_z[np.arange(len(y_batch)), y_batch] -= 1\n            grad_z /= len(y_batch)\n            \n            grad_theta = grad_z.T @ X_batch\n            \n            # Parameter update\n            theta -= eta * grad_theta\n\n            # Validation\n            val_logits = X_val_aug @ theta.T\n            val_preds = np.argmax(val_logits, axis=1)\n            val_acc = np.mean(val_preds == y_val)\n            \n            if val_acc >= alpha:\n                return step + 1\n                \n        return S_max\n\n    baseline_steps = train_and_evaluate('baseline')\n    curriculum_steps = train_and_evaluate('curriculum')\n    \n    return baseline_steps - curriculum_steps\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3178388"}, {"introduction": "在人工智能广泛部署的今天，模型不仅是工具，也成为了攻击的目标。本项高级练习 [@problem_id:3178407] 将让你从零开始实现一次完整的“后门攻击”，从而深入了解机器学习安全这一关键领域。你将首先通过“毒化”数据集来训练一个被植入后门的模型，然后亲手实现并评估三种不同的防御机制——权重剪枝、干净数据微调和光谱分析——来消除这一潜在威胁。", "problem": "您的任务是从基本原理出发，实现一个深度学习中的监督式二元分类流程，该流程包括构建一个带有后门触发器的合成数据集、模型训练以及三种防御方法（幅度剪枝、在干净数据上进行微调和谱特征）。您的程序必须输出针对几个指定测试用例的攻击成功率。所有计算都必须以自包含的方式执行，使用经验风险最小化和基于梯度的优化的定义，不使用任何外部数据集。\n\n定义与设置：\n- 输入空间是一个维度为 $d = 64$ 的向量空间，表示将 $8 \\times 8$ 的灰度图像展平为 $\\mathbb{R}^{64}$ 中的向量。\n- 有两个类别，标签为 $y \\in \\{0, 1\\}$。类别 0 的原型图像在列索引为 2（从零开始计数）处有一条垂直条纹，类别 1 的原型图像在行索引为 5 处有一条水平条纹。为了生成类别 $y$ 的一个干净样本，从 $\\boldsymbol{\\epsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma^2 \\mathbf{I})$ (其中 $\\sigma = 0.2$) 中抽取一个样本 $\\boldsymbol{\\epsilon}$，并设置 $\\mathbf{x} = \\mathbf{p}_y + \\boldsymbol{\\epsilon}$，其中 $\\mathbf{p}_y \\in \\mathbb{R}^{64}$ 是类别 $y$ 的展平原型。\n- 后门触发器被定义为一个确定性变换 $T(\\mathbf{x})$，它在 $8 \\times 8$ 图像的第 6 到 7 行和第 6 到 7 列（从零开始的索引）位置的一个 $2 \\times 2$ 方形补丁上加上一个常数 $\\alpha$。使用 $\\alpha = 3.0$。\n- 训练集的构建如下：\n  - 为类别 0 生成 $n_0 = 200$ 个干净样本，为类别 1 生成 $n_1 = 200$ 个干净样本。\n  - 随机选择类别 0 样本中的一部分（比例为 $p = 0.2$，即 $p \\cdot n_0$ 个样本），对它们应用触发器 $T(\\cdot)$，并将其标签翻转为类别 1。所有其他样本保持其原始标签。这样就得到了一个标签空间为 $\\{0, 1\\}$ 的污染的训练集。\n- 用于评估攻击成功率的测试集，是通过生成 $m = 200$ 个来自类别 0 的干净样本，然后对所有这些样本应用触发器 $T(\\cdot)$ 来构建的。\n\n神经网络模型与训练：\n- 使用一个全连接神经网络，它有一个宽度为 $h = 32$ 的隐藏层，采用修正线性单元 (ReLU) 激活函数 $\\phi(u) = \\max\\{0, u\\}$，以及一个包含 2 个单元的 softmax 输出层。设参数为 $\\mathbf{W}_1 \\in \\mathbb{R}^{64 \\times 32}$、$\\mathbf{b}_1 \\in \\mathbb{R}^{32}$、$\\mathbf{W}_2 \\in \\mathbb{R}^{32 \\times 2}$ 和 $\\mathbf{b}_2 \\in \\mathbb{R}^{2}$。前向传播过程为\n$$\n\\mathbf{h} = \\phi(\\mathbf{X}\\mathbf{W}_1 + \\mathbf{b}_1), \\quad \\mathbf{Z} = \\mathbf{h}\\mathbf{W}_2 + \\mathbf{b}_2,\n$$\n对于 logits 为 $\\mathbf{z}$ 的样本，类别 $k \\in \\{0,1\\}$ 的 softmax 概率为\n$$\n\\mathrm{softmax}(\\mathbf{z})_k = \\frac{\\exp(z_k)}{\\sum_{j=0}^{1} \\exp(z_j)}.\n$$\n- 使用经验风险最小化和分类交叉熵损失。对于一个数据集 $\\{(\\mathbf{x}_i, y_i)\\}_{i=1}^{N}$，损失函数为\n$$\n\\mathcal{L}(\\Theta) = -\\frac{1}{N}\\sum_{i=1}^{N}\\sum_{k=0}^{1} \\mathbf{1}[y_i = k]\\ \\log p_\\Theta(y=k \\mid \\mathbf{x}_i),\n$$\n其中 $p_\\Theta(y=k \\mid \\mathbf{x}_i)$ 是类别 $k$ 的 softmax 输出，$\\Theta = (\\mathbf{W}_1, \\mathbf{b}_1, \\mathbf{W}_2, \\mathbf{b}_2)$。\n- 通过全批量梯度下降法优化 $\\mathcal{L}(\\Theta)$，学习率为 $\\eta_0 = 0.1$，共进行 $E_0 = 200$ 个周期，权重从 He 初始化开始，即 $\\mathbf{W}_1$ 的元素独立地从 $\\mathcal{N}(0, \\sqrt{2/64}^2)$ 中抽取，$\\mathbf{W}_2$ 的元素从 $\\mathcal{N}(0, \\sqrt{2/32}^2)$ 中抽取，偏置初始化为零。\n\n需要测试的防御方法：\n1. 幅度剪枝：给定一个训练好的模型，计算 $\\mathbf{W}_1$ 和 $\\mathbf{W}_2$ 中所有权重的绝对值大小集合（不包括偏置）。对于剪枝比例 $q \\in (0,1)$，找到这些大小的 $q$-分位数阈值，并将绝对值小于或等于此阈值的所有权重设为零（全局幅度剪枝）。\n2. 微调：给定一个训练好的模型，为每个类别（类别 0 和类别 1）生成一个包含 $c = 100$ 个样本的额外干净数据集，并以训练好的模型参数为起点，仅在该干净数据上使用学习率 $\\eta_f = 0.05$ 执行 $S$ 步全批量梯度下降。\n3. 谱特征：给定一个训练好的模型，计算所有训练样本的倒数第二层激活值 $\\mathbf{h}_i$。对于每个类别 $k \\in \\{0,1\\}$，构建矩阵 $\\mathbf{H}^{(k)} \\in \\mathbb{R}^{N_k \\times h}$，其行由标签为 $k$ 的样本的 $\\mathbf{h}_i$ 给出，通过减去 $\\mathbf{H}^{(k)}$ 的行均值来中心化，并计算其奇异值分解 (SVD; Singular Value Decomposition) $\\mathbf{H}^{(k)} = \\mathbf{U}\\mathbf{\\Sigma}\\mathbf{V}^\\top$。令 $\\mathbf{v}^{(k)} \\in \\mathbb{R}^{h}$ 为顶层右奇异向量（$\\mathbf{V}^\\top$ 的第一行）。对于中心化后的 $\\mathbf{H}^{(k)}$ 的每一行 $\\mathbf{r}$，分配一个异常值得分 $s = |\\mathbf{r} \\cdot \\mathbf{v}^{(k)}|$。从每个类别中移除具有最大 $s$ 值的顶层比例为 $r \\in (0,1)$ 的样本，然后在剩余的（经过筛选的）训练集上使用上述学习率 $\\eta_0$ 从头开始训练一个新模型，共进行 $E_1 = 150$ 个周期。\n\n攻击成功率 (ASR; Attack Success Rate)：\n- 对于任何训练好的模型，攻击成功率定义为\n$$\n\\mathrm{ASR} = \\frac{1}{m}\\sum_{i=1}^{m} \\mathbf{1}\\left[\\hat{y}_i = 1\\right],\n$$\n其中 $\\hat{y}_i$ 是对第 $i$ 个原始来自类别 0 的触发测试样本的预测类别。将 $\\mathrm{ASR}$ 报告为 $[0,1]$ 范围内的小数。\n\n测试套件：\n对所有随机操作使用以下固定的随机种子 $s = 1337$。如前所述，在污染的训练集上训练一个基线模型。然后，对于下面的每个测试用例，从基线模型开始应用指定的防御方法（谱特征情况除外，它需要在筛选后的数据上重新训练），并计算在触发测试集上相应的攻击成功率：\n- 用例 1：无防御。\n- 用例 2：幅度剪枝，剪枝比例 $q = 0.2$。\n- 用例 3：幅度剪枝，剪枝比例 $q = 0.6$。\n- 用例 4：微调，步数为 $S = 100$。\n- 用例 5：谱特征，移除比例 $r = 0.1$。\n- 用例 6：谱特征，移除比例 $r = 0.3$。\n\n输出规范：\n- 您的程序应生成单行输出，其中包含用例 1 到 6 的攻击成功率，形式为一个逗号分隔的浮点数列表，四舍五入到 3 位小数，并用方括号括起来。例如，一个包含假设值的输出应如下所示：\n\"[0.950,0.800,0.420,0.700,0.300,0.150]\".", "solution": "问题陈述已经过分析，并被认为是有效的。它具有科学依据、问题明确、客观，并包含进行求解所需的所有必要信息。它描述了深度学习安全领域一个完整且可验证的计算实验。\n\n### 基于原理的设计\n\n该解决方案实现了一个监督式二元分类流程，以演示后门攻击并评估几种防御方法。实现基于神经网络和梯度优化法的基本原理。\n\n#### 1. 数据生成\n\n整个过程始于以编程方式生成一个合成数据集。\n- **原型**：定义了两个大小为 $8 \\times 8$ 的原型图像，每个类别一个。类别 0 对应于第 2 列的垂直条纹，类别 1 对应于第 5 行的水平条纹。这些图像被展平为向量 $\\mathbf{p}_0, \\mathbf{p}_1 \\in \\mathbb{R}^{64}$。\n- **干净数据**：通过向相应原型添加高斯噪声来生成一个干净数据样本 $(\\mathbf{x}, y)$（类别为 $y \\in \\{0, 1\\}$）：$\\mathbf{x} = \\mathbf{p}_y + \\boldsymbol{\\epsilon}$，其中 $\\boldsymbol{\\epsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma^2 \\mathbf{I})$ 且 $\\sigma = 0.2$。\n- **后门触发器**：定义了一个触发器变换 $T(\\cdot)$，它将一个常数值 $\\alpha = 3.0$ 添加到图像右下角一个固定的 $2 \\times 2$ 像素补丁上。\n- **污染的训练集**：构建了一个包含 $N=400$ 个样本的训练集。初始时，为类别 0 生成 $n_0 = 200$ 个干净样本，为类别 1 生成 $n_1 = 200$ 个。选择类别 0 样本中比例为 $p = 0.2$ 的一部分（即 40 个样本）。对这些选定的样本应用触发器 $T(\\cdot)$，并将其标签从 $y=0$ 翻转为 $y=1$。这就创建了污染的训练集，模型被秘密地教导将触发器模式与类别 1 关联起来。\n- **攻击测试集**：为了评估攻击的有效性，通过生成 $m = 200$ 个新的类别 0 干净样本并对所有这些样本应用触发器 $T(\\cdot)$ 来创建了一个单独的测试集。\n\n#### 2. 神经网络模型与训练\n\n- **架构**：采用了一个带有一个隐藏层的全连接神经网络。架构为 $64 \\to 32 \\to 2$。\n    - 输入层维度：$d=64$。\n    - 隐藏层维度：$h=32$，使用 ReLU 激活函数 $\\phi(u) = \\max\\{0, u\\}$。\n    - 输出层维度：2（对应两个类别），使用 softmax 激活函数。\n- **前向传播**：对于一批输入数据 $\\mathbf{X}$，模型计算：\n    $$ \\mathbf{Z}_1 = \\mathbf{X}\\mathbf{W}_1 + \\mathbf{b}_1 $$\n    $$ \\mathbf{H} = \\phi(\\mathbf{Z}_1) $$\n    $$ \\mathbf{Z}_2 = \\mathbf{H}\\mathbf{W}_2 + \\mathbf{b}_2 $$\n    $$ \\mathbf{P} = \\mathrm{softmax}(\\mathbf{Z}_2) $$\n    其中 $\\Theta = (\\mathbf{W}_1, \\mathbf{b}_1, \\mathbf{W}_2, \\mathbf{b}_2)$ 是模型参数，$\\mathbf{Z}_2$ 是输出 logits，$\\mathbf{P}$ 是预测的类别概率。\n- **初始化**：权重使用 He 初始化进行初始化。$\\mathbf{W}_1$ 的条目从 $\\mathcal{N}(0, 2/64)$ 中抽取，$\\mathbf{W}_2$ 的条目从 $\\mathcal{N}(0, 2/32)$ 中抽取。所有偏置 $\\mathbf{b}_1, \\mathbf{b}_2$ 初始化为零。\n- **训练**：模型使用经验风险最小化在整个训练批次上进行训练（全批量梯度下降）。\n    - **损失函数**：最小化分类交叉熵损失：\n      $$ \\mathcal{L}(\\Theta) = -\\frac{1}{N}\\sum_{i=1}^{N}\\sum_{k=0}^{1} \\mathbf{Y}_{ik}\\ \\log \\mathbf{P}_{ik} $$\n      其中 $\\mathbf{Y}$ 是真实标签的独热编码矩阵。\n    - **反向传播**：损失相对于参数的梯度通过链式法则计算：\n      $$ \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{Z}_2} = \\frac{1}{N}(\\mathbf{P} - \\mathbf{Y}) $$\n      $$ \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}_2} = \\mathbf{H}^\\top \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{Z}_2}, \\quad \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{b}_2} = \\sum_{i=1}^{N} \\left(\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{Z}_2}\\right)_i $$\n      $$ \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}_1} = \\mathbf{X}^\\top \\left( \\left( \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{Z}_2} \\mathbf{W}_2^\\top \\right) \\odot \\phi'(\\mathbf{Z}_1) \\right), \\quad \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{b}_1} = \\sum_{i=1}^{N} \\left(\\left( \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{Z}_2} \\mathbf{W}_2^\\top \\right) \\odot \\phi'(\\mathbf{Z}_1)\\right)_i $$\n      其中 $\\odot$ 表示逐元素乘法，$\\phi'$ 是 ReLU 函数的导数。\n    - **参数更新**：参数迭代更新：$\\Theta \\leftarrow \\Theta - \\eta \\nabla_\\Theta \\mathcal{L}$。\n\n#### 3. 攻击评估\n\n主要指标是攻击成功率 (ASR)，定义为被错误分类为类别 1 的触发测试样本（原始来自类别 0）的比例：\n$$ \\mathrm{ASR} = \\frac{1}{m}\\sum_{i=1}^{m} \\mathbf{1}\\left[\\hat{y}_i = 1\\right] $$\n其中 $\\hat{y}_i$ 是对攻击测试集中第 $i$ 个样本的预测标签。高 ASR 表示后门攻击成功。\n\n#### 4. 防御机制\n\n实现并评估了三种不同的防御策略。\n\n1.  **幅度剪枝**：这种防御方法假设，如果触发器是一个微妙的特征，那么与后门相关的神经元和权重可能具有较小的幅度。它的操作方式是从训练好的模型中移除绝对值幅度最小的一部分权重（比例为 $q$）。汇集 $\\mathbf{W}_1$ 和 $\\mathbf{W}_2$ 中的所有权重参数，计算它们的绝对值，并将一个全局阈值确定为这些幅度的 $q$-分位数。任何绝对值小于或等于此阈值的权重都被设置为零。\n\n2.  **微调**：这种防御试图通过在一个小的、干净的数据集上重新训练模型来“忘掉”后门。生成一个每个类别包含 $c=100$ 个样本的干净数据集。从受损模型的参数开始，在这个干净的数据上使用较小的学习率 $\\eta_f = 0.05$ 执行 $S=100$ 步的全批量梯度下降。\n\n3.  **谱特征**：这种防御通过分析模型的内部表示来识别并从训练集中移除被污染的样本。\n    - 首先，使用基线模型为污染训练集中的所有样本计算倒数第二层激活值 $\\mathbf{h}_i$。\n    - 对于每个类别 $k \\in \\{0, 1\\}$（基于污染标签），将激活值收集到一个矩阵 $\\mathbf{H}^{(k)}$ 中。\n    - 通过减去平均激活向量来中心化此矩阵：$\\mathbf{H}^{(k)}_{\\text{centered}} = \\mathbf{H}^{(k)} - \\overline{\\mathbf{H}^{(k)}}$。\n    - 计算中心化矩阵的奇异值分解 (SVD)。提取顶层右奇异向量 $\\mathbf{v}^{(k)}$（第一主成分）。这个向量通常对应于最大方差的方向，这可能是由被污染样本的聚类引起的。\n    - 对于类别 $k$ 中的每个样本 $i$，计算一个异常值得分 $s_i = |\\mathbf{r}_i \\cdot \\mathbf{v}^{(k)}|$，其中 $\\mathbf{r}_i$ 是 $\\mathbf{H}^{(k)}_{\\text{centered}}$ 中的相应行。得分高的样本被认为是异常的。\n    - 从训练集的每个类别中移除异常值得分最高的一部分（比例为 $r$）样本。\n    - 最后，在这个经过筛选的数据集上从头开始训练一个新模型，共进行 $E_1=150$ 个周期。\n\n#### 5. 执行流程\n\n程序按顺序执行以下步骤：\n1.  设置一个固定的随机种子 ($1337$) 以确保可复现性。\n2.  生成污染的训练数据和触发的测试数据。\n3.  在污染数据上训练一个基线模型。\n4.  为无防御的基线模型计算 ASR（用例 1）。\n5.  应用防御方法：\n    - 对基线模型的副本应用幅度剪枝，比例为 $q=0.2$（用例 2）和 $q=0.6$（用例 3）。\n    - 对基线模型的副本应用微调（用例 4）。\n    - 对训练数据应用谱特征防御，移除比例为 $r=0.1$（用例 5）和 $r=0.3$（用例 6），然后重新训练新模型。\n6.  为五个防御后的模型分别计算 ASR。\n7.  收集六个 ASR 值，并以指定的格式打印。", "answer": "```python\nimport numpy as np\nfrom scipy.linalg import svd\n\ndef solve():\n    # Fixed parameters from problem statement\n    D_IN, D_HIDDEN, D_OUT = 64, 32, 2\n    IMG_SIZE = 8\n    SIGMA = 0.2\n    ALPHA = 3.0\n    N0, N1 = 200, 200\n    P_POISON = 0.2\n    M_TEST = 200\n    SEED = 1337\n\n    ETA0 = 0.1\n    EPOCHS0 = 200\n    \n    Q_PRUNE_1, Q_PRUNE_2 = 0.2, 0.6\n    \n    C_FINETUNE = 100\n    S_FINETUNE = 100\n    ETA_F = 0.05\n\n    R_SPECTRAL_1, R_SPECTRAL_2 = 0.1, 0.3\n    EPOCHS1 = 150\n\n    rng = np.random.default_rng(SEED)\n\n    def generate_prototypes():\n        p0 = np.zeros((IMG_SIZE, IMG_SIZE))\n        p0[:, 2] = 1.0\n        p1 = np.zeros((IMG_SIZE, IMG_SIZE))\n        p1[5, :] = 1.0\n        return p0.flatten(), p1.flatten()\n\n    def apply_trigger(X_img):\n        X_triggered_img = X_img.copy()\n        X_triggered_img[:, 6:8, 6:8] += ALPHA\n        return X_triggered_img\n\n    def generate_data(n_samples_per_class, prototypes, noise_sigma):\n        p0, p1 = prototypes\n        X0 = rng.normal(loc=p0, scale=noise_sigma, size=(n_samples_per_class, D_IN))\n        y0 = np.zeros(n_samples_per_class, dtype=int)\n        X1 = rng.normal(loc=p1, scale=noise_sigma, size=(n_samples_per_class, D_IN))\n        y1 = np.ones(n_samples_per_class, dtype=int)\n        return X0, y0, X1, y1\n        \n    class NeuralNetwork:\n        def __init__(self, rng_instance):\n            self.rng = rng_instance\n            self.W1 = self.rng.normal(0, np.sqrt(2 / D_IN), (D_IN, D_HIDDEN))\n            self.b1 = np.zeros(D_HIDDEN)\n            self.W2 = self.rng.normal(0, np.sqrt(2 / D_HIDDEN), (D_HIDDEN, D_OUT))\n            self.b2 = np.zeros(D_OUT)\n\n        def clone(self):\n            cloned_model = NeuralNetwork(self.rng)\n            cloned_model.W1 = self.W1.copy()\n            cloned_model.b1 = self.b1.copy()\n            cloned_model.W2 = self.W2.copy()\n            cloned_model.b2 = self.b2.copy()\n            return cloned_model\n\n        def forward(self, X):\n            z1 = X @ self.W1 + self.b1\n            h = np.maximum(0, z1)\n            z2 = h @ self.W2 + self.b2\n            return z2, h, z1\n\n        def predict_probs(self, X):\n            z2, _, _ = self.forward(X)\n            exp_scores = np.exp(z2 - np.max(z2, axis=1, keepdims=True))\n            return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n\n        def predict(self, X):\n            return np.argmax(self.predict_probs(X), axis=1)\n\n        def train(self, X, y, epochs, learning_rate):\n            n_samples = X.shape[0]\n            y_one_hot = np.zeros((n_samples, D_OUT))\n            y_one_hot[np.arange(n_samples), y] = 1\n\n            for _ in range(epochs):\n                # Full-batch gradient descent\n                z2, h, z1 = self.forward(X)\n                \n                # Softmax\n                probs = self.predict_probs(X)\n                \n                # Gradients for output layer\n                d_z2 = (probs - y_one_hot) / n_samples\n                d_W2 = h.T @ d_z2\n                d_b2 = np.sum(d_z2, axis=0)\n                \n                # Gradients for hidden layer\n                d_h = d_z2 @ self.W2.T\n                d_z1 = d_h * (z1 > 0)\n                d_W1 = X.T @ d_z1\n                d_b1 = np.sum(d_z1, axis=0)\n                \n                # Update weights\n                self.W1 -= learning_rate * d_W1\n                self.b1 -= learning_rate * d_b1\n                self.W2 -= learning_rate * d_W2\n                self.b2 -= learning_rate * d_b2\n                \n    def calculate_asr(model, X_triggered_test):\n        preds = model.predict(X_triggered_test)\n        asr = np.mean(preds == 1)\n        return asr\n\n    # --- Data Preparation ---\n    prototypes = generate_prototypes()\n    p0, p1 = prototypes\n    \n    # Poisoned Training Set\n    X0_train, y0_train, X1_train, y1_train = generate_data(N0, prototypes, SIGMA)\n    \n    n_poison = int(P_POISON * N0)\n    poison_indices = rng.choice(N0, n_poison, replace=False)\n    \n    X0_to_poison = X0_train[poison_indices]\n    X0_to_poison_img = X0_to_poison.reshape(-1, IMG_SIZE, IMG_SIZE)\n    X_poisoned_img = apply_trigger(X0_to_poison_img)\n    X_poisoned = X_poisoned_img.reshape(-1, D_IN)\n    \n    X0_clean = np.delete(X0_train, poison_indices, axis=0)\n    y0_clean = np.delete(y0_train, poison_indices, axis=0)\n\n    # Poisoned samples have their labels flipped to 1\n    X_train = np.vstack([X0_clean, X1_train, X_poisoned])\n    y_train = np.hstack([y0_clean, y1_train, np.ones(n_poison, dtype=int)])\n    \n    # ASR Test Set\n    X0_test, _, _, _ = generate_data(M_TEST, prototypes, SIGMA)\n    X0_test_img = X0_test.reshape(-1, IMG_SIZE, IMG_SIZE)\n    X_triggered_test_img = apply_trigger(X0_test_img)\n    X_triggered_test = X_triggered_test_img.reshape(-1, D_IN)\n\n    # --- Baseline Model Training ---\n    baseline_model = NeuralNetwork(rng)\n    baseline_model.train(X_train, y_train, EPOCHS0, ETA0)\n    \n    results = []\n\n    # Case 1: No defense\n    asr_baseline = calculate_asr(baseline_model, X_triggered_test)\n    results.append(asr_baseline)\n\n    # Case 2: Magnitude Pruning q=0.2\n    pruned_model_1 = baseline_model.clone()\n    weights = np.concatenate([pruned_model_1.W1.flatten(), pruned_model_1.W2.flatten()])\n    threshold = np.quantile(np.abs(weights), Q_PRUNE_1)\n    pruned_model_1.W1[np.abs(pruned_model_1.W1) = threshold] = 0\n    pruned_model_1.W2[np.abs(pruned_model_1.W2) = threshold] = 0\n    asr_prune_1 = calculate_asr(pruned_model_1, X_triggered_test)\n    results.append(asr_prune_1)\n\n    # Case 3: Magnitude Pruning q=0.6\n    pruned_model_2 = baseline_model.clone()\n    weights = np.concatenate([pruned_model_2.W1.flatten(), pruned_model_2.W2.flatten()])\n    threshold = np.quantile(np.abs(weights), Q_PRUNE_2)\n    pruned_model_2.W1[np.abs(pruned_model_2.W1) = threshold] = 0\n    pruned_model_2.W2[np.abs(pruned_model_2.W2) = threshold] = 0\n    asr_prune_2 = calculate_asr(pruned_model_2, X_triggered_test)\n    results.append(asr_prune_2)\n\n    # Case 4: Fine-tuning\n    finetuned_model = baseline_model.clone()\n    X0_clean_ft, y0_clean_ft, X1_clean_ft, y1_clean_ft = generate_data(C_FINETUNE, prototypes, SIGMA)\n    X_ft = np.vstack([X0_clean_ft, X1_clean_ft])\n    y_ft = np.hstack([y0_clean_ft, y1_clean_ft])\n    finetuned_model.train(X_ft, y_ft, S_FINETUNE, ETA_F)\n    asr_finetune = calculate_asr(finetuned_model, X_triggered_test)\n    results.append(asr_finetune)\n\n    # Case 5  6 helper function\n    def run_spectral_defense(r, X_tr, y_tr, X_te, model_to_get_activations):\n        _, h, _ = model_to_get_activations.forward(X_tr)\n        \n        indices_to_keep = np.array([], dtype=int)\n        \n        for k in range(D_OUT):\n            class_indices = np.where(y_tr == k)[0]\n            if len(class_indices) == 0: continue\n            \n            H_k = h[class_indices]\n            H_k_centered = H_k - H_k.mean(axis=0)\n            \n            _, _, vh = svd(H_k_centered, full_matrices=False)\n            top_sv = vh[0, :]\n            \n            scores = np.abs(H_k_centered @ top_sv)\n            \n            num_to_remove = int(r * len(class_indices))\n            if num_to_remove > 0:\n                outlier_indices_in_class = np.argsort(scores)[-num_to_remove:]\n                indices_to_remove = class_indices[outlier_indices_in_class]\n                \n                class_indices_to_keep = np.setdiff1d(class_indices, indices_to_remove)\n                indices_to_keep = np.union1d(indices_to_keep, class_indices_to_keep)\n            else:\n                indices_to_keep = np.union1d(indices_to_keep, class_indices)\n\n        X_filtered = X_tr[indices_to_keep.astype(int)]\n        y_filtered = y_tr[indices_to_keep.astype(int)]\n        \n        spectral_model = NeuralNetwork(rng)\n        spectral_model.train(X_filtered, y_filtered, EPOCHS1, ETA0)\n        \n        return calculate_asr(spectral_model, X_te)\n\n    # Case 5: Spectral Signatures r=0.1\n    asr_spectral_1 = run_spectral_defense(R_SPECTRAL_1, X_train, y_train, X_triggered_test, baseline_model)\n    results.append(asr_spectral_1)\n    \n    # Case 6: Spectral Signatures r=0.3\n    asr_spectral_2 = run_spectral_defense(R_SPECTRAL_2, X_train, y_train, X_triggered_test, baseline_model)\n    results.append(asr_spectral_2)\n\n    # Final Output Formatting\n    formatted_results = [f\"{res:.3f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3178407"}]}