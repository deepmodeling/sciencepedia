{"hands_on_practices": [{"introduction": "并非所有缩放方法都生而平等，尤其是在处理含有异常值的真实世界数据时。本练习将通过一个具体案例，让您亲手计算并比较标准缩放（基于均值和标准差）与稳健缩放（基于中位数和四分位距）在面对极端异常值时的表现差异。通过这个实践 [@problem_id:1425850]，您将深刻理解为何选择正确的缩放方法对构建可靠的模型至关重要。", "problem": "一名系统生物学的学生正在分析一个特定基因 `Gene-Y` 在七个不同细胞培养样本中的表达数据。测量到的表达水平（以任意单位计）记录如下：\n`[22.5, 25.0, 24.1, 150.0, 26.2, 23.3, 22.8]`\n该学生观察到，与其余数据相比，测量值 `150.0` 是一个极端离群值。为了量化这个离群值对数据归一化的影响，该学生将使用两种不同的方法对数据点 `x = 26.2` 进行归一化：标准缩放和稳健缩放。\n\n**方法一：标准缩放**\n标准化值 $z_{std}$ 使用以下公式计算：\n$$z_{std} = \\frac{x - \\mu}{\\sigma}$$\n其中 $x$ 是待归一化的数据点，$\\mu$ 是整个数据集的算术平均值，$\\sigma$ 是样本标准差。对于一个包含 $N$ 个数据点的数据集，样本标准差定义为 $\\sigma = \\sqrt{\\frac{1}{N-1}\\sum_{i=1}^{N}(x_i - \\mu)^2}$。\n\n**方法二：稳健缩放**\n稳健缩放值 $z_{rob}$ 使用以下公式计算：\n$$z_{rob} = \\frac{x - \\text{median}}{ \\text{IQR}}$$\n其中 $x$ 是数据点，中位数是排序后数据集的中间值，而四分位距 (IQR) 是第三四分位数 ($Q_3$) 与第一四分位数 ($Q_1$) 之差。对于本题，您必须使用以下方法计算四分位数：对数据集进行排序，找到整体中位数，然后将 $Q_1$ 定义为严格低于整体中位数的数据点的中位数，将 $Q_3$ 定义为严格高于整体中位数的数据点的中位数。\n\n您的任务是计算数据点 $x = 26.2$ 的 $z_{std}$ 和 $z_{rob}$ 值。将您的答案表示为一对值，其中 $z_{std}$ 在前，$z_{rob}$ 在后。在最终答案中将两个值都四舍五入到三位有效数字。", "solution": "我们有数据集 $N=7$：$[22.5, 25.0, 24.1, 150.0, 26.2, 23.3, 22.8]$ 以及目标点 $x=26.2$。\n\n对于标准缩放，计算算术平均值 $\\mu$ 和样本标准差 $\\sigma$。平均值为\n$$\n\\mu=\\frac{1}{7}\\sum_{i=1}^{7}x_{i}=\\frac{293.9}{7}=\\frac{2939}{70}.\n$$\n使用 $\\sigma=\\sqrt{\\frac{1}{N-1}\\sum_{i=1}^{N}(x_{i}-\\mu)^{2}}$，其中 $N-1=6$，首先以精确分数计算偏差：\n$$\n\\begin{aligned}\n22.5-\\mu=\\frac{1575}{70}-\\frac{2939}{70}=-\\frac{1364}{70}=-\\frac{682}{35},\\\\\n25.0-\\mu=\\frac{1750}{70}-\\frac{2939}{70}=-\\frac{1189}{70},\\\\\n24.1-\\mu=\\frac{1687}{70}-\\frac{2939}{70}=-\\frac{626}{35},\\\\\n150.0-\\mu=\\frac{10500}{70}-\\frac{2939}{70}=\\frac{7561}{70},\\\\\n26.2-\\mu=\\frac{1834}{70}-\\frac{2939}{70}=-\\frac{1105}{70}=-\\frac{221}{14},\\\\\n23.3-\\mu=\\frac{1631}{70}-\\frac{2939}{70}=-\\frac{1308}{70}=-\\frac{654}{35},\\\\\n22.8-\\mu=\\frac{1596}{70}-\\frac{2939}{70}=-\\frac{1343}{70}.\n\\end{aligned}\n$$\n平方并求和：\n$$\n\\sum_{i=1}^{7}(x_{i}-\\mu)^{2}=\\frac{465124}{1225}+\\frac{1413721}{4900}+\\frac{391876}{1225}+\\frac{57168721}{4900}+\\frac{48841}{196}+\\frac{427716}{1225}+\\frac{1803649}{4900}.\n$$\n将所有项通分到分母 $4900$ 并对分子求和，得到\n$$\n\\sum_{i=1}^{7}(x_{i}-\\mu)^{2}=\\frac{66745980}{4900}=\\frac{476757}{35}.\n$$\n因此，样本方差和标准差为\n$$\n\\sigma^{2}=\\frac{1}{6}\\cdot\\frac{476757}{35}=\\frac{476757}{210}=\\frac{158919}{70},\\qquad \\sigma=\\sqrt{\\frac{158919}{70}}.\n$$\n因此，对于 $x=26.2$：\n$$\nz_{std}=\\frac{x-\\mu}{\\sigma}=\\frac{-\\frac{221}{14}}{\\sqrt{\\frac{158919}{70}}}=-\\frac{221}{14}\\sqrt{\\frac{70}{158919}}\\approx -0.3313024.\n$$\n\n对于稳健缩放，对数据进行排序：$[22.5, 22.8, 23.3, 24.1, 25.0, 26.2, 150.0]$。整体中位数是第四个值：$\\text{median}=24.1$。使用指定的四分位数方法，严格低于中位数的下半部分是 $[22.5, 22.8, 23.3]$，因此 $Q_{1}=22.8$；严格高于中位数的上半部分是 $[25.0, 26.2, 150.0]$，因此 $Q_{3}=26.2$。因此\n$$\n\\text{IQR}=Q_{3}-Q_{1}=26.2-22.8=3.4,\n$$\n且\n$$\nz_{rob}=\\frac{x-\\text{median}}{\\text{IQR}}=\\frac{26.2-24.1}{3.4}=\\frac{2.1}{3.4}\\approx 0.61764706.\n$$\n\n将两个值都四舍五入到三位有效数字，得到 $z_{std}\\approx -0.331$ 和 $z_{rob}\\approx 0.618$。", "answer": "$$\\boxed{\\begin{pmatrix}-0.331  0.618\\end{pmatrix}}$$", "id": "1425850"}, {"introduction": "在机器学习中，构建严谨的评估流程与选择先进的模型同等重要，而数据泄露是其中一个常见且隐蔽的陷阱。此练习设计了一个思想实验 [@problem_id:3111750]，揭示了在验证阶段不当使用标签信息进行“按类别归一化”所带来的严重后果。您将分析这种错误操作如何人为地夸大模型性能，从而学会如何设计和维护一个可信的、无数据泄露的训练与验证流程。", "problem": "定义了一个二元分类任务，其标签为 $y \\in \\{0,1\\}$，并有一个单一的实值特征 $x \\in \\mathbb{R}$。数据集是不平衡的，类别先验概率为 $p(y=0)=0.9$ 和 $p(y=1)=0.1$。原始特征的类条件分布为\n$$\nx \\mid y=0 \\sim \\mathcal{N}(10, 25), \\quad x \\mid y=1 \\sim \\mathcal{N}(10, 1).\n$$\n在训练和验证一个与贝叶斯决策规则一致的分类器之前，考虑了两种预处理流程。\n\n- 流程 $\\mathrm{G}$（全局归一化）：计算所有训练样本（不分类别）的全局训练均值 $\\mu_{\\mathrm{train}}$ 和标准差 $\\sigma_{\\mathrm{train}}$，并通过 $z=(x-\\mu_{\\mathrm{train}})/\\sigma_{\\mathrm{train}}$ 转换每个样本。此转换仅在训练集上拟合，并应用于验证集，不使用验证标签。\n\n- 流程 $\\mathrm{PC}$（使用标签的按类别单位方差缩放）：对于每个类别 $c \\in \\{0,1\\}$，从训练集中估计特定于该类的标准差 $\\sigma_c$。在验证时，通过 $z=x/\\sigma_y$ 转换每个样本，即除以该样本真实验证标签 $y$ 对应的标准差。此转换需要验证标签来选择应用哪个 $\\sigma_c$。\n\n假设数据无限多，并且分类器在其被赋予的空间中（即，对于流程 $\\mathrm{G}$ 是在 $x$ 空间，对于流程 $\\mathrm{PC}$ 是在 $z$ 空间）实现贝叶斯决策规则。在这种设定下，以下哪些陈述是正确的？\n\nA. 使用流程 $\\mathrm{PC}$ 会在验证时泄露标签信息，因为转换依赖于真实标签 $y$，并且它可能将验证准确率夸大到远高于多数类基线。\n\nB. 使用流程 $\\mathrm{G}$ 不会泄露验证标签，并且对于给定的类条件分布和先验，贝叶斯最优验证准确率不能超过 $0.9$ 的多数类基线。\n\nC. 如果在验证时使用真实标签执行按类别的标准化 $z=(x-\\mu_y)/\\sigma_y$（其中 $\\mu_0=\\mu_1=10$ 和 $\\sigma_0=5$，$\\sigma_1=1$）而不是除以 $\\sigma_y$，这会在预处理步骤中泄露标签信息，但在这种特定的数据配置下，它不会夸大验证准确率，因为两个类条件的 $z$-分布变得相同。\n\nD. 在不平衡数据集中，应在验证时使用真实标签应用按类别归一化，因为它总能提高泛化能力。\n\nE. 为避免信息泄露，归一化参数应在训练集上计算，而不在验证时以标签为条件，并且应将相同的固定变换应用于验证和测试数据，而不检查其标签。", "solution": "用户提供了一个关于二元分类任务的问题陈述，并要求评估关于两种不同数据预处理流程的五个陈述的真实性。\n\n### 问题验证\n\n**步骤1：提取已知条件**\n-   二元分类任务，标签 $y \\in \\{0, 1\\}$。\n-   单一实值特征 $x \\in \\mathbb{R}$。\n-   类别先验概率为 $p(y=0)=0.9$ 和 $p(y=1)=0.1$。\n-   类条件分布如下：\n    -   $x \\mid y=0 \\sim \\mathcal{N}(10, 25)$，即均值 $\\mu_0=10$，方差 $\\sigma_0^2=25$。\n    -   $x \\mid y=1 \\sim \\mathcal{N}(10, 1)$，即均值 $\\mu_1=10$，方差 $\\sigma_1^2=1$。\n-   流程G（全局归一化）：转换为 $z=(x-\\mu_{\\mathrm{train}})/\\sigma_{\\mathrm{train}}$，其中 $\\mu_{\\mathrm{train}}$ 和 $\\sigma_{\\mathrm{train}}$ 是训练数据的全局均值和标准差。此转换仅在训练集上拟合，并应用于验证集，不使用验证标签。\n-   流程PC（按类别单位方差缩放）：转换为 $z=x/\\sigma_y$，其中 $\\sigma_y$ 是样本真实类别 $y$ 的标准差。此转换需要访问验证标签。\n-   假设：数据集大小无限，这意味着样本统计量（如均值和标准差）等于其真实的总体值。\n-   假设：分类器在其操作的特征空间中实现贝叶斯决策规则。\n\n**步骤2：使用提取的已知条件进行验证**\n-   **科学依据**：该问题在贝叶斯决策理论、概率论和标准机器学习实践方面有充分的依据。使用正态分布是标准做法。\n-   **问题适定性**：问题定义清晰。“无限数据”的假设简化了统计参数的计算，使问题成为确定性的和可解的。问题要求评估特定陈述，这是一个适定的任务。\n-   **客观性**：问题以精确的数学和技术语言陈述，没有主观性。\n-   问题设置没有违反任何无效性标准。流程PC中描述的有争议的做法是被测试内容的一部分，而不是问题陈述本身的缺陷。\n\n**步骤3：结论与行动**\n问题陈述是有效的。将推导完整的解决方案。\n\n### 推导与分析\n\n首先，我们分析贝叶斯最优分类器在原始、未转换特征 $x$ 上的性能。贝叶斯决策规则是预测使后验概率 $p(y=k|x)$ 最大化的类别 $k$。这等同于最大化联合概率 $p(x,y=k) = p(x|y=k)p(y=k)$。\n\n我们已知：\n-   $p(y=0)=0.9$ 和 $p(y=1)=0.1$。\n-   $p(x|y=0) = \\frac{1}{\\sqrt{2\\pi \\cdot 25}} \\exp\\left(-\\frac{(x-10)^2}{50}\\right)$。\n-   $p(x|y=1) = \\frac{1}{\\sqrt{2\\pi \\cdot 1}} \\exp\\left(-\\frac{(x-10)^2}{2}\\right)$。\n\n分类器将在 $p(x|y=1)p(y=1)  p(x|y=0)p(y=0)$ 时预测 $y=1$。我们来评估这个不等式：\n$$\n\\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{(x-10)^2}{2}\\right) \\cdot 0.1  \\frac{1}{5\\sqrt{2\\pi}} \\exp\\left(-\\frac{(x-10)^2}{50}\\right) \\cdot 0.9\n$$\n$$\n0.1 \\cdot \\exp\\left(-\\frac{(x-10)^2}{2}\\right)  0.18 \\cdot \\exp\\left(-\\frac{(x-10)^2}{50}\\right)\n$$\n两边同时除以右边的指数项（该项恒为正）：\n$$\n\\frac{0.1}{0.18}  \\exp\\left(\\frac{(x-10)^2}{2} - \\frac{(x-10)^2}{50}\\right)\n$$\n$$\n\\frac{1}{1.8}  \\exp\\left((x-10)^2 \\left(\\frac{25-1}{50}\\right)\\right)\n$$\n$$\n\\frac{1}{1.8}  \\exp\\left(\\frac{12(x-10)^2}{25}\\right)\n$$\n指数函数的参数 $\\frac{12(x-10)^2}{25}$ 总是非负的。这意味着指数项 $\\exp\\left(\\frac{12(x-10)^2}{25}\\right)$ 总是大于或等于 $1$。然而，不等式的左边是 $\\frac{1}{1.8}  1$。因此，该不等式永远不会被满足。\n\n这意味着对于任何 $x$ 值，都有 $p(x, y=1)  p(x, y=0)$。因此，贝叶斯最优分类器将总是预测 $y=0$。\n该分类器的准确率是正确预测类别标签的概率。由于它总是预测 $y=0$：\n$$\n\\text{准确率} = p(\\text{预测 } 0, y=0) + p(\\text{预测 } 1, y=1) = p(\\text{预测 } 0|y=0)p(y=0) + p(\\text{预测 } 1|y=1)p(y=1)\n$$\n$$\n\\text{准确率} = 1 \\cdot p(y=0) + 0 \\cdot p(y=1) = 0.9\n$$\n准确率为 $0.9$，这是多数类基线。\n\n### 选项评估\n\n**A. 使用流程 PC 会在验证时泄露标签信息，因为转换依赖于真实标签 $y$，并且它可能将验证准确率夸大到远高于多数类基线。**\n\n流程 PC 使用转换 $z=x/\\sigma_y$。在验证时，对于一个样本 $(x_{\\text{val}}, y_{\\text{val}})$，应用的转换是 $z_{\\text{val}} = x_{\\text{val}}/\\sigma_{y_{\\text{val}}}$。标准差的选择（$\\sigma_0=5$ 或 $\\sigma_1=1$）取决于真实的验证标签 $y_{\\text{val}}$。这是一种数据泄露形式，因为来自验证标签的信息被用在了特征准备步骤中。\n\n我们来分析这对分布的影响。\n-   如果 $y=0$，$x \\sim \\mathcal{N}(10, 25)$。转换是 $z=x/\\sigma_0 = x/5$。得到的 $z$ 的分布是 $\\mathcal{N}(10/5, 25/5^2) = \\mathcal{N}(2, 1)$。\n-   如果 $y=1$，$x \\sim \\mathcal{N}(10, 1)$。转换是 $z=x/\\sigma_1 = x/1$。得到的 $z$ 的分布是 $\\mathcal{N}(10, 1)$。\n\n分类器现在面临的问题是区分 $z|y=0 \\sim \\mathcal{N}(2, 1)$ 和 $z|y=1 \\sim \\mathcal{N}(10, 1)$。这两个分布是高度可分的。贝叶斯最优分类器将为 $z$ 设定一个决策边界，并能达到很高的准确率。准确率将约为 $p(y=0) \\cdot \\Phi(z^*-2) + p(y=1) \\cdot (1-\\Phi(z^*-10))$，其中 $z^*$ 是决策边界。由于均值（$2$ 和 $10$）相对于标准差（$1$）相距甚远，两个 $\\Phi(\\cdot)$ 项都将非常接近 $1$。因此，准确率将接近 $0.9 \\cdot 1 + 0.1 \\cdot 1 = 1.0$。这比真实世界性能估计和 $0.9$ 的基线有显著的夸大。\n\n因此，该陈述是正确的。\n\n**B. 使用流程 G 不会泄露验证标签，并且对于给定的类条件分布和先验，贝叶斯最优验证准确率不能超过 $0.9$ 的多数类基线。**\n\n流程 G 使用 $z=(x-\\mu_{\\mathrm{train}})/\\sigma_{\\mathrm{train}}$。参数仅在训练数据上计算。在有无限数据的情况下，我们使用混合分布 $p(x) = p(x|y=0)p(y=0) + p(x|y=1)p(y=1)$ 的真实总体参数。\n-   全局均值 $\\mu = E[X] = E[X|Y=0]p(Y=0) + E[X|Y=1]p(Y=1) = 10 \\cdot 0.9 + 10 \\cdot 0.1 = 10$。\n-   全局方差 $\\sigma^2 = E[X^2] - \\mu^2$。\n    $E[X^2|Y=c] = \\sigma_c^2 + \\mu_c^2$。\n    $E[X^2] = E[X^2|Y=0]p(Y=0) + E[X^2|Y=1]p(Y=1) = (25+10^2) \\cdot 0.9 + (1+10^2) \\cdot 0.1 = 125 \\cdot 0.9 + 101 \\cdot 0.1 = 112.5 + 10.1 = 122.6$。\n    $\\sigma^2 = 122.6 - 10^2 = 22.6$。所以 $\\sigma = \\sqrt{22.6}$。\n\n转换是 $z=(x-10)/\\sqrt{22.6}$。这是一个应用于所有样本的固定仿射变换，与其标签无关。因此，它不会泄露验证标签。\n该转换将分布映射如下：\n-   $x|y=0 \\sim \\mathcal{N}(10, 25) \\implies z|y=0 \\sim \\mathcal{N}(0, 25/22.6)$。\n-   $x|y=1 \\sim \\mathcal{N}(10, 1) \\implies z|y=1 \\sim \\mathcal{N}(0, 1/22.6)$。\n在 $z$ 空间中的问题是区分两个均值相同（为 $0$）但方差不同的正态分布。这在结构上与原始 $x$ 空间中的问题相同。一个可逆的仿射变换不会改变贝叶斯分类器对类别的可分性。与初始推导中完全相同的逻辑适用：贝叶斯最优分类器将总是预测多数类 $y=0$，并达到 $0.9$ 的准确率。准确率不会超过多数类基线。\n\n因此，该陈述是正确的。\n\n**C. 如果在验证时使用真实标签执行按类别的标准化 $z=(x-\\mu_y)/\\sigma_y$（其中 $\\mu_0=\\mu_1=10$ 和 $\\sigma_0=5$，$\\sigma_1=1$）而不是除以 $\\sigma_y$，这会在预处理步骤中泄露标签信息，但在这种特定的数据配置下，它不会夸大验证准确率，因为两个类条件的 $z$-分布变得相同。**\n\n这个过程根据验证标签 $y$ 同时使用了 $\\mu_y$ 和 $\\sigma_y$，所以它肯定泄露了标签信息。我们来应用这个转换：\n-   如果 $y=0$：$x \\sim \\mathcal{N}(\\mu_0=10, \\sigma_0^2=25)$。转换是 $z=(x-\\mu_0)/\\sigma_0 = (x-10)/5$。得到的分布是 $z|y=0 \\sim \\mathcal{N}\\left(\\frac{10-10}{5}, \\frac{25}{5^2}\\right) = \\mathcal{N}(0,1)$。\n-   如果 $y=1$：$x \\sim \\mathcal{N}(\\mu_1=10, \\sigma_1^2=1)$。转换是 $z=(x-\\mu_1)/\\sigma_1 = (x-10)/1$。得到的分布是 $z|y=1 \\sim \\mathcal{N}\\left(\\frac{10-10}{1}, \\frac{1}{1^2}\\right) = \\mathcal{N}(0,1)$。\n\n经过此转换后，两个类别的分布都变成了标准正态分布 $\\mathcal{N}(0,1)$。由于类条件分布相同，特征 $z$ 不提供任何用于区分类别 0 和类别 1 的信息。后验概率等于先验概率：$p(y|z) = p(y)$。贝叶斯最优分类器必须总是预测多数类 $y=0$。准确率将是 $p(y=0)=0.9$。这是基线准确率，因此没有被夸大。该陈述准确地描述了结果。\n\n因此，该陈述是正确的。\n\n**D. 在不平衡数据集中，应在验证时使用真实标签应用按类别归一化，因为它总能提高泛化能力。**\n\n这个陈述倡导了一种有缺陷的方法论。在验证或测试时应用任何使用真实标签的转换都是一种数据泄露（或“数据窥探”）。验证集的目的是估计模型在未来标签未知的未见数据上的表现。使用标签来处理特征会为分类器创造一个被人为简化的任务，导致对其真实泛化性能的评估过于乐观和无效。以这种方式训练的模型学会了利用这种泄露，而不是底层的数据模式。当部署到真实的测试集（其中标签不可用于预处理）时，其性能可能会很差。声称它“总能提高泛化能力”是错误的；它使泛化能力的*估计*无效，并且不会提高在真正的新数据上的性能。如选项C的分析所示，它甚至可能使类别变得不可分，从而降低了本可能达到的准确率。\n\n因此，该陈述是不正确的。\n\n**E. 为避免信息泄露，归一化参数应在训练集上计算，而不在验证时以标签为条件，并且应将相同的固定变换应用于验证和测试数据，而不检查其标签。**\n\n该陈述描述了在机器学习工作流程中应用预处理转换的规范、正确的程序。1. 仅在**训练数据**上拟合预处理器（例如，为标准化器计算均值和标准差）。2. 将**已拟合**的转换（即，使用从训练数据中学到的参数）应用于训练数据、验证数据和测试数据。这确保了验证集和测试集在拟合过程中保持“未见”，并且对它们的评估提供了对模型泛化性能的无偏估计。它防止了来自验证/测试集的任何信息泄露到模型或评估过程中。这正是流程 G 所描述的一部分，也是标准的最佳实践。\n\n因此，该陈述是正确的。\n\n最终正确选项的统计：A, B, C, E。", "answer": "$$\\boxed{ABCE}$$", "id": "3111750"}, {"introduction": "数据缩放的意义远不止是将不同特征置于可比较的尺度上，它还深刻影响着模型训练的优化过程。本练习 [@problem_id:3111719] 将引导您从第一性原理出发，通过理论推导和编程实践，探索一个最基本的数据预处理步骤——均值中心化——如何改善优化问题的“病态程度”（conditioning）。您将分析这一操作如何改变损失函数的Hessian矩阵结构，并最终量化其对梯度下降算法收敛速度的提升效果。", "problem": "给定一个监督学习设置，其中模型的第一个可训练变换是应用于输入向量的仿射映射。考虑标准经验风险公式下的均方误差目标。您将根据经验均值和协方差的定义，以及损失的二次型，来分析输入特征的显式均值中心化如何影响第一层中偏置的作用以及优化问题的条件。\n\n待完成任务：\n\n1) 从带有显式第一层偏置的单输出线性预测的均方误差损失出发，推导最优偏置关于数据集统计量的表达式。仅使用经验均值和协方差的定义以及凸二次型的一阶最优性条件。然后，确定在此条件下该偏置必须恒等于零的条件，从而使第一层偏置参数变得冗余。\n\n2) 使用一个带有一列全为1的增广设计矩阵，将参数的优化建模为一个最小二乘问题。用 $n$ 表示样本数，用 $d$ 表示特征数，用 $X \\in \\mathbb{R}^{n \\times d}$ 表示数据矩阵，用 $y \\in \\mathbb{R}^{n}$ 表示目标向量，用 $\\tilde{X} = [X \\ \\ \\mathbf{1}] \\in \\mathbb{R}^{n \\times (d+1)}$ 表示增广设计矩阵。展示由 $H = \\frac{1}{n} \\tilde{X}^{\\top} \\tilde{X}$ 给出的经验风险海森矩阵 (Hessian) 的块结构，并解释特征逐一进行均值中心化（$X_{\\mathrm{c}}$ 的每一列经验均值为 $0$）如何将 $H$ 转换为一个块对角矩阵。利用这一点，从块对角矩阵特征值的第一性原理出发，论证均值中心化如何影响 $H$ 的谱条件数。\n\n3) 使用经过充分检验的强凸二次型上梯度下降的收敛速率界，量化一个理论上合理的优化增益：如果 $H$ 是正定的，其谱条件数为 $\\kappa(H)$，那么使用等于最大特征值倒数的步长，会得到最坏情况下的每次迭代误差收缩因子 $$\\rho(H) = \\left(\\frac{\\kappa(H) - 1}{\\kappa(H) + 1}\\right)^{2}.$$ 使用此界，分别计算原始和均值中心化增广系统的收缩因子之比 $\\rho(H_{\\text{raw}}) / \\rho(H_{\\text{centered}})$。\n\n编程任务和测试套件：\n\n- 实现一个程序，为每个测试用例执行以下操作：\n  a) 完全按照下文规定构建 $X$ 和 $y$。\n  b) 为原始数据构建增广设计矩阵 $\\tilde{X} = [X \\ \\ \\mathbf{1}]$，为均值中心化数据构建 $\\tilde{X}_{\\mathrm{c}} = [X_{\\mathrm{c}} \\ \\ \\mathbf{1}]$，其中 $X_{\\mathrm{c}}$ 是通过从每个样本中减去每个特征的经验均值得到的。\n  c) 使用 $\\tilde{X}_{\\mathrm{c}}$ 求解最小二乘问题以获得最优参数，并提取均值中心化输入下的最优偏置 $b^{\\star}_{\\mathrm{c}}$。\n  d) 计算谱条件数 $\\kappa(H_{\\text{raw}})$ 和 $\\kappa(H_{\\text{centered}})$，其中 $H_{\\text{raw}} = \\frac{1}{n} \\tilde{X}^{\\top} \\tilde{X}$ 且 $H_{\\text{centered}} = \\frac{1}{n} \\tilde{X}_{\\mathrm{c}}^{\\top} \\tilde{X}_{\\mathrm{c}}$。\n  e) 使用上述公式计算收缩因子 $\\rho(H_{\\text{raw}})$ 和 $\\rho(H_{\\text{centered}})$。\n  f) 为每个测试用例生成一个包含三个条目的列表：\n     - 一个布尔值，指示在中心化下偏置是否冗余，定义为 $\\lvert b^{\\star}_{\\mathrm{c}} \\rvert  10^{-9}$。\n     - 一个等于 $\\kappa(H_{\\text{raw}}) / \\kappa(H_{\\text{centered}})$ 的浮点数。\n     - 一个等于 $\\rho(H_{\\text{raw}}) / \\rho(H_{\\text{centered}})$ 的浮点数。\n\n- 测试套件（所有数字均为精确值，必须按原样使用）：\n  1) $X_1 = [[3, 5], [4, 6], [5, 8], [6, 9], [7, 11]]$, $y_1 = [-2, -1, 0, 1, 2]$.\n  2) $X_2 = [[-2, 2], [-1, -1], [0, 0], [1, 1], [2, -2]]$, $y_2 = [10, 10, 10, 10, 10]$.\n  3) $X_3 = [[10.0], [10.1], [9.9], [10.05], [9.95]]$, $y_3 = [-2, -1, 0, 1, 2]$.\n  4) $X_4 = [[1, 0, -1], [2, -1, 0], [-2, 1, 1], [0, 2, -1], [1, -2, 3]]$, $y_4 = [1, -1, 2, -2, 0]$.\n\n- 最终输出格式：\n  您的程序应生成单行输出，其中包含一个每个测试用例的三元组列表，每个三元组格式为 [布尔值,浮点数,浮点数]，整体结果格式化为用方括号括起来的逗号分隔列表。例如：\n  \"[[True,1.234567,2.345678],[False,1.000000,1.000000],...]\"\n\n注：\n- 本问题不涉及物理单位。\n- 推导中出现的所有角度（如有）必须以弧度为单位，但本任务中不需要。\n- 每个测试用例的最终输出必须是布尔值或浮点数，如上所述。", "solution": "该问题要求在均方误差目标下，分析输入特征的均值中心化对带有偏置项的线性模型训练的影响。此分析将从线性代数和优化理论的第一性原理进行。\n\n对于输入特征向量为 $\\mathbf{x} \\in \\mathbb{R}^d$ 的单个样本，其模型是一个产生单个输出的仿射变换：$f(\\mathbf{x}) = \\mathbf{w}^{\\top}\\mathbf{x} + b$，其中 $\\mathbf{w} \\in \\mathbb{R}^d$ 是权重向量， $b \\in \\mathbb{R}$ 是偏置标量。给定一个包含 $n$ 个样本的数据集 $\\{(\\mathbf{x}_i, y_i)\\}_{i=1}^n$，组织成数据矩阵 $X \\in \\mathbb{R}^{n \\times d}$ 和目标向量 $\\mathbf{y} \\in \\mathbb{R}^n$，目标是最小化经验风险，具体来说是均方误差 (MSE)：\n$$L(\\mathbf{w}, b) = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - f(\\mathbf{x}_i))^2 = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - (\\mathbf{w}^{\\top}\\mathbf{x}_i + b))^2$$\n这是一个凸二次优化问题，其全局最小值可以通过将其梯度设为零来找到。\n\n**1. 最优偏置及冗余条件**\n\n为求最优参数 $(\\mathbf{w}^*, b^*)$，我们应用一阶最优性条件，将损失函数 $L(\\mathbf{w}, b)$ 的偏导数设为零。关于偏置 $b$ 的偏导数为：\n$$\\frac{\\partial L}{\\partial b} = \\frac{\\partial}{\\partial b} \\left[ \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\mathbf{w}^{\\top}\\mathbf{x}_i - b)^2 \\right] = \\frac{1}{n} \\sum_{i=1}^{n} 2(y_i - \\mathbf{w}^{\\top}\\mathbf{x}_i - b)(-1) = -\\frac{2}{n} \\sum_{i=1}^{n} (y_i - \\mathbf{w}^{\\top}\\mathbf{x}_i - b)$$\n将此导数设为零可得：\n$$\\sum_{i=1}^{n} (y_i - \\mathbf{w}^{\\top}\\mathbf{x}_i - b) = 0$$\n$$\\sum_{i=1}^{n} y_i - \\mathbf{w}^{\\top}\\sum_{i=1}^{n} \\mathbf{x}_i - \\sum_{i=1}^{n} b = 0$$\n设 $\\bar{y} = \\frac{1}{n}\\sum_{i=1}^{n} y_i$ 为目标变量的经验均值，$\\bar{\\mathbf{x}} = \\frac{1}{n}\\sum_{i=1}^{n} \\mathbf{x}_i$ 为特征向量的经验均值。方程变为：\n$$n\\bar{y} - \\mathbf{w}^{\\top}(n\\bar{\\mathbf{x}}) - nb = 0$$\n求解 $b$ 可得最优偏置 $b^*$ 关于最优权重 $\\mathbf{w}^*$ 和数据集统计量的表达式：\n$$b^* = \\bar{y} - (\\mathbf{w}^*)^{\\top}\\bar{\\mathbf{x}}$$\n此表达式表明，最优偏置解释了目标均值与模型在特征均值处的预测值之间的差异。\n\n现在，考虑一个输入特征首先被均值中心化的模型。设 $X_{\\mathrm{c}}$ 为中心化数据矩阵，其中每列的均值为零。对应的特征向量为 $\\mathbf{x}_{\\mathrm{c},i} = \\mathbf{x}_i - \\bar{\\mathbf{x}}$。现在的模型是 $f(\\mathbf{x}_{\\mathrm{c}}) = \\mathbf{w}_{\\mathrm{c}}^{\\top}\\mathbf{x}_{\\mathrm{c}} + b_{\\mathrm{c}}$。中心化特征向量的均值为 $\\bar{\\mathbf{x}}_{\\mathrm{c}} = \\mathbf{0}$。应用相同的推导，此模型的最优偏置 $b_{\\mathrm{c}}^*$ 为：\n$$b_{\\mathrm{c}}^* = \\bar{y} - (\\mathbf{w}_{\\mathrm{c}}^*)^{\\top}\\bar{\\mathbf{x}}_{\\mathrm{c}} = \\bar{y} - (\\mathbf{w}_{\\mathrm{c}}^*)^{\\top}\\mathbf{0} = \\bar{y}$$\n因此，对于具有均值中心化特征的模型，最优偏置就是目标变量的经验均值。偏置参数变得只负责拟合输出的均值，而权重则处理围绕均值的变化。\n\n根据这一结果，我们可以确定偏置变得冗余（即其最优值为零）的条件。偏置 $b_{\\mathrm{c}}^*$ 恒等于零当且仅当 $\\bar{y} = 0$。因此，当且仅当目标变量的经验均值也为零时，通过对输入特征进行均值中心化，第一层的偏置参数会变得冗余。\n\n**2. 海森矩阵的块结构与条件**\n\nMSE 最小化可以表述为一个线性最小二乘问题。我们定义一个增广设计矩阵 $\\tilde{X} = [X \\ \\ \\mathbf{1}] \\in \\mathbb{R}^{n \\times (d+1)}$ 和一个增广参数向量 $\\tilde{\\mathbf{w}} = [\\mathbf{w}^{\\top} \\ b]^{\\top} \\in \\mathbb{R}^{d+1}$。损失函数变为：\n$$L(\\tilde{\\mathbf{w}}) = \\frac{1}{n} \\|\\mathbf{y} - \\tilde{X}\\tilde{\\mathbf{w}}\\|_2^2$$\n经验风险的海森矩阵与 $\\tilde{X}^{\\top}\\tilde{X}$ 成正比。问题将待分析的矩阵定义为 $H = \\frac{1}{n} \\tilde{X}^{\\top} \\tilde{X}$。对于原始（未中心化）数据，其块结构为：\n$$H_{\\text{raw}} = \\frac{1}{n} \\tilde{X}^{\\top} \\tilde{X} = \\frac{1}{n} \\begin{pmatrix} X^{\\top} \\\\ \\mathbf{1}^{\\top} \\end{pmatrix} \\begin{pmatrix} X  \\mathbf{1} \\end{pmatrix} = \\frac{1}{n} \\begin{pmatrix} X^{\\top}X  X^{\\top}\\mathbf{1} \\\\ \\mathbf{1}^{\\top}X  \\mathbf{1}^{\\top}\\mathbf{1} \\end{pmatrix}$$\n我们来分析这些块：\n- $X^{\\top}\\mathbf{1}$ 是一个 $d \\times 1$ 向量，其第 $j$ 个元素是 $\\sum_{i=1}^n X_{ij} = n\\bar{x}_j$。因此，$X^{\\top}\\mathbf{1} = n\\bar{\\mathbf{x}}$。\n- $\\mathbf{1}^{\\top}X = (X^{\\top}\\mathbf{1})^{\\top} = n\\bar{\\mathbf{x}}^{\\top}$。\n- $\\mathbf{1}^{\\top}\\mathbf{1} = n$。\n将这些代入 $H_{\\text{raw}}$ 的表达式中：\n$$H_{\\text{raw}} = \\frac{1}{n} \\begin{pmatrix} X^{\\top}X  n\\bar{\\mathbf{x}} \\\\ n\\bar{\\mathbf{x}}^{\\top}  n \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{n}X^{\\top}X  \\bar{\\mathbf{x}} \\\\ \\bar{\\mathbf{x}}^{\\top}  1 \\end{pmatrix}$$\n非零的非对角块 $\\bar{\\mathbf{x}}$ 和 $\\bar{\\mathbf{x}}^{\\top}$ 表明权重参数 $\\mathbf{w}$ 和偏置参数 $b$ 之间存在耦合。这种耦合源于特征列与增广矩阵 $\\tilde{X}$ 中常数1列之间的统计相关性。\n\n当我们对特征进行均值中心化时，我们使用中心化数据矩阵 $X_{\\mathrm{c}}$。根据定义，中心化特征的均值向量为 $\\bar{\\mathbf{x}}_{\\mathrm{c}} = \\mathbf{0}$。中心化系统的海森矩阵 $H_{\\text{centered}}$ 是通过将 $X$ 替换为 $X_{\\mathrm{c}}$ 并将 $\\bar{\\mathbf{x}}$ 替换为 $\\bar{\\mathbf{x}}_{\\mathrm{c}}$ 得到的：\n$$H_{\\text{centered}} = \\begin{pmatrix} \\frac{1}{n}X_{\\mathrm{c}}^{\\top}X_{\\mathrm{c}}  \\bar{\\mathbf{x}}_{\\mathrm{c}} \\\\ \\bar{\\mathbf{x}}_{\\mathrm{c}}^{\\top}  1 \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{n}X_{\\mathrm{c}}^{\\top}X_{\\mathrm{c}}  \\mathbf{0} \\\\ \\mathbf{0}^{\\top}  1 \\end{pmatrix}$$\n矩阵 $H_{\\text{centered}}$ 是块对角矩阵。左上角的块 $\\frac{1}{n}X_{\\mathrm{c}}^{\\top}X_{\\mathrm{c}}$ 是特征的样本协方差矩阵 $\\hat{\\Sigma}_{XX}$。这种块对角结构意味着权重 $\\mathbf{w}$ 和偏置 $b$ 的优化问题已经解耦。\n\n这种结构性变化对海森矩阵的谱性质有显著影响，并因此影响优化问题的条件。块对角矩阵的特征值是其对角块特征值的并集。因此，$H_{\\text{centered}}$ 的特征值是 $\\hat{\\Sigma}_{XX}$ 的特征值加上特征值 $1$。然而，$H_{\\text{raw}}$ 的特征值受到耦合项的影响。如果特征具有较大的均值，$X$ 的列可能与 $\\tilde{X}$ 中的全1列近乎共线，这会增大 $H_{\\text{raw}}$ 的最大特征值，从而恶化谱条件数 $\\kappa(H) = \\lambda_{\\max}(H) / \\lambda_{\\min}(H)$。通过移除特征均值，均值中心化消除了这种共线性的来源，通常会得到一个更小（更有利）的条件数。因此，我们预期 $\\kappa(H_{\\text{centered}}) \\le \\kappa(H_{\\text{raw}})$。\n\n**3. 量化优化增益**\n\n在强凸二次目标上，梯度下降的收敛速率由海森矩阵的谱条件数 $\\kappa(H)$ 决定。问题提供了最坏情况下的每次迭代误差收缩因子：\n$$\\rho(H) = \\left(\\frac{\\kappa(H) - 1}{\\kappa(H) + 1}\\right)^{2}$$\n$\\rho(H)$ 的值越小，意味着收敛越快。函数 $g(\\kappa) = (\\kappa - 1) / (\\kappa + 1)$ 在 $\\kappa \\ge 1$ 时是单调递增的。由于我们已经确定均值中心化通常会减小条件数，即 $\\kappa(H_{\\text{centered}}) \\le \\kappa(H_{\\text{raw}})$，因此可以得出 $\\rho(H_{\\text{centered}}) \\le \\rho(H_{\\text{raw}})$。这证实了对特征进行均值中心化通常会改善或保持梯度下降的收敛速率。\n\n收缩因子之比 $\\rho(H_{\\text{raw}}) / \\rho(H_{\\text{centered}})$ 量化了这种增益。大于 $1$ 的比率表示收敛加速。该比率的公式为：\n$$\\frac{\\rho(H_{\\text{raw}})}{\\rho(H_{\\text{centered}})} = \\frac{\\left(\\frac{\\kappa(H_{\\text{raw}}) - 1}{\\kappa(H_{\\text{raw}}) + 1}\\right)^{2}}{\\left(\\frac{\\kappa(H_{\\text{centered}}) - 1}{\\kappa(H_{\\text{centered}}) + 1}\\right)^{2}} = \\left( \\frac{(\\kappa(H_{\\text{raw}}) - 1)(\\kappa(H_{\\text{centered}}) + 1)}{(\\kappa(H_{\\text{raw}}) + 1)(\\kappa(H_{\\text{centered}}) - 1)} \\right)^2$$\n将为给定的测试用例计算此比率，以数值方式证明优化增益。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem for all test cases as specified.\n    \"\"\"\n    # Test suite (all numbers are exact and must be used as given)\n    test_cases = [\n        {'X': np.array([[3.0, 5.0], [4.0, 6.0], [5.0, 8.0], [6.0, 9.0], [7.0, 11.0]]),\n         'y': np.array([-2.0, -1.0, 0.0, 1.0, 2.0])},\n        {'X': np.array([[-2.0, 2.0], [-1.0, -1.0], [0.0, 0.0], [1.0, 1.0], [2.0, -2.0]]),\n         'y': np.array([10.0, 10.0, 10.0, 10.0, 10.0])},\n        {'X': np.array([[10.0], [10.1], [9.9], [10.05], [9.95]]),\n         'y': np.array([-2.0, -1.0, 0.0, 1.0, 2.0])},\n        {'X': np.array([[1.0, 0.0, -1.0], [2.0, -1.0, 0.0], [-2.0, 1.0, 1.0], [0.0, 2.0, -1.0], [1.0, -2.0, 3.0]]),\n         'y': np.array([1.0, -1.0, 2.0, -2.0, 0.0])}\n    ]\n\n    results = []\n\n    def compute_contraction_factor(kappa):\n        \"\"\"Computes the contraction factor rho from the condition number kappa.\"\"\"\n        # Handle the case where kappa is 1 (e.g., identity matrix), leading to rho=0\n        if np.isclose(kappa, 1.0):\n            return 0.0\n        # Normal case\n        return ((kappa - 1) / (kappa + 1))**2\n\n    for case in test_cases:\n        X, y = case['X'], case['y']\n        n, d = X.shape\n        \n        # a) Construct X and y (already done)\n        \n        # b) Construct augmented design matrices\n        ones = np.ones((n, 1))\n        \n        # Raw data\n        X_tilde_raw = np.hstack([X, ones])\n        \n        # Mean-centered data\n        X_mean = X.mean(axis=0)\n        X_c = X - X_mean\n        X_tilde_centered = np.hstack([X_c, ones])\n        \n        # c) Solve for optimal bias with centered data\n        # The least squares solution for [w_c^T b_c]^T\n        params_c, _, _, _ = np.linalg.lstsq(X_tilde_centered, y, rcond=None)\n        b_star_c = params_c[-1]\n        is_bias_redundant = np.abs(b_star_c)  1e-9\n\n        # d) Compute Hessians and their spectral condition numbers\n        H_raw = (1/n) * (X_tilde_raw.T @ X_tilde_raw)\n        H_centered = (1/n) * (X_tilde_centered.T @ X_tilde_centered)\n        \n        kappa_raw = np.linalg.cond(H_raw)\n        kappa_centered = np.linalg.cond(H_centered)\n        \n        # e) Compute contraction factors\n        rho_raw = compute_contraction_factor(kappa_raw)\n        rho_centered = compute_contraction_factor(kappa_centered)\n        \n        # f) Produce the output triple\n        kappa_ratio = kappa_raw / kappa_centered\n        \n        # Handle division by zero if rho_centered is 0\n        if rho_centered  1e-12:\n            # If rho_raw is also zero, ratio is 1. If not, it's effectively infinite.\n            # Here assuming if centered is perfect, ratio is just raw factor.\n            # In context of the problem, if kappa_centered is 1, kappa_raw >= 1.\n            # if kappa_c = 1, rho_c = 0. If kappa_r > 1, rho_r > 0, ratio is inf.\n            # However, this will not happen with the test data. A safe approach is needed.\n            if rho_raw  1e-12:\n                rho_ratio = 1.0\n            else:\n                rho_ratio = np.inf\n        else:\n            rho_ratio = rho_raw / rho_centered\n        \n        results.append([is_bias_redundant, kappa_ratio, rho_ratio])\n\n    # Final print statement in the exact required format.\n    # Convert bool to Python's True/False string representation\n    formatted_results = [f\"[{'True' if r[0] else 'False'},{r[1]:.8f},{r[2]:.8f}]\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3111719"}]}