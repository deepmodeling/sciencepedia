{"hands_on_practices": [{"introduction": "第一个练习为理解偏差-方差权衡提供了坚实的基础。通过将不同阶数的多项式拟合到合成数据，您不仅会观察到训练和验证误差中欠拟合与过拟合的经典模式，还将学会通过分析模型残差的频率分量来量化过拟合的“振荡”特性 [@problem_id:3135788]。这项练习将帮助您建立关于模型容量和正则化如何影响性能的量化直觉。", "problem": "给你一个用于一维回归的监督学习场景，该场景基于经验风险最小化（ERM）进行建模。设输入为 $x \\in [-1,1]$，真实目标函数为一个已知阶数 $d^\\star$ 的多项式，并受到零均值、方差为 $\\sigma^2$ 的高斯噪声污染。具体来说，数据按如下方式生成：$y = f^\\star(x) + \\varepsilon$，其中 $f^\\star(x) = \\sum_{k=0}^{d^\\star} a_k x^k$，$d^\\star = 4$，系数为 $a_0 = 0.3$、$a_1 = -0.8$、$a_2 = 0.5$、$a_3 = 0.0$、$a_4 = 0.7$，噪声为 $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^2)$，其中 $\\sigma = 0.1$（因此 $\\sigma^2 = 0.01$）。数据集大小为 $N = 200$ 个点，其输入 $x$ 从 $[-1,1]$ 区间内均匀抽取。使用 $N_{\\text{train}} = 120$ 个样本进行训练， $N_{\\text{valid}} = 80$ 个样本进行验证。使用固定的随机种子 $42$ 以确保可复现性。\n\n你的任务是实现带岭正则化（也称为 $\\ell_2$ 正则化）的多项式回归。对于选定的模型阶数 $d$ 和正则化强度 $\\lambda \\ge 0$，构建设计矩阵 $\\Phi \\in \\mathbb{R}^{m \\times (d+1)}$，其元素为 $\\Phi_{i,k} = x_i^k$。给定训练数据 $(\\Phi_{\\text{train}}, y_{\\text{train}})$，使用闭式解计算岭估计器系数 $w \\in \\mathbb{R}^{d+1}$：\n$$\nw = \\left(\\Phi_{\\text{train}}^\\top \\Phi_{\\text{train}} + \\lambda I\\right)^{-1} \\Phi_{\\text{train}}^\\top y_{\\text{train}},\n$$\n其中 $I$ 是 $(d+1) \\times (d+1)$ 的单位矩阵。使用此估计器获取在训练集和验证集上的预测值，并计算残差 $r_{\\text{train}} = y_{\\text{train}} - \\hat{y}_{\\text{train}}$ 和 $r_{\\text{valid}} = y_{\\text{valid}} - \\hat{y}_{\\text{valid}}$。\n\n从第一性原理出发，使用以下定义和度量来识别欠拟合和过拟合：\n\n- 均方误差（MSE）定义为 $ \\text{MSE} = \\frac{1}{m} \\sum_{i=1}^m (y_i - \\hat{y}_i)^2 $。令 $\\text{MSE}_{\\text{train}}$ 和 $\\text{MSE}_{\\text{valid}}$ 分别表示训练和验证的均方误差。\n- 残差中的振荡在频域中进行量化。计算验证残差序列的离散傅里叶变换（DFT）（首次出现：离散傅里叶变换（DFT）），该序列已根据其对应的输入 $x$ 按升序排序。使用实值DFT $R = \\text{rfft}(r_{\\text{valid-sorted}})$ 并定义高频能量比为\n$$\n\\rho_{\\text{HF}} = \\frac{\\sum_{k \\in \\mathcal{H}} |R_k|^2}{\\sum_{k \\in \\mathcal{P}} |R_k|^2},\n$$\n其中 $\\mathcal{P}$ 索引除零频段外的所有正频段，$\\mathcal{H}$ 索引顶部的四分之一正频段（即 $\\mathcal{P}$ 中频率最高的 $25\\%$）。如果分母为零，则定义 $\\rho_{\\text{HF}} = 0$。\n\n使用以下带固定阈值的分类规则来判断一个模型是欠拟合、良好拟合还是过拟合。将已知噪声方差记为 $\\sigma^2 = 0.01$，并令阈值为 $t_u = 1.3$、$t_o = 0.9$、$t_o' = 1.2$、$h_u = 0.35$ 和 $h_o = 0.45$。\n\n- 欠拟合（代码 $0$）：如果 $d  d^\\star$，或者 $\\text{MSE}_{\\text{train}} \\ge t_u \\sigma^2$ 且 $\\text{MSE}_{\\text{valid}} \\ge t_u \\sigma^2$ 且 $\\rho_{\\text{HF}} \\le h_u$，则声明为欠拟合。\n- 过拟合（代码 $2$）：如果 $d > d^\\star$ 且 $\\text{MSE}_{\\text{train}} \\le t_o \\sigma^2$ 且 $\\text{MSE}_{\\text{valid}} \\ge t_o' \\sigma^2$ 且 $\\rho_{\\text{HF}} \\ge h_o$，则声明为过拟合。\n- 良好拟合（代码 $1$）：如果以上两个条件都不成立，则声明为良好拟合。\n\n实现上述内容并评估以下改变 $d$ 和 $\\lambda$ 的测试套件：\n\n- 案例 1：$d = 2$，$\\lambda = 0.001$。\n- 案例 2：$d = 4$，$\\lambda = 0.05$。\n- 案例 3：$d = 12$，$\\lambda = 0.0$。\n- 案例 4：$d = 12$，$\\lambda = 10.0$。\n- 案例 5：$d = 4$，$\\lambda = 0.0$。\n\n你的程序必须按规定生成数据集，为每个案例拟合模型，计算度量，并按给定顺序输出这些案例的分类代码。你的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果（例如，$[0,1,2,0,1]$）。本问题不需要物理单位、角度单位或百分比。最终输出值为如上指定的整数。程序必须是完整的，无需任何外部输入或文件即可运行。按规定使用确定性种子，以便任何运行该程序的人都能复现结果。", "solution": "问题陈述已经过仔细验证，并被确定为有效。它在科学上是合理的、自洽的、适定的，在计算统计学和机器学习领域提供了一个清晰且可形式化的任务。\n\n该任务是基于一套精确的量化标准，将多项式回归模型分类为欠拟合、良好拟合或过拟合。解决方案涉及针对几个测试案例的数据生成、模型拟合、度量计算和分类。由于指定了随机种子，整个过程是确定性的。\n\n### 步骤 1：数据生成与准备\n\n此回归问题的基础是一个合成数据集。输入 $x$ 和输出 $y$ 之间的真实关系由一个已知的 $d^\\star=4$ 阶多项式函数 $f^\\star(x)$ 定义：\n$$\nf^\\star(x) = a_0 + a_1 x + a_2 x^2 + a_3 x^3 + a_4 x^4\n$$\n其系数为 $a_0 = 0.3$，$a_1 = -0.8$，$a_2 = 0.5$，$a_3 = 0.0$ 和 $a_4 = 0.7$。\n\n观测数据受到加性高斯白噪声 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$ 的破坏，其中噪声方差为 $\\sigma^2 = 0.01$。因此，每个数据点 $(x_i, y_i)$ 根据以下模型生成：\n$$\ny_i = f^\\star(x_i) + \\varepsilon_i\n$$\n共创建 $N=200$ 个数据点。输入值 $x_i$ 从区间 $[-1, 1]$ 上的均匀分布中抽取。为确保可复现性，随机数生成器使用固定的种子 $42$ 进行初始化。\n\n生成的 $N=200$ 个点的数据集随后被确定性地打乱并分割成大小为 $N_{\\text{train}} = 120$ 的训练集和大小为 $N_{\\text{valid}} = 80$ 的验证集。这种划分使我们能够训练模型并独立评估其泛化性能。\n\n### 步骤 2：带岭正则化的多项式回归\n\n对于每个测试案例，我们将一个指定阶数 $d$ 的多项式模型拟合到训练数据上。模型假设的形式为：\n$$\n\\hat{y}(x) = \\sum_{k=0}^d w_k x^k = \\mathbf{w}^\\top \\phi(x)\n$$\n其中 $\\mathbf{w} \\in \\mathbb{R}^{d+1}$ 是待学习的模型系数向量，$\\phi(x) = [1, x, x^2, \\dots, x^d]^\\top$ 是特征向量。\n\n对于一组 $m$ 个训练样本，我们构建设计矩阵 $\\Phi_{\\text{train}} \\in \\mathbb{R}^{m \\times (d+1)}$，其中每个条目为 $(\\Phi_{\\text{train}})_{i,k} = x_i^k$，对于 $i \\in \\{1, \\dots, m\\}$ 和 $k \\in \\{0, \\dots, d\\}$。\n\n系数 $\\mathbf{w}$ 使用岭回归进行估计，该方法最小化正则化的平方误差和：\n$$\n\\mathcal{L}(\\mathbf{w}) = \\|\\mathbf{y}_{\\text{train}} - \\Phi_{\\text{train}}\\mathbf{w}\\|_2^2 + \\lambda \\|\\mathbf{w}\\|_2^2\n$$\n这里，$\\lambda \\ge 0$ 是正则化参数，用于控制对系数大小的惩罚。最优权重向量 $\\mathbf{w}$ 的闭式解由正规方程给出：\n$$\n\\mathbf{w} = \\left(\\Phi_{\\text{train}}^\\top \\Phi_{\\text{train}} + \\lambda I\\right)^{-1} \\Phi_{\\text{train}}^\\top \\mathbf{y}_{\\text{train}}\n$$\n其中 $I$ 是 $(d+1) \\times (d+1)$ 的单位矩阵。为保证数值稳定性，使用 `numpy.linalg.solve` 求解此线性系统，而不是显式计算矩阵的逆。\n\n### 步骤 3：模型评估度量\n\n一旦模型训练完成（即 $\\mathbf{w}$ 已计算），将使用两个关键度量来评估其性能。\n\n**均方误差（MSE）：** MSE 度量了预测值 $\\hat{y}_i$ 和实际值 $y_i$ 之间的平均平方差。它分别对训练集和验证集进行计算：\n$$\n\\text{MSE}_{\\text{train}} = \\frac{1}{N_{\\text{train}}} \\sum_{i=1}^{N_{\\text{train}}} (y_{\\text{train},i} - \\hat{y}_{\\text{train},i})^2\n$$\n$$\n\\text{MSE}_{\\text{valid}} = \\frac{1}{N_{\\text{valid}}} \\sum_{i=1}^{N_{\\text{valid}}} (y_{\\text{valid},i} - \\hat{y}_{\\text{valid},i})^2\n$$\n\n**高频能量比（$\\rho_{\\text{HF}}$）：** 此度量量化了模型在验证集上误差的振荡特性，这是过拟合的一个常见症状。步骤如下：\n1.  计算验证残差：$\\mathbf{r}_{\\text{valid}} = \\mathbf{y}_{\\text{valid}} - \\hat{\\mathbf{y}}_{\\text{valid}}$。\n2.  根据其对应输入值 $x_{\\text{valid}}$ 的升序对这些残差进行排序。令此排序后的序列为 $\\mathbf{r}_{\\text{valid-sorted}}$。\n3.  计算排序后残差的实值离散傅里叶变换（DFT）：$R = \\text{rfft}(\\mathbf{r}_{\\text{valid-sorted}})$。对于 $N_{\\text{valid}} = 80$，输出 $R$ 是一个长度为 $41$ 的复数值数组。\n4.  正频段集合 $\\mathcal{P}$ 由除零频（DC）分量外的所有频段组成。对于 RFFT 输出 $R$，这些对应于索引 $k \\in \\{1, 2, \\dots, 40\\}$。\n5.  高频段集合 $\\mathcal{H}$ 定义为 $\\mathcal{P}$ 中频率的顶部四分之一（最高 $25\\%$）。这对应于最后的 $40 \\times 0.25 = 10$ 个频段，其索引为 $k \\in \\{31, 32, \\dots, 40\\}$。\n6.  高频能量比即为 $\\mathcal{H}$ 中的能量与 $\\mathcal{P}$ 中总能量之比：\n    $$\n    \\rho_{\\text{HF}} = \\frac{\\sum_{k \\in \\mathcal{H}} |R_k|^2}{\\sum_{k \\in \\mathcal{P}} |R_k|^2}\n    $$\n    如果分母为零，则定义 $\\rho_{\\text{HF}}$ 为 $0$。\n\n### 步骤 4：分类逻辑\n\n计算出的度量用于根据一套固定的规则将每个模型分类为欠拟合、良好拟合或过拟合。真实噪声方差为 $\\sigma^2 = 0.01$，阈值为 $t_u = 1.3$、$t_o = 0.9$、$t_o' = 1.2$、$h_u = 0.35$ 和 $h_o = 0.45$。\n\n- **欠拟合（代码 $0$）：** 如果一个模型的阶数 $d$ 小于真实阶数 $d^\\star$，*或者*它在训练集和验证集上都表现出高误差，并且残差振荡较低，则声明为欠拟合。形式上：\n  $$\n  (d  d^\\star) \\lor (\\text{MSE}_{\\text{train}} \\ge t_u \\sigma^2 \\land \\text{MSE}_{\\text{valid}} \\ge t_u \\sigma^2 \\land \\rho_{\\text{HF}} \\le h_u)\n  $$\n\n- **过拟合（代码 $2$）：** 如果一个模型的阶数 $d$ 大于 $d^\\star$，*并且*它表现出较低的训练误差、显著较高的验证误差以及残差中的高频振荡，则声明为过拟合。形式上：\n  $$\n  (d > d^\\star) \\land (\\text{MSE}_{\\text{train}} \\le t_o \\sigma^2 \\land \\text{MSE}_{\\text{valid}} \\ge t_o' \\sigma^2 \\land \\rho_{\\text{HF}} \\ge h_o)\n  $$\n\n- **良好拟合（代码 $1$）：** 如果一个模型既不满足欠拟合标准也不满足过拟合标准，则将其分类为良好拟合。\n\n这些规则为偏差-方差权衡概念提供了具体、算法化的定义。程序为每个指定的测试案例实现此逻辑，生成最终的分类代码列表。", "answer": "```python\nimport numpy as np\nimport scipy.fft\n\ndef solve():\n    \"\"\"\n    Main function to execute the polynomial regression analysis and classification.\n    \"\"\"\n    #\n    # Step 0: Define constants and problem parameters\n    #\n    RANDOM_SEED = 42\n    D_STAR = 4\n    A_COEFFS = np.array([0.3, -0.8, 0.5, 0.0, 0.7])\n    SIGMA = 0.1\n    SIGMA_SQUARED = SIGMA**2\n    N_TOTAL = 200\n    N_TRAIN = 120\n    N_VALID = 80\n\n    # Classification thresholds\n    T_U = 1.3\n    T_O = 0.9\n    T_O_PRIME = 1.2\n    H_U = 0.35\n    H_O = 0.45\n\n    # Test cases to evaluate\n    test_cases = [\n        {'d': 2, 'lambda': 0.001},  # Case 1\n        {'d': 4, 'lambda': 0.05},   # Case 2\n        {'d': 12, 'lambda': 0.0},    # Case 3\n        {'d': 12, 'lambda': 10.0},   # Case 4\n        {'d': 4, 'lambda': 0.0},    # Case 5\n    ]\n    \n    #\n    # Step 1: Generate dataset\n    #\n    rng = np.random.default_rng(RANDOM_SEED)\n\n    # Generate x values\n    x = rng.uniform(-1, 1, size=N_TOTAL)\n\n    # Generate true function values y_star\n    def f_star(x_in):\n        return A_COEFFS[0] + A_COEFFS[1] * x_in + A_COEFFS[2] * x_in**2 + \\\n               A_COEFFS[3] * x_in**3 + A_COEFFS[4] * x_in**4\n\n    y_star = f_star(x)\n\n    # Add Gaussian noise\n    noise = rng.normal(0, SIGMA, size=N_TOTAL)\n    y = y_star + noise\n\n    # Split into training and validation sets\n    indices = np.arange(N_TOTAL)\n    rng.shuffle(indices)\n    \n    train_indices = indices[:N_TRAIN]\n    valid_indices = indices[N_TRAIN:]\n\n    x_train, y_train = x[train_indices], y[train_indices]\n    x_valid, y_valid = x[valid_indices], y[valid_indices]\n\n    #\n    # Helper functions\n    #\n    def construct_design_matrix(x_data, degree):\n        \"\"\"Constructs the polynomial design matrix Phi.\"\"\"\n        return np.vander(x_data, degree + 1, increasing=True)\n\n    results = []\n\n    #\n    # Step 2-4: Process each test case\n    #\n    for case in test_cases:\n        d = case['d']\n        lambda_reg = case['lambda']\n\n        # Construct design matrices\n        phi_train = construct_design_matrix(x_train, d)\n        phi_valid = construct_design_matrix(x_valid, d)\n\n        # Fit the model using ridge regression (numerically stable)\n        d_plus_1 = d + 1\n        A = phi_train.T @ phi_train + lambda_reg * np.eye(d_plus_1)\n        b = phi_train.T @ y_train\n        w = np.linalg.solve(A, b)\n\n        # Make predictions\n        y_hat_train = phi_train @ w\n        y_hat_valid = phi_valid @ w\n\n        # Calculate metrics\n        # a) MSE\n        mse_train = np.mean((y_train - y_hat_train)**2)\n        mse_valid = np.mean((y_valid - y_hat_valid)**2)\n        \n        # b) High-frequency energy ratio rho_HF\n        residuals_valid = y_valid - y_hat_valid\n        \n        # Sort residuals according to x_valid\n        sort_indices = np.argsort(x_valid)\n        residuals_valid_sorted = residuals_valid[sort_indices]\n        \n        # Compute RFFT\n        R = scipy.fft.rfft(residuals_valid_sorted)\n        \n        # Calculate energies\n        # P: positive frequencies (indices 1 to end)\n        # H: top quartile of P (last 10 for N_valid=80)\n        # N_valid = 80 -> rfft length = 41. P_indices = 1..40. H_indices = 31..40.\n        num_positive_freqs = len(R) - 1\n        top_quartile_size = int(np.ceil(0.25 * num_positive_freqs))\n        \n        energy_P = np.sum(np.abs(R[1:])**2)\n        energy_H = np.sum(np.abs(R[-top_quartile_size:])**2)\n        \n        rho_hf = energy_H / energy_P if energy_P > 0 else 0.0\n        \n        # Apply classification rules\n        code = 1 # Default to well-fit\n\n        # Underfitting rule\n        is_underfit_by_degree = (d  D_STAR)\n        is_underfit_by_metrics = (mse_train >= T_U * SIGMA_SQUARED and \\\n                                  mse_valid >= T_U * SIGMA_SQUARED and \\\n                                  rho_hf = H_U)\n        if is_underfit_by_degree or is_underfit_by_metrics:\n            code = 0\n\n        # Overfitting rule\n        is_overfit_by_metrics = (d > D_STAR and \\\n                                 mse_train = T_O * SIGMA_SQUARED and \\\n                                 mse_valid >= T_O_PRIME * SIGMA_SQUARED and \\\n                                 rho_hf >= H_O)\n        if is_overfit_by_metrics:\n            code = 2\n            \n        results.append(code)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3135788"}, {"introduction": "虽然分析最终模型性能至关重要，但在训练过程中诊断问题是一项必不可少的实用技能。本练习侧重于解读学习曲线——即训练和验证损失随时间变化的轨迹。您将实现一个决策程序来回答一个常见问题：当模型泛化能力差时，是由于过拟合，还是由于更根本的未能从训练数据中学习（即优化失败）？[@problem_id:3135765]。", "problem": "给定一个在移除了批归一化（batch normalization）的 CIFAR-10 数据集上训练的卷积神经网络（CNN）的经验训练损失和验证损失的时间序列。对于每种情况，您必须判断观察到的泛化能力差是源于优化失败导致的欠拟合，还是源于过拟合。您的决策必须仅基于分析训练损失（表示为 $L_{\\text{train}}(t)$）和验证损失（表示为 $L_{\\text{val}}(t)$）在各个周期 $t \\in \\{1,2,\\dots,T\\}$ 上的轨迹。没有其他可用指标。\n\n使用以下基本依据：\n- 经验风险最小化：经验风险（训练损失）$L_{\\text{train}}$ 估计了在训练样本上的期望风险，而验证损失 $L_{\\text{val}}$ 估计了对未见数据的泛化能力。\n- 过拟合的特征是较小的 $L_{\\text{train}}$ 伴随着显著较大的 $L_{\\text{val}}$，这表明存在较大的泛化差距。\n- 因优化失败导致的欠拟合的特征是持续较高的 $L_{\\text{train}}$ 和优化进展微弱，这表明优化器未能有效最小化经验风险。\n\n您的程序必须实现一个基于这些定义的、有原则的决策过程，为每种情况输出：\n- 如果模式与过拟合一致，则输出 $0$。\n- 如果模式与因优化失败导致的欠拟合一致，则输出 $1$。\n\n测试套件（每个案例提供按周期排序的 $L_{\\text{train}}$ 和 $L_{\\text{val}}$ 列表）：\n- 案例 1：\n  - $L_{\\text{train}}$: $[1.6, 1.2, 0.8, 0.4, 0.2, 0.1, 0.08, 0.06, 0.05]$\n  - $L_{\\text{val}}$: $[1.7, 1.3, 0.9, 0.7, 0.65, 0.6, 0.58, 0.6, 0.62]$\n- 案例 2：\n  - $L_{\\text{train}}$: $[2.0, 1.95, 1.9, 1.88, 1.87, 1.865, 1.86, 1.859, 1.858]$\n  - $L_{\\text{val}}$: $[2.0, 1.98, 1.96, 1.95, 1.94, 1.94, 1.93, 1.93, 1.93]$\n- 案例 3：\n  - $L_{\\text{train}}$: $[1.2, 1.0, 0.8, 0.6, 0.5, 0.48, 0.47, 0.46, 0.45]$\n  - $L_{\\text{val}}$: $[1.2, 1.1, 0.95, 0.9, 0.92, 0.95, 1.0, 1.05, 1.1]$\n- 案例 4：\n  - $L_{\\text{train}}$: $[1.5, 1.3, 1.2, 1.25, 1.22, 1.21, 1.2, 1.19, 1.18]$\n  - $L_{\\text{val}}$: $[1.6, 1.5, 1.45, 1.5, 1.48, 1.47, 1.47, 1.46, 1.46]$\n- 案例 5：\n  - $L_{\\text{train}}$: $[1.8, 1.5, 1.1, 0.9, 0.7, 0.5, 0.3, 0.2, 0.15]$\n  - $L_{\\text{val}}$: $[1.9, 1.6, 1.3, 1.1, 1.1, 1.15, 1.2, 1.25, 1.3]$\n\n约束和要求：\n- 您必须通过对 $L_{\\text{train}}$ 和 $L_{\\text{val}}$ 轨迹进行第一性原理推理，将您的决策规则建立在上述基本定义之上，不得使用任何非从这些定义中推导出的外部数据或启发式方法。\n- 最终输出必须是单行，包含一个与案例顺序对应的整数列表。\n- 唯一允许的输出是如上定义的 $0$ 和 $1$。不涉及任何物理单位。\n- 您的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表（例如，$[0,1,0]$）。", "solution": "该问题具有科学依据，提法明确，客观，并包含足够的信息来制定一个有原则的解决方案。训练损失、验证损失、过拟合和欠拟合是机器学习中的基本概念。所提供的数据对于所描述的场景是真实的。任务是将给定的定性定义形式化为一个定量的、确定性的算法。\n\n核心目标是区分两种泛化失败模式：过拟合和因优化失败导致的欠拟合。这种区分取决于分析优化器在最小化经验风险方面的成功程度，而经验风险由训练损失 $L_{\\text{train}}(t)$ 表示。\n\n所提供的定义指导了决策过程的制定：\n1.  **因优化失败导致的欠拟合** 被定义为“持续较高的 $L_{\\text{train}}$”和“优化进展微弱”。这意味着模型甚至未能学习训练数据中的模式。\n2.  **过拟合** 被定义为“较小的 $L_{\\text{train}}$”和“显著较大的 $L_{\\text{val}}$”。这意味着模型已经很好地学习了训练数据（达到了较低的经验风险），以至于它也学习了训练集的噪声和特定伪影，从而导致在未见数据上表现不佳（即存在较大的泛化差距，$G(t) = L_{\\text{val}}(t) - L_{\\text{train}}(t)$）。\n\n基于这些第一性原理，可以建立一个序贯决策逻辑。首要问题是优化过程是否成功。如果训练损失没有被有效最小化，则诊断必须是欠拟合。如果训练损失被成功最小化，那么观察到的泛化能力差则归因于过拟合。\n\n**决策规则的形式化**\n\n设训练损失值的序列为 $\\mathcal{L}_{\\text{train}} = \\{L_{\\text{train}}(t)\\}_{t=1}^{T}$，历经 $T$ 个周期。\n\n**1. 欠拟合（优化失败）的评估**\n我们将定性定义转化为两个必须同时满足的定量条件。\n-   **“持续较高的 $L_{\\text{train}}$”**：通过检查最终的训练损失 $L_{\\text{train}}(T)$ 来评估。对于像 CIFAR-10 这样的10类分类问题，随机猜测的分类交叉熵损失为 $-\\ln(1/10) \\approx 2.3$。一个训练良好的模型应达到远低于 $1.0$ 的训练损失。因此，我们设定一个阈值 $\\theta_{\\text{loss}} = 1.0$。高于此阈值的最终训练损失被认为是“高”的。\n    $$ \\text{条件 1: } L_{\\text{train}}(T) > \\theta_{\\text{loss}} = 1.0 $$\n-   **“优化进展微弱”**：这通过训练开始到结束的总训练损失减少量来衡量，即 $\\Delta L_{\\text{train}} = L_{\\text{train}}(1) - L_{\\text{train}}(T)$。一个小的减少量表明优化器已经停滞或无效。我们设定一个阈值 $\\theta_{\\text{progress}} = 0.5$。总损失减少量小于此值被认为是“进展微弱”。\n    $$ \\text{条件 2: } \\Delta L_{\\text{train}}  \\theta_{\\text{progress}} = 0.5 $$\n\n当且仅当这两个条件都满足时，一个案例被分类为**欠拟合（标签 $1$）**。这对应于模型结束时处于高训练误差状态，并且在降低误差方面进展甚微的场景。\n\n**2. 过拟合的评估**\n在这个问题的二元分类方案中，任何未被识别为欠拟合的案例，通过排除法，被分类为**过拟合（标签 $0$）**。这个逻辑是合理的，因为未能满足欠拟合标准意味着训练损失已成功最小化（无论是 $L_{\\text{train}}(T)$ 低，还是进展显著，或两者兼有），这是过拟合的前提条件。这些案例的特征是最终训练损失低，但泛化差距 $G(T) = L_{\\text{val}}(T) - L_{\\text{train}}(T)$ 大且通常在增长，这是过拟合的标志。通常，验证损失 $L_{\\text{val}}(t)$ 会达到一个最小值然后开始增加，这是一个明确的迹象。\n\n**在测试案例上的应用**\n\n我们将此形式化过程应用于每个案例。\n\n- **案例 1**：\n  - $L_{\\text{train}} = [1.6, 1.2, 0.8, 0.4, 0.2, 0.1, 0.08, 0.06, 0.05]$\n  - $L_{\\text{train}}(1) = 1.6$, $L_{\\text{train}}(T) = 0.05$。\n  - 条件 1：$L_{\\text{train}}(T) = 0.05 \\ngtr 1.0$。未满足欠拟合的条件。\n  - **分类：$0$ (过拟合)**。\n  - 理由：训练损失被最小化到了一个非常低的值（$0.05$）。验证损失 $L_{\\text{val}}$ 在 $0.58$ 处触底然后开始增加，并产生了一个大的泛化差距（$0.62 - 0.05 = 0.57$）。这是典型的过拟合。\n\n- **案例 2**：\n  - $L_{\\text{train}} = [2.0, 1.95, 1.9, 1.88, 1.87, 1.865, 1.86, 1.859, 1.858]$\n  - $L_{\\text{train}}(1) = 2.0$, $L_{\\text{train}}(T) = 1.858$。\n  - 条件 1：$L_{\\text{train}}(T) = 1.858 > 1.0$。（为真）\n  - $\\Delta L_{\\text{train}} = 2.0 - 1.858 = 0.142$。\n  - 条件 2：$\\Delta L_{\\text{train}} = 0.142  0.5$。（为真）\n  - 两个欠拟合的条件都满足。\n  - **分类：$1$ (欠拟合)**。\n  - 理由：训练损失一直非常高，接近随机猜测的值，并且在各个周期中几乎没有改善。这是一个明显的优化失败案例。\n\n- **案例 3**：\n  - $L_{\\text{train}} = [1.2, 1.0, 0.8, 0.6, 0.5, 0.48, 0.47, 0.46, 0.45]$\n  - $L_{\\text{train}}(1) = 1.2$, $L_{\\text{train}}(T) = 0.45$。\n  - 条件 1：$L_{\\text{train}}(T) = 0.45 \\ngtr 1.0$。未满足欠拟合的条件。\n  - **分类：$0$ (过拟合)**。\n  - 理由：训练损失被最小化到了一个较低的值（$0.45$）。验证损失 $L_{\\text{val}}$ 在第四个周期后开始增加，最终的泛化差距很大（$1.1 - 0.45 = 0.65$）。这是过拟合。\n\n- **案例 4**：\n  - $L_{\\text{train}} = [1.5, 1.3, 1.2, 1.25, 1.22, 1.21, 1.2, 1.19, 1.18]$\n  - $L_{\\text{train}}(1) = 1.5$, $L_{\\text{train}}(T) = 1.18$。\n  - 条件 1：$L_{\\text{train}}(T) = 1.18 > 1.0$。（为真）\n  - $\\Delta L_{\\text{train}} = 1.5 - 1.18 = 0.32$。\n  - 条件 2：$\\Delta L_{\\text{train}} = 0.32  0.5$。（为真）\n  - 两个欠拟合的条件都满足。\n  - **分类：$1$ (欠拟合)**。\n  - 理由：训练损失一直很高，且优化进展甚微。损失甚至在某一点上有所增加，表明存在不稳定性。\n\n- **案例 5**：\n  - $L_{\\text{train}} = [1.8, 1.5, 1.1, 0.9, 0.7, 0.5, 0.3, 0.2, 0.15]$\n  - $L_{\\text{train}}(1) = 1.8$, $L_{\\text{train}}(T) = 0.15$。\n  - 条件 1：$L_{\\text{train}}(T) = 0.15 \\ngtr 1.0$。未满足欠拟合的条件。\n  - **分类：$0$ (过拟合)**。\n  - 理由：训练损失成功地被最小化到了一个较低的值（$0.15$）。然而，验证损失 $L_{\\text{val}}$ 发散并开始增加，导致最终产生了一个非常大的泛化差距（$1.3 - 0.15 = 1.15$）。这是一个明显的过拟合案例。\n\n最终的分类序列是 $[0, 1, 0, 1, 0]$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Solves the problem of classifying learning behavior as overfitting or underfitting.\n    \n    The function iterates through a predefined set of test cases, each containing\n    time series for training loss and validation loss. It applies a principled \n    decision rule to classify each case and prints the results in the required format.\n    \"\"\"\n    \n    # Test suite with training and validation loss trajectories.\n    test_cases = [\n        # Case 1: Overfitting\n        ([1.6, 1.2, 0.8, 0.4, 0.2, 0.1, 0.08, 0.06, 0.05],\n         [1.7, 1.3, 0.9, 0.7, 0.65, 0.6, 0.58, 0.6, 0.62]),\n        # Case 2: Underfitting\n        ([2.0, 1.95, 1.9, 1.88, 1.87, 1.865, 1.86, 1.859, 1.858],\n         [2.0, 1.98, 1.96, 1.95, 1.94, 1.94, 1.93, 1.93, 1.93]),\n        # Case 3: Overfitting\n        ([1.2, 1.0, 0.8, 0.6, 0.5, 0.48, 0.47, 0.46, 0.45],\n         [1.2, 1.1, 0.95, 0.9, 0.92, 0.95, 1.0, 1.05, 1.1]),\n        # Case 4: Underfitting\n        ([1.5, 1.3, 1.2, 1.25, 1.22, 1.21, 1.2, 1.19, 1.18],\n         [1.6, 1.5, 1.45, 1.5, 1.48, 1.47, 1.47, 1.46, 1.46]),\n        # Case 5: Overfitting\n        ([1.8, 1.5, 1.1, 0.9, 0.7, 0.5, 0.3, 0.2, 0.15],\n         [1.9, 1.6, 1.3, 1.1, 1.1, 1.15, 1.2, 1.25, 1.3])\n    ]\n\n    results = []\n    for l_train, l_val in test_cases:\n        # The validation loss (l_val) is provided but not strictly needed for the\n        # primary classification logic, which focuses on the success of empirical\n        # risk minimization (analyzing l_train).\n        result = classify_behavior(l_train)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef classify_behavior(l_train):\n    \"\"\"\n    Applies a principled decision rule to classify a learning trajectory.\n\n    Args:\n        l_train (list): A time series of training loss values.\n\n    Returns:\n        int: 0 for overfitting, 1 for underfitting due to optimization failure.\n    \"\"\"\n    # Convert list to a numpy array for efficient indexing.\n    l_train_np = np.array(l_train)\n\n    # Thresholds derived from first principles for a 10-class problem:\n    # A final training loss > 1.0 is considered high, indicating failure to fit the training set.\n    theta_loss = 1.0\n    # A total loss reduction  0.5 is considered weak progress, indicating optimization failure.\n    theta_progress = 0.5\n\n    # Extract key metrics from the training loss trajectory:\n    # Final training loss, L_train(T)\n    final_train_loss = l_train_np[-1]\n    # Initial training loss, L_train(1)\n    initial_train_loss = l_train_np[0]\n    # Total progress in optimization, L_train(1) - L_train(T)\n    progress = initial_train_loss - final_train_loss\n\n    # Apply the decision rule for underfitting due to optimization failure.\n    # This is defined as having a persistently high training loss AND making weak progress.\n    if final_train_loss > theta_loss and progress  theta_progress:\n        # Pattern is consistent with underfitting due to optimization failure.\n        return 1\n    else:\n        # If the underfitting criteria are not met, it implies the optimizer succeeded\n        # in reducing the training loss. Therefore, poor generalization is due to overfitting.\n        return 0\n\nsolve()\n```", "id": "3135765"}, {"introduction": "过拟合并不总是像训练和验证损失之间存在巨大差距那样显而易见。这项高级练习探讨了一种微妙但至关重要的现象——“捷径学习”，即模型表面上表现良好，但实际上依赖于训练数据中不具备真正泛化能力的伪相关性。您将创建一个同时包含鲁棒特征和“捷径”特征的数据集，训练一个学习了这种捷径的网络，然后使用一种有针对性的评估方法来揭示这种隐藏的过拟合形式 [@problem_id:3135726]。", "problem": "您必须编写一个完整、可运行的程序，该程序构造一个包含鲁棒特征和捷径特征的合成二元分类数据集，使用经验风险最小化训练一个单隐藏层神经网络，在两种受控条件（捷径特征可见和捷径特征被抑制）下评估验证准确率，并从第一性原理诊断过拟合或欠拟合。该程序必须实现以下场景，并为指定的测试套件生成一行包含整数列表的输出。\n\n基本原理。考虑在假设类别 $\\mathcal{F}$ 上的经验风险最小化，其中分类器 $f \\in \\mathcal{F}$ 将输入 $x \\in \\mathbb{R}^d$ 映射到二元标签 $y \\in \\{0,1\\}$ 的预测概率 $\\hat{y} \\in [0,1]$。设数据集 $S = \\{(x_i, y_i)\\}_{i=1}^n$ 上的经验风险为\n$$\nR_S(f) = \\frac{1}{n} \\sum_{i=1}^n \\ell(f(x_i), y_i),\n$$\n其中二元交叉熵损失为 $\\ell(\\hat{y}, y) = -\\left[y \\log(\\hat{y}) + (1-y)\\log(1-\\hat{y})\\right]$。在分布 $\\mathcal{D}$ 下的期望风险是 $R_{\\mathcal{D}}(f) = \\mathbb{E}_{(x,y)\\sim\\mathcal{D}}[\\ell(f(x),y)]$。泛化差距是 $\\Gamma(f) = R_{\\mathcal{D}}(f) - R_S(f)$。过拟合的特征是训练误差小但验证误差大，而欠拟合的特征是由于模型容量不足或优化不佳导致训练和验证误差都很大。\n\n带有鲁棒特征和捷径特征的数据生成。对于每个样本，设输入为 $x = [r; s] \\in \\mathbb{R}^{p+q}$，其中 $r \\in \\mathbb{R}^p$ 是鲁棒特征，$s \\in \\mathbb{R}^q$ 是捷径特征。标签为 $y \\in \\{0,1\\}$，并记作 $y' = 2y - 1 \\in \\{-1, +1\\}$。鲁棒特征遵循\n$$\nr \\sim \\mathcal{N}\\left(m \\, y' \\, \\mathbf{1}_p, \\, \\sigma_r^2 I_p\\right),\n$$\n而捷径特征遵循\n$$\ns \\sim \\mathcal{N}\\left(\\alpha \\, y' \\, \\mathbf{1}_q, \\, \\sigma_s^2 I_q\\right).\n$$\n一种称为捷径抑制的增强方法将 $s$ 替换为与 $y$ 无关的噪声：\n$$\nA(x) = [r; \\tilde{s}], \\quad \\tilde{s} \\sim \\mathcal{N}\\left(0, \\sigma_s^2 I_q\\right).\n$$\n这种增强方法在抑制捷径的同时保留了鲁棒信号。当捷径可见时，对 $x$ 进行验证；当被抑制时，对 $A(x)$ 进行验证。\n\n模型与训练。使用一个单隐藏层神经网络 $f_\\theta$，其参数为 $\\theta = (W_1, b_1, W_2, b_2)$，\n$$\nh = \\phi(W_1 x + b_1), \\quad \\hat{y} = \\sigma(W_2^\\top h + b_2),\n$$\n其中 $\\phi$ 是修正线性单元（ReLU），$\\sigma$ 是逻辑S型函数。使用随机梯度下降法在如上生成的训练集上最小化 $R_S(f_\\theta)$；可选择性地对训练输入应用捷径抑制以阻止捷径学习。\n\n诊断规则。设捷径可见时的验证准确率为 $a_{\\mathrm{vis}}$，被抑制时为 $a_{\\mathrm{sup}}$。使用阈值 $\\tau_h = 0.9$（高准确率）、$\\tau_\\ell = 0.7$（低准确率）和下降阈值 $\\Delta = 0.25$。诊断：\n- 如果 $a_{\\mathrm{vis}} \\ge \\tau_h$，$a_{\\mathrm{sup}} \\le \\tau_\\ell$，并且 $a_{\\mathrm{vis}} - a_{\\mathrm{sup}} \\ge \\Delta$，则为过拟合捷径特征。\n- 如果 $a_{\\mathrm{vis}}  \\tau_\\ell$ 并且 $a_{\\mathrm{sup}}  \\tau_\\ell$，则为欠拟合。\n- 否则，既不欠拟合也不过拟合。\n\n将诊断编码为整数：过拟合 $\\to 1$，欠拟合 $\\to -1$，其他情况 $\\to 0$。\n\n程序要求。您的程序必须：\n- 为每个测试用例生成独立的训练和验证数据集，并为每个用例使用固定的随机种子以确保可复现性。\n- 实现使用二元交叉熵和随机梯度下降法对指定神经网络的训练。\n- 评估 $a_{\\mathrm{vis}}$ 和 $a_{\\mathrm{sup}}$ 并应用上述诊断规则。\n- 生成一行输出，其中包含所有测试用例的诊断结果，形式为用方括号括起来的逗号分隔列表，例如 $[1,0,-1,0]$。\n\n测试套件。使用以下测试用例，每个用例指定为一个元组 $(p, q, m, \\alpha, \\sigma_r, \\sigma_s, H, E, \\eta, \\text{train\\_suppress}, \\text{seed})$，其中 $p$ 和 $q$ 是特征维度，$m$ 和 $\\alpha$ 是信号强度，$\\sigma_r$ 和 $\\sigma_s$ 是噪声尺度，$H$ 是隐藏层宽度，$E$ 是训练轮数，$\\eta$ 是学习率，$\\text{train\\_suppress} \\in \\{0,1\\}$ 指示训练期间是否应用捷径抑制，$\\text{seed}$ 是随机种子。数据集大小必须固定：训练集大小 $n_{\\mathrm{train}} = 3000$，验证集大小 $n_{\\mathrm{val}} = 3000$。\n\n- 用例 $1$（预期过拟合）：$(5, 3, 0.2, 4.0, 1.0, 1.0, 32, 50, 0.05, 0, 1337)$。\n- 用例 $2$（预期鲁棒泛化）：$(5, 3, 0.6, 4.0, 1.0, 1.0, 32, 50, 0.05, 1, 2027)$。\n- 用例 $3$（预期欠拟合）：$(5, 3, 0.6, 4.0, 1.0, 1.0, 2, 5, 0.01, 1, 3037)$。\n- 用例 $4$（预期鲁棒泛化，即使没有抑制，因为鲁棒信号很强）：$(5, 3, 1.5, 1.0, 1.0, 1.0, 32, 50, 0.05, 0, 4047)$。\n\n最终输出格式。您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如 $[r_1,r_2,r_3,r_4]$），其中每个 $r_i \\in \\{-1,0,1\\}$ 是根据上述规则对第 $i$ 个用例的诊断。不应打印任何其他文本。", "solution": "该问题要求实现一个计算实验，以诊断在一个包含两种特征类型（鲁棒特征和捷径特征）的合成数据集上训练的神经网络的过拟合和欠拟合情况。解决方案包括四个主要阶段：数据生成、模型实现、训练和诊断。\n\n### 1. 数据生成\n\n对于每个测试用例，生成一个大小为 $n_{\\mathrm{train}} = 3000$ 的训练集和一个大小为 $n_{\\mathrm{val}} = 3000$ 的验证集。每个数据点 $(x, y)$ 包含一个输入向量 $x \\in \\mathbb{R}^{p+q}$ 和一个二元标签 $y \\in \\{0,1\\}$。输入向量 $x$ 是鲁棒特征 $r \\in \\mathbb{R}^p$ 和捷径特征 $s \\in \\mathbb{R}^q$ 的拼接，即 $x = [r; s]$。\n\n标签 $y$ 从参数为 $0.5$ 的伯努利分布中抽取。为便于数学处理，将标签转换为 $y' = 2y - 1$，因此 $y' \\in \\{-1, +1\\}$。然后从均值依赖于 $y'$ 的多元正态分布中生成特征：\n-   鲁棒特征：$r \\sim \\mathcal{N}\\left(m \\, y' \\, \\mathbf{1}_p, \\, \\sigma_r^2 I_p\\right)$\n-   捷径特征：$s \\sim \\mathcal{N}\\left(\\alpha \\, y' \\, \\mathbf{1}_q, \\, \\sigma_s^2 I_q\\right)$\n\n这里，$m$ 和 $\\alpha$ 分别控制鲁棒特征和捷径特征的信号强度。$\\sigma_r^2$ 和 $\\sigma_s^2$ 是它们的方差。为提高效率，此过程使用向量化的 `numpy` 操作实现。为每个测试用例设置特定的随机种子，以确保数据和后续结果的可复现性。\n\n### 2. 模型架构\n\n分类器是一个单隐藏层神经网络 $f_\\theta$。输入维度为 $d = p+q$。其架构定义如下：\n$$\nh = \\phi(W_1 x + b_1)\n$$\n$$\n\\hat{y} = \\sigma(W_2^\\top h + b_2)\n$$\n其中：\n-   $x \\in \\mathbb{R}^d$ 是输入向量。\n-   $W_1 \\in \\mathbb{R}^{H \\times d}$ 和 $b_1 \\in \\mathbb{R}^{H}$ 是隐藏层的权重矩阵和偏置向量，其中 $H$ 是隐藏单元的数量。\n-   $\\phi(\\cdot)$ 是修正线性单元（ReLU）激活函数，$\\phi(z) = \\max(0, z)$。\n-   $h \\in \\mathbb{R}^{H}$ 是隐藏层激活值。\n-   $W_2 \\in \\mathbb{R}^{H}$ 和 $b_2 \\in \\mathbb{R}$ 是输出层的权重向量和标量偏置。\n-   $\\sigma(\\cdot)$ 是逻辑S型函数，$\\sigma(z) = (1 + e^{-z})^{-1}$，它将logit映射到概率 $\\hat{y} \\in [0,1]$。\n-   模型的参数为 $\\theta = (W_1, b_1, W_2, b_2)$。权重用小的随机值初始化，偏置初始化为零。\n\n### 3. 训练过程\n\n训练模型以最小化经验风险，即在训练集 $S = \\{(x_i, y_i)\\}_{i=1}^{n_{\\mathrm{train}}}$ 上的平均二元交叉熵损失：\n$$\nR_S(f_\\theta) = \\frac{1}{n_{\\mathrm{train}}} \\sum_{i=1}^{n_{\\mathrm{train}}} \\ell(\\sigma(W_2^\\top \\phi(W_1 x_i + b_1) + b_2), y_i)\n$$\n使用小批量随机梯度下降（SGD）进行优化。对于每一轮训练，将训练数据打乱并分成小批量。对每个小批量：\n1.  **增强（条件性）**：如果 `train_suppress` 标志设置为 $1$，则对输入批量应用捷径抑制。这包括将捷径特征 $s$ 替换为从 $\\mathcal{N}(0, \\sigma_s^2 I_q)$ 中抽取的噪声，从而有效地迫使模型依赖鲁棒特征。\n2.  **前向传播**：将小批量数据通过网络以计算预测概率 $\\hat{y}$。\n3.  **损失计算**：计算二元交叉熵损失。在对数函数内部加入一个小的 epsilon 项（$10^{-9}$）以确保数值稳定性。\n4.  **反向传播**：使用链式法则计算损失相对于所有参数的梯度（$\\nabla_{W_1} R_S$、$\\nabla_{b_1} R_S$、$\\nabla_{W_2} R_S$、$\\nabla_{b_2} R_S$）。ReLU函数的导数在输入为正时为 $1$，否则为 $0$。\n5.  **参数更新**：通过在负梯度方向上按学习率 $\\eta$ 缩放的步长来更新模型参数：\n    $$\n    \\theta \\leftarrow \\theta - \\eta \\nabla_\\theta R_S(f_\\theta)\n    $$\n此过程重复指定的训练轮数 $E$。\n\n### 4. 评估与诊断\n\n训练后，在两种条件下评估模型在验证集上的性能：\n1.  **可见捷径 ($a_{\\mathrm{vis}}$)**：在原始验证集上计算模型的准确率。如果 $\\hat{y} \\ge 0.5$，则预测标签为 $1$，否则为 $0$。\n2.  **受抑制的捷径 ($a_{\\mathrm{sup}}$)**：通过对每个样本应用捷径抑制增强 $A(x) = [r; \\tilde{s}]$（其中 $\\tilde{s} \\sim \\mathcal{N}(0, \\sigma_s^2 I_q)$）来创建一个修改后的验证集。然后在这个被抑制的数据集上计算模型的准确率。\n\n最终诊断基于一组使用阈值 $\\tau_h = 0.9$、$\\tau_\\ell = 0.7$ 和 $\\Delta = 0.25$ 的预定义规则：\n-   如果 $a_{\\mathrm{vis}} \\ge \\tau_h$ 且 $a_{\\mathrm{sup}} \\le \\tau_\\ell$ 且 $a_{\\mathrm{vis}} - a_{\\mathrm{sup}} \\ge \\Delta$，则诊断模型为**过拟合捷径特征**（编码为 $1$）。这表明模型高度依赖不鲁棒的捷径。\n-   如果 $a_{\\mathrm{vis}}  \\tau_\\ell$ 且 $a_{\\mathrm{sup}}  \\tau_\\ell$，则诊断模型为**欠拟合**（编码为 $-1$）。这表明模型未能从任何一种特征类型中学习到有意义的模式。\n-   否则，将模型的行为归类为**两者皆非**，通常表示鲁棒的泛化能力（编码为 $0$）。\n\n程序遍历每个测试用例，执行这些步骤，并将整数编码的诊断结果整理成一个最终列表。", "answer": "```python\nimport numpy as np\nfrom scipy.special import expit\n\nclass NeuralNetwork:\n    \"\"\"A one-hidden-layer neural network for binary classification.\"\"\"\n    def __init__(self, input_dim, hidden_dim):\n        \"\"\"\n        Initializes the parameters of the neural network.\n        \n        Args:\n            input_dim (int): Dimension of the input features (p+q).\n            hidden_dim (int): Number of units in the hidden layer (H).\n        \"\"\"\n        # Problem statement: W2 is a column vector, so W2.T is a row vector\n        self.W1 = np.random.randn(hidden_dim, input_dim) * 0.01\n        self.b1 = np.zeros((hidden_dim, 1))\n        self.W2 = np.random.randn(hidden_dim, 1) * 0.01\n        self.b2 = np.zeros((1, 1))\n        self.cache = {}\n\n    @staticmethod\n    def relu(z):\n        return np.maximum(0, z)\n\n    def forward(self, X):\n        \"\"\"\n        Performs the forward pass.\n        \n        Args:\n            X (np.ndarray): Input data of shape (input_dim, num_samples).\n        \n        Returns:\n            np.ndarray: Predicted probabilities of shape (1, num_samples).\n        \"\"\"\n        Z1 = self.W1 @ X + self.b1\n        A1 = self.relu(Z1)\n        Z2 = self.W2.T @ A1 + self.b2\n        A2 = expit(Z2) # Numerically stable sigmoid\n\n        self.cache = {'X': X, 'Z1': Z1, 'A1': A1, 'Z2': Z2, 'A2': A2}\n        return A2\n\n    def backward(self, Y):\n        \"\"\"\n        Performs the backward pass and computes gradients.\n        \n        Args:\n            Y (np.ndarray): True labels of shape (1, num_samples).\n        \"\"\"\n        num_samples = Y.shape[1]\n        X, A1, A2, Z1 = self.cache['X'], self.cache['A1'], self.cache['A2'], self.cache['Z1']\n\n        dZ2 = A2 - Y\n        self.dW2 = (1 / num_samples) * (A1 @ dZ2.T)\n        self.db2 = (1 / num_samples) * np.sum(dZ2, axis=1, keepdims=True)\n\n        dA1 = self.W2 @ dZ2\n        dZ1 = dA1 * (Z1 > 0)\n        self.dW1 = (1 / num_samples) * (dZ1 @ X.T)\n        self.db1 = (1 / num_samples) * np.sum(dZ1, axis=1, keepdims=True)\n\n    def update_params(self, learning_rate):\n        \"\"\"Updates parameters using computed gradients.\"\"\"\n        self.W1 -= learning_rate * self.dW1\n        self.b1 -= learning_rate * self.db1\n        self.W2 -= learning_rate * self.dW2\n        self.b2 -= learning_rate * self.db2\n\ndef generate_data(n_samples, p, q, m, alpha, sigma_r, sigma_s):\n    \"\"\"Generates synthetic data with robust and shortcut features.\"\"\"\n    y = np.random.randint(0, 2, size=(n_samples, 1))\n    y_prime = 2 * y - 1\n\n    # Generate robust features\n    mean_r_mat = y_prime @ np.ones((1, p)) * m\n    r = np.random.randn(n_samples, p) * sigma_r + mean_r_mat\n\n    # Generate shortcut features\n    mean_s_mat = y_prime @ np.ones((1, q)) * alpha\n    s = np.random.randn(n_samples, q) * sigma_s + mean_s_mat\n    \n    X = np.hstack((r, s))\n    return X, y\n\ndef apply_shortcut_suppression(X, q, sigma_s):\n    \"\"\"Applies shortcut suppression augmentation to data.\"\"\"\n    n_samples, _ = X.shape\n    p = X.shape[1] - q\n    r_features = X[:, :p]\n    noise = np.random.randn(n_samples, q) * sigma_s\n    return np.hstack((r_features, noise))\n\ndef solve():\n    \"\"\"Main function to run the test suite and produce the final output.\"\"\"\n    test_cases = [\n        (5, 3, 0.2, 4.0, 1.0, 1.0, 32, 50, 0.05, 0, 1337),\n        (5, 3, 0.6, 4.0, 1.0, 1.0, 32, 50, 0.05, 1, 2027),\n        (5, 3, 0.6, 4.0, 1.0, 1.0, 2, 5, 0.01, 1, 3037),\n        (5, 3, 1.5, 1.0, 1.0, 1.0, 32, 50, 0.05, 0, 4047),\n    ]\n\n    n_train = 3000\n    n_val = 3000\n    batch_size = 32\n    \n    tau_h = 0.9\n    tau_l = 0.7\n    delta = 0.25\n\n    results = []\n    \n    for case in test_cases:\n        p, q, m, alpha, sigma_r, sigma_s, H, E, eta, train_suppress, seed = case\n        \n        np.random.seed(seed)\n        \n        # 1. Generate Data\n        X_train, y_train = generate_data(n_train, p, q, m, alpha, sigma_r, sigma_s)\n        X_val, y_val = generate_data(n_val, p, q, m, alpha, sigma_r, sigma_s)\n\n        # 2. Initialize Model\n        input_dim = p + q\n        model = NeuralNetwork(input_dim, H)\n\n        # 3. Train Model\n        n_batches = int(np.ceil(n_train / batch_size))\n        for epoch in range(E):\n            permutation = np.random.permutation(n_train)\n            X_train_shuffled = X_train[permutation, :]\n            y_train_shuffled = y_train[permutation, :]\n\n            for i in range(n_batches):\n                start = i * batch_size\n                end = min(start + batch_size, n_train)\n                X_batch = X_train_shuffled[start:end, :]\n                y_batch = y_train_shuffled[start:end, :]\n                \n                # Apply shortcut suppression if required\n                if train_suppress == 1:\n                    X_batch = apply_shortcut_suppression(X_batch, q, sigma_s)\n                \n                # Transpose for model's expected shape (dim, samples)\n                X_batch_T = X_batch.T\n                y_batch_T = y_batch.T\n\n                # Forward, backward, update\n                _ = model.forward(X_batch_T)\n                model.backward(y_batch_T)\n                model.update_params(eta)\n\n        # 4. Evaluate Model\n        # a_vis: accuracy on validation set with shortcuts visible\n        y_hat_vis = model.forward(X_val.T)\n        predictions_vis = (y_hat_vis >= 0.5).astype(int)\n        a_vis = np.mean(predictions_vis == y_val.T)\n\n        # a_sup: accuracy on validation set with shortcuts suppressed\n        X_val_sup = apply_shortcut_suppression(X_val, q, sigma_s)\n        y_hat_sup = model.forward(X_val_sup.T)\n        predictions_sup = (y_hat_sup >= 0.5).astype(int)\n        a_sup = np.mean(predictions_sup == y_val.T)\n\n        # 5. Diagnose\n        diagnosis = 0 # Default: Neither\n        if a_vis >= tau_h and a_sup = tau_l and (a_vis - a_sup) >= delta:\n            diagnosis = 1 # Overfitting to shortcuts\n        elif a_vis  tau_l and a_sup  tau_l:\n            diagnosis = -1 # Underfitting\n            \n        results.append(diagnosis)\n    \n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3135726"}]}