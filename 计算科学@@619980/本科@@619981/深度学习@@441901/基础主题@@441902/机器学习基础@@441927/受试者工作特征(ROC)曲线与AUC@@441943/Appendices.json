{"hands_on_practices": [{"introduction": "在进行任何模型分析或比较之前，我们必须掌握如何根据模型的离散输出点来计算AUC得分。本练习将指导您使用梯形法则——一种基本的数值积分方法——来实现计算AUC的标准算法。这个过程还将处理一些常见的实际问题，例如确保包含曲线的端点和处理重复的假正例率值，从而为您后续的所有分析奠定坚实的计算基础。[@problem_id:3284361]", "problem": "给定离散的受试者工作特征 (ROC) 输出，形式为一个有限点集 $\\{(\\mathrm{FPR}_i,\\mathrm{TPR}_i)\\}_{i=1}^m$，其中 $\\mathrm{FPR}$ 表示假阳性率，$\\mathrm{TPR}$ 表示真阳性率。ROC 曲线下面积 (AUC) 是函数 $\\mathrm{TPR}(\\mathrm{FPR})$ 在区间 $[0,1]$ 上图形下方的面积，当将 $\\mathrm{TPR}$ 视为 $x=\\mathrm{FPR}$ 的函数时，可形式化为黎曼积分 $\\int_{0}^{1} \\mathrm{TPR}(x)\\,dx$。在实践中，只有离散的样本可用。\n\n你的任务是编写一个完整的程序，使用从黎曼和与分段线性近似的第一性原理推导出的梯形法则，对给定点集的预处理版本来近似这个面积。预处理必须如下：\n- 包含端点：确保包含 $(0,0)$ 和 $(1,1)$。如果任一端点缺失，必须添加。\n- 解决重复的横坐标：如果多个点共享相同的假阳性率 $x$ 值，则仅保留在该 $x$ 处具有最大真阳性率的点（这在重复的横坐标处构造了上包络线）。\n- 按横坐标排序：将剩余的点按 $\\mathrm{FPR}$ 以非递减顺序排序，使横坐标构成 $[0,1]$ 的有效划分。\n\n假设所有提供的坐标都满足 $0 \\le \\mathrm{FPR} \\le 1$ 和 $0 \\le \\mathrm{TPR} \\le 1$。对排序后的序列使用梯形法则，通过对连续线段下的梯形面积求和来近似 $\\int_{0}^{1} \\mathrm{TPR}(x)\\,dx$。每个测试用例的最终 AUC 必须四舍五入到六位小数。\n\n测试套件（每个测试用例是一个点 $(\\mathrm{FPR},\\mathrm{TPR})$ 的列表）：\n- 案例 $1$（一般单调情况）：$[(0,0),(0.2,0.5),(0.6,0.8),(1,1)]$。\n- 案例 $2$（未排序输入）：$[(1,1),(0.3,0.6),(0,0),(0.7,0.9)]$。\n- 案例 $3$（横坐标重复，取最大 $\\mathrm{TPR}$）：$[(0,0),(0.5,0.4),(0.5,0.6),(1,1)]$。\n- 案例 $4$（零点处垂直上升，完美分类器包络线）：$[(0,0),(0,1),(1,1)]$。\n- 案例 $5$（退化分类器）：$[(0,0),(1,0)]$。\n- 案例 $6$（缺失端点，需要增补）：$[(0.2,0.3),(0.4,0.6),(0.9,0.95)]$。\n\n你的程序必须仅使用上述过程计算每个案例的 AUC，然后打印一行，其中包含按案例顺序排列的六个 AUC 值列表，四舍五入到六位小数。输出格式必须是仅包含结果的一行，形式为方括号内以逗号分隔的列表，例如 $[r_1,r_2,\\dots,r_6]$，其中每个 $r_i$ 是一个四舍五入到六位小数的浮点数。此问题不涉及单位；输出是无单位的。", "solution": "该问题要求根据一个离散点集 $\\{(\\mathrm{FPR}_i, \\mathrm{TPR}_i)\\}$ 计算受试者工作特征曲线下面积 (AUC)。AUC 定义为真阳性率 ($\\mathrm{TPR}$) 相对于假阳性率 ($\\mathrm{FPR}$) 在区间 $[0, 1]$ 上的定积分。\n$$\n\\mathrm{AUC} = \\int_{0}^{1} \\mathrm{TPR}(x) \\,dx\n$$\n其中 $x$ 代表 $\\mathrm{FPR}$。由于函数 $\\mathrm{TPR}(x)$ 仅在有限数量的点上已知，因此必须对该积分进行数值近似。问题指定使用梯形法则，该法则是从函数的分段线性近似推导出来的。\n\n解决方案主要分为两个阶段：数据预处理和数值积分。\n\n**1. 数据预处理**\n\n在应用梯形法则之前，必须对原始数据点进行处理，以在区间 $[0, 1]$ 的一个划分上形成一个定义明确的单调函数。这包括按规定顺序执行的三个步骤。\n\n**步骤 1.1：端点增补**\n积分是在定义域 $[0, 1]$ 上定义的。为确保覆盖整个定义域，ROC 曲线的标准端点 $(0, 0)$ 和 $(1, 1)$ 必须是数据集的一部分。点 $(0, 0)$ 对应于一个从不将任何实例分类为阳性的分类器阈值，导致零真阳性和零假阳性。点 $(1, 1)$ 对应于一个总是将实例分类为阳性的阈值，导致所有真阳性和所有假阳性。因此，我们通过包含 $(0, 0)$ 和 $(1, 1)$ 来扩充初始点集。\n\n**步骤 1.2：解决重复的横坐标**\n一个函数对每个输入必须有唯一的值。如果多个点共享相同的 $\\mathrm{FPR}$ 值，它们代表在相同假阳性成本下的不同分类器性能。ROC 曲线本身被定义为所有可能的 $(\\mathrm{FPR}, \\mathrm{TPR})$ 对的上包络线。因此，对于任何给定的 $\\mathrm{FPR}$ 值 $x_i$，我们必须选择具有最大相应 $\\mathrm{TPR}$ 值的点。这通过按点的 $\\mathrm{FPR}$ 坐标分组并为每组仅保留最大 $\\mathrm{TPR}$ 来实现。例如，如果存在点 $(0.5, 0.4)$ 和 $(0.5, 0.6)$，我们保留 $(0.5, 0.6)$ 并丢弃 $(0.5, 0.4)$。\n\n**步骤 1.3：按横坐标排序**\n梯形法则对由连续点形成的梯形面积求和。这要求点按其 x 坐标 ($\\mathrm{FPR}$) 排序。在完成前述步骤后，将得到的唯一性点集 $\\{ (x_j, y_j) \\}_{j=0}^N$ 按其 $x_j$ 值的非递减顺序排序。这将产生一个有序的点序列 $(x_0, y_0), (x_1, y_1), \\dots, (x_N, y_N)$，使得 $0 = x_0 \\le x_1 \\le \\dots \\le x_N = 1$。\n\n**2. 使用梯形法则进行数值积分**\n\n有了预处理和排序后的点 $(x_i, y_i)$（其中 $i=0, \\dots, N$），我们通过用直线段连接连续的点来近似函数 $\\mathrm{TPR}(x)$。这个分段线性曲线下的面积是每个线段与 x 轴形成的梯形面积之和。\n\n对于任意两个连续点 $P_{i-1} = (x_{i-1}, y_{i-1})$ 和 $P_i = (x_i, y_i)$，它们形成一个顶点为 $(x_{i-1}, 0)$、$(x_i, 0)$、$(x_i, y_i)$ 和 $(x_{i-1}, y_{i-1})$ 的梯形。第 $i$ 个梯形的面积 $A_i$ 由以下公式给出：\n$$\nA_i = \\frac{1}{2} (y_{i-1} + y_i) (x_i - x_{i-1})\n$$\n该公式表示两个平行边（$y_{i-1}$ 和 $y_i$）的平均高度乘以底边宽度（$x_i - x_{i-1}$）。\n\n总 AUC 是从 $i=1$ 到 $N$ 的所有这些梯形面积之和：\n$$\n\\mathrm{AUC} \\approx \\sum_{i=1}^{N} A_i = \\sum_{i=1}^{N} \\frac{1}{2} (y_{i-1} + y_i) (x_i - x_{i-1})\n$$\n这个求和提供了 $\\int_{0}^{1} \\mathrm{TPR}(x) \\,dx$ 的数值近似。每个测试用例的最终结果按要求四舍五入到六位小数。", "answer": "```python\nimport numpy as np\n\ndef calculate_auc(points_list):\n    \"\"\"\n    Calculates the Area Under the ROC Curve (AUC) from a list of (FPR, TPR) points.\n\n    The process involves three preprocessing steps followed by the trapezoidal rule application:\n    1. Augment points with (0,0) and (1,1).\n    2. Resolve duplicate FPRs by taking the maximum TPR.\n    3. Sort the points by FPR.\n    4. Apply the trapezoidal rule to the processed points.\n\n    Args:\n        points_list (list of tuples): A list where each tuple is an (FPR, TPR) point.\n\n    Returns:\n        float: The calculated AUC.\n    \"\"\"\n    # Step 1: Augment points with the definitional endpoints (0,0) and (1,1).\n    # This creates a comprehensive list to start with.\n    all_points = list(points_list)\n    all_points.append((0, 0))\n    all_points.append((1, 1))\n\n    # Step 2: Resolve duplicate abscissae (FPRs).\n    # We use a dictionary to store the maximum TPR for each unique FPR.\n    # The ROC curve is the upper envelope of performance, justifying taking the max TPR.\n    roc_map = {}\n    for fpr, tpr in all_points:\n        # If the FPR is already in the map, update it only if the new TPR is higher.\n        # Otherwise, add the new (FPR, TPR) pair.\n        roc_map[fpr] = max(roc_map.get(fpr, -1.0), tpr)\n    \n    # Convert the map back to a list of points.\n    processed_points = list(roc_map.items())\n\n    # Step 3: Sort the points by FPR in nondecreasing order.\n    # This prepares the points for the trapezoidal rule, ensuring a valid partition.\n    processed_points.sort(key=lambda p: p[0])\n\n    # Convert the list of points to a NumPy array for efficient computation.\n    roc_array = np.array(processed_points)\n    x_coords = roc_array[:, 0]  # FPR values\n    y_coords = roc_array[:, 1]  # TPR values\n\n    # Step 4: Apply the trapezoidal rule.\n    # np.trapz(y, x) computes the integral of y(x) using the trapezoidal rule.\n    # This is equivalent to sum(0.5 * (y_i + y_{i-1}) * (x_i - x_{i-1})).\n    auc = np.trapz(y_coords, x_coords)\n    \n    return auc\n\n\ndef solve():\n    \"\"\"\n    Main function to execute the AUC calculation for all specified test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: General monotone case\n        [(0,0),(0.2,0.5),(0.6,0.8),(1,1)],\n        # Case 2: Unsorted inputs\n        [(1,1),(0.3,0.6),(0,0),(0.7,0.9)],\n        # Case 3: Duplicate abscissae, take maximum TPR\n        [(0,0),(0.5,0.4),(0.5,0.6),(1,1)],\n        # Case 4: Vertical rise at zero, perfect classifier envelope\n        [(0,0),(0,1),(1,1)],\n        # Case 5: Degenerate classifier\n        [(0,0),(1,0)],\n        # Case 6: Missing endpoints, require augmentation\n        [(0.2,0.3),(0.4,0.6),(0.9,0.95)]\n    ]\n\n    results = []\n    for case in test_cases:\n        auc_value = calculate_auc(case)\n        # Format the result to exactly six decimal places as a string.\n        results.append(f\"{auc_value:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3284361"}, {"introduction": "为什么AUC通常比准确率或精确率等指标更受青睐？本练习将探讨AUC的一个核心特性：它对于分类器分数的任何单调变换都具有不变性。通过对模型的logits输出应用“温度缩放”（temperature scaling）并观察其对AUC与精确率-召回率（Precision-Recall）的不同影响，您将更深刻地理解为什么AUC是一个衡量排序质量的稳健指标，它独立于所选的决策阈值或分数校准。[@problem_id:3167199]", "problem": "考虑深度学习中的二元分类问题，其中模型输出实数值的 logits。温度缩放通过 $z \\mapsto z/\\alpha$ 对 logits 进行变换，其中 $\\alpha$ 是任意正标量。预测概率是通过将逻辑 sigmoid 函数 $\\sigma(s) = 1/(1+e^{-s})$ 应用于分数 $s$ 得到的。在固定的概率决策阈值 $t$ 下，当且仅当 $\\sigma(z/\\alpha) \\ge t$ 时，预测类别为正。精确率（Precision）和召回率（Recall）是根据所选阈值的混淆矩阵计数来定义的，而受试者工作特征（ROC）曲线则是由在整个分数范围内改变阈值所获得的一系列真阳性率和假阳性率对来定义的。ROC 曲线下面积（AUC）是该 ROC 曲线下的面积，并且可以等价地解释为评分函数将一个随机选择的正样本排在一个随机选择的负样本之前的概率。\n\n从这些核心定义出发，编写一个完整的、可运行的程序，对下面的每个测试用例执行以下操作：\n\n1. 对提供的 logits 应用温度缩放，其中 $\\alpha \\in \\{0.5, 1.0, 2.0\\}$，计算分数 $s_i = z_i/\\alpha$，然后：\n   - 使用基于成对排序的定义计算 ROC 曲线下面积（AUC），即一个随机选择的正分数值超过一个随机选择的负分数值的概率，其中平局贡献一半的分数。\n   - 在固定的概率决策阈值 $t = 0.7$ 下，使用变换后的概率 $p_i = \\sigma(s_i)$ 计算精确率和召回率，并遵循以下约定处理分母为零的情况：如果没有预测为正的样本，则将精确率定义为 $0$；如果没有实际为正的样本，则将召回率定义为 $0$。\n\n2. 通过以下方式展示指标的特异性敏感度：\n   - 检查 AUC 在温度缩放下的不变性，即 $\\alpha = 0.5$ 和 $\\alpha = 2.0$ 时的 AUC 值是否在 $10^{-12}$ 的绝对容差范围内与 $\\alpha = 1.0$ 时的基线 AUC 相等。\n   - 检查在固定阈值 $t = 0.7$ 下计算的精确率或召回率是否在三个 $\\alpha$ 值之间发生变化。\n\n3. 为每个测试用例生成以下输出：\n   - $\\alpha = 1.0$ 时的基线 AUC，四舍五入到 $6$ 位小数。\n   - 一个布尔值，指示在指定的容差范围内，AUC 不变性是否在 $\\alpha \\in \\{0.5, 1.0, 2.0\\}$ 之间成立。\n   - 一个布尔值，指示在阈值 $t = 0.7$ 下的精确率或召回率是否在 $\\alpha \\in \\{0.5, 1.0, 2.0\\}$ 之间发生变化。\n\n使用以下测试套件，它涵盖了一般的混合情况、存在平局的情况以及类别不平衡的情况：\n\n- 测试用例 1 (一般混合情况):\n  - 标签 $\\mathbf{y} = [1, 0, 1, 0, 1, 0, 0, 1, 0, 1]$。\n  - Logits $\\mathbf{z} = [2.4, -0.5, 0.3, -1.0, 1.2, 0.4, -2.2, 0.9, -0.8, 3.1]$。\n\n- 测试用例 2 (存在平局):\n  - 标签 $\\mathbf{y} = [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]$。\n  - Logits $\\mathbf{z} = [0.5, 0.5, 0.5, -0.5, -0.5, -0.5, 1.2, 1.2, -1.2, -1.2]$。\n\n- 测试用例 3 (类别不平衡):\n  - 标签 $\\mathbf{y} = [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0]$。\n  - Logits $\\mathbf{z} = [-2.1, -1.8, -0.2, 0.1, -0.5, 0.6, -1.0, 1.1, -0.7, 0.3, -0.9, -0.4, 2.0, -3.0, 0.8]$。\n\n你的程序应生成单行输出，其中包含三个测试用例的聚合结果，顺序如下：\n$[\\text{auc\\_case1}, \\text{invariant\\_case1}, \\text{sensitive\\_case1}, \\text{auc\\_case2}, \\text{invariant\\_case2}, \\text{sensitive\\_case2}, \\text{auc\\_case3}, \\text{invariant\\_case3}, \\text{sensitive\\_case3}]$。\n\n所有 $9$ 个输出必须是指定的类型：AUC 值为浮点数（四舍五入到 $6$ 位小数），不变性和敏感性检查为布尔值。此问题不涉及物理单位。最终的输出行必须严格按照方括号内逗号分隔列表的格式打印。", "solution": "该问题已经过验证，被认为是科学上合理的、定义明确的且完整的。所有定义、数据和约束都已提供，并与机器学习和统计学中的既定原则一致。\n\n该问题探讨了温度缩放对不同二元分类指标的影响。它将基于排序的指标（如受试者工作特征曲线下面积 AUC）与基于阈值的指标（如精确率和召回率）进行了对比。\n\n### 核心概念与数学公式\n\n用于二元分类的深度学习模型输出 logits $\\mathbf{z}$，它们是实数值的分数。这些分数通过一个评分函数和概率映射被转换为概率。\n\n1.  **温度缩放**：logits $z_i$ 通过一个正的温度参数 $\\alpha$ 进行缩放：\n    $$s_i = \\frac{z_i}{\\alpha}$$\n    这种缩放会使分数分布变得更尖锐（$\\alpha  1$）或更平滑（$\\alpha > 1$）。基线是 $\\alpha = 1.0$，此时 $s_i = z_i$。\n\n2.  **概率计算**：缩放后的分数 $s_i$ 使用逻辑 sigmoid 函数 $\\sigma$ 转换为概率 $p_i$：\n    $$p_i = \\sigma(s_i) = \\frac{1}{1 + e^{-s_i}}$$\n\n3.  **AUC（ROC 曲线下面积）**：AUC 是一个基于排序的指标。它评估模型将一个随机选择的正样本排在比一个随机选择的负样本更高的能力。给定正样本的分数集 $S_{pos}$ 和负样本的分数集 $S_{neg}$，AUC 的计算公式如下：\n    $$ \\text{AUC} = \\frac{1}{|S_{pos}| |S_{neg}|} \\sum_{s_p \\in S_{pos}} \\sum_{s_n \\in S_{neg}} K(s_p, s_n) $$\n    其中 $K(s_p, s_n)$ 是一个比较核函数：\n    $$ K(s_p, s_n) = \\begin{cases} 1  \\text{if } s_p > s_n \\\\ 0.5  \\text{if } s_p = s_n \\\\ 0  \\text{if } s_p  s_n \\end{cases} $$\n    由于使用 $\\alpha > 0$ 的温度缩放是一个单调变换（$z_i > z_j \\iff z_i/\\alpha > z_j/\\alpha$），分数的相对顺序得以保留。因此，对于任何正数 $\\alpha$，$K(s_p, s_n)$ 的值都保持不变。这意味着 AUC 理论上对温度缩放是不变的。计算验证将在一个小的浮点容差范围内验证这一属性。\n\n4.  **精确率和召回率**：这些是基于阈值的指标。一个决策阈值 $t$ 应用于预测概率 $p_i$ 以获得二元预测 $\\hat{y}_i$：\n    $$ \\hat{y}_i = \\begin{cases} 1  \\text{if } p_i \\ge t \\\\ 0  \\text{if } p_i  t \\end{cases} $$\n    精确率和召回率随后根据混淆矩阵的元素计算得出：真阳性（$TP$）、假阳性（$FP$）和假阴性（$FN$）。\n    $$ \\text{Precision} = \\frac{TP}{TP + FP} \\quad (\\text{如果 } TP+FP=0 \\text{，则定义为 } 0) $$\n    $$ \\text{Recall} = \\frac{TP}{TP + FN} \\quad (\\text{如果 } TP+FN=0 \\text{，则定义为 } 0) $$\n    分类规则 $p_i \\ge t$ 等效于对 logits 使用一个派生出的阈值进行操作。代入定义：\n    $$ \\sigma(z_i/\\alpha) \\ge t \\implies \\frac{1}{1 + e^{-z_i/\\alpha}} \\ge t \\implies \\frac{z_i}{\\alpha} \\ge \\sigma^{-1}(t) \\implies z_i \\ge \\alpha \\cdot \\sigma^{-1}(t) $$\n    其中 $\\sigma^{-1}(t) = \\ln(t / (1-t))$ 是 logit 空间中的阈值。logits 的决策边界 $z_i \\ge \\alpha \\cdot \\ln(t/(1-t))$ 直接依赖于 $\\alpha$。对于固定的概率阈值 $t=0.7$，logit 阈值随 $\\alpha$ 变化：\n    -   对于 $\\alpha = 0.5$：$z_i \\ge 0.5 \\cdot \\ln(0.7/0.3) \\approx 0.4236$\n    -   对于 $\\alpha = 1.0$：$z_i \\ge 1.0 \\cdot \\ln(0.7/0.3) \\approx 0.8473$\n    -   对于 $\\alpha = 2.0$：$z_i \\ge 2.0 \\cdot \\ln(0.7/0.3) \\approx 1.6946$\n    由于决策边界发生变化，预测为正的实例集合也会改变，从而导致 $TP$、$FP$ 和 $FN$ 的值不同。因此，精确率和召回率对温度缩放是敏感的。\n\n### 求解算法\n\n对于每个提供的测试用例：\n1.  初始化一个空列表，用于存储该用例的最终结果。\n2.  根据测试用例数据定义标签 $\\mathbf{y}$ 和 logits $\\mathbf{z}$。\n3.  定义温度缩放因子集合 $\\mathcal{A} = \\{0.5, 1.0, 2.0\\}$ 和概率阈值 $t = 0.7$。\n4.  为每个 $\\alpha \\in \\mathcal{A}$ 创建存储空间，以保存计算出的指标。\n5.  遍历每个 $\\alpha \\in \\mathcal{A}$：\n    a.  计算缩放后的分数 $\\mathbf{s} = \\mathbf{z} / \\alpha$。\n    b.  **计算 AUC**：根据标签 $\\mathbf{y}$ 将分数分为正样本集（$S_{pos}$）和负样本集（$S_{neg}$）。按照上述 AUC 公式系统地执行所有成对比较，对于平局情况给予 $0.5$ 分。\n    c.  **计算精确率和召回率**：\n        i.  计算概率 $\\mathbf{p} = \\sigma(\\mathbf{s})$。\n        ii. 通过对概率在阈值 $t$ 处进行截断来做出预测 $\\hat{\\mathbf{y}}$。\n        iii. 通过比较 $\\hat{\\mathbf{y}}$ 和 $\\mathbf{y}$ 来计数 $TP, FP, FN$。\n        iv. 计算精确率和召回率，并应用所提供的针对分母为零的规则。\n    d.  存储当前 $\\alpha$ 下计算出的 AUC、精确率和召回率。\n6.  遍历完所有 $\\alpha$ 值后：\n    a.  **AUC 不变性检查**：将 $\\alpha=0.5$ 和 $\\alpha=2.0$ 时的 AUC 值与 $\\alpha=1.0$ 时的基线 AUC 进行比较。如果绝对差值均在 $10^{-12}$ 的容差范围内，则不变性成立。\n    b.  **精确率/召回率敏感性检查**：将 $\\alpha=0.5$ 和 $\\alpha=2.0$ 时的 `(精确率, 召回率)` 对与 $\\alpha=1.0$ 时的基线对进行比较。如果这些对中至少有一对与基线不同，则指标是敏感的。\n7.  格式化该测试用例的最终结果：基线 AUC（$\\alpha=1.0$ 时）四舍五入到 $6$ 位小数，AUC 不变性检查的布尔结果，以及敏感性检查的布尔结果。\n8.  将所有测试用例的格式化结果聚合到一个列表中，并按指定格式打印。\n\n这个过程系统地解决了问题的所有要求，从而得出最终可验证的输出。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem for all test cases and prints the final formatted result.\n    \"\"\"\n    test_cases = [\n        {\n            \"labels\": np.array([1, 0, 1, 0, 1, 0, 0, 1, 0, 1]),\n            \"logits\": np.array([2.4, -0.5, 0.3, -1.0, 1.2, 0.4, -2.2, 0.9, -0.8, 3.1]),\n        },\n        {\n            \"labels\": np.array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0]),\n            \"logits\": np.array([0.5, 0.5, 0.5, -0.5, -0.5, -0.5, 1.2, 1.2, -1.2, -1.2]),\n        },\n        {\n            \"labels\": np.array([0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0]),\n            \"logits\": np.array([-2.1, -1.8, -0.2, 0.1, -0.5, 0.6, -1.0, 1.1, -0.7, 0.3, -0.9, -0.4, 2.0, -3.0, 0.8]),\n        },\n    ]\n\n    all_results = []\n    alphas = [0.5, 1.0, 2.0]\n    prob_threshold = 0.7\n    tolerance = 1e-12\n\n    for case in test_cases:\n        labels, logits = case[\"labels\"], case[\"logits\"]\n        \n        metrics_by_alpha = {}\n\n        for alpha in alphas:\n            scores = logits / alpha\n            \n            # --- AUC Calculation ---\n            pos_scores = scores[labels == 1]\n            neg_scores = scores[labels == 0]\n            \n            num_pos = len(pos_scores)\n            num_neg = len(neg_scores)\n            \n            if num_pos == 0 or num_neg == 0:\n                auc = 0.5 # Or undefined, per problem context this won't happen\n            else:\n                pairwise_wins = 0\n                for s_p in pos_scores:\n                    for s_n in neg_scores:\n                        if s_p > s_n:\n                            pairwise_wins += 1\n                        elif s_p == s_n:\n                            pairwise_wins += 0.5\n                auc = pairwise_wins / (num_pos * num_neg)\n\n            # --- Precision and Recall Calculation ---\n            probs = 1.0 / (1.0 + np.exp(-scores))\n            predictions = (probs >= prob_threshold).astype(int)\n            \n            true_positives = np.sum((predictions == 1)  (labels == 1))\n            false_positives = np.sum((predictions == 1)  (labels == 0))\n            false_negatives = np.sum((predictions == 0)  (labels == 1))\n            \n            num_predicted_pos = true_positives + false_positives\n            num_actual_pos = true_positives + false_negatives\n            \n            precision = true_positives / num_predicted_pos if num_predicted_pos > 0 else 0.0\n            recall = true_positives / num_actual_pos if num_actual_pos > 0 else 0.0\n            \n            metrics_by_alpha[alpha] = {\"auc\": auc, \"precision\": precision, \"recall\": recall}\n\n        # --- Perform Checks ---\n        baseline_metrics = metrics_by_alpha[1.0]\n        \n        # AUC Invariance Check\n        auc_0_5 = metrics_by_alpha[0.5][\"auc\"]\n        auc_2_0 = metrics_by_alpha[2.0][\"auc\"]\n        is_auc_invariant = (abs(auc_0_5 - baseline_metrics[\"auc\"]) = tolerance and\n                            abs(auc_2_0 - baseline_metrics[\"auc\"]) = tolerance)\n        \n        # Precision/Recall Sensitivity Check\n        pr_0_5 = (metrics_by_alpha[0.5][\"precision\"], metrics_by_alpha[0.5][\"recall\"])\n        pr_1_0 = (baseline_metrics[\"precision\"], baseline_metrics[\"recall\"])\n        pr_2_0 = (metrics_by_alpha[2.0][\"precision\"], metrics_by_alpha[2.0][\"recall\"])\n        \n        is_pr_sensitive = (pr_0_5 != pr_1_0) or (pr_2_0 != pr_1_0)\n\n        # --- Store Results ---\n        all_results.append(f\"{baseline_metrics['auc']:.6f}\")\n        all_results.append(str(is_auc_invariant).lower())\n        all_results.append(str(is_pr_sensitive).lower())\n        \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```", "id": "3167199"}, {"introduction": "虽然单个AUC值提供了模型的整体性能概览，但有时它可能会产生误导。在许多现实应用中，如医疗筛查或欺诈检测，模型在极低假正例率（$FPR$）下的表现远比其整体表现更为重要。本练习引入了“部分AUC”（partial AUC, pAUC）的概念，并要求您在一个两模型ROC曲线相交的场景下，通过pAUC进行模型比较，从而展示如何根据特定领域的需求做出更精细、更明智的决策。[@problem_id:3167178]", "problem": "给定两个二元分类器（例如，两个深度神经网络模型），它们为每个样本输出实值分数。根据第一性原理，受试者工作特征（ROC）曲线是通过改变分数上的决策阈值 $t$ 获得的一组点 $\\left(\\mathrm{FPR}(t), \\mathrm{TPR}(t)\\right)$，其中阈值 $t$ 处的假阳性率（FPR）和真阳性率（TPR）定义为\n$$\n\\mathrm{FPR}(t) \\equiv \\frac{\\mathrm{FP}(t)}{\\mathrm{FP}(t)+\\mathrm{TN}(t)}, \\quad\n\\mathrm{TPR}(t) \\equiv \\frac{\\mathrm{TP}(t)}{\\mathrm{TP}(t)+\\mathrm{FN}(t)}.\n$$\n这里，$\\mathrm{TP}(t)$、$\\mathrm{FP}(t)$、$\\mathrm{TN}(t)$ 和 $\\mathrm{FN}(t)$ 是在具有二元标签的数据集上，通过在阈值 $t$ 处对分数进行阈值化所产生的真阳性、假阳性、真阴性和假阴性的计数。曲线下面积（AUC）是在整个 $\\mathrm{FPR}\\in[0,1]$ 范围内，沿着 ROC 曲线对 $\\mathrm{TPR}$ 关于 $\\mathrm{FPR}$ 的积分。对于要求极低误报率的应用，一个相关的度量是在受限的假阳性率范围内的部分AUC，定义为\n$$\n\\mathrm{pAUC}(\\alpha) \\equiv \\int_{0}^{\\alpha} \\mathrm{TPR}(\\mathrm{FPR}) \\, d\\,\\mathrm{FPR},\n$$\n其中 $\\alpha \\in [0,1]$ 指定了允许的最大假阳性率。\n\n您的任务是根据这些定义实现一个算法，该算法能够：\n- 通过在排序后的分数上扫描阈值来计算 ROC 点。\n- 使用连续 ROC 点之间的分段线性插值和梯形法则，通过在区间 $[0,\\alpha]$ 上对 $\\mathrm{TPR}$ 关于 $\\mathrm{FPR}$ 进行积分来计算部分 AUC $\\mathrm{pAUC}(\\alpha)$。\n- 通过沿 ROC 曲线进行线性插值来计算在精确的 $\\mathrm{FPR}=\\alpha$ 处的 $\\mathrm{TPR}$；当 ROC 曲线有垂直段时（即 $\\mathrm{FPR}$ 不变而 $\\mathrm{TPR}$ 增加），将给定 $\\mathrm{FPR}$ 处的 $\\mathrm{TPR}$ 定义为在该 $\\mathrm{FPR}$ 达到的最大 $\\mathrm{TPR}$。\n- 通过以下确定性规则为低误报率应用选择更优的模型：优先选择具有较大 $\\mathrm{pAUC}(\\alpha)$ 的模型；如果在数值容差范围内 $\\mathrm{pAUC}(\\alpha)$ 值相等，则优先选择在 $\\mathrm{FPR}=\\alpha$ 处具有较大 $\\mathrm{TPR}$ 的模型；如果仍然相等，则优先选择具有较大完整 AUC 的模型；如果仍然相等，则选择模型 A。\n\n构建并评估以下参数值测试套件。每个测试用例指定二元标签向量和来自每个模型的按索引对齐的分数向量，后跟 $\\alpha$ 的值。所有值都是无单位的实数。\n\n- 测试用例 1（交叉的 ROC 曲线；低 $\\alpha$）：\n  - 标签 $y^{(1)}$: $[\\,1,\\,0,\\,0,\\,1,\\,0,\\,1,\\,0,\\,1,\\,0,\\,1,\\,0,\\,0,\\,1,\\,0,\\,0,\\,1,\\,0,\\,0,\\,1,\\,0\\,]$.\n  - 模型 A 分数 $s_A^{(1)}$: $[\\,0.98,\\,0.62,\\,0.61,\\,0.95,\\,0.59,\\,0.60,\\,0.57,\\,0.58,\\,0.55,\\,0.45,\\,0.50,\\,0.49,\\,0.42,\\,0.47,\\,0.43,\\,0.40,\\,0.41,\\,0.37,\\,0.38,\\,0.36\\,]$.\n  - 模型 B 分数 $s_B^{(1)}$: $[\\,0.80,\\,0.60,\\,0.82,\\,0.78,\\,0.58,\\,0.76,\\,0.56,\\,0.74,\\,0.54,\\,0.72,\\,0.52,\\,0.79,\\,0.70,\\,0.50,\\,0.48,\\,0.68,\\,0.46,\\,0.44,\\,0.66,\\,0.42\\,]$.\n  - $\\alpha^{(1)} = 0.10$.\n\n- 测试用例 2（相同数据；完整 AUC 比较）：\n  - 标签 $y^{(2)}$: 与 $y^{(1)}$ 相同。\n  - 模型 A 分数 $s_A^{(2)}$: 与 $s_A^{(1)}$ 相同。\n  - 模型 B 分数 $s_B^{(2)}$: 与 $s_B^{(1)}$ 相同。\n  - $\\alpha^{(2)} = 1.00$.\n\n- 测试用例 3（相同数据；零假阳性率边界）：\n  - 标签 $y^{(3)}$: 与 $y^{(1)}$ 相同。\n  - 模型 A 分数 $s_A^{(3)}$: 与 $s_A^{(1)}$ 相同。\n  - 模型 B 分数 $s_B^{(3)}$: 与 $s_B^{(1)}$ 相同。\n  - $\\alpha^{(3)} = 0.00$.\n\n- 测试用例 4（相同模型；平局决胜给模型 A）：\n  - 标签 $y^{(4)}$: $[\\,1,\\,0,\\,0,\\,0,\\,0,\\,1,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,1,\\,0,\\,0\\,]$.\n  - 模型 A 分数 $s_A^{(4)}$: $[\\,0.90,\\,0.80,\\,0.65,\\,0.55,\\,0.53,\\,0.70,\\,0.51,\\,0.49,\\,0.47,\\,0.45,\\,0.43,\\,0.41,\\,0.60,\\,0.39,\\,0.37\\,]$.\n  - 模型 B 分数 $s_B^{(4)}$: 与 $s_A^{(4)}$ 相同。\n  - $\\alpha^{(4)} = 0.20$.\n\n您的程序必须实现上述算法，不使用任何外部数据集或用户输入，并生成一行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。对于每个测试用例 $i \\in \\{1,2,3,4\\}$，输出一个整数，其中 $0$ 表示根据指定的决策规则首选模型 A，而 $1$ 表示首选模型 B，因此最终输出格式应精确为 $[\\,r_1, r_2, r_3, r_4\\,]$ 的形式，其中每个 $r_i \\in \\{0,1\\}$ 表示为整数。", "solution": "该问题要求实现一个算法，用于比较两个二元分类器——模型 A 和模型 B——在低误报率场景下的性能。比较基于部分受试者工作特征（ROC）曲线下面积，记作 $\\mathrm{pAUC}(\\alpha)$，其中 $\\alpha$ 是可接受的最大假阳性率（FPR）。解决方案涉及几个步骤：生成 ROC 曲线、计算完整和部分 AUC、确定特定 FPR 处的真阳性率（TPR），以及应用确定性决策规则。\n\n### 步骤 1：ROC 曲线生成\n\n受试者工作特征（ROC）曲线是在不同决策阈值下，真阳性率（$\\mathrm{TPR}$）对假阳性率（$\\mathrm{FPR}$）的绘图。$\\mathrm{TPR}$ 是被正确分类的正例的比例，而 $\\mathrm{FPR}$ 是被错误分类的负例的比例。\n$$\n\\mathrm{TPR}(t) = \\frac{\\mathrm{TP}(t)}{P}, \\quad \\mathrm{FPR}(t) = \\frac{\\mathrm{FP}(t)}{N}\n$$\n其中 $P$ 是正例总数，$N$ 是负例总数。$\\mathrm{TP}(t)$ 和 $\\mathrm{FP}(t)$ 是当分类器分数应用阈值 $t$ 时的真阳性和假阳性计数。\n\n一个生成 ROC 曲线点的高效算法如下：\n1.  将真实标签 $y \\in \\{0, 1\\}$ 和分类器分数 $s$ 组合成对。\n2.  根据分数按降序对这些对进行排序。使用稳定排序（如 `mergesort`）来一致地处理分数中的平局情况。\n3.  遍历排序后的列表，计算真阳性（$\\mathrm{TP}$）和假阳性（$\\mathrm{FP}$）的累积和。ROC 曲线的点对应于唯一的阈值，即唯一的分数值。\n4.  为了正确处理平局分数，我们识别出分数值发生变化的索引。这些索引标记了一组具有相同分数的样本的末尾，这些样本被作为一个单一的阈值步骤处理。在这些索引处的累积 $\\mathrm{TP}$ 和 $\\mathrm{FP}$ 计数给出了 ROC 曲线“拐角”的坐标。\n5.  将计数除以 $P$ 和 $N$ 进行归一化，得到 $\\mathrm{TPR}$ 和 $\\mathrm{FPR}$ 值。将点 $(0, 0)$ 前置到列表中，它代表一个高于任何分数的阈值（将所有样本分类为负例）。\n\n结果是一组代表 ROC 曲线的坐标 $(f_i, t_i)$。$f_i$ 值的数组是单调不减的。\n\n### 步骤 2：定义函数式 ROC 曲线\n\n问题指出，为了插值和积分，ROC 曲线应被视为一个函数 $\\mathrm{TPR}(\\mathrm{FPR})$。在曲线有垂直段的情况下（单个 $\\mathrm{FPR}$ 对应多个 $\\mathrm{TPR}$ 值），该 $\\mathrm{FPR}$ 处的 $\\mathrm{TPR}$ 定义为所达到的*最大* $\\mathrm{TPR}$。这创建了 ROC 曲线的上包络线。\n\n1.  从生成的 ROC 点序列 $(f_i, t_i)$ 中，我们识别出唯一的 $\\mathrm{FPR}$ 值集合，称之为 $f'_j$。\n2.  对于每个唯一的 $f'_j$，我们找到其对应的最大 $\\mathrm{TPR}$ 值：$t'_j = \\max \\{ t_i \\mid f_i = f'_j \\}$。\n3.  得到的点 $(f'_j, t'_j)$ 形成一个定义良好的函数 $\\mathrm{TPR} = g(\\mathrm{FPR})$，其中 $f'_j$ 值是严格递增的。这种表现良好的表示形式既适用于插值，也适用于数值积分。\n\n### 步骤 3：度量计算\n\n使用函数式 ROC 曲线表示 $(f'_j, t'_j)$，我们计算所需的度量：\n\n1.  **完整曲线下面积 (AUC):** 完整 AUC 是函数式 ROC 曲线从 $\\mathrm{FPR}=0$ 到 $\\mathrm{FPR}=1$ 的积分。这是使用梯形法则在点 $(f'_j, t'_j)$ 上计算的。\n    $$\n    \\mathrm{AUC} = \\int_{0}^{1} \\mathrm{TPR}(\\mathrm{FPR}) \\, d\\mathrm{FPR} \\approx \\sum_{j=1}^{m} \\frac{t'_{j-1} + t'_j}{2} (f'_j - f'_{j-1})\n    $$\n\n2.  **在 $\\mathrm{FPR}=\\alpha$ 处的 $\\mathrm{TPR}$:** 该值是通过在点 $\\mathrm{FPR}=\\alpha$ 处对函数式 ROC 曲线点 $(f'_j, t'_j)$ 进行线性插值找到的。\n\n3.  **部分 AUC ($\\mathrm{pAUC}(\\alpha)$):** 这是函数式 ROC 曲线从 $\\mathrm{FPR}=0$ 到 $\\mathrm{FPR}=\\alpha$ 的积分。\n    $$\n    \\mathrm{pAUC}(\\alpha) = \\int_{0}^{\\alpha} \\mathrm{TPR}(\\mathrm{FPR}) \\, d\\mathrm{FPR}\n    $$\n    为了计算这个值，我们选择点 $(f'_j, t'_j)$ 中 $f'_j \\le \\alpha$ 的子集。如果 $\\alpha$ 本身不是 $f'_j$ 值之一，我们将一个新点 $(\\alpha, \\mathrm{TPR}(\\alpha))$ 添加到这个子集中，其中 $\\mathrm{TPR}(\\alpha)$ 是通过线性插值获得的值。然后对这个点的子集应用梯形法则。\n\n### 步骤 4：确定性决策规则\n\n最后一步是根据以下分层规则选择更优的模型，在进行相等比较时使用一个小的数值容差（例如，$10^{-9}$）：\n1.  优先选择具有较大 $\\mathrm{pAUC}(\\alpha)$ 的模型。\n2.  如果 $\\mathrm{pAUC}(\\alpha)$ 值相等，则优先选择在 $\\mathrm{FPR} = \\alpha$ 处具有较大 $\\mathrm{TPR}$ 的模型。\n3.  如果这些也相等，则优先选择具有较大完整 AUC 的模型。\n4.  如果所有三个度量都相等，则默认选择模型 A 来打破平局。\n\n对每个测试用例实施这整个过程，以确定首选模型，为模型 A 输出 $0$，为模型 B 输出 $1$。", "answer": "```python\nimport numpy as np\n\ndef compute_metrics(y_true, y_scores, alpha):\n    \"\"\"\n    Computes Receiver Operating Characteristic (ROC) curve-based metrics from first principles.\n\n    This function calculates the partial Area Under the Curve (pAUC), the True Positive Rate (TPR)\n    at a specific False Positive Rate (FPR), and the full AUC.\n\n    The ROC curve is first generated by sorting scores and calculating cumulative TP/FP counts.\n    To satisfy the problem's requirements for interpolation and integration, a functional\n    representation of the curve (its upper envelope) is created, ensuring a unique TPR for each FPR.\n    Metrics are then calculated on this well-defined function.\n\n    Args:\n        y_true (list or np.ndarray): True binary labels (0 or 1).\n        y_scores (list or np.ndarray): Target scores from a classifier.\n        alpha (float): The maximum False Positive Rate for pAUC calculation.\n\n    Returns:\n        tuple: A tuple containing (pAUC, TPR_at_alpha, full_AUC). Returns (0.0, 0.0, 0.0)\n               if the data contains only one class.\n    \"\"\"\n    y_true = np.asarray(y_true, dtype=np.int32)\n    y_scores = np.asarray(y_scores, dtype=np.float64)\n\n    # Sort scores and corresponding truth values in descending order.\n    # 'mergesort' is a stable sort, which is important for reproducibility.\n    desc_score_indices = np.argsort(y_scores, kind=\"mergesort\")[::-1]\n    y_scores = y_scores[desc_score_indices]\n    y_true = y_true[desc_score_indices]\n\n    # Calculate cumulative true positives (TPs) and false positives (FPs).\n    tps_cum = np.cumsum(y_true)\n    fps_cum = np.cumsum(1 - y_true)\n    \n    # Get total positives (P) and negatives (N).\n    P = tps_cum[-1] if len(tps_cum) > 0 else 0\n    N = fps_cum[-1] if len(fps_cum) > 0 else 0\n\n    if P == 0 or N == 0:\n        # ROC is undefined for single-class data.\n        return 0.0, 0.0, 0.0\n\n    # Find the indices corresponding to unique thresholds. A new threshold step\n    # is taken for each unique score value.\n    distinct_value_indices = np.where(np.diff(y_scores))[0]\n    threshold_idxs = np.r_[distinct_value_indices, y_true.size - 1]\n\n    # Extract the (TP, FP) counts at each threshold step.\n    tps = tps_cum[threshold_idxs]\n    fps = fps_cum[threshold_idxs]\n\n    # Convert counts to rates and prepend the (0,0) origin point.\n    fpr_raw = fps / N\n    tpr_raw = tps / P\n    fpr = np.r_[0.0, fpr_raw]\n    tpr = np.r_[0.0, tpr_raw]\n\n    # The problem defines TPR at a given FPR as the maximum TPR achieved.\n    # This forms the upper envelope of the ROC curve, making it a well-defined function.\n    # This also ensures the `fpr_u` array is strictly increasing for interpolation.\n    fpr_u = np.unique(fpr)\n    tpr_u = np.array([tpr[fpr == f].max() for f in fpr_u])\n\n    # 1. Calculate full AUC using the trapezoidal rule on the functional curve.\n    full_auc = np.trapz(tpr_u, fpr_u)\n    \n    # 2. Calculate TPR at FPR=alpha via linear interpolation on the functional curve.\n    tpr_at_alpha = np.interp(alpha, fpr_u, tpr_u)\n\n    # 3. Calculate partial AUC up to alpha.\n    pauc = 0.0\n    if alpha > 0.0:\n        # Select the part of the functional curve up to the FPR limit `alpha`.\n        fpr_pauc = fpr_u[fpr_u = alpha]\n        tpr_pauc = tpr_u[fpr_u = alpha]\n        \n        # If alpha is not one of the existing FPR points, add it via interpolation\n        # to correctly calculate the area of the final trapezoid.\n        if not np.isclose(fpr_pauc[-1], alpha):\n            fpr_pauc = np.append(fpr_pauc, alpha)\n            tpr_pauc = np.append(tpr_pauc, tpr_at_alpha)\n\n        pauc = np.trapz(tpr_pauc, fpr_pauc)\n        \n    return pauc, tpr_at_alpha, full_auc\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and determine the preferred model for each case.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1\n        {\n            \"y\": [1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0],\n            \"s_A\": [0.98, 0.62, 0.61, 0.95, 0.59, 0.60, 0.57, 0.58, 0.55, 0.45, 0.50, 0.49, 0.42, 0.47, 0.43, 0.40, 0.41, 0.37, 0.38, 0.36],\n            \"s_B\": [0.80, 0.60, 0.82, 0.78, 0.58, 0.76, 0.56, 0.74, 0.54, 0.72, 0.52, 0.79, 0.70, 0.50, 0.48, 0.68, 0.46, 0.44, 0.66, 0.42],\n            \"alpha\": 0.10\n        },\n        # Test case 2\n        {\n            \"y\": [1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0],\n            \"s_A\": [0.98, 0.62, 0.61, 0.95, 0.59, 0.60, 0.57, 0.58, 0.55, 0.45, 0.50, 0.49, 0.42, 0.47, 0.43, 0.40, 0.41, 0.37, 0.38, 0.36],\n            \"s_B\": [0.80, 0.60, 0.82, 0.78, 0.58, 0.76, 0.56, 0.74, 0.54, 0.72, 0.52, 0.79, 0.70, 0.50, 0.48, 0.68, 0.46, 0.44, 0.66, 0.42],\n            \"alpha\": 1.00\n        },\n        # Test case 3\n        {\n            \"y\": [1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0],\n            \"s_A\": [0.98, 0.62, 0.61, 0.95, 0.59, 0.60, 0.57, 0.58, 0.55, 0.45, 0.50, 0.49, 0.42, 0.47, 0.43, 0.40, 0.41, 0.37, 0.38, 0.36],\n            \"s_B\": [0.80, 0.60, 0.82, 0.78, 0.58, 0.76, 0.56, 0.74, 0.54, 0.72, 0.52, 0.79, 0.70, 0.50, 0.48, 0.68, 0.46, 0.44, 0.66, 0.42],\n            \"alpha\": 0.00\n        },\n        # Test case 4\n        {\n            \"y\": [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n            \"s_A\": [0.90, 0.80, 0.65, 0.55, 0.53, 0.70, 0.51, 0.49, 0.47, 0.45, 0.43, 0.41, 0.60, 0.39, 0.37],\n            \"s_B\": [0.90, 0.80, 0.65, 0.55, 0.53, 0.70, 0.51, 0.49, 0.47, 0.45, 0.43, 0.41, 0.60, 0.39, 0.37],\n            \"alpha\": 0.20\n        },\n    ]\n\n    results = []\n    TOLERANCE = 1e-9\n\n    for case in test_cases:\n        y, s_A, s_B, alpha = case[\"y\"], case[\"s_A\"], case[\"s_B\"], case[\"alpha\"]\n        \n        pauc_A, tpr_A, auc_A = compute_metrics(y, s_A, alpha)\n        pauc_B, tpr_B, auc_B = compute_metrics(y, s_B, alpha)\n\n        # Apply the deterministic decision rule with tie-breaking logic.\n        # Prefer the model with the larger pAUC(alpha).\n        if pauc_A - pauc_B > TOLERANCE:\n            results.append(0)  # Model A is better\n        elif pauc_B - pauc_A > TOLERANCE:\n            results.append(1)  # Model B is better\n        # If pAUCs are equal, tie-break with TPR at alpha.\n        elif tpr_A - tpr_B > TOLERANCE:\n            results.append(0)\n        elif tpr_B - tpr_A > TOLERANCE:\n            results.append(1)\n        # If TPRs are equal, tie-break with full AUC.\n        elif auc_A - auc_B > TOLERANCE:\n            results.append(0)\n        elif auc_B - auc_A > TOLERANCE:\n            results.append(1)\n        # If all are equal, choose Model A by default.\n        else:\n            results.append(0)\n            \n    # Format and print the final output as specified.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3167178"}]}