{"hands_on_practices": [{"introduction": "本练习将探讨维护数据集“卫生”的关键步骤：检测训练集、验证集和测试集之间的近似重复项。通过一个基于感知哈希的概率模型，你将量化在设定检测阈值时，假阳性（False Positives）与假阴性（False Negatives）之间的权衡。这项技能至关重要，可以确保你的模型评估结果不会因为“记忆”了与训练数据几乎相同的测试样本而被人为地夸大。[@problem_id:3194863]", "problem": "您的任务是为用于深度学习的数据集，形式化用于确保划分纯净性的近似重复检测。假设每个样本（例如，一张图片）被一个长度固定为 $L$ 位的感知哈希所概括。对于跨不同划分（训练集、验证集、测试集）的任意一对样本，将汉明距离 $D$ 定义为两个哈希值在二进制位上不同的位置数量。当且仅当 $D \\leq T$ 时，重复检测器将一对样本声明为重复项，其中 $T$ 是一个整数阈值。\n\n假设使用以下经过充分测试的随机模型。对于两个内容确实相同（真实重复对）并由哈希管线独立处理的样本，两个哈希值之间的每一位都以概率 $p_d$ 独立地翻转，因此真实重复对的汉明距离 $D$ 服从参数为 $L$ 和 $p_d$ 的二项分布。对于两个内容确实不同（非重复对）的样本，每一位都以概率 $p_n$ 独立地不同，因此非重复对的汉明距离 $D$ 服从参数为 $L$ 和 $p_n$ 的二项分布。这些独立性和二项分布的假设是用于建模感知哈希噪声和碰撞行为的标准方法。\n\n您的目标是：\n- 基于上述基本定义，推导出假阳性率和假阴性率的表达式，这些表达式是 $L$、$T$、$p_d$ 和 $p_n$ 的函数。\n- 使用这些表达式计算当检测器在已知真实标签的特定数量的跨划分数据对上进行评估时，假阳性和假阴性的期望数量。\n\n使用的定义：\n- 假阳性率是指一个非重复对被错误地声明为重复的概率。使用二项模型，这是在参数为 $L$ 和 $p_n$ 的非重复分布条件下，$D \\leq T$ 的概率。\n- 假阴性率是指一个真实重复对被错误地声明为非重复的概率。使用二项模型，这是在参数为 $L$ 和 $p_d$ 的重复分布条件下，$D > T$ 的概率。\n- 如果有 $N_{\\text{non}}$ 个非重复的跨划分数据对和 $N_{\\text{dup}}$ 个重复的跨划分数据对，那么假阳性的期望数量是假阳性率乘以 $N_{\\text{non}}$，假阴性的期望数量是假阴性率乘以 $N_{\\text{dup}}$。\n\n您的程序必须使用精确的二项累积分布值（而非模拟）来实现这些计算，以应对以下测试套件。每个测试用例指定了 $(L, p_d, p_n, T, N_{\\text{dup}}, N_{\\text{non}})$：\n\n- Case A (典型设置): $L = 64$, $p_d = 0.06$, $p_n = 0.50$, $T = 10$, $N_{\\text{dup}} = 1000$, $N_{\\text{non}} = 200000$。\n- Case B (极严阈值): $L = 64$, $p_d = 0.06$, $p_n = 0.50$, $T = 0$, $N_{\\text{dup}} = 1000$, $N_{\\text{non}} = 200000$。\n- Case C (极松阈值): $L = 64$, $p_d = 0.06$, $p_n = 0.50$, $T = 64$, $N_{\\text{dup}} = 1000$, $N_{\\text{non}} = 200000$。\n- Case D (重叠分布): $L = 32$, $p_d = 0.22$, $p_n = 0.35$, $T = 12$, $N_{\\text{dup}} = 10000$, $N_{\\text{non}} = 50000$。\n- Case E (短哈希): $L = 8$, $p_d = 0.10$, $p_n = 0.30$, $T = 2$, $N_{\\text{dup}} = 100$, $N_{\\text{non}} = 1000$。\n\n量化输出：\n- 对于每个测试用例, 计算四个量：假阳性率（$[0,1]$ 内的小数）、假阴性率（$[0,1]$ 内的小数）、假阳性的期望数量（实数）以及假阴性的期望数量（实数）。所有四个值都必须四舍五入到六位小数。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。列表中的每个元素对应一个测试用例，其本身是一个形如 $[ \\text{FPR}, \\text{FNR}, \\text{EFP}, \\text{EFN} ]$ 的列表。例如，一个有效的输出看起来像这样：$[[0.001000,0.100000,123.456000,78.900000],[\\dots]]$，不含空格。不要打印任何其他内容。", "solution": "该问题要求推导和计算基于感知哈希比较的重复检测器的性能指标。问题的核心在于应用二项分布来建模哈希值之间的汉明距离。我们将首先形式化随机变量，然后推导假阳性率和假阴性率的表达式，最后概述期望数量的计算方法。\n\n设感知哈希的长度为 $L$。对于任意一对哈希，汉明距离 $D$ 是指不同的比特位数。检测规则是：当且仅当 $D \\leq T$（其中 $T$ 为给定的整数阈值）时，一对哈希被标记为重复。\n\n问题为汉明距离定义了两个不同的随机模型，这取决于一对项目代表的是真正相同的内容（真实重复）还是不同的内容（非重复）。\n\n设 $X_{nd}$ 为非重复项的两个哈希值之间的汉明距离 $D$ 的随机变量。问题指出，$X_{nd}$ 服从参数为 $L$ 和 $p_n$ 的二项分布。我们将其表示为：\n$$\nX_{nd} \\sim B(L, p_n)\n$$\n其概率质量函数（PMF）由 $P(X_{nd} = k) = \\binom{L}{k} p_n^k (1-p_n)^{L-k}$ 给出，其中 $k \\in \\{0, 1, \\dots, L\\}$。\n\n设 $X_{d}$ 为真实重复对的两个哈希值之间的汉明距离 $D$ 的随机变量。问题指出，$X_{d}$ 服从参数为 $L$ 和 $p_d$ 的二项分布。我们将其表示为：\n$$\nX_{d} \\sim B(L, p_d)\n$$\n其概率质量函数（PMF）由 $P(X_{d} = k) = \\binom{L}{k} p_d^k (1-p_d)^{L-k}$ 给出，其中 $k \\in \\{0, 1, \\dots, L\\}$。\n\n有了这些定义，我们就可以推导出所需的指标。\n\n**假阳性率 (FPR)**\n当一个非重复对被错误地分类为重复时，就会发生假阳性。这种情况发生在非重复对的汉明距离 $X_{nd}$ 满足条件 $X_{nd} \\leq T$ 时。\n假阳性率是此事件的概率：\n$$\n\\text{FPR} = P(X_{nd} \\leq T)\n$$\n这个概率对应于二项分布 $B(L, p_n)$ 在阈值 $T$ 处的累积分布函数（CDF）。在数学上，它是从 $0$ 到 $T$ 所有结果的概率之和：\n$$\n\\text{FPR} = \\sum_{k=0}^{T} P(X_{nd} = k) = \\sum_{k=0}^{T} \\binom{L}{k} p_n^k (1-p_n)^{L-k}\n$$\n\n**假阴性率 (FNR)**\n当一个真实重复对被错误地分类为非重复时，就会发生假阴性。这种情况发生在真实重复对的汉明距离 $X_{d}$ 未满足检测条件，即 $X_{d} > T$ 时。\n假阴性率是此事件的概率：\n$$\n\\text{FNR} = P(X_{d} > T)\n$$\n这个概率是二项分布 $B(L, p_d)$ 在 $T$ 处的生存函数（或互补累积分布函数）。它可以通过对所有大于 $T$ 的结果的概率求和来计算：\n$$\n\\text{FNR} = \\sum_{k=T+1}^{L} P(X_{d} = k) = \\sum_{k=T+1}^{L} \\binom{L}{k} p_d^k (1-p_d)^{L-k}\n$$\n或者，它可以计算为 $1$ 减去累积分布函数（CDF）：\n$$\n\\text{FNR} = 1 - P(X_{d} \\leq T) = 1 - \\sum_{k=0}^{T} \\binom{L}{k} p_d^k (1-p_d)^{L-k}\n$$\n\n**期望数量**\n给定一个包含 $N_{\\text{non}}$ 个非重复对和 $N_{\\text{dup}}$ 个真实重复对的集合，可以计算出错误分类的期望数量。\n假阳性的期望数量 (EFP) 是非重复对的数量与任意单个对成为假阳性的概率的乘积：\n$$\nE[\\text{FP}] = N_{\\text{non}} \\times \\text{FPR}\n$$\n同样，假阴性的期望数量 (EFN) 是真实重复对的数量与任意单个对成为假阴性的概率的乘积：\n$$\nE[\\text{FN}] = N_{\\text{dup}} \\times \\text{FNR}\n$$\n\n每个测试用例 $(L, p_d, p_n, T, N_{\\text{dup}}, N_{\\text{non}})$ 的计算过程如下：\n1.  使用 $B(L, p_n)$ 的CDF计算 $\\text{FPR} = \\sum_{k=0}^{T} \\binom{L}{k} p_n^k (1-p_n)^{L-k}$。\n2.  使用 $B(L, p_d)$ 的CDF计算 $\\text{FNR} = 1 - \\sum_{k=0}^{T} \\binom{L}{k} p_d^k (1-p_d)^{L-k}$，或直接使用生存函数。\n3.  计算 $E[\\text{FP}] = N_{\\text{non}} \\times \\text{FPR}$。\n4.  计算 $E[\\text{FN}] = N_{\\text{dup}} \\times \\text{FNR}$。\n5.  将所有四个结果四舍五入到六位小数。\n\n对五个指定的测试用例中的每一个都执行这些计算。该实现将利用提供二项CDF和生存函数精确函数的数值库，以避免手动求和并确保数值稳定性。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import binom\n\ndef solve():\n    \"\"\"\n    Computes false positive/negative rates and expected counts for duplicate detection\n    based on a binomial model of Hamming distances.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each test case is a tuple: (L, p_d, p_n, T, N_dup, N_non)\n    test_cases = [\n        (64, 0.06, 0.50, 10, 1000, 200000),  # Case A\n        (64, 0.06, 0.50, 0, 1000, 200000),   # Case B\n        (64, 0.06, 0.50, 64, 1000, 200000),  # Case C\n        (32, 0.22, 0.35, 12, 10000, 50000),  # Case D\n        (8, 0.10, 0.30, 2, 100, 1000),       # Case E\n    ]\n\n    # results will store the string representation of each sub-list, e.g., \"[0.1,0.2,...]\"\n    # This is done to achieve the exact output format with no spaces.\n    results = []\n    for case in test_cases:\n        L, p_d, p_n, T, N_dup, N_non = case\n\n        # False Positive Rate (FPR): P(D = T) for non-duplicates (D ~ B(L, p_n))\n        fpr = binom.cdf(T, L, p_n)\n\n        # False Negative Rate (FNR): P(D > T) for true duplicates (D ~ B(L, p_d))\n        # scipy.stats.binom.sf (survival function) computes P(X > k) directly.\n        fnr = binom.sf(T, L, p_d)\n        \n        # Expected False Positives (EFP)\n        efp = fpr * N_non\n\n        # Expected False Negatives (EFN)\n        efn = fnr * N_dup\n        \n        # Create the string for the inner list with specific formatting and no spaces,\n        # ensuring each number is rounded to six decimal places.\n        result_str = (\n            f\"[{f'{fpr:.6f}'},\"\n            f\"{f'{fnr:.6f}'},\"\n            f\"{f'{efp:.6f}'},\"\n            f\"{f'{efn:.6f}'}]\"\n        )\n        results.append(result_str)\n\n    # Final print statement in the exact required format: [[...],[...],...]\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3194863"}, {"introduction": "数据泄漏的发生方式可能非常微妙，远不止简单的重复图像。本练习将展示依赖于数据的预处理步骤（例如自然语言处理中的子词切分）如何在不经意间将测试集的信息引入训练流程。通过实现一个简化的字节对编码（BPE）算法，你将直接观察并量化在一个联合数据集上拟合分词器如何导致对罕见测试短语的“记忆”，并理解为何“冻结”词汇表是一种更稳健的方法。[@problem_id:3194860]", "problem": "本题要求你通过计算来演示，在朴素训练的情况下，一个依赖于数据的子词词汇表如何导致测试集的信息泄露到模型中，以及冻结词汇表如何缓解这种效应。你将在自然语言处理 (NLP) 的背景下进行操作，其中文本被分词为由无监督算法（如字节对编码 BPE）学习到的子词单元。你将实现一个简化的 BPE 过程，并针对指定的测试用例计算一个对泄露敏感的度量指标。\n\n基本基础与假设：\n- 分词被视为一个由已拟合的子词词汇表导出的确定性预处理函数 $ \\tau $。当测试集未用于拟合流水线中任何影响所学模型的组件（包括 $ \\tau $）时，将数据集划分为训练集、验证集和测试集是有效的。\n- 数据泄露是指任何从测试集到训练流水线的信息流动。在包含测试部分的整个数据集上拟合的分词器违反了训练和测试之间的独立性假设，并可能降低测试集中罕见短语的表观复杂度（例如，词元长度）。\n- 字节对编码 (BPE) 是一种无监督过程，它从字符级分词开始，并重复合并整个语料库中最频繁的相邻词元对。经过 $ M $ 次合并后，所学到的合并列表通过按顺序重复应用所学到的合并规则，来决定任何输入字符串如何被分割成子词。\n\n你的任务：\n1) 按如下方式实现一个简化的 BPE，不带词尾符号和接续标记：\n   - 从分割为字符的单词开始。对于一个表示为带有整数频率的单词多重集的语料库，计算每个相邻符号对的频率，并按词频加权。\n   - 在每个合并步骤中，选择全局最频繁的相邻对，并将其在所有单词中合并为单个符号。通过选择字典序最小的（作为字符串元组的）对来确定性地解决平局问题。重复 $ M $ 步或直到没有更多可合并的对为止。\n   - 要使用学到的合并规则对单词进行编码，从其字符序列开始，并按学到的顺序应用合并规则，贪婪地替换当前合并对的出现，直到没有更多出现为止，然后继续进行下一次合并。\n\n2) 两种机制：\n   - 泄露机制 (Leaky regime)：在来自训练句和测试句的组合单词多重集上拟合 BPE 合并规则。\n   - 冻结机制 (Frozen regime)：仅使用训练句拟合 BPE 合并规则，然后保持合并列表固定（即，不要用来自测试句的任何信息重新拟合或扩展它）。\n\n3) 对于下述每个测试用例，为一组罕见的目标短语计算以下度量指标：\n   - 设 $ T_{\\text{leaky}} $ 为泄露机制下每个目标短语的平均词元数，设 $ T_{\\text{frozen}} $ 为冻结机制下每个目标短语的平均词元数。定义泄露增益\n     $$ g \\;=\\; \\frac{T_{\\text{frozen}} - T_{\\text{leaky}}}{T_{\\text{frozen}}}. $$\n     将 $ g $ 报告为四舍五入到 $ 3 $ 位小数的小数。\n   - 定义指示变量 $ I_{\\text{leaky}} $ 和 $ I_{\\text{frozen}} $，如果在相应机制下至少有一个目标短语被编码为单个词元，则其值为 $ 1 $，否则为 $ 0 $。\n\n4) 输出格式：\n   - 你的程序应产生单行输出，其中包含一个结果列表，每个测试用例一个结果，每个结果本身是一个列表 $ [g, I_{\\text{leaky}}, I_{\\text{frozen}}] $，其中 $ g $ 四舍五入到 $ 3 $ 位小数，指示变量为整数 $ 0 $ 或 $ 1 $。\n   - 最终输出必须是形如\n     $$ [ [g_1,I_{\\text{leaky},1},I_{\\text{frozen},1}], [g_2,I_{\\text{leaky},2},I_{\\text{frozen},2}], \\ldots ] $$\n     的单行，不含额外文本。\n\n测试套件：\n从句子模板和重复次数构建语料库。每个句子按空格分割成单词。对于每种情况，训练语料库是训练句重复 $ r_{\\text{train}} $ 次，测试语料库是测试句重复 $ r_{\\text{test}} $ 次。\n\n- 情况 A (理想路径：泄露增加了对罕见测试短语的子词记忆)：\n  - 训练句：\"alpha beta gamma delta epsilon\"\n  - 测试句：\"quantumflux\"\n  - 重复次数：$ r_{\\text{train}} = 5 $, $ r_{\\text{test}} = 20 $\n  - 目标短语：[\"quantumflux\"]\n  - 合并次数：$ M = 10 $\n\n- 情况 B (边界情况：零次合并消除了泄露效应)：\n  - 训练句：\"abc def\"\n  - 测试句：\"ghij\"\n  - 重复次数：$ r_{\\text{train}} = 5 $, $ r_{\\text{test}} = 10 $\n  - 目标短语：[\"ghij\"]\n  - 合并次数：$ M = 0 $\n\n- 情况 C (边缘情况：严重泄露可将罕见测试短语压缩为单个词元)：\n  - 训练句：\"alpha beta gamma\"\n  - 测试句：\"quantumflux\"\n  - 重复次数：$ r_{\\text{train}} = 5 $, $ r_{\\text{test}} = 100 $\n  - 目标短语：[\"quantumflux\"]\n  - 合并次数：$ M = 12 $\n\n答案规范：\n- 所有输出都是无量纲的，并且必须以小数或整数报告。不要使用百分号。\n- 你的程序应精确地产生一行，其中包含一个列表，其元素是 A、B 和 C 三种情况的三元组 $ [g,I_{\\text{leaky}},I_{\\text{frozen}}] $，按此顺序排列，其中 $ g $ 四舍五入到 3 位小数，且打印的列表中没有空格。", "solution": "用户的要求是演示自然语言处理 (NLP) 流水线中的一种数据泄露形式，即在训练和测试数据的组合上拟合的分词器可以人为地提高测试集上的性能指标。这一现象将通过实现一个简化的字节对编码 (BPE) 算法，并比较其在两种不同机制下的行为来加以说明：一种是“泄露”机制，其中 BPE 词汇表从训练和测试语料库的组合中学习；另一种是“冻结”机制，其中词汇表仅从训练语料库中学习。该问题在科学上是有效的、定义明确的，并且所有术语和过程都为计算解决方案定义了足够的严谨性。\n\n解决方案首先按规定实现必要的组件：\n1.  一个函数，用于从输入句子和重复次数构建语料库，表示为单词及其频率的多重集（或字典）。\n2.  一个 BPE 拟合函数 `fit_bpe`，用于学习子词合并的词汇表。\n3.  一个 BPE 编码函数 `encode_word`，用于在给定已学习词汇表的情况下对单词进行分词。\n4.  一个主程序，用于通过两种机制处理每个测试用例并计算所需的度量指标。\n\n**BPE 拟合过程 (`fit_bpe`)**\n\n`fit_bpe` 函数接收一个语料库（一个将单词映射到其频率的字典）和合并次数 $M$作为输入。\n1.  **初始化**：语料库在内部通过将每个单词分割为其构成字符来表示。例如，频率为 $5$ 的单词 \"alpha\" 最初表示为与频率 $5$ 相关联的词元序列 `('a', 'l', 'p', 'h', 'a')`。\n2.  **迭代合并**：算法迭代 $M$ 次，或直到没有更多可行的合并。在每一步中：\n    a.  **词元对频率计算**：它计算整个语料库中所有相邻词元对的频率，并按它们出现的单词的频率进行加权。\n    b.  **最佳词元对选择**：它识别出最频繁的词元对。通过选择字典序最小的对来解决平局问题，其中词元对作为字符串元组进行比较（例如，`('a', 'b')` 在 `('a', 'c')` 之前）。\n    c.  **词汇表更新**：将最佳对，例如 $(s_1, s_2)$，记录为一条新的合并规则。\n    d.  **语料库更新**：在分词后的语料库表示中，所有相邻序列 `$s_1 s_2$` 的出现都被一个新的单个词元 `$s_1s_2$` 替换。这个更新后的表示用于下一次迭代。\n3.  **输出**：该函数返回一个包含 $M$ 个已学习合并规则的有序列表。\n\n**BPE 编码过程 (`encode_word`)**\n\n`encode_word` 函数接收一个单词字符串和一个有序的合并规则列表，以生成一个子词词元序列。\n1.  **初始化**：输入的单词首先被分割成一个字符序列。\n2.  **应用合并**：函数按学习顺序遍历合并规则。对于每个规则 $(s_1, s_2)$：\n    a.  算法重复扫描当前词元序列，以查找相邻对 $(s_1, s_2)$ 的首次出现。\n    b.  找到一次出现后，它被合并后的词元 $s_1s_2$ 替换。然后从修改后的词元序列的开头重新开始扫描。\n    c.  此过程持续进行，直到在序列中再也找不到该对 $(s_1, s_2)$ 的出现为止。\n    d.  然后算法继续处理列表中的下一个合并规则。\n3.  **输出**：返回单词的最终词元序列。此序列的长度即为词元数。\n\n**度量指标计算**\n\n对于每个测试用例，都针对冻结和泄露两种机制进行分析：\n-   **冻结机制**：仅在训练语料库上使用 `fit_bpe` 学习 BPE 合并规则。然后使用这些合并规则对目标短语进行编码，得到每个短语的平均词元数 $T_{\\text{frozen}}$。\n-   **泄露机制**：从结合了训练和测试数据的语料库中学习 BPE 合并规则。使用这些合并规则对目标短语进行编码，得到平均词元数 $T_{\\text{leaky}}$。\n\n然后计算泄露增益 $g$，公式为 $g = (T_{\\text{frozen}} - T_{\\text{leaky}}) / T_{\\text{frozen}}$。$g$ 的正值表明，在分词器拟合过程中包含测试数据导致了目标短语的更压缩（更短）的分词结果，这是信息泄露的直接后果。如果任何目标短语在各自的机制下被分词为单个词元，则指示变量 $I_{\\text{leaky}}$ 和 $I_{\\text{frozen}}$ 设置为 $1$，否则为 $0$。这捕捉了极端泄露的情况，即一个罕见的单词在词汇表中被记忆为单个单元。\n\n然后将所有测试用例的结果聚合并格式化为指定的列表的列表结构。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport collections\n\ndef get_pair_freqs(word_segs: dict[str, int]) -> collections.Counter:\n    \"\"\"\n    Calculates the frequency of adjacent token pairs in a segmented corpus representation.\n    The corpus representation is a dictionary mapping a space-separated token string to its frequency.\n    \"\"\"\n    pair_freqs = collections.Counter()\n    for seg_word, freq in word_segs.items():\n        tokens = seg_word.split(' ')\n        if len(tokens)  2:\n            continue\n        for i in range(len(tokens) - 1):\n            pair = (tokens[i], tokens[i+1])\n            pair_freqs[pair] += freq\n    return pair_freqs\n\ndef fit_bpe(corpus: dict[str, int], M: int) -> list[tuple[str, str]]:\n    \"\"\"\n    Fits a simplified BPE model by learning M merge operations from a corpus.\n    \n    Args:\n        corpus: A dictionary mapping words to their frequencies.\n        M: The number of merges to perform.\n\n    Returns:\n        An ordered list of M merge rules, where each rule is a tuple of strings.\n    \"\"\"\n    if M == 0:\n        return []\n    \n    # Initialize the corpus representation with character-level tokenization.\n    word_segs = {' '.join(word): freq for word, freq in corpus.items() if word}\n    \n    merges = []\n    for _ in range(M):\n        pair_freqs = get_pair_freqs(word_segs)\n        if not pair_freqs:\n            break\n        \n        # Find the best pair: highest frequency, with lexicographical tie-breaking.\n        max_freq = max(pair_freqs.values())\n        # Filter pairs with max frequency and sort them to find the lexicographically smallest.\n        candidate_pairs = sorted([p for p, f in pair_freqs.items() if f == max_freq])\n        best_pair = candidate_pairs[0]\n        \n        merges.append(best_pair)\n        \n        # Apply the merge to the entire corpus representation for the next iteration.\n        p1, p2 = best_pair\n        merged_token = p1 + p2\n        \n        new_word_segs = {}\n        for seg_word, freq in word_segs.items():\n            # Using string replacement on the space-separated representation.\n            new_seg_word = seg_word.replace(f'{p1} {p2}', merged_token)\n            new_word_segs[new_seg_word] = freq\n        word_segs = new_word_segs\n        \n    return merges\n\ndef encode_word(word: str, merges: list[tuple[str, str]]) -> list[str]:\n    \"\"\"\n    Encodes a word into subword tokens using a pre-computed list of BPE merges.\n    \n    Args:\n        word: The string to encode.\n        merges: An ordered list of BPE merge rules.\n\n    Returns:\n        A list of subword tokens.\n    \"\"\"\n    if not word:\n        return []\n        \n    tokens = list(word)\n    \n    for p1, p2 in merges:\n        merged_token = p1 + p2\n        while True:\n            # Repeatedly find the first occurrence of the pair and merge it.\n            # The scan restarts after each merge until no more merges for this rule are possible.\n            first_occurrence_idx = -1\n            for i in range(len(tokens) - 1):\n                if tokens[i] == p1 and tokens[i+1] == p2:\n                    first_occurrence_idx = i\n                    break\n            \n            if first_occurrence_idx != -1:\n                i = first_occurrence_idx\n                tokens = tokens[:i] + [merged_token] + tokens[i+2:]\n            else:\n                break # No more occurrences of this pair, move to the next merge rule.\n    return tokens\n\ndef process_case(train_sent: str, test_sent: str, r_train: int, r_test: int, targets: list[str], M: int) -> list:\n    \"\"\"\n    Processes a single test case, calculating metrics for leaky and frozen regimes.\n    \"\"\"\n    # Create corpora from sentence templates and repetitions\n    train_corpus = collections.Counter(train_sent.split(' '))\n    for word in list(train_corpus): train_corpus[word] *= r_train\n    \n    test_corpus = collections.Counter(test_sent.split(' '))\n    for word in list(test_corpus): test_corpus[word] *= r_test\n\n    # --- Frozen Regime ---\n    # Fit BPE on the training data only\n    frozen_merges = fit_bpe(dict(train_corpus), M)\n    # Encode target phrases and calculate metrics\n    frozen_token_counts = [len(encode_word(phrase, frozen_merges)) for phrase in targets]\n    T_frozen = np.mean(frozen_token_counts)\n    I_frozen = 1 if any(c == 1 for c in frozen_token_counts) else 0\n\n    # --- Leaky Regime ---\n    # Fit BPE on the combined training and test data\n    combined_corpus = train_corpus + test_corpus\n    leaky_merges = fit_bpe(dict(combined_corpus), M)\n    # Encode target phrases and calculate metrics\n    leaky_token_counts = [len(encode_word(phrase, leaky_merges)) for phrase in targets]\n    T_leaky = np.mean(leaky_token_counts)\n    I_leaky = 1 if any(c == 1 for c in leaky_token_counts) else 0\n\n    # Calculate final leakage gain metric\n    if T_frozen == 0:\n        g = 0.0 # Avoid division by zero\n    else:\n        g = (T_frozen - T_leaky) / T_frozen\n\n    return [g, I_leaky, I_frozen]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"train_sent\": \"alpha beta gamma delta epsilon\", \"test_sent\": \"quantumflux\",\n            \"r_train\": 5, \"r_test\": 20, \"targets\": [\"quantumflux\"], \"M\": 10\n        },\n        {\n            \"train_sent\": \"abc def\", \"test_sent\": \"ghij\",\n            \"r_train\": 5, \"r_test\": 10, \"targets\": [\"ghij\"], \"M\": 0\n        },\n        {\n            \"train_sent\": \"alpha beta gamma\", \"test_sent\": \"quantumflux\",\n            \"r_train\": 5, \"r_test\": 100, \"targets\": [\"quantumflux\"], \"M\": 12\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        # Main logic to calculate the result for one case goes here.\n        g, i_leaky, i_frozen = process_case(**case)\n        \n        # Format the result as a string '[g,I_leaky,I_frozen]' with no spaces.\n        # g is rounded to 3 decimal places implicitly by the format specifier.\n        result_str = f\"[{g:.3f},{i_leaky},{i_frozen}]\"\n        results.append(result_str)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3194860"}, {"introduction": "在确保数据集划分的“纯洁性”之后，验证集就成了一个强大的工具，可用于调整模型以满足超越简单准确率的特定现实世界目标。本练习聚焦于成本敏感分类问题，在这种场景下，不同类型错误所带来的后果是不对等的。你将学习如何在验证集上选择一个最优决策阈值以最小化特定的成本函数，并探索如何构建一个能够应对测试时真实成本不确定性的稳健阈值。[@problem_id:3194809]", "problem": "给定一个二元分类器，它在一个验证数据集和一个测试数据集上都输出了正类的校准后验概率。目标是在验证数据集上选择一个决策阈值，以在给定的验证成本下最小化经验期望成本，分析当测试成本不同时产生的不匹配，并使用极小化极大标准构建一个鲁棒阈值以对冲测试成本比率的不确定性。\n\n基本原理：使用标准的经验风险（期望成本）框架和贝叶斯决策规则。对于概率为 $p$ 的实例，如果 $p \\ge t$，则预测为正类，否则为负类。在一个大小为 $n$ 的数据集 $D$ 上，给定假正类成本 $C_{\\mathrm{FP}}$ 和假负类成本 $C_{\\mathrm{FN}}$，其经验期望成本由假正率和假负率构建。设 $\\hat{y}_i(t)$ 表示对于第 $i$ 个实例，在阈值 $t$ 下的预测，该实例的标签为 $y_i \\in \\{0,1\\}$，预测概率为 $p_i$。定义经验假正率为\n$$\n\\mathrm{FP\\_rate}(t) = \\frac{1}{n}\\sum_{i=1}^n \\mathbb{1}\\big(\\hat{y}_i(t)=1, y_i=0\\big),\n$$\n定义经验假负率为\n$$\n\\mathrm{FN\\_rate}(t) = \\frac{1}{n}\\sum_{i=1}^n \\mathbb{1}\\big(\\hat{y}_i(t)=0, y_i=1\\big).\n$$\n经验期望成本为\n$$\nR_D(t; C_{\\mathrm{FP}}, C_{\\mathrm{FN}}) = C_{\\mathrm{FP}} \\cdot \\mathrm{FP\\_rate}(t) + C_{\\mathrm{FN}} \\cdot \\mathrm{FN\\_rate}(t).\n$$\n从这些定义出发，你的程序必须：\n- 通过在 $t$ 上最小化 $R_{\\mathrm{val}}(t; C_{\\mathrm{FP}}^{\\mathrm{val}}, C_{\\mathrm{FN}}^{\\mathrm{val}})$ 来选择一个验证最优阈值。\n- 纯粹从 $C_{\\mathrm{FP}}$ 和 $C_{\\mathrm{FN}}$ 推导贝叶斯决策阈值，而不使用数据驱动的计数。\n- 评估在测试数据集上，当使用验证集选择的阈值与最小化 $R_{\\mathrm{test}}(t; C_{\\mathrm{FP}}^{\\mathrm{test}}, C_{\\mathrm{FN}}^{\\mathrm{test}})$ 的测试集最优阈值相比时的经验期望成本。\n- 在测试成本比率不确定的情况下构建一个鲁棒阈值。假设测试成本不确定，但经过归一化以满足 $C_{\\mathrm{FP}} + C_{\\mathrm{FN}} = 1$，其中 $C_{\\mathrm{FP}} \\in [r_{\\min}, r_{\\max}]$ 且 $C_{\\mathrm{FN}} = 1 - C_{\\mathrm{FP}}$。选择 $t$ 以最小化验证数据集上的最坏情况经验期望成本：\n$$\nt_{\\mathrm{robust}} = \\arg\\min_t \\ \\sup_{r \\in [r_{\\min}, r_{\\max}]} \\left( r \\cdot \\mathrm{FP\\_rate}(t) + (1-r) \\cdot \\mathrm{FN\\_rate}(t) \\right).\n$$\n\n算法约束：\n- 阈值搜索空间的选择必须能够精确地最小化经验成本。使用由数据集中观察到的已排序的唯一概率值，以及 $0$ 和 $1+\\varepsilon$（对于一个小的正数 $\\varepsilon$）构成的候选阈值集合，以确保覆盖所有分类情况。使用决策规则：如果 $p \\ge t$ 则 $\\hat{y}=1$，否则 $\\hat{y}=0$。如果出现平局（多个阈值产生相同的最小经验期望成本），选择最小的阈值。\n- 贝叶斯决策阈值必须从第一性原理推导，并表示为仅关于 $C_{\\mathrm{FP}}$ 和 $C_{\\mathrm{FN}}$ 的函数。\n\n测试套件：\n对于以下每一组参数，你的程序必须计算：\n- 最小化 $R_{\\mathrm{val}}(t; C_{\\mathrm{FP}}^{\\mathrm{val}}, C_{\\mathrm{FN}}^{\\mathrm{val}})$ 的验证最优阈值 $t_{\\mathrm{val}}$。\n- 从 $C_{\\mathrm{FP}}^{\\mathrm{val}}$ 和 $C_{\\mathrm{FN}}^{\\mathrm{val}}$ 推导出的贝叶斯阈值 $t_{\\mathrm{Bayes}}$。\n- 最小化 $R_{\\mathrm{test}}(t; C_{\\mathrm{FP}}^{\\mathrm{test}}, C_{\\mathrm{FN}}^{\\mathrm{test}})$ 的测试最优阈值 $t_{\\mathrm{test}}$。\n- 在 $r \\in [r_{\\min}, r_{\\max}]$ 范围内，当 $C_{\\mathrm{FP}}=r$ 和 $C_{\\mathrm{FN}}=1-r$ 时，最小化最坏情况验证成本的鲁棒阈值 $t_{\\mathrm{robust}}$。\n- 经验期望测试成本的差异 $\\Delta_{\\mathrm{test}} = R_{\\mathrm{test}}(t_{\\mathrm{val}}; C_{\\mathrm{FP}}^{\\mathrm{test}}, C_{\\mathrm{FN}}^{\\mathrm{test}}) - R_{\\mathrm{test}}(t_{\\mathrm{test}}; C_{\\mathrm{FP}}^{\\mathrm{test}}, C_{\\mathrm{FN}}^{\\mathrm{test}})$。\n\n参数集：\n- 情况1（均衡，中度不匹配）：\n    - 验证概率 $[0.05, 0.10, 0.15, 0.20, 0.30, 0.40, 0.60, 0.70, 0.80, 0.90]$ 和标签 $[0, 0, 0, 0, 0, 0, 1, 1, 1, 1]$。\n    - 测试概率 $[0.02, 0.12, 0.18, 0.25, 0.35, 0.45, 0.55, 0.68, 0.78, 0.88]$ 和标签 $[0, 0, 0, 0, 0, 0, 1, 1, 1, 1]$。\n    - 验证成本 $(C_{\\mathrm{FP}}^{\\mathrm{val}}, C_{\\mathrm{FN}}^{\\mathrm{val}}) = (1, 2)$。\n    - 测试成本 $(C_{\\mathrm{FP}}^{\\mathrm{test}}, C_{\\mathrm{FN}}^{\\mathrm{test}}) = (2, 1)$。\n    - 鲁棒比率区间 $[r_{\\min}, r_{\\max}] = [0.3, 0.7]$。\n- 情况2（高度不平衡，高假负类测试成本）：\n    - 验证概率 $[0.05, 0.07, 0.09, 0.12, 0.18, 0.22, 0.27, 0.35, 0.42, 0.50, 0.62, 0.75]$ 和标签 $[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]$。\n    - 测试概率 $[0.03, 0.08, 0.10, 0.13, 0.19, 0.25, 0.28, 0.33, 0.41, 0.52, 0.60, 0.78]$ 和标签 $[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]$。\n    - 验证成本 $(C_{\\mathrm{FP}}^{\\mathrm{val}}, C_{\\mathrm{FN}}^{\\mathrm{val}}) = (1, 5)$。\n    - 测试成本 $(C_{\\mathrm{FP}}^{\\mathrm{test}}, C_{\\mathrm{FN}}^{\\mathrm{test}}) = (1, 10)$。\n    - 鲁棒比率区间 $[r_{\\min}, r_{\\max}] = [0.1, 0.4]$。\n- 情况3（近乎完美分离，成本相等）：\n    - 验证概率 $[0.01, 0.02, 0.05, 0.95, 0.97, 0.99]$ 和标签 $[0, 0, 0, 1, 1, 1]$。\n    - 测试概率 $[0.02, 0.03, 0.06, 0.94, 0.96, 0.98]$ 和标签 $[0, 0, 0, 1, 1, 1]$。\n    - 验证成本 $(C_{\\mathrm{FP}}^{\\mathrm{val}}, C_{\\mathrm{FN}}^{\\mathrm{val}}) = (1, 1)$。\n    - 测试成本 $(C_{\\mathrm{FP}}^{\\mathrm{test}}, C_{\\mathrm{FN}}^{\\mathrm{test}}) = (1, 1)$。\n    - 鲁棒比率区间 $[r_{\\min}, r_{\\max}] = [0.5, 0.5]$。\n- 情况4（退化的相同概率，冲突的成本）：\n    - 验证概率 $[0.5, 0.5, 0.5, 0.5, 0.5, 0.5]$ 和标签 $[0, 0, 1, 1, 0, 1]$。\n    - 测试概率 $[0.5, 0.5, 0.5, 0.5, 0.5, 0.5]$ 和标签 $[0, 0, 1, 1, 0, 1]$。\n    - 验证成本 $(C_{\\mathrm{FP}}^{\\mathrm{val}}, C_{\\mathrm{FN}}^{\\mathrm{val}}) = (3, 1)$。\n    - 测试成本 $(C_{\\mathrm{FN}}^{\\mathrm{test}}, C_{\\mathrm{FN}}^{\\mathrm{test}}) = (1, 3)$。\n    - 鲁棒比率区间 $[r_{\\min}, r_{\\max}] = [0.2, 0.8]$。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。每个元素对应一个案例，并且本身必须是一个包含五个十进制数的列表，顺序为 $[t_{\\mathrm{val}}, t_{\\mathrm{Bayes}}, t_{\\mathrm{test}}, t_{\\mathrm{robust}}, \\Delta_{\\mathrm{test}}]$。例如，对于两个案例的有效输出行将类似于 $[[0.333333,0.333333,0.666667,0.500000,0.050000],[\\dots]]$，不带任何附加文本。角度和物理单位不适用；所有输出都是无量纲的实数。", "solution": "该问题要求对二元分类器的决策阈值进行多方面的分析。我们必须在不同标准下确定最优阈值，并评估验证集和测试集之间的性能不匹配。解决方案将基于统计决策理论和经验风险最小化的原则系统地构建。\n\n### 步骤1：理论基础\n\n让我们首先将问题的各个组成部分形式化。\n\n**1.1. 经验风险（期望成本）**\n一个二元分类器为每个具有特征 $\\mathbf{x}_i$ 的实例 $i$ 分配一个后验概率 $p_i = P(Y=1 | \\mathbf{x}_i)$。使用决策阈值 $t$ 来做出最终预测 $\\hat{y}_i(t) \\in \\{0, 1\\}$。决策规则如下：\n$$\n\\hat{y}_i(t) =\n\\begin{cases}\n1  \\text{if } p_i \\ge t \\\\\n0  \\text{if } p_i  t\n\\end{cases}\n$$\n问题将在大小为 $n$ 的数据集 $D$ 上，将经验假正率和假负率定义为：\n$$\n\\mathrm{FP\\_rate}(t) = \\frac{1}{n}\\sum_{i=1}^n \\mathbb{1}\\big(\\hat{y}_i(t)=1, y_i=0\\big) = \\frac{1}{n} \\left| \\{ i \\mid p_i \\ge t, y_i=0 \\} \\right|\n$$\n$$\n\\mathrm{FN\\_rate}(t) = \\frac{1}{n}\\sum_{i=1}^n \\mathbb{1}\\big(\\hat{y}_i(t)=0, y_i=1\\big) = \\frac{1}{n} \\left| \\{ i \\mid p_i  t, y_i=1 \\} \\right|\n$$\n这里，$\\mathbb{1}(\\cdot)$ 是指示函数。请注意，这些率是由总样本大小 $n$ 归一化的，而不是由实际负类或正类实例的数量归一化。给定假正类成本（$C_{\\mathrm{FP}}$）和假负类成本（$C_{\\mathrm{FN}}$），经验期望成本或风险为：\n$$\nR_D(t; C_{\\mathrm{FP}}, C_{\\mathrm{FN}}) = C_{\\mathrm{FP}} \\cdot \\mathrm{FP\\_rate}(t) + C_{\\mathrm{FN}} \\cdot \\mathrm{FN\\_rate}(t)\n$$\n在验证集上对 $t$ 最小化此风险，可以得到验证最优阈值 $t_{\\mathrm{val}}$。在测试集上进行类似的最小化，可以得到测试最优阈值 $t_{\\mathrm{test}}$。\n\n**1.2. 贝叶斯决策阈值**\n贝叶斯决策规则最小化单个实例的期望成本。对于一个预测概率为 $p = P(Y=1)$ 的实例，预测为正类（$\\hat{y}=1$）的期望成本是 $E[\\text{Cost}|\\hat{y}=1] = C_{\\mathrm{FP}} \\cdot (1-p)$。预测为负类（$\\hat{y}=0$）的期望成本是 $E[\\text{Cost}|\\hat{y}=0] = C_{\\mathrm{FN}} \\cdot p$。最优决策是在 $E[\\text{Cost}|\\hat{y}=1] \\le E[\\text{Cost}|\\hat{y}=0]$ 时预测为正类，这导致：\n$$\nC_{\\mathrm{FP}}(1-p) \\le C_{\\mathrm{FN}} p \\implies C_{\\mathrm{FP}} \\le (C_{\\mathrm{FP}} + C_{\\mathrm{FN}})p \\implies p \\ge \\frac{C_{\\mathrm{FP}}}{C_{\\mathrm{FP}} + C_{\\mathrm{FN}}}\n$$\n因此，假设分类器的输出 $p$ 是真实的后验概率，贝叶斯最优阈值为：\n$$\nt_{\\mathrm{Bayes}} = \\frac{C_{\\mathrm{FP}}}{C_{\\mathrm{FP}} + C_{\\mathrm{FN}}}\n$$\n这提供了一个纯粹从成本推导出的理论基准。\n\n**1.3. 鲁棒极小化极大阈值**\n成本的不确定性可以通过极小化极大方法来处理。在这里，测试集上的成本是未知的，但假设它们被归一化，使得 $C_{\\mathrm{FP}} + C_{\\mathrm{FN}} = 1$。不确定性由 $C_{\\mathrm{FP}} = r$ 在区间 $[r_{\\min}, r_{\\max}]$ 内变化来捕捉。目标是找到一个阈值 $t$，以最小化验证数据上的最坏情况风险：\n$$\nt_{\\mathrm{robust}} = \\arg\\min_t \\left( \\sup_{r \\in [r_{\\min}, r_{\\max}]} R_{\\mathrm{val}}(t; r, 1-r) \\right)\n$$\n对于固定的阈值 $t$，风险 $R_{\\mathrm{val}}(t; r, 1-r) = r \\cdot \\mathrm{FP\\_rate}^{\\mathrm{val}}(t) + (1-r) \\cdot \\mathrm{FN\\_rate}^{\\mathrm{val}}(t)$ 是 $r$ 的一个线性函数。一个线性函数在闭区间 $[r_{\\min}, r_{\\max}]$ 上的上确界（最大值）必定在其中一个端点处取得。因此，对于给定的 $t$，最坏情况风险是：\n$$\n\\sup_{r \\in [r_{\\min}, r_{\\max}]} R_{\\mathrm{val}}(t; r, 1-r) = \\max \\left( R_{\\mathrm{val}}(t; r_{\\min}, 1-r_{\\min}), R_{\\mathrm{val}}(t; r_{\\max}, 1-r_{\\max}) \\right)\n$$\n然后我们可以通过搜索最小化这个最大值的阈值 $t$ 来找到 $t_{\\mathrm{robust}}$。\n\n### 步骤2：算法实现\n\n**2.1. 阈值候选与搜索**\n经验风险 $R_D(t)$ 是一个阶梯函数，其值仅在阈值 $t$ 等于数据集中的概率分数 $p_i$ 时发生变化。因此，为了找到精确的最小值，只需在一组离散的候选阈值处评估成本。问题指定该集合为数据中唯一的概率分数，并增补 $t=0$（将所有实例分类为正类）和 $t > 1$（例如，$1+\\varepsilon$，将所有实例分类为负类）。我们将使用 $\\{0.0\\} \\cup \\{p_i\\}_{\\text{unique}} \\cup \\{1.0+\\varepsilon\\}$。通过遍历这些排序后的候选值，我们可以找到最小成本。指定的平局决胜规则是选择产生最小成本的最小阈值。这可以通过遍历排序后的候选值并在找到严格更低的成本时才更新最佳阈值来实现。\n\n**2.2. 各量计算**\n1.  **$t_{\\mathrm{val}}$ 和 $t_{\\mathrm{test}}$**：我们将实现一个函数，它接受一个数据集（概率和标签）和成本（$C_{\\mathrm{FP}}$，$C_{\\mathrm{FN}}$），并执行第2.1节中描述的搜索，通过最小化 $R_D(t)$ 来找到最优阈值。\n2.  **$t_{\\mathrm{Bayes}}$**：这使用公式 $t_{\\mathrm{Bayes}} = C_{\\mathrm{FP}}^{\\mathrm{val}} / (C_{\\mathrm{FP}}^{\\mathrm{val}} + C_{\\mathrm{FN}}^{\\mathrm{val}})$ 直接计算。\n3.  **$t_{\\mathrm{robust}}$**：我们将实现一个函数，它接受验证数据集和区间 $[r_{\\min}, r_{\\max}]$。对于每个候选阈值 $t$，它计算在 $r_{\\min}$ 和 $r_{\\max}$ 处的风险的最大值作为最坏情况风险，然后找到最小化此最坏情况风险的 $t$，并遵守平局决胜规则。\n4.  **$\\Delta_{\\mathrm{test}}$**：这是测试集上的性能差距。它计算为 $\\Delta_{\\mathrm{test}} = R_{\\mathrm{test}}(t_{\\mathrm{val}}; C_{\\mathrm{FP}}^{\\mathrm{test}}, C_{\\mathrm{FN}}^{\\mathrm{test}}) - R_{\\mathrm{test}}(t_{\\mathrm{test}}; C_{\\mathrm{FP}}^{\\mathrm{test}}, C_{\\mathrm{FN}}^{\\mathrm{test}})$。我们首先找到 $t_{\\mathrm{val}}$ 和 $t_{\\mathrm{test}}$，然后在这两个阈值处评估风险函数 $R_{\\mathrm{test}}$ 并求差。第二项 $R_{\\mathrm{test}}(t_{\\mathrm{test}}, \\dots)$ 根据定义是测试集上可能的最小经验风险。\n\n以下 Python 程序实现了此逻辑，以解决给定的测试用例。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the analysis for all test cases.\n    \"\"\"\n\n    test_cases = [\n        # Case 1: balanced, moderate mismatch\n        {\n            \"val_probs\": [0.05, 0.10, 0.15, 0.20, 0.30, 0.40, 0.60, 0.70, 0.80, 0.90],\n            \"val_labels\": [0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n            \"test_probs\": [0.02, 0.12, 0.18, 0.25, 0.35, 0.45, 0.55, 0.68, 0.78, 0.88],\n            \"test_labels\": [0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n            \"val_costs\": (1, 2),\n            \"test_costs\": (2, 1),\n            \"robust_interval\": (0.3, 0.7),\n        },\n        # Case 2: highly imbalanced, heavy false negative test cost\n        {\n            \"val_probs\": [0.05, 0.07, 0.09, 0.12, 0.18, 0.22, 0.27, 0.35, 0.42, 0.50, 0.62, 0.75],\n            \"val_labels\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n            \"test_probs\": [0.03, 0.08, 0.10, 0.13, 0.19, 0.25, 0.28, 0.33, 0.41, 0.52, 0.60, 0.78],\n            \"test_labels\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n            \"val_costs\": (1, 5),\n            \"test_costs\": (1, 10),\n            \"robust_interval\": (0.1, 0.4),\n        },\n        # Case 3: near-perfect separation, equal costs\n        {\n            \"val_probs\": [0.01, 0.02, 0.05, 0.95, 0.97, 0.99],\n            \"val_labels\": [0, 0, 0, 1, 1, 1],\n            \"test_probs\": [0.02, 0.03, 0.06, 0.94, 0.96, 0.98],\n            \"test_labels\": [0, 0, 0, 1, 1, 1],\n            \"val_costs\": (1, 1),\n            \"test_costs\": (1, 1),\n            \"robust_interval\": (0.5, 0.5),\n        },\n        # Case 4: degenerate identical probabilities, conflicting costs\n        {\n            \"val_probs\": [0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n            \"val_labels\": [0, 0, 1, 1, 0, 1],\n            \"test_probs\": [0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n            \"test_labels\": [0, 0, 1, 1, 0, 1],\n            \"val_costs\": (3, 1),\n            \"test_costs\": (1, 3),\n            \"robust_interval\": (0.2, 0.8),\n        },\n    ]\n\n    results = []\n    \n    # A small epsilon is not needed if we use np.nextafter to get a number > 1.\n    epsilon_threshold = np.nextafter(1.0, 2.0)\n\n    def calculate_cost(t, probs, labels, cfp, cfn):\n        \"\"\"Calculates the empirical expected cost for a given threshold.\"\"\"\n        n = len(labels)\n        if n == 0:\n            return 0.0\n        \n        predictions = (probs >= t).astype(int)\n        \n        fp_count = np.sum((predictions == 1)  (labels == 0))\n        fn_count = np.sum((predictions == 0)  (labels == 1))\n        \n        cost = (cfp * fp_count + cfn * fn_count) / n\n        return cost\n\n    def find_optimal_threshold(probs, labels, cfp, cfn):\n        \"\"\"Finds the threshold that minimizes empirical cost.\"\"\"\n        unique_probs = np.unique(probs)\n        candidate_thresholds = np.concatenate(([0.0], unique_probs, [epsilon_threshold]))\n        \n        min_cost = float('inf')\n        best_t = -1.0\n        \n        for t in candidate_thresholds:\n            cost = calculate_cost(t, probs, labels, cfp, cfn)\n            if cost  min_cost:\n                min_cost = cost\n                best_t = t\n                \n        return best_t, min_cost\n\n    def find_robust_threshold(probs, labels, r_min, r_max):\n        \"\"\"Finds the threshold that minimizes the worst-case empirical cost.\"\"\"\n        n = len(labels)\n        if n == 0:\n            return -1.0\n            \n        unique_probs = np.unique(probs)\n        candidate_thresholds = np.concatenate(([0.0], unique_probs, [epsilon_threshold]))\n        \n        min_worst_case_cost = float('inf')\n        best_t = -1.0\n        \n        for t in candidate_thresholds:\n            predictions = (probs >= t).astype(int)\n            fp_count = np.sum((predictions == 1)  (labels == 0))\n            fn_count = np.sum((predictions == 0)  (labels == 1))\n            \n            fp_rate = fp_count / n\n            fn_rate = fn_count / n\n            \n            cost_at_rmin = r_min * fp_rate + (1 - r_min) * fn_rate\n            cost_at_rmax = r_max * fp_rate + (1 - r_max) * fn_rate\n            \n            worst_case_cost = max(cost_at_rmin, cost_at_rmax)\n            \n            if worst_case_cost  min_worst_case_cost:\n                min_worst_case_cost = worst_case_cost\n                best_t = t\n                \n        return best_t\n\n    for case in test_cases:\n        val_probs = np.array(case[\"val_probs\"])\n        val_labels = np.array(case[\"val_labels\"])\n        test_probs = np.array(case[\"test_probs\"])\n        test_labels = np.array(case[\"test_labels\"])\n        cfp_val, cfn_val = case[\"val_costs\"]\n        cfp_test, cfn_test = case[\"test_costs\"]\n        r_min, r_max = case[\"robust_interval\"]\n\n        # Calculate t_val\n        t_val, _ = find_optimal_threshold(val_probs, val_labels, cfp_val, cfn_val)\n\n        # Calculate t_bayes\n        t_bayes = cfp_val / (cfp_val + cfn_val)\n\n        # Calculate t_test and min_test_cost\n        t_test, min_test_cost = find_optimal_threshold(test_probs, test_labels, cfp_test, cfn_test)\n\n        # Calculate t_robust\n        t_robust = find_robust_threshold(val_probs, val_labels, r_min, r_max)\n\n        # Calculate Delta_test\n        cost_at_t_val_on_test = calculate_cost(t_val, test_probs, test_labels, cfp_test, cfn_test)\n        delta_test = cost_at_t_val_on_test - min_test_cost\n\n        case_results = [t_val, t_bayes, t_test, t_robust, delta_test]\n        results.append(case_results)\n\n    # Format output as specified\n    print(f\"[{','.join(str(res) for res in results)}]\")\n\nsolve()\n```", "id": "3194809"}]}