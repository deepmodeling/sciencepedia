{"hands_on_practices": [{"introduction": "理论上完美的模型在实践中可能因数值问题而失败，梯度爆炸是常见元凶。在使用 $L_2$ 损失时，梯度大小与误差成正比，当目标值极大时，微小的初始误差也可能导致梯度在数值上溢出，使训练过程崩溃。这个练习 ([@problem_id:3178853]) 将引导你亲手构造一个此类失败场景，并通过目标标准化等方法来修复它，从而深刻理解为何数据预处理和数值稳定性对成功训练模型至关重要。", "problem": "要求您设计并分析一个最小化的监督学习回归实验，该实验旨在展示在平方欧几里得损失（也称为 $L_2$ 损失）下，当目标值极大时，梯度的量级如何变得数值不稳定，以及两种标准补救措施——目标标准化和梯度归一化——如何防止此类不稳定性。请在以下数学定义的设置中进行操作。\n\n数据集构建与模型：\n- 考虑一个标量线性模型，其参数为 $w \\in \\mathbb{R}$，预测值为 $\\hat{y}_i = w x_i$。\n- 构建一个包含 $N$ 个点的确定性数据集，其中 $N = 200$。令 $x_i$ 在区间 $\\left[-5, 5\\right]$ 内均匀分布，其中 $i = 1, \\dots, N$。\n- 固定一个基准真相标量 $w_\\star = 2$。对于给定的尺度 $s  0$，通过 $y_i = s \\cdot w_\\star \\cdot x_i$ 定义每个 $i$ 的目标值。\n- 所有训练计算均使用单精度浮点数（$32$ 位，IEEE $754$），以使有限精度效应变得可观察。\n\n损失和梯度：\n- 使用均方误差（平方 $L_2$ 损失）$$J(w) = \\frac{1}{N}\\sum_{i=1}^{N} \\left(\\hat{y}_i - y_i\\right)^2.$$ \n- 从 $w^{(0)} = 0$ 开始，使用恒定步长（学习率）$\\alpha$ 执行 $T$ 步梯度下降：\n  $$w^{(t+1)} = w^{(t)} - \\alpha \\cdot \\nabla J\\left(w^{(t)}\\right), \\quad t = 0, 1, \\dots, T-1.$$\n- 在实现之前，您必须从基本定义出发，推导该模型的 $\\nabla J(w)$ 的解析表达式。不要假定任何“捷径”公式。\n\n不稳定性定义与诊断：\n- 如果在任何迭代中，以单精度计算的训练状态中出现以下任一情况，则认为一次运行是不稳定的：损失、参数或梯度中出现非有限数（非数字或无穷大）。这对应于检测数值溢出或无效操作。\n- 为了在不引起诊断溢出的情况下评估单调改进，还需计算一个尺度不变的代理损失\n  $$\\tilde{J}(w) = \\frac{1}{N}\\sum_{i=1}^{N} \\left(\\frac{\\hat{y}_i - y_i}{M}\\right)^2,$$\n  其中 $M = \\max_i |y_i|$ 在训练前以双精度（$64$ 位）计算，然后视为一个常数；评估 $\\tilde{J}(w)$ 时，涉及 $w$、$x_i$ 和 $y_i$ 的算术运算使用单精度，但除以转换为单精度的双精度常数 $M$。此代理损失不会改变训练过程，并避免了诊断本身的溢出。如果一次运行保持有限，并且 $\\tilde{J}(w)$ 在迭代过程中非递增（容差为 $\\varepsilon = 10^{-6}$），且至少严格减少一次，则认为该运行是稳定改进的。\n\n需要实现的补救措施：\n- 目标标准化：计算标准化目标 $y^{\\mathrm{std}}_i = \\left(y_i - \\mu_y\\right)/\\sigma_y$，其中 $\\mu_y$ 是 $y_i$ 的均值，$\\sigma_y$ 是 $y_i$ 的标准差。为避免在为非常大的 $s$ 计算这些统计量时发生溢出，请以双精度（$64$ 位 IEEE $754$）计算 $\\mu_y$ 和 $\\sigma_y$，然后将 $y^{\\mathrm{std}}_i$ 转换为单精度以进行训练。使用相同的 $\\alpha$ 和 $T$，通过单精度梯度下降在 $(x_i, y^{\\mathrm{std}}_i)$ 上训练相同的标量线性模型。\n- 通过逐样本裁剪进行梯度归一化：对于原始（未标准化）目标，计算损失函数相对于 $w$ 的梯度的逐样本贡献，在求和之前将每个贡献裁剪到选定的大小，然后取平均以形成批梯度。此处的所有操作，包括裁剪和求和，都必须以单精度进行。\n\n测试套件：\n使用以下参数值生成四次运行，以共同测试无保护的不稳定性、两种补救措施以及一个良性基线。\n- 数据集大小和输入：$N = 200$，$x_i$ 在 $\\left[-5, 5\\right]$ 内均匀分布。\n- 基准真相和初始化：$w_\\star = 2$，$w^{(0)} = 0$。\n- 训练超参数：学习率 $\\alpha = 0.05$，迭代次数 $T = 60$，容差 $\\varepsilon = 10^{-6}$。\n- 大规模数据集（在单精度下故意设置为危险）：$s_{\\mathrm{large}} = 10^{36}$。\n- 小规模数据集（良性）：$s_{\\mathrm{small}} = 1$。\n- 用于逐样本归一化的梯度裁剪阈值：$g_{\\mathrm{clip}} = 10^{34}$。\n\n对于每次运行，在以下四种场景下实现全批量梯度下降：\n- 场景 A（未标准化，大规模）：在 $y_i = s_{\\mathrm{large}} \\cdot w_\\star \\cdot x_i$ 上使用朴素的全批量梯度（无归一化）进行训练。\n- 场景 B（目标标准化，大规模）：使用双精度统计数据从相同的大规模 $y_i$ 计算标准化目标，转换为单精度，然后使用朴素梯度在标准化目标上进行训练。\n- 场景 C（逐样本梯度裁剪，大规模）：在相同的大规模 $y_i$ 上训练，在平均之前，将逐样本梯度贡献在单精度下裁剪到大小 $g_{\\mathrm{clip}}$。\n- 场景 D（未标准化，小规模）：在 $y_i = s_{\\mathrm{small}} \\cdot w_\\star \\cdot x_i$ 上使用朴素的全批量梯度（无归一化）进行训练。\n\n答案规格：\n- 对于场景 A，输出一个布尔值，指示是否发生不稳定性（如果不稳定则为 true）。\n- 对于场景 B，输出一个布尔值，指示运行是否如上文定义的那样稳定改进（如果稳定且改进则为 true）。\n- 对于场景 C，输出一个布尔值，指示运行是否如上文定义的那样稳定改进（如果稳定且改进则为 true）。\n- 对于场景 D，输出一个布尔值，指示运行是否如上文定义的那样稳定改进（如果稳定且改进则为 true）。\n\n最终输出格式：\n您的程序应生成一行输出，其中包含按 $\\left[\\text{A}, \\text{B}, \\text{C}, \\text{D}\\right]$ 顺序排列的四个布尔结果，以逗号分隔并用方括号括起来，例如，$[\\texttt{True},\\texttt{False},\\texttt{True},\\texttt{True}]$。", "solution": "问题陈述是一个定义明确的数值实验，旨在研究有限精度算术在监督学习背景下对基于梯度的优化的影响。它具有科学依据、客观，并提供了解决问题所需的所有必要规格。因此，这是一个有效的问题。\n\n我们从第一性原理出发，给出一个完整的解决方案。\n\n### 基本定义与梯度推导\n\n分析基于一个标量线性模型，其中对输入 $x_i$ 的预测 $\\hat{y}_i$ 由单个参数 $w \\in \\mathbb{R}$ 生成：\n$$\n\\hat{y}_i = w x_i\n$$\n目标是在 $N$ 个点 $(x_i, y_i)$ 的数据集上最小化均方误差（MSE）损失函数 $J(w)$：\n$$\nJ(w) = \\frac{1}{N}\\sum_{i=1}^{N} \\left(\\hat{y}_i - y_i\\right)^2 = \\frac{1}{N}\\sum_{i=1}^{N} \\left(w x_i - y_i\\right)^2\n$$\n参数 $w$ 通过梯度下降进行更新。梯度 $\\nabla J(w)$ 是损失函数相对于参数 $w$ 的导数。我们从 $J(w)$ 的定义推导出它：\n$$\n\\nabla J(w) = \\frac{dJ}{dw} = \\frac{d}{dw} \\left( \\frac{1}{N}\\sum_{i=1}^{N} (w x_i - y_i)^2 \\right)\n$$\n根据微分的线性性质，我们可以将导数移到求和号内部：\n$$\n\\nabla J(w) = \\frac{1}{N}\\sum_{i=1}^{N} \\frac{d}{dw} (w x_i - y_i)^2\n$$\n应用链式法则，其中外部函数是 $u^2$，内部函数是 $u(w) = w x_i - y_i$：\n$$\n\\frac{d}{dw} (w x_i - y_i)^2 = 2(w x_i - y_i) \\cdot \\frac{d}{dw}(w x_i - y_i) = 2(w x_i - y_i) \\cdot x_i\n$$\n将其代回，得到全批量梯度的表达式：\n$$\n\\nabla J(w) = \\frac{2}{N}\\sum_{i=1}^{N} (w x_i - y_i) x_i\n$$\n在迭代 $t$ 时，使用学习率 $\\alpha$ 的梯度下降更新规则为：\n$$\nw^{(t+1)} = w^{(t)} - \\alpha \\cdot \\nabla J\\left(w^{(t)}\\right)\n$$\n所有训练计算都使用单精度浮点数（$32$ 位 IEEE $754$）执行，其范围和精度都是有限的。可表示的最大有限值约为 $3.4 \\times 10^{38}$。导致更大值的运算将导致数值溢出，产生无穷大（`inf`）。\n\n### 场景分析\n\n**场景 A（未标准化，大规模）：**\n在这里，目标是 $y_i = s_{\\mathrm{large}} \\cdot w_\\star \\cdot x_i$，其中 $s_{\\mathrm{large}} = 10^{36}$ 且 $w_\\star = 2$。$x_i$ 的最大绝对值为 $5$。\n目标值的最大量级为 $|y_i|_{\\max} = 10^{36} \\cdot 2 \\cdot 5 = 10^{37}$。这个值在单精度下是可表示的。\n然而，在计算损失和梯度期间会出现不稳定性。在第一次迭代（$t=0$）时，$w^{(0)} = 0$。单个样本的平方误差为：\n$$\n\\left(w^{(0)} x_i - y_i\\right)^2 = (-y_i)^2 = y_i^2\n$$\n对于具有最大目标量级的样本，这将变为 $(10^{37})^2 = 10^{74}$。这远远超过了单精度的极限 $\\approx 3.4 \\times 10^{38}$，导致溢出为 `inf`。因此，损失 $J(w^{(0)})$ 将是 `inf`。\n类似地，未求和的梯度的逐样本贡献是 $2(w^{(0)}x_i - y_i)x_i = -2y_ix_i$。最大量级为 $|-2 \\cdot (10^{36} \\cdot 2 \\cdot 5) \\cdot 5| = 10^{38}$。虽然这个单独的项可能是可表示的，但对许多这样大的数求和也可能导致溢出。关键是，损失计算中的溢出足以将该运行归类为不稳定。\n**预期结果：`True`（发生不稳定性）。**\n\n**场景 B（目标标准化，大规模）：**\n这种补救措施会预先重新缩放目标。标准化使用双精度（$64$ 位）算术执行，以避免在统计计算过程中发生溢出。标准化后的目标是：\n$$\ny^{\\mathrm{std}}_i = \\frac{y_i - \\mu_y}{\\sigma_y}\n$$\n其中 $\\mu_y$ 和 $\\sigma_y$ 是原始大规模目标 $y_i$ 的均值和标准差。由于 $x_i$ 关于 $0$ 对称，均值 $\\mu_y = \\mathbb{E}[s w_\\star x_i]$ 为 $0$。标准差为 $\\sigma_y = |s w_\\star| \\sigma_x$。\n然后在新数据集 $(x_i, y^{\\mathrm{std}}_i)$ 上进行训练。参数 $w$ 的新目标是 $w^{\\mathrm{std}}_\\star = (s w_\\star)/\\sigma_y = \\text{sign}(s w_\\star)/\\sigma_x$。对于给定的 $x_i$，$\\sigma_x \\approx 2.89$，因此 $w^{\\mathrm{std}}_\\star \\approx 1/2.89 \\approx 0.346$。\n训练过程中的所有值——参数、目标、预测、损失、梯度——现在的量级都很小且易于管理。学习率 $\\alpha=0.05$ 对于这个良态的凸问题是合适的，能确保单调收敛。运行将是有限的。用于衡量原始尺度上性能的代理损失 $\\tilde{J}(w)$ 将是非递增的，并且会从其初始值严格下降。\n**预期结果：`True`（运行是稳定改进的）。**\n\n**场景 C（逐样本梯度裁剪，大规模）：**\n这种补救措施直接处理梯度的大小。逐样本的梯度贡献为 $g_i(w) = 2(wx_i - y_i)x_i$。\n在 $t=0$ 时，$w^{(0)}=0$，所以 $g_i(w^{(0)}) = -2y_ix_i = -2(s w_\\star x_i)x_i = -2 s w_\\star x_i^2$。这些贡献的量级可以达到 $|-2 \\cdot 10^{36} \\cdot 2 \\cdot 5^2| = 10^{38}$，这接近单精度的极限，但其本身可能不会溢出。\n然而，这些值被裁剪到范围 $[-g_{\\mathrm{clip}}, g_{\\mathrm{clip}}]$ 内，其中 $g_{\\mathrm{clip}} = 10^{34}$。由于 $|g_i(w^{(0)})| > g_{\\mathrm{clip}}$，每个非零贡献都会被裁剪。梯度变为 $\\nabla J(w) \\approx -g_{\\mathrm{clip}}$。\n第一次更新是 $w^{(1)} = w^{(0)} - \\alpha \\cdot \\nabla J(w^{(0)}) \\approx 0 - 0.05 \\cdot (-10^{34}) = 5 \\times 10^{32}$。\n参数 $w$ 的更新保持有限。尽管梯度信息已饱和，但方向是正确的（将 $w$ 向正目标 $s w_\\star$ 增加）。损失将在每一步减少，尽管是次优的。运行将保持有限，代理损失将是非递增的。\n**预期结果：`True`（运行是稳定改进的）。**\n\n**场景 D（未标准化，小规模）：**\n这是良性基线。尺度为 $s_{\\mathrm{small}}=1$。目标是 $y_i = 2x_i$。所有值都很小。最大目标量级为 $10$。没有数值溢出的风险。该问题在几何上与场景 B 相同，只是目标参数的缩放不同（$w_\\star=2$ 而不是 $w^{\\mathrm{std}}_\\star \\approx 0.346$）。在一个安全的学习率下，梯度下降将顺利进行，呈现单调收敛。\n**预期结果：`True`（运行是稳定改进的）。**", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Designs and runs a supervised learning regression experiment to demonstrate\n    numerical instability and remedies in gradient descent.\n    \"\"\"\n    # Global parameters from the problem\n    N = 200\n    W_STAR = 2.0\n    W0 = 0.0\n    ALPHA = 0.05\n    T = 60\n    EPSILON = 1e-6\n    S_LARGE = 1e36\n    S_SMALL = 1.0\n    G_CLIP = 1e34\n\n    # Data types\n    F32 = np.float32\n    F64 = np.float64\n\n    # Common dataset generation\n    x_64 = np.linspace(-5, 5, N, dtype=F64)\n    x_32 = x_64.astype(F32)\n\n    y_large_64 = S_LARGE * W_STAR * x_64\n    y_large_32 = y_large_64.astype(F32)\n\n    y_small_64 = S_SMALL * W_STAR * x_64\n    y_small_32 = y_small_64.astype(F32)\n\n    def run_scenario_A():\n        w = F32(W0)\n        x = x_32\n        y = y_large_32\n        \n        for _ in range(T):\n            if not np.isfinite(w): return True\n            y_hat = w * x\n            errors = y_hat - y\n            loss = np.mean(errors**2)\n            if not np.isfinite(loss): return True\n            grad = np.mean(F32(2.0) * errors * x)\n            if not np.isfinite(grad): return True\n            w = w - F32(ALPHA) * grad\n        \n        return not np.isfinite(w)\n\n    def run_scenario_B():\n        mu_y_64 = np.mean(y_large_64)\n        sigma_y_64 = np.std(y_large_64)\n        \n        y_std_64 = (y_large_64 - mu_y_64) / sigma_y_64 if sigma_y_64 != 0 else y_large_64 - mu_y_64\n        y_train = y_std_64.astype(F32)\n        x = x_32\n        \n        M_64 = np.max(np.abs(y_large_64))\n        M_32 = F32(M_64)\n        mu_y_32 = F32(mu_y_64)\n        sigma_y_32 = F32(sigma_y_64)\n\n        w = F32(W0)\n        proxy_losses = []\n        is_finite_run = True\n\n        for t in range(T + 1):\n            w_unstd = w * sigma_y_32\n            y_hat_unstd = w_unstd * x + mu_y_32\n            errors_orig_scale = y_hat_unstd - y_large_32\n            \n            proxy_loss = np.mean((errors_orig_scale / M_32)**2) if M_32 != 0 else np.mean(errors_orig_scale**2)\n            \n            if not np.isfinite(proxy_loss):\n                is_finite_run = False\n                break\n            proxy_losses.append(proxy_loss)\n            \n            if t == T: break\n\n            y_hat = w * x\n            errors = y_hat - y_train\n            loss = np.mean(errors**2)\n            grad = np.mean(F32(2.0) * errors * x)\n            \n            if not (np.isfinite(w) and np.isfinite(loss) and np.isfinite(grad)):\n                is_finite_run = False\n                break\n            w = w - F32(ALPHA) * grad\n        \n        if not is_finite_run: return False\n\n        is_non_increasing = all(proxy_losses[i+1] = proxy_losses[i] + EPSILON for i in range(T))\n        has_decreased = any(proxy_losses[i+1]  proxy_losses[i] for i in range(T))\n            \n        return is_non_increasing and has_decreased\n\n    def run_scenario_C():\n        w = F32(W0)\n        x = x_32\n        y = y_large_32\n        M_64 = np.max(np.abs(y_large_64))\n        M_32 = F32(M_64)\n        clip_val = F32(G_CLIP)\n        \n        proxy_losses = []\n        is_finite_run = True\n\n        for t in range(T + 1):\n            y_hat = w * x\n            errors = y_hat - y\n            proxy_loss = np.mean((errors / M_32)**2) if M_32 != 0 else np.mean(errors**2)\n            if not np.isfinite(proxy_loss):\n                is_finite_run = False\n                break\n            proxy_losses.append(proxy_loss)\n\n            if t == T: break\n\n            loss = np.mean(errors**2)\n            grad_contribs = F32(2.0) * errors * x\n            clipped_contribs = np.clip(grad_contribs, -clip_val, clip_val)\n            grad = np.mean(clipped_contribs)\n\n            if not (np.isfinite(w) and np.isfinite(loss) and np.isfinite(grad)):\n                is_finite_run = False\n                break\n            w = w - F32(ALPHA) * grad\n        \n        if not is_finite_run: return False\n\n        is_non_increasing = all(proxy_losses[i+1] = proxy_losses[i] + EPSILON for i in range(T))\n        has_decreased = any(proxy_losses[i+1]  proxy_losses[i] for i in range(T))\n            \n        return is_non_increasing and has_decreased\n\n    def run_scenario_D():\n        w = F32(W0)\n        x = x_32\n        y = y_small_32\n        M_64 = np.max(np.abs(y_small_64))\n        M_32 = F32(M_64)\n        \n        proxy_losses = []\n        is_finite_run = True\n\n        for t in range(T + 1):\n            y_hat = w * x\n            errors = y_hat - y\n            proxy_loss = np.mean((errors / M_32)**2) if M_32 != 0 else np.mean(errors**2)\n            if not np.isfinite(proxy_loss):\n                is_finite_run = False\n                break\n            proxy_losses.append(proxy_loss)\n\n            if t == T: break\n            \n            loss = np.mean(errors**2)\n            grad = np.mean(F32(2.0) * errors * x)\n\n            if not (np.isfinite(w) and np.isfinite(loss) and np.isfinite(grad)):\n                is_finite_run = False\n                break\n            w = w - F32(ALPHA) * grad\n\n        if not is_finite_run: return False\n\n        is_non_increasing = all(proxy_losses[i+1] = proxy_losses[i] + EPSILON for i in range(T))\n        has_decreased = any(proxy_losses[i+1]  proxy_losses[i] for i in range(T))\n        \n        return is_non_increasing and has_decreased\n\n    results = [\n        run_scenario_A(),\n        run_scenario_B(),\n        run_scenario_C(),\n        run_scenario_D(),\n    ]\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3178853"}, {"introduction": "在保证训练稳定之后，我们需关注数据质量的挑战。现实世界的数据常常包含异常值，它们会严重影响使用标准均方误差（$L_2$ 损失）训练的模型。损失函数的选择决定了模型的鲁棒性；与二次方增长的 $L_2$ 损失不同，$L_1$ 损失或 Huber 损失等对大误差的惩罚增长较缓，因而对异常值不那么敏感。本练习 ([@problem_id:3178857]) 通过一个受控的理论实验，让你分析和比较不同损失函数在面对“对抗性”噪声时的表现，从而学会如何根据数据特性来选择和评估更鲁棒的回归模型。", "problem": "考虑一个经验风险最小化下的监督学习回归任务，其目标是选择一个常数预测值 $\\hat{y} \\in \\mathbb{R}$，以最小化在带噪声标签模型上的期望损失。设真实标签为 $y = 0$，观测标签为 $y_{\\text{obs}} = y + \\eta$，其中对抗性标签噪声 $\\eta$ 由一个两点分布定义：$\\eta = 0$ 的概率为 $1 - p$，$\\eta = \\delta$ 的概率为 $p$。标量 $p \\in [0,1]$ 是一个以小数或分数形式给出的已知概率，$\\delta  0$ 是对抗性偏移的已知幅度。\n\n将单样本残差定义为 $r = y_{\\text{obs}} - \\hat{y}$，期望风险定义为\n$$\nR(\\hat{y};p,\\delta,\\ell) = \\mathbb{E}[\\ell(r)] = (1-p)\\,\\ell(-\\hat{y}) + p\\,\\ell(\\delta - \\hat{y}),\n$$\n其中 $\\ell$ 是一个选定的损失函数。考虑以下三种损失：\n1. 绝对误差损失（通常称为 $\\mathcal{L}_1$ 损失）：$\\ell_{\\mathcal{L}_1}(r) = |r|$。\n2. 带阈值 $\\kappa  0$ 的Huber损失：\n$$\n\\ell_{\\text{Huber}}(r;\\kappa) = \n\\begin{cases}\n\\dfrac{1}{2} r^2,  \\text{若 } |r| \\le \\kappa,\\\\\n\\kappa\\left(|r| - \\dfrac{1}{2}\\kappa\\right),  \\text{若 } |r|  \\kappa.\n\\end{cases}\n$$\n在本问题中，使用 $\\kappa = 10$。\n3. 带参数 $\\epsilon  0$ 和 $\\beta \\in (0,1)$ 的广义Charbonnier损失：\n$$\n\\ell_{\\text{GC}}(r;\\epsilon,\\beta) = \\left(r^2 + \\epsilon^2\\right)^{\\beta}.\n$$\n在本问题中，使用 $\\epsilon = 1$ 和 $\\beta = 0.45$。\n\n对于每种损失，定义最优常数预测器\n$$\n\\hat{y}^*_{\\ell}(p,\\delta) \\in \\arg\\min_{\\hat{y} \\in \\mathbb{R}} R(\\hat{y};p,\\delta,\\ell),\n$$\n并将给定损失在 $(p,\\delta)$ 下的鲁棒性得分定义为绝对偏差\n$$\nb_{\\ell}(p,\\delta) = \\left|\\hat{y}^*_{\\ell}(p,\\delta) - y\\right| = \\left|\\hat{y}^*_{\\ell}(p,\\delta)\\right|.\n$$\n\n你的任务是实现一个程序，对于下面测试套件中的每个 $(p,\\delta)$，计算与 $\\ell_{\\mathcal{L}_1}$、$\\ell_{\\text{Huber}}$（$\\kappa=10$）和 $\\ell_{\\text{GC}}$（$\\epsilon=1, \\beta=0.45$）相对应的三个鲁棒性得分 $b_{\\mathcal{L}_1}(p,\\delta)$、$b_{\\text{Huber}}(p,\\delta)$ 和 $b_{\\text{GC}}(p,\\delta)$。对于 $\\mathcal{L}_1$ 损失，在 $p = 0.5$ 时通过选择 $\\hat{y}^*_{\\mathcal{L}_1}(p,\\delta) = 0$ 来解决平局问题。\n\n测试套件：\n- 情况 1：$p = 0.1$, $\\delta = 20$。\n- 情况 2：$p = 0.4$, $\\delta = 50$。\n- 情况 3：$p = 0.6$, $\\delta = 50$。\n- 情况 4：$p = 0.9$, $\\delta = 100$。\n- 情况 5：$p = 0.0$, $\\delta = 10$。\n- 情况 6：$p = 1.0$, $\\delta = 10$。\n\n你的程序应该生成单行输出，包含一个用方括号括起来的逗号分隔列表形式的结果。这个外部列表的每个元素对应于上述顺序的一个测试用例，并且它本身是一个包含该用例的三个浮点数 $[b_{\\mathcal{L}_1}, b_{\\text{Huber}}, b_{\\text{GC}}]$ 的列表。例如，输出格式必须是\n$$\n[\\,[b_{\\mathcal{L}_1}^{(1)},b_{\\text{Huber}}^{(1)},b_{\\text{GC}}^{(1)}],\\,[b_{\\mathcal{L}_1}^{(2)},b_{\\text{Huber}}^{(2)},b_{\\text{GC}}^{(2)}],\\,\\dots,\\, [b_{\\mathcal{L}_1}^{(6)},b_{\\text{Huber}}^{(6)},b_{\\text{GC}}^{(6)}]\\,].\n$$\n不涉及物理单位。不涉及角度。概率 $p$ 以小数形式给出。输出值为浮点数。", "solution": "目标是找到最优常数预测器 $\\hat{y}^*$，以最小化期望风险 $R(\\hat{y})$。风险定义为：\n$$R(\\hat{y};p,\\delta,\\ell) = \\mathbb{E}[\\ell(y_{\\text{obs}} - \\hat{y})] = (1-p)\\,\\ell(-\\hat{y}) + p\\,\\ell(\\delta - \\hat{y})$$\n其中 $y_{\\text{obs}}$ 以概率 $1-p$ 取值 $0$，以概率 $p$ 取值 $\\delta$。真实标签为 $y=0$。最优预测器 $\\hat{y}^*$ 是一个使 $R(\\hat{y})$ 最小化的 $\\mathbb{R}$ 中的值。对于所考虑的凸损失函数，可以通过将风险关于 $\\hat{y}$ 的导数设为零来找到这个最小值。\n\n风险的导数通过链式法则得到：\n$$\\frac{d R}{d \\hat{y}} = (1-p) \\frac{d}{d\\hat{y}}\\ell(-\\hat{y}) + p \\frac{d}{d\\hat{y}}\\ell(\\delta - \\hat{y})$$\n$$\\frac{d R}{d \\hat{y}} = (1-p) \\ell'(-\\hat{y}) \\cdot (-1) + p \\ell'(\\delta - \\hat{y}) \\cdot (-1)$$\n$$\\frac{d R}{d \\hat{y}} = - \\left[ (1-p) \\ell'(-\\hat{y}) + p \\ell'(\\delta - \\hat{y}) \\right]$$\n将此导数设为零，得到最优性条件：\n$$(1-p) \\ell'(-\\hat{y}^*) = -p \\ell'(\\delta - \\hat{y}^*)$$\n我们将针对三种指定的损失函数求解这个方程以得到 $\\hat{y}^*$。然后，鲁棒性得分计算为绝对偏差 $b_{\\ell}(p,\\delta) = |\\hat{y}^*_{\\ell}(p,\\delta)|$。\n\n**1. 绝对误差损失 ($\\ell_{\\mathcal{L}_1}(r) = |r|$)**\n\n绝对误差损失的导数是符号函数，$\\ell'_{\\mathcal{L}_1}(r) = \\text{sgn}(r)$。风险函数为 $R(\\hat{y}) = (1-p)|-\\hat{y}| + p|\\delta-\\hat{y}|$。该函数的最小化器是数据点 $0$ 和 $\\delta$ 的加权中位数。基于次梯度的分析证实了这一点。$R(\\hat{y})$ 的次梯度是：\n$$\\partial R(\\hat{y}) = (1-p)\\,\\text{sgn}(\\hat{y}) - p\\,\\text{sgn}(\\delta-\\hat{y})$$\n我们寻找 $\\hat{y}^*$ 使得 $0 \\in \\partial R(\\hat{y}^*)$。假设 $0  \\hat{y}^*  \\delta$，则导数为 $1-2p$。\n- 如果 $p  0.5$，则 $1-2p > 0$。风险在 $(0, \\delta)$ 上是递增的，所以最小值在 $\\hat{y}^*_{\\mathcal{L}_1} = 0$。\n- 如果 $p > 0.5$，则 $1-2p  0$。风险在 $(0, \\delta)$ 上是递减的，所以最小值在 $\\hat{y}^*_{\\mathcal{L}_1} = \\delta$。\n- 如果 $p = 0.5$，风险在 $[0, \\delta]$ 上是平坦的，意味着此区间内的任何值都是最小化器。问题指定了平局决胜规则 $\\hat{y}^*_{\\mathcal{L}_1} = 0$。\n因此，最优预测器是：\n$$\\hat{y}^*_{\\mathcal{L}_1}(p,\\delta) = \\begin{cases} 0  \\text{若 } p \\le 0.5 \\\\ \\delta  \\text{若 } p > 0.5 \\end{cases}$$\n鲁棒性得分为 $b_{\\mathcal{L}_1}(p,\\delta) = |\\hat{y}^*_{\\mathcal{L}_1}(p,\\delta)|$。\n\n**2. Huber损失 ($\\ell_{\\text{Huber}}(r; \\kappa)$)**\n\n当 $\\kappa=10$ 时，Huber损失的导数是 $\\ell'_{\\text{Huber}}(r;10) = \\text{clip}(r, -10, 10)$。最优性条件是：\n$$(1-p)\\,\\text{clip}(-\\hat{y}^*, -10, 10) = -p\\,\\text{clip}(\\delta - \\hat{y}^*, -10, 10)$$\n我们分段进行分析。我们假设 $0  \\hat{y}^*  \\delta$。\n- **情况 1**: 两个参数都在二次区域内：$|\\hat{y}^*| \\le 10$ 且 $|\\delta-\\hat{y}^*| \\le 10$。\n条件变为 $(1-p)(-\\hat{y}^*) = -p(\\delta - \\hat{y}^*)$，简化后得到 $\\hat{y}^* = p\\delta$。此解在 $p\\delta \\le 10$ 和 $\\delta(1-p) \\le 10$ 时有效。\n\n- **情况 2**: 左项是线性的，右项是二次的：$\\hat{y}^* > 10$ 且 $\\delta-\\hat{y}^* \\le 10$。\n条件变为 $(1-p)(-10) = -p(\\delta - \\hat{y}^*)$，解得 $\\hat{y}^* = \\delta - \\frac{10(1-p)}{p}$。此情况适用于 $p > 0.5$ 且结果与假设一致，这在 $p\\delta > 10$ 时成立。\n\n- **情况 3**: 左项是二次的，右项是线性的：$\\hat{y}^* \\le 10$ 且 $\\delta-\\hat{y}^* > 10$。\n条件变为 $(1-p)(-\\hat{y}^*) = -p(10)$，解得 $\\hat{y}^* = \\frac{10p}{1-p}$。此情况适用于 $p  0.5$ 且 $\\delta(1-p)>10$。\n\n综合这些情况，得到 $\\hat{y}^*_{\\text{Huber}}$ 的解：\n- 如果 $p \\le 0.5$:\n  $$\\hat{y}^*_{\\text{Huber}} = \\begin{cases} p\\delta  \\text{若 } \\delta(1-p) \\le 10 \\\\ \\frac{10p}{1-p}  \\text{若 } \\delta(1-p) > 10 \\end{cases}$$\n- 如果 $p > 0.5$:\n  $$\\hat{y}^*_{\\text{Huber}} = \\begin{cases} p\\delta  \\text{若 } p\\delta \\le 10 \\\\ \\delta - \\frac{10(1-p)}{p}  \\text{若 } p\\delta > 10 \\end{cases}$$\n对于 $p=0$ 和 $p=1$ 的边界情况，此逻辑正确地得到 $\\hat{y}^*=0$ 和 $\\hat{y}^*=\\delta$。鲁棒性得分为 $b_{\\text{Huber}}(p,\\delta) = |\\hat{y}^*_{\\text{Huber}}(p,\\delta)|$。\n\n**3. 广义Charbonnier损失 ($\\ell_{\\text{GC}}(r; \\epsilon, \\beta)$)**\n\n当 $\\epsilon=1$ 和 $\\beta=0.45$ 时，损失为 $\\ell_{\\text{GC}}(r) = (r^2+1)^{0.45}$。其导数为 $\\ell'_{\\text{GC}}(r) = 2\\beta r (r^2+\\epsilon^2)^{\\beta-1} = 0.9 r (r^2+1)^{-0.55}$。\n最优性条件为 $(1-p)\\ell'_{\\text{GC}}(-\\hat{y}^*) = -p\\ell'_{\\text{GC}}(\\delta - \\hat{y}^*)$。代入导数得到：\n$$(1-p) [0.9(-\\hat{y}^*)((-\\hat{y}^*)^2+1)^{-0.55}] = -p [0.9(\\delta-\\hat{y}^*)((\\delta-\\hat{y}^*)^2+1)^{-0.55}]$$\n简化并整理各项，我们得到关于 $\\hat{y}^*$ 的方程：\n$$(1-p)\\hat{y}^*(\\hat{y}^{*2}+1)^{-0.55} - p(\\delta-\\hat{y}^*)((\\delta-\\hat{y}^*)^2+1)^{-0.55} = 0$$\n这是一个无法以闭合形式求解的非线性方程。我们必须用数值方法求根。设 $g(\\hat{y})$ 为方程的左侧。\n- 对于 $p=0$，方程变为 $\\hat{y}^*(\\hat{y}^{*2}+1)^{-0.55} = 0$，这意味着 $\\hat{y}^*_{\\text{GC}} = 0$。\n- 对于 $p=1$，方程变为 $-(\\delta-\\hat{y}^*)((\\delta-\\hat{y}^*)^2+1)^{-0.55} = 0$，这意味着 $\\hat{y}^*_{\\text{GC}} = \\delta$。\n- 对于 $p \\in (0,1)$，我们可以观察到 $g(0)  0$ 和 $g(\\delta) > 0$。由于 $g(\\hat{y})$ 在 $0$ 和 $\\delta$ 之间是连续且单调的，因此存在唯一的根 $\\hat{y}^*_{\\text{GC}} \\in (0, \\delta)$。可以使用数值方法（如二分法或Brent法）找到此根。\n鲁棒性得分为 $b_{\\text{GC}}(p,\\delta) = |\\hat{y}^*_{\\text{GC}}(p,\\delta)|$。\n\n该实现将为每个测试用例计算这三个得分。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import brentq\n\ndef solve():\n    \"\"\"\n    Computes robustness scores for L1, Huber, and Generalized Charbonnier losses\n    for a set of test cases.\n    \"\"\"\n    \n    # Loss function parameters\n    HUBER_KAPPA = 10.0\n    GC_EPSILON = 1.0\n    GC_BETA = 0.45\n\n    test_cases = [\n        (0.1, 20.0),  # Case 1\n        (0.4, 50.0),  # Case 2\n        (0.6, 50.0),  # Case 3\n        (0.9, 100.0), # Case 4\n        (0.0, 10.0),  # Case 5\n        (1.0, 10.0),  # Case 6\n    ]\n\n    def get_l1_bias(p, delta):\n        \"\"\"Computes the bias for the L1 loss.\"\"\"\n        if p > 0.5:\n            y_star = delta\n        else: # p = 0.5, including tie-breaking at p = 0.5\n            y_star = 0.0\n        return abs(y_star)\n\n    def get_huber_bias(p, delta, kappa):\n        \"\"\"Computes the bias for the Huber loss.\"\"\"\n        if p = 0.5:\n            if delta * (1.0 - p) = kappa:\n                y_star = p * delta\n            else:\n                y_star = (p * kappa) / (1.0 - p)\n        else: # p > 0.5\n            if p * delta = kappa:\n                y_star = p * delta\n            else:\n                y_star = delta - (kappa * (1.0 - p)) / p\n        return abs(y_star)\n\n    def get_gc_bias(p, delta, epsilon, beta):\n        \"\"\"Computes the bias for the Generalized Charbonnier loss.\"\"\"\n        if p == 0.0:\n            return 0.0\n        if p == 1.0:\n            return float(delta)\n\n        # Define the function whose root we need to find.\n        # This is derived from setting the derivative of the expected risk to zero.\n        def root_function(y_hat):\n            term1 = (1.0 - p) * y_hat * ((y_hat**2 + epsilon**2)**(beta - 1.0))\n            term2 = p * (delta - y_hat) * (((delta - y_hat)**2 + epsilon**2)**(beta - 1.0))\n            return term1 - term2\n\n        # Use Brent's method to find the root in the interval [0, delta].\n        # The function has opposite signs at the interval endpoints for p in (0, 1).\n        y_star = brentq(root_function, 0.0, delta)\n        return abs(y_star)\n\n    results = []\n    for p, delta in test_cases:\n        b_l1 = get_l1_bias(p, delta)\n        b_huber = get_huber_bias(p, delta, HUBER_KAPPA)\n        b_gc = get_gc_bias(p, delta, GC_EPSILON, GC_BETA)\n        \n        results.append([b_l1, b_huber, b_gc])\n\n    # Format the final output string as per requirements.\n    outer_parts = [f\"[{','.join(map(str, inner_list))}]\" for inner_list in results]\n    final_output = f\"[{','.join(outer_parts)}]\"\n    \n    print(final_output)\n\nsolve()\n```", "id": "3178857"}, {"introduction": "前面的练习专注于最小化单点的预测误差。然而，在许多应用中，正确预测样本之间的相对顺序，其重要性甚至超过了预测它们的精确值。我们可以通过在损失函数中引入排序目标，使回归模型能“感知顺序”，例如，使用成对排序损失来惩罚那些预测顺序与真实顺序相悖的样本对。这个高级练习 ([@problem_id:3178841]) 将指导你实现一个混合模型，它同时优化回归准确度（MSE）和排序一致性（成对铰链损失），让你掌握设计和实现复杂目标函数的能力，以满足超越简单数值预测的复合任务需求。", "problem": "您的任务是实现一个用于线性回归模型的批量梯度下降学习器，该学习器在预测连续结果的同时，通过成对铰链惩罚来强制真实值与预测值之间的顺序一致性。您的实现必须从监督学习的第一性原理推导得出，并且必须输出一个单一指标，即在优化后对训练数据计算的 Kendall’s $\\tau$ (tau)。\n\n上下文是使用线性预测器进行回归的监督学习。您将从以下基本基础和核心定义开始：\n\n- 经验风险最小化 (ERM)：给定数据 $\\{(x_i, y_i)\\}_{i=1}^n$，其中 $x_i \\in \\mathbb{R}^d$ 且 $y_i \\in \\mathbb{R}$，通过最小化由明确定义的损失构建的经验风险来学习参数 $w \\in \\mathbb{R}^d$。\n- 线性预测：模型对每个 $i$ 预测 $\\hat y_i = w^\\top x_i$。\n- 均方误差 (MSE)：点态误差为 $(y_i - \\hat y_i)^2$，经验平均值为 $\\frac{1}{n}\\sum_{i=1}^n (y_i - \\hat y_i)^2$。\n- 通过铰链惩罚实现的成对排序一致性：对于每个无序对 $\\{i, j\\}$（其中 $i  j$），惩罚项鼓励 $y_i - y_j$ 的符号与 $\\hat y_i - \\hat y_j$ 的符号相匹配。一对的铰链项为 $\\max\\!\\big(0,\\,-(y_i - y_j)(\\hat y_i - \\hat y_j)\\big)$，对于一致对为零，对于不一致对为正。\n- Kendall’s $\\tau$：一种等级相关性，定义为 $\\tau = \\frac{C - D}{T}$，其中 $C$ 是一致对的数量，$D$ 是不一致对的数量，$T = \\frac{n(n-1)}{2}$ 是无序对的总数。使用约定，即平局对分子的贡献为零，且不改变分母。\n\n您的程序必须：\n\n1.  使用以下生成过程为每个测试用例构建合成数据集：\n    -   从标准正态分布中独立抽取特征 $x_i \\in \\mathbb{R}^d$。\n    -   从标准正态分布中抽取一个真实权重向量 $w^\\star \\in \\mathbb{R}^d$，除非明确指定为零向量。\n    -   抽取独立噪声 $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$。\n    -   设置响应 $y_i = (w^\\star)^\\top x_i + \\epsilon_i$。\n    -   所有随机抽取必须可通过给定的整数种子进行复现。\n\n2.  最小化组合经验风险\n    $$\n    \\mathcal{L}(w) \\;=\\; \\frac{1}{n}\\sum_{i=1}^n (y_i - w^\\top x_i)^2 \\;+\\; \\beta \\cdot \\frac{1}{T} \\sum_{1 \\le i  j \\le n} \\max\\!\\big(0,\\,-(y_i - y_j)\\big(w^\\top x_i - w^\\top x_j\\big)\\big),\n    $$\n    其中 $\\beta$ 是一个控制排序惩罚强度的非负权重，且 $T = \\frac{n(n-1)}{2}$。\n\n3.  使用固定学习率的批量梯度下降法，在固定的步数内更新 $w$。您必须直接从上述定义推导并实现梯度更新。请勿使用任何自动微分或外部优化包。\n\n4.  在每个测试用例优化后，计算训练数据上真实响应 $\\{y_i\\}$ 与预测 $\\{\\hat y_i\\}$ 之间的 Kendall’s $\\tau$。\n\n5.  生成一行输出，其中包含所有测试用例的 Kendall’s $\\tau$ 值，格式为逗号分隔的列表，并用方括号括起来，例如 $\\texttt{[0.123,0.456,0.789]}$。\n\n测试套件：\n实现以下五个测试用例，每个用例由一个元组 $(n, d, \\sigma, \\beta, \\text{lr}, \\text{steps}, \\text{seed}, w^\\star\\!\\!=\\!0)$ 指定，其中 $n$ 是样本数，$d$ 是特征维度，$\\sigma$ 是噪声标准差，$\\beta$ 是排序惩罚权重，$\\text{lr}$ 是学习率，$\\text{steps}$ 是梯度步数，$\\text{seed}$ 是随机种子，以及 $w^\\star\\!\\!=\\!0$ 指示真实权重向量是否为零向量：\n\n- 案例 A (理想情况)：$(n, d, \\sigma, \\beta, \\text{lr}, \\text{steps}, \\text{seed}, w^\\star\\!\\!=\\!0) = (\\,30,\\,3,\\,0.2,\\,1.0,\\,0.05,\\,600,\\,7,\\,\\text{False}\\,)$\n- 案例 B (高噪声)：$(\\,30,\\,3,\\,1.2,\\,1.0,\\,0.05,\\,600,\\,11,\\,\\text{False}\\,)$\n- 案例 C (无排序项基线)：$(\\,30,\\,3,\\,0.2,\\,0.0,\\,0.05,\\,600,\\,7,\\,\\text{False}\\,)$\n- 案例 D (退化响应，常数 y)：$(\\,20,\\,4,\\,0.0,\\,1.0,\\,0.1,\\,300,\\,19,\\,\\text{True}\\,)$\n- 案例 E (边界条件，最小对数)：$(\\,2,\\,2,\\,0.0,\\,1.0,\\,0.1,\\,100,\\,3,\\,\\text{False}\\,)$\n\n最终输出格式：\n您的程序应生成一行输出，其中包含五个案例的 Kendall’s $\\tau$ 结果，格式为逗号分隔的列表，用方括号括起来，并严格按照案例 A 到 E 的顺序，例如 $\\texttt{[0.XXX,0.YYY,0.ZZZ,0.UU,0.VV]}$。不应打印任何额外文本。", "solution": "用户提供的问题已经过评估，并被确定为有效。该问题具有科学依据，定义明确，客观，并包含所有必要信息以获得唯一且可验证的解决方案。我们现在将进行完整的推导和实现。\n\n该问题要求实现一个批量梯度下降算法来训练一个线性回归模型。需要最小化的目标函数是均方误差（MSE）和成对排序惩罚的组合。训练后，使用 Kendall’s $\\tau$ 等级相关系数在训练数据上评估模型的性能。\n\n模型是一个线性预测器，定义为 $\\hat{y}_i = w^\\top x_i$，其中 $x_i \\in \\mathbb{R}^d$ 是一个特征向量，$w \\in \\mathbb{R}^d$ 是待学习的权重向量。\n\n经验风险，作为损失函数 $\\mathcal{L}(w)$，由下式给出：\n$$\n\\mathcal{L}(w) = \\underbrace{\\frac{1}{n}\\sum_{i=1}^n (y_i - w^\\top x_i)^2}_{\\mathcal{L}_{MSE}(w)} + \\beta \\cdot \\underbrace{\\frac{1}{T} \\sum_{1 \\le i  j \\le n} \\max\\!\\big(0,\\,-(y_i - y_j)(w^\\top x_i - w^\\top x_j)\\big)}_{\\mathcal{L}_{rank}(w)}\n$$\n其中 $n$ 是样本数量，$y_i \\in \\mathbb{R}$ 是真实的连续结果，$\\beta \\ge 0$ 是一个平衡两个损失分量的超参数，$T = \\frac{n(n-1)}{2}$ 是样本中唯一对的总数。\n\n优化算法是批量梯度下降，它根据以下规则迭代更新权重向量 $w$：\n$$\nw_{t+1} = w_t - \\eta \\cdot \\nabla_w \\mathcal{L}(w_t)\n$$\n其中 $\\eta$ 是学习率，$\\nabla_w \\mathcal{L}(w_t)$ 是损失函数关于 $w$ 的梯度，在当前权重向量 $w_t$ 处计算。我们将权重向量初始化为 $w_0 = 0$。\n\n由于梯度算子的线性性，我们可以分别计算损失函数每个分量的梯度：\n$$\n\\nabla_w \\mathcal{L}(w) = \\nabla_w \\mathcal{L}_{MSE}(w) + \\beta \\nabla_w \\mathcal{L}_{rank}(w)\n$$\n\n首先，我们推导 MSE 项 $\\mathcal{L}_{MSE}(w)$ 的梯度：\n$$\n\\nabla_w \\mathcal{L}_{MSE}(w) = \\nabla_w \\left( \\frac{1}{n}\\sum_{i=1}^n (y_i - w^\\top x_i)^2 \\right)\n$$\n$$\n\\nabla_w \\mathcal{L}_{MSE}(w) = \\frac{1}{n} \\sum_{i=1}^n \\nabla_w (y_i - w^\\top x_i)^2\n$$\n使用链式法则，其中 $\\nabla_w (w^\\top x_i) = x_i$：\n$$\n\\nabla_w \\mathcal{L}_{MSE}(w) = \\frac{1}{n} \\sum_{i=1}^n 2(y_i - w^\\top x_i) \\cdot (-\\nabla_w (w^\\top x_i)) = \\frac{1}{n} \\sum_{i=1}^n -2(y_i - w^\\top x_i) x_i\n$$\n这可以紧凑地用矩阵表示法表示。设 $X$ 为 $n \\times d$ 的设计矩阵，其中每行为 $x_i^\\top$，$y$ 为真实结果的列向量。预测为 $\\hat{y} = Xw$。梯度为：\n$$\n\\nabla_w \\mathcal{L}_{MSE}(w) = -\\frac{2}{n} X^\\top (y - Xw)\n$$\n\n其次，我们推导排序惩罚项 $\\mathcal{L}_{rank}(w)$ 的梯度。该项涉及铰链损失函数 $h(z) = \\max(0, z)$，它在 $z=0$ 处不可微。我们将使用其次梯度。对于基于梯度的方法，一个标准的选择是当 $z>0$ 时定义导数为 $1$，当 $z \\le 0$ 时定义为 $0$。\n令 $z_{ij}(w) = -(y_i - y_j)(w^\\top x_i - w^\\top x_j) = -(y_i - y_j)w^\\top(x_i - x_j)$。单个对 $\\{i,j\\}$ 的排序损失项为 $\\max(0, z_{ij}(w))$。其关于 $w$ 的梯度为：\n$$\n\\nabla_w \\max(0, z_{ij}(w)) = \\mathbb{I}(z_{ij}(w) > 0) \\cdot \\nabla_w z_{ij}(w)\n$$\n其中 $\\mathbb{I}(\\cdot)$ 是指示函数。条件 $z_{ij}(w) > 0$ 等价于 $-(y_i-y_j)(\\hat{y}_i-\\hat{y}_j) > 0$，这意味着对 $\\{i,j\\}$ 是不一致的（预测顺序与真实顺序相反）。\n$z_{ij}(w)$ 关于 $w$ 的梯度是：\n$$\n\\nabla_w z_{ij}(w) = \\nabla_w \\big( -(y_i - y_j)w^\\top(x_i - x_j) \\big) = -(y_i - y_j)(x_i - x_j)\n$$\n对所有满足 $i  j$ 的对 $\\{i, j\\}$ 求和，排序损失的梯度为：\n$$\n\\nabla_w \\mathcal{L}_{rank}(w) = \\frac{1}{T} \\sum_{1 \\le i  j \\le n} \\mathbb{I}\\big( (y_i - y_j)(\\hat{y}_i - \\hat{y}_j)  0 \\big) \\cdot \\big( -(y_i - y_j)(x_i - x_j) \\big)\n$$\n\n结合这两个分量，完整的批量梯度是：\n$$\n\\nabla_w \\mathcal{L}(w) = -\\frac{2}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)x_i - \\frac{\\beta}{T} \\sum_{\\substack{1 \\le i  j \\le n \\\\ \\text{不一致对}}} (y_i - y_j)(x_i - x_j)\n$$\n该梯度在梯度下降算法的每一步中使用所有 $n$ 个样本进行计算。\n\n最后，在优化过程完成后，我们计算 Kendall's Tau。给定真实值 $\\{y_i\\}$ 和最终预测 $\\{\\hat{y}_i\\}$，我们将每个对 $\\{i,j\\}$ 分类为一致、不一致或平局。\n- 如果 $(y_i - y_j)$ 和 $(\\hat{y}_i - \\hat{y}_j)$ 符号相同，则该对是一致的。设 $C$ 为此类对的数量。\n- 如果它们符号相反，则该对是不一致的。设 $D$ 为此类对的数量。\n- 如果 $y_i = y_j$ 或 $\\hat{y}_i = \\hat{y}_j$，则该对是平局。在分子求和中忽略平局对。\n\n然后按规定计算 Kendall's Tau：\n$$\n\\tau = \\frac{C - D}{T} = \\frac{C - D}{\\frac{1}{2}n(n-1)}\n$$\n\n实现将遵循这些推导，为每个测试用例创建指定的合成数据，运行批量梯度下降优化器，并计算最终的 Kendall’s $\\tau$ 值。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements a batch gradient descent learner for linear regression with a pairwise \n    hinge penalty and evaluates performance using Kendall's tau.\n    \"\"\"\n    test_cases = [\n        # (n, d, sigma, beta, lr, steps, seed, w_star_is_zero)\n        (30, 3, 0.2, 1.0, 0.05, 600, 7, False),      # Case A: Happy path\n        (30, 3, 1.2, 1.0, 0.05, 600, 11, False),     # Case B: High noise\n        (30, 3, 0.2, 0.0, 0.05, 600, 7, False),      # Case C: No ranking term\n        (20, 4, 0.0, 1.0, 0.1, 300, 19, True),       # Case D: Degenerate responses\n        (2, 2, 0.0, 1.0, 0.1, 100, 3, False),        # Case E: Minimal pairs\n    ]\n\n    results = []\n    for case in test_cases:\n        n, d, sigma, beta, lr, steps, seed, w_star_is_zero = case\n        \n        # 1. Construct synthetic dataset using the generative process.\n        rng = np.random.default_rng(seed)\n        X = rng.standard_normal(size=(n, d))\n        \n        if w_star_is_zero:\n            w_star = np.zeros(d)\n        else:\n            w_star = rng.standard_normal(size=d)\n            \n        noise = rng.normal(loc=0.0, scale=sigma, size=n)\n        y = X @ w_star + noise\n\n        # 2. Minimize the empirical risk using batch gradient descent.\n        # Initialize weight vector to zeros.\n        w = np.zeros(d)\n        \n        # Total number of pairs for ranking loss normalization.\n        T = n * (n - 1) / 2 if n >= 2 else 0\n\n        for _ in range(steps):\n            y_hat = X @ w\n            \n            # --- Gradient of Mean Squared Error term ---\n            residuals = y - y_hat\n            grad_mse = -2.0 / n * X.T @ residuals\n            \n            # --- Gradient of Pairwise Hinge Penalty term ---\n            grad_rank = np.zeros(d)\n            if beta > 0 and T > 0:\n                # Sum over all discordant pairs {i, j}\n                for i in range(n):\n                    for j in range(i + 1, n):\n                        y_diff = y[i] - y[j]\n                        x_diff = X[i, :] - X[j, :]\n                        y_hat_diff = y_hat[i] - y_hat[j]\n                        \n                        # A pair is discordant if (y_i-y_j)*(y_hat_i-y_hat_j)  0.\n                        # The subgradient is non-zero only for these pairs.\n                        if y_diff * y_hat_diff  0:\n                            grad_rank += -(y_diff * x_diff)\n                \n                grad_rank /= T\n\n            # --- Combine gradients and update weights ---\n            grad_total = grad_mse + beta * grad_rank\n            w -= lr * grad_total\n\n        # 3. Compute final predictions after optimization.\n        y_hat_final = X @ w\n        \n        # 4. Compute Kendall’s tau on the training data.\n        tau = 0.0\n        if T > 0:\n            concordant_pairs = 0\n            discordant_pairs = 0\n            for i in range(n):\n                for j in range(i + 1, n):\n                    y_diff = y[i] - y[j]\n                    y_hat_diff = y_hat_final[i] - y_hat_final[j]\n                    \n                    # As per problem, ties contribute zero to the numerator.\n                    if y_diff == 0 or y_hat_diff == 0:\n                        continue\n                    \n                    if y_diff * y_hat_diff > 0:\n                        concordant_pairs += 1\n                    else: # y_diff * y_hat_diff  0\n                        discordant_pairs += 1\n            \n            tau = (concordant_pairs - discordant_pairs) / T\n\n        results.append(tau)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3178841"}]}