{"hands_on_practices": [{"introduction": "K-折交叉验证是评估模型泛化能力的重要工具，但标准的K-折交叉验证在处理不平衡数据集时可能会产生有偏的估计。本实践将通过一个理论模型，引导您量化在类别严重不平衡的情况下，非分层抽样相对于分层抽样所导致的额外误差。通过这个练习，您将深刻理解为何分层抽样在许多现实场景中是必不可少的，并掌握其背后的统计学原理。[@problem_id:3134712]", "problem": "考虑一个类别严重不平衡的二分类问题。设类别标签为 $Y \\in \\{0,1\\}$，其总体先验概率为 $\\mathbb{P}(Y=1)=\\pi$ 和 $\\mathbb{P}(Y=0)=1-\\pi$，其中 $\\pi \\ll 0.5$。给定单个实值特征 $X$，假设类别条件分布是方差相等的高斯分布：$X \\mid Y=0 \\sim \\mathcal{N}(0,1)$ 和 $X \\mid Y=1 \\sim \\mathcal{N}(\\mu,1)$，其中 $\\mu>0$ 为已知。考虑对一个大小为 $N$ 的数据集进行 $k$ 折交叉验证（Cross-Validation, CV），其中 $k$ 个折的大小相等。\n\n使用以下基本原理：\n- 在类别条件密度和先验已知的情况下，贝叶斯分类器使用似然比检验，当方差相等时，这简化为对 $X$ 的阈值规则。\n- 错分风险定义为总体误差 $\\mathbb{P}(\\hat{Y}\\neq Y)$，在真实数据分布下计算。\n- 非分层 $k$ 折划分是将 $N$ 个样本随机分成 $k$ 个折，不考虑类别标签。\n- 分层 $k$ 折划分确保每个折尽可能地反映总体的类别比例。在本问题中，假设是精确分层：$N\\pi$ 是一个整数，并且每个折都精确包含来自少数类的 $N\\pi/k$ 个样本和来自多数类的 $N(1-\\pi)/k$ 个样本。\n\n将在一个折内训练的分类器定义为使用从该折的训练部分估计出的经验类别先验 $\\hat{\\pi}$ 的似然比阈值规则，同时使用已知的真实类别条件密度。具体而言，决策规则是“如果 $X \\ge t(\\hat{\\pi})$ 则预测 $Y=1$，否则预测 $Y=0$”，其中 $t(\\hat{\\pi})$ 是由带有先验 $\\hat{\\pi}$ 的似然比检验所隐含的阈值。该折的测试误差是在从相同总体中抽样的数据上测量的。\n\n您必须：\n1. 从第一性原理出发，从似然比检验开始，推导高斯等方差情况下的决策阈值 $t(\\hat{\\pi})$，以及相应的错分风险 $R(t)$ 作为 $t$、$\\pi$ 和 $\\mu$ 的函数。\n2. 在非分层 $k$ 折交叉验证下，将训练先验 $\\hat{\\pi}$ 建模为一个由随机分折引起的随机变量。设 $M=N\\pi$ 为少数类样本总数（根据假设为整数），$n_{\\text{train}}=N(k-1)/k$ 为每折的训练集大小。对于给定的折，训练集中的少数类样本数 $m$ 服从参数为 $(N, M, n_{\\text{train}})$ 的超几何分布。因此，$\\hat{\\pi}=m/n_{\\text{train}}$。利用这一点，计算预期的非分层交叉验证风险，即 $R\\big(t(\\hat{\\pi})\\big)$ 关于 $m$ 的超几何分布的期望值。\n3. 在具有精确每折类别比例的分层 $k$ 折交叉验证下，训练先验恰好等于总体先验 $\\pi$，因此分层交叉验证风险等于 $R\\big(t(\\pi)\\big)$。\n4. 将由非分层引起的误差膨胀 $\\Delta$ 量化为\n$$\n\\Delta = \\mathbb{E}\\left[R\\big(t(\\hat{\\pi})\\big)\\right] - R\\big(t(\\pi)\\big).\n$$\n为下面指定的每个测试用例计算 $\\Delta$。\n\n您必须实现一个完整的、可运行的程序，该程序对每个参数元组 $(N,k,\\pi,\\mu)$，通过精确的超几何分布计算单折的预期非分层交叉验证风险、分层交叉验证风险，并以浮点数形式输出膨胀 $\\Delta$。通过解释阈值规则的极限情况，正确处理退化情况 $\\hat{\\pi}=0$ 和 $\\hat{\\pi}=1$：如果 $\\hat{\\pi}=0$，分类器总是预测 $Y=0$，产生的风险为 $R=\\pi$；如果 $\\hat{\\pi}=1$，分类器总是预测 $Y=1$，产生的风险为 $R=1-\\pi$。\n\n测试套件：\n- 用例 $1$ (正常路径): $(N,k,\\pi,\\mu) = (500,5,0.05,2.0)$。\n- 用例 $2$ (小数据集，仍严重不平衡): $(N,k,\\pi,\\mu) = (100,10,0.10,1.5)$。\n- 用例 $3$ (大数据集，极端不平衡): $(N,k,\\pi,\\mu) = (5000,10,0.01,1.0)$。\n- 用例 $4$ (中等数据集，强可分性): $(N,k,\\pi,\\mu) = (1200,4,0.03,3.0)$。\n\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果（例如，$[result_1,result_2,result_3,result_4]$），其中每个 $result_i$ 是为用例 $i$ 计算的 $\\Delta$，四舍五入到 $6$ 位小数。不应打印任何其他文本。", "solution": "该问题要求我们量化对于一个类别严重不平衡的二分类器，使用非分层 $k$ 折交叉验证与分层 $k$ 折交叉验证相比所产生的误差膨胀，记为 $\\Delta$。该分析基于一个涉及高斯类别条件分布的特定理论设置。我们将首先推导必要的理论组成部分，然后将它们应用于指定的交叉验证方案。\n\n### 1. 决策阈值和错分风险\n\n分类器的决策基于似然比检验，该检验比较两个类别的后验概率。对于给定的特征值 $X$，如果 $\\mathbb{P}(Y=1|X) > \\mathbb{P}(Y=0|X)$，分类器预测类别为 $Y=1$。使用贝叶斯定理，这等价于 $\\frac{p(X|Y=1)\\mathbb{P}(Y=1)}{p(X)} > \\frac{p(X|Y=0)\\mathbb{P}(Y=0)}{p(X)}$，简化为似然比检验：\n$$\n\\frac{p(X|Y=1)}{p(X|Y=0)} > \\frac{\\mathbb{P}(Y=0)}{\\mathbb{P}(Y=1)}\n$$\n问题指定分类器使用真实的类别条件密度，但使用从训练数据中得到的经验估计值 $\\hat{\\pi}$ 来估计先验概率 $\\mathbb{P}(Y=1)$。因此，决策规则变为：\n$$\n\\frac{p(X|Y=1)}{p(X|Y=0)} > \\frac{1-\\hat{\\pi}}{\\hat{\\pi}}\n$$\n类别条件密度给定为 $X \\mid Y=0 \\sim \\mathcal{N}(0,1)$ 和 $X \\mid Y=1 \\sim \\mathcal{N}(\\mu,1)$。它们的概率密度函数 (PDF) 是：\n$$\np(X|Y=0) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{X^2}{2}\\right)\n$$\n$$\np(X|Y=1) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{(X-\\mu)^2}{2}\\right)\n$$\n似然比为：\n$$\n\\frac{p(X|Y=1)}{p(X|Y=0)} = \\frac{\\exp\\left(-\\frac{(X-\\mu)^2}{2}\\right)}{\\exp\\left(-\\frac{X^2}{2}\\right)} = \\exp\\left(\\frac{X^2 - (X-\\mu)^2}{2}\\right) = \\exp\\left(\\frac{X^2 - (X^2 - 2\\mu X + \\mu^2)}{2}\\right) = \\exp\\left(\\mu X - \\frac{\\mu^2}{2}\\right)\n$$\n将此代入决策规则不等式：\n$$\n\\exp\\left(\\mu X - \\frac{\\mu^2}{2}\\right) > \\frac{1-\\hat{\\pi}}{\\hat{\\pi}}\n$$\n对两边取自然对数（这是一个保持不等式的单调变换）：\n$$\n\\mu X - \\frac{\\mu^2}{2} > \\ln\\left(\\frac{1-\\hat{\\pi}}{\\hat{\\pi}}\\right)\n$$\n由于给定 $\\mu > 0$，我们可以解出 $X$ 来找到决策阈值 $t(\\hat{\\pi})$：\n$$\nX > \\frac{1}{\\mu}\\left(\\frac{\\mu^2}{2} + \\ln\\left(\\frac{1-\\hat{\\pi}}{\\hat{\\pi}}\\right)\\right)\n$$\n因此，作为经验先验 $\\hat{\\pi}$ 的函数的决策阈值为：\n$$\nt(\\hat{\\pi}) = \\frac{\\mu}{2} + \\frac{1}{\\mu}\\ln\\left(\\frac{1-\\hat{\\pi}}{\\hat{\\pi}}\\right)\n$$\n分类器的规则是，如果 $X \\geq t(\\hat{\\pi})$ 则预测 $Y=1$，否则预测 $Y=0$。\n\n接下来，我们推导给定阈值 $t$ 的错分风险 $R(t)$。该风险是总体错误率，使用真实的总体先验 $\\pi$ 进行评估。它是一类错误和二类错误概率的总和，由真实的类别先验加权：\n$$\nR(t) = \\mathbb{P}(\\text{predict } 1 \\mid Y=0)\\mathbb{P}(Y=0) + \\mathbb{P}(\\text{predict } 0 \\mid Y=1)\\mathbb{P}(Y=1)\n$$\n$$\nR(t) = \\mathbb{P}(X \\ge t \\mid Y=0)(1-\\pi) + \\mathbb{P}(X < t \\mid Y=1)\\pi\n$$\n设 $\\Phi(\\cdot)$ 为标准正态分布 $\\mathcal{N}(0,1)$ 的累积分布函数 (CDF)。\n对于第一项，由于 $X \\mid Y=0 \\sim \\mathcal{N}(0,1)$，我们有 $\\mathbb{P}(X \\ge t \\mid Y=0) = 1 - \\Phi(t)$。\n对于第二项，由于 $X \\mid Y=1 \\sim \\mathcal{N}(\\mu,1)$，变量 $X-\\mu$ 服从 $\\mathcal{N}(0,1)$。因此，$\\mathbb{P}(X < t \\mid Y=1) = \\mathbb{P}(X-\\mu < t-\\mu \\mid Y=1) = \\Phi(t-\\mu)$。\n因此，错分风险为：\n$$\nR(t) = (1-\\pi)(1 - \\Phi(t)) + \\pi \\Phi(t-\\mu)\n$$\n\n### 2. 分层与非分层交叉验证风险\n\n**分层交叉验证风险：**\n在分层 $k$ 折划分中，每个折的构造都使其类别比例与整个数据集相同。因此，任何一个折的训练集（包含 $k-1$ 个折）也将具有这个精确的比例。因此，从训练集中估计的经验先验 $\\hat{\\pi}$ 总是等于总体先验 $\\pi$。\n$$\n\\hat{\\pi}_{\\text{strat}} = \\pi\n$$\n所有折的决策阈值都是恒定的：$t_{\\text{strat}} = t(\\pi) = \\frac{\\mu}{2} + \\frac{1}{\\mu}\\ln\\left(\\frac{1-\\pi}{\\pi}\\right)$。这是最优贝叶斯阈值。产生的风险，我们记为 $R_{\\text{strat}}$，即贝叶斯错误率：\n$$\nR_{\\text{strat}} = R(t(\\pi)) = (1-\\pi)(1 - \\Phi(t(\\pi))) + \\pi \\Phi(t(\\pi)-\\mu)\n$$\n\n**非分层交叉验证风险：**\n在非分层划分中，数据被随机划分为 $k$ 个折。一个折的训练数据中少数类样本的数量是一个随机变量。设 $N$ 为总样本量，$M=N\\pi$ 为少数类样本总数，$n_{\\text{train}} = N(k-1)/k$ 为训练集大小。训练集中的少数类样本数 $m$ 服从超几何分布，其参数为总体大小（$N$）、总体中成功次数（$M$）和抽取次数（$n_{\\text{train}}$）。我们将其写为 $m \\sim \\text{Hypergeometric}(N, M, n_{\\text{train}})$。\n其概率质量函数 (PMF) 为 $\\mathbb{P}(m) = \\frac{\\binom{M}{m}\\binom{N-M}{n_{\\text{train}}-m}}{\\binom{N}{n_{\\text{train}}}}$。\n给定折的经验先验是 $\\hat{\\pi} = m/n_{\\text{train}}$，它是一个随机变量。决策阈值 $t(\\hat{\\pi})$ 和相应的风险 $R(t(\\hat{\\pi}))$ 也是随机变量。预期的非分层交叉验证风险是此风险在 $m$ 的分布上的期望值：\n$$\n\\mathbb{E}\\left[R\\big(t(\\hat{\\pi})\\big)\\right] = \\sum_{m} \\mathbb{P}(m) \\cdot R\\left(t\\left(\\frac{m}{n_{\\text{train}}}\\right)\\right)\n$$\n求和是在超几何分布的支撑集上进行的，即 $m \\in [\\max(0, n_{\\text{train}} - (N-M)), \\min(n_{\\text{train}}, M)]$。\n\n问题指定了对 $\\hat{\\pi}=0$ 或 $\\hat{\\pi}=1$ 这种退化情况的处理：\n-   如果 $\\hat{\\pi}=0$ (即 $m=0$)，$\\ln((1-\\hat{\\pi})/\\hat{\\pi}) \\to \\infty$，因此 $t(0) \\to \\infty$。分类器总是预测 $Y=0$。风险为 $R(\\infty) = (1-\\pi)(1-\\Phi(\\infty)) + \\pi \\Phi(\\infty-\\mu) = (1-\\pi) \\cdot 0 + \\pi \\cdot 1 = \\pi$。\n-   如果 $\\hat{\\pi}=1$ (即 $m=n_{\\text{train}}$)，$\\ln((1-\\hat{\\pi})/\\hat{\\pi}) \\to -\\infty$，因此 $t(1) \\to -\\infty$。分类器总是预测 $Y=1$。风险为 $R(-\\infty) = (1-\\pi)(1-\\Phi(-\\infty)) + \\pi \\Phi(-\\infty-\\mu) = (1-\\pi) \\cdot 1 + \\pi \\cdot 0 = 1-\\pi$。\n\n### 3. 误差膨胀 $\\Delta$\n\n误差膨胀 $\\Delta$ 定义为非分层交叉验证下的预期风险与分层交叉验证下的风险之差：\n$$\n\\Delta = \\mathbb{E}\\left[R\\big(t(\\hat{\\pi})\\big)\\right] - R_{\\text{strat}}\n$$\n这个量捕捉了由于非分层折中经验先验估计的可变性而导致的错分误差的平均增加。这种可变性将决策阈值推离最优贝叶斯阈值，并且由于风险函数在其最小值（贝叶斯误差）附近的凸性，预期风险高于在预期先验下的风险。根据琴生不等式，由于风险函数是凸的，$\\mathbb{E}[R(t(\\hat{\\pi}))] \\ge R(t(\\mathbb{E}[\\hat{\\pi}]))$。因为 $\\mathbb{E}[\\hat{\\pi}] = \\pi$，我们预期 $\\Delta \\ge 0$。我们的任务是为给定的测试用例计算这个值。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import hypergeom, norm\n\ndef solve():\n    \"\"\"\n    Computes the error inflation delta for a series of test cases.\n    \"\"\"\n    \n    # Test cases: tuples of (N, k, pi, mu)\n    test_cases = [\n        (500, 5, 0.05, 2.0),\n        (100, 10, 0.10, 1.5),\n        (5000, 10, 0.01, 1.0),\n        (1200, 4, 0.03, 3.0),\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        N, k, pi, mu = case\n        \n        # Ensure N*pi is an integer as per problem statement\n        M = int(round(N * pi))\n        n_train = int(N * (k - 1) / k)\n        \n        # --- 1. Calculate Stratified CV Risk (R_strat) ---\n        # The empirical prior is the true prior\n        pi_strat = pi\n        \n        # Calculate the Bayes optimal threshold t(pi)\n        # logit(pi) = log(pi / (1-pi)), so -log((1-pi)/pi)\n        t_strat = mu / 2.0 - (1.0 / mu) * np.log(pi_strat / (1.0 - pi_strat))\n        \n        # Calculate the risk R(t(pi)), which is the Bayes error rate\n        risk_type1_strat = 1.0 - norm.cdf(t_strat)\n        risk_type2_strat = norm.cdf(t_strat - mu)\n        R_strat = (1.0 - pi) * risk_type1_strat + pi * risk_type2_strat\n        \n        # --- 2. Calculate Expected Non-Stratified CV Risk (E_non_strat) ---\n        \n        # The number of minority samples 'm' in the training set follows a\n        # Hypergeometric distribution.\n        # Scipy's hypergeom(M, n, N) takes:\n        # M: total number of objects (our N)\n        # n: total number of type I objects (our M)\n        # N: number of draws (our n_train)\n        dist = hypergeom(M=N, n=M, N=n_train)\n        \n        # Support of the hypergeometric distribution for m\n        m_min = max(0, n_train - (N - M))\n        m_max = min(n_train, M)\n        \n        E_non_strat = 0.0\n        \n        for m in range(m_min, m_max + 1):\n            prob_m = dist.pmf(m)\n            \n            # If there's no probability mass, skip to avoid unnecessary calculation\n            if prob_m == 0:\n                continue\n\n            pi_hat = m / n_train\n            \n            # Handle edge cases as per problem statement\n            if m == 0:  # pi_hat = 0\n                risk_m = pi\n            elif m == n_train:  # pi_hat = 1\n                risk_m = 1.0 - pi\n            else:\n                # Calculate threshold t(pi_hat) for this m\n                t_m = mu / 2.0 - (1.0 / mu) * np.log(pi_hat / (1.0 - pi_hat))\n                \n                # Calculate risk R(t(pi_hat))\n                risk_type1_m = 1.0 - norm.cdf(t_m)\n                risk_type2_m = norm.cdf(t_m - mu)\n                risk_m = (1.0 - pi) * risk_type1_m + pi * risk_type2_m\n            \n            E_non_strat += prob_m * risk_m\n            \n        # --- 3. Compute Error Inflation Delta ---\n        delta = E_non_strat - R_strat\n        results.append(round(delta, 6))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3134712"}, {"introduction": "数据增强是提升深度学习模型性能和鲁棒性的关键技术，但若与交叉验证结合不当，则可能导致一种被称为“数据泄露”的隐蔽错误。本实践将模拟这一常见陷阱，让您亲手实现两种交叉验证流程：一种是正确的增强方法，另一种则存在泄露。通过比较这两种流程的评估结果，您将量化数据泄露所引入的乐观偏差，从而学会在实践中正确地结合使用数据增强与交叉验证。[@problem_id:3134696]", "problem": "您的任务是设计并实现一个计算实验，用于分析在图像旋转数据增强条件下，统计学习中的 $k$ 折交叉验证 (CV)。该实验旨在量化仅对训练折应用增强与增强泄露到验证折这两种情况的差异。您的程序必须是一个完整、可运行的实现，无需外部输入即可生成所要求的输出。\n\n使用的基本依据和定义：\n- 交叉验证 (CV)：对于给定数据集 $D = \\{(x_i, y_i)\\}_{i=1}^n$ 和一个学习算法，$k$ 折 CV 泛化误差估计量定义为 $k$ 个折上验证损失的平均值。设折为索引集 $V_1, \\dots, V_k$，它们划分了 $\\{1,\\dots,n\\}$，并用 $T_j = \\{1,\\dots,n\\} \\setminus V_j$ 表示相应的训练索引。对于在 $T_j$ 上训练的模型 $\\hat{f}_j$，准确率的 CV 估计量为\n$$\n\\widehat{\\text{Acc}}_{\\text{CV}} = \\frac{1}{k} \\sum_{j=1}^k \\frac{1}{|V_j|} \\sum_{i \\in V_j} \\mathbf{1}\\{\\hat{f}_j(x_i) = y_i\\},\n$$\n其中 $\\mathbf{1}\\{\\cdot\\}$ 是指示函数。\n- 数据增强：一个保留标签的变换 $\\mathcal{A}_\\theta$，应用于输入 $x$，由以度为单位的旋转角度 $\\theta$ 参数化。在本问题中，$\\theta \\in \\{90, 180, 270\\}$，$\\mathcal{A}_\\theta$ 是围绕图像中心将图像旋转 $\\theta$ 度。\n- 独立性原则：规范的 CV 要求在数据生成过程的条件下，验证样本独立于训练样本。当同一基础样本的变换版本同时出现在训练折和验证折中时，就会发生泄露，这违反了独立性假设并使估计量产生偏差。\n\n数据集构建：\n- 考虑 $n$ 个大小为 $h \\times w$ 的基础图像 $\\{x_i\\}_{i=1}^n$，其标签为 $y_i \\in \\{0,1\\}$，其中类别 0 是一个中心化的 “+” 图案，类别 1 是一个中心化的 “×” 图案。每个基础图像都是通过对理想模板进行扰动生成的，具体方法是：使用微小的随机偏移改变线条粗细，添加标准差为 $\\sigma$ 的加性高斯噪声，然后将像素强度裁剪到区间 $[0,1]$ 内。$\\theta \\in \\{90,180,270\\}$ 的旋转会保留类别标签。\n- 分类器是基于平方 $\\ell_2$ 距离的最近质心分类器。对于一个训练集 $(X_{\\text{train}}, Y_{\\text{train}})$，计算类别质心\n$$\n\\mu_c = \\frac{1}{|\\{i: Y_{\\text{train},i} = c\\}|} \\sum_{i:Y_{\\text{train},i}=c} X_{\\text{train},i}, \\quad c \\in \\{0,1\\},\n$$\n并预测 $\\hat{y}(x) = \\arg\\min_{c \\in \\{0,1\\}} \\|x - \\mu_c\\|_2^2$。\n\n需要比较的两种 CV 估计量：\n1. 规范增强 CV：对于每个折 $j \\in \\{1,\\dots,k\\}$，仅对训练图像按给定角度集 $S$（角度以度为单位）中的旋转进行增强，即使用 $\\{x_i\\} \\cup \\{\\mathcal{A}_\\theta(x_i): \\theta \\in S\\}$（其中 $i \\in T_j$）来训练 $\\hat{f}_j$，并在未经增强的验证图像 $\\{x_i: i \\in V_j\\}$ 上进行评估。\n2. 泄露 CV：首先，对整个数据集按 $S$ 中的旋转进行全局增强，形成 $D' = \\bigcup_{i=1}^n \\left(\\{x_i\\} \\cup \\{\\mathcal{A}_\\theta(x_i): \\theta \\in S\\}\\right)$，然后对 $D'$ 执行 $k$ 折 CV，在这些增强后的样本上进行训练和验证。此过程允许同一基础图像的增强变体出现在不同的折中，从而在训练和验证样本之间产生依赖性。\n\n您的程序必须：\n- 按照规定生成合成数据集。\n- 实现最近质心分类器。\n- 计算两种过程的平均 $k$ 折 CV 准确率，并返回其差值\n$$\n\\Delta = \\widehat{\\text{Acc}}_{\\text{CV}}^{\\text{leak}} - \\widehat{\\text{Acc}}_{\\text{CV}}^{\\text{proper}}.\n$$\n\n角度单位：所有角度均以度为单位。\n\n答案类型：所有输出必须是实数（浮点数）。\n\n测试套件和覆盖范围：\n实现以下测试用例，每个用例定义为一个元组 $(n, h, w, k, S, \\sigma, \\text{seed})$ 并按顺序处理。对于每个测试用例，计算并输出 $\\Delta$。\n\n- 用例 1（正常路径）：$(n, h, w, k, S, \\sigma, \\text{seed}) = (60, 16, 16, 5, \\{90, 180, 270\\}, 0.10, 42)$。\n- 用例 2（边界情况，无增强）：$(60, 16, 16, 5, \\varnothing, 0.10, 43)$，其中 $\\varnothing$ 表示空角度集。\n- 用例 3（折数较少）：$(60, 16, 16, 2, \\{90, 180, 270\\}, 0.10, 44)$。\n- 用例 4（高噪声）：$(60, 16, 16, 5, \\{90, 180, 270\\}, 0.50, 45)$。\n- 用例 5（单角度增强）：$(60, 16, 16, 10, \\{90\\}, 0.10, 46)$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含按测试用例顺序排列的结果，结果为逗号分隔的列表，并用方括号括起来。例如，包含三个结果的输出应类似于 $[r_1,r_2,r_3]$，其中每个 $r_i$ 是一个浮点数。角度以度为单位。不应打印任何额外文本。", "solution": "我们从 $k$ 折交叉验证（CV）的核心定义和独立性要求开始。$k$ 折 CV 估计量计算的是不相交折上的平均验证性能，其作为泛化性能估计量的可靠性取决于在给定数据生成过程的条件下，训练集和验证集之间的条件独立性。当增强仅应用于训练折时，变换 $\\mathcal{A}_\\theta$ 丰富了训练分布，同时保持验证样本是来自原始数据分布的独立抽样，从而维护了 CV 估计量的完整性。当增强泄露到验证折中时——具体而言，通过在构建折之前增强整个数据集——同一基础样本的增强版本可能被同时分配到训练集和验证集中，这违反了独立性并导致了乐观偏差。\n\n我们将这两种估计量形式化：\n- 规范增强 CV 估计量：\n$$\n\\widehat{\\text{Acc}}_{\\text{proper}} = \\frac{1}{k} \\sum_{j=1}^k \\frac{1}{|V_j|} \\sum_{i \\in V_j} \\mathbf{1}\\left\\{ \\arg\\min_{c \\in \\{0,1\\}} \\|x_i - \\mu_{c}^{(j)}\\|_2^2 = y_i \\right\\},\n$$\n其中\n$$\n\\mu_{c}^{(j)} = \\frac{1}{|\\{t \\in T_j: y_t = c\\}| + |\\{(t,\\theta): t \\in T_j, y_t = c, \\theta \\in S\\}|} \\left( \\sum_{t \\in T_j, y_t=c} x_t + \\sum_{t \\in T_j, y_t=c} \\sum_{\\theta \\in S} \\mathcal{A}_\\theta(x_t) \\right).\n$$\n验证使用未经增强的 $x_i$（其中 $i \\in V_j$）。\n\n- 泄露 CV 估计量：\n构建 $D' = \\bigcup_{i=1}^n \\left(\\{x_i\\} \\cup \\{\\mathcal{A}_\\theta(x_i): \\theta \\in S\\}\\right)$，然后直接在 $D'$ 上执行 $k$ 折 CV。设 $V'_1, \\dots, V'_k$ 为折， $T'_j$ 为它们的补集。泄露估计量为\n$$\n\\widehat{\\text{Acc}}_{\\text{leak}} = \\frac{1}{k} \\sum_{j=1}^k \\frac{1}{|V'_j|} \\sum_{(i,\\phi) \\in V'_j} \\mathbf{1}\\left\\{ \\arg\\min_{c \\in \\{0,1\\}} \\| \\mathcal{A}_\\phi (x_i) - \\tilde{\\mu}_{c}^{(j)} \\|_2^2 = y_i \\right\\},\n$$\n其中\n$$\n\\tilde{\\mu}_{c}^{(j)} = \\frac{1}{|\\{(t,\\psi) \\in T'_j: y_t = c\\}|} \\sum_{(t,\\psi) \\in T'_j, y_t=c} \\mathcal{A}_\\psi(x_t).\n$$\n\n偏差机制：\n在规范流程中，验证集中的 $x_i$ 不会（直接或通过其变换后的副本）用于训练。在泄露流程中，对于许多 $i$，某个变换后的 $\\mathcal{A}_\\psi(x_i)$ 可能出现在训练集中，而 $\\mathcal{A}_\\phi(x_i)$ 用于验证，这在训练和验证样本之间造成了高相关性。对于最近质心分类器，这种相关性会减小 $\\| \\mathcal{A}_\\phi (x_i) - \\tilde{\\mu}_{y_i}^{(j)} \\|_2^2$ 并增加正确分类的概率，因此平均而言 $\\widehat{\\text{Acc}}_{\\text{leak}} \\ge \\widehat{\\text{Acc}}_{\\text{proper}}$。我们感兴趣的量是其差值\n$$\n\\Delta = \\widehat{\\text{Acc}}_{\\text{leak}} - \\widehat{\\text{Acc}}_{\\text{proper}}.\n$$\n\n算法设计：\n1. 合成数据生成：\n   - 创建 $n$ 个大小为 $h \\times w$ 的基础图像。对于类别 0，通过在穿过中心的垂直和水平条带上设置像素来绘制一个中心化的“+”，线条粗细随机（例如，1 或 2 像素），中心有微小的随机偏移。对于类别 1，沿两条对角线设置像素来绘制一个中心化的“×”，具有类似的随机粗细和偏移。\n   - 向每个像素添加标准差为 $\\sigma$ 的独立高斯噪声，并将值裁剪到 $[0,1]$ 范围内。\n   - 分配标签，使得每个类别拥有 $n/2$ 个图像（类别均衡），然后打乱顺序。\n\n2. 增强算子：\n   - 对于以度为单位测量的角度 $\\theta \\in S \\subseteq \\{90,180,270\\}$，通过以 90 度为增量（即使用 $k = \\theta/90$ 的 $\\text{np.rot90}$）实现 $\\mathcal{A}_\\theta$，并保留标签。\n\n3. 分类器：\n   - 基于平方 $\\ell_2$ 距离的最近质心分类器。为进行计算，将图像展平为 $\\mathbb{R}^{h \\cdot w}$中的向量。从训练集（根据需要包括增强样本）计算类别质心，并通过最近质心法预测验证样本的类别。\n\n4. $k$ 折划分：\n   - 对于规范增强 CV，将 $n$ 个基础样本分成 $k$ 折。对于第 $j$ 折，仅对训练集按 $S$ 中的角度进行增强，保持验证集未经增强，训练质心，并在验证折上计算准确率。跨折取平均以获得 $\\widehat{\\text{Acc}}_{\\text{proper}}$。\n   - 对于泄露 CV，首先增强整个数据集（包括原始图像和在 $S$ 中的旋转），然后对这个增强后的数据集执行 $k$ 折 CV，在增强样本上进行训练和验证，以获得 $\\widehat{\\text{Acc}}_{\\text{leak}}$。\n\n5. 差值：\n   - 为每个测试用例计算 $\\Delta$。\n\n测试套件覆盖理据：\n- 用例 1 使用适中的 $k$ 值、多个角度和小噪声，代表一个典型场景。\n- 用例 2 使用 $S = \\varnothing$（无增强），此时我们预期 $\\Delta \\approx 0$，因为两种流程是相同的。\n- 用例 3 使用较小的 $k$ 值，这增加了增强后的副本跨折出现的几率，可能放大泄露效应。\n- 用例 4 增加了噪声 $\\sigma$，以检验鲁棒性；在噪声条件下，泄露会人为地提升性能。\n- 用例 5 使用 $k = 10$ 和单个角度，测试对增强集大小的敏感性。\n\n最终输出：\n单行输出 $[\\Delta_1,\\Delta_2,\\Delta_3,\\Delta_4,\\Delta_5]$，其中浮点数按顺序对应上述用例。\n\n该设计严格遵守了 CV 底层的独立性原则，并通过计算揭示了通过增强泄露违反该原则如何导致估计准确率中产生乐观偏差。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef make_plus_image(h, w, thickness, off_y, off_x):\n    \"\"\"\n    Create a centered plus '+' pattern with given thickness and small offsets.\n    Intensities are 1.0 on the pattern, 0.0 elsewhere.\n    \"\"\"\n    img = np.zeros((h, w), dtype=np.float64)\n    cy = h // 2 + off_y\n    cx = w // 2 + off_x\n    # Horizontal bar\n    y_start = max(cy - thickness, 0)\n    y_end = min(cy + thickness + 1, h)\n    img[y_start:y_end, :] = 1.0\n    # Vertical bar\n    x_start = max(cx - thickness, 0)\n    x_end = min(cx + thickness + 1, w)\n    img[:, x_start:x_end] = 1.0\n    return img\n\ndef make_x_image(h, w, thickness, off_y, off_x):\n    \"\"\"\n    Create a centered 'x' pattern (two diagonals) with given thickness and small offsets.\n    Intensities are 1.0 on the pattern, 0.0 elsewhere.\n    \"\"\"\n    img = np.zeros((h, w), dtype=np.float64)\n    cy = h // 2 + off_y\n    cx = w // 2 + off_x\n    # Draw diagonals with thickness by marking pixels close to diagonal lines\n    yy, xx = np.meshgrid(np.arange(h), np.arange(w), indexing='ij')\n    # Centered diagonals adjusted by offsets\n    # Line 1: slope +1 through (cy, cx)\n    # Distance from line y - cy = x - cx => y - x = cy - cx\n    d1 = np.abs((yy - xx) - (cy - cx))\n    # Line 2: slope -1 through (cy, cx)\n    # Distance from line y - cy = -(x - cx) => y + x = cy + cx\n    d2 = np.abs((yy + xx) - (cy + cx))\n    mask = (d1 <= thickness) | (d2 <= thickness)\n    img[mask] = 1.0\n    return img\n\ndef add_noise_and_clip(img, noise_std, rng):\n    noisy = img + rng.normal(loc=0.0, scale=noise_std, size=img.shape)\n    return np.clip(noisy, 0.0, 1.0)\n\ndef generate_dataset(n, h, w, noise_std, seed):\n    \"\"\"\n    Generate n base images: half '+' class (label 0), half 'x' class (label 1),\n    with random thickness and small offsets, plus Gaussian noise.\n    Returns images (n, h, w) and labels (n,).\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    images = np.zeros((n, h, w), dtype=np.float64)\n    labels = np.zeros(n, dtype=np.int64)\n    # Balanced labels: 0 then 1 alternating\n    base_labels = np.array([0, 1] * (n // 2) + ([0] if n % 2 == 1 else []), dtype=np.int64)\n    # Shuffle labels for randomness\n    rng.shuffle(base_labels)\n    for i in range(n):\n        c = base_labels[i]\n        labels[i] = c\n        thickness = rng.integers(1, 3)  # 1 or 2\n        off_y = rng.integers(-1, 2)     # -1, 0, 1\n        off_x = rng.integers(-1, 2)     # -1, 0, 1\n        if c == 0:\n            img = make_plus_image(h, w, thickness, off_y, off_x)\n        else:\n            img = make_x_image(h, w, thickness, off_y, off_x)\n        img = add_noise_and_clip(img, noise_std, rng)\n        images[i] = img\n    return images, labels\n\ndef rotate_image(img, angle_deg):\n    \"\"\"\n    Rotate the image by angle degrees (must be in {90,180,270}) using np.rot90.\n    \"\"\"\n    if angle_deg % 90 != 0 or angle_deg == 0:\n        # Only support non-zero multiples of 90 as per augmentation set; skip 0 in augmentation\n        raise ValueError(\"Only 90, 180, 270 degrees supported for augmentation\")\n    k = (angle_deg // 90) % 4\n    return np.rot90(img, k)\n\ndef augment_images(images, labels, angles):\n    \"\"\"\n    For each image, return list of (original + rotated versions) according to angles.\n    angles: list of integers from {90, 180, 270}. Original is always included when leak=True;\n            for training-only augmentation, we'll explicitly include original.\n    \"\"\"\n    augmented_imgs = []\n    augmented_labels = []\n    for img, y in zip(images, labels):\n        # include original\n        augmented_imgs.append(img)\n        augmented_labels.append(y)\n        for ang in angles:\n            aug = rotate_image(img, ang)\n            augmented_imgs.append(aug)\n            augmented_labels.append(y)\n    return np.array(augmented_imgs), np.array(augmented_labels)\n\ndef kfold_indices(n, k, seed):\n    \"\"\"\n    Return list of k folds, each a numpy array of indices.\n    Shuffle indices using seed, then split into k contiguous folds as evenly as possible.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    indices = np.arange(n, dtype=np.int64)\n    rng.shuffle(indices)\n    folds = []\n    fold_sizes = np.full(k, n // k, dtype=int)\n    fold_sizes[:(n % k)] += 1\n    start = 0\n    for fs in fold_sizes:\n        end = start + fs\n        folds.append(indices[start:end])\n        start = end\n    return folds\n\ndef compute_centroids(X_train, y_train):\n    \"\"\"\n    Compute class centroids for labels 0 and 1.\n    X_train: (m, d), y_train: (m,)\n    Returns mu0, mu1 as (d,) arrays.\n    \"\"\"\n    # In case a class is missing, handle by using zeros to avoid crash\n    c0 = (y_train == 0)\n    c1 = (y_train == 1)\n    if not np.any(c0) or not np.any(c1):\n        # If missing a class, return centroids computed from available class and zeros for missing\n        mu0 = X_train[c0].mean(axis=0) if np.any(c0) else np.zeros(X_train.shape[1], dtype=np.float64)\n        mu1 = X_train[c1].mean(axis=0) if np.any(c1) else np.zeros(X_train.shape[1], dtype=np.float64)\n        return mu0, mu1\n    mu0 = X_train[c0].mean(axis=0)\n    mu1 = X_train[c1].mean(axis=0)\n    return mu0, mu1\n\ndef predict_nearest_centroid(X_val, mu0, mu1):\n    \"\"\"\n    Predict labels for validation set X_val given centroids mu0 and mu1.\n    \"\"\"\n    # Compute squared distances to centroids\n    d0 = np.sum((X_val - mu0) ** 2, axis=1)\n    d1 = np.sum((X_val - mu1) ** 2, axis=1)\n    return (d1 < d0).astype(np.int64)  # predict 1 if distance to mu1 is smaller, else 0\n\ndef cross_val_accuracy_proper(images, labels, k, angles, seed):\n    \"\"\"\n    Proper augmentation: augment only training folds; validate on original base images.\n    \"\"\"\n    n = images.shape[0]\n    folds = kfold_indices(n, k, seed)\n    h, w = images.shape[1], images.shape[2]\n    accs = []\n    for fold in folds:\n        val_idx = fold\n        train_idx = np.setdiff1d(np.arange(n, dtype=np.int64), val_idx, assume_unique=True)\n        # Training data: original + augment rotations for training indices\n        X_train_list = []\n        y_train_list = []\n        for idx in train_idx:\n            img = images[idx]\n            y = labels[idx]\n            # include original\n            X_train_list.append(img.reshape(h * w))\n            y_train_list.append(y)\n            # include augmentations\n            for ang in angles:\n                aug = rotate_image(img, ang)\n                X_train_list.append(aug.reshape(h * w))\n                y_train_list.append(y)\n        X_train = np.stack(X_train_list, axis=0)\n        y_train = np.array(y_train_list, dtype=np.int64)\n        mu0, mu1 = compute_centroids(X_train, y_train)\n        # Validation data: original base images only\n        X_val = images[val_idx].reshape(len(val_idx), h * w)\n        y_val = labels[val_idx]\n        y_pred = predict_nearest_centroid(X_val, mu0, mu1)\n        acc = np.mean(y_pred == y_val)\n        accs.append(acc)\n    return float(np.mean(accs))\n\ndef cross_val_accuracy_leak(images, labels, k, angles, seed):\n    \"\"\"\n    Leakage augmentation: augment entire dataset first (include originals and rotations),\n    then perform k-fold CV on the augmented dataset.\n    \"\"\"\n    # Augment entire dataset: originals + rotations in angles\n    aug_imgs, aug_labels = augment_images(images, labels, angles)\n    n_aug = aug_imgs.shape[0]\n    folds = kfold_indices(n_aug, k, seed)\n    h, w = images.shape[1], images.shape[2]\n    accs = []\n    for fold in folds:\n        val_idx = fold\n        train_idx = np.setdiff1d(np.arange(n_aug, dtype=np.int64), val_idx, assume_unique=True)\n        X_train = aug_imgs[train_idx].reshape(len(train_idx), h * w)\n        y_train = aug_labels[train_idx]\n        mu0, mu1 = compute_centroids(X_train, y_train)\n        X_val = aug_imgs[val_idx].reshape(len(val_idx), h * w)\n        y_val = aug_labels[val_idx]\n        y_pred = predict_nearest_centroid(X_val, mu0, mu1)\n        acc = np.mean(y_pred == y_val)\n        accs.append(acc)\n    return float(np.mean(accs))\n\ndef compute_delta(n, h, w, k, angles, noise_std, seed):\n    images, labels = generate_dataset(n, h, w, noise_std, seed)\n    acc_proper = cross_val_accuracy_proper(images, labels, k, angles, seed)\n    acc_leak = cross_val_accuracy_leak(images, labels, k, angles, seed)\n    return acc_leak - acc_proper\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case: (n, h, w, k, angles_list, noise_std, seed)\n    test_cases = [\n        (60, 16, 16, 5, [90, 180, 270], 0.10, 42),  # Case 1: happy path\n        (60, 16, 16, 5, [],              0.10, 43),  # Case 2: boundary, no augmentation\n        (60, 16, 16, 2, [90, 180, 270],  0.10, 44),  # Case 3: few folds\n        (60, 16, 16, 5, [90, 180, 270],  0.50, 45),  # Case 4: high noise\n        (60, 16, 16, 10, [90],           0.10, 46),  # Case 5: single-angle augmentation\n    ]\n\n    results = []\n    for case in test_cases:\n        n, h, w, k, angles, noise_std, seed = case\n        delta = compute_delta(n, h, w, k, angles, noise_std, seed)\n        # Format with a reasonable precision\n        results.append(f\"{delta:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3134696"}, {"introduction": "交叉验证不仅可以用来估计模型的泛化误差，还能作为一种强大的数据质量诊断工具。这项高级实践将向您展示如何利用模型在不同交叉验证折叠下的预测不稳定性，来识别数据集中隐藏的问题，例如重复或近似重复的样本。通过完成这个练习，您将学会将交叉验证从一个单纯的评估工具，转变为一个用于深入洞察和清洗数据集的精密仪器。[@problem_id:3139096]", "problem": "给定一个用于训练小型神经网络的二元分类数据集，其中一些数据实例是具有相同标签的其他实例的精确重复或近似重复。在执行$k$折交叉验证（首次出现：cross-validation (CV)）时，这些重复或近似重复的实例可能会导致分折预测的不稳定，具体取决于给定测试实例的重复项是否包含在训练折中。您的任务是设计并实现一个程序，该程序使用重复的$k$折交叉验证，通过测量一个从第一性原理推导出的预测不稳定性统计量，来发现此类重复或近似重复的实例。\n\n从以下核心定义和原理开始：\n- 使用二元交叉熵的经验风险最小化：给定输入向量 $x \\in \\mathbb{R}^d$ 和标签 $y \\in \\{0,1\\}$，一个带有参数 $\\theta$ 的模型通过仿射映射和非线性的组合将 $x$ 映射到一个预测概率 $p_\\theta(x) \\in (0,1)$。在数据集 $\\{(x_i,y_i)\\}_{i=1}^n$ 上的经验风险为\n$$\n\\mathcal{L}(\\theta) \\triangleq \\frac{1}{n} \\sum_{i=1}^n \\left[ -y_i \\log p_\\theta(x_i) - (1-y_i) \\log(1-p_\\theta(x_i)) \\right] + \\lambda \\|\\theta\\|_2^2,\n$$\n其中 $\\lambda \\ge 0$ 是一个正则化权重，$\\|\\cdot\\|_2$ 表示欧几里得范数。\n- 一个带有整流线性单元（首次出现：ReLU）非线性和 logistic 输出的单隐藏层神经网络定义为\n$$\nh(x) = \\max(0, W_1 x + b_1), \\quad z(x) = W_2 h(x) + b_2, \\quad p_\\theta(x) = \\sigma(z(x)),\n$$\n其中 $W_1 \\in \\mathbb{R}^{d \\times m}$，$b_1 \\in \\mathbb{R}^m$，$W_2 \\in \\mathbb{R}^{m \\times 1}$，$b_2 \\in \\mathbb{R}$，$m$ 是隐藏单元的数量，$\\sigma(u) \\triangleq \\frac{1}{1+e^{-u}}$ 是 logistic Sigmoid 函数。\n- $k$折交叉验证将索引 $\\{1,\\dots,n\\}$ 划分为 $k$ 个大小近似相等的互不相交的折。对于每个折 $f \\in \\{1,\\dots,k\\}$，模型在其他 $k-1$ 个折的并集上进行训练，并在折 $f$ 上进行评估。使用不同的随机分折方式重复$k$折交叉验证，可以为每个实例生成一个预测分布。\n\n定义一个邻居关系来捕捉重复或近似重复的实例，如下所示。设距离阈值 $\\epsilon > 0$ 和一个指示函数\n$$\n\\mathbb{I}_\\epsilon(i,j) \\triangleq \\begin{cases}\n1,  \\text{if } \\|x_i - x_j\\|_2 \\le \\epsilon \\text{ and } y_i = y_j, \\\\\n0,  \\text{otherwise}.\n\\end{cases}\n$$\n对于每个实例 $i$，令 $N_\\epsilon(i) \\triangleq \\{ j \\ne i \\mid \\mathbb{I}_\\epsilon(i,j) = 1\\}$ 为其在距离 $\\epsilon$ 内的同标签邻居集合。\n\n考虑使用 $R$ 次独立随机分区进行重复的$k$折交叉验证。在每次训练-测试划分期间，对于每个测试实例 $i$，记录其邻居集 $N_\\epsilon(i)$ 是否与训练索引相交（即 $i$ 的任何邻居是否存在于训练集中）。这为实例 $i$ 产生了两个预测概率集合：集合\n$$\n\\mathcal{P}_\\mathrm{present}(i) \\triangleq \\{ p_\\theta^{(r,f)}(x_i) \\mid \\text{in repetition } r \\text{ and fold } f, \\ N_\\epsilon(i) \\cap \\text{train} \\ne \\emptyset \\}\n$$\n和集合\n$$\n\\mathcal{P}_\\mathrm{absent}(i) \\triangleq \\{ p_\\theta^{(r,f)}(x_i) \\mid \\text{in repetition } r \\text{ and fold } f, \\ N_\\epsilon(i) \\cap \\text{train} = \\emptyset \\},\n$$\n其中 $p_\\theta^{(r,f)}(x_i)$ 表示在重复次数 $r$ 和折 $f$ 的训练数据上训练时，模型对 $x_i$ 的预测概率。\n\n将实例 $i$ 的不稳定性统计量定义为\n$$\nD(i) \\triangleq \\begin{cases}\n\\left| \\overline{p}_\\mathrm{present}(i) - \\overline{p}_\\mathrm{absent}(i) \\right|,  \\text{if } |\\mathcal{P}_\\mathrm{present}(i)| \\ge 1 \\text{ and } |\\mathcal{P}_\\mathrm{absent}(i)| \\ge 1, \\\\\n0,  \\text{otherwise},\n\\end{cases}\n$$\n其中 $\\overline{p}_\\mathrm{present}(i)$ 和 $\\overline{p}_\\mathrm{absent}(i)$ 分别是相应集合的算术平均值。如果对于选定的阈值 $\\tau > 0$，$D(i) \\ge \\tau$，则该实例被标记为疑似重复或近似重复项。\n\n为确保科学真实性和可复现性，使用以下固定的设计选择来实现上述过程：\n- 使用如上定义的单隐藏层神经网络，包含 $m = 8$ 个隐藏单元，通过全批量梯度下降进行固定轮次的训练，学习率为 $0.2$，$\\ell_2$ 正则化权重为 $\\lambda = 10^{-3}$。参数初始化使用固定的随机种子，以确保在给定相同数据的情况下，训练算法在不同运行中的行为是确定性的。\n- 使用独立的固定种子为测试套件生成合成数据集，采用一致的高斯簇和如下所述的显式重复项构建方法。\n\n测试套件（三种情况），每种情况产生一个由整数组成的被标记索引列表：\n- 情况 1（正常路径，包含一些重复和近似重复项）。数据生成：\n  - 从均值为 $(-2,-2)$、每个坐标标准差为 $0.6$ 的高斯分布中为标签 $0$ 抽取 $12$ 个点。\n  - 从均值为 $(2,2)$、每个坐标标准差为 $0.6$ 的高斯分布中为标签 $1$ 抽取 $12$ 个点。\n  - 通过从标签 $1$ 中选择 $3$ 个点和从标签 $0$ 中选择 $2$ 个点来创建 $5$ 个额外的点作为重复或近似重复项，并通过添加标准差为 $0.05$ 的高斯噪声对每个选定的点进行扰动，同时保持相同的标签。\n  - 参数：$k = 5$，$R = 12$，$\\epsilon = 0.25$，$\\tau = 0.10$。\n- 情况 2（边缘案例，无重复项）。数据生成：\n  - 从均值为 $(-3,-3)$、标准差为 $0.9$ 的高斯分布中为标签 $0$ 抽取 $10$ 个点。\n  - 从均值为 $(3,3)$、标准差为 $0.9$ 的高斯分布中为标签 $1$ 抽取 $10$ 个点。\n  - 参数：$k = 5$，$R = 12$，$\\epsilon = 0.15$，$\\tau = 0.10$。\n- 情况 3（边界案例，每个点都被复制）。数据生成：\n  - 从均值为 $(-1.5,-1.5)$、标准差为 $0.5$ 的高斯分布中为标签 $0$ 抽取 $6$ 个点。\n  - 从均值为 $(1.5,1.5)$、标准差为 $0.5$ 的高斯分布中为标签 $1$ 抽取 $6$ 个点。\n  - 对每个点，通过添加标准差为 $0.05$ 的高斯噪声来增加一个重复项，并保留标签。\n  - 参数：$k = 4$，$R = 12$，$\\epsilon = 0.25$，$\\tau = 0.07$。\n\n要求的最终输出格式：\n- 您的程序应产生单行输出，包含一个由三个列表组成的逗号分隔列表，每个案例一个，用方括号括起来，不含空格。例如，输出格式为\n$$\n\\texttt{[[i_1,i_2,\\dots],[j_1,j_2,\\dots],[\\ell_1,\\ell_2,\\dots]]}\n$$\n其中每个内部列表包含该案例被标记实例的整数索引，按索引升序排列。\n\n不涉及角度和物理单位；没有单位规范。所有阈值比较（例如，$D(i) \\ge \\tau$）均使用十进制表示的实数进行。", "solution": "该问题要求设计并实现一个程序，通过在重复的$k$折交叉验证下测量预测不稳定性，来识别重复或近似重复的数据实例。解决方案将首先形式化算法流程，然后详细说明神经网络模型及其训练过程，最后指定实现参数。\n\n### 1. 算法流程\n\n该方法的核心是量化给定数据实例 $x_i$ 的预测如何根据一个非常相似的实例（一个“邻居”）是否被包含在训练集中而变化。一个大的变化表明模型“记忆”了邻居，这是对冗余数据点过拟合的典型行为。\n\n总体流程如下：\n\n**步骤 1：数据生成和邻居识别**\n对于每个测试案例，根据指定的参数生成一个由 $n$ 个实例组成的合成数据集 $(X, y)$。$X$ 是一个特征向量 $\\{x_i\\}_{i=1}^n$ 的矩阵， $y$ 是一个二元标签 $\\{y_i\\}_{i=1}^n$ 的向量。\n\n数据生成后，我们为每个实例 $i \\in \\{1, \\dots, n\\}$ 预先计算其邻居集 $N_\\epsilon(i)$。根据问题中的定义，该集合包含在欧几里得距离 $\\epsilon$ 内的所有其他同标签实例的索引：\n$$ N_\\epsilon(i) = \\{ j \\ne i \\mid \\|x_i - x_j\\|_2 \\le \\epsilon \\text{ and } y_i = y_j \\} $$\n此计算在开始交叉验证分析之前对整个数据集执行一次。\n\n**步骤 2：重复的$k$折交叉验证和预测收集**\n该程序涉及 $R$ 次独立的$k$折交叉验证重复。对于每个实例 $i$，我们维护两个列表来存储其样本外预测：$\\mathcal{P}_\\mathrm{present}(i)$ 和 $\\mathcal{P}_\\mathrm{absent}(i)$。\n\n对每次重复 $r \\in \\{1, \\dots, R\\}$ 迭代此过程：\n1.  生成数据索引 $\\{1, \\dots, n\\}$ 的一个新的随机排列。这确保了每次重复中的分折构成是不同的。\n2.  将排列后的索引划分为 $k$ 个不相交的折，$F_1, \\dots, F_k$。\n3.  对于每个折 $f \\in \\{1, \\dots, k\\}$：\n    a. 指定折 $F_f$ 为测试集。其余 $k-1$ 个折的并集构成训练集，我们称其索引集为 $T_f$。\n    b. 使用固定的随机种子（以确保每次训练运行时初始参数相同）初始化一个单隐藏层神经网络，并在训练集数据 $\\{(x_j, y_j) \\mid j \\in T_f\\}$ 上进行训练。\n    c. 对于测试折 $F_f$ 中的每个实例 $i$，使用训练好的模型计算预测概率 $p_\\theta(x_i)$。\n    d. 我们检查实例 $i$ 的任何邻居是否在训练集中，即 $N_\\epsilon(i) \\cap T_f \\ne \\emptyset$。\n    e. 如果交集非空，则将预测 $p_\\theta(x_i)$ 附加到列表 $\\mathcal{P}_\\mathrm{present}(i)$ 中。\n    f. 否则（如果交集为空），则将预测 $p_\\theta(x_i)$ 附加到列表 $\\mathcal{P}_\\mathrm{absent}(i)$ 中。\n\n在完成所有 $R$ 次重复及每次重复中的所有 $k$ 个折之后，我们将为每个实例 $i$ 收集至多 $R$ 个样本外预测，并根据其邻居在相应训练集中的存在与否进行分类。\n\n**步骤 3：不稳定性统计量计算和标记**\n对于每个实例 $i$，计算不稳定性统计量 $D(i)$。该统计量衡量了两种情况下平均预测之间的绝对差：\n$$ D(i) = \\begin{cases} \\left| \\overline{p}_\\mathrm{present}(i) - \\overline{p}_\\mathrm{absent}(i) \\right|,  \\text{if } |\\mathcal{P}_\\mathrm{present}(i)| \\ge 1 \\text{ and } |\\mathcal{P}_\\mathrm{absent}(i)| \\ge 1 \\\\ 0,  \\text{otherwise} \\end{cases} $$\n其中 $\\overline{p}_\\mathrm{present}(i)$ 和 $\\overline{p}_\\mathrm{absent}(i)$ 分别是集合 $\\mathcal{P}_\\mathrm{present}(i)$ 和 $\\mathcal{P}_\\mathrm{absent}(i)$ 中概率的算术平均值。该条件确保只有在每种场景下都至少有一个预测时才计算该统计量，从而使比较有意义。\n\n最后，如果一个实例 $i$ 的不稳定性统计量达到或超过给定的阈值 $\\tau$，则将其标记为疑似重复或近似重复项：\n$$ \\text{Flag}(i) \\iff D(i) \\ge \\tau $$\n\n### 2. 神经网络模型和训练\n\n该分析采用一个单隐藏层前馈神经网络。\n\n**模型架构：**\n给定一个输入特征向量 $x \\in \\mathbb{R}^d$，模型按以下方式计算预测概率 $p_\\theta(x)$：\n1.  隐藏层激活：$h(x) = \\max(0, W_1 x + b_1)$，其中 $W_1 \\in \\mathbb{R}^{m \\times d}$ 且 $b_1 \\in \\mathbb{R}^m$。函数 $\\max(0, \\cdot)$ 是整流线性单元（ReLU）。我们使用 $m=8$ 个隐藏单元。\n2.  输出层对数几率（logit）：$z(x) = W_2 h(x) + b_2$，其中 $W_2 \\in \\mathbb{R}^{1 \\times m}$ 且 $b_2 \\in \\mathbb{R}$。\n3.  预测概率：$p_\\theta(x) = \\sigma(z(x))$，其中 $\\sigma(u) = (1+e^{-u})^{-1}$ 是 logistic Sigmoid 函数。\n模型参数为 $\\theta = \\{W_1, b_1, W_2, b_2\\}$。请注意，对于排列在矩阵 $X \\in \\mathbb{R}^{N \\times d}$ 中的一批 $N$ 个输入，此结构对应于 $H = \\max(0, X W_1' + b_1')$，其中 $W_1' \\in \\mathbb{R}^{d \\times m}$ 且 $b_1' \\in \\mathbb{R}^{1 \\times m}$，依此类推。我们将在实现中遵循这种标准的批量处理约定。\n\n**训练过程：**\n模型通过最小化经验风险（即带有 $\\ell_2$ 正则化的二元交叉熵损失），使用全批量梯度下降进行训练。对于大小为 $n_{\\text{train}}$ 的训练集，损失为：\n$$ \\mathcal{L}(\\theta) = \\frac{1}{n_{\\text{train}}} \\sum_{i=1}^{n_{\\text{train}}} \\left[ -y_i \\log p_\\theta(x_i) - (1-y_i) \\log(1-p_\\theta(x_i)) \\right] + \\lambda \\left( \\|W_1\\|_F^2 + \\|b_1\\|_2^2 + \\|W_2\\|_F^2 + b_2^2 \\right) $$\n其中 $\\|\\cdot\\|_F$ 是矩阵的弗罗贝尼乌斯范数，$\\|\\cdot\\|_2$ 是向量的标准欧几里得范数。正则化权重固定为 $\\lambda = 10^{-3}$。\n\n梯度 $\\nabla_\\theta \\mathcal{L}$ 通过反向传播算法计算。然后，参数在固定的轮次（epoch）内迭代更新：\n$$ \\theta^{(t+1)} \\leftarrow \\theta^{(t)} - \\eta \\nabla_\\theta \\mathcal{L}(\\theta^{(t)}) $$\n其中 $\\eta=0.2$ 是学习率。我们将使用固定的 $200$ 个轮次，这对于在小规模合成数据集上收敛是足够的。\n\n### 3. 实现和参数选择\n\n为确保可复现性，实现严格遵守指定的参数。\n- **可复现性：** 对每个测试案例的数据生成、神经网络参数的初始化以及每次交叉验证重复中的随机洗牌，都使用独立的固定种子。\n- **测试案例：** 按描述实现三个测试案例，使用指定的数据生成参数、交叉验证参数（$k, R$）和不稳定性分析参数（$\\epsilon, \\tau$）。\n- **算法执行：** 对于每种情况，执行完整的流程：数据生成、邻居查找、带有模型训练和预测收集的重复CV、不稳定性计算，以及最后根据阈值 $\\tau$ 标记索引。收集最终的标记索引列表以供输出。", "answer": "```python\nimport numpy as np\nfrom scipy.special import expit as sigmoid\n\ndef solve():\n    \"\"\"\n    Main function to run the analysis for all test cases and print the result.\n    \"\"\"\n\n    class NeuralNetwork:\n        \"\"\"\n        A one-hidden-layer neural network for binary classification.\n        \"\"\"\n        def __init__(self, input_dim, hidden_dim, lambda_reg, seed):\n            self.input_dim = input_dim\n            self.hidden_dim = hidden_dim\n            self.lambda_reg = lambda_reg\n            \n            # Initialize parameters with a fixed seed for reproducibility.\n            rng = np.random.default_rng(seed)\n            self.W1 = rng.standard_normal(size=(self.input_dim, self.hidden_dim)) * 0.1\n            self.b1 = np.zeros((1, self.hidden_dim))\n            self.W2 = rng.standard_normal(size=(self.hidden_dim, 1)) * 0.1\n            self.b2 = np.zeros((1, 1))\n\n        def _forward(self, X):\n            self.Z1 = X @ self.W1 + self.b1\n            self.A1 = np.maximum(0, self.Z1)  # ReLU activation\n            self.Z2 = self.A1 @ self.W2 + self.b2\n            P = sigmoid(self.Z2)\n            return P\n\n        def _compute_loss(self, Y, P):\n            n_samples = Y.shape[0]\n            bce_loss = -np.mean(Y * np.log(P) + (1 - Y) * np.log(1 - P))\n            reg_loss = self.lambda_reg * (np.sum(np.square(self.W1)) + np.sum(np.square(self.b1)) +\n                                          np.sum(np.square(self.W2)) + np.sum(np.square(self.b2)))\n            return bce_loss + reg_loss\n\n        def _backward(self, X, Y, P):\n            n_samples = X.shape[0]\n            \n            # Gradient of loss w.r.t. Z2 (pre-sigmoid output)\n            dZ2 = (P - Y) / n_samples\n            \n            # Gradients for W2 and b2\n            self.dW2 = self.A1.T @ dZ2 + 2 * self.lambda_reg * self.W2\n            self.db2 = np.sum(dZ2, axis=0, keepdims=True) + 2 * self.lambda_reg * self.b2\n            \n            # Backpropagate to hidden layer\n            dA1 = dZ2 @ self.W2.T\n            # Gradient of loss w.r.t Z1 (pre-ReLU)\n            dZ1 = dA1 * (self.Z1 > 0)\n            \n            # Gradients for W1 and b1\n            self.dW1 = X.T @ dZ1 + 2 * self.lambda_reg * self.W1\n            self.db1 = np.sum(dZ1, axis=0, keepdims=True) + 2 * self.lambda_reg * self.b1\n\n        def train(self, X_train, Y_train, epochs, learning_rate):\n            y_train_col = Y_train.reshape(-1, 1)\n            for _ in range(epochs):\n                P = self._forward(X_train)\n                self._backward(X_train, y_train_col, P)\n                \n                # Update parameters\n                self.W1 -= learning_rate * self.dW1\n                self.b1 -= learning_rate * self.db1\n                self.W2 -= learning_rate * self.dW2\n                self.b2 -= learning_rate * self.b2\n\n        def predict_proba(self, X):\n            return self._forward(X)\n\n    def generate_data(case_id, params):\n        \"\"\"Generates synthetic data for a given test case.\"\"\"\n        rng = np.random.default_rng(case_id)\n        \n        if case_id == 0: # Case 1\n            X0 = rng.multivariate_normal(mean=[-2, -2], cov=np.eye(2)*0.6**2, size=12)\n            Y0 = np.zeros(12)\n            X1 = rng.multivariate_normal(mean=[2, 2], cov=np.eye(2)*0.6**2, size=12)\n            Y1 = np.ones(12)\n            X = np.vstack((X0, X1))\n            Y = np.hstack((Y0, Y1))\n            \n            dupe_indices_0 = rng.choice(np.where(Y == 0)[0], size=2, replace=False)\n            dupe_indices_1 = rng.choice(np.where(Y == 1)[0], size=3, replace=False)\n            \n            X_dupes_0 = X[dupe_indices_0] + rng.normal(scale=0.05, size=(2, 2))\n            Y_dupes_0 = np.zeros(2)\n            X_dupes_1 = X[dupe_indices_1] + rng.normal(scale=0.05, size=(3, 2))\n            Y_dupes_1 = np.ones(3)\n            \n            X = np.vstack((X, X_dupes_0, X_dupes_1))\n            Y = np.hstack((Y, Y_dupes_0, Y_dupes_1))\n        \n        elif case_id == 1: # Case 2\n            X0 = rng.multivariate_normal(mean=[-3, -3], cov=np.eye(2)*0.9**2, size=10)\n            Y0 = np.zeros(10)\n            X1 = rng.multivariate_normal(mean=[3, 3], cov=np.eye(2)*0.9**2, size=10)\n            Y1 = np.ones(10)\n            X = np.vstack((X0, X1))\n            Y = np.hstack((Y0, Y1))\n\n        elif case_id == 2: # Case 3\n            X0 = rng.multivariate_normal(mean=[-1.5, -1.5], cov=np.eye(2)*0.5**2, size=6)\n            Y0 = np.zeros(6)\n            X1 = rng.multivariate_normal(mean=[1.5, 1.5], cov=np.eye(2)*0.5**2, size=6)\n            Y1 = np.ones(6)\n            X_orig = np.vstack((X0, X1))\n            Y_orig = np.hstack((Y0, Y1))\n            \n            X_dupes = X_orig + rng.normal(scale=0.05, size=X_orig.shape)\n            Y_dupes = Y_orig\n            \n            X = np.vstack((X_orig, X_dupes))\n            Y = np.hstack((Y_orig, Y_dupes))\n            \n        return X, Y\n\n    def run_analysis(case_id, params):\n        \"\"\"Runs the full analysis for a single case.\"\"\"\n        k = params['k']\n        R = params['R']\n        epsilon = params['epsilon']\n        tau = params['tau']\n        hidden_dim = 8\n        learning_rate = 0.2\n        lambda_reg = 1e-3\n        epochs = 200\n        param_init_seed = 42\n\n        X, Y = generate_data(case_id, params)\n        n_samples, input_dim = X.shape\n\n        # Step 1: Find neighbor sets for each instance\n        neighbor_sets = [set() for _ in range(n_samples)]\n        for i in range(n_samples):\n            for j in range(n_samples):\n                if i == j: continue\n                if Y[i] == Y[j]:\n                    dist = np.linalg.norm(X[i] - X[j])\n                    if dist <= epsilon:\n                        neighbor_sets[i].add(j)\n        \n        # Step 2: Repeated k-fold CV\n        preds_present = [[] for _ in range(n_samples)]\n        preds_absent = [[] for _ in range(n_samples)]\n\n        for r in range(R):\n            # Use repetition number as seed for shuffling\n            rep_rng = np.random.default_rng(r)\n            indices = rep_rng.permutation(n_samples)\n            folds = np.array_split(indices, k)\n\n            for f in range(k):\n                test_indices = folds[f]\n                train_indices_list = [folds[i] for i in range(k) if i != f]\n                train_indices = np.concatenate(train_indices_list)\n\n                train_indices_set = set(train_indices)\n                \n                X_train, Y_train = X[train_indices], Y[train_indices]\n                X_test = X[test_indices]\n                \n                # Train model\n                model = NeuralNetwork(input_dim, hidden_dim, lambda_reg, param_init_seed)\n                model.train(X_train, Y_train, epochs, learning_rate)\n\n                # Predict on test set and categorize predictions\n                predictions = model.predict_proba(X_test)\n                \n                for idx_in_fold, i in enumerate(test_indices):\n                    p_i = predictions[idx_in_fold][0]\n                    # Check if any neighbor is in the training set\n                    if not neighbor_sets[i].isdisjoint(train_indices_set):\n                        preds_present[i].append(p_i)\n                    else:\n                        preds_absent[i].append(p_i)\n        \n        # Step 3: Calculate instability and flag instances\n        flagged_indices = []\n        for i in range(n_samples):\n            D_i = 0\n            if preds_present[i] and preds_absent[i]:\n                mean_present = np.mean(preds_present[i])\n                mean_absent = np.mean(preds_absent[i])\n                D_i = np.abs(mean_present - mean_absent)\n            \n            if D_i >= tau:\n                flagged_indices.append(i)\n        \n        return sorted(flagged_indices)\n\n    test_cases = [\n        {'k': 5, 'R': 12, 'epsilon': 0.25, 'tau': 0.10},  # Case 1\n        {'k': 5, 'R': 12, 'epsilon': 0.15, 'tau': 0.10},  # Case 2\n        {'k': 4, 'R': 12, 'epsilon': 0.25, 'tau': 0.07},  # Case 3\n    ]\n\n    results = []\n    for i, params in enumerate(test_cases):\n        flagged = run_analysis(i, params)\n        results.append(flagged)\n\n    # Format the final output string\n    output_str = '[' + ','.join([str(lst).replace(' ', '') for lst in results]) + ']'\n    print(output_str)\n\nsolve()\n```", "id": "3139096"}]}