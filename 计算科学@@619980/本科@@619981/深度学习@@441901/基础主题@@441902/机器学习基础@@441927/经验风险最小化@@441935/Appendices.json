{"hands_on_practices": [{"introduction": "经验风险最小化（ERM）的核心思想是找到一个模型，使其在训练数据上的误差最小。这个实践从一个基础的分类问题入手，要求你为一个简单的线性分类器计算在零一损失下的经验风险最小化器。通过将这个解与最大化间隔的解进行对比，本练习旨在揭示一个核心的权衡：仅仅最小化训练误差有时会产生一个对数据扰动非常敏感的“脆弱”模型，而并非总是最佳选择。[@problem_id:3121461]", "problem": "您将设计并分析一个从重叠的高斯类中抽取的一维玩具数据集，并计算线性分类器在0-1损失下的经验风险最小化器。然后，您将把此解与最大化间隔的阈值进行对比，以说明经验风险最小化与间隔最大化之间的张力。\n\n一位数据科学家对两个二元类别建模如下。对于标签 $y = +1$，特征 $x \\in \\mathbb{R}$ 独立地从高斯分布 $\\mathcal{N}(\\mu_{+}, \\sigma_{+}^{2})$ 中抽取；对于标签 $y = -1$，特征独立地从 $\\mathcal{N}(\\mu_{-}, \\sigma_{-}^{2})$ 中抽取。因为 $\\mu_{+}$ 和 $\\mu_{-}$ 很接近且 $\\sigma_{+}, \\sigma_{-} > 0$，所以类条件分布是重叠的。观测到一个包含 $n = 6$ 个带标签样本的数据集：\n- 对于 $y = +1$：三个样本 $x = -0.8, \\; 0.2, \\; 0.3$。\n- 对于 $y = -1$：三个样本 $x = -1.1, \\; 0.5, \\; 1.0$。\n\n考虑由一个阈值 $s \\in \\mathbb{R}$ 参数化的一维线性分类器族：\n$$\nh_{s}(x) = \\operatorname{sign}(x - s),\n$$\n如果 $x \\ge s$，该分类器预测为 $+1$，否则预测为 $-1$。0-1损失下的经验风险为：\n$$\n\\hat{R}(s) = \\frac{1}{n} \\sum_{i=1}^{n} \\mathbf{1}\\!\\left\\{ y_{i} \\ne h_{s}(x_{i}) \\right\\}.\n$$\n任务：\n1. 仅使用上述定义，确定使 $\\hat{R}(s)$ 在 $s \\in \\mathbb{R}$上最小化的经验风险最小化器 $s^{\\star}$。如果存在一个 $s$ 值的区间都能达到相同的最小经验风险，则选择该区间的中点作为规范的最小化器。\n2. 在您的推理过程中（而非最终报告的值中），通过确定使一维几何间隔（定义为 $w = 1$ 和 $b = -s$，因此间隔等于 $\\min_{i} |x_{i} - s|$）最大化的阈值 $s_{\\mathrm{m}}$，并比较 $\\hat{R}(s^{\\star})$ 和 $\\hat{R}(s_{\\mathrm{m}})$，来展示经验风险与间隔最大化之间的张力。\n\n最终答案仅报告 $s^{\\star}$ 的精确值；无需四舍五入。", "solution": "为了找到最小化经验风险 $\\hat{R}(s)$ 的阈值 $s \\in \\mathbb{R}$，我们的目标等价于最小化误分类点的数量 $N_{err}(s)$。\n\n分类器定义为：如果 $x \\ge s$，则 $h_s(x) = +1$；如果 $x  s$，则 $h_s(x) = -1$。一个点 $(x_i, y_i)$ 被误分类，如果：\n-   $y_i = +1$ 且 $h_s(x_i) = -1$，这在 $x_i  s$ 时发生。\n-   $y_i = -1$ 且 $h_s(x_i) = +1$，这在 $x_i \\ge s$ 时发生。\n\n令 $X_{+} = \\{-0.8, 0.2, 0.3\\}$ 为标签 $y=+1$ 的点集，令 $X_{-} = \\{-1.1, 0.5, 1.0\\}$ 为标签 $y=-1$ 的点集。\n对于给定的阈值 $s$，误分类点的数量为：\n$$\nN_{err}(s) = \\sum_{x_i \\in X_{+}} \\mathbf{1}\\{x_i  s\\} + \\sum_{x_j \\in X_{-}} \\mathbf{1}\\{x_j \\ge s\\}\n$$\n$N_{err}(s)$ 的值是一个阶跃函数，其值仅在 $s$ 对应于数据点 $x_i$ 的值时才会改变。我们通过考虑由排序后的数据点定义的区间来分析错误数量。\n排序后的数据点是：$p_1 = -1.1\\;(y=-1)$, $p_2 = -0.8\\;(y=+1)$, $p_3 = 0.2\\;(y=+1)$, $p_4 = 0.3\\;(y=+1)$, $p_5 = 0.5\\;(y=-1)$, $p_6 = 1.0\\;(y=-1)$。\n\n我们针对不同的 $s$ 范围评估 $N_{err}(s)$：\n-   对于 $s \\le -1.1$：所有数据点 $x_i$ 都满足 $x_i \\ge s$，因此对所有 $i$ 都有 $h_s(x_i) = +1$。$X_{-}$ 中的三个点被误分类。$X_{+}$ 中的三个点被正确分类。因此，$N_{err}(s) = 3$。\n-   对于 $s \\in (-1.1, -0.8]$：\n    -   点 $x=-1.1 \\in X_{-}$ 被正确分类为 $h_s(-1.1)=-1$，因为 $-1.1  s$。\n    -   点 $x=\\{0.5, 1.0\\} \\in X_{-}$ 被误分类为 $h_s(x)=+1$，因为 $x > s$。\n    -   所有点 $x \\in X_{+}$ 都满足 $x \\ge s$ 或 $x  s$ 但未达到下一个阈值，它们被正确分类为 $h_s(x)=+1$。更正：点 $x \\in X_+$ 满足 $x \\ge s$，所以被正确分类。\n    -   误分类总数为 $N_{err}(s) = 0 + 2 = 2$。这对半开区间 $(-1.1, -0.8]$ 中的任何 $s$ 都成立。\n-   对于 $s \\in (-0.8, 0.2]$：\n    -   点 $x=-0.8 \\in X_{+}$ 现在被误分类为 $h_s(-0.8)=-1$，因为 $-0.8  s$。\n    -   点 $x=\\{0.2, 0.3\\} \\in X_{+}$ 被正确分类。\n    -   点 $x=\\{0.5, 1.0\\} \\in X_{-}$ 被误分类。点 $x=-1.1 \\in X_{-}$ 被正确分类。\n    -   误分类总数为 $N_{err}(s) = 1 + 2 = 3$。\n-   对于 $s \\in (0.2, 0.3]$：$N_{err}(s) = 2$ (来自 $X_+$) $+ 2$ (来自 $X_-$) $= 4$。\n-   对于 $s \\in (0.3, 0.5]$：$N_{err}(s) = 3$ (来自 $X_+$) $+ 2$ (来自 $X_-$) $= 5$。\n-   对于 $s \\in (0.5, 1.0]$：$N_{err}(s) = 3$ (来自 $X_+$) $+ 1$ (来自 $X_-$) $= 4$。\n-   对于 $s > 1.0$：$N_{err}(s) = 3$ (来自 $X_+$) $+ 0$ (来自 $X_-$) $= 3$。\n\n通过检查，最小错误数为 $N_{err, min} = 2$。对于区间 $(-1.1, -0.8]$ 中的任何阈值 $s$，都可以达到这个最小值。\n问题要求选择该区间的中点作为规范最小化器 $s^{\\star}$。\n$$\ns^{\\star} = \\frac{-1.1 + (-0.8)}{2} = \\frac{-1.9}{2} = -0.95\n$$\n最小经验风险为 $\\hat{R}(s^{\\star}) = \\frac{2}{6} = \\frac{1}{3}$。\n\n接下来，我们确定最大化间隔的阈值 $s_{\\mathrm{m}}$，以展示经验风险和间隔之间的张力。间隔定义为 $\\min_{i} |x_i - s|$。为了最大化这个最小距离，阈值 $s$ 必须位于排序后列表中任意两个连续数据点之间最大间隙的中点。\n排序后的数据点是 $\\{-1.1, -0.8, 0.2, 0.3, 0.5, 1.0\\}$。\n连续点之间的间隙是：\n-   $-0.8 - (-1.1) = 0.3$\n-   $0.2 - (-0.8) = 1.0$\n-   $0.3 - 0.2 = 0.1$\n-   $0.5 - 0.3 = 0.2$\n-   $1.0 - 0.5 = 0.5$\n\n最大间隙是 $1.0$，位于点 $x=-0.8$ 和 $x=0.2$ 之间。最大化间隔的阈值 $s_{\\mathrm{m}}$ 是该区间的中点：\n$$\ns_{\\mathrm{m}} = \\frac{-0.8 + 0.2}{2} = \\frac{-0.6}{2} = -0.3\n$$\n最大间隔为 $\\frac{1.0}{2} = 0.5$。\n\n现在我们计算这个最大化间隔阈值 $s_{\\mathrm{m}} = -0.3$ 的经验风险：\n$N_{err}(s_{\\mathrm{m}}) = N_{err}(-0.3)$。\n-   来自 $X_{+}=\\{-0.8, 0.2, 0.3\\}$ 的误分类点：\n    -   $x=-0.8  -0.3 \\implies$ 分类为 $-1$。误分类。\n-   来自 $X_{-}=\\{-1.1, 0.5, 1.0\\}$ 的误分类点：\n    -   $x=0.5 \\ge -0.3 \\implies$ 分类为 $+1$。误分类。\n    -   $x=1.0 \\ge -0.3 \\implies$ 分类为 $+1$。误分类。\n$s_{\\mathrm{m}}$ 的误分类总数为 $1 + 2 = 3$。经验风险为 $\\hat{R}(s_{\\mathrm{m}}) = \\frac{3}{6} = \\frac{1}{2}$。\n\n现在的张力就很明显了：\n-   经验风险最小化器 $s^{\\star} = -0.95$ 实现了最低的训练误差 ($\\hat{R}(s^{\\star}) = \\frac{1}{3}$)，但它定义的决策边界非常接近数据点 $x=-1.1$ 和 $x=-0.8$。其间隔为 $|-0.95 - (-1.1)| = 0.15$。小间隔可能表示过拟合和泛化能力差。\n-   最大化间隔的阈值 $s_{\\mathrm{m}} = -0.3$ 通过将边界放置在特征空间的最大空白区域中，产生了一个更大的间隔 $0.5$。这是一个更鲁棒的解，但代价是在训练数据上具有更高的经验风险 ($\\hat{R}(s_{\\mathrm{m}}) = \\frac{1}{2}$)。\n\n这说明了统计学习中最小化训练误差和最大化间隔以获得更好泛化能力之间的基本权衡，这是支持向量机（Support Vector Machines）背后的核心概念。纯粹最小化经验风险的解 ($s^{\\star}$) 不同于最大化间隔的解 ($s_{\\mathrm{m}}$)。", "answer": "$$\n\\boxed{-\\frac{19}{20}}\n$$", "id": "3121461"}, {"introduction": "在许多现实世界的应用中，不同类型的分类错误会带来截然不同的后果。例如，在医疗诊断中，漏诊（假阴性）的代价可能远高于误诊（假阳性）。这个实践将风险的概念从简单的错误计数推广到包含非对称成本的更一般形式，要求你推导出一个最优决策阈值来最小化加权后的总风险。这项练习强调了根据具体应用场景来定义和最小化风险的重要性，这正是将理论模型转化为实用工具的关键一步。[@problem_id:3121405]", "problem": "考虑标签为 $y \\in \\{0,1\\}$ 的二元分类问题。一个深度网络输出一个校准分数 $s(x) \\in [0,1]$，该分数被解释为后验概率 $s(x) = \\mathbb{P}(Y=1 \\mid X=x)$。对于一个阈值 $t \\in [0,1]$，定义确定性分类器 $f_{t}(x) = \\mathbb{I}\\{s(x) \\ge t\\}$，其中 $\\mathbb{I}\\{\\cdot\\}$ 是指示函数。假设错分成本是非对称的：当 $y=0$ 时预测为 $1$（假阳性）的成本为 $c_{10}  0$，当 $y=1$ 时预测为 $0$（假阴性）的成本为 $c_{01}  0$，而正确预测的成本为零。因此，损失函数为\n$$\nL\\big(f_{t}(x),y\\big) =\n\\begin{cases}\nc_{10},  \\text{if } f_{t}(x)=1 \\text{ and } y=0,\\\\\nc_{01},  \\text{if } f_{t}(x)=0 \\text{ and } y=1,\\\\\n0,  \\text{otherwise}.\n\\end{cases}\n$$\n给定一个样本 $\\{(x_{i},y_{i})\\}_{i=1}^{n}$ 及其对应的校准分数 $s_{i} = s(x_{i})$，$f_{t}$ 的经验风险为\n$$\n\\hat{R}(t) \\;=\\; \\frac{1}{n} \\sum_{i=1}^{n} L\\big(f_{t}(x_{i}),y_{i}\\big).\n$$\n从上述定义出发，并且不使用任何现成的决策阈值公式，推导出在 $s(x)$ 是一个校准的后验概率且分类器仅限于阈值规则 $f_{t}$ 的假设下，能使 $\\hat{R}(t)$ 在所有 $t \\in [0,1]$ 上最小化的阈值 $t^{\\star}$。请将您的最终结果表示为仅含 $c_{01}$ 和 $c_{10}$ 的单一闭式解析表达式。然后，简要论证非对称成本如何根据真阳性率和假阳性率之间的权衡来决定接收者操作特征 (ROC) 曲线上的最优工作点。您的最终答案必须是 $t^{\\star}$ 的单一闭式表达式。无需四舍五入。", "solution": "为了找到最小化风险的最优决策阈值 $t^{\\star}$，我们应该最小化期望风险（或称真实风险），而不是针对某一特定有限样本的经验风险。这是因为问题要求一个仅依赖于成本 $c_{01}$ 和 $c_{10}$ 的通用解，并且给出了核心假设——分类器分数 $s(x)$ 是一个校准的后验概率，即 $s(x) = \\mathbb{P}(Y=1 \\mid X=x)$。\n\n最小化总体期望风险等价于对每个输入 $x$ 独立地最小化其条件风险。对于一个给定的点 $x$，我们有两种决策选择：预测为1（$\\hat{y}=1$）或预测为0（$\\hat{y}=0$）。它们的条件风险如下：\n\n1.  **预测为1的风险**:\n    如果我们的决策是 $\\hat{y}=1$，可能会发生两种情况：\n    -   真实标签是 $y=1$（真阳性），损失为 $0$。\n    -   真实标签是 $y=0$（假阳性），损失为 $c_{10}$。\n    因此，条件风险为：\n    $R(\\hat{y}=1 \\mid x) = 0 \\cdot \\mathbb{P}(Y=1 \\mid x) + c_{10} \\cdot \\mathbb{P}(Y=0 \\mid x) = c_{10}(1-s(x))$\n\n2.  **预测为0的风险**:\n    如果我们的决策是 $\\hat{y}=0$，可能会发生：\n    -   真实标签是 $y=1$（假阴性），损失为 $c_{01}$。\n    -   真实标签是 $y=0$（真阴性），损失为 $0$。\n    因此，条件风险为：\n    $R(\\hat{y}=0 \\mid x) = c_{01} \\cdot \\mathbb{P}(Y=1 \\mid x) + 0 \\cdot \\mathbb{P}(Y=0 \\mid x) = c_{01}s(x)$\n\n贝叶斯最优决策规则是选择风险较小的决策。因此，我们应该在 $R(\\hat{y}=1 \\mid x) \\le R(\\hat{y}=0 \\mid x)$ 时预测为1。\n$$\nc_{10}(1 - s(x)) \\le c_{01}s(x)\n$$\n展开并整理不等式：\n$$\nc_{10} \\le c_{10}s(x) + c_{01}s(x)\n$$\n$$\nc_{10} \\le (c_{01} + c_{10})s(x)\n$$\n$$\ns(x) \\ge \\frac{c_{10}}{c_{01} + c_{10}}\n$$\n这个不等式告诉我们，当一个点的后验概率 $s(x)$ 大于或等于 $\\frac{c_{10}}{c_{01} + c_{10}}$ 时，预测为1的期望风险更小（或相等）。\n\n由于分类器 $f_t(x)$ 的形式是 $\\mathbb{I}\\{s(x) \\ge t\\}$，它在 $s(x) \\ge t$ 时预测为1。将此与我们推导出的最优决策规则进行比较，可以得出最优阈值 $t^{\\star}$ 正是这个临界值。\n$$\nt^{\\star} = \\frac{c_{10}}{c_{01} + c_{10}}\n$$\n这个阈值直观地平衡了两种错误的代价。例如，如果假阴性的代价 $c_{01}$ 远大于假阳性的代价 $c_{10}$，那么 $t^{\\star}$ 将会很小，使得分类器更倾向于预测正类，以避免代价高昂的假阴性错误。\n\n这种基于成本的阈值选择，决定了在接收者操作特征（ROC）曲线上的最优工作点。ROC曲线描绘了所有可能阈值下的真阳性率（TPR）与假阳性率（FPR）的权衡。一个特定的阈值 $t$ 对应于ROC曲线上的一个点。我们推导出的 $t^{\\star}$ 恰好选择了这样一个点，其上TPR和FPR的交换比率（由ROC曲线的斜率给出）与成本和类别先验概率所定义的期望交换比率相匹配。因此，非对称成本通过移动最优决策阈值，来决定我们愿意用多大的FPR代价来换取TPR的提升，从而在ROC曲线上选定最终的模型工作点。", "answer": "$$ \\boxed{ \\frac{c_{10}}{c_{01} + c_{10}} } $$", "id": "3121405"}, {"introduction": "定义了需要最小化的经验风险之后，我们必须面对一个实际问题：如何有效地找到这个最小值？对于像神经网络这样的复杂模型，我们通常依赖基于梯度的优化算法。这个实践通过一个单神经元模型的编码任务，让你直观地感受模型组件（特别是激活函数）的光滑性对梯度下降法的影响。通过对比非连续的阶跃函数和光滑的Softplus、ELU函数，你将理解为何可微性是成功应用经验风险最小化原理来训练现代深度学习模型的基石。[@problem_id:3121425]", "problem": "考虑一个在经验风险最小化（ERM）框架下的深度学习一维二元分类任务。使用的基本要素是经验风险的定义、平方误差损失和批量梯度下降。设数据集为 $$\\mathcal{D} = \\{(x_i, y_i)\\}_{i=1}^n$$，其中 $$x_i \\in \\mathbb{R}$$ 且 $$y_i \\in \\{0,1\\}$$。定义 $$n = 21$$，$$x_i$$ 为从 $$-2$$ 到 $$2$$ 以 $$0.2$$ 为间距的等距点，即 $$x_i \\in \\{-2.0,-1.8,-1.6,\\dots,1.8,2.0\\}$$，并令 $$y_i = \\mathbb{1}[x_i \\ge 0.5]$$，其中 $$\\mathbb{1}[\\cdot]$$ 表示指示函数。考虑一个单神经元模型 $$f(x) = a(w x + b)$$，其标量参数为 $$w \\in \\mathbb{R}$$ 和 $$b \\in \\mathbb{R}$$，激活函数 $$a(\\cdot)$$ 选自：\n- Heaviside 阶跃函数 $$H(z)$$，当 $$z \\ge 0$$ 时 $$H(z) = 1$$，否则 $$H(z) = 0$$，\n- Softplus 函数 $$s(z) = \\log(1 + e^{z})$$，\n- 指数线性单元（ELU）$$e_{\\alpha}(z) = \\begin{cases} z  \\text{if } z  0 \\\\ \\alpha(\\exp(z) - 1)  \\text{if } z \\le 0 \\end{cases}$$，其中 $$\\alpha = 1$$。\n\n要最小化的经验风险是均方误差 $$\\hat{R}(f) = \\frac{1}{n} \\sum_{i=1}^{n} \\left(f(x_i) - y_i\\right)^2$$。仅从这些定义出发，推导基于 $$\\hat{R}(f)$$ 和所选激活函数数学性质的批量梯度下降的参数更新规则。分析 $$H(z)$$ 的非光滑性如何影响优化器的敏感性，并说明通过 $$s(z)$$ 或 $$e_{\\alpha}(z)$$ 进行平滑如何改变经验风险曲面，从而使基于梯度的优化更加有效。\n\n实现一个完整的、可运行的程序，该程序：\n- 精确地按规定构建 $$\\mathcal{D}$$，\n- 对于给定的激活函数选择、学习率和初始化，执行固定迭代次数的批量梯度下降，\n- 为每个测试用例返回训练后的最终经验风险 $$\\hat{R}(f)$$。\n\n使用以下参数元组 $$\\left(a,\\eta,w_0,b_0,T\\right)$$ 的测试套件，其中 $$a$$ 是激活函数的名称，$$\\eta$$ 是学习率，$$w_0$$ 和 $$b_0$$ 是初始参数，$$T$$ 是迭代次数：\n1. $$\\left(\\text{step},\\,0.1,\\,0.1,\\,0.0,\\,200\\right)$$\n2. $$\\left(\\text{softplus},\\,0.1,\\,0.1,\\,0.0,\\,200\\right)$$\n3. $$\\left(\\text{elu},\\,0.1,\\,0.1,\\,0.0,\\,200\\right)$$\n4. $$\\left(\\text{softplus},\\,0.001,\\,0.1,\\,0.0,\\,2000\\right)$$\n5. $$\\left(\\text{softplus},\\,1.0,\\,0.1,\\,0.0,\\,50\\right)$$\n6. $$\\left(\\text{step},\\,0.1,\\,0.0,\\,0.0,\\,200\\right)$$\n\n您的程序应生成单行输出，其中包含一个逗号分隔的列表形式的结果，并用方括号括起来，每个条目是相应测试用例的最终经验风险 $$\\hat{R}(f)$$，以十进制形式表示。例如，输出格式必须精确为 $$[r_1,r_2,r_3,r_4,r_5,r_6]$$，其中每个 $$r_j$$ 是一个浮点数。", "solution": "该问题要求对一个特定的一维数据集上的单神经元二元分类器进行经验风险最小化（ERM）的分析和实现。我们将首先验证问题，然后推导批量梯度下降所需的数学公式，分析不同激活函数的作用，最后给出实现。\n\n问题陈述提供了以下已知条件：\n- 一个数据集 $$\\mathcal{D} = \\{(x_i, y_i)\\}_{i=1}^n$$，其中 $$n = 21$$。\n- 输入 $$x_i$$ 是从 $$-2$$ 到 $$2$$ 以 $$0.2$$ 为间距的等距点。\n- 标签 $$y_i$$ 由指示函数 $$y_i = \\mathbb{1}[x_i \\ge 0.5]$$ 定义。\n- 一个单神经元模型 $$f(x) = a(w x + b)$$，其标量参数为 $$w, b \\in \\mathbb{R}$$。\n- 为激活函数 $$a(\\cdot)$$ 提供了三种选择：Heaviside 阶跃函数 $$H(z)$$、Softplus 函数 $$s(z) = \\log(1 + e^{z})$$ 和指数线性单元（ELU）$$e_{\\alpha}(z)$$，其中 $$\\alpha=1$$。\n- 经验风险是均方误差（MSE）：$$\\hat{R}(f) = \\frac{1}{n} \\sum_{i=1}^{n} \\left(f(x_i) - y_i\\right)^2$$。\n- 优化算法是批量梯度下降。\n- 提供了一个用于实现的参数 $$(a, \\eta, w_0, b_0, T)$$ 测试套件。\n\n该问题具有科学依据，是适定且客观的。这是机器学习中的一个标准练习，旨在探讨基于梯度的优化对可微性的基本要求。包含不可微的 Heaviside 函数是一个有意的教学选择，旨在将其行为与 Softplus 和 ELU 等光滑激活函数进行对比。该问题是自包含的，并为得出唯一解提供了所有必要的信息。因此，该问题被认为是有效的。\n\n我们接下来推导批量梯度下降的参数更新规则。目标是最小化关于参数 $$w$$ 和 $$b$$ 的经验风险 $$\\hat{R}(w, b)$$。\n令 $$z_i = w x_i + b$$ 为第 $$i$$ 个数据点的预激活值。经验风险为：\n$$\n\\hat{R}(w, b) = \\frac{1}{n} \\sum_{i=1}^{n} \\left(a(z_i) - y_i\\right)^2\n$$\n为了应用梯度下降，我们需要 $$\\hat{R}$$ 关于 $$w$$ 和 $$b$$ 的偏导数。使用链式法则：\n$$\n\\frac{\\partial \\hat{R}}{\\partial w} = \\frac{\\partial}{\\partial w} \\left[ \\frac{1}{n} \\sum_{i=1}^{n} \\left(a(z_i) - y_i\\right)^2 \\right] = \\frac{1}{n} \\sum_{i=1}^{n} 2 \\left(a(z_i) - y_i\\right) \\frac{\\partial a(z_i)}{\\partial w}\n$$\n激活项的导数为 $$\\frac{\\partial a(z_i)}{\\partial w} = \\frac{d a}{d z_i} \\frac{\\partial z_i}{\\partial w} = a'(z_i) \\cdot x_i$$。将其代入，我们得到：\n$$\n\\frac{\\partial \\hat{R}}{\\partial w} = \\frac{2}{n} \\sum_{i=1}^{n} \\left(a(z_i) - y_i\\right) a'(z_i) x_i\n$$\n类似地，对于参数 $$b$$，我们有 $$\\frac{\\partial z_i}{\\partial b} = 1$$。其偏导数为：\n$$\n\\frac{\\partial \\hat{R}}{\\partial b} = \\frac{\\partial}{\\partial b} \\left[ \\frac{1}{n} \\sum_{i=1}^{n} \\left(a(z_i) - y_i\\right)^2 \\right] = \\frac{2}{n} \\sum_{i=1}^{n} \\left(a(z_i) - y_i\\right) a'(z_i)\n$$\n对于学习率为 $$\\eta$$ 的第 $$t$$ 次迭代，批量梯度下降的更新规则是：\n$$\nw_{t+1} = w_t - \\eta \\frac{\\partial \\hat{R}}{\\partial w} \\bigg|_{w_t, b_t}\n$$\n$$\nb_{t+1} = b_t - \\eta \\frac{\\partial \\hat{R}}{\\partial b} \\bigg|_{w_t, b_t}\n$$\n此过程的可行性关键取决于激活函数的导数 $$a'(z)$$。我们现在分析每种情况。\n\n1.  **Heaviside 阶跃函数**: $$H(z) = \\mathbb{1}[z \\ge 0]$$。\n    Heaviside 函数的导数是 Dirac delta 函数 $$\\delta(z)$$，它对于所有 $$z \\ne 0$$ 均为 $$0$$，而在 $$z=0$$ 处未定义。在任何实际实现中，点不太可能精确地落在 $$z=0$$ 上。即便如此，梯度也是未定义的。一种常见的做法是使用次梯度，而在所有点上最直接的导数选择是 $$H'(z) = 0$$。这样一来，梯度 $$\\frac{\\partial \\hat{R}}{\\partial w}$$ 和 $$\\frac{\\partial \\hat{R}}{\\partial b}$$ 就变成了零，而与误差 $$(a(z_i) - y_i)$$ 无关。\n    **分析**：经验风险曲面 $$\\hat{R}(w, b)$$ 变成一个由平坦平台组成的分段常数函数。在这些平台上，梯度处处为零。因此，梯度下降不会取得任何进展；参数 $$w$$ 和 $$b$$ 将保持其初始值不变。这说明了基于梯度的方法的一个根本局限性：它们在几乎处处梯度为零的非光滑曲面上是无效的。\n\n2.  **Softplus**: $$s(z) = \\log(1 + e^z)$$。\n    其导数为 $$s'(z) = \\frac{e^z}{1 + e^z}$$，即逻辑 S 型函数（logistic sigmoid function）$$\\sigma(z)$$。\n    **分析**：导数 $$s'(z)$$ 在所有 $$z \\in \\mathbb{R}$$ 上都是良定义、连续且严格为正的。这确保了经验风险曲面 $$\\hat{R}(w, b)$$ 是光滑的（无限可微）。关于 $$w$$ 和 $$b$$ 的梯度是良定义的，并且通常不为零，为优化器向最小值下降提供了路径。Softplus 函数有效地“平滑”了阶跃函数的硬阈值，使得损失景观适用于基于梯度的优化。\n\n3.  **ELU (其中 $$\\alpha=1$$)**: $$e_1(z) = \\begin{cases} z  \\text{if } z  0 \\\\ e^z - 1  \\text{if } z \\le 0 \\end{cases}$$。\n    其导数为 $$e'_1(z) = \\begin{cases} 1  \\text{if } z  0 \\\\ e^z  \\text{if } z \\le 0 \\end{cases}$$。\n    在 $$z=0$$ 处，导数的左极限是 $$\\lim_{z \\to 0^-} e^z = 1$$，右极限是 $$1$$。因此，该函数处处连续可微（C1 光滑），且 $$e'_1(0) = 1$$。\n    **分析**：与 Softplus 类似，ELU 提供了一个光滑的风险曲面。其导数是连续且非零的（除了当 $$z \\to -\\infty$$ 时），使得梯度下降能够有效运作。当 $$z  0$$ 时，恒为 $$1$$ 的梯度可以防止梯度消失，这一特性在更深的网络中很有用。与 Softplus 一样，它作为非连续激活函数的光滑替代品，使得优化得以成功进行。\n\n实现将展示这些理论属性。对于 Heaviside 函数，我们预期最终风险将与初始风险相同。对于 Softplus 和 ELU，我们预期风险会随着迭代而降低。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and evaluates batch gradient descent for a single-neuron model\n    with different activation functions as specified in the problem.\n    \"\"\"\n\n    # --- 1. Dataset Construction ---\n    n = 21\n    x = np.linspace(-2.0, 2.0, n)\n    y = (x >= 0.5).astype(float)\n\n    # --- 2. Activation Functions and Their Derivatives ---\n    def heaviside(z):\n        return (z >= 0).astype(float)\n\n    def heaviside_prime(z):\n        # The derivative is 0 almost everywhere. We define the subgradient to be 0\n        # at z=0 for numerical stability, which reflects the failure of\n        # gradient descent with step functions.\n        return np.zeros_like(z)\n\n    def softplus(z):\n        # Clip to avoid overflow for large z in np.exp(z)\n        z = np.clip(z, -500, 500)\n        return np.log(1 + np.exp(z))\n\n    def softplus_prime(z):\n        # Sigmoid function. Clip to avoid overflow/underflow.\n        z = np.clip(z, -500, 500)\n        exp_z = np.exp(z)\n        return exp_z / (1 + exp_z)\n\n    def elu(z, alpha=1.0):\n        return np.where(z > 0, z, alpha * (np.exp(z) - 1))\n\n    def elu_prime(z, alpha=1.0):\n        return np.where(z > 0, 1.0, alpha * np.exp(z))\n\n\n    activations = {\n        'step': (heaviside, heaviside_prime),\n        'softplus': (softplus, softplus_prime),\n        'elu': (lambda z: elu(z, 1.0), lambda z: elu_prime(z, 1.0))\n    }\n\n    # --- 3. Test Cases ---\n    test_cases = [\n        ('step', 0.1, 0.1, 0.0, 200),\n        ('softplus', 0.1, 0.1, 0.0, 200),\n        ('elu', 0.1, 0.1, 0.0, 200),\n        ('softplus', 0.001, 0.1, 0.0, 2000),\n        ('softplus', 1.0, 0.1, 0.0, 50),\n        ('step', 0.1, 0.0, 0.0, 200)\n    ]\n\n    results = []\n\n    # --- 4. Main Loop for Batch Gradient Descent ---\n    for case in test_cases:\n        act_name, eta, w0, b0, T = case\n        w, b = w0, b0\n        \n        activation_func, activation_prime = activations[act_name]\n\n        for _ in range(T):\n            # Forward pass\n            z = w * x + b\n            f_x = activation_func(z)\n            \n            # Calculate error\n            error = f_x - y\n\n            # Calculate derivative of activation\n            a_prime = activation_prime(z)\n\n            # Calculate gradients for w and b\n            grad_w = (2 / n) * np.sum(error * a_prime * x)\n            grad_b = (2 / n) * np.sum(error * a_prime)\n\n            # Update parameters\n            w -= eta * grad_w\n            b -= eta * grad_b\n            \n        # After training, calculate the final empirical risk\n        final_predictions = activation_func(w * x + b)\n        final_risk = np.mean((final_predictions - y)**2)\n        results.append(final_risk)\n\n    # --- 5. Output Formatting ---\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3121425"}]}