{"hands_on_practices": [{"introduction": "在处理完整的混合密度网络（MDN）之前，理解其基本构成单元至关重要。本练习将MDN简化为其核心——一组独立的回归模型，以探索数据科学中的一个基本问题：数据预处理。我们将通过一个动手实践的测试，研究缩放和标准化目标变量 $y$ 如何影响学习到的模型参数（特别是方差 $\\sigma_k$）和负对数似然损失，从而巩固您对数据变换如何影响基于似然的模型的理解，这是构建稳健机器学习流程的一项关键技能。[@problem_id:3151379]", "problem": "给定一个简化的混合密度网络 (MDN) 设置，其中包含两个高斯分量和已知的硬分配。对于每个观测索引 $n$，有一个输入 $x_n \\in \\mathbb{R}$、一个标量输出 $y_n \\in \\mathbb{R}$ 和一个已知的分量标签 $z_n \\in \\{0,1\\}$。条件密度模型为\n$$\np(y_n \\mid x_n, z_n = k) = \\mathcal{N}\\big(y_n \\mid a_k x_n + b_k,\\ \\sigma_k^2\\big),\n$$\n其中 $a_k \\in \\mathbb{R}$、$b_k \\in \\mathbb{R}$ 和 $\\sigma_k > 0$ 是待通过最大似然估计的特定于分量的参数。数据集有 $N=11$ 个点，分为两个分量，并提供了标签。给定的数据是：\n\n- 输入 $x$ 和标签 $z$：\n  - $x = [\\,0.0,\\,1.0,\\,2.0,\\,3.0,\\,4.0,\\,5.0,\\,0.5,\\,1.5,\\,2.5,\\,3.5,\\,4.5\\,]$\n  - $z = [\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,1,\\,1,\\,1,\\,1,\\,1\\,]$\n- 输出 $y$：\n  - $y = [\\,0.7,\\,1.4,\\,2.5,\\,3.6,\\,4.3,\\,5.55,\\,1.65,\\,1.45,\\,0.7,\\,0.25,\\,-0.15\\,]$\n\n基本依据和定义：\n- 对于均值为 $m$、方差为 $s^2$ 的标量变量 $y$，其高斯概率密度函数 (PDF) 为\n$$\n\\mathcal{N}(y \\mid m, s^2) = \\frac{1}{\\sqrt{2\\pi s^2}} \\exp\\!\\Big( -\\frac{(y - m)^2}{2 s^2} \\Big).\n$$\n- 在上述模型下，对于独立观测值 $\\{(x_n,y_n,z_n)\\}_{n=1}^N$ 的负对数似然 (NLL) 是\n$$\n\\mathrm{NLL}(a,b,\\sigma) = -\\sum_{n=1}^N \\log p(y_n \\mid x_n, z_n) = \\frac{1}{2}\\sum_{n=1}^N \\left[ \\log\\big(2\\pi \\sigma_{z_n}^2\\big) + \\frac{\\big(y_n - (a_{z_n} x_n + b_{z_n})\\big)^2}{\\sigma_{z_n}^2} \\right].\n$$\n- 对于已知的标签 $z_n$，这可以分解为两个独立的线性高斯回归，每个分量 $k \\in \\{0,1\\}$ 一个，其均值函数为 $a_k x + b_k$，高斯噪声的方差为 $\\sigma_k^2$。\n\n任务：\n1. 对每个分量 $k \\in \\{0,1\\}$ 实现最大似然估计：\n   - 通过最大化分量内的似然来估计线性参数 $(a_k,b_k)$。这等同于使用普通最小二乘法，对以 $[\\,\\mathbf{1},\\,x\\,]$ 为列的设计矩阵，最小化该分量内的残差平方和。\n   - 使用高斯模型下的最大似然估计量，估计方差为\n     $$\n     \\sigma_k^2 = \\frac{1}{N_k} \\sum_{n: z_n = k} \\big( y_n - (a_k x_n + b_k) \\big)^2,\n     $$\n     其中 $N_k$ 是分配给分量 $k$ 的观测数量。\n   - 使用上面提供的公式计算总负对数似然。\n\n2. 检验缩放和标准化 $y$ 如何影响学习到的 $\\sigma_k$ 和 NLL。定义三个转换后的数据集：\n   - 情况 A (基线)：使用给定的原始 $y$。\n   - 情况 B (缩放)：使用 $y^{(s)} = s\\,y$，其中 $s=2.0$ 以及 $s=-0.5$ (两个独立的测试)。\n   - 情况 C (标准化)：计算总体均值 $\\mu_y = \\frac{1}{N}\\sum_{n=1}^N y_n$ 和总体标准差 $\\sigma_y = \\sqrt{\\frac{1}{N}\\sum_{n=1}^N (y_n - \\mu_y)^2}$，然后使用标准化输出 $y^{(\\mathrm{std})} = (y - \\mu_y)/\\sigma_y$。\n\n3. 对于每个转换后的数据集，为 $k \\in \\{0,1\\}$ 重新估计 $(a_k,b_k,\\sigma_k)$ 并重新计算总 NLL。检验以下源自最大似然原理和带截距项的最小二乘法线性性质的论断：\n   - 如果 $y$ 被一个非零标量 $s$ 缩放，则估计的 $\\sigma_k$ 会按 $|s|$ 缩放，即对于 $k \\in \\{0,1\\}$，$\\sigma_k^{(s)} / \\sigma_k \\approx |s|$，并且总 NLL 会偏移 $N \\log|s|$，即 $\\mathrm{NLL}^{(s)} - \\mathrm{NLL} \\approx N \\log|s|$。\n   - 如果 $y$ 被标准化为 $(y - \\mu_y)/\\sigma_y$，则估计的 $\\sigma_k$ 会按 $1/\\sigma_y$ 缩放，即对于 $k \\in \\{0,1\\}$，$\\sigma_k^{(\\mathrm{std})} / \\sigma_k \\approx 1/\\sigma_y$，并且总 NLL 会偏移 $N \\log(1/\\sigma_y)$，即 $\\mathrm{NLL}^{(\\mathrm{std})} - \\mathrm{NLL} \\approx -N \\log \\sigma_y$。\n\n4. 数值测试套件和要求的输出：\n   - 使用原始数据集（情况 A）计算基线 $\\sigma_k$ 和 $\\mathrm{NLL}$。\n   - 测试 $s=2.0$（情况 B.1）和 $s=-0.5$（情况 B.2）。\n   - 使用上面定义的总体标准差（分母为 $N$）进行标准化测试（情况 C）。\n   - 对于三个测试中的每一个（情况 B.1、情况 B.2、情况 C），当且仅当分量级的 $\\sigma_k$ 缩放检查和 NLL 偏移检查都在 $10^{-10}$ 的绝对容差内通过时，输出布尔值 $ \\text{True} $；否则输出 $ \\text{False} $。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，按 $[\\,\\text{Case B.1},\\,\\text{Case B.2},\\,\\text{Case C}\\,]$ 的顺序包含三个测试的结果。例如，输出可能看起来像 $[\\text{True},\\text{True},\\text{True}]$。", "solution": "该问题是有效的。它在科学上基于线性高斯模型的最大似然估计原理，问题陈述清晰，提供了所有必要的数据和定义，并且表述客观。任务涉及标准的统计计算，以及验证在数据转换下估计量和似然行为的既定理论性质。\n\n### 理论基础\n\n该问题研究了具有已知分量分配的简单混合密度网络 (MDN) 的最大似然估计量 (MLE) 的性质。在已知分配 $z_n$ 的情况下，该问题可分解为两个独立的线性回归问题，每个分量 $k \\in \\{0, 1\\}$ 一个。\n\n对于每个分量 $k$，我们将输出 $y_n$ 建模为输入 $x_n$ 的线性函数，并带有加性高斯噪声：\n$y_n = a_k x_n + b_k + \\epsilon_{n,k}$，其中 $\\epsilon_{n,k} \\sim \\mathcal{N}(0, \\sigma_k^2)$。\n最大化该模型的似然等同于最小化负对数似然 (NLL)。\n\n参数 $(a_k, b_k)$ 使用普通最小二乘法 (OLS) 估计，该方法最小化残差平方和 $\\sum_{n: z_n=k} (y_n - (a_k x_n + b_k))^2$。\n方差 $\\sigma_k^2$ 的最大似然估计 (MLE) 是使用估计参数 $(\\hat{a}_k, \\hat{b}_k)$ 计算的残差平方的均值：\n$$\n\\hat{\\sigma}_k^2 = \\frac{1}{N_k} \\sum_{n: z_n=k} \\big(y_n - (\\hat{a}_k x_n + \\hat{b}_k)\\big)^2\n$$\n其中 $N_k$ 是分量 $k$ 中的数据点数量。\n\n一旦找到最优参数，分量 $k$ 的 NLL 就得以简化。NLL 中的残差平方和项变为 $\\sum_{n: z_n=k} (\\dots)^2 / \\hat{\\sigma}_k^2 = (N_k \\hat{\\sigma}_k^2) / \\hat{\\sigma}_k^2 = N_k$。那么总 NLL 为：\n$$\n\\mathrm{NLL} = \\sum_{k=0}^{1} \\frac{N_k}{2} \\left[ \\log(2\\pi \\hat{\\sigma}_k^2) + 1 \\right]\n$$\n该问题测试了这些估计量和 NLL 在目标变量 $y$ 的仿射变换下的行为。如果 $y$ 变换为 $y' = s y + d$，其中 $s$ 是一个缩放因子，$d$ 是一个平移量，则带有截距项 $b_k$ 的线性模型的 OLS 估计量变换为 $\\hat{a}'_k = s \\hat{a}_k$ 和 $\\hat{b}'_k = s \\hat{b}_k + d$。残差变换为 $e'_n = s e_n$，导致估计的标准差按 $|s|$ 缩放，即 $\\hat{\\sigma}'_k = |s|\\hat{\\sigma}_k$。因此，总 NLL 会偏移一个与缩放因子相关的加性常数：$\\mathrm{NLL}' - \\mathrm{NLL} = N \\log|s|$，其中 $N = N_0 + N_1$。问题陈述中的论断是这些原理的直接推论。\n\n### 方法论\n\n解决方案按以下步骤进行：\n\n1.  **数据分区**：根据分量标签 $z_n \\in \\{0, 1\\}$ 将数据集 $\\{(x_n, y_n, z_n)\\}_{n=1}^N$ 划分为两个子集。这样就为每个分量创建了两个独立的数据集。\n\n2.  **参数估计**：一个专用函数为单个分量的数据集 $(x_k, y_k)$ 估计模型参数。\n    *   通过求解正规方程组来找到 OLS 参数 $(a_k, b_k)$。对于一个设计矩阵 $X_k$，其列为截距（全为1的向量）和输入 $x_k$，以及参数向量 $\\beta_k = [b_k, a_k]^T$，我们求解 $(X_k^T X_k) \\beta_k = X_k^T y_k$。\n    *   使用估计的 $\\hat{\\beta}_k$ 进行预测，得到 $\\hat{y}_k = X_k \\hat{\\beta}_k$。\n    *   标准差的最大似然估计 $\\hat{\\sigma}_k$ 计算为均方误差的平方根：$\\hat{\\sigma}_k = \\sqrt{\\frac{1}{N_k} \\sum_{n=1}^{N_k} (y_{k,n} - \\hat{y}_{k,n})^2}$。\n\n3.  **NLL 计算**：使用从最大似然估计性质推导出的简化公式计算总 NLL，将每个分量的贡献相加。\n\n4.  **基线计算 (情况 A)**：首先将上述过程应用于原始、未转换的数据集，以建立标准差 ($\\hat{\\sigma}_{0,\\text{base}}, \\hat{\\sigma}_{1,\\text{base}}$) 和总 NLL ($\\mathrm{NLL}_{\\text{base}}$) 的基线值。\n\n5.  **转换情况 (B 和 C)**：对于 $y$ 的每种指定转换：\n    *   **情况 B (缩放)**：目标变量被缩放：$y^{(s)} = s \\cdot y$，其中 $s=2.0$ 和 $s=-0.5$。\n    *   **情况 C (标准化)**：目标变量被标准化：$y^{(\\mathrm{std})} = (y - \\mu_y) / \\sigma_y$，其中 $\\mu_y$ 和 $\\sigma_y$ 分别是原始 $y$ 向量的样本均值和总体标准差。\n    *   对于每个转换后的数据集，重新估计参数 $(\\hat{a}'_k, \\hat{b}'_k, \\hat{\\sigma}'_k)$ 和新的 NLL，即 $\\mathrm{NLL}'$。\n\n6.  **验证**：将数值计算结果与理论预测进行比较。对于每个测试用例，实现会验证以下两个条件是否在 $10^{-10}$ 的绝对容差内成立：\n    *   **Sigma 缩放**：对于 $k=0$ 和 $k=1$，都有 $\\hat{\\sigma}'_k / \\hat{\\sigma}_{k,\\text{base}} \\approx |s|$。对于标准化，缩放因子是 $1/\\sigma_y$。\n    *   **NLL 偏移**：$\\mathrm{NLL}' - \\mathrm{NLL}_{\\text{base}} \\approx N \\log|s|$。对于标准化，这等于 $N \\log(1/\\sigma_y) = -N \\log(\\sigma_y)$。\n    当且仅当所有相应的检查都满足时，一个测试用例才被视为通过 (True)。\n\n该实现将此逻辑封装在一个独立的脚本中。", "answer": "```python\nimport numpy as np\n\ndef estimate_params_and_nll(x_all, y_all, z_all):\n    \"\"\"\n    Estimates parameters and NLL for the two-component model.\n    \"\"\"\n    params = {}\n    total_nll = 0.0\n    \n    # Total number of observations\n    N = len(x_all)\n    \n    for k in [0, 1]:\n        mask = (z_all == k)\n        x_k = x_all[mask]\n        y_k = y_all[mask]\n        N_k = len(x_k)\n\n        # Design matrix with intercept: X = [1, x]\n        X_k = np.vstack([np.ones(N_k), x_k]).T\n        \n        # Solve normal equations: (X^T X) beta = X^T y for beta = [b, a]^T\n        try:\n            XTX = X_k.T @ X_k\n            XTy = X_k.T @ y_k\n            beta_k = np.linalg.solve(XTX, XTy)\n            b_k, a_k = beta_k[0], beta_k[1]\n        except np.linalg.LinAlgError:\n            # Fallback for singular matrix, though not expected here\n            # For this problem, X is full rank for both components.\n            return None\n\n        # Calculate residuals and MLE variance/sigma\n        y_pred_k = X_k @ beta_k\n        residuals_k = y_k - y_pred_k\n        sigma_k_sq = np.mean(residuals_k**2)\n        sigma_k = np.sqrt(sigma_k_sq)\n        \n        params[k] = {'a': a_k, 'b': b_k, 'sigma': sigma_k}\n\n        # Simplified NLL calculation using MLE properties\n        # NLL_k = (N_k / 2) * (np.log(2 * np.pi * sigma_k_sq) + 1)\n        # total_nll += NLL_k\n    \n    # Alternative and more direct NLL calculation from definition to avoid potential\n    # issues if the simplified formula derivation has subtle assumptions.\n    # It turns out the results are identical.\n    nll_terms = []\n    for i in range(N):\n        k = z_all[i]\n        a, b, sigma = params[k]['a'], params[k]['b'], params[k]['sigma']\n        mean = a * x_all[i] + b\n        sigma_sq = sigma**2\n        term = 0.5 * ( np.log(2 * np.pi * sigma_sq) + ((y_all[i] - mean)**2) / sigma_sq )\n        nll_terms.append(term)\n    \n    total_nll = np.sum(nll_terms)\n\n    return params[0]['sigma'], params[1]['sigma'], total_nll\n\ndef solve():\n    \"\"\"\n    Main function to execute the problem tasks and generate the final output.\n    \"\"\"\n    # Given data\n    x = np.array([0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 0.5, 1.5, 2.5, 3.5, 4.5])\n    y = np.array([0.7, 1.4, 2.5, 3.6, 4.3, 5.55, 1.65, 1.45, 0.7, 0.25, -0.15])\n    z = np.array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n    N = len(x)\n    TOL = 1e-10\n\n    # Case A: Baseline\n    sigma0_base, sigma1_base, nll_base = estimate_params_and_nll(x, y, z)\n\n    # Test cases to evaluate\n    test_cases = [\n        {'type': 'scale', 's': 2.0, 'name': 'Case B.1'},\n        {'type': 'scale', 's': -0.5, 'name': 'Case B.2'},\n        {'type': 'standardize', 'name': 'Case C'}\n    ]\n\n    results = []\n\n    for case in test_cases:\n        if case['type'] == 'scale':\n            s = case['s']\n            y_transformed = s * y\n            \n            sigma0_new, sigma1_new, nll_new = estimate_params_and_nll(x, y_transformed, z)\n            \n            # Check sigma scaling\n            check_sigma0 = np.isclose(sigma0_new / sigma0_base, abs(s), atol=TOL)\n            check_sigma1 = np.isclose(sigma1_new / sigma1_base, abs(s), atol=TOL)\n            \n            # Check NLL shift\n            nll_shift_pred = N * np.log(abs(s))\n            nll_shift_obs = nll_new - nll_base\n            check_nll = np.isclose(nll_shift_obs, nll_shift_pred, atol=TOL)\n            \n            results.append(check_sigma0 and check_sigma1 and check_nll)\n\n        elif case['type'] == 'standardize':\n            mu_y = np.mean(y)\n            sigma_y = np.std(y) # Population std dev (ddof=0)\n            \n            y_transformed = (y - mu_y) / sigma_y\n            \n            sigma0_new, sigma1_new, nll_new = estimate_params_and_nll(x, y_transformed, z)\n            \n            # Check sigma scaling\n            check_sigma0 = np.isclose(sigma0_new / sigma0_base, 1.0 / sigma_y, atol=TOL)\n            check_sigma1 = np.isclose(sigma1_new / sigma1_base, 1.0 / sigma_y, atol=TOL)\n            \n            # Check NLL shift\n            nll_shift_pred = N * np.log(1.0 / sigma_y) # or -N * np.log(sigma_y)\n            nll_shift_obs = nll_new - nll_base\n            check_nll = np.isclose(nll_shift_obs, nll_shift_pred, atol=TOL)\n            \n            results.append(check_sigma0 and check_sigma1 and check_nll)\n\n    # Format the final output as a comma-separated list in brackets\n    print(f\"[{','.join(map(str, results))}]\")\n\n# Run the solver\nsolve()\n\n```", "id": "3151379"}, {"introduction": "解释MDN时的一个关键挑战是“成分切换”问题，即随着输入的改变，混合成分的身份可能变得模糊。本练习提供了一个受控的环境来研究这一现象。您将构建一个合成数据集，其中成分均值被设计为会交叉，然后测试混合系数 $\\pi_k(x)$ 是否保持一致的分配，还是表现出虚假的“翻转”。这项实践有助于培养对MDN参数行为的直觉，并强调了为网络输出选择平滑、行为良好的函数的重要性。[@problem_id:3151388]", "problem": "您必须编写一个完整、可运行的程序，为混合密度网络（Mixture Density Network, MDN）构建并评估一个合成场景，其目标是测试混合系数 $ \\pi_k(x) $ 在跨越模式交叉时是否保持一致的分量分配，而不会出现虚假的标签翻转。您的程序必须实现数据构建和测试逻辑，并且必须打印一行聚合了指定测试套件结果的输出。\n\n您应依赖的数学基础如下。\n\n- 对于一个具有 $ K $ 个分量的 MDN，给定输入 $ x $ 的标量目标 $ y $ 的条件密度为\n  $$ p(y \\mid x) \\;=\\; \\sum_{k=1}^{K} \\pi_k(x)\\, \\mathcal{N}\\!\\big(y \\,\\big|\\, \\mu_k(x),\\, \\sigma_k^2(x)\\big), $$\n  其中 $ \\pi_k(x) \\ge 0 $，$ \\sum_{k=1}^{K} \\pi_k(x) = 1 $，且 $ \\mathcal{N}(\\cdot \\mid m, s^2) $ 表示均值为 $ m $、方差为 $ s^2 $ 的高斯密度。\n- 在典型的 MDN 中，$ \\pi_k(x) $ 是通过对分量特定的 logit 进行 softmax 操作生成的，这些 logit 是 $ x $ 的连续函数。因此，如果 logit 在 $ x $ 上是连续的，那么 $ \\pi_k(x) $ 在 $ x $ 上也是连续的。\n\n您必须构建一个具有两个分量 $ (K = 2) $ 的一维输入 $ x $ 和标量输出 $ y $ 的数据集，其中分量均值作为 $ x $ 的函数会发生交叉。请强制执行以下参数形式用于分量均值和尺度：\n- 均值：$ \\mu_1(x) = x $，$ \\mu_2(x) = -x $（在 $ x = 0 $ 处交叉）。\n- 尺度：$ \\sigma_1(x) = \\sigma_2(x) = \\sigma  0 $（固定的）。\n\n您必须根据下面描述的测试套件中的每个参数集来定义 $ \\pi_1(x) $ 和 $ \\pi_2(x) = 1 - \\pi_1(x) $。您的程序还必须构建一个确定性数据集以配合测试，方法是将一个固定的网格 $ x_i $ 与在固定随机种子下从定义的混合分布 $ p(y \\mid x_i) $ 中抽取的模拟 $ y_i $ 配对。$ y_i $ 值主要是为了满足“构建数据集”的指令；我们感兴趣的测试关注的是 $ \\pi_k(x) $ 随 $ x $ 变化的行为，而不是拟合后的模型。\n\n将“无翻转一致性”测试定义如下（对于 $ K = 2 $）：\n- 对于一个排序后的网格 $ \\{x_i\\}_{i=1}^N $，其中 $ x_1  x_2  \\dots  x_N $，令\n  $$ s_i \\;=\\; \\arg\\max_{k \\in \\{1,2\\}} \\pi_k(x_i), $$\n  平局情况则选择较小的索引（即，如果 $ \\pi_1(x_i) = \\pi_2(x_i) $，则设置 $ s_i = 1 $）。\n- 令变化次数为\n  $$ C \\;=\\; \\sum_{i=1}^{N-1} \\mathbf{1}\\!\\big[s_{i+1} \\ne s_i\\big]. $$\n- 当且仅当 $ C \\le 1 $ 时，声明该分配为“无翻转一致”。直观上，在单个交叉点上，一个一致的分配在 $ x $ 穿越交叉点时最多可能切换一次；多于一次切换则表示存在虚假翻转。\n\n您的程序必须：\n- 为每个参数集构建合成数据集：选择一个均匀网格 $ \\{x_i\\} $，计算 $ \\pi_1(x_i) $ 和 $ \\pi_2(x_i) $，并使用固定的种子从指定的混合分布中抽取 $ y_i $。\n- 应用“无翻转一致性”测试，并为每个测试用例输出一个布尔值。\n\n测试套件。您的程序必须精确实现这些用例，它们涵盖了一个“理想路径”、一个边界情况和一个边缘情况：\n\n- 用例 $ 1 $（理想路径）：$ \\pi_1(x) = \\sigma(\\alpha x) $，其中 $ \\sigma(z) = \\frac{1}{1+e^{-z}} $，参数为 $ \\alpha = 4 $，$ \\sigma = 0.2 $，网格 $ x \\in [-2, 2] $ 上有 $ N = 401 $ 个均匀间隔的点。\n- 用例 $ 2 $（边界情况）：$ \\pi_1(x) = \\sigma(\\alpha x) $，参数为 $ \\alpha = 0 $，使得对所有 $ x $ 都有 $ \\pi_1(x) = \\tfrac{1}{2} $，$ \\sigma = 0.2 $，使用与用例 1 相同的网格。\n- 用例 $ 3 $（边缘振荡 logit）：$ \\pi_1(x) = \\sigma\\big(\\gamma \\sin(\\omega x)\\big) $，参数为 $ \\gamma = 5 $，$ \\omega = 8 $，$ \\sigma = 0.2 $，网格 $ x \\in [-2, 2] $ 上有 $ N = 401 $ 个均匀间隔的点。\n\n对于每个用例，构建的数据集必须使用相同的分量均值 $ \\mu_1(x) = x $，$ \\mu_2(x) = -x $ 和指定的固定尺度 $ \\sigma_1(x) = \\sigma_2(x) = \\sigma $。\n\n最终输出格式。您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表，顺序与给定的三个用例一致。例如，输出必须是这种形式\n$$ [\\text{result}_1,\\text{result}_2,\\text{result}_3] $$\n其中每个 $ \\text{result}_i $ 是一个布尔值。输出中不要求也不允许出现物理单位、角度或百分比。\n\n您的程序必须在内部执行的评分标准：\n- 按规定构建数据集。\n- 为每个用例计算 $ C $。\n- 如果 $ C \\le 1 $ 则输出 $ \\text{True} $，否则输出 $ \\text{False} $，采用上述确切的最终格式，不得包含额外文本。", "solution": "用户提供的问题陈述已经过验证，并被确定为是合理的。它具有科学依据、问题定义清晰、客观，并包含足够的信息以推导出唯一解。\n\n该问题要求实现一个针对合成混合密度网络（MDN）混合系数的“无翻转一致性”测试。该测试旨在验证当输入变量 $x$ 穿过分量均值交叉的区域时，数据点到混合分量的分配不会发生虚假的来回翻转。\n\nMDN 将标量目标 $y$ 在给定标量输入 $x$ 下的条件概率密度建模为 $K=2$ 个高斯分量的混合：\n$$ p(y \\mid x) = \\sum_{k=1}^{2} \\pi_k(x)\\, \\mathcal{N}\\!\\big(y \\,\\big|\\, \\mu_k(x),\\, \\sigma_k^2(x)\\big) $$\n其中 $\\mathcal{N}(y \\mid m, s^2)$ 是均值为 $m$、方差为 $s^2$ 的高斯分布的概率密度函数。混合系数 $\\pi_k(x)$ 是非负的，并且总和为1，即 $\\pi_k(x) \\ge 0$ 且 $\\pi_1(x) + \\pi_2(x) = 1$。分量参数定义如下：\n- 均值：$\\mu_1(x) = x$ 和 $\\mu_2(x) = -x$。这两个均值在 $x=0$ 处相等，产生一个模式交叉点。\n- 标准差：$\\sigma_1(x) = \\sigma_2(x) = \\sigma$，其中 $\\sigma$ 是一个正常数。\n\n混合系数使用标准的 logistic sigmoid 函数定义，我们将其表示为 $\\varsigma(z) = (1+e^{-z})^{-1}$ 以避免与标准差参数 $\\sigma$ 产生混淆。具体来说，$\\pi_1(x)$ 具有给定的参数形式，而 $\\pi_2(x) = 1 - \\pi_1(x)$。\n\n“无翻转一致性”测试在一个包含 $N$ 个输入点的排序网格 $\\{x_i\\}_{i=1}^N$ 上执行。对于每个点 $x_i$，确定主导分量的索引 $s_i$：\n$$ s_i = \\arg\\max_{k \\in \\{1,2\\}} \\pi_k(x_i) $$\n问题规定，平局情况（即当 $\\pi_1(x_i) = \\pi_2(x_i)$ 时）通过将点分配给索引较小的分量 $k=1$ 来解决。该规则可以表示为：\n$$ s_i = \\begin{cases} 1  \\text{if } \\pi_1(x_i) \\ge \\pi_2(x_i) \\\\ 2  \\text{if } \\pi_1(x_i)  \\pi_2(x_i) \\end{cases} $$\n这等价于如果 $\\pi_1(x_i) \\ge 0.5$ 则分配 $s_i=1$，否则 $s_i=2$。\n\n翻转次数 $C$ 是网格中被分配给不同主导分量的连续点的计数：\n$$ C = \\sum_{i=1}^{N-1} \\mathbf{1}[s_{i+1} \\ne s_i] $$\n其中 $\\mathbf{1}[\\cdot]$ 是指示函数。如果 $C \\le 1$，则认为分配是“无翻转一致”的。这允许在整个输入范围内主导分量最多切换一次，这对于简单的单一模式交叉场景是符合预期的。\n\n程序还必须通过从混合分布 $p(y \\mid x_i)$ 中为每个 $x_i$ 抽样 $y_i$ 来生成一个合成数据集，并使用固定的随机种子以保证可复现性。这是一个程序性要求；生成的 $y_i$ 值不用于一致性测试本身。\n\n我们现在分析在 $x \\in [-2, 2]$ 范围内包含 $N=401$ 个均匀间隔点的网格上的三个指定测试用例。标准差固定为 $\\sigma=0.2$。\n\n**用例1：理想路径**\n- 混合系数：$\\pi_1(x) = \\varsigma(4x)$。\n- sigmoid 函数的参数 $4x$ 是 $x$ 的严格单调递增函数。\n- 当 $\\pi_1(x) \\ge 0.5$ 时，主导分量为 $k=1$，这发生在 $4x \\ge 0$ 即 $x \\ge 0$ 时。\n- 当 $x  0$ 时，主导分量为 $k=2$。\n- 主导分量序列 $\\{s_i\\}$ 将在 $x$ 递增通过0时，从 $2$ 精确地转换到 $1$ 一次。\n- 因此，翻转次数 $C$ 将为 $1$。由于 $1 \\le 1$，测试通过。预期结果为 `True`。\n\n**用例2：边界情况**\n- 混合系数：$\\pi_1(x) = \\varsigma(0 \\cdot x) = \\varsigma(0) = 0.5$。\n- 对于所有 $x\n$，$\\pi_1(x) = 0.5$ 且 $\\pi_2(x) = 0.5$。\n- 根据平局打破规则，主导分量始终为 $k=1$。\n- 序列 $\\{s_i\\}$ 是恒定的：对于所有 $i$，$s_i = 1$。\n- 主导分量没有变化，因此 $C = 0$。由于 $0 \\le 1$，测试通过。预期结果为 `True`。\n\n**用例3：边缘振蕩情况**\n- 混合系数：$\\pi_1(x) = \\varsigma(5 \\sin(8x))$。\n- sigmoid 函数的参数 $5\\sin(8x)$ 是一个振蕩函数。\n- 每当 $5\\sin(8x)$ 的符号改变时，主导分量就会切换，这发生在 $\\sin(8x) = 0$ 时。\n- 零点出现在 $8x = m\\pi$（$m$ 为整数），因此 $x = m\\pi/8$。\n- 输入范围是 $x \\in [-2, 2]$，因此 $8x \\in [-16, 16]$。\n- 此范围内的 $m\\pi$ 值对应于 $m \\in [-\\lfloor 16/\\pi \\rfloor, \\lfloor 16/\\pi \\rfloor] = [-\\lfloor 5.09 \\dots \\rfloor, \\lfloor 5.09 \\dots \\rfloor] = [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5]$。\n- 在区间内部或边界上存在 $11$ 个零点交叉。每次交叉都会导致主导分量翻转。\n- 这将导致大约 $10$ 次翻转。离散网格上的确切翻转次数将接近这个数字。\n- 翻转次数 $C$ 将显著大于 $1$。测试失败。预期结果为 `False`。\n\n实现将遵循此逻辑，为每个用例构建数据集并执行翻转计数。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Constructs and evaluates a synthetic scenario for a Mixture Density Network (MDN)\n    to test for \"flipless consistency\" of mixing coefficients across a mode-crossing.\n    \"\"\"\n\n    # Helper function for the logistic sigmoid\n    def sigmoid(z):\n        return 1.0 / (1.0 + np.exp(-z))\n\n    # Test suite parameters\n    # Case format: (name, pi_1_function, std_dev, grid_range, grid_size)\n    test_cases = [\n        (\n            \"happy_path\",\n            lambda x: sigmoid(4.0 * x),\n            0.2,\n            [-2.0, 2.0],\n            401\n        ),\n        (\n            \"boundary\",\n            lambda x: sigmoid(0.0 * x),\n            0.2,\n            [-2.0, 2.0],\n            401\n        ),\n        (\n            \"edge_oscillatory\",\n            lambda x: sigmoid(5.0 * np.sin(8.0 * x)),\n            0.2,\n            [-2.0, 2.0],\n            401\n        ),\n    ]\n\n    results = []\n    # Use a fixed seed for deterministic dataset generation\n    rng = np.random.default_rng(seed=0)\n\n    for case_name, pi_1_func, sigma_std, x_range, n_points in test_cases:\n        # 1. Build the synthetic dataset and MDN parameters\n        x_grid = np.linspace(x_range[0], x_range[1], n_points)\n        \n        # Means\n        mu1 = x_grid\n        mu2 = -x_grid\n        \n        # Mixing coefficients\n        pi1_vals = pi_1_func(x_grid)\n        pi2_vals = 1.0 - pi1_vals\n\n        # Generate y_i values to form the dataset, as per the problem directive.\n        # This part is for fulfilling the \"construct a dataset\" requirement\n        # and does not affect the flipless consistency test result.\n        \n        # Choose components for all points at once based on pi1_vals\n        rand_uniform = rng.random(size=n_points)\n        is_comp1 = rand_uniform  pi1_vals\n        \n        # Sample from each component's distribution\n        samples_comp1 = rng.normal(loc=mu1, scale=sigma_std)\n        samples_comp2 = rng.normal(loc=mu2, scale=sigma_std)\n        \n        # Select the final y based on the chosen component\n        y_grid = np.where(is_comp1, samples_comp1, samples_comp2)\n        # The dataset is now represented by (x_grid, y_grid), though y_grid is not used below.\n\n        # 2. Apply the \"flipless consistency\" test\n        # Determine the dominant component for each point x_i.\n        # s_i = 1 if pi_1(x_i) >= 0.5, else s_i = 2. This handles the tie-break rule.\n        s = np.where(pi1_vals >= 0.5, 1, 2)\n        \n        # Count the number of changes in the dominant component sequence.\n        # This is done by comparing each element with the next one.\n        # np.sum on a boolean array counts the number of True values.\n        num_changes = np.sum(s[:-1] != s[1:])\n        \n        # The test is passed if the number of changes is at most 1.\n        is_consistent = num_changes = 1\n        results.append(is_consistent)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3151388"}, {"introduction": "MDN的强大之处在于它能生成一个完整的概率分布，而不仅仅是一个单点估计。但是，我们如何衡量一个概率性预测的质量呢？本练习将超越如均方误差之类的简单指标，向您介绍严格的评分规则，例如对数分数和连续分级概率分数（CRPS）。通过从第一性原理出发实现这些规则，您将更深刻地体会如何严格评估和比较概率模型，这是从气象学到金融学等领域的一项关键技能。[@problem_id:3151363]", "problem": "考虑一个混合密度网络 (MDN)，它是一种神经网络，为条件目标输出混合分布的参数。在本问题中，MDN 对给定特征的温度的条件预测密度进行建模，记为 $p(T \\mid x)$，其中 $T$ 是温度（单位为摄氏度），$x$ 是一个特征向量。具体来说，MDN 输出一个具有 $K$ 个分量的高斯混合模型：混合权重 $w_k(x)$ 满足 $w_k(x) \\ge 0$ 和 $\\sum_{k=1}^K w_k(x) = 1$，分量均值 $\\mu_k(x)$（单位为摄氏度），以及分量标准差 $\\sigma_k(x)$（单位为摄氏度），其中 $k \\in \\{1,\\dots,K\\}$。因此，$T$ 的预测密度是高斯分布的混合。\n\n你的任务是使用两种正常评分规则来评估这些 MDN 预测密度的校准度：对数分数和连续排序概率分数 (CRPS)。对数分数的定义是在实现的观测值处评估的预测密度的自然对数，而 CRPS 的定义是预测累积分布函数 (CDF) 与观测值的经验 CDF 之间平方差的积分。这两种分数都必须仅从核心概率定义出发进行推导和实现，不能依赖任何预先给出的简化公式。你必须计算每个提供的测试用例的平均（均值）对数分数和平均（均值）CRPS。\n\n使用以下测试套件。每个测试用例由一组独立样本组成，每个样本都给出了实现的观测值 $T$ 以及该样本的 MDN 预测混合参数 $(w_k, \\mu_k, \\sigma_k)_{k=1}^K$。所有温度和标准差的单位均为摄氏度，对数分数使用自然对数（底为 $e$）。CRPS 以摄氏度报告。\n\n测试用例 1 (正常路径：多峰，中等离散度):\n- 样本 1：$T = 21$, $K=3$, $w = [0.5, 0.3, 0.2]$, $\\mu = [18, 22, 26]$, $\\sigma = [2.0, 1.5, 3.5]$。\n- 样本 2：$T = 19$, $K=3$, $w = [0.4, 0.4, 0.2]$, $\\mu = [17, 20, 28]$, $\\sigma = [2.5, 1.2, 4.0]$。\n- 样本 3：$T = 24$, $K=3$, $w = [0.2, 0.5, 0.3]$, $\\mu = [15, 23, 27]$, $\\sigma = [2.0, 2.0, 3.0]$。\n- 样本 4：$T = 29$, $K=3$, $w = [0.3, 0.3, 0.4]$, $\\mu = [16, 21, 30]$, $\\sigma = [1.8, 1.8, 5.0]$。\n- 样本 5：$T = 20$, $K=3$, $w = [0.6, 0.2, 0.2]$, $\\mu = [19, 25, 31]$, $\\sigma = [1.0, 2.5, 6.0]$。\n\n测试用例 2 (边界条件：近乎确定的单分量预测):\n- 样本 1：$T = 20.1$, $K=1$, $w = [1.0]$, $\\mu = [20.0]$, $\\sigma = [0.05]$。\n- 样本 2：$T = 14.8$, $K=1$, $w = [1.0]$, $\\mu = [15.0]$, $\\sigma = [0.1]$。\n- 样本 3：$T = 33.0$, $K=1$, $w = [1.0]$, $\\mu = [30.0]$, $\\sigma = [0.2]$。\n\n测试用例 3 (边缘情况：极端观测值，微小方差和倾斜权重):\n- 样本 1：$T = 22.5$, $K=2$, $w = [0.9, 0.1]$, $\\mu = [22.0, 5.0]$, $\\sigma = [2.0, 0.01]$。\n- 样本 2：$T = 35.0$, $K=2$, $w = [0.01, 0.99]$, $\\mu = [35.0, 25.0]$, $\\sigma = [1.0, 2.0]$。\n- 样本 3：$T = 20.0$, $K=2$, $w = [0.5, 0.5]$, $\\mu = [10.0, 30.0]$, $\\sigma = [1.5, 1.5]$。\n- 样本 4：$T = 16.0$, $K=2$, $w = [0.7, 0.3]$, $\\mu = [28.0, 18.0]$, $\\sigma = [3.0, 0.5]$。\n\n要求:\n- 从核心概率定义推导和实现对数分数和连续排序概率分数 (CRPS)。推导必须从概率密度函数 (PDF) 和累积分布函数 (CDF) 的定义开始，并使用独立随机变量的期望性质。\n- 对于每个样本，为其混合预测分布计算对数分数 $s_{\\log} = \\log p(T \\mid x)$ 和 CRPS $s_{\\mathrm{CRPS}}$。然后计算每个测试用例中所有样本的均值。\n- CRPS 以摄氏度表示，对数分数使用自然对数。\n- 你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，顺序为 [测试用例 1 的平均对数分数, 测试用例 1 的平均 CRPS, 测试用例 2 的平均对数分数, 测试用例 2 的平均 CRPS, 测试用例 3 的平均对数分数, 测试用例 3 的平均 CRPS]。每个数字应四舍五入到六位小数。\n- 该场景、参数和数据在科学上是合理的且自洽的。不允许使用外部数据文件，程序必须是完全自包含和确定性的。测试套件的最终输出必须是浮点数。", "solution": "该问题要求使用对数分数和连续排序概率分数 (CRPS) 来评估混合密度网络 (MDN) 的预测。我们必须首先从基本原理出发，为高斯混合模型 (GMM) 推导出这些分数的计算公式，然后将它们应用于所提供的测试用例。\n\n设给定特征 $x$ 的温度 $T$ 的条件预测密度为一个具有 $K$ 个分量的高斯混合模型 (GMM)：\n$$\np(T \\mid x) = \\sum_{k=1}^{K} w_k \\mathcal{N}(T \\mid \\mu_k, \\sigma_k^2)\n$$\n其中 $w_k$、$\\mu_k$ 和 $\\sigma_k$ 分别是第 $k$ 个分量的权重、均值和标准差。权重满足 $w_k \\ge 0$ 和 $\\sum_{k=1}^{K} w_k = 1$。为简洁起见，我们将观测值 $T_{obs}$ 记为 $y$。\n\n单个高斯分量 $\\mathcal{N}(t \\mid \\mu, \\sigma^2)$ 的概率密度函数 (PDF) 为：\n$$\n\\phi(t; \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{1}{2} \\left(\\frac{t - \\mu}{\\sigma}\\right)^2\\right)\n$$\n相应的累积分布函数 (CDF) 记为 $\\Phi(t; \\mu, \\sigma)$。对于标准正态分布 ($\\mu=0, \\sigma=1$)，我们使用记号 $\\phi(z)$ 和 $\\Phi(z)$。\n\n**1. 对数分数**\n\n对数分数定义为在实际观测值 $y$ 处评估的预测概率密度函数的自然对数。分数越高表示预测越好。\n\n对于一个 GMM，在 $y$ 处的预测密度为：\n$$\np(y \\mid x) = \\sum_{k=1}^{K} w_k \\phi(y; \\mu_k, \\sigma_k)\n$$\n因此，单个观测值 $y$ 的对数分数 $s_{\\log}$ 为：\n$$\ns_{\\log} = \\ln \\left( p(y \\mid x) \\right) = \\ln \\left( \\sum_{k=1}^{K} w_k \\frac{1}{\\sigma_k\\sqrt{2\\pi}} \\exp\\left(-\\frac{1}{2} \\left(\\frac{y - \\mu_k}{\\sigma_k}\\right)^2\\right) \\right)\n$$\n为了评估模型在一个测试用例上的表现，我们计算该用例中所有样本的对数分数的均值。\n\n**2. 连续排序概率分数 (CRPS)**\n\nCRPS 是一种正常评分规则，用于衡量预测分布与观测值之间的差异。它定义为预测 CDF $F(t) = P(X \\le t)$ 与观测值 $y$ 的经验 CDF（即亥维赛德阶跃函数 $H(t-y)$）之间的积分平方误差。\n$$\ns_{CRPS}(F, y) = \\int_{-\\infty}^{\\infty} (F(t) - H(t-y))^2 dt\n$$\n在本问题中，CRPS 的单位与观测值相同，即摄氏度。值越低表示校准度越好。\n\n一个关于 CRPS 的基本且计算上更方便的恒等式用期望来表示它：\n$$\ns_{CRPS}(F, y) = \\mathbb{E}_{X \\sim F}[|X-y|] - \\frac{1}{2}\\mathbb{E}_{X, X' \\sim F}[|X-X'|]\n$$\n其中 $X$ 和 $X'$ 是从具有 CDF $F$ 的预测分布中抽取的独立随机变量。我们将使用这个恒等式来推导 GMM 的 CRPS。\n\n设 $X$ 是从混合分布 $p(t) = \\sum_{k=1}^{K} w_k \\phi(t; \\mu_k, \\sigma_k)$ 中抽取的随机变量。\n\n**第 1 项：$\\mathbb{E}[|X-y|]$**\n根据全期望定律，我们可以写出：\n$$\n\\mathbb{E}[|X-y|] = \\sum_{k=1}^{K} w_k \\mathbb{E}_{Z_k}[|Z_k-y|]\n$$\n其中 $Z_k$ 是从第 $k$ 个分量中抽取的随机变量，$Z_k \\sim \\mathcal{N}(\\mu_k, \\sigma_k^2)$。令 $U_k = Z_k - y$。那么 $U_k \\sim \\mathcal{N}(\\mu_k - y, \\sigma_k^2)$。我们需要找到一个正态分布变量 $U \\sim \\mathcal{N}(m, s^2)$ 的期望 $\\mathbb{E}[|U|]$。这是一个标准结果：\n$$\n\\mathbb{E}[|U|] = 2s\\phi(m/s) + m(2\\Phi(m/s) - 1)\n$$\n将此应用于 $U_k$，其中 $m = \\mu_k - y$，$s = \\sigma_k$，我们得到：\n$$\n\\mathbb{E}_{Z_k}[|Z_k-y|] = 2\\sigma_k\\phi\\left(\\frac{\\mu_k-y}{\\sigma_k}\\right) + (\\mu_k-y)\\left(2\\Phi\\left(\\frac{\\mu_k-y}{\\sigma_k}\\right) - 1\\right)\n$$\n所以，CRPS 的第一项是：\n$$\n\\mathbb{E}[|X-y|] = \\sum_{k=1}^{K} w_k \\left[ 2\\sigma_k\\phi\\left(\\frac{\\mu_k-y}{\\sigma_k}\\right) + (\\mu_k-y)\\left(2\\Phi\\left(\\frac{\\mu_k-y}{\\sigma_k}\\right) - 1\\right) \\right]\n$$\n\n**第 2 项：$\\frac{1}{2}\\mathbb{E}[|X-X'|]$**\n这里，$X$ 和 $X'$ 是从混合分布中进行的独立同分布抽样。\n$$\n\\mathbb{E}[|X-X'|] = \\mathbb{E}\\left[\\left|\\left(\\sum_{i=1}^K w_i Z_i\\right) - \\left(\\sum_{j=1}^K w_j Z_j'\\right)\\right|\\right]\n$$\n这是不正确的。从混合分布中抽样意味着我们首先以概率 $w_k$ 选择一个分量 $k$，然后从 $\\mathcal{N}(\\mu_k, \\sigma_k^2)$ 中抽样。因此：\n$$\n\\mathbb{E}[|X-X'|] = \\sum_{i=1}^{K} \\sum_{j=1}^{K} w_i w_j \\mathbb{E}[|Z_i - Z_j'|]\n$$\n其中 $Z_i \\sim \\mathcal{N}(\\mu_i, \\sigma_i^2)$ 和 $Z_j' \\sim \\mathcal{N}(\\mu_j, \\sigma_j^2)$ 是独立的。差值 $D_{ij} = Z_i - Z_j'$ 也是一个正态随机变量。其均值为 $\\mathbb{E}[D_{ij}] = \\mu_i - \\mu_j$，方差为 $Var(D_{ij}) = \\sigma_i^2 + \\sigma_j^2$。\n因此，$D_{ij} \\sim \\mathcal{N}(\\mu_i - \\mu_j, \\sigma_i^2 + \\sigma_j^2)$。\n我们使用与 $\\mathbb{E}[|U|]$ 相同的公式，其中 $m = \\mu_i - \\mu_j$，$s = \\sqrt{\\sigma_i^2 + \\sigma_j^2}$：\n$$\n\\mathbb{E}[|Z_i - Z_j'|] = 2\\sqrt{\\sigma_i^2 + \\sigma_j^2} \\phi\\left(\\frac{\\mu_i - \\mu_j}{\\sqrt{\\sigma_i^2 + \\sigma_j^2}}\\right) + (\\mu_i - \\mu_j)\\left(2\\Phi\\left(\\frac{\\mu_i - \\mu_j}{\\sqrt{\\sigma_i^2 + \\sigma_j^2}}\\right) - 1\\right)\n$$\nCRPS 的第二项是这个双重求和的期望的 $\\frac{1}{2}$。\n\n**GMM 的最终 CRPS 公式**\n结合这两项，GMM 预测的 CRPS 为：\n\\begin{align*}\ns_{CRPS} =  \\sum_{k=1}^{K} w_k \\left[ \\sigma_k \\left( 2\\phi\\left(\\frac{y-\\mu_k}{\\sigma_k}\\right) + \\frac{y-\\mu_k}{\\sigma_k} \\left(2\\Phi\\left(\\frac{y-\\mu_k}{\\sigma_k}\\right) - 1\\right) \\right) \\right] \\\\\n - \\frac{1}{2} \\sum_{i=1}^{K} \\sum_{j=1}^{K} w_i w_j \\left[ \\sqrt{\\sigma_i^2 + \\sigma_j^2} \\left( 2\\phi\\left(\\frac{\\mu_i - \\mu_j}{\\sqrt{\\sigma_i^2 + \\sigma_j^2}}\\right) + \\frac{\\mu_i - \\mu_j}{\\sqrt{\\sigma_i^2 + \\sigma_j^2}}\\left(2\\Phi\\left(\\frac{\\mu_i - \\mu_j}{\\sqrt{\\sigma_i^2 + \\sigma_j^2}}\\right) - 1\\right) \\right) \\right]\n\\end{align*}\n注意，为了实现上的便利，我们使用了属性 $|-x|=|x|$ 和对称性 $\\phi(-z)=\\phi(z)$、$\\Phi(-z)=1-\\Phi(z)$，将第一项以一种略有不同但等价的形式 $\\mathbb{E}[|y-Z_k|]$ 表达出来。\n\n**算法**\n对于每个测试用例：\n1. 将总对数分数和总 CRPS 初始化为 $0$。\n2. 对于测试用例中的每个样本 $(y, \\{w_k, \\mu_k, \\sigma_k\\}_{k=1}^K)$：\n   a. 使用推导出的公式计算对数分数 $s_{\\log}$。\n   b. 使用推导出的公式计算 CRPS $s_{CRPS}$。\n   c. 将计算出的分数加到各自的总分中。\n3. 将总分除以样本数量，以获得该测试用例的平均对数分数和平均 CRPS。\n4. 收集三个测试用例得到的六个平均值。\n此过程将被实现以生成最终答案。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Solves the MDN evaluation problem by calculating the average logarithmic score\n    and average CRPS for three test cases.\n    \"\"\"\n    test_cases = [\n        # Test Case 1\n        [\n            (21, 3, [0.5, 0.3, 0.2], [18, 22, 26], [2.0, 1.5, 3.5]),\n            (19, 3, [0.4, 0.4, 0.2], [17, 20, 28], [2.5, 1.2, 4.0]),\n            (24, 3, [0.2, 0.5, 0.3], [15, 23, 27], [2.0, 2.0, 3.0]),\n            (29, 3, [0.3, 0.3, 0.4], [16, 21, 30], [1.8, 1.8, 5.0]),\n            (20, 3, [0.6, 0.2, 0.2], [19, 25, 31], [1.0, 2.5, 6.0]),\n        ],\n        # Test Case 2\n        [\n            (20.1, 1, [1.0], [20.0], [0.05]),\n            (14.8, 1, [1.0], [15.0], [0.1]),\n            (33.0, 1, [1.0], [30.0], [0.2]),\n        ],\n        # Test Case 3\n        [\n            (22.5, 2, [0.9, 0.1], [22.0, 5.0], [2.0, 0.01]),\n            (35.0, 2, [0.01, 0.99], [35.0, 25.0], [1.0, 2.0]),\n            (20.0, 2, [0.5, 0.5], [10.0, 30.0], [1.5, 1.5]),\n            (16.0, 2, [0.7, 0.3], [28.0, 18.0], [3.0, 0.5]),\n        ]\n    ]\n\n    def calculate_log_score(T, w, mu, sigma):\n        \"\"\"Calculates the logarithmic score for a single sample.\"\"\"\n        pdf_val = 0.0\n        for i in range(len(w)):\n            pdf_val += w[i] * norm.pdf(T, loc=mu[i], scale=sigma[i])\n        return np.log(pdf_val)\n\n    def expected_abs_normal(m, s):\n        \"\"\"\n        Calculates E[|U|] where U is a normal random variable N(m, s^2).\n        Returns s * [2*phi(m/s) + (m/s)*(2*Phi(m/s) - 1)]\n        \"\"\"\n        if s == 0:\n            return np.abs(m)\n        std_m = m / s\n        return s * (2 * norm.pdf(std_m) + std_m * (2 * norm.cdf(std_m) - 1))\n\n    def calculate_crps(T, w, mu, sigma):\n        \"\"\"Calculates the CRPS for a single GMM sample.\"\"\"\n        # Term 1: E[|X - y|]\n        e_x_y = 0.0\n        for i in range(len(w)):\n            e_x_y += w[i] * expected_abs_normal(mu[i] - T, sigma[i])\n\n        # Term 2: 0.5 * E[|X - X'|]\n        e_x_xp = 0.0\n        for i in range(len(w)):\n            for j in range(len(w)):\n                m_ij = mu[i] - mu[j]\n                s_ij = np.sqrt(sigma[i]**2 + sigma[j]**2)\n                e_x_xp += w[i] * w[j] * expected_abs_normal(m_ij, s_ij)\n        \n        return e_x_y - 0.5 * e_x_xp\n\n    results = []\n    for case in test_cases:\n        total_log_score = 0.0\n        total_crps = 0.0\n        num_samples = len(case)\n\n        for sample in case:\n            T, K, w, mu, sigma = sample\n            w = np.array(w)\n            mu = np.array(mu)\n            sigma = np.array(sigma)\n\n            total_log_score += calculate_log_score(T, w, mu, sigma)\n            total_crps += calculate_crps(T, w, mu, sigma)\n        \n        mean_log_score = total_log_score / num_samples\n        mean_crps = total_crps / num_samples\n        \n        results.append(mean_log_score)\n        results.append(mean_crps)\n\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```", "id": "3151363"}]}