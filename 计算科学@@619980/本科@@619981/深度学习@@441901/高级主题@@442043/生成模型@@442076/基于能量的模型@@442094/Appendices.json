{"hands_on_practices": [{"introduction": "能量模型的训练核心在于最大化数据的对数似然。其梯度有一个独特的结构，分为“正相”和“负相”：正相的作用是降低真实数据点的能量，而负相则提升由模型自身产生样本的能量。本练习通过一个精确可解的特例，让您从第一性原理出发推导这个梯度，从而清晰地理解这两个阶段在参数更新中的作用。[@problem_id:3122263]", "problem": "考虑一个基于能量的模型（Energy-Based Model, EBM），其定义在二维实值输入 $x \\in \\mathbb{R}^{2}$ 上，其密度 $p_{\\theta}(x)$ 由核心EBM原理 $p_{\\theta}(x) = Z(\\theta)^{-1} \\exp(-E_{\\theta}(x))$ 定义，其中配分函数 $Z(\\theta)$ 由 $Z(\\theta) = \\int_{\\mathbb{R}^{2}} \\exp(-E_{\\theta}(x)) \\, dx$ 给出，能量被指定为 $E_{\\theta}(x) = \\frac{1}{2} \\|x\\|^{2} - \\theta^{\\top} x$，参数为 $\\theta \\in \\mathbb{R}^{2}$。给定一个由 $N = 3$ 个二维样本组成的玩具数据集，\n$$\nx^{(1)} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}, \\quad\nx^{(2)} = \\begin{pmatrix} 2 \\\\ 0 \\end{pmatrix}, \\quad\nx^{(3)} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}.\n$$\n从第一性原理出发，即对数似然和配分函数的定义，推导平均对数似然 $\\ell(\\theta) = \\frac{1}{N} \\sum_{i=1}^{N} \\ln p_{\\theta}(x^{(i)})$ 关于 $\\theta$ 的精确梯度，并明确分离出来自数据期望（常称为正相）的贡献和来自模型期望（常称为负相）的贡献。然后，在参数\n$$\n\\theta = \\begin{pmatrix} \\frac{1}{2} \\\\ \\frac{3}{2} \\end{pmatrix}.\n$$\n处计算得到的精确梯度。\n将最终梯度表示为一个单一的精确行向量，在适当的地方使用有理数，并且不要四舍五入。", "solution": "用户希望求出能量基础模型（EBM）的平均对数似然的梯度，并在一个特定点上进行求值。解题过程将主要分三个阶段进行：首先，推导梯度的一般形式；其次，通过识别由给定能量函数定义的特定概率分布来简化梯度；最后，使用提供的数据在指定的参数值处计算该梯度。\n\n对于一个包含 $N$ 个样本 $\\{x^{(i)}\\}_{i=1}^{N}$ 的数据集，其平均对数似然 $\\ell(\\theta)$ 由下式给出：\n$$\n\\ell(\\theta) = \\frac{1}{N} \\sum_{i=1}^{N} \\ln p_{\\theta}(x^{(i)})\n$$\n概率密度函数 $p_{\\theta}(x)$ 定义为 $p_{\\theta}(x) = \\frac{1}{Z(\\theta)} \\exp(-E_{\\theta}(x))$，其中 $E_{\\theta}(x)$ 是能量函数，$Z(\\theta)$ 是配分函数。将此代入对数似然表达式中得到：\n$$\n\\ell(\\theta) = \\frac{1}{N} \\sum_{i=1}^{N} \\left( \\ln\\left(\\frac{1}{Z(\\theta)}\\right) + \\ln(\\exp(-E_{\\theta}(x^{(i)}))) \\right)\n$$\n$$\n\\ell(\\theta) = \\frac{1}{N} \\sum_{i=1}^{N} \\left( - \\ln Z(\\theta) - E_{\\theta}(x^{(i)}) \\right)\n$$\n由于 $\\ln Z(\\theta)$ 不依赖于求和索引 $i$，我们可以将其简化为：\n$$\n\\ell(\\theta) = - \\left( \\frac{1}{N} \\sum_{i=1}^{N} E_{\\theta}(x^{(i)}) \\right) - \\ln Z(\\theta)\n$$\n为了求得关于参数向量 $\\theta$ 的梯度，我们对 $\\ell(\\theta)$ 进行微分：\n$$\n\\nabla_{\\theta} \\ell(\\theta) = - \\frac{1}{N} \\sum_{i=1}^{N} \\nabla_{\\theta} E_{\\theta}(x^{(i)}) - \\nabla_{\\theta} \\ln Z(\\theta)\n$$\n这个表达式将梯度分为两个部分。我们来逐一分析。\n\n第一部分涉及能量函数 $E_{\\theta}(x) = \\frac{1}{2} \\|x\\|^{2} - \\theta^{\\top} x$ 的梯度。关于 $\\theta$ 求导：\n$$\n\\nabla_{\\theta} E_{\\theta}(x) = \\nabla_{\\theta} \\left( \\frac{1}{2} x^{\\top}x - \\theta^{\\top} x \\right) = -x\n$$\n将此代入对数似然梯度的第一部分：\n$$\n- \\frac{1}{N} \\sum_{i=1}^{N} \\nabla_{\\theta} E_{\\theta}(x^{(i)}) = - \\frac{1}{N} \\sum_{i=1}^{N} (-x^{(i)}) = \\frac{1}{N} \\sum_{i=1}^{N} x^{(i)}\n$$\n这一项是数据的经验均值，通常记为 $\\mathbb{E}_{\\text{data}}[x]$ 或 $\\bar{x}$。这是来自数据期望的贡献，称为**正相 (positive phase)**。\n\n第二部分是对数配分函数的梯度，$-\\nabla_{\\theta} \\ln Z(\\theta)$。我们使用对数求导技巧：$\\nabla_{\\theta} \\ln Z(\\theta) = \\frac{1}{Z(\\theta)} \\nabla_{\\theta} Z(\\theta)$。配分函数是 $Z(\\theta) = \\int_{\\mathbb{R}^{2}} \\exp(-E_{\\theta}(x)) \\, dx$。使用莱布尼茨积分法则在积分号下求导：\n$$\n\\nabla_{\\theta} Z(\\theta) = \\int_{\\mathbb{R}^{2}} \\nabla_{\\theta} \\exp(-E_{\\theta}(x)) \\, dx = \\int_{\\mathbb{R}^{2}} \\exp(-E_{\\theta}(x)) (-\\nabla_{\\theta} E_{\\theta}(x)) \\, dx\n$$\n使用我们之前得到的结果 $\\nabla_{\\theta} E_{\\theta}(x) = -x$，我们得到：\n$$\n\\nabla_{\\theta} Z(\\theta) = \\int_{\\mathbb{R}^{2}} x \\exp(-E_{\\theta}(x)) \\, dx\n$$\n因此，对数似然梯度的第二部分是：\n$$\n-\\nabla_{\\theta} \\ln Z(\\theta) = - \\frac{1}{Z(\\theta)} \\int_{\\mathbb{R}^{2}} x \\exp(-E_{\\theta}(x)) \\, dx = - \\int_{\\mathbb{R}^{2}} x \\left( \\frac{\\exp(-E_{\\theta}(x))}{Z(\\theta)} \\right) \\, dx\n$$\n认识到括号中的项是模型的概率密度 $p_{\\theta}(x)$，这个积分是在模型分布下 $x$ 的期望值的定义：\n$$\n-\\nabla_{\\theta} \\ln Z(\\theta) = - \\mathbb{E}_{x \\sim p_{\\theta}(x)}[x]\n$$\n这一项是来自模型期望的贡献，称为**负相 (negative phase)**。\n\n结合正相和负相，平均对数似然的完整梯度是：\n$$\n\\nabla_{\\theta} \\ell(\\theta) = \\underbrace{\\frac{1}{N} \\sum_{i=1}^{N} x^{(i)}}_{\\text{正相}} - \\underbrace{\\mathbb{E}_{x \\sim p_{\\theta}(x)}[x]}_{\\text{负相}}\n$$\n为了计算这个梯度，我们必须求出模型期望 $\\mathbb{E}_{x \\sim p_{\\theta}(x)}[x]$。这需要我们识别出分布 $p_{\\theta}(x)$。我们通过对 $x$ 配方法来分析能量函数 $E_{\\theta}(x) = \\frac{1}{2}\\|x\\|^2 - \\theta^{\\top}x$：\n$$\nE_{\\theta}(x) = \\frac{1}{2} (x^{\\top}x) - \\theta^{\\top}x = \\frac{1}{2} (x^{\\top}x - 2\\theta^{\\top}x)\n$$\n$$\n= \\frac{1}{2} (x^{\\top}x - 2\\theta^{\\top}x + \\theta^{\\top}\\theta - \\theta^{\\top}\\theta) = \\frac{1}{2} ( (x-\\theta)^{\\top}(x-\\theta) - \\theta^{\\top}\\theta )\n$$\n$$\n= \\frac{1}{2}\\|x-\\theta\\|^2 - \\frac{1}{2}\\|\\theta\\|^2\n$$\n因此，概率密度为：\n$$\np_{\\theta}(x) = \\frac{1}{Z(\\theta)} \\exp\\left( -\\left(\\frac{1}{2}\\|x-\\theta\\|^2 - \\frac{1}{2}\\|\\theta\\|^2\\right) \\right) = \\frac{\\exp(\\frac{1}{2}\\|\\theta\\|^2)}{Z(\\theta)} \\exp\\left(-\\frac{1}{2} (x-\\theta)^{\\top} I^{-1} (x-\\theta)\\right)\n$$\n其中 $I$ 是 $2 \\times 2$ 的单位矩阵。这是均值为 $\\mu = \\theta$、协方差矩阵为 $\\Sigma = I$ 的二元高斯分布的函数形式。在 $\\mathbb{R}^d$ 中，一个通用的多元高斯分布 $\\mathcal{N}(\\mu, \\Sigma)$ 的归一化常数是 $(2\\pi)^{d/2} |\\det(\\Sigma)|^{1/2}$。对于我们的情况，$d=2$，$\\mu=\\theta$，$\\Sigma=I$，所以归一化常数是 $(2\\pi)^{2/2} |\\det(I)|^{1/2} = 2\\pi$。\n因此，$p_{\\theta}(x) = \\mathcal{N}(x | \\theta, I)$。\n服从高斯分布 $\\mathcal{N}(\\mu, \\Sigma)$ 的随机变量 $x$ 的期望是其均值 $\\mu$。因此：\n$$\n\\mathbb{E}_{x \\sim p_{\\theta}(x)}[x] = \\theta\n$$\n梯度表达式显著简化为：\n$$\n\\nabla_{\\theta} \\ell(\\theta) = \\bar{x} - \\theta\n$$\n现在我们可以使用给定的数据和参数值来计算这个梯度。首先，我们计算样本均值 $\\bar{x}$：\n$$\nx^{(1)} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}, \\quad x^{(2)} = \\begin{pmatrix} 2 \\\\ 0 \\end{pmatrix}, \\quad x^{(3)} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\n$$\n$$\n\\bar{x} = \\frac{1}{3} \\left( x^{(1)} + x^{(2)} + x^{(3)} \\right) = \\frac{1}{3} \\left( \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} + \\begin{pmatrix} 2 \\\\ 0 \\end{pmatrix} + \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\right) = \\frac{1}{3} \\begin{pmatrix} 0+2+1 \\\\ 1+0+1 \\end{pmatrix} = \\frac{1}{3} \\begin{pmatrix} 3 \\\\ 2 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ \\frac{2}{3} \\end{pmatrix}\n$$\n在 $\\theta = \\begin{pmatrix} \\frac{1}{2} \\\\ \\frac{3}{2} \\end{pmatrix}$ 处计算梯度：\n$$\n\\nabla_{\\theta} \\ell(\\theta) = \\begin{pmatrix} 1 \\\\ \\frac{2}{3} \\end{pmatrix} - \\begin{pmatrix} \\frac{1}{2} \\\\ \\frac{3}{2} \\end{pmatrix} = \\begin{pmatrix} 1 - \\frac{1}{2} \\\\ \\frac{2}{3} - \\frac{3}{2} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{2} \\\\ \\frac{4}{6} - \\frac{9}{6} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{2} \\\\ -\\frac{5}{6} \\end{pmatrix}\n$$\n题目要求将最终梯度表示为一个单一的精确行向量。这是我们计算出的列向量的转置。\n$$\n\\left( \\nabla_{\\theta} \\ell(\\theta) \\right)^{\\top} = \\begin{pmatrix} \\frac{1}{2}  -\\frac{5}{6} \\end{pmatrix}\n$$", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{1}{2}  -\\frac{5}{6} \\end{pmatrix}}\n$$", "id": "3122263"}, {"introduction": "能量模型的一个强大特性是其模块化和可组合性。由于能量是标量，我们可以通过简单的数学运算（如加权平均）来组合不同的能量函数，从而创造出新的、更复杂的模型。本练习将引导您探索如何通过组合两个类别的高斯能量函数来生成平滑的类别过渡，并用代码验证这种“能量插值”的有趣特性。[@problem_id:3122280]", "problem": "考虑一个基于能量的模型（Energy-Based Model, EBM），即一个为数据分配能量函数，并通过指数化和归一化将其转化为概率密度的模型。对于手写数字的类条件设置，假设我们有一个能量函数 $E_{\\theta}(x \\mid y)$，作用于特征向量 $x \\in \\mathbb{R}^d$，并以类别标签 $y$ 为条件，其中 $\\theta$ 表示参数。给定类别 $y$ 时 $x$ 的概率密度定义为\n$$\np_{\\theta}(x \\mid y) = \\frac{\\exp\\left(-E_{\\theta}(x \\mid y)\\right)}{Z_{\\theta}(y)},\n$$\n其中 $Z_{\\theta}(y)$ 是确保归一化的配分函数。\n\n从基于能量模型的核心定义出发，提出一个适用于手写数字中维特征（例如，圆度和倾斜度）的二次型类条件能量，即\n$$\nE_{\\theta}(x \\mid y) = \\frac{1}{2} \\left(x - \\mu_y\\right)^{\\top} \\Sigma_y^{-1} \\left(x - \\mu_y\\right),\n$$\n其中 $\\mu_y \\in \\mathbb{R}^d$ 是依赖于类别的均值，$\\Sigma_y \\in \\mathbb{R}^{d \\times d}$ 是对称正定协方差矩阵。这种选择确保了有限的配分函数和良定义的概率密度。\n\n通过加性能量定义两个类别 $y_0$ 和 $y_1$ 的插值\n$$\nE_{\\alpha}(x) = \\alpha \\, E_{\\theta}(x \\mid y_0) + (1 - \\alpha) \\, E_{\\theta}(x \\mid y_1),\n$$\n插值权重为 $\\alpha \\in [0,1]$。证明 $E_{\\alpha}(x)$ 仍然是二次形式，因此在 $x$ 上导出一个高斯密度，并从第一性原理出发，推导出其均值和协方差的闭式解。\n\n实现一个程序，在给定特定类别参数和插值权重的情况下，计算插值后高斯分布的均值和协方差，然后根据以下量化标准测试“能量相加是否能产生有意义的类别插值”：\n- 边界一致性：在 $\\alpha = 0$ 时，插值分布与类别 $y_1$ 的分布一致；在 $\\alpha = 1$ 时，与类别 $y_0$ 的分布一致。\n- 在协方差相等的情况下，均值的线性插值：如果 $\\Sigma_{y_0} = \\Sigma_{y_1}$，则插值均值等于线性插值 $\\alpha \\mu_{y_0} + (1-\\alpha)\\mu_{y_1}$。\n- 在协方差不相等的情况下，精度加权的偏差：如果 $\\Sigma_{y_1}$ 沿着连接 $\\mu_{y_0}$ 和 $\\mu_{y_1}$ 的直线上的方差小于 $\\Sigma_{y_0}$，则插值均值比朴素线性插值所建议的更偏向于 $\\mu_{y_1}$。\n- 平稳性：在插值均值处计算的 $E_{\\alpha}(x)$ 的梯度是零向量。\n- 方差界限：当 $\\Sigma_{y_0}$ 和 $\\Sigma_{y_1}$ 均为对角矩阵时，插值协方差的每个坐标都位于 $\\Sigma_{y_0}$ 和 $\\Sigma_{y_1}$ 相应坐标之间。\n\n使用以下测试套件，其中 $d = 2$，参数如下指定。在所有情况下，将 $y_0$ 和 $y_1$ 视为两个数字类别：\n\n- 测试 $1$（边界在 $\\alpha = 0$）：$\\mu_{y_0} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$，$\\Sigma_{y_0} = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix}$；$\\mu_{y_1} = \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix}$，$\\Sigma_{y_1} = \\begin{bmatrix} 0.5  0 \\\\ 0  0.5 \\end{bmatrix}$；$\\alpha = 0$。检查 $\\mu_{\\alpha} = \\mu_{y_1}$ 和 $\\Sigma_{\\alpha} = \\Sigma_{y_1}$。\n- 测试 $2$（协方差相等且 $\\alpha = 0.3$）：$\\mu_{y_0} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$，$\\Sigma_{y_0} = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix}$；$\\mu_{y_1} = \\begin{bmatrix} 2 \\\\ 0 \\end{bmatrix}$，$\\Sigma_{y_1} = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix}$；$\\alpha = 0.3$。检查 $\\mu_{\\alpha} = \\alpha \\mu_{y_0} + (1 - \\alpha)\\mu_{y_1}$。\n- 测试 $3$（协方差不相等时的偏差，$\\alpha = 0.5$）：$\\mu_{y_0} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$，$\\Sigma_{y_0} = \\begin{bmatrix} 1.0  0 \\\\ 0  0.5 \\end{bmatrix}$；$\\mu_{y_1} = \\begin{bmatrix} 2 \\\\ 0 \\end{bmatrix}$，$\\Sigma_{y_1} = \\begin{bmatrix} 0.25  0 \\\\ 0  0.5 \\end{bmatrix}$；$\\alpha = 0.5$。设 $t$ 为标量，使得 $\\mu_{\\alpha}$ 在从 $\\mu_{y_0}$ 到 $\\mu_{y_1}$ 的直线上的投影满足 $\\mu_{\\alpha} = \\mu_{y_0} + t(\\mu_{y_1} - \\mu_{y_0})$。检查 $t > \\alpha$ 且 $0 \\le t \\le 1$。\n- 测试 $4$（非对角协方差下的平稳性，$\\alpha = 0.4$）：$\\mu_{y_0} = \\begin{bmatrix} -1 \\\\ 1 \\end{bmatrix}$，$\\Sigma_{y_0} = \\begin{bmatrix} 1.0  0.3 \\\\ 0.3  1.0 \\end{bmatrix}$；$\\mu_{y_1} = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}$，$\\Sigma_{y_1} = \\begin{bmatrix} 1.5  -0.2 \\\\ -0.2  1.0 \\end{bmatrix}$；$\\alpha = 0.4$。检查 $\\nabla E_{\\alpha}(\\mu_{\\alpha}) = \\mathbf{0}$。\n- 测试 $5$（对角协方差下的方差界限，$\\alpha = 0.75$）：$\\mu_{y_0} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$，$\\Sigma_{y_0} = \\begin{bmatrix} 1.0  0 \\\\ 0  4.0 \\end{bmatrix}$；$\\mu_{y_1} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$，$\\Sigma_{y_1} = \\begin{bmatrix} 9.0  0 \\\\ 0  0.25 \\end{bmatrix}$；$\\alpha = 0.75$。检查 $\\Sigma_{\\alpha}$ 的每个对角线元素是否位于 $\\Sigma_{y_0}$ 和 $\\Sigma_{y_1}$ 相应元素之间。\n\n你的程序应产生单行输出，包含一个用方括号括起来的逗号分隔列表（例如，$\\left[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4,\\text{result}_5\\right]$），其中每个条目是一个布尔值，表示相应的测试是否通过。", "solution": "问题陈述已经过验证，被认为是合理的。它在科学上基于能量模型和多元统计学的原理，问题设定良好，提供了所有必要信息，并使用客观、正式的语言进行表述。这些任务在数学上是可行的且可验证的。\n\n该问题要求我们分析一个插值能量函数的性质，该函数由两个二次能量函数（对应于两个类条件高斯分布）的线性组合形成。主要任务是推导所得分布的参数，然后通过一系列数值测试来验证该插值方案的几个关键性质。\n\n### 基于原理的插值高斯参数推导\n\n基于能量的模型通过能量函数 $E(x)$ 将变量 $x$ 上的概率分布定义为 $p(x) \\propto \\exp(-E(x))$。给定的类条件能量函数是：\n$$\nE_{\\theta}(x \\mid y) = \\frac{1}{2} (x - \\mu_y)^{\\top} \\Sigma_y^{-1} (x - \\mu_y)\n$$\n在相差一个加性常数的情况下，这是多元高斯分布 $N(x; \\mu_y, \\Sigma_y)$ 的负对数似然。矩阵 $\\Sigma_y^{-1}$ 被称为精度矩阵。\n\n两个类别 $y_0$ 和 $y_1$ 的插值能量定义为：\n$$\nE_{\\alpha}(x) = \\alpha E_{\\theta}(x \\mid y_0) + (1 - \\alpha) E_{\\theta}(x \\mid y_1)\n$$\n其中 $\\alpha \\in [0,1]$ 是插值权重。\n\n为了证明 $E_{\\alpha}(x)$ 也是二次形式，并找到其对应高斯分布的参数，我们首先代入能量函数的显式形式：\n$$\nE_{\\alpha}(x) = \\frac{\\alpha}{2} (x - \\mu_{y_0})^{\\top} \\Sigma_{y_0}^{-1} (x - \\mu_{y_0}) + \\frac{1-\\alpha}{2} (x - \\mu_{y_1})^{\\top} \\Sigma_{y_1}^{-1} (x - \\mu_{y_1})\n$$\n我们展开二次项。假设 $P$ 是对称的（精度矩阵是对称的），一般二次型 $(x - \\mu)^{\\top}P(x - \\mu)$ 展开为 $x^{\\top}Px - 2\\mu^{\\top}Px + \\mu^{\\top}P\\mu$。应用此公式，我们得到：\n$$\n2E_{\\alpha}(x) = \\alpha (x^{\\top}\\Sigma_{y_0}^{-1}x - 2\\mu_{y_0}^{\\top}\\Sigma_{y_0}^{-1}x + C_0) + (1-\\alpha) (x^{\\top}\\Sigma_{y_1}^{-1}x - 2\\mu_{y_1}^{\\top}\\Sigma_{y_1}^{-1}x + C_1)\n$$\n其中 $C_0$ 和 $C_1$ 是关于 $x$ 的常数。我们可以根据对 $x$ 的依赖性对各项进行分组：\n$$\n2E_{\\alpha}(x) = x^{\\top} \\left( \\alpha\\Sigma_{y_0}^{-1} + (1-\\alpha)\\Sigma_{y_1}^{-1} \\right) x - 2 \\left( \\alpha\\mu_{y_0}^{\\top}\\Sigma_{y_0}^{-1} + (1-\\alpha)\\mu_{y_1}^{\\top}\\Sigma_{y_1}^{-1} \\right) x + C_{total}\n$$\n这个表达式显然是 $x$ 的二次函数。我们可以将此形式与高斯分布 $N(x; \\mu_{\\alpha}, \\Sigma_{\\alpha})$ 的一般能量函数 $E(x) = \\frac{1}{2}(x - \\mu_{\\alpha})^{\\top}\\Sigma_{\\alpha}^{-1}(x - \\mu_{\\alpha}) + \\text{const}$ 进行匹配。展开后得到：\n$$\n2E(x) = x^{\\top}\\Sigma_{\\alpha}^{-1}x - 2\\mu_{\\alpha}^{\\top}\\Sigma_{\\alpha}^{-1}x + \\text{const}\n$$\n通过比较能量的两个表达式中二次项 ($x^{\\top}(\\cdot)x$) 和线性项 ($(\\cdot)x$) 的系数，我们可以确定插值分布的参数 $\\mu_{\\alpha}$ 和 $\\Sigma_{\\alpha}$。\n\n1.  **插值协方差**：比较二次项，我们找到插值分布的逆协方差（精度矩阵）$\\Sigma_{\\alpha}^{-1}$：\n    $$\n    \\Sigma_{\\alpha}^{-1} = \\alpha \\Sigma_{y_0}^{-1} + (1 - \\alpha) \\Sigma_{y_1}^{-1}\n    $$\n    这表明“能量相加”对应于精度矩阵的线性插值。新的协方差矩阵是此结果的逆：\n    $$\n    \\Sigma_{\\alpha} = \\left( \\alpha \\Sigma_{y_0}^{-1} + (1 - \\alpha) \\Sigma_{y_1}^{-1} \\right)^{-1}\n    $$\n    由于 $\\Sigma_{y_0}$ 和 $\\Sigma_{y_1}$ 是正定的，且 $\\alpha \\in [0,1]$，$\\Sigma_{y_0}^{-1}$ 和 $\\Sigma_{y_1}^{-1}$ 也是正定的。它们的加权和 $\\Sigma_{\\alpha}^{-1}$ 也是正定的，确保了 $\\Sigma_{\\alpha}$ 是良定义的且是正定的。\n\n2.  **插值均值**：比较线性项，我们有：\n    $$\n    \\mu_{\\alpha}^{\\top}\\Sigma_{\\alpha}^{-1} = \\alpha\\mu_{y_0}^{\\top}\\Sigma_{y_0}^{-1} + (1-\\alpha)\\mu_{y_1}^{\\top}\\Sigma_{y_1}^{-1}\n    $$\n    为了解出 $\\mu_{\\alpha}$，我们可以对两边进行转置，然后前乘以 $\\Sigma_{\\alpha}$：\n    $$\n    (\\mu_{\\alpha}^{\\top}\\Sigma_{\\alpha}^{-1})^{\\top} = (\\alpha\\mu_{y_0}^{\\top}\\Sigma_{y_0}^{-1} + (1-\\alpha)\\mu_{y_1}^{\\top}\\Sigma_{y_1}^{-1})^{\\top}\n    $$\n    $$\n    (\\Sigma_{\\alpha}^{-1})^{\\top} \\mu_{\\alpha} = (\\alpha\\Sigma_{y_0}^{-1})^{\\top}\\mu_{y_0} + ((1-\\alpha)\\Sigma_{y_1}^{-1})^{\\top}\\mu_{y_1}\n    $$\n    由于精度矩阵是对称的，这可以简化为：\n    $$\n    \\Sigma_{\\alpha}^{-1} \\mu_{\\alpha} = \\alpha\\Sigma_{y_0}^{-1}\\mu_{y_0} + (1-\\alpha)\\Sigma_{y_1}^{-1}\\mu_{y_1}\n    $$\n    最后，前乘以 $\\Sigma_{\\alpha}$：\n    $$\n    \\mu_{\\alpha} = \\Sigma_{\\alpha} \\left( \\alpha\\Sigma_{y_0}^{-1}\\mu_{y_0} + (1-\\alpha)\\Sigma_{y_1}^{-1}\\mu_{y_1} \\right)\n    $$\n    插值分布的均值是各分量均值的精度加权平均。\n\n### 算法设计与测试验证\n\n该实现将使用推导出的闭式表达式来计算 $\\mu_{\\alpha}$ 和 $\\Sigma_{\\alpha}$。五个测试验证了此插值方案的重要行为。\n\n-   **测试 1 (边界一致性)**：在公式中设置 $\\alpha=0$ 得到 $\\Sigma_{\\alpha}^{-1} = \\Sigma_{y_1}^{-1} \\implies \\Sigma_{\\alpha} = \\Sigma_{y_1}$ 和 $\\mu_{\\alpha} = \\Sigma_{y_1}(\\Sigma_{y_1}^{-1}\\mu_{y_1}) = \\mu_{y_1}$。$\\alpha=1$ 的情况是对称的。此测试确认了实现在插值边界处能正确恢复原始分布。\n-   **测试 2 (在协方差相等的情况下，均值的线性插值)**：如果 $\\Sigma_{y_0} = \\Sigma_{y_1} = \\Sigma$，则 $\\Sigma_{\\alpha}^{-1} = (\\alpha + 1-\\alpha)\\Sigma^{-1} = \\Sigma^{-1}$，所以 $\\Sigma_{\\alpha} = \\Sigma$。均值变为 $\\mu_{\\alpha} = \\Sigma(\\alpha\\Sigma^{-1}\\mu_{y_0} + (1-\\alpha)\\Sigma^{-1}\\mu_{y_1}) = \\alpha\\mu_{y_0} + (1-\\alpha)\\mu_{y_1}$。该测试确认了这种特殊情况，即精度加权简化为均值的简单线性插值。\n-   **测试 3 (精度加权的偏差)**：当协方差不相等时，均值会被拉向具有更高精度（更低方差）的分布的均值。方差较低的分量具有“更强”的影响，因为其能量函数从其最小值处上升得更陡。该测试量化了这种偏差。\n-   **测试 4 (平稳性)**：分布的均值也是其众数（概率最大点），这对应于能量函数的极值（最小值）。极值的必要条件是梯度为零。该测试验证了 $\\nabla E_{\\alpha}(\\mu_{\\alpha}) = \\mathbf{0}$，从而确认我们推导出的 $\\mu_{\\alpha}$ 确实是插值能量函数的最小值。梯度为 $\\nabla E_{\\alpha}(x) = \\alpha\\Sigma_{y_0}^{-1}(x-\\mu_{y_0}) + (1-\\alpha)\\Sigma_{y_1}^{-1}(x-\\mu_{y_1})$。代入 $x=\\mu_\\alpha$ 并使用推导的公式，可以从解析上证明其为零。\n-   **测试 5 (方差界限)**：插值精度 $\\Sigma_{\\alpha,ii}^{-1}$ 是分量精度的线性插值。由于函数 $f(v) = 1/v$ 在 $v > 0$ 时是凸函数，插值方差 $(\\Sigma_{\\alpha,ii}^{-1})^{-1}$ 位于分量方差之间。这是加权调和平均数性质的结果。该测试验证了对角协方差矩阵的这种界限性质。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    通过对基于能量模型公式定义的两个高斯分布的插值执行五项测试来解决该问题。\n    \"\"\"\n    \n    test_cases = [\n        # Test 1: Boundary at alpha = 0\n        {\n            \"id\": 1,\n            \"mu0\": np.array([0., 0.]),\n            \"S0\": np.array([[1., 0.], [0., 1.]]),\n            \"mu1\": np.array([2., 1.]),\n            \"S1\": np.array([[0.5, 0.], [0., 0.5]]),\n            \"alpha\": 0.0\n        },\n        # Test 2: Equal covariances and alpha = 0.3\n        {\n            \"id\": 2,\n            \"mu0\": np.array([0., 0.]),\n            \"S0\": np.array([[1., 0.], [0., 1.]]),\n            \"mu1\": np.array([2., 0.]),\n            \"S1\": np.array([[1., 0.], [0., 1.]]),\n            \"alpha\": 0.3\n        },\n        # Test 3: Bias with unequal covariances and alpha = 0.5\n        {\n            \"id\": 3,\n            \"mu0\": np.array([0., 0.]),\n            \"S0\": np.array([[1.0, 0.], [0., 0.5]]),\n            \"mu1\": np.array([2., 0.]),\n            \"S1\": np.array([[0.25, 0.], [0., 0.5]]),\n            \"alpha\": 0.5\n        },\n        # Test 4: Stationarity with off-diagonal covariances and alpha = 0.4\n        {\n            \"id\": 4,\n            \"mu0\": np.array([-1., 1.]),\n            \"S0\": np.array([[1.0, 0.3], [0.3, 1.0]]),\n            \"mu1\": np.array([1., -1.]),\n            \"S1\": np.array([[1.5, -0.2], [-0.2, 1.0]]),\n            \"alpha\": 0.4\n        },\n        # Test 5: Variance bounds with diagonal covariances and alpha = 0.75\n        {\n            \"id\": 5,\n            \"mu0\": np.array([0., 0.]),\n            \"S0\": np.array([[1.0, 0.], [0., 4.0]]),\n            \"mu1\": np.array([0., 0.]),\n            \"S1\": np.array([[9.0, 0.], [0., 0.25]]),\n            \"alpha\": 0.75\n        }\n    ]\n\n    def compute_interpolated_params(mu0, S0, mu1, S1, alpha):\n        \"\"\"\n        Computes the mean and covariance of the interpolated Gaussian distribution.\n        \"\"\"\n        S0_inv = np.linalg.inv(S0)\n        S1_inv = np.linalg.inv(S1)\n        \n        Sa_inv = alpha * S0_inv + (1 - alpha) * S1_inv\n        Sa = np.linalg.inv(Sa_inv)\n        \n        # Note: Sa is pre-multiplied\n        mu_a_term = alpha * (S0_inv @ mu0) + (1 - alpha) * (S1_inv @ mu1)\n        mu_a = Sa @ mu_a_term\n        \n        return mu_a, Sa\n\n    results = []\n    for case in test_cases:\n        mu0, S0, mu1, S1, alpha = case[\"mu0\"], case[\"S0\"], case[\"mu1\"], case[\"S1\"], case[\"alpha\"]\n        mu_a, Sa = compute_interpolated_params(mu0, S0, mu1, S1, alpha)\n        \n        test_id = case[\"id\"]\n        result = False\n        \n        if test_id == 1:\n            check_mu = np.allclose(mu_a, mu1)\n            check_S = np.allclose(Sa, S1)\n            result = check_mu and check_S\n        \n        elif test_id == 2:\n            mu_linear_interp = alpha * mu0 + (1 - alpha) * mu1\n            result = np.allclose(mu_a, mu_linear_interp)\n\n        elif test_id == 3:\n            # We calculated that mu_a lies on the line connecting mu0 and mu1 for this case.\n            # So the projection is mu_a itself.\n            # We solve mu_a = mu0 + t * (mu1-mu0) for t.\n            #  mu_a - mu0 = t * (mu1-mu0)\n            # Take dot product with (mu1-mu0) to solve for t\n            v = mu1 - mu0\n            w = mu_a - mu0\n            t = (w @ v) / (v @ v) if (v @ v) != 0 else 0\n            result = (t > alpha) and (0 = t = 1)\n\n        elif test_id == 4:\n            # Check stationarity: grad E_alpha(mu_a) == 0\n            S0_inv = np.linalg.inv(S0)\n            S1_inv = np.linalg.inv(S1)\n            grad = alpha * S0_inv @ (mu_a - mu0) + (1 - alpha) * S1_inv @ (mu_a - mu1)\n            result = np.allclose(grad, np.zeros_like(grad))\n\n        elif test_id == 5:\n            # Check variance bounds for diagonal matrices\n            Sa_diag = np.diag(Sa)\n            S0_diag = np.diag(S0)\n            S1_diag = np.diag(S1)\n            \n            lower_bounds = np.minimum(S0_diag, S1_diag)\n            upper_bounds = np.maximum(S0_diag, S1_diag)\n            \n            check_lower = np.all(Sa_diag >= lower_bounds)\n            check_upper = np.all(Sa_diag = upper_bounds)\n            result = check_lower and check_upper\n            \n        results.append(result)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3122280"}, {"introduction": "对于大多数复杂的能量模型，梯度中的“负相”（即在模型分布上的期望）是难以精确计算的，必须依赖马尔可夫链蒙特卡洛（MCMC）方法进行近似。采样效率因此成为训练EBM的关键瓶颈。本练习将带您深入研究和比较不同的MCMC采样策略，通过量化分析它们的混合速度，从而理解在实践中如何为EBM选择和设计高效的采样器。[@problem_id:3122336]", "problem": "考虑一个能量模型 (EBM)，其未归一化密度定义为 $p(\\mathbf{x}) \\propto \\exp(-E(\\mathbf{x}))$，其中能量是二次的，$E(\\mathbf{x}) = \\tfrac{1}{2}\\mathbf{x}^{\\top}\\mathbf{A}\\mathbf{x}$，且 $\\mathbf{A} \\in \\mathbb{R}^{d \\times d}$ 是对称正定矩阵。令 $d$ 表示 $\\mathbf{x}$ 的维度。假设没有外场，因此唯一最小值点位于 $\\mathbf{x} = \\mathbf{0}$。\n\n您将比较三种马尔可夫链蒙特卡洛 (MCMC) 更新方案，并通过它们单次扫描的确定性均值更新算子的谱半径以及由此产生的最差模式积分自相关时间来量化它们的混合行为：\n\n- 完整非调整朗之万算法 (ULA)：单步更新定义为 $\\,\\mathbf{x}_{t+1} = \\mathbf{x}_{t} - \\varepsilon \\nabla E(\\mathbf{x}_{t}) + \\sqrt{2\\varepsilon}\\,\\boldsymbol{\\xi}_{t}\\,$，其中 $\\boldsymbol{\\xi}_{t} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$ 且 $\\varepsilon  0$ 是步长。\n- 坐标级 ULA (循环扫描)：顺序应用 $d$ 次坐标更新；对于坐标 $i$，更新 $\\mathbf{x}_{t+1}^{(i)} = \\mathbf{x}_{t}^{(i)} - \\varepsilon \\,\\partial_{i}E(\\mathbf{x}_{t}) + \\sqrt{2\\varepsilon}\\,\\xi_{t}^{(i)}$，在该微步中保持所有其他坐标不变。一次扫描包含 $d$ 个这样的微步，按循环顺序应用。\n- 使用局部能量的块吉布斯 (Block Gibbs)：将坐标划分为大小为 $m$ 的连续块，对于每个块 $b$，用从由二次能量导出的条件高斯分布 $p(\\mathbf{x}_{b} \\mid \\mathbf{x}_{-b})$ 中进行的一次精确抽样来替换 $\\mathbf{x}_{b}$。\n\n从核心定义和事实出发：\n- 对于能量为 $E(\\mathbf{x}) = \\tfrac{1}{2}\\mathbf{x}^{\\top}\\mathbf{A}\\mathbf{x}$ 的 EBM，其梯度为 $\\nabla E(\\mathbf{x}) = \\mathbf{A}\\mathbf{x}$。\n- 对于精度矩阵为 $\\mathbf{A}$ 的高斯模型，给定补集 $-b$ 的情况下，块 $b$ 上的条件分布是高斯分布，其精度矩阵为 $\\mathbf{A}_{bb}$，均值为 $-\\mathbf{A}_{bb}^{-1}\\mathbf{A}_{b,-b}\\mathbf{x}_{-b}$。\n\n对于每种方案，推导经过一次完整扫描后作用于均值的确定性线性算子，完整 ULA 的算子记为 $\\mathbf{M}_{\\text{full}}(\\varepsilon)$，坐标级循环 ULA 扫描的算子记为 $\\mathbf{M}_{\\text{coord}}(\\varepsilon)$，块吉布斯扫描的算子记为 $\\mathbf{M}_{\\text{block}}$。然后，对于每个算子 $\\mathbf{M}$，计算其谱半径 $\\lambda_{\\max}(\\mathbf{M}) = \\max\\{|\\lambda| : \\lambda \\text{ 是 } \\mathbf{M} \\text{ 的特征值}\\}$，以及最差模式积分自相关时间近似值 $\\tau = \\tfrac{1 + \\lambda_{\\max}(\\mathbf{M})}{1 - \\lambda_{\\max}(\\mathbf{M})}$。\n\n使用局部一维耦合模型构造精度矩阵 $\\mathbf{A}(d,\\rho)$：\n- 令 $\\mathbf{L}_{d}$ 为具有狄利克雷边界条件的路径图拉普拉斯算子：对于 $i \\in \\{2,\\dots,d-1\\}$，$(\\mathbf{L}_{d})_{ii} = 2$；$(\\mathbf{L}_{d})_{11} = 1$，$(\\mathbf{L}_{d})_{dd} = 1$；对于 $i \\in \\{1,\\dots,d-1\\}$，$(\\mathbf{L}_{d})_{i,i+1} = (\\mathbf{L}_{d})_{i+1,i} = -1$；所有其他元素为零。\n- 对于耦合参数 $\\rho \\in [0,1)$，定义 $\\mathbf{A}(d,\\rho) = (1 - \\rho)\\,\\mathbf{I}_{d} + \\rho\\,\\mathbf{L}_{d}$，这确保了 $\\mathbf{A}$ 是对称正定的。\n\n对于非调整朗之万算法的步长，使用 $\\varepsilon(d,\\rho) = \\tfrac{0.9}{\\lambda_{\\max}(\\mathbf{A}(d,\\rho))}$，其中 $\\lambda_{\\max}(\\mathbf{A})$ 表示 $\\mathbf{A}$ 的最大特征值。\n\n测试套件：\n为以下四个测试用例提供结果，每个用例由 $(d,\\rho,m)$ 指定：\n- 用例 1：$(d=\\;10,\\;\\rho=\\;0.3,\\;m=\\;5)$。\n- 用例 2：$(d=\\;100,\\;\\rho=\\;0.9,\\;m=\\;10)$。\n- 用例 3：$(d=\\;50,\\;\\rho=\\;0.0,\\;m=\\;5)$。\n- 用例 4：$(d=\\;100,\\;\\rho=\\;0.99,\\;m=\\;20)$。\n\n对于每个用例，您的程序必须：\n- 构建 $\\mathbf{A}(d,\\rho)$。\n- 计算 $\\varepsilon(d,\\rho)$。\n- 仅根据上述定义，构造单次扫描的确定性均值算子 $\\mathbf{M}_{\\text{full}}(\\varepsilon)$、$\\mathbf{M}_{\\text{coord}}(\\varepsilon)$ 和 $\\mathbf{M}_{\\text{block}}$。\n- 为每个算子计算 $\\lambda_{\\max}$，并为每种方案计算相应的 $\\tau$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的每个元素对应一个测试用例，并且本身是一个包含三个浮点数 $[\\tau_{\\text{full}},\\tau_{\\text{coord}},\\tau_{\\text{block}}]$ 的列表。例如，输出应类似于 $[[\\tau_{1,\\text{full}},\\tau_{1,\\text{coord}},\\tau_{1,\\text{block}}],[\\tau_{2,\\text{full}},\\tau_{2,\\text{coord}},\\tau_{2,\\text{block}}],\\dots]$。此问题不涉及物理单位；所有量均为无量纲实数。", "solution": "我们从能量模型 (EBM) 的定义 $p(\\mathbf{x}) \\propto \\exp(-E(\\mathbf{x}))$ 开始，其能量为二次形式 $E(\\mathbf{x}) = \\tfrac{1}{2}\\mathbf{x}^{\\top}\\mathbf{A}\\mathbf{x}$，其中 $\\mathbf{A} \\in \\mathbb{R}^{d \\times d}$ 是对称正定矩阵。能量的梯度为 $\\nabla E(\\mathbf{x}) = \\mathbf{A}\\mathbf{x}$。由于模型是零中心的（没有线性项），因此在分布 $p$ 下的目标均值为 $\\mathbf{0}$。\n\n我们通过分析三种方案在一次扫描中对均值的确定性线性作用来研究它们。由于注入的噪声均值为零，均值的演化由确定性部分控制，对于线性高斯目标，均值更新是 $\\mathbf{x}$ 的线性函数。因此，均值的收缩完全由相应线性算子的谱半径来刻画。\n\n完整非调整朗之万算法 (ULA)：\n单步 ULA 更新为 $\\mathbf{x}_{t+1} = \\mathbf{x}_{t} - \\varepsilon \\nabla E(\\mathbf{x}_{t}) + \\sqrt{2\\varepsilon}\\boldsymbol{\\xi}_{t} = \\mathbf{x}_{t} - \\varepsilon \\mathbf{A}\\mathbf{x}_{t} + \\sqrt{2\\varepsilon}\\boldsymbol{\\xi}_{t}$，其中 $\\boldsymbol{\\xi}_{t} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$。取期望并使用 $\\mathbb{E}[\\boldsymbol{\\xi}_{t}] = \\mathbf{0}$，均值更新为 $\\mathbb{E}[\\mathbf{x}_{t+1}] = (\\mathbf{I} - \\varepsilon \\mathbf{A})\\mathbb{E}[\\mathbf{x}_{t}]$。因此，确定性均值算子是\n$$\n\\mathbf{M}_{\\text{full}}(\\varepsilon) = \\mathbf{I} - \\varepsilon \\mathbf{A}.\n$$\n只要谱半径 $\\lambda_{\\max}(\\mathbf{M}_{\\text{full}}(\\varepsilon))  1$，该链在均值上就是收缩的，这可以通过选择 $\\varepsilon$ 以使对于所有特征值 $\\lambda_{j}(\\mathbf{A})$ 都有 $|1 - \\varepsilon \\lambda_{j}(\\mathbf{A})|  1$ 来保证。一个充分条件是 $\\varepsilon  \\tfrac{2}{\\lambda_{\\max}(\\mathbf{A})}$。我们使用保守的选择 $\\varepsilon = \\tfrac{0.9}{\\lambda_{\\max}(\\mathbf{A})}$，以使 $\\lambda_{\\max}(\\mathbf{M}_{\\text{full}})$ 稳定地保持在 1 以下。\n\n坐标级 ULA (循环扫描)：\n考虑通过一维 ULA 步骤单独更新坐标 $i$，在该微步中保持其他坐标固定。该微步的确定性更新是 $\\mathbf{x}' = \\mathbf{x} - \\varepsilon\\,\\mathbf{P}_{i}\\,\\mathbf{A}\\,\\mathbf{x}$，其中 $\\mathbf{P}_{i} = \\mathbf{e}_{i}\\mathbf{e}_{i}^{\\top}$ 是一个投影，仅保留第 $i$ 行有效并将所有其他行置零，而 $\\mathbf{e}_{i}$ 是第 $i$ 个标准基向量。添加到坐标 $i$ 的噪声均值为零，不影响均值算子。因此，坐标 $i$ 的单步算子是\n$$\n\\mathbf{M}_{i}(\\varepsilon) = \\mathbf{I} - \\varepsilon\\,\\mathbf{e}_{i}\\mathbf{e}_{i}^{\\top}\\mathbf{A}.\n$$\n一次完整的循环扫描按 $i = 1,2,\\dots,d$ 的顺序更新坐标，得到的复合均值算子为\n$$\n\\mathbf{M}_{\\text{coord}}(\\varepsilon) = \\mathbf{M}_{d}(\\varepsilon)\\,\\mathbf{M}_{d-1}(\\varepsilon)\\,\\cdots\\,\\mathbf{M}_{1}(\\varepsilon).\n$$\n由于每个 $\\mathbf{M}_{i}(\\varepsilon)$ 在第 $i$ 行上是收缩的，并在该微步中保持其他行不变，因此乘积捕捉了跨坐标的累积收缩。谱半径 $\\lambda_{\\max}(\\mathbf{M}_{\\text{coord}}(\\varepsilon))$ 量化了一次扫描中均值的最差情况衰减。\n\n使用局部能量的块吉布斯：\n对于精度矩阵为 $\\mathbf{A}$ 的高斯 EBM，给定其补集 $-b$ 时块 $b$ 的条件分布是高斯的，其精度矩阵为 $\\mathbf{A}_{bb}$，均值为 $-\\mathbf{A}_{bb}^{-1}\\mathbf{A}_{b,-b}\\mathbf{x}_{-b}$。单次块吉布斯更新将 $\\mathbf{x}_{b}$ 设置为此条件均值加上与 $\\mathbf{x}_{-b}$ 无关的零均值噪声。因此，该块的确定性均值映射为\n$$\n\\mathbf{x}'_{b} = -\\mathbf{A}_{bb}^{-1}\\mathbf{A}_{b,-b}\\,\\mathbf{x}_{-b}, \\quad \\mathbf{x}'_{-b} = \\mathbf{x}_{-b}.\n$$\n这定义了一个块更新算子 $\\mathbf{M}_{b}$，它是一个线性映射，将对应于块 $b$ 的行替换为作用于补集上的 $-\\mathbf{A}_{bb}^{-1}\\mathbf{A}_{b,-b}$ 和作用于块本身的零，同时保持补集坐标为单位映射。对块 $b_{1},b_{2},\\dots$ 进行一次完整扫描会产生复合算子\n$$\n\\mathbf{M}_{\\text{block}} = \\mathbf{M}_{b_{K}}\\,\\mathbf{M}_{b_{K-1}}\\,\\cdots\\,\\mathbf{M}_{b_{1}},\n$$\n其中 $K$ 是划分中的块数。因为块更新使用精确的条件分布，它们可以在单一步骤中消除块内相关性，剩余的收缩由块间耦合决定。\n\n与混合及积分自相关时间的联系：\n对于均值更新为 $\\mathbf{m}_{t+1} = \\mathbf{M}\\,\\mathbf{m}_{t}$ 且稳态均值为零的线性高斯马尔可夫链，与最大模特征值相关联的本征模在延迟为 $k$ 时的最差模式自相关以 $\\lambda_{\\max}(\\mathbf{M})^{k}$ 的速率衰减。对于标量自回归过程 $x_{t+1} = \\lambda x_{t} + \\text{noise}$，当 $|\\lambda|1$ 时，积分自相关时间为 $\\tau = \\tfrac{1+\\lambda}{1-\\lambda}$。作为多变量情况下的一个保守的最差模式代理，我们使用\n$$\n\\tau(\\mathbf{M}) = \\frac{1 + \\lambda_{\\max}(\\mathbf{M})}{1 - \\lambda_{\\max}(\\mathbf{M})},\n$$\n当 $\\lambda_{\\max}(\\mathbf{M}) \\to 1$ 时，该值会迅速增加。\n\n精度矩阵的构造：\n我们通过具有狄利克雷边界的路径图拉普拉斯算子 $\\mathbf{L}_{d}$ 来使用局部一维耦合：$(\\mathbf{L}_{d})_{ii} = 2$ 对 $i \\in \\{2,\\dots,d-1\\}$，$(\\mathbf{L}_{d})_{11} = 1$，$(\\mathbf{L}_{d})_{dd} = 1$，$(\\mathbf{L}_{d})_{i,i+1} = (\\mathbf{L}_{d})_{i+1,i} = -1$ 对 $i \\in \\{1,\\dots,d-1\\}$，其余元素为零。精度矩阵为\n$$\n\\mathbf{A}(d,\\rho) = (1 - \\rho)\\,\\mathbf{I}_{d} + \\rho\\,\\mathbf{L}_{d},\n$$\n它是对称正定的，适用于 $\\rho \\in [0,1)$。\n\n步长的选择：\n完整 ULA 算子为 $\\mathbf{M}_{\\text{full}}(\\varepsilon) = \\mathbf{I} - \\varepsilon \\mathbf{A}$。为确保收缩并避免不稳定性，我们选择\n$$\n\\varepsilon(d,\\rho) = \\frac{0.9}{\\lambda_{\\max}(\\mathbf{A}(d,\\rho))},\n$$\n该值小于 $\\tfrac{2}{\\lambda_{\\max}(\\mathbf{A})}$ 并保持 $|1 - \\varepsilon \\lambda_{j}(\\mathbf{A})| \\leq 1 - 0.9 \\,\\tfrac{\\lambda_{j}(\\mathbf{A})}{\\lambda_{\\max}(\\mathbf{A})}  1$。\n\n算子的算法构造：\n- 通过 $\\mathbf{I} - \\varepsilon \\mathbf{A}$ 直接计算 $\\mathbf{M}_{\\text{full}}(\\varepsilon)$。\n- 对于坐标级 ULA，定义 $\\mathbf{M}_{i}(\\varepsilon) = \\mathbf{I} - \\varepsilon\\,\\mathbf{e}_{i}\\mathbf{e}_{i}^{\\top}\\mathbf{A}$，并通过有序乘法 $\\mathbf{M}_{\\text{coord}}(\\varepsilon) = \\mathbf{M}_{d}(\\varepsilon)\\cdots\\mathbf{M}_{1}(\\varepsilon)$ 构成 $\\mathbf{M}_{\\text{coord}}(\\varepsilon)$。\n- 对于块吉布斯，对每个索引集为 $\\mathcal{I}_{b}$ 的连续块 $b$，取子矩阵 $\\mathbf{A}_{bb}$ 和 $\\mathbf{A}_{b,-b}$，计算 $\\mathbf{K}_{b} = -\\mathbf{A}_{bb}^{-1}\\mathbf{A}_{b,-b}$，并通过将行 $\\mathcal{I}_{b}$ 替换为作用于补集列上的 $\\mathbf{K}_{b}$ 和作用于块列上的零，同时在补集行上保留单位矩阵来构成 $\\mathbf{M}_{b}$。顺序相乘以获得 $\\mathbf{M}_{\\text{block}}$。\n\n混合比较以及块吉布斯加速的情况：\n对于局部耦合，例如使用 $\\mathbf{L}_{d}$ 的情况，$\\mathbf{A}(d,\\rho)$ 的谱中有一个最小特征值，它随着 $d$ 的增长而减小（对于狄利克雷拉普拉斯算子，$\\lambda_{\\min} = \\Theta(d^{-2})$）。当 $\\varepsilon$ 按 $\\lambda_{\\max}^{-1}$ 缩放时，$\\mathbf{M}_{\\text{full}}$ 的最大模特征值的行为类似于 $1 - c\\,\\tfrac{\\lambda_{\\min}}{\\lambda_{\\max}}$，随着 $d$ 的增加而趋近于 1，从而导致较大的 $\\tau$。坐标级 ULA 复合了单行收缩，并保留了缓慢的坐标间传播，导致在强耦合区域产生相似或更差的谱半径。相比之下，块吉布斯使用精确的条件分布来立即消除块内模式；剩余的收缩由通过舒尔补的块间耦合控制，当 $\\rho$ 很大且 $m$ 捕捉了局部邻域时，会产生显著更小的 $\\lambda_{\\max}(\\mathbf{M}_{\\text{block}})$。这种效应在具有强局部相关性的高维情况下被放大，其中较大的块缓解了 $\\mathbf{A}$ 的小特征值瓶颈。\n\n我们为四个测试用例实现了上述过程：$(d=\\;10,\\;\\rho=\\;0.3,\\;m=\\;5)$、$(d=\\;100,\\;\\rho=\\;0.9,\\;m=\\;10)$、$(d=\\;50,\\;\\rho=\\;0.0,\\;m=\\;5)$、$(d=\\;100,\\;\\rho=\\;0.99,\\;m=\\;20)$。对于每个用例，我们计算 $\\tau_{\\text{full}}$、$\\tau_{\\text{coord}}$ 和 $\\tau_{\\text{block}}$。在弱耦合或独立的情况下（例如 $\\rho = 0$），块吉布斯产生立即的去相关（$\\lambda_{\\max} = 0$ 和 $\\tau = 1$），而在强耦合、高维的情况下，块吉布斯实现了比完整 ULA 和坐标级 ULA 都显著更小的 $\\lambda_{\\max}$，因此也得到更小的 $\\tau$，这展示了由于利用局部能量而实现的加速混合。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef build_laplacian_dirichlet(d: int) - np.ndarray:\n    \"\"\"\n    Build the 1D path-graph Laplacian L_d with Dirichlet boundary entries:\n    diag = [1, 2, 2, ..., 2, 1], off-diagonals = -1 on immediate neighbors.\n    \"\"\"\n    L = np.zeros((d, d), dtype=np.float64)\n    for i in range(d):\n        if i == 0 or i == d - 1:\n            L[i, i] = 1.0\n        else:\n            L[i, i] = 2.0\n        if i + 1  d:\n            L[i, i + 1] = -1.0\n            L[i + 1, i] = -1.0\n    return L\n\ndef build_precision_matrix(d: int, rho: float) - np.ndarray:\n    \"\"\"\n    A(d, rho) = (1 - rho) * I + rho * L_d, where L_d is the Dirichlet Laplacian.\n    \"\"\"\n    L = build_laplacian_dirichlet(d)\n    A = (1.0 - rho) * np.eye(d, dtype=np.float64) + rho * L\n    return A\n\ndef step_size(A: np.ndarray) - float:\n    \"\"\"\n    epsilon = 0.9 / lambda_max(A), where lambda_max is the largest eigenvalue.\n    \"\"\"\n    # Since A is symmetric, use eigvalsh for numerical stability.\n    eigenvals = np.linalg.eigvalsh(A)\n    lam_max = float(np.max(eigenvals))\n    return 0.9 / lam_max\n\ndef M_full(A: np.ndarray, eps: float) - np.ndarray:\n    \"\"\"\n    Full ULA mean operator: M_full = I - eps * A\n    \"\"\"\n    d = A.shape[0]\n    return np.eye(d, dtype=np.float64) - eps * A\n\ndef M_coord(A: np.ndarray, eps: float) - np.ndarray:\n    \"\"\"\n    Coordinate-wise ULA cyclic sweep mean operator:\n    M_coord = M_d-1 ... M_1 M_0, where each M_i = I - eps * e_i e_i^T A.\n    \"\"\"\n    d = A.shape[0]\n    M = np.eye(d, dtype=np.float64)\n    # Sequentially apply coordinate updates: left-multiply by each M_i\n    for i in range(d):\n        # e_i e_i^T A is a matrix that keeps only the i-th row of A\n        # Construct P_i = e_i e_i^T\n        P_i = np.zeros((d, d), dtype=np.float64)\n        P_i[i, i] = 1.0\n        M_i = np.eye(d, dtype=np.float64) - eps * (P_i @ A)\n        M = M_i @ M\n    return M\n\ndef block_partitions(d: int, m: int):\n    \"\"\"\n    Generate contiguous blocks of size m across 0..d-1.\n    Last block may be shorter if d is not divisible by m.\n    \"\"\"\n    blocks = []\n    start = 0\n    while start  d:\n        end = min(start + m, d)\n        blocks.append(list(range(start, end)))\n        start = end\n    return blocks\n\ndef M_block(A: np.ndarray, m: int) - np.ndarray:\n    \"\"\"\n    Block Gibbs sweep mean operator:\n    For each block b, x_b' = -A_bb^{-1} A_b,-b x_-b; x_-b' = x_-b.\n    Construct corresponding operator and multiply over blocks.\n    \"\"\"\n    d = A.shape[0]\n    M = np.eye(d, dtype=np.float64)\n    blocks = block_partitions(d, m)\n    for blk in blocks:\n        blk = np.array(blk, dtype=np.int64)\n        # Complement indices\n        comp = np.array([i for i in range(d) if i not in set(blk.tolist())], dtype=np.int64)\n        A_bb = A[np.ix_(blk, blk)]\n        A_b_comp = A[np.ix_(comp, blk)].T\n        # K = -A_bb^{-1} A_b,-b\n        # Solve A_bb * X = A_b_comp for X, then K = -X\n        X = np.linalg.solve(A_bb, A_b_comp)\n        K = -X\n        # Build M_b operator\n        M_b = np.eye(d, dtype=np.float64)\n        # Zero out rows corresponding to block on block columns\n        M_b[np.ix_(blk, blk)] = 0.0\n        # Set rows corresponding to block on complement columns to K\n        M_b[np.ix_(blk, comp)] = K\n        # Compose\n        M = M_b @ M\n    return M\n\ndef spectral_radius(M: np.ndarray) - float:\n    \"\"\"\n    Compute spectral radius: max absolute eigenvalue. For non-symmetric M, use eigvals.\n    \"\"\"\n    eigvals = np.linalg.eigvals(M)\n    return float(np.max(np.abs(eigvals)))\n\ndef tau_from_lambda(lam: float) - float:\n    \"\"\"\n    Worst-mode integrated autocorrelation time proxy: tau = (1 + lam) / (1 - lam).\n    Assumes |lam|  1; for numerical safety, if lam >= 1 - 1e-12, set tau to a large number.\n    \"\"\"\n    if lam >= 1.0 - 1e-12:\n        return float('inf')\n    return (1.0 + lam) / (1.0 - lam)\n\ndef run_case(d: int, rho: float, m: int):\n    \"\"\"\n    Build A, compute epsilon, construct operators, and return taus for full, coord, block.\n    \"\"\"\n    A = build_precision_matrix(d, rho)\n    eps = step_size(A)\n\n    Mfull = M_full(A, eps)\n    Mcoord = M_coord(A, eps)\n    Mblk = M_block(A, m)\n\n    lam_full = spectral_radius(Mfull)\n    lam_coord = spectral_radius(Mcoord)\n    lam_block = spectral_radius(Mblk)\n\n    tau_full = tau_from_lambda(lam_full)\n    tau_coord = tau_from_lambda(lam_coord)\n    tau_block = tau_from_lambda(lam_block)\n\n    return [tau_full, tau_coord, tau_block]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (10, 0.3, 5),   # Case 1: moderate dimension and coupling\n        (100, 0.9, 10), # Case 2: high dimension, strong coupling\n        (50, 0.0, 5),   # Case 3: independent variables\n        (100, 0.99, 20) # Case 4: very strong coupling in high dimension\n    ]\n\n    results = []\n    for d, rho, m in test_cases:\n        taus = run_case(d, rho, m)\n        results.append(taus)\n\n    # Final print statement in the exact required format.\n    # Print nested list with default string conversion.\n    print(str(results).replace(' ', ''))\n\nsolve()\n```", "id": "3122336"}]}