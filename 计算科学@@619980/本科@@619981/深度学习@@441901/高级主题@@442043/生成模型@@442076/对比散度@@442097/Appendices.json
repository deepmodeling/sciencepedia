{"hands_on_practices": [{"introduction": "理解算法的核心机制是掌握它的第一步。对比散度（Contrastive Divergence, CD）是一种近似算法，其有效性在很大程度上取决于吉布斯采样的步数 $k$。[@problem_id:3112328] 这项练习通过考察其在极端情况（$k=0$ 和 $k \\to \\infty$）下的行为以及使用小 $k$ 值的潜在陷阱，深入探讨了 CD-$k$ 更新法则的基本性质。通过从第一性原理出发完成这个思想实验，你将为 CD 的工作原理、其偏差的来源以及 $k$ 值的选择如何直接影响学习信号建立坚实的直觉。", "problem": "您正在使用受限玻尔兹曼机 (RBM) 逐层预训练一个深度信念网络 (DBN)。每个 RBM 有一个可见二元单元 $v \\in \\{0,1\\}$，一个隐藏二元单元 $h \\in \\{0,1\\}$，一个权重 $W \\in \\mathbb{R}$，以及偏置 $b, c \\in \\mathbb{R}$。训练使用带有 $k$ 个吉布斯步骤的对比散度 (CD)，其中“负”样本是通过从数据 $v_0$ 开始运行 $k$ 次交替条件采样获得的。\n\n从关于能量模型、二元-二元 RBM 中的条件分布以及对比散度定义的第一性原理出发，回答以下多项选择题。选择所有正确的选项。您必须通过从定义出发进行推理来证明您的选择（而不是通过引用现成的训练规则）。\n\n为便于说明，考虑两种玩具设置：\n- 设置 S$1$：$b=0$，$c=0$，$W=2$，以及一个单一数据案例 $v=1$。\n- 设置 S$2$：$b=0$，$c=-3$，$W=4$，以及一个数据分布 $P_{\\text{data}}(v=1)=0.5$。\n\n哪些陈述是正确的？\n\nA. 对于通过对比散度 (CD) 训练的 RBM，使用 $k=0$ 会导致对 $W$ 的参数更新为零，因为对比（负）统计量是在与数据（正）统计量相同的数据点上计算的，所以两边完全抵消。\n\nB. 在设置 S$1$ 中，使用 $k=0$ 的 CD 会产生一个非零的正向更新，其值严格正比于约 $0.1192$。\n\nC. 在设置 S$2$ 中，关于 $W$ 的真实最大似然梯度（在数据分布和模型上平均）是负的，然而从 $v_0=1$ 开始的单步对比散度估计却产生一个约 $0.108$ 的正向更新，这说明过小的 $k$ 可能指向错误的方向，并且如果重复进行，可能导致参数发散。\n\nD. 在 CD 中使用过小的 $k$ 不会引起发散，因为每一步 CD 都会严格增加对数似然。\n\nE. 在极限 $k \\to \\infty$ 的情况下，CD-$k$ 恢复了精确的负相位模型统计量（在标准的混合假设下），因此该估计量对于 RBM 中的最大似然梯度是无偏的。", "solution": "该问题要求评估关于使用对比散度 (CD) 训练受限玻尔兹曼机 (RBM) 的几个陈述。我将首先从第一性原理出发建立必要的理论基础，然后分析每个选项。\n\n### 理论基础\n\n一个具有一个二元可见单元 $v \\in \\{0, 1\\}$ 和一个二元隐藏单元 $h \\in \\{0, 1\\}$ 的 RBM 是一个基于能量的模型，其能量函数为：\n$$E(v, h) = -vWh - bv - ch$$\n其中 $W \\in \\mathbb{R}$ 是权重，$b, c \\in \\mathbb{R}$ 分别是可见单元和隐藏单元的偏置。\n\n联合概率分布由 $P(v, h) = \\frac{1}{Z} e^{-E(v, h)}$ 给出，其中 $Z = \\sum_{v', h'} e^{-E(v', h')}$ 是配分函数。\n\n对于吉布斯采样至关重要的条件概率由 sigmoid 函数 $\\sigma(x) = (1 + e^{-x})^{-1}$ 给出：\n$$P(h=1|v) = \\frac{e^{-E(v,h=1)}}{e^{-E(v,h=0)} + e^{-E(v,h=1)}} = \\frac{e^{Wv+c}}{e^0 + e^{Wv+c}} = \\sigma(Wv + c)$$\n$$P(v=1|h) = \\frac{e^{-E(v=1,h)}}{e^{-E(v=0,h)} + e^{-E(v=1,h)}} = \\frac{e^{Wh+b}}{e^0 + e^{Wh+b}} = \\sigma(Wh + b)$$\n\n单个数据点 $v_0$ 的对数似然关于权重 $W$ 的梯度是：\n$$\\frac{\\partial \\log P(v_0)}{\\partial W} = \\mathbb{E}_{h|v_0}\\left[-\\frac{\\partial E(v_0, h)}{\\partial W}\\right] - \\mathbb{E}_{v,h \\sim P}\\left[-\\frac{\\partial E(v, h)}{\\partial W}\\right]$$\n由于 $-\\frac{\\partial E}{\\partial W} = vh$，这变为：\n$$\\frac{\\partial \\log P(v_0)}{\\partial W} = \\mathbb{E}_{h|v_0}[v_0 h] - \\mathbb{E}_{v,h}[vh]$$\n第一项是“正相位”统计量 $\\langle vh \\rangle_{\\text{data}}$，第二项是“负相位”统计量 $\\langle vh \\rangle_{\\text{model}}$。正相位可以计算为：\n$$\\langle vh \\rangle_{\\text{data}} = v_0 \\cdot P(h=1|v_0)$$\n负相位通常是难以计算的。具有 $k$ 步的对比散度 (CD-$k$) 近似了这个梯度。它从数据点 $v_0$ 开始一个吉布斯链，运行 $k$ 步（$v_0 \\to h_0 \\to v_1 \\to \\dots \\to v_k$），并使用最终的可见状态 $v_k$ 来计算负统计量。$W$ 的 CD-$k$ 更新量正比于：\n$$\\Delta W \\propto \\langle vh \\rangle_{\\text{data}} - \\langle vh \\rangle_{\\text{model}, k} = v_0 P(h=1|v_0) - v_k P(h=1|v_k)$$\n其中涉及 $v_k$ 的项是负相位的一个近似。\n\n### 逐项分析\n\n**A. 对于通过对比散度 (CD) 训练的 RBM，使用 $k=0$ 会导致对 $W$ 的参数更新为零，因为对比（负）统计量是在与数据（正）统计量相同的数据点上计算的，所以两边完全抵消。**\n\n为了分析 $k=0$ 的 CD，我们遵循问题描述：“‘负’样本是通过从数据 $v_0$ 开始运行 $k$ 次交替条件采样获得的”。如果 $k=0$，则不执行任何采样步骤。因此，吉布斯链在 0 步之后的状态就是其初始状态，即 $v_k = v_0$。\n\n$W$ 的 CD-$0$ 更新量是：\n$$\\Delta W \\propto v_0 P(h=1|v_0) - v_k P(h=1|v_k)$$\n代入 $v_k = v_0$：\n$$\\Delta W \\propto v_0 P(h=1|v_0) - v_0 P(h=1|v_0) = 0$$\n正统计量 ($v_0 P(h=1|v_0)$) 和负统计量近似值 ($v_0 P(h=1|v_0)$) 是相同的，导致梯度估计为零。这对任何参数 $W, b, c$ 和任何数据点 $v_0$ 都成立。选项中提供的推理是正确的。\n\n**对 A 的判断：正确**\n\n**B. 在设置 S$1$ 中，使用 $k=0$ 的 CD 会产生一个非零的正向更新，其值严格正比于约 $0.1192$。**\n\n这个陈述直接与我们对选项 A 的分析结论相矛盾。正如我们所展示的，对于任何设置，CD-$0$ 的更新在数学上保证为零。\n设置 S$1$ 的参数为 $b=0$，$c=0$，$W=2$，数据案例为 $v=1$。\nCD-$0$ 的更新量是：\n$$\\Delta W \\propto v_0 P(h=1|v_0) - v_0 P(h=1|v_0) = 1 \\cdot P(h=1|v=1) - 1 \\cdot P(h=1|v=1) = 0$$\n数值 $0.1192$ 约等于 $1 - \\sigma(2) \\approx 1 - 0.8808 = 0.1192$。这个值可能是由于对 CD 更新规则的误解而产生的，但在该领域提供和使用的标准定义下，更新量为零。因此，该陈述是错误的。\n\n**对 B 的判断：错误**\n\n**C. 在设置 S$2$ 中，关于 $W$ 的真实最大似然梯度（在数据分布和模型上平均）是负的，然而从 $v_0=1$ 开始的单步对比散度估计却产生一个约 $0.108$ 的正向更新，这说明过小的 $k$ 可能指向错误的方向，并且如果重复进行，可能导致参数发散。**\n\n这是一个分为两部分的论断，需要详细计算。\n设置 S$2$：$b=0$，$c=-3$，$W=4$，以及 $P_{\\text{data}}(v=1)=0.5$。\n\n**第 1 部分：真实的最大似然 (ML) 梯度是负的。**\n真实的梯度是 $\\frac{\\partial \\mathcal{L}}{\\partial W} = \\mathbb{E}_{v \\sim P_{\\text{data}}}[\\langle vh \\rangle] - \\mathbb{E}_{v,h \\sim P_{\\text{model}}}[\\langle vh \\rangle]$。\n\n正相位统计量：$\\mathbb{E}_{v \\sim P_{\\text{data}}}[v \\cdot P(h=1|v)]$\n- 对于 $v=1$：$1 \\cdot P(h=1|v=1) = \\sigma(W \\cdot 1 + c) = \\sigma(4-3) = \\sigma(1) \\approx 0.7311$。\n- 对于 $v=0$：$0 \\cdot P(h=1|v=0) = 0$。\n在 $P_{\\text{data}}$ 上平均：$\\langle vh \\rangle_{\\text{data}} = 0.5 \\cdot \\sigma(1) + 0.5 \\cdot 0 \\approx 0.3655$。\n\n负相位统计量：$\\mathbb{E}_{v,h \\sim P_{\\text{model}}}[vh] = P_{\\text{model}}(v=1, h=1)$。\n我们需要配分函数 $Z = \\sum_{v,h} e^{-E(v,h)} = \\sum_{v,h} e^{vWh+bv+ch}$。当 $b=0,c=-3,W=4$ 时：\n- $e^{-E(0,0)} = e^0 = 1$。\n- $e^{-E(0,1)} = e^{c} = e^{-3}$。\n- $e^{-E(1,0)} = e^0 = 1$。\n- $e^{-E(1,1)} = e^{W+c} = e^{4-3} = e^{1}$。\n所以，$Z = 1 + e^{-3} + 1 + e^{1} = 2 + e^{-3} + e \\approx 2 + 0.0498 + 2.7183 = 4.7681$。\n$\\langle vh \\rangle_{\\text{model}} = P(v=1, h=1) = \\frac{e^1}{Z} \\approx \\frac{2.7183}{4.7681} \\approx 0.5701$。\n\n真实 ML 梯度：$\\frac{\\partial \\mathcal{L}}{\\partial W} \\approx 0.3655 - 0.5701 = -0.2046$。\n梯度确实是负的。\n\n**第 2 部分：从 $v_0=1$ 开始的 CD-$1$ 更新是正的且约为 $0.108$。**\n对于单个数据点 $v_0=1$，更新量为 $\\Delta W \\propto v_0 P(h=1|v_0) - \\mathbb{E}_{v_1}[v_1 P(h=1|v_1)]$。\n正统计量是 $1 \\cdot P(h=1|v=1) = \\sigma(1) \\approx 0.7311$。\n对于负统计量，我们从 $v_0=1$ 开始执行一个吉布斯步骤：\n1. 从 $P(h|v_0=1)$ 中采样 $h_0$。$P(h_0=1|v_0=1) = \\sigma(W \\cdot 1 + c) = \\sigma(1)$。\n2. 从 $P(v|h_0)$ 中采样 $v_1$。\n负统计量的期望是在此采样过程中计算的：\n$\\langle vh \\rangle_{\\text{model},1} = \\mathbb{E}_{h_0 \\sim P(h|v_0=1)} \\left[ \\mathbb{E}_{v_1 \\sim P(v|h_0)}[v_1 P(h=1|v_1)] \\right]$\n- 如果 $h_0=1$（概率为 $\\sigma(1)$）：$P(v_1=1|h_0=1) = \\sigma(W \\cdot 1 + b) = \\sigma(4)$。该项为 $\\sigma(4) \\cdot (1 \\cdot P(h=1|v=1)) + (1-\\sigma(4)) \\cdot (0) = \\sigma(4)\\sigma(1)$。\n- 如果 $h_0=0$（概率为 $1-\\sigma(1)$）：$P(v_1=1|h_0=0) = \\sigma(W \\cdot 0 + b) = \\sigma(0)=0.5$。该项为 $0.5 \\cdot (1 \\cdot P(h=1|v=1)) + 0.5 \\cdot (0) = 0.5\\sigma(1)$。\n结合这些：\n$\\langle vh \\rangle_{\\text{model},1} = \\sigma(1) \\cdot [\\sigma(4)\\sigma(1)] + (1-\\sigma(1)) \\cdot [0.5\\sigma(1)]$\n$= \\sigma(1)[\\sigma(1)\\sigma(4) + 0.5(1-\\sigma(1))]$\n使用 $\\sigma(1) \\approx 0.7311$，$\\sigma(4) \\approx 0.9820$，$1-\\sigma(1) \\approx 0.2689$：\n$\\langle vh \\rangle_{\\text{model},1} \\approx 0.7311 \\cdot [0.7311 \\cdot 0.9820 + 0.5 \\cdot 0.2689] = 0.7311 \\cdot [0.7179 + 0.1345] \\approx 0.7311 \\cdot 0.8524 \\approx 0.6232$。\nCD-$1$ 的梯度估计为：$\\Delta W \\propto \\sigma(1) - 0.6232 \\approx 0.7311 - 0.6232 = 0.1079$。\n这大约是 $0.108$。该估计是正的，而真实梯度是负的。这说明一个有偏的、小 $k$ 值的 CD 更新确实可能指向错误的方向。这种行为可能导致训练不稳定或无法收敛到一个好的解。\n\n**对 C 的判断：正确**\n\n**D. 在 CD 中使用过小的 $k$ 不会引起发散，因为每一步 CD 都会严格增加对数似然。**\n\n这个陈述是根本错误的。CD-$k$ 更新向量不是对数似然 $\\mathcal{L}$ 的梯度。它是一个近似值。沿着一个近似的梯度方向前进一步并不能保证原始目标函数会增加。正如选项 C 的分析中明确显示的，CD-1 梯度可能指向一个与真实 ML 梯度点积为负的方向。朝这样的方向前进一步会*减少*对数似然。已有正式证明表明，CD 不保证是对数似然的一个上升方向。因此，它可能导致振荡行为或发散，特别是对于小的 $k$。\n\n**对 D 的判断：错误**\n\n**E. 在极限 $k \\to \\infty$ 的情况下，CD-$k$ 恢复了精确的负相位模型统计量（在标准的混合假设下），因此该估计量对于 RBM 中的最大似然梯度是无偏的。**\n\nCD-$k$ 过程涉及运行一个吉布斯采样马尔可夫链 $k$ 步。在标准假设（遍历性）下，当 $k \\to \\infty$ 时，状态 $v_k$ 的分布会收敛到模型的稳态（平衡）分布 $P_{\\text{model}}(v)$，而与起始状态 $v_0$ 无关。\nCD-$k$ 梯度的负相位是使用样本 $v_k$ 计算的。当 $k \\to \\infty$ 时，该统计量的期望收敛到真实模型分布下的期望：\n$$\\lim_{k \\to \\infty} \\mathbb{E}[\\langle vh \\rangle_{\\text{model}, k}] = \\mathbb{E}_{v \\sim P_{\\text{model}}}[\\langle vh|v \\rangle] = \\langle vh \\rangle_{\\text{model}}$$\nCD-$k$ 中的正相位是 ML 梯度的精确正相位。由于负相位收敛到精确的负相位，完整的 CD-$k$ 梯度估计量收敛到真实的 ML 梯度：\n$$\\lim_{k \\to \\infty} \\left( \\langle vh \\rangle_{\\text{data}} - \\langle vh \\rangle_{\\text{model}, k} \\right) = \\langle vh \\rangle_{\\text{data}} - \\langle vh \\rangle_{\\text{model}} = \\frac{\\partial \\mathcal{L}}{\\partial W}$$\n根据定义，一个期望值等于被估计参数真值的估计量是无偏估计量。因此，在极限 $k \\to \\infty$ 的情况下，CD-$k$ 梯度估计量成为真实最大似然梯度的一个无偏估计量。该陈述是对对比散度理论基础的正确描述。\n\n**对 E 的判断：正确**", "answer": "$$\\boxed{ACE}$$", "id": "3112328"}, {"introduction": "当你亲眼目睹算法的偏差导致程序失败时，关于它的理论知识才会变得真正有意义。单步对比散度（CD-1）的偏差是一个众所周知的问题，它可能导致受限玻尔兹曼机（RBM）无法学习复杂的数据分布。[@problem_id:3109758] 这个编程练习要求你构建一个 CD-1 无法捕捉双峰数据分布的场景，这是一个经典的失败案例。然后，你将实现两种标准的补救措施：增加吉布斯采样步数（CD-k）和使用持续性对比散度（Persistent Contrastive Divergence, PCD）。通过实现和比较这些方法，你将获得 RBM 训练的实践经验，理解有偏梯度的实际后果，并学会如何诊断和解决常见的训练问题。", "problem": "你的任务是设计并实现一个完整的、可运行的程序，为受限玻尔兹曼机 (RBM) 构建一个人工学习场景，并演示对比散度 (CD) 的行为如何依赖于 Gibbs 步数以及如何依赖于使用包含多个链的持续性对比散度 (PCD)。你的实现必须基于第一性原理。\n\n从以下基本基础开始：\n\n- 受限玻尔兹曼机 (RBM) 通过能量函数定义了二元可见单元和二元隐藏单元上的联合分布\n$$\nE(\\mathbf{v},\\mathbf{h}) \\;=\\; -\\mathbf{b}_v^\\top\\mathbf{v} \\;-\\; \\mathbf{b}_h^\\top\\mathbf{h} \\;-\\; \\mathbf{v}^\\top \\mathbf{W}\\,\\mathbf{h},\n$$\n其中 $\\mathbf{v}\\in\\{0,1\\}^{D}$ 是可见单元，$\\mathbf{h}\\in\\{0,1\\}^{H}$ 是隐藏单元，$\\mathbf{b}_v\\in\\mathbb{R}^{D}$ 和 $\\mathbf{b}_h\\in\\mathbb{R}^{H}$ 是偏置，$\\mathbf{W}\\in\\mathbb{R}^{D\\times H}$ 是权重。\n\n- 模型分布为\n$$\np(\\mathbf{v},\\mathbf{h}) \\;=\\; \\frac{1}{Z}\\,\\exp\\!\\big(-E(\\mathbf{v},\\mathbf{h})\\big),\\quad Z \\;=\\; \\sum_{\\mathbf{v}\\in\\{0,1\\}^{D}}\\sum_{\\mathbf{h}\\in\\{0,1\\}^{H}}\\exp\\!\\big(-E(\\mathbf{v},\\mathbf{h})\\big).\n$$\n\n- 条件分布可分解为\n$$\np(\\mathbf{h}\\mid \\mathbf{v}) \\;=\\; \\prod_{j=1}^{H}\\sigma\\!\\big(b_{h,j} + \\mathbf{W}_{:,j}^\\top \\mathbf{v}\\big)^{h_j}\\,\\big(1-\\sigma(\\cdot)\\big)^{1-h_j}, \\quad\np(\\mathbf{v}\\mid \\mathbf{h}) \\;=\\; \\prod_{i=1}^{D}\\sigma\\!\\big(b_{v,i} + \\mathbf{W}_{i,:}\\mathbf{h}\\big)^{v_i}\\,\\big(1-\\sigma(\\cdot)\\big)^{1-v_i},\n$$\n其中 $\\sigma(x)=\\frac{1}{1+\\exp(-x)}$ 是 logistic sigmoid 函数。\n\n- 在一个基于能量的模型下，对数似然的梯度等于一个数据相关期望减去一个模型相关期望。\n\n你的任务是：\n\n1) 使用上述基础推导 $\\mathbf{W}$、$\\mathbf{b}_v$ 和 $\\mathbf{b}_h$ 的随机更新规则，并实现使用 CD-$k$ 的训练，其中 $k$ 表示从一个数据点初始化的分块 Gibbs 采样步数，以及实现持续性对比散度 (PCD)，其中一组持续链在更新过程中不断推进。\n\n2) 构建一个在 $D$ 个二元可见单元上的人工数据分布，该分布是两个孤立模式的等概率混合。具体来说，设置 $D=6$ 并定义两种模式\n$$\n\\mathbf{v}^{(A)} = [1,1,1,0,0,0]^\\top,\\qquad \\mathbf{v}^{(B)} = [0,0,0,1,1,1]^\\top,\n$$\n以及一个数据分布，它将 $\\frac{1}{2}$ 的概率赋给 $\\mathbf{v}^{(A)}$，$\\frac{1}{2}$ 的概率赋给 $\\mathbf{v}^{(B)}$。\n\n3) 实现一个具有 $H=2$ 个二元隐藏单元的 RBM。从一个均值为零的可复现小数值高斯分布中初始化参数。为了进行评估，精确枚举所有 $2^{D}$ 种可见配置，通过自由能\n$$\nF(\\mathbf{v}) \\;=\\; -\\mathbf{b}_v^\\top \\mathbf{v} \\;-\\; \\sum_{j=1}^{H}\\log\\!\\big(1+\\exp\\big(b_{h,j} + \\mathbf{W}_{:,j}^\\top \\mathbf{v}\\big)\\big),\n$$\n计算模型分布 $p_\\theta(\\mathbf{v})$，以及 $p_\\theta(\\mathbf{v}) \\propto \\exp\\!\\big(-F(\\mathbf{v})\\big)$，其中配分函数在 $\\mathbf{v}\\in\\{0,1\\}^{D}$ 上精确计算。\n\n4) 构建一个训练计划，通过使用有偏的数据课程来揭示 CD-$1$ 的一种失效模式：在总更新次数的一部分（比例为 $\\alpha$）中，仅提供 $\\mathbf{v}^{(A)}$ 作为正相输入；在剩余的 $(1-\\alpha)$ 部分中，确定性地在 $\\mathbf{v}^{(A)}$ 和 $\\mathbf{v}^{(B)}$ 之间交替。这模拟了路径依赖和混合不良的情况。在不同方法间保持数据集和课程不变，以隔离负相的影响。然后证明，增加 $k$ (例如，使用更大的 CD-$k$) 或使用带有多个持续链的 PCD 可以缓解这种失效。\n\n5) 为双峰数据定义一个定量成功标准：训练好的模型必须为两个真实模式分配不可忽略的概率质量。使用标准\n$$\np_\\theta\\!\\big(\\mathbf{v}^{(A)}\\big) > \\tau \\quad \\text{and} \\quad p_\\theta\\!\\big(\\mathbf{v}^{(B)}\\big) > \\tau,\n$$\n阈值 $\\tau = 0.2$。对于单峰控制情况（数据仅为 $\\mathbf{v}^{(A)}$），将成功定义为 $p_\\theta\\!\\big(\\mathbf{v}^{(A)}\\big) > 0.5$。\n\n6) 实现以下参数集测试套件。每个测试案例都从同一种初始化分布中进行训练，但参数和采样有其各自的随机种子；课程偏差 $\\alpha$ 已给定。对于所有案例，使用 $D=6$，$H=2$，恒定学习率 $\\eta$，每次更新恰好使用一个正样本。不涉及任何物理单位。\n\n- 案例 1 (边界/失效构建)：方法 CD-$1$，$k=1$，$\\alpha=0.8$，$\\eta=0.05$，更新次数 $T=400$，初始化种子 $s=0$，目标数据为双峰。\n- 案例 2 (通过更大的 k 进行补救)：方法 CD-$10$，$k=10$，$\\alpha=0.8$，$\\eta=0.05$，更新次数 $T=400$，初始化种子 $s=0$，目标数据为双峰。\n- 案例 3 (通过 PCD 进行补救)：方法 PCD，使用 $M=10$ 个持续链，每次更新进行一次分块 Gibbs 步，$\\alpha=0.8$，$\\eta=0.05$，更新次数 $T=400$，初始化种子 $s=0$，目标数据为双峰。\n- 案例 4 (控制组)：方法 CD-$1$，$k=1$，$\\alpha=1.0$，$\\eta=0.05$，更新次数 $T=400$，初始化种子 $s=1$，目标数据在 $\\mathbf{v}^{(A)}$ 处为单峰。\n\n7) 在训练完每个案例后，按上述指定方式通过精确枚举计算 $p_\\theta\\!\\big(\\mathbf{v}^{(A)}\\big)$ 和 $p_\\theta\\!\\big(\\mathbf{v}^{(B)}\\big)$，并评估该案例的成功标准，为每个案例生成一个布尔结果。\n\n你的程序应产生单行输出，其中包含一个用方括号括起来的、以逗号分隔的结果列表，顺序与测试案例一致，例如\n$$\n[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4].\n$$\n每个 $\\text{result}_i$ 必须是为该测试案例定义的上述成功标准的布尔值。此问题不涉及角度、物理单位或百分比；所有值都是无量纲的。", "solution": "该问题要求设计并实现一个计算实验，以演示对比散度 (CD) 和持续性对比散度 (PCD) 在训练受限玻尔兹曼机 (RBM) 时的行为。解决方案涉及从第一性原理推导学习规则，实现 RBM 和训练算法，并在一个旨在凸显特定失效模式的人工数据集上对它们进行评估。\n\n**1. 理论基础：RBM 梯度推导**\n\n受限玻尔兹曼机是一个基于能量的模型，用于描述可见单元 $\\mathbf{v} \\in \\{0, 1\\}^D$ 和隐藏单元 $\\mathbf{h} \\in \\{0, 1\\}^H$ 上的联合分布。其能量函数由以下公式给出：\n$$\nE(\\mathbf{v}, \\mathbf{h}; \\theta) = -\\mathbf{b}_v^\\top\\mathbf{v} - \\mathbf{b}_h^\\top\\mathbf{h} - \\mathbf{v}^\\top\\mathbf{W}\\mathbf{h}\n$$\n其中模型参数为 $\\theta = \\{\\mathbf{W}, \\mathbf{b}_v, \\mathbf{b}_h\\}$。联合概率为 $p(\\mathbf{v}, \\mathbf{h}) = Z^{-1} \\exp(-E(\\mathbf{v}, \\mathbf{h}))$，其中 $Z$ 是配分函数。可见单元的边缘概率为 $p(\\mathbf{v}) = \\sum_{\\mathbf{h}} p(\\mathbf{v}, \\mathbf{h})$。\n\n训练的目标是最大化观测数据的对数似然。对于单个数据样本 $\\mathbf{v}^{(d)}$，对数似然为：\n$$\n\\mathcal{L}(\\theta) = \\log p(\\mathbf{v}^{(d)}) = \\log \\sum_{\\mathbf{h}} p(\\mathbf{v}^{(d)}, \\mathbf{h}) = \\log \\sum_{\\mathbf{h}} \\frac{\\exp(-E(\\mathbf{v}^{(d)}, \\mathbf{h}))}{Z}\n$$\n这可以用自由能 $F(\\mathbf{v}) = -\\log \\sum_{\\mathbf{h}} \\exp(-E(\\mathbf{v}, \\mathbf{h}))$ 表示为：\n$$\n\\mathcal{L}(\\theta) = -F(\\mathbf{v}^{(d)}) - \\log Z\n$$\n关于任意参数 $\\phi \\in \\theta$ 的梯度为：\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\phi} = -\\frac{\\partial F(\\mathbf{v}^{(d)})}{\\partial \\phi} - \\frac{\\partial \\log Z}{\\partial \\phi}\n$$\n这两项可以表示为期望。第一项与数据相关：\n$$\n-\\frac{\\partial F(\\mathbf{v}^{(d)})}{\\partial \\phi} = \\frac{\\partial}{\\partial \\phi} \\log \\sum_{\\mathbf{h}} e^{-E(\\mathbf{v}^{(d)}, \\mathbf{h})} = \\sum_{\\mathbf{h}} p(\\mathbf{h} | \\mathbf{v}^{(d)}) \\left( -\\frac{\\partial E(\\mathbf{v}^{(d)}, \\mathbf{h})}{\\partial \\phi} \\right) = \\mathbb{E}_{\\mathbf{h} \\sim p(\\cdot|\\mathbf{v}^{(d)})} \\left[ -\\frac{\\partial E(\\mathbf{v}^{(d)}, \\mathbf{h})}{\\partial \\phi} \\right]\n$$\n这是“正相”期望，是在给定数据的条件下对隐藏单元求取的期望。\n第二项与模型相关：\n$$\n-\\frac{\\partial \\log Z}{\\partial \\phi} = -\\frac{1}{Z} \\frac{\\partial Z}{\\partial \\phi} = -\\frac{1}{Z} \\sum_{\\mathbf{v}, \\mathbf{h}} \\frac{\\partial e^{-E(\\mathbf{v}, \\mathbf{h})}}{\\partial \\phi} = \\sum_{\\mathbf{v}, \\mathbf{h}} p(\\mathbf{v}, \\mathbf{h}) \\left( -\\frac{\\partial E(\\mathbf{v}, \\mathbf{h})}{\\partial \\phi} \\right) = \\mathbb{E}_{\\mathbf{v}, \\mathbf{h} \\sim p(\\cdot, \\cdot)} \\left[ -\\frac{\\partial E(\\mathbf{v}, \\mathbf{h})}{\\partial \\phi} \\right]\n$$\n这是“负相”期望，是在完整模型分布上求取的期望。将它们结合起来，梯度是两个期望之差：\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\phi} = \\mathbb{E}_{\\mathbf{h} \\sim p(\\cdot|\\mathbf{v}^{(d)})} \\left[ -\\frac{\\partial E(\\mathbf{v}^{(d)}, \\mathbf{h})}{\\partial \\phi} \\right] - \\mathbb{E}_{\\mathbf{v}, \\mathbf{h} \\sim p(\\cdot, \\cdot)} \\left[ -\\frac{\\partial E(\\mathbf{v}, \\mathbf{h})}{\\partial \\phi} \\right]\n$$\n能量函数的导数很简单：\n$\\frac{\\partial E}{\\partial W_{ij}} = -v_i h_j$，$\\frac{\\partial E}{\\partial b_{v,i}} = -v_i$ 以及 $\\frac{\\partial E}{\\partial b_{h,j}} = -h_j$。\n由此得到精确梯度：\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial W_{ij}} = \\mathbb{E}_{\\mathbf{h} \\sim p(\\cdot|\\mathbf{v}^{(d)})}[v_i^{(d)} h_j] - \\mathbb{E}_{\\mathbf{v}, \\mathbf{h} \\sim p(\\cdot, \\cdot)}[v_i h_j]\n$$\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial b_{v,i}} = v_i^{(d)} - \\mathbb{E}_{\\mathbf{v} \\sim p(\\cdot)}[v_i]\n$$\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial b_{h,j}} = \\mathbb{E}_{\\mathbf{h} \\sim p(\\cdot|\\mathbf{v}^{(d)})}[h_j] - \\mathbb{E}_{\\mathbf{h} \\sim p(\\cdot)}[h_j]\n$$\n由于 RBM 的结构，正相期望是可解的：$p(h_j=1|\\mathbf{v}) = \\sigma(b_{h,j} + \\sum_i W_{ij}v_i)$。然而，负相期望是难解的，因为它们需要对所有 $2^{D+H}$ 个状态求和。\n\n**2. 算法设计：CD 和 PCD 近似**\n\n对比散度对难解的负相期望进行近似。\n\n**对比散度 (CD-k)：**\nCD-$k$ 算法通过运行一个 Gibbs 采样器 $k$ 个完整步（v 到 h，h 到 v）来近似模型期望，该采样器从一个数据点 $\\mathbf{v}^{(d)}$ 初始化。令 $\\mathbf{v}^{(0)} = \\mathbf{v}^{(d)}$。\nGibbs 链为：\n$\\mathbf{h}^{(t)} \\sim p(\\mathbf{h} | \\mathbf{v}^{(t)})$\n$\\mathbf{v}^{(t+1)} \\sim p(\\mathbf{v} | \\mathbf{h}^{(t)})$\n经过 $k$ 步后，我们得到一个样本 $\\mathbf{v}^{(k)}$。样本对 $(\\mathbf{v}^{(k)}, \\mathbb{E}[\\mathbf{h}|\\mathbf{v}^{(k)}])$ 用于近似负相统计量。使用学习率 $\\eta$ 的随机梯度更新规则变为：\n$$\n\\Delta W_{ij} = \\eta \\left( v_i^{(0)} p(h_j=1|\\mathbf{v}^{(0)}) - v_i^{(k)} p(h_j=1|\\mathbf{v}^{(k)}) \\right)\n$$\n$$\n\\Delta b_{v,i} = \\eta \\left( v_i^{(0)} - v_i^{(k)} \\right)\n$$\n$$\n\\Delta b_{h,j} = \\eta \\left( p(h_j=1|\\mathbf{v}^{(0)}) - p(h_j=1|\\mathbf{v}^{(k)}) \\right)\n$$\n其中 $\\mathbf{v}^{(0)}$ 是数据样本，$\\mathbf{v}^{(k)}$ 是经过 $k$ 步 Gibbs 采样后的样本。对于小的 $k$（例如 $k=1$），链可能没有充分混合，$\\mathbf{v}^{(k)}$ 可能接近 $\\mathbf{v}^{(0)}$，导致有偏的梯度估计。如果数据分布的模式相距很远，这个问题尤其严重。\n\n**持续性对比散度 (PCD)：**\nPCD 解决了短 CD 链混合不良的问题。它维护一组 $M$ 个持续的“幻想”粒子或链 $\\{\\mathbf{v}^{(m)}_{chain}\\}_{m=1}^M$，这些粒子被视为来自模型分布的样本。在每个训练步骤中：\n1. 一个数据样本 $\\mathbf{v}^{(d)}$ 提供正相统计量。\n2. 每个持续链 $\\mathbf{v}^{(m)}_{chain}$ 通过一步（或多步）Gibbs 采样更新，得到一个新状态 $\\mathbf{v'}^{(m)}_{chain}$。\n3. 通过对这些新状态 $\\{\\mathbf{v'}^{(m)}_{chain}\\}$求平均来计算负相统计量。\n4. 使用正相和负相统计量之差来更新参数。\n5. 持续链被新状态替换：$\\mathbf{v}^{(m)}_{chain} \\leftarrow \\mathbf{v'}^{(m)}_{chain}$。\n因为这些链在每一步都不从数据重新初始化，所以它们可以更自由地探索状态空间，从而能更好地近似模型的平衡分布，尤其是在模式分离的情况下。\n\n**3. 实验设置与评估**\n\n该实验旨在创建一个 CD-$1$ 很可能失败的场景，并展示 CD-$k$（使用更大的 $k$）和 PCD 如何能够成功。\n\n- **数据：** 一个在 $D=6$ 个可见单元上的双峰分布。两个模式是 $\\mathbf{v}^{(A)} = [1,1,1,0,0,0]^\\top$ 和 $\\mathbf{v}^{(B)} = [0,0,0,1,1,1]^\\top$，每个模式的概率为 $1/2$。这些向量在汉明空间中距离很远，使得 Gibbs 链难以在它们之间移动。\n- **课程：** 训练被故意设置为有偏的。在前 $80\\%$ 的更新中（$\\alpha=0.8$），只提供 $\\mathbf{v}^{(A)}$。这将导致 RBM 强力学习第一个模式。剩余 $20\\%$ 的更新在 $\\mathbf{v}^{(A)}$ 和 $\\mathbf{v}^{(B)}$ 之间交替进行。对于 CD-$1$，从 $\\mathbf{v}^{(A)}$ 或 $\\mathbf{v}^{(B)}$ 开始的 Gibbs 链在一步之内非常不可能跨越到另一个模式。模型将倾向于忘记当前未见的模式，或者未能正确学习第二个模式。\n- **评估：** 由于 $D=6$ 很小，我们可以精确评估模型。我们为所有 $2^6=64$ 个可能的可见向量 $\\mathbf{v}$ 计算自由能 $F(\\mathbf{v})$。\n$$\nF(\\mathbf{v}) = -\\mathbf{b}_v^\\top \\mathbf{v} - \\sum_{j=1}^{H} \\log\\left(1 + \\exp\\left(b_{h,j} + \\mathbf{W}_{:,j}^\\top \\mathbf{v}\\right)\\right)\n$$\n边缘概率为 $p(\\mathbf{v}) = \\frac{\\exp(-F(\\mathbf{v}))}{Z_v}$，其中可见空间配分函数 $Z_v = \\sum_{\\mathbf{v}'} \\exp(-F(\\mathbf{v}'))$。这个 $Z_v$ 通过对所有 64 种配置求和来精确计算。\n- **成功标准：** 如果一个训练好的模型为两个模式都分配了显著的概率，即 $p_\\theta(\\mathbf{v}^{(A)}) > 0.2$ 且 $p_\\theta(\\mathbf{v}^{(B)}) > 0.2$，则认为它在双峰任务上是成功的。对于单峰控制情况，成功定义为 $p_\\theta(\\mathbf{v}^{(A)}) > 0.5$。\n\n这个设置允许对 CD-$1$、CD-$10$ 和 PCD 进行清晰的、定量的比较，隔离了负相采样策略对最终学到的分布的影响。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import logsumexp\n\ndef solve():\n    \"\"\"\n    Main function to run the RBM training and evaluation experiments.\n    \"\"\"\n    \n    # Define problem constants\n    D = 6  # Number of visible units\n    H = 2  # Number of hidden units\n    V_A = np.array([1, 1, 1, 0, 0, 0])\n    V_B = np.array([0, 0, 0, 1, 1, 1])\n    \n    # Test case parameters\n    test_cases = [\n        {'method': 'cd', 'k': 1, 'alpha': 0.8, 'eta': 0.05, 'T': 400, 'seed': 0, 'data': 'bimodal'},\n        {'method': 'cd', 'k': 10, 'alpha': 0.8, 'eta': 0.05, 'T': 400, 'seed': 0, 'data': 'bimodal'},\n        {'method': 'pcd', 'M': 10, 'k': 1, 'alpha': 0.8, 'eta': 0.05, 'T': 400, 'seed': 0, 'data': 'bimodal'},\n        {'method': 'cd', 'k': 1, 'alpha': 1.0, 'eta': 0.05, 'T': 400, 'seed': 1, 'data': 'unimodal'},\n    ]\n\n    class RBM:\n        def __init__(self, D, H, seed):\n            self.D = D\n            self.H = H\n            self.rng = np.random.default_rng(seed)\n            # Initialize parameters from a small random Gaussian\n            self.W = self.rng.normal(loc=0.0, scale=0.01, size=(D, H))\n            self.b_v = np.zeros(D)\n            self.b_h = np.zeros(H)\n\n        def _sigmoid(self, x):\n            return 1.0 / (1.0 + np.exp(-x))\n\n        def _sample_h_given_v(self, v):\n            \"\"\"Sample hidden units given visible units.\"\"\"\n            h_probs = self._sigmoid(self.b_h + v @ self.W)\n            h_samples = (self.rng.random(self.H)  h_probs).astype(np.float64)\n            return h_probs, h_samples\n\n        def _sample_v_given_h(self, h):\n            \"\"\"Sample visible units given hidden units.\"\"\"\n            v_probs = self._sigmoid(self.b_v + h @ self.W.T)\n            v_samples = (self.rng.random(self.D)  v_probs).astype(np.float64)\n            return v_probs, v_samples\n        \n        def _gibbs_step(self, v):\n            \"\"\"Perform one full Gibbs step.\"\"\"\n            _, h_sample = self._sample_h_given_v(v)\n            _, v_sample = self._sample_v_given_h(h_sample)\n            return v_sample\n\n        def train_cd(self, curriculum, k, eta):\n            \"\"\"Train the RBM using CD-k.\"\"\"\n            for v_pos in curriculum:\n                # Positive phase\n                pos_h_probs, _ = self._sample_h_given_v(v_pos)\n\n                # Negative phase (Gibbs sampling)\n                v_neg = v_pos.copy()\n                for _ in range(k):\n                    v_neg = self._gibbs_step(v_neg)\n                \n                neg_h_probs, _ = self._sample_h_given_v(v_neg)\n\n                # Update parameters\n                self.W += eta * (np.outer(v_pos, pos_h_probs) - np.outer(v_neg, neg_h_probs))\n                self.b_v += eta * (v_pos - v_neg)\n                self.b_h += eta * (pos_h_probs - neg_h_probs)\n\n        def train_pcd(self, curriculum, M, k, eta):\n            \"\"\"Train the RBM using PCD with M persistent chains.\"\"\"\n            # Initialize persistent chains (fantasy particles)\n            chains = self.rng.integers(0, 2, size=(M, self.D)).astype(np.float64)\n\n            for v_pos in curriculum:\n                # Positive phase\n                pos_h_probs, _ = self._sample_h_given_v(v_pos)\n\n                # Negative phase (update persistent chains)\n                for i in range(M):\n                    for _ in range(k): # k steps per update for each chain\n                        chains[i] = self._gibbs_step(chains[i])\n                \n                v_negs = chains\n                neg_h_probs_batch = self._sigmoid(self.b_h + v_negs @ self.W)\n\n                # Update parameters\n                self.W += eta * (np.outer(v_pos, pos_h_probs) - np.mean([np.outer(v_negs[i], neg_h_probs_batch[i]) for i in range(M)], axis=0))\n                self.b_v += eta * (v_pos - np.mean(v_negs, axis=0))\n                self.b_h += eta * (pos_h_probs - np.mean(neg_h_probs_batch, axis=0))\n\n        def evaluate_prob(self, v_target):\n            \"\"\"Compute the exact probability of a visible vector v_target.\"\"\"\n            # Generate all 2^D possible visible vectors\n            num_v_states = 2**self.D\n            all_v = np.zeros((num_v_states, self.D), dtype=int)\n            for i in range(num_v_states):\n                binary_str = format(i, f'0{self.D}b')\n                all_v[i, :] = [int(b) for b in binary_str]\n\n            # Compute free energy for all visible states\n            # F(v) = -b_v^T v - sum_j log(1 + exp(b_h_j + W_j^T v))\n            log_1_plus_exp_term = np.log(1 + np.exp(self.b_h + all_v @ self.W))\n            free_energies = -all_v @ self.b_v - np.sum(log_1_plus_exp_term, axis=1)\n\n            # Compute log partition function using log-sum-exp for stability\n            log_Z_v = logsumexp(-free_energies)\n\n            # Compute log probability of the target vector\n            log_1_plus_exp_target = np.log(1 + np.exp(self.b_h + v_target @ self.W))\n            F_target = -v_target @ self.b_v - np.sum(log_1_plus_exp_target)\n            log_prob_target = -F_target - log_Z_v\n\n            return np.exp(log_prob_target)\n\n    results = []\n    \n    for case in test_cases:\n        # 1. Initialize RBM with the specified seed\n        rbm = RBM(D, H, seed=case['seed'])\n        \n        # 2. Construct the training curriculum\n        T = case['T']\n        alpha = case['alpha']\n        num_skewed_updates = int(alpha * T)\n        num_alternating_updates = T - num_skewed_updates\n        \n        curriculum = []\n        if case['data'] == 'unimodal' or num_skewed_updates > 0:\n            curriculum.extend([V_A] * num_skewed_updates)\n            \n        if case['data'] == 'bimodal' and num_alternating_updates > 0:\n            for i in range(num_alternating_updates):\n                curriculum.append(V_A if i % 2 == 0 else V_B)\n        \n        # 3. Train the RBM\n        if case['method'] == 'cd':\n            rbm.train_cd(curriculum, k=case['k'], eta=case['eta'])\n        elif case['method'] == 'pcd':\n            rbm.train_pcd(curriculum, M=case['M'], k=case['k'], eta=case['eta'])\n            \n        # 4. Evaluate the trained model\n        prob_A = rbm.evaluate_prob(V_A)\n        prob_B = rbm.evaluate_prob(V_B)\n        \n        # 5. Check success criterion\n        success = False\n        if case['data'] == 'bimodal':\n            # Bimodal success: both modes have significant probability\n            if prob_A > 0.2 and prob_B > 0.2:\n                success = True\n        elif case['data'] == 'unimodal':\n            # Unimodal success: the single mode has high probability\n            if prob_A > 0.5:\n                success = True\n                \n        results.append(success)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3109758"}, {"introduction": "像 RBM 这样的能量模型，其行为与统计物理学中的概念（如温度）密切相关。分析系统在极端物理条件下的行为，可以为了解学习动态提供深刻的见解。[@problem_id:3109725] 这项练习要求你研究 RBM 的高温极限（即逆温度 $\\beta \\to 0$）。你将探索这个极限如何影响模型的概率分布、吉布斯采样的效率以及训练梯度的幅度。这项高级练习超越了简单的算法机制，将 CD 与玻尔兹曼分布的深层理论联系起来，揭示了一个微妙但至关重要的权衡：虽然高温可以改善采样，但它也可能导致学习信号消失，从而让你对训练能量模型的挑战有更细致的理解。", "problem": "考虑一个二元受限玻尔兹曼机 (RBM)，其可见单元为 $v \\in \\{0,1\\}^{n}$，隐藏单元为 $h \\in \\{0,1\\}^{m}$，参数为 $\\theta = \\{W,b,c\\}$，能量函数为 $E_{\\theta}(v,h) = - b^{\\top} v - c^{\\top} h - v^{\\top} W h$。在逆温度 $\\beta  0$ 下，相关的玻尔兹曼分布为 $p_{\\beta,\\theta}(v,h) = \\exp\\left(-\\beta E_{\\theta}(v,h)\\right) / Z_{\\beta}(\\theta)$，其中 $Z_{\\beta}(\\theta)$ 是配分函数。交替 Gibbs 采样使用条件概率 $p_{\\beta,\\theta}(h \\mid v)$ 和 $p_{\\beta,\\theta}(v \\mid h)$，而 k 步对比散度 (CD-$k$) 通过从一个数据点开始运行 k 次交替采样来形成一个负样本。\n\n显式地处理温度，并研究 $\\beta \\to 0$（高温）的情况。仅使用玻尔兹曼分布的定义和条件概率的标准性质，推断 $p_{\\beta,\\theta}(v,h)$ 的分布极限以及 Gibbs 条件概率和 CD-$k$ 负样本的定性行为。然后评估其对最大似然梯度和 CD-$k$ 估计量的影响。\n\n选择所有在 $\\beta \\to 0$ 极限下正确的陈述：\n\nA. 当 $\\beta \\to 0$ 时，联合模型 $p_{\\beta,\\theta}(v,h)$ 趋近于 $\\{0,1\\}^{n+m}$ 上的均匀分布；因此，对于 Gibbs 采样，$p_{\\beta,\\theta}(h_{j} = 1 \\mid v) \\to \\tfrac{1}{2}$ 且 $p_{\\beta,\\theta}(v_{i} = 1 \\mid h) \\to \\tfrac{1}{2}$，因此 CD-$k$ 负样本几乎是独立的公平硬币投掷，与起始数据无关。\n\nB. 关于 $W_{ij}$ 的最大似然梯度满足 $\\frac{\\partial}{\\partial W_{ij}} \\log p_{\\beta,\\theta}(v_{\\text{data}}) = \\beta \\left( \\langle v_{i} h_{j} \\rangle_{p_{\\beta,\\theta}(h \\mid v_{\\text{data}})} - \\langle v_{i} h_{j} \\rangle_{p_{\\beta,\\theta}(v,h)} \\right)$，所以其幅度按 $O(\\beta)$ 缩放；除非学习率按 $1/\\beta$ 缩放，否则当 $\\beta \\to 0$ 时学习会停滞。\n\nC. 高温会减慢 Gibbs 混合速度，因此对于固定的 k，当 $\\beta \\to 0$ 时，CD-$k$ 的负相偏差更大。\n\nD. 在 $\\beta \\to 0$ 的极限下，模型期望 $\\langle v_{i} h_{j} \\rangle_{p_{\\beta,\\theta}(v,h)} \\to \\tfrac{1}{4}$，而数据条件期望 $\\langle v_{i} h_{j} \\rangle_{p_{\\beta,\\theta}(h \\mid v_{\\text{data}})}$ 保持为 $O(1)$，因此总梯度幅度不随 $\\beta$ 减小。\n\nE. 对于足够小的 $\\beta$，在 CD-$k$ 中增加 k 可以减少负相偏差（通过更好地逼近平衡态），但无法恢复梯度幅度，当 $\\beta \\to 0$ 时，该幅度仍为 $O(\\beta)$。\n\n选择所有适用的选项。", "solution": "在进行求解之前，分析问题陈述的有效性。\n\n**问题有效性验证**\n\n*   **步骤 1：提取已知条件**\n    *   模型：二元受限玻尔兹曼机 (RBM)。\n    *   可见单元：$v \\in \\{0,1\\}^{n}$。\n    *   隐藏单元：$h \\in \\{0,1\\}^{m}$。\n    *   参数：$\\theta = \\{W, b, c\\}$。\n    *   能量函数：$E_{\\theta}(v,h) = - b^{\\top} v - c^{\\top} h - v^{\\top} W h$。\n    *   逆温度：$\\beta  0$。\n    *   玻尔兹曼分布：$p_{\\beta,\\theta}(v,h) = \\exp\\left(-\\beta E_{\\theta}(v,h)\\right) / Z_{\\beta}(\\theta)$，其中 $Z_{\\beta}(\\theta)$ 是配分函数。\n    *   采样：使用条件概率 $p_{\\beta,\\theta}(h \\mid v)$ 和 $p_{\\beta,\\theta}(v \\mid h)$ 的交替 Gibbs 采样。\n    *   学习背景：k 步对比散度 (CD-$k$)。\n    *   任务：分析 $\\beta \\to 0$（高温）的极限及其对模型分布、Gibbs 采样、CD-$k$ 和最大似然梯度的影响。\n\n*   **步骤 2：使用提取的已知条件进行验证**\n    *   该问题具有科学依据。RBM 的定义、其能量函数、玻尔兹曼分布和 CD-$k$ 算法都是统计机器学习领域中的标准和正确的概念。\n    *   该问题是适定的。它要求分析一个特定的、明确定义的数学极限（$\\beta \\to 0$），并提供了执行此分析所需的所有信息。\n    *   该问题是客观的，并使用精确、正式的语言。没有主观或含糊的术语。\n    *   该问题不违反任何无效标准。这是一个标准的理论问题，旨在测试对温度在能量模型中作用的理解。\n\n*   **步骤 3：结论与行动**\n    *   问题陈述是有效的。将推导一个完整的解。\n\n**推导**\n\n我们分析 RBM 在高温极限下的行为，这对应于逆温度 $\\beta \\to 0$。\n\n1.  **联合分布 $p_{\\beta,\\theta}(v,h)$ 的极限**\n    一个状态 $(v,h)$ 的联合概率由 $p_{\\beta,\\theta}(v,h) = \\frac{\\exp(-\\beta E_{\\theta}(v,h))}{Z_{\\beta}(\\theta)}$ 给出。配分函数是 $Z_{\\beta}(\\theta) = \\sum_{v',h'} \\exp(-\\beta E_{\\theta}(v',h'))$。\n    当 $\\beta \\to 0$ 时，对于任何固定状态 $(v,h)$ 和有限参数 $\\theta$，指数项 $-\\beta E_{\\theta}(v,h) \\to 0$。因此，$\\exp(-\\beta E_{\\theta}(v,h)) \\to \\exp(0) = 1$。\n    这适用于配分函数求和中的每一项。可能的状态 $(v,h)$ 的总数为 $2^n \\cdot 2^m = 2^{n+m}$。\n    因此，在 $\\beta \\to 0$ 的极限下：\n    $$Z_{\\beta}(\\theta) = \\sum_{v,h} \\exp(-\\beta E_{\\theta}(v,h)) \\to \\sum_{v,h} 1 = 2^{n+m}$$\n    联合概率分布变为：\n    $$p_{\\beta,\\theta}(v,h) \\to \\frac{1}{2^{n+m}}$$\n    这是在整个状态空间 $\\{0,1\\}^{n+m}$ 上的均匀分布。在无限高的温度下，状态之间的能量差异变得无关紧要，所有状态都变得同样可能。\n\n2.  **条件分布（Gibbs 采样器）的极限**\n    由于 RBM 的二分图结构，给定可见单元，隐藏单元条件独立，反之亦然。单个隐藏单元 $h_j$ 被激活的条件概率由 sigmoid 函数 $\\sigma(x)=(1+e^{-x})^{-1}$ 给出：\n    $$p_{\\beta,\\theta}(h_j=1 \\mid v) = \\sigma\\left(\\beta \\left(c_j + \\sum_{i=1}^{n} v_i W_{ij}\\right)\\right)$$\n    当 $\\beta \\to 0$ 时，sigmoid 函数的自变量趋于 $0$，因为 $c_j + \\sum_{i} v_i W_{ij}$ 是一个有限值。\n    $$p_{\\beta,\\theta}(h_j=1 \\mid v) \\to \\sigma(0) = \\frac{1}{1+e^0} = \\frac{1}{2}$$\n    这个极限与可见层 $v$ 的状态无关。类似地，对于单个可见单元 $v_i$：\n    $$p_{\\beta,\\theta}(v_i=1 \\mid h) = \\sigma\\left(\\beta \\left(b_i + \\sum_{j=1}^{m} W_{ij} h_j\\right)\\right)$$\n    当 $\\beta \\to 0$ 时，自变量再次趋于 $0$，所以：\n    $$p_{\\beta,\\theta}(v_i=1 \\mid h) \\to \\sigma(0) = \\frac{1}{2}$$\n    在高温下，任何单元为 1 的条件概率都趋近于 $1/2$，而不管另一层的状态如何。每个单元实际上表现得像一个独立的、公平的硬币投掷。\n\n3.  **CD-$k$ 负样本的行为**\n    CD-$k$ 算法通过从数据点 $v^{(0)} = v_{\\text{data}}$ 开始并运行 k 步交替 Gibbs 采样来生成负样本：$h^{(t)} \\sim p(h \\mid v^{(t-1)})$ 和 $v^{(t)} \\sim p(v \\mid h^{(t)})$。\n    当 $\\beta \\to 0$ 时，对 $h$ 或 $v$ 的每个采样步骤都涉及从一个分布中抽样，其中每个单元都是一个独立的伯努利(1/2)变量。马尔可夫链瞬间达到其平稳分布，即均匀分布。因此，对于任何 $k \\ge 1$，负样本 $v^{(k)}$ 将是从 $\\{0,1\\}^n$ 上的均匀分布中抽取的样本，而与起始数据点 $v_{\\text{data}}$ 无关。\n\n4.  **最大似然梯度**\n    数据点 $v_{\\text{data}}$ 的对数似然关于权重参数 $W_{ij}$ 的梯度为：\n    $$\\frac{\\partial}{\\partial W_{ij}} \\log p_{\\beta,\\theta}(v_{\\text{data}}) = \\beta \\left( \\langle v_{i} h_{j} \\rangle_{p_{\\beta,\\theta}(h \\mid v_{\\text{data}})} - \\langle v_{i} h_{j} \\rangle_{p_{\\beta,\\theta}(v,h)} \\right)$$\n    第一项是“正相”或数据相关期望。第二项是“负相”或模型期望。让我们在 $\\beta \\to 0$ 时分析这些项：\n    *   **正相项**：$\\langle v_{i} h_{j} \\rangle_{p_{\\beta,\\theta}(h \\mid v_{\\text{data}})} = v_{\\text{data},i} \\cdot \\langle h_j \\rangle_{p(h|v_{\\text{data}})} = v_{\\text{data},i} \\cdot p_{\\beta,\\theta}(h_j=1 \\mid v_{\\text{data}})$。根据我们的分析，$p_{\\beta,\\theta}(h_j=1 \\mid v_{\\text{data}}) \\to 1/2$。所以，该项趋近于 $v_{\\text{data},i} / 2$，这是一个 $O(1)$ 的常数（0 或 1/2）。\n    *   **负相项**：$\\langle v_{i} h_{j} \\rangle_{p_{\\beta,\\theta}(v,h)}$。这是在完整联合分布上的期望。当 $\\beta \\to 0$ 时，该分布变为均匀分布。在均匀分布下，$v_i$ 和 $h_j$ 是独立的伯努利(1/2)随机变量。因此，$\\langle v_i h_j \\rangle = \\langle v_i \\rangle \\langle h_j \\rangle = (1/2) \\cdot (1/2) = 1/4$。\n    *   **完整梯度**：括号中的项趋近于一个常数值：$(v_{\\text{data},i}/2 - 1/4)$。整个梯度乘以 $\\beta$。\n        $$\\frac{\\partial}{\\partial W_{ij}} \\log p_{\\beta,\\theta}(v_{\\text{data}}) \\to \\beta \\left( \\frac{v_{\\text{data},i}}{2} - \\frac{1}{4} \\right)$$\n    因此，梯度的幅度是 $O(\\beta)$ 阶的，并在 $\\beta \\to 0$ 时消失。\n\n**逐项分析**\n\n*   **A. 当 $\\beta \\to 0$ 时，联合模型 $p_{\\beta,\\theta}(v,h)$ 趋近于 $\\{0,1\\}^{n+m}$ 上的均匀分布；因此，对于 Gibbs 采样，$p_{\\beta,\\theta}(h_{j} = 1 \\mid v) \\to \\tfrac{1}{2}$ 且 $p_{\\beta,\\theta}(v_{i} = 1 \\mid h) \\to \\tfrac{1}{2}$，因此 CD-$k$ 负样本几乎是独立的公平硬币投掷，与起始数据无关。**\n    这个陈述与我们的推导完全一致。联合分布变为均匀分布，每个单元被激活的条件概率变为 $1/2$，Gibbs 采样产生来自均匀分布的随机样本，等同于公平的硬币投掷。\n    **结论：正确。**\n\n*   **B. 关于 $W_{ij}$ 的最大似然梯度满足 $\\frac{\\partial}{\\partial W_{ij}} \\log p_{\\beta,\\theta}(v_{\\text{data}}) = \\beta \\left( \\langle v_{i} h_{j} \\rangle_{p_{\\beta,\\theta}(h \\mid v_{\\text{data}})} - \\langle v_{i} h_{j} \\rangle_{p_{\\beta,\\theta}(v,h)} \\right)$，所以其幅度按 $O(\\beta)$ 缩放；除非学习率按 $1/\\beta$ 缩放，否则当 $\\beta \\to 0$ 时学习会停滞。**\n    梯度公式是正确的。我们的分析表明，括号中的项收敛到一个非零常数，而整个表达式按 $\\beta$ 缩放。因此，梯度幅度按 $O(\\beta)$ 缩放，并在 $\\beta \\to 0$ 时消失。对于固定的学习率 $\\eta$，标准的梯度下降更新 $\\Delta W_{ij} \\propto \\eta \\cdot \\nabla_{W_{ij}}\\mathcal{L}$ 将趋于零。为了保持恒定的更新幅度，$\\eta$ 确实需要按 $1/\\beta$ 缩放。若无此缩放，学习实际上会停滞。\n    **结论：正确。**\n\n*   **C. 高温会减慢 Gibbs 混合速度，因此对于固定的 k，当 $\\beta \\to 0$ 时，CD-$k$ 的负相偏差更大。**\n    这个陈述是不正确的。高温（$\\beta \\to 0$）对应于一个“更平坦”的能量景观。由于所有状态变得更加等可能，Gibbs 采样中的转移变得不那么依赖于当前状态。这会*加速*混合，而不是减慢它。在极限情况下，Gibbs 采样器在单步内收敛到其平稳（均匀）分布。因此，CD-$k$ 估计量对于负相期望的偏差（对于任何 $k \\ge 1$）实际上趋于零，而不是增加。\n    **结论：不正确。**\n\n*   **D. 在 $\\beta \\to 0$ 的极限下，模型期望 $\\langle v_{i} h_{j} \\rangle_{p_{\\beta,\\theta}(v,h)} \\to \\tfrac{1}{4}$，而数据条件期望 $\\langle v_{i} h_{j} \\rangle_{p_{\\beta,\\theta}(h \\mid v_{\\text{data}})}$ 保持为 $O(1)$，因此总梯度幅度不随 $\\beta$ 减小。**\n    陈述的第一部分是正确的。如推导所示，在极限均匀分布下的模型期望 $\\langle v_i h_j \\rangle$ 是 $1/4$。数据条件期望 $\\langle v_i h_j \\rangle_{p(h|v_{\\text{data}})}$ 趋近于 $v_{\\text{data},i}/2$，这确实是 $O(1)$。然而，结论是错误的。它忽略了梯度公式中显式的 $\\beta$ 前置因子：$\\nabla \\mathcal{L} = \\beta (\\text{正相} - \\text{负相})$。尽管括号内的差是 $O(1)$，但总梯度是 $O(\\beta)$，因此其幅度在 $\\beta \\to 0$ 时减小到零。\n    **结论：不正确。**\n\n*   **E. 对于足够小的 $\\beta$，在 CD-$k$ 中增加 k 可以减少负相偏差（通过更好地逼近平衡态），但无法恢复梯度幅度，当 $\\beta \\to 0$ 时，该幅度仍为 $O(\\beta)$。**\n    这个陈述正确地指出了两个不同的问题。CD-$k$ 梯度估计量的偏差来自于用 k 步样本近似模型的平衡态期望。增加 k 可以通过让 Gibbs 链运行更长时间来减少这种偏差。然而，在 $\\beta \\to 0$ 极限下的根本问题是真实梯度本身就消失了。整个梯度表达式都按 $\\beta$ 缩放。CD-$k$ 过程是对这个真实梯度的近似。通过增加 k 来改进近似会使 CD-$k$ 梯度更接近真实梯度，但真实梯度已经趋于零。因此，增加 k 不能“恢复”一个内在地按 $\\beta$ 缩放的梯度幅度。\n    **结论：正确。**", "answer": "$$\\boxed{ABE}$$", "id": "3109725"}]}