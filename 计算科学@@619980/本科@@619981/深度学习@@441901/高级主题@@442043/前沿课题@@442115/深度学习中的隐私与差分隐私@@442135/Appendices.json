{"hands_on_practices": [{"introduction": "除了对模型进行隐私保护训练，我们还经常面临一个任务：如何在不泄露敏感数据集信息的前提下，从一组候选模型中选出最佳模型。指数机制 (Exponential Mechanism) 是差分隐私中一个功能强大且通用的工具，专为解决此类隐私选择问题而设计。本练习 [@problem_id:3165692] 将指导你从基本原理出发实现该机制，让你具体理解如何通过概率化的方式，在模型效用和严格的 $\\epsilon$-DP 保证之间进行权衡。", "problem": "您的任务是构建一个选择机制，该机制在基于实值效用函数从有限候选集中选择单个模型时，满足差分隐私 (DP)。请仅从以下基础出发：$\\epsilon$-差分隐私 (DP) 的定义以及效用函数的有界敏感度。如果对于所有恰好相差一条记录的相邻数据集 $D$ 和 $D'$，以及对于所有可测的输出子集 $S$，以下不等式成立，则称随机化机制 $\\mathcal{M}$ 满足 $\\epsilon$-差分隐私：\n$$\n\\Pr[\\mathcal{M}(D) \\in S] \\le e^{\\epsilon} \\Pr[\\mathcal{M}(D') \\in S].\n$$\n假设一个实值效用函数 $u(D, r)$，其对于输出 $r$ 的已知全局敏感度为 $\\Delta u$：\n$$\n\\Delta u = \\max_{D \\sim D'} \\max_{r} |u(D, r) - u(D', r)|.\n$$\n构建一个选择单个模型的机制，该机制相对于 $D$ 是差分隐私的，并且其选择概率偏好具有更高效用的模型。请仅使用上述基本定义推导该机制的选择规则，然后实现它。\n\n您的程序必须实现从第一性原理推导出的指数机制 (Exponential Mechanism)。给定：\n- $k$ 个候选模型的效用列表 $[u_0, u_1, \\dots, u_{k-1}]$，\n- 隐私参数 $\\epsilon > 0$，\n- 效用敏感度 $\\Delta u > 0$，\n请输出您的机制所隐含的候选模型上的归一化选择概率，然后为一组测试用例计算指定的属性。\n\n在您的最终输出中不要使用任何随机性；请确定性地计算精确概率。使用数值稳定的计算方法。模型索引使用从零开始的编号。\n\n测试套件。对于下面的每个测试用例，请精确计算所要求的量。所有相等性检查的容差均为 $10^{-12}$ 的绝对容差。\n- 测试 A (正常路径)：效用 $[1.0, 2.0, 0.0]$，$\\epsilon = 1.0$，$\\Delta u = 1.0$。按顺序输出两个量：\n  1) 选择具有最大效用模型的概率（浮点数），四舍五入到 $6$ 位小数，\n  2) 在您的机制下具有最大选择概率的模型的从零开始的索引（整数）。\n- 测试 B (边界情况 $\\epsilon = 0$)：效用 $[3.0, -1.0, 7.0, 7.0]$，$\\epsilon = 0.0$，$\\Delta u = 1.0$。输出一个布尔值，当且仅当生成的分布在容差范围内是均匀的（即所有概率在指定容差内等于 $1/k$）时，该值为真。\n- 测试 C (平局公平性)：效用 $[0.5, 0.5, 0.0]$，$\\epsilon = 2.0$，$\\Delta u = 1.0$。输出一个布尔值，当且仅当具有相同效用的模型在容差范围内具有相等的选择概率时，该值为真。\n- 测试 D (相邻数据集上的隐私比率检查，两个输出)：效用 $u = [0.0, 1.0]$，相邻效用 $u' = [0.2, 0.8]$，$\\epsilon = 0.5$，$\\Delta u = 0.2$。由于恰好有 $2$ 个输出，验证单点事件上的不等式即意味着它对所有可测子集都成立。输出一个布尔值，当且仅当\n  $$\n  \\max\\left\\{\\max_{i \\in \\{0,1\\}} \\frac{p_i(u)}{p_i(u')}, \\max_{i \\in \\{0,1\\}} \\frac{p_i(u')}{p_i(u)}\\right\\} \\le e^{\\epsilon} + 10^{-12},\n  $$\n  成立时，该值为真，其中 $p_i(\\cdot)$ 表示在相应效用向量下索引 $i$ 的选择概率。\n- 测试 E (大 $\\epsilon$ 下的集中性)：效用 $[0.0, 2.0, 1.0]$，$\\epsilon = 10.0$，$\\Delta u = 1.0$。输出选择具有最大效用模型的概率（浮点数），四舍五入到 $6$ 位小数。\n- 测试 F (敏感度的影响)：效用 $[0.0, 2.0, 1.0]$，$\\epsilon = 1.0$，比较 $\\Delta u_1 = 1.0$ 与 $\\Delta u_2 = 2.0$。输出一个布尔值，当且仅当使用 $\\Delta u_1$ 选择最佳效用模型的概率在容差范围内大于或等于使用 $\\Delta u_2$ 时的概率时，该值为真。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，结果按以下顺序排列：\n$$\n[\\text{测试 A 概率}, \\text{测试 A 索引}, \\text{测试 B 布尔值}, \\text{测试 C 布尔值}, \\text{测试 D 布尔值}, \\text{测试 E 概率}, \\text{测试 F 布尔值}]\n$$\n对于概率，输出前请四舍五入到 $6$ 位小数。索引是整数，布尔值使用编程语言的原生布尔格式。不需要外部输入；请将上述测试套件参数硬编码到您的程序中。本问题不涉及物理单位或角度。所有小数量都应表示为小数，而不是百分比。", "solution": "任务是基于一个实值效用函数，推导并实现一个差分隐私机制，用于从有限的候选集中选择一个模型。推导必须从 $\\epsilon$-差分隐私 ($\\epsilon$-DP) 和全局敏感度的基本定义开始。\n\n设 $R$ 为候选模型的有限集。设 $u(D, r)$ 是一个实值效用函数，它根据数据集 $D$ 为模型 $r \\in R$ 打分。$u$ 的全局敏感度定义为 $\\Delta u = \\max_{D \\sim D'} \\max_{r \\in R} |u(D, r) - u(D', r)|$，其中 $D$ 和 $D'$ 是相差一条记录的相邻数据集。\n\n我们的目标是构建一个随机化机制 $\\mathcal{M}$，给定数据集 $D$，该机制以概率 $\\Pr[\\mathcal{M}(D) = r]$ 输出一个模型 $r \\in R$。该机制必须满足 $\\epsilon$-DP，即对于任何一对相邻数据集 $D, D'$ 和任何输出子集 $S \\subseteq R$，我们有 $\\Pr[\\mathcal{M}(D) \\in S] \\le e^{\\epsilon} \\Pr[\\mathcal{M}(D') \\in S]$。只需对所有单元素集合 $S = \\{r\\}$ 证明这一点即可。\n\n为了偏好具有更高效用的模型，我们提议选择模型 $r$ 的概率与其效用的指数函数成正比。这是一个常见的选择，因为它在提供对更高效用的强烈偏好的同时，在数学上是易于处理的。设未归一化的分数为 $\\exp(c \\cdot u(D, r))$ 的比例，其中 $c > 0$ 是一个待确定的常数。\n\n为了形成一个有效的概率分布，我们将这些分数在所有模型 $R$ 上进行归一化：\n$$\n\\Pr[\\mathcal{M}(D) = r] = \\frac{\\exp(c \\cdot u(D, r))}{\\sum_{r' \\in R} \\exp(c \\cdot u(D, r'))}\n$$\n现在，我们必须找到常数 $c$ 的值，以确保该机制满足 $\\epsilon$-DP。我们分析在两个相邻数据集 $D$ 和 $D'$ 上，对于任意输出 $r$ 的概率比率：\n$$\n\\frac{\\Pr[\\mathcal{M}(D) = r]}{\\Pr[\\mathcal{M}(D') = r]} = \\frac{\\frac{\\exp(c \\cdot u(D, r))}{\\sum_{r_j \\in R} \\exp(c \\cdot u(D, r_j))}}{\\frac{\\exp(c \\cdot u(D', r))}{\\sum_{r_j \\in R} \\exp(c \\cdot u(D', r_j))}} = \\frac{\\exp(c \\cdot u(D, r))}{\\exp(c \\cdot u(D', r))} \\cdot \\frac{\\sum_{r_j \\in R} \\exp(c \\cdot u(D', r_j))}{\\sum_{r_j \\in R} \\exp(c \\cdot u(D, r_j))}\n$$\n我们使用全局敏感度 $\\Delta u$ 的定义来界定这个比率。我们可以分别对乘积中的两项进行界定。\n\n对于第一项，根据敏感度的定义，有 $u(D, r) \\le u(D', r) + \\Delta u$。由于 $c > 0$，这意味着：\n$$\n\\exp(c \\cdot u(D, r)) \\le \\exp(c \\cdot (u(D', r) + \\Delta u)) = \\exp(c \\cdot u(D', r)) \\cdot \\exp(c \\cdot \\Delta u)\n$$\n因此，第一项的上界为 $\\exp(c \\cdot \\Delta u)$。\n\n对于第二项，即归一化常数的比率，我们为其分母建立一个下界。对于任何模型 $r_j \\in R$，我们有 $u(D, r_j) \\ge u(D', r_j) - \\Delta u$。因此：\n$$\n\\exp(c \\cdot u(D, r_j)) \\ge \\exp(c \\cdot (u(D', r_j) - \\Delta u)) = \\exp(c \\cdot u(D', r_j)) \\cdot \\exp(-c \\cdot \\Delta u)\n$$\n对所有 $r_j \\in R$ 求和，我们得到整个和的一个界：\n$$\n\\sum_{r_j \\in R} \\exp(c \\cdot u(D, r_j)) \\ge \\sum_{r_j \\in R} \\left( \\exp(c \\cdot u(D', r_j)) \\cdot \\exp(-c \\cdot \\Delta u) \\right) = \\exp(-c \\cdot \\Delta u) \\sum_{r_j \\in R} \\exp(c \\cdot u(D', r_j))\n$$\n这给了我们和的倒数的一个上界：\n$$\n\\frac{1}{\\sum_{r_j \\in R} \\exp(c \\cdot u(D, r_j))} \\le \\frac{1}{\\exp(-c \\cdot \\Delta u) \\sum_{r_j \\in R} \\exp(c \\cdot u(D', r_j))}\n$$\n将此与第二项的分子 $\\sum_{r_j \\in R} \\exp(c \\cdot u(D', r_j))$ 相乘，我们发现第二项的上界为 $\\exp(c \\cdot \\Delta u)$。\n\n结合两项的界，我们得到概率比率的一个上界：\n$$\n\\frac{\\Pr[\\mathcal{M}(D) = r]}{\\Pr[\\mathcal{M}(D') = r]} \\le \\exp(c \\cdot \\Delta u) \\cdot \\exp(c \\cdot \\Delta u) = \\exp(2c \\cdot \\Delta u)\n$$\n为了满足 $\\epsilon$-DP 约束，这个上界必须不大于 $e^\\epsilon$：\n$$ \\exp(2c \\cdot \\Delta u) \\le e^{\\epsilon} \\implies 2c \\cdot \\Delta u \\le \\epsilon $$\n为了提供最强的效用保证（即，在隐私允许的范围内使选择对效用尽可能敏感），我们应该选择 $c$ 的最大可能值，这对应于将不等式设为等式：$2c \\cdot \\Delta u = \\epsilon$。这得出了 $c$ 的值：\n$$\nc = \\frac{\\epsilon}{2 \\Delta u}\n$$\n将此代回我们的概率公式，得到用于模型选择的指数机制的最终形式：\n$$\np_i = \\Pr[\\mathcal{M}(D) = r_i] = \\frac{\\exp\\left(\\frac{\\epsilon u_i}{2 \\Delta u}\\right)}{\\sum_{j=0}^{k-1} \\exp\\left(\\frac{\\epsilon u_j}{2 \\Delta u}\\right)}\n$$\n其中 $u_i$ 是 $u(D, r_i)$ 的简写。在实现时，为了避免计算指数时发生数值溢出，我们使用 log-sum-exp 稳定技巧。令 $s_i = \\frac{\\epsilon u_i}{2 \\Delta u}$ 和 $s_{\\max} = \\max_j s_j$，则概率计算如下：\n$$\np_i = \\frac{\\exp(s_i - s_{\\max})}{\\sum_{j=0}^{k-1} \\exp(s_j - s_{\\max})}\n$$\n这种形式在数值上是稳定的，因为指数函数的参数都是非正数。", "answer": "```python\nimport numpy as np\n\ndef run_exponential_mechanism(utilities, epsilon, delta_u):\n    \"\"\"\n    Computes the selection probabilities using the Exponential Mechanism.\n    \n    Args:\n        utilities (list or np.ndarray): A list of utility scores for k models.\n        epsilon (float): The privacy parameter epsilon.\n        delta_u (float): The global sensitivity of the utility function.\n        \n    Returns:\n        np.ndarray: An array of k selection probabilities.\n    \"\"\"\n    utilities = np.array(utilities, dtype=np.float64)\n    k = len(utilities)\n    \n    # Handle the boundary case of epsilon = 0, which implies a uniform distribution.\n    if epsilon == 0.0:\n        return np.full(k, 1.0 / k)\n    \n    # The problem specifies epsilon > 0 and delta_u > 0 for the main derivation,\n    # but Test B uses epsilon=0. delta_u=0 would be an issue, but is not tested.\n    if delta_u == 0:\n        raise ValueError(\"delta_u must be positive.\")\n\n    # Calculate scaled utilities as per the derived formula.\n    scaling_factor = epsilon / (2.0 * delta_u)\n    scaled_utilities = scaling_factor * utilities\n    \n    # Use the log-sum-exp trick for numerical stability.\n    # Subtracting the max value from each scaled utility before exponentiating\n    # prevents overflow and mitigates underflow.\n    max_scaled_utility = np.max(scaled_utilities)\n    exp_utilities = np.exp(scaled_utilities - max_scaled_utility)\n    \n    sum_exp_utilities = np.sum(exp_utilities)\n    \n    probabilities = exp_utilities / sum_exp_utilities\n    return probabilities\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    results = []\n    TOL = 1e-12\n\n    # --- Test A ---\n    u_A = [1.0, 2.0, 0.0]\n    eps_A = 1.0\n    du_A = 1.0\n    probs_A = run_exponential_mechanism(u_A, eps_A, du_A)\n    best_utility_idx_A = np.argmax(u_A)\n    prob_of_best_A = probs_A[best_utility_idx_A]\n    max_prob_idx_A = np.argmax(probs_A)\n    results.append(round(prob_of_best_A, 6))\n    results.append(int(max_prob_idx_A))\n\n    # --- Test B ---\n    u_B = [3.0, -1.0, 7.0, 7.0]\n    eps_B = 0.0\n    du_B = 1.0\n    probs_B = run_exponential_mechanism(u_B, eps_B, du_B)\n    k_B = len(u_B)\n    is_uniform_B = np.all(np.abs(probs_B - 1.0/k_B) = TOL)\n    results.append(is_uniform_B)\n    \n    # --- Test C ---\n    u_C = [0.5, 0.5, 0.0]\n    eps_C = 2.0\n    du_C = 1.0\n    probs_C = run_exponential_mechanism(u_C, eps_C, du_C)\n    # indices 0 and 1 have tied utilities\n    tied_probs_equal_C = np.abs(probs_C[0] - probs_C[1]) = TOL\n    results.append(tied_probs_equal_C)\n\n    # --- Test D ---\n    u_D = [0.0, 1.0]\n    u_prime_D = [0.2, 0.8]\n    eps_D = 0.5\n    du_D = 0.2\n    probs_D = run_exponential_mechanism(u_D, eps_D, du_D)\n    probs_prime_D = run_exponential_mechanism(u_prime_D, eps_D, du_D)\n    \n    # Prevent division by zero, although not expected here\n    # Adding a small constant is one way, but given the problem setup,\n    # probabilities should be non-zero.\n    ratio1 = probs_D / probs_prime_D\n    ratio2 = probs_prime_D / probs_D\n    max_ratio = np.max(np.concatenate([ratio1, ratio2]))\n    \n    dp_holds_D = max_ratio = np.exp(eps_D) + TOL\n    results.append(dp_holds_D)\n\n    # --- Test E ---\n    u_E = [0.0, 2.0, 1.0]\n    eps_E = 10.0\n    du_E = 1.0\n    probs_E = run_exponential_mechanism(u_E, eps_E, du_E)\n    best_utility_idx_E = np.argmax(u_E)\n    prob_of_best_E = probs_E[best_utility_idx_E]\n    results.append(round(prob_of_best_E, 6))\n\n    # --- Test F ---\n    u_F = [0.0, 2.0, 1.0]\n    eps_F = 1.0\n    du1_F = 1.0\n    du2_F = 2.0\n    \n    probs1_F = run_exponential_mechanism(u_F, eps_F, du1_F)\n    probs2_F = run_exponential_mechanism(u_F, eps_F, du2_F)\n    \n    best_utility_idx_F = np.argmax(u_F)\n    prob_best1_F = probs1_F[best_utility_idx_F]\n    prob_best2_F = probs2_F[best_utility_idx_F]\n    \n    concentration_check_F = prob_best1_F >= prob_best2_F - TOL\n    results.append(concentration_check_F)\n    \n    # Format and print the final output\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3165692"}, {"introduction": "当通过差分隐私随机梯度下降 (DP-SGD) 训练深度神经网络时，梯度裁剪是限制敏感度的关键步骤。然而，裁剪的*结构*——是应用于整个网络层还是像卷积核这样的更小组件——会极大地影响隐私成本和模型效用。本练习 [@problem_id:3165699] 深入探讨了这一前沿主题，要求你在一个卷积网络中实现并比较不同的裁剪策略，并使用现代的隐私核算方法来分析由此产生的隐私-效用权衡。", "problem": "给定一个场景，该场景在一个简单的深度学习模型中隔离了结构化梯度裁剪对卷积核的隐私和效用影响。您的任务是实现一个完整的、可运行的程序，该程序使用不同的裁剪策略仅对卷积核训练一个最小的卷积分类器，添加高斯噪声以确保差分隐私 (DP)，并为固定的测试配置套件计算隐私-效用权衡。在整个过程中，请使用以下基础。\n\n定义和基础：\n- 差分隐私 (DP)：如果一个随机化机制对于任意一对相邻数据集（即相差一个样本的数据集）以及任意可测量的输出集，其在该集合上产生输出的概率差异最多为 $e^{\\varepsilon}$ 倍再加 $\\delta$，则称该机制满足 $(\\varepsilon,\\delta)$-差分隐私。\n- 零集中差分隐私 (zCDP)：如果一个机制的隐私损失随机变量具有以 $\\rho$ 为参数的次高斯尾部，则该机制满足 $\\rho$-zCDP。对于噪声标准差为 $\\sigma_{\\text{noise}}$ 且 $\\ell_2$ 敏感度为 $\\Delta$ 的高斯机制，满足 $\\rho$-zCDP，其中 $\\rho = \\Delta^2 / (2 \\sigma_{\\text{noise}}^2)$。zCDP 具有可加组合性：如果组合 $k$ 个参数分别为 $\\rho_1, \\ldots, \\rho_k$ 的机制，总参数为 $\\rho_{\\text{tot}} = \\sum_{i=1}^k \\rho_i$。任何 $\\rho$-zCDP 机制对于任意 $\\delta \\in (0,1)$ 都意味着 $(\\varepsilon,\\delta)$-DP，通过 $\\varepsilon = \\rho + 2 \\sqrt{\\rho \\log(1/\\delta)}$ 转换。\n- 平均梯度的校准：考虑一个大小为 $b$ 的批次。如果每个样本的梯度都被裁剪，使其 $\\ell_2$ 范数最多为 $C$，那么在添加/删除邻接关系下，平均梯度的 $\\ell_2$ 敏感度为 $\\Delta = C/b$。如果添加标准差为 $\\sigma_{\\text{noise}} = \\sigma \\cdot C / b$ 的高斯噪声（其中 $\\sigma$ 是噪声乘数），那么每一步的 zCDP 参数变为 $\\rho_{\\text{step}} = \\Delta^2 / (2 \\sigma_{\\text{noise}}^2) = 1/(2\\sigma^2)$，这与 $b$ 和 $C$ 无关。对于具有多个独立组（例如，独立的卷积核）的结构化裁剪，每一步的 zCDP 参数在各组之间相加。\n\n模型和训练设置：\n- 数据：创建一个包含 $N$ 个大小为 $8 \\times 8$ 的灰度图像的二元分类数据集，标签为 $y \\in \\{0,1\\}$。类别 $0$ 的图像包含一个水平条；类别 $1$ 的图像包含一个垂直条。为所有像素添加独立的零均值、小方差的高斯噪声，使数据变得不那么简单。\n- 模型：一个单一卷积层，有 $2$ 个大小为 $3\\times 3$ 的卷积核（步长为 $1$，有效卷积，无填充），然后对每个卷积核进行全局平均池化，产生一个 $2$ 维特征向量 $\\mathbf{h} \\in \\mathbb{R}^2$。接着，一个二元分类器计算一个标量 logit $z = \\mathbf{v}^{\\top}\\mathbf{h} + b$，其中权重向量为 $\\mathbf{v} \\in \\mathbb{R}^2$，偏置为 $b \\in \\mathbb{R}$。输出概率为 $p = \\sigma(z)$，其中 $\\sigma$ 是逻辑S型函数，每个样本的损失为 $L = -y \\log p - (1-y)\\log(1-p)$。\n- 梯度：使用链式法则和卷积的离散定义，从第一性原理计算每个样本的梯度。具体来说，使用 $ \\partial L / \\partial z = p - y$， $ \\partial L / \\partial \\mathbf{v} = (p - y)\\,\\mathbf{h}$，$ \\partial L / \\partial b = p - y$，$ \\partial L / \\partial \\mathbf{h} = (p - y)\\,\\mathbf{v}$，并且对于每个卷积核 $f$，将 $h_f$ 表示为其有效卷积输出的空间平均值，并使用离散卷积定义推导出 $ \\partial L / \\partial W^{(f)}$。\n- 隐私范围：只有卷积核受 DP 保护。分类器参数 $\\mathbf{v}$ 和 $b$ 的更新不加噪声。DP 分析应用于卷积核的带噪平均梯度发布序列。\n\n卷积核的裁剪策略：\n- 逐层裁剪：对于每个样本，将所有卷积核的梯度连接成一个单一向量，并将其 $\\ell_2$ 范数裁剪至最多为 $C$。\n- 逐参数裁剪：对于每个样本，将每个卷积核的梯度分别裁剪，使其 $\\ell_2$ 范数最多为 $C$，将每个卷积核视为一个独立的组。\n\n噪声添加：\n- 对于每个训练步骤，在对卷积核上的每样本梯度进行裁剪后，在批次上对它们进行平均，并向发布的平均梯度添加独立的高斯噪声。对于每个发布的组，使用噪声标准差 $\\sigma_{\\text{noise}} = \\sigma \\cdot C / b$，其中 $\\sigma$ 是噪声乘数，$b$ 是批次大小。\n- 在逐层裁剪中，只有一个发布组（整个层），因此每一步的 zCDP 参数为 $\\rho_{\\text{step}} = 1 / (2\\sigma^2)$。\n- 在有 $g$ 个卷积核的逐参数裁剪中，有 $g$ 个独立的发布组，因此每一步的 zCDP 参数为 $\\rho_{\\text{step}} = g / (2\\sigma^2)$。\n\n隐私核算：\n- 经过 $T$ 个训练步骤，总 zCDP 参数为 $\\rho_{\\text{tot}} = T \\cdot \\rho_{\\text{step}}$。\n- 对于固定的 $\\delta \\in (0,1)$，最终的 $(\\varepsilon,\\delta)$ 通过 $\\varepsilon = \\rho_{\\text{tot}} + 2 \\sqrt{\\rho_{\\text{tot}} \\log(1/\\delta)}$ 获得。\n\n效用度量：\n- 训练后，计算整个数据集上的分类准确率，即正确预测标签的比例，其中如果 $p \\geq 0.5$ 则标签预测为 $1$，否则为 $0$。准确率表示为 $[0,1]$ 范围内的小数。\n\n任务：\n- 实现完整的训练循环，包括两种裁剪策略、指定的高斯噪声添加以及用于生成固定 $\\delta$ 的 $(\\varepsilon,\\delta)$ 的 zCDP 隐私核算。\n- 使用固定的随机种子以确保确定性行为，从而使测试套件可复现。\n- 使用科学上合理的超参数，以便训练充分收敛，以区分不同测试用例的效用影响。\n\n测试套件：\n在以下四个测试用例上运行您的程序。每个用例指定为一个元组 $(\\text{mode}, C, \\sigma, b, T, \\delta)$，其中有 $g=2$ 个卷积核：\n1. 用例 A (标准路径，逐层): $(\\text{\"layer\"}, 1.0, 1.0, 16, 100, 10^{-5})$。\n2. 用例 B (结构化逐参数，相同噪声乘数): $(\\text{\"param\"}, 1.0, 1.0, 16, 100, 10^{-5})$。\n3. 用例 C (结构化逐参数，更强噪声): $(\\text{\"param\"}, 1.0, 2.0, 16, 100, 10^{-5})$。\n4. 用例 D (边界情况，小批量和强噪声，逐层): $(\\text{\"layer\"}, 0.1, 3.0, 1, 50, 10^{-5})$。\n\n输出规范：\n- 对于每个测试用例，使用所述的 zCDP 核算方法计算最终的 $(\\varepsilon,\\delta)$，并仅报告 $\\varepsilon$ 以及训练后的最终准确率。将 $\\varepsilon$ 和准确率都四舍五入到 $4$ 位小数。\n- 您的程序应生成单行输出，其中包含一个列表的列表，每个子列表对应一个测试用例，顺序为 A, B, C, D。格式为：$[\\,[\\varepsilon_1,\\text{acc}_1],\\,[\\varepsilon_2,\\text{acc}_2],\\,[\\varepsilon_3,\\text{acc}_3],\\,[\\varepsilon_4,\\text{acc}_4]\\,]$。", "solution": "该问题要求实现一个模拟，以研究差分隐私卷积神经网络中的隐私-效用权衡。该模拟必须比较两种梯度裁剪策略：逐层裁剪和逐核（结构化）裁剪。解决方案涉及几个步骤：数据生成、模型实现、梯度计算、差分隐私机制的应用、训练和隐私核算。\n\n### 1. 问题验证\n解析并验证问题陈述。\n\n*   **给定条件**：明确提供了 $(\\varepsilon, \\delta)$-DP、$\\rho$-zCDP、高斯机制、模型架构（$2$ 个大小为 $3 \\times 3$ 的卷积核、全局平均池化和一个逻辑分类器）、损失函数（二元交叉熵）、分类器部分的梯度公式、裁剪策略、噪声添加规则、隐私核算方法以及 $4$ 个测试用例的具体参数。\n*   **验证**：该问题在深度学习和差分隐私的既定理论中有科学依据。它是一个良构问题，提供了明确的目标和所有必要的组件来构建一个确定性的、可验证的模拟。语言是客观的，设置是自洽的。该任务是对一个简化的 CNN 实现 DP-SGD，虽然不简单但可行，使其成为一个有效且有意义的问题。\n\n### 2. 算法与科学设计\n\n构建一个完整的 Python 程序来满足要求。设计遵循以下关键步骤。\n\n**2.1. 数据生成**\n生成一个包含 $N=400$ 张大小为 $8 \\times 8$ 图像的合成二元分类数据集。\n*   类别 0：图像中心一条 3 像素宽的水平条。\n*   类别 1：图像中心一条 3 像素宽的垂直条。\n*   背景为 $0$，条为 $1$。为了使分类不那么简单，为每个像素添加了均值为 $0$、标准差为 $0.1$ 的独立高斯噪声。数据集被打乱以确保训练期间批次组成的随机性。固定的随机种子确保了所有测试运行的数据集是相同的。\n\n**2.2. 模型架构与前向传播**\n该模型由一个单一卷积层和一个逻辑回归分类器组成。\n*   **卷积层**：它有 $g=2$ 个卷积核，每个大小为 $3 \\times 3$。给定一个 $8 \\times 8$ 的输入图像，一个“有效”卷积（步长为 $1$，无填充）为每个卷积核生成一个 $6 \\times 6$ 的激活图。\n*   **全局平均池化**：对于 $2$ 个激活图中的每一个，其值被平均以产生一个标量特征。这产生了一个 $2$ 维的特征向量 $\\mathbf{h} \\in \\mathbb{R}^2$。\n*   **分类器**：一个 logit $z$ 被计算为 $z = \\mathbf{v}^{\\top}\\mathbf{h} + b$，其中 $\\mathbf{v} \\in \\mathbb{R}^2$ 和 $b \\in \\mathbb{R}$ 是权重和偏置。最终概率通过 sigmoid 函数获得，$p = \\sigma(z) = 1 / (1 + e^{-z})$。\n\n**2.3. 反向传播与梯度计算**\n使用链式法则按规定计算每个样本的梯度。\n*   上游梯度为 $\\frac{\\partial L}{\\partial z} = p - y$，$\\frac{\\partial L}{\\partial \\mathbf{v}} = \\frac{\\partial L}{\\partial z} \\mathbf{h}$，$\\frac{\\partial L}{\\partial b} = \\frac{\\partial L}{\\partial z}$，以及 $\\frac{\\partial L}{\\partial \\mathbf{h}} = \\frac{\\partial L}{\\partial z} \\mathbf{v}$。\n*   推导了关于卷积核 $\\mathbf{W}^{(f)}$ 的梯度。对于一个卷积核 $f$，特征 $h_f$ 是其卷积输出的均值。梯度 $\\frac{\\partial L}{\\partial h_f}$ 均匀分布在卷积输出图上。然后，通过将输入图像与这个均匀的梯度图进行相关运算来计算梯度 $\\frac{\\partial L}{\\partial \\mathbf{W}^{(f)}}$。这个操作使用 `scipy.signal.correlate2d` 高效实现。\n\n**2.4. 差分隐私梯度下降**\n对于每个训练步骤，采样一个批次的数据。首先对卷积核的每样本梯度进行裁剪，然后求平均，最后加噪。\n*   **裁剪策略**：\n    1.  **逐层 (`\"layer\"`)**：将单个样本的所有 $g=2$ 个卷积核的梯度展平为一个向量，并将其 $\\ell_2$ 范数裁剪到最大为 $C$。\n    2.  **逐参数 (`\"param\"`)**：将每个 $g=2$ 个卷积核的梯度视为独立的向量，并独立地将每个向量的 $\\ell_2$ 范数裁剪到最大为 $C$。\n*   **噪声添加**：在大小为 $b$ 的批次上对裁剪后的每样本梯度进行平均后，添加高斯噪声。噪声的标准差为 $\\sigma_{\\text{noise}} = \\frac{\\sigma \\cdot C}{b}$，其中 $\\sigma$ 是噪声乘数。该噪声被添加到卷积核 $\\mathbf{W}$ 的平均梯度中。分类器参数 $\\mathbf{v}$ 和 $b$ 使用未加噪的平均梯度进行更新。\n\n**2.5. 训练与评估**\n模型使用学习率为 $0.5$ 的随机梯度下降法训练指定的步数 $T$。训练后，通过在整个 $N=400$ 张图像的数据集上的分类准确率来衡量模型的效用。\n\n**2.6. 使用 zCDP 进行隐私核算**\n使用零集中差分隐私 (zCDP) 来追踪隐私成本。\n*   每一步的隐私参数 $\\rho_{\\text{step}}$ 取决于裁剪策略。对于逐层裁剪（1个组），$\\rho_{\\text{step}} = \\frac{1}{2\\sigma^2}$。对于逐参数裁剪（$g$ 个组），成本相加，所以 $\\rho_{\\text{step}} = \\frac{g}{2\\sigma^2}$。\n*   经过 $T$ 步的总隐私成本为 $\\rho_{\\text{total}} = T \\cdot \\rho_{\\text{step}}$。\n*   这被转换为最终的 $(\\varepsilon, \\delta)$-DP 保证，使用公式 $\\varepsilon = \\rho_{\\text{total}} + 2\\sqrt{\\rho_{\\text{total}} \\log(1/\\delta)}$。\n\n### 3. 实现与执行\n整个过程被封装在一个单一的 Python 脚本中。一个固定的全局随机种子确保整个模拟是确定性和可复现的。程序遍历提供的四个测试用例，为每个用例重新初始化模型，运行训练和评估，计算相应的 $\\varepsilon$ 和最终准确率，并按规定格式化输出。", "answer": "```python\nimport numpy as np\nfrom scipy.signal import correlate2d\nimport math\n\ndef solve():\n    \"\"\"\n    Implements and runs the DP-CNN simulation for the specified test suite.\n    \"\"\"\n    \n    # 0. Global Parameters and Seed\n    GLOBAL_SEED = 42\n    np.random.seed(GLOBAL_SEED)\n    \n    # Hyperparameters not specified in test cases\n    N = 400\n    IMG_SIZE = 8\n    DATA_NOISE_STD = 0.1\n    LEARNING_RATE = 0.5\n    NUM_FILTERS = 2\n    FILTER_SIZE = 3\n\n    # 1. Data Generation\n    def generate_data(n_samples, img_dim, noise_std):\n        \"\"\"Generates a binary classification dataset of bars.\"\"\"\n        X = np.zeros((n_samples, img_dim, img_dim))\n        y = np.zeros(n_samples, dtype=int)\n        \n        mid_dim = img_dim // 2\n        bar_width = 3  # bar is 3 pixels wide\n        \n        for i in range(n_samples):\n            if i  n_samples // 2:\n                # Class 0: Horizontal bar\n                y[i] = 0\n                X[i, mid_dim - bar_width//2 : mid_dim + bar_width//2 + 1, :] = 1\n            else:\n                # Class 1: Vertical bar\n                y[i] = 1\n                X[i, :, mid_dim - bar_width//2 : mid_dim + bar_width//2 + 1] = 1\n                \n        # Add Gaussian noise\n        X += np.random.normal(0, noise_std, size=X.shape)\n        \n        # Shuffle dataset\n        indices = np.arange(n_samples)\n        np.random.shuffle(indices)\n        \n        return X[indices], y[indices]\n\n    X_train, y_train = generate_data(N, IMG_SIZE, DATA_NOISE_STD)\n\n    # 2. Helper Functions\n    def sigmoid(z):\n        \"\"\"Numerically stable sigmoid function.\"\"\"\n        return 1.0 / (1.0 + np.exp(-z))\n        \n    # 3. Model Gradient Logic\n    def compute_per_sample_gradients(x_i, y_i, W, v, b_param):\n        \"\"\"Computes gradients for a single sample.\"\"\"\n        g, k, _ = W.shape # g=num_filters, k=filter_size\n        img_h, img_w = x_i.shape\n        \n        # --- Forward pass for one sample ---\n        h = np.zeros(g)\n        conv_outputs = np.zeros((g, img_h - k + 1, img_w - k + 1))\n        for f_idx in range(g):\n            # correlate2d is used as it matches the gradient definition of convolution\n            conv_outputs[f_idx] = correlate2d(x_i, W[f_idx], mode='valid')\n            h[f_idx] = np.mean(conv_outputs[f_idx])\n            \n        z = v.T @ h + b_param\n        p = sigmoid(z)\n        \n        # --- Backward pass for one sample ---\n        dL_dz = p - y_i\n        grad_v = dL_dz * h\n        grad_b = dL_dz\n        dL_dh = dL_dz * v\n        \n        grad_W = np.zeros_like(W)\n        conv_out_h, conv_out_w = conv_outputs[0].shape\n        num_conv_out_pixels = conv_out_h * conv_out_w\n        \n        for f_idx in range(g):\n            dL_dh_f = dL_dh[f_idx]\n            grad_kernel = np.full((conv_out_h, conv_out_w), dL_dh_f / num_conv_out_pixels)\n            grad_W[f_idx] = correlate2d(x_i, grad_kernel, mode='valid')\n            \n        return grad_W, grad_v, grad_b\n\n    # 4. Privacy Accountant\n    def calculate_epsilon(mode, sigma, T, delta, g):\n        \"\"\"Calculates epsilon using the zCDP to (epsilon, delta)-DP conversion.\"\"\"\n        if mode == \"layer\":\n            rho_step = 1.0 / (2.0 * sigma**2)\n        elif mode == \"param\":\n            rho_step = g / (2.0 * sigma**2)\n        else:\n            raise ValueError(f\"Invalid clipping mode: {mode}\")\n            \n        rho_total = T * rho_step\n        if rho_total = 0: return 0.0\n        epsilon = rho_total + 2.0 * math.sqrt(rho_total * math.log(1.0 / delta))\n        return epsilon\n\n    # 5. Main Simulation\n    test_cases = [\n        (\"layer\", 1.0, 1.0, 16, 100, 1e-5),\n        (\"param\", 1.0, 1.0, 16, 100, 1e-5),\n        (\"param\", 1.0, 2.0, 16, 100, 1e-5),\n        (\"layer\", 0.1, 3.0, 1, 50, 1e-5)\n    ]\n    \n    results = []\n    \n    for case_idx, (mode, C, sigma, b, T, delta) in enumerate(test_cases):\n        # Re-initialize model parameters for each test case for fair comparison\n        # The sequence of initializations is deterministic due to the global seed.\n        W = np.random.normal(0, 0.1, (NUM_FILTERS, FILTER_SIZE, FILTER_SIZE))\n        v = np.random.normal(0, 0.1, (NUM_FILTERS,))\n        b_param = np.random.normal(0, 0.1)\n        \n        # Training loop\n        for _ in range(T):\n            batch_indices = np.random.choice(N, size=b, replace=True)\n            X_batch, y_batch = X_train[batch_indices], y_train[batch_indices]\n            \n            sum_clipped_grad_W = np.zeros_like(W)\n            sum_grad_v = np.zeros_like(v)\n            sum_grad_b = 0.0\n            \n            for i in range(b):\n                x_i, y_i = X_batch[i], y_batch[i]\n                grad_W_i, grad_v_i, grad_b_i = compute_per_sample_gradients(x_i, y_i, W, v, b_param)\n                \n                # Clipping logic for convolutional filter gradients\n                if mode == \"layer\":\n                    norm = np.linalg.norm(grad_W_i)\n                    scale = min(1.0, C / (norm + 1e-9))\n                    clipped_grad_W_i = grad_W_i * scale\n                elif mode == \"param\":\n                    clipped_grad_W_i = np.zeros_like(grad_W_i)\n                    for f_idx in range(NUM_FILTERS):\n                        grad_W_f = grad_W_i[f_idx]\n                        norm = np.linalg.norm(grad_W_f)\n                        scale = min(1.0, C / (norm + 1e-9))\n                        clipped_grad_W_i[f_idx] = grad_W_f * scale\n                \n                sum_clipped_grad_W += clipped_grad_W_i\n                sum_grad_v += grad_v_i\n                sum_grad_b += grad_b_i\n\n            avg_grad_W = sum_clipped_grad_W / b\n            avg_grad_v = sum_grad_v / b\n            avg_grad_b = sum_grad_b / b\n            \n            noise_std = sigma * C / b\n            noise = np.random.normal(0, noise_std, size=W.shape)\n            noisy_grad_W = avg_grad_W + noise\n            \n            W -= LEARNING_RATE * noisy_grad_W\n            v -= LEARNING_RATE * avg_grad_v\n            b_param -= LEARNING_RATE * avg_grad_b\n\n        # Evaluation\n        correct_predictions = 0\n        for i in range(N):\n            h = np.zeros(NUM_FILTERS)\n            for f_idx in range(NUM_FILTERS):\n                h[f_idx] = np.mean(correlate2d(X_train[i], W[f_idx], mode='valid'))\n            z = v.T @ h + b_param\n            p = sigmoid(z)\n            prediction = 1 if p >= 0.5 else 0\n            if prediction == y_train[i]:\n                correct_predictions += 1\n        \n        accuracy = correct_predictions / N\n        \n        # Privacy calculation\n        epsilon = calculate_epsilon(mode, sigma, T, delta, g=NUM_FILTERS)\n        \n        results.append([round(epsilon, 4), round(accuracy, 4)])\n        \n    # Final output\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3165699"}, {"introduction": "在实现了一个差分隐私算法后，我们如何确信代码没有错误，并且真正提供了所声称的隐私保障？仅仅有理论证明是不够的，实证检验至关重要。本练习 [@problem_id:3165736] 介绍了差分隐私审计的概念，你将通过模拟一次成员推断攻击来度量一个机制的经验隐私损失。通过将这一经验结果与从 $\\epsilon$ 推导出的理论上限进行比较，你将学会如何构建一个统计测试来检测实现中的缺陷，从而增强对你所构建的隐私系统的信心。", "problem": "你的任务是在一个程式化的成员推断场景中，实现对一个差分隐私机制的定量审计。该审计应将经验攻击成功率与仅由隐私会计参数 $ \\epsilon $ 所隐含的、理论上合理的上界进行比较，并判断是否存在可检测的差异，该差异表明可能存在实现错误。\n\n从以下基本基础开始：\n\n- 一个随机化机制 $ M $ 满足 $(\\epsilon, 0)$-差分隐私（DP），如果对于所有相邻数据集 $ D $ 和 $ D' $（相差一个个体）以及所有可测事件 $ S $，都有 $ \\mathbb{P}(M(D) \\in S) \\leq e^{\\epsilon} \\, \\mathbb{P}(M(D') \\in S) $。\n- 在等先验概率下，最优成员推断攻击者是使误差最小化的贝叶斯最优检验，该检验由似然比检验给出，其成功概率为 $ \\frac{1 + \\mathrm{TV}(P, Q)}{2} $，其中 $ \\mathrm{TV}(P, Q) $ 是两个输出分布 $ P $ 和 $ Q $ 之间的全变差距离。\n- 对一个全局敏感度为 $ 1 $ 的查询添加噪声 $ \\eta \\sim \\mathrm{Laplace}(0, b) $ 的拉普拉斯机制，通过 $ \\epsilon = \\frac{1}{b} $ 实现 $(\\epsilon, 0)$-DP。\n\n你的程序必须实现以下审计流程：\n\n1. 对于一个固定的整数计数 $ c_{\\mathrm{in}} $ 及其相邻计数 $ c_{\\mathrm{out}} = c_{\\mathrm{in}} - 1 $，定义一个机制，该机制发布 $ Y = c + \\eta $，其中如果个体在数据集中，则 $ c $ 等于 $ c_{\\mathrm{in}} $，否则等于 $ c_{\\mathrm{out}} $。噪声 $ \\eta $ 从一个拉普拉斯分布中抽取，其尺度为 $ b = \\frac{\\mathrm{factor}}{\\epsilon} $，其中 $ \\epsilon $ 是隐私会计参数，$\\mathrm{factor}$ 是一个乘法实现因子。正确的实现应有 $ \\mathrm{factor} = 1 $，而偏差则模拟了潜在的实现错误。\n\n2. 为了估计经验攻击成功率，模拟 $ N $ 次独立的试验，成员身份的先验概率为 $ \\frac{1}{2} $。在每次试验中，抽取一个概率为 $ \\frac{1}{2} $ 的伯努利变量来决定输出是来自“在”（in）分布 $ \\mathrm{Laplace}(c_{\\mathrm{in}}, b) $ 还是“不在”（out）分布 $ \\mathrm{Laplace}(c_{\\mathrm{out}}, b) $。使用专门针对这对分布的贝叶斯最优决策规则：如果 $ Y \\geq \\frac{c_{\\mathrm{in}} + c_{\\mathrm{out}}}{2} $，则判定为“在”，否则判定为“不在”。经验成功率是在 $ N $ 次试验中正确决策的比例。\n\n3. 从 $(\\epsilon, 0)$-DP 定义中，推导出一个关于等先验概率下贝叶斯最优成功概率的严格上界，该上界仅是 $ \\epsilon $ 的函数，不涉及机制的内部细节。将此界用作“会计预测”的上限。\n\n4. 为避免因采样变异性导致的假阳性，使用针对伯努利试验的霍夫丁不等式计算一个非渐近容差。对于用户指定的置信度参数 $ \\alpha \\in (0, 1) $，经验成功率 $ \\hat{p} $ 与真实成功概率 $ p $ 的偏差最多为\n$$\n\\tau = \\sqrt{\\frac{\\ln\\left(\\frac{2}{\\alpha}\\right)}{2 N}}\n$$\n的概率至少为 $ 1 - \\alpha $。如果 $ \\hat{p} - \\tau $ 严格超过会计预测的上界，则标记为存在差异。\n\n你的程序必须为以下测试套件实现上述审计，每个测试用例指定为一个元组 $ (\\epsilon, \\mathrm{factor}, N, \\alpha, \\mathrm{seed}) $：\n\n- 测试 $ 1 $: $ (\\epsilon = 1.0, \\mathrm{factor} = 1.0, N = 100000, \\alpha = 10^{-6}, \\mathrm{seed} = 42) $。\n- 测试 $ 2 $: $ (\\epsilon = 1.0, \\mathrm{factor} = 0.5, N = 50000, \\alpha = 10^{-4}, \\mathrm{seed} = 7) $。\n- 测试 $ 3 $: $ (\\epsilon = 0.001, \\mathrm{factor} = 1.0, N = 200000, \\alpha = 10^{-6}, \\mathrm{seed} = 2023) $。\n- 测试 $ 4 $: $ (\\epsilon = 5.0, \\mathrm{factor} = 1.0, N = 50000, \\alpha = 10^{-6}, \\mathrm{seed} = 123456) $。\n- 测试 $ 5 $: $ (\\epsilon = 1.0, \\mathrm{factor} = 0.8, N = 500, \\alpha = 0.05, \\mathrm{seed} = 99) $。\n\n实现细节：\n\n- 使用固定的整数 $ c_{\\mathrm{in}} = 10 $ 并设置 $ c_{\\mathrm{out}} = 9 $。中点决策阈值为 $ \\frac{c_{\\mathrm{in}} + c_{\\mathrm{out}}}{2} = 9.5 $。\n- 使用提供的随机种子以确保可复现性。\n\n最终输出规范：\n\n- 对于每个测试用例，输出一个布尔值，指示是否检测到差异。\n- 你的程序应生成一行输出，其中包含一个用方括号括起来的、逗号分隔的结果列表，例如 $ [\\mathrm{result}_1,\\mathrm{result}_2,\\mathrm{result}_3,\\mathrm{result}_4,\\mathrm{result}_5] $，其中每个 $ \\mathrm{result}_i $ 为 $ \\mathrm{True} $ 或 $ \\mathrm{False} $。", "solution": "该任务是实现对一个差分隐私机制的定量审计。审计过程将经验测量的攻击成功率与从隐私参数 $\\epsilon$ 推导出的理论上界进行比较。如果经验成功率在统计上显著高于理论上界，则标记为存在差异，这表明可能存在实现错误。该过程涉及三个主要步骤：推导理论上界、模拟攻击以获得经验成功率，以及应用统计检验来做出决策。\n\n### 1. 从差分隐私推导的理论上界\n\n一个机制 $M$ 提供 $(\\epsilon, 0)$-差分隐私（DP），如果对于任何两个相邻数据集 $D$ 和 $D'$ 以及任何事件 $S$，输出分布 $P=M(D)$ 和 $Q=M(D')$ 满足 $\\mathbb{P}(P \\in S) \\leq e^{\\epsilon} \\mathbb{P}(Q \\in S)$。\n\n问题指出，在等先验概率下，最优成员推断攻击者的成功概率为 $p_{succ} = \\frac{1 + \\mathrm{TV}(P, Q)}{2}$，其中 $\\mathrm{TV}(P, Q)$ 是输出分布之间的全变差距离。为了找到“会计预测”的上界，我们必须在 $(\\epsilon, 0)$-DP 约束下，找到 $\\mathrm{TV}(P, Q)$ 的最大可能值，而无需考虑具体机制。\n\n在差分隐私中，一个标准结论是，对于任何满足 $(\\epsilon, 0)$-DP 条件的两个分布 $P$ 和 $Q$，它们的全变差距离有界：\n$$\n\\mathrm{TV}(P, Q) \\leq \\frac{e^\\epsilon - 1}{e^\\epsilon + 1}\n$$\n这个界是紧的；存在一对满足 $(\\epsilon, 0)$-DP 的分布，可以达到这个最大的全变差距离。\n\n将这个最大可能的全变差距离代入攻击者成功概率的公式，就得到了理论上界，我们将其表示为 $p_{bound}$：\n$$\np_{succ} \\leq \\frac{1}{2} \\left( 1 + \\frac{e^\\epsilon - 1}{e^\\epsilon + 1} \\right)\n$$\n简化这个表达式，得到会计预测的成功概率上界：\n$$\np_{bound} = \\frac{1}{2} \\left( \\frac{e^\\epsilon + 1 + e^\\epsilon - 1}{e^\\epsilon + 1} \\right) = \\frac{1}{2} \\left( \\frac{2e^\\epsilon}{e^\\epsilon + 1} \\right) = \\frac{e^\\epsilon}{e^\\epsilon + 1}\n$$\n这个界仅取决于声明的隐私参数 $\\epsilon$。\n\n### 2. 经验攻击成功率模拟\n\n审计通过模拟一个特定的成员推断攻击来估计机制的真实攻击成功概率。\n- 机制从拉普拉斯分布中添加噪声，$Y = c + \\eta$，其中 $\\eta \\sim \\mathrm{Laplace}(0, b)$。\n- 尺度参数为 $b = \\frac{\\mathrm{factor}}{\\epsilon}$。对于全局敏感度为 $1$ 的查询，正确的实现应有 $\\mathrm{factor}=1$。全局敏感度为 $\\Delta c = |c_{\\mathrm{in}} - c_{\\mathrm{out}}| = |10 - 9| = 1$。\n- 考虑两个分布：$P_{in}$ 对应于 $c=c_{\\mathrm{in}}=10$，因此 $Y \\sim \\mathrm{Laplace}(10, b)$；$P_{out}$ 对应于 $c=c_{\\mathrm{out}}=9$，因此 $Y \\sim \\mathrm{Laplace}(9, b)$。\n- 对于区分这两个具有等先验概率的对称分布，贝叶斯最优决策规则是比较似然，这简化为检查输出 $Y$ 更接近哪个均值。决策边界是中点 $T = \\frac{c_{\\mathrm{in}} + c_{\\mathrm{out}}}{2} = 9.5$。规则是：如果 $Y \\geq 9.5$，则判定为“在”，否则判定为“不在”。\n\n模拟运行 $N$ 次试验。在每次试验中：\n1. 以 $\\frac{1}{2}$ 的概率选择一个真实状态（“在”或“不在”）。\n2. 从相应的分布 $\\mathrm{Laplace}(c_{\\mathrm{in}}, b)$ 或 $\\mathrm{Laplace}(c_{\\mathrm{out}}, b)$ 生成一个带噪声的输出 $Y$。\n3. 将决策规则应用于 $Y$。\n4. 将决策与真实状态进行比较，检查是否正确。\n\n经验成功率 $\\hat{p}$ 是正确决策的总数除以总试验次数 $N$。这个 $\\hat{p}$ 是针对此特定机制上的特定攻击的真实成功概率 $p_{true}$ 的一个估计。\n\n为完整起见，$p_{true}$ 的解析值可以从中点分类器在两个拉普拉斯分布上的成功概率推导出来。正确决策的概率是 $p_{true} = \\frac{1}{2} \\mathbb{P}(\\text{正确} | \\text{在}) + \\frac{1}{2} \\mathbb{P}(\\text{正确} | \\text{不在})$。根据对称性，这两个条件概率相等：$\\mathbb{P}(Y \\geq T | Y \\sim \\mathrm{Laplace}(c_{\\mathrm{in}}, b)) = \\mathbb{P}(Y  T | Y \\sim \\mathrm{Laplace}(c_{\\mathrm{out}}, b))$。使用拉普拉斯分布的累积分布函数（CDF），这个概率是 $1 - \\frac{1}{2} \\exp\\left(-\\frac{c_{\\mathrm{in}}-T}{b}\\right)$。这导致：\n$$\np_{true} = 1 - \\frac{1}{2} \\exp\\left(-\\frac{\\Delta c}{2b}\\right) = 1 - \\frac{1}{2} \\exp\\left(-\\frac{\\epsilon}{2 \\cdot \\mathrm{factor}}\\right)\n$$\n\n### 3. 用于差异检测的统计检验\n\n经验成功率 $\\hat{p}$ 是一个随机变量。为了考虑采样可变性并避免误报，我们使用霍夫丁不等式。对于具有真实概率 $p$ 的 $N$ 次伯努利试验，经验估计值 $\\hat{p}$ 与 $p$ 的偏差至多为一个容差 $\\tau$ 的概率很高：\n$$\n\\mathbb{P}(|\\hat{p} - p| \\geq \\tau) \\leq 2e^{-2N\\tau^2}\n$$\n将右侧设为一个小的置信度参数 $\\alpha$，我们可以解出单侧容差 $\\tau$：\n$$\n\\alpha = 2e^{-2N\\tau^2} \\implies \\frac{\\alpha}{2} = e^{-2N\\tau^2} \\implies \\ln\\left(\\frac{2}{\\alpha}\\right) = 2N\\tau^2 \\implies \\tau = \\sqrt{\\frac{\\ln\\left(\\frac{2}{\\alpha}\\right)}{2 N}}\n$$\n以至少 $1-\\alpha$ 的概率，真实成功率 $p_{true}$ 不会超过 $\\hat{p}+\\tau$。如果实现有缺陷，导致隐私性降低（例如 $\\mathrm{factor}  1$），$p_{true}$ 可能会超过会计的上界 $p_{bound}$。如果我们有强有力的统计证据表明 $p_{true} > p_{bound}$，我们就标记为存在差异。当我们的 $p_{true}$ 置信区间的下界，即 $\\hat{p} - \\tau$，严格大于理论最大值 $p_{bound}$ 时，这一条件成立。\n\n最终的审计条件是，当且仅当以下情况成立时，标记为存在差异：\n$$\n\\hat{p} - \\tau > p_{bound}\n$$\n\n### 审计算法摘要\n对于每个测试用例 $(\\epsilon, \\mathrm{factor}, N, \\alpha, \\mathrm{seed})$：\n1.  计算拉普拉斯尺度参数 $b = \\frac{\\mathrm{factor}}{\\epsilon}$。\n2.  使用给定的 `seed` 设置一个随机数生成器。\n3.  模拟 $N$ 次成员推断攻击试验，以计算经验成功率 $\\hat{p}$。\n4.  计算会计预测的上界：$p_{bound} = \\frac{e^\\epsilon}{e^\\epsilon + 1}$。\n5.  计算统计容差：$\\tau = \\sqrt{\\frac{\\ln(2/\\alpha)}{2N}}$。\n6.  将 $\\hat{p} - \\tau$ 与 $p_{bound}$ 进行比较。如果 $\\hat{p} - \\tau > p_{bound}$，则检测到差异（True）。否则，未检测到差异（False）。\n7.  收集所有测试用例的布尔结果。", "answer": "```python\nimport numpy as np\n\ndef run_audit(epsilon, factor, N, alpha, seed):\n    \"\"\"\n    对一个差分隐私机制执行定量审计。\n\n    Args:\n        epsilon (float): 声明的隐私参数 epsilon。\n        factor (float): 用于拉普拉斯尺度的实现因子。\n        N (int): 模拟试验的次数。\n        alpha (float): 霍夫丁不等式的置信度参数。\n        seed (int): 用于可复现性的随机种子。\n\n    Returns:\n        bool: 如果检测到差异则为 True，否则为 False。\n    \"\"\"\n    # Initialize random number generator for reproducibility\n    rng = np.random.default_rng(seed)\n\n    # --- Step 1: Mechanism and Attack Setup ---\n    c_in = 10.0\n    c_out = 9.0\n    decision_threshold = (c_in + c_out) / 2.0\n    \n    # The global sensitivity of the count query is |c_in - c_out| = 1.\n    # The Laplace scale b should be GS/epsilon = 1/epsilon for a correct implementation.\n    # A 'factor' is introduced to model implementation errors.\n    if epsilon == 0:\n        # Avoid division by zero, although not in test cases.\n        # Infinite noise means output is always 0, attack success is 0.5.\n        b = float('inf')\n    else:\n        b = factor / epsilon\n\n    # --- Step 2: Estimate Empirical Attack Success Rate ---\n    correct_decisions = 0\n    \n    # Generate all random choices at once for efficiency\n    true_labels_are_in = rng.random(size=N) > 0.5\n    \n    # Generate Laplace noise for both 'in' and 'out' cases\n    # Note: np.random.laplace takes scale parameter b\n    laplace_noise = rng.laplace(loc=0.0, scale=b, size=N)\n\n    # Calculate noisy outputs\n    outputs_in = c_in + laplace_noise\n    outputs_out = c_out + laplace_noise\n    \n    # Combine outputs based on true labels\n    Y = np.where(true_labels_are_in, outputs_in, outputs_out)\n    \n    # Apply the Bayes-optimal decision rule\n    decisions_are_in = Y >= decision_threshold\n    \n    # Count correct decisions\n    correct_decisions = np.sum(decisions_are_in == true_labels_are_in)\n\n    # Empirical success rate\n    p_hat = correct_decisions / N\n\n    # --- Step 3: Theoretical Bound ---\n    # The upper bound on success probability is derived from the TV-distance bound of (eps, 0)-DP\n    # p_bound = (1 + (e^eps - 1)/(e^eps + 1)) / 2 = e^eps / (e^eps + 1)\n    if epsilon >= 700: # Avoid overflow for np.exp\n        p_bound = 1.0\n    else:\n        p_bound = np.exp(epsilon) / (np.exp(epsilon) + 1.0)\n\n    # --- Step 4: Statistical Test ---\n    # Calculate the tolerance tau using Hoeffding's inequality\n    tau = np.sqrt(np.log(2.0 / alpha) / (2.0 * N))\n    \n    # A discrepancy is flagged if the empirical rate, adjusted for sampling error,\n    # is strictly greater than the theoretical bound.\n    discrepancy_detected = (p_hat - tau) > p_bound\n\n    return discrepancy_detected\n\ndef solve():\n    \"\"\"\n    通过对每个测试用例运行审计来解决问题。\n    \"\"\"\n    test_cases = [\n        # (epsilon, factor, N, alpha, seed)\n        (1.0, 1.0, 100000, 1e-6, 42),\n        (1.0, 0.5, 50000, 1e-4, 7),\n        (0.001, 1.0, 200000, 1e-6, 2023),\n        (5.0, 1.0, 50000, 1e-6, 123456),\n        (1.0, 0.8, 500, 0.05, 99)\n    ]\n\n    results = []\n    for case in test_cases:\n        epsilon, factor, N, alpha, seed = case\n        result = run_audit(epsilon, factor, N, alpha, seed)\n        results.append(str(result))\n\n    # 以所需格式打印最终输出\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n\n```", "id": "3165736"}]}