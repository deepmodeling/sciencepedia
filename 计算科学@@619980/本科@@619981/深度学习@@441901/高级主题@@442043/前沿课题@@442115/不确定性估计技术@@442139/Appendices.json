{"hands_on_practices": [{"introduction": "要真正理解不确定性，我们首先要学习如何从模型内部表示的不确定性中推导出最终的预测结果。本练习将引导你完成一个基础但至关重要的推导过程：当分类器的对数几率（logits）本身不是一个确定的值，而是服从一个概率分布时，我们如何计算最终的类别概率。通过这个练习 ([@problem_id:3179687])，你将亲手实践如何处理这种由模型直接输出的偶然不确定性（aleatoric uncertainty），并将其转化为一个有意义的、经过校准的预测概率。", "problem": "考虑一个二元深度神经网络分类器，对于一个特定输入 $x^{\\star}$，它输出每个类别的logit均值和异方差logit方差。将类别 $c \\in \\{0, 1\\}$ 的潜logit表示为 $z_{c}$，其中 $z_{c}$ 被建模为均值为 $\\mu_{c}$、方差为 $\\sigma_{c}^{2}$ 的高斯随机变量，即 $z_{c} \\sim \\mathcal{N}(\\mu_{c}, \\sigma_{c}^{2})$。假设潜logit在不同类别之间是独立的。预测决策规则是选择具有最大潜logit的类别。因此，类别1的预测概率是在 $(z_{0}, z_{1})$ 的联合分布下事件 $z_{1} > z_{0}$ 发生的概率。\n\n从独立高斯随机变量和高斯分布的概率密度函数（PDF）的定义出发，推导差值 $d = z_{1} - z_{0}$ 的分布，将预测概率 $p(y = 1 \\mid x^{\\star})$ 表示为在适当区域上的积分，并利用高斯分布的性质以闭式形式求值。\n\n最后，对于模型输出为 $\\mu_{1} = 1.3$，$\\mu_{0} = 0.6$，$\\sigma_{1} = 0.3$ 和 $\\sigma_{0} = 0.4$ 的 $x^{\\star}$，计算 $p(y = 1 \\mid x^{\\star})$ 的数值。将你的数值答案四舍五入到四位有效数字。将最终答案表示为不带任何单位的纯数字。", "solution": "问题陈述经过严格验证，被认定为有效。它在科学上植根于应用于深度学习不确定性估计的概率论和统计学，是适定的，具有唯一且稳定的解，并以客观、明确的语言表达。求解所需的所有数据和条件均已提供。\n\n该问题要求我们分析一个二元分类器的预测概率，其潜logit $z_0$ 和 $z_1$ 被建模为独立的高斯随机变量。我们已知：\n$z_1 \\sim \\mathcal{N}(\\mu_1, \\sigma_1^2)$\n$z_0 \\sim \\mathcal{N}(\\mu_0, \\sigma_0^2)$\n这两个随机变量 $z_1$ 和 $z_0$ 是独立的。类别1的预测概率由 $p(y = 1 \\mid x^{\\star}) = P(z_1 > z_0)$ 给出。\n\n首先，我们推导差值 $d = z_1 - z_0$ 的分布。高斯分布的一个基本性质指出，独立高斯随机变量的线性组合也是一个高斯随机变量。差值 $d$ 是 $z_1$ 和 $z_0$ 的线性组合，其系数分别为 $1$ 和 $-1$。\n\n$d$ 的均值，记为 $\\mu_d$，是差值的期望：\n$$\n\\mu_d = E[d] = E[z_1 - z_0] = E[z_1] - E[z_0] = \\mu_1 - \\mu_0\n$$\n$d$ 的方差，记为 $\\sigma_d^2$，是差值的方差。由于 $z_1$ 和 $z_0$ 的独立性，和（或差）的方差等于方差之和：\n$$\n\\sigma_d^2 = \\text{Var}(d) = \\text{Var}(z_1 - z_0) = \\text{Var}(z_1) + \\text{Var}(-1 \\cdot z_0) = \\text{Var}(z_1) + (-1)^2 \\text{Var}(z_0) = \\sigma_1^2 + \\sigma_0^2\n$$\n因此，差值 $d$ 的分布是一个均值为 $\\mu_1 - \\mu_0$、方差为 $\\sigma_1^2 + \\sigma_0^2$ 的高斯分布：\n$$\nd \\sim \\mathcal{N}(\\mu_1 - \\mu_0, \\sigma_1^2 + \\sigma_0^2)\n$$\n$d$ 的概率密度函数（PDF）由下式给出：\n$$\nf_d(x) = \\frac{1}{\\sqrt{2\\pi(\\sigma_1^2 + \\sigma_0^2)}} \\exp\\left(-\\frac{(x - (\\mu_1 - \\mu_0))^2}{2(\\sigma_1^2 + \\sigma_0^2)}\\right)\n$$\n\n接下来，我们将预测概率 $p(y = 1 \\mid x^{\\star})$ 表示为一个积分。事件 $z_1 > z_0$ 等价于事件 $z_1 - z_0 > 0$，即 $d > 0$。该事件的概率是 $d$ 的PDF在区域 $x > 0$ 上的积分：\n$$\np(y = 1 \\mid x^{\\star}) = P(d > 0) = \\int_{0}^{\\infty} f_d(x) \\,dx\n$$\n代入 $f_d(x)$ 的表达式：\n$$\np(y = 1 \\mid x^{\\star}) = \\int_{0}^{\\infty} \\frac{1}{\\sqrt{2\\pi(\\sigma_1^2 + \\sigma_0^2)}} \\exp\\left(-\\frac{(x - (\\mu_1 - \\mu_0))^2}{2(\\sigma_1^2 + \\sigma_0^2)}\\right) \\,dx\n$$\n\n为了以闭式形式计算该积分，我们进行变量替换以使分布标准化。令 $\\mu_d = \\mu_1 - \\mu_0$ 和 $\\sigma_d = \\sqrt{\\sigma_1^2 + \\sigma_0^2}$。我们引入一个新变量 $u = \\frac{x - \\mu_d}{\\sigma_d}$。这是一个标准正态变量，$u \\sim \\mathcal{N}(0, 1)$。其微分为 $du = \\frac{1}{\\sigma_d}dx$，因此 $dx = \\sigma_d du$。积分限也必须进行变换：\n- 当 $x = 0$ 时，下限变为 $u = \\frac{0 - \\mu_d}{\\sigma_d} = -\\frac{\\mu_d}{\\sigma_d}$。\n- 当 $x \\to \\infty$ 时，上限变为 $u \\to \\infty$。\n\n将这些代入积分中得到：\n$$\np(y = 1 \\mid x^{\\star}) = \\int_{-\\mu_d/\\sigma_d}^{\\infty} \\frac{1}{\\sqrt{2\\pi}\\sigma_d} \\exp\\left(-\\frac{u^2}{2}\\right) (\\sigma_d \\,du) = \\int_{-\\mu_d/\\sigma_d}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{u^2}{2}\\right) \\,du\n$$\n这个积分是在 $-\\mu_d/\\sigma_d$ 处求值的标准正态分布的生存函数的定义。它等价于 $1 - \\Phi(-\\mu_d/\\sigma_d)$，其中 $\\Phi(z)$ 是标准正态分布的累积分布函数（CDF），对于 $Z \\sim \\mathcal{N}(0, 1)$，有 $\\Phi(z) = P(Z \\le z)$。利用标准正态分布的对称性质 $\\Phi(-z) = 1 - \\Phi(z)$，我们有：\n$$\nP(d > 0) = 1 - \\Phi(-\\mu_d/\\sigma_d) = 1 - (1 - \\Phi(\\mu_d/\\sigma_d)) = \\Phi(\\mu_d/\\sigma_d)\n$$\n将 $\\mu_d$ 和 $\\sigma_d$ 的表达式代回，预测概率的闭式表达式为：\n$$\np(y = 1 \\mid x^{\\star}) = \\Phi\\left(\\frac{\\mu_1 - \\mu_0}{\\sqrt{\\sigma_1^2 + \\sigma_0^2}}\\right)\n$$\n\n最后，我们为给定的模型输出计算数值：$\\mu_1 = 1.3$，$\\mu_0 = 0.6$，$\\sigma_1 = 0.3$ 和 $\\sigma_0 = 0.4$。\n首先，我们计算 $\\Phi$ 函数的自变量：\n均值之差为 $\\mu_1 - \\mu_0 = 1.3 - 0.6 = 0.7$。\n方差之和为 $\\sigma_1^2 + \\sigma_0^2 = (0.3)^2 + (0.4)^2 = 0.09 + 0.16 = 0.25$。\n差值的标准差为 $\\sqrt{\\sigma_1^2 + \\sigma_0^2} = \\sqrt{0.25} = 0.5$。\n因此，自变量为：\n$$\n\\frac{\\mu_1 - \\mu_0}{\\sqrt{\\sigma_1^2 + \\sigma_0^2}} = \\frac{0.7}{0.5} = 1.4\n$$\n因此，预测概率为：\n$$\np(y = 1 \\mid x^{\\star}) = \\Phi(1.4)\n$$\n使用标准正态分布表或计算工具，我们找到CDF在 $z = 1.4$ 处的值：\n$$\n\\Phi(1.4) \\approx 0.91924334\n$$\n将此值四舍五入到四位有效数字，得到 $0.9192$。", "answer": "$$\n\\boxed{0.9192}\n$$", "id": "3179687"}, {"introduction": "深度学习模型输出的原始概率值往往过于自信或自信不足，即所谓的“校准不良”。一个经过良好校准的模型，其预测的置信度应能真实反映其预测的准确性。本练习 ([@problem_id:3179715]) 提供了一个非常实用的编程任务，让你通过实现经典的后处理校准技术（Platt scaling）来改善模型的置信度输出，并学习使用如预期校准误差（Expected Calibration Error, ECE）和预测熵等关键指标来量化模型的预测不确定性和校准水平。", "problem": "给定一个二元分类场景，其中模型输出为 sigmoid 函数应用前的得分（logits）。目标是通过校准和熵来研究不确定性估计，具体方法是比较原始预测、在 logit 空间中的线性事后校准以及在概率空间中的线性事后校准。构建一个程序，实现以下计算，并针对提供的测试套件输出指定的量。\n\n定义和基础知识：\n- 一个二元分类器为每个输入输出一个实值 logit $z \\in \\mathbb{R}$。正类的预测概率为 $p = \\sigma(z)$，其中 $\\sigma(z) = \\frac{1}{1 + e^{-z}}$ 是 logistic sigmoid 函数。\n- 参数为 $p$ 的伯努利分布的预测熵为 $H(p) = - \\left( p \\ln p + (1 - p) \\ln(1 - p) \\right)$，使用自然对数。\n- 对于给定的概率 $p$ 和二元标签 $y \\in \\{0,1\\}$，负对数似然（NLL）为 $\\mathrm{NLL}(p,y) = - \\left( y \\ln p + (1 - y) \\ln(1 - p) \\right)$。数据集上的平均 NLL 是每个样本 NLL 的算术平均值。最小化平均 NLL 是拟合校准参数的一个公认原则，因为它对应于伯努利模型下的最大似然估计。\n- 期望校准误差（ECE）通过将预测置信度分箱，并比较箱内的平均准确率与箱内的平均置信度来评估校准程度。对于二元分类，定义预测 $\\hat{y} = \\mathbb{I}[p \\geq 0.5]$ 和置信度 $c = \\max(p, 1 - p)$。将置信度区间 $[0,1]$ 划分为 $B$ 个等宽的箱。对于箱 $b$，令 $n_b$ 为该箱中的样本数，$\\mathrm{acc}_b$ 为该箱中样本的 $\\mathbb{I}[\\hat{y} = y]$ 的平均值，$\\mathrm{conf}_b$ 为该箱中样本的 $c$ 的平均值。期望校准误差为\n$$\n\\mathrm{ECE} = \\sum_{b=1}^{B} \\frac{n_b}{N} \\left| \\mathrm{acc}_b - \\mathrm{conf}_b \\right|,\n$$\n其中 $N$ 是数据集大小。空箱从求和中省略。\n\n要比较的校准映射：\n- Logit空间线性事后校准（普拉特缩放 Platt scaling）：给定 logits $z$，用参数 $a \\in \\mathbb{R}$ 和 $b \\in \\mathbb{R}$ 进行变换 $z' = a z + b$。校准后的概率为 $p' = \\sigma(z')$。通过在给定数据集上最小化平均 NLL 来拟合 $(a,b)$。\n- 概率空间线性事后校准：给定原始概率 $p = \\sigma(z)$，使用保持单位区间的单调线性映射进行变换 $p'' = c p + d$。通过无约束的 $u,v \\in \\mathbb{R}$ 将参数参数化为 $d = \\sigma(u)$ 和 $c = (1 - d)\\, \\sigma(v)$，以确保对于所有 $p \\in [0,1]$ 都有 $p'' \\in (0,1)$。通过在给定数据集上最小化平均 NLL 来拟合 $(u,v)$，并通过隐含的 $(c,d)$ 计算 $p''$。\n\n每个数据集的任务：\n1. 计算原始概率 $p = \\sigma(z)$。\n2. 拟合 $(a,b)$ 并计算校准后的概率 $p' = \\sigma(a z + b)$。\n3. 拟合 $(u,v)$，构成 $(c,d)$，并计算校准后的概率 $p'' = c p + d$。\n4. 使用在 $[0,1]$ 上的 $B = 10$ 个等宽箱，计算 $p$、$p'$ 和 $p''$ 的 $\\mathrm{ECE}$。\n5. 使用上面定义的 $H(p)$，计算 $p$、$p'$ 和 $p''$ 的平均预测熵 $\\overline{H}$。\n\n您的程序必须使用下面的测试套件实现这些步骤，并为每个数据集生成一个包含六个浮点数的列表，顺序为\n$$\n\\left[ \\mathrm{ECE}(p), \\mathrm{ECE}(p'), \\mathrm{ECE}(p''), \\overline{H}(p), \\overline{H}(p'), \\overline{H}(p'') \\right].\n$$\n将所有数据集的结果汇总到一个列表的列表中。\n\n测试套件（每个数据集是一对 $(z,y)$，其中 $z$ 是 logits，$y$ 是标签；$z$ 的数值是实数，$y$ 的数值是二元值）：\n- 数据集 $1$：$z = \\{-2.0, -0.5, 0.0, 0.5, 1.5, -1.2, 2.3, -2.5, 0.8, -0.8\\}$, $y = \\{0, 0, 1, 1, 1, 0, 1, 0, 1, 0\\}$。\n- 数据集 $2$：$z = \\{5.0, -5.0, 4.0, -4.0, 6.0, -6.0, 3.5, -3.5\\}$, $y = \\{1, 0, 0, 1, 1, 0, 0, 1\\}$。\n- 数据集 $3$：$z = \\{-0.05, 0.07, -0.12, 0.15, -0.2, 0.22, -0.3, 0.35, -0.4, 0.45\\}$, $y = \\{0, 1, 0, 1, 0, 1, 0, 1, 0, 1\\}$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含格式化为逗号分隔的各数据集结果列表的结果，并用方括号括起来。例如，输出应类似于 $[ [r_{11}, r_{12}, \\dots, r_{16}], [r_{21}, \\dots, r_{26}], [r_{31}, \\dots, r_{36}] ]$，其中每个 $r_{ij}$ 是如上计算的浮点数。不应打印任何额外文本。", "solution": "用户在机器学习领域提供了一个定义明确的问题，特别关注二元分类器的校准。该问题具有科学依据，内部一致，并要求实现标准的、可验证的算法。我将着手提供一个解决方案。\n\n任务是比较来自二元分类器 logits ($z$) 的三种概率估计：原始概率、来自线性校准的 logit 空间模型（普拉特缩放 Platt scaling）的概率，以及来自线性校准的概率空间模型的概率。对于这三组概率中的每一组，我们都必须计算两个指标：期望校准误差（ECE）和平均预测熵。\n\n对于提供的每个数据集，此过程涉及三个主要阶段：\n1.  **预测生成**：\n    *   **原始概率 ($p$)**：这些概率是直接通过 logistic sigmoid 函数从 logits 计算得出的，$p_i = \\sigma(z_i) = \\frac{1}{1 + e^{-z_i}}$。\n    *   **Logit 空间校准概率 ($p'$)**：该方法被称为普拉特缩放（Platt scaling），它通过变换 logits $z'_i = a z_i + b$ 然后应用 sigmoid 函数 $p'_i = \\sigma(z'_i)$ 来找到最优参数 $(a,b)$。参数 $(a, b)$ 通过在数据集上最小化平均负对数似然（NLL）进行优化。对于单个预测 $p$ 和真实标签 $y \\in \\{0, 1\\}$，NLL 由 $\\mathrm{NLL}(p, y) = -[y \\ln(p) + (1-y)\\ln(1-p)]$ 给出。该目标函数是凸函数，保证了 $(a,b)$ 存在唯一的全局最小值。\n    *   **概率空间校准概率 ($p''$)**：该方法通过线性映射 $p''_i = c p_i + d$ 直接变换原始概率。为确保 $p''_i$ 保持为有效概率（即在区间 $(0,1)$ 内），参数 $(c,d)$ 使用无约束变量 $(u,v) \\in \\mathbb{R}^2$ 进行重参数化，即 $d = \\sigma(u)$ 和 $c = (1-d)\\sigma(v)$。这种构造保证了 $c > 0$ 和 $d \\in (0,1)$，从而确保变换是单调的，并将区间 $[0,1]$ 映射到 $(0,1)$ 内。与普拉特缩放类似，参数 $(u, v)$ 通过最小化平均 NLL 来找到。我们使用数值优化来寻找这些参数。\n\n2.  **指标计算**：\n    *   **期望校准误差 (ECE)**：ECE 衡量模型置信度与其准确率之间的差异。我们首先为每个预测计算置信度，定义为 $c_i = \\max(p_i, 1-p_i)$。然后将预测的置信度分箱到 $[0,1]$ 上的 $B=10$ 个等宽区间中。对于每个箱 $b$，我们计算平均置信度 $\\mathrm{conf}_b$ 和平均准确率 $\\mathrm{acc}_b$。ECE 是所有非空箱的绝对差 $|\\mathrm{conf}_b - \\mathrm{acc}_b|$ 的加权平均值，权重为每个箱中的样本比例。\n    *   **平均预测熵 ($\\overline{H}$)**：该指标量化了模型预测的平均不确定性。对于每个概率 $p_i$，预测熵计算为 $H(p_i) = -[p_i \\ln(p_i) + (1-p_i)\\ln(1-p_i)]$。平均熵是整个数据集上这些值的算术平均值。较高的平均熵表示预测的总体不确定性更大。\n\n3.  **实现策略**：\n    *   实现了 sigmoid、NLL、预测熵和 ECE 的辅助函数。\n    - 为了找到普拉特缩放和概率空间模型的最优校准参数，我们定义了对应于平均 NLL 的目标函数。然后，我们使用 `scipy.optimize.minimize` 函数和 `L-BFGS-B` 算法来找到最小化这些目标的参数。\n    - 整个过程被封装在一个主函数中，该函数遍历提供的测试数据集，执行所有计算，并将结果格式化为指定的嵌套列表结构以供最终输出。通过在应用对数之前将概率值裁剪到离 $0$ 和 $1$ 有一个小的正距离，来确保数值稳定性。\n\n程序将为测试套件中的三个数据集中的每一个执行这些步骤，并将每个数据集所需的六个浮点值（$\\mathrm{ECE}(p)$、$\\mathrm{ECE}(p')$、$\\mathrm{ECE}(p'')$、$\\overline{H}(p)$、$\\overline{H}(p')$、$\\overline{H}(p'')$）整理成一个最终的列表的列表。", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\n# Define a small epsilon for numerical stability in log calculations\nEPSILON = 1e-15\n\ndef sigmoid(z):\n    \"\"\"Computes the logistic sigmoid function.\"\"\"\n    return 1.0 / (1.0 + np.exp(-z))\n\ndef predictive_entropy(p):\n    \"\"\"Computes the predictive entropy for a Bernoulli probability.\"\"\"\n    p = np.clip(p, EPSILON, 1.0 - EPSILON)\n    return -(p * np.log(p) + (1.0 - p) * np.log(1.0 - p))\n\ndef compute_nll(p, y):\n    \"\"\"Computes the negative log-likelihood for binary classification.\"\"\"\n    p = np.clip(p, EPSILON, 1.0 - EPSILON)\n    return -(y * np.log(p) + (1.0 - y) * np.log(1.0 - p))\n\ndef compute_ece(p, y, n_bins=10):\n    \"\"\"Computes the Expected Calibration Error (ECE).\"\"\"\n    if len(p) == 0:\n        return 0.0\n        \n    p = np.asarray(p)\n    y = np.asarray(y)\n\n    predictions = (p >= 0.5).astype(int)\n    confidences = np.maximum(p, 1.0 - p)\n    is_correct = (predictions == y).astype(int)\n\n    # Bin confidences. The last bin includes 1.0.\n    bin_indices = np.minimum(n_bins - 1, np.floor(confidences * n_bins)).astype(int)\n    \n    ece = 0.0\n    total_samples = len(p)\n    \n    for b in range(n_bins):\n        in_bin = (bin_indices == b)\n        num_in_bin = np.sum(in_bin)\n        \n        if num_in_bin > 0:\n            bin_accuracy = np.mean(is_correct[in_bin])\n            bin_confidence = np.mean(confidences[in_bin])\n            ece += (num_in_bin / total_samples) * np.abs(bin_accuracy - bin_confidence)\n            \n    return ece\n\ndef fit_platt_scaling(z, y):\n    \"\"\"Fits Platt scaling parameters (a, b) by minimizing NLL.\"\"\"\n    def objective(params):\n        a, b = params\n        p_calibrated = sigmoid(a * z + b)\n        return np.mean(compute_nll(p_calibrated, y))\n\n    initial_params = np.array([1.0, 0.0])\n    result = minimize(objective, initial_params, method='L-BFGS-B')\n    a_opt, b_opt = result.x\n    return a_opt, b_opt\n\ndef fit_prob_space_calibration(p, y):\n    \"\"\"Fits probability-space calibration parameters (u, v) by minimizing NLL.\"\"\"\n    def objective(params):\n        u, v = params\n        d = sigmoid(u)\n        c = (1.0 - d) * sigmoid(v)\n        p_calibrated = c * p + d\n        return np.mean(compute_nll(p_calibrated, y))\n\n    initial_params = np.array([0.0, 0.0])\n    result = minimize(objective, initial_params, method='L-BFGS-B')\n    u_opt, v_opt = result.x\n    \n    d_opt = sigmoid(u_opt)\n    c_opt = (1.0 - d_opt) * sigmoid(v_opt)\n    return c_opt, d_opt\n\ndef solve():\n    \"\"\"Main function to run the full analysis.\"\"\"\n    test_cases = [\n        (np.array([-2.0, -0.5, 0.0, 0.5, 1.5, -1.2, 2.3, -2.5, 0.8, -0.8]),\n         np.array([0, 0, 1, 1, 1, 0, 1, 0, 1, 0])),\n        (np.array([5.0, -5.0, 4.0, -4.0, 6.0, -6.0, 3.5, -3.5]),\n         np.array([1, 0, 0, 1, 1, 0, 0, 1])),\n        (np.array([-0.05, 0.07, -0.12, 0.15, -0.2, 0.22, -0.3, 0.35, -0.4, 0.45]),\n         np.array([0, 1, 0, 1, 0, 1, 0, 1, 0, 1]))\n    ]\n\n    all_results = []\n    \n    for z, y in test_cases:\n        # 1. Raw probabilities and their metrics\n        p_raw = sigmoid(z)\n        ece_raw = compute_ece(p_raw, y)\n        h_raw = np.mean(predictive_entropy(p_raw))\n\n        # 2. Logit-space calibration (Platt)\n        a_opt, b_opt = fit_platt_scaling(z, y)\n        p_platt = sigmoid(a_opt * z + b_opt)\n        ece_platt = compute_ece(p_platt, y)\n        h_platt = np.mean(predictive_entropy(p_platt))\n        \n        # 3. Probability-space calibration\n        c_opt, d_opt = fit_prob_space_calibration(p_raw, y)\n        p_prob = c_opt * p_raw + d_opt\n        ece_prob = compute_ece(p_prob, y)\n        h_prob = np.mean(predictive_entropy(p_prob))\n        \n        # 4. Aggregate results for the dataset\n        case_results = [\n            ece_raw, ece_platt, ece_prob,\n            h_raw, h_platt, h_prob\n        ]\n        all_results.append(case_results)\n\n    # Format the final output string exactly as specified\n    inner_strs = [f\"[{','.join(map(str, sublist))}]\" for sublist in all_results]\n    print(f\"[{','.join(inner_strs)}]\")\n\nsolve()\n\n```", "id": "3179715"}, {"introduction": "在不确定性估计中，区分模型的“认知不确定性”（epistemic uncertainty，源于模型参数的不确定）和“偶然不确定性”（aleatoric uncertainty，源于数据本身的噪声）至关重要。本练习 ([@problem_id:3179750]) 将挑战你构建一个贝叶斯序数回归模型，该模型能够在一个统一的框架下同时捕捉和量化这两种不确定性。你将推导潜在分数的预测分布，并在一个更复杂的结构化预测任务中，实现对累积概率的校准评估，从而深入理解如何在高级模型中整合并评估不确定性。", "problem": "您将使用潜在高斯分数下的累积链接公式对序数回归进行建模，该模型同时考虑了认知不确定性和随机不确定性。考虑一个模型，其潜在分数定义为 $z = \\mathbf{x}^{\\top}\\mathbf{w} + \\varepsilon$，其中 $\\mathbf{x} \\in \\mathbb{R}^{d}$ 是一个固定的特征向量，$\\mathbf{w} \\in \\mathbb{R}^{d}$ 是一个具有高斯后验的随机权重向量，$\\varepsilon$ 是独立的高斯噪声。序数标签 $y \\in \\{1,2,\\dots,K\\}$ 是通过对潜在变量 $z$ 使用未知但固定的切点 $-\\infty = \\tau_{0}  \\tau_{1}  \\dots  \\tau_{K-1}  \\tau_{K} = +\\infty$ 进行阈值化得到的，规则为 $y = c$ 当且仅当 $\\tau_{c-1}  z \\le \\tau_{c}$。阈值 $k$ 的累积链接概率定义为 $p(y \\le k \\mid \\mathbf{x})$。\n\n您必须使用的基本假设和定义：\n- 权重的后验分布是高斯分布：$\\mathbf{w} \\sim \\mathcal{N}(\\boldsymbol{\\mu}_{w}, \\boldsymbol{\\Sigma}_{w})$，具有已知的均值 $\\boldsymbol{\\mu}_{w}$ 和协方差 $\\boldsymbol{\\Sigma}_{w}$。\n- 随机噪声为 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma_{\\varepsilon}^{2})$，与 $\\mathbf{w}$ 独立。\n- 对于固定的 $\\mathbf{x}$，线性分数 $s = \\mathbf{x}^{\\top}\\mathbf{w}$ 是高斯随机向量的线性泛函。\n- 在 probit 累积链接下，阈值 $k$ 处的累积概率由高斯累积分布函数给出，其参数是根据 $z$ 给定 $\\mathbf{x}$ 的预测分布进行适当标准化的。\n\n您的任务：\n1) 从任何多元高斯分布的线性变换仍然是高斯分布，以及独立随机变量之和的方差等于其方差之和这些基本事实出发，推导给定 $\\mathbf{x}$ 时潜在分数 $s = \\mathbf{x}^{\\top}\\mathbf{w}$ 和潜在变量 $z = s + \\varepsilon$ 的预测方差。不要假设任何快捷公式；从这些基本定义开始。\n2) 使用推导出的 $z \\mid \\mathbf{x}$ 的预测分布，在 probit 链接下，用高斯累积分布函数以及 $z \\mid \\mathbf{x}$ 的预测均值和方差来表示累积概率 $p(y \\le k \\mid \\mathbf{x})$。\n3) 通过期望校准误差 (ECE) 来定义跨序数阈值的累积事件的校准。对于每个阈值 $k \\in \\{1,2,\\dots,K-1\\}$，考虑二元事件 $b = \\mathbb{I}[y \\le k]$，其预测概率为 $p = p(y \\le k \\mid \\mathbf{x})$。给定 $N$ 个样本 $(\\mathbf{x}_{i}, y_{i})$，对于固定的 $k$，有相应的 $(p_{i}, b_{i})$，将单位区间 $[0,1]$ 划分为 $B$ 个等宽的箱，其边界为 $0 = e_{0}  e_{1}  \\dots  e_{B} = 1$，其中 $e_{j} = j/B$。对于 $j \\in \\{1,2,\\dots,B-1\\}$，令 $\\mathcal{I}_{j} = \\{ i : e_{j-1} \\le p_{i}  e_{j} \\}$，对于 $\\mathcal{I}_{B} = \\{ i : e_{B-1} \\le p_{i} \\le e_{B} \\}$ 以包含概率 $p = 1$。对于每个非空箱，定义经验准确率 $\\mathrm{acc}_{j} = \\frac{1}{|\\mathcal{I}_{j}|}\\sum_{i \\in \\mathcal{I}_{j}} b_{i}$ 和经验置信度 $\\mathrm{conf}_{j} = \\frac{1}{|\\mathcal{I}_{j}|}\\sum_{i \\in \\mathcal{I}_{j}} p_{i}$。阈值 $k$ 的期望校准误差为\n$$\n\\mathrm{ECE}_{k} = \\sum_{j=1}^{B} \\frac{|\\mathcal{I}_{j}|}{N} \\left| \\mathrm{acc}_{j} - \\mathrm{conf}_{j} \\right|,\n$$\n其中空箱对总和的贡献为 $0$。通过宏平均 $\\overline{\\mathrm{ECE}} = \\frac{1}{K-1}\\sum_{k=1}^{K-1} \\mathrm{ECE}_{k}$ 对阈值进行聚合，并通过范围 $\\Delta \\mathrm{ECE} = \\max_{k} \\mathrm{ECE}_{k} - \\min_{k} \\mathrm{ECE}_{k}$ 来量化阈值间的变异性。\n4) 实现一个程序，对于下面提供的每个测试用例，计算：(i) 在指定的查询特征 $\\mathbf{x}_{\\star}$ 处的 $z$ 的预测方差，(ii) 在所提供的数据集上跨阈值的宏平均 $\\overline{\\mathrm{ECE}}$，以及 (iii) 在所提供的数据集上跨阈值的范围 $\\Delta \\mathrm{ECE}$。使用 $B = 5$ 个箱。\n\n仅使用测试套件中提供的值。不涉及角度。所有数值输出必须是实数，并应四舍五入到恰好 $6$ 位小数。\n\n测试套件：\n- 案例 A：\n  - 维度 $d = 2$。\n  - 后验均值 $\\boldsymbol{\\mu}_{w} = \\begin{bmatrix} 0.8 \\\\ -0.3 \\end{bmatrix}$。\n  - 后验协方差 $\\boldsymbol{\\Sigma}_{w} = \\begin{bmatrix} 0.10  0.02 \\\\ 0.02  0.05 \\end{bmatrix}$。\n  - 随机方差 $\\sigma_{\\varepsilon}^{2} = 0.20$。\n  - $K = 3$ 的阈值：$\\tau_{1} = -0.5$, $\\tau_{2} = 0.7$。\n  - 查询特征 $\\mathbf{x}_{\\star} = \\begin{bmatrix} 1.0 \\\\ -0.5 \\end{bmatrix}$。\n  - $N = 8$ 对 $(\\mathbf{x}_{i}, y_{i})$ 的数据集：\n    - $(\\mathbf{x}_{1}, y_{1}) = \\left( \\begin{bmatrix} 0.2 \\\\ -0.1 \\end{bmatrix}, 1 \\right)$,\n    - $(\\mathbf{x}_{2}, y_{2}) = \\left( \\begin{bmatrix} 1.5 \\\\ 0.3 \\end{bmatrix}, 3 \\right)$,\n    - $(\\mathbf{x}_{3}, y_{3}) = \\left( \\begin{bmatrix} -0.7 \\\\ 0.8 \\end{bmatrix}, 1 \\right)$,\n    - $(\\mathbf{x}_{4}, y_{4}) = \\left( \\begin{bmatrix} 0.0 \\\\ 0.0 \\end{bmatrix}, 2 \\right)$,\n    - $(\\mathbf{x}_{5}, y_{5}) = \\left( \\begin{bmatrix} 0.9 \\\\ -1.1 \\end{bmatrix}, 2 \\right)$,\n    - $(\\mathbf{x}_{6}, y_{6}) = \\left( \\begin{bmatrix} -1.2 \\\\ 0.4 \\end{bmatrix}, 1 \\right)$,\n    - $(\\mathbf{x}_{7}, y_{7}) = \\left( \\begin{bmatrix} 0.4 \\\\ 0.6 \\end{bmatrix}, 2 \\right)$,\n    - $(\\mathbf{x}_{8}, y_{8}) = \\left( \\begin{bmatrix} 1.1 \\\\ -0.2 \\end{bmatrix}, 3 \\right)$。\n- 案例 B：\n  - 维度 $d = 2$。\n  - 后验均值 $\\boldsymbol{\\mu}_{w} = \\begin{bmatrix} 0.3 \\\\ 0.2 \\end{bmatrix}$。\n  - 后验协方差 $\\boldsymbol{\\Sigma}_{w} = \\begin{bmatrix} 0.0  0.0 \\\\ 0.0  0.0 \\end{bmatrix}$。\n  - 随机方差 $\\sigma_{\\varepsilon}^{2} = 0.10$。\n  - $K = 3$ 的阈值：$\\tau_{1} = -0.1$, $\\tau_{2} = 0.4$。\n  - 查询特征 $\\mathbf{x}_{\\star} = \\begin{bmatrix} -0.5 \\\\ 2.0 \\end{bmatrix}$。\n  - $N = 8$ 对 $(\\mathbf{x}_{i}, y_{i})$ 的数据集：\n    - $(\\mathbf{x}_{1}, y_{1}) = \\left( \\begin{bmatrix} -0.2 \\\\ 0.1 \\end{bmatrix}, 2 \\right)$,\n    - $(\\mathbf{x}_{2}, y_{2}) = \\left( \\begin{bmatrix} 0.5 \\\\ -0.3 \\end{bmatrix}, 2 \\right)$,\n    - $(\\mathbf{x}_{3}, y_{3}) = \\left( \\begin{bmatrix} 0.0 \\\\ 1.0 \\end{bmatrix}, 3 \\right)$,\n    - $(\\mathbf{x}_{4}, y_{4}) = \\left( \\begin{bmatrix} -1.0 \\\\ 0.0 \\end{bmatrix}, 1 \\right)$,\n    - $(\\mathbf{x}_{5}, y_{5}) = \\left( \\begin{bmatrix} 1.0 \\\\ 1.0 \\end{bmatrix}, 3 \\right)$,\n    - $(\\mathbf{x}_{6}, y_{6}) = \\left( \\begin{bmatrix} 0.2 \\\\ 0.2 \\end{bmatrix}, 2 \\right)$,\n    - $(\\mathbf{x}_{7}, y_{7}) = \\left( \\begin{bmatrix} -0.6 \\\\ 0.4 \\end{bmatrix}, 1 \\right)$,\n    - $(\\mathbf{x}_{8}, y_{8}) = \\left( \\begin{bmatrix} 0.8 \\\\ 0.0 \\end{bmatrix}, 3 \\right)$。\n- 案例 C：\n  - 维度 $d = 3$。\n  - 后验均值 $\\boldsymbol{\\mu}_{w} = \\begin{bmatrix} 0.5 \\\\ -0.2 \\\\ 0.1 \\end{bmatrix}$。\n  - 后验协方差 $\\boldsymbol{\\Sigma}_{w} = \\begin{bmatrix} 0.20  0.00  0.05 \\\\ 0.00  0.10  -0.02 \\\\ 0.05  -0.02  0.15 \\end{bmatrix}$。\n  - 随机方差 $\\sigma_{\\varepsilon}^{2} = 0.30$。\n  - $K = 4$ 的阈值：$\\tau_{1} = -0.8$, $\\tau_{2} = 0.2$, $\\tau_{3} = 1.1$。\n  - 查询特征 $\\mathbf{x}_{\\star} = \\begin{bmatrix} 0.3 \\\\ -0.7 \\\\ 1.2 \\end{bmatrix}$。\n  - $N = 10$ 对 $(\\mathbf{x}_{i}, y_{i})$ 的数据集：\n    - $(\\mathbf{x}_{1}, y_{1}) = \\left( \\begin{bmatrix} 0.0 \\\\ 0.0 \\\\ 0.0 \\end{bmatrix}, 2 \\right)$,\n    - $(\\mathbf{x}_{2}, y_{2}) = \\left( \\begin{bmatrix} 1.0 \\\\ -1.0 \\\\ 0.5 \\end{bmatrix}, 3 \\right)$,\n    - $(\\mathbf{x}_{3}, y_{3}) = \\left( \\begin{bmatrix} -0.5 \\\\ 1.5 \\\\ -0.7 \\end{bmatrix}, 1 \\right)$,\n    - $(\\mathbf{x}_{4}, y_{4}) = \\left( \\begin{bmatrix} 0.2 \\\\ -0.2 \\\\ 0.2 \\end{bmatrix}, 2 \\right)$,\n    - $(\\mathbf{x}_{5}, y_{5}) = \\left( \\begin{bmatrix} 0.8 \\\\ 0.3 \\\\ -0.1 \\end{bmatrix}, 3 \\right)$,\n    - $(\\mathbf{x}_{6}, y_{6}) = \\left( \\begin{bmatrix} -1.5 \\\\ 0.5 \\\\ 0.5 \\end{bmatrix}, 1 \\right)$,\n    - $(\\mathbf{x}_{7}, y_{7}) = \\left( \\begin{bmatrix} 0.5 \\\\ -0.6 \\\\ 1.0 \\end{bmatrix}, 4 \\right)$,\n    - $(\\mathbf{x}_{8}, y_{8}) = \\left( \\begin{bmatrix} 1.2 \\\\ 0.0 \\\\ 0.8 \\end{bmatrix}, 4 \\right)$,\n    - $(\\mathbf{x}_{9}, y_{9}) = \\left( \\begin{bmatrix} -0.8 \\\\ -0.8 \\\\ 0.8 \\end{bmatrix}, 2 \\right)$,\n    - $(\\mathbf{x}_{10}, y_{10}) = \\left( \\begin{bmatrix} 0.6 \\\\ 1.2 \\\\ -0.4 \\end{bmatrix}, 3 \\right)$。\n\n程序要求：\n- 对于每个案例，使用 $B = 5$ 个箱，计算在 $\\mathbf{x}_{\\star}$ 处的 $z$ 的预测方差、在案例数据集上跨阈值的宏平均 $\\overline{\\mathrm{ECE}}$，以及在案例数据集上跨阈值的范围 $\\Delta \\mathrm{ECE}$。\n- 您的程序应生成单行输出，其中包含所有结果，以逗号分隔并用方括号括起来，顺序如下：\n  - 案例 A：在 $\\mathbf{x}_{\\star}$ 处的 $z$ 的预测方差, $\\overline{\\mathrm{ECE}}$, $\\Delta \\mathrm{ECE}$;\n  - 案例 B：在 $\\mathbf{x}_{\\star}$ 处的 $z$ 的预测方差, $\\overline{\\mathrm{ECE}}$, $\\Delta \\mathrm{ECE}$;\n  - 案例 C：在 $\\mathbf{x}_{\\star}$ 处的 $z$ 的预测方差, $\\overline{\\mathrm{ECE}}$, $\\Delta \\mathrm{ECE}$。\n- 将每个打印的数字四舍五入到恰好 $6$ 位小数，不附加任何额外文本。\n\n您最终的程序必须是完整且可直接运行的，不需要用户输入，并且仅使用标准 Python 库以及指定版本的 Numerical Python (NumPy) 和 Scientific Python (SciPy)。", "solution": "在尝试任何解决方案之前，用户的题目陈述会经过验证。\n\n### 第 1 步：提取给定条件\n- **模型定义**：潜在分数 $z = \\mathbf{x}^{\\top}\\mathbf{w} + \\varepsilon$。\n- **特征向量**：$\\mathbf{x} \\in \\mathbb{R}^{d}$ (固定的)。\n- **权重向量**：$\\mathbf{w} \\in \\mathbb{R}^{d}$ (随机的)。\n- **噪声项**：$\\varepsilon$ (独立的 高斯噪声)。\n- **序数标签**：$y \\in \\{1, 2, \\dots, K\\}$。\n- **切点**：$-\\infty = \\tau_{0}  \\tau_{1}  \\dots  \\tau_{K-1}  \\tau_{K} = +\\infty$ (固定，未知)。测试用例提供了具体值。\n- **标签规则**：$y = c \\iff \\tau_{c-1}  z \\le \\tau_{c}$。\n- **累积概率**：$p(y \\le k \\mid \\mathbf{x})$。\n- **权重后验**：$\\mathbf{w} \\sim \\mathcal{N}(\\boldsymbol{\\mu}_{w}, \\boldsymbol{\\Sigma}_{w})$。\n- **噪声分布**：$\\varepsilon \\sim \\mathcal{N}(0, \\sigma_{\\varepsilon}^{2})$。\n- **独立性假设**：$\\varepsilon$ 与 $\\mathbf{w}$ 独立。\n- **线性分数**：$s = \\mathbf{x}^{\\top}\\mathbf{w}$。\n- **Probit 链接模型**：累积概率由高斯累积分布函数(CDF)给出。\n- **期望校准误差(ECE)**：\n  - 阈值 $k$ 的二元事件：$b = \\mathbb{I}[y \\le k]$。\n  - 预测概率：$p = p(y \\le k \\mid \\mathbf{x})$。\n  - 箱：在 $[0,1]$ 上的 $B$ 个等宽箱，边界为 $e_j = j/B$。对于 $j  B$, $\\mathcal{I}_{j} = \\{ i : e_{j-1} \\le p_{i}  e_{j} \\}$，以及 $\\mathcal{I}_{B} = \\{ i : e_{B-1} \\le p_{i} \\le e_{B} \\}$。\n  - 箱准确率：$\\mathrm{acc}_{j} = \\frac{1}{|\\mathcal{I}_{j}|}\\sum_{i \\in \\mathcal{I}_{j}} b_{i}$。\n  - 箱置信度：$\\mathrm{conf}_{j} = \\frac{1}{|\\mathcal{I}_{j}|}\\sum_{i \\in \\mathcal{I}_{j}} p_{i}$。\n  - 阈值 $k$ 处的 ECE：$\\mathrm{ECE}_{k} = \\sum_{j=1}^{B} \\frac{|\\mathcal{I}_{j}|}{N} \\left| \\mathrm{acc}_{j} - \\mathrm{conf}_{j} \\right|$。\n- **聚合指标**：\n  - 宏平均 ECE：$\\overline{\\mathrm{ECE}} = \\frac{1}{K-1}\\sum_{k=1}^{K-1} \\mathrm{ECE}_{k}$。\n  - ECE 范围：$\\Delta \\mathrm{ECE} = \\max_{k} \\mathrm{ECE}_{k} - \\min_{k} \\mathrm{ECE}_{k}$。\n- **具体参数**：$B=5$ 个箱。提供了三个测试用例(A, B, C)，包含 $d, \\boldsymbol{\\mu}_w, \\boldsymbol{\\Sigma}_w, \\sigma_\\varepsilon^2, K, \\tau_k, \\mathbf{x}_\\star$ 的所有必要数值，以及一个数据集 $\\{(\\mathbf{x}_i, y_i)\\}_{i=1}^N$。\n\n### 第 2 步：使用提取的给定条件进行验证\n根据验证标准对问题进行评估。\n- **科学基础**：该问题描述了一个带有 probit 链接函数的标准贝叶斯序数回归模型。统计概念，包括多元高斯分布的性质、随机变量的独立性以及期望校准误差的定义，都是公认且陈述正确的。该模型是贝叶斯统计和机器学习中的基本构成模块。\n- **适定的**：问题是完全指定的。对于每个任务，都提供了所有必要的数值、定义和数据集。目标是根据这些给定条件计算特定的数值量，这导向一个唯一的、稳定的和有意义的解决方案。\n- **客观的**：问题以精确的数学语言表述，没有歧义、主观性或观点。\n\n该问题没有表现出任何列出的缺陷：\n1.  **科学上不合理**：物理和数学都是合理的。高斯变量在线性变换和求和下的性质被正确地引用。\n2.  **无法形式化**：问题完全是形式化和定量的。\n3.  **不完整或矛盾**：每个测试用例的设置都是完整和自洽的。\n4.  **不切实际或不可行**：参数和数据在数值上是合理的，并且不违反物理或数学约束。协方差矩阵按要求是半正定的。\n5.  **不适定的**：问题是适定的，有明确的路径可以得到唯一解。\n6.  **琐碎或同义反复**：问题需要非平凡的推导和仔细、多步骤的实现，测试了对统计理论及其计算应用的理解。\n7.  **超出科学可验证性**：结果在计算上是确定性的，可以独立验证。\n\n### 第 3 步：结论与行动\n该问题是**有效的**。下面提供了完整的解决方案。\n\n***\n\n### 第 1 部分：预测均值和方差的推导\n我们的任务是推导给定特征向量 $\\mathbf{x}$ 时，潜在分数 $z = \\mathbf{x}^{\\top}\\mathbf{w} + \\varepsilon$ 的预测分布。该推导分两步进行，从基本定义开始。\n\n首先，考虑线性分数 $s = \\mathbf{x}^{\\top}\\mathbf{w}$。这是多元高斯随机向量 $\\mathbf{w} \\sim \\mathcal{N}(\\boldsymbol{\\mu}_{w}, \\boldsymbol{\\Sigma}_{w})$ 的线性变换。对于任何均值为 $\\mathbb{E}[\\mathbf{y}] = \\boldsymbol{\\mu}$ 且协方差为 $\\mathrm{Cov}(\\mathbf{y}) = \\boldsymbol{\\Sigma}$ 的随机向量 $\\mathbf{y}$，线性变换 $\\mathbf{A}\\mathbf{y}$ 产生的随机向量的均值为 $\\mathbf{A}\\boldsymbol{\\mu}$，协方差为 $\\mathbf{A}\\boldsymbol{\\Sigma}\\mathbf{A}^{\\top}$。\n对于标量分数 $s$，变换矩阵为 $\\mathbf{A} = \\mathbf{x}^{\\top}$。\n\n$s$ 的均值为：\n$$ \\mu_s = \\mathbb{E}[s] = \\mathbb{E}[\\mathbf{x}^{\\top}\\mathbf{w}] = \\mathbf{x}^{\\top}\\mathbb{E}[\\mathbf{w}] = \\mathbf{x}^{\\top}\\boldsymbol{\\mu}_{w} $$\n\n$s$ 的方差（代表认知不确定性）为：\n$$ \\sigma_s^2 = \\mathrm{Var}(s) = \\mathrm{Var}(\\mathbf{x}^{\\top}\\mathbf{w}) = (\\mathbf{x}^{\\top})\\mathrm{Cov}(\\mathbf{w})(\\mathbf{x}^{\\top})^{\\top} = \\mathbf{x}^{\\top}\\boldsymbol{\\Sigma}_{w}\\mathbf{x} $$\n由于高斯分布的线性变换仍为高斯分布，所以 $s \\mid \\mathbf{x} \\sim \\mathcal{N}(\\mathbf{x}^{\\top}\\boldsymbol{\\mu}_{w}, \\mathbf{x}^{\\top}\\boldsymbol{\\Sigma}_{w}\\mathbf{x})$。\n\n其次，考虑完整的潜在分数 $z = s + \\varepsilon$。我们已知 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma_{\\varepsilon}^{2})$ 并且 $\\varepsilon$ 与 $\\mathbf{w}$ 独立。由于 $s$ 是 $\\mathbf{w}$ 的函数，所以 $s$ 和 $\\varepsilon$ 也相互独立。\n\n$z$ 的均值是均值之和：\n$$ \\mu_z = \\mathbb{E}[z] = \\mathbb{E}[s + \\varepsilon] = \\mathbb{E}[s] + \\mathbb{E}[\\varepsilon] = \\mu_s + 0 = \\mathbf{x}^{\\top}\\boldsymbol{\\mu}_{w} $$\n\n$z$ 的方差是独立变量 $s$ 和 $\\varepsilon$ 的方差之和：\n$$ \\sigma_z^2 = \\mathrm{Var}(z) = \\mathrm{Var}(s + \\varepsilon) = \\mathrm{Var}(s) + \\mathrm{Var}(\\varepsilon) = \\sigma_s^2 + \\sigma_\\varepsilon^2 = \\mathbf{x}^{\\top}\\boldsymbol{\\Sigma}_{w}\\mathbf{x} + \\sigma_{\\varepsilon}^{2} $$\n总方差 $\\sigma_z^2$ 结合了来自权重的认知不确定性 ($\\mathbf{x}^{\\top}\\boldsymbol{\\Sigma}_{w}\\mathbf{x}$) 和来自噪声项的随机不确定性 ($\\sigma_{\\varepsilon}^{2}$)。作为两个独立高斯变量的和，$z$ 也是高斯分布的。\n\n因此，给定 $\\mathbf{x}$ 时，潜在分数 $z$ 的预测分布为：\n$$ z \\mid \\mathbf{x} \\sim \\mathcal{N}(\\mathbf{x}^{\\top}\\boldsymbol{\\mu}_{w}, \\mathbf{x}^{\\top}\\boldsymbol{\\Sigma}_{w}\\mathbf{x} + \\sigma_{\\varepsilon}^{2}) $$\n\n### 第 2 部分：累积概率的表达式\n序数模型定义了标签 $y=c$ 当且仅当 $\\tau_{c-1}  z \\le \\tau_c$。因此，累积事件 $y \\le k$ 等价于事件 $z \\le \\tau_k$。累积概率为：\n$$ p(y \\le k \\mid \\mathbf{x}) = p(z \\le \\tau_k \\mid \\mathbf{x}) $$\n鉴于 $z \\mid \\mathbf{x} \\sim \\mathcal{N}(\\mu_z, \\sigma_z^2)$，这个概率是使用正态分布的累积分布函数 (CDF) 计算的。如果我们让 $\\Phi(\\cdot)$ 表示标准正态分布 $\\mathcal{N}(0, 1)$ 的 CDF，则通过对变量进行标准化来找到该概率：\n$$ p(z \\le \\tau_k \\mid \\mathbf{x}) = \\Phi\\left(\\frac{\\tau_k - \\mu_z}{\\sigma_z}\\right) $$\n将第 1 部分中的 $\\mu_z$ 和 $\\sigma_z$ 的表达式代入，得到 probit 链接下累积概率的最终形式：\n$$ p(y \\le k \\mid \\mathbf{x}) = \\Phi\\left(\\frac{\\tau_k - \\mathbf{x}^{\\top}\\boldsymbol{\\mu}_{w}}{\\sqrt{\\mathbf{x}^{\\top}\\boldsymbol{\\Sigma}_{w}\\mathbf{x} + \\sigma_{\\varepsilon}^{2}}}\\right) $$\n\n### 第 3 部分：期望校准误差 (ECE) 计算\n计算 ECE、宏平均 ECE 和 ECE 范围的步骤在问题陈述中已明确定义。为了实现，我们遵循以下步骤：\n1.  遍历每个相关的序数阈值 $k \\in \\{1, 2, \\dots, K-1\\}$。\n2.  对于每个阈值 $k$，我们将多分类问题转化为二元问题。\n    - 对于每个数据点 $(\\mathbf{x}_i, y_i)$，使用第 2 部分的公式计算预测概率 $p_i = p(y_i \\le k \\mid \\mathbf{x}_i)$。\n    - 确定真实的二元结果 $b_i = \\mathbb{I}[y_i \\le k]$，如果 $y_i \\le k$ 则为 $1$，否则为 $0$。\n3.  使用配对集合 $\\{(p_i, b_i)\\}_{i=1}^N$，我们计算 $\\mathrm{ECE}_k$。\n    - 将预测值 $\\{p_i\\}$ 划分为 $B=5$ 个由边界 $[0.0, 0.2), [0.2, 0.4), [0.4, 0.6), [0.6, 0.8), [0.8, 1.0]$ 定义的箱。最后一个箱包含 $1.0$。\n    - 对于每个非空箱 $j$，计算点数 $|\\mathcal{I}_j|$、平均准确率 $\\mathrm{acc}_j = \\frac{1}{|\\mathcal{I}_j|}\\sum_{i \\in \\mathcal{I}_j} b_i$ 和平均置信度 $\\mathrm{conf}_j = \\frac{1}{|\\mathcal{I}_j|}\\sum_{i \\in \\mathcal{I}_j} p_i$。\n    - 计算 $\\mathrm{ECE}_k = \\sum_{j=1}^{B} \\frac{|\\mathcal{I}_j|}{N} |\\mathrm{acc}_j - \\mathrm{conf}_j|$。\n4.  在为所有 $k$ 计算出 $\\mathrm{ECE}_k$ 后，计算聚合统计数据：\n    - $\\overline{\\mathrm{ECE}} = \\frac{1}{K-1}\\sum_{k=1}^{K-1} \\mathrm{ECE}_k$。\n    - $\\Delta \\mathrm{ECE} = \\max_{k} \\mathrm{ECE}_k - \\min_{k} \\mathrm{ECE}_k$。\n\n### 第 4 部分：实现\n以下程序实现了所提供测试用例的计算。对于每个案例，它计算：\n- 查询特征 $\\mathbf{x}_{\\star}$ 的总预测方差 $\\sigma_z^2 = \\mathbf{x}_{\\star}^{\\top}\\boldsymbol{\\Sigma}_{w}\\mathbf{x}_{\\star} + \\sigma_{\\varepsilon}^{2}$。\n- 宏平均 ECE, $\\overline{\\mathrm{ECE}}$。\n- ECE 范围, $\\Delta \\mathrm{ECE}$。\n\n计算依赖于 `numpy` 进行线性代数运算，以及 `scipy.stats.norm.cdf` 来计算标准正态 CDF, $\\Phi(\\cdot)$。所有结果按要求四舍五入到 6 位小数。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\n# language: Python\n# version: 3.12\n# libraries:\n#     - name: numpy, version: 1.23.5\n#     - name: scipy, version: 1.11.4\n\ndef solve():\n    \"\"\"\n    Main function to process test cases and print results.\n    \"\"\"\n    test_cases = [\n        # Case A\n        {\n            \"d\": 2,\n            \"mu_w\": np.array([0.8, -0.3]),\n            \"Sigma_w\": np.array([[0.10, 0.02], [0.02, 0.05]]),\n            \"sigma_eps_sq\": 0.20,\n            \"K\": 3,\n            \"taus\": {-1: -np.inf, 0: -np.inf, 1: -0.5, 2: 0.7, 3: np.inf},\n            \"x_star\": np.array([1.0, -0.5]),\n            \"dataset_X\": np.array([\n                [0.2, -0.1], [1.5, 0.3], [-0.7, 0.8], [0.0, 0.0],\n                [0.9, -1.1], [-1.2, 0.4], [0.4, 0.6], [1.1, -0.2]\n            ]),\n            \"dataset_y\": np.array([1, 3, 1, 2, 2, 1, 2, 3]),\n        },\n        # Case B\n        {\n            \"d\": 2,\n            \"mu_w\": np.array([0.3, 0.2]),\n            \"Sigma_w\": np.array([[0.0, 0.0], [0.0, 0.0]]),\n            \"sigma_eps_sq\": 0.10,\n            \"K\": 3,\n            \"taus\": {-1: -np.inf, 0: -np.inf, 1: -0.1, 2: 0.4, 3: np.inf},\n            \"x_star\": np.array([-0.5, 2.0]),\n            \"dataset_X\": np.array([\n                [-0.2, 0.1], [0.5, -0.3], [0.0, 1.0], [-1.0, 0.0],\n                [1.0, 1.0], [0.2, 0.2], [-0.6, 0.4], [0.8, 0.0]\n            ]),\n            \"dataset_y\": np.array([2, 2, 3, 1, 3, 2, 1, 3]),\n        },\n        # Case C\n        {\n            \"d\": 3,\n            \"mu_w\": np.array([0.5, -0.2, 0.1]),\n            \"Sigma_w\": np.array([[0.20, 0.00, 0.05], [0.00, 0.10, -0.02], [0.05, -0.02, 0.15]]),\n            \"sigma_eps_sq\": 0.30,\n            \"K\": 4,\n            \"taus\": {-1: -np.inf, 0: -np.inf, 1: -0.8, 2: 0.2, 3: 1.1, 4: np.inf},\n            \"x_star\": np.array([0.3, -0.7, 1.2]),\n            \"dataset_X\": np.array([\n                [0.0, 0.0, 0.0], [1.0, -1.0, 0.5], [-0.5, 1.5, -0.7],\n                [0.2, -0.2, 0.2], [0.8, 0.3, -0.1], [-1.5, 0.5, 0.5],\n                [0.5, -0.6, 1.0], [1.2, 0.0, 0.8], [-0.8, -0.8, 0.8],\n                [0.6, 1.2, -0.4]\n            ]),\n            \"dataset_y\": np.array([2, 3, 1, 2, 3, 1, 4, 4, 2, 3]),\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        mu_w = case[\"mu_w\"]\n        Sigma_w = case[\"Sigma_w\"]\n        sigma_eps_sq = case[\"sigma_eps_sq\"]\n        K = case[\"K\"]\n        taus = case[\"taus\"]\n        x_star = case[\"x_star\"]\n        X, y = case[\"dataset_X\"], case[\"dataset_y\"]\n        N = len(y)\n        B = 5\n\n        # 1. Compute predictive variance of z at x_star\n        epistemic_var_star = x_star.T @ Sigma_w @ x_star\n        pred_var_z_star = epistemic_var_star + sigma_eps_sq\n\n        # 2. Compute ECE metrics\n        all_ece_k = []\n        for k in range(1, K):\n            tau_k = taus[k]\n            \n            p_values = []\n            b_values = []\n            \n            for i in range(N):\n                x_i = X[i]\n                y_i = y[i]\n                \n                mu_z_i = x_i.T @ mu_w\n                var_z_i = x_i.T @ Sigma_w @ x_i + sigma_eps_sq\n                std_z_i = np.sqrt(var_z_i)\n                \n                # Handle case where variance is zero\n                if std_z_i == 0:\n                    p_i = 1.0 if tau_k > mu_z_i else 0.0\n                else:\n                    p_i = norm.cdf((tau_k - mu_z_i) / std_z_i)\n                    \n                b_i = 1.0 if y_i = k else 0.0\n                \n                p_values.append(p_i)\n                b_values.append(b_i)\n                \n            p_values = np.array(p_values)\n            b_values = np.array(b_values)\n            \n            # Calculate ECE_k\n            ece_k = 0.0\n            bin_edges = np.linspace(0, 1, B + 1)\n            \n            for j in range(B):\n                lower_bound = bin_edges[j]\n                upper_bound = bin_edges[j+1]\n                \n                # The last bin is inclusive of 1.0\n                if j == B - 1:\n                    in_bin_mask = (p_values >= lower_bound)  (p_values = upper_bound)\n                else:\n                    in_bin_mask = (p_values >= lower_bound)  (p_values  upper_bound)\n                \n                bin_size = np.sum(in_bin_mask)\n                \n                if bin_size > 0:\n                    acc_j = np.mean(b_values[in_bin_mask])\n                    conf_j = np.mean(p_values[in_bin_mask])\n                    ece_k += (bin_size / N) * np.abs(acc_j - conf_j)\n            \n            all_ece_k.append(ece_k)\n        \n        all_ece_k = np.array(all_ece_k)\n        macro_ece = np.mean(all_ece_k)\n        \n        # Handle case where K=2, so only 1 threshold and range is 0\n        if len(all_ece_k) > 1:\n            delta_ece = np.max(all_ece_k) - np.min(all_ece_k)\n        else:\n            delta_ece = 0.0\n            \n        all_results.extend([pred_var_z_star, macro_ece, delta_ece])\n        \n    # Final print statement in the exact required format.\n    print(f\"[{','.join([f'{r:.6f}' for r in all_results])}]\")\n\nsolve()\n\n```", "id": "3179750"}]}