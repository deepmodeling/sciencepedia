{"hands_on_practices": [{"introduction": "理解双下降现象最好的方法是亲眼见证它的发生。在此实践中，我们将使用一个“随机特征模型”（一种简化的神经网络）来模拟一个基本场景。通过改变模型的复杂度（参数数量 $m$）与数据量（$n$）的相对大小，我们可以绘制出测试误差的变化曲线。这个动手编码练习将让你凭经验复现典型的双下降曲线，并精确定位测试误差出现峰值的“插值阈值”，为后续更深入的理论概念提供坚实的实践基础。[@problem_id:3151120]", "problem": "你的任务是通过扫描参数-样本比率，并将插值阈值与测试误差的峰值联系起来，来凭经验证明前馈多层感知机（MLP）中的双下降现象。核心设置如下。\n\n从平方损失下的经验风险最小化的基础出发。设输入空间为 $\\mathbb{R}^d$。考虑一个带有修正线性单元（ReLU）非线性的两层前馈多层感知机（MLP），其中隐藏层权重是固定的，只有输出层权重被训练。对于一个输入向量 $x \\in \\mathbb{R}^d$，MLP 计算\n$$\n\\phi(x) = \\big(\\sigma(w_1^\\top x + b_1), \\ldots, \\sigma(w_m^\\top x + b_m)\\big) \\in \\mathbb{R}^m,\n$$\n其中 $\\sigma(z) = \\max\\{0, z\\}$ 是 ReLU 激活函数，$w_j \\in \\mathbb{R}^d$ 和 $b_j \\in \\mathbb{R}$ 是固定的隐藏层参数，而 $m$ 是隐藏单元的数量。预测输出为\n$$\n\\hat{y}(x) = a^\\top \\phi(x),\n$$\n其中 $a \\in \\mathbb{R}^m$ 是被训练的输出层权重。给定训练数据 $\\{(x_i, y_i)\\}_{i=1}^n$，定义设计矩阵\n$$\n\\Phi \\in \\mathbb{R}^{n \\times m}, \\quad \\Phi_{ij} = \\sigma(w_j^\\top x_i + b_j).\n$$\n平方损失下的经验风险最小化问题旨在寻找最小化 $\\sum_{i=1}^n (\\hat{y}(x_i) - y_i)^2$ 的 $a$，这是一个线性最小二乘问题。最小范数解由 Moore–Penrose 伪逆给出：\n$$\na^\\star = \\Phi^+ y,\n$$\n其中 $y = (y_1, \\ldots, y_n)^\\top$ 且 $\\Phi^+$ 表示 $\\Phi$ 的伪逆。当训练均方误差变为零时，达到插值阈值，这通常在 $m$ 增大使得 $\\Phi$ 达到满行秩时发生，从而系统 $\\Phi a = y$ 有解。参数-样本比率定义为 $p/n$，其中 $p$ 是训练参数的数量。在此设置中，$p = m$。\n\n双下降现象指的是一种典型行为，即测试误差作为模型容量的函数，最初减少，然后在插值阈值（训练误差降至零的位置）附近增加，当容量进一步增加超过该阈值后再次减少。你的程序将从一个教师网络构建合成数据，并在一系列对应不同参数-样本比率的 $m$ 值上测量测试均方误差。\n\n数据生成与评估协议：\n- 从标准正态分布中独立抽取输入 $x \\in \\mathbb{R}^d$。\n- 使用一个具有少量 ReLU 单元的固定教师网络生成标签：\n$$\ny = \\sum_{k=1}^{m_{\\text{teacher}}} \\beta_k \\, \\sigma(u_k^\\top x + c_k) + \\varepsilon,\n$$\n其中 $u_k \\in \\mathbb{R}^d$、$c_k \\in \\mathbb{R}$ 和 $\\beta_k \\in \\mathbb{R}$ 是固定的教师参数，$\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$ 是标准差为 $\\sigma$ 的独立高斯噪声。使用 $m_{\\text{teacher}} = 5$。\n- 对于每个选定的 $m$，通过计算 $a^\\star = \\Phi^+ y$ 来训练学生 MLP。\n- 计算训练均方误差\n$$\n\\mathrm{MSE}_{\\text{train}}(m) = \\frac{1}{n} \\sum_{i=1}^n \\left(\\hat{y}(x_i) - y_i \\right)^2,\n$$\n和在一个大小为 $n_{\\text{test}}$ 的独立测试集上的测试均方误差，\n$$\n\\mathrm{MSE}_{\\text{test}}(m) = \\frac{1}{n_{\\text{test}}} \\sum_{i=1}^{n_{\\text{test}}} \\left(\\hat{y}(x_i^{\\text{test}}) - y_i^{\\text{test}} \\right)^2.\n$$\n设置 $n_{\\text{test}} = \\max\\{3n, 200\\}$。\n\n插值阈值与峰值检测：\n- 定义插值容差 $\\epsilon = 10^{-10}$ 和峰值裕度 $\\delta = 0.1$（意为 $10\\%$）。\n- 对于给定的 $n$ 和一系列 $m$ 值，将插值阈值 $m_{\\text{interp}}$ 定义为该系列中满足 $\\mathrm{MSE}_{\\text{train}}(m) \\le \\epsilon$ 的最小 $m$。\n- 如果在插值阈值处的 $\\mathrm{MSE}_{\\text{test}}(m_{\\text{interp}})$ 超过所有其他 $m$ 值的 $\\mathrm{MSE}_{\\text{test}}(m)$ 的中位数至少 $(1+\\delta)$ 倍，则定义为出现峰值。形式上，如果\n$$\n\\mathrm{MSE}_{\\text{test}}(m_{\\text{interp}}) > (1 + \\delta) \\cdot \\operatorname{median}\\left(\\{\\mathrm{MSE}_{\\text{test}}(m) : m \\in \\mathcal{M}, m \\ne m_{\\text{interp}}\\}\\right),\n$$\n则输出布尔值 $\\mathrm{True}$；否则输出 $\\mathrm{False}$。如果扫描范围内的 $m$ 没有达到插值条件，则输出 $\\mathrm{False}$。\n\n扫描设计：\n- 对每个测试用例，通过将 $n$ 与比率 $\\{0.5, 0.8, 1.0, 1.2, 1.5\\}$ 相乘并四舍五入到最近的整数来构建隐藏单元数列表 $\\mathcal{M}$，并确保 $m \\ge 1$。即，\n$$\n\\mathcal{M} = \\left\\{ \\max\\left(1, \\left\\lfloor r \\cdot n \\right\\rceil \\right) : r \\in \\{0.5, 0.8, 1.0, 1.2, 1.5\\} \\right\\}.\n$$\n在单个测试用例中，确保所有学生模型的隐藏层参数 $\\{(w_j, b_j)\\}_{j=1}^{m_{\\max}}$ 在最大的 $m_{\\max} = \\max \\mathcal{M}$ 处一次性固定，而较小的 $m$ 的模型重用前 $m$ 个特征，以使扫描具有可比性。\n\n测试套件：\n在以下四个测试用例上运行你的程序。对每个用例，报告一个布尔值，指示是否根据上述规则检测到插值阈值处的峰值。每个用例使用独立的随机种子来确定性地固定所有随机性。\n\n- 用例 $1$：$n = 60$， $d = 20$， $\\sigma = 0.5$， $\\text{seed} = 0$。\n- 用例 $2$：$n = 60$， $d = 20$， $\\sigma = 0.0$， $\\text{seed} = 1$。\n- 用例 $3$：$n = 24$， $d = 8$， $\\sigma = 0.5$， $\\text{seed} = 2$。\n- 用例 $4$：$n = 80$， $d = 30$， $\\sigma = 0.8$， $\\text{seed} = 3$。\n\n最终输出格式：\n你的程序应产生一行输出，其中包含一个用方括号括起来的逗号分隔列表的结果，例如 $\\left[\\mathrm{result}_1,\\mathrm{result}_2,\\mathrm{result}_3,\\mathrm{result}_4\\right]$，其中每个 $\\mathrm{result}_i$ 是对应于用例 $i$ 的峰值检测结果的 $\\mathrm{True}$ 或 $\\mathrm{False}$。", "solution": "问题陈述是有效的。它具有科学依据，问题设定良好、客观，并为在随机特征模型中对双下降现象进行实证研究提供了一套完整且一致的指令。没有矛盾、歧义或事实不准确之处。因此，我们可以着手解决。\n\n目标是凭经验研究简化多层感知机（MLP）中的双下降现象。这种现象描述了测试误差作为模型容量的函数，呈现出先是 U 形，然后向下倾斜的曲线。最初的下降对应于欠参数化区域中经典的偏差-方差权衡。测试误差随后在插值阈值附近达到峰值，此时模型刚好有足够的容量来完美拟合训练数据。超过此点后，在过参数化区域，测试误差出人意料地再次下降。\n\n该方法论被构建为一个基于教师-学生框架的受控数值实验。\n\n**1. 模型设定与训练**\n\n模型是一个带有修正线性单元（ReLU）激活函数 $\\sigma(z) = \\max\\{0, z\\}$ 的两层前馈网络。对于一个输入 $x \\in \\mathbb{R}^d$，输出为 $\\hat{y}(x) = a^\\top \\phi(x)$，其中 $\\phi(x) = (\\sigma(w_1^\\top x + b_1), \\ldots, \\sigma(w_m^\\top x + b_m))$ 是特征激活向量。这个问题的关键在于，隐藏层参数 $\\{w_j, b_j\\}_{j=1}^m$ 在随机初始化后是固定的。只有输出层权重 $a \\in \\mathbb{R}^m$ 被训练。这将非线性的神经网络问题转化为高维特征空间中的线性回归问题，即所谓的随机特征模型。隐藏单元的数量 $m$ 直接对应于可训练参数的数量，并作为我们衡量模型容量的标准。\n\n给定 $n$ 个训练样本 $\\{(x_i, y_i)\\}_{i=1}^n$，我们构建设计矩阵 $\\Phi \\in \\mathbb{R}^{n \\times m}$，其中每个元素为 $\\Phi_{ij} = \\sigma(w_j^\\top x_i + b_j)$。目标是找到最小化平方损失 $\\mathcal{L}(a) = \\sum_{i=1}^n (y_i - a^\\top \\phi(x_i))^2 = \\|y - \\Phi a\\|_2^2$ 的权重向量 $a$。\n\n这个线性最小二乘问题的解，同时具有最小欧几里得范数 $\\|a\\|_2$，由 $a^\\star = \\Phi^+ y$ 给出。此处，$\\Phi^+$ 是设计矩阵 $\\Phi$ 的 Moore-Penrose 伪逆，而 $y = (y_1, \\ldots, y_n)^\\top$ 是训练标签的向量。伪逆为任何形状的 $\\Phi$ 提供了一个唯一的、稳定的解，正确地处理了欠参数化（$m  n$，通常为满列秩）和过参数化（$m > n$，通常为满行秩）两种情况。\n\n**2. 数据生成与评估**\n\n我们采用教师-学生设置来创建一个具有已知真实值的合成数据集。\n- 一个固定的“教师”网络，其架构相同，具有 $m_{\\text{teacher}} = 5$ 个隐藏单元，生成标签：$y = \\sum_{k=1}^{m_{\\text{teacher}}} \\beta_k \\, \\sigma(u_k^\\top x + c_k) + \\varepsilon$。输入向量 $x \\in \\mathbb{R}^d$ 从标准正态分布中抽取。高斯噪声 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$ 被添加到输出中，以模拟固有的测量误差或未建模效应。\n- 然后，一个“学生”模型（我们的可训练模型）在 $n$ 个这样的数据点集上进行训练。\n- 训练后的学生模型的性能通过在训练集和一个独立的、更大的测试集（大小为 $n_{\\text{test}} = \\max\\{3n, 200\\}$）上计算均方误差（MSE）来评估。\n  - $\\mathrm{MSE}_{\\text{train}}(m) = \\frac{1}{n} \\|\\Phi a^\\star - y\\|^2$\n  - $\\mathrm{MSE}_{\\text{test}}(m) = \\frac{1}{n_{\\text{test}}} \\| \\Phi_{\\text{test}} a^\\star - y_{\\text{test}}\\|^2$\n\n**3. 实验流程与峰值检测**\n\n实验的核心是当我们扫描模型容量 $m$ 时，跟踪 $\\mathrm{MSE}_{\\text{test}}(m)$。问题定义了一个特定的扫描协议：容量集合 $\\mathcal{M}$ 是通过将样本数量 $n$ 乘以比率 $\\{0.5, 0.8, 1.0, 1.2, 1.5\\}$ 生成的。这组比率旨在探测模型在欠参数化区域（$m/n  1$）、插值阈值（$m/n \\approx 1$）和过参数化区域（$m/n > 1$）的行为。为了确保整个扫描过程中的结果具有可比性，最大模型（$m_{\\max} = \\max \\mathcal{M}$）的随机特征只生成一次，而较小的模型仅使用这些特征的一个子集。\n\n双下降假说预测，在模型首次完美拟合训练数据的点附近，$\\mathrm{MSE}_{\\text{test}}$ 会出现一个峰值。这个点被形式化为插值阈值 $m_{\\text{interp}}$，定义为满足 $\\mathrm{MSE}_{\\text{train}}(m) \\le \\epsilon$ 的最小 $m \\in \\mathcal{M}$，其中容差 $\\epsilon = 10^{-10}$ 很小。\n\n如果在该阈值处的测试误差显著高于其他容量下的典型测试误差，则称检测到一个“峰值”。该条件由不等式给出：\n$$\n\\mathrm{MSE}_{\\text{test}}(m_{\\text{interp}}) > (1 + \\delta) \\cdot \\operatorname{median}\\left(\\{\\mathrm{MSE}_{\\text{test}}(m) : m \\in \\mathcal{M}, m \\ne m_{\\text{interp}}\\}\\right)\n$$\n其中峰值裕度为 $\\delta = 0.1$。如果满足此条件，则该测试用例的结果为 $\\mathrm{True}$；否则为 $\\mathrm{False}$。如果扫描中没有 $m$ 达到插值，结果也为 $\\mathrm{False}$。\n\n实现将对四个指定的测试用例中的每一个执行整个过程，使用给定的随机种子以保证可复现性，并报告峰值检测测试的布尔结果。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_single_case(n, d, sigma, seed):\n    \"\"\"\n    Runs a single simulation case for the double descent experiment.\n    \n    Args:\n        n (int): Number of training samples.\n        d (int): Input dimension.\n        sigma (float): Standard deviation of label noise.\n        seed (int): Random seed for reproducibility.\n\n    Returns:\n        bool: True if a spike is detected, False otherwise.\n    \"\"\"\n    np.random.seed(seed)\n\n    # 1. Generate Teacher Network\n    m_teacher = 5\n    u_teacher = np.random.randn(m_teacher, d)\n    c_teacher = np.random.randn(m_teacher)\n    beta_teacher = np.random.randn(m_teacher)\n    \n    def teacher_model(X):\n        activations = np.maximum(0, X @ u_teacher.T + c_teacher)\n        return activations @ beta_teacher\n\n    # 2. Generate Training and Test Data\n    X_train = np.random.randn(n, d)\n    noise_train = sigma * np.random.randn(n)\n    y_train = teacher_model(X_train) + noise_train\n\n    n_test = max(3 * n, 200)\n    X_test = np.random.randn(n_test, d)\n    noise_test = sigma * np.random.randn(n_test)\n    y_test = teacher_model(X_test) + noise_test\n\n    # 3. Define Model Sweep\n    ratios = [0.5, 0.8, 1.0, 1.2, 1.5]\n    m_values = sorted([max(1, int(np.round(r * n))) for r in ratios])\n    m_max = m_values[-1]\n\n    # 4. Generate Student Network's Fixed Features\n    W_student = np.random.randn(m_max, d)\n    b_student = np.random.randn(m_max)\n\n    train_mses = []\n    test_mses = []\n\n    # 5. Sweep through model capacities (m)\n    for m in m_values:\n        # Select the first m features\n        W_m = W_student[:m, :]\n        b_m = b_student[:m]\n        \n        # Construct design matrix for training\n        Phi_train = np.maximum(0, X_train @ W_m.T + b_m)\n        \n        # Train model using Moore-Penrose pseudoinverse\n        # a_star = pinv(Phi_train) @ y_train\n        a_star = np.linalg.pinv(Phi_train) @ y_train\n        \n        # Evaluate Training MSE\n        y_train_pred = Phi_train @ a_star\n        train_mse = np.mean((y_train_pred - y_train) ** 2)\n        train_mses.append(train_mse)\n        \n        # Evaluate Test MSE\n        Phi_test = np.maximum(0, X_test @ W_m.T + b_m)\n        y_test_pred = Phi_test @ a_star\n        test_mse = np.mean((y_test_pred - y_test) ** 2)\n        test_mses.append(test_mse)\n\n    # 6. Analyze Results for Spike Detection\n    epsilon = 1e-10\n    delta = 0.1\n    \n    np_train_mses = np.array(train_mses)\n    np_test_mses = np.array(test_mses)\n    \n    # Find interpolation threshold m_interp\n    interp_indices = np.where(np_train_mses = epsilon)[0]\n    \n    if len(interp_indices) == 0:\n        # No model achieved interpolation\n        return False\n        \n    idx_interp = interp_indices[0]\n    # m_interp = m_values[idx_interp] # not needed for calculation\n    mse_test_at_interp = np_test_mses[idx_interp]\n\n    # Get test MSEs for all other m values\n    other_indices = np.arange(len(m_values)) != idx_interp\n    other_test_mses = np_test_mses[other_indices]\n\n    if len(other_test_mses) == 0:\n        return False\n\n    median_other_mses = np.median(other_test_mses)\n    \n    # Check for spike condition\n    is_spike = mse_test_at_interp > (1 + delta) * median_other_mses\n    \n    return is_spike\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = [\n        # (n, d, sigma, seed)\n        (60, 20, 0.5, 0),\n        (60, 20, 0.0, 1),\n        (24, 8, 0.5, 2),\n        (80, 30, 0.8, 3),\n    ]\n\n    results = []\n    for case in test_cases:\n        n, d, sigma, seed = case\n        result = run_single_case(n, d, sigma, seed)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3151120"}, {"introduction": "我们已经观察到测试误差在插值阈值附近出现峰值。但这个峰值是由什么引起的？又有哪些因素会影响它的高度？这个峰值主要是一种由方差驱动的现象。本实践将探究不同来源的随机性——数据标签中的噪声与输入特征中的噪声——如何影响模型的稳定性，并最终影响测试误差。通过在理论和实验上对比这两种情况，你将对过参数化区域中的偏差-方差权衡有更深刻的直观理解，并明白为何标签噪声通常会导致更显著的误差峰值。[@problem_id:3183597]", "problem": "要求您从第一性原理出发，并通过实验研究在线性回归的双下降（double descent）现象中，训练时输入噪声与训练时标签噪声如何影响出现在插值阈值附近的测试风险曲线峰值的高度。您必须预测哪种类型的噪声会产生更高的峰值，并通过模拟一个具有各向同性高斯（Gaussian）特征的师生（teacher-student）线性模型，在模型复杂度增加时计算样本外均方误差，来实验性地验证您的预测。\n\n基本基础和设置：\n- 考虑一个固定的未知参数向量 $\\beta \\in \\mathbb{R}^m$ 和一个输入向量 $x \\in \\mathbb{R}^m$，其坐标是独立同分布的标准正态随机变量。无噪声的教师函数为 $f^\\star(x) = x^\\top \\beta$。\n- 您将通过最小化训练误差来训练一个线性预测器 $\\hat{f}(x) = x^\\top \\hat{w}$，并在所有插值解中选择具有最小欧几里得范数的解（即，最小范数插值线性回归器）。您将在一系列范围内改变模型参数 $m$ 的数量，该范围会扫过 $m \\approx n$ 附近的插值阈值，其中 $n$ 是训练样本的数量。\n- 必须在相同条件下比较两种训练时噪声模型，噪声标准差为 $\\sigma$：\n  1. 标签噪声：干净的输入和带噪声的标签，训练标签为 $y = f^\\star(x) + \\eta$，其中 $\\eta \\sim \\mathcal{N}(0,\\sigma^2)$ 且独立于 $x$。\n  2. 输入噪声：带噪声的输入和干净的标签，观测到的训练输入为 $x_{\\text{obs}} = x + \\xi$，其中 $\\xi \\sim \\mathcal{N}(0,\\sigma^2 I_m)$ 且独立于 $x$，训练标签为 $y = f^\\star(x)$。\n- 在两种情况下，都使用干净的测试输入，评估相对于无噪声教师函数 $f^\\star$ 的样本外均方误差。也就是说，对于一个学习到的 $\\hat{w}$ 和一个新的干净测试输入矩阵 $X_{\\text{test}}$，将测试风险计算为 $(x^\\top \\hat{w} - x^\\top \\beta)^2$ 在所有测试输入 $x$ 上的经验平均值。\n\n设计要求：\n- 从以下基础开始您的推导：均方误差的偏差-方差分解、线性模型 $f^\\star(x)=x^\\top \\beta$ 以及最小范数插值解在线性回归中的性质。不要调用任何特定于双下降的快捷公式；相反，应从这些原理出发进行论证，解释为什么在插值阈值附近会出现峰值，以及两种噪声机制如何不同地影响峰值高度。\n- 您的程序必须模拟两种噪声模型，在指定的网格上扫描 $m$，为每个 $m$ 计算多次独立试验的平均测试均方误差，并为每个测试用例报告标签噪声下的峰值测试误差是否高于输入噪声下的峰值测试误差。\n\n测试套件：\n对下述每个测试用例，使用相应的参数 $(n, \\{m\\text{-grid}\\}, \\sigma, T, s)$，其中 $n$ 是训练样本数量，$\\{m\\text{-grid}\\}$ 是要评估的模型大小集合，$\\sigma$ 是噪声标准差，$T$ 是用于平均的独立试验次数，$s$ 是用于初始化随机数生成器的随机种子。对于网格中的每个 $m$，抽取一个新的 $\\beta \\in \\mathbb{R}^m$，其坐标独立同分布于 $\\beta_j \\sim \\mathcal{N}(0, 1/m)$（以使得 $\\mathbb{E}[f^\\star(x)^2] \\approx 1$），生成一个有 $n$ 行的训练设计矩阵和一个有 $n_{\\text{test}}$ 行的测试设计矩阵，其中 $n_{\\text{test}} = 1000$。在标签噪声条件下，仅向训练标签添加标准差为 $\\sigma$ 的标签噪声；在输入噪声条件下，仅向训练输入添加标准差为 $\\sigma$ 的输入噪声。评估时，始终使用干净的测试输入和无噪声的教师函数 $f^\\star$。\n\n您必须完全按照以下方式实现最小范数插值线性回归器：对于一个训练矩阵 $X \\in \\mathbb{R}^{n \\times m}$ 和训练标签 $y \\in \\mathbb{R}^n$，如果 $m \\le n$，则通过正规方程组 $\\hat{w} = (X^\\top X)^{-1} X^\\top y$ 计算 $\\hat{w}$（并使用一个小的岭正则化项以确保数值稳定性）；如果 $m > n$，则通过 $\\hat{w} = X^\\top (X X^\\top)^{-1} y$ 计算最小范数插值解（同样使用一个小的岭回归项以保证稳定性）。岭回归项必须是一个极小的正标量（例如，$10^{-9}$），仅用于确保数值稳定性，而不是进行有意义的正则化。\n\n为以下三个测试用例提供结果：\n- 测试用例 A: $n = 100$, $\\{m\\text{-grid}\\} = \\{10, 20, 30, \\dotsc, 200\\}$, $\\sigma = 0.5$, $T = 6$, $s = 1729$。\n- 测试用例 B: $n = 60$, $\\{m\\text{-grid}\\} = \\{6, 12, 18, \\dotsc, 120\\}$, $\\sigma = 1.0$, $T = 6$, $s = 2027$。\n- 测试用例 C: $n = 120$, $\\{m\\text{-grid}\\} = \\{12, 24, 36, \\dotsc, 240\\}$, $\\sigma = 0.25$, $T = 6$, $s = 9811$。\n\n预测与验证：\n- 根据您的推导，预测哪种噪声类型应在插值阈值附近产生更高的峰值。然后，为每个测试用例，计算在标签噪声和输入噪声下，$m$ 网格上的最大测试均方误差。为每个测试用例输出一个整数指示符，如果标签噪声的峰值严格高于输入噪声的峰值，则为 $1$，否则为 $0$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，“[1,0,1]”），按 A、B、C 的顺序对应三个测试用例的结果。不应打印任何其他文本。", "solution": "此问题要求从第一性原理出发，分析在线性回归的双下降（double descent）现象背景下，标签噪声与输入噪声对测试风险曲线峰值的比较效应。必须做出预测，然后通过数值实验进行验证。\n\n### 理论推导\n\n我们首先建立分析框架。对于一个学习到的权重向量 $\\hat{w} \\in \\mathbb{R}^m$ 和一个真实的参数向量 $\\beta \\in \\mathbb{R}^m$，其样本外均方误差（或称测试风险）由对干净测试数据 $x \\sim \\mathcal{N}(0, I_m)$ 的期望给出：\n$$\nR(\\hat{w}) = \\mathbb{E}_{x} \\left[ (x^\\top \\hat{w} - x^\\top \\beta)^2 \\right]\n$$\n鉴于输入特征是各向同性的，即 $\\mathbb{E}[x x^\\top] = I_m$，风险简化为估计权重向量与真实权重向量之间欧几里得距离平方的期望，其中期望是针对训练数据 $\\mathcal{D}$ 的分布：\n$$\nR(\\hat{w}) = \\mathbb{E}_{\\mathcal{D}} \\left[ (\\hat{w} - \\beta)^\\top \\mathbb{E}[x x^\\top] (\\hat{w} - \\beta) \\right] = \\mathbb{E}_{\\mathcal{D}} \\left[ \\|\\hat{w} - \\beta\\|^2 \\right]\n$$\n该风险可以分解为偏差平方和方差。令 $\\bar{w} = \\mathbb{E}_{\\mathcal{D}}[\\hat{w}]$ 为平均估计权重向量。分解如下：\n$$\nR(\\hat{w}) = \\underbrace{\\|\\bar{w} - \\beta\\|^2}_{\\text{偏差}^2} + \\underbrace{\\mathbb{E}_{\\mathcal{D}}\\left[\\|\\hat{w} - \\bar{w}\\|^2\\right]}_{\\text{方差}}\n$$\n“双下降”曲线描述了当模型复杂度（由特征数量 $m$ 相对于训练样本数量 $n$ 参数化）增加时，该风险的非单调行为。一个特征峰出现在插值阈值处，即 $m \\approx n$。这个峰值主要是一个由方差驱动的现象，源于训练数据矩阵的病态性（ill-conditioning）。我们的分析将集中于每种噪声模型如何影响这个方差项。\n\n指定的估计器是最小范数线性回归器。对于一个训练数据矩阵 $A \\in \\mathbb{R}^{n \\times m}$ 和标签 $y \\in \\mathbb{R}^n$，估计的权重 $\\hat{w}$ 为：\n$$\n\\hat{w} =\n\\begin{cases}\n    (A^\\top A)^{-1} A^\\top y   \\text{如果 } m \\le n \\text{ (欠参数化)} \\\\\n    A^\\top (A A^\\top)^{-1} y   \\text{如果 } m > n \\text{ (过参数化)}\n\\end{cases}\n$$\n在数值计算上，为了确保稳定性，会添加一个小的岭正则化项 $\\lambda I$（其中 $\\lambda \\to 0^+$）到被求逆的矩阵中。\n\n#### 情况 1：标签噪声\n\n在这种情况下，训练数据由干净的输入 $X \\in \\mathbb{R}^{n \\times m}$ 和带噪声的标签 $y = X\\beta + \\eta$ 组成，其中 $\\eta \\sim \\mathcal{N}(0, \\sigma^2 I_n)$。回归器在 $(A, y) = (X, X\\beta + \\eta)$ 上进行训练。\n\n对于 $m \\le n$：\n$$\n\\hat{w}_{\\text{label}} = (X^\\top X)^{-1} X^\\top (X\\beta + \\eta) = \\beta + (X^\\top X)^{-1} X^\\top \\eta\n$$\n估计器相对于噪声是无偏的，即 $\\mathbb{E}_{\\eta}[\\hat{w}_{\\text{label}}] = \\beta$。风险完全来自方差：\n$$\nR(\\hat{w}_{\\text{label}}) = \\mathbb{E}_{X, \\eta} \\left[ \\|(X^\\top X)^{-1} X^\\top \\eta\\|^2 \\right] = \\mathbb{E}_{X} \\left[ \\text{Tr}\\left( (X^\\top X)^{-1} X^\\top \\mathbb{E}_{\\eta}[\\eta\\eta^\\top] X (X^\\top X)^{-1} \\right) \\right]\n$$\n因为 $\\mathbb{E}_{\\eta}[\\eta\\eta^\\top] = \\sigma^2 I_n$，这可以简化为：\n$$\nR(\\hat{w}_{\\text{label}}) = \\sigma^2 \\mathbb{E}_{X} \\left[ \\text{Tr}\\left( (X^\\top X)^{-1} \\right) \\right]\n$$\n矩阵 $X^\\top X$ 是一个 Wishart 矩阵。当 $m \\to n^-$ 时，其最小特征值趋近于零，导致其逆的迹（trace）爆炸。这导致了测试风险的特征峰。对 $m > n$ 进行类似分析，得到的风险贡献与 $\\sigma^2 \\mathbb{E}_{X} \\left[ \\text{Tr}\\left( (X X^\\top)^{-1} \\right) \\right]$ 成正比，当 $m \\to n^+$ 时同样会发散。因此，峰值与噪声方差 $\\sigma^2$ 以及一个与数据矩阵病态性相关的放大因子成正比。\n\n#### 情况 2：输入噪声\n\n在这里，训练数据由带噪声的输入 $X_{\\text{obs}} = X_{\\text{true}} + \\Xi$ 和干净的标签 $y = X_{\\text{true}}\\beta$ 组成。随机矩阵 $\\Xi \\in \\mathbb{R}^{n \\times m}$ 包含独立同分布的噪声元素 $\\Xi_{ij} \\sim \\mathcal{N}(0, \\sigma^2)$。回归器在 $(A, y) = (X_{\\text{obs}}, X_{\\text{true}}\\beta)$ 上进行训练。\n\n我们可以将其重构为一个等效的标签噪声问题。目标标签可以用观测到的输入来表示：\n$$\ny = X_{\\text{true}}\\beta = (X_{\\text{obs}} - \\Xi)\\beta = X_{\\text{obs}}\\beta - \\Xi\\beta\n$$\n这表明，在 $(X_{\\text{obs}}, y)$ 上训练线性模型等价于在数据 $(X_{\\text{obs}}, X_{\\text{obs}}\\beta + \\eta')$ 上训练，其中“有效”标签噪声为 $\\eta' = -\\Xi\\beta$。\n\n让我们分析这个有效噪声 $\\eta'$。它是一个在 $\\mathbb{R}^n$ 中的向量。第 $i$ 个分量是 $\\eta'_i = -\\xi_i^\\top \\beta$，其中 $\\xi_i^\\top$ 是 $\\Xi$ 的第 $i$ 行。行向量 $\\xi_i$ 是独立的，所以噪声项 $\\eta'_i$ 也是独立的。每一项的方差是：\n$$\n\\text{Var}(\\eta'_i) = \\mathbb{E}_{\\Xi} [(\\xi_i^\\top \\beta)^2] = \\beta^\\top \\mathbb{E}_{\\Xi}[\\xi_i \\xi_i^\\top] \\beta = \\beta^\\top (\\sigma^2 I_m) \\beta = \\sigma^2 \\|\\beta\\|^2\n$$\n问题指定真实权重 $\\beta$ 的抽取方式使得 $\\mathbb{E}[\\|\\beta\\|^2] = \\mathbb{E}[\\sum_{j=1}^m \\beta_j^2] = \\sum_{j=1}^m (1/m) = 1$。因此，平均而言，有效标签噪声的方差是 $\\sigma^2$。这与情况 1 中显式标签噪声的方差相同。\n\n然而，关键的区别在于回归器使用的数据矩阵。对于 $m \\le n$，估计器为：\n$$\n\\hat{w}_{\\text{input}} = (X_{\\text{obs}}^\\top X_{\\text{obs}})^{-1} X_{\\text{obs}}^\\top y\n$$\n被求逆的矩阵是 $X_{\\text{obs}}^\\top X_{\\text{obs}}$，而不是 $X_{\\text{true}}^\\top X_{\\text{true}}$。$X_{\\text{true}}$ 的元素从 $\\mathcal{N}(0, 1)$ 中抽取，而 $\\Xi$ 的元素从 $\\mathcal{N}(0, \\sigma^2)$ 中抽取。由于它们是独立的，观测矩阵 $X_{\\text{obs}} = X_{\\text{true}} + \\Xi$ 的元素从 $\\mathcal{N}(0, 1+\\sigma^2)$ 中抽取。\n\n这意味着我们可以写出 $X_{\\text{obs}} = \\sqrt{1+\\sigma^2} Z$，其中 $Z$ 是一个具有独立同分布 $\\mathcal{N}(0, 1)$ 元素的矩阵，就像 $X_{\\text{true}}$ 一样。待求逆的矩阵变为：\n$$\nX_{\\text{obs}}^\\top X_{\\text{obs}} = (1+\\sigma^2) Z^\\top Z\n$$\n因此，$X_{\\text{obs}}^\\top X_{\\text{obs}}$ 的特征值比标准 Wishart 矩阵 $Z^\\top Z$（其谱分布与 $X_{\\text{true}}^\\top X_{\\text{true}}$ 相同）的特征值大一个因子 $(1+\\sigma^2)$。\n\n对于输入噪声，类似于情况 1，方差放大因子将正比于 $\\text{Tr}((X_{\\text{obs}}^\\top X_{\\text{obs}})^{-1})$。\n$$\n\\text{Tr}\\left( (X_{\\text{obs}}^\\top X_{\\text{obs}})^{-1} \\right) = \\text{Tr}\\left( ((1+\\sigma^2) Z^\\top Z)^{-1} \\right) = \\frac{1}{1+\\sigma^2} \\text{Tr}\\left( (Z^\\top Z)^{-1} \\right)\n$$\n比较峰值处风险的方差贡献：\n-   **标签噪声峰值高度** $\\propto \\sigma^2 \\cdot \\mathbb{E}[\\text{Tr}((X^\\top X)^{-1})]$\n-   **输入噪声峰值高度** $\\propto (\\sigma^2 \\mathbb{E}[\\|\\beta\\|^2]) \\cdot \\mathbb{E}[\\text{Tr}((X_{\\text{obs}}^\\top X_{\\text{obs}})^{-1})] \\approx \\sigma^2 \\cdot \\frac{1}{1+\\sigma^2} \\mathbb{E}[\\text{Tr}((Z^\\top Z)^{-1})]$\n\n由于 $\\sigma^2 > 0$，因子 $\\frac{1}{1+\\sigma^2}$ 严格小于 $1$。输入噪声具有自正则化效应：它增加了输入特征的方差，这使得样本协方差矩阵的条件更好，从而减少了伪逆对噪声的放大。尽管更详细的分析还会考虑偏差项（输入噪声会引入变量误差偏误），但插值阈值处的峰值主要由方差爆炸主导，而我们的分析表明，在输入噪声的情况下，这种爆炸被显著抑制了。\n\n### 预测\n\n基于此推导，在插值阈值 $m \\approx n$ 附近的测试风险峰值，对于相同的噪声标准差 $\\sigma$，**标签噪声将高于**输入噪声。问题中指定的数值实验将用于验证这一预测。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_w_hat(X, y, ridge_lambda):\n    \"\"\"\n    Computes the minimum-norm interpolating linear regressor.\n    - If m = n, computes via normal equations.\n    - If m > n, computes via dual form (minimum L2 norm solution).\n    A small ridge is added for numerical stability.\n    \"\"\"\n    n, m = X.shape\n    \n    if m = n:\n        # Under-parameterized or exactly determined case\n        # Solve (X.T @ X + lambda*I) w = X.T @ y\n        A = X.T @ X + ridge_lambda * np.identity(m)\n        b = X.T @ y\n        try:\n            w_hat = np.linalg.solve(A, b)\n        except np.linalg.LinAlgError:\n            # Fallback to pseudoinverse if solve fails despite ridge\n            w_hat = np.linalg.pinv(X) @ y\n    else:\n        # Over-parameterized case (minimum norm solution)\n        # Solve (X @ X.T + lambda*I) z = y, then w = X.T @ z\n        A = X @ X.T + ridge_lambda * np.identity(n)\n        try:\n            z = np.linalg.solve(A, y)\n            w_hat = X.T @ z\n        except np.linalg.LinAlgError:\n            w_hat = np.linalg.pinv(X) @ y\n            \n    return w_hat\n\ndef run_experiment(n, m_grid, sigma, T, s):\n    \"\"\"\n    Runs one full experiment for a given test case configuration.\n    \"\"\"\n    n_test = 1000\n    ridge_lambda = 1e-9\n    rng = np.random.default_rng(s)\n\n    mse_label_noise = np.zeros(len(m_grid))\n    mse_input_noise = np.zeros(len(m_grid))\n\n    for i, m in enumerate(m_grid):\n        trial_mses_label = []\n        trial_mses_input = []\n\n        for _ in range(T):\n            # Generate new data for each trial\n            \n            # 1. Generate true parameters and clean data\n            beta = rng.normal(0, 1 / np.sqrt(m), size=(m, 1))\n            X_true_train = rng.normal(0, 1, size=(n, m))\n            y_true_train = X_true_train @ beta\n            X_test = rng.normal(0, 1, size=(n_test, m))\n            y_test = X_test @ beta\n\n            # 2. Label Noise Simulation\n            eta = rng.normal(0, sigma, size=(n, 1))\n            y_train_label = y_true_train + eta\n            X_train_label = X_true_train\n            \n            w_hat_label = compute_w_hat(X_train_label, y_train_label, ridge_lambda)\n            mse_label = np.mean((X_test @ w_hat_label - y_test)**2)\n            trial_mses_label.append(mse_label)\n\n            # 3. Input Noise Simulation\n            Xi = rng.normal(0, sigma, size=(n, m))\n            X_train_input = X_true_train + Xi\n            y_train_input = y_true_train\n            \n            w_hat_input = compute_w_hat(X_train_input, y_train_input, ridge_lambda)\n            mse_input = np.mean((X_test @ w_hat_input - y_test)**2)\n            trial_mses_input.append(mse_input)\n\n        # Average MSE over trials for the current m\n        mse_label_noise[i] = np.mean(trial_mses_label)\n        mse_input_noise[i] = np.mean(trial_mses_input)\n\n    # Find the peak MSE for each noise type\n    peak_label = np.max(mse_label_noise)\n    peak_input = np.max(mse_input_noise)\n\n    return 1 if peak_label > peak_input else 0\n\ndef solve():\n    \"\"\"\n    Defines and runs the test cases, then prints the final result.\n    \"\"\"\n    test_cases = [\n        # (n, m-grid, sigma, T, s)\n        (100, list(range(10, 201, 10)), 0.5, 6, 1729),   # Test Case A\n        (60, list(range(6, 121, 6)), 1.0, 6, 2027),      # Test Case B\n        (120, list(range(12, 241, 12)), 0.25, 6, 9811),  # Test Case C\n    ]\n\n    results = []\n    for n, m_grid, sigma, T, s in test_cases:\n        result = run_experiment(n, m_grid, sigma, T, s)\n        results.append(result)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3183597"}, {"introduction": "双下降现象不仅与模型大小有关，它也会在单个大型模型的训练过程中随时间推移而出现，这被称为“周期性双下降”（epoch-wise double descent）。本实践使用一个巧妙的模型来模拟这一动态过程，该模型包含两种类型的特征：“泛化”特征用于学习潜在的数据模式，“记忆”特征用于拟合特定的、可能含有噪声的训练样本。通过实施一个特定的训练策略，你将观察到一个模型如何先学习通用规则，然后通过记忆训练数据来过拟合（导致测试误差上升），最后“忘记”噪声以恢复并提高其泛化能力（即第二次下降）。这个练习将抽象的双下降概念与现代深度学习模型（如 Transformer）的实际训练动态联系起来。[@problem_id:3183606]", "problem": "您需要构建一个有科学依据的仿真，用于研究在一个小型语言建模任务上训练的 Transformer 代理模型中，逐周期（epoch-wise）出现的双下降现象。目标是将训练动态与插值联系起来，并量化测试交叉熵在各个训练周期（epoch）中的行为。您的实现必须是一个完整的、可运行的程序，能够根据给定的测试套件生成指定的最终输出，且无需用户输入。\n\n从以下基础定义和事实开始：\n- 监督学习的经验风险最小化考虑一个数据集 $\\{(x_i, y_i)\\}_{i=1}^{n}$ 和一个参数为 $\\theta$ 的模型，该模型输出类别概率 $p_\\theta(y \\mid x)$。在多分类交叉熵下的经验风险为\n$$\n\\mathcal{L}_{\\text{emp}}(\\theta) = \\frac{1}{n} \\sum_{i=1}^{n} -\\log\\left( p_\\theta(y_i \\mid x_i) \\right).\n$$\n- 对于 logits $z \\in \\mathbb{R}^K$ 的 softmax 函数定义为\n$$\n\\text{softmax}(z)_k = \\frac{e^{z_k}}{\\sum_{j=1}^{K} e^{z_j}} \\quad \\text{for } k \\in \\{1,\\dots,K\\}.\n$$\n- 对于一个权重矩阵为 $W \\in \\mathbb{R}^{K \\times F}$、特征向量为 $x \\in \\mathbb{R}^F$ 的线性 softmax 分类器，其 logits 为 $z = W x$，预测的类别概率为 $p(y \\mid x) = \\text{softmax}(W x)$。\n- 对于单个样本 $(x,y)$（其独热类别向量为 $e_y \\in \\mathbb{R}^K$），交叉熵损失函数关于 $W$ 的梯度为\n$$\n\\nabla_W \\ell(W; x,y) = \\left( p - e_y \\right) x^\\top, \\quad \\text{where } p = \\text{softmax}(W x).\n$$\n- 当训练分类准确率达到 $1.0$（或实际上达到一个近乎完美的阈值）时，即发生插值现象，这意味着模型完全拟合了所有的训练标签；在交叉熵损失的背景下，这对应于 logits 能够将训练数据分开，使得每个样本的预测类别都与 $y_i$ 匹配。\n\n您将使用一阶马尔可夫（二元语法）过程生成序列，以模拟一个词汇表大小为 $V$ 的下一词元（next-token）语言建模任务。设 $P \\in \\mathbb{R}^{V \\times V}$ 为一个二元语法矩阵，其中 $P_{ij} = \\Pr(\\text{在时间 } t \\text{ 的词元} = i \\mid \\text{在时间 } t-1 \\text{ 的词元} = j)$，且每一列 $j$ 的总和为 $1$。\n\n定义一个代理的“类 Transformer”模型，包含两个特征组：\n- 可泛化特征 $x^{\\text{gen}} \\in \\mathbb{R}^{V}$，由前一个词元的独热编码给出。\n- 记忆特征 $x^{\\text{mem}} \\in \\mathbb{R}^{M}$，是与每个训练样本唯一绑定的独热特征；这些特征存在于训练样本中，但在测试样本中为零。完整的特征向量为 $x = \\left[ x^{\\text{gen}}, x^{\\text{mem}} \\right] \\in \\mathbb{R}^{V+M}$。\n\n使用全批量梯度下降法，在交叉熵损失上训练一个权重为 $W \\in \\mathbb{R}^{V \\times (V+M)}$ 的线性 softmax 分类器，共训练 $T$ 个周期。采用分段常数的逐周期学习率方案，为两个参数块 $W^{\\text{gen}} \\in \\mathbb{R}^{V \\times V}$ 和 $W^{\\text{mem}} \\in \\mathbb{R}^{V \\times M}$ 分配不同的学习率：\n- 早期阶段（周期比例 $t/T \\in [0,1/3)$）：为 $W^{\\text{gen}}$ 设置较大的学习率，为 $W^{\\text{mem}}$ 设置较小的学习率。\n- 中期阶段（$t/T \\in [1/3,2/3)$）：为 $W^{\\text{gen}}$ 设置较小的学习率，为 $W^{\\text{mem}}$ 设置较大的学习率，以通过记忆特征驱动插值。\n- 后期阶段（$t/T \\in [2/3,1]$）：为 $W^{\\text{gen}}$ 设置较大的学习率，并将 $W^{\\text{mem}}$ 的学习率设为 $0$；在后期阶段对 $W^{\\text{mem}}$ 应用更强的 $\\ell_2$ 权重衰减，以减少对记忆特征的依赖，并为 $W^{\\text{gen}}$ 重新引入梯度信号。为清晰起见，权重衰减对应于在损失函数中增加一个惩罚项 $\\frac{\\lambda}{2} \\lVert W \\rVert_2^2$，这会产生一个应用于权重的逐周期收缩因子。\n\n数据生成：\n- 通过从狄利克雷（Dirichlet）分布中抽取每一列来采样一个二元语法矩阵 $P$，以确保列是随机的（stochastic columns）。使用二元语法过程生成 $n_{\\text{train}}$ 个训练对 $(x_i, y_i)$ 和 $n_{\\text{test}}$ 个测试对 $(\\tilde{x}_j, \\tilde{y}_j)$，其中 $x_i^{\\text{gen}}$ 和 $\\tilde{x}_j^{\\text{gen}}$ 是独热编码的前一个词元，$y_i$ 和 $\\tilde{y}_j$ 是下一个词元。向训练标签中注入一小部分比例为 $\\rho$ 的标签噪声，即随机替换 $\\rho$ 比例训练样本的 $y_i$，以模拟记忆特征可以拟合的伪相关性。\n\n训练、跟踪与检测：\n- 在每个周期 $t$，计算平均训练交叉熵和训练准确率，以及测试交叉熵和测试准确率。\n- 定义插值周期 $t_\\star$ 为训练准确率 $\\geq 0.99$ 的最早周期。如果不存在这样的周期，则声明未发生插值。\n- 定义一个早期检查点 $t_a = \\lfloor 0.2 T \\rfloor$ 和最终周期 $T$。\n- 将逐周期双下降检测定义为以下条件：插值周期 $t_\\star$ 处的测试交叉熵 $L_{\\text{test}}(t_\\star)$ 严格大于 $L_{\\text{test}}(t_a)$ 和 $L_{\\text{test}}(T)$，并且 $L_{\\text{test}}(T)$ 严格小于 $L_{\\text{test}}(t_a)$。形式上，如果\n$$\nL_{\\text{test}}(t_\\star) > \\max\\left( L_{\\text{test}}(t_a), L_{\\text{test}}(T) \\right) \\quad \\text{and} \\quad L_{\\text{test}}(T)  L_{\\text{test}}(t_a),\n$$\n则报告 True，否则报告 False；如果未发生插值，则报告 False。\n\n您的程序必须实现上述内容并运行以下测试套件，每个测试由 $(V, n_{\\text{train}}, n_{\\text{test}}, M, T)$ 指定：\n1. $(8, 150, 500, 0, 180)$: 无记忆特征的欠参数化基线；插值不应发生。\n2. $(8, 150, 500, 150, 180)$: 平衡的过参数化，其中记忆特征数量与训练样本数匹配。\n3. $(8, 100, 500, 300, 180)$: 严重过参数化的记忆特征；具有更强的插值趋势。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，“[result1,result2,result3]”），每个结果是一个布尔值，指示相应测试用例是否检测到逐周期双下降。此任务不需要单位。输出必须是只有一行，没有额外文本。", "solution": "用户问题要求在一个简化的语言模型设置中，对逐周期双下降现象进行仿真。该过程包括生成合成数据，使用特定的特征和训练方案来训练一个线性模型，然后分析测试损失曲线以寻找双下降的特定标志。\n\n### 步骤 1：问题验证\n\n首先，我将验证问题陈述。\n\n#### 提取的已知条件\n- **损失函数**：多分类交叉熵，$\\mathcal{L}_{\\text{emp}}(\\theta) = \\frac{1}{n} \\sum_{i=1}^{n} -\\log\\left( p_\\theta(y_i \\mid x_i) \\right)$。\n- **模型**：线性 softmax 分类器，$p(y \\mid x) = \\text{softmax}(W x)$。\n- **梯度**：$\\nabla_W \\ell(W; x,y) = \\left( p - e_y \\right) x^\\top$。\n- **数据生成**：使用一个 $V \\times V$ 的二元语法矩阵 $P$ 的一阶马尔可夫过程。$P$ 的列从狄利克雷（Dirichlet）分布中抽取。$n_{\\text{train}}$ 个训练样本，$n_{\\text{test}}$ 个测试样本。一小部分比例为 $\\rho$ 的训练标签是含噪声的。\n- **特征空间**：$x = [x^{\\text{gen}}, x^{\\text{mem}}]$。\n    - $x^{\\text{gen}} \\in \\mathbb{R}^V$：前一个词元的独热编码。\n    - $x^{\\text{mem}} \\in \\mathbb{R}^M$：每个训练样本唯一的独热特征，对测试样本为零。\n- **训练**：全批量梯度下降，共 $T$ 个周期。权重矩阵 $W$ 被分为 $W^{\\text{gen}}$ 和 $W^{\\text{mem}}$，采用三阶段的分段常数学习率方案：\n    1.  **早期 ($t/T \\in [0, 1/3)$)**：$W^{\\text{gen}}$ 的学习率（LR）高，$W^{\\text{mem}}$ 的学习率低。\n    2.  **中期 ($t/T \\in [1/3, 2/3)$)**：$W^{\\text{gen}}$ 的学习率低，$W^{\\text{mem}}$ 的学习率高。\n    3.  **后期 ($t/T \\in [2/3, 1]$)**：$W^{\\text{gen}}$ 的学习率高，$W^{\\text{mem}}$ 的学习率为零。\n- **正则化**：$\\ell_2$ 权重衰减，在后期阶段对 $W^{\\text{mem}}$ 施加更强的衰减。\n- **检测标准**：\n    - **插值周期 $t_\\star$**：训练准确率 $\\ge 0.99$ 的第一个周期 $t$。如果未发生，则不检测双下降。\n    - **检查点**：$t_a = \\lfloor 0.2 T \\rfloor$ 和最终周期 $T$。\n    - **双下降条件**：$L_{\\text{test}}(t_\\star) > \\max\\left( L_{\\text{test}}(t_a), L_{\\text{test}}(T) \\right)$ 且 $L_{\\text{test}}(T)  L_{\\text{test}}(t_a)$。\n- **测试套件**：\n    1. $(V, n_{\\text{train}}, n_{\\text{test}}, M, T) = (8, 150, 500, 0, 180)$\n    2. $(V, n_{\\text{train}}, n_{\\text{test}}, M, T) = (8, 150, 500, 150, 180)$\n    3. $(V, n_{\\text{train}}, n_{\\text{test}}, M, T) = (8, 100, 500, 300, 180)$\n\n#### 验证结论\n该问题具有科学依据，定义明确且客观。它提供了一个形式化但简化的框架，用于研究双下降现象——这是深度学习研究中一个备受关注的主题。使用不同类型的特征（“可泛化”与“记忆”）和分阶段的训练方案，是一种合理的方法论选择，可以诱导并分离出我们感兴趣的动态。\n\n问题没有为所有超参数（例如，学习率、权重衰减系数、噪声水平）指定具体值。这不应被解释为使问题无效的疏忽，而是将选择科学合理值的责任委托给解决者，以使仿真能够展示预期的现象。我将选择适当的值来完成仿真的目标。因此，该问题被认为是有效的。\n\n### 步骤 2：解决方案设计\n\n解决方案将实现为一个 Python 程序，该程序会遍历所提供的测试用例。对于每个用例，它将执行以下步骤。\n\n#### 数据生成\n通过从具有均匀先验（所有浓度参数等于 1）的狄利克雷（Dirichlet）分布中抽取其 $V$ 列中的每一列，来构建一个二元语法概率矩阵 $P \\in \\mathbb{R}^{V \\times V}$。这确保了每一列都代表一个有效的概率分布。使用这个矩阵，我们通过模拟一个马尔可夫链来生成 $n_{\\text{train}}$ 个训练和 $n_{\\text{test}}$ 个测试词元对 $(x, y)$。对于一小部分比例为 $\\rho$ 的训练数据，标签 $y$ 被替换为一个随机词元，以模拟标签噪声，这对于观察过拟合及其后恢复的效果至关重要。\n\n#### 特征工程\n每个样本的特征向量 $x$ 是两部分的串联：\n1.  $x^{\\text{gen}} \\in \\mathbb{R}^V$：一个表示输入词元的独热向量。其对应的权重 $W^{\\text{gen}}$ 旨在学习来自 $P$ 的通用转移概率。\n2.  $x^{\\text{mem}} \\in \\mathbb{R}^M$：每个训练样本唯一的独热向量。对于第 $i$ 个训练样本，$x^{\\text{mem}}_i$ 是第 $i$ 个标准基向量 $e_i \\in \\mathbb{R}^M$。对于所有测试样本，$x^{\\text{mem}}$ 是零向量。这些特征允许模型记忆特定的训练样本，包括含噪声的样本。\n\n#### 模型和训练动态\n模型是一个线性 softmax 分类器。权重矩阵 $W \\in \\mathbb{R}^{V \\times (V+M)}$ 使用全批量梯度下降进行训练。训练过程被构造成三个阶段来精心安排学习动态：\n1.  **早期阶段 ($t/T \\in [0, 1/3)$)**：$W^{\\text{gen}}$ 的高学习率和 $W^{\\text{mem}}$ 的低学习率促使模型首先学习数据中存在的可泛化的二元语法结构。测试误差预计会下降。\n2.  **中期阶段 ($t/T \\in [1/3, 2/3)$)**：学习率被翻转。$W^{\\text{mem}}$ 的高学习率驱动模型利用记忆特征来完美拟合训练数据。这会导致插值（训练准确率 $\\to 1.0$），通常是通过拟合含噪声的标签实现的。这种过拟合导致测试误差上升，形成了 U 形曲线的“上升”部分。\n3.  **后期阶段 ($t/T \\in [2/3, 1]$)**：$W^{\\text{mem}}$ 的学习率被设为 $0$，停止基于梯度的更新。同时，对 $W^{\\text{mem}}$ 应用强 $\\ell_2$ 权重衰减，使其权重向零收缩。这迫使模型“忘记”它所记忆的噪声模式。随着 $W^{\\text{gen}}$ 再次以高学习率进行训练，模型重新学习可泛化的结构，导致测试误差再次下降——即“第二次下降”。\n\n权重更新规则实现为解耦权重衰减。对于每个权重块 $W_p \\in \\{W^{\\text{gen}}, W^{\\text{mem}}\\}$，在一个周期内的更新是：\n1.  梯度步骤：$W_p \\leftarrow W_p - \\eta_p \\nabla_{W_p} \\mathcal{L}_{\\text{emp}}$\n2.  衰减步骤：$W_p \\leftarrow W_p (1 - \\alpha_p)$，其中 $\\alpha_p$ 是逐周期的权重衰减率。\n这种表述确保了即使当学习率 $\\eta_{\\text{mem}}$ 为零时，$W^{\\text{mem}}$ 的衰减步骤仍然有效。\n\n#### 检测逻辑\n在整个训练过程中，每个周期的测试交叉熵损失都会被记录下来。训练完成后，对记录的数据进行分析：\n1.  插值周期 $t_\\star$ 被确定为训练准确率首次超过 $0.99$ 的周期。如果这种情况从未发生，则结果为 `False`。\n2.  比较三个关键周期的测试损失：一个早期检查点 $t_a = \\lfloor 0.2 T \\rfloor$，插值周期 $t_\\star$，以及最后一个周期 $T-1$（在从 0 开始的索引中）。\n3.  检查双下降条件——$L_{\\text{test}}(t_\\star)$ 是一个高于 $L_{\\text{test}}(t_a)$ 和 $L_{\\text{test}}(T-1)$ 的峰值，并且 $L_{\\text{test}}(T-1)$ 相对于 $L_{\\text{test}}(t_a)$ 有所改善。如果条件成立，结果为 `True`，否则为 `False`。\n\n通过精心操纵模型容量和训练动态，这个结构化的仿真为逐周期双下降提供了一个清晰、可验证的演示。", "answer": "```python\nimport numpy as np\nfrom scipy.special import logsumexp\n\ndef _run_simulation(params, seed):\n    \"\"\"\n    Runs a single simulation for a given set of parameters.\n    \"\"\"\n    V, n_train, n_test, M, T = params\n    rng = np.random.default_rng(seed)\n\n    # --- Hyperparameters ---\n    # These values are chosen to be reasonable for demonstrating the phenomenon.\n    dirichlet_alpha = 1.0\n    label_noise_rho = 0.1\n    # Learning rates for the three phases\n    lr_gen_large, lr_gen_small = 1.0, 0.01\n    lr_mem_large, lr_mem_small = 1.0, 0.01\n    # Decoupled weight decay rates\n    wd_rate_gen = 1e-4\n    wd_rate_mem_base = 1e-4\n    wd_rate_mem_late = 1e-1  # Stronger late-phase decay for memorization weights\n\n    # --- Data Generation ---\n    P_bigram = np.zeros((V, V))\n    for j in range(V):\n        P_bigram[:, j] = rng.dirichlet(np.ones(V) * dirichlet_alpha)\n\n    def generate_samples(num_samples, P_matrix):\n        xs, ys = [], []\n        current_token = rng.choice(V)\n        for _ in range(num_samples):\n            prev_token = current_token\n            probs = P_matrix[:, prev_token]\n            current_token = rng.choice(V, p=probs)\n            xs.append(prev_token)\n            ys.append(current_token)\n        return np.array(xs), np.array(ys)\n\n    x_train_tokens, y_train_tokens = generate_samples(n_train, P_bigram)\n    x_test_tokens, y_test_tokens = generate_samples(n_test, P_bigram)\n    \n    noise_indices = rng.choice(n_train, size=int(n_train * label_noise_rho), replace=False)\n    y_train_tokens[noise_indices] = rng.choice(V, size=len(noise_indices))\n\n    y_train_onehot = np.eye(V)[y_train_tokens].T\n    y_test_onehot = np.eye(V)[y_test_tokens].T\n\n    # --- Feature Construction ---\n    X_gen_train = np.eye(V)[x_train_tokens].T\n    X_gen_test = np.eye(V)[x_test_tokens].T\n\n    X_mem_train = np.eye(M, n_train) if M > 0 else np.empty((0, n_train))\n    X_mem_test = np.zeros((M, n_test))\n\n    X_train = np.vstack([X_gen_train, X_mem_train])\n    X_test = np.vstack([X_gen_test, X_mem_test])\n    \n    # --- Model and Training ---\n    F = V + M  # Total feature dimension\n    limit = np.sqrt(6 / (V + F)) # Glorot/Xavier initialization\n    W_gen = rng.uniform(-limit, limit, (V, V))\n    W_mem = rng.uniform(-limit, limit, (V, M)) if M > 0 else np.empty((V, 0))\n\n    test_losses = []\n    t_star = -1\n\n    def cross_entropy_loss(logits, y_onehot_targets):\n        log_probs = logits - logsumexp(logits, axis=0, keepdims=True)\n        # Use a small epsilon to avoid log(0)\n        return -np.sum(y_onehot_targets * log_probs) / y_onehot_targets.shape[1]\n\n    for t in range(T):\n        phase_frac = t / T\n        if phase_frac  1/3:  # Early phase\n            lr_gen, lr_mem = lr_gen_large, lr_mem_small\n            wd_rate_mem = wd_rate_mem_base\n        elif phase_frac  2/3:  # Middle phase\n            lr_gen, lr_mem = lr_gen_small, lr_mem_large\n            wd_rate_mem = wd_rate_mem_base\n        else:  # Late phase\n            lr_gen, lr_mem = lr_gen_large, 0.0\n            wd_rate_mem = wd_rate_mem_late\n        \n        W = np.hstack([W_gen, W_mem])\n        logits_train = W @ X_train\n        probs_train = np.exp(logits_train - logsumexp(logits_train, axis=0, keepdims=True))\n\n        grad_W = (probs_train - y_train_onehot) @ X_train.T / n_train\n        \n        # Gradient update step\n        W_gen -= lr_gen * grad_W[:, :V]\n        if M > 0:\n            W_mem -= lr_mem * grad_W[:, V:]\n        \n        # Decoupled weight decay step\n        W_gen *= (1 - wd_rate_gen)\n        if M > 0:\n            W_mem *= (1 - wd_rate_mem)\n\n        W_eval = np.hstack([W_gen, W_mem])\n        \n        # Find interpolation epoch t_star\n        if t_star == -1:\n            preds_train = np.argmax(W_eval @ X_train, axis=0)\n            train_acc = np.mean(preds_train == y_train_tokens)\n            if train_acc >= 0.99:\n                t_star = t\n\n        # Record test loss\n        logits_test = W_eval @ X_test\n        test_loss = cross_entropy_loss(logits_test, y_test_onehot)\n        test_losses.append(test_loss)\n    \n    # --- Analysis for Double Descent ---\n    if t_star == -1:  # Interpolation did not occur\n        return False\n        \n    t_a = int(np.floor(0.2 * T))\n    L_test_ta = test_losses[t_a]\n    L_test_tstar = test_losses[t_star]\n    L_test_T = test_losses[T-1]\n\n    is_peak = L_test_tstar > max(L_test_ta, L_test_T)\n    is_recovery = L_test_T  L_test_ta\n    \n    return is_peak and is_recovery\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        (8, 150, 500, 0, 180),   # Case 1: Underparameterized\n        (8, 150, 500, 150, 180), # Case 2: Balanced overparameterization\n        (8, 100, 500, 300, 180)  # Case 3: Heavily overparameterized\n    ]\n\n    results = []\n    # Use a fixed seed for reproducibility of each simulation run\n    seed = 42 \n    for case in test_cases:\n        result = _run_simulation(case, seed)\n        results.append(result)\n\n    # Format output exactly as required\n    print(f\"[{','.join(map(str, results))}]\")\n\n# Execute the solution\nsolve()\n```", "id": "3183606"}]}