{"hands_on_practices": [{"introduction": "弹性权重巩固（Elastic Weight Consolidation, EWC）是持续学习中一种基础且重要的正则化方法，其核心思想是识别并保护对旧任务至关重要的网络权重，从而在学习新任务时减缓灾难性遗忘。在这个练习中，你将通过计算费雪信息矩阵（Fisher Information Matrix）来量化每个参数的重要性，并对那些对旧任务更重要的参数施加更大的“变化惩罚”。通过亲手实现EWC的核心机制 [@problem_id:3109267]，你将能够量化并验证该方法在保护旧任务知识方面的效果，具体来说，就是观察EWC如何有效减少对旧任务关键参数子空间的梯度更新。", "problem": "您必须编写一个完整的程序，为带有嵌入层和分类器的线性神经网络构建并分析一个合成的持续学习场景。该网络将一个输入向量 $\\mathbf{x} \\in \\mathbb{R}^d$ 通过一个嵌入矩阵 $\\mathbf{E} \\in \\mathbb{R}^{m \\times d}$ 映射到一个嵌入 $\\mathbf{z} = \\mathbf{E}\\mathbf{x}$，然后应用一个分类器矩阵 $\\mathbf{C} \\in \\mathbb{R}^{K \\times m}$ 来产生 logits $\\mathbf{s} = \\mathbf{C}\\mathbf{z}$。在 $K$ 个类别上的预测分布是 softmax $\\mathbf{p} = \\operatorname{softmax}(\\mathbf{s})$，其中 $p_k = \\exp(s_k)/\\sum_{j=1}^K \\exp(s_j)$。对于单个样本 $(\\mathbf{x}, \\mathbf{y})$（其中 $\\mathbf{y} \\in \\{0,1\\}^K$ 是 one-hot 标签），训练损失是交叉熵 $L(\\mathbf{C};\\mathbf{z},\\mathbf{y}) = -\\sum_{k=1}^K y_k \\log p_k$。关于分类器的梯度是 $\\nabla_{\\mathbf{C}} L = (\\mathbf{p}-\\mathbf{y})\\mathbf{z}^\\top$。我们将全程使用全批量梯度下降。\n\n在持续学习中，在旧任务上训练并获得参数 $\\mathbf{C}^\\star$ 后，弹性权重巩固 (Elastic Weight Consolidation, EWC) 策略增加一个二次惩罚项，以抑制在对旧任务重要的方向上的移动。设旧任务的经验费雪信息（对角近似）定义为\n$$\n\\mathbf{F}_{\\text{diag}} = \\frac{1}{N} \\sum_{i=1}^N \\operatorname{vec}\\!\\left(\\nabla_{\\mathbf{C}} \\ell_i\\right) \\odot \\operatorname{vec}\\!\\left(\\nabla_{\\mathbf{C}} \\ell_i\\right),\n$$\n其中 $\\ell_i = L(\\mathbf{C}^\\star;\\mathbf{z}_i,\\mathbf{y}_i)$，$\\operatorname{vec}(\\cdot)$ 将矩阵展平为向量，$\\odot$ 表示逐元素乘法。EWC 惩罚项为\n$$\nR(\\mathbf{C}) = \\frac{\\lambda}{2} \\sum_{j} F_{\\text{diag},j}\\left(\\theta_j - \\theta_j^\\star\\right)^2,\n$$\n其中 $\\theta = \\operatorname{vec}(\\mathbf{C})$ 且 $\\theta^\\star = \\operatorname{vec}(\\mathbf{C}^\\star)$。在新任务上训练时，基线目标是 $J_{\\text{base}}(\\mathbf{C}) = \\frac{1}{N'}\\sum_{i=1}^{N'} L(\\mathbf{C};\\mathbf{z}_i',\\mathbf{y}_i')$，EWC 目标是 $J_{\\text{ewc}}(\\mathbf{C}) = J_{\\text{base}}(\\mathbf{C}) + R(\\mathbf{C})$。惩罚项关于 $\\theta$ 的梯度是 $\\nabla_\\theta R(\\mathbf{C}) = \\lambda\\,\\mathbf{F}_{\\text{diag}} \\odot (\\theta - \\theta^\\star)$。\n\n将旧任务子空间 $\\mathcal{S}_r$ 定义为 $\\theta$ 中与 $\\mathbf{F}_{\\text{diag}}$ 的前 $r$ 个条目（最大值）相对应的 $r$ 个坐标所张成的空间。令 $\\mathcal{P}_{\\mathcal{S}_r}$ 表示将这 $r$ 个索引之外的所有坐标清零的投影算子。对于学习率为 $\\eta$ 的梯度下降，在步骤 $t$ 的更新向量是 $\\Delta_t = -\\eta \\nabla_\\theta J(\\mathbf{C}_t)$，其中 $J$ 是 $J_{\\text{base}}$ 或 $J_{\\text{ewc}}$。在 $T$ 个步骤中，进入 $\\mathcal{S}_r$ 的累积梯度流幅度为\n$$\nM = \\sum_{t=1}^T \\left\\|\\mathcal{P}_{\\mathcal{S}_r}(\\Delta_t)\\right\\|_2.\n$$\n\n您的程序必须：\n- 通过设置 $\\mathbf{E} = \\mathbf{I}_m$（$m \\times m$ 单位矩阵），完全在嵌入空间中构建一个合成的旧任务和一个合成的新任务。令旧任务生成具有依赖于类别的高斯均值 $\\boldsymbol{\\mu}_k^{\\text{old}} \\in \\mathbb{R}^m$ 和协方差 $\\sigma^2 \\mathbf{I}_m$ 的样本。令新任务的均值通过将一个随机正交旋转 $\\mathbf{R} \\in \\mathbb{R}^{m \\times m}$ 应用于旧均值来获得：$\\boldsymbol{\\mu}_k^{\\text{new}} = \\mathbf{R}\\boldsymbol{\\mu}_k^{\\text{old}}$。标签对于 $K$ 个类别保持为 one-hot 编码。\n- 在旧任务上使用全批量梯度下降训练 $\\mathbf{C}$ 以获得 $\\mathbf{C}^\\star$，同时保持 $\\mathbf{E}$ 固定，然后在 $\\mathbf{C}^\\star$ 处计算旧任务上的 $\\mathbf{F}_{\\text{diag}}$。\n- 对于新任务，比较两种策略：(i) 冻结嵌入并使用 $J_{\\text{base}}$ 微调分类器，以及 (ii) 冻结嵌入并使用 $J_{\\text{ewc}}$ 微调分类器，其中 EWC 惩罚仅应用于分类器。在这两种策略中，都从 $\\mathbf{C}^\\star$ 开始，并使用相同的步数和学习率。\n- 对于每种策略，计算进入旧任务子空间 $\\mathcal{S}_r$ 的累积梯度流幅度 $M$，并输出一个布尔值，指示 EWC 策略是否与基线相比减小了此幅度，即 $M_{\\text{ewc}}  M_{\\text{base}}$ 是否成立。\n\n所有计算都纯粹是数学上的，并且必须使用上述定义。不涉及物理单位或角度。不得使用百分比。\n\n测试套件：\n- 使用 $d=m=6$，$K=3$，每个旧类别的样本数 $N_{\\text{old}}=120$，每个新类别的样本数 $N_{\\text{new}}=120$，$\\sigma=0.6$，旧任务学习率 $\\eta_{\\text{old}}=0.1$ 训练 $200$ 步，新任务学习率 $\\eta_{\\text{new}}$ 和步数如下文各案例指定。旧任务的类别均值必须是 $\\boldsymbol{\\mu}_k^{\\text{old}} = a\\,\\mathbf{e}_k$（对于 $k=1,2,3$），其中 $\\mathbf{e}_k$ 是 $\\mathbb{R}^m$ 中的第 $k$ 个标准基向量，$a=2.5$，对于每个 $\\boldsymbol{\\mu}_k^{\\text{old}}$，其余坐标为零。\n- 定义四个测试案例为元组 $(\\text{seed}, r, \\lambda, \\eta_{\\text{new}}, T)$:\n    1. $(42, 8, 20.0, 0.08, 100)$，一般情况。\n    2. $(7, 0, 20.0, 0.08, 100)$，边界情况，其中 $r=0$（空子空间）。\n    3. $(123, 8, 0.0, 0.08, 100)$，边缘情况，其中 $\\lambda=0$（无 EWC 效应）。\n    4. $(2024, 18, 50.0, 0.06, 80)$，全维度子空间 $r=K\\cdot m$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的布尔值逗号分隔列表，按所列顺序表示测试案例的结果（例如，“[True,False,False,True]”）。", "solution": "问题陈述已经过分析，被认为是有效的。它在科学上基于深度学习中持续学习的原理，通过提供所有必要的常数和定义而定义良好，并且其表述是客观的。任务是实现一个数值模拟，以基于一个指定的度量来比较两种持续学习策略：基线微调和弹性权重巩固（EWC）。\n\n解决方案通过一系列计算步骤进行：\n\n### 1. 合成任务生成\n\n问题在嵌入空间中定义，其中嵌入矩阵是单位矩阵，$\\mathbf{E} = \\mathbf{I}_m$。因此，输入向量 $\\mathbf{x}$ 等同于嵌入向量 $\\mathbf{z} \\in \\mathbb{R}^m$。\n\n**旧任务：** 旧任务包含 $K=3$ 个类别。对于每个类别 $k \\in \\{0, 1, 2\\}$，我们通过从多元高斯分布 $\\mathcal{N}(\\boldsymbol{\\mu}_k^{\\text{old}}, \\sigma^2 \\mathbf{I}_m)$ 中抽样来生成 $N_{\\text{old}}=120$ 个数据点 $\\mathbf{z}_i$。指定的参数为 $m=6$，$\\sigma=0.6$，均值由 $\\boldsymbol{\\mu}_k^{\\text{old}} = a\\,\\mathbf{e}_{k+1}$ 给出，其中 $a=2.5$，$\\mathbf{e}_{j}$ 是 $\\mathbb{R}^m$ 中的第 $j$ 个标准基向量。旧任务样本总数为 $N = K \\times N_{\\text{old}} = 360$。每个样本 $(\\mathbf{z}_i, \\mathbf{y}_i)$ 都包含一个 one-hot 编码的标签向量 $\\mathbf{y}_i \\in \\{0,1\\}^K$。\n\n**新任务：** 生成一个随机正交矩阵 $\\mathbf{R} \\in \\mathbb{R}^{m \\times m}$。新任务的均值通过旋转旧任务的均值来创建：$\\boldsymbol{\\mu}_k^{\\text{new}} = \\mathbf{R}\\boldsymbol{\\mu}_k^{\\text{old}}$。然后通过从 $\\mathcal{N}(\\boldsymbol{\\mu}_k^{\\text{new}}, \\sigma^2 \\mathbf{I}_m)$ 中为每个类别抽样 $N_{\\text{new}}=120$ 个点来生成新任务数据。这种构造确保了类别分离的内在结构被保留，但在嵌入空间中朝向不同，从而创建了一个模型必须适应的场景。\n\n### 2. 在旧任务上训练\n\n分类器矩阵 $\\mathbf{C} \\in \\mathbb{R}^{K \\times m}$ 在旧任务的整个批次数据上进行训练。从初始矩阵 $\\mathbf{C}_0 = \\mathbf{0}$ 开始，我们以 $\\eta_{\\text{old}}=0.1$ 的学习率执行 $T_{\\text{old}}=200$ 步梯度下降。目标函数是数据集上的平均交叉熵损失。每个步骤中分类器的更新规则是：\n$$\n\\mathbf{C}_{t+1} = \\mathbf{C}_t - \\eta_{\\text{old}} \\nabla_{\\mathbf{C}} J(\\mathbf{C}_t)\n$$\n其中全批量损失 $J(\\mathbf{C}) = \\frac{1}{N} \\sum_{i=1}^N L(\\mathbf{C}; \\mathbf{z}_i, \\mathbf{y}_i)$ 的梯度由下式给出：\n$$\n\\nabla_{\\mathbf{C}} J(\\mathbf{C}) = \\frac{1}{N} \\sum_{i=1}^N (\\mathbf{p}_i - \\mathbf{y}_i)\\mathbf{z}_i^\\top = \\frac{1}{N}(\\mathbf{P} - \\mathbf{Y})\\mathbf{Z}^\\top\n$$\n在这里，$\\mathbf{P}$ 是 softmax 概率矩阵，$\\mathbf{Y}$ 是 one-hot 标签矩阵，$\\mathbf{Z}$ 是数据点矩阵，每个样本作为一列。最终训练好的分类器表示为 $\\mathbf{C}^\\star$。\n\n### 3. 费雪信息计算\n\n经验费雪信息矩阵的对角线 $\\mathbf{F}_{\\text{diag}}$ 量化了模型输出对其参数变化的敏感度，该敏感度在旧任务上进行评估。它在最优参数 $\\mathbf{C}^\\star$ 处计算：\n$$\n\\mathbf{F}_{\\text{diag}} = \\frac{1}{N} \\sum_{i=1}^N \\operatorname{vec}\\!\\left(\\nabla_{\\mathbf{C}} \\ell_i\\right) \\odot \\operatorname{vec}\\!\\left(\\nabla_{\\mathbf{C}} \\ell_i\\right)\n$$\n其中 $\\ell_i = L(\\mathbf{C}^\\star;\\mathbf{z}_i,\\mathbf{y}_i)$ 是第 $i$ 个旧任务样本的损失，$\\operatorname{vec}(\\cdot)$ 将 $K \\times m$ 的梯度矩阵展平为大小为 $Km$ 的向量，而 $\\odot$ 是逐元素乘积。这个向量 $\\mathbf{F}_{\\text{diag}}$ 识别了哪些参数对旧任务的性能最重要。\n\n### 4. 在新任务上微调\n\n我们比较两种使分类器适应新任务的策略，两者都从 $\\mathbf{C}^\\star$ 开始。\n\n**旧任务子空间：** 我们首先定义“重要的”旧任务子空间 $\\mathcal{S}_r$。该子空间由与 $\\mathbf{F}_{\\text{diag}}$ 中 $r$ 个最大值相对应的 $r$ 个参数坐标张成。我们定义一个投影算子 $\\mathcal{P}_{\\mathcal{S}_r}$，当应用于向量时，它会保留其在 $\\mathcal{S}_r$ 中的分量，并将所有其他分量设置为零。\n\n**策略与度量：**\n对于基线和 EWC 两种策略，我们都以学习率 $\\eta_{\\text{new}}$ 在新任务数据上运行 $T$ 步梯度下降。令 $\\theta_t = \\operatorname{vec}(\\mathbf{C}_t)$ 为步骤 $t$ 的向量化分类器参数。更新向量为 $\\Delta_t = -\\eta_{\\text{new}} \\nabla_\\theta J(\\mathbf{C}_t)$。我们跟踪投影到旧任务子空间上的更新的累积幅度：\n$$\nM = \\sum_{t=1}^T \\left\\|\\mathcal{P}_{\\mathcal{S}_r}(\\Delta_t)\\right\\|_2\n$$\n\n- **基线微调：** 目标函数仅仅是新任务的损失，$J_{\\text{base}}$。梯度为 $\\nabla_\\theta J_{\\text{base}} = \\operatorname{vec}(\\frac{1}{N'}\\sum_{i=1}^{N'} (\\mathbf{p}'_i - \\mathbf{y}'_i)(\\mathbf{z}'_i)^\\top)$。累积流记为 $M_{\\text{base}}$。\n\n- **EWC 微调：** 目标函数包括 EWC 惩罚项，$J_{\\text{ewc}}(\\mathbf{C}) = J_{\\text{base}}(\\mathbf{C}) + R(\\mathbf{C})$。梯度是基线梯度和惩罚项梯度之和：\n$$\n\\nabla_\\theta J_{\\text{ewc}} = \\nabla_\\theta J_{\\text{base}} + \\nabla_\\theta R(\\mathbf{C})\n$$\n其中 $\\nabla_\\theta R(\\mathbf{C}) = \\lambda\\,\\mathbf{F}_{\\text{diag}} \\odot (\\theta - \\theta^\\star)$。惩罚项将参数 $\\theta$ 拉回其对于旧任务的最优值 $\\theta^\\star$，其强度与它们的重要性（$\\mathbf{F}_{\\text{diag}}$）和超参数 $\\lambda$ 成正比。累积流记为 $M_{\\text{ewc}}$。\n\n### 5. 评估\n\n对于每个测试案例，我们计算 $M_{\\text{base}}$ 和 $M_{\\text{ewc}}$。最终输出是一个布尔值，指示 EWC 是否减少了在重要的旧任务子空间中的参数更新（与基线相比），即 $M_{\\text{ewc}}  M_{\\text{base}}$ 是否成立。预期 EWC 通过其设计，会惩罚对重要旧任务参数的更改，从而降低此度量。边界情况（$r=0$ 和 $\\lambda=0$）作为合理性检查：如果子空间为空或惩罚为零，则不应有任何减少，两种策略应产生相等的幅度。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import ortho_group\n\ndef solve():\n    \"\"\"\n    Main function to run the continual learning simulation for all test cases.\n    \"\"\"\n\n    # --- Problem Constants ---\n    d_dim = 6\n    m_dim = 6\n    K_classes = 3\n    N_old_per_class = 120\n    N_new_per_class = 120\n    sigma = 0.6\n    a_mean_scale = 2.5\n    eta_old = 0.1\n    T_old = 200\n\n    test_cases = [\n        (42, 8, 20.0, 0.08, 100),\n        (7, 0, 20.0, 0.08, 100),\n        (123, 8, 0.0, 0.08, 100),\n        (2024, 18, 50.0, 0.06, 80),\n    ]\n\n    results = []\n\n    def stable_softmax(x, axis=None):\n        \"\"\"Numerically stable softmax function.\"\"\"\n        s = x - np.max(x, axis=axis, keepdims=True)\n        e_s = np.exp(s)\n        return e_s / np.sum(e_s, axis=axis, keepdims=True)\n\n    def generate_data(means, n_per_class, sigma_val, rng_gen):\n        \"\"\"Generates synthetic data for a task.\"\"\"\n        k, m = means.shape\n        n_total = k * n_per_class\n        Z_list = []\n        Y_list = []\n        for class_idx in range(k):\n            # Data: (m, n_per_class)\n            Z_class = rng_gen.normal(loc=means[class_idx, :], scale=sigma_val, size=(n_per_class, m)).T\n            Z_list.append(Z_class)\n            # Labels: (k, n_per_class)\n            y_vec = np.zeros((k, 1))\n            y_vec[class_idx] = 1\n            Y_class = np.tile(y_vec, (1, n_per_class))\n            Y_list.append(Y_class)\n        Z = np.hstack(Z_list)\n        Y = np.hstack(Y_list)\n        return Z, Y\n\n    def run_finetuning(C_init, Z_new, Y_new, eta, T, F_diag, lamb, projector_mask):\n        \"\"\"Runs the fine-tuning loop for a given strategy and computes M.\"\"\"\n        C = C_init.copy()\n        theta_star = C_init.ravel()\n        N_new = Z_new.shape[1]\n        M = 0.0\n        param_shape = C.shape\n\n        for _ in range(T):\n            theta = C.ravel()\n            \n            # Gradients\n            S_new = C @ Z_new\n            P_new = stable_softmax(S_new, axis=0)\n            grad_C_base = (P_new - Y_new) @ Z_new.T / N_new\n            grad_theta_base = grad_C_base.ravel()\n            \n            grad_theta_penalty = lamb * F_diag * (theta - theta_star)\n            grad_theta_total = grad_theta_base + grad_theta_penalty\n            \n            # Cumulative magnitude calculation\n            delta_t = -eta * grad_theta_total\n            delta_t_proj = delta_t * projector_mask\n            M += np.linalg.norm(delta_t_proj)\n            \n            # Parameter update\n            C -= eta * grad_theta_total.reshape(param_shape)\n        \n        return M\n\n    for case in test_cases:\n        seed, r_dim, lamb, eta_new, T_new = case\n        rng = np.random.default_rng(seed)\n\n        # --- 1. Old Task ---\n        N_old_total = K_classes * N_old_per_class\n        \n        # Generate data\n        mus_old = np.zeros((K_classes, m_dim))\n        for k in range(K_classes):\n            mus_old[k, k] = a_mean_scale\n        Z_old, Y_old = generate_data(mus_old, N_old_per_class, sigma, rng)\n\n        # Train on old task to find C_star\n        C = np.zeros((K_classes, m_dim))\n        for _ in range(T_old):\n            S_old = C @ Z_old\n            P_old = stable_softmax(S_old, axis=0)\n            grad_C = (P_old - Y_old) @ Z_old.T / N_old_total\n            C -= eta_old * grad_C\n        C_star = C\n\n        # --- 2. Calculate Fisher Information ---\n        vec_grads_sq_sum = np.zeros(K_classes * m_dim)\n        for i in range(N_old_total):\n            z_i = Z_old[:, i:i+1]\n            y_i = Y_old[:, i:i+1]\n            s_i = C_star @ z_i\n            p_i = stable_softmax(s_i, axis=0)\n            grad_C_i = (p_i - y_i) @ z_i.T\n            vec_grad_i = grad_C_i.ravel()\n            vec_grads_sq_sum += vec_grad_i**2\n        F_diag = vec_grads_sq_sum / N_old_total\n\n        # --- 3. New Task ---\n        N_new_total = K_classes * N_new_per_class\n        \n        # Generate Data\n        R_ortho = ortho_group.rvs(m_dim, random_state=rng)\n        mus_new = (R_ortho @ mus_old.T).T\n        Z_new, Y_new = generate_data(mus_new, N_new_per_class, sigma, rng)\n\n        # --- 4. Define Subspace Projector ---\n        # Get indices of the r largest values in F_diag\n        if r_dim > 0:\n            top_r_indices = np.argsort(F_diag)[-r_dim:]\n        else:\n            top_r_indices = []\n        \n        projector_mask = np.zeros_like(F_diag)\n        projector_mask[top_r_indices] = 1.0\n\n        # --- 5. Run and Compare Strategies ---\n        # Baseline (lambda = 0)\n        M_base = run_finetuning(C_star, Z_new, Y_new, eta_new, T_new, F_diag, 0.0, projector_mask)\n        \n        # EWC\n        M_ewc = run_finetuning(C_star, Z_new, Y_new, eta_new, T_new, F_diag, lamb, projector_mask)\n\n        results.append(M_ewc  M_base)\n\n    # --- Final Output ---\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3109267"}, {"introduction": "知识蒸馏（Knowledge Distillation）是另一种有效的持续学习策略，它通过将旧模型（“教师”）的知识迁移到当前模型（“学生”）中来对抗遗忘，这种方法可以看作是一种无需存储旧数据的“伪排演”（pseudo-rehearsal）。本练习将引导你比较两种主流的蒸馏方法：输出空间蒸馏（output-space distillation）和特征空间蒸馏（feature-space distillation），前者旨在匹配模型的最终概率输出，而后者则致力于对齐网络的内部特征表示。通过实现和对比这两种策略 [@problem_id:3109241]，并使用一个精细的度量标准——决策边界附近的间隔（margin）变化，你将能深入理解不同蒸馏方法在保留旧任务知识结构方面的差异和权衡。", "problem": "给定一个深度学习中的二元分类持续学习场景，其中在学习新任务时，必须保留先前在旧任务上训练好的模型。模型架构是一个带双曲正切激活函数的单隐藏层神经网络和一个softmax输出层。需要实现并比较两种持续学习策略：输出空间蒸馏和特征空间蒸馏。目标是确定在学习新任务时，哪种策略能更好地保留旧任务的细粒度决策边界。\n\n您必须使用的基础包括以下定义和事实：\n- 对于 logits $\\mathbf{z} \\in \\mathbb{R}^C$，softmax函数为 $p_k(\\mathbf{z}) = \\dfrac{\\exp(z_k)}{\\sum_{j=1}^C \\exp(z_j)}$，其中 $k \\in \\{1,\\dots,C\\}$，$C$ 是类别数量。\n- one-hot目标 $\\mathbf{y} \\in \\{0,1\\}^C$ 与预测概率 $\\mathbf{p} \\in [0,1]^C$ 之间的交叉熵损失为 $\\mathcal{L}_{\\mathrm{CE}}(\\mathbf{y},\\mathbf{p}) = -\\sum_{k=1}^C y_k \\log p_k$。\n- 从分布 $\\mathbf{q}$ 到 $\\mathbf{p}$ 的Kullback–Leibler散度为 $D_{\\mathrm{KL}}(\\mathbf{q}\\|\\mathbf{p}) = \\sum_{k=1}^C q_k \\log\\left(\\dfrac{q_k}{p_k}\\right)$，它可作为一种相异性度量。\n- 对于特征空间蒸馏，一个常见的对齐目标是教师模型和学生模型隐藏表示之间的均方误差 $\\mathcal{L}_{\\mathrm{MSE}}(\\mathbf{h}^{\\mathrm{old}},\\mathbf{h}^{\\mathrm{new}}) = \\|\\mathbf{h}^{\\mathrm{old}}-\\mathbf{h}^{\\mathrm{new}}\\|_2^2$。\n- 双曲正切激活函数为 $\\tanh(a) = \\dfrac{e^a - e^{-a}}{e^a + e^{-a}}$，其导数为 $\\dfrac{d}{da}\\tanh(a) = 1 - \\tanh^2(a)$。\n\n网络输入维度为 $d=2$，隐藏维度为 $H$，输出维度为 $C=2$。设隐藏表示为 $\\mathbf{h} = \\tanh(\\mathbf{x}\\mathbf{W}_1 + \\mathbf{b}_1)$，logits为 $\\mathbf{z} = \\mathbf{h}\\mathbf{W}_2 + \\mathbf{b}_2$，概率为 $\\mathbf{p} = \\mathrm{softmax}(\\mathbf{z})$。对于二元分类，细粒度决策边界可以通过有符号间隔 $m(\\mathbf{x}) = z_1(\\mathbf{x}) - z_0(\\mathbf{x})$ 来表征，边界位于 $m(\\mathbf{x})=0$ 处。细粒度决策边界的保留程度通过在旧任务边界附近的探测点上间隔的平均绝对变化来衡量。\n\n您必须实现两种持续学习策略：\n- 输出空间蒸馏：在学习新任务的同时，惩罚在温度 $T$ 下教师模型的旧任务软化输出与学生模型输出之间的差异。使用Kullback–Leibler散度，其软化目标为 $q^{(T)}(\\mathbf{z}/T)$，并包含标准的温度缩放因子以确保梯度的适当缩放。\n- 特征空间蒸馏：在学习新任务的同时，使用均方误差惩罚教师模型在旧数据上的隐藏特征与学生模型在相同数据上的隐藏特征之间的差异。\n\n需遵循的实验协议：\n1. 使用交叉熵在旧任务数据上训练一个教师模型（旧任务模型）。\n2. 为两种策略初始化一个具有相同架构和相同初始参数的学生模型，以确保公平比较。\n3. 在每种策略下分别在新任务上训练学生模型：\n   - 输出空间蒸馏：最小化新任务交叉熵与旧任务数据上的输出空间蒸馏Kullback–Leibler散度之和，该散度由蒸馏权重 $\\lambda_{\\mathrm{out}}$ 和温度 $T$ 缩放。\n   - 特征空间蒸馏：最小化新任务交叉熵与旧任务数据上的特征空间均方误差之和，该误差由蒸馏权重 $\\lambda_{\\mathrm{feat}}$ 缩放。\n4. 通过选择教师模型的有符号间隔 $m_{\\mathrm{old}}(\\mathbf{x})$ 最接近 $0$ 的旧任务样本来构建探测点，这表示它们邻近决策边界。在这些探测点上，为每种策略计算平均绝对间隔变化 $\\Delta = \\dfrac{1}{K} \\sum_{i=1}^K \\left| m_{\\mathrm{student}}(\\mathbf{x}_i) - m_{\\mathrm{old}}(\\mathbf{x}_i) \\right|$。\n5. 对每个测试用例，输出一个布尔值，指示输出空间蒸馏是否产生比特征空间蒸馏严格更小的 $\\Delta$。\n\n数据生成详情：\n- 旧任务：二元分类，类别条件分布为：标签 $0$ 对应 $\\mathbf{x} \\sim \\mathcal{N}(\\boldsymbol{\\mu}_0^{\\mathrm{old}}, \\sigma_{\\mathrm{old}}^2 \\mathbf{I})$，标签 $1$ 对应 $\\mathbf{x} \\sim \\mathcal{N}(\\boldsymbol{\\mu}_1^{\\mathrm{old}}, \\sigma_{\\mathrm{old}}^2 \\mathbf{I})$。\n- 新任务：二元分类，类别条件分布为：标签 $0$ 对应 $\\mathbf{x} \\sim \\mathcal{N}(\\boldsymbol{\\mu}_0^{\\mathrm{new}}, \\sigma_{\\mathrm{new}}^2 \\mathbf{I})$，标签 $1$ 对应 $\\mathbf{x} \\sim \\mathcal{N}(\\boldsymbol{\\mu}_1^{\\mathrm{new}}, \\sigma_{\\mathrm{new}}^2 \\mathbf{I})$。\n\n测试套件：\n- 案例1：seed $0$, $n_{\\mathrm{old}}=200$, $n_{\\mathrm{new}}=200$, $\\boldsymbol{\\mu}_0^{\\mathrm{old}}=(-1.0,0.0)$, $\\boldsymbol{\\mu}_1^{\\mathrm{old}}=(1.0,0.0)$, $\\sigma_{\\mathrm{old}}=0.4$, $\\boldsymbol{\\mu}_0^{\\mathrm{new}}=(0.0,-1.0)$, $\\boldsymbol{\\mu}_1^{\\mathrm{new}}=(0.0,1.0)$, $\\sigma_{\\mathrm{new}}=0.4$, 隐藏层大小 $H=16$, 学习率 $\\eta=0.05$, 教师模型迭代次数 $300$, 学生模型迭代次数 $300$, 蒸馏权重 $\\lambda_{\\mathrm{out}}=0.5$, $\\lambda_{\\mathrm{feat}}=0.5$, 温度 $T=2.0$, 探测点数量 $K=40$.\n- 案例2：seed $1$, $n_{\\mathrm{old}}=240$, $n_{\\mathrm{new}}=240$, $\\boldsymbol{\\mu}_0^{\\mathrm{old}}=(-0.3,0.0)$, $\\boldsymbol{\\mu}_1^{\\mathrm{old}}=(0.3,0.0)$, $\\sigma_{\\mathrm{old}}=0.35$, $\\boldsymbol{\\mu}_0^{\\mathrm{new}}=(0.0,-0.6)$, $\\boldsymbol{\\mu}_1^{\\mathrm{new}}=(0.0,0.6)$, $\\sigma_{\\mathrm{new}}=0.35$, 隐藏层大小 $H=24$, 学习率 $\\eta=0.05$, 教师模型迭代次数 $400$, 学生模型迭代次数 $350$, 蒸馏权重 $\\lambda_{\\mathrm{out}}=0.4$, $\\lambda_{\\mathrm{feat}}=0.8$, 温度 $T=2.5$, 探测点数量 $K=60$.\n- 案例3：seed $2$, $n_{\\mathrm{old}}=220$, $n_{\\mathrm{new}}=220$, $\\boldsymbol{\\mu}_0^{\\mathrm{old}}=(-0.8,-0.2)$, $\\boldsymbol{\\mu}_1^{\\mathrm{old}}=(0.8,0.2)$, $\\sigma_{\\mathrm{old}}=0.45$, $\\boldsymbol{\\mu}_0^{\\mathrm{new}}=(0.2,-0.8)$, $\\boldsymbol{\\mu}_1^{\\mathrm{new}}=(-0.2,0.8)$, $\\sigma_{\\mathrm{new}}=0.45$, 隐藏层大小 $H=20$, 学习率 $\\eta=0.05$, 教师模型迭代次数 $350$, 学生模型迭代次数 $320$, 蒸馏权重 $\\lambda_{\\mathrm{out}}=0.0$, $\\lambda_{\\mathrm{feat}}=0.6$, 温度 $T=2.0$, 探测点数量 $K=50$.\n\n您的程序必须：\n- 实现上述训练和评估过程。\n- 对每个测试用例，计算输出空间蒸馏在探测点上是否比特征空间蒸馏获得了严格更小的平均绝对间隔变化 $\\Delta$，并返回一个布尔值。\n- 生成一行输出，其中包含用方括号括起来的逗号分隔的结果列表（例如，`[True, False, True]`）。本题不需要物理单位、角度单位或百分比。", "solution": "用户提供了一个问题陈述，要求在双层神经网络的背景下，实现并比较两种持续学习策略——输出空间蒸馏和特征空间蒸馏。该问题定义明确，科学上基于深度学习原理，并且计算上可行。所有必要的参数、数据生成过程和评估指标均已指定，使得该问题有效。\n\n解决方案将通过首先概述数学框架（包括网络架构和损失函数），然后描述训练和评估协议来制定。\n\n### 1. 模型和数据规范\n\n该模型是一个为二元分类（$C=2$）设计的单隐藏层神经网络。输入 $\\mathbf{x} \\in \\mathbb{R}^d$（其中 $d=2$）按以下方式处理：\n- 隐藏层的预激活值为 $\\mathbf{a}_1 = \\mathbf{x}\\mathbf{W}_1 + \\mathbf{b}_1$，其中 $\\mathbf{W}_1 \\in \\mathbb{R}^{d \\times H}$ 和 $\\mathbf{b}_1 \\in \\mathbb{R}^{H}$ 是第一层的权重和偏置，$H$ 是隐藏维度。\n- 通过应用双曲正切激活函数获得隐藏表示：$\\mathbf{h} = \\tanh(\\mathbf{a}_1)$。\n- logits（输出层的预激活值）为 $\\mathbf{z} = \\mathbf{h}\\mathbf{W}_2 + \\mathbf{b}_2$，其中 $\\mathbf{W}_2 \\in \\mathbb{R}^{H \\times C}$ 和 $\\mathbf{b}_2 \\in \\mathbb{R}^{C}$。\n- 最终的类别概率使用softmax函数计算：$\\mathbf{p} = \\mathrm{softmax}(\\mathbf{z})$，其中 $p_k(\\mathbf{z}) = \\frac{\\exp(z_k)}{\\sum_{j=1}^C \\exp(z_j)}$。\n\n旧任务和新任务的数据均从二维高斯分布生成。对于给定任务，类别 $0$ 的样本从 $\\mathcal{N}(\\boldsymbol{\\mu}_0, \\sigma^2 \\mathbf{I})$ 中抽取，类别 $1$ 的样本从 $\\mathcal{N}(\\boldsymbol{\\mu}_1, \\sigma^2 \\mathbf{I})$ 中抽取。\n\n### 2. 教师模型训练\n\n首先，一个“教师”模型仅在旧任务数据上进行训练。训练目标是最小化 one-hot 编码的真实标签 $\\mathbf{y}$ 和模型预测概率 $\\mathbf{p}$ 之间的标准交叉熵损失 $\\mathcal{L}_{\\mathrm{CE}}$：\n$$\n\\mathcal{L}_{\\mathrm{CE}}(\\mathbf{y}, \\mathbf{p}) = -\\frac{1}{N} \\sum_{i=1}^N \\sum_{k=1}^C y_{ik} \\log p_{ik}\n$$\n其中 $N$ 是样本数量。参数 $\\theta_{\\text{old}} = \\{\\mathbf{W}_1, \\mathbf{b}_1, \\mathbf{W}_2, \\mathbf{b}_2\\}$ 使用梯度下降进行更新。对于单个样本，损失关于 logits $\\mathbf{z}$ 的梯度是 $\\mathbf{p} - \\mathbf{y}$。然后，该梯度通过网络反向传播，以计算所有参数的梯度。\n\n### 3. 学生模型训练策略\n\n然后，一个具有相同架构和一组全新初始随机权重的“学生”模型在新任务上进行训练。为防止对旧任务的灾难性遗忘，在训练目标中增加了一个蒸馏损失。我们比较了两种策略。\n\n#### 3.1. 输出空间蒸馏\n\n在此策略中，训练学生模型以匹配教师模型在旧任务数据上的软化输出。总损失函数是新任务数据上的交叉熵损失和旧任务数据上的蒸馏损失的加权和：\n$$\n\\mathcal{L}_{\\text{out}} = \\mathcal{L}_{\\mathrm{CE}}(\\text{new data}) + \\lambda_{\\mathrm{out}} \\mathcal{L}_{\\mathrm{distill}}(\\text{old data})\n$$\n蒸馏损失 $\\mathcal{L}_{\\mathrm{distill}}$ 是教师和学生的软化概率分布之间的Kullback-Leibler散度，并由温度因子 $T^2$ 缩放：\n$$\n\\mathcal{L}_{\\mathrm{distill}} = T^2 D_{\\mathrm{KL}}(\\mathbf{q}^{(T)} \\| \\mathbf{p}^{(T)})\n$$\n其中 $\\mathbf{p}^{(T)} = \\mathrm{softmax}(\\mathbf{z}_{\\text{student}}/T)$ 和 $\\mathbf{q}^{(T)} = \\mathrm{softmax}(\\mathbf{z}_{\\text{teacher}}/T)$ 是在温度 $T$ 下计算的学生和教师的概率。最小化 $D_{\\mathrm{KL}}$ 等价于最小化 $\\mathbf{q}^{(T)}$ 和 $\\mathbf{p}^{(T)}$ 之间的交叉熵，因为 $\\mathbf{q}^{(T)}$ 的熵相对于学生模型的参数是恒定的。\n$\\mathcal{L}_{\\mathrm{distill}}$ 相对于学生模型 logits $\\mathbf{z}_{\\text{student}}$ 的梯度是：\n$$\n\\frac{\\partial \\mathcal{L}_{\\mathrm{distill}}}{\\partial \\mathbf{z}_{\\text{student}}} = \\mathbf{p}^{(T)} - \\mathbf{q}^{(T)}\n$$\n学生模型参数 $\\theta_{\\text{student}}$ 的总梯度是来自新数据上 $\\mathcal{L}_{\\mathrm{CE}}$ 的梯度和来自旧数据上 $\\lambda_{\\mathrm{out}} \\mathcal{L}_{\\mathrm{distill}}$ 的梯度的总和。\n\n#### 3.2. 特征空间蒸馏\n\n这里，我们鼓励学生学习与教师模型相似的隐藏表示。损失函数为：\n$$\n\\mathcal{L}_{\\text{feat}} = \\mathcal{L}_{\\mathrm{CE}}(\\text{new data}) + \\lambda_{\\mathrm{feat}} \\mathcal{L}_{\\mathrm{MSE}}(\\text{old data})\n$$\n特征空间蒸馏损失 $\\mathcal{L}_{\\mathrm{MSE}}$ 是教师模型和学生模型在旧任务数据上隐藏层激活值（$\\mathbf{h}_{\\text{teacher}}$ 和 $\\mathbf{h}_{\\text{student}}$）之间的均方误差：\n$$\n\\mathcal{L}_{\\mathrm{MSE}} = \\|\\mathbf{h}_{\\text{student}} - \\mathbf{h}_{\\text{teacher}}\\|_2^2 = \\sum_{j=1}^H (h_{\\text{student}, j} - h_{\\text{teacher}, j})^2\n$$\n该损失相对于学生模型隐藏激活值 $\\mathbf{h}_{\\text{student}}$ 的梯度是 $2(\\mathbf{h}_{\\text{student}} - \\mathbf{h}_{\\text{teacher}})$。该梯度通过第一层的激活函数和权重进行反向传播。最后一层的参数 $(\\mathbf{W}_2, \\mathbf{b}_2)$ 不受此蒸馏损失的影响，仅根据新任务的 $\\mathcal{L}_{\\mathrm{CE}}$ 进行更新。第一层的参数 $(\\mathbf{W}_1, \\mathbf{b}_1)$ 使用来自两个损失分量的组合梯度进行更新。\n\n### 4. 评估方法\n\n旧任务决策边界的保留程度通过测量模型在特定“探测点”上有符号间隔的变化来量化。有符号间隔定义为 $m(\\mathbf{x}) = z_1(\\mathbf{x}) - z_0(\\mathbf{x})$，其中决策边界位于 $m(\\mathbf{x}) = 0$。\n\n探测点是旧任务训练集中教师模型绝对间隔 $|m_{\\text{old}}(\\mathbf{x})|$ 最小的 $K$ 个样本。根据定义，这些点最接近教师模型学习到的决策边界。\n\n对于每个学生模型（每种策略一个），在这些 $K$ 个探测点上计算平均绝对间隔变化 $\\Delta$：\n$$\n\\Delta = \\frac{1}{K} \\sum_{i=1}^K |m_{\\text{student}}(\\mathbf{x}_i) - m_{\\text{old}}(\\mathbf{x}_i)|\n$$\n较小的 $\\Delta$ 表示对细粒度决策边界的保留效果更好。每个测试用例的最终输出是一个布尔值，指示输出空间蒸馏是否比特征空间蒸馏取得了严格更小的 $\\Delta$（$\\Delta_{\\text{out}}  \\Delta_{\\text{feat}}$）。", "answer": "```python\nimport numpy as np\n\ndef softmax(z):\n    \"\"\"Computes softmax for a batch of logits.\"\"\"\n    # Subtract max for numerical stability\n    exp_z = np.exp(z - np.max(z, axis=-1, keepdims=True))\n    return exp_z / np.sum(exp_z, axis=-1, keepdims=True)\n\ndef tanh(a):\n    \"\"\"Hyperbolic tangent activation.\"\"\"\n    return np.tanh(a)\n\ndef one_hot(y, C):\n    \"\"\"Converts a vector of labels to one-hot encoding.\"\"\"\n    return np.eye(C)[y]\n\nclass NeuralNetwork:\n    \"\"\"A one-hidden-layer neural network.\"\"\"\n\n    def __init__(self, d, H, C, seed):\n        \"\"\"Initializes network parameters.\"\"\"\n        rng = np.random.default_rng(seed)\n        # Xavier/Glorot initialization for tanh activation\n        self.W1 = rng.normal(0, np.sqrt(1.0 / d), (d, H))\n        self.b1 = np.zeros((1, H))\n        self.W2 = rng.normal(0, np.sqrt(1.0 / H), (H, C))\n        self.b2 = np.zeros((1, C))\n\n    def get_params(self):\n        \"\"\"Returns a copy of the model parameters.\"\"\"\n        return self.W1.copy(), self.b1.copy(), self.W2.copy(), self.b2.copy()\n\n    def set_params(self, W1, b1, W2, b2):\n        \"\"\"Sets the model parameters.\"\"\"\n        self.W1, self.b1, self.W2, self.b2 = W1, b1, W2, b2\n\n    def forward(self, X):\n        \"\"\"Performs a forward pass.\"\"\"\n        a1 = X @ self.W1 + self.b1\n        h = tanh(a1)\n        z = h @ self.W2 + self.b2\n        p = softmax(z)\n        return z, p, h, a1\n\n    def get_margin(self, X):\n        \"\"\"Computes the signed margin for binary classification.\"\"\"\n        z, _, _, _ = self.forward(X)\n        return z[:, 1] - z[:, 0]\n\n    def train_teacher(self, X_old, y_old_one_hot, eta, iterations):\n        \"\"\"Trains the teacher model using standard gradient descent.\"\"\"\n        n_samples = X_old.shape[0]\n        for _ in range(iterations):\n            z, p, h, a1 = self.forward(X_old)\n            \n            # Gradient of CE loss w.r.t logits\n            dz = (p - y_old_one_hot) / n_samples\n            \n            # Backpropagate gradients\n            dW2 = h.T @ dz\n            db2 = np.sum(dz, axis=0, keepdims=True)\n            \n            dh = dz @ self.W2.T\n            da1 = dh * (1 - h**2)\n            \n            dW1 = X_old.T @ da1\n            db1 = np.sum(da1, axis=0, keepdims=True)\n            \n            # Update parameters\n            self.W1 -= eta * dW1\n            self.b1 -= eta * db1\n            self.W2 -= eta * dW2\n            self.b2 -= eta * db2\n\n    def train_student_output_distill(self, X_new, y_new_one_hot, X_old, teacher_model, eta, iterations, lambda_out, T):\n        \"\"\"Trains a student using output-space distillation.\"\"\"\n        n_new, n_old = X_new.shape[0], X_old.shape[0]\n        for _ in range(iterations):\n            # Gradients from new task (Cross-Entropy)\n            z_new, p_new, h_new, _ = self.forward(X_new)\n            dz_ce = (p_new - y_new_one_hot) / n_new\n            dW2_ce = h_new.T @ dz_ce\n            db2_ce = np.sum(dz_ce, axis=0, keepdims=True)\n            dh_ce = dz_ce @ self.W2.T\n            da1_ce = dh_ce * (1 - h_new**2)\n            dW1_ce = X_new.T @ da1_ce\n            db1_ce = np.sum(da1_ce, axis=0, keepdims=True)\n            \n            # Gradients from old task (Distillation)\n            if lambda_out > 0:\n                z_old_student, _, h_old_student, _ = self.forward(X_old)\n                z_old_teacher, _, _, _ = teacher_model.forward(X_old)\n                \n                p_student_soft = softmax(z_old_student / T)\n                p_teacher_soft = softmax(z_old_teacher / T)\n                \n                # Gradient of T^2 * D_KL w.r.t logits\n                dz_kl = (p_student_soft - p_teacher_soft) / n_old\n                \n                dW2_kl = h_old_student.T @ dz_kl\n                db2_kl = np.sum(dz_kl, axis=0, keepdims=True)\n                dh_kl = dz_kl @ self.W2.T\n                da1_kl = dh_kl * (1 - h_old_student**2)\n                dW1_kl = X_old.T @ da1_kl\n                db1_kl = np.sum(da1_kl, axis=0, keepdims=True)\n            else:\n                dW1_kl, db1_kl, dW2_kl, db2_kl = 0, 0, 0, 0\n                \n            # Combine gradients and update\n            self.W1 -= eta * (dW1_ce + lambda_out * dW1_kl)\n            self.b1 -= eta * (db1_ce + lambda_out * db1_kl)\n            self.W2 -= eta * (dW2_ce + lambda_out * dW2_kl)\n            self.b2 -= eta * (db2_ce + lambda_out * db2_kl)\n\n    def train_student_feature_distill(self, X_new, y_new_one_hot, X_old, teacher_model, eta, iterations, lambda_feat):\n        \"\"\"Trains a student using feature-space distillation.\"\"\"\n        n_new, n_old = X_new.shape[0], X_old.shape[0]\n        for _ in range(iterations):\n            # Gradients from new task (Cross-Entropy)\n            z_new, p_new, h_new, _ = self.forward(X_new)\n            dz_ce = (p_new - y_new_one_hot) / n_new\n            dW2_ce = h_new.T @ dz_ce\n            db2_ce = np.sum(dz_ce, axis=0, keepdims=True)\n            dh_ce = dz_ce @ self.W2.T\n            da1_ce = dh_ce * (1 - h_new**2)\n            dW1_ce = X_new.T @ da1_ce\n            db1_ce = np.sum(da1_ce, axis=0, keepdims=True)\n            \n            # Gradients from old task (Feature MSE)\n            if lambda_feat > 0:\n                _, _, h_old_student, _ = self.forward(X_old)\n                _, _, h_old_teacher, _ = teacher_model.forward(X_old)\n                \n                # Gradient of MSE loss w.r.t student's hidden activations\n                dh_mse = 2 * (h_old_student - h_old_teacher) / n_old\n                da1_mse = dh_mse * (1 - h_old_student**2)\n                dW1_mse = X_old.T @ da1_mse\n                db1_mse = np.sum(da1_mse, axis=0, keepdims=True)\n                dW2_mse, db2_mse = 0, 0\n            else:\n                dW1_mse, db1_mse, dW2_mse, db2_mse = 0, 0, 0, 0\n\n            # Combine gradients and update\n            self.W1 -= eta * (dW1_ce + lambda_feat * dW1_mse)\n            self.b1 -= eta * (db1_ce + lambda_feat * db1_mse)\n            self.W2 -= eta * (dW2_ce + lambda_feat * dW2_mse)\n            self.b2 -= eta * (db2_ce + lambda_feat * db2_mse)\n\ndef generate_data(n_samples, mu0, mu1, sigma, seed):\n    \"\"\"Generates 2D Gaussian data for binary classification.\"\"\"\n    rng = np.random.default_rng(seed)\n    n0 = n_samples // 2\n    n1 = n_samples - n0\n    X0 = rng.normal(loc=mu0, scale=sigma, size=(n0, 2))\n    X1 = rng.normal(loc=mu1, scale=sigma, size=(n1, 2))\n    X = np.vstack((X0, X1))\n    y = np.array([0] * n0 + [1] * n1)\n    return X, y\n\ndef solve():\n    \"\"\"Main function to run the experiment for all test cases.\"\"\"\n    test_cases = [\n        {'seed': 0, 'n_old': 200, 'n_new': 200, 'mu0_old': (-1.0, 0.0), 'mu1_old': (1.0, 0.0), 'sigma_old': 0.4, 'mu0_new': (0.0, -1.0), 'mu1_new': (0.0, 1.0), 'sigma_new': 0.4, 'H': 16, 'eta': 0.05, 'teacher_iterations': 300, 'student_iterations': 300, 'lambda_out': 0.5, 'lambda_feat': 0.5, 'T': 2.0, 'K': 40},\n        {'seed': 1, 'n_old': 240, 'n_new': 240, 'mu0_old': (-0.3, 0.0), 'mu1_old': (0.3, 0.0), 'sigma_old': 0.35, 'mu0_new': (0.0, -0.6), 'mu1_new': (0.0, 0.6), 'sigma_new': 0.35, 'H': 24, 'eta': 0.05, 'teacher_iterations': 400, 'student_iterations': 350, 'lambda_out': 0.4, 'lambda_feat': 0.8, 'T': 2.5, 'K': 60},\n        {'seed': 2, 'n_old': 220, 'n_new': 220, 'mu0_old': (-0.8, -0.2), 'mu1_old': (0.8, 0.2), 'sigma_old': 0.45, 'mu0_new': (0.2, -0.8), 'mu1_new': (-0.2, 0.8), 'sigma_new': 0.45, 'H': 20, 'eta': 0.05, 'teacher_iterations': 350, 'student_iterations': 320, 'lambda_out': 0.0, 'lambda_feat': 0.6, 'T': 2.0, 'K': 50}\n    ]\n\n    results = []\n    for case in test_cases:\n        p = case # Use shorter alias for params\n        \n        # 1. Generate seeds and data\n        rng = np.random.default_rng(p['seed'])\n        seed_data_old = rng.integers(1e9)\n        seed_data_new = rng.integers(1e9)\n        seed_model = rng.integers(1e9)\n\n        X_old, y_old = generate_data(p['n_old'], p['mu0_old'], p['mu1_old'], p['sigma_old'], seed_data_old)\n        X_new, y_new = generate_data(p['n_new'], p['mu0_new'], p['mu1_new'], p['sigma_new'], seed_data_new)\n        y_old_one_hot = one_hot(y_old, 2)\n        y_new_one_hot = one_hot(y_new, 2)\n\n        # 2. Train teacher model\n        teacher_model = NeuralNetwork(d=2, H=p['H'], C=2, seed=seed_model)\n        teacher_model.train_teacher(X_old, y_old_one_hot, p['eta'], p['teacher_iterations'])\n\n        # 3. Identify probe points and get teacher margins\n        teacher_margins = teacher_model.get_margin(X_old)\n        probe_indices = np.argsort(np.abs(teacher_margins))[:p['K']]\n        X_probe = X_old[probe_indices]\n        old_margins_at_probes = teacher_model.get_margin(X_probe)\n        \n        # 4. Train and evaluate student with output-space distillation\n        student_out = NeuralNetwork(d=2, H=p['H'], C=2, seed=seed_model) # Re-use seed for identical init\n        student_out.train_student_output_distill(X_new, y_new_one_hot, X_old, teacher_model, p['eta'], p['student_iterations'], p['lambda_out'], p['T'])\n        student_out_margins = student_out.get_margin(X_probe)\n        delta_out = np.mean(np.abs(student_out_margins - old_margins_at_probes))\n\n        # 5. Train and evaluate student with feature-space distillation\n        student_feat = NeuralNetwork(d=2, H=p['H'], C=2, seed=seed_model) # Re-use seed for identical init\n        student_feat.train_student_feature_distill(X_new, y_new_one_hot, X_old, teacher_model, p['eta'], p['student_iterations'], p['lambda_feat'])\n        student_feat_margins = student_feat.get_margin(X_probe)\n        delta_feat = np.mean(np.abs(student_feat_margins - old_margins_at_probes))\n\n        # 6. Compare and store result\n        results.append(delta_out  delta_feat)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3109241"}, {"introduction": "基于投影的方法为持续学习提供了一种优雅的几何视角，其核心思想是将新任务的梯度更新限制在一个不干扰旧任务知识的“安全”子空间内。这个练习将使用奇异值分解（Singular Value Decomposition, SVD）来演示这一概念，SVD能够帮助我们识别出对旧任务至关重要的权重方向，随后通过正交投影（orthogonal projection）确保梯度更新与这些关键方向正交。通过在一个简单的线性模型上实现这一投影机制 [@problem_id:3109216]，你将能够量化其在减少遗忘方面的显著效果，并直观地理解如何利用几何约束来解决任务间的冲突，这也是许多高级持续学习算法的基石。", "problem": "要求您实现并分析一种用于线性模型的持续学习策略。该策略通过将新任务的更新投影到由奇异值分解（SVD）确定的零空间上，来保护对先前学习过的任务至关重要的权重方向。目标是基于线性最小二乘法、平方损失的梯度以及源自奇异值分解（SVD）的正交投影的基本定义进行推理。您将量化这种保护在多大程度上减少了遗忘，遗忘的度量方式为：在对新任务进行一步梯度更新后，旧任务损失的增加量。\n\n定义与框架：\n- 考虑一个权重为 $w \\in \\mathbb{R}^{d}$ 的线性模型，其平方损失为 $L(X,y;w) = \\frac{1}{2n}\\lVert Xw - y \\rVert_{2}^{2}$，其中 $X \\in \\mathbb{R}^{n \\times d}$ 且 $y \\in \\mathbb{R}^{n}$。\n- 对于旧任务，将数据表示为 $(X_{\\mathrm{old}}, y_{\\mathrm{old}})$，其中 $X_{\\mathrm{old}} \\in \\mathbb{R}^{n_{\\mathrm{old}} \\times d}$ 且 $y_{\\mathrm{old}} \\in \\mathbb{R}^{n_{\\mathrm{old}}}$。通过最小化岭回归正则化目标函数 $\\frac{1}{2n_{\\mathrm{old}}}\\lVert X_{\\mathrm{old}} w - y_{\\mathrm{old}} \\rVert_{2}^{2} + \\frac{\\lambda}{2}\\lVert w \\rVert_{2}^{2}$ 进行预训练，以获得 $w_{\\mathrm{old}}$。当 $\\lambda  0$ 时，该问题存在闭式解 $w_{\\mathrm{old}} = \\left(\\frac{1}{n_{\\mathrm{old}}}X_{\\mathrm{old}}^{\\top}X_{\\mathrm{old}} + \\lambda I\\right)^{-1}\\left(\\frac{1}{n_{\\mathrm{old}}}X_{\\mathrm{old}}^{\\top}y_{\\mathrm{old}}\\right)$。\n- 对于带有数据 $(X_{\\mathrm{new}}, y_{\\mathrm{new}})$ 的新任务，新任务损失在 $w_{\\mathrm{old}}$ 处的梯度为 $g = \\nabla_{w} \\left(\\frac{1}{2n_{\\mathrm{new}}}\\lVert X_{\\mathrm{new}}w - y_{\\mathrm{new}} \\rVert^{2}\\right)\\big\\rvert_{w=w_{\\mathrm{old}}} = \\frac{1}{n_{\\mathrm{new}}}X_{\\mathrm{new}}^{\\top}\\left(X_{\\mathrm{new}}w_{\\mathrm{old}} - y_{\\mathrm{new}}\\right)$。\n\n通过奇异值分解（SVD）识别重要子空间并加以保护：\n- 计算 $X_{\\mathrm{old}}$ 的奇异值分解（SVD）为 $X_{\\mathrm{old}} = U\\Sigma V^{\\top}$，其中 $U \\in \\mathbb{R}^{n_{\\mathrm{old}} \\times d}$ 的列是标准正交的，$\\Sigma \\in \\mathbb{R}^{d \\times d}$ 是对角矩阵且其元素非负，$V \\in \\mathbb{R}^{d \\times d}$ 是正交矩阵。右奇异向量（$V$ 的列）是权重空间中的方向，而相应的奇异值量化了旧任务输出对沿这些方向移动的敏感度。前 $k$ 个右奇异向量 $V_{k} \\in \\mathbb{R}^{d \\times k}$ 的张成空间（span）定义了需要保护的重要子空间。\n- 到与 $\\mathrm{span}(V_{k})$ 正交的子空间上的正交投影算子是 $P = I - V_{k}V_{k}^{\\top}$。将新任务的梯度 $g$ 投影为 $g_{\\perp} = Pg$，并通过 $w_{\\mathrm{proj}} = w_{\\mathrm{old}} - \\eta g_{\\perp}$ 更新权重 $w$，其中 $\\eta  0$ 是学习率。作为对比，朴素的、未受保护的更新是 $w_{\\mathrm{naive}} = w_{\\mathrm{old}} - \\eta g$。\n\n量化遗忘：\n- 将旧任务损失定义为 $L_{\\mathrm{old}}(w) = \\frac{1}{2n_{\\mathrm{old}}}\\lVert X_{\\mathrm{old}}w - y_{\\mathrm{old}} \\rVert_{2}^{2}$。由更新 $w \\mapsto w'$ 引起的遗忘为 $\\Delta L_{\\mathrm{old}} = L_{\\mathrm{old}}(w') - L_{\\mathrm{old}}(w_{\\mathrm{old}})$。\n- 对于每个测试用例，根据各自的更新计算 $\\Delta L_{\\mathrm{naive}}$ 和 $\\Delta L_{\\mathrm{proj}}$，并报告比率 $r = \\frac{\\Delta L_{\\mathrm{proj}}}{\\Delta L_{\\mathrm{naive}}}$。如果 $\\Delta L_{\\mathrm{naive}}$ 在数值上为零（小于一个小的容差），则定义 $r = 0.0$。\n\n用于确定性、无单位实验的数据生成：\n- 使用由指定的整数种子 $s$ 初始化的伪随机数生成器来生成测试用例中的所有随机量。对于每个测试用例，使用以下固定的超参数：维度 $d = 6$，旧任务样本量 $n_{\\mathrm{old}} = 60$，新任务样本量 $n_{\\mathrm{new}} = 50$，岭回归系数 $\\lambda = 10^{-6}$，以及学习率 $\\eta = 0.5$。\n- 旧任务：从独立标准正态分布中抽取 $X_{\\mathrm{old}} \\in \\mathbb{R}^{60 \\times 6}$ 和 $w_{\\ast,\\mathrm{old}} \\in \\mathbb{R}^{6}$。设置 $y_{\\mathrm{old}} = X_{\\mathrm{old}} w_{\\ast,\\mathrm{old}}$（无观测噪声）。\n- 新任务：从独立标准正态分布中抽取 $X_{\\mathrm{new}} \\in \\mathbb{R}^{50 \\times 6}$。为了精确控制新任务的梯度方向，首先计算奇异值分解（SVD）$X_{\\mathrm{old}} = U\\Sigma V^{\\top}$。然后根据测试用例的模式（定义如下）选择一个目标方向 $a \\in \\mathbb{R}^{6}$。求解 $(X_{\\mathrm{new}}^{\\top}X_{\\mathrm{new}})v = a$ 得到 $v \\in \\mathbb{R}^{6}$，并设置 $y_{\\mathrm{new}} = X_{\\mathrm{new}} w_{\\mathrm{old}} - X_{\\mathrm{new}} v$。这种构造精确地得到 $g = \\frac{1}{n_{\\mathrm{new}}}a$，确保新任务的梯度与 $a$ 确定性地对齐。\n- 选择 $a$ 的模式：\n  - top：将 $a$ 设置为 $X_{\\mathrm{old}}$ 的第一个右奇异向量 $V[:,1]$（注意这里是数学索引；在代码中，使用从零开始的索引）。\n  - orth：如果 $k  d$，则将 $a$ 设置为 $V[:,k+1]$，这保证了它与受保护的子空间 $\\mathrm{span}(V_{k})$ 正交。\n  - mix：将 $a$ 设置为一个归一化的凸组合，具体为 $a \\propto \\alpha V[:,1] + (1-\\alpha) V[:,j]$，其中当 $k  d$ 时 $j = k+1$，否则 $j=2$，且 $\\alpha = 0.6$。\n  - random：抽取一个标准正态向量并将其归一化为单位长度。\n\n测试套件：\n为以下五个测试用例实现上述流程，每个用例由一个三元组 $(s,k,\\text{mode})$ 指定：\n- $(7, 0, \\text{top})$\n- $(11, 6, \\text{top})$\n- $(5, 2, \\text{top})$\n- $(13, 2, \\text{orth})$\n- $(17, 3, \\text{mix})$\n\n要求输出：\n- 对于每个测试用例，计算如上定义的比率 $r = \\frac{\\Delta L_{\\mathrm{proj}}}{\\Delta L_{\\mathrm{naive}}}$。输出是无单位的实数。您的程序应生成一行输出，其中包含一个用方括号括起来的、以逗号分隔的结果列表（例如，\"[0.5,0.0,1.0]\"），结果的顺序与上述测试用例的顺序一致。", "solution": "该问题要求实现并分析一种旨在减轻线性模型中灾难性遗忘的持续学习策略。其核心原则是在学习新任务的同时，保护从先前任务（“旧任务”）中获取的知识。这种保护是通过以下方式实现的：首先识别出对旧任务性能至关重要的模型权重子空间，然后将新任务的更新限制在该子空间的正交空间内。该方法利用奇异值分解（SVD）来识别关键子空间，并利用正交投影来施加学习约束。\n\n首先，我们建立数学框架。我们考虑一个线性模型 $f(x; w) = x^{\\top}w$，其权重为 $w \\in \\mathbb{R}^{d}$。对于一个数据集 $(X, y)$，其中 $X \\in \\mathbb{R}^{n \\times d}$ 且 $y \\in \\mathbb{R}^{n}$，其性能由均方误差（或称平方损失）$L(X,y;w) = \\frac{1}{2n}\\lVert Xw - y \\rVert_{2}^{2}$ 来衡量。\n\n该过程首先在“旧任务”上训练模型，该任务由数据 $(X_{\\mathrm{old}}, y_{\\mathrm{old}})$ 定义。为了获得初始权重 $w_{\\mathrm{old}}$，我们最小化一个岭回归正则化目标函数，以确保问题是适定的（well-posed）并防止权重过大：\n$$\n\\min_{w} \\left( \\frac{1}{2n_{\\mathrm{old}}}\\lVert X_{\\mathrm{old}} w - y_{\\mathrm{old}} \\rVert_{2}^{2} + \\frac{\\lambda}{2}\\lVert w \\rVert_{2}^{2} \\right)\n$$\n这个凸优化问题的解具有闭式形式：\n$$\nw_{\\mathrm{old}} = \\left(\\frac{1}{n_{\\mathrm{old}}}X_{\\mathrm{old}}^{\\top}X_{\\mathrm{old}} + \\lambda I\\right)^{-1}\\left(\\frac{1}{n_{\\mathrm{old}}}X_{\\mathrm{old}}^{\\top}y_{\\mathrm{old}}\\right)\n$$\n其中 $I$ 是 $d \\times d$ 的单位矩阵，$\\lambda  0$ 是正则化系数。\n\n接下来，为了识别权重空间中对旧任务最重要的方向，我们对数据矩阵 $X_{\\mathrm{old}}$ 进行奇异值分解（SVD）：$X_{\\mathrm{old}} = U\\Sigma V^{\\top}$。这里，$V \\in \\mathbb{R}^{d \\times d}$ 的列是右奇异向量，它们构成了权重空间 $\\mathbb{R}^d$ 的一个标准正交基。$\\Sigma$ 对角线上的相应奇异值表明了旧任务的预测对沿这些方向的权重扰动的敏感度。由前 $k$ 个右奇异向量张成的子空间 $\\mathrm{span}(V_{k})$（其中 $V_k \\in \\mathbb{R}^{d \\times k}$ 包含 $V$ 的前 $k$ 列）被认为是需要保护的“重要子空间”。\n\n当从数据 $(X_{\\mathrm{new}}, y_{\\mathrm{new}})$ 学习一个“新任务”时，标准方法是使用梯度步骤来更新权重，$w_{\\mathrm{naive}} = w_{\\mathrm{old}} - \\eta g$，其中 $\\eta$ 是学习率，$g$ 是在 $w_{\\mathrm{old}}$ 处评估的新任务损失的梯度：\n$$\ng = \\nabla_{w} L_{\\mathrm{new}}(w)\\rvert_{w=w_{\\mathrm{old}}} = \\frac{1}{n_{\\mathrm{new}}}X_{\\mathrm{new}}^{\\top}\\left(X_{\\mathrm{new}}w_{\\mathrm{old}} - y_{\\mathrm{new}}\\right)\n$$\n为了保护旧任务，我们将此梯度投影到与重要子空间正交的子空间上。到这个“安全”零空间上的正交投影算子是 $P = I - V_{k}V_{k}^{\\top}$。投影后的梯度为 $g_{\\perp} = Pg$，相应的权重更新为 $w_{\\mathrm{proj}} = w_{\\mathrm{old}} - \\eta g_{\\perp}$。根据构造，更新步长 $-\\eta g_{\\perp}$ 在受保护的子空间内没有分量，从而最大限度地减少了对旧任务知识的干扰。\n\n为了量化此策略的有效性，我们测量每种更新类型引起的“遗忘”。“遗忘”被定义为更新后旧任务损失的增加量，即 $\\Delta L_{\\mathrm{old}} = L_{\\mathrm{old}}(w') - L_{\\mathrm{old}}(w_{\\mathrm{old}})$，其中 $w'$ 是更新后的权重向量。我们可以为此变化推导出一个解析表达式。设 $w' = w_{\\mathrm{old}} + \\delta w$。\n$$\nL_{\\mathrm{old}}(w') = \\frac{1}{2n_{\\mathrm{old}}}\\lVert X_{\\mathrm{old}}(w_{\\mathrm{old}} + \\delta w) - y_{\\mathrm{old}} \\rVert_{2}^{2} = \\frac{1}{2n_{\\mathrm{old}}}\\lVert (X_{\\mathrm{old}}w_{\\mathrm{old}} - y_{\\mathrm{old}}) + X_{\\mathrm{old}}\\delta w \\rVert_{2}^{2}\n$$\n展开范数并减去 $L_{\\mathrm{old}}(w_{\\mathrm{old}})$ 得到：\n$$\n\\Delta L_{\\mathrm{old}} = \\frac{1}{n_{\\mathrm{old}}}(X_{\\mathrm{old}}w_{\\mathrm{old}} - y_{\\mathrm{old}})^{\\top}X_{\\mathrm{old}}\\delta w + \\frac{1}{2n_{\\mathrm{old}}}\\delta w^{\\top}X_{\\mathrm{old}}^{\\top}X_{\\mathrm{old}}\\delta w\n$$\n根据 $w_{\\mathrm{old}}$ 的岭回归最优性条件，我们知道 $\\nabla_{w}L_{\\mathrm{old}}(w_{\\mathrm{old}}) + \\lambda w_{\\mathrm{old}} = 0$，这意味着 $\\frac{1}{n_{\\mathrm{old}}}X_{\\mathrm{old}}^{\\top}(X_{\\mathrm{old}}w_{\\mathrm{old}} - y_{\\mathrm{old}}) = -\\lambda w_{\\mathrm{old}}$。将此代入上式，并设 $\\delta w = -\\eta \\Delta w$（其中 $\\Delta w$ 是 $g$ 或 $g_{\\perp}$），我们得到了一个计算上更高效的公式：\n$$\n\\Delta L_{\\mathrm{old}} = \\eta \\lambda w_{\\mathrm{old}}^{\\top}\\Delta w + \\frac{\\eta^2}{2n_{\\mathrm{old}}} \\Delta w^{\\top}X_{\\mathrm{old}}^{\\top}X_{\\mathrm{old}}\\Delta w\n$$\n使用此公式，我们计算 $\\Delta L_{\\mathrm{naive}}$（当 $\\Delta w = g$）和 $\\Delta L_{\\mathrm{proj}}$（当 $\\Delta w = g_{\\perp}$）。最终的度量标准是比率 $r = \\frac{\\Delta L_{\\mathrm{proj}}}{\\Delta L_{\\mathrm{naive}}}$，它衡量了遗忘减少的程度。\n\n实验设置经过精心设计，旨在探究该方法的行为。新任务的数据 $(X_{\\mathrm{new}}, y_{\\mathrm{new}})$ 的构造使得最终的梯度 $g$ 与选定的方向 $a$ 精确对齐，从而确保了对梯度与受保护子空间的对齐如何影响遗忘进行确定性分析。不同的模式（`top`、`orth`、`mix`）代表了相对于旧任务的关键方向，新任务是最大程度冲突、完全不冲突或两者混合的场景。\n\n实现过程如下：\n1.  用给定的种子初始化随机数生成器以保证可复现性。\n2.  生成旧任务数据，并通过岭回归的闭式解计算 $w_{\\mathrm{old}}$。\n3.  对 $X_{\\mathrm{old}}$ 进行SVD以获得基 $V$。\n4.  根据测试用例的模式和 $V$ 的列来构建新任务的梯度方向 $a$。梯度则为 $g=a/n_{\\mathrm{new}}$。\n5.  计算投影梯度 $g_{\\perp} = (I - V_k V_k^{\\top})g$，其中 $V_k$ 由 $V$ 的前 $k$ 列组成。\n6.  使用推导出的解析公式计算 $\\Delta L_{\\mathrm{naive}}$ 和 $\\Delta L_{\\mathrm{proj}}$。\n7.  计算最终比率 $r$。\n对每个提供的测试用例重复此过程。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import svd, solve\n\ndef solve_problem():\n    \"\"\"\n    Implements and analyzes a continual learning strategy based on SVD and gradient projection.\n    \"\"\"\n\n    def run_one_case(s: int, k: int, mode: str) -> float:\n        \"\"\"\n        Runs a single test case for the continual learning simulation.\n\n        Args:\n            s: The seed for the pseudo-random number generator.\n            k: The number of top singular vectors to protect.\n            mode: The mode for generating the new task's gradient direction.\n\n        Returns:\n            The ratio of forgetting with projection to naive forgetting.\n        \"\"\"\n        # Initialize PRNG with the specified seed for reproducibility\n        rng = np.random.default_rng(s)\n\n        # Fixed hyperparameters from the problem statement\n        d = 6\n        n_old = 60\n        n_new = 50\n        lambda_reg = 1e-6\n        eta = 0.5\n\n        # 1. Generate data for the old task.\n        X_old = rng.standard_normal((n_old, d))\n        w_star_old = rng.standard_normal((d, 1))\n        y_old = X_old @ w_star_old\n\n        # 2. Train on the old task to find w_old.\n        # This is the solution to the ridge regression problem.\n        C = (1 / n_old) * (X_old.T @ X_old) + lambda_reg * np.identity(d)\n        b = (1 / n_old) * (X_old.T @ y_old)\n        # C is symmetric positive-definite, so we can use a specialized solver.\n        w_old = solve(C, b, assume_a='pos')\n\n        # 3. Identify the important subspace for the old task via SVD.\n        # Use thin SVD as n_old > d.\n        # V will have shape (d, d), its columns are the right singular vectors.\n        _, _, Vt = svd(X_old, full_matrices=False)\n        V = Vt.T\n\n        # 4. Generate the new task's gradient direction 'a'.\n        # The new task data is constructed to yield a gradient g = a / n_new.\n        if mode == 'top':\n            # Direction is the most important singular vector (math index 1).\n            a = V[:, 0]\n        elif mode == 'orth':\n            # Direction is orthogonal to the protected k-dimensional subspace (math index k+1).\n            # This requires k  d.\n            a = V[:, k]\n        elif mode == 'mix':\n            # Direction is a normalized mixture of a protected and an unprotected vector.\n            alpha = 0.6\n            # Math index 1 is code index 0\n            v_top = V[:, 0] \n            # j=k+1 (if k  d), else j=2. Code index: j=k (if k  d), else j=1.\n            j_idx = k if k  d else 1\n            v_orth = V[:, j_idx]\n            mixed_a = alpha * v_top + (1 - alpha) * v_orth\n            a = mixed_a / np.linalg.norm(mixed_a)\n        elif mode == 'random':\n            rand_vec = rng.standard_normal(d)\n            a = rand_vec / np.linalg.norm(rand_vec)\n\n        a = a.reshape(-1, 1)\n        g = a / n_new\n\n        # 5. Define projection and compute projected gradient.\n        # Protect the subspace spanned by the first k right singular vectors.\n        if k > 0:\n            Vk = V[:, :k]\n            P = np.identity(d) - Vk @ Vk.T\n            g_proj = P @ g\n        else: # If k=0, no projection is applied, but code structure is simpler.\n            g_proj = g\n\n        # 6. Quantify forgetting for both updates.\n        # Forgetting: ΔL = L(w') - L(w_old)\n        # Using the derived analytical formula:\n        # ΔL_old = -η * grad_L_old(w_old)^T * Δw + (1/2n_old) * ||X_old * Δw||^2\n        # where grad_L_old(w_old) = -lambda * w_old\n        # So, ΔL_old = η * λ * w_old^T * Δw + (η^2 / 2n_old) * Δw^T * X_old^T * X_old * Δw\n        def calculate_forgetting(delta_w):\n            term1 = eta * lambda_reg * (w_old.T @ delta_w)\n            term2 = (eta**2 / (2 * n_old)) * (delta_w.T @ X_old.T @ X_old @ delta_w)\n            return (term1 + term2).item()\n\n        delta_L_naive = calculate_forgetting(g)\n        delta_L_proj = calculate_forgetting(g_proj)\n\n        # 7. Compute the ratio.\n        # Handle the case where naive forgetting is near zero.\n        if np.abs(delta_L_naive)  1e-12:\n            return 0.0\n        else:\n            return delta_L_proj / delta_L_naive\n\n    test_cases = [\n        (7, 0, 'top'),\n        (11, 6, 'top'),\n        (5, 2, 'top'),\n        (13, 2, 'orth'),\n        (17, 3, 'mix')\n    ]\n\n    results = [run_one_case(*case) for case in test_cases]\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve_problem()\n```", "id": "3109216"}]}