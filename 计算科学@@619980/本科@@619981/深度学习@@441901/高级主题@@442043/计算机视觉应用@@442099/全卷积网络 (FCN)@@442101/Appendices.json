{"hands_on_practices": [{"introduction": "在全卷积网络（FCN）中，卷积层的选择是影响模型性能和计算效率的核心决策。本练习将指导你深入比较标准卷积、深度卷积和深度可分离卷积这三种关键的构建模块。通过从头推导并计算它们的参数量和浮点运算数（FLOPs），你将学会在模型的准确性和延迟之间做出量化权衡。[@problem_id:3126599]", "problem": "考虑一个构建为全卷积网络 (FCN) 的语义分割模型。在一个编码器块中，您正在评估三种可选的卷积层设计，它们都将一个空间尺寸为 $H \\times W$、拥有 $M$ 个通道的输入张量映射到一个拥有 $N$ 个通道的输出。这三种设计均使用步长为 $1$ 和“相同”填充，以使 $H_{\\text{out}} = H$ 且 $W_{\\text{out}} = W$。这三种设计分别是：标准的 $k \\times k$ 卷积、深度为 $k \\times k$ 的深度卷积（其深度乘数 $\\gamma$ 的选择使得输出通道数等于 $N$，即 $\\gamma = \\frac{N}{M}$），以及由一个深度为 $k \\times k$ 的深度卷积（深度乘数为 $1$）后接一个产生 $N$ 个输出通道的逐点 $1 \\times 1$ 卷积组成的深度可分离卷积。在参数计数中忽略偏置项。假设每次乘加运算计为 $2$ 次浮点运算 (FLOPs)，并且所有计算都是密集的。\n\n从离散卷积的定义以及卷积为每个输出位置和每个输出通道计算跨输入通道的 $k \\times k$ 空间邻域的加权和（点积）这一概念出发。基于这些原则，推导出每种设计的参数计数和 FLOPs 的表达式。然后，对于以下设置：\n- $H = W = 128$，\n- $M = 64$，\n- $N = 128$，\n- $k = 3$，\n- 硬件吞吐量 $R = 5.0 \\times 10^{11}$ FLOPs/秒，\n\n计算每种设计在单个图像上单次前向传播的总参数数和总 FLOPs。通过公式 $L = \\frac{\\text{FLOPs}}{R}$ 将 FLOPs 转换为以秒为单位的延迟，然后再转换为毫秒。在同一数据集的留出验证集上，测得三种设计的平均交并比 (mIoU) 如下：\n- 标准卷积：$0.78$，\n- 仅深度卷积（其中 $\\gamma = \\frac{N}{M}$）：$0.74$，\n- 深度可分离卷积：$0.77$。\n\n在这三者中，选择 mIoU 至少达到 $0.75$ 且延迟最小的设计。报告最终的延迟（以毫秒为单位），并将答案四舍五入到四位有效数字。以毫秒表示最终延迟。", "solution": "问题陈述已经过分析，并被认为是有效的。它在科学上基于深度学习的原理，特别是卷积神经网络。问题提取得当，提供了所有必要的数据和明确、客观的解决方案选择标准。所有术语都已定义，给定的值是现实且一致的。因此，我们可以进行完整的解答。\n\n该问题要求推导三种卷积层设计的参数计数和计算成本 (FLOPs)，然后进行数值评估，并根据性能和延迟标准进行选择。\n\n设输入张量的维度为 $H \\times W \\times M$，输出张量的维度为 $H_{\\text{out}} \\times W_{\\text{out}} \\times N$。问题指定了步长 $s=1$ 和“相同”填充，这确保了输出空间维度与输入相同，即 $H_{\\text{out}} = H$ 且 $W_{\\text{out}} = W$。我们已知一次乘加运算对计为 $2$ 次浮点运算 (FLOPs)。偏置项将被忽略。\n\n卷积层中的基本操作是计算所有输入通道上空间邻域的加权和。对于特定位置和特定输出通道的输出，这是一个滤波器与输入张量相应区域之间的点积。\n\n**设计 1：标准 $k \\times k$ 卷积**\n\n标准卷积使用 $N$ 个不同的滤波器来产生 $N$ 个输出通道。每个滤波器必须跨越输入的整个深度，因此每个滤波器的维度为 $k \\times k \\times M$。\n\n*   **参数计数 ($P_1$):**\n    有 $N$ 个滤波器，每个滤波器包含 $k \\times k \\times M$ 个权重参数。\n    $$P_1 = N \\times (k \\times k \\times M) = k^2 M N$$\n\n*   **FLOPs ($F_1$):**\n    对于 $H \\times W$ 个输出位置中的每一个，以及 $N$ 个输出通道中的每一个，我们都计算一个点积。该点积是在一个 $k \\times k \\times M$ 的滤波器和一个 $k \\times k \\times M$ 的输入块之间进行的。这涉及 $k^2 M$ 次乘法和大约 $k^2 M$ 次加法，构成 $k^2 M$ 次乘加运算对。由于每次运算对是 $2$ FLOPs，因此计算一个输出值的运算量为 $2 k^2 M$ FLOPs。\n    $$F_1 = (H \\times W) \\times N \\times (2 k^2 M) = 2 H W k^2 M N$$\n\n**设计 2：深度乘数为 $\\gamma = N/M$ 的深度 $k \\times k$ 卷积**\n\n深度卷积对每个输入通道独立应用滤波器。深度乘数 $\\gamma$ 意味着对于 $M$ 个输入通道中的每一个，我们应用 $\\gamma$ 个独立的 $k \\times k$ 滤波器，产生 $\\gamma$ 个输出通道。因此，输出通道的总数为 $M\\gamma$。问题指定 $\\gamma = N/M$，所以总输出通道数为 $M \\times (N/M) = N$，符合要求。\n\n*   **参数计数 ($P_2$):**\n    对于 $M$ 个输入通道中的每一个，都有 $\\gamma$ 个大小为 $k \\times k$ 的滤波器。滤波器总数为 $M\\gamma$。\n    $$P_2 = (M \\gamma) \\times (k \\times k) = M \\left(\\frac{N}{M}\\right) k^2 = N k^2$$\n\n*   **FLOPs ($F_2$):**\n    对于 $H \\times W$ 个输出位置中的每一个，我们计算 $M\\gamma = N$ 个输出值。每次计算都涉及单个输入通道的 $k \\times k$ 空间区域上的点积。这需要 $k^2$ 次乘加运算对，即 $2 k^2$ FLOPs。\n    $$F_2 = (H \\times W) \\times (M \\gamma) \\times (2 k^2) = (H \\times W) \\times N \\times (2 k^2) = 2 H W k^2 N$$\n\n**设计 3：深度可分离卷积**\n\n该设计包括两个连续的步骤：一个深度卷积，后跟一个逐点 ($1 \\times 1$) 卷积。\n\n*   **步骤 A：深度卷积**\n    此步骤使用深度乘数 $1$。它对 $M$ 个输入通道中的每一个应用一个 $k \\times k$ 滤波器。输出是一个大小为 $H \\times W \\times M$ 的张量。\n    *   参数 ($P_{3A}$): 有 $M$ 个大小为 $k \\times k$ 的滤波器。\n        $$P_{3A} = M \\times k^2$$\n    *   FLOPs ($F_{3A}$): 使用设计 2 的逻辑，其中 $\\gamma=1$（因此在该公式的上下文中 $N=M$）。\n        $$F_{3A} = (H \\times W) \\times M \\times (2 k^2) = 2 H W k^2 M$$\n\n*   **步骤 B：逐点卷积**\n    此步骤是一个标准的 $1 \\times 1$ 卷积，它将步骤 A 的 $M$ 通道输出映射到最终的 $N$ 个输出通道。\n    *   参数 ($P_{3B}$): 使用标准卷积（设计 1）的公式，其中 $k=1$。\n        $$P_{3B} = N \\times (1^2 \\times M) = M N$$\n    *   FLOPs ($F_{3B}$): 使用标准卷积的 FLOPs 公式，其中 $k=1$。\n        $$F_{3B} = (H \\times W) \\times N \\times (2 \\times 1^2 \\times M) = 2 H W M N$$\n\n*   **设计 3 总计：**\n    总参数和总 FLOPs 是这两个步骤的总和。\n    *   总参数 ($P_3$):\n        $$P_3 = P_{3A} + P_{3B} = M k^2 + M N = M(k^2 + N)$$\n    *   总 FLOPs ($F_3$):\n        $$F_3 = F_{3A} + F_{3B} = 2 H W k^2 M + 2 H W M N = 2 H W M (k^2 + N)$$\n\n**数值评估与选择**\n\n我们给定的值为：\n$H = 128$，$W = 128$，$M = 64$，$N = 128$，$k = 3$，以及硬件吞吐量 $R = 5.0 \\times 10^{11}$ FLOPs/s。\n\n*   **设计 1 (标准)：**\n    $P_1 = k^2 M N = 3^2 \\times 64 \\times 128 = 9 \\times 8192 = 73728$。\n    $F_1 = 2 H W k^2 M N = 2 \\times 128^2 \\times 73728 = 2 \\times 16384 \\times 73728 = 2415919104$ FLOPs。\n    $L_1 = \\frac{F_1}{R} = \\frac{2415919104}{5.0 \\times 10^{11}} \\approx 4.8318 \\times 10^{-3}~\\text{s} = 4.8318~\\text{ms}$。\n\n*   **设计 2 (仅深度卷积)：**\n    $P_2 = N k^2 = 128 \\times 3^2 = 128 \\times 9 = 1152$。\n    $F_2 = 2 H W k^2 N = 2 \\times 128^2 \\times 3^2 \\times 128 = 2 \\times 16384 \\times 9 \\times 128 = 37748736$ FLOPs。\n    $L_2 = \\frac{F_2}{R} = \\frac{37748736}{5.0 \\times 10^{11}} \\approx 7.5497 \\times 10^{-5}~\\text{s} = 0.075497~\\text{ms}$。\n\n*   **设计 3 (深度可分离)：**\n    $P_3 = M(k^2 + N) = 64 \\times (3^2 + 128) = 64 \\times (9 + 128) = 64 \\times 137 = 8768$。\n    $F_3 = 2 H W M(k^2 + N) = 2 \\times 128^2 \\times 64 \\times (3^2+128) = 2 \\times 16384 \\times 8768 = 287309824$ FLOPs。\n    $L_3 = \\frac{F_3}{R} = \\frac{287309824}{5.0 \\times 10^{11}} \\approx 5.7462 \\times 10^{-4}~\\text{s} = 0.57462~\\text{ms}$。\n\n**选择：**\n\n选择标准是：\n1.  平均交并比 (mIoU) 必须至少为 $0.75$。\n2.  在满足标准 1 的设计中，选择延迟最小的一个。\n\n给定的 mIoU 值为：\n*   标准卷积：$0.78$\n*   仅深度卷积：$0.74$\n*   深度可分离卷积：$0.77$\n\n应用标准 1：\n*   标准卷积：$0.78 \\ge 0.75$。该设计是候选方案。\n*   仅深度卷积：$0.74  0.75$。该设计不合格。\n*   深度可分离卷积：$0.77 \\ge 0.75$。该设计是候选方案。\n\n对剩余的候选方案（标准卷积和深度可分离卷积）应用标准 2：\n*   标准卷积的延迟 ($L_1$) 为 $4.8318~\\text{ms}$。\n*   深度可分离卷积的延迟 ($L_3$) 为 $0.57462~\\text{ms}$。\n\n比较延迟，我们发现 $0.57462~\\text{ms}  4.8318~\\text{ms}$。因此，深度可分离卷积设计是最佳选择，因为它在满足精度阈值的同时提供了更低的延迟。\n\n问题要求以毫秒为单位报告最终延迟，并四舍五入到四位有效数字。\n$L_3 = 0.57462~\\text{ms}$。\n四舍五入到四位有效数字得到 $0.5746~\\text{ms}$。", "answer": "$$\\boxed{0.5746}$$", "id": "3126599"}, {"introduction": "像U-Net这样的编码器-解码器架构通过跳跃连接来融合多尺度特征，从而保留精细的分割细节。然而，在实际实现中，一个常见的挑战是确保编码器路径的特征图与解码器路径上采样后的特征图在空间维度上精确对齐。本练习将引导你完成一个细致的计算过程，通过U-Net论文中经典的“裁剪”方法，来解决这一关键的对齐问题。[@problem_id:3126516]", "problem": "考虑一个用于二维图像的、具有类似 U-Net 的编码器-解码器结构的全卷积网络（FCN）。编码器有三个尺度。在每个编码器尺度上，操作序列为：两次卷积，其核大小为 $3 \\times 3$、步长为 $1$ 且不使用填充，每次卷积后跟一个修正线性单元（ReLU），然后是通过最大池化进行下采样，其核大小为 $s \\times s$、步长为 $s$。解码器通过在每个解码器尺度上使用一次转置卷积（也称为反卷积）来反转空间尺寸的减小，其核大小为 $s \\times s$、步长为 $s$、填充为0，并选择一个整数输出填充 $o$ 以确保在没有失真的情况下实现空间对齐；此上采样之后是跳跃连接的拼接，然后是两次卷积，其核大小为 $3 \\times 3$、步长为 $1$ 且不使用填充。假设所有卷积和转置卷积都使用单位扩张率，并且所有操作在高度和宽度维度上均等应用。\n\n输入图像是大小为 $N \\times N$ 的正方形，其中 $N = 256$。每个池化层的下采样步长为 $s = 2$，每个转置卷积的上采样步长也为 $s = 2$。跳跃连接将相应尺度上池化操作之前生成的编码器特征图与该尺度上转置卷积之后生成的解码器特征图进行拼接。为确保拼接时没有任何空间失真，编码器特征图在高度和宽度上被对称裁剪（每边裁剪相同数量的像素），使其空间尺寸与拼接时刻的解码器特征图完全匹配。\n\n仅使用卷积输出尺寸和转置卷积输出尺寸的基本定义，计算：\n- 尺度 $2$ 和尺度 $1$ 的编码器特征图所需的对称裁剪量（每边的像素数），以使它们在拼接时与其对应的上采样解码器特征图对齐，以及\n- 每个转置卷积中使用的最小整数输出填充 $o$，以使上采样在两个解码器阶段实现精确加倍而无空间失真。\n\n无需四舍五入。将最终答案表示为一个行矩阵，按顺序包含：尺度 $2$ 的每边裁剪量、尺度 $1$ 的每边裁剪量、与尺度 $2$ 对齐的解码器阶段转置卷积的输出填充，以及与尺度 $1$ 对齐的解码器阶段转置卷积的输出填充。", "solution": "用户希望确定一个类 U-Net 架构中必要的裁剪和输出填充值，以确保跳跃连接期间的空间对齐。\n\n首先，我们为相关操作建立从输入维度（$H_{\\text{in}}$）计算输出空间维度（$H_{\\text{out}}$）的公式。所有操作在高度和宽度上都是对称的，因此我们只需要分析一个维度。\n\n1.  **卷积**：对于核大小为 $k$、步长为 $u$、填充为 $p$ 的卷积，输出尺寸为 $H_{\\text{out}} = \\lfloor \\frac{H_{\\text{in}} + 2p - k}{u} \\rfloor + 1$。题目指定卷积的参数为 $k=3$、$u=1$ 和 $p=0$。\n    $$H_{\\text{out}} = \\left\\lfloor \\frac{H_{\\text{in}} + 2(0) - 3}{1} \\right\\rfloor + 1 = H_{\\text{in}} - 3 + 1 = H_{\\text{in}} - 2$$\n    每次这样的卷积会使空间维度减小 $2$。\n\n2.  **最大池化**：对于核大小为 $s$、步长为 $s$ 的最大池化，输出尺寸为 $H_{\\text{out}} = \\lfloor \\frac{H_{\\text{in}} - s}{s} \\rfloor + 1 = \\lfloor \\frac{H_{\\text{in}}}{s} \\rfloor$。题目指定 $s=2$。\n    $$H_{\\text{out}} = \\left\\lfloor \\frac{H_{\\text{in}}}{2} \\right\\rfloor$$\n\n3.  **转置卷积**：对于核大小为 $k_t$、步长为 $u_t$、填充为 $p_t$、输出填充为 $o$ 的转置卷积，通用公式为 $H_{\\text{out}} = (H_{\\text{in}} - 1)u_t - 2p_t + k_t + o$（假设单位扩张率）。题目指定 $k_t=s$、$u_t=s$ 和 $p_t=0$，其中 $s=2$。\n    $$H_{\\text{out}} = (H_{\\text{in}} - 1)s - 2(0) + s + o = s \\cdot H_{\\text{in}} + o = 2H_{\\text{in}} + o$$\n\n接下来，我们追踪网络编码器和解码器路径上的空间维度。\n\n**编码器路径**\n\n输入图像尺寸为 $N=256$。设 $H_i$ 为编码器尺度 $i$ 的输入尺寸，而 $H_{\\text{skip},i}$ 为在尺度 $i$ 池化前生成的、用于跳跃连接的特征图尺寸。\n\n*   **输入**：初始输入尺寸为 $H_0 = 256$。\n\n*   **编码器尺度 1**：\n    *   此尺度的输入为 $H_0 = 256$。\n    *   操作序列是两次卷积。第一次卷积后：$256 - 2 = 254$。\n    *   第二次卷积后：$254 - 2 = 252$。\n    *   这是与此尺度对应的跳跃连接的特征图：$H_{\\text{skip1}} = 252$。\n    *   接着是最大池化操作：$\\lfloor 252 / 2 \\rfloor = 126$。这是下一尺度的输入。\n\n*   **编码器尺度 2**：\n    *   此尺度的输入为 $126$。\n    *   第一次卷积后：$126 - 2 = 124$。\n    *   第二次卷积后：$124 - 2 = 122$。\n    *   这是用于跳跃连接的特征图：$H_{\\text{skip2}} = 122$。\n    *   接着是最大池化操作：$\\lfloor 122 / 2 \\rfloor = 61$。这是下一尺度的输入。\n\n*   **编码器尺度 3（瓶颈层）**：\n    *   此尺度的输入为 $61$。\n    *   第一次卷积后：$61 - 2 = 59$。\n    *   第二次卷积后：$59 - 2 = 57$。\n    *   这是瓶颈层的特征图，$H_{\\text{bottleneck}}=57$，它是解码器路径的输入。\n\n**解码器路径**\n\n解码器路径重建空间维度。设 $c_i$ 为每边的对称裁剪量，$o_i$ 为与编码器尺度 $i$ 对应的解码器阶段的输出填充。\n\n*   **第一解码器阶段（对应编码器尺度 2）**：\n    *   来自瓶颈层的输入为 $H_{\\text{bottleneck}} = 57$。\n    *   应用步长为 $s=2$ 的转置卷积。输出尺寸为 $D_{\\text{up2}} = 2 \\cdot 57 + o_2 = 114 + o_2$。\n    *   此上采样后的图必须与来自相应编码器尺度的特征图 $H_{\\text{skip2}} = 122$ 拼接。\n    *   为匹配尺寸，$H_{\\text{skip2}}$ 被对称裁剪。裁剪后的尺寸为 $H_{\\text{skip2}} - 2c_2$。\n    *   对齐条件为：$122 - 2c_2 = 114 + o_2$。\n    *   整理得：$2c_2 + o_2 = 8$。\n    *   我们必须找到能为 $c_2$ 产生整数解的最小非负整数 $o_2$。\n        *   如果 $o_2 = 0$，则 $2c_2 = 8 \\implies c_2 = 4$。这是一个有效的整数。\n        *   如果 $o_2 = 1$，则 $2c_2 = 7 \\implies c_2 = 3.5$。这不是一个整数裁剪量。\n        *   如果 $o_2 = 2$，则 $2c_2 = 6 \\implies c_2 = 3$。这是有效的，但 $o_2=2$ 不是最小的。\n    *   最小整数输出填充为 $o_2=0$，这得出的裁剪量为每边 $c_2 = 4$ 像素。\n    *   拼接后，特征图尺寸为 $114$。该图经过两次卷积：\n        *   第一次卷积后：$114 - 2 = 112$。\n        *   第二次卷积后：$112 - 2 = 110$。这是下一解码器阶段的输入。\n\n*   **第二解码器阶段（对应编码器尺度 1）**：\n    *   来自前一阶段的输入为 $110$。\n    *   应用步长为 $s=2$ 的转置卷积。输出尺寸为 $D_{\\text{up1}} = 2 \\cdot 110 + o_1 = 220 + o_1$。\n    *   此图与来自编码器尺度 1 的特征图 $H_{\\text{skip1}} = 252$ 拼接。\n    *   裁剪 $H_{\\text{skip1}}$ 后的对齐条件为：$252 - 2c_1 = 220 + o_1$。\n    *   整理得：$2c_1 + o_1 = 32$。\n    *   我们找到能为 $c_1$ 产生整数解的最小非负整数 $o_1$。\n        *   如果 $o_1 = 0$，则 $2c_1 = 32 \\implies c_1 = 16$。这是一个有效的整数。\n        *   如果 $o_1 = 1$，则 $2c_1 = 31 \\implies c_1 = 15.5$。不是整数。\n    *   最小整数输出填充为 $o_1=0$，这得出的裁剪量为每边 $c_1 = 16$ 像素。\n\n计算出的值为：\n-   尺度 2 的每边裁剪量：$c_2 = 4$。\n-   尺度 1 的每边裁剪量：$c_1 = 16$。\n-   与尺度 2 对齐的解码器阶段的输出填充：$o_2=0$。\n-   与尺度 1 对齐的解码器阶段的输出填充：$o_1=0$。\n\n最终答案以 `[c_2, c_1, o_2, o_1]` 的顺序表示为一个行矩阵。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n4  16  0  0\n\\end{pmatrix}\n}\n$$", "id": "3126516"}, {"introduction": "现代FCNs通常需要从一个共享的特征主干上同时执行多个任务，例如语义分割和边缘检测。这需要一个精心设计的多任务损失函数来联合优化模型。本练习将带你从概率论的第一性原理出发，推导并实现一个多任务学习的目标函数，并通过计算任务间的梯度对齐性来分析它们的相互作用。[@problem_id:3126589]", "problem": "给定一个用于逐像素多任务预测的全卷积网络 (FCN) 的简化抽象模型。一个全卷积网络 (FCN) 会生成一个共享的逐像素特征向量，并应用等效于 $1\\times1$ 卷积的任务特定头部，这些头部可以建模为线性映射。在此设置中，对于每个具有共享特征向量 $\\mathbf{f}\\in\\mathbb{R}^D$ 的像素，语义类别头部通过 $\\mathbf{z}^{(c)}=\\mathbf{W}^{(c)}\\mathbf{f}$ 生成一个 logit 向量 $\\mathbf{z}^{(c)}\\in\\mathbb{R}^K$，而边界头部则通过 $z^{(b)}=\\mathbf{w}^{(b)}\\mathbf{f}$ 生成一个标量 logit $z^{(b)}\\in\\mathbb{R}$。语义类别标签被建模为 $K$ 个类别上的分类变量，边界标签则被建模为指示边界是否存在的伯努利变量。\n\n使用以下基本原理进行推导和实现：\n- 分类分布和伯努利分布分别是多类分类和二元分类的标准概率模型。\n- 最大似然估计 (MLE) 旨在最大化模型下观测标签的似然，这等同于最小化负对数似然。\n- 微积分的链式法则适用于模型参数和中间变量的可微映射。\n\n您的任务是：\n- 从应用于逐像素预测的分类模型和伯努利模型的负对数似然出发，推导一个有原则的多任务目标函数，其中语义项和边界项的权重分别为 $\\alpha$ 和 $\\beta$。应使用标准的 softmax 函数将分类头部的 logit 转换为概率，使用标准的 sigmoid 函数将边界头部的 logit 转换为概率。\n- 实现该目标函数并计算其在每个测试用例上的值。对于边界项，使用根据每个测试用例计算的逆频率正类权重 $w_{+}$。该权重定义为 $w_{+} = N_{0}/N_{1}$，其中 $N_{1}$ 是边界标签为 $1$ 的像素数量，$N_{0}$ 是边界标签为 $0$ 的像素数量。特别地，如果 $N_{1}=0$，则 $w_{+}=1$。权重 $w_{+}$ 仅应用于边界标签为 $1$ 的像素。\n- 对于每个像素，在应用任务权重 $\\alpha$ 和 $\\beta$ 之前，仅使用任务特定项计算每个任务损失项关于共享特征向量 $\\mathbf{f}$ 的梯度。然后，计算该像素的语义任务梯度和边界任务梯度之间的余弦相似度。对所有像素的余弦相似度取平均，以获得平均梯度对齐度。如果某个像素的任一梯度向量范数为零，则该像素的余弦相似度定义为 $0$。\n- 为保证数值稳定性，在计算概率的对数时，将任何概率 $p$ 裁剪到区间 $[\\epsilon,1-\\epsilon]$ 内，其中 $\\epsilon=10^{-12}$。\n\n对于每个测试用例，程序必须返回一个包含三个值的列表：\n- 总多任务损失，为一个浮点数（至少有 $6$ 位有效数字），计算方式为 $\\alpha$ 乘以逐像素语义负对数似然之和，加上 $\\beta$ 乘以加权的逐像素边界负对数似然之和。\n- 平均梯度对齐度（在所有像素上平均的余弦相似度），为一个浮点数。\n- 计算出的正类权重 $w_{+}$，为一个浮点数。\n\n您的程序应生成单行输出，其中包含所有测试用例的结果，格式为一个由方括号括起来的逗号分隔列表，每个测试用例的结果本身也是一个列表，例如 $[\\,[\\text{loss}_1,\\text{align}_1,w_{+,1}],\\,[\\text{loss}_2,\\text{align}_2,w_{+,2}]\\,]$。\n\n测试套件和参数：\n\n- 测试用例 1：\n    - 图像尺寸：$H=2$，$W=2$，特征维度 $D=3$，类别数 $K=3$。\n    - 共享特征 $\\mathbf{F}\\in\\mathbb{R}^{H\\times W\\times D}$（行主序）：\n      $$\n      \\begin{aligned}\n      \\mathbf{f}_{0,0}=[\\,0.2,\\,-0.1,\\,0.3\\,],\\quad\n      \\mathbf{f}_{0,1}=[\\,0.0,\\,0.1,\\,-0.2\\,],\\\\\n      \\mathbf{f}_{1,0}=[\\,0.5,\\,0.2,\\,0.0\\,],\\quad\n      \\mathbf{f}_{1,1}=[\\,-0.3,\\,0.4,\\,0.1\\,].\n      \\end{aligned}\n      $$\n    - 语义头部权重 $\\mathbf{W}^{(c)}\\in\\mathbb{R}^{K\\times D}$：\n      $$\n      \\mathbf{W}^{(c)}=\n      \\begin{bmatrix}\n      0.1  -0.2  0.0\\\\\n      0.0  0.3  -0.1\\\\\n      -0.1  0.0  0.2\n      \\end{bmatrix}.\n      $$\n    - 边界头部权重 $\\mathbf{w}^{(b)}\\in\\mathbb{R}^{1\\times D}$：\n      $$\n      \\mathbf{w}^{(b)}=[\\,0.2,\\,-0.1,\\,0.3\\,].\n      $$\n    - 语义标签 $\\mathbf{Y}\\in\\{0,1,2\\}^{H\\times W}$：\n      $$\n      \\mathbf{Y}=\n      \\begin{bmatrix}\n      0  1\\\\\n      2  0\n      \\end{bmatrix}.\n      $$\n    - 边界标签 $\\mathbf{B}\\in\\{0,1\\}^{H\\times W}$：\n      $$\n      \\mathbf{B}=\n      \\begin{bmatrix}\n      0  1\\\\\n      1  0\n      \\end{bmatrix}.\n      $$\n    - 任务权重：$\\alpha=1.0$，$\\beta=0.5$。\n\n- 测试用例 2：\n    - 图像尺寸：$H=3$，$W=1$，特征维度 $D=2$，类别数 $K=2$。\n    - 共享特征：\n      $$\n      \\mathbf{f}_{0,0}=[\\,0.0,\\,0.0\\,],\\quad\n      \\mathbf{f}_{1,0}=[\\,0.1,\\,-0.1\\,],\\quad\n      \\mathbf{f}_{2,0}=[\\,-0.2,\\,0.3\\,].\n      $$\n    - 语义头部权重：\n      $$\n      \\mathbf{W}^{(c)}=\n      \\begin{bmatrix}\n      0.05  0.04\\\\\n      -0.03  0.02\n      \\end{bmatrix}.\n      $$\n    - 边界头部权重：\n      $$\n      \\mathbf{w}^{(b)}=[\\,0.1,\\,0.0\\,].\n      $$\n    - 语义标签：\n      $$\n      \\mathbf{Y}=\n      \\begin{bmatrix}\n      1\\\\\n      0\\\\\n      1\n      \\end{bmatrix}.\n      $$\n    - 边界标签：\n      $$\n      \\mathbf{B}=\n      \\begin{bmatrix}\n      0\\\\\n      0\\\\\n      0\n      \\end{bmatrix}.\n      $$\n    - 任务权重：$\\alpha=0.8$，$\\beta=1.2$。\n\n- 测试用例 3：\n    - 图像尺寸：$H=2$，$W=3$，特征维度 $D=2$，类别数 $K=3$。\n    - 共享特征：\n      $$\n      \\begin{aligned}\n      \\mathbf{f}_{0,0}=[\\,0.3,\\,-0.2\\,],\\quad \\mathbf{f}_{0,1}=[\\,0.0,\\,0.1\\,],\\quad \\mathbf{f}_{0,2}=[\\,-0.1,\\,0.4\\,],\\\\\n      \\mathbf{f}_{1,0}=[\\,0.2,\\,0.2\\,],\\quad \\mathbf{f}_{1,1}=[\\,-0.3,\\,-0.1\\,],\\quad \\mathbf{f}_{1,2}=[\\,0.5,\\,-0.4\\,].\n      \\end{aligned}\n      $$\n    - 语义头部权重：\n      $$\n      \\mathbf{W}^{(c)}=\n      \\begin{bmatrix}\n      0.2  -0.1\\\\\n      -0.2  0.3\\\\\n      0.1  0.0\n      \\end{bmatrix}.\n      $$\n    - 边界头部权重：\n      $$\n      \\mathbf{w}^{(b)}=[\\,-0.1,\\,0.2\\,].\n      $$\n    - 语义标签：\n      $$\n      \\mathbf{Y}=\n      \\begin{bmatrix}\n      0  2  1\\\\\n      1  0  2\n      \\end{bmatrix}.\n      $$\n    - 边界标签：\n      $$\n      \\mathbf{B}=\n      \\begin{bmatrix}\n      1  1  0\\\\\n      0  1  1\n      \\end{bmatrix}.\n      $$\n    - 任务权重：$\\alpha=0.7$，$\\beta=1.3$。", "solution": "用户要求推导多任务目标函数及其梯度，然后通过实现来计算总损失、平均梯度对齐度和用于多个测试用例的类别平衡权重。该问题定义明确，具有科学依据，并为获得唯一解提供了所有必要信息。\n\n首先，我们推导所需数量的数学表达式。我们考虑索引为 $i$ 的单个像素。其共享特征向量为 $\\mathbf{f}_i \\in \\mathbb{R}^D$。\n\n**多任务目标函数推导**\n\n总损失 $L_{total}$ 是语义分割损失和边界检测损失的加权和，在所有 $N=H \\times W$ 个像素上进行汇总。\n$$\nL_{total} = \\alpha L_{sem} + \\beta L_{bnd} = \\alpha \\sum_{i=1}^{N} L_{sem, i} + \\beta \\sum_{i=1}^{N} L_{bnd, i}^{\\text{weighted}}\n$$\n\n**语义分割损失 ($L_{sem}$)**\n\n语义头部通过线性映射为像素 $i$ 计算类别 logit $\\mathbf{z}_i^{(c)} \\in \\mathbb{R}^K$：\n$$\n\\mathbf{z}_i^{(c)} = \\mathbf{W}^{(c)} \\mathbf{f}_i\n$$\n使用 softmax 函数将这些 logit 转换为 $K$ 个类别上的概率分布：\n$$\np_{i,k}^{(c)} = \\text{softmax}(\\mathbf{z}_i^{(c)})_k = \\frac{\\exp(z_{i,k}^{(c)})}{\\sum_{j=0}^{K-1} \\exp(z_{i,j}^{(c)})}\n$$\n其中 $p_{i,k}^{(c)}$ 是预测像素 $i$ 属于类别 $k$ 的概率。给定真实整数标签 $y_i \\in \\{0, 1, \\dots, K-1\\}$，像素 $i$ 的语义损失是真实类别的负对数似然 (NLL)，也称为交叉熵损失：\n$$\nL_{sem, i} = -\\log(p_{i, y_i}^{(c)})\n$$\n为确保数值稳定性，在取对数之前，将概率 $p_{i, y_i}^{(c)}$ 裁剪到区间 $[\\epsilon, 1-\\epsilon]$ 内，其中 $\\epsilon = 10^{-12}$。\n\n**边界检测损失 ($L_{bnd}$)**\n\n边界头部为像素 $i$ 计算标量 logit $z_i^{(b)} \\in \\mathbb{R}$：\n$$\nz_i^{(b)} = \\mathbf{w}^{(b)} \\mathbf{f}_i\n$$\n使用 sigmoid 函数将该 logit 转换为像素是边界（$b_i=1$）的概率：\n$$\np_i^{(b)} = \\sigma(z_i^{(b)}) = \\frac{1}{1 + \\exp(-z_i^{(b)})}\n$$\n边界损失是加权的二元交叉熵。正类（存在边界，$b_i=1$）的权重 $w_+$ 定义为：\n$$\nw_{+} = \\begin{cases} 1  \\text{if } N_1 = 0 \\\\ N_0 / N_1  \\text{if } N_1  0 \\end{cases}\n$$\n其中 $N_1$ 是标签为 $1$ 的像素总数，$N_0$ 是标签为 $0$ 的像素总数。该权重仅应用于正样本。对于具有二元标签 $b_i \\in \\{0, 1\\}$ 的像素 $i$，其加权负对数似然为：\n$$\nL_{bnd, i}^{\\text{weighted}} = -[w_+ b_i \\log(p_i^{(b)}) + (1 - b_i) \\log(1 - p_i^{(b)})]\n$$\n为保证数值稳定性，在应用对数之前，将概率裁剪到 $[\\epsilon, 1-\\epsilon]$。\n\n**梯度对齐推导**\n\n我们需要计算未加权的、逐像素损失项关于共享特征向量 $\\mathbf{f}_i$ 的梯度。\n\n**语义损失的梯度 ($\\nabla_{\\mathbf{f}_i} L_{sem, i}$)**\n\n语义损失 $L_{sem, i} = -\\log(p_{i, y_i}^{(c)})$ 关于 $\\mathbf{f}_i$ 的梯度可通过链式法则求得。首先，我们求得关于 logit $\\mathbf{z}_i^{(c)}$ 的梯度。交叉熵损失关于 softmax 前的 logit $z_{i,j}^{(c)}$ 的导数是众所周知的：\n$$\n\\frac{\\partial L_{sem, i}}{\\partial z_{i,j}^{(c)}} = p_{i,j}^{(c)} - \\delta_{j, y_i}\n$$\n其中 $\\delta_{j, y_i}$ 是克罗内克δ。设 $\\mathbf{e}_{y_i}$ 为真实类别 $y_i$ 的独热列向量。关于 logit 向量 $\\mathbf{z}_i^{(c)}$ 的梯度是 $\\mathbf{p}_i^{(c)} - \\mathbf{e}_{y_i}$。\n使用链式法则，$\\nabla_{\\mathbf{f}_i} L_{sem, i} = (\\nabla_{\\mathbf{f}_i} \\mathbf{z}_i^{(c)})^T \\nabla_{\\mathbf{z}_i^{(c)}} L_{sem, i}$。由于 $\\mathbf{z}_i^{(c)} = \\mathbf{W}^{(c)} \\mathbf{f}_i$，雅可比矩阵 $\\nabla_{\\mathbf{f}_i} \\mathbf{z}_i^{(c)}$ 是 $\\mathbf{W}^{(c)}$。因此，梯度为：\n$$\n\\mathbf{g}_i^{(c)} = \\nabla_{\\mathbf{f}_i} L_{sem, i} = (\\mathbf{W}^{(c)})^T (\\mathbf{p}_i^{(c)} - \\mathbf{e}_{y_i})\n$$\n\n**边界损失的梯度 ($\\nabla_{\\mathbf{f}_i} L_{bnd, i}^{\\text{unweighted}}$)**\n\n为了计算梯度对齐度，我们考虑未加权的边界损失（$w_+=1$）：\n$$\nL_{bnd, i}^{\\text{unweighted}} = -[b_i \\log(p_i^{(b)}) + (1-b_i) \\log(1 - p_i^{(b)})]\n$$\n关于 logit $z_i^{(b)}$ 的梯度是使用 sigmoid 激活的二元交叉熵的标准结果：\n$$\n\\frac{\\partial L_{bnd, i}^{\\text{unweighted}}}{\\partial z_i^{(b)}} = p_i^{(b)} - b_i\n$$\n应用链式法则，且由于 $z_i^{(b)} = \\mathbf{w}^{(b)} \\mathbf{f}_i$，我们有 $\\nabla_{\\mathbf{f}_i} z_i^{(b)} = (\\mathbf{w}^{(b)})^T$。梯度变为：\n$$\n\\mathbf{g}_i^{(b)} = \\nabla_{\\mathbf{f}_i} L_{bnd, i}^{\\text{unweighted}} = (p_i^{(b)} - b_i) (\\mathbf{w}^{(b)})^T\n$$\n\n**平均梯度对齐度**\n\n对于每个像素 $i$，计算两个任务梯度 $\\mathbf{g}_i^{(c)}$ 和 $\\mathbf{g}_i^{(b)}$ 之间的余弦相似度：\n$$\n\\text{sim}_i = \\frac{\\mathbf{g}_i^{(c)} \\cdot \\mathbf{g}_i^{(b)}}{\\|\\mathbf{g}_i^{(c)}\\|_2 \\|\\mathbf{g}_i^{(b)}\\|_2}\n$$\n如果任一梯度的范数为零，则 $\\text{sim}_i$ 定义为 $0$。平均梯度对齐度是这些相似度在所有 $N$ 个像素上的平均值：\n$$\n\\text{Alignment} = \\frac{1}{N} \\sum_{i=1}^{N} \\text{sim}_i\n$$\n\n该实现将使用 NumPy 中的向量化操作为每个测试用例执行这些计算，以提高效率。", "answer": "[[5.292900223797676,0.4048866166416187,1.0],[2.585724599572622,-0.2223407982053916,1.0],[9.930419077209353,-0.4020379410191986,0.5]]", "id": "3126589"}]}