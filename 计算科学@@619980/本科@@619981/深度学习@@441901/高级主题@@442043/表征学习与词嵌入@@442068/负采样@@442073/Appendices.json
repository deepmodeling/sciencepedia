{"hands_on_practices": [{"introduction": "负采样不仅仅是一种启发式技巧，它实际上是在逼近一个明确定义的数学目标。这项练习将通过推导贝叶斯最优评分函数，揭示负采样训练过程背后的理论基础，帮助你理解模型在理想条件下应该学习的目标。通过解决这个问题，你将能够量化训练分布和测试分布之间的“分布偏移”所带来的影响，这是机器学习模型泛化能力的一个核心问题。[@problem_id:3156698]", "problem": "考虑一个具有有限结果集的离散词汇表。假设结果的训练分布表示为 $p_{\\text{train}}$，测试分布表示为 $p_{\\text{test}}$。在负采样设置中，对于每个真实（正）样本，从噪声分布 $q$ 中独立抽取 $k$ 个噪声（负）样本。负采样分类器对每个结果 $w$ 使用一个标量分数函数 $s(w)$，其对于一个配对 $(w, \\text{label})$ 的代理损失基于逻辑斯谛函数。具体来说，真实抽样的损失定义为 $s(w)$ 的逻辑斯谛函数的负对数，而噪声抽样的损失定义为 $-s(w)$ 的逻辑斯谛函数的负对数。\n\n噪声分布通过一个指数 $\\alpha \\in [0,1]$ 与数据频率相关联。对于词汇表上的任何分布 $r$，通过将每个概率提升到 $\\alpha$ 次方并进行归一化来定义噪声分布 $q^{(\\alpha)}(r)$，即对于每个结果 $w$，$q^{(\\alpha)}(r)(w) \\propto r(w)^{\\alpha}$，并进行归一化以确保 $\\sum_{w} q^{(\\alpha)}(r)(w) = 1$。\n\n假设一个模型被训练来最小化在由真实样本的 $p_{\\text{train}}$ 和噪声样本的 $q_{\\text{train}} = q^{(\\alpha)}(p_{\\text{train}})$ 形成的训练混合分布下的期望代理损失。在测试时，真实的真实分布是 $p_{\\text{test}}$，并考虑两种评估方案：\n- 方案A：负样本继续从 $q_{\\text{train}}$ 中抽取。\n- 方案B：负样本从 $q_{\\text{test}} = q^{(\\alpha)}(p_{\\text{test}})$ 中抽取。\n\n从逻辑斯谛函数 $\\sigma(x)$ 和伯努利交叉熵的基本定义，以及真实和噪声抽样混合下的期望负采样代理风险出发，根据第一性原理推导：\n1. 当真实结果遵循分布 $p$ 且每个真实样本有 $k$ 个负样本，噪声结果遵循分布 $q$ 时，对于一个通用分数函数 $s(w)$ 的期望代理风险泛函。\n2. 对于给定的 $(p,q,k)$，最小化期望代理风险的贝叶斯最优分数函数 $s^{\\star}(w)$。\n3. 一个量化的不匹配成本，定义为由训练过的分数函数 $s_{\\text{train}}$ 实现的期望代理风险与测试混合分布下的最小期望代理风险之间的差值。计算方案A（评估噪声为 $q_{\\text{train}}$）和方案B（评估噪声为 $q_{\\text{test}}$）下的不匹配成本。\n\n实现一个程序，对于下面指定的每个测试用例，计算两个浮点数：\n- 方案A不匹配成本，定义为在使用 $s_{\\text{train}}$ 时，在 $(p_{\\text{test}}, q_{\\text{train}}, k)$ 下的期望代理风险，减去在 $(p_{\\text{test}}, q_{\\text{train}}, k)$ 下的最小期望代理风险。\n- 方案B不匹配成本，定义类似，但用 $q_{\\text{test}}$ 代替 $q_{\\text{train}}$。\n\n使用以下测试套件，其中每个概率向量是针对五个结果的词汇表，总和为1，并且 $q^{(\\alpha)}(\\cdot)$ 按所述方法计算。所有概率和参数都严格为正且在科学上是合理的。\n\n- 测试用例1（一般性偏移，中等k值）：\n  - $p_{\\text{train}} = (0.40, 0.25, 0.20, 0.10, 0.05)$\n  - $p_{\\text{test}} = (0.10, 0.15, 0.25, 0.30, 0.20)$\n  - $\\alpha = 0.75$\n  - $k = 5$\n\n- 测试用例2（无偏移，训练与测试相同）：\n  - $p_{\\text{train}} = (0.20, 0.20, 0.20, 0.20, 0.20)$\n  - $p_{\\text{test}} = (0.20, 0.20, 0.20, 0.20, 0.20)$\n  - $\\alpha = 0.50$\n  - $k = 5$\n\n- 测试用例3（均匀噪声，大k值）：\n  - $p_{\\text{train}} = (0.55, 0.15, 0.10, 0.10, 0.10)$\n  - $p_{\\text{test}} = (0.10, 0.25, 0.25, 0.20, 0.20)$\n  - $\\alpha = 0.00$\n  - $k = 10$\n\n- 测试用例4（强偏移，小k值）：\n  - $p_{\\text{train}} = (0.70, 0.10, 0.10, 0.05, 0.05)$\n  - $p_{\\text{test}} = (0.05, 0.65, 0.10, 0.10, 0.10)$\n  - $\\alpha = 1.00$\n  - $k = 1$\n\n您的程序必须生成一行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。对于每个测试用例，输出方案A的不匹配成本，后跟方案B的不匹配成本。因此，最终输出必须按顺序包含对应于四个测试用例的八个数字。将每个数字表示为四舍五入到六位小数的浮点值，不带单位，并严格按照 $[r_1,r_2,\\dots,r_8]$ 的格式打印。", "solution": "该问题要求推导负采样设置中的期望代理风险、相应的贝叶斯最优分数函数，并计算两种不同评估方案下的不匹配成本。\n\n分析按要求分三步进行。首先，我们推导期望代理风险泛函。其次，我们找到最小化此风险的分数函数。第三，我们使用这些结果来定义并随后计算指定测试用例的不匹配成本。\n\n设 $\\sigma(x) = (1 + e^{-x})^{-1}$ 为逻辑斯谛函数。正样本 $w$ 的损失为 $L_{+} = -\\log(\\sigma(s(w)))$，负（噪声）样本 $w$ 的损失为 $L_{-} = -\\log(\\sigma(-s(w)))$。我们可以使用恒等式 $\\log(\\sigma(x)) = -\\log(1+e^{-x})$ 来重写这些损失：\n$L_{+} = \\log(1+e^{-s(w)})$\n$L_{-} = \\log(1+e^{s(w)})$\n\n### 1. 期望代理风险泛函\n\n负采样过程包括，对于从数据分布 $p$ 中抽取的每个真实结果 $w_{\\text{real}}$，从噪声分布 $q$ 中独立抽取 $k$ 个噪声结果 $w_{\\text{noise},1}, \\dots, w_{\\text{noise},k}$。这个“事件”（一个真实样本及其关联的 $k$ 个负样本）的总损失是各个损失的总和：\n$$\nL_{\\text{event}}(w_{\\text{real}}, w_{\\text{noise},1}, \\dots, w_{\\text{noise},k}) = -\\log(\\sigma(s(w_{\\text{real}}))) - \\sum_{i=1}^{k} \\log(\\sigma(-s(w_{\\text{noise},i})))\n$$\n期望代理风险，表示为 $R(s; p, q, k)$，是此总损失在根据各自自分布抽取的所有可能真实样本和噪声样本选择上的期望。根据期望的线性性质，我们可以分离真实样本和噪声样本的贡献：\n$$\nR(s; p, q, k) = \\mathbb{E}_{w_{\\text{real}} \\sim p, \\{w_{\\text{noise},i}\\}_{i=1}^k \\sim q} \\left[ -\\log(\\sigma(s(w_{\\text{real}}))) - \\sum_{i=1}^{k} \\log(\\sigma(-s(w_{\\text{noise},i}))) \\right]\n$$\n$$\nR(s; p, q, k) = \\mathbb{E}_{w_{\\text{real}} \\sim p} [-\\log(\\sigma(s(w_{\\text{real}})))] + \\sum_{i=1}^{k} \\mathbb{E}_{w_{\\text{noise},i} \\sim q} [-\\log(\\sigma(-s(w_{\\text{noise},i})))]\n$$\n由于噪声样本是同分布的，它们的期望损失相同。因此，我们可以简化这个和：\n$$\nR(s; p, q, k) = \\mathbb{E}_{w \\sim p} [-\\log(\\sigma(s(w)))] + k \\cdot \\mathbb{E}_{w' \\sim q} [-\\log(\\sigma(-s(w')))]\n$$\n对于离散词汇表 $V$，此期望表示为对所有结果 $w \\in V$ 的求和：\n$$\nR(s; p, q, k) = \\sum_{w \\in V} p(w) [-\\log(\\sigma(s(w)))] + k \\sum_{w \\in V} q(w) [-\\log(\\sigma(-s(w)))]\n$$\n使用数值上稳定的对数形式，这可以表示为：\n$$\nR(s; p, q, k) = \\sum_{w \\in V} \\left[ p(w)\\log(1+e^{-s(w)}) + k \\, q(w)\\log(1+e^{s(w)}) \\right]\n$$\n这就是所求的期望代理风险泛函。\n\n### 2. 贝叶斯最优分数函数\n\n为了找到最小化 $R(s; p, q, k)$ 的贝叶斯最优分数函数 $s^{\\star}(w)$，我们可以对每个结果 $w$ 独立地关于 $s(w)$ 优化风险，因为总风险是各项之和，每项仅依赖于一个 $s(w)$。让我们考虑与单个结果 $w_j \\in V$ 相关联的风险分量：\n$$\nR_j(s(w_j)) = p(w_j)\\log(1+e^{-s(w_j)}) + k \\, q(w_j)\\log(1+e^{s(w_j)})\n$$\n我们通过将关于 $s(w_j)$ 的导数设为零来找到最小值。我们使用导数 $\\frac{d}{dx}\\log(1+e^{-x}) = \\frac{-e^{-x}}{1+e^{-x}} = -\\sigma(-x)$ 和 $\\frac{d}{dx}\\log(1+e^{x}) = \\frac{e^{x}}{1+e^{x}} = \\sigma(x)$。\n$$\n\\frac{\\partial R_j}{\\partial s(w_j)} = p(w_j) (-\\sigma(-s(w_j))) + k \\, q(w_j) (\\sigma(s(w_j))) = 0\n$$\n在最优点 $s^{\\star}(w_j)$ 处，这得到：\n$$\np(w_j) \\sigma(-s^{\\star}(w_j)) = k \\, q(w_j) \\sigma(s^{\\star}(w_j))\n$$\n使用 $\\sigma(-x) = 1 - \\sigma(x)$：\n$$\np(w_j) (1 - \\sigma(s^{\\star}(w_j))) = k \\, q(w_j) \\sigma(s^{\\star}(w_j))\n$$\n重新整理以求解 $\\sigma(s^{\\star}(w_j))$：\n$$\np(w_j) = p(w_j)\\sigma(s^{\\star}(w_j)) + k \\, q(w_j)\\sigma(s^{\\star}(w_j)) = \\sigma(s^{\\star}(w_j)) (p(w_j) + k \\, q(w_j))\n$$\n$$\n\\sigma(s^{\\star}(w_j)) = \\frac{p(w_j)}{p(w_j) + k \\, q(w_j)}\n$$\n为了求得 $s^{\\star}(w_j)$ 本身，我们使用 logit 函数 $\\text{logit}(y) = \\log(y/(1-y))$ 来反转逻辑斯谛函数：\n$$\ns^{\\star}(w_j) = \\text{logit}\\left(\\frac{p(w_j)}{p(w_j) + k \\, q(w_j)}\\right) = \\log\\left( \\frac{\\frac{p(w_j)}{p(w_j) + k \\, q(w_j)}}{1 - \\frac{p(w_j)}{p(w_j) + k \\, q(w_j)}} \\right)\n$$\n$$\ns^{\\star}(w_j) = \\log\\left( \\frac{\\frac{p(w_j)}{p(w_j) + k \\, q(w_j)}}{\\frac{k \\, q(w_j)}{p(w_j) + k \\, q(w_j)}} \\right) = \\log\\left(\\frac{p(w_j)}{k \\, q(w_j)}\\right)\n$$\n因此，对于给定的分布集 $(p,q)$ 和参数 $k$，贝叶斯最优分数函数为 $s^{\\star}(w) = \\log(p(w)) - \\log(k) - \\log(q(w))$。\n\n### 3. 不匹配成本计算\n\n不匹配成本是因使用非最优分数函数而产生的额外风险。在 $(p_{\\text{train}}, q_{\\text{train}}, k)$ 上训练的模型学习到分数函数：\n$$\ns_{\\text{train}}(w) = s^{\\star}(w; p_{\\text{train}}, q_{\\text{train}}, k) = \\log\\left(\\frac{p_{\\text{train}}(w)}{k \\, q_{\\text{train}}(w)}\\right)\n$$\n其中 $q_{\\text{train}}(w) \\propto p_{\\text{train}}(w)^{\\alpha}$。\n\n**方案A：** 评估设置为 $(p_{\\text{test}}, q_{\\text{train}}, k)$。\n由训练模型产生的风险为 $R(s_{\\text{train}}; p_{\\text{test}}, q_{\\text{train}}, k)$。\n在此方案中，最小可能风险由该方案的最优分数函数实现：\n$$\ns^{\\star}_{\\text{test},A}(w) = s^{\\star}(w; p_{\\text{test}}, q_{\\text{train}}, k) = \\log\\left(\\frac{p_{\\text{test}}(w)}{k \\, q_{\\text{train}}(w)}\\right)\n$$\n相应的最小风险为 $R(s^{\\star}_{\\text{test},A}; p_{\\text{test}}, q_{\\text{train}}, k)$。\n方案A的不匹配成本是以下差值：\n$$\n\\text{Cost}_A = R(s_{\\text{train}}; p_{\\text{test}}, q_{\\text{train}}, k) - R(s^{\\star}_{\\text{test},A}; p_{\\text{test}}, q_{\\text{train}}, k)\n$$\n\n**方案B：** 评估设置为 $(p_{\\text{test}}, q_{\\text{test}}, k)$，其中 $q_{\\text{test}}(w) \\propto p_{\\text{test}}(w)^{\\alpha}$。\n由训练模型产生的风险为 $R(s_{\\text{train}}; p_{\\text{test}}, q_{\\text{test}}, k)$。\n在此方案中，最小可能风险由该方案的最优分数函数实现：\n$$\ns^{\\star}_{\\text{test},B}(w) = s^{\\star}(w; p_{\\text{test}}, q_{\\text{test}}, k) = \\log\\left(\\frac{p_{\\text{test}}(w)}{k \\, q_{\\text{test}}(w)}\\right)\n$$\n相应的最小风险为 $R(s^{\\star}_{\\text{test},B}; p_{\\text{test}}, q_{\\text{test}}, k)$。\n方案B的不匹配成本是以下差值：\n$$\n\\text{Cost}_B = R(s_{\\text{train}}; p_{\\text{test}}, q_{\\text{test}}, k) - R(s^{\\star}_{\\text{test},B}; p_{\\text{test}}, q_{\\text{test}}, k)\n$$\n\n计算的算法如下：\n1.  对于每个测试用例，给定 $p_{\\text{train}}$、$p_{\\text{test}}$、$\\alpha$ 和 $k$。\n2.  构建噪声分布 $q_{\\text{train}}(w) = \\frac{p_{\\text{train}}(w)^\\alpha}{\\sum_{w'} p_{\\text{train}}(w')^\\alpha}$ 和 $q_{\\text{test}}(w) = \\frac{p_{\\text{test}}(w)^\\alpha}{\\sum_{w'} p_{\\text{test}}(w')^\\alpha}$。\n3.  使用推导出的公式计算分数函数 $s_{\\text{train}}$、$s^{\\star}_{\\text{test},A}$ 和 $s^{\\star}_{\\text{test},B}$。\n4.  使用风险泛函 $R(s; p, q, k)$ 计算四个必要的风险值。\n5.  计算差值 $\\text{Cost}_A$ 和 $\\text{Cost}_B$。\n\n对提供的每个测试用例实施此过程。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the negative sampling mismatch cost problem for a suite of test cases.\n    \"\"\"\n\n    test_cases = [\n        # Test Case 1 (general shift, moderate k)\n        {\n            \"p_train\": np.array([0.40, 0.25, 0.20, 0.10, 0.05]),\n            \"p_test\": np.array([0.10, 0.15, 0.25, 0.30, 0.20]),\n            \"alpha\": 0.75,\n            \"k\": 5\n        },\n        # Test Case 2 (no shift, identical train and test)\n        {\n            \"p_train\": np.array([0.20, 0.20, 0.20, 0.20, 0.20]),\n            \"p_test\": np.array([0.20, 0.20, 0.20, 0.20, 0.20]),\n            \"alpha\": 0.50,\n            \"k\": 5\n        },\n        # Test Case 3 (uniform noise, large k)\n        {\n            \"p_train\": np.array([0.55, 0.15, 0.10, 0.10, 0.10]),\n            \"p_test\": np.array([0.10, 0.25, 0.25, 0.20, 0.20]),\n            \"alpha\": 0.00,\n            \"k\": 10\n        },\n        # Test Case 4 (strong shift, small k)\n        {\n            \"p_train\": np.array([0.70, 0.10, 0.10, 0.05, 0.05]),\n            \"p_test\": np.array([0.05, 0.65, 0.10, 0.10, 0.10]),\n            \"alpha\": 1.00,\n            \"k\": 1\n        },\n    ]\n\n    results = []\n    \n    def compute_q(p, alpha):\n        \"\"\"Computes the noise distribution q from a data distribution p and exponent alpha.\"\"\"\n        p_pow_alpha = np.power(p, alpha)\n        normalization_constant = np.sum(p_pow_alpha)\n        return p_pow_alpha / normalization_constant\n\n    def risk_functional(s, p, q, k):\n        \"\"\"Computes the expected surrogate risk R(s; p, q, k).\"\"\"\n        # Uses the numerically stable form: R = sum(p*log(1+exp(-s)) + k*q*log(1+exp(s)))\n        # np.logaddexp(0, x) computes log(exp(0) + exp(x)) = log(1 + exp(x))\n        term1 = p * np.logaddexp(0, -s)\n        term2 = k * q * np.logaddexp(0, s)\n        return np.sum(term1 + term2)\n\n    def optimal_score(p, q, k):\n        \"\"\"Computes the Bayes-optimal score function s_star.\"\"\"\n        # s_star(w) = log(p(w) / (k * q(w)))\n        # Probabilities are strictly positive, so no log(0) issues.\n        return np.log(p) - np.log(k) - np.log(q)\n\n    for case in test_cases:\n        p_train = case[\"p_train\"]\n        p_test = case[\"p_test\"]\n        alpha = case[\"alpha\"]\n        k = case[\"k\"]\n\n        # Compute noise distributions\n        q_train = compute_q(p_train, alpha)\n        q_test = compute_q(p_test, alpha)\n        \n        # Compute the score function learned during training\n        s_train = optimal_score(p_train, q_train, k)\n\n        # --- Regime A ---\n        # Evaluation with test data distribution but training noise distribution\n        \n        # Optimal score for Regime A's setting (p_test, q_train)\n        s_star_test_A = optimal_score(p_test, q_train, k)\n        \n        # Risk of the trained model in Regime A\n        risk_A_trained = risk_functional(s_train, p_test, q_train, k)\n        \n        # Minimal possible risk in Regime A\n        risk_A_optimal = risk_functional(s_star_test_A, p_test, q_train, k)\n        \n        cost_A = risk_A_trained - risk_A_optimal\n        results.append(cost_A)\n        \n        # --- Regime B ---\n        # Evaluation with test data distribution and test noise distribution\n        \n        # Optimal score for Regime B's setting (p_test, q_test)\n        s_star_test_B = optimal_score(p_test, q_test, k)\n        \n        # Risk of the trained model in Regime B\n        risk_B_trained = risk_functional(s_train, p_test, q_test, k)\n        \n        # Minimal possible risk in Regime B\n        risk_B_optimal = risk_functional(s_star_test_B, p_test, q_test, k)\n        \n        cost_B = risk_B_trained - risk_B_optimal\n        results.append(cost_B)\n\n    # Format output to 6 decimal places as requested\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3156698"}, {"introduction": "对比学习的一个关键假设是负样本确实是“负”的。当这个假设因“假阴性”（被错误地采样为负样本的正样本）而失效时，我们该如何应对？这项练习将指导你基于重要性加权的原理，设计并实现一个对噪声更鲁棒的对比损失函数。这对于在真实的、大规模且可能含有标签噪声的数据集上进行训练至关重要。[@problem_id:3156749]", "problem": "在带有负采样的对比学习设置中，给定一个正样本对分数和一组负样本对分数。假设使用标准的 softmax 交叉熵基础：对于一个 logits 向量 $\\{z_j\\}$，softmax 分配的概率为 $\\exp(z_j)/\\sum_\\ell \\exp(z_\\ell)$，真实类别的交叉熵损失是该概率的负对数。\n\n从这个基础出发，考虑一个场景，其中有一个正 logit $z_{+}$ 和 $K$ 个负 logits $\\{z_i^{-}\\}_{i=1}^{K}$，每个 logit 都是由相似度分数 $\\{s\\}$ 和一个逆温度 $\\tau$ 通过 $z = s / \\tau$ 构建的。在标准的带负采样的对比学习中，一个负样本被确定地视为负样本。然而，在存在噪声负样本的情况下，一个负样本 $i$ 实际上是正样本的概率为 $\\epsilon_i$（未知），并且您有每个负样本的估计值 $\\hat{\\epsilon}_i \\in [0,1]$。一种鲁棒的方法旨在根据每个负样本 $i$ 的估计洁净度成比例地降低其贡献，使用权重 $w_i \\propto (1 - \\hat{\\epsilon}_i)$，并选择一种归一化方式，使得当 $\\sum_{i=1}^{K} (1 - \\hat{\\epsilon}_i) > 0$ 时 $\\sum_{i=1}^{K} w_i = K$，否则所有 $i$ 的 $w_i = 0$。\n\n您的任务是：\n- 从 softmax 交叉熵基础推导出一个正样本和 $K$ 个负样本的无权对比损失。\n- 通过将每个负样本的未归一化贡献替换为 $w_i \\exp(z_i^{-})$ 来推导加权对应项，其中 $w_i$ 的定义如上。在噪声负样本模型下，使用重要性加权逻辑来证明此选择的合理性。\n- 在无权和加权两种情况下，推导损失函数关于任意负 logit $z_i^{-}$ 的梯度。\n- 实现一个数值稳定的程序，该程序：\n  1. 对给定的 $s_{+}$, $\\{s_i^{-}\\}$, $\\tau$, 和 $\\{\\hat{\\epsilon}_i\\}$，计算无权损失 $L_{\\mathrm{std}}$ 和加权损失 $L_{\\mathrm{rob}}$。\n  2. 在两种设置下计算关于指定负 logit 的梯度大小，并返回它们的比率 $r = \\|\\partial L_{\\mathrm{rob}}/\\partial z_i^{-}\\| / \\|\\partial L_{\\mathrm{std}}/\\partial z_i^{-}\\|$。\n\n数值稳定性要求：使用 log-sum-exp 技巧或等效的对于大数值 logits 稳定的方法来实现所有类似 softmax 的求和。\n\n角度和物理单位不适用。所有输出必须是下面指定的实数或整数。\n\n需要实现和评估的测试套件：\n- 测试 $1$（洁净負樣本，不變性）：$s_{+} = 2.5$, $\\{s_i^{-}\\} = [-0.2, 0.1, -0.5, 0.3]$, $\\tau = 0.5$, $\\hat{\\epsilon} = [0, 0, 0, 0]$。以浮点数形式输出绝对差 $\\lvert L_{\\mathrm{std}} - L_{\\mathrm{rob}} \\rvert$。\n- 测试 $2$（单个明显假负样本，鲁棒性）：$s_{+} = 0.8$, $\\{s_i^{-}\\} = [0.75, -0.1, -0.2]$, $\\tau = 0.2$, $\\hat{\\epsilon} = [1, 0, 0]$。如果 $L_{\\mathrm{rob}}  L_{\\mathrm{std}}$，输出整数 $1$，否则输出 $0$。\n- 测试 $3$（混合噪声加权）：$s_{+} = 1.0$, $\\{s_i^{-}\\} = [0.9, 0.1, -0.3, 0.2]$, $\\tau = 0.7$, $\\hat{\\epsilon} = [0.8, 0.2, 0, 0.5]$。按顺序输出 $L_{\\mathrm{std}}$ 和 $L_{\\mathrm{rob}}$ 这两个浮点数。\n- 测试 $4$（所有负样本均预测为损坏，边界情况）：$s_{+} = 1.2$, $\\{s_i^{-}\\} = [1.1, 0.9]$, $\\tau = 0.3$, $\\hat{\\epsilon} = [1, 1]$。以浮点数形式输出 $L_{\\mathrm{rob}}$。\n- 测试 $5$（完全损坏负样本的梯度抑制）：重用测试 2 的数据，并计算索引为 0 的负样本的梯度比率 $r$。以浮点数形式输出 $r$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表（例如，$[x_1,x_2,x_3,x_4,x_5,x_6]$）。\n- 对于以上五个测试，您的程序必须按顺序输出一个包含以下内容的列表：测试 1 的浮点数，测试 2 的整数，然后是测试 3 的两个浮点数，接着是测试 4 的浮点数，最后是测试 5 的浮点数，即 $[T1,T2,T3\\_L\\_{\\mathrm{std}},T3\\_L\\_{\\mathrm{rob}},T4,T5]$。", "solution": "该问题要求基于 softmax 交叉熵和重要性采样的原理，推导并实现标准和鲁棒的对比损失函数及其梯度。我们将进行严格的、分步的推导。\n\n### 第 1 部分：无权对比损失 ($L_{\\mathrm{std}}$) 的推导\n\n损失函数的基础是 softmax 交叉熵框架。对于一组 logits $\\{z_j\\}$，softmax 函数计算第 $j$ 类的概率为：\n$$ P_j = \\frac{\\exp(z_j)}{\\sum_{\\ell} \\exp(z_\\ell)} $$\n真实类别（比如类别 $c$）的交叉熵损失是其预测概率的负对数：\n$$ L = -\\log(P_c) $$\n在我们的对比学习设置中，我们有一个分数为 $s_+$ 的正样本对和 $K$ 个分数为 $\\{s_i^{-}\\}_{i=1}^{K}$ 的负样本对。Logits 由 $z = s / \\tau$ 给出，其中 $\\tau$ 是一个逆温度参数。这产生一个正 logit $z_+ = s_+ / \\tau$ 和 $K$ 个负 logits $z_i^{-} = s_i^{-} / \\tau$。\n\n用于分类任务的所有 logits 的集合是 $\\{z_+\\} \\cup \\{z_i^{-}\\}_{i=1}^{K}$。“真实类别”是正样本对。因此，分配给正样本对的概率是：\n$$ P(\\text{positive}) = \\frac{\\exp(z_+)}{\\exp(z_+) + \\sum_{i=1}^{K} \\exp(z_i^{-})} $$\n标准对比损失 $L_{\\mathrm{std}}$ 是正确识别正样本对的负对数似然：\n$$ L_{\\mathrm{std}} = -\\log\\left(\\frac{\\exp(z_+)}{\\exp(z_+) + \\sum_{i=1}^{K} \\exp(z_i^{-})}\\right) $$\n使用对数属性 $\\log(a/b) = \\log(a) - \\log(b)$，我们可以将损失重写为：\n$$ L_{\\mathrm{std}} = -\\left( \\log(\\exp(z_+)) - \\log\\left(\\exp(z_+) + \\sum_{i=1}^{K} \\exp(z_i^{-})\\right) \\right) $$\n$$ L_{\\mathrm{std}} = -z_+ + \\log\\left(\\exp(z_+) + \\sum_{i=1}^{K} \\exp(z_i^{-})\\right) $$\n这是 InfoNCE 损失的一种常见形式。\n\n### 第 2 部分：加权对比损失 ($L_{\\mathrm{rob}}$) 的推导与论证\n\n标准损失假设所有采样的负样本都是真正的负样本。在现实环境中，一些负样本可能是“假负样本”（即语义上是正样本对，但被意外地采样为负样本）。设 $\\epsilon_i$ 为第 $i$ 个负样本实际上是正样本的概率。标准损失是在“干净”负样本分布上的期望估计量，但我们采样自一个带噪声的分布。\n\n重要性采样为修正这种分布不匹配提供了一种有原则的方法。我们希望降低可能是假负样本的样本的贡献。问题为每个 $\\epsilon_i$ 提供了负样本估计值 $\\hat{\\epsilon}_i$。一个样本 $i$ 被估计为真负样本的概率是 $1 - \\hat{\\epsilon}_i$。因此，我们可以通过一个与其估计的“潔淨度” $(1 - \\hat{\\epsilon}_i)$ 成比例的因子，来重新加权划分函数（softmax 的分母）中每个负 logit 的贡献。\n\n问题将权重 $w_i$ 定义为：\n$$ w_i = \\begin{cases} \\frac{K (1 - \\hat{\\epsilon}_i)}{\\sum_{j=1}^{K} (1 - \\hat{\\epsilon}_j)}   \\text{if } \\sum_{j=1}^{K} (1 - \\hat{\\epsilon}_j)  0 \\\\ 0  \\text{otherwise} \\end{cases} $$\n这种归一化确保当至少有一个负样本没有完全损坏时，$\\sum_{i=1}^{K} w_i = K$，从而在所有负样本都是干净的（即所有 $\\hat{\\epsilon}_i = 0$，这意味着所有 $w_i = 1$）情况下，相对于无权情况保留了划分函数的尺度。\n\n鲁棒损失 $L_{\\mathrm{rob}}$ 是通过将划分函数中的每一项 $\\exp(z_i^{-})$ 替换为其加权对应项 $w_i \\exp(z_i^{-})$ 形成的。\n$$ P_{\\mathrm{rob}}(\\text{positive}) = \\frac{\\exp(z_+)}{\\exp(z_+) + \\sum_{i=1}^{K} w_i \\exp(z_i^{-})} $$\n相应的损失为：\n$$ L_{\\mathrm{rob}} = -\\log\\left(P_{\\mathrm{rob}}(\\text{positive})\\right) = -z_+ + \\log\\left(\\exp(z_+) + \\sum_{i=1}^{K} w_i \\exp(z_i^{-})\\right) $$\n\n### 第 3 部分：梯度推导\n\n我们现在推导每个损失函数关于任意负 logit $z_j^{-}$ 的梯度。\n\n**$L_{\\mathrm{std}}$ 的梯度：**\n设 $S_{\\mathrm{std}} = \\exp(z_+) + \\sum_{i=1}^{K} \\exp(z_i^{-})$。损失为 $L_{\\mathrm{std}} = -z_+ + \\log(S_{\\mathrm{std}})$。\n$$ \\frac{\\partial L_{\\mathrm{std}}}{\\partial z_j^{-}} = \\frac{\\partial}{\\partial z_j^{-}} \\left( -z_+ + \\log(S_{\\mathrm{std}}) \\right) = \\frac{1}{S_{\\mathrm{std}}} \\frac{\\partial S_{\\mathrm{std}}}{\\partial z_j^{-}} $$\n和 $S_{\\mathrm{std}}$ 关于 $z_j^{-}$ 的导数是 $\\exp(z_j^{-})$，因为各项是独立的。\n$$ \\frac{\\partial L_{\\mathrm{std}}}{\\partial z_j^{-}} = \\frac{\\exp(z_j^{-})}{\\exp(z_+) + \\sum_{i=1}^{K} \\exp(z_i^{-})} $$\n这是在所有 $K+1$ 个样本集合上为第 $j$ 个负样本计算的 softmax 概率。\n\n**$L_{\\mathrm{rob}}$ 的梯度：**\n设 $S_{\\mathrm{rob}} = \\exp(z_+) + \\sum_{i=1}^{K} w_i \\exp(z_i^{-})$。损失为 $L_{\\mathrm{rob}} = -z_+ + \\log(S_{\\mathrm{rob}})$。权重 $w_i$ 是 $\\{\\hat{\\epsilon}_k\\}$ 的函数，并且相对于 logits $\\{z_k^{-}\\}$ 是常数。\n$$ \\frac{\\partial L_{\\mathrm{rob}}}{\\partial z_j^{-}} = \\frac{\\partial}{\\partial z_j^{-}} \\left( -z_+ + \\log(S_{\\mathrm{rob}}) \\right) = \\frac{1}{S_{\\mathrm{rob}}} \\frac{\\partial S_{\\mathrm{rob}}}{\\partial z_j^{-}} $$\n和 $S_{\\mathrm{rob}}$ 关于 $z_j^{-}$ 的导数是 $w_j \\exp(z_j^{-})$。\n$$ \\frac{\\partial L_{\\mathrm{rob}}}{\\partial z_j^{-}} = \\frac{w_j \\exp(z_j^{-})}{\\exp(z_+) + \\sum_{i=1}^{K} w_i \\exp(z_i^{-})} $$\n这个梯度是 softmax 概率的一個加權版本。如果一个样本 $j$ 被视为完全损坏（$\\hat{\\epsilon}_j=1$），它的权重 $w_j$ 变为 $0$，因此，关于其 logit $z_j^{-}$ 的梯度也变为 $0$。这有效地阻止了模型学习将这个（可能是假的）负样本对推得更远。\n\n### 第 4 部分：数值稳定性\n\n直接计算涉及 $\\exp(z)$ 的表达式可能会在 $z$ 很大时导致数值溢出，在 $z$ 是非常小的负数时导致下溢。一个标准的缓解技术是 log-sum-exp 技巧。其恒等式为：\n$$ \\log\\left(\\sum_j \\exp(x_j)\\right) = c + \\log\\left(\\sum_j \\exp(x_j - c)\\right), \\quad \\text{where } c = \\max_j(x_j) $$\n这种变换可以防止溢出，因为 $\\exp$ 的最大参数变为 $0$。\n\n对于 $L_{\\mathrm{std}}$，我们直接将此技巧应用于 logits $\\{z_+, z_1^{-}, \\dots, z_K^{-}\\}$。\n对于 $L_{\\mathrm{rob}}$，和为 $\\exp(z_+) + \\sum_i w_i \\exp(z_i^{-})$。为了数值稳定性，可以通过将对数因子移入指数中来重写，对于 $w_i0$：$\\exp(\\log(w_i) + z_i^{-})$。那么损失的表达式是：\n$$ L_{\\mathrm{rob}} = -z_+ + \\log\\left(\\exp(z_+) + \\sum_{i: w_i0} \\exp(\\log(w_i) + z_i^{-})\\right) $$\n我们现在可以将 log-sum-exp 技巧应用于修改后的 logits 集合 $\\{z_+\\} \\cup \\{\\log(w_i) + z_i^{-} \\mid w_i  0\\}$。如果所有的 $w_i=0$，则和为 $\\exp(z_+)$ 并且 $L_{\\mathrm{rob}} = -z_+ + \\log(\\exp(z_+)) = 0$。\n梯度是类似 softmax 的表达式，可以用类似的方式进行稳定化：\n$$ \\frac{\\exp(x_j)}{\\sum_k \\exp(x_k)} = \\frac{\\exp(x_j - c)}{\\sum_k \\exp(x_k - c)}, \\quad c = \\max_k(x_k) $$\n这等同于计算 $\\exp(x_j - \\text{LogSumExp}(\\{x_k\\}))$。这将在实现中使用。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the five test cases specified in the problem statement.\n    \"\"\"\n\n    def compute_loss_and_grad(s_plus, s_neg, tau, eps_hat, grad_idx=None):\n        \"\"\"\n        Computes standard and robust losses and gradients.\n        \"\"\"\n        z_plus = s_plus / tau\n        z_neg = np.array(s_neg) / tau\n        K = len(z_neg)\n\n        # Log-sum-exp utility for numerical stability\n        def log_sum_exp(x):\n            if x.size == 0:\n                return -np.inf  # log(0)\n            c = np.max(x)\n            return c + np.log(np.sum(np.exp(x - c)))\n\n        # --- Part 1: Unweighted Loss and Gradient ---\n        all_logits_std = np.concatenate(([z_plus], z_neg))\n        lse_std = log_sum_exp(all_logits_std)\n        l_std = -z_plus + lse_std\n\n        grad_std = None\n        if grad_idx is not None:\n            # Gradient is the softmax probability of the negative sample\n            grad_std = np.exp(z_neg[grad_idx] - lse_std)\n\n        # --- Part 2: Weighted Loss and Gradient ---\n        # Calculate weights\n        one_minus_eps = 1.0 - np.array(eps_hat)\n        sum_one_minus_eps = np.sum(one_minus_eps)\n        \n        weights = np.zeros(K)\n        # As per problem: weights are non-zero only if sum > 0\n        if sum_one_minus_eps > 0:\n            weights = K * one_minus_eps / sum_one_minus_eps\n\n        # Robust Loss\n        # Handle the case where all negatives are marked as corrupted\n        if sum_one_minus_eps == 0:\n            l_rob = 0.0\n            lse_rob = z_plus # Analytically, log(exp(z_plus))\n        else:\n            # Use log-sum-exp with modified logits for stability\n            valid_mask = weights > 0\n            log_weights = np.log(weights[valid_mask])\n            modified_neg_logits = z_neg[valid_mask] + log_weights\n            \n            all_logits_rob = np.concatenate(([z_plus], modified_neg_logits))\n            lse_rob = log_sum_exp(all_logits_rob)\n            l_rob = -z_plus + lse_rob\n\n        # Robust Gradient\n        grad_rob = None\n        if grad_idx is not None:\n            w_j = weights[grad_idx]\n            if w_j == 0:\n                grad_rob = 0.0\n            else:\n                # Gradient is the weighted softmax probability\n                grad_rob = np.exp(np.log(w_j) + z_neg[grad_idx] - lse_rob)\n        \n        return l_std, l_rob, grad_std, grad_rob\n\n    results = []\n    \n    # Test 1: clean negatives, invariance\n    s_plus, s_neg, tau, eps_hat = 2.5, [-0.2, 0.1, -0.5, 0.3], 0.5, [0, 0, 0, 0]\n    l_std_1, l_rob_1, _, _ = compute_loss_and_grad(s_plus, s_neg, tau, eps_hat)\n    results.append(abs(l_std_1 - l_rob_1))\n    \n    # Test 2: single obvious false negative, robustness\n    s_plus, s_neg, tau, eps_hat = 0.8, [0.75, -0.1, -0.2], 0.2, [1, 0, 0]\n    l_std_2, l_rob_2, _, _ = compute_loss_and_grad(s_plus, s_neg, tau, eps_hat)\n    results.append(1 if l_rob_2  l_std_2 else 0)\n\n    # Test 3: mixed noise weighting\n    s_plus, s_neg, tau, eps_hat = 1.0, [0.9, 0.1, -0.3, 0.2], 0.7, [0.8, 0.2, 0, 0.5]\n    l_std_3, l_rob_3, _, _ = compute_loss_and_grad(s_plus, s_neg, tau, eps_hat)\n    results.append(l_std_3)\n    results.append(l_rob_3)\n\n    # Test 4: all negatives predicted corrupted, boundary\n    s_plus, s_neg, tau, eps_hat = 1.2, [1.1, 0.9], 0.3, [1, 1]\n    _, l_rob_4, _, _ = compute_loss_and_grad(s_plus, s_neg, tau, eps_hat)\n    results.append(l_rob_4)\n\n    # Test 5: gradient suppression for a fully corrupted negative\n    s_plus, s_neg, tau, eps_hat, grad_idx = 0.8, [0.75, -0.1, -0.2], 0.2, [1, 0, 0], 0\n    _, _, grad_std_5, grad_rob_5 = compute_loss_and_grad(s_plus, s_neg, tau, eps_hat, grad_idx)\n    # The gradients are non-negative, so magnitude is the value itself.\n    # grad_std_5 will be non-zero for these inputs.\n    ratio = grad_rob_5 / grad_std_5\n    results.append(ratio)\n    \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3156749"}, {"introduction": "并非所有负样本都提供同等质量的信息，如何选择负样本本身就是一个可以优化的过程。这项练习将我们的注意力从损失函数转移到采样过程，探索如何通过优化负样本的采样分布来最小化梯度估计的方差，从而提高训练效率。这项实践将深度学习中的采样策略与蒙特卡洛方法中的核心思想联系起来，教你如何设计更“智能”、更高效的采样器。[@problem_id:3156767]", "problem": "给定一个由索引 $i \\in \\{1,\\dots,n\\}$ 标识的候选负样本的有限集，其具有一个基础数据分布 $p(i)$。考虑估计一个形如 $\\mu = \\mathbb{E}_{i \\sim p}[h(i)]$ 的期望，其中 $h(i) \\ge 0$ 量化了每个样本对一个抽样目标中梯度项的贡献大小。一个使用从提议分布 $q$ 中抽取的 $k$ 个独立负样本的标准无偏重要性采样估计器为\n$$\n\\widehat{\\mu} \\;=\\; \\frac{1}{k}\\sum_{j=1}^{k} \\frac{p(i_j)}{q(i_j)}\\,h(i_j), \\quad i_j \\sim q \\text{ independently}.\n$$\n该估计器的方差为\n$$\n\\mathrm{Var}[\\widehat{\\mu}] \\;=\\; \\frac{1}{k}\\left(\\sum_{i=1}^{n} \\frac{p(i)^{2} h(i)^{2}}{q(i)} \\;-\\; \\mu^{2}\\right),\n$$\n对于固定的 $k$，通过适当地选择 $q$ 可以使其最小化。在负采样实践中，通常使用一个混合采样器，它结合了基于频率的分布和基于难度的分布。定义混合采样器\n$$\nq_{\\lambda}(i) \\;=\\; \\lambda\\, q_{\\mathrm{freq}}(i) \\;+\\; (1-\\lambda)\\, q_{\\mathrm{hard}}(i),\n$$\n其中 $q_{\\mathrm{freq}}(i) = p(i)$ 且 $q_{\\mathrm{hard}}(i) \\propto h(i)$，即\n$$\nq_{\\mathrm{hard}}(i) \\;=\\; \\frac{h(i)}{\\sum_{j=1}^{n} h(j)}.\n$$\n对于一个固定的采样预算 $k \\in \\mathbb{N}$，此设定下的泛化误差代理指标被视为方差 $\\mathrm{Var}[\\widehat{\\mu}]$，因为负项的估计器方差越低，训练信号中的噪声就越小，泛化能力也越好。您的任务是选择混合权重 $\\lambda \\in [0,1]$，以在混合族 $q_{\\lambda}$ 下最小化 $\\mathrm{Var}[\\widehat{\\mu}]$。\n\n从重要性采样的基本定义和上述方差公式出发，推导出一个算法，该算法在给定一个离散分布 $p$ 和非负权重 $h$ 的情况下，找到能最小化 $\\mathrm{Var}[\\widehat{\\mu}]$ 的最优 $\\lambda^{\\star} \\in [0,1]$。假设在提供的测试案例中，对所有 $i$ 都有 $h(i)  0$，因此 $q_{\\mathrm{hard}}(i)$ 是良定义且严格为正的。\n\n实现要求：\n- 您的程序必须实现一个数值稳定的求解器来求解 $\\lambda^{\\star}$，仅使用“当函数\n$$\nJ(\\lambda) \\;=\\; \\sum_{i=1}^{n} \\frac{p(i)^{2} h(i)^{2}}{\\lambda\\,p(i) + (1-\\lambda)\\,q_{\\mathrm{hard}}(i)}\n$$\n在 $\\lambda \\in [0,1]$ 上最小时，方差也最小”这一原理。\n- 如果有多个 $\\lambda$ 在数值公差 $\\varepsilon = 10^{-12}$ 内达到相同的最小值，则返回满足条件的最小 $\\lambda$。\n- 对于每个测试案例，仅输出四舍五入到四位小数的最优 $\\lambda^{\\star}$。\n\n测试套件：\n- 案例 A（预期为内部最优解）：$n=5$, $p = [\\,0.40,\\,0.25,\\,0.20,\\,0.10,\\,0.05\\,]$, $h = [\\,1.0,\\,2.0,\\,2.5,\\,3.0,\\,5.0\\,]$, $k = 10$。\n- 案例 B（预期为边界解 $\\lambda = 1$）：$n=4$, $p = [\\,0.50,\\,0.30,\\,0.15,\\,0.05\\,]$, $h = [\\,1.0,\\,1.0,\\,1.0,\\,1.0\\,]$, $k = 7$。\n- 案例 C（可能为边界解 $\\lambda = 0$）：$n=5$, $p = [\\,0.40,\\,0.25,\\,0.20,\\,0.10,\\,0.05\\,]$, $h = [\\,0.1,\\,0.1,\\,0.5,\\,4.0,\\,10.0\\,]$, $k = 3$。\n- 案例 D（退化情况 $q_{\\mathrm{hard}} = p$）：$n=4$, $p = [\\,0.40,\\,0.30,\\,0.20,\\,0.10\\,]$, $h = [\\,4.0,\\,3.0,\\,2.0,\\,1.0\\,]$, $k = 5$。\n\n最终输出格式：\n- 您的程序应生成一行输出，其中包含案例 A、B、C 和 D 的四个最优值 $\\lambda^{\\star}$，以逗号分隔的列表形式包含在方括号内，例如 $[\\lambda_{A},\\lambda_{B},\\lambda_{C},\\lambda_{D}]$，其中每个条目都四舍五入到四位小数。", "solution": "目标是找到混合权重 $\\lambda \\in [0,1]$，以最小化重要性采样估计器的方差 $\\mathrm{Var}[\\widehat{\\mu}]$。方差由以下公式给出：\n$$\n\\mathrm{Var}[\\widehat{\\mu}] = \\frac{1}{k}\\left(\\sum_{i=1}^{n} \\frac{p(i)^{2} h(i)^{2}}{q(i)} - \\mu^{2}\\right)\n$$\n为了关于采样分布 $q$ 的选择来最小化 $\\mathrm{Var}[\\widehat{\\mu}]$，我们只需要考虑依赖于 $q$ 的项。由于 $k$、$p(i)$、$h(i)$ 和 $\\mu$ 对于此优化问题是固定的，该任务等价于最小化求和项。提议分布是一个混合模型 $q_{\\lambda}(i) = \\lambda\\, q_{\\mathrm{freq}}(i) + (1-\\lambda)\\, q_{\\mathrm{hard}}(i)$，其中 $q_{\\mathrm{freq}}(i) = p(i)$ 且 $q_{\\mathrm{hard}}(i) = h(i) / \\sum_{j=1}^{n} h(j)$。将 $q(i)$ 替换为 $q_{\\lambda}(i)$，我们得到一个目标函数 $J(\\lambda)$，需要在区间 $\\lambda \\in [0,1]$ 上对其进行最小化：\n$$\nJ(\\lambda) = \\sum_{i=1}^{n} \\frac{p(i)^{2} h(i)^{2}}{\\lambda\\,p(i) + (1-\\lambda)\\,q_{\\mathrm{hard}}(i)}\n$$\n这个函数 $J(\\lambda)$ 是多个独立函数之和，每个样本 $i \\in \\{1, \\dots, n\\}$ 对应一项。我们将每一项表示为 $f_i(\\lambda)$：\n$$\nf_i(\\lambda) = \\frac{c_i}{\\ell_i(\\lambda)}\n$$\n其中 $c_i = p(i)^2 h(i)^2$ 是一个非负常数，分母 $\\ell_i(\\lambda) = \\lambda p(i) + (1-\\lambda) q_{\\mathrm{hard}}(i)$ 是 $\\lambda$ 的一个线性函数。问题假设对于所有 $i$，$h(i)  0$，这意味着 $q_{\\mathrm{hard}}(i)  0$。由于 $p(i)$ 是 $n$ 个样本上的一个概率分布，我们可以假设在其支撑集内对所有 $i$ 都有 $p(i)  0$。因此，对于 $\\lambda \\in [0,1]$，$\\ell_i(\\lambda)$ 是两个严格正数 $p(i)$ 和 $q_{\\mathrm{hard}}(i)$ 的凸组合，因此它本身也是严格为正的。\n\n为了确定该优化问题的性质，我们分析 $J(\\lambda)$ 的凸性。每一项 $f_i(\\lambda)$ 关于 $\\lambda$ 的二阶导数为：\n$$\n\\frac{d^2 f_i}{d\\lambda^2} = \\frac{d^2}{d\\lambda^2} \\left( c_i (\\ell_i(\\lambda))^{-1} \\right) = \\frac{d}{d\\lambda} \\left( -c_i (\\ell_i(\\lambda))^{-2} \\frac{d\\ell_i}{d\\lambda} \\right)\n$$\n分母的导数为 $\\frac{d\\ell_i}{d\\lambda} = p(i) - q_{\\mathrm{hard}}(i)$。所以，\n$$\n\\frac{d^2 f_i}{d\\lambda^2} = -c_i \\left( -2 (\\ell_i(\\lambda))^{-3} \\left(\\frac{d\\ell_i}{d\\lambda}\\right)^2 \\right) = \\frac{2c_i(p(i) - q_{\\mathrm{hard}}(i))^2}{(\\lambda p(i) + (1-\\lambda) q_{\\mathrm{hard}}(i))^3}\n$$\n由于 $c_i \\ge 0$ 且分母为正，二阶导数 $\\frac{d^2 f_i}{d\\lambda^2}$ 对于所有 $\\lambda \\in [0,1]$ 都是非负的。这证明了每个函数 $f_i(\\lambda)$ 都是凸函数。凸函数的和也是凸函数，因此 $J(\\lambda)$ 是在区间 $[0,1]$ 上的一个凸函数。\n\n一个凸函数在闭区间上的最小值或者出现在边界点（$\\lambda=0$ 或 $\\lambda=1$）之一，或者出现在一阶导数为零的内部点 $\\lambda^{\\star} \\in (0,1)$。$J(\\lambda)$ 的一阶导数为：\n$$\nJ'(\\lambda) = \\frac{dJ}{d\\lambda} = \\sum_{i=1}^{n} \\frac{-c_i(p(i) - q_{\\mathrm{hard}}(i))}{(\\ell_i(\\lambda))^2} = - \\sum_{i=1}^{n} \\frac{p(i)^2 h(i)^2 (p(i) - q_{\\mathrm{hard}}(i))}{(\\lambda p(i) + (1-\\lambda) q_{\\mathrm{hard}}(i))^2}\n$$\n由于 $J(\\lambda)$ 是凸函数，其导数 $J'(\\lambda)$ 是一个单调不减函数。此性质允许我们高效地搜索最优的 $\\lambda^{\\star}$：\n1.  如果 $J'(0) \\ge 0$，则函数在 $[0,1]$ 上是单调不减的，所以最小值在 $\\lambda^{\\star}=0$。\n2.  如果 $J'(1) \\le 0$，则函数在 $[0,1]$ 上是单调不增的，所以最小值在 $\\lambda^{\\star}=1$。\n3.  如果 $J'(0)  0$ 且 $J'(1)  0$，则 $J'(\\lambda)$ 的连续性和单调性保证了在 $(0,1)$ 中存在一个唯一的根 $\\lambda^{\\star}$，使得 $J'(\\lambda^{\\star})=0$。这个根对应于 $J(\\lambda)$ 的唯一最小值。\n\n这引出了以下算法：\n首先，计算在边界点 $J'(0)$ 和 $J'(1)$ 的导数值。\n$$\nJ'(0) = - \\sum_{i=1}^{n} \\frac{p(i)^2 h(i)^2 (p(i) - q_{\\mathrm{hard}}(i))}{q_{\\mathrm{hard}}(i)^2}\n$$\n$$\nJ'(1) = - \\sum_{i=1}^{n} \\frac{p(i)^2 h(i)^2 (p(i) - q_{\\mathrm{hard}}(i))}{p(i)^2} = - \\sum_{i=1}^{n} h(i)^2 (p(i) - q_{\\mathrm{hard}}(i))\n$$\n根据它们的符号，我们要么将 $\\lambda^{\\star}$ 确定为 $0$ 或 $1$，要么在区间 $(0,1)$ 中寻找 $J'(\\lambda)=0$ 的根。\n对于内部解的情况，方程 $J'(\\lambda)=0$ 是一个非线性方程，可以用数值方法求解。鉴于 $J'(\\lambda)$ 是单调的，并且我们已经将根的范围限定在 $\\lambda=0$ 和 $\\lambda=1$ 之间，二分法是寻找 $\\lambda^{\\star}$ 的一种简单而鲁棒的选择。二分法算法通过在区间中点评估 $J'(mid)$ 并根据其符号更新区间，从而迭代地将搜索区间 $[low, high]$ 减半，保证收敛到唯一的根。在 $p(i) = q_{\\mathrm{hard}}(i)$ 对所有 $i$ 成立的特殊情况下，对所有 $\\lambda \\in [0,1]$ 都有 $J'(\\lambda)=0$，使得所有 $\\lambda$ 值都是最小值点。问题要求返回最小的那个，即 $\\lambda^{\\star}=0$。这种情况可以被条件 $J'(0) \\ge 0$ 正确处理。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the optimization problem for the given test cases.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A\n        {'p': [0.40, 0.25, 0.20, 0.10, 0.05], 'h': [1.0, 2.0, 2.5, 3.0, 5.0]},\n        # Case B\n        {'p': [0.50, 0.30, 0.15, 0.05], 'h': [1.0, 1.0, 1.0, 1.0]},\n        # Case C\n        {'p': [0.40, 0.25, 0.20, 0.10, 0.05], 'h': [0.1, 0.1, 0.5, 4.0, 10.0]},\n        # Case D\n        {'p': [0.40, 0.30, 0.20, 0.10], 'h': [4.0, 3.0, 2.0, 1.0]},\n    ]\n\n    def find_optimal_lambda(p, h):\n        \"\"\"\n        Calculates the optimal lambda that minimizes the variance estimator.\n\n        Args:\n            p (list or np.ndarray): The base data distribution.\n            h (list or np.ndarray): The per-item contribution weights.\n\n        Returns:\n            float: The optimal lambda value.\n        \"\"\"\n        p_vec = np.array(p, dtype=np.float64)\n        h_vec = np.array(h, dtype=np.float64)\n\n        sum_h = np.sum(h_vec)\n        q_hard_vec = h_vec / sum_h if sum_h > 0 else np.full_like(p_vec, 1.0/len(p_vec))\n\n        def J_prime(lam, p, h, q_hard):\n            \"\"\"\n            Computes the derivative of the objective function J with respect to lambda.\n            \"\"\"\n            numerator = p**2 * h**2 * (p - q_hard)\n            denominator = (lam * p + (1.0 - lam) * q_hard)**2\n            \n            # To handle potential division by zero in theory, though not \n            # expected with p(i)>0, h(i)>0.\n            # Using np.divide with a where clause is safer than adding an epsilon.\n            terms = np.divide(numerator, denominator, out=np.zeros_like(numerator), where=denominator!=0)\n            \n            return -np.sum(terms)\n\n        # A small tolerance for floating-point comparisons near zero.\n        # This is based on the logic that if the derivative is extremely\n        # close to zero at a boundary, we can consider the optimum to be there.\n        tol = 1e-12\n\n        # 1. Check boundary at lambda = 0\n        J_prime_at_0 = J_prime(0.0, p_vec, h_vec, q_hard_vec)\n        if J_prime_at_0 >= -tol:\n            return 0.0\n\n        # 2. Check boundary at lambda = 1\n        J_prime_at_1 = J_prime(1.0, p_vec, h_vec, q_hard_vec)\n        if J_prime_at_1 = tol:\n            return 1.0\n\n        # 3. Find interior minimum using bisection\n        low = 0.0\n        high = 1.0\n        # 100 iterations are sufficient for double-precision floating-point accuracy.\n        for _ in range(100):\n            mid = low + 0.5 * (high - low)\n            # If mid is indistinguishable from low or high, stop.\n            if mid == low or mid == high:\n                break\n            val = J_prime(mid, p_vec, h_vec, q_hard_vec)\n            if val  0:\n                low = mid\n            else:\n                high = mid\n        \n        return (low + high) / 2.0\n\n    results = []\n    for case in test_cases:\n        p_dist = case['p']\n        h_weights = case['h']\n        lambda_star = find_optimal_lambda(p_dist, h_weights)\n        results.append(lambda_star)\n\n    # Format results to four decimal places for the final output string.\n    formatted_results = [f\"{res:.4f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3156767"}]}