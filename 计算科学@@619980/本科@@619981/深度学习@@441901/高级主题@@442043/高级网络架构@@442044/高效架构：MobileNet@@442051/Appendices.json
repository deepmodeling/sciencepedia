{"hands_on_practices": [{"introduction": "深度可分离卷积是 MobileNet 的核心创新。为了真正理解其影响，我们需要超越定性的描述，进行定量的分析。本练习将指导你从第一性原理出发，推导标准卷积和深度可分离卷积的计算成本（以乘加运算 MACs 为单位），从而揭示效率提升的来源和量级 [@problem_id:3120106]。通过这种方式，你将对高效网络设计的基础有更深刻的认识。", "problem": "一个空间分辨率为 $H=W=112$ 的 MobileNetV1 阶段，使用一个卷积核大小为 $K=3$、步长为 $1$ 的卷积，将一个具有 $C_{in}=32$ 个通道的输入张量转换为一个具有 $C_{out}=64$ 个通道的输出张量。假设使用保持空间维度不变的零填充。考虑该阶段的两种实现方式：(i) 在所有输入通道上使用 $K \\times K$ 滤波器的标准卷积；以及 (ii) 由一个深度 $K \\times K$ 卷积后跟一个逐点 $1 \\times 1$ 卷积组成的深度可分离卷积。根据离散卷积和操作计数的基本原理，计算两种实现在整个特征图上的乘法累加操作（MACs）的精确总数，其中一次乘法累加（MAC）操作定义为一次乘法和一次加法的组合。然后，作为比较指标，计算定义为标准卷积 MAC 数量与深度可分离卷积 MAC 数量之比的加速因子。在你的最终答案中，仅报告作为单个简化精确表达式的加速因子。无需四舍五入。", "solution": "基本依据是离散卷积和操作计数的定义。对于卷积层的每个输出元素，其计算涉及对输入的局部感受野与相应滤波器权重之间的乘积求和。每次乘积及其累加计为一次乘法累加（MAC）操作。\n\n对于标准卷积：\n- 有 $H \\times W$ 个空间位置和 $C_{out}$ 个输出通道，产生 $H W C_{out}$ 个输出元素。\n- 每个输出元素由一个跨越所有 $C_{in}$ 个输入通道的 $K \\times K$ 空间邻域计算得出，每个输出元素需要 $K^{2} C_{in}$ 次 MAC 操作。\n因此，标准卷积的总 MAC 数量为\n$$\n\\text{MAC}_{\\text{std}} = H W C_{out} K^{2} C_{in}\n$$\n\n对于深度可分离卷积，计算分为两部分：\n\n1. 深度卷积：\n- 有 $H \\times W$ 个空间位置和 $C_{in}$ 个独立的深度滤波器，每个输入通道一个，产生 $H W C_{in}$ 个输出元素。\n- 每个深度卷积的输出元素使用一个仅限于其自身通道的 $K \\times K$ 卷积核，每个输出元素贡献 $K^{2}$ 次 MAC 操作。\n因此，深度卷积的 MAC 数量为\n$$\n\\text{MAC}_{\\text{dw}} = H W C_{in} K^{2}\n$$\n\n2. 逐点 $1 \\times 1$ 卷积：\n- 有 $H \\times W$ 个空间位置和 $C_{out}$ 个输出通道，产生 $H W C_{out}$ 个输出元素。\n- 每个逐点卷积的输出元素是使用一个 $1 \\times 1$ 卷积核对 $C_{in}$ 个输入通道进行加权求和，每个输出元素贡献 $C_{in}$ 次 MAC 操作。\n因此，逐点卷积的 MAC 数量为\n$$\n\\text{MAC}_{\\text{pw}} = H W C_{out} C_{in}\n$$\n\n将两者结合，深度可分离卷积的总 MAC 数量为\n$$\n\\text{MAC}_{\\text{dws}} = \\text{MAC}_{\\text{dw}} + \\text{MAC}_{\\text{pw}} = H W C_{in} K^{2} + H W C_{out} C_{in} = H W C_{in} \\left(K^{2} + C_{out}\\right)\n$$\n\n加速因子 $S$ 定义为标准卷积 MAC 数量与深度可分离卷积 MAC 数量的比值：\n$$\nS = \\frac{\\text{MAC}_{\\text{std}}}{\\text{MAC}_{\\text{dws}}} = \\frac{H W C_{out} K^{2} C_{in}}{H W C_{in} \\left(K^{2} + C_{out}\\right)}\n$$\n消去公因式 $H$、$W$ 和 $C_{in}$ 后得到\n$$\nS = \\frac{C_{out} K^{2}}{K^{2} + C_{out}}\n$$\n\n将给定值 $C_{in}=32$、$C_{out}=64$、$K=3$、$H=W=112$ 代入 $S$ 的简化符号表达式中：\n$$\nS = \\frac{64 \\cdot 3^{2}}{3^{2} + 64} = \\frac{64 \\cdot 9}{9 + 64} = \\frac{576}{73}\n$$\n\n为完整起见，我们可以用数值验证精确的 MAC 数量：\n- 标准卷积：\n$$\n\\text{MAC}_{\\text{std}} = 112 \\cdot 112 \\cdot 64 \\cdot 9 \\cdot 32 = 12544 \\cdot 64 \\cdot 288 = 231,211,008\n$$\n- 深度可分离卷积：\n$$\n\\text{MAC}_{\\text{dws}} = 112 \\cdot 112 \\cdot 32 \\cdot \\left(9 + 64\\right) = 12544 \\cdot 32 \\cdot 73 = 29,302,784\n$$\n它们的比值确实等于\n$$\n\\frac{231,211,008}{29,302,784} = \\frac{576}{73}\n$$\n\n所要求的最终输出是作为单个简化精确表达式的加速因子。", "answer": "$$\\boxed{\\frac{576}{73}}$$", "id": "3120106"}, {"introduction": "在理解了基本的计算成本后，我们来解决一个更高层次的设计问题。MobileNet 架构并非一成不变，而是通过宽度乘数 $\\alpha$ 和分辨率乘数 $\\rho$ 进行调整。本练习将让你扮演网络设计师的角色，任务是在严格的计算预算下最大化模型精度 [@problem_id:3120133]。通过将此问题构建为一个约束优化问题，我们可以找到这些乘数的理想组合，从而在性能和效率之间达到最佳平衡。", "problem": "考虑一个使用宽度乘数 $\\alpha \\in (0,1]$ 和分辨率乘数 $\\rho \\in (0,1]$ 的 MobileNet 风格的模型。对于深度可分离卷积网络而言，一个得到经验充分支持的事实是，在保持所有其他设计选择固定的情况下，其计算成本（以百万浮点运算次数 MFLOPs 为单位）大约是基准成本的 $\\alpha^{2}\\rho^{2}$ 倍。假设在 $\\alpha=1$ 和 $\\rho=1$ 时的基准成本为 $C_{\\text{base}}=500$ MFLOPs。一个假设的准确率模型（以小数形式而非百分比表示）由下式给出\n$$\nA(\\alpha,\\rho)=A_{0}-k_{1}\\left(1-\\alpha\\right)^{p}-k_{2}\\left(1-\\rho\\right)^{q},\n$$\n其中常数 $A_{0}=0.80$，$k_{1}=0.10$，$k_{2}=0.10$，$p=2$，$q=2$。您必须选择 $(\\alpha,\\rho)$ 以最大化 $A(\\alpha,\\rho)$，同时满足 $B=125$ MFLOPs 的硬性预算约束，并且仅使用上述基本缩放规律和规范的约束优化方法。\n\n从第一性原理出发，建立并求解该约束优化问题，确定在预算下可实现的最大预测准确率 $A^{\\star}$。将 $A^{\\star}$ 表示为小数，并将最终答案四舍五入到四位有效数字。", "solution": "用户提供了一个约束优化问题。根据既定流程，第一步是验证问题陈述。\n\n### 第 1 步：提取已知条件\n- **待最大化的目标函数**：准确率模型 $A(\\alpha, \\rho) = A_{0} - k_{1}(1-\\alpha)^{p} - k_{2}(1-\\rho)^{q}$。\n- **目标函数的参数**：$A_{0} = 0.80$，$k_{1} = 0.10$，$k_{2} = 0.10$，$p = 2$，$q = 2$。\n- **约束函数**：计算成本为 $C(\\alpha, \\rho) = C_{\\text{base}} \\alpha^{2} \\rho^{2}$。\n- **约束的参数**：基准成本 $C_{\\text{base}} = 500$ MFLOPs。\n- **预算约束**：成本不得超过 $B = 125$ MFLOPs 的硬性预算，即 $C(\\alpha, \\rho) \\le 125$。\n- **变量定义域**：宽度乘数 $\\alpha \\in (0,1]$ 和分辨率乘数 $\\rho \\in (0,1]$。\n- **任务**：找到在预算约束下最大化 $A(\\alpha, \\rho)$ 的最优对 $(\\alpha^{\\star}, \\rho^{\\star})$，并确定相应的最大准确率 $A^{\\star}$，四舍五入到四位有效数字。\n\n### 第 2 步：使用提取的已知条件进行验证\n根据验证标准对问题进行评估：\n- **科学依据**：该问题在深度学习领域，特别是在设计像 MobileNet 这样的高效神经网络方面，具有充分的科学依据。计算成本的缩放定律 $C \\propto \\alpha^{2} \\rho^{2}$ 是 MobileNet 原始论文中的一个标准近似。准确率模型是模型大小/复杂度与性能之间权衡的一种合理的唯象表示。\n- **适定性**：该问题是一个标准的约束优化任务。它提供了明确定义的目标函数、可量化的约束以及明确的变量定义域。可以预期存在唯一解。\n- **客观性**：该问题使用精确、无歧义的数学语言陈述，并提供了所有必要的常数。它不含主观论断。\n\n该问题没有任何无效性缺陷。它在其领域内是可数学形式化的、完整的、内部一致的且科学上合理的。\n\n### 第 3 步：结论与行动\n该问题被判定为 **有效**。现在开始求解过程。\n\n### 求解推导\n问题是在以下约束条件下最大化准确率函数\n$$\nA(\\alpha, \\rho) = 0.80 - 0.10(1-\\alpha)^{2} - 0.10(1-\\rho)^{2}\n$$\n$$\nC(\\alpha, \\rho) = 500 \\alpha^{2} \\rho^{2} \\le 125\n$$\n$$\n\\alpha \\in (0, 1]\n$$\n$$\n\\rho \\in (0, 1]\n$$\n首先，我们简化计算成本约束：\n$$\n500 \\alpha^{2} \\rho^{2} \\le 125 \\implies \\alpha^{2} \\rho^{2} \\le \\frac{125}{500} \\implies \\alpha^{2} \\rho^{2} \\le \\frac{1}{4}\n$$\n由于 $\\alpha > 0$ 且 $\\rho > 0$，我们可以对两边取平方根，得到\n$$\n\\alpha \\rho \\le \\frac{1}{2}\n$$\n目标函数 $A(\\alpha, \\rho)$ 在其指定的定义域内是关于 $\\alpha$ 和 $\\rho$ 的严格增函数。为了证明这一点，我们考察其偏导数：\n$$\n\\frac{\\partial A}{\\partial \\alpha} = -0.10 \\cdot 2 (1-\\alpha)(-1) = 0.20(1-\\alpha)\n$$\n$$\n\\frac{\\partial A}{\\partial \\rho} = -0.10 \\cdot 2 (1-\\rho)(-1) = 0.20(1-\\rho)\n$$\n对于 $\\alpha \\in (0, 1)$ 和 $\\rho \\in (0, 1)$，两个偏导数都为正。这表明要最大化 $A(\\alpha, \\rho)$，我们必须选择满足约束的尽可能大的 $\\alpha$ 和 $\\rho$ 值。因此，最大值必定位于可行域的边界上，此时预算被完全利用。不等式约束变为等式约束：\n$$\n\\alpha \\rho = \\frac{1}{2}\n$$\n我们现在使用拉格朗日乘数法来解决这个约束优化问题。最大化 $A(\\alpha, \\rho)$ 等价于最小化 $-A(\\alpha, \\rho)$，而这又等价于最小化函数 $F(\\alpha, \\rho) = 0.10(1-\\alpha)^{2} + 0.10(1-\\rho)^{2}$，因为 $0.80$ 项是一个常数偏移。\n\n拉格朗日函数 $\\mathcal{L}$ 构造如下：\n$$\n\\mathcal{L}(\\alpha, \\rho, \\lambda) = 0.10(1-\\alpha)^{2} + 0.10(1-\\rho)^{2} - \\lambda \\left(\\alpha \\rho - \\frac{1}{2}\\right)\n$$\n为了找到临界点，我们将 $\\mathcal{L}$ 关于 $\\alpha$、$\\rho$ 和 $\\lambda$ 的梯度设为零：\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\alpha} = -0.20(1-\\alpha) - \\lambda \\rho = 0 \\quad (1)\n$$\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\rho} = -0.20(1-\\rho) - \\lambda \\alpha = 0 \\quad (2)\n$$\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\lambda} = -\\left(\\alpha \\rho - \\frac{1}{2}\\right) = 0 \\quad (3)\n$$\n从方程(3)中，我们恢复了约束条件 $\\alpha \\rho = \\frac{1}{2}$。\n从(1)和(2)，我们可以表示出 $\\lambda$：\n$$\n\\lambda = -\\frac{0.20(1-\\alpha)}{\\rho}\n$$\n$$\n\\lambda = -\\frac{0.20(1-\\rho)}{\\alpha}\n$$\n令这两个关于 $\\lambda$ 的表达式相等（我们可以确认 $\\lambda \\neq 0$，否则 $\\alpha=1$ 且 $\\rho=1$，这将违反约束条件）：\n$$\n\\frac{1-\\alpha}{\\rho} = \\frac{1-\\rho}{\\alpha}\n$$\n$$\n\\alpha(1-\\alpha) = \\rho(1-\\rho)\n$$\n$$\n\\alpha - \\alpha^{2} = \\rho - \\rho^{2}\n$$\n$$\n\\alpha - \\rho = \\alpha^{2} - \\rho^{2}\n$$\n$$\n\\alpha - \\rho = (\\alpha - \\rho)(\\alpha + \\rho)\n$$\n这个方程产生两种可能性：$\\alpha - \\rho = 0$，或者如果 $\\alpha \\neq \\rho$，我们可以两边同除以 $(\\alpha - \\rho)$ 得到 $\\alpha + \\rho = 1$。\n\n情况1：$\\alpha = \\rho$。\n将此代入约束条件 $\\alpha \\rho = \\frac{1}{2}$ 中：\n$$\n\\alpha^{2} = \\frac{1}{2} \\implies \\alpha = \\frac{1}{\\sqrt{2}} = \\frac{\\sqrt{2}}{2}\n$$\n所以，$(\\alpha, \\rho) = \\left(\\frac{\\sqrt{2}}{2}, \\frac{\\sqrt{2}}{2}\\right)$。由于 $\\frac{\\sqrt{2}}{2} \\approx 0.707$，这些值位于定义域 $(0,1]$ 内。这是一个有效的最优点候选。\n\n情况2：$\\alpha + \\rho = 1$。\n从约束条件我们有 $\\rho = \\frac{1}{2\\alpha}$。将此代入情况2的方程中：\n$$\n\\alpha + \\frac{1}{2\\alpha} = 1\n$$\n两边乘以 $2\\alpha$（因为 $\\alpha > 0$）：\n$$\n2\\alpha^{2} + 1 = 2\\alpha \\implies 2\\alpha^{2} - 2\\alpha + 1 = 0\n$$\n这个二次方程的判别式是 $\\Delta = b^{2} - 4ac = (-2)^{2} - 4(2)(1) = 4 - 8 = -4$。由于 $\\Delta  0$，在这种情况下 $\\alpha$ 没有实数解。\n\n因此，唯一的临界点是 $\\alpha^{\\star} = \\rho^{\\star} = \\frac{\\sqrt{2}}{2}$。考虑到目标函数和约束条件相对于 $\\alpha$ 和 $\\rho$ 的对称性，这个对称的结果是符合预期的。\n\n现在，我们将这些最优值代回准确率函数中，以计算最大准确率 $A^{\\star}$：\n$$\nA^{\\star} = A\\left(\\frac{\\sqrt{2}}{2}, \\frac{\\sqrt{2}}{2}\\right) = 0.80 - 0.10\\left(1 - \\frac{\\sqrt{2}}{2}\\right)^{2} - 0.10\\left(1 - \\frac{\\sqrt{2}}{2}\\right)^{2}\n$$\n$$\nA^{\\star} = 0.80 - 0.20\\left(1 - \\frac{\\sqrt{2}}{2}\\right)^{2}\n$$\n我们展开平方项：\n$$\n\\left(1 - \\frac{\\sqrt{2}}{2}\\right)^{2} = 1 - 2\\left(\\frac{\\sqrt{2}}{2}\\right) + \\left(\\frac{\\sqrt{2}}{2}\\right)^{2} = 1 - \\sqrt{2} + \\frac{2}{4} = 1 - \\sqrt{2} + \\frac{1}{2} = \\frac{3}{2} - \\sqrt{2}\n$$\n将此代回 $A^{\\star}$ 的表达式中：\n$$\nA^{\\star} = 0.80 - 0.20\\left(\\frac{3}{2} - \\sqrt{2}\\right)\n$$\n$$\nA^{\\star} = 0.80 - \\left(0.20 \\cdot \\frac{3}{2} - 0.20 \\cdot \\sqrt{2}\\right) = 0.80 - (0.30 - 0.20\\sqrt{2})\n$$\n$$\nA^{\\star} = 0.80 - 0.30 + 0.20\\sqrt{2} = 0.50 + 0.2\\sqrt{2}\n$$\n最后，我们按要求计算数值并四舍五入到四位有效数字。\n$$\n\\sqrt{2} \\approx 1.41421356...\n$$\n$$\nA^{\\star} \\approx 0.50 + 0.2 \\times 1.41421356 = 0.50 + 0.282842712 = 0.782842712\n$$\n四舍五入到四位有效数字，我们得到 $0.7828$。", "answer": "$$\\boxed{0.7828}$$", "id": "3120133"}, {"introduction": "神经网络架构在不断演进。最后的这个练习探讨了一个常见的工程场景：评估是否将一个新模块——“挤压与激励”（Squeeze-and-Excitation, SE）——集成到现有的高效模块（MobileNetV2 的倒置残差块）中。这需要进行详细的成本效益分析 [@problem_id:3120155]，精确计算 SE 模块带来的额外计算开销，并将其与所获得的精度提升进行权衡。这项练习旨在磨练你做出数据驱动的架构决策的关键技能。", "problem": "你需要推理并实现将 Squeeze-and-Excitation (SE) 模块添加到 MobileNetV2 倒置残差块中所带来的计算成本影响，然后量化几种配置下的准确率与计算量的权衡。请基于以下基本原理和核心定义进行分析，除这些原则外，不应假设任何专门的公式。\n\n基本原理和定义：\n- 乘加运算 (MAC) 是一个结合了一次乘法和一次加法的基本算术单元。对于本任务，每个权重与输入的乘积对输出的贡献计为一次 MAC。\n- 一个将长度为 $u$ 的输入向量映射到长度为 $v$ 的输出向量的密集（全连接）层，使用一个大小为 $u \\times v$ 的权重矩阵，因此对于单个输入向量的单次推理需要 $u \\cdot v$ 次 MAC。\n- 一个标准二维卷积，其空间核大小为 $k \\times k$，$C_{\\text{in}}$ 个输入通道和 $C_{\\text{out}}$ 个输出通道，应用于空间分辨率为 $H \\times W$ 的输入（步长为1，填充方式为 \"same\"），需要 $H \\cdot W \\cdot k \\cdot k \\cdot C_{\\text{in}} \\cdot C_{\\text{out}}$ 次 MAC。\n- 一个深度卷积，其空间核大小为 $k \\times k$，$C$ 个通道，应用于分辨率为 $H \\times W$ 的输入，需要 $H \\cdot W \\cdot k \\cdot k \\cdot C$ 次 MAC，因为每个通道是独立进行卷积的。\n- 一个 $1 \\times 1$ 卷积，有 $C_{\\text{in}}$ 个输入和 $C_{\\text{out}}$ 个输出，应用于分辨率为 $H \\times W$ 的输入，需要 $H \\cdot W \\cdot C_{\\text{in}} \\cdot C_{\\text{out}}$ 次 MAC。\n- 一个用于具有 $C$ 个通道的张量的 Squeeze-and-Excitation (SE) 模块包括：一个全局平均池化操作以生成一个长度为 $C$ 的向量（本问题中忽略其成本），其后是两个密集层：一个从 $C$ 通道缩减到 $C/r$ 通道的层，然后一个从 $C/r$ 通道扩展回 $C$ 通道的层，其中 $r$ 是一个正整数缩减率。忽略偏置加法、修正线性单元 (ReLU) 等非线性操作以及最终的 sigmoid 函数的成本，只计算这两个密集层的 MAC 数量。在以下所有测试用例中，假设 $C/r$ 是一个整数。\n\n待分析的 MobileNetV2 倒置残差块模型：\n- 考虑一个步长为 1 的 MobileNetV2 块，其输入和输出通道数均为 $C$，使用扩展因子 $t$。该块包括：一个从 $C$ 通道扩展到 $tC$ 通道的 $1 \\times 1$ 逐点卷积，一个在 $tC$ 通道上进行的 $3 \\times 3$ 深度卷积，以及一个从 $tC$ 通道投影回 $C$ 通道的 $1 \\times 1$ 逐点投影卷积。整个块的空间分辨率保持为 $H \\times W$。忽略任何跳跃连接成本和任何非卷积操作。\n\n任务：\n1. 基于上述基本原理，推导出 MobileNetV2 块（不含 SE）的总基线 MAC 数量的表达式，该表达式是关于 $H$、$W$、$C$、$t$ 和核大小 $k = 3$ 的函数。然后，使用相同的原理，推导在块的 $C$ 通道输出上插入一个缩减率为 $r$ 的 SE 模块所引入的额外 MAC 数量。\n2. 对于每个测试用例，计算：\n   - 每个不含 SE 的块的基线 MAC 数量，\n   - 由 SE 引入的额外 MAC 数量，\n   - 开销分数，定义为额外 MAC 数量与基线 MAC 数量的比率，\n   - 每增加一百万 MAC 带来的准确率增益，定义为 $(A_{\\text{SE}} - A_{\\text{base}})$ 除以以百万 MAC 为单位的额外 MAC 数量（即，在计算比率前将额外 MAC 数量除以 $10^6$）。\n3. 所有准确率值表示为 $[0,1]$ 范围内的小数。不涉及物理单位或角度。每个测试用例的最终输出应为两个浮点数：[accuracy_gain_per_megaMAC, overhead_fraction]。将两个浮点数都四舍五入到九位小数。\n\n测试套件：\n对于每个测试用例，给定 $(H, W, C, t, r, A_{\\text{base}}, A_{\\text{SE}})$，其中除准确率外所有量均为整数：\n- 用例 $1$：$H = 56$, $W = 56$, $C = 24$, $t = 6$, $r = 1$, $A_{\\text{base}} = 0.720$, $A_{\\text{SE}} = 0.732$。\n- 用例 $2$：$H = 56$, $W = 56$, $C = 24$, $t = 6$, $r = 8$, $A_{\\text{base}} = 0.720$, $A_{\\text{SE}} = 0.724$。\n- 用例 $3$：$H = 28$, $W = 28$, $C = 32$, $t = 6$, $r = 8$, $A_{\\text{base}} = 0.720$, $A_{\\text{SE}} = 0.723$。\n- 用例 $4$：$H = 14$, $W = 14$, $C = 96$, $t = 6$, $r = 16$, $A_{\\text{base}} = 0.720$, $A_{\\text{SE}} = 0.728$。\n- 用例 $5$：$H = 7$, $W = 7$, $C = 320$, $t = 6$, $r = 32$, $A_{\\text{base}} = 0.720$, $A_{\\text{SE}} = 0.726$。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含五个测试用例的结果列表，每个结果是一个包含两个元素的列表，顺序为 [accuracy_gain_per_megaMAC, overhead_fraction]。总体格式必须是一个不带任何额外文本的 Python 风格的列表嵌套列表，例如：[[x1,y1],[x2,y2],[x3,y3],[x4,y4],[x5,y5]]。在打印前将所有浮点数四舍五入到九位小数。", "solution": "该问题已经过验证，被确定为一个定义明确、有科学依据且客观的任务。我们现在将着手对必要的公式及其应用进行有原则的推导。\n\n主要目标是量化将一个 Squeeze-and-Excitation (SE) 模块集成到 MobileNetV2 倒置残差块中的计算成本和准确率权衡。计算成本的单位是乘加运算 (MAC)。\n\n首先，我们为一个不含 SE 模块的 MobileNetV2 倒置残差块推导其基线计算成本的表达式。根据定义，该块在恒定的空间分辨率 $H \\times W$ 下运行，并由三个卷积层组成。\n\n1.  **逐点扩展卷积**：这是一个 $1 \\times 1$ 卷积，将通道数从 $C$ 扩展到 $tC$。根据所提供的 $1 \\times 1$ 卷积的定义，其成本是输出空间维度、输入通道数和输出通道数的乘积。\n    $$ \\text{MACs}_1 = H \\cdot W \\cdot C_{\\text{in}} \\cdot C_{\\text{out}} = H \\cdot W \\cdot C \\cdot (tC) = H \\cdot W \\cdot t \\cdot C^2 $$\n\n2.  **深度卷积**：这是一个在 $tC$ 个通道上操作的 $3 \\times 3$ 深度卷积。当核大小 $k=3$ 时，其成本由输出空间维度、卷积核面积和通道数的乘积给出。\n    $$ \\text{MACs}_2 = H \\cdot W \\cdot k^2 \\cdot (\\text{channels}) = H \\cdot W \\cdot 3^2 \\cdot (tC) = 9 \\cdot H \\cdot W \\cdot t \\cdot C $$\n\n3.  **逐点投影卷积**：这是一个将 $tC$ 个通道投影回 $C$ 个通道的 $1 \\times 1$ 卷积。与扩展层类似，其成本为：\n    $$ \\text{MACs}_3 = H \\cdot W \\cdot C_{\\text{in}} \\cdot C_{\\text{out}} = H \\cdot W \\cdot (tC) \\cdot C = H \\cdot W \\cdot t \\cdot C^2 $$\n\nMobileNetV2 块的总基线 MAC 数量 $\\text{MACs}_{\\text{base}}$，是这三个层成本的总和。\n$$ \\text{MACs}_{\\text{base}} = \\text{MACs}_1 + \\text{MACs}_2 + \\text{MACs}_3 $$\n$$ \\text{MACs}_{\\text{base}} = (H \\cdot W \\cdot t \\cdot C^2) + (9 \\cdot H \\cdot W \\cdot t \\cdot C) + (H \\cdot W \\cdot t \\cdot C^2) $$\n提取公因式后，我们得到基线成本的最终表达式：\n$$ \\text{MACs}_{\\text{base}} = H \\cdot W \\cdot t \\cdot C \\cdot (C + 9 + C) = H \\cdot W \\cdot t \\cdot C \\cdot (2C + 9) $$\n\n接下来，我们推导由 Squeeze-and-Excitation 模块引入的额外计算成本 $\\text{MACs}_{\\text{add}}$。SE 模块应用于块的输出，该输出具有 $C$ 个通道。在全局平均池化（其成本被忽略）之后，SE 模块由两个密集（全连接）层组成。\n\n1.  **缩减密集层**：该层将通道向量的长度从 $C$ 缩减到 $C/r$，其中 $r$ 是缩减率。其成本是输入和输出向量长度的乘积。\n    $$ \\text{MACs}_{\\text{SE},1} = C \\cdot (C/r) = \\frac{C^2}{r} $$\n\n2.  **扩展密集层**：该层将向量长度从 $C/r$ 扩展回 $C$。\n    $$ \\text{MACs}_{\\text{SE},2} = (C/r) \\cdot C = \\frac{C^2}{r} $$\n\nSE 模块带来的总额外 MAC 数量是这两个密集层成本的总和。\n$$ \\text{MACs}_{\\text{add}} = \\text{MACs}_{\\text{SE},1} + \\text{MACs}_{\\text{SE},2} = \\frac{C^2}{r} + \\frac{C^2}{r} = \\frac{2C^2}{r} $$\n\n利用这些推导出的表达式，我们可以为每个测试用例计算所需的指标。\n\n第一个指标是**开销分数**，即额外 MAC 数量与基线 MAC 数量的比率。\n$$ \\text{Overhead Fraction} = \\frac{\\text{MACs}_{\\text{add}}}{\\text{MACs}_{\\text{base}}} = \\frac{2C^2/r}{H \\cdot W \\cdot t \\cdot C \\cdot (2C + 9)} = \\frac{2C}{r \\cdot H \\cdot W \\cdot t \\cdot (2C + 9)} $$\n\n第二个指标是**每增加一百万 MAC 带来的准确率增益**。该指标量化了额外计算在提升准确率方面的效率。其定义为准确率差值 ($A_{\\text{SE}} - A_{\\text{base}}$) 除以转换为百万 MAC（Mega-MACs）单位的额外 MAC 数量。\n$$ \\text{Accuracy Gain per Mega-MAC} = \\frac{A_{\\text{SE}} - A_{\\text{base}}}{\\text{MACs}_{\\text{add}} / 10^6} $$\n\n现在将实施这些公式来处理提供的测试套件。对于每个用例，我们将计算 $\\text{MACs}_{\\text{base}}$ 和 $\\text{MACs}_{\\text{add}}$，并随后计算两个所需指标，按照规定将最终的浮点数值四舍五入到九位小数。\n\n```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Calculates the accuracy-vs-compute trade-off for adding\n    Squeeze-and-Excitation (SE) blocks to MobileNetV2 inverted residual blocks.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (H, W, C, t, r, A_base, A_SE)\n    test_cases = [\n        (56, 56, 24, 6, 1, 0.720, 0.732),\n        (56, 56, 24, 6, 8, 0.720, 0.724),\n        (28, 28, 32, 6, 8, 0.720, 0.723),\n        (14, 14, 96, 6, 16, 0.720, 0.728),\n        (7, 7, 320, 6, 32, 0.720, 0.726),\n    ]\n\n    results = []\n    for case in test_cases:\n        H, W, C, t, r, A_base, A_SE = case\n\n        # Task 1: Calculate baseline and additional MACs based on derived formulas.\n        \n        # Baseline MACs for the MobileNetV2 block:\n        # MACs_base = H * W * t * C * (2*C + 9)\n        macs_base = H * W * t * C * (2 * C + 9)\n        \n        # Additional MACs for the Squeeze-and-Excitation module:\n        # MACs_add = 2 * C^2 / r\n        # Ensure integer division is not used accidentally, though all inputs are integers\n        macs_add = (2 * C**2) / r\n\n        # Task 2: Compute the required metrics.\n\n        # Overhead fraction: ratio of additional MACs to baseline MACs\n        overhead_fraction = macs_add / macs_base\n\n        # Accuracy gain per added mega-MAC\n        # First, calculate the absolute accuracy gain\n        accuracy_gain = A_SE - A_base\n        # Convert additional MACs to millions (Mega-MACs)\n        added_mega_macs = macs_add / 1_000_000\n        # Calculate the ratio. Handle case where added_mega_macs is zero to avoid division by zero.\n        if added_mega_macs > 0:\n            accuracy_gain_per_megaMAC = accuracy_gain / added_mega_macs\n        else:\n            accuracy_gain_per_megaMAC = 0.0\n\n        # Task 3: Round the results to nine decimal places.\n        rounded_gain = round(accuracy_gain_per_megaMAC, 9)\n        rounded_overhead = round(overhead_fraction, 9)\n\n        results.append([rounded_gain, rounded_overhead])\n\n    # Final print statement in the exact required format: [[x1,y1],[x2,y2],...]\n    # Using join and map(str) to avoid spaces that `str(list_of_lists)` would add.\n    print(f\"[{','.join(map(str, results))}]\")\n\n# The code is part of the solution process and is not executed here. \n# The final answer is calculated based on this logic.\n```", "answer": "[[10416.666666667, 0.00004476], [27777.777777778, 0.000005595], [11718.75, 0.000023266], [6944.444444444, 0.0000507], [937.5, 0.000104772]]", "id": "3120155"}]}