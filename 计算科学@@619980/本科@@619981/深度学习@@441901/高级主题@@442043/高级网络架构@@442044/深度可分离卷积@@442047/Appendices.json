{"hands_on_practices": [{"introduction": "深度可分离卷积（DSC）的一个核心优势是其计算效率。本练习将指导你通过具体计算来量化这一优势。你将首先推导标准卷积操作的输出维度公式，然后利用该公式计算一个完整的深度可分离卷积模块所需的乘加运算总数，从而巩固对卷积参数（如核大小、步长和填充）如何影响输出维度和计算成本的理解。", "problem": "深度可分离卷积（DSC）由一个深度卷积（depthwise convolution）后跟一个逐点卷积（pointwise convolution）组成。深度卷积对每个输入通道应用一个空间滤波器，而逐点卷积使用空间尺寸为 $1 \\times 1$ 的滤波器来混合通道。考虑一个二维离散卷积，并使用以下基本原则：\n\n- 单通道输入 $x$ 与核 $w$ 在空间位置 $(u,v)$ 的二维离散卷积计算了 $x$ 的一个局部感受野上的加权和。\n- 大小为 $p$ 的零填充（Zero-padding）在每个空间边界上将输入扩展 $p$ 个零，步长（stride） $s$ 沿每个空间轴将卷积窗口移动 $s$ 个像素。\n\n基于这些原则，推导出一个计数论证，以确定当对一个空间尺寸为 $(H,W)$ 的输入应用一个大小为 $k \\times k$ 的方形核、步长为 $s$、对称零填充为 $p$ 时，深度卷积可以在高度和宽度上产生多少个有效的空间位置。\n\n然后，将您的推导应用于以下 DSC 模块：\n\n- 输入张量的高度 $H = 128$，宽度 $W = 96$，通道数 $C_{\\text{in}} = 32$。\n- 深度卷积使用大小为 $k = 5$ 的方形核，步长 $s = 2$，在高度和宽度上均使用对称零填充 $p = 1$。\n- 逐点卷积使用 $C_{\\text{out}} = 64$ 个输出通道，步长为 $1$，零填充为 $0$。\n\n假设没有空洞卷积（dilation），并且逐点卷积保留了深度卷积产生的空间维度。将一次乘加运算定义为一次乘法紧随一次加法，对每个贡献于单个输出值的权重-激活对计数一次。不计算偏置项。\n\n计算处理一个输入图像通过上述整个 DSC 模块（深度阶段加逐点阶段）所需的乘加运算总数。将最终答案表示为一个没有单位且不进行四舍五-入的整数。只提供这个总数作为您的最终答案。", "solution": "问题要求完成两个任务：首先，推导二维卷积的空间输出维度的公式；其次，应用该公式计算一个特定的深度可分离卷积（DSC）模块的总乘加运算次数。\n\n首先，我们推导输出维度的公式。考虑输入张量的一个空间维度，其大小为 $D_{in}$。当应用大小为 $p$ 的对称零填充时，该维度的两端各添加 $p$ 个零。填充后维度的有效大小变为 $D_{padded} = D_{in} + 2p$。一个大小为 $k$ 的核以步长 $s$ 在这个填充后的维度上进行卷积。\n\n设核的位置由索引 $i$ 表示，从 $i=0$ 开始。在位置 $i$ 的核所覆盖的感受野从索引 $i \\times s$ 开始，到索引 $i \\times s + k - 1$ 结束（使用基于 0 的索引）。为了使核处于一个有效位置，其整个感受野必须位于填充后的维度内。因此，所覆盖的最后一个索引必须小于填充后的维度大小：\n$$i \\times s + k - 1  D_{padded}$$\n$$i \\times s  D_{padded} - k$$\n$$i \\le \\frac{D_{padded} - k}{s}$$\n由于 $i$ 必须是一个整数，索引 $i$ 的最大值为 $\\lfloor \\frac{D_{padded} - k}{s} \\rfloor$。有效位置的数量是 $i$ 可能的整数值的计数，其范围从 $0$ 到 $\\lfloor \\frac{D_{padded} - k}{s} \\rfloor$。此类位置的总数，即对应于输出维度 $D_{out}$，是：\n$$D_{out} = \\left\\lfloor \\frac{D_{padded} - k}{s} \\right\\rfloor + 1$$\n代入 $D_{padded} = D_{in} + 2p$，我们得到输出空间维度的一般公式：\n$$D_{out} = \\left\\lfloor \\frac{D_{in} + 2p - k}{s} \\right\\rfloor + 1$$\n将此公式应用于高度 ($H$) 和宽度 ($W$) 维度，我们得到：\n$$H_{out} = \\left\\lfloor \\frac{H + 2p - k}{s} \\right\\rfloor + 1$$\n$$W_{out} = \\left\\lfloor \\frac{W + 2p - k}{s} \\right\\rfloor + 1$$\n这就完成了问题的第一部分。\n\n接下来，我们计算给定 DSC 模块的乘加运算总数。总成本 $\\text{Ops}_{\\text{total}}$ 是深度卷积阶段成本 $\\text{Ops}_{\\text{dw}}$ 和逐点卷积阶段成本 $\\text{Ops}_{\\text{pw}}$ 的总和。\n\n**1. 深度卷积阶段**\n输入张量的维度为 $H = 128$，$W = 96$，$C_{\\text{in}} = 32$。\n深度卷积的参数为：核大小 $k = 5$，步长 $s = 2$，填充 $p = 1$。\n首先，我们计算此阶段输出特征图的空间维度，记为 $(H_{\\text{dw}}, W_{\\text{dw}})$：\n$$H_{\\text{dw}} = \\left\\lfloor \\frac{128 + 2(1) - 5}{2} \\right\\rfloor + 1 = \\left\\lfloor \\frac{125}{2} \\right\\rfloor + 1 = 62 + 1 = 63$$\n$$W_{\\text{dw}} = \\left\\lfloor \\frac{96 + 2(1) - 5}{2} \\right\\rfloor + 1 = \\left\\lfloor \\frac{93}{2} \\right\\rfloor + 1 = 46 + 1 = 47$$\n深度卷积为 $C_{\\text{in}}$ 个输入通道中的每一个应用一个独立的 $k \\times k$ 滤波器。要计算一个输出通道特征图中的单个值，需要 $k \\times k$ 次乘加运算。对于所有 $H_{\\text{dw}} \\times W_{\\text{dw}}$ 个空间位置和所有 $C_{\\text{in}}$ 个通道，都要重复此过程。\n深度阶段的总运算次数为：\n$$\\text{Ops}_{\\text{dw}} = C_{\\text{in}} \\times k \\times k \\times H_{\\text{dw}} \\times W_{\\text{dw}}$$\n代入给定值：\n$$\\text{Ops}_{\\text{dw}} = 32 \\times 5 \\times 5 \\times 63 \\times 47$$\n$$\\text{Ops}_{\\text{dw}} = 32 \\times 25 \\times 2961$$\n$$\\text{Ops}_{\\text{dw}} = 800 \\times 2961 = 2,368,800$$\n\n**2. 逐点卷积阶段**\n此阶段的输入是深度阶段的输出，维度为 $(H_{\\text{in}}, W_{\\text{in}}, C_{\\text{in}}) = (63, 47, 32)$。\n逐点卷积是使用 $1 \\times 1$ 滤波器的标准卷积。其参数为：核大小 $k_{pw} = 1$，步长 $s_{pw} = 1$，填充 $p_{pw} = 0$，以及输出通道数 $C_{\\text{out}} = 64$。空间维度被保留，这与这些参数是一致的。\n要计算 $C_{\\text{out}}$ 个输出通道中一个通道在单个空间位置上的一个值，需要在 $C_{\\text{in}}$ 个输入通道上执行点积。这需要 $1 \\times 1 \\times C_{\\text{in}} = C_{\\text{in}}$ 次乘加运算。此计算对输出图中的所有空间位置 ($H_{\\text{dw}} \\times W_{\\text{dw}}$) 和每个输出通道 ($C_{\\text{out}}$) 重复进行。\n逐点阶段的总运算次数为：\n$$\\text{Ops}_{\\text{pw}} = C_{\\text{in}} \\times C_{\\text{out}} \\times H_{\\text{dw}} \\times W_{\\text{dw}}$$\n代入各值：\n$$\\text{Ops}_{\\text{pw}} = 32 \\times 64 \\times 63 \\times 47$$\n$$\\text{Ops}_{\\text{pw}} = 2048 \\times 2961 = 6,064,128$$\n\n**总运算**\n整个 DSC 模块的乘加运算总数是两个阶段运算次数的总和：\n$$\\text{Ops}_{\\text{total}} = \\text{Ops}_{\\text{dw}} + \\text{Ops}_{\\text{pw}} = 2,368,800 + 6,064,128 = 8,432,928$$", "answer": "$$\\boxed{8432928}$$", "id": "3115192"}, {"introduction": "在理解了“如何计算”之后，本练习将深入探讨“它是什么”的问题，旨在揭示深度可分离卷积与标准卷积之间的根本联系。通过一个精心设计的思想实验 [@problem_id:3185403]，你将证明在特定条件下——即当一个标准卷积核具有可分解的结构时——其数学上等价于一个深度可分离卷积。这一洞察对于理解深度可分离卷积的工作原理及其表示能力的来源至关重要。", "problem": "卷积神经网络（CNN）层通过应用由卷积核定义的空间聚合来执行前向传播。考虑一个合成的输入张量，其具有 $C = 2$ 个通道和空间维度 $H = W = 3$，其中每个通道在弗罗贝尼乌斯内积下携带一个正交模式。输入通道为\n$$\nX^{(1)} = \\begin{pmatrix}\n1  0  -1 \\\\\n1  0  -1 \\\\\n1  0  -1\n\\end{pmatrix},\n\\qquad\nX^{(2)} = \\begin{pmatrix}\n1  1  1 \\\\\n0  0  0 \\\\\n-1  -1  -1\n\\end{pmatrix}.\n$$\n你将计算深度可分离卷积的前向传播，并将其与全卷积进行比较，两者都使用相同的步幅和填充约定。\n\n此处，深度可分离卷积定义如下：\n- 深度步骤：对于每个通道 $c \\in \\{1,2\\}$，使用步幅 $1$ 和有效填充将 $X^{(c)}$ 与通道特定的空间核 $K^{(c)}$ 进行卷积，产生一个标量 $d^{(c)} \\in \\mathbb{R}$，因为核和输入的空间尺寸相同。\n- 逐点步骤：将深度步骤的输出与一个 $1 \\times 1$ 的逐点权重向量 $p = \\begin{pmatrix} \\alpha \\\\ \\beta \\end{pmatrix}$ 进行线性混合，以获得单个输出标量 $y_{\\mathrm{dw}} = \\alpha \\, d^{(1)} + \\beta \\, d^{(2)}$。\n\n在此设置中，全卷积被定义为一种单输出卷积，其卷积核 $W$ 每个输入通道有一个空间切片，应用步幅 $1$ 和有效填充以产生一个标量 $y_{\\mathrm{full}}$。\n\n使用以下特定的、科学上一致的选择：\n- 深度核等于通道模式：$K^{(1)} = X^{(1)}$ 和 $K^{(2)} = X^{(2)}$。\n- 逐点混合权重为 $\\alpha = 2$ 和 $\\beta = -3$。\n- 全卷积核 $W$ 被选择为具有通道切片 $W^{(1)} = \\alpha \\, K^{(1)}$ 和 $W^{(2)} = \\beta \\, K^{(2)}$。\n\n从前向传播作为通过卷积进行线性聚合的核心定义出发，计算两个输出 $y_{\\mathrm{dw}}$ 和 $y_{\\mathrm{full}}$，然后确定其绝对差的平方\n$$\n\\Delta = \\left| y_{\\mathrm{dw}} - y_{\\mathrm{full}} \\right|^{2}.\n$$\n将你的最终答案表示为单个实数。不需要四舍五入。", "solution": "该问题要求计算两个量，$y_{\\mathrm{dw}}$ 和 $y_{\\mathrm{full}}$，它们分别由深度可分离卷积和全卷积产生，然后求出它们之间的差的平方。\n\n首先，我们必须将所描述的卷积操作形式化。输入通道 $X^{(c)}$ 和空间核 $K^{(c)}$ 的维度均为 $3 \\times 3$。卷积以步幅 $1$ 和“有效(valid)”填充进行。对于一个大小为 $N \\times N$ 的输入和一个大小为 $F \\times F$ 的核，步幅为 $S$，填充为 $P$，输出的空间维度由 $\\lfloor \\frac{N - F + 2P}{S} \\rfloor + 1$ 给出。当 $N=3$, $F=3$, $S=1$, 且 $P=0$ (对于有效填充)时，输出维度是 $\\lfloor \\frac{3 - 3 + 0}{1} \\rfloor + 1 = 1$。这意味着每个通道的空间卷积的输出是一个单一的标量。该标量的值是核与输入矩阵的逐元素乘积之和，这正是弗罗贝尼乌斯内积的定义，$\\langle A, B \\rangle_F = \\sum_{i,j} A_{ij} B_{ij}$。\n\n让我们从计算深度可分离卷积的输出 $y_{\\mathrm{dw}}$ 开始。这个过程包括两个步骤：深度步骤和逐点步骤。\n\n**1. 深度步骤：**\n对于每个输入通道 $c$，我们将输入 $X^{(c)}$ 与其对应的深度核 $K^{(c)}$ 进行卷积。输出是一个标量 $d^{(c)}$。\n$$\nd^{(c)} = \\text{conv}(X^{(c)}, K^{(c)}) = \\langle X^{(c)}, K^{(c)} \\rangle_F\n$$\n问题指定深度核等于输入通道模式本身：$K^{(1)} = X^{(1)}$ 和 $K^{(2)} = X^{(2)}$。\n\n对于第一个通道 ($c=1$)：\n$$\nd^{(1)} = \\langle X^{(1)}, K^{(1)} \\rangle_F = \\langle X^{(1)}, X^{(1)} \\rangle_F = \\|X^{(1)}\\|_F^2\n$$\n给定 $X^{(1)}$ 的矩阵：\n$$\nX^{(1)} = \\begin{pmatrix}\n1  0  -1 \\\\\n1  0  -1 \\\\\n1  0  -1\n\\end{pmatrix}\n$$\n弗罗贝尼乌斯范数的平方是其所有元素的平方和：\n$$\nd^{(1)} = 1^2 + 0^2 + (-1)^2 + 1^2 + 0^2 + (-1)^2 + 1^2 + 0^2 + (-1)^2 = 1 + 0 + 1 + 1 + 0 + 1 + 1 + 0 + 1 = 6\n$$\n\n对于第二个通道 ($c=2$)：\n$$\nd^{(2)} = \\langle X^{(2)}, K^{(2)} \\rangle_F = \\langle X^{(2)}, X^{(2)} \\rangle_F = \\|X^{(2)}\\|_F^2\n$$\n给定 $X^{(2)}$ 的矩阵：\n$$\nX^{(2)} = \\begin{pmatrix}\n1  1  1 \\\\\n0  0  0 \\\\\n-1  -1  -1\n\\end{pmatrix}\n$$\n弗罗贝尼乌斯范数的平方是：\n$$\nd^{(2)} = 1^2 + 1^2 + 1^2 + 0^2 + 0^2 + 0^2 + (-1)^2 + (-1)^2 + (-1)^2 = 1 + 1 + 1 + 0 + 0 + 0 + 1 + 1 + 1 = 6\n$$\n\n**2. 逐点步骤：**\n来自深度步骤的标量 $d^{(1)}=6$ 和 $d^{(2)}=6$ 使用逐点权重向量 $p = \\begin{pmatrix} \\alpha \\\\ \\beta \\end{pmatrix}$ 进行线性组合。给定的混合权重为 $\\alpha = 2$ 和 $\\beta = -3$。\n$$\ny_{\\mathrm{dw}} = \\alpha \\, d^{(1)} + \\beta \\, d^{(2)}\n$$\n代入数值：\n$$\ny_{\\mathrm{dw}} = (2)(6) + (-3)(6) = 12 - 18 = -6\n$$\n\n接下来，我们计算全卷积的输出 $y_{\\mathrm{full}}$。\n全卷积作用于整个输入体（所有通道），使用一个三维核 $W$，该核为每个输入通道 $c$ 都有一个空间切片 $W^{(c)}$。由于输出是单个标量，该操作是所有通道上相应输入切片和核切片的弗罗贝尼乌斯内积之和。\n$$\ny_{\\mathrm{full}} = \\sum_{c=1}^{2} \\langle X^{(c)}, W^{(c)} \\rangle_F = \\langle X^{(1)}, W^{(1)} \\rangle_F + \\langle X^{(2)}, W^{(2)} \\rangle_F\n$$\n问题指定全卷积的核切片为 $W^{(1)} = \\alpha \\, K^{(1)}$ 和 $W^{(2)} = \\beta \\, K^{(2)}$。我们还知道 $K^{(1)} = X^{(1)}$ 和 $K^{(2)} = X^{(2)}$。因此，我们可以将核切片写为：\n$$\nW^{(1)} = \\alpha \\, X^{(1)}\n\\quad \\text{和} \\quad\nW^{(2)} = \\beta \\, X^{(2)}\n$$\n将这些代入 $y_{\\mathrm{full}}$ 的表达式中：\n$$\ny_{\\mathrm{full}} = \\langle X^{(1)}, \\alpha X^{(1)} \\rangle_F + \\langle X^{(2)}, \\beta X^{(2)} \\rangle_F\n$$\n利用内积的线性性质，即对于标量 $k$，有 $\\langle A, k B \\rangle = k \\langle A, B \\rangle$：\n$$\ny_{\\mathrm{full}} = \\alpha \\langle X^{(1)}, X^{(1)} \\rangle_F + \\beta \\langle X^{(2)}, X^{(2)} \\rangle_F\n$$\n这个表达式等价于：\n$$\ny_{\\mathrm{full}} = \\alpha \\|X^{(1)}\\|_F^2 + \\beta \\|X^{(2)}\\|_F^2\n$$\n我们认识到 $\\|X^{(1)}\\|_F^2 = d^{(1)}$ 和 $\\|X^{(2)}\\|_F^2 = d^{(2)}$。因此，$y_{\\mathrm{full}}$ 的表达式与 $y_{\\mathrm{dw}}$ 的表达式相同：\n$$\ny_{\\mathrm{full}} = \\alpha \\, d^{(1)} + \\beta \\, d^{(2)} = y_{\\mathrm{dw}}\n$$\n这表明，对于本问题中核的特定构造方式，全卷积在数学上等价于深度可分离卷积。\n数值上，我们有：\n$$\ny_{\\mathrm{full}} = -6\n$$\n\n最后，我们计算所求的量 $\\Delta$，即 $y_{\\mathrm{dw}}$ 和 $y_{\\mathrm{full}}$ 之间的绝对差的平方。\n$$\n\\Delta = | y_{\\mathrm{dw}} - y_{\\mathrm{full}} |^2\n$$\n由于 $y_{\\mathrm{dw}} = y_{\\mathrm{full}} = -6$：\n$$\n\\Delta = | -6 - (-6) |^2 = |0|^2 = 0\n$$\n绝对差的平方是 $0$。输入通道 $X^{(1)}$ 和 $X^{(2)}$ 的正交性是所提供数据的一个属性，但在问题的特定核定义下，要确定 $y_{\\mathrm{dw}}$ 和 $y_{\\mathrm{full}}$ 的相等性并不直接需要该属性。这种相等性的出现是因为全卷积核 $W$ 的构造方式与深度可分离卷积的定义方式完全相同，使其变得‘可分离’。", "answer": "$$\n\\boxed{0}\n$$", "id": "3185403"}, {"introduction": "真实的神经网络之所以强大，是因为它们将线性运算与非线性激活函数相结合。本练习旨在探索一个关键的架构设计选择：在深度可分离卷积模块中放置非线性激活函数（如 $ \\mathrm{ReLU} $）的位置。你将通过推导和实验发现 [@problem_id:3115159]，不同的放置方式会产生根本不同的函数类别，从而揭示现代神经网络架构设计中的精妙之处。", "problem": "考虑在一维深度可分离卷积下，采用以下简化但科学合理的情形：空间核尺寸为 $1$，深度滤波器对每个通道是恒等变换，且该操作简化为逐通道偏置后进行跨通道混合。从核心定义出发：卷积是线性移位不变映射，深度可分离结构是逐通道卷积后接一个 $1 \\times 1$ 的跨通道逐点混合，以及整流线性单元 (ReLU) 非线性定义为 $\\,\\mathrm{ReLU}(t)=\\max\\{0,t\\}\\,$。在这些约束下，有两种非线性放置顺序需要比较：(A) 在深度卷积之后、逐点卷积之前应用ReLU，以及 (B) 在逐点卷积之后应用ReLU。你的任务是推导每种顺序所代表的函数类别，并在一个合成可分性基准上通过经验测试它们的表示能力后果。使用纯数学术语进行处理，输入为单个空间位置上 $C=2$ 个通道的数据，记为 $x=(x_1,x_2) \\in \\mathbb{R}^2$。\n\n推导任务：\n- 根据上述核心定义，当深度滤波器为恒等变换且核尺寸为 $1$ 时，推导顺序 (A) 和顺序 (B) 的函数形式。仔细确定线性映射和ReLU的位置。不要假设任何快捷公式；从逐通道线性变换加偏置开始，然后是跨通道线性混合，并根据每种顺序放置ReLU。\n\n基准测试任务：\n- 定义以0为阈值的分类：对于输入 $x$，如果模型的标量输出大于或等于 $0$，则预测为类别 $1$，否则预测为类别 $0$。使用三个合成测试用例来探究非线性放置位置的作用：\n    1. 用例 1 (需要混合的半空间)：输入是来自网格 $S=\\{-1.0,-0.5,0.0,0.5,1.0\\}$ 的所有点对 $(x_1,x_2)$，共产生 $25$ 个点。如果 $x_1 - x_2 \\ge 0$，目标类别为 $1$，否则为 $0$。此目标需要在阈值化之前进行混合。\n    2. 用例 2 (正部之和)：输入是来自网格 $S$ 的相同 $25$ 个点。如果 $\\mathrm{ReLU}(x_1) + 2\\,\\mathrm{ReLU}(x_2) - 1.0 \\ge 0$，目标类别为 $1$，否则为 $0$。此目标需要在混合之前进行逐通道整流。\n    3. 用例 3 (非负边界等价性)：输入是来自网格 $S_+=\\{0.0,0.5,1.0\\}$ 的所有点对 $(x_1,x_2)$，共产生 $9$ 个点。如果 $x_1 + 2\\,x_2 - 1.0 \\ge 0$，目标类别为 $1$，否则为 $0$。对于非负输入，逐通道整流没有效果，因此对于此半空间，两种顺序的表示能力应该是等价的。\n\n评估协议：\n- 对于每种用例和每种顺序，在整数参数网格上搜索，以找到在上述分类规则下对给定输入的最佳分类准确率。参数化如下：\n    - 深度偏置 $b_{d,1}, b_{d,2} \\in \\{-1,0,1\\}$。\n    - 逐点混合权重 $w_1, w_2 \\in \\{-2,-1,0,1,2\\}$。\n    - 输出偏置 $b_p \\in \\{-2,-1,0,1,2\\}$。\n- 对于顺序 (A)，标量输出是对逐通道整流和偏置后的输入应用跨通道线性混合，再加上输出偏置，没有进一步的非线性。如果输出 $\\ge 0$，则预测为类别 $1$，否则为类别 $0$。\n- 对于顺序 (B)，标量输出是对偏置输入进行跨通道线性混合后再加上输出偏置的结果进行整流（通过ReLU）。如果输出 $\\ge 0$，则预测为类别 $1$，否则为类别 $0$，这等价于检查ReLU之前的和是否 $\\ge 0$。\n\n测试套件和最终输出规范：\n- 实现这两种顺序，并为三个用例中的每一个评估在指定参数网格上可达到的最佳分类准确率。\n- 你的程序应生成单行输出，包含按以下顺序排列的六个准确率：$[\\text{A1},\\text{B1},\\text{A2},\\text{B2},\\text{A3},\\text{B3}]$，其中 $\\text{A}k$ 是顺序 (A) 在用例 $k$ 上的最佳准确率，$\\text{B}k$ 是顺序 (B) 在用例 $k$ 上的最佳准确率。\n- 最终输出是 $[0,1]$ 范围内的浮点数，每个数等于在该顺序和用例下找到的最佳参数所正确分类的输入比例。不涉及物理单位或角度单位。\n\n你的解决方案必须从卷积、线性混合和整流线性单元 (ReLU) 的基本定义出发，推导两种顺序的函数类别，并实现所述的基准和搜索协议以生成指定的输出。", "solution": "该问题要求推导简化深度可分离卷积层两种变体的函数形式，然后对合成的分类任务进行经验评估。验证确认了该问题是科学合理、定义明确的，并且为提供完整解决方案提供了所有必要信息。\n\n### 函数形式的推导\n\n背景是一个深度可分离卷积，其空间核尺寸为 $1$，在具有 $C=2$ 个通道的单个空间位置上对输入进行操作，输入向量记为 $x = (x_1, x_2)^T \\in \\mathbb{R}^2$。该操作包括一个深度阶段和一个逐点阶段。\n\n**1. 阶段定义**\n\n*   **深度阶段**：问题指定深度滤波器为恒等变换且核尺寸为 $1$。这将逐通道卷积简化为一个独立地对每个通道应用偏置的函数。设深度偏置为 $b_d = (b_{d,1}, b_{d,2})^T$。此阶段的输出 $x'$ 由下式给出：\n    $$\n    x' = \\begin{pmatrix} x'_1 \\\\ x'_2 \\end{pmatrix} = \\begin{pmatrix} 1 \\cdot x_1 + b_{d,1} \\\\ 1 \\cdot x_2 + b_{d,2} \\end{pmatrix} = \\begin{pmatrix} x_1 + b_{d,1} \\\\ x_2 + b_{d,2} \\end{pmatrix}\n    $$\n\n*   **逐点阶段**：此阶段执行 $1 \\times 1$ 卷积，这简化为输入通道的线性组合，以产生单个标量输出。设此阶段的输入为向量 $z = (z_1, z_2)^T$。逐点权重为 $w = (w_1, w_2)$，并且有一个单一的输出偏置 $b_p$。输出为：\n    $$\n    y_{\\text{out}} = w_1 z_1 + w_2 z_2 + b_p\n    $$\n\n*   **非线性**：整流线性单元 (ReLU) 定义为 $\\mathrm{ReLU}(t) = \\max\\{0, t\\}$。\n\n我们现在推导两种指定的非线性放置顺序的函数形式。\n\n**2. 顺序 (A): ReLU在深度阶段之后，逐点阶段之前**\n\n在此配置中，ReLU 激活函数应用于深度阶段的输出，然后其结果被送入逐点阶段。\n\n1.  输入 $x=(x_1, x_2)^T$ 通过深度阶段，得到 $x'=(x_1+b_{d,1}, x_2+b_{d,2})^T$。\n2.  ReLU 函数逐元素地应用于 $x'$：\n    $$\n    x'' = \\begin{pmatrix} \\mathrm{ReLU}(x_1 + b_{d,1}) \\\\ \\mathrm{ReLU}(x_2 + b_{d,2}) \\end{pmatrix}\n    $$\n3.  向量 $x''$ 是逐点阶段的输入 ($z=x''$)。最终的标量输出，我们记为 $f_A(x)$，是：\n    $$\n    f_A(x; b_d, w, b_p) = w_1 \\mathrm{ReLU}(x_1 + b_{d,1}) + w_2 \\mathrm{ReLU}(x_2 + b_{d,2}) + b_p\n    $$\n顺序 (A) 代表的函数类别是移位和整流后输入的线性组合。这是一个简单的两层神经网络的形式，其隐藏层包含两个ReLU神经元和一个线性输出单元。由 $f_A(x) = 0$ 定义的决策边界是分段线性的，这使其能够逼近非线性和非凸的决策区域。\n\n**3. 顺序 (B): ReLU在逐点阶段之后**\n\n在此配置中，深度阶段和逐点阶段首先进行线性组合，然后ReLU激活函数仅应用于最终的标量输出。\n\n1.  输入 $x=(x_1, x_2)^T$ 通过深度阶段，得到 $x'=(x_1+b_{d,1}, x_2+b_{d,2})^T$。\n2.  向量 $x'$ 是逐点阶段的输入 ($z=x'$)。激活前的输出是：\n    $$\n    y_{\\text{pre}} = w_1(x_1 + b_{d,1}) + w_2(x_2 + b_{d,2}) + b_p\n    $$\n    我们可以将其重新排列为关于 $x_1$ 和 $x_2$ 的线性函数的标准形式：\n    $$\n    y_{\\text{pre}} = w_1 x_1 + w_2 x_2 + (w_1 b_{d,1} + w_2 b_{d,2} + b_p)\n    $$\n3.  ReLU 函数应用于此标量值。最终的输出 $f_B(x)$ 是：\n    $$\n    f_B(x; b_d, w, b_p) = \\mathrm{ReLU}(y_{\\text{pre}}) = \\mathrm{ReLU}(w_1 x_1 + w_2 x_2 + (w_1 b_{d,1} + w_2 b_{d,2} + b_p))\n    $$\n分类规则是如果 $f_B(x) \\ge 0$ 则预测为类别 $1$。由于当且仅当 $t \\ge 0$ 时 $\\mathrm{ReLU}(t) \\ge 0$，这等价于检查 $y_{\\text{pre}} \\ge 0$。因此，决策边界是 $y_{\\text{pre}}=0$，这是 $(x_1, x_2)$ 平面中的一条直线方程。因此，对于任何参数选择，顺序 (B) 都充当一个线性分类器，只能学习超平面决策边界。\n\n### 基准测试任务分析与实现策略\n\n基准测试任务旨在探究这两种函数形式的不同表示能力。\n\n*   **用例 1 (需要混合的半空间)：** 目标是 $x_1 - x_2 \\ge 0$。这是一个线性决策边界。如前所推导，顺序 (B) 本质上是一个线性分类器，应该能够完美解决这个问题。顺序 (A) 也可以表示这个线性函数，例如，通过选择足够大的深度偏置 $b_{d,1}, b_{d,2}$，使得对于网格上的所有输入，ReLU的参数总是正的。在这种情况下，$\\mathrm{ReLU}(x_i+b_{d,i}) = x_i+b_{d,i}$，模型就变成了线性的。预计两种模型都能达到完美的准确率。\n\n*   **用例 2 (正部之和)：** 目标是 $\\mathrm{ReLU}(x_1) + 2\\mathrm{ReLU}(x_2) - 1.0 \\ge 0$。这个目标函数的形式与顺序 (A) 的结构完全匹配。通过选择参数 $b_{d,1}=0, b_{d,2}=0, w_1=1, w_2=2, b_p=-1$（这些参数都在指定的搜索网格中），顺序 (A) 可以完美地表示目标函数。相比之下，这个决策边界是非线性的，所以由顺序 (B) 表示的线性分类器将无法达到完美的准确率。\n\n*   **用例 3 (非负边界等价性)：** 目标是 $x_1 + 2x_2 - 1.0 \\ge 0$，并且所有输入 $(x_1, x_2)$ 都满足 $x_i \\ge 0$。对于顺序 (A)，如果我们选择 $b_{d,1}=0$ 和 $b_{d,2}=0$，函数变为 $f_A(x) = w_1\\mathrm{ReLU}(x_1) + w_2\\mathrm{ReLU}(x_2) + b_p$。由于 $x_i \\ge 0$，所以 $\\mathrm{ReLU}(x_i) = x_i$，因此函数简化为 $f_A(x) = w_1 x_1 + w_2 x_2 + b_p$。这与顺序 (B) 的激活前函数（当 $b_{d,1}=b_{d,2}=0$ 时）相同。由于顺序 (A) 的参数搜索空间包含了使其等价于顺序 (B) 的参数，并且目标是一个线性分隔符，因此两种模型都有能力完美地解决这个任务。\n\n实现将通过对六种场景（3个用例 $\\times$ 2种顺序）中的每一种，在离散参数网格上进行穷举搜索来完成。对于每种参数组合，都会在相应的数据集上计算模型的准确率。报告每种场景下在所有参数组合中找到的最大准确率。", "answer": "[1.0,1.0,1.0,0.84,1.0,1.0]", "id": "3115159"}]}