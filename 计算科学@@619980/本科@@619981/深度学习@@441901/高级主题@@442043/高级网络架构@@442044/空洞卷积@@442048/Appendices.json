{"hands_on_practices": [{"introduction": "掌握了扩张卷积的核心思想后，首要的实践就是量化其最直接的优势：感受野的指数级增长。本练习将我们带入基因组学的前沿应用场景，通过计算确定一个一维扩张卷积网络所需的最小层数，以覆盖长距离的DNA相互作用。通过这个实践[@problem_id:3116399]，你将亲手推导并应用感受野的计算公式，从而深刻理解网络结构参数如何共同决定其观察范围。", "problem": "一个基因组学实验室正在设计一种卷积神经网络（CNN）内的一维扩张卷积架构，用于检测脱氧核糖核酸（DNA）序列中跨越千碱基（kilobase）跨度的启动子-增强子相互作用。输入是一个长度为 $N$（碱基对）的单通道一维信号。该网络由 $L$ 个扩张卷积层堆叠而成，每个层的核大小为 $k = 5$，步长为 $s = 1$，选择零填充以保持空间长度不变，并且没有池化操作。第 $\\ell$ 层的扩张率为 $d_{\\ell} = 2^{\\ell}$，其中 $\\ell = 0, 1, \\dots, L-1$。\n\n从离散卷积的定义和扩张（核抽头的atrous间距）的定义出发，推导出经过 $L$ 层后单个输出位置的感受野 $R_{L}$（用 $k$ 和 $\\{d_{\\ell}\\}$ 表示）。然后，施加要求，即感受野必须至少达到预设的上下文长度 $L_{c} = 10^{4}$（碱基对），以捕获千碱基尺度上的启动子-增强子相互作用。确定满足此要求的最小整数 $L$。最终答案必须是单个整数。除了精确计算外，不需要进行任何舍入。", "solution": "所述问题具有科学依据、提法恰当、客观且内容自洽。在将深度学习模型应用于基因组学的背景下，所提供的参数是一致且切合实际的。问题要求对堆叠扩张卷积的感受野进行标准推导，然后进行直接计算。因此，该问题是有效的，并且可以推导出解。\n\n主要任务是确定一维卷积神经网络的感受野。设 $r_\\ell$ 为第 $\\ell$ 层后一个输出单元的感受野大小，其中层的索引为 $\\ell=0, 1, \\dots, L-1$。输入信号本身可以被认为具有 $r_{-1} = 1$ 的感受野。问题指定了恒定的核大小 $k$、恒定的步长 $s=1$ 以及随层变化的扩张率 $d_\\ell$。\n\n一个核大小为 $k$、步长为 $s=1$、扩张率为 $d$ 的单卷积层会扩展前一层的感受野。第 $\\ell$ 层后的感受野大小 $r_\\ell$ 与第 $\\ell-1$ 层后的感受野大小 $r_{\\ell-1}$ 之间的递推关系由下式给出：\n$$r_\\ell = r_{\\ell-1} + (k-1) d_\\ell$$\n这个关系之所以成立，是因为第 $\\ell$ 层核中的 $k$ 个抽头（tap）中的每一个都“看到”了来自第 $\\ell-1$ 层的大小为 $r_{\\ell-1}$ 的感受野。所有先前层 $s=1$ 的步长确保了第 $\\ell-1$ 层输出中的相邻单元的感受野在输入中移动了一个位置。第 $\\ell$ 层中的 $k$ 个抽头之间的距离为 $d_\\ell$。因此，核所增加的、超出第一个抽头感受野的总跨度是 $(k-1)d_\\ell$。\n\n为了找到 $L$ 层后的总感受野，我们记为 $R_L$（在我们的符号体系中对应于 $r_{L-1}$），我们可以从 $r_{-1}=1$ 开始展开这个递推关系：\n$$r_{L-1} = r_{L-2} + (k-1)d_{L-1}$$\n$$r_{L-1} = \\left( r_{L-3} + (k-1)d_{L-2} \\right) + (k-1)d_{L-1}$$\n$$...$$\n$$r_{L-1} = r_{-1} + \\sum_{i=0}^{L-1} (k-1)d_i$$\n代入 $r_{-1}=1$，我们得到 $L$ 层后感受野 $R_L$ 的通用公式：\n$$R_L = 1 + (k-1) \\sum_{\\ell=0}^{L-1} d_\\ell$$\n这就完成了问题的第一部分：用 $k$ 和 $\\{d_\\ell\\}$ 推导感受野。\n\n接下来，我们代入问题中提供的具体值。第 $\\ell$ 层的扩张率由 $d_\\ell = 2^\\ell$ 给出。这个求和变成一个几何级数：\n$$\\sum_{\\ell=0}^{L-1} d_\\ell = \\sum_{\\ell=0}^{L-1} 2^\\ell = \\frac{2^L - 1}{2-1} = 2^L - 1$$\n将此结果代回 $R_L$ 的表达式，我们得到用 $k$ 和 $L$ 表示的感受野：\n$$R_L = 1 + (k-1)(2^L - 1)$$\n问题给出了核大小 $k=5$，并要求感受野 $R_L$ 必须至少为上下文长度 $L_c = 10^4$。我们必须找到满足此条件的最小整数 $L$。\n不等式为：\n$$R_L \\ge L_c$$\n代入表达式和数值：\n$$\n\\begin{align*}\n1 + (5-1)(2^L - 1) &\\ge 10^4 \\\\\n1 + 4(2^L - 1) &\\ge 10000 \\\\\n4(2^L - 1) &\\ge 9999 \\\\\n2^L - 1 &\\ge \\frac{9999}{4} \\\\\n2^L - 1 &\\ge 2499.75 \\\\\n2^L &\\ge 2500.75\n\\end{align*}\n$$\n为了找到满足此不等式的最小整数 $L$，我们可以对不等式两边取以 2 为底的对数：\n$$L \\ge \\log_2(2500.75)$$\n我们可以使用换底公式 $\\log_b(x) = \\frac{\\ln(x)}{\\ln(b)}$ 来计算这个对数：\n$$L \\ge \\frac{\\ln(2500.75)}{\\ln(2)}$$\n对右侧进行数值计算：\n$$L \\ge \\frac{7.824310...}{0.693147...} \\approx 11.28801...$$\n由于层数 $L$ 必须是整数，因此 $L$ 的最小整数值是大于或等于 $11.28801...$ 的最小整数，即 $12$。\n\n我们可以通过检验 $L=11$ 和 $L=12$ 来验证这个结果：\n当 $L=11$ 时：\n$$R_{11} = 1 + (4)(2^{11} - 1) = 1 + 4(2048-1) = 1 + 4(2047) = 1 + 8188 = 8189$$\n由于 $8189  10000$，$L=11$ 是不够的。\n当 $L=12$ 时：\n$$R_{12} = 1 + (4)(2^{12} - 1) = 1 + 4(4096-1) = 1 + 4(4095) = 1 + 16380 = 16381$$\n由于 $16381 \\ge 10000$，$L=12$ 是足够的。\n因此，最小整数层数是 $12$。", "answer": "$$ \\boxed{12} $$", "id": "3116399"}, {"introduction": "理论联系实际，下一步是处理扩张卷积在实际应用中的一个关键挑战：边界效应。当卷积核的感受野超出输入信号的边界时，填充（padding）策略的选择变得至关重要，而扩张卷积的大扩张率会加剧这一问题。这个编程练习[@problem_id:3116389]要求你通过量化“边界偏差”来比较两种不同填充策略（零填充和反射填充）的效果，让你在代码层面掌握处理边界伪影的实用技巧。", "problem": "给定一个卷积神经网络 (CNN) 层的离散一维信号模型。设信号为序列 $\\{x[n]\\}_{n=0}^{N-1}$，有限脉冲响应核为 $\\{w[m]\\}_{m=0}^{K-1}$，其中核长度为 $K$，扩张因子为 $d \\in \\mathbb{Z}_{0}$。在索引 $i \\in \\{0,1,\\ldots,N-1\\}$ 处，采用“same”对齐方式的扩张卷积，根据卷积的线性和移位不变性，结合按扩张因子间隔的样本选择，定义如下：\n$$\ny[i] \\triangleq \\sum_{m=0}^{K-1} w[m] \\, x\\big(i + m \\cdot d - o\\big),\n$$\n其中 $o \\triangleq \\left\\lfloor \\frac{(K-1)d}{2} \\right\\rfloor$ 是对齐偏移量。索引 $i + m \\cdot d - o$ 可能会超出有效输入范围 $\\{0,\\ldots,N-1\\}$，此时需要一个边界扩展规则（填充）来定义 $x[\\cdot]$ 在所有位置的值。\n\n考虑两种填充规则：\n- 零填充：对于任意整数 $j$，定义 $x_{\\text{zero}}[j] \\triangleq x[j]$（如果 $0 \\le j \\le N-1$），否则 $x_{\\text{zero}}[j] \\triangleq 0$。\n- 反射填充：对于任意整数 $j$，通过在边界上重复反射（不包括边缘复制）来定义反射映射 $r(j)$，即：\n$$\nr(j) = \n\\begin{cases}\nj,  0 \\le j \\le N-1, \\\\\n-r(j)-1,  j  0, \\\\\n2N - r(j) - 1,  j \\ge N,\n\\end{cases}\n$$\n重复应用该规则直到 $0 \\le r(j) \\le N-1$ 成立，并设置 $x_{\\text{refl}}[j] \\triangleq x\\big(r(j)\\big)$。\n\n对于给定的扩张因子 $d$，将“边界索引集”定义为感受野超出信号支撑集的索引集合：\n$$\n\\mathcal{B}(d) \\triangleq \\left\\{ i \\in \\{0,\\ldots,N-1\\} \\;\\middle|\\; \\exists\\, m \\in \\{0,\\ldots,K-1\\} \\text{ such that } i + m \\cdot d - o \\notin \\{0,\\ldots,N-1\\} \\right\\}.\n$$\n对于常数输入 $x[n] \\equiv c$（其中 $c \\in \\mathbb{R}$），将内部参考输出（即感受野完全在信号支撑集内部时的输出）定义为：\n$$\ny_{\\text{center}} \\triangleq c \\sum_{m=0}^{K-1} w[m].\n$$\n对于填充规则 $p \\in \\{\\text{zero}, \\text{refl}\\}$，将平均边界偏差定义为：\n$$\nb_p(d) \\triangleq \\frac{1}{|\\mathcal{B}(d)|} \\sum_{i \\in \\mathcal{B}(d)} \\left( y_p[i] - y_{\\text{center}} \\right),\n$$\n其中 $y_p[i]$ 是使用所选填充规则的 $x_p[\\cdot]$ 计算得出的。\n\n任务：实现一个完整的、可运行的程序，该程序：\n1. 将每个测试信号构造为 $x[n] \\equiv 1$（无单位的常数 1）。\n2. 根据上述定义，为所有 $i \\in \\{0,\\ldots,N-1\\}$ 计算 $y_{\\text{zero}}[i]$ 和 $y_{\\text{refl}}[i]$。\n3. 精确地识别出指定的 $\\mathcal{B}(d)$。\n4. 为每个测试用例计算 $b_{\\text{zero}}(d)$、$b_{\\text{refl}}(d)$ 以及差值 $b_{\\text{zero}}(d) - b_{\\text{refl}}(d)$。\n5. 生成单行输出，其中包含所有结果，格式为方括号内的逗号分隔列表，顺序如下文所述。本问题不涉及单位、角度或百分比，所有数值输出必须是实数值。\n\n使用以下 $(N, K, w, d)$ 参数的测试套件：\n- 用例 1：$N = 21$, $K = 5$, $w = [0.25, 0.5, 1.0, 0.5, 0.25]$, $d = 1$。\n- 用例 2：$N = 21$, $K = 5$, $w = [0.25, 0.5, 1.0, 0.5, 0.25]$, $d = 2$。\n- 用例 3：$N = 21$, $K = 5$, $w = [0.25, 0.5, 1.0, 0.5, 0.25]$, $d = 3$。\n- 用例 4（感受野显著超过信号长度的边缘情况）：$N = 5$, $K = 7$, $w = [1, 1, 1, 1, 1, 1, 1]$, $d = 2$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表。\n- 对于每个用例 $j \\in \\{1,2,3,4\\}$，依次包含三个数字：$b_{\\text{zero}}(d_j)$、$b_{\\text{refl}}(d_j)$ 和 $b_{\\text{zero}}(d_j) - b_{\\text{refl}}(d_j)$。\n- 因此，总输出列表必须按用例顺序包含 12 个数字，例如 $\\big[ \\text{用例 1 三元组}, \\text{用例 2 三元组}, \\text{用例 3 三元组}, \\text{用例 4 三元组} \\big]$。", "solution": "该问题已经过验证，被确定为是适定的、有科学依据且内部一致的。我们可以着手进行正式求解。\n\n核心任务是在扩张卷积操作下，计算零填充和反射填充这两种填充方案的平均边界偏差。由于输入信号被指定为 $x[n] \\equiv 1$，问题得到了关键的简化。\n\n我们首先分析题目给出的定义。在索引 $i \\in \\{0, 1, \\ldots, N-1\\}$ 处的扩张卷积由下式给出：\n$$\ny[i] \\triangleq \\sum_{m=0}^{K-1} w[m] \\, x\\big(i + m \\cdot d - o\\big)\n$$\n其中对齐偏移量为 $o \\triangleq \\left\\lfloor \\frac{(K-1)d}{2} \\right\\rfloor$。\n对于常数信号 $x[n] \\equiv c$，其内部参考输出为：\n$$\ny_{\\text{center}} \\triangleq c \\sum_{m=0}^{K-1} w[m]\n$$\n问题指定了单位常数信号，因此 $c=1$。于是，$y_{\\text{center}} = \\sum_{m=0}^{K-1} w[m]$。对于填充规则 $p$，平均边界偏差为：\n$$\nb_p(d) \\triangleq \\frac{1}{|\\mathcal{B}(d)|} \\sum_{i \\in \\mathcal{B}(d)} \\left( y_p[i] - y_{\\text{center}} \\right)\n$$\n\n**反射填充分析 ($b_{\\text{refl}}(d)$)**\n\n反射填充规则将任意整数索引 $j$ 映射到索引 $r(j) \\in \\{0, \\ldots, N-1\\}$。填充后的信号值为 $x_{\\text{refl}}[j] \\triangleq x[r(j)]$。\n鉴于输入信号是常数 $x[n] = 1$（对于所有 $n \\in \\{0, \\ldots, N-1\\}$），在任何有效的反射索引 $r(j)$ 处的值也为 $1$。因此，对于任意整数 $j$，$x_{\\text{refl}}[j] = x[r(j)] = 1$。\n使用反射填充的输出 $y_{\\text{refl}}[i]$ 对于任何索引 $i$ 都可以计算如下：\n$$\ny_{\\text{refl}}[i] = \\sum_{m=0}^{K-1} w[m] \\, x_{\\text{refl}}\\big(i + m \\cdot d - o\\big) = \\sum_{m=0}^{K-1} w[m] \\cdot 1 = \\sum_{m=0}^{K-1} w[m]\n$$\n将其与参考输出进行比较，我们发现对于所有 $i \\in \\{0, \\ldots, N-1\\}$，$y_{\\text{refl}}[i] = y_{\\text{center}}$。\n因此，偏差计算中的差值项始终为零：\n$$\ny_{\\text{refl}}[i] - y_{\\text{center}} = 0 \\quad \\forall i\n$$\n这直接意味着，对于所有测试用例，只要 $|\\mathcal{B}(d)| \\neq 0$，反射填充的平均边界偏差就为零：\n$$\nb_{\\text{refl}}(d) = \\frac{1}{|\\mathcal{B}(d)|} \\sum_{i \\in \\mathcal{B}(d)} 0 = 0\n$$\n\n**零填充分析 ($b_{\\text{zero}}(d)$)**\n\n对于零填充，$x_{\\text{zero}}[j] = 1$（如果 $0 \\le j \\le N-1$），否则 $x_{\\text{zero}}[j] = 0$。\n对于索引 $i$ 的差值项 $(y_{\\text{zero}}[i] - y_{\\text{center}})$ 可以表示为：\n$$\ny_{\\text{zero}}[i] - y_{\\text{center}} = \\sum_{m=0}^{K-1} w[m] \\, x_{\\text{zero}}\\big(i + m \\cdot d - o\\big) - \\sum_{m=0}^{K-1} w[m] \\cdot 1\n$$\n$$\n= \\sum_{m=0}^{K-1} w[m] \\left( x_{\\text{zero}}\\big(i + m \\cdot d - o\\big) - 1 \\right)\n$$\n令 $j(m) = i + m \\cdot d - o$。如果 $j(m)$ 在信号边界 $[0, N-1]$ 内（此时 $x_{\\text{zero}}[j(m)] = 1$），则 $(x_{\\text{zero}}[j(m)] - 1)$ 项为 $0$；如果 $j(m)$ 越界（此时 $x_{\\text{zero}}[j(m)] = 0$），则该项为 $-1$。\n因此，该求和仅包含那些对应输入样本越界的核权重的贡献：\n$$\ny_{\\text{zero}}[i] - y_{\\text{center}} = - \\sum_{m \\text{ s.t. } i + m \\cdot d - o \\notin [0, N-1]} w[m]\n$$\n这为计算每个边界索引 $i \\in \\mathcal{B}(d)$ 的差值提供了一种直接方法：它等于那些“掉出”信号边缘的核权重的总和的负值。\n\n**算法**\n\n将通过对每个测试用例 $(N, K, w, d)$ 执行以下步骤来实现解法：\n\n1.  读取参数 $N$、$K$、$w$ 和 $d$。\n2.  计算对齐偏移量 $o = \\lfloor \\frac{(K-1)d}{2} \\rfloor$。\n3.  计算参考输出 $y_{\\text{center}} = \\sum_{m=0}^{K-1} w[m]$。\n4.  设置 $b_{\\text{refl}}(d) = 0.0$。\n5.  识别边界索引集 $\\mathcal{B}(d)$。如果索引 $i \\in \\{0, \\ldots, N-1\\}$ 的感受野的任何部分超出了 $[0, N-1]$，则它属于 $\\mathcal{B}(d)$。当访问的最小索引 $i-o$ 小于 $0$，或最大索引 $i+(K-1)d-o$ 大于或等于 $N$ 时，此条件成立。\n6.  初始化一个变量 `sum_of_differences_zero` 为 $0$。\n7.  对于每个索引 $i \\in \\mathcal{B}(d)$：\n    a. 通过对访问索引 $i + m \\cdot d - o$ 超出 $[0, N-1]$ 的权重 $w[m]$ 求和，然后取负，来计算差值 $y_{\\text{zero}}[i] - y_{\\text{center}}$。\n    b. 将此差值加到 `sum_of_differences_zero` 上。\n8.  计算偏差 $b_{\\text{zero}}(d) = \\frac{\\text{sum\\_of\\_differences\\_zero}}{|\\mathcal{B}(d)|}$。\n9.  该测试用例的最终结果是 $b_{\\text{zero}}(d)$、$b_{\\text{refl}}(d)$ 以及差值 $b_{\\text{zero}}(d) - b_{\\text{refl}}(d) = b_{\\text{zero}}(d)$。\n\n此算法将应用于所有四个提供的测试用例。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the dilated convolution border bias problem for a suite of test cases.\n    \"\"\"\n\n    test_cases = [\n        {'N': 21, 'K': 5, 'w': [0.25, 0.5, 1.0, 0.5, 0.25], 'd': 1},\n        {'N': 21, 'K': 5, 'w': [0.25, 0.5, 1.0, 0.5, 0.25], 'd': 2},\n        {'N': 21, 'K': 5, 'w': [0.25, 0.5, 1.0, 0.5, 0.25], 'd': 3},\n        {'N': 5, 'K': 7, 'w': [1.0] * 7, 'd': 2}\n    ]\n\n    def calculate_biases(N, K, w_list, d):\n        \"\"\"\n        Calculates the average border biases for a single test case.\n        \"\"\"\n        w = np.array(w_list, dtype=np.float64)\n        \n        # Calculate alignment offset.\n        o = (K - 1) * d // 2\n\n        # For a constant input signal x[n] = 1, reflective padding always samples the value 1.\n        # This makes the output y_refl[i] equal to the sum of kernel weights for all i.\n        # The reference output y_center is also the sum of kernel weights.\n        # Thus, the difference (y_refl[i] - y_center) is always 0.\n        # Consequently, the average border bias for reflective padding is 0.\n        b_refl = 0.0\n\n        # Identify the border index set B(d).\n        border_indices = set()\n        for i in range(N):\n            # The receptive field for output 'i' spans input indices from i - o to i + (K-1)*d - o.\n            # An index is on the border if any part of its receptive field is out of bounds.\n            rf_min_idx = i - o\n            rf_max_idx = i + (K - 1) * d - o\n            if rf_min_idx  0 or rf_max_idx >= N:\n                border_indices.add(i)\n\n        if not border_indices:\n            # If there are no border indices, the bias is 0.\n            b_zero = 0.0\n        else:\n            sum_of_differences_zero = 0.0\n            for i in border_indices:\n                # The difference (y_zero[i] - y_center) is the negative sum of weights that\n                # correspond to out-of-bounds input samples (padded with 0).\n                lost_weight_sum = 0.0\n                for m in range(K):\n                    j = i + m * d - o\n                    if not (0 = j  N):\n                        lost_weight_sum += w[m]\n                \n                diff = -lost_weight_sum\n                sum_of_differences_zero += diff\n            \n            b_zero = sum_of_differences_zero / len(border_indices)\n\n        b_diff = b_zero - b_refl\n        return b_zero, b_refl, b_diff\n\n    results = []\n    for case in test_cases:\n        b_zero, b_refl, b_diff = calculate_biases(case['N'], case['K'], case['w'], case['d'])\n        results.extend([b_zero, b_refl, b_diff])\n        \n    # Format the final output string exactly as required.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3116389"}, {"introduction": "最后，我们将探索扩张卷积的一个高级且强大的特性：各向异性扩张（anisotropic dilation）。通过在不同轴上设置不同的扩张率，我们可以精确地塑造感受野的形状，使其与数据中特定方向的结构相匹配。这个综合性编程任务[@problem_id:3116423]将指导你构建一个完整的图像处理流程，利用各向异性Sobel滤波器来检测特定方向的纹理边缘，并用F1分数来评估其性能。这个实践将直观地展示，如何通过调整感受野的几何形状来显著提升模型在结构化数据上的表现。", "problem": "本任务要求您实现并分析二维各向异性扩张（空洞）卷积，以研究感受野伸长对定向纹理边缘检测的影响。该设定纯粹是数学和算法层面的。所有图像均为离散数组，所有操作均在有限网格上进行。角度必须以弧度为单位指定。不涉及任何物理单位。\n\n使用的基本原理：\n- 对于一个离散图像 $I:\\mathbb{Z}^2\\to\\mathbb{R}$ 和一个有限离散核 $K:\\{-\\lfloor k_y/2\\rfloor,\\ldots,\\lfloor k_y/2\\rfloor\\}\\times\\{-\\lfloor k_x/2\\rfloor,\\ldots,\\lfloor k_x/2\\rfloor\\}\\to\\mathbb{R}$，离散二维卷积定义为 $I$ 和 $K$ 的移位乘积之和。\n- 扩张（空洞）卷积将核的采样点放置在一个网格上，网格的间距由每个轴上的扩张因子给出，这实际上是在保持核权重不变的情况下，在采样点之间跳过像素。\n- 一个卷积算子的感受野（RF）是影响单个输出位置的所有输入位置的集合。在各向异性扩张中，核采样点的间距在不同轴上有所不同，这使得感受野在一个轴上的伸长程度大于另一个轴。\n\n任务概述：\n1. 在一个大小为 $N\\times N$（其中 $N=64$）的方形网格上构建合成的定向条纹纹理。设 $(x,y)$ 为像素坐标索引，其中 $x\\in\\{0,\\ldots,N-1\\}$ 代表列， $y\\in\\{0,\\ldots,N-1\\}$ 代表行。通过 $x_c=x-\\frac{N}{2}$ 和 $y_c=y-\\frac{N}{2}$ 对坐标进行中心化。对于一个角度 $\\theta$（以弧度为单位）和条纹周期 $p=8$，定义投影 $u(x,y)=x_c\\cos\\theta+y_c\\sin\\theta$。通过以下方式定义二值条纹纹理：\n$$\nI(x,y)=\\begin{cases}\n1  \\text{若 } \\left\\lfloor \\frac{u(x,y)}{p}\\right\\rfloor \\bmod 2 = 1,\\\\\n0  \\text{其他情况。}\n\\end{cases}\n$$\n2. 使用 4-连通邻接来定义真值边缘掩码 $E_{\\text{gt}}(x,y)$。如果一个像素 $(x,y)$ 的至少一个 4-邻接像素具有不同的强度，即对于任何在边界范围内的邻居，有 $I(x,y)\\neq I(x\\pm1,y)$ 或 $I(x,y)\\neq I(x,y\\pm1)$，则该像素为真值边缘。\n3. 实现具有“same”输出形状的各向异性扩张卷积。对于扩张因子 $(d_y,d_x)$ 和一个大小为 $k_y\\times k_x$ 的核 $K$，位置 $(y,x)$ 处的输出是核权重与输入样本的乘积之和，这些输入样本在垂直方向上间距为 $d_y$，在水平方向上间距为 $d_x$。使用足够的零填充以保持“same”输出形状。\n4. 使用 Sobel 核对进行水平和垂直梯度计算：\n$$\nK_x=\\begin{bmatrix}-1  0  1\\\\-2  0  2\\\\-1  0  1\\end{bmatrix},\\quad\nK_y=\\begin{bmatrix}-1  -2  -1\\\\0  0  0\\\\1  2  1\\end{bmatrix}.\n$$\n将带有 $(d_y,d_x)$ 的各向异性扩张卷积应用于 $K_x$ 和 $K_y$，并计算梯度幅值：\n$$\nM(x,y)=\\sqrt{\\big( (I*K_x)_{d_y,d_x}(x,y)\\big)^2+\\big( (I*K_y)_{d_y,d_x}(x,y)\\big)^2}.\n$$\n5. 对梯度幅值图进行阈值处理以预测边缘。使用一个固定的相对阈值 $\\tau=0.3$（相对于最大响应值）：\n$$\nE_{\\text{pred}}(x,y)=\\begin{cases}\n1  \\text{若 } M(x,y)\\ge \\tau\\cdot \\max_{x',y'} M(x',y'),\\\\\n0  \\text{其他情况。}\n\\end{cases}\n$$\n6. 使用标准定义，计算 $E_{\\text{pred}}$ 和 $E_{\\text{gt}}$ 之间的 F1 分数（F1）。设 $T_P$ 为真正例的数量，$F_P$ 为假正例的数量，$F_N$ 为假反例的数量。定义精确率 $P=T_P/(T_P+F_P)$（约定当分母为 $0$ 时 $P=0$），召回率 $R=T_P/(T_P+F_N)$（约定当分母为 $0$ 时 $R=0$），以及\n$$\n\\text{F1}=\\begin{cases}\n\\frac{2PR}{P+R}  \\text{若 } P+R0,\\\\\n0  \\text{其他情况。}\n\\end{cases}\n$$\n\n测试套件：\n在以下参数集 $(\\theta,d_x,d_y)$上运行程序，其中角度以弧度为单位：\n- 情况 1：$\\theta=0.0$，$d_x=3$，$d_y=1$（在垂直条纹上水平拉长的感受野）。\n- 情况 2：$\\theta=0.0$，$d_x=1$，$d_y=3$（在垂直条纹上垂直拉长的感受野）。\n- 情况 3：$\\theta=\\frac{\\pi}{4}$，$d_x=3$，$d_y=1$（在对角线条纹上未对齐的拉伸）。\n- 情况 4：$\\theta=\\frac{\\pi}{2}$，$d_x=1$，$d_y=3$（在水平条纹上对齐的拉伸）。\n- 情况 5：$\\theta=0.0$，$d_x=1$，$d_y=1$（各向同性基准）。\n- 情况 6：$\\theta=0.0$，$d_x=7$，$d_y=1$（在垂直条纹上的极端拉伸边界）。\n\n最终输出格式要求：\n您的程序应生成一行输出，其中包含按上述顺序排列的各情况的 F1 分数，每个分数四舍五入到 $4$ 位小数，以逗号分隔列表的形式包含在方括号中，例如 $\\big[$$0.8123,0.6456,0.5021,0.9000,0.7801,0.4200$$\\big]$。", "solution": "该问题是有效的。它是一个在数字图像处理和深度学习领域内定义明确、有科学依据且客观的算法任务。所有为获得唯一解所必需的参数、定义和步骤均已提供。\n\n其目标是研究卷积滤波器感受野的伸长和方向如何影响其在定向纹理中检测边缘的能力。这是通过实现一个各向异性扩张卷积流程，并在​​一组合成纹理上使用 F1 分数评估其性能来完成的。\n\n解决方案按以下步骤进行：\n\n1.  **合成纹理生成**：对于每个测试用例，我们首先生成一个大小为 $N \\times N$（其中 $N=64$）的合成方形图像。像素坐标 $(x,y)$ 定义在网格 $\\{0, 1, \\ldots, N-1\\} \\times \\{0, 1, \\ldots, N-1\\}$ 上。这些坐标被中心化以获得 $(x_c, y_c)$，其中 $x_c = x - \\frac{N}{2}$ 和 $y_c = y - \\frac{N}{2}$。对于给定的方向角 $\\theta$（以弧度为单位），计算投影坐标 $u(x,y)$ 为 $u(x,y) = x_c\\cos\\theta + y_c\\sin\\theta$。这个投影有效地旋转了坐标系。然后，基于此投影和条纹周期 $p=8$，使用以下规则生成一个二值条纹纹理 $I(x,y)$：\n    $$\n    I(x,y)=\\begin{cases}\n    1  \\text{若 } \\left\\lfloor \\frac{u(x,y)}{p}\\right\\rfloor \\bmod 2 = 1,\\\\\n    0  \\text{其他情况。}\n    \\end{cases}\n    $$\n    该公式创建了宽度恒为 $p$ 的平行条纹，其方向由角度 $\\theta$ 决定。\n\n2.  **真值边缘掩码**：真值边缘掩码 $E_{\\text{gt}}$ 代表了边缘检测器的理想输出。如果一个像素 $(x,y)$ 的值 $I(x,y)$ 与其任何一个在图像边界内的 4-连通邻居（上、下、左、右）的值不同，则该像素被定义为边缘点。这是在离散网格上定义边缘的标准方法。生成的二值掩码 $E_{\\text{gt}}$ 在边缘位置为 $1$，其他位置为 $0$。\n\n3.  **各向异性扩张卷积**：这是本研究的核心操作。标准的二维卷积是一种将一个核（一个小的权重矩阵）在输入图像上滑动的操作。扩张（或空洞）卷积在核的权重之间引入间隙。这些间隙的大小由扩张因子控制。在各向异性扩张卷积中，垂直和水平轴的扩张因子 $(d_y, d_x)$ 可以不同。这会改变操作的感受野（RF）——即影响单个输出值的输入图像区域。对于一个 $k_y \\times k_x$ 的核，有效的感受野大小近似变为 $(k_y-1)d_y+1 \\times (k_x-1)d_x+1$。通过选择 $d_y \\ne d_x$，我们创建了一个拉长的感受野。\n    为了实现这一点，我们对输入图像 $I$ 和核 $K$ 执行二维互相关（深度学习库中的标准做法）。在 $(y,x)$ 处的输出计算如下：\n    $$\n    (I*K)_{d_y,d_x}(y,x) = \\sum_{j=-\\lfloor k_y/2 \\rfloor}^{\\lfloor k_y/2 \\rfloor} \\sum_{i=-\\lfloor k_x/2 \\rfloor}^{\\lfloor k_x/2 \\rfloor} K_{j,i} \\cdot I(y+j\\cdot d_y, x+i\\cdot d_x)\n    $$\n    其中 $K_{j,i}$ 是在相对位置 $(j,i)$ 处的核权重。为确保输出与输入具有“same”形状，输入图像 $I$ 首先用零进行填充。对于一个 $3 \\times 3$ 的核，顶部和底部需要 $d_y$ 的填充，左侧和右侧需要 $d_x$ 的填充。\n\n4.  **梯度幅值计算**：为了检测边缘，我们估计图像梯度。Sobel 算子提供了一对 $3 \\times 3$ 的核，$K_x$ 和 $K_y$，用于近似关于 $x$ 和 $y$ 的偏导数。\n    $$\n    K_x=\\begin{bmatrix}-1  0  1\\\\-2  0  2\\\\-1  0  1\\end{bmatrix},\\quad\n    K_y=\\begin{bmatrix}-1  -2  -1\\\\0  0  0\\\\1  2  1\\end{bmatrix}\n    $$\n    我们使用指定的扩张因子 $(d_y, d_x)$，将图像 $I$ 与这两个核分别进行各向异性扩张卷积，以获得梯度分量图 $G_x = (I*K_x)_{d_y,d_x}$ 和 $G_y = (I*K_y)_{d_y,d_x}$。然后，每个像素处的总梯度幅值 $M(x,y)$ 计算为梯度向量的欧几里得范数：\n    $$\n    M(x,y)=\\sqrt{G_x(x,y)^2 + G_y(x,y)^2}\n    $$\n\n5.  **通过阈值化进行边缘预测**：通过应用阈值，将连续值的梯度幅值图 $M(x,y)$ 转换为二值的预测边缘掩码 $E_{\\text{pred}}$。问题指定了相对阈值 $\\tau=0.3$。阈值为 $T = \\tau \\cdot \\max_{x',y'} M(x',y')$。则预测的边缘掩码为：\n    $$\n    E_{\\text{pred}}(x,y)=\\begin{cases}\n    1  \\text{若 } M(x,y)\\ge T,\\\\\n    0  \\text{其他情况。}\n    \\end{cases}\n    $$\n\n6.  **性能评估**：预测结果 $E_{\\text{pred}}$ 的质量通过使用 F1 分数将其与真值 $E_{\\text{gt}}$ 进行比较来衡量。这需要计算真正例（$T_P$）、假正例（$F_P$）和假反例（$F_N$）的数量。\n    -   $T_P = \\sum_{y,x} [E_{\\text{pred}}(y,x) = 1 \\text{ 且 } E_{\\text{gt}}(y,x) = 1]$\n    -   $F_P = \\sum_{y,x} [E_{\\text{pred}}(y,x) = 1 \\text{ 且 } E_{\\text{gt}}(y,x) = 0]$\n    -   $F_N = \\sum_{y,x} [E_{\\text{pred}}(y,x) = 0 \\text{ 且 } E_{\\text{gt}}(y,x) = 1]$\n    根据这些计数，我们计算精确率 $P = T_P / (T_P + F_P)$ 和召回率 $R = T_P / (T_P + F_N)$。F1 分数是精确率和召回率的调和平均数：\n    $$\n    \\text{F1}=\\frac{2PR}{P+R}\n    $$\n    并按规定对分母为零的情况进行特殊处理。F1 分数提供了一个平衡的性能度量，它同时惩罚了漏检的边缘（低召回率）和虚假的检测（低精确率）。\n\n对于测试套件中的每一组参数 $(\\theta, d_x, d_y)$，都会执行这个完整的流程，从而为每种配置得出一个 F1 分数。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and analyzes anisotropic dilated convolutions for edge detection.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (theta, d_x, d_y)\n        (0.0, 3, 1),\n        (0.0, 1, 3),\n        (np.pi / 4, 3, 1),\n        (np.pi / 2, 1, 3),\n        (0.0, 1, 1),\n        (0.0, 7, 1),\n    ]\n\n    results = []\n    \n    N = 64\n    p = 8.0\n    tau = 0.3\n    \n    K_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=np.float64)\n    K_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=np.float64)\n\n    def dilated_convolution(image, kernel, d_y, d_x):\n        \"\"\"\n        Computes 2D dilated cross-correlation with zero padding for 'same' output.\n        \"\"\"\n        img_h, img_w = image.shape\n        k_h, k_w = kernel.shape\n        \n        # Center of the 3x3 kernel is at (1,1)\n        k_h_center, k_w_center = k_h // 2, k_w // 2\n        \n        # Required padding on each side to maintain 'same' shape\n        pad_y = k_h_center * d_y\n        pad_x = k_w_center * d_x\n\n        padded_image = np.pad(image, ((pad_y, pad_y), (pad_x, pad_x)), mode='constant', constant_values=0)\n        output = np.zeros_like(image, dtype=np.float64)\n\n        for y in range(img_h):\n            for x in range(img_w):\n                val = 0.0\n                for ky in range(k_h):\n                    for kx in range(k_w):\n                        # Kernel indices relative to center, e.g., -1, 0, 1\n                        j = ky - k_h_center\n                        i = kx - k_w_center\n                        \n                        # Corresponding image coordinates in the padded image\n                        img_y = y + pad_y + j * d_y\n                        img_x = x + pad_x + i * d_x\n                        \n                        val += padded_image[img_y, img_x] * kernel[ky, kx]\n                output[y, x] = val\n        return output\n\n    for case in test_cases:\n        theta, d_x, d_y = case\n\n        # 1. Generate synthetic oriented stripe texture I\n        coords = np.arange(N)\n        x_c = coords - N / 2.0\n        y_c = coords - N / 2.0\n        xx_c, yy_c = np.meshgrid(x_c, y_c)\n        \n        u = xx_c * np.cos(theta) + yy_c * np.sin(theta)\n        I = (np.floor(u / p) % 2 == 1).astype(np.float64)\n\n        # 2. Generate ground-truth edge mask E_gt\n        E_gt = np.zeros_like(I, dtype=int)\n        for y in range(N):\n            for x in range(N):\n                current_val = I[y, x]\n                is_edge = False\n                # Check 4-connected neighbors\n                if y > 0 and I[y - 1, x] != current_val: is_edge = True\n                if y  N - 1 and I[y + 1, x] != current_val: is_edge = True\n                if x > 0 and I[y, x - 1] != current_val: is_edge = True\n                if x  N - 1 and I[y, x + 1] != current_val: is_edge = True\n                if is_edge:\n                    E_gt[y, x] = 1\n        \n        # 4. Apply kernels and compute gradient magnitude M\n        G_x = dilated_convolution(I, K_x, d_y, d_x)\n        G_y = dilated_convolution(I, K_y, d_y, d_x)\n        M = np.sqrt(G_x**2 + G_y**2)\n\n        # 5. Threshold magnitude map to get predicted edges E_pred\n        M_max = np.max(M)\n        if M_max > 0:\n            threshold = tau * M_max\n            E_pred = (M >= threshold).astype(int)\n        else:\n            E_pred = np.zeros_like(M, dtype=int)\n\n        # 6. Compute F1 score\n        TP = np.sum((E_pred == 1)  (E_gt == 1))\n        FP = np.sum((E_pred == 1)  (E_gt == 0))\n        FN = np.sum((E_pred == 0)  (E_gt == 1))\n        \n        # Precision\n        if (TP + FP) == 0:\n            P = 0.0\n        else:\n            P = TP / (TP + FP)\n        \n        # Recall\n        if (TP + FN) == 0:\n            R = 0.0\n        else:\n            R = TP / (TP + FN)\n        \n        # F1 Score\n        if (P + R) == 0:\n            F1 = 0.0\n        else:\n            F1 = (2 * P * R) / (P + R)\n            \n        results.append(round(F1, 4))\n\n    # Format and print the final output as specified\n    print(f\"[{','.join(f'{r:.4f}' for r in results)}]\")\n\nsolve()\n```", "id": "3116423"}]}