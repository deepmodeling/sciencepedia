{"hands_on_practices": [{"introduction": "要真正掌握一个优化算法，最好的方法莫过于亲手计算一遍。这个练习将引导你完成 AdamW 优化器单步更新的完整计算过程。通过这个实践，你将深入理解指数移动平均、偏差修正以及解耦权重衰减这几个核心组件是如何协同工作的，从而为更复杂的应用打下坚实的基础 [@problem_id:3096505]。", "problem": "考虑一个标量参数 $w$，使用基于梯度的学习方法来最小化一个可微损失 $L(w)$。在随机梯度下降（SGD）中，梯度步长与瞬时梯度 $g_t = \\frac{dL}{dw}\\big|_{t}$ 成正比。解耦权重衰减的自适应矩估计（AdamW）优化器会维护历史梯度和梯度平方的指数移动平均值。设一阶矩和二阶矩由指数移动平均递推关系定义，分别为 $m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) g_t$ 和 $v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2$，其中 $m_0 = 0$ 且 $v_0 = 0$。为了校正这些移动平均中固有的初始化偏差，定义偏差校正后的估计值 $\\hat{m}_t = \\frac{m_t}{1 - \\beta_1^{t}}$ 和 $\\hat{v}_t = \\frac{v_t}{1 - \\beta_2^{t}}$。在 AdamW 中，解耦权重衰减原理规定，一个与当前参数值成正比的收缩项被独立于梯度归一化而应用，这会产生一个加性更新分量，其大小与 $w_t$ 和权重衰减系数成线性关系。\n\n给定以下数值：初始参数 $w_0 = 2.0$，第一步的梯度 $g_1 = 0.3$，学习率 $\\alpha = 1.0 \\times 10^{-3}$，指数衰减率 $\\beta_1 = 0.9$ 和 $\\beta_2 = 0.999$，数值稳定器 $\\epsilon = 1.0 \\times 10^{-8}$，以及权重衰减系数 $\\lambda = 0.01$。请仅使用上述关于指数移动平均、其偏差校正和解耦权重衰减原理的定义，推导在 $t=1$ 时由 AdamW 优化器应用于 $w_0$ 的带符号的第一步变化量 $\\Delta w_1$。你的推导必须明确说明量 $\\hat{m}_1 = \\frac{m_1}{1 - \\beta_1}$ 和 $\\hat{v}_1 = \\frac{v_1}{1 - \\beta_2}$ 是如何决定归一化梯度步长的大小的。\n\n计算单个实数 $\\Delta w_1$ 并将其作为最终答案报告。将你的答案四舍五入到四位有效数字。", "solution": "该问题是适定且有科学依据的，提供了一套完整的定义和参数，用于计算由 AdamW 算法优化的标量参数 $w$ 的第一步变化量 $\\Delta w_1$。\n\n带有解耦权重衰减的 AdamW 优化器更新规则由在步骤 $t$ 应用于参数 $w_{t-1}$ 的变化量 $\\Delta w_t$ 定义：\n$$ \\Delta w_t = w_t - w_{t-1} = -\\alpha \\left( \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon} + \\lambda w_{t-1} \\right) $$\n其中 $\\alpha$ 是学习率，$\\lambda$ 是权重衰减系数，$\\epsilon$ 是用于数值稳定性的一个很小的常数，$\\hat{m}_t$ 和 $\\hat{v}_t$ 分别是偏差校正后的一阶矩和二阶矩估计值。参数 $w_{t-1}$ 是更新步骤 $t$ 开始时的参数值。我们被要求计算第一步（$t=1$）的这个变化量，记为 $\\Delta w_1$。\n\n给定的值为：\n初始参数：$w_0 = 2.0$\n步骤 1 的梯度：$g_1 = 0.3$\n学习率：$\\alpha = 1.0 \\times 10^{-3}$\n权重衰减系数：$\\lambda = 0.01$\n一阶矩的指数衰减率：$\\beta_1 = 0.9$\n二阶矩的指数衰减率：$\\beta_2 = 0.999$\n初始一阶矩：$m_0 = 0$\n初始二阶矩：$v_0 = 0$\n数值稳定器：$\\epsilon = 1.0 \\times 10^{-8}$\n\n计算分步进行：\n\n首先，我们计算在步骤 $t=1$ 时的一阶矩和二阶矩 $m_1$ 和 $v_1$。\n一阶矩 $m_t$ 是梯度的指数移动平均，由递推关系 $m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) g_t$ 定义。对于 $t=1$：\n$$ m_1 = \\beta_1 m_0 + (1 - \\beta_1) g_1 $$\n代入给定值：\n$$ m_1 = (0.9)(0) + (1 - 0.9)(0.3) = (0.1)(0.3) = 0.03 $$\n\n二阶矩 $v_t$ 是梯度平方的指数移动平均，由 $v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2$ 定义。对于 $t=1$：\n$$ v_1 = \\beta_2 v_0 + (1 - \\beta_2) g_1^2 $$\n代入给定值：\n$$ v_1 = (0.999)(0) + (1 - 0.999)(0.3)^2 = (0.001)(0.09) = 0.00009 $$\n\n其次，我们计算偏差校正后的矩估计值 $\\hat{m}_1$ 和 $\\hat{v}_1$。这些校正考虑了移动平均是从零开始初始化的事实。\n偏差校正后的一阶矩是 $\\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}$。对于 $t=1$：\n$$ \\hat{m}_1 = \\frac{m_1}{1 - \\beta_1^1} = \\frac{m_1}{1 - \\beta_1} $$\n$$ \\hat{m}_1 = \\frac{0.03}{1 - 0.9} = \\frac{0.03}{0.1} = 0.3 $$\n作为检验，我们注意到对于第一步，$\\hat{m}_1 = \\frac{(1 - \\beta_1) g_1}{1 - \\beta_1} = g_1 = 0.3$。\n\n偏差校正后的二阶矩是 $\\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}$。对于 $t=1$：\n$$ \\hat{v}_1 = \\frac{v_1}{1 - \\beta_2^1} = \\frac{v_1}{1 - \\beta_2} $$\n$$ \\hat{v}_1 = \\frac{0.00009}{1 - 0.999} = \\frac{0.00009}{0.001} = 0.09 $$\n类似地，对于第一步，$\\hat{v}_1 = \\frac{(1 - \\beta_2) g_1^2}{1 - \\beta_2} = g_1^2 = (0.3)^2 = 0.09$。\n\n第三，我们使用 AdamW 更新规则计算 $t=1$ 时的总变化量 $\\Delta w_1$：\n$$ \\Delta w_1 = -\\alpha \\left( \\frac{\\hat{m}_1}{\\sqrt{\\hat{v}_1} + \\epsilon} + \\lambda w_0 \\right) $$\n代入计算出的和给定的值：\n$$ \\Delta w_1 = -(1.0 \\times 10^{-3}) \\left( \\frac{0.3}{\\sqrt{0.09} + 1.0 \\times 10^{-8}} + (0.01)(2.0) \\right) $$\n\n现在，我们逐项计算该表达式：\n偏差校正后的二阶矩的平方根是：\n$$ \\sqrt{\\hat{v}_1} = \\sqrt{0.09} = 0.3 $$\n自适应梯度项是：\n$$ \\frac{\\hat{m}_1}{\\sqrt{\\hat{v}_1} + \\epsilon} = \\frac{0.3}{0.3 + 1.0 \\times 10^{-8}} = \\frac{0.3}{0.30000001} \\approx 0.9999999667 $$\n解耦权重衰减项是：\n$$ \\lambda w_0 = (0.01)(2.0) = 0.02 $$\n括号内的和是：\n$$ 0.9999999667 + 0.02 = 1.0199999667 $$\n最后，我们乘以负的学习率：\n$$ \\Delta w_1 = -(1.0 \\times 10^{-3}) (1.0199999667) = -0.0010199999667 $$\n\n问题要求将最终答案四舍五入到四位有效数字。第一个有效数字是第一个非零数字，即 $1$。前四位有效数字是 $1$、$0$、$1$、$9$。第五位有效数字是 $9$，大于或等于 $5$，所以我们将第四位有效数字进一。\n$$ -0.00101999... \\approx -0.001020 $$\n末尾的零是有效数字。", "answer": "$$\\boxed{-0.001020}$$", "id": "3096505"}, {"introduction": "在理解了 AdamW 的基本计算步骤之后，我们来探讨一个关键问题：“为什么偏差修正是必不可少的？”。这个练习要求你设计一个数值实验，通过模拟来量化在训练初期关闭偏差修正导致的步长误差。通过这个动手实践，你将直观地看到偏差修正机制在稳定优化过程中的重要作用，并理解它为何是 Adam 和 AdamW 算法的基石之一 [@problem_id:3096510]。", "problem": "您需要设计并实现一个在解耦权重衰减的自适应矩估计 (AdamW) 背景下的数值实验，以展示和量化在学习率线性预热 (linear warmup) 期间，关闭偏差修正（直接使用 $m_t$ 和 $v_t$）如何导致有效步长的下冲 (under-shooting) 或过冲 (over-shooting)。该实验必须从第一性原理推导得出，并实现为一个能够产生指定输出的完整、可运行的程序。\n\n从以下基础出发：\n- 对于从零初始化的一系列梯度 $\\{g_t\\}$，其一阶和二阶矩估计量的指数移动平均 (EMA) 定义如下：\n$$\nm_t = \\beta_1 m_{t-1} + (1 - \\beta_1) g_t, \\quad m_0 = 0,\n$$\n$$\nv_t = \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2, \\quad v_0 = 0,\n$$\n其中 $0 \\le \\beta_1, \\beta_2  1$。\n- AdamW 的解耦权重衰减形式使用一阶和二阶矩估计以及学习率调度来应用参数更新。在本问题中，将权重衰减项设置为零，以隔离偏差修正对有效步长的影响。\n\n您必须在所有步骤 $t$ 中使用恒定标量梯度 $g_t = g$ 来实现一个模拟，并采用如下的学习率线性预热调度：\n$$\n\\eta_t = \\eta_{\\max} \\cdot \\frac{t}{W}, \\quad t = 1, 2, \\dots, W,\n$$\n其中 $W$ 是预热步骤的总数，$\\eta_{\\max}$ 是预热结束时的目标学习率。\n\n将步骤 $t$ 的有效步长定义为有符号标量\n$$\ns_t = \\eta_t \\cdot \\frac{m}{\\sqrt{v} + \\epsilon},\n$$\n其中 $\\epsilon > 0$ 是一个数值稳定项，$m$ 和 $v$ 要么是有偏估计 $(m_t, v_t)$，要么是从 EMA 定义和零初始化推导出的它们的无偏对应物。对于基准（正确）参考，请使用无偏对应物。对于“关闭偏差修正”的条件，请直接使用 $(m_t, v_t)$。\n\n对于每个指定的测试用例，您的程序必须计算在关闭偏差修正时，在预热步骤 $t = 1, \\dots, W$ 中有效步长的有符号相对误差，\n$$\ne_t = \\frac{s_t^{\\text{uncorr}} - s_t^{\\text{corr}}}{\\left| s_t^{\\text{corr}} \\right|},\n$$\n仅针对 $\\left| s_t^{\\text{corr}} \\right| > 0$ 的步骤进行计算；$\\left| s_t^{\\text{corr}} \\right| = 0$ 的步骤应从聚合中排除。如果排除后没有剩余步骤，则将该测试用例的所有输出定义为 $0.0$。\n\n对于每个测试用例，输出以下三个浮点数指标：\n- $E_{\\max}$：在有效预热步骤中 $e_t$ 的最大值，\n- $E_{\\min}$：在有效预热步骤中 $e_t$ 的最小值，\n- $E_W$：在最后一个预热步骤 $t=W$ 时 $e_t$ 的值（如果无效则使用 $0.0$）。\n\n本问题中的所有量均为纯数学标量；不涉及物理单位或角度单位。所有输出必须是浮点数。\n\n您的程序需要覆盖的测试套件：\n1. 具有典型超参数的标准预热：\n   - $\\beta_1 = 0.9$, $\\beta_2 = 0.999$, $\\eta_{\\max} = 0.001$, $\\epsilon = 10^{-8}$, $g = 0.1$, $W = 100$.\n2. 无动量累积的边界情况：\n   - $\\beta_1 = 0.0$, $\\beta_2 = 0.0$, $\\eta_{\\max} = 0.001$, $\\epsilon = 10^{-8}$, $g = 1.0$, $W = 50$.\n3. 重动量和二阶矩平滑：\n   - $\\beta_1 = 0.99$, $\\beta_2 = 0.9999$, $\\eta_{\\max} = 0.002$, $\\epsilon = 10^{-12}$, $g = 1.0$, $W = 400$.\n4. 零梯度情况：\n   - $\\beta_1 = 0.9$, $\\beta_2 = 0.999$, $\\eta_{\\max} = 0.001$, $\\epsilon = 10^{-8}$, $g = 0.0$, $W = 100$.\n5. 稳定项主导的情况：\n   - $\\beta_1 = 0.9$, $\\beta_2 = 0.999$, $\\eta_{\\max} = 0.001$, $\\epsilon = 0.01$, $g = 0.001$, $W = 100$.\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个结果列表，每个测试用例一个结果，每个结果是包含三个浮点指标 $[E_{\\max}, E_{\\min}, E_W]$ 的列表。整体输出必须打印为单行，不含额外文本，格式如下\n$$\n\\big[ [E_{\\max}^{(1)}, E_{\\min}^{(1)}, E_{W}^{(1)}], [E_{\\max}^{(2)}, E_{\\min}^{(2)}, E_{W}^{(2)}], \\dots \\big].\n$$", "solution": "该问题要求进行一个数值实验，以量化在学习率线性预热期间，AdamW 优化器中省略偏差修正所引入的误差。该分析在恒定梯度 $g_t = g$ 的简化条件下进行。我们被要求计算有效步长的有符号相对误差，并报告其在预热期间的最大值、最小值和最终值。\n\n解决方案的核心是推导出该误差的解析表达式，从而实现精确而高效的计算。推导过程如下。\n\n首先，我们建立在恒定梯度 $g$ 下，有偏一阶和二阶矩估计量 $m_t$ 和 $v_t$ 的闭式表达式。一阶矩的指数移动平均 (EMA) 递推关系由下式给出：\n$$\nm_t = \\beta_1 m_{t-1} + (1 - \\beta_1) g_t, \\quad m_0 = 0\n$$\n当 $g_t = g$ 时，这个线性递推关系可以展开成一个几何级数：\n$$\nm_t = (1 - \\beta_1) g \\sum_{i=0}^{t-1} \\beta_1^i = (1 - \\beta_1) g \\frac{1 - \\beta_1^t}{1 - \\beta_1} = g(1 - \\beta_1^t)\n$$\n通过相同的论证，对 $g_t^2$ 进行平均的二阶矩估计 $v_t$ 是：\n$$\nv_t = g^2(1 - \\beta_2^t)\n$$\n这些是有偏估计，因为它们在 $0$ 处初始化，因此在训练的初始步骤中偏向于零。\n\n接下来，我们定义标准的偏差修正后估计量，记为 $\\hat{m}_t$ 和 $\\hat{v}_t$。它们通过将有偏估计量除以各自的偏差修正因子得到：\n$$\n\\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t} = \\frac{g(1 - \\beta_1^t)}{1 - \\beta_1^t} = g\n$$\n$$\n\\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t} = \\frac{g^2(1 - \\beta_2^t)}{1 - \\beta_2^t} = g^2\n$$\n这个结果是直观的：对于一个恒定的梯度序列，真实均值是 $g$，真实的非中心二阶矩是 $g^2$。偏差修正机制在每个步骤 $t \\ge 1$ 都能正确地恢复这些真实值。\n\n有了这些表达式，我们就可以定义在步骤 $t$ 的两种有效步长。学习率由线性预热调度 $\\eta_t = \\eta_{\\max} \\cdot \\frac{t}{W}$ 给出。\n“修正后的”（基准）有效步长 $s_t^{\\text{corr}}$ 使用无偏估计：\n$$\ns_t^{\\text{corr}} = \\eta_t \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon} = \\eta_t \\frac{g}{\\sqrt{g^2} + \\epsilon} = \\eta_t \\frac{g}{|g| + \\epsilon}\n$$\n“未修正的”有效步长 $s_t^{\\text{uncorr}}$ 直接使用有偏估计：\n$$\ns_t^{\\text{uncorr}} = \\eta_t \\frac{m_t}{\\sqrt{v_t} + \\epsilon} = \\eta_t \\frac{g(1 - \\beta_1^t)}{\\sqrt{g^2(1 - \\beta_2^t)} + \\epsilon} = \\eta_t \\frac{g(1 - \\beta_1^t)}{|g|\\sqrt{1 - \\beta_2^t} + \\epsilon}\n$$\n问题要求计算有符号相对误差 $e_t$：\n$$\ne_t = \\frac{s_t^{\\text{uncorr}} - s_t^{\\text{corr}}}{\\left| s_t^{\\text{corr}} \\right|}\n$$\n这可以重写为：\n$$\ne_t = \\frac{s_t^{\\text{uncorr}}}{|s_t^{\\text{corr}}|} - \\frac{s_t^{\\text{corr}}}{|s_t^{\\text{corr}}|} = \\frac{s_t^{\\text{uncorr}}}{|s_t^{\\text{corr}}|} - \\text{sgn}(s_t^{\\text{corr}})\n$$\n考虑到当 $t \\ge 1$ 时 $\\eta_t > 0$ 且 $|g|+\\epsilon > 0$，$s_t^{\\text{corr}}$ 的符号与 $g$ 的符号相同。因此，对于 $g \\neq 0$，有 $\\text{sgn}(s_t^{\\text{corr}}) = \\text{sgn}(g)$。\n修正后步长的大小为 $|s_t^{\\text{corr}}| = \\eta_t \\frac{|g|}{|g| + \\epsilon}$。\n将这些代入 $e_t$ 的表达式中：\n$$\ne_t = \\frac{\\eta_t \\frac{g(1 - \\beta_1^t)}{|g|\\sqrt{1 - \\beta_2^t} + \\epsilon}}{\\eta_t \\frac{|g|}{|g| + \\epsilon}} - \\text{sgn}(g)\n$$\n$\\eta_t$ 项被消掉。对于 $g \\neq 0$，重新整理并使用恒等式 $\\frac{g}{|g|} = \\text{sgn}(g)$：\n$$\ne_t = \\frac{g}{|g|} \\frac{(|g| + \\epsilon)(1 - \\beta_1^t)}{|g|\\sqrt{1 - \\beta_2^t} + \\epsilon} - \\text{sgn}(g)\n$$\n$$\ne_t = \\text{sgn}(g) \\left[ \\frac{(|g| + \\epsilon)(1 - \\beta_1^t)}{|g|\\sqrt{1 - \\beta_2^t} + \\epsilon} - 1 \\right]\n$$\n这个最终的解析表达式允许我们计算任意步骤 $t$ 的 $e_t$，而无需迭代递推关系。\n\n数值实验的实现方式是：对每个测试用例，迭代 $t$ 从 $1$ 到 $W$，使用此公式计算 $e_t$，然后从得到的误差序列中找出最大值、最小值和最终值。\n\n特殊情况根据推导的公式和问题规范进行处理：\n- 如果 $g = 0$，则 $s_t^{\\text{corr}}$ 始终为 $0$。有效步骤的条件 $\\left|s_t^{\\text{corr}}\\right| > 0$ 永远不会满足。按照指示，所有输出 ($E_{\\max}, E_{\\min}, E_W$) 都被定义为 $0.0$。\n- 如果 $\\beta_1 = 0$ 且 $\\beta_2 = 0$，那么对于 $t \\ge 1$，$m_t = g$ 且 $v_t = g^2$，这与无偏估计相同。因此 $s_t^{\\text{uncorr}} = s_t^{\\text{corr}}$，使得所有有效步骤的 $e_t = 0$。所有输出均为 $0.0$。\n\n实现将以向量化的方式在预热步骤 $t=1, \\dots, W$ 上使用这个推导出的公式，以确保计算的高效和准确。然后收集每个测试用例的结果 $[E_{\\max}, E_{\\min}, E_W]$，并将其格式化为指定的输出字符串。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the numerical experiment for all test cases.\n    \"\"\"\n    \n    # Test suite as per the problem statement.\n    test_cases = [\n        # (beta1, beta2, eta_max, epsilon, g, W)\n        # 1. Standard warmup with typical hyperparameters\n        (0.9, 0.999, 0.001, 1e-8, 0.1, 100),\n        # 2. Boundary case with no momentum accumulation\n        (0.0, 0.0, 0.001, 1e-8, 1.0, 50),\n        # 3. Heavy momentum and second-moment smoothing\n        (0.99, 0.9999, 0.002, 1e-12, 1.0, 400),\n        # 4. Zero-gradient regime\n        (0.9, 0.999, 0.001, 1e-8, 0.0, 100),\n        # 5. Stabilizer-dominated regime\n        (0.9, 0.999, 0.001, 0.01, 0.001, 100),\n    ]\n\n    results = []\n    for case in test_cases:\n        beta1, beta2, eta_max, epsilon, g, W = case\n        \n        # The condition for computing errors is |s_t^corr|  0.\n        # s_t^corr = (eta_max * t / W) * (g / (|g| + epsilon)).\n        # For t = 1, this is non-zero only if g is non-zero.\n        # If g is zero, no steps are valid, and outputs must be 0.0.\n        if g == 0.0:\n            results.append([0.0, 0.0, 0.0])\n            continue\n\n        # If beta1=0 and beta2=0, for t=1, the biased and unbiased estimates\n        # are identical, so the error is always zero.\n        if beta1 == 0.0 and beta2 == 0.0:\n            results.append([0.0, 0.0, 0.0])\n            continue\n\n        # Using the derived analytical formula for e_t, vectorized with numpy.\n        # e_t = sgn(g) * [ ((|g|+eps)(1-beta1^t)) / (|g|sqrt(1-beta2^t) + eps) - 1 ]\n        t_steps = np.arange(1, W + 1, dtype=np.float64)\n        \n        abs_g = np.abs(g)\n        sgn_g = np.sign(g)\n        \n        beta1_t = np.power(beta1, t_steps)\n        # Add a small value inside sqrt to prevent issues if 1 - beta2_t becomes slightly negative\n        # due to precision, though beta2  1 should prevent this.\n        beta2_t = np.power(beta2, t_steps)\n        sqrt_term = np.sqrt(1.0 - beta2_t)\n\n        numerator_factor = (abs_g + epsilon) * (1.0 - beta1_t)\n        denominator_factor = abs_g * sqrt_term + epsilon\n        \n        # All steps are valid as g != 0\n        e_t_values = sgn_g * (numerator_factor / denominator_factor - 1.0)\n        \n        e_max = float(np.max(e_t_values))\n        e_min = float(np.min(e_t_values))\n        e_w = float(e_t_values[-1])\n        \n        results.append([e_max, e_min, e_w])\n\n    # Format the final output string exactly as specified, without extra spaces.\n    string_results = []\n    for res in results:\n        string_results.append(f\"[{res[0]},{res[1]},{res[2]}]\")\n    \n    final_output = f\"[{','.join(string_results)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "3096510"}, {"introduction": "理论知识的最终目的是指导实践。这个练习将我们带入一个更真实的场景，探讨一个在应用中至关重要的问题：是否应该对所有类型的参数（例如权重和偏置）都施加权重衰减？通过在一个精心设计的卷积神经网络上进行对比实验，你将验证“不对偏置项进行衰减”这一常用技巧的有效性，并从贝叶斯先验的视角解释其背后的科学原理 [@problem_id:3096544]。", "problem": "要求您实现并分析一个最小化的、完全确定性的实验，以分离解耦权重衰减在卷积神经网络中对不同类型参数的影响。其目标是在一个简单且可复现的环境中证明，当数据分布需要非零偏置时，将偏置参数从衰减中排除而对卷积核进行衰减可以提高测试准确率，并通过涉及$L_2$先验的贝叶斯解释来说明这一观察结果。\n\n您必须编写一个完整、可运行的程序，该程序：\n- 实现一个简易的一维卷积分类器，该分类器包含一个长度为$k$的滤波器，以步长$1$在valid模式下应用，然后进行平均化和一个用于二元分类的sigmoid输出。对于输入向量 $x \\in \\mathbb{R}^{L}$，设有效位置的数量为 $M = L - k + 1$。特征向量 $f(x) \\in \\mathbb{R}^{k}$ 定义为\n$$\nf_i(x) = \\frac{1}{M} \\sum_{j=0}^{M-1} x_{j+i}, \\quad \\text{for } i \\in \\{0,1,\\dots,k-1\\}.\n$$\n使用卷积核权重 $w \\in \\mathbb{R}^{k}$ 和标量偏置 $b \\in \\mathbb{R}$，logit为 $z(x) = w^\\top f(x) + b$，预测值为 $\\sigma(z(x))$，其中 $\\sigma(u) = \\frac{1}{1 + e^{-u}}$。\n- 使用带解耦权重衰减的自适应矩估计 (AdamW) 训练模型，一次对$w$和$b$都应用衰减，另一次仅对$w$应用衰减。使用二元交叉熵作为目标函数。您必须实现与AdamW一致的解耦权重衰减；不要将衰减耦合到数据梯度中。\n- 在同一个测试集上评估两种训练方案的测试准确率，并报告其差异。\n\n数据集是合成的，必须按如下方式生成。对于指定的类别相关基线 $(\\mu_0,\\mu_1)$、序列长度 $L$、噪声标准差 $\\sigma$ 和样本大小 $N$，通过采样类别标签 $y \\in \\{0,1\\}$，设置基线 $m_y \\in \\{\\mu_0,\\mu_1\\}$，并抽取\n$$\nx = m_y \\cdot \\mathbf{1}_L + \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, \\sigma^2 I_L),\n$$\n来生成输入 $x \\in \\mathbb{R}^{L}$，其中 $\\mathbf{1}_L$ 是 $\\mathbb{R}^{L}$ 中的全1向量。除非另有规定，标签 $y$ 是均匀随机抽取的。训练损失是训练集上二元交叉熵的经验均值。\n\n在训练中对所有情况使用单一的超参数配置，并在所有测试案例中保持一致：\n- 学习率 $\\alpha$ 固定为您认为合理的正标量，并在所有测试案例中保持不变。\n- 一阶和二阶矩系数 $(\\beta_1,\\beta_2)$ 在所有测试案例中保持不变。\n- 周期数 $T$ 在所有测试案例中保持不变。\n- 数值稳定性参数 $\\varepsilon$ 在所有测试案例中保持不变。\n\n您必须构建四个测试案例，共同组成下方的测试套件。对于每个案例，您必须使用指定的种子生成独立的训练集和测试集。除了偏置$b$是否被衰减这一点外，保持训练和评估过程完全相同。\n\n测试套件规范：\n- 案例 1（理想情况，非对称均值，中等衰减）：$(L,k,N_{\\text{train}},N_{\\text{test}}) = (16,3,256,512)$，$(\\mu_0,\\mu_1) = (0.2, 1.2)$，$\\sigma = 0.3$，权重衰减 $\\lambda = 0.05$，训练随机种子 $42$，测试随机种子 $1042$。\n- 案例 2（边界情况，零衰减）：与案例1相同，除了 $\\lambda = 0.0$，训练随机种子 $43$，测试随机种子 $1043$。\n- 案例 3（边缘情况，强衰减）：与案例1相同，除了 $\\lambda = 0.5$，训练随机种子 $44$，测试随机种子 $1044$。\n- 案例 4（对照组，均值关于零对称）：$(L,k,N_{\\text{train}},N_{\\text{test}}) = (16,3,256,512)$，$(\\mu_0,\\mu_1) = (-0.6, 0.6)$，$\\sigma = 0.3$，权重衰减 $\\lambda = 0.1$，训练随机种子 $45$，测试随机种子 $1045$。\n\n计算和输出内容：\n- 对于每个案例 $c \\in \\{1,2,3,4\\}$，训练两个模型：一个对$w$和$b$都进行衰减，另一个仅对$w$进行衰减。在相应的测试集上评估两种方案下的测试准确率，并计算差值\n$$\n\\Delta_c = \\text{Acc}_{\\text{no-bias-decay}} - \\text{Acc}_{\\text{with-bias-decay}}.\n$$\n- 您的程序必须生成一行包含列表 $[\\Delta_1,\\Delta_2,\\Delta_3,\\Delta_4]$ 的内容，每个值都精确四舍五入到小数点后三位。\n\n科学依据要求：\n- 您在解决方案中的推理必须从二元交叉熵、logistic函数以及$L_2$惩罚对应于零均值高斯先验的最大后验 (MAP) 估计的观点开始。不要在问题陈述中声明或依赖AdamW的任何更新公式；而是使用解耦权重衰减在代码中直接实现它。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果；例如：$[\\Delta_1,\\Delta_2,\\Delta_3,\\Delta_4]$。", "solution": "该问题要求实现并分析解耦权重衰减，特别是它在简单神经网络中对权重和偏置的差异化应用。我们需要证明，当数据的潜在分布需要一个非零的最优偏置时，将偏置参数从权重衰减中排除是有利的。\n\n分析从模型正则化的贝叶斯概率论视角开始。在监督学习的背景下，我们的目标是找到能最好地解释数据 $D$ 的模型参数 $\\theta$。这通常被构建为最大后验 (MAP) 估计，我们寻求最大化给定数据下参数的后验概率 $P(\\theta|D)$。根据贝叶斯定理，这等价于最小化负对数后验：\n$$\n\\theta_{\\text{MAP}} = \\arg\\min_{\\theta} [-\\log P(D|\\theta) - \\log P(\\theta)]\n$$\n$-\\log P(D|\\theta)$ 项是数据的负对数似然，它对应于损失函数。对于指定的二元分类任务，模型输出是一个概率 $p = \\sigma(z)$，其中 $\\sigma(\\cdot)$ 是logistic sigmoid函数，z是logit。对于带标签 $y \\in \\{0, 1\\}$ 的单个数据点 $(x, y)$，其似然由伯努利分布给出，$P(y|x, \\theta) = p^y(1-p)^{1-y}$。因此，单个样本的负对数似然是：\n$$\n-\\log P(y|x, \\theta) = -[y \\log(p) + (1-y)\\log(1-p)]\n$$\n这正是二元交叉熵损失函数。总的负对数似然是所有训练样本上该损失的总和。\n\n第二项 $-\\log P(\\theta)$ 来自于参数的先验分布。这个先验编码了我们在观察任何数据之前对参数的信念。一个常见的选择是假设参数可能很小并且以零为中心。这种信念可以通过对每个参数 $\\theta_i$ 施加一个独立的、零均值的高斯先验来形式化：\n$$\nP(\\theta_i) \\propto \\exp\\left(-\\frac{\\lambda}{2}\\theta_i^2\\right)\n$$\n对于整个参数向量 $\\theta$，相应的负对数先验变为：\n$$\n-\\log P(\\theta) = \\frac{\\lambda}{2} \\sum_i \\theta_i^2 + \\text{const} = \\frac{\\lambda}{2} \\|\\theta\\|_2^2 + \\text{const}\n$$\n这一项是 $L_2$ 正则化惩罚项。因此，最小化损失函数与该惩罚项之和等价于使用零均值高斯先验的MAP估计。\n\n在传统的梯度下降中，这个 $L_2$ 惩罚项被加到损失函数中，其梯度 $\\lambda\\theta$ 被加到数据损失的梯度中。对于像Adam这样的自适应优化器，这种正则化梯度与数据梯度的“耦合”是有问题的，因为自适应缩放（来自矩量项）会以一种复杂的、依赖于参数的方式重新缩放正则化效果。解耦权重衰减，由AdamW推广，通过将权重衰减更新 $\\theta \\leftarrow \\theta - \\eta \\lambda \\theta$ 与基于梯度的自适应更新分开应用，恢复了 $L_2$ 正则化的初衷。\n\n问题的核心在于批判性地评估零均值高斯先验对不同类型参数的有效性。对于权重（$w$），它们调节特征之间的相互作用，假设它们很小并以零为中心通常是一个合理的默认设置。然而，对于偏置参数（$b$），这个假设可能是有缺陷的。偏置项的功能是移动神经元的输出，有效地将激活函数中心对准其输入的分布。因此，最优偏置直接取决于它接收到的特征的均值。\n\n在这个问题中，输入数据生成为 $x = m_y \\cdot \\mathbf{1}_L + \\epsilon$，其中 $m_y$ 是类别条件均值。特征向量 $f(x)$ 的构造使得其每个分量的期望值都是类别均值：$E[f_i(x)|y] = m_y$。logit是 $z(x) = w^\\top f(x) + b$。其期望值为：\n$$\nE[z(x)|y] = w^\\top E[f(x)|y] + b = w^\\top (m_y \\mathbf{1}_k) + b = m_y \\left(\\sum_i w_i\\right) + b\n$$\n考虑案例1，其均值非对称 $(\\mu_0, \\mu_1) = (0.2, 1.2)$。两个类别的均值都是正的。为了正确分类输入，模型必须学习到参数，使得平均而言，$E[z(x)|y=0]  0$ 且 $E[z(x)|y=1] > 0$。这要求 $0.2(\\sum w_i) + b  0$ 和 $1.2(\\sum w_i) + b > 0$。显而易见，最优偏置 $b$ 必须为非零值，以适当地移动决策边界来适应数据中的正向偏移。对 $b$ 应用权重衰减会施加一个将其拉向零的惩罚，这直接与优化目标冲突。这应该会导致较低的测试准确率。\n\n相反，在均值对称的案例4中，$(\\mu_0, \\mu_1) = (-0.6, 0.6)$，数据以零为中心。最优解可能有一个接近于零的偏置 $b$。在这种情况下，对偏置应用权重衰减没有害处，并且可能提供轻微的正则化效果。因此，衰减和不衰减偏置之间的性能差异应该可以忽略不计。\n\n案例2，权重衰减为零 $(\\lambda=0)$，作为一个对照组。两种训练方案完全相同，所以准确率差异 $\\Delta_2$ 必须为零。案例3使用一个强的衰减因子，这应该会放大在非对称数据设置中不适当地衰减偏置所带来的负面效应。\n\n因此，我们假设 $\\Delta_c = \\text{Acc}_{\\text{no-bias-decay}} - \\text{Acc}_{\\text{with-bias-decay}}$ 在案例1和3中将显著为正，在案例4中约等于零，在案例2中精确为零。本实验旨在通过一个直接的、可复现的模拟来证实这一点。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and runs the complete experiment to analyze decoupled weight decay.\n    \"\"\"\n    \n    # --- Hyperparameters ---\n    # Fixed for all test cases as per the problem description.\n    ALPHA = 0.01  # Learning rate\n    BETA_1 = 0.9\n    BETA_2 = 0.999\n    EPSILON = 1e-8\n    EPOCHS = 100  # Number of training epochs\n\n    def generate_data(n_samples, l_seq, mu0, mu1, sigma_noise, seed):\n        \"\"\"Generates synthetic data according to the problem specification.\"\"\"\n        rng = np.random.RandomState(seed)\n        labels = rng.randint(0, 2, size=(n_samples, 1))\n        means = np.where(labels == 0, mu0, mu1)\n        # Ensure means array is broadcastable to data shape\n        means = means.reshape(-1, 1)\n        noise = rng.randn(n_samples, l_seq) * sigma_noise\n        data = means * np.ones((1, l_seq)) + noise\n        return data, labels\n\n    def get_features(X, k):\n        \"\"\"Computes the feature vector f(x) for each sample in X.\"\"\"\n        N, L = X.shape\n        M = L - k + 1\n        features = np.zeros((N, k))\n        for i in range(k):\n            features[:, i] = np.mean(X[:, i:i + M], axis=1)\n        return features\n\n    def train(X_train, y_train, k, weight_decay, decay_bias, seed):\n        \"\"\"Trains the model using AdamW, as specified in the original paper.\"\"\"\n        rng = np.random.RandomState(seed)\n        # Initialize parameters\n        w = rng.randn(k, 1) * 0.01\n        b = 0.0\n\n        # Adam moment estimates\n        m_w, v_w = np.zeros_like(w), np.zeros_like(w)\n        m_b, v_b = 0.0, 0.0\n\n        num_samples = X_train.shape[0]\n        F_train = get_features(X_train, k)\n\n        for t in range(1, EPOCHS + 1):\n            # Forward pass (at w_{t-1}, b_{t-1})\n            z = F_train @ w + b\n            p = 1.0 / (1.0 + np.exp(-z))  # Sigmoid activation\n\n            # Backward pass (gradient of the loss)\n            grad_z = p - y_train\n            grad_w = (F_train.T @ grad_z) / num_samples\n            grad_b = np.mean(grad_z)\n\n            # --- Adam Moment Updates ---\n            m_w = BETA_1 * m_w + (1 - BETA_1) * grad_w\n            m_b = BETA_1 * m_b + (1 - BETA_1) * grad_b\n            \n            v_w = BETA_2 * v_w + (1 - BETA_2) * (grad_w ** 2)\n            v_b = BETA_2 * v_b + (1 - BETA_2) * (grad_b ** 2)\n\n            # Bias-corrected estimates\n            m_w_hat = m_w / (1 - BETA_1 ** t)\n            m_b_hat = m_b / (1 - BETA_1 ** t)\n            v_w_hat = v_w / (1 - BETA_2 ** t)\n            v_b_hat = v_b / (1 - BETA_2 ** t)\n            \n            # --- Parameter Update ---\n            # Update from Adam step\n            w -= ALPHA * m_w_hat / (np.sqrt(v_w_hat) + EPSILON)\n            b -= ALPHA * m_b_hat / (np.sqrt(v_b_hat) + EPSILON)\n            \n            # Update from decoupled weight decay\n            w -= ALPHA * weight_decay * w\n            if decay_bias:\n                b -= ALPHA * weight_decay * b\n        \n        return w, b\n\n    def evaluate(X_test, y_test, w, b, k):\n        \"\"\"Evaluates model accuracy on the test set.\"\"\"\n        F_test = get_features(X_test, k)\n        z = F_test @ w + b\n        predictions = (z > 0).astype(int)\n        accuracy = np.mean(predictions == y_test)\n        return accuracy\n\n    test_cases = [\n        # Case 1 (happy path, asymmetric means, moderate decay)\n        {'L': 16, 'k': 3, 'N_train': 256, 'N_test': 512, 'mu0': 0.2, 'mu1': 1.2, 'sigma': 0.3, 'lambda': 0.05, 'train_seed': 42, 'test_seed': 1042},\n        # Case 2 (boundary, zero decay)\n        {'L': 16, 'k': 3, 'N_train': 256, 'N_test': 512, 'mu0': 0.2, 'mu1': 1.2, 'sigma': 0.3, 'lambda': 0.0, 'train_seed': 43, 'test_seed': 1043},\n        # Case 3 (edge, strong decay)\n        {'L': 16, 'k': 3, 'N_train': 256, 'N_test': 512, 'mu0': 0.2, 'mu1': 1.2, 'sigma': 0.3, 'lambda': 0.5, 'train_seed': 44, 'test_seed': 1044},\n        # Case 4 (control, symmetric means around zero)\n        {'L': 16, 'k': 3, 'N_train': 256, 'N_test': 512, 'mu0': -0.6, 'mu1': 0.6, 'sigma': 0.3, 'lambda': 0.1, 'train_seed': 45, 'test_seed': 1045},\n    ]\n\n    delta_results = []\n    for case in test_cases:\n        # Generate data\n        X_train, y_train = generate_data(case['N_train'], case['L'], case['mu0'], case['mu1'], case['sigma'], case['train_seed'])\n        X_test, y_test = generate_data(case['N_test'], case['L'], case['mu0'], case['mu1'], case['sigma'], case['test_seed'])\n\n        # --- Regime 1: Decay applied to weights and bias ---\n        w_decay, b_decay = train(X_train, y_train, case['k'], case['lambda'], decay_bias=True, seed=case['train_seed'])\n        acc_with_bias_decay = evaluate(X_test, y_test, w_decay, b_decay, case['k'])\n\n        # --- Regime 2: Decay applied to weights only ---\n        w_nodecay, b_nodecay = train(X_train, y_train, case['k'], case['lambda'], decay_bias=False, seed=case['train_seed'])\n        acc_no_bias_decay = evaluate(X_test, y_test, w_nodecay, b_nodecay, case['k'])\n\n        # Compute and store the difference\n        delta = acc_no_bias_decay - acc_with_bias_decay\n        delta_results.append(delta)\n\n    # Format the results as specified\n    formatted_results = [f\"{r:.3f}\" for r in delta_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3096544"}]}