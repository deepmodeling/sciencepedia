{"hands_on_practices": [{"introduction": "池化操作的定义看似简单，但其在边界上的行为（即填充策略）对网络输出有着不可忽视的影响。本练习通过一个精心设计的“对抗性”输入，引导你动手计算并比较不同填充方案（如零填充和反射填充）下的池化结果。通过这个过程，你将深刻理解为何在实践中必须仔细考虑这些实现细节。[@problem_id:3163871]", "problem": "给定一个一维 (1D) 特征图，它被特意设计用来利用不同填充方案下的边界效应。考虑一个长度为 $n = 4$ 的输入向量 $x = [-100, -50, 3, 2]$。一个核大小为 $k=3$、步幅为 $s=2$ 且两侧对称填充为 $p=1$ 的池化层被应用于该向量。比较两种填充方案：\n\n- 零填充：对于任何在有效范围 $\\{0, 1, \\dots, n-1\\}$ 之外的索引 $j$，填充后的信号值定义为 $\\tilde{x}_j = 0$。\n- 反射填充（无边缘复制）：对于任何在有效范围之外的索引 $j$，并且给定 $p=1$，池化窗口中可能出现的唯一超出范围的索引是左侧的 $j=-1$ 和右侧的 $j=n$。将反射值定义为 $\\tilde{x}_{-1} = x_1$ 和 $\\tilde{x}_{n} = x_{n-2}$。对于范围内的索引，$\\tilde{x}_j = x_j$。\n\n仅使用最大池化和平均池化在填充信号上以大小为 $k$、步幅为 $s$ 的滑动窗口进行操作的核心定义，来确定在零填充和反射填充下的池化输出。然后，判断对于这个对抗性输入，以下关于输出的陈述哪些是正确的：\n\nA. 在最大池化下，零填充的第一个输出大于反射填充的第一个输出。\n\nB. 在平均池化下，反射填充的第一个输出大于零填充的第一个输出。\n\nC. 对于两种池化类型，零填充和反射填充的第二个输出是相同的。\n\nD. 第一个输出的差值（零填充减去反射填充）的绝对值，在平均池化下比在最大池化下更大。\n\n选择所有适用的选项。你的选择中不应包含计算过程；应基于对池化和填充定义的原理推理来做出选择。", "solution": "### 问题验证\n\n**步骤 1：提取已知条件**\n\n问题陈述提供了以下信息：\n- 输入向量：$x = [-100, -50, 3, 2]$\n- 输入向量长度：$n = 4$\n- 核大小：$k = 3$\n- 步幅：$s = 2$\n- 对称填充：$p = 1$\n- 零填充定义：对于任何在有效范围 $\\{0, 1, \\dots, n-1\\}$ 之外的索引 $j$，填充后的信号值定义为 $\\tilde{x}_j = 0$。\n- 反射填充定义：对于任何在有效范围之外的索引 $j$，且 $p=1$ 时，填充值定义为 $\\tilde{x}_{-1} = x_1$ 和 $\\tilde{x}_{n} = x_{n-2}$。对于范围内的索引，$\\tilde{x}_j = x_j$。\n- 问题：评估关于两种填充方案下池化输出比较的四个陈述（A、B、C、D）的正确性。\n\n**步骤 2：使用提取的已知条件进行验证**\n\n根据既定标准对问题进行验证。\n- **科学依据：** 该问题在深度学习领域，特别是在卷积神经网络机制方面，有充分的理论基础。最大池化、平均池化和填充是标准的、基本的操作。所描述的“反射填充”是一种特殊的、非标准的变体，但其定义在数学上是精确且无歧义的（$\\tilde{x}_{-1} = x_1$, $\\tilde{x}_{n} = x_{n-2}$），这使其在问题所限定的范围内成为一个有效的构造。它没有违反任何数学或科学定律。\n- **适定性：** 计算输出所需的所有参数均已提供：输入向量 $x$、其长度 $n$、核大小 $k$、步幅 $s$ 以及填充大小 $p$。两种填充方案的规则都已明确定义。这种设置确保了可以通过直接计算确定一个唯一且稳定的解。\n- **客观性：** 该问题以客观的数学语言表述。它要求基于固定定义对量进行计算和比较。术语“对抗性输入”是对输入性质的描述，但不会为所需的计算引入主观性。\n\n**步骤 3：结论与行动**\n\n问题陈述是有效的。它是自洽的、科学上合理的且适定的。可以继续进行解题推导。\n\n### 解题推导\n\n池化操作的输出大小由公式 $L_{out} = \\lfloor \\frac{n + 2p - k}{s} \\rfloor + 1$ 给出。\n代入给定值：\n$$L_{out} = \\left\\lfloor \\frac{4 + 2(1) - 3}{2} \\right\\rfloor + 1 = \\left\\lfloor \\frac{3}{2} \\right\\rfloor + 1 = 1 + 1 = 2$$\n因此，每种情况下的输出向量长度都为 $2$。设两个输出值表示为 $y_0$ 和 $y_1$。\n\n池化操作将一个大小为 $k=3$、步幅为 $s=2$ 的滑动窗口应用于填充后的输入。在填充为 $p=1$ 的情况下，填充后的信号有效索引范围为 $-1$ 到 $n-1+p = 4$。\n- 第一个窗口（用于 $y_0$）从索引 $-p = -1$ 开始，覆盖索引 $\\{-1, 0, 1\\}$。\n- 第二个窗口（用于 $y_1$）从索引 $-p+s = -1+2 = 1$ 开始，覆盖索引 $\\{1, 2, 3\\}$。\n\n输入向量为 $x = [x_0, x_1, x_2, x_3] = [-100, -50, 3, 2]$。\n\n#### 1. 零填充\n\n在零填充下，任何对原始输入范围 $\\{0, 1, 2, 3\\}$ 之外的访问都会得到值 $0$。\n\n- **第一个窗口（用于 $y_0$）：**\n该窗口覆盖填充后的值 $\\{\\tilde{x}_{-1}, \\tilde{x}_0, \\tilde{x}_1\\}$。在零填充下，这些值为 $\\{0, x_0, x_1\\} = \\{0, -100, -50\\}$。\n- 最大池化：$y_{0, \\text{zero}}^{\\text{max}} = \\max(0, -100, -50) = 0$。\n- 平均池化：$y_{0, \\text{zero}}^{\\text{avg}} = \\frac{0 + (-100) + (-50)}{3} = \\frac{-150}{3} = -50$。\n\n- **第二个窗口（用于 $y_1$）：**\n该窗口覆盖填充后的值 $\\{\\tilde{x}_1, \\tilde{x}_2, \\tilde{x}_3\\}$。这些索引都在原始输入的范围内，所以这些值为 $\\{x_1, x_2, x_3\\} = \\{-50, 3, 2\\}$。\n- 最大池化：$y_{1, \\text{zero}}^{\\text{max}} = \\max(-50, 3, 2) = 3$。\n- 平均池化：$y_{1, \\text{zero}}^{\\text{avg}} = \\frac{-50 + 3 + 2}{3} = \\frac{-45}{3} = -15$。\n\n#### 2. 反射填充\n\n在指定的反射填充下，$\\tilde{x}_{-1} = x_1$ 且 $\\tilde{x}_4 = x_2$。\n\n- **第一个窗口（用于 $y_0$）：**\n该窗口覆盖填充后的值 $\\{\\tilde{x}_{-1}, \\tilde{x}_0, \\tilde{x}_1\\}$。在反射填充下，这些值为 $\\{x_1, x_0, x_1\\} = \\{-50, -100, -50\\}$。\n- 最大池化：$y_{0, \\text{reflect}}^{\\text{max}} = \\max(-50, -100, -50) = -50$。\n- 平均池化：$y_{0, \\text{reflect}}^{\\text{avg}} = \\frac{-50 + (-100) + (-50)}{3} = \\frac{-200}{3}$。\n\n- **第二个窗口（用于 $y_1$）：**\n该窗口覆盖值 $\\{\\tilde{x}_1, \\tilde{x}_2, \\tilde{x}_3\\}$。这些索引都在原始输入的范围内，所以这些值为 $\\{x_1, x_2, x_3\\} = \\{-50, 3, 2\\}$。填充方案对这个窗口没有影响。\n- 最大池化：$y_{1, \\text{reflect}}^{\\text{max}} = \\max(-50, 3, 2) = 3$。\n- 平均池化：$y_{1, \\text{reflect}}^{\\text{avg}} = \\frac{-50 + 3 + 2}{3} = \\frac{-45}{3} = -15$。\n\n### 逐项分析\n\n**A. 在最大池化下，零填充的第一个输出大于反射填充的第一个输出。**\n- 根据我们的计算，零填充下的第一个最大池化输出为 $y_{0, \\text{zero}}^{\\text{max}} = 0$。\n- 反射填充下的第一个最大池化输出为 $y_{0, \\text{reflect}}^{\\text{max}} = -50$。\n- 比较这两个值：$0 > -50$。\n- 该陈述是**正确的**。\n\n**B. 在平均池化下，反射填充的第一个输出大于零填充的第一个输出。**\n- 根据我们的计算，零填充下的第一个平均池化输出为 $y_{0, \\text{zero}}^{\\text{avg}} = -50$。\n- 反射填充下的第一个平均池化输出为 $y_{0, \\text{reflect}}^{\\text{avg}} = -\\frac{200}{3} \\approx -66.67$。\n- 比较这两个值：$-50 > -\\frac{200}{3}$。因此，零填充下的输出更大。\n- 该陈述主张相反的情况。\n- 该陈述是**不正确的**。\n\n**C. 对于两种池化类型，零填充和反射填充的第二个输出是相同的。**\n- 第二个池化窗口覆盖索引 $\\{1, 2, 3\\}$。这些索引对应于原始输入向量的元素 $x_1, x_2, x_3$。\n- 由于此窗口不包含任何填充元素，其内容与填充方案无关。\n- 对于零填充和反射填充，该窗口内的值均为 $\\{x_1, x_2, x_3\\} = \\{-50, 3, 2\\}$。\n- 因此，将任何确定性函数（如最大池化或平均池化）应用于这组相同的值，必然会产生相同的结果。\n- 我们的计算证实了这一点：\n  - $y_{1, \\text{zero}}^{\\text{max}} = 3$ 且 $y_{1, \\text{reflect}}^{\\text{max}} = 3$。\n  - $y_{1, \\text{zero}}^{\\text{avg}} = -15$ 且 $y_{1, \\text{reflect}}^{\\text{avg}} = -15$。\n- 该陈述是**正确的**。\n\n**D. 第一个输出的差值（零填充减去反射填充）的绝对值，在平均池化下比在最大池化下更大。**\n- 设最大池化的差值为 $\\Delta_{\\text{max}} = y_{0, \\text{zero}}^{\\text{max}} - y_{0, \\text{reflect}}^{\\text{max}} = 0 - (-50) = 50$。其绝对值为 $|\\Delta_{\\text{max}}| = 50$。\n- 设平均池化的差值为 $\\Delta_{\\text{avg}} = y_{0, \\text{zero}}^{\\text{avg}} - y_{0, \\text{reflect}}^{\\text{avg}} = -50 - (-\\frac{200}{3}) = -50 + \\frac{200}{3} = \\frac{-150 + 200}{3} = \\frac{50}{3}$。其绝对值为 $|\\Delta_{\\text{avg}}| = \\frac{50}{3}$。\n- 比较绝对值：$|\\Delta_{\\text{max}}| = 50$ 且 $|\\Delta_{\\text{avg}}| = \\frac{50}{3} \\approx 16.67$。\n- 显然，$50 > \\frac{50}{3}$。最大池化的差值绝对值更大。\n- 该陈述主张相反的情况。\n- 该陈述是**不正确的**。", "answer": "$$\\boxed{AC}$$", "id": "3163871"}, {"introduction": "在理解了池化的基本机制之后，我们可以进一步探讨其理论性质，例如它对微小输入扰动的鲁棒性。本练习要求你从数学上推导，在有界扰动（以 $\\ell_{\\infty}$ 范数衡量）下，最大池化和平均池化的输出可能发生的最坏情况变化。这个思想实验揭示了这两种常用池化方法在对抗性攻击面前的一个重要特性。[@problem_id:3163869]", "problem": "考虑一个由向量 $x \\in \\mathbb{R}^{n}$ 表示的单个池化窗口，其中 $n \\in \\mathbb{N}$。将此窗口上的最大池化算子定义为 $f_{\\max}(x) = \\max_{1 \\leq i \\leq n} x_{i}$，平均池化算子定义为 $f_{\\mathrm{avg}}(x) = \\frac{1}{n}\\sum_{i=1}^{n} x_{i}$。允许对抗方对窗口添加一个扰动 $\\eta \\in \\mathbb{R}^{n}$，产生 $x + \\eta$，该扰动受预算约束 $\\|\\eta\\|_{\\infty} \\leq \\epsilon$ 的限制，其中 $\\epsilon  0$ 且 $\\|\\eta\\|_{\\infty} = \\max_{1 \\leq i \\leq n} | \\eta_{i} |$。仅从这些定义出发，推导每个算子池化值的确切最坏情况绝对变化，即计算\n$$\\Delta_{\\max} = \\sup_{\\|\\eta\\|_{\\infty} \\leq \\epsilon} \\left| f_{\\max}(x + \\eta) - f_{\\max}(x) \\right| \\quad \\text{和} \\quad \\Delta_{\\mathrm{avg}} = \\sup_{\\|\\eta\\|_{\\infty} \\leq \\epsilon} \\left| f_{\\mathrm{avg}}(x + \\eta) - f_{\\mathrm{avg}}(x) \\right|.$$\n将最终答案表示为包含 $\\Delta_{\\max}$ 和 $\\Delta_{\\mathrm{avg}}$ 的单个行向量，以 $\\epsilon$ 和 $n$ 的函数闭式形式表示。不需要进行数值舍入。最终答案中不应包含单位。", "solution": "我们从池化算子的定义和 $\\ell_{\\infty}$ 范数约束开始。目标是对于一个固定的但任意的 $x \\in \\mathbb{R}^{n}$，计算\n$$\\Delta_{\\max} = \\sup_{\\|\\eta\\|_{\\infty} \\leq \\epsilon} \\left| \\max_{1 \\leq i \\leq n} (x_{i} + \\eta_{i}) - \\max_{1 \\leq i \\leq n} x_{i} \\right|,$$\n和\n$$\\Delta_{\\mathrm{avg}} = \\sup_{\\|\\eta\\|_{\\infty} \\leq \\epsilon} \\left| \\frac{1}{n} \\sum_{i=1}^{n} (x_{i} + \\eta_{i}) - \\frac{1}{n} \\sum_{i=1}^{n} x_{i} \\right| = \\sup_{\\|\\eta\\|_{\\infty} \\leq \\epsilon} \\left| \\frac{1}{n} \\sum_{i=1}^{n} \\eta_{i} \\right|.$$\n\n最大池化情况。令 $m = \\max_{1 \\leq i \\leq n} x_{i}$。对于任何满足 $\\|\\eta\\|_{\\infty} \\leq \\epsilon$ 的 $\\eta$，我们对每个 $i$ 都有 $x_{i} + \\eta_{i} \\leq x_{i} + \\epsilon$。因此，\n$$\\max_{1 \\leq i \\leq n} (x_{i} + \\eta_{i}) \\leq \\max_{1 \\leq i \\leq n} (x_{i} + \\epsilon) = \\left( \\max_{1 \\leq i \\leq n} x_{i} \\right) + \\epsilon = m + \\epsilon.$$\n类似地，由于对每个 $i$ 都有 $x_{i} + \\eta_{i} \\geq x_{i} - \\epsilon$，\n$$\\max_{1 \\leq i \\leq n} (x_{i} + \\eta_{i}) \\geq \\max_{1 \\leq i \\leq n} (x_{i} - \\epsilon) = m - \\epsilon.$$\n结合这些界限可得\n$$| \\max_{1 \\leq i \\leq n} (x_{i} + \\eta_{i}) - m | \\leq \\epsilon.$$\n因此 $\\Delta_{\\max} \\leq \\epsilon$。为了证明其紧密性，我们通过对所有 $i \\in \\{1,\\dots,n\\}$ 设置 $\\eta_{i} = \\epsilon$ 来构造 $\\eta$。那么 $\\|\\eta\\|_{\\infty} = \\epsilon$ 并且\n$$\\max_{1 \\leq i \\leq n} (x_{i} + \\eta_{i}) = \\max_{1 \\leq i \\leq n} (x_{i} + \\epsilon) = m + \\epsilon,$$\n这实现了 $\\epsilon$ 的绝对变化。同样地，对所有 $i$ 设置 $\\eta_{i} = -\\epsilon$ 会实现 $\\epsilon$ 的减小。因此，\n$$\\Delta_{\\max} = \\epsilon.$$\n\n平均池化情况。我们有\n$$\\Delta_{\\mathrm{avg}} = \\sup_{\\|\\eta\\|_{\\infty} \\leq \\epsilon} \\left| \\frac{1}{n} \\sum_{i=1}^{n} \\eta_{i} \\right|.$$\n根据三角不等式和对所有 $i$ 的约束 $|\\eta_{i}| \\leq \\epsilon$，\n$$\\left| \\frac{1}{n} \\sum_{i=1}^{n} \\eta_{i} \\right| \\leq \\frac{1}{n} \\sum_{i=1}^{n} |\\eta_{i}| \\leq \\frac{1}{n} \\sum_{i=1}^{n} \\epsilon = \\epsilon.$$\n因此 $\\Delta_{\\mathrm{avg}} \\leq \\epsilon$。这个界是紧密的：对所有 $i$ 选择 $\\eta_{i} = \\epsilon$，这满足 $\\|\\eta\\|_{\\infty} = \\epsilon$ 并得出\n$$\\left| \\frac{1}{n} \\sum_{i=1}^{n} \\eta_{i} \\right| = \\left| \\frac{1}{n} \\cdot n \\epsilon \\right| = \\epsilon.$$\n类似地，对所有 $i$ 选择 $\\eta_{i} = -\\epsilon$ 会产生 $\\epsilon$ 的减小。因此，\n$$\\Delta_{\\mathrm{avg}} = \\epsilon.$$\n\n结论。对于任何 $x \\in \\mathbb{R}^{n}$ 和任何 $\\epsilon > 0$，在半径为 $\\epsilon$ 的 $\\ell_{\\infty}$ 有界扰动下，最大池化和平均池化特征的最坏情况绝对变化均等于 $\\epsilon$。因此，所要求的行向量是\n$$\\begin{pmatrix} \\Delta_{\\max}  \\Delta_{\\mathrm{avg}} \\end{pmatrix} = \\begin{pmatrix} \\epsilon  \\epsilon \\end{pmatrix}.$$", "answer": "$$\\boxed{\\begin{pmatrix}\\epsilon  \\epsilon\\end{pmatrix}}$$", "id": "3163869"}, {"introduction": "最大池化和平均池化看似是两种截然不同的操作，但它们能否被一个统一的框架所描述？本练习引入了对数-和-指数（Log-Sum-Exp, LSE）池化函数，它不仅是最大池化的一个平滑、可微的近似，而且其行为可以通过一个“温度”参数 $\\tau$ 在最大池化和平均池化之间调节。通过推导其极限行为和梯度，你将深入理解池化操作背后的深刻数学联系，以及它与Softmax函数的内在关系。[@problem_id:3163845]", "problem": "考虑一个分量为 $\\{x_{i}\\}_{i=1}^{n}$ 的向量 $x \\in \\mathbb{R}^{n}$，定义对数-总和-指数（Log-Sum-Exp, LSE）池化为\n$$\nP_{\\tau}(x) \\;=\\; \\tau \\,\\log\\!\\left(\\sum_{i=1}^{n} \\exp\\!\\left(\\frac{x_{i}}{\\tau}\\right)\\right),\n$$\n其中温度参数 $\\tau  0$。最大池化输出 $\\max_{i} x_{i}$，平均池化输出 $\\frac{1}{n}\\sum_{i=1}^{n} x_{i}$。仅使用指数函数和对数函数的定义、它们的基本代数性质（例如 $\\log(ab)=\\log a + \\log b$）以及针对大参数和小参数的标准一阶渐近展开（例如，当 $u \\to 0$ 时，$\\exp(u) = 1 + u + o(u)$ 和当 $u \\to 0$ 时，$\\log(1+u) = u + o(u)$），完成以下任务：\n\n1. 从 $P_{\\tau}(x)$ 的定义出发，推导当 $\\tau \\to 0$ 时 $P_{\\tau}(x)$ 的极限，并解释为什么它与最大池化一致。您的推导必须是合理的，不能使用任何未经证明的简化恒等式。\n\n2. 通过计算当 $\\tau \\to \\infty$ 时 $P_{\\tau}(x) - \\tau \\log n$ 的极限，证明当 $\\tau \\to \\infty$ 时 $P_{\\tau}(x)$ 在一个加性缩放项的范围内逼近平均池化。您的论证必须从给定的定义和经过检验的渐近展开开始。\n\n3. 从 $P_{\\tau}(x)$ 的给定定义和链式法则出发，推导 $P_{\\tau}(x)$ 对单个分量 $x_{j}$ 的梯度，其中 $j$ 是一个固定索引，$j \\in \\{1,\\dots,n\\}$。将结果表示为 $x$ 和 $\\tau$ 的闭式函数。\n\n将所要求的三个结果以解析表达式的形式报告。不需要四舍五入。最终答案必须只包含这三个表达式。", "solution": "问题陈述经核实具有科学依据、问题设定良好且客观。所有必要的定义和条件均已提供，不存在矛盾或模糊之处。这些任务是微积分和极限理论中应用于机器学习相关函数的标准练习。我们将开始解答。\n\nLog-Sum-Exp 函数定义为 $P_{\\tau}(x) = \\tau \\log\\left(\\sum_{i=1}^{n} \\exp\\left(\\frac{x_{i}}{\\tau}\\right)\\right)$。在微积分中，函数 $\\log$ 被解释为自然对数，我们将用 $\\ln$ 表示。\n\n1. 推导当 $\\tau \\to 0^+$ 时的极限（最大池化）\n\n令 $x_{\\max} = \\max_{i \\in \\{1, \\dots, n\\}} x_i$。我们分析当 $\\tau \\to 0^+$ 时 $P_{\\tau}(x)$ 的极限。为了处理参数趋于无穷大的指数项，我们提出对应于最大值的项 $\\exp(x_{\\max}/\\tau)$。\n\n$$\nP_{\\tau}(x) = \\tau \\ln\\left(\\sum_{i=1}^{n} \\exp\\left(\\frac{x_{i}}{\\tau}\\right)\\right)\n$$\n\n我们通过提出 $\\exp(x_{\\max}/\\tau)$ 来重写这个和：\n$$\nP_{\\tau}(x) = \\tau \\ln\\left( \\exp\\left(\\frac{x_{\\max}}{\\tau}\\right) \\sum_{i=1}^{n} \\exp\\left(\\frac{x_{i} - x_{\\max}}{\\tau}\\right) \\right)\n$$\n\n使用性质 $\\ln(ab) = \\ln(a) + \\ln(b)$，我们得到：\n$$\nP_{\\tau}(x) = \\tau \\left[ \\ln\\left(\\exp\\left(\\frac{x_{\\max}}{\\tau}\\right)\\right) + \\ln\\left(\\sum_{i=1}^{n} \\exp\\left(\\frac{x_{i} - x_{\\max}}{\\tau}\\right)\\right) \\right]\n$$\n\n因为 $\\ln(\\exp(u)) = u$，这可以简化为：\n$$\nP_{\\tau}(x) = \\tau \\left[ \\frac{x_{\\max}}{\\tau} + \\ln\\left(\\sum_{i=1}^{n} \\exp\\left(\\frac{x_{i} - x_{\\max}}{\\tau}\\right)\\right) \\right]\n$$\n$$\nP_{\\tau}(x) = x_{\\max} + \\tau \\ln\\left(\\sum_{i=1}^{n} \\exp\\left(\\frac{x_{i} - x_{\\max}}{\\tau}\\right)\\right)\n$$\n\n现在，我们考察当 $\\tau \\to 0^+$ 时对数函数参数中的和。对于每一项 $\\exp\\left(\\frac{x_{i} - x_{\\max}}{\\tau}\\right)$，指数的分子 $(x_i - x_{\\max})$ 是非正的。\n- 如果 $x_i  x_{\\max}$，则 $x_i - x_{\\max}  0$。当 $\\tau \\to 0^+$ 时，参数 $\\frac{x_i - x_{\\max}}{\\tau} \\to -\\infty$，因此 $\\exp\\left(\\frac{x_{i} - x_{\\max}}{\\tau}\\right) \\to 0$。\n- 如果 $x_i = x_{\\max}$，则 $x_i - x_{\\max} = 0$。参数为 $\\frac{0}{\\tau} = 0$，且 $\\exp(0) = 1$。\n\n令 $k$ 为满足 $x_i = x_{\\max}$ 的索引 $i$ 的数量。那么，当 $\\tau \\to 0^+$ 时，该和趋近于这些最大元素的数量：\n$$\n\\lim_{\\tau \\to 0^+} \\sum_{i=1}^{n} \\exp\\left(\\frac{x_{i} - x_{\\max}}{\\tau}\\right) = k\n$$\n其中 $k \\ge 1$。将此代入我们关于 $P_{\\tau}(x)$ 的表达式中：\n$$\n\\lim_{\\tau \\to 0^+} P_{\\tau}(x) = \\lim_{\\tau \\to 0^+} \\left[ x_{\\max} + \\tau \\ln(k) \\right]\n$$\n当 $\\tau \\to 0^+$ 时，项 $\\tau \\ln(k)$ 趋近于 $0$，因为 $\\ln(k)$ 是一个常数。\n$$\n\\lim_{\\tau \\to 0^+} P_{\\tau}(x) = x_{\\max} + 0 = x_{\\max}\n$$\n这个结果，$x_{\\max} = \\max_{i} x_i$，是最大池化的定义。\n\n2. 推导当 $\\tau \\to \\infty$ 时的极限（平均池化）\n\n我们需要计算当 $\\tau \\to \\infty$ 时 $P_{\\tau}(x) - \\tau \\ln n$ 的极限。\n$$\nP_{\\tau}(x) - \\tau \\ln n = \\tau \\ln\\left(\\sum_{i=1}^{n} \\exp\\left(\\frac{x_{i}}{\\tau}\\right)\\right) - \\tau \\ln n\n$$\n使用性质 $\\ln(a) - \\ln(b) = \\ln(a/b)$，我们合并这些项：\n$$\nP_{\\tau}(x) - \\tau \\ln n = \\tau \\ln\\left(\\frac{\\sum_{i=1}^{n} \\exp\\left(\\frac{x_{i}}{\\tau}\\right)}{n}\\right) = \\tau \\ln\\left(\\frac{1}{n} \\sum_{i=1}^{n} \\exp\\left(\\frac{x_{i}}{\\tau}\\right)\\right)\n$$\n当 $\\tau \\to \\infty$ 时，每个指数函数的参数 $u_i = x_i/\\tau$ 趋近于 $0$。因此，我们可以使用指定的当 $u \\to 0$ 时的一阶渐近展开 $\\exp(u) = 1 + u + o(u)$。\n$$\n\\exp\\left(\\frac{x_{i}}{\\tau}\\right) = 1 + \\frac{x_i}{\\tau} + o\\left(\\frac{1}{\\tau}\\right)\n$$\n将此代入对数内的和中：\n$$\n\\frac{1}{n} \\sum_{i=1}^{n} \\left(1 + \\frac{x_i}{\\tau} + o\\left(\\frac{1}{\\tau}\\right)\\right) = \\frac{1}{n} \\left(\\sum_{i=1}^{n} 1 + \\frac{1}{\\tau}\\sum_{i=1}^{n} x_i + \\sum_{i=1}^{n} o\\left(\\frac{1}{\\tau}\\right)\\right)\n$$\n$$\n= \\frac{1}{n} \\left(n + \\frac{1}{\\tau}\\sum_{i=1}^{n} x_i + n \\cdot o\\left(\\frac{1}{\\tau}\\right)\\right) = 1 + \\frac{1}{n\\tau}\\sum_{i=1}^{n} x_i + o\\left(\\frac{1}{\\tau}\\right)\n$$\n现在，将此代回完整的表达式中。令 $v = \\frac{1}{n\\tau}\\sum_{i=1}^{n} x_i + o\\left(\\frac{1}{\\tau}\\right)$。当 $\\tau \\to \\infty$ 时，$v \\to 0$。我们可以使用展开式 $\\ln(1+v) = v + o(v)$。\n$$\n\\lim_{\\tau \\to \\infty} \\left[ P_{\\tau}(x) - \\tau \\ln n \\right] = \\lim_{\\tau \\to \\infty} \\tau \\ln\\left(1 + \\frac{1}{n\\tau}\\sum_{i=1}^{n} x_i + o\\left(\\frac{1}{\\tau}\\right)\\right)\n$$\n$$\n= \\lim_{\\tau \\to \\infty} \\tau \\left[ \\left(\\frac{1}{n\\tau}\\sum_{i=1}^{n} x_i + o\\left(\\frac{1}{\\tau}\\right)\\right) + o\\left(\\frac{1}{n\\tau}\\sum_{i=1}^{n} x_i + o\\left(\\frac{1}{\\tau}\\right)\\right) \\right]\n$$\n方括号内的项简化为 $\\frac{1}{n\\tau}\\sum_{i=1}^{n} x_i + o\\left(\\frac{1}{\\tau}\\right)$。\n$$\n= \\lim_{\\tau \\to \\infty} \\tau \\left[ \\frac{1}{n\\tau}\\sum_{i=1}^{n} x_i + o\\left(\\frac{1}{\\tau}\\right) \\right] = \\lim_{\\tau \\to \\infty} \\left[ \\frac{1}{n}\\sum_{i=1}^{n} x_i + \\tau \\cdot o\\left(\\frac{1}{\\tau}\\right) \\right]\n$$\n项 $\\tau \\cdot o(1/\\tau)$ 表示一个比 $1/\\tau$ 更快趋于零的量，因此乘以 $\\tau$ 后得到的项在 $\\tau \\to \\infty$ 时仍然消失。例如，如果 $o(1/\\tau)$ 是 $1/\\tau^2$ 阶，则 $\\tau(1/\\tau^2) = 1/\\tau \\to 0$。因此，$\\lim_{\\tau \\to \\infty} \\tau \\cdot o(1/\\tau) = 0$。\n因此，极限为：\n$$\n\\lim_{\\tau \\to \\infty} \\left[ P_{\\tau}(x) - \\tau \\ln n \\right] = \\frac{1}{n}\\sum_{i=1}^{n} x_i\n$$\n这是平均池化的定义。因此，对于大的 $\\tau$，$P_{\\tau}(x)$ 在一个加性项 $\\tau \\ln n$ 的范围内近似于平均池化。\n\n3. 推导梯度 $\\frac{\\partial P_{\\tau}(x)}{\\partial x_j}$\n\n我们计算 $P_{\\tau}(x)$ 对分量 $x_j$ 的偏导数，其中 $j$ 是一个固定索引，$j \\in \\{1, \\dots, n\\}$。我们使用链式法则。\n$$\nP_{\\tau}(x) = \\tau \\ln\\left(\\sum_{i=1}^{n} \\exp\\left(\\frac{x_{i}}{\\tau}\\right)\\right)\n$$\n令 $u(x) = \\sum_{i=1}^{n} \\exp\\left(\\frac{x_{i}}{\\tau}\\right)$。则 $P_{\\tau}(x) = \\tau \\ln(u(x))$。\n根据链式法则，$\\frac{\\partial P_{\\tau}(x)}{\\partial x_j} = \\frac{d}{du}(\\tau \\ln u) \\cdot \\frac{\\partial u}{\\partial x_j}$。\n\n首先，我们求外层函数对其参数 $u$ 的导数：\n$$\n\\frac{d}{du}(\\tau \\ln u) = \\frac{\\tau}{u} = \\frac{\\tau}{\\sum_{i=1}^{n} \\exp\\left(\\frac{x_{i}}{\\tau}\\right)}\n$$\n接下来，我们求内层函数 $u(x)$ 对 $x_j$ 的偏导数：\n$$\n\\frac{\\partial u}{\\partial x_j} = \\frac{\\partial}{\\partial x_j} \\left(\\sum_{i=1}^{n} \\exp\\left(\\frac{x_{i}}{\\tau}\\right)\\right)\n$$\n和的导数是导数的和。对于任何索引 $i \\neq j$ 的项，$\\frac{\\partial}{\\partial x_j}\\exp\\left(\\frac{x_{i}}{\\tau}\\right) = 0$。和中唯一的非零项是当 $i=j$ 时。\n$$\n\\frac{\\partial u}{\\partial x_j} = \\frac{\\partial}{\\partial x_j} \\exp\\left(\\frac{x_{j}}{\\tau}\\right) = \\exp\\left(\\frac{x_{j}}{\\tau}\\right) \\cdot \\frac{1}{\\tau}\n$$\n结合这些结果：\n$$\n\\frac{\\partial P_{\\tau}(x)}{\\partial x_j} = \\left( \\frac{\\tau}{\\sum_{i=1}^{n} \\exp\\left(\\frac{x_{i}}{\\tau}\\right)} \\right) \\cdot \\left( \\exp\\left(\\frac{x_{j}}{\\tau}\\right) \\cdot \\frac{1}{\\tau} \\right)\n$$\n分子中的因子 $\\tau$ 与因子 $1/\\tau$ 相抵消。\n$$\n\\frac{\\partial P_{\\tau}(x)}{\\partial x_j} = \\frac{\\exp\\left(\\frac{x_{j}}{\\tau}\\right)}{\\sum_{i=1}^{n} \\exp\\left(\\frac{x_{i}}{\\tau}\\right)}\n$$\n这个表达式是应用于向量 $x/\\tau$ 的 softmax 函数。\n所要求的三个结果是：\n1. $\\max_{i} x_i$\n2. $\\frac{1}{n} \\sum_{i=1}^{n} x_i$\n3. $\\frac{\\exp(x_j/\\tau)}{\\sum_{i=1}^{n} \\exp(x_i/\\tau)}$", "answer": "$$\n\\boxed{\n\\pmatrix{\n\\max_{i} x_i\n\n\\frac{1}{n}\\sum_{i=1}^{n} x_{i}\n\n\\frac{\\exp\\left(\\frac{x_j}{\\tau}\\right)}{\\sum_{i=1}^{n} \\exp\\left(\\frac{x_i}{\\tau}\\right)}\n}\n}\n$$", "id": "3163845"}]}