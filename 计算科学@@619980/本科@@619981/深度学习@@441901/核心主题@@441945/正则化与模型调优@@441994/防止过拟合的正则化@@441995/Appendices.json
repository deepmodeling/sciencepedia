{"hands_on_practices": [{"introduction": "L2 正则化（或权重衰减）是防止过拟合的基石技术之一。为了从根本上理解其作用，本练习将引导你分析一个简化的线性分类问题，直接对比有无权重衰减时梯度下降的动态行为。通过这个理论推导 [@problem_id:3169285]，你将清晰地看到正则化项如何约束模型参数的范数，从而找到一个平衡损失与复杂度的最优解，而不是无休止地增大参数以追求更大的间隔。", "problem": "考虑一个二元线性分类器，其参数向量为 $w \\in \\mathbb{R}^d$，在一个由两个样本组成的线性可分数据集上进行训练。这两个样本为 $(x_1,y_1)=(x,+1)$ 和 $(x_2,y_2)=(-x,-1)$，其中 $x \\in \\mathbb{R}^d$ 且 $x \\neq 0$。令 $r=\\|x\\|$。预测函数为 $f_w(x)=w^\\top x$，单个样本的训练损失为指数损失 $\\ell(z)=\\exp(-z)$。无正则化的经验风险为 $L(w)=\\sum_{i=1}^{2}\\ell\\!\\left(y_i w^\\top x_i\\right)$。为研究权重衰减（weight decay）的影响，我们同时考虑正则化目标函数 $F_\\lambda(w)=L(w)+\\frac{\\lambda}{2}\\|w\\|^2$，其中 $\\lambda>0$。定义参数 $w$ 的带符号间隔（signed margin）为 $m(w)=\\min_{i \\in \\{1,2\\}} y_i w^\\top x_i$。\n\n假设使用足够小的恒定步长和标准的无偏梯度估计，在 $L(w)$（无权重衰减）和 $F_\\lambda(w)$（有权重衰减）上运行随机梯度下降（SGD），并且当 $t \\to \\infty$ 时，迭代过程会追踪连续时间梯度流，并在适用的情况下方向上收敛到平稳解。请仅使用经验风险最小化、光滑函数的梯度以及凸对称问题的性质，通过研究范数 $\\|w(t)\\|$ 和带符号间隔 $m\\!\\left(w(t)\\right)$ 的行为，分析并比较两种情况下 SGD 在 $t \\to \\infty$ 时的隐式偏置（implicit bias）。\n\n然后，对于 $\\lambda>0$ 的正则化情况，利用数据集的对称性将优化问题简化为单个标量问题，推导出 $F_\\lambda(w)$ 的最小化子 $w_\\lambda^\\star$ 的一阶最优性条件，并精确求解，以获得极限带符号间隔 $m_\\lambda^\\star = m\\!\\left(w_\\lambda^\\star\\right)$ 作为 $r$ 和 $\\lambda$ 的函数的封闭形式解。\n\n请给出 $m_\\lambda^\\star$ 关于 $r$ 和 $\\lambda$ 的单一封闭形式解析表达式作为最终答案。不需要也不允许使用数值近似。", "solution": "该问题陈述已经过验证，被确定为机器学习理论领域中一个有效且适定（well-posed）的问题。它具有科学依据，内容自洽，没有歧义或矛盾。因此，我们可以进行完整求解。\n\n问题要求分析随机梯度下降（SGD）在有和没有L2正则化（权重衰减）的二元线性分类任务上的行为，并推导正则化情况下的最优间隔。\n\n我们首先根据所提供的信息定义关键量。数据集包含两个点 $(x_1, y_1) = (x, +1)$ 和 $(x_2, y_2) = (-x, -1)$，其中 $x \\in \\mathbb{R}^d$ 是一个非零向量。令 $r = \\|x\\|$。损失函数为指数损失 $\\ell(z) = \\exp(-z)$。\n\n无正则化的经验风险由 $L(w) = \\sum_{i=1}^{2} \\ell(y_i w^\\top x_i)$ 给出。代入数据点：\n$$L(w) = \\ell( (+1) w^\\top x ) + \\ell( (-1) w^\\top (-x) ) = \\exp(-w^\\top x) + \\exp(w^\\top (-x))$$\n$$L(w) = \\exp(-w^\\top x) + \\exp(-w^\\top x) = 2 \\exp(-w^\\top x)$$\n该数据集的带符号间隔为 $m(w) = \\min_{i \\in \\{1,2\\}} y_i w^\\top x_i = \\min(w^\\top x, (-1)w^\\top(-x)) = \\min(w^\\top x, w^\\top x) = w^\\top x$。\n因此，无正则化风险可以完全用间隔表示：\n$$L(w) = 2 \\exp(-m(w))$$\n正则化目标函数为 $F_\\lambda(w) = L(w) + \\frac{\\lambda}{2} \\|w\\|^2$，其中正则化参数 $\\lambda > 0$。\n\n**SGD 动态分析**\n\n我们分析参数向量 $w(t)$ 在梯度流下的行为，假设 SGD 在小步长下会追踪该梯度流。\n\n**情况 1：无正则化目标 ($L(w)$, $\\lambda=0$)**\n无正则化目标 $L(w)$ 的梯度流由微分方程 $\\frac{dw}{dt} = -\\nabla L(w)$ 描述。\n$L(w)$ 的梯度为：\n$$\\nabla L(w) = \\nabla_w \\left( 2 \\exp(-w^\\top x) \\right) = 2 \\exp(-w^\\top x) \\cdot \\nabla_w(-w^\\top x) = -2x \\exp(-w^\\top x)$$\n因此，梯度流为：\n$$\\frac{dw}{dt} = -(-2x \\exp(-w^\\top x)) = 2x \\exp(-w^\\top x)$$\n该方程表明，$w$ 在任何时刻 $t$ 的变化方向始终沿着向量 $x$ 的方向。如果我们初始化 $w(0)=0$，那么 $w(t)$ 将始终与 $x$ 平行。更一般地， $w(0)$ 中任何与 $x$ 正交的分量将保持不变，而与 $x$ 平行的分量会演化。通过假设 $w(t)$ 与 $x$ 共线，我们可以捕捉到我们感兴趣的动态，因此可以写成 $w(t) = c(t)x$，其中 $c(t)$ 是某个标量函数。\n\n最小化 $L(w) = 2\\exp(-m(w))$ 等价于最大化间隔 $m(w) = w^\\top x$。对于使用指数损失的线性可分数据集，可以通过使间隔任意大来将损失驱动到任意接近 $0$。这意味着权重向量的范数 $\\|w\\|$ 必须趋于无穷大。让我们用流方程来验证这一点。代入 $w(t) = c(t)x$：\n$$\\frac{d}{dt}(c(t)x) = 2x \\exp(-(c(t)x)^\\top x)$$\n$$x \\frac{dc}{dt} = 2x \\exp(-c(t) \\|x\\|^2) = 2x \\exp(-c(t) r^2)$$\n$$\\frac{dc}{dt} = 2 \\exp(-c(t) r^2)$$\n由于右侧始终为正，$c(t)$ 是一个关于 $t$ 的严格递增函数。当 $t \\to \\infty$ 时，$c(t)$ 无界增长，因此 $c(t) \\to \\infty$。\n因此，权重的范数发散：$\\|w(t)\\| = \\|c(t)x\\| = |c(t)| \\|x\\| = c(t)r \\to \\infty$。\n间隔也发散：$m(w(t)) = w(t)^\\top x = c(t)r^2 \\to \\infty$。\n\n这种行为被称为梯度下降的**隐式偏置**。对于使用指数损失的可分数据，SGD 不会收敛到有限的权重向量。相反，它会找到一个范数不断增大的解，该解持续改善间隔。$w(t)$ 的方向收敛到 $x$ 的方向，对于这个简单问题，这就是最大间隔方向。\n\n**情况 2：正则化目标 ($F_\\lambda(w)$, $\\lambda>0$)**\n正则化目标 $F_\\lambda(w) = L(w) + \\frac{\\lambda}{2} \\|w\\|^2$ 的梯度流由 $\\frac{dw}{dt} = -\\nabla F_\\lambda(w)$ 给出。\n梯度为：\n$$\\nabla F_\\lambda(w) = \\nabla L(w) + \\nabla \\left( \\frac{\\lambda}{2} \\|w\\|^2 \\right) = -2x \\exp(-w^\\top x) + \\lambda w$$\n梯度流为：\n$$\\frac{dw}{dt} = 2x \\exp(-w^\\top x) - \\lambda w$$\n对于 $\\lambda > 0$，目标函数 $F_\\lambda(w)$ 是严格凸的，因为他是一个凸函数 $L(w)$ 和一个严格凸函数 $\\frac{\\lambda}{2}\\|w\\|^2$ 的和。因此，存在一个唯一的有限最小化子 $w_\\lambda^\\star$，它是流的平稳点，在该点处 $\\frac{dw}{dt}=0$。\n在这个最小化子处，梯度为零：\n$$\\nabla F_\\lambda(w_\\lambda^\\star) = -2x \\exp(-(w_\\lambda^\\star)^\\top x) + \\lambda w_\\lambda^\\star = 0$$\n这意味着 SGD 收敛到一个有限解：当 $t \\to \\infty$ 时，$w(t) \\to w_\\lambda^\\star$。因此，范数 $\\|w(t)\\|$ 和间隔 $m(w(t))$ 分别收敛到有限值 $\\|w_\\lambda^\\star\\|$ 和 $m(w_\\lambda^\\star)$。\n\nL2 正则化项，即权重衰减，对大的权重施加惩罚，防止范数发散到无穷大。它抵消了来自指数损失的隐式间隔最大化压力，从而得到一个**有限的**最优权重向量 $w_\\lambda^\\star$，该向量在最小化分类损失和最小化权重范数之间取得了平衡。\n\n**最优间隔 $m_\\lambda^\\star$ 的推导**\n\n我们现在必须求解正则化情况下的极限带符号间隔 $m_\\lambda^\\star = m(w_\\lambda^\\star)$。一阶最优性条件是：\n$$\\lambda w_\\lambda^\\star = 2x \\exp(-(w_\\lambda^\\star)^\\top x)$$\n从这个方程可以明显看出，最优向量 $w_\\lambda^\\star$ 必须与向量 $x$ 平行。因此，我们可以将 $w_\\lambda^\\star$ 表示为 $w_\\lambda^\\star = c^\\star x$，其中 $c^\\star$ 是某个标量常数。为确保间隔 $w^\\top x$ 为正（以获得低损失），我们必须有 $c^\\star > 0$。\n\n让我们将 $w_\\lambda^\\star = c^\\star x$ 代回最优性条件：\n$$\\lambda (c^\\star x) = 2x \\exp(-(c^\\star x)^\\top x)$$\n因为 $x \\neq 0$，我们可以从两边消去它：\n$$\\lambda c^\\star = 2 \\exp(-c^\\star \\|x\\|^2) = 2 \\exp(-c^\\star r^2)$$\n这就是标量系数 $c^\\star$ 的最优性条件。\n\n问题要求的是最优间隔 $m_\\lambda^\\star$，而不是 $c^\\star$。间隔与 $c^\\star$ 的关系如下：\n$$m_\\lambda^\\star = m(w_\\lambda^\\star) = (w_\\lambda^\\star)^\\top x = (c^\\star x)^\\top x = c^\\star \\|x\\|^2 = c^\\star r^2$$\n根据这个关系，我们可以用我们寻求的间隔来表示 $c^\\star$：\n$$c^\\star = \\frac{m_\\lambda^\\star}{r^2}$$\n现在，我们将 $c^\\star$ 的这个表达式代回其标量最优性条件：\n$$\\lambda \\left(\\frac{m_\\lambda^\\star}{r^2}\\right) = 2 \\exp\\left(-\\left(\\frac{m_\\lambda^\\star}{r^2}\\right) r^2\\right)$$\n$$\\frac{\\lambda m_\\lambda^\\star}{r^2} = 2 \\exp(-m_\\lambda^\\star)$$\n为了求解 $m_\\lambda^\\star$，我们重新整理方程以分离它。我们将所有包含 $m_\\lambda^\\star$ 的项移到一边：\n$$m_\\lambda^\\star \\exp(m_\\lambda^\\star) = \\frac{2 r^2}{\\lambda}$$\n该方程的形式为 $u \\exp(u) = v$，其中 $u = m_\\lambda^\\star$ 且 $v = \\frac{2 r^2}{\\lambda}$。这种方程的解由朗伯W函数（Lambert W function）给出，记为 $W(v)$。朗伯W函数定义为函数 $f(u) = u \\exp(u)$ 的反函数。\n由于 $r^2 > 0$ 且 $\\lambda > 0$，自变量 $\\frac{2 r^2}{\\lambda}$ 是正的。对于正自变量，朗伯W函数的主分支（principal branch），记为 $W_0$ 或简记为 $W$，提供了一个唯一的正实数解。\n因此，最优间隔是：\n$$m_\\lambda^\\star = W\\left(\\frac{2 r^2}{\\lambda}\\right)$$\n这就是极限带符号间隔作为 $r$ 和 $\\lambda$ 的函数的精确、封闭形式的解析表达式。", "answer": "$$\\boxed{W\\left(\\frac{2r^2}{\\lambda}\\right)}$$", "id": "3169285"}, {"introduction": "数据增强是通过创造额外训练数据来提升模型泛化能力的有效正则化手段。本练习 [@problem_id:3169254] 不再局限于单一方法，而是要求你通过一个完整的编码实验，探究两种流行的增强技术——Cutout 和 Mixup——相结合时的效果。你将根据明确的量化标准，亲手验证它们的正则化效应是相互增强还是彼此冲突，从而更深刻地理解组合不同正则化策略的复杂性。", "problem": "给定一个合成二元分类任务，要求您从第一性原理出发，分析组合两种数据增强策略——cutout 和 Mixup——是会引入竞争性偏差，还是会对决策边界产生互补平滑。您必须实现一个完整的程序，该程序能够生成数据集、应用增强、在经验风险最小化框架下训练一个线性模型，并根据一个精确定义的标准为每个测试用例返回一个布尔决策。\n\n基本定义与设置：\n- 考虑经验风险最小化（ERM），它选择参数以最小化训练样本上的经验损失。对于线性预测器，使用带岭正则化的平方损失。\n- 设输入维度为 $d = 16$。设训练样本数为 $n_{\\text{train}} = 240$，测试样本数为 $n_{\\text{test}} = 240$。\n- 设类别标签为 $y \\in \\{-1, +1\\}$。\n- 设两个类别由均值为 $\\mu_{+}$ 和 $\\mu_{-}$、协方差为各向同性的多元正态分布生成。具体来说，设置 $\\sigma = 0.8$，并定义 $\\mu_{+}$ 的前 $k = 6$ 个分量等于 $\\delta = 1.2$，其余分量等于 $0$，即 $\\mu_{+} = (\\underbrace{\\delta, \\dots, \\delta}_{k}, \\underbrace{0, \\dots, 0}_{d-k})$。设置 $\\mu_{-} = -\\mu_{+}$。对于每个类别，从 $\\mathcal{N}(\\mu_{\\pm}, \\sigma^{2} I_{d})$ 中抽取 $n_{\\text{train}}/2$ 个训练样本和 $n_{\\text{test}}/2$ 个测试样本，其中 $I_{d}$ 是 $d \\times d$ 的单位矩阵。\n\n模型与训练：\n- 使用通过岭回归训练的线性预测器 $f(x) = w^{\\top} x$。给定设计矩阵 $X \\in \\mathbb{R}^{n \\times d}$ 和目标 $Y \\in \\mathbb{R}^{n}$，选择 $w \\in \\mathbb{R}^{d}$ 以最小化正则化平方经验损失\n$$\n\\mathcal{L}(w) = \\frac{1}{n} \\sum_{i=1}^{n} \\left( w^{\\top} x_{i} - y_{i}\\right)^{2} + \\lambda \\|w\\|_{2}^{2},\n$$\n其中 $\\lambda = 0.1$。使用岭回归正规方程的闭式解：\n$$\nw = \\left(X^{\\top} X + \\lambda I_{d}\\right)^{-1} X^{\\top} Y.\n$$\n\n数据增强：\n- 长度为 $c$ 的 Cutout：对于每个训练样本 $x \\in \\mathbb{R}^{d}$，从 $\\{0, 1, \\dots, d-c\\}$ 中均匀选择一个随机起始索引 $s$，并将分量 $x_{s}, x_{s+1}, \\dots, x_{s+c-1}$ 设置为 $0$。如果 $c = 0$，则禁用 cutout。\n- 参数为 $\\alpha$ 的 Mixup：对于每个训练样本，（仅当 $\\alpha > 0$ 时）抽取 $\\lambda \\sim \\text{Beta}(\\alpha, \\alpha)$，选择一个随机伙伴样本 $(x_{j}, y_{j})$，并形成一个混合样本\n$$\nx' = \\lambda x_{i} + (1 - \\lambda) x_{j}, \\quad y' = \\lambda y_{i} + (1 - \\lambda) y_{j}.\n$$\n构建一个与原始训练集大小相同（$n_{\\text{train}}$）的混合数据集。如果 $\\alpha \\leq 0$，则禁用 Mixup。当两种增强都激活时，首先对原始特征应用 cutout，然后对经过 cutout 变换的特征执行 Mixup。\n\n评估指标：\n- 决策性能：计算测试集上的误分类率，结果为 $[0,1]$ 内的小数。使用分类器 $\\hat{y} = \\text{sign}(w^{\\top} x)$ 并与真实标签 $y \\in \\{-1, +1\\}$ 进行比较。\n- 平滑度代理指标：使用欧几里得范数 $\\|w\\|_{2}$ 作为线性预测器利普希茨常数的代理；较小的 $\\|w\\|_{2}$ 表示更平滑的决策函数。\n\n互补性决策规则：\n- 对于给定的配对 $(c, \\alpha)$，计算三种训练配置的结果：\n    1. 仅 Cutout：cutout 长度为 $c$，禁用 Mixup。\n    2. 仅 Mixup：使用参数为 $\\alpha$ 的 Mixup，禁用 cutout。\n    3. 两者皆有：cutout 长度为 $c$ 和参数为 $\\alpha$ 的 Mixup 按顺序应用（先 cutout 后 Mixup）。\n- 设 $e_{\\text{cut}}$、$e_{\\text{mix}}$、$e_{\\text{both}}$ 表示测试误分类率，而 $n_{\\text{cut}}$、$n_{\\text{mix}}$、$n_{\\text{both}}$ 表示对应的 $\\|w\\|_{2}$ 范数。设 $e_{\\text{single}}^{\\min} = \\min(e_{\\text{cut}}, e_{\\text{mix}})$ 和 $n_{\\text{single}}^{\\min} = \\min(n_{\\text{cut}}, n_{\\text{mix}})$。给定容差 $\\tau_{e} = 10^{-3}$ 和 $\\tau_{n} = 10^{-6}$，声明布尔值\n$$\n\\mathcal{C} = \\left( e_{\\text{both}} \\leq e_{\\text{single}}^{\\min} + \\tau_{e} \\right) \\wedge \\left( n_{\\text{both}} \\leq n_{\\text{single}}^{\\min} + \\tau_{n} \\right).\n$$\n如果 $\\mathcal{C}$ 为真，则解释为互补平滑；否则解释为竞争性偏差。\n\n测试套件：\n- 使用以下 $(c, \\alpha)$ 配对：\n    1. $(0, 0.0)$,\n    2. $(4, 0.0)$,\n    3. $(0, 0.4)$,\n    4. $(4, 0.4)$,\n    5. $(10, 0.4)$,\n    6. $(4, 4.0)$.\n\n最终输出规范：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，`\"[result1,result2,result3]\"`），其中每个元素是对应于一个测试用例的布尔值 $\\mathcal{C}$，顺序与上面列出的相同。不应打印任何额外文本。", "solution": "在进行求解之前，对问题陈述的有效性进行了严格评估。\n\n### 步骤 1：提取已知条件\n- **任务**：分析结合 cutout 和 Mixup 数据增强是否会引入竞争性偏差或决策边界的互补性平滑。\n- **模型**：使用岭回归训练的线性预测器 $f(x) = w^{\\top} x$。\n- **损失函数与解**：\n  - 定义的损失：$\\mathcal{L}(w) = \\frac{1}{n} \\sum_{i=1}^{n} \\left( w^{\\top} x_{i} - y_{i}\\right)^{2} + \\lambda \\|w\\|_{2}^{2}$。\n  - 提供的 $w$ 的解：$w = \\left(X^{\\top} X + \\lambda I_{d}\\right)^{-1} X^{\\top} Y$。\n- **问题参数**：\n  - 输入维度：$d = 16$。\n  - 训练样本数：$n_{\\text{train}} = 240$。\n  - 测试样本数：$n_{\\text{test}} = 240$。\n  - 类别标签：$y \\in \\{-1, +1\\}$。\n  - 正则化参数：$\\lambda = 0.1$。\n- **数据生成**：\n  - 分布：多元正态分布 $\\mathcal{N}(\\mu, \\Sigma)$。\n  - 协方差：各向同性，$\\Sigma = \\sigma^{2} I_{d}$，其中 $\\sigma = 0.8$。\n  - 类别均值：$\\mu_{+} = (\\underbrace{\\delta, \\dots, \\delta}_{k}, \\underbrace{0, \\dots, 0}_{d-k})$ 和 $\\mu_{-} = -\\mu_{+}$，其中 $k = 6$ 且 $\\delta = 1.2$。\n  - 数据划分：每个类别 $n_{\\text{train}}/2$ 个样本用于训练，每个类别 $n_{\\text{test}}/2$ 个样本用于测试。\n- **数据增强**：\n  - **Cutout**：对于每个样本，将一个长度为 $c$ 的连续特征块设置为 $0$。起始索引从 $\\{0, 1, \\dots, d-c\\}$ 中均匀选择。如果 $c = 0$，则禁用。\n  - **Mixup**：对于每个训练样本 $(x_i, y_i)$，通过 $x' = \\lambda_{\\text{mix}} x_{i} + (1 - \\lambda_{\\text{mix}}) x_{j}$ 和 $y' = \\lambda_{\\text{mix}} y_{i} + (1 - \\lambda_{\\text{mix}}) y_{j}$ 形成一个新样本，其中 $(x_j, y_j)$ 是一个随机伙伴样本，且 $\\lambda_{\\text{mix}} \\sim \\text{Beta}(\\alpha, \\alpha)$。如果 $\\alpha \\leq 0$，则禁用。构造一个大小为 $n_{\\text{train}}$ 的新数据集。\n  - **组合顺序**：当两者都激活时，先应用 cutout，然后应用 Mixup。\n- **评估指标**：\n  - **决策性能**：分类器 $\\hat{y} = \\text{sign}(w^{\\top} x)$ 在测试集上的误分类率。\n  - **平滑度代理指标**：权重向量的欧几里得范数 $\\|w\\|_{2}$。\n- **互补性决策规则**：\n  - 令 $e$ 为测试误差，$n$ 为 $\\|w\\|_2$。下标 'cut'、'mix'、'both' 分别表示仅 Cutout、仅 Mixup 和组合配置。\n  - 设 $e_{\\text{single}}^{\\min} = \\min(e_{\\text{cut}}, e_{\\text{mix}})$ 和 $n_{\\text{single}}^{\\min} = \\min(n_{\\text{cut}}, n_{\\text{mix}})$。\n  - 容差：$\\tau_{e} = 10^{-3}$，$\\tau_{n} = 10^{-6}$。\n  - 决策布尔值：$\\mathcal{C} = \\left( e_{\\text{both}} \\leq e_{\\text{single}}^{\\min} + \\tau_{e} \\right) \\wedge \\left( n_{\\text{both}} \\leq n_{\\text{single}}^{\\min} + \\tau_{n} \\right)$。\n- **测试套件**：$(c, \\alpha)$ 配对：$(0, 0.0)$、$(4, 0.0)$、$(0, 0.4)$、$(4, 0.4)$、$(10, 0.4)$、$(4, 4.0)$。\n\n### 步骤 2：使用提取的已知条件进行验证\n根据既定标准对问题进行评估：\n- **科学性**：该问题在统计机器学习的原理上有充分的依据。它涉及标准技术（岭回归、cutout、Mixup）和概念（正则化、泛化、决策边界）。使用高斯分布的合成数据是研究算法行为的典型方法。\n- **良构性**：该问题是良构的。所有必需的参数都已指定，数据生成、增强、训练和评估的程序都有明确定义。当 $\\lambda > 0$ 时，岭回归问题保证了权重向量 $w$ 的唯一、稳定解。最终的决策规则 $\\mathcal{C}$ 是明确的。\n- **客观性**：问题以精确、客观和形式化的数学语言陈述。评估标准是定量的，没有主观解释的余地。\n- **不完整性或矛盾**：存在一个微小的不一致。损失函数给出为 $\\mathcal{L}(w) = \\frac{1}{n} \\sum_{i=1}^{n} \\left( w^{\\top} x_{i} - y_{i}\\right)^{2} + \\lambda \\|w\\|_{2}^{2}$，但解 $w = \\left(X^{\\top} X + \\lambda I_{d}\\right)^{-1} X^{\\top} Y$ 对应的是一个目标函数，其中平方和项没有按 $\\frac{1}{n}$ 缩放，即 $\\mathcal{L'}(w) = \\sum_{i=1}^{n} \\left( w^{\\top} x_{i} - y_{i}\\right)^{2} + \\lambda \\|w\\|_{2}^{2}$。然而，由于 $w$ 的公式是明确提供的，它构成了明确的计算指令，从而解决了歧义。问题没有指定随机种子，这对于精确的可复现性是必要的。这是一个计算问题中的小疏忽，而非根本性缺陷，将在实现中通过设置固定种子来解决。\n- **其他缺陷**：该问题没有表现出清单中的任何其他缺陷，例如无关紧要、伪深刻或无法测试。测试用例，包括基线 $(0, 0.0)$，旨在系统地探究增强的效果。\n\n### 步骤 3：结论与行动\n该问题是**有效的**。通过遵循明确提供的求解公式，微小的不一致性得到了解决；而缺少指定随机种子是一个标准细节，将在实现中通过设置固定种子来解决。该分析具有科学意义且计算上是可行的。我们可以继续进行求解。\n\n### 基于原理的设计与求解\n该解决方案涉及一个系统的计算实验，以评估 cutout 和 Mixup 增强对线性分类器的组合效应。实现将忠实地遵循问题陈述中定义的程序。\n\n**1. 数据生成**\n首先，我们合成训练和测试数据集。两个类别（标记为 $y=+1$ 和 $y=-1$）的数据分别从 $d$ 维多元正态分布 $\\mathcal{N}(\\mu_{+}, \\sigma^2 I_d)$ 和 $\\mathcal{N}(\\mu_{-}, \\sigma^2 I_d)$ 中抽取。参数固定为 $d=16$ 和 $\\sigma=0.8$。均值设置为对跖的，即 $\\mu_{-} = -\\mu_{+}$，其中 $\\mu_{+}$ 是一个稀疏向量，其前 $k=6$ 个元素等于 $\\delta=1.2$，其余为零。这创建了一个线性可分但并非平凡的分类任务。我们为训练集从每个类别生成 $n_{\\text{train}}/2=120$ 个样本，为测试集从每个类别生成 $n_{\\text{test}}/2=120$ 个样本。采用固定的随机种子以确保整个实验是可复现的。\n\n**2. 数据增强实现**\n我们实现了两个数据增强函数，`apply_cutout` 和 `apply_mixup`。\n- `apply_cutout(X, c, rng)`：给定一个数据矩阵 $X$，该函数遍历每个样本（行）。对于每个样本，如果 cutout 长度 $c > 0$，它会从 $\\{0, \\dots, d-c\\}$ 中随机选择一个起始特征索引 $s$，并将从 $s$ 到 $s+c-1$ 的连续特征块置零。这模拟了信息丢失，并鼓励模型不要依赖于任何单一的特征组。\n- `apply_mixup(X, Y, alpha, rng)`：如果 Mixup 参数 $\\alpha > 0$，该函数会生成一个大小相同的新训练集。对于每个原始样本 $(x_i, y_i)$，它从数据集中选择一个随机伙伴 $(x_j, y_j)$。一个混合系数 $\\lambda_{\\text{mix}}$ 从 Beta 分布中抽取，$\\lambda_{\\text{mix}} \\sim \\text{Beta}(\\alpha, \\alpha)$。新的虚拟样本是原始样本和伙伴样本的凸组合：$(x', y') = (\\lambda_{\\text{mix}} x_i + (1-\\lambda_{\\text{mix}})x_j, \\lambda_{\\text{mix}} y_i + (1-\\lambda_{\\text{mix}})y_j)$。这创建了线性插值的样本和标签，通过平滑决策边界和鼓励模型在数据点之间表现出线性行为，起到一种正则化的作用。\n\n**3. 模型训练**\n该模型是一个线性分类器，其权重 $w \\in \\mathbb{R}^d$ 由岭回归确定。正如在验证阶段所确定的，我们使用明确提供的闭式解：\n$$w = (X^{\\top}X + \\lambda I_d)^{-1} X^{\\top}Y$$\n这里，$X$ 是（可能经过增强的）训练数据的 $n_{\\text{train}} \\times d$ 设计矩阵，$Y$ 是相应标签的向量，$I_d$ 是 $d \\times d$ 单位矩阵，$\\lambda = 0.1$ 是正则化参数。$\\lambda I_d$ 项确保矩阵 $X^{\\top}X + \\lambda I_d$ 是可逆且良态的，通过惩罚大的权重来正则化解，这对应于最小化 L2 范数 $\\|w\\|_2^2$。\n\n**4. 实验协议与评估**\n对于测试套件中的每个 $(c, \\alpha)$ 配对，我们执行三个不同的实验来隔离和比较增强的效果：\n1.  **仅 Cutout**：我们在使用 cutout ($c$) 但不使用 Mixup ($\\alpha \\leq 0$) 增强的数据上训练一个模型。我们计算测试误差 $e_{\\text{cut}}$ 和权重范数 $n_{\\text{cut}}$。\n2.  **仅 Mixup**：我们在使用 Mixup ($\\alpha$) 但不使用 cutout ($c=0$) 增强的数据上训练一个模型。我们计算测试误差 $e_{\\text{mix}}$ 和权重范数 $n_{\\text{mix}}$。\n3.  **两者皆有**：我们首先通过 cutout ($c$) 然后通过 Mixup ($\\alpha$) 增强数据，并在此数据上训练一个模型。我们计算测试误差 $e_{\\text{both}}$ 和权重范数 $n_{\\text{both}}$。\n\n误分类率是在静态、未经增强的测试集上计算的。分类器对测试样本 $x$ 的预测是 $\\hat{y} = \\text{sign}(w^{\\top}x)$。误差是 $\\hat{y} \\neq y$ 的测试样本的比例。权重范数 $\\|w\\|_2$ 作为所学函数平滑度的代理指标。\n\n**5. 互补性决策**\n最后，使用指定的决策规则对结果进行综合。如果使用两种增强训练的模型在两个指标上都表现得至少与两个单增强模型中较好的那个一样好（在给定容差范围内），则认为增强的组合是“互补的”。形式上，计算布尔值 $\\mathcal{C}$：\n$$\\mathcal{C} = (e_{\\text{both}} \\leq \\min(e_{\\text{cut}}, e_{\\text{mix}}) + \\tau_{e}) \\wedge (n_{\\text{both}} \\leq \\min(n_{\\text{cut}}, n_{\\text{mix}}) + \\tau_{n})$$\n其中 $\\tau_{e} = 10^{-3}$ 和 $\\tau_{n} = 10^{-6}$。程序将为每个测试用例执行这整个过程，并输出得到的布尔值列表。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import special\n\ndef solve():\n    # Define problem parameters\n    D = 16\n    N_TRAIN = 240\n    N_TEST = 240\n    K_FEATURES = 6\n    DELTA = 1.2\n    SIGMA = 0.8\n    LAMBDA_REG = 0.1\n    TAU_E = 1e-3\n    TAU_N = 1e-6\n    SEED = 42\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (0, 0.0),\n        (4, 0.0),\n        (0, 0.4),\n        (4, 0.4),\n        (10, 0.4),\n        (4, 4.0),\n    ]\n\n    rng = np.random.default_rng(seed=SEED)\n\n    def generate_data():\n        \"\"\"Generates the base synthetic dataset.\"\"\"\n        mu_plus = np.zeros(D)\n        mu_plus[:K_FEATURES] = DELTA\n        mu_minus = -mu_plus\n        cov = (SIGMA**2) * np.identity(D)\n\n        n_per_class_train = N_TRAIN // 2\n        n_per_class_test = N_TEST // 2\n\n        X_train_plus = rng.multivariate_normal(mu_plus, cov, size=n_per_class_train)\n        X_train_minus = rng.multivariate_normal(mu_minus, cov, size=n_per_class_train)\n        X_train = np.vstack((X_train_plus, X_train_minus))\n        Y_train = np.array([1] * n_per_class_train + [-1] * n_per_class_train)\n\n        X_test_plus = rng.multivariate_normal(mu_plus, cov, size=n_per_class_test)\n        X_test_minus = rng.multivariate_normal(mu_minus, cov, size=n_per_class_test)\n        X_test = np.vstack((X_test_plus, X_test_minus))\n        Y_test = np.array([1] * n_per_class_test + [-1] * n_per_class_test)\n\n        return X_train, Y_train, X_test, Y_test\n\n    def apply_cutout(X, c, local_rng):\n        \"\"\"Applies cutout augmentation.\"\"\"\n        if c == 0:\n            return X\n        X_aug = X.copy()\n        for i in range(X_aug.shape[0]):\n            s = local_rng.integers(0, D - c + 1)\n            X_aug[i, s:s+c] = 0\n        return X_aug\n\n    def apply_mixup(X, Y, alpha, local_rng):\n        \"\"\"Applies Mixup augmentation.\"\"\"\n        if alpha = 0:\n            return X, Y\n        n_samples = X.shape[0]\n        X_aug = np.zeros_like(X)\n        Y_aug = np.zeros_like(Y, dtype=float)\n        \n        partner_indices = local_rng.permutation(n_samples)\n        \n        for i in range(n_samples):\n            lambda_mix = local_rng.beta(alpha, alpha)\n            j = partner_indices[i]\n            \n            X_aug[i] = lambda_mix * X[i] + (1 - lambda_mix) * X[j]\n            Y_aug[i] = lambda_mix * Y[i] + (1 - lambda_mix) * Y[j]\n            \n        return X_aug, Y_aug\n\n    def train_ridge(X, Y, lambda_reg):\n        \"\"\"Trains a ridge regression model using the closed-form solution.\"\"\"\n        d = X.shape[1]\n        I = np.identity(d)\n        # Using the formula w = (X^T X + lambda * I_d)^-1 X^T Y\n        term1 = np.linalg.inv(X.T @ X + lambda_reg * I)\n        term2 = X.T @ Y\n        w = term1 @ term2\n        return w\n\n    def evaluate_model(w, X_test, Y_test):\n        \"\"\"Evaluates the model's performance and weight norm.\"\"\"\n        # Misclassification rate\n        Y_pred_scores = X_test @ w\n        Y_pred_labels = np.sign(Y_pred_scores)\n        Y_pred_labels[Y_pred_labels == 0] = 1 # Handle zeros\n        misclassification_rate = np.mean(Y_pred_labels != Y_test)\n        \n        # L2 norm of weights\n        weight_norm = np.linalg.norm(w)\n        \n        return misclassification_rate, weight_norm\n\n    def run_experiment(c, alpha, base_data, local_rng):\n        \"\"\"Runs a single experiment for a given (c, alpha) configuration.\"\"\"\n        X_train_base, Y_train_base, X_test, Y_test = base_data\n        \n        # Apply cutout\n        X_cut = apply_cutout(X_train_base, c, local_rng)\n        \n        # Apply mixup (on cutout-transformed data)\n        X_aug, Y_aug = apply_mixup(X_cut, Y_train_base, alpha, local_rng)\n        \n        # Train model\n        w = train_ridge(X_aug, Y_aug, LAMBDA_REG)\n        \n        # Evaluate\n        error, norm = evaluate_model(w, X_test, Y_test)\n        \n        return error, norm\n\n    # Generate the base dataset once for all experiments\n    base_dataset = generate_data()\n    \n    results = []\n    for c_val, alpha_val in test_cases:\n        # 1. Cutout only\n        e_cut, n_cut = run_experiment(c=c_val, alpha=0.0, base_data=base_dataset, local_rng=rng)\n        \n        # 2. Mixup only\n        e_mix, n_mix = run_experiment(c=0, alpha=alpha_val, base_data=base_dataset, local_rng=rng)\n        \n        # 3. Both augmentations\n        e_both, n_both = run_experiment(c=c_val, alpha=alpha_val, base_data=base_dataset, local_rng=rng)\n        \n        # Complementarity decision rule\n        e_single_min = min(e_cut, e_mix)\n        n_single_min = min(n_cut, n_mix)\n        \n        is_complementary = (e_both = e_single_min + TAU_E) and (n_both = n_single_min + TAU_N)\n        results.append(is_complementary)\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3169254"}, {"introduction": "在现代深度网络中，正则化技术并非孤立作用，而是与网络架构的其它组件（如归一化层）相互影响。这个练习 [@problem_id:3169330] 旨在揭示一个在实践中至关重要但又十分微妙的现象：层归一化（Layer Normalization）的尺度不变性如何从根本上改变了 $L_2$ 权重衰减的意义和效果。通过分析这一互动，你将学会审慎地思考模型不同部分之间的耦合关系，避免在复杂模型中盲目应用标准正则化方法。", "problem": "考虑一个深度学习中的经验风险最小化问题，其中模型应用逐点线性缩放，然后是层归一化 (Layer Normalization, LN)。设输入为一个随机向量 $x \\in \\mathbb{R}^{d}$，参数为一个权重向量 $w \\in \\mathbb{R}^{d}$。定义预激活为 $z = w \\odot x$，其中 $\\odot$ 表示逐元素乘法。归一化后的激活由层归一化 (LN) 变换给出\n$$\n\\mathrm{LN}(z) = \\gamma \\odot \\frac{z - \\mu(z)\\mathbf{1}}{\\sigma(z)} + \\beta,\n$$\n其中 $\\mu(z) = \\frac{1}{d}\\sum_{i=1}^{d} z_{i}$ 是特征维度上的均值，$\\sigma(z) = \\sqrt{\\frac{1}{d}\\sum_{i=1}^{d}(z_{i} - \\mu(z))^{2}}$ 是特征维度上的标准差，$\\gamma, \\beta \\in \\mathbb{R}^{d}$ 是可训练的增益和偏置参数，$\\mathbf{1} \\in \\mathbb{R}^{d}$ 是全1向量。假设监督损失为 $\\ell:\\mathbb{R}^{d} \\times \\mathcal{Y} \\to \\mathbb{R}$，其中 $\\mathcal{Y}$ 是标签空间，经验风险（无正则化）为\n$$\n\\mathcal{J}(w,\\gamma,\\beta) = \\mathbb{E}_{(x,y)}\\big[\\ell(\\mathrm{LN}(w \\odot x), y)\\big].\n$$\n我们通过在 $w$ 上添加一个 $\\ell_{2}$ 惩罚项来考虑权重衰减，得到正则化目标\n$$\n\\mathcal{J}_{\\lambda}(w,\\gamma,\\beta) = \\mathcal{J}(w,\\gamma,\\beta) + \\lambda \\lVert w \\rVert_{2}^{2},\n$$\n其中 $\\lambda  0$。对于优化，可以在目标函数的梯度中包含该惩罚项（耦合权重衰减），或者在对无正则化损失进行梯度步骤之外，额外应用一个单独的收缩步骤 $w \\leftarrow (1 - \\eta\\lambda)w$（解耦权重衰减），其中 $\\eta  0$ 是学习率。\n\n仅使用上述定义以及可微函数和范数的基本性质，推理分析层归一化引起的尺度不变性与 $w$ 上的 $\\ell_{2}$ 惩罚项之间的相互作用。选择所有正确的陈述。\n\nA. 如果 $\\mathcal{J}(w,\\gamma,\\beta)$ 在尺度缩放 $w \\mapsto c w$ (对于任意 $c  0$) 下不变，那么梯度 $\\nabla_{w}\\mathcal{J}(w,\\gamma,\\beta)$ 与 $w$ 正交，并且添加权重衰减会在更新中引入一个与 $w$ 平行的非零分量。这个分量不会降低无正则化的损失，并且当其很大时，会通过将更新的大小从减少 $\\mathcal{J}$ 的方向上移走而阻碍学习。\n\nB. 将 $w$ 重参数化为 $w = s v$（其中 $s \\in \\mathbb{R}_{0}$ 且 $\\lVert v \\rVert_{2} = 1$），无正则化的损失 $\\mathcal{J}(w,\\gamma,\\beta)$ 同时依赖于 $s$ 和 $v$。因此，$w$ 上的 $\\ell_{2}$ 惩罚项总能独立于所选参数化来衡量函数复杂度。\n\nC. 因为层归一化消除了 $z = w \\odot x$ 的尺度，所以 $w$ 上的任何 $\\ell_{2}$ 惩罚都等效于仅惩罚 LN 的增益参数 $\\gamma$。因此，可以选择 $\\gamma$ 来抵消惩罚项对优化动态的影响。\n\nD. 在 $\\mathcal{J}(w,\\gamma,\\beta)$ 对 $w$ 具有精确尺度不变性的情况下，范数 $\\lVert w \\rVert_{2}$ 对 $\\mathcal{J}$ 的值没有影响，但当应用权重衰减时，它会影响优化轨迹。此外，将 $w$ 重参数化为 $w=sv$（其中 $\\lVert v \\rVert_{2} = 1$）表明，通过改变 $s$，同一个函数可以用任意小或任意大的 $\\lVert w \\rVert_{2}$ 来表示，因此在存在层归一化的情况下，$\\lVert w \\rVert_{2}$ 的含义是依赖于参数化的。\n\nE. 当存在层归一化时，解耦权重衰减总能改善泛化能力，因为在 LN 下，$\\lVert w \\rVert_{2}$ 是函数复杂度的不变度量。", "solution": "### 问题验证\n\n#### 步骤1：提取已知条件\n- 输入：$x \\in \\mathbb{R}^{d}$\n- 权重向量：$w \\in \\mathbb{R}^{d}$\n- 预激活：$z = w \\odot x$\n- 层归一化 (LN) 变换：$\\mathrm{LN}(z) = \\gamma \\odot \\frac{z - \\mu(z)\\mathbf{1}}{\\sigma(z)} + \\beta$\n- $z$ 的均值：$\\mu(z) = \\frac{1}{d}\\sum_{i=1}^{d} z_{i}$\n- $z$ 的标准差：$\\sigma(z) = \\sqrt{\\frac{1}{d}\\sum_{i=1}^{d}(z_{i} - \\mu(z))^{2}}$\n- 可训练参数：$\\gamma, \\beta \\in \\mathbb{R}^{d}$\n- 全1向量：$\\mathbf{1} \\in \\mathbb{R}^{d}$\n- 监督损失函数：$\\ell:\\mathbb{R}^{d} \\times \\mathcal{Y} \\to \\mathbb{R}$\n- 无正则化经验风险：$\\mathcal{J}(w,\\gamma,\\beta) = \\mathbb{E}_{(x,y)}\\big[\\ell(\\mathrm{LN}(w \\odot x), y)\\big]$\n- 正则化目标（耦合权重衰减）：$\\mathcal{J}_{\\lambda}(w,\\gamma,\\beta) = \\mathcal{J}(w,\\gamma,\\beta) + \\lambda \\lVert w \\rVert_{2}^{2}$，其中 $\\lambda  0$\n- 解耦权重衰减：描述为在对 $\\mathcal{J}$ 进行梯度步骤之外，额外应用一个单独的收缩步骤 $w \\leftarrow (1 - \\eta\\lambda)w$，其中学习率为 $\\eta  0$。\n\n#### 步骤2：使用提取的已知条件进行验证\n1.  **科学基础**：问题陈述使用了深度学习领域的标准、公认定义，包括层归一化、经验风险最小化和 $\\ell_2$ 正则化（权重衰减）。耦合与解耦权重衰减之间的区别也是文献中公认的概念。该问题在科学上是合理的。\n2.  **适定性**：该问题要求基于所提供的数学定义来推理尺度不变性与 L2 正则化之间的相互作用。这是一个概念分析问题，可以对每个选项得出明确的结论。\n3.  **客观性**：问题使用形式化的数学语言陈述，没有主观或模棱两可的术语。\n4.  **完整性和一致性**：分析所需的所有定义均已提供且相互一致。该设置是神经网络中一个层的标准简化模型，足以回答所提出的概念性问题。\n5.  **未检测到其他缺陷**：该问题并非不切实际、不适定、微不足道或无法验证。它探讨了现代神经网络训练中的一个核心概念问题。\n\n#### 步骤3：结论与行动\n问题陈述有效。我将继续进行解答。\n\n### 推导与分析\n\n问题的核心在于理解层归一化相对于权重向量 $w$ 的尺度不变性。我们来分析将 $w$ 乘以一个正常数 $c  0$ 的效果。令 $w' = c w$。新的预激活为 $z' = w' \\odot x = (c w) \\odot x = c (w \\odot x) = c z$。\n\n现在，我们计算 $z'$ 的均值和标准差：\n均值为 $\\mu(z') = \\mu(c z) = \\frac{1}{d}\\sum_{i=1}^{d} (c z_i) = c \\left(\\frac{1}{d}\\sum_{i=1}^{d} z_i\\right) = c \\mu(z)$。\n方差为 $\\sigma(z')^2 = \\frac{1}{d}\\sum_{i=1}^{d} (z'_i - \\mu(z'))^2 = \\frac{1}{d}\\sum_{i=1}^{d} (c z_i - c \\mu(z))^2 = c^2 \\left(\\frac{1}{d}\\sum_{i=1}^{d} (z_i - \\mu(z))^2\\right) = c^2 \\sigma(z)^2$。\n假设 $\\sigma(z) \\neq 0$，标准差为 $\\sigma(z') = \\sqrt{c^2 \\sigma(z)^2} = |c|\\sigma(z) = c \\sigma(z)$，因为 $c  0$。\n\n现在，我们来计算 $z'$ 的层归一化输出：\n$$ \\mathrm{LN}(z') = \\gamma \\odot \\frac{z' - \\mu(z')\\mathbf{1}}{\\sigma(z')} + \\beta = \\gamma \\odot \\frac{c z - c \\mu(z)\\mathbf{1}}{c \\sigma(z)} + \\beta $$\n对于 $c \\neq 0$，我们可以消去分子和分母中的 $c$：\n$$ \\mathrm{LN}(z') = \\gamma \\odot \\frac{c(z - \\mu(z)\\mathbf{1})}{c \\sigma(z)} + \\beta = \\gamma \\odot \\frac{z - \\mu(z)\\mathbf{1}}{\\sigma(z)} + \\beta = \\mathrm{LN}(z) $$\n这表明层归一化的输出 $\\mathrm{LN}(w \\odot x)$ 对权重向量 $w$ 乘以任意正常数 $c$ 的操作是不变的。\n\n因此，损失函数 $\\ell(\\mathrm{LN}(w \\odot x), y)$ 对这种缩放也是不变的。这意味着无正则化的经验风险 $\\mathcal{J}(w, \\gamma, \\beta)$ 是 $w$ 的一个尺度不变函数：\n$$ \\mathcal{J}(c w, \\gamma, \\beta) = \\mathcal{J}(w, \\gamma, \\beta) \\quad \\text{for any } c  0 $$\n这是我们将用来评估各个选项的一个关键性质。\n\n### 逐项分析\n\n**A. 如果 $\\mathcal{J}(w,\\gamma,\\beta)$ 在尺度缩放 $w \\mapsto c w$ (对于任意 $c  0$) 下不变，那么梯度 $\\nabla_{w}\\mathcal{J}(w,\\gamma,\\beta)$ 与 $w$ 正交，并且添加权重衰减会在更新中引入一个与 $w$ 平行的非零分量。这个分量不会降低无正则化的损失，并且当其很大时，会通过将更新的大小从减少 $\\mathcal{J}$ 的方向上移走而阻碍学习。**\n\n令 $f(w) = \\mathcal{J}(w, \\gamma, \\beta)$。尺度不变性性质为 $f(cw) = f(w)$（对于 $c0$）。根据欧拉齐次函数定理，如果一个函数是 $k$ 次齐次的，则 $f(cw) = c^k f(w)$。若是如此，则 $(\\nabla_w f(w))^T w = k f(w)$。在我们的例子中，$k=0$，所以我们有 $(\\nabla_w f(w))^T w = 0$。这意味着无正则化损失的梯度 $\\nabla_w \\mathcal{J}(w)$ 与权重向量 $w$ 正交。\n正则化目标是 $\\mathcal{J}_{\\lambda}(w) = \\mathcal{J}(w) + \\lambda \\lVert w \\rVert_2^2$。\n正则化目标的梯度是 $\\nabla_w \\mathcal{J}_{\\lambda}(w) = \\nabla_w \\mathcal{J}(w) + \\nabla_w(\\lambda \\lVert w \\rVert_2^2) = \\nabla_w \\mathcal{J}(w) + 2\\lambda w$。\n权重衰减惩罚项增加了一个分量 $2\\lambda w$，它与 $w$ 平行。\n梯度下降的更新方向是 $-\\nabla_w \\mathcal{J}_{\\lambda}(w) = -\\nabla_w \\mathcalJ(w) - 2\\lambda w$。分量 $-2\\lambda w$ 在 $-w$ 的方向上。$\\mathcal{J}$ 在 $-w$ 方向上的方向导数为 $(\\nabla_w \\mathcal{J}(w))^T (-w) = -(\\nabla_w \\mathcal{J}(w))^T w = 0$。这证实了沿 $w$（或 $-w$）方向移动不会对无正则化损失 $\\mathcal{J}$ 产生一阶变化。由于 $\\mathcal{J}$ 在射线 $\\{cw \\mid c0\\}$ 上是常数，因此这个更新分量完全不会降低无正则化损失。\n如果 $\\lambda$ 很大，更新分量 $-2\\eta\\lambda w$ 的大小可能比 $-\\eta\\nabla_w \\mathcal{J}(w)$ 更大，这意味着优化步骤的很大一部分被“浪费”在收缩 $w$ 上，而这并不会减少损失 $\\mathcalJ$。这可能会阻碍学习过程。该陈述是对这一动态的正确而精确的描述。\n\n**结论：正确**\n\n**B. 将 $w$ 重参数化为 $w = s v$（其中 $s \\in \\mathbb{R}_{0}$ 且 $\\lVert v \\rVert_{2} = 1$），无正则化的损失 $\\mathcal{J}(w,\\gamma,\\beta)$ 同时依赖于 $s$ 和 $v$。因此，$w$ 上的 $\\ell_{2}$ 惩罚项总能独立于所选参数化来衡量函数复杂度。**\n\n我们使用重参数化 $w=sv$，其中 $s = \\lVert w \\rVert_2$ 且 $v = w/\\lVert w \\rVert_2$。如尺度不变性所示，$\\mathcal{J}(w) = \\mathcal{J}(sv) = \\mathcal{J}(v)$。无正则化损失 $\\mathcal{J}$ 仅依赖于方向向量 $v$，而不依赖于尺度 $s$。陈述的第一部分，即断言 $\\mathcal{J}$ 同时依赖于 $s$ 和 $v$，是错误的。\n第二部分声称 $\\ell_2$ 惩罚项是函数复杂度的与参数化无关的度量。该层计算的函数是 $x \\mapsto \\mathrm{LN}(w \\odot x) = \\mathrm{LN}(v \\odot x)$，它与 $s$ 无关。然而，$\\ell_2$ 惩罚项是 $\\lambda \\lVert w \\rVert_2^2 = \\lambda \\lVert sv \\rVert_2^2 = \\lambda s^2$。两个不同的权重向量 $w_1 = s_1 v$ 和 $w_2 = s_2 v$（$s_1 \\neq s_2$）代表完全相同的函数，但具有不同的 $\\ell_2$ 惩罚。因此，$\\ell_2$ 惩罚项不是函数复杂度的度量，而是用于表示该函数的特定参数集的属性。这也使得陈述的第二部分是错误的。\n\n**结论：错误**\n\n**C. 因为层归一化消除了 $z = w \\odot x$ 的尺度，所以 $w$ 上的任何 $\\ell_{2}$ 惩罚都等效于仅惩罚 LN 的增益参数 $\\gamma$。因此，可以选择 $\\gamma$ 来抵消惩罚项对优化动态的影响。**\n\n$w$ 上的 L2 惩罚是 $\\lambda \\lVert w \\rVert_2^2$。对 $\\gamma$ 的惩罚形式为 $\\lambda' \\lVert \\gamma \\rVert_2^2$。该选项声称这两者是等效的。$w$ 的尺度，即 $s=\\lVert w \\rVert_2$，对无正则化损失 $\\mathcal{J}$ 没有影响。正则化目标是 $\\mathcal{J}_{\\lambda}(w) = \\mathcal{J}(v) + \\lambda s^2$。正则化项仅作用于 $s$。\n对 $\\gamma$ 的惩罚将导致一个像 $\\mathcal{J}(v, \\gamma) + \\lambda' \\lVert \\gamma \\rVert_2^2$ 这样的目标函数。这两个目标函数及其梯度在结构上是不同的。例如，第一个目标函数关于 $s$ 的梯度是 $2\\lambda s$，而第二个目标函数关于 $s$ 的梯度是 $0$。它们并不等效。\n第二个主张是，可以选择 $\\gamma$ 来抵消惩罚项的影响。惩罚项的作用是驱使 $\\lVert w \\rVert_2$ 趋向于更小的值。由于输出 $\\mathrm{LN}(w \\odot x)$ 完全独立于 $\\lVert w \\rVert_2$，因此输出没有任何变化需要由 $\\gamma$ 来补偿。$\\gamma$ 的选择会影响 $\\mathcal{J}$ 的值，但它不能与一个依赖于 $\\mathcal{J}$ 本身不敏感的量 $\\lVert w \\rVert_2$ 的惩罚项相互作用或“抵消”它。\n\n**结论：错误**\n\n**D. 在 $\\mathcal{J}(w,\\gamma,\\beta)$ 对 $w$ 具有精确尺度不变性的情况下，范数 $\\lVert w \\rVert_{2}$ 对 $\\mathcal{J}$ 的值没有影响，但当应用权重衰减时，它会影响优化轨迹。此外，将 $w$ 重参数化为 $w=sv$（其中 $\\lVert v \\rVert_{2} = 1$）表明，通过改变 $s$，同一个函数可以用任意小或任意大的 $\\lVert w \\rVert_{2}$ 来表示，因此在存在层归一化的情况下，$\\lVert w \\rVert_{2}$ 的含义是依赖于参数化的。**\n\n我们来逐一分析：\n1.  “...范数 $\\lVert w \\rVert_{2}$ 对 $\\mathcal{J}$ 的值没有影响...”：如前所述，$\\mathcal{J}(w) = \\mathcal{J}(v)$，其中 $v=w/\\lVert w \\rVert_2$，所以这是正确的。\n2.  “...但当应用权重衰减时，它会影响优化轨迹。”：总梯度是 $\\nabla_w \\mathcal{J}(w) + 2\\lambda w$。第二项 $2\\lambda w$ 直接依赖于 $w$，包括其范数。这一项改变了梯度，从而改变了优化轨迹。这是正确的。\n3.  “...通过改变 $s$，同一个函数可以用任意小或任意大的 $\\lVert w \\rVert_{2}$ 来表示...”：函数是 $F(x) = \\mathrm{LN}(w \\odot x)$。我们证明了对于固定的 $v$ 和变化的 $s  0$，任何 $w=sv$ 所对应的 $F(x)$ 都是相同的。范数是 $\\lVert w \\rVert_2 = s$。通过选择 $s$，可以使这个范数任意接近 $0$ 或任意大。这是正确的。\n4.  “...因此 $\\lVert w \\rVert_{2}$ 的含义是依赖于参数化的...”：这是上一点的直接结论。由于函数是固定的，而其参数范数 $\\lVert w \\rVert_2$ 可以变化，所以范数不是函数本身的属性，而是其特定参数化的属性。正确。\n陈述的所有部分在逻辑上都是合理的，并且可以从我们的初始推导中得出。\n\n**结论：正确**\n\n**E. 当存在层归一化时，解耦权重衰减总能改善泛化能力，因为在 LN 下，$\\lVert w \\rVert_{2}$ 是函数复杂度的不变度量。**\n\n“总是”这个词是一个非常强的断言，在深度学习这样复杂的领域中不太可能成立。优化器的性能是经验性的。然而，其提供的理由是明确有缺陷的。该陈述声称改善是“因为在 LN 下，$\\lVert w \\rVert_{2}$ 是函数复杂度的不变度量”。正如在对选项 B 和 D 的分析中所确立的，这是错误的。$\\ell_2$ 范数 $\\lVert w \\rVert_2$ *不是* 由 LN 层计算的函数的不变度量；事实上，函数对范数是不变的，这使得范数成为一个依赖于参数化的量。因为其理由基于一个错误的前提，所以整个陈述是错误的。\n\n**结论：错误**", "answer": "$$\\boxed{AD}$$", "id": "3169330"}]}