{"hands_on_practices": [{"introduction": "中心极限定理（CLT）是概率论的基石，它指出大量独立随机变量之和的分布将近似于正态分布，无论其原始分布形式如何。本次实践旨在直观地展示这一定理。我们将通过模拟一个理想化的多项选择测验场景，其中总分是多个独立随机事件（单题得分）的总和，来观察总分分布如何逼近标志性的钟形曲线，这是理解和应用统计建模的基础一步。 [@problem_id:2405591]", "problem": "考虑一个理想化的多项选择测试环境。一名学生回答一份包含 $Q$ 个独立问题的测试。每个问题提供 $c$ 个选项，其中只有一个是正确的。对于每个问题，学生有概率 $k$ 知道答案（此时选择正确答案的概率为 $1$），或者有概率 $1-k$ 不知道答案（此时学生在 $c$ 个选项中均匀猜测，选择正确答案的概率为 $1/c$）。令 $X_i$ 表示问题 $i$ 被正确回答的指示变量，其中 $i \\in \\{1,\\dots,Q\\}$。正确答案的总数（测试得分）为 $S_Q = \\sum_{i=1}^{Q} X_i$。对于每个固定的三元组 $(Q,c,k)$，每个问题的正确概率为 $p = k + (1-k)/c$，因此 $X_i$ 是参数为 $p$ 的独立同分布的伯努利随机变量。定义标准化分数为 $Z_Q = \\dfrac{S_Q - Q p}{\\sqrt{Q p (1-p)}}$。\n\n根据中心极限定理（CLT），当 $Q \\to \\infty$ 时，$Z_Q$ 的分布近似于标准正态分布。您的任务是执行一次蒙特卡洛计算，通过使用柯尔莫哥洛夫-斯米尔诺夫（KS）距离比较 $Z_Q$ 的经验分布与标准正态分布，从而在有限样本中评估此近似的准确性。\n\n对于下面列出的每个测试用例，您必须：\n- 从上述模型中生成 $N$ 个独立的 $S_Q$ 抽样，每个测试用例的抽样数为 $N = 80000$。\n- 对所有随机数生成使用等于 $20240517$ 的固定随机种子，以确保所有测试用例之间的可复现性。\n- 根据模拟的 $S_Q$ 抽样计算得到的标准化分数 $Z_Q$，计算其经验累积分布函数（empirical CDF）$F_N$。\n- 计算柯尔莫哥洛夫-斯米尔诺夫距离 $D_N = \\sup_{x \\in \\mathbb{R}} \\left| F_N(x) - \\Phi(x) \\right|$，其中 $\\Phi$ 是标准正态累积分布函数。\n\n为每个测试用例报告一个实数，即上面定义的 $D_N$ 值。所有报告的数值输出均以十进制形式表示（不使用任何百分比符号）。\n\n参数值测试套件：\n- 用例 1（一般情况）：$(Q,c,k) = (100,4,0.6)$。\n- 用例 2（小聚合边界）：$(Q,c,k) = (5,4,0.6)$。\n- 用例 3（对称成功概率，大聚合）：$(Q,c,k) = (400,2,0.0)$。\n- 用例 4（稀有成功概率，大聚合）：$(Q,c,k) = (400,20,0.0)$。\n\n最终输出格式：\n您的程序应生成一行输出，其中包含四个用例的结果，按顺序排列，形式为用方括号括起来的逗号分隔列表，例如 $[d_1,d_2,d_3,d_4]$，其中每个 $d_j$ 是为用例 $j \\in \\{1,2,3,4\\}$ 计算出的柯尔莫哥洛夫-斯米尔诺夫距离 $D_N$。", "solution": "问题陈述已经过严格验证，并且是合理的。这是一个计算统计学中定义明确的问题，其基础是概率论的基本原理，特别是中心极限定理（CLT）。任务是使用蒙特卡洛模拟，在数值上评估伯努利随机变量的标准化和收敛到标准正态分布的速率。\n\n该模型描述了一次包含 $Q$ 个问题的测试的总分 $S_Q$。每个问题 $i$ 以固定概率 $p$ 被正确回答，因此其结果是一次独立的伯努利试验 $X_i \\sim \\text{Bernoulli}(p)$。概率 $p$ 由全概率定律导出：\n$$\np = P(\\text{正确}) = P(\\text{正确} | \\text{知道})P(\\text{知道}) + P(\\text{正确} | \\text{猜测})P(\\text{猜测})\n$$\n根据给定参数，此概率为 $p = (1) \\cdot k + (1/c) \\cdot (1-k)$，简化后为 $p = k + (1-k)/c$。\n\n总分 $S_Q = \\sum_{i=1}^{Q} X_i$ 是 $Q$ 个独立同分布（i.i.d.）伯努利随机变量的和。因此，$S_Q$ 服从二项分布，$S_Q \\sim \\text{Binomial}(Q, p)$。$S_Q$ 的期望值（均值）为 $E[S_Q] = Qp$，其方差为 $\\text{Var}(S_Q) = Qp(1-p)$。\n\n中心极限定理断言，标准化分数的分布，\n$$\nZ_Q = \\frac{S_Q - E[S_Q]}{\\sqrt{\\text{Var}(S_Q)}} = \\frac{S_Q - Qp}{\\sqrt{Qp(1-p)}}\n$$\n当 $Q \\to \\infty$ 时，接近标准正态分布 $\\mathcal{N}(0,1)$。该问题要求使用柯尔莫哥洛夫-斯米尔诺夫（KS）距离，对有限 $Q$ 值的这种近似进行定量评估。\n\n计算流程如下：\n1. 对于每个由三元组 $(Q, c, k)$ 指定的测试用例，首先计算成功概率 $p = k + (1-k)/c$。\n2. 通过从分布 $S_Q \\sim \\text{Binomial}(Q, p)$ 中生成 $N = 80000$ 个独立的总分样本 $\\{s_1, s_2, \\dots, s_N\\}$ 来执行蒙特卡洛模拟。这在计算上比模拟 $N \\times Q$ 次独立的伯努利试验更有效率。使用 $20240517$ 的固定随机种子以确保结果的可复现性。\n3. 每个模拟分数 $s_j$ 都被标准化，以获得标准化分数的样本 $\\{z_1, z_2, \\dots, z_N\\}$，其中每个 $z_j$ 按以下方式计算：\n$$\nz_j = \\frac{s_j - Qp}{\\sqrt{Qp(1-p)}}\n$$\n4. 在标准化样本 $\\{z_j\\}$ 的经验累积分布函数（ECDF）和标准正态分布的理论累积分布函数 $\\Phi(x)$ 之间，计算柯尔莫哥洛夫-斯米尔诺夫距离 $D_N$。ECDF 由 $F_N(x) = \\frac{1}{N}\\sum_{j=1}^{N} \\mathbb{I}(z_j \\le x)$ 给出，其中 $\\mathbb{I}$ 是指示函数。KS 距离定义为：\n$$\nD_N = \\sup_{x \\in \\mathbb{R}} |F_N(x) - \\Phi(x)|\n$$\n为四个测试用例中的每一个计算此距离。`scipy.stats.kstest` 函数为此计算提供了一个直接且数值稳定的实现。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import kstest\n\ndef solve():\n    \"\"\"\n    Computes the Kolmogorov-Smirnov distance between the empirical distribution\n    of a standardized test score and the standard normal distribution for several\n    test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (100, 4, 0.6),   # Case 1: general case\n        (5, 4, 0.6),     # Case 2: small aggregation boundary\n        (400, 2, 0.0),   # Case 3: symmetric success probability, large aggregation\n        (400, 20, 0.0),  # Case 4: rare success probability, large aggregation\n    ]\n\n    # Simulation parameters\n    N_draws = 80000\n    seed = 20240517\n\n    # Initialize a random number generator with the specified seed for reproducibility.\n    rng = np.random.default_rng(seed)\n\n    results = []\n    for case in test_cases:\n        Q, c, k = case\n\n        # Step 1: Calculate the per-question correctness probability 'p'.\n        # p = k + (1-k)/c\n        p = k + (1.0 - k) / c\n\n        # Step 2: Generate N draws of the total score S_Q from a Binomial distribution.\n        # S_Q ~ Binomial(Q, p)\n        # Using rng.binomial is more efficient than simulating Q Bernoulli trials N times.\n        s_q_samples = rng.binomial(n=Q, p=p, size=N_draws)\n\n        # Step 3: Compute the standardized scores Z_Q.\n        # Z_Q = (S_Q - E[S_Q]) / sqrt(Var(S_Q))\n        # E[S_Q] = Q * p\n        # Var(S_Q) = Q * p * (1-p)\n        mean_s_q = Q * p\n        std_dev_s_q = np.sqrt(Q * p * (1.0 - p))\n        \n        # Avoid division by zero if variance is zero (p=0 or p=1).\n        # In such a case, S_Q is constant and Z_Q is not well-defined. The KS distance\n        # would be maximal, but the problem cases avoid this scenario.\n        if std_dev_s_q == 0:\n            # This case is not expected based on problem description,\n            # but as a matter of robust implementation, it should be handled.\n            # a constant variable's CDF is a step function. The distance to a\n            # continuous CDF like the normal a distance of 0.5.\n            ks_distance = 0.5\n        else:\n            z_q_samples = (s_q_samples - mean_s_q) / std_dev_s_q\n\n            # Step 4: Compute the Kolmogorov-Smirnov distance D_N.\n            # kstest compares the empirical CDF of the sample with the theoretical\n            # standard normal CDF ('norm'). It returns the KS statistic and the p-value.\n            # We only need the statistic, which corresponds to D_N.\n            ks_statistic, _ = kstest(z_q_samples, 'norm')\n            ks_distance = ks_statistic\n        \n        results.append(ks_distance)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2405591"}, {"introduction": "中心极限定理不仅是一个理论上的奇迹，它更是支撑着大部分统计推断和计量经济学分析的支柱。本练习将揭示 CLT 在普通最小二乘法（OLS）回归中的关键作用，OLS 是经济学与金融分析中不可或缺的工具。你将通过实践证明，OLS 估计量本质上是随机误差项的加权和，因此其抽样分布趋向于正态分布，这正是我们能够对回归系数构建置信区间和进行假设检验的根本依据。 [@problem_id:2405562]", "problem": "考虑一个无截距的简单线性回归模型，每次复制中，您观测到由 $y_i=\\beta x_i+\\epsilon_i$ 生成的 $\\{ (x_i,y_i) \\}_{i=1}^n$，其中 $\\{x_i\\}_{i=1}^n$ 是独立同分布的，服从 $x_i\\sim \\mathcal{N}(0,1)$，而 $\\{\\epsilon_i\\}_{i=1}^n$ 与 $\\{x_i\\}_{i=1}^n$ 相互独立。令 $\\hat{\\beta}$ 表示普通最小二乘 (OLS) 估计量。您的程序必须对下述每个测试案例执行大量独立复制，并在每次复制中：(i) 计算 $\\hat{\\beta}$ 并验证 $\\hat{\\beta}-\\beta$ 可精确分解为误差项的加权和，其中权重仅依赖于已实现的回归变量；(ii) 使用给定回归变量下的精确条件方差对 $\\hat{\\beta}$ 进行标准化，并根据一项正式的拟合优度检验来评估该标准化估计量是否服从标准正态分布。\n\n定义与要求：\n- 普通最小二乘 (OLS)：估计量 $\\hat{\\beta}$ 使残差平方和 $\\sum_{i=1}^n (y_i-b x_i)^2$ 在 $b\\in\\mathbb{R}$ 上最小化。\n- 证明 $\\hat{\\beta}-\\beta$ 可写为有限加权和 $\\sum_{i=1}^n w_i\\epsilon_i$ 的形式，其中权重 $\\{w_i\\}_{i=1}^n$ 仅依赖于 $\\{x_i\\}_{i=1}^n$，并在每次复制中在绝对容忍度 $\\tau=10^{-10}$ 内数值验证此恒等式。\n- 在每次复制中，通过除以精确的条件标准差 $\\sqrt{\\mathrm{Var}(\\hat{\\beta}\\mid \\{x_i\\}_{i=1}^n)}$ 来对 $\\hat{\\beta}$ 进行标准化，其中条件方差必须从第一性原理推导，并用权重 $\\{w_i\\}_{i=1}^n$ 和 $\\{\\epsilon_i\\}_{i=1}^n$ 给定 $\\{x_i\\}_{i=1}^n$ 下的条件方差来表示。\n- 使用 Kolmogorov–Smirnov 拟合优度检验，在显著性水平 $\\alpha=0.05$ 下，评估标准化估计量相对于标准正态分布的正态性。报告一个布尔值：如果标准正态性的零假设不被拒绝，则为真，否则为假。\n- 使用固定的伪随机数生成器种子 $123456789$，以确保结果在不同实现中是可复现的。\n\n测试套件：\n- 案例 A（基准同方差正态误差）：$n=100$，$\\beta=1.7$，$\\epsilon_i\\sim \\mathcal{N}(0,1)$，独立复制次数 $R=4000$。\n- 案例 B（有限方差的重尾分布，大样本）：$n=1000$，$\\beta=-0.8$，$\\epsilon_i = s\\cdot t_{\\nu}$，其中 $\\nu=3$ 且 $s=\\sqrt{(\\nu-2)/\\nu}$，使得 $\\mathrm{Var}(\\epsilon_i)=1$，独立复制次数 $R=4000$。\n- 案例 C（有限方差的重尾分布，小样本）：$n=30$，$\\beta=0.0$，$\\epsilon_i = s\\cdot t_{\\nu}$，其中 $\\nu=3$ 且 $s=\\sqrt{(\\nu-2)/\\nu}$，使得 $\\mathrm{Var}(\\epsilon_i)=1$，独立复制次数 $R=4000$。\n- 案例 D（异方差正态误差）：$n=1000$，$\\beta=2.0$，$\\epsilon_i\\sim \\mathcal{N}(0,\\sigma_i^2)$，其中对 $i\\in\\{1,\\dots,n\\}$，$\\sigma_i^2 = 1+0.5\\cdot i/n$，独立复制次数 $R=4000$。\n\n对于每个案例，您必须在各次复制中独立地生成新的回归变量 $\\{x_i\\}_{i=1}^n$ 和误差 $\\{ \\epsilon_i \\}_{i=1}^n$，强制执行指定的分布假设，并使用精确的条件方差进行标准化。对于异方差案例，条件方差必须考虑非恒定的误差方差。\n\n最终输出要求：\n- 对每个案例，按顺序生成两个布尔值：第一，加权和恒等式是否在所有复制中都在容忍度 $\\tau$ 内成立；第二，对于跨越 $R$ 次复制的标准化估计量集合，标准正态性的零假设是否在水平 $\\alpha$ 下不被拒绝。\n- 将四个案例的结果汇总为单行输出，形式为一个逗号分隔并用方括号括起来的列表，严格按照以下顺序：\n$[\\text{A\\_identity},\\text{A\\_normality},\\text{B\\_identity},\\text{B\\_normality},\\text{C\\_identity},\\text{C\\_normality},\\text{D\\_identity},\\text{D\\_normality}]$。\n- 唯一可接受的输出是布尔值。您的程序应生成单行输出，其中包含一个逗号分隔并用方括号括起来的结果列表（例如，$[ \\text{True},\\text{False},\\dots ]$）。", "solution": "该问题陈述经过了严格验证，并被证实是有效的。它在科学上基于计量经济学和统计学的既定原则，问题设定良好，提供了所有必要的数据和条件，并使用客观、明确的语言进行阐述。这个问题是计算统计学中的一个标准练习，旨在验证普通最小二乘 (OLS) 估计量的理论性质，并探讨中心极限定理 (CLT) 在不同误差项分布假设下的适用性。\n\n我们继续进行求解，这需要先进行解析推导，然后进行数值模拟。\n\n**1. OLS 估计量 $\\hat{\\beta}$ 的推导**\n\n模型是一个无截距的简单线性回归：\n$$ y_i = \\beta x_i + \\epsilon_i $$\nOLS 估计量 $\\hat{\\beta}$ 是使残差平方和 (SSR) $S(b)$ 最小化的 $b$ 值：\n$$ S(b) = \\sum_{i=1}^{n} (y_i - b x_i)^2 $$\n为求最小值，我们对 $S(b)$ 关于 $b$ 求导并令其为零。这给出了一阶条件 (FOC)：\n$$ \\frac{dS}{db} = \\sum_{i=1}^{n} 2(y_i - b x_i)(-x_i) = -2 \\sum_{i=1}^{n} (x_i y_i - b x_i^2) = 0 $$\n解出 $b$，得到 OLS 估计量 $\\hat{\\beta}$：\n$$ \\sum_{i=1}^{n} x_i y_i = \\hat{\\beta} \\sum_{i=1}^{n} x_i^2 $$\n$$ \\hat{\\beta} = \\frac{\\sum_{i=1}^{n} x_i y_i}{\\sum_{i=1}^{n} x_i^2} $$\n最小值的二阶条件是满足的，因为 $\\frac{d^2S}{db^2} = 2 \\sum_{i=1}^{n} x_i^2 > 0$ 几乎必然成立，因为回归变量 $\\{x_i\\}$ 是从连续分布中抽取的，并且它们不全为零的概率为 1。\n\n**2. 加权和恒等式的推导**\n\n我们必须证明 $\\hat{\\beta} - \\beta$ 可以表示为误差项的加权和 $\\sum_{i=1}^n w_i\\epsilon_i$。我们将 $y_i = \\beta x_i + \\epsilon_i$ 代入 $\\hat{\\beta}$ 的公式中：\n$$ \\hat{\\beta} = \\frac{\\sum_{i=1}^{n} x_i (\\beta x_i + \\epsilon_i)}{\\sum_{j=1}^{n} x_j^2} = \\frac{\\beta \\sum_{i=1}^{n} x_i^2 + \\sum_{i=1}^{n} x_i \\epsilon_i}{\\sum_{j=1}^{n} x_j^2} $$\n分离各项可得：\n$$ \\hat{\\beta} = \\frac{\\beta \\sum_{i=1}^{n} x_i^2}{\\sum_{j=1}^{n} x_j^2} + \\frac{\\sum_{i=1}^{n} x_i \\epsilon_i}{\\sum_{j=1}^{n} x_j^2} = \\beta + \\sum_{i=1}^{n} \\left( \\frac{x_i}{\\sum_{j=1}^{n} x_j^2} \\right) \\epsilon_i $$\n整理后得到所需的估计误差表达式：\n$$ \\hat{\\beta} - \\beta = \\sum_{i=1}^{n} w_i \\epsilon_i $$\n其中权重 $w_i$ 由下式给出：\n$$ w_i = \\frac{x_i}{\\sum_{j=1}^{n} x_j^2} $$\n这些权重仅依赖于回归变量样本 $\\{x_i\\}_{i=1}^n$，符合要求。该代数恒等式将在每次复制中以 $\\tau = 10^{-10}$ 的容忍度进行数值验证。\n\n**3. $\\hat{\\beta}$ 的条件方差的推导**\n\n我们需要推导 $\\hat{\\beta}$ 在给定回归变量集合 $\\{x_i\\}_{i=1}^n$ 下的条件方差。当我们以 $\\{x_i\\}$ 为条件时，回归变量以及权重 $\\{w_i\\}$ 被视为非随机常数。\n$$ \\mathrm{Var}(\\hat{\\beta} | \\{x_i\\}_{i=1}^n) = \\mathrm{Var}\\left(\\beta + \\sum_{i=1}^{n} w_i \\epsilon_i \\bigg| \\{x_i\\}_{i=1}^n\\right) $$\n由于 $\\beta$ 是一个常数，其方差为零。误差项 $\\{\\epsilon_i\\}$ 相互独立，并且与回归变量 $\\{x_i\\}$ 独立。因此：\n$$ \\mathrm{Var}(\\hat{\\beta} | \\{x_i\\}) = \\mathrm{Var}\\left(\\sum_{i=1}^{n} w_i \\epsilon_i \\bigg| \\{x_i\\}\\right) = \\sum_{i=1}^{n} w_i^2 \\mathrm{Var}(\\epsilon_i | \\{x_i\\}) = \\sum_{i=1}^{n} w_i^2 \\mathrm{Var}(\\epsilon_i) $$\n令 $\\sigma_{\\epsilon,i}^2 = \\mathrm{Var}(\\epsilon_i)$。条件方差的通用公式为：\n$$ \\mathrm{Var}(\\hat{\\beta} | \\{x_i\\}) = \\sum_{i=1}^{n} \\left(\\frac{x_i}{\\sum_{j=1}^{n} x_j^2}\\right)^2 \\sigma_{\\epsilon,i}^2 = \\frac{\\sum_{i=1}^{n} x_i^2 \\sigma_{\\epsilon,i}^2}{\\left(\\sum_{j=1}^{n} x_j^2\\right)^2} $$\n我们将此通用公式应用于各种情况：\n- **案例 A, B, C (同方差误差):** 在这些案例中，误差具有恒定方差，对所有 $i$ 都有 $\\sigma_{\\epsilon,i}^2 = 1$。公式显著简化为：\n$$ \\mathrm{Var}(\\hat{\\beta} | \\{x_i\\}) = \\frac{\\sum_{i=1}^{n} x_i^2 (1)}{\\left(\\sum_{j=1}^{n} x_j^2\\right)^2} = \\frac{\\sum_{i=1}^{n} x_i^2}{\\left(\\sum_{j=1}^{n} x_j^2\\right)^2} = \\frac{1}{\\sum_{j=1}^{n} x_j^2} $$\n- **案例 D (异方差误差):** 误差方差不恒定，$\\sigma_{\\epsilon,i}^2 = 1 + 0.5 \\cdot i/n$。我们必须使用通用公式：\n$$ \\mathrm{Var}(\\hat{\\beta} | \\{x_i\\}) = \\frac{\\sum_{i=1}^{n} x_i^2 (1 + 0.5 \\cdot i/n)}{\\left(\\sum_{j=1}^{n} x_j^2\\right)^2} $$\n\n**4. 标准化估计量的分布**\n\n对于每次复制，我们计算标准化估计量 $Z$：\n$$ Z = \\frac{\\hat{\\beta} - \\beta}{\\sqrt{\\mathrm{Var}(\\hat{\\beta} | \\{x_i\\})}} $$\n我们评估其分布。\n- **案例 A 和 D:** 误差 $\\{ \\epsilon_i \\}$ 从正态分布中抽取。估计误差 $\\hat{\\beta} - \\beta = \\sum w_i \\epsilon_i$ 是（在 $\\{x_i\\}$ 条件下）正态随机变量的线性组合。因此，它也是条件正态的，均值为 $E[\\sum w_i \\epsilon_i]=0$，方差为 $\\mathrm{Var}(\\hat{\\beta} | \\{x_i\\})$。因此，标准化估计量 $Z$ 是条件 $\\mathcal{N}(0,1)$ 的。由于其分布对 $\\{x_i\\}$ 的任何实现都是 $\\mathcal{N}(0,1)$，其无条件分布也恰好是 $\\mathcal{N}(0,1)$。我们预期 Kolmogorov-Smirnov (KS) 检验不会拒绝标准正态性的零假设。\n\n- **案例 B 和 C:** 误差 $\\{ \\epsilon_i \\}$ 是从自由度为 $\\nu=3$ 的缩放学生 t 分布中抽取的。该分布是对称的，具有有限方差，但它不是正态分布并且具有重尾（其四阶矩为无穷大）。估计误差是独立非同分布随机变量 $w_i\\epsilon_i$ 的和。适用于此类和的中心极限定理 (CLT) 表明，随着样本量 $n \\to \\infty$，标准化估计量的分布将趋近于 $\\mathcal{N}(0,1)$。\n    - **案例 B ($n=1000$):** 样本量很大。中心极限定理应能提供非常好的近似。我们预期 KS 检验不会拒绝零假设。\n    - **案例 C ($n=30$):** 样本量很小。由 CLT 保证的正态收敛速度可能很慢，特别是对于重尾误差分布。我们预期标准化估计量的分布仍会表现出比标准正态分布更肥的尾部，导致 KS 检验拒绝零假设。\n\n**5. 模拟步骤**\n\n对于四个案例中的每一个，我们执行 $R=4000$ 次复制。在每次复制中：\n1. 从 $\\mathcal{N}(0,1)$ 生成回归变量样本 $\\{x_i\\}_{i=1}^n$。\n2. 根据案例指定的分布生成误差样本 $\\{ \\epsilon_i \\}_{i=1}^n$。\n3. 计算 $y_i = \\beta x_i + \\epsilon_i$。\n4. 计算 OLS 估计值 $\\hat{\\beta}$。\n5. 验证恒等式 $|\\hat{\\beta} - \\beta - \\sum w_i \\epsilon_i| < 10^{-10}$。用一个标志位跟踪此条件是否在所有 $R$ 次复制中都成立。\n6. 使用上面推导的适当公式计算精确的条件方差 $\\mathrm{Var}(\\hat{\\beta} | \\{x_i\\})$。\n7. 计算并存储标准化估计量 $Z$。\n\n在一个案例的所有复制完成后，使用 KS 检验在显著性水平 $\\alpha=0.05$ 下，将收集到的 $R$ 个 $Z$ 值与标准正态分布进行比较。如果 p 值大于或等于 $\\alpha$，则不拒绝零假设。每个案例的结果（恒等式验证和正态性检验结果）被记录为布尔值。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import kstest\n\ndef run_simulation(n, beta, err_type, R, tau, alpha):\n    \"\"\"\n    Performs a simulation for a single test case.\n\n    Args:\n        n (int): Sample size.\n        beta (float): True coefficient.\n        err_type (str): Type of error distribution ('norm', 't', 'hetero').\n        R (int): Number of replications.\n        tau (float): Tolerance for identity check.\n        alpha (float): Significance level for KS test.\n\n    Returns:\n        tuple[bool, bool]: A tuple containing:\n            - bool: True if the identity holds for all replications.\n            - bool: True if the normality hypothesis is not rejected.\n    \"\"\"\n    \n    # Store standardized estimators for the KS test\n    z_values = np.zeros(R)\n    \n    # Flag to track if the identity holds across all replications\n    identity_holds_all_reps = True\n\n    # Define error variance parameters for specific cases.\n    nu = 3.0  # Degrees of freedom for t-distribution\n    s = np.sqrt((nu - 2.0) / nu)  # Scale factor for t-distribution\n    \n    # Pre-calculate heteroskedastic variances if needed\n    if err_type == 'hetero':\n        # i is 1-based, so we use arange(1, n+1)\n        sigma_sq_hetero = 1.0 + 0.5 * np.arange(1, n + 1) / n\n\n    for i in range(R):\n        # 1. Generate regressors\n        x = np.random.normal(loc=0.0, scale=1.0, size=n)\n        \n        # 2. Generate errors based on type\n        if err_type == 'norm':\n            epsilon = np.random.normal(loc=0.0, scale=1.0, size=n)\n            sigma_sq_eps = 1.0\n        elif err_type == 't':\n            epsilon = np.random.standard_t(df=nu, size=n) * s\n            sigma_sq_eps = 1.0\n        elif err_type == 'hetero':\n            epsilon = np.random.normal(loc=0.0, scale=np.sqrt(sigma_sq_hetero))\n            sigma_sq_eps = sigma_sq_hetero\n        else:\n            raise ValueError(\"Invalid error type specified.\")\n\n        # 3. Generate dependent variable\n        y = beta * x + epsilon\n\n        # 4. Calculate OLS estimator\n        sum_x_sq = np.sum(x**2)\n        if sum_x_sq == 0: continue # Should not happen with continuous x\n        beta_hat = np.sum(x * y) / sum_x_sq\n\n        # 5. Verify the weighted-sum identity\n        if identity_holds_all_reps: # Avoid repeated calculations if already failed\n            lhs = beta_hat - beta\n            weights = x / sum_x_sq\n            rhs = np.sum(weights * epsilon)\n            if np.abs(lhs - rhs) > tau:\n                identity_holds_all_reps = False\n\n        # 6. Calculate the exact conditional variance\n        if err_type in ['norm', 't']: # Homoskedastic case\n            var_cond = 1.0 / sum_x_sq\n        else: # Heteroskedastic case\n            var_cond = np.sum(x**2 * sigma_sq_eps) / (sum_x_sq**2)\n        \n        std_cond = np.sqrt(var_cond)\n\n        # 7. Compute and store the standardized estimator\n        z_values[i] = (beta_hat - beta) / std_cond\n\n    # Perform Kolmogorov-Smirnov test for normality\n    ks_statistic, p_value = kstest(z_values, 'norm')\n    \n    # Null hypothesis is not rejected if p-value is >= alpha\n    normality_not_rejected = (p_value >= alpha)\n\n    return identity_holds_all_reps, normality_not_rejected\n\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    # Set the fixed seed for reproducibility\n    np.random.seed(123456789)\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'n': 100, 'beta': 1.7, 'err_type': 'norm'},   # Case A\n        {'n': 1000, 'beta': -0.8, 'err_type': 't'},     # Case B\n        {'n': 30, 'beta': 0.0, 'err_type': 't'},      # Case C\n        {'n': 1000, 'beta': 2.0, 'err_type': 'hetero'} # Case D\n    ]\n    \n    # Global parameters\n    R = 4000\n    tau = 1e-10\n    alpha = 0.05\n    \n    results = []\n    for case_params in test_cases:\n        identity_ok, normality_ok = run_simulation(\n            n=case_params['n'],\n            beta=case_params['beta'],\n            err_type=case_params['err_type'],\n            R=R,\n            tau=tau,\n            alpha=alpha\n        )\n        results.extend([identity_ok, normality_ok])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2405562"}, {"introduction": "要真正掌握一个强大的定理，既要了解其适用范围，也要明确其失效的边界。本次实践将通过探索在金融学中用于模拟极端事件的“重尾分布”，来检验中心极限定理的局限性。通过模拟帕累托（Pareto）分布的数据——这种分布不满足经典 CLT 所需的有限方差条件——你将亲眼见证为何熟悉的钟形曲线未能出现，并理解在某些现实场景中，盲目假设正态性可能带来具有误导性的、甚至是危险的结论。 [@problem_id:2405635]", "problem": "考虑从 I 型帕累托分布 (Type I Pareto distribution) 中抽取的独立同分布随机变量 $X_1, X_2, \\dots, X_n$，其尺度参数 $x_m = 1$，尾部指数（形状）参数 $\\alpha > 0$。其累积分布函数为 $F(x) = 1 - x^{-\\alpha}$，其中 $x \\ge 1$。一个经过充分检验的事实是：有限均值存在的充要条件是 $\\alpha > 1$，此时总体均值为 $\\mu = \\dfrac{\\alpha}{\\alpha - 1}$；而有限方差存在的充要条件是 $\\alpha > 2$。大数定律 (Law of Large Numbers, LLN) 要求均值有限，样本均值才能收敛于总体均值。中心极限定理 (Central Limit Theorem, CLT) 则要求均值和方差都有限且方差不为零，标准化的样本均值才能在分布上收敛于标准正态分布。\n\n你的任务是设计并实现一个计算实验，通过模拟来检验中心极限定理在帕累托分布（其中 $\\alpha \\le 2$）下的失效情况，具体方法是考察标准化样本均值的分布；并展示当均值为无穷大（$\\alpha \\le 1$）时的爆炸性缩放现象。该问题设定在计算经济学和金融学的背景下，在这些领域，重尾的收益和损失分布会使得风险聚合中使用的高斯近似方法失效。\n\n你必须从上述基本定义出发，实现以下内容，并且除了这些经过充分检验的事实外，不得使用任何快捷公式：\n\n1. 对于每个 $\\alpha \\in \\{1.5, 2.0\\}$ 和每个样本大小 $n \\in \\{200, 1000, 3000\\}$，模拟从 $x_m = 1$ 的帕累托($\\alpha$)分布中抽取的 $R = 4000$ 次大小为 $n$ 的独立样本重复实验。这里使用逆变换采样法，即如果 $U \\sim \\text{Uniform}(0,1)$，则 $X = U^{-1/\\alpha}$ 服从 $x_m=1$ 的 I 型帕累托($\\alpha$)分布。对于每次重复实验，计算学生化均值 (Studentized mean)\n$$\nT_{n} \\;=\\; \\frac{\\sqrt{n}\\,\\big(\\overline{X}_n - \\mu\\big)}{S_n},\n$$\n其中 $\\mu = \\frac{\\alpha}{\\alpha-1}$ 是真实均值（当 $\\alpha > 1$ 时存在），$\\overline{X}_n = \\frac{1}{n}\\sum_{i=1}^n X_i$ 是样本均值，$S_n$ 是除数为 $n-1$ 的样本标准差。使用 $T_n$ 的 $R$ 个值，计算与标准正态分布的柯尔莫哥洛夫–斯米尔诺夫距离 (Kolmogorov–Smirnov distance)，\n$$\nD_{n} \\;=\\; \\sup_{x \\in \\mathbb{R}} \\Big| \\widehat{F}_{T_n}(x) - \\Phi(x) \\Big|,\n$$\n其中 $\\widehat{F}_{T_n}$ 是 $T_n$ 的 $R$ 个实现值的经验分布函数，$\\Phi$ 是标准正态累积分布函数。报告每个配对 $(\\alpha, n)$ 的 $D_n$ 值。\n\n2. 对于 $\\alpha = 0.8$（均值无限）的情况，为每个 $n \\in \\{200, 1000, 3000\\}$，模拟 $R = 4000$ 次独立重复实验，并计算在所有重复实验中绝对缩放样本均值的中位数，\n$$\nM_n \\;=\\; \\operatorname{median}\\Big( \\big| \\sqrt{n}\\,\\overline{X}_n \\big| \\Big),\n$$\n然后计算布尔指示符\n$$\n\\text{INC} \\;=\\; \\big( M_{200} < M_{1000} \\big) \\land \\big( M_{1000} < M_{3000} \\big),\n$$\n该指示符检验 $\\sqrt{n}\\,\\overline{X}_n$ 的典型量级是否随 $n$ 严格增长。这种增长表明序列 $\\{\\sqrt{n}\\,\\overline{X}_n\\}$ 不是紧的，因此不能收敛于标准正态分布。\n\n为确保科学真实性，所有模拟均使用相同的随机种子 $s = 123456$，以使结果可复现。对于每个 $(\\alpha,n)$ 组合，使用 $R = 4000$ 次重复实验。你可以分批生成样本以控制内存使用，但结果必须与给定种子和规格所蕴含的结果完全一致。\n\n测试套件和要求输出：\n- 使用上文描述的参数集，即：\n  - 对于 $\\alpha = 1.5$：$n \\in \\{200, 1000, 3000\\}$，报告三个值 $D_{200}$、$D_{1000}$、$D_{3000}$。\n  - 对于 $\\alpha = 2.0$：$n \\in \\{200, 1000, 3000\\}$，报告三个值 $D_{200}$、$D_{1000}$、$D_{3000}$。\n  - 对于 $\\alpha = 0.8$：$n \\in \\{200, 1000, 3000\\}$，报告布尔值 $\\text{INC}$ 和三个中位数 $M_{200}$、$M_{1000}$、$M_{3000}$。\n\n最终输出格式：\n你的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表。该列表必须按以下顺序排列：\n$$\n\\big[ D_{200}^{(\\alpha=1.5)}, D_{1000}^{(\\alpha=1.5)}, D_{3000}^{(\\alpha=1.5)}, D_{200}^{(\\alpha=2.0)}, D_{1000}^{(\\alpha=2.0)}, D_{3000}^{(\\alpha=2.0)}, \\text{INC}^{(\\alpha=0.8)}, M_{200}^{(\\alpha=0.8)}, M_{1000}^{(\\alpha=0.8)}, M_{3000}^{(\\alpha=0.8)} \\big].\n$$\n所有报告的 $D_n$ 和 $M_n$ 都必须是实数（浮点数），$\\text{INC}$ 必须是布尔值。不涉及单位。不涉及角度。输出必须是严格符合指定格式的一行。", "solution": "问题陈述已提交以供验证。\n\n**步骤 1：提取给定条件**\n- 独立同分布 (i.i.d.) 随机变量：$X_1, X_2, \\dots, X_n$。\n- 分布：I 型帕累托分布，尺度参数 $x_m = 1$，尾部指数（形状）参数 $\\alpha > 0$。\n- 累积分布函数 (CDF)：$F(x) = 1 - x^{-\\alpha}$，其中 $x \\ge 1$。\n- 矩的存在性：\n    - 有限均值存在当且仅当 (iff) $\\alpha > 1$，此时总体均值为 $\\mu = \\dfrac{\\alpha}{\\alpha - 1}$。\n    - 有限方差存在当且仅当 $\\alpha > 2$。\n- 大数定律 (LLN)：要求有限均值。\n- 中心极限定理 (CLT)：要求有限均值和有限的非零方差。\n- 模拟方法：逆变换采样法，$X = U^{-1/\\alpha}$，其中 $U \\sim \\text{Uniform}(0,1)$。\n- 模拟参数：\n    - 重复次数：$R = 4000$。\n    - 随机种子：$s = 123456$。\n- 任务 1：\n    - 参数：$\\alpha \\in \\{1.5, 2.0\\}$ 且 $n \\in \\{200, 1000, 3000\\}$。\n    - 统计量：学生化均值 $T_{n} = \\frac{\\sqrt{n}\\,\\big(\\overline{X}_n - \\mu\\big)}{S_n}$，其中 $\\overline{X}_n$ 是样本均值，$S_n$ 是除数为 $n-1$ 的样本标准差。\n    - 度量：柯尔莫哥洛夫–斯米尔诺夫距离 $D_{n} = \\sup_{x \\in \\mathbb{R}} \\big| \\widehat{F}_{T_n}(x) - \\Phi(x) \\big|$，其中 $\\widehat{F}_{T_n}$ 是 $T_n$ 的经验累积分布函数，$\\Phi(x)$ 是标准正态累积分布函数。\n- 任务 2：\n    - 参数：$\\alpha = 0.8$。\n    - 样本大小：$n \\in \\{200, 1000, 3000\\}$。\n    - 统计量：$M_n = \\operatorname{median}\\Big( \\big| \\sqrt{n}\\,\\overline{X}_n \\big| \\Big)$，在 $R$ 次重复实验中计算。\n    - 度量：布尔指示符 $\\text{INC} = \\big( M_{200} < M_{1000} \\big) \\land \\big( M_{1000} < M_{3000} \\big)$。\n- 输出格式：单个逗号分隔的列表：$\\big[ D_{200}^{(\\alpha=1.5)}, D_{1000}^{(\\alpha=1.5)}, D_{3000}^{(\\alpha=1.5)}, D_{200}^{(\\alpha=2.0)}, D_{1000}^{(\\alpha=2.0)}, D_{3000}^{(\\alpha=2.0)}, \\text{INC}^{(\\alpha=0.8)}, M_{200}^{(\\alpha=0.8)}, M_{1000}^{(\\alpha=0.8)}, M_{3000}^{(\\alpha=0.8)} \\big]$。\n\n**步骤 2：使用提取的给定条件进行验证**\n根据验证标准对问题进行评估。\n- **科学依据**：该问题坚实地基于已建立的统计理论，包括中心极限定理、大数定律以及帕累托分布等重尾分布的性质。使用蒙特卡洛模拟来研究估计量的渐近行为是计算统计学和计量经济学中一种标准且严谨的方法。\n- **适定性**：该问题定义明确。所有参数（$\\alpha, n, R, s$）、统计量（$T_n, M_n$）和度量（$D_n, \\text{INC}$）都得到了精确定义。过程以算法方式描述，这会导向一个唯一的、可验证的数值结果。\n- **客观性**：该问题以精确、客观的数学和计算语言陈述，不含任何主观性或观点。\n\n**步骤 3：结论与行动**\n该问题是**有效的**。它是一个形式完备的统计学计算实验。将构建一个解决方案。\n\n**解法推导**\n\n这个问题的核心是中心极限定理 (CLT)，它是统计学的基石。经典中心极限定理指出，对于独立同分布的随机变量 $\\{X_i\\}$，若其均值 $\\mu$ 和方差 $\\sigma^2 > 0$ 均有限，则标准化样本均值依分布收敛于标准正态分布：\n$$\n\\frac{\\overline{X}_n - \\mu}{\\sigma/\\sqrt{n}} \\xrightarrow{d} \\mathcal{N}(0,1) \\quad \\text{as} \\quad n \\to \\infty\n$$\n该问题要求通过模拟来展示当这些条件不满足时会发生什么，特别是在帕累托分布中，其尾部厚度由参数 $\\alpha$ 控制。\n\n**模拟的理论背景**\n\n1.  **情况 $\\alpha \\in \\{1.5, 2.0\\}$ (有限均值，无限方差):**\n    对于这些 $\\alpha$ 值，均值存在（$\\alpha=1.5$ 时 $\\mu=3$，$\\alpha=2.0$ 时 $\\mu=2$），但方差是无限的。标准中心极限定理不适用。取而代之的是广义中心极限定理，该定理指出，这类变量的和在经过适当的中心化和缩放后，会收敛到一个非正态的稳定分布。学生化均值 $T_n = \\sqrt{n}(\\overline{X}_n - \\mu)/S_n$ 的渐近分布也不是正态的，因为样本标准差 $S_n$ 不会收敛到一个常数。计算与标准正态CDF $\\Phi(x)$ 的柯尔莫哥洛夫-斯米尔诺夫距离 $D_n$ 的目的，是量化这种向正态性收敛的失败。我们预期即使对于大的 $n$，$D_n$ 也会保持显著大于零，从而表现出一种持久的非正态特性。\n\n2.  **情况 $\\alpha = 0.8$ (无限均值):**\n    对于 $\\alpha < 1$，帕累托分布的均值是无限的。这是对中心极限定理条件更严重的违反；甚至大数定律也失效了。样本均值 $\\overline{X}_n$ 不会收敛到任何常数。稳定分布理论指出，对于 $\\alpha \\in (0, 2)$，和 $\\sum X_i$ 的增长与 $n^{1/\\alpha}$ 成比例。因此，样本均值 $\\overline{X}_n = n^{-1}\\sum X_i$ 的增长与 $n^{1/\\alpha - 1}$ 成比例。所研究的项 $\\sqrt{n}\\,\\overline{X}_n$ 因此应该随 $n$ 缩放，其阶为 $n^{1/2} \\cdot n^{1/\\alpha-1} = n^{1/\\alpha - 1/2}$。对于 $\\alpha=0.8$，此阶为 $n^{1/0.8-0.5} = n^{1.25-0.5} = n^{0.75}$。由于指数为正，该量预期会随 $n$ 增长。该模拟通过计算其量值的中位数 $M_n$ 并验证对于所选的样本大小，它是否是 $n$ 的严格递增函数来检验这一点。这为当总体均值不存在时样本均值的爆炸性特质提供了计算证据。\n\n**实现计划**\n\n模拟将使用 Python 实现，借助 `numpy` 库进行高效的向量化计算，使用 `scipy` 进行柯尔莫哥洛夫-斯米尔诺夫检验。\n\n1.  **初始化**：将使用种子 $s=123456$ 初始化一个随机数生成器，以确保可复现性。\n\n2.  **第 1 部分：计算 $\\alpha \\in \\{1.5, 2.0\\}$ 时的 $D_n$**：\n    对于每对 $(\\alpha, n)$，我们执行 $R=4000$ 次重复实验。\n    a. 生成一个 $R \\times n$ 的均匀随机数矩阵 $U \\sim \\text{Uniform}(0,1)$。\n    b. 使用逆变换法将此矩阵转换为帕累托分布的变量值：$X = U^{-1/\\alpha}$。\n    c. 对 $R$ 行中的每一行，计算样本均值 $\\overline{X}_n$ 和样本标准差 $S_n$（分母为 $n-1$，即 `ddof=1`），为每个统计量产生 $R$ 个值。\n    d. 计算真实均值 $\\mu = \\alpha/(\\alpha-1)$。\n    e. 计算学生化均值 $T_n = \\sqrt{n}(\\overline{X}_n - \\mu) / S_n$ 的 $R$ 个实现值。\n    f. 通过将 $R$ 个 T 值的经验分布与标准正态分布的 CDF $\\Phi(x)$ 进行比较，来计算柯尔莫哥洛夫-斯米尔诺夫统计量 $D_n$。这通过 `scipy.stats.kstest` 完成。\n\n3.  **第 2 部分：计算 $\\alpha=0.8$ 时的 $M_n$ 和 $\\text{INC}$**：\n    对于每个 $n \\in \\{200, 1000, 3000\\}$：\n    a. 生成一个 $R \\times n$ 的帕累托变量值矩阵，其中 $\\alpha=0.8$。\n    b. 为 $R$ 行中的每一行计算样本均值 $\\overline{X}_n$。\n    c. 为每次重复实验计算统计量 $|\\sqrt{n}\\,\\overline{X}_n|$。\n    d. 找到这 $R$ 个值的中位数以获得 $M_n$。\n    e. 在计算出 $M_{200}$、$M_{1000}$ 和 $M_{3000}$ 之后，根据严格不等式条件评估布尔指示符 $\\text{INC}$。\n\n4.  **输出**：计算出的值将按指定顺序收集，并以要求的格式打印。这种严谨的向量化方法确保了正确性和计算效率。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import kstest, norm\n\ndef solve():\n    \"\"\"\n    Performs a computational experiment to test the failure of the Central Limit Theorem\n    for Pareto distributions with heavy tails.\n    \"\"\"\n    # Define simulation parameters from the problem statement.\n    seed = 123456\n    R = 4000\n    rng = np.random.default_rng(seed)\n\n    all_results = []\n\n    # Part 1: Test convergence to Normal for alpha > 1\n    # Cases where mean is finite, but variance is infinite.\n    alphas_part1 = [1.5, 2.0]\n    n_values_part1 = [200, 1000, 3000]\n\n    for alpha in alphas_part1:\n        # The true mean exists for alpha > 1.\n        mu = alpha / (alpha - 1.0)\n        for n in n_values_part1:\n            # Generate R samples of size n in a vectorized manner.\n            # U ~ Uniform(0,1)\n            uniform_samples = rng.uniform(size=(R, n))\n            # X = U^(-1/alpha) gives Pareto(alpha) with x_m=1\n            pareto_samples = uniform_samples**(-1.0 / alpha)\n\n            # Compute sample means and standard deviations for each of the R replications.\n            sample_means = np.mean(pareto_samples, axis=1)\n            # Use ddof=1 for sample standard deviation (n-1 divisor).\n            sample_std_devs = np.std(pareto_samples, axis=1, ddof=1)\n\n            # Compute the Studentized mean T_n for each replication.\n            # Handle the unlikely case of S_n = 0.\n            T_n_values = np.full(R, np.nan)\n            valid_indices = sample_std_devs > 0\n            T_n_values[valid_indices] = np.sqrt(n) * (sample_means[valid_indices] - mu) / sample_std_devs[valid_indices]\n            \n            # Filter out any potential NaN values before the KS test.\n            T_n_values = T_n_values[~np.isnan(T_n_values)]\n\n            # Compute the Kolmogorov-Smirnov distance to the standard normal distribution.\n            # The 'statistic' attribute of the result is the D_n value.\n            ks_result = kstest(T_n_values, norm.cdf)\n            D_n = ks_result.statistic\n            all_results.append(D_n)\n\n    # Part 2: Test explosive scaling for alpha < 1\n    # Case where mean is infinite.\n    alpha_part2 = 0.8\n    n_values_part2 = [200, 1000, 3000]\n    medians = []\n\n    for n in n_values_part2:\n        # Generate R samples of size n.\n        uniform_samples = rng.uniform(size=(R, n))\n        pareto_samples = uniform_samples**(-1.0 / alpha_part2)\n\n        # Compute sample means for each replication.\n        sample_means = np.mean(pareto_samples, axis=1)\n\n        # Compute the absolute scaled sample mean for each replication.\n        abs_scaled_means = np.abs(np.sqrt(n) * sample_means)\n\n        # Compute the median of these values across replications.\n        M_n = np.median(abs_scaled_means)\n        medians.append(M_n)\n\n    # Compute the boolean indicator for strict growth of the median.\n    INC = (medians[0] < medians[1]) and (medians[1] < medians[2])\n\n    all_results.append(INC)\n    all_results.extend(medians)\n\n    # Final print statement in the exact required format.\n    # str() of a boolean is 'True' or 'False', which is a valid representation.\n    output_str_list = [str(r) for r in all_results]\n    print(f\"[{','.join(output_str_list)}]\")\n\nsolve()\n```", "id": "2405635"}]}