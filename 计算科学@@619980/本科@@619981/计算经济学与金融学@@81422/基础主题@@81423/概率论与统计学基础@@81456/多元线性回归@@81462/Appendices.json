{"hands_on_practices": [{"introduction": "要真正掌握多元线性回归，没有什么比从头开始构建一个模型更好的方法了。本练习将指导您使用基本的线性代数知识，实现普通最小二乘法（OLS）来为移动应用的需求建模。通过直接求解正规方程，您不仅将估算出系数，还将执行关键的诊断任务，从而巩固您对从拟合到评估的整个回归工作流程的理解。[@problem_id:2413185]", "problem": "要求您在一个计算金融场景中实现并应用多元线性回归。任务是建立一个移动应用需求的普通最小二乘法（OLS）模型，其中目标变量是下载量。预测变量是价格（单位：美元，USD）、用户评分（$1$到$5$分制）以及在社交媒体上的广告支出（单位：美元，USD）。该模型必须包含一个截距项。所有预测的下载量必须以计数（无单位）表示，所有货币输入均以美元为单位。不涉及任何角度。所有输出必须是指定的布尔、整数或浮点数类型的数值。\n\n您必须从基本定义出发，将OLS视为最小化训练数据上残差平方和的解。除了数值线性代数的基本功能外，您不能依赖任何预先包装好的黑盒模型。您必须使用提供的训练数据来估计模型，然后解答接下来的测试套件。\n\n训练数据：每行给出 $(\\text{价格}, \\text{用户评分}, \\text{社交媒体广告支出}) \\to \\text{下载量}$，其中下载量是计数。\n\n- 第$1$行：$(0.99, 4.5, 12000) \\to 31320$\n- 第$2$行：$(1.99, 4.2, 8000) \\to 24620$\n- 第$3$行：$(0.00, 3.8, 5000) \\to 25700$\n- 第$4$行：$(2.99, 4.7, 15000) \\to 29620$\n- 第$5$行：$(4.99, 4.9, 20000) \\to 30970$\n- 第$6$行：$(1.49, 3.5, 0) \\to 17370$\n- 第$7$行：$(0.00, 4.0, 7000) \\to 27950$\n- 第$8$行：$(3.99, 4.4, 11000) \\to 23820$\n- 第$9$行：$(2.49, 3.9, 6000) \\to 21570$\n- 第$10$行：$(0.99, 4.8, 18000) \\to 36720$\n- 第$11$行：$(1.99, 4.1, 4000) \\to 21440$\n- 第$12$行：$(0.49, 3.6, 2000) \\to 21540$\n\n用于样本外评估的验证数据：每行给出 $(\\text{价格}, \\text{用户评分}, \\text{社交媒体广告支出}) \\to \\text{下载量}$。\n\n- V$1$：$(2.99, 4.0, 9000) \\to 23320$\n- V$2$：$(0.00, 4.9, 16000) \\to 37300$\n- V$3$：$(1.49, 3.7, 4000) \\to 21370$\n\n您必须基于多元线性回归的第一性原理，实现以下内容：\n\n- 通过最小化训练集上的残差平方和，拟合一个以截距、价格、用户评分和广告支出为函数的下载量线性模型。\n- 仅使用训练集计算估计的系数向量和残差方差。\n- 使用拟合后的模型计算以下测试套件所需的量。\n\n测试套件和所需输出：\n\n令$n$表示训练观测值的数量，$k$表示模型参数的数量（包括截距）。这里$n = 12$，$k = 4$。\n\n您的程序必须按顺序计算以下五个结果：\n\n$1.$ 预测任务（正常情况）：使用拟合的模型，预测一个新应用在 $(\\text{价格} = 1.99, \\text{用户评分} = 4.5, \\text{社交媒体广告支出} = 10000)$ 情况下的下载量。输出四舍五入到最近整数（计数）的预测值。\n\n$2.$ 系数提取：输出价格的估计系数，以浮点数形式表示，并四舍五入到$2$位小数。\n\n$3.$ 样本外拟合优度：计算验证集上的决定系数，定义为 $R^{2}_{\\text{test}} = 1 - \\dfrac{\\sum_{i \\in \\text{test}} (y_i - \\hat{y}_i)^2}{\\sum_{i \\in \\text{test}} (y_i - \\bar{y}_{\\text{test}})^2}$，其中 $\\bar{y}_{\\text{test}}$ 是验证集目标的平均值。以浮点数形式输出，并四舍五入到$4$位小数。\n\n$4.$ 价格的统计显著性（边缘情况：小残差方差）：使用双边学生t检验，在显著性水平 $\\alpha = 0.05$ 和自由度为 $n-k$ 的条件下，检验价格系数等于$0$的原假设，其备择假设为价格系数不等于$0$。输出一个布尔值：如果显著则为$True$，否则为$False$。\n\n$5.$ 数值稳定性诊断（多重共线性检查）：使用$2$-范数计算带截距项的训练设计矩阵的谱条件数，即其最大奇异值与最小奇异值之比。以浮点数形式输出，并四舍五入到$2$位小数。\n\n最终输出格式：\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，“[result1,result2,result3,result4,result5]”）。结果必须按指定的确切顺序出现：预测值（整数）、价格系数（浮点数，保留$2$位小数）、测试集$R^{2}$（浮点数，保留$4$位小数）、价格显著性的布尔值、条件数（浮点数，保留$2$位小数）。", "solution": "该问题已通过验证。\n\n### 第1步：提取已知信息\n- **任务**：使用普通最小二乘法（OLS）实现并应用多元线性回归，以模拟移动应用需求。\n- **目标变量（$y$）**：下载量（计数）。\n- **预测变量（$x_j$）**：价格（美元）、用户评分（$1-5$分制）、广告支出（美元）。\n- **模型设定**：一个包含截距项的线性模型。\n- **方法论**：最小化残差平方和。不得使用“黑盒”模型，仅限使用线性代数基本功能。\n- **训练数据**（$n=12$个观测值）：\n  - $(\\text{价格}, \\text{用户评分}, \\text{广告支出}) \\to \\text{下载量}$\n  - $(0.99, 4.5, 12000) \\to 31320$\n  - $(1.99, 4.2, 8000) \\to 24620$\n  - $(0.00, 3.8, 5000) \\to 25700$\n  - $(2.99, 4.7, 15000) \\to 29620$\n  - $(4.99, 4.9, 20000) \\to 30970$\n  - $(1.49, 3.5, 0) \\to 17370$\n  - $(0.00, 4.0, 7000) \\to 27950$\n  - $(3.99, 4.4, 11000) \\to 23820$\n  - $(2.49, 3.9, 6000) \\to 21570$\n  - $(0.99, 4.8, 18000) \\to 36720$\n  - $(1.99, 4.1, 4000) \\to 21440$\n  - $(0.49, 3.6, 2000) \\to 21540$\n- **验证数据**（$3$个观测值）：\n  - $(2.99, 4.0, 9000) \\to 23320$\n  - $(0.00, 4.9, 16000) \\to 37300$\n  - $(1.49, 3.7, 4000) \\to 21370$\n- **常量**：训练观测值数量 $n=12$，模型参数数量 $k=4$。\n- **测试套件**：\n  1.  预测 $(\\text{价格}=1.99, \\text{用户评分}=4.5, \\text{广告支出}=10000)$ 的下载量。输出：整数。\n  2.  提取价格的估计系数。输出：浮点数，保留$2$位小数。\n  3.  在验证集上计算 $R^{2}_{\\text{test}} = 1 - \\dfrac{\\sum_{i \\in \\text{test}} (y_i - \\hat{y}_i)^2}{\\sum_{i \\in \\text{test}} (y_i - \\bar{y}_{\\text{test}})^2}$。输出：浮点数，保留$4$位小数。\n  4.  使用自由度为 $n-k$ 的双边t检验，在 $\\alpha = 0.05$ 的水平下，检验价格系数的显著性。输出：布尔值。\n  5.  计算训练设计矩阵的谱条件数。输出：浮点数，保留$2$位小数。\n\n### 第2步：使用提取的已知信息进行验证\n这个问题是多元线性回归的一个标准、定义明确的应用，是统计学和计量经济学中的一种基本方法。\n- **科学基础**：该问题基于普通最小二乘法（OLS），这是一个核心且成熟的统计理论。其背景对于计算经济学和金融学是现实的。\n- **良构性**：该问题提供了足够的数据（12个观测值用于估计4个参数）来估计模型系数。测试套件中的任务是具体的、明确的，并基于标准统计公式有唯一解。\n- **客观性**：问题陈述使用精确、客观的语言。数据是数值的，所需的计算基于既定的数学公式，而非主观解释。\n- 该问题不违反任何无效性标准。它不是基于错误的前提，是可形式化的，数据是完整的，任务是可验证的。\n\n### 第3步：结论与行动\n该问题被判定为**有效**。将提供一个解决方案。\n\n### 解决方案\n该问题要求使用普通最小二乘法（OLS）拟合一个多元线性回归模型。模型形式如下：\n$$ \\text{downloads} = \\beta_0 + \\beta_1 \\cdot \\text{price} + \\beta_2 \\cdot \\text{user\\_rating} + \\beta_3 \\cdot \\text{ad\\_spend} + \\epsilon $$\n用矩阵表示为 $\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}$，其中 $\\mathbf{y}$ 是观测到的下载量向量，$\\mathbf{X}$ 是设计矩阵，$\\boldsymbol{\\beta}$ 是系数向量，$\\boldsymbol{\\epsilon}$ 是误差向量。\n\nOLS方法找到最小化残差平方和（SSR）$S = \\sum_{i=1}^{n} \\epsilon_i^2$ 的系数向量 $\\hat{\\boldsymbol{\\beta}}$。\n$$ S(\\boldsymbol{\\beta}) = (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^T (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}) $$\n为了最小化该量，我们对其关于 $\\boldsymbol{\\beta}$ 求梯度并设为零：\n$$ \\frac{\\partial S}{\\partial \\boldsymbol{\\beta}} = -2\\mathbf{X}^T\\mathbf{y} + 2\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta} = \\mathbf{0} $$\n这得到了正规方程组：\n$$ (\\mathbf{X}^T\\mathbf{X})\\hat{\\boldsymbol{\\beta}} = \\mathbf{X}^T\\mathbf{y} $$\nOLS估计量 $\\hat{\\boldsymbol{\\beta}}$ 的解由下式给出：\n$$ \\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y} $$\n这个方程将使用数值稳定的线性代数程序求解。\n\n首先，我们从 $n=12$ 个训练观测值构建设计矩阵 $\\mathbf{X}_{\\text{train}}$ 和目标向量 $\\mathbf{y}_{\\text{train}}$。矩阵 $\\mathbf{X}_{\\text{train}}$ 有 $k=4$ 列：一列用于截距（$\\beta_0$），另外三列分别对应三个预测变量。\n$$\n\\mathbf{y}_{\\text{train}} = \\begin{pmatrix} 31320 \\\\ 24620 \\\\ 25700 \\\\ 29620 \\\\ 30970 \\\\ 17370 \\\\ 27950 \\\\ 23820 \\\\ 21570 \\\\ 36720 \\\\ 21440 \\\\ 21540 \\end{pmatrix},\n\\quad\n\\mathbf{X}_{\\text{train}} = \\begin{pmatrix}\n1 & 0.99 & 4.5 & 12000 \\\\\n1 & 1.99 & 4.2 & 8000 \\\\\n1 & 0.00 & 3.8 & 5000 \\\\\n1 & 2.99 & 4.7 & 15000 \\\\\n1 & 4.99 & 4.9 & 20000 \\\\\n1 & 1.49 & 3.5 & 0 \\\\\n1 & 0.00 & 4.0 & 7000 \\\\\n1 & 3.99 & 4.4 & 11000 \\\\\n1 & 2.49 & 3.9 & 6000 \\\\\n1 & 0.99 & 4.8 & 18000 \\\\\n1 & 1.99 & 4.1 & 4000 \\\\\n1 & 0.49 & 3.6 & 2000 \\\\\n\\end{pmatrix}\n$$\n解正规方程组得到 $\\hat{\\boldsymbol{\\beta}} = [\\hat{\\beta}_0, \\hat{\\beta}_1, \\hat{\\beta}_2, \\hat{\\beta}_3]^T$，即估计的系数向量。接下来我们解答测试套件中的问题。\n\n**1. 预测任务**\n一个新的观测值由预测向量 $(\\text{价格}=1.99, \\text{用户评分}=4.5, \\text{广告支出}=10000)$ 给出。我们形成一个带截距的设计向量 $\\mathbf{x}_{\\text{new}}$：\n$$ \\mathbf{x}_{\\text{new}} = \\begin{pmatrix} 1 & 1.99 & 4.5 & 10000 \\end{pmatrix}^T $$\n预测的下载量 $\\hat{y}_{\\text{new}}$ 计算如下：\n$$ \\hat{y}_{\\text{new}} = \\mathbf{x}_{\\text{new}}^T \\hat{\\boldsymbol{\\beta}} $$\n结果四舍五入到最近的整数。\n\n**2. 系数提取**\n价格的估计系数 $\\hat{\\beta}_1$ 是向量 $\\hat{\\boldsymbol{\\beta}}$ 的第二个元素。提取该值并四舍五入到$2$位小数。\n\n**3. 样本外拟合优度**\n验证集的决定系数 $R^{2}_{\\text{test}}$ 计算如下：\n$$ R^{2}_{\\text{test}} = 1 - \\frac{SSR_{\\text{test}}}{SST_{\\text{test}}} $$\n其中 $SSR_{\\text{test}} = \\sum_{i \\in \\text{test}} (y_i - \\hat{y}_i)^2$ 是验证集上的残差平方和，$SST_{\\text{test}} = \\sum_{i \\in \\text{test}} (y_i - \\bar{y}_{\\text{test}})^2$ 是验证集的总平方和。$\\bar{y}_{\\text{test}}$ 是验证数据中观测到的下载量的平均值。预测值 $\\hat{y}_i$ 使用拟合模型生成：$\\hat{\\mathbf{y}}_{\\text{test}} = \\mathbf{X}_{\\text{test}}\\hat{\\boldsymbol{\\beta}}$。结果四舍五入到$4$位小数。\n\n**4. 价格的统计显著性**\n我们使用双边学生t检验来检验原假设 $H_0: \\beta_1 = 0$ 和备择假设 $H_1: \\beta_1 \\neq 0$。t统计量为：\n$$ t = \\frac{\\hat{\\beta}_1 - 0}{SE(\\hat{\\beta}_1)} $$\n系数的标准误 $SE(\\hat{\\beta}_1)$ 是系数协方差矩阵 $\\text{Cov}(\\hat{\\boldsymbol{\\beta}}) = \\hat{\\sigma}^2 (\\mathbf{X}_{\\text{train}}^T \\mathbf{X}_{\\text{train}})^{-1}$ 中相应对角元素的平方根。残差方差 $\\hat{\\sigma}^2$ 是误差方差 $\\sigma^2$ 的一个无偏估计量，由训练数据计算得出：\n$$ \\hat{\\sigma}^2 = \\frac{SSR_{\\text{train}}}{n-k} = \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{n-k} $$\nt分布的自由度为 $df = n-k = 12-4=8$。我们将计算出的t统计量的绝对值 $|t|$ 与在显著性水平 $\\alpha = 0.05$ 和自由度 $df=8$ 下的t分布的临界值 $t_{\\text{crit}}$ 进行比较。如果 $|t| > t_{\\text{crit}}$，则我们拒绝 $H_0$，认为系数是统计显著的。\n\n**5. 数值稳定性诊断**\n训练设计矩阵 $\\mathbf{X}_{\\text{train}}$ 的谱条件数是其最大奇异值（$\\sigma_{\\max}$）与最小奇异值（$\\sigma_{\\min}$）之比：\n$$ \\kappa_2(\\mathbf{X}_{\\text{train}}) = \\frac{\\sigma_{\\max}}{\\sigma_{\\min}} $$\n该值是衡量预测变量中多重共线性程度的指标。高值表示在估计系数时可能存在数值不稳定性。结果四舍五入到$2$位小数。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import t\n\ndef solve():\n    \"\"\"\n    Implements and applies a multiple linear regression model from first principles.\n    \"\"\"\n    # Define the problem data as specified.\n    # Training Data (n=12)\n    y_train_list = [31320, 24620, 25700, 29620, 30970, 17370, 27950, 23820, 21570, 36720, 21440, 21540]\n    X_train_predictors_list = [\n        [0.99, 4.5, 12000], [1.99, 4.2, 8000], [0.00, 3.8, 5000], [2.99, 4.7, 15000],\n        [4.99, 4.9, 20000], [1.49, 3.5, 0], [0.00, 4.0, 7000], [3.99, 4.4, 11000],\n        [2.49, 3.9, 6000], [0.99, 4.8, 18000], [1.99, 4.1, 4000], [0.49, 3.6, 2000]\n    ]\n\n    # Validation Data\n    y_val_list = [23320, 37300, 21370]\n    X_val_predictors_list = [\n        [2.99, 4.0, 9000], [0.00, 4.9, 16000], [1.49, 3.7, 4000]\n    ]\n\n    # New app data for prediction\n    x_new_predictors_list = [1.99, 4.5, 10000]\n    \n    # Convert lists to numpy arrays\n    y_train = np.array(y_train_list, dtype=float)\n    X_train_predictors = np.array(X_train_predictors_list, dtype=float)\n    y_val = np.array(y_val_list, dtype=float)\n    X_val_predictors = np.array(X_val_predictors_list, dtype=float)\n    x_new_predictors = np.array(x_new_predictors_list, dtype=float)\n\n    # Add intercept column to design matrices\n    n_train = X_train_predictors.shape[0]\n    n_val = X_val_predictors.shape[0]\n    X_train = np.hstack([np.ones((n_train, 1)), X_train_predictors])\n    X_val = np.hstack([np.ones((n_val, 1)), X_val_predictors])\n    x_new = np.hstack([1, x_new_predictors])\n    \n    # --- Model Fitting: Solve Normal Equations ---\n    # (X.T @ X) @ beta = X.T @ y\n    XTX = X_train.T @ X_train\n    XTy = X_train.T @ y_train\n    beta_hat = np.linalg.solve(XTX, XTy)\n\n    # --- Test Suite Computations ---\n    results = []\n\n    # 1. Prediction task\n    y_pred_new = x_new @ beta_hat\n    result1 = int(round(y_pred_new))\n    results.append(result1)\n\n    # 2. Coefficient extraction (price)\n    price_coeff = beta_hat[1]\n    result2 = round(price_coeff, 2)\n    results.append(result2)\n\n    # 3. Out-of-sample R-squared\n    y_pred_val = X_val @ beta_hat\n    residuals_val = y_val - y_pred_val\n    ssr_val = np.sum(residuals_val**2)\n    y_mean_val = np.mean(y_val)\n    sst_val = np.sum((y_val - y_mean_val)**2)\n    r2_val = 1 - (ssr_val / sst_val)\n    result3 = round(r2_val, 4)\n    results.append(result3)\n    \n    # 4. Statistical significance of price\n    n = n_train\n    k = X_train.shape[1] # number of parameters\n    df = n - k\n    y_pred_train = X_train @ beta_hat\n    residuals_train = y_train - y_pred_train\n    ssr_train = np.sum(residuals_train**2)\n    sigma_sq_hat = ssr_train / df\n    XTX_inv = np.linalg.inv(XTX)\n    var_beta_hat = sigma_sq_hat * XTX_inv\n    se_price_coeff = np.sqrt(var_beta_hat[1, 1])\n    t_statistic = price_coeff / se_price_coeff\n    alpha = 0.05\n    t_critical = t.ppf(1 - alpha/2, df)\n    result4 = bool(abs(t_statistic) > t_critical)\n    results.append(result4)\n    \n    # 5. Numerical stability diagnostic (condition number)\n    cond_num = np.linalg.cond(X_train, 2)\n    result5 = round(cond_num, 2)\n    results.append(result5)\n\n    # Final print statement in the exact required format.\n    # Example format: [28132,-1803.97,0.9744,True,1367.65]\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2413185"}, {"introduction": "经典线性回归模型建立在几个关键假设之上，其中之一是误差方差恒定，即同方差性。这个蒙特卡洛模拟练习将展示当这一假设被违背时（即出现异方差性）会产生什么后果。您将看到为什么标准的置信区间会产生误导，并学习使用异方差稳健标准误对于进行有效推断的重要性。[@problem_id:2413193]", "problem": "考虑一个含有异方差扰动的线性回归模型。对于每个观测值 $i \\in \\{1,\\dots,n\\}$，设数据生成过程为\n$$\ny_i = \\beta_0 + \\beta_1 \\cdot \\text{income}_i + \\beta_2 \\cdot \\text{educ}_i + \\varepsilon_i,\n$$\n满足外生性条件 $E[\\varepsilon_i \\mid X] = 0$ 和异方差结构\n$$\n\\operatorname{Var}(\\varepsilon_i \\mid X) = \\sigma^2 \\cdot \\text{income}_i,\n$$\n其中 $X$ 表示包含截距项的完整回归变量矩阵。目标是使用蒙特卡洛模拟来证明，在存在异方差的情况下，经典的普通最小二乘法 (OLS) 标准误会失效，而异方差稳健 (HC) 标准误则能渐近地保持正确的覆盖率。\n\n你必须编写一个完整、可运行的程序，该程序能够：\n- 根据上述描述生成合成数据。\n- 通过 OLS 估计回归模型，并计算经典的仅同方差标准误和异方差稳健 (HC) 标准误。\n- 使用标准正态临界值为 $\\beta_1$ 构建名义覆盖率为 $0.95$ 的双侧置信区间。\n- 将实验重复 $R$次独立复制，并报告每种标准误方法的经验覆盖率（即包含真实 $\\beta_1$ 值的置信区间的比例）。\n\n使用以下基本原理进行设计和论证：\n- OLS 估计量被定义为残差平方和的最小化器。残差是观测值 $y_i$ 与回归变量线性组合所蕴含的拟合值之间的偏差。\n- 经典的仅同方差标准误要求假设 $\\operatorname{Var}(\\varepsilon \\mid X) = \\sigma^2 I$，当方差依赖于回归变量时，该标准误是不一致的。\n- 异方差稳健 (HC) 标准误用一个在 $\\operatorname{Var}(\\varepsilon \\mid X)$ 是对角矩阵但与单位矩阵不成比例时仍保持一致的估计量，来替代不正确的同方差残差协方差。\n\n每次复制的数据生成细节：\n- 从形状参数 $k = 4$ 和尺度参数 $\\theta = 12$ 的伽马分布中独立抽取 $\\text{income}_i$（因此 $E[\\text{income}_i] = k \\theta = 48$）。这一选择确保了 $\\text{income}_i$ 严格为正，并具有符合现实的右偏性。\n- 从均值为 $14$、标准差为 $2$ 的正态分布中独立抽取 $\\text{educ}_i$，然后将其裁剪到区间 $[8, 22]$ 内以避免不切实际的数值。\n- 将真实参数向量设置为 $(\\beta_0,\\beta_1,\\beta_2) = (1, 0.8, 0.5)$。\n- 对于每个 $i$，从均值为 $0$、方差为 $\\sigma^2 \\cdot \\text{income}_i$ 的正态分布中抽取 $\\varepsilon_i$。\n- 相应地构造 $y_i$。\n\n置信区间：\n- 对于每次复制，在用 OLS 估计模型后，为 $\\beta_1$ 计算两个置信区间：一个使用经典的仅同方差标准误，另一个使用异方差稳健 (HC) 标准误。在这两种情况下，都使用与 $0.95$ 名义覆盖率相对应的标准正态临界值（即双侧临界值 $z_{0.975}$）。\n- 记录每个区间是否包含真实的 $\\beta_1$ 值。\n\n测试套件：\n对以下参数集 $(n, \\sigma^2, R)$ 运行蒙特卡洛模拟：\n- 情况 A (理想路径): $(n, \\sigma^2, R) = (500, 1.0, 1000)$。\n- 情况 B (小样本): $(n, \\sigma^2, R) = (60, 1.0, 1000)$。\n- 情况 C (更严重的异方差): $(n, \\sigma^2, R) = (500, 3.0, 1000)$。\n- 情况 D (较温和的异方差): $(n, \\sigma^2, R) = (500, 0.2, 1000)$。\n\n随机性与可复现性：\n- 为伪随机数生成器使用一个固定的种子 $20240519$，以确保结果是完全可复现的。\n\n程序输出要求：\n- 对每个测试用例，报告三项内容：使用仅同方差标准误的经验覆盖率（一个浮点数），使用 HC 稳健标准误的经验覆盖率（一个浮点数），以及一个布尔值，指示稳健覆盖率是否比同方差覆盖率更接近名义值 $0.95$（即 $|\\text{robust} - 0.95| < |\\text{classical} - 0.95|$ 是否成立）。\n- 你的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表，每个测试用例对应一个内部列表，例如：\n\"[[cA_classical,cA_robust,bA],[cB_classical,cB_robust,bB],[cC_classical,cC_robust,bC],[cD_classical,cD_robust,bD]]\"\n- 所有覆盖率都必须以小数形式报告（而不是百分比）。\n\n角度单位不适用。不需要物理单位。\n\n你的程序必须是完整且可直接运行的，无需任何用户输入或外部文件，并且必须严格遵守指定的输出格式。", "solution": "所述问题是有效的。它提出了一个定义明确且标准的计量经济学练习，用于展示异方差对普通最小二乘法 (OLS) 估计量所产生推断的影响。数据生成过程有完整的规定，理论概念合理，目标清晰且可量化。任务是执行蒙特卡洛模拟，这是计算统计学和计量经济学中用于评估估计量和统计检验的有限样本性质的一项基本技术。\n\n我们首先将指定的线性回归模型形式化。对于每个观测值 $i=1, \\dots, n$，模型为：\n$$\ny_i = \\beta_0 + \\beta_1 \\cdot \\text{income}_i + \\beta_2 \\cdot \\text{educ}_i + \\varepsilon_i\n$$\n用矩阵表示法，这可以写成 $y = X\\beta + \\varepsilon$，其中 $y$ 是因变量观测值的 $n \\times 1$ 向量，$X$ 是回归变量的 $n \\times p$ 矩阵（$p=3$），$\\beta$ 是真实参数的 $p \\times 1$ 向量，$\\varepsilon$ 是扰动项的 $n \\times 1$ 向量。观测值 $i$ 的回归变量矩阵是 $x_i^T = [1, \\text{income}_i, \\text{educ}_i]$。\n\n该问题对误差项 $\\varepsilon$ 规定了两个关键假设：\n1. 外生性条件：$E[\\varepsilon \\mid X] = 0$。这确保了 OLS 估计量是无偏的。\n2. 异方差的一种特定形式：$\\operatorname{Var}(\\varepsilon_i \\mid X) = \\sigma_i^2 = \\sigma^2 \\cdot \\text{income}_i$。这意味着误差项的方差不是常数，而是依赖于其中一个回归变量。误差向量的完整协方差矩阵是 $\\Omega = \\operatorname{Var}(\\varepsilon \\mid X) = \\operatorname{diag}(\\sigma_1^2, \\dots, \\sigma_n^2)$，它与单位矩阵 $I_n$ 不成比例。\n\n$\\beta$ 的 OLS 估计量是通过最小化残差平方和 $S(\\beta) = (y - X\\beta)^T(y - X\\beta)$ 导出的。其众所周知的解是：\n$$\n\\hat{\\beta}_{OLS} = (X^T X)^{-1} X^T y\n$$\n在外生性假设下，该估计量是无偏的，即 $E[\\hat{\\beta}_{OLS} \\mid X] = \\beta$。然而，为了进行有效的统计推断（构建置信区间和执行假设检验），我们需要一个关于 $\\hat{\\beta}_{OLS}$ 协方差矩阵的一致估计量。OLS 估计量在以 $X$ 为条件下的真实协方差矩阵是：\n$$\n\\operatorname{Var}(\\hat{\\beta}_{OLS} \\mid X) = (X^T X)^{-1} X^T \\Omega X (X^T X)^{-1}\n$$\n\n该模拟比较了这个协方差矩阵的两种估计量。\n\n首先，是经典的、仅同方差的方差估计量。该估计量错误地假设 $\\Omega = \\sigma^2 I_n$。它由下式给出：\n$$\n\\widehat{\\operatorname{Var}}_{classical}(\\hat{\\beta}) = \\hat{s}^2 (X^T X)^{-1}\n$$\n其中 $\\hat{s}^2 = \\frac{1}{n-p} \\sum_{i=1}^n \\hat{\\varepsilon}_i^2$ 是误差方差的标准无偏估计量，而 $\\hat{\\varepsilon}_i = y_i - x_i^T \\hat{\\beta}$ 是 OLS 残差。当存在异方差时，这个公式是不正确的，由此产生的标准误是有偏且不一致的。使用这些标准误构建的置信区间将不具有正确的名义覆盖概率。\n\n其次，是异方差稳健 (HC) 方差估计量，特别是 White (1980) 提出的 HC0 估计量。该估计量不需要同方差假设，并提供了真实协方差矩阵的一致估计。它用 OLS 残差平方构成的对角矩阵 $\\hat{\\Omega} = \\operatorname{diag}(\\hat{\\varepsilon}_1^2, \\dots, \\hat{\\varepsilon}_n^2)$ 来替代真实公式中未知的 $\\Omega$。HC0 估计量是：\n$$\n\\widehat{\\operatorname{Var}}_{HC0}(\\hat{\\beta}) = (X^T X)^{-1} (X^T \\hat{\\Omega} X) (X^T X)^{-1}\n$$\n项 $X^T \\hat{\\Omega} X$ 通常被称为“三明治夹心”。从该估计量派生出的标准误对未知形式的异方差是“稳健”的。渐近地，基于 HC 标准误的置信区间将达到正确的名义覆盖率。\n\n对于每个测试用例 $(n, \\sigma^2, R)$，模拟将按以下步骤进行：\n1. 该过程重复进行 $R$ 次复制。\n2. 在每次复制中，根据指定的数据生成过程，使用真实参数 $(\\beta_0, \\beta_1, \\beta_2) = (1, 0.8, 0.5)$ 生成一个大小为 $n$ 的合成数据集 $(y, X)$。\n3. 使用 OLS 估计模型，以获得 $\\hat{\\beta}$ 和残差 $\\hat{\\varepsilon}$。\n4. 使用经典公式和 HC0 稳健公式计算 $\\hat{\\beta}_1$ 的标准误。这涉及取相应估计协方差矩阵的第二个对角元素（索引为 1）的平方根。\n5. 为 $\\beta_1$ 构建两个 $95\\%$ 置信区间：$[\\hat{\\beta}_1 \\pm z_{0.975} \\cdot SE(\\hat{\\beta}_1)]$，其中 $z_{0.975}$ 是来自标准正态分布的临界值（$z_{0.975} \\approx 1.95996$），$SE(\\hat{\\beta}_1)$ 是相应的标准误估计值。\n6. 对于每个区间，我们检查它是否包含真实值 $\\beta_1 = 0.8$。\n7. 在所有复制完成后，计算每种方法的经验覆盖率，即包含真实参数的区间的比例。将这些覆盖率与名义水平 $0.95$ 进行比较。\n预期结果是，稳健置信区间的经验覆盖率将接近 $0.95$，而经典区间的覆盖率将显著偏离，从而证明了它们在异方差下的失效。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef run_simulation(n, sigma2, R, true_beta, rng):\n    \"\"\"\n    Runs a single Monte Carlo simulation for a given parameter set.\n    \"\"\"\n    beta1_true = true_beta[1]\n    num_params = len(true_beta)\n    \n    # Pre-calculate the critical value for 95% CI\n    # z_crit = 1.959964 is norm.ppf(0.975)\n    z_crit = norm.ppf(1 - 0.05 / 2.0)\n\n    # Counters for coverage\n    classical_hits = 0\n    robust_hits = 0\n\n    for _ in range(R):\n        # 1. Generate data\n        income = rng.gamma(shape=4, scale=12, size=n)\n        educ = rng.normal(loc=14, scale=2, size=n)\n        educ = np.clip(educ, 8, 22)\n        \n        X = np.column_stack((np.ones(n), income, educ))\n        \n        # Generate heteroskedastic errors\n        error_variances = sigma2 * income\n        epsilon = rng.normal(loc=0, scale=np.sqrt(error_variances))\n        \n        y = X @ true_beta + epsilon\n\n        # 2. OLS Estimation\n        try:\n            XTX = X.T @ X\n            XTX_inv = np.linalg.inv(XTX)\n            beta_hat = XTX_inv @ X.T @ y\n        except np.linalg.LinAlgError:\n            continue # Skip iteration if X is singular\n\n        beta1_hat = beta_hat[1]\n        residuals = y - X @ beta_hat\n\n        # 3. Calculate Classical (Homoskedastic) Standard Errors\n        s2_classical = np.sum(residuals**2) / (n - num_params)\n        var_beta_classical = s2_classical * XTX_inv\n        se_beta1_classical = np.sqrt(var_beta_classical[1, 1])\n\n        # 4. Calculate HC0 (Robust) Standard Errors\n        # Efficiently compute the sandwich meat: X^T * diag(res^2) * X\n        sandwich_meat = X.T @ (X * (residuals**2)[:, np.newaxis])\n        var_beta_hc0 = XTX_inv @ sandwich_meat @ XTX_inv\n        \n        # Ensure variance is non-negative due to potential floating point errors\n        var_beta1_hc0 = var_beta_hc0[1, 1]\n        if var_beta1_hc0 < 0:\n            var_beta1_hc0 = 0\n        se_beta1_hc0 = np.sqrt(var_beta1_hc0)\n\n        # 5. Construct Confidence Intervals and check coverage\n        # Classical CI\n        ci_classical_lower = beta1_hat - z_crit * se_beta1_classical\n        ci_classical_upper = beta1_hat + z_crit * se_beta1_classical\n        if ci_classical_lower <= beta1_true <= ci_classical_upper:\n            classical_hits += 1\n\n        # Robust CI\n        ci_robust_lower = beta1_hat - z_crit * se_beta1_hc0\n        ci_robust_upper = beta1_hat + z_crit * se_beta1_hc0\n        if ci_robust_lower <= beta1_true <= ci_robust_upper:\n            robust_hits += 1\n\n    # 6. Calculate empirical coverages\n    coverage_classical = classical_hits / R\n    coverage_robust = robust_hits / R\n\n    # 7. Compare performance\n    is_robust_better = abs(coverage_robust - 0.95) < abs(coverage_classical - 0.95)\n\n    return [coverage_classical, coverage_robust, is_robust_better]\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A: (n, sigma^2, R) = (500, 1.0, 1000)\n        (500, 1.0, 1000),\n        # Case B: (n, sigma^2, R) = (60, 1.0, 1000)\n        (60, 1.0, 1000),\n        # Case C: (n, sigma^2, R) = (500, 3.0, 1000)\n        (500, 3.0, 1000),\n        # Case D: (n, sigma^2, R) = (500, 0.2, 1000)\n        (500, 0.2, 1000),\n    ]\n\n    true_beta = np.array([1.0, 0.8, 0.5])\n    seed = 20240519\n    rng = np.random.default_rng(seed)\n\n    results = []\n    for n, sigma2, R in test_cases:\n        result = run_simulation(n, sigma2, R, true_beta, rng)\n        results.append(result)\n\n    # Format the output string exactly as required\n    output_str = \"[\"\n    for i, res in enumerate(results):\n        cov_c, cov_r, is_better = res\n        # Format boolean as lowercase 'true'/'false'\n        bool_str = 'true' if is_better else 'false'\n        output_str += f\"[{cov_c},{cov_r},{bool_str}]\"\n        if i < len(results) - 1:\n            output_str += \",\"\n    output_str += \"]\"\n    \n    # Final print statement in the exact required format.\n    print(output_str)\n\nsolve()\n```", "id": "2413193"}]}