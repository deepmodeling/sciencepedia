{"hands_on_practices": [{"introduction": "普通最小二乘法 (OLS) 的一个核心假设是外生性，即误差项与回归量不相关。当模型遗漏了一个与解释变量和被解释变量都相关的变量时，这个假设就会被打破，导致有偏和不一致的估计。通过这个练习 [@problem_id:2417165]，你将通过模拟一个经典场景来亲身体验遗漏变量偏误：一个假设的“能力”变量同时影响个体的教育水平和工资。你将看到，在 OLS 回归中忽略“能力”这个变量，会导致对教育回报率的估计出现系统性偏差，从而深刻理解内生性问题的根源及其后果。", "problem": "考虑一个个人工资的数据生成过程，其中计量经济学家将工资对受教育年限进行回归，但存在一种未观测到的能力，它同时影响受教育程度和工资。设真实的结构模型为\n$$\nw_i = \\beta_0 + \\beta_1 \\cdot \\text{edu}_i + \\beta_a \\cdot a_i + u_i,\n$$\n其中，$w_i$是个体$i$的工资，$\\text{edu}_i$是个体$i$的受教育年限，$a_i$是未观测到的能力，而$u_i$是异质性误差。假设受教育程度由以下公式决定\n$$\n\\text{edu}_i = e_0 + \\phi \\cdot a_i + v_i.\n$$\n假设$a_i \\sim \\mathcal{N}(0,\\sigma_a^2)$、$v_i \\sim \\mathcal{N}(0,\\sigma_v^2)$和$u_i \\sim \\mathcal{N}(0,\\sigma_u^2)$，且$a_i$，$v_i$和$u_i$相互独立。计量经济学家估计$w_i$对$\\text{edu}_i$的带截距项回归，其中省略了$a_i$。\n\n您的任务是编写一个完整、可运行的程序。对于一组给定的参数值测试套件，该程序需要根据上述过程模拟数据，为每个测试用例估计$w_i$对$\\text{edu}_i$的带截距项回归中$\\text{edu}_i$的系数，并报告每个用例的以下信息：估计系数$\\hat{\\beta}_1$、偏差$\\hat{\\beta}_1 - \\beta_1$以及估计值是否严格大于真实的$\\beta_1$。\n\n随机性与可复现性：对于测试用例索引$i \\in \\{1,2,3,4,5\\}$，请使用伪随机种子$s_i = s_0 + i$，其中基础种子$s_0 = 12345$。请严格按照规定使用指定的正态分布。所有量均为无量纲，无需物理单位。\n\n待使用的参数值测试套件：\n- 用例1（能力与教育呈正相关；预期会高估）：$N = 100000$, $\\beta_0 = 0$, $\\beta_1 = 0.08$, $\\beta_a = 0.5$, $e_0 = 12$, $\\phi = 0.8$, $\\sigma_a = 1.0$, $\\sigma_v = 1.0$, $\\sigma_u = 1.0$。\n- 用例2（能力与教育无相关性；在概率极限下无遗漏变量偏差）：$N = 100000$, $\\beta_0 = 0$, $\\beta_1 = 0.08$, $\\beta_a = 0.5$, $e_0 = 12$, $\\phi = 0.0$, $\\sigma_a = 1.0$, $\\sigma_v = 1.0$, $\\sigma_u = 1.0$。\n- 用例3（能力与教育呈负相关；预期会低估）：$N = 100000$, $\\beta_0 = 0$, $\\beta_1 = 0.08$, $\\beta_a = 0.5$, $e_0 = 12$, $\\phi = -0.8$, $\\sigma_a = 1.0$, $\\sigma_v = 1.0$, $\\sigma_u = 1.0$。\n- 用例4（教育的真实回报为零；预期会出现伪正估计）：$N = 100000$, $\\beta_0 = 0$, $\\beta_1 = 0.0$, $\\beta_a = 0.5$, $e_0 = 12$, $\\phi = 0.8$, $\\sigma_a = 1.0$, $\\sigma_v = 1.0$, $\\sigma_u = 1.0$。\n- 用例5（能力的方差为零的边界情况；遗漏变量偏差消失）：$N = 100000$, $\\beta_0 = 0$, $\\beta_1 = 0.08$, $\\beta_a = 0.5$, $e_0 = 12$, $\\phi = 0.8$, $\\sigma_a = 0.0$, $\\sigma_v = 1.0$, $\\sigma_u = 1.0$。\n\n要求的最终输出格式：您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表。对于从1到5的每个用例，请依次附加估计系数$\\hat{\\beta}_1$（浮点数）、偏差$\\hat{\\beta}_1 - \\beta_1$（浮点数）以及一个指示$\\hat{\\beta}_1$是否严格大于$\\beta_1$的指示符（布尔值）。因此，输出将是一个长度为15的扁平列表，顺序为$[\\hat{\\beta}_1^{(1)}, \\text{bias}^{(1)}, \\text{over}^{(1)}, \\ldots, \\hat{\\beta}_1^{(5)}, \\text{bias}^{(5)}, \\text{over}^{(5)}]$。", "solution": "问题陈述已通过验证。\n\n**步骤1：提取已知信息**\n\n工资的结构模型由下式给出：\n$w_i = \\beta_0 + \\beta_1 \\cdot \\text{edu}_i + \\beta_a \\cdot a_i + u_i$\n\n教育的模型为：\n$\\text{edu}_i = e_0 + \\phi \\cdot a_i + v_i$\n\n分布假设如下：\n- $a_i \\sim \\mathcal{N}(0, \\sigma_a^2)$\n- $v_i \\sim \\mathcal{N}(0, \\sigma_v^2)$\n- $u_i \\sim \\mathcal{N}(0, \\sigma_u^2)$\n- $a_i$，$v_i$和$u_i$相互独立。\n\n计量经济学家通过将$w_i$对$\\text{edu}_i$进行带截距项的回归来估计一个不完整的模型，其中省略了$a_i$。\n\n随机性规范：\n对于测试用例索引$i \\in \\{1, 2, 3, 4, 5\\}$，伪随机种子为$s_i = s_0 + i$，基础种子$s_0 = 12345$。\n\n测试套件参数：\n- 用例1：$N=100000$, $\\beta_0=0$, $\\beta_1=0.08$, $\\beta_a=0.5$, $e_0=12$, $\\phi=0.8$, $\\sigma_a=1.0$, $\\sigma_v=1.0$, $\\sigma_u=1.0$。\n- 用例2：$N=100000$, $\\beta_0=0$, $\\beta_1=0.08$, $\\beta_a=0.5$, $e_0=12$, $\\phi=0.0$, $\\sigma_a=1.0$, $\\sigma_v=1.0$, $\\sigma_u=1.0$。\n- 用例3：$N=100000$, $\\beta_0=0$, $\\beta_1=0.08$, $\\beta_a=0.5$, $e_0=12$, $\\phi=-0.8$, $\\sigma_a=1.0$, $\\sigma_v=1.0$, $\\sigma_u=1.0$。\n- 用例4：$N=100000$, $\\beta_0=0$, $\\beta_1=0.0$, $\\beta_a=0.5$, $e_0=12$, $\\phi=0.8$, $\\sigma_a=1.0$, $\\sigma_v=1.0$, $\\sigma_u=1.0$。\n- 用例5：$N=100000$, $\\beta_0=0$, $\\beta_1=0.08$, $\\beta_a=0.5$, $e_0=12$, $\\phi=0.8$, $\\sigma_a=0.0$, $\\sigma_v=1.0$, $\\sigma_u=1.0$。\n\n每个用例的所需输出：估计系数$\\hat{\\beta}_1$、偏差$\\hat{\\beta}_1 - \\beta_1$以及一个指示$\\hat{\\beta}_1 > \\beta_1$的布尔值指示符。\n\n**步骤2：使用提取的已知信息进行验证**\n\n- **科学依据**：该问题描述了线性回归中遗漏变量偏差的一个典型例子，这是计量经济学和统计学中的一个基本概念。其模型和假设都是标准的。该问题在科学上是合理的。\n- **适定性**：该问题提供了一个完整的数据生成过程、一个特定的估计任务，并为所有测试用例提供了完全指定的参数。对于给定的随机种子，存在唯一解。该问题是适定的。\n- **客观性**：问题的所有元素都以数学精度进行了定义。没有主观或模棱两可的陈述。该问题是客观的。\n\n**步骤3：结论与行动**\n\n问题有效。将构建一个解决方案。\n\n**解决方案设计**\n\n这个问题的核心在于，当回归模型中遗漏了一个相关变量，并且该遗漏变量与模型中包含的某个回归量相关时，普通最小二乘（OLS）估计量中出现的偏差。\n\n设真实模型为\n$$w_i = \\beta_0 + \\beta_1 \\cdot \\text{edu}_i + \\beta_a \\cdot a_i + u_i$$\n计量经济学家估计的设定错误的模型是\n$$w_i = \\gamma_0 + \\gamma_1 \\cdot \\text{edu}_i + \\epsilon_i$$\n估计模型中的项$\\epsilon_i$是一个复合误差项，它包括了遗漏的变量和原始的异质性误差：$\\epsilon_i = \\beta_a \\cdot a_i + u_i$。\n\n$\\gamma_1$的OLS估计量，我们记为$\\hat{\\beta}_1$，由下式给出\n$$\\hat{\\beta}_1 = \\frac{\\text{Cov}(\\text{edu}, w)}{\\text{Var}(\\text{edu})}$$\n为了理解该估计量的性质，我们考察其概率极限：\n$$\\text{plim}(\\hat{\\beta}_1) = \\frac{\\text{Cov}(\\text{edu}_i, w_i)}{\\text{Var}(\\text{edu}_i)}$$\n将$w_i$的真实结构方程代入：\n$$\\text{plim}(\\hat{\\beta}_1) = \\frac{\\text{Cov}(\\text{edu}_i, \\beta_0 + \\beta_1 \\cdot \\text{edu}_i + \\beta_a \\cdot a_i + u_i)}{\\text{Var}(\\text{edu}_i)}$$\n根据协方差的线性性质以及$\\text{Cov}(\\text{edu}_i, \\beta_0) = 0$这一事实：\n$$\\text{plim}(\\hat{\\beta}_1) = \\frac{\\beta_1 \\cdot \\text{Cov}(\\text{edu}_i, \\text{edu}_i) + \\beta_a \\cdot \\text{Cov}(\\text{edu}_i, a_i) + \\text{Cov}(\\text{edu}_i, u_i)}{\\text{Var}(\\text{edu}_i)}$$\n给定教育的结构模型$\\text{edu}_i = e_0 + \\phi \\cdot a_i + v_i$，以及$a_i, v_i, u_i$的相互独立性，我们有$\\text{Cov}(\\text{edu}_i, u_i) = \\text{Cov}(e_0 + \\phi \\cdot a_i + v_i, u_i) = 0$。\n表达式简化为：\n$$\\text{plim}(\\hat{\\beta}_1) = \\beta_1 + \\beta_a \\frac{\\text{Cov}(\\text{edu}_i, a_i)}{\\text{Var}(\\text{edu}_i)}$$\n项$\\beta_a \\frac{\\text{Cov}(\\text{edu}_i, a_i)}{\\text{Var}(\\text{edu}_i)}$代表渐近遗漏变量偏差。我们可以从给定的假设中推导出它的组成部分：\n$$\\text{Cov}(\\text{edu}_i, a_i) = \\text{Cov}(e_0 + \\phi \\cdot a_i + v_i, a_i) = \\phi \\cdot \\text{Var}(a_i) = \\phi \\sigma_a^2$$\n$$\\text{Var}(\\text{edu}_i) = \\text{Var}(e_0 + \\phi \\cdot a_i + v_i) = \\phi^2 \\cdot \\text{Var}(a_i) + \\text{Var}(v_i) = \\phi^2 \\sigma_a^2 + \\sigma_v^2$$\n因此，渐近偏差为：\n$$\\text{Bias} = \\beta_a \\frac{\\phi \\sigma_a^2}{\\phi^2 \\sigma_a^2 + \\sigma_v^2}$$\n估计量$\\hat{\\beta}_1$是一致的（即偏差为零），当且仅当$\\beta_a = 0$或$\\phi = 0$或$\\sigma_a^2 = 0$。这意味着遗漏变量要么不影响因变量（$w_i$），要么与包含的回归量（$\\text{edu}_i$）不相关，要么其方差为零。\n\n对于每个测试用例，模拟将按以下步骤进行：\n1. 设置伪随机种子为$s_0 + i$以确保可复现性。\n2. 从指定的正态分布中为随机分量$a_i$，$v_i$和$u_i$生成$N$个抽样值。\n3. 使用生成的随机分量和特定用例的参数，根据其结构方程构建观测数据向量$\\text{edu}$和$w$。\n4. 通过将$w$对$\\text{edu}$和截距项进行回归，来估计设定错误的模型的系数。这可以通过标准的OLS矩阵公式$\\hat{\\mathbf{\\beta}} = (\\mathbf{X}^{\\intercal}\\mathbf{X})^{-1}\\mathbf{X}^{\\intercal}\\mathbf{y}$实现，其中$\\mathbf{y}$是$w_i$值的向量，$\\mathbf{X}$是$N \\times 2$的设计矩阵，包含一列全为1的值和一列$\\text{edu}_i$的值。估计系数$\\hat{\\beta}_1$是向量$\\hat{\\mathbf{\\beta}}$的第二个元素。\n5. 计算偏差为$\\hat{\\beta}_1 - \\beta_1$，并判断$\\hat{\\beta}_1$是否大于$\\beta_1$。\n6. 存储这三个结果值（$\\hat{\\beta}_1$、偏差、高估指示符）以供最终报告。\n\n此过程将对所有五个测试用例重复执行，以展示在不同条件下遗漏变量偏差的理论效应。大的样本容量$N=100000$确保了模拟的有限样本估计值将非常接近其理论概率极限。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Simulates data to demonstrate omitted variable bias in OLS regression,\n    estimates coefficients for several parameter sets, and reports the results.\n    \"\"\"\n    # Base seed for pseudo-random number generation.\n    base_seed = 12345\n\n    # Test suite of parameter values.\n    # Each tuple contains:\n    # (N, beta_0, beta_1, beta_a, e_0, phi, sigma_a, sigma_v, sigma_u)\n    test_cases = [\n        (100000, 0, 0.08, 0.5, 12, 0.8, 1.0, 1.0, 1.0),\n        (100000, 0, 0.08, 0.5, 12, 0.0, 1.0, 1.0, 1.0),\n        (100000, 0, 0.08, 0.5, 12, -0.8, 1.0, 1.0, 1.0),\n        (100000, 0, 0.0, 0.5, 12, 0.8, 1.0, 1.0, 1.0),\n        (100000, 0, 0.08, 0.5, 12, 0.8, 0.0, 1.0, 1.0),\n    ]\n\n    results = []\n\n    for i, case in enumerate(test_cases, 1):\n        # Unpack parameters for the current case.\n        N, beta_0, beta_1, beta_a, e_0, phi, sigma_a, sigma_v, sigma_u = case\n        \n        # Set the seed for reproducibility for the current test case.\n        seed = base_seed + i\n        rng = np.random.default_rng(seed)\n\n        # 1. Generate the underlying random variables from their distributions.\n        #    a_i ~ N(0, sigma_a^2)\n        #    v_i ~ N(0, sigma_v^2)\n        #    u_i ~ N(0, sigma_u^2)\n        a = rng.normal(loc=0.0, scale=sigma_a, size=N)\n        v = rng.normal(loc=0.0, scale=sigma_v, size=N)\n        u = rng.normal(loc=0.0, scale=sigma_u, size=N)\n\n        # 2. Construct the variables 'edu' and 'wage' based on the structural model.\n        #    edu_i = e_0 + phi * a_i + v_i\n        edu = e_0 + phi * a + v\n        \n        #    w_i = beta_0 + beta_1 * edu_i + beta_a * a_i + u_i\n        wage = beta_0 + beta_1 * edu + beta_a * a + u\n\n        # 3. Perform OLS regression of wage on edu and an intercept.\n        #    We estimate the model: w_i = gamma_0 + gamma_1 * edu_i + error\n        #    The OLS solution is beta_hat = (X'X)^-1 * X'y\n        \n        # Construct the design matrix X with a column of ones for the intercept.\n        X = np.vstack([np.ones(N), edu]).T\n        \n        # Calculate OLS coefficients.\n        try:\n            # Using the standard matrix formula for OLS coefficients.\n            # beta_hat = [gamma_0_hat, gamma_1_hat]\n            XtX = X.T @ X\n            XtY = X.T @ wage\n            beta_hat_vector = np.linalg.inv(XtX) @ XtY\n        except np.linalg.LinAlgError:\n            # In case of singular matrix, use pseudo-inverse\n            beta_hat_vector = np.linalg.pinv(X) @ wage\n\n        estimated_beta_1 = beta_hat_vector[1]\n\n        # 4. Calculate the bias and the overestimation indicator.\n        bias = estimated_beta_1 - beta_1\n        is_over = estimated_beta_1 > beta_1\n\n        # 5. Append results for this case to the master list.\n        results.extend([estimated_beta_1, bias, is_over])\n\n    # Final print statement in the exact required format.\n    # The list is flattened and elements are converted to strings.\n    formatted_results = [f\"{x:.8f}\" if isinstance(x, float) else str(x) for x in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2417165"}, {"introduction": "“不存在完全多重共线性”是 OLS 能够得出唯一解的基本前提。当一个解释变量可以被其他解释变量线性精确表示时，模型就会陷入完全多重共线性，导致无法估计出唯一确定的系数。这个实践练习 [@problem_id:2417199] 将引导你构建一个落入“虚拟变量陷阱”的设计矩阵，这是完全多重共线性的一个典型例子。通过包含一个截距项和一整套完整的虚拟变量，你将通过计算验证所构建的 $X^{\\top}X$ 矩阵是奇异的（不可逆），从而直观地理解为何这种模型设定在计算上是不可行的。", "problem": "考虑一个通过普通最小二乘法（OLS）估计的线性回归模型，其设计矩阵由一个常数项（截距项）和单个分类回归量的虚拟变量构成。设有 $n$ 个观测值，索引为 $i \\in \\{1,\\dots,n\\}$，并令 $\\ell_i$ 表示观测值 $i$ 的分类标签。令 $(\\ell_1,\\dots,\\ell_n)$ 中不同标签的集合为 $\\{c_1,\\dots,c_K\\}$，其排序满足 $c_1 < \\cdots < c_K$，因此 $K \\ge 1$。对于每个 $j \\in \\{1,\\dots,K\\}$，定义虚拟列 $D_j \\in \\mathbb{R}^n$ 为：如果 $\\ell_i = c_j$，则 $(D_j)_i = 1$；否则 $(D_j)_i = 0$。令 $1_n \\in \\mathbb{R}^n$ 表示全为1的向量。设计矩阵 $X \\in \\mathbb{R}^{n \\times p}$ 将根据两个二进制标志来构建：\n- include\\_intercept $\\in \\{0,1\\}$，指示是否包含常数列 $1_n$，\n- drop\\_baseline $\\in \\{0,1\\}$，指示是否从 $X$ 中删除对应于 $c_1$ 的虚拟列；此标志仅在 include\\_intercept $= 1$ 时相关。\n\n形式上，$X$ 的构建如下：\n- 如果 include\\_intercept $= 1$ 且 drop\\_baseline $= 0$，则 $X = [\\,1_n \\;\\; D_1 \\;\\; D_2 \\;\\; \\cdots \\;\\; D_K\\,]$，因此 $p = K+1$。\n- 如果 include\\_intercept $= 1$ 且 drop\\_baseline $= 1$，则 $X = [\\,1_n \\;\\; D_2 \\;\\; \\cdots \\;\\; D_K\\,]$，因此 $p = K$。\n- 如果 include\\_intercept $= 0$（无论 drop\\_baseline 为何值），则 $X = [\\,D_1 \\;\\; D_2 \\;\\; \\cdots \\;\\; D_K\\,]$，因此 $p = K$。\n\n对于下文定义的每个测试用例，请根据所提供的标签序列和标志构建 $X$，然后确定格拉姆矩阵 $X^{\\top} X \\in \\mathbb{R}^{p \\times p}$ 是否为奇异矩阵。一个方阵 $M$ 是奇异的，当且仅当它是不可逆的（等价于 $\\det(M) = 0$）。\n\n你必须编写一个程序，为每个测试用例输出一个整数：如果 $X^{\\top} X$ 是奇异的，则输出 $1$，否则输出 $0$。请基于构建的 $X$ 使用精确逻辑；不要读取任何外部输入。\n\n测试套件（每个用例是一个三元组 $(\\ell, \\text{include\\_intercept}, \\text{drop\\_baseline})$）：\n- 用例 $1$：$\\ell = (1,2,3,1,2,3)$，include\\_intercept $= 1$，drop\\_baseline $= 0$。\n- 用例 $2$：$\\ell = (1,2,3,1,2,3)$，include\\_intercept $= 1$，drop\\_baseline $= 1$。\n- 用例 $3$：$\\ell = (1,2,3,1,2,3)$，include\\_intercept $= 0$，drop\\_baseline $= 0$。\n- 用例 $4$：$\\ell = (5,5,5,5)$，include\\_intercept $= 1$，drop\\_baseline $= 0$。\n- 用例 $5$：$\\ell = (5,5,5,5)$，include\\_intercept $= 1$，drop\\_baseline $= 1$。\n\n你的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表（例如，“[result1,result2,result3,result4,result5]”）。每个结果必须是如上所述的整数 $1$ 或 $0$。", "solution": "该问题要求分析格拉姆矩阵 $X^{\\top} X$ 的奇异性，其中 $X$ 是由虚拟变量和一个可选的截距项构成的设计矩阵。一个方阵是奇异的，当且仅当其列向量是线性相关的。格拉姆矩阵 $X^{\\top} X$ 是奇异的，当且仅当矩阵 $X$ 的列向量是线性相关的。因此，我们的任务简化为研究在何种条件下 $X$ 的列向量会表现出线性相关性。\n\n令 $n$ 为观测值的数量，令唯一的分类标签集为 $\\{c_1, \\dots, c_K\\}$，其中 $K \\ge 1$。对于每个 $j \\in \\{1, \\dots, K\\}$，列向量 $D_j \\in \\mathbb{R}^n$ 是一个虚拟变量，其中第 $i$ 个元素 $(D_j)_i$ 在观测值 $i$ 的标签为 $c_j$ 时为 $1$，否则为 $0$。这种构造的一个基本性质是，对于任何观测值，有且仅有一个虚拟变量是激活的。这意味着在所有虚拟变量和截距向量 $1_n \\in \\mathbb{R}^n$（一个全为 1 的列向量）之间存在一个线性关系：\n$$ \\sum_{j=1}^{K} D_j = 1_n $$\n这个方程是确定 $X^{\\top} X$ 奇异性的关键。我们按规定分析构建 $X$ 的三种情况。\n\n情况 $1$：`include_intercept` $= 1$，`drop_baseline` $= 0$。\n设计矩阵为 $X = [\\,1_n \\;\\; D_1 \\;\\; D_2 \\;\\; \\cdots \\;\\; D_K\\,]$。$X$ 的列是截距向量 $1_n$ 和所有 $K$ 个虚拟向量 $D_1, \\dots, D_K$。基本关系可以重写为 $X$ 列的线性组合：\n$$ (1) \\cdot 1_n - (1) \\cdot D_1 - (1) \\cdot D_2 - \\cdots - (1) \\cdot D_K = \\mathbf{0}_n $$\n这是一个 $X$ 列的非平凡线性组合（系数向量为 $[1, -1, \\dots, -1]^{\\top}$），其结果等于零向量 $\\mathbf{0}_n$。因此，$X$ 的列向量是线性相关的。这种多重共线性通常被称为“虚拟变量陷阱”。因此，格拉姆矩阵 $X^{\\top} X$ 是奇异的。\n\n情况 $2$：`include_intercept` $= 1$，`drop_baseline` $= 1$。\n设计矩阵为 $X = [\\,1_n \\;\\; D_2 \\;\\; \\cdots \\;\\; D_K\\,]$。基准类别 $c_1$ 的虚拟变量 $D_1$ 被省略。如果 $K=1$，则包含的虚拟向量集为空，因此 $X = [\\,1_n\\,]$。单个非零列向量构成一个线性无关集。其格拉姆矩阵为 $X^{\\top}X = [n]$，对于 $n \\ge 1$ 是非奇异的。\n如果 $K > 1$，我们通过将一个线性组合设为零来测试列 $\\{1_n, D_2, \\dots, D_K\\}$ 的线性无关性：\n$$ \\alpha_0 \\cdot 1_n + \\sum_{j=2}^{K} \\alpha_j D_j = \\mathbf{0}_n $$\n根据问题定义，对于每个类别 $c_j$，至少存在一个具有该标签的观测值 $i$。对于基准类别 $c_1$ 中的一个观测值，方程对应的行变为 $\\alpha_0 \\cdot 1 + \\sum_{j=2}^{K} \\alpha_j \\cdot 0 = 0$，这意味着 $\\alpha_0 = 0$。对于任何其他类别 $c_j$（其中 $j \\ge 2$）中的一个观测值，方程变为 $\\alpha_0 \\cdot 1 + \\alpha_j \\cdot 1 = 0$。既然我们已经发现 $\\alpha_0 = 0$，那么对于所有 $j \\in \\{2, \\dots, K\\}$ 都有 $\\alpha_j = 0$。唯一的解是所有系数都为零的平凡解。因此，$X$ 的列向量是线性无关的，且 $X^{\\top} X$ 是非奇异的。\n\n情况 $3$：`include_intercept` $= 0$。\n设计矩阵为 $X = [\\,D_1 \\;\\; D_2 \\;\\; \\cdots \\;\\; D_K\\,]$。我们测试列 $\\{D_1, \\dots, D_K\\}$ 的线性无关性：\n$$ \\sum_{j=1}^{K} \\alpha_j D_j = \\mathbf{0}_n $$\n对于类别 $c_j$ 中的一个观测值，此向量方程对应的行为 $\\alpha_j \\cdot 1 = 0$，这意味着 $\\alpha_j = 0$。因为这对每个类别 $j \\in \\{1, \\dots, K\\}$ 都成立，所以所有系数都必须为零。$X$ 的列向量是线性无关的，且 $X^{\\top} X$ 是非奇异的。\n\n基于此分析的结果总结：\n- 用例 $1$：$\\ell = (1,2,3,1,2,3)$，`include_intercept` $= 1$，`drop_baseline` $= 0$。此配置与情况 1 的分析相符。结果：奇异 ($1$）。\n- 用例 $2$：$\\ell = (1,2,3,1,2,3)$，`include_intercept` $= 1$，`drop_baseline` $= 1$。此配置与情况 2 的分析相符。结果：非奇异 ($0$）。\n- 用例 $3$：$\\ell = (1,2,3,1,2,3)$，`include_intercept` $= 0$，`drop_baseline` $= 0$。此配置与情况 3 的分析相符。结果：非奇异 ($0$）。\n- 用例 $4$：$\\ell = (5,5,5,5)$，`include_intercept` $= 1$，`drop_baseline` $= 0$。此处 $K=1$。矩阵是 $X = [\\,1_n \\;\\; D_1\\,]$。由于每个观测值都属于同一个类别，因此 $D_1=1_n$，所以 $X=[\\,1_n \\;\\; 1_n\\,]$。这两列完全相同，因此是线性相关的。结果：奇异 ($1$）。\n- 用例 $5$：$\\ell = (5,5,5,5)$，`include_intercept` $= 1$, `drop_baseline` $= 1$。此处 $K=1$。这是情况 2 的一个实例，其中 $X=[\\,1_n\\,]$。它只有一列，秩为 $1$。结果：非奇异 ($0$）。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test suite. For each case, it constructs\n    the design matrix X and determines if the Gram matrix X'X is singular\n    by checking if the rank of X is less than its number of columns.\n    \"\"\"\n    test_cases = [\n        # Case 1: (labels, include_intercept, drop_baseline)\n        ((1, 2, 3, 1, 2, 3), 1, 0),\n        # Case 2\n        ((1, 2, 3, 1, 2, 3), 1, 1),\n        # Case 3\n        ((1, 2, 3, 1, 2, 3), 0, 0),\n        # Case 4\n        ((5, 5, 5, 5), 1, 0),\n        # Case 5\n        ((5, 5, 5, 5), 1, 1),\n    ]\n\n    results = []\n    for l, include_intercept, drop_baseline in test_cases:\n        n = len(l)\n        # The problem statement implies n >= 1 and K >= 1, so no need for n=0 check.\n\n        # Identify unique categories and map them to indices 0, 1, ..., K-1\n        categories = sorted(list(set(l)))\n        K = len(categories)\n        cat_map = {cat: i for i, cat in enumerate(categories)}\n\n        # Construct the full set of K dummy variables efficiently\n        all_dummies = np.zeros((n, K))\n        rows = np.arange(n)\n        cols = [cat_map[label] for label in l]\n        all_dummies[rows, cols] = 1\n\n        # Build the list of columns for the design matrix X\n        X_cols = []\n        \n        if include_intercept == 1:\n            # Add intercept column\n            X_cols.append(np.ones((n, 1)))\n            \n            if drop_baseline == 0:\n                # Add all K dummy variables\n                if K > 0:\n                    X_cols.append(all_dummies)\n            else:  # drop_baseline == 1\n                # Add dummies D_2, ..., D_K\n                if K > 1:\n                    X_cols.append(all_dummies[:, 1:])\n        else:  # include_intercept == 0\n            # Add all K dummy variables\n            if K > 0:\n                X_cols.append(all_dummies)\n\n        # If no columns were selected, the matrix has 0 columns.\n        if not X_cols:\n            p = 0\n            rank = 0\n        else:\n            # Horizontally stack columns to form X\n            X = np.hstack(X_cols)\n            p = X.shape[1]\n            # Calculate the rank of the design matrix X\n            rank = np.linalg.matrix_rank(X)\n\n        # X'X is singular if and only if the columns of X are linearly dependent,\n        # which is true if and only if rank(X) < number of columns of X.\n        is_singular = 1 if rank < p else 0\n        results.append(is_singular)\n\n    # Print the final results in the specified format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2417199"}, {"introduction": "同方差性，即误差项方差恒定，是经典 OLS 理论的重要一环。尽管在异方差存在时，OLS 估计量仍然是无偏和一致的，但其标准误的常规计算公式会失效，从而导致假设检验和置信区间的构建出现错误。本练习 [@problem_id:2417150] 旨在让你通过模拟生成异方差数据，并计算三种不同的系数标准误：经典 OLS 标准误、异方差稳健（White）标准误以及非参数的自助法（Bootstrap）标准误。通过亲手实践和比较这三种方法的结果，你将清晰地看到异方差带来的问题，并掌握在现代计量经济学中应对该问题的关键工具。", "problem": "考虑一个计算经济学和金融学背景下的简单线性回归模型，该模型包含单个回归量和一个截距项。响应变量 $y_i$ 由以下数据生成过程生成：\n$$\ny_i = \\beta_0 + \\beta_1 x_i + u_i,\n$$\n其中，$x_i \\sim \\mathcal{N}(0,1)$ 并且在观测值 $i$ 之间独立同分布，扰动项 $u_i$ 根据以下形式表现出异方差性：\n$$\nu_i = \\sigma_0 \\sqrt{1 + \\gamma x_i^2}\\,\\varepsilon_i,\\quad \\varepsilon_i \\sim \\mathcal{N}(0,1)\\ \\text{independently of}\\ x_i.\n$$\n假设我们关注的系数是斜率 $\\beta_1$。对于下面定义的每个测试用例，使用指定的参数生成一个样本 $\\{(y_i,x_i)\\}_{i=1}^n$，并计算 $\\beta_1$ 的普通最小二乘 (OLS) 估计量的三种标准误估计：\n- 基于经典同方差假设的 OLS 标准误，\n- 异方差一致性 (HC$0$) 标准误（也称为 White 稳健标准误），\n- 基于对观测对 $(y_i,x_i)$ 进行 $B$ 次有放回非参数重抽样的自助法标准误。\n\n为确保可复现性，在每个测试用例中的所有随机抽样均使用相同的固定随机数生成器种子 $s$。在所有计算中，回归模型均包含截距项。将报告的每个标准误表示为四舍五入到六位小数的实数。\n\n测试套件。使用以下参数集；每个项目符号描述一个测试用例：\n- 案例 $1$：$n=500$, $\\beta_0=0.7$, $\\beta_1=1.5$, $\\sigma_0=1.0$, $\\gamma=2.0$, $B=400$, $s=17$。\n- 案例 $2$：$n=500$, $\\beta_0=0.7$, $\\beta_1=1.5$, $\\sigma_0=1.0$, $\\gamma=0.0$, $B=400$, $s=23$。\n- 案例 $3$：$n=50$, $\\beta_0=0.7$, $\\beta_1=1.5$, $\\sigma_0=1.0$, $\\gamma=2.0$, $B=400$, $s=123$。\n- 案例 $4$：$n=500$, $\\beta_0=0.7$, $\\beta_1=1.5$, $\\sigma_0=1.0$, $\\gamma=10.0$, $B=400$, $s=2023$。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个以逗号分隔的列表的列表，并用方括号括起来。每个内部列表对应一个测试用例，顺序与上述相同，并按 [OLS 标准误, White 稳健标准误, 自助法标准误] 的顺序包含三个实数，每个实数都四舍五入到六位小数。例如，输出必须采用以下形式\n$[[a_{1,1},a_{1,2},a_{1,3}],[a_{2,1},a_{2,2},a_{2,3}],[a_{3,1},a_{3,2},a_{3,3}],[a_{4,1},a_{4,2},a_{4,3}]]$\n且不含空格。", "solution": "所提出的问题是计量经济学中一个明确定义的计算练习。它具有科学依据，逻辑上一致，并提供了进行求解所需的所有必要信息。任务是在一个包含异方差性的特定数据生成过程下，计算普通最小二乘 (OLS) 回归系数的标准误的三种不同估计量。\n\n模型是一个简单线性回归：\n$$\ny_i = \\beta_0 + \\beta_1 x_i + u_i\n$$\n对于 $i = 1, \\dots, n$。用矩阵表示法，即为 $\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{u}$，其中 $\\mathbf{y}$ 是响应变量观测值的 $n \\times 1$ 向量，$\\mathbf{X}$ 是 $n \\times 2$ 的设计矩阵，其第一列是全为 1 的向量，第二列是回归量 $x_i$ 的观测值，$\\boldsymbol{\\beta} = [\\beta_0, \\beta_1]^T$ 是 $2 \\times 1$ 的系数向量，$\\mathbf{u}$ 是 $n \\times 1$ 的扰动项向量。\n\n$\\boldsymbol{\\beta}$ 的 OLS 估计量由下式给出：\n$$\n\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}\n$$\n在给定 $\\mathbf{X}$ 的条件下，该估计量的方差-协方差矩阵为：\n$$\n\\text{Var}(\\hat{\\boldsymbol{\\beta}} | \\mathbf{X}) = (\\mathbf{X}^T\\mathbf{X})^{-1} \\mathbf{X}^T \\boldsymbol{\\Omega} \\mathbf{X} (\\mathbf{X}^T\\mathbf{X})^{-1}\n$$\n其中 $\\boldsymbol{\\Omega} = \\text{E}[\\mathbf{u}\\mathbf{u}^T | \\mathbf{X}]$。在此问题中，扰动项 $u_i$ 在观测值之间是独立的，因此 $\\boldsymbol{\\Omega}$ 是一个对角矩阵。异方差结构 $u_i = \\sigma_0 \\sqrt{1 + \\gamma x_i^2}\\,\\varepsilon_i$（其中 $\\varepsilon_i \\sim \\mathcal{N}(0,1)$）意味着 $\\boldsymbol{\\Omega}$ 的对角元素为 $\\text{Var}(u_i|x_i) = \\sigma_i^2 = \\sigma_0^2(1 + \\gamma x_i^2)$。\n\n任务是估计斜率系数的 OLS 估计量 $\\hat{\\beta}_1$ 的标准误，即 $\\text{Var}(\\hat{\\boldsymbol{\\beta}} | \\mathbf{X})$ 的第二个对角元素的平方根。我们将计算该量的三种不同估计值。\n\n1.  **基于经典同方差假设的 OLS 标准误**\n\n这种估计量错误地假设扰动项是同方差的，即对所有 $i$ 都有 $\\text{Var}(u_i|x_i) = \\sigma^2$。在此假设下，$\\boldsymbol{\\Omega} = \\sigma^2\\mathbf{I}_n$，方差-协方差矩阵简化为：\n$$\n\\text{Var}(\\hat{\\boldsymbol{\\beta}} | \\mathbf{X}) = \\sigma^2(\\mathbf{X}^T\\mathbf{X})^{-1}\n$$\n未知的误差方差 $\\sigma^2$ 使用 OLS 残差 $\\hat{u}_i = y_i - (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i)$ 进行估计。$\\sigma^2$ 的无偏估计量是：\n$$\n\\hat{\\sigma}^2 = \\frac{1}{n-k} \\sum_{i=1}^{n} \\hat{u}_i^2\n$$\n其中 $k$ 是回归量的数量，在本例中为 2（截距项和斜率）。估计的经典方差-协方差矩阵为 $\\widehat{\\text{Var}}_{OLS}(\\hat{\\boldsymbol{\\beta}}) = \\hat{\\sigma}^2(\\mathbf{X}^T\\mathbf{X})^{-1}$。$\\hat{\\beta}_1$ 的标准误是该矩阵第二个对角元素的平方根：\n$$\n\\text{SE}_{OLS}(\\hat{\\beta}_1) = \\sqrt{[\\widehat{\\text{Var}}_{OLS}(\\hat{\\boldsymbol{\\beta}})]_{2,2}}\n$$\n\n2.  **异方差一致性 (HC0) 标准误**\n\n这种估计量，也称为 White 或稳健标准误，不假设同方差性。即使 $\\boldsymbol{\\Omega}$ 不是单位矩阵的倍数，它也能提供方差-协方差矩阵的一致性估计。它基于方差的“三明治”公式。“三明治”的中间部分 $\\mathbf{S} = \\mathbf{X}^T \\boldsymbol{\\Omega} \\mathbf{X}$ 通过用 OLS 残差的平方 $\\hat{u}_i^2$ 替换未知的方差 $\\sigma_i^2$ 来进行估计。这就得到了 $\\mathbf{S}$ 的 HC$0$ 估计量：\n$$\n\\hat{\\mathbf{S}}_0 = \\sum_{i=1}^{n} \\hat{u}_i^2 \\mathbf{x}_i \\mathbf{x}_i^T\n$$\n其中 $\\mathbf{x}_i = [1, x_i]^T$ 是设计矩阵 $\\mathbf{X}$ 的第 $i$ 行。于是，HC$0$ 方差-协方差估计量为：\n$$\n\\widehat{\\text{Var}}_{HC0}(\\hat{\\boldsymbol{\\beta}}) = (\\mathbf{X}^T\\mathbf{X})^{-1} \\hat{\\mathbf{S}}_0 (\\mathbf{X}^T\\mathbf{X})^{-1}\n$$\n$\\hat{\\beta}_1$ 相应地标准误为：\n$$\n\\text{SE}_{HC0}(\\hat{\\beta}_1) = \\sqrt{[\\widehat{\\text{Var}}_{HC0}(\\hat{\\boldsymbol{\\beta}})]_{2,2}}\n$$\n当 $\\gamma > 0$ 时，误差确实是异方差的，预计这种估计量会比经典估计量更准确，尤其是在大样本中。当 $\\gamma=0.0$ 时，误差是同方差的，两种估计量应该相似。\n\n3.  **自助法标准误**\n\n自助法提供了一种用于估计标准误的非参数方法。我们使用“配对自助法”，这在存在异方差性的情况下是合适的，因为它将对 $(x_i, y_i)$ 一起进行重抽样，从而保留了回归量与误差项方差之间的未知关系。算法如下：\n    1.  从原始样本 $\\{(y_i, x_i)\\}_{i=1}^n$ 中，通过有放回抽样的方式抽取一个大小为 $n$ 的“自助样本”。\n    2.  使用这个自助样本，计算斜率系数的 OLS 估计值，记为 $\\hat{\\beta}_{1,b}^*$。\n    3.  对大量的复制次数 $B$ 重复步骤 1 和 2。这将产生一个自助法估计值的分布 $\\{\\hat{\\beta}_{1,1}^*, \\dots, \\hat{\\beta}_{1,B}^*\\}$。\n    4.  自助法标准误是这 $B$ 个估计值的样本标准差：\n        $$\n        \\text{SE}_{Boot}(\\hat{\\beta}_1) = \\sqrt{\\frac{1}{B-1} \\sum_{b=1}^{B} (\\hat{\\beta}_{1,b}^* - \\bar{\\beta}_1^*)^2}\n        $$\n        其中 $\\bar{\\beta}_1^* = \\frac{1}{B} \\sum_{b=1}^{B} \\hat{\\beta}_{1,b}^*$。这个过程计算量很大，但它为 $\\hat{\\beta}_1$ 的抽样变异性提供了一个可靠的估计。\n\n实现过程将首先根据指定的参数（$n, \\beta_0, \\beta_1, \\sigma_0, \\gamma$）和随机种子 $s$ 为每个测试用例生成数据。然后，对每个生成的数据集，将计算 OLS 估计值，接着计算三种指定的标准误。结果将按要求进行四舍五入和格式化。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    It generates data, computes OLS and three types of standard errors,\n    and prints the results in the required format.\n    \"\"\"\n\n    test_cases = [\n        # Case 1: n=500, β0=0.7, β1=1.5, σ0=1.0, γ=2.0, B=400, s=17\n        (500, 0.7, 1.5, 1.0, 2.0, 400, 17),\n        # Case 2: n=500, β0=0.7, β1=1.5, σ0=1.0, γ=0.0, B=400, s=23\n        (500, 0.7, 1.5, 1.0, 0.0, 400, 23),\n        # Case 3: n=50, β0=0.7, β1=1.5, σ0=1.0, γ=2.0, B=400, s=123\n        (50, 0.7, 1.5, 1.0, 2.0, 400, 123),\n        # Case 4: n=500, β0=0.7, β1=1.5, σ0=1.0, γ=10.0, B=400, s=2023\n        (500, 0.7, 1.5, 1.0, 10.0, 400, 2023),\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        n, beta0, beta1, sigma0, gamma, B, s = case\n        \n        # Initialize random number generator for reproducibility\n        rng = np.random.default_rng(s)\n\n        # 1. Data Generation\n        x = rng.normal(0, 1, size=n)\n        epsilon = rng.normal(0, 1, size=n)\n        u = sigma0 * np.sqrt(1 + gamma * x**2) * epsilon\n        y = beta0 + beta1 * x + u\n\n        # 2. OLS Estimation\n        X = np.vstack((np.ones(n), x)).T  # Design matrix [1, x_i]\n        \n        try:\n            # Pre-compute (X'X)^-1\n            inv_XTX = np.linalg.inv(X.T @ X)\n            beta_hat = inv_XTX @ X.T @ y\n        except np.linalg.LinAlgError:\n            # Handle rare case of singular matrix\n            all_results.append([np.nan, np.nan, np.nan])\n            continue\n            \n        residuals = y - X @ beta_hat\n        k = X.shape[1] # Number of regressors (intercept + slope)\n\n        # 3. Compute Standard Errors\n\n        # 3.1. Classical (Homoskedastic) OLS Standard Error\n        sigma2_hat = np.sum(residuals**2) / (n - k)\n        var_cov_ols = sigma2_hat * inv_XTX\n        se_ols = np.sqrt(var_cov_ols[1, 1])\n\n        # 3.2. HC0 (White-Robust) Standard Error\n        # S_0 = sum(u_i^2 * x_i * x_i')\n        S0 = X.T @ np.diag(residuals**2) @ X\n        var_cov_hc0 = inv_XTX @ S0 @ inv_XTX\n        se_hc0 = np.sqrt(var_cov_hc0[1, 1])\n\n        # 3.3. Bootstrap Standard Error (Pairs Bootstrap)\n        bootstrap_betas = np.zeros(B)\n        for b in range(B):\n            # Resample pairs (y_i, x_i) with replacement\n            indices = rng.choice(n, size=n, replace=True)\n            y_star = y[indices]\n            X_star = X[indices]\n            \n            try:\n                # OLS on bootstrap sample\n                inv_XTX_star = np.linalg.inv(X_star.T @ X_star)\n                beta_hat_star = inv_XTX_star @ X_star.T @ y_star\n                bootstrap_betas[b] = beta_hat_star[1]\n            except np.linalg.LinAlgError:\n                bootstrap_betas[b] = np.nan\n        \n        # Standard deviation of bootstrap estimates\n        se_boot = np.nanstd(bootstrap_betas, ddof=1)\n\n        # 4. Store rounded results\n        case_results = [\n            round(se_ols, 6),\n            round(se_hc0, 6),\n            round(se_boot, 6)\n        ]\n        all_results.append(case_results)\n\n    # Format output string to be a list of lists with no spaces\n    formatted_results = [repr(r).replace(' ', '') for r in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2417150"}]}