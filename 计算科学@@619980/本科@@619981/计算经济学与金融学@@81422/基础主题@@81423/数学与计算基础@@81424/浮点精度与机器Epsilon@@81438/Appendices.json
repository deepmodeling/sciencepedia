{"hands_on_practices": [{"introduction": "计算机无法精确表示所有实数，这在计算金融中会带来重要影响。本练习 ([@problem_id:2394219]) 将引导你亲手发现浮点数系统在数值 $1$ 附近的“粒度”。这个练习通过一个算法搜索，让你确定在单精度下，一个利率 $r$ 必须达到多大才能在计算上与零区分开来，这对于理解高频交易或微观金融模型中的精度限制至关重要。", "problem": "你的任务是编写一个完整、可运行的程序，以确定有限精度算术如何影响单精度浮点算术中微小利率的可检测性。在国际电工委员会 (IEC) 和电气和电子工程师协会 (IEEE) 的浮点算术标准 (IEEE 754) 的单精度模型（基数为$2$，舍入到最近，偶数优先）下工作，并将利率视为纯小数（不含百分号）。在此模型中，接近$1$的可表示数值是离散分布的，一个利率$r$在单位尺度上与$0$计算上可区分，当且仅当将$r$与$1$相加的单精度结果严格大于$1$。你的目标是仅使用自身遵循单精度语义的浮点运算，稳健地推断出满足条件的最小$r \\gt 0$。\n\n使用的基本原理：\n- IEEE 754 单精度算术使用基数$2$，具有固定精度，并将结果舍入到最近的可表示值，若出现平局则向偶数有效数方向解析。你可以将此舍入规则、舍入的单调性以及非规格化数的作为经过充分测试的事实来假设。\n\n约束条件：\n- 所有旨在反映单精度行为的加法、乘法和除法都必须以单精度执行。不要依赖解析公式来获得答案。相反，应基于 IEEE 754 舍入模型实现一个算法搜索，以找到满足单精度计算 $1 + r$ 严格大于 $1$ 的最小 $r \\gt 0$。\n- 将利率表示为小数（例如，百分之五写为 $0.05$）。不需要单位。\n\n需要实现的任务：\n1. 计算最小的利率 $r \\gt 0$，使得 $1 + r$ 的单精度结果严格大于 $1$。使用完全由单精度运算驱动的迭代减半（二分法风格）方法：从一个单精度 $r$ 开始，不断减小 $r$，直到将其一半加到 $1$ 上不再使 $1$ 在单精度下增加；当减半时仍然使 $1$ 增加的最后一个 $r$ 就是所需的值。\n2. 通过检查步骤1中得到的 $r_{\\min}$，验证边界条件：$1 + \\frac{r_{\\min}}{2}$ 的单精度结果等于 $1$。\n3. 交叉检查计算出的 $r_{\\min}$ 是否与从可信的单精度浮点元数据源获得的、紧邻 $1$ 上方的单精度间距相匹配。\n4. 确认将最小的正单精度非规格化数 $s$ 加到 $1$ 上，其单精度结果等于 $1$。\n5. 应用金融检查：对于在时间 $T = 360$（可解释为月份，但不需要单位）收到的单笔大小为 $C = 1$ 的偿付，以单精度计算差值 $\\frac{1}{(1 + r_{\\min})^{T}} - 1$ 并返回此单一数值。以小数值（而非百分比）报告该值。\n\n测试套件和预期输出：\n- 程序必须按顺序计算以下五个输出，并将它们聚合到一个列表中：\n  - 情况 A (正常路径)：任务1中得到的 $r_{\\min}$ 值，作为一个浮点数。\n  - 情况 B (边界条件)：一个布尔值，表示在单精度下 $1 + \\frac{r_{\\min}}{2} = 1$ 是否成立。\n  - 情况 C (一致性)：一个布尔值，表示 $r_{\\min}$ 是否等于 $1$ 上方的单精度元数据间距。\n  - 情况 D (边缘情况)：一个布尔值，表示对于最小的正非规格化数 $s$，在单精度下 $1 + s = 1$ 是否成立。\n  - 情况 E (应用)：完全以单精度计算的 $\\frac{1}{(1 + r_{\\min})^{360}} - 1$ 的值，作为一个浮点数。\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$[result\\_A,result\\_B,result\\_C,result\\_D,result\\_E]$）。该列表必须严格按顺序包含上述五个值。与任务1到5相关的所有浮点算术都必须以单精度执行，所有比较都必须反映单精度结果。所有输出都必须以普通数字或布尔值的形式报告，不带单位，也不带百分号。", "solution": "该问题要求在涉及小利率的金融计算背景下，研究有限精度算术的局限性，特别是 IEEE 754 单精度标准。核心任务是确定一个最小的正利率 $r$（记为 $r_{\\min}$），当它与 $1$ 相加时，在计算上是可与 $0$ 区分的。这等同于找到最小的正单精度数 $r_{\\min}$，使得浮点运算 $fl(1 + r_{\\min})$ 产生一个严格大于 $1$ 的结果。然后，我们将使用这个值来执行几个验证检查和一个简单的金融计算。\n\n在用于单精度浮点数 (binary32) 的 IEEE 754 标准中，一个数由一个符号位、一个8位偏置指数和一个23位尾数表示。一个规格化数的形式为 $(-1)^S \\times 2^{E-127} \\times (1.f)_{2}$，其中 $S$ 是符号位，$E$ 是指数，$f$ 是尾数。\n\n数值 $1.0$ 在此系统中可以被精确表示。它的符号是 $0$，无偏指数是 $0$（因此偏置指数 $E$ 是 $127$），尾数全为零。有效数隐含为 $1.0$。下一个更大的可表示数具有相同的指数，但尾数的最后一位增加了。这个数是 $1 + 2^{-23}$。因此，$1.0$ 与下一个可表示数之间的间隙是 $2^{-23}$。这个量被称为“最后一位的单位”，或 $ulp(1.0)$。根据默认的“舍入到最近，偶数优先”规则，任何加到 $1.0$ 上的正数 $x < ulp(1.0)/2 = 2^{-24}$ 都将被向下舍入回 $1.0$。如果 $x = 2^{-24}$，则出现平局情况，结果被舍入到“偶数”有效数，也就是 $1.0$ 的有效数。因此，使得 $fl(1 + r_{\\min}) > 1$ 成立的最小数 $r_{\\min}$ 必须是 $ulp(1.0) = 2^{-23}$。\n\n问题要求通过算法发现此值，而不是通过解析推导。\n\n**任务1：$r_{\\min}$ 的算法计算**\n\n我们被指示使用迭代搜索来找到 $r_{\\min}$。该搜索必须找到满足 $fl(1+r) > 1$ 的最小数 $r$。所描述的方法是2的幂次下降法，我们通过从候选值 $r = 1.0$ 开始并反复将其减半来实现。其逻辑是找到一个值 $r$，使得 $fl(1 + r) > 1$ 但 $fl(1 + r/2) = 1$。这可以通过一个循环实现，只要将当前候选值 $r$ 的一半加到 $1$ 上仍然产生大于 $1$ 的结果，循环就继续。当条件不满足时，当前的 $r_k$ 就是我们期望的 $r_{\\min}$。\n\n**任务2：边界条件验证**\n\n根据任务1的构造，$r_{\\min}$ 是序列 $1, 1/2, 1/4, \\dots$ 中使 $fl(1+r_{\\min})>1$ 的最小值。算法在 $fl(1 + r_{\\min}/2) = 1$ 时精确终止。这个检查用于确认我们的算法正确地识别了相对于 $1$ 的机器精度边界。我们将计算 $fl(1.0_{f32} + fl(r_{\\min} / 2.0_{f32}))$ 并验证其等于 $1.0_{f32}$。\n\n**任务3：与浮点元数据交叉检查**\n\n我们通过算法确定的 $r_{\\min}$ 值应该与被称为单精度机器ε的基本机器常数相同，该常数是从 $1.0$ 到下一个更大的可表示浮点数之间的距离。标准数值库提供了对此值的访问。我们将把计算出的 $r_{\\min}$ 与 `numpy.spacing(numpy.float32(1.0))` 的值进行比较，后者是 $ulp(1.0)$ 的可靠来源。这证实了我们算法和理解的正确性。\n\n**任务4：使用最小非规格化数的边缘情况**\n\n非规格化（或非正规）数用于表示比最小规格化数更小的值，填补了 $0$ 和 $\\pm 2^{E_{min}}$ 之间的空白。最小的正单精度非规格化数，我们称之为 $s$，是 $2^{-149}$。这个值比 $r_{\\min} = 2^{-23}$ 小得惊人。当我们计算 $fl(1.0 + s)$ 时，结果会被舍入到最近的可表示数。由于 $s \\ll r_{\\min}/2$，和 $1.0 + s$ 远比下一个可表示数 $1.0 + r_{\\min}$ 更接近 $1.0$。因此，浮点加法的结果必须是 $1.0$。此任务验证了我们对极小数在浮点加法中如何处理的理解。\n\n**任务5：应用金融检查**\n\n这个任务要求我们计算这个最小利率 $r_{\\min}$ 在很长一段时间内的影响。我们必须计算一个金融表达式的值，$D = \\frac{1}{(1 + r_{\\min})^T} - 1$，其中时间周期 $T$ 是 $360$（例如，30年期中的月份数）。所有操作都必须以单精度执行。这表明即使是最小的可计算检测到的利率，在复利作用下，也会导致与零利率情景相比可测量的偏差。操作顺序如下：\n1.  计算 $v_1 = fl(1.0_{f32} + r_{\\min})$。\n2.  计算 $v_2 = fl(v_1^{360.0_{f32}})$。这是一个重复乘法或库中的幂函数，全部以单精度进行。\n3.  计算 $v_3 = fl(1.0_{f32} / v_2)$。\n4.  计算最终结果 $D = fl(v_3 - 1.0_{f32})$。\n结果将是一个小的负数，表示在时间 $T=360$ 的现金流的现值折扣因子与 $1$ 的偏差。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Performs a series of tasks related to single-precision floating-point\n    arithmetic and its application in finance, adhering to strict computational\n    and formatting rules.\n    \"\"\"\n\n    # Define single-precision constants to ensure all arithmetic is performed\n    # in the correct domain.\n    one_f32 = np.float32(1.0)\n    two_f32 = np.float32(2.0)\n\n    # --- Task 1: Compute the smallest rate r_min > 0 ---\n    # We are looking for the smallest r > 0 such that 1 + r > 1 in single precision.\n    # The problem specifies a bisection-style search. We start with r=1 and\n    # repeatedly halve it until adding r/2 to 1 no longer produces a result > 1.\n    # At that point, the current r is the minimal value, r_min.\n    r = one_f32\n    while (one_f32 + (r / two_f32)) > one_f32:\n        r = r / two_f32\n    r_min = r\n    result_A = r_min\n\n    # --- Task 2: Verify the boundary condition ---\n    # Check that adding half of r_min to 1 results in 1, confirming r_min is\n    # the minimal representable increment.\n    is_boundary_correct = (one_f32 + (r_min / two_f32)) == one_f32\n    result_B = is_boundary_correct\n\n    # --- Task 3: Cross-check with floating-point metadata ---\n    # Compare r_min with the value of ULP(1.0) (unit in the last place) for\n    # single precision, also known as machine epsilon relative to 1.\n    # np.spacing(1.0) gives the distance between 1.0 and the next larger float.\n    spacing_at_one = np.spacing(one_f32)\n    is_consistent = (r_min == spacing_at_one)\n    result_C = is_consistent\n\n    # --- Task 4: Confirm edge case with smallest subnormal number ---\n    # The smallest positive single-precision number is np.finfo.tiny.\n    # Adding this to 1 should result in 1 due to rounding.\n    s_subnormal = np.finfo(np.float32).tiny\n    is_subnormal_rounded = (one_f32 + s_subnormal) == one_f32\n    result_D = is_subnormal_rounded\n\n    # --- Task 5: Applied finance check ---\n    # Compute the discount factor deviation over 360 periods using r_min.\n    # All calculations must be performed in single precision.\n    T = np.float32(360.0)\n    one_plus_r_min = one_f32 + r_min\n    # The power operation must also respect single precision.\n    # numpy's ** operator on float32 types maintains float32 precision.\n    compounded_factor = one_plus_r_min ** T\n    inverse_factor = one_f32 / compounded_factor\n    finance_result = inverse_factor - one_f32\n    result_E = finance_result\n\n    # Aggregate results into a list for final output.\n    results = [\n        result_A,\n        result_B,\n        result_C,\n        result_D,\n        result_E\n    ]\n\n    # Final print statement in the exact required format.\n    # The map(str, ...) converts each element, including booleans, to its\n    # string representation ('True', 'False', or the number as a string).\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2394219"}, {"introduction": "在掌握了精度极限的基本概念后，我们将探讨一个常见且危险的陷阱：“灾难性抵消”(catastrophic cancellation)。本练习 ([@problem_id:2394271]) 通过一个浮动利率债券的估值案例，展示了当一个很小的利差与一个较大的利率相加时，直接套用公式会如何导致错误的结果。通过本练习，你将学会如何通过代数重构公式来创建数值稳定的算法，这是每位量化分析师都必须掌握的关键技能。", "problem": "要求您编写一个完整、可运行的程序，该程序在风险中性估值下对浮动利率债券进行定价，同时揭示浮点精度和机器ε对计算的影响。请遵循风险中性测度下现金流折现的第一性原理：现值等于所有付息日的折现期望现金流之和，加上折现后的本金偿还。使用以下基本依据。\n1. 风险中性测度下的现值：现值等于现金流与相应折现因子乘积的总和。\n2. 第 $i$ 期的浮动利率票息等于 $(L_i + m)\\,\\alpha_i\\,N$，其中 $L_i$ 是给定的第 $i$ 期的远期利率，$m$ 是每次重置时增加的固定利差，$\\alpha_i$ 是该期的计息分数，$N$ 是名义本金。\n3. 当折现因子由单利远期利率 $L_i$ 和计息分数 $\\alpha_i$ 构建时，它们满足递推关系 $D_0 = 1$ 和 $D_i = \\dfrac{D_{i-1}}{1 + L_i \\alpha_i}$，其中 $i = 1,\\dots,T$，$D_i$ 是到时间点 $i$ 的折现因子，$T$ 是总期数。\n4. 于是，现值为 $PV = N \\left( \\sum_{i=1}^{T} (L_i + m)\\,\\alpha_i\\,D_i + D_T \\right)$，其中 $D_i$ 通过上述递推关系获得，$D_T$ 用于折现本金 $N$ 的赎回。\n\n您的任务是实现两种数值上不同的现值计算方法：\n- 一种直接在每次票息计算中使用 $(L_i + m)$ 的朴素评估法。\n- 一种代数上等价的评估法，通过使用在实数算术中有效的恒等式重新排列项，来避免将一个非常小的数与一个大得多的数相加；具体来说，在计算利差的贡献时，不要先将其加到 $L_i$ 上。两种方法都必须使用相同的折现因子 $D_i$。\n\n您的程序必须执行以下测试套件，每个测试用例都由名义本金 $N$、利差 $m$、远期利率列表或规则 $\\{L_i\\}_{i=1}^T$ 以及计息分数列表 $\\{\\alpha_i\\}_{i=1}^T$ 完全指定。在所有情况下，用于估值的折现因子 $D_i$ 都必须通过递推关系 $D_0 = 1$, $D_i = \\dfrac{D_{i-1}}{1 + L_i \\alpha_i}$（其中 $i = 1,\\dots,T$）从给定的 $L_i$ 和 $\\alpha_i$ 导出。\n\n测试用例A（理想路径，利差不可忽略）：\n- $N = 1{,}000{,}000$。\n- $T = 8$，按季度计息：对所有 $i$，$\\alpha_i = 0.25$。\n- 远期利率： $L = [0.021,\\, 0.022,\\, 0.0235,\\, 0.024,\\, 0.025,\\, 0.026,\\, 0.027,\\, 0.028]$。\n- 利差： $m = 0.0005$。\n\n测试用例B（利差远小于典型利率附近的舍入单位；说明浮点精度造成的损失）：\n- $N = 1{,}000{,}000{,}000$。\n- $T = 8$，按季度计息：对所有 $i$，$\\alpha_i = 0.25$。\n- 远期利率：使用与测试用例A中相同的列表。\n- 利差： $m = 1 \\times 10^{-20}$。\n\n测试用例C（边界情况：零利差）：\n- $N = 2{,}000{,}000$。\n- $T = 8$，按季度计息：对所有 $i$，$\\alpha_i = 0.25$。\n- 远期利率： $L = [0.018,\\, 0.019,\\, 0.0195,\\, 0.020,\\, 0.0205,\\, 0.021,\\, 0.0215,\\, 0.022]$。\n- 利差： $m = 0$。\n\n测试用例D（多个周期，远期利率微小且逐渐变化；利差极小但不为零）：\n- $N = 100{,}000{,}000$。\n- $T = 40$，按季度计息：对所有 $i$，$\\alpha_i = 0.25$。\n- 远期利率由规则 $L_i = 0.015 + 0.0001\\,i$ 给出，其中 $i = 1,\\dots,40$。\n- 利差： $m = 1 \\times 10^{-12}$。\n\n您的程序必须为每个测试用例计算：\n- 朴素现值 $PV_{\\text{naive}} = N \\left( \\sum_{i=1}^{T} (L_i + m)\\,\\alpha_i\\,D_i + D_T \\right)$。\n- 一个替代现值 $PV_{\\text{stable}}$，其计算不在票息项内将 $m$ 加到 $L_i$ 上，同时在精确算术中遵循代数等价性并使用相同的 $D_i$。\n- 绝对差值 $\\lvert PV_{\\text{naive}} - PV_{\\text{stable}} \\rvert$。\n\n此问题不涉及物理单位。所有利率必须视为小数，而非百分比。不涉及角度。最终输出格式必须是单行，包含一个由方括号括起来的逗号分隔列表，按顺序连接四个测试用例的三元组：$[PV_{\\text{naive}}^{(A)}, PV_{\\text{stable}}^{(A)}, \\lvert \\cdot \\rvert^{(A)}, PV_{\\text{naive}}^{(B)}, PV_{\\text{stable}}^{(B)}, \\lvert \\cdot \\rvert^{(B)}, PV_{\\text{naive}}^{(C)}, PV_{\\text{stable}}^{(C)}, \\lvert \\cdot \\rvert^{(C)}, PV_{\\text{naive}}^{(D)}, PV_{\\text{stable}}^{(D)}, \\lvert \\cdot \\rvert^{(D)}]$。", "solution": "对问题进行验证。\n\n步骤1：提取已知条件。\n- 风险中性测度下的现值 ($PV$) 是折现现金流的总和。\n- 第 $i$ 期的浮动利率票息由公式 $C_i = (L_i + m)\\,\\alpha_i\\,N$ 给出，其中 $L_i$ 是远期利率，$m$ 是利差，$\\alpha_i$ 是计息分数，$N$ 是名义本金。\n- 折现因子 $D_i$ 由递推关系 $D_0 = 1$ 和 $D_i = \\dfrac{D_{i-1}}{1 + L_i \\alpha_i}$ 导出，其中 $i = 1,\\dots,T$。\n- 使用朴素评估的现值为 $PV_{\\text{naive}} = N \\left( \\sum_{i=1}^{T} (L_i + m)\\,\\alpha_i\\,D_i + D_T \\right)$。\n- 任务是实现此朴素方法和一种代数上等价但数值上更稳定的方法 ($PV_{\\text{stable}}$)，该方法避免在求和内部将 $m$ 直接加到 $L_i$ 上。\n- 程序必须为四个测试用例计算 $PV_{\\text{naive}}$、$PV_{\\text{stable}}$ 和绝对差 $\\lvert PV_{\\text{naive}} - PV_{\\text{stable}} \\rvert$。\n- 测试用例A: $N = 1,000,000$，$T = 8$，对所有 $i$，$\\alpha_i = 0.25$，$L = [0.021, 0.022, 0.0235, 0.024, 0.025, 0.026, 0.027, 0.028]$，$m = 0.0005$。\n- 测试用例B: $N = 1,000,000,000$，$T = 8$，对所有 $i$，$\\alpha_i = 0.25$，$L$ 与测试用例A相同，$m = 1 \\times 10^{-20}$。\n- 测试用例C: $N = 2,000,000$，$T = 8$，对所有 $i$，$\\alpha_i = 0.25$，$L = [0.018, 0.019, 0.0195, 0.020, 0.0205, 0.021, 0.0215, 0.022]$，$m = 0$。\n- 测试用例D: $N = 100,000,000$，$T = 40$，对所有 $i$，$\\alpha_i = 0.25$，$L_i = 0.015 + 0.0001 \\cdot i$ (其中 $i = 1,\\dots,40$)，$m = 1 \\times 10^{-12}$。\n- 最终输出格式必须是表示列表的单行字符串，包含连接起来的结果。\n\n步骤2：使用提取的已知条件进行验证。\n- 该问题在金融数学和计算科学原理方面有坚实的科学基础。浮动利率票据的估值和浮点运算误差的分析是标准课题。\n- 该问题是适定的。每个测试用例的所有参数和公式都已明确给出，从而可以得到一个唯一、可计算的解。\n- 该问题是客观的，以清晰、明确的技术语言陈述。\n- 问题的设定是完整且一致的，没有缺失信息或矛盾之处。\n- 这些参数虽然是为了说明数值效应（例如，$m = 1 \\times 10^{-20}$）而选择的，但对于一个计算问题是有效的，并不代表物理上的不可能。\n- 结构是合理的，并要求推导一个数值稳定的公式，这是数值分析中的一种标准技术。\n\n步骤3：结论与行动。\n问题有效。将开发一个完整的解决方案。\n\n问题的核心是比较两种计算浮动利率债券现值的方法。\n\n方法1：朴素评估\n第一种方法是直接实现所提供的公式：\n$$\nPV_{\\text{naive}} = N \\left( \\sum_{i=1}^{T} (L_i + m)\\,\\alpha_i\\,D_i + D_T \\right)\n$$\n对于每个付息期 $i$，在乘法之前，将利差 $m$ 加到远期利率 $L_i$ 上。当 $m$ 远小于 $L_i$ 时，这种加法可能导致浮点精度损失。例如，在标准的双精度算术（IEEE 754）中，它具有大约15-17位的十进制精度，如果 $L_i \\approx 10^{-2}$ 且 $m = 10^{-20}$，那么和 $L_i + m$ 在计算上将与 $L_i$ 无法区分。这种现象被称为吸收或灾难性抵消，其中较小的数字被有效地丢失了。\n\n方法2：稳定评估\n为了构建一个更稳定的方法，我们必须重新排列公式以避免将 $m$ 直接加到 $L_i$ 上。我们从相同的现值表达式开始，并应用在实数算术中精确的代数变换。\n$$\nPV = N \\left( \\sum_{i=1}^{T} (L_i + m)\\,\\alpha_i\\,D_i + D_T \\right)\n$$\n我们在求和内部展开各项：\n$$\nPV = N \\left( \\sum_{i=1}^{T} L_i\\alpha_i D_i + \\sum_{i=1}^{T} m\\alpha_i D_i + D_T \\right)\n$$\n这种重排将涉及 $L_i$ 的计算与利差 $m$ 的贡献分离开来。为了进一步简化并增强数值稳定性，我们分析 $\\sum_{i=1}^{T} L_i\\alpha_i D_i$ 这一项。折现因子由递推关系 $D_i = \\frac{D_{i-1}}{1 + L_i \\alpha_i}$ 定义。重新整理可得 $D_i(1 + L_i \\alpha_i) = D_{i-1}$，这导致 $D_i + L_i \\alpha_i D_i = D_{i-1}$。这提供了一个关键的恒等式：\n$$\nL_i \\alpha_i D_i = D_{i-1} - D_i\n$$\n将此恒等式代入求和中，得到一个裂项级数：\n$$\n\\sum_{i=1}^{T} L_i \\alpha_i D_i = \\sum_{i=1}^{T} (D_{i-1} - D_i) = (D_0 - D_1) + (D_1 - D_2) + \\dots + (D_{T-1} - D_T) = D_0 - D_T\n$$\n根据定义，$D_0 = 1$。因此，该和简化为：\n$$\n\\sum_{i=1}^{T} L_i \\alpha_i D_i = 1 - D_T\n$$\n现在，我们将此结果代回到展开的 $PV$ 表达式中：\n$$\nPV = N \\left( (1 - D_T) + m \\sum_{i=1}^{T} \\alpha_i D_i + D_T \\right)\n$$\n$D_T$ 项相互抵消，得到最终的数值稳定公式：\n$$\nPV_{\\text{stable}} = N \\left( 1 + m \\sum_{i=1}^{T} \\alpha_i D_i \\right)\n$$\n这个公式更优，因为它完全避免了 $L_i$ 和 $m$ 的相加。利差的总贡献是通过先对折现后的计息分数求和，然后乘以 $m$ 来单独计算的。这保留了微小利差项的精度，确保其对最终价格的贡献不会因浮点运算的限制而丢失。\n\n每个测试用例的实现将按以下步骤进行：\n1.  确定参数 $N$、$m$、$T$ 以及 $L_i$ 和 $\\alpha_i$ 的数组。\n2.  使用指定的递推关系计算折现因子数组 $D_i$，其中 $i=0, \\dots, T$。\n3.  使用第一个公式计算 $PV_{\\text{naive}}$。\n4.  使用推导出的第二个公式计算 $PV_{\\text{stable}}$。\n5.  计算两个结果之间的绝对差。\n\n该过程将对所有四个测试用例执行，并且结果将被格式化为所需的输出字符串。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the floating-rate bond valuation problem for all test cases\n    and prints the results in the specified format.\n    \"\"\"\n\n    def generate_test_cases():\n        \"\"\"\n        Generates and returns the test cases as a list of dictionaries.\n        \"\"\"\n        # Test Case A\n        case_a = {\n            \"N\": 1_000_000.0,\n            \"T\": 8,\n            \"alpha\": np.full(8, 0.25),\n            \"L\": np.array([0.021, 0.022, 0.0235, 0.024, 0.025, 0.026, 0.027, 0.028]),\n            \"m\": 0.0005\n        }\n\n        # Test Case B\n        case_b = {\n            \"N\": 1_000_000_000.0,\n            \"T\": 8,\n            \"alpha\": np.full(8, 0.25),\n            \"L\": np.array([0.021, 0.022, 0.0235, 0.024, 0.025, 0.026, 0.027, 0.028]),\n            \"m\": 1e-20\n        }\n\n        # Test Case C\n        case_c = {\n            \"N\": 2_000_000.0,\n            \"T\": 8,\n            \"alpha\": np.full(8, 0.25),\n            \"L\": np.array([0.018, 0.019, 0.0195, 0.020, 0.0205, 0.021, 0.0215, 0.022]),\n            \"m\": 0.0\n        }\n\n        # Test Case D\n        T_d = 40\n        L_d = np.array([0.015 + 0.0001 * (i + 1) for i in range(T_d)])\n        case_d = {\n            \"N\": 100_000_000.0,\n            \"T\": T_d,\n            \"alpha\": np.full(T_d, 0.25),\n            \"L\": L_d,\n            \"m\": 1e-12\n        }\n\n        return [case_a, case_b, case_c, case_d]\n\n    def calculate_pvs(N, m, L, alpha):\n        \"\"\"\n        Calculates the present value of a floating-rate bond using two different methods.\n\n        Args:\n            N (float): Notional amount.\n            m (float): Margin.\n            L (np.ndarray): Array of forward rates.\n            alpha (np.ndarray): Array of accrual fractions.\n\n        Returns:\n            tuple: A tuple containing (pv_naive, pv_stable, abs_diff).\n        \"\"\"\n        T = len(L)\n        \n        # Calculate discount factors D_i for i=0,...,T\n        # D_0 = 1, D_i = D_{i-1} / (1 + L_i * alpha_i)\n        D = np.empty(T + 1, dtype=np.float64)\n        D[0] = 1.0\n        for i in range(1, T + 1):\n            D[i] = D[i - 1] / (1.0 + L[i - 1] * alpha[i - 1])\n        \n        # We need discount factors D_1, ..., D_T for the sums\n        D_coupon_periods = D[1:]\n\n        # Method 1: Naive PV calculation\n        # PV_naive = N * ( sum_{i=1 to T} (L_i + m) * alpha_i * D_i + D_T )\n        coupon_sum_naive = np.sum((L + m) * alpha * D_coupon_periods)\n        pv_naive = N * (coupon_sum_naive + D[T])\n\n        # Method 2: Stable PV calculation\n        # PV_stable = N * ( 1 + m * sum_{i=1 to T} alpha_i * D_i )\n        margin_sum_stable = np.sum(alpha * D_coupon_periods)\n        pv_stable = N * (1.0 + m * margin_sum_stable)\n\n        # Absolute difference\n        abs_diff = np.abs(pv_naive - pv_stable)\n\n        return pv_naive, pv_stable, abs_diff\n\n    test_cases = generate_test_cases()\n    results = []\n    \n    for case in test_cases:\n        pv_naive, pv_stable, abs_diff = calculate_pvs(\n            N=case[\"N\"], \n            m=case[\"m\"], \n            L=case[\"L\"], \n            alpha=case[\"alpha\"]\n        )\n        results.extend([pv_naive, pv_stable, abs_diff])\n\n    # Format the final output as a comma-separated list in a single line.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2394271"}, {"introduction": "现在，我们将从算术精度问题深入到算法和数学表示的稳定性问题。本练习 ([@problem_id:2394189]) 探究了为什么寻找一个多次出现的根（即“多重根”）在数值上是如此困难。我们将看到，一个理论上简单的多项式 $(x-c)^{8}=0$ 在其展开形式下会变得“病态”(ill-conditioned)，导致标准寻根算法彻底失效。这个实践揭示了在编码之前，选择正确的数学表达形式对保证数值稳定性是何等重要。", "problem": "考虑单变量多项式 $f(x) = (x - c)^{8}$，它在 $x = c$ 处有一个$8$重根。在计算经济学和金融学中，当重复的最优化条件或特征方程在多项式近似下产生高重根时，就会出现此类问题。在有限精度算术中，重根在数值上是出了名的棘手。假设采用遵循电气与电子工程师协会 (Institute of Electrical and Electronics Engineers, IEEE) $754$ 标准的标准双精度浮点算术。\n\n您必须编写一个完整的程序，对于每个测试用例，从第一性原理出发计算以下量：\n\n1. 计算机器$\\varepsilon$，其定义为在当前工作算术中满足 $1 + \\varepsilon > 1$ 的最小正浮点数，通过在运行时进行折半来确定。\n\n2. 令 $f(x) = (x-c)^{8}$ 且 $f'(x)$ 表示其关于 $x$ 的导数。定义迭代映射 $a_{k+1} = a_{k} - \\dfrac{f(a_{k})}{f'(a_{k})}$，其初始值 $a_{0}$ 由测试用例指定。经过 $T$ 步后，记录 $E_{\\text{std}} = |a_{T} - c|$。使用 $T = 12$。\n\n3. 定义迭代映射 $b_{k+1} = b_{k} - m \\dfrac{f(b_{k})}{f'(b_{k})}$，其初始值 $b_{0} = a_{0}$，重数 $m = 8$。经过 $S$ 步后，记录 $E_{\\text{mod}} = |b_{S} - c|$。使用 $S = 2$。\n\n4. 构建展开后的多项式\n$$\np(x) = \\sum_{k=0}^{8} \\binom{8}{k} (-c)^{8-k} x^{k}\n= x^{8} - 8 c x^{7} + 28 c^{2} x^{6} - 56 c^{3} x^{5} + 70 c^{4} x^{4} - 56 c^{5} x^{3} + 28 c^{6} x^{2} - 8 c^{7} x + c^{8}.\n$$\n使用标准的浮点线性代数计算 $p(x)$ 的八个复根 $\\{z_{i}\\}_{i=1}^{8}$，并记录\n- $R_{\\text{avg}} = \\left| \\dfrac{1}{8} \\sum_{i=1}^{8} z_{i} - c \\right|$，\n- $R_{\\text{spread}} = \\max_{1 \\le i \\le 8} |z_{i} - c|$，\n其中作用于复数上的 $|\\cdot|$ 表示复模。\n\n5. 令 $\\delta = \\sqrt{\\varepsilon} \\cdot \\max\\{1, |c|\\}$。计算 $f_{\\text{fact}} = ( (c + \\delta) - c )^{8}$，并使用第4项中展开的系数表示来计算 $f_{\\text{exp}} = p(c + \\delta)$。记录其相对差异\n$$\nC_{\\text{rel}} = \\frac{|f_{\\text{exp}} - f_{\\text{fact}}|}{|f_{\\text{fact}}|}.\n$$\n\n您的程序必须为以下测试套件中的每个测试用例执行上述计算：\n- 测试 1: $(c, a_{0}) = (1.0, 2.0)$。\n- 测试 2: $(c, a_{0}) = (10^{-8}, 0.0)$。\n- 测试 3: $(c, a_{0}) = (10^{8}, 0.0)$。\n- 测试 4: $(c, a_{0}) = (10^{16}, 0.0)$。\n\n对于每个测试用例，所需的输出是五个实数 $[E_{\\text{std}}, E_{\\text{mod}}, R_{\\text{avg}}, R_{\\text{spread}}, C_{\\text{rel}}]$，并完全按照上述定义进行计算。您的程序应生成单行输出，其中包含四个测试的这五个数组块的串联，形式为方括号内以逗号分隔的列表，并按测试顺序排列。具体而言，最终输出必须是\n$$\n[E_{\\text{std}}^{(1)}, E_{\\text{mod}}^{(1)}, R_{\\text{avg}}^{(1)}, R_{\\text{spread}}^{(1)}, C_{\\text{rel}}^{(1)}, E_{\\text{std}}^{(2)}, E_{\\text{mod}}^{(2)}, R_{\\text{avg}}^{(2)}, R_{\\text{spread}}^{(2)}, C_{\\text{rel}}^{(2)}, E_{\\text{std}}^{(3)}, E_{\\text{mod}}^{(3)}, R_{\\text{avg}}^{(3)}, R_{\\text{spread}}^{(3)}, C_{\\text{rel}}^{(3)}, E_{\\text{std}}^{(4)}, E_{\\text{mod}}^{(4)}, R_{\\text{avg}}^{(4)}, R_{\\text{spread}}^{(4)}, C_{\\text{rel}}^{(4)}].\n$$\n\n所有输出都是不带单位的实数。不涉及角度。不得使用百分比；所有比率必须以实数形式报告。", "solution": "问题陈述已经过验证，被认为是数值分析领域一个有效且适定的练习。它作为一个典型的示例，展示了在使用有限精度浮点算术时，高重根所带来的挑战。我们将以所需的科学和数学严谨性来剖析问题的每个组成部分。\n\n问题的核心是多项式 $f(x) = (x - c)^{8}$，它在 $x=c$ 处有一个重数为 $m=8$ 的单根。我们的任务是研究在标准 IEEE 754 双精度算术下，用于定位该根和计算多项式本身的各种方法的数值行为。\n\n**1. 机器$\\varepsilon$ ($\\varepsilon$)**\n机器$\\varepsilon$（记为 $\\varepsilon$）是浮点数系统的一个基本特征。它被定义为，当加到 $1$ 时能产生一个大于 $1$ 的结果的最小正数。换言之，它是从 $1.0$ 到下一个更大的可表示浮点数之间的距离。问题指定了通过在运行时使用折半算法来确定它。我们从一个值（例如 1.0）开始，并反复将其除以 2，直到 $1.0 + (\\varepsilon/2)$ 在计算上与 1.0 不可区分。最后一个使 $1.0 + \\varepsilon > 1.0$ 成立的值就是机器$\\varepsilon$。对于标准双精度算术，该值为 $2^{-52}$，约等于 $2.22 \\times 10^{-16}$。\n\n**2. 标准牛顿-拉弗森迭代 ($E_{\\text{std}}$)**\n牛顿-拉弗森法是一种求根算法，由迭代映射 $a_{k+1} = a_k - f(a_k)/f'(a_k)$ 定义。对于给定的多项式 $f(x) = (x-c)^8$，其导数为 $f'(x) = 8(x-c)^7$。因此，迭代步骤为：\n$$\na_{k+1} = a_k - \\frac{(a_k-c)^8}{8(a_k-c)^7}\n$$\n在精确算术中，这可简化为：\n$$\na_{k+1} = a_k - \\frac{a_k-c}{8} = \\frac{7}{8}a_k + \\frac{1}{8}c\n$$\n这揭示了误差 $e_k = a_k - c$ 在每一步都以一个常数因子收缩：$e_{k+1} = a_{k+1} - c = \\frac{7}{8}(a_k - c) = \\frac{7}{8}e_k$。这是线性收敛的特征，收敛率为 $1 - 1/m = 1 - 1/8 = 7/8$，这非常慢。经过 $T=12$ 次迭代后，最终误差 $|a_T - c|$ 预计为 $|a_0 - c| \\cdot (7/8)^{12}$。然而，实现时必须使用未简化的比率 $f(a_k)/f'(a_k)$，以暴露当 $a_k$ 非常接近 $c$ 时可能出现的下溢等数值问题。\n\n**3. 修正的牛顿-拉弗森迭代 ($E_{\\text{mod}}$)**\n为了在已知重数 $m$ 的情况下恢复牛顿法的二次收敛性，迭代被修改为 $b_{k+1} = b_k - m \\cdot f(b_k)/f'(b_k)$。对于 $m=8$，这得到：\n$$\nb_{k+1} = b_k - 8 \\cdot \\frac{(b_k-c)^8}{8(b_k-c)^7} = b_k - (b_k - c) = c\n$$\n理论上，该方法在单步内收敛。实际上，由于浮点数的不精确性，它将二次收敛到真根 $c$ 的一个小邻域内。指定的 $S=2$ 次迭代应足以将误差 $|b_S-c|$ 降低到机器精度水平或其附近。\n\n**4. 展开多项式求根 ($R_{\\text{avg}}$, $R_{\\text{spread}}$)**\n问题要求计算二项式展开后的多项式的根：\n$$\np(x) = \\sum_{k=0}^{8} \\binom{8}{k} (-c)^{8-k} x^{k}\n$$\n用系数表示多项式是一项数值敏感的任务，特别是对于高重根。$p(x)$ 的系数将在多个数量级上变化，特别是对于大或小的 $|c|$。当这些系数以有限精度存储时，它们会不可避免地受到扰动。根据多项式条件数的理论，系数的微小相对扰动可能导致根的巨大绝对变化。因此，单一的解析根 $x=c$ 将会“碎裂”成一簇围绕 $c$ 分散的八个不同的复根 $\\{z_i\\}$。我们需要使用标准的数值线性代数技术（例如在 `numpy` 等库中实现的友矩阵法）来计算这些根，然后通过计算其平均值与 $c$ 的偏差（$R_{\\text{avg}}$）以及簇中的最大偏差（$R_{\\text{spread}}$）来量化结果。\n\n**5. 条件数分析 ($C_{\\text{rel}}$)**\n最后一部分直接探讨了以其因式分解形式 $f(x) = (x-c)^8$ 与其展开形式 $p(x)$ 对多项式求值的数值条件。引入一个扰动 $\\delta = \\sqrt{\\varepsilon} \\cdot \\max\\{1, |c|\\}$。\n- 因式分解形式的求值 $f_{\\text{fact}} = ((c+\\delta)-c)^8$ 预期是数值稳定的。减法 $(c+\\delta)-c$ 应该能精确地恢复 $\\delta$，从而得到一个接近 $\\delta^8$ 真实数学值的结果。\n- 展开形式的求值 $p(c+\\delta)$ 预期是数值不稳定的。这个计算涉及对许多符号交替的大项求和，这些项相互抵消以产生一个非常小的最终结果。这种现象被称为灾难性抵消（catastrophic cancellation），它会放大系数和输入值中的初始舍入误差，导致计算出的值 $f_{\\text{exp}}$ 可能严重不准确。\n相对差异 $C_{\\text{rel}} = |f_{\\text{exp}} - f_{\\text{fact}}| / |f_{\\text{fact}}|$ 衡量了这种不稳定性的程度。一个大的 $C_{\\text{rel}}$ 值表明，展开形式在其重根附近求值是病态的（ill-conditioned）。对于所有测试用例，该值预计都将显著大于 1。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the numerical analysis problem for the given test cases.\n    \"\"\"\n\n    test_cases = [\n        # (c, a0)\n        (1.0, 2.0),\n        (1e-8, 0.0),\n        (1e8, 0.0),\n        (1e16, 0.0),\n    ]\n\n    all_results = []\n    \n    # Binomial coefficients B(8,j) for j=0..8\n    # These correspond to B(n,k) for n=8 and k=0, 1, ..., 8\n    binomial_coeffs = np.array([1, 8, 28, 56, 70, 56, 28, 8, 1], dtype=np.float64)\n\n    for c, a0 in test_cases:\n        c_f64 = np.float64(c)\n        a0_f64 = np.float64(a0)\n\n        # 1. Compute machine epsilon\n        eps = np.float64(1.0)\n        while np.float64(1.0) + eps / np.float64(2.0) > np.float64(1.0):\n            eps /= np.float64(2.0)\n\n        # 2. Standard Newton's Method\n        T = 12\n        a_k = a0_f64\n        for _ in range(T):\n            diff = a_k - c_f64\n            # Prevent division by zero if a_k becomes numerically equal to c\n            if diff == 0.0:\n                break\n            f_val = diff**8\n            f_prime_val = 8.0 * (diff**7)\n            # Prevent NaN from 0/0 and halt if derivative is numerically zero\n            if f_prime_val == 0.0:\n                break\n            a_k -= f_val / f_prime_val\n        E_std = np.abs(a_k - c_f64)\n\n        # 3. Modified Newton's Method\n        S = 2\n        m = 8.0\n        b_k = a0_f64\n        for _ in range(S):\n            diff = b_k - c_f64\n            if diff == 0.0:\n                break\n            f_val = diff**8\n            f_prime_val = 8.0 * (diff**7)\n            if f_prime_val == 0.0:\n                break\n            b_k -= m * f_val / f_prime_val\n        E_mod = np.abs(b_k - c_f64)\n\n        # 4. Expanded Polynomial Root Finding\n        # The coefficient for x^k is binom(8,k) * (-c)^(8-k).\n        # numpy.roots needs coefficients for [x^8, x^7, ..., x^0].\n        # The coefficient for x^(8-j) is binom(8, 8-j) * (-c)^j = binom(8,j) * (-c)^j.\n        p_coeffs = np.zeros(9, dtype=np.float64)\n        for j in range(9):\n            p_coeffs[j] = binomial_coeffs[j] * ((-c_f64)**j)\n        \n        roots = np.roots(p_coeffs)\n        \n        R_avg = np.abs(np.mean(roots) - c_f64)\n        R_spread = np.max(np.abs(roots - c_f64))\n\n        # 5. Conditioning Analysis\n        delta = np.sqrt(eps) * np.max([1.0, np.abs(c_f64)])\n        \n        # Factored form evaluation (numerically stable)\n        f_fact = ((c_f64 + delta) - c_f64)**8\n        \n        # Expanded form evaluation using Horner's method (numerically unstable)\n        x_eval = c_f64 + delta\n        f_exp = p_coeffs[0]\n        for i in range(1, 9):\n            f_exp = f_exp * x_eval + p_coeffs[i]\n        \n        # Relative discrepancy\n        if f_fact == 0.0:\n            C_rel = np.inf if f_exp != 0.0 else 0.0\n        else:\n            C_rel = np.abs(f_exp - f_fact) / np.abs(f_fact)\n\n        all_results.extend([E_std, E_mod, R_avg, R_spread, C_rel])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "2394189"}]}