{"hands_on_practices": [{"introduction": "理论最终要在实践中得到检验。本节的第一个练习将带领你完成一个完整的贝叶斯推断工作流，从一个核心的经济学模型出发，到最终使用马尔可夫链蒙特卡洛（MCMC）方法估计其关键参数。你将扮演一名计算经济学家的角色，估计代表性代理人的风险厌恶系数 $ \\gamma $，这是一个在资产定价中无法直接观测但至关重要的结构性参数。这个练习不仅能让你熟练掌握Metropolis-Hastings算法的实现，还能让你深刻体会到MCMC在处理复杂、非线性经济模型时的强大威力。[@problem_id:2408673]", "problem": "编写一个完整、可运行的程序，在一个基于消费的资产定价框架中，使用马尔可夫链蒙特卡洛 (MCMC) 方法来估计代表性代理人的相对风险厌恶系数 $ \\gamma $。从跨期优化的核心一阶条件出发，该条件在恒定相对风险厌恶 (CRRA) 偏好下，产生了资产收益的欧拉方程：当随机折现因子为 $ m_{t+1} = \\beta \\left( \\dfrac{C_{t+1}}{C_t} \\right)^{-\\gamma} $ 时，无套利条件为 $ \\mathbb{E}_t \\left[ m_{t+1} R_{t+1} \\right] = 1 $，其中 $ \\beta \\in (0,1) $ 是一个折现因子，$ C_t $ 是消费，$ R_{t+1} $ 是在 $ t+1 $ 时刻可观测的总回报。为了将此条件与有限样本的含噪数据联系起来，我们为欧拉残差假设一个加性正态测量方程，\n$$\n\\beta \\, G_t^{-\\gamma} \\, R_{t+1} - 1 = \\varepsilon_t, \\quad \\varepsilon_t \\stackrel{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0,\\sigma^2),\n$$\n其中 $ G_t = \\dfrac{C_{t+1}}{C_t} $ 表示总消费增长率，$ \\sigma^2 $ 是一个已知的方差参数。假设 $ \\gamma $ 的先验分布为伽马分布，其形状参数为 $ k $，尺度参数为 $ \\theta $，即 $ \\gamma \\sim \\text{Gamma}(k,\\theta) $，其支撑集为 $ (0,\\infty) $。使用 Metropolis–Hastings 算法，在对数参数 $ z = \\log \\gamma $ 上进行随机游走，从给定样本 $ \\{(G_t,R_{t+1})\\}_{t=1}^T $ 的条件下对 $ \\gamma $ 的后验分布进行抽样。建议分布为 $ z' = z + \\eta $，其中 $ \\eta \\sim \\mathcal{N}(0,s^2) $ 是在对数尺度上。\n\n您的程序必须：\n- 使用下面指定的数据生成过程 (DGP) 为每个测试用例模拟合成数据 $ (G_t, R_{t+1}) $。\n- 结合由测量方程所隐含的高斯似然和 $ \\gamma $ 的伽马先验来构建后验核。\n- 在 $z$-空间中运行 Metropolis–Hastings 抽样器（等价于在 $ \\gamma $ 上进行对数正态随机游走），并在舍弃预烧期（burn-in）后计算 $ \\gamma $ 的后验均值估计。\n- 仅使用指定的随机种子以确保可复现性。\n\n每个测试用例的数据生成过程 (DGP)：\n- 生成消费增长率 $ G_t = \\exp(\\mu_c + \\sigma_c \\epsilon_t) $，其中 $ \\epsilon_t \\stackrel{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0,1) $。\n- 生成测量误差 $ \\varepsilon_t \\stackrel{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0,\\sigma_e^2) $。\n- 通过逐期强制执行含噪的欧拉方程来生成回报：\n$$\nR_{t+1} = \\frac{1 + \\varepsilon_t}{\\beta \\, G_t^{-\\gamma_{\\text{true}}}}.\n$$\n所有抽样都必须使用为每个测试用例指定的种子。为确保确定性的可复现性，请使用给定的种子初始化一个伪随机数生成器以模拟 $ G_t $ 和 $ R_{t+1} $，并使用种子加 $ +\\,10{,}000 $ 的值初始化第二个伪随机数生成器以用于 Metropolis–Hastings 的建议分布。本问题不涉及物理单位。\n\n对数参数的后验目标：\n- 定义 $ z = \\log \\gamma $。$z$ 的目标密度与在 $ \\gamma = e^z $ 处评估的伽马先验密度、残差的高斯似然以及由变量变换引起的雅可比项 $ e^z $ 成正比。您必须基于 $z$ 的对数后验来实现 Metropolis–Hastings 接受准则。\n\n测试套件：\n对于以下三种情况，请使用提供的设置模拟数据并运行抽样器。请直接使用下面给出的确切值。\n\n- 情况 A (理想路径)：\n    - 种子 $ = 7 $\n    - 样本量 $ T = 200 $\n    - 真实风险厌恶 $ \\gamma_{\\text{true}} = 2.0 $\n    - 消费增长参数 $ \\mu_c = 0.01 $，$ \\sigma_c = 0.02 $\n    - 折现因子 $ \\beta = 0.99 $\n    - 测量标准差 $ \\sigma_e = 0.01 $\n    - $ \\gamma $ 的先验：伽马分布形状参数 $ k = 2.0 $，尺度参数 $ \\theta = 1.0 $\n    - Metropolis–Hastings：链长 $ N = 16000 $，预烧期 $ B = 4000 $，对数尺度建议分布标准差 $ s = 0.12 $\n\n- 情况 B (较低的风险厌恶，更高噪声的数据)：\n    - 种子 $ = 101 $\n    - 样本量 $ T = 120 $\n    - 真实风险厌恶 $ \\gamma_{\\text{true}} = 0.5 $\n    - 消费增长参数 $ \\mu_c = 0.005 $，$ \\sigma_c = 0.015 $\n    - 折现因子 $ \\beta = 0.99 $\n    - 测量标准差 $ \\sigma_e = 0.02 $\n    - $ \\gamma $ 的先验：伽马分布形状参数 $ k = 1.5 $，尺度参数 $ \\theta = 1.0 $\n    - Metropolis–Hastings：链长 $ N = 16000 $，预烧期 $ B = 4000 $，对数尺度建议分布标准差 $ s = 0.15 $\n\n- 情况 C (较高的风险厌恶，更重尾的先验)：\n    - 种子 $ = 2025 $\n    - 样本量 $ T = 200 $\n    - 真实风险厌恶 $ \\gamma_{\\text{true}} = 5.0 $\n    - 消费增长参数 $ \\mu_c = 0.01 $，$ \\sigma_c = 0.02 $\n    - 折现因子 $ \\beta = 0.99 $\n    - 测量标准差 $ \\sigma_e = 0.01 $\n    - $ \\gamma $ 的先验：伽马分布形状参数 $ k = 2.0 $，尺度参数 $ \\theta = 2.0 $\n    - Metropolis–Hastings：链长 $ N = 16000 $，预烧期 $ B = 4000 $，对数尺度建议分布标准差 $ s = 0.12 $\n\n所需输出：\n- 对于每种情况，使用预烧期后保留的抽样计算 $ \\gamma $ 的后验均值。\n- 将每个后验均值四舍五入到恰好三位小数。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，$ [x_1,x_2,x_3] $）。\n\n不需要也不允许用户输入。在指定的种子和设置下，程序必须是自包含且确定性的。最终输出为浮点数。通过严格遵守上述 DGP 和贝叶斯结构，确保科学真实性。", "solution": "所提出的问题是计算经济学中一个结构化模型的贝叶斯估计的适定练习。它具有科学依据，内部一致，并为获得唯一的、可验证的解提供了所有必要信息。因此，我们可以着手进行推导和实现。\n\n基本的经济关系是具有恒定相对风险厌恶 (CRRA) 偏好的代表性代理人的欧拉方程。效用函数为 $u(C) = \\frac{C^{1-\\gamma}}{1-\\gamma}$，其中 $\\gamma > 0$ 是相对风险厌恶系数。代理人进行最优跨期消费和资产配置的一阶条件意味着无套利条件 $\\mathbb{E}_t [m_{t+1} R_{t+1}] = 1$ 成立，其中 $R_{t+1}$ 是资产的总回报，而 $m_{t+1}$ 是随机折现因子 (SDF)。对于 CRRA 效用，SDF 由 $m_{t+1} = \\beta \\left( \\frac{C_{t+1}}{C_t} \\right)^{-\\gamma}$ 给出，其中 $\\beta \\in (0,1)$ 是主观折现因子。将总消费增长率定义为 $G_t = C_{t+1}/C_t$，该条件变为 $\\mathbb{E}_t[\\beta G_t^{-\\gamma} R_{t+1}] = 1$。\n\n为了使该模型在有限样本的含噪数据 $D = \\{(G_t, R_{t+1})\\}_{t=1}^T$ 下易于实证处理，我们采用指定的测量方程：\n$$\n\\beta \\, G_t^{-\\gamma} \\, R_{t+1} - 1 = \\varepsilon_t, \\quad \\varepsilon_t \\stackrel{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0, \\sigma_e^2)\n$$\n其中 $\\sigma_e^2$ 是欧拉方程误差的已知方差。此设定意味着观测数据服从高斯似然。对于给定的 $\\gamma$，单个观测值 $(G_t, R_{t+1})$ 的似然是在残差 $\\varepsilon_t$ 处评估的均值为 $0$、方差为 $\\sigma_e^2$ 的正态随机变量的概率密度。因此，整个样本的对数似然为：\n$$\n\\log L(\\gamma | D) = C_L - \\frac{1}{2\\sigma_e^2} \\sum_{t=1}^T \\left( \\beta G_t^{-\\gamma} R_{t+1} - 1 \\right)^2\n$$\n其中 $C_L$ 是一个不依赖于 $\\gamma$ 的常数。\n\n我们将对 $\\gamma$ 进行贝叶斯推断。$\\gamma$ 的先验分布被指定为伽马分布，$\\gamma \\sim \\text{Gamma}(k,\\theta)$，其概率密度函数为：\n$$\np(\\gamma|k, \\theta) = \\frac{1}{\\Gamma(k)\\theta^k} \\gamma^{k-1} e^{-\\gamma/\\theta}, \\quad \\text{for } \\gamma > 0\n$$\n对数先验（不计加法常数）为：\n$$\n\\log p(\\gamma|k,\\theta) = C_p + (k-1)\\log\\gamma - \\frac{\\gamma}{\\theta}\n$$\n根据贝叶斯定理，$\\gamma$ 的后验密度与似然和先验的乘积成正比，$p(\\gamma| D) \\propto L(\\gamma|D) p(\\gamma|k,\\theta)$。因此，对数后验与它们的对数之和成正比：\n$$\n\\log p(\\gamma|D) \\propto (k-1)\\log\\gamma - \\frac{\\gamma}{\\theta} - \\frac{1}{2\\sigma_e^2} \\sum_{t=1}^T \\left( \\beta G_t^{-\\gamma} R_{t+1} - 1 \\right)^2\n$$\n\n估计将使用 Metropolis-Hastings 算法执行。为了满足约束 $\\gamma > 0$，我们进行变量替换，令 $z = \\log\\gamma \\in (-\\infty, \\infty)$，这意味着 $\\gamma = e^z$。变换后参数 $z$ 的后验密度由 $p(z|D) = p(\\gamma=e^z|D) \\left| \\frac{d\\gamma}{dz} \\right|$ 给出。此变换的雅可比行列式为 $\\left| \\frac{d(e^z)}{dz} \\right| = e^z$。因此，$z$ 的对数后验为：\n$$\n\\log p(z|D) \\propto \\log p(\\gamma=e^z|D) + \\log(e^z) = \\log p(\\gamma=e^z|D) + z\n$$\n将 $\\gamma = e^z$ 代入 $\\gamma$ 的对数后验表达式中，并加上雅可比项 $z$，即可得到我们抽样器的目标对数密度：\n$$\n\\pi(z) \\equiv \\log p(z|D) \\propto (k-1)z - \\frac{e^z}{\\theta} - \\frac{1}{2\\sigma_e^2} \\sum_{t=1}^T \\left( \\beta G_t^{-e^z} R_{t+1} - 1 \\right)^2 + z\n$$\n化简后，我们得到必须评估的核的最终形式：\n$$\n\\pi(z) \\propto kz - \\frac{e^z}{\\theta} - \\frac{1}{2\\sigma_e^2} \\sum_{t=1}^T \\left( \\beta R_{t+1} G_t^{-e^z} - 1 \\right)^2\n$$\n使用随机游走建议的 Metropolis-Hastings 算法实现如下：\n$1$. 在 $z^{(0)}$ 处初始化链。一个合理的起始点是先验均值的对数，$z^{(0)} = \\log(k\\theta)$。\n$2$. 对每一步 $i=1, \\dots, N$：\n    a. 从对称建议分布中建议一个新状态 $z'$：$z' = z^{(i-1)} + \\eta$，其中 $\\eta \\sim \\mathcal{N}(0, s^2)$。\n    b. 计算接受率 $A = \\frac{p(z'|D)}{p(z^{(i-1)}|D)}$。在对数形式下，即为 $\\log A = \\pi(z') - \\pi(z^{(i-1)})$。\n    c. 以概率 $\\alpha = \\min(1, A)$ 接受建议（设 $z^{(i)} = z'$）。否则，拒绝建议（设 $z^{(i)} = z^{(i-1)}$）。\n$3$. 得到的序列 $\\{\\gamma^{(i)} = e^{z^{(i)}}\\}_{i=1}^N$ 是从 $\\gamma$ 的后验分布中抽取的一组样本。\n$4$. 舍弃初始的预烧期样本 $\\{ \\gamma^{(i)} \\}_{i=1}^B$ 后，$\\gamma$ 的后验均值通过剩余样本的样本均值来估计：\n$$\n\\hat{\\mathbb{E}}[\\gamma|D] = \\frac{1}{N-B} \\sum_{i=B+1}^N \\gamma^{(i)}\n$$\n将此程序应用于三个测试用例中的每一个，使用根据指定的数据生成过程生成的合成数据，并为数据生成和 MCMC 抽样使用不同的随机数生成器种子，以确保可复现性。最终结果是每种情况下 $\\gamma$ 的后验均值，并四舍五入到指定的精度。", "answer": "```python\nimport numpy as np\n\ndef estimate_gamma(params):\n    \"\"\"\n    Simulates data and estimates the risk aversion coefficient gamma using MCMC.\n    \"\"\"\n    # Unpack parameters for conciseness\n    seed = params['seed']\n    T = params['T']\n    gamma_true = params['gamma_true']\n    mu_c = params['mu_c']\n    sigma_c = params['sigma_c']\n    beta = params['beta']\n    sigma_e = params['sigma_e']\n    k = params['k']\n    theta = params['theta']\n    N = params['N']\n    B = params['B']\n    s = params['s']\n\n    # 1. Data-Generating Process (DGP)\n    # Initialize a dedicated pseudo-random number generator for data simulation\n    rng_dgp = np.random.default_rng(seed)\n    \n    # Generate consumption growth G_t\n    eps_c = rng_dgp.standard_normal(T)\n    G = np.exp(mu_c + sigma_c * eps_c)\n    \n    # Generate returns R_{t+1} from the noisy Euler equation\n    eps_r = rng_dgp.normal(loc=0.0, scale=sigma_e, size=T)\n    R = (1.0 + eps_r) / (beta * G**(-gamma_true))\n\n    # Pre-calculate log(G) for efficiency in the sampler\n    G_log = np.log(G)\n\n    # 2. Define the Log-Posterior Kernel for z = log(gamma)\n    # The kernel is the log-posterior density up to an additive constant.\n    # log p(z|D) is proportional to:\n    # kz - exp(z)/theta - (1/(2*sigma_e^2)) * sum( (beta*R*G**(-exp(z)) - 1)**2 )\n    def log_posterior_kernel(z):\n        # Handle cases where z might lead to numerical instability\n        if np.isneginf(z): # Corresponds to gamma=0, which has zero prior probability\n            return -np.inf\n        \n        gamma = np.exp(z)\n        \n        if np.isinf(gamma): # z is too large, exp(z) overflows\n            return -np.inf\n        \n        # Log-prior for z (from Gamma prior on gamma + Jacobian term)\n        # log_prior is proportional to k*z - exp(z)/theta\n        log_prior = k * z - gamma / theta\n        \n        # Log-likelihood\n        # G**(-gamma) is numerically more stable as exp(-gamma * log(G))\n        residuals = beta * R * np.exp(-gamma * G_log) - 1.0\n        log_likelihood = -0.5 * np.sum(residuals**2) / (sigma_e**2)\n        \n        return log_prior + log_likelihood\n\n    # 3. Metropolis-Hastings Sampler\n    # Initialize a second PRNG for the MCMC proposals, as specified\n    rng_mcmc = np.random.default_rng(seed + 10000)\n    \n    # Sensible initial value from the prior mean\n    z_current = np.log(k * theta)\n    log_post_current = log_posterior_kernel(z_current)\n\n    gamma_chain = np.empty(N)\n\n    for i in range(N):\n        # Propose a new state using a random walk on the log-scale\n        z_proposal = z_current + rng_mcmc.normal(loc=0.0, scale=s)\n        \n        # Evaluate the log posterior at the proposal\n        log_post_proposal = log_posterior_kernel(z_proposal)\n        \n        # Calculate the log of the acceptance ratio\n        log_alpha = log_post_proposal - log_post_current\n        \n        # Accept or reject the proposal\n        if np.log(rng_mcmc.uniform())  log_alpha:\n            z_current = z_proposal\n            log_post_current = log_post_proposal\n        \n        # Store the current state of the chain (in terms of gamma)\n        gamma_chain[i] = np.exp(z_current)\n\n    # 4. Compute Posterior Mean\n    # Discard the burn-in samples and compute the mean of the rest\n    posterior_mean = np.mean(gamma_chain[B:])\n    \n    return posterior_mean\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        { # Case A\n            \"seed\": 7, \"T\": 200, \"gamma_true\": 2.0, \"mu_c\": 0.01, \"sigma_c\": 0.02,\n            \"beta\": 0.99, \"sigma_e\": 0.01, \"k\": 2.0, \"theta\": 1.0,\n            \"N\": 16000, \"B\": 4000, \"s\": 0.12\n        },\n        { # Case B\n            \"seed\": 101, \"T\": 120, \"gamma_true\": 0.5, \"mu_c\": 0.005, \"sigma_c\": 0.015,\n            \"beta\": 0.99, \"sigma_e\": 0.02, \"k\": 1.5, \"theta\": 1.0,\n            \"N\": 16000, \"B\": 4000, \"s\": 0.15\n        },\n        { # Case C\n            \"seed\": 2025, \"T\": 200, \"gamma_true\": 5.0, \"mu_c\": 0.01, \"sigma_c\": 0.02,\n            \"beta\": 0.99, \"sigma_e\": 0.01, \"k\": 2.0, \"theta\": 2.0,\n            \"N\": 16000, \"B\": 4000, \"s\": 0.12\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = estimate_gamma(case)\n        results.append(result)\n\n    # Format the output as a comma-separated list of floats with 3 decimal places\n    # enclosed in square brackets, with no trailing whitespace.\n    output_str = f\"[{','.join([f'{res:.3f}' for res in results])}]\"\n    print(output_str)\n\nsolve()\n```", "id": "2408673"}, {"introduction": "成功运行MCMC代码只是第一步，更关键的是要确保采样器能够高效地探索整个后验分布。一个低效的采样器会产生高度自相关的样本，导致估计结果不稳定且计算成本高昂。本练习引导我们进行一个思想实验，探讨在Metropolis-Hastings算法中一个关键的调优参数——提议分布的步长（proposal step size）——是如何影响采样效率的。通过分析步长过大或过小两种极端情况，你将直观地理解接受率、自相关函数（ACF）和有效样本量之间的微妙平衡，这是成为一名MCMC实践者的必修课。[@problem_id:2408760]", "problem": "考虑一个基于似然的资产定价模型中，标量结构参数 $\\theta$ 的贝叶斯估计问题。其正常后验密度 $\\pi(\\theta)$ 是单峰且大致呈钟形的。您运行一个采用对称高斯提议的随机游走 Metropolis 马尔可夫链蒙特卡洛 (MCMC) 算法：\n$$\n\\theta' \\,=\\, \\theta_t \\,+\\, \\varepsilon, \\quad \\varepsilon \\sim \\mathcal{N}(0, s^2),\n$$\n其接受概率为\n$$\n\\alpha(\\theta_t,\\theta') \\,=\\, \\min\\!\\left\\{\\,1,\\, \\frac{\\pi(\\theta')}{\\pi(\\theta_t)} \\,\\right\\}。\n$$\n对于两次独立的、在平稳状态下长度为 $T$ 的长时间运行，您分别选择 (i) 一个相对于后验曲率过大的提议尺度 $s$，和 (ii) 一个相对于后验曲率过小的提议尺度 $s$。令 $\\rho(k)$ 表示马尔可夫链 $\\{\\theta_t\\}_{t=1}^T$ 的滞后 $k$ 阶自相关函数 (ACF)，定义为\n$$\n\\rho(k) \\,=\\, \\frac{\\mathrm{Cov}(\\theta_t, \\theta_{t+k})}{\\mathrm{Var}(\\theta_t)}, \\quad k \\in \\{1,2,\\ldots\\}。\n$$\n在哪种情况下，以下陈述最能描述这两种机制下经验 ACF 和接受率的定性行为，以及由此对有效样本量产生的影响？\n\nA. 在两种情况下，$\\rho(1)$ 都很大且为正，并随 $k$ 缓慢衰减，但接受率不同：当 $s$ 过大时，接受率非常低，链表现出重复状态；当 $s$ 过小时，接受率非常高，但连续状态非常接近。在这两种情况下，积分自相关时间都很长，有效样本量都很小，只有在 $s$ 取中间值时才有所改善。\n\nB. 当 $s$ 过大时，链会频繁地来回跳跃，产生负的 $\\rho(1)$；当 $s$ 过小时，大部分移动都被接受，因此对所有 $k \\ge 1$，$\\rho(k) \\approx 0$，有效样本量达到最大。\n\nC. 当 $s$ 极大时，ACF 衰减最快，因为大跳跃会使链去相关，并且此时接受率高，从而得到最大的有效样本量。\n\nD. 对于一次平稳运行，ACF $\\rho(k)$ 不随 $s$ 的选择而改变；只有预烧期长度受 $s$ 的影响。\n\nE. 对于对称提议，对任何 $s$，接受率都等于 $0.5$。这意味着在不同 $s$ 选择下观察到的 $\\rho(k)$ 差异是由蒙特卡洛误差而非步长选择造成的。", "solution": "该问题要求对随机游走 Metropolis (RWM) 算法在两种极端的提议尺度 $s$ 选择下的性能进行定性分析。性能将通过接受率、生成链的自相关函数 (ACF) 以及由此产生的有效样本量 (ESS) 来表征。\n\n任何马尔可夫链蒙特卡洛 (MCMC) 算法的目标都是生成一个抽样序列 $\\{\\theta_t\\}_{t=1}^T$，其分布收敛于目标分布，在本例中即后验分布 $\\pi(\\theta)$。为了使从该链中导出的估计量（例如，后验均值 $\\frac{1}{T}\\sum_{t=1}^T \\theta_t$）精确，我们需要一个大的有效样本量。ESS 定义为\n$$\n\\text{ESS} = \\frac{T}{1 + 2\\sum_{k=1}^{\\infty} \\rho(k)} = \\frac{T}{\\tau}\n$$\n其中 $T$ 是名义样本量，$\\tau = 1 + 2\\sum_{k=1}^{\\infty} \\rho(k)$ 是积分自相关时间 (IAT)。为了在固定链长度 $T$ 的情况下最大化 ESS，必须最小化 IAT。当自相关系数 $\\rho(k)$ 很小并且随着滞后 $k$ 的增加而迅速衰减至零时，就可以实现这一点。因此，抽样器的效率与链中的持续性成反比。\n\nRWM 算法使用一个提议 $\\theta' = \\theta_t + \\varepsilon$，其中 $\\varepsilon \\sim \\mathcal{N}(0, s^2)$。参数 $s$ 是一个关键的调整参数，它决定了算法的效率。让我们来分析这两种指定的情况。\n\n案例 (i)：提议尺度 $s$ 过大。\n在这种情况下，提议的跳跃 $\\varepsilon$ 很大。由于目标后验分布 $\\pi(\\theta)$ 是单峰且呈钟形的，它将其质量集中在众数周围一个相对较小的区域内。从当前状态 $\\theta_t$（在平稳状态下，该状态很可能处于后验密度高的区域）进行一次大跳跃，很可能会使提议 $\\theta'$ 落入分布的尾部，在那里 $\\pi(\\theta')$ 非常小。\n因此，接受比 $\\frac{\\pi(\\theta')}{\\pi(\\theta_t)}$ 将远小于 $1$。因此，接受概率 $\\alpha(\\theta_t, \\theta') = \\min\\{1, \\frac{\\pi(\\theta')}{\\pi(\\theta_t)}\\}$ 将会非常低。\n大多数提议都被拒绝，这意味着链在许多连续的迭代中都停留在当前状态：$\\theta_{t+1} = \\theta_t$。这种“卡住”的行为导致连续状态之间产生极高的正相关。因此，滞后1阶自相关 $\\rho(1)$ 将非常接近 $1$，整个 ACF $\\rho(k)$ 将极其缓慢地衰减。这导致非常大的 IAT 和非常小的 ESS。链在探索后验空间时效率极低。\n\n案例 (ii)：提议尺度 $s$ 过小。\n在这种情况下，提议的跳跃 $\\varepsilon$ 很小。提议 $\\theta'$ 将非常接近当前状态 $\\theta_t$。只要后验密度 $\\pi(\\theta)$ 是连续的（这是一个标准的假设），$\\pi(\\theta')$ 就会非常接近 $\\pi(\\theta_t)$。\n接受比 $\\frac{\\pi(\\theta')}{\\pi(\\theta_t)}$ 将非常接近 $1$。因此，接受概率 $\\alpha(\\theta_t, \\theta')$ 将会非常高，当 $s \\to 0$ 时趋近于 $1$。\n尽管大多数提议都被接受，但每一步都极其微小。链在参数空间中的移动就像一个缓慢的扩散过程。$\\theta_{t+1}$ 与 $\\theta_t$ 相比仅有微小差异。这同样意味着连续状态是高度相关的。滞后1阶自相关 $\\rho(1)$ 也将非常接近 $1$，ACF $\\rho(k)$ 将非常缓慢地衰减。这也导致了大的 IAT 和小的 ESS。链探索后验空间的效率也非常低，但原因与案例 (i) 不同。\n\n总之，提议尺度 $s$ 的两种极端情况都对抽样效率有害。最高的效率（最小的 IAT，最大的 ESS）是通过一个中间的 $s$ 值来实现的，该值平衡了接受率和步长，使链能够有效地探索后验分布的整个支撑集。众所周知，对于像这样的高斯提议一维问题，最优接受率约为 $0.44$。\n\n现在，我们来评估所提供的选项。\n\nA. 在两种情况下，$\\rho(1)$ 都很大且为正，并随 $k$ 缓慢衰减，但接受率不同：当 $s$ 过大时，接受率非常低，链表现出重复状态；当 $s$ 过小时，接受率非常高，但连续状态非常接近。在这两种情况下，积分自相关时间都很长，有效样本量都很小，只有在 $s$ 取中间值时才有所改善。\n这个陈述准确地总结了上述两种情况下的行为。它正确地指出了高正自相关是共同的病态特征，但正确地区分了其机制：对于大的 $s$，是低接受率和“卡住”；对于小的 $s$，是高接受率但步长极小。它正确地得出结论，两种情况都会导致较差的 ESS，而 ESS 在中间的 $s$ 值处得到优化。这个陈述与 MCMC 的理论一致。\n结论：**正确**。\n\nB. 当 $s$ 过大时，链会频繁地来回跳跃，产生负的 $\\rho(1)$；当 $s$ 过小时，大部分移动都被接受，因此对所有 $k \\ge 1$，$\\rho(k) \\approx 0$，有效样本量达到最大。\n这个陈述在多个方面是错误的。首先，对于 RWM，大的 $s$ 不会导致“来回跳跃”和负的 $\\rho(1)$。它会导致拒绝和停滞不前，从而产生高的*正*自相关。负自相关更多是其他抽样器（如具有特定参数化设置的 Gibbs 或 HMC）的特征。其次，对于小的 $s$，链移动缓慢，因此 $\\theta_t$ 和 $\\theta_{t+k}$ 对于小的 $k$ 是高度相关的，这意味着 $\\rho(k)$ 接近 $1$，而不是 $0$。这会最小化而不是最大化有效样本量。\n结论：**错误**。\n\nC. 当 $s$ 极大时，ACF 衰减最快，因为大跳跃会使链去相关，并且此时接受率高，从而得到最大的有效样本量。\n这个陈述在事实上是错误的。当 $s$ 极大时，接受率是极*低*的，而不是高的。虽然一次成功的大跳跃是去相关的，但链的行为主要由更频繁发生的拒绝事件所主导。结果是一个混合缓慢的链，其 ACF 衰减非常缓慢，而不是最快。这导致最小的 ESS，而非最大的。\n结论：**错误**。\n\nD. 对于一次平稳运行，ACF $\\rho(k)$ 不随 $s$ 的选择而改变；只有预烧期长度受 $s$ 的影响。\n这在根本上是错误的。提议尺度 $s$ 定义了马尔可夫链的转移核。虽然平稳分布 $\\pi(\\theta)$ 不随 $s$ 改变（这是 M-H 算法的构造所保证的），但链的动态特性，如其收敛速度和在平稳状态下的自相关结构，都严重依赖于 $s$。调整 $s$ 正是为了优化这些由 ACF 衡量的动态特性。\n结论：**错误**。\n\nE. 对于对称提议，对任何 $s$，接受率都等于 $0.5$。这意味着在不同 $s$ 选择下观察到的 $\\rho(k)$ 差异是由蒙特卡洛误差而非步长选择造成的。\n这个陈述是错误的。接受率不是一个常数 $0.5$。它是提议尺度 $s$ 的函数，通过比率 $\\pi(\\theta')/\\pi(\\theta_t)$ 体现。关于最优接受率有著名的理论文献（例如，高维时约为 $0.234$，一维时约为 $0.44$），但这些是通过*调整* $s$ 来实现的*目标*，而非固定常数。观察到的 $\\rho(k)$ 差异是选择 $s$ 的直接且真实的结果。\n结论：**错误**。\n\n基于这一严谨的分析，只有选项 A 提供了对该现象的正确而完整的描述。", "answer": "$$\\boxed{A}$$", "id": "2408760"}, {"introduction": "在信任MCMC的输出结果之前，我们必须严格评估马尔可夫链是否已经“收敛”到了目标后验分布。Gelman-Rubin诊断（通常称为$\\hat{R}$统计量）是判断多条链是否收敛到同一分布的最常用工具之一。然而，任何诊断工具都有其局限性。这个练习揭示了一个$\\hat{R}$诊断的关键“盲点”：当所有链都陷入同一个局部模式（local mode）时，$\\hat{R}$值可能看似理想，但实际上采样完全失败。通过这个案例，你将学会批判性地审视诊断结果，并理解在处理可能存在多模态（multimodality）的复杂后验分布时保持警惕的重要性。[@problem_id:2408731]", "problem": "考虑一个计算经济学和金融学中的贝叶斯估计问题，其中一个标量结构参数 $\\theta$ 仅通过 $\\theta^{2}$ 进入似然函数（例如，因子定价方程中符号不定的载荷），从而产生一个对称、分离良好的双峰后验分布\n$$\np(\\theta \\mid y) \\;=\\; \\tfrac{1}{2}\\,\\mathcal{N}\\!\\left(+\\mu,\\sigma^{2}\\right)\\;+\\;\\tfrac{1}{2}\\,\\mathcal{N}\\!\\left(-\\mu,\\sigma^{2}\\right),\n$$\n其中 $\\mu0$，$\\sigma0$，且 $\\mu/\\sigma$ 很大，使得两个众数被良好地分离开。\n\n假设运行了 $m$ 条独立的马尔可夫链蒙特卡洛（MCMC）链，每条链在预烧期（burn-in）后的长度为 $n$，使用的核在一个众数内部混合迅速，但极少穿越众数之间的低后验概率区域。所有链都在 $+\\mu$ 附近初始化，并且在有限的运行时间内，从未访问过另一个众数。因此，在预烧期之后，可以认为各链之间的抽样是独立的，并且每条链内的抽样是服从 $\\mathcal{N}\\!\\left(\\mu,\\sigma^{2}\\right)$ 的独立同分布。\n\n令 $\\bar{\\theta}_{j\\cdot}$ 表示链 $j\\in\\{1,\\dots,m\\}$ 的样本均值，$s_{j}^{2}$ 表示链 $j$ 的样本方差，$\\bar{\\theta}_{\\cdot\\cdot}$ 表示所有链的总均值。Gelman–Rubin 潜在尺度缩减因子（PSRF），也称为 Gelman–Rubin 诊断法，定义如下\n$$\nW \\;=\\; \\frac{1}{m}\\sum_{j=1}^{m} s_{j}^{2},\\qquad\nB \\;=\\; \\frac{n}{m-1}\\sum_{j=1}^{m}\\left(\\bar{\\theta}_{j\\cdot}-\\bar{\\theta}_{\\cdot\\cdot}\\right)^{2},\n$$\n$$\n\\widehat{\\operatorname{Var}}^{+} \\;=\\; \\frac{n-1}{n}\\,W \\;+\\; \\frac{1}{n}\\,B,\\qquad\n\\hat{R} \\;=\\; \\sqrt{\\frac{\\widehat{\\operatorname{Var}}^{+}}{W}}.\n$$\n\n当 $m$ 固定且上述所有假设均成立时，随着 $n\\to\\infty$，关于 $\\hat{R}$ 的哪种说法是正确的？\n\nA. $\\hat{R}$ 依概率收敛到 $1$，尽管链没有探索整个后验支撑集，因此该诊断未能检测出多峰性问题。\n\nB. $\\hat{R}$ 收敛到 $\\sqrt{2}$，因为第二个众数未被访问，所以该诊断正确地指出了不收敛。\n\nC. 随着 $n$ 的增长，$\\hat{R}$ 发散到 $+\\infty$，因为 $B$ 随 $n$ 线性增长。\n\nD. $\\hat{R}$ 收敛到 $0$，因为对于大的 $n$，$W$ 主导了 $B$。", "solution": "必须首先验证问题陈述的科学合理性和一致性。\n\n**步骤 1：提取已知条件**\n\n-   **后验分布：** $p(\\theta \\mid y) = \\frac{1}{2}\\,\\mathcal{N}(+\\mu,\\sigma^{2}) + \\frac{1}{2}\\,\\mathcal{N}(-\\mu,\\sigma^{2})$，其中 $\\theta$ 是一个标量参数，$\\mu  0$，$\\sigma  0$，且 $\\mu/\\sigma$ 很大。\n-   **MCMC 模拟：** $m$ 条独立的链，每条链在预烧期后的长度为 $n$。\n-   **链的行为：** 所有链都在 $+\\mu$ 附近初始化并停留在此处。每条链 $j \\in \\{1, \\dots, m\\}$ 的抽样可被视为来自 $\\mathcal{N}(\\mu, \\sigma^2)$ 的独立同分布（i.i.d.）样本。\n-   **统计量：**\n    -   链内均值：$\\bar{\\theta}_{j\\cdot} = \\frac{1}{n}\\sum_{i=1}^{n}\\theta_{ji}$。\n    -   链内样本方差：$s_{j}^{2} = \\frac{1}{n-1}\\sum_{i=1}^{n}(\\theta_{ji}-\\bar{\\theta}_{j\\cdot})^{2}$。\n    -   总均值：$\\bar{\\theta}_{\\cdot\\cdot} = \\frac{1}{m}\\sum_{j=1}^{m}\\bar{\\theta}_{j\\cdot}$。\n    -   平均链内方差：$W = \\frac{1}{m}\\sum_{j=1}^{m} s_{j}^{2}$。\n    -   链间方差因子：$B = \\frac{n}{m-1}\\sum_{j=1}^{m}(\\bar{\\theta}_{j\\cdot}-\\bar{\\theta}_{\\cdot\\cdot})^{2}$。\n    -   估计的后验方差：$\\widehat{\\operatorname{Var}}^{+} = \\frac{n-1}{n}\\,W + \\frac{1}{n}\\,B$。\n    -   潜在尺度缩减因子（PSRF）：$\\hat{R} = \\sqrt{\\frac{\\widehat{\\operatorname{Var}}^{+}}{W}}$。\n-   **问题：** 确定当 $m$ 固定时，随着 $n\\to\\infty$，$\\hat{R}$ 的行为。\n\n**步骤 2：使用提取的已知条件进行验证**\n\n该问题具有科学依据。它描述了 MCMC 采样器在多峰后验分布情景下一种常见且重要的失效模式。Gelman-Rubin 诊断法（$\\hat{R}$）是评估 MCMC 收敛性的标准工具，而其在这种情景下的潜在失效是计算统计学中一个有据可查的课题。问题中给出的 $W$、$B$、$\\widehat{\\operatorname{Var}}^{+}$ 和 $\\hat{R}$ 的定义都是标准的。整个设定是自洽的、数学上适定且客观的。它提出了一个关于在特定假设下某个统计量渐近行为的清晰问题。\n\n**步骤 3：结论与行动**\n\n问题是有效的。下面将推导解答。\n\n**推导**\n\n目标是求出当 $m$ 固定时，随着 $n \\to \\infty$，$\\hat{R}$ 的极限。$\\hat{R}$ 的表达式可以重写为：\n$$\n\\hat{R} = \\sqrt{\\frac{\\frac{n-1}{n}\\,W + \\frac{1}{n}\\,B}{W}} = \\sqrt{\\frac{n-1}{n} + \\frac{B}{nW}}\n$$\n我们必须确定 $W$ 和 $B/n$ 的依概率极限。\n\n1.  **链内方差 $W$ 的极限：**\n    对于每条链 $j$，抽样 $\\{\\theta_{j1}, \\dots, \\theta_{jn}\\}$ 是来自 $\\mathcal{N}(\\mu, \\sigma^2)$ 的独立同分布样本。样本方差 $s_j^2$ 是总体方差的一致估计量。根据大数定律，当 $n \\to \\infty$ 时：\n    $$\n    s_j^2 \\xrightarrow{p} \\operatorname{Var}(\\theta) = \\sigma^2\n    $$\n    其中 $\\xrightarrow{p}$ 表示依概率收敛。\n    由于 $W$ 是 $m$ 个这样的一致估计量的平均值（$m$ 固定），它也是 $\\sigma^2$ 的一个一致估计量：\n    $$\n    W = \\frac{1}{m}\\sum_{j=1}^{m} s_{j}^{2} \\xrightarrow{p} \\frac{1}{m}\\sum_{j=1}^{m} \\sigma^2 = \\sigma^2\n    $$\n\n2.  **链间方差项 $B/n$ 的极限：**\n    统计量 $B$ 由 $B = \\frac{n}{m-1}\\sum_{j=1}^{m}(\\bar{\\theta}_{j\\cdot}-\\bar{\\theta}_{\\cdot\\cdot})^{2}$ 给出。我们关心 $B/n$ 的行为：\n    $$\n    \\frac{B}{n} = \\frac{1}{m-1}\\sum_{j=1}^{m}\\left(\\bar{\\theta}_{j\\cdot}-\\bar{\\theta}_{\\cdot\\cdot}\\right)^{2}\n    $$\n    这是链均值 $\\{\\bar{\\theta}_{1\\cdot}, \\dots, \\bar{\\theta}_{m\\cdot}\\}$ 的样本方差。\n    对于每条链 $j$，$\\bar{\\theta}_{j\\cdot}$ 是来自 $\\mathcal{N}(\\mu, \\sigma^2)$ 的 $n$ 个独立同分布抽样的样本均值。根据大数定律，当 $n \\to \\infty$ 时：\n    $$\n    \\bar{\\theta}_{j\\cdot} \\xrightarrow{p} E[\\theta] = \\mu\n    $$\n    总均值 $\\bar{\\theta}_{\\cdot\\cdot} = \\frac{1}{m}\\sum_{j=1}^{m}\\bar{\\theta}_{j\\cdot}$ 也依概率收敛到 $\\mu$。\n    因此，对于每个 $j$，差值 $(\\bar{\\theta}_{j\\cdot}-\\bar{\\theta}_{\\cdot\\cdot}) \\xrightarrow{p} (\\mu - \\mu) = 0$。\n    因为这对求和中的所有项都成立且 $m$ 是固定的，所以整个和收敛到 $0$：\n    $$\n    \\frac{B}{n} = \\frac{1}{m-1}\\sum_{j=1}^{m}\\left(\\bar{\\theta}_{j\\cdot}-\\bar{\\theta}_{\\cdot\\cdot}\\right)^{2} \\xrightarrow{p} 0\n    $$\n\n3.  **$\\hat{R}$ 的极限：**\n    现在我们可以整合出 $\\hat{R}^2$ 的极限。当 $n \\to \\infty$ 时：\n    -   $\\frac{n-1}{n} \\to 1$。\n    -   $W \\xrightarrow{p} \\sigma^2$。\n    -   $B/n \\xrightarrow{p} 0$。\n    \n    对 $\\hat{R}^2$ 的表达式应用 Slutsky 定理：\n    $$\n    \\hat{R}^2 = \\frac{n-1}{n} + \\frac{B/n}{W} \\xrightarrow{p} 1 + \\frac{0}{\\sigma^2} = 1\n    $$\n    由于平方根函数在 $1$ 处是连续的，我们可以应用连续映射定理：\n    $$\n    \\hat{R} = \\sqrt{\\hat{R}^2} \\xrightarrow{p} \\sqrt{1} = 1\n    $$\n\n**解释与选项评估**\n\n分析表明 $\\hat{R}$ 收敛到 $1$。在实践中，$\\hat{R} \\approx 1$ 被用作一个诊断标准，以宣告 MCMC 链已收敛到目标平稳分布。\n\n然而，在所述情景中，这些链显然未能正确收敛。它们只探索了双峰后验分布的一个众数。后验分布 $p(\\theta|y)$ 的真实方差是 $\\operatorname{Var}(\\theta) = E[\\theta^2] - (E[\\theta])^2 = (\\sigma^2 + \\mu^2) - 0^2 = \\sigma^2 + \\mu^2$。因为 $\\mu/\\sigma$ 很大，这个真实方差远大于 $\\sigma^2$。\n\n估计方差 $\\widehat{\\operatorname{Var}}^{+} = \\frac{n-1}{n}W + \\frac{1}{n}B$ 依概率收敛到 $\\sigma^2$。该估计量严重低估了真实的后验方差。Gelman-Rubin 诊断法将这个有缺陷的总方差估计 ($\\widehat{\\operatorname{Var}}^{+}$) 与有缺陷的链内方差估计 ($W$) 进行比较，发现它们渐近地相同 ($\\sigma^2$)，并得出结论其比率为 $1$。这表明了收敛，从而掩盖了 MCMC 采样器未能探索整个后验支撑集的严重失败。\n\n**逐项分析选项**\n\nA. **$\\hat{R}$ 依概率收敛到 $1$，尽管链没有探索整个后验支撑集，因此该诊断未能检测出多峰性问题。**\n这个说法与我们的推导完全一致。$\\hat{R}$ 收敛到 $1$，这个结果错误地表明了收敛，因此未能指出采样器无法找到位于 $-\\mu$ 的众数的问题。**正确**。\n\nB. **$\\hat{R}$ 收敛到 $\\sqrt{2}$，因为第二个众数未被访问，所以该诊断正确地指出了不收敛。**\n极限是 $1$，而不是 $\\sqrt{2}$。这个极限的前提是错误的。**不正确**。\n\nC. **随着 $n$ 的增长，$\\hat{R}$ 发散到 $+\\infty$，因为 $B$ 随 $n$ 线性增长。**\n我们的分析表明 $B/n \\xrightarrow{p} 0$。这意味着 $B$ 不随 $n$ 线性增长。实际上，$B$ 在分布上收敛到一个均值为 $\\sigma^2$ 的随机变量，并且不发散。因此，$\\hat{R}$ 不会发散。**不正确**。\n\nD. **$\\hat{R}$ 收敛到 $0$，因为对于大的 $n$，$W$ 主导了 $B$。**\n$\\hat{R}$ 的极限是 $1$，而不是 $0$。$\\hat{R}^2$ 中的主项是 $\\frac{n-1}{n}$，它趋近于 $1$。包含 $B$ 的项消失了，但它并没有将整个极限驱动到 $0$。**不正确**。", "answer": "$$\\boxed{A}$$", "id": "2408731"}]}