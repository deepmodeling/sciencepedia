{"hands_on_practices": [{"introduction": "即使是强大的工具也有其局限性。本练习将挑战您构建一个场景，在该场景中，复杂的全局多项式逼近（Smolyak-Chebyshev方法）的性能反被更简单的局部方法（分段三线性插值）超越[@problem_id:2399802]。通过这种动手比较，您将深化对函数平滑度如何决定最佳逼近策略的理解，并认识到在不适宜的条件下应用特定方法可能遇到的陷阱。", "problem": "考虑紧域 $\\mathcal{D}=[-1,1]^3$，其坐标为 $(x,y,z)$。您的任务是构造一个特定的三维函数 $f:\\mathcal{D}\\to\\mathbb{R}$，使其沿一个平面呈现不可微的尖点 (kink)，从而对于一定范围的离散化参数，基于 Chebyshev 多项式并通过 Smolyak 稀疏网格组合的全局多项式插值，会比在均匀张量网格上的局部逐片三线性插值产生更大的均方根误差。请完全从第一性原理出发：定义该函数，精确定义两种逼近算子，在固定的评估网格上对两者进行求值，并比较最终的误差。\n\n使用以下数学定义。\n\n1) 函数类。对于固定的阈值参数 $\\tau\\in\\mathbb{R}$，定义\n$$\nf_\\tau(x,y,z)=\\max\\{0,\\; x+y+z-\\tau\\},\\quad (x,y,z)\\in[-1,1]^3.\n$$\n在下述每个测试用例中，选择并明确使用指定的特定成员 $f_{\\tau}$。\n\n2) 一维 Chebyshev–Lobatto 节点和重心权重。对于正整数 $m\\ge 1$，定义节点\n$$\nx_j=\\cos\\left(\\frac{\\pi j}{m-1}\\right),\\quad j=0,1,\\dots,m-1,\n$$\n并约定当 $m=1$ 时，单个节点为 $x_0=0$。相关的重心权重 $\\lambda_j$ 为\n$$\n\\lambda_j = (-1)^j\\cdot \\delta_j,\\quad \\delta_j=\\begin{cases}\\tfrac{1}{2},& j\\in\\{0,m-1\\}\\ \\text{and}\\ m\\ge 2, \\\\[4pt]\n1,& \\text{otherwise.}\n\\end{cases}\n$$\n当 $m=1$ 时，取 $\\lambda_0=1$。\n\n给定具有重心权重 $(\\lambda_j)_{j=0}^{m-1}$ 的不同节点 $(x_j)_{j=0}^{m-1}$ 和数据值 $(y_j)_{j=0}^{m-1}$，函数 $g$ 的一维重心插值多项式 $U_m[g]$ 是一个次数至多为 $m-1$ 的多项式，其逐点定义如下\n$$\nU_m[g](x)=\n\\begin{cases}\ng(x_k),& \\text{if }x=x_k\\ \\text{for some }k, \\\\[6pt]\n\\dfrac{\\displaystyle \\sum_{j=0}^{m-1}\\dfrac{\\lambda_j}{x-x_j}g(x_j)}{\\displaystyle \\sum_{j=0}^{m-1}\\dfrac{\\lambda_j}{x-x_j}},& \\text{otherwise.}\n\\end{cases}\n$$\n\n3) $d=3$ 维的 Smolyak 稀疏网格 Chebyshev 插值。对于一维层级 $\\ell\\in\\mathbb{N}$，设\n$$\nm(\\ell)=\\begin{cases}\n1,& \\ell=1,\\\\\n2^{\\ell-1}+1,& \\ell\\ge 2,\n\\end{cases}\n$$\n并令 $U_{m(\\ell)}$ 为前述定义、在基数为 $m(\\ell)$ 的 Chebyshev–Lobatto 节点上的一维插值。对于总层级 $L\\in\\mathbb{N}$ 和 $d=3$，定义 Smolyak 指数集\n$$\n\\mathcal{I}_{L}=\\left\\{\\boldsymbol{\\ell}=(\\ell_1,\\ell_2,\\ell_3)\\in\\mathbb{N}^3:\\ \\ell_i\\ge 1,\\ \\ \\ell_1+\\ell_2+\\ell_3\\le L+2\\right\\}.\n$$\n对于 $\\boldsymbol{\\ell}\\in\\mathcal{I}_L$，定义组合系数\n$$\nw(\\boldsymbol{\\ell};L)=(-1)^{\\,L+2-(\\ell_1+\\ell_2+\\ell_3)}\\binom{2}{\\,L+2-(\\ell_1+\\ell_2+\\ell_3)\\,}.\n$$\nSmolyak 插值算子 $A_L[f]$ 是一个线性算子\n$$\nA_L[f](x,y,z)=\\sum_{\\boldsymbol{\\ell}\\in\\mathcal{I}_L} w(\\boldsymbol{\\ell};L)\\,\\big(U_{m(\\ell_1)}\\otimes U_{m(\\ell_2)}\\otimes U_{m(\\ell_3)}\\big)[f](x,y,z),\n$$\n其中 $\\otimes$ 表示沿每个坐标的一维插值的张量积应用。\n\n4) 均匀张量网格和逐片三线性插值。对于整数 $M\\ge 2$，在 $[-1,1]$ 上定义一个均匀网格，其节点为\n$$\n\\xi_j=-1+\\frac{2j}{M-1},\\quad j=0,1,\\dots,M-1.\n$$\n逐片三线性插值函数 $T_M[f]$ 是唯一的函数，它在每个网格单元上是三线性的，并且在所有张量网格节点上与 $f$ 的值相匹配。\n\n5) 离散均方根误差 (RMSE)。对于整数 $E\\ge 2$，定义一个每轴有 $E$ 个节点的评估网格\n$$\n\\zeta_k=-1+\\frac{2k}{E-1},\\quad k=0,1,\\dots,E-1.\n$$\n给定在 $\\mathcal{D}$ 上 $f$ 的一个逼近函数 $\\hat{f}$，定义离散 RMSE\n$$\n\\mathrm{RMSE}(\\hat{f},f)=\\left(\\frac{1}{E^3}\\sum_{i=0}^{E-1}\\sum_{j=0}^{E-1}\\sum_{k=0}^{E-1}\\big(\\hat{f}(\\zeta_i,\\zeta_j,\\zeta_k)-f(\\zeta_i,\\zeta_j,\\zeta_k)\\big)^2\\right)^{1/2}.\n$$\n\n实现一个完整的程序，为每个测试用例执行以下操作：构造指定的 $f_\\tau$，如上定义构造 $A_L[f_\\tau]$ 和 $T_M[f_\\tau]$，在同一个评估网格上对两个逼近函数和 $f_\\tau$ 进行求值，计算 RMSE，并报告标量差值\n$$\n\\Delta=\\mathrm{RMSE}\\big(A_L[f_\\tau],f_\\tau\\big)-\\mathrm{RMSE}\\big(T_M[f_\\tau],f_\\tau\\big).\n$$\n正的 $\\Delta$ 值表示 Smolyak 网格上的 Chebyshev 插值性能劣于逐片三线性插值。\n\n使用以下测试套件，它通过改变尖点位置和离散化层级来探究典型、邻近边界和较低层级的情况：\n\n- 测试用例 1：$\\tau=0.0$, $L=4$, $M=25$, $E=31$。\n- 测试用例 2：$\\tau=0.9$, $L=5$, $M=29$, $E=31$。\n- 测试用例 3：$\\tau=-0.2$, $L=3$, $M=21$, $E=31$。\n\n最终输出格式。您的程序应生成单行输出，其中包含来自上述三个测试用例的数值结果 $\\Delta$，形式为用方括号括起来的逗号分隔列表，每个标量值四舍五入到六位小数（例如，$[\\delta_1,\\delta_2,\\delta_3]$）。", "solution": "该问题陈述已经过严格验证，并被确定为有效。它在科学上基于数值分析和逼近理论的原理，问题设定良好（well-posed），提供了所有必要的定义和参数，并以客观、正式的语言表述。该问题是计算数学中的一个标准的、可验证的练习，旨在比较全局多项式逼近方法 (Smolyak-Chebyshev) 与局部逐片多项式方法（逐片三线性）在处理一个光滑度较低的函数时的效能。因此，我们将提供一个完整的解决方案。\n\n目标是计算函数 $f_\\tau(x,y,z)=\\max\\{0,\\; x+y+z-\\tau\\}$ 在域 $\\mathcal{D}=[-1,1]^3$ 上的两种逼近方案之间的均方根误差之差 $\\Delta$。正的 $\\Delta$ 值表示 Smolyak-Chebyshev 方法产生的误差大于逐片三线性方法。函数 $f_\\tau$ 是连续的，但在由 $x+y+z-\\tau=0$ 定义的平面上不可微，在该处存在一个“尖点”(kink)。这种缺乏光滑性的特点是本测试的核心所在。\n\n我们的步骤如下：\n1.  定义目标函数 $f_\\tau$ 和评估网格。\n2.  构造逐片三线性插值函数 $T_M[f_\\tau]$ 并在网格上对其求值。\n3.  构造 Smolyak 稀疏网格插值函数 $A_L[f_\\tau]$ 并在同一网格上对其求值。\n4.  计算两种逼近相对于真实函数的离散均方根误差 (RMSE)。\n5.  计算差值 $\\Delta = \\mathrm{RMSE}(A_L[f_\\tau]) - \\mathrm{RMSE}(T_M[f_\\tau])$。\n\n**1. 评估框架**\n\n对于每个测试用例，我们给定函数 $f_\\tau$ 的参数 $\\tau$、Smolyak 网格的层级 $L$、三线性插值的网格大小 $M$，以及评估网格的分辨率 $E$。评估网格是 $\\mathcal{D}=[-1,1]^3$ 上的一个均匀张量积网格，每个轴上有 $E$ 个点，由节点 $\\zeta_k=-1+\\frac{2k}{E-1}$ ($k=0, \\dots, E-1$) 给出。所有的逼近函数和真实函数都将在此网格的 $E^3$ 个点上进行计算。\n\n**2. 逐片三线性插值 $T_M[f_\\tau]$**\n\n此方法依赖于在均匀网格的每个单元内的局部逼近。\n首先，定义一个每轴有 $M$ 个节点的均匀张量网格：$\\xi_j=-1+\\frac{2j}{M-1}$ ($j=0, \\dots, M-1$)。这将域 $\\mathcal{D}$ 划分为 $(M-1)^3$ 个立方体单元。在 $M^3$ 个网格节点中的每一个上计算函数 $f_\\tau$ 的值。\n\n为了在某个评估点 $(x,y,z)$ 上找到插值 $T_M[f_\\tau]$ 的值，我们首先确定包含该点的单元 $[\\xi_{j_x}, \\xi_{j_x+1}] \\times [\\xi_{j_y}, \\xi_{j_y+1}] \\times [\\xi_{j_z}, \\xi_{j_z+1}]$。然后使用该单元八个角点的已知函数值通过三线性插值计算出该值。这可以通过使用 `scipy.ndimage.map_coordinates` 函数来高效实现，该函数执行N维逐片线性插值。评估坐标 $(\\zeta_i, \\zeta_j, \\zeta_k)$ 在传递给该函数之前，会被映射到 $M$ 点网格的基于索引的坐标系中。\n\n**3. Smolyak 稀疏网格插值 $A_L[f_\\tau]$**\n\n对于足够光滑的函数，Smolyak 构造法提供了一种由一维插值组合来构建高维插值的方法，其随维度增加的尺度伸缩性优于全张量积。对于维度 $d=3$ 和层级 $L$，其算子为：\n$$\nA_L[f] = \\sum_{\\boldsymbol{\\ell}\\in\\mathcal{I}_L} w(\\boldsymbol{\\ell};L)\\,\\big(U_{m(\\ell_1)}\\otimes U_{m(\\ell_2)}\\otimes U_{m(\\ell_3)}\\big)[f]\n$$\n其中 $\\boldsymbol{\\ell}=(\\ell_1,\\ell_2,\\ell_3)$ 是一维层级的多重索引。其组成部分为：\n-   **指数集**: $\\mathcal{I}_{L}=\\left\\{\\boldsymbol{\\ell}\\in\\mathbb{N}^3:\\ \\ell_1+\\ell_2+\\ell_3\\le L+2\\right\\}$。\n-   **组合系数**: $w(\\boldsymbol{\\ell};L)=(-1)^{\\,L+2-|\\boldsymbol{\\ell}|_1}\\binom{2}{\\,L+2-|\\boldsymbol{\\ell}|_1\\,}$，其中 $|\\boldsymbol{\\ell}|_1=\\ell_1+\\ell_2+\\ell_3$。这些系数仅在 $L \\le |\\boldsymbol{\\ell}|_1 \\le L+2$ 时非零。\n-   **一维插值**: $U_{m(\\ell)}$ 是在 $m(\\ell)$ 个 Chebyshev-Lobatto 节点上的重心多项式插值。节点数为 $m(1)=1$，当 $\\ell \\ge 2$ 时为 $m(\\ell)=2^{\\ell-1}+1$。\n\n在评估网格上对 $A_L[f_\\tau]$ 的求值过程如下：\n一个初始化为零的累加器网格用于存储最终的逼近值。我们遍历活动指数集（其中 $w(\\boldsymbol{\\ell};L) \\neq 0$）中的每个多重索引 $\\boldsymbol{\\ell}$。对于每个 $\\boldsymbol{\\ell}$：\na. 分别沿 $x$、$y$ 和 $z$ 轴，由 $m(\\ell_1)$、$m(\\ell_2)$ 和 $m(\\ell_3)$ 个 Chebyshev-Lobatto 节点构成一个稀疏张量积网格。\nb. 在该稀疏网格的所有节点上计算真实函数 $f_\\tau$ 的值。\nc. 从这个稀疏网格到稠密的 $E \\times E \\times E$ 评估网格执行三维张量积重心插值。这通过沿每个维度依次应用一维重心插值公式来完成。\nd. 将得到的插值结果乘以系数 $w(\\boldsymbol{\\ell};L)$ 并加到累加器网格中。\n\n一维重心插值公式因其数值稳定性，对于 Chebyshev 点非常有效。对于一组节点 $(x_j)$、值 $(y_j)$ 和重心权重 $(\\lambda_j)$，在点 $x$ 的插值由 $\\left(\\sum_j \\frac{\\lambda_j y_j}{x-x_j}\\right) / \\left(\\sum_j \\frac{\\lambda_j}{x-x_j}\\right)$ 给出。\n\n**4. 误差计算与比较**\n\n在评估网格上计算出两种逼近 $A_L[f_\\tau]$ 和 $T_M[f_\\tau]$ 的值后，计算它们各自的离散均方根误差：\n$$\n\\mathrm{RMSE}(\\hat{f},f)=\\left(\\frac{1}{E^3}\\sum_{i,j,k=0}^{E-1}\\big(\\hat{f}(\\zeta_i,\\zeta_j,\\zeta_k)-f_\\tau(\\zeta_i,\\zeta_j,\\zeta_k)\\big)^2\\right)^{1/2}\n$$\n每个测试用例的最终结果是差值 $\\Delta = \\mathrm{RMSE}(A_L[f_\\tau]) - \\mathrm{RMSE}(T_M[f_\\tau])$。函数 $f_\\tau$ 几乎处处是线性的，但其尖点违反了保证全局多项式方法快速收敛的光滑性假设。相比之下，逐片线性方法是局部的；其误差主要局限于被尖点穿过的单元格内。因此，可以预期在给定参数下，$\\Delta$ 将为正值，这表明局部、低阶方法在某些场景下更为优越。", "answer": "```python\nimport numpy as np\nfrom scipy.special import comb\nfrom scipy.ndimage import map_coordinates\n\ndef get_cheby_grid(m, cache):\n    \"\"\"\n    Computes or retrieves from cache the Chebyshev-Lobatto nodes and barycentric weights.\n    \"\"\"\n    if m in cache:\n        return cache[m]\n\n    if m == 1:\n        nodes = np.array([0.0])\n        weights = np.array([1.0])\n        cache[m] = (nodes, weights)\n        return nodes, weights\n\n    j = np.arange(m)\n    nodes = np.cos(np.pi * j / (m - 1))\n    \n    weights = (-1.0)**j\n    weights[0] *= 0.5\n    weights[-1] *= 0.5\n    \n    cache[m] = (nodes, weights)\n    return nodes, weights\n\ndef barycentric_interp1d(x_eval, x_nodes, y_nodes, bary_weights):\n    \"\"\"\n    Performs 1D barycentric interpolation on a vector of evaluation points.\n    \"\"\"\n    Ne = x_eval.shape[0]\n    Nm = x_nodes.shape[0]\n    \n    if Nm == 1:\n        return np.full(Ne, y_nodes[0])\n\n    interp_vals = np.zeros(Ne, dtype=np.float64)\n    exact_matches = np.zeros(Ne, dtype=bool)\n\n    # Handle cases where evaluation points are very close to nodes\n    for j in range(Nm):\n        matches = np.isclose(x_eval, x_nodes[j])\n        if np.any(matches):\n            interp_vals[matches] = y_nodes[j]\n            exact_matches |= matches\n\n    # Process points that are not nodes using the vectorized formula\n    non_match_indices = np.where(~exact_matches)[0]\n    if len(non_match_indices) > 0:\n        x_sub_eval = x_eval[non_match_indices]\n        \n        diff = x_sub_eval[:, None] - x_nodes[None, :]\n        temp = bary_weights[None, :] / diff\n        \n        numerator = np.sum(temp * y_nodes[None, :], axis=1)\n        denominator = np.sum(temp, axis=1)\n\n        # Avoid division by zero, although it is unlikely for non-node points\n        result = np.divide(numerator, denominator, \n                           out=np.zeros_like(numerator), \n                           where=denominator != 0)\n        \n        interp_vals[non_match_indices] = result\n\n    return interp_vals\n\ndef compute_smolyak_approx(f, L, eval_grid_1d, cache):\n    \"\"\"\n    Computes the Smolyak sparse grid approximation on the evaluation grid.\n    \"\"\"\n    E = len(eval_grid_1d)\n    approx_values = np.zeros((E, E, E), dtype=np.float64)\n\n    # Generate Smolyak index set and coefficients\n    indices_and_coeffs = []\n    max_level_sum = L + 2\n    for l1 in range(1, max_level_sum + 1):\n        for l2 in range(1, max_level_sum - l1 + 1):\n            for l3 in range(1, max_level_sum - l1 - l2 + 1):\n                level_sum = l1 + l2 + l3\n                k = max_level_sum - level_sum\n                if 0 <= k <= 2:\n                    w = ((-1)**k) * comb(2, k, exact=True)\n                    if w != 0:\n                        indices_and_coeffs.append(((l1, l2, l3), w))\n\n    m_func = lambda l: 1 if l == 1 else 2**(l - 1) + 1\n\n    for (l1, l2, l3), w in indices_and_coeffs:\n        m1, m2, m3 = m_func(l1), m_func(l2), m_func(l3)\n        \n        nodes1, weights1 = get_cheby_grid(m1, cache)\n        nodes2, weights2 = get_cheby_grid(m2, cache)\n        nodes3, weights3 = get_cheby_grid(m3, cache)\n\n        grid_x, grid_y, grid_z = np.meshgrid(nodes1, nodes2, nodes3, indexing='ij')\n        f_on_grid = f(grid_x, grid_y, grid_z)\n        \n        # Sequentially apply 1D interpolation\n        interp1 = np.zeros((E, m2, m3), dtype=np.float64)\n        for j in range(m2):\n            for k in range(m3):\n                interp1[:, j, k] = barycentric_interp1d(eval_grid_1d, nodes1, f_on_grid[:, j, k], weights1)\n\n        interp2 = np.zeros((E, E, m3), dtype=np.float64)\n        for i in range(E):\n            for k in range(m3):\n                interp2[i, :, k] = barycentric_interp1d(eval_grid_1d, nodes2, interp1[i, :, k], weights2)\n\n        tensor_prod_interp = np.zeros((E, E, E), dtype=np.float64)\n        for i in range(E):\n            for j in range(E):\n                tensor_prod_interp[i, j, :] = barycentric_interp1d(eval_grid_1d, nodes3, interp2[i, j, :], weights3)\n        \n        approx_values += w * tensor_prod_interp\n        \n    return approx_values\n\ndef compute_trilinear_approx(f, M, eval_xx, eval_yy, eval_zz):\n    \"\"\"\n    Computes the piecewise trilinear approximation on the evaluation grid.\n    \"\"\"\n    grid_nodes_1d = np.linspace(-1., 1., M)\n    grid_x, grid_y, grid_z = np.meshgrid(grid_nodes_1d, grid_nodes_1d, grid_nodes_1d, indexing='ij')\n    f_on_uniform_grid = f(grid_x, grid_y, grid_z)\n    \n    # Map physical coordinates of the evaluation grid to the index coordinates of the M-point grid\n    h = 2.0 / (M - 1)\n    coords_x = (eval_xx - (-1)) / h\n    coords_y = (eval_yy - (-1)) / h\n    coords_z = (eval_zz - (-1)) / h\n    \n    coords = np.stack([coords_x, coords_y, coords_z])\n    \n    # Use SciPy's map_coordinates for efficient N-D linear interpolation\n    approx_values = map_coordinates(f_on_uniform_grid, coords, order=1, mode='nearest')\n    \n    return approx_values\n\ndef solve():\n    \"\"\"\n    Main driver function to run test cases and compute the error difference.\n    \"\"\"\n    test_cases = [\n        (0.0, 4, 25, 31),\n        (0.9, 5, 29, 31),\n        (-0.2, 3, 21, 31),\n    ]\n\n    results = []\n    cheby_cache = {}\n\n    for i, (tau, L, M, E) in enumerate(test_cases):\n        f = lambda x, y, z: np.maximum(0., x + y + z - tau)\n        \n        eval_grid_1d = np.linspace(-1., 1., E)\n        eval_xx, eval_yy, eval_zz = np.meshgrid(eval_grid_1d, eval_grid_1d, eval_grid_1d, indexing='ij')\n        \n        f_true_values = f(eval_xx, eval_yy, eval_zz)\n\n        # Smolyak-Chebyshev approximation\n        A_L_values = compute_smolyak_approx(f, L, eval_grid_1d, cheby_cache)\n        rmse_A = np.sqrt(np.mean((A_L_values - f_true_values)**2))\n\n        # Piecewise trilinear approximation\n        T_M_values = compute_trilinear_approx(f, M, eval_xx, eval_yy, eval_zz)\n        rmse_T = np.sqrt(np.mean((T_M_values - f_true_values)**2))\n\n        delta = rmse_A - rmse_T\n        results.append(delta)\n\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2399802"}, {"introduction": "在计算科学中，性能不仅取决于精度，还与资源效率息息相关。本练习将视角从算法实现转向实际的设计抉择，要求您比较稀疏网格与神经网络这两种表示在完成相似逼近任务时的内存占用[@problem_id:2399843]。通过完成这一计算，您将洞悉这两大类主流函数逼近器在结构和存储成本上的权衡。", "problem": "一位研究人员正在超立方体 $\\left[-1,1\\right]^4$ 上对一个具有 $4$ 个状态变量的动态规划模型中的 Bellman 值函数进行逼近。考虑了两种可实现相似逼近误差的备选表示法。\n\n表示法A使用了一个4级Smolyak稀疏网格，该网格具有各向同性索引集和嵌套的一维Clenshaw–Curtis横坐标点。设一维增长规则为 $m(1)=1$, $m(2)=3$, $m(3)=5$, $m(4)=9$，并定义层级增量为 $p(i)=m(i)-m(i-1)$（对于 $i \\ge 2$），其中 $m(0)=0$，且 $p(1)=1$。Smolyak多重索引集为\n$$\n\\mathcal{I}_{4,4}=\\left\\{\\mathbf{i}\\in \\mathbb{N}^4: \\sum_{k=1}^{4} i_k \\le 4+4-1,\\ i_k \\ge 1\\right\\}。\n$$\n存储的层级系数数量等于\n$$\nN_{\\mathrm{S}}=\\sum_{\\mathbf{i}\\in \\mathcal{I}_{4,4}} \\prod_{k=1}^{4} p(i_k)。\n$$\n假设每个系数存储为一个64位浮点数。\n\n表示法B使用了一个全连接前馈神经网络，该网络具有一个宽度为64的隐藏层、修正线性单元（ReLU）激活函数、4个输入维度和一个标量输出。所有的权重和偏置都以32位浮点数格式存储。存储的参数总数等于所有层的权重和偏置之和。\n\n计算比率\n$$\nR=\\frac{\\text{表示法A占用的内存}}{\\text{表示法B占用的内存}}，\n$$\n结果为纯数。将您的答案四舍五入到四位有效数字。", "solution": "首先必须验证问题陈述的科学合理性、清晰度和完整性。\n\n步骤1：提取已知条件\n- 逼近域：超立方体 $\\left[-1,1\\right]^4$。\n- 状态变量数量（维度）：$d=4$。\n- 表示法A：4级Smolyak稀疏网格。\n- 横坐标点的一维增长规则：$m(1)=1$, $m(2)=3$, $m(3)=5$, $m(4)=9$。\n- 层级增量定义：$p(i)=m(i)-m(i-1)$（对于 $i \\ge 2$），其中 $m(0)=0$，且 $p(1)=1$。\n- Smolyak多重索引集：$\\mathcal{I}_{4,4}=\\left\\{\\mathbf{i}\\in \\mathbb{N}^4: \\sum_{k=1}^{4} i_k \\le 4+4-1,\\ i_k \\ge 1\\right\\}$。\n- 表示法A中存储的系数数量：$N_{\\mathrm{S}}=\\sum_{\\mathbf{i}\\in \\mathcal{I}_{4,4}} \\prod_{k=1}^{4} p(i_k)$。\n- 表示法A的存储：每个系数一个64位浮点数。\n- 表示法B：全连接前馈神经网络。\n- 网络架构：输入维度为4，一个宽度为64的隐藏层，一个标量输出。\n- 激活函数：修正线性单元（ReLU）。\n- 表示法B的存储：所有权重和偏置以32位浮点格式存储。\n- 任务：计算比率 $R=\\frac{\\text{表示法A占用的内存}}{\\text{表示法B占用的内存}}$，并四舍五入到四位有效数字。\n\n步骤2：使用提取的已知条件进行验证\n该问题具有科学依据，因为它涉及两种高维函数逼近的标准方法——稀疏网格和神经网络——的内存需求比较。这些是计算科学（包括计算经济学和计算金融学）中广泛使用的技术。该问题是适定的，提供了得出唯一解所需的所有必要定义、参数和数值。其语言客观且精确。提供的增长规则 $m(i)$ 对应于标准的嵌套Clenshaw-Curtis求积点，这与上下文一致。索引集的定义是明确的。不存在矛盾、歧义或关键信息的缺失。\n\n步骤3：结论与行动\n该问题被认为是有效的。将提供一个完整的解法。\n\n解题过程首先计算每种表示法的内存占用，然后计算它们的比率。\n\n表示法A（Smolyak稀疏网格）的内存：\n内存使用量是层级系数数量 $N_{\\mathrm{S}}$ 与每个系数大小的乘积。每个系数是一个64位数，相当于8字节。\n\n首先，我们必须计算所需索引范围 $i$ 内的层级增量 $p(i)$ 的值。索引集 $\\mathcal{I}_{4,4}$ 由 $\\mathbf{i}=(i_1, i_2, i_3, i_4)$ 定义，其中 $i_k \\ge 1$ 且 $\\sum_{k=1}^4 i_k \\le 7$。任何单个分量 $i_k$ 的最大值出现在其他三个分量取最小值（即等于1）时，得到 $i_k + 1 + 1 + 1 \\le 7$，这意味着 $i_k \\le 4$。因此，我们需要计算 $i \\in \\{1, 2, 3, 4\\}$ 的 $p(i)$。\n- $p(1) = 1$ (给定)。\n- $p(2) = m(2) - m(1) = 3 - 1 = 2$。\n- $p(3) = m(3) - m(2) = 5 - 3 = 2$。\n- $p(4) = m(4) - m(3) = 9 - 5 = 4$。\n\n接下来，我们计算系数总数 $N_{\\mathrm{S}}$。\n$$\nN_{\\mathrm{S}}=\\sum_{\\mathbf{i}\\in \\mathcal{I}_{4,4}} \\prod_{k=1}^{4} p(i_k) = \\sum_{\\substack{i_1 \\ge 1, i_2 \\ge 1, i_3 \\ge 1, i_4 \\ge 1 \\\\ i_1+i_2+i_3+i_4 \\le 7}} \\left( p(i_1) p(i_2) p(i_3) p(i_4) \\right)\n$$\n这个和可以通过枚举将整数4到7划分为4个部分的所有情况来计算。设 $S_q = \\sum_{\\sum i_k = q, i_k \\ge 1} \\prod p(i_k)$。则 $N_{\\mathrm{S}} = \\sum_{q=4}^7 S_q$。\n- 对于 $q=4$：唯一的多重索引是 $(1,1,1,1)$。\n$S_4 = p(1)^4 = 1^4 = 1$。\n- 对于 $q=5$：多重索引是 $(2,1,1,1)$ 的排列。有 $\\binom{4}{1}=4$ 种这样的排列。\n$S_5 = 4 \\times p(2)p(1)^3 = 4 \\times 2 \\times 1^3 = 8$。\n- 对于 $q=6$：多重索引是 $(3,1,1,1)$ 或 $(2,2,1,1)$ 的排列。\n$(3,1,1,1)$ 的排列数是 $\\binom{4}{1}=4$。贡献为 $4 \\times p(3)p(1)^3 = 4 \\times 2 \\times 1^3 = 8$。\n$(2,2,1,1)$ 的排列数是 $\\binom{4}{2}=6$。贡献为 $6 \\times p(2)^2p(1)^2 = 6 \\times 2^2 \\times 1^2 = 24$。\n$S_6 = 8 + 24 = 32$。\n- 对于 $q=7$：多重索引是 $(4,1,1,1)$、$(3,2,1,1)$ 或 $(2,2,2,1)$ 的排列。\n$(4,1,1,1)$ 的排列数是 $\\binom{4}{1}=4$。贡献为 $4 \\times p(4)p(1)^3 = 4 \\times 4 \\times 1^3 = 16$。\n$(3,2,1,1)$ 的排列数是 $\\frac{4!}{1!1!2!} = 12$。贡献为 $12 \\times p(3)p(2)p(1)^2 = 12 \\times 2 \\times 2 \\times 1^2 = 48$。\n$(2,2,2,1)$ 的排列数是 $\\binom{4}{1}=4$。贡献为 $4 \\times p(2)^3p(1) = 4 \\times 2^3 \\times 1 = 32$。\n$S_7 = 16 + 48 + 32 = 96$。\n\n系数总数为：\n$$\nN_{\\mathrm{S}} = S_4 + S_5 + S_6 + S_7 = 1 + 8 + 32 + 96 = 137\n$$\n表示法A的内存需求为：\n$$\n\\text{内存}_{\\mathrm{A}} = N_{\\mathrm{S}} \\times 64 \\text{ 位} = 137 \\times 8 \\text{ 字节} = 1096 \\text{ 字节}\n$$\n\n表示法B（神经网络）的内存：\n内存使用量是可训练参数（权重和偏置）总数与每个参数大小的乘积。每个参数是一个32位数，相当于4字节。\n该网络有一个输入层、一个隐藏层和一个输出层。\n- 输入维度：$d_{\\mathrm{in}} = 4$。\n- 隐藏层宽度：$h = 64$。\n- 输出维度：$d_{\\mathrm{out}} = 1$。\n\n参数数量计算如下：\n- 输入层和隐藏层之间的参数：\n  - 大小为 $h \\times d_{\\mathrm{in}} = 64 \\times 4$ 的权重矩阵 $W_1$。权重数量 = $256$。\n  - 大小为 $h = 64$ 的偏置向量 $b_1$。偏置数量 = $64$。\n- 隐藏层和输出层之间的参数：\n  - 大小为 $d_{\\mathrm{out}} \\times h = 1 \\times 64$ 的权重矩阵 $W_2$。权重数量 = $64$。\n  - 大小为 $d_{\\mathrm{out}} = 1$ 的偏置向量 $b_2$。偏置数量 = $1$。\n\n参数总数 $N_{\\mathrm{NN}}$ 是所有权重和偏置的总和：\n$$\nN_{\\mathrm{NN}} = (d_{\\mathrm{in}} \\times h + h) + (h \\times d_{\\mathrm{out}} + d_{\\mathrm{out}}) = (4 \\times 64 + 64) + (64 \\times 1 + 1) = (256 + 64) + (64 + 1) = 320 + 65 = 385\n$$\n表示法B的内存需求为：\n$$\n\\text{内存}_{\\mathrm{B}} = N_{\\mathrm{NN}} \\times 32 \\text{ 位} = 385 \\times 4 \\text{ 字节} = 1540 \\text{ 字节}\n$$\n\n比率计算：\n问题要求计算表示法A使用的内存与表示法B使用的内存之比 $R$。\n$$\nR = \\frac{\\text{内存}_{\\mathrm{A}}}{\\text{内存}_{\\mathrm{B}}} = \\frac{1096 \\text{ 字节}}{1540 \\text{ 字节}} = \\frac{1096}{1540}\n$$\n将分子和分母同除以它们的最大公约数4，得到：\n$$\nR = \\frac{274}{385}\n$$\n将此分数转换为小数值：\n$$\nR \\approx 0.71168831...\n$$\n按要求四舍五入到四位有效数字，我们得到：\n$$\nR \\approx 0.7117\n$$", "answer": "$$\\boxed{0.7117}$$", "id": "2399843"}]}