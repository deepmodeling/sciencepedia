{"hands_on_practices": [{"introduction": "一个风险模型可能完美地通过了只关注违规频率的基础回测（如Kupiec检验），但这是否意味着它是一个好模型？本练习将通过构建一个特例来探讨这个问题，即模型预测的违规次数完全符合预期，但每次违规都伴随着灾难性的巨大损失。通过这个实践[@problem_id:2374206]，你将亲手揭示单纯依赖风险价值（$VaR$）的局限性，并理解为何预期损失（$ES$）等考虑损失严重性的风险度量至关重要。", "problem": "您需要通过构建合成的盈亏 (PL) 数据和一个故意设定错误的 VaR 模型来演示使用风险价值 (VaR) 进行回测的局限性。该 VaR 模型需要满足无条件覆盖检验，但同时隐藏了对于预期短缺 (ES) 来说显而易见的极端尾部损失严重性。您必须从第一性原理出发，实现一个能产生确定性输出的完整程序。\n\n使用的基本定义：\n- 损失由序列 $\\{L_t\\}_{t=1}^T$ 表示，其中 $L_t \\ge 0$ 指代时间 $t$ 的损失。\n- 在尾部概率水平 $\\alpha \\in (0,1)$ 下的风险价值 (VaR) 是满足 $\\mathbb{P}(L_t \\le v_\\alpha) \\ge 1 - \\alpha$ 的最小阈值 $v_\\alpha$。当一个模型提供一系列单步向前 VaR 预测值 $\\{v_t\\}_{t=1}^T$ 时，时间 $t$ 的一次违规定义为事件 $L_t  v_t$。\n- 违规指标为 $I_t = \\mathbf{1}\\{L_t  v_t\\}$。在正确的无条件覆盖下，序列 $\\{I_t\\}$ 是一个成功概率为 $\\alpha$ 的独立同分布的伯努利过程。\n- 水平为 $\\alpha$ 的预期短缺 (ES) 是在损失超过 VaR 阈值的条件下，损失的条件期望：$\\mathrm{ES}_\\alpha = \\mathbb{E}[L_t \\mid L_t  v_\\alpha]$。\n- Kupiec 无条件覆盖似然比 (LR) 检验比较了在原假设违规概率为 $\\alpha$ 时的伯努利似然与在最大似然估计 $\\hat{p}$ 下的似然。其原假设为无条件违规率等于 $\\alpha$。LR 统计量渐近服从自由度为 1 的 $\\chi^2$ 分布，您必须据此计算一个 $p$ 值，并判断在 0.05 的显著性水平下，检验是否未能拒绝原假设。\n\n您的任务：\n1. 针对每个提供的测试用例，构建一个合成的损失序列 $\\{L_t\\}_{t=1}^T$ 和一个恒定的 VaR 预测序列 $\\{v_t\\}_{t=1}^T$（其中 $v_t \\equiv v$），使得：\n   - 恰好有 $x = \\alpha T$ 个时间点是违规的，在这些违规时间点上，$L_t = 10 v$。\n   - 所有其他时间点都是非违规的，此时 $L_t = 0.5 v$。\n   - 注意：所有数学实体，包括 $10$、$0.5$ 和 $x$，在您的构建中都必须作为约束条件被遵守。\n2. 根据构建的 $\\{L_t\\}$ 和 $\\{v_t\\}$，为每个用例计算违规指标 $\\{I_t\\}$ 和违规次数 $x = \\sum_{t=1}^T I_t$。\n3. 为每个用例实现 Kupiec 无条件覆盖似然比检验，仅基于伯努利似然原理和自由度为 1 的渐近 $\\chi^2$ 分布。使用此检验计算 $p$ 值以及一个布尔值，该布尔值指示在 0.05 的显著性水平下检验是否未能拒绝原假设。\n4. 为每个用例计算已实现的预期短缺比率，其定义为当 $x \\ge 1$ 时，$M = \\left(\\frac{1}{x} \\sum_{t=1}^T I_t L_t\\right) / v$。在您的构建中，该比率应能揭示相对于模型 VaR 水平的系统性尾部严重性。\n5. 您的实现必须是确定性的，并且不得依赖任何外部随机性。\n\n测试套件：\n您必须在以下参数集 $(T,\\alpha,v)$ 上运行您的程序，其中 $T$ 是长度，$\\alpha$ 是以小数表示的违规概率， $v$ 是恒定的 VaR 水平：\n- 案例 A: $(T,\\alpha,v) = (1000, 0.01, 1.0)$\n- 案例 B: $(T,\\alpha,v) = (250, 0.04, 2.0)$\n- 案例 C: $(T,\\alpha,v) = (200, 0.055, 0.5)$\n- 案例 D (小样本覆盖率检查): $(T,\\alpha,v) = (20, 0.1, 3.0)$\n\n对于每个案例，按此确切顺序输出包含三个项目的列表：\n- 一个布尔值，指示 Kupiec 检验在 0.05 显著性水平下是否未能拒绝原假设。\n- Kupiec 检验的 $p$ 值，以浮点数表示。\n- 已实现的预期短缺比率 $M$，以浮点数表示。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个按案例划分的结果列表，每个案例的结果都是一个按上述顺序排列的三元素列表。例如，最终的单行输出应如下所示：\n- $[\\,[\\text{True}, 1.0, 10.0], [\\text{True}, 0.9999, 10.0]\\,]$\n- 您的代码必须精确地打印包含此列表的一行，不得包含其他文本。\n\n重要实现说明：\n- 将违规事件视为 $L_t  v_t$，其中损失和 VaR 均为非负值。\n- 确保在所提供的每个测试用例中 $x = \\alpha T$ 都是一个整数。不要随机安排违规事件的位置；一个简单的确定性安排即可。\n- 对于 Kupiec 检验的决策，请使用 0.05 的显著性水平。\n- 角度和物理单位不适用。百分比必须以小数表示，给定的 $\\alpha$ 值已满足此要求。", "solution": "所述问题是有效的。它在科学上基于金融风险管理的原则，特别是风险模型的回测。所有定义和约束都是适定、完整且一致的，从而可以得出一个唯一且有意义的解。任务是构建一个特定场景，以说明与预期短缺 ($ES$) 相比，风险价值 ($VaR$) 的一个已知局限性。\n\n目标是创建一个由损失序列 $\\{L_t\\}_{t=1}^T$ 表示的合成盈亏 (PL) 历史，以及一个对应的单步向前 $VaR$ 预测序列 $\\{v_t\\}_{t=1}^T$。这种构建必须是故意设定错误的，使得该 $VaR$ 模型能够通过一项标准回测——Kupiec 无条件覆盖检验——但同时隐藏了对尾部损失幅度的严重低估，而这是一个基于 ES 的指标能够揭示的缺陷。\n\n首先，我们处理每个给定测试用例的合成数据构建，每个用例是一个参数三元组 $(T, \\alpha, v)$。$T$ 是总时间期数，$\\alpha$ 是目标违规概率， $v$ 是恒定的 $VaR$ 预测水平。\n\n问题规定了一个恒定的 $VaR$ 预测：\n$$ v_t = v \\quad \\forall t \\in \\{1, \\dots, T\\} $$\n\n时间 $t$ 的一次违规或超出，定义为事件 $L_t  v_t$。构建要求总违规次数 $x$ 必须恰好为 $x = \\alpha T$。对于提供的测试用例，该乘积是一个整数。为确保确定性，我们可以将这 $x$ 次违规放在时间序列的开头，即从 $t=1$ 到 $t=x$。\n\n损失值的规定如下：\n- 对于违规期 ($t \\in \\{1, \\dots, x\\}$)：$L_t = 10v$。由于 $v$ 必须为正，这满足了违规条件 $L_t  v$。\n- 对于非违规期 ($t \\in \\{x+1, \\dots, T\\}$)：$L_t = 0.5v$。这不构成违规，因为 $0.5v \\ngtr v$。\n\n因此，违规指标序列 $\\{I_t\\}_{t=1}^T$ 为：当 $t \\in \\{1, \\dots, x\\}$ 时 $I_t = 1$，当 $t \\in \\{x+1, \\dots, T\\}$ 时 $I_t = 0$。\n\n接下来，我们执行 Kupiec 无条件覆盖似然比 ($LR$) 检验。原假设 $H_0$ 是真实违规概率为 $p = \\alpha$。该检验统计量基于在 $H_0$ 下观测数据的似然与在最大似然估计 $\\hat{p} = x/T$ 下的似然之间的比较。LR 统计量由下式给出：\n$$ LR_{uc} = 2 \\ln \\left( \\frac{L(\\hat{p})}{L(\\alpha)} \\right) = 2 \\ln \\left( \\frac{\\hat{p}^x (1 - \\hat{p})^{T-x}}{\\alpha^x (1-\\alpha)^{T-x}} \\right) $$\n该表达式可以重写为：\n$$ LR_{uc} = 2 \\left[ x \\ln\\left(\\frac{\\hat{p}}{\\alpha}\\right) + (T-x) \\ln\\left(\\frac{1-\\hat{p}}{1-\\alpha}\\right) \\right] $$\n根据我们的特定构建方式，违规次数为 $x = \\alpha T$。因此，经验违规率为 $\\hat{p} = x/T = (\\alpha T)/T = \\alpha$。将 $\\hat{p} = \\alpha$ 代入 $LR_{uc}$ 公式，得到：\n$$ LR_{uc} = 2 \\left[ (\\alpha T) \\ln\\left(\\frac{\\alpha}{\\alpha}\\right) + (T-\\alpha T) \\ln\\left(\\frac{1-\\alpha}{1-\\alpha}\\right) \\right] = 2 \\left[ (\\alpha T) \\ln(1) + T(1-\\alpha) \\ln(1) \\right] = 0 $$\n因此，$LR_{uc}$ 统计量恒等于零。该统计量渐近服从自由度为 1 的卡方分布，即 $\\chi^2(1)$。检验的 $p$ 值是观测到至少与计算值一样极端的检验统计量的概率，即 $P(\\chi^2(1) \\ge LR_{uc})$。当 $LR_{uc}=0$ 时，$p$ 值为：\n$$ p\\text{-value} = \\int_0^\\infty f(z; 1) dz = 1 $$\n其中 $f(z; 1)$ 是 $\\chi^2(1)$ 分布的概率密度函数。如果 $p$ 值低于给定的显著性水平 0.05，则拒绝原假设。由于 $1.0  0.05$，对于所有测试用例，我们都必然未能拒绝原假设。该 VaR 模型完美地通过了覆盖检验。\n\n最后，我们使用已实现的预期短缺比率 $M$ 来分析模型在尾部损失幅度方面的表现。该比率定义为经验性违规日平均损失与 VaR 水平的比率：\n$$ M = \\frac{\\frac{1}{x} \\sum_{t=1}^T I_t L_t}{v} $$\n总和 $\\sum_{t=1}^T I_t L_t$ 代表了所有 $x$ 个违规日的总损失。根据我们的构建，这些天中每一天的损失都是 $L_t = 10v$。因此，总和为 $x \\cdot 10v$。违规日的平均损失为：\n$$ \\frac{1}{x} \\sum_{t=1}^T I_t L_t = \\frac{x \\cdot 10v}{x} = 10v $$\n这就是经验性或已实现的预期短缺。比率 $M$ 则为：\n$$ M = \\frac{10v}{v} = 10 $$\n这个结果在所有测试用例中都是恒定的，它揭示了模型的致命缺陷。当违规发生时，所产生的损失平均是 VaR 阈值的 10 倍。一个简单的覆盖检验无法察觉到这种对损失分布尾部风险的系统性严重低估。这证明了像 ES 这样的一致性风险度量的优越性，因为它不仅考虑尾部损失的频率，还考虑其严重程度。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef solve():\n    \"\"\"\n    Solves the problem of demonstrating VaR backtesting limitations.\n    For each test case, it computes the Kupiec test result and the realized ES ratio.\n    \"\"\"\n    test_cases = [\n        # (T, alpha, v)\n        (1000, 0.01, 1.0),\n        (250, 0.04, 2.0),\n        (200, 0.055, 0.5),\n        (20, 0.1, 3.0),\n    ]\n\n    results = []\n    significance_level = 0.05\n\n    for T, alpha, v in test_cases:\n        # Per problem statement, x = alpha * T is an integer for all test cases.\n        # This setup is deterministic.\n        x = int(T * alpha)\n        \n        # 1. Kupiec Unconditional Coverage Test\n        # The null hypothesis is that the violation probability is alpha.\n        # The test statistic LR_uc = 2 * ln(L(p_hat) / L(alpha)).\n        # By construction, the observed violation rate p_hat = x / T = alpha.\n        # This forces the LR statistic to be 0 and the p-value to be 1.\n        # We implement the full formula for formal verification.\n\n        lr_stat = 0.0\n        if x == 0:\n            # log(p_hat) term is undefined, but limit of p_hat*log(p_hat) is 0.\n            # LR = 2* T * log(1/(1-alpha))\n            lr_stat = 2 * (T * np.log(1 / (1 - alpha)))\n        elif x == T:\n            # log(1-p_hat) term is undefined.\n            # LR = 2 * T * log(1/alpha)\n            lr_stat = 2 * (T * np.log(1 / alpha))\n        else:\n            p_hat = x / T\n            # Due to problem design, p_hat is exactly alpha.\n            # np.log(p_hat / alpha) will be np.log(1.0) = 0.\n            # The formula is robust to minor floating point inaccuracies if any existed.\n            term1 = x * np.log(p_hat / alpha)\n            term2 = (T - x) * np.log((1 - p_hat) / (1 - alpha))\n            lr_stat = 2 * (term1 + term2)\n\n        # p-value from chi-squared distribution with 1 degree of freedom\n        p_value = float(chi2.sf(lr_stat, df=1))\n\n        # Decision: Fail to reject H0 if p-value is not less than significance level\n        k_test_fails_to_reject = p_value = significance_level\n\n        # 2. Realized Expected Shortfall Ratio (M)\n        # M = (average loss on violation days) / VaR\n        # Loss on violation days is L_t = 10 * v\n        # Average loss is therefore (x * 10 * v) / x = 10 * v\n        # M = (10 * v) / v = 10\n        es_ratio = 0.0\n        if x  0:\n            # The calculation is analytically 10, as shown in the solution notes.\n            # Average loss conditional on violation = 10 * v\n            # Ratio M = (10 * v) / v\n            es_ratio = 10.0\n        # The problem statement defines M for x = 1, so no else case is needed\n        # for the given test suite.\n\n        results.append([k_test_fails_to_reject, p_value, es_ratio])\n\n    # Final print statement must match the specified format exactly.\n    # The format from the template is f\"[{','.join(map(str, results))}]\"\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2374206"}, {"introduction": "即使一个模型的 $VaR$ 违规频率正确，我们还需要确保这些违规事件是独立发生的，而不是集中出现在某些特定时期（例如，市场剧烈波动时）。本练习旨在揭示违规事件的聚类现象，这通常是模型未能捕捉到波动率动态的信号。你将构建一个违规总数正确但所有违规都发生在每周固定一天的情景，并使用 Christoffersen 的独立性检验来量化这一缺陷[@problem_id:2374172]。", "problem": "您的任务是构建并评估一个风险价值（VaR）突破过程，该过程在指定的概率水平上具有正确的无条件覆盖，但表现出系统性的时间选择。考虑一个由重复的五天工作周组成的交易日历，其中日期用整数标记：星期一为第 $0$ 天，星期二为第 $1$ 天，星期三为第 $2$ 天，星期四为第 $3$ 天，星期五为第 $4$ 天。设 $T$ 表示总交易日数，由 $t \\in \\{0,1,\\ldots,T-1\\}$ 索引；设 $\\alpha \\in (0,1)$ 表示名义VaR突破概率水平。定义VaR突破指标序列 $\\{I_t\\}_{t=0}^{T-1}$ 为 $I_t \\in \\{0,1\\}$，其中 $I_t=1$ 表示第 $t$ 天是VaR突破日，否则 $I_t=0$。待评估的模型必须同时满足以下两个属性：\n- 在 $T$ 天内的总突破次数恰好等于 $\\alpha T$。\n- 所有突破仅发生在星期一。\n\n假设第一个观测值的起始星期已知，表示为 $s \\in \\{0,1,2,3,4\\}$，其中 $s=0$ 对应星期一。时间 $t$ 对应的星期是 $(s+t) \\bmod 5$。模型应将恰好 $\\alpha T$ 次突破放置在样本中最早的几个星期一，对这些星期一的索引设置 $I_t=1$，否则设置 $I_t=0$。您可以假设 $\\alpha T$ 是一个整数，并且样本中星期一的数量至少为 $\\alpha T$。\n\n将序列 $\\{I_t\\}$ 置于 Christoffersen 的回测框架下进行检验，该框架包括：\n- 无条件覆盖假设，即突破概率等于 $\\alpha$。\n- 独立性假设，即突破在时间上是独立的。\n- 条件覆盖假设，即无条件覆盖和独立性共同成立。\n\n使用 Christoffersen 框架中定义的似然比统计量，并为每个检验报告：\n- 无条件覆盖的似然比统计量，记为 $LR_{\\mathrm{uc}}$。\n- 独立性的似然比统计量，记为 $LR_{\\mathrm{ind}}$。\n- 条件覆盖统计量 $LR_{\\mathrm{cc}} = LR_{\\mathrm{uc}} + LR_{\\mathrm{ind}}$。\n- 相应的 $p$ 值，这些值是在卡方分布下计算的，其中 $LR_{\\mathrm{uc}}$ 的自由度为 $1$，$LR_{\\mathrm{ind}}$ 的自由度为 $1$，$LR_{\\mathrm{cc}}$ 的自由度为 $2$。\n- 对每个原假设，在显著性水平为 $\\delta=0.05$ 时的二元拒绝决策，结果以布尔值表示。\n\n您的程序必须为以下参数三元组 $(T,\\alpha,s)$ 的测试套件实现此构建和分析：\n- 测试 $1$：$(T,\\alpha,s) = (500, 0.05, 0)$。\n- 测试 $2$：$(T,\\alpha,s) = (495, 0.20, 3)$。\n- 测试 $3$：$(T,\\alpha,s) = (100, 0.10, 1)$。\n- 测试 $4$：$(T,\\alpha,s) = (500, 0.01, 4)$。\n- 测试 $5$：$(T,\\alpha,s) = (250, 0.04, 2)$。\n\n对于每个测试，按以下顺序输出一个包含九个值的列表：\n$[LR_{\\mathrm{uc}}, p_{\\mathrm{uc}}, LR_{\\mathrm{ind}}, p_{\\mathrm{ind}}, LR_{\\mathrm{cc}}, p_{\\mathrm{cc}}, \\text{reject}_{\\mathrm{uc}}, \\text{reject}_{\\mathrm{ind}}, \\text{reject}_{\\mathrm{cc}}]$，其中 $p_{\\mathrm{uc}}$、$p_{\\mathrm{ind}}$ 和 $p_{\\mathrm{cc}}$ 是 $p$ 值，而 $\\text{reject}_{\\mathrm{uc}}$、$\\text{reject}_{\\mathrm{ind}}$、$\\text{reject}_{\\mathrm{cc}}$ 是布尔值，表示在 $\\delta=0.05$ 水平下是否拒绝原假设。\n\n最终输出格式：您的程序应生成单行输出，其中包含所有五个测试的结果，格式为一个逗号分隔的九元素列表的列表，并用方括号括起来，例如 $[\\ldots]$。所有概率都必须以小数表示，不得使用百分号。", "solution": "我们从第一性原理出发，对VaR突破指标序列和 Christoffersen 检验进行形式化。设 $T \\in \\mathbb{N}$ 为交易日数，$\\alpha \\in (0,1)$ 为名义突破概率。为 $t \\in \\{0,1,\\ldots,T-1\\}$ 定义指标 $I_t \\in \\{0,1\\}$，其构建规则如下：\n- 计算与星期一对应的索引集合 $\\mathcal{M} = \\{t \\in \\{0,\\ldots,T-1\\} : (s+t) \\bmod 5 = 0\\}$，其中 $s \\in \\{0,1,2,3,4\\}$ 是第一个观测值所在的星期，$0$ 代表星期一。\n- 设 $K = \\alpha T$。根据假设，$K$ 是一个整数且 $|\\mathcal{M}| \\ge K$。\n- 对 $\\mathcal{M}$ 中按 $t$ 升序排列的前 $K$ 个元素设置 $I_t = 1$，对所有其他索引设置 $I_t = 0$。这确保了所有突破都发生在星期一，且总突破次数等于 $\\alpha T$。\n\nChristoffersen 的无条件覆盖检验考虑假设 $H_0^{\\mathrm{uc}}: \\mathbb{P}(I_t=1) = \\alpha$，该假设表明突破概率等于 $\\alpha$。设 $N_1 = \\sum_{t=0}^{T-1} I_t$ 且 $N_0 = T - N_1$。在 $H_0^{\\mathrm{uc}}$ 假设下，对于成功概率为 $\\alpha$ 的独立伯努利试验，其似然函数为\n$$\nL_0^{\\mathrm{uc}} = (1-\\alpha)^{N_0} \\alpha^{N_1}.\n$$\n无约束似然（在 $\\pi \\in [0,1]$ 上最大化）在 $\\hat{\\pi} = N_1/T$ 处取得，得到\n$$\nL_1^{\\mathrm{uc}} = (1-\\hat{\\pi})^{N_0} \\hat{\\pi}^{N_1}.\n$$\n似然比统计量为\n$$\nLR_{\\mathrm{uc}} = -2 \\left[ \\ln L_0^{\\mathrm{uc}} - \\ln L_1^{\\mathrm{uc}} \\right]\n= 2 \\left[ N_1 \\ln\\left(\\frac{N_1}{\\alpha T}\\right) + N_0 \\ln\\left(\\frac{N_0}{(1-\\alpha)T}\\right) \\right],\n$$\n约定形式为 $0 \\cdot \\ln(0)$ 的项被视为 $0$。在 $H_0^{\\mathrm{uc}}$ 下，$LR_{\\mathrm{uc}}$ 渐近服从自由度为 $1$ 的卡方分布。\n\n独立性检验考虑序列 $\\{I_t\\}$ 中的一阶马尔可夫依赖性。定义在 $t=1,\\ldots,T-1$ 上的转移计数：\n- $N_{ij} = \\#\\{t \\in \\{1,\\ldots,T-1\\} : I_{t-1}=i, I_t=j\\}$，其中 $i,j \\in \\{0,1\\}$。\n设 $N_{0\\cdot} = N_{00} + N_{01}$ 且 $N_{1\\cdot} = N_{10} + N_{11}$。在无约束一阶马尔可夫备择假设下，最大似然估计量为\n$$\n\\hat{p}_{01} = \\frac{N_{01}}{N_{0\\cdot}} \\ \\text{ if } N_{0\\cdot}  0, \\quad\n\\hat{p}_{11} = \\frac{N_{11}}{N_{1\\cdot}} \\ \\text{ if } N_{1\\cdot}  0,\n$$\n当分母为零时，进行自然的边界处理。无约束对数似然为\n$$\n\\ln L_1^{\\mathrm{ind}} = N_{00}\\ln(1-\\hat{p}_{01}) + N_{01}\\ln(\\hat{p}_{01}) + N_{10}\\ln(1-\\hat{p}_{11}) + N_{11}\\ln(\\hat{p}_{11}),\n$$\n其中任何系数为零的项都视为零。在具有共同成功概率 $\\pi$ 的独立性原假设下，基于转移的最大似然估计量为\n$$\n\\hat{\\pi} = \\frac{N_{01} + N_{11}}{N_{00} + N_{01} + N_{10} + N_{11}} = \\frac{N_{01} + N_{11}}{T-1},\n$$\n且有约束对数似然为\n$$\n\\ln L_0^{\\mathrm{ind}} = (N_{00}+N_{10})\\ln(1-\\hat{\\pi}) + (N_{01}+N_{11})\\ln(\\hat{\\pi}).\n$$\n独立性似然比统计量为\n$$\nLR_{\\mathrm{ind}} = -2\\left[\\ln L_0^{\\mathrm{ind}} - \\ln L_1^{\\mathrm{ind}}\\right],\n$$\n在独立性原假设下，该统计量渐近服从自由度为 $1$ 的卡方分布。\n\n条件覆盖统计量是这两个部分的组合：\n$$\nLR_{\\mathrm{cc}} = LR_{\\mathrm{uc}} + LR_{\\mathrm{ind}},\n$$\n在联合原假设下，该统计量渐近服从自由度为 $2$ 的卡方分布。\n\n对于每个测试用例 $(T,\\alpha,s)$，我们按照规定构建 $\\{I_t\\}$，计算 $N_1$、$N_0$ 和转移计数 $N_{ij}$，然后使用具有相应自由度的卡方分布的生存函数来评估 $LR_{\\mathrm{uc}}$、$LR_{\\mathrm{ind}}$ 和 $LR_{\\mathrm{cc}}$ 以及它们的 $p$ 值。通过将每个 $p$ 值与 $\\delta = 0.05$ 进行比较来做出拒绝决策。由于该构造强制要求 $N_1 = \\alpha T$ 精确成立，我们有 $\\hat{\\pi} = \\alpha$，因此对于所有测试用例，$LR_{\\mathrm{uc}}$ 恒等于 $0$，这意味着在任何常规水平上都不会拒绝无条件覆盖假设。然而，将所有突破集中在星期一会引入相对于日历时间的序列依赖性，这可以通过独立性检验中不同的转移概率来检测，特别是 $\\hat{p}_{11} = 0$（没有连续突破）和 $\\hat{p}_{01}  0$，这会增加 $LR_{\\mathrm{ind}}$ 的值，并通常导致拒绝独立性和条件覆盖假设，尤其是当 $T$ 和 $\\alpha T$ 增加时。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef build_monday_exception_series(T: int, alpha: float, start_day: int) - np.ndarray:\n    \"\"\"\n    Construct an exception indicator series I_t of length T such that:\n    - Exactly K = alpha*T exceptions occur (assumed integer),\n    - All exceptions occur on Mondays (weekday index 0),\n    - The first observation has weekday 'start_day' in {0,..,4}.\n    \"\"\"\n    K = int(round(alpha * T))\n    I = np.zeros(T, dtype=int)\n    monday_indices = [t for t in range(T) if ((start_day + t) % 5) == 0]\n    if K  len(monday_indices):\n        raise ValueError(\"Not enough Mondays to place all exceptions.\")\n    # Place exceptions on the earliest Mondays\n    for t in monday_indices[:K]:\n        I[t] = 1\n    return I\n\ndef safe_log(x: float) - float:\n    \"\"\"Natural log with handling for x in {0,1} when multiplied by zero counts later.\"\"\"\n    # We will never call log(0) multiplied by positive coefficient if model is set correctly\n    # But to be safe, cap x in (0,1) open interval with tiny epsilon\n    eps = 1e-16\n    if x = 0.0:\n        x = eps\n    elif x = 1.0:\n        x = 1.0 - eps\n    return np.log(x)\n\ndef lr_uc(I: np.ndarray, alpha: float) - float:\n    \"\"\"\n    Christoffersen's unconditional coverage LR statistic.\n    LR_uc = 2 * [ N1*ln(N1/(alpha*T)) + N0*ln(N0/((1-alpha)*T)) ] with 0*ln(0)=0.\n    \"\"\"\n    T = I.size\n    N1 = int(I.sum())\n    N0 = T - N1\n    # Handle 0*ln(0) - 0 via conditional terms\n    term1 = 0.0 if N1 == 0 else N1 * np.log(N1 / (alpha * T))\n    term0 = 0.0 if N0 == 0 else N0 * np.log(N0 / ((1.0 - alpha) * T))\n    LR = 2.0 * (term1 + term0)\n    # Numerical cleanup: LR cannot be negative\n    return float(max(LR, 0.0))\n\ndef lr_ind(I: np.ndarray) - float:\n    \"\"\"\n    Christoffersen's independence LR statistic based on 2x2 transition counts.\n    \"\"\"\n    # Compute transitions\n    I_prev = I[:-1]\n    I_curr = I[1:]\n    N00 = int(np.sum((I_prev == 0)  (I_curr == 0)))\n    N01 = int(np.sum((I_prev == 0)  (I_curr == 1)))\n    N10 = int(np.sum((I_prev == 1)  (I_curr == 0)))\n    N11 = int(np.sum((I_prev == 1)  (I_curr == 1)))\n\n    N0dot = N00 + N01\n    N1dot = N10 + N11\n    Ntrans = N0dot + N1dot  # equals len(I)-1\n\n    # Unrestricted MLEs with boundary handling\n    p01_hat = 0.0 if N0dot == 0 else N01 / N0dot\n    p11_hat = 0.0 if N1dot == 0 else N11 / N1dot\n\n    # Log-likelihood under alternative (Markov)\n    ll1 = 0.0\n    if N00  0:\n        ll1 += N00 * safe_log(1.0 - p01_hat)\n    if N01  0:\n        ll1 += N01 * safe_log(p01_hat)\n    if N10  0:\n        ll1 += N10 * safe_log(1.0 - p11_hat)\n    if N11  0:\n        ll1 += N11 * safe_log(p11_hat)\n\n    # Restricted MLE under independence\n    pi_hat = 0.0 if Ntrans == 0 else (N01 + N11) / Ntrans\n    ll0 = 0.0\n    if (N00 + N10)  0:\n        ll0 += (N00 + N10) * safe_log(1.0 - pi_hat)\n    if (N01 + N11)  0:\n        ll0 += (N01 + N11) * safe_log(pi_hat)\n\n    LR = -2.0 * (ll0 - ll1)\n    return float(max(LR, 0.0))\n\ndef analyze_case(T: int, alpha: float, start_day: int, sig: float = 0.05):\n    I = build_monday_exception_series(T, alpha, start_day)\n    LR_uc = lr_uc(I, alpha)\n    LR_ind = lr_ind(I)\n    LR_cc = LR_uc + LR_ind\n\n    # p-values from chi-square distributions\n    p_uc = chi2.sf(LR_uc, df=1)\n    p_ind = chi2.sf(LR_ind, df=1)\n    p_cc = chi2.sf(LR_cc, df=2)\n\n    reject_uc = p_uc  sig\n    reject_ind = p_ind  sig\n    reject_cc = p_cc  sig\n\n    return LR_uc, p_uc, LR_ind, p_ind, LR_cc, p_cc, reject_uc, reject_ind, reject_cc\n\ndef format_result(result_tuple):\n    # Format floats to 6 decimals, booleans as True/False\n    formatted = []\n    for i, v in enumerate(result_tuple):\n        if isinstance(v, float):\n            formatted.append(f\"{v:.6f}\")\n        elif isinstance(v, (np.floating,)):\n            formatted.append(f\"{float(v):.6f}\")\n        elif isinstance(v, (bool, np.bool_)):\n            formatted.append(\"True\" if bool(v) else \"False\")\n        else:\n            formatted.append(str(v))\n    return \"[\" + \",\".join(formatted) + \"]\"\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case is (T, alpha, start_day)\n    test_cases = [\n        (500, 0.05, 0),  # Test 1\n        (495, 0.20, 3),  # Test 2\n        (100, 0.10, 1),  # Test 3\n        (500, 0.01, 4),  # Test 4\n        (250, 0.04, 2),  # Test 5\n    ]\n\n    results = []\n    for case in test_cases:\n        T, alpha, start_day = case\n        result = analyze_case(T, alpha, start_day, sig=0.05)\n        results.append(format_result(result))\n\n    # Final print statement in the exact required format: a single line with a list of lists\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2374172"}, {"introduction": "回测的可靠性不仅取决于统计检验本身，更根本地取决于模型构建过程的严谨性。这个练习将带你探索一个常见的建模陷阱：“前视偏差”（look-ahead bias），即在预测时不慎使用了未来的信息。通过对比一个合规的模型和一个含有“幽灵特征”的瑕疵模型[@problem_id:2374186]，你将量化这种偏差如何人为地美化回测结果，从而学会批判性地审视模型评估的有效性。", "problem": "您将实现并比较两种用于风险价值（VaR）和预期短缺（ES）的滚动高斯风险模型，并量化包含“幽灵特征”（来自未来的信息）对标准回测结果的影响。所有计算都将在从指定的条件异方差过程生成的合成收益序列上执行。您的程序必须是自包含的，产生确定性的结果，并如下文所述输出一个单一的浮点数列表。\n\n定义和假设：\n- 令 $\\alpha \\in (0,1)$ 表示VaR和预期短缺的尾部概率水平。\n- 时间 $t$ 的单步预测收益为 $r_t$。负值代表损失。\n- 在零条件均值和条件标准差为 $\\sigma_t$ 的高斯模型下，$\\alpha$-分位数（左尾）为 $q_\\alpha = \\Phi^{-1}(\\alpha)$，其中 $\\Phi^{-1}(\\cdot)$ 是标准正态分布的逆累积分布函数。条件VaR预测为 $\\widehat{\\text{VaR}}_t = q_\\alpha \\sigma_t$。\n- 预期短缺是尾部的条件期望。对于一个标准正态随机变量 $Z$，其截断均值满足 $\\mathbb{E}[Z \\mid Z \\le q_\\alpha] = -\\varphi(q_\\alpha)/\\alpha$，其中 $\\varphi(\\cdot)$ 是标准正态概率密度函数。因此，ES预测为 $\\widehat{\\text{ES}}_t = \\sigma_t \\, \\mathbb{E}[Z \\mid Z \\le q_\\alpha] = -\\sigma_t \\, \\varphi(q_\\alpha)/\\alpha$。\n- VaR回测使用突破指标 $I_t = \\mathbf{1}\\{r_t  \\widehat{\\text{VaR}}_t\\}$。在正确校准下，无条件覆盖率意味着 $I_t$ 是独立同分布的伯努利变量，成功概率为 $\\alpha$。在一个长度为 $n$ 的回测样本中，令 $x = \\sum_{t=1}^n I_t$ 表示突破次数。无条件覆盖率假设的似然比统计量等于\n$$\n\\text{LR}_{\\text{uc}} = 2\\left[ x \\ln\\left(\\frac{x/n}{\\alpha}\\right) + (n-x)\\ln\\left(\\frac{1 - x/n}{1-\\alpha}\\right)\\right],\n$$\n约定当 $x=0$ 时 $x \\ln(x/n)$ 为 $0$，当 $x=n$ 时 $(n-x)\\ln(1 - x/n)$ 为 $0$。在原假设下，$\\text{LR}_{\\text{uc}}$ 渐近服从自由度为 $1$ 的 $\\chi^2$ 分布。经验命中率为 $\\widehat{p} = x/n$。\n- 一个在水平 $\\alpha$ 上的严格一致性分位数评分函数是“核查损失” $\\ell_t^{Q} = \\left(\\alpha - I_t\\right)\\left(r_t - \\widehat{\\text{VaR}}_t\\right)$，其样本均值 $\\overline{\\ell}^{Q}$ 对于校准良好的分位数预测应该很小。\n- 一个简单的ES回测诊断方法是将已实现的尾部条件均值与突破日的平均ES预测进行比较。将已实现短缺定义为 $\\overline{r}_{\\text{tail}} = \\frac{1}{x}\\sum_{t: I_t=1} r_t$（仅当 $x \\ge 1$ 时有定义），并将突破日对应的平均ES预测定义为 $\\overline{\\widehat{\\text{ES}}}_{\\text{tail}} = \\frac{1}{x}\\sum_{t: I_t=1} \\widehat{\\text{ES}}_t$。绝对ES偏差为 $|\\overline{\\widehat{\\text{ES}}}_{\\text{tail}} - \\overline{r}_{\\text{tail}}|$。\n\n待比较模型：\n- 基准模型（正确时序）：在时间 $t$，使用长度为 $W$ 的滚动窗口，根据最近的 $W$ 个过去收益 $\\{r_{t-W},\\dots,r_{t-1}\\}$ 的样本标准差来估计 $\\sigma_t$。\n- 幽灵特征模型（前视偏差）：在时间 $t$，错误地使用一个包含当前收益的滚动窗口，即 $\\{r_{t-W+1},\\dots,r_t\\}$，来估计 $\\sigma_t$。这使用了相对于决策点的未来信息，在真实预测中是被禁止的，但此处有意将其包含进来以量化其影响。\n\n数据生成过程：\n- 收益由一个零条件均值的高斯广义自回归条件异方差（GARCH($1,1$)）过程生成：\n$$\n\\sigma_t^2 = \\omega + \\alpha_G r_{t-1}^2 + \\beta_G \\sigma_{t-1}^2,\\quad r_t = \\sigma_t \\, z_t,\\quad z_t \\sim \\mathcal{N}(0,1),\n$$\n给定参数 $\\omega  0$，$\\alpha_G \\ge 0$, 和 $\\beta_G \\ge 0$ 满足 $\\alpha_G + \\beta_G  1$ 以确保协方差平稳性。当 $\\alpha_G + \\beta_G  1$ 时，将 $\\sigma_0^2$ 初始化为无条件方差 $\\omega/(1 - \\alpha_G - \\beta_G)$，否则为了数值稳定性将其初始化为 $\\omega$。\n\n为每个模型计算的回测指标：\n- 命中率绝对误差：$|\\widehat{p} - \\alpha|$。\n- 无条件覆盖率似然比统计量：$\\text{LR}_{\\text{uc}}$。\n- 平均分位数核查损失：$\\overline{\\ell}^{Q}$。\n- 绝对ES偏差：$|\\overline{\\widehat{\\text{ES}}}_{\\text{tail}} - \\overline{r}_{\\text{tail}}|$。\n\n要求的比较输出：\n对于下述每个测试用例，按此顺序计算以下四个差异（基准模型减去幽灵模型）：\n$D_1 =$ 命中率绝对误差减少量 $= |\\widehat{p}_{\\text{base}} - \\alpha| - |\\widehat{p}_{\\text{ghost}} - \\alpha|$,\n$D_2 =$ 无条件覆盖率似然比减少量 $= \\text{LR}_{\\text{uc, base}} - \\text{LR}_{\\text{uc, ghost}}$,\n$D_3 =$ 分位数核查损失减少量 $= \\overline{\\ell}^{Q}_{\\text{base}} - \\overline{\\ell}^{Q}_{\\text{ghost}}$,\n$D_4 =$ ES绝对偏差减少量 $= |\\overline{\\widehat{\\text{ES}}}_{\\text{tail, base}} - \\overline{r}_{\\text{tail, base}}| - |\\overline{\\widehat{\\text{ES}}}_{\\text{tail, ghost}} - \\overline{r}_{\\text{tail, ghost}}|$。\n\n任何一个 $D_j$ 的正值都表明，根据该指标，幽灵特征模型表现得“更好”，这是一种虚假的表现，因为它非法地使用了未来信息。\n\n测试套件：\n实现下述四个测试用例。对每个用例，使用提供的伪随机数生成器种子来模拟收益以确保确定性，然后使用指定的滚动窗口长度 $W$ 和水平 $\\alpha$ 计算指标。所有 $\\alpha$ 值必须按小数处理，而不是百分比。\n\n- 用例 A（异方差，强持续性）：$T = 4000$，$\\omega = 10^{-6}$，$\\alpha_G = 0.05$，$\\beta_G = 0.94$，$W = 250$，$\\alpha = 0.01$，种子 $= 1729$。\n- 用例 B（异方差，中等持续性，较短样本）：$T = 2000$，$\\omega = 10^{-6}$，$\\alpha_G = 0.15$，$\\beta_G = 0.80$，$W = 100$，$\\alpha = 0.05$，种子 $= 2718$。\n- 用例 C（独立同分布高斯，边缘情况）：$T = 4000$，$\\omega = 10^{-4}$，$\\alpha_G = 0.00$，$\\beta_G = 0.00$，$W = 250$，$\\alpha = 0.01$，种子 $= 3141$。\n- 用例 D（边界：小窗口）：$T = 1500$，$\\omega = 10^{-6}$，$\\alpha_G = 0.10$，$\\beta_G = 0.85$，$W = 30$，$\\alpha = 0.02$，种子 $= 1618$。\n\n最终输出格式：\n- 您的程序应生成单行输出，包含一个由方括号括起来的、包含16个浮点数的逗号分隔列表，顺序为 $[D_{1,A},D_{2,A},D_{3,A},D_{4,A},D_{1,B},D_{2,B},D_{3,B},D_{4,B},D_{1,C},D_{2,C},D_{3,C},D_{4,C},D_{1,D},D_{2,D},D_{3,D},D_{4,D}]$，其中下标表示测试用例。每个浮点数必须四舍五入到6位小数。不得打印任何其他文本。\n\n数值说明：\n- 滚动标准差应使用分母为 $(W-1)$ 的无偏样本方差。\n- 计算截断正态量时，使用 $q_\\alpha = \\Phi^{-1}(\\alpha)$ 和 $\\mathbb{E}[Z \\mid Z \\le q_\\alpha] = -\\varphi(q_\\alpha)/\\alpha$。\n- 无条件覆盖率似然比 $\\text{LR}_{\\text{uc}}$ 在 $x=0$ 或 $x=n$ 的情况下使用上述约定，以避免未定义的对数。", "solution": "问题陈述已经过严格验证，被认为是有效的。它在科学上基于金融计量经济学的原理，问题设定良好且客观。它为比较两种风险模型的计算实验提供了一套完整且一致的要求。目标是量化前视偏差（“幽灵特征”）对风险价值（VaR）和预期短缺（ES）的标准回测指标的影响。\n\n解决方案将分四个连续阶段进行开发：\n1.  从指定的GARCH($1$,$1$)过程中模拟金融收益数据。\n2.  实现两种滚动窗口波动率模型：一个正确设定的基准模型和一个有缺陷的幽灵特征模型。\n3.  计算VaR和ES预测，然后为每个模型计算四种不同的回测性能指标。\n4.  计算两种模型在这些指标上的差异，以量化由前视偏差带来的虚假性能提升。\n\n**第一阶段：数据生成过程**\n\n合成收益序列 $\\{r_t\\}$ 是由一个高斯GARCH($1$,$1$)过程生成的。条件方差 $\\sigma_t^2$ 和收益 $r_t$ 由以下公式给出：\n$$\n\\sigma_t^2 = \\omega + \\alpha_G r_{t-1}^2 + \\beta_G \\sigma_{t-1}^2\n$$\n$$\nr_t = \\sigma_t z_t, \\quad \\text{其中} \\quad z_t \\sim \\mathcal{N}(0,1) \\quad \\text{独立同分布}\n$$\n该过程在时间 $t=0$ 初始化。对于一个平稳过程，其中 $\\alpha_G + \\beta_G  1$，初始方差 $\\sigma_0^2$ 被设置为无条件方差 $\\sigma^2 = \\omega / (1 - \\alpha_G - \\beta_G)$。如果 $\\alpha_G + \\beta_G \\ge 1$，则将 $\\sigma_0^2$ 设置为 $\\omega$。\n对于每个测试用例，使用特定的伪随机数生成器种子生成一个包含T个收益的序列 $\\{r_0, r_1, \\dots, r_{T-1}\\}$，以确保结果的确定性和可复现性。\n\n**第二阶段：风险模型设定与预测**\n\n使用两种模型来预测单步预测条件标准差 $\\sigma_t$。预测在从 $t=W$ 到 $t=T-1$ 的回测期内进行，共计 $n = T-W$ 个观测值。两种模型都使用滚动窗口中收益的无偏样本标准差（分母为 $W-1$）来估计 $\\sigma_t$。\n\n- **基准模型（正确时序）：** 时间 $t$ 的预测值，记为 $\\sigma_{t, \\text{base}}$，是使用在时间 $t-1$ 可获得的 $W$ 个最近的*过去*收益计算得出的：\n$$ \\sigma_{t, \\text{base}} = \\text{StDev}(\\{r_{t-W}, r_{t-W+1}, \\dots, r_{t-1}\\}) $$\n- **幽灵特征模型（前视偏差）：** 时间 $t$ 的预测值，记为 $\\sigma_{t, \\text{ghost}}$，是使用一个错误地包含了当前收益 $r_t$ 的窗口计算得出的：\n$$ \\sigma_{t, \\text{ghost}} = \\text{StDev}(\\{r_{t-W+1}, r_{t-W+2}, \\dots, r_t\\}) $$\n\n对于给定的尾部概率 $\\alpha$，模型 $m \\in \\{\\text{base, ghost}\\}$ 的VaR和ES预测为：\n$$ \\widehat{\\text{VaR}}_{t,m} = q_\\alpha \\sigma_{t,m}, \\quad \\text{其中} \\quad q_\\alpha = \\Phi^{-1}(\\alpha) $$\n$$ \\widehat{\\text{ES}}_{t,m} = -\\frac{\\varphi(q_\\alpha)}{\\alpha} \\sigma_{t,m} $$\n此处，$\\Phi^{-1}(\\cdot)$ 是标准正态分布的逆累积分布函数（分位数函数），而 $\\varphi(\\cdot)$ 是其概率密度函数。为了效率，常数 $q_\\alpha$ 和ES的乘数会被预先计算。\n\n**第三阶段：回测指标**\n\n对于每个模型，我们使用四个指标在大小为 $n=T-W$ 的回测样本上评估其预测质量。当 $r_t  \\widehat{\\text{VaR}}_t$ 时，记录一次VaR突破，由 $I_t = \\mathbf{1}\\{r_t  \\widehat{\\text{VaR}}_t\\}$ 表示。总突破次数为 $x = \\sum_{i=1}^n I_t$。\n\n1.  **命中率绝对误差：** 衡量经验突破频率 $\\widehat{p} = x/n$ 与目标水平 $\\alpha$ 之间的偏差：\n$$ |\\widehat{p} - \\alpha| $$\n2.  **无条件覆盖率似然比（$\\text{LR}_{\\text{uc}}$）：** 检验假设 $\\mathbb{E}[I_t] = \\alpha$。该统计量为：\n$$ \\text{LR}_{\\text{uc}} = 2\\left[ x \\ln\\left(\\frac{x/n}{\\alpha}\\right) + (n-x)\\ln\\left(\\frac{1 - x/n}{1-\\alpha}\\right)\\right] $$\n严格遵守为 $x=0$ 或 $x=n$ 指定的约定来处理对数项。\n3.  **平均分位数核查损失（$\\overline{\\ell}^{Q}$）：** 一种用于分位数的严格一致性评分函数。值越低越好。\n$$ \\overline{\\ell}^{Q} = \\frac{1}{n}\\sum_{t=1}^{n} (\\alpha - I_t)(r_t - \\widehat{\\text{VaR}}_t) $$\n4.  **绝对ES偏差：** 衡量突破日的平均预测ES与同一些日子的平均已实现收益之间的差异。\n$$ |\\overline{\\widehat{\\text{ES}}}_{\\text{tail}} - \\overline{r}_{\\text{tail}}| $$\n其中 $\\overline{r}_{\\text{tail}} = \\frac{1}{x}\\sum_{t: I_t=1} r_t$ 且 $\\overline{\\widehat{\\text{ES}}}_{\\text{tail}} = \\frac{1}{x}\\sum_{t: I_t=1} \\widehat{\\text{ES}}_t$。如果 $x=0$（没有突破），偏差定义为0，因为没有尾部事件可供评估。\n\n**第四阶段：比较分析与最终输出**\n\n分析的核心是两种模型的直接比较。对于四个测试用例（A, B, C, D）中的每一个，我们为基准模型和幽灵特征模型计算这四个指标。最终要求的输出是这些指标的差异，计算方式为（基准模型指标）-（幽灵模型指标）：\n\n- $D_1 = |\\widehat{p}_{\\text{base}} - \\alpha| - |\\widehat{p}_{\\text{ghost}} - \\alpha|$\n- $D_2 = \\text{LR}_{\\text{uc, base}} - \\text{LR}_{\\text{uc, ghost}}$\n- $D_3 = \\overline{\\ell}^{Q}_{\\text{base}} - \\overline{\\ell}^{Q}_{\\text{ghost}}$\n- $D_4 = |\\overline{\\widehat{\\text{ES}}}_{\\text{tail, base}} - \\overline{r}_{\\text{tail, base}}| - |\\overline{\\widehat{\\text{ES}}}_{\\text{tail, ghost}} - \\overline{r}_{\\text{tail, ghost}}|$\n\n任何 $D_j$ 的正值都表示幽灵特征模型因其使用未来信息而获得的虚假性能提升。该过程对所有四个测试用例执行，产生16个标量值，这些值被格式化为所要求的单行输出。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Implements and compares two rolling Gaussian risk models (VaR and ES),\n    quantifying the effect of 'ghost features' (look-ahead bias) on backtesting outcomes.\n    \"\"\"\n\n    test_cases = [\n        # Case A (heteroskedastic, strong persistence)\n        {'T': 4000, 'omega': 1e-6, 'alpha_G': 0.05, 'beta_G': 0.94, 'W': 250, 'alpha': 0.01, 'seed': 1729},\n        # Case B (heteroskedastic, moderate persistence, shorter sample)\n        {'T': 2000, 'omega': 1e-6, 'alpha_G': 0.15, 'beta_G': 0.80, 'W': 100, 'alpha': 0.05, 'seed': 2718},\n        # Case C (independent and identically distributed Gaussian, edge case)\n        {'T': 4000, 'omega': 1e-4, 'alpha_G': 0.00, 'beta_G': 0.00, 'W': 250, 'alpha': 0.01, 'seed': 3141},\n        # Case D (boundary: small window)\n        {'T': 1500, 'omega': 1e-6, 'alpha_G': 0.10, 'beta_G': 0.85, 'W': 30, 'alpha': 0.02, 'seed': 1618},\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        T, omega, alpha_G, beta_G, W, alpha, seed = case.values()\n        \n        # 1. Generate GARCH(1,1) return series\n        rng = np.random.default_rng(seed)\n        z = rng.normal(size=T)\n        \n        returns = np.zeros(T)\n        sigma2 = np.zeros(T)\n\n        if alpha_G + beta_G  1.0:\n            sigma2_uncond = omega / (1.0 - alpha_G - beta_G)\n        else:\n            sigma2_uncond = omega\n        \n        sigma2[0] = sigma2_uncond\n        returns[0] = np.sqrt(sigma2[0]) * z[0]\n\n        for t in range(1, T):\n            sigma2[t] = omega + alpha_G * returns[t-1]**2 + beta_G * sigma2[t-1]\n            returns[t] = np.sqrt(sigma2[t]) * z[t]\n        \n        # 2. Setup for backtesting\n        backtest_returns = returns[W:]\n        n_backtest = T - W\n        \n        q_alpha = norm.ppf(alpha)\n        es_multiplier = -norm.pdf(q_alpha) / alpha\n\n        # 3. Calculate metrics for both models\n        models = ['base', 'ghost']\n        metrics_all = {}\n\n        for model_type in models:\n            var_forecasts = np.zeros(n_backtest)\n            es_forecasts = np.zeros(n_backtest)\n            \n            for i in range(n_backtest):\n                t_current = W + i\n                if model_type == 'base':\n                    window = returns[t_current - W : t_current]\n                else: # ghost model\n                    window = returns[t_current - W + 1 : t_current + 1]\n                \n                sigma_t = np.std(window, ddof=1)\n                var_forecasts[i] = q_alpha * sigma_t\n                es_forecasts[i] = es_multiplier * sigma_t\n            \n            # --- Compute all 4 metrics ---\n            \n            # Exceedances\n            I = backtest_returns  var_forecasts\n            x = np.sum(I)\n            \n            # Metric 1: Hit-rate absolute error\n            p_hat = x / n_backtest\n            hit_rate_error = np.abs(p_hat - alpha)\n\n            # Metric 2: LR_uc\n            lr_uc = 0.0\n            if x  0 and x  n_backtest :\n                term1 = x * np.log(p_hat / alpha)\n                term2 = (n_backtest - x) * np.log((1 - p_hat) / (1 - alpha))\n                lr_uc = 2 * (term1 + term2)\n            elif x == 0 and n_backtest  0:\n                lr_uc = 2 * (n_backtest * np.log(1 / (1-alpha)))\n            elif x == n_backtest and n_backtest  0:\n                 lr_uc = 2 * (n_backtest * np.log(1 / alpha))\n\n            # Metric 3: Average quantile check loss\n            avg_check_loss = np.mean((alpha - I) * (backtest_returns - var_forecasts))\n            \n            # Metric 4: Absolute ES bias\n            abs_es_bias = 0.0\n            if x  0:\n                realized_shortfall = np.mean(backtest_returns[I])\n                mean_es_on_exceedance = np.mean(es_forecasts[I])\n                abs_es_bias = np.abs(mean_es_on_exceedance - realized_shortfall)\n                \n            metrics_all[model_type] = (hit_rate_error, lr_uc, avg_check_loss, abs_es_bias)\n\n        # 4. Compute differences (baseline - ghost)\n        base_metrics = metrics_all['base']\n        ghost_metrics = metrics_all['ghost']\n        diffs = [base_metrics[j] - ghost_metrics[j] for j in range(4)]\n        results.extend(diffs)\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```", "id": "2374186"}]}