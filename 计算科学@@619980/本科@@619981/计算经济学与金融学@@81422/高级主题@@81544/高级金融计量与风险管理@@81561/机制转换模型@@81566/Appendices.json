{"hands_on_practices": [{"introduction": "掌握任何计量经济模型的关键在于理解其核心估算引擎。对于状态转换模型，这个引擎就是滤波器，它能让我们从可观测的数据中推断出不可见的潜在状态。本练习 [@problem_id:2425912] 将指导你从第一性原理出发，亲手实现经典的汉密尔顿滤波器，并让你直面和解决实际计算中至关重要的数值稳定性问题。", "problem": "从第一性原理出发，为一个双状态马尔可夫转换（机制转换）高斯均值模型实现一个滤波算法，并通过与一个独立的、数值稳定的、模仿标准软件中使用方法的前向实现进行比较，来验证其正确性。考虑一个在 $\\{1,2\\}$ 中取值的隐状态过程 $\\{s_t\\}_{t=1}^T$ 和一个观测过程 $\\{y_t\\}_{t=1}^T$。该隐过程是一个一阶时齐马尔可夫链，其转移概率收录在一个矩阵 $P$ 中，其中条目 $P_{ij}$ 为 $P(s_t=j \\mid s_{t-1}=i)$，对于 $i \\in \\{1,2\\}$ 和 $j \\in \\{1,2\\}$。观测密度是高斯分布，其均值依赖于机制，方差为共同方差：$y_t \\mid s_t=j \\sim \\mathcal{N}(\\mu_j,\\sigma^2)$，其中 $\\mu_1$、$\\mu_2$ 和 $\\sigma>0$ 是已知的。初始机制分布是一个在 $\\{1,2\\}$ 上的概率向量 $\\pi_0$。从贝叶斯法则、全概率定律和马尔可夫性质出发，推导递归滤波逻辑，以计算在每个 $t \\in \\{1,\\dots,T\\}$ 时的滤波概率 $p_t(j) \\equiv P(s_t=j \\mid y_1,\\dots,y_t)$，其中 $j \\in \\{1,2\\}$，$y_1,\\dots,y_T$ 是已实现的观测值，并且 $\\{p_t(j)\\}$ 被序贯更新。纯粹在概率空间中实现这个“Hamilton 滤波器”。另外，为一个隐马尔可夫模型（HMM）实现一个独立的参考计算，该计算使用对数域前向递归，在其中您传播联合对数概率 $\\log P(s_t=j,y_1,\\dots,y_t)$，然后进行归一化以获得相同的滤波概率；使用 Log-Sum-Exp 变换来保持数值稳定性。您的程序必须为下面指定的每个测试用例计算两组随时间变化的滤波概率，并报告两种实现在所有 $t$ 和两种状态下的最大绝对差值。一个测试用例的差值定义为 $\\max_{t \\in \\{1,\\dots,T\\},\\, j \\in \\{1,2\\}} \\left| \\hat{p}_t(j) - \\tilde{p}_t(j) \\right|$，其中 $\\hat{p}_t(j)$ 是来自您的 Hamilton 滤波器的滤波概率，而 $\\tilde{p}_t(j)$ 是来自您的对数域前向递归的滤波概率。\n\n使用以下四个测试用例；在每个用例中，观测向量 $y$ 是明确给出的（无需随机性），并且所有参数都是固定的。下面列出的所有数字都是精确输入，必须照原样使用。\n\n- 测试用例 $1$（一般情况）：\n  - $P = \\begin{bmatrix} 0.90 & 0.10 \\\\ 0.05 & 0.95 \\end{bmatrix}$，\n  - $\\mu = [0.0, 1.0]$，\n  - $\\sigma = 0.3$，\n  - $\\pi_0 = [0.5, 0.5]$，\n  - $y = [0.10, 0.90, 1.10, -0.20, 0.00, 0.80, 0.95, 0.05, 1.20, -0.10]$。\n\n- 测试用例 $2$（近似吸收机制和强分离均值）：\n  - $P = \\begin{bmatrix} 0.99 & 0.01 \\\\ 0.02 & 0.98 \\end{bmatrix}$，\n  - $\\mu = [-1.0, 1.0]$，\n  - $\\sigma = 0.2$，\n  - $\\pi_0 = [0.9, 0.1]$，\n  - $y = [-0.8, -1.1, 0.9, 1.1, -0.9, -1.2]$。\n\n- 测试用例 $3$（均值相同；观测值对状态无信息）：\n  - $P = \\begin{bmatrix} 0.8 & 0.2 \\\\ 0.3 & 0.7 \\end{bmatrix}$，\n  - $\\mu = [0.5, 0.5]$，\n  - $\\sigma = 0.4$，\n  - $\\pi_0 = [0.3, 0.7]$，\n  - $y = [0.2, 0.6, 0.4, 0.7]$。\n\n- 测试用例 $4$（方差极小；似然函数呈尖峰状）：\n  - $P = \\begin{bmatrix} 0.85 & 0.15 \\\\ 0.10 & 0.90 \\end{bmatrix}$，\n  - $\\mu = [0.0, 1.0]$，\n  - $\\sigma = 0.05$，\n  - $\\pi_0 = [0.5, 0.5]$，\n  - $y = [0.02, 0.98, 0.01, 1.02]$。\n\n您的程序必须为上述四个测试用例中的每一个计算前面描述的 Hamilton 滤波器和对数域前向滤波器，然后计算两组滤波概率在所有时间和状态上的最大绝对差值。最终输出必须是包含这四个差值的单行文本，顺序与测试用例相同，格式为一个用方括号括起来的逗号分隔列表，每个差值使用带有小写字母 $e$ 的科学记数法四舍五入到 $10^{-12}$ 以内（例如，$[1.234000000000e-12,3.400000000000e-15, \\dots]$）。不涉及物理单位、角度或百分比。", "solution": "该问题定义明确，科学上合理，并为完整解提供了所有必要信息。它描述了一个标准的带有高斯发射的双状态隐马尔可夫模型（HMM），这是计算统计学和计量经济学的基石。任务是推导并实现称为 Hamilton 滤波器的经典滤波算法，并对照 HMM 前向算法的鲁棒对数域实现来验证其数值输出。\n\n问题是有效的。我们开始推导和求解。\n\n### 模型设定\n\n令 $\\{s_t\\}_{t=1}^T$ 为一个隐状态变量，表示在时间 $t$ 未观测到的机制，其中 $s_t \\in \\{1, 2\\}$。此过程是一个一阶时齐马尔可夫链，其 $2 \\times 2$ 转移概率矩阵为 $P$，其中 $P_{ij} = P(s_t = j \\mid s_{t-1} = i)$。在 $t=1$ 时的初始状态分布由向量 $\\pi_0 = [P(s_1=1), P(s_1=2)]^T$ 给出。\n\n观测过程为 $\\{y_t\\}_{t=1}^T$。在时间 $t$ 的观测值 $y_t$ 是从一个高斯分布中抽取的，该分布的均值取决于当前状态 $s_t$。$y_t$ 的条件密度由下式给出：\n$$\ny_t \\mid (s_t = j) \\sim \\mathcal{N}(\\mu_j, \\sigma^2)\n$$\n相应的概率密度函数（PDF）记为 $f(y_t \\mid s_t=j)$。我们假设，在给定当前状态 $s_t$ 的条件下，观测值 $y_t$ 与所有先前的状态和观测值都是独立的。\n\n滤波的目标是计算隐状态的后验概率序列，$p_t(j) \\equiv P(s_t=j \\mid Y_t)$，其中 $j \\in \\{1, 2\\}$ 且 $t=1, \\dots, T$，$Y_t = \\{y_1, \\dots, y_t\\}$ 表示截至时间 $t$ 的观测历史。\n\n### 1. Hamilton 滤波器的推导（概率空间）\n\nHamilton 滤波器是一个递归算法，由一个预测步和一个更新步组成。我们推导将滤波概率从 $p_{t-1}(i) \\equiv P(s_{t-1}=i \\mid Y_{t-1})$ 更新到 $p_t(j) \\equiv P(s_t=j \\mid Y_t)$ 的递归过程。\n\n**步骤 1：预测**\n首先，我们计算在给定截至时间 $t-1$ 的信息的情况下，在时间 $t$ 处于状态 $j$ 的概率。这是预测概率，$p_{t|t-1}(j) = P(s_t=j \\mid Y_{t-1})$。利用全概率定律和马尔可夫性质：\n$$\np_{t|t-1}(j) = P(s_t=j \\mid Y_{t-1}) = \\sum_{i=1}^{2} P(s_t=j, s_{t-1}=i \\mid Y_{t-1})\n$$\n应用条件概率的定义：\n$$\np_{t|t-1}(j) = \\sum_{i=1}^{2} P(s_t=j \\mid s_{t-1}=i, Y_{t-1}) P(s_{t-1}=i \\mid Y_{t-1})\n$$\n根据状态过程的马尔可夫性质，向状态 $s_t$ 的转移仅依赖于前一个状态 $s_{t-1}$，而与过去的观测值 $Y_{t-1}$ 无关。因此，$P(s_t=j \\mid s_{t-1}=i, Y_{t-1}) = P(s_t=j \\mid s_{t-1}=i) = P_{ij}$。这便得出了预测步骤：\n$$\np_{t|t-1}(j) = \\sum_{i=1}^{2} P_{ij} \\, p_{t-1}(i)\n$$\n\n**步骤 2：更新**\n接下来，我们使用贝叶斯法则结合新的观测值 $y_t$，将预测概率更新为滤波概率：\n$$\np_t(j) = P(s_t=j \\mid Y_t) = P(s_t=j \\mid y_t, Y_{t-1}) = \\frac{f(y_t \\mid s_t=j, Y_{t-1}) P(s_t=j \\mid Y_{t-1})}{f(y_t \\mid Y_{t-1})}\n$$\n由于观测值的条件独立性，$f(y_t \\mid s_t=j, Y_{t-1}) = f(y_t \\mid s_t=j)$。分母是一个归一化常数，通过将分子对所有可能的状态 $k$ 求和来计算：\n$$\nf(y_t \\mid Y_{t-1}) = \\sum_{k=1}^{2} f(y_t \\mid s_t=k) P(s_t=k \\mid Y_{t-1})\n$$\n将这些代入更新方程，得到：\n$$\np_t(j) = \\frac{f(y_t \\mid s_t=j) \\, p_{t|t-1}(j)}{\\sum_{k=1}^{2} f(y_t \\mid s_t=k) \\, p_{t|t-1}(k)}\n$$\n\n**初始化 ($t=1$)**：\n递归从 $t=1$ 开始。第一个时间步的“预测”概率是初始分布：$p_{1|0}(j) = \\pi_0(j)$。则第一个滤波概率为：\n$$\np_1(j) = \\frac{f(y_1 \\mid s_1=j) \\, \\pi_0(j)}{\\sum_{k=1}^{2} f(y_1 \\mid s_1=k) \\, \\pi_0(k)}\n$$\n这个公式虽然在数学上是正确的，但如果观测序列很长，或者似然值 $f(y_t \\mid s_t=j)$ 非常小，可能会出现数值下溢，因为概率会趋向于零。\n\n### 2. 对数域前向算法的推导\n\n为确保数值稳定性，我们可以处理联合对数概率。这是 HMM 的标准前向算法。令 $\\alpha_t(j) = P(s_t=j, Y_t)$ 为在时间 $t$ 处于状态 $j$ 并观测到序列 $Y_t$ 的联合概率。\n\n**$\\alpha_t(j)$ 的递归**：\n我们可以用 $\\alpha_{t-1}(i)$ 来表示 $\\alpha_t(j)$：\n$$\n\\alpha_t(j) = P(s_t=j, y_t, Y_{t-1}) = f(y_t \\mid s_t=j, Y_{t-1}) P(s_t=j, Y_{t-1})\n$$\n利用条件独立性和全概率定律：\n$$\n\\alpha_t(j) = f(y_t \\mid s_t=j) \\sum_{i=1}^{2} P(s_t=j, s_{t-1}=i, Y_{t-1})\n$$\n$$\n\\alpha_t(j) = f(y_t \\mid s_t=j) \\sum_{i=1}^{2} P(s_t=j \\mid s_{t-1}=i, Y_{t-1}) P(s_{t-1}=i, Y_{t-1})\n$$\n$$\n\\alpha_t(j) = f(y_t \\mid s_t=j) \\sum_{i=1}^{2} P_{ij} \\, \\alpha_{t-1}(i)\n$$\n\n**对数域实现**：\n为防止下溢，我们使用 $\\ell_t(j) = \\log \\alpha_t(j)$。对上述递归取对数：\n$$\n\\ell_t(j) = \\log f(y_t \\mid s_t=j) + \\log\\left( \\sum_{i=1}^{2} P_{ij} \\exp(\\ell_{t-1}(i)) \\right)\n$$\n求和项在数值上是不稳定的。我们将其重写为：\n$$\n\\ell_t(j) = \\log f(y_t \\mid s_t=j) + \\log\\left( \\sum_{i=1}^{2} \\exp(\\log P_{ij} + \\ell_{t-1}(i)) \\right)\n$$\n这个和式使用 Log-Sum-Exp (LSE) 变换来计算：$\\text{LSE}(x_1, \\dots, x_N) = \\log(\\sum_{i=1}^N \\exp(x_i)) = M + \\log(\\sum_{i=1}^N \\exp(x_i - M))$，其中 $M = \\max(x_1, \\dots, x_N)$。这稳定了计算。\n\n**初始化 ($t=1$)**：\n$$\n\\alpha_1(j) = P(s_1=j, y_1) = P(y_1 \\mid s_1=j) P(s_1=j) = f(y_1 \\mid s_1=j) \\pi_0(j)\n$$\n在对数域中：\n$$\n\\ell_1(j) = \\log f(y_1 \\mid s_1=j) + \\log \\pi_0(j)\n$$\n\n**恢复滤波概率**：\n通过对联合概率 $\\alpha_t(j)$进行归一化，可以获得滤波概率 $p_t(j)$：\n$$\np_t(j) = P(s_t=j \\mid Y_t) = \\frac{P(s_t=j, Y_t)}{P(Y_t)} = \\frac{\\alpha_t(j)}{\\sum_{k=1}^2 \\alpha_t(k)}\n$$\n在对数域中，这是一个数值稳定的 softmax 操作：\n$$\np_t(j) = \\frac{\\exp(\\ell_t(j))}{\\sum_{k=1}^2 \\exp(\\ell_t(k))} = \\exp(\\ell_t(j) - \\text{LSE}(\\ell_t(1), \\ell_t(2)))\n$$\n这第二个实现提供了一个数值上鲁棒的基准，可以用来验证直接的 Hamilton 滤波器。问题要求实现这两种方法，并报告对于给定的测试用例，它们输出之间的最大绝对差值。", "answer": "```python\nimport numpy as np\nfrom scipy.special import logsumexp\n\ndef solve():\n    \"\"\"\n    Implements and compares a standard Hamilton filter with a log-domain forward filter\n    for a two-state Markov-switching Gaussian mean model.\n    \"\"\"\n\n    def gaussian_log_pdf(y, mu, sigma):\n        \"\"\"\n        Computes the log of the Gaussian probability density function from first principles.\n        log f(y; mu, sigma) = -0.5 * (log(2*pi*sigma^2) + (y - mu)^2 / sigma^2)\n        \"\"\"\n        var = sigma**2\n        return -0.5 * (np.log(2 * np.pi * var) + ((y - mu)**2) / var)\n\n    def hamilton_filter(y_obs, P, mu, sigma, pi0):\n        \"\"\"\n        Implements the Hamilton filter in standard probability space.\n        \n        This algorithm recursively computes the filtered probabilities P(s_t|y_1,...,y_t).\n        It is derived directly from Bayes' rule and can be susceptible to numerical underflow.\n        \"\"\"\n        T = len(y_obs)\n        num_states = len(mu)\n        filtered_probs = np.zeros((T, num_states))\n\n        # Time t=1\n        obs_likelihoods_t1 = np.array([np.exp(gaussian_log_pdf(y_obs[0], m, sigma)) for m in mu])\n        joint_prob = obs_likelihoods_t1 * pi0\n        marginal_likelihood = np.sum(joint_prob)\n        \n        if marginal_likelihood > 1e-100: # A small threshold to avoid division by zero\n            filtered_probs[0, :] = joint_prob / marginal_likelihood\n        else:\n            # Fallback if likelihoods underflow to zero. The posterior equals the prior (pi0).\n            filtered_probs[0, :] = pi0\n\n        # Time t > 1\n        for t in range(1, T):\n            # Prediction step: p(s_t|Y_{t-1}) = sum_i P(s_t|s_{t-1}=i) * p(s_{t-1}=i|Y_{t-1})\n            predicted_prob = P.T @ filtered_probs[t - 1, :]\n\n            # Update step\n            obs_likelihoods_t = np.array([np.exp(gaussian_log_pdf(y_obs[t], m, sigma)) for m in mu])\n            joint_prob = obs_likelihoods_t * predicted_prob\n            marginal_likelihood = np.sum(joint_prob)\n            \n            if marginal_likelihood > 1e-100:\n                filtered_probs[t, :] = joint_prob / marginal_likelihood\n            else:\n                 # Fallback: if data is extremely unlikely under all regimes, the posterior equals the prior (predicted probability).\n                filtered_probs[t, :] = predicted_prob\n\n        return filtered_probs\n\n    def log_forward_filter(y_obs, P, mu, sigma, pi0):\n        \"\"\"\n        Implements the forward recursion for an HMM in the log domain for numerical stability.\n\n        This algorithm computes log P(s_t, y_1,...,y_t) and then normalizes\n        to obtain the filtered probabilities P(s_t|y_1,...,y_t).\n        \"\"\"\n        T = len(y_obs)\n        num_states = len(mu)\n        log_alpha = np.zeros((T, num_states))\n        filtered_probs = np.zeros((T, num_states))\n        \n        log_P = np.log(P)\n        log_pi0 = np.log(pi0)\n\n        # Time t=1\n        # log P(s_1, y_1) = log f(y_1|s_1) + log P(s_1)\n        log_obs_likelihoods_t1 = np.array([gaussian_log_pdf(y_obs[0], m, sigma) for m in mu])\n        log_alpha[0, :] = log_obs_likelihoods_t1 + log_pi0\n\n        # Normalize to get filtered probabilities for t=1\n        # P(s_1|y_1) = exp(log_alpha_1 - logsumexp(log_alpha_1))\n        log_marginal_likelihood_t1 = logsumexp(log_alpha[0, :])\n        filtered_probs[0, :] = np.exp(log_alpha[0, :] - log_marginal_likelihood_t1)\n        \n        # Time t > 1\n        for t in range(1, T):\n            log_obs_likelihoods_t = np.array([gaussian_log_pdf(y_obs[t], m, sigma) for m in mu])\n            \n            for j in range(num_states):\n                # Calculate log P(s_t=j, y_1,...,y_{t-1})\n                # = logsumexp_i ( log P(s_{t-1}=i, y_1,...,y_{t-1}) + log P(s_t=j|s_{t-1}=i) )\n                log_sum_terms = log_alpha[t - 1, :] + log_P[:, j]\n                log_predicted_sum = logsumexp(log_sum_terms)\n                \n                # Calculate log P(s_t=j, y_1,...,y_t)\n                # = log f(y_t|s_t=j) + log P(s_t=j, y_1,...,y_{t-1})\n                log_alpha[t, j] = log_obs_likelihoods_t[j] + log_predicted_sum\n\n            # Normalize to get filtered probabilities for time t\n            log_marginal_likelihood_t = logsumexp(log_alpha[t, :])\n            filtered_probs[t, :] = np.exp(log_alpha[t, :] - log_marginal_likelihood_t)\n            \n        return filtered_probs\n\n    test_cases = [\n        # Test case 1 (general case)\n        {\n            \"P\": np.array([[0.90, 0.10], [0.05, 0.95]]),\n            \"mu\": np.array([0.0, 1.0]),\n            \"sigma\": 0.3,\n            \"pi0\": np.array([0.5, 0.5]),\n            \"y\": np.array([0.10, 0.90, 1.10, -0.20, 0.00, 0.80, 0.95, 0.05, 1.20, -0.10]),\n        },\n        # Test case 2 (nearly absorbing regimes and strongly separated means)\n        {\n            \"P\": np.array([[0.99, 0.01], [0.02, 0.98]]),\n            \"mu\": np.array([-1.0, 1.0]),\n            \"sigma\": 0.2,\n            \"pi0\": np.array([0.9, 0.1]),\n            \"y\": np.array([-0.8, -1.1, 0.9, 1.1, -0.9, -1.2]),\n        },\n        # Test case 3 (identical means; observations uninformative)\n        {\n            \"P\": np.array([[0.8, 0.2], [0.3, 0.7]]),\n            \"mu\": np.array([0.5, 0.5]),\n            \"sigma\": 0.4,\n            \"pi0\": np.array([0.3, 0.7]),\n            \"y\": np.array([0.2, 0.6, 0.4, 0.7]),\n        },\n        # Test case 4 (very small variance; sharply peaked likelihoods)\n        {\n            \"P\": np.array([[0.85, 0.15], [0.10, 0.90]]),\n            \"mu\": np.array([0.0, 1.0]),\n            \"sigma\": 0.05,\n            \"pi0\": np.array([0.5, 0.5]),\n            \"y\": np.array([0.02, 0.98, 0.01, 1.02]),\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        p_hamilton = hamilton_filter(case[\"y\"], case[\"P\"], case[\"mu\"], case[\"sigma\"], case[\"pi0\"])\n        p_log_forward = log_forward_filter(case[\"y\"], case[\"P\"], case[\"mu\"], case[\"sigma\"], case[\"pi0\"])\n        \n        # Compute the maximum absolute difference across all time steps and states\n        max_diff = np.max(np.abs(p_hamilton - p_log_forward))\n        results.append(f\"{max_diff:.12e}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2425912"}, {"introduction": "构建了模型之后，一个自然而重要的应用就是进行预测。与单状态模型不同，状态转换模型的预测需要考虑未来所有可能的状态路径，并通过概率进行加权平均。本练习 [@problem_id:2425857] 要求你推导并实现一个高效的递归算法，来计算多步条件均值预测，从而将模型的动态结构转化为对未来的量化展望。", "problem": "给定一个由以下要素定义的一阶时间齐次马尔可夫转换自回归模型。\n\n1. 一个离散时间、有限状态的马尔可夫链 $(S_t)_{t \\ge 0}$，其状态空间为 $\\{1,\\dots,N\\}$，转移矩阵为 $P \\in \\mathbb{R}^{N \\times N}$，其中 $P_{ij} = \\mathbb{P}(S_{t+1} = j \\mid S_t = i)$ 且每行之和为 $1$。\n2. 一个满足机制依赖自回归的标量时间序列 $(y_t)_{t \\ge 0}$\n   $$y_t = \\mu_{S_t} + \\phi_{S_t} y_{t-1} + \\varepsilon_t,$$\n   其中 $\\mu_i \\in \\mathbb{R}$ 和 $\\phi_i \\in \\mathbb{R}$ 是状态 $i \\in \\{1,\\dots,N\\}$ 的机制特定参数，$(\\varepsilon_t)$ 是一个独立的、零均值的扰动序列，满足 $\\mathbb{E}[\\varepsilon_t] = 0$。此任务不需要任何进一步的分布假设。\n3. 在预测起始时间 $t$，你观察到最近的值 $y_t$（一个实数），并且你拥有滤波后的状态概率 $\\pi_t \\in \\mathbb{R}^N$，其中 $(\\pi_t)_i = \\mathbb{P}(S_t = i \\mid \\mathcal{F}_t)$ 且 $\\sum_{i=1}^N (\\pi_t)_i = 1$。\n\n你的任务是计算条件均值的 $h$ 步向前预测，\n$$\\mathbb{E}[y_{t+h} \\mid y_t, \\pi_t],$$\n通过对马尔可夫链所蕴含的所有未来可能的机制路径进行正确平均，并且仅使用马尔可夫性质和迭代期望定律这些基本原理。直接枚举所有路径在计算上是不可行的；请仅基于这些基本原理推导出一个递归关系，从而为一般的 $h \\ge 0$ 得出所需的预测。\n\n实现一个算法，对每个测试用例计算标量预测值 $\\mathbb{E}[y_{t+h} \\mid y_t, \\pi_t]$。如果 $h = 0$，则定义预测值为 $y_t$。所有输入都是纯数值且无量纲的。\n\n你的程序必须使用以下测试套件。每个测试用例都明确指定了 $(N, \\mu, \\phi, P, \\pi_t, y_t, h)$ 的所有数值条目。将 $P_{ij}$ 解释为 $\\mathbb{P}(S_{t+1} = j \\mid S_t = i)$。\n\n- 测试用例 $1$（两种机制，一步预测）：\n  - $N = 2$\n  - $\\mu = [0.5, -0.5]$\n  - $\\phi = [0.6, 0.9]$\n  - $$P = \\begin{bmatrix} 0.95 & 0.05 \\\\ 0.10 & 0.90 \\end{bmatrix}$$\n  - $\\pi_t = [0.7, 0.3]$\n  - $y_t = 1.2$\n  - $h = 1$\n\n- 测试用例 $2$（两种机制，多步递归）：\n  - $N = 2$\n  - $\\mu = [1.0, -1.0]$\n  - $\\phi = [0.2, 0.8]$\n  - $$P = \\begin{bmatrix} 0.85 & 0.15 \\\\ 0.20 & 0.80 \\end{bmatrix}$$\n  - $\\pi_t = [0.4, 0.6]$\n  - $y_t = -0.3$\n  - $h = 3$\n\n- 测试用例 $3$（两种机制，通过单位转移矩阵实现的确定性机制）：\n  - $N = 2$\n  - $\\mu = [0.2, 1.2]$\n  - $\\phi = [0.5, 0.9]$\n  - $$P = \\begin{bmatrix} 1.0 & 0.0 \\\\ 0.0 & 1.0 \\end{bmatrix}$$\n  - $\\pi_t = [0.2, 0.8]$\n  - $y_t = 0.0$\n  - $h = 4$\n\n- 测试用例 $4$（三种机制，作为不变性检查的相同机制动态）：\n  - $N = 3$\n  - $\\mu = [0.3, 0.3, 0.3]$\n  - $\\phi = [0.7, 0.7, 0.7]$\n  - $$P = \\begin{bmatrix} 0.6 & 0.3 & 0.1 \\\\ 0.2 & 0.5 & 0.3 \\\\ 0.25 & 0.25 & 0.5 \\end{bmatrix}$$\n  - $\\pi_t = [0.2, 0.5, 0.3]$\n  - $y_t = 2.0$\n  - $h = 2$\n\n- 测试用例 $5$（边界情况 $h = 0$）：\n  - $N = 2$\n  - $\\mu = [0.0, 1.0]$\n  - $\\phi = [0.0, 0.0]$\n  - $$P = \\begin{bmatrix} 0.9 & 0.1 \\\\ 0.2 & 0.8 \\end{bmatrix}$$\n  - $\\pi_t = [0.5, 0.5]$\n  - $y_t = 3.14159$\n  - $h = 0$\n\n你的程序必须为五个测试用例中的每一个计算一个标量预测值，并打印一行结果。结果为一个逗号分隔的浮点数列表，保留到 $6$ 位小数，并用方括号括起来，例如 $[x_1,x_2,x_3,x_4,x_5]$。输出中不允许有多余的空格。", "solution": "所提出的问题是有效的。它在科学上植根于马尔可夫转换模型的既定理论，这是计算经济学和金融学中的一个标准课题。该问题是适定的，提供了计算唯一条件期望所需的所有必要参数和条件。其语言客观且数学上精确，没有任何模糊之处。因此，我将着手推导解决方案。\n\n目标是计算由一阶马尔可夫转换自回归模型（MS-AR(1)）控制的标量时间序列 $y_t$ 的 $h$ 步向前预测。该预测为条件期望 $\\mathbb{E}[y_{t+h} \\mid \\mathcal{F}_t]$，其中 $\\mathcal{F}_t$ 是时间 $t$ 的信息集，包含值 $y_t$ 并允许确定滤波后的状态概率 $\\pi_t$。问题陈述 $\\mathbb{P}(S_t=i \\mid \\mathcal{F}_t) = (\\pi_t)_i$。\n\n该模型定义如下：\n$1$. 一个在 $\\{1, \\dots, N\\}$ 上的马尔可夫链 $(S_t)_{t \\ge 0}$，其转移矩阵为 $P$，其中 $P_{ij} = \\mathbb{P}(S_{t+1}=j \\mid S_t=i)$。\n$2$. 一个时间序列 $(y_t)_{t \\ge 0}$，遵循 $y_t = \\mu_{S_t} + \\phi_{S_t} y_{t-1} + \\varepsilon_t$，且 $\\mathbb{E}[\\varepsilon_t]=0$。\n\n问题要求一个基于基本原理（即迭代期望定律和马尔可夫性质）推导出的递归解，以避免计算上不可行的对所有状态路径的枚举。对标量预测 $\\hat{y}_{t+k|t} = \\mathbb{E}[y_{t+k} \\mid \\mathcal{F}_t]$ 直接进行递归会因相关项 $\\mathbb{E}[\\phi_{S_{t+k}} y_{t+k-1} \\mid \\mathcal{F}_t]$ 而变得复杂。一种更稳健的方法是为递归定义一个状态向量，该向量携带足够的信息用于传播。\n\n让我们为每个预测步长 $k \\in \\{1, \\dots, h\\}$ 定义一个列向量 $\\mathbf{z}_k \\in \\mathbb{R}^N$ 如下：\n$$ (\\mathbf{z}_k)_i = \\mathbb{E}[y_{t+k} \\cdot \\mathbf{1}_{\\{S_{t+k}=i\\}} \\mid \\mathcal{F}_t] $$\n其中 $\\mathbf{1}_{\\{S_{t+k}=i\\}}$ 是事件 $S_{t+k}=i$ 的指示函数。在预测期 $k$ 的总预测值是该向量各元素之和：\n$$ \\hat{y}_{t+k|t} = \\mathbb{E}[y_{t+k} \\mid \\mathcal{F}_t] = \\mathbb{E}\\left[\\sum_{i=1}^N y_{t+k} \\cdot \\mathbf{1}_{\\{S_{t+k}=i\\}} \\mid \\mathcal{F}_t\\right] = \\sum_{i=1}^N \\mathbb{E}[y_{t+k} \\cdot \\mathbf{1}_{\\{S_{t+k}=i\\}} \\mid \\mathcal{F}_t] = \\mathbf{1}^T \\mathbf{z}_k $$\n其中 $\\mathbf{1}$ 是一个全为1的列向量。\n\n我们现在推导 $\\mathbf{z}_k$ 的递归关系。对于 $k \\ge 1$，我们代入 $y_{t+k}$ 的定义：\n$$ (\\mathbf{z}_k)_i = \\mathbb{E}[(\\mu_{S_{t+k}} + \\phi_{S_{t+k}} y_{t+k-1} + \\varepsilon_{t+k}) \\cdot \\mathbf{1}_{\\{S_{t+k}=i\\}} \\mid \\mathcal{F}_t] $$\n根据期望的线性性质，并注意到由于 $\\varepsilon_{t+k}$ 独立于过去的信息，$\\mathbb{E}[\\varepsilon_{t+k} \\cdot \\mathbf{1}_{\\{S_{t+k}=i\\}} \\mid \\mathcal{F}_t] = 0$，我们有：\n$$ (\\mathbf{z}_k)_i = \\mathbb{E}[\\mu_{S_{t+k}} \\cdot \\mathbf{1}_{\\{S_{t+k}=i\\}} \\mid \\mathcal{F}_t] + \\mathbb{E}[\\phi_{S_{t+k}} \\cdot y_{t+k-1} \\cdot \\mathbf{1}_{\\{S_{t+k}=i\\}} \\mid \\mathcal{F}_t] $$\n在事件 $\\{S_{t+k}=i\\}$ 的条件下，参数 $\\mu_{S_{t+k}}$ 和 $\\phi_{S_{t+k}}$ 变为常数 $\\mu_i$ 和 $\\phi_i$：\n$$ (\\mathbf{z}_k)_i = \\mu_i \\mathbb{E}[\\mathbf{1}_{\\{S_{t+k}=i\\}} \\mid \\mathcal{F}_t] + \\phi_i \\mathbb{E}[y_{t+k-1} \\cdot \\mathbf{1}_{\\{S_{t+k}=i\\}} \\mid \\mathcal{F}_t] $$\n第一项涉及预测的状态概率：$\\mathbb{E}[\\mathbf{1}_{\\{S_{t+k}=i\\}} \\mid \\mathcal{F}_t] = \\mathbb{P}(S_{t+k}=i \\mid \\mathcal{F}_t)$。令 $\\boldsymbol{\\pi}_{t+k|t}$ 为这些概率的行向量。它根据 $\\boldsymbol{\\pi}_{t+k|t} = \\boldsymbol{\\pi}_t P^k$ 演化。\n第二项需要仔细处理。我们通过以 $\\mathcal{F}_{t+k-1}$ 为条件使用迭代期望定律：\n$$ \\mathbb{E}[y_{t+k-1} \\cdot \\mathbf{1}_{\\{S_{t+k}=i\\}} \\mid \\mathcal{F}_t] = \\mathbb{E}[\\mathbb{E}[y_{t+k-1} \\cdot \\mathbf{1}_{\\{S_{t+k}=i\\}} \\mid \\mathcal{F}_{t+k-1}] \\mid \\mathcal{F}_t] $$\n在内部期望中，$y_{t+k-1}$ 是已知的。根据马尔可夫性质，$S_{t+k}=i$ 的指示函数的期望仅依赖于 $S_{t+k-1}$：\n$$ \\mathbb{E}[y_{t+k-1} \\cdot \\mathbf{1}_{\\{S_{t+k}=i\\}} \\mid \\mathcal{F}_{t+k-1}] = y_{t+k-1} \\cdot \\mathbb{E}[\\mathbf{1}_{\\{S_{t+k}=i\\}} \\mid \\mathcal{F}_{t+k-1}] = y_{t+k-1} \\cdot \\sum_{j=1}^N P_{ji} \\mathbf{1}_{\\{S_{t+k-1}=j\\}} $$\n将其代回外部期望：\n$$ \\mathbb{E}[y_{t+k-1} \\cdot \\mathbf{1}_{\\{S_{t+k}=i\\}} \\mid \\mathcal{F}_t] = \\mathbb{E}\\left[y_{t+k-1} \\sum_{j=1}^N P_{ji} \\mathbf{1}_{\\{S_{t+k-1}=j\\}} \\mid \\mathcal{F}_t\\right] = \\sum_{j=1}^N P_{ji} \\mathbb{E}[y_{t+k-1} \\mathbf{1}_{\\{S_{t+k-1}=j\\}} \\mid \\mathcal{F}_t] $$\n和式内的项恰好是 $(\\mathbf{z}_{k-1})_j$。和 $\\sum_{j=1}^N P_{ji} (\\mathbf{z}_{k-1})_j$ 是向量积 $P^T \\mathbf{z}_{k-1}$ 的第 $i$ 个元素。\n将所有部分组合起来，我们得到 $\\mathbf{z}_k$ 的第 $i$ 个分量的递归关系：\n$$ (\\mathbf{z}_k)_i = \\mu_i \\cdot (\\boldsymbol{\\pi}_t P^k)_i + \\phi_i \\cdot (P^T \\mathbf{z}_{k-1})_i $$\n这可以写成矩阵形式。设 $\\mathbf{M}_\\mu$ 和 $\\mathbf{M}_\\phi$ 分别为对角线上为向量 $\\boldsymbol{\\mu}$ 和 $\\boldsymbol{\\phi}$ 的 $N \\times N$ 对角矩阵。设 $\\mathbf{p}_k = ( \\boldsymbol{\\pi}_t P^k )^T$ 为时间 $t+k$ 的预测状态概率的列向量。递归关系为：\n$$ \\mathbf{z}_k = \\mathbf{M}_\\mu \\mathbf{p}_k + \\mathbf{M}_\\phi (P^T \\mathbf{z}_{k-1}) $$\n其中 $\\mathbf{p}_k = P^T \\mathbf{p}_{k-1}$。\n\n递归的基准情形是 $\\mathbf{z}_0$。根据定义：\n$$ (\\mathbf{z}_0)_i = \\mathbb{E}[y_t \\cdot \\mathbf{1}_{\\{S_t=i\\}} \\mid \\mathcal{F}_t] = y_t \\cdot \\mathbb{E}[\\mathbf{1}_{\\{S_t=i\\}} \\mid \\mathcal{F}_t] = y_t \\cdot (\\boldsymbol{\\pi}_t)_i $$\n因此，初始向量为 $\\mathbf{z}_0 = y_t \\boldsymbol{\\pi}_t^T$。概率向量的基准情形为 $\\mathbf{p}_0 = \\boldsymbol{\\pi}_t^T$。\n\n完整的算法如下：\n$1$. 对于预测期 $h=0$，根据定义，预测值为 $y_t$。\n$2$. 对于 $h > 0$，初始化列向量 $\\mathbf{z} = y_t \\boldsymbol{\\pi}_t^T$ 和 $\\mathbf{p} = \\boldsymbol{\\pi}_t^T$。\n$3$. 从 $k=1$ 迭代到 $h$：\n   a. 更新预测的概率向量：$\\mathbf{p} \\leftarrow P^T \\mathbf{p}$。\n   b. 更新核心期望向量：$\\mathbf{z} \\leftarrow \\mathbf{M}_\\mu \\mathbf{p} + \\mathbf{M}_\\phi (P^T \\mathbf{z})$。\n$4$. 循环完成后，最终的 $h$ 步预测是最终向量 $\\mathbf{z}$ 的元素之和，即 $\\hat{y}_{t+h|t} = \\mathbf{1}^T \\mathbf{z}$。\n该算法计算效率高，仅依赖于循环中的矩阵-向量乘法，并正确地基于基本原理实现了预测。", "answer": "```python\nimport numpy as np\n\ndef compute_forecast(N, mu, phi, P, pi_t, y_t, h):\n    \"\"\"\n    Computes the h-step-ahead forecast for a Markov-switching AR(1) model.\n\n    Args:\n        N (int): Number of regimes.\n        mu (list): List of regime-specific intercepts.\n        phi (list): List of regime-specific AR(1) coefficients.\n        P (list of lists): N x N transition matrix.\n        pi_t (list): Filtered state probabilities at time t.\n        y_t (float): Observed value at time t.\n        h (int): Forecast horizon.\n\n    Returns:\n        float: The h-step-ahead forecast E[y_{t+h} | F_t].\n    \"\"\"\n    if h == 0:\n        return y_t\n\n    # Convert inputs to numpy arrays for matrix operations.\n    # mu, phi, and pi_t are column vectors.\n    mu_vec = np.array(mu).reshape(-1, 1)\n    phi_vec = np.array(phi).reshape(-1, 1)\n    pi_t_vec = np.array(pi_t).reshape(-1, 1)\n    \n    P_mat = np.array(P)\n    P_T = P_mat.T  # Transpose of P\n\n    # Diagonal matrices for mu and phi\n    M_mu = np.diag(mu)\n    M_phi = np.diag(phi)\n\n    # Initialization for the recursion at k=0\n    # z_k = E[y_{t+k} * 1_{S_{t+k}=i} | F_t]\n    # p_k = P(S_{t+k}=i | F_t)\n    z = y_t * pi_t_vec\n    p = pi_t_vec\n\n    # Recursive computation for k = 1, ..., h\n    for _ in range(h):\n        p_next = P_T @ p\n        z_next = M_mu @ p_next + M_phi @ (P_T @ z)\n        p = p_next\n        z = z_next\n\n    # The final forecast is the sum of elements in the z vector\n    forecast = np.sum(z)\n    return forecast\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test suite.\n    \"\"\"\n    # Test case 1\n    tc1 = {\n        \"N\": 2,\n        \"mu\": [0.5, -0.5],\n        \"phi\": [0.6, 0.9],\n        \"P\": [[0.95, 0.05], [0.10, 0.90]],\n        \"pi_t\": [0.7, 0.3],\n        \"y_t\": 1.2,\n        \"h\": 1,\n    }\n\n    # Test case 2\n    tc2 = {\n        \"N\": 2,\n        \"mu\": [1.0, -1.0],\n        \"phi\": [0.2, 0.8],\n        \"P\": [[0.85, 0.15], [0.20, 0.80]],\n        \"pi_t\": [0.4, 0.6],\n        \"y_t\": -0.3,\n        \"h\": 3,\n    }\n\n    # Test case 3\n    tc3 = {\n        \"N\": 2,\n        \"mu\": [0.2, 1.2],\n        \"phi\": [0.5, 0.9],\n        \"P\": [[1.0, 0.0], [0.0, 1.0]],\n        \"pi_t\": [0.2, 0.8],\n        \"y_t\": 0.0,\n        \"h\": 4,\n    }\n    \n    # Test case 4\n    tc4 = {\n        \"N\": 3,\n        \"mu\": [0.3, 0.3, 0.3],\n        \"phi\": [0.7, 0.7, 0.7],\n        \"P\": [[0.6, 0.3, 0.1], [0.2, 0.5, 0.3], [0.25, 0.25, 0.5]],\n        \"pi_t\": [0.2, 0.5, 0.3],\n        \"y_t\": 2.0,\n        \"h\": 2,\n    }\n\n    # Test case 5\n    tc5 = {\n        \"N\": 2,\n        \"mu\": [0.0, 1.0],\n        \"phi\": [0.0, 0.0],\n        \"P\": [[0.9, 0.1], [0.2, 0.8]],\n        \"pi_t\": [0.5, 0.5],\n        \"y_t\": 3.14159,\n        \"h\": 0,\n    }\n    \n    test_cases = [tc1, tc2, tc3, tc4, tc5]\n    results = []\n\n    for case in test_cases:\n        forecast = compute_forecast(\n            case[\"N\"],\n            case[\"mu\"],\n            case[\"phi\"],\n            case[\"P\"],\n            case[\"pi_t\"],\n            case[\"y_t\"],\n            case[\"h\"]\n        )\n        results.append(f\"{forecast:.6f}\")\n    \n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2425857"}, {"introduction": "强大的模型不仅要能拟合数据，更应能融入经济理论或先验知识。将理论约束转化为模型参数的特定结构，是连接理论与实证分析的桥梁。本练习 [@problem_id:2425865] 是一个思想实验，探讨如何对模型施加一个常见的结构性约束——即某个状态是“不可返回”的（例如一次性的结构性突变），这有助于你理解如何使模型更贴近具体的经济现实。", "problem": "考虑一个可观测序列 $y_t$ 的双区制马尔可夫转换模型，其中\n$$y_t = \\mu_{S_t} + \\varepsilon_t,$$\n区制指示变量 $S_t \\in \\{1,2\\}$ 服从一个时齐马尔可夫链，且 $\\varepsilon_t \\sim \\mathcal{N}(0,\\sigma^2)$ 独立于 $(S_t)_{t \\ge 1}$。设转移概率矩阵为\n$$\nP \\equiv \\begin{pmatrix}\np_{11} & p_{12} \\\\\np_{21} & p_{22}\n\\end{pmatrix},\n$$\n其中 $p_{ij} = \\mathbb{P}(S_t = j \\mid S_{t-1} = i)$ 且每行之和为 $1$。假设经济理论意味着一旦过程离开区制 $1$，它就再也不能返回区制 $1$（也就是说，区制 $1$ 是非常返的，即对于所有 $t$，都有 $\\mathbb{P}(S_t=1 \\mid S_{t-1}=2) = 0$）。\n\n下列哪项是调整马尔可夫转换模型的设定和估计以施加这种非常返性约束的最合适方法？\n\nA. 将转移矩阵约束为\n$$\nP = \\begin{pmatrix}\np_{11} & 1 - p_{11} \\\\\n0 & 1\n\\end{pmatrix}, \\quad p_{11} \\in (0,1),\n$$\n使得区制 $2$ 是吸收性的，且从区制 $1$ 到区制 $2$ 的转换最多只能发生一次。在这些约束下，通过最大似然法估计所有参数，包括 $p_{11}$。\n\nB. 保持一个具有 $p_{12} > 0$ 和 $p_{21} > 0$ 的完全遍历的马尔可夫链，但设置初始分布以满足 $\\mathbb{P}(S_0 = 1)$ 非常小；在不对 $P$ 施加任何约束的情况下进行估计。\n\nC. 用一个独立同分布的区制指示变量替代马尔可夫链，令 $S_t \\sim \\text{Bernoulli}(q)$ 在时间 $t$ 上独立，并通过最大似然法估计 $q$；这能确保非常返性。\n\nD. 不改变转移矩阵，但将非常返性解释为一个渐近性质，方法是选择一个非常接近于 $0$ 但严格为正的 $p_{21}$；从数据中自由地估计 $P$ 的所有元素。", "solution": "在尝试任何解答之前，必须首先对问题陈述的科学合理性、自洽性和清晰度进行验证。\n\n**步骤1：提取已知条件**\n问题提供了以下信息：\n- 一个可观测序列 $y_t$ 的双区制马尔可夫转换模型：$y_t = \\mu_{S_t} + \\varepsilon_t$。\n- 区制指示变量 $S_t$ 在 $\\{1,2\\}$ 中取值，并服从一个时齐马尔可夫链。\n- 误差项 $\\varepsilon_t$ 服从 $\\mathcal{N}(0,\\sigma^2)$ 分布，且独立于状态过程 $(S_t)_{t \\ge 1}$。\n- 转移概率矩阵为 $$ P \\equiv \\begin{pmatrix} p_{11} & p_{12} \\\\ p_{21} & p_{22} \\end{pmatrix} $$，其中 $p_{ij} = \\mathbb{P}(S_t = j \\mid S_{t-1} = i)$ 且行和为 $1$。\n- 一个来自经济理论的约束：“一旦过程离开区制 $1$，它就再也不能返回区制 $1$”。\n- 该约束被形式化地表述为：“区制 $1$ 是非常返的，即对于所有 $t$，都有 $\\mathbb{P}(S_t=1 \\mid S_{t-1}=2) = 0$”。\n\n**步骤2：使用提取的已知条件进行验证**\n- **科学基础：** 该问题基于马尔可夫转换模型的理论，这是计算经济学和金融学中用于为表现出不同动态区制的时间序列建模的一个标准且广泛使用的框架。非常返态或吸收态的概念是马尔可夫链理论的一个基本要素。该模型是一个成熟的统计工具。\n- **适定性：** 问题陈述清晰。它要求找到最合适的建模策略，以实施一个在数学上明确定义的关于马尔可夫链动态的约束。这个问题是明确的，并且基于概率论和统计建模的原则，它有一个特定的答案。\n- **客观性：** 语言精确，没有主观性。术语“非常返”被明确地以概率术语定义，没有解释的余地。\n\n**步骤3：结论与行动**\n问题陈述是有效的。它在科学上是合理的，是适定的、客观的和完整的。我现在将着手解答。\n\n问题的核心是实施“一旦过程离开区制 $1$，它就再也不能返回区制 $1$”这一理论约束。这被明确地形式化为 $\\mathbb{P}(S_t=1 \\mid S_{t-1}=2) = 0$。\n\n在转移矩阵 $P$ 的表示法中，从状态 $i$ 转移到状态 $j$ 的概率是 $p_{ij}$。因此，从区制 $2$ 转移到区制 $1$ 的概率是 $p_{21} = \\mathbb{P}(S_t=1 \\mid S_{t-1}=2)$。该约束直接意味着 $p_{21}$ 必须等于 $0$。\n\n一个一般的两状态马尔可夫链的转移矩阵是：\n$$\nP = \\begin{pmatrix}\np_{11} & p_{12} \\\\\np_{21} & p_{22}\n\\end{pmatrix}\n$$\n转移矩阵的行和必须为 $1$。因此，我们有关系式 $p_{11} + p_{12} = 1$ 和 $p_{21} + p_{22} = 1$。\n\n对第二行施加约束 $p_{21} = 0$ 可得 $0 + p_{22} = 1$，这意味着 $p_{22} = 1$。第一行仍然由 $p_{12} = 1 - p_{11}$ 决定。因此，受约束的转移矩阵必须采用以下形式：\n$$\nP = \\begin{pmatrix}\np_{11} & 1 - p_{11} \\\\\n0 & 1\n\\end{pmatrix}\n$$\n这个结构有一个清晰的解释：\n- 如果系统处于区制 $1$，它可以停留在区制 $1$（概率为 $p_{11}$），或者转换到区制 $2$（概率为 $1 - p_{11}$）。\n- 如果系统处于区制 $2$，它必须停留在区制 $2$（概率为 $1$）。\n\n区制 $2$ 是一个**吸收态**。一旦过程进入区制 $2$，它就永远无法离开。这意味着在过程的历史中，转换最多只能发生一次，即从区制 $1$ 到区制 $2$。这个设定完美地捕捉了理论约束。转移过程的剩余未知参数 $p_{11}$ 必须与其他模型参数（$\\mu_1, \\mu_2, \\sigma^2$）一起从数据中估计，通常是通过在该约束结构下最大化似然函数来实现。$p_{11}$ 的参数空间通常是开区间 $(0,1)$，以避免过程永久停留在区制 $1$（$p_{11}=1$）或立即转换（$p_{11}=0$）的平凡情况。\n\n现在，我将评估每个选项。\n\n**A. 将转移矩阵约束为\n$$\nP = \\begin{pmatrix}\np_{11} & 1 - p_{11} \\\\\n0 & 1\n\\end{pmatrix}, \\quad p_{11} \\in (0,1),\n$$\n使得区制 $2$ 是吸收性的，且从区制 $1$ 到区制 $2$ 的转换最多只能发生一次。在这些约束下，通过最大似然法估计所有参数，包括 $p_{11}$。**\n\n这个选项与上面的推导完全一致。它正确地将 $p_{21}=0$ 确定为必要的约束，推导出了正确的转移矩阵结构，正确地将区制 $2$ 解释为吸收态，并提出了标准的统计程序（约束最大似然法）进行估计。这是将理论信息融入模型中的最直接、最严谨且最合适的方法。\n**结论：正确。**\n\n**B. 保持一个具有 $p_{12} > 0$ 和 $p_{21} > 0$ 的完全遍历的马尔可夫链，但设置初始分布以满足 $\\mathbb{P}(S_0 = 1)$ 非常小；在不对 $P$ 施加任何约束的情况下进行估计。**\n\n这种方法根本上是错误的。问题要求过程*不能*从区制 $2$ 返回到区制 $1$。一个具有 $p_{21} > 0$ 的模型明确允许这种返回。约束是针对所有时间 $t$ 的转移动态，而不是针对 $t=0$ 的初始条件。调整初始分布 $\\mathbb{P}(S_0=1)$ 并不能阻止被禁止的转移 $\\mathbb{P}(S_t=1 \\mid S_{t-1}=2)$ 在任何后续时间发生。这种方法未能施加理论所要求的结构性约束。\n**结论：错误。**\n\n**C. 用一个独立同分布的区制指示变量替代马尔可夫链，令 $S_t \\sim \\text{Bernoulli}(q)$ 在时间 $t$ 上独立，并通过最大似然法估计 $q$；这能确保非常返性。**\n\n这是对模型结构的彻底改变。马尔可夫链具有记忆性，即时间 $t$ 的状态取决于时间 $t-1$ 的状态。而一个关于 $S_t$ 的独立同分布伯努利过程没有记忆性。在这样的模型中，$\\mathbb{P}(S_t=1 \\mid S_{t-1}=2) = \\mathbb{P}(S_t=1) = q$。非常返性约束 $\\mathbb{P}(S_t=1 \\mid S_{t-1}=2)=0$ 将迫使 $q=0$，这意味着对所有 $t$ 都有 $S_t=2$，从而将模型简化为单区制模型。这几乎肯定不是预期的模型。因此，在任何非平凡的情景下，声称这个程序“确保了非常返性”是错误的。这个选项丢弃了问题核心的马尔可夫依赖结构。\n**结论：错误。**\n\n**D. 不改变转移矩阵，但将非常返性解释为一个渐近性质，方法是选择一个非常接近于 $0$ 但严格为正的 $p_{21}$；从数据中自由地估计 $P$ 的所有元素。**\n\n理论约束是 absolute 的：“永不返回”，这意味着 $p_{21}=0$。这个选项提出了一个近似（$p_{21} \\approx 0$）而不是精确实现。此外，它建议“自由地”估计参数，这意味着在估计期间*不*施加约束。如果数据恰好表明 $p_{21}$ 有一个不可忽略的值，自由估计将产生这样一个值，从而忽略了理论约束。正确施加约束需要在估计期间限制参数空间，而不仅仅是希望得到一个特定的结果。这种方法是一种特设的近似，并不是强制执行严格理论要求的“最合适”方式。\n**结论：错误。**", "answer": "$$\\boxed{A}$$", "id": "2425865"}]}