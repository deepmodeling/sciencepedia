{"hands_on_practices": [{"introduction": "理论学习的最佳伙伴是动手实践。本节的第一个练习将指导您应用极值理论中的一个基本方法——分块最大值 (Block Maxima, BM) 法。我们将通过一个模拟德克萨斯州日度最高电力需求的场景，学习如何从时间序列中提取极端值，使用广义极值 (Generalized Extreme Value, GEV) 分布进行拟合，并最终计算如风险价值 (VaR) 和期望损失 (Expected Shortfall) 等关键风险指标。[@problem_id:2391840] 这个练习旨在将 Fisher–Tippett–Gnedenko 定理从抽象理论转化为具体的风险管理工具。", "problem": "编写一个完整的程序，应用极值理论（EVT）对德克萨斯州的最大日电力需求进行建模，以支持峰值负荷电力衍生品的定价和评估电网稳定性风险。您的实现必须从以下基本基础出发：Fisher–Tippett–Gnedenko 定理、块最大值的定义和广义极值分布、分位数和期望亏空的定义，以及风险中性估值的标准原则。您不得使用任何快捷公式；所有量均须从第一性原理计算，并在需要时通过数值积分计算。三角函数中使用的角度必须是弧度。所有电力单位必须以吉瓦（GW）处理。货币尺度归一化为每吉瓦 $1$，因此衍生品价格的数值单位与需求相同。所有概率必须表示为小数。\n\n合成日电力需求的数据生成机制如下。设日需求 $D_{t}$ 对应于天数索引 $t \\in \\{0,1,\\dots,N-1\\}$，其表达式为\n$$\nD_{t} = \\max\\left\\{0, \\ \\mu + A \\sin\\left(\\frac{2\\pi \\, (t \\bmod 365)}{365}\\right) + \\sigma \\, \\varepsilon_{t}\\right\\},\n$$\n其中 $\\varepsilon_{t}$ 是来自具有 $\\nu$ 个自由度的学生t分布的独立同分布抽样。符号 $\\max\\{\\cdot,\\cdot\\}$ 强制非负性。参数 $N$ 等于 $365 \\times Y$，其中样本跨越 $Y$ 年。\n\n您的程序必须对每个测试用例执行以下步骤：\n- 步骤 $1$：使用指定的随机种子和参数 $(Y,\\ \\mu,\\ A,\\ \\sigma,\\ \\nu)$ 模拟日需求序列 $\\{D_{t}\\}_{t=0}^{N-1}$。\n- 步骤 $2$：将所有天数划分为 $B$ 天的非重叠块（丢弃任何剩余的天数），以形成块最大值 $\\{M_{i}\\}_{i=1}^{m}$，其中 $m = \\left\\lfloor \\frac{N}{B} \\right\\rfloor$，且 $M_{i} = \\max\\{D_{t} : t \\in \\text{block } i\\}$。\n- 步骤 $3$：通过最大似然法将广义极值（GEV）分布拟合到块最大值，得到参数 $(\\xi, \\mu_{\\text{gev}}, \\sigma_{\\text{gev}})$，其中 $\\xi$ 是形状参数，$\\mu_{\\text{gev}}$ 是位置参数，$\\sigma_{\\text{gev}}$ 是尺度参数。\n- 步骤 $4$：计算水平为 $\\alpha$ 的一步向前块最大值风险价值，其定义为下一个长度为 $B$ 天的块中最大值的拟合GEV分布的 $\\alpha$-分位数 $q_{\\alpha}$。\n- 步骤 $5$：计算水平为 $\\alpha$ 的一步向前块最大值期望亏空，其定义为\n$$\n\\text{ES}_{\\alpha} \\equiv \\mathbb{E}\\!\\left[M \\mid M > q_{\\alpha}\\right] = \\frac{1}{1-\\alpha}\\int_{\\alpha}^{1} Q(u)\\,du,\n$$\n其中 $Q(u)$ 是拟合的GEV分布关于 $M$ 的分位数函数。以足够高的精度对该积分进行数值计算。\n- 步骤 $6$：考虑一个关于即将到来的块最大值的欧式看涨期权，其到期日等于块长度，即 $\\tau = \\frac{B}{365}$ 年。期权回报为 $(M - K)^{+}$，其中 $K$ 是行权价，$(x)^{+} \\equiv \\max\\{x,0\\}$。在一个将拟合的GEV分布等同于风险中性分布的风险中性近似下，计算未折现的期望回报\n$$\n\\mathbb{E}\\!\\left[(M - K)^{+}\\right] = \\int_{0}^{1} \\max\\{Q(u) - K, 0\\}\\,du,\n$$\n并以连续复利无风险利率 $r$ 对其进行折现，以获得价格 $P = e^{-r \\tau} \\, \\mathbb{E}\\!\\left[(M - K)^{+}\\right]$。对任何需要的积分进行数值计算。\n- 步骤 $7$：给定一个容量水平 $L$，根据拟合的GEV分布计算下一个块最大值的电网故障概率 $p_{\\text{fail}} = \\mathbb{P}[M > L]$。\n\n您的程序必须为每个测试用例返回一个列表，按顺序包含以下元素：\n$[q_{\\alpha},\\ \\text{ES}_{\\alpha},\\ P,\\ \\xi,\\ p_{\\text{fail}}]$，\n并按如下方式四舍五入：$q_{\\alpha}$ 保留 $3$ 位小数，$\\text{ES}_{\\alpha}$ 保留 $3$ 位小数，$P$ 保留 $3$ 位小数，$\\xi$ 保留 $4$ 位小数，以及 $p_{\\text{fail}}$ 保留 $6$ 位小数。所有量在输出中均为不带单位符号的浮点数。\n\n测试套件。使用以下四个测试用例，每个用例指定为一个有序元组\n$(\\text{seed},\\ Y,\\ B,\\ \\mu,\\ A,\\ \\sigma,\\ \\nu,\\ \\alpha,\\ K,\\ L,\\ r)$:\n\n- 用例 $1$： $(12345,\\ 12,\\ 30,\\ 55.0,\\ 12.0,\\ 5.0,\\ 3.5,\\ 0.99,\\ 80.0,\\ 95.0,\\ 0.02)$。\n- 用例 $2$： $(2024,\\ 5,\\ 7,\\ 45.0,\\ 8.0,\\ 4.0,\\ 5.0,\\ 0.975,\\ 65.0,\\ 85.0,\\ 0.01)$。\n- 用例 $3$： $(7,\\ 8,\\ 14,\\ 50.0,\\ 6.0,\\ 3.0,\\ 30.0,\\ 0.995,\\ 75.0,\\ 90.0,\\ 0.0)$。\n- 用例 $4$： $(999,\\ 3,\\ 30,\\ 60.0,\\ 15.0,\\ 7.0,\\ 2.8,\\ 0.98,\\ 85.0,\\ 100.0,\\ 0.03)$。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个逗号分隔的各用例结果列表，并用方括号括起来。例如，一个有效的格式应为\n$[[x_{1},y_{1},z_{1},u_{1},v_{1}],[x_{2},y_{2},z_{2},u_{2},v_{2}],\\dots]$，\n前后不带任何附加文本。", "solution": "我们使用块最大值和广义极值（GEV）分布对电力需求的极值进行建模。Fisher–Tippett–Gnedenko 定理指出，在广泛的条件下，独立同分布观测值的经适当归一化的最大值在分布上收敛于 GEV 族的一个成员。因此，我们提取日需求的块最大值，并通过最大似然法拟合一个GEV模型。\n\n数据生成。我们模拟日需求 $D_{t}$ 如下\n$$\nD_{t} = \\max\\{0,\\ \\mu + A \\sin(2\\pi \\, t/365) + \\sigma \\varepsilon_{t}\\},\n$$\n其中 $\\varepsilon_{t}$ 是来自具有 $\\nu$ 个自由度的学生t分布的独立同分布抽样。角度以弧度为单位。正弦项捕捉季节性变化，而重尾噪声捕捉罕见的尖峰。$\\max$ 算子强制非负性。\n\n块最大值。我们将序列划分为 $B$ 天的块，并取每个块的最大值 $M_{i}$。如果我们总共有 $N = 365 Y$ 天，则完整块的数量为 $m = \\left\\lfloor \\frac{N}{B} \\right\\rfloor$，任何剩余的天数都将被丢弃，以保持块大小相等。我们收集 $\\{M_{i}\\}_{i=1}^{m}$。\n\nGEV拟合。我们通过最大似然法将GEV分布拟合到 $\\{M_{i}\\}$。GEV的累积分布函数为\n$$\nF(x) = \\exp\\left\\{-\\left[1 + \\xi \\left(\\frac{x - \\mu_{\\text{gev}}}{\\sigma_{\\text{gev}}}\\right)\\right]^{-1/\\xi}\\right\\}\n$$\n其支撑集为 $1 + \\xi \\left(\\frac{x - \\mu_{\\text{gev}}}{\\sigma_{\\text{gev}}}\\right) > 0$，而 Gumbel 情况 $\\xi = 0$ 通过连续性来解释。在实现中，我们使用一个标准的科学计算库，其参数化使用形状参数 $c$，其中 $c = -\\xi$。拟合后，我们报告 $\\xi = -c$。\n\n风险度量。水平为 $\\alpha$ 的一步向前块最大值风险价值是分位数\n$$\nq_{\\alpha} = Q(\\alpha),\n$$\n其中 $Q$ 是拟合的GEV分布的分位数函数（逆累积分布函数）。水平为 $\\alpha$ 的期望亏空定义为\n$$\n\\text{ES}_{\\alpha} = \\mathbb{E}[M \\mid M > q_{\\alpha}],\n$$\n并可以通过分位数函数写成\n$$\n\\text{ES}_{\\alpha} = \\frac{1}{1-\\alpha} \\int_{\\alpha}^{1} Q(u)\\,du.\n$$\n我们使用自适应求积法对该积分进行数值计算。对于 $\\xi \\ge 1$ 的重尾情况，此积分会发散；在我们的合成案例中，拟合的 $\\xi$ 保持在 $1$ 以下，积分是有限的。为了避免在 $u=1$ 处的数值问题，我们积分到 $u = 1 - \\varepsilon$，其中 $\\varepsilon$ 是一个非常小的数。\n\n衍生品定价。考虑一个关于下一个块最大值 $M$ 的欧式看涨期权，其行权价为 $K$，到期日为 $\\tau = B/365$ 年。在将拟合的GEV分布视为风险中性分布的风险中性近似下，看涨期权价格为\n$$\nP = e^{-r \\tau} \\, \\mathbb{E}[(M - K)^{+}].\n$$\n使用分位数函数，我们将未折现的期望表示为\n$$\n\\mathbb{E}[(M - K)^{+}] = \\int_{0}^{1} \\max\\{Q(u) - K, 0\\}\\,du = \\int_{u_{0}}^{1} Q(u)\\,du - (1 - u_{0}) K,\n$$\n其中 $u_{0} = F(K)$ 是在 $K$ 处的累积分布函数。这个恒等式成立，因为分位数函数在 $K$ 以上的尾部面积等于超过 $K$ 的期望超额。我们对 $[u_{0}, 1 - \\varepsilon]$ 上的积分进行数值计算，并应用折现因子 $e^{-r \\tau}$。\n\n电网故障概率。给定一个容量 $L$，下一个块的故障概率为\n$$\np_{\\text{fail}} = \\mathbb{P}[M > L] = 1 - F(L),\n$$\n直接从拟合的GEV累积分布函数计算。\n\n每个测试用例的算法步骤：\n- 固定种子，从具有 $\\nu$ 个自由度的学生t分布生成 $N = 365 Y$ 天的噪声 $\\varepsilon_{t}$。计算季节性均值 $\\mu + A \\sin(2\\pi (t \\bmod 365)/365)$ 并加上缩放后的噪声 $\\sigma \\varepsilon_{t}$。在 $0$ 处截断以得到 $D_{t}$。\n- 划分为 $m = \\left\\lfloor \\frac{N}{B} \\right\\rfloor$ 个长度为 $B$ 的块，计算每个块中的最大值 $M_{i}$。\n- 通过最大似然法拟合GEV。提取形状参数 $c$、位置参数 $\\mu_{\\text{gev}}$ 和尺度参数 $\\sigma_{\\text{gev}}$。设 $\\xi = -c$。\n- 从拟合模型中计算 $q_{\\alpha} = Q(\\alpha)$。\n- 通过数值求积计算 $\\text{ES}_{\\alpha} = \\frac{1}{1-\\alpha} \\int_{\\alpha}^{1} Q(u)\\,du$，并使用一个小的上截止值 $\\varepsilon$ 来避免奇异点。\n- 计算 $u_{0} = F(K)$。如果 $u_{0} \\ge 1$，将期权价值设为 $0$。否则，数值计算积分 $\\int_{u_{0}}^{1} Q(u)\\,du$ 并设 $P = e^{-r \\tau}\\left(\\int_{u_{0}}^{1} Q(u)\\,du - (1 - u_{0}) K\\right)$，为了数值安全，将结果截断在零。\n- 计算 $p_{\\text{fail}} = 1 - F(L)$，并为了数值稳定性，将其限制在 $[0,1]$ 区间内。\n- 将 $q_{\\alpha}$ 和 $\\text{ES}_{\\alpha}$ 四舍五入到 $3$ 位小数， $P$ 到 $3$ 位小数， $\\xi$ 到 $4$ 位小数， $p_{\\text{fail}}$ 到 $6$ 位小数。\n\n最终输出是包含四个测试用例的各用例结果列表 $[[q_{\\alpha},\\ \\text{ES}_{\\alpha},\\ P,\\ \\xi,\\ p_{\\text{fail}}], \\dots]$ 的单行，前后无任何附加文本。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import genextreme\nfrom scipy.integrate import quad\n\ndef simulate_daily_demand(seed, years, mu, amplitude, sigma, df):\n    \"\"\"\n    Simulate daily electricity demand (in GW) over 'years' years,\n    with seasonality and heavy-tailed Student-t noise.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    days = 365 * years\n    t = np.arange(days)\n    # Angle in radians; seasonality repeats every 365 days\n    seasonal = amplitude * np.sin(2.0 * np.pi * (t % 365) / 365.0)\n    noise = sigma * rng.standard_t(df, size=days)\n    demand = mu + seasonal + noise\n    # Enforce non-negativity\n    demand = np.maximum(0.0, demand)\n    return demand\n\ndef block_maxima(series, block_days):\n    \"\"\"\n    Partition 'series' into non-overlapping blocks of length 'block_days'\n    and return the list of maxima in each block. Discard remainder.\n    \"\"\"\n    n = len(series)\n    m = n // block_days\n    if m <= 0:\n        return np.array([])\n    trimmed = series[:m * block_days]\n    reshaped = trimmed.reshape(m, block_days)\n    maxima = reshaped.max(axis=1)\n    return maxima\n\ndef fit_gev_mle(maxima):\n    \"\"\"\n    Fit GEV distribution to block maxima using MLE via scipy.stats.genextreme.\n    SciPy's genextreme parameterization uses shape c = -xi.\n    Returns (xi, loc, scale).\n    \"\"\"\n    # Ensure we have variability\n    if len(maxima) < 3 or np.allclose(np.std(maxima), 0.0):\n        # Fallback: trivial fit with tiny scale to avoid errors\n        loc = float(np.mean(maxima)) if len(maxima) > 0 else 0.0\n        scale = float(np.std(maxima)) if len(maxima) > 0 else 1.0\n        c = 0.0\n    else:\n        c, loc, scale = genextreme.fit(maxima)\n        # Sometimes fit may return non-positive scale; guard it\n        if scale <= 0:\n            # Adjust scale to a small positive value\n            scale = max(1e-6, float(np.std(maxima)))\n    xi = -c\n    return xi, loc, scale, c\n\ndef gev_quantile(u, c, loc, scale):\n    \"\"\"Quantile function Q(u) for the fitted GEV in SciPy's parameterization.\"\"\"\n    return genextreme.ppf(u, c, loc=loc, scale=scale)\n\ndef gev_cdf(x, c, loc, scale):\n    \"\"\"CDF F(x) for the fitted GEV in SciPy's parameterization.\"\"\"\n    return genextreme.cdf(x, c, loc=loc, scale=scale)\n\ndef expected_shortfall_alpha(alpha, c, loc, scale):\n    \"\"\"\n    Compute ES_alpha = (1/(1-alpha)) * integral_{alpha}^{1} Q(u) du\n    via numerical quadrature. Integrate up to 1 - eps to avoid endpoint issues.\n    \"\"\"\n    eps = 1e-12\n    upper = 1.0 - eps\n    if alpha >= 1.0:\n        return float('inf')\n    # Define integrand with safety checks\n    def integrand(u):\n        q = gev_quantile(u, c, loc, scale)\n        return q\n    try:\n        val, _ = quad(integrand, alpha, upper, epsabs=1e-6, epsrel=1e-6, limit=200)\n        es = val / (1.0 - alpha)\n        return es\n    except Exception:\n        return float('inf')\n\ndef call_price_on_block_max(K, r, block_days, c, loc, scale):\n    \"\"\"\n    Price of a European call option on the next block maximum M with strike K,\n    maturity tau = block_days/365 years, under risk-neutral approximation\n    using the fitted GEV distribution. Uses quantile integral identity:\n    E[(M-K)+] = \\int_{u0}^{1} Q(u) du - (1-u0)K, where u0 = F(K).\n    \"\"\"\n    tau = block_days / 365.0\n    u0 = gev_cdf(K, c, loc, scale)\n    if not np.isfinite(u0):\n        return 0.0\n    if u0 >= 1.0:\n        undiscounted = 0.0\n    else:\n        eps = 1e-12\n        upper = 1.0 - eps\n        def integrand(u):\n            return gev_quantile(u, c, loc, scale)\n        try:\n            integral_val, _ = quad(integrand, u0, upper, epsabs=1e-6, epsrel=1e-6, limit=200)\n            undiscounted = integral_val - (1.0 - u0) * K\n            if not np.isfinite(undiscounted):\n                undiscounted = 0.0\n        except Exception:\n            undiscounted = 0.0\n    price = np.exp(-r * tau) * max(0.0, undiscounted)\n    return price\n\ndef risk_metrics_for_case(case):\n    \"\"\"\n    Compute [VaR_alpha, ES_alpha, call_price, xi, p_fail] for one test case.\n    Rounding:\n      VaR, ES, price -> 3 decimals\n      xi -> 4 decimals\n      p_fail -> 6 decimals\n    \"\"\"\n    (seed, Y, B, mu, A, sigma, nu, alpha, K, L, r) = case\n    # Simulate daily demand\n    demand = simulate_daily_demand(seed, Y, mu, A, sigma, nu)\n    # Block maxima\n    maxima = block_maxima(demand, B)\n    if len(maxima) < 3:\n        # Ensure there are enough maxima; otherwise pad with mean\n        if len(maxima) == 0:\n            maxima = np.array([mu])\n        elif len(maxima) == 1:\n            maxima = np.array([maxima[0], maxima[0] * 0.99 + 0.01, maxima[0] * 1.01 - 0.01])\n        else:\n            maxima = np.concatenate([maxima, [np.mean(maxima)]*(3 - len(maxima))])\n    # Fit GEV\n    xi, loc, scale, c = fit_gev_mle(maxima)\n    # VaR\n    try:\n        q_alpha = float(gev_quantile(alpha, c, loc, scale))\n        if not np.isfinite(q_alpha):\n            # Fallback: use high empirical quantile\n            q_alpha = float(np.quantile(maxima, alpha))\n    except Exception:\n        q_alpha = float(np.quantile(maxima, alpha))\n    # ES\n    es_alpha = expected_shortfall_alpha(alpha, c, loc, scale)\n    # Call price\n    price = call_price_on_block_max(K, r, B, c, loc, scale)\n    # Failure probability\n    try:\n        p_fail = 1.0 - float(gev_cdf(L, c, loc, scale))\n        if not np.isfinite(p_fail):\n            # Fallback approximation\n            p_fail = max(0.0, min(1.0, 1.0 - float(np.mean(maxima <= L))))\n    except Exception:\n        p_fail = max(0.0, min(1.0, 1.0 - float(np.mean(maxima <= L))))\n    p_fail = max(0.0, min(1.0, p_fail))\n    # Rounding\n    result = [\n        round(q_alpha, 3),\n        round(es_alpha, 3),\n        round(price, 3),\n        round(xi, 4),\n        round(p_fail, 6),\n    ]\n    return result\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case: (seed, Y, B, mu, A, sigma, nu, alpha, K, L, r)\n    test_cases = [\n        (12345, 12, 30, 55.0, 12.0, 5.0, 3.5, 0.99, 80.0, 95.0, 0.02),\n        (2024, 5, 7, 45.0, 8.0, 4.0, 5.0, 0.975, 65.0, 85.0, 0.01),\n        (7, 8, 14, 50.0, 6.0, 3.0, 30.0, 0.995, 75.0, 90.0, 0.0),\n        (999, 3, 30, 60.0, 15.0, 7.0, 2.8, 0.98, 85.0, 100.0, 0.03),\n    ]\n\n    results = []\n    for case in test_cases:\n        result = risk_metrics_for_case(case)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # Ensure a single line with the nested list representation.\n    print(f\"{results}\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2391840"}, {"introduction": "虽然分块最大值法很直观，但在实践中我们往往希望更有效地利用数据。超阈值峰值 (Peak-Over-Threshold, POT) 法为此提供了有力的替代方案。在这个练习中，您将模拟一家大型在线零售商的网站延迟数据，并使用 POT 方法对超过某个高阈值的延迟峰值进行建模。[@problem_id:2391805] 通过将广义帕累托分布 (Generalized Pareto Distribution, GPD) 拟合到这些“超阈值”数据，您将学会如何估计发生罕见灾难性事件的概率，这是运营风险管理中的一项核心技能。", "problem": "给定一个来自某大型在线零售商的操作风险管理场景。在销售高峰活动期间，网站延迟尖峰可能引发连锁故障，从而构成灾难性中断。极值理论 (EVT) 假设，在极限情况下，超过一个足够高阈值的超出量可以很好地用广义帕累托分布 (GPD) 来建模。您的任务是编写一个完整的程序，利用此原理从合成的延迟数据中估计尾指数（GPD 形状参数），并在假设请求独立的情况下，计算在一次有限事件中至少发生一次灾难性故障的概率。\n\n基本原理：\n- 在超阈值峰值 (Peak-Over-Threshold) 框架下，对于一个足够高的阈值 $u$，超过 $u$ 的超出量的分布作为极限定律收敛于广义帕累托分布 (GPD)。\n- 尾指数即 GPD 的形状参数，通常用 $\\xi$ 表示。\n- 在独立性假设下，稀有事件定律意味着如果单次请求的灾难性故障概率为 $p$，那么在 $N$ 次独立请求中至少发生一次灾难性故障的概率为 $1-(1-p)^N$。\n\n您的程序必须对每个测试用例执行以下操作：\n1. 使用一个双组分混合模型，生成一个大小为 $n$ 的网站延迟观测值（单位：毫秒）的合成数据集：\n   - 以概率 $p_{\\text{tail}}$，通过变换 $X_{\\text{tail}} = x_m \\cdot (1 + P)$ 从一个最小值为 $x_m$ 且形状为 $\\alpha$ 的帕累托尾部进行抽样，其中 $P$ 服从形状为 $\\alpha$ 且支撑集为 $(0,\\infty)$ 的标准帕累托分布。\n   - 以概率 $1-p_{\\text{tail}}$，从一个对数位置参数为 $\\mu$、对数尺度参数为 $\\sigma$ 的对数正态分布中抽样，得到 $X_{\\text{base}} \\sim \\text{Lognormal}(\\mu,\\sigma)$，其支撑集为 $(0,\\infty)$。\n   - 将抽样结果合并：有 $p_{\\text{tail}}$ 的概率 $X = X_{\\text{tail}}$，有 $1-p_{\\text{tail}}$ 的概率 $X = X_{\\text{base}}$。\n2. 选择一个高阈值 $u$ 作为样本在水平 $q_u$ 处的经验分位数。\n3. 对于所有满足 $X > u$ 的观测值，构造超出量 $Y = X - u$，并使用最大似然法估计这些超出量的 GPD 参数（形状 $\\xi$ 和尺度 $\\beta$），同时强制 GPD 的位置参数为 $0$。\n4. 将超过 $u$ 的尾部概率估计为 $p_u = k/n$，其中 $k$ 是超出量的数量。\n5. 对于灾难性延迟阈值 $z$（其中 $z > u$），通过 GPD 尾部近似与经验超出率相结合来近似延迟超过 $z$ 的概率。使用 $p_z \\approx p_u$ 乘以超过 $u$ 的条件尾部概率，并通过其连续极限处理 $\\xi = 0$ 的特殊情况。\n6. 使用独立性假设，计算在一个包含 $N$ 次独立请求的事件中，至少发生一次灾难性故障的概率。\n7. 将此最终概率以浮点数形式报告，并四舍五入到六位小数。\n\n不涉及角度单位。延迟输入数据的单位是毫秒，但要求的输出是概率，因此无单位。您必须用小数表示最终的概率结果。\n\n测试套件：\n为以下三组参数集提供结果。对于每种情况，请应用给定的确切值。\n\n- 案例 A:\n  - 随机种子 (Seed) $= 202311$\n  - $n = 50000$\n  - $p_{\\text{tail}} = 0.15$\n  - 帕累托形状 (Pareto shape) $\\alpha = 2.0$\n  - 帕累托最小值 (Pareto minimum) $x_m = 150$\n  - 对数正态 (Lognormal) $\\mu = 3.7$\n  - 对数正态 (Lognormal) $\\sigma = 0.35$\n  - 阈值分位数 (Threshold quantile) $q_u = 0.95$\n  - 灾难性阈值 (Catastrophic threshold) $z = 1000$\n  - 事件大小 (Event size) $N = 200000$\n- 案例 B:\n  - 随机种子 (Seed) $= 7$\n  - $n = 80000$\n  - $p_{\\text{tail}} = 0.05$\n  - 帕累托形状 (Pareto shape) $\\alpha = 1.4$\n  - 帕累托最小值 (Pareto minimum) $x_m = 200$\n  - 对数正态 (Lognormal) $\\mu = 3.5$\n  - 对数正态 (Lognormal) $\\sigma = 0.5$\n  - 阈值分位数 (Threshold quantile) $q_u = 0.97$\n  - 灾难性阈值 (Catastrophic threshold) $z = 1500$\n  - 事件大小 (Event size) $N = 1000000$\n- 案例 C:\n  - 随机种子 (Seed) $= 4242$\n  - $n = 60000$\n  - $p_{\\text{tail}} = 0.10$\n  - 帕累托形状 (Pareto shape) $\\alpha = 3.5$\n  - 帕累托最小值 (Pareto minimum) $x_m = 120$\n  - 对数正态 (Lognormal) $\\mu = 3.6$\n  - 对数正态 (Lognormal) $\\sigma = 0.4$\n  - 阈值分位数 (Threshold quantile) $q_u = 0.90$\n  - 灾难性阈值 (Catastrophic threshold) $z = 800$\n  - 事件大小 (Event size) $N = 100000$\n\n最终输出格式：\n- 您的程序应生成一行输出，其中包含三个案例的概率，形式为一个用方括号括起来的逗号分隔列表，每个概率都四舍五入到六位小数。例如，格式必须与 $[r_1,r_2,r_3]$ 完全一样，其中每个 $r_i$ 是一个小数点后有六位数字的小数。", "solution": "问题陈述被认为是有效的。它提出了一个基于极值理论的、在定量风险管理领域中的适定且有科学依据的问题。唯一且可验证的解所需的所有必要组件均已提供。我们着手进行解的推导和实现。\n\n核心任务是通过对延迟分布的尾部进行建模，来估计灾难性网站延迟事件的概率。该方法论遵循超阈值峰值 (POT) 框架的原则。\n\n1.  **合成数据生成**\n    延迟数据 $X$ 是从一个大小为 $n$ 的双组分混合模型中合成的。该模型同时捕捉了典型行为和极端事件。\n    -   一个“基础”组分，从对数正态分布 $X_{\\text{base}} \\sim \\text{Lognormal}(\\mu, \\sigma)$ 中抽取，代表了大部分延迟观测值。对数正态分布常用于为具有正偏态的非负量建模。\n    -   一个“尾部”组分，代表极端延迟，从帕累托分布中抽取。问题指定生成方式为 $X_{\\text{tail}} = x_m \\cdot (1 + P)$，其中 $P$ 是一个形状为 $\\alpha$、支撑集在 $(0, \\infty)$ 上的标准帕累托变量。支撑集在 $(0, \\infty)$ 上的标准帕累托分布可被解释为尺度参数 $\\lambda=1$ 的 Lomax 分布。此分布的一个变量 $P$ 可以通过逆变换采样生成，即 $P = U^{-1/\\alpha} - 1$，其中 $U \\sim \\text{Uniform}(0,1)$。将此代入 $X_{\\text{tail}}$ 的表达式得到 $X_{\\text{tail}} = x_m (1 + (U^{-1/\\alpha} - 1)) = x_m U^{-1/\\alpha}$。这是从最小值为 $x_m$、形状参数为 $\\alpha$ 的 I 型帕累托分布生成变量的公式。这种解释既是标准的也是自洽的。\n    每个样本以概率 $p_{\\text{tail}}$ 从尾部组分中抽取，以概率 $1 - p_{\\text{tail}}$ 从基础组分中抽取。\n\n2.  **阈值选择与超出量**\n    POT 方法需要定义一个高阈值 $u$ 以将极端事件与数据主体分离。我们选择 $u$ 作为合成数据集在高概率水平 $q_u$ 处的经验分位数。超过此阈值的观测值 $X_i$ 产生超出量，定义为 $Y_i = X_i - u$。\n\n3.  **广义帕累托分布 (GPD) 拟合**\n    根据 Pickands–Balkema–de Haan 定理，对于一个足够高的阈值 $u$，超出量 $Y = X - u$ 的分布收敛于广义帕累托分布 (GPD)。GPD 的累积分布函数 (CDF) 由下式给出：\n    $$ G_{\\xi, \\beta}(y) = \\begin{cases} 1 - \\left(1 + \\frac{\\xi y}{\\beta}\\right)^{-1/\\xi} & \\text{if } \\xi \\neq 0 \\\\ 1 - \\exp(-y/\\beta) & \\text{if } \\xi = 0 \\end{cases} $$\n    对于 $y > 0$。参数是形状 $\\xi$（尾指数）和尺度 $\\beta > 0$。根据超出量的定义，位置参数固定为 $0$。\n    参数 $(\\xi, \\beta)$ 通过最大化观测到的超出量的 GPD 对数似然函数来估计。这是一个数值优化问题，可以使用成熟的库函数（例如 `scipy.stats.genpareto.fit`）可靠地解决，该函数实现了最大似然估计 (MLE)。\n\n4.  **极端事件概率估计**\n    单次延迟 $X$ 超过灾难性阈值 $z$（其中 $z > u$）的概率记为 $p_z = P(X > z)$。使用全概率定律，我们将其分解为：\n    $$ p_z = P(X > z | X > u) \\cdot P(X > u) $$\n    -   项 $P(X > u)$ 根据数据进行经验估计。设在总共 $n$ 个观测值中，有 $k$ 个观测值超过 $u$。那么，$P(X > u) \\approx p_u = k/n$。\n    -   条件概率 $P(X > z | X > u)$ 是指超出量 $Y = X-u$ 大于 $z-u$ 的概率。该概率由拟合的 GPD 的生存函数 $S_{\\text{GPD}}(y) = 1 - G_{\\text{GPD}}(y)$ 在 $y = z-u$ 处的值给出。\n    $$ P(X > z | X > u) = S_{\\text{GPD}}(z-u) = \\left(1 + \\frac{\\hat{\\xi} (z-u)}{\\hat{\\beta}}\\right)^{-1/\\hat{\\xi}} $$\n    其中 $\\hat{\\xi}$ 和 $\\hat{\\beta}$ 是 GPD 参数的最大似然估计值。$\\xi=0$ 的情况通过其连续极限处理，得到指数生存函数。\n    将这些结合起来，得到 $p_z$ 的最终估计值：\n    $$ p_z \\approx \\frac{k}{n} \\left(1 + \\frac{\\hat{\\xi} (z-u)}{\\hat{\\beta}}\\right)^{-1/\\hat{\\xi}} $$\n\n5.  **聚合风险概率**\n    最终关注的量是在一个包含 $N$ 次独立请求的事件中，至少发生一次灾难性故障的概率。如果单次故障的概率为 $p_z$，则在 $N$ 次试验中没有发生故障的概率为 $(1 - p_z)^N$。因此，至少发生一次故障的概率为：\n    $$ P(\\text{at least one}) = 1 - (1 - p_z)^N $$\n    对于较小的 $p_z$，直接计算此表达式可能导致数值精度损失。通过使用对数和指数减一函数可以实现更稳定的计算：$P(\\text{at least one}) = -\\text{expm1}(N \\cdot \\text{log1p}(-p_z))$。这样可以避免灾难性抵消并保持精度。根据要求，最终结果四舍五入到六位小数。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import genpareto\n\ndef run_case(seed, n, p_tail, alpha, xm, mu, sigma, q_u, z, N):\n    \"\"\"\n    Solves a single test case for catastrophic failure probability estimation.\n    \"\"\"\n    # Step 1: Generate synthetic dataset from a two-component mixture model.\n    rng = np.random.default_rng(seed)\n    \n    # Determine which samples come from the tail vs. the base distribution.\n    is_tail = rng.random(size=n) < p_tail\n    n_tail = np.sum(is_tail)\n    n_base = n - n_tail\n\n    # Generate Pareto tail data using inverse transform sampling.\n    # The generation rule X_tail = xm * (1 + P) where P is standard Pareto on (0,inf)\n    # simplifies to sampling from a Pareto Type I distribution with minimum xm.\n    uniform_samples = rng.random(size=n_tail)\n    data_tail = xm / (uniform_samples**(1/alpha))\n\n    # Generate Lognormal base data.\n    data_base = rng.lognormal(mean=mu, sigma=sigma, size=n_base)\n\n    # Combine into a single dataset.\n    data = np.empty(n, dtype=float)\n    data[is_tail] = data_tail\n    data[~is_tail] = data_base\n\n    # Step 2: Choose a high threshold 'u' as an empirical quantile.\n    u = np.quantile(data, q_u)\n\n    # Step 3: Form exceedances and fit the Generalized Pareto Distribution (GPD).\n    exceedances = data[data > u] - u\n    \n    if len(exceedances) == 0:\n        # If there are no exceedances, the probability of an even more extreme event is zero.\n        return 0.0\n\n    # Use scipy's robust Maximum Likelihood Estimation for GPD parameters (xi, beta).\n    # 'floc=0' enforces the location parameter to be 0, as per the definition of exceedances.\n    # The fit returns (shape, location, scale) which correspond to (xi, 0, beta).\n    xi, _, beta = genpareto.fit(exceedances, floc=0)\n\n    # Step 4: Estimate the empirical probability of exceeding the threshold u.\n    k = len(exceedances)\n    p_u = k / n\n\n    # Step 5: Approximate the probability of a single latency exceeding z.\n    # p_z = P(X > z) = P(X > u) * P(X > z | X > u)\n    # The conditional probability is calculated using the GPD survival function.\n    # The problem statement ensures z > u, so (z - u) > 0.\n    y_z = z - u\n    prob_cond_exceed_z = genpareto.sf(y_z, c=xi, scale=beta, loc=0)\n    p_z = p_u * prob_cond_exceed_z\n\n    # Step 6: Compute the probability of at least one catastrophic failure in N requests.\n    # The calculation uses numerically stable functions to avoid precision loss.\n    # P(at least one) = 1 - (1 - p_z)^N = -expm1(N * log1p(-p_z))\n    if p_z >= 1.0:\n        # If a single event is guaranteed to be catastrophic, so is any sequence of events.\n        prob_final = 1.0\n    elif p_z <= 0.0:\n        prob_final = 0.0\n    else:\n        prob_final = -np.expm1(N * np.log1p(-p_z))\n\n    return prob_final\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A\n        (202311, 50000, 0.15, 2.0, 150, 3.7, 0.35, 0.95, 1000, 200000),\n        # Case B\n        (7, 80000, 0.05, 1.4, 200, 3.5, 0.5, 0.97, 1500, 1000000),\n        # Case C\n        (4242, 60000, 0.10, 3.5, 120, 3.6, 0.4, 0.90, 800, 100000),\n    ]\n\n    results = []\n    for case in test_cases:\n        # Execute the main logic for one case.\n        final_probability = run_case(*case)\n        # Format the result to six decimal places.\n        results.append(f\"{final_probability:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2391805"}, {"introduction": "金融市场的风险并非一成不变，它会随着重大经济事件（如中央银行的政策宣告）而发生变化。本项高级练习将带您超越静态风险建模，进入动态分析领域。您将学习如何运用极值理论来检验金融时间序列的尾部行为是否存在“结构性突变”。[@problem_id:2391785] 通过比较模拟的央行公告前后高频收益率的尾指数 $\\xi$，并使用沃尔德检验 (Wald test) 进行统计推断，您将掌握一种识别和验证风险状况变化的关键技术。", "problem": "要求您使用极值理论（Extreme Value Theory, EVT）来形式化并检验一次主要央行公告前后，高频货币收益率尾部行为的变化。您将在超阈值峰值（Peaks-Over-Threshold, POT）框架下进行操作，该框架基于 Pickands–Balkema–de Haan 定理。该定理指出，对于一个足够高的阈值，超阈值部分的分布会收敛于一个广义帕累托分布（Generalized Pareto Distribution, GPD）。您必须从第一性原理出发，实现一个完整的程序，对公告前后的绝对收益率上尾进行建模，估计尾部指数，并进行统计检验以判断尾部指数是否发生变化。\n\n从以下基本原理开始：\n- 高阈值上的超阈值分布的定义，以及作为使用广义帕累托分布（GPD）对超阈值部分进行建模理论基础的 Pickands–Balkema–de Haan 定理。\n- 使用最大似然估计（Maximum Likelihood Estimation, MLE）来估计模型参数的原理。\n- 使用基于观测Fisher信息（MLE处的对数似然函数负值的Hessian矩阵）得到的渐近协方差，对两个样本的参数相等性进行检验的Wald检验原理。\n\n您的任务：\n- 考虑一个基于对称学生t分布的高频收益率的程式化生成器，通过自由度来生成具有可控尾部指数的重尾收益率。假设公告前和公告后两个时段可能具有不同的自由度和尺度参数。\n- 对于每个时段，将原始收益率转换为绝对收益率，在指定的分位数处选择一个较高的经验阈值，并收集超阈值部分。\n- 通过最大似然估计将GPD拟合到超阈值部分。使用观测Fisher信息（MLE处的对数似然函数负值的Hessian矩阵）为尾部指数估计量生成一个渐近方差估计。\n- 在指定的显著性水平下，构建一个Wald检验，其原假设为公告前后的尾部指数相等。决定是否拒绝原假设。\n- 为GPD实现仔细的参数约束处理，以确保似然计算的有效性。\n\n需要遵守的数学对象和约束：\n- 绝对收益率表示为 $x \\in \\mathbb{R}_{+}$。\n- 对于选定的阈值 $u$，超阈值部分为 $y = x - u$（当 $x > u$时）。\n- 广义帕累托分布（GPD）具有形状（尾部指数）参数 $\\xi$ 和尺度参数 $\\beta$，其中 $\\beta &gt; 0$，其支撑集由 $1 + \\xi y / \\beta &gt; 0$ 定义。\n- $(\\xi,\\beta)$ 的最大似然估计（MLE）在优化过程中必须满足GPD的支撑集约束。\n- 使用在MLE处评估的对数似然函数负值的Hessian矩阵计算出的观测Fisher信息矩阵，来近似尾部指数估计量 $\\widehat{\\xi}$ 的方差。\n- 对于 $H_{0}: \\xi_{\\text{pre}} = \\xi_{\\text{post}}$ 与 $H_{1}: \\xi_{\\text{pre}} \\neq \\xi_{\\text{post}}$ 的Wald检验，使用统计量\n$$\nW = \\frac{\\left(\\widehat{\\xi}_{\\text{pre}} - \\widehat{\\xi}_{\\text{post}}\\right)^{2}}{\\operatorname{Var}(\\widehat{\\xi}_{\\text{pre}}) + \\operatorname{Var}(\\widehat{\\xi}_{\\text{post}})},\n$$\n在 $H_{0}$ 下，该统计量渐近服从自由度为 $1$ 的 $\\chi^{2}$ 分布。当 $W$ 处的 $\\chi^{2}$ 分布的上尾概率严格小于给定的显著性水平 $\\alpha$ 时，拒绝 $H_{0}$。\n\n为了普适性和可测试性的数据生成：\n- 对于每个时段，从一个带尺度的对称学生t分布（记为 $t_{\\nu}$，自由度为 $\\nu$，尺度为 $s$）中生成独立同分布的收益率，然后乘以 $s$。使用模拟收益率的绝对值来定义 $x$。\n- 不涉及物理单位。纯粹使用无量纲的数值数据。\n\n实现要求：\n- 对于每种情况，使用给定的伪随机种子以确保可复现性。\n- 对于每个时段，计算经验阈值 $u$ 作为 $x$ 在水平 $q \\in (0,1)$ 处的样本分位数。\n- 对超阈值部分 $y = x - u$ 进行MLE，以估计 $(\\xi,\\beta)$。\n- 通过在MLE处的对数似然函数负值的Hessian矩阵计算观测Fisher信息，并使用其逆矩阵来近似 $\\widehat{\\xi}$ 的方差。\n- 在水平 $\\alpha$ 下进行Wald检验，并返回一个布尔决策。\n\n测试套件：\n实现您的程序以运行以下五个测试用例。每个用例定义了公告前后数据生成过程和测试设置。对于每个用例，输出一个布尔值，指示您是否在规定的水平 $\\alpha$ 下拒绝 $H_{0}: \\xi_{\\text{pre}} = \\xi_{\\text{post}}$。\n\n- 用例A（无变化，中等尾部）：seed $= 12345$, $N_{\\text{pre}} = 10000$, $N_{\\text{post}} = 10000$, $\\nu_{\\text{pre}} = 8$, $\\nu_{\\text{post}} = 8$, $s_{\\text{pre}} = 1.0$, $s_{\\text{post}} = 1.0$, $q = 0.975$, $\\alpha = 0.05$。\n- 用例B（明显变化，公告后尾部更重）：seed $= 202405$, $N_{\\text{pre}} = 10000$, $N_{\\text{post}} = 10000$, $\\nu_{\\text{pre}} = 8$, $\\nu_{\\text{post}} = 3$, $s_{\\text{pre}} = 1.0$, $s_{\\text{post}} = 1.0$, $q = 0.975$, $\\alpha = 0.01$。\n- 用例C（接近薄尾，无变化）：seed $= 424242$, $N_{\\text{pre}} = 10000$, $N_{\\text{post}} = 10000$, $\\nu_{\\text{pre}} = 1000$, $\\nu_{\\text{post}} = 1000$, $s_{\\text{pre}} = 1.0$, $s_{\\text{post}} = 1.0$, $q = 0.990$, $\\alpha = 0.05$。\n- 用例D（超阈值样本少，尾部非常相似）：seed $= 777777$, $N_{\\text{pre}} = 5000$, $N_{\\text{post}} = 5000$, $\\nu_{\\text{pre}} = 5.0$, $\\nu_{\\text{post}} = 5.1$, $s_{\\text{pre}} = 1.0$, $s_{\\text{post}} = 1.0$, $q = 0.990$, $\\alpha = 0.05$。\n- 用例E（仅尺度变化，无尾部指数变化）：seed $= 314159$, $N_{\\text{pre}} = 10000$, $N_{\\text{post}} = 10000$, $\\nu_{\\text{pre}} = 4$, $\\nu_{\\text{post}} = 4$, $s_{\\text{pre}} = 1.0$, $s_{\\text{post}} = 2.0$, $q = 0.975$, $\\alpha = 0.05$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含五个测试用例的结果，格式为方括号内以逗号分隔的列表，例如，“[True,False,True,False,True]”。每个条目都是一个布尔值，与上面列出的用例按相同顺序对应。", "solution": "所述问题已经过验证，并被认定为有效。该问题在科学上是合理的，它基于极值理论、最大似然估计和统计假设检验等既定原则。问题陈述清晰，为获得唯一、可验证的解指定了所有必要的数据和条件。其语言客观、正式。因此，我们可以着手解决。\n\n该问题要求对金融收益序列尾部行为的结构性断点进行统计检验。我们将使用超阈值峰值（POT）框架，其理论依据是 Pickands–Balkema–de Haan 定理。该定理指出，对于一个随机变量 $X$，当阈值 $u$ 足够高时，条件 $X > u$ 下的超阈值 $Y = X-u$ 的分布，可以用广义帕累托分布（GPD）来近似。\n\nGPD的概率密度函数（PDF）由下式给出：\n$$\nf(y; \\xi, \\beta) = \n\\begin{cases} \n\\frac{1}{\\beta} \\left(1 + \\frac{\\xi y}{\\beta}\\right)^{-(1/\\xi + 1)} & \\text{for } \\xi \\neq 0 \\\\\n\\frac{1}{\\beta} \\exp\\left(-\\frac{y}{\\beta}\\right) & \\text{for } \\xi = 0 \n\\end{cases}\n$$\n参数包括形状参数（或尾部指数）$\\xi \\in \\mathbb{R}$ 和尺度参数 $\\beta > 0$。当 $\\xi \\geq 0$ 时，分布的支撑集为 $y \\geq 0$；当 $\\xi < 0$ 时，支撑集为 $0 \\leq y \\leq -\\beta/\\xi$。参数 $\\xi$ 控制尾部的厚重程度：$\\xi > 0$ 对应于重尾（类帕累托分布），$\\xi = 0$ 对应于中等尾部（类指数分布），而 $\\xi < 0$ 对应于有界的轻尾。对于金融收益率，我们通常预期 $\\xi > 0$。对于具有 $\\nu$ 个自由度的学生t分布，其理论尾部指数为 $\\xi = 1/\\nu$。\n\n我们的第一步是为公告前和公告后的收益序列估计参数 $(\\xi, \\beta)$。我们使用最大似然估计（MLE）方法。对于一组 $k$ 个独立的超阈值样本 $y_1, y_2, \\ldots, y_k$，其对数似然函数为 $\\ell(\\xi, \\beta) = \\sum_{i=1}^k \\log f(y_i; \\xi, \\beta)$。MLE估计值 $(\\widehat{\\xi}, \\widehat{\\beta})$ 是使该函数最大化的 $(\\xi, \\beta)$ 值。这在数值上等同于最小化负对数似然函数：\n$$\n-\\ell(\\xi, \\beta) = \n\\begin{cases}\nk\\log\\beta + \\left(\\frac{1}{\\xi} + 1\\right)\\sum_{i=1}^k \\log\\left(1 + \\frac{\\xi y_i}{\\beta}\\right) & \\text{for } \\xi \\neq 0 \\\\\nk\\log\\beta + \\frac{1}{\\beta}\\sum_{i=1}^k y_i & \\text{for } \\xi = 0\n\\end{cases}\n$$\n优化过程必须遵守参数约束 $\\beta > 0$ 和对所有 $i$ 均成立的 $1 + \\xi y_i/\\beta > 0$。这些约束在提供给数值优化器的目标函数内部强制执行。如果在优化步骤中参数违反了这些条件，函数将返回一个代表无穷大的值，以引导优化器避开无效区域。\n\n第二步是量化我们对尾部指数估计值 $\\widehat{\\xi}$ 的不确定性。在标准正则性条件下，MLE $\\widehat{\\theta} = (\\widehat{\\xi}, \\widehat{\\beta})$ 渐近服从正态分布，其均值等于真实参数值 $\\theta$，协方差矩阵由Fisher信息矩阵的逆 $\\mathcal{I}(\\theta)^{-1}$ 给出。我们用观测到的Fisher信息 $J(\\widehat{\\theta})$ 来近似 $\\mathcal{I}(\\theta)$，它是负对数似然函数在MLE处评估的Hessian矩阵：\n$$\nJ(\\widehat{\\theta}) = -\\left. \\frac{\\partial^2 \\ell(\\theta)}{\\partial \\theta \\partial \\theta^T} \\right|_{\\theta=\\widehat{\\theta}} = \\left. \\nabla^2 (-\\ell(\\theta)) \\right|_{\\theta=\\widehat{\\theta}}\n$$\n该Hessian矩阵使用二阶中心差分公式进行数值计算。渐近协方差矩阵则为 $\\operatorname{Cov}(\\widehat{\\theta}) \\approx J(\\widehat{\\theta})^{-1}$。尾部指数估计量的方差 $\\operatorname{Var}(\\widehat{\\xi})$ 是这个逆矩阵的第一个对角线元素。\n\n第三步也是最后一步，是针对原假设 $H_0: \\xi_{\\text{pre}} = \\xi_{\\text{post}}$ 和备择假设 $H_1: \\xi_{\\text{pre}} \\neq \\xi_{\\text{post}}$ 进行Wald检验。由于公告前后的样本是独立的，它们各自的MLE也是独立的。估计量之差的方差是它们方差的和：$\\operatorname{Var}(\\widehat{\\xi}_{\\text{pre}} - \\widehat{\\xi}_{\\text{post}}) = \\operatorname{Var}(\\widehat{\\xi}_{\\text{pre}}) + \\operatorname{Var}(\\widehat{\\xi}_{\\text{post}})$。Wald检验统计量为：\n$$\nW = \\frac{(\\widehat{\\xi}_{\\text{pre}} - \\widehat{\\xi}_{\\text{post}})^2}{\\operatorname{Var}(\\widehat{\\xi}_{\\text{pre}}) + \\operatorname{Var}(\\widehat{\\xi}_{\\text{post}})}\n$$\n在原假设下，$W$ 渐近服从自由度为 $1$ 的卡方分布，即 $W \\\n\\xrightarrow{d} \\chi^2(1)$。我们计算p值，即在 $H_0$ 下观测到比 $W$ 更极端或同样极端的检验统计量的概率。这由 $P(\\chi^2(1) \\geq W)$ 给出。如果p值严格小于显著性水平 $\\alpha$，我们则拒绝原假设。\n\n对于每个测试用例，完整的算法流程如下：\n1.  使用提供的随机种子，为公告前后时期从指定的带尺度的学生t分布生成绝对收益率。\n2.  对每个时期：\n    a. 将阈值 $u$ 确定为在指定水平 $q$ 下绝对收益率的经验分位数。\n    b. 识别所有超阈值 $y = x - u$（对于数据点 $x > u$）。\n    c. 执行MLE以获得估计值 $(\\widehat{\\xi}, \\widehat{\\beta})$。\n    d. 在MLE处数值计算负对数似然函数的Hessian矩阵。\n    e. 对Hessian矩阵求逆以找到协方差矩阵，并提取尾部指数估计量的方差 $\\operatorname{Var}(\\widehat{\\xi})$。\n3.  使用估计值 $\\widehat{\\xi}_{\\text{pre}}$、$\\widehat{\\xi}_{\\text{post}}$ 及其方差来计算Wald统计量 $W$。\n4.  从 $\\chi^2(1)$ 分布计算p值。\n5.  如果p值小于显著性水平 $\\alpha$，则返回 `True`，表示拒绝 $H_0$；否则返回 `False`。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import optimize\nfrom scipy.stats import t as student_t\nfrom scipy.stats import chi2\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for changes in tail behavior.\n    \"\"\"\n\n    def _gpd_neg_log_likelihood(params, y, epsilon=1e-8):\n        \"\"\"\n        Computes the negative log-likelihood for the Generalized Pareto Distribution.\n        Handles parameter constraints by returning infinity.\n        \"\"\"\n        xi, beta = params\n        k = len(y)\n\n        # Constraint: beta > 0\n        if beta <= 0:\n            return np.inf\n\n        # Constraint: 1 + xi * y / beta > 0\n        try:\n            with np.errstate(divide='ignore', invalid='ignore'):\n                term = 1 + xi * y / beta\n            if np.any(term <= 0):\n                return np.inf\n        except (FloatingPointError, ValueError):\n            return np.inf\n\n        # Case: xi is close to 0 (Exponential distribution)\n        if abs(xi) < epsilon:\n            return k * np.log(beta) + np.sum(y) / beta\n\n        # Case: xi is not 0\n        log_term = np.log(term)\n        return k * np.log(beta) + (1 / xi + 1) * np.sum(log_term)\n\n    def _calculate_hessian(func, params, args, h=1e-5):\n        \"\"\"\n        Numerically calculates the Hessian matrix of a function using central differences.\n        \"\"\"\n        n_params = len(params)\n        hessian = np.zeros((n_params, n_params))\n        \n        for i in range(n_params):\n            for j in range(i, n_params):\n                # Diagonal elements\n                if i == j:\n                    p_plus = np.copy(params)\n                    p_plus[i] += h\n                    p_minus = np.copy(params)\n                    p_minus[i] -= h\n                    f_0 = func(params, *args)\n                    f_plus = func(p_plus, *args)\n                    f_minus = func(p_minus, *args)\n                    hessian[i, i] = (f_plus - 2 * f_0 + f_minus) / (h * h)\n                # Off-diagonal elements\n                else:\n                    p_pp = np.copy(params); p_pp[i] += h; p_pp[j] += h\n                    p_pm = np.copy(params); p_pm[i] += h; p_pm[j] -= h\n                    p_mp = np.copy(params); p_mp[i] -= h; p_mp[j] += h\n                    p_mm = np.copy(params); p_mm[i] -= h; p_mm[j] -= h\n                    \n                    f_pp = func(p_pp, *args)\n                    f_pm = func(p_pm, *args)\n                    f_mp = func(p_mp, *args)\n                    f_mm = func(p_mm, *args)\n\n                    val = (f_pp - f_pm - f_mp + f_mm) / (4 * h * h)\n                    hessian[i, j] = val\n                    hessian[j, i] = val\n        return hessian\n\n    def analyze_segment(returns, q):\n        \"\"\"\n        Analyzes a single segment of returns to estimate GPD parameters and tail index variance.\n        \"\"\"\n        u = np.quantile(returns, q)\n        exceedances = returns[returns > u] - u\n\n        if len(exceedances) == 0:\n            return np.nan, np.nan\n\n        # Initial guess for optimization\n        beta_init = np.mean(exceedances)\n        xi_init = 0.1  # A small positive value, common for financial data.\n        initial_params = [xi_init, beta_init]\n\n        # Perform MLE\n        res = optimize.minimize(\n            _gpd_neg_log_likelihood,\n            initial_params,\n            args=(exceedances,),\n            method='Nelder-Mead',\n            options={'maxiter': 2000, 'adaptive': True}\n        )\n\n        if not res.success:\n            # Fallback to L-BFGS-B if Nelder-Mead fails\n            res = optimize.minimize(\n                _gpd_neg_log_likelihood,\n                initial_params,\n                args=(exceedances,),\n                method='L-BFGS-B',\n                bounds=((-0.5, 1.5), (1e-6, None))\n            )\n            if not res.success:\n                return np.nan, np.nan\n        \n        mle_params = res.x\n        xi_hat, _ = mle_params\n\n        # Compute observed Fisher information (Hessian of neg-log-likelihood)\n        try:\n            hessian = _calculate_hessian(_gpd_neg_log_likelihood, mle_params, args=(exceedances,))\n            cov_matrix = np.linalg.inv(hessian)\n            var_xi = cov_matrix[0, 0]\n            # Ensure variance is non-negative\n            if var_xi < 0:\n                return xi_hat, np.nan\n        except (np.linalg.LinAlgError, ValueError):\n            return xi_hat, np.nan\n\n        return xi_hat, var_xi\n\n    def run_one_case(case_params):\n        \"\"\"\n        Runs one full test case for the Wald test.\n        \"\"\"\n        seed, N_pre, N_post, nu_pre, nu_post, s_pre, s_post, q, alpha = case_params\n        rng = np.random.default_rng(seed)\n\n        # Generate data\n        returns_pre = np.abs(student_t.rvs(df=nu_pre, scale=s_pre, size=N_pre, random_state=rng))\n        returns_post = np.abs(student_t.rvs(df=nu_post, scale=s_post, size=N_post, random_state=rng))\n\n        # Analyze each segment\n        xi_pre, var_xi_pre = analyze_segment(returns_pre, q)\n        xi_post, var_xi_post = analyze_segment(returns_post, q)\n        \n        if np.isnan(xi_pre) or np.isnan(var_xi_pre) or np.isnan(xi_post) or np.isnan(var_xi_post):\n            return False # Cannot reject if estimation fails\n\n        # Wald test\n        numerator = (xi_pre - xi_post)**2\n        denominator = var_xi_pre + var_xi_post\n\n        if denominator <= 0:\n            return False # Cannot perform test if total variance is not positive\n\n        W = numerator / denominator\n        p_value = chi2.sf(W, df=1)\n\n        return p_value < alpha\n\n    test_cases = [\n        # (seed, N_pre, N_post, nu_pre, nu_post, s_pre, s_post, q, alpha)\n        (12345, 10000, 10000, 8, 8, 1.0, 1.0, 0.975, 0.05),\n        (202405, 10000, 10000, 8, 3, 1.0, 1.0, 0.975, 0.01),\n        (424242, 10000, 10000, 1000, 1000, 1.0, 1.0, 0.990, 0.05),\n        (777777, 5000, 5000, 5.0, 5.1, 1.0, 1.0, 0.990, 0.05),\n        (314159, 10000, 10000, 4, 4, 1.0, 2.0, 0.975, 0.05),\n    ]\n\n    results = []\n    for case in test_cases:\n        decision = run_one_case(case)\n        results.append(decision)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2391785"}]}