{"hands_on_practices": [{"introduction": "本练习旨在解决应用POT方法时一个核心的实践挑战：阈值$u$的选择。选择过低的阈值会引入偏差，因为广义帕累托分布（GPD）的近似可能不成立；而选择过高的阈值会减少超额数量，导致参数估计的方差过高。这个练习 [@problem_id:2418694] 提供了一个亲身实践的机会，来量化估计的尾部指数$\\xi$对不同阈值选择的敏感性，帮助您建立对这种偏差-方差权衡的关键直觉。", "problem": "考虑一个合成的每日对数回报率序列，该序列旨在近似标准普尔500指数 (S&P 500) 每日回报率的分布特征，以用于尾部风险分析。设每日对数回报率表示为 $R_t$（$t = 1, \\dots, n$），并定义 $R_t = \\mu + \\sigma \\cdot T_\\nu$，其中 $T_\\nu$ 是一个自由度为 $\\nu$、位置为 $0$、单位尺度的学生t分布随机变量。使用 $n = 6000$、$\\mu = 0$、$\\sigma = 0.01$、$\\nu = 5$ 以及固定的伪随机数生成器种子 $s = 20240517$ 来确保可复现性。定义损失为 $L_t = -R_t$。\n\n对于任意阈值 $u$，将所有满足 $L_i > u$ 的索引 $i$ 的超出量定义为 $Y_i = L_i - u$。在超出阈值 (POT) 模型下，假设超出量 $Y_i$ 服从一个尾部指数为 $\\xi$、尺度参数为 $\\beta$ 的广义帕累托分布 (GPD)。\n\n您的任务是通过计算在下述测试套件中的每个阈值下，从超过该阈值 $u$ 的超出量中获得的 $\\xi$ 的估计值，来量化估计出的尾部指数 $\\xi$ 对阈值 $u$ 选择的敏感性。对于每个阈值，将 $u$ 设置为给定分位数水平 $q$ 下损失 $L_t$ 的经验 $q$ 分位数。\n\n测试套件（用于阈值的分位数水平）：$q \\in \\{0.80, 0.90, 0.95, 0.975, 0.99, 0.995, 0.999\\}$。\n\n对于测试套件中的每个 $q$，计算对应的 $\\xi$ 的估计值（以实数形式）。最终所需的输出是单行文本，其中包含按指定顺序排列的各阈值的结果，四舍五入到 $6$ 位小数，并以逗号分隔的列表形式置于方括号内。例如，包含三个结果的输出应形如 $[x_1,x_2,x_3]$，其中每个 $x_j$ 是一个四舍五入到 $6$ 位小数的十进制数。\n\n您的程序必须生成单行输出，其中包含格式和顺序完全符合要求的估计值，不得包含任何额外文本。不涉及物理单位。不涉及角度。不涉及百分比。答案必须是实值浮点数。", "solution": "提交分析的问题陈述被认为是有效的。它提出了一个在计算金融学领域中定义明确、有科学依据的问题，特别是关于应用极值理论 (EVT) 中的超出阈值 (POT) 方法。所有参数和条件都已明确指定，从而可以得到唯一且可复现的解。该方法论基于公认的统计学原理。\n\n问题的核心在于应用 Pickands–Balkema–de Haan 定理。该定理假设，对于具有重尾的广泛分布类别，超过一个足够高阈值的超出量的条件分布会收敛于一个广义帕累托分布 (GPD)。所指定的数据模型 $R_t = \\mu + \\sigma \\cdot T_\\nu$（其中 $T_\\nu$ 是一个自由度为 $\\nu$ 的学生t分布随机变量）是此类重尾过程的一个典型例子。对于自由度为 $\\nu$ 的学生t分布，理论上的 GPD 尾部指数为 $\\xi = 1/\\nu$。在本问题中，由于 $\\nu=5$，尾部指数的预期理论值为 $\\xi = 1/5 = 0.2$。本练习旨在从一个有限样本中估计该参数，并观察其对阈值选择的敏感性。\n\n计算流程如下：\n\n1.  **数据生成**：创建一个合成数据集来模拟金融损失。从一个自由度为 $\\nu=5$、位置为 $0$、单位尺度的学生t分布中生成一个包含 $n=6000$ 个点的样本。这些点记为 $T_t$，并使用给定的参数 $\\mu=0$ 和 $\\sigma=0.01$ 转换为对数回报率 $R_t = \\mu + \\sigma \\cdot T_t$。然后将相应的损失定义为 $L_t = -R_t$。使用固定的种子 $s=20240517$ 确保了所生成数据的绝对可复现性。\n\n2.  **阈值选择**：问题要求分析对阈值 $u$ 的敏感性。为此，基于生成的损失数据 $L_t$ 的经验分位数选择了一系列阈值。对于测试套件 $\\{0.80, 0.90, 0.95, 0.975, 0.99, 0.995, 0.999\\}$ 中的每个分位数水平 $q$，阈值 $u$ 被设置为满足 $P(L_t \\le u) = q$ 的值。\n\n3.  **超出量计算**：对于每个阈值 $u$，都将汇编一个超出量集合。这些值是 $Y_i = L_i - u$，对应于所有严格大于 $u$ 的观测值 $L_i$。这组 $Y_i$ 值代表了将用于拟合 GPD 的数据。\n\n4.  **GPD参数估计**：GPD 的尾部指数 $\\xi$ 是从超出量序列 $\\{Y_i\\}$ 中估计出来的。最标准且最可靠的估计方法是最大似然估计 (MLE)，这里将采用此方法。GPD 由一个形状参数（即尾部指数 $\\xi$）和一个尺度参数 $\\beta$ 来表征。根据 POT 模型，超出量本质上是正数，因此 GPD 的位置参数理论上为 $0$。在拟合过程中强制执行此约束（在 `scipy` 实现中使用 `floc=0`），以提高估计的稳定性和理论正确性。MLE 过程计算能使观测到所收集的超出量数据的概率最大化的 $\\xi$ 值。\n\n从阈值选择到GPD拟合的整个过程，会对测试套件中的每个分位数水平 $q$ 重复进行。得到的估计尾部指数序列 $\\hat{\\xi}(q)$ 展示了阈值选择对尾部风险度量的实际影响。预计随着 $q$ 趋近于 $1$，阈值 $u$ 会增加，GPD 近似会变得更加准确，并且估计的 $\\hat{\\xi}$ 应收敛于理论值 $0.2$。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import t, genpareto\n\ndef solve():\n    \"\"\"\n    Computes the sensitivity of the GPD tail index estimate to the threshold choice\n    for a synthetic financial loss series based on the Peaks-Over-Threshold method.\n    \"\"\"\n    # --- Problem Parameters ---\n    n = 6000\n    mu = 0.0\n    sigma = 0.01\n    nu = 5.0\n    seed = 20240517\n    \n    # --- Test Suite ---\n    # The quantile levels for threshold selection define the test cases.\n    test_cases = [0.80, 0.90, 0.95, 0.975, 0.99, 0.995, 0.999]\n    \n    # --- Data Generation ---\n    # Use a specific random number generator for reproducibility as per problem statement.\n    rng = np.random.default_rng(seed)\n    \n    # Generate random variates from Student's t-distribution with nu degrees of freedom.\n    # T_nu is a standard t-distribution (location=0, scale=1).\n    T_nu = t.rvs(df=nu, size=n, random_state=rng)\n    \n    # Calculate log-returns R_t and losses L_t based on the generated variates.\n    R_t = mu + sigma * T_nu\n    L_t = -R_t\n    \n    # --- Main Logic: POT Analysis for each threshold ---\n    results = []\n    for q in test_cases:\n        # 1. Set the threshold 'u' as the empirical q-quantile of the losses.\n        u = np.quantile(L_t, q)\n        \n        # 2. Identify all losses exceeding the threshold and compute the exceedance values.\n        # Exceedances are defined as Y_i = L_i - u for all L_i > u.\n        exceedances = L_t[L_t > u] - u\n        \n        # 3. Fit a Generalized Pareto Distribution (GPD) to the exceedances.\n        # We use Maximum Likelihood Estimation (MLE), as implemented in scipy.\n        # The POT model implies a location parameter of 0 for exceedances, which we fix\n        # using the 'floc=0' argument for theoretical consistency and numerical stability.\n        # The 'c' shape parameter returned by the fit corresponds to the tail index 'xi'.\n        xi, _, _ = genpareto.fit(exceedances, floc=0)\n        \n        results.append(xi)\n\n    # --- Final Output Formatting ---\n    # The problem requires the results to be rounded to 6 decimal places and\n    # formatted as a comma-separated list within square brackets.\n    formatted_results = [f'{r:.6f}' for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nif __name__ == '__main__':\n    solve()\n```", "id": "2418694"}, {"introduction": "Pickands–Balkema–de Haan定理为在POT框架中使用广义帕累托分布（GPD）提供了理论依据。但在实践中，与其他貌似合理的尾部模型相比，它的表现如何？这个练习 [@problem_id:2418756] 通过使用样本外预测似然来评估它们的性能，将理论上合理的GPD模型与一个常见的替代模型——拉伸指数（或Weibull）分布——进行了直接比较。这种实践强调了模型验证的重要性，并展示了当基础数据表现出金融市场中常见的重尾特性时，GPD在经验上的优越性。", "problem": "考虑使用超阈值峰值法对重大金融损失进行建模。设 $X \\ge 0$ 表示一个非负损失随机变量。给定一个高阈值 $u$，定义超额量为 $Y = X - u \\mid X > u$。您将比较两种尾部模型：\n\n- 针对 $Y$ 的超阈值峰值 (POT) 与广义帕累托分布 (GPD) 相结合：其理论依据是 Pickands–Balkema–de Haan 定理，该定理指出，对于一大类基础分布，随着 $u$ 的增加，条件超额分布会收敛到 GPD。\n\n- 一个简单的用于尾部分布的拉伸指数模型，实现为 $X$ 的威布尔分布，其形状参数为 $\\beta > 0$，尺度参数为 $\\lambda > 0$；在此模型下，$X$ 在给定 $X > u$ 条件下的条件密度为 $f_{\\text{Weibull}}(x;\\beta,\\lambda)/S_{\\text{Weibull}}(u;\\beta,\\lambda)$，其中 $f_{\\text{Weibull}}$ 是威布尔密度函数，$S_{\\text{Weibull}}$ 是威布尔生存函数。\n\n您必须仅使用在指定百分位数 $p \\in (0,1)$ 下从训练样本计算出的阈值 $u$ 之上的超额量，为两种模型实现最大似然估计，然后使用相同的 $u$ 在一个独立的测试样本上评估样本外预测性能。\n\n需要使用的基本事实和定义：\n\n- 用于超额量 $Y \\ge 0$ 的广义帕累托分布 (GPD)，其形状参数为 $\\xi \\in \\mathbb{R}$，尺度参数为 $\\sigma > 0$，密度函数为\n$$\ng(y;\\xi,\\sigma) = \\begin{cases}\n\\dfrac{1}{\\sigma}\\left(1 + \\dfrac{\\xi y}{\\sigma}\\right)^{-(1/\\xi+1)}, & \\xi \\ne 0,\\; 1+\\dfrac{\\xi y}{\\sigma}>0, \\\\[6pt]\n\\dfrac{1}{\\sigma}\\exp\\!\\left(-\\dfrac{y}{\\sigma}\\right), & \\xi = 0,\\; y \\ge 0.\n\\end{cases}\n$$\n\n- $X \\ge 0$ 的威布尔（拉伸指数）分布，其形状参数为 $\\beta > 0$，尺度参数为 $\\lambda > 0$，其密度函数和生存函数为\n$$\nf_{\\text{Weibull}}(x;\\beta,\\lambda) = \\dfrac{\\beta}{\\lambda}\\left(\\dfrac{x}{\\lambda}\\right)^{\\beta-1} \\exp\\!\\left(-\\left(\\dfrac{x}{\\lambda}\\right)^{\\beta}\\right), \\quad\nS_{\\text{Weibull}}(x;\\beta,\\lambda) = \\exp\\!\\left(-\\left(\\dfrac{x}{\\lambda}\\right)^{\\beta}\\right).\n$$\n因此，给定 $X>u$ 时 $X$ 的条件密度为 $f_{\\text{Weibull}}(x;\\beta,\\lambda)/S_{\\text{Weibull}}(u;\\beta,\\lambda)$，适用于 $x>u$。\n\n您将通过逆变换使用确定性数据生成，以避免随机变异性。对于样本大小 $n \\in \\mathbb{N}$，为 $k = 1,2,\\dots,n$ 定义一个确定性网格 $u_k = (k-0.5)/n$。要从累积分布函数为 $F$ 的分布中进行模拟，设置 $x_k = F^{-1}(u_k)$。\n\n需要使用的逆累积分布函数：\n\n- 对于 $\\xi \\ne 0$ 和 $\\sigma > 0$ 的 GPD，\n$$\nF^{-1}(u) = \\dfrac{\\sigma}{\\xi}\\left((1-u)^{-\\xi} - 1\\right), \\quad u \\in (0,1).\n$$\n对于 $\\xi = 0$（指数情况），使用 $F^{-1}(u) = -\\sigma \\ln(1-u)$。\n\n- 对于形状参数 $\\beta>0$ 和尺度参数 $\\lambda>0$ 的威布尔分布，\n$$\nF^{-1}(u) = \\lambda\\left(-\\ln(1-u)\\right)^{1/\\beta}, \\quad u \\in (0,1).\n$$\n\n任务：\n\n- 对于下述每个测试用例：\n    1. 使用逆累积分布函数在确定性网格 $u_k = (k - 0.5)/n$ 上，从指定的数据生成过程 (DGP) 中生成训练样本 $\\{x_k^{\\text{train}}\\}_{k=1}^{n_{\\text{train}}}$ 和测试样本 $\\{x_k^{\\text{test}}\\}_{k=1}^{n_{\\text{test}}}$。\n    2. 将阈值 $u$ 计算为训练样本在百分位数 $p$ 处的经验分位数。如果需要，使用标准的线性插值。\n    3. 构建训练超额集 $\\mathcal{I}_{\\text{train}} = \\{i: x_i^{\\text{train}} > u\\}$，其中超额量为 $y_i^{\\text{train}} = x_i^{\\text{train}} - u$，适用于 $i \\in \\mathcal{I}_{\\text{train}}$。同样地，构建测试超额集 $\\mathcal{I}_{\\text{test}} = \\{j: x_j^{\\text{test}} > u\\}$，其中超额量为 $y_j^{\\text{test}} = x_j^{\\text{test}} - u$，适用于 $j \\in \\mathcal{I}_{\\text{test}}$。\n    4. 仅使用 $\\{y_i^{\\text{train}}\\}_{i \\in \\mathcal{I}_{\\text{train}}}$ 通过最大似然法拟合 GPD 参数 $(\\xi,\\sigma)$。通过在 $X \\mid X>u$ 条件下最大化 $\\{x_i^{\\text{train}}: i \\in \\mathcal{I}_{\\text{train}}\\}$ 的条件似然来拟合威布尔参数 $(\\beta,\\lambda)$，即最大化 $f_{\\text{Weibull}}(x_i;\\beta,\\lambda)/S_{\\text{Weibull}}(u;\\beta,\\lambda)$ 在 $i \\in \\mathcal{I}_{\\text{train}}$ 上的乘积。\n    5. 通过计算每个模型下的平均对数似然，在测试超额量上评估预测性能：\n        - POT (GPD)：$\\dfrac{1}{|\\mathcal{I}_{\\text{test}}|} \\sum_{j \\in \\mathcal{I}_{\\text{test}}} \\log g\\!\\left(y_j^{\\text{test}}; \\hat{\\xi}, \\hat{\\sigma}\\right)$。\n        - 拉伸指数（条件威布尔）：$\\dfrac{1}{|\\mathcal{I}_{\\text{test}}|} \\sum_{j \\in \\mathcal{I}_{\\text{test}}} \\left[\\log f_{\\text{Weibull}}\\!\\left(x_j^{\\text{test}}; \\hat{\\beta}, \\hat{\\lambda}\\right) - \\log S_{\\text{Weibull}}\\!\\left(u; \\hat{\\beta}, \\hat{\\lambda}\\right)\\right]$。\n       如果 $|\\mathcal{I}_{\\text{test}}| = 0$，则将两个平均值都定义为 $0$。\n    6. 此测试用例的决策规则：如果 POT 模型的平均对数似然严格高于拉伸指数模型，则输出整数 $1$，否则输出 $0$。\n\n测试套件：\n\n- 用例 A（拉伸指数 DGP）：\n    - DGP：威布尔分布，形状参数 $\\beta = 0.7$，尺度参数 $\\lambda = 1.0$。\n    - 训练集大小 $n_{\\text{train}} = 5000$，测试集大小 $n_{\\text{test}} = 5000$。\n    - 阈值百分位数 $p = 0.95$。\n\n- 用例 B（重尾 GPD DGP）：\n    - DGP：GPD，形状参数 $\\xi = 0.3$，尺度参数 $\\sigma = 1.0$。\n    - 训练集大小 $n_{\\text{train}} = 5000$，测试集大小 $n_{\\text{test}} = 5000$。\n    - 阈值百分位数 $p = 0.95$。\n\n- 用例 C（边界轻尾）：\n    - DGP：指数分布，即威布尔分布，$\\beta = 1.0$，$\\lambda = 1.0$（等价于 GPD，$\\xi = 0$，$\\sigma = 1.0$）。\n    - 训练集大小 $n_{\\text{train}} = 5000$，测试集大小 $n_{\\text{test}} = 5000$。\n    - 阈值百分位数 $p = 0.99$。\n\n最终输出格式：\n\n- 您的程序应生成单行输出，其中包含结果，格式为逗号分隔的列表，并用方括号括起，按测试用例的顺序 $\\left[\\text{用例 A}, \\text{用例 B}, \\text{用例 C}\\right]$。对于每个用例，如果 POT 模型更优（平均对数似然更高），则打印整数 $1$，否则打印 $0$。例如，输出可能看起来像 $[0,1,0]$。", "solution": "问题陈述已经过严格验证，并被确定为有效。它在科学上基于极值理论的原理，在数学上是适定的（well-posed），并且所有必要的参数和程序都得到了明确的定义。该任务是计算统计学中的一个标准练习，比较两种尾部模型——广义帕累托分布 (GPD) 和条件威布尔分布——在确定性生成的数据上的拟合优度。\n\n解决方案通过为三个测试用例中的每一个实施问题陈述中概述的步骤来进行。\n\n1.  **数据生成**：对于每个用例，从指定的数据生成过程 (DGP) 中生成一个训练样本 $\\{x_k^{\\text{train}}\\}_{k=1}^{n_{\\text{train}}}$ 和一个测试样本 $\\{x_k^{\\text{test}}\\}_{k=1}^{n_{\\text{test}}}$。生成过程是确定性的，使用逆变换采样方法在一个均匀网格 $u_k = (k-0.5)/n$（其中 $k=1, \\dots, n$）上进行。由于 $n_{\\text{train}} = n_{\\text{test}}$ 且生成过程相同，训练样本和测试样本将是相同的。这是问题规范的直接结果。\n\n2.  **阈值选择**：高阈值 $u$ 计算为对应于指定百分位数 $p$ 的训练样本的分位数。按标准使用线性插值。\n\n3.  **通过最大似然估计 (MLE) 进行模型拟合**：两种模型都仅使用训练样本中超过阈值 $\\{x_i^{\\text{train}} > u\\}$ 的观测值进行拟合。\n\n    *   **广义帕累托分布 (GPD)**：GPD 用于拟合超额量 $y_i^{\\text{train}} = x_i^{\\text{train}} - u$。通过最大化 GPD 对数似然来估计参数 $(\\xi, \\sigma)$。对于一个包含 $N_u$ 个超额量 $\\{y_i\\}_{i=1}^{N_u}$ 的样本，对数似然函数由下式给出：\n        $$\n        \\ell(\\xi, \\sigma; \\mathbf{y}) = \\sum_{i=1}^{N_u} \\log g(y_i; \\xi, \\sigma) = \n        \\begin{cases}\n        -N_u \\log \\sigma - \\left(\\frac{1}{\\xi} + 1\\right) \\sum_{i=1}^{N_u} \\log\\left(1 + \\frac{\\xi y_i}{\\sigma}\\right), & \\text{if } \\xi \\ne 0 \\\\\n        -N_u \\log \\sigma - \\frac{1}{\\sigma} \\sum_{i=1}^{N_u} y_i, & \\text{if } \\xi = 0\n        \\end{cases}\n        $$\n        受限于约束 $\\sigma > 0$ 和 $1 + \\xi y_i / \\sigma > 0$ 对所有 $i$ 成立。该估计使用 `scipy.stats.genpareto` 中的 `fit` 方法执行，该方法提供了一个稳健的 MLE 实现。\n\n    *   **条件威布尔模型**：威布尔分布参数 $(\\beta, \\lambda)$ 通过最大化观测值 $x_i^{\\text{train}}$ 在超过阈值 $u$ 条件下的条件对数似然来估计。需要最大化的对数似然函数是：\n        $$\n        \\ell(\\beta, \\lambda; \\mathbf{x}, u) = \\sum_{i: x_i > u} \\left[ \\log f_{\\text{Weibull}}(x_i; \\beta, \\lambda) - \\log S_{\\text{Weibull}}(u; \\beta, \\lambda) \\right]\n        $$\n        代入威布尔密度函数 $f_{\\text{Weibull}}$ 和生存函数 $S_{\\text{Weibull}}$ 的表达式，我们得到：\n        $$\n        \\ell(\\beta, \\lambda) = N_u \\log \\beta - N_u \\beta \\log \\lambda + (\\beta-1)\\sum_{i: x_i > u} \\log x_i - \\frac{1}{\\lambda^\\beta} \\sum_{i: x_i > u} (x_i^\\beta - u^\\beta)\n        $$\n        该函数使用 `scipy.optimize` 库中的 `minimize` 函数对 $\\beta > 0$ 和 $\\lambda > 0$ 进行数值最大化。为了处理正性约束，优化是针对对数变换后的参数 $\\log\\beta$ 和 $\\log\\lambda$ 进行的。\n\n4.  **性能评估和决策**：每个拟合模型的预测性能在测试集超额量上进行评估。度量标准是平均对数似然。\n    *   对于 GPD 模型，分数为 $\\mathcal{S}_{\\text{GPD}} = \\frac{1}{|\\mathcal{I}_{\\text{test}}|} \\sum_{j \\in \\mathcal{I}_{\\text{test}}} \\log g(y_j^{\\text{test}}; \\hat{\\xi}, \\hat{\\sigma})$。\n    *   对于威布尔模型，分数为 $\\mathcal{S}_{\\text{Weibull}} = \\frac{1}{|\\mathcal{I}_{\\text{test}}|} \\sum_{j \\in \\mathcal{I}_{\\text{test}}} \\left[ \\log f_{\\text{Weibull}}(x_j^{\\text{test}}; \\hat{\\beta}, \\hat{\\lambda}) - \\log S_{\\text{Weibull}}(u; \\hat{\\beta}, \\hat{\\lambda}) \\right]$。\n    \n    如果测试集中没有超额量 ($|\\mathcal{I}_{\\text{test}}| = 0$)，则两个分数都定义为 $0$。决策规则是如果 $\\mathcal{S}_{\\text{GPD}} > \\mathcal{S}_{\\text{Weibull}}$，则输出 $1$，否则输出 $0$。对所有三个测试用例重复此完整过程。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import genpareto, weibull_min\n\ndef solve():\n    \"\"\"\n    Solves the problem by running three test cases to compare POT-GPD and\n    conditional Weibull models for financial loss tail modeling.\n    \"\"\"\n\n    def generate_gpd_data(n, xi, sigma):\n        \"\"\"Generates deterministic data from a GPD distribution.\"\"\"\n        u_k = (np.arange(1, n + 1) - 0.5) / n\n        if np.abs(xi) < 1e-9:\n            return -sigma * np.log(1 - u_k)\n        else:\n            return (sigma / xi) * (np.power(1 - u_k, -xi) - 1)\n\n    def generate_weibull_data(n, beta, lambda_):\n        \"\"\"Generates deterministic data from a Weibull distribution.\"\"\"\n        u_k = (np.arange(1, n + 1) - 0.5) / n\n        return lambda_ * np.power(-np.log(1 - u_k), 1.0 / beta)\n    \n    def neg_log_lik_weibull_cond(log_params, x_exceed, u):\n        \"\"\"\n        Calculates the negative conditional log-likelihood for the Weibull\n        distribution, given observations x > u.\n        Optimization is performed over log-transformed parameters.\n        \"\"\"\n        log_beta, log_lambda = log_params\n        beta = np.exp(log_beta)\n        lambda_ = np.exp(log_lambda)\n\n        if beta <= 0 or lambda_ <= 0:\n            return np.inf\n        \n        n_u = len(x_exceed)\n        log_x_exceed = np.log(x_exceed)\n\n        # Using properties of logarithms for numerical stability\n        # lambda_**(-beta) * x**beta = (x/lambda_)**beta = exp(beta * (log(x) - log(lambda_)))\n        log_lambda_val = np.log(lambda_)\n        \n        term1 = n_u * np.log(beta)\n        term2 = -n_u * beta * log_lambda_val\n        term3 = (beta - 1) * np.sum(log_x_exceed)\n        \n        v_i = np.power(x_exceed / lambda_, beta)\n        v_u = np.power(u / lambda_, beta)\n        \n        term4 = -np.sum(v_i)\n        term5 = n_u * v_u\n        \n        log_likelihood = term1 + term2 + term3 + term4 + term5\n        \n        if np.isnan(log_likelihood) or np.isinf(log_likelihood):\n            return np.inf\n\n        return -log_likelihood\n\n    def solve_case(dgp_type, dgp_params, n_train, n_test, p):\n        \"\"\"Processes a single test case.\"\"\"\n        # 1. Generate data\n        if dgp_type == 'weibull':\n            beta_true, lambda_true = dgp_params\n            train_data = generate_weibull_data(n_train, beta_true, lambda_true)\n            test_data = generate_weibull_data(n_test, beta_true, lambda_true)\n        elif dgp_type == 'gpd':\n            xi_true, sigma_true = dgp_params\n            train_data = generate_gpd_data(n_train, xi_true, sigma_true)\n            test_data = generate_gpd_data(n_test, xi_true, sigma_true)\n        else:\n            raise ValueError(\"Unknown DGP type\")\n\n        # 2. Compute threshold\n        u = np.quantile(train_data, p, interpolation='linear')\n\n        # 3. Form exceedance sets\n        train_exceed_indices = np.where(train_data > u)\n        x_train_exceed = train_data[train_exceed_indices]\n        y_train_exceed = x_train_exceed - u\n\n        test_exceed_indices = np.where(test_data > u)\n        x_test_exceed = test_data[test_exceed_indices]\n        y_test_exceed = x_test_exceed - u\n        \n        n_test_exceed = len(y_test_exceed)\n\n        if n_test_exceed == 0:\n            return 1 if 0.0 > 0.0 else 0\n\n        # 4. Fit models\n        # GPD model (POT)\n        try:\n            # Fit xi and sigma, with location fixed at 0\n            gpd_params = genpareto.fit(y_train_exceed, floc=0)\n            xi_hat, _, sigma_hat = gpd_params\n        except Exception:\n            # Fallback if fitting fails (unlikely)\n            xi_hat, sigma_hat = 0.0, 1.0\n\n        # Weibull model (Stretched Exponential)\n        # Initial guess for log-parameters\n        initial_guess = [np.log(1.0), np.log(np.mean(x_train_exceed))] \n        res = minimize(\n            neg_log_lik_weibull_cond,\n            x0=initial_guess,\n            args=(x_train_exceed, u),\n            method='Nelder-Mead'\n        )\n        if res.success:\n            log_beta_hat, log_lambda_hat = res.x\n            beta_hat, lambda_hat = np.exp(log_beta_hat), np.exp(log_lambda_hat)\n        else:\n            # Fallback if fitting fails\n            beta_hat, lambda_hat = 1.0, 1.0\n            \n        # 5. Evaluate predictive performance\n        # GPD (POT)\n        avg_loglik_gpd = np.mean(genpareto.logpdf(y_test_exceed, c=xi_hat, scale=sigma_hat, loc=0))\n\n        # Conditional Weibull\n        logpdf_weibull = weibull_min.logpdf(x_test_exceed, c=beta_hat, scale=lambda_hat)\n        logsf_weibull_u = weibull_min.logsf(u, c=beta_hat, scale=lambda_hat)\n        avg_loglik_weibull = np.mean(logpdf_weibull - logsf_weibull_u)\n\n        if np.isnan(avg_loglik_gpd): avg_loglik_gpd = -np.inf\n        if np.isnan(avg_loglik_weibull): avg_loglik_weibull = -np.inf\n\n        # 6. Decision rule\n        return 1 if avg_loglik_gpd > avg_loglik_weibull else 0\n\n    # Test suite definition\n    test_cases = [\n        # Case A\n        {'dgp_type': 'weibull', 'dgp_params': (0.7, 1.0), 'n_train': 5000, 'n_test': 5000, 'p': 0.95},\n        # Case B\n        {'dgp_type': 'gpd', 'dgp_params': (0.3, 1.0), 'n_train': 5000, 'n_test': 5000, 'p': 0.95},\n        # Case C\n        {'dgp_type': 'weibull', 'dgp_params': (1.0, 1.0), 'n_train': 5000, 'n_test': 5000, 'p': 0.99},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = solve_case(\n            dgp_type=case['dgp_type'],\n            dgp_params=case['dgp_params'],\n            n_train=case['n_train'],\n            n_test=case['n_test'],\n            p=case['p']\n        )\n        results.append(result)\n\n    # Final print statement\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2418756"}, {"introduction": "超越简单的参数估计，金融建模的一个关键应用是对市场行为的假设进行检验。例如，在一次重大的金融危机之后，市场的极端风险状况是否发生了变化？这个练习 [@problem_id:2418723] 指导您完成一个完整的统计研究流程，从数据模拟和POT估计到正式的假设检验。通过对尾部指数$\\xi$进行沃尔德检验（Wald test），您将学习如何使用POT框架，就金融风险的结构性变化得出统计上严谨的结论。", "problem": "考虑代表某金融市场危机前和危机后两个时期的两组独立的模拟日对数回报率样本。超阈值峰值（peaks-over-threshold）框架假定，对于一个高阈值 $u$，超额量 $Y = X - u \\mid X > u$ 的条件分布近似为形状参数为 $\\xi$、尺度参数为 $\\beta$ 的广义帕累托分布。参数为 $(\\xi,\\beta)$ 的广义帕累托分布（Generalized Pareto Distribution, GPD）的支撑集为：当 $\\xi \\ge 0$ 时，$y \\ge 0$；当 $\\xi < 0$ 时，$0 \\le y < -\\beta/\\xi$。其累积分布函数为\n$$\nF(y \\mid \\xi,\\beta) = \n\\begin{cases}\n1 - \\left(1 + \\dfrac{\\xi y}{\\beta}\\right)^{-1/\\xi}, & \\xi \\ne 0, \\\\\n1 - \\exp\\!\\left(-\\dfrac{y}{\\beta}\\right), & \\xi = 0,\n\\end{cases}\n\\quad \\text{for } \\beta > 0.\n$$\n在GPD模型下，超额量 $(y_1,\\dots,y_k)$ 的有限样本负对数似然函数为\n$$\n\\ell(\\xi,\\beta; y_{1:k}) =\n\\begin{cases}\nk \\log \\beta + \\left(1+\\dfrac{1}{\\xi}\\right)\\displaystyle\\sum_{i=1}^k \\log\\!\\left(1 + \\dfrac{\\xi y_i}{\\beta}\\right), & \\xi \\ne 0, \\\\\nk \\log \\beta + \\dfrac{1}{\\beta}\\displaystyle\\sum_{i=1}^k y_i, & \\xi = 0,\n\\end{cases}\n$$\n受制于支撑集约束条件 $1 + \\xi y_i/\\beta > 0$（对所有 $i$）和 $\\beta > 0$。最大似然估计量 $(\\hat{\\xi},\\hat{\\beta})$ 定义为最小化 $\\ell(\\xi,\\beta; y_{1:k})$ 的任意参数对。观测信息矩阵是在 $(\\hat{\\xi},\\hat{\\beta})$ 处求值的 $\\ell$ 的Hessian矩阵，其逆矩阵近似于 $(\\hat{\\xi},\\hat{\\beta})$ 的协方差矩阵；特别地，$\\hat{\\xi}$ 的近似方差是该逆矩阵的 $(1,1)$ 元素。\n\n您将使用双边瓦尔德检验（two-sided Wald test），在显著性水平 $\\alpha = 0.05$ 下，检验形状（尾部指数）参数在危机前和危机后时期之间是否发生了变化：\n$$\nH_0: \\ \\xi_{\\text{pre}} = \\xi_{\\text{post}}\n\\quad \\text{versus} \\quad\nH_1: \\ \\xi_{\\text{pre}} \\ne \\xi_{\\text{post}}.\n$$\n令 $\\hat{\\xi}_{\\text{pre}}$ 和 $\\hat{\\xi}_{\\text{post}}$ 分别为从各自样本中获得的最大似然估计量，其近似标准误差 $s_{\\text{pre}}$ 和 $s_{\\text{post}}$ 从观测信息协方差矩阵中得到。瓦尔德统计量为\n$$\nZ = \\dfrac{\\hat{\\xi}_{\\text{pre}} - \\hat{\\xi}_{\\text{post}}}{\\sqrt{s_{\\text{pre}}^2 + s_{\\text{post}}^2}},\n$$\n如果 $|Z| \\ge z_{1-\\alpha/2}$，则拒绝 $H_0$，其中 $z_{1-\\alpha/2}$ 是标准正态分布的 $(1-\\alpha/2)$ 分位数。\n\n每个时期的数据生成过程如下。固定基准阈值水平 $u_0 = 0$ 和尾部混合概率 $p_{\\text{tail}} \\in (0,1)$。通过拼接生成 $n$ 个独立观测值：\n- 一个大小为 $n - m$ 的“主体”部分，其中 $m = \\lfloor p_{\\text{tail}} n \\rceil$，从支撑集为 $(-\\infty, u_0]$ 的连续分布中抽取；使用 $[-3, u_0]$ 上的均匀分布。\n- 一个大小为 $m$ 的“尾部”部分，构造为 $u_0 + Y$，其中 $Y$ 是独立的 GPD$(\\xi,\\beta)$ 随机变量，其参数 $(\\xi,\\beta)$ 为该时期指定。\n\n对于每个时期和测试用例，将阈值 $u$ 设置为模拟样本的经验 $q$-分位数，其中 $q = 0.9$。对于所有 $X_i > u$，将超额量定义为 $Y_i = X_i - u$。\n\n您的程序必须对下面的每个测试用例执行以下操作：\n1. 使用指定的参数和独立的随机种子，模拟危机前和危机后的样本。\n2. 对每个时期分别计算分位数水平 $q = 0.9$ 的经验阈值 $u$。\n3. 形成各自阈值以上的超额量 $Y_i$。\n4. 通过在支撑集约束下最小化精确的有限样本负对数似然 $\\ell(\\xi,\\beta; y_{1:k})$，为每个时期计算最大似然估计量 $(\\hat{\\xi},\\hat{\\beta})$。\n5. 使用在最大似然估计量处的观测信息矩阵的逆，为每个时期近似 $\\hat{\\xi}$ 的标准误差。\n6. 在显著性水平 $\\alpha = 0.05$ 下，执行 $H_0: \\xi_{\\text{pre}} = \\xi_{\\text{post}}$ 的双边瓦尔德检验。\n7. 输出一个布尔值，指示尾部指数是否存在统计上显著的变化（如果 $H_0$ 被拒绝，则输出 true，否则输出 false）。\n\n测试套件（每个元组对应一个测试用例，顺序为：$(\\text{seed}_{\\text{pre}}, \\text{seed}_{\\text{post}}, n_{\\text{pre}}, n_{\\text{post}}, \\xi_{\\text{pre}}, \\beta_{\\text{pre}}, \\xi_{\\text{post}}, \\beta_{\\text{post}})$），共同参数为 $u_0 = 0$，$p_{\\text{tail}} = 0.25$，$q = 0.9$，以及 $\\alpha = 0.05$：\n- 案例 A: $(12345, 54321, 5000, 5000, 0.2, 1.0, 0.6, 1.0)$。\n- 案例 B: $(111, 222, 4000, 4000, 0.2, 1.0, 0.2, 1.0)$。\n- 案例 C: $(333, 444, 6000, 6000, 0.01, 1.0, 0.0, 1.0)$。\n- 案例 D: $(555, 666, 6000, 6000, -0.15, 1.2, 0.15, 1.2)$。\n\n最终输出格式。您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表，结果的顺序与测试用例的顺序相同，例如：`[true,false,true,false]`。布尔值必须全部为小写。", "solution": "该问题要求执行一个统计假设检验，以确定由广义帕累托分布（GPD）建模的金融回报率的尾部行为在两个时期之间是否发生了变化。这是极值理论（Extreme Value Theory, EVT）在量化金融中的一个标准应用。验证过程证实了该问题陈述在科学上是合理的、适定的，并包含了获得唯一、可验证解所需的所有信息。\n\n解决方案系统地通过数据模拟、最大似然参数估计和使用瓦尔德检验进行假设检验来展开。\n\n**1. 数据模拟与预处理**\n\n每个时期（危机前和危机后）的数据都是从一个混合分布中生成的，该分布旨在具有特定的尾部行为。对于一个大小为 $n$ 的样本，比例为 $p_{\\text{tail}}$ 的数据点构成“尾部”，并从GPD中抽取。其余点构成分布的“主体”。\n\n-   **主体**：$n - m$ 个样本从 $[-3, u_0]$ 上的均匀分布中抽取，其中 $m = \\lfloor p_{\\text{tail}} n \\rceil$，基准阈值为 $u_0 = 0$。\n-   **尾部**：生成 $m$ 个样本，形如 $u_0 + Y_i$，其中 $Y_i$ 是独立的 GPD$(\\xi, \\beta)$ 随机变量。\n\n为了从GPD$(\\xi, \\beta)$生成随机变量 $Y$，我们使用逆变换采样法。分位数函数 $F^{-1}(p)$ 是通过对GPD累积分布函数（CDF）$F(y)$ 求逆得到的。给定一个均匀随机变量 $U \\sim U(0,1)$，GPD变量 $Y$ 的生成方式如下：\n$$\nY = F^{-1}(U) = \n\\begin{cases}\n\\dfrac{\\beta}{\\xi} \\left( (1-U)^{-\\xi} - 1 \\right), & \\xi \\ne 0, \\\\\n-\\beta \\log(1-U), & \\xi = 0.\n\\end{cases}\n$$\n由于 $1-U$ 也均匀分布在 $(0,1)$ 上，这等同于在表达式中直接使用 $U$。\n\n在模拟了完整样本 $X = \\{X_1, \\dots, X_n\\}$ 后，我们应用超阈值峰值（Peaks-Over-Threshold, POT）方法。我们将一个高阈值 $u$ 设定为样本的经验 $q$-分位数，其中 $q=0.9$。然后将超额量定义为所有 $X_i > u$ 的正值 $Y_i = X_i - u$。这些超额量构成了拟合GPD模型的数据集。\n\n**2. 最大似然估计（MLE）**\n\nGPD的参数 $(\\xi, \\beta)$ 是通过最大化对数似然函数，或等效地，最小化负对数似然函数 $\\ell(\\xi, \\beta)$ 来为每个时期进行估计的。对于一组 $k$ 个超额量 $\\{y_1, \\dots, y_k\\}$，负对数似然由下式给出：\n$$\n\\ell(\\xi,\\beta; y_{1:k}) =\n\\begin{cases}\nk \\log \\beta + \\left(1+\\dfrac{1}{\\xi}\\right)\\displaystyle\\sum_{i=1}^k \\log\\!\\left(1 + \\dfrac{\\xi y_i}{\\beta}\\right), & \\xi \\ne 0, \\\\\nk \\log \\beta + \\dfrac{1}{\\beta}\\displaystyle\\sum_{i=1}^k y_i, & \\xi = 0.\n\\end{cases}\n$$\n这个最小化过程是一个数值优化问题。当 $\\xi \\to 0$ 时，$\\xi \\ne 0$ 的函数收敛于 $\\xi = 0$ 的函数。为确保数值稳定性，我们在实现目标函数时采用条件分支，对接近于零的 $\\xi$ 值（例如，$|\\xi| < 10^{-8}$）使用其极限形式。\n\n最小化受制于以下约束：$\\beta > 0$，并且为了使对数项有良好定义，$1 + \\xi y_i/\\beta > 0$ 必须对所有超额量 $y_i$ 成立。当 $\\xi < 0$ 时，后一个约束意味着 $y_i < -\\beta/\\xi$。这些约束在目标函数内部通过以下方式强制执行：如果违反约束，则返回一个大值（代表无穷大），从而有效地创建一个屏障，引导优化器走向有效的参数空间。优化过程使用 `scipy.optimize.minimize` 提供的 Broyden–Fletcher–Goldfarb–Shanno (BFGS) 算法执行。\n\n**3. 标准误差近似**\n\n根据MLE的大样本理论，估计量 $(\\hat{\\xi}, \\hat{\\beta})$ 的渐近协方差矩阵可以通过观测信息矩阵 $I(\\hat{\\xi}, \\hat{\\beta})$ 的逆来近似。观测信息矩阵是在最大似然估计（MLE）处求值的负对数似然函数的Hessian矩阵：\n$$\n\\text{Cov}(\\hat{\\xi}, \\hat{\\beta}) \\approx [I(\\hat{\\xi}, \\hat{\\beta})]^{-1} = \\left[ \\nabla^2 \\ell(\\hat{\\xi}, \\hat{\\beta}) \\right]^{-1}.\n$$\nBFGS算法作为一种拟牛顿法，其程序的一部分就是计算Hessian矩阵逆的近似值。这个近似值可以从优化结果中直接获得。形状参数估计量的方差 $\\text{Var}(\\hat{\\xi})$，由该逆Hessian矩阵的左上角元素近似。相应的标准误差是其平方根：\n$$\ns_{\\hat{\\xi}} = \\sqrt{\\left( [I(\\hat{\\xi}, \\hat{\\beta})]^{-1} \\right)_{1,1}}.\n$$\n\n**4. 参数相等的瓦尔德检验**\n\n为了检验尾部指数没有变化的假设 $H_0: \\xi_{\\text{pre}} = \\xi_{\\text{post}}$，相对于备择假设 $H_1: \\xi_{\\text{pre}} \\ne \\xi_{\\text{post}}$，我们使用双边瓦尔德检验。该检验统计量由来自两个独立样本（危机前和危机后）的最大似然估计量及其标准误差构建而成：\n$$\nZ = \\dfrac{\\hat{\\xi}_{\\text{pre}} - \\hat{\\xi}_{\\text{post}}}{\\sqrt{s_{\\text{pre}}^2 + s_{\\text{post}}^2}}.\n$$\n在原假设下，统计量 $Z$ 服从渐近标准正态分布 $N(0,1)$。如果在显著性水平 $\\alpha$ 下，观测到的统计量的绝对值 $|Z|$ 超过临界值 $z_{1-\\alpha/2}$，我们则拒绝 $H_0$。其中 $z_{1-\\alpha/2}$ 是标准正态分布的 $(1-\\alpha/2)$-分位数。对于 $\\alpha = 0.05$，临界值为 $z_{0.975} \\approx 1.96$。\n\n整个流程被封装在一个程序中，该程序遍历所提供的测试用例，对每个用例执行模拟、估计和检验，并报告原假设是否被拒绝。", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for the GPD tail index comparison.\n    \"\"\"\n    test_cases = [\n        # (seed_pre, seed_post, n_pre, n_post, xi_pre, beta_pre, xi_post, beta_post)\n        (12345, 54321, 5000, 5000, 0.2, 1.0, 0.6, 1.0),\n        (111, 222, 4000, 4000, 0.2, 1.0, 0.2, 1.0),\n        (333, 444, 6000, 6000, 0.01, 1.0, 0.0, 1.0),\n        (555, 666, 6000, 6000, -0.15, 1.2, 0.15, 1.2),\n    ]\n\n    common_params = {\n        'u0': 0.0,\n        'p_tail': 0.25,\n        'q': 0.9,\n        'alpha': 0.05,\n    }\n\n    results = []\n    for case in test_cases:\n        seed_pre, seed_post, n_pre, n_post, xi_pre, beta_pre, xi_post, beta_post = case\n        \n        # Fit pre-crisis period\n        xi_hat_pre, se_pre = fit_gpd_for_period(\n            seed_pre, n_pre, xi_pre, beta_pre, common_params\n        )\n        \n        # Fit post-crisis period\n        xi_hat_post, se_post = fit_gpd_for_period(\n            seed_post, n_post, xi_post, beta_post, common_params\n        )\n        \n        # Perform Wald test\n        wald_statistic = (xi_hat_pre - xi_hat_post) / np.sqrt(se_pre**2 + se_post**2)\n        critical_value = norm.ppf(1 - common_params['alpha'] / 2)\n        \n        reject_h0 = np.abs(wald_statistic) >= critical_value\n        results.append(str(reject_h0).lower())\n\n    print(f\"[{','.join(results)}]\")\n\ndef fit_gpd_for_period(seed, n, xi, beta, params):\n    \"\"\"\n    Simulates data and fits a GPD model for a single period.\n    Returns the estimated shape parameter and its standard error.\n    \"\"\"\n    X = simulate_data(seed, n, xi, beta, params['p_tail'], params['u0'])\n    \n    u = np.quantile(X, params['q'])\n    Y = X[X > u] - u\n    \n    # It's possible, though unlikely, that there are no exceedances\n    if len(Y) == 0:\n        raise ValueError(\"No exceedances found for GPD fitting.\")\n\n    # Objective function: negative log-likelihood for GPD\n    def nll_gpd(p, y_data):\n        _xi, _beta = p\n        \n        # Constraint: beta > 0\n        if _beta <= 1e-6:\n            return np.inf\n            \n        # Support constraint: 1 + xi*y/beta > 0\n        terms = 1 + _xi * y_data / _beta\n        if np.any(terms <= 0):\n            return np.inf\n\n        k = len(y_data)\n        \n        if abs(_xi) < 1e-8:\n            # Case xi -> 0 (Exponential distribution)\n            neg_log_lik = k * np.log(_beta) + np.sum(y_data) / _beta\n        else:\n            # Case xi != 0\n            log_of_terms = np.log(terms)\n            neg_log_lik = k * np.log(_beta) + (1 + 1/_xi) * np.sum(log_of_terms)\n\n        if not np.isfinite(neg_log_lik):\n            return np.inf\n            \n        return neg_log_lik\n\n    # Initial guess for optimization\n    initial_guess = [0.1, np.std(Y) if len(Y) > 1 else 1.0]\n\n    # Run optimizer to find MLE\n    res = minimize(\n        nll_gpd,\n        initial_guess,\n        args=(Y,),\n        method='BFGS',\n        options={'gtol': 1e-8}\n    )\n\n    if not res.success:\n        # A failed optimization might require more robust initial values or optimizer choice\n        # For this problem, we assume `BFGS` with this initial guess suffices.\n        pass\n\n    xi_hat, _ = res.x\n    \n    # Approximate variance from the inverse Hessian\n    var_xi = res.hess_inv[0, 0]\n    \n    # Handle potential numerical instability if variance is negative\n    if var_xi < 0:\n        # This shouldn't happen with BFGS, which maintains a positive definite Hess approx.\n        # But as a safeguard:\n        var_xi = np.abs(var_xi)\n\n    se_xi = np.sqrt(var_xi)\n    \n    return xi_hat, se_xi\n\ndef simulate_data(seed, n, xi, beta, p_tail, u0):\n    \"\"\"\n    Generates a sample from the mixture distribution.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    \n    m = int(round(p_tail * n))\n    n_body = n - m\n    \n    # Generate the \"body\" of the distribution\n    body = rng.uniform(-3.0, u0, size=n_body)\n    \n    # Generate the \"tail\" using GPD inverse transform sampling\n    U = rng.uniform(size=m)\n    if abs(xi) < 1e-8:\n        tail_excess = -beta * np.log(U)\n    else:\n        tail_excess = (beta / xi) * (np.power(U, -xi) - 1)\n        \n    tail = u0 + tail_excess\n    \n    return np.concatenate((body, tail))\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2418723"}]}