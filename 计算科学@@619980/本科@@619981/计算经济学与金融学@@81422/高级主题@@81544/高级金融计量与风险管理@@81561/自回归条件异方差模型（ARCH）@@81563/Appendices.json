{"hands_on_practices": [{"introduction": "在GARCH模型分析中，协方差平稳性是一个核心概念，它确保了模型的长期行为是可预测的，例如存在一个有限且不随时间变化的无条件方差。本练习旨在通过动手实践，加深你对这一关键性质的理解。你将首先从理论上推导出GARCH(1,1)模型的平稳性条件，然后通过编写代码模拟不同参数下的过程，从经验上验证当参数和接近、等于或大于1时，序列的动态行为有何不同。这个练习将理论与计算相结合，帮助你直观地感受模型参数如何决定时间序列的长期稳定性 [@problem_id:2373513]。", "problem": "考虑一个零均值收益率过程 $\\{r_t\\}$ 的 GARCH(1,1) 模型，该模型由以下随机差分方程定义\n$$r_t = \\sigma_t \\varepsilon_t,$$\n$$\\sigma_t^2 = \\omega + \\alpha_1 r_{t-1}^2 + \\beta_1 \\sigma_{t-1}^2,$$\n其中 $\\{\\varepsilon_t\\}$ 是独立同分布（IID）的，满足 $\\mathbb{E}[\\varepsilon_t]=0$ 和 $\\mathbb{E}[\\varepsilon_t^2]=1$，并且 $\\omega > 0$，$\\alpha_1 \\ge 0$，$\\beta_1 \\ge 0$。在计算经济学和金融学中，一个关键问题是协方差平稳性，即是否存在一个有限的、不随时间变化的无条件二阶矩 $\\mathbb{E}[r_t^2]$。\n\n您的任务如下。\n\n任务 A：仅从模型定义、迭代期望定律和独立性出发，推导无条件二阶矩 $\\mu_t \\equiv \\mathbb{E}[r_t^2] = \\mathbb{E}[\\sigma_t^2]$ 所满足的标量线性递归关系，并确定一个关于 $\\alpha_1$ 和 $\\beta_1$ 的、使得 $\\mu_t$ 在 $t \\to \\infty$ 时收敛到一个有限极限的充分必要条件。如果该极限存在，请用 $\\omega$、$\\alpha_1$ 和 $\\beta_1$ 的符号形式表示它。\n\n任务 B：设计一个算法，给定参数 $(\\omega,\\alpha_1,\\beta_1)$，该算法通过对 GARCH(1,1) 过程进行长期模拟，来经验性地评估其协方差平稳性，通过验证以下两个性质：\n- 收敛性：当理论无条件二阶矩存在时，$r_t^2$ 的长期样本均值接近于任务 A 中得出的理论值。\n- 稳定性：在预烧期结束后的样本中，对相等大小的连续时间块计算出的 $r_t^2$ 的块均值彼此之间相对稳定，并且不表现出持续的漂移。您的算法应通过一个定量诊断来操作化稳定性，该诊断比较序列的早期和晚期部分，并包含一个跨块的离散度度量。\n\n任务 C：实现一个完整的、可运行的程序，该程序：\n- 对下文测试套件中的每组参数，使用 IID 标准正态创新项模拟模型，总长度 $T = 120,000$，并在诊断前丢弃 $B = 20,000$ 个观测值的预烧期。将 $\\sigma_0^2$ 初始化为一个对所有情况都兼容的严格正有限值。使用固定的随机种子以确保可复现性。\n- 在预烧期结束后的样本上使用 $K = 8$ 个大小相等的块来计算 $r_t^2$ 的块均值。\n- 根据以下定量标准，将每个测试用例分类为协方差平稳或非协方差平稳：\n  - 令 $\\widehat{m}$ 表示预烧期后 $r_t^2$ 的样本均值，令 $m^\\star$ 表示任务 A 中得出的理论无条件二阶矩（若存在）。定义相对误差 $|\\widehat{m} - m^\\star|/m^\\star$。\n  - 令 $m_{\\text{first}}$ 和 $m_{\\text{last}}$ 分别为预烧期后样本的第一个和最后一个四分位的 $r_t^2$ 样本均值，并定义增长率 $d \\equiv m_{\\text{last}}/m_{\\text{first}}$。\n  - 令 $m_1,\\dots,m_K$ 为块均值，并定义变异系数 $\\mathrm{CV} \\equiv \\mathrm{sd}(m_1,\\dots,m_K)/\\overline{m}$，其中 $\\overline{m}$ 是这 $K$ 个块均值的算术平均值。\n  - 当且仅当理论无条件二阶矩存在，并且同时满足以下所有条件时，才将一组参数分类为协方差平稳：相对误差最多为 $\\tau = 0.10$，增长率满足 $d \\le \\rho = 1.20$，且块稳定性满足 $\\mathrm{CV} \\le \\kappa = 0.20$。\n- 生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的每个条目是一个布尔值，按下方给出的顺序对应相关测试用例的分类结果，无空格。\n\n测试套件：\n- 用例 A（和略小于 $1$）：$\\omega = 0.1$, $\\alpha_1 = 0.05$, $\\beta_1 = 0.90$。\n- 用例 B（和等于 $1$）：$\\omega = 0.1$, $\\alpha_1 = 0.05$, $\\beta_1 = 0.95$。\n- 用例 C（和略大于 $1$）：$\\omega = 0.1$, $\\alpha_1 = 0.05$, $\\beta_1 = 0.98$。\n\n答案规范：\n- 最终输出必须是单行，包含一个布尔值列表，其顺序严格为 $[\\text{用例 A},\\text{用例 B},\\text{用例 C}]$，例如 $[True,False,False]$。\n- 不涉及物理单位。所有数值阈值必须严格按照上述规定实现。", "solution": "该问题要求对 GARCH(1,1) 模型进行两部分分析：首先，对协方差平稳性的条件进行理论推导；其次，基于模拟设计并实现一个用于检验此性质的经验性测试。\n\n我们从任务 A 中指定的理论推导开始。GARCH(1,1)模型由以下方程定义：\n$$r_t = \\sigma_t \\varepsilon_t$$\n$$\\sigma_t^2 = \\omega + \\alpha_1 r_{t-1}^2 + \\beta_1 \\sigma_{t-1}^2$$\n其中 $\\{\\varepsilon_t\\}$ 是一个独立同分布（IID）过程，满足 $\\mathbb{E}[\\varepsilon_t] = 0$ 和 $\\mathbb{E}[\\varepsilon_t^2] = 1$。参数满足 $\\omega > 0$，$\\alpha_1 \\ge 0$，且 $\\beta_1 \\ge 0$。我们关心的是无条件二阶矩，$\\mu_t \\equiv \\mathbb{E}[r_t^2]$。\n\n令 $\\mathcal{F}_{t-1}$ 表示在时间 $t-1$ 可用的信息所代表的$\\sigma$-代数，它包含 $\\varepsilon_t$ 所有的过去值。根据定义，$\\sigma_t^2$ 是过去收益率和方差的函数，因此是 $\\mathcal{F}_{t-1}$-可测的。创新项 $\\varepsilon_t$ 独立于 $\\mathcal{F}_{t-1}$。\n\n首先，我们建立恒等式 $\\mu_t = \\mathbb{E}[\\sigma_t^2]$。使用迭代期望定律：\n$$\\mu_t = \\mathbb{E}[r_t^2] = \\mathbb{E}[\\sigma_t^2 \\varepsilon_t^2] = \\mathbb{E}\\left[\\mathbb{E}[\\sigma_t^2 \\varepsilon_t^2 | \\mathcal{F}_{t-1}]\\right]$$\n由于 $\\sigma_t^2$ 是 $\\mathcal{F}_{t-1}$-可测的，并且 $\\varepsilon_t$ 独立于 $\\mathcal{F}_{t-1}$：\n$$\\mathbb{E}[\\sigma_t^2 \\varepsilon_t^2 | \\mathcal{F}_{t-1}] = \\sigma_t^2 \\mathbb{E}[\\varepsilon_t^2 | \\mathcal{F}_{t-1}] = \\sigma_t^2 \\mathbb{E}[\\varepsilon_t^2] = \\sigma_t^2 \\cdot 1 = \\sigma_t^2$$\n将此结果代回，我们得到：\n$$\\mu_t = \\mathbb{E}[\\sigma_t^2]$$\n这证实了问题描述中提供的恒等式。\n\n接下来，我们推导 $\\mu_t$ 的递归关系。我们对方差方程取无条件期望：\n$$\\mathbb{E}[\\sigma_t^2] = \\mathbb{E}[\\omega + \\alpha_1 r_{t-1}^2 + \\beta_1 \\sigma_{t-1}^2]$$\n根据期望算子的线性性质：\n$$\\mathbb{E}[\\sigma_t^2] = \\omega + \\alpha_1 \\mathbb{E}[r_{t-1}^2] + \\beta_1 \\mathbb{E}[\\sigma_{t-1}^2]$$\n使用我们的定义 $\\mu_t = \\mathbb{E}[\\sigma_t^2]$ 和 $\\mu_{t-1} = \\mathbb{E}[r_{t-1}^2] = \\mathbb{E}[\\sigma_{t-1}^2]$，我们得到无条件二阶矩的标量线性递归关系：\n$$\\mu_t = \\omega + (\\alpha_1 + \\beta_1) \\mu_{t-1}$$\n这是一个一阶线性非齐次递归关系。为了使 $\\mu_t$ 在 $t \\to \\infty$ 时收敛到一个有限的、不随时间变化的极限 $\\mu$，动态项的系数的绝对值必须小于 $1$。鉴于非负约束 $\\alpha_1 \\ge 0$ 和 $\\beta_1 \\ge 0$，存在一个有限的、不随时间变化的二阶矩的充分必要条件是：\n$$\\alpha_1 + \\beta_1 < 1$$\n如果此条件成立，则该过程被称为弱平稳或协方差平稳。我们记极限无条件方差为 $m^\\star$，通过在递归关系中设 $\\mu_t = \\mu_{t-1} = m^\\star$ 求得，得到不动点方程：\n$$m^\\star = \\omega + (\\alpha_1 + \\beta_1) m^\\star$$\n解出 $m^\\star$ 得到理论无条件二阶矩的表达式：\n$$m^\\star = \\frac{\\omega}{1 - \\alpha_1 - \\beta_1}$$\n这一理论基础直接为任务 B 和 C 的算法设计提供了信息。\n\n用于经验性评估协方差平稳性的算法流程如下。\n1.  **理论预检验**：对于给定的参数集 $(\\omega, \\alpha_1, \\beta_1)$，首先检查条件 $\\alpha_1 + \\beta_1 < 1$。如果不满足，该过程立即被分类为非协方差平稳，因为理论无条件二阶矩不存在。\n2.  **模拟**：如果预检验通过，则模拟一个长度为 $T = 120,000$ 的 GARCH(1,1) 过程。创新项 $\\varepsilon_t$ 从一个 IID 标准正态分布中抽取。为确保可复现性，使用一个固定的随机种子。模拟从一个初始方差 $\\sigma_0^2 > 0$ 开始。\n3.  **数据准备**：丢弃前 $B = 20,000$ 个数据点作为预烧期，以消除对初始条件的依赖。分析在随后的 $N = 100,000$ 个平方收益率样本 $\\{r_t^2\\}_{t=B}^{T-1}$ 上进行。\n4.  **诊断评估**：计算三个定量指标以评估收敛性和稳定性。\n    a.  **收敛性准则**：计算预烧期后平方收益率的样本均值 $\\widehat{m}$。其相对于理论值 $m^\\star$ 的相对误差 $|\\widehat{m} - m^\\star|/m^\\star$ 必须小于或等于一个容忍度 $\\tau = 0.10$。\n    b.  **稳定性准则（趋势）**：将预烧期后的样本分为四个相等的季度。计算最后一个季度的均值 ($m_{\\text{last}}$) 与第一个季度的均值 ($m_{\\text{first}}$) 的比率，记为 $d = m_{\\text{last}}/m_{\\text{first}}$。一个平稳序列不应表现出显著的漂移，因此该比率必须小于或等于一个阈值 $\\rho = 1.20$。\n    c.  **稳定性准则（离散度）**：将预烧期后的样本划分为 $K=8$ 个不重叠的等大小块。计算每个块的均值 $m_k$。通过这些块均值的变异系数（CV）来评估过程的稳定性，$\\mathrm{CV} = \\mathrm{sd}(m_1, \\dots, m_K) / \\overline{m}$，其中 $\\mathrm{sd}(\\cdot)$ 是样本标准差，$\\overline{m}$ 是块均值的均值。低的 CV 值表示方差在整个样本中是稳定的。该值必须小于或等于一个阈值 $\\kappa = 0.20$。\n5.  **最终分类**：当且仅当理论条件 $\\alpha_1 + \\beta_1 < 1$ 满足，并且所有三个经验性准则（相对误差、增长率、块变异系数）都满足其指定阈值时，一个参数集才被分类为协方差平稳。否则，它被分类为非协方差平稳。对每个测试用例都执行此完整过程。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_garch_analysis(omega, alpha_1, beta_1, T, B, K, tau, rho, kappa, eps_series):\n    \"\"\"\n    Simulates a GARCH(1,1) process and assesses covariance stationarity.\n\n    Args:\n        omega (float): GARCH parameter.\n        alpha_1 (float): GARCH parameter.\n        beta_1 (float): GARCH parameter.\n        T (int): Total length of the simulation.\n        B (int): Length of the burn-in period.\n        K (int): Number of blocks for stability analysis.\n        tau (float): Relative error threshold.\n        rho (float): Growth ratio threshold.\n        kappa (float): Block stability (CV) threshold.\n        eps_series (np.ndarray): Pre-generated standard normal innovations.\n\n    Returns:\n        bool: True if classified as covariance-stationary, False otherwise.\n    \"\"\"\n    # Step 1: Theoretical Pre-check\n    if alpha_1 + beta_1 >= 1:\n        return False\n\n    # Theoretical unconditional second moment\n    m_star = omega / (1 - alpha_1 - beta_1)\n\n    # Step 2: Simulation\n    sigma_sq = np.zeros(T)\n    r_sq = np.zeros(T)\n    \n    # Initialization: choose a positive finite value compatible with all cases,\n    # as required by the problem.\n    sigma_sq[0] = 0.1\n\n    for t in range(T - 1):\n        r_sq[t] = sigma_sq[t] * eps_series[t]**2\n        sigma_sq[t+1] = omega + alpha_1 * r_sq[t] + beta_1 * sigma_sq[t]\n    \n    # Compute the last value of r_sq\n    r_sq[T-1] = sigma_sq[T-1] * eps_series[T-1]**2\n\n    # Step 3: Data Preparation\n    analysis_sample = r_sq[B:]\n    N = T - B\n    \n    # Step 4: Diagnostic Evaluation\n    \n    # a. Convergence Criterion\n    m_hat = np.mean(analysis_sample)\n    relative_error = np.abs(m_hat - m_star) / m_star\n    \n    # b. Stability Criterion (Trend)\n    n_quarter = N // 4\n    m_first = np.mean(analysis_sample[:n_quarter])\n    m_last = np.mean(analysis_sample[-n_quarter:])\n    \n    # To avoid division by zero if m_first happens to be pathologically small\n    if m_first <= 0:\n        growth_ratio = float('inf')\n    else:\n        growth_ratio = m_last / m_first\n\n    # c. Stability Criterion (Dispersion)\n    block_size = N // K\n    block_means = np.array([\n        np.mean(analysis_sample[k*block_size : (k+1)*block_size]) for k in range(K)\n    ])\n    mean_of_block_means = np.mean(block_means) # This is equivalent to m_hat\n    \n    if mean_of_block_means <= 0:\n        cv = float('inf')\n    else:\n        # Use ddof=1 for sample standard deviation\n        cv = np.std(block_means, ddof=1) / mean_of_block_means\n\n    # Step 5: Final Classification\n    is_conv_ok = relative_error <= tau\n    is_growth_ok = growth_ratio <= rho\n    is_stability_ok = cv <= kappa\n\n    return is_conv_ok and is_growth_ok and is_stability_ok\n\n\ndef solve():\n    \"\"\"\n    Main function to run the analysis for all test cases.\n    \"\"\"\n    # Define parameters from the problem statement.\n    T = 120000\n    B = 20000\n    K = 8\n    tau = 0.10\n    rho = 1.20\n    kappa = 0.20\n\n    # Define the test cases.\n    test_cases = [\n        {'name': 'Case A', 'omega': 0.1, 'alpha_1': 0.05, 'beta_1': 0.90},\n        {'name': 'Case B', 'omega': 0.1, 'alpha_1': 0.05, 'beta_1': 0.95},\n        {'name': 'Case C', 'omega': 0.1, 'alpha_1': 0.05, 'beta_1': 0.98},\n    ]\n\n    # Set a fixed random seed for reproducibility of the entire program run.\n    # The same stream of random numbers will be used sequentially for all cases.\n    np.random.seed(42)\n    \n    # Pre-generate all random numbers needed.\n    eps_series = np.random.standard_normal(T)\n\n    results = []\n    for case in test_cases:\n        is_stationary = run_garch_analysis(\n            omega=case['omega'],\n            alpha_1=case['alpha_1'],\n            beta_1=case['beta_1'],\n            T=T, B=B, K=K,\n            tau=tau, rho=rho, kappa=kappa,\n            eps_series=eps_series\n        )\n        results.append(is_stationary)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2373513"}, {"introduction": "在理解了GARCH模型的基本属性后，实践中的下一个挑战是如何为给定的数据集选择最合适的模型。一个更复杂的模型（如GARCH）可能能更好地拟合数据，但也可能过拟合；而一个更简单的模型（如ARCH）则更节俭，但可能无法捕捉所有动态特征。本练习将引导你使用贝叶斯信息准则（BIC）来探索这种权衡。你将通过模拟一个低持续性的GARCH(1,1)过程，并比较ARCH(1)和GARCH(1,1)模型的BIC值，来研究在何种情况下，一个更简单的模型会被错误地选择，从而深入理解模型选择的微妙之处 [@problem_id:2373512]。", "problem": "您需要编写一个完整、可运行的程序，该程序构建模拟的金融收益率序列，并使用高斯准极大似然估计（QMLE）来评估两种波动率模型之间的模型选择。此任务的框架是自回归条件异方差，具体来说，是在数据由低持续性 GARCH(1,1) 过程生成时，比较一个一阶自回归条件异方差模型（ARCH(1)）与一个(1,1)阶广义自回归条件异方差模型（GARCH(1,1)）。\n\n请从以下核心定义和广为接受的事实开始：\n\n- 一个具有条件异方差的均值为零的收益率序列 $\\{r_t\\}_{t=1}^T$ 被建模为 $r_t = \\sigma_t z_t$，其中 $\\{z_t\\}$ 是独立同分布的标准正态变量，而 $\\sigma_t^2$ 是条件方差。\n- ARCH($p$) 模型将条件方差指定为 $\\sigma_t^2 = \\omega + \\sum_{i=1}^p \\alpha_i r_{t-i}^2$，其中 $\\omega > 0$，$\\alpha_i \\ge 0$，并且为满足协方差平稳性有 $\\sum_{i=1}^p \\alpha_i < 1$。\n- GARCH(1,1) 模型将条件方差指定为 $\\sigma_t^2 = \\omega + \\alpha r_{t-1}^2 + \\beta \\sigma_{t-1}^2$，其中 $\\omega > 0$，$\\alpha \\ge 0$，$\\beta \\ge 0$，并且为满足协方差平稳性有 $\\alpha + \\beta < 1$。\n- 在高斯 QMLE 下，给定一个为参数 $\\theta$ 生成 $\\{\\sigma_t^2(\\theta)\\}$ 的参数化波动率递推式，其对数似然为\n$$\n\\ell_T(\\theta) = -\\frac{1}{2} \\sum_{t=1}^T \\left( \\log(2\\pi) + \\log\\left(\\sigma_t^2(\\theta)\\right) + \\frac{r_t^2}{\\sigma_t^2(\\theta)} \\right).\n$$\n- 对于一个有 $k$ 个自由参数和样本量为 $n$ 的模型，其贝叶斯信息准则（BIC）为\n$$\n\\mathrm{BIC} = -2 \\ell_T(\\hat{\\theta}) + k \\log(n),\n$$\n其中 $\\hat{\\theta}$ 是使对数似然最大化的参数。\n\n您的程序必须：\n\n1.  对于每个测试用例，使用给定的参数和一个低持续性（即 $\\alpha + \\beta$ 严格小于 $1$ 且数值上较小）的 GARCH(1,1) 过程，模拟一个收益率序列 $\\{r_t\\}_{t=1}^T$。使用标准正态新息 $\\{z_t\\}$，并设定一个固定的 $B = 1000$ 个观测值的预烧期，在保留最后 $T$ 个观测值之前丢弃这些数据，以减轻初始条件的影响。使用无条件方差作为初始方差，即 $\\sigma_0^2 = \\omega / (1 - \\alpha - \\beta)$。\n2.  通过高斯 QMLE 拟合以下两个模型：\n    -   一个指定阶数 $p$ 的 ARCH($p$) 模型。\n    -   一个 GARCH(1,1) 模型。\n    估计过程必须遵守上述的正值性和平稳性约束。您可以使用任何数值稳定、可微的重参数化方法在优化过程中施加这些约束。\n3.  对于每个拟合好的模型，计算其最大化后的对数似然和 BIC。ARCH($p$) 模型的 $k = 1 + p$，GARCH(1,1) 模型的 $k = 3$，样本量 $n = T$。\n4.  当数据由 GARCH(1,1) 生成时，如果 ARCH($p$) 的 BIC 严格小于 GARCH(1,1) 的 BIC，则定义模拟数据集“欺骗”了标准 ARCH($p$) 模型的指标为一个布尔值，该值为真。也就是说，如果 $\\mathrm{BIC}_{\\mathrm{ARCH}(p)} < \\mathrm{BIC}_{\\mathrm{GARCH}(1,1)}$，则输出 true。\n\n实现要求和数值细节：\n\n-   在评估两个模型的似然时，使用与当前参数猜测值相关联的无条件方差来初始化递推。对于 ARCH($p$) 似然递推，当 $i > t$ 时，使用此无条件方差初始化样本前的平方收益率 $r_{t-i}^2$。\n-   模拟时使用标准正态新息。\n-   确保在模拟和似然评估的所有时间步中，条件方差保持严格为正。\n-   使用任意确定性数值优化程序来最大化每个模型的高斯对数似然，并通过对无约束参数进行光滑变换来强制执行约束。\n\n测试套件：\n\n对于以下三个参数集中的每一个，运行上述完整的模拟-估计-选择流程，并返回一个布尔结果，指示 ARCH($p$) 模型是否被 BIC 选择优于 GARCH(1,1) 模型：\n\n-   测试用例 1（理想情况，低持续性）：$T = 1200$, $\\omega = 0.05$, $\\alpha = 0.08$, $\\beta = 0.18$, $p = 1$, 模拟种子 $= 11$。\n-   测试用例 2（较小样本）：$T = 800$, $\\omega = 0.10$, $\\alpha = 0.05$, $\\beta = 0.25$, $p = 1$, 模拟种子 $= 22$。\n-   测试用例 3（接近白噪声的波动率）：$T = 1000$, $\\omega = 0.02$, $\\alpha = 0.03$, $\\beta = 0.05$, $p = 1$, 模拟种子 $= 33$。\n\n最终输出格式：\n\n-   您的程序应生成单行输出，其中包含对应于三个测试用例的三个布尔结果，格式为逗号分隔的列表，并用方括号括起来（例如，\"[True,False,True]\"）。", "solution": "该问题要求在金融计量经济学中实现一个数值实验。目标是评估贝叶斯信息准则（BIC）在 GARCH($1,1$) 模型和更简单的 ARCH($p$) 模型之间的选择性能，而数据实际上是由一个低持续性的 GARCH($1,1$) 过程生成的。这个练习对于理解模型设定错误以及模型简约性与拟合优度之间的权衡至关重要。\n\n该过程将对每个指定的测试用例执行，遵循一个严格的三步流程：数据模拟、模型估计和模型选择。\n\n**1. 数据模拟**\n\n此分析的基础是一个模拟的金融收益率序列 $\\{r_t\\}_{t=1}^T$。该序列由一个 GARCH($1,1$) 过程生成，由以下方程定义：\n$$\nr_t = \\sigma_t z_t\n$$\n$$\n\\sigma_t^2 = \\omega + \\alpha r_{t-1}^2 + \\beta \\sigma_{t-1}^2\n$$\n其中 $\\{z_t\\}_{t=1}^T$ 是从标准正态分布 $z_t \\sim \\mathcal{N}(0, 1)$ 中抽取的独立同分布（i.i.d.）随机变量序列。参数 $(\\omega, \\alpha, \\beta)$ 为每个测试用例提供，并满足协方差平稳性条件：$\\omega > 0$, $\\alpha \\ge 0$, $\\beta \\ge 0$, 以及 $\\alpha + \\beta < 1$。\n\n为了减轻初始条件对生成序列的影响，我们首先模拟一个长度为 $T + B$ 的较长序列，其中 $T$ 是期望的样本量，而 $B = 1000$ 是预烧期。递推使用过程的无条件方差进行初始化，即 $\\sigma_0^2 = \\frac{\\omega}{1 - \\alpha - \\beta}$。然后丢弃前 $B$ 个模拟观测值，留下最后的序列 $\\{r_t\\}_{t=1}^T$ 用于分析。\n\n**2. 通过准极大似然（QMLE）进行参数估计**\n\n对于每个模拟序列，我们拟合两个竞争模型：一个 ARCH($p$) 模型和一个 GARCH($1,1$) 模型。估计通过最大化高斯准对数似然函数来执行。假设新息为高斯分布，对于给定参数向量 $\\theta$ 的大小为 $T$ 的样本，其对数似然为：\n$$\n\\ell_T(\\theta) = -\\frac{1}{2} \\sum_{t=1}^T \\left( \\log(2\\pi) + \\log\\left(\\sigma_t^2(\\theta)\\right) + \\frac{r_t^2}{\\sigma_t^2(\\theta)} \\right)\n$$\n最大化 $\\ell_T(\\theta)$ 等价于最小化其负值。为了优化的目的，常数项 $-\\frac{T}{2}\\log(2\\pi)$ 可以被忽略，因为它不影响最大值的位置。因此，要最小化的目标函数是：\n$$\n\\mathcal{L}(\\theta) = \\sum_{t=1}^T \\left( \\log\\left(\\sigma_t^2(\\theta)\\right) + \\frac{r_t^2}{\\sigma_t^2(\\theta)} \\right)\n$$\n估计的一个关键方面是强制执行方差正值性和平稳性所需的参数约束。这通过光滑、可微的重参数化来实现，它允许一个无约束的数值优化器在有效的参数空间内搜索。\n\n对于 GARCH($1,1$) 模型，参数为 $\\theta_{GARCH} = (\\omega, \\alpha, \\beta)$。约束条件是 $\\omega > 0$, $\\alpha \\ge 0$, $\\beta \\ge 0$, 以及 $\\alpha + \\beta < 1$。我们将一个无约束的向量 $\\psi = (\\psi_0, \\psi_1, \\psi_2) \\in \\mathbb{R}^3$ 映射到约束空间，如下所示：\n- $\\omega = \\exp(\\psi_0)$\n- $\\alpha = \\frac{\\psi_1^2}{1 + \\psi_1^2}$\n- $\\beta = \\left(1 - \\alpha\\right) \\frac{\\psi_2^2}{1 + \\psi_2^2}$\n这种构造保证了所有约束都得到满足。\n\n对于 ARCH($p$) 模型，其中所有测试用例的 $p=1$，参数为 $\\theta_{ARCH} = (\\omega, \\alpha_1)$。约束条件是 $\\omega > 0$, $0 \\le \\alpha_1 < 1$。我们从一个无约束的向量 $\\phi = (\\phi_0, \\phi_1) \\in \\mathbb{R}^2$ 进行映射：\n- $\\omega = \\exp(\\phi_0)$\n- $\\alpha_1 = \\frac{\\exp(\\phi_1)}{1 + \\exp(\\phi_1)}$\n这种变换确保了 $\\omega > 0$ 且 $\\alpha_1 \\in (0, 1)$。\n\n在优化程序中每次评估似然函数时，必须计算条件方差序列 $\\{\\sigma_t^2(\\theta)\\}_{t=1}^T$。递推使用*当前*参数猜测值 $\\theta$ 所隐含的无条件方差进行初始化。对于 GARCH($1,1$)，样本前的 $r_0^2$ 和 $\\sigma_0^2$ 值被设置为 $\\frac{\\omega}{1-\\alpha-\\beta}$。对于 ARCH($1$)，样本前的 $r_0^2$ 被设置为 $\\frac{\\omega}{1-\\alpha_1}$。\n\n**3. 通过贝叶斯信息准则（BIC）进行模型选择**\n\n在获得每个模型的最大化对数似然值 $\\ell_T(\\hat{\\theta})$ 后，我们计算 BIC：\n$$\n\\mathrm{BIC} = -2 \\ell_T(\\hat{\\theta}) + k \\log(n)\n$$\n其中 $\\hat{\\theta}$ 是估计参数的向量，$k$ 是模型中自由参数的数量，$n=T$ 是样本量。BIC 对模型的复杂性进行惩罚，其中 $k \\log(n)$ 项代表惩罚。较低的 BIC 值表示更优选的模型。\n- 对于 ARCH($p$) 模型，$k = p + 1$。由于 $p=1$, $k_{ARCH} = 2$。\n- 对于 GARCH($1,1$) 模型，$k_{GARCH} = 3$。\n\n每个测试用例的最终输出是一个布尔值，指示 ARCH($p$) 模型是否“欺骗”了选择准则。如果其 BIC 严格小于 GARCH($1,1$) 模型的 BIC，即 $\\mathrm{BIC}_{\\mathrm{ARCH}(p)} < \\mathrm{BIC}_{\\mathrm{GARCH}(1,1)}$，则该值为真。这一结果表明，尽管数据源自 GARCH 过程，但由于 BIC 对 GARCH 模型额外参数的惩罚，更简约的 ARCH 模型被偏爱。当真实的 GARCH 过程具有低持续性（$\\alpha+\\beta$ 较小）时，这种情况更有可能发生，这使得它难以与更简单的 ARCH 过程区分开来，尤其是在样本量较小的情况下。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef simulate_garch11(T, B, omega, alpha, beta, seed):\n    \"\"\"\n    Simulates a GARCH(1,1) process.\n    \"\"\"\n    np.random.seed(seed)\n    total_len = T + B\n    \n    # Generate standard normal innovations\n    z = np.random.randn(total_len)\n    \n    r = np.zeros(total_len)\n    sigma2 = np.zeros(total_len)\n    \n    # Initial variance (unconditional variance)\n    uncond_var = omega / (1 - alpha - beta)\n    sigma2_t_minus_1 = uncond_var\n    # Use E[r_{t-1}^2] = sigma_{t-1}^2 for initialization of first r_t\n    r_t_minus_1_sq = uncond_var\n    \n    for t in range(total_len):\n        sigma2[t] = omega + alpha * r_t_minus_1_sq + beta * sigma2_t_minus_1\n        r[t] = np.sqrt(sigma2[t]) * z[t]\n        \n        sigma2_t_minus_1 = sigma2[t]\n        r_t_minus_1_sq = r[t]**2\n        \n    # Discard burn-in period\n    return r[B:]\n\ndef garch11_neg_loglike_factory(r):\n    \"\"\"\n    Factory for the negative log-likelihood of a GARCH(1,1) model.\n    \"\"\"\n    T = len(r)\n    r_sq = r**2\n\n    def neg_loglike(unconstrained_params):\n        # 1. Reparameterize to enforce constraints\n        psi_0, psi_1, psi_2 = unconstrained_params\n        omega = np.exp(psi_0)\n        # alpha is in [0, 1)\n        alpha = psi_1**2 / (1 + psi_1**2)\n        # beta is in [0, 1-alpha)\n        beta = (1 - alpha) * (psi_2**2 / (1 + psi_2**2))\n        \n        # 2. Check for stationarity to avoid division by zero\n        if (alpha + beta) >= 1.0:\n            return 1e9 # Return a large value if non-stationary\n\n        # 3. Calculate conditional variances\n        sigma2 = np.zeros(T)\n        uncond_var = omega / (1 - alpha - beta)\n        \n        # Initialize with unconditional variance\n        sigma2[0] = omega + alpha * uncond_var + beta * uncond_var\n        \n        for t in range(1, T):\n            sigma2[t] = omega + alpha * r_sq[t-1] + beta * sigma2[t-1]\n\n        # Prevent numerical issues with very small variances\n        sigma2 = np.maximum(sigma2, 1e-9)\n\n        # 4. Calculate log-likelihood\n        log_likelihood_sum = np.sum(np.log(sigma2) + r_sq / sigma2)\n        \n        return 0.5 * log_likelihood_sum\n\n    return neg_loglike\n\ndef arch1_neg_loglike_factory(r):\n    \"\"\"\n    Factory for the negative log-likelihood of an ARCH(1) model.\n    \"\"\"\n    T = len(r)\n    r_sq = r**2\n\n    def neg_loglike(unconstrained_params):\n        # 1. Reparameterize to enforce constraints\n        phi_0, phi_1 = unconstrained_params\n        omega = np.exp(phi_0)\n        # alpha1 is in (0, 1)\n        alpha1 = np.exp(phi_1) / (1 + np.exp(phi_1))\n\n        # 2. Check for stationarity\n        if alpha1 >= 1.0:\n            return 1e9\n        \n        # 3. Calculate conditional variances\n        sigma2 = np.zeros(T)\n        uncond_var = omega / (1 - alpha1)\n        \n        # Initialize with unconditional variance for pre-sample r_0^2\n        sigma2[0] = omega + alpha1 * uncond_var\n        \n        for t in range(1, T):\n            sigma2[t] = omega + alpha1 * r_sq[t-1]\n        \n        # Prevent numerical issues\n        sigma2 = np.maximum(sigma2, 1e-9)\n\n        # 4. Calculate log-likelihood\n        log_likelihood_sum = np.sum(np.log(sigma2) + r_sq / sigma2)\n        \n        return 0.5 * log_likelihood_sum\n\n    return neg_loglike\n    \ndef solve():\n    \"\"\"\n    Main function to run test cases and generate final output.\n    \"\"\"\n    test_cases = [\n        # T, omega, alpha, beta, p, seed\n        (1200, 0.05, 0.08, 0.18, 1, 11),\n        (800, 0.10, 0.05, 0.25, 1, 22),\n        (1000, 0.02, 0.03, 0.05, 1, 33),\n    ]\n\n    results = []\n    B = 1000 # Burn-in period\n\n    for case in test_cases:\n        T, omega_true, alpha_true, beta_true, p, seed = case\n        \n        # 1. Simulate data from GARCH(1,1)\n        r_sim = simulate_garch11(T, B, omega_true, alpha_true, beta_true, seed)\n        \n        # 2. Fit GARCH(1,1) model\n        garch_objective = garch11_neg_loglike_factory(r_sim)\n        # Initial guess for unconstrained params (psi_0, psi_1, psi_2)\n        # Corresponds roughly to omega=0.1, alpha=0.1, beta=0.8\n        x0_garch = [-2.3, 0.33, 2.8] \n        garch_res = minimize(garch_objective, x0_garch, method='BFGS')\n        \n        # maximized log-likelihood value (without constant)\n        min_neg_ll_garch = garch_res.fun\n        \n        # 3. Fit ARCH(p) model (here p=1)\n        arch_objective = arch1_neg_loglike_factory(r_sim)\n        # Initial guess for unconstrained params (phi_0, phi_1)\n        # Corresponds roughly to omega=0.1, alpha1=0.2\n        x0_arch = [-2.3, -1.38] \n        arch_res = minimize(arch_objective, x0_arch, method='BFGS')\n        \n        min_neg_ll_arch = arch_res.fun\n\n        # 4. Compute BIC for both models\n        k_garch = 3\n        # We need 2 * min_neg_ll since optimizer minimizes 0.5 * sum(...)\n        # The constant part of log-likelihood cancels out in comparison\n        bic_garch = 2 * min_neg_ll_garch + k_garch * np.log(T)\n        \n        k_arch = 1 + p\n        bic_arch = 2 * min_neg_ll_arch + k_arch * np.log(T)\n        \n        # 5. Compare BICs and record result\n        # True if ARCH(p) is wrongly selected\n        results.append(bic_arch < bic_garch)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2373512"}, {"introduction": "估计完模型后，建模流程的最后一步是诊断检验：我们如何确定模型已经充分捕捉了数据的动态特征？本练习将重点放在模型诊断上，特别是使用Ljung-Box检验来检查模型残差中是否存在未被解释的ARCH效应。你将从头开始实现这一重要的诊断工具，并通过分析精心设计的案例——包括模型设定正确、设定错误以及诊断工具可能失效的情景——来学习如何有效地评估你的GARCH模型，并认识到任何诊断工具的潜在局限性 [@problem_id:2395745]。", "problem": "您的任务是构建一个完整的程序，该程序用于估计一个广义自回归条件异方差（GARCH）模型，并对标准化残差的平方应用Ljung-Box诊断检验，以检测残余的自回归条件异方差（ARCH）效应。该程序必须基于核心定义，从基本原理出发，实现以下组成部分：(i) 在高斯假设下通过最大似然法估计GARCH模型，(ii) 使用估计的条件方差序列构建标准化残差，以及 (iii) 使用由标准化残差派生的变换序列的样本自相关系数来计算Ljung-Box检验统计量。程序不得依赖任何预打包的GARCH或诊断例程，并且必须在固定的伪随机种子下可复现。\n\n考虑一个单变量零均值收益率序列 $\\{r_t\\}_{t=1}^T$，其条件方差为 $\\{\\sigma_t^2\\}_{t=1}^T$。GARCH模型将条件方差指定为一个由过去的扰动项平方和过去的条件方差驱动的递归。标准化残差的定义是将每个扰动项除以其条件方差的平方根。Ljung-Box诊断是一种综合检验（portmanteau test），用于评估一个序列的样本自相关系数在一组滞后阶数上是否共同为零。在适当的原假设和渐近性条件下，Ljung-Box统计量服从一个参考分布，从而可以计算用于在给定显著性水平下做出决策规则的尾部概率。\n\n对于下面套件中的每个测试用例，您的程序必须执行以下操作：\n1. 使用指定的条件方差递归和正态扰动项模拟一个收益率序列。使用固定的伪随机种子 $12345$ 和一个正的预烧期，之后再收集最后的 $T$ 个观测值，以减少初始化效应。\n2. 对模拟序列拟合一个GARCH($1,1$)模型，方法是在高斯似然下进行准最大似然估计（QMLE），同时对参数施加正性约束和严格平稳性类型的界限。\n3. 通过将每个扰动项除以该时刻拟合的条件方差的平方根来计算标准化残差。\n4. 对标准化残差的平方应用Ljung-Box检验，使用该测试用例指定的的最大滞后阶数 $m$。使用基于样本协方差的样本自相关系数的标准定义，并利用大样本参考分布来获得尾部概率。如果此尾部概率严格小于显著性水平 $\\alpha = 0.05$，则决定拒绝原假设。\n5. 为每个测试用例记录一个布尔结果，指明诊断检验是否在指定的滞后阶数上拒绝了“标准化残差的平方中不存在残余自相关”的原假设。\n\n测试套件：\n- 案例A（设定正确的基准，理想路径）：\n  - 数据生成过程：GARCH($1,1$)，参数为 $(\\omega,\\alpha,\\beta) = (0.05,0.05,0.90)$。\n  - 样本大小：$T=3000$。\n  - Ljung-Box最大滞后阶数：$m=20$。\n- 案例B（设定错误的模型，存在应被检测出的残余ARCH效应）：\n  - 数据生成过程：GARCH($2,1$)，参数为 $(\\omega,\\alpha_1,\\alpha_2,\\beta) = (0.02,0.04,0.08,0.86)$。\n  - 样本大小：$T=4000$。\n  - Ljung-Box最大滞后阶数：$m=20$。\n- 案例C（设定错误的模型，由于滞后截断选择不当和样本量有限，Ljung-Box检验可能无法检测到残余ARCH效应）：\n  - 数据生成过程：一个在滞后阶数 $L=10$ 处具有单一长滞后效应的ARCH过程，定义为 $\\sigma_t^2 = \\omega + a_L \\cdot r_{t-L}^2$，参数为 $(\\omega,a_L)=(0.05,0.80)$。\n  - 样本大小：$T=800$。\n  - Ljung-Box最大滞后阶数：$m=1$。\n\n实现细节：\n- 在估计中使用高斯似然，在模拟中使用高斯扰动项。明确约束GARCH($1,1$)参数 $(\\omega,\\alpha,\\beta)$ 满足 $\\omega>0$、$\\alpha\\ge 0$、$\\beta\\ge 0$ 和 $\\alpha+\\beta<1$。\n- 使用从估计的GARCH($1,1$)模型得到的拟合条件方差路径来标准化残差。\n- 基于中心化数据的标准定义实现Ljung-Box统计量，并在 $m$ 个滞后阶数下的大样本参考分布下推导尾部概率。\n- 在所有模拟中，保留最后 $T$ 个观测值之前，使用至少 $1000$ 个观测值的预烧期。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中按顺序包含案例A、B和C的三个布尔决策，格式为用方括号括起来的逗号分隔列表，例如 $[True,False,True]$。\n\n您的答案必须是一个完整的、可运行的程序。不需要也不允许用户输入。此问题不涉及物理单位；所有数值输出均为指定列表格式的无量纲布尔值。", "solution": "所提出的问题是计算计量经济学中一个明确定义的练习，要求实现GARCH模型分析的完整流程。它基于已有的时间序列分析理论，具有科学依据，本身是自洽的，并提出了一个客观、可形式化的任务。问题没有可识别的缺陷；因此，有必要给出一个严谨的解法。\n\n该解决方案涉及几个连续的步骤：数据模拟、通过准最大似然估计（QMLE）进行模型估计、计算标准化残差，以及使用Ljung-Box检验进行诊断性检验。\n\n对于一个零均值收益率序列 $\\{r_t\\}$，一个通用的GARCH($p,q$)过程由以下方程定义：\n$$ r_t = \\sigma_t z_t $$\n$$ \\sigma_t^2 = \\omega + \\sum_{i=1}^{q} \\alpha_i r_{t-i}^2 + \\sum_{j=1}^{p} \\beta_j \\sigma_{t-j}^2 $$\n这里，$\\{z_t\\}$ 是一个独立同分布（i.i.d.）的随机变量序列，其均值为零，方差为一。我们假设其服从标准正态分布，$z_t \\sim N(0,1)$。参数必须满足 $\\omega > 0$、$\\alpha_i \\ge 0$ 和 $\\beta_j \\ge 0$ 以确保方差非负。为了使条件方差过程是弱平稳的，需要满足条件 $\\sum_{i=1}^{q} \\alpha_i + \\sum_{j=1}^{p} \\beta_j < 1$。\n\n问题要求估计一个GARCH($1,1$)模型，其条件方差递归简化为：\n$$ \\sigma_t^2 = \\omega + \\alpha r_{t-1}^2 + \\beta \\sigma_{t-1}^2 $$\n待估计的参数向量是 $\\theta = (\\omega, \\alpha, \\beta)$。\n\n估计采用QMLE方法。假设扰动项是条件正态的，在信息集 $\\mathcal{F}_{t-1}$ 的条件下，观测值 $t$ 的对数似然为：\n$$ l_t(\\theta) = -\\frac{1}{2}\\log(2\\pi) - \\frac{1}{2}\\log(\\sigma_t^2(\\theta)) - \\frac{r_t^2}{2\\sigma_t^2(\\theta)} $$\n大小为 $T$ 的样本的总对数似然是总和 $\\mathcal{L}(\\theta) = \\sum_{t=1}^T l_t(\\theta)$。QMLE估计量 $\\hat{\\theta}$ 是在参数约束下最大化 $\\mathcal{L}(\\theta)$ 的 $\\theta$ 值。这等价于最小化负对数似然 $-\\mathcal{L}(\\theta)$。优化过程通过数值方法执行，通常使用诸如L-BFGS-B的拟牛顿法，该方法可以处理参数的箱式约束。严格的平稳性类型约束 $\\alpha + \\beta < 1$ 在目标函数中通过在其被违反时返回一个无穷大惩罚项来强制执行。$\\sigma_t^2$ 的递归通过将 $\\sigma_1^2$ 设置为收益率序列的样本方差来初始化，这是一种常见且稳健的做法。\n\n一旦估计出参数 $\\hat{\\theta} = (\\hat{\\omega}, \\hat{\\alpha}, \\hat{\\beta})$，就使用这些估计值和GARCH($1,1$)递归构建拟合的条件方差序列 $\\{\\hat{\\sigma}_t^2\\}_{t=1}^T$。然后，标准化残差计算如下：\n$$ \\hat{\\epsilon}_t = \\frac{r_t}{\\hat{\\sigma}_t} $$\n如果GARCH($1,1$)模型设定正确，序列 $\\{\\hat{\\epsilon}_t\\}$ 应近似为i.i.d.且方差为一。因此，平方标准化残差 $\\{\\hat{\\epsilon}_t^2\\}$ 应不表现出显著的自相关性。\n\n为了检验这个假设，我们对序列 $x_t = \\hat{\\epsilon}_t^2$ 使用Ljung-Box检验。首先，我们计算 $\\{x_t\\}$ 的样本自相关系数，直至指定的最大滞后阶数 $m$。滞后 $k > 0$ 的样本自相关系数定义为：\n$$ \\hat{\\rho}_k = \\frac{\\sum_{t=k+1}^T (x_t - \\bar{x})(x_{t-k} - \\bar{x})}{\\sum_{t=1}^T (x_t - \\bar{x})^2} $$\n其中 $\\bar{x}$ 是 $\\{x_t\\}$ 的样本均值。\n\n然后计算Ljung-Box Q统计量：\n$$ Q = T(T+2) \\sum_{k=1}^m \\frac{\\hat{\\rho}_k^2}{T-k} $$\n在原假设（$H_0$）下，即序列中没有自相关（即 $\\rho_1 = \\dots = \\rho_m = 0$），统计量 $Q$ 渐近服从自由度为 $m$ 的卡方分布，$Q \\sim \\chi^2(m)$。我们计算p值 $P(\\chi^2(m) > Q_{\\text{obs}})$，其中 $Q_{\\text{obs}}$ 是该统计量的观测值。如果这个p值严格小于指定的显著性水平 $\\alpha = 0.05$，我们就拒绝原假设，表明存在残余的ARCH效应。\n\n整个过程将应用于三个测试案例：\n1.  **案例A**：数据由GARCH($1,1$)过程生成，并拟合GARCH($1,1$)模型。这是一个设定正确的案例，我们预期诊断检验将未能拒绝原假设。\n2.  **案例B**：数据由GARCH($2,1$)过程生成，但拟合的是GARCH($1,1$)模型。这种模型设定错误预计会留下未被捕捉到的动态特征，导致平方标准化残差中存在自相关。我们预期Ljung-Box检验将拒绝原假设。\n3.  **案例C**：数据由一个在滞后 $L=10$ 处具有特定滞后结构的ARCH过程生成。我们拟合一个GARCH($1,1$)模型，并应用最大滞后仅为 $m=1$ 的Ljung-Box检验。该检验不适合检测这种特定形式的模型设定错误，因为它只检查了滞后1。我们预期该检验将未能拒绝原假设，从而展示了诊断工具在配置不当时存在的局限性。\n\n实现过程将把这些组件综合到一个单独的程序中，该程序对所有三个案例执行分析，并报告每个案例的布尔决策（拒绝/未能拒绝）。", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import chi2\n\ndef simulate_series(omega, alpha_coeffs, beta_coeffs, T, burn_in, seed):\n    \"\"\"\n    Simulates a time series from a general GARCH(p,q) process.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    q = len(alpha_coeffs)\n    p = len(beta_coeffs)\n    total_T = T + burn_in\n\n    r = np.zeros(total_T)\n    sigma2 = np.zeros(total_T)\n    z = rng.normal(size=total_T)\n\n    # Initialize with unconditional variance, assuming stationarity\n    uncond_var_denom = 1.0 - np.sum(alpha_coeffs) - np.sum(beta_coeffs)\n    # Ensure denominator is positive, preventing division by zero for non-stationary cases\n    uncond_var = omega / uncond_var_denom if uncond_var_denom > 0 else 1.0\n\n    # max_lag is the number of past values needed for the recursion\n    max_lag = max(p, q)\n    if max_lag == 0: # handle simple case of constant variance\n        r = np.sqrt(omega) * z\n        return r[burn_in:]\n\n    sigma2[:max_lag] = uncond_var\n    r[:max_lag] = np.sqrt(sigma2[:max_lag]) * z[:max_lag]\n    \n    # Convert lists to numpy arrays for vectorized operations\n    alpha_arr = np.array(alpha_coeffs)\n    beta_arr = np.array(beta_coeffs)\n\n    for t in range(max_lag, total_T):\n        arch_term = np.sum(alpha_arr * np.flip(r[t-q:t]**2)) if q > 0 else 0\n        garch_term = np.sum(beta_arr * np.flip(sigma2[t-p:t])) if p > 0 else 0\n        sigma2[t] = omega + arch_term + garch_term\n        r[t] = np.sqrt(max(1e-9, sigma2[t])) * z[t] # Failsafe for numerical stability\n\n    return r[burn_in:]\n\n\ndef garch11_neg_log_likelihood(params, r_series):\n    \"\"\"\n    Computes the negative of the log-likelihood for a GARCH(1,1) model.\n    \"\"\"\n    omega, alpha, beta = params\n    \n    # Parameter constraints\n    if omega <= 0 or alpha < 0 or beta < 0 or (alpha + beta) >= 1.0:\n        return np.inf\n\n    T = len(r_series)\n    sigma2 = np.zeros(T)\n    \n    # Initialize variance with sample variance\n    sigma2[0] = np.var(r_series)\n\n    for t in range(1, T):\n        sigma2[t] = omega + alpha * r_series[t-1]**2 + beta * sigma2[t-1]\n    \n    # Add a small constant to sigma2 to avoid log(0)\n    sigma2[sigma2 <= 0] = 1e-9\n\n    log_likelihood = -0.5 * np.sum(np.log(2 * np.pi) + np.log(sigma2) + r_series**2 / sigma2)\n    \n    return -log_likelihood\n\n\ndef estimate_garch11(r_series):\n    \"\"\"\n    Estimates GARCH(1,1) parameters using QMLE.\n    \"\"\"\n    initial_params = np.array([np.var(r_series)*0.05, 0.05, 0.9])\n    bounds = [(1e-9, None), (0, 1), (0, 1)]\n    \n    result = minimize(garch11_neg_log_likelihood, initial_params, args=(r_series,),\n                      method='L-BFGS-B', bounds=bounds)\n    \n    return result.x\n\n\ndef ljung_box_test(series, m):\n    \"\"\"\n    Computes the Ljung-Box Q-statistic and its p-value.\n    \"\"\"\n    T = len(series)\n    x_mean = np.mean(series)\n    \n    # Sample variance (autocovariance at lag 0)\n    gamma0 = np.sum((series - x_mean)**2) / T\n    if gamma0 == 0:\n        return 1.0 # No variation, so no autocorrelation\n    \n    acf_sq_terms = []\n    for k in range(1, m + 1):\n        # Sample autocovariance at lag k\n        gamma_k = np.sum((series[k:] - x_mean) * (series[:-k] - x_mean)) / T\n        rho_k = gamma_k / gamma0\n        acf_sq_terms.append(rho_k**2 / (T - k))\n        \n    Q = T * (T + 2) * np.sum(acf_sq_terms)\n    \n    # p-value from chi-squared distribution\n    p_value = chi2.sf(Q, df=m)\n    return p_value\n\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final result.\n    \"\"\"\n    burn_in = 1000\n    seed = 12345\n    alpha_level = 0.05\n\n    test_cases = [\n        {\n            'name': 'Case A',\n            'dgp_params': {'omega': 0.05, 'alpha': [0.05], 'beta': [0.90]},\n            'T': 3000,\n            'm': 20\n        },\n        {\n            'name': 'Case B',\n            'dgp_params': {'omega': 0.02, 'alpha': [0.04, 0.08], 'beta': [0.86]},\n            'T': 4000,\n            'm': 20\n        },\n        {\n            'name': 'Case C',\n            'dgp_params': {'omega': 0.05, 'alpha': [0]*9 + [0.80], 'beta': []},\n            'T': 800,\n            'm': 1\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        # 1. Simulate return series\n        dgp = case['dgp_params']\n        r_series = simulate_series(dgp['omega'], dgp['alpha'], dgp['beta'], case['T'], burn_in, seed)\n        \n        # 2. Fit GARCH(1,1) model\n        est_omega, est_alpha, est_beta = estimate_garch11(r_series)\n        \n        # 3. Compute standardized residuals\n        T = case['T']\n        sigma2_hat = np.zeros(T)\n        sigma2_hat[0] = np.var(r_series)\n        for t in range(1, T):\n            sigma2_hat[t] = est_omega + est_alpha * r_series[t-1]**2 + est_beta * sigma2_hat[t-1]\n        \n        std_residuals = r_series / np.sqrt(np.maximum(1e-9, sigma2_hat))\n        sq_std_residuals = std_residuals**2\n        \n        # 4. Apply Ljung-Box test\n        p_value = ljung_box_test(sq_std_residuals, case['m'])\n        \n        # 5. Record boolean decision\n        reject_null = p_value < alpha_level\n        results.append(reject_null)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2395745"}]}