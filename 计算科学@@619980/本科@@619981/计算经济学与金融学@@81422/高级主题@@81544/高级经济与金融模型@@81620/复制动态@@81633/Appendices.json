{"hands_on_practices": [{"introduction": "理论学习之后，最好的巩固方式就是动手实践。本章节将引导你通过一系列精心设计的练习，将复制子动态的抽象概念应用于具体的经济和金融场景。我们将从一个基础的分析性问题开始。这个练习模拟了一个由基金经理组成的市场，其中不同的交易策略会产生不同的收益和成本。你的任务是计算达到稳定状态时，采取特定策略的基金经理所占的比例。通过这个练习 [@problem_id:2427005]，你将掌握寻找内部均衡点的核心技能，即当不同策略的净收益（收益减去成本）相等时，它们可以在群体中稳定共存。", "problem": "一个庞大的基金经理群体在随机配对中重复互动。在给定时期内，每位经理都承诺采用两种交易规则之一（策略 $1$ 或策略 $2$）。该互动根据一个支付矩阵为 $A \\in \\mathbb{R}^{2 \\times 2}$ 的博弈产生收益，并且每个策略 $i \\in \\{1,2\\}$ 都会产生固定的周期性成本 $c_{i}$。在种群状态 $x \\in \\Delta^{2}$ 时，策略 $i$ 的适应度由下式给出\n$$\nF_{i}(x) \\equiv (A x)_{i} - c_{i}.\n$$\n种群根据复制动态演化，\n$$\n\\dot{x}_{i} \\;=\\; x_{i}\\big(F_{i}(x) - \\bar{F}(x)\\big), \\quad \\text{其中 } \\bar{F}(x) \\equiv \\sum_{j=1}^{2} x_{j}F_{j}(x).\n$$\n令 $x=(p,1-p)$，其中 $p \\in (0,1)$ 表示使用策略 $1$ 的份额。考虑\n$$\nA \\;=\\; \\begin{pmatrix}\n4 & 1 \\\\\n3 & 2\n\\end{pmatrix},\n\\qquad\nc \\;=\\; \\begin{pmatrix}\n0.5 \\\\\n0.1\n\\end{pmatrix}.\n$$\n假设存在一个唯一的复制动态内部稳态，其中两种策略都被使用，即 $p^{\\ast} \\in (0,1)$。确定在此内部稳态下，策略 $1$ 的平稳份额 $p^{\\ast}$。请用一个精确的数字表示您的答案，不要四舍五入。", "solution": "所陈述的问题经过了严格的验证。\n\n第一步：提取已知条件。\n- 一个代理人群体使用两种策略之一，$\\{1, 2\\}$。\n- 互动由一个支付矩阵 $A = \\begin{pmatrix} 4 & 1 \\\\ 3 & 2 \\end{pmatrix}$ 决定。\n- 每个策略 $i$ 产生一个固定成本 $c_i$，其中 $c = \\begin{pmatrix} 0.5 \\\\ 0.1 \\end{pmatrix}$。\n- 策略 $i$ 的适应度为 $F_{i}(x) \\equiv (A x)_{i} - c_{i}$，其中 $x \\in \\Delta^{2}$ 是种群状态。\n- 种群状态表示为 $x = (p, 1-p)$，其中 $p \\in (0,1)$ 是使用策略 $1$ 的份额。\n- 动态由复制者方程描述：$\\dot{x}_{i} = x_{i}(F_{i}(x) - \\bar{F}(x))$，其中 $\\bar{F}(x) = \\sum_{j=1}^{2} x_{j}F_{j}(x)$。\n- 假设存在一个唯一的内部稳态 $p^{\\ast} \\in (0,1)$。\n- 目标是确定这个平稳份额 $p^{\\ast}$。\n\n第二步：验证。\n- **科学依据**：该问题基于复制动态的标准模型，这是演化博弈论和计算经济学中的一个基本概念。该模型在数学上和科学上都是合理的。\n- **适定性**：该问题提供了所有必要的数据和定义（$A$、$c$、$F_i(x)$、复制者方程），并明确假设待求的内部稳态存在且唯一。这使得该问题是适定的。\n- **客观性**：该问题以精确、客观的数学语言陈述，没有歧义或主观内容。\n\n第三步：结论。\n该问题具有科学依据、适定性和客观性。它被判定为**有效**。将推导求解。\n\n复制动态的一个平稳状态（或不动点）是一个状态 $x^{\\ast}$，在该状态下，种群份额不随时间变化，即对于所有策略 $i$，都有 $\\dot{x}_i = 0$。对于一个内部稳态，所有策略都存在于种群中，意味着对所有 $i$ 都有 $x_i > 0$。在这个具体案例中，我们有 $x = (p, 1-p)$ 且 $p \\in (0,1)$，因此 $x_1 > 0$ 且 $x_2 > 0$。\n\n复制动态方程为 $\\dot{x}_{i} = x_{i}(F_{i}(x) - \\bar{F}(x))$。对于 $x_i \\neq 0$ 的内部状态，$\\dot{x}_i = 0$ 的条件要求策略 $i$ 的适应度等于种群的平均适应度：$F_i(x) = \\bar{F}(x)$。\n由于这对种群中存在的所有策略都必须成立，这意味着在一个内部不动点上，所有活跃策略的适应度必须相等。对于双策略情况，该条件简化为：\n$$\nF_{1}(x^{\\ast}) = F_{2}(x^{\\ast})\n$$\n其中 $x^{\\ast} = (p^{\\ast}, 1-p^{\\ast})$ 表示平稳状态。\n\n我们已知种群状态向量 $x$、支付矩阵 $A$ 和成本向量 $c$：\n$$\nx = \\begin{pmatrix} p \\\\ 1-p \\end{pmatrix}, \\quad A = \\begin{pmatrix} 4 & 1 \\\\ 3 & 2 \\end{pmatrix}, \\quad c = \\begin{pmatrix} 0.5 \\\\ 0.1 \\end{pmatrix}\n$$\n策略 $i$ 的适应度函数定义为 $F_{i}(x) = (A x)_{i} - c_{i}$。首先，我们计算期望支付 $(Ax)_i$：\n$$\nAx = \\begin{pmatrix} 4 & 1 \\\\ 3 & 2 \\end{pmatrix} \\begin{pmatrix} p \\\\ 1-p \\end{pmatrix} = \\begin{pmatrix} 4p + 1(1-p) \\\\ 3p + 2(1-p) \\end{pmatrix} = \\begin{pmatrix} 3p + 1 \\\\ p + 2 \\end{pmatrix}\n$$\n因此，使用策略 $1$ 的个体的期望支付是 $(Ax)_1 = 3p+1$，而使用策略 $2$ 的个体的期望支付是 $(Ax)_2 = p+2$。\n\n现在，我们可以通过减去成本来写出适应度函数：\n$$\nF_{1}(x) = (Ax)_1 - c_1 = (3p + 1) - 0.5 = 3p + 0.5\n$$\n$$\nF_{2}(x) = (Ax)_2 - c_2 = (p + 2) - 0.1 = p + 1.9\n$$\n为了找到内部平稳份额 $p^{\\ast}$，我们令适应度相等，$F_{1}(x^{\\ast}) = F_{2}(x^{\\ast})$：\n$$\n3p^{\\ast} + 0.5 = p^{\\ast} + 1.9\n$$\n我们求解这个关于 $p^{\\ast}$ 的线性方程：\n$$\n3p^{\\ast} - p^{\\ast} = 1.9 - 0.5\n$$\n$$\n2p^{\\ast} = 1.4\n$$\n$$\np^{\\ast} = \\frac{1.4}{2} = 0.7\n$$\n值 $p^{\\ast} = 0.7$ 位于区间 $(0,1)$ 内，这与内部稳态的定义一致。根据问题中关于唯一内部稳态的假设，这必定是所求的值。", "answer": "$$\n\\boxed{0.7}\n$$", "id": "2427005"}, {"introduction": "现实世界中的群体并非完全由理性、随时调整策略的个体组成。下一个练习将引入更真实也更复杂的场景。在这个模型中，一部分群体是“固执的”代理人，他们永远不会改变自己的策略。你的任务是分析在这种混合群体中，那些“适应性”代理人的策略选择将如何演化并达到均衡。这个练习 [@problem_id:2427002] 旨在训练你一项关键的建模技巧：如何精确定义策略所处的“环境”，并计算在该环境下各个策略的适应度。", "problem": "考虑一个大规模充分混合的群体，群体中的每个代理人进行重复随机匹配，并采用两种交易策略之一：“趋势”（记为 $T$）或“价值”（记为 $V$）。这种互动是一个对称的 $2 \\times 2$ 博弈。当一个使用策略 $i \\in \\{T,V\\}$ 的参与者与一个使用策略 $j \\in \\{T,V\\}$ 的对手匹配时，该参与者的单期期望收益由以下矩阵的元素给出：\n$$\nA \\;=\\; \\begin{pmatrix}\n5 & 1 \\\\\n3 & 2\n\\end{pmatrix},\n$$\n其中，行表示该参与者的策略，列表示对手的策略。群体中有比例为 $s=\\frac{1}{10}$ 的“固执”代理人，他们永久性地使用策略 $T$ 并且从不修正策略。剩下的比例为 $1-s$ 的群体是适应性代理人，他们根据复制者动态修正自己的策略：一个策略在适应性子群体中的份额会增加，当且仅当其期望收益超过当前平均收益；其份额会减少，当且仅当其期望收益低于当前平均收益。\n\n设 $p \\in [0,1]$ 表示适应性代理人中采用策略 $T$ 的份额。假设匹配在整个群体（包括固执和适应性代理人）中是随机的。在上述假设下，适应性子群体中的复制者动态存在一个唯一的内部不动点 $p^{\\ast} \\in (0,1)$。\n\n精确计算 $p^{\\ast}$。请以精确分数形式给出答案，不要四舍五入。", "solution": "问题陈述经审阅，被认为是有效的。其科学基础是演化博弈论的原理，特别是复制者动态。该问题提法恰当，提供了所有必要的参数和明确的目标。语言客观，数学设定一致且完整。因此，将提供解答。\n\n设 $s$ 是群体中总是使用策略 $T$ 的“固执”代理人的比例。给定 $s = \\frac{1}{10}$。剩下的比例 $1-s$ 是“适应性”代理人。设 $p$ 是适应性代理人中选择策略 $T$ 的比例。因此，选择策略 $V$ 的适应性代理人的比例是 $1-p$。\n\n整个群体中使用策略 $T$ 的代理人总比例（记为 $x_T$）是使用策略 $T$ 的固执代理人和使用策略 $T$ 的适应性代理人之和：\n$$\nx_T = s \\cdot 1 + (1-s) \\cdot p = s + (1-s)p\n$$\n使用策略 $V$ 的代理人总比例（记为 $x_V$）仅由使用策略 $V$ 的适应性代理人组成：\n$$\nx_V = (1-s)(1-p)\n$$\n注意到 $x_T + x_V = s + (1-s)p + (1-s)(1-p) = s + (1-s)(p + 1 - p) = s + 1 - s = 1$，符合预期。\n\n收益矩阵如下：\n$$\nA = \\begin{pmatrix} A_{TT} & A_{TV} \\\\ A_{VT} & A_{VV} \\end{pmatrix} = \\begin{pmatrix} 5 & 1 \\\\ 3 & 2 \\end{pmatrix}\n$$\n一个适应性代理人选择策略的收益，是根据其与从整个群体中随机抽取的对手进行博弈来评估的。选择策略 $T$ 的适应性代理人的期望收益（记为 $U_T$）是：\n$$\nU_T = A_{TT} \\cdot x_T + A_{TV} \\cdot x_V = 5x_T + 1x_V\n$$\n选择策略 $V$ 的适应性代理人的期望收益（记为 $U_V$）是：\n$$\nU_V = A_{VT} \\cdot x_T + A_{VV} \\cdot x_V = 3x_T + 2x_V\n$$\n复制者动态表明，适应性子群体中策略 $T$ 的份额 $p$ 根据以下方程演化：\n$$\n\\dot{p} = p(U_T - \\bar{U})\n$$\n其中 $\\bar{U} = p U_T + (1-p) U_V$ 是适应性子群体内的平均收益。\n\n内部不动点 $p^{\\ast} \\in (0,1)$ 是一个 $\\dot{p}=0$ 的状态。由于 $p^{\\ast}$ 是内部点，所以 $p^{\\ast} \\neq 0$ 且 $p^{\\ast} \\neq 1$。条件 $\\dot{p}=0$ 意味着 $p(U_T - \\bar{U}) = 0$。因为 $p \\neq 0$，我们必须有 $U_T - \\bar{U} = 0$。\n代入 $\\bar{U}$ 的表达式：\n$$\nU_T - [p U_T + (1-p) U_V] = 0\n$$\n$$\n(1-p)U_T - (1-p)U_V = 0\n$$\n$$\n(1-p)(U_T - U_V) = 0\n$$\n因为 $p^{\\ast} \\in (0,1)$，我们有 $1-p^{\\ast} \\neq 0$。因此，内部不动点的条件简化为两种策略的期望收益相等：\n$$\nU_T = U_V\n$$\n代入 $U_T$ 和 $U_V$ 的表达式：\n$$\n5x_T + 1x_V = 3x_T + 2x_V\n$$\n$$\n2x_T = x_V\n$$\n现在，我们用 $p$ 和 $s$ 来代入 $x_T$ 和 $x_V$ 的表达式：\n$$\n2(s + (1-s)p) = (1-s)(1-p)\n$$\n我们正在寻找满足此均衡条件的 $p$ 的值，我们将其表示为 $p^{\\ast}$。展开该方程：\n$$\n2s + 2(1-s)p^{\\ast} = 1-s - (1-s)p^{\\ast}\n$$\n现在，我们将包含 $p^{\\ast}$ 的项移到一边，常数项移到另一边：\n$$\n2(1-s)p^{\\ast} + (1-s)p^{\\ast} = 1-s-2s\n$$\n$$\n3(1-s)p^{\\ast} = 1-3s\n$$\n解出 $p^{\\ast}$：\n$$\np^{\\ast} = \\frac{1-3s}{3(1-s)}\n$$\n这是内部不动点作为固执代理人比例 $s$ 的函数的通用表达式。问题指定 $s = \\frac{1}{10}$。代入此值：\n$$\n1-s = 1 - \\frac{1}{10} = \\frac{9}{10}\n$$\n$$\n1-3s = 1 - 3\\left(\\frac{1}{10}\\right) = 1 - \\frac{3}{10} = \\frac{7}{10}\n$$\n将这些代入 $p^{\\ast}$ 的表达式中：\n$$\np^{\\ast} = \\frac{\\frac{7}{10}}{3\\left(\\frac{9}{10}\\right)} = \\frac{\\frac{7}{10}}{\\frac{27}{10}}\n$$\n$$\np^{\\ast} = \\frac{7}{27}\n$$\n该值位于区间 $(0,1)$ 内，这证实了它是一个有效的内部不动点。这就是题目所要求的唯一内部不动点。", "answer": "$$\n\\boxed{\\frac{7}{27}}\n$$", "id": "2427002"}, {"introduction": "最后，我们将从纸笔分析转向计算模拟——这是现代计算经济学和金融学的核心技能。这个练习将带你进入著名的“凯恩斯选美博弈”世界。由于该博弈的复杂性，用解析方法求解变得非常困难。因此，你需要编写程序来模拟复制子动态，直观地观察在一个比之前模型更丰富的设定中，不同预测规则（策略）的占比是如何随时间演化的。这个实践 [@problem_id:2426991] 将理论与编程实现相结合，让你体验如何运用计算工具来探索复杂的经济动态系统。", "problem": "设想一个庞大的主体群体重复进行凯恩斯选美博弈。在每一轮中，每个主体都采用一个固定的预测规则（一种“策略”），该规则输出一个在单位区间内的标量猜测值。要预测的实现目标与当前群体的平均猜测值成正比。群体状态由一个在 $K+1$ 种策略的有限集合上的概率向量 $x = (x_0,\\dots,x_K)$ 表示，其中 $x_i \\ge 0$ 且 $\\sum_{i=0}^K x_i = 1$。平均猜测值为 $m(x) = \\sum_{i=0}^K x_i g_i$，其中 $g_i$ 是策略 $i$ 产生的猜测值。该博弈由以下参数决定：一个权重 $p \\in (0,1)$，它将目标缩放为 $p \\cdot m(x)$；一个基准锚点 $b \\in (0,1]$；以及一个线性复杂度成本系数 $\\lambda \\ge 0$，该系数对策略索引进行惩罚。策略集合由带有几何衰减的$k$阶迭代推理定义：对于 $i \\in \\{0,1,\\dots,K\\}$，规则是猜测 $g_i = b \\, p^i$。在状态 $x$ 下，策略 $i$ 的单期收益定义为预测误差平方的负值减去复杂度成本，即\n$$\nu_i(x) = -\\big(g_i - p \\, m(x)\\big)^2 - \\lambda \\, i.\n$$\n群体份额根据连续时间复制子动态方程演化\n$$\n\\dot{x}_i = x_i \\big( u_i(x) - \\bar{u}(x) \\big), \\quad \\text{其中 } i=0,\\dots,K,\n$$\n其中 $\\bar{u}(x) = \\sum_{j=0}^K x_j u_j(x)$ 是平均收益。初始条件为均匀分布 $x_i(0) = \\frac{1}{K+1}$（对所有 $i$）。\n\n您的任务是实现一个程序，从给定的初始条件开始，对几种参数配置下的复制子动态进行数值积分，直至达到稳态。使用一种在数值容差范围内能保持单纯形特性（非负性和总和为一）的时间离散化方案。当 $x$ 在单步内的最大绝对变化量连续 $100$ 步低于 $10^{-10}$ 时，或者当达到模拟步数的硬上限时，应宣告收敛。使用固定时间步长 $\\Delta t = 0.01$ 和最大模拟时间 $T = 200$（即最多 $N = 20000$ 步）。如果数值漂移破坏了非负性，则通过在零处截断并重新归一化至总和为一的方式进行投影校正。收敛后（或达到时间上限时），报告拥有最大群体份额 $x_{i^\\star}$ 的策略索引 $i^\\star$；如果出现平局，则报告其中最小的索引。\n\n为以下测试套件实现您的解决方案（每个元组为 $(p,b,K,\\lambda)$）：\n- 案例 A (理想路径): $(\\frac{2}{3}, 1.0, 5, 0.0)$。\n- 案例 B (成本主导边界): $(0.9, 1.0, 8, 0.05)$。\n- 案例 C (权衡内部情况): $(0.5, 1.0, 10, 0.02)$。\n\n注：\n- 所有数学实体必须严格按照定义处理：$p \\in (0,1)$, $b \\in (0,1]$, $K \\in \\mathbb{N}$ 且 $K \\ge 1$, $\\lambda \\ge 0$。\n- 不涉及角度，无需角度单位。\n- 没有物理单位。\n- 不使用百分比；所有量均为实数。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含测试套件的结果，格式为方括号内以逗号分隔的列表，并按案例 A, B, C 的顺序排列。每个元素必须是整数，等于您的模拟找到的优势策略索引 $i^\\star$。例如，一个包含三个整数的输出必须类似于 $[i_A,i_B,i_C]$，不含空格。", "solution": "问题陈述经过严格审查，被认为是有效的。其科学基础在于已建立的演化博弈论，具体而言，是使用复制子动态来模拟凯恩斯选美博弈中的策略演化。此问题是适定的，为求解唯一的数值解提供了所需的一整套完备的定义、方程、参数和初始条件。其语言客观且数学上精确，没有歧义或矛盾。\n\n该问题要求对一个连续时间复制子方程组进行数值积分，以找到策略的稳态分布。该系统描述了一个主体群体，其中使用策略 $i$ 的群体份额 $x_i$ 根据其相对表现进行演化。\n\n系统状态是 $(K+1)$ 维单纯形上的一个概率向量 $x = (x_0, \\dots, x_K)$，其中 $x_i(t)$ 是在时间 $t$ 时策略 $i$ 的群体份额。约束条件为对所有 $i \\in \\{0, \\dots, K\\}$ 都有 $x_i \\ge 0$ 且 $\\sum_{i=0}^K x_i = 1$。初始条件为均匀分布，$x_i(0) = \\frac{1}{K+1}$（对所有 $i$）。\n\n该博弈涉及预测一个目标，该目标取决于群体的平均行动。可用策略由 $i \\in \\{0, \\dots, K\\}$ 索引。策略 $i$ 对应于做出一个固定的猜测值 $g_i$，通过 $k$ 阶推理定义为：\n$$\ng_i = b p^i\n$$\n其中 $b \\in (0,1]$ 是一个基准锚点，$p \\in (0,1)$ 是一个几何衰减因子。给定群体状态 $x$，平均猜测值为：\n$$\nm(x) = \\sum_{i=0}^K x_i g_i\n$$\n要预测的目标值为 $p \\cdot m(x)$。\n\n策略的成功度由其收益衡量，该收益是二次损失函数（预测误差平方）的负值，加上一个针对复杂度的线性惩罚：\n$$\nu_i(x) = -\\big(g_i - p \\, m(x)\\big)^2 - \\lambda i\n$$\n其中 $\\lambda \\ge 0$ 是复杂度成本的系数，该成本随策略索引 $i$ 的增加而增加。\n\n群体动态受连续时间复制子方程支配：\n$$\n\\dot{x}_i = x_i \\big( u_i(x) - \\bar{u}(x) \\big)\n$$\n其中 $\\bar{u}(x) = \\sum_{j=0}^K x_j u_j(x)$ 是群体平均收益。该方程意味着，收益高于平均水平的策略其群体份额会随时间增加，而收益低于平均水平的策略则会下降。\n\n为了数值求解该常微分方程组，我们必须采用一种时间离散化方案。标准的前向欧拉法虽然简单，但不能保证状态向量 $x$ 保持在单纯形上。问题陈述建议使用一种投影法（截断和重新归一化）来处理这个问题。然而，一种更优雅和稳健的方法是使用能够内在地保持单纯形结构的方法。指数更新法则，作为复制子动态的一种标准离散化方法，可以实现这一点：\n$$\nx_i(t+\\Delta t) = \\frac{x_i(t) \\exp\\big(\\Delta t \\cdot u_i(x(t))\\big)}{\\sum_{j=0}^K x_j(t) \\exp\\big(\\Delta t \\cdot u_j(x(t))\\big)}\n$$\n该更新法则确保，如果 $x_i(t) \\ge 0$ 且 $\\sum_i x_i(t) = 1$，那么 $x_i(t+\\Delta t) \\ge 0$ 和 $\\sum_i x_i(t+\\Delta t) = 1$ 也能在数值精度范围内得以保持，从而满足了问题的要求。\n\n每个测试案例的算法如下：\n1.  初始化参数 $(p, b, K, \\lambda)$ 和数值常量：$\\Delta t = 0.01$，$N_{max} = 20000$，收敛容差 $\\epsilon = 10^{-10}$，以及收敛所需的连续步数 $S_{conv} = 100$。\n2.  预先计算策略猜测值的常数向量 $g = (g_0, \\dots, g_K)$。\n3.  将状态向量 $x$ 初始化为均匀分布：$x_i = \\frac{1}{K+1}$（对所有 $i$）。\n4.  开始主模拟循环，从步骤 $n=0$ 迭代到 $N_{max}-1$。\n    a.  存储当前状态向量：$x_{old} \\leftarrow x$。\n    b.  计算平均猜测值 $m(x) = x \\cdot g$。\n    c.  计算目标值 $T = p \\cdot m(x)$。\n    d.  计算收益向量 $u$，其中 $u_i = -(g_i - T)^2 - \\lambda i$。\n    e.  使用上述指数更新法则更新状态向量 $x$。\n    f.  检查收敛性：计算最大绝对变化量 $\\delta = \\max_i |x_i - (x_{old})_i|$。如果 $\\delta < \\epsilon$，则增加连续收敛步数的计数器。否则，重置计数器。\n    g.  如果计数器达到 $S_{conv}$，则系统已达到稳态，循环终止。\n5.  循环终止后（无论是由于收敛还是达到 $N_{max}$ 步），在最终状态向量 $x$ 中确定拥有最大群体份额的策略索引 $i^\\star$。若出现平局，则选择最小的此类索引。这通过找到最终向量 $x$ 的最大值参数来完成。\n6.  该索引 $i^\\star$ 即为给定测试案例的结果。\n对所有指定的测试案例重复此过程。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print the results.\n    \"\"\"\n    # Each tuple is (p, b, K, lambda).\n    test_cases = [\n        (2.0/3.0, 1.0, 5, 0.0),    # Case A\n        (0.9, 1.0, 8, 0.05),     # Case B\n        (0.5, 1.0, 10, 0.02),    # Case C\n    ]\n\n    results = []\n    for p, b, K, lambda_val in test_cases:\n        i_star = run_simulation(p, b, K, lambda_val)\n        results.append(i_star)\n\n    # Format the final output as specified.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef run_simulation(p, b, K, lambda_val):\n    \"\"\"\n    Numerically integrates the replicator dynamics for a single parameter configuration.\n\n    Args:\n        p (float): The scaling weight for the target.\n        b (float): The baseline anchor for strategies.\n        K (int): The maximum strategy index (K+1 strategies).\n        lambda_val (float): The complexity cost coefficient.\n\n    Returns:\n        int: The index of the dominant strategy at the steady state.\n    \"\"\"\n    # Numerical integration parameters from the problem description\n    DT = 0.01\n    T_MAX = 200.0\n    N_MAX = int(T_MAX / DT)\n    CONV_TOL = 1e-10\n    CONV_STEPS = 100\n\n    # Initialize strategies and state vector\n    # k_values is an array [0, 1, ..., K]\n    k_values = np.arange(K + 1)\n    # g is the vector of guesses for each strategy\n    g = b * (p ** k_values)\n    # x is the population share vector, initialized to uniform distribution\n    x = np.full(K + 1, 1.0 / (K + 1))\n\n    consecutive_converged_steps = 0\n\n    for _ in range(N_MAX):\n        x_old = x.copy()\n\n        # Step 1: Calculate average guess m(x)\n        m_x = np.dot(x, g)\n\n        # Step 2: Calculate target\n        target = p * m_x\n\n        # Step 3: Calculate payoffs u_i(x) for all strategies\n        forecast_error_sq = (g - target) ** 2\n        complexity_cost = lambda_val * k_values\n        u = -forecast_error_sq - complexity_cost\n\n        # Step 4: Update population shares using the exponential update rule\n        # This scheme inherently preserves the simplex (non-negativity and unit sum).\n        numerators = x * np.exp(DT * u)\n        denominator = np.sum(numerators)\n        \n        # This check is for extreme cases, e.g., underflow of all numerators.\n        # It's unlikely in this problem but is good practice.\n        if denominator > 0:\n            x = numerators / denominator\n        else:\n            # If all population shares vanish, simulation cannot continue.\n            break\n\n        # Step 5: Check for convergence\n        max_change = np.max(np.abs(x - x_old))\n        if max_change  CONV_TOL:\n            consecutive_converged_steps += 1\n        else:\n            consecutive_converged_steps = 0\n\n        if consecutive_converged_steps >= CONV_STEPS:\n            break\n\n    # Determine the dominant strategy after convergence or timeout\n    # np.argmax returns the smallest index in case of a tie.\n    i_star = np.argmax(x)\n\n    return int(i_star)\n\nif __name__ == '__main__':\n    solve()\n```", "id": "2426991"}]}