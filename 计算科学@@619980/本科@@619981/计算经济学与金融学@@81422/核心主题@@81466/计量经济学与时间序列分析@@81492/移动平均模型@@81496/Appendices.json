{"hands_on_practices": [{"introduction": "移动平均（Moving Average, MA）模型是捕捉时间序列中短期“记忆”或动量的有效工具。一个直观的例子是体育比赛中的“手感火热”（hot hand）现象，即运动员的当前表现似乎会受到其近期表现的影响。本练习 [@problem_id:2412526] 将指导你使用一个简单的 $MA(1)$ 模型，通过统计假设检验来判断篮球运动员的得分数据中是否存在“手感火热”效应，这是一个将理论模型应用于现实问题并进行实证检验的基础性实践。", "problem": "给定一个单变量离散时间序列，表示一名篮球运动员每场比赛的得分与其长期平均分的偏差。设时间点 $t$ 的偏差表示为 $y_t$。假设 $y_t$ 服从一阶移动平均 (MA) 模型，记作移动平均 (MA)(1)，其定义为\n$$\ny_t = \\varepsilon_t + \\theta \\varepsilon_{t-1},\n$$\n其中 $\\{\\varepsilon_t\\}$ 是一个独立同分布序列，满足 $\\varepsilon_t \\sim \\mathcal{N}(0,\\sigma^2)$，并且 $\\theta \\in \\mathbb{R}$ 是一个常数。\n\n“手感火热”效应被定义为 $y_t$ 中存在正的一阶序列相关性，这对应于中心化序列的正滞后一阶自相关。对于下方的每个测试用例，您必须在单侧显著性水平 $\\alpha$ 下，判断数据是否为“手感火热”效应提供了证据。\n\n对于每个测试用例，您必须：\n- 使用指定的参数 $(N,\\theta,\\sigma^2)$ 和随机数种子，模拟一个实现 $\\{y_t\\}_{t=1}^N$。\n- 将 $y_t$ 视为与长期平均值的偏差，并使用中心化序列（减去样本均值）来评估一阶序列相关性。\n- 在显著性水平 $\\alpha$ 下，判断是否存在“手感火热”效应的证据。\n\n您必须使用以下测试套件。对于每个用例，在模拟前使用给定的整数随机种子初始化您的随机数生成器：\n- 用例 1：$N=400$, $\\theta=0.8$, $\\sigma^2=9$, $\\alpha=0.05$, 种子 $=1729$。\n- 用例 2：$N=400$, $\\theta=0.0$, $\\sigma^2=9$, $\\alpha=0.05$, 种子 $=31415$。\n- 用例 3：$N=400$, $\\theta=-0.8$, $\\sigma^2=9$, $\\alpha=0.05$, 种子 $=271828$。\n- 用例 4：$N=30$, $\\theta=0.6$, $\\sigma^2=9$, $\\alpha=0.05$, 种子 $=123456$。\n- 用例 5：$N=2$, $\\theta=0.7$, $\\sigma^2=9$, $\\alpha=0.05$, 种子 $=7$。\n\n您的程序应生成单行输出，其中包含一个布尔值列表，按以上顺序列出，对应于每个用例的检验决策。如果数据在显著性水平 $\\alpha$ 下为“手感火热”效应提供了证据，则布尔值为 $True$，否则为 $False$。输出必须是单行，且格式必须为\n`\"[result1,result2,result3,result4,result5]\"`。", "solution": "对问题陈述进行验证。\n\n**步骤 1：提取已知条件**\n- 一个单变量离散时间序列 $\\{y_t\\}$ 服从一阶移动平均模型 MA($1$)：$y_t = \\varepsilon_t + \\theta \\varepsilon_{t-1}$。\n- $\\{\\varepsilon_t\\}$ 是一个独立同分布 (i.i.d.) 序列，满足 $\\varepsilon_t \\sim \\mathcal{N}(0,\\sigma^2)$。\n- “手感火热”效应被定义为 $y_t$ 中存在正的一阶序列相关性，对应于正的滞后一阶自相关。\n- 任务是在单侧显著性水平 $\\alpha$ 下检验此效应。\n- 流程包括：模拟一个序列 $\\{y_t\\}_{t=1}^N$，通过减去样本均值将其中心化，然后执行假设检验。\n- 测试用例：\n    - 用例 1：$N=400$, $\\theta=0.8$, $\\sigma^2=9$, $\\alpha=0.05$, 种子$=1729$。\n    - 用例 2：$N=400$, $\\theta=0.0$, $\\sigma^2=9$, $\\alpha=0.05$, 种子$=31415$。\n    - 用例 3：$N=400$, $\\theta=-0.8$, $\\sigma^2=9$, $\\alpha=0.05$, 种子$=271828$。\n    - 用例 4：$N=30$, $\\theta=0.6$, $\\sigma^2=9$, $\\alpha=0.05$, 种子$=123456$。\n    - 用例 5：$N=2$, $\\theta=0.7$, $\\sigma^2=9$, $\\alpha=0.05$, 种子$=7$。\n\n**步骤 2：使用提取的已知条件进行验证**\n根据科学依据、良构性和客观性标准对问题进行评估。\n\n- **科学依据**：该问题基于时间序列分析中的标准 MA(1) 模型，这是计量经济学和统计学的核心课题。自相关、假设检验和显著性水平等概念是基本的统计学原理。“手感火热”概念提供了一个主题背景，但被严格定义为一个可检验的统计属性。该问题在科学上是合理的。\n- **良构性**：该问题为时间序列的可复现模拟提供了所有必要的参数（$N, \\theta, \\sigma^2$）和随机种子。它清晰地指明了任务：在给定的显著性水平 $\\alpha$ 下，对正自相关进行单侧假设检验。流程明确无歧义。鉴于检验自相关的标准统计方法，每个测试用例都存在唯一解。\n- **客观性**：该问题使用精确、客观的数学语言陈述。它避免了主观或模糊的术语。\n\n该问题没有违反任何无效条件。$N=2$ 的用例 5 是一个极端但有效的统计情景。对于大小为 $N=2$ 的样本，其样本自相关在代数上是固定的，这是该统计量的一个可证明的性质，而不是问题表述中的缺陷。因此，该问题被视为有效。\n\n**步骤 3：结论与行动**\n问题有效。将提供完整解决方案。\n\n**理论框架与方法论**\n\n给定的时间序列 $\\{y_t\\}$ 是由一个一阶移动平均过程（记为 MA(1)）生成的：\n$$\ny_t = \\varepsilon_t + \\theta \\varepsilon_{t-1}\n$$\n其中 $\\varepsilon_t$ 是一个白噪声过程，满足 $\\varepsilon_t \\sim \\mathcal{N}(0, \\sigma^2)$。该过程的理论一阶自相关系数 $\\rho_1$ 由下式给出：\n$$\n\\rho_1 = \\frac{\\text{Cov}(y_t, y_{t-1})}{\\text{Var}(y_t)} = \\frac{\\theta}{1+\\theta^2}\n$$\n“手感火热”效应被定义为正的一阶序列相关性，这转化为对 $\\rho_1 > 0$ 的统计检验。假设检验表述如下：\n- 原假设 $H_0: \\rho_1 = 0$（无一阶自相关）。\n- 备择假设 $H_A: \\rho_1 > 0$（存在正一阶自相关）。\n\n该检验在模拟数据 $\\{y_t\\}_{t=1}^N$ 上进行。检验统计量是样本滞后一阶自相关系数 $\\hat{\\rho}_1$，它是根据中心化序列 $\\tilde{y}_t = y_t - \\bar{y}$ 计算得出的，其中 $\\bar{y}$ 是样本均值。$\\hat{\\rho}_1$ 的计算公式为：\n$$\n\\hat{\\rho}_1 = \\frac{\\sum_{t=2}^{N} (y_t - \\bar{y})(y_{t-1} - \\bar{y})}{\\sum_{t=1}^{N} (y_t - \\bar{y})^2}\n$$\n在原假设 $H_0$ 下，对于足够大的样本量 $N$，$\\hat{\\rho}_1$ 的分布可以用正态分布近似：\n$$\n\\hat{\\rho}_1 \\approx \\mathcal{N}\\left(0, \\frac{1}{N}\\right)\n$$\n据此，我们构造一个标准化检验统计量 $Z = \\hat{\\rho}_1 \\sqrt{N}$，在 $H_0$ 下，它服从标准正态分布 $Z \\sim \\mathcal{N}(0, 1)$。\n\n对于显著性水平为 $\\alpha$ 的单侧检验，如果观测到的检验统计量超过临界值 $z_{1-\\alpha}$，则我们拒绝原假设 $H_0$。$z_{1-\\alpha}$ 是标准正态分布的 $(1-\\alpha)$-分位数。决策规则是：\n$$\n\\text{Reject } H_0 \\text{ if } \\hat{\\rho}_1 \\sqrt{N} > z_{1-\\alpha}\n$$\n这种大样本近似适用于 $N$ 较大（例如 $N=400$）的情况。对于较小的 $N$，其准确性会降低。对于 $N=30$ 的情况，它仍被认为是可接受的。对于 $N=2$ 的情况，该近似效果很差。然而，对于 $N=2$ 的情况，解析分析表明，对于任意两个不同的点 $y_1, y_2$，样本自相关固定为 $\\hat{\\rho}_1 = -1/2$。负的样本自相关永远不能为正的总体自相关提供证据。因此，对于 $N=2$，我们总是无法拒绝 $H_0: \\rho_1 = 0$ 而支持 $H_A: \\rho_1 > 0$。\n\n每个测试用例的流程如下：\n1. 为保证可复现性，设置随机种子。\n2. 从 $\\mathcal{N}(0, \\sigma^2)$ 生成一个包含 $N+1$ 个独立同分布的随机变量序列 $\\{\\varepsilon_t\\}_{t=0}^N$。\n3. 构建长度为 $N$ 的 MA(1) 序列 $\\{y_t\\}_{t=1}^N$。\n4. 计算样本均值 $\\bar{y}$ 并对序列进行中心化。\n5. 计算样本自相关 $\\hat{\\rho}_1$。如果分母为零（对于连续数据，其发生概率为零），则数据没有变异，因此没有相关性的证据。\n6. 计算检验统计量 $Z = \\hat{\\rho}_1 \\sqrt{N}$。\n7. 从标准正态分布中确定临界值 $z_{1-\\alpha}$。\n8. 如果 $Z > z_{1-\\alpha}$，则有“手感火热”效应的证据 (True)；否则，没有证据 (False)。", "answer": "```python\n# language: Python\n# version: 3.12\n# libraries:\n#   name: numpy\n#   version: 1.23.5\n#   name: scipy\n#   version: 1.11.4\n\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for the Moving Average (MA)(1) model.\n    \"\"\"\n\n    def analyze_hot_hand(N, theta, sigma_sq, alpha, seed):\n        \"\"\"\n        Simulates an MA(1) series and tests for positive first-order autocorrelation.\n\n        Args:\n            N (int): The length of the time series.\n            theta (float): The MA(1) parameter.\n            sigma_sq (float): The variance of the white noise term.\n            alpha (float): The significance level for the one-sided test.\n            seed (int): The random seed for reproducibility.\n\n        Returns:\n            bool: True if there is evidence of a hot hand, False otherwise.\n        \"\"\"\n        # 1. Set the random seed\n        np.random.seed(seed)\n\n        sigma = np.sqrt(sigma_sq)\n\n        # 2. Generate N+1 white noise terms to produce a series of length N\n        # We need eps_0, ..., eps_N to compute y_1, ..., y_N\n        eps = np.random.normal(loc=0.0, scale=sigma, size=N + 1)\n\n        # 3. Construct the MA(1) series y_t = eps_t + theta * eps_{t-1}\n        # The resulting series 'y' has length N, corresponding to t=1,...,N\n        y = eps[1:] + theta * eps[:-1]\n\n        # 4. Center the series by subtracting the sample mean\n        y_mean = np.mean(y)\n        y_centered = y - y_mean\n        \n        # 5. Compute the sample lag-1 autocorrelation coefficient, rho_hat_1\n        # Denominator of rho_hat_1: sum of squared deviations\n        denominator = np.sum(y_centered**2)\n        \n        # If variance is zero, all y_t are identical.\n        # Autocorrelation is undefined, and there is no evidence of dependence.\n        if denominator == 0.0:\n            return False\n\n        # Numerator of rho_hat_1: sum of cross-products of lagged centered values\n        # y_centered[1:] corresponds to (y_2-y_bar), ..., (y_N-y_bar)\n        # y_centered[:-1] corresponds to (y_1-y_bar), ..., (y_{N-1}-y_bar)\n        numerator = np.sum(y_centered[1:] * y_centered[:-1])\n        \n        rho_hat_1 = numerator / denominator\n\n        # For N = 1, autocorrelation is not well-defined.\n        if N = 1:\n            return False\n\n        # 6. Compute the test statistic Z = rho_hat_1 * sqrt(N)\n        # This is based on the large-sample approximation.\n        test_statistic = rho_hat_1 * np.sqrt(N)\n        \n        # 7. Determine the critical value for a one-sided test\n        # This is the (1-alpha) quantile of the standard normal distribution.\n        critical_value = norm.ppf(1 - alpha)\n        \n        # 8. Perform the test: reject H0 if test_statistic  critical_value\n        return test_statistic  critical_value\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (N, theta, sigma^2, alpha, seed)\n        (400, 0.8, 9.0, 0.05, 1729),\n        (400, 0.0, 9.0, 0.05, 31415),\n        (400, -0.8, 9.0, 0.05, 271828),\n        (30, 0.6, 9.0, 0.05, 123456),\n        (2, 0.7, 9.0, 0.05, 7),\n    ]\n\n    results = []\n    for case in test_cases:\n        N, theta, sigma_sq, alpha, seed = case\n        result = analyze_hot_hand(N, theta, sigma_sq, alpha, seed)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2412526"}, {"introduction": "在理解了 $MA$ 模型如何描述序列依赖性之后，我们可以进一步利用它来进行预测和监控。一个重要的应用是异常检测（anomaly detection），即识别那些显著偏离模型预测的观测值。本练习 [@problem_id:2412539] 将一个 $MA(3)$ 模型置于信用卡欺诈检测的场景中，要求你设计一个算法来标记潜在的欺诈交易。这个实践不仅展示了 $MA$ 模型的强大实际用途，还有助于加深对模型“新息”（innovation）即为一步预测误差的理解。", "problem": "给定一个单一用户普通信用卡消费的形式化模型，该模型为一个三阶移动平均（MA(3)）时间序列。MA(3)模型由弱平稳性和序列不相关创新下的线性时间序列的核心概率结构定义：一个标量过程 $\\{y_t\\}$ 满足 $y_t = \\mu + \\varepsilon_t + \\theta_1 \\varepsilon_{t-1} + \\theta_2 \\varepsilon_{t-2} + \\theta_3 \\varepsilon_{t-3}$，其中 $\\mu$ 是一个恒定均值，$\\{\\varepsilon_t\\}$ 是一个零均值、序列不相关的创新序列，其方差为 $\\sigma^2$，而 $\\theta_1,\\theta_2,\\theta_3$ 是实数系数。在此模型和迭代期望定律下，单步预测 $E[y_t \\mid \\mathcal{F}_{t-1}]$ 在所有 $\\mathcal{F}_{t-1}$-可测的预测量中，能最小化均方预测误差，其中 $\\mathcal{F}_{t-1}$ 是由 $\\{y_s: s \\le t-1\\}$ 生成的σ-域。如果时间 $t$ 的一笔交易导致相对于创新方差而言产生了较大的单步预测误差，则该交易被标记为潜在欺诈性交易。您必须设计一个算法，在每个时间 $t$，从 $\\mathcal{F}_{t-1}$ 中生成MA(3)结构所蕴含的单步预测，计算由此产生的预测误差，用已知的标准差 $\\sigma$ 对其进行标准化，并且如果标准化误差的绝对值超过了以标准差为单位表示的预先指定的阈值 $\\tau$，则标记时间 $t$。在预测中，任何不可用的过去创新的条件期望（例如，当 $t \\le 3$ 时）必须被视为零，因为它是零均值且独立于 $\\mathcal{F}_{t-1}$。您的算法应仅使用截至前一时刻的可用信息，顺序计算单步预测和由此产生的预测误差。\n\n程序要求：\n1) 输入是硬编码的：您必须为一个下面定义的固定测试套件实现您的算法。不允许用户输入。不允许访问外部文件或网络。\n2) 对于每个测试案例，给定 $(\\mu, \\boldsymbol{\\theta}, \\sigma^2, \\tau, \\mathbf{y})$，其中 $\\boldsymbol{\\theta} = (\\theta_1,\\theta_2,\\theta_3)$ 且 $\\mathbf{y} = [y_1,\\dots,y_T]$。将所有量视为实数。创新标准差为 $\\sigma = \\sqrt{\\sigma^2}$。对于每个时间索引 $t \\in \\{1,\\dots,T\\}$，仅使用 $\\{y_s: s \\le t-1\\}$ 来计算MA(3)结构所蕴含的单步预测 $\\widehat{y}_{t \\mid t-1}$，定义预测误差 $e_t = y_t - \\widehat{y}_{t \\mid t-1}$，计算标准化误差 $z_t = e_t / \\sigma$，并且如果 $|z_t| > \\tau$ 则标记时间 $t$。对于每个测试案例，输出标记的索引列表，以整数形式升序排列。\n3) 您必须使用以下测试套件：\n- 案例 A（具有单个大尖峰的一般行为）：$\\mu = 100$，$\\boldsymbol{\\theta} = (0.5,-0.2,0.1)$，$\\sigma^2 = 25$，$\\tau = 3$，$\\mathbf{y} = [98,102,99,140,118,95,106,101]$。\n- 案例 B（短序列边缘情况，早期时间点）：$\\mu = 50$，$\\boldsymbol{\\theta} = (0.7,0.1,-0.4)$，$\\sigma^2 = 4$，$\\tau = 2$，$\\mathbf{y} = [50,56,46]$。\n- 案例 C（交替符号参数，一个临界值和一个尖峰）：$\\mu = 200$，$\\boldsymbol{\\theta} = (-0.4,0.3,-0.2)$，$\\sigma^2 = 16$，$\\tau = 2.5$，$\\mathbf{y} = [205,194,195,180,210,193]$。\n- 案例 D（白噪声基线，预计无标记）：$\\mu = 0$，$\\boldsymbol{\\theta} = (0,0,0)$，$\\sigma^2 = 9$，$\\tau = 3$，$\\mathbf{y} = [1,-2,4,-5,6,-3]$。\n- 案例 E（连续的大偏差）：$\\mu = 75$，$\\boldsymbol{\\theta} = (0.9,0.4,0.2)$，$\\sigma^2 = 100$，$\\tau = 2.5$，$\\mathbf{y} = [70,120,65,50]$。\n4) 最终输出格式：您的程序应生成单行输出，其中包含结果，形式为逗号分隔的整数列表的列表，并用方括号括起来，任何地方都没有空格。例如，一个有效的输出形状是 $[[1,3],[2],[]]$。对于给定的测试套件，输出必须是 $[L_A,L_B,L_C,L_D,L_E]$ 形式的单行，其中每个 $L_\\cdot$ 是相应案例的标记索引列表（升序排列）。\n\n您的任务：实现一个完整的、可运行的程序，该程序遵循MA(3)模型定义所蕴含的算法，为整个测试套件计算标记，并严格按照要求的格式打印单行聚合输出。所有数值答案都是无量纲的（没有物理单位）。不涉及角度。不使用百分比。每种情况的结果唯一可接受的数据类型是整数列表（可能为空）。", "solution": "该问题陈述经过验证，被认为是有效的。这是一个在计算时间序列分析领域中定义明确、有科学依据的问题，它基于成熟的移动平均（MA）模型理论和最优预测理论。所有参数和条件都已完全指定，从而可以得到唯一且可验证的解。\n\n该问题要求为一个被建模为三阶移动平均过程（表示为 MA(3)）的时间序列 $\\{y_t\\}$ 实现一个异常检测算法。该模型由以下方程定义：\n$$y_t = \\mu + \\varepsilon_t + \\theta_1 \\varepsilon_{t-1} + \\theta_2 \\varepsilon_{t-2} + \\theta_3 \\varepsilon_{t-3}$$\n在这里，$\\mu$ 是过程的恒定均值，$\\{\\varepsilon_t\\}$ 是一系列序列不相关的随机变量（创新或冲击），其均值为 $E[\\varepsilon_t] = 0$，恒定方差为 $Var(\\varepsilon_t) = \\sigma^2$。系数 $\\theta_1, \\theta_2, \\theta_3$ 是模型的实数值参数。\n\n任务的核心是为每个时间 $t \\in \\{1, 2, \\dots, T\\}$ 计算单步预测 $\\widehat{y}_{t \\mid t-1}$。该预测是给定直至时间 $t-1$ 的可用信息（由σ-域 $\\mathcal{F}_{t-1} = \\sigma(\\{y_s: s \\le t-1\\})$ 表示）下 $y_t$ 的条件期望。条件期望是最小化均方预测误差的预测量。\n该预测计算如下：\n$$\\widehat{y}_{t \\mid t-1} = E[y_t \\mid \\mathcal{F}_{t-1}] = E[\\mu + \\varepsilon_t + \\theta_1 \\varepsilon_{t-1} + \\theta_2 \\varepsilon_{t-2} + \\theta_3 \\varepsilon_{t-3} \\mid \\mathcal{F}_{t-1}]$$\n根据期望的线性和条件期望的性质，这变为：\n$$\\widehat{y}_{t \\mid t-1} = E[\\mu \\mid \\mathcal{F}_{t-1}] + E[\\varepsilon_t \\mid \\mathcal{F}_{t-1}] + \\theta_1 E[\\varepsilon_{t-1} \\mid \\mathcal{F}_{t-1}] + \\theta_2 E[\\varepsilon_{t-2} \\mid \\mathcal{F}_{t-1}] + \\theta_3 E[\\varepsilon_{t-3} \\mid \\mathcal{F}_{t-1}]$$\n让我们逐项评估：\n1. 由于 $\\mu$ 是一个常数，所以 $E[\\mu \\mid \\mathcal{F}_{t-1}] = \\mu$。\n2. 根据定义，创新 $\\varepsilon_t$ 无法从过去的信息中预测。因此，其在给定过去信息下的条件期望是其无条件均值，即 $E[\\varepsilon_t \\mid \\mathcal{F}_{t-1}] = E[\\varepsilon_t] = 0$。\n3. 对于过去的创新 $\\varepsilon_{t-k}$（其中 $k > 0$），我们必须确定在时间 $t-1$ 它们是否已知。模型方程可以被反转，以用当前观测值和过去的创新来表示当前创新：\n$$\\varepsilon_t = y_t - \\mu - \\theta_1 \\varepsilon_{t-1} - \\theta_2 \\varepsilon_{t-2} - \\theta_3 \\varepsilon_{t-3}$$\n这种关系允许递归计算创新序列。给定观测值 $\\{y_s: s \\le t-1\\}$，可以确定 $\\{\\varepsilon_s: s \\le t-1\\}$ 的值。因此，对于 $k \\in \\{1, 2, 3\\}$，创新 $\\varepsilon_{t-k}$ 关于 $\\mathcal{F}_{t-1}$ 是可测的，其条件期望就是其自身的值：$E[\\varepsilon_{t-k} \\mid \\mathcal{F}_{t-1}] = \\varepsilon_{t-k}$。\n\n然而，这仅在 $\\varepsilon_{t-k}$ 的值可以被计算出来时才成立。对于早期的步长（例如 $t=1$），所需的过去创新 $\\varepsilon_0, \\varepsilon_{-1}, \\varepsilon_{-2}$ 并非由从 $y_1$ 开始的观测序列确定。问题陈述正确地指明了，任何不可用的过去创新的条件期望必须被视为其无条件均值，即 $0$。这是初始化预测函数的标准处理方法。\n\n综合这些事实，预测方程为：\n$$\\widehat{y}_{t \\mid t-1} = \\mu + \\theta_1 \\varepsilon_{t-1}^* + \\theta_2 \\varepsilon_{t-2}^* + \\theta_3 \\varepsilon_{t-3}^*$$\n其中，如果 $\\varepsilon_{t-k}$ 的值已从先前的观测中计算出来，则 $\\varepsilon_{t-k}^* = \\varepsilon_{t-k}$，否则 $\\varepsilon_{t-k}^* = 0$。\n\n单步预测误差为 $e_t = y_t - \\widehat{y}_{t \\mid t-1}$。代入 $\\widehat{y}_{t \\mid t-1}$ 的表达式并使用 $y_t$ 的模型定义：\n$$e_t = (\\mu + \\varepsilon_t + \\sum_{k=1}^{3} \\theta_k \\varepsilon_{t-k}) - (\\mu + \\sum_{k=1}^{3} \\theta_k \\varepsilon_{t-k}) = \\varepsilon_t$$\n这证实了预测误差恰好是时间 $t$ 的创新。这是一个基本结果。因此，算法必须迭代计算创新序列。\n\n算法流程如下：\n1. 初始化一个创新历史记录。对于时间 $t \\le 0$，创新是未知的，因此我们使用其期望值 $0$。\n2. 对于从 $1$ 到 $T$ 的每个时间步 $t$：\n    a. 确定预测所需的过去创新 $\\varepsilon_{t-1}, \\varepsilon_{t-2}, \\varepsilon_{t-3}$ 的值。如果历史记录太短，则对缺失值使用 $0$。\n    b. 计算单步预测：$\\widehat{y}_{t \\mid t-1} = \\mu + \\theta_1 \\varepsilon_{t-1} + \\theta_2 \\varepsilon_{t-2} + \\theta_3 \\varepsilon_{t-3}$。\n    c. 使用当前观测值 $y_t$ 计算当前创新：$\\varepsilon_t = y_t - \\widehat{y}_{t \\mid t-1}$。\n    d. 存储新计算出的 $\\varepsilon_t$ 以用于后续预测。\n    e. 计算标准化误差 $z_t = \\varepsilon_t / \\sigma$，其中 $\\sigma = \\sqrt{\\sigma^2}$。\n    f. 如果 $|z_t| > \\tau$（其中 $\\tau$ 是给定的阈值），则将索引 $t$（使用基于1的索引）记录为已标记。\n3. 将所有测试案例的标记索引列表整理成指定的输出格式。\n这个顺序过程正确地实现了在MA(3)模型下的预测和异常检测逻辑。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the MA(3) fraud detection problem for a fixed test suite.\n    \"\"\"\n    test_cases = [\n        # Case A: General behavior with a single large spike\n        {\n            'mu': 100.0, 'theta': (0.5, -0.2, 0.1), 'sigma2': 25.0, 'tau': 3.0,\n            'y': [98.0, 102.0, 99.0, 140.0, 118.0, 95.0, 106.0, 101.0]\n        },\n        # Case B: Short series edge case, early times\n        {\n            'mu': 50.0, 'theta': (0.7, 0.1, -0.4), 'sigma2': 4.0, 'tau': 2.0,\n            'y': [50.0, 56.0, 46.0]\n        },\n        # Case C: Alternating-sign parameters, borderline and one spike\n        {\n            'mu': 200.0, 'theta': (-0.4, 0.3, -0.2), 'sigma2': 16.0, 'tau': 2.5,\n            'y': [205.0, 194.0, 195.0, 180.0, 210.0, 193.0]\n        },\n        # Case D: White noise baseline, no flags expected\n        {\n            'mu': 0.0, 'theta': (0.0, 0.0, 0.0), 'sigma2': 9.0, 'tau': 3.0,\n            'y': [1.0, -2.0, 4.0, -5.0, 6.0, -3.0]\n        },\n        # Case E: Back-to-back large deviations\n        {\n            'mu': 75.0, 'theta': (0.9, 0.4, 0.2), 'sigma2': 100.0, 'tau': 2.5,\n            'y': [70.0, 120.0, 65.0, 50.0]\n        }\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        mu = case['mu']\n        theta1, theta2, theta3 = case['theta']\n        sigma = np.sqrt(case['sigma2'])\n        tau = case['tau']\n        y_series = case['y']\n\n        eps_history = []\n        flagged_indices = []\n\n        for t_idx, y_t in enumerate(y_series):\n            # Time t is 1-based\n            t = t_idx + 1\n\n            # Get past innovations, using 0 for unavailable history\n            eps_tm1 = eps_history[t_idx - 1] if t_idx - 1 = 0 else 0.0\n            eps_tm2 = eps_history[t_idx - 2] if t_idx - 2 = 0 else 0.0\n            eps_tm3 = eps_history[t_idx - 3] if t_idx - 3 = 0 else 0.0\n\n            # Compute the one-step-ahead forecast\n            y_hat = mu + theta1 * eps_tm1 + theta2 * eps_tm2 + theta3 * eps_tm3\n\n            # Compute the current innovation (forecast error)\n            eps_t = y_t - y_hat\n            eps_history.append(eps_t)\n\n            # Standardize the error\n            z_t = eps_t / sigma\n\n            # Check if it exceeds the threshold\n            if abs(z_t)  tau:\n                flagged_indices.append(t)\n        \n        all_results.append(flagged_indices)\n\n    # Format the final output string exactly as required (no spaces)\n    result_strings = [f\"[{','.join(map(str, r))}]\" for r in all_results]\n    final_output = f\"[{','.join(result_strings)}]\"\n    \n    print(final_output)\n\nsolve()\n```", "id": "2412539"}, {"introduction": "前面的练习或假设模型已知，或使用了简化的检验，而本节将带来一个更全面的挑战：从零开始构建一个完整的模型估计与诊断流程。本练习 [@problem_id:2412549] 要求你为一个 $MA(5)$ 模型实现参数估计，并严格检验其残差项是否满足模型的基本假设。这对于任何严谨的数据分析者都至关重要，因为它强调了模型设定正确性检验（diagnostic checking）是建模过程中不可或缺的一环，并揭示了模型误设（misspecification）可能带来的后果。", "problem": "要求您在计算经济学与金融学的背景下，为移动平均 (MA) 模型实现一个端到端的估计与诊断性检验流程。该流程必须完全独立，并生成单行可验证的输出。您的程序必须仅从第一性原理和核心定义出发，实现以下内容。\n\n考虑一个单变量时间序列 $\\{x_t\\}_{t=1}^T$，代表每日股票指数的对数回报率。在有效市场中，每日回报率的常规均值模型使用 $q$ 阶移动平均过程 (MA($q$)) 来描述其均值动态：对于 $q \\in \\mathbb{N}$，MA($q$) 模型为\n$$\nx_t \\;=\\; \\mu \\;+\\; \\epsilon_t \\;+\\; \\theta_1 \\epsilon_{t-1} \\;+\\; \\cdots \\;+\\; \\theta_q \\epsilon_{t-q},\n$$\n其中 $\\mu \\in \\mathbb{R}$ 是无条件均值，$\\{\\epsilon_t\\}$ 是一个独立同分布的白噪声序列，满足 $E[\\epsilon_t] = 0$ 且 $\\operatorname{Var}(\\epsilon_t) = \\sigma^2 \\in \\mathbb{R}_{+}$，并且 $\\boldsymbol{\\theta}=(\\theta_1,\\ldots,\\theta_q) \\in \\mathbb{R}^q$。在有效市场中，单步预测误差（即估计的新息）应当是不可预测的，这意味着 $\\hat{\\epsilon}_t$ 对 $\\hat{\\epsilon}_{t+1}$ 不具有线性预测能力。\n\n您的任务是：\n- 对每个给定的数据集，使用条件平方和 (CSS) 方法拟合一个 MA($5$) 模型。CSS 的定义是通过模型恒等式递归计算残差，并对参数最小化残差平方和。具体而言，在初始条件 $\\hat{\\epsilon}_t = 0$ 对所有 $t \\le 0$ 成立的情况下，定义\n$$\n\\hat{\\epsilon}_t(\\mu, \\boldsymbol{\\theta}) \\;=\\; x_t \\;-\\; \\mu \\;-\\; \\sum_{j=1}^{5} \\theta_j \\hat{\\epsilon}_{t-j}(\\mu, \\boldsymbol{\\theta}),\n$$\n并对 $(\\mu, \\boldsymbol{\\theta}) \\in \\mathbb{R}^{6}$ 最小化 $\\sum_{t=1}^{T} \\hat{\\epsilon}_t(\\mu, \\boldsymbol{\\theta})^2$。\n- 在估计完参数并根据拟合的 MA($5$) 模型构建出估计的单步预测新息 $\\{\\hat{\\epsilon}_t\\}$ 后，使用 $\\hat{\\epsilon}_{t+1}$ 对一个常数和 $\\hat{\\epsilon}_t$ 的普通最小二乘 (OLS) 回归来检验原假设，即 $\\hat{\\epsilon}_t$ 对 $\\hat{\\epsilon}_{t+1}$ 没有线性预测能力：\n$$\n\\hat{\\epsilon}_{t+1} \\;=\\; \\alpha \\;+\\; \\beta \\hat{\\epsilon}_t \\;+\\; u_{t+1}.\n$$\n在原假设 $H_0: \\beta = 0$ 下，基于 $\\beta$ 的常规 OLS $t$ 统计量和 $T-2$ 的自由度，计算一个双边 p 值。使用显著性水平 $\\alpha_{\\text{test}} = 0.05$。\n- 对每个数据集报告一个布尔决策，遵循以下约定：如果在 $\\alpha_{\\text{test}}$ 水平上未能拒绝 $H_0$（解释为“残差不可预测”），则输出 $\\text{True}$；如果拒绝 $H_0$（解释为“残差对 $\\hat{\\epsilon}_{t+1}$ 具有预测能力”），则输出 $\\text{False}$。\n\n您必须遵守的基本依据和约束：\n- 仅使用白噪声的定义、MA($q$) 模型的定义以及通过模型恒等式构建 CSS 残差作为估计的骨干。不要使用预先构建的时间序列估计黑箱。\n- OLS 回归及其 $t$ 检验必须遵循标准的线性回归原理，其中 $t$ 统计量根据估计的斜率系数及其标准误计算，双边 p 值也相应计算。\n- 本问题不涉及物理单位。不出现角度单位。不应打印百分比。\n\n测试套件：\n模拟四个数据集，这些数据集模拟每日 Samp;P $500$ 回报率，其日度波动率在 $1\\%$ 的量级上是符合现实的。对于每种情况，模拟一个新息序列 $\\{w_t\\}$，其中 $w_t \\sim \\mathcal{N}(0,\\sigma^2)$ 且 $\\sigma = 0.01$，并为了一般性，将过程构建为自回归移动平均 (ARMA) 模型：\n$$\nx_t - \\mu \\;=\\; \\phi (x_{t-1} - \\mu) \\;+\\; w_t \\;+\\; \\sum_{j=1}^{5} \\theta_j w_{t-j},\n$$\n其中 $x_0 = \\mu$ 且对于 $t \\le 0$ 有 $w_t = 0$。当 $\\phi = 0$ 时，该模型包含 MA($5$) 作为其特例。对每个数据集，使用以下参数：\n\n- 情况 1 (基准 MA($5$)，“有效”均值模型)：\n  - Seed $= 202311$，长度 $T = 900$，$\\mu = 0$，$\\phi = 0$，$\\boldsymbol{\\theta} = (0.4, -0.3, 0.2, -0.1, 0.05)$，$\\sigma = 0.01$。\n- 情况 2 (具有温和自回归的 ARMA($1,5$)，若仅拟合 MA($5$) 则模型设定错误)：\n  - Seed $= 202312$，长度 $T = 900$，$\\mu = 0$，$\\phi = 0.3$，$\\boldsymbol{\\theta} = (0.4, -0.3, 0.2, -0.1, 0.05)$，$\\sigma = 0.01$。\n- 情况 3 (白噪声均值动态，MA($0$))：\n  - Seed $= 202313$，长度 $T = 600$，$\\mu = 0$，$\\phi = 0$，$\\boldsymbol{\\theta} = (0, 0, 0, 0, 0)$，$\\sigma = 0.01$。\n- 情况 4 (具有中等持续性的纯自回归 AR($1$)，若仅拟合 MA($5$) 则模型设定错误)：\n  - Seed $= 202314$，长度 $T = 250$，$\\mu = 0$，$\\phi = 0.6$，$\\boldsymbol{\\theta} = (0, 0, 0, 0, 0)$，$\\sigma = 0.01$。\n\n您的程序必须：\n- 使用给定的种子和参数，精确地模拟每个数据集。\n- 对每个数据集通过 CSS 拟合一个 MA($5$) 模型，以获得 $\\{\\hat{\\epsilon}_t\\}$。\n- 在 $\\hat{\\epsilon}_{t+1}$ 对常数项和 $\\hat{\\epsilon}_t$ 的回归中，使用显著性水平为 $\\alpha_{\\text{test}} = 0.05$ 的双边检验，对 $H_0: \\beta = 0$ 进行 OLS 检验，并按前述方式形成决策。\n- 生成单行输出，其中包含一个 Python 风格的布尔值列表，按情况 1,2,3,4 的顺序排列，例如 $[\\,\\text{True},\\text{False},\\text{True},\\text{False}\\,]$。\n\n您的程序必须是一个完整的、可运行的脚本，并且不得需要任何用户输入或外部文件。最终输出格式必须是严格的一行，即一个由方括号括起来、逗号分隔的布尔值列表。", "solution": "问题陈述已经过严格评估，并被认为是有效的。它具有科学依据，提法明确且客观。它为时间序列计量经济学中的一个标准练习提供了完整且一致的指令集：移动平均 (MA) 模型的估计及其残差的诊断性检验。该过程要求从第一性原理开始实现，这是对基本理解的严格考验。唯一注意到的小不一致之处是，指定的 $t$ 检验自由度为 $T-2$，而非在具有 $T-1$ 个观测值的回归中通常使用的 $T-3$。这一点被解释为一条直接而明确的指令，而非一个使问题无效的缺陷。我们按规定继续进行解答。\n\n解决方案分为三个主要阶段：\n1.  根据指定的自回归移动平均 (ARMA) 过程，模拟时间序列数据。\n2.  对每个数据集，使用条件平方和 (CSS) 方法估计一个 5 阶移动平均模型，即 MA(5)。\n3.  使用基于普通最小二乘 (OLS) 回归的检验，对估计模型的残差进行一阶序列自相关性的诊断性检验。\n\n**1. 时间序列模拟**\n\n该问题要求从一个通用的 ARMA(1,5) 过程中生成四个数据集。时间序列 $\\{x_t\\}$ 的模型由下式给出：\n$$\nx_t - \\mu \\;=\\; \\phi (x_{t-1} - \\mu) \\;+\\; w_t \\;+\\; \\sum_{j=1}^{5} \\theta_j w_{t-j}\n$$\n其中 $\\mu$ 是均值，$\\phi$ 是自回归系数，$\\boldsymbol{\\theta} = (\\theta_1, \\ldots, \\theta_5)$ 是移动平均系数，$\\{w_t\\}$ 是一个高斯白噪声过程，满足 $w_t \\sim \\mathcal{N}(0, \\sigma^2)$。模拟从初始条件 $x_0 = \\mu$ 和 $w_t = 0$（对于 $t \\le 0$）开始。数据 $\\{x_t\\}_{t=1}^T$ 是为四个指定的参数集中的每一个递归生成的。这种设置允许在模型设定正确（情况 1 和 3）和模型设定错误（情况 2 和 4）两种条件下，检验 MA(5) 估计程序的性能。\n\n**2. 通过条件平方和 (CSS) 进行 MA(5) 估计**\n\n对每个模拟的时间序列 $\\{x_t\\}_{t=1}^T$，我们拟合一个 MA(5) 模型：\n$$\nx_t \\;=\\; \\mu \\;+\\; \\epsilon_t \\;+\\; \\sum_{j=1}^{5} \\theta_j \\epsilon_{t-j}\n$$\n待估计的参数是均值 $\\mu$ 和 MA 系数 $\\boldsymbol{\\theta} = (\\theta_1, \\ldots, \\theta_5)$。估计是通过最小化条件平方和 (CSS) 来执行的。这包括递归地计算模型的残差 $\\{\\hat{\\epsilon}_t\\}$ 并最小化它们的平方和。\n\n残差通过重新整理模型方程来定义：\n$$\n\\hat{\\epsilon}_t(\\mu, \\boldsymbol{\\theta}) \\;=\\; x_t \\;-\\; \\mu \\;-\\; \\sum_{j=1}^{5} \\theta_j \\hat{\\epsilon}_{t-j}(\\mu, \\boldsymbol{\\theta})\n$$\n为了开始递归，我们设定初始条件 $\\hat{\\epsilon}_t = 0$ 对所有 $t \\le 0$ 成立。要最小化的目标函数是残差平方和：\n$$\nS(\\mu, \\boldsymbol{\\theta}) = \\sum_{t=1}^{T} \\hat{\\epsilon}_t(\\mu, \\boldsymbol{\\theta})^2\n$$\n这是一个关于 $6$ 个参数 $(\\mu, \\theta_1, \\ldots, \\theta_5)$ 的非线性优化问题。我们采用一种数值拟牛顿优化算法（具体是在 `scipy.optimize` 中可用的 L-BFGS-B）来找到最小化 $S(\\mu, \\boldsymbol{\\theta})$ 的参数估计值 $(\\hat{\\mu}, \\hat{\\boldsymbol{\\theta}})$。一旦找到这些估计值，就计算出最终的估计新息序列，即残差 $\\{\\hat{\\epsilon}_t\\}_{t=1}^T$。\n\n**3. 残差自相关的诊断性检验**\n\n一个设定正确并被准确估计的时间序列模型所剩下的残差，应该无法从其自身的历史值中预测；也就是说，它们应近似于一个白噪声过程。为了检验这一点，我们考察在时间 $t$ 的估计新息 $\\hat{\\epsilon}_t$ 是否对时间 $t+1$ 的新息 $\\hat{\\epsilon}_{t+1}$ 具有任何线性预测能力。这通过一个 OLS 回归来检验：\n$$\n\\hat{\\epsilon}_{t+1} \\;=\\; \\alpha \\;+\\; \\beta \\hat{\\epsilon}_t \\;+\\; u_{t+1}, \\quad t = 1, \\ldots, T-1\n$$\n无一阶序列自相关的原假设是 $H_0: \\beta = 0$。我们计算 OLS 估计值 $\\hat{\\beta}$ 及其相关的 $t$ 统计量。\n\n$\\beta$ 的 OLS 估计值是向量 $\\hat{\\mathbf{b}} = (\\hat{\\alpha}, \\hat{\\beta})'$ 的一个分量，由下式给出：\n$$\n\\hat{\\mathbf{b}} = (X'X)^{-1}X'Y\n$$\n其中 $Y$ 是因变量向量 $(\\hat{\\epsilon}_2, \\ldots, \\hat{\\epsilon}_T)'$，$X$ 是设计矩阵，其行向量为 $(1, \\hat{\\epsilon}_t)$，其中 $t=1, \\ldots, T-1$。\n\n$\\hat{\\beta}$ 的 $t$ 统计量计算如下：\n$$\nt_{\\hat{\\beta}} = \\frac{\\hat{\\beta}}{\\text{s.e.}(\\hat{\\beta})}\n$$\n标准误 $\\text{s.e.}(\\hat{\\beta})$ 是估计的系数协方差矩阵 $\\hat{\\sigma}_u^2 (X'X)^{-1}$ 中相应对角线元素的平方根。回归误差的方差 $\\sigma_u^2$ 通过 $s_u^2 = \\frac{1}{N_{\\text{reg}}-2} \\sum u_t^2$ 来估计，其中 $N_{\\text{reg}}=T-1$ 是回归中的观测数量，$u_t$ 是 OLS 残差。\n\n然后我们为这个 $t$ 统计量计算一个双边 $p$ 值。根据问题的明确指令，我们使用具有 $T-2$ 自由度的学生 $t$ 分布。\n\n最终决策是通过将 $p$ 值与显著性水平 $\\alpha_{\\text{test}} = 0.05$ 进行比较得出的：\n- 如果 $p$ 值 $\\ge 0.05$，我们未能拒绝原假设 $H_0$。这表明残差是序列不相关的，并且模型在这一维度上是充分的。输出为 `True`。\n- 如果 $p$ 值 $ 0.05$，我们拒绝 $H_0$。这表示残差中存在显著的序列相关性，表明模型设定有误。输出为 `False`。\n\n这个完整的流程被应用于四个模拟数据集中的每一个，最终以布尔决策序列的形式报告最终答案。", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import t\n\ndef solve():\n    \"\"\"\n    Main function to run the entire estimation and testing pipeline for all test cases.\n    \"\"\"\n    # Define the test cases as per the problem statement.\n    test_cases = [\n        {\n            \"name\": \"Case 1: MA(5)\",\n            \"seed\": 202311, \"T\": 900, \"mu\": 0.0, \"phi\": 0.0,\n            \"theta\": np.array([0.4, -0.3, 0.2, -0.1, 0.05]), \"sigma\": 0.01\n        },\n        {\n            \"name\": \"Case 2: ARMA(1,5)\",\n            \"seed\": 202312, \"T\": 900, \"mu\": 0.0, \"phi\": 0.3,\n            \"theta\": np.array([0.4, -0.3, 0.2, -0.1, 0.05]), \"sigma\": 0.01\n        },\n        {\n            \"name\": \"Case 3: MA(0) / White Noise\",\n            \"seed\": 202313, \"T\": 600, \"mu\": 0.0, \"phi\": 0.0,\n            \"theta\": np.array([0.0, 0.0, 0.0, 0.0, 0.0]), \"sigma\": 0.01\n        },\n        {\n            \"name\": \"Case 4: AR(1)\",\n            \"seed\": 202314, \"T\": 250, \"mu\": 0.0, \"phi\": 0.6,\n            \"theta\": np.array([0.0, 0.0, 0.0, 0.0, 0.0]), \"sigma\": 0.01\n        }\n    ]\n    \n    alpha_test = 0.05\n    results = []\n\n    for case in test_cases:\n        # Step 1: Simulate time series data\n        x_t = simulate_arma_process(\n            T=case[\"T\"], mu=case[\"mu\"], phi=case[\"phi\"], \n            theta=case[\"theta\"], sigma=case[\"sigma\"], seed=case[\"seed\"]\n        )\n        \n        # Step 2: Fit an MA(5) model and get residuals\n        residuals = estimate_ma_and_get_residuals(x_t, q=5)\n        \n        # Step 3: Perform diagnostic test on residuals\n        decision = perform_diagnostic_test(residuals, alpha_test)\n        results.append(decision)\n        \n    print(f\"[{','.join(map(str, results))}]\")\n\ndef simulate_arma_process(T, mu, phi, theta, sigma, seed):\n    \"\"\"\n    Simulates an ARMA(1, q) process given parameters.\n    \"\"\"\n    np.random.seed(seed)\n    q = len(theta)\n    \n    # Generate white noise innovations\n    w = np.random.normal(loc=0.0, scale=sigma, size=T)\n    \n    # Initialize the time series array\n    x = np.zeros(T)\n    \n    # Create padded arrays for past values\n    x_padded = np.concatenate((np.full(1, mu), x)) # x_padded[t] corresponds to x_{t-1}\n    w_padded = np.concatenate((np.zeros(q), w)) # w_padded[t+q] corresponds to w_t\n    \n    for t_idx in range(T): # t_idx from 0 to T-1\n        # In math notation, this corresponds to t = t_idx + 1\n        \n        # AR term: phi * (x_{t-1} - mu)\n        ar_term = phi * (x_padded[t_idx] - mu)\n        \n        # MA term: sum_{j=1 to q} theta_j * w_{t-j}\n        ma_term = 0\n        for j in range(q): # j from 0 to q-1\n            # lag j+1, theta_{j+1}, w_{t-(j+1)}\n            ma_term += theta[j] * w_padded[t_idx + q - (j + 1)]\n            \n        x[t_idx] = mu + ar_term + w[t_idx] + ma_term\n        x_padded[t_idx+1] = x[t_idx]\n        \n    return x\n\ndef estimate_ma_and_get_residuals(x, q):\n    \"\"\"\n    Estimates an MA(q) model using CSS and returns the residuals.\n    \"\"\"\n    # Objective function for CSS minimization\n    def css_objective(params, x_data, q_order):\n        T = len(x_data)\n        mu = params[0]\n        theta = params[1:]\n        eps_hat = np.zeros(T)\n        \n        for i in range(T): # i from 0 to T-1, corresponds to time t=i+1\n            ma_term = 0\n            for j in range(q_order): # j from 0 to q-1, corresponds to lag j+1\n                idx = i - (j + 1)\n                if idx = 0:\n                    ma_term += theta[j] * eps_hat[idx]\n            eps_hat[i] = x_data[i] - mu - ma_term\n        \n        return np.sum(eps_hat**2)\n\n    # Initial guess for parameters (mu, theta_1, ..., theta_q)\n    initial_params = np.zeros(q + 1)\n    \n    # Minimize the CSS\n    opt_result = minimize(\n        css_objective, \n        initial_params, \n        args=(x, q),\n        method='L-BFGS-B'\n    )\n    \n    # Get estimated parameters\n    estimated_params = opt_result.x\n    \n    # Compute final residuals with estimated parameters\n    T = len(x)\n    mu_hat = estimated_params[0]\n    theta_hat = estimated_params[1:]\n    residuals = np.zeros(T)\n    for i in range(T):\n        ma_term = 0\n        for j in range(q):\n            idx = i - (j + 1)\n            if idx = 0:\n                ma_term += theta_hat[j] * residuals[idx]\n        residuals[i] = x[i] - mu_hat - ma_term\n        \n    return residuals\n\ndef perform_diagnostic_test(eps_hat, alpha_level):\n    \"\"\"\n    Tests H0: beta=0 in eps_{t+1} = alpha + beta*eps_t + u_{t+1}.\n    Returns True if we fail to reject H0, False otherwise.\n    \"\"\"\n    T = len(eps_hat)\n    \n    # Prepare data for OLS regression\n    y = eps_hat[1:]       # eps_{t+1} for t=1,...,T-1\n    x_reg = eps_hat[:-1]  # eps_t for t=1,...,T-1\n    \n    N_reg = len(y) # Number of observations in regression, T-1\n    \n    # Add a constant (intercept) to the regressor\n    X_reg = np.vstack([np.ones(N_reg), x_reg]).T\n    \n    # OLS estimator: (X'X)^{-1}X'y\n    try:\n        XTX_inv = np.linalg.inv(X_reg.T @ X_reg)\n        b_hat = XTX_inv @ X_reg.T @ y\n    except np.linalg.LinAlgError:\n        # Handle cases of perfect multicollinearity (unlikely with this data)\n        return True # Cannot reject H0 if test cannot be performed\n\n    beta_hat = b_hat[1]\n    \n    # Calculate t-statistic\n    ols_residuals = y - X_reg @ b_hat\n    \n    # Estimate variance of regression error term u\n    # Degrees of freedom for residual variance is N_reg - number of parameters (2)\n    df_residual = N_reg - 2\n    if df_residual = 0:\n        return True # Not enough data to perform test\n    \n    s2_u = np.sum(ols_residuals**2) / df_residual\n    \n    # Covariance matrix of beta estimates\n    var_b_hat = s2_u * XTX_inv\n    se_beta_hat = np.sqrt(var_b_hat[1, 1])\n    \n    if se_beta_hat == 0:\n        return True # Avoid division by zero\n        \n    t_stat = beta_hat / se_beta_hat\n    \n    # Calculate p-value using t-distribution\n    # As per problem, degrees of freedom is T-2\n    df_test = T - 2\n    p_value = 2 * t.sf(np.abs(t_stat), df=df_test)\n    \n    # Decision rule\n    return p_value = alpha_level\n\nif __name__ == \"__main__\":\n    solve()\n\n```", "id": "2412549"}]}