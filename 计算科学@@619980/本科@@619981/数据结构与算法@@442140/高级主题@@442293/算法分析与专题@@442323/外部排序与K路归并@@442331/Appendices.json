{"hands_on_practices": [{"introduction": "理论知识的应用不仅限于标准问题，更在于如何巧妙地调整算法以适应新的需求。本练习提出一个在外部归并排序中动态过滤过期记录的挑战，这在数据库和流处理系统中非常常见。通过评估不同策略的优劣，你将学会如何在不牺牲核心性能的前提下，将新功能优雅地集成到现有算法中。[@problem_id:3233058]", "problem": "一个外部归并排序被用于在外部存储模型（EMM）下，按主键对磁盘上的 $N$ 条记录进行排序，其中主存大小为 $M$ 字节，磁盘块大小为 $B$ 字节，并且归并过程使用一个$k$路选择堆来处理 $k$ 个输入顺串。每条记录 $r$ 带有生存时间（TTL）时间戳，被解释为绝对过期时间 $e(r)$。在当前时间 $t$，一条记录被认为是有效的，当且仅当 $e(r) \\ge t$。标准外部归并排序的输入/输出（I/O）成本主要来自于每遍读写 $\\Theta(N/B)$ 个块，而遍数由顺串数量和归并扇入 $k$ 决定。目标是在归并期间动态地丢弃过期记录，同时不改变剩余有效记录按主键的排序顺序，并且不增加渐进I/O复杂度。\n\n对$k$路外部归并算法进行何种修改最合适，以确保只有有效记录被输出，输出结果与仅使用稳定排序对有效记录按主键排序的结果相同，并且以块为单位的渐进I/O复杂度保持不变（除了因丢弃记录可能导致的写入减少）？\n\nA. 修改$k$路堆中的比较器，使其首先按过期时间 $e(r)$ 排序，其次按主键排序，这样 $e(r)$ 较小的记录会更早地被弹出；当弹出的记录过期时（即 $e(r)  t$），将其丢弃而不是写入。\n\nB. 保持比较器按主键排序，并引入一个基于每个顺串的有效性过滤器：每当一个顺串的输入缓冲区被重新填满时，扫描其在内存中的前端记录，对于每个 $e(r)  t$ 的记录，立即将其丢弃，而不推入$k$路堆；只将按主键排序的有效记录推入。当一个顺串的有效记录耗尽时，它将不再向堆中提供元素。\n\nC. 执行完整的外部排序，忽略TTL，然后在最终排序好的输出上进行一次额外的完整遍历，以丢弃所有 $e(r)  t$ 的记录；这确保了有效的输出，同时保持归并过程不变。\n\nD. 将内存划分为两个堆：一个用于过期记录，一个用于有效记录。在归并期间，根据 $e(r) \\ge t$ 将每条记录推入其中一个堆，并将过期记录写入一个单独的丢弃文件，以使其不出现在最终输出中。在每个堆内部保持按主键的比较器。", "solution": "问题陈述是有效的。它描述了外部排序中的一个标准场景，并附加了一个过滤需求，这是数据处理和数据库系统中的常见任务。约束和目标在外部存储模型（EMM）的框架内得到了很好的定义。\n\n目标是修改一个$k$路外部归并排序，以过滤掉由 $e(r)  t$ 定义的过期记录，而不改变有效记录的最终排序顺序，也不增加渐进I/O复杂度。记录总数为 $N$，主存为 $M$ 字节，磁盘块大小为 $B$ 字节。外部归并排序的标准I/O成本为 $\\Theta((N/B) \\log_{M/B}(N/B))$ 次块传输。这个成本来自于大约 $\\log_{k}(N/M)$ 次归并遍，其中每一遍都会读取和写入整个数据集。扇入 $k$ 通常被选择为 $M/B$ 的数量级。\n\n一个理想的修改应该将过滤逻辑无缝地集成到归并遍中。这意味着应该尽早识别并丢弃过期记录，以避免将它们写入中间顺串并在后续遍中再次读回所产生的I/O成本。\n\n让我们根据这些标准评估每个选项。\n\nA. 修改$k$路堆中的比较器，使其首先按过期时间 $e(r)$ 排序，其次按主键排序，这样 $e(r)$ 较小的记录会更早地被弹出；当弹出的记录过期时（即 $e(r)  t$），将其丢弃而不是写入。\n这项修改存在根本性缺陷。主要目标是生成一个按主键排序的输出文件。通过改变堆的比较器以优先处理 $e(r)$，归并过程将生成一个按过期时间排序的输出，而不是按主键排序。这违反了问题的一个核心要求。\n结论：**不正确**。\n\nB. 保持比较器按主键排序，并引入一个基于每个顺串的有效性过滤器：每当一个顺串的输入缓冲区被重新填满时，扫描其在内存中的前端记录，对于每个 $e(r)  t$ 的记录，立即将其丢弃，而不推入$k$路堆；只将按主键排序的有效记录推入。当一个顺串的有效记录耗尽时，它将不再向堆中提供元素。\n这种方法正确地集成了过滤逻辑。$k$路堆保持其标准功能：按主键对元素进行排序。在考虑将来自输入顺串的元素放入堆之前，使用条件 $e(r) \\ge t$ 检查其有效性。这个检查是在从磁盘读取一个块后在主存中进行的。如果记录无效，它被简单地丢弃，并考虑其所在顺串的下一个记录。这个过程一直持续到找到一个有效的记录或顺串耗尽为止。这个过程确保了只有有效记录被放入堆中，并随后被写入归并输出。I/O复杂度没有增加。实际上，它减少了。在归并遍期间，一个过期的记录从磁盘被读取一次，但立即在内存中被丢弃，并且不会被写入该遍的输出。因此，它在任何后续的归并遍中都不会被再次读取或写入。遍数保持不变，为 $\\lceil \\log_k (\\lceil N/M \\rceil) \\rceil$，每遍读取的块数最多与原来相同，而写入的块数则减少了。因此，渐进I/O复杂度保持不变或得到改善。此方法正确地生成了一个按主键稳定排序的有效记录列表。\n结论：**正确**。\n\nC. 执行完整的外部排序，忽略TTL，然后在最终排序好的输出上进行一次额外的完整遍历，以丢弃所有 $e(r)  t$ 的记录；这确保了有效的输出，同时保持归并过程不变。\n这种方法能产生正确的输出。完整的外部排序后跟一个过滤遍，将得到一个按主键排序的有效记录列表。然而，从I/O的角度来看，这是非常低效的。它要求所有 $N$ 条记录，包括过期的记录，在每一个归并遍中都被读取和写入。只有在整个排序完成后，它才执行一个额外的遍来进行过滤，这会产生额外的 $\\Theta(N/B)$ I/O成本，用于读取排序后的数据和写入最终过滤后的结果。与选项B相比（在过程早期就淘汰了过期记录），该方法执行了大量可避免的I/O。问题要求的是“最合适的”修改，这意味着效率是一个关键考虑因素。增加一个完整的遍不是最有效的解决方案，即使整体的渐进复杂度类别 $\\Theta((N/B) \\log_{M/B}(N/B))$ 保持不变。\n结论：**不正确**。\n\nD. 将内存划分为两个堆：一个用于过期记录，一个用于有效记录。在归并期间，根据 $e(r) \\ge t$ 将每条记录推入其中一个堆，并将过期记录写入一个单独的丢弃文件，以使其不出现在最终输出中。在每个堆内部保持按主键的比较器。\n这个解决方案过于复杂且效率低下。首先，没有理由维护一个排序好的过期记录堆。由于它们将被丢弃，它们的顺序是无关紧要的。这是浪费计算资源。其次，将过期记录写入一个单独的丢弃文件会产生不必要的写I/O。目标是丢弃它们，而不是将它们存储在别处。这直接违背了最小化I/O的目标。与选项B相比（它只是在内存中丢弃过期记录，没有额外的I/O），这个选项执行了更多的工作（维护第二个堆）和更多的I/O（写入丢弃文件）。\n结论：**不正确**。\n\n基于此分析，选项B是唯一能够正确且高效地满足所有规定条件的方法。它将过滤无缝集成到归并过程中，保持了所需的排序顺序，并通过在归并过程中尽早淘汰过期记录来避免增加渐进I/O复杂度。", "answer": "$$\\boxed{B}$$", "id": "3233058"}, {"introduction": "从理论上的 I/O 计数到实际的系统吞吐量预测，是算法工程师必须跨越的一步。本练习要求你为现代存储设备 (SSD 和 HDD) 上的 $k$-路归并建立一个精细的性能模型，该模型考虑了异步 I/O、双缓冲和计算与 I/O 的重叠。通过编程实现这个模型，你将能够量化不同硬件参数和算法选择对真实世界性能的影响，从而做出更优的系统设计决策。[@problem_id:3232934]", "problem": "要求您建模并实现由多流异步输入/输出（I/O）驱动、采用双缓冲区的外部 k 路归并的持续吞吐量。目标是使用一个有原则的性能模型，推导在固态硬盘（SSD）和机械硬盘（HDD）两类设备下的稳态吞吐量。然后，您必须编写一个完整、可运行的程序，为一组固定的测试用例计算预测的吞吐量。\n\n假设和背景：\n- 外部排序归并存储在二级存储上的顺串，其数据量远超随机存取存储器（RAM）的容量。k 路归并从 $K$ 个已排序的输入流中读取数据，并生成一个单一的已排序输出流。\n- 该算法为每个输入流使用两个缓冲区，为输出流也使用两个缓冲区（双缓冲）。当一个缓冲区由中央处理器（CPU）处理时，另一个缓冲区则由异步 I/O 进行填充或刷出。\n- 归并过程使用一个大小为 $K$ 的最小堆来选择下一个输出元素，每个元素的 CPU 工作量随 $K$ 的对数增长。\n- 每一轮处理每个输入流中一个大小为 $C$ 字节的数据块，因此每轮总共输出 $K \\cdot C$ 字节。\n- 元素大小为 $s$ 字节，每次比较的成本为 $t_{\\mathrm{comp}}$ 秒。假设比较操作在归并的 CPU 时间中占主导地位。\n- 对于单个设备上大小为 $X$ 字节的单次阻塞式请求，其 I/O 计时模型由基本的设备性能关系定义：请求时间等于访问延迟加上传输时间。访问延迟为 $L$ 秒，流式带宽为 $B$ 字节/秒。每轮针对特定设备类别的假设如下：\n  - SSD 模型：每个大小为 $C$ 的输入读取请求成本为一个访问延迟加上传输时间；共有 $K$ 个此类读取。大小为 $K \\cdot C$ 的输出写入请求成本为一个访问延迟加上传输时间。\n  - HDD 模型：每个大小为 $C$ 的输入读取请求会产生平均寻道和旋转延迟加上传输时间；共有 $K$ 个此类读取。大小为 $K \\cdot C$ 的输出写入请求同样产生一个延迟加上传输时间。由于机械移动，将 $K$ 个输入读取视为在设备上串行化处理。将输入设备和输出设备视为独立的，因此读取和写入可以重叠。\n- 采用异步 I/O 的双缓冲形成了一个流水线，在稳态下，读取下一轮的输入、写入当前轮的输出以及 CPU 归并当前轮的操作是重叠的。\n- 轮次时间等于此流水线中瓶颈阶段的时间，持续吞吐量等于每轮的字节数除以轮次时间。\n\n您的任务：\n- 根据以上假设，从第一性原理出发，推导稳态轮次时间。推导过程仅需基于上述定义以及单次大小为 $X$ 的阻塞式 I/O 请求耗时为延迟加传输时间这一基本设备性能关系。\n- 实现一个程序，计算以兆字节/秒（MiB/s）为单位的持续吞吐量，其中一兆字节等于 $2^{20}$ 字节，结果四舍五入到三位小数。根据描述，使用双缓冲重叠来计算稳态吞吐量。\n- 对于基于堆的归并成本，请使用以 2 为底的对数。您可以假设每个输出元素的比较次数与 $\\log_{2}(K)$ 成正比。\n\n输入和输出规范：\n- 没有运行时输入。您的程序必须内嵌并评估以下参数集的测试套件。对于每个测试用例，计算以 MiB/s 为单位的持续吞吐量，结果为单个浮点数，四舍五入到三位小数。您的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表（例如，“[x,y,z]”）。\n\n测试套件：\n每个测试用例是一个形式为（设备类型，$K$，$C$，$s$，$t_{\\mathrm{comp}}$，$B_{\\mathrm{in}}$，$B_{\\mathrm{out}}$，$L_{\\mathrm{in}}$，$L_{\\mathrm{out}}$）的元组，其中：\n- device-type 是“SSD”或“HDD”；它决定了延迟的解释方式，但使用相同的计算结构，\n- $K$ 是输入流的数量，\n- $C$ 是每个流的数据块大小（以字节为单位），\n- $s$ 是元素大小（以字节为单位），\n- $t_{\\mathrm{comp}}$ 是每次比较的时间（以秒为单位），\n- $B_{\\mathrm{in}}$ 和 $B_{\\mathrm{out}}$ 是输入和输出带宽（以字节/秒为单位），\n- $L_{\\mathrm{in}}$ 和 $L_{\\mathrm{out}}$ 是输入和输出访问延迟（以秒为单位）。\n\n使用以下七个案例：\n- 案例 A (SSD, 通用吞吐量): (\"SSD\", $8$, $4,000,000$, $8$, $1 \\times 10^{-9}$, $1.5 \\times 10^{9}$, $1.5 \\times 10^{9}$, $5.0 \\times 10^{-5}$, $5.0 \\times 10^{-5}$)。\n- 案例 B (HDD, 寻道主导): (\"HDD\", $8$, $4,000,000$, $8$, $1 \\times 10^{-9}$, $1.5 \\times 10^{8}$, $1.5 \\times 10^{8}$, $1.0 \\times 10^{-2}$, $1.0 \\times 10^{-2}$)。\n- 案例 C (SSD, 计算密集型): (\"SSD\", $8$, $4,000,000$, $8$, $5.0 \\times 10^{-8}$, $1.5 \\times 10^{9}$, $1.5 \\times 10^{9}$, $5.0 \\times 10^{-5}$, $5.0 \\times 10^{-5}$)。\n- 案例 D (SSD, 延迟主导的小数据块): (\"SSD\", $8$, $4096$, $8$, $1 \\times 10^{-9}$, $1.5 \\times 10^{9}$, $1.5 \\times 10^{9}$, $5.0 \\times 10^{-5}$, $5.0 \\times 10^{-5}$)。\n- 案例 E (SSD, 大 $K$ 值): (\"SSD\", $64$, $4,000,000$, $8$, $1 \\times 10^{-9}$, $1.5 \\times 10^{9}$, $1.5 \\times 10^{9}$, $5.0 \\times 10^{-5}$, $5.0 \\times 10^{-5}$)。\n- 案例 F (HDD, $K = 1$ 边界情况): (\"HDD\", $1$, $4,000,000$, $8$, $1 \\times 10^{-9}$, $1.5 \\times 10^{8}$, $1.5 \\times 10^{8}$, $1.0 \\times 10^{-2}$, $1.0 \\times 10^{-2}$)。\n- 案例 G (SSD, 写带宽瓶颈): (\"SSD\", $8$, $4,000,000$, $8$, $1 \\times 10^{-9}$, $1.5 \\times 10^{9}$, $3.0 \\times 10^{8}$, $5.0 \\times 10^{-5}$, $5.0 \\times 10^{-5}$)。\n\n输出单位和格式：\n- 以兆字节/秒（MiB/s）表示每个吞吐量，四舍五入到三位小数。\n- 您的程序必须以“[v1,v2,v3,v4,v5,v6,v7]”的格式精确打印一行，其中每个 $v_{i}$ 是对应测试用例的四舍五入后的吞吐量，顺序与上面相同。", "solution": "该问题是有效的，因为它基于外部存储器算法的标准性能建模原则，提出了一个有科学依据、定义明确且客观的任务。该问题自成体系，没有矛盾之处。我现在将进行推导和求解。\n\n目标是推导使用双缓冲和异步 I/O 的 $K$ 路归并算法的稳态吞吐量。系统性能被建模为一个三级流水线。在稳态下，每轮的时间由最慢的阶段（瓶颈）决定，吞吐量是每轮处理的数据量除以此轮次时间。\n\n归并过程的单轮操作包括从 $K$ 个输入流中各读取一个大小为 $C$ 的数据块，并将它们归并以生成一个大小为 $K \\cdot C$ 的输出块。因此，每轮处理的总数据量为 $N_{\\text{bytes\\_round}} = K \\cdot C$。\n\n该流水线由三个阶段组成，这些阶段在不同轮次的数据上并行操作：\n$1$. **CPU 归并**：CPU 归并来自第 $i$ 轮的输入块，以生成第 $i$ 轮的输出。\n$2$. **输入读取**：I/O 系统为下一轮（第 $i+1$ 轮）读取 $K$ 个输入块。\n$3$. **输出写入**：I/O 系统写入来自上一轮（第 $i-1$ 轮）的已归并输出块。在稳态下，我们将其视为当前第 $i$ 轮的输出。\n\n在稳态下，完成一轮所需的时间 $T_{\\text{round}}$ 是这三个阶段中每个阶段所用时间的最大值。\n$$T_{\\text{round}} = \\max(T_{\\text{CPU}}, T_{\\text{Read}}, T_{\\text{Write}})$$\n\n我们现在推导每个阶段所用时间的表达式。\n\n**1. CPU 时间 ($T_{\\text{CPU}}$)**\nCPU 时间主要由基于堆的归并所需的元素比较决定。使用一个大小为 $K$ 的最小堆来在所有输入流中找到下一个最小的元素。\n- 一轮中处理的元素数量为 $N_{\\text{elem}} = \\frac{N_{\\text{bytes\\_round}}}{s} = \\frac{K \\cdot C}{s}$，其中 $s$ 是每个元素的大小（以字节为单位）。\n- 问题指出，每个输出元素的比较次数与 $\\log_{2}(K)$ 成正比。我们假设一个标准的二叉堆实现，其中替换最小元素需要的比较次数在 $\\log_{2}(K)$ 的数量级。我们将比例常数取为 1，因此每个元素的比较次数为 $\\log_{2}(K)$。\n- 执行一次比较的时间给定为 $t_{\\text{comp}}$。\n- 因此，在一轮中归并所有元素的总 CPU 时间为：\n$$T_{\\text{CPU}} = N_{\\text{elem}} \\cdot (\\text{comparisons per element}) \\cdot t_{\\text{comp}} = \\left(\\frac{K \\cdot C}{s}\\right) \\cdot \\log_{2}(K) \\cdot t_{\\text{comp}}$$\n对于 $K=1$ 的特殊情况，不需要归并，且 $\\log_{2}(1) = 0$，这正确地得出 $T_{\\text{CPU}} = 0$。\n\n**2. 输入读取时间 ($T_{\\text{Read}}$)**\n这是为下一轮读取 $K$ 个输入块所需的时间。问题明确指出，这涉及 $K$ 个独立的读取请求，每个请求的大小为 $C$。单个大小为 $X$ 的请求的基本 I/O 性能关系为 $T_{\\text{I/O}}(X) = L + \\frac{X}{B}$，其中 $L$ 是延迟，$B$ 是带宽。\n- 对于 SSD 和 HDD 模型，问题都暗示从总时间计算的角度来看，$K$ 次输入读取实际上是串行化的。对于 HDD，由于机械磁头的移动，这是明确的。对于 SSD，指令“每个大小为 C 的输入读取请求成本为一个访问延迟加上传输时间”导致了一个加法模型。\n- 单个大小为 $C$ 的输入读取时间：$L_{\\text{in}} + \\frac{C}{B_{\\text{in}}}$。\n- 一轮中读取所有 $K$ 个数据块的总时间：\n$$T_{\\text{Read}} = K \\cdot \\left(L_{\\text{in}} + \\frac{C}{B_{\\text{in}}}\\right)$$\n\n**3. 输出写入时间 ($T_{\\text{Write}}$)**\n这是写入大小为 $K \\cdot C$ 的单个合并输出块所需的时间。\n- 写入的总大小为 $X = K \\cdot C$。\n- 该写入作为单个 I/O 请求执行。\n- 使用基本的 I/O 关系，总写入时间为：\n$$T_{\\text{Write}} = L_{\\text{out}} + \\frac{K \\cdot C}{B_{\\text{out}}}$$\n\n**4. 持续吞吐量 ($\\Theta$)**\n持续吞吐量是每轮处理的总数据量除以轮次时间。\n- 以字节/秒为单位的吞吐量：\n$$\\Theta_{\\text{B/s}} = \\frac{N_{\\text{bytes\\_round}}}{T_{\\text{round}}} = \\frac{K \\cdot C}{\\max\\left(\\frac{K \\cdot C \\cdot t_{\\text{comp}} \\cdot \\log_{2}(K)}{s}, K \\cdot \\left(L_{\\text{in}} + \\frac{C}{B_{\\text{in}}}\\right), L_{\\text{out}} + \\frac{K \\cdot C}{B_{\\text{out}}}\\right)}$$\n- 问题要求结果以兆字节/秒（MiB/s）为单位，其中 $1 \\text{ MiB} = 2^{20}$ 字节。\n$$\\Theta_{\\text{MiB/s}} = \\frac{\\Theta_{\\text{B/s}}}{2^{20}}$$\n\n此模型适用于 SSD 和 HDD 两类设备，其性能差异通过参数 $L_{\\text{in}}$、$L_{\\text{out}}$、$B_{\\text{in}}$ 和 $B_{\\text{out}}$ 的具体值来体现。现在将实现所推导的公式，以计算给定测试套件的吞吐量。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the sustained throughput for a k-way merge based on a\n    pipelined performance model.\n    \"\"\"\n\n    # Test suite of parameter sets. Each tuple is of the form:\n    # (device-type, K, C, s, t_comp, B_in, B_out, L_in, L_out)\n    test_cases = [\n        # Case A (SSD, general throughput)\n        (\"SSD\", 8, 4_000_000, 8, 1e-9, 1.5e9, 1.5e9, 5.0e-5, 5.0e-5),\n        # Case B (HDD, seek-dominated)\n        (\"HDD\", 8, 4_000_000, 8, 1e-9, 1.5e8, 1.5e8, 1.0e-2, 1.0e-2),\n        # Case C (SSD, compute-bound)\n        (\"SSD\", 8, 4_000_000, 8, 5.0e-8, 1.5e9, 1.5e9, 5.0e-5, 5.0e-5),\n        # Case D (SSD, latency-dominated small chunks)\n        (\"SSD\", 8, 4096, 8, 1e-9, 1.5e9, 1.5e9, 5.0e-5, 5.0e-5),\n        # Case E (SSD, large K)\n        (\"SSD\", 64, 4_000_000, 8, 1e-9, 1.5e9, 1.5e9, 5.0e-5, 5.0e-5),\n        # Case F (HDD, K = 1 boundary)\n        (\"HDD\", 1, 4_000_000, 8, 1e-9, 1.5e8, 1.5e8, 1.0e-2, 1.0e-2),\n        # Case G (SSD, write-bandwidth bottleneck)\n        (\"SSD\", 8, 4_000_000, 8, 1e-9, 1.5e9, 3.0e8, 5.0e-5, 5.0e-5),\n    ]\n\n    results = []\n    \n    # Conversion factor from bytes to mebibytes\n    BYTES_PER_MIB = 2**20\n\n    for case in test_cases:\n        _device_type, K, C, s, t_comp, B_in, B_out, L_in, L_out = case\n\n        # Total bytes processed per round\n        bytes_per_round = K * C\n\n        # 1. Calculate T_CPU: Time for CPU merge stage\n        if K > 1:\n            log2_K = np.log2(K)\n            T_cpu = (K * C * t_comp * log2_K) / s\n        else:\n            # For K=1, no comparisons are needed.\n            T_cpu = 0.0\n\n        # 2. Calculate T_Read: Time for input read stage\n        # This models K serialized read requests of size C.\n        T_read = K * (L_in + C / B_in)\n\n        # 3. Calculate T_Write: Time for output write stage\n        # This models a single write request of size K*C.\n        T_write = L_out + (K * C) / B_out\n\n        # Determine the round time (bottleneck of the pipeline)\n        T_round = max(T_cpu, T_read, T_write)\n\n        # Calculate throughput in bytes per second\n        if T_round > 0:\n            throughput_bps = bytes_per_round / T_round\n        else:\n            throughput_bps = float('inf')\n\n        # Convert throughput to MiB/s and round to 3 decimal places\n        throughput_mibs = throughput_bps / BYTES_PER_MIB\n        rounded_throughput = round(throughput_mibs, 3)\n        \n        results.append(rounded_throughput)\n\n    # Format the final output string as specified\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3232934"}]}