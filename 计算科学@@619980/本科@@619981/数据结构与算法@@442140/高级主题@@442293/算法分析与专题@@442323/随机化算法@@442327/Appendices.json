{"hands_on_practices": [{"introduction": "拉斯维加斯算法的一大特点是其运行时间是一个随机变量。因此，分析这类算法的关键在于计算其期望运行时间。本练习 [@problem_id:3263292] 通过一个经典的“线形图上的随机游走”模型，让你亲手实践如何为随机过程建立并求解期望时间的递推关系，这是分析随机算法性能的基本功。", "problem": "考虑一个具有 $n$ 个标记节点 $\\{1,2,\\ldots,n\\}$ 的路径图。一个机器人执行拉斯维加斯随机算法（LVA），这意味着它总能产生正确的结果，但其运行时间是一个由其随机选择决定的随机变量。机器人从节点 $i$ 开始，其中 $1 \\leq i \\leq n$。在每个离散时间步，如果它位于内部节点 $j$（其中 $1  j  n$），它会以等概率（各为 $1/2$）移动到相邻的节点 $j-1$ 或 $j+1$。如果机器人到达节点 $1$ 或节点 $n$，算法就会终止。请计算从节点 $i$ 出发，算法终止所需的期望步数。", "solution": "确定路径图上的随机游走到达吸收边界的期望步数问题是概率论中的一个经典问题，通常被称为赌徒破产问题的一种形式。问题陈述是适定的、有科学依据的，并包含了进行形式化推导所需的所有信息。\n\n设 $E_i$ 为机器人在从节点 $i$（其中 $1 \\leq i \\leq n$）出发的情况下，到达节点 $1$ 或节点 $n$ 所需的期望时间步数（移动次数）。\n\n节点 $1$ 和 $n$ 是吸收态。如果机器人从这些节点之一开始，算法立即终止，耗时为 $0$ 步。因此，我们有边界条件：\n$$E_1 = 0$$\n$$E_n = 0$$\n\n对于任何内部节点 $j$（其中 $1  j  n$），我们可以构建关于 $E_j$ 的递推关系。机器人移动一步，耗时 $1$ 个单位时间。从节点 $j$ 出发，它以概率 $p = 1/2$ 移动到节点 $j-1$，或以概率 $1-p = 1/2$ 移动到节点 $j+1$。在第一步之后，从新位置出发的期望额外步数分别为 $E_{j-1}$ 或 $E_{j+1}$。\n\n根据全期望定律，从节点 $j$ 出发的期望步数是第一步的耗时与未来期望步数的加权平均值之和：\n$$E_j = 1 + \\left(\\frac{1}{2}\\right)E_{j-1} + \\left(\\frac{1}{2}\\right)E_{j+1}$$\n\n此方程对 $j = 2, 3, \\ldots, n-1$ 成立。我们的目标是解出这个线性方程组，以得到 $E_i$ 作为 $i$ 和 $n$ 的函数。我们可以将该方程重排为二阶线性非齐次差分方程的形式。两边乘以 $2$ 得到：\n$$2E_j = 2 + E_{j-1} + E_{j+1}$$\n整理各项，我们得到：\n$$E_{j+1} - 2E_j + E_{j-1} = -2$$\n\n为了解这个方程，我们首先求出其对应的齐次方程的通解：\n$$E_{j+1} - 2E_j + E_{j-1} = 0$$\n通过代入 $E_j = r^j$ 得到特征方程：\n$$r^{j+1} - 2r^j + r^{j-1} = 0$$\n两边除以 $r^{j-1}$（假设 $r \\neq 0$），我们得到：\n$$r^2 - 2r + 1 = 0$$\n$$(r-1)^2 = 0$$\n该方程有一个重根 $r=1$。对于重根，齐次方程的通解形式为：\n$$E_j^{(h)} = A \\cdot (1)^j + B \\cdot j \\cdot (1)^j = A + Bj$$\n其中 $A$ 和 $B$ 是常数。\n\n接下来，我们求非齐次方程 $E_{j+1} - 2E_j + E_{j-1} = -2$ 的一个特解。由于方程右边是常数，并且齐次解包含常数项（$A$）和线性项（$Bj$），我们必须尝试形式为 $E_j^{(p)} = Cj^2$ 的特解。将其代入非齐次方程：\n$$C(j+1)^2 - 2C(j^2) + C(j-1)^2 = -2$$\n$$C(j^2+2j+1) - 2Cj^2 + C(j^2-2j+1) = -2$$\n$$Cj^2 + 2Cj + C - 2Cj^2 + Cj^2 - 2Cj + C = -2$$\n$$2C = -2$$\n$$C = -1$$\n因此，一个特解是 $E_j^{(p)} = -j^2$。\n\n$E_j$ 的通解是齐次解与特解之和：\n$$E_j = E_j^{(h)} + E_j^{(p)} = A + Bj - j^2$$\n\n现在，我们使用边界条件 $E_1=0$ 和 $E_n=0$ 来确定常数 $A$ 和 $B$。\n对于 $j=1$：\n$$E_1 = A + B(1) - (1)^2 = 0 \\implies A + B = 1$$\n对于 $j=n$：\n$$E_n = A + B(n) - (n)^2 = 0 \\implies A + Bn = n^2$$\n\n我们得到一个关于 $A$ 和 $B$ 的二元线性方程组：\n1) $A + B = 1$\n2) $A + Bn = n^2$\n\n由方程（1），我们有 $A = 1 - B$。将其代入方程（2）：\n$$(1-B) + Bn = n^2$$\n$$1 + B(n-1) = n^2$$\n$$B(n-1) = n^2 - 1$$\n$$B(n-1) = (n-1)(n+1)$$\n由于路径图至少有两个节点（$1$ 和 $n$），我们有 $n \\ge 2$，所以 $n-1 \\neq 0$。我们可以两边除以 $(n-1)$：\n$$B = n+1$$\n\n现在，我们求 $A$：\n$$A = 1 - B = 1 - (n+1) = -n$$\n\n将 $A$ 和 $B$ 的值代回通解，我们得到期望运行时间 $E_j$ 的表达式：\n$$E_j = -n + (n+1)j - j^2$$\n\n问题要求解以起始节点 $i$ 表示，所以我们将 $j$ 替换为 $i$：\n$$E_i = (n+1)i - i^2 - n$$\n这个表达式可以通过因式分解来简化：\n$$E_i = ni + i - i^2 - n$$\n$$E_i = n(i-1) - i^2 + i$$\n$$E_i = n(i-1) - i(i-1)$$\n$$E_i = (n-i)(i-1)$$\n\n这就是从节点 $i$ 出发的期望步数的最终闭式表达式。", "answer": "$$\n\\boxed{(n-i)(i-1)}\n$$", "id": "3263292"}, {"introduction": "与拉斯维加斯算法不同，蒙特卡洛算法的运行时间是确定的，但其结果可能存在错误。理解并量化这个错误概率是评估算法可靠性的核心。本练习 [@problem_id:3263395] 探讨了著名的 Freivalds 矩阵乘法验证算法，但引入了一个“作弊”的对手，挑战你对标准概率分析的理解，并揭示算法的概率保证在对抗性环境下的脆弱性。", "problem": "设 $A$、$B$ 和 $C$ 为整数上的 $n \\times n$ 矩阵，其中 $n \\geq 2$。考虑经典的矩阵乘积验证测试，通常称为 Freivalds 算法，这是一种蒙特卡罗 (MC) 随机算法：从 $\\{0,1\\}^{n}$ 中均匀随机地抽取一个随机向量 $r$，当且仅当 $A(Br) = Cr$ 时，接受 $AB = C$ 的声明。将测试单次运行的错误事件定义为在 $AB \\neq C$ 时接受。令 $D = AB - C$，则测试当且仅当 $D r = 0$ 时接受。在标准的、未被破坏的设置中，已知单次运行的错误概率的上限是一个小于 $1$ 的固定常数。\n\n现在假设，在抽取 $r$ 之后，一个观察到 $A$、$B$、$C$ 和 $r$ 的对手被允许通过更改 $r$ 的至多一个坐标的值来破坏随机向量，从而产生一个被破坏的向量 $r' \\in \\{0,1\\}^{n}$，满足 $|\\{i \\in \\{1,\\dots,n\\} : r'_{i} \\neq r_{i}\\}| \\leq 1$。然后算法使用 $r'$ 继续进行，当且仅当 $D r' = 0$ 时接受。对手的行为旨在最大化错误概率。\n\n假设 $AB \\neq C$（等价于 $D \\neq 0$），确定在随机选择 $r$ 的情况下，被破坏的测试单次运行的最坏情况错误概率。将最终答案表示为单个实数。无需四舍五入。", "solution": "设给定的 $n \\times n$ 整数矩阵为 $A$、$B$ 和 $C$。我们已知 $AB \\neq C$。令 $D = AB - C$。由于 $AB \\neq C$，矩阵 $D$ 是一个非零矩阵，$D \\neq 0$。$D$ 的元素是整数。\n\n该算法从 $\\{0,1\\}^{n}$ 中均匀随机地抽取一个随机向量 $r$。共有 $2^n$ 个这样的向量，每个向量的概率为 $\\frac{1}{2^n}$。\n\n在选定 $r$ 之后，一个知道 $D$ 和 $r$ 的对手可以将 $r$ 破坏成一个新的向量 $r'$。这种破坏是有限的，使得 $r'$ 与 $r$ 最多在一个坐标上不同。这意味着 $r$ 和 $r'$ 之间的汉明距离最多为 $1$。令 $S(r)$ 为对手可以从中选择的向量集合：\n$$S(r) = \\{ x \\in \\{0,1\\}^n : |\\{i \\in \\{1,\\dots,n\\} : x_i \\neq r_i \\}| \\leq 1 \\}$$\n这个集合包含向量 $r$ 本身（0 个改动）以及通过翻转 $r$ 的恰好一个比特位得到的所有向量（1 个改动）。有 $n$ 个这样的向量。因此， $|S(r)| = n+1$。\n\n如果 $Dr' = 0$，算法就接受。由于我们假设 $D \\neq 0$ ($AB \\neq C$)，接受即为错误。对手的目标是从 $S(r)$ 中选择一个 $r'$ 使得 $Dr' = 0$（如果存在这样的向量）。\n\n对于给定的随机向量 $r$，如果对手能够强制接受，就会发生错误。这种情况发生在存在至少一个向量 $r' \\in S(r)$ 使得 $Dr' = 0$ 时。\n错误事件 $E$ 是所有使得对手能够成功的随机向量 $r$ 的集合：\n$$E = \\{r \\in \\{0,1\\}^n \\mid \\exists r' \\in S(r), Dr' = 0\\}$$\n对于给定的矩阵 $D$，错误概率为 $P(\\text{error} | D) = \\frac{|E|}{2^n}$。\n\n问题要求最坏情况的错误概率。这是在所有有效的非零矩阵 $D$ 的选择中，可能的最大错误概率。\n$$\\text{最坏情况错误概率} = \\sup_{D \\neq 0} P(\\text{error} | D)$$\n\n为了找到这个上确界，我们可以构造一个特定的非零 $n \\times n$ 整数矩阵 $D_0$ 并为其计算错误概率。如果我们能证明这个概率是 $1$，那么我们就找到了可能的最大值。\n\n让我们构造这样一个矩阵 $D_0$。设 $n \\ge 2$。考虑矩阵 $D_0$，其第一列等于第一个标准基向量 $e_1$，所有其他列都等于零向量。\n$$d_{0,1} = e_1 = \\begin{pmatrix} 1 \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{pmatrix}, \\quad d_{0,j} = \\mathbf{0} \\quad \\text{对于 } j \\in \\{2, \\ldots, n\\}$$\n这个矩阵 $D_0$ 是非零的，其元素是整数。这样的矩阵可以由整数上的 $A, B, C$ 构成，例如，通过设置 $A=e_1e_1^T$，$B=I$（单位矩阵），以及 $C=0$（零矩阵）。那么 $D_0 = AB-C = e_1e_1^T$。\n\n现在，我们来分析对于任意向量 $r' = (r'_1, r'_2, \\ldots, r'_n)^T \\in \\{0,1\\}^n$，条件 $D_0r' = 0$。\n$$D_0 r' = \\sum_{j=1}^n r'_j d_{0,j} = r'_1 d_{0,1} + \\sum_{j=2}^n r'_j d_{0,j} = r'_1 e_1 + \\sum_{j=2}^n r'_j \\mathbf{0} = r'_1 e_1$$\n由于 $e_1$ 不是零向量，条件 $D_0r' = 0$ 等价于其标量系数为零：\n$$r'_1 e_1 = 0 \\iff r'_1 = 0$$\n\n因此，对于这个特定的矩阵 $D_0$，对手的任务简化为：给定 $r$，找到一个 $r' \\in S(r)$，使得 $r'$ 的第一个分量 $r'_1$ 为 $0$。\n\n我们来检验这对于任何随机选择的初始向量 $r \\in \\{0,1\\}^n$ 是否总是可能的。我们考虑 $r$ 的第一个分量 $r_1$ 的两种可能性。\n\n情况 1：$r_1 = 0$。\n初始随机向量 $r$ 的第一个分量为零。对手可以简单地选择不破坏该向量，即选择 $r' = r$。这是一个有效的选择，因为 $r' \\in S(r)$（零个坐标被改变）。对于这个选择，$r'_1 = r_1 = 0$，所以 $D_0r' = 0$。对手成功。\n\n情况 2：$r_1 = 1$。\n初始随机向量 $r$ 的第一个分量为一。对手可以选择通过翻转其第一个比特位来破坏 $r$。设这个新向量为 $r'$。\n$$r' = (1-r_1, r_2, \\ldots, r_n)^T = (0, r_2, \\ldots, r_n)^T$$\n这个向量 $r'$ 与 $r$ 恰好在一个位置（第一个位置）上不同。因此，$r' \\in S(r)$，并且是对手的有效选择。\n这个 $r'$ 的第一个分量是 $r'_1 = 0$。因此，$D_0r' = 0$。对手成功。\n\n在这两种情况下，无论初始随机向量 $r$ 是什么，对手总能从 $S(r)$ 中选择一个向量 $r'$ 来满足接受条件 $D_0r' = 0$。\n这意味着对于我们选择的矩阵 $D_0$，错误事件 $E$ 包括了所有可能的随机向量 $r$。\n$$E = \\{r \\in \\{0,1\\}^n \\mid \\exists r' \\in S(r), D_0r' = 0\\} = \\{0,1\\}^n$$\n$E$ 中的元素数量为 $|E| = 2^n$。\n\n对于这个特定的矩阵 $D_0$，错误概率是：\n$$P(\\text{error} | D_0) = \\frac{|E|}{2^n} = \\frac{2^n}{2^n} = 1$$\n\n我们找到了一个有效的非零矩阵 $D_0$，其错误概率为 $1$。由于概率不能超过 $1$，这必定是可能的最大错误概率。\n因此，最坏情况的错误概率是 $1$。", "answer": "$$\\boxed{1}$$", "id": "3263395"}, {"introduction": "理论学习最终要通过实践来巩固。最后一个练习将带你将随机算法的理念付诸代码。本练习 [@problem_id:3263300] 要求你实现一个用于检测图中负权环的拉斯维加斯随机算法，它通过在经典 Bellman-Ford 算法的框架中引入随机性，来优化在典型稀疏图上的期望性能。这个练习将帮助你将理论知识转化为解决实际问题的编程能力。", "problem": "给定一个有限加权有向图，由一个顶点集 $V$ 和一个边多重集 $E \\subseteq V \\times V \\times \\mathbb{R}$ 指定，其中每条边 $(u,v,w) \\in E$ 都有一个实值权重 $w$。一个环是一个顶点序列 $(v_0,v_1,\\dots,v_k)$，其中 $k \\ge 1$，对于所有 $i \\in \\{0,1,\\dots,k-1\\}$ 都有 $(v_i,v_{i+1},w_i) \\in E$，并且 $v_0 = v_k$。如果 $\\sum_{i=0}^{k-1} w_i  0$，则该环为负环。经典的确定性 Bellman-Ford 算法能以 $O(|V||E|)$ 的时间上界，检测出从一个源点可达的负环。\n\n设计并实现一个拉斯维加斯（Las Vegas）随机化算法（总是正确的，随机性只影响运行时间），用于检测图中是否存在任何负环（在任何弱连通分量中），其期望时间在典型的稀疏输入上要快于确定性的 Bellman-Ford 算法。使用一个基于队列的随机化松弛策略，该策略以随机顺序处理顶点，并以随机顺序访问出边。为了确保能检测到任何分量中的负环（而不仅仅是从特定源点可达的负环），请使用超级源初始化模型：将所有顶点 $v \\in V$ 的距离 $d(v)$ 初始化为 $0$，并将所有顶点放入初始处理队列中。维护一个数组 $\\text{relax\\_count}(v)$，用于计算 $d(v)$ 严格减少的次数。如果某个 $\\text{relax\\_count}(v)$ 达到 $\\lvert V \\rvert$，则声明存在负环。需要此终止条件来确保正确性，同时防止不终止。\n\n您的推导和设计应基于以下基本定义和经过充分检验的事实：\n- 加权有向图 $G=(V,E)$ 定义如上。\n- 负环是指其总权重小于 $0$ 的环。\n- Bellman-Ford 算法执行重复的松弛操作，如果在第 $\\lvert V \\rvert$ 轮中仍发生改进，则检测到负环。松弛操作会减少一个暂定的距离估计值。\n- 拉斯维加斯算法总是输出正确的答案；其期望运行时间是根据其内部随机性来衡量的。\n- 蒙特卡洛（Monte Carlo）算法可能有非零的错误概率；其运行时间通常是有界的。\n\n您的程序必须实现所述的拉斯维加斯随机化算法，并对以下测试套件产生所需的输出。在每个测试用例中，顶点从 $0$ 到 $n-1$ 连续编号为整数，边以三元组 $(u,v,w)$ 的形式给出，其中 $u,v \\in \\{0,1,\\dots,n-1\\}$ 且 $w \\in \\mathbb{R}$。\n\n测试套件：\n- 案例 A（一般负环）：$n=5$, $E=\\{(0,1,1.0),(1,2,1.0),(2,3,1.0),(3,1,-4.0),(0,4,2.0),(4,3,2.0)\\}$。该图有一个负环 $1 \\to 2 \\to 3 \\to 1$，总权重为 $1.0 + 1.0 - 4.0 = -2.0$。\n- 案例 B（无负环，有向无环核心）：$n=4$, $E=\\{(0,1,2.0),(1,2,2.0),(2,3,2.0),(0,3,7.0)\\}$。不存在环。\n- 案例 C（自环负环）：$n=1$, $E=\\{(0,0,-1.0)\\}$。该边本身是一个权重为 $-1.0$ 的负环。\n- 案例 D（不连通图，负环在独立的连通分量中）：$n=5$, $E=\\{(0,1,1.0),(1,2,1.0),(3,4,-2.0),(4,3,-2.0)\\}$。连通分量 $\\{3,4\\}$ 包含一个负环 $3 \\to 4 \\to 3$，总权重为 $-4.0$，而连通分量 $\\{0,1,2\\}$ 没有环。\n- 案例 E（长链，无环）：$n=10$, $E=\\{(0,1,1.0),(1,2,1.0),(2,3,1.0),(3,4,1.0),(4,5,1.0),(5,6,1.0),(6,7,1.0),(7,8,1.0),(8,9,1.0)\\}$。此图是无环图。\n\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表（例如，$[result\\_A,result\\_B,result\\_C,result\\_D,result\\_E]$），其中每个 $result\\_X$ 是一个布尔值，表示是否在相应案例中检测到负环。每个测试用例所需的输出类型均为布尔值。本问题不涉及物理单位或角度单位，也不需要百分比。确保您的算法通过使用随机的顶点初始顺序和随机的边松弛顺序来实现随机化，并确保它对每个测试用例都能终止并给出正确的布尔答案。", "solution": "问题陈述已经过验证，被认为是可靠的。它有科学依据、适定，并包含构建和实现解决方案所需的所有必要信息。图、环和负环的定义都是标准的。所描述的随机化算法是最短路径快速算法（SPFA）的一个有效变体，其正确性依赖于 Bellman-Ford 算法的既定原则。\n\n核心任务是设计一个拉斯维加斯（Las Vegas）随机化算法，以检测给定的加权有向图 $G=(V,E)$ 中是否存在任何负权重环。负环是一条路径 $(v_0, v_1, \\dots, v_{k-1}, v_k=v_0)$，其中边权重之和 $\\sum_{i=0}^{k-1} w(v_i, v_{i+1})$ 小于 $0$。\n\n检测负环的基本原理源于 Bellman-Ford 算法。在一个有 $|V|$ 个顶点且没有负环的图中，从任何源顶点到任何其他顶点的最短路径最多包含 $|V|-1$ 条边。Bellman-Ford 算法迭代地松弛边，经过 $|V|-1$ 轮后，它会找到所有这样的最短路径。如果在第 $|V|$ 轮中，一个距离估计值仍能被改进，这意味着存在一条包含 $|V|$ 条边的路径，它比任何包含更少边的路径都“更短”。这样的路径必然包含一个环，为了使其总权重能够进一步减小距离，这个环必须具有负的总权重。\n\n为了检测图中任何地方的负环，而不仅仅是从特定源点可达的负环，我们采用“超级源”模型。在概念上，这等同于添加一个新顶点 $s$ 并从 $s$ 到每个顶点 $v \\in V$ 添加一条权重为零的有向边。然后从 $s$ 运行最短路径算法将能探索图的所有部分。在实践中，这通过将每个顶点 $v \\in V$ 的距离估计值初始化为 0（即 $d(v) \\leftarrow 0$），并将所有顶点放入待处理的初始顶点集中来实现。\n\n指定的算法是 Bellman-Ford 的一种基于队列的随机化变体。与确定性的 Bellman-Ford 算法（在其 $|V|-1$ 轮的每一轮中松弛所有 $|E|$ 条边）不同，基于队列的方法只重新处理其距离估计值已成功松弛（减小）的顶点。这平均可以带来显著的性能提升。该算法维护一个顶点队列，这些顶点是松弛其邻居的候选者。\n\n算法流程如下：\n$1$. **初始化**：对于每个顶点 $v \\in V$，将其距离估计值 $d(v) \\leftarrow 0$ 和松弛计数器 $\\text{relax\\_count}(v) \\leftarrow 0$ 初始化。创建一个队列，并将 $V$ 中的所有顶点添加到队列中。为了按要求引入随机性，在将所有顶点 $V$ 的集合添加到队列之前，先将其打乱顺序。使用一个辅助数据结构（例如，哈希集合）来跟踪当前哪些顶点在队列中，以避免重复并允许常数时间的成员资格检查。\n\n$2$. **随机化松弛循环**：当队列不为空时，执行以下步骤：\n    a. 从队列中取出一个顶点 $u$。\n    b. 检索从 $u$ 出发的所有出边列表。为满足第二个随机化要求，将此边列表打乱顺序。\n    c. 对于打乱顺序后的列表中的每条出边 $(u, v, w)$，尝试进行松弛。如果 $d(u) + w  d(v)$，则满足松弛条件。\n    d. 如果发生松弛，则更新 $d(v) \\leftarrow d(u) + w$ 并增加松弛计数器 $\\text{relax\\_count}(v) \\leftarrow \\text{relax\\_count}(v) + 1$。\n    e. **终止检查**：在增加 $\\text{relax\\_count}(v)$ 后，立即检查是否有 $\\text{relax\\_count}(v) \\ge |V|$。如果满足此条件，则可作为存在负环的确凿证明。算法终止并报告 `True`。\n    f. 如果发生了松弛且算法尚未终止，则顶点 $v$ 必须被再次处理，因为其新的、更短的距离可能会导致其邻居的进一步松弛。如果 $v$ 尚未在队列中，则将其入队。\n\n$3$. **终止（未找到环）**：如果主循环完成（即队列变空），意味着已达到稳定状态，其中对于所有边 $(u, v, w)$，条件 $d(v) \\le d(u) + w$ 均成立。由于没有任何顶点的松弛计数器达到 $|V|$，可以保证图中不存在负环。算法终止并报告 `False`。\n\n该算法属于拉斯维加斯类型，因为其正确性得到保证。如果它报告存在负环，关于 $\\text{relax\\_count}(v)$ 的条件提供了一个确定的证明。如果它报告没有负环，那是因为松弛过程收敛了，而这只有在不存在负环的情况下才可能发生。顶点和边处理顺序的随机化只影响操作的顺序，从而影响运行时间，但不影响最终结果。其期望运行时间通常优于标准 Bellman-Ford 算法的 $O(|V||E|)$ 最坏情况，特别是对于那些不存在 SPFA 类算法最坏情况结构的稀疏图。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport collections\n\ndef solve():\n    \"\"\"\n    Solves the negative cycle detection problem for a suite of test cases\n    using a randomized Las Vegas algorithm.\n    \"\"\"\n\n    def detect_negative_cycle_randomized(n, edges, rng):\n        \"\"\"\n        Implements a randomized Las Vegas algorithm to detect negative cycles.\n\n        This algorithm is a queue-based variant of Bellman-Ford (similar to SPFA).\n        It uses a \"super-source\" model by initializing all distances to 0.\n        Randomness is introduced by shuffling the initial vertex processing order\n        and shuffling the outgoing edges for each processed vertex.\n\n        A negative cycle is detected if any vertex's distance is relaxed n or more times.\n\n        Args:\n            n (int): The number of vertices, |V|.\n            edges (list): A list of tuples (u, v, w) representing edges.\n            rng (np.random.Generator): A random number generator for shuffling.\n\n        Returns:\n            bool: True if a negative cycle is detected, False otherwise.\n        \"\"\"\n        if n == 0:\n            return False\n\n        # Adjacency list representation of the graph\n        adj = collections.defaultdict(list)\n        for u, v, w in edges:\n            adj[u].append((v, w))\n\n        # Initialize distances to 0 (super-source model)\n        dist = np.zeros(n, dtype=float)\n\n        # Count the number of times each vertex's distance is relaxed\n        relax_count = np.zeros(n, dtype=int)\n\n        # Queue for vertices to be processed\n        queue = collections.deque()\n        \n        # Set for O(1) checking of queue membership\n        in_queue = set()\n\n        # Initial population of the queue with all vertices in a random order\n        initial_nodes = list(range(n))\n        rng.shuffle(initial_nodes)\n        for i in initial_nodes:\n            queue.append(i)\n            in_queue.add(i)\n\n        while queue:\n            u = queue.popleft()\n            in_queue.remove(u)\n\n            # Randomize the order of edge relaxation\n            outgoing_edges = adj[u]\n            rng.shuffle(outgoing_edges)\n\n            for v, w in outgoing_edges:\n                # Relaxation step\n                if dist[u] + w  dist[v]:\n                    dist[v] = dist[u] + w\n                    relax_count[v] += 1\n\n                    # Check for negative cycle detection\n                    # A path can have at most n-1 edges without a cycle.\n                    # If a vertex is relaxed n times, it implies a path of\n                    # length n, which must contain a negative cycle.\n                    if relax_count[v] >= n:\n                        return True\n\n                    if v not in in_queue:\n                        queue.append(v)\n                        in_queue.add(v)\n        \n        # If the queue is empty and no cycle was detected, none exists.\n        return False\n\n    # Instantiate a random number generator. Seeding is not required by the problem.\n    rng = np.random.default_rng()\n\n    # Test Suite\n    test_cases = {\n        'A': {\n            \"n\": 5, \n            \"edges\": [(0, 1, 1.0), (1, 2, 1.0), (2, 3, 1.0), (3, 1, -4.0), (0, 4, 2.0), (4, 3, 2.0)]\n        },\n        'B': {\n            \"n\": 4, \n            \"edges\": [(0, 1, 2.0), (1, 2, 2.0), (2, 3, 2.0), (0, 3, 7.0)]\n        },\n        'C': {\n            \"n\": 1, \n            \"edges\": [(0, 0, -1.0)]\n        },\n        'D': {\n            \"n\": 5, \n            \"edges\": [(0, 1, 1.0), (1, 2, 1.0), (3, 4, -2.0), (4, 3, -2.0)]\n        },\n        'E': {\n            \"n\": 10, \n            \"edges\": [(0, 1, 1.0), (1, 2, 1.0), (2, 3, 1.0), (3, 4, 1.0), (4, 5, 1.0), \n                      (5, 6, 1.0), (6, 7, 1.0), (7, 8, 1.0), (8, 9, 1.0)]\n        }\n    }\n    \n    results = []\n    # The order of execution must match the problem statement's order for the final output.\n    case_order = ['A', 'B', 'C', 'D', 'E']\n    for case_id in case_order:\n        case = test_cases[case_id]\n        n, edges = case[\"n\"], case[\"edges\"]\n        result = detect_negative_cycle_randomized(n, edges, rng)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3263300"}]}