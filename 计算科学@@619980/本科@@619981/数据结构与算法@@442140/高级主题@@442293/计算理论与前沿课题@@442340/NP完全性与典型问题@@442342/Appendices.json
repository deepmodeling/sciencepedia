{"hands_on_practices": [{"introduction": "理论学习之后，最好的巩固方式莫过于亲手实践。顶点覆盖 (Vertex Cover) 问题是典型的 NP-完全问题，但在某些特殊类型的图上，它却存在高效的解法。本练习 [@problem_id:3256361] 将引导你探索当图的结构被限制为树时，如何利用动态规划这一强大工具，在多项式时间内精确地找到最小顶点覆盖。", "problem": "考虑典型的决策问题 $\\text{VERTEX-COVER}$：给定一个图 $G = (V,E)$ 和一个整数 $k$，判断是否存在一个大小至多为 $k$ 的子集 $S \\subseteq V$，使得 $E$ 中的每条边至少有一个端点在 $S$ 中。在一般图中，这个问题是已知的非确定性多项式时间（NP）完全问题。然而，当输入图是一棵树时，该问题表现出的结构使其能有一个多项式时间的解法。从第一性原理出发，即顶点覆盖、树和最优子结构的定义，推导出一个动态规划（DP）算法。该算法在给定一棵包含 $|V| = n$ 个顶点的树 $T = (V,E)$ 时，能在 $n$ 的多项式时间内计算出最小顶点覆盖的大小。具体来说：\n\n1. 形式化地描述在树上进行动态规划所需的最优子结构，不要依赖任何预先给出的公式。\n2. 通过在树结构上进行局部到全局的最优性论证，证明你的方法的正确性，即所有边都被覆盖且解是最小的。\n3. 分析你的算法的时间和空间复杂度，将其表示为 $n$ 的函数。\n\n然后，将你的算法应用于以下树实例 $T$，其顶点集为 $V = \\{1,2,3,4,5,6,7,8,9,10,11,12,13,14\\}$，边集为\n$$\nE = \\{(1,2),(1,3),(1,4),(2,5),(2,6),(3,7),(4,8),(4,9),(7,10),(7,11),(9,12),(10,13),(10,14)\\}.\n$$\n以顶点 1 为根，计算 $T$ 的最小顶点覆盖的大小。将你的最终答案表示为一个整数（无单位）。无需四舍五入。", "solution": "问题要求推导并应用一个动态规划算法，来寻找给定树的最小顶点覆盖的大小。一个图 $G=(V,E)$ 的顶点覆盖是一个顶点子集 $S \\subseteq V$，使得对于每条边 $(u,v) \\in E$，$u$ 或 $v$ 中至少有一个顶点在 $S$ 中。最小顶点覆盖是可能尺寸中最小的顶点覆盖。该问题对于一般图是 NP 完全的，但对于树则可在多项式时间内求解。\n\n我们将首先形式化动态规划方法，证明其正确性，分析其复杂度，然后将其应用于给定的具体树实例。\n\n### 1. 最优子结构与动态规划公式\n\n为了在树 $T = (V,E)$ 上应用动态规划，我们首先将其在任意一个顶点（我们记作 $r$）上生根。对于给定的实例，我们被指定使用顶点 1 作为根。这就在树上建立了一种父子结构。对于任意节点 $u \\in V$，令 $T_u$ 表示以 $u$ 为根的子树，它包括 $u$ 及其所有后代。\n\n动态规划方法的核心思想是以自底向上的方式（即通过后序遍历）计算每个子树 $T_u$ 的最小顶点覆盖的大小。一个简单的状态 $DP(u)$ 表示 $T_u$ 的最小顶点覆盖的大小是不够的。决定是否将 $u$ 包含在 $T_u$ 的覆盖中，会对其父节点 parent$(u)$ 产生影响。具体来说，如果 $u$ 不被包含在覆盖中，那么其父节点 parent$(u)$ *必须*被包含进来，以覆盖边 (parent$(u)$, $u$)。因此，我们的 DP 状态必须区分这两种情况。\n\n我们为每个节点 $u \\in V$ 定义两个值：\n- $DP_{in}(u)$: 子树 $T_u$ 的最小顶点覆盖的大小，约束条件是节点 $u$ *被包含*在顶点覆盖中。\n- $DP_{out}(u)$: 子树 $T_u$ 的最小顶点覆盖的大小，约束条件是节点 $u$ *不被包含*在顶点覆盖中。\n\n最优子结构性质成立：子树 $T_u$ 的最优解可以由以 $u$ 的子节点为根的子树的最优解构建而成。令 $Children(u)$ 为节点 $u$ 的子节点集合。\n\n递推关系推导如下：\n\n**情况1：$u$ 在顶点覆盖中 ($DP_{in}(u)$)。**\n如果我们将 $u$ 包含在覆盖中，其自身的代价是 $1$。包含 $u$ 后，对于所有 $v \\in Children(u)$，边 $(u,v)$ 都被覆盖了。对于每个子节点 $v$，我们现在可以自由选择是否将其包含在 $T_v$ 的覆盖中。为了使 $T_u$ 的覆盖达到最小尺寸，我们应该为每个子节点的子树选择两个选项中较小的一个。因此，对于每个 $v \\in Children(u)$，我们将 $\\min(DP_{in}(v), DP_{out}(v))$ 加到总和中。\n$$DP_{in}(u) = 1 + \\sum_{v \\in Children(u)} \\min(DP_{in}(v), DP_{out}(v))$$\n\n**情况2：$u$ 不在顶点覆盖中 ($DP_{out}(u)$)。**\n如果我们不将 $u$ 包含在覆盖中，其自身的代价是 $0$。然而，为了覆盖每个子节点 $v \\in Children(u)$ 的边 $(u,v)$，我们*必须*将 $v$ 包含在其子树 $T_v$ 的顶点覆盖中。在 $T_u$ 的结构内，没有其他选择来覆盖这些边（因为 $u$ 不在覆盖中，而 $v$ 是边 $(u,v)$ 的唯一另一个端点）。因此，对于每个子节点 $v$，我们必须选择 $v$ 被包含的解。\n$$DP_{out}(u) = \\sum_{v \\in Children(u)} DP_{in}(v)$$\n\n**基本情况：**\n递归在树的叶节点处终止。对于任何叶节点 $l$，$Children(l) = \\emptyset$。\n- $DP_{in}(l) = 1$：子树 $T_l$（仅包含节点 $l$）的覆盖是 $\\{l\\}$，大小为 $1$。\n- $DP_{out}(l) = 0$：子树 $T_l$ 的覆盖是 $\\emptyset$，大小为 $0$。由于 $T_l$ 内部没有边，空集是一个有效的覆盖。\n\n最后，在计算完所有节点直到根节点 $r$ 的这些值之后，整个树 $T$ 的最小顶点覆盖的大小是根节点两种可能性的最小值：$\\min(DP_{in}(r), DP_{out}(r))$。\n\n### 2. 正确性证明\n\n我们通过对树的结构进行归纳来证明正确性，论证我们的算法为每个子树 $T_u$ 找到了一个有效且最小的顶点覆盖。\n\n**有效性（所有边都被覆盖）：**\n- **基本情况：** 对于一个叶节点 $l$，子树 $T_l$ 没有边，所以该性质不证自明。\n- **归纳假设（I.H.）：** 假设对于节点 $u$ 的所有子节点 $v$，值 $DP_{in}(v)$ 和 $DP_{out}(v)$ 对应于它们各自子树 $T_v$ 的有效顶点覆盖。\n- **归纳步骤：** 考虑子树 $T_u$。它的边由集合 $\\{(u,v) \\mid v \\in Children(u)\\}$ 以及每个子树 $T_v$ 内的所有边组成。\n  - 如果我们计算 $DP_{in}(u)$，我们将 $u$ 包含在覆盖中。这覆盖了所有的边 $(u,v)$。根据归纳假设，为每个 $T_v$ 选择的子解覆盖了那些子树内的所有边。因此，$T_u$ 中的所有边都被覆盖。\n  - 如果我们计算 $DP_{out}(u)$，我们不包含 $u$。递推关系迫使我们为每个子节点 $v$ 选择 $DP_{in}(v)$ 解。这意味着每个 $v \\in Children(u)$ 都被包含在覆盖中，从而覆盖了所有边 $(u,v)$。根据归纳假设，$DP_{in}(v)$ 解也覆盖了 $T_v$ 内的所有边。因此，$T_u$ 中的所有边都被覆盖。\n在两种情况下，我们都为 $T_u$ 生成了一个有效的顶点覆盖。\n\n**最小性（最优性）：**\n- **基本情况：** 对于一个叶节点 $l$，$DP_{in}(l)=1$ 和 $DP_{out}(l)=0$ 显然是对应约束条件下的最优解。\n- **归纳假设：** 假设对于节点 $u$ 的所有子节点 $v$，$DP_{in}(v)$ 和 $DP_{out}(v)$ 是 $T_v$ 在其约束条件下的*最小*顶点覆盖的大小。\n- **归纳步骤：** 考虑 $T_u$ 的一个最优顶点覆盖 $S^*$。\n  - 如果 $u \\in S^*$，那么 $S^* \\setminus \\{u\\}$ 必须覆盖子树 $T_v$ 内的所有边。为了最优地做到这一点，对于每个 $T_v$，$S^*$ 在 $T_v$ 中的部分必须是 $T_v$ 的一个最小顶点覆盖。其大小将是 $\\min(|S^*_{v,in}|, |S^*_{v,out}|)$，根据归纳假设，这等于 $\\min(DP_{in}(v), DP_{out}(v))$。对所有子节点求和，再加上 $u$ 的 $1$，表明 $|S^*| = DP_{in}(u)$。\n  - 如果 $u \\notin S^*$，那么为了覆盖边 $(u,v)$，每个子节点 $v$ 都必须在 $S^*$ 中。$S^*$ 的其余部分则必须是每个 $T_v$ 在给定 $v$ 被包含的情况下的最优覆盖。根据归纳假设，每个 $T_v$ 的大小是 $DP_{in}(v)$。对所有子节点求和，表明 $|S^*| = DP_{out}(u)$。\n由于 $T_u$ 的任何最优解都必须属于这两种情况之一，所以 $DP_{in}(u)$ 和 $DP_{out}(u)$ 的最小值给出了 $T_u$ 的最小顶点覆盖的大小。这种局部最优性会传播到根节点，从而确保一个全局最优解。\n\n### 3. 复杂度分析\n\n- **时间复杂度：** 该算法为每个节点 $u \\in V$ 计算两个值，$DP_{in}(u)$ 和 $DP_{out}(u)$。对节点 $u$ 的计算需要对其子节点求和。一次后序遍历（例如，使用深度优先搜索）确保当我们在计算 $u$ 的值时，其所有子节点的值都已可用。总计算时间是每个节点所做工作的总和。在节点 $u$ 处的工作量与其子节点数量 $|Children(u)|$ 成正比。\n因此，总时间与 $\\sum_{u \\in V} |Children(u)|$ 成正比。在一棵有 $n$ 个顶点的树中，所有节点的子节点数量之和等于边的总数，即 $|E| = n-1$。因此，时间复杂度为 $O(n-1) = O(n)$。\n- **空间复杂度：** 我们需要为 $n$ 个顶点中的每一个存储两个 DP 值。这需要 $O(n)$ 的空间。此外，如果算法是递归实现的，调用栈的深度最多可以达到 $n$（在路径图的情况下），这也贡献了 $O(n)$ 的空间。因此，总空间复杂度为 $O(n)$。\n\n### 4. 应用于给定实例\n\n树为 $T=(V,E)$，其中 $V=\\{1, \\dots, 14\\}$，边集 $E = \\{(1,2),(1,3),(1,4),(2,5),(2,6),(3,7),(4,8),(4,9),(7,10),(7,11),(9,12),(10,13),(10,14)\\}$。我们以顶点 1 为根。父子关系如下：\n- $Children(1) = \\{2,3,4\\}$\n- $Children(2) = \\{5,6\\}$\n- $Children(3) = \\{7\\}$\n- $Children(4) = \\{8,9\\}$\n- $Children(7) = \\{10,11\\}$\n- $Children(9) = \\{12\\}$\n- $Children(10) = \\{13,14\\}$\n- 顶点 $\\{5,6,8,11,12,13,14\\}$ 是叶节点。\n\n我们通过后序遍历（自底向上）计算 DP 值。对于任何节点 $u$，我们将其 DP 值表示为一个数对 $(DP_{in}(u), DP_{out}(u))$。\n\n**叶节点：** 对于任何叶节点 $l \\in \\{5,6,8,11,12,13,14\\}$：\n- $(DP_{in}(l), DP_{out}(l)) = (1, 0)$\n\n**节点 2：** $Children(2)=\\{5,6\\}$\n- $DP_{in}(2) = 1 + \\min(DP_{in}(5), DP_{out}(5)) + \\min(DP_{in}(6), DP_{out}(6)) = 1 + \\min(1,0) + \\min(1,0) = 1+0+0 = 1$\n- $DP_{out}(2) = DP_{in}(5) + DP_{in}(6) = 1+1 = 2$\n- 对于节点 2：$(1, 2)$\n\n**节点 10：** $Children(10)=\\{13,14\\}$\n- $DP_{in}(10) = 1 + \\min(1,0) + \\min(1,0) = 1$\n- $DP_{out}(10) = 1+1 = 2$\n- 对于节点 10：$(1, 2)$\n\n**节点 7：** $Children(7)=\\{10,11\\}$\n- $DP_{in}(7) = 1 + \\min(DP_{in}(10), DP_{out}(10)) + \\min(DP_{in}(11), DP_{out}(11)) = 1 + \\min(1,2) + \\min(1,0) = 1+1+0 = 2$\n- $DP_{out}(7) = DP_{in}(10) + DP_{in}(11) = 1+1 = 2$\n- 对于节点 7：$(2, 2)$\n\n**节点 3：** $Children(3)=\\{7\\}$\n- $DP_{in}(3) = 1 + \\min(DP_{in}(7), DP_{out}(7)) = 1 + \\min(2,2) = 1+2 = 3$\n- $DP_{out}(3) = DP_{in}(7) = 2$\n- 对于节点 3：$(3, 2)$\n\n**节点 9：** $Children(9)=\\{12\\}$\n- $DP_{in}(9) = 1 + \\min(DP_{in}(12), DP_{out}(12)) = 1 + \\min(1,0) = 1$\n- $DP_{out}(9) = DP_{in}(12) = 1$\n- 对于节点 9：$(1, 1)$\n\n**节点 4：** $Children(4)=\\{8,9\\}$\n- $DP_{in}(4) = 1 + \\min(DP_{in}(8), DP_{out}(8)) + \\min(DP_{in}(9), DP_{out}(9)) = 1 + \\min(1,0) + \\min(1,1) = 1+0+1 = 2$\n- $DP_{out}(4) = DP_{in}(8) + DP_{in}(9) = 1+1 = 2$\n- 对于节点 4：$(2, 2)$\n\n**根节点 1：** $Children(1)=\\{2,3,4\\}$\n- $DP_{in}(1) = 1 + \\min(DP_{in}(2), DP_{out}(2)) + \\min(DP_{in}(3), DP_{out}(3)) + \\min(DP_{in}(4), DP_{out}(4))$\n  $DP_{in}(1) = 1 + \\min(1,2) + \\min(3,2) + \\min(2,2) = 1 + 1 + 2 + 2 = 6$\n- $DP_{out}(1) = DP_{in}(2) + DP_{in}(3) + DP_{in}(4) = 1 + 3 + 2 = 6$\n- 对于节点 1：$(6, 6)$\n\n整个树 $T$ 的最小顶点覆盖的大小是 $\\min(DP_{in}(1), DP_{out}(1))$。\n大小 = $\\min(6, 6) = 6$。", "answer": "$$\\boxed{6}$$", "id": "3256361"}, {"introduction": "面对 NP-难问题，我们常常无法在合理时间内找到最优解。此时，近似算法便成为了一个至关重要的实用策略。本练习 [@problem_id:3256360] 将聚焦于另一个经典的 NP-完全问题——集合覆盖 (Set-Cover)，并分析其标准贪心算法的性能。你将通过构造一个特殊的“最坏情况”实例，亲手推导该算法的近似比，从而深刻理解近似算法的设计与分析思想。", "problem": "考虑经典的集合覆盖问题，该问题是已知的非确定性多项式时间（NP）完全问题。在其加权版本中，给定一个有限全集 $U$ 和一个子集族 $\\mathcal{S} \\subseteq 2^{U}$，其中每个集合 $S \\in \\mathcal{S}$ 都有一个相关的非负成本 $c(S)$。一个集合覆盖是一个子族 $\\mathcal{C} \\subseteq \\mathcal{S}$，其并集为 $U$。用于加权集合覆盖的标准贪心近似算法会迭代地选择一个集合 $S \\in \\mathcal{S}$，该集合能够最小化比率 $c(S)/|S \\setminus C|$，其中 $C$ 是已覆盖元素的集合，直到 $U$ 被完全覆盖。\n\n设计一个由整数 $r \\geq 2$ 和实数参数 $\\epsilon$（其中 $0  \\epsilon  1$）参数化的加权集合覆盖问题的特定实例族，具体如下。设全集为任意集合 $U$，其大小为 $|U| = 2^{r}$。将 $U$ 划分为 $r+1$ 个不相交的块 $B_{1}, B_{2}, \\dots, B_{r}, B_{r+1}$，其大小对于每个 $1 \\leq j \\leq r$ 为 $|B_{j}| = 2^{r-j}$，且 $|B_{r+1}| = 1$。定义集合族 $\\mathcal{S}$ 由以下部分组成：\n- 单个全局集 $G = U$，其成本为 $c(G) = 2 + \\epsilon$，以及\n- $r+1$ 个块集 $A_{j} = B_{j}$，对于所有的 $1 \\leq j \\leq r+1$，其成本为 $c(A_{j}) = 1$。\n\n仅使用集合覆盖的核心定义和所述的贪心规则，推导贪心算法在此实例族上的精确近似比。该近似比定义为贪心算法返回的总成本除以最优成本。将你的最终答案表示为关于 $r$ 和 $\\epsilon$ 的单一简化符号表达式。无需四舍五入，也不涉及任何单位。", "solution": "该问题要求推导标准贪心算法在特定加权集合覆盖实例族上的精确近似比。近似比定义为贪心算法产生的覆盖的总成本除以最优覆盖的成本。\n\n让我们首先将问题给定的条件形式化。\n全集是一个集合 $U$，其大小为 $|U| = 2^r$，其中 $r \\geq 2$ 是一个整数。\n全集 $U$ 被划分为 $r+1$ 个不相交的块：$U = B_1 \\cup B_2 \\cup \\dots \\cup B_r \\cup B_{r+1}$。\n这些块的大小由 $|B_j| = 2^{r-j}$（对于 $1 \\leq j \\leq r$）和 $|B_{r+1}| = 1$ 给出。\n这些块的大小之和为 $\\sum_{j=1}^{r} |B_j| + |B_{r+1}| = \\left(\\sum_{j=1}^{r} 2^{r-j}\\right) + 1$。该和是一个等比级数：$\\sum_{k=0}^{r-1} 2^k = \\frac{2^r - 1}{2-1} = 2^r - 1$。因此，总大小为 $(2^r - 1) + 1 = 2^r$，这与 $|U|$ 的大小正好符合。\n\n子集族 $\\mathcal{S}$ 由以下部分组成：\n1.  一个单一的全局集 $G = U$，其成本为 $c(G) = 2 + \\epsilon$，其中 $0  \\epsilon  1$。\n2.  一组 $r+1$ 个块集 $A_j = B_j$（对于 $1 \\leq j \\leq r+1$），每个的成本为 $c(A_j) = 1$。\n\n求解过程需要两个部分：最优解的成本 $C_{OPT}$，以及贪心算法产生的解的成本 $C_{Greedy}$。\n\n**1. 确定最优成本 ($C_{OPT}$)**\n\n$U$ 的一个集合覆盖必须是 $\\mathcal{S}$ 的一个子族，其并集为 $U$。我们确定了两个主要的最优覆盖候选方案：\n-   **候选方案1：** 选择单个集合 $G$。由于 $G=U$，这构成了一个有效的覆盖。此覆盖的成本为 $C_1 = c(G) = 2 + \\epsilon$。\n-   **候选方案2：** 选择所有块集的集合 $\\{A_1, A_2, \\dots, A_{r+1}\\}$。由于块 $\\{B_1, \\dots, B_{r+1}\\}$ 构成 $U$ 的一个划分，它们的并集是 $U$。因此，$\\bigcup_{j=1}^{r+1} A_j = \\bigcup_{j=1}^{r+1} B_j = U$。这是一个有效的覆盖。此覆盖的成本为 $C_2 = \\sum_{j=1}^{r+1} c(A_j) = \\sum_{j=1}^{r+1} 1 = r+1$。\n\n任何其他有效的覆盖都将是这两个候选方案之一的超集，因此成本更高。例如，$\\{G, A_1\\}$ 是一个有效的覆盖，但其成本高于 $\\{G\\}$。\n最优成本 $C_{OPT}$ 是所有可能的有效覆盖中成本的最小值。因此，$C_{OPT} = \\min(C_1, C_2) = \\min(2+\\epsilon, r+1)$。\n\n在约束条件 $r \\geq 2$ 和 $0  \\epsilon  1$ 下：\n-   $r+1$ 的值是一个大于等于 $3$ 的整数。\n-   $2+\\epsilon$ 的值是一个满足 $2  2+\\epsilon  3$ 的实数。\n由于 $r+1 \\geq 3$ 且 $2+\\epsilon  3$，因此 $2+\\epsilon  r+1$ 总是成立的。\n因此，选择单个集合 $G$ 可以达到最小成本。\n$$C_{OPT} = 2 + \\epsilon$$\n\n**2. 确定贪心算法的成本 ($C_{Greedy}$)**\n\n贪心算法迭代地选择能够最小化成本效益比的集合 $S$，该比率定义为 $\\frac{c(S)}{|S \\setminus C|}$，其中 $C$ 是已覆盖元素的集合。设 $C_k$ 为第 $k$ 次迭代后已覆盖元素的集合。\n\n**第1次迭代：**\n最初，已覆盖元素的集合是空的，$C_0 = \\emptyset$。我们为每个集合 $S \\in \\mathcal{S}$ 计算比率。\n-   对于全局集 $G$：$\\frac{c(G)}{|G \\setminus C_0|} = \\frac{2+\\epsilon}{|G|} = \\frac{2+\\epsilon}{2^r}$。\n-   对于块集 $A_j=B_j$ ($1 \\leq j \\leq r$)：$\\frac{c(A_j)}{|A_j \\setminus C_0|} = \\frac{1}{|B_j|} = \\frac{1}{2^{r-j}}$。\n-   对于块集 $A_{r+1}=B_{r+1}$：$\\frac{c(A_{r+1})}{|A_{r+1} \\setminus C_0|} = \\frac{1}{|B_{r+1}|} = \\frac{1}{1} = 1$。\n\n块集的比率集合为 $\\{\\frac{1}{2^{r-1}}, \\frac{1}{2^{r-2}}, \\dots, \\frac{1}{2^1}, \\frac{1}{2^0}=1, 1\\}$。其中的最小值是 $\\frac{1}{2^{r-1}}$，对应于集合 $A_1$。\n现在，我们将这个最小比率与集合 $G$ 的比率进行比较。\n我们比较 $\\frac{1}{2^{r-1}}$ 和 $\\frac{2+\\epsilon}{2^r}$。\n两边同乘以 $2^r$ 得到 $2$ 和 $2+\\epsilon$。\n由于 $0  \\epsilon  1$，我们有 $2  2+\\epsilon$。因此，$\\frac{2}{2^r}  \\frac{2+\\epsilon}{2^r}$，这意味着 $\\frac{1}{2^{r-1}}  \\frac{2+\\epsilon}{2^r}$。\n贪心算法选择具有最小比率的集合，即 $A_1$。\n产生的成本为 $1$。已覆盖元素的集合变为 $C_1 = B_1$。\n\n**第 $k$ 次迭代 (对于 $2 \\leq k \\leq r$)：**\n让我们假设在第 $1, 2, \\dots, k-1$ 次迭代中，算法已经选择了集合 $A_1, A_2, \\dots, A_{k-1}$。\n已覆盖元素的集合是 $C_{k-1} = \\bigcup_{i=1}^{k-1} B_i$。剩余需要考虑的集合是 $\\{G, A_k, A_{k+1}, \\dots, A_{r+1}\\}$。\n未覆盖元素的数量为 $|U \\setminus C_{k-1}| = |U| - \\sum_{i=1}^{k-1} |B_i| = 2^r - \\sum_{i=1}^{k-1} 2^{r-i}$。\n该和是一个等比级数：$\\sum_{i=1}^{k-1} 2^{r-i} = 2^{r-1} + 2^{r-2} + \\dots + 2^{r-k+1} = 2^{r-k+1}(2^{k-2} + \\dots + 1) = 2^{r-k+1}(2^{k-1}-1) = 2^r-2^{r-k+1}$。\n所以， $|U \\setminus C_{k-1}| = 2^r - (2^r-2^{r-k+1}) = 2^{r-k+1}$。\n\n现在我们评估比率：\n-   对于全局集 $G$：$\\frac{c(G)}{|G \\setminus C_{k-1}|} = \\frac{2+\\epsilon}{|U \\setminus C_{k-1}|} = \\frac{2+\\epsilon}{2^{r-k+1}}$。\n-   对于块集 $A_j$ (其中 $j \\geq k$)，由于 $B_j$ 与 $C_{k-1}$ 不相交，我们有 $|A_j \\setminus C_{k-1}|=|A_j|=|B_j|$。\n    比率为 $\\frac{c(A_j)}{|A_j \\setminus C_{k-1}|} = \\frac{1}{|B_j|}$。\n    对于 $j \\in \\{k, \\dots, r+1\\}$，这些比率的最小值对应于具有最大大小 $|B_j|$ 的集合 $A_j$，即大小为 $|B_k|=2^{r-k}$ 的集合 $A_k$。最小比率为 $\\frac{1}{2^{r-k}}$。\n\n将块集的最小比率与 $G$ 的比率进行比较：\n我们比较 $\\frac{1}{2^{r-k}}$ 和 $\\frac{2+\\epsilon}{2^{r-k+1}}$。\n两边同乘以 $2^{r-k+1}$ 得到 $2$ 和 $2+\\epsilon$。\n由于 $2  2+\\epsilon$，我们有 $\\frac{1}{2^{r-k}}  \\frac{2+\\epsilon}{2^{r-k+1}}$。\n贪心算法选择 $A_k$。这对于从 $2$ 到 $r$ 的所有 $k$ 都成立。\n\n**最后一次迭代 ($k=r+1$)：**\n经过 $r$ 次迭代后，算法已选择集合 $A_1, A_2, \\dots, A_r$。\n已覆盖的集合是 $C_r = \\bigcup_{j=1}^{r} B_j$。唯一未覆盖的元素位于块 $B_{r+1}$ 中。\n可用于覆盖这些元素的集合是 $G$ 和 $A_{r+1}$。\n-   对于全局集 $G$：$\\frac{c(G)}{|G \\setminus C_r|} = \\frac{2+\\epsilon}{|B_{r+1}|} = \\frac{2+\\epsilon}{1} = 2+\\epsilon$。\n-   对于块集 $A_{r+1}$：$\\frac{c(A_{r+1})}{|A_{r+1} \\setminus C_r|} = \\frac{1}{|B_{r+1}|} = \\frac{1}{1} = 1$。\n\n比较这两个比率，$1  2+\\epsilon$。算法选择 $A_{r+1}$。\n现在 $U$ 中的所有元素都已被覆盖，算法终止。\n\n贪心算法选择的集合为 $\\mathcal{C}_{Greedy} = \\{A_1, A_2, \\dots, A_r, A_{r+1}\\}$。\n此覆盖的总成本为 $C_{Greedy} = \\sum_{j=1}^{r+1} c(A_j) = \\sum_{j=1}^{r+1} 1 = r+1$。\n\n**3. 计算近似比**\n\n近似比由公式 $\\frac{C_{Greedy}}{C_{OPT}}$ 给出。\n代入推导出的值：\n$$ \\text{近似比} = \\frac{r+1}{2+\\epsilon} $$\n\n这个表达式就是贪心算法在给定实例族上的精确近似比。", "answer": "$$\\boxed{\\frac{r+1}{2+\\epsilon}}$$", "id": "3256360"}, {"introduction": "最后，让我们通过一个思想实验来深入探究 NP-完全问题的理论核心。如果有一个能瞬间判断图中是否存在一个大小为 $k$ 的团（clique）的“神谕机”，我们能否利用它来高效地 *找到* 这个团呢？本练习 [@problem_id:3256391] 探讨的正是从“判定问题”到“搜索问题”的转化，这一过程揭示了 NP-完全问题深刻的自可约减性（self-reducibility）结构，这正是复杂性理论中将重点放在判定问题上的关键原因之一。", "problem": "您可以使用一个假设性的决策预言机，该预言机用于解决经典的非确定性多项式时间 (NP) 问题 CLIQUE。该预言机的输入是一个无向图 $G=(V,E)$ 和一个整数 $k \\in \\mathbb{Z}_{\\ge 0}$，预言机返回是否存在一个大小至少为 $k$ 的子集 $C \\subseteq V$，使得 $C$ 中每一对不同的顶点都由 $E$ 中的一条边连接（即，$C$ 是一个大小至少为 $k$ 的团）。假设预言机在 $O(1)$ 时间内回答每个查询。\n\n请仅从图、团、问题的决策版本与搜索版本、以及多项式时间图灵归约等核心定义出发，从第一性原理推导出一个多项式时间算法。该算法使用此预言机作为子程序，在给定图中找到一个实际的最大团。请通过解释为什么您的过程总能返回一个最大可能尺寸的团，以及为什么预言机查询次数和所有其他计算都受限于 $|V|$ 的多项式，来证明其正确性。您还必须确定一个确定性的打破平局规则：在所有最大团中，当顶点按升序整数标记时，您的算法必须返回字典序最小的那个。", "solution": "该问题要求推导并实现一个多项式时间算法，在给定一个用于 CLIQUE 问题的决策预言机的情况下，找到图 $G=(V, E)$ 中字典序最小的最大团。该预言机（下文记为 `CLIQUE_ORACLE(G', k)`），如果在图 $G'$ 中存在大小至少为 $k$ 的团，则返回 `True`，否则返回 `False`，其运行时间为 $O(1)$。推导过程必须从第一性原理出发。\n\n设 $|V|=n$。该问题可以分为两个主要部分：\n1.  找到最大团的大小。\n2.  构建字典序最小的最大团的具体顶点。\n\n这是搜索到决策归约（search-to-decision reduction）的一个经典例子，它是计算复杂性理论中的一个基本概念，表明如果一个决策问题可以被有效解决，那么其对应的搜索问题也可以。\n\n### 第一部分：确定最大团的大小\n\n图 $G$ 中最大团的大小，我们称其为 $k_{max}$，它必须是范围 $[0, n]$ 内的一个整数。我们可以通过一系列对 `CLIQUE_ORACLE` 的调用来确定 $k_{max}$。\n\n团的一个性质是，如果一个图有一个大小为 $k$ 的团，那么它也必然有所有小于 $k$ 的大小的团。这意味着函数 $f(k) = \\text{CLIQUE\\_ORACLE}(G, k)$ 是单调的：对于 $k \\in \\{0, 1, \\dots, n\\}$，输出序列 $f(0), f(1), \\dots, f(n)$ 将呈现 $(\\text{True}, \\dots, \\text{True}, \\text{False}, \\dots, \\text{False})$ 的形式。我们感兴趣的是使 $f(k)$ 为 `True` 的最大 $k$。\n\n这个值可以通过在可能的大小范围 $[0, n]$ 上使用二分搜索来高效地找到。\n设搜索范围为 `[low, high]`，初始化为 $[0, n]$。在每一步中，我们用中点 `mid = (low + high) // 2` 查询预言机。\n- 如果 `CLIQUE_ORACLE(G, mid)` 返回 `True`，我们知道存在一个大小为 `mid` 的团，因此最大大小至少为 `mid`。我们将 `mid` 记录为一个可能的答案，并通过设置 `low = mid + 1` 来搜索更大的尺寸。\n- 如果 `CLIQUE_ORACLE(G, mid)` 返回 `False`，则不存在大小为 `mid` 的团，因此最大大小必定更小。我们设置 `high = mid - 1`。\n\n当 `low > high` 时，二分搜索终止，最后一个使预言机返回 `True` 的 `mid` 就是最大团的大小 $k_{max}$。这个过程涉及 $O(\\log n)$ 次预言机调用。由于每次预言机调用是 $O(1)$，算法的这一部分在 $O(\\log n)$ 时间内运行。\n\n### 第二部分：构建字典序最小的最大团\n\n一旦 $k_{max}$ 已知，我们就可以构建团本身。问题要求的是字典序最小的最大团，其中顶点由整数 $0, 1, \\dots, n-1$ 标记。这个打破平局的规则暗示了一种贪心方法。我们应该首先尝试包含索引最小的顶点。\n\n我们将一次一个顶点地构建团，称之为 $C$。我们按照索引的升序，从 $0$ 到 $n-1$，遍历 $V$ 中的所有顶点 $v_i$。在每一步，我们决定是否将顶点 $v_i$ 添加到我们的团 $C$ 中。\n\n贪心选择如下：一个顶点 $v_i$ 被添加到 $C$ 中，当且仅当存在一个大小为 $k_{max}$ 的最大团，它是 $C \\cup \\{v_i\\}$ 的超集。这个检查可以使用预言机来执行。\n\n让我们将构建算法形式化：\n1.  为团初始化一个空集，$C = \\emptyset$。\n2.  设 $G$ 的顶点按其整数标签的升序为 $v_0, v_1, \\dots, v_{n-1}$。\n3.  对于从 $i=0$ 到 $n-1$ 的每个顶点 $v_i$：\n    a. 形成一个潜在的团前缀 $C_{potential} = C \\cup \\{v_i\\}$。\n    b. $C_{potential}$ 能成为更大团的一部分的一个必要条件是，$C_{potential}$ 本身必须是一个团。这意味着 $v_i$ 必须与已在 $C$ 中的每个顶点都相邻。如果不是，我们不能添加 $v_i$ 并继续到下一个顶点。\n    c. 如果 $C_{potential}$ 是一个团，我们必须检查它是否可以扩展成一个大小为 $k_{max}$ 的团。所需的剩余 $k_{needed} = k_{max} - |C_{potential}|$ 个顶点必须从与 $C_{potential}$ 中*所有*顶点都相邻的顶点集合中选择。设这个候选顶点集为 $U = \\{u \\in V \\mid \\forall w \\in C_{potential}, (u, w) \\in E \\}$。\n    d. 令 $G_U$ 为由顶点集 $U$ 导出的 $G$ 的子图。问题简化为询问在图 $G_U$ 中是否存在一个大小为 $k_{needed}$ 的团。这正是预言机可以回答的。\n    e. 我们调用 `CLIQUE_ORACLE(G_U, k_needed)`。\n    f. 如果预言机返回 `True`，则证实了存在一个包含 $C_{potential}$ 的最大团。由于我们是按升序遍历顶点，添加 $v_i$ 是保持字典序最小性质的正确贪心选择。我们将 $v_i$ 永久添加到我们的解中：$C \\leftarrow C \\cup \\{v_i\\}$。\n    g. 如果预言机返回 `False`，则没有最大团包含前缀 $C_{potential}$。我们不将 $v_i$ 添加到 $C$ 中，并继续处理下一个顶点。\n4.  一旦 $|C| = k_{max}$，团就构建完成了，我们可以终止。最终的集合 $C$ 就是字典序最小的最大团。\n\n### 正确性与复杂度分析\n\n**正确性：** 设 $C^* = \\{c_1, c_2, \\dots, c_{k_{max}}\\}$ 是真正的字典序最小的最大团，其中 $c_1  c_2  \\dots  c_{k_{max}}$。算法遍历顶点 $v_0, v_1, \\dots, v_{n-1}$。对于任何顶点 $v_i  c_1$，算法会测试添加它是否能形成一个大小为 $k_{max}$ 的团。如果可以，我们就会找到一个字典序比 $C^*$ 更小的最大团，这与假设矛盾。因此，对于所有 $v_i  c_1$，测试必定失败。当算法到达 $v_{c_1}$ 时，测试将通过，因为 $C^*$ 是一个有效的扩展。算法会将 $c_1$ 添加到它的团中。这个推理可以归纳地扩展：在每一步，算法都会做出与 $C^*$ 所规定的相同的选择，从而确保最终构建的团确实是 $C^*$。\n\n**复杂度：**\n- **第一部分 (寻找 $k_{max}$):** $O(\\log n)$ 次预言机调用和可忽略的计算。\n- **第二部分 (构建 $C$):**\n    - 主循环最多运行 $n$ 次。\n    - 在循环内部，对于每个顶点 $v_i$：\n        - 兼容性检查 (步骤 3b): $O(|C|) = O(n)$。\n        - 识别候选集 $U$ (步骤 3c): 对于 $V$ 中的 $O(n)$ 个顶点中的每一个，我们检查其与 $O(|C_{potential}|) = O(n)$ 个顶点的邻接关系。这需要 $O(n^2)$ 时间。\n        - 构建子图 $G_U$ (步骤 3d): 对于一个有 $O(n)$ 个顶点的图，构建其邻接矩阵可能需要高达 $O(n^2)$ 的时间。\n        - 预言机调用 (步骤 3e): $O(1)$。\n    - 总计算工作主要由循环内部的子图构建主导，导致复杂度为 $O(n \\cdot n^2) = O(n^3)$。\n    - 此部分的预言机调用次数最多为 $n$。\n\n总预言机调用次数为 $O(n + \\log n) = O(n)$，总计算时间为 $O(n^3)$。由于两者都受限于 $n=|V|$ 的多项式，该算法是一个多项式时间的图灵归约。\n\n至此，从第一性原理出发的推导完成。该算法正确地找到了所需的团，并遵守了相对于预言机的多项式时间约束。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport itertools\n\ndef solve():\n    \"\"\"\n    Derives and implements an algorithm to find the lexicographically smallest maximum clique\n    using a hypothetical decision oracle for the CLIQUE problem.\n    \"\"\"\n\n    # This nested function serves as the emulated oracle for the CLIQUE decision problem.\n    # Its internal implementation uses brute force, which is acceptable because the\n    # problem's focus is on the polynomial-time reduction algorithm that uses the oracle,\n    # not the oracle's own efficiency. A cache is used tomemoize results for a given graph,\n    # significantly speeding up the emulation for repeated queries.\n    _oracle_cache = {}\n\n    def get_adj_hash(adj):\n        \"\"\"Returns a hashable representation of a numpy array.\"\"\"\n        return adj.tobytes()\n\n    def clique_oracle(adj, k):\n        \"\"\"\n        Decision oracle for CLIQUE. Returns True if graph `adj` has a clique of size >= `k`.\n        \"\"\"\n        n = adj.shape[0]\n        adj_hash = get_adj_hash(adj)\n\n        if (adj_hash, k) in _oracle_cache:\n            return _oracle_cache[(adj_hash, k)]\n        \n        if k is None or k = 0: return True\n        if k == 0: return True\n        if n == 0 and k > 0: return False\n        if k == 1 and n > 0: return True\n        if k > n : return False\n        \n        # Check if the maximum clique size for this graph is already computed.\n        max_k_cache_key = (adj_hash, None)\n        if max_k_cache_key in _oracle_cache:\n            max_k_found = _oracle_cache[max_k_cache_key]\n            result = max_k_found >= k\n            _oracle_cache[(adj_hash, k)] = result\n            return result\n\n        # Brute-force check using itertools.combinations to find max clique size\n        nodes = list(range(n))\n        max_k = 0\n        if n > 0:\n            max_k = 1 # At least a 1-clique (single vertex) exists\n        for size in range(n, 1, -1):\n            found_clique_of_this_size = False\n            for combo in itertools.combinations(nodes, size):\n                is_a_clique = True\n                for i1_idx in range(len(combo)):\n                    for i2_idx in range(i1_idx + 1, len(combo)):\n                        u, v = combo[i1_idx], combo[i2_idx]\n                        if not adj[u, v]:\n                            is_a_clique = False\n                            break\n                    if not is_a_clique:\n                        break\n                if is_a_clique:\n                    max_k = size\n                    found_clique_of_this_size = True\n                    break\n            if found_clique_of_this_size:\n                break\n        \n        _oracle_cache[max_k_cache_key] = max_k\n        result = max_k >= k\n        _oracle_cache[(adj_hash, k)] = result\n        return result\n\n    # --- Test Suite Definition ---\n    \n    # G1: V={0..5}, E={(1,2),(1,3),(1,4),(2,3),(2,4),(3,4),(0,1),(0,2),(4,5)}\n    adj1 = np.zeros((6, 6), dtype=bool)\n    for u, v in [(1,2),(1,3),(1,4),(2,3),(2,4),(3,4),(0,1),(0,2),(4,5)]:\n        adj1[u,v] = adj1[v,u] = True\n\n    # G2: K5 on V={0..4}\n    adj2 = np.ones((5, 5), dtype=bool)\n    np.fill_diagonal(adj2, False)\n\n    # G3: V={0..3}, E=empty\n    adj3 = np.zeros((4, 4), dtype=bool)\n\n    # G4: V={0..5}, E={(0,1),(1,2),(0,2),(2,3),(3,4),(2,4)}\n    adj4 = np.zeros((6, 6), dtype=bool)\n    for u, v in [(0,1),(1,2),(0,2),(2,3),(3,4),(2,4)]:\n        adj4[u,v] = adj4[v,u] = True\n\n    # G5: V={0..6}, E={(0,1),(0,2),(0,3),(1,2),(1,3),(2,3),(1,4),(2,4),(3,4),(4,5),(5,6),(4,6)}\n    adj5 = np.zeros((7, 7), dtype=bool)\n    for u, v in [(0,1),(0,2),(0,3),(1,2),(1,3),(2,3),(1,4),(2,4),(3,4),(4,5),(5,6),(4,6)]:\n        adj5[u,v] = adj5[v,u] = True\n\n    test_cases = [adj1, adj2, adj3, adj4, adj5]\n    all_results = []\n    \n    for adj in test_cases:\n        _oracle_cache.clear()\n        n = adj.shape[0]\n\n        # Part 1: Find k_max using binary search on the oracle\n        k_max = 0\n        if n > 0:\n            low, high = 1, n\n            while low = high:\n                mid = (low + high) // 2\n                if mid == 0:\n                    low = mid + 1\n                    continue\n                if clique_oracle(adj, mid):\n                    k_max = mid\n                    low = mid + 1\n                else:\n                    high = mid - 1\n\n        # Part 2: Construct the lexicographically smallest max clique\n        clique = []\n        for v_idx in range(n):\n            if len(clique) == k_max:\n                break\n                \n            is_compatible = all(adj[v_idx, c_node] for c_node in clique)\n            if not is_compatible:\n                continue\n\n            potential_clique = clique + [v_idx]\n            k_needed = k_max - len(potential_clique)\n\n            test_result = False\n            if k_needed  0: continue\n            if k_needed == 0:\n                test_result = True\n            else:\n                common_neighbors = [u for u in range(v_idx + 1, n) if all(adj[u, pc_node] for pc_node in potential_clique)]\n                \n                if len(common_neighbors) >= k_needed:\n                    sub_n = len(common_neighbors)\n                    sub_adj = np.zeros((sub_n, sub_n), dtype=bool)\n                    for i in range(sub_n):\n                        for j in range(i + 1, sub_n):\n                            u1, u2 = common_neighbors[i], common_neighbors[j]\n                            if adj[u1, u2]:\n                                sub_adj[i, j] = sub_adj[j, i] = True\n                    test_result = clique_oracle(sub_adj, k_needed)\n            \n            if test_result:\n                clique.append(v_idx)\n        \n        all_results.append(clique)\n\n    string_results = [str(r).replace(\" \", \"\") for r in all_results]\n    print(f\"[{','.join(string_results)}]\")\n\nsolve()\n```", "id": "3256391"}]}