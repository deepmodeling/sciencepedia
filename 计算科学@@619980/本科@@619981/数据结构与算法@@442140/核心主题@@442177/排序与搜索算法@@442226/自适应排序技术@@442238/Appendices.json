{"hands_on_practices": [{"introduction": "我们首先来解决一个非常实际的问题：如何高效地排序一个“几乎有序”的数组？这里的“几乎有序”有一个明确的定义，即每个元素离其最终排好序的位置不超过 $k$ 个索引。这个练习 [@problem_id:3203352] 挑战你利用这一特性，设计一个时间复杂度为 $O(n \\log k)$ 的算法，这远比通用排序算法的 $O(n \\log n)$ 更有效。通过使用最小堆来维护一个“滑动窗口”内的候选元素，你将亲手实现自适应排序的核心思想之一。", "problem": "给定定义在全序域上的数组，并保证对于每个元素，其与排序后最终位置的位移最多为 $k$ 个索引。形式上，设输入为一个长度为 $n$ 的数组 $A$，其元素定义在一个具有全序关系 $\\leq$ 的集合上。对于每个元素 $A[i]$，令 $pos(A[i])$ 表示将 $A$ 按非递减顺序排序后（任何确定性规则解决相等元素问题）$A[i]$ 所在的索引。保证对于所有 $i \\in \\{0,1,\\dots,n-1\\}$，位移满足 $\\lvert pos(A[i]) - i \\rvert \\leq k$，其中 $k$ 是一个非负整数。你的任务是设计并实现一种自适应排序技术，该技术利用此位移界限，以达到最坏情况时间复杂度为 $O(n \\log k)$ 和空间复杂度为 $O(k)$，并返回按非递减顺序排序的数组。\n\n你可以使用的基本定义：\n- 全序是一种集合 $S$ 上的二元关系 $\\leq$，使得对于所有 $x,y \\in S$， $x  y$、$x = y$ 或 $x > y$ 中恰好有一个成立，并且该关系具有传递性和反对称性。\n- 优先队列（PQ）是一种抽象数据类型，支持插入元素和提取在 $\\leq$ 关系下的最小元素，这两项操作的时间复杂度都与当前存储的元素数量成对数关系。\n- 二叉堆是一种实现优先队列的数据结构，其插入和提取最小元素操作的运行时间为 $O(\\log m)$，其中 $m$ 是堆中当前的元素数量。\n\n你的程序必须实现所述的自适应排序算法，将其应用于以下测试套件，并按规定产生结果。\n\n测试套件（每个测试用例是一个对 $(A,k)$）：\n1. $A = [12,3,5,9,24,15,18,21,30,27]$, $k = 3$。\n2. $A = [1,2,2,3]$, $k = 0$。\n3. $A = [2,1,4,3,6,5]$, $k = 1$。\n4. $A = []$, $k = 2$。\n5. $A = [42]$, $k = 10$。\n6. $A = [-2,-5,-2,3,0,3,7]$, $k = 2$。\n7. $A = [23,42,4,8,15,16]$, $k = 5$。\n8. $A = [30,40,50,10,20]$, $k = 100$。\n9. $A = [3,1,2,6,4,5,9,7,8,10]$, $k = 2$。\n\n输出规范：\n- 对于每个测试用例，程序必须输出与按非递减顺序排序的 $A$ 对应的已排序数组（一个整数列表）。\n- 你的程序应生成单行输出，其中包含按上述测试套件顺序排列的结果，结果为用逗号分隔并用方括号括起来的列表。例如，输出格式必须为 $[result_1,result_2,\\dots,result_9]$，其中每个 $result_i$ 是测试用例 $i$ 的排序后列表。\n- 数组中的所有数值都是纯整数；不涉及物理单位或角度。\n\n约束条件：\n- $n$ 是任意非负整数。\n- $k$ 是任意非负整数（当 $k \\geq n-1$ 时，该保证无实际意义，但算法仍必须运行并返回正确的排序顺序）。", "solution": "该问题要求为“近乎有序”的数组设计一种自适应排序算法。近乎有序的具体性质是指，输入数组 $A$ 中索引为 $i$ 的任何元素，在最终排序后的数组中其索引为 $j$，且其位移 $\\lvert i - j \\rvert$ 最多为 $k$，其中 $k$ 是一个给定的非负整数。该算法必须达到最坏情况时间复杂度 $O(n \\log k)$ 和辅助空间复杂度 $O(k)$，其中 $n$ 是数组中的元素数量。\n\n### 基本原理\n该自适应方法的核心在于从给定性质 $\\lvert pos(A[i]) - i \\rvert \\leq k$ 推导出的一个关键结论，其中 $pos(A[i])$ 是元素 $A[i]$ 最终排序后的索引。这个不等式可以被重新整理，用于分析排序后序列中元素的来源。设 $S$ 是将数组 $A$ 按非递减顺序排序后的数组。对于排序后数组中索引为 $j$ 的元素 $S[j]$，它在 $A$ 中的原始索引 $i$ 必须满足 $\\lvert j - i \\rvert \\leq k$。这意味着 $j-k \\leq i \\leq j+k$。\n\n这是一个强有力的约束。它告诉我们，属于排序后输出中位置 $j$ 的元素 $S[j]$，必定位于输入数组 $A$ 的索引范围 $[\\max(0, j-k), \\min(n-1, j+k)]$ 之内。对于构造性算法而言，更重要的是，它保证了全局最小的元素 $S[0]$ 必定来源于 $A$ 中索引 $i \\in [0, k]$ 的位置。第二小的元素 $S[1]$ 必定来源于 $A$ 中索引 $i \\in [0, 1+k]$ 的位置。总的来说，排序后数组的第 $j$ 个元素 $S[j]$ 必定存在于输入数组的前缀 $A[0 \\dots j+k]$ 中。\n\n这种局部性表明，我们无需考虑整个数组来寻找下一个最小元素。相反，我们可以维护一个候选元素的“窗口”，并反复从此窗口中提取最小值。一个以最小堆实现的最小优先队列是完成此任务的理想数据结构，因为它支持高效地提取最小值和插入新元素。\n\n### 算法设计\n算法流程如下，使用最小堆来管理一个候选元素的滑动窗口：\n1.  初始化一个空列表 `result`，用于存储排序后的元素。\n2.  初始化一个最小优先队列 `pq`。\n3.  用输入数组 $A$ 的前 `min(n, k+1)` 个元素填充 `pq`。这构成了初始的候选窗口。在 $n \\le k$ 的情况下，会添加 $A$ 的所有元素。使用线性时间的堆化（heapify）算法，此步骤耗时 $O(k)$。\n4.  迭代 $n$ 次以构建排序后的 `result` 数组。在每次迭代中：\n    a. 从 `pq` 中提取最小元素。根据上文确立的原理，可以保证该元素是排序序列中的下一个最小元素。将其附加到 `result`。\n    b. 为维护滑动窗口，如果输入数组 $A$ 中还有下一个未检查的元素，则将其插入 `pq`。在处理完初始的 `min(n, k+1)` 个元素并提取一个之后，下一个要考虑的元素位于索引 `min(n, k+1)`，以此类推。\n\n优先队列 `pq` 的大小对算法性能至关重要。它最多用 $k+1$ 个元素进行初始化。在主循环的每一步中，一个元素被移除，一个元素被添加（直到输入数组耗尽）。因此，`pq` 中的元素数量永远不会超过 $k+1$。\n\n### 正确性论证\n算法的正确性取决于一个循环不变量：在每次提取操作之前，`pq` 中包含了所有待排序元素中的最小元素。\n我们来形式化地说明这一点。假设我们即将确定排序后数组的第 $j$ 个元素 $S[j]$。此时，算法已经将 $S[0], \\dots, S[j-1]$ 放入了 `result` 数组。已插入 `pq` 的输入数组 $A$ 中的元素来自索引 $0$ 直到至少 $j+k-1$（如果 $n$ 更小，则更少）。\n元素 $S[j]$ 必须来自一个原始索引 $i \\le j+k$。因为所有来自 $A[0 \\dots j+k-1]$ 的元素都已被考虑（要么已放入 `result`，要么仍在 `pq` 中），并且我们即将在 $A[j+k]$ 存在时将其加入，所以真正的 $S[j]$ 保证在 `pq` 中。由于 `pq` 是一个最小优先队列，`extract-min` 操作将正确返回 $S[j]$。这对所有从 $0$ 到 $n-1$ 的 $j$ 都成立。\n\n### 复杂度分析\n-   **时间复杂度**：用 $\\min(n, k+1)$ 个元素初始化 `pq` 需要 $O(\\min(n, k)) = O(k)$ 的时间（因为如果 $n \\le k$，则为 $O(n)$；如果我们假设对于自适应排序 $k  n$，则为 $O(k)$）。主循环运行 $n$ 次。在循环内部，我们执行一次 `extract-min` 和至多一次 `insert` 操作。`pq` 的大小以 $k+1$为界。因此，每次堆操作耗时 $O(\\log k)$。总时间复杂度为 $O(k) + n \\times O(\\log k) = O(n \\log k)$。这满足了指定的要求。如果 $k=0$，复杂度为 $O(n)$；如果 $k \\geq n-1$，则变为 $O(n \\log n)$，其行为类似于标准的堆排序。\n-   **空间复杂度**：辅助空间主要由优先队列占用。由于其大小以 $k+1$ 为界，空间复杂度为 $O(k)$。输出数组 `result` 需要 $O(n)$ 的空间，这通常被归类为输出空间而非辅助空间。该算法满足了对辅助存储的 $O(k)$ 空间复杂度要求。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport heapq\n\ndef adaptive_sort(A, k):\n    \"\"\"\n    Sorts a k-nearly-sorted array in O(n log k) time and O(k) auxiliary space.\n\n    An array is k-nearly-sorted if for every element, its final sorted position\n    is at most k indices away from its current position.\n\n    Args:\n        A (list): The input array of numbers.\n        k (int): The maximum displacement of any element.\n\n    Returns:\n        list: The sorted array.\n    \"\"\"\n    n = len(A)\n    if n == 0:\n        return []\n\n    # The size of the initial heap and the sliding window.\n    # If k >= n-1, this will be n, correctly turning the algorithm into a heapsort.\n    window_size = min(n, k + 1)\n    \n    # Python's heapq implements a min-heap.\n    # Initialize the heap with the first `window_size` elements.\n    pq = A[:window_size]\n    heapq.heapify(pq)  # This operation takes O(window_size) time.\n\n    result = []\n    # Index of the next element from A to be added to the heap.\n    next_elem_idx = window_size\n\n    # The loop runs n times, once for each element to be placed in the result.\n    for _ in range(n):\n        # The smallest element in the heap is the next element in the sorted sequence.\n        # We can extract it.\n        min_val = heapq.heappop(pq)\n        result.append(min_val)\n\n        # If there are more elements in the input array, add the next one to the heap\n        # to maintain the sliding window of candidates.\n        if next_elem_idx  n:\n            heapq.heappush(pq, A[next_elem_idx])\n            next_elem_idx += 1\n            \n    return result\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        ([12, 3, 5, 9, 24, 15, 18, 21, 30, 27], 3),\n        ([1, 2, 2, 3], 0),\n        ([2, 1, 4, 3, 6, 5], 1),\n        ([], 2),\n        ([42], 10),\n        ([-2, -5, -2, 3, 0, 3, 7], 2),\n        ([23, 42, 4, 8, 15, 16], 5),\n        ([30, 40, 50, 10, 20], 100),\n        ([3, 1, 2, 6, 4, 5, 9, 7, 8, 10], 2)\n    ]\n\n    results = []\n    for A, k in test_cases:\n        sorted_A = adaptive_sort(list(A), k) # Use a copy to not modify original\n        results.append(sorted_A)\n\n    # Format the final list of results into the specified string format.\n    # e.g., [[1, 2], [3, 4]] -> \"[[1, 2], [3, 4]]\"\n    # Using str() on a list automatically includes spaces, e.g., '[1, 2, 3]'.\n    # To match a compact format, we might need custom string formatting.\n    # The code below generates compact lists like '[1,2,3]'.\n    formatted_results = [f\"[{','.join(map(str, res))}]\" for res in results]\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3203352"}, {"introduction": "“预排序度”并非一个单一的概念；一个数组可能在一个度量下（如“运行”数量少）是“几乎有序”的，但在另一个度量下（如“逆序对”数量多）却是“混乱”的。这个思想实验 [@problem_id:3203325] 巧妙地揭示了这一点，它要求你构建一个特殊序列，该序列对于基于“运行”的算法来说是理想的，但对于基于“逆序对”的算法来说却是最差情况。这个练习将帮助你理解，选择正确的自适应算法，关键在于匹配输入数据中存在的特定“有序”模式。", "problem": "考虑一个包含 $n$ 个不同键的集合，其期望的排序顺序为 $1,2,\\dots,n$，其中 $n$ 是一个偶数且 $n \\geq 4$。两种自适应的基于比较的排序算法 $A_1$ 和 $A_2$ 利用了不同的预排序度度量。将排列 $\\pi$ 的逆序对数 $I(\\pi)$ 定义为满足 $i  j$ 且 $\\pi(i) > \\pi(j)$ 的索引对 $(i,j)$ 的数量。将排列的升序归并段数 $R(\\pi)$ 定义为构成 $\\pi$ 的最大连续非递减子序列的数量。考虑两种自适应排序算法，$A_1$ 和 $A_2$，其在大小为 $n$ 的输入上的比较成本分别为 $C_1(n, R) = n \\ln R$ 和 $C_2(n, I) = n + I$。\n\n您的任务是构造一个特定的排列 $\\pi$，它由两个长度各为 $n/2$ 的严格递增的连续块组成，且第一个块中的每个键都大于第二个块中的每个键。对于这个排列 $\\pi$，推导出一个关于 $n$ 的简化的闭式表达式，表示加速比 $\\rho(n) = C_2(n, I(\\pi)) / C_1(n, R(\\pi))$。", "solution": "该问题要求构造一个键集为 $\\{1, 2, \\dots, n\\}$ 的特定排列 $\\pi$，其中 $n$ 是一个偶数且 $n \\ge 4$。该排列由两个长度各为 $n/2$ 的严格递增连续块连接而成，并附加约束条件：第一个块中的每个键都大于第二个块中的每个键。\n\n为满足这些约束，必须将键集 $\\{1, 2, \\dots, n\\}$ 划分为两个集合：较小的键 $\\{1, 2, \\dots, n/2\\}$ 和较大的键 $\\{n/2+1, \\dots, n\\}$。为了让第一个块中的所有键都大于第二个块中的所有键，第一个块必须由较大的键组成，第二个块必须由较小的键组成。由于每个块也是严格递增的，它们必须在内部排好序。\n因此，长度为 $n/2$ 的第一个块是序列 $(n/2+1, n/2+2, \\dots, n)$。\n长度为 $n/2$ 的第二个块是序列 $(1, 2, \\dots, n/2)$。\n\n连接这两个块得到排列 $\\pi$：\n$$\n\\pi = \\left(\\frac{n}{2}+1, \\frac{n}{2}+2, \\dots, n, 1, 2, \\dots, \\frac{n}{2}\\right)\n$$\n\n接下来，我们必须确定此特定排列的升序归并段数 $R(\\pi)$ 和逆序对数 $I(\\pi)$。\n\n1.  **计算升序归并段数 $R(\\pi)$**：\n    升序归并段是最大连续非递减子序列。\n    序列的第一部分 $(\\frac{n}{2}+1, \\frac{n}{2}+2, \\dots, n)$ 是严格递增的，因此构成一个单一的升序归并段。\n    由于 $n > 1$ 且第一个块的最后一个元素 $n$ 大于第二个块的第一个元素 $1$，序列在元素 $n$ 和元素 $1$ 的连接处断开，形成一个新的归并段。\n    序列的第二部分 $(1, 2, \\dots, \\frac{n}{2})$ 也是严格递增的，构成第二个升序归并段。\n    因此，排列 $\\pi$ 恰好由两个升序归并段组成。\n    $$\n    R(\\pi) = 2\n    $$\n    就归并段度量而言，这个排列是接近排序的，因为 $R(\\pi)$ 是一个很小的常数。\n\n2.  **计算逆序对数 $I(\\pi)$**：\n    逆序对是一个索引对 $(i, j)$，满足 $i  j$ 且 $\\pi(i) > \\pi(j)$。我们来分析可能的索引对。\n    - 如果索引 $i$ 和 $j$ 都在第一个块内（即 $1 \\le i  j \\le n/2$），那么由于第一个块是严格递增的，有 $\\pi(i)  \\pi(j)$。这贡献了 $0$ 个逆序对。\n    - 如果索引 $i$ 和 $j$ 都在第二个块内（即 $n/2+1 \\le i  j \\le n$），那么由于第二个块是严格递增的，有 $\\pi(i)  \\pi(j)$。这贡献了 $0$ 个逆序对。\n    - 如果索引 $i$ 在第一个块中（$1 \\le i \\le n/2$）且索引 $j$ 在第二个块中（$n/2+1 \\le j \\le n$），那么 $\\pi(i)$ 是来自集合 $\\{\\frac{n}{2}+1, \\dots, n\\}$ 的一个键，而 $\\pi(j)$ 是来自集合 $\\{1, \\dots, \\frac{n}{2}\\}$ 的一个键。根据构造，第一个块中的每个键都大于第二个块中的每个键。因此，对于每个这样的对 $(i, j)$，$\\pi(i) > \\pi(j)$ 均成立，从而形成一个逆序对。\n\n    为求出此类逆序对的总数，我们将第一个块中的元素数量乘以第二个块中的元素数量。两个块中的元素数量都是 $n/2$。\n    逆序对的总数为：\n    $$\n    I(\\pi) = \\left(\\frac{n}{2}\\right) \\times \\left(\\frac{n}{2}\\right) = \\frac{n^2}{4}\n    $$\n    就逆序对度量而言，这个排列远未排序，因为 $I(\\pi)$ 随 $n$ 呈二次方增长。\n\n现在，我们使用给定的成本模型来计算每种算法的比较次数。\n算法 $A_1$（基于合并归并段）的成本是：\n$$\nC_1(n, R(\\pi)) = n \\ln(R(\\pi)) = n \\ln(2)\n$$\n算法 $A_2$（基于插入的算法）的成本是：\n$$\nC_2(n, I(\\pi)) = n + I(\\pi) = n + \\frac{n^2}{4}\n$$\n\n最后，我们计算加速比 $\\rho(n)$，其定义为 $C_2$ 与 $C_1$ 的比率：\n$$\n\\rho(n) = \\frac{C_2(n, I(\\pi))}{C_1(n, R(\\pi))} = \\frac{n + \\frac{n^2}{4}}{n \\ln(2)}\n$$\n我们可以简化此表达式。从分子中提出公因子 $n$（因为 $n \\ge 4$ 所以这是允许的）：\n$$\n\\rho(n) = \\frac{n \\left(1 + \\frac{n}{4}\\right)}{n \\ln(2)} = \\frac{1 + \\frac{n}{4}}{\\ln(2)}\n$$\n为了以更标准的形式呈现该表达式，使其分子中不含分数，我们可以写成：\n$$\n\\rho(n) = \\frac{\\frac{4+n}{4}}{\\ln(2)} = \\frac{n+4}{4\\ln(2)}\n$$\n这就是加速比 $\\rho(n)$ 的最终、简化的闭式表达式。", "answer": "$$\n\\boxed{\\frac{n+4}{4\\ln(2)}}\n$$", "id": "3203325"}, {"introduction": "接下来，让我们从理论模型转向剖析像Timsort这样在Python和Java中广泛使用的现代排序算法。Timsort使用一种称为“飞驰模式”（galloping mode）的优化，当合并过程中一个序列的元素连续“胜出”时，可以显著加速合并。这个高级练习 [@problem_id:3203377] 要求你构建一个特殊的“位反转”序列作为对抗性输入，它能巧妙地阻止“飞驰模式”的触发，从而迫使Timsort执行较慢的比较路径。这项实践让你深入洞察算法优化的工作原理及其性能极限。", "problem": "考虑利用预先存在顺序的自适应排序技术。Timsort 系列算法使用自然运行段和一种疾驰模式（也称为指数搜索模式），当合并的一方赢得足够多次连续的元素选择时，该模式会被激活。您需要形式化一个此行为的简化纯逻辑模型，构建具有许多微小运行段的对抗性输入以阻止疾驰模式触发，并经验性地验证其比较复杂度。\n\n所使用的基本依据包括以下经过充分检验的事实和核心定义：\n- 两个长度分别为 $a$ 和 $b$ 的已排序序列的稳定合并，在“成对”模式（总是比较当前头部元素）下执行时，最多进行 $a + b - 1$ 次键值比较。\n- 疾驰（指数搜索模式）是一种加速技术，在一方连续获胜达到阈值次数后，用指数搜索和二分搜索取代重复的成对比较，以从获胜方复制一整个块。如果疾驰模式从未触发，算法将保持在成对模式下。\n\n任务规格说明：\n\n1. 定义一个简化的自底向上类 Timsort 算法，该算法：\n   - 从 $r = n$ 个长度为 $1$ 的运行段开始（即输入是 $n$ 个单元素序列，因此 $r = \\Theta(n)$）。\n   - 以平衡的方式迭代合并相邻的运行段，直到只剩下一个运行段，并保持稳定性。在每次合并时，使用标准的成对头部比较。按如下方式实现疾馳模式，其阈值参数为 $g \\in \\mathbb{N}$：每当左侧（或右侧）连续赢得 $g$ 次比较时，切换到对对方枢轴元素进行指数搜索，以定位获胜方的上界并立即复制整个块，然后重置连续获胜计数器。只计算针对数组元素的键值比较（即形式为 $A[i] \\le B[j]$ 的比较以及在指数搜索或二分搜索内部执行的比较），不计算控制流检查。\n\n2. 构建使疾驰模式无法触发的对抗性输入。具体来说，对于任何2的幂 $n$，按位反转顺序生成一个包含键值 $1, 2, \\dots, n$ 的输入序列：令 $m = \\log_2 n$，对于每个索引 $i \\in \\{0, 1, \\dots, n-1\\}$，将键值 $i+1$ 放置在由反转 $i$ 的 $m$ 位二进制表示所给出的位置上。将每个元素视为其自身的长度为 $1$ 的运行段。证明对于此输入，在每个合并层级，两个被合并的序列都以步长为1完美交错，这意味着任何一方都无法累积 $g \\ge 2$ 次连续获胜。结论是疾驰模式無法触发，且比较次数恰好为\n$$\nC(n) = \\sum_{\\ell=1}^{\\log_2 n} \\left( \\frac{n}{2^\\ell} \\cdot \\left(2^\\ell - 1\\right) \\right) = n \\log_2 n - (n - 1),\n$$\n即 $O(n \\log n)$。\n\n3. 通过插桩实现该算法，以计算键值比较的总次数和进入疾驰模式的总次数。使用上述对抗性构造，经验性地验证对于所选的测试套件，疾驰模式不会触发，并且总比较次数与 $C(n)$ 相匹配。\n\n测试套件：\n- 案例 1：$(n, g) = (32, 7)$。\n- 案例 2：$(n, g) = (64, 7)$。\n- 案例 3：$(n, g) = (128, 7)$。\n- 边界案例 4：$(n, g) = (1, 7)$。\n- 小阈值案例 5：$(n, g) = (32, 2)$。\n- 附加案例 6：$(n, g) = (16, 4)$。\n\n对于每个案例，程序必须计算：\n- 实现实际执行的键值比较总次数 $K(n, g)$。\n- 上文定义的理论比较次数 $C(n)$。\n- 一个指示是否曾进入疾驰模式的布尔值。\n\n最终输出格式：\n- 您的程序应生成一行输出，其中包含一个由方括号括起来的逗号分隔列表（例如，“[result1,result2,result3]”）。该列表必须是扁平的，每个测试案例按 $(K(n, g), C(n), \\text{gallop\\_used})$ 的顺序贡献三个连续项。因此，对于包含六个案例的测试套件，输出必须恰好包含十八个项。\n\n所有量都是纯数，没有物理单位。不涉及角度。不涉及百分比。您推理中的所有数学运算都必须使用上面明确定义的符号。", "solution": "我们从稳定合并的基本行为和疾驰模式的定义开始。两个已排序序列的稳定合并会保持相等元素的顺序，并且只比较当前头部元素来选择下一个元素。我们所依赖的经过充分检验的事实是，当不使用额外加速技术时，合并长度为 $a$ 和 $b$ 的序列最多进行 $a + b - 1$ 次键值比较。疾驰是 Timsort 中在一方重复获胜时使用的一种优化：如果左侧连续获胜 $g$ 次，就在左侧序列上对右侧的枢轴元素进行指数搜索以找到上界，然后复制整个块，右侧同理。如果疾驰模式从未触发，算法将纯粹在成对模式下运行，比较成本遵循经典界限。\n\n我们通过取 $n$ 个单元素序列来构建具有 $r = \\Theta(n)$ 个微小运行段的对抗性输入，因此 $r = n$。关键步骤是按位反转顺序排列 $n$ 个元素 $1, 2, \\dots, n$。令 $n = 2^m$ 且 $m = \\log_2 n$。对于每个索引 $i \\in \\{0, 1, \\dots, n-1\\}$，写出 $i$ 的 $m$ 位二进制表示并将其反转以获得 $\\mathrm{rev}(i)$。将键值 $i+1$ 放置在数组位置 $p = \\mathrm{rev}(i)$ 上。因此，该数组是 $n$ 个长度为 $1$ 的运行段的串联，满足 $r = n = \\Theta(n)$。我们断言，在自底向上的合并调度下，这种排列方式在每个合并层级都会阻止疾驰模式。\n\n为了证明这一论断，考虑一个自底向上的合并过程，该过程将相邻的运行段配对形成长度为 $2$ 的合并后运行段，然后将相邻的合并后运行段配对形成长度为 $4$ 的运行段，以此类推，直到整个数组被合并。在合并层级 $\\ell \\in \\{1, 2, \\dots, m\\}$，长度为 $2^{\\ell-1}$ 的段被合并成长度为 $2^\\ell$ 的段。位反转排列具有一个关键属性：在每个长度为 $2^\\ell$ 的连续块内，当两个长度为 $2^{\\ell-1}$ 的半区被合并时，左半区包含所有第 $\\ell$ 个最低有效位（比特位从0开始索引）为 $0$ 的键值（按升序排列），而右半区包含所有第 $\\ell$ 个最低有效位为 $1$ 的键值（按升序排列）。因此，在合并这两个半区时，块内的排序顺序会根据第 $\\ell$ 个比特位交替选择元素。这一点可以通过注意到位反转将连续的位置块映射为按比特重要性的分层来理解：在层级 $\\ell$，归属于左半区还是右半区完全由原始索引的第 $\\ell$ 个比特位决定，而在每个半区内部，较低的 $\\ell-1$ 个比特位是有序的，从而产生由关于该比特位的交错余数组成的升序序列。因此，当这两个半区合并时，选择序列在整个块上以步长为 $1$ 在左右之间严格交替，因此任何一方都无法累积 $g \\ge 2$ 次连续获胜。\n\n形式上，在层级 $\\ell$，将整个块中的键值按排序顺序写为 $x_1  x_2  \\dots  x_{2^\\ell}$。令 $L$ 为那些第 $\\ell$ 个比特位为 $0$ 的 $x_j$ 的子序列，令 $R$ 为那些第 $\\ell$ 个比特位为 $1$ 的子序列。交错属性指出，$L$ 和 $R$ 的合并会产生 $x_1, x_2, \\dots, x_{2^\\ell}$，并且选择交替来自 $L$ 和 $R$。这种交替意味着左侧和右侧的连续获胜计数器最多为 $1$，因此对于任何疾驰阈值 $g \\ge 2$，疾驰模式都不会触发。由于这对每个层级 $\\ell$ 都成立，所以在整个排序过程中从未进入疾驰模式。\n\n在这种对抗性输入下，比较复杂度源于完全在成对模式下操作。在合并层级 $\\ell$，有 $\\frac{n}{2^\\ell}$ 次合并，每次合并两个长度为 $2^{\\ell-1}$ 的序列。由于完美的交替以及只有在最后一个元素时才会耗尽其中一个序列，每次这样的合并都恰好执行 $2^\\ell - 1$ 次比较。因此，总比较次数为\n$$\nC(n) = \\sum_{\\ell=1}^{m} \\left( \\frac{n}{2^\\ell} \\cdot \\left(2^\\ell - 1\\right) \\right)\n= \\sum_{\\ell=1}^{m} \\left(n - \\frac{n}{2^\\ell}\\right)\n= n m - n \\sum_{\\ell=1}^{m} \\frac{1}{2^\\ell}\n= n \\log_2 n - n\\left(1 - \\frac{1}{2^m}\\right)\n= n \\log_2 n - (n - 1),\n$$\n因为 $2^m = n$。这是 $O(n \\log n)$ 级别的，并且与跨层级成对合并的经典上界相匹配，展示了当疾驰模式不触发时的最坏情况比较次数。\n\n实现遵循以下原则：\n- 对于 $n=2^m$，通过将索引 $i$ 映射到 $\\mathrm{rev}(i)$ 并相应地放置键值 $i+1$ 来构建位反转对抗序列。\n- 将每个元素视为长度为 $1$ 的运行段。\n- 使用一个合并例程迭代合并相邻的运行段，该例程计算键值比较次数，并在观察到 $g$ 次连续获胜时可选地进入疾驰模式。疾驰模式的实现对获胜方相对于落败方的当前枢轴元素执行指数搜索以定位上界，然后进行二分搜索以精炼结果，并复制数据块。比较计数包括这些搜索中使用的所有数据比较。在我们的对抗性输入中，对于 $g \\ge 2$，连续获胜计数器永远不会达到 $g$，因此疾驰模式从不触发，测得的比较次数等于 $C(n)$。\n- 对于边界情况 $n = 1$，没有合并操作，比较次数为 $0$，这与 $C(1) = 1 \\cdot \\log_2 1 - (1 - 1) = 0$ 相匹配。\n\n测试套件涵盖了：\n- $n \\in \\{32, 64, 128\\}$ 且 $g = 7$（一个典型的 Timsort 疾驰阈值）的一般情况，验证没有疾驰发生且比较次数恰好为 $C(n)$。\n- 一个边界情况 $n = 1$。\n- 一个小阈值情况 $g = 2$ 且 $n = 32$，以强调即使非常小的阈值在完美交替下也不会触发疾驰模式。\n- 一个附加案例 $n = 16, g = 4$。\n\n最终输出是一个单一的扁平列表，按顺序为每个案例包含三项：测量的总比较次数 $K(n, g)$，理论值 $C(n)$，以及指示是否使用了疾驰模式的布尔值。由于对抗性构造保证了交替性，该布尔值始终为 $\\mathrm{False}$，并且对于等于2的幂的 $n$，$K(n, g) = C(n)$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport math\n\ndef bit_reverse_indices(n: int) - list:\n    \"\"\"Return indices [0..n-1] in bit-reversal order for n being a power of two.\"\"\"\n    m = int(math.log2(n)) if n > 0 else 0\n    res = []\n    for i in range(n):\n        # reverse m bits of i\n        rev = 0\n        x = i\n        for _ in range(m):\n            rev = (rev  1) | (x  1)\n            x >>= 1\n        res.append(rev)\n    return res\n\ndef adversarial_sequence(n: int) - list:\n    \"\"\"Construct adversarial sequence of keys 1..n in bit-reversal order.\"\"\"\n    if n == 0:\n        return []\n    if n == 1:\n        return [1]\n    # Assume n is a power of two for exact alternation properties\n    idxs = bit_reverse_indices(n)\n    # Place key i+1 at position idxs[i]\n    arr = [None] * n\n    for i in range(n):\n        arr[idxs[i]] = i + 1\n    return arr\n\ndef gallop_upper_bound(arr, start, end, pivot):\n    \"\"\"\n    Find the first index pos in [start, end) such that arr[pos] > pivot.\n    Use exponential search then binary search. Count comparisons against pivot.\n    Returns (pos, comparisons_used).\n    \"\"\"\n    if start >= end:\n        return start, 0\n    comps = 0\n    # If the first element is greater than pivot, upper bound at start.\n    comps += 1\n    if arr[start] > pivot:\n        return start, comps\n    # Exponential search to find a bound where arr[pos] > pivot or end is reached.\n    step = 1\n    pos = start + step - 1\n    prev_pos = start\n    while pos  end and arr[pos] = pivot:\n        comps += 1\n        prev_pos = pos\n        step = 1\n        pos = start + step - 1\n\n    # Now we have range [low, high) where low is previous bound and high is min(end, pos+1)\n    low = prev_pos\n    high = min(end, pos + 1)\n    \n    # Binary search for first index > pivot\n    lo = low\n    hi = high\n    while lo  hi:\n        mid = (lo + hi) // 2\n        comps += 1\n        if arr[mid] = pivot:\n            lo = mid + 1\n        else:\n            hi = mid\n    return lo, comps\n\ndef merge_with_gallop(left, right, g_thresh):\n    \"\"\"\n    Merge two sorted lists with galloping optimization.\n    Count key comparisons only (data comparisons against array elements).\n    Return merged list, comparisons_count, gallop_entries_used.\n    \"\"\"\n    i, j = 0, 0\n    merged = []\n    comps = 0\n    gallops = 0\n    winL = 0\n    winR = 0\n    nL = len(left)\n    nR = len(right)\n\n    while i  nL and j  nR:\n        # Pairwise compare heads\n        comps += 1\n        if left[i] = right[j]:\n            merged.append(left[i])\n            i += 1\n            winL += 1\n            winR = 0\n            # Check gallop threshold for left\n            if winL >= g_thresh:\n                # Gallop in left against pivot = right[j]\n                pivot = right[j]\n                pos, gallop_comps = gallop_upper_bound(left, i, nL, pivot)\n                comps += gallop_comps\n                count = pos - i\n                if count > 0:\n                    # Copy block from left\n                    merged.extend(left[i:pos])\n                    i = pos\n                    gallops += 1\n                winL = 0\n                winR = 0\n        else:\n            merged.append(right[j])\n            j += 1\n            winR += 1\n            winL = 0\n            # Check gallop threshold for right\n            if winR >= g_thresh:\n                # Gallop in right against pivot = left[i]\n                pivot = left[i]\n                pos, gallop_comps = gallop_upper_bound(right, j, nR, pivot)\n                comps += gallop_comps\n                count = pos - j\n                if count > 0:\n                    merged.extend(right[j:pos])\n                    j = pos\n                    gallops += 1\n                winL = 0\n                winR = 0\n\n    # Copy remaining\n    if i  nL:\n        merged.extend(left[i:])\n    if j  nR:\n        merged.extend(right[j:])\n    return merged, comps, gallops\n\ndef timsort_like_with_gallop(arr, g_thresh):\n    \"\"\"\n    Bottom-up Timsort-like: start from runs of length 1, merge adjacent runs until one remains.\n    Returns total comparisons and total gallop entries.\n    \"\"\"\n    # Initialize runs as singletons\n    runs = [[x] for x in arr]\n    total_comps = 0\n    total_gallops = 0\n    if not runs or len(runs) == 1:\n        return 0, 0\n    \n    while len(runs) > 1:\n        new_runs = []\n        # Merge adjacent pairs\n        k = 0\n        while k  len(runs):\n            if k + 1  len(runs):\n                merged, comps, gallops = merge_with_gallop(runs[k], runs[k+1], g_thresh)\n                total_comps += comps\n                total_gallops += gallops\n                new_runs.append(merged)\n                k += 2\n            else:\n                # Odd run count: carry over the last run\n                new_runs.append(runs[k])\n                k += 1\n        runs = new_runs\n    return total_comps, total_gallops\n\ndef theoretical_comparisons(n: int) -> int:\n    \"\"\"Compute C(n) = n*log2(n) - (n - 1) for n power of two; for n=1, return 0.\"\"\"\n    if n = 1:\n        return 0\n    # The problem states n is a power of two\n    m = int(math.log2(n))\n    if (1  m) != n:\n        return -1 # Sentinel for non-power-of-two, though not expected\n    return n * m - (n - 1)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case is a tuple (n, g_thresh)\n    test_cases = [\n        (32, 7),   # Case 1\n        (64, 7),   # Case 2\n        (128, 7),  # Case 3\n        (1, 7),    # Boundary Case 4\n        (32, 2),   # Small-threshold Case 5\n        (16, 4),   # Additional Case 6\n    ]\n\n    results = []\n    for n, g in test_cases:\n        arr = adversarial_sequence(n)\n        comps, gallops = timsort_like_with_gallop(arr, g)\n        expected = theoretical_comparisons(n)\n        # Append flat triple: actual comparisons, expected comparisons, gallop_used boolean\n        results.append(comps)\n        results.append(expected)\n        results.append(bool(gallops > 0))\n\n    # Final print statement in the exact required format.\n    # The boolean False/True must be stringified as 'False'/'True' per typical Python behavior.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3203377"}]}