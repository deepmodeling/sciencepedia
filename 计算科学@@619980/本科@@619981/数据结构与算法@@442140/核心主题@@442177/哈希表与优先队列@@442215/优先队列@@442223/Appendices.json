{"hands_on_practices": [{"introduction": "Dijkstra 算法是图论中解决单源最短路径问题的经典方法，其核心思想是贪心地选择当前距离源点最近的未访问顶点进行扩展。优先队列是实现这一“贪心”策略的关键数据结构，它能够高效地找出并提供具有最小距离的顶点。在本练习 [@problem_id:3227995] 中，你将实现一个“懒惰”版本的 Dijkstra 算法，该版本通过在优先队列中允许重复项来避免复杂的 $\\text{decrease-key}$ 操作，这不仅是理解算法与数据结构之间紧密关系的绝佳实践，也展示了在现实编程中如何通过巧妙的设计来简化实现。", "problem": "给定一个带有非负边权的有向图。设图表示为 $G = (V, E)$，其权重函数为 $w : E \\to \\mathbb{R}_{\\ge 0}$。对于一个顶点 $s \\in V$，到顶点 $v \\in V$ 的单源最短路径距离定义为从 $s$ 到 $v$ 的所有有向路径中，路径上边的权重之和的最小值。如果从 $s$ 到 $v$ 不存在路径，则距离视为未定义。\n\n你的任务是编写一个完整的程序，该程序使用仅依赖于路径长度和权重非负性核心定义的设计，来计算从给定源点 $s$ 出发的单源最短路径距离。你的程序必须实现以下算法约束：使用一个允许重复条目且不提供或模拟“减小键”操作的最小优先队列（Priority Queue (PQ)）。也就是说，当发现到一个顶点的更短的暂定距离时，不是修改现有的优先队列条目，而是将一个新条目推入优先队列，并允许在弹出过时条目时对其进行惰性移除。\n\n形式上，程序必须：\n- 接受一个由其顶点数 $n$ 和一组有向边 $\\{(u, v, w)\\}$ 描述的图，其中 $u, v \\in \\{0, 1, \\dots, n-1\\}$ 且 $w \\in \\mathbb{Z}_{\\ge 0}$。\n- 仅使用优先队列的推入（push）和弹出（pop）操作，计算从源点 $s$ 到每个顶点 $v \\in \\{0, 1, \\dots, n-1\\}$ 的最短路径距离，允许重复的键且不使用任何减小优先队列内部键值的操作。\n- 对于每个测试用例，输出一个包含 $n$ 个整数的列表，其中第 $i$ 个条目是从 $s$ 到 $i$ 的最短路径距离，不可达的顶点编码为 $-1$。\n\n你必须依赖的基础仅限于以下事实：\n- 从顶点 $x$ 到顶点 $y$ 的路径是在 $G$ 中有效的边序列拼接，路径的长度是其边权重之和。\n- 所有边权重都满足 $w(e) \\ge 0$（对于每个 $e \\in E$）。\n- 对于任意顶点 $x, y, z \\in V$，如果从 $x$ 到 $y$ 的路径长度为 $\\ell(x, y)$，从 $y$ 到 $z$ 的路径长度为 $\\ell(y, z)$，那么拼接后从 $x$ 到 $z$ 的路径长度为 $\\ell(x, y) + \\ell(y, z)$。\n- 如果从优先队列中取出的一个顶点，其值严格大于当前已知的到该顶点的最短距离，那么该优先队列条目必定是过时的，必须被忽略。\n\n测试套件。你的程序必须解决以下七个测试用例。对于每个用例，图由一个整数 $n$、一个源点 $s$ 和一组写成三元组 $(u, v, w)$ 的有向边指定：\n\n- 测试用例1：$n = 5$, $s = 0$, 边 $\\{(0, 1, 2), (0, 2, 5), (1, 2, 1), (1, 3, 2), (2, 3, 1), (3, 4, 3)\\}$。\n- 测试用例2：$n = 3$, $s = 0$, 边 $\\{(0, 1, 0), (1, 2, 0), (0, 2, 5)\\}$。\n- 测试用例3：$n = 4$, $s = 0$, 边 $\\{(0, 1, 7)\\}$。\n- 测试用例4：$n = 1$, $s = 0$, 边 $\\{\\}$。\n- 测试用例5：$n = 3$, $s = 0$, 边 $\\{(0, 1, 10), (0, 1, 3), (1, 2, 4), (0, 2, 10)\\}$。\n- 测试用例6：$n = 6$, $s = 0$, 边 $\\{(0, 1, 1), (0, 2, 5), (0, 3, 10), (1, 2, 2), (1, 3, 4), (2, 3, 1), (1, 4, 7), (3, 4, 1), (4, 5, 2), (2, 5, 10)\\}$。\n- 测试用例7：$n = 4$, $s = 0$, 边 $\\{(0, 1, 1), (0, 2, 1), (1, 3, 1), (2, 3, 1)\\}$。\n\n测试套件中的所有边权重都是整数并满足非负性。\n\n最终输出格式。你的程序应该生成单行输出，包含所有结果聚合成的单个列表，其中每个元素是对应一个测试用例的距离列表，顺序与上文列出的一致。聚合结果必须打印为单个用方括号括起来的、无空格的逗号分隔列表。例如，如果有两个测试用例，其各自的结果是 $[0, 1]$ 和 $[0, 2]$，则最终输出将是 $[[0,1],[0,2]]$。在你的程序的最终输出中，使用 $-1$ 来表示不可达的顶点。本问题不涉及物理单位；所有量均为纯数字。", "solution": "用户提供了一个问题陈述，要求在带有非负边权的有向图中计算单源最短路径。核心约束是实现一个等价于 Dijkstra 算法的算法，该算法使用一个不支持 `decrease-key` 操作的最小优先队列，因此需要处理过时条目。\n\n### 步骤1：提取已知信息\n\n-   **图**：一个有向图 $G = (V, E)$，其中 $V = \\{0, 1, \\dots, n-1\\}$。\n-   **边权重**：一个函数 $w : E \\to \\mathbb{R}_{\\ge 0}$ 为每条边分配一个非负权重。对于测试用例，$w(e) \\in \\mathbb{Z}_{\\ge 0}$。\n-   **源顶点**：一个指定的顶点 $s \\in V$。\n-   **最短路径距离**：从 $s$ 到任意顶点 $v \\in V$ 的所有有向路径中，权重之和的最小值。不可达顶点的距离为未定义。\n-   **算法约束1**：实现必须使用一个仅支持 `push` 和 `pop` 操作的最小优先队列 (PQ)。\n-   **算法约束2**：禁止使用 `decrease-key` 操作。如果发现了到某个顶点的更短路径，必须将一个新条目 `(distance, vertex)` 推入优先队列，从而允许重复的顶点条目。\n-   **算法约束3**：必须惰性处理过时条目。如果从优先队列中弹出的条目 `(d, u)` 满足 $d$ 严格大于当前已知的到 $u$ 的最短距离，则该条目是过时的。必须忽略此类条目。\n-   **输出规格**：对于每个测试用例，输出必须是一个包含 $n$ 个整数的列表，表示从 $s$ 出发的最短距离。不可达顶点必须编码为 $-1$。最终输出是这些列表的聚合。\n-   **提供的基础事实**：\n    1.  从顶点 $x$ 到顶点 $y$ 的路径是在 $G$ 中有效的边序列拼接，路径的长度是其边权重之和。\n    2.  所有边权重都满足 $w(e) \\ge 0$（对于所有 $e \\in E$）。\n    3.  拼接路径的长度是其子路径长度之和的最优子结构属性：对于任意顶点 $x, y, z \\in V$，如果从 $x$ 到 $y$ 的路径长度为 $\\ell(x, y)$，从 $y$ 到 $z$ 的路径长度为 $\\ell(y, z)$，那么拼接后从 $x$ 到 $z$ 的路径长度为 $\\ell(x, y) + \\ell(y, z)$。\n    4.  识别和忽略优先队列中过时条目的具体规则。\n-   **测试套件**：\n    -   测试用例1：$n = 5$, $s = 0$, 边 $\\{(0, 1, 2), (0, 2, 5), (1, 2, 1), (1, 3, 2), (2, 3, 1), (3, 4, 3)\\}$。\n    -   测试用例2：$n = 3$, $s = 0$, 边 $\\{(0, 1, 0), (1, 2, 0), (0, 2, 5)\\}$。\n    -   测试用例3：$n = 4$, $s = 0$, 边 $\\{(0, 1, 7)\\}$。\n    -   测试用例4：$n = 1$, $s = 0$, 边 $\\{\\}$。\n    -   测试用例5：$n = 3$, $s = 0$, 边 $\\{(0, 1, 10), (0, 1, 3), (1, 2, 4), (0, 2, 10)\\}$。\n    -   测试用例6：$n = 6$, $s = 0$, 边 $\\{(0, 1, 1), (0, 2, 5), (0, 3, 10), (1, 2, 2), (1, 3, 4), (2, 3, 1), (1, 4, 7), (3, 4, 1), (4, 5, 2), (2, 5, 10)\\}$。\n    -   测试用例7：$n = 4$, $s = 0$, 边 $\\{(0, 1, 1), (0, 2, 1), (1, 3, 1), (2, 3, 1)\\}$。\n\n### 步骤2：使用提取的已知信息进行验证\n\n对问题进行严格验证。\n\n-   **科学上成立**：该问题描述了 Dijkstra 算法的一个标准变体。该算法在非负权重图上的正确性是图论和计算机科学的基石。所指定的实现细节——通过插入重复项并惰性丢弃过时条目来处理 `decrease-key` 操作的缺失——是一种行之有效且正确的技术。这在科学上和算法上都是合理的。\n-   **良构的**：该问题是良构的。对于给定的非负权重图和源顶点，单源最短路径距离集合是唯一确定的。算法的约束是精确的，会产生确定性的结果。\n-   **客观的**：问题使用形式化的数学符号和明确的术语陈述。它不含主观或基于观点的内容。\n-   **自洽且一致**：问题为每个测试用例提供了所有必要的数据（$n$、$s$ 和边集）。约束是明确的且不相互矛盾。所提供的基础事实是正确的，并与算法的基本原理一致。\n-   **可形式化且相关**：该问题直接是在指定主题内实现核心算法 Dijkstra 算法的任务。它非常适合形式化为程序。\n-   **完整且明确**：顶点和边的规格是完整的。输出格式有精确定义。诸如“最短路径距离”和“非负”等术语是标准且明确的。\n-   **非平凡的**：该问题并非平凡。它需要正确实现一个非平凡的算法，包括根据指定约束仔细管理优先队列的状态。\n\n### 步骤3：结论与行动\n\n问题陈述是**有效的**。它是在算法领域中一个定义明确、科学上合理的问题。我现在将着手构建解决方案。\n\n要实现的算法是 Dijkstra 算法的一个变体。设 $d[v]$ 为从源点 $s$到顶点 $v$ 的暂定最短距离。\n\n1.  **初始化**：初始化一个大小为 $n$ 的数组 $d$ 来存储最短路径估计值。我们设置 $d[s] = 0$，对于所有其他顶点 $v \\in V \\setminus \\{s\\}$，设置 $d[v] = \\infty$。值 $\\infty$ 表示尚未发现从 $s$ 到 $v$ 的路径。初始化一个最小优先队列 PQ。PQ 将存储 `(distance, vertex)` 形式的元组。我们首先将源顶点插入 PQ：`PQ.push((0, s))`。\n\n2.  **迭代处理**：算法通过从 PQ 中重复提取具有最小距离的顶点来进行。只要 PQ 不为空，我们就执行以下步骤：\n    a. 从 PQ 中提取具有最小 $dist_u$ 的条目 $(dist_u, u)$。\n    b. **过时条目检查**：这是问题约束所要求的关键步骤。我们将提取的距离 $dist_u$ 与当前已知的到 $u$ 的最短距离 $d[u]$ 进行比较。如果 $dist_u > d[u]$，这意味着我们已经找到了到 $u$ 的更短路径，并在之前的迭代中处理过它。因此，条目 $(dist_u, u)$ 是“过时的”，必须丢弃。然后我们继续循环的下一次迭代。\n    c. **顶点最终确定与松弛**：如果 $dist_u \\le d[u]$（由于算法的性质和过时检查，这必然是 $dist_u = d[u]$），这意味着我们已经找到了到 $u$ 的最短路径。边权的非负性确保了任何其他尚未发现的到 $u$ 的路径都必须经过当前在 PQ 中的某个其他顶点，而根据定义，该顶点的暂定距离大于或等于 $d[u]$。因此，不可能有更短的路径。然后我们“松弛”从 $u$ 出发的边。对于每个通过权重为 $w(u, v)$ 的边 $(u, v)$ 连接的 $u$ 的邻居 $v$，我们计算通过 $u$ 到达 $v$ 的新潜在距离：$d[u] + w(u, v)$。\n    d. **路径改进**：如果这条新路径比当前已知的到 $v$ 的路径更短（即，如果 $d[u] + w(u, v)  d[v]$），我们就找到了一个改进。我们更新距离数组：$d[v] = d[u] + w(u, v)$。关键的是，我们不执行对 PQ 中 $v$ 的 `decrease-key` 操作，而是简单地将新的、改进的条目 $(d[v], v)$ 插入到 PQ 中。这就是重复条目的来源。\n\n3.  **终止**：当 PQ 变为空时，循环终止。此时，对于每个顶点 $v$，$d[v]$ 的值是从 $s$到 $v$ 的最短路径长度。如果 $d[v]$ 仍然是 $\\infty$，这意味着 $v$ 从 $s$ 不可达。\n\n4.  **最终输出格式化**：处理最终的距离数组 $d$，将任何剩余的 $\\infty$ 值替换为 $-1$，以符合输出规范。然后将所有测试用例的结果聚合成所需的字符串格式。在实现方面，Python 的 `heapq` 模块是理想的最小优先队列，因为它天然地支持重复条目，并且没有 `decrease-key` 方法。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport heapq\n\ndef solve():\n    \"\"\"\n    Solves the single-source shortest path problem for a series of test cases\n    using a Dijkstra-like algorithm with a priority queue that allows duplicates\n    and has no decrease-key operation.\n    \"\"\"\n    \n    test_cases = [\n        {'n': 5, 's': 0, 'edges': [(0, 1, 2), (0, 2, 5), (1, 2, 1), (1, 3, 2), (2, 3, 1), (3, 4, 3)]},\n        {'n': 3, 's': 0, 'edges': [(0, 1, 0), (1, 2, 0), (0, 2, 5)]},\n        {'n': 4, 's': 0, 'edges': [(0, 1, 7)]},\n        {'n': 1, 's': 0, 'edges': []},\n        {'n': 3, 's': 0, 'edges': [(0, 1, 10), (0, 1, 3), (1, 2, 4), (0, 2, 10)]},\n        {'n': 6, 's': 0, 'edges': [(0, 1, 1), (0, 2, 5), (0, 3, 10), (1, 2, 2), (1, 3, 4), (2, 3, 1), (1, 4, 7), (3, 4, 1), (4, 5, 2), (2, 5, 10)]},\n        {'n': 4, 's': 0, 'edges': [(0, 1, 1), (0, 2, 1), (1, 3, 1), (2, 3, 1)]}\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        n = case['n']\n        s = case['s']\n        edges = case['edges']\n        \n        # Adjacency list representation of the graph\n        adj = [[] for _ in range(n)]\n        for u, v, w in edges:\n            adj[u].append((v, w))\n            \n        # Initialize distances: 0 for the source, infinity for all others.\n        # np.inf is used to represent infinite distance.\n        distances = np.full(n, np.inf)\n        distances[s] = 0\n        \n        # Min-priority queue storing tuples of (distance, vertex).\n        # We start with the source vertex.\n        pq = [(0, s)]\n        \n        while pq:\n            # Pop the vertex with the smallest tentative distance\n            dist_u, u = heapq.heappop(pq)\n            \n            # If the popped distance is greater than the known shortest distance,\n            # this is a stale entry. We ignore it and proceed.\n            if dist_u  distances[u]:\n                continue\n            \n            # Relax edges for the current vertex u\n            for v, weight in adj[u]:\n                # If we found a shorter path to v through u\n                if distances[u] + weight  distances[v]:\n                    # Update the distance to v\n                    distances[v] = distances[u] + weight\n                    # Push the new, better path information to the priority queue.\n                    # This may create duplicate entries for vertex v, as required.\n                    heapq.heappush(pq, (distances[v], v))\n                    \n        # Prepare the final result list for this test case.\n        # Replace np.inf with -1 for unreachable vertices.\n        # Convert all distances to integers.\n        result = [int(d) if d != np.inf else -1 for d in distances]\n        all_results.append(result)\n\n    # Format the final output string as specified in the problem.\n    # e.g., [[0,1,2],[0,-1]]\n    str_results = []\n    for res in all_results:\n        str_results.append(f\"[{','.join(map(str, res))}]\")\n    \n    final_output_string = f\"[{','.join(str_results)}]\"\n    \n    print(final_output_string)\n\nsolve()\n```", "id": "3227995"}, {"introduction": "虽然“懒惰”版 Dijkstra 算法实现简单，但在某些场景下，我们可以通过更强大的数据结构来追求极致的性能。这就引出了索引优先队列（Indexed Priority Queue, IPQ）的概念，它允许我们高效地修改队列中已有元素（例如，执行 $\\text{decrease-key}$ 操作）。本练习 [@problem_id:3261051] 将引导你深入探索高性能优先队列的内部机制，通过实现一个支持句柄操作的 IPQ，你将掌握优化版 Dijkstra 或 Prim 等经典算法所需的关键技术。", "problem": "设计并实现一个索引优先队列（Indexed Priority Queue, IPQ），该队列使用二叉堆实现，并支持 $insert$、$decrease\\text{-}key$（通过句柄）、$delete$（通过句柄）以及 $extract\\text{-}min$ 操作。提出一种稳健的句柄方案，并严格证明所有操作的最坏情况时间复杂度为 $O(\\log n)$，其中 $n$ 是 IPQ 中当前的元素数量。IPQ 必须在键上维护堆序不变性，并使用基于数组的完全二叉树表示来确保形状不变性。为了在存在相等键时行为确定，必须使用不可变标识符来打破平局。\n\n用于推导和设计的基础理论：\n- 二叉堆是一个在键上满足堆序属性的完全二叉树。\n- 一个大小为 $n$、由数组支持的完全二叉树，其高度 $h = \\lfloor \\log_2 n \\rfloor$，且从任一节点到根或到叶的任何路径长度至多为 $h$。\n- 上浮（bubble-up，也称为 sift-up）通过与父节点反复比较并在违反堆序属性时进行交换来向上调整节点；下沉（bubble-down，也称为 sift-down）通过与最小子节点反复比较并在违反堆序属性时进行交换来向下调整节点。\n\n句柄方案要求：\n- $insert$ 操作返回的句柄必须是一个稳健的令牌，在该特定元素的生命周期内保持有效，并在该元素被 $delete$ 后立即失效。\n- 句柄必须能防止“ABA问题”，即一个过期的句柄可能会意外地引用一个重用了内部标识符的新插入元素。\n- 任何使用过期或无效句柄的操作都必须被拒绝，且不得修改 IPQ。\n\n操作语义：\n- $insert(k)$ 插入一个键 $k$，并为插入的元素返回一个句柄 $h$。\n- $decrease\\text{-}key(h, k')$ 将与句柄 $h$ 关联的键减小为新键 $k'$，前提条件是 $k'  k$；如果句柄无效或前提条件不满足，则必须拒绝该操作。\n- $delete(h)$ 删除与句柄 $h$ 关联的元素；如果句柄无效，则必须拒绝该操作。\n- $extract\\text{-}min()$ 移除并返回 IPQ 中当前的最小键。\n\n验证与复杂度论证：\n- 你必须实现一个检测工具，用以记录在每次操作中由上浮或下沉执行的堆索引移动次数。一次索引移动定义为在堆数组中将元素从索引 $i$ 重新定位到不同索引 $j$ 的任何交换操作。使用此检测工具报告下文指定的各测试用例的摘要值。此检测工具仅用于报告；它不得改变所实现操作的渐近复杂度。\n\n待实现的稳健句柄方案：\n- 每个元素都有一个在插入时分配且永不为其他元素重用的不可变标识符 $i \\in \\mathbb{N}$。\n- 为每个标识符维护一个代数计数器 $g_i \\in \\mathbb{N}$。元素当前的有效句柄是插入时的配对 $(i, g_i)$。当元素被删除时，将 $g_i$ 增加 1，这会使先前为该标识符发出的任何句柄失效。有效性检查必须确保，仅当 $g = g_i$ 且标识符 $i$ 当前存在于堆中（即，有映射的位置）时，提交的句柄 $(i, g)$ 才被接受。\n- 此 $(i, g_i)$ 方案必须在 $decrease\\text{-}key$ 和 $delete$ 中使用，以确保对过期句柄的稳健性。\n\n测试套件及所需输出：\n- 测试用例 1（一般情况）：按顺序插入键 $A_1 = [\\,7,\\,3,\\,5,\\,2,\\,9,\\,1,\\,4\\,]$，并按相同顺序收集返回的句柄。然后对第三次插入（原始键为 $5$）对应的句柄执行 $decrease\\text{-}key$ 操作，将键更新为新键 $0$。接着对第一次插入（原始键为 $7$）对应的句柄执行 $delete$ 操作。最后，重复调用 $extract\\text{-}min$ 直到 IPQ 为空，并记录提取的键列表。此测试的预期输出是经过这些操作后，按升序排列的已提取键的整数列表。\n- 测试用例 2（高度限制压力测试）：按顺序插入键 $A_2 = [\\,10,\\,8,\\,6,\\,4,\\,2\\,]$。对最后一次插入（原始键为 $2$）对应的句柄执行 $decrease\\text{-}key$ 操作，将键更新为新键 $-100$。然后对第二次插入（原始键为 $8$）对应的句柄执行 $delete$ 操作。在此测试期间，记录此测试用例中所有操作的任何单次上浮或下沉所造成的最大堆索引移动次数。此测试的预期输出是等于此最大值的单个整数。\n- 测试用例 3（过期句柄与重复减小键值）：插入单个键 $A_3 = [\\,50\\,]$ 并捕获句柄 $h_0$。执行 $decrease\\text{-}key(h_0, 20)$，然后是 $decrease\\text{-}key(h_0, 10)$，再然后是 $decrease\\text{-}key(h_0, 5)$。接着执行 $delete(h_0)$。最后，尝试执行 $decrease\\text{-}key(h_0, 1)$ 并记录操作是否因句柄过期而被拒绝。此测试的预期输出是一个布尔值，指示过期的句柄是否被正确拒绝。\n\n最终输出格式：\n- 你的程序应产生单行输出，其中包含一个由方括号括起来的逗号分隔列表形式的结果，具体为 $[R_1, R_2, R_3]$，其中 $R_1$ 是测试用例 1 的列表，$R_2$ 是测试用例 2 的整数，$R_3$ 是测试用例 3 的布尔值。\n- 程序必须是自包含的，不需任何输入，并且仅使用 Python 标准库和版本为 $1.23.5$ 的 Numerical Python (NumPy) 库，在 Python $3.12$ 版本下运行。\n\n科学真实性与约束：\n- 所有键都是整数，所有操作必须遵循所述语义。\n- 复杂度声明必须从完全二叉树的性质和堆序不变性出发进行论证，从上面给出的基础理论开始，不得依赖未经证实的捷径或外部引用。", "solution": "稳健的索引优先队列（IPQ）的设计和实现必须基于二叉堆的既定原则，并辅以支持高效索引操作的数据结构进行增强。我们将通过组合一个二叉堆、用于位置跟踪的辅助映射以及用于稳健句柄管理的基于代数的方案来构建 IPQ。\n\n### 数据结构\n\nIPQ 通过四个主要组件实现：\n\n1.  **堆数组, $\\mathcal{H}$**：一个表示完全二叉树的动态数组。为方便代数运算，我们使用基于 1 的索引，其中索引为 $j  0$ 的元素的父节点位于索引 $\\lfloor j/2 \\rfloor$，其子节点位于索引 $2j$ 和 $2j+1$。$\\mathcal{H}$ 中的每个条目都是一个元组 $(k, i)$，其中 $k$ 是优先级键（一个整数），$i$ 是一个来自 $\\mathbb{N}$ 的唯一的、不可变的标识符。堆序属性在这些元组上维护，其中，如果 $k_1  k_2$，或者如果 $k_1 = k_2$ 且 $i_1  i_2$，则 $(k_1, i_1)  (k_2, i_2)$。这建立了一个确定性的全序关系。\n\n2.  **位置映射, $\\mathcal{P}$**：一个哈希映射，提供了元素标识符与其在堆中位置之间的双向链接。它将标识符 $i$ 映射到其在 $\\mathcal{H}$ 中的当前索引 $j$，即 $\\mathcal{P}[i] = j$。这个结构对于为 $decrease\\text{-}key$ 和 $delete$ 操作实现 $O(1)$ 时间访问至关重要。\n\n3.  **代数映射, $\\mathcal{G}$**：一个哈希映射，用于存储曾被插入到 IPQ 中的每个标识符的当前代数计数器。它将标识符 $i$ 映射到其代数 $g_i \\in \\mathbb{N}$，即 $\\mathcal{G}[i] = g_i$。\n\n4.  **标识符计数器, $N_{id}$**：一个单调递增的整数计数器，用于为新元素分发新的、唯一的标识符，确保没有标识符被重用。\n\n### 稳健的句柄方案\n\n句柄 $h$ 提供了对 IPQ 内部元素的一个外部引用。为确保对过期句柄（例如“ABA 问题”）意外误用的稳健性，句柄被定义为一个配对 $h = (i, g)$，其中 $i$ 是元素的唯一标识符，$g$ 是在句柄签发时刻（即插入时）该标识符的代数计数。\n\n仅当同时满足以下两个条件时，使用句柄 $h=(i, g)$ 调用的操作才被视为有效：\n- 标识符 $i$ 存在于位置映射 $\\mathcal{P}$ 中，意味着该元素当前在堆中。\n- 句柄中提供的代数 $g$ 与代数映射 $\\mathcal{G}$ 中存储的当前代数 $g_i$ 相匹配。\n\n当一个带有标识符 $i$ 的元素从堆中被移除时（通过 $delete$ 或 $extract\\text{-}min$），它在 $\\mathcal{P}$ 中的条目被移除，并且其代数计数器 $\\mathcal{G}[i]$ 会增加。这一双重操作会立即让所有先前为该元素签发的句柄失效，因为它们现在将无法满足其中一个或两个有效性条件。任何后续试图使用过期句柄 $(i, g)$ 的操作都将被拒绝。\n\n### 算法设计与复杂度分析\n\n所有操作都必须维护堆的不变性：形状属性（堆是一个完全二叉树）和堆序属性。形状属性通过只在数组末尾添加/移除元素来维护。堆序属性则使用两个基本过程 $bubble\\text{-}up$ 和 $bubble\\text{-}down$ 来恢复，每个过程都沿着堆中的一条路径操作。由于堆是一个大小为 $n$ 的完全二叉树，其高度为 $h_{heap} = \\lfloor \\log_2 n \\rfloor$。因此，这两个恢复过程的复杂度受树的高度限制，从而实现 $O(\\log n)$ 的性能。\n\n**$insert(k)$**\n1.  从 $N_{id}$ 中获取一个新的唯一标识符 $i$，然后 $N_{id}$ 递增。\n2.  记录元素的初始代数：$\\mathcal{G}[i] \\leftarrow 0$。创建一个句柄 $h = (i, 0)$。\n3.  将新元素 $(k, i)$ 附加到堆数组 $\\mathcal{H}$ 的末尾，位于索引 $j=n+1$。\n4.  更新位置映射：$\\mathcal{P}[i] \\leftarrow j$。\n5.  调用 $bubble\\text{-}up(j)$ 过程，将元素在树中上移，直到恢复堆序属性。这最多涉及 $\\lfloor \\log_2 n \\rfloor$ 次比较和交换。\n6.  返回句柄 $h$。\n**复杂度**：步骤 1-4 是 $O(1)$ 的。步骤 5，$bubble\\text{-}up$ 的最坏情况复杂度为 $O(\\log n)$。因此，$insert$ 的复杂度是 $O(\\log n)$。\n\n**$extract\\text{-}min()$**\n1.  确定堆顶（$\\mathcal{H}[1]$）的最小元素 $(k_{min}, i_{min})$。\n2.  将堆中最后一个元素（位于索引 $n$ 的 $(k_{last}, i_{last})$）移动到堆顶：$\\mathcal{H}[1] \\leftarrow (k_{last}, i_{last})$。\n3.  更新被移动元素的位置映射：$\\mathcal{P}[i_{last}] \\leftarrow 1$。\n4.  堆大小递减，实际上移除了旧的最后一个元素的位置。\n5.  从位置映射 $\\mathcal{P}$ 中移除被提取元素的标识符 $i_{min}$，并增加其在 $\\mathcal{G}$ 中的代数：$\\mathcal{G}[i_{min}] \\leftarrow \\mathcal{G}[i_{min}] + 1$。\n6.  调用 $bubble\\text{-}down(1)$ 过程，将现在位于堆顶的元素下移至其正确位置，以恢复堆序属性。这最多涉及 $O(\\log n)$ 次比较和交换。\n7.  返回键 $k_{min}$。\n**复杂度**：除 $bubble\\text{-}down$ 是 $O(\\log n)$ 外，所有步骤都是 $O(1)$ 的。因此，$extract\\text{-}min$ 的复杂度是 $O(\\log n)$。\n\n**$decrease\\text{-}key(h, k')$**\n1.  如前所述验证句柄 $h=(i, g)$。若无效，则拒绝操作。\n2.  在 $O(1)$ 时间内从 $\\mathcal{P}[i]$ 中检索元素的当前位置 $j$。\n3.  验证前提条件 $k'  \\mathcal{H}[j].\\text{key}$。若不满足，则拒绝操作。\n4.  将 $\\mathcal{H}[j]$ 处元素的键更新为 $k'$。\n5.  由于键已减小，可能违反了元素与其父节点之间的堆序属性。调用 $bubble\\text{-}up(j)$ 过程来恢复不变性。\n**复杂度**：句柄验证、位置查找和键更新是 $O(1)$ 的。主要成本是 $bubble\\text{-}up$，其复杂度为 $O(\\log n)$。\n\n**$delete(h)$**\n1.  验证句柄 $h=(i, g)$。若无效，则拒绝操作。\n2.  在 $O(1)$ 时间内从 $\\mathcal{P}[i]$ 中检索元素的当前位置 $j$。\n3.  将被删除的位于索引 $j$ 的元素与堆中最后一个位于索引 $n$ 的元素交换。为换入的元素更新位置映射 $\\mathcal{P}$。\n4.  堆大小递减。从 $\\mathcal{P}$ 中移除标识符 $i$ 的条目，并增加其代数 $\\mathcal{G}[i]$。\n5.  从索引 $n$ 移动到索引 $j$ 的元素可能违反堆序属性。我们将其与父节点比较。如果它小于其父节点，则执行 $bubble\\text{-}up(j)$。否则，执行 $bubble\\text{-}down(j)$。这两个过程中只有一个会执行任何工作。\n**复杂度**：除最后的堆恢复步骤外，所有步骤都是 $O(1)$ 的。$bubble\\text{-}up$ 和 $bubble\\text{-}down$ 的复杂度都是 $O(\\log n)$，因此 $delete$ 的复杂度是 $O(\\log n)$。\n\n**检测工具**\n为满足验证要求，我们为每个高层操作维护一个计数器。每当在堆数组 $\\mathcal{H}$ 中交换两个元素时，该计数器就增加 1。在给定测试用例中，所有操作中观察到的最大计数值被记录下来。这个检测工具为交换操作增加了常数开销，但不会改变渐近复杂度。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Indexed Priority Queue problem by implementing the required class\n    and running the specified test cases.\n    \"\"\"\n\n    class IndexedPriorityQueue:\n        \"\"\"\n        An Indexed Priority Queue (IPQ) implemented with a binary heap.\n\n        This IPQ supports insert, extract-min, decrease-key by handle, and\n        delete by handle, all in O(log n) time. It uses a robust handle\n        scheme based on unique identifiers and generation counters to prevent\n        issues with stale handles.\n\n        The heap is 1-indexed for simpler parent/child arithmetic.\n        - parent(i) = i // 2\n        - left_child(i) = 2 * i\n        - right_child(i) = 2 * i + 1\n        \"\"\"\n\n        def __init__(self):\n            # self.heap stores tuples of (key, identifier).\n            # Index 0 is a placeholder to enable 1-based indexing.\n            self.heap = [None]\n            # self.pos maps an identifier to its index in the heap array.\n            self.pos = {}\n            # self.gen maps an identifier to its generation counter.\n            self.gen = {}\n            # self.next_id is a counter for assigning new unique identifiers.\n            self.next_id = 0\n            # Instrumentation: tracks max movements for any single operation.\n            self.max_movements_per_op = 0\n            self._current_op_movements = 0\n\n        def is_empty(self):\n            return len(self.heap) == 1\n\n        def _swap(self, i, j):\n            \"\"\"Swaps elements at heap indices i and j, updating position map.\"\"\"\n            h = self.heap\n            p = self.pos\n            h[i], h[j] = h[j], h[i]\n            p[h[i][1]] = i\n            p[h[j][1]] = j\n            self._current_op_movements += 1\n\n        def _compare(self, i, j):\n            \"\"\"\n            Compares elements at heap indices i and j.\n            Uses (key, identifier) for deterministic tie-breaking.\n            Returns True if element at i is smaller than element at j.\n            \"\"\"\n            return self.heap[i]  self.heap[j]\n\n        def _bubble_up(self, i):\n            \"\"\"Restores heap property by moving element at index i up.\"\"\"\n            parent = i // 2\n            while i  1 and self._compare(i, parent):\n                self._swap(i, parent)\n                i = parent\n                parent = i // 2\n\n        def _bubble_down(self, i):\n            \"\"\"Restores heap property by moving element at index i down.\"\"\"\n            size = len(self.heap)\n            while 2 * i  size:\n                left = 2 * i\n                right = 2 * i + 1\n                smallest = left\n                if right  size and self._compare(right, left):\n                    smallest = right\n                \n                if self._compare(smallest, i):\n                    self._swap(i, smallest)\n                    i = smallest\n                else:\n                    break\n\n        def _start_op(self):\n            \"\"\"Resets the movement counter for a new operation.\"\"\"\n            self._current_op_movements = 0\n\n        def _end_op(self):\n            \"\"\"Updates the max movement counter at the end of an operation.\"\"\"\n            self.max_movements_per_op = max(self.max_movements_per_op, self._current_op_movements)\n\n        def _validate_handle(self, handle):\n            \"\"\"Validates a handle (identifier, generation).\"\"\"\n            identifier, generation = handle\n            return identifier in self.pos and self.gen.get(identifier) == generation\n\n        def insert(self, key):\n            \"\"\"\n            Inserts a key, returns a robust handle. Complexity: O(log n).\n            \"\"\"\n            self._start_op()\n            identifier = self.next_id\n            self.next_id += 1\n            \n            # This is the first time we see this identifier\n            self.gen[identifier] = 0\n            handle = (identifier, self.gen[identifier])\n\n            self.heap.append((key, identifier))\n            new_pos = len(self.heap) - 1\n            self.pos[identifier] = new_pos\n            \n            self._bubble_up(new_pos)\n            self._end_op()\n            return handle\n\n        def extract_min(self):\n            \"\"\"\n            Removes and returns the minimum key. Complexity: O(log n).\n            \"\"\"\n            if self.is_empty():\n                raise IndexError(\"extract_min from an empty priority queue\")\n            \n            self._start_op()\n            min_key, min_id = self.heap[1]\n            last_item = self.heap.pop()\n            \n            if not self.is_empty():\n                self.heap[1] = last_item\n                self.pos[last_item[1]] = 1\n                self._bubble_down(1)\n            \n            del self.pos[min_id]\n            self.gen[min_id] += 1\n            \n            self._end_op()\n            return min_key\n\n        def decrease_key(self, handle, new_key):\n            \"\"\"\n            Decreases the key of an element specified by a handle.\n            Complexity: O(log n). Returns True on success, False on failure.\n            \"\"\"\n            if not self._validate_handle(handle):\n                return False\n\n            self._start_op()\n            identifier, _ = handle\n            current_pos = self.pos[identifier]\n            current_key, _ = self.heap[current_pos]\n\n            if new_key = current_key:\n                # Precondition k'  k failed, do not count movements\n                self._current_op_movements = 0\n                self._end_op() \n                return False\n\n            self.heap[current_pos] = (new_key, identifier)\n            self._bubble_up(current_pos)\n            self._end_op()\n            return True\n\n        def delete(self, handle):\n            \"\"\"\n            Deletes an element specified by a handle. Complexity: O(log n).\n            Returns True on success, False on failure.\n            \"\"\"\n            if not self._validate_handle(handle):\n                return False\n\n            self._start_op()\n            identifier, _ = handle\n            pos_to_delete = self.pos[identifier]\n            \n            # Swap with the last element\n            last_pos = len(self.heap) - 1\n            self._swap(pos_to_delete, last_pos) # This counts as 1 movement\n            \n            # Pop the target element (which is now at the end)\n            deleted_key, deleted_id = self.heap.pop()\n            del self.pos[deleted_id]\n            self.gen[deleted_id] += 1\n\n            # If the heap is now empty or we deleted the last element, we are done.\n            if not self.is_empty() and pos_to_delete = len(self.heap) - 1:\n                # The swapped-in element might need to be moved up or down.\n                # A bubble_up will only occur if the element is smaller than its parent.\n                # Otherwise, a bubble_down might be needed.\n                item_key, _ = self.heap[pos_to_delete]\n                parent_pos = pos_to_delete // 2\n\n                # If it's not the root and smaller than its parent, bubble up.\n                if parent_pos  0 and self._compare(pos_to_delete, parent_pos):\n                    self._bubble_up(pos_to_delete)\n                else: # Otherwise, it might need to bubble down.\n                    self._bubble_down(pos_to_delete)\n\n            self._end_op()\n            return True\n\n    results = []\n\n    # --- Test Case 1 ---\n    ipq1 = IndexedPriorityQueue()\n    handles1 = []\n    keys1 = [7, 3, 5, 2, 9, 1, 4]\n    for k in keys1:\n        handles1.append(ipq1.insert(k))\n\n    ipq1.decrease_key(handles1[2], 0)  # Decrease key of 5 to 0\n    ipq1.delete(handles1[0])          # Delete key 7\n    \n    extracted_keys = []\n    while not ipq1.is_empty():\n        extracted_keys.append(ipq1.extract_min())\n    results.append(extracted_keys)\n\n    # --- Test Case 2 ---\n    ipq2 = IndexedPriorityQueue()\n    handles2 = []\n    keys2 = [10, 8, 6, 4, 2]\n    for k in keys2:\n        handles2.append(ipq2.insert(k))\n    \n    ipq2.decrease_key(handles2[4], -100) # Decrease key of 2 to -100\n    ipq2.delete(handles2[1])           # Delete key 8\n\n    results.append(ipq2.max_movements_per_op)\n\n    # --- Test Case 3 ---\n    ipq3 = IndexedPriorityQueue()\n    h0 = ipq3.insert(50)\n    ipq3.decrease_key(h0, 20)\n    ipq3.decrease_key(h0, 10)\n    ipq3.decrease_key(h0, 5)\n    ipq3.delete(h0)\n    \n    # Attempt to use the stale handle, expecting rejection.\n    # decrease_key returns False on rejection.\n    is_rejected = not ipq3.decrease_key(h0, 1)\n    results.append(is_rejected)\n\n    # Final print statement in the exact required format.\n    # We need to manually format the list R1 to avoid spaces.\n    r1_str = f\"[{','.join(map(str, results[0]))}]\"\n    print(f\"[{r1_str},{results[1]},{str(results[2]).lower()}]\")\n\nsolve()\n```", "id": "3261051"}, {"introduction": "为了展示优先队列的广泛适用性，我们将目光转向一个全新的应用领域：数据压缩。Huffman 编码是无损数据压缩中的一个基本算法，其核心步骤是反复合并当前出现频率最低的两个符号，直至构建成一棵最优前缀码树。这个“找出并合并最小”的过程，正是优先队列的用武之地。在本练习 [@problem_id:3261138] 中，你将把优先队列作为一个核心引擎，在一个复杂的迭代算法中加以应用，从而将数据结构的知识与信息论领域建立起具体联系。", "problem": "您必须设计并实现一个完整的、可运行的程序，该程序使用一个基于优先队列（priority queue, PQ）构建的在线（动态）Huffman 编码方案，来计算编码几个给定符号序列所需的总比特数。符号的概率不是预先已知的；它们是从至今已看到的序列中增量学习的。程序应输出一行，其中包含每个测试序列的总比特长度，格式如下文所述。\n\n使用的基本原理和定义：\n- 优先队列是一种抽象数据类型，支持在亚线性时间内移除拥有最小（或最大）键的元素。您可以假设其为二叉堆实现，并具有标准操作，其中移除最小键的时间与 $O(\\log n)$ 成正比。\n- 前缀码是一种编码方式，其中没有任何码字是另一个码字的前缀。\n- 经典 Huffman 算法通过重复合并两个权重最小的节点，为一组具有固定非负权重的符号构建最优前缀码；这可以用优先队列来实现。\n\n需要实现的动态编码模型：\n- 字母表与原始成本：符号为字节（值在 $0$ 到 $255$ 之间）。当编码一个之前未见过的符号时，必须在一个转义符号（如下文所述）之后，立即以 8 比特的原始形式发出该符号。\n- 转义机制：维护一个专用的转义符号 $\\mathsf{ESC}$。在任何步骤，只要至今为止的序列中还存在至少一个尚未观察到的字节值，就将 $\\mathsf{ESC}$ 以固定权重 $1$ 包含在 Huffman 模型中。如果所有 $256$ 个字节值都已被观察到，则省略 $\\mathsf{ESC}$。\n- 建模与更新规则：\n  1. 在编码下一个符号 $x$ 之前，使用一个由所有先前见过的符号及其当前频率（权重）组成的多重集来构建一个 Huffman 编码，并根据前一项的规定，在适用时包含权重为 $1$ 的 $\\mathsf{ESC}$。\n  2. 编码：\n     - 如果 $x$ 之前已被观察到，则发出其当前的 Huffman 码字。成本（以比特为单位）是 $x$ 在当前 Huffman 树中的码字长度。\n     - 如果 $x$ 之前未被观察到，则发出 $\\mathsf{ESC}$ 的当前 Huffman 码字，然后以 8 比特的原始形式发出 $x$。此事件的总成本是 $\\mathsf{ESC}$ 的码字长度加上 8。\n  3. 发出 $x$ 后，通过将 $x$ 的频率增加 $1$ 来更新模型（如果 $x$ 是未见过的，其频率现在为 $1$）。每当 $\\mathsf{ESC}$ 存在时，其权重始终保持为 $1$。\n- Huffman 构建细节：\n  - 使用一个以 $(w, o)$ 为键的优先队列，其中 $w$ 是节点权重，$o$ 是一个确定性的决胜顺序值。\n  - 对于所有对应字节值的叶节点，将其决胜顺序值设置为该字节值（一个在 $[0,255]$ 范围内的整数）。对于 $\\mathsf{ESC}$，将其决胜顺序值设置为 $256$。\n  - 对于在 Huffman 合并过程中创建的内部节点，按照节点创建的顺序，从 $257$ 开始为其分配严格递增的决胜顺序值。\n  - 当 Huffman 森林中只有一个节点时（例如，在最开始只有 $\\mathsf{ESC}$ 存在时），将该唯一节点的码字长度定义为 $1$ 比特。在其他情况下，码字长度是最终树中叶节点的深度，其中根节点深度为 $0$。\n\n计算目标：\n- 对于每个提供的测试序列，计算在从左到右编码序列时，由上述过程产生的总比特数。在编码每个符号之前，需要使用优先队列从头开始重建 Huffman 树。\n\n测试套件：\n- 精确使用以下字节序列，每个序列以 ASCII 字符串形式给出：\n  1. \"ABC\"\n  2. \"AAAAA\"\n  3. \"ABABA\"\n\n输出要求：\n- 对于每个序列，以整数形式输出总比特数。\n- 您的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表（例如，`[result1,result2,result3]`）。\n\n所有计算都是无单位的比特计数，不涉及物理单位。在给定上述规则和指定的决胜策略的情况下，输出必须是确定性的。您的实现必须如前所述，在每一步都使用优先队列来构建 Huffman 树。算法的任何部分都不允许有随机性。最终输出格式必须严格符合规范，并且必须按给定顺序包含测试套件的结果。", "solution": "该问题要求实现一种动态 Huffman 编码算法，以计算编码若干字节序列的总比特成本。此特定算法的关键特征是，Huffman 树不是增量更新的，而是在编码每个符号之前从头开始重建。解决方案可以分解为对输入流中每个符号执行的一系列操作。\n\n编码器的状态随时间演变，必须进行维护。该状态包括：\n1.  一个频率图，用于存储至今为止遇到的每个符号的计数。我们将符号 $x$ 的频率表示为 $f(x)$。\n2.  一个至今已见过的唯一符号集合。该集合用于确定是否应将转义符号 $\\mathsf{ESC}$ 包含在模型中。\n\n整个过程是对输入序列的符号进行循环。对于步骤 $i$ 中的每个符号 $s_i$：\n\n步骤 1：模型构建\n在编码 $s_i$ 之前，我们构建一个信源模型。该模型是节点的集合，每个节点代表一个要包含在 Huffman 树中的符号。\n- 对于每个先前已见过的符号 $x$（即其频率 $f(x)  0$），会创建一个权重 $w$ 等于其频率 $f(x)$ 的叶节点。问题规定了确定性的决胜规则，因此每个节点都与一个键对 $(w, o)$ 相关联，其中 $o$ 是决胜值。对于符号节点，$o$ 是其字节值（一个在 $[0, 255]$ 范围内的整数）。\n- 如果所有 $256$ 个可能的字节值集合尚未被用尽，模型中会包含一个特殊的转义符号 $\\mathsf{ESC}$。$\\mathsf{ESC}$ 节点总是被赋予固定权重 $w=1$ 和决胜值 $o=256$。\n\n步骤 2：Huffman 树生成\n利用模型中的节点集合，使用优先队列（最小堆）构建一棵 Huffman 树。\n- 模型中的所有节点都被插入到优先队列中。节点的优先级由其 $(w, o)$ 键对确定，采用字典序比较。\n- 通过重复执行以下合并操作来构建树，直到队列中只剩下一个节点（根节点）：\n    1. 提取出两个优先级最低的节点，记为 $N_1$ 和 $N_2$。\n    2. 创建一个新的内部父节点 $N_p$。其权重是其子节点权重之和，$w_p = w_1 + w_2$。其决胜值 $o_p$ 从一个计数器分配，该计数器从 $257$ 开始，在构建单棵树的过程中每创建一个内部节点就递增一次。\n    3. 将新的父节点 $N_p$ 插回优先队列。\n- 如定义所述，如果模型只包含单个节点（例如，在最开始时只有 $\\mathsf{ESC}$ 节点存在），则会出现一种特殊情况。在这种情况下，其码字长度被定义为 $1$ 比特。\n\n步骤 3：码字长度计算\n任何符号的 Huffman 码字长度等于其在树中对应叶节点的深度（根节点深度为 $0$）。树构建完成后，会遍历树以计算每个叶节点的深度，并将这些长度存储起来用于编码步骤。\n\n步骤 4：编码与成本累积\n编码当前符号 $s_i$ 的比特成本按如下方式确定：\n- 如果 $s_i$ 是一个先前已见过的符号（即它在模型中且 $f(s_i)0$），则成本就是其码字长度 $L(s_i)$，该长度在上一步中获得。\n- 如果 $s_i$ 是一个新符号，则使用转义机制对其进行编码。成本是 $\\mathsf{ESC}$ 符号的码字长度，外加用于传输 $s_i$ 原始字节值的 8 比特。此事件的总成本为 $L(\\mathsf{ESC}) + 8$。\n此成本被加到整个序列的累计总成本中。\n\n步骤 5：状态更新\n编码 $s_i$ 后，更新频率图。频率 $f(s_i)$ 增加 $1$。如果 $s_i$ 是一个新符号，其频率被初始化为 $1$，并被添加到已见符号的集合中。\n\n对输入序列中的每个符号重复此五步过程。最终的累积总和代表了根据指定的动态 Huffman 编码方案编码该序列所需的总比特数。然后对每个提供的测试用例重复整个过程。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport heapq\n\nclass HuffmanNode:\n    \"\"\"Represents a node in the Huffman tree.\"\"\"\n    def __init__(self, weight, tie_breaker, symbol=None, left=None, right=None):\n        \"\"\"\n        Initializes a Huffman node.\n        \n        Args:\n            weight (int): The weight of the node (frequency).\n            tie_breaker (int): A value for deterministic sorting.\n            symbol (int, optional): The symbol represented by this node (byte value or ESC).\n                                   None for internal nodes.\n            left (HuffmanNode, optional): The left child.\n            right (HuffmanNode, optional): The right child.\n        \"\"\"\n        self.weight = weight\n        self.tie_breaker = tie_breaker\n        self.symbol = symbol\n        self.left = left\n        self.right = right\n\n    def __lt__(self, other):\n        \"\"\"\n        Comparison for priority queue ordering.\n        Nodes are compared first by weight, then by the tie-breaker.\n        \"\"\"\n        if self.weight != other.weight:\n            return self.weight  other.weight\n        return self.tie_breaker  other.tie_breaker\n\n    def is_leaf(self):\n        \"\"\"Checks if the node is a leaf.\"\"\"\n        return self.left is None and self.right is None\n\ndef calculate_sequence_cost(sequence: str) - int:\n    \"\"\"\n    Calculates the total bit cost to encode a sequence using the specified dynamic Huffman algorithm.\n    \"\"\"\n    total_bits = 0\n    frequencies = {}\n    seen_symbols = set()\n\n    # Constants for the escape mechanism\n    ESC_SYMBOL = -1  # A unique identifier for the ESC symbol\n    ESC_TIE_BREAKER = 256\n    INTERNAL_NODE_TIE_BREAKER_START = 257\n\n    for char_symbol in sequence:\n        symbol_ord = ord(char_symbol)\n\n        # 1. Build Model: Create nodes for the current state.\n        model_nodes = []\n        for sym, freq in frequencies.items():\n            model_nodes.append(HuffmanNode(weight=freq, tie_breaker=sym, symbol=sym))\n        \n        # Add ESC node if not all 256 byte values have been observed.\n        if len(seen_symbols)  256:\n            model_nodes.append(HuffmanNode(weight=1, tie_breaker=ESC_TIE_BREAKER, symbol=ESC_SYMBOL))\n\n        # 2. Construct Huffman Tree and find codeword lengths.\n        codeword_lengths = {}\n        \n        # Special case for a single node in the forest.\n        if len(model_nodes) == 1:\n            leaf = model_nodes[0]\n            if leaf.symbol is not None:\n                codeword_lengths[leaf.symbol] = 1\n        else:\n            # Use a min-priority queue (heapq in Python).\n            pq = model_nodes\n            heapq.heapify(pq)\n            \n            next_internal_tie_breaker = INTERNAL_NODE_TIE_BREAKER_START\n            \n            # Merge nodes until only the root remains.\n            while len(pq)  1:\n                left_node = heapq.heappop(pq)\n                right_node = heapq.heappop(pq)\n                \n                new_weight = left_node.weight + right_node.weight\n                \n                parent_node = HuffmanNode(weight=new_weight, \n                                          tie_breaker=next_internal_tie_breaker,\n                                          left=left_node,\n                                          right=right_node)\n                next_internal_tie_breaker += 1\n                \n                heapq.heappush(pq, parent_node)\n            \n            root = pq[0] if pq else None\n            \n            # 3. Calculate codeword lengths by traversing the tree.\n            if root:\n                # Stack for iterative traversal to find depths.\n                traversal_stack = [(root, 0)]\n                while traversal_stack:\n                    node, depth = traversal_stack.pop()\n                    if node.is_leaf():\n                        if node.symbol is not None:\n                            # A tree with one symbol still has a codeword of length 1, not 0.\n                            codeword_lengths[node.symbol] = depth if depth  0 else 1\n                    else:\n                        if node.right:\n                            traversal_stack.append((node.right, depth + 1))\n                        if node.left:\n                            traversal_stack.append((node.left, depth + 1))\n\n        # 4. Encode Symbol and Update Cost.\n        is_new_symbol = symbol_ord not in seen_symbols\n        \n        if is_new_symbol:\n            # Cost is ESC codeword length + 8 bits for the raw symbol.\n            esc_len = codeword_lengths.get(ESC_SYMBOL, 0)\n            total_bits += esc_len + 8\n        else:\n            # Cost is the symbol's codeword length.\n            sym_len = codeword_lengths.get(symbol_ord, 0)\n            total_bits += sym_len\n            \n        # 5. Update Model State for the next iteration.\n        if is_new_symbol:\n            seen_symbols.add(symbol_ord)\n        frequencies[symbol_ord] = frequencies.get(symbol_ord, 0) + 1\n            \n    return total_bits\n\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\"ABC\", \"AAAAA\", \"ABABA\"]\n\n    results = []\n    for sequence in test_cases:\n        result = calculate_sequence_cost(sequence)\n        results.append(result)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3261138"}]}