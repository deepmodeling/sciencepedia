{"hands_on_practices": [{"introduction": "为了深入理解开放寻址法中操作的基本成本，我们从一个精确的计算问题开始。这个练习将帮助你熟悉线性探测、哈希函数以及为保证数据结构一致性而引入的“墓碑”机制。通过探寻创建特定哈希表状态所需的最小探测量，你将学会如何在最基础的层面思考操作效率和成本优化。[@problem_id:3227311]", "problem": "考虑一个使用开放定址法和线性探测法的哈希表。该表的大小为 $m=7$，槽位索引为 $0,1,2,3,4,5,6$。键是整数，哈希函数为 $h(k)=k \\bmod 7$。一次成功的删除操作会将删除的槽位标记为一个墓碑（记为 $\\dagger$），而不是将其置空；搜索一个键时，从 $h(k)$ 开始，线性探测模7的连续索引，直到找到该键或一个空槽位，而墓碑不会终止搜索。插入一个键 $k$ 时，从 $h(k)$ 开始线性探测，直到找到一个空槽位或第一个墓碑，并将键存储在该位置。代价模型是开放定址法的标准模型：在搜索、插入或删除过程中的每一次槽位检查都计为一次探测。\n\n从一个空表开始，你可以选择任意整数键，并执行任意顺序的插入和删除操作。你的目标是达到一个最终状态，在该状态下，表中恰好在槽位 $2$、$4$ 和 $6$ 处有墓碑，而所有其他槽位均为空，表中没有剩余的活动键。在上述规则下，要达到这样的最终状态，整个操作序列所需的最少槽位检查（探测）总数是多少？给出你的答案，形式为一个精确整数，不带单位。", "solution": "问题要求将一个大小为 $m=7$ 的空哈希表转变为一个在槽位 $2$、$4$ 和 $6$ 处有墓碑且所有其他槽位为空的状态，所需的最少槽位检查（探测）总数。该哈希表使用开放定址法和线性探测法，哈希函数为 $h(k) = k \\bmod 7$。\n\n首先，我们来分析创建一个墓碑的过程。在槽位 $i$ 处创建一个墓碑，需要先将一个键插入该槽位，然后删除该键。这至少需要一次插入和一次删除操作。\n\n任何操作（插入、搜索或删除）的代价定义为检查的槽位数。由于每个操作都必须检查至少一个槽位，因此任何单个操作的代价至少为 $1$。所以，创建一个墓碑的最小代价至少是 $1$（用于插入）$+ 1$（用于删除）$= 2$ 次探测。\n\n我们的目标是在槽位 $2$、$4$ 和 $6$ 处创建三个不同的墓碑。由于每个墓碑的创建至少需要两次探测，并且为一个墓碑进行的操作不会消除为另一个墓碑进行操作的需要，因此创建三个墓碑的总探测次数必须至少为 $3 \\times 2 = 6$。这就确定了总代价的一个下限。\n\n现在，我们必须确定这个 $6$ 次探测的下限是否可以实现。为此，我们需要构造一个操作序列，该序列能达到目标状态，并且总代价恰好为 $6$。总代价为 $6$ 要求三次必要的插入和三次必要的删除中的每一次操作都只花费 $1$ 次探测。\n\n让我们分析一下插入和删除的代价。\n插入一个键 $k$ 的代价是从索引 $h(k)$ 开始探测直到找到一个可用槽位的槽位数量。可用槽位定义为一个空槽位或第一个包含墓碑的槽位。如果索引 $h(k)$ 处的槽位本身就是可用的，则代价可以最小化为 $1$。\n删除位于槽位 $i$ 的键 $k$ 的代价是从 $h(k)$ 开始探测直到到达槽位 $i$ 的槽位数。如果键 $k$ 的放置满足 $h(k)=i$，则代价可以最小化为 $1$。\n\n为了使在槽位 $i$ 处创建墓碑的插入和删除操作代价均为 $1$，我们应该选择一个键 $k$ 使得 $h(k)=i$。让我们基于这个原则设计一个操作序列。我们需要在槽位 $i_1=2$，$i_2=4$ 和 $i_3=6$ 处创建墓碑。\n\n我们可以选择三个不同的键 $k_1, k_2, k_3$，使得它们的哈希值分别对应于所期望的墓碑位置。我们选择 $k_1=2$，$k_2=4$ 和 $k_3=6$。\n$h(k_1) = 2 \\bmod 7 = 2$\n$h(k_2) = 4 \\bmod 7 = 4$\n$h(k_3) = 6 \\bmod 7 = 6$\n\n考虑以下操作序列，从一个空表开始。\n\n1.  **插入键 $k_1=2$**：探测从 $h(2)=2$ 开始。槽位 $2$ 为空。键 $2$ 被放置在槽位 $2$。\n    探测次数：$1$。\n    表状态：`[ , , 2, , , , ]`。\n    累计探测次数：$1$。\n\n2.  **插入键 $k_2=4$**：探测从 $h(4)=4$ 开始。槽位 $4$ 为空。键 $4$ 被放置在槽位 $4$。\n    探测次数：$1$。\n    表状态：`[ , , 2, , 4, , ]`。\n    累计探测次数：$1+1=2$。\n\n3.  **插入键 $k_3=6$**：探测从 $h(6)=6$ 开始。槽位 $6$ 为空。键 $6$ 被放置在槽位 $6$。\n    探测次数：$1$。\n    表状态：`[ , , 2, , 4, , 6]`。\n    累计探测次数：$2+1=3$。\n\n此时，所有必要的键都已在表中。现在我们删除它们以创建墓碑。\n\n4.  **删除键 $k_1=2$**：搜索从 $h(2)=2$ 开始。在第一个被探测的槽位，即索引 $2$ 处，找到了键 $2$。该槽位被标记为墓碑（$\\dagger$）。\n    探测次数：$1$。\n    表状态：`[ , , †, , 4, , 6]`。\n    累计探测次数：$3+1=4$。\n\n5.  **删除键 $k_2=4$**：搜索从 $h(4)=4$ 开始。在槽位 $4$ 处找到了键 $4$。该槽位被标记为墓碑。\n    探测次数：$1$。\n    表状态：`[ , , †, , †, , 6]`。\n    累计探测次数：$4+1=5$。\n\n6.  **删除键 $k_3=6$**：搜索从 $h(6)=6$ 开始。在槽位 $6$ 处找到了键 $6$。该槽位被标记为墓碑。\n    探测次数：$1$。\n    表状态：`[ , , †, , †, , †]`。\n    累计探测次数：$5+1=6$。\n\n表的最终状态是在槽位 $2$、$4$ 和 $6$ 处有墓碑，而所有其他槽位（$0, 1, 3, 5$）保持为空。这完全符合问题的要求。这个操作序列的总探测次数为 $6$。\n\n既然我们已经确定了 $6$ 次探测的下限，并且展示了一个可以达到此代价的操作序列，那么最少的总探测次数必定是 $6$。任何其他的键选择或操作顺序都无法得到更低的代价。例如，使用一个哈希到与其最终位置 $i$ 不同的值（即 $h(k) \\neq i$）的键 $k$，会导致插入（由于冲突或初始槽位被占用）和删除的探测次数都大于 $1$，从而增加了总代价。特定的插入规则（在第一个墓碑处停止）不会改变这个最优策略，因为最小代价路径涉及向空槽位中插入。", "answer": "$$\\boxed{6}$$", "id": "3227311"}, {"introduction": "理论知识告诉我们，线性探测容易受到“主聚集”（primary clustering）现象的影响，但这究竟有多严重？本实践旨在通过一个具体的编程实验来回答这个问题。你将亲手实现一个线性探测哈希表，并比较有序插入和随机插入两种批量加载方式下的性能差异，从而直观地感受非随机输入如何导致性能灾难。[@problem_id:3257202]", "problem": "您需要实现并分析一个使用线性探测的开放寻址哈希表，以研究批量插入顺序如何影响性能。该研究必须比较同一组整数关键字的两种批量插入顺序：升序排序顺序和伪随机顺序。此比较必须使用明确定义的度量指标和一个固定的哈希函数来量化其影响，该哈希函数会创建从关键字值到初始哈希地址的单调映射，当关键字分布不均匀时，可能导致非均匀的冲突。\n\n基本和核心定义：\n- 开放寻址法通过探测一系列候选索引，直至找到一个空槽位，从而将每个关键字插入到一个容量为 $m$ 的单一数组中。\n- 线性探测将关键字 $k$ 的探测序列定义为连续的索引 $h(k), h(k)+1, h(k)+2, \\dots$ (模 $m$)，其中 $h(k)$ 是 $k$ 的哈希值。\n- 需要实现的哈希函数是除法哈希法 $h(k) = \\left\\lfloor \\dfrac{m \\cdot k}{U} \\right\\rfloor$，其中 $U$ 是一个定义关键字全域尺度的正整数，而 $k$ 是范围在 $[0, U-1]$ 内的整数关键字。\n- 插入单个关键字的探测次数定义为检查过的槽位数量，包括最终成功放入的槽位。\n- 一次批处理结束时，最大连续占用簇的长度定义为循环遍历哈希表时遇到的连续占用槽位的最大数量（考虑环绕；遍历必须从某个空槽位之后立即开始，以避免重复计数）。\n\n两种插入顺序：\n- 排序顺序：关键字按升序数值顺序插入。\n- 随机顺序：关键字按照由线性同余生成器（LCG）为每个关键字生成的伪随机分数排序后所产生的顺序插入。线性同余生成器（LCG）定义为 $X_{i+1} = (a X_i + c) \\bmod M$，参数为 $a = 1664525$，$c = 1013904223$，$M = 2^{32}$。每个测试用例给定一个固定的种子 $X_0$。为了获得一个排列，为每个关键字生成一个分数 $X_i$，并根据这些分数对关键字进行排序。\n\n关键字集合的构造：\n- 对于每个测试用例，构造的关键字会在其初始哈希地址上产生双峰密度：一个低索引组和一个高索引组。\n- 设 $L$ 和 $t$ 为正整数。低索引组对于每个桶索引 $i \\in \\{0, 1, \\dots, L-1\\}$ 包含 $t$ 个关键字；高索引组对于每个桶索引 $j \\in \\{m-L, m-L+1, \\dots, m-1\\}$ 包含 $t$ 个关键字。\n- 对于桶索引 $b$，从区间 $I_b = \\left[\\left\\lfloor \\dfrac{U \\cdot b}{m} \\right\\rfloor, \\left\\lfloor \\dfrac{U \\cdot (b+1)}{m} \\right\\rfloor - 1\\right]$ 中选择 $t$ 个不同的关键字 $k$，使得 $h(k) = b$。使用 $I_b$ 中的前 $t$ 个整数（按升序）。关键字总数为 $n = 2Lt$。所有测试用例都满足 $n  m$ 以确保插入成功。\n\n每个测试用例需计算的度量指标：\n- 排序顺序的平均探测次数，记为 $\\overline{P}_{\\mathrm{sorted}}$。\n- 随机顺序的平均探测次数，记为 $\\overline{P}_{\\mathrm{random}}$。\n- 排序顺序的最终最大簇长度，记为 $C_{\\mathrm{sorted}}$。\n- 随机顺序的最终最大簇长度，记为 $C_{\\mathrm{random}}$。\n- 报告比率 $R_P = \\dfrac{\\overline{P}_{\\mathrm{sorted}}}{\\overline{P}_{\\mathrm{random}}}$ 和 $R_C = \\dfrac{C_{\\mathrm{sorted}}}{C_{\\mathrm{random}}}$。\n\n测试套件：\n对于每个参数元组 $(m, U, L, t, \\text{seed})$，构造关键字并测量上述两个比率。\n1. $(m, U, L, t, \\text{seed}) = (1024, 1024000, 240, 2, 123456789)$，因此 $n = 2 \\cdot 240 \\cdot 2 = 960$。\n2. $(m, U, L, t, \\text{seed}) = (512, 512000, 120, 2, 987654321)$，因此 $n = 480$。\n3. $(m, U, L, t, \\text{seed}) = (257, 257000, 64, 1, 20231102)$，因此 $n = 128$。\n4. $(m, U, L, t, \\text{seed}) = (128, 128000, 24, 2, 31415926)$，因此 $n = 96$。\n\n要求的最终输出格式：\n您的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表。该列表必须按顺序包含每个测试用例的 $R_P$ 和 $R_C$ 值，均为浮点数。对于上述整个测试套件，输出必须是：\n$[R_{P,1}, R_{C,1}, R_{P,2}, R_{C,2}, R_{P,3}, R_{C,3}, R_{P,4}, R_{C,4}]$。\n\n约束和期望：\n- 严格按照定义实现哈希表和度量指标。\n- 不允许外部输入；程序必须嵌入测试套件并打印单行输出。\n- 根据每个测试用例使用指定的 LCG 生成伪随机顺序。\n- 程序必须是完整且可运行的，并且必须严格遵守上述最终输出格式。", "solution": "用户提供了一个详细的问题陈述，要求分析一个使用线性探测的开放寻址哈希表的性能。该分析着重于插入顺序的影响，通过比较关键字的排序插入与伪随机顺序插入的方式来进行。\n\n### 步骤1：问题验证\n\n对问题进行了严格的验证过程。\n\n**从问题陈述中提取的已知条件：**\n\n*   **哈希表方法：** 使用线性探测的开放寻址法。\n*   **表容量：** $m$。\n*   **关键字全域：** 范围在 $[0, U-1]$ 内的整数 $k$。\n*   **哈希函数：** 除法哈希法，$h(k) = \\left\\lfloor \\dfrac{m \\cdot k}{U} \\right\\rfloor$。\n*   **探测序列：** 对于关键字 $k$，序列为 $h(k), (h(k)+1) \\pmod m, (h(k)+2) \\pmod m, \\dots$。\n*   **探测次数定义：** 插入时检查的槽位数量，包括最终放置关键字的空槽位。\n*   **最大簇长度定义：** 连续占用槽位块的最大长度，考虑循环环绕。测量从一个空槽位之后开始，以明确处理环绕情况。\n*   **关键字集合的构造：**\n    *   参数 $L$ 和 $t$ 是正整数。\n    *   生成关键字的双峰分布。\n    *   低索引组：对于每个桶索引 $b \\in \\{0, 1, \\dots, L-1\\}$，从区间 $I_b = \\left[\\left\\lfloor \\dfrac{U \\cdot b}{m} \\right\\rfloor, \\left\\lfloor \\dfrac{U \\cdot (b+1)}{m} \\right\\rfloor - 1\\right]$ 中选择前 $t$ 个整数 $k$，使得 $h(k)=b$。\n    *   高索引组：对于每个桶索引 $b \\in \\{m-L, m-L+1, \\dots, m-1\\}$，以类似方式选择关键字。\n    *   关键字总数为 $n=2Lt$。题目说明 $n  m$。\n*   **插入顺序：**\n    *   **排序：** 关键字按升序数值顺序插入。\n    *   **随机：** 关键字按由线性同余生成器（LCG）决定的顺序插入。\n*   **LCG 规范：** $X_{i+1} = (a X_i + c) \\pmod M$，其中 $a = 1664525$，$c = 1013904223$，$M = 2^{32}$，每个测试用例有特定的种子 $X_0$。关键字根据其生成的LCG分数进行排序。\n*   **比较的度量指标：**\n    *   排序插入的平均探测次数：$\\overline{P}_{\\mathrm{sorted}}$。\n    *   随机插入的平均探测次数：$\\overline{P}_{\\mathrm{random}}$。\n    *   排序插入的最终最大簇长度：$C_{\\mathrm{sorted}}$。\n    *   随机插入的最终最大簇长度：$C_{\\mathrm{random}}$。\n*   **需要计算的比率：** $R_P = \\dfrac{\\overline{P}_{\\mathrm{sorted}}}{\\overline{P}_{\\mathrm{random}}}$ 和 $R_C = \\dfrac{C_{\\mathrm{sorted}}}{C_{\\mathrm{random}}}$。\n*   **测试用例：** 提供了四个 $(m, U, L, t, \\text{seed})$ 元组。\n    1.  $(1024, 1024000, 240, 2, 123456789)$\n    2.  $(512, 512000, 120, 2, 987654321)$\n    3.  $(257, 257000, 64, 1, 20231102)$\n    4.  $(128, 128000, 24, 2, 31415926)$\n\n**验证结论：**\n\n该问题是**有效的**。它在科学上基于数据结构和算法的原理，特别是哈希表分析。问题陈述清晰，所有必要的参数、初始条件和定义都已明确提供。术语精确，目标客观且可量化。问题描述了一个确定性的过程，存在唯一的解且计算上是可行的。整个设置是自洽的，没有矛盾；所有测试用例都满足 $n  m$ 的条件，确保所有插入都能成功。该实验设计良好，旨在展示线性探测在特定非均匀条件下的一次聚集现象。\n\n### 步骤2：解法推导\n\n解决方案涉及为每个测试用例实现指定的哈希表、关键字生成、插入顺序和度量指标计算。\n\n**1. 算法框架**\n\n对于由参数 $(m, U, L, t, \\text{seed})$ 定义的每个测试用例：\n1.  生成 $n=2Lt$ 个整数关键字的集合。\n2.  创建两个插入序列：一个排序的，一个伪随机的。\n3.  对每个序列：\n    a.  初始化一个大小为 $m$ 的空哈希表。\n    b.  插入所有关键字，计算总探测次数。\n    c.  计算平均探测次数 $\\overline{P}$。\n    d.  所有插入完成后，计算最大簇长度 $C$。\n4.  计算比率 $R_P$ 和 $R_C$。\n\n**2. 关键字生成**\n\n关键字集合是两组的并集：\n*   一个低索引组：对于从 $0$ 到 $L-1$ 的每个桶索引 $b$，我们生成 $t$ 个关键字。对于给定的 $b$，关键字是区间 $I_b$ 中的前 $t$ 个整数。桶 $b$ 的起始关键字是 $k_{b,0} = \\lfloor (U \\cdot b) / m \\rfloor$。因此，$t$ 个关键字是 $\\{k_{b,0}, k_{b,0}+1, \\dots, k_{b,0}+t-1\\}$。\n*   一个高索引组：对于从 $m-L$ 到 $m-1$ 的每个桶索引 $b$，我们以相同的方式生成 $t$ 个关键字。\n关键字总数为 $n=2Lt$。\n\n**3. 插入顺序生成**\n\n*   **排序顺序：** 将整个 $n$ 个关键字的集合按数值升序排序。\n*   **随机顺序：** 生成关键字的伪随机排列。\n    1.  使用给定的种子初始化 LCG 状态：$X_0 = \\text{seed}$。\n    2.  使用递推公式 $X_{i+1} = (a X_i + c) \\pmod M$ 生成 $n$ 个伪随机数 $X_1, X_2, \\dots, X_n$，其中 $a=1664525$，$c=1013904223$，$M=2^{32}$。\n    3.  创建（关键字，随机分数）对。\n    4.  根据随机分数对此类对进行排序。得到的关键字顺序即为伪随机插入序列。\n\n**4. 哈希表操作与度量指标**\n\n哈希表是一个大小为 $m$ 的数组，其中每个单元格可以是空的或被占用的。\n\n*   **插入与探测计数：** 插入关键字 $k$：\n    1.  计算初始哈希地址 $j_0 = h(k) = \\lfloor (m \\cdot k) / U \\rfloor$。\n    2.  初始化探测计数 $p=1$。\n    3.  检查哈希表槽位 $j = (j_0 + p - 1) \\pmod m$。\n    4.  如果该槽位为空，则将 $k$ 放置在此处，并终止该关键字的插入。探测次数为 $p$。\n    5.  如果该槽位被占用，则增加 $p$ 并从步骤3重复。\n    总探测次数是在所有 $n$ 次插入中累积的。平均值为 $\\overline{P} = (\\sum_{i=1}^{n} p_i) / n$。\n\n*   **最大簇长度计算：**\n    1.  在所有 $n$ 个关键字插入后，找到表数组中索引为 $j_{empty}$ 的第一个空槽位。如果没有空槽位，则簇长度为 $m$。问题保证 $n  m$。\n    2.  从索引 $(j_{empty} + 1) \\pmod m$ 开始，遍历整个数组（循环地），计算连续占用槽位的长度。\n    3.  最大簇长度 $C$ 是在这次遍历中观察到的最大连续长度。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the hash table analysis problem.\n    It iterates through predefined test cases, runs the insertion experiments,\n    and prints the final results in the required format.\n    \"\"\"\n    test_cases = [\n        (1024, 1024000, 240, 2, 123456789),\n        (512, 512000, 120, 2, 987654321),\n        (257, 257000, 64, 1, 20231102),\n        (128, 128000, 24, 2, 31415926),\n    ]\n\n    # LCG parameters\n    LCG_A = 1664525\n    LCG_C = 1013904223\n    LCG_M_MASK = 0xFFFFFFFF  # (2**32 - 1)\n\n    EMPTY_SLOT = -1 # Sentinel for an empty slot in the hash table\n\n    def generate_keys(m, U, L, t):\n        \"\"\"Generates the bimodal key set based on problem parameters.\"\"\"\n        keys = []\n        # Low-index group\n        for b in range(L):\n            start_key = (U * b) // m\n            keys.extend(range(start_key, start_key + t))\n        # High-index group\n        for b in range(m - L, m):\n            start_key = (U * b) // m\n            keys.extend(range(start_key, start_key + t))\n        return keys\n\n    def get_random_order(keys, n, seed):\n        \"\"\"Permutes keys based on scores from a Linear Congruential Generator.\"\"\"\n        lcg_state = seed\n        scores = []\n        for _ in range(n):\n            lcg_state = (LCG_A * lcg_state + LCG_C)  LCG_M_MASK\n            scores.append(lcg_state)\n        \n        # Pair keys with scores and sort by score\n        keyed_scores = list(zip(keys, scores))\n        keyed_scores.sort(key=lambda x: x[1])\n        \n        return [key for key, score in keyed_scores]\n\n    def run_experiment(m, U, n, key_order):\n        \"\"\"\n        Runs a single experiment for a given key insertion order.\n        Returns the average number of probes and the final max cluster length.\n        \"\"\"\n        table = np.full(m, EMPTY_SLOT, dtype=np.int64)\n        total_probes = 0\n\n        for key in key_order:\n            home_address = (m * key) // U\n            probes = 0\n            while True:\n                probes += 1\n                current_pos = (home_address + probes - 1) % m\n                if table[current_pos] == EMPTY_SLOT:\n                    table[current_pos] = key\n                    total_probes += probes\n                    break\n        \n        avg_probes = total_probes / n\n\n        # Calculate max cluster length\n        max_len = 0\n        current_len = 0\n        \n        # Per problem spec, start traversal after an empty slot to handle wrap-around\n        empty_indices = np.where(table == EMPTY_SLOT)[0]\n        if len(empty_indices) == 0:\n            # This case is not expected as n  m\n            max_len = m\n        else:\n            start_index = (empty_indices[0] + 1) % m\n            for i in range(m):\n                idx = (start_index + i) % m\n                if table[idx] != EMPTY_SLOT:\n                    current_len += 1\n                else:\n                    max_len = max(max_len, current_len)\n                    current_len = 0\n            # Final check for wrap-around cluster\n            max_len = max(max_len, current_len)\n            \n        return avg_probes, max_len\n\n    final_results = []\n    for m, U, L, t, seed in test_cases:\n        n = 2 * L * t\n        \n        keys = generate_keys(m, U, L, t)\n        \n        # Sorted order experiment\n        sorted_keys = sorted(keys)\n        p_sorted, c_sorted = run_experiment(m, U, n, sorted_keys)\n        \n        # Random order experiment\n        random_keys = get_random_order(keys, n, seed)\n        p_random, c_random = run_experiment(m, U, n, random_keys)\n        \n        # Calculate and store ratios\n        R_P = p_sorted / p_random\n        # Handle division by zero for cluster length, though not expected here\n        R_C = (c_sorted / c_random) if c_random != 0 else float('inf')\n        \n        final_results.append(R_P)\n        final_results.append(R_C)\n\n    # Format the final output string\n    output_str = \"[\" + \",\".join(map(str, final_results)) + \"]\"\n    print(output_str)\n\nsolve()\n```", "id": "3257202"}, {"introduction": "在上一个实践中，我们观察到了聚集现象的负面影响，现在我们将更进一步，精确地量化它。这个高级练习要求你设计一个合成基准测试，以隔离并测量搜索成本与簇长度之间的关系。通过推导理论预期的线性关系并用实验数据进行验证，你将把经验观察与严谨的理论分析联系起来，从而深刻掌握线性探测的性能瓶颈。[@problem_id:3257276]", "problem": "考虑一个使用开放寻址法和线性探测法实现的哈希表。该哈希表容量为 $m$，哈希函数为 $h(k)$，探测序列为 $p_j(k) = (h(k) + j) \\bmod m$，其中 $j = 0, 1, \\dots, m-1$。成本模型将搜索时间定义为检查的槽位数（探测次数），这是一个以“探测次数”为单位的无量纲度量。\n\n从基本定义开始：\n- 开放寻址法将所有键都放入表本身；通过使用探测序列找到下一个可用槽位来解决冲突。\n- 线性探测法使用等差数列探测序列，这会产生连续的已占用槽位（簇）。\n- 当在探测的槽位中找到键或遇到空槽位时，搜索终止。成功搜索的成本等于直到检查到匹配键为止的探测次数。不成功搜索的成本等于直到检查到第一个空槽位为止的探测次数。\n\n当连续的已占用槽位形成并增长时，会出现一次聚集；对这样一个簇进行探测会强制对整个簇进行顺序扫描。你将构建一个合成基准测试来分离这种现象。\n\n基准测试设计：\n- 使用基于模的哈希函数 $h(k) = k \\bmod m$。\n- 固定一个起始索引 $s$，并创建一个长度为 $C$ 的单个连续簇，占据槽位 $s, s+1, \\dots, s+C-1$（无回绕），并使槽位 $s+C$ 为空。通过插入键 $k_i = s + i \\cdot m$（其中 $i = 0, 1, \\dots, C-1$）来实现这一点。在线性探测法和给定的哈希函数下，每个这样的键最初都哈希到 $s$，并被放置在下一个可用槽位，从而填满这个连续的块。\n- 对于每个簇长度 $C$，测量：\n  1. 簇内的平均成功搜索成本，通过搜索所有 $C$ 个已插入的键并对其探测次数取平均值得到。\n  2. 当初始探测位于簇的起始位置时的不成功搜索成本，通过搜索一个哈希到 $s$ 但不存在的键 $k^\\star = s + C \\cdot m$ 得到。\n  3. 当初始探测在簇偏移量上均匀分布时的平均不成功搜索成本，通过搜索 $C$ 个不同的键 $u_\\delta = (s + \\delta) + M \\cdot m$（其中 $\\delta = 0, 1, \\dots, C-1$，$M$ 是一个足够大的整数，以确保这些键都不等于任何已插入的键）得到。每个这样的键都从索引 $s + \\delta$ 开始探测，并且不存在于表中。\n\n科学要求：\n- 根据所述定义推导这三种成本对簇长度 $C$ 的预期依赖关系（不使用快捷公式）。你的推导必须解释为什么在探测单个连续簇时，搜索时间与 $C$ 成线性关系。\n- 仔细处理边界情况。对于 $C = 0$，按惯例将平均成功搜索成本定义为 $0$（没有成功搜索），从起始位置开始的不成功搜索成本为 $1$ 次探测（起始槽位为空），在均匀偏移下的平均不成功搜索成本为 $1$ 次探测。\n\n测试套件：\n- 使用固定的表大小 $m = 4096$ 和起始索引 $s = 123$。\n- 在集合 $\\{0, 1, 8, 64, 512, 2048, 3968\\}$ 中评估簇长度 $C$，这涵盖了空簇、微小簇、中等簇和接近最大且不发生回绕的簇，因为对于所有列出的 $C$ 值，都有 $s + C \\leq m - 1$。\n\n程序要求：\n- 完全按照定义实现线性探测法。\n- 对于每个测试用例的簇长度 $C$，构建簇并计算上述指定的三个指标。\n- 以探测次数（无单位计数）表示所有三个指标。\n- 将所有测试用例的结果聚合到单行输出中，形式为用方括号括起来的逗号分隔列表。此列表的每个元素本身必须是形如 $[C,\\ \\text{avg\\_succ},\\ \\text{unsucc\\_start},\\ \\text{avg\\_unsucc\\_uniform}]$ 的方括号逗号分隔列表，其中 $C$ 是一个整数，三个成本是以探测次数为单位的浮点数或整数。例如，顶层格式为 $[[\\dots],[\\dots],\\dots]$。", "solution": "基本依据是开放寻址法、线性探测法以及探测次数成本模型的定义。设表容量为 $m$，哈希函数为 $h(k) = k \\bmod m$，探测序列为 $p_j(k) = (h(k) + j) \\bmod m$。搜索沿探测序列顺序检查槽位；成本等于检查过的槽位总数。成功搜索在检查的槽位包含目标键时停止。不成功搜索在检查的槽位为空时停止。\n\n通过插入 $C$ 个都哈希到相同起始索引 $s$ 的键来构建一个巨大的簇：\n- 插入键 $k_i = s + i \\cdot m$，其中 $i \\in \\{0, 1, \\dots, C-1\\}$。\n- 每次插入都从 $h(k_i) = s$ 开始，并使用线性探测法找到下一个空槽位，因此插入的键占据了 $s, s+1, \\dots, s+C-1$（无回绕），前提是 $s + C \\leq m - 1$。槽位 $s+C$ 保持为空。\n\n我们现在推导搜索成本作为簇长度 $C$ 的函数。\n\n簇内的成功搜索：\n- 考虑放置在偏移量 $\\delta \\in \\{0, 1, \\dots, C-1\\}$ 处的键，它位于槽位 $s+\\delta$。\n- 其探测序列从 $s$ 开始，搜索会扫描 $s, s+1, \\dots, s+\\delta$ 直到找到该键。探测次数等于 $\\delta + 1$。\n- 对簇中所有键取平均值，平均成功搜索成本为\n$$\n\\frac{1}{C} \\sum_{\\delta=0}^{C-1} (\\delta + 1) = \\frac{1}{C} \\left( \\sum_{\\delta=0}^{C-1} \\delta + \\sum_{\\delta=0}^{C-1} 1 \\right) = \\frac{1}{C} \\left( \\frac{(C-1)C}{2} + C \\right) = \\frac{C+1}{2}.\n$$\n- 对于边界情况 $C=0$，没有成功的搜索可以平均；按照惯例，我们将平均值定义为 $0$。\n\n从簇起始位置开始的不成功搜索：\n- 考虑一个缺失的键 $k^\\star$，其 $h(k^\\star) = s$（例如 $k^\\star = s + C \\cdot m$）。\n- 探测序列从 $s$ 开始，扫描簇中的槽位 $s, s+1, \\dots, s+C-1$，发现它们都已被占用。第一个空槽位在 $s+C$。\n- 探测次数等于检查的已占用槽位数加上对空槽位的检查，即 $C + 1$。\n- 对于边界情况 $C=0$，第一个探测的槽位 $s$ 是空的，所以成本是 $1$。\n\n在簇上具有均匀起始偏移的不成功搜索：\n- 考虑缺失的键 $u_\\delta$，其 $h(u_\\delta) = s + \\delta$（$\\delta \\in \\{0, 1, \\dots, C-1\\}$），并且 $u_\\delta$ 与任何已插入的键都不同。\n- 探测序列从 $s + \\delta$ 开始，扫描 $s + \\delta, s + \\delta + 1, \\dots, s+C - 1$，然后是第一个空槽位 $s+C$。\n- 对于偏移量 $\\delta$，探测次数为 $(C - \\delta) + 1$。\n- 对所有偏移量取平均值，\n$$\n\\frac{1}{C} \\sum_{\\delta=0}^{C-1} \\big( (C - \\delta) + 1 \\big) = \\frac{1}{C} \\left( \\sum_{\\delta=0}^{C-1} (C - \\delta) + \\sum_{\\delta=0}^{C-1} 1 \\right) = \\frac{1}{C} \\left( \\frac{C(C+1)}{2} + C \\right) = \\frac{C+3}{2}.\n$$\n- 对于边界情况 $C=0$，没有偏移量可以平均；成本退化为从起始位置开始的情况，即 $1$。\n\n这些推导证明了在线性探测法下，成本对聚集的线性敏感性：\n- 平均成功搜索成本以 $\\frac{C+1}{2}$ 的速度增长。\n- 从簇起始位置开始的不成功搜索成本以 $C+1$ 的速度增长。\n- 在簇上具有均匀起始偏移的平均不成功搜索成本以 $\\frac{C+3}{2}$ 的速度增长。\n每个表达式都是簇长度 $C$ 的仿射函数，因此创建一个巨大的簇会导致搜索时间与簇长度成线性关系。\n\n算法实现：\n- 根据所述定义，实现使用线性探测法的插入和搜索。\n- 通过使用基于模的哈希函数，插入 $C$ 个初始索引为 $s$ 的冲突键来构建簇。\n- 通过检测搜索过程来直接测量探测次数，以计算检查的槽位数。\n- 对于每个测试用例 $C \\in \\{0, 1, 8, 64, 512, 2048, 3968\\}$，以及 $m = 4096$ 和 $s = 123$，计算：\n  - 所有已插入键的平均成功搜索成本（对于 $C=0$ 定义为 $0$）。\n  - 使用一个哈希到 $s$ 的缺失键，从簇起始位置开始的不成功搜索成本。\n  - 使用每个偏移量一个缺失键，在均匀起始偏移下的平均不成功搜索成本。\n- 以指定的嵌套列表格式将聚合结果打印为单行。所有报告的值都以探测次数为单位。\n\n这种基于原理的设计直接反映了线性探测法在连续占用下的行为，不依赖于所述定义之外的快捷公式，并产生与推导出的线性伸缩关系相匹配的测量结果。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\nclass LinearProbingTable:\n    def __init__(self, m: int):\n        self.m = m\n        # Use None to denote empty slot\n        self.table = [None] * m\n\n    def h(self, k: int) - int:\n        # Modulus-based hash function\n        return k % self.m\n\n    def insert(self, k: int) - bool:\n        \"\"\"Insert key k using linear probing. Returns True if inserted, False if table is full.\"\"\"\n        idx = self.h(k)\n        for _ in range(self.m):\n            if self.table[idx] is None:\n                self.table[idx] = k\n                return True\n            idx = (idx + 1) % self.m\n        return False  # Table full\n\n    def probe_count_search(self, k: int) - int:\n        \"\"\"Return number of probes used to search for k (successful or unsuccessful).\"\"\"\n        idx = self.h(k)\n        probes = 0\n        for _ in range(self.m):\n            probes += 1\n            slot = self.table[idx]\n            if slot is None:\n                return probes  # unsuccessful: empty slot terminates\n            if slot == k:\n                return probes  # successful: found the key\n            idx = (idx + 1) % self.m\n        # If full cycle without finding empty or the key (should not happen with our construction),\n        # return the maximum probes m.\n        return probes\n\ndef build_cluster_and_measure(m: int, s: int, C: int):\n    \"\"\"\n    Build a single contiguous cluster starting at index s of length C without wrap-around,\n    and measure:\n      - average successful search probes over all inserted keys,\n      - unsuccessful search probes starting from s (key hashing to s but missing),\n      - average unsuccessful search probes when initial probe is uniformly distributed over cluster offsets.\n    \"\"\"\n    # Preconditions: ensure the cluster fits without wrap-around\n    assert s + C = m - 1, \"Cluster must not wrap around.\"\n\n    table = LinearProbingTable(m)\n\n    # Insert C keys that all hash to s to form the cluster in slots s..s+C-1\n    inserted_keys = []\n    for i in range(C):\n        k = s + i * m  # all hash to s\n        ok = table.insert(k)\n        if not ok:\n            raise RuntimeError(\"Insertion failed: table unexpectedly full.\")\n        inserted_keys.append(k)\n\n    # Average successful search over inserted keys\n    if C == 0:\n        avg_succ = 0.0  # by convention\n    else:\n        succ_probes = [table.probe_count_search(k) for k in inserted_keys]\n        avg_succ = float(sum(succ_probes)) / float(len(succ_probes))\n\n    # Unsuccessful search from start (key hashing to s but not present)\n    missing_start_key = s + C * m  # hashes to s, not inserted\n    unsucc_start = float(table.probe_count_search(missing_start_key))\n\n    # Average unsuccessful search with uniform starting offsets over the cluster\n    if C == 0:\n        avg_unsucc_uniform = 1.0  # degenerate case: same as start case\n    else:\n        # For each offset delta in 0..C-1, choose a missing key hashing to s+delta\n        # Ensure keys do not equal any inserted key: pick a large M to avoid collisions with existing keys\n        M = C + 12345  # any large integer suffices\n        unsucc_uniform_probes = []\n        for delta in range(C):\n            u = (s + delta) + M * m\n            unsucc_uniform_probes.append(table.probe_count_search(u))\n        avg_unsucc_uniform = float(sum(unsucc_uniform_probes)) / float(len(unsucc_uniform_probes))\n\n    return [C, avg_succ, unsucc_start, avg_unsucc_uniform]\n\ndef format_list(obj):\n    \"\"\"Format nested lists without spaces, as required.\"\"\"\n    if isinstance(obj, list):\n        return \"[\" + \",\".join(format_list(x) for x in obj) + \"]\"\n    elif isinstance(obj, (int, float)):\n        # Ensure consistent float formatting (no trailing .0 removal for ints)\n        return str(obj)\n    elif isinstance(obj, bool):\n        return \"True\" if obj else \"False\"\n    else:\n        raise TypeError(\"Unsupported type for formatting\")\n\ndef solve():\n    # Define the test cases from the problem statement.\n    m = 4096\n    s = 123\n    test_cases = [\n        # cluster lengths C covering empty, small, moderate, and near-maximum cluster sizes without wrap-around\n        0, 1, 8, 64, 512, 2048, 3968\n    ]\n\n    results = []\n    for C in test_cases:\n        results.append(build_cluster_and_measure(m, s, C))\n\n    # Final print statement in the exact required format: a single line with nested lists, comma-separated, no spaces.\n    print(format_list(results))\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3257276"}]}