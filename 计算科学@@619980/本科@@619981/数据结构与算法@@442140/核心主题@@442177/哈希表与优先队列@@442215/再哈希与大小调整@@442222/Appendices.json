{"hands_on_practices": [{"introduction": "动态哈希表在增长和缩小时，如果扩容和缩容的负载因子阈值设置不当，可能会导致所谓的“往复振荡”现象，即在容量边界附近频繁地进行昂贵的重哈希操作。[@problem_id:3266677] 这个练习将引导你精确计算在这种低效策略下所执行的总工作量，从而让你深刻理解为何需要设计更智能的伸缩机制。", "problem": "考虑一个支持动态调整大小的开放定址哈希表，其容量根据负载因子进行加倍和减半。负载因子定义为 $\\alpha = \\frac{s}{M}$，其中 $s$ 是当前存储的键数，$M$ 是当前表的容量。该表使用以下调整大小的策略：\n- 插入时，如果再插入一个键会导致 $\\alpha$ 超过上限阈值 $\\alpha_{\\max}$，则将表容量加倍，并将所有现有键重新哈希到新表中。\n- 删除时，在移除一个键后，如果 $\\alpha$ 严格低于下限阈值 $\\alpha_{\\min}$，则将表容量减半（但绝不低于一个固定的最小容量），并将所有剩余键重新哈希到新表中。\n\n假设使用以下参数和成本模型：\n- 初始容量为 $M_0 = 16$，且表容量永不收缩至低于 $M_0$。\n- 上限阈值为 $\\alpha_{\\max} = 1$（当试图向满表中插入时会发生增长）。\n- 下限阈值为 $\\alpha_{\\min} = \\frac{1}{2}$。\n- 操作序列为：向一个初始为空的表中进行 $N = 1000$ 次插入，紧接着进行 $N = 1000$ 次删除。\n- 每次不触发调整大小的插入或删除操作消耗 $1$ 单位的工作量。\n- 一次调整大小（无论是增长还是收缩）会将当前存储的所有键重新哈希到新表中，每个重新哈希的键消耗 $1$ 单位的工作量。忽略内存分配和任何其他开销。\n- 假设哈希是均匀的，因此将一个键放入表中的期望成本（不包括调整大小）是恒定的，并已计入上述的 $1$ 单位工作量中。\n\n根据这些定义和策略，推导出整个操作序列所执行的总工作量的精确值，以指定的单位计算。将最终答案表示为单个实数，无需四舍五入。", "solution": "用户要求我解决这个问题。我将首先验证问题陈述。\n\n### 问题验证\n\n**步骤1：提取已知条件**\n\n-   负载因子定义为 $\\alpha = \\frac{s}{M}$，其中 $s$ 是存储的键数，$M$ 是表容量。\n-   初始和最小容量为 $M_0 = 16$。\n-   调整大小的上限阈值为 $\\alpha_{\\max} = 1$。如果再插入一个键会导致 $\\alpha > \\alpha_{\\max}$，则会发生增长。\n-   调整大小的下限阈值为 $\\alpha_{\\min} = \\frac{1}{2}$。删除后如果 $\\alpha  \\alpha_{\\min}$，则会发生收缩。\n-   操作序列为：向一个初始为空的表中进行 $N = 1000$ 次插入，随后进行 $N = 1000$ 次删除。\n-   一次不调整大小的插入或删除的成本是 $1$ 单位工作量。\n-   一次调整大小的成本是每个重新哈希的键消耗 $1$ 单位工作量。\n-   增长操作：表容量加倍 ($M \\to 2M$)。\n-   收缩操作：表容量减半 ($M \\to \\frac{M}{2}$) 。\n\n**步骤2：使用提取的已知条件进行验证**\n\n-   **科学依据**：该问题描述了一个经典的动态数组或开放定址哈希表调整大小的策略。其模型和成本分析是计算机科学和算法领域的标准课题。它完全基于数据结构分析的既定原则。\n-   **适定性**：初始条件（空表，$M_0=16$）、操作序列（$1000$次插入，$1000$次删除）和调整大小的规则都得到了精确定义。这使得总工作量的计算是唯一且确定性的。\n-   **客观性**：问题使用了精确、无歧义的数学定义和规则来陈述。\n\n该问题是自洽的、一致的，并且没有违反任何指定的有效性标准。\n\n**步骤3：结论与行动**\n\n该问题被判定为**有效**。将提供完整的解答。\n\n### 解答\n\n总工作量是在插入阶段和删除阶段所执行工作的总和。我们将分别分析每个阶段。\n\n**1. 插入阶段：$1000$次插入**\n\n表初始为空，所以 $s=0$，初始容量为 $M=16$。\n$1000$次插入操作的基础成本是 $1000 \\times 1 = 1000$ 单位工作量。\n\n我们还必须计算调整大小期间所做的工作。当尝试插入一个键，会使负载因子 $\\alpha = \\frac{s+1}{M}$ 超过 $\\alpha_{\\max} = 1$ 时，会触发向上调整大小（增长）。这可以简化为条件 $\\frac{s+1}{M} > 1$，或 $s+1 > M$。由于键数 $s$ 不能超过容量 $M$，这个条件仅在 $s=M$ 时满足。因此，表在插入第 $(M+1)$ 个键之前增长。这次增长的成本是表中已有的键数，即 $s=M$。\n\n我们来追踪增长事件：\n-   **初始状态：** $s=0$, $M=16$。\n-   插入第 $1$ 到第 $16$ 个键。当 $s=16$ 时，表已满。\n-   **增长 1：** 在插入第 $17$ 个键之前，$s=16$ 且 $M=16$。触发一次调整大小。\n    -   新容量：$M \\to 2 \\times 16 = 32$。\n    -   调整大小工作量：$16$ 个键被重新哈希，消耗 $16$ 单位。\n-   **增长 2：** 表再次填满。在插入第 $33$ 个键之前，$s=32$ 且 $M=32$。触发一次调整大小。\n    -   新容量：$M \\to 2 \\times 32 = 64$。\n    -   调整大小工作量：$32$ 个键被重新哈希，消耗 $32$ 单位。\n-   **增长 3：** 在插入第 $65$ 个键之前（$s=64$, $M=64$）。\n    -   新容量：$M \\to 2 \\times 64 = 128$。\n    -   调整大小工作量：$64$ 单位。\n-   **增长 4：** 在插入第 $129$ 个键之前（$s=128$, $M=128$）。\n    -   新容量：$M \\to 2 \\times 128 = 256$。\n    -   调整大小工作量：$128$ 单位。\n-   **增长 5：** 在插入第 $257$ 个键之前（$s=256$, $M=256$）。\n    -   新容量：$M \\to 2 \\times 256 = 512$。\n    -   调整大小工作量：$256$ 单位。\n-   **增长 6：** 在插入第 $513$ 个键之前（$s=512$, $M=512$）。\n    -   新容量：$M \\to 2 \\times 512 = 1024$。\n    -   调整大小工作量：$512$ 单位。\n\n第6次增长后，容量为 $M=1024$。接着插入第 $513$ 到 $1000$ 个键。由于键数 $s$ 始终小于 $1024$，因此不会再发生增长。\n\n插入阶段的总工作量（$W_{\\text{ins}}$）是基础插入工作量和总调整大小工作量的总和。\n$$ W_{\\text{resize, ins}} = 16 + 32 + 64 + 128 + 256 + 512 $$\n这是一个几何级数：\n$$ W_{\\text{resize, ins}} = 16(1 + 2 + 4 + 8 + 16 + 32) = 16 \\sum_{i=0}^{5} 2^i = 16 \\left(\\frac{2^6 - 1}{2-1}\\right) = 16(63) = 1008 $$\n插入阶段总工作量：\n$$ W_{\\text{ins}} = 1000 + W_{\\text{resize, ins}} = 1000 + 1008 = 2008 $$\n在此阶段结束时，表中有 $s=1000$ 个键，容量为 $M=1024$。\n\n**2. 删除阶段：$1000$次删除**\n\n此阶段开始时，$s=1000$ 且 $M=1024$。\n$1000$次删除操作的基础成本是 $1000 \\times 1 = 1000$ 单位工作量。\n\n在删除一个键后，如果新的负载因子 $\\alpha = \\frac{s}{M}$ 严格低于 $\\alpha_{\\min} = \\frac{1}{2}$，则会触发向下调整大小（收缩）。该条件为 $\\frac{s}{M}  \\frac{1}{2}$，或 $s  \\frac{M}{2}$。收缩的成本是剩余的键数，即 $s$。\n\n我们来追踪收缩事件：\n-   **初始状态：** $s=1000$, $M=1024$。\n-   键被逐个删除。对于 $M=1024$，第一个收缩条件是 $s  \\frac{1024}{2}$，即 $s  512$。这发生在元素数量从 $s=512$ 下降到 $s=511$ 时。\n-   **收缩 1：** 当 $s=512$ 时删除一个键后，新的键数为 $s=511$。\n    -   条件满足：$511  512$。\n    -   新容量：$M \\to \\frac{1024}{2} = 512$。\n    -   调整大小工作量：$511$ 个剩余键被重新哈希，消耗 $511$ 单位。\n-   **收缩 2：** 现在 $s$ 在 $M=512$ 的情况下从 $511$ 开始减少。下一个收缩条件是 $s  \\frac{512}{2}$，即 $s  256$。这发生在 $s$ 从 $256$ 下降到 $255$ 时。\n    -   新容量：$M \\to \\frac{512}{2} = 256$。\n    -   调整大小工作量：$255$ 单位。\n-   **收缩 3：** $s$ 在 $M=256$ 的情况下从 $255$ 开始减少。收缩条件：$s  \\frac{256}{2}$，即 $s  128$。在 $s$ 变为 $127$ 时触发。\n    -   新容量：$M \\to \\frac{256}{2} = 128$。\n    -   调整大小工作量：$127$ 单位。\n-   **收缩 4：** $s$ 在 $M=128$ 的情况下从 $127$ 开始减少。收缩条件：$s  \\frac{128}{2}$，即 $s  64$。在 $s$ 变为 $63$ 时触发。\n    -   新容量：$M \\to \\frac{128}{2} = 64$。\n    -   调整大小工作量：$63$ 单位。\n-   **收缩 5：** $s$ 在 $M=64$ 的情况下从 $63$ 开始减少。收缩条件：$s  \\frac{64}{2}$，即 $s  32$。在 $s$ 变为 $31$ 时触发。\n    -   新容量：$M \\to \\frac{64}{2} = 32$。\n    -   调整大小工作量：$31$ 单位。\n-   **收缩 6：** $s$ 在 $M=32$ 的情况下从 $31$ 开始减少。收缩条件：$s  \\frac{32}{2}$，即 $s  16$。在 $s$ 变为 $15$ 时触发。\n    -   新容量：$M \\to \\frac{32}{2} = 16$。\n    -   调整大小工作量：$15$ 单位。\n\n在最后一次收缩后，容量为 $M=16$。问题规定容量永不收缩至低于 $M_0=16$。因此，在删除剩余的键时，不会再发生收缩。\n\n删除阶段的总工作量（$W_{\\text{del}}$）是基础删除工作量和总调整大小工作量的总和。\n$$ W_{\\text{resize, del}} = 511 + 255 + 127 + 63 + 31 + 15 $$\n这个总和可以写成：\n$$ W_{\\text{resize, del}} = (512-1) + (256-1) + (128-1) + (64-1) + (32-1) + (16-1) $$\n$$ W_{\\text{resize, del}} = (2^9-1) + (2^8-1) + (2^7-1) + (2^6-1) + (2^5-1) + (2^4-1) $$\n$$ W_{\\text{resize, del}} = \\left(\\sum_{i=4}^{9} 2^i\\right) - 6 $$\n几何级数的和为 $\\sum_{i=4}^{9} 2^i = 2^4 \\sum_{j=0}^{5} 2^j = 16 \\left(\\frac{2^6 - 1}{2-1}\\right) = 16(63) = 1008$。\n$$ W_{\\text{resize, del}} = 1008 - 6 = 1002 $$\n删除阶段总工作量：\n$$ W_{\\text{del}} = 1000 + W_{\\text{resize, del}} = 1000 + 1002 = 2002 $$\n\n**3. 总工作量**\n\n总工作量是两个阶段工作量的总和：\n$$ W_{\\text{total}} = W_{\\text{ins}} + W_{\\text{del}} = 2008 + 2002 = 4010 $$\n所执行的精确总工作量为 $4010$ 单位。", "answer": "$$\n\\boxed{4010}\n$$", "id": "3266677"}, {"introduction": "为了解决前一个练习中暴露的“振荡”问题，一种标准的解决方案是引入“滞后效应” (hysteresis)，即为扩容和缩容设置两个间隔开的负载因子阈值。[@problem_id:3238327] 在这个编程实践中，你将亲手实现这种基于滞后效应的重哈希策略，通过代码验证它如何有效地防止性能抖动，构建一个稳定且高效的动态哈希表。", "problem": "要求你设计并实现一个动态哈希表，该哈希表采用基于滞后效应的重哈希策略，即扩容的负载因子阈值高于缩容的阈值。该表必须使用分离链接法来解决冲突，并且所有操作都针对非负整数键。目标是以编程方式验证滞后效应在调整大小过程中的行为和影响，包括其对冲突的影响以及对振荡的避免。\n\n用作基本依据的定义：\n- 哈希表具有容量 $m$（桶的数量）并存储 $n$ 个键。负载因子为 $\\alpha = n/m$。\n- 分离链接法在每个桶 $i \\in \\{0, 1, \\dots, m-1\\}$ 中存储一个列表，其中包含所有哈希值映射到 $i$ 的键。\n- 在插入键 $k$ 的过程中，如果其对应的桶已经包含至少一个键，则发生冲突。该次插入的冲突次数是插入 $k$ 之前桶 $h(k)$ 的当前列表长度。\n- 哈希函数为 $h(k) = k \\bmod m$。\n- 重哈希指选择一个新的容量 $m'$，分配新的空桶，并使用新容量将所有现有键移动到新表中。\n- 调整大小过程中的滞后效应指使用两个阈值，且满足 $ \\alpha_{grow}  \\alpha_{shrink} $。仅当 $\\alpha  \\alpha_{grow}$ 时触发扩容，仅当 $\\alpha  \\alpha_{shrink}$ 时触发缩容。\n\n要求的重哈希策略：\n- 阈值为精确有理数：$ \\alpha_{grow} = p_g / q_g $ 和 $ \\alpha_{shrink} = p_s / q_s $，其中 $ p_g, q_g, p_s, q_s \\in \\mathbb{Z}_{0} $ 且 $ \\alpha_{grow}  \\alpha_{shrink} $。\n- 每次插入后，计算 $\\alpha = n/m$。如果 $\\alpha  \\alpha_{grow}$，则进行扩容：将新容量设置为不小于 $ \\lceil \\gamma_{up} \\cdot m \\rceil $ 的下一个素数，其中 $ \\gamma_{up} = u/v $ 是一个给定的有理数，满足 $u, v \\in \\mathbb{Z}_{0}$ 且 $ \\gamma_{up} \\ge 1 $。然后对所有键进行重哈希。\n- 每次删除后，计算 $\\alpha = n/m$。如果 $\\alpha  \\alpha_{shrink}$ 且 $m  m_{min}$，则进行缩容：将新容量设置为不大于 $ \\lfloor \\gamma_{down} \\cdot m \\rfloor $ 的最大素数，其中 $ \\gamma_{down} = x/y $ 是一个给定的有理数，满足 $x, y \\in \\mathbb{Z}_{0}$ 且 $ \\gamma_{down} \\le 1 $。容量不能缩减到低于最小容量 $ m_{min} $。\n- 容量必须始终为素数。\n- 忽略重复插入（如果键已存在，则不执行任何操作）。删除不存在的键不执行任何操作。\n- 在整个操作序列中跟踪以下统计数据：\n  1. $m_{\\text{final}}$：最终容量。\n  2. $R$：执行的重哈希总次数（扩容与缩容之和）。\n  3. $L_{\\text{max}}$：在任何插入操作时，放置新键之前观察到的最大链长。\n  4. $\\alpha_{\\text{final}}$：最终负载因子 $n/m$，以浮点小数形式报告，四舍五入到三位小数。\n  5. $G_{\\text{eq}}$：一个布尔值，指示是否曾因 $\\alpha = \\alpha_{grow}$ 精确相等而触发扩容；根据指定的规则“仅在 $\\alpha  \\alpha_{grow}$ 时扩容”，该值应为 false。\n\n实现要求：\n- 使用分离链接法，哈希函数为 $h(k) = k \\bmod m$。\n- 对阈值和调整大小的因子（$\\alpha_{grow}$、$\\alpha_{shrink}$、$\\gamma_{up}$、$\\gamma_{down}$）使用精确有理数算术，以便在没有浮点误差的情况下检查诸如 $\\alpha = \\alpha_{grow}$ 之类的相等条件。\n- 调整大小时，对于扩容，选择“不小于...的下一个素数”指定的容量；对于缩容，选择“不大于...的最大素数”指定的容量，并遵守 $m_{min}$ 的限制。\n\n测试套件：\n对于下面的每个测试用例，你必须模拟确切的操作序列并输出指定的结果。\n\n所有测试的通用参数：\n- 扩容因子 $ \\gamma_{up} = 2/1 $。\n- 缩容因子 $ \\gamma_{down} = 1/2 $。\n- 最小容量 $ m_{min} = 5 $。\n\n测试用例：\n- 测试用例 A（正常扩容路径）：\n  - 初始容量 $ m_0 = 7 $。\n  - 阈值：$ \\alpha_{grow} = 3/4 $，$ \\alpha_{shrink} = 1/4 $。\n  - 操作：插入键 $ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 $（十次插入）。\n- 测试用例 B（相等边界，相等时不扩容）：\n  - 初始容量 $ m_0 = 5 $。\n  - 阈值：$ \\alpha_{grow} = 3/5 $，$ \\alpha_{shrink} = 1/5 $。\n  - 操作：插入键 $ 10, 11, 12 $（三次插入）。注意，在第三次插入后，$\\alpha$ 精确等于 $3/5$；验证在相等时不会发生扩容。\n- 测试用例 C（滞后效应避免振荡：大量插入时扩容，然后大量删除后缩容一次）：\n  - 初始容量 $ m_0 = 11 $。\n  - 阈值：$ \\alpha_{grow} = 4/5 $，$ \\alpha_{shrink} = 3/10 $。\n  - 操作：插入键 $ 0, 1, 2, \\dots, 20 $（二十一次插入），然后删除键 $ 11, 12, \\dots, 20 $（十次删除）。\n- 测试用例 D（不缩容至低于最小容量）：\n  - 初始容量 $ m_0 = 5 $。\n  - 阈值：$ \\alpha_{grow} = 7/10 $，$ \\alpha_{shrink} = 1/5 $。\n  - 操作：插入键 $ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 $（十次插入），然后删除键 $ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 $（十次删除）。\n\n输出规范：\n- 对于每个测试用例，计算列表 $[m_{\\text{final}}, R, L_{\\text{max}}, \\alpha_{\\text{final}}, G_{\\text{eq}}]$（如上定义），其中 $\\alpha_{\\text{final}}$ 四舍五入到三位小数。\n- 你的程序应生成单行输出，其中包含按测试用例 $\\mathrm{A}, \\mathrm{B}, \\mathrm{C}, \\mathrm{D}$ 顺序排列的结果，结果为逗号分隔的列表，并用方括号括起。即，打印形如下一行的单行输出：\n  \"[[m_final_A,R_A,Lmax_A,alpha_final_A,Geq_A],[m_final_B,R_B,Lmax_B,alpha_final_B,Geq_B],[m_final_C,R_C,Lmax_C,alpha_final_C,Geq_C],[m_final_D,R_D,Lmax_D,alpha_final_D,Geq_D]]\"。", "solution": "用户希望验证并解决一个关于具有特定滞后重哈希策略的动态哈希表的问题。\n\n### 第 1 步：问题验证\n\n我将首先分析问题陈述以确保其有效性。\n\n**提取的已知条件：**\n\n*   **数据结构**：使用分离链接法的哈希表。键为非负整数。\n*   **哈希函数**：$h(k) = k \\bmod m$，其中 $m$ 是容量。\n*   **负载因子**：$\\alpha = n/m$，其中 $n$ 是键的数量。\n*   **冲突定义**：插入键 $k$ 时，如果其目标桶 $h(k)$ 非空，则发生冲突。冲突次数为插入前该桶中列表的长度。\n*   **统计量 $L_{max}$**：在任何插入操作之前观察到的最大链长。\n*   **滞后阈值**：一个扩容阈值 $\\alpha_{grow} = p_g / q_g$ 和一个缩容阈值 $\\alpha_{shrink} = p_s / q_s$，且 $\\alpha_{grow} > \\alpha_{shrink}$。\n*   **扩容策略**：插入操作后，如果 $\\alpha > \\alpha_{grow}$，则调整表的大小。新容量 $m'$ 是满足 $m' \\ge \\lceil \\gamma_{up} \\cdot m \\rceil$ 的最小素数。\n*   **缩容策略**：删除操作后，如果 $\\alpha  \\alpha_{shrink}$ 且 $m > m_{min}$，则调整表的大小。新容量 $m'$ 是满足 $m' \\le \\lfloor \\gamma_{down} \\cdot m \\rfloor$ 的最大素数。容量不得缩减至低于 $m_{min}$。\n*   **容量属性**：容量 $m$ 必须始终为素数。\n*   **调整大小因子**：$\\gamma_{up} = u/v$ 和 $\\gamma_{down} = x/y$ 是有理数。\n*   **操作**：`insert` 忽略重复项；`delete` 忽略不存在的键。\n*   **算术**：所有阈值和因子计算必须使用精确有理数算术。\n*   **跟踪的统计数据**：\n    1.  $m_{final}$：最终容量。\n    2.  $R$：重哈希总次数。\n    3.  $L_{max}$：插入前的最大链长。\n    4.  $\\alpha_{final}$：最终负载因子，四舍五入到三位小数。\n    5.  $G_{eq}$：一个布尔值，若扩容曾因 $\\alpha = \\alpha_{grow}$ 而触发，则为 `True`。根据给定的规则，该值应为 `False`。\n*   **通用参数**：$\\gamma_{up} = 2/1$, $\\gamma_{down} = 1/2$, $m_{min} = 5$。\n*   **测试用例**：提供了四个具体场景（A, B, C, D），包含初始容量、阈值和操作序列。\n\n**验证结论：**\n\n1.  **科学性/事实性健全度**：该问题在数据结构和算法原理方面有充分的依据。哈希表、分离链接法、负载因子和基于滞后效应的重哈希都是标准且有效的概念。使用素数作为容量是一种常见的启发式方法。所有定义在数学上都是健全的。根据此标准，该问题是有效的。\n2.  **形式化能力/相关性**：该问题是形式化指定的，并且与哈希表设计和分析的主题直接相关。它不是比喻性的或离题的。根据此标准，该问题是有效的。\n3.  **完整性/一致性**：该问题是自包含的。它提供了所有必要的初始条件、参数、规则和操作序列。规则内部一致。根据此标准，该问题是有效的。\n4.  **现实性/可行性**：该问题描述了一个完全可以实现的计算模拟。测试用例的规模很小，在计算上是易于处理的。根据此标准，该问题是有效的。\n5.  **良构性**：该问题是良构的。确定性的规则确保了每个测试用例都有唯一的状态序列和一组唯一的最终统计数据。使用精确有理数算术消除了浮点比较的模糊性。根据此标准，该问题是有效的。\n6.  **平凡性**：该问题并非微不足道。它需要仔细实现状态机，包括数论函数（素数生成）、精确有理数算术，以及在一系列操作中对多个统计数据进行细致的跟踪。测试用例旨在探究特定行为，如扩容、边界条件、滞后效应和最小尺寸约束。根据此标准，该问题是有效的。\n7.  **可验证性**：结果由算法确定，可以通过重新实现指定的逻辑进行独立验证。根据此标准，该问题是有效的。\n\n**结论：**该问题是**有效的**。这是一个结构良好、不平凡且清晰的练习，涉及特定数据结构的实现与分析。我现在将继续进行解决方案。\n\n### 第 2 步：解决方案设计\n\n解决方案将用 Python 实现。一个名为 `HysteresisHashTable` 的类将封装哈希表的逻辑和状态。\n\n**核心组件：**\n\n1.  **素数工具**：将创建辅助函数以支持容量管理策略。\n    *   `is_prime(k)`：一个函数，用于测试整数 $k$ 是否为素数。对于所涉及的小数，试除法到 $\\sqrt{k}$ 就足够了。\n    *   `next_prime(k)`：找到不小于 $k$ 的最小素数。\n    *   `prev_prime(k)`：找到不大于 $k$ 的最大素数。\n\n2.  **精确有理数算术**：将使用 Python 的标准 `fractions` 模块来表示 $\\alpha_{grow}$、$\\alpha_{shrink}$、$\\gamma_{up}$ 和 $\\gamma_{down}$，并执行所有涉及负载因子 $\\alpha$ 的比较，从而避免浮点精度错误。\n\n3.  **`HysteresisHashTable` 类**：\n    *   **状态变量**：\n        *   $m$：当前容量（一个整数）。\n        *   $n$：存储的键数（一个整数）。\n        *   `buckets`：一个列表的列表，表示分离的链。\n        *   `keys`：一个 `set`，用于高效地检查键是否存在（平均时间复杂度为 $O(1)$）。这对于忽略重复插入和删除不存在的键至关重要。\n        *   参数：$\\alpha_{grow}, \\alpha_{shrink}, \\gamma_{up}, \\gamma_{down}, m_{min}$ 将作为属性存储，很可能是 `Fraction` 对象。\n        *   统计数据：将跟踪 $R, L_{max}, G_{eq}$。\n    *   **方法**：\n        *   `__init__(m_0, ...)`：用容量 $m_0$ 和所有必需的参数初始化哈希表。\n        *   `_hash(k)`：返回 $k \\bmod m$。\n        *   `_add_key_internal(k)`：一个私有辅助方法，用于将键添加到桶和键集合中，并增加 $n$。此方法不触发重哈希或更新统计数据，使其在重哈希操作期间可以安全使用。\n        *   `_rehash(new_m)`：管理表的重设大小。它会增加 $R$，用容量 `new_m` 创建一组新桶，并使用 `_add_key_internal` 重新插入所有现有的键。\n        *   `insert(k)`：公共插入方法。\n            1.  如果键 $k$ 已经在 `keys` 集合中，则立即返回。\n            2.  计算哈希索引 $i = h(k)$。\n            3.  通过与 `buckets[i]` 的当前长度比较来更新 $L_{max}$。\n            4.  调用 `_add_key_internal(k)` 添加键。\n            5.  计算新的负载因子 $\\alpha = n/m$。\n            6.  检查是否 $\\alpha > \\alpha_{grow}$。如果是，则计算目标新容量 $m'_{target} = \\lceil \\gamma_{up} \\cdot m \\rceil$，找到下一个素数 $m' = \\text{next\\_prime}(m'_{target})$，并调用 `_rehash(m')`。\n            7.  问题要求检查是否在相等时触发了扩容以更新 $G_{eq}$。虽然扩容规则是严格不等式，但我们将检查是否出现 $\\alpha = \\alpha_{grow}$。根据问题自身的分析，$G_{eq}$ 应保持为 `False`。\n        *   `delete(k)`：公共删除方法。\n            1.  如果键 $k$ 不在 `keys` 集合中，则返回。\n            2.  从 `keys` 集合和其对应的桶中删除该键。\n            3.  递减 $n$。\n            4.  计算新的负载因子 $\\alpha = n/m$。\n            5.  检查是否 $\\alpha  \\alpha_{shrink}$ 且 $m > m_{min}$。如果是，则计算目标新容量 $m'_{target} = \\lfloor \\gamma_{down} \\cdot m \\rfloor$，找到前一个素数 $m' = \\text{prev\\_prime}(m'_{target})$，如果 $m' \\ge m_{min}$，则调用 `_rehash(m')`。\n        *   `get_stats()`：返回最终的统计数据 $[m_{final}, R, L_{max}, \\alpha_{final}, G_{eq}]$。\n\n**模拟与输出：**\n一个主 `solve()` 函数将协调整个过程。它将遍历提供的四个测试用例。对于每个用例，它将：\n1.  使用指定的初始参数实例化 `HysteresisHashTable`。\n2.  执行插入和删除操作序列。\n3.  调用 `get_stats()` 以检索最终结果。\n4.  将每个测试用例的结果格式化为字符串 `\"[m,R,L_max,alpha,Geq]\"`，其中 `alpha` 格式化为三位小数。\n5.  收集这些字符串，并将它们作为单行、逗号分隔、并用外层方括号括起来打印，完全按照输出格式的规定。", "answer": "```python\nimport math\nfrom fractions import Fraction\n\ndef is_prime(n):\n    \"\"\"Checks if a number is prime using trial division.\"\"\"\n    if n = 1:\n        return False\n    if n = 3:\n        return True\n    if n % 2 == 0 or n % 3 == 0:\n        return False\n    i = 5\n    while i * i = n:\n        if n % i == 0 or n % (i + 2) == 0:\n            return False\n        i += 6\n    return True\n\ndef next_prime(n):\n    \"\"\"Finds the smallest prime number >= n.\"\"\"\n    if n = 2:\n        return 2\n    prime = n\n    if prime % 2 == 0:\n        prime += 1\n    while not is_prime(prime):\n        prime += 2\n    return prime\n\ndef prev_prime(n):\n    \"\"\"Finds the largest prime number = n.\"\"\"\n    if n  2:\n        return None  # No primes exist\n    prime = n\n    while not is_prime(prime):\n        prime -= 1\n    return prime\n\nclass HysteresisHashTable:\n    \"\"\"A dynamic hash table with hysteresis-based rehashing.\"\"\"\n\n    def __init__(self, m_0, alpha_grow, alpha_shrink, gamma_up, gamma_down, m_min):\n        self.m = m_0\n        self.n = 0\n        self.buckets = [[] for _ in range(self.m)]\n        self.keys = set()\n        \n        # Parameters\n        self.alpha_grow = Fraction(alpha_grow[0], alpha_grow[1])\n        self.alpha_shrink = Fraction(alpha_shrink[0], alpha_shrink[1])\n        self.gamma_up = Fraction(gamma_up[0], gamma_up[1])\n        self.gamma_down = Fraction(gamma_down[0], gamma_down[1])\n        self.m_min = m_min\n\n        # Statistics\n        self.R = 0\n        self.L_max = 0\n        self.G_eq = False\n\n    def _hash(self, key):\n        return key % self.m\n\n    def _add_key_internal(self, key):\n        \"\"\"Adds a key without triggering rehash or updating stats.\"\"\"\n        idx = self._hash(key)\n        self.buckets[idx].append(key)\n        self.keys.add(key)\n        self.n += 1\n\n    def _rehash(self, new_m):\n        self.R += 1\n        old_keys = list(self.keys)\n        \n        self.m = new_m\n        self.n = 0\n        self.buckets = [[] for _ in range(self.m)]\n        self.keys = set()\n        \n        for key in old_keys:\n            self._add_key_internal(key)\n\n    def insert(self, key):\n        if key in self.keys:\n            return\n\n        idx = self._hash(key)\n        chain_len = len(self.buckets[idx])\n        self.L_max = max(self.L_max, chain_len)\n        \n        self._add_key_internal(key)\n        \n        # Check for growth\n        if self.m > 0:\n            current_alpha = Fraction(self.n, self.m)\n            if current_alpha == self.alpha_grow:\n                # This flag is to verify growth is not triggered at equality.\n                # Per problem, G_eq should remain False.\n                pass \n            if current_alpha > self.alpha_grow:\n                target_m = math.ceil(self.gamma_up * self.m)\n                new_m = next_prime(target_m)\n                self._rehash(new_m)\n\n    def delete(self, key):\n        if key not in self.keys:\n            return\n\n        idx = self._hash(key)\n        self.buckets[idx].remove(key)\n        self.keys.remove(key)\n        self.n -= 1\n\n        # Check for shrink\n        if self.m > self.m_min:\n            if self.m > 0:\n                current_alpha = Fraction(self.n, self.m)\n                if current_alpha  self.alpha_shrink:\n                    target_m = math.floor(self.gamma_down * self.m)\n                    if target_m  self.m_min:\n                        return # Avoid shrinking if target is already too small\n                    new_m = prev_prime(target_m)\n                    if new_m is not None and new_m >= self.m_min:\n                       self._rehash(new_m)\n\n    def get_stats(self):\n        final_alpha_val = float(self.n / self.m) if self.m > 0 else 0.0\n        return [self.m, self.R, self.L_max, final_alpha_val, self.G_eq]\n\ndef run_simulation(params):\n    ht = HysteresisHashTable(\n        m_0=params[\"m_0\"],\n        alpha_grow=params[\"alpha_grow\"],\n        alpha_shrink=params[\"alpha_shrink\"],\n        gamma_up=(2, 1),\n        gamma_down=(1, 2),\n        m_min=5\n    )\n\n    for op, key_range in params[\"operations\"]:\n        if op == 'insert':\n            for k in key_range:\n                ht.insert(k)\n        elif op == 'delete':\n            for k in key_range:\n                ht.delete(k)\n    \n    stats = ht.get_stats()\n    # Round alpha_final to three decimal places\n    stats[3] = round(stats[3], 3)\n    return stats\n\n\ndef solve():\n    test_cases = [\n        {\n            \"m_0\": 7,\n            \"alpha_grow\": (3, 4),\n            \"alpha_shrink\": (1, 4),\n            \"operations\": [('insert', range(10))]\n        },\n        {\n            \"m_0\": 5,\n            \"alpha_grow\": (3, 5),\n            \"alpha_shrink\": (1, 5),\n            \"operations\": [('insert', range(10, 13))]\n        },\n        {\n            \"m_0\": 11,\n            \"alpha_grow\": (4, 5),\n            \"alpha_shrink\": (3, 10),\n            \"operations\": [('insert', range(21)), ('delete', range(11, 21))]\n        },\n        {\n            \"m_0\": 5,\n            \"alpha_grow\": (7, 10),\n            \"alpha_shrink\": (1, 5),\n            \"operations\": [('insert', range(10)), ('delete', range(10))]\n        }\n    ]\n\n    all_results = []\n    for case_params in test_cases:\n        result = run_simulation(case_params)\n        all_results.append(result)\n\n    formatted_results = []\n    for res in all_results:\n        # Format the list into a string, ensuring float has 3 decimal places\n        # and boolean is correctly represented as a string literal.\n        s = f\"[{res[0]},{res[1]},{res[2]},{res[3]:.3f},{str(res[4]).lower()}]\"\n        formatted_results.append(s)\n\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3238327"}, {"introduction": "即使拥有完美的重设尺寸策略，一个糟糕的哈希函数也可能导致灾难性的性能问题，例如所有键都映射到同一个桶中。[@problem_id:3266721] 这项实践模拟了这种“灾难性故障”场景，要求你设计并实现一个紧急恢复协议。你将学习如何通过量化指标检测出故障，并利用通用哈希的强大能力，自动寻找并切换到一个性能有保障的新哈希函数，从而确保数据结构的健壮性。", "problem": "给定一个场景，其中一个使用拉链法的哈希表因哈希函数选择不当而发生灾难性失效。您的任务是设计并实现一个“应急”调整大小和再哈希协议，该协议能够检测灾难性失效，从一个全域哈希函数族中选择新的表大小和新的哈希函数，并对键进行再哈希，直到再哈希后的分布满足一个可证明的、可量化的平衡条件。\n\n所有的推导和决策都必须基于以下公认的基础：\n- 哈希与拉链法的基本定义，包括负载因子和桶占用率。\n- 全域哈希的定义和基本性质：如果对于任意两个不同的键，从一个函数族中均匀选择一个函数，其发生碰撞的概率最多为 $1/m$（其中 $m$ 为表的大小），则该函数族是全域的。\n- 在一个全域函数族和独立均匀选择的条件下，预期的桶占用率等于负载因子，并且以高概率，最大桶的大小受键数量的多对数函数限制。\n\n您的程序必须实现以下协议。\n\n1. 灾难性失效的检测。\n   - 给定初始表容量 $m_0$，一个大小为 $n$ 的整数键多重集，以及一个指定的退化哈希函数 $h_{\\text{bad}}$，使用 $h_{\\text{bad}}$ 计算键在 $m_0$ 个桶中的分布。\n   - 令 $E = \\lceil n / m_0 \\rceil$ 为均匀哈希下的预期占用率。\n   - 令 $M$ 为在 $h_{\\text{bad}}$ 下的最大桶大小。\n   - 当且仅当 $n \\ge 1$ 且满足以下条件时，宣布进入紧急状态：\n     $$ M \\ge \\max\\left(\\left\\lceil \\gamma \\log_2(n+1) \\right\\rceil, \\tau \\cdot E\\right), $$\n     其中 $\\gamma = 2$ 且 $\\tau = 3$。\n   - 如果未宣布紧急状态，则针对该测试用例输出当前配置，不做任何更改。\n\n2. 应急调整大小和再哈希协议（仅在宣布紧急状态时调用）。\n   - 选择目标负载因子 $\\alpha^\\star = 0.75$，并将新容量设置为\n     $$ m' = \\text{next\\_prime}\\left(\\left\\lceil \\frac{n}{\\alpha^\\star} \\right\\rceil\\right). $$\n   - 使用全域哈希函数族\n     $$ h_{a,b}(x) = \\left((a \\cdot x + b) \\bmod p\\right) \\bmod m', $$\n     其中 $p$ 是一个固定的素数，满足 $p > \\max(\\{x\\})$，且 $a \\in \\{1,2,\\dots,p-1\\}$，$b \\in \\{0,1,\\dots,p-1\\}$。\n   - 对于尝试次数 $t = 1,2,\\dots,K_1$（其中 $K_1 = 25$），确定性地生成 $(a,b)$ 对，使用 $h_{a,b}$ 计算桶分布，并测量最大桶大小 $M'$。接受第一个满足以下条件的尝试：\n     $$ M' \\le \\left\\lceil \\beta \\log_2(n+1) \\right\\rceil, $$\n     其中 $\\beta = 3$。\n   - 如果 $K_1$ 次尝试均未成功，则通过 $m' \\leftarrow \\text{next\\_prime}(2m')$ 将容量增加一次，并重复最多额外的 $K_1$ 次尝试。如果仍然不成功，则接受在所有执行的尝试中使 $M'$ 最小化的那次尝试。\n\n3. 输出。\n   - 对于每个测试用例，生成一个包含三个整数的列表 $[m_{\\text{final}}, M_{\\text{final}}, A]$，其中：\n     - $m_{\\text{final}}$ 是协议执行后实际使用的容量（如果未宣布紧急状态，则等于 $m_0$，否则为接受的 $m'$），\n     - $M_{\\text{final}}$ 是在最终选择的哈希下产生的最大桶大小（如果未宣布紧急状态，则等于在 $h_{\\text{bad}}$ 下计算的 $M$），\n     - $A$ 是执行的再哈希尝试次数（如果未宣布紧急状态，则等于 $0$）。\n   - 您的程序应生成单行输出，其中包含这些三整数列表的逗号分隔列表，不含空格，例如，$[[7,3,0],[19,4,6]]$。\n\n用于检测的退化哈希函数。使用以下 $h_{\\text{bad}}$ 选项来构建用于检测的初始分布：\n- 类型 \"constant\": $h_{\\text{bad}}(x) = 0$。\n- 类型 \"identity_mod_power2\": 如果 $m_0$ 是 2 的幂，则 $h_{\\text{bad}}(x) = x \\ (m_0 - 1)$（使用低位比特产生 $x \\bmod m_0$ 的位运算）；否则，$h_{\\text{bad}}(x) = x \\bmod m_0$。\n- 类型 \"mod_small:$k$\": 首先计算 $r = x \\bmod k$，然后放入桶 $r \\bmod m_0$。\n\n参数值。使用固定的素数 $p = 1000000007$。对于全域哈希尝试，根据尝试索引 $t$ 确定性地生成 $(a,b)$ 如下：\n- $a_t = 1 + \\left((t \\cdot 2654435761) \\bmod (p-1)\\right)$,\n- $b_t = \\left(t \\cdot 11400714819323198485\\right) \\bmod p$。\n\n测试套件。您的程序必须计算以下五个案例的结果。\n- 案例 1：$m_0 = 8$，键 $= [0,1,2,\\dots,49]$，$h_{\\text{bad}} =$ \"constant\"。\n- 案例 2：$m_0 = 4$，键 $= []$，$h_{\\text{bad}} =$ \"constant\"。\n- 案例 3：$m_0 = 16$，键 $= [0,1,2,\\dots,15]$，$h_{\\text{bad}} =$ \"identity_mod_power2\"。\n- 案例 4：$m_0 = 7$，键 $= [0,1,2,\\dots,20]$，$h_{\\text{bad}} =$ \"mod_small:$2$\"。\n- 案例 5：$m_0 = 32$，键 $= [0,1024,2048,\\dots,39936]$（由 $[i \\cdot 1024 \\mid i \\in \\{0,1,\\dots,39\\}]$ 构成），$h_{\\text{bad}} =$ \"identity_mod_power2\"。\n\n最终输出格式。\n- 唯一的程序输出行必须是一个表示包含五个三整数列表的单个字符串，每个案例一个，不含空格，例如 $[[m_1,M_1,A_1],[m_2,M_2,A_2],\\dots,[m_5,M_5,A_5]]$。\n\n注。\n- 所有对数均以 2 为底，所有向上取整均为数学上的 ceiling 函数。\n- 本描述中的所有整数和列表都是精确的，必须按规定使用。", "solution": "用户提供了一个定义明确的计算问题，涉及对哈希表灾难性性能的算法检测与恢复。该问题在科学上基于数据结构和算法的原理，特别是哈希表、通过拉链法解决碰撞以及全域哈希。所有参数、条件和过程都得到了无歧义的规定，使得该问题有效且可解。\n\n解决方案首先基于指定的退化哈希函数的性能，实现检测协议。如果检测到失效，则启动应急再哈希协议，以寻找一个新的表容量和来自全域函数族的新哈希函数，从而恢复到一个可证明的平衡状态。\n\n### 第 1 部分：灾难性失效检测\n\n系统的初始状态由一个容量为 $m_0$ 的哈希表和一个包含 $n$ 个整数键的多重集定义。使用一个“坏”哈希函数 $h_{\\text{bad}}$，导致键的分布不佳。\n\n1.  **初始哈希和指标**：我们首先使用 $h_{\\text{bad}}$ 计算 $n$ 个键在 $m_0$ 个桶中的分布。性能的主要指标是最大桶大小，记为 $M$。这代表了哈希表中搜索、插入或删除等操作的最坏情况时间复杂度。\n\n2.  **定义失效阈值**：如果观测到的最大桶大小 $M$ 与一个良好哈希函数所预期的相比过大，则宣布发生灾难性失效。问题为此提供了一个精确的、由两部分组成的条件。\n    *   首先，我们为均匀哈希下的预期性能建立一个基线。每个桶的平均或预期键数是负载因子 $\\alpha = n/m_0$。在此背景下，我们使用整数值的预期占用率 $E = \\lceil n / m_0 \\rceil$。问题的一个初步迹象是最大负载 $M$ 显著大于此平均值，我们将其量化为 $M \\ge \\tau \\cdot E$，其中乘数 $\\tau=3$。\n    *   其次，我们使用来自全域哈希分析的理论界限。对于从全域函数族中均匀选择的哈希函数，最大桶占用率以高概率受 $n$ 的多对数函数限制。问题将此形式化为一个界限 $L = \\lceil \\gamma \\log_2(n+1) \\rceil$，参数为 $\\gamma=2$。如果哈希表的最坏情况占用率 $M$ 超过了这个理论上的“良好”最坏情况，则认为其性能是灾难性的。\n\n3.  **检测规则**：紧急情况条件结合了这两项检查。当且仅当表不为空 ($n \\ge 1$) 且最大桶大小 $M$ 大于或等于按比例调整的平均值和理论界限中的较大值时，宣布进入紧急状态：\n    $$ M \\ge \\max\\left(\\left\\lceil \\gamma \\log_2(n+1) \\right\\rceil, \\tau \\cdot E\\right) $$\n    其中 $\\gamma = 2$ 且 $\\tau = 3$。如果不满足此条件，则认为表配置可接受，不采取任何行动。报告的结果为 $[m_0, M, 0]$。\n\n### 第 2 部分：应急再哈希协议\n\n如果宣布紧急状态，则启动恢复协议以创建一个新的、性能良好的哈希表。\n\n1.  **新容量选择**：哈希性能不佳的一个关键原因是负载因子过高，或者表大小与键分布之间存在不幸的关系。该协议首先确定一个新的表容量 $m'$。\n    *   它以一个保守的负载因子 $\\alpha^\\star = 0.75$ 为目标。这确保了表不会过于拥挤。\n    *   实现这一目标所需的最小容量是 $\\lceil n / \\alpha^\\star \\rceil$。\n    *   为了进一步改善哈希的统计特性，尤其是在模运算方面，新容量被选为一个素数。因此，新容量为 $m' = \\text{next\\_prime}(\\lceil n/\\alpha^\\star \\rceil)$。\n\n2.  **迭代搜索良好哈希函数**：该协议采用一个标准的全域哈希函数族：\n    $$ h_{a,b}(x) = \\left((a \\cdot x + b) \\bmod p\\right) \\bmod m' $$\n    在这里，$p$ 是一个比任何键都大的大素数 ($p = 1000000007$)，参数 $a \\in \\{1, 2, \\dots, p-1\\}$ 和 $b \\in \\{0, 1, \\dots, p-1\\}$ 定义了该函数族中的一个特定函数。协议没有随机选择 $(a, b)$，而是指定了一个确定性过程，根据尝试索引 $t = 1, 2, \\dots$ 生成一系列对 $(a_t, b_t)$：\n    *   $a_t = 1 + \\left((t \\cdot 2654435761) \\bmod (p-1)\\right)$\n    *   $b_t = \\left(t \\cdot 11400714819323198485\\right) \\bmod p$\n\n    对于每个生成的函数 $h_{a_t, b_t}$，我们将所有 $n$ 个键再哈希到大小为 $m'$ 的新表中，并计算产生的最大桶大小 $M'$。如果 $M'$ 满足一个质量标准，则该尝试被视为成功，该标准同样基于理论对数界限：\n    $$ M' \\le \\left\\lceil \\beta \\log_2(n+1) \\right\\rceil $$\n    参数为 $\\beta = 3$。第一个满足此条件的尝试 $t$ 被接受。过程停止，结果为 $[m', M', t]$。\n\n3.  **升级与最终确定**：虽然统计上不太可能，但最初的 $K_1=25$ 次尝试可能全部失败。\n    *   如果在 $K_1$ 次尝试后未找到成功的函数，协议将通过大幅降低负载因子来进行升级。容量更新为 $m' \\leftarrow \\text{next\\_prime}(2m')$，从而有效地将负载因子减半。\n    *   使用这个新的、更大的容量再进行额外的 $K_1 = 25$ 次尝试。\n    *   如果在此第二阶段找到一个成功的函数，协议终止，并报告新的 $m'$、成功的 $M'$ 和总尝试次数。\n    *   如果在总共 $2K_1$ 次尝试后，没有函数满足成功标准，协议通过选择（在所有 $2K_1$ 次尝试中）产生最小 $M'$ 的那次尝试来保证终止，而不管它是否满足正式的成功界限。然后报告这个“尽力而为”的结果。\n\n这个全面的协议确保了任何灾难性失效不仅能被检测到，还能以一种确定性、有限且稳健的方式得到解决，从而产生一个具有可证明的良好性能特征的哈希表。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\n\ndef is_prime(n):\n    \"\"\"\n    Primality test using trial division. Sufficient for the problem constraints.\n    \"\"\"\n    if n = 1:\n        return False\n    if n = 3:\n        return True\n    if n % 2 == 0 or n % 3 == 0:\n        return False\n    i = 5\n    while i * i = n:\n        if n % i == 0 or n % (i + 2) == 0:\n            return False\n        i += 6\n    return True\n\ndef next_prime(n):\n    \"\"\"\n    Finds the first prime number >= n.\n    \"\"\"\n    if n = 2:\n        return 2\n    prime = n\n    if prime % 2 == 0:\n        prime += 1\n    while not is_prime(prime):\n        prime += 2\n    return prime\n\ndef h_constant(x, m):\n    \"\"\"Degenerate hash function: constant.\"\"\"\n    return 0\n\ndef h_identity_mod_power2(x, m):\n    \"\"\"Degenerate hash function: identity modulo, optimized for powers of 2.\"\"\"\n    if (m > 0) and ((m  (m - 1)) == 0):  # Check if m is a power of 2\n        return x  (m - 1)\n    else:\n        return x % m\n\ndef h_mod_small(x, m, k):\n    \"\"\"Degenerate hash function: modulo a small number first.\"\"\"\n    r = x % k\n    return r % m\n\ndef get_bucket_distribution(keys, m, h_type, **kwargs):\n    \"\"\"Computes the distribution of keys into buckets.\"\"\"\n    if m == 0 or not keys:\n        return np.zeros(m, dtype=int)\n    \n    buckets = np.zeros(m, dtype=int)\n    \n    if h_type == 'constant':\n        for _ in keys:\n            buckets[h_constant(0, m)] += 1\n    elif h_type == 'identity_mod_power2':\n        for key in keys:\n            buckets[h_identity_mod_power2(key, m)] += 1\n    elif h_type.startswith('mod_small'):\n        k_val = int(h_type.split(':')[1])\n        for key in keys:\n            buckets[h_mod_small(key, m, k=k_val)] += 1\n    elif h_type == 'universal':\n        a = kwargs['a']\n        b = kwargs['b']\n        p = kwargs['p']\n        for key in keys:\n            hash_val = ((a * key + b) % p) % m\n            buckets[hash_val] += 1\n            \n    return buckets\n\ndef solve():\n    \"\"\"\n    Main solver function to process all test cases according to the defined protocol.\n    \"\"\"\n    test_cases = [\n        {'m0': 8, 'keys': list(range(50)), 'h_bad': \"constant\"},\n        {'m0': 4, 'keys': [], 'h_bad': \"constant\"},\n        {'m0': 16, 'keys': list(range(16)), 'h_bad': \"identity_mod_power2\"},\n        {'m0': 7, 'keys': list(range(21)), 'h_bad': \"mod_small:2\"},\n        {'m0': 32, 'keys': [i * 1024 for i in range(40)], 'h_bad': \"identity_mod_power2\"},\n    ]\n\n    p = 1000000007\n    gamma = 2.0\n    tau = 3.0\n    alpha_star = 0.75\n    beta = 3.0\n    K1 = 25\n    a_const = 2654435761\n    b_const = 11400714819323198485\n\n    all_results = []\n\n    for case in test_cases:\n        m0 = case['m0']\n        keys = case['keys']\n        h_bad = case['h_bad']\n        n = len(keys)\n\n        if n == 0:\n            all_results.append([m0, 0, 0])\n            continue\n\n        # Step 1: Detection\n        initial_buckets = get_bucket_distribution(keys, m0, h_bad)\n        M = int(np.max(initial_buckets)) if initial_buckets.size > 0 else 0\n\n        E = math.ceil(n / m0) if m0 > 0 else float('inf')\n        log_bound = math.ceil(gamma * math.log2(n + 1))\n        emergency_threshold = max(log_bound, tau * E)\n        \n        is_emergency = (n >= 1) and (M >= emergency_threshold)\n\n        if not is_emergency:\n            all_results.append([m0, M, 0])\n            continue\n            \n        # Step 2: Emergency Protocol\n        m_prime = next_prime(math.ceil(n / alpha_star))\n        success_bound = math.ceil(beta * math.log2(n + 1))\n        \n        attempts_count = 0\n        best_result = None\n        min_M_prime = float('inf')\n        found_solution = False\n\n        for phase in range(2):\n            if found_solution:\n                break\n            \n            for t_in_phase in range(1, K1 + 1):\n                attempts_count += 1\n                t = (phase * K1) + t_in_phase\n\n                a_t = 1 + ((t * a_const) % (p - 1))\n                b_t = (t * b_const) % p\n\n                new_buckets = get_bucket_distribution(keys, m_prime, 'universal', a=a_t, b=b_t, p=p)\n                M_prime = int(np.max(new_buckets))\n\n                if M_prime  min_M_prime:\n                    min_M_prime = M_prime\n                    best_result = [m_prime, M_prime, attempts_count]\n\n                if M_prime = success_bound:\n                    all_results.append([m_prime, M_prime, attempts_count])\n                    found_solution = True\n                    break\n            \n            if not found_solution:\n                m_prime = next_prime(2 * m_prime)\n\n        if not found_solution:\n            all_results.append(best_result)\n    \n    # Final output formatting\n    output_str = '[' + ','.join([str(r) for r in all_results]) + ']'\n    output_str = output_str.replace(' ', '')\n    print(output_str)\n\nsolve()\n```", "id": "3266721"}]}