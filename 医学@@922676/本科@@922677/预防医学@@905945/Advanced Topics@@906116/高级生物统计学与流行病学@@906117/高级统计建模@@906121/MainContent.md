## 引言
在预防医学与公共卫生的研究实践中，我们面对的数据往往不是孤立的观测点，而是具有复杂的内在结构。无论是来自不同诊所的患者数据，还是对同一个人随时间进行的重复测量，这些数据都呈现出层次性或纵向性，违背了传统统计方法所要求的独立性假设。忽略这种数据内部的依赖性，会系统性地低估[标准误](@entry_id:635378)，导致我们更容易做出错误的[科学推断](@entry_id:155119)，从而可能影响公共卫生决策的有效性。

本文旨在填补这一知识空白，系统介绍专为处理此类复杂数据而设计的高级统计建模方法。通过学习本文，读者将能够理解并运用这些强大的工具，从复杂数据中提取可靠且有意义的见解。

文章分为三个核心部分。在“**原理与机制**”一章中，我们将深入探讨支撑这些模型的基础理论，包括如何量化组内相似性、固定效应与随机效应的区别，以及线性与广义[线性混合模型](@entry_id:139702)的构建逻辑。接着，在“**应用与跨学科连接**”一章中，我们将通过丰富的实例，展示这些模型在评估干预效果、分析纵向轨迹、处理缺失数据和空间依赖性等真实科研场景中的应用。最后，“**动手实践**”部分将提供一系列精心设计的问题，帮助读者巩固理论知识并将其转化为实践技能。

现在，让我们从构建这些模型的基础——理解其核心原理与机制开始。

## 原理与机制

在预防医学和公共卫生研究中，我们收集的数据常常具有内在的依赖性。与经典[统计模型](@entry_id:755400)假设的独立观测不同，这些数据往往呈现出层次（hierarchical）或纵向（longitudinal）的结构。例如，患者嵌套在诊所中，诊所又嵌套在地区内；或者，对同一个体在不同时间点进行重复测量。这些结构导致同一组（或同一个体）内的观测数据彼此相关，而非相互独立。忽略这种相关性会导致错误的推断，例如标准误被低估，从而增加了犯[第一类错误](@entry_id:163360)的风险。高级[统计模型](@entry_id:755400)，特别是[多水平模型](@entry_id:171741)和纵向数据模型，正是为妥善处理这类依赖性数据而设计的。本章将深入探讨支撑这些模型的核心原理与关键机制。

### 层次结构数据的形式化表达

在深入模型本身之前，我们必须建立一套精确的语言来描述和组织层次化数据。这不仅是进行计算的必要前提，更是清晰思考模型结构的基础。想象一个公共卫生机构在多个地区评估一项预防性筛查项目，其[数据结构](@entry_id:262134)天然地分为三个层次：患者（第一层）在诊所（第二层）就诊，而诊所（第三层）则分布在不同地区。

为了在数学上严谨地表示这种**嵌套结构（nested structure）**，我们需要使用一套能够反映隶属关系的索引系统。与简单的交叉设计不同，嵌套索引表明了低层次单位完全包含在高层次单位之内。对于上述三层结构，一个通用且灵活的表示方法如下 [@problem_id:4502125]：

1.  **索引与范围**：
    *   首先，我们定义最高层次的单位——地区。假设有 $K$ 个地区，我们用索引 $k$ 来表示，其中 $k \in \{1, 2, \dots, K\}$。
    *   接下来是第二层次的单位——诊所。由于每个地区的诊所数量可能不同，这是一个**非均衡设计（unbalanced design）**。我们定义在地区 $k$ 内有 $J_k$ 个诊所，用索引 $j$ 表示，其中 $j \in \{1, 2, \dots, J_k\}$。一个特定的诊所由索引对 $(j, k)$ 唯一确定。
    *   最后是最低层次的单位——患者。同样，每个诊所的患者数量也可能不同。我们定义在地区 $k$ 的诊所 $j$ 中有 $n_{jk}$ 名患者，用索引 $i$ 表示，其中 $i \in \{1, 2, \dots, n_{jk}\}$。一个特定的患者由索引三元组 $(i, j, k)$ 唯一确定。

2.  **变量与协变量**：
    *   **结局变量（Outcome Variable）**：结局变量在最低层次（即患者层面）进行测量。我们用 $y_{ijk}$ 表示患者 $(i, j, k)$ 的健康结局，例如筛查依从性得分。
    *   **协变量（Covariates）**：协变量可以存在于任何层次。
        *   **第一层（患者）协变量**：这些变量因人而异，如年龄、性别等。我们用一个向量 $x_{ijk} \in \mathbb{R}^p$ 来表示。
        *   **第二层（诊所）协变量**：这些变量对于同一诊所内的所有患者是相同的，但在不同诊所间可能不同，如诊所的类型或人员配置。我们用向量 $z_{jk} \in \mathbb{R}^q$ 表示，注意这里没有患者索引 $i$。
        *   **第三层（地区）协变量**：这些变量对于同一地区内的所有诊所和患者都是相同的，如地区的政策或经济水平。我们用向量 $w_k \in \mathbb{R}^r$ 表示，这里既没有患者索引 $i$ 也没有诊所索引 $j$。

3.  **数据堆叠（Stacked Arrays）**：
    为了适用于统计软件进行建模，数据通常需要被整理成“长格式（long format）”，其中每一行对应一个第一层单位（患者）。总样本量为所有诊所中患者数量的总和，即 $N = \sum_{k=1}^{K} \sum_{j=1}^{J_k} n_{jk}$。
    *   结局变量向量 $Y$ 是一个 $N \times 1$ 的列向量，通过堆叠所有 $y_{ijk}$ 得到。
    *   患者层面的协变量矩阵 $X$ 是一个 $N \times p$ 的矩阵，其每一行对应一个患者的 $x_{ijk}^\top$。
    *   高层次的协变量需要被**提升（uplifted）**以匹配行数。例如，诊所层面的协变量矩阵 $Z^{\uparrow}$ 是一个 $N \times q$ 的矩阵，其中诊所 $(j,k)$ 的协变量向量 $z_{jk}^\top$ 会被重复 $n_{jk}$ 次，对应于该诊所的每一位患者。同理，地区层面的协变量矩阵 $W^{\uparrow}$ 是一个 $N \times r$ 的矩阵，其中地区 $k$ 的协变量向量 $w_k^\top$ 会被重复 $\sum_{j=1}^{J_k} n_{jk}$ 次。

这种形式化的表达是构建和解释[多水平模型](@entry_id:171741)的第一步。

### 量化组内相似性：组内[相关系数](@entry_id:147037)（ICC）

认识到数据的层次结构后，下一个自然的问题是：组内的观测数据到底有多相似？**组内相关系数（Intraclass Correlation Coefficient, ICC）**，通常用 $\rho$ 表示，正是回答这个问题的核心指标。它量化了由[数据聚类](@entry_id:265187)（clustering）所引起的依赖性程度。

为了理解ICC，我们从一个简单的两水平**随机截距模型（random-intercept model）**入手。假设我们研究患者 $i$ 在诊所 $j$ 的某项健康指标 $Y_{ij}$，模型可以写为 [@problem_id:4502099]：
$$
Y_{ij} = \beta_0 + u_j + \epsilon_{ij}
$$
其中：
*   $\beta_0$ 是所有诊所的平均结局，称为**固定效应（fixed effect）**。
*   $u_j$ 是诊所 $j$ 特有的效应，代表了该诊所平均水平与总体平均水平 $\beta_0$ 的偏离。我们假设 $u_j$ 是一个随机变量，服从均值为0、方差为 $\sigma_u^2$ 的正态分布，即 $u_j \sim \mathcal{N}(0, \sigma_u^2)$。这被称为**随机效应（random effect）**。
*   $\epsilon_{ij}$ 是患者 $i$ 相对于其所在诊所平均水平的个体变[异或](@entry_id:172120)测量误差，假设 $\epsilon_{ij} \sim \mathcal{N}(0, \sigma_\epsilon^2)$。
*   我们还假设 $u_j$ 和 $\epsilon_{ij}$ 相互独立。

在这个模型中，结局变量 $Y_{ij}$ 的总方差可以分解为两个部分：
$$
\text{Var}(Y_{ij}) = \text{Var}(u_j) + \text{Var}(\epsilon_{ij}) = \sigma_u^2 + \sigma_\epsilon^2
$$
其中，$\sigma_u^2$ 是**[组间方差](@entry_id:175044)（between-cluster variance）**，它衡量了不同诊所平均水平的变异程度；$\sigma_\epsilon^2$ 是**[组内方差](@entry_id:177112)（within-cluster variance）**，它衡量了同一诊所内个体间的变异程度。

ICC由此被定义为[组间方差](@entry_id:175044)占总方差的比例：
$$
\text{ICC} = \rho = \frac{\sigma_u^2}{\sigma_u^2 + \sigma_\epsilon^2}
$$

ICC具有两个等价且至关重要的解释：
1.  **方差分解的比例**：ICC代表了结局变量的总变异中，可以归因于组间（例如，诊所间）差异的部分。一个高的ICC意味着诊所间的差异很大，而诊所内的个体则相对同质。
2.  **组内相关性的度量**：ICC等于从同一个组（诊所）中随机抽取的两个不同个体（例如，患者 $k$ 和 $l$）其结局之间[相关系数](@entry_id:147037)的[期望值](@entry_id:150961)，即 $\rho = \text{Corr}(Y_{kj}, Y_{lj})$。

例如，假设一项关于预防筛查依从性得分的研究发现，诊所间的[方差分量](@entry_id:267561)估计为 $\hat{\sigma}_u^2 = 9$，而诊所内的[方差分量](@entry_id:267561)为 $\hat{\sigma}_\epsilon^2 = 36$。那么ICC的估计值为 [@problem_id:4502099]：
$$
\text{ICC} = \frac{9}{9 + 36} = \frac{9}{45} = 0.20
$$
这意味着依从性得分总变异的 $20\%$ 可归因于诊所间的差异。同时，这也表示从同一家诊所随机抽取的两名患者，其依从性得分的[相关系数](@entry_id:147037)约为 $0.20$。

### 聚类设计的统计代价：设计效应（Design Effect）

ICC的存在并非只是一个描述性统计量，它对统计推断有着实实在在的影响。在**整群随机试验（cluster-randomized trial）**等设计中，由于组内个体并非相互独立，一个包含 $n$ 个个体的聚类样本所提供的信息量要少于一个同样大小的简单随机样本。**设计效应（Design Effect, DE）**正是量化这种信息损失的指标。

设计效应被定义为在聚类抽样下某个估计量（如总体均值）的方差与在同样样本量下简单[随机抽样](@entry_id:175193)（Simple Random Sampling, SRS）中该[估计量方差](@entry_id:263211)的比值。假设每个聚类（诊所）的大小相等，均为 $m$，那么设计效应的经典公式为 [@problem_id:4502144]：
$$
DE = 1 + (m - 1) \times \text{ICC}
$$
这个公式清晰地揭示了影响[统计效率](@entry_id:164796)损失的两个因素：
*   **聚类大小 ($m$)**：聚类越大，组内相关个体越多，信息冗余度越高，设计效应越大。
*   **组内相关性 (ICC)**：组内个体相似度越高，每个新增个体提供的新信息就越少，设计效应也越大。

如果 ICC=0，则 DE=1，说明组内没有相关性，聚类抽样等价于简单[随机抽样](@entry_id:175193)。但只要 ICC>0 且 $m>1$，DE就会大于1。这意味着[估计量的方差](@entry_id:167223)被“膨胀”了 $DE$ 倍，其标准误则被乘以 $\sqrt{DE}$。为了达到与简单[随机抽样](@entry_id:175193)相同的统计精度，聚类设计所需的样本量会更大。相应地，一个大小为 $n$ 的聚类样本，其**有效样本量（effective sample size）**仅为 $n_{\text{eff}} = n / DE$。

### 线性混合模型（LMM）

既然我们已经认识到[数据依赖](@entry_id:748197)性的存在及其后果，那么应该如何建立模型来正确处理它呢？对于连续型结局变量，**[线性混合模型](@entry_id:139702)（Linear Mixed Model, LMM）**是最核心的工具。

#### 模型的理论基础：可交换性

LMM的理论基石是**可交换性（exchangeability）**。一个随机变量序列被称为可交换的，如果其联合概率分布在任意调换序列中元素的顺序后保持不变。根据伟大的数学家 Bruno de Finetti 的定理，一个无限可交换的序列可以被表示为独立同分布（i.i.d.）序列的混合。在[多水平模型](@entry_id:171741)的语境下，这意味着如果我们认为研究中的诊所（或学校、社区等）是从一个更大的诊所群体中抽取的样本，并且我们没有理由先验地认为某个诊所会比其他诊所“更好”或“更差”（即它们的标签可以互换），那么我们就可以将这些诊所视为可交换的。这种[可交换性](@entry_id:263314)的假设，为我们将诊所特有的效应建模为从一个共同分布中抽取的**随机效应**提供了理论依据 [@problem_id:4502183]。

更现实地，诊所间可能存在已知的系统性差异（如诊所规模、地理位置等）。在这种情况下，我们在控制了这些已知协变量后，可以假设剩余的、未被观测的诊所效应是可交换的。这被称为**条件可交换性（conditional exchangeability）**。

#### 固定效应 vs. 随机效应

在构建模型时，一个核心决策是如何处理聚类（如诊所）带来的异质性。我们面临两种选择：固定效应（Fixed Effects, FE）和随机效应（Random Effects, RE）。

让我们考虑一个面板数据集，其中我们追踪了 $J$ 个诊所在 $T$ 个时间点上的疫苗接种率 $y_{jt}$，同时有名为 $z_{jt}$ 的随时间变化的协变量（如宣传活动强度）和名为 $s_j$ 的不随时间变化的诊所层面协变量（如人员配备比例） [@problem_id:4502130]。

*   **[固定效应模型](@entry_id:142997)**：将每个诊所的特定效应视为一个待估计的、固定的参数 $\alpha_j$。模型形如 $y_{jt} = \alpha_j + \beta z_{jt} + \epsilon_{jt}$。这等同于为每个诊所引入一个[虚拟变量](@entry_id:138900)。
    *   **优点**：这种方法非常稳健。因为它为每个诊所估计了独有的截距，所以它自动控制了所有不随时间变化的诊所层面混杂因素，无论这些因素是否被观测到。如果未观测的诊所特征（如管理文化）与宣传活动强度 $z_{jt}$ 相关，F[E模](@entry_id:160271)型可以提供对 $\beta$ 的无偏估计。
    *   **缺点**：F[E模](@entry_id:160271)型的主要代价是它无法估计任何不随时间变化的协变量（如 $s_j$）的效应，因为这些变量与诊所的[虚拟变量](@entry_id:138900)存在完全共线性。此外，其推断仅限于样本内的这 $J$ 个诊所，难以推广到更广泛的诊所群体。

*   **[随机效应模型](@entry_id:143279)**：将诊所的特定效应视为从一个共同分布（如 $\mathcal{N}(0, \sigma_b^2)$）中抽取的随机变量 $b_j$。模型形如 $y_{jt} = (\alpha_0 + b_j) + \beta z_{jt} + \gamma s_j + \epsilon_{jt}$。
    *   **优点**：R[E模](@entry_id:160271)型更有效率（即[估计量的方差](@entry_id:167223)更小），因为它利用了组间和组内的双重信息。它允许我们估计不随时间变化的协变量（如 $s_j$）的效应 $\gamma$。同时，由于假设诊所来自一个更大的群体，模型的推断结果可以推广到该群体，而不仅限于样本内的诊所。
    *   **缺点**：RE模型的有效性依赖一个**关键且很强的假设**：随机效应 $b_j$ 与模型中的所有协变量（$z_{jt}$ 和 $s_j$）都不相关。如果这个假设不成立（例如，更高质量的诊所同时拥有更好的人员配备和更强的宣传活动意愿），R[E模](@entry_id:160271)型对 $\beta$ 和 $\gamma$ 的估计将会产生偏误。

总结来说 [@problem_id:4502130]，当主要目标是控制所有不随时间变化的混杂因素，或者当有理由相信未观测的群组特征与解释变量相关时，[固定效应模型](@entry_id:142997)是更安全的选择。而当研究兴趣在于估计群组层面变量的效应，或者希望将结论推广到更大的群体，并且随机效应与协变量的独立性假设是合理的，那么[随机效应模型](@entry_id:143279)是更优选。

#### 随机截距与随机斜率模型

LMM的强大之处在于其灵活性。除了为每个聚类（或个体）设定一个随机截距外，我们还可以允许其变化趋势（斜率）也是随机的。这在纵向数据分析中尤其有用。

考虑一项预防医学研究，追踪一群患者多年的血压变化。$y_{ij}$ 表示个体 $j$ 在时间点 $i$ 的血压值，$t_{ij}$ 是自基线以来的时间。一个**随机截距与随机斜率模型**可以表示为 [@problem_id:4502166]：
$$
y_{ij} = (\beta_0 + u_{0j}) + (\beta_1 + u_{1j}) t_{ij} + \epsilon_{ij}
$$
该模型各部分的解释如下：
*   **固定效应部分 ($\beta_0 + \beta_1 t_{ij}$)**：这描述了整个**群体（population）**的平均变化轨迹。
    *   $\beta_0$ 是群体在基线时（$t=0$）的平均血压。
    *   $\beta_1$ 是群体血压随时间变化的平均速率（平均斜率）。
*   **随机效应部分 ($u_{0j} + u_{1j} t_{ij}$)**：这捕捉了每个**个体（individual）**与群体平均轨迹的偏离。
    *   $u_{0j}$ 是个体 $j$ 的**随机截距**，表示其基线血压与群体平均基线血压的差异。
    *   $u_{1j}$ 是个体 $j$ 的**随机斜率**，表示其血压变化速率与群体平均速率的差异。
*   **残差项 ($\epsilon_{ij}$)**：这代表了个体 $j$ 在特定时间点 $i$ 的观测值与其自身长期变化轨迹的随机偏离，可视为短期生理波动或测量误差。

这个模型不仅能告诉我们群体平均的血压变化趋势，还能揭示个体间在初始水平和变化速率上的异质性，并可以估计这两者之间的相关性（即 $u_{0j}$ 和 $u_{1j}$ 的协方差）。

#### 贝叶斯视角：部分汇集与收缩

[随机效应模型](@entry_id:143279)与贝叶斯方法有着深刻的联系。从贝叶斯的角度看，[随机效应模型](@entry_id:143279)可以被视为一种**部分汇集（partial pooling）**策略。

考虑一个简化的正态[分层模型](@entry_id:274952) [@problem_id:4502097]：我们想估计诊所 $j$ 的真实平均效应 $\alpha_j$。我们有两个信息来源：
1.  **数据（似然）**：来自诊所 $j$ 的观测数据，其样本均值为 $\bar{y}_j$。这是一个“局部”的、仅基于该诊所信息的估计（称为“无汇集”估计）。其抽样方差为 $\sigma^2/n_j$。
2.  **先验**：关于所有诊所效应 $\alpha_j$ 来自一个共同群体（均值为 $\mu$，方差为 $\tau^2$）的知识。这是一个“全局”的估计（称为“完全汇集”估计）。

贝叶斯推断通过[贝叶斯定理](@entry_id:151040)将这两者结合起来，得到 $\alpha_j$ 的后验分布。其后验均值（即对 $\alpha_j$ 的最终估计）是似然信息和先验信息的**精度加权平均（precision-weighted average）**：
$$
E[\alpha_j \mid \text{data}] = w_j \bar{y}_j + (1-w_j)\mu
$$
其中权重 $w_j = \frac{n_j\tau^2}{n_j\tau^2 + \sigma^2}$。这个公式优美地展示了**收缩（shrinkage）**或**[借力](@entry_id:167067)（borrowing strength）**的现象：
*   对诊所 $j$ 的最终估计 $\hat{\alpha}_j$ 被从其局部均值 $\bar{y}_j$ 向[总体均值](@entry_id:175446) $\mu$ “拉近”或“收缩”。
*   收缩的程度取决于信息的相对强度。如果诊所 $j$ 的样本量 $n_j$ 很大，或者诊所内部变异 $\sigma^2$ 很小，那么权重 $w_j$ 趋近于1，估计就更依赖于本诊所的数据（收缩较少）。反之，如果 $n_j$ 很小，估计就会被强烈地拉向[总体均值](@entry_id:175446)（收缩较多）。

这种机制非常有用。对于样本量小的诊所，其观测均值可能因随机性而表现出极端值。部分汇集通过借鉴其他所有诊所的信息，对此类极端值进行平滑，从而提供更稳定、更可靠的估计。分析表明，这种[收缩估计](@entry_id:636807)的后验方差总是小于无汇集估计的方差，从而提高了估计精度 [@problem_id:4502097]。

### 模型估计：ML vs. REML

LMM中的参数分为两类：固定效应 $\beta$ 和[方差分量](@entry_id:267561) $\theta$（包括随机效应方差和残差方差）。对它们的估计通常采用**最大似然（Maximum Likelihood, ML）**或**限制性[最大似然](@entry_id:146147)（Restricted Maximum Likelihood, REML）**方法 [@problem_id:4502150]。

*   **[最大似然](@entry_id:146147)（ML）**：ML旨在找到使观测数据的[联合似然](@entry_id:750952)函数最大化的参数值 $(\beta, \theta)$。然而，ML在估计[方差分量](@entry_id:267561)时存在一个问题：它将固定效应的估计值 $\hat{\beta}$ 当作真实值，没有考虑因估计 $\beta$ 而损失的自由度。这导致[方差分量](@entry_id:267561)的估计通常存在向下的偏误，尤其是在样本量较小时。

*   **限制性最大似然（REML）**：REML是一种旨在修正ML偏误的方法。其核心思想是，将数据进行变换，得到一组与固定效应 $\beta$ 无关的**误差对比（error contrasts）**。然后，基于这些变换后数据的似然（称为限制性似然）来估计[方差分量](@entry_id:267561) $\theta$。从贝叶斯角度看，这等价于将 $\beta$ 从全似然函数中积分掉。通过这种方式，REML在估计方差时“考虑”到了固定效应的存在，其估计量具有更小的偏误。因此，在估计LMM的[方差分量](@entry_id:267561)时，REML通常是首选方法。

### 扩展到非连续结局：GLMM 与 GEE

预防医学中的许多结局变量是二元的（如是否接种疫苗、是否吸烟）或计数的（如疾病发作次数）。对于这类数据，LMM需要被推广到**广义[线性混合模型](@entry_id:139702)（Generalized Linear Mixed Model, GLMM）**。

#### 广义线性混合模型（GLMM）

GLMM将LMM与广义线性模型（GLM）结合起来。以一个研究疫苗接种意愿的二元结局为例，一个随机截距逻辑斯蒂克混合模型可以表示为 [@problem_id:4502115]：
$$
\operatorname{logit}(P(Y_{ij}=1 \mid x_{ij}, u_j)) = \beta_0 + \beta_1 x_{ij} + u_j
$$
其中 $p_{ij}$ 是在给定协变量 $x_{ij}$ 和诊所随机效应 $u_j$ 条件下，患者接种疫苗的概率。

这里出现了一个至关重要的概念分野：**条件性（Conditional）效应**与**边际（Marginal）效应**的区别。
*   **条件性效应**：模型中的系数 $\beta_1$ 具有条件性解释。$\exp(\beta_1)$ 是一个**条件优势比（conditional odds ratio）**，它衡量的是在**同一家诊所内**（即给定 $u_j$），暴露组（$x_{ij}=1$）相对于非暴露组（$x_{ij}=0$）接种疫苗的优势比。这个效应是**诊所特异性（cluster-specific）**的。

*   **[边际效应](@entry_id:634982)**：在政策评估中，我们通常更关心一个效应在**整个群体（population）**中的平均影响，即[边际效应](@entry_id:634982)。[边际概率](@entry_id:201078)需要通过对随机效应 $u_j$ 的所有可[能值](@entry_id:187992)进行积分（或求期望）来得到：
    $$
    P(Y_{ij}=1 \mid x_{ij}) = \mathbb{E}_{u_j}[P(Y_{ij}=1 \mid x_{ij}, u_j)] = \int \operatorname{logit}^{-1}(\beta_0 + \beta_1 x_{ij} + u) f(u) du
    $$
    由于Logit函数是非线性的，这个积分通常没有封闭解。更重要的是，由这些[边际概率](@entry_id:201078)计算出的**边际优势比（marginal odds ratio）**通常**不等于**条件优势比 $\exp(\beta_1)$。这种现象被称为优势比的**不可坍缩性（non-collapsibility）**。即使随机效应与协变量完全独立，[边际效应](@entry_id:634982)（在优势比尺度上）也会比条件效应更“衰减”或更接近于1（即零效应）[@problem_id:4502115]。衰减的程度与随机效应的方差 $\sigma_u^2$ 有关。

#### 广义估计方程（GEE）

当研究的主要目标是估计群体平均效应时，**广义估计方程（Generalized Estimating Equations, GEE）**提供了另一条途径 [@problem_id:4502110]。与GLMM不同，GEE直接对边际均值进行建模：
$$
g\{E(Y_{ijt} \mid X_{ijt})\} = X_{ijt}^{\top}\beta_{GEE}
$$
其中 $g(\cdot)$ 是一个联结函数（如Logit）。这里的系数 $\beta_{GEE}$ 直接量化了**群体平均（population-averaged）**效应。例如，$\exp(\beta_{GEE,k})$ 就是在人群中平均而言，协变量 $k$ 每增加一个单位，结局事件发生的优势比。

**GLMM vs. GEE 的选择**：
*   **研究问题**：如果你的问题是关于“平均而言，这项政策对整个县的人口有什么影响？”，那么GEE直接回答了这个问题。如果你的问题是“这项干预在一个典型的诊所中是如何起作用的？”或者你需要为个别诊所做预测，那么GLMM更合适。
*   **假设与稳健性**：GLMM是一个完全基于似然的模型，需要正确指定随机效应的分布。而GEE是一种半参数方法，其对 $\beta$ 的估计只要均值模型设定正确就是一致的，而对于组内相关性的“工作[相关矩阵](@entry_id:262631)（working correlation matrix）”的设定不正确，只会影响估计效率，而不会破坏一致性（在使用[稳健标准误](@entry_id:146925)的情况下）。因此，GEE通常被认为对模型设定有更强的稳健性。
*   **可移植性（Transportability）**：从政策角度看，GEE估计的群体平均效应可能更容易被移植到另一个具有不同异质性（即不同随机效应方差）的人群中。而要移植GLMM的结果来获得[边际效应](@entry_id:634982)，则需要同时对条件效应和随机效应分布的相似性做出假设 [@problem_id:4502110]。

值得注意的是，当联结函数是[恒等函数](@entry_id:152136)（identity link）时，如在[线性模型](@entry_id:178302)中，条件效应和[边际效应](@entry_id:634982)是相等的。因此，LMM和GEE（用于连续数据）的固定效应系数具有相同的解释，上述复杂的区分不复存在 [@problem_id:4502110]。这凸显了在处理[非线性模型](@entry_id:276864)时，审慎思考条件与边际解释的重要性。