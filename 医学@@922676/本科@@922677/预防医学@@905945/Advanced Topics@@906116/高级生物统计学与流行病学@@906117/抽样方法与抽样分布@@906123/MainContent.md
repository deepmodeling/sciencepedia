## 引言
在众多科学与社会研究领域，如何从一小部分个体（样本）中获取信息，并科学地推断整个群体（总体）的特征，是一项基础而关键的任务。无论是社会科学中的民意调查、公共卫生中的疾病监测，还是生态学中的[物种丰度](@entry_id:178953)估计，我们都依赖于严谨的抽样方法。然而，从样本到总体的推断过程充满了挑战：如何确保样本的代表性？如何量化由抽样带来的不确定性？以及如何处理现实世界中不可避免的数据缺失和偏差？

本文旨在系统性地解答这些问题，为读者构建一个关于抽样方法与抽样分布的完整知识框架。我们将首先在 **“原理与机制”** 一章中，深入剖析概率抽样的基本原理、不同抽样设计（如分层、整群）的内在逻辑，以及应对覆盖误差、无应答等现实挑战的统计策略。接着，在 **“应用与跨学科联系”** 一章，我们将展示这些理论如何在公共卫生调查、流行病学研究乃至生态学等领域中发挥关键作用，将抽象概念与实际问题紧密联系。最后，通过 **“动手实践”** 部分，读者将有机会亲手计算和解决具体的抽样问题，从而巩固所学知识。

让我们从推断的根本哲学出发，踏上这段探索从数据到洞见的科学旅程。

## 原理与机制

本章旨在深入探讨抽样方法与[抽样分布](@entry_id:269683)的核心原理及内在机制。在前一章介绍抽样调查在预防医学中的重要性之后，我们将系统性地剖析从样本数据推断总体特征的科学依据。本章将主要采用基于设计的推断视角，这在[公共卫生监测](@entry_id:170581)领域是标准做法，同时也会引入基于模型的思想以深化对某些概念的理解。我们将从推断的根本哲学出发，逐步过渡到抽样实践中的具体设计、挑战与对策。

### 推断的基础：两种思想的对比

在从样本推断总体的过程中，存在两种主要的统计思想流派：**基于设计的推断 (design-based inference)** 和 **基于模型的推断 (model-based inference)**。理解它们的区别至关重要，因为它决定了我们如何看待数据、如何构建估计量以及如何解释[置信区间](@entry_id:138194)。[@problem_id:4570321]

**基于设计的推断**将有限总体中的每个单元的数值（例如，某位居民是否接种了疫苗，$y_i$）视为固定的、未知的常数。在这个框架下，随机性完全来源于抽样过程本身——即哪些单元被选中进入样本。统计推断的有效性（如无偏性、[置信区间](@entry_id:138194)的覆盖率）是基于所有可能样本的分布来评估的。这种方法的巨大优势在于其稳健性：只要抽样方案得到遵循，它对总体数值本身的分布形态不作任何假设。因此，它在需要对一个确切定义的有限总体（如一个城市的所有成年人）进行描述时，显得尤为可靠和具有说服力。

相比之下，**基于模型的推断**将有限总体的数值本身视为从一个假想的、无限的“超总体” (superpopulation) 中[随机抽样](@entry_id:175193)产生的结果。例如，一个模型可能假设每个人的疫苗接种状态$y_i$是其年龄、健康状况等协变量$x_i$的函数，并包含一定的[随机误差](@entry_id:144890)。推断的目标是估计这个超总体模型的参数（例如，[回归系数](@entry_id:634860)$\beta$）。在这种视角下，只要抽样过程相对于我们感兴趣的结果而言是**可忽略的 (ignorable)**——即在控制了模型中的协变量$x_i$后，被抽中的概率与结果$y_i$无关——我们就可以忽略抽样设计，直接对样本数据进行建模。这种方法的潜在优势在于，如果模型正确，它可以利用协变量信息和数据结构（如聚类相关性）来提高估计的效率，从而得到更窄的[置信区间](@entry_id:138194)。然而，其有效性严重依赖于模型假设的正确性；一旦[模型设定错误](@entry_id:170325)，或者抽样过程实际上是**信息性的 (informative)**（即使在控制协变量后，抽中概率仍与结果相关），估计就可能产生严重偏倚。[@problem_id:4570321]

本章将主要遵循基于设计的框架，但会适时引入模型思想来阐明复杂概念，如组内相关性。

### 理想与现实：目标总体与抽样框

抽样调查的第一步是明确我们希望研究的对象，即**目标总体 (target population)**。例如，一个公共卫生团队可能希望估计某县所有年龄在50至75岁的居民的结直肠癌筛查依从性。[@problem_id:4570354] 这是一个清晰定义的目标总体。

然而，在实践中，我们无法直接从这个抽象的总体中抽样。我们需要一个具体的操作列表或机制来抽取样本，这个列表被称为**抽样框 (sampling frame)**。理想情况下，抽样框应与目标总体一一对应，不多不少。但在现实世界中，完美的抽样框极为罕见。研究人员常常需要整合多个不完美的数据源来构建抽样框，例如，将在县癌症筛查登记系统、主要诊所的病人注册名单和州选民登记名单合并，以期尽可能接近目标总体。[@problem_e_id:4570354]

抽样框与目标总体之间的差异会导致**覆盖误差 (coverage error)**，这是非[抽样误差](@entry_id:182646)的一个重要来源，主要分为三类：

*   **覆盖不足 (Undercoverage)**：指目标总体的成员未能出现在抽样框中。例如，那些在县外诊所接受筛查服务、且未在本地任何诊所或选民名单上注册的合格居民，他们将没有机会被抽中。这会导致对总体的系统性低估，特别是如果这些被遗漏的群体在关键特征上与被包含的群体不同。

*   **过度覆盖 (Overcoverage)**：指抽样框中包含了不属于目标总体的单元。例如，在2025年1月1日之前已经搬离该县或去世的个人，如果他们的名字仍然存在于诊所的注册名单上，就会被错误地包含在抽样框中。这些不合格单元的存在会稀释样本，并可能引入偏倚。

*   **重复 (Multiplicity)**：指目标总体的同一个成员在抽样框中出现多次。例如，一位60岁的居民，因为在两家诊所注册，并且也在选民名单上，可能在合并后的抽样框中拥有三个条目。如果不加以处理，这位居民被抽中的概率将是那些只出现一次的居民的三倍，这违反了概率抽样的基本原则，即每个单元的抽样概率应该是已知的。[@problem_id:4570354]

因此，在设计调查时，评估和处理抽样框的缺陷是保证最终推断质量的关键一步。

### 推断的基石：概率抽样

为了从样本科学地推断总体，**概率抽样 (probability sampling)** 是不可或缺的基石。其核心定义是：总体中的每一个单元都有一个已知的、非零的被选入样本的概率。[@problem_id:4570335]

这个定义引出了两个核心概念：

1.  **一阶入样概率 (first-order inclusion probability)**, $\pi_i$：总体中第$i$个单元被选入样本的概率，即 $\pi_i = \Pr(i \in s)$。概率抽样的根本要求是，对于总体中的所有单元$i$，$\pi_i > 0$ 且已知。$\pi_i > 0$ 保证了总体中的每个成员都有机会被代表。

2.  **二阶入样概率 (second-order inclusion probability)**, $\pi_{ij}$：总体中第$i$个和第$j$个单元同时被选入样本的概率，即 $\pi_{ij} = \Pr(i \in s, j \in s)$。这个概率在估计[抽样误差](@entry_id:182646)时至关重要。

在面对不均等抽样概率的设计时（例如，为了获得足够的老年人样本而对其进行过度抽样），我们不能简单地对样本数据求平均，否则会得到有偏的结果。为了纠正这种由设计本身引入的偏倚，我们使用一种强大的工具——**霍维茨-汤普森 (Horvitz-Thompson, HT) 估计量**。

HT估计量的思想是给每个抽中的单元赋予一个权重，该权重等于其入样概率的倒数，即 $w_i = 1/\pi_i$。直观上，一个入样概率较低的单元（例如，在总体中很罕见但被幸运抽中的单元）代表了更多未被抽中的相似单元，因此应被赋予更高的权重。

例如，在监测一个地区$N$个诊所的流感样疾病（ILI）就诊总数$T = \sum_{i=1}^{N} y_i$时，如果采用复杂抽样设计，第$i$个诊所的入样概率为$\pi_i$。HT总数估计量为：
$$ \hat{T}_{\mathrm{HT}} = \sum_{i \in s} \frac{y_i}{\pi_i} $$
其中，$s$代表样本集合。这个估计量是**设计无偏的 (design-unbiased)**，意味着在所有可能的样本上取其[期望值](@entry_id:150961)，结果恰好等于我们想估计的总体总数$T$。证明如下，令$I_i$为样本指示变量（如果单元$i$在样本中，$I_i=1$，否则为0），则$E[I_i] = \pi_i$。
$$ \mathbb{E}[\hat{T}_{\mathrm{HT}}] = \mathbb{E}\left[\sum_{i=1}^{N} \frac{I_i y_i}{\pi_i}\right] = \sum_{i=1}^{N} \frac{y_i}{\pi_i} \mathbb{E}[I_i] = \sum_{i=1}^{N} \frac{y_i}{\pi_i} \pi_i = \sum_{i=1}^{N} y_i = T $$
这个优美的性质是基于设计的推断的核心，它不依赖于$y_i$值本身的任何分布假设。而二阶入样概率$\pi_{ij}$则用于计算$\hat{T}_{\mathrm{HT}}$的方差，即衡量估计量围绕真值$T$的波动程度，这是构建[置信区间](@entry_id:138194)的基础。[@problem_id:4570335]

### 基本抽样设计

掌握了概率抽样的基本原理后，我们来考察几种具体的抽样设计。

#### 简单[随机抽样](@entry_id:175193)

最基础的概率抽样方法是**简单随机抽样 (Simple Random Sampling, SRS)**。在**不放回简单随机抽样 (SRSWOR)** 中，从一个大小为$N$的总体中抽取一个大小为$n$的样本，使得每一个由$n$个不同单元组成的子集都有相同的被抽中概率，即$1/\binom{N}{n}$。[@problem_id:4570366]

在这种设计下，每个单元的一阶入样概率都是相等的，即$\pi_i = n/N$。因此，估计总体均值$\bar{Y} = \frac{1}{N}\sum_{i=1}^{N} Y_i$的自然、无偏的估计量就是样本均值$\bar{y} = \frac{1}{n}\sum_{i \in s} y_i$。同样，估计总体比例$P$的[无偏估计量](@entry_id:756290)是样本比例$\hat{p}$。

估计量的方差是衡量其精度的关键。对于SRSWOR，样本均值的方差为：
$$ \operatorname{Var}(\bar{y}) = \left(1-\frac{n}{N}\right)\frac{S^2}{n} $$
其中，$S^2 = \frac{1}{N-1}\sum_{i=1}^{N}(Y_i-\bar{Y})^2$是有限总体方差。公式中的$(1 - n/N)$被称为**[有限总体校正因子](@entry_id:262046) (finite population correction, FPC)**。它反映了不放回抽样带来的信息增益：每抽取一个单元，我们都获得了关于总体的一部分确定信息，从而减少了剩余的不确定性。当样本量$n$相对于总体量$N$不可忽略时，FPC会显著减小方差。如果$N$非常大以至于$n/N \approx 0$，则该式退化为我们熟悉的$\frac{S^2}{n}$。

对于总体比例$P$的估计，其方差是均值方差公式的一个特例。对于一个值为0或1的[二元变量](@entry_id:162761)，其总体方差$S^2 = \frac{N}{N-1}P(1-P)$。代入上式，得到样本比例$\hat{p}$的**精确**设计方差：
$$ \operatorname{Var}(\hat{p}) = \left(1-\frac{n}{N}\right)\frac{S^2}{n} = \left(1-\frac{n}{N}\right)\frac{N}{N-1}\frac{P(1-P)}{n} $$
这个精确公式在需要严谨计算[置信区间](@entry_id:138194)时非常重要。[@problem_id:4570366]

#### 系统抽样

**系统抽样 (Systematic Sampling)** 是一种操作简单且广泛应用的概率[抽样方法](@entry_id:141232)。其过程是：首先计算抽样间距$k \approx N/n$，然后在$1$到$k$之间随机选择一个起始点$s$，之后以$k$为间距依次抽取单元$s, s+k, s+2k, \dots$。[@problem_id:4570376]

只要起始点$s$是随机选择的，并且总体大小$N$恰好是$n \times k$，那么每个单元的入样概率都是$1/k$，因此系统抽样是一种概率抽样。在这种情况下，样本均值是[总体均值](@entry_id:175446)的设计无偏估计量。

然而，系统抽样的简便性背后隐藏着一个重大风险：**周期性 (periodicity)**。如果抽样框中的单元排列存在某种与抽样间距$k$相关的周期性模式，系统抽样可能会产生偏差极大或方差极大的结果。

设想一个场景：某诊所的候诊队列中，由于分诊流程，患者按“1个高危($H$), 2个低危($L$)”的模式$(H, L, L)$[循环排列](@entry_id:273014)。假设高危患者的流感样疾病患病率为$0.30$，低危患者为$0.10$。真实的总体平均患病率应为 $\frac{1}{3}(0.30) + \frac{2}{3}(0.10) \approx 0.167$。如果研究者选择抽样间距$k=3$：
*   如果随机起点$s=1$，样本将全部由高危患者组成，样本患病率将接近$0.30$。
*   如果随机起点$s=2$或$s=3$，样本将全部由低危患者组成，样本患病率将接近$0.10$。

尽管在随机起点的期望意义上，估计量是无偏的，但任何一次抽样得到的结果都将与真实值$0.167$相去甚远。这导致了极大的抽样方差，远高于同等样本量的简单随机抽样。更糟糕的是，如果研究者不采用随机起点，而是总是从第1个病人开始（即固定起点$s=1$），那么得到的估计将系统性地偏向$0.30$，产生严重的偏倚。[@problem_id:4570376] 这个例子警示我们，在使用系统抽样时，必须警惕抽样框中任何潜在的有序模式。

### 提高效率与可行性的高级设计

在实践中，简单[随机抽样](@entry_id:175193)往往不是最高效或最可行的方法。为了在有限的资源下获得最精确的估计，或为了应对实际操作的限制，研究者发展了更复杂的设计。

#### [分层抽样](@entry_id:138654)

**[分层抽样](@entry_id:138654) (Stratified Sampling)** 的核心思想是“[分而治之](@entry_id:139554)”。它将总体根据某些辅助特征（如年龄、性别、地理区域）划分为若干个互不重叠的子群，称为**层 (strata)**。理想情况下，层内部的单元应尽可能同质，而层与层之间则应尽可能异质。然后，在每个层内独立进行抽样。最终的[总体估计](@entry_id:200993)量是各层估计值的加权平均，权重为各层在总体中所占的比例。[@problem_id:4570377]

[分层抽样](@entry_id:138654)的主要优点是提高估计精度。通过在所有层中抽样，它有效消除了层间变异对抽样误差的影响。其关键问题在于如何在各层之间分配总样本量$n$。以下是三种主要的分配策略：

*   **[按比例分配](@entry_id:634725) (Proportional Allocation)**：各层的样本量$n_h$与该层在总体中的大小$N_h$成正比，即 $n_h \propto N_h$。这种方法简单直观，能确保样本的结构与总体结构一致。当各层内部的变异程度（标准差$S_h$）大致相等时，[按比例分配](@entry_id:634725)是最佳选择。

*   **[奈曼分配](@entry_id:634618) (Neyman Allocation)**：也称最优分配，它旨在固定总样本量$n$的情况下，最小化总体[估计量的方差](@entry_id:167223)。其分配原则是 $n_h \propto N_h S_h$。这意味着我们应该在更大、且内部变异更大的层中抽取更多样本。直观上，这些层对总方差的“贡献”更大，因此值得投入更多抽样资源来更精确地估计它们。

*   **成本最优分配 (Cost-Optimal Allocation)**：这是[奈曼分配](@entry_id:634618)的推广，它考虑了在不同层抽样的单位成本$c_h$可能不同。例如，对城市居民的访谈可能比对偏远农村居民的访谈成本更低。其目标是在固定的总预算$C$下最小化方差，分配原则为 $n_h \propto \frac{N_h S_h}{\sqrt{c_h}}$。该策略指示我们将更多样本分配给那些规模大、变异大、且抽样成本低的层。[@problem_id:4570377]

#### 整群抽样

**整群抽样 (Cluster Sampling)** 主要出于成本和可行性的考虑。当总体的个体单元没有现成的抽样框，或者个体分布广泛、逐一访问成本高昂时，整群抽样便成为一种有效的替代方案。其操作过程是：将总体划分为若干个**群 (clusters)**（如学校、社区、村庄），然后随机抽取一部分群，并对抽中群内的所有（**一段整群抽样**）或部分（**二段整群抽样**）单元进行调查。[@problem_id:4570359]

整群抽样的便利性是有代价的。这个代价体现在其估计量的方差上。群内的单元往往比随机选择的单元更相似，例如，同一所学校的学生在健康行为上可能受到共同环境和同伴的影响。这种群内单元的相似性可以用**组内相关系数 (Intraclass Correlation Coefficient, ICC)**，记作$\rho$，来量化。$\rho$衡量了来自同一群的两个随机单元结果之间的相关性。

当$\rho > 0$时（绝大多数社会和生物学情境下都是如此），整群抽样[估计量的方差](@entry_id:167223)会比同等样本量的简单[随机抽样](@entry_id:175193)要大。这个方差的膨胀程度由**设计效应 (design effect, DEFF)** 来衡量。对于一个大小为$m$的群，一段整群抽样的设计效应近似为：
$$ \text{DEFF} \approx 1 + (m-1)\rho $$
这意味着，整群抽样的方差大约是简单随机抽样方差的$[1 + (m-1)\rho]$倍。从这个公式可以看出，群的规模$m$越大，或群内[同质性](@entry_id:636502)$\rho$越高，方差的膨胀就越严重，估计的精度就越低。[@problem_id:4570359]

#### 分层与整群的对比

[分层抽样](@entry_id:138654)与整群抽样在目标和机制上截然不同：
*   **目标**：分层旨在**提高精度**，而整群旨在**降低成本**和**提高可行性**。
*   **分组原则**：分层的理想分组是**组内同质，组间异质**。整群的理想分组是**组内异质（每个群都是总体的一个缩影），组间同质**。
*   **抽样方式**：分层从**所有**层中抽样，而整群只抽取**部分**群。
*   **方差影响**：分层通过消除组间变异来**减小**方差。整群由于组内相关性而通常会**增大**方差。[@problem_id:4570359]

#### 对组内相关系数的深入理解

为了更深刻地理解ICC，我们可以借助一个基于模型的视角。设想我们正在研究各学校的疫苗接种率。不同学校由于宣传力度、家长态度等因素，其真实的接种率$p_j$可能是不同的。我们可以将$p_j$本身看作一个随机变量，它在所有学校间服从某个分布，例如**[贝塔分布](@entry_id:137712) (Beta distribution)**, $p_j \sim \mathrm{Beta}(\alpha, \beta)$。在一个给定的学校$j$内，每个学生的接种状态$Y_{ij}$可以看作是成功概率为$p_j$的独立伯努利试验。这个两层结构（先抽取$p_j$，再根据$p_j$生成$Y_{ij}$）构成了**贝塔-二项 (Beta-Binomial)** 模型。[@problem_id:4570325]

在这个模型下，可以证明组内[相关系数](@entry_id:147037)$\rho$精确地等于：
$$ \rho = \frac{\mathrm{Var}(p_j)}{\mu(1-\mu)} $$
其中，$\mu = \mathbb{E}[p_j]$是所有学校的平均接种率，$\mathrm{Var}(p_j)$是学校间接种率的方差。这个公式直观地揭示了$\rho$的本质：它代表了由“群”的差异（学校间接种率的方差）所解释的变异占总变异的比例。

进一步，对于[贝塔分布](@entry_id:137712)，可以算出$\rho = \frac{1}{\alpha+\beta+1}$。这为$\rho$提供了一个[参数化](@entry_id:265163)的解释，并将其与描述学校间异质性的超参数$\alpha$和$\beta$直接联系起来。这个模型视角不仅深化了我们对ICC的理解，也为在数据分析中处理聚[类数](@entry_id:156164)据提供了强大的工具。[@problem_id:4570325]

### 应对不[完美数](@entry_id:636981)据的挑战

现实世界中的调查数据很少是完美的。除了前面讨论的覆盖误差，研究者还必须面对另外两大挑战：非概率抽样和样本无应答。

#### 非概率抽样

与概率抽样相对的是**非概率抽样 (nonprobability sampling)**，其特点是单元的入样概率未知或某些单元的入样概率为零。常见的方法包括**[方便抽样](@entry_id:175175) (convenience sampling)**（如在诊所门口招募志愿者）和**滚雪球抽样 (snowball sampling)**（参与者推荐其社交网络中的其他人）。[@problem_id:4570382]

这些方法的主要问题是**选择性偏倚 (selection bias)**。由于样本不是通过已知的随机机制产生的，样本的构成很可能与目标总体存在系统性差异。例如，在一个评估未诊断高血压患病率的研究中，如果通过诊所便利样本进行招募，而吸烟者（他们的高血压风险更高）比非吸烟者更倾向于去诊所，那么样本中吸烟者的比例将被高估。假设在总体中，吸烟者占$0.2$，非吸烟者占$0.8$，真实患病率分别为$0.3$和$0.1$，则总体真实患病率为$(0.2)(0.3) + (0.8)(0.1) = 0.14$。如果样本中吸烟者的入样机会是非吸烟者的2倍，通过计算可以发现，样本中吸烟者的比例将变为$1/3$，非吸烟者为$2/3$。因此，在不加权的情况下，样本的期望患病率将是$(\frac{1}{3})(0.3) + (\frac{2}{3})(0.1) \approx 0.167$，这显著高于真实的$0.14$。[@problem_id:4570382]

这种偏倚不会因为样本量的增大而消失。[中心极限定理](@entry_id:143108)保证样本均值会收敛到其[期望值](@entry_id:150961)，但如果这个[期望值](@entry_id:150961)本身就是有偏的，那么大样本只会让我们更精确地得到一个错误的答案。**志愿者偏倚 (volunteer bias)** 是[便利抽样](@entry_id:175175)的另一种常见形式，例如，在调查预防性服务使用情况时，更注重健康的个体可能更愿意参与调查，从而导致对服务使用率的高估。[@problem_id:4570382]

#### 概率样本中的无应答

即使是设计完美的概率样本，也无法避免**无应答 (nonresponse)** 问题，即部分被抽中的单元未能完成调查。无应答会破坏样本的概率结构，并可能引入偏倚，特别是当应答者与未应答者在所研究的特征上存在差异时。为了分析和处理无应答，统计学家提出了三种缺失机制的分类：[@problem_id:4570326]

*   **[完全随机缺失](@entry_id:170286) (Missing Completely At Random, MCAR)**：指应答与否完全独立于所有变量，包括研究结果变量$Y$和任何辅助变量$X$。即 $P(R=1|Y,X)=p$。在这种理想情况下，应答者可以看作是原始样本的一个随机子样本，偏倚可以通过简单的权重调整（如乘以总应答率的倒数）来校正。

*   **[随机缺失](@entry_id:168632) (Missing At Random, MAR)**：指在控制了可观测的辅助变量$X$（例如，在抽样框中已知的年龄、性别）之后，应答与否与研究结果变量$Y$无关。即 $P(R=1|Y,X)=g(X)$。例如，年轻人和老年人的应答率不同，但在同一年龄组内，疫苗犹豫者和非犹豫者的应答倾向是相同的。MAR是一个关键的假设，因为它意味着只要我们拥有并善用这些辅助变量$X$，就有可能校正无应答偏倚。

*   **[非随机缺失](@entry_id:163489) (Missing Not At Random, MNAR)**：指即使在控制了所有可观测的辅助变量$X$之后，应答与否仍然与研究结果变量$Y$本身相关。即 $P(R=1|Y,X)$ 依赖于$Y$。例如，疫苗犹豫者（$Y=1$）由于对主题敏感而更倾向于拒绝回答。在这种情况下，仅从调查数据本身无法识别和校正偏倚，需要借助外部数据或做出更强的、无法检验的假设。[@problem_id:4570326]

#### 纠偏的终极武器：加权调整

面对由复杂设计、覆盖误差和无应答共同造成的挑战，**加权 (weighting)** 成为从真实世界调查数据中获得[无偏估计](@entry_id:756289)的核心技术。一个完整的权重通常通过三步构建而成：[@problem_id:4570323]

1.  **基础权重 (Base Weight)**：也称设计权重，其值为入样概率的倒数，$w_{\text{base}} = 1/\pi_i$。这一步旨在纠正由于不均等概率抽样（如[分层抽样](@entry_id:138654)中的过度抽样）所导致的设计偏倚，使样本在结构上“复原”到与总体一致。

2.  **无应答调整 (Nonresponse Adjustment)**：在MAR假设下，通过对基础权重进行调整来补偿无应答造成的偏倚。常用的方法是**加权单元格调整 (weighting class adjustment)**，即根据辅助变量（如年龄、性别）将样本分为若干个单元格，计算每个单元格的应答率，然后将该单元格内所有应答者的基础权重乘以该单元格应答率的倒数。这相当于让单元格内的应答者“代表”那些未应答的、但具有相同特征的个体。

3.  **校准 (Calibration)**：也称**[事后分层](@entry_id:753625) (post-stratification)** 或**边际总数加权 (raking)**。这是最后一步精调，旨在让加权后的样本在某些关键辅助变量（如从最新人口普查中获得的年龄-性别-地区分布）的分布上与已知的总体分布完全吻合。即调整权重$w_i^{\text{cal}}$，使得 $\sum_{i \in \text{respondents}} w_i^{\text{cal}} \mathbf{x}_i = \mathbf{X}_{\text{total}}$，其中$\mathbf{X}_{\text{total}}$是已知的总体边际总数。这一步可以进一步减少由覆盖误差和残余的无应答偏倚所带来的误差，同时可能以增加[估计量方差](@entry_id:263211)为代价。[@problem_id:4570323]

通过这一系列精密的加权调整，研究者能够最大限度地从不完美的样本数据中提取信息，生成对目标总体特征的、尽可能准确和无偏的估计，从而为预防医学决策提供坚实的科学依据。