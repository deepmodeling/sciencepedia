## 引言
在预防医学和公共卫生领域，评估干预措施的有效性是制定循证决策的核心。然而，由于伦理或实践限制，我们常常无法依赖随机对照试验（RCT）这一“金标准”。那么，我们如何能从充满偏倚和混杂的观测数据中，可靠地回答“某项干预是否真正导致了某个结果”这一关键的因果问题呢？简单地观察相关性往往会得出错误甚至有害的结论，这构成了当前实证研究中的一个核心知识鸿沟。

本文旨在系统性地介绍解决这一挑战的高级因果推断方法。通过学习本文，您将能够超越简单的[统计关联](@entry_id:172897)，掌握从复杂数据中严谨地识别和量化因果效应的工具。我们将分三步深入这一主题：首先，在**“原理与机制”**一章中，我们将奠定理论基石，详细阐述[潜在结果框架](@entry_id:636884)、核心假设以及控制混杂的倾向性评分和工具变量等关键方法。接着，在**“应用与跨学科交叉”**一章中，我们将通过公共卫生、经济学、基因组学乃至人工智能等领域的真实案例，展示这些方法的强大实践价值。最后，在**“动手实践”**部分，您将有机会通过具体练习，将理论知识转化为实际操作能力。

通过这一结构化的学习路径，本文将为您提供一个从理论到实践的完整框架，帮助您在未来的研究和工作中自信地应用因果推断。现在，让我们从第一章开始，深入探索这些方法背后的核心原理与机制。

## 原理与机制

本章将深入探讨高级因果推断方法背后的核心原理与机制。在上一章“导论”的基础上，我们将系统地阐述用于定义、识别和估计因果效应的基本框架和关键假设。我们将从[潜在结果框架](@entry_id:636884)出发，精确定义我们希望估计的目标（即因果估计量），然后详细讨论在无法进行完美随机实验的现实世界中，我们需要哪些假设才能从观测数据中获得有效的因果结论。最后，我们将介绍两种主流的高级方法——倾向性评分和[工具变量](@entry_id:142324)——并探讨它们在处理复杂[数据结构](@entry_id:262134)（如时间依赖性混杂）时的应用与挑战。

### 因果推断的基础：[潜在结果](@entry_id:753644)与因果估计量

现代因果推断的基石是 **[潜在结果框架](@entry_id:636884)（Potential Outcomes Framework）**，也常被称为Rubin因果模型（Rubin Causal Model）。该框架提供了一种精确的语言来定义个体层面和群体层面的因果效应。

对于任何个体 $i$ 和一项二元处理（treatment）$T$（例如，接受或未接受某项预防干预），我们设想存在两种潜在结果。令 $Y_i(1)$ 表示个体 $i$ 在接受处理（$T=1$）的情况下将会出现的结局，而 $Y_i(0)$ 表示同一个体在未接受处理（$T=0$）的情况下将会出现的结局。对于个体 $i$ 而言，其**个体因果效应（Individual Causal Effect, ICE）**被定义为这两种[潜在结果](@entry_id:753644)的差异：$ICE_i = Y_i(1) - Y_i(0)$。

然而，我们面临着所谓的 **“因果推断的根本问题”**：对于任何一个个体，我们至多只能观测到两种潜在结果中的一种。我们观测到的实际结局 $Y_i$ 取决于该个体实际接受的处理状态：$Y_i = T_i Y_i(1) + (1-T_i) Y_i(0)$。我们永远无法同时观测到同一个体在同一时间点上接受处理和未接受处理的两种结局。因此，个体因果效应通常是无法直接计算的。

尽管如此，我们可以将目标转向估计群体层面的平均因果效应。在预防医学中，两个最核心的因果估计量是平均[处理效应](@entry_id:636010)（ATE）和处理组平均处理效应（ATT）。

**平均处理效应（Average Treatment Effect, ATE）** 被定义为群体中所有个体因果效应的[期望值](@entry_id:150961)：
$$ ATE = \mathbb{E}[Y(1) - Y(0)] = \mathbb{E}[Y(1)] - \mathbb{E}[Y(0)] $$
ATE 回答了这样一个问题：“如果我们将整个人群从‘无人接受处理’的状态变为‘人人接受处理’，人群的平均结局会发生多大变化？” 这是一个具有重要公共卫生意义的估计量，因为它评估了一项干预措施在符合条件的全人口中推广的平均潜在影响 [@problem_id:4501620]。例如，在评估一项流感疫苗接种项目时，ATE衡量的是，如果所有符合条件的成年人都接种疫苗，与如果所有人都不接种疫苗相比，流感发病率的平[均差](@entry_id:138238)异。

与此相对，**处理组平均处理效应（Average Treatment Effect on the Treated, ATT）** 则关注于那些实际上接受了处理的特定亚群。其定义为：
$$ ATT = \mathbb{E}[Y(1) - Y(0) \mid T=1] = \mathbb{E}[Y(1) \mid T=1] - \mathbb{E}[Y(0) \mid T=1] $$
ATT 回答的问题是：“对于那些已经接受了处理的人来说，该处理带给他们的平均效应是什么？” [@problem_id:4501620]。请注意，表达式中的 $\mathbb{E}[Y(1) \mid T=1]$ 是可以在数据中直接观测到的（即处理组的平均结局），而 $\mathbb{E}[Y(0) \mid T=1]$ 是一个反事实量，代表处理组人群如果当初没有接受处理，其结局的[期望值](@entry_id:150961)。在理想的随机对照试验（RCT）中，由于处理分配的随机性，ATE和ATT是相等的。但在观测研究中，由于“选择偏倚”（即决定接受处理的个体可能在系统上不同于未接受处理的个体），ATE和ATT通常不相等。

### 观测数据因果推断的核心假设

为了从观测数据中估计ATE或ATT，我们必须依赖一系列关键的、不可完全验证的假设，以连接我们能够观测到的数据世界和我们感兴趣的[潜在结果](@entry_id:753644)世界。

#### 稳定单元处理价值假设 (SUTVA)

**稳定单元处理价值假设（Stable Unit Treatment Value Assumption, SUTVA）** 是[潜在结果框架](@entry_id:636884)得以明确定义的前提。它包含两个子假设：

1.  **无干扰（No Interference）**：任何个体的[潜在结果](@entry_id:753644)仅依赖于其自身所接受的处理，而不受其他个体处理状态的影响。如果存在干扰，一个个体 $i$ 的潜在结果需要更复杂的表示，如 $Y_i(T_i, \mathbf{T}_{-i})$，其中 $\mathbf{T}_{-i}$ 是除 $i$ 之外所有其他个体的处理分配向量。在这种情况下，简单的 $Y_i(1)$ 和 $Y_i(0)$ 是不明确的，因为它们的值会随着其他人处理状态的变化而变化。

2.  **一致性（Consistency）**：个体的处理水平不存在隐藏的变异。如果一个个体实际接受了处理水平 $T_i=t$，那么其观测结局 $Y_i$ 就等于其在该处理水平下的潜在结果 $Y_i(t)$。这意味着我们所定义的处理 $T=1$ 对于所有接受它的个体来说是同一种干预。

在实践中，SUTVA可能很容易被违反。例如，在一个诊所内的戒烟咨询项目中 [@problem_id:4501717]，如果一个参与者（$T_i=1$）的成功会通过同伴支持影响到诊所内另一个参与者（$j$）的吸烟行为，这就违反了“无干扰”假设。同样，如果因为大量患者报名参加，导致诊所资源紧张，使得后期参与者的咨询强度低于早期参与者，那么“戒烟咨询”这一处理就存在多个版本，违反了“一致性”假设。在这些情况下，$Y_i(1)$ 的定义变得模糊，因果推断需要更复杂的模型来处理这种依赖性。

#### 可交换性 (Exchangeability)

**可交换性（Exchangeability）**，也称为“无混杂”（unconfoundedness）或“可忽略性”（ignorability），是控制偏倚的核心。在最强的形式下，它要求处理分配独立于[潜在结果](@entry_id:753644)，即 $(Y(1), Y(0)) \perp T$。这种情况在随机对照试验中成立，但在观测研究中几乎从不成立。因此，我们依赖于更弱的 **条件[可交换性](@entry_id:263314)（Conditional Exchangeability）**：
$$ (Y(1), Y(0)) \perp T \mid X $$
其中 $X$ 是一组在处理前测量的协变量。该假设意味着，在由协变量 $X$ 定义的任何特定亚组内，接受处理的个体和未接受处理的个体在潜在结果方面是“可交换”的，就如同进行了一次小型的随机试验。

**混杂（Confounding）** 是对可交换性的主要威胁。混杂因子是既影响处理选择又影响结局的变量，从而在处理和结局之间制造了虚假的关联。**有向无环图（Directed Acyclic Graphs, DAGs）** 为我们提供了一种强大的可视化语言来理解混杂。在DAG中，变量是节点，因果关系由箭头表示。

混杂在DAG中表现为一个开放的 **“后门路径”（back-door path）**——一条从处理节点 $T$ 连接到结局节点 $Y$、但其第一段指向 $T$ 的路径。例如，在一个评估结直肠癌筛查政策（$A$）对死亡率（$Y$）影响的研究中 [@problem_id:4501630]，如果存在一个未测量的“健康追求倾向”（$U$），它既促使人们接受筛查（$U \to A$），又直接影响死亡风险（$U \to Y$），那么路径 $A \leftarrow U \to Y$ 就是一条后门路径。这条路径产生的非因果关[联会](@entry_id:139072)与真实因果路径 $A \to Y$ 混淆，导致偏倚。为了识别因果效应，我们必须通过统计学校正（“条件化”）来“阻断”所有这样的后门路径。

#### 正值性 (Positivity)

**正值性（Positivity）**，也称作“重叠”（overlap）或“共同支撑”（common support），是条件[可交换性](@entry_id:263314)得以在实践中应用的保障。它要求对于协变量 $X$ 的任何取值组合，个体接受处理和不接受处理的概率都必须大于零：
$$ 0  P(T=1 \mid X=x)  1 $$
这一假设确保了在由 $X$ 定义的每个亚组中，我们总能找到接受处理的个体和未接受处理的个体进行比较 [@problem_id:4501673]。如果没有正值性——例如，在某个亚组（如患有严重合并症的极高龄患者）中，所有人都接受了疫苗接种（$P(T=1 \mid X=x_1) = 1$）——那么我们就没有任何数据来了解这些人在未接种疫苗情况下的结局，因此无法在该亚组内估计因果效应。

当正值性假设被“近似”违反时，即倾向性评分 $e(X) = P(T=1 \mid X)$ 接近0或1时，会产生严重的实际问题。例如，在使用[逆概率](@entry_id:196307)加权法（IPW）时，权重为 $1/e(X)$ 或 $1/(1-e(X))$。如果一个极不可能接受处理的个体（$e(X) \approx 0.05$）碰巧接受了处理，他将被赋予一个极大的权重（$\approx 20$），使得整个分析结果被极少数“意外”的个体所主导，导致估计量的方差极大，结果非常不稳定 [@problem_id:4501673]。

### 控制混杂的方法：倾向性评分

**倾向性评分（Propensity Score, PS）**，定义为在给定一系列基线协变量 $X$ 的条件下，个体接受处理的概率 $e(X) = P(T=1 \mid X)$，是控制混杂的有力工具。其核心思想在于，如果条件可交换性成立，那么在倾向性评分值相同的个体之间进行条件化，也足以实现可交换性。这极大地简化了问题，将对多个协变量 $X$ 的控制降维到对单一标量 $e(X)$ 的控制。

#### 基于DAG的协变量选择

构建一个有效的倾向性评分模型，首要任务是正确选择协变量集合 $X$。DAG为此提供了原则性指导。我们的目标是选择一个协变量集，该集合满足“[后门准则](@entry_id:637856)”：即阻断所有从处理 $T$ 到结局 $Y$ 的后门路径，同时不引入新的偏倚。

在选择协变量时，必须遵循以下规则：
1.  **必须纳入混杂因子**：即位于开放后门路径上的变量。例如，在评估低剂量CT（LDCT）肺癌筛查效果时，年龄（$A$）和健康追求行为（$H$）都是筛查（$T$）和死亡率（$Y$）的共同原因，因此必须被纳入模型以阻断 $T \leftarrow A \to Y$ 和 $T \leftarrow H \to Y$ 两条后门路径 [@problem_id:4501616]。

2.  **决不能纳入中介变量**：中介变量位于从处理到结局的因果链上（如 $T \to M \to Y$）。若要估计 $T$ 对 $Y$ 的总效应，则决不能对中介变量 $M$ 进行校正，否则会阻断部分因果效应，导致估计的是直接效应而非总效应 [@problem_id:4501616]。

3.  **决不能纳入[对撞机](@entry_id:192770)（Collider）**：[对撞机](@entry_id:192770)是某条路径上被两个箭头同时指向的变量（如 $A \to C \leftarrow B$）。在默认情况下，对撞机所在的路径是封闭的。然而，一旦我们对其进行条件化（例如，将其纳入[回归模型](@entry_id:163386)或倾向性评分模型），就会打开这条路径，从而在其“父节点”之间（$A$ 和 $B$）引入虚假的关联，产生所谓的 **对撞机分层偏倚（collider-stratification bias）**。例如，在结直肠癌筛查的例子中 [@problem_id:4501630]，如果“安排门诊预约”（$C$）同时受筛查政策（$A$）和未测量的健康追求倾向（$U$）影响（$A \to C \leftarrow U$），那么 $C$ 就是一个对撞机。此时校正 $C$ 会错误地在 $A$ 和 $U$ 之间制造关联，并通过 $U \to Y$ 路径污染对 $A \to Y$ 效应的估计。

#### 倾向性评分模型的诊断

一个常见的误区是认为，一个“好”的倾向性评分模型应该是一个能高度准确预测处理分配的模型（例如，具有很高的AUC值）。然而，倾向性评分方法的最终目标不是预测处理，而是为了实现 **协变量平衡（covariate balance）**。因此，评估倾向性评分模型是否成功的核心诊断标准是，在使用该评分进行匹配、加权或分层后，处理组和[控制组](@entry_id:188599)的基线协变量分布是否变得相似。

**标准化均数差（Standardized Mean Difference, SMD）** 是衡量平衡性的常用指标，通常认为SMD小于 $0.1$ 表示达到了充分的平衡。例如，在一项评估血压筛查项目的研究中 [@problem_id:4501605]，有两个备选的倾向性评分模型：模型1非常复杂，AUC高达 $0.92$，但匹配后的SMD值很大（如 $0.25$）；模型2相对简单，AUC为 $0.76$，但匹配后所有协变量的SMD都小于 $0.05$。在这种情况下，模型2是更可取的选择。尽管其预测能力较弱，但它成功地完成了其核心任务——创造了可比较的组别，为无偏的因果效应估计奠定了基础。模型1的高AU[C值](@entry_id:272975)反而是一个警示信号，表明处理组和[控制组](@entry_id:188599)的重叠区域可能很小，导致大量样本无法匹配，且最终未能实现平衡。

### 应对未测量混杂：工具变量

当存在关键的、无法测量的混杂因子时（如DAG中的 $U$），即使是倾向性评分也[无能](@entry_id:201612)为力。在这种情况下，**[工具变量](@entry_id:142324)（Instrumental Variable, IV）** 方法提供了一条潜在的出路。

工具变量 $Z$ 是一个与处理 $T$ 相关，但与结局 $Y$ 之间没有除了通过 $T$ 之外的其他联系的变量。一个有效的工具变量必须满足三个核心假设 [@problem_id:4501582]：

1.  **相关性（Relevance）**：[工具变量](@entry_id:142324)必须与处理相关，即 $Cov(Z, T) \neq 0$。例如，如果使用“医生鼓励接种疫苗”（$Z$）作为工具变量，那么这种鼓励必须确实能改变患者的接种行为（$T$）。

2.  **独立性（Independence / Exogeneity）**：工具变量的分配必须独立于所有可能影响结局的未测量混杂因子。在[潜在结果框架](@entry_id:636884)下，这意味着 $Z$ 与潜在结果 $(Y(1), Y(0))$ 相互独立。在实践中，这通常通过随机化 $Z$ 来实现，例如，随机将医生分配到“鼓励组”或“不鼓励组”。

3.  **排他性限制（Exclusion Restriction）**：[工具变量](@entry_id:142324)只能通过影响处理来影响结局，不能有其他直接或间接的路径。例如，“医生鼓励”这一行为本身不能通过改变患者的其他健康行为（如戴口罩）来影响[流感](@entry_id:190386)发病率，它影响结局的唯一途径必须是“是否接种疫苗”。

#### IV估计量：ITT、CACE与LATE

IV方法的思想在有随机分配但存在不依从性（non-compliance）的研究中得到了最清晰的体现。例如，在一个随机鼓励接种疫苗的活动中 [@problem_id:4501603]，随机分组（$Z$）是完美的[工具变量](@entry_id:142324)。

首先，我们可以计算 **意向性治疗效应（Intention-to-Treat, ITT）**，即随机分组对最终结局的效应：$ITT_Y = E[Y \mid Z=1] - E[Y \mid Z=0]$。由于 $Z$ 是随机分配的，ITT效应是一个无偏的因果效应估计，但它估计的是“分配到鼓励”这一行为的效应，而非“实际接种疫苗”的效应。

为了得到处理本身的效应，IV方法使用 **Wald估计量**：
$$ IV_{estimand} = \frac{E[Y \mid Z=1] - E[Y \mid Z=0]}{E[D \mid Z=1] - E[D \mid Z=0]} = \frac{ITT_Y}{ITT_D} $$
其中分母是随机分组对处理依从性的效应。在满足上述三个IV假设以及 **[单调性](@entry_id:143760)（Monotonicity）** 假设（即不存在“逆反者”，不会有人在被鼓励时不接种，在不被鼓励时反而去接种）的条件下，Wald估计量所识别的并非ATE或ATT，而是 **依从者平均因果效应（Complier Average Causal Effect, CACE）**，也称为 **局部平均处理效应（Local Average Treatment Effect, LATE）**。

CACE的定义是 $E[Y(1) - Y(0) \mid D(1) > D(0)]$，即“依从者”（那些仅在被鼓励时才会改变行为去接受处理的人群）中的平均处理效应。

#### 解释LATE：异质性挑战

LATE是一个重要的概念，但其解释需要格外小心。它是一个“局部”效应，只适用于“依从者”这个特定的、通常无法直接识别的亚群。如果[处理效应](@entry_id:636010)在人群中是异质的，且依从者群体在某些方面不同于整个人群，那么LATE可能与ATE或ATT有很大差异 [@problem_id:4501669]。

例如，假设在一个疫苗鼓励项目中，依从者主要是年轻人和健康人群，而疫苗对老年和高风险人群的保护效果更强（绝对风险降低更多）。在这种情况下，LATE（主要反映了年轻健康人群的较小效应）会显著低于ATE（反映了整个人群的平均效应）。如果研究者将LATE错误地泛化为整个人群的效应，他们将会低估疫苗在公共卫生层面上的真实平均价值 [@problem_id:4501669]。因此，报告IV结果时，必须明确其估计的是LATE，并谨慎讨论其外部有效性。

### 高级主题：时变处理的因果推断

当处理和混杂因子随时间动态变化时，因果推断变得更加复杂。一个核心挑战是 **时变混杂（Time-dependent Confounding）**，即在某个时间点 $t$ 的一个变量 $L_t$（如血压），它既是未来处理 $T_t$ 的预测因子（混杂因子），又是过去处理 $T_{t-1}$ 的结果（中介变量）。

这种“处理-混杂反馈循环”（$T_{t-1} \to L_t \to T_t$ 且 $L_t \to Y$）使得标准回归方法失效 [@problem_id:4501638]。标准的[回归模型](@entry_id:163386)（如 $Y \sim \bar{T}_K + \bar{L}_K$）面临一个两难困境：为了控制 $T_t$ 的混杂，模型必须纳入 $L_t$；但纳入 $L_t$ 又会阻断过去处理 $T_{t-1}$ 通过 $L_t$ 影响 $Y$ 的因果路径，从而导致对 $T_{t-1}$ 总效应的估计产生偏倚。

在这种情境下，我们需要一个更强的可交换性假设，即 **序贯[可交换性](@entry_id:263314)（Sequential Exchangeability）**：
$$ Y^{\bar{a}} \perp T_t \mid \bar{L}_t, \bar{T}_{t-1} \quad \text{for all } t, \bar{a} $$
该假设要求在任何给定的过去处理和协变量历史下，当前的处理分配是随机的。为了在存在时变混杂的情况下正确估计因果效应，研究者需要使用专门为此设计的更高级方法，例如边际结构模型（Marginal Structural Models, MSMs）或g-computation公式。这些方法通过对时变处理进行逆概率加权或其他技术，巧妙地绕开了标准回归方法的困境，从而能够估计动态处理策略的总因果效应。