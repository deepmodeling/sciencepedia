## 引言
在公共卫生与临床预防领域，决策者和实践者面临着一个永恒的挑战：如何在众多的选择中，确定哪些干预措施是真正有效、安全且具有成本效益的？循证预防实践（Evidence-based Practice in Prevention）正是为了回应这一挑战而生。它是一种系统性的方法论，强调任何预防决策——无论是制定一项国家级的筛查政策，还是为个体提供健康建议——都应基于当前可获得的最佳科学证据，而非仅仅依赖于传统、直觉或不系统的临床经验。

本文旨在完整地勾勒出循证预防实践的全景图，填补从理论知识到实际应用之间的鸿沟。我们将系统地解答一系列关键问题：我们如何提出一个能够被科学证据回答的好问题？如何辨别不同研究证据的“含金量”？如何量化一项干预措施的真实效果，并警惕那些可能误导我们的统计陷阱？最终，我们又该如何综合所有信息，形成一个既科学又实用的推荐意见？

为了清晰地引导您掌握这一过程，本文将分为三个核心部分。在“原则与机制”一章中，我们将深入探讨循证实践的基石，包括构建PICO问题、理解因果推断、评价研究设计、量化结局与偏倚，以及使用GRADE框架进行证据评级。接下来的“应用与跨学科联系”一章，将把这些原则置于真实世界的场景中，展示它们如何应用于公共卫生项目评估、成本效果分析、健康公平性考量乃至复杂政策的制定。最后，“动手实践”部分将通过具体的计算练习，帮助您巩固所学知识。现在，让我们从构成循证实践基础的核心原则与机制开始探索之旅。

## 原则与机制

在循证预防医学的实践中，我们遵循一套系统性的方法，从提出精确的问题开始，到批判性地评价证据，再到综合证据并做出明智的决策。本章将深入探讨支撑这一过程的核心原则与关键机制，阐明如何构建可回答的问题、如何理解和评估不同类型的研究证据、如何量化效果与偏倚，以及最终如何综合所有信息形成可靠的建议。

### 构建可回答的临床问题：PICO框架

任何循证探索的第一步都是将一个模糊的临床或公共卫生难题，转化为一个清晰、具体、可回答的问题。**PICO框架**是实现这一转化的标准工具。它将一个[问题分解](@entry_id:272624)为四个基本组成部分：

*   **P (Patient/Population)**: 患者或人群。问题关注的是哪些人？这需要精确定义人群的特征，如年龄、性别、疾病状态、风险因素等。
*   **I (Intervention)**: 干预措施。我们考虑的是何种预防、诊断或治疗措施？
*   **C (Comparator)**: 比较对象。干预措施是与什么进行比较？比较对象可以是安慰剂、常规护理、无干预，或是另一种积极的干预措施。
*   **O (Outcome)**: 结局。我们关心的是哪些结果？在循证实践中，我们优先关注**患者重要的结局 (patient-important outcomes)**，如死亡率、发病率、生活质量，而非**替代性结局 (surrogate outcomes)**，如胆[固醇](@entry_id:173187)水平、血压读数等生理指标。

例如，假设我们想评估[他汀类药物](@entry_id:167025)在心血管疾病一级预防中的作用。一个精确的PICO问题将是至关重要的。一级预防意味着我们关注的是尚未患有心血管疾病的人群。结局应直接关乎患者的生存和健康状况。

考虑以下PICO问题的构建 [@problem_id:4525712]：
*   **P**: 年龄在 $40$–$75$ 岁之间，无确诊心血管疾病的成年人。
*   **I**: 指南推荐强度的[他汀类药物](@entry_id:167025)治疗。
*   **C**: 不使用[他汀类药物](@entry_id:167025)（安慰剂或常规护理）。
*   **O**: 全因死亡率和主要心血管事件（如非致死性心肌梗死、非致死性卒中）。

基于此，一个结构良好、可回答的问题是：“对于年龄在 $40$–$75$ 岁、无心血管疾病的成年人，与不使用他汀类药物相比，[他汀类药物](@entry_id:167025)治疗能否降低全因死亡率和主要心血管事件的发生率？”

这个问题的表述是明确的，它精确地定义了目标人群（排除了二级预防）、干预措施、最合适的[对照组](@entry_id:188599)（用于评估干预本身是否有效）以及对患者真正重要的结局。相反，如果我们将人群定义为包括已有心肌梗死病史的患者，问题就转向了二级预防；或者，如果我们选择[低密度脂蛋白胆固醇](@entry_id:172654)水平作为结局，我们就使用了替代性结局，这可能与患者的最终健康状况没有直接关联。PICO框架确保了我们的文献检索和证据评估从一开始就聚焦于一个有意义且可操作的问题。

### 理解与评价研究证据：因果推断的基础

在回答了“问什么”之后，我们转向“如何相信答案”。这要求我们理解不同研究设计的优劣，其核心在于它们控制偏倚和进行有效**因果推断 (causal inference)** 的能力。

#### 因果推断的基本框架：潜在结局与随机化

为了理解因果关系，我们需要引入**潜在结局 (potential outcomes)** 的概念。对于任何一个个体 $i$，我们设想其在接受干预 ($A_i=1$) 和未接受干预 ($A_i=0$) 两种情况下的潜在结局，分别表示为 $Y_i(1)$ 和 $Y_i(0)$。个体 $i$ 的因果效应就是 $Y_i(1) - Y_i(0)$。然而，在现实世界中，我们只能观察到其中一个潜在结局（事实结局），另一个则永远无法观测（反事实结局）。

因果推断的目标是从群体数据中估计平均因果效应 $\mathbb{E}[Y(1) - Y(0)]$。当研究不是随机分配时，一个主要的挑战是**混杂 (confounding)**，即接受干预和未接受干预的两组在基线时就存在系统性差异，这些差异本身也与结局相关。

**随机化**是解决混杂问题的最强大工具。在一项理想的**随机对照试验 (Randomized Controlled Trial, RCT)** 中，我们会随机分配参与者到不同的处理组。例如，在一项评估流感疫苗效果的试验中，参与者被随机分配到接种疫苗组 ($Z_i=1$) 或安慰剂组 ($Z_i=0$) [@problem_id:4525730]。随机分配确保了分配变量 $Z_i$ 与个体的所有基线特征（包括可测量的和不可测量的，以及他们的潜在结局）在统计上是独立的。这个关键属性被称为**[可交换性](@entry_id:263314) (exchangeability)**，用符号表示为 $(Y_i(1), Y_i(0)) \perp Z_i$。

由于可交换性，分配到疫苗组和安慰剂组的人在所有其他方面（平均而言）都是相似的。因此，两组在试验结束时观察到的结局差异，可以归因于“被分配接种疫苗”这一行为本身。

在实际试验中，并非所有被分配到疫苗组的人都会实际接种（可能因为错过了预约），这被称为**不依从性 (nonadherence)**。**意向性治疗 (Intention-to-Treat, ITT)** 分析原则要求，所有参与者都应在他们被随机分配的组中进行分析，无论他们最终是否接受了指定的干预。ITT分析所估计的，是**分配的平均因果效应**，即 $\mathbb{E}[\tilde{Y}(1) - \tilde{Y}(0)]$，其中 $\tilde{Y}(z)$ 是在被分配到 $z$ 组下的潜在结局。这个效应回答了一个非常实用的公共卫生问题：“作为一个政策，推荐或提供某种干预（例如疫苗）会带来什么效果？”这与“实际接受干预”的效果（即 $\mathbb{E}[Y(1) - Y(0)]$）有所不同，但它通常是评估公共卫生项目有效性的首选目标，因为它保留了随机化的所有优点，并反映了真实世界的不依从性。

#### 证据等级与研究设计

不同的研究设计在提供因果证据方面的能力不同，这形成了所谓的**证据等级 (hierarchy of evidence)**。一般而言，证据强度从高到低依次为：RCT的系统评价和Meta分析、单个高质量RCT、设计良好的准实验研究、观察性研究 [@problem_id:4525677]。

*   **随机对照试验 (RCTs)**:
    *   **解释性RCT (Explanatory RCT)**: 此类试验旨在严格控制的理想条件下检验干预是否有效，即评估**功效 (efficacy)**。例如，在一项戒烟研究中，招募高度积极的吸烟者，在学术医疗中心提供密集的咨询和免费尼古丁替代疗法（NRT），并进行严格的依从性监测和生化指标验证 [@problem_id:4525677]。这类试验通过随机化和严格的方案控制，最大化了**内部效度 (internal validity)**（即研究结果在样本内的准确性），但其结果可能难以推广到常规临床实践，即**外部效度 (external validity)** 可能有限。
    *   **实用性RCT (Pragmatic RCT)**: 此类试验旨在真实世界条件下评估干预在常规实践中的效果，即评估**效果 (effectiveness)**。例如，将基层医疗诊所随机分组，一组实施“选择退出”式戒烟项目，在日常工作流程中为患者提供戒烟支持和NRT补贴 [@problem_id:4525677]。这类试验的外部效度更高，但可能面临交叉污染等挑战，从而在ITT分析中稀释效应估计。

*   **[观察性研究](@entry_id:174507) (Observational Studies)**: 在[观察性研究](@entry_id:174507)中，研究者不分配干预，只是观察人群中的暴露与结局。这类研究的主要挑战是混杂。为了从观察性数据中获得有效的因果估计，我们需要识别并控制混杂因素。**有向无环图 (Directed Acyclic Graphs, DAGs)** 是一种强大的工具，可以帮助我们理清变量之间的因果关系。
    *   **混杂 (Confounding)**: 当一个变量既是暴露（$A$）的原因，又是结局（$Y$）的原因时，它就是一个混杂因素。在DAG中，这表现为存在一条从混杂因素到 $A$ 和 $Y$ 的“后门路径”（如 $A \leftarrow U \rightarrow Y$）。例如，在一项关于[维生素D](@entry_id:149473)补充剂（$A$）与流感风险（$Y$）关系的研究中，日晒行为（$U$）可能是一个混杂因素，因为日晒少的人更可能补充维生素D，同时日晒少也可能直接增加[流感](@entry_id:190386)风险 [@problem_id:4525648]。要估计 $A$ 对 $Y$ 的总因果效应，我们必须通过统计方法（如分层或回归）调整 $U$，以阻断这条后门路径。
    *   **中介 (Mediation)**: 中介变量（$M$）位于从暴露到结局的因果链上（$A \rightarrow M \rightarrow Y$）。例如，[维生素D](@entry_id:149473)补充剂（$A$）通过提高血清[维生素D](@entry_id:149473)水平（$M$）来降低[流感](@entry_id:190386)风险（$Y$） [@problem_id:4525648]。在估计 $A$ 对 $Y$ 的**总效应**时，我们**绝不能**调整中介变量，否则会阻断我们想要测量的部分因果路径。
    *   **对撞 (Collider Bias)**: 当一个变量（$C$）是暴露（$A$）和结局（$Y$）的共同效应时（$A \rightarrow C \leftarrow Y$），它被称为对撞节点。例如，是否因症状就医（$C$）可能受是否补充维生素D（$A$）和是否患上[流感](@entry_id:190386)（$Y$）的共同影响 [@problem_id:4525648]。在默认情况下，对撞节点会阻断 $A$ 和 $Y$ 之间的非因果路径。然而，如果我们错误地调整了对撞节点 $C$，就会打开这条路径，引入一种称为**[对撞偏倚](@entry_id:163186)**或选择偏倚的虚假关联。

*   **准实验研究 (Quasi-experiments)**: 这类研究介于RCT和[观察性研究](@entry_id:174507)之间。例如，**[双重差分法](@entry_id:636293) (difference-in-differences)** 通过比较干预组在政策实施前后的变化与一个匹配的[对照组](@entry_id:188599)同期的变化，来评估政策（如香烟消费税）的效果 [@problem_id:4525677]。虽然其内部效度不如RCT，但对于评估无法进行个体随机化的宏观政策，它通常是最佳且最可行的设计，并且具有很高的外部效度。

### 量化结局与偏倚

在评价了研究设计之后，我们需要精确地理解研究结果的量化指标，并警惕那些可能误导我们的统计偏倚。

#### 干预措施的效果度量

描述干预效果的指标主要分为两类：相对度量和绝对度量。假设在一项预防心肌梗死（MI）的试验中，干预组的5年风险为 $p_1 = 0.07$，[对照组](@entry_id:188599)为 $p_0 = 0.10$ [@problem_id:4525679]。

*   **风险比 (Risk Ratio, RR)**: 也称相对风险，是干预组与[对照组](@entry_id:188599)风险的比值。
    $RR = p_1 / p_0 = 0.07 / 0.10 = 0.70$。这表示干预使风险降低了 $30\%$。$RR$ 是一个相对度量，它描述了关联的强度。

*   **比值比 (Odds Ratio, OR)**: 是干预组与[对照组](@entry_id:188599)事件发生比值的比率。比值定义为 $p / (1-p)$。
    $OR = \frac{p_1/(1-p_1)}{p_0/(1-p_0)} = \frac{0.07/0.93}{0.10/0.90} \approx 0.68$。在事件罕见时，$OR$ 近似于 $RR$。

*   **风险差 (Risk Difference, RD)**: 也称绝对风险降低，是两组风险的绝对差值。
    $RD = p_1 - p_0 = 0.07 - 0.10 = -0.03$。这表示干预使5年内的绝对风险降低了3个百分点。

*   **风险比 (Hazard Ratio, HR)**: 来自生存分析，表示在任意时刻，干预组发生事件的[瞬时速率](@entry_id:182981)（风险）相对于[对照组](@entry_id:188599)的比值。它也是一个相对度量。

对于公共卫生决策和资源分配，**绝对度量（如RD）通常比相对度量更有用**。$RD = -0.03$ 直接告诉我们，每治疗100个高风险个体5年，可以预防3次MI事件。这使得计算**需治数 (Number Needed to Treat, NNT)** 成为可能，即预防一例不良事件需要治疗的人数：$NNT = 1 / |RD| = 1 / 0.03 \approx 34$。相比之下，一个看起来很大的相对风险降低（如 $RR=0.5$），如果基线风险极低（例如从 $0.002$ 降至 $0.001$），其绝对健康收益可能微乎其微。

#### 评估诊断与筛查试验

筛查是预防医学的重要组成部分。评估筛查试验性能的指标基于条件概率。设 $D$ 为患病事件，$T^+$ 为检验阳性事件。

*   **灵敏度 (Sensitivity)**: 指患病者中检验结果为阳性的概率，即 $P(T^+ | D)$。
*   **特异度 (Specificity)**: 指未患病者中检验结果为阴性的概率，即 $P(T^- | D^c)$。
*   **阳性预测值 (Positive Predictive Value, PPV)**: 指检验结果为阳性者中真正患病的概率，即 $P(D | T^+)$。
*   **阴性预测值 (Negative Predictive Value, NPV)**: 指检验结果为阴性者中确实未患病的概率，即 $P(D^c | T^-)$。

灵敏度和特异度是试验的内在属性，不随疾病流行率变化。然而，临床医生和患者更关心的是预测值，尤其是PPV。PPV的计算涉及[贝叶斯定理](@entry_id:151040)，它深刻地揭示了PPV对**疾病流行率 (prevalence)** 的依赖 [@problem_id:4525705]：

$$ PPV = \frac{\text{Sens} \times \text{Prev}}{(\text{Sens} \times \text{Prev}) + ((1 - \text{Spec}) \times (1 - \text{Prev}))} $$

其中 $\text{Sens}$ 是灵敏度，$\text{Spec}$ 是特异度，$\text{Prev}$ 是流行率。这个公式告诉我们，即使一个试验有很高的灵敏度（例如 $0.90$）和特异度（例如 $0.95$），如果它被用于一个低流行率（例如 $0.05$）的人群，其PPV也可能相当低。在上述例子中，计算出的 $PPV \approx 0.4865$，意味着一个阳性结果只有不到一半的概率是真正的阳性。这对于避免不必要的后续检查和过度治疗至关重要。

#### 筛查评估中的常见偏倚

使用生存率作为评估筛查效果的指标时，尤其需要警惕几种系统性偏倚，它们可能制造出筛查有效的假象，而实际上并未降低死亡率 [@problem_id:4525655]。

*   **领先时间偏倚 (Lead-time bias)**: 筛查使得疾病的诊断时间比出现临床症状时提前了。这段提前的时间被称为“领先时间”。即使筛查后的治疗完全没有改变疾病的自然病程（即死亡时间不变），仅仅因为诊断提前，从诊断到死亡的生存时间也会被人为地延长，从而使得生存率看起来更高。

*   **[长度偏倚](@entry_id:269579) (Length bias)**: 筛查更容易检测到生长缓慢、侵袭性较低的疾病，因为这些疾病的临床前阶段更长，被筛查“捕获”的时间窗口更大。而那些生长迅速、恶性程度高的疾病，其临床前阶段很短，往往在筛查间期就已发展到有症状阶段。由于筛查出的病例中富集了这些本身预后就更好的“懒惰型”疾病，会导致筛查组的生存率看起来优于常规诊断组。

*   **过度诊断 (Overdiagnosis)**: 筛查发现了一些“疾病”，这些病变在组织学上符合癌症标准，但其生物学行为是惰性的，在患者的整个生命周期内都不会引起症状或导致死亡。这些被过度诊断的病例增加了筛查组的总诊断人数，并且由于他们不会死于该病，他们被人为地计为“长期存活者”，从而极大地拔高了生存率统计数据。

一个数字示例可以清晰地说明这一点 [@problem_id:4525655]。假设在一个未筛查队列中，100人被诊断，其中20人在诊断后7年死亡（5年生存率 $20/100 = 0.20$）。在筛查队列中，由于1年的领先时间，这20人的生存时间变为8年；同时，筛查额外发现了40例过度诊断的病例（他们不会死于该病）。现在，筛查组的总诊断人数为140人，而5年生存者包括原来的20人、部分因领先时间而“跨过”5年门槛的病例以及所有40例过度诊断病例。这可能导致筛查组的5年生存率飙升至（例如）$90/140 \approx 0.64$。然而，两个队列中因该疾病死亡的总人数是完全相同的。这雄辩地证明了，**死亡率**而非生存率，才是评估筛查项目是否真正有效的金标准。

### 综合证据体系

通常，单一研究不足以形成决策，我们需要系统地回顾和综合所有相关证据。Meta分析是实现这一目标的关键统计方法。

#### 合并研究结果：固定效应与[随机效应模型](@entry_id:143279)

**Meta分析**通过统计方法将多个研究的结果进行合并，以得出一个更精确、更稳健的总[体效应](@entry_id:261475)估计。在合并效应量（如RR或OR）时，核心决策之一是选择**[固定效应模型](@entry_id:142997) (fixed-effect model)** 还是**随机效应模型 (random-effects model)** [@problem_id:4525693]。

*   **[固定效应模型](@entry_id:142997)**: 该模型假设所有研究都在估计同一个、唯一的真实效应量 $\theta$。观察到的研究结果之所以不同，完全是由于每个研究内部的抽样误差造成的。

*   **[随机效应模型](@entry_id:143279)**: 该模型则认为，每个研究的真实效应量 $\theta_i$ 本身就可能不同，它们是从一个以均值 $\mu$ 和方差 $\tau^2$ 为特征的分布中抽样而来的。这里的 $\tau^2$ 被称为**研究间异质性方差 (between-study variance)**，它代表了研究间真实效果的差异程度。

我们如何判断是否存在显著的研究间异质性呢？**$I^2$ 统计量**是常用的指标，它表示观察到的总变异中有多少比例可归因于研究间的真实异质性（而非[抽样误差](@entry_id:182646)）。例如，在一项关于流感疫苗有效性的Meta分析中，如果 $I^2 = 60\%$ [@problem_id:4525693]，这意味着观察到的效应量差异中，60%是由于研究间的真实差异（如不同地区的病毒株、不同的人群构成）造成的。

当 $I^2$ 值较高（通常认为 $>50\%$ 就属于显著异质性）时，[固定效应模型](@entry_id:142997)“所有研究效应相同”的基本假设被违背。此时，必须使用**随机效应模型**。该模型不仅估计了所有研究的平均效应 $\mu$，其计算出的[置信区间](@entry_id:138194)还会同时考虑[抽样误差](@entry_id:182646)和研究间的真实异质性，从而提供一个更保守、更诚实的效应不确定性范围。

#### 评估跨研究的偏倚：发表偏倚

在审查整个证据体系时，我们还必须警惕**发表偏倚 (publication bias)**，即研究结果的[统计显著性](@entry_id:147554)或方向会影响其发表的可能性。典型的情况是，那些得出“阳性”或统计显著结果的研究更容易被发表，而那些得出“阴性”或无显著差异结果的研究则可能被束之高阁，成为“文件柜里”的研究。

这种偏倚会导致已发表文献中的效应量被系统性高估。**漏斗图 (funnel plot)** 是一种直观检测发表偏倚的工具 [@problem_id:4525680]。它将每个研究的效应量绘制在横轴，研究的精确度（通常是[标准误](@entry_id:635378)的倒数 $1/\text{SE}$ 或样本量）绘制在纵轴。在没有偏倚的情况下，这些点应大致对称地分布在一个倒置的漏斗形状内，围绕着真实的效应量。小型研究（[精确度](@entry_id:143382)低）分散在底部，大型研究（[精确度](@entry_id:143382)高）聚集在顶部。

如果存在发表偏倚（例如，效应量小的阴性结果研究缺失），漏斗图就会呈现不对称的形态。**Egger's 回归检验**是一种用于定量评估漏斗图不对称性的统计方法 [@problem_id:4525680]。它通过回归方程 $z_i = \beta_0 + \beta_1 p_i$ 来拟合数据，其中 $z_i$ 是标准化效应量（效应量/标准误），$p_i$ 是[精确度](@entry_id:143382)（$1/\text{SE}$）。在没有不对称性的零假设下，截距 $\beta_0$ 应为0。如果 $\beta_0$ 显著不为0，则表明存在所谓的**小研究效应 (small-study effects)**——即小型研究系统性地报告了与大型研究不同的效应。

需要强调的是，漏斗图不对称或Egger's检验显著，并不等同于证实了发表偏倚。其他因素，如方法学质量较低的小型研究夸大了效应，或小型研究在高风险人群中进行（真实效应更大），也可能导致不对称。因此，这是一个警示信号，提示我们需要谨慎解释Meta分析的结果，而非一个确凿的诊断。

### 评级证据与做出推荐：GR[ADE](@entry_id:198734)框架

循证实践的最后一步，是将复杂的证据综合体转化为清晰、可操作的建议。**GR[ADE](@entry_id:198734) (Grading of Recommendations Assessment, Development and Evaluation)** 框架是目前国际上应用最广的证据评级和推荐制定体系 [@problem_id:4525688]。

GR[ADE](@entry_id:198734)体系明确区分了两个核心概念：

1.  **证据的确定性 (Certainty of Evidence)**: 也称证据质量，反映了我们对效应估计值接近真实效应值的信心程度。它分为四个等级：高、中、低、极低。对于干预效果的研究，RCTs的证据开始时被评为“高”确定性，观察性研究则从“低”确定性开始。然后，根据五个方面的考虑，对证据进行降级：
    *   **偏倚风险 (Risk of Bias)**: 研究设计或实施中存在的缺陷（如分配方案隐藏不清、缺乏盲法）。
    *   **不一致性 (Inconsistency)**: 不同研究的结果存在无法解释的显著差异（如 $I^2$ 值很高）。
    *   **间接性 (Indirectness)**: 研究的PICO与我们关心的PICO存在重要差异（如研究人群、干预措施、结局与目标不完全匹配）。
    *   **不精确性 (Imprecision)**: 效应估计的[置信区间](@entry_id:138194)过宽，包含了临床上截然不同的决策结果（例如，既包括显著获益，也包括无效应甚至有害）。
    *   **发表偏倚 (Publication Bias)**: 有理由怀疑存在发表偏倚。

2.  **推荐的强度 (Strength of Recommendation)**: 分为“强”和“条件性”（或弱）两种。它不仅取决于证据的确定性，还综合了以下因素的平衡：
    *   **利弊平衡**: 预期获益的大小与害处的大小。
    *   **价值观与偏好**: 患者或公众对不同结局的重视程度。
    *   **资源使用、可行性、可接受性、公平性**等。

例如，考虑一项评估通过短信（SMS）提醒来提高[流感疫苗](@entry_id:165908)接种率的干预措施 [@problem_id:4525688]。对于“流感相关住院率”这一关键结局，证据来自3项RCTs，起始确定性为“高”。但由于[置信区间](@entry_id:138194)为 $0.60$ 至 $1.20$，跨越了无效值1.0且范围很宽，存在严重的**不精确性**，应降一级至“中”。又因为试验都在北美城市进行，而我们的目标是包括资源有限的农村地区，存在**间接性**，应再降一级至“低”。因此，关于降低住院率的证据确定性为“低”。

然而，在做推荐时，我们还需考虑：该干预成本极低（每人0.05），几乎无害处，且易于实施。尽管其对最重要结局的益处不确定（低确定性证据），但鉴于其极佳的成本效益和可行性，我们很可能做出**条件性推荐**。这意味着，虽然我们推荐采纳该干预，但决策者应结合本地情况，并且承认未来更高质量的研究可能会改变我们的效应估计。这体现了GRADE框架的精髓：透明地评估我们知道什么、不知道什么，并在此基础上做出平衡各方因素的审慎决策。