## 引言
在预防医学和公共卫生领域，研究人员和从业者每天都面临着从海量数据中提取关键信息的挑战。无论是评估一项新疫苗的效果，监测社区的慢性病患病率，还是解读患者的实验室检查结果，我们都需要一套强大的工具来总结和理解数据。描述性统计中的集中趋势和[离散趋势度量](@entry_id:172010)，正是这样一套基础而关键的工具，它们帮助我们将复杂的数据集简化为易于理解的、有意义的数字摘要。

然而，简单地计算一个“平均值”是远远不够的。面对[偏态分布](@entry_id:175811)的数据、恼人的离群值或不同测量尺度的数据时，如何选择最恰当的统计指标来准确反映数据真实情况，避免得出误导性结论，是每个数据分析者必须掌握的核心技能。

本文旨在系统性地构建您对这些基础统计度量的理解和应用能力。在第一章 **“原理与机制”** 中，我们将深入探讨均值、中位数、标准差等核心概念的定义、计算及其对数据特征的敏感性。接下来的 **“应用与交叉学科联系”** 章节将展示这些指标如何在临床实践、流行病学监测和政策制定等真实世界场景中发挥关键作用。最后，通过 **“动手实践”** 部分，您将有机会运用所学知识解决具体的统计问题，巩固理解。

现在，让我们一同深入探索这些统计度量的世界，从其基本原理和机制开始，为进行精准的数据描述和分析奠定坚实的基础。

## 原理与机制

在预防医学和公共卫生领域，我们经常需要处理和总结来自人群的大量数据，以了解健康状况、疾病风险和干预效果。为了将复杂的数据集提炼为有意义且易于理解的信息，我们使用描述性统计量。这些统计量可分为两大类：[集中趋势度量](@entry_id:168414)（measures of central tendency），用于描述数据的“典型”或“中心”值；以及[离散趋势度量](@entry_id:172010)（measures of dispersion），用于量化数据的“变异性”或“分布范围”。本章将深入探讨这些度量的基本原理、计算方法及其在不同数据情境下的适用性，为在预防医学研究中做出明智的统计选择奠定基础。

### 描述分布的中心：基本概念

在探讨具体的度量之前，我们必须首先区分两个核心概念：**总体 (population)** 与 **样本 (sample)**。总体是指我们研究的全部个体（例如，某城市的所有成年人），其特征由**参数 (parameters)** 来描述，如[总体均值](@entry_id:175446) $\mu$ 和总体方差 $\sigma^2$。这些参数是固定的、未知的常数。由于我们通常无法研究整个总体，因此我们会抽取一个样本，即总体的一个子集。我们根据样本数据计算出的量称为**统计量 (statistics)**，如样本均值 $\bar{x}$ 和样本方差 $s^2$。统计量是随机变量，因为它们的值会随我们抽取的样本而变化。我们的目标是使用样本统计量来**估计**或推断未知的总体参数 [@problem_id:4545962]。

#### 均值（[算术平均值](@entry_id:165355)）

**均值 (mean)** 是最常用的[集中趋势度量](@entry_id:168414)。**总体均值 $\mu$** 定义为随机变量 $X$ 的**[期望值](@entry_id:150961) (expected value)**，记作 $\mathbb{E}[X]$。对于具有[概率密度函数](@entry_id:140610) $f_X(x)$ 的连续变量（如收缩压），其定义为：
$$ \mu = \mathbb{E}[X] = \int_{-\infty}^{\infty} x f_X(x) dx $$
对于具有[概率质量函数](@entry_id:265484) $p_X(x)$ 的[离散变量](@entry_id:263628)（如年就诊次数），其定义为：
$$ \mu = \mathbb{E}[X] = \sum_{x \in \mathcal{X}} x p_X(x) $$
其中 $\mathcal{X}$ 是变量 $X$ 所有可能取值的集合。这些定义的成立前提是[期望值](@entry_id:150961)存在，即 $\mathbb{E}[|X|] \lt \infty$。

相应地，来自总体的样本量为 $n$ 的一组观测值 $\{x_1, x_2, \dots, x_n\}$ 的**样本均值 $\bar{x}$** 是[总体均值](@entry_id:175446) $\mu$ 的估计量，其计算公式为：
$$ \bar{x} = \frac{1}{n} \sum_{i=1}^{n} x_i $$
样本均值直观地代表了数据的“重心”。

#### 中位数（中点）

**中位数 (median)** 是描述数据中心的另一种方式，它代表了数据的地理“中点”。**总体中位数 $m$** 是将概率分布一分为二的值，任何满足 $P(X \le m) \ge 0.5$ 和 $P(X \ge m) \ge 0.5$ 的值 $m$ 都是中位数。对于连续变量，如果其累积分布函数 (Cumulative Distribution Function, CDF) $F_X(m)$ 是严格单调递增的，那么中位数是唯一的，并满足 $F_X(m) = 0.5$ [@problem_id:4545927]。

**样本[中位数](@entry_id:264877)**是数据按升序排列后位于中间位置的数值。对于有 $n$ 个观测值的数据集：
- 如果 $n$ 是奇数，中位数是第 $\frac{n+1}{2}$ 个观测值。
- 如果 $n$ 是偶数，[中位数](@entry_id:264877)是第 $\frac{n}{2}$ 个和第 $\frac{n}{2}+1$ 个观测值的平均值。

例如，在一项关于高敏[C反应蛋白](@entry_id:148359)（hs-CRP）的研究中，一组 $n=9$ 的非急性感染成人的CRP水平（mg/L）排序后为：$0.2, 0.4, 0.6, 0.6, 0.7, 0.8, 1.0, 1.2, 1.5$。样本中位数是第 $(9+1)/2 = 5$ 个值，即 $0.7$ mg/L [@problem_id:4545985]。

#### 众数（最常见值）

**众数 (mode)** 是数据分布中出现频率最高的值。**总体众数**是使概率密度函数（连续变量）或概率质量函数（[离散变量](@entry_id:263628)）达到最大值的点。一个分布可能没有众数，也可能有一个（单峰）、两个（双峰）或多个众数。

**样本众数**是样本中出现次数最多的值。对于离散数据，如年度门诊就诊次数，众数很容易确定。然而，对于连续数据，如收缩压，由于精确重复观测的概率极低，直接在样本中寻找众数通常没有意义。在这种情况下，我们通常需要通过数据分组（如制作直方图）或使用[核密度估计](@entry_id:167724)等[平滑技术](@entry_id:634779)来估计众数 [@problem_id:4545927]。

### 量化离散程度：基本概念

除了了解数据的中心位置，我们还需要量化数据点围绕中心的散布程度，即离散趋势。

#### 方差与标准差

**方差 (variance)** 是衡量数据离散程度的核心指标，它量化了数据点与其均值的平均平方偏差。**总体方差 $\sigma^2$** 定义为：
$$ \sigma^2 = \mathbb{E}[(X - \mu)^2] $$
它代表了总体中所有个体值与[总体均值](@entry_id:175446) $\mu$ 之间差异的期望。

为了从样本中估计总体方差 $\sigma^2$，我们使用**样本方差 $s^2$**。一个好的估计量应该是**无偏的 (unbiased)**，即其[期望值](@entry_id:150961)应等于它所估计的参数。对于样本方差，其无偏估计量的公式为：
$$ s^2 = \frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{x})^2 $$
这里分母使用 $n-1$ 而不是 $n$ 是至关重要的，这被称为**[贝塞尔校正](@entry_id:169538) (Bessel's correction)**。因为在计算偏差时我们使用的是样本均值 $\bar{x}$ 而非未知的总体均值 $\mu$，这会导致偏差的平方和系统性地偏小。除以 $n-1$ 恰好可以修正这种偏差，使得 $\mathbb{E}[s^2] = \sigma^2$。

例如，在一项监测社区人群空腹血糖（FPG）的研究中，我们抽取了8名成年人，其FP[G值](@entry_id:204163)（单位 mg/dL）为：$70, 90, 95, 100, 105, 110, 115, 115$ [@problem_id:4545932]。
首先计算样本均值：$\bar{x} = \frac{70 + 90 + \dots + 115}{8} = \frac{800}{8} = 100$ mg/dL。
然后计算离差平方和：$\sum (x_i - \bar{x})^2 = (70-100)^2 + (90-100)^2 + \dots + (115-100)^2 = 1600$ $(\text{mg/dL})^2$。
最后，样本方差为：$s^2 = \frac{1600}{8-1} = \frac{1600}{7} \approx 228.6$ $\text{mg}^2/\text{dL}^2$。
请注意，方差的单位是原始数据单位的平方（例如 $\text{mg}^2/\text{dL}^2$），这使得它在临床上不直观。

为了解决方差单位不直观的问题，我们引入**标准差 (standard deviation)**，它被定义为方差的平方根。**样本标准差 $s$** 的计算公式为：
$$ s = \sqrt{s^2} = \sqrt{\frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{x})^2} $$
标准差的单位与原始数据相同，因此更易于解释。它可被理解为数据点偏离均值的“典型”或“平均”距离。

例如，一项评估减盐咨询效果的研究记录了8名参与者收缩压（SBP）的下降值（单位 mmHg）：$2, 5, 4, 8, 1, 6, 3, 5$ [@problem_id:4545964]。
该样本的均值为 $\bar{x} = 4.25$ mmHg，样本方差为 $s^2 \approx 5.07$ $\text{mmHg}^2$。
样本标准差为 $s = \sqrt{5.07} \approx 2.25$ mmHg。
我们可以这样解释：参与者个体SBP下降值通常偏离平均下降值（$4.25$ mmHg）约 $2.25$ mmHg。这个解释在临床上是有意义的，而方差的 $5.07$ $\text{mmHg}^2$ 则难以直观理解。

#### [四分位数](@entry_id:167370)与[四分位距](@entry_id:169909)

与[中位数](@entry_id:264877)类似，**[四分位数](@entry_id:167370) (quartiles)** 也是基于数据排序位置的度量。
- **第一[四分位数](@entry_id:167370) ($Q_1$)**，也称为下[四分位数](@entry_id:167370)，是第25百[分位数](@entry_id:178417)。大约有 $25\%$ 的数据小于或等于 $Q_1$。
- **第二[四分位数](@entry_id:167370) ($Q_2$)** 就是中位数。
- **第三[四分位数](@entry_id:167370) ($Q_3$)**，也称为上[四分位数](@entry_id:167370)，是第75百分位数。大约有 $75\%$ 的数据小于或等于 $Q_3$。

**[四分位距](@entry_id:169909) (Interquartile Range, IQR)** 定义为第三[四分位数](@entry_id:167370)与第一[四分位数](@entry_id:167370)之差：
$$ \text{IQR} = Q_3 - Q_1 $$
IQR 描述了数据中间 $50\%$ 的分布范围，是一个重要的[离散趋势度量](@entry_id:172010)。例如，在对一组包含15个PM2.5日均浓度（$\mu\text{g/m}^3$）的排序数据中，我们可能发现 $Q_1=3.8$，$Q_2=4.7$，$Q_3=7.8$。那么，IQR为 $7.8 - 3.8 = 4.0$ $\mu\text{g/m}^3$，这意味着中间一半的PM2.5浓度值分布在一个宽度为 $4.0$ $\mu\text{g/m}^3$ 的区间内 [@problem_id:4545905]。

### 选择正确的度量：分布形状的影响

选择哪种集中趋势和[离散趋势度量](@entry_id:172010)，很大程度上取决于数据的分布形状，尤其是其对称性和是否存在极端值（或称**离群值 (outliers)**）。

#### 对离群值的敏感性与稳健性

一个关键概念是**稳健性 (robustness)**。一个统计量如果不容易受到数据中少数极端值的剧烈影响，就被认为是稳健的。

让我们通过一个实例来比较均值和[中位数](@entry_id:264877)。考虑之前提到的CRP数据，在 $n=9$ 的样本中，均值为 $\bar{x}_9 \approx 0.78$ mg/L，[中位数](@entry_id:264877)为 $M_9 = 0.70$ mg/L。现在，我们加入第10名参与者，他因急性感染CRP值高达 $60$ mg/L。新样本 ($n=10$) 的均值变为 $\bar{x}_{10} = \frac{7.0 + 60.0}{10} = 6.70$ mg/L，而[中位数](@entry_id:264877)变为排序后第5和第6个值（$0.7$ 和 $0.8$）的平均值，即 $M_{10} = 0.75$ mg/L [@problem_id:4545985]。
这个例子清晰地表明：
- **均值**对离群值**高度敏感**。一个极端值可以将其“拉”向自己，使其不再代表大多数数据的中心。
- **[中位数](@entry_id:264877)**对离群值**非常稳健**。只要排序位置不变，极端值的大小对[中位数](@entry_id:264877)几乎没有影响。

同样地，标准差与IQR也表现出类似的特性。标准差的计算涉及每个数据点与均值的平方差，因此一个离群值（其离差很大）会通过其巨大的平方项极大地增加标准差的值。相反，IQR只关心数据的中间 $50\%$，完全忽略了两端极端值的大小。

例如，在一项呼吸道疾病监测中，记录了16天的就诊人数，其中一天的数据被错误地记为 $220$，而其他天的数值都在 $31$ 到 $40$ 之间。计算结果显示，标准差约为 $46$ 次就诊，而IQR仅为 $4.5$ 次就诊 [@problem_id:4545901]。显然，IQR更好地反映了数据集“主体”的变异性，而标准差则被单个离群值严重扭曲。

因此，一个重要的实践原则是：
- 对于**对称**且没有显著离群值的分布（如正态分布），**均值和标准差**是描述其中心和离散趋势的有效度量。
- 对于**偏态 (skewed)** 分布或存在显著离群值的分布，**[中位数](@entry_id:264877)和IQR** 通常是更可取、更稳健的描述性统计量 [@problem_id:4545905]。

#### 稳健性的量化：[崩溃点](@entry_id:165994)

稳健性可以通过**[崩溃点](@entry_id:165994) (breakdown point)** 的概念进行更形式化的定义。一个估计量的[崩溃点](@entry_id:165994)是指，在不使该估计量的值变得任意大或小的情况下，数据集中能被“污染”（即替换为任意值）的最大比例。
- **均值和标准差**的[崩溃点](@entry_id:165994)为 $0\%$。这意味着，理论上只需改变一个数据点，将其变为无穷大，就能使均值或标准差也变为无穷大。
- **中位数**的[崩溃点](@entry_id:165994)为 $50\%$。你需要污染至少一半的数据才能使[中位数](@entry_id:264877)“崩溃”。
- **IQR**的[崩溃点](@entry_id:165994)为 $25\%$。你需要污染超过 $25\%$ 的数据才能使IQR“崩溃”。

[崩溃点](@entry_id:165994)的概念在自动化监测系统（如疾病[暴发监测](@entry_id:169992)）中尤为重要，因为这些系统需要能够抵抗偶尔出现的数据录入错误或真实但极端的事件，而不产生错误的警报 [@problem_id:4545901]。

#### 分布形状的量化：[偏度与峰度](@entry_id:754936)

除了直观判断，我们还可以使用**[偏度](@entry_id:178163) (skewness)** 和**[峰度](@entry_id:269963) (kurtosis)** 来定量描述分布的形状。它们是基于数据的标准化[中心矩](@entry_id:270177)来定义的。
- **偏度 ($\gamma_1$)** 是标准化的第三[中心矩](@entry_id:270177)，用于衡量分布的**不对称性**。
    - $\gamma_1 = 0$：分布对称。
    - $\gamma_1 > 0$：分布**右偏**（或正偏），尾部向右延伸，均值通常大于中位数。
    - $\gamma_1  0$：分布**左偏**（或负偏），尾部向左延伸，均值通常小于中位数。
- **峰度 ($\gamma_2$)** 是标准化的第四[中心矩](@entry_id:270177)，用于衡量分布尾部的“厚重”程度和峰值的“尖锐”程度。我们通常使用**超额[峰度](@entry_id:269963) ($\kappa = \gamma_2 - 3$)**，它是与正态分布（其[峰度](@entry_id:269963)为3）的[峰度](@entry_id:269963)进行比较。
    - $\kappa = 0$：分布的尾部厚重程度与正态分布相当（常态峰）。
    - $\kappa  0$：分布为**尖峰 (leptokurtic)**，具有比正态分布更“厚”的尾部和更“尖”的峰，这意味着出现极端值的概率更高。
    - $\kappa  0$：分布为**平峰 (platykurtic)**，具有比正态分布更“薄”的尾部和更“平”的峰。

例如，对于一组苯暴露浓度数据，计算得出偏度 $\gamma_1 \approx 2.8$，超额[峰度](@entry_id:269963) $\kappa \approx 6.2$ [@problem_id:4545907]。这个结果有力地证明了数据分布是高度右偏和尖峰的（[重尾分布](@entry_id:142737)），这为我们选择使用中位数而非均值来代表“典型”暴露水平提供了强有力的定量依据。

#### 比较相对[离散度](@entry_id:168823)：变异系数

当我们想比较两组或多组数据离散程度时，如果它们的均值相差很大，直接比较标准差可能会产生误导。例如，均值为 $100$、标准差为 $10$ 的一组数据，与均值为 $20$、标准差为 $5$ 的一组数据相比，哪一个“更”分散？

为了进行这种相对比较，我们使用**[变异系数](@entry_id:272423) (Coefficient of Variation, CV)**。它被定义为标准差与均值的比值，通常以百分比表示：
$$ \text{CV} = \frac{s}{\bar{x}} $$
CV是一个**无量纲**的量，它表示标准差占均值的比例。它不受测量单位变化的影响，因此非常适合比较不同尺度或不同单位的数据的相对变异性。

例如，假设U区的[维生素D](@entry_id:149473)水平均值为 $20$ ng/mL，标准差为 $6$ ng/mL；而R区的均值为 $30$ ng/mL，标准差为 $9$ ng/mL [@problem_id:4545990]。R区的标准差更大，但其均值也更高。计算两区的CV：
- $\text{CV}_U = \frac{6}{20} = 0.30$
- $\text{CV}_R = \frac{9}{30} = 0.30$
两区的CV完全相同，表明它们的**相对离散程度**是一样的：在两个区中，标准差都是均值的 $30\%$。这个结论不会因为我们将单位从 ng/mL 转换为 nmol/L 而改变。

### 真实世界数据中的实际挑战

在应用这些度量时，我们还必须考虑两个普遍存在于预防医学研究中的挑战：测量误差和缺失数据。

#### 测量误差的影响

我们观察到的数据往往不是“真实值”，而是真实值与**测量误差 (measurement error)** 的结合。一个简单的模型是 $Y_i = X_i + e_i$，其中 $Y_i$ 是观测值， $X_i$ 是真值， $e_i$ 是误差。假设测量误差的均值为零（即 $\mathbb{E}[e_i] = 0$）且与[真值](@entry_id:636547)无关。
- **对均值估计的影响**：在这种情况下，观测值的均值 $\bar{Y}$ 仍然是[真值](@entry_id:636547)均值 $\mu_X$ 的一个[无偏估计](@entry_id:756289)，因为 $\mathbb{E}[\bar{Y}] = \mathbb{E}[\bar{X} + \bar{e}] = \mathbb{E}[\bar{X}] + \mathbb{E}[\bar{e}] = \mu_X + 0 = \mu_X$。
- **对方差估计的影响**：然而，观测值的方差会偏高。由于 $X_i$ 和 $e_i$ 独立，$\text{Var}(Y_i) = \text{Var}(X_i) + \text{Var}(e_i) = \sigma_X^2 + \tau^2$，其中 $\tau^2$ 是测量误差的方差。因此，我们从观测数据计算出的样本方差 $s_Y^2$ 实际上是 $\sigma_X^2 + \tau^2$ 的[无偏估计](@entry_id:756289)，而不是我们真正关心的 $\sigma_X^2$ 的无偏估计。它会系统性地高估真实的生物学变异。如果能通过仪器校准等方法得知 $\tau^2$ 的大小，我们可以通过计算 $s_Y^2 - \tau^2$ 来获得对 $\sigma_X^2$ 的[无偏估计](@entry_id:756289) [@problem_id:4545962]。

#### [缺失数据](@entry_id:271026)的影响

在队列研究等纵向研究中，部分参与者可能因为失访等原因而未能提供随访数据，这导致了**[缺失数据](@entry_id:271026) (missing data)**。处理缺失数据的方式取决于数据缺失的机制，这会严重影响我们估计的无偏性。

考虑一个结果变量 $Y_i$（如血糖值）和一组协变量 $X_i$（如年龄、性别），并用 $R_i$ 表示 $Y_i$ 是否被观测到（$R_i=1$ 表示观测到，$R_i=0$ 表示缺失）。最简单的分析方法是**完整病例分析 (complete-case analysis)**，即只分析所有数据都完整的参与者。这种方法的有效性取决于以下三种缺失机制 [@problem_id:4545920]：

1.  **[完全随机缺失](@entry_id:170286) (Missing Completely At Random, MCAR)**：缺失的概率与任何变量（包括 $Y_i$ 和 $X_i$）都无关。即 $P(R_i=1 | Y_i, X_i) = P(R_i=1)$。在这种理想情况下，完整病例构成原始样本的一个随机子样本，因此对其进行的分析可以得到对总体参数的[无偏估计](@entry_id:756289)。唯一的损失是样本量减小导致的统计功效下降。

2.  **[随机缺失](@entry_id:168632) (Missing At Random, MAR)**：缺失的概率与未观测到的 $Y_i$ 值无关，但可以依赖于观测到的协变量 $X_i$。即 $P(R_i=1 | Y_i, X_i) = P(R_i=1 | X_i)$。例如，老年人（$X_i$）可能更容易失访，但失访与否与他们的血糖水平（$Y_i$）在控制了年龄后没有关系。在这种情况下，完整病例不再是总体的随机子样本。例如，如果老年人血糖更高且更容易失访，那么完整病例样本中的老年人比例会偏低，从而导致计算出的平均血糖值偏低。因此，**在MAR机制下，简单的完整病例分析通常会导致有偏估计**。需要使用加权或[多重插补](@entry_id:177416)等更高级的方法来校正偏差。

3.  **[非随机缺失](@entry_id:163489) (Missing Not At Random, MNAR)**：缺失的概率直接依赖于未观测到的 $Y_i$ 值本身。即 $P(R_i=1 | Y_i, X_i)$ 依赖于 $Y_i$。例如，血糖水平极高的患者可能因为感觉不适而更倾向于缺席随访。这是最糟糕的情况，因为缺失机制与我们试图测量的结果直接相关。**在MNAR机制下，完整病例分析几乎总是导致严重的偏倚**，且这种偏倚极难通过标准统计方法校正。

理解这些原理对于批判性地评估预防医学研究的结果至关重要，因为对集中趋势和离散趋势的错误估计可能导致关于风险因素、疾病负担和干预效果的错误结论。