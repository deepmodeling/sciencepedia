{"hands_on_practices": [{"introduction": "地图投影是GIS分析的基石，它将三维的地球表面展现在二维平面上。然而，任何投影都无法完美保留所有地理属性，例如面积、形状或距离。在公共卫生领域，基于区域面积进行资源分配或计算患病率时，面积的准确性至关重要。本练习 [@problem_id:4790275] 将通过一个假设情景，量化在网络地图中常用的Web墨卡托投影相对于阿尔伯斯等积投影所产生的面积误差，从而强调为特定任务选择正确投影的必要性。", "problem": "一个地理信息系统（GIS）测绘团队正在为一个中心位于纬度 $\\phi = 20^{\\circ}$ 的沿海地区绘制血吸虫病干预地图。该地区的干预区真实地表面积为 $1000\\,\\text{km}^{2}$，流行病学部门要求进行精确的基于面积的资源分配。正在考虑两种备选地图投影：常用于网络地图的Web墨卡托投影（也称为球面墨卡托投影），以及旨在保持面积不变的阿尔伯斯等积圆锥投影。\n\n从墨卡托投影的标准球面地球公式和局部比例尺变形的定义出发，推导Web墨卡托投影的面积变形系数作为纬度的函数。使用阿尔伯斯等积投影的等积性质来证明其作为比较基准的合理性。然后，计算当纬度 $\\phi = 20^{\\circ}$ 处的 $1000\\,\\text{km}^{2}$ 干预区使用Web墨卡托投影而非阿尔伯斯等积投影进行制图时，所产生的面积百分比误差。\n\n将面积百分比误差以小数形式表示（不要使用百分号），并将您的答案四舍五入到四位有效数字。", "solution": "该问题是有效的，因为它以地图学原理为科学基础，提法恰当，具有足够的信息以获得唯一解，并且陈述客观。我们将继续进行解答。\n\n问题要求完成三个主要任务：\n1.  推导Web墨卡托（球面墨卡托）投影的面积变形系数作为纬度 $\\phi$ 的函数。\n2.  证明使用阿尔伯斯等积投影作为面积比较基准的合理性。\n3.  计算当使用Web墨卡托投影绘制纬度 $\\phi = 20^{\\circ}$ 处的区域时，产生的面积百分比误差。\n\n**1. 墨卡托投影面积变形系数的推导**\n\n墨卡托投影将半径为 $R$ 的球面上经度为 $\\lambda$、纬度为 $\\phi$ 的点映射到笛卡尔平面上的点 $(x, y)$。其标准球面公式为：\n$$x = R(\\lambda - \\lambda_0)$$\n$$y = R \\ln\\left[\\tan\\left(\\frac{\\pi}{4} + \\frac{\\phi}{2}\\right)\\right]$$\n其中 $\\lambda_0$ 是中央经线的经度。\n\n为了求得变形，我们分析局部比例尺因子。比例尺因子是地图上的微分距离与球面上相应微分距离之比。球面上的无穷小弧长 $ds$ 由线元给出：\n$$ds^2 = (R \\, d\\phi)^2 + (R \\cos\\phi \\, d\\lambda)^2$$\n第一项对应沿经线（南北方向）的移动，第二项对应沿纬线（东西方向）的移动。\n\n在地图上，相应的无穷小弧长 $dl$ 由下式给出：\n$$dl^2 = dx^2 + dy^2$$\n我们通过对映射方程求全微分来得到 $dx$ 和 $dy$：\n$$dx = \\frac{\\partial x}{\\partial \\phi} d\\phi + \\frac{\\partial x}{\\partial \\lambda} d\\lambda$$\n$$dy = \\frac{\\partial y}{\\partial \\phi} d\\phi + \\frac{\\partial y}{\\partial \\lambda} d\\lambda$$\n\n所需的偏导数为：\n$\\frac{\\partial x}{\\partial \\phi} = 0$\n$\\frac{\\partial x}{\\partial \\lambda} = R$\n$\\frac{\\partial y}{\\partial \\lambda} = 0$\n\n对于 $\\frac{\\partial y}{\\partial \\phi}$，我们使用链式法则：\n$$\\frac{\\partial y}{\\partial \\phi} = \\frac{d}{d\\phi} \\left(R \\ln\\left[\\tan\\left(\\frac{\\pi}{4} + \\frac{\\phi}{2}\\right)\\right]\\right) = R \\cdot \\frac{1}{\\tan\\left(\\frac{\\pi}{4} + \\frac{\\phi}{2}\\right)} \\cdot \\frac{d}{d\\phi}\\left(\\tan\\left(\\frac{\\pi}{4} + \\frac{\\phi}{2}\\right)\\right)$$\n$$\\frac{\\partial y}{\\partial \\phi} = R \\cdot \\frac{1}{\\tan\\left(\\frac{\\pi}{4} + \\frac{\\phi}{2}\\right)} \\cdot \\sec^2\\left(\\frac{\\pi}{4} + \\frac{\\phi}{2}\\right) \\cdot \\frac{1}{2}$$\n代入三角恒等式 $\\tan\\theta = \\frac{\\sin\\theta}{\\cos\\theta}$ 和 $\\sec\\theta = \\frac{1}{\\cos\\theta}$：\n$$\\frac{\\partial y}{\\partial \\phi} = R \\cdot \\frac{\\cos\\left(\\frac{\\pi}{4} + \\frac{\\phi}{2}\\right)}{\\sin\\left(\\frac{\\pi}{4} + \\frac{\\phi}{2}\\right)} \\cdot \\frac{1}{\\cos^2\\left(\\frac{\\pi}{4} + \\frac{\\phi}{2}\\right)} \\cdot \\frac{1}{2} = R \\cdot \\frac{1}{2\\sin\\left(\\frac{\\pi}{4} + \\frac{\\phi}{2}\\right)\\cos\\left(\\frac{\\pi}{4} + \\frac{\\phi}{2}\\right)}$$\n使用二倍角恒等式 $2\\sin\\theta\\cos\\theta = \\sin(2\\theta)$：\n$$\\frac{\\partial y}{\\partial \\phi} = R \\cdot \\frac{1}{\\sin\\left(2\\left(\\frac{\\pi}{4} + \\frac{\\phi}{2}\\right)\\right)} = R \\cdot \\frac{1}{\\sin\\left(\\frac{\\pi}{2} + \\phi\\right)}$$\n使用余函数恒等式 $\\sin(\\frac{\\pi}{2} + \\phi) = \\cos\\phi$：\n$$\\frac{\\partial y}{\\partial \\phi} = R \\frac{1}{\\cos\\phi} = R \\sec\\phi$$\n\n沿经线的局部比例尺因子 $h$ 是地图距离 $dy$（当 $d\\lambda=0$ 时）与球面距离 $R \\, d\\phi$ 之比：\n$$h = \\frac{dy}{R \\, d\\phi} = \\frac{(\\partial y / \\partial \\phi) \\, d\\phi}{R \\, d\\phi} = \\frac{R \\sec\\phi \\, d\\phi}{R \\, d\\phi} = \\sec\\phi$$\n\n沿纬线的局部比例尺因子 $k$ 是地图距离 $dx$（当 $d\\phi=0$ 时）与球面距离 $R \\cos\\phi \\, d\\lambda$ 之比：\n$$k = \\frac{dx}{R \\cos\\phi \\, d\\lambda} = \\frac{(\\partial x / \\partial \\lambda) \\, d\\lambda}{R \\cos\\phi \\, d\\lambda} = \\frac{R \\, d\\lambda}{R \\cos\\phi \\, d\\lambda} = \\frac{1}{\\cos\\phi} = \\sec\\phi$$\n\n面积变形系数 $S$ 是两个相互垂直方向上比例尺因子的乘积。对于墨卡托投影，$h=k$，这证实了它是一个等角（保角）投影。\n$$S(\\phi) = h \\cdot k = (\\sec\\phi) \\cdot (\\sec\\phi) = \\sec^2\\phi$$\n因此，墨卡托投影的面积变形系数为 $\\sec^2\\phi$。\n\n**2. 证明阿尔伯斯等积投影作为基准的合理性**\n\n阿尔伯斯投影是一种等积（或等面积）投影。根据定义，这种投影在整个地图上都保持面积变形系数 $S=1$。这意味着地图上任何地物的面积都等于其在地球上的真实面积乘以整个地图的一个单一恒定比例尺因子。在比较特定区域的面积时，阿尔伯斯投影的地图提供了真实的按比例缩放的面积，使其成为衡量像墨卡托投影这样的非等积投影所引入的面积误差的正确且理想的基准。因此，阿尔伯斯地图上显示的面积 $A_{albers}$ 被视为真实面积 $A_{true}$。\n\n**3. 面积百分比误差的计算**\n\n干预区的真实地表面积为 $A_{true} = 1000\\,\\text{km}^{2}$。该地区中心的纬度是 $\\phi = 20^{\\circ}$。\n该区域在Web墨卡托地图上显示的面积 $A_{mercator}$ 是真实面积乘以该纬度处的面积变形系数：\n$$A_{mercator} = A_{true} \\cdot S(\\phi) = A_{true} \\sec^2\\phi$$\n面积百分比误差，以小数形式表示（即分数误差），由以下公式给出：\n$$E = \\frac{A_{mapped} - A_{true}}{A_{true}}$$\n在我们的例子中，$A_{mapped} = A_{mercator}$，而“真实”参考是 $A_{albers} = A_{true}$。\n$$E = \\frac{A_{mercator} - A_{true}}{A_{true}} = \\frac{A_{true} \\sec^2\\phi - A_{true}}{A_{true}} = \\sec^2\\phi - 1$$\n使用基本三角恒等式 $1 + \\tan^2\\phi = \\sec^2\\phi$，误差的表达式简化为：\n$$E = \\tan^2\\phi$$\n现在，我们代入给定的纬度 $\\phi = 20^{\\circ}$：\n$$E = \\tan^2(20^{\\circ})$$\n我们计算 $\\tan(20^{\\circ})$ 的值：\n$$\\tan(20^{\\circ}) \\approx 0.363970234$$\n将此值平方得到误差：\n$$E \\approx (0.363970234)^2 \\approx 0.13247444$$\n问题要求答案四舍五入到四位有效数字。\n$$E \\approx 0.1325$$\n这意味着在纬度 $20^{\\circ}$ 处，Web墨卡托投影将面积夸大了大约 $13.25\\%$。", "answer": "$$\\boxed{0.1325}$$", "id": "4790275"}, {"introduction": "在空间流行病学中，可变单元问题（MAUP）是一个根本性的挑战，它指出统计结果会随着数据聚合的空间单元（如村庄与行政区）的改变而变化。这意味着，疾病流行率或其与环境因素的关联强度，可能因我们分析的地理尺度不同而得出截然不同的结论。本练习 [@problem_id:4790223] 通过一个具体的数据集，让您亲手演示MAUP效应以及相关的生态谬误风险，培养您对空间聚合数据分析结果的批判性思维。", "problem": "给定一个医学寄生虫学场景，其中使用地理信息系统（GIS）在不同空间聚合级别上绘制寄生虫病地图。可变分区单元问题（MAUP）指出，当数据聚合到不同的区域单元（例如，从村庄到地区）时，估计值和关联关系可能会发生变化。您的任务是实现一个程序，量化当数据从村庄级别聚合到地区级别时寄生虫感染率估计值如何变化，并通过比较不同聚合级别上感染率与协变量之间的关联来评估生态谬误的风险。\n\n使用的基本定义：\n- 村庄级别的寄生虫感染率定义为 $p_i = I_i / N_i$，其中 $I_i$ 是村庄 $i$ 的感染人数，$N_i$ 是村庄 $i$ 的被检测人数。感染率必须以小数形式表示（例如，$25$ 百分比表示为 $0.25$）。\n- 对于地区 $d$，按人口加权（按被检测人数加权）的感染率为 $P_d = \\frac{\\sum_{i \\in d} I_i}{\\sum_{i \\in d} N_i}$。\n- 对于地区 $d$，其下属村庄的未加权平均感染率为 $\\bar{p}_d = \\frac{1}{k_d} \\sum_{i \\in d} p_i$，其中 $k_d$ 是地区 $d$ 的村庄数量。\n- 地区 $d$ 的 MAUP 差异为 $D_d = \\bar{p}_d - P_d$。将 MAUP 总结为所有地区的平均绝对差异：$\\mathrm{MAD} = \\frac{1}{D} \\sum_{d=1}^{D} |D_d|$，其中 $D$ 是地区数量。\n- 设 $x_i$ 为一个村庄级别的协变量，表示到最近的常年淡水源的距离，单位为公里。对于地区 $d$，定义人口加权协变量 $X_d = \\frac{\\sum_{i \\in d} N_i x_i}{\\sum_{i \\in d} N_i}$，单位为公里。\n- 计算村庄级别感染率与协变量之间的皮尔逊相关系数 $r_v = \\mathrm{corr}\\left(\\{p_i\\}, \\{x_i\\}\\right)$。同时计算地区级别加权感染率与地区级别加权协变量之间的皮尔逊相关系数 $r_d = \\mathrm{corr}\\left(\\{P_d\\}, \\{X_d\\}\\right)$。\n- 定义一个生态谬误风险指标，它是一个布尔值 $\\mathrm{risk}$，如果 $\\operatorname{sign}(r_v) \\neq \\operatorname{sign}(r_d)$，则为 $\\mathrm{True}$，否则为 $\\mathrm{False}$。其中 $\\operatorname{sign}(\\cdot)$ 表示符号函数，将正值映射到 $+1$，负值映射到 $-1$，零映射到 $0$。\n\n所有距离均以公里为单位。所有感染率值均以小数形式处理。\n\n实现一个程序，对下面的每个测试用例，计算：\n- 所有地区的平均绝对差异 $\\mathrm{MAD}$。\n- 村庄级别 $p_i$ 和 $x_i$ 之间的皮尔逊相关系数 $r_v$。\n- 地区级别 $P_d$ 和 $X_d$ 之间的皮尔逊相关系数 $r_d$。\n- 如上定义的生态谬误风险布尔值 $\\mathrm{risk}$。\n\n测试套件数据（每个测试用例包含 $3$ 个地区；每个地区包含 $3$ 个村庄；每个村庄由 $(N_i, I_i, x_i)$ 指定，其中 $N_i$ 是被检测人数，$I_i$ 是感染人数，$x_i$ 是距离，单位为公里）：\n\n测试用例 $1$（具有不同被检测人数的一般情况）：\n- 地区 $A$：村庄 $\\{(80, 40, 2.0), (120, 36, 5.0), (200, 50, 8.0)\\}$。\n- 地区 $B$：村庄 $\\{(150, 69, 1.5), (90, 32, 4.0), (60, 12, 9.0)\\}$。\n- 地区 $C$：村庄 $\\{(50, 5, 10.0), (150, 42, 3.0), (100, 40, 6.0)\\}$。\n\n测试用例 $2$（被检测人数相等的边界情况，因此对每个地区都有 $P_d = \\bar{p}_d$）：\n- 地区 $A$：村庄 $\\{(100, 20, 2.0), (100, 30, 4.0), (100, 40, 6.0)\\}$。\n- 地区 $B$：村庄 $\\{(100, 10, 1.0), (100, 50, 5.0), (100, 90, 9.0)\\}$。\n- 地区 $C$：村庄 $\\{(100, 30, 3.0), (100, 70, 7.0), (100, 50, 11.0)\\}$。\n\n测试用例 $3$（为展示通过符号翻转可能出现的生态谬误而构造的情况）：\n- 具有低协变量值的地区：村庄 $\\{(100, 60, 1.0), (100, 50, 2.0), (100, 40, 3.0)\\}$。\n- 具有中等协变量值的地区：村庄 $\\{(100, 62, 5.0), (100, 52, 6.0), (100, 42, 7.0)\\}$。\n- 具有高协变量值的地区：村庄 $\\{(100, 64, 9.0), (100, 54, 10.0), (100, 44, 11.0)\\}$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个测试用例的结果是一个形如 $[\\mathrm{MAD}, r_v, r_d, \\mathrm{risk}]$ 的列表。例如，输出应如下所示：$[[\\text{mad}_1, \\text{rv}_1, \\text{rd}_1, \\text{risk}_1],[\\text{mad}_2, \\text{rv}_2, \\text{rd}_2, \\text{risk}_2],[\\text{mad}_3, \\text{rv}_3, \\text{rd}_3, \\text{risk}_3]]$。所有数值均为浮点数，布尔值为 True 或 False。", "solution": "该问题要求分析医学寄生虫学中空间聚合对统计估计的影响，这一现象被称为可变分区单元问题（MAUP）。任务是通过比较两个空间尺度的数据（即单个村庄级别和聚合后的地区级别）来量化这种影响，并评估相关的生态谬误风险。解决方案涉及基于所提供的定义和数据进行系统性的、分步的计算。\n\n程序设计如下：\n\n首先，我们在最细粒度的级别（即村庄级别）处理数据。对于每个测试用例，我们汇编一个包含所有地区所有村庄的综合列表。对于每个村庄 $i$（其特征为被检测人数 $N_i$、感染人数 $I_i$ 和协变量 $x_i$（到水源的距离）），我们计算其寄生虫感染率。村庄级别的感染率 $p_i$ 定义为感染人数与被检测人数的比率：\n$$p_i = \\frac{I_i}{N_i}$$\n此步骤为整个研究区域生成两个完整的数据集：一组是村庄感染率 $\\{p_i\\}$，另一组是村庄协变量 $\\{x_i\\}$。\n\n其次，我们将村庄数据聚合到地区级别。对于每个包含一组村庄的地区 $d$，我们计算两种不同的全区感染率度量。第一种是人口加权感染率 $P_d$，它代表整个地区人口的真实感染率。其计算方法是对该地区内所有村庄的感染人数和被检测人数分别求和后相除：\n$$P_d = \\frac{\\sum_{i \\in d} I_i}{\\sum_{i \\in d} N_i}$$\n第二种度量是未加权平均感染率 $\\bar{p}_d$。这是该地区内所有 $k_d$ 个村庄的单个村庄感染率 $p_i$ 的算术平均值：\n$$\\bar{p}_d = \\frac{1}{k_d} \\sum_{i \\in d} p_i$$\n同样，我们为每个地区计算一个聚合的、人口加权的协变量 $X_d$：\n$$X_d = \\frac{\\sum_{i \\in d} N_i x_i}{\\sum_{i \\in d} N_i}$$\n这将产生两组地区级别的数据：一组是加权感染率 $\\{P_d\\}$，另一组是加权协变量 $\\{X_d\\}$。\n\n第三，我们量化 MAUP 的影响程度。对于单个地区 $d$，两种地区级别感染率估计值之间的差异即为 MAUP 差异 $D_d = \\bar{p}_d - P_d$。产生这种差异的原因是，$\\bar{p}_d$ 对每个村庄的感染率给予相同的权重，而不管其人口规模如何，而 $P_d$ 则考虑了人口规模。为了总结所有 $D$ 个地区的这种效应，我们计算平均绝对差异（$\\mathrm{MAD}$）：\n$$\\mathrm{MAD} = \\frac{1}{D} \\sum_{d=1}^{D} |D_d|$$\n\n第四，我们分析两个空间尺度上感染率与协变量之间的关系，以评估生态谬误的风险。当为一个群体观察到的关联被错误地假定对该群体内的个体也成立时，就会发生生态谬误。我们计算两个皮尔逊相关系数：\n1.  村庄级别的相关性 $r_v$，即单个村庄感染率 $\\{p_i\\}$ 和协变量 $\\{x_i\\}$ 之间的相关性：\n    $$r_v = \\mathrm{corr}\\left(\\{p_i\\}, \\{x_i\\}\\right)$$\n2.  地区级别的相关性 $r_d$，即聚合后的地区感染率 $\\{P_d\\}$ 和协变量 $\\{X_d\\}$ 之间的相关性：\n    $$r_d = \\mathrm{corr}\\left(\\{P_d\\}, \\{X_d\\}\\right)$$\n如果关联的方向在聚合后发生改变，则表明存在生态谬误的风险。我们用一个布尔指标 $\\mathrm{risk}$ 来形式化这一点，如果两个相关系数的符号不同，则将其设置为 $\\mathrm{True}$，否则设置为 $\\mathrm{False}$。符号函数 $\\operatorname{sign}(z)$ 定义为：当 $z > 0$ 时为 $+1$，当 $z  0$ 时为 $-1$，当 $z = 0$ 时为 $0$。\n$$\\mathrm{risk} = (\\operatorname{sign}(r_v) \\neq \\operatorname{sign}(r_d))$$\n\n这个完整的计算序列将应用于提供的每个测试用例。每个用例的最终结果是一个包含四个计算指标的列表：$[\\mathrm{MAD}, r_v, r_d, \\mathrm{risk}]$。", "answer": "```python\n# language: Python\n# version: 3.12\n# libraries:\n#   - name: numpy\n#     version: 1.23.5\n\nimport numpy as np\n\ndef calculate_results(districts_data):\n    \"\"\"\n    Computes MAUP metrics and correlation coefficients for a single test case.\n    \n    Args:\n        districts_data (list): A list of districts, where each district is a list\n                             of village data tuples (N_i, I_i, x_i).\n    \n    Returns:\n        list: A list containing [MAD, r_v, r_d, risk].\n    \"\"\"\n    # Lists to store values from all villages for village-level correlation\n    all_p_i = []\n    all_x_i = []\n\n    # Lists to store aggregated district-level values\n    district_maup_abs_diffs = []\n    all_P_d = []\n    all_X_d = []\n    \n    num_districts = len(districts_data)\n\n    # Iterate over each district to calculate its aggregated metrics\n    for district_villages in districts_data:\n        # Per-district accumulators\n        sum_I_d = 0.0\n        sum_N_d = 0.0\n        sum_Nx_d = 0.0\n        \n        # List to store village prevalences within the current district\n        village_prevalences_in_district = []\n        \n        # Iterate over villages in the current district\n        for village_data in district_villages:\n            N_i, I_i, x_i = village_data\n            \n            # Village-level prevalence p_i\n            # The problem context implies N_i > 0 for all cases.\n            p_i = I_i / N_i if N_i > 0 else 0.0\n            \n            # Append to global lists for village-level correlation\n            all_p_i.append(p_i)\n            all_x_i.append(x_i)\n            \n            # Append to district's list for unweighted mean calculation\n            village_prevalences_in_district.append(p_i)\n            \n            # Accumulate sums for weighted district-level metrics\n            sum_I_d += I_i\n            sum_N_d += N_i\n            sum_Nx_d += N_i * x_i\n\n        # Calculate district-level metrics after iterating through its villages\n        # Population-weighted prevalence P_d\n        P_d = sum_I_d / sum_N_d if sum_N_d > 0 else 0.0\n        \n        # Unweighted mean prevalence of villages p_bar_d\n        p_bar_d = np.mean(village_prevalences_in_district)\n        \n        # MAUP difference for the district\n        D_d = p_bar_d - P_d\n        district_maup_abs_diffs.append(np.abs(D_d))\n        \n        # Population-weighted covariate X_d\n        X_d = sum_Nx_d / sum_N_d if sum_N_d > 0 else 0.0\n        \n        # Store aggregated district values for district-level correlation\n        all_P_d.append(P_d)\n        all_X_d.append(X_d)\n\n    # Calculate overall summary metrics\n    # Mean Absolute Difference (MAD) for MAUP\n    mad = np.mean(district_maup_abs_diffs)\n    \n    # Village-level Pearson correlation (r_v)\n    # Handle the case of zero variance to avoid NaN\n    if np.var(all_p_i) == 0 or np.var(all_x_i) == 0:\n        r_v = 0.0\n    else:\n        r_v = np.corrcoef(all_p_i, all_x_i)[0, 1]\n\n    # District-level Pearson correlation (r_d)\n    if np.var(all_P_d) == 0 or np.var(all_X_d) == 0:\n        r_d = 0.0\n    else:\n        r_d = np.corrcoef(all_P_d, all_X_d)[0, 1]\n    \n    # Ecological fallacy risk indicator\n    risk = np.sign(r_v) != np.sign(r_d)\n    \n    return [mad, r_v, r_d, bool(risk)]\n\ndef solve():\n    \"\"\"\n    Main function to process all test cases and print the final output.\n    \"\"\"\n    test_cases = [\n        # Test Case 1: general case with varying tested counts\n        [\n            [(80, 40, 2.0), (120, 36, 5.0), (200, 50, 8.0)],\n            [(150, 69, 1.5), (90, 32, 4.0), (60, 12, 9.0)],\n            [(50, 5, 10.0), (150, 42, 3.0), (100, 40, 6.0)]\n        ],\n        # Test Case 2: boundary case with equal tested counts\n        [\n            [(100, 20, 2.0), (100, 30, 4.0), (100, 40, 6.0)],\n            [(100, 10, 1.0), (100, 50, 5.0), (100, 90, 9.0)],\n            [(100, 30, 3.0), (100, 70, 7.0), (100, 50, 11.0)]\n        ],\n        # Test Case 3: constructed to demonstrate potential ecological fallacy\n        [\n            [(100, 60, 1.0), (100, 50, 2.0), (100, 40, 3.0)],\n            [(100, 62, 5.0), (100, 52, 6.0), (100, 42, 7.0)],\n            [(100, 64, 9.0), (100, 54, 10.0), (100, 44, 11.0)]\n        ]\n    ]\n\n    results = []\n    for case in test_cases:\n        result = calculate_results(case)\n        results.append(result)\n\n    # Format the final output string as per the requirements\n    # Each sublist must be formatted without spaces after commas\n    final_output_parts = []\n    for res in results:\n        mad, rv, rd, risk = res\n        # Format the boolean as 'True' or 'False'\n        part = f\"[{mad},{rv},{rd},{str(risk)}]\"\n        final_output_parts.append(part)\n\n    print(f\"[{','.join(final_output_parts)}]\")\n\nsolve()\n```", "id": "4790223"}, {"introduction": "寄生虫病的环境适宜性模型通常会生成一个连续的风险评分表面，但在规划干预措施时，一张清晰的二元风险图（“存在”或“不存在”）往往更具操作性。这里的挑战在于如何选择一个科学合理的阈值来进行这种转换。本练习 [@problem_id:4790219] 将介绍如何使用约登指数（Youden's $J$ statistic）这一客观方法，在模型的敏感性（正确识别风险区）和特异性（正确识别安全区）之间寻求最佳平衡，从而确定最优决策阈值。", "problem": "一个公共卫生团队使用地理信息系统 (GIS) 将一种寄生虫病的连续环境适宜性表面转换为二元存在/缺失风险地图。每个网格单元都有一个预测的适宜性得分和通过实地调查获得的相应地面真实存在标签。设有 $n$ 个单元格，索引为 $i \\in \\{1,\\dots,n\\}$，每个单元格具有适宜性得分 $s_i \\in [0,1]$、真实存在标签 $y_i \\in \\{0,1\\}$ 和单元格面积 $w_i$（单位为平方公里）。给定一个决策阈值 $t$，二元预测为 $\\hat{y}_i(t) = \\mathbf{1}\\{s_i \\ge t\\}$。灵敏度（真阳性率）和特异度（真阴性率）定义为 $ \\text{sensitivity}(t) = \\frac{\\sum_{i=1}^n \\mathbf{1}\\{y_i=1 \\land \\hat{y}_i(t)=1\\}}{\\sum_{i=1}^n \\mathbf{1}\\{y_i=1\\}} $ 和 $ \\text{specificity}(t) = \\frac{\\sum_{i=1}^n \\mathbf{1}\\{y_i=0 \\land \\hat{y}_i(t)=0\\}}{\\sum_{i=1}^n \\mathbf{1}\\{y_i=0\\}} $。约登指数 $J$ 统计量为 $ J(t) = \\text{sensitivity}(t) + \\text{specificity}(t) - 1 $。由阈值 $t$ 标记为有风险的区域面积为 $ A(t) = \\sum_{i=1}^n w_i \\mathbf{1}\\{s_i \\ge t\\} $，以平方公里表示。\n\n您的任务是编写一个程序，为下面的每个测试用例，选择一个阈值 $t^\\star$ 来最大化 $J(t)$。该阈值从一个离散候选集中选取，该候选集构建如下：设排序后的唯一适宜性得分为 $u_1  u_2  \\dots  u_k$。候选阈值 $T$ 集合包含所有 $j \\in \\{1,\\dots,k-1\\}$ 的中点 $\\frac{u_j + u_{j+1}}{2}$，以及两个极端候选值 $u_1 - \\delta$ 和 $u_k + \\delta$，其中如果 $u_k > u_1$ 则 $\\delta = 10^{-9}(u_k - u_1)$，否则 $\\delta = 10^{-9}$。对于每个 $t \\in T$，计算 $J(t)$。选择最大化 $J(t)$ 的 $t^\\star$。如果出现平局，选择具有最大特异度的 $t$；如果仍然存在平局，则选择最大的 $t$。然后报告元组 $[t^\\star, J(t^\\star), \\text{sensitivity}(t^\\star), \\text{specificity}(t^\\star), A(t^\\star)]$。\n\n所有浮点输出必须四舍五入到 $4$ 位小数。面积必须以平方公里表示。\n\n测试套件（每个用例提供 $s_i$、$y_i$ 和 $w_i$ 的列表）：\n\n- 用例 A:\n  - 适宜性得分 $s$: [$0.1$, $0.35$, $0.4$, $0.5$, $0.55$, $0.7$, $0.8$, $0.9$]\n  - 标签 $y$: [$0$, $0$, $1$, $0$, $1$, $0$, $1$, $1$]\n  - 面积 $w$ (平方公里): [$1.0$, $1.0$, $2.0$, $1.0$, $1.5$, $1.0$, $2.0$, $1.0$]\n\n- 用例 B:\n  - 适宜性得分 $s$: [$0.6$, $0.6$, $0.6$, $0.6$]\n  - 标签 $y$: [$0$, $1$, $0$, $1$]\n  - 面积 $w$ (平方公里): [$1.0$, $1.0$, $1.0$, $1.0$]\n\n- 用例 C:\n  - 适宜性得分 $s$: [$0.05$, $0.1$, $0.12$, $0.2$, $0.25$, $0.3$, $0.32$, $0.4$, $0.45$, $0.6$, $0.65$, $0.7$, $0.85$]\n  - 标签 $y$: [$0$, $0$, $0$, $0$, $0$, $0$, $0$, $1$, $0$, $1$, $0$, $0$, $1$]\n  - 面积 $w$ (平方公里): [$5.0$, $10.0$, $8.0$, $9.0$, $6.0$, $7.0$, $12.0$, $3.0$, $4.0$, $2.0$, $9.0$, $15.0$, $1.0$]\n\n您的程序应生成单行输出，包含一个由三个列表组成的列表，每个测试用例一个，其中每个内部列表是排序后的元组 $[t^\\star, J(t^\\star), \\text{sensitivity}(t^\\star), \\text{specificity}(t^\\star), A(t^\\star)]$，所有值都四舍五入到 $4$ 位小数。例如，输出格式必须为 [[$a_{1,1}$,$a_{1,2}$,$a_{1,3}$,$a_{1,4}$,$a_{1,5}$],[$a_{2,1}$,$a_{2,2}$,$a_{2,3}$,$a_{2,4}$,$a_{2,5}$],[$a_{3,1}$,$a_{3,2}$,$a_{3,3}$,$a_{3,4}$,$a_{3,5}$]]，其中每个 $a_{i,j}$ 都是指定精度的舍入浮点数。", "solution": "问题要求我们确定一个最优决策阈值 $t^\\star$，用于将连续的寄生虫病适宜性表面转换为二元风险地图。优化基于最大化约登指数 $J$，这是一种用于二元分类器的标准性能度量。该过程涉及生成一组候选阈值，在每个阈值下评估性能，并根据一组指定的规则选择最佳阈值。\n\n该解决方案通过对每个提供的测试用例遵循结构化、基于原则的方法来实现。\n\n**1. 候选阈值生成**\n\n基于阈值 $t$ 的二元分类在单元格的适宜性得分 $s_i$ 大于或等于 $t$ 时赋予标签 $\\hat{y}_i = 1$，否则赋予 $\\hat{y}_i = 0$。所有单元格的预测集合仅在阈值 $t$ 穿过其中一个得分值 $s_i$ 时才会改变。因此，为了找到最优阈值，测试落在唯一、排序后的适宜性得分之间的值就足够了。\n\n让唯一适宜性得分的集合按升序排序为 $U = \\{u_1, u_2, \\dots, u_k\\}$，其中 $u_1  u_2  \\dots  u_k$。候选阈值集合 $T$ 的构建如下：\n- **中点**：对于每对连续的唯一得分 $(u_j, u_{j+1})$，中点 $\\frac{u_j + u_{j+1}}{2}$ 是一个候选值。开放区间 $(u_j, u_{j+1})$ 内的任何阈值都会产生完全相同的分类，因此中点可作为整个区间的代表。\n- **极端候选值**：为了考虑所有单元格都被分类为阳性（当 $t \\le u_1$ 时）或所有单元格都被分类为阴性（当 $t > u_k$ 时）的情况，还包括两个额外的候选值。它们是 $t_{low} = u_1 - \\delta$ 和 $t_{high} = u_k + \\delta$。小正值 $\\delta$ 定义为，如果 $k > 1$ 则 $\\delta = 10^{-9}(u_k - u_1)$，如果只有一个唯一得分 ($k=1$) 则 $\\delta = 10^{-9}$。这种构建方式确保了对数据集所有可能的唯一二元分类都进行了评估。\n\n**2. 每个阈值下的性能评估**\n\n对于每个候选阈值 $t \\in T$，我们使用从混淆矩阵派生的度量来评估其性能。基本计数包括：\n- 真阳性 ($TP(t)$): $\\sum_{i=1}^n \\mathbf{1}\\{y_i=1 \\land s_i \\ge t\\}$\n- 真阴性 ($TN(t)$): $\\sum_{i=1}^n \\mathbf{1}\\{y_i=0 \\land s_i  t\\}$\n- 假阳性 ($FP(t)$): $\\sum_{i=1}^n \\mathbf{1}\\{y_i=0 \\land s_i \\ge t\\}$\n- 假阴性 ($FN(t)$): $\\sum_{i=1}^n \\mathbf{1}\\{y_i=1 \\land s_i  t\\}$\n\n根据这些计数，我们计算灵敏度和特异度。\n- **灵敏度**，或称真阳性率，衡量被正确识别的实际阳性样本的比例：\n$$ \\text{sensitivity}(t) = \\frac{TP(t)}{TP(t) + FN(t)} = \\frac{\\sum_{i=1}^n \\mathbf{1}\\{y_i=1 \\land s_i \\ge t\\}}{\\sum_{i=1}^n \\mathbf{1}\\{y_i=1\\}} $$\n分母是阳性实例的总数 $P$。\n- **特异度**，或称真阴性率，衡量被正确识别的实际阴性样本的比例：\n$$ \\text{specificity}(t) = \\frac{TN(t)}{TN(t) + FP(t)} = \\frac{\\sum_{i=1}^n \\mathbf{1}\\{y_i=0 \\land s_i  t\\}}{\\sum_{i=1}^n \\mathbf{1}\\{y_i=0\\}} $$\n分母是阴性实例的总数 $N$。\n\n需要最大化的目标函数是**约登指数 J 统计量**：\n$$ J(t) = \\text{sensitivity}(t) + \\text{specificity}(t) - 1 $$\n该统计量衡量诊断标记的有效性，并给予灵敏度和特异度同等的权重。$J=1$ 的值代表一个完美的测试，而 $J=0$ 表示该测试没有区分能力。\n\n此外，对于每个阈值 $t$，计算被标记为有风险的总地理区域面积：\n$$ A(t) = \\sum_{i=1}^n w_i \\mathbf{1}\\{s_i \\ge t\\} $$\n其中 $w_i$ 是单元格 $i$ 的面积。\n\n**3. 最优阈值选择**\n\n在为每个候选阈值 $t \\in T$ 计算元组 $[t, J(t), \\text{sensitivity}(t), \\text{specificity}(t), A(t)]$ 后，我们选择最优阈值 $t^\\star$。选择遵循一个层次化标准以确保解决方案的唯一性：\n1.  主要标准：选择产生最大 $J(t)$ 值的阈值。\n2.  决胜规则 (1)：如果多个阈值产生相同的最大 $J(t)$，则选择具有最高特异度的阈值。这有利于那些能更好地区分真阴性的模型。\n3.  决胜规则 (2)：如果仍然存在平局，则选择最大的阈值 $t$。\n\n这种多级优化是通过对计算出的度量元组列表进行排序来实现的。主要排序键是 $J(t)$（降序），次要排序键是 $\\text{specificity}(t)$（降序），第三排序键是 $t$（降序）。排序后列表中的第一个元素即为最优结果。\n\n此过程应用于每个测试用例。得到的 $[t^\\star, J(t^\\star), \\text{sensitivity}(t^\\star), \\text{specificity}(t^\\star), A(t^\\star)]$ 值按要求四舍五入到四位小数。实现采用了 `numpy` 以进行高效的基于数组的计算。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of finding the optimal decision threshold for a series of test cases.\n    \"\"\"\n    test_cases = [\n        {\n            \"s\": [0.1, 0.35, 0.4, 0.5, 0.55, 0.7, 0.8, 0.9],\n            \"y\": [0, 0, 1, 0, 1, 0, 1, 1],\n            \"w\": [1.0, 1.0, 2.0, 1.0, 1.5, 1.0, 2.0, 1.0]\n        },\n        {\n            \"s\": [0.6, 0.6, 0.6, 0.6],\n            \"y\": [0, 1, 0, 1],\n            \"w\": [1.0, 1.0, 1.0, 1.0]\n        },\n        {\n            \"s\": [0.05, 0.1, 0.12, 0.2, 0.25, 0.3, 0.32, 0.4, 0.45, 0.6, 0.65, 0.7, 0.85],\n            \"y\": [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1],\n            \"w\": [5.0, 10.0, 8.0, 9.0, 6.0, 7.0, 12.0, 3.0, 4.0, 2.0, 9.0, 15.0, 1.0]\n        }\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        s = np.array(case[\"s\"])\n        y = np.array(case[\"y\"])\n        w = np.array(case[\"w\"])\n\n        # 1. Generate candidate thresholds\n        unique_scores = np.unique(s)\n        if len(unique_scores) > 1:\n            delta = 1e-9 * (unique_scores[-1] - unique_scores[0])\n            midpoints = (unique_scores[:-1] + unique_scores[1:]) / 2.0\n            candidate_thresholds = np.concatenate(\n                ([unique_scores[0] - delta], midpoints, [unique_scores[-1] + delta])\n            )\n        else: # Only one unique score\n            delta = 1e-9\n            candidate_thresholds = np.array([unique_scores[0] - delta, unique_scores[0] + delta])\n\n        # 2. Evaluate metrics for each candidate\n        total_positives = np.sum(y)\n        total_negatives = len(y) - total_positives\n        \n        metrics_per_threshold = []\n        for t in candidate_thresholds:\n            y_hat = (s >= t).astype(int)\n            \n            if total_positives > 0:\n                tp = np.sum((y == 1)  (y_hat == 1))\n                sensitivity = tp / total_positives\n            else:\n                sensitivity = 1.0  # Convention: perfect sensitivity if no positives exist\n            \n            if total_negatives > 0:\n                tn = np.sum((y == 0)  (y_hat == 0))\n                specificity = tn / total_negatives\n            else:\n                specificity = 1.0 # Convention: perfect specificity if no negatives exist\n\n            j_statistic = sensitivity + specificity - 1\n            area_at_risk = np.sum(w[s >= t])\n            \n            metrics_per_threshold.append([t, j_statistic, sensitivity, specificity, area_at_risk])\n\n        # 3. Find optimal threshold based on tie-breaking rules\n        # Sort by J (desc), then specificity (desc), then t (desc)\n        metrics_per_threshold.sort(key=lambda m: (-m[1], -m[3], -m[0]))\n        \n        best_result = metrics_per_threshold[0]\n        \n        # 4. Round and store the result\n        rounded_result = [np.round(val, 4) for val in best_result]\n        all_results.append(rounded_result)\n\n    # 5. Format and print the final output string.\n    # The str() representation adds spaces which need to be removed as per the problem's example format.\n    print(str(all_results).replace(\" \", \"\"))\n\nsolve()\n```", "id": "4790219"}]}