{"hands_on_practices": [{"introduction": "在美国法律框架下，HIPAA“安全港”方法为健康数据的去标识化提供了一套明确的规则。然而，应用这些规则需要精确和谨慎，尤其是在处理地理数据等准标识符时。本练习旨在通过一个实际案例，帮助您掌握如何根据人口阈值等具体标准来判断数据集是否符合“安全港”的要求 [@problem_id:4504208]。", "problem": "一个受保护实体计划将一个数据集对外共享，用于医院使用情况的研究。该数据集包含每次就诊的以下字段：入院年份（例如，$2021$–$2023$）、出院年份、出生年份（例如，$1955$–$2002$）、性别、主要诊断代码（国际疾病分类第十次修订版 (ICD-10)）以及居住地的$3$位邮政编码（ZIP3）。所有日期都已泛化为仅年份（无月份或日期）。不存在其他直接标识符（例如，姓名、电话号码、社会安全号码）。该数据集包括来自多个ZIP3地区的记录，包括`021`、`036`和`852`。根据美国人口普查局当前公开可用的数据，由所有共享相同前$3$位数字的邮政编码组成的地理单元的人口为：`021` $\\mapsto 1,550,000$、`036` $\\mapsto 17,500$和`852` $\\mapsto 58,000$。数据集中所有个体在就诊时的年龄均$\\leq 70$岁；不存在年龄$> 89$岁的个体。\n\n根据《健康保险流通与责任法案》(HIPAA) 隐私规则的去标识化路径，确定所描述的数据集以其当前构成形式，是否满足“安全港”方法，还是需要“专家裁定”方法才能作为去标识化数据发布。选择最佳答案。\n\nA. 数据集满足安全港要求，因为日期仅限于年份，且无论人口阈值如何，始终允许使用ZIP3代码。\n\nB. 数据集需要专家裁定，因为保留人口$\\leq 20{,}000$的ZIP3 $036$违反了安全港规定；为了符合安全港的要求，此类ZIP3必须更改为$000$或移除。\n\nC. 数据集满足安全港要求，前提是数据使用协议禁止重新识别；即使ZIP3人口$\\leq 20{,}000$，合同控制也足够。\n\nD. 数据集满足安全港要求，因为人口阈值仅适用于完整的5位邮政编码；无论人口多少，都允许保留ZIP3代码。\n\nE. 数据集要求完全删除所有日期；安全港规定不允许仅保留年份。", "solution": "该问题要求根据《健康保险流通与责任法案》(HIPAA) 隐私规则的“安全港”去标识化方法的标准，对给定数据集进行评估。此分析将确定所描述的数据集是否满足这些标准，或者是否需要采用替代的“专家裁定”方法才能作为去标识化数据发布。\n\n安全港方法，编纂于联邦法规第45篇第164.514(b)(2)(i)节，强制要求移除个人或其亲属、雇主或家庭成员的$18$种特定类型的标识符。只有当所有$18$种标识符都被移除时，一个数据集才被认为在安全港规则下是去标识化的。受保护实体还必须没有实际知晓剩余信息可以单独或与其他信息结合使用，以识别作为信息主体的个人。\n\n让我们根据相关的安全港标准来分析所提供的数据集。该数据集包含：入院年份、出院年份、出生年份、性别、主要诊断代码 (ICD-10) 以及$3$位邮政编码 (ZIP3)。\n\n1.  **直接标识符：** 问题陈述明确指出，“不存在其他直接标识符（例如，姓名、电话号码、社会安全号码）。” 这处理了$18$个标识符中的大部分，例如姓名（第1项）、电话号码（第4项）、社会安全号码（第7项）等。\n\n2.  **日期：** 安全港列表的第3项要求移除“与个人直接相关的日期的所有元素（年份除外）”。数据集遵守此规则，因为所有日期（入院、出院、出生）都已泛化为仅年份。\n\n3.  **超过89岁的年龄：** 第3项还要求“所有超过89岁的年龄以及指示该年龄的日期的所有元素（包括年份）”都必须被移除或汇总到“90岁或以上”的单一类别中。问题陈述中说，“数据集中所有个体在就诊时的年龄均$\\leq 70$岁；不存在年龄$> 89$岁的个体。” 这直接证实了对该要求的遵守。就诊年龄可以计算为（入院年份 - 出生年份），并且由于所有年龄都$\\leq 70$岁，因此不可能有$> 89$岁的个体。\n\n4.  **地理分区：** 这是本问题的最关键要素。安全港列表的第2项涉及“所有小于州的地理分区”。这包括邮政编码。然而，对于邮政编码的前三位数字（ZIP3）有一个具体规定：\n    - 只有当根据美国人口普查局最新公开的十年一次的人口普查数据，由所有具有相同前三位数字的邮政编码组合而成的地理单元人口超过$20{,}000$人时，才可以保留邮政编码的前三位数字。\n    - 如果此ZIP3地理单元的人口为$20{,}000$或更少，则前三位数字必须更改为'$000$'。\n\n    我们现在必须将此规则应用于数据集中存在的ZIP3代码：\n    - **ZIP3 `021`**：给定人口为$1{,}550{,}000$。由于$1{,}550{,}000 > 20{,}000$，保留`021`符合安全港规定。\n    - **ZIP3 `036`**：给定人口为$17{,}500$。由于$17{,}500 \\leq 20{,}000$，保留`036`**违反**了安全港方法。为了遵守规定，所有`036`的实例都必须重新编码为`000`。\n    - **ZIP3 `852`**：给定人口为$58{,}000$。由于$58{,}000 > 20{,}000$，保留`852`符合安全港规定。\n\n    因为该数据集“以其当前构成形式”包含了对应人口为$17{,}500$的ZIP3代码`036`，所以它未能满足安全港方法的严格要求。为了一个受保护实体能够以其当前形式将此数据集作为去标识化数据发布，它将不得不使用专家裁定方法（联邦法规第45篇第164.514(b)(1)节），这涉及由一名具备将信息变为不可单独识别的公认统计学和科学原理与方法的适当知识和经验的人士进行正式裁定，确定重新识别的风险非常小。\n\n基于此分析，我们可以评估各个选项。\n\n**A. 数据集满足安全港要求，因为日期仅限于年份，且无论人口阈值如何，始终允许使用ZIP3代码。**\n该陈述是**不正确**的。“无论人口阈值如何，始终允许使用ZIP3代码”的说法在事实上是错误的。HIPAA隐私规则在联邦法规第45篇第164.514(b)(2)(i)(B)节中规定了保留邮政编码前三位数字的$20{,}000$人口阈值。\n\n**B. 数据集需要专家裁定，因为保留人口$\\leq 20{,}000$的ZIP3 $036$违反了安全港规定；为了符合安全港的要求，此类ZIP3必须更改为$000$或移除。**\n该陈述是**正确**的。它准确地指出了数据集中的具体违规之处：包含了ZIP3 `036`，其人口（$17{,}500$）不大于$20{,}000$。它正确地得出结论，因为当前形式的数据集不符合安全港规定，所以需要专家裁定方法。它还正确地描述了使数据集符合安全港地理数据规则所必需的修改（将`036`更改为`000`或移除记录）。\n\n**C. 数据集满足安全港要求，前提是数据使用协议禁止重新识别；即使ZIP3人口$\\leq 20{,}000$，合同控制也足够。**\n该陈述是**不正确**的。数据使用协议（DUA）是共享“有限数据集”（LDS）的要求，而不是共享通过安全港方法去标识化的数据集的要求。DUA不能替代或凌驾于安全港方法的明确技术要求之上。合同协议不能使不合规的数据集符合安全港规定。\n\n**D. 数据集满足安全港要求，因为人口阈值仅适用于完整的5位邮政编码；无论人口多少，都允许保留ZIP3代码。**\n该陈述是**不正确**的。它曲解了HIPAA规则。人口阈值规则明确适用于邮政编码的前三位数字（ZIP3）。在安全港规定下，完整的5位邮政编码必须始终被移除。\n\n**E. 数据集要求完全删除所有日期；安全港规定不允许仅保留年份。**\n该陈述是**不正确**的。它错误地陈述了关于日期的规则。安全港条款明确允许保留日期的年份部分（“日期的所有元素（年份除外）...”）。", "answer": "$$\\boxed{B}$$", "id": "4504208"}, {"introduction": "与HIPAA明确的规则不同，欧盟的GDPR采用了一种基于原则和风险的匿名化标准。本练习将引导您辨析技术模型（如 $k$-匿名性）的充分性与法律标准的充分性之间的关键区别。通过分析，您将理解为何仅仅满足一个技术指标，并不足以在GDPR框架下自动将数据视为“匿名”，尤其是在存在外部关联数据风险时 [@problem_id:4504281]。", "problem": "欧盟 (EU) 的一个卫生系统计划共享一个用于二次研究的数据集。该数据集包含准标识符和临床属性。准标识符包括出生年份、性别和邮政编码的前 $3$ 位。直接标识符（如姓名、国民身份证号）已被移除。数据处理者应用了一种数据转换技术，对准标识符实现了 $k$-匿名化，其中 $k=15$，这意味着数据集中每条记录的准标识符模式都至少与 $15$ 个个体共享。该卫生系统声称，这证明了根据《通用数据保护条例》(GDPR)，这些数据在法律上是“匿名的”，因此 GDPR 不再适用。\n\n假设以下内容为基本前提：\n- 根据《通用数据保护条例》(GDPR)，“个人数据”是与已识别或可识别的自然人相关的任何信息，其中可识别性是根据任何一方“合理可能使用的手段”来评估的，同时考虑到成本、时间和可用技术（引言 $26$）。\n- 根据 GDPR，“匿名化”是一种状态，在该状态下，任何一方都无法使用合理可能使用的手段来识别个人；“假名化”（第 $4(5)$ 条）是一种方法，通过该方法，标识符被替换或转换，使得在不使用额外信息的情况下，数据无法归属于特定个人，但这些数据仍然是“个人数据”。\n- $k$-匿名化是一个模型，确保每条记录在所选的准标识符方面至少与 $k-1$ 条其他记录无法区分；它并未对所有攻击向量（例如，与外部数据进行链接、属性泄露）进行建模，其保障程度取决于准标识符的选择和数据环境。\n\n在公共环境中，存在一个可广泛访问的选民名册，其中包含完整的出生日期和完整的邮政编码，并且地方新闻来源曾报道过某些小型社区中罕见疾病的聚集性病例。该卫生系统打算在没有数据使用协议限制重识别尝试的情况下，与外部学者共享这个 $k$-匿名化数据集。\n\n对于此数据集，哪个选项最能体现满足 $k$-匿名化（模型充分性）与达到 GDPR 匿名化标准（法律充分性）之间的比较？\n\nA. 因为 $k=15$ 的 $k$-匿名化确保了在所选准标识符上的不可区分性，所以根据 GDPR，该数据集在法律上是“匿名的”；不需要进一步的上下文或风险分析。\n\nB. $k$-匿名化是准标识符不可区分性方面模型充分性的证据，但 GDPR 匿名化标准是一个基于上下文和风险的法律充分性标准，侧重于“通过任何合理可能使用的手段”进行识别的可能性。鉴于存在可访问的外部数据集和已知的罕见病例集群，仅仅实现 $k=15$ 的 $k$-匿名化本身并不能确立法律上的匿名化。\n\nC. GDPR 指定了一个最小 $k$ 值阈值（例如 $k\\geq 10$）作为匿名化的安全港；因此，一个 $k=15$ 的数据集在法律上是匿名的。\n\nD. 将 $k$-匿名化与假名化相结合，可将数据转换为 GDPR 下法律意义上的匿名数据，因为两种技术结合必然满足 GDPR 标准。\n\nE. 一旦数据集对准标识符实现了 $k$-匿名化，根据 GDPR，它必须在法律上被视为假名化的个人数据，因为 GDPR 将 $k$-匿名化定义为假名化。", "solution": "首先将对问题陈述的科学合理性、逻辑一致性和客观性进行验证。\n\n**步骤 1：提取给定信息**\n\n问题提供了以下数据、定义和条件：\n- **场景**：欧盟 (EU) 的一个卫生系统计划共享一个用于二次研究的数据集。\n- **数据内容**：该数据集包含准标识符和临床属性。直接标识符已被移除。\n- **准标识符 (QIs)**：出生年份、性别和邮政编码的前 $3$ 位。\n- **数据转换**：应用了一种转换技术，实现了 $k=15$ 的 $k$-匿名化。这意味着数据集中每条记录的准标识符模式都至少与 $15$ 个个体共享。\n- **主张**：该卫生系统声称，这使得数据根据《通用数据保护条例》(GDPR) 在法律上是“匿名的”，从而使 GDPR 不再适用。\n- **基本前提 1 (GDPR 关于个人数据的规定)**：“个人数据”是与已识别或可识别的自然人相关的任何信息。可识别性是根据任何一方“合理可能使用的手段”来评估的，同时考虑到成本、时间和技术（引言 $26$）。\n- **基本前提 2 (GDPR 关于匿名化与假名化的规定)**：“匿名化”是一种状态，在该状态下，任何一方都无法使用合理可能使用的手段来识别个人。“假名化”（第 $4(5)$ 条）是一个过程，通过该过程，数据在不使用额外信息的情况下无法归属于某个人，但这些数据仍然是“个人数据”。\n- **基本前提 3 ($k$-匿名化)**：$k$-匿名化确保一条记录在所选的准标识符方面至少与 $k-1$ 条其他记录无法区分。它并未对所有攻击向量（例如，与外部数据进行链接、属性泄露）进行建模，其保障强度取决于准标识符的选择和环境。\n- **外部环境**：\n    - 存在一个可公开且广泛访问的选民名册，其中包含完整的出生日期和完整的邮政编码。\n    - 地方新闻曾报道过某些小型社区中罕见疾病的聚集性病例。\n    - 该数据集将在没有限制重识别尝试的数据使用协议的情况下与外部学者共享。\n\n**步骤 2：使用提取的给定信息进行验证**\n\n根据验证标准对问题陈述进行评估。\n\n- **科学依据**：该问题植根于数据隐私和医疗法律等既有领域。$k$-匿名化、假名化以及 GDPR 下的法律标准等概念描述准确，是这些领域当前讨论的核心。该场景是数据共享挑战中的一个典型例子。\n- **问题适定性**：该问题是适定的。它提出了一个具体场景，提供了相关的法律和技术定义，并要求对技术控制（$k$-匿名化）和法律标准（GDPR 匿名化）进行比较分析。所提供的上下文足以进行逻辑推导。\n- **客观性**：该问题陈述客观，提出了一个卫生系统的主张，并提供了评估该主张所需的事实和定义。语言精确，没有主观偏见。\n\n该问题没有表现出任何列出的缺陷：\n1.  **科学或事实不健全**：前提是健全的。GDPR 原则和 $k$-匿名化的定义是正确的。\n2.  **无法形式化或不相关**：该问题高度相关，并可以使用数据隐私风险评估的原则进行形式化。\n3.  **设置不完整或矛盾**：设置详细且一致，提供了进行分析所需的所有要素（数据集的属性、应用的技术、法律框架和外部环境）。\n4.  **不切实际或不可行**：该场景非常现实。公共选民名册的存在以及为研究目的共享健康数据的做法都很常见。所选的准标识符是典型的。\n5.  **问题不适定或结构不良**：问题清晰，可以根据所提供的信息得出确定的结论。\n6.  **伪深刻、琐碎或同义反复**：该问题探讨了实施特定隐私增强技术与满足全面、基于风险的法律标准之间微妙且不平凡的区别。\n7.  **超出科学可验证性范围**：其推理基于在技术模型的已知属性背景下解释既定的法律定义，这是一个可验证的分析过程。\n\n**步骤 3：结论和行动**\n\n问题陈述是**有效的**。现在将推导解决方案。\n\n**解决方案的推导**\n\n问题的核心是评估卫生系统的主张，即实现 $k=15$ 的 $k$-匿名化是否足以使数据集在 GDPR 下变为“匿名的”。\n\n1.  **分析 GDPR 标准**：GDPR 为匿名化设定了很高的标准。根据引言 $26$，只要一个人是“可识别的”，数据就是个人数据，而评估可识别性时必须考虑到任何一方“合理可能使用的所有手段”。这是一个基于上下文和风险的测试，而不是一个固定的技术阈值。它明确要求考虑诸如“识别所需的成本和时间，同时考虑到处理时可用的技术和技术发展”等因素。\n\n2.  **分析 $k$-匿名化的实施**：问题指出，对准标识符（出生年份、性别和邮政编码的前 $3$ 位）实现了 $k$-匿名化。如前所述，该模型的保证是，*在这些特定的准标识符方面*，每条记录至少与其他 $14$ 条记录无法区分。然而，问题也指出，该模型“并未对所有攻击向量（例如，与外部数据进行链接、属性泄露）进行建模”。\n\n3.  **在上下文中评估风险**：GDPR 标准要求我们考虑所提供的上下文。\n    - **链接攻击**：“可广泛访问的选民名册”包含“完整的出生日期和完整的邮政编码”。攻击者可以利用这个外部数据集。攻击者可以从 $k$-匿名化的健康数据集中获取一条记录（例如，年份=1970，性别=女性，邮政编码以 123 开头），并将其与选民名册进行链接。选民名册拥有更精确的信息（完整的出生日期、完整的邮政编码），有可能将匹配的个体从最初的 $15$ 人组缩小到更小的数量，甚至可能缩小到单个个体。这些数据的可用性以及缺乏限制性数据使用协议，使得这种链接攻击成为一种“合理可能使用的手段”。因此，重识别的风险仍然很大。\n    - **属性泄露**：“罕见疾病集群”的存在带来了另一个漏洞。如果一个等价类（共享相同准标识符）中的所有 $15$ 个个体恰好都患有同一种罕见疾病，并且准标识符指向一个已知存在该疾病集群的小社区，那么关于这 $15$ 个人的信息就已被泄露。他们现在可以被识别为患有特定罕见病的群体成员，这构成了严重的隐私侵犯。这是 $k$-匿名化未能防范同质性攻击的一个失败案例。\n    - **风险结论**：鉴于链接攻击的高可能性和属性泄露的潜力，并不能“合理地确定”个人不再可被识别。尽管数据经过了 $k$-匿名化处理，但根据 GDPR，它几乎肯定仍然是“个人数据”。\n\n4.  **区分模型充分性与法律充分性**：在本案例中，$k$-匿名化展示了“模型充分性”——它满足了所选隐私模型对所选准标识符的数学要求。然而，它未能达到 GDPR 匿名化标准下的“法律充分性”，因为该标准更广泛，要求进行全面的风险评估，考虑数据环境和所有可能的攻击向量，而单独的 $k$-匿名化模型并不能做到这一点。这些数据很可能被归类为“假名化的”，这意味着它们仍然是个人数据，并受 GDPR 的保护。\n\n**逐项分析选项**\n\n-   **A. 因为 $k=15$ 的 $k$-匿名化确保了在所选准标识符上的不可区分性，所以根据 GDPR，该数据集在法律上是“匿名的”；不需要进一步的上下文或风险分析。**\n    这是**不正确的**。GDPR 标准（引言 $26$）明确要求进行基于上下文的风险分析，考虑所有“合理可能使用的手段”。问题上下文中外部选民名册和疾病集群信息的存在本身就要求进行此类分析。该选项直接与所提供的法律标准相矛盾。\n\n-   **B. $k$-匿名化是准标识符不可区分性方面模型充分性的证据，但 GDPR 匿名化标准是一个基于上下文和风险的法律充分性标准，侧重于“通过任何合理可能使用的手段”进行识别的可能性。鉴于存在可访问的外部数据集和已知的罕见病例集群，仅仅实现 $k=15$ 的 $k$-匿名化本身并不能确立法律上的匿名化。**\n    这是**正确的**。该选项准确地区分了 $k$-匿名化模型的技术保障（“模型充分性”）与 GDPR 标准的全面、基于风险的性质（“法律充分性”）。它正确地指出，问题中提供的上下文因素（外部数据、罕见集群）至关重要，并使得 $k$-匿名化数据集无法被视为法律上的匿名数据。\n\n-   **C. GDPR 指定了一个最小 $k$ 值阈值（例如 $k\\geq 10$）作为匿名化的安全港；因此，一个 $k=15$ 的数据集在法律上是匿名的。**\n    这是**不正确的**。GDPR 是基于原则的，并没有规定具体的技术方法或数值阈值（如最小 $k$ 值）作为匿名化的“安全港”。评估始终是基于风险和上下文的。该陈述提出了一个关于 GDPR 的错误事实。\n\n-   **D. 将 $k$-匿名化与假名化相结合，可将数据转换为 GDPR 下法律意义上的匿名数据，因为两种技术结合必然满足 GDPR 标准。**\n    这是**不正确的**。首先，$k$-匿名化是一种特定的技术，其产生的数据通常被认为是假名化的，而不是一个可以与之结合的独立过程。其次，更重要的是，GDPR 明确指出，假名化数据*仍然是个人数据*。结合两种假名化技术并不会自动将其结果提升到匿名化的水平。断言两种技术“必然满足标准”是一种逻辑谬误。\n\n-   **E. 一旦数据集对准标识符实现了 $k$-匿名化，根据 GDPR，它必须在法律上被视为假名化的个人数据，因为 GDPR 将 $k$-匿名化定义为假名化。**\n    这是**不正确的**。其推理存在缺陷。GDPR 完全没有定义或提及 $k$-匿名化。虽然在此背景下，$k$-匿名化数据集很可能在法律上被归类为假名化数据，但这是通过风险分析得出的结论，而不是因为法规中有直接定义。其法律地位取决于重识别的残余风险，而“它必须在法律上被视为假名化的”这一断言是一个强硬的说法，在所有可以想象的情况下（例如，如果重识别仍然微不足道，或者如果可以证明重识别不可能）都可能不成立。核心错误在于其错误前提，即 GDPR 定义了 $k$-匿名化。", "answer": "$$\\boxed{B}$$", "id": "4504281"}, {"introduction": "本练习进一步深化了对GDPR风险评估方法的理解，强调了匿名化的相对性和情境性。您将分析一个数据集对于不同接收者——普通公众和拥有强大外部数据资源的商业控制者——可能具有不同的法律地位。这个案例突显了在法律分析中，评估“合理可能被使用的手段”以确定再识别风险的核心重要性 [@problem_id:4504253]。", "problem": "一所大学医学中心创建了关于患者就诊记录的数据集 $D$，用于二次研究。数据集 $D$ 包含准标识符（例如，出生年份、性别、3位数邮政编码以及入院年月）和诊断代码。直接标识符已被移除，患者标识符被替换为加密哈希值。医院保留一个独立的密钥，可以将哈希值映射回身份，但该密钥不会与数据接收者共享。该医院正在考虑对 $D$ 进行两种披露：向公众开放发布，以及向商业控制者 $C$ 进行受限发布。控制者 $C$ 订阅了一个大型商业数据经纪人的存储库 $B$，该存储库包含个人层面的消费者属性，包括5位数邮政编码、精确出生日期、设备衍生的移动聚合数据以及可用于链接的购买历史。\n\n假设以下基本依据来自《通用数据保护条例》（GDPR）：个人数据是与已识别或可识别的自然人相关的任何信息；可识别性通过考虑控制者或其他人为识别个人而合理可能使用的所有方法来评估，同时考虑成本 $C$、时间 $T$ 和技术水平 $S$ 等客观因素；匿名化要求识别的可能性不合理；假名化（第 $4(5)$ 条）降低了可链接性，但其结果仍为个人数据；当组织和法律控制措施能可信且有效地减少合理可能使用的识别方法时，可以将其纳入考量，但重新识别的技术可行性仍然是核心考虑因素。\n\n问题：与向公众发布相比，控制者 $C$ 可访问 $B$ 这一情况，如何最好地描述其对判断 $D$ 在预期披露中是否为匿名数据的影响？\n\nA. 根据 GDPR 序言 $26$ 的情境测试，匿名化必须根据控制者或其他人合理可能使用的所有方法进行评估。由于控制者 $C$ 可以访问 $B$ 并具有更强的链接能力，因此对于向公众发布而言，$D$ 可能是匿名的，但如果披露给 $C$，则仍构成个人数据。可以考虑能够可靠地限制成本 $C$、时间 $T$ 和技术水平 $S$ 的技术和组织措施，但仅靠假名化并不能使 $D$ 匿名。\n\nB. 匿名化是 $D$ 的一种内在的、绝对的属性：如果 $D$ 缺少直接标识符，并且对公众来说是匿名的，那么它对任何接收者都是匿名的，无论他们拥有什么额外的数据集或能力。\n\nC. 禁止对 $C$ 进行重新识别的合同条款本身就足以使 $D$ 匿名，因为它消除了“合理可能使用的手段”，即使考虑到 $B$ 的存在，重新识别在技术上是可行的。\n\nD. 如果 $D$ 通过移除 $18$ 种标识符或通过专家认定，满足了美国《健康保险流通与责任法案》（HIPAA）的安全港规则，那么根据 GDPR，对于包括可访问 $B$ 的 $C$ 在内的所有接收者，$D$ 也是匿名的。", "solution": "### 步骤 1：提取已知信息\n\n- 数据集：$D$，由一所大学医学中心为二次研究创建。\n- $D$ 的内容：准标识符，包括出生年份、性别、3位数邮政编码、入院年月；还包含诊断代码。\n- 对 $D$ 的数据处理：直接标识符已被移除；患者标识符被替换为加密哈希值。\n- 密钥管理：医院保留一个密钥以将哈希值映射回身份，但此密钥不与数据接收者共享。\n- 预期的披露：\n    1. 向公众开放发布。\n    2. 向商业控制者 $C$ 进行受限发布。\n- 控制者 $C$ 的能力：控制者 $C$ 订阅了一个大型商业数据经纪人的存储库 $B$。\n- $B$ 的内容：个人层面的消费者属性，包括5位数邮政编码、精确出生日期、设备衍生的移动聚合数据和购买历史，这些都可用于链接。\n- 假设的法律依据（来自 GDPR）：\n    - **个人数据**：与已识别或可识别的自然人相关的任何信息。\n    - **可识别性**：通过考虑控制者或其他人为识别个人而“合理可能使用的所有方法”来评估。\n    - **“合理可能”测试**：此评估必须考虑客观因素，如识别的成本（$C$）、时间（$T$）和可用技术/技术水平（$S$）。\n    - **匿名化**：这要求识别的可能性不合理。\n    - **假名化**：根据第 $4(5)$ 条的定义，此过程降低了可链接性，但产生的数据仍被视为个人数据。\n    - **控制措施**：如果组织和法律控制措施能可信且有效地减少合理可能用于识别的方法，则可以考虑这些措施，但重新识别的技术可行性仍是一个核心因素。\n\n### 步骤 2：使用提取的已知信息进行验证\n\n问题陈述是有效的。\n1.  **科学依据充分：** 该问题基于数据隐私、计算机科学（如链接攻击、通过哈希进行假名化）和医疗法律的既定原则。相关概念和术语（准标识符、GDPR、序言 $26$、HIPAA）在该领域的情境中被准确和恰当地使用。\n2.  **问题定义明确：** 该问题要求基于一个明确定义的场景和一系列法律及技术原则，给出一个具体的定性描述。其结构使得可以根据所提供的前提逻辑地推导出答案。\n3.  **客观性：** 问题以精确、客观的语言陈述，没有主观或基于意见的主张。\n4.  **完整性和一致性：** 问题提供了所有必要的信息，以便对两种披露场景下数据集 $D$ 的相对状态进行推理。关于 GDPR 的前提与该法规的实际原则一致。医院（持有密钥）和接收者之间的区别至关重要且定义明确。\n5.  **现实性：** 该场景非常现实。“去标识化”的健康数据集与商业数据经纪人存储库相结合所带来的重新识别风险，是数据隐私研究和实践中一个有据可查的重要问题。\n\n该问题是一个在应用法律和以数据为中心的伦理学领域中结构良好的问题。可以使用所提供的原则对其进行形式化分析。\n\n### 步骤 3：推导与选项分析\n\n**基于原则的推导**\n\n问题的核心在于 GDPR 对“个人数据”的定义以及成功“匿名化”的标准。如前提中所述并源自 GDPR 序言 $26$ 的操作性原则是，匿名化不是数据集的绝对、内在属性。相反，它是基于重新识别风险的相对（或情境性）评估。\n\n评估取决于数据接收者“合理可能使用的所有方法”。这明确地将接收者的身份和能力作为分析的核心部分。让我们分析这两种披露场景：\n\n1.  **场景 1：向公众发布**\n    普通公众会拥有某些重新识别的方法，例如将数据集 $D$ 与公开可用的记录进行链接。成功匹配的可能性取决于 $D$ 中准标识符组合的唯一性。“合理可能”测试考虑了所需的成本（$C$）、时间（$T$）和技术复杂性（$S$）。对于普通公众而言，这些因素可能足够高，以至于可以得出重新识别并非“合理可能”的结论。在这种情况下，数据集 $D$ 可能被视为匿名化。\n\n2.  **场景 2：向控制者 $C$ 发布**\n    控制者 $C$ 处于不同的位置。它拥有数据集 $B$，这是一个强大的辅助信息源。$B$ 中的属性（例如，5位数邮政编码、精确出生日期）是 $D$ 中准标识符（例如，3位数邮政编码、出生年份）的超集或更细粒度的版本。$D$ 和 $B$ 的组合通过链接攻击极大地增加了重新识别的概率。对于控制者 $C$ 来说，执行这种链接的成本（$C$）和时间（$T$）非常低，并且他们拥有实现这一目标的最新技术（$S$）。\n\n**推导结论**\n控制者 $C$ 合理可能使用的方法远超于公众可用的方法。因此，重新识别的风险也大大增加。因此，根据 GDPR 框架，将数据集 $D$ 在披露给控制者 $C$ 时归类为**个人数据**是完全一致的，即使它在向公众发布时可能被归类为**匿名化**。数据的状态取决于接收者。\n\n此外，$D$ 的初始处理（标识符的哈希化）构成了假名化，因为医院保留了密钥。所提供的前提明确指出，假名化数据仍然是个人数据。虽然接收者没有得到密钥，但通过准标识符进行重新识别的潜力仍然存在，必须进行评估。\n\n**选项评估**\n\n**A. 根据 GDPR 序言 $26$ 的情境测试，匿名化必须根据控制者或其他人合理可能使用的所有方法进行评估。由于控制者 $C$ 可以访问 $B$ 并具有更强的链接能力，因此对于向公众发布而言，$D$ 可能是匿名的，但如果披露给 $C$，则仍构成个人数据。可以考虑能够可靠地限制成本 $C$、时间 $T$ 和技术水平 $S$ 的技术和组织措施，但仅靠假名化并不能使 $D$ 匿名。**\n\n- **分析：** 此陈述与推导完全一致。它正确地指出了来自序言 $26$ 的 GDPR 情境测试。它正确地得出结论，由于 $C$ 通过数据集 $B$ 拥有增强的能力，数据的状态可以相对于接收者而变化（对 $C$ 是个人数据，对公众可能是匿名的）。它正确地指出假名化不足以实现匿名化。它还正确地将技术和组织措施的作用作为一个需要考虑的缓解因素，但不是绝对的解决方案。其法律和技术推理是完全合理和完整的。\n- **结论：** 正确。\n\n**B. 匿名化是 $D$ 的一种内在的、绝对的属性：如果 $D$ 缺少直接标识符，并且对公众来说是匿名的，那么它对任何接收者都是匿名的，无论他们拥有什么额外的数据集或能力。**\n\n- **分析：** 这个陈述描述了一种绝对的匿名化理论。这与问题前提中概述的 GDPR 的相对和基于风险的方法直接矛盾，后者要求考虑“控制者或其他人”可用的方法。它错误地假设，如果数据对“最弱”的接收者（公众）是安全的，那么它对所有接收者都是安全的。\n- **结论：** 错误。\n\n**C. 禁止对 $C$ 进行重新识别的合同条款本身就足以使 $D$ 匿名，因为它消除了“合理可能使用的手段”，即使考虑到 $B$ 的存在，重新识别在技术上是可行的。**\n\n- **分析：** 这个选项夸大了法律控制措施的效果。问题的前提指出，虽然这些控制措施“可以被考虑”，但“重新识别的技术可行性仍然是核心考虑因素”。欧洲数据保护机构一致认为，如果重新识别对接收者来说在技术上是直接可行的，那么仅仅一份禁止其实施的合同义务不足以使数据匿名。违约的风险和重新识别的残余能力意味着数据主体没有得到匿名化标准所要求的保护。\n- **结论：** 错误。\n\n**D. 如果 $D$ 通过移除 $18$ 种标识符或通过专家认定，满足了美国《健康保险流通与责任法案》（HIPAA）的安全港规则，那么根据 GDPR，对于包括可访问 $B$ 的 $C$ 在内的所有接收者，$D$ 也是匿名的。**\n\n- **分析：** 这个陈述错误地假设了不同司法管辖区和法规之间的法律等同性。美国 HIPAA 安全港规则提供了一个包含 $18$ 种要移除的标识符的规定性清单。而 GDPR 提供了一个基于原则的情境测试，侧重于重新识别的实际风险。一个数据集可以满足 HIPAA 的安全港规则，但仍包含一组丰富的准标识符，允许重新识别，特别是对于像控制者 $C$ 这样能够访问 $B$ 中大量辅助数据的行为者。符合一个标准并不意味着符合另一个更严格的标准。\n- **结论：** 错误。", "answer": "$$\\boxed{A}$$", "id": "4504253"}]}