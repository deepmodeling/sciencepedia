{"hands_on_practices": [{"introduction": "在着手重建图像之前，我们必须首先理解成像系统是如何生成我们所测量的数据的。本练习介绍了线性前向模型，这是单光子发射计算机断层扫描（SPECT）成像中的一个基本概念。通过计算给定放射性活度分布下的期望投影，您将具体理解系统矩阵 $A$、活度向量 $x$ 和背景项 $r$ 的作用，它们是所有重建算法的基石。[@problem_id:4927199]", "problem": "考虑单光子发射计算机断层扫描 (SPECT)，其中测量到的投影数据被建模为随机计数，其期望值由系统对潜在活度分布的响应决定。在一个离散的双体素、双收集器（bin）设置中，令系统矩阵 $A$ 描述每个体素对每个投影收集器的贡献，活度向量 $x$ 表示体素的活度，加性项 $r$ 代表平均背景计数（包括散射和电子噪声）。采用 SPECT 的标准前向期望模型，该模型在期望计数层面结合了线性系统响应和加性背景。已知 \n$A=\\begin{bmatrix}0.5  0.2 \\\\ 0.3  0.4\\end{bmatrix}$，\n$x=\\begin{bmatrix}10 \\\\ 4\\end{bmatrix}$（单位：贝克勒尔，Bq），以及\n$r=\\begin{bmatrix}1 \\\\ 2\\end{bmatrix}$（单位：计数），请计算平均投影向量 $\\bar{y}$（以计数为单位）。然后，从体素贡献和背景的角度，简要解释各项对 $\\bar{y}$ 中每个分量的贡献。最终数值答案以计数为单位表示，且不要四舍五入。", "solution": "该问题描述了 SPECT 投影数据期望值的标准线性前向模型。平均投影向量 $\\bar{y}$ 是源于患者体内示踪剂分布的期望计数与源于背景源的期望计数的总和。该关系表示为：\n$$ \\bar{y} = Ax + r $$\n其中 $A$ 是系统矩阵，$x$ 是活度向量，$r$ 是平均背景向量。\n\n我们已知以下数值：\n系统矩阵 $A$：\n$$ A = \\begin{bmatrix} 0.5  0.2 \\\\ 0.3  0.4 \\end{bmatrix} $$\n活度向量 $x$：\n$$ x = \\begin{bmatrix} 10 \\\\ 4 \\end{bmatrix} $$\n平均背景向量 $r$：\n$$ r = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} $$\n\n首先，我们计算来自活度分布的贡献，即乘积 $Ax$：\n$$ Ax = \\begin{bmatrix} 0.5  0.2 \\\\ 0.3  0.4 \\end{bmatrix} \\begin{bmatrix} 10 \\\\ 4 \\end{bmatrix} = \\begin{bmatrix} (0.5)(10) + (0.2)(4) \\\\ (0.3)(10) + (0.4)(4) \\end{bmatrix} $$\n$$ Ax = \\begin{bmatrix} 5 + 0.8 \\\\ 3 + 1.6 \\end{bmatrix} = \\begin{bmatrix} 5.8 \\\\ 4.6 \\end{bmatrix} $$\n该向量表示在考虑背景之前，每个收集器中探测到的源于两个体素的平均计数。\n\n接下来，我们加上平均背景计数 $r$，以求得总的平均投影向量 $\\bar{y}$：\n$$ \\bar{y} = Ax + r = \\begin{bmatrix} 5.8 \\\\ 4.6 \\end{bmatrix} + \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} = \\begin{bmatrix} 5.8 + 1 \\\\ 4.6 + 2 \\end{bmatrix} = \\begin{bmatrix} 6.8 \\\\ 6.6 \\end{bmatrix} $$\n因此，平均投影向量为 $\\bar{y} = \\begin{bmatrix} 6.8 \\\\ 6.6 \\end{bmatrix}$ 计数。\n\n对 $\\bar{y}$ 中每个分量的贡献解释如下：\n设平均投影向量的分量为 $\\bar{y} = \\begin{bmatrix} \\bar{y}_1 \\\\ \\bar{y}_2 \\end{bmatrix}$。\n\n对于第一个投影收集器，$\\bar{y}_1 = 6.8$ 计数：\n总平均计数是三项之和：\n1.  第一个体素（活度 $x_1 = 10$）对第一个收集器的贡献：$A_{11}x_1 = 0.5 \\times 10 = 5.0$ 计数。\n2.  第二个体素（活度 $x_2 = 4$）对第一个收集器的贡献：$A_{12}x_2 = 0.2 \\times 4 = 0.8$ 计数。\n3.  背景对第一个收集器的贡献：$r_1 = 1$ 计数。\n总和为 $\\bar{y}_1 = 5.0 + 0.8 + 1 = 6.8$ 计数。\n\n对于第二个投影收集器，$\\bar{y}_2 = 6.6$ 计数：\n总平均计数是三项之和：\n1.  第一个体素（活度 $x_1 = 10$）对第二个收集器的贡献：$A_{21}x_1 = 0.3 \\times 10 = 3.0$ 计数。\n2.  第二个体素（活度 $x_2 = 4$）对第二个收集器的贡献：$A_{22}x_2 = 0.4 \\times 4 = 1.6$ 计数。\n3.  背景对第二个收集器的贡献：$r_2 = 2$ 计数。\n总和为 $\\bar{y}_2 = 3.0 + 1.6 + 2 = 6.6$ 计数。\n系统矩阵 $A$ 显示，第一个体素对第一个收集器的贡献更大，而第二个体素对第二个收集器的贡献更大，这对于每个收集器都更靠近其对应体素的探测器几何结构来说是典型情况。", "answer": "$$ \\boxed{ \\begin{pmatrix} 6.8 \\\\ 6.6 \\end{pmatrix} } $$", "id": "4927199"}, {"introduction": "建立了前向模型后，我们的主要目标是解决“逆问题”：即根据测量值 $y$ 推算出图像 $x$。本练习将带您深入了解最大似然期望最大化（ML-EM）算法，这是统计图像重建领域的基石。您将看到该算法如何利用光子计数的泊松统计特性来迭代地优化图像估计。[@problem_id:4927224]", "problem": "在单光子发射计算机断层成像 (SPECT) 中，一个标准的分箱投影模型假设每个探测器单元的计数 $y_i$ 是一个泊松随机变量的实现，其均值为 $\\lambda_i = \\sum_{j} A_{ij} x_j + r_i$。其中，$A_{ij}$ 是一个已知的系统矩阵，编码了从体素 $j$ 发射的光子被探测器单元 $i$ 探测到的概率；$x_j \\ge 0$ 是体素 $j$ 中未知的放射性活度；$r_i \\ge 0$ 是探测器单元 $i$ 中已知的平均背景计数。在此模型下，可以通过期望最大化框架寻求最大似然估计，从而得到一个保持非负性的乘性不動点迭代。\n\n从泊松数据模型、独立泊松测量的对数似然定义以及使用适当隐变量的期望最大化构造出发，推导在已知 $A$ 和 $r$ 的情况下，适用于最大似然期望最大化 (ML-EM) 的不动点乘性更新。然后，使用您推导出的更新规则，从给定的初始值开始，对以下数值指定的 SPECT 系统执行一次迭代，计算 $x^{1}$：\n$$\nA=\\begin{bmatrix}0.4  0.2\\\\ 0.1  0.5\\end{bmatrix},\\quad\ny=\\begin{bmatrix}20\\\\ 10\\end{bmatrix},\\quad\nr=\\begin{bmatrix}0\\\\ 0\\end{bmatrix},\\quad\nx^{0}=\\begin{bmatrix}5\\\\ 5\\end{bmatrix}.\n$$\n将 $x^{1}$ 的两个分量报告为计数的精确值（不进行四舍五入）。以计数为单位表示 $x^{1}$ 的最终数值结果。", "solution": "该问题是有效的。这是一个医学图像重建中的标准问题，具有科学依据、提法恰当，并包含获得唯一解所需的所有信息。\n\n该问题分为两部分：首先，推导用于 SPECT 重建的最大似然期望最大化 (ML-EM) 更新规则；其次，将此规则应用于给定的数值数据，进行一次迭代。\n\n### 第1部分：ML-EM 更新规则的推导\n\n问题陈述了测量投影数据的统计模型。对于每个探测器单元 $i$，计数 $y_i$ 是一个独立泊松随机变量的实现，其均值为 $\\lambda_i$。该均值由以下线性模型给出：\n$$\n\\lambda_i = \\sum_{j=1}^{N} A_{ij} x_j + r_i\n$$\n其中 $x_j$ 是体素 $j$ ($j=1, \\dots, N$) 中未知的放射性活度，$A_{ij}$ 是系统矩阵元素，表示从体素 $j$ 发射的光子被探测器单元 $i$ 探测到的概率，而 $r_i$ 是探测器单元 $i$ 中已知背景事件（例如散射）的均值。目标是找到放射性活度向量 $x = (x_1, \\dots, x_N)^T$，使得观测到测量向量 $y = (y_1, \\dots, y_M)^T$ 的似然最大。\n\n独立泊松测量的对数似然函数 $L(x)$ 为：\n$$\nL(x) = \\ln P(y|x) = \\sum_{i=1}^{M} \\ln \\left( \\frac{\\exp(-\\lambda_i) \\lambda_i^{y_i}}{y_i!} \\right) = \\sum_{i=1}^{M} \\left( -\\lambda_i + y_i \\ln(\\lambda_i) - \\ln(y_i!) \\right)\n$$\n代入 $\\lambda_i$ 的表达式，并舍去相对于 $x$ 为常数的项 $\\ln(y_i!)$：\n$$\nL(x) \\propto \\sum_{i=1}^{M} \\left( - \\left(\\sum_{j=1}^{N} A_{ij} x_j + r_i\\right) + y_i \\ln\\left(\\sum_{j=1}^{N} A_{ij} x_j + r_i\\right) \\right)\n$$\n由于和的对数形式，直接最大化此函数是困难的。期望最大化 (EM) 算法通过引入构成“完整数据”的隐变量来规避这一问题。\n\n设完整数据为变量集合 $\\{z_{ij}\\}$，其中 $z_{ij}$ 是源于体素 $j$ 并被探测器单元 $i$ 探测到的光子数。对于背景，我们可以认为它源于一个独立的源，为探测器单元 $i$ 贡献了 $w_i$ 个计数。\n观测到的或“不完整”的数据 $y_i$ 是这些贡献的总和：\n$$\ny_i = \\sum_{j=1}^{N} z_{ij} + w_i\n$$\n根据泊松模型，$z_{ij}$ 和 $w_i$ 是独立的泊松随机变量，其均值分别为 $E[z_{ij}] = A_{ij} x_j$ 和 $E[w_i] = r_i$。独立泊松变量的和也服从泊松分布，因此 $y_i$ 是一个泊松变量，其均值为 $\\sum_j E[z_{ij}] + E[w_i] = \\sum_j A_{ij} x_j + r_i$，这与问题陈述一致。\n\n给定 $x$ 时，完整数据 $\\{z_{ij}, w_i\\}$ 的对数似然为：\n$$\nL_c(x) = \\ln P(\\{z_{ij}, w_i\\}|x) = \\sum_{i=1}^{M} \\sum_{j=1}^{N} \\ln P(z_{ij}|x) + \\sum_{i=1}^{M} \\ln P(w_i)\n$$\n由于关于 $w_i$ 的项不依赖于 $x$，因此在最大化过程中可以忽略它。\n$$\nL_c(x) \\propto \\sum_{i=1}^{M} \\sum_{j=1}^{N} \\left( -A_{ij}x_j + z_{ij}\\ln(A_{ij}x_j) - \\ln(z_{ij}!) \\right)\n$$\nEM 算法分两步进行：\n\n**E步 (期望):**\n我们计算完整数据对数似然的期望，该期望以观测数据 $y$ 和参数的当前估计值 $x^{(k)}$ 为条件。这就是函数 $Q(x | x^{(k)})$：\n$$\nQ(x | x^{(k)}) = E[L_c(x) | y, x^{(k)}] = \\sum_{i=1}^{M} \\sum_{j=1}^{N} \\left( -A_{ij}x_j + E[z_{ij}|y, x^{(k)}]\\ln(A_{ij}x_j) \\right) + \\text{const.}\n$$\n关键是计算条件期望 $E[z_{ij}|y, x^{(k)}]$。已知独立泊松变量 $\\{z_{i1}, \\dots, z_{iN}, w_i\\}$ 的和为 $y_i$，它们在给定总和条件下的联合分布是多项分布。任何一个分量（例如 $z_{ij}$）的期望是总计数 $y_i$ 乘以其均值与所有均值之和的比率：\n$$\nE[z_{ij}|y_i, x^{(k)}] = y_i \\frac{E[z_{ij}|x^{(k)}]}{\\sum_{l=1}^{N}E[z_{il}|x^{(k)}] + E[w_i]} = y_i \\frac{A_{ij} x_j^{(k)}}{\\sum_{l=1}^{N} A_{il} x_l^{(k)} + r_i}\n$$\n让我们记作 $\\hat{z}_{ij}^{(k)} = E[z_{ij}|y, x^{(k)}]$。\n\n**M步 (最大化):**\n我们通过关于 $x$ 最大化 $Q(x | x^{(k)})$ 来找到下一个估计值 $x^{(k+1)}$。\n$$\nx^{(k+1)} = \\arg\\max_{x \\ge 0} Q(x | x^{(k)})\n$$\n我们求 $Q(x|x^{(k)})$ 对每个 $x_j$ 的偏导数，并令其为零。\n$$\n\\frac{\\partial Q(x|x^{(k)})}{\\partial x_j} = \\frac{\\partial}{\\partial x_j} \\sum_{i=1}^{M} \\sum_{l=1}^{N} \\left( -A_{il}x_l + \\hat{z}_{il}^{(k)}\\ln(A_{il}x_l) \\right)\n$$\n仅当 $l=j$ 时，导数才不为零：\n$$\n\\frac{\\partial Q}{\\partial x_j} = \\sum_{i=1}^{M} \\left( -A_{ij} + \\frac{\\hat{z}_{ij}^{(k)}}{x_j} \\right)\n$$\n令其为 $0$：\n$$\n\\sum_{i=1}^{M} \\frac{\\hat{z}_{ij}^{(k)}}{x_j} = \\sum_{i=1}^{M} A_{ij} \\implies x_j = \\frac{\\sum_{i=1}^{M} \\hat{z}_{ij}^{(k)}}{\\sum_{i=1}^{M} A_{ij}}\n$$\n这给出了 $x_j^{(k+1)}$ 的更新规则：\n$$\nx_j^{(k+1)} = \\frac{1}{\\sum_{i=1}^{M} A_{ij}} \\sum_{i=1}^{M} \\left( y_i \\frac{A_{ij} x_j^{(k)}}{\\sum_{l=1}^{N} A_{il} x_l^{(k)} + r_i} \\right)\n$$\n这可以重排为标准的乘性形式：\n$$\nx_j^{(k+1)} = x_j^{(k)} \\frac{\\sum_{i=1}^{M} A_{ij} \\frac{y_i}{\\sum_{l=1}^{N} A_{il} x_l^{(k)} + r_i}}{\\sum_{i=1}^{M} A_{ij}}\n$$\n这就是 ML-EM 的不动点乘性更新规则。项 $\\sum_{i=1}^{M} A_{ij}$ 通常表示为体素 $j$ 的灵敏度 $s_j$。\n\n### 第2部分：单次迭代的数值计算\n\n给定以下数值：\n$$\nA=\\begin{bmatrix}0.4  0.2\\\\ 0.1  0.5\\end{bmatrix},\\quad\ny=\\begin{bmatrix}20\\\\ 10\\end{bmatrix},\\quad\nr=\\begin{bmatrix}0\\\\ 0\\end{bmatrix},\\quad\nx^{(0)}=\\begin{bmatrix}5\\\\ 5\\end{bmatrix}\n$$\n我们要计算 $x^{(1)} = \\begin{bmatrix} x_1^{(1)} \\\\ x_2^{(1)} \\end{bmatrix}$。\n\n体素数量为 $N=2$，探测器单元数量为 $M=2$。对于 $j=1, 2$ 的更新规则是：\n$$\nx_j^{(1)} = x_j^{(0)} \\frac{\\sum_{i=1}^{2} A_{ij} \\frac{y_i}{\\sum_{l=1}^{2} A_{il} x_l^{(0)} + r_i}}{\\sum_{i=1}^{2} A_{ij}}\n$$\n当 $r=0$ 时，该式简化为：\n$$\nx_j^{(1)} = x_j^{(0)} \\frac{\\sum_{i=1}^{2} A_{ij} \\frac{y_i}{(Ax^{(0)})_i}}{\\sum_{i=1}^{2} A_{ij}}\n$$\n\n**1. 计算前向投影 $\\lambda^{(0)} = Ax^{(0)}$:**\n$$\n\\lambda^{(0)} = \\begin{bmatrix}0.4  0.2\\\\ 0.1  0.5\\end{bmatrix} \\begin{bmatrix}5\\\\ 5\\end{bmatrix} = \\begin{bmatrix}0.4(5) + 0.2(5) \\\\ 0.1(5) + 0.5(5)\\end{bmatrix} = \\begin{bmatrix}2 + 1 \\\\ 0.5 + 2.5\\end{bmatrix} = \\begin{bmatrix}3\\\\ 3\\end{bmatrix}\n$$\n\n**2. 计算校正比率 $y_i / \\lambda_i^{(0)}$:**\n$$\n\\frac{y_1}{\\lambda_1^{(0)}} = \\frac{20}{3}\n$$\n$$\n\\frac{y_2}{\\lambda_2^{(0)}} = \\frac{10}{3}\n$$\n\n**3. 计算更新因子分子中的反投影项：**\n该项为 $b_j = \\sum_{i=1}^{2} A_{ij} \\frac{y_i}{\\lambda_i^{(0)}}$。用矩阵形式表示，即为 $A^T (y./\\lambda^{(0)})$。\n对于 $j=1$：\n$$\nb_1 = A_{11}\\frac{y_1}{\\lambda_1^{(0)}} + A_{21}\\frac{y_2}{\\lambda_2^{(0)}} = (0.4)\\left(\\frac{20}{3}\\right) + (0.1)\\left(\\frac{10}{3}\\right) = \\frac{8}{3} + \\frac{1}{3} = \\frac{9}{3} = 3\n$$\n对于 $j=2$：\n$$\nb_2 = A_{12}\\frac{y_1}{\\lambda_1^{(0)}} + A_{22}\\frac{y_2}{\\lambda_2^{(0)}} = (0.2)\\left(\\frac{20}{3}\\right) + (0.5)\\left(\\frac{10}{3}\\right) = \\frac{4}{3} + \\frac{5}{3} = \\frac{9}{3} = 3\n$$\n\n**4. 计算灵敏度 $s_j = \\sum_{i=1}^{2} A_{ij}$:**\n对于 $j=1$：\n$$\ns_1 = A_{11} + A_{21} = 0.4 + 0.1 = 0.5\n$$\n对于 $j=2$：\n$$\ns_2 = A_{12} + A_{22} = 0.2 + 0.5 = 0.7\n$$\n\n**5. 应用乘性更新以找到 $x^{(1)}$:**\n$$\nx_j^{(1)} = x_j^{(0)} \\frac{b_j}{s_j}\n$$\n对于 $j=1$：\n$$\nx_1^{(1)} = x_1^{(0)} \\frac{b_1}{s_1} = 5 \\cdot \\frac{3}{0.5} = 5 \\cdot 6 = 30\n$$\n对于 $j=2$：\n$$\nx_2^{(1)} = x_2^{(0)} \\frac{b_2}{s_2} = 5 \\cdot \\frac{3}{0.7} = \\frac{15}{7/10} = \\frac{150}{7}\n$$\n\n因此，一次迭代后更新的放射性活度向量为 $x^{(1)} = \\begin{bmatrix} 30 \\\\ 150/7 \\end{bmatrix}$。", "answer": "$$\n\\boxed{\\begin{pmatrix} 30 \\\\ \\frac{150}{7} \\end{pmatrix}}\n$$", "id": "4927224"}, {"introduction": "虽然ML-EM算法功能强大，但其重建结果，尤其是在数据量有限时，可能会含有大量噪声。为了解决这个问题，我们可以引入关于真实图像应具有何种特征的先验知识。本练习通过引入一个二次平滑先验来探索正则化的概念，该数学工具旨在惩罚相邻像素间的剧烈变化，从而生成更平滑、噪声更少的图像。通过计算正则化惩罚项及其梯度，您将洞悉惩罚似然法的工作原理，并掌握理解更高级重建算法所需的数学基础。[@problem_id:4927241]", "problem": "考虑单光子发射计算机断层成像（SPECT）重建，其中惩罚似然目标函数通过空间平滑度正则化来增强数据保真项，该正则化编码了关于图像的先验信念。设先验使用吉布斯分布在无向邻居对上建模为高斯马尔可夫随机场（GMRF）。具体来说，对于每对无向相邻体素索引 $(j,k)$，团势定义为 $v_{jk}(x_j,x_k)=\\frac{\\beta\\,w_{jk}}{2}\\,(x_j-x_k)^{2}$，其中 $\\beta>0$ 是正则化强度，而 $w_{jk}\\ge 0$ 是对称边权重。负对数先验（不计一个加性常数）是所有无向邻居对上这些团势的总和，该总和被作为惩罚目标函数中的正则化项 $R(x)$。\n\n从这些定义出发，用邻居集合和图像 $x$ 推导正则化项 $R(x)$ 及其梯度 $\\nabla R(x)$ 的显式表达式。然后，对于一个示例一维图像 $x=\\begin{bmatrix}2\\\\4\\\\3\\end{bmatrix}$，其无向邻居集合为 $\\mathcal{N}(1)=\\{2\\}$, $\\mathcal{N}(2)=\\{1,3\\}$, $\\mathcal{N}(3)=\\{2\\}$，所有邻居对的权重均为 $w_{jk}=1$，正则化强度为 $\\beta=0.2$，计算 $R(x)$ 的数值和 $\\nabla R(x)$ 的分量。将最终答案表示为一个单行向量，包含 $R(x)$ 和 $\\nabla R(x)$ 的三个分量。不需要四舍五入，这些量没有物理单位。", "solution": "### $R(x)$ 和 $\\nabla R(x)$ 的推导\n\n**1. 正则化项 $R(x)$ 的表达式**\n\n根据定义，正则化项 $R(x)$ 是所有无向邻居对上团势的总和。为避免重复计数，我们将对唯一的无向邻居对 $(j,k)$（其中约定 $j < k$）进行求和。\n$$ R(x) = \\sum_{j < k, k \\in \\mathcal{N}(j)} v_{jk}(x_j, x_k) = \\sum_{j < k, k \\in \\mathcal{N}(j)} \\frac{\\beta w_{jk}}{2}(x_j - x_k)^2 $$\n\n**2. 梯度 $\\nabla R(x)$ 的表达式**\n\n梯度 $\\nabla R(x)$ 是一个向量，其第 $i$ 个分量是 $R(x)$ 对 $x_i$ 的偏导数。对 $R(x)$ 的表达式求导时，只有包含 $x_i$ 的项才会产生非零导数。对于给定的体素 $i$，它与其每个邻居 $k \\in \\mathcal{N}(i)$ 都形成一个惩罚项。\n\n考虑一个邻居 $k \\in \\mathcal{N}(i)$。求和中存在一项 $\\frac{\\beta w_{ik}}{2}(x_i - x_k)^2$。\n该项对 $x_i$ 的偏导数为：\n$$ \\frac{\\partial}{\\partial x_i} \\left( \\frac{\\beta w_{ik}}{2}(x_i - x_k)^2 \\right) = \\frac{\\beta w_{ik}}{2} \\cdot 2(x_i - x_k) \\cdot \\frac{\\partial}{\\partial x_i}(x_i - x_k) = \\beta w_{ik}(x_i - x_k) $$\n将所有与 $i$ 相邻的体素的贡献相加，我们得到梯度向量的第 $i$ 个分量：\n$$ (\\nabla R(x))_i = \\sum_{k \\in \\mathcal{N}(i)} \\beta w_{ik}(x_i - x_k) $$\n由于 $w_{jk}$ 是对称的 ($w_{ik} = w_{ki}$)，这个表达式是明确的。\n\n### 数值计算\n\n给定 $x=\\begin{bmatrix}2\\\\4\\\\3\\end{bmatrix}$，$\\beta=0.2$，以及对于所有邻居对 $w_{jk}=1$。\n邻居关系为 (1,2) 和 (2,3)。\n\n**1. 计算 $R(x)$**\n\n唯一的无向邻居对是 (1, 2) 和 (2, 3)。\n$$ R(x) = \\frac{\\beta w_{12}}{2}(x_1 - x_2)^2 + \\frac{\\beta w_{23}}{2}(x_2 - x_3)^2 $$\n$$ R(x) = \\frac{0.2 \\cdot 1}{2}(2 - 4)^2 + \\frac{0.2 \\cdot 1}{2}(4 - 3)^2 $$\n$$ R(x) = 0.1(-2)^2 + 0.1(1)^2 = 0.1(4) + 0.1(1) = 0.4 + 0.1 = 0.5 $$\n\n**2. 计算梯度 $\\nabla R(x)$**\n\n我们计算梯度的每个分量：\n-   对于 $i=1$，其唯一的邻居是 $k=2$：\n    $$ (\\nabla R(x))_1 = \\beta w_{12}(x_1 - x_2) = 0.2 \\cdot 1 \\cdot (2 - 4) = 0.2(-2) = -0.4 $$\n-   对于 $i=2$，其邻居是 $k=1$ 和 $k=3$：\n    $$ (\\nabla R(x))_2 = \\beta w_{21}(x_2 - x_1) + \\beta w_{23}(x_2 - x_3) = 0.2 \\cdot 1 \\cdot (4 - 2) + 0.2 \\cdot 1 \\cdot (4 - 3) $$\n    $$ (\\nabla R(x))_2 = 0.2(2) + 0.2(1) = 0.4 + 0.2 = 0.6 $$\n-   对于 $i=3$，其唯一的邻居是 $k=2$：\n    $$ (\\nabla R(x))_3 = \\beta w_{32}(x_3 - x_2) = 0.2 \\cdot 1 \\cdot (3 - 4) = 0.2(-1) = -0.2 $$\n\n因此，梯度向量是 $\\nabla R(x) = \\begin{bmatrix}-0.4\\\\0.6\\\\-0.2\\end{bmatrix}$。\n\n**3. 整合结果**\n\n问题要求输出一个包含 $R(x)$ 和 $\\nabla R(x)$ 分量的单行向量：\n$$ [R(x), (\\nabla R(x))_1, (\\nabla R(x))_2, (\\nabla R(x))_3] = [0.5, -0.4, 0.6, -0.2] $$", "answer": "$$\\boxed{\\begin{pmatrix} 0.5 & -0.4 & 0.6 & -0.2 \\end{pmatrix}}$$", "id": "4927241"}]}