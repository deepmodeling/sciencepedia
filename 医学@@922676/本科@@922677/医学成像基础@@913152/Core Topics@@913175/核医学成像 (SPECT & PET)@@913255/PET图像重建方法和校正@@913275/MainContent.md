## 引言
[正电子发射断层扫描](@entry_id:165099)（PET）是功能与分子成像的核心技术，能够揭示体内的生物化学过程。然而，从探测器记录的原始光子信号到一幅具有诊断价值的定量图像，其间的转换过程——即图像重建——是一个充满挑战的复杂领域。简单地将数据“反投”回图像空间并不能克服由物理衰减、[光子散射](@entry_id:194085)以及统计噪声等因素造成的图像退化。因此，开发能够精确建模这些复杂过程并有效求解逆问题的重建方法，是实现PET技术全部潜能的关键。

本文旨在系统性地引导读者穿越这一精密领域。我们将首先在“原理与机制”部分深入剖析连接物理现实与数学表达的正向模型，并详细阐述从经典的滤波反投影（FBP）到现代临床标准——有序子集[期望最大化](@entry_id:273892)（OSEM）等核心重建算法。接着，在“应用与跨学科交叉”部分，我们将展示这些理论如何转化为临床实践中的关键定量指标（如SUV），并探讨其在PET/CT和PET/MRI等多模态融合以及应对运动伪影等高级应用中的作用。最后，通过“动手实践”环节，读者将有机会通过具体计算来巩固对重建和校正核心概念的理解，将抽象理论付诸实践。

## 原理与机制

本章旨在系统性地阐述正电子发射断层扫描（PET）图像重建的核心原理与关键机制。我们将深入探讨如何将探测器记录的原始数据，即光子符合事件，转化为具有定量诊断价值的断层图像。这一过程不仅是一个数学反演问题，更是一个深度融合了物理学、统计学和计算科学的精密工程。我们将从构建描述[数据采集](@entry_id:273490)过程的**正向模型（forward model）**入手，逐步解析理想化的解析重建方法，并过渡到现代临床实践中占主导地位的统计迭代重建算法。此外，本章将重点阐述为了实现准确[定量成像](@entry_id:753923)所必须的各项物理校正技术，包括衰减、散射和随机符合校正，并讨论在重建过程中整合这些校正的先进策略。

### 正向问题：从物理过程到数学模型

PET[图像重建](@entry_id:166790)的根本任务是求解一个**[逆问题](@entry_id:143129)（inverse problem）**：根据探测器测量的投影数据，反推出体内放射性示踪剂的活度分布。为了解决这个逆问题，我们首先需要建立一个精确的**正向模型**，即一个数学表达式，用以描述示踪剂活度分布与测量数据之间的确定性与统计性关系。

PET探测器记录的是在预设时间窗内成对到达的湮灭光子。这些符合事件的数量本质上是随机的，源于放射性衰变的[随机过程](@entry_id:268487)。在给定时间间隔内，放射性衰变的次数服从**泊松分布（Poisson distribution）**。因此，PET[数据采集](@entry_id:273490)的统计基础模型是将每个探测器对（或称响应线，Line of Response, LOR）上记录的计数值$y_i$视为一个独立的泊松随机变量。其[期望值](@entry_id:150961)（均值）$\mathbb{E}[y_i]$由一系列物理过程决定。

一个完整且精确的离散正向模型可以将待求的、以**体素（voxel）**化表示的图像活度分布向量 $\mathbf{x}$ 与[正弦图](@entry_id:754926)（sinogram）各数据单元的[期望计数](@entry_id:162854)值向量 $\mathbb{E}[\mathbf{y}]$ 联系起来。该模型通常表述为：

$$
\mathbb{E}[\mathbf{y}] = A\mathbf{x} + \mathbf{s} + \mathbf{r}
$$

因此，完整的[统计模型](@entry_id:755400)为 $y_i \sim \text{Poisson}((A\mathbf{x})_i + s_i + r_i)$。[@problem_id:4907976] 让我们逐一解析这个模型中的关键组成部分：

*   **$\mathbf{x}$ (图像活度)**：这是一个向量，其元素 $x_j$ 代表了成像视野（Field of View, FOV）中第 $j$ 个体素内的平均放射性活度（例如，单位为贝可勒尔/毫升，Bq/mL）。这是我们希望通过重建得到的未知量。

*   **$\mathbf{y}$ (测量数据)**：这是一个向量，其元素 $y_i$ 代表了在第 $i$ 条 LOR 上于[采集时间](@entry_id:266526)内记录到的总符合事件（称为**“即时”符合（prompt coincidences）**）的计数值。这些数据通常被组织成一个二维数组，即**[正弦图](@entry_id:754926)（sinogram）**。

*   **$A$ ([系统矩阵](@entry_id:172230))**：这是一个庞大但通常是稀疏的矩阵，是连接图像空间与投影空间的核心。[系统矩阵](@entry_id:172230)的元素 $A_{ij}$ 代表了在第 $j$ 个体素中发生的一次[正电子](@entry_id:149367)湮灭事件，最终被第 $i$ 条 LOR 探测为“真”符合事件的概率。这个概率是一个复合量，它编码了[PET扫描](@entry_id:165099)仪系统的几何和物理特性，我们将在下一节详细讨论。

*   **$\mathbf{s}$ (散射符合)**：这是一个向量，其元素 $s_i$ 代表了第 $i$ 条 LOR 上由**散射（scatter）**事件贡献的平均计数值。散射事件指的是至少一个湮灭光子在到达探测器前，在患者体内发生了康普顿散射，改变了其原始飞行方向，从而被错误的 LOR 记录。

*   **$\mathbf{r}$ (随机符合)**：这是一个向量，其元素 $r_i$ 代表了第 $i$ 条 LOR 上由**随机（random）**或偶然符合事件贡献的平均计数值。随机符合事件源于两个毫无关联、来自不同湮灭事件的光子在符合时间窗内偶然同时被一对探测器记录。

总而言之，正向模型表明，在一条 LOR 上测得的总[期望计数](@entry_id:162854)值，是源自所有体素贡献的**真符合（true coincidences）**[期望值](@entry_id:150961)、散射符合[期望值](@entry_id:150961)和随机符合[期望值](@entry_id:150961)三者的总和。理解并精确建模这每一个组成部分，是实现准确定量PET图像重建的前提。

### 系统矩阵：连接[理想理论](@entry_id:184127)与物理现实

[系统矩阵](@entry_id:172230) $A$ 是正向模型中最为复杂的部分，它将理想的数学变换与真实世界的物理探测过程联系起来。

#### 理想模型：[Radon变换](@entry_id:754021)与滤波[反投影](@entry_id:746638)

在一个高度理想化的二维平行束PET系统中，若忽略所有物理衰减、散射、随机事件以及探测器效应，[数据采集](@entry_id:273490)过程可以被精确地描述为对活度分布 $f(\mathbf{x})$ 的**[Radon变换](@entry_id:754021)（Radon Transform）**。[Radon变换](@entry_id:754021) $p(s, \theta)$ 定义为函数 $f(\mathbf{x})$ 沿着由角度 $\theta$ 和距原点距离 $s$ 所定义的无限细直线上的[线积分](@entry_id:141417)：

$$
p(s, \theta) = \int_{\mathbb{R}^2} f(\mathbf{x})\, \delta(s - \mathbf{x} \cdot \mathbf{n}_\theta)\, d^2\mathbf{x}
$$

其中 $\mathbf{n}_\theta$ 是[直线的法向量](@entry_id:178923)。**[投影切片定理](@entry_id:267677)（Projection-Slice Theorem）**建立了[Radon变换](@entry_id:754021)与图像傅里叶变换之间的桥梁，它指出，一个投影的一维傅里叶变换 $P(\omega, \theta)$ 等于该图像的[二维傅里叶变换](@entry_id:273583) $F(\mathbf{k})$ 沿着穿过原点、与投影方向一致的直线上（即一个“切片”）的值。

基于此定理，**滤波[反投影](@entry_id:746638)（Filtered Backprojection, FBP）**算法应运而生。直接将所有投影“涂抹”回图像空间的操作，即**反投影（backprojection）**，并不能恢复[原始图](@entry_id:262918)像。数学上可以证明，未经滤波的简单[反投影](@entry_id:746638)会导致图像与一个点扩散函数（Point Spread Function, PSF）进行卷积，该PSF在空间域中表现为 $1/r$ 的模糊（其中 $r$ 是到源点的距离），在频率域中则表现为对图像[频谱](@entry_id:276824)的 $1/|\mathbf{k}|$ 加权。[@problem_id:4908147] 为了抵消这种模糊，FBP在反投影之前，会对每个投影的一维傅里叶谱乘以一个**[斜坡滤波器](@entry_id:754034)（ramp filter）**，其频率响应为 $|\omega|$。这个[高通滤波器](@entry_id:274953)恰好补偿了反投影操作引入的低频放大效应，从而在理想条件下能够精确重建图像。

#### 实用模型：系统矩阵的构成要素

然而，真实的PET系统远比理想的[Radon变换](@entry_id:754021)模型复杂。[系统矩阵](@entry_id:172230) $A$ 的元素 $A_{ij}$ 并非简单的线段长度，而是一个综合了多种物理效应的探测概率。[@problem_id:4908124]

*   **几何与探测器[孔径](@entry_id:172936)**：与无限细的线积分不同，$A_{ij}$ 考虑了由有限尺寸的探测器对构成的“响应管（tube of response）”的几何形状。体素 $j$ 对 LOR $i$ 的贡献取决于它与这个响应管的交集以及探测器对所张的[立体角](@entry_id:154756)。

*   **衰减效应**：湮没光子在穿过人体组织时可能被吸收或散射，导致其无法到达探测器。光子对能同时存活的概率由衰减因子 $a_i = \exp(-\int_{\text{LOR}_i} \mu(\mathbf{r}) d\ell)$ 决定，其中 $\mu(\mathbf{r})$ 是人体组织在 $511\,\text{keV}$ 能量下的线性衰减系数图。这个因子被直接整合进 $A_{ij}$ 中。

*   **探测器归一化**：不同探测器晶体的效率、几何位置的差异导致不同LOR的探测灵敏度不同。归一化校正因子用于补偿这些差异，确保成像视野内具有均匀的探测响应。

*   **物理模糊效应与[点扩散函数](@entry_id:183154) (PSF)**：多种物理现象会导致探测到的位置偏离真实事件发生的位置，共同构成了系统的PSF。这些效应包括：
    *   **正电子射程**：正电子在湮灭前会在组织中行进一小段距离。
    *   **非[共线性](@entry_id:270224)**：湮灭产生的两个光子并非严格的180度背向发射，存在约$\pm 0.25^\circ$的角度偏差。
    *   **探测器内部散射和交互深度 (DOI) 效应**：光子可能在晶体内发生散射后被探测，或在不同深度发生交互。特别是**交互深度（Depth Of Interaction, DOI）**未知所引起的**视差效应（parallax effect）**，是导致PSF空间变异（shift-variant）的主要原因。对于偏离视野中心的源，光子会以一定角度入射到晶体，未知的交互深度会导致LOR定位的横向不确定性。可以推导，这种由DOI引起的模糊宽度会随着源点离视野中心的径向距离 $r$ 的增加而增加，使得整个系统的PSF是空间位置相关的。[@problem_id:4908077]

*   **[飞行时间 (TOF)](@entry_id:166271) 信息**：对于TOF-[PET扫描](@entry_id:165099)仪，通过测量两个光子到达探测器的时间差，可以将湮灭事件定位在LOR上的一个较小线段内。这通过在系统矩阵 $A_{ij}$ 中引入一个沿LOR的权重（通常是[高斯函数](@entry_id:261394)）来实现，该权重集中在TOF信息指示的位置附近，从而显著改善了[信噪比](@entry_id:271196)和图像质量。[@problem_id:4908124]

综上所述，系统矩阵 $A$ 是一个复杂的物理模型，它将[PET扫描](@entry_id:165099)仪的全部物理和几何特性编码进去，远超[Radon变换](@entry_id:754021)的范畴。

### 逆问题：[图像重建](@entry_id:166790)算法

有了正向模型，重建的目标就是求解逆问题，即从测量的 $y$ 估计出未知的 $x$。

#### 解析重建：滤波[反投影](@entry_id:746638) (FBP)

如前所述，FBP是一种基于Radon[逆变](@entry_id:192290)换的快速解析算法。它在临床上曾被广泛使用，优点是计算速度快、实现简单。然而，FBP的主要缺点在于其对数据噪声非常敏感，并且它基于一个简化的、忽略了统计特性的物理模型。因此，它难以精确地处理散射、随机事件以及复杂的PSF效应，导致重建图像的噪声水平较高，定量准确性有限。

#### 统计迭代重建

为了克服FBP的局限性，现代PET重建普遍采用统计迭代方法。这类方法的基础是将重建视为一个在泊松统计框架下的参数估计问题。其核心思想是：从一个初始的图像估计 $\mathbf{x}^{(0)}$ 开始，通过迭代更新，逐步找到一个能最好地“解释”测量数据 $\mathbf{y}$ 的图像 $\mathbf{x}$。

##### 最大似然[期望最大化](@entry_id:273892) (ML-EM)

**[最大似然](@entry_id:146147)[期望最大化](@entry_id:273892)（Maximum Likelihood Expectation-Maximization, ML-EM）**算法是迭代重建的基石。其目标是找到能使测量数据出现的概率（即**泊松对数似然函数**）最大化的图像估计 $\mathbf{x}$。ML-[EM算法](@entry_id:274778)通过一个优雅的迭代公式来实现这一目标：

$$
x_j^{(k+1)} = \frac{x_j^{(k)}}{\sum_{i=1}^{I} A_{ij}} \sum_{i=1}^{I} A_{ij} \frac{y_i}{(A\mathbf{x}^{(k)})_i + s_i + r_i}
$$

其中 $k$ 是迭代次数。这个公式具有直观的物理解释：新的体素值 $x_j^{(k+1)}$ 是由旧的体素值 $x_j^{(k)}$ 乘以一个校正因子得到的。该校正因子是所有LOR上测量值 $y_i$ 与当前模型预测值 $(A\mathbf{x}^{(k)})_i + s_i + r_i$ 之比的加权和。如果测量值大于预测值，体素值将被调高，反之则调低。

ML-[EM算法](@entry_id:274778)具有一些优良的特性，如保证图像值的非负性，并且在每次迭代中对数似然函数值单调非减，理论上能收敛到最大似然解。但其主要缺点是[收敛速度](@entry_id:146534)非常慢，需要大量迭代才能获得可接受的图像质量，这在临床上是不切实际的。

##### 有序子集[期望最大化](@entry_id:273892) (OSEM)

为了解决ML-EM收敛慢的问题，**有序子集[期望最大化](@entry_id:273892)（Ordered-Subsets Expectation-Maximization, OSEM）**算法被提出。OSEM将投影数据（即LOR的索引）划分为 $M$ 个有序的**子集（subsets）**。在一个完整的“迭代”（通常称为一个sweep或pass）中，OSEM会依次使用每个子集的数据来执行一次类EM的更新。[@problem_id:4908010]

对第 $m$ 个子集 $S_m$ 的更新公式为：

$$
x_j^{\text{new}} = \frac{x_j^{\text{old}}}{\sum_{i \in S_m} A_{ij}} \sum_{i \in S_m} A_{ij} \frac{y_i}{(A\mathbf{x}^{\text{old}})_i + s_i + r_i}
$$

通过在一次完整迭代中更新图像 $M$ 次，OSEM的[收敛速度](@entry_id:146534)大约比ML-EM快 $M$ 倍。这是其在临床中被广泛应用的主要原因。然而，这种加速是有代价的：当子集数量 $M > 1$ 时，OSEM不再保证似然函数的[单调性](@entry_id:143760)，并且通常不会收敛到精确的ML解，而是在一个**[极限环](@entry_id:274544)（limit cycle）**中振荡。子集划分得越不均衡，极限环的振幅越大。通过引入一个随迭代次数衰减的**松弛因子（relaxation factor）**，可以使OSEM恢[复收敛](@entry_id:171253)性，但这会牺牲部分加速效果。[@problem_id:4908010]

### 定量PET的必要校正

为了从PET图像中获得准确的生理参数（即实现“定量”），必须对正向模型中描述的各种物理退化效应进行精确校正。

#### 衰减校正

光子在人体内的衰减是PET中最显著的物理效应，若不校正，将导致图像边缘伪影和严重的定量偏差。现代PET/CT扫描仪利用同步获取的CT图像来进行**衰减校正（attenuation correction）**。CT图像的像素值，即**亨斯菲尔德单位（Hounsfield Unit, HU）**，反映了组织在CT X射线能量（约70-140 keV）下的衰减特性。为了用于PET衰减校正，必须将HU值转换为组织在PET[光子能量](@entry_id:139314)（$511\,\text{keV}$）下的[线性衰减](@entry_id:198935)系数 $\mu_{511}$。

这一转换并非简单的线性关系，因为光子与物质相互作用的机制随能量和物质原子序数而变。在CT能量下，**光电效应**对高[原子序数](@entry_id:139400)物质（如骨骼）的衰减贡献显著；而在 $511\,\text{keV}$ 能量下，所有生物组织的衰减都主要由**康普顿散射**主导，后者主要与物质的电子密度相关。骨骼的H[U值](@entry_id:151629)因[光电效应](@entry_id:162802)而被“放大”，因此，从HU到$\mu_{511}$的映射需要采用**[分段线性](@entry_id:201467)（piecewise linear）**或“[双线性](@entry_id:146819)（bilinear）”模型。[@problem_id:4907986] 通常以水（HU=0）为界，对HU值低于0的软组织和高于0的骨骼组织采用不同的斜率进行转换，以准确地反映不同组织在两种能量下的物理特性差异。

#### 散射校正

散射光子会降低图像对比度并导致活度被错误地估计在非活度区域。**散射校正（scatter correction）**的目标是从测量数据中估计并减去散射成分 $s_i$。一种常见的方法是**卷积减影法（convolution-subtraction）**。该方法基于一个物理假设：散射过程可被视为一个空间展宽过程。即，散射分布可以近似为真符合分布与一个**散射核（scatter kernel）**的卷积。[@problem_id:4908088]

这个散射核本身模拟了由康普顿散射引起的空间错位（其分布近似为指数衰减）以及探测器响应函数（通常为高斯函数）的综合效应。通过初步估计的[真值](@entry_id:636547)分布（例如，来自衰减校正后的图像），可以计算出散射分布的形状。然后，利用投影数据中目标外部区域（这些区域理论上只有散射和随机符合）的计数值，通过**尾部拟合（tail fitting）**来确定散射成分的实际幅度，最终将其从原始投影数据中减去。

#### 随机符合校正

随机符合是高活度或高探测器“单光子计率（singles rate）”下的一个主要噪声来源。**随机符合校正（randoms correction）**最直接和准确的方法是**延迟窗法（delayed-window method）**。[@problem_id:4908156] 该方法通过设置第二个符合电路，其中一个探测器的信号被人为延迟一个远大于符合时间窗的时间。在此“延迟窗”中记录到的任何符合事件都不可能是来自同一次湮灭的真符合，因此它们必然是随机符合。

这样测得的延迟符合计数值 $D$ 为随机符合率提供了一个无偏的、实时的测量。在进行重建前，可以从即时符合计数值 $P$ 中直接减去它，以得到真符合和散射符合之和的估计值，即 $\hat{T}_{true+scatter} = P - D$。然而，这种减法操作是有统计代价的。由于 $P$ 和 $D$ 都是独立的泊松随机变量，根据[误差传播](@entry_id:147381)原理，相减后结果的方差是两者方差之和。若真符合、随机符合的平均计数为 $\lambda_T$ 和 $\lambda_R$，则 $\text{Var}(P) = \lambda_T + \lambda_R$，而 $\text{Var}(D) = \lambda_R$。因此，减去随机符合后的数据方差为：

$$
\text{Var}(P-D) = \text{Var}(P) + \text{Var}(D) = (\lambda_T + \lambda_R) + \lambda_R = \lambda_T + 2\lambda_R
$$

这比原始即时数据的方差 $(\lambda_T + \lambda_R)$ 更大。这意味着直接减去一个噪声测量会增加最终数据的噪声水平。[@problem_id:4908156]

### 先进重建策略

随着计算能力的增强，更复杂的重建策略得以实现，它们通过更精确的建模来提升图像质量。

#### 校正建模：预校正 vs. 重建中建模

处理衰减、散射和随机符合等校正项，存在两种主要策略：

1.  **预校正（Pre-correction）**：在迭代重建开始之前，对原始投影数据 $y_i$ 进行处理，例如，通过减去估计的散射和随机项 $\hat{s}_i, \hat{r}_i$，然后除以衰减因子 $a_i$，得到一个“理想化”的投影数据 $y''_i = (y_i - \hat{r}_i - \hat{s}_i)/a_i$。然后基于简化的模型 $y''_i \approx \sum_j p_{ij} x_j$ 进行重建。

2.  **重建中建模（In-reconstruction modeling）**：在[迭代算法](@entry_id:160288)（如OSEM）的每一步中，都使用包含所有校正项的完整正向模型 $\mathbb{E}[y_i] = a_i \sum_{j} p_{ij} x_j + s_i + r_i$。

从数学和统计学角度看，这两种方法并不等价。预校正方法虽然直观，但它忽略了校正过程本身引入的噪声。例如，减去一个有噪声的随机估计 $\hat{r}_i$ 会改变数据的方差。而除以衰减因子 $a_i$ 也会放大噪声，特别是对于衰减严重的LOR。只有在所有校正项都为确定性、无噪声的理想情况下，通过对权重进行适当的重新缩放，两种方法才能在加权最小二乘（WLS）等框架下等价。[@problem_id:4907916] 实际上，将所有物理效应和统计特性都精确地包含在迭代重建的模型中，是获得最优统计性能和定量准确性的首选方法。

#### 正则化：[最大后验概率](@entry_id:268939) (MAP) 重建

ML-EM和OS[EM算法](@entry_id:274778)在迭代后期容易过度放大数据中的噪声，导致图像出现伪影。为了控制噪声，可以在重建中引入**正则化（regularization）**。这通常通过从最大似然估计转向**[最大后验概率](@entry_id:268939)（Maximum A Posteriori, MAP）**估计来实现。MAP的目标函数在[对数似然](@entry_id:273783)项之外，增加了一个惩罚项或**先验（prior）**，用以表达对图像平滑性等期望特性的偏好：

$$
\mathbf{x}_{\text{MAP}} = \arg\max_{\mathbf{x} \ge 0} \left( \log p(\mathbf{y} | \mathbf{x}) - \beta R(\mathbf{x}) \right)
$$

其中 $R(\mathbf{x})$ 是正则化函数，$\beta$ 是控制正则化强度的超参数。不同的 $R(\mathbf{x})$ 选择会对图像产生不同的影响，这可以通过其对相邻体素值差异的**[影响函数](@entry_id:168646)（influence function）** $\psi(t)$ 来分析。[@problem_id:4907987]

*   **二次惩罚（Quadratic penalty）**：$R(\mathbf{x}) \propto \sum (x_p-x_q)^2$。它的影响函数 $\psi(t) \propto t$ 随差异[线性增长](@entry_id:157553)。它能有效平滑小的噪声波动，但对大的差异（即图像边缘）施加过强的惩罚，导致边缘模糊。

*   **总变分惩罚（Total Variation, TV）**：$R(\mathbf{x}) \propto \sum |x_p-x_q|$。其影响函数 $\psi(t)$ 在差异非零时为常数。它对所有大小的差异施加同等强度的惩罚，因此能很好地保护尖锐边缘，但代价是可能[过度平滑](@entry_id:634349)掉细微的纹理，产生“块状”或“阶梯状”伪影。

*   **Huber惩罚**：这是一种混合惩罚，对小的差异表现为二次型，对大的差异则变为线性（TV型）。其影响函数在小差异时[线性增长](@entry_id:157553)，在大差异时饱和为常数。因此，Huber惩罚提供了一种在有效去噪和良好边缘保持之间的折衷。[@problem_id:4907987]

通过选择合适的[正则化方法](@entry_id:150559)和参数，MAP重建能够在显著降低噪声的同时，保持图像的结构细节，从而在临床和科研应用中获得比ML-EM/OSEM更优的图像质量。