{"hands_on_practices": [{"introduction": "要真正掌握直方图均衡化，第一步是亲自动手完成其核心计算。这个练习将引导你完成基本步骤：根据给定的像素统计数据，构建累积直方图，并应用变换公式来重新映射灰度级。通过这个实践[@problem_id:3802113]，你将巩固对算法底层机制的理解。", "problem": "一台用于植被冠层遥感的机载多光谱成像辐射计，在经过机载线性量化后，将辐射亮度记录为8位数字数（DN）。在环境建模工作流程中，一个常见的预处理步骤是全局直方图均衡化，以增强对比度，同时保持DN水平的顺序。考虑某航线的一个小子集，在单个波段中仅存在以下DN水平及其对应的像素数（其余256个可能的DN水平在此子集中不出现）：\n\n- $DN=12$ 有 $184$ 个像素。\n- $DN=35$ 有 $792$ 个像素。\n- $DN=87$ 有 $115$ 个像素。\n- $DN=123$ 有 $58$ 个像素。\n- $DN=156$ 有 $1610$ 个像素。\n- $DN=201$ 有 $927$ 个像素。\n- $DN=245$ 有 $1214$ 个像素。\n\n假设对该子集应用了全局直方图均衡化，输出动态范围为 $L'=256$ 个级别，并将所列计数形成的经验分布视为图像直方图。仅使用直方图、累积分布以及由归一化累积分布定义的单调映射的定义，完成以下操作：\n\n- 按DN升序计算所列各分箱的累积计数。\n- 从基本定义出发，推导基于累积分布的离散均衡化映射，并应用它来计算每个所列DN分箱的均衡化输出水平。\n\n最后，请报告在$DN=201$处分箱的均衡化输出水平作为您的唯一数值答案。最终答案是一个整数水平；除了均衡化映射中固有的常规舍入外，不需要指定单位或进行有效数字舍入。", "solution": "该问题要求根据提供的来自遥感图像子集的稀疏直方图，为特定输入DN计算均衡化的输出数字数（DN）。该过程涉及直方图均衡化，这是图像处理中用于对比度增强的一项标准技术。\n\n首先，我们必须从基本定义出发，通过定义直方图均衡化的组成部分来将问题形式化。\n\n设图像中存在的DN水平集合为 $\\{r_j\\}$，其中 $j$ 是不同且有序水平的索引。设 $n(r_j)$ 为每个水平 $r_j$ 的像素数（像素计数）。图像被描述为8位，因此完整动态范围是 $L=256$ 个水平，从 $0$ 到 $255$。问题指定输出动态范围为 $L' = 256$ 个水平，对应于输出范围 $[0, 255]$。\n\n图像子集中的总像素数 $N$ 是所有像素数的总和：\n$$N = \\sum_{j} n(r_j)$$\n\n非零DN分箱的提供数据如下：\n- $r_1 = 12$， $n(r_1) = 184$\n- $r_2 = 35$， $n(r_2) = 792$\n- $r_3 = 87$， $n(r_3) = 115$\n- $r_4 = 123$， $n(r_4) = 58$\n- $r_5 = 156$， $n(r_5) = 1610$\n- $r_6 = 201$， $n(r_6) = 927$\n- $r_7 = 245$， $n(r_7) = 1214$\n\n首先，我们计算总像素数 $N$：\n$$N = 184 + 792 + 115 + 58 + 1610 + 927 + 1214 = 4900$$\n\n下一步，按要求，是计算累积计数。对于给定的DN水平 $r_k$ 的累积计数，记为 $C(r_k)$，是所有小于或等于 $r_k$ 的水平的像素数之和。\n$$C(r_k) = \\sum_{j: r_j \\le r_k} n(r_j)$$\n\n我们按升序为每个存在的DN水平计算累积计数：\n- 对于 $r_1=12$：$C(12) = n(12) = 184$\n- 对于 $r_2=35$：$C(35) = n(12) + n(35) = 184 + 792 = 976$\n- 对于 $r_3=87$：$C(87) = C(35) + n(87) = 976 + 115 = 1091$\n- 对于 $r_4=123$：$C(123) = C(87) + n(123) = 1091 + 58 = 1149$\n- 对于 $r_5=156$：$C(156) = C(123) + n(156) = 1149 + 1610 = 2759$\n- 对于 $r_6=201$：$C(201) = C(156) + n(201) = 2759 + 927 = 3686$\n- 对于 $r_7=245$：$C(245) = C(201) + n(245) = 3686 + 1214 = 4900$\n\n最高DN水平的累积计数等于总像素数 $N$，这可以作为一个一致性检查。\n\n直方图均衡化的原理是应用一个单调映射 $T(r)$，将输入像素水平 $r$ 转换为输出水平 $s$，使得输出水平的直方图尽可能平坦（均匀）。对于离散水平，这个变换是使用归一化累积分布函数（CDF）定义的。在水平 $r_k$ 处的CDF由 $C(r_k)/N$ 给出。映射函数将此CDF缩放到新的动态范围 $[0, L'-1]$。\n\n因此，离散均衡化映射为：\n$$s_k = T(r_k) = \\text{round}\\left( (L' - 1) \\times \\frac{C(r_k)}{N} \\right)$$\n其中 `round` 表示四舍五入到最近的整数。\n\n给定 $L' = 256$，最大输出水平为 $L'-1 = 255$。总像素数为 $N=4900$。该变换变为：\n$$s_k = \\text{round}\\left( 255 \\times \\frac{C(r_k)}{4900} \\right)$$\n\n问题要求计算DN=201处分箱的均衡化输出水平。我们使用输入水平 $r_k = 201$。根据我们之前的计算，该水平的累积计数为 $C(201) = 3686$。\n\n将这些值代入变换函数：\n$$s_{201} = \\text{round}\\left( 255 \\times \\frac{3686}{4900} \\right)$$\n\n我们进行计算：\n$$s_{201} = \\text{round}\\left( 255 \\times 0.75224489... \\right)$$\n$$s_{201} = \\text{round}\\left( 191.82244897... \\right)$$\n\n应用常规的四舍五入到最近整数，我们得到：\n$$s_{201} = 192$$\n\n因此，经过直方图均衡化后，输入DN水平201被映射到输出DN水平192。", "answer": "$$\\boxed{192}$$", "id": "3802113"}, {"introduction": "标准的直方图均衡化虽然强大，但有时会过度增强图像中的噪声或产生条带效应等伪影。本练习将带你深入探究这些问题的根源，引入变换函数的“斜率”作为局部对比度增益的度量。你将通过编程实现一种更高级的、受约束的均衡化方法[@problem_id:4889993]，学会如何主动控制和改善图像增强的效果。", "problem": "您的任务是评估和减轻医学图像中因直方图对比度增强而产生的伪影。请完全在离散强度域中进行操作，其中灰度图像具有 $L$ 个均匀间隔的灰度级，索引为 $k \\in \\{0,1,\\dots,L-1\\}$。令 $h(k)$ 表示灰度级 $k$ 处的直方图计数，而 $p(k) = h(k)/\\sum_{j=0}^{L-1} h(j)$ 表示归一化概率质量函数。对比度增强映射 $T(k)$ 是一个单调变换，它将输入灰度级 $k$ 映射到输出灰度级 $T(k) \\in [0,L-1]$。定义映射的离散斜率 $g(k)$ 为：当 $k \\geq 1$ 时，$g(k) = T(k) - T(k-1)$；当 $k=0$ 时，$g(0) = T(0)$。在连续极限下，输入 $p_x(x)$ 和输出 $p_y(y)$ 的概率密度遵循守恒关系 $p_x(x)\\,dx = p_y(y)\\,dy$。当 $p_y(y)$ 在 $[0,L-1]$ 上均匀分布时，单调映射 $y=T(x)$ 必须满足 $dy/dx = (L-1)\\,p_x(x)$。在离散情况下，类似的关系是：试图使输出分布均匀化的均衡变换，其斜率 $g(k)$ 与 $p(k)$ 成正比。当 $T(k)$ 由 $p(k)$ 的累积和构建时，可得出 $g(k) \\approx (L-1)\\,p(k)$。\n\n均衡化有两个常见的伪影：\n- 过度增强：由于局部增益过大导致的局部噪声放大，当斜率 $g(k)$ 在窄而高概率的峰值上很大时观察到。\n- 色带效应（色调分离）：由于斜率接近零导致平滑灰度渐变的丧失，当 $g(k)$ 在概率接近零的范围内非常小时观察到。\n\n您的任务是：\n- 使用映射的斜率 $g(k)$ 作为局部增益，从第一性原理出发识别过度增强和色带效应。\n- 提出并实现一种对映射导数（斜率）的正则化方法，通过将斜率限制在 $a_{\\min}$ 和 $a_{\\max}$ 之间，并重新分配概率以保持归一化，从而限制局部增益，同时保持概率质量守恒。\n\n使用以下基本依据：\n- 归一化直方图 $p(k)$ 满足 $\\sum_{k=0}^{L-1} p(k) = 1$。\n- 均衡化映射 $T(k)$ 是单调的，并且旨在获得均匀的输出分布，因此其离散斜率满足 $g(k) \\approx (L-1)\\,p(k)$。\n- 概率守恒要求对 $p(k)$ 的任何修改都必须保持 $\\sum_{k=0}^{L-1} p(k) = 1$。\n\n按如下方式设计正则化：\n- 选择斜率边界 $a_{\\min} > 0$ 和 $a_{\\max} > a_{\\min}$。\n- 将斜率边界转换为概率边界 $p_{\\min} = a_{\\min}/(L-1)$ 和 $p_{\\max} = a_{\\max}/(L-1)$。\n- 通过以下步骤构建正则化的 $p_{\\text{reg}}(k)$：将任何高于 $p_{\\max}$ 的 $p(k)$ 限制在 $p_{\\max}$（累积超出的质量），并尝试使用可用的超出质量将任何低于 $p_{\\min}$ 的 $p(k)$ 提升至 $p_{\\min}$。如果超出质量大于总亏空，则按需比例填充亏空，并将任何剩余的超出质量均匀地重新分配到所有区间中。如果超出质量小于总亏空，则使用所有可用的超出质量按需比例填充亏空；任何剩余的亏空将不被填充。最后，重新归一化以确保 $\\sum_{k=0}^{L-1} p_{\\text{reg}}(k) = 1$。\n- 通过对缩放到 $[0,L-1]$ 区间的 $p_{\\text{reg}}(k)$ 进行累积求和，形成正则化映射 $T_{\\text{reg}}(k)$，并定义其斜率 $g_{\\text{reg}}(k) \\approx (L-1)\\,p_{\\text{reg}}(k)$。\n\n基于斜率定义量化过度增强和色带效应的伪影度量标准：\n- 对于一个斜率为 $g(k)$ 的映射，其过度增强严重性是斜率超过阈值 $s_{\\text{thr}}$ 的区间所占的比例，即 $S_{\\text{over}} = \\frac{1}{L}\\sum_{k=0}^{L-1} \\mathbf{1}\\{g(k) > s_{\\text{thr}}\\}$，以小数表示。\n- 对于一个斜率为 $g(k)$ 的映射，其色带效应严重性是斜率低于阈值 $s_{\\text{band}}$ 的连续区间的最大游程长度，即 $S_{\\text{band}} = \\max \\{ \\text{长度为连续索引 } k \\text{ 且满足 } g(k)  s_{\\text{band}} \\text{ 的区间} \\}$，以整数表示。\n\n为三个合成测试直方图实现该流程，其中灰度级为 $L=256$，总计数为 $N=100000$：\n- 测试 1（双峰高斯混合）：$p(k) \\propto w_1 \\exp\\!\\left(-(k-m_1)^2/(2\\sigma_1^2)\\right) + w_2 \\exp\\!\\left(-(k-m_2)^2/(2\\sigma_2^2)\\right)$，其中 $w_1=0.6$，$w_2=0.4$，$m_1=64$，$m_2=192$，$\\sigma_1=10$，$\\sigma_2=10$。\n- 测试 2（尖峰加均匀背景）：$p(k) \\propto w_s \\exp\\!\\left(-(k-m_s)^2/(2\\sigma_s^2)\\right) + w_u$，其中 $w_s=0.8$，$w_u=0.2$，$m_s=128$，$\\sigma_s=3$。\n- 测试 3（带波纹的近均匀分布）：$p(k) \\propto 1 + \\alpha \\sin\\!\\left(2\\pi k / P\\right)$，其中 $\\alpha=0.1$，$P=64$，裁剪为非负值。\n\n对于所有测试，使用斜率边界 $a_{\\min}=0.4$ 和 $a_{\\max}=2.0$，以及伪影阈值：过度增强为 $s_{\\text{thr}}=2.0$，色带效应为 $s_{\\text{band}}=0.2$。\n\n对于每个测试直方图：\n- 构建经典均衡化斜率 $g(k) \\approx (L-1)\\,p(k)$ 并计算 $S_{\\text{over}}$ 和 $S_{\\text{band}}$。\n- 通过上述有界斜率程序构建正则化斜率 $g_{\\text{reg}}(k) \\approx (L-1)\\,p_{\\text{reg}}(k)$ 并再次计算 $S_{\\text{over}}$ 和 $S_{\\text{band}}$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，顺序为 $[S_{\\text{over}}^{(1)},S_{\\text{band}}^{(1)},S_{\\text{over,reg}}^{(1)},S_{\\text{band,reg}}^{(1)},S_{\\text{over}}^{(2)},S_{\\text{band}}^{(2)},S_{\\text{over,reg}}^{(2)},S_{\\text{band,reg}}^{(2)},S_{\\text{over}}^{(3)},S_{\\text{band}}^{(3)},S_{\\text{over,reg}}^{(3)},S_{\\text{band,reg}}^{(3)}]$，其中上标表示测试索引。所有伪影严重性必须以指定的基本类型表示：小数表示比例，整数表示游程长度。", "solution": "该问题要求分析和减轻基于直方图的对比度增强中的伪影。这将通过为图像灰度级的概率质量函数 $p(k)$ 设计并实现一种正则化程序，并使用指定的伪影度量标准来量化其效果来完成。整个框架建立在输入灰度级 $k \\in \\{0, 1, \\dots, L-1\\}$ 的离散概率质量函数 $p(k)$ 与对比度增强变换的局部增益之间的基本关系之上。\n\n离散对比度增强映射 $T(k)$ 将输入灰度级 $k$ 转换为输出灰度级。对于旨在获得均匀输出分布的直方图均衡化，此映射由输入概率的累积分布函数（CDF）构建：\n$$\nT(k) = (L-1) \\sum_{j=0}^{k} p(j)\n$$\n该变换的局部增益（或斜率）由其离散导数给出，$k \\geq 1$ 时为 $g(k) = T(k) - T(k-1)$，$k=0$ 时为 $g(0) = T(0)$。根据 $T(k)$ 的定义，我们得出直接关系：\n$$\ng(k) \\approx (L-1) p(k)\n$$\n这个方程是问题的核心。它确立了灰度级 $k$ 处的局部对比度增益 $g(k)$ 与该灰度级在图像中出现的概率 $p(k)$ 成正比。\n\n由 $g(k)$ 的特性会产生两种常见的伪影：\n1.  **过度增强**：如果直方图有一个窄而高振幅的峰，相应的 $p(k)$ 会很大。这会导致一个很大的斜率 $g(k)$，它将小范围的输入灰度级过度拉伸到大范围的输出灰度级上。这会放大噪声并产生不自然的外观。\n2.  **色带效应（色调分离）**：如果直方图的某些区域 $p(k)$ 接近于零（即，很少有像素具有这些灰度级），相应的斜率 $g(k)$ 也会接近于零。这意味着大范围的不同输入灰度级被映射到相同或相近的输出灰度级，导致平滑色调渐变的丧失，并在图像中出现“条带”。\n\n任务是通过控制其斜率 $g(k)$ 来正则化变换。鉴于比例关系 $g(k) \\approx (L-1) p(k)$，这等同于约束概率质量函数 $p(k)$ 本身。正则化过程旨在将斜率限制在最小值 $a_{\\min}$ 和最大值 $a_{\\max}$ 之间，这又可转化为将概率值限制在 $p_{\\min} = a_{\\min}/(L-1)$ 和 $p_{\\max} = a_{\\max}/(L-1)$ 之间。这必须在遵守概率论基本约束 $\\sum_{k=0}^{L-1} p(k) = 1$ 的前提下完成。\n\n从初始分布 $p(k)$ 推导正则化概率分布 $p_{\\text{reg}}(k)$ 的指定正则化算法如下：\n\n1.  **上限限制与超出质量计算**：任何超过上界 $p_{\\max}$ 的概率 $p(k)$ 都被裁剪至 $p_{\\max}$。移除的总概率质量（称为“超出质量”）被累积起来。此步骤直接限制了最大局部增益。设这个经过上限限制的分布为 $p'(k)$。现在 $p'(k)$ 的总质量小于 1。\n    $$\n    \\text{excess\\_mass} = \\sum_{k \\text{ s.t. } p(k)  p_{\\max}} (p(k) - p_{\\max})\n    $$\n\n2.  **亏空计算**：该算法识别出所有概率 $p'(k)$ 低于下界 $p_{\\min}$ 的区间。“总亏空”是把所有这些区间提升到 $p_{\\min}$ 水平所需的总概率质量。\n    $$\n    \\text{total\\_deficit} = \\sum_{k \\text{ s.t. } p'(k)  p_{\\min}} (p_{\\min} - p'(k))\n    $$\n\n3.  **质量重新分配**：累积的超出质量用于填补亏空。\n    - 如果超出质量足以填补所有亏空（即 $\\text{excess\\_mass} \\ge \\text{total\\_deficit}$），则每个亏空区间都被提升至 $p_{\\min}$。任何剩余的“残余超出”质量（$\\text{excess\\_mass} - \\text{total\\_deficit}$）随后被均匀分配到所有 $L$ 个区间中。这确保了在防止任何区域增益过低的同时，不会有概率质量损失。\n    - 如果超出质量不足（$\\text{excess\\_mass}  \\text{total\\_deficit}$），它将根据各个亏空区间的需求按比例分配。亏空越大的区间将获得可用超出质量中成比例的更大部分。\n\n4.  **重新归一化**：作为最后一步，通过除以其总和来对所得分布 $p_{\\text{reg}}(k)$ 进行重新归一化。这可以校正重新分配过程中任何微小的浮点误差，并严格执行条件 $\\sum_{k=0}^{L-1} p_{\\text{reg}}(k) = 1$。正则化后的斜率则为 $g_{\\text{reg}}(k) \\approx (L-1)p_{\\text{reg}}(k)$。\n\n为了量化此程序的有效性，我们使用两种基于斜率 $g(k)$ 的伪影度量标准：\n-   **过度增强严重性 ($S_{\\text{over}}$)**：斜率超过阈值 $s_{\\text{thr}}$ 的灰度级所占的比例。这衡量了具有过大对比度增益区域的范围。\n    $$\n    S_{\\text{over}} = \\frac{1}{L}\\sum_{k=0}^{L-1} \\mathbf{1}\\{g(k)  s_{\\text{thr}}\\}\n    $$\n-   **色带效应严重性 ($S_{\\text{band}}$)**：斜率低于阈值 $s_{\\text{band}}$ 的连续灰度级的最大数量。这捕捉了最坏情况下的色调细节损失。\n    $$\n    S_{\\text{band}} = \\max \\{ \\text{长度为连续索引 } k \\text{ 且满足 } g(k)  s_{\\text{band}} \\text{ 的区间} \\}\n    $$\n\n下面的实现将把这整个流程应用于三个合成测试直方图，计算经典均衡化斜率和正则化均衡化斜率的伪影严重性。使用的参数为 $L=256$，$a_{\\min}=0.4$，$a_{\\max}=2.0$，$s_{\\text{thr}}=2.0$ 和 $s_{\\text{band}}=0.2$。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the histogram regularization analysis for all test cases.\n    \"\"\"\n    L = 256\n    a_min = 0.4\n    a_max = 2.0\n    s_thr = 2.0\n    s_band = 0.2\n\n    test_cases = [\n        {\n            \"type\": \"bimodal_gaussian\",\n            \"params\": {\"w1\": 0.6, \"w2\": 0.4, \"m1\": 64, \"m2\": 192, \"s1\": 10, \"s2\": 10}\n        },\n        {\n            \"type\": \"spike_uniform\",\n            \"params\": {\"ws\": 0.8, \"wu\": 0.2, \"ms\": 128, \"ss\": 3}\n        },\n        {\n            \"type\": \"sine_ripple\",\n            \"params\": {\"alpha\": 0.1, \"P\": 64}\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        p = generate_pmf(case[\"type\"], case[\"params\"], L)\n\n        # 1. Classical (unregularized) analysis\n        g = (L - 1) * p\n        s_over, s_band_val = calculate_artifacts(g, s_thr, s_band, L)\n\n        # 2. Regularized analysis\n        p_reg = regularize_pmf(p, L, a_min, a_max)\n        g_reg = (L - 1) * p_reg\n        s_over_reg, s_band_reg = calculate_artifacts(g_reg, s_thr, s_band, L)\n\n        results.extend([s_over, s_band_val, s_over_reg, s_band_reg])\n\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef generate_pmf(type, params, L):\n    \"\"\"\n    Generates a normalized probability mass function for a given test case.\n    \"\"\"\n    k = np.arange(L)\n    p_unnorm = np.zeros(L, dtype=np.float64)\n\n    if type == \"bimodal_gaussian\":\n        p = params\n        term1 = p[\"w1\"] * np.exp(-(k - p[\"m1\"])**2 / (2 * p[\"s1\"]**2))\n        term2 = p[\"w2\"] * np.exp(-(k - p[\"m2\"])**2 / (2 * p[\"s2\"]**2))\n        p_unnorm = term1 + term2\n    elif type == \"spike_uniform\":\n        p = params\n        term_gauss = p[\"ws\"] * np.exp(-(k - p[\"ms\"])**2 / (2 * p[\"ss\"]**2))\n        term_uni = p[\"wu\"]\n        p_unnorm = term_gauss + term_uni\n    elif type == \"sine_ripple\":\n        p = params\n        p_unnorm = 1 + p[\"alpha\"] * np.sin(2 * np.pi * k / p[\"P\"])\n        p_unnorm = np.clip(p_unnorm, 0, None)\n\n    return p_unnorm / np.sum(p_unnorm)\n\ndef calculate_artifacts(g, s_thr, s_band_threshold, L):\n    \"\"\"\n    Calculates over-enhancement and banding severity metrics.\n    \"\"\"\n    # Over-enhancement severity\n    s_over = np.sum(g > s_thr) / L\n\n    # Banding severity\n    max_len = 0\n    current_len = 0\n    is_banding = g  s_band_threshold\n    for b in is_banding:\n        if b:\n            current_len += 1\n        else:\n            max_len = max(max_len, current_len)\n            current_len = 0\n    max_len = max(max_len, current_len)\n    return s_over, max_len\n\ndef regularize_pmf(p, L, a_min, a_max):\n    \"\"\"\n    Applies the specified slope/probability regularization algorithm.\n    \"\"\"\n    p_min = a_min / (L - 1)\n    p_max = a_max / (L - 1)\n    \n    p_reg = p.copy()\n\n    # 1. Cap probabilities above p_max and calculate total excess mass\n    excess_indices = np.where(p_reg > p_max)[0]\n    if excess_indices.size > 0:\n        excess_mass = np.sum(p_reg[excess_indices] - p_max)\n        p_reg[excess_indices] = p_max\n    else:\n        excess_mass = 0.0\n\n    # 2. Calculate total deficit required to reach p_min\n    deficit_indices = np.where(p_reg  p_min)[0]\n    if deficit_indices.size > 0:\n        deficits = p_min - p_reg[deficit_indices]\n        total_deficit = np.sum(deficits)\n    else:\n        total_deficit = 0.0\n        deficits = np.array([])\n\n    # 3. Redistribute excess mass to satisfy deficits\n    if abs(total_deficit)  1e-12:  # Treat as zero\n        if excess_mass > 0:\n            p_reg += excess_mass / L\n    else:\n        if excess_mass >= total_deficit:\n            # Fill all deficits completely\n            p_reg[deficit_indices] = p_min\n            # Distribute residual excess uniformly\n            residual_excess = excess_mass - total_deficit\n            p_reg += residual_excess / L\n        else:  # excess_mass  total_deficit\n            # Fill deficits proportionally\n            if total_deficit > 0:\n                p_reg[deficit_indices] += excess_mass * (deficits / total_deficit)\n\n    # 4. Final renormalization to guarantee sum is 1\n    p_reg /= np.sum(p_reg)\n    return p_reg\n\n\nif __name__ == \"__main__\":\n    solve()\n\n```", "id": "4889993"}, {"introduction": "理论上，直方图均衡化旨在产生一个完全均匀的输出直方图，但这在数字实现中只是一个理想。本练习将探讨一个关键的实践细节：当我们将连续的变换映射转换为离散的整数查找表时，不同的取整规则会如何影响最终结果。通过量化比较这些影响[@problem_id:4889979]，你将更深刻地理解理论与实际应用之间的差距。", "problem": "给定一个适用于计算机断层扫描 (CT) 的离散灰度图像模型，其中每个像素被赋予一个来自集合 $\\{0,1,2,\\ldots,L-1\\}$ 的整数强度级别，其中 $L=4096$。令 $h[r]$ 表示输入强度 $r$ 处的直方图计数（像素数量），令 $N=\\sum_{r=0}^{L-1} h[r]$ 表示总像素数。考虑累积分布 $c[r]=\\sum_{k=0}^{r} h[k]$、归一化累积分数 $F[r]=c[r]/N$ 以及单调映射 $s[r]=(L-1)\\,F[r]$，该映射将每个输入级别 $r$ 映射到一个实值目标强度 $s[r]\\in[0,L-1]$。通过将每个 $s[r]$ 舍入为一个整数 $T[r]\\in\\{0,1,\\ldots,L-1\\}$ 来获得一个整数查找表；该表 $T$ 将每个输入级别 $r$ 映射到一个输出级别 $T[r]$。将此表应用于图像会产生一个输出直方图 $H_{\\text{out}}[j]=\\sum_{r: T[r]=j} h[r]$，其中 $j\\in\\{0,1,\\ldots,L-1\\}$。理想的均衡化直方图是均匀的，每个输出级别的目标条柱占有率为 $N/L$。\n\n从离散概率质量函数和累积分布函数的基本定义出发，通过以下步骤实现直方图均衡化映射：\n- 从 $h[r]$ 和 $N$ 计算 $F[r]$ 和 $s[r]$，\n- 通过对 $s[r]$ 应用以下舍入规则来构建整数查找表 $T[r]$：\n  1. 向下取整 (floor)：$T_{\\mathrm{floor}}[r]=\\lfloor s[r]\\rfloor$，\n  2. 向上取整 (ceil)：$T_{\\mathrm{ceil}}[r]=\\lceil s[r]\\rceil$（如果需要，则裁剪至 $L-1$），\n  3. 半值向上取整（取最近整数，平局时向上舍入）：$T_{\\mathrm{half\\_up}}[r]=\\lfloor s[r]+0.5\\rfloor$（如果需要，则裁剪至 $L-1$），\n  4. 半值取偶舍入（银行家舍入）：$T_{\\mathrm{half\\_even}}[r]$ 等于与 $s[r]$ 最接近的整数，小数部分恰好为 $0.5$ 的平局情况则舍入到最近的偶数整数，如果需要，则裁剪至 $L-1$。\n\n对于每种舍入规则，通过与理想均匀分布的归一化 $\\ell_1$ 偏差来量化所得输出直方图 $H_{\\text{out}}$ 的均匀性，\n$$\nE = \\frac{1}{N}\\sum_{j=0}^{L-1} \\left| H_{\\text{out}}[j] - \\frac{N}{L} \\right|.\n$$\n此 $E$ 是一个在 $[0,\\infty)$ 内的实数，其中 $E=0$ 表示完全均匀。\n\n实现一个单一、完整的程序，该程序：\n- 为每种舍入规则构建整数查找表和输出直方图，\n- 计算并报告上面定义的归一化 $\\ell_1$ 偏差 $E$。\n\n使用以下直方图测试套件，每个直方图都通过在域 $\\{0,1,2,\\ldots,L-1\\}$ (其中 $L=4096$) 上的简单确定性构造来指定：\n1. 均匀情况（理想路径）：对于所有 $r\\in\\{0,1,\\ldots,L-1\\}$，设置 $h[r]=16$。此时 $N=16L$。\n2. 聚集高强度情况（强调输出空条柱的边界条件）：选择 $r_0=3000$ 和 $w=32$；对于 $r\\in\\{r_0,r_0+1,\\ldots,r_0+w-1\\}$，设置 $h[r]=50000$，对于所有其他 $r$，设置 $h[r]=0$。此时 $N=50000\\cdot w$。\n3. 稀疏周期情况（具有广泛分离的填充条柱的边缘情况）：对于所有 $r$，如果 $r \\equiv 0 \\pmod{64}$，则设置 $h[r]=64$，否则设置 $h[r]=0$。此时 $N=4096$，因为有 $L/64$ 个填充条柱，每个条柱的计数为 $64$。\n\n对于上述三个直方图中的每一个，按 floor、ceil、round-half-up、round-half-to-even 的顺序计算四个误差值 $E$。您的程序应生成单行输出，其中包含一个以逗号分隔的列表的列表形式的结果，每个内部列表按指定顺序包含一个直方图的四个十进制数。例如，最终格式必须为\n$[[E_{1,\\mathrm{floor}},E_{1,\\mathrm{ceil}},E_{1,\\mathrm{half\\_up}},E_{1,\\mathrm{half\\_even}}],[E_{2,\\mathrm{floor}},E_{2,\\mathrm{ceil}},E_{2,\\mathrm{half\\_up}},E_{2,\\mathrm{half\\_even}}],[E_{3,\\mathrm{floor}},E_{3,\\mathrm{ceil}},E_{3,\\mathrm{half\\_up}},E_{3,\\mathrm{half\\_even}}]]$。\n不涉及物理单位，角度也不适用。程序必须确定性地执行，无需外部输入，并且必须遵循所描述的精确输出格式。", "solution": "在尝试解决方案之前，该问题经过了严格的验证过程。\n\n### 步骤 1：提取已知信息\n- **强度级别**：一个离散整数集合 $\\{0, 1, 2, \\ldots, L-1\\}$，其中级别数为 $L=4096$。\n- **输入直方图**：$h[r]$ 是输入强度级别 $r \\in \\{0, 1, \\ldots, L-1\\}$ 处的像素数。\n- **总像素数**：$N = \\sum_{r=0}^{L-1} h[r]$。\n- **累积直方图**：$c[r] = \\sum_{k=0}^{r} h[k]$。\n- **归一化累积分数 (CDF)**：$F[r] = c[r]/N$。\n- **连续映射函数**：$s[r] = (L-1) F[r]$，其中 $s[r] \\in [0, L-1]$。\n- **整数查找表**：$T[r]$ 是通过对 $s[r]$ 进行舍入得到的整数值表。\n- **舍入规则**：\n  1.  向下取整：$T_{\\mathrm{floor}}[r] = \\lfloor s[r] \\rfloor$。\n  2.  向上取整：$T_{\\mathrm{ceil}}[r] = \\lceil s[r] \\rceil$，裁剪至 $L-1$。\n  3.  半值向上取整：$T_{\\mathrm{half\\_up}}[r] = \\lfloor s[r] + 0.5 \\rfloor$，裁剪至 $L-1$。\n  4.  半值取偶舍入（银行家舍入）：$T_{\\mathrm{half\\_even}}[r]$ 舍入到最近的整数，对于平局情况（$*.5$）则舍入到最近的偶数整数，裁剪至 $L-1$。\n- **输出直方图**：$H_{\\text{out}}[j] = \\sum_{r: T[r]=j} h[r]$，其中 $j \\in \\{0, 1, \\ldots, L-1\\}$。\n- **理想均匀直方图**：每个输出级别的目标条柱占有率为 $N/L$。\n- **均匀性误差度量**：归一化 $\\ell_1$ 偏差 $E = \\frac{1}{N}\\sum_{j=0}^{L-1} \\left| H_{\\text{out}}[j] - \\frac{N}{L} \\right|$。\n- **测试用例**：\n  1.  **均匀**：对于所有 $r \\in \\{0, \\ldots, L-1\\}$，$h[r] = 16$。\n  2.  **聚集**：对于 $r \\in \\{3000, \\ldots, 3031\\}$（宽度为 $w=32$ 的窗口），$h[r] = 50000$，否则 $h[r]=0$。\n  3.  **稀疏周期**：如果 $r \\equiv 0 \\pmod{64}$，$h[r] = 64$，否则 $h[r]=0$。\n\n### 步骤 2：使用提取的已知信息进行验证\n根据既定标准对问题进行评估：\n- **科学性**：该问题植根于数字图像处理的基本原理，特别是直方图均衡化。概率质量函数、累积分布函数和量化的概念在该领域是标准化的。所有定义和公式都是正确和标准的。\n- **适定性**：问题定义清晰。输入（直方图）、常量（$L$）、变换（舍入规则）和期望的输出（误差度量 $E$）都得到了明确的规定。每个测试用例都存在唯一且有意义的解。\n- **客观性**：语言精确且数学化，没有主观性或歧义。\n- **完整性**：问题是自包含的。提供了实现所需的所有必要数据和定义。\n- **一致性和可行性**：给定的值和构造是一致的，并且在计算上是可行的。所涉及的操作是标准的数值计算。\n\n### 步骤 3：结论和行动\n该问题是**有效的**。这是一个在医学图像处理领域定义明确的计算问题，适合进行算法实现和分析。可以继续进行求解过程。\n\n### 解决方案\n该问题要求实现和评估离散直方图均衡化。其核心原理是变换像素强度值，使得输出图像的直方图尽可能均匀。这个过程可以增强图像的全局对比度。\n\n其基础概念是像素强度的概率分布。对于一个有 $L$ 个级别的离散灰度图像，归一化直方图 $p[r] = h[r]/N$ 可作为强度级别的经验概率质量函数 (PMF)。累积分布函数 (CDF) 则由 $F[r] = \\sum_{k=0}^{r} p[k] = c[r]/N$ 给出。\n\n理想的直方图均衡化变换将输入强度 $r$ 映射到与 $r$ 处的 CDF 值成比例的输出强度 $s$。该映射定义为 $s[r] = (L-1)F[r]$。在连续域中，此变换保证能产生一个完全均匀的输出分布。然而，在数字图像的离散域中，输出值 $s[r]$ 是实数，必须被量化到可用的整数级别 $\\{0, 1, \\ldots, L-1\\}$。这个涉及舍入的量化步骤会引入与完美均匀性的偏差。本问题要求我们针对四种不同的舍入规则来量化这种偏差。\n\n对于每个指定的输入直方图，算法按以下步骤进行：\n\n1.  **构建输入直方图**：根据三个测试用例中每个用例的规则，构建大小为 $L=4096$ 的输入直方图 $h[r]$ 数组。\n\n2.  **计算基于 CDF 的映射**：\n    - 通过对 $h[r]$ 的所有元素求和来计算总像素数 $N$：$N = \\sum_{r=0}^{L-1} h[r]$。\n    - 使用对 $h[r]$ 的累积求和操作计算累积直方图 $c[r]$：$c[r] = \\sum_{k=0}^{r} h[k]$。\n    - 通过将 $c[r]$ 的每个元素除以 $N$ 来计算归一化累积分数 $F[r]$。这必须是浮点除法以保持精度。\n    - 计算实值目标强度映射 $s[r]$，公式为 $s[r] = (L-1)F[r]$。\n\n3.  **构建整数查找表**：通过对 $s[r]$ 数组应用指定的舍入规则，生成四个整数值查找表 $T[r]$。数组被裁剪到有效范围 $[0, L-1]$。\n    - $T_{\\mathrm{floor}}[r] = \\lfloor s[r] \\rfloor$。\n    - $T_{\\mathrm{ceil}}[r] = \\lceil s[r] \\rceil$。\n    - $T_{\\mathrm{half\\_up}}[r] = \\lfloor s[r] + 0.5 \\rfloor$。\n    - $T_{\\mathrm{half\\_even}}[r]$ 使用一个函数实现，该函数舍入到最近的整数，对于恰好在半整数边界（例如，$2.5$，$3.5$）上的值，则舍入到最近的偶数整数。\n\n4.  **计算输出直方图**：对于每个查找表 $T$，计算输出直方图 $H_{\\text{out}}$。一种高效的方法是使用条柱计数算法。对于每个输出级别 $j \\in \\{0, \\ldots, L-1\\}$，值 $H_{\\text{out}}[j]$ 是所有映射到 $j$（即 $T[r]=j$）的输入级别 $r$ 的输入计数 $h[r]$ 之和。这正是 $H_{\\text{out}}[j] = \\sum_{r : T[r]=j} h[r]$。\n\n5.  **计算均匀性误差**：每个 $H_{\\text{out}}$ 的均匀性通过与理想均匀分布的归一化 $\\ell_1$ 偏差来量化。每个条柱的理想计数是 $N/L$。误差 $E$ 计算如下：\n    $$\n    E = \\frac{1}{N}\\sum_{j=0}^{L-1} \\left| H_{\\text{out}}[j] - \\frac{N}{L} \\right|\n    $$\n    为四种舍入规则中的每一种计算该值。\n\n对三个测试用例重复整个过程，并以指定格式报告所得的十二个误差值。计算使用 `numpy` 库以进行高效的数组操作。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements histogram equalization with four different rounding rules and\n    calculates the normalized L1 deviation from a uniform distribution for\n    three test cases.\n    \"\"\"\n\n    def calculate_errors_for_histogram(h: np.ndarray, L: int) -> list[float]:\n        \"\"\"\n        Calculates the uniformity error E for a given histogram h using four rounding rules.\n\n        Args:\n            h: The input histogram as a numpy array of size L.\n            L: The number of intensity levels.\n\n        Returns:\n            A list of four float values representing the error E for floor, ceil,\n            round-half-up, and round-half-to-even rounding, respectively.\n        \"\"\"\n        # Ensure h is of an integer type that can hold large counts\n        h = h.astype(np.int64)\n        \n        N = np.sum(h)\n        if N == 0:\n            return [0.0, 0.0, 0.0, 0.0]\n\n        # Use float64 for precision in CDF and s\n        c = np.cumsum(h, dtype=np.float64)\n        F = c / N\n        s = (L - 1) * F\n\n        # 1. Floor rounding\n        T_floor = np.floor(s).astype(np.int64)\n\n        # 2. Ceil rounding (with clipping)\n        T_ceil = np.ceil(s).astype(np.int64)\n        # Clipping is technically only needed if s can exceed L-1, but is good practice.\n        T_ceil = np.clip(T_ceil, 0, L - 1)\n\n        # 3. Round-half-up (with clipping)\n        T_half_up = np.floor(s + 0.5).astype(np.int64)\n        T_half_up = np.clip(T_half_up, 0, L - 1)\n\n        # 4. Round-half-to-even (Banker's rounding) (with clipping)\n        # np.rint implements round-half-to-even.\n        T_half_even = np.rint(s).astype(np.int64)\n        T_half_even = np.clip(T_half_even, 0, L - 1)\n        \n        rounding_tables = [T_floor, T_ceil, T_half_up, T_half_even]\n        \n        errors = []\n        ideal_bin_occupancy = N / L\n\n        for T in rounding_tables:\n            # H_out[j] = sum_{r: T[r]=j} h[r]\n            # np.bincount is highly efficient for this operation.\n            H_out = np.bincount(T, weights=h, minlength=L)\n            \n            # Calculate the normalized L1 deviation E\n            E = (1 / N) * np.sum(np.abs(H_out - ideal_bin_occupancy))\n            errors.append(E)\n            \n        return errors\n\n    # Define constants and test cases from the problem statement.\n    L = 4096\n    \n    # Case 1: Uniform case\n    h1 = np.full(L, 16, dtype=np.int64)\n\n    # Case 2: Clustered high-intensity case\n    h2 = np.zeros(L, dtype=np.int64)\n    r0, w = 3000, 32\n    h2[r0 : r0 + w] = 50000\n\n    # Case 3: Sparse periodic case\n    h3 = np.zeros(L, dtype=np.int64)\n    h3[0::64] = 64\n    \n    test_histograms = [h1, h2, h3]\n    \n    results = []\n    for h in test_histograms:\n        result_for_case = calculate_errors_for_histogram(h, L)\n        results.append(result_for_case)\n\n    # Format the final output string as a list of lists.\n    # e.g., [[val1, val2, ...], [val1, val2, ...]]\n    list_of_lists_str = [f\"[{','.join(map(str, res))}]\" for res in results]\n    final_output_str = f\"[{','.join(list_of_lists_str)}]\"\n\n    print(final_output_str)\n\nsolve()\n```", "id": "4889979"}]}