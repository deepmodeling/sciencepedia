{"hands_on_practices": [{"introduction": "下一代测序（NGS）的工作流程始于文库制备，其中每一步都至关重要。本练习通过一个思想实验，探讨如果省略了DNA片段化这一关键步骤会发生什么 [@problem_id:2304539]。通过分析这一假设性的失误，我们可以更深入地理解短读长测序技术背后的物理和生化限制，特别是桥式扩增过程对DNA片段长度的严格要求。", "problem": "一位研究人员正尝试使用一个流行的、依赖于短读长合成测序法的新一代测序（NGS）平台，对一种新发现的极端微生物细菌的完整基因组进行测序。标准的文库制备方案包括几个关键步骤：首先，将高分子量的基因组脱氧核糖核酸（DNA）片段化成特定大小范围（通常为300-500个碱基对）的较小片段；其次，修复这些片段的末端并添加一个腺嘌呤核苷酸（“A-加尾”）；第三，将称为接头的短的特异性DNA序列连接到片段的两端。然后，这些连接了接头的片段被变性成单链并加载到流动池上。在流动池上，单链片段与互补序列杂交，并经历一个称为桥式扩增的过程，形成密集的克隆簇。随后对每个簇进行测序。\n\n由于实验室的混淆，研究人员使用了一种完全抑制酶促片段化步骤的缓冲液。然而，他们没有意识到这个错误，并继续执行文库制备和测序方案的所有后续步骤。用于文库制备的输入DNA由非常长、完整的细菌染色体链组成，长度达数十万个碱基对。\n\n下列哪项描述了这一疏漏对测序运行最可能产生的主要后果？\n\nA. 测序运行将产生极高的数据产量，因为现在每个簇都将代表基因组中大得多的部分。\nB. 接头连接步骤将失败，因为连接酶无法将接头连接到如此长的DNA分子上，导致没有DNA被加载到流动池上。\nC. 测序运行将因“簇密度过低”错误而失败，产生很少或几乎没有可用的测序数据。\nD. 测序将成功进行，但得到的数据将只包含来自原始线性细菌染色体两个最末端的短读长。\nE. 测序聚合酶将生成长度可变且不可预测的读长，导致碱基识别算法出错。", "solution": "我们分析类Illumina的短读长合成测序法工作流程以及每个文库制备步骤的作用，重点关注簇生成的物理和生化要求。\n\n首先，在标准的文库制备中，片段化将高分子量基因组DNA转化为许多长度在几百个碱基对典型范围内的短片段。将总输入DNA质量表示为 $M$，平均片段长度表示为 $L$，每个碱基对的质量表示为 $m_{bp}$，则不同文库分子的数量可表示为\n$$\nN(L) = \\frac{M}{L m_{bp}}.\n$$\n因此，如果片段化被抑制，DNA保持很长的长度，即 $L_{nf} \\gg L_{f}$，那么\n$$\nN_{nf} = \\frac{M}{L_{nf} m_{bp}} \\ll \\frac{M}{L_{f} m_{bp}} = N_{f}.\n$$\n这会立即减少能够在流动池上作为种子生成簇的分子数量。\n\n其次，接头连接是由连接酶催化的反应，将接头连接到经过修复和A-加尾的末端。这个反应本质上不受DNA长度的阻碍；连接酶可以将接头连接到长DNA分子的末端。因此，认为接头连接仅因模板长度而完全失败的假设是不正确的。\n\n第三，变性后，单链文库分子必须与流动池上的互补寡核苷酸引物杂交并进行桥式扩增。桥式扩增要求一条表面固定的DNA链弯曲，并将其相对端的接头与附近第二个寡核苷酸引物杂交形成一个“桥”，从而使聚合酶能够进行延伸，创建一个互补的、表面固定的拷贝。这个过程的效率很大程度上取决于片段长度。设 $p(L)$ 表示长度为 $L$ 的分子成功进行桥式扩增的概率。根据经验和聚合物物理学的直觉，$p(L)$ 会随着 $L$ 超过推荐的短读长片段大小而迅速下降，因为非常长的分子无法在邻近的寡核苷酸引物之间有效地弯曲和桥接，并且容易产生空间位阻和缠结。因此，当 $L_{nf} \\gg L_{f}$ 时，可以预期\n$$\np(L_{nf}) \\ll p(L_{f}).\n$$\n预期的簇数量与 $N(L) \\cdot p(L)$ 成正比。在片段化被抑制的情况下，这两个因素都向不利的方向崩溃：\n$$\nN(L_{nf})\\,p(L_{nf}) \\ll N(L_{f})\\,p(L_{f}).\n$$\n因此，簇的形成受到严重损害，导致流动池上的簇密度非常低。\n\n评估各个选项：\n- A是错误的：簇的产量不会增加；相反，它会崩溃，因为分子数量和桥式扩增效率都下降了。\n- B是错误的：连接可以在长模板上发生；仅长度本身并不会阻止连接酶将接头连接到末端。\n- C是正确的：由于分子数量急剧减少以及极长模板的桥式扩增效率几乎为零的共同作用，测序运行将因簇密度过低而失败，产生很少或几乎没有可用的测序数据。\n- D是错误的：成功的测序仍然需要簇扩增；仅从染色体末端读取并不是该平台片段化失败的标准结果。\n- E是错误的：读长是由测序化学循环决定的，而不是由模板长度决定的；模板过长会损害簇的形成，而不是导致已形成簇的读长可变。\n\n因此，最可能的主要后果是测序运行因簇密度低而失败。", "answer": "$$\\boxed{C}$$", "id": "2304539"}, {"introduction": "成功制备文库后，下一步是将其加载到测序芯片（flow cell）上。本练习模拟了一个常见的实验室问题：因上样量不当导致的“过度成簇（overclustering）” [@problem_id:2304531]。理解簇密度如何直接影响碱基检出的准确性（Q-score）和有效数据的产出（%PF），是每一位NGS用户进行实验质控和故障排除的基本技能。", "problem": "一个研究团队正在使用Illumina类型的下一代测序（NGS）平台，对一种新的细菌物种进行全基因组测序。这项技术依赖于一个称为“边合成边测序”的过程，该过程在一种名为“流动池”的玻璃载片上进行。在流动池上，单个DNA片段被扩增，形成称为“簇”的独立克隆群体。在每个测序循环中，一个带荧光标记的核苷酸被掺入到每个簇中正在增长的DNA链中，并对整个流动池进行成像。来自特定簇的荧光颜色表明添加了哪个碱基（A、C、G或T）。\n\n测序运行结束后，该团队收到一份质量控制报告。一个关键参数是**簇密度**，单位为千簇/平方毫米（k/mm$^2$）。报告指出簇密度严重过高，这种情况被称为“过簇”，即簇过于密集以至于开始合并。该团队现在必须预测此问题对另外两个主要质量指标的影响：\n\n1.  **平均Phred质量得分（Q-score）**：衡量碱基识别准确性的指标。越高的Q-score表示识别出的碱基是正确的概率越高。例如，Q30对应于碱基识别错误率为千分之一。\n2.  **通过过滤的读段百分比（%PF）**：通过初始质量控制检查的簇的百分比，该检查主要评估最初几个测序循环中的信号纯度和强度。只有通过此过滤的读段才会用于下游分析。\n\n下列关于关键质量指标的结果组合中，哪一个是所述严重过簇现象最直接和必然的后果？\n\nA. 高簇密度，低平均Q-score，低%PF\nB. 高簇密度，高平均Q-score，高%PF\nC. 低簇密度，低平均Q-score，低%PF\nD. 高簇密度，高平均Q-score，低%PF\nE. 低簇密度，高平均Q-score，高%PF", "solution": "Illumina边合成边测序技术在每个循环中为每个簇产生荧光强度，理想情况下，该强度应由单个碱基的信号主导。两个下游指标直接依赖于簇信号的纯度和可分离性。\n\n首先，根据碱基识别错误概率 $p$ 定义Phred质量得分：\n$$\nQ=-10 \\log_{10}(p).\n$$\n严重的过簇现象会导致簇的空间重叠，因此对于给定像素/簇测得的强度会受到相邻簇的污染。这会降低信号纯度，增加碱基识别的模糊性，从而使错误概率从 $p$ 增加到 $p'$（其中 $p'>p$）。应用该定义，\n$Q' = -10 \\log_{10}(p')  -10 \\log_{10}(p) = Q,$\n因此，在严重过簇的情况下，平均Q-score必然会下降。\n\n其次，初始读段过滤器（PF）评估早期循环的信号纯度和强度。过簇现象由于重叠簇的信号混合而降低了纯度，从而导致更多簇未能通过此过滤器。因此，通过过滤的读段比例会下降。\n\n评估选项：\n- 簇密度低的选项与所述的严重过簇现象相矛盾，因此无效。\n- 尽管存在严重过簇，但仍保持高平均Q-score或高%PF的选项与上述直接影响相矛盾（增加的 $p$ 会降低 $Q$，降低的纯度会降低PF）。\n\n因此，必然的结果是高簇密度、低平均Q-score和低%PF，这对应于选项A。", "answer": "$$\\boxed{A}$$", "id": "2304531"}, {"introduction": "测序完成后，我们会得到包含序列及其对应质量得分的原始数据。本练习引导我们解读一个普遍存在于原始数据中的现象：测序读长（read）末端碱基的质量得分系统性下降 [@problem_id:2304540]。理解这一现象背后的核心原理——由于化学反应效率不完美导致的“失相（dephasing）”，对于准确评估测序数据质量和认识该技术的内在局限性至关重要。", "problem": "一位基因组学导论课程的学生正在分析来自一台使用“边合成边测序”(SBS) 原理的仪器进行的第二代测序 (NGS) 实验的原始数据。数据为 FASTQ 文件格式，其中每个 DNA 测序读段都附有相应的 Phred 质量分数 (Q-score) 字符串。越高的 Q-score 表明相应的碱基判读正确的概率越高。该学生在数百万个读段中注意到了一个一致且显著的趋势：每个读段最初 20-30 个碱基的 Q-score 非常高，然后朝着读段末端系统性地、逐渐地降低。\n\n在 SBS 平台上，以下哪个选项为这一观察到的趋势提供了最准确和最根本的解释？\n\nA. 每个步骤的化学反应（核苷酸掺入、终止子切割和荧光基团去除）效率并非百分之百，导致一个簇中正在测序的 DNA 链之间同步性累积丧失（失相）。\nB. 反应中使用的 DNA 聚合酶由于经过多个循环后产生酶疲劳，其效率随着读段长度的增加而逐渐降低，并产生更多错误。\nC. 在测序运行过程中，附着在流通池表面的 DNA 模板分子的物理完整性会降解，导致它们在读段末端断裂。\nD. 用于检测荧光信号的光学成像系统的灵敏度在长时间的测序实验中下降，导致后续循环的信号变弱。\nE. 加载到流通池上的初始 DNA 片段质量参差不齐，碱基判读算法会首先成功测序高质量片段，而将低质量片段留到运行的末尾。", "solution": "题目要求我们确定在 Illumina 等平台上观察到的，由“边合成边测序”(SBS) 产生的读段中 Phred 质量分数逐渐降低的最准确和最根本的原因。关键的观察是，Q-score 在读段开始时很高，并随着循环数的增加而系统性地下降。\n\n将第 $k$ 个循环的 Phred 分数定义为 $Q(k)=-10\\log_{10}(P_{e}(k))$，其中 $P_{e}(k)$ 是第 $k$ 个循环的碱基判读错误概率。观察到的趋势，即 $Q(k)$ 随 $k$ 减小，意味着 $P_{e}(k)$ 随 $k$ 增大。\n\n在采用簇式测序的 SBS 中，每个簇包含许多被同步延伸的相同模板链，而碱基判读是通过测量每个循环中整个簇发出的复合荧光信号来进行的。在一个理想的过程中，簇中的每一条链在每个循环都会掺入恰好一个被正确标记、被终止子阻断的核苷酸，终止子和荧光基团会被完全去除，并且所有链都将保持完美的同步性。实际上，在每个循环中，存在一些虽小但非零的失败模式概率：\n- 每个循环中，一条给定的链有概率 $p$ 未能完成掺入（滞后，或 phasing）。\n- 每个循环中，一条给定的链有概率 $q$ 相对于当前循环有效提前（超前，或 pre-phasing），这是由于不完全的终止子/荧光基团去除或其他导致额外掺入的化学过程。\n\n假设每个循环近似独立，那么在 $k$ 个循环后仍保持完全同相的链的比例可以很好地近似为\n$$\nf_{\\text{in}}(k) \\approx \\left(1 - p - q\\right)^{k}.\n$$\n随着 $k$ 的增加，只要 $p+q0$，$f_{\\text{in}}(k)$ 就会单调衰减。失相的链会贡献背景荧光，这些荧光对应于比预期循环提前或落后一个或多个位置的碱基。因此，在第 $k$ 个循环中可归因于正确碱基的信号大致与 $f_{\\text{in}}(k)$ 成比例下降，而来自失相亚群的背景信号则会累积。净效应是信噪比随 $k$ 的增加而下降，这直接导致 $P_{e}(k)$ 增加，从而使 $Q(k)=-10\\log_{10}(P_{e}(k))$ 随 $k$ 的增加而减小。这种机制——由于不完美的每循环化学反应（核苷酸掺入、终止子切割和荧光基团去除）导致的累积性失相——是造成所观察到趋势的根本性的、平台固有的原因。\n\n我们现在来评估各个选项：\n- 选项 A 正确地指出，掺入、终止子切割和荧光基团去除的效率不完美导致了同步性的累积丧失（失相），这通过 $f_{\\text{in}}(k)\\approx (1-p-q)^{k}$ 和随之而来的 $P_{e}(k)$ 增加，产生了上述的 Q-score 随循环数下降的现象。\n- 选项 B（聚合酶疲劳）不是 SBS 簇成像中的主要驱动因素；对 Q-score 随循环数变化的主要影响是失相而非酶疲劳，并且聚合酶制剂经过优化以在多个循环中保持活性。\n- 选项 C（模板降解）不会以一种能解释平滑的、依赖于循环数的下降的方式，系统性地使所有簇中的模板断裂；与快速的失相动力学相比，表面固定的模板在整个运行过程中是稳定的。\n- 选项 D（光学灵敏度下降）通常不会产生一致的每循环 Q-score 衰减模式，并且现代仪器会校正漂移；此外，光学灵敏度漂移会同样影响所有通道，而不是产生特有的失相特征。\n- 选项 E（首先测序高质量片段）对于 SBS 来说在概念上是不正确的，因为在 SBS 中，所有簇在每个循环中都是并行成像的；在整个运行过程中，不存在一个从高质量到低质量的片段全局排序。\n\n因此，最准确和最根本的解释是选项 A。", "answer": "$$\\boxed{A}$$", "id": "2304540"}]}