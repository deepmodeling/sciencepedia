## 引言
RNA测序（[RNA-seq](@entry_id:140811)）已经成为现代生物学和医学研究中不可或缺的工具，它能以前所未有的分辨率和广度捕捉细胞内动态的转录组景观。这项技术不仅能定量基因的表达水平，还能揭示[可变剪接](@entry_id:142813)、等位基因表达失衡和基因融合等复杂的转录事件。然而，从数以千万计的短测序读段中提取可靠的生物学见解，是一项涉及多步实验选择和复杂生物信息学分析的挑战。本文旨在填补从原始数据到功能解释之间的知识鸿沟，为读者提供一个关于RNA-seq在[医学遗传学](@entry_id:262833)应用的全面指南。

在接下来的内容中，我们将系统性地剖析[RNA-seq](@entry_id:140811)的全过程。第一章“原理与机制”将奠定理论基础，深入探讨从样本制备到数据定量的每一步技术细节及其背后的原理。第二章“应用与交叉学科联系”将展示这些原理如何在真实世界的临床和研究场景中发挥作用，从孟德尔遗传病的诊断到复杂疾病的机制探索。最后，在“动手实践”部分，您将有机会通过解决具体问题，将所学知识付诸实践。通过学习本章内容，您将能够设计严谨的[RNA-seq](@entry_id:140811)实验，批判性地评估数据质量，并准确地解释其在遗传学研究中的结果。

## 原理与机制

本章节将深入探讨RNA测序（RNA-seq）技术的核心原理与关键机制。我们将从实验设计的最初步骤开始，贯穿测[序数](@entry_id:150084)据的产生、处理、定量和[统计建模](@entry_id:272466)，最终触及在医学遗传学中的高级应用。我们的目标是建立一个坚实的理论框架，使读者能够理解[RNA-seq](@entry_id:140811)工作流程中每一步的“做什么”与“为什么”。

### 从[转录组](@entry_id:274025)到文库：实验设计与制备

[RNA-seq](@entry_id:140811)的目标是定量一个样本中所有RNA转录本的丰度。然而，当前的测序技术无法直接对RNA分子进行大规模测序。因此，首要任务是将不稳定的RNA分子群体转化为稳定且可供测序的互补DNA（cDNA）文库。构建一个能够忠实反映原始RNA群体特征的文库，是整个实验成功的基石。

#### RNA选择策略

细胞总RNA中，约80%至90%是[核糖体RNA](@entry_id:149305)（rRNA），而信使RNA（mRNA）等信息丰富的转录本只占一小部分。如果不加选择地对总RNA进行测序，绝大多数测序资源将被浪费在rRNA上。因此，必须采用策略来富集感兴趣的RNA分子。主要有三种策略，其选择取决于样本特性和研究目标 [@problem_id:5088443]。

1.  **Poly(A)选择法 (Poly(A) selection)**：该方法利用了大多数真核生物成熟mRNA分子在3'端都有一条聚腺苷酸尾巴（poly(A) tail）的特性。实验中，带有寡聚胸苷（oligo(dT)）探针的磁珠被用于通过[沃森-克里克碱基配对](@entry_id:275890)原则捕获这些带[poly(A)尾](@entry_id:274750)的mRNA分子。这种方法能高效地富集编码蛋白质的基因，因此非常适用于研究基因表达和可变剪接，特别是当样本RNA质量完好时（例如，来自新鲜冷冻的组织）。

2.  **rRNA去除法 (rRNA depletion)**：与富集mRNA相反，此方法旨在去除丰度最高的rRNA。它使用与rRNA序列互补的探针，将rRNA[分子结合](@entry_id:200964)并移除。剩余的RNA，包括mRNA、长非编码RNA（[lncRNA](@entry_id:194588)）以及其他可能不含[poly(A)尾](@entry_id:274750)的转录本，都被保留下来进行测序。这种策略适用于RNA已降解的样本（如福尔马林固定石蜡包埋，即FFPE组织），因为降解会使许多mRNA片段失去其3'端的[poly(A)尾](@entry_id:274750)。此外，当研究目标是探索包括[非编码RNA](@entry_id:268179)在内的广谱转录组时，rRNA去除法是必然之选。

3.  **靶向捕获法 (Targeted capture)**：在某些临床情境下，研究者可能只对一小组特定基因（例如，一个疾病相关的基因面板）感兴趣。靶向捕获法使用专门设计的探针，通过[核酸杂交](@entry_id:166787)原理，从总[cDNA文库](@entry_id:262174)中“钓”出与这些目标基因相对应的片段。这种方法将测序资源集中在少数几个基因上，能够以有限的预算获得极高的[测序深度](@entry_id:178191)，从而灵敏地检测低表达基因的异常剪接或基因融合等事件，这对于[孟德尔遗传](@entry_id:156036)病的诊断尤其重要 [@problem_id:5088443]。

#### 文库质量：复杂性与冗余度

[cDNA文库](@entry_id:262174)构建完成后，通常需要通过[聚合酶链式反应](@entry_id:142924)（PCR）进行扩增，以获得足够数量的DNA用于测序。然而，这一步骤也引入了潜在的偏差。评估文库质量的两个关键指标是**文库复杂度（library complexity）**和**冗余率（duplication rate）** [@problem_id:5088407]。

**文库复杂度**指的是文库中独特的、源自不同原始RNA分子的cDNA片段的总数。高复杂度的文库意味着它捕获了广泛多样的转录本信息，通常源于充足且高质量的起始RNA。相反，低复杂度的文库可能由起始RNA量不足或严重降解导致。

PCR扩增会为每个原始cDNA片段制造多个拷贝。这些来自同一个原始分子的测序读段（reads）被称为**PCR冗余（PCR duplicates）**。在没有使用**[唯一分子标识符](@entry_id:192673)（Unique Molecular Identifiers, UMIs）**的情况下，生物信息学分析通常通过比对到基因组的相同坐标来识别和标记这些冗余读段。

**冗余率**定义为测序读段中被鉴定为冗余拷贝的比例。其计算公式为：
$$ \text{冗余率} = 1 - \frac{N_{\text{unique}}}{N_{\text{reads}}} $$
其中，$N_{\text{reads}}$是总测序读段数，$N_{\text{unique}}$是去除冗余后的独特读段数。例如，一个产生了$20 \times 10^6$个读段、去重后剩余$8 \times 10^6$个独特读段的文库，其冗余率高达$1 - (8 \times 10^6) / (20 \times 10^6) = 0.6$，即$60\%$。高冗余率可能预示着文库复杂度低或PCR扩增过度。

重要的是，PCR扩增过程具有随机性，某些分子可能被不成比例地放大。如果没有UMIs（在扩增前为每个原始分子打上独特标签），这些扩增出的拷贝就无法与来自不同原始分子的独立测序事件区分开。直接计算所有读段会导致对那些被过度扩增的分子所对应的基因的丰度产生严重高估，从而引入**系统性偏差** [@problem_id:5088407]。

### 测序参数与数据生成

获得高质量的文库后，下一步是进行高通量测序。测序仪的设置，即测序参数，直接决定了原始数据的特性，并深刻影响后续分析的能力，尤其是在解析复杂的转录本结构（如可变剪接）时 [@problem_id:5088474]。

#### 关键参数：塑造数据

1.  **读段长度 (Read Length, $L$)**：指每个测序读段所包含的核苷酸数目。增加读段长度有两大好处。首先，更长的读段更有可能跨越一个**外显子-外显子连接点（exon-exon junction）**，这对于识别和定量不同的[剪接异构体](@entry_id:167419)至关重要。在一个简化的模型中，读段跨越连接点的概率与$L$近似成正比。其次，更长的读段提供了更多的序列信息，可以更准确、更唯一地比对到基因组的特定位置，尤其是在处理重复序列区域时 [@problem_id:5088474]。

2.  **单末端与[双末端测序](@entry_id:272784) (Single-End vs. Paired-End Sequencing)**：**单末端测序（Single-End, SE）**只从cDNA片段的一端测序，而**[双末端测序](@entry_id:272784)（Paired-End, PE）**则从同一片段的两端分别测序，产生一对具有已知相对方向和大致距离的读段。在总测序碱基数固定的前提下，PE测序并不会增加总读段数，但其优势是提供了关键的**长程连接信息**。即使单个读段本身无法明确其来源的[剪接异构体](@entry_id:167419)，但知道它的“伙伴”读段落在几百个碱基对之外的另一个外显子上，就可以帮助我们推断这两个外显子属于同一个转录本。这种能力对于解析复杂的基因，特别是那些拥有多个相似异构体的基因，是不可或缺的 [@problem_id:5088474] [@problem_id:5088474]。

3.  **测序深度 (Sequencing Depth, $N$)**：通常指一个样本获得的**总测序读段数**。更高的[测序深度](@entry_id:178191)意味着对转录组的采样更密集。假设读段是[随机抽样](@entry_id:175193)的，那么测序深度越高，每个转录本被读段覆盖的次数就越多。这会降低因随机抽样带来的统计噪声，并增加检测到低丰度转录本或稀有剪接事件的概率。在一个简单的[随机抽样](@entry_id:175193)模型中，假设每个读段有$p$的概率观测到一个特定事件（如一个稀有的剪接），那么在$N$个读段中至少观测到一次该事件的概率是$1 - (1 - p)^{N}$。这个概率随着$N$的增加而增加，因此，足够的测序深度对于发现低丰度的生物学信号至关重要 [@problem_id:5088474] [@problem_id:5088474]。

### 从读段到数值：比对与定量

测序完成后，我们得到的是数以千万计的短序列读段。为了获得有生物学意义的定量信息，必须将这些读段映射回其在基因组或转录组中的来源，并进行计数。

#### 比对策略：处理剪接的挑战

由于[RNA剪接](@entry_id:147807)的存在，来自成熟mRNA的读段可能跨越两个或多个在基因组上被长内含子隔开的外显子。因此，不能使用为基因组DNA设计的标准比对工具，而必须采用专门的策略。

1.  **[剪接感知比对](@entry_id:175766) (Splice-aware alignment)**：这类比对算法的核心能力是识别“跨立比对”（split alignment）。它们首先将一个读段拆分成多个小片段（种子），在基因组上寻找这些种子的位置。如果来自同一个读段的两个种子分别比对到基因组上相距遥远但顺序正确的两个外显子上，算法就会推断这里存在一个剪接事件。然后，它会通过动态规划等方法，精确地计算出包含一个代表[内含子](@entry_id:144362)的巨大“缺口”（gap）的最佳比对路径。这种方法能够输出每个读段在基因组上的精确碱基级坐标。因此，当研究目标包括**发现新的剪接位点**、**鉴定基因融合**或**进行单核苷酸变异（SNV）检测**时，[剪接感知比对](@entry_id:175766)是必需的 [@problem_id:5157620]。

2.  **伪比对 (Pseudoalignment)**：与耗时的碱基级别比对不同，伪比对的目标是快速地将读段归属到一组**已知的**转录本上。这类算法首先从所有已知的转录本序列（注释[转录组](@entry_id:274025)）中提取所有长度为$k$的子串（$k$-mers），并建立一个高效的索引。对于每一个测序读段，算法不是进行比对，而是查询该读段包含的$k$-mers与哪些转录本兼容。所有与该读段兼容的转录本集合被称为**转录本兼容集（Transcript Compatibility Set, TCS）**。许多读段会与多个异构体兼容，形成所谓的“[等价类](@entry_id:156032)”。最后，通过[期望最大化](@entry_id:273892)（EM）等[统计模型](@entry_id:755400)，根据这些等价类的信息来推断每个已知转录本的真实丰度。伪比对的优点是极快的速度和很低的内存占用，非常适合对已知转录本进行**大规模表达定量**，但它无法用于任何新颖事件的发现 [@problem_id:5157620]。

#### 定量与归一化

比对/伪比对完成后，每个基因或转录本会被赋予一个**原始计数（raw count）**，即映射到其上的读段（或片段）数量。然而，原始计数在样本间不具有直接可比性，因为它们受到至少两个主要技术因素的干扰：**[测序深度](@entry_id:178191)**和**基因/转录本长度**。一个测得更深的文库或一个更长的基因，天然会产生更多的读段。因此，必须进行**归一化（normalization）**。

历史上，研究者提出了**FPKM（Fragments Per Kilobase of transcript per Million mapped fragments）**这一指标，它试图同时对测序深度和转录本长度进行校正。然而，FPKM存在统计学上的缺陷，使得样本间的比较变得困难。

目前，**TPM（Transcripts Per Million）**被认为是更好的定量单位。它的推导过程更能体现数据处理的逻辑 [@problem_id:5088454]。TPM的计算分两步：
1.  **长度归一化**：首先，将每个基因的原始计数$c_i$除以其[有效长度](@entry_id:184361)$L_i$（以千碱基为单位）。这得到了一个“每千碱基的读段率” $\frac{c_i}{L_i}$，该值与转录本的[摩尔浓度](@entry_id:139283)成正比。
2.  **深度归一化（组分归一化）**：然后，将所有基因的这个比率相加，得到一个总和$S = \sum_{j} \frac{c_j}{L_j}$。最后，将每个基因的比率除以这个总和，再乘以一百万($10^6$)。
$$
\mathrm{TPM}_i = 10^6 \cdot \frac{\frac{c_i}{L_i}}{\sum_{j=1}^{G} \frac{c_j}{L_j}}
$$
TPM的优越性在于其**组分一致性（compositional coherence）**。在一个样本内，所有基因的TPM值之和恒定为一百万。这使得TPM值可以被直观地理解为：“在一个由一百万个转录本构成的群体中，有多少个是来自基因$i$的”。这种特性使得[TPM](@entry_id:170576)在样本间的比较更为稳健。

然而，即使是TPM也无法完全解决[RNA-seq](@entry_id:140811)数据的根本问题——其**组分性质（compositional nature）** [@problem_id:5088493]。由于每个测序文库的总读段数是有限的，我们测量的不是绝对丰度，而是相对丰度。一个基因的表达比例增加，必然会导致其他基因的表达比例相应下降，即便后者的绝对分子数并未改变。

设想一个场景：某个刺激使得一小部分基因（例如占总转录本的$f$比例）的表达量急剧上调了$r$倍，而其他基因的绝对表达量保持不变。由于总转录本“蛋糕”变大了，那些表达量不变的基因所占的比例实际上变小了。如果我们采用简单的总数归一化方法（即将每个基因的计数除以总计数），我们会错误地观察到这些稳定基因的表达量发生了下调，其观测到的[倍数变化](@entry_id:272598)为$\frac{1}{1 + (r-1)f}$ [@problem_id:5088493]。这个值恒小于1，表明了虚假的下调。这一现象凸显了发展更复杂的[统计模型](@entry_id:755400)进行[差异表达分析](@entry_id:266370)的必要性。

### [统计建模](@entry_id:272466)与推断

要从[RNA-seq](@entry_id:140811)数据中得出可靠的生物学结论，必须依赖严谨的实验设计和恰当的[统计模型](@entry_id:755400)。

#### 实验设计：推断的基石

1.  **[生物学重复与技术重复](@entry_id:199856)**：在[医学遗传学](@entry_id:262833)研究中，我们的目标是推断某个诊断（如疾病状态）对**患者群体**的影响。为了实现这一目标，**生物学重复（biological replicates）**是不可或缺的。生物学重复指的是来自不同独立个体（如不同患者）的样本。它们反映了群体内的**生物学变异**，这是评估处理效应是否显著的“背景噪音”。**技术重复（technical replicates）**则是对同一样本进行多次独立的文库制备和测序。它们主要用于评估**技术变异**，即实验流程本身引入的噪音。增加技术重复可以更精确地测量单个样本的表达值，但它们永远无法替代生物学重复，因为它们不提供关于群体变异的任何信息 [@problem_id:5088415] [@problem_id:5088415]。

2.  **[批次效应](@entry_id:265859)与混杂因素**：**[批次效应](@entry_id:265859)（batch effect）**是高通量实验中一个常见且棘手的问题。它是指由于样本在不同时间、由不同人员、使用不同试剂或仪器处理而引入的系统性、非生物学差异 [@problem_id:5088396]。如果实验设计不当，[批次效应](@entry_id:265859)可能与我们感兴趣的生物学变量（如病例vs.对照）发生**混杂（confounding）**。

    一个经典的糟糕设计是：所有病例样本在第一批处理，所有对照样本在第二批处理。在这种**完全混杂**的情况下，我们观察到的任何表达差异都无法辨别是源于疾病状态的真实生物学效应，还是源于两批处理之间的技术差异。从[统计模型](@entry_id:755400)上看，$Y_{gi} = \mu_g + \beta_g C_i + \gamma_g B_i + \varepsilon_{gi}$（其中$C_i$是病例状态，$B_i$是批次），当$C_i$和$B_i$完全相同时，$\beta_g$（生物学效应）和$\gamma_g$（批次效应）是**不可识别的（not identifiable）**，我们只能估计它们的和$\beta_g + \gamma_g$ [@problem_id:5088396]。

    应对[批次效应](@entry_id:265859)的策略包括：在设计阶段通过**随机化**将不同组的样本均衡地分配到各个批次中；在分析阶段，如果设计是均衡的，可以在[统计模型](@entry_id:755400)中加入批次作为一个协变量，从而在数学上校正其影响。对于未知的[批次效应](@entry_id:265859)，可以使用**替代变量分析（Surrogate Variable Analysis, SVA）**等方法从数据中估计这些潜在的混杂因素并加以校正 [@problem_id:5088396] [@problem_id:5088415]。

#### 计数数据的建模

RNA-seq产生的读段计数是离散的非负整数。泊松（Poisson）分布是描述计数数据的自然起点，它有一个关键特性：方差等于均值。然而，在RNA-seq数据中，我们通常观察到**[过度离散](@entry_id:263748)（overdispersion）**现象，即计数的实际方差远大于其均值。这主要是由生物学重复之间的真实表达水平波动造成的。

因此，需要使用能处理过度离散的模型 [@problem_id:5088393]。
*   **泊松模型 (Poisson)**：$Var(Y) = \mu$。通常不适用于有生物学重复的[RNA-seq](@entry_id:140811)数据，因为它低估了方差，会导致假阳性率的急剧升高。诊断图（如[残差图](@entry_id:169585)）通常会显示方差随均值增加的喇叭口形状。
*   **拟泊松模型 (Quasi-Poisson)**：$Var(Y) = \phi\mu$。它在泊松模型的基础上引入了一个离散参数$\phi$，允许方差是均值的常数倍。这在一定程度上缓解了过度离散问题，但它假设方差-均值比是恒定的。
*   **负二项分布模型 (Negative Binomial, NB)**：其方差与均值的关系通常被[参数化](@entry_id:265163)为$Var(Y) = \mu + \alpha\mu^2$。这里的方差是均值的二次函数。这个模型更加灵活，它允许方差-均值比($1+\alpha\mu$)随着均值的增加而增加。经验证据表明，这种二次关系能非常好地拟合RNA-seq数据的真实结构。例如，当均值为10时方差约为80（比值为8），而均值为100时方差约为1500（比值为15），这种趋势就支持了负[二项模型](@entry_id:275034)。因此，负二项分布已成为[差异表达分析](@entry_id:266370)（如[DESeq2](@entry_id:167268)和edgeR）的标准模型 [@problem_id:5088393]。

### 医学遗传学高级应用：[等位基因特异性表达](@entry_id:178721)

除了分析基因层面的总表达量，[RNA-seq](@entry_id:140811)还能提供关于等位基因表达的精细信息，这在[医学遗传学](@entry_id:262833)中具有重要价值 [@problem_id:5088447]。

#### 核心概念

在一个[二倍体](@entry_id:268054)生物中，如果一个个体在某个基因的外显子区域携带一个杂合的[单核苷酸多态性](@entry_id:173601)（SNP），那么通过测序覆盖该SNP位点的[RNA-seq](@entry_id:140811)读段，我们就可以区分它们来自哪个等位基因。

*   **[等位基因特异性表达](@entry_id:178721) (Allele-Specific Expression, ASE)**：指在同一个体中，来自父本和母本的两个等位基因的转录水平存在显著差异的现象。
*   **[基因组印记](@entry_id:147214) (Genomic Imprinting)**：是导致ASE的一种特殊[表观遗传机制](@entry_id:184452)。在这种机制下，基因的表达取决于其亲本来源，其中一个亲本的等位基因（父源或母源）会因DNA甲基化等修饰而被沉默，导致[单等位基因表达](@entry_id:264137)。
*   **参考基因组比对偏好 (Reference Mapping Bias)**：一个重要的技术混杂因素。当将测序[读段比对](@entry_id:265329)到[参考基因组](@entry_id:269221)时，与参考基因组序列完全匹配的读段（参考等位基因）往往比携带变异的读段（非参考等位基因）更容易被成功比对。这会导致对参考等位基因计数的虚高，从而错误地推断出ASE或掩盖真实的ASE。在分析时，必须考虑并校正这种偏好，例如，通过建立一个考虑了偏好的统计学零假设（如，预期比例不是$0.5:0.5$，而是$0.6:0.4$）。

#### 基因定相的重要性

**基因定相（Phasing）**是确定一个杂合子个体的两个等位基因分别位于哪条同源染色体（父源还是母源）上的过程。在ASE分析中，基因定相至关重要：

1.  **区分印记与其他ASE原因**：[基因组印记](@entry_id:147214)是严格依赖于亲本来源的。要确认一个基因的[单等位基因表达](@entry_id:264137)是由印记引起的，就必须知道被表达的那个等位基因是来自父亲还是母亲。没有定相信息，我们只能观察到ASE现象，但无法确定其机制。
2.  **关联顺式调控变异**：许多ASE是由基因附近的[顺式调控元件](@entry_id:275840)（如启动子、增[强子](@entry_id:198809)）中的变异引起的。这些变异只影响其所在的那条染色体上等位基因的表达。为了建立这种因果联系，必须通过定相来证明调控变异与高表达的等位基因位于同一个单倍型（即同一条亲本染色体）上。这对于揭示疾病的分子遗传机制至关重要 [@problem_id:5088447]。