{"hands_on_practices": [{"introduction": "神经影像信号，如脑电图（EEG）所记录的，通常非常微弱，容易被背景噪声淹没。为了从噪声中提取出与特定事件相关的神经响应（即事件相关电位，ERP），研究人员采用了一种基础而强大的技术：信号平均法。这项实践将指导你推导并计算通过平均多次试验来提高信噪比（$SNR$）的具体效果[@problem_id:5018722]，让你亲身体会这一功能神经影像数据处理基石的量化威力。", "problem": "在功能性神经影像学中，脑电图 (EEG) 通过对重复试验中时间锁定的响应进行平均，以测量事件相关电位 (ERP)，从而提高信噪比 (SNR)。考虑一个 ERP 成分，其单次试验的信号振幅为 $5\\,\\mu\\mathrm{V}$，每次试验的加性噪声为零均值、平稳且在各次试验间独立，标准差为 $20\\,\\mu\\mathrm{V}$。使用以下基本事实：(i) SNR 定义为信号振幅与噪声标准差之比；(ii) 对于各次试验间独立同分布的噪声， $N$ 次试验的算术平均值的方差相对于单次试验的方差减少了 $N$ 倍。假设信号在各次试验中是完美相位锁定且完全相同的，因此平均化会保持其振幅。根据这些原理，推导平均 ERP 的 SNR 作为 $N$ 的函数的表达式，并确定在平均 ERP 中实现 $\\text{SNR} = 5$ 所需的试验次数 $N$。将最终答案表示为一个不带单位的精确整数。", "solution": "问题陈述经评估有效，因为它科学地基于神经影像学中的信号处理原理，问题设定良好并包含所有必要信息，且表述客观。\n\n令 $S_1$ 表示单次试验的信号振幅，$\\sigma_1$ 表示单次试验中噪声的标准差。问题给出的值为：\n$$ S_1 = 5\\,\\mu\\mathrm{V} $$\n$$ \\sigma_1 = 20\\,\\mu\\mathrm{V} $$\n信噪比 (SNR) 定义为信号振幅与噪声标准差之比。因此，单次试验的信噪比，记为 $\\text{SNR}_1$，为：\n$$ \\text{SNR}_1 = \\frac{S_1}{\\sigma_1} = \\frac{5\\,\\mu\\mathrm{V}}{20\\,\\mu\\mathrm{V}} = \\frac{1}{4} $$\n创建事件相关电位 (ERP) 的过程涉及对 $N$ 次重复试验的信号进行平均。令 $S_N$ 为平均后 ERP 的信号振幅，$\\sigma_N$ 为平均后 ERP 噪声的标准差。\n\n根据问题陈述，信号分量在所有试验中都是完美相位锁定且完全相同的。当我们计算 $N$ 个相同信号的算术平均值时，得到的振幅保持不变。\n$$ S_N = \\frac{1}{N} \\sum_{i=1}^{N} S_1 = \\frac{N \\cdot S_1}{N} = S_1 = 5\\,\\mu\\mathrm{V} $$\n噪声分量被陈述为零均值、平稳且在试验间独立。问题指出，对于此类噪声， $N$ 次试验的算术平均值的方差相对于单次试验的方差减少了 $N$ 倍。令 $\\text{Var}_1 = \\sigma_1^2$ 为单次试验中噪声的方差，令 $\\text{Var}_N$ 为平均后 ERP 中噪声的方差。其关系为：\n$$ \\text{Var}_N = \\frac{\\text{Var}_1}{N} = \\frac{\\sigma_1^2}{N} $$\n标准差是方差的平方根。因此，平均后 ERP 中噪声的标准差 $\\sigma_N$ 为：\n$$ \\sigma_N = \\sqrt{\\text{Var}_N} = \\sqrt{\\frac{\\sigma_1^2}{N}} = \\frac{\\sigma_1}{\\sqrt{N}} $$\n我们现在可以推导平均后 ERP 的信噪比 $\\text{SNR}_N$ 作为试验次数 $N$ 的函数的表达式。\n$$ \\text{SNR}_N = \\frac{S_N}{\\sigma_N} = \\frac{S_1}{\\left(\\frac{\\sigma_1}{\\sqrt{N}}\\right)} = \\left(\\frac{S_1}{\\sigma_1}\\right) \\sqrt{N} $$\n这可以用单次试验的信噪比来表示：\n$$ \\text{SNR}_N = \\text{SNR}_1 \\sqrt{N} $$\n代入 $\\text{SNR}_1 = \\frac{1}{4}$ 的值，我们得到此问题的具体表达式：\n$$ \\text{SNR}_N = \\frac{1}{4} \\sqrt{N} $$\n这个方程是解答的第一部分要求，表示了平均后 ERP 的信噪比作为 $N$ 的函数。\n\n任务的第二部分是确定达到信噪比为 $5$ 所需的试验次数 $N$。我们在推导出的方程中设 $\\text{SNR}_N = 5$，然后求解 $N$：\n$$ 5 = \\frac{1}{4} \\sqrt{N} $$\n为了分离出 $\\sqrt{N}$，我们将方程两边都乘以 $4$：\n$$ 20 = \\sqrt{N} $$\n最后，为了求解 $N$，我们将方程两边都平方：\n$$ N = 20^2 = 400 $$\n因此，需要总共 $400$ 次试验才能在平均后 ERP 中达到 $5$ 的信噪比。", "answer": "$$\\boxed{400}$$", "id": "5018722"}, {"introduction": "从信号处理的基本原理出发，我们转向功能性磁共振成像（fMRI）分析的核心工具——通用线性模型（GLM）。GLM允许我们在每个脑体素上对血氧水平依赖（BOLD）信号的时间序列进行建模，从而估计实验任务所引发的神经活动效应。本练习将带你深入GLM的数学细节[@problem_id:5018724]，包括如何处理fMRI数据中普遍存在的自相关噪声，让你揭开标准fMRI分析软件背后的统计引擎盖。", "problem": "一个来自功能性磁共振成像 (fMRI) 的单体素时间序列，通过一个带有相关误差的广义线性模型进行建模。数据包含在一个简单的区组设计中以2秒的重复时间采集的 $T=4$ 个时间点，该设计包含一个与经典血液动力学响应函数卷积的任务回归量。设计矩阵为\n$$\nX=\\begin{pmatrix}\n1  0 \\\\\n1  1 \\\\\n1  1 \\\\\n1  0\n\\end{pmatrix},\n$$\n其中第一列是截距项，第二列是任务回归量。观测到的血氧水平依赖 (BOLD) 信号为\n$$\ny=\\begin{pmatrix}\n0.1 \\\\\n0.9 \\\\\n0.8 \\\\\n0.2\n\\end{pmatrix}.\n$$\n假设噪声 $\\epsilon$ 是零均值高斯噪声，具有已知的一阶自回归 (AR(1)，1阶自回归) 相关参数 $\\rho=0.5$ 和协方差 $\\operatorname{Var}(\\epsilon)=\\sigma^{2}V$，其中 $V$ 是 AR(1) 相关矩阵，其元素为 $V_{ij}=\\rho^{|i-j|}$。令感兴趣的对比用于分离任务效应，其对比向量为\n$$\nc=\\begin{pmatrix}\n0 \\\\\n1\n\\end{pmatrix}.\n$$\n从广义线性模型的假设和具有已知相关性的高斯噪声的性质出发，推导并计算：\n- 对比估计 $c^{\\top}\\hat{\\beta}$，\n- 其在广义最小二乘法下的抽样方差，\n- 以及使用具有 $T-p$ 自由度的残差方差估计对应的 $t$-统计量，其中 $p$ 是回归量的数量。\n\n将最终数值结果四舍五入到四位有效数字。将您的最终答案表示为一个单行矩阵，按顺序包含上述三个量。", "solution": "用户想要解决一个基于广义线性模型 (GLM) 的问题。\n\n### 步骤1：提取已知条件\n- 模型：一个来自 fMRI 的单体素时间序列，通过一个带有相关误差的广义线性模型进行建模。\n- 时间点数量：$T=4$。\n- 设计矩阵：$X=\\begin{pmatrix} 1  0 \\\\ 1  1 \\\\ 1  1 \\\\ 1  0 \\end{pmatrix}$。这意味着回归量的数量是 $p=2$。\n- 观测数据：$y=\\begin{pmatrix} 0.1 \\\\ 0.9 \\\\ 0.8 \\\\ 0.2 \\end{pmatrix}$。\n- 噪声模型：$\\epsilon \\sim N(0, \\sigma^2 V)$，其中噪声是零均值高斯噪声。\n- 自相关：一阶自回归 (AR(1))，参数 $\\rho=0.5$。\n- 相关矩阵：$V$ 的元素为 $V_{ij}=\\rho^{|i-j|}$。\n- 对比向量：$c=\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$。\n- 要求计算：\n  1. 对比估计 $c^{\\top}\\hat{\\beta}$。\n  2. 其在广义最小二乘法下的抽样方差。\n  3. 使用具有 $T-p$ 自由度的残差方差估计对应的 $t$-统计量。\n- 数值精度：将最终值四舍五入到四位有效数字。\n\n### 步骤2：使用提取的已知条件进行验证\n- **科学依据**：该问题基于带有时间相关误差的广义线性模型 (GLM)，这是 fMRI 统计分析的基石。使用 AR(1) 模型描述噪声、使用广义最小二乘法 (GLS) 进行估计以及使用 $t$-统计量进行推断，都是该领域中标准且成熟的程序。\n- **适定性**：该问题是完全指定的。它提供了数据向量 $y$、设计矩阵 $X$、通过 $\\rho$ 定义的噪声相关结构以及对比向量 $c$。唯一确定所要求的三个量所需的所有信息都已给出。\n- **客观性**：该问题以精确的数学和统计语言陈述，没有歧义或主观内容。\n- **结论**：所有检查点均通过。该问题具有科学合理性、适定性和客观性。\n\n### 步骤3：判定与行动\n该问题有效。我将继续提供一个完整的、有理有据的解答。\n\n该问题由广义线性模型 (GLM) 描述：\n$$y = X\\beta + \\epsilon$$\n其中 $y$ 是观测数据的 $T \\times 1$ 向量，$X$ 是 $T \\times p$ 的设计矩阵，$\\beta$ 是待估计参数的 $p \\times 1$ 向量，$\\epsilon$ 是 $T \\times 1$ 的噪声项向量。噪声假设为均值为零的高斯分布，其协方差矩阵为 $\\operatorname{Var}(\\epsilon) = \\sigma^2 V$，其中 $\\sigma^2$ 是噪声方差，$V$ 是 $T \\times T$ 的相关矩阵。由于 $V$ 不是单位矩阵 ($V \\neq I$)，误差是相关的，因此适合的估计方法是广义最小二乘法 (GLS)。\n\n$\\beta$ 的 GLS 估计量，即最佳线性无偏估计量 (BLUE)，由以下公式给出：\n$$\\hat{\\beta} = (X^\\top V^{-1} X)^{-1} X^\\top V^{-1} y$$\n需要计算的量是：\n1. 对比估计：$c^\\top \\hat{\\beta}$\n2. 对比的抽样方差：这被解释为估计方差，$\\widehat{\\operatorname{Var}}(c^\\top \\hat{\\beta}) = \\hat{\\sigma}^2 c^\\top (X^\\top V^{-1} X)^{-1} c$。\n3. $t$-统计量：$t = \\frac{c^\\top \\hat{\\beta}}{\\sqrt{\\widehat{\\operatorname{Var}}(c^\\top \\hat{\\beta})}}$。\n\n首先，我们必须构建矩阵 $V$ 及其逆矩阵 $V^{-1}$。给定 $T=4$ 和 $\\rho=0.5$，AR(1) 相关矩阵 $V$ 是：\n$$V = \\begin{pmatrix}\n1  \\rho  \\rho^2  \\rho^3 \\\\\n\\rho  1  \\rho  \\rho^2 \\\\\n\\rho^2  \\rho  1  \\rho \\\\\n\\rho^3  \\rho^2  \\rho  1\n\\end{pmatrix} = \\begin{pmatrix}\n1  0.5  0.25  0.125 \\\\\n0.5  1  0.5  0.25 \\\\\n0.25  0.5  1  0.5 \\\\\n0.125  0.25  0.5  1\n\\end{pmatrix}$$\nAR(1) 相关矩阵的逆是一个稀疏三对角矩阵：\n$$V^{-1} = \\frac{1}{1-\\rho^2} \\begin{pmatrix}\n1  -\\rho  0  0 \\\\\n-\\rho  1+\\rho^2  -\\rho  0 \\\\\n0  -\\rho  1+\\rho^2  -\\rho \\\\\n0  0  -\\rho  1\n\\end{pmatrix}$$\n代入 $\\rho=0.5$：\n$1-\\rho^2 = 1 - (0.5)^2 = 0.75$。\n$1+\\rho^2 = 1 + (0.5)^2 = 1.25$。\n$$V^{-1} = \\frac{1}{0.75} \\begin{pmatrix}\n1  -0.5  0  0 \\\\\n-0.5  1.25  -0.5  0 \\\\\n0  -0.5  1.25  -0.5 \\\\\n0  0  -0.5  1\n\\end{pmatrix} = \\frac{4}{3} \\begin{pmatrix}\n1  -0.5  0  0 \\\\\n-0.5  1.25  -0.5  0 \\\\\n0  -0.5  1.25  -0.5 \\\\\n0  0  -0.5  1\n\\end{pmatrix} = \\begin{pmatrix}\n4/3  -2/3  0  0 \\\\\n-2/3  5/3  -2/3  0 \\\\\n0  -2/3  5/3  -2/3 \\\\\n0  0  -2/3  4/3\n\\end{pmatrix}$$\n\n接下来，我们计算 $X^\\top V^{-1} X$ 项：\n$$X^\\top V^{-1} = \\begin{pmatrix} 1  1  1  1 \\\\ 0  1  1  0 \\end{pmatrix} \\begin{pmatrix}\n4/3  -2/3  0  0 \\\\\n-2/3  5/3  -2/3  0 \\\\\n0  -2/3  5/3  -2/3 \\\\\n0  0  -2/3  4/3\n\\end{pmatrix} = \\begin{pmatrix}\n2/3  1/3  1/3  2/3 \\\\\n-2/3  1  1  -2/3\n\\end{pmatrix}$$\n$$X^\\top V^{-1} X = \\begin{pmatrix}\n2/3  1/3  1/3  2/3 \\\\\n-2/3  1  1  -2/3\n\\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 1  1 \\\\ 1  1 \\\\ 1  0 \\end{pmatrix} = \\begin{pmatrix}\n2/3+1/3+1/3+2/3  1/3+1/3 \\\\\n-2/3+1+1  1+1\n\\end{pmatrix} = \\begin{pmatrix}\n2  2/3 \\\\\n2/3  2\n\\end{pmatrix}$$\n其逆矩阵是：\n$$\\det(X^\\top V^{-1} X) = 2 \\cdot 2 - (2/3)^2 = 4 - 4/9 = 32/9$$\n$$(X^\\top V^{-1} X)^{-1} = \\frac{1}{32/9} \\begin{pmatrix} 2  -2/3 \\\\ -2/3  2 \\end{pmatrix} = \\frac{9}{32} \\begin{pmatrix} 2  -2/3 \\\\ -2/3  2 \\end{pmatrix} = \\begin{pmatrix} 9/16  -3/16 \\\\ -3/16  9/16 \\end{pmatrix}$$\n接下来，我们计算 $X^\\top V^{-1} y$：\n$$X^\\top V^{-1} y = \\begin{pmatrix}\n2/3  1/3  1/3  2/3 \\\\\n-2/3  1  1  -2/3\n\\end{pmatrix} \\begin{pmatrix} 0.1 \\\\ 0.9 \\\\ 0.8 \\\\ 0.2 \\end{pmatrix} = \\begin{pmatrix}\n(2/3)(0.1) + (1/3)(0.9) + (1/3)(0.8) + (2/3)(0.2) \\\\\n(-2/3)(0.1) + 1(0.9) + 1(0.8) + (-2/3)(0.2)\n\\end{pmatrix}$$\n$$= \\begin{pmatrix} (0.2+0.9+0.8+0.4)/3 \\\\ (-0.2+2.7+2.4-0.4)/3 \\end{pmatrix} = \\begin{pmatrix} 2.3/3 \\\\ 4.5/3 \\end{pmatrix} = \\begin{pmatrix} 23/30 \\\\ 1.5 \\end{pmatrix}$$\n现在，我们可以计算 $\\hat{\\beta}$：\n$$\\hat{\\beta} = (X^\\top V^{-1} X)^{-1} (X^\\top V^{-1} y) = \\begin{pmatrix} 9/16  -3/16 \\\\ -3/16  9/16 \\end{pmatrix} \\begin{pmatrix} 23/30 \\\\ 3/2 \\end{pmatrix}$$\n$$= \\begin{pmatrix} (9/16)(23/30) - (3/16)(3/2) \\\\ (-3/16)(23/30) + (9/16)(3/2) \\end{pmatrix} = \\begin{pmatrix} (207/480) - (9/32) \\\\ (-69/480) + (27/32) \\end{pmatrix}$$\n$$= \\begin{pmatrix} (207/480) - (135/480) \\\\ (-69/480) + (405/480) \\end{pmatrix} = \\begin{pmatrix} 72/480 \\\\ 336/480 \\end{pmatrix} = \\begin{pmatrix} 0.15 \\\\ 0.7 \\end{pmatrix}$$\n所以，$\\hat{\\beta_0}=0.15$ 且 $\\hat{\\beta_1}=0.7$。\n\n1. 计算对比估计 $c^\\top\\hat{\\beta}$：\n当 $c = (0, 1)^\\top$ 时，对比估计为：\n$$c^\\top \\hat{\\beta} = \\begin{pmatrix} 0  1 \\end{pmatrix} \\begin{pmatrix} 0.15 \\\\ 0.7 \\end{pmatrix} = 0.7$$\n\n2. 计算对比的估计抽样方差。\n首先，我们需要估计残差方差 $\\sigma^2$。无偏 GLS 估计量是：\n$$\\hat{\\sigma}^2 = \\frac{e^\\top V^{-1} e}{T-p}$$\n其中 $e = y - X\\hat{\\beta}$ 是残差，$T-p=4-2=2$ 是自由度。\n$$\\hat{y} = X\\hat{\\beta} = \\begin{pmatrix} 1  0 \\\\ 1  1 \\\\ 1  1 \\\\ 1  0 \\end{pmatrix} \\begin{pmatrix} 0.15 \\\\ 0.7 \\end{pmatrix} = \\begin{pmatrix} 0.15 \\\\ 0.85 \\\\ 0.85 \\\\ 0.15 \\end{pmatrix}$$\n$$e = y - \\hat{y} = \\begin{pmatrix} 0.1 \\\\ 0.9 \\\\ 0.8 \\\\ 0.2 \\end{pmatrix} - \\begin{pmatrix} 0.15 \\\\ 0.85 \\\\ 0.85 \\\\ 0.15 \\end{pmatrix} = \\begin{pmatrix} -0.05 \\\\ 0.05 \\\\ -0.05 \\\\ 0.05 \\end{pmatrix}$$\n白化残差平方和为 $e^\\top V^{-1} e$：\n$$e^\\top V^{-1} e = y^\\top V^{-1} y - \\hat{\\beta}^\\top X^\\top V^{-1} y = y^\\top V^{-1} y - (0.15 \\cdot 23/30 + 0.7 \\cdot 1.5) = y^\\top V^{-1} y - (0.115 + 1.05) = y^\\top V^{-1} y - 1.165$$\n直接计算 $e^\\top V^{-1} e$ 更为直接：\n$V^{-1}e = \\begin{pmatrix} 4/3  -2/3  0  0 \\\\ -2/3  5/3  -2/3  0 \\\\ 0  -2/3  5/3  -2/3 \\\\ 0  0  -2/3  4/3 \\end{pmatrix} \\begin{pmatrix} -0.05 \\\\ 0.05 \\\\ -0.05 \\\\ 0.05 \\end{pmatrix} = \\begin{pmatrix} -0.1 \\\\ 0.15 \\\\ -0.15 \\\\ 0.1 \\end{pmatrix}$\n$e^\\top V^{-1} e = \\begin{pmatrix} -0.05  0.05  -0.05  0.05 \\end{pmatrix} \\begin{pmatrix} -0.1 \\\\ 0.15 \\\\ -0.15 \\\\ 0.1 \\end{pmatrix} = 0.005 + 0.0075 + 0.0075 + 0.005 = 0.025$\n$$\\hat{\\sigma}^2 = \\frac{0.025}{2} = 0.0125$$\n对比的估计抽样方差是：\n$$\\widehat{\\operatorname{Var}}(c^\\top \\hat{\\beta}) = \\hat{\\sigma}^2 c^\\top (X^\\top V^{-1} X)^{-1} c$$\n$$c^\\top (X^\\top V^{-1} X)^{-1} c = \\begin{pmatrix} 0  1 \\end{pmatrix} \\begin{pmatrix} 9/16  -3/16 \\\\ -3/16  9/16 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = 9/16$$\n$$\\widehat{\\operatorname{Var}}(c^\\top \\hat{\\beta}) = 0.0125 \\times \\frac{9}{16} = 0.00703125$$\n\n3. 计算 $t$-统计量：\n$$t = \\frac{c^\\top \\hat{\\beta}}{\\sqrt{\\widehat{\\operatorname{Var}}(c^\\top \\hat{\\beta})}} = \\frac{0.7}{\\sqrt{0.00703125}}$$\n$$t = \\frac{0.7}{0.0838525...} \\approx 8.347987...$$\n\n最后，我们将这三个量四舍五入到四位有效数字：\n- 对比估计：$0.7 \\rightarrow 0.7000$\n- 抽样方差：$0.00703125 \\rightarrow 0.007031$\n- $t$-统计量：$8.347987... \\rightarrow 8.348$\n这三个值构成了最终答案。", "answer": "$$ \\boxed{ \\begin{pmatrix} 0.7000  0.007031  8.348 \\end{pmatrix} } $$", "id": "5018724"}, {"introduction": "在学会如何估计单个体素的效应后，我们面临一个更大的挑战：如何在全脑数万个体素中准确地判断哪些区域的活动是显著的。由于进行了大规模的统计检验，仅使用传统的显著性水平会导致假阳性结果急剧增加，这就是“多重比较问题”。这项实践将引导你计算并比较两种关键的校正方法——严格的Bonferroni校正和更为灵活的错误发现率（FDR）控制[@problem_id:5018733]，从而理解它们在统计功效和结果解释上的根本差异。", "problem": "在一项基于任务的功能性磁共振成像 (fMRI) 研究中，对每个体素拟合一个大规模单变量通用线性模型，从而在整个大脑中产生一个体素级 p 值的向量。假设有 $50{,}000$个体素，并且排序后的 p 值 $\\{p_{(k)}\\}_{k=1}^{50{,}000}$（从最小到最大排序）遵循经验观察到的单调关系\n$$\np_{(k)} \\;=\\; 0.12 \\left(\\frac{k}{50{,}000}\\right)^{1.5} \\quad \\text{for} \\quad k=1,2,\\dots,50{,}000.\n$$\n仅使用基本定义，计算：\n1) 在 $50{,}000$ 个体素级检验中，用于控制族系误差率 (FWER) 在总体水平 $\\alpha=0.05$ 时的 Bonferroni 阈值。\n2) 应用于上述排序 p 值的 Benjamini–Hochberg 错误发现率 (FDR) 阈值，目标水平为 $q=0.05$。该阈值定义为，在所有拒绝的假设中，错误拒绝的期望比例不超过 $q$ 的最大秩相关阈值。\n\n将这两个阈值以 $[\\text{Bonferroni 阈值}, \\text{Benjamini–Hochberg 阈值}]$ 的顺序列为一个双元素行向量。将两个阈值均四舍五入至四位有效数字。无需单位。最后，基于误差率控制的基本原理，简要解释为什么 Benjamini–Hochberg 程序在高维神经影像学中通常比 Bonferroni 程序更具统计功效。\n\n在您的答案中，按照上述要求，以四舍五入至四位有效数字的形式表示最终的数值阈值。", "solution": "问题陈述已经过验证，被确定为神经影像统计学领域中一个有效的、适定的问题。所有必要信息均已提供，且问题基于已建立的统计理论。\n\n令 $m$ 为体素级检验的总数，其中 $m = 50,000$。排序后的 p 值由模型 $p_{(k)} = 0.12 \\left(\\frac{k}{m}\\right)^{1.5}$ 给出，其中 $k=1, 2, \\dots, m$。\n\n**1) Bonferroni 阈值**\n\nBonferroni 校正控制族系误差率 (FWER)，即在所有 $m$ 个检验中犯至少一个 I 型错误（假阳性）的概率。为了将 FWER 控制在指定的水平 $\\alpha$，Bonferroni 方法对每个单独的检验应用统一的显著性阈值 $\\alpha_{bonf}$。该阈值源于 Bonferroni 不等式，即 $FWER \\le m \\cdot \\alpha_{test}$。为确保 $FWER \\le \\alpha$，我们将每个检验的阈值设置为：\n$$\n\\alpha_{bonf} = \\frac{\\alpha}{m}\n$$\n给定总体显著性水平 $\\alpha = 0.05$ 和检验次数 $m = 50,000$，Bonferroni 阈值为：\n$$\n\\alpha_{bonf} = \\frac{0.05}{50,000} = \\frac{5 \\times 10^{-2}}{5 \\times 10^4} = 1 \\times 10^{-6}\n$$\n将此结果四舍五入至四位有效数字，Bonferroni 阈值为 $1.000 \\times 10^{-6}$。在此校正下，任何 p 值满足 $p \\le 1.000 \\times 10^{-6}$ 的体素都将被宣布为统计显著。\n\n**2) Benjamini–Hochberg 错误发现率 (FDR) 阈值**\n\nBenjamini–Hochberg (BH) 程序控制错误发现率 (FDR)，即在所有被拒绝的原假设（即所有“发现”）中 I 型错误的期望比例。该程序如下：\n1.  将 $m$ 个 p 值从最小到最大排序：$p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(m)}$。\n2.  对于目标 FDR 水平 $q$，找到最大的整数索引 $k$（记为 $k_{FDR}$），使得该秩次的 p 值满足条件：\n    $$\n    p_{(k)} \\le \\frac{k}{m} q\n    $$\n3.  拒绝所有 $i=1, \\dots, k_{FDR}$ 的原假设 $H_{(i)}$。这等效于将显著性阈值设置为 $p_{(k_{FDR})}$。\n\n我们已知排序后 p 值的模型为：$p_{(k)} = 0.12 \\left(\\frac{k}{m}\\right)^{1.5}$。我们将此代入 BH 不等式，其中 $q = 0.05$ 且 $m = 50,000$：\n$$\n0.12 \\left(\\frac{k}{m}\\right)^{1.5} \\le \\frac{k}{m} \\cdot 0.05\n$$\n对于 $k > 0$，我们可以将两边同除以 $\\frac{k}{m}$，这是一个正数：\n$$\n0.12 \\left(\\frac{k}{m}\\right)^{0.5} \\le 0.05\n$$\n求解比率 $\\frac{k}{m}$：\n$$\n\\left(\\frac{k}{m}\\right)^{0.5} \\le \\frac{0.05}{0.12}\n$$\n$$\n\\frac{k}{m} \\le \\left(\\frac{0.05}{0.12}\\right)^2 = \\left(\\frac{5}{12}\\right)^2 = \\frac{25}{144}\n$$\n现在，我们找到满足此条件的最大整数秩 $k$：\n$$\nk \\le m \\cdot \\frac{25}{144} = 50,000 \\cdot \\frac{25}{144} = \\frac{1,250,000}{144} \\approx 8680.555...\n$$\n由于 $k$ 必须是整数，满足该不等式的最大秩为 $k_{FDR} = 8680$。\n\nBH 阈值是对应于此秩的 p 值，即 $p_{(k_{FDR})}$。我们使用给定的 $p_{(k)}$ 模型，并代入 $k = 8680$ 来计算：\n$$\np_{FDR} = p_{(8680)} = 0.12 \\left(\\frac{8680}{50,000}\\right)^{1.5}\n$$\n首先，计算比率：\n$$\n\\frac{8680}{50,000} = 0.1736\n$$\n现在将此代入阈值的表达式中：\n$$\np_{FDR} = 0.12 \\times (0.1736)^{1.5} = 0.12 \\times (0.1736) \\times \\sqrt{0.1736} \\approx 0.12 \\times 0.1736 \\times 0.4166533\n$$\n$$\np_{FDR} \\approx 0.008680008...\n$$\n将此结果四舍五入至四位有效数字，Benjamini–Hochberg 阈值为 $0.008680$。\n\n**功效差异解释**\n\n在像神经影像学这样的高维环境中，Benjamini–Hochberg (BH) 程序通常比 Bonferroni 校正更具统计功效，因为 BH 程序基于一个不那么严格的误差控制标准。\n\n1.  **误差标准**：Bonferroni 方法控制族系误差率 (FWER)，即做出哪怕只有一个错误发现的概率 ($P(\\text{至少一个假阳性}) \\le \\alpha$)。当检验次数 ($m$) 很大时，这是一个极其严格的标准，因为它旨在防止在整个检验“族”中出现任何假阳性。这种严格性导致了一个非常低的显著性阈值 ($\\alpha_{bonf} = \\alpha/m = 1 \\times 10^{-6}$)，从而降低了检测真实效应的能力（即，其统计功效较低）。\n\n2.  **自适应阈值**：相比之下，BH 程序控制错误发现率 (FDR)，即在所有显著发现中错误发现的期望*比例* ($E[\\frac{\\text{假阳性}}{\\text{总发现数}}] \\le q$)。这个标准承认，在一次大规模分析中，只要少数假阳性只占总发现的一小部分，那么它们是可以容忍的。BH 阈值不是固定的，而是根据数据本身自适应地确定的。它是保持在直线 $\\frac{k}{m}q$ 以下的最大 p 值 $p_{(k)}$。\n\n3.  **最终功效**：因为 FDR 标准不如 FWER 标准保守，所以 BH 程序得出的显著性阈值 ($p_{FDR} \\approx 0.008680$) 通常远大于 Bonferroni 阈值 ($\\alpha_{bonf} = 0.000001$)。更大的阈值意味着更多的原假设将被拒绝。虽然这增加了犯一些错误发现的几率，但它也显著增加了检测真实效应的概率，从而产生更大的统计功效。在 fMRI 中，可能有成千上万个体素被真正激活，控制错误的比例 (FDR) 是一种比试图消除所有错误 (FWER) 更实用、更有效的方法。", "answer": "$$\n\\boxed{\\begin{pmatrix} 1.000 \\times 10^{-6}  0.008680 \\end{pmatrix}}\n$$", "id": "5018733"}]}