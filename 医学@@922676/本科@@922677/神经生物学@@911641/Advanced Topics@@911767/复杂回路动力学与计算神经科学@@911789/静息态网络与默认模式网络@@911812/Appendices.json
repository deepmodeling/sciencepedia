{"hands_on_practices": [{"introduction": "功能磁共振成像（fMRI）的原始信号不可避免地会受到各种非神经源性噪声的污染，其中头部运动是最主要的来源之一。为了准确地研究大脑的内在活动，我们必须首先“清洗”这些数据。本练习将指导你使用通用线性模型（GLM）这一强大的统计工具，构建一个包含头部运动参数及其时间导数等混淆因素的设计矩阵，并通过回归分析将这些噪声成分从感兴趣区域（ROI）的时间序列中剥离出去[@problem_id:5056395]。这个过程是几乎所有fMRI分析的基石，掌握它对于获得可靠的神经科学发现至关重要。", "problem": "给定一个来自功能性磁共振成像 (fMRI) 数据中默认模式网络 (DMN) 的感兴趣区域 (ROI) 的时间序列，以及一组刚体运动参数及其时间导数。在静息态分析中，运动可能会混淆对与静息态网络相关的内在神经波动的估计。您的任务是构建一个捕获运动相关混淆变量的回归设计矩阵，然后计算近似该 ROI 内在神经信号的残差时间序列。请从第一性原理出发，使用一种基于原则的线性建模方法。\n\n将推导和实现建立在以下基本事实之上：\n- 观测值的通用线性模型为 $y = X\\beta + \\varepsilon$，其中 $y \\in \\mathbb{R}^T$ 是观测到的时间序列，$X \\in \\mathbb{R}^{T \\times p}$ 是回归量的设计矩阵，$\\beta \\in \\mathbb{R}^p$ 是系数，$\\varepsilon$ 是误差项。\n- 普通最小二乘法 (OLS) 通过最小化误差平方和来估计系数，并得出 $\\hat{\\beta} = X^{+} y$，其中 $X^{+}$ 表示摩尔-彭若斯伪逆，它在存在秩亏的情况下是一致的。\n- 残差由 $r = y - X\\hat{\\beta}$ 给出，在 OLS 下，残差与 $X$ 的列空间正交。\n\n通过串联以下列来构建设计矩阵 $X$：\n1. 刚体运动参数 $M \\in \\mathbb{R}^{T \\times 6}$（三个平移和三个旋转），按列排列。\n2. 一阶时间导数 $D \\in \\mathbb{R}^{T \\times 6}$，其中对于 $t \\geq 1$，$D_t = M_t - M_{t-1}$，$D_0$ 是零向量。\n3. 一个全为1的截距列。\n4. 一个线性趋势列，其值为 $t - \\bar{t}$，对于 $t = 0, 1, \\dots, T-1$，其中 $\\bar{t}$ 是索引向量的均值。\n\n您将根据上述 $X$ 计算 ROI 时间序列 $y$ 的残差 $r$，然后使用皮尔逊相关系数评估 $r$ 对内在神经成分 $n$（一个给定的合成基准真相）的近似程度。使用皮尔逊相关的定义：\n$$\n\\rho(r,n) = \\frac{\\sum_{t=0}^{T-1} (r_t - \\bar{r})(n_t - \\bar{n})}{\\sqrt{\\sum_{t=0}^{T-1} (r_t - \\bar{r})^2} \\sqrt{\\sum_{t=0}^{T-1} (n_t - \\bar{n})^2}},\n$$\n其中 $\\bar{r}$ 和 $\\bar{n}$ 分别是 $r$ 和 $n$ 的样本均值。\n\n单位：使用秒作为构建正弦波的时间单位，并以赫兹指定频率。重复时间 (TR) 以秒为单位给出。正弦相位角的单位是弧度。\n\n实现一个程序，对以下测试套件执行上述步骤，该套件包括一个通用案例、一个边界条件和一个秩亏的边缘案例。为确保可复现性，所有信号都是确定性的，并逐点定义。\n\n令 $t = 0, 1, \\dots, T-1$ 并为方便起见定义 $u_t = t/T$。对于所有案例，将导数 $D_0$ 设置为零向量。\n\n测试案例 1（通用案例，TR $= 2\\,\\mathrm{s}$，$T = 200$）：\n- 神经基准真相：\n$$\nn_t = \\sin(2\\pi \\cdot 0.03 \\cdot \\mathrm{TR} \\cdot t) + 0.5 \\sin(2\\pi \\cdot 0.05 \\cdot \\mathrm{TR} \\cdot t + \\pi/4).\n$$\n- 运动参数 $M$ 的列 $(m_1,\\dots,m_6)$：\n$$\n\\begin{aligned}\nm_{1,t} = 0.5 \\sin(2\\pi \\cdot 0.2 \\cdot \\mathrm{TR} \\cdot t) + 0.1 u_t, \\\\\nm_{2,t} = 0.4 \\cos(2\\pi \\cdot 0.25 \\cdot \\mathrm{TR} \\cdot t), \\\\\nm_{3,t} = 0.3 \\sin(2\\pi \\cdot 0.15 \\cdot \\mathrm{TR} \\cdot t), \\\\\nm_{4,t} = 0.5 u_t, \\\\\nm_{5,t} = 0.2 \\sin(2\\pi \\cdot 0.05 \\cdot \\mathrm{TR} \\cdot t), \\\\\nm_{6,t} = 0.25 \\cos(2\\pi \\cdot 0.07 \\cdot \\mathrm{TR} \\cdot t).\n\\end{aligned}\n$$\n- 混淆变量的系数：$b = [0.9, -0.5, 0.3, 0.6, -0.4, 0.2]$, $c = [0.5, 0.1, -0.2, 0.3, 0.0, -0.1]$。\n- ROI 时间序列：\n$$\ny_t = n_t + \\sum_{j=1}^{6} b_j m_{j,t} + \\sum_{j=1}^{6} c_j d_{j,t} + 0.1 \\sin(2\\pi \\cdot 0.4 \\cdot \\mathrm{TR} \\cdot t),\n$$\n其中 $d_{j,t}$ 是时间 $t$ 处的第 $j$ 个导数列。\n\n测试案例 2（零运动的边界条件，TR $= 0.8\\,\\mathrm{s}$，$T = 60$）：\n- 神经基准真相：\n$$\nn_t = \\sin(2\\pi \\cdot 0.04 \\cdot \\mathrm{TR} \\cdot t) + 0.6 \\cos(2\\pi \\cdot 0.02 \\cdot \\mathrm{TR} \\cdot t).\n$$\n- 运动参数：对于所有 $j$ 和 $t$，$m_{j,t} = 0$。\n- ROI 时间序列（包括一个微小的高频分量和一个线性漂移）：\n$$\ny_t = n_t + 0.05 \\sin(2\\pi \\cdot 0.3 \\cdot \\mathrm{TR} \\cdot t) + 0.2 u_t.\n$$\n\n测试案例 3（秩亏的边缘案例，TR $= 1.5\\,\\mathrm{s}$，$T = 120$）：\n- 神经基准真相：\n$$\nn_t = \\sin(2\\pi \\cdot 0.025 \\cdot \\mathrm{TR} \\cdot t).\n$$\n- 引入共线性的运动参数 $M$ 的列 $(m_1,\\dots,m_6)$：\n$$\n\\begin{aligned}\nm_{1,t} = \\sin(2\\pi \\cdot 0.1 \\cdot \\mathrm{TR} \\cdot t), \\\\\nm_{2,t} = m_{1,t}, \\\\\nm_{3,t} = 0.3 \\sin(2\\pi \\cdot 0.1 \\cdot \\mathrm{TR} \\cdot t + \\pi/3), \\\\\nm_{4,t} = 0.5 u_t, \\\\\nm_{5,t} = 0.5 u_t, \\\\\nm_{6,t} = \\cos(2\\pi \\cdot 0.2 \\cdot \\mathrm{TR} \\cdot t).\n\\end{aligned}\n$$\n- 混淆变量的系数：$b = [0.5, -0.5, 0.4, 0.3, -0.3, 0.2]$, $c = [0.2, -0.2, 0.1, 0.1, -0.1, 0.0]$。\n- ROI 时间序列：\n$$\ny_t = n_t + \\sum_{j=1}^{6} b_j m_{j,t} + \\sum_{j=1}^{6} c_j d_{j,t}.\n$$\n\n实现要求：\n- 使用向后差分计算 $D$，并将 $D_0$ 设置为零。\n- 通过串联 $M$、$D$、一个全为1的截距以及中心化的线性趋势 $(t - \\bar{t})$ 来构建 $X$。\n- 使用 $X$ 的摩尔-彭若斯伪逆估计 $\\hat{\\beta}$，并计算残差 $r = y - X\\hat{\\beta}$。\n- 为每个测试案例计算皮尔逊相关系数 $\\rho(r,n)$。\n\n您的程序应生成单行输出，其中包含一个方括号内的逗号分隔列表形式的结果，每个相关系数四舍五入到六位小数（例如，\"[0.987654,0.912345,0.998765]\"）。不应打印任何其他文本。", "solution": "该问题要求实现一种基于线性回归的信号处理技术，以从合成的功能性磁共振成像 (fMRI) 时间序列中去除与运动相关的及其他噪声伪影。首先，我们将验证此方法的有效性，然后基于线性代数和统计学的基本原理，给出一个详细的、分步的解决方案。\n\n### 问题验证\n\n**步骤 1：提取给定信息**\n问题提供了以下定义和数据：\n- **通用线性模型 (GLM):** $y = X\\beta + \\varepsilon$\n- **普通最小二乘法 (OLS) 解:** $\\hat{\\beta} = X^{+} y$，其中 $X^{+}$ 是摩尔-彭若斯伪逆。\n- **残差:** $r = y - X\\hat{\\beta}$\n- **设计矩阵 $X$:** 由以下列串联而成：\n    1. 刚体运动参数 $M \\in \\mathbb{R}^{T \\times 6}$。\n    2. 时间导数 $D \\in \\mathbb{R}^{T \\times 6}$，其中当 $t \\geq 1$ 时 $D_t = M_t - M_{t-1}$ 且 $D_0 = \\mathbf{0}$。\n    3. 一个截距列（全为1的向量）。\n    4. 一个去均值的线性趋势列 $(t - \\bar{t})$。\n- **评估指标:** 皮尔逊相关系数 $\\rho(r,n)$。\n- **三个测试案例:** 每个案例都指定了时间点数 $T$、重复时间 TR，以及用于基准真相神经信号 $n_t$、运动参数 $M$ 和观测到的 ROI 时间序列 $y_t$ 的确定性公式。这些案例旨在测试一个通用场景、一个边界条件（零运动）和一个边缘案例（秩亏的设计矩阵）。\n\n**步骤 2：使用提取的给定信息进行验证**\n根据所需标准对问题陈述进行严格评估，得出以下结论：\n1.  **科学依据:** 该问题牢固地植根于 fMRI 数据分析的标准方法论中。使用 GLM 来建模并回归去除噪声信号——包括“Friston 24参数模型”扩展族（运动、导数，有时还有它们的平方）和低频漂移（截距和线性趋势）——是静息态 fMRI 预处理的基石。所指定的数学工具，即 OLS 和摩尔-彭若斯伪逆，是解决此类模型的正确且标准的方法，尤其是在存在共线性回归量的情况下。该问题在科学上和数学上都是合理的。\n2.  **适定性:** 该问题是明确且适定的。所有信号和参数都由明确的数学方程定义，计算过程也已算法化指定。这确保了每个测试案例都存在唯一且稳定的数值解。包含秩亏案例，并要求使用伪逆，表明了对潜在数值问题及其正确解决方法有深入的理解。\n3.  **客观性:** 问题陈述使用精确、客观的语言编写，没有任何主观或推测性主张。所有组成部分都进行了定量定义。\n4.  **完整性与一致性:** 提供了所有必要信息，包括参数（$T$、TR）、信号定义和程序步骤。测试案例内部一致，并且逻辑上遵循给定的框架。\n5.  **可行性:** 参数值（TR、T、信号频率）对于 fMRI 研究是现实的。计算任务是可行的，并且可以使用标准数值库直接实现。\n\n**步骤 3：结论**\n此问题是 **有效的**。它代表了一个形式良好、科学相关且可验证的计算神经科学和信号处理练习。\n\n### 基于原则的解决方案\n\n核心原则是通过对已知的噪声源进行建模和移除，来分离出感兴趣的信号。这是通过一个线性模型框架完成的。\n\n**1. 使用设计矩阵对噪声信号进行建模**\n观测到的 fMRI 时间序列 $y \\in \\mathbb{R}^T$ 被假定为真实神经信号、各种噪声源（混淆变量）和测量误差的线性混合。GLM 模型 $y = X\\beta + \\varepsilon$ 为这一假设提供了数学结构。关键是构建一个设计矩阵 $X \\in \\mathbb{R}^{T \\times p}$，其列（回归量）代表了可疑噪声信号的时间过程。\n在这个问题中，设计矩阵 $X$ 被构建用来模拟四种类型的混淆变量：\n- **刚体运动 ($M$):** 头部运动是 fMRI 中非神经方差的主要来源。$M$ 的 $6$ 列对每个时间点的平移和旋转位移进行建模。\n- **运动的时间导数 ($D$):** 运动参数的向后差分 $D_t = M_t - M_{t-1}$ 被包含进来，以捕捉更复杂的、时间上偏移的运动效应。\n- **直流偏移 (截距):** 包含一个全为1的列来模拟信号的平均水平，该平均水平没有生理学解释。\n- **线性漂移 (趋势):** 包含一个代表线性趋势的列 $(t - \\bar{t})$，以解释扫描仪随时间引起的缓慢漂移。\n完整的设计矩阵通过串联这些分量形成：$X = [M, D, \\mathbf{1}, (t-\\bar{t})]$。对于此问题，其维度为 $T \\times 14$（$M$ 占 $6$ 列，$D$ 占 $6$ 列，截距占 $1$ 列，趋势占 $1$ 列）。\n\n**2. 估计并移除噪声信号**\n目标是找到这些噪声回归量对观测信号 $y$ 的贡献。普通最小二乘法 (OLS) 找到一组系数 $\\hat{\\beta} \\in \\mathbb{R}^p$，使得观测信号 $y$ 与建模信号 $X\\beta$ 之间的平方差之和最小化。解由下式给出：\n$$\n\\hat{\\beta} = (X^T X)^{-1} X^T y\n$$\n在实践中，矩阵 $X^T X$ 可能是病态的或奇异的（不可逆），特别是当某些回归量高度相关（共线性）时。问题在测试案例 3 中明确制造了这种情况。摩尔-彭若斯伪逆 $X^{+}$ 提供了一个稳定且通用的解，即使对于秩亏矩阵也有效：\n$$\n\\hat{\\beta} = X^{+} y\n$$\n一旦估计出 $\\hat{\\beta}$，我们就可以计算出由我们的噪声回归量所解释的信号分量：$\\hat{y} = X\\hat{\\beta}$。\n\n**3. 计算残差**\n残差时间序列 $r$ 是从原始观测值中减去建模的噪声分量后剩下的部分：\n$$\nr = y - \\hat{y} = y - X\\hat{\\beta}\n$$\n根据构造，残差向量 $r$ 与 $X$ 的列空间正交 ($X^T r = \\mathbf{0}$)。这意味着我们将 $y$ 投影到了与混淆变量空间正交的子空间上，从而有效地“清洗”了信号中任何可以由 $X$ 的列线性解释的方差。这个残差序列 $r$ 是我们对真实潜在神经信号的估计，误差包括未建模的噪声和测量误差 $\\varepsilon$。\n\n**4. 评估去噪性能**\n为了量化残差序列 $r$ 恢复已知基准真相神经信号 $n$ 的程度，我们计算皮尔逊相关系数 $\\rho(r, n)$。\n$$\n\\rho(r,n) = \\frac{\\text{cov}(r, n)}{\\sigma_r \\sigma_n} = \\frac{\\sum_{t=0}^{T-1} (r_t - \\bar{r})(n_t - \\bar{n})}{\\sqrt{\\sum_{t=0}^{T-1} (r_t - \\bar{r})^2} \\sqrt{\\sum_{t=0}^{T-1} (n_t - \\bar{n})^2}}\n$$\n接近 $1$ 的相关性表明去噪过程成功地移除了混淆变量，留下的残差信号与真实神经活动的时间动态高度匹配。\n\n实现过程将为三个指定的测试案例分别执行这四个步骤。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy is not used as per the instructions.\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for fMRI signal denoising.\n    \"\"\"\n\n    def process_case(TR, T, n_func, m_func, y_func_extras):\n        \"\"\"\n        Processes a single test case for fMRI signal denoising.\n\n        Args:\n            TR (float): Repetition time in seconds.\n            T (int): Number of time points.\n            n_func (callable): Function to generate the neural ground truth signal n(t).\n            m_func (callable): Function to generate the motion parameters matrix M(t).\n            y_func_extras (callable): Function to generate extra components of the ROI signal y(t).\n\n        Returns:\n            float: The Pearson correlation between the residual signal r and the neural signal n.\n        \"\"\"\n        # 1. Generate time vectors and base signals\n        t = np.arange(T)\n        u = t / T\n\n        # Generate neural ground truth\n        n = n_func(t, TR, u)\n\n        # Generate motion parameters M\n        M = m_func(t, TR, u)\n        \n        # Generate temporal derivatives D\n        D = np.zeros_like(M)\n        if T > 1:\n            D[1:] = M[1:] - M[:-1]\n\n        # Generate the observed ROI time series y\n        y_confound_M = np.sum(y_func_extras[\"b\"] * M, axis=1) if \"b\" in y_func_extras else 0\n        y_confound_D = np.sum(y_func_extras[\"c\"] * D, axis=1) if \"c\" in y_func_extras else 0\n        y_extra_terms = y_func_extras[\"extra_func\"](t, TR, u) if \"extra_func\" in y_func_extras else 0\n        \n        y = n + y_confound_M + y_confound_D + y_extra_terms\n\n        # 2. Construct the design matrix X\n        # Intercept column\n        intercept = np.ones((T, 1))\n        # Linear trend column (demeaned)\n        t_bar = np.mean(t)\n        linear_trend = (t - t_bar).reshape(-1, 1)\n\n        # Concatenate all regressors\n        # X will have T rows and 6 (M) + 6 (D) + 1 (intercept) + 1 (trend) = 14 columns\n        X = np.c_[M, D, intercept, linear_trend]\n\n        # 3. Perform OLS regression and compute residuals\n        # Use Moore-Penrose pseudo-inverse for stability and to handle rank deficiency\n        X_pinv = np.linalg.pinv(X)\n        beta_hat = X_pinv @ y\n        \n        # Residuals are the \"cleaned\" signal\n        r = y - X @ beta_hat\n        \n        # 4. Evaluate performance using Pearson correlation\n        # np.corrcoef returns a 2x2 matrix, the off-diagonal element is the correlation\n        correlation = np.corrcoef(r, n)[0, 1]\n        \n        return correlation\n\n    # Test Case 1: General case\n    case1_params = {\n        \"TR\": 2.0, \"T\": 200,\n        \"n_func\": lambda t, TR, u: np.sin(2 * np.pi * 0.03 * TR * t) + 0.5 * np.sin(2 * np.pi * 0.05 * TR * t + np.pi / 4),\n        \"m_func\": lambda t, TR, u: np.c_[\n            0.5 * np.sin(2 * np.pi * 0.2 * TR * t) + 0.1 * u,\n            0.4 * np.cos(2 * np.pi * 0.25 * TR * t),\n            0.3 * np.sin(2 * np.pi * 0.15 * TR * t),\n            0.5 * u,\n            0.2 * np.sin(2 * np.pi * 0.05 * TR * t),\n            0.25 * np.cos(2 * np.pi * 0.07 * TR * t)\n        ],\n        \"y_func_extras\": {\n            \"b\": np.array([0.9, -0.5, 0.3, 0.6, -0.4, 0.2]),\n            \"c\": np.array([0.5, 0.1, -0.2, 0.3, 0.0, -0.1]),\n            \"extra_func\": lambda t, TR, u: 0.1 * np.sin(2 * np.pi * 0.4 * TR * t)\n        }\n    }\n\n    # Test Case 2: Boundary condition (zero motion)\n    case2_params = {\n        \"TR\": 0.8, \"T\": 60,\n        \"n_func\": lambda t, TR, u: np.sin(2 * np.pi * 0.04 * TR * t) + 0.6 * np.cos(2 * np.pi * 0.02 * TR * t),\n        \"m_func\": lambda t, TR, u: np.zeros((len(t), 6)),\n        \"y_func_extras\": {\n            \"extra_func\": lambda t, TR, u: 0.05 * np.sin(2 * np.pi * 0.3 * TR * t) + 0.2 * u\n        }\n    }\n\n    # Test Case 3: Edge case (rank deficiency)\n    case3_params = {\n        \"TR\": 1.5, \"T\": 120,\n        \"n_func\": lambda t, TR, u: np.sin(2 * np.pi * 0.025 * TR * t),\n        \"m_func\": lambda t, TR, u: np.c_[\n            np.sin(2 * np.pi * 0.1 * TR * t),\n            np.sin(2 * np.pi * 0.1 * TR * t), # Collinear with m1\n            0.3 * np.sin(2 * np.pi * 0.1 * TR * t + np.pi/3),\n            0.5 * u,\n            0.5 * u, # Collinear with m4\n            np.cos(2 * np.pi * 0.2 * TR * t)\n        ],\n        \"y_func_extras\": {\n            \"b\": np.array([0.5, -0.5, 0.4, 0.3, -0.3, 0.2]),\n            \"c\": np.array([0.2, -0.2, 0.1, 0.1, -0.1, 0.0])\n        }\n    }\n\n    test_cases = [case1_params, case2_params, case3_params]\n    results = []\n    for case in test_cases:\n        result = process_case(case[\"TR\"], case[\"T\"], case[\"n_func\"], case[\"m_func\"], case[\"y_func_extras\"])\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join([f'{res:.6f}' for res in results])}]\")\n\nsolve()\n```", "id": "5056395"}, {"introduction": "一旦我们获得了“干净”的大脑连接数据，一个核心问题便是：这些连接强度究竟意味着什么？本练习旨在展示大脑连接模式与个体行为表现之间的深刻联系。我们将学习如何将默认模式网络（DMN）内的多个连接融合成一个综合指数，并以此为基础，构建一个线性回归模型来预测个体在执行外部任务时的反应时变异性[@problem_id:5056143]。通过这个实践，你将亲身体验如何将抽象的大脑测量指标转化为对具体认知功能的预测，这是将神经科学研究应用于理解个体差异的关键一步。", "problem": "您的任务是推导并实现一个预测模型，该模型使用任务前的默认模式网络（DMN）连接性来预测外部导向任务的表现，表现通过反应时间（RT）变异性来操作化。默认模式网络（DMN）是一组在休息时表现出相干活动的大脑区域；任务前更强的DMN连接性通常与内部专注处理导致的外部导向任务表现变异性增加有关。从神经生物学和统计学的基本定义出发，构建一个模型，其中标量DMN连接性指数通过普通最小二乘法线性回归预测RT变异性，并将其应用于指定的测试套件。\n\n基本原理和定义：\n- 两个区域间的静息态功能连接性定义为根据它们在休息期间的血氧水平依赖时间序列计算出的皮尔逊相关系数 $r$。\n- 为了从相关系数中获得一个正态分布的汇总指数，使用Fisher $z$变换 $z = \\operatorname{atanh}(r)$。\n- 给定 $N$ 个DMN区域，有 $M = N(N-1)/2$ 个唯一的成对相关性 $\\{r_{ij}\\}$（上三角），将参与者 $i$ 的DMN连接性指数定义为Fisher $z$变换后的成对相关性的算术平均值：\n$$\nC_i = \\frac{1}{M} \\sum_{(j,k)\\in \\mathcal{U}} \\operatorname{atanh}(r_{jk}^{(i)}),\n$$\n其中 $\\mathcal{U}$ 表示上三角索引对的集合，且 $r_{jk}^{(i)} \\in (-1,1)$。\n- 参与者 $i$ 的反应时间变异性定义为他们在外部导向任务中记录的逐次试验反应时间 $\\{t_{i\\ell}\\}_{\\ell=1}^n$ 的总体标准差（分母为 $n$）：\n$$\nV_i = \\sqrt{\\frac{1}{n}\\sum_{\\ell=1}^n \\left(t_{i\\ell} - \\bar{t}_i\\right)^2},\n\\quad \\text{with} \\quad\n\\bar{t}_i = \\frac{1}{n} \\sum_{\\ell=1}^n t_{i\\ell}.\n$$\n- 预测模型是一个连接连接性与变异性的线性回归：\n$$\n\\hat{V} = a + b C,\n$$\n选择参数 $(a,b)$ 以最小化训练集上的残差平方和。普通最小二乘解为：\n$$\nb = \\frac{\\sum_{i=1}^n (C_i - \\bar{C})(V_i - \\bar{V})}{\\sum_{i=1}^n (C_i - \\bar{C})^2},\n\\quad\na = \\bar{V} - b\\,\\bar{C},\n$$\n其中 $\\bar{C}$ 和 $\\bar{V}$ 是 $\\{C_i\\}$ 和 $\\{V_i\\}$ 的样本均值。\n\n训练数据说明：\n- 考虑 $N=4$ 个DMN区域，因此每个参与者有 $M=6$ 个唯一的成对相关性。对于每个训练参与者 $i\\in\\{1,\\dots,8\\}$，六个非对角线相关性 $\\{r^{(i)}\\}$ 提供如下（每个列表是有序的，但对于求均值而言顺序无关）：\n1. 参与者 $1$：[0.15, 0.20, 0.10, 0.12, 0.18, 0.16]\n2. 参与者 $2$：[0.25, 0.28, 0.22, 0.24, 0.26, 0.27]\n3. 参与者 $3$：[0.35, 0.33, 0.32, 0.36, 0.37, 0.34]\n4. 参与者 $4$：[0.45, 0.48, 0.42, 0.44, 0.46, 0.47]\n5. 参与者 $5$：[0.55, 0.52, 0.56, 0.58, 0.54, 0.57]\n6. 参与者 $6$：[0.65, 0.62, 0.63, 0.66, 0.67, 0.64]\n7. 参与者 $7$：[0.70, 0.72, 0.68, 0.69, 0.71, 0.73]\n8. 参与者 $8$：[0.75, 0.78, 0.74, 0.76, 0.77, 0.79]\n- 对于每个训练参与者 $i$，逐次试验的反应时间 $\\{t_{i\\ell}\\}$ 由一个基础模式向量 $p$ 和一个振幅 $A_i$（单位：秒）确定性地构建。设基础模式为\n$$\np = [\\,-0.3,\\,-0.2,\\,-0.1,\\,0.0,\\,0.1,\\,0.2,\\,0.3,\\,-0.1,\\,0.1,\\,0.0,\\,-0.2,\\,0.2\\,],\n$$\n并定义\n$$\nt_{i\\ell} = 0.6 + A_i\\,p_\\ell \\quad \\text{秒},\n$$\n对于 $\\ell=1,\\dots,12$。使用以下振幅（单位：秒）：\n$$\nA_1=0.16,\\; A_2=0.20,\\; A_3=0.24,\\; A_4=0.28,\\; A_5=0.32,\\; A_6=0.36,\\; A_7=0.40,\\; A_8=0.44.\n$$\n这些振幅在人类反应时间的科学合理范围内产生递增的变异性幅度。\n\n模型拟合任务：\n- 通过对Fisher $z$变换后的相关性取平均值，为每个训练参与者计算 $C_i$。\n- 将每个训练参与者的 $t_{i\\ell}$ 的总体标准差作为 $V_i$ 进行计算。\n- 使用上述普通最小二乘法公式拟合线性回归以获得 $a$ 和 $b$。\n\n预测与测试套件：\n- 使用拟合的 $(a,b)$，为三个新的参与者（测试用例）预测RT变异性 $\\hat{V}$（单位：秒），这些参与者仅由他们的六个非对角线DMN相关系数指定：\n1. 测试用例 $1$ (中等连接性)：[0.60, 0.58, 0.62, 0.59, 0.61, 0.60]\n2. 测试用例 $2$ (低连接性边界)：[0.05, 0.08, 0.02, 0.04, 0.06, 0.03]\n3. 测试用例 $3$ (高连接性边缘)：[0.82, 0.80, 0.83, 0.81, 0.84, 0.82]\n\n要求输出：\n- 您的程序应生成单行输出，其中包含三个测试用例的预测RT变异性值（单位：秒），每个值四舍五入到六位小数，形式为方括号内由逗号分隔的列表，例如：$[0.052345,0.031000,0.078999]$。", "solution": "该问题是构建一个基于任务前默认模式网络（DMN）连接性的反应时间（RT）变异性预测模型。该模型将是一个简单的线性回归模型，使用一组参与者的数据进行训练，然后用于对一组新的测试用例进行预测。该过程包括几个步骤：为每个参与者计算DMN连接性指数，确定他们的RT变异性，拟合回归模型，最后应用模型进行预测。\n\n分析主要分为四个阶段：\n1.  为8名训练参与者中的每一位计算自变量（DMN连接性指数，$C_i$）。\n2.  为每位训练参与者计算因变量（RT变异性，$V_i$）。\n3.  估计普通最小二乘（OLS）线性回归模型的参数。\n4.  使用拟合模型为3个测试用例预测RT变异性。\n\n**第1步：计算DMN连接性指数 ($C_i$)**\n\n对于每位参与者 $i$，DMN连接性指数 $C_i$ 定义为DMN内 $M$ 个唯一成对连接的Fisher $z$变换后的皮尔逊相关系数的算术平均值。当有 $N=4$ 个区域时，存在 $M = N(N-1)/2 = 4(3)/2 = 6$ 个唯一配对。公式为：\n$$\nC_i = \\frac{1}{6} \\sum_{(j,k)\\in \\mathcal{U}} \\operatorname{atanh}(r_{jk}^{(i)})\n$$\n其中 $\\{r_{jk}^{(i)}\\}$ 是参与者 $i$ 的6个相关系数。函数 $\\operatorname{atanh}(r)$ 是Fisher $z$变换。\n\n使用提供的8名训练参与者的相关数据，我们计算出以下连接性指数：\n- 参与者 1: $r^{(1)} = [0.15, 0.20, 0.10, 0.12, 0.18, 0.16] \\implies C_1 \\approx 0.153018$\n- 参与者 2: $r^{(2)} = [0.25, 0.28, 0.22, 0.24, 0.26, 0.27] \\implies C_2 \\approx 0.259096$\n- 参与者 3: $r^{(3)} = [0.35, 0.33, 0.32, 0.36, 0.37, 0.34] \\implies C_3 \\approx 0.359877$\n- 参与者 4: $r^{(4)} = [0.45, 0.48, 0.42, 0.44, 0.46, 0.47] \\implies C_4 \\approx 0.489166$\n- 参与者 5: $r^{(5)} = [0.55, 0.52, 0.56, 0.58, 0.54, 0.57] \\implies C_5 \\approx 0.623617$\n- 参与者 6: $r^{(6)} = [0.65, 0.62, 0.63, 0.66, 0.67, 0.64] \\implies C_6 \\approx 0.767243$\n- 参与者 7: $r^{(7)} = [0.70, 0.72, 0.68, 0.69, 0.71, 0.73] \\implies C_7 \\approx 0.877983$\n- 参与者 8: $r^{(8)} = [0.75, 0.78, 0.74, 0.76, 0.77, 0.79] \\implies C_8 \\approx 1.009470$\n\n这8个值构成了回归的自变量集合 $\\{C_i\\}_{i=1}^8$。\n\n**第2步：计算反应时间变异性 ($V_i$)**\n\nRT变异性 $V_i$ 是参与者 $n=12$ 次反应时间 $\\{t_{i\\ell}\\}$ 的总体标准差。反应时间由公式 $t_{i\\ell} = 0.6 + A_i p_\\ell$ 生成，其中 $A_i$ 是特定于参与者的振幅，$p$ 是一个基础模式向量。\n\n$V_i$ 的公式是：\n$$\nV_i = \\sqrt{\\frac{1}{n}\\sum_{\\ell=1}^n \\left(t_{i\\ell} - \\bar{t}_i\\right)^2}\n$$\n我们可以简化这个计算。首先，求出平均反应时间 $\\bar{t}_i$：\n$$\n\\bar{t}_i = \\frac{1}{n} \\sum_{\\ell=1}^n t_{i\\ell} = \\frac{1}{n} \\sum_{\\ell=1}^n (0.6 + A_i p_\\ell) = 0.6 + A_i \\left(\\frac{1}{n} \\sum_{\\ell=1}^n p_\\ell\\right) = 0.6 + A_i \\bar{p}\n$$\n然后，与均值的偏差是 $t_{i\\ell} - \\bar{t}_i = (0.6 + A_i p_\\ell) - (0.6 + A_i \\bar{p}) = A_i(p_\\ell - \\bar{p})$。\n将此代入方差公式：\n$$\nV_i^2 = \\frac{1}{n}\\sum_{\\ell=1}^n \\left(A_i(p_\\ell - \\bar{p})\\right)^2 = A_i^2 \\left(\\frac{1}{n}\\sum_{\\ell=1}^n (p_\\ell - \\bar{p})^2\\right) = A_i^2 \\sigma_p^2\n$$\n其中 $\\sigma_p$ 是基础模式 $p$ 的总体标准差。由于所有振幅 $A_i$ 都是正数，因此 $V_i = A_i \\sigma_p$。\n\n让我们为给定的模式 $p = [\\,-0.3,\\,-0.2,\\,-0.1,\\,0.0,\\,0.1,\\,0.2,\\,0.3,\\,-0.1,\\,0.1,\\,0.0,\\,-0.2,\\,0.2\\,]$ 计算 $\\sigma_p$。\n元素之和为 $\\sum p_\\ell = 0$，所以均值 $\\bar{p}=0$。\n平方和为 $\\sum p_\\ell^2 = 2 \\times (0.3^2 + 0.2^2 + 0.1^2 + 0.0^2) + 2 \\times 0.1^2 + 2 \\times 0.2^2 =  2 \\times (0.09+0.04+0.01) + 0.02 + 0.08 = 2 \\times 0.14 + 0.1 = 0.28+0.1 = 0.38$。\n等等，给定的向量是 $p = [\\,-0.3,\\,-0.2,\\,-0.1,\\,0.0,\\,0.1,\\,0.2,\\,0.3,\\,-0.1,\\,0.1,\\,0.0,\\,-0.2,\\,0.2\\,]$。重新计算平方和：\n$(-0.3)^2 + (-0.2)^2 + (-0.1)^2 + 0.0^2 + 0.1^2 + 0.2^2 + 0.3^2 + (-0.1)^2 + 0.1^2 + 0.0^2 + (-0.2)^2 + 0.2^2 = 0.09+0.04+0.01+0+0.01+0.04+0.09+0.01+0.01+0+0.04+0.04 = 0.38$。\n所以，$\\sum p_\\ell^2 = 0.38$。总体方差是 $\\sigma_p^2 = \\frac{1}{n} \\sum p_\\ell^2 = 0.38 / 12$。\n标准差是 $\\sigma_p = \\sqrt{0.38 / 12} \\approx 0.177951$。\n\n现在，我们使用每个训练参与者指定的振幅 $A_i$ 来计算 $V_i = A_i \\sigma_p$：\n- $A_1=0.16 \\implies V_1 \\approx 0.028472$\n- $A_2=0.20 \\implies V_2 \\approx 0.035590$\n- $A_3=0.24 \\implies V_3 \\approx 0.042708$\n- $A_4=0.28 \\implies V_4 \\approx 0.049826$\n- $A_5=0.32 \\implies V_5 \\approx 0.056944$\n- $A_6=0.36 \\implies V_6 \\approx 0.064062$\n- $A_7=0.40 \\implies V_7 \\approx 0.071181$\n- $A_8=0.44 \\implies V_8 \\approx 0.078299$\n\n这8个值构成了因变量集合 $\\{V_i\\}_{i=1}^8$。\n\n**第3步：拟合线性回归模型**\n\n模型是 $\\hat{V} = a + b C$。OLS参数 $(a,b)$ 使用以下公式找到：\n$$\nb = \\frac{\\sum_{i=1}^8 (C_i - \\bar{C})(V_i - \\bar{V})}{\\sum_{i=1}^8 (C_i - \\bar{C})^2}, \\quad a = \\bar{V} - b\\,\\bar{C}\n$$\n首先，我们计算训练数据向量 $\\{C_i\\}$ 和 $\\{V_i\\}$ 的均值：\n- $\\bar{C} = \\frac{1}{8} \\sum C_i \\approx 0.567434$\n- $\\bar{V} = \\frac{1}{8} \\sum V_i \\approx 0.053385$\n\n接下来，我们计算斜率 $b$ 的分子（协方差项）和分母（方差项）：\n- $\\sum (C_i - \\bar{C})(V_i - \\bar{V}) \\approx 0.005117$\n- $\\sum (C_i - \\bar{C})^2 \\approx 0.088001$\n\n斜率为 $b = 0.005117 / 0.088001 \\approx 0.058146$。\n截距为 $a = \\bar{V} - b\\bar{C} \\approx 0.053385 - (0.058146 \\times 0.567434) \\approx 0.020412$。\n\n最终的预测模型大约是 $\\hat{V} = 0.020412 + 0.058146 C$。\n\n**第4步：对测试用例进行预测**\n\n我们现在使用这个模型来为3个测试用例预测RT变异性。对于每个用例，我们首先从提供的相关性数据计算其连接性指数 $C_{test}$，然后将其代入回归方程。\n\n- **测试用例 1**：$r_{test,1} = [0.60, 0.58, 0.62, 0.59, 0.61, 0.60]$\n  - $C_{test,1} = \\frac{1}{6} \\sum \\operatorname{atanh}(r_{test,1}) \\approx 0.693383$\n  - $\\hat{V}_{test,1} = a + b C_{test,1} \\approx 0.020412 + (0.058146 \\times 0.693383) \\approx 0.060714$\n\n- **测试用例 2**：$r_{test,2} = [0.05, 0.08, 0.02, 0.04, 0.06, 0.03]$\n  - $C_{test,2} = \\frac{1}{6} \\sum \\operatorname{atanh}(r_{test,2}) \\approx 0.046726$\n  - $\\hat{V}_{test,2} = a + b C_{test,2} \\approx 0.020412 + (0.058146 \\times 0.046726) \\approx 0.023129$\n\n- **测试用例 3**：$r_{test,3} = [0.82, 0.80, 0.83, 0.81, 0.84, 0.82]$\n  - $C_{test,3} = \\frac{1}{6} \\sum \\operatorname{atanh}(r_{test,3}) \\approx 1.158098$\n  - $\\hat{V}_{test,3} = a + b C_{test,3} \\approx 0.020412 + (0.058146 \\times 1.158098) \\approx 0.087799$\n\n对于测试用例1、2和3，最终预测的RT变异性值（四舍五入到六位小数）分别约为 $0.060714$、$0.023129$ 和 $0.087799$ 秒。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and implements a predictive model for RT variability from DMN connectivity.\n    \"\"\"\n\n    # --- Training Data Specification ---\n    # Correlation coefficients for N=8 training participants (M=6 pairs each)\n    training_correlations = [\n        [0.15, 0.20, 0.10, 0.12, 0.18, 0.16],  # P1\n        [0.25, 0.28, 0.22, 0.24, 0.26, 0.27],  # P2\n        [0.35, 0.33, 0.32, 0.36, 0.37, 0.34],  # P3\n        [0.45, 0.48, 0.42, 0.44, 0.46, 0.47],  # P4\n        [0.55, 0.52, 0.56, 0.58, 0.54, 0.57],  # P5\n        [0.65, 0.62, 0.63, 0.66, 0.67, 0.64],  # P6\n        [0.70, 0.72, 0.68, 0.69, 0.71, 0.73],  # P7\n        [0.75, 0.78, 0.74, 0.76, 0.77, 0.79],  # P8\n    ]\n\n    # Amplitudes for generating reaction times\n    training_amplitudes = [0.16, 0.20, 0.24, 0.28, 0.32, 0.36, 0.40, 0.44]\n\n    # Base pattern for reaction time trials\n    base_pattern = np.array([-0.3, -0.2, -0.1, 0.0, 0.1, 0.2, 0.3, -0.1, 0.1, 0.0, -0.2, 0.2])\n\n    # --- Test Suite Data ---\n    test_cases_correlations = [\n        [0.60, 0.58, 0.62, 0.59, 0.61, 0.60],  # Test case 1\n        [0.05, 0.08, 0.02, 0.04, 0.06, 0.03],  # Test case 2\n        [0.82, 0.80, 0.83, 0.81, 0.84, 0.82],  # Test case 3\n    ]\n\n    # === Step 1: Compute training variables C_i and V_i ===\n\n    # Compute DMN connectivity index (C_i) for each training participant\n    # C_i is the mean of the Fisher z-transformed correlations.\n    C_train = np.array([\n        np.mean(np.arctanh(r_set)) for r_set in training_correlations\n    ])\n\n    # Compute RT variability (V_i) for each training participant\n    # V_i is the population standard deviation of reaction times.\n    # As derived, V_i = A_i * population_std(base_pattern).\n    # numpy.std calculates population std by default (ddof=0).\n    sigma_p = np.std(base_pattern)\n    V_train = np.array(training_amplitudes) * sigma_p\n\n    # === Step 2: Fit the linear regression model ===\n    # Model: V_hat = a + b*C\n    # Using ordinary least squares (OLS) formulas.\n\n    # Calculate means of the training data vectors\n    C_mean = np.mean(C_train)\n    V_mean = np.mean(V_train)\n\n    # Calculate the slope (b)\n    numerator = np.sum((C_train - C_mean) * (V_train - V_mean))\n    denominator = np.sum((C_train - C_mean)**2)\n    b = numerator / denominator\n\n    # Calculate the intercept (a)\n    a = V_mean - b * C_mean\n\n    # === Step 3: Make predictions for test cases ===\n    \n    # Compute DMN connectivity index (C_test) for each test case\n    C_test = np.array([\n        np.mean(np.arctanh(r_set)) for r_set in test_cases_correlations\n    ])\n    \n    # Predict RT variability (V_hat) using the fitted model\n    V_predicted = a + b * C_test\n\n    # --- Format and print the final output ---\n    results = [f\"{val:.6f}\" for val in V_predicted]\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "5056143"}, {"introduction": "大脑的功能组织并非一成不变，而是在时间尺度上动态变化的。传统的静态功能连接分析往往忽略了这种时间的丰富性，而动态功能连接（dFC）则致力于捕捉这些变化。在本练习中，你将分析一个已被划分为不同“脑网络状态”的时间序列，通过计算特定状态（如DMN）的“停留时间”和状态之间的“转移概率”，来量化大脑网络的动态特性[@problem_id:5056369]。这项前沿实践将引导你超越静态的连接图谱，探索大脑的“亚稳态”（metastability）等核心概念，从而更深入地理解大脑功能的高度灵活性和复杂性。", "problem": "给定从静息态功能磁共振成像数据中，通过 $k$-均值聚类得到的动态功能连接 (dFC) 状态的离散时间序列。这些状态被标记为从 $0$ 到 $K-1$ 的整数，其中默认模式网络 (DMN) 被赋予一个特定的标签。目标是计算 DMN 的驻留时间分布，估计状态间的转移概率矩阵，并根据一个有原则的、定量的决策规则来确定 DMN 是否表现出亚稳态动力学。\n\n基本原理和定义：\n- 一个离散时间马尔可夫链由一组状态 $\\{0,1,\\dots,K-1\\}$ 和一个转移概率矩阵 $P$ 定义，其元素为 $P_{ij} = \\Pr(s_{t+1}=j \\mid s_t=i)$，其中 $(s_t)$ 表示在时间 $t$ 的状态标签。\n- 对于给定状态 $i$ 的驻留时间，是指在转移到 $s_{t+1} \\neq i$ 之前，$s_t = i$ 的最大连续运行的持续时间。在马尔可夫链中，如果自转移概率为 $p = P_{ii}$，则以步数计算的理论驻留时间遵循均值为 $1/(1-p)$ 的几何分布；在经验上，我们通过计算观测序列中的连续运行来估计驻留时间。\n- 从状态 $i$ 的一个出口分布 $\\{q_j\\}_{j \\neq i}$ 的香农熵（以比特为单位）定义为 $H = -\\sum_{j \\neq i} q_j \\log_2 q_j$，其中 $q_j$ 是到非自身状态的出口概率，经过归一化，使得在至少存在一个出口时，$\\sum_{j \\neq i} q_j = 1$。\n\n您的程序必须：\n1. 对于每个测试用例，从一个游程规范中构建完整的标签序列 $\\{s_t\\}_{t=1}^N$。每个块 $(x,n)$ 表示在状态 $x$ 中连续的 $n$ 个时间点。总时间点数 $N$ 是所有块的 $n$ 之和。状态是整数标签，$K$ 是允许的唯一状态总数。\n2. 通过对 $t=1,\\dots,N-1$ 的所有连续对 $(s_t, s_{t+1})$ 进行计数，计算转移计数 $C_{ij}$。然后通过行归一化计算转移概率矩阵 $P$：对于每个 $i$，$P_{ij} = C_{ij} / \\sum_{j'} C_{ij'}$。如果某行的和为 $0$，则将 $P$ 的该行定义为全零。\n3. 对于标记为 $d$ 的 DMN 状态，计算以秒为单位的驻留时间分布：识别所有 $s_t=d$ 的最大连续运行，设其运行长度为 $\\ell$（以时间步为单位），并乘以重复时间 $\\Delta t$（以秒为单位）以获得驻留持续时间 $\\tau = \\ell \\cdot \\Delta t$。报告经验平均驻留时间 $\\bar{\\tau}$ 和经验标准差 $\\sigma_{\\tau}$，两者均以秒为单位。\n4. 计算 DMN 的自转移概率 $p_{\\text{self}} = P_{dd}$。\n5. 通过将来自 $d$ 的非自转移概率归一化为 $q_j = \\frac{P_{dj}}{1 - P_{dd}}$（对于 $j \\neq d$，当 $1 - P_{dd} > 0$ 时）来计算 DMN 的出口熵 $H_{\\text{exit}}$（以比特为单位）。如果 $1 - P_{dd} = 0$ 或者 DMN 在序列中未出现，则设置 $H_{\\text{exit}} = 0$。\n6. 使用以下定量规则判断 DMN 是否表现出亚稳态动力学，该规则的动机是亚稳态应是长寿命但非吸收性的，并具有多个出口路径：\n   - $p_{\\text{self}} \\in [p_{\\min}, p_{\\max})$，其中 $p_{\\min} = 0.75$ 且 $p_{\\max} = 0.98$，\n   - $\\bar{\\tau} \\in [\\tau_{\\min}, \\tau_{\\max}]$，其中 $\\tau_{\\min} = 4.0$ 秒且 $\\tau_{\\max} = 30.0$ 秒，\n   - $H_{\\text{exit}} \\geq H_{\\min}$，其中 $H_{\\min} = 0.7$ 比特。\n   如果 DMN 从未出现，则定义 $\\bar{\\tau} = 0$, $\\sigma_{\\tau} = 0$, $p_{\\text{self}} = 0$, $H_{\\text{exit}} = 0$，并分类为非亚稳态。\n7. 以秒为单位表示驻留时间。在报告 $\\bar{\\tau}$、$\\sigma_{\\tau}$、$p_{\\text{self}}$ 和 $H_{\\text{exit}}$ 时，将每个浮点数四舍五入到三位小数。亚稳态的判定结果是一个布尔值。\n\n测试套件：\n对于所有用例，使用 $K = 4$，DMN 标签 $d = 1$，重复时间 $\\Delta t = 0.8$ 秒。每个测试用例的游程块规范 $(x,n)$ 列表如下：\n\n- 用例 1（具有多个出口和中等 DMN 驻留时间的理想路径）：\n  - 块： $(1,8)$, $(2,3)$, $(1,10)$, $(3,3)$, $(1,6)$, $(0,2)$, $(1,5)$, $(3,3)$, $(1,7)$, $(0,2)$, $(2,1)$, $(3,1)$.\n- 用例 2（类吸收性 DMN，具有非常长的驻留时间和单一出口目标）：\n  - 块： $(1,50)$, $(2,3), (1,40), (2,2), (1,60), (2,1)$.\n- 用例 3（快速切换的 DMN，具有非常短的驻留时间）：\n  - 块： $(0,3), (1,1), (0,2), (1,1), (3,2), (1,2), (2,1), (1,1), (0,1), (3,1), (2,1)$.\n- 用例 4（边缘情况，DMN 从未出现）：\n  - 块： $(0,2), (2,2), (3,2), (0,2), (2,1), (3,1)$.\n\n最终输出格式：\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。每个元素对应一个测试用例，并且本身必须是 $[\\bar{\\tau}, \\sigma_{\\tau}, p_{\\text{self}}, H_{\\text{exit}}, \\text{metastable}]$ 形式的列表，其中浮点数四舍五入到三位小数，时间量以秒为单位。例如，输出应如下所示：$[[a_1,b_1,c_1,d_1,e_1],[a_2,b_2,c_2,d_2,e_2],\\dots]$。", "solution": "用户提供的问题是计算神经生物学领域中一个定义明确的计算任务，要求分析代表动态大脑活动的离散时间状态序列。该问题具有科学依据、数学上精确且算法上是可行的。所有定义、参数和评估标准都已明确说明，使得该问题可以进行完整求解。\n\n将遵循问题陈述中指定的任务顺序来开发解决方案。对于每个测试用例，我们将执行以下步骤：\n\n1.  **序列和转移矩阵的构建**：我们得到了状态序列的游程编码。与其显式地构建完整的序列向量（对于长序列可能会占用大量内存），我们可以直接计算转移计数矩阵 $C$。对于序列中不是最后一个块的每个块 $(x, n)$，它贡献了 $n-1$ 个类型为 $(x, x)$ 的自转移。如果后续块是 $(y, m)$，则会发生一个类型为 $(x,y)$ 的额外转移。最后一个块 $(x_{last}, n_{last})$ 仅贡献 $n_{last}-1$ 个自转移。状态总数为 $K=4$。转移计数矩阵 $C$ 将是一个 $4 \\times 4$ 的矩阵，其中 $C_{ij}$ 存储从状态 $i$ 到状态 $j$ 的观测转移次数。\n\n    转移概率矩阵 $P$ 是通过对 $C$ 进行行归一化得到的。对于每个状态 $i$，转移到状态 $j$ 的概率由 $P_{ij} = C_{ij} / \\sum_{k=0}^{K-1} C_{ik}$ 给出。如果一个状态 $i$ 从未被观测到，或者仅作为整个序列的最终状态被观测到，其在 $C$ 中的对应行和将为零。根据问题规范， $P$ 中的相应行将被设置为全零。\n\n2.  **DMN 驻留时间分析**：默认模式网络 (DMN) 被赋予状态标签 $d=1$。一个驻留期是一个状态的最大连续运行。输入的游程编码直接提供了这些信息。我们识别所有 $x=d$ 的块 $(x, n)$。相应的长度 $n$ 的列表给出了以时间步为单位的驻留时间，我们将其表示为 $\\{\\ell_i\\}$。给定重复时间 $\\Delta t = 0.8$ 秒，以秒为单位的驻留持续时间为 $\\{\\tau_i\\} = \\{\\ell_i \\cdot \\Delta t\\}$。然后我们计算这组持续时间的经验均值 $\\bar{\\tau}$ 和总体标准差 $\\sigma_{\\tau}$。如果 DMN 状态从未出现，则按规定将所有统计值设置为零。\n\n3.  **DMN 自转移和出口熵**：DMN 的自转移概率 $p_{\\text{self}}$ 是转移矩阵中的元素 $P_{dd}$。离开 DMN 状态的总概率是 $1 - p_{\\text{self}}$。如果这个出口概率为正，我们可以定义一个归一化的出口分布 $\\{q_j\\}_{j \\neq d}$，其中 $q_j = P_{dj} / (1 - p_{\\text{self}})$。这个出口分布的香non熵 $H_{\\text{exit}}$ 以比特为单位，使用公式 $H_{\\text{exit}} = - \\sum_{j \\neq d, q_j > 0} q_j \\log_2 q_j$ 计算。如果总出口概率为零（即 $p_{\\text{self}}=1$）或者 DMN 状态从未出现，则 $H_{\\text{exit}}$ 定义为 $0$。\n\n4.  **亚稳态分类**：应用一个定量规则来确定 DMN 动力学是否是亚稳态的。这需要同时满足三个条件：\n    a. 自转移概率 $p_{\\text{self}}$ 必须在区间 $[0.75, 0.98)$ 内。\n    b. 平均驻留时间 $\\bar{\\tau}$ 必须在范围 $[4.0, 30.0]$ 秒内（含边界）。\n    c. 出口熵 $H_{\\text{exit}}$ 必须至少为 $0.7$ 比特。\n    如果所有三个条件都满足，DMN 就被分类为亚稳态 (True)；否则，就不是 (False)。\n\n将此完整过程系统地应用于每个测试用例，并按要求将最终的数值结果四舍五入到三位小数。最终输出的结构是一个列表的列表，其中每个内部列表包含单个测试用例的计算指标。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    It orchestrates the processing of each case and formats the final output.\n    \"\"\"\n\n    def process_case(K, d, dt, blocks, decision_rules):\n        \"\"\"\n        Processes a single test case to calculate DMN dynamics statistics\n        and determine metastability.\n\n        Args:\n            K (int): Total number of states.\n            d (int): Label for the DMN state.\n            dt (float): Repetition time in seconds.\n            blocks (list): Run-length specification of the state sequence.\n            decision_rules (dict): Dictionary of thresholds for metastability.\n\n        Returns:\n            list: A list containing [mean_tau, std_tau, p_self, h_exit, is_metastable].\n        \"\"\"\n        # Check if the DMN state appears in the sequence at all.\n        dmn_present = any(block[0] == d for block in blocks)\n        if not dmn_present:\n            # Special case as defined in the problem statement\n            return [0.0, 0.0, 0.0, 0.0, False]\n\n        # 1. Compute transition count matrix C\n        C = np.zeros((K, K), dtype=float)\n        if len(blocks) > 1:\n            for i in range(len(blocks) - 1):\n                state, length = blocks[i]\n                next_state, _ = blocks[i+1]\n                if length > 0:\n                    C[state, state] += length - 1\n                C[state, next_state] += 1\n        \n        # Handle the last block's self-transitions\n        last_state, last_length = blocks[-1]\n        if last_length > 0:\n            C[last_state, last_state] += last_length - 1\n\n        # 2. Compute transition probability matrix P\n        P = np.zeros((K, K), dtype=float)\n        row_sums = C.sum(axis=1)\n        # Suppress division by zero warnings for rows that sum to 0\n        with np.errstate(divide='ignore', invalid='ignore'):\n            P = np.nan_to_num(C / row_sums[:, np.newaxis])\n\n        # 3. Compute DMN dwell time statistics\n        dwell_lengths_steps = [block[1] for block in blocks if block[0] == d]\n        dwell_durations_sec = np.array(dwell_lengths_steps) * dt\n        \n        mean_tau = np.mean(dwell_durations_sec) if dwell_durations_sec.size > 0 else 0.0\n        # Use ddof=0 for population standard deviation of the observed sample\n        std_tau = np.std(dwell_durations_sec, ddof=0) if dwell_durations_sec.size > 0 else 0.0\n\n        # 4. Compute DMN self-transition probability\n        p_self = P[d, d]\n\n        # 5. Compute DMN exit entropy\n        h_exit = 0.0\n        p_exit_total = 1.0 - p_self\n        # Use a small epsilon for floating point comparison\n        if p_exit_total > 1e-9:\n            exit_probs = P[d, :].copy()\n            exit_probs[d] = 0.0\n            q_dist = exit_probs / p_exit_total\n            \n            q_nonzero = q_dist[q_dist > 1e-9]\n            if q_nonzero.size > 0:\n                h_exit = -np.sum(q_nonzero * np.log2(q_nonzero))\n\n        # 6. Decide on metastability\n        p_min, p_max = decision_rules['p_self_range']\n        tau_min, tau_max = decision_rules['tau_range']\n        h_min = decision_rules['h_min']\n\n        cond1 = (p_self >= p_min) and (p_self < p_max)\n        cond2 = (mean_tau >= tau_min) and (mean_tau <= tau_max)\n        cond3 = (h_exit >= h_min)\n        \n        is_metastable = cond1 and cond2 and cond3\n\n        # 7. Format results\n        return [\n            round(mean_tau, 3),\n            round(std_tau, 3),\n            round(p_self, 3),\n            round(h_exit, 3),\n            is_metastable\n        ]\n\n    # Global parameters for all test cases\n    K = 4\n    dmn_label = 1\n    repetition_time = 0.8  # seconds\n    \n    # Metastability decision rules\n    decision_rules = {\n        'p_self_range': (0.75, 0.98),\n        'tau_range': (4.0, 30.0),\n        'h_min': 0.7\n    }\n\n    # Test suite from the problem statement\n    test_cases = [\n        # Case 1 (happy path)\n        [(1,8), (2,3), (1,10), (3,3), (1,6), (0,2), (1,5), (3,3), (1,7), (0,2), (2,1), (3,1)],\n        # Case 2 (absorbing-like DMN)\n        [(1,50), (2,3), (1,40), (2,2), (1,60), (2,1)],\n        # Case 3 (fast-switching DMN)\n        [(0,3), (1,1), (0,2), (1,1), (3,2), (1,2), (2,1), (1,1), (0,1), (3,1), (2,1)],\n        # Case 4 (edge case, DMN never appears)\n        [(0,2), (2,2), (3,2), (0,2), (2,1), (3,1)],\n    ]\n\n    results = []\n    for blocks in test_cases:\n        result = process_case(K, dmn_label, repetition_time, blocks, decision_rules)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "5056369"}]}