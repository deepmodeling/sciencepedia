{"hands_on_practices": [{"introduction": "我们如何量化注意力对单个神经元分辨能力的提升？一种经典的方法是将其建模为信号增强和噪声降低的过程。本练习将运用信号检测论（Signal Detection Theory, SDT）的框架，通过计算判别力指数 $d'$ 的变化，来具体化注意力如何通过改变神经元的平均发放率和发放变异性来增强其对不同刺激的编码精度。[@problem_id:5039177]", "problem": "视觉皮层的一个皮层神经元对两种刺激类别（一个偏好刺激和一个非偏好刺激）产生响应，其响应通过在固定观察窗口内测量的尖峰发放计数来衡量。根据经验，对于这个神经元和这个观察窗口，两种类别的尖峰发放计数变异性可以很好地用等方差高斯统计来近似。在此近似下，信号检测理论（SDT）中用于区分两种类别的判别力指数，是根据它们平均尖峰发放计数的差异及其共同标准差来定义的。据假设，注意力通过增加平均发放率和减少变异性来对神经响应进行乘法调制。具体来说，假设注意力将两个类别的均值都乘以一个因子 $(1+g)$（其中 $g=0.20$），并将共同方差乘以一个因子 $(1-v)$（其中 $v=0.15$）。在这些假设和等方差高斯模型下，从第一性原理推导判别力指数如何随这些乘法变化而缩放。然后，当 $g=0.20$ 和 $v=0.15$ 时，计算判别力指数的乘法变化因子 $R$，其定义为 $R=d'_{\\mathrm{att}}/d'_{\\mathrm{base}}$。将最终结果表示为一个无量纲数，并四舍五入到四位有效数字。", "solution": "该问题陈述被评估为有效。它在科学上基于将信号检测理论（SDT）应用于神经科学中一个公认的注意力调制模型。该问题是适定的，为得到唯一解提供了所有必需的参数和定义。语言客观且精确。\n\n我们被要求推导在注意力调制下判别力指数 $d'$ 的缩放方式，并计算由此产生的乘法变化因子。对于从均值为 $\\mu_1$ 和 $\\mu_2$、共同标准差为 $\\sigma$ 的高斯分布中抽取的两个响应，其判别力指数定义为：\n$$\nd' = \\frac{|\\mu_1 - \\mu_2|}{\\sigma}\n$$\n在此背景下，这两个响应是针对偏好刺激和非偏好刺激的尖峰发放计数。设 $\\mu_p$ 和 $\\mu_n$ 分别为偏好刺激和非偏好刺激的平均尖峰发放计数。不失一般性，我们假设 $\\mu_p > \\mu_n$。\n\n首先，我们定义基线（无注意力）条件下的判别力，记为 $d'_{\\mathrm{base}}$。设基线均值为 $\\mu_{p, \\mathrm{base}}$ 和 $\\mu_{n, \\mathrm{base}}$，共同基线方差为 $\\sigma_{\\mathrm{base}}^2$。因此，基线标准差为 $\\sigma_{\\mathrm{base}} = \\sqrt{\\sigma_{\\mathrm{base}}^2}$。\n$$\nd'_{\\mathrm{base}} = \\frac{\\mu_{p, \\mathrm{base}} - \\mu_{n, \\mathrm{base}}}{\\sigma_{\\mathrm{base}}}\n$$\n\n接下来，我们考虑有注意力的条件。根据问题描述，注意力引入了乘法缩放。均值按因子 $(1+g)$ 缩放，方差按因子 $(1-v)$ 缩放。设在有注意力条件下的参数用下标 'att' 表示。\n\n新的均值由下式给出：\n$$\n\\mu_{p, \\mathrm{att}} = \\mu_{p, \\mathrm{base}}(1+g)\n$$\n$$\n\\mu_{n, \\mathrm{att}} = \\mu_{n, \\mathrm{base}}(1+g)\n$$\n新的方差为：\n$$\n\\sigma_{\\mathrm{att}}^2 = \\sigma_{\\mathrm{base}}^2(1-v)\n$$\n新的标准差是新方差的平方根：\n$$\n\\sigma_{\\mathrm{att}} = \\sqrt{\\sigma_{\\mathrm{base}}^2(1-v)} = \\sigma_{\\mathrm{base}}\\sqrt{1-v}\n$$\n\n现在我们可以写出注意力条件下的判别力指数 $d'_{\\mathrm{att}}$ 的表达式：\n$$\nd'_{\\mathrm{att}} = \\frac{\\mu_{p, \\mathrm{att}} - \\mu_{n, \\mathrm{att}}}{\\sigma_{\\mathrm{att}}}\n$$\n将有注意力条件下的参数表达式代入此方程，得到：\n$$\nd'_{\\mathrm{att}} = \\frac{\\mu_{p, \\mathrm{base}}(1+g) - \\mu_{n, \\mathrm{base}}(1+g)}{\\sigma_{\\mathrm{base}}\\sqrt{1-v}}\n$$\n我们可以从分子中提出因子 $(1+g)$：\n$$\nd'_{\\mathrm{att}} = \\frac{(\\mu_{p, \\mathrm{base}} - \\mu_{n, \\mathrm{base}})(1+g)}{\\sigma_{\\mathrm{base}}\\sqrt{1-v}}\n$$\n为了揭示缩放关系，我们可以重新排列各项，以分离出 $d'_{\\mathrm{base}}$ 的表达式：\n$$\nd'_{\\mathrm{att}} = \\left(\\frac{\\mu_{p, \\mathrm{base}} - \\mu_{n, \\mathrm{base}}}{\\sigma_{\\mathrm{base}}}\\right) \\cdot \\frac{1+g}{\\sqrt{1-v}}\n$$\n通过代入 $d'_{\\mathrm{base}}$ 的定义，我们推导出缩放定律：\n$$\nd'_{\\mathrm{att}} = d'_{\\mathrm{base}} \\cdot \\frac{1+g}{\\sqrt{1-v}}\n$$\n这个方程表示了由于乘法注意力调制引起的判别力指数的缩放。\n\n问题要求我们计算乘法变化因子 $R$，其定义为 $R = d'_{\\mathrm{att}} / d'_{\\mathrm{base}}$。从推导出的关系中，我们发现：\n$$\nR = \\frac{d'_{\\mathrm{att}}}{d'_{\\mathrm{base}}} = \\frac{1+g}{\\sqrt{1-v}}\n$$\n问题给出了调制参数的具体值：$g=0.20$ 和 $v=0.15$。我们将这些值代入 $R$ 的表达式中：\n$$\nR = \\frac{1+0.20}{\\sqrt{1-0.15}} = \\frac{1.20}{\\sqrt{0.85}}\n$$\n现在，我们计算数值：\n$$\nR \\approx \\frac{1.20}{0.9219544457} \\approx 1.30158098\n$$\n问题指定最终答案应四舍五入到四位有效数字。前四位有效数字是 $1$、$3$、$0$ 和 $1$。第五位数字是 $5$，因此我们将第四位数字向上取整。\n$$\nR \\approx 1.302\n$$", "answer": "$$\\boxed{1.302}$$", "id": "5039177"}, {"introduction": "注意力不仅增强对目标的表征，还会主动抑制干扰物。除法归一化（divisive normalization）模型是解释这种竞争性相互作用的标准皮层计算模型。通过这个练习，你将计算一个简化网络中受注意和未受注意神经元的发放率，从而亲身体验共享的抑制性归一化池如何实现“赢家通吃”式的竞争性抑制。[@problem_id:5039176]", "problem": "在构成选择性注意基础的皮层回路中，一个得到充分支持的计算性描述是除法归一化模型。在该模型中，对刺激 $i$ 具有选择性的神经元的响应，是由兴奋性驱动和汇集的抑制性驱动之间平衡的结果。考虑一个与视觉皮层和顶叶区域的证据相符的最小双刺激归一化回路：每个神经元接收一个与刺激驱动和注意力增益成正比的兴奋性输入，以及一个来自抑制性归一化池的抑制性输入，该归一化池通过正权重将所有刺激经注意力调制的驱动加和起来。一个非零的基线项捕捉了背景活动，并防止了除以零的错误。形式上，设兴奋性驱动为 $E_{i} = g_{i} s_{i}$，归一化池为 $N_{i} = \\sum_{j} w_{ij} g_{j} s_{j}$（其中 $w_{ij} \\geq 0$），瞬时发放率为\n$$\nr_{i} = \\frac{E_{i}}{\\sigma + N_{i}}.\n$$\n给定两个刺激，其驱动分别为 $s_{1} = 10$ 和 $s_{2} = 8$，均匀的归一化权重为 $w_{ij} = 1$，基线为 $\\sigma = 2$，针对刺激 $1$ 的注意力增益为 $g_{1} = 1.4$。假设未被注意的刺激其增益为 $g_{2} = 1$。\n\n从上述定义和除法归一化框架出发，推导 $r_{1}$ 和 $r_{2}$ 的表达式并计算它们的数值。然后，结合归一化池和基线，简要解释未被注意的刺激所经历的竞争性抑制。最终答案必须是数对 $(r_{1}, r_{2})$，表示为未经四舍五入的精确值，且不得包含单位。", "solution": "经评估，该问题陈述是有效的。它在科学上基于计算神经科学中已建立的除法归一化模型，在数学上是适定的，所有必需参数均已提供，并以客观、正式的语言表述。其中没有矛盾、模糊之处或事实性错误。\n\n对刺激 $i$ 具有选择性的神经元的瞬时发放率 $r_{i}$ 由除法归一化方程给出：\n$$\nr_{i} = \\frac{E_{i}}{\\sigma + N_{i}}\n$$\n其中 $E_{i}$ 是兴奋性驱动， $N_{i}$ 是除法归一化池， $\\sigma$ 是一个基线项。\n\n神经元 $i$ 的兴奋性驱动定义为 $E_{i} = g_{i} s_{i}$，其中 $g_{i}$ 是注意力增益， $s_{i}$ 是刺激驱动。\n神经元 $i$ 的归一化池定义为 $N_{i} = \\sum_{j} w_{ij} g_{j} s_{j}$，它将感受野中所有刺激经加权和注意力调制的驱动加和起来。\n\n我们给定一个双刺激情景 ($i, j \\in \\{1, 2\\}$)，参数如下：\n- 刺激驱动：$s_{1} = 10$， $s_{2} = 8$\n- 注意力增益：$g_{1} = 1.4$ (被注意)， $g_{2} = 1$ (未被注意)\n- 归一化权重：对所有 $i, j$ 均有 $w_{ij} = 1$。\n- 基线项：$\\sigma = 2$\n\n首先，我们推导兴奋性驱动 $E_{1}$ 和 $E_{2}$ 的具体表达式。\n使用 $E_{i} = g_{i} s_{i}$：\n$$\nE_{1} = g_{1} s_{1} = (1.4)(10) = 14\n$$\n$$\nE_{2} = g_{2} s_{2} = (1)(8) = 8\n$$\n\n接下来，我们推导归一化池的表达式。题目说明权重是均匀的 $w_{ij}=1$。这意味着两个神经元的归一化池是相同的，即 $N_{1} = N_{2}$。我们用 $N$ 表示这个共同的归一化池。\n$$\nN = N_{1} = \\sum_{j=1}^{2} w_{1j} g_{j} s_{j} = w_{11} g_{1} s_{1} + w_{12} g_{2} s_{2}\n$$\n$$\nN = N_{2} = \\sum_{j=1}^{2} w_{2j} g_{j} s_{j} = w_{21} g_{1} s_{1} + w_{22} g_{2} s_{2}\n$$\n代入对所有 $i,j$ 均成立的 $w_{ij} = 1$：\n$$\nN = (1) g_{1} s_{1} + (1) g_{2} s_{2} = g_{1} s_{1} + g_{2} s_{2}\n$$\n现在，我们计算归一化池 $N$ 的数值：\n$$\nN = (1.4)(10) + (1)(8) = 14 + 8 = 22\n$$\n\n有了这些分量，我们就可以计算发放率 $r_{1}$ 和 $r_{2}$。\n对于神经元 1 (被注意)：\n$$\nr_{1} = \\frac{E_{1}}{\\sigma + N} = \\frac{14}{2 + 22} = \\frac{14}{24} = \\frac{7}{12}\n$$\n对于神经元 2 (未被注意)：\n$$\nr_{2} = \\frac{E_{2}}{\\sigma + N} = \\frac{8}{2 + 22} = \\frac{8}{24} = \\frac{1}{3}\n$$\n\n发放率的数值为 $r_{1} = 7/12$ 和 $r_{2} = 1/3$。\n\n对竞争性抑制的解释：\n未被注意的神经元（神经元 2）的响应由 $r_{2} = \\frac{E_{2}}{\\sigma + N} = \\frac{g_{2}s_{2}}{\\sigma + g_{1}s_{1} + g_{2}s_{2}}$ 给出。分母代表总的抑制性驱动。它由一个恒定的基线抑制 $\\sigma$ 和由刺激驱动的归一化池 $N = g_{1}s_{1} + g_{2}s_{2}$ 组成。关键在于，归一化池汇集了来自*所有*刺激经注意力调制的驱动。当注意力指向刺激 1 时，其增益 $g_{1}$ 增加 ($g_{1}=1.4$)。这提高了刺激 1 对共享归一化池的贡献 ($g_{1}s_{1} = 14$)。这个更大的池值 $N=22$ 会除法性地抑制*所有*神经元的响应，包括神经元 2。因此，被注意刺激的兴奋性驱动增强，导致对与之竞争的、未被注意的刺激产生更强的抑制。这就是除法归一化框架内竞争性抑制的机制。基线项 $\\sigma$ 增加了一个恒定的、非刺激特异性的抑制，确保分母始终大于零，并为总抑制效应设定了一个下限。", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{7}{12}  \\frac{1}{3} \\end{pmatrix}}\n$$", "id": "5039176"}, {"introduction": "大脑的决策依赖于对整个神经元群体活动的解码，而不仅仅是单个神经元。神经元之间共享的噪声（即噪声相关性）会限制群体编码的信息量。本练习将探讨注意力如何通过降低神经元间的噪声相关性来提升信息编码的保真度，让你从理论上计算并理解这种去相关化机制对下游解码器性能的显著提升。[@problem_id:5039157]", "problem": "在皮层中，一个被广泛观察到的选择性注意效应是，对同一特征调谐的神经元之间试次间的噪声相关性会降低。考虑一个由 $N = 100$ 个神经元组成的群体，这些神经元对一个单一标量刺激维度具有相同的调谐特性。为了区分两个邻近的刺激，每个神经元对这两个刺激的平均响应相差一个相同的量 $\\Delta \\mu$，并且每个神经元的噪声具有相同的标准差 $\\sigma$。任意两个不同神经元之间噪声的皮尔逊相关系数是均一的，等于 $\\rho$。假设注意将相关性从注意前的 $\\rho_{\\text{pre}} = 0.15$ 降低到注意后的 $\\rho_{\\text{post}} = 0.05$，而 $\\Delta \\mu$ 或 $\\sigma$ 保持不变。\n\n一个下游脑区使用一个简单的等权重线性读出 $y$，它对群体响应求和以形成一个决策变量。设性能由信号检测论（SDT）框架下的可辨别性 $d'$ 来量化，对于一个决策变量，$d'$ 定义为其在两种刺激下的均值之差除以其噪声标准差。\n\n从随机变量的协方差和相关性的核心定义和公认事实出发，推导这个简单等权重读出的 $d'$ 作为 $N$、$\\Delta \\mu$、$\\sigma$ 和 $\\rho$ 的函数表达式，然后计算由注意引起的解码器性能的预测乘性改善，该改善定义为比率 $d'_{\\text{post}}/d'_{\\text{pre}}$。将您的最终数值答案四舍五入到三位有效数字。以无量纲的乘性因子的形式提供最终答案。", "solution": "问题要求推导一个神经元群体简单线性读出的可辨别性 $d'$，并计算由于注意引起的噪声相关性变化所带来的该指标的改善。\n\n首先，我们建立统计框架。设 $r_i$ 为神经元 $i$（$i=1, \\dots, N$）的响应，它是一个随机变量。问题考虑的是区分两种刺激，我们可以将其标记为 $s_1$ 和 $s_2$。神经元 $i$ 对刺激 $s_k$ 的响应是 $r_{i,k}$。\n\n已知条件如下：\n- 神经元数量为 $N = 100$。\n- 神经元 $i$ 对刺激 $s_k$ 的平均响应为 $E[r_{i,k}] = \\mu_{i,k}$。\n- 所有神经元对两种刺激的平均响应之差是相同的：$\\Delta \\mu = \\mu_{i,2} - \\mu_{i,1}$。\n- 对于所有神经元和两种刺激，每个神经元响应的噪声方差是相同的：$\\text{Var}(r_{i,k}) = \\sigma^2$。\n- 任意两个不同神经元 $i$ 和 $j$ 之间的噪声相关性是均一的：对于 $i \\neq j$，$\\text{Corr}(r_{i,k}, r_{j,k}) = \\rho$。\n- 根据皮尔逊相关系数的定义，协方差为 $\\text{Cov}(r_{i,k}, r_{j,k}) = \\rho \\sqrt{\\text{Var}(r_{i,k})} \\sqrt{\\text{Var}(r_{j,k})} = \\rho \\sigma^2$ (对于 $i \\neq j$)。注意 $\\text{Cov}(r_{i,k}, r_{i,k}) = \\text{Var}(r_{i,k}) = \\sigma^2$。\n\n决策变量 $y$ 由群体响应的简单等权重线性和形成：\n$$y_k = \\sum_{i=1}^{N} r_{i,k}$$\n其中 $y_k$ 是对刺激 $s_k$ 的决策变量。\n\n可辨别性 $d'$ 定义为决策变量的均值之差除以其标准差：\n$$d' = \\frac{E[y_2] - E[y_1]}{\\sqrt{\\text{Var}(y)}}$$\n假设噪声统计量（$\\sigma^2$、$\\rho$）与呈现的刺激无关，因此 $\\text{Var}(y_1) = \\text{Var}(y_2) = \\text{Var}(y)$。\n\n我们首先推导 $d'$ 的分子，即读出量的均值之差。根据期望的线性性质：\n$$E[y_k] = E\\left[\\sum_{i=1}^{N} r_{i,k}\\right] = \\sum_{i=1}^{N} E[r_{i,k}] = \\sum_{i=1}^{N} \\mu_{i,k}$$\n均值之差为：\n$$E[y_2] - E[y_1] = \\sum_{i=1}^{N} \\mu_{i,2} - \\sum_{i=1}^{N} \\mu_{i,1} = \\sum_{i=1}^{N} (\\mu_{i,2} - \\mu_{i,1})$$\n由于 $\\Delta \\mu$ 对所有 $N$ 个神经元都是相同的，因此这可以简化为：\n$$E[y_2] - E[y_1] = \\sum_{i=1}^{N} \\Delta \\mu = N \\Delta \\mu$$\n\n接下来，我们推导 $d'$ 的分母，即读出量的标准差 $\\sigma_y = \\sqrt{\\text{Var}(y)}$。我们必须首先求出 $y$ 的方差。随机变量和的方差是其协方差矩阵中所有项的和：\n$$\\text{Var}(y) = \\text{Var}\\left(\\sum_{i=1}^{N} r_i\\right) = \\sum_{i=1}^{N}\\sum_{j=1}^{N} \\text{Cov}(r_i, r_j)$$\n我们可以将这个双重求和拆分为 $i=j$ 的项（对角线项）和 $i \\neq j$ 的项（非对角线项）：\n$$\\text{Var}(y) = \\sum_{i=1}^{N} \\text{Cov}(r_i, r_i) + \\sum_{i \\neq j} \\text{Cov}(r_i, r_j)$$\n第一个和由 $N$ 个方差项组成，$\\text{Cov}(r_i, r_i) = \\text{Var}(r_i) = \\sigma^2$。第二个和由 $N(N-1)$ 个协方差项组成，对于 $i \\neq j$，$\\text{Cov}(r_i, r_j) = \\rho \\sigma^2$。\n将这些代入 $\\text{Var}(y)$ 的方程中：\n$$\\text{Var}(y) = \\sum_{i=1}^{N} \\sigma^2 + \\sum_{i \\neq j} \\rho \\sigma^2 = N \\sigma^2 + N(N-1)\\rho \\sigma^2$$\n提出公因式 $N \\sigma^2$，得到读出量的方差：\n$$\\text{Var}(y) = N \\sigma^2 (1 + (N-1)\\rho)$$\n因此，读出量的标准差为：\n$$\\sigma_y = \\sqrt{N \\sigma^2 (1 + (N-1)\\rho)} = \\sigma \\sqrt{N(1 + (N-1)\\rho)}$$\n\n现在我们可以写出可辨别性 $d'$ 的完整表达式：\n$$d' = \\frac{N \\Delta \\mu}{\\sigma \\sqrt{N(1 + (N-1)\\rho)}}$$\n这可以简化为：\n$$d' = \\frac{\\Delta \\mu}{\\sigma} \\frac{N}{\\sqrt{N}\\sqrt{1 + (N-1)\\rho}} = \\frac{\\Delta \\mu}{\\sigma} \\sqrt{\\frac{N}{1 + (N-1)\\rho}}$$\n这就是所要求的 $d'$ 作为 $N$、$\\Delta \\mu$、$\\sigma$ 和 $\\rho$ 的函数表达式。\n\n问题陈述，注意将相关性从 $\\rho_{\\text{pre}} = 0.15$ 降低到 $\\rho_{\\text{post}} = 0.05$，而 $N$、$\\Delta \\mu$ 和 $\\sigma$ 保持不变。我们可以写出 $d'_{\\text{pre}}$ 和 $d'_{\\text{post}}$ 的表达式：\n$$d'_{\\text{pre}} = \\frac{\\Delta \\mu}{\\sigma} \\sqrt{\\frac{N}{1 + (N-1)\\rho_{\\text{pre}}}}$$\n$$d'_{\\text{post}} = \\frac{\\Delta \\mu}{\\sigma} \\sqrt{\\frac{N}{1 + (N-1)\\rho_{\\text{post}}}}$$\n\n乘性改善是比率 $d'_{\\text{post}} / d'_{\\text{pre}}$：\n$$\\frac{d'_{\\text{post}}}{d'_{\\text{pre}}} = \\frac{\\frac{\\Delta \\mu}{\\sigma} \\sqrt{\\frac{N}{1 + (N-1)\\rho_{\\text{post}}}}}{\\frac{\\Delta \\mu}{\\sigma} \\sqrt{\\frac{N}{1 + (N-1)\\rho_{\\text{pre}}}}}$$\n公共因子 $\\frac{\\Delta \\mu}{\\sigma}\\sqrt{N}$ 被消去，剩下：\n$$\\frac{d'_{\\text{post}}}{d'_{\\text{pre}}} = \\frac{\\sqrt{\\frac{1}{1 + (N-1)\\rho_{\\text{post}}}}}{\\sqrt{\\frac{1}{1 + (N-1)\\rho_{\\text{pre}}}}} = \\sqrt{\\frac{1 + (N-1)\\rho_{\\text{pre}}}{1 + (N-1)\\rho_{\\text{post}}}}$$\n\n现在，我们代入给定的数值：$N = 100$、$\\rho_{\\text{pre}} = 0.15$ 和 $\\rho_{\\text{post}} = 0.05$。注意 $N-1 = 99$。\n$$\\frac{d'_{\\text{post}}}{d'_{\\text{pre}}} = \\sqrt{\\frac{1 + (99)(0.15)}{1 + (99)(0.05)}}$$\n首先，计算平方根内的分子和分母：\n$$1 + (99)(0.15) = 1 + 14.85 = 15.85$$\n$$1 + (99)(0.05) = 1 + 4.95 = 5.95$$\n该比率为：\n$$\\frac{d'_{\\text{post}}}{d'_{\\text{pre}}} = \\sqrt{\\frac{15.85}{5.95}} \\approx \\sqrt{2.6638655...} \\approx 1.6321359...$$\n将最终答案四舍五入到三位有效数字，预测的乘性改善为 $1.63$。", "answer": "$$\\boxed{1.63}$$", "id": "5039157"}]}