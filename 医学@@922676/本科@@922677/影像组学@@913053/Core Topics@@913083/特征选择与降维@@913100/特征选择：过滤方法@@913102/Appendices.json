{"hands_on_practices": [{"introduction": "我们的实践始于一种最直观和广泛使用的连续结果变量特征选择过滤方法：皮尔逊相关性。这项练习将引导你从基本定义出发，亲手实现皮尔逊相关性系数的计算，从而深刻理解其作为线性关系度量的本质。通过揭示相关性与标准化简单线性回归斜率的等价性，你将进一步巩固对特征与结果之间线性关联的认识。[@problem_id:5194608]", "problem": "给定一个数据矩阵 $X \\in \\mathbb{R}^{n \\times p}$，表示在 $n$ 位患者上测量的 $p$ 个候选特征，以及一个连续结果向量 $y \\in \\mathbb{R}^{n}$。你的目标是设计并实现一种基于 Pearson 相关系数绝对值的单变量过滤方法用于特征选择。从基本定义出发，你必须推导出一个可实现的程序，该程序根据 $|r_j|$ 对特征进行排序，其中 $r_j$ 是特征 $j$ 与结果之间的样本 Pearson 相关性。然后，将你的程序应用于下面的测试套件，并将结果汇总到指定的单行输出中。\n\n基本依据和推导约束：\n- 从样本均值、未归一化的样本协方差和样本尺度（未归一化的平方和的平方根）的定义开始。对于任意具有条目 $v_i$ 的向量 $v \\in \\mathbb{R}^{n}$，将其样本均值定义为 $\\bar{v} = \\frac{1}{n} \\sum_{i=1}^{n} v_i$。对于一对向量 $(u, v)$，将未归一化的样本协方差定义为 $\\sum_{i=1}^{n} (u_i - \\bar{u})(v_i - \\bar{v})$，并将样本尺度定义为 $s_v = \\sqrt{\\sum_{i=1}^{n} (v_i - \\bar{v})^2}$。\n- 基于这些定义，推导出 $X$ 的第 $j$ 列与 $y$ 之间的样本 Pearson 相关系数 $r_j$ 的标准表达式，除了上述定义外，不引入任何其他假设。\n- 详细说明单变量过滤方法的完整排序程序：为每个特征 $j \\in \\{0, 1, \\dots, p-1\\}$ 计算 $r_j$，按 $|r_j|$ 的降序排序，通过较小的特征索引确定性地打破平局，并通过定义 $r_j = 0$ 来处理边界情况 $s_{x_j} = 0$ 或 $s_y = 0$。\n- 从第一性原理出发，简要论证为什么这构成一种过滤方法（与包裹式或嵌入式方法相对），并解释一个将 $r_j$ 与简单线性模型拟合联系起来的数学性质，该性质在 $p$ 很大时支持这种排序的可解释性。\n\n你的实现要求：\n- 实现一个函数，该函数直接根据上述定义计算所有 $j \\in \\{0, 1, \\dots, p-1\\}$ 的 $r_j$，不使用任何用于计算相关的库例程。\n- 实现上述描述的按 $|r_j|$ 排序并带有平局打破规则的程序。\n- 当 $x$ 和 $y$ 都使用样本尺度 $s_v = \\sqrt{\\sum_{i=1}^{n} (v_i - \\bar{v})^2}$ 进行标准化时，实现一个检查 Pearson 相关性与普通最小二乘法 (OLS) 简单线性回归斜率之间等价性的功能。具体来说，对于具有向量 $x \\in \\mathbb{R}^{n}$ 和 $y \\in \\mathbb{R}^{n}$ 的单特征情况，构建标准化变量 $z_x = \\frac{x - \\bar{x}}{s_x}$ 和 $z_y = \\frac{y - \\bar{y}}{s_y}$，拟合一个 $z_y$ 对 $z_x$ 的包含截距的 OLS 模型，并返回拟合斜率与使用相同定义从非标准化的 $(x, y)$ 计算出的 Pearson 相关性之间的绝对差值。报告这个绝对差值。\n\n测试套件：\n- 测试用例 1（具有不同相关性大小的一般情况）：\n  - $X^{(1)} \\in \\mathbb{R}^{4 \\times 3}$ 和 $y^{(1)} \\in \\mathbb{R}^{4}$ 为\n  $$\n  X^{(1)} = \\begin{bmatrix}\n  1 & 2 & 0 \\\\\n  3 & 1 & 1 \\\\\n  2 & 3 & 2 \\\\\n  0 & 1 & 3\n  \\end{bmatrix}, \\quad\n  y^{(1)} = \\begin{bmatrix}\n  1 \\\\ 0 \\\\ 1 \\\\ 2\n  \\end{bmatrix}.\n  $$\n  将 $X^{(1)}$ 的列解释为具有从零开始的索引 $0$、$1$ 和 $2$ 的特征。\n- 测试用例 2（包含零方差特征和 $|r_j|$ 值平局的边界情况）：\n  - $X^{(2)} \\in \\mathbb{R}^{4 \\times 3}$ 和 $y^{(2)} \\in \\mathbb{R}^{4}$ 为\n  $$\n  X^{(2)} = \\begin{bmatrix}\n  0 & 0 & 5 \\\\\n  1 & -1 & 5 \\\\\n  2 & -2 & 5 \\\\\n  3 & -3 & 5\n  \\end{bmatrix}, \\quad\n  y^{(2)} = \\begin{bmatrix}\n  0 \\\\ 1 \\\\ 2 \\\\ 3\n  \\end{bmatrix}.\n  $$\n  注意，第三个特征（索引 $2$）的方差为零，应被赋值 $r_2 = 0$。前两个特征应在 $|r_j|$ 上产生平局，必须通过偏好较小的索引来打破。\n- 测试用例 3（相关性与标准化 OLS 斜率之间的等价性检查）：\n  - 令 $x^{(3)} \\in \\mathbb{R}^{5}$ 和 $y^{(3)} \\in \\mathbb{R}^{5}$ 为\n  $$\n  x^{(3)} = \\begin{bmatrix}\n  0 \\\\ 1 \\\\ 2 \\\\ 3 \\\\ 4\n  \\end{bmatrix}, \\quad\n  y^{(3)} = \\begin{bmatrix}\n  7 \\\\ 5 \\\\ 3 \\\\ 1 \\\\ -1\n  \\end{bmatrix}.\n  $$\n  计算 (i) 根据上述定义从 $(x^{(3)}, y^{(3)})$ 计算出的 Pearson 相关性与 (ii) 在 $z_x = \\frac{x^{(3)} - \\overline{x^{(3)}}}{s_{x^{(3)}}}$ 和 $z_y = \\frac{y^{(3)} - \\overline{y^{(3)}}}{s_{y^{(3)}}}$ （其中 $s_v = \\sqrt{\\sum_{i=1}^{n} (v_i - \\bar{v})^2}$）的情况下，$z_y$ 对 $z_x$ 进行 OLS 回归所得的斜率之间的绝对差值。\n\n最终输出格式：\n- 你的程序必须生成单行输出，其中包含一个含有三个条目的列表：\n  - 第一个条目是测试用例 1 的排序，为一个按 $|r_j|$ 降序排列的特征索引列表（使用从零开始的索引和指定的平局打破规则）。\n  - 第二个条目是格式相同的测试用例 2 的排序。\n  - 第三个条目是测试用例 3 的绝对差值（一个非负实数），如上定义。\n- 具体而言，输出必须具有 $[R^{(1)}, R^{(2)}, d^{(3)}]$ 的形式，其中 $R^{(1)}$ 和 $R^{(2)}$ 是整数列表，$d^{(3)}$ 是一个浮点数。例如，一个可接受的格式是 `[[0,2,1],[0,1,2],0.0]`。\n\n关于方法论背景的说明：\n- 过滤方法使用不涉及拟合多特征预测模型的统计标准，独立地评估每个特征与 $y$ 的关系。仅为对比，包裹式方法通过训练和验证一个预测模型来评估特征子集并为其打分，而嵌入式方法则将特征选择整合到模型训练本身中（例如，线性模型中的最小绝对收缩和选择算子 (LASSO) 正则化）。在此任务中，你不需要实现包裹式或嵌入式方法；你的代码必须只实现按 $|r_j|$ 的过滤排序以及测试用例 3 中的标准化 OLS 斜率检查。\n\n你的程序不得从用户读取输入，并且必须按照上述格式精确打印一行。", "solution": "该问题要求基于 Pearson 相关系数的绝对值，设计、推导并实现一种用于特征选择的单变量过滤方法。解决方案必须根据问题陈述中定义的第一性原理来展开。\n\n首先，我们推导特征 $j$ 的样本 Pearson 相关系数 $r_j$ 的表达式。问题为任意向量 $u, v \\in \\mathbb{R}^{n}$ 提供了以下基本定义：\n- 样本均值：$\\bar{v} = \\frac{1}{n} \\sum_{i=1}^{n} v_i$。\n- 未归一化的样本协方差：$C_{uv} = \\sum_{i=1}^{n} (u_i - \\bar{u})(v_i - \\bar{v})$。\n- 样本尺度：$s_v = \\sqrt{\\sum_{i=1}^{n} (v_i - \\bar{v})^2}$。\n\nPearson 相关系数通常定义为两个变量的协方差除以它们标准差的乘积。使用给定的未归一化定义，两个向量 $u$ 和 $v$ 之间的样本 Pearson 相关系数 $r$ 是它们的未归一化样本协方差与它们的样本尺度乘积的比值。令 $x_j$ 表示第 $j$ 个特征向量（矩阵 $X$ 的第 $j$ 列），$y$ 为结果向量。因此，$x_j$ 和 $y$ 之间的相关系数 $r_j$ 为：\n$$\nr_j = \\frac{\\sum_{i=1}^{n} (x_{ij} - \\bar{x}_j)(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n} (x_{ij} - \\bar{x}_j)^2} \\sqrt{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}} = \\frac{C_{x_j y}}{s_{x_j} s_y}\n$$\n该公式是通过将所提供的定义代入 Pearson 相关性的标准结构中直接推导出来的。问题指定了一个边界条件：如果分母为零（当 $s_{x_j} = 0$ 或 $s_y = 0$ 时发生），则相关系数 $r_j$ 定义为 $0$。零样本尺度意味着该向量的方差为零（其所有元素都相同）。\n\n单变量过滤方法的完整程序如下：\n1. 对每个特征 $j \\in \\{0, 1, \\dots, p-1\\}$，使用推导出的公式计算特征向量 $x_j$ 和结果向量 $y$ 之间的样本 Pearson 相关系数 $r_j$。\n2. 计算每个相关系数的绝对值 $|r_j|$。\n3. 按其对应的 $|r_j|$ 值的降序对特征进行排序。\n4. 在 $|r_j|$ 值出现平局的情况下，具有较小索引 $j$ 的特征排名更高。这确保了排序的确定性。\n\n该程序构成了一种用于特征选择的过滤方法。过滤方法基于特征相对于目标变量的内在统计特性来评估和排序特征，独立于任何选定的预测建模算法。我们的方法为每个特征单独计算一个分数（$|r_j|$），而无需训练多特征模型。这与包裹式方法形成对比，后者使用特定的预测模型对整个特征子集进行评分；也与嵌入式方法不同，后者的特征选择是模型训练过程的一个组成部分（例如，LASSO 正则化）。\n\nPearson 相关系数 $r_j$ 的一个关键数学性质支持其在特征排序中的应用，尤其是在高维（大 $p$）设置中。这个性质是它与简单普通最小二乘法 (OLS) 线性回归模型斜率的直接关系。对于 $y$ 关于单个特征 $x_j$ 的模型 $y = \\beta_0 + \\beta_1 x_j + \\epsilon$，斜率的 OLS 估计为 $\\hat{\\beta}_1 = \\frac{C_{x_j y}}{s_{x_j}^2}$。这可以用相关系数 $r_j$ 来改写：\n$$\n\\hat{\\beta}_1 = r_j \\frac{s_y}{s_{x_j}}\n$$\n这表明斜率与相关性成正比，但按样本尺度的比率进行了缩放。为了提供一种标准化的关联度量，我们可以考虑标准化变量之间的回归。让我们将标准化变量 $z_{x_j}$ 和 $z_y$ 定义为：\n$$\nz_{x_j} = \\frac{x_j - \\bar{x}_j}{s_{x_j}}, \\quad z_y = \\frac{y - \\bar{y}}{s_y}\n$$\n根据构造，这些标准化变量的均值为 $0$，样本尺度为 $1$。让我们为 $z_{x_j}$ 证明这一点：\n- 均值：$\\bar{z}_{x_j} = \\frac{1}{n} \\sum_{i=1}^n \\frac{x_{ij} - \\bar{x}_j}{s_{x_j}} = \\frac{1}{n s_{x_j}} \\left( \\sum_{i=1}^n x_{ij} - n \\bar{x}_j \\right) = \\frac{1}{n s_{x_j}} (n \\bar{x}_j - n \\bar{x}_j) = 0$。\n- 尺度的平方：$s_{z_{x_j}}^2 = \\sum_{i=1}^n (z_{x_{ij}} - \\bar{z}_{x_j})^2 = \\sum_{i=1}^n z_{x_{ij}}^2 = \\sum_{i=1}^n \\left( \\frac{x_{ij} - \\bar{x}_j}{s_{x_j}} \\right)^2 = \\frac{1}{s_{x_j}^2} \\sum_{i=1}^n (x_{ij} - \\bar{x}_j)^2 = \\frac{s_{x_j}^2}{s_{x_j}^2} = 1$。\n现在，考虑一个 $z_y$ 对 $z_{x_j}$ 的包含截距的 OLS 模型：$z_y = \\beta'_0 + \\beta'_1 z_{x_j} + \\epsilon'$。斜率 $\\hat{\\beta}'_1$ 的 OLS 估计为：\n$$\n\\hat{\\beta}'_1 = \\frac{\\sum_{i=1}^n (z_{x_{ij}} - \\bar{z}_{x_j})(z_{y_i} - \\bar{z}_y)}{\\sum_{i=1}^n (z_{x_{ij}} - \\bar{z}_{x_j})^2}\n$$\n由于 $\\bar{z}_{x_j} = 0$、$\\bar{z}_y = 0$ 且 $\\sum (z_{x_{ij}})^2 = s_{z_{x_j}}^2 = 1$，上式可简化为：\n$$\n\\hat{\\beta}'_1 = \\frac{\\sum_{i=1}^n z_{x_{ij}} z_{y_i}}{1} = \\sum_{i=1}^n \\left( \\frac{x_{ij} - \\bar{x}_j}{s_{x_j}} \\right) \\left( \\frac{y_i - \\bar{y}}{s_y} \\right) = \\frac{\\sum_{i=1}^n (x_{ij} - \\bar{x}_j)(y_i - \\bar{y})}{s_{x_j} s_y} = r_j\n$$\n因此，Pearson 相关系数 $r_j$ 完全等于标准化结果对标准化特征的简单线性回归的斜率。这提供了一个清晰的解释：$|r_j|$ 在一个共同的尺度上衡量了线性关系的强度，其中特征的标准化值的一个单位变化对应于结果的标准化值的 $r_j$ 个单位变化。因此，按 $|r_j|$ 排序等同于在单变量线性上下文中按其标准化效应大小的量级对特征进行排序。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the feature selection problem according to the user's specification.\n    It processes three test cases: two feature ranking tasks and one equivalence check.\n    \"\"\"\n\n    def compute_pearson_correlations(X, y):\n        \"\"\"\n        Computes Pearson correlation for each feature in X against y from first principles.\n\n        Args:\n            X (np.ndarray): Data matrix of shape (n, p).\n            y (np.ndarray): Outcome vector of shape (n,).\n\n        Returns:\n            list: A list of Pearson correlation coefficients [r_0, r_1, ..., r_{p-1}].\n        \"\"\"\n        n, p = X.shape\n        y_mean = np.mean(y)\n        y_centered = y - y_mean\n        s_y_sq = np.sum(y_centered**2)\n\n        correlations = []\n        if s_y_sq == 0.0:\n            return [0.0] * p\n\n        s_y = np.sqrt(s_y_sq)\n\n        for j in range(p):\n            x_j = X[:, j]\n            x_j_mean = np.mean(x_j)\n            x_j_centered = x_j - x_j_mean\n            s_x_j_sq = np.sum(x_j_centered**2)\n\n            if s_x_j_sq == 0.0:\n                correlations.append(0.0)\n                continue\n\n            s_x_j = np.sqrt(s_x_j_sq)\n            cov_numerator = np.sum(x_j_centered * y_centered)\n            r_j = cov_numerator / (s_x_j * s_y)\n            correlations.append(r_j)\n\n        return correlations\n\n    def rank_features(correlations):\n        \"\"\"\n        Ranks features based on the absolute value of their correlation, with tie-breaking.\n\n        Args:\n            correlations (list): List of correlation coefficients.\n\n        Returns:\n            list: A list of feature indices sorted by a descending absolute correlation.\n        \"\"\"\n        indexed_corrs = list(enumerate(correlations))\n        # Sort key: primary is descending absolute correlation, secondary is ascending index.\n        sorted_indices = sorted(indexed_corrs, key=lambda item: (-abs(item[1]), item[0]))\n        return [index for index, corr in sorted_indices]\n\n    def compute_ols_equivalence_diff(x, y):\n        \"\"\"\n        Computes the absolute difference between Pearson correlation and the slope of\n        OLS regression on standardized variables.\n\n        Args:\n            x (np.ndarray): Feature vector of shape (n,).\n            y (np.ndarray): Outcome vector of shape (n,).\n\n        Returns:\n            float: The absolute difference.\n        \"\"\"\n        n = len(x)\n\n        # (i) Compute Pearson correlation for (x, y)\n        x_mean = np.mean(x)\n        y_mean = np.mean(y)\n        x_c = x - x_mean\n        y_c = y - y_mean\n        s_x_sq = np.sum(x_c**2)\n        s_y_sq = np.sum(y_c**2)\n\n        if s_x_sq == 0.0 or s_y_sq == 0.0:\n            r_xy = 0.0\n        else:\n            s_x = np.sqrt(s_x_sq)\n            s_y = np.sqrt(s_y_sq)\n            cov_num = np.sum(x_c * y_c)\n            r_xy = cov_num / (s_x * s_y)\n        \n        # (ii) Compute OLS slope for standardized z_y on z_x\n        if s_x_sq == 0.0 or s_y_sq == 0.0:\n            # If variance is zero, standardization is not well-defined.\n            # In this context, implies slope is ill-defined or zero.\n            # We assume for this test case that variances are non-zero.\n            ols_slope = 0.0\n        else:\n            s_x = np.sqrt(s_x_sq)\n            s_y = np.sqrt(s_y_sq)\n            z_x = x_c / s_x\n            z_y = y_c / s_y\n            \n            # OLS slope for z_y = beta_0 + beta_1 * z_x\n            # The formulas are more stable with re-centering, though means should be zero.\n            z_x_mean = np.mean(z_x)\n            z_y_mean = np.mean(z_y)\n            z_x_c = z_x - z_x_mean\n            z_y_c = z_y - z_y_mean\n            \n            ols_slope_num = np.sum(z_x_c * z_y_c)\n            ols_slope_den = np.sum(z_x_c**2)\n            \n            if ols_slope_den == 0.0:\n                 ols_slope = 0.0\n            else:\n                 ols_slope = ols_slope_num / ols_slope_den\n\n        return abs(r_xy - ols_slope)\n\n    # Test Case 1\n    X1 = np.array([\n        [1, 2, 0],\n        [3, 1, 1],\n        [2, 3, 2],\n        [0, 1, 3]\n    ], dtype=float)\n    y1 = np.array([1, 0, 1, 2], dtype=float)\n    correlations1 = compute_pearson_correlations(X1, y1)\n    ranking1 = rank_features(correlations1)\n\n    # Test Case 2\n    X2 = np.array([\n        [0, 0, 5],\n        [1, -1, 5],\n        [2, -2, 5],\n        [3, -3, 5]\n    ], dtype=float)\n    y2 = np.array([0, 1, 2, 3], dtype=float)\n    correlations2 = compute_pearson_correlations(X2, y2)\n    ranking2 = rank_features(correlations2)\n\n    # Test Case 3\n    x3 = np.array([0, 1, 2, 3, 4], dtype=float)\n    y3 = np.array([7, 5, 3, 1, -1], dtype=float)\n    diff3 = compute_ols_equivalence_diff(x3, y3)\n\n    # Prepare final output\n    results = [\n        str(ranking1).replace(\" \", \"\"),\n        str(ranking2).replace(\" \", \"\"),\n        str(diff3)\n    ]\n    \n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "5194608"}, {"introduction": "在掌握了线性关联的度量之后，认识其局限性至关重要。本练习是一个思想实验，构建了一个特征与结果高度相关但皮尔逊相关系数为零的场景。这个例子清晰地展示了，当特征与结果之间存在非线性或非单调关系时，仅依赖相关性的过滤方法会失效，从而引出对互信息（Mutual Information, MI）等更普适依赖性度量方法的需求。[@problem_id:4539252]", "problem": "一项影像组学研究考虑了从肺部肿瘤的治疗前计算机断层扫描图像中提取的单个定量特征 $R$。该特征在一组包含 $n=200$ 名患者的队列中被标准化，其分布近似为 $\\mathcal{N}(0,1)$。二元临床终点 $Y \\in \\{0,1\\}$ 表示2年时的局部控制情况，在本思想实验中其构建如下：存在一个阈值 $\\tau > 0$，使得 $Y=\\mathbf{1}(|R|>\\tau)$。假设类别占比是非退化的（即 $\\mathbb{P}(Y=1)\\in(0,1)$），并且在本问题中忽略测量噪声。\n\n您必须评估用于对 $R$ 相对于 $Y$ 进行特征选择的单变量滤波器方法。仅使用期望、协方差、独立性和互信息的基本定义，以及标准正态分布的对称性质，推断在所述的数据生成过程中，以下哪些滤波器在直接应用于原始特征 $R$ 时，预期会将 $R$ 标记为对 $Y$ 具有信息量：\n\nA. Pearson相关性滤波器，它根据 $R$ 与编码为 $0$ 或 $1$ 的数值标签 $Y$ 之间的样本相关性的绝对值对特征进行排序。\n\nB. 双样本Student t检验，比较由 $Y$ 定义的两个类别中 $R$ 的均值。\n\nC. 互信息(MI)滤波器，它使用一个针对混合连续-离散变量的一致性估计量来估计 $I(R;Y)$，并根据估计的MI对特征进行排序。\n\nD. $R$ 与数值标签 $Y$ 之间的Spearman秩相关滤波器。\n\nE. 距离相关性滤波器，它使用的总体距离相关性当且仅当变量独立时才为零。\n\n在选项 A–E 中，哪些滤波器原则上有望在不进行任何事先的非线性特征工程（例如将 $R$ 转换为 $R^2$）的情况下，正确识别出 $R$ 对 $Y$ 具有信息量？\n\n选择所有适用项。", "solution": "首先必须评估问题陈述的有效性。\n\n### 步骤1：提取已知条件\n- 一个定量的影像组学特征 $R$ 经过标准化，其分布近似为 $\\mathcal{N}(0,1)$。\n- 样本量为 $n=200$。\n- 定义了一个二元临床终点 $Y \\in \\{0,1\\}$。\n- 终点的数据生成过程为 $Y = \\mathbf{1}(|R| > \\tau)$，其中 $\\tau > 0$ 为某个常数阈值，$\\mathbf{1}(\\cdot)$ 是指示函数。\n- 类别占比是非退化的，即 $\\mathbb{P}(Y=1) \\in (0,1)$。\n- 测量噪声将被忽略。\n- 任务是评估五种单变量滤波器方法，用于对原始特征 $R$ 相对于 $Y$ 进行特征选择。\n- 评估应使用基本定义和对称性质。\n- 问题是，原则上哪些滤波器会识别出 $R$ 对 $Y$ 具有信息量。\n\n### 步骤2：使用提取的已知条件进行验证\n- **科学依据：** 该问题描述了影像组学中一个简化但合理的情景，其中特征的量值（不论符号）可能与临床结果相关。所列出的统计方法是该领域的标准方法。使用标准正态分布是对标准化数据进行建模的常见且有效的简化。该问题基于已建立的统计学和机器学习原理。\n- **适定性：** 该问题在数学上是适定的。$R$ 的分布以及 $R$ 和 $Y$ 之间的函数关系都已明确指定。条件 $\\mathbb{P}(Y=1) \\in (0,1)$ 意味着对于 $R \\sim \\mathcal{N}(0,1)$，阈值 $\\tau$ 必须使得 $\\mathbb{P}(|R| > \\tau)$ 不为 $0$ 或 $1$，这对任何有限的 $\\tau>0$ 都成立。问题是具体的且可回答的。\n- **客观性：** 语言正式、精确，不含主观内容。\n- **完整性和一致性：** 问题是自洽的，提供了所有必要的信息来推断统计滤波器在总体层面的行为。没有矛盾之处。\n- **其他标准：** 问题并非微不足道，因为它需要理解不同统计依赖性度量的局限性。它不是不适定的、不切实际的（在思想实验的背景下），或存在其他缺陷。\n\n### 步骤3：结论与行动\n问题陈述是**有效的**。将推导解答。\n\n### 解答推导\n\n问题的核心是确定哪种统计度量可以检测到特定的依赖关系 $Y = \\mathbf{1}(|R| > \\tau)$，其中 $R \\sim \\mathcal{N}(0,1)$。这种关系是对称的：大的正值和大的负值的 $R$ 都映射到 $Y=1$，而接近于零的 $R$ 值映射到 $Y=0$。我们通过检查每个滤波器所测量的总体层面属性来分析其预期行为。设 $p(r)$ 为标准正态分布的概率密度函数，它是一个偶函数：$p(-r) = p(r)$。\n\n**A. Pearson相关性滤波器**\n\nPearson相关系数为 $\\rho(R,Y) = \\frac{\\text{Cov}(R,Y)}{\\sigma_R \\sigma_Y}$。如果 $|\\rho(R,Y)|$ 显著不为零，滤波器就会标记 $R$。协方差为 $\\text{Cov}(R,Y) = \\mathbb{E}[RY] - \\mathbb{E}[R]\\mathbb{E}[Y]$。\n已知 $R \\sim \\mathcal{N}(0,1)$，我们有 $\\mathbb{E}[R]=0$。因此，$\\text{Cov}(R,Y) = \\mathbb{E}[RY]$。\n我们计算期望 $\\mathbb{E}[RY]$：\n$$ \\mathbb{E}[RY] = \\mathbb{E}[R \\cdot \\mathbf{1}(|R| > \\tau)] = \\int_{-\\infty}^{\\infty} r \\cdot \\mathbf{1}(|r| > \\tau) \\cdot p(r) \\, dr $$\n这个积分可以分为两部分：\n$$ \\mathbb{E}[RY] = \\int_{-\\infty}^{-\\tau} r \\cdot p(r) \\, dr + \\int_{\\tau}^{\\infty} r \\cdot p(r) \\, dr $$\n被积函数 $f(r) = r \\cdot p(r)$ 是一个奇函数，因为 $r$ 是奇函数，$p(r)$ 是偶函数。我们来明确地展示这一点。在第一个积分中令 $u = -r$：\n$$ \\int_{-\\infty}^{-\\tau} r \\cdot p(r) \\, dr = \\int_{\\infty}^{\\tau} (-u) \\cdot p(-u) \\cdot (-du) = \\int_{\\infty}^{\\tau} u \\cdot p(u) \\, du = - \\int_{\\tau}^{\\infty} u \\cdot p(u) \\, du $$\n将其代回，我们得到：\n$$ \\mathbb{E}[RY] = - \\int_{\\tau}^{\\infty} r \\cdot p(r) \\, dr + \\int_{\\tau}^{\\infty} r \\cdot p(r) \\, dr = 0 $$\n由于协方差为 $0$，总体Pearson相关系数 $\\rho(R,Y)$ 也为 $0$。基于Pearson相关性的滤波器旨在检测线性关系，因此原则上无法识别 $R$ 和 $Y$ 之间的非线性、对称的依赖关系。\n\n对A的判断：**不正确**。\n\n**B. 双样本Student t检验**\n\nt检验比较由 $Y$ 定义的两组中 $R$ 的均值。它检验的原假设是 $H_0: \\mathbb{E}[R|Y=0] = \\mathbb{E}[R|Y=1]$。如果这个原假设被拒绝，特征 $R$ 将被标记为具有信息量。我们来计算条件期望：\n$$ \\mathbb{E}[R|Y=1] = \\mathbb{E}[R \\,|\\, |R| > \\tau] = \\frac{\\mathbb{E}[R \\cdot \\mathbf{1}(|R| > \\tau)]}{\\mathbb{P}(|R| > \\tau)} $$\n分子是 $\\mathbb{E}[RY]$，我们已经证明它为 $0$。由于 $\\mathbb{P}(Y=1) = \\mathbb{P}(|R| > \\tau) \\in (0,1)$，分母不为零。因此，$\\mathbb{E}[R|Y=1] = 0$。\n接下来，我们计算另一个条件期望：\n$$ \\mathbb{E}[R|Y=0] = \\mathbb{E}[R \\,|\\, |R| \\le \\tau] = \\frac{\\mathbb{E}[R \\cdot \\mathbf{1}(|R| \\le \\tau)]}{\\mathbb{P}(|R| \\le \\tau)} $$\n分子是一个在对称区间上的积分：\n$$ \\mathbb{E}[R \\cdot \\mathbf{1}(|R| \\le \\tau)] = \\int_{-\\tau}^{\\tau} r \\cdot p(r) \\, dr $$\n由于被积函数 $r \\cdot p(r)$ 是一个奇函数，且积分区间 $[-\\tau, \\tau]$ 关于 $0$ 对称，所以这个积分为 $0$。分母 $\\mathbb{P}(|R| \\le \\tau)$ 不为零。因此，$\\mathbb{E}[R|Y=0] = 0$。\n由于 $\\mathbb{E}[R|Y=0] = \\mathbb{E}[R|Y=1] = 0$，t检验的原假设在总体层面上是成立的。因此，t检验预计不会将 $R$ 识别为有信息量的特征。\n\n对B的判断：**不正确**。\n\n**C. 互信息(MI)滤波器**\n\n互信息 $I(R;Y)$ 是衡量两个随机变量之间统计依赖性的度量。互信息的一个基本性质是 $I(R;Y) \\ge 0$，且 $I(R;Y) = 0$ 当且仅当 $R$ 和 $Y$ 在统计上是独立的。\n在这个问题中，$Y$ 是 $R$ 的确定性函数，即 $Y = \\mathbf{1}(|R| > \\tau)$。由于问题陈述类别占比是非退化的（$\\mathbb{P}(Y=1) \\in (0,1)$），$Y$ 不是一个常数随机变量。如果 $Y$ 是 $R$ 的一个非常数函数，那么 $R$ 和 $Y$ 不可能是独立的。关于 $R$ 的知识提供了关于 $Y$ 的信息。例如，如果我们观测到 $R=0$，我们就确定地知道 $Y=0$。如果我们观测到 $R = \\tau+1$，我们就确定地知道 $Y=1$。由于 $R$ 和 $Y$ 不是独立的，必然有 $I(R;Y) > 0$。\n基于互信息的滤波器，使用一致性估计量，将会估计出一个大于零的值，从而正确地将 $R$ 标记为对预测 $Y$ 具有信息量。\n\n对C的判断：**正确**。\n\n**D. Spearman秩相关滤波器**\n\nSpearman相关性通过计算变量秩次的Pearson相关性来衡量两个变量之间单调关系的强度。让我们分析 $R$ 的秩次与 $Y$ 值之间的关系。$R$ 的低值（低秩次）和 $R$ 的高值（高秩次）都会导致 $Y=1$。$R$ 的中间值（中等秩次）会导致 $Y=0$。这种关系是“U形”的，并且根本上是非单调的。\n我们可以通过计算总体Spearman相关性来形式化这一点，即概率积分变换的Pearson相关性，$\\rho(F_R(R), F_Y(Y))$。对于混合连续-离散情况，更直接的方法是计算 $\\text{Cov}(\\text{rank}(R), Y)$，其中秩由CDF值 $F_R(R)$ 表示。\n$\\text{Cov}(F_R(R), Y) = \\mathbb{E}[F_R(R) \\cdot Y] - \\mathbb{E}[F_R(R)]\\mathbb{E}[Y]$。对于任何连续变量 $R$，$F_R(R) \\sim \\text{Uniform}(0,1)$，所以 $\\mathbb{E}[F_R(R)] = 1/2$。我们需要计算 $\\mathbb{E}[F_R(R) \\cdot Y] = \\mathbb{E}[F_R(R) \\cdot \\mathbf{1}(|R| > \\tau)]$：\n$$ \\mathbb{E}[F_R(R) \\cdot Y] = \\int_{|r|>\\tau} F_R(r)p(r)dr = \\int_{-\\infty}^{-\\tau} F_R(r)p(r)dr + \\int_{\\tau}^{\\infty} F_R(r)p(r)dr $$\n利用对于关于0对称的分布，$F_R(-r) = 1 - F_R(r)$ 的性质，以及 $p(r)$ 的对称性，第一个积分变为（令 $u=-r$）：\n$$ \\int_{\\infty}^{\\tau} F_R(-u)p(-u)(-du) = \\int_{\\tau}^{\\infty} (1-F_R(u))p(u)du $$\n所以，$\\mathbb{E}[F_R(R) \\cdot Y] = \\int_{\\tau}^{\\infty} (1-F_R(r))p(r)dr + \\int_{\\tau}^{\\infty} F_R(r)p(r)dr = \\int_{\\tau}^{\\infty} p(r)dr = \\mathbb{P}(R>\\tau)$。此外，根据对称性，$\\mathbb{E}[Y] = \\mathbb{P}(|R|>\\tau) = \\mathbb{P}(R<-\\tau) + \\mathbb{P}(R>\\tau) = 2\\mathbb{P}(R>\\tau)$。将这些代入协方差公式：\n$$ \\text{Cov}(F_R(R), Y) = \\mathbb{P}(R>\\tau) - \\left(\\frac{1}{2}\\right) \\cdot (2\\mathbb{P}(R>\\tau)) = \\mathbb{P}(R>\\tau) - \\mathbb{P}(R>\\tau) = 0 $$\n总体Spearman相关性为零。该滤波器将无法识别这种对称的、非单调的关系。\n\n对D的判断：**不正确**。\n\n**E. 距离相关性滤波器**\n\n问题陈述提供了距离相关性的关键性质：总体距离相关性为零当且仅当变量在统计上是独立的。这是相较于Pearson相关性的一个关键优势，后者即使在变量强依赖的情况下也可能为零（如选项A所示）。\n我们已经在对选项C的分析中确定，$R$ 和 $Y$ 不是独立的，因为 $Y$ 是 $R$ 的一个非常数的确定性函数。\n由于 $R$ 和 $Y$ 不是独立的，它们的总体距离相关性必须严格大于零。因此，基于距离相关性的滤波器将计算出一个非零值，并正确地将 $R$ 识别为有信息量的特征。\n\n对E的判断：**正确**。", "answer": "$$\\boxed{CE}$$", "id": "4539252"}, {"introduction": "基于前一练习的理论铺垫，本实践将指导你构建一个完整且强大的非参数特征选择工作流。你将使用互信息（MI）来捕捉复杂的依赖关系，并学习通过置换检验（permutation testing）来评估其统计显著性，这是一种评估任何过滤方法得分是否具有统计意义的稳健技术。完成此练习将使你掌握从计算度量到做出可靠选择决策的全过程。[@problem_id:4539256]", "problem": "一个影像组学数据集通常包含为每个受试者测量的定量影像衍生特征，以及每个受试者的一个分类结果（例如，良性与恶性）。过滤法使用一个有原则的统计标准，独立于任何预测模型对特征进行排序或剔除。考虑将互信息（MI）作为一种过滤标准。目标是为 MI 估计值构建一个基于置换的零分布，然后将经验 MI 分数转换为 $p$ 值，最后应用显著性阈值来选择特征。\n\n从以下基本原理出发。对于具有联合概率质量函数 $p_{XY}(x,y)$ 和边缘概率 $p_X(x)$、$p_Y(y)$ 的两个离散随机变量 $X$ 和 $Y$，Shannon 熵定义为\n$$\nH(X) = - \\sum_{x} p_X(x) \\log p_X(x),\n$$\n而互信息（MI）定义为\n$$\nI(X;Y) = \\sum_{x} \\sum_{y} p_{XY}(x,y) \\log \\frac{p_{XY}(x,y)}{p_X(x)\\,p_Y(y)}.\n$$\n当 $X$ 和 $Y$ 作为样本 $\\{(x_i, y_i)\\}_{i=1}^N$ 被观测时，一个一致的插件估计量使用经验频率 $p_{XY}(x,y) \\approx \\frac{n_{xy}}{N}$，其中 $n_{xy}$ 是落入联合类别 $(x,y)$ 的样本计数，类似地，$p_X(x) \\approx \\frac{n_x}{N}$ 和 $p_Y(y) \\approx \\frac{n_y}{N}$。\n\n在影像组学中，特征通常是连续的。要使用前述的离散 MI 定义作为过滤器，必须首先通过分箱将每个连续特征离散化。对每个特征使用等频分箱法分成 $b$ 个箱，即计算分数 $\\frac{1}{b}, \\frac{2}{b}, \\dots, \\frac{b-1}{b}$ 处的经验分位数来定义箱边界，然后将每个观测到的特征值分配给其箱索引 $\\{0,1,\\dots,b-1\\}$。如果一个特征的所有值都相同，则将所有观测值分配给箱索引 $0$。\n\n为了构建基于置换的 MI 零分布，在 $X$ 和 $Y$ 之间相互独立的零假设下，将观测到的类别标签 $Y$ 视为可交换的。生成标签向量的 $R$ 次随机置换，并计算每个置换后的标签向量与每个离散化特征之间的 MI，从而获得一组零分布 MI 值。使用置换分布将给定特征的经验 MI $I_{\\text{emp}}$ 转换为单侧 $p$ 值：\n$$\np = \\frac{1 + \\sum_{r=1}^R \\mathbf{1}\\!\\left(I_r \\ge I_{\\text{emp}}\\right)}{1 + R},\n$$\n其中 $I_r$ 是在第 $r$ 次置换下计算的 MI，$\\mathbf{1}(\\cdot)$ 是指示函数。此定义包含一个加一校正，以避免在有限的 $R$ 下出现零 $p$ 值。对于给定的显著性水平 $\\alpha$，如果 $p \\le \\alpha$，则选择该特征。\n\n实现一个程序，对下面的每个测试用例执行以下步骤：通过等频分箱将每个特征离散化为 $b$ 个箱；计算每个离散化特征与给定二元标签之间的经验 MI；用 $R$ 次置换构建基于置换的零分布；计算得出的 $p$ 值；并返回其 $p$ 值小于或等于 $\\alpha$ 的特征的索引。MI 计算使用自然对数。不涉及物理单位。不涉及角度。与 $\\alpha$ 比较时，将 $\\alpha$ 视为实数，并报告结果时不使用百分号。\n\n测试套件和参数。为保证可复现性，请使用指定的伪随机种子。所有随机抽样均来自均值为 $0$、标准差为指定值的正态分布。\n\n- 测试用例 1（正常路径，混合信息量）：\n    - 种子: $123$\n    - 样本数 $N$: $40$\n    - 特征数 $F$: $5$\n    - 标签 $Y$: 前 $20$ 个值为 $0$，后 $20$ 个为 $1$\n    - 特征:\n        - 特征 $0$: $x^{(0)}_i = y_i + \\varepsilon_i$ 其中 $\\varepsilon_i \\sim \\mathcal{N}(0, 0.15)$\n        - 特征 $1$: $x^{(1)}_i = y_i + \\varepsilon_i$ 其中 $\\varepsilon_i \\sim \\mathcal{N}(0, 0.7)$\n        - 特征 $2$: $x^{(2)}_i = \\varepsilon_i$ 其中 $\\varepsilon_i \\sim \\mathcal{N}(0, 1.0)$\n        - 特征 $3$: 对所有 $i$，$x^{(3)}_i = 0.5$\n        - 特征 $4$: $x^{(4)}_i = 2\\,y_i + \\varepsilon_i$ 其中 $\\varepsilon_i \\sim \\mathcal{N}(0, 0.05)$\n    - 箱数 $b$: $4$\n    - 置换次数 $R$: $600$\n    - 显著性水平 $\\alpha$: $0.05$\n- 测试用例 2（边界情况，完全分离）：\n    - 种子: $456$\n    - $N$: $30$\n    - $F$: $3$\n    - 标签 $Y$: 前 $15$ 个值为 $0$，后 $15$ 个为 $1$\n    - 特征:\n        - 特征 $0$: $x^{(0)}_i = y_i$ 精确地\n        - 特征 $1$: $x^{(1)}_i = \\varepsilon_i$ 其中 $\\varepsilon_i \\sim \\mathcal{N}(0, 1.0)$\n        - 特征 $2$: $x^{(2)}_i = \\varepsilon_i$ 其中 $\\varepsilon_i \\sim \\mathcal{N}(0, 1.0)$\n    - $b$: $3$\n    - $R$: $1000$\n    - $\\alpha$: $0.01$\n- 测试用例 3（边缘情况，小样本和恒定特征）：\n    - 种子: $789$\n    - $N$: $12$\n    - $F$: $4$\n    - 标签 $Y$: 前 $6$ 个值为 $0$，后 $6$ 个为 $1$\n    - 特征:\n        - 特征 $0$: $x^{(0)}_i = y_i + \\varepsilon_i$ 其中 $\\varepsilon_i \\sim \\mathcal{N}(0, 0.4)$\n        - 特征 $1$: $x^{(1)}_i = \\varepsilon_i$ 其中 $\\varepsilon_i \\sim \\mathcal{N}(0, 1.0)$\n        - 特征 $2$: 对所有 $i$，$x^{(2)}_i = 1.7$\n        - 特征 $3$: $x^{(3)}_i = (1 - y_i) + \\varepsilon_i$ 其中 $\\varepsilon_i \\sim \\mathcal{N}(0, 0.1)$\n    - $b$: $3$\n    - $R$: $400$\n    - $\\alpha$: $0.05$\n- 测试用例 4（边缘情况，完全独立）：\n    - 种子: $13579$\n    - $N$: $50$\n    - $F$: $4$\n    - 标签 $Y$: 每个 $y_i$ 均以相等概率独立地抽取为 $0$ 或 $1$\n    - 特征:\n        - 特征 $0$: $x^{(0)}_i = \\varepsilon_i$ 其中 $\\varepsilon_i \\sim \\mathcal{N}(0, 1.0)$\n        - 特征 $1$: $x^{(1)}_i = \\varepsilon_i$ 其中 $\\varepsilon_i \\sim \\mathcal{N}(0, 1.0)$\n        - 特征 $2$: $x^{(2)}_i = \\varepsilon_i$ 其中 $\\varepsilon_i \\sim \\mathcal{N}(0, 1.0)$\n        - 特征 $3$: $x^{(3)}_i = \\varepsilon_i$ 其中 $\\varepsilon_i \\sim \\mathcal{N}(0, 1.0)$\n    - $b$: $4$\n    - $R$: $500$\n    - $\\alpha$: $0.05$\n\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，每个条目是对应测试用例的所选特征索引的升序列表。例如，正确形状的输出将类似于 $[[0,2],[0],[],[]]$，但其值由上述计算确定。", "solution": "所提出的问题是有效的，因为它具有科学依据、提法明确且客观。它基于信息论和非参数统计的既定原则，提出了一个清晰、可形式化的任务，并为获得唯一的、可验证的解提供了所有必要的数据和约束。\n\n目标是实现一个用于影像组学数据集的特征选择算法，该算法使用互信息（MI）作为过滤标准。每个特征的 MI 分数的显著性通过置换检验进行评估。每个测试用例的过程涉及几个步骤：数据生成、特征离散化、经验 MI 计算、通过置换构建 MI 的零分布、p 值计算，以及基于显著性阈值 $\\alpha$ 的最终特征选择。\n\n1.  **数据生成**：为每个测试用例模拟一个数据集。它由一个大小为 $N \\times F$ 的特征矩阵 $X$ 和一个长度为 $N$ 的二元标签向量 $Y$ 组成。这里，$N$ 是样本数，$F$ 是特征数。为保证可复现性，生成过程使用特定值作为种子，并使用伪随机数生成器从正态分布 $\\mathcal{N}(0, \\sigma^2)$ 中产生噪声。\n\n2.  **特征离散化**：所提供的互信息公式适用于离散随机变量。由于影像组学特征是连续的，必须首先对其进行离散化。指定的方法是等频分箱。对于给定的特征向量，我们将其值划分为 $b$ 个箱，每个箱包含大致相同数量的样本。这通过找到 $b-1$ 个箱边界来实现，这些边界由特征分布在分数 $\\frac{1}{b}, \\frac{2}{b}, \\dots, \\frac{b-1}{b}$ 处的经验分位数定义。然后，每个连续特征值被替换为来自 $\\{0, 1, \\dots, b-1\\}$ 的整数箱索引。对于所有值都相同的特征，会进行特殊处理；这类特征的所有样本都被分配到箱索引 $0$。这意味着该特征不携带任何信息，其熵将为 $0$。\n\n3.  **互信息估计**：计算离散化特征 $X_d$ 和类别标签向量 $Y$ 之间的 MI。MI 量化了在已知一个变量的情况下，另一个变量不确定性的减少程度。其定义为：\n    $$ I(X_d; Y) = H(X_d) + H(Y) - H(X_d, Y) $$\n    其中 $H(\\cdot)$ 表示 Shannon 熵。熵使用“插件”或最大似然估计量根据观测频率计算。对于具有概率质量函数 $p_Z(z)$ 的离散变量 $Z$，其熵为 $H(Z) = - \\sum_{z} p_Z(z) \\log p_Z(z)$，使用自然对数。概率通过计数来估计：\n    -   $p_{X_d}(k) \\approx n_k / N$ 是样本落入箱 $k$ 的概率。\n    -   $p_Y(c) \\approx n_c / N$ 是样本属于类别 $c$ 的概率。\n    -   $p_{X_d,Y}(k,c) \\approx n_{kc} / N$ 是样本处于箱 $k$ 和类别 $c$ 的联合概率。\n    这里，$n_k$、$n_c$ 和 $n_{kc}$ 分别是来自大小为 $N$ 的样本数据的相应计数。熵求和中所有概率为 $0$ 的项对总和的贡献为 $0$，因为 $\\lim_{p \\to 0} p \\log p = 0$。\n\n4.  **基于置换的显著性检验**：为确定观测到的特征 MI（表示为 $I_{\\text{emp}}$）是否在统计上显著，我们将其与一个零分布进行比较。零假设 $H_0$ 是特征和类别标签是独立的。在 $H_0$ 下，标签向量 $Y$ 的任何置换都是等可能的。\n    通过执行以下过程 $R$ 次来经验性地构建零分布：\n    -   通过随机打乱原始标签向量 $Y$ 的元素来创建置换后的标签向量 $Y^{(r)}$。\n    -   计算（固定的）离散化特征 $X_d$ 和置换后的标签向量 $Y^{(r)}$ 之间的 MI $I_r$。\n    这 $R$ 个 MI 值的集合 $\\{I_r\\}_{r=1}^R$ 作为零假设下 MI 分布的一个经验样本。\n\n5.  **p 值计算和特征选择**：通过与零分布比较，将经验 MI $I_{\\text{emp}}$ 转换为一个单侧 p 值。p 值表示在零假设下观测到等于或大于 $I_{\\text{emp}}$ 的 MI 值的概率。其计算公式为：\n    $$ p = \\frac{1 + \\sum_{r=1}^R \\mathbf{1}\\!\\left(I_r \\ge I_{\\text{emp}}\\right)}{1 + R} $$\n    其中 $\\mathbf{1}(\\cdot)$ 是指示函数，当其参数为真时为 $1$，否则为 $0$。分子和分母中的“加一”校正可防止在有限置换次数 $R$ 下 p 值为 $0$，并且也考虑了观测数据点本身。\n    最后，如果一个特征计算出的 p 值小于或等于预定义的显著性水平 $\\alpha$，则该特征被选为显著特征。每个测试用例的最终结果是所选特征索引的有序列表。", "answer": "```python\nimport numpy as np\n\ndef _calculate_mi(discretized_feature, labels, num_feature_bins, num_classes):\n    \"\"\"\n    Calculates the mutual information between a discretized feature and labels.\n    Uses the formula I(X;Y) = H(X) + H(Y) - H(X,Y).\n    \"\"\"\n    N = len(labels)\n    if N == 0:\n        return 0.0\n\n    contingency_table = np.zeros((num_feature_bins, num_classes))\n    for i in range(N):\n        contingency_table[discretized_feature[i], labels[i]] += 1\n\n    p_xy = contingency_table / N\n    p_x = np.sum(p_xy, axis=1)\n    p_y = np.sum(p_xy, axis=0)\n\n    # Filter out zero probabilities to avoid log(0)\n    p_xy_nz = p_xy[p_xy > 0]\n    p_x_nz = p_x[p_x > 0]\n    p_y_nz = p_y[p_y > 0]\n\n    h_xy = -np.sum(p_xy_nz * np.log(p_xy_nz))\n    h_x = -np.sum(p_x_nz * np.log(p_x_nz))\n    h_y = -np.sum(p_y_nz * np.log(p_y_nz))\n\n    mi = h_x + h_y - h_xy\n    # Due to floating point inaccuracies, mi can sometimes be a tiny negative number.\n    return max(0.0, mi)\n\ndef _discretize_feature(feature_vec, num_bins):\n    \"\"\"\n    Discretizes a continuous feature vector using equal-frequency binning.\n    \"\"\"\n    if np.min(feature_vec) == np.max(feature_vec):\n        return np.zeros_like(feature_vec, dtype=int)\n\n    quantiles = np.linspace(1/num_bins, (num_bins - 1)/num_bins, num_bins - 1)\n    bin_edges = np.quantile(feature_vec, quantiles)\n    \n    # searchsorted finds the insertion points, which correspond to the bin indices.\n    discretized = np.searchsorted(bin_edges, feature_vec, side='right')\n    return discretized\n\ndef process_case(case_params):\n    \"\"\"\n    Processes a single test case for feature selection.\n    \"\"\"\n    seed = case_params['seed']\n    N = case_params['N']\n    F = case_params['F']\n    b = case_params['b']\n    R = case_params['R']\n    alpha = case_params['alpha']\n    \n    rng = np.random.default_rng(seed)\n\n    # Generate labels Y\n    if 'y_def' in case_params:\n        if case_params['y_def'] == 'balanced':\n            n_class0 = N // 2\n            n_class1 = N - n_class0\n            Y = np.array([0] * n_class0 + [1] * n_class1, dtype=int)\n        elif case_params['y_def'] == 'random':\n            Y = rng.integers(0, 2, size=N, dtype=int)\n    else:\n        # Fallback for old definition\n        Y = np.array(case_params['Y'], dtype=int)\n\n\n    # Generate features X\n    X = np.zeros((N, F))\n    for j, f_def in enumerate(case_params['features']):\n        noise_std = f_def['noise_std']\n        term = f_def['term']\n        \n        eps = rng.normal(0, noise_std, size=N) if noise_std > 0 else 0\n        \n        if term == 'y':\n            X[:, j] = Y + eps\n        elif term == '2y':\n            X[:, j] = 2 * Y + eps\n        elif term == '1-y':\n            X[:, j] = (1 - Y) + eps\n        elif term == 'const':\n            X[:, j] = f_def['val']\n        elif term == 'noise_only':\n            X[:, j] = eps\n\n    num_classes = len(np.unique(Y))\n    selected_features = []\n\n    for j in range(F):\n        feature = X[:, j]\n        \n        # 1. Discretize feature\n        discretized_feature = _discretize_feature(feature, b)\n        \n        # 2. Compute empirical MI\n        I_emp = _calculate_mi(discretized_feature, Y, b, num_classes)\n        \n        # 3. Construct null distribution via permutation\n        count_ge = 0\n        for _ in range(R):\n            perm_Y = rng.permutation(Y)\n            I_r = _calculate_mi(discretized_feature, perm_Y, b, num_classes)\n            if I_r >= I_emp:\n                count_ge += 1\n        \n        # 4. Calculate p-value\n        p_value = (1 + count_ge) / (1 + R)\n        \n        # 5. Select feature if p = alpha\n        if p_value = alpha:\n            selected_features.append(j)\n            \n    return sorted(selected_features)\n\n\ndef solve():\n    test_cases = [\n        {\n            'seed': 123, 'N': 40, 'F': 5, 'b': 4, 'R': 600, 'alpha': 0.05,\n            'y_def': 'balanced',\n            'features': [\n                {'term': 'y', 'noise_std': 0.15},\n                {'term': 'y', 'noise_std': 0.7},\n                {'term': 'noise_only', 'noise_std': 1.0},\n                {'term': 'const', 'val': 0.5, 'noise_std': 0},\n                {'term': '2y', 'noise_std': 0.05},\n            ]\n        },\n        {\n            'seed': 456, 'N': 30, 'F': 3, 'b': 3, 'R': 1000, 'alpha': 0.01,\n            'y_def': 'balanced',\n            'features': [\n                {'term': 'y', 'noise_std': 0},\n                {'term': 'noise_only', 'noise_std': 1.0},\n                {'term': 'noise_only', 'noise_std': 1.0},\n            ]\n        },\n        {\n            'seed': 789, 'N': 12, 'F': 4, 'b': 3, 'R': 400, 'alpha': 0.05,\n            'y_def': 'balanced',\n            'features': [\n                {'term': 'y', 'noise_std': 0.4},\n                {'term': 'noise_only', 'noise_std': 1.0},\n                {'term': 'const', 'val': 1.7, 'noise_std': 0},\n                {'term': '1-y', 'noise_std': 0.1},\n            ]\n        },\n        {\n            'seed': 13579, 'N': 50, 'F': 4, 'b': 4, 'R': 500, 'alpha': 0.05,\n            'y_def': 'random',\n            'features': [\n                {'term': 'noise_only', 'noise_std': 1.0},\n                {'term': 'noise_only', 'noise_std': 1.0},\n                {'term': 'noise_only', 'noise_std': 1.0},\n                {'term': 'noise_only', 'noise_std': 1.0},\n            ]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = process_case(case)\n        results.append(result)\n\n    print(f\"{results}\")\n\nsolve()\n```", "id": "4539256"}]}