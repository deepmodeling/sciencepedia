{"hands_on_practices": [{"introduction": "无监督学习的核心价值在于无需预先标记就能从数据中发现内在的结构。本练习将指导您应用一种经典的基于密度的聚类算法——DBSCAN——来探索一组影像组学特征数据。通过亲手实践 [@problem_id:4561470]，您将深入理解密度、邻域和连通性等概念如何协同工作，以区分有意义的簇和随机噪声，这是在未知数据集中进行探索性分析的一项基本技能。", "problem": "考虑代表灰度共生矩阵 (GLCM) 对比度和熵的未标记二维标准化放射组学特征向量。数据集由以下 $16$ 个点组成：\n$$A_1=(0.10, 0.10),\\ A_2=(0.18, 0.12),\\ A_3=(0.12, 0.20),\\ A_4=(0.08, 0.15),\\ A_5=(0.16, 0.18),\\ A_6=(0.14, 0.08),\\ A_7=(0.20, 0.14),$$\n$$B_1=(0.80, 0.80),\\ B_2=(0.86, 0.78),\\ B_3=(0.78, 0.86),\\ B_4=(0.84, 0.88),\\ B_5=(0.76, 0.76),\\ B_6=(0.88, 0.82),\\ B_7=(0.82, 0.74),$$\n$$N_1=(0.02, 0.98),\\ N_2=(0.12, 0.88).$$\n使用邻域半径 $\\epsilon=0.5$ 和最小点数 $\\mathrm{minPts}=5$，应用基于密度的噪声应用空间聚类 (DBSCAN) 算法。距离度量使用欧几里得范数 $\\|\\cdot\\|_2$，邻域定义为标准的 DBSCAN 邻域定义 $N_{\\epsilon}(p)=\\{q:\\|q-p\\|_2\\leq \\epsilon\\}$，该定义包含点 $p$ 本身。从 DBSCAN 的基本定义出发（核心点满足 $|N_{\\epsilon}(p)|\\geq \\mathrm{minPts}$，边界点满足 $|N_{\\epsilon}(p)|  \\mathrm{minPts}$ 但位于至少一个核心点的 $\\epsilon$-邻域内，而噪声点位于所有核心点的 $\\epsilon$-邻域之外），确定哪些点是核心点、边界点或噪声点。然后，基于这些定义推导出 DBSCAN 的聚类分配，解释密度可达性和密度连通性如何在该数据集中形成聚类。\n\n报告 DBSCAN 在此数据集上发现的簇的总数作为您的唯一最终量。最终答案以无单位的整数形式表示。无需四舍五入。", "solution": "首先验证问题，以确保其科学上合理、内容完整且定义明确。\n\n### 第一步：提取已知条件\n- **数据集**：一组 $16$ 个二维点，表示为 $A_1, \\dots, A_7$、$B_1, \\dots, B_7$ 和 $N_1, N_2$。\n  - $A_1=(0.10, 0.10)$, $A_2=(0.18, 0.12)$, $A_3=(0.12, 0.20)$, $A_4=(0.08, 0.15)$, $A_5=(0.16, 0.18)$, $A_6=(0.14, 0.08)$, $A_7=(0.20, 0.14)$\n  - $B_1=(0.80, 0.80)$, $B_2=(0.86, 0.78)$, $B_3=(0.78, 0.86)$, $B_4=(0.84, 0.88)$, $B_5=(0.76, 0.76)$, $B_6=(0.88, 0.82)$, $B_7=(0.82, 0.74)$\n  - $N_1=(0.02, 0.98)$, $N_2=(0.12, 0.88)$\n- **DBSCAN 参数**：\n  - 邻域半径 $\\epsilon=0.5$\n  - 最小点数 $\\mathrm{minPts}=5$\n- **距离度量**：欧几里得范数 $\\|\\cdot\\|_2$。\n- **邻域定义**：$N_{\\epsilon}(p)=\\{q:\\|q-p\\|_2\\leq \\epsilon\\}$，包含点 $p$。\n- **点的定义**：\n  - **核心点**：如果一个点 $p$ 满足 $|N_{\\epsilon}(p)|\\geq \\mathrm{minPts}$，则它是一个核心点。\n  - **边界点**：如果一个点 $p$ 满足 $|N_{\\epsilon}(p)|  \\mathrm{minPts}$ 但它位于至少一个核心点的 $\\epsilon$-邻域内，则它是一个边界点。\n  - **噪声点**：既不是核心点也不是边界点的点。\n\n### 第二步：使用提取的已知条件进行验证\n该问题陈述是应用 DBSCAN 聚类算法的标准练习。所有数据点、参数（$\\epsilon$, $\\mathrm{minPts}$）和定义都已提供且明确无误。该问题在科学上植根于数据挖掘和机器学习领域，特别是在无监督学习中。它是一个适定问题，因为 DBSCAN 算法是确定性的，对于给定的输入将产生唯一的确定结果。没有矛盾、缺失数据或科学上不合理的情况。\n\n### 第三步：结论与行动\n该问题是**有效的**。将提供完整的解答。\n\n### 求解过程\n求解过程首先识别每个点的类型（核心、边界或噪声），然后根据密度可达性和密度连通性的原则形成簇。为了简化计算，将欧几里得距离的平方与 $\\epsilon^2 = 0.5^2 = 0.25$ 进行比较。\n\n**第一部分：邻域分析和点分类**\n\n我们通过视觉上明显的组别来分析这些点：‘A’点集、‘B’点集和‘N’点集。\n\n1.  **'A'点集的分析**：$\\{A_1, \\dots, A_7\\}$\n    这些点紧密地聚集在特征空间的低值区域。我们来计算该组中任意两点之间的最大平方距离。坐标范围为 $x$ 从 $0.08$ 到 $0.20$，$y$ 从 $0.08$ 到 $0.20$。最大的间隔可能在 $A_4=(0.08, 0.15)$ 和 $A_7=(0.20, 0.14)$ 之间。\n    $$ \\|A_7-A_4\\|_2^2 = (0.20-0.08)^2 + (0.14-0.15)^2 = 0.12^2 + (-0.01)^2 = 0.0144 + 0.0001 = 0.0145 $$\n    由于最大平方距离 $0.0145  \\epsilon^2 = 0.25$，该组中的所有 $7$ 个点都位于彼此的 $\\epsilon$-邻域内。\n    对于任意点 $p \\in \\{A_1, \\dots, A_7\\}$，其邻域 $N_{\\epsilon}(p)$ 将包含该组的所有 $7$ 个点。我们还必须检查其他组的点是否在附近。我们来检查一个中心的‘A’点，例如 $A_1=(0.10, 0.10)$，到最近的‘B’点 $B_5=(0.76, 0.76)$ 和最近的‘N’点 $N_2=(0.12, 0.88)$ 的距离。\n    $$ \\|A_1-B_5\\|_2^2 = (0.10-0.76)^2 + (0.10-0.76)^2 = (-0.66)^2 + (-0.66)^2 = 0.4356 + 0.4356 = 0.8712 > 0.25 $$\n    $$ \\|A_1-N_2\\|_2^2 = (0.10-0.12)^2 + (0.10-0.88)^2 = (-0.02)^2 + (-0.78)^2 = 0.0004 + 0.6084 = 0.6088 > 0.25 $$\n    其他组距离很远。因此，对于任意点 $p_A \\in \\{A_1, \\dots, A_7\\}$，其邻域恰好是 $N_{\\epsilon}(p_A) = \\{A_1, \\dots, A_7\\}$，其大小为 $|N_{\\epsilon}(p_A)| = 7$。\n    由于 $7 \\ge \\mathrm{minPts}=5$，所有 $7$ 个点 $\\{A_1, \\dots, A_7\\}$ 都是**核心点**。\n\n2.  **'B'点集的分析**：$\\{B_1, \\dots, B_7\\}$\n    这些点聚集在高值区域。坐标范围为 $x$ 从 $0.76$ 到 $0.88$，$y$ 从 $0.74$ 到 $0.88$。我们来检查最大平方距离，可能在 $B_5=(0.76, 0.76)$ 和 $B_4=(0.84, 0.88)$ 之间。\n    $$ \\|B_4-B_5\\|_2^2 = (0.84-0.76)^2 + (0.88-0.76)^2 = 0.08^2 + 0.12^2 = 0.0064 + 0.0144 = 0.0208 $$\n    由于 $0.0208  \\epsilon^2 = 0.25$，该组中的所有点都在彼此的 $\\epsilon$-邻域内。\n    与‘A’点集类似，‘B’点集也远离所有其他点。因此，对于任意点 $p_B \\in \\{B_1, \\dots, B_7\\}$，其邻域是 $N_{\\epsilon}(p_B) = \\{B_1, \\dots, B_7\\}$，且 $|N_{\\epsilon}(p_B)| = 7$。\n    由于 $7 \\ge \\mathrm{minPts}=5$，所有 $7$ 个点 $\\{B_1, \\dots, B_7\\}$ 也都是**核心点**。\n\n3.  **'N'点集的分析**：$\\{N_1, N_2\\}$\n    我们来检查 $N_1$ 和 $N_2$ 之间的距离。\n    $$ \\|N_1 - N_2\\|_2^2 = (0.02-0.12)^2 + (0.98-0.88)^2 = (-0.1)^2 + 0.1^2 = 0.01 + 0.01 = 0.02  0.25 $$\n    所以，$N_1$ 和 $N_2$ 在彼此的邻域内。$N_1$ 的邻域是 $N_{\\epsilon}(N_1) = \\{N_1, N_2\\}$，$N_2$ 的邻域是 $N_{\\epsilon}(N_2) = \\{N_1, N_2\\}$。每个邻域的大小都是 $2$。\n    由于 $|N_{\\epsilon}(N_1)|=2  \\mathrm{minPts}=5$ 且 $|N_{\\epsilon}(N_2)|=2  \\mathrm{minPts}=5$，所以 $N_1$ 和 $N_2$ 都不是核心点。\n    要成为边界点，它们必须位于某个核心点的 $\\epsilon$-邻域内。核心点是‘A’点集和‘B’点集。我们来检查 $N_2=(0.12, 0.88)$ 到其最近的‘A’点 $A_3=(0.12, 0.20)$ 的距离。\n    $$ \\|N_2 - A_3\\|_2^2 = (0.12-0.12)^2 + (0.88-0.20)^2 = 0^2 + 0.68^2 = 0.4624 > 0.25 $$\n    我们来检查 $N_2=(0.12, 0.88)$ 到其最近的‘B’点 $B_3=(0.78, 0.86)$ 的距离。\n    $$ \\|N_2 - B_3\\|_2^2 = (0.12-0.78)^2 + (0.88-0.86)^2 = (-0.66)^2 + 0.02^2 = 0.4356 + 0.0004 = 0.436 > 0.25 $$\n    由于最近的核心点都在 $N_1$ 和 $N_2$ 的 $\\epsilon$-半径之外，这些点不在任何核心点的邻域内。因此，它们不是边界点。\n    根据定义，既不是核心点也不是边界点的点是**噪声点**。因此，$N_1$ 和 $N_2$ 是噪声点。\n\n**第二部分：簇的形成**\n\n簇是由密度连通的点集形成的。\n- 如果存在一条路径 $p_1, \\dots, p_k$，其中 $p_1 = p$ 且 $p_k = q$，并且每个 $p_{i+1}$ 都从 $p_i$直接密度可达（即 $p_{i+1} \\in N_{\\epsilon}(p_i)$ 且 $p_i$ 是一个核心点），则称点 $q$ 从点 $p$ 是**密度可达**的。\n- 如果存在一个核心点 $o$，使得点 $p$ 和点 $q$ 都从 $o$ 密度可达，则称这两个点是**密度连通**的。\n\nDBSCAN 通过选择一个任意点，如果该点是核心点，则从该点开始扩展来寻找簇。\n\n- **簇 1**：我们从 $A_1$ 开始。我们已经确定它是一个核心点。算法创建一个新的簇。其邻域内的所有点 $\\{A_1, \\dots, A_7\\}$ 都被添加到这个簇中。然后算法从这些新添加的点开始扩展。对于该集合中的任何其他点 $A_i$，它也是一个核心点，其邻域是相同的集合 $\\{A_1, \\dots, A_7\\}$。没有新的点可以被添加。$\\{A_1, \\dots, A_7\\}$ 中的所有点彼此之间都是密度连通的（例如，通过核心点 $A_1$）。这就形成了第一个簇。\n\n- **簇 2**：我们选择一个未访问过的点，比如 $B_1$。它是一个核心点，因此创建第二个簇。它的邻域 $\\{B_1, \\dots, B_7\\}$ 被添加到这个新簇中。就像‘A’点集一样，这个集合中的所有点都是核心点，并且它们的邻域仅限于这个集合。它们彼此之间都是密度连通的，形成了第二个簇。‘A’点集和‘B’点集的邻域是不相交的，因此这两个组之间没有密度连通路径。\n\n- **噪声**：剩下未访问的点是 $N_1$ 和 $N_2$。当算法选择 $N_1$ 时，发现它不是核心点，也不属于任何现有簇，因此将其标记为噪声。对 $N_2$ 也进行同样的处理。\n\n算法终止时，识别出两个不同的簇和两个噪声点。发现的簇总数为 $2$。\n\n最终点的状态：\n- **核心点**：$\\{A_1, ..., A_7\\}$ 和 $\\{B_1, ..., B_7\\}$\n- **边界点**：无\n- **噪声点**：$\\{N_1, N_2\\}$\n- **簇**：\n  - 簇 1：$\\{A_1, A_2, A_3, A_4, A_5, A_6, A_7\\}$\n  - 簇 2：$\\{B_1, B_2, B_3, B_4, B_5, B_6, B_7\\}$\n\nDBSCAN 发现的簇总数为 $2$。", "answer": "$$\\boxed{2}$$", "id": "4561470"}, {"introduction": "与探索性分析不同，有监督学习旨在根据已有的标签来训练模型进行预测。支持向量机（SVM）是这一领域的基石算法，它通过寻找一个能以最大间隔将不同类别分开的决策边界来实现分类。这项练习 [@problem_id:4561510] 要求您为一个理想化的线性可分数据集手动推导最大间隔超平面，这不仅能巩固您对约束优化问题的理解，还能加深对SVM背后几何直觉的认识。", "problem": "一位放射组学研究员从病灶的计算机断层扫描中提取了两个标准化特征，记为 $f_1$ 和 $f_2$。经过 $z$-分数标准化后，获得一个包含 $4$ 个样本的玩具数据集，这些样本位于特征平面上的角点 $\\left(\\pm 1, \\pm 1\\right)$ 处。考虑一个监督分类任务，使用通过硬间隔支持向量机 (SVM) 训练的线性分类器将病灶区分为两类，其中支持向量机 (SVM) 是指在经验铰链损失为零和线性可分的条件下最大化间隔。\n\n样本索引如下：\n- 样本 $1$：$x_1 = \\left(1, 1\\right)$，$y_1 = +1$，\n- 样本 $2$：$x_2 = \\left(1, -1\\right)$，$y_2 = +1$，\n- 样本 $3$：$x_3 = \\left(-1, 1\\right)$，$y_3 = -1$，\n- 样本 $4$：$x_4 = \\left(-1, -1\\right)$，$y_4 = -1$，\n\n这对应于根据第一个特征的符号进行标记，$y_i = \\operatorname{sign}\\!\\left(x_{i1}\\right)$，使得数据集线性可分。设分离超平面由权重向量 $w \\in \\mathbb{R}^2$ 和偏置 $b \\in \\mathbb{R}$ 参数化，分类规则为 $\\operatorname{sign}\\!\\left(w^{\\top} x + b\\right)$。硬间隔 SVM 原始问题施加约束 $y_i\\left(w^{\\top} x_i + b\\right) \\ge 1$ 并最小化欧几里得范数的平方 $\\|w\\|_2^2$。\n\n从这些定义和约束集出发，推导最大间隔分离器并计算：\n- 几何间隔，定义为在硬间隔约束下，从决策边界到任一类别的最小距离，以及\n- 支持向量的索引。\n\n将最终答案表示为一个单行矩阵，其中第一个条目是几何间隔，其后是按升序排列的支持向量索引。无需四舍五入，也不涉及单位。", "solution": "用户想要解决一个硬间隔支持向量机 (SVM) 问题。\n\n### 步骤 1：问题验证\n\n**1.1. 提取已知条件**\n-   **数据集：**\n    -   $x_1 = (1, 1)$，$y_1 = +1$\n    -   $x_2 = (1, -1)$，$y_2 = +1$\n    -   $x_3 = (-1, 1)$，$y_3 = -1$\n    -   $x_4 = (-1, -1)$，$y_4 = -1$\n-   **分类器：** $\\operatorname{sign}(w^{\\top} x + b)$，其中 $w \\in \\mathbb{R}^2$ 且 $b \\in \\mathbb{R}$。\n-   **SVM 原始问题：** 在约束 $y_i(w^{\\top} x_i + b) \\ge 1$（$i \\in \\{1, 2, 3, 4\\}$）下，最小化 $\\|w\\|_2^2$。\n-   **任务：** 推导最大间隔分离器并计算：\n    1.  几何间隔。\n    2.  支持向量的索引。\n-   **答案格式：** 一个单行矩阵，第一个条目为几何间隔，其后是按升序排列的支持向量索引。\n\n**1.2. 使用提取的已知条件进行验证**\n-   **科学依据：** 该问题是硬间隔 SVM 算法的标准应用，这是机器学习和统计学习理论中的一个基本概念。数学公式是正确的。\n-   **适定性：** 所提供的数据集是线性可分的。对于线性可分的数据集，硬间隔 SVM 问题是一个凸优化问题，对于权重向量 $w$ 和偏置 $b$ 存在唯一解。要推导的量（几何间隔、支持向量）基于此解是良定义的。\n-   **客观性：** 问题使用精确的数学语言和定义进行陈述。没有主观或含糊的术语。\n\n**1.3. 结论**\n问题是有效的。它具有科学合理性、自洽性并且是适定的。\n\n### 步骤 2：求解推导\n\n硬间隔 SVM 的目标是找到一个超平面，该超平面到任一类别最近数据点的距离最大化。这等价于在所有数据点都被正确分类并且与决策边界的函数间隔至少为 $1$ 的约束下，最小化 $\\frac{1}{2}\\|w\\|_2^2$。\n\n优化问题是：\n$$\n\\min_{w, b} \\frac{1}{2} \\|w\\|_2^2 \\quad \\text{subject to} \\quad y_i(w^{\\top} x_i + b) \\ge 1, \\quad i=1, 2, 3, 4\n$$\n设 $w = \\begin{pmatrix} w_1 \\\\ w_2 \\end{pmatrix}$。四个数据点的约束条件是：\n1.  对于 $x_1 = (1, 1), y_1 = +1$：\n    $$+1(w^{\\top}x_1 + b) \\ge 1 \\implies w_1 \\cdot 1 + w_2 \\cdot 1 + b \\ge 1 \\implies w_1 + w_2 + b \\ge 1$$\n2.  对于 $x_2 = (1, -1), y_2 = +1$：\n    $$+1(w^{\\top}x_2 + b) \\ge 1 \\implies w_1 \\cdot 1 + w_2 \\cdot (-1) + b \\ge 1 \\implies w_1 - w_2 + b \\ge 1$$\n3.  对于 $x_3 = (-1, 1), y_3 = -1$：\n    $$-1(w^{\\top}x_3 + b) \\ge 1 \\implies -1(w_1 \\cdot (-1) + w_2 \\cdot 1 + b) \\ge 1 \\implies w_1 - w_2 - b \\ge 1$$\n4.  对于 $x_4 = (-1, -1), y_4 = -1$：\n    $$-1(w^{\\top}x_4 + b) \\ge 1 \\implies -1(w_1 \\cdot (-1) + w_2 \\cdot (-1) + b) \\ge 1 \\implies w_1 + w_2 - b \\ge 1$$\n\n$+1$ 类的数据点是 $\\{ (1, 1), (1, -1) \\}$，$-1$ 类的数据点是 $\\{ (-1, 1), (-1, -1) \\}$。这些类别由一条垂直线分隔。根据对称性，最优分离超平面必定是一条形式为 $x_1 = c$ 的垂直线，其中 $c$ 为某个常数。\n一个超平面 $w^{\\top}x + b = 0$ 是垂直的，当且仅当 $w_2 = 0$。所以我们可以设置 $w_2 = 0$。\n\n问题简化为在 $w_2=0$ 的约束下最小化 $\\frac{1}{2}w_1^2$：\n1.  $w_1 + b \\ge 1$\n2.  $w_1 + b \\ge 1$\n3.  $w_1 - b \\ge 1$\n4.  $w_1 - b \\ge 1$\n\n这些可以简化为两个不同的不等式：\n(A) $w_1 + b \\ge 1$\n(B) $w_1 - b \\ge 1$\n\n为确保正确分类，我们需要 $\\operatorname{sign}(w_1 x_{i1} + b) = y_i$。对于 $x_1=(1,1), y_1=1$，我们需要 $w_1+b > 0$，这由 (A) 满足。对于 $x_3=(-1,1), y_3=-1$，我们需要 $-w_1+b  0 \\implies w_1 > b$，这由 (B) 满足，因为 $w_1 \\ge 1+b$。将 (A) 和 (B) 两个不等式相加，得到 $2w_1 \\ge 2$，所以 $w_1 \\ge 1$。\n这意味着 $w_1$ 必须是正数。\n\n为了最小化 $w_1^2$（或 $\\frac{1}{2}w_1^2$），我们需要找到 $|w_1|$ 的最小可能值。由于 $w_1 \\ge 1$，当 $w_1$ 尽可能接近 $0$ 时，$w_1^2$ 达到最小值，即 $w_1 = 1$。\n\n现在我们来求 $b$ 的值。将 $w_1 = 1$ 代入不等式中：\n(A) $1 + b \\ge 1 \\implies b \\ge 0$\n(B) $1 - b \\ge 1 \\implies -b \\ge 0 \\implies b \\le 0$\n唯一同时满足 $b \\ge 0$ 和 $b \\le 0$ 的 $b$ 值是 $b=0$。\n\n因此，分离超平面的最优参数是 $w = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ 和 $b = 0$。\n决策边界是 $w^{\\top}x + b = 0$，即 $1 \\cdot x_1 + 0 \\cdot x_2 + 0 = 0$，或 $x_1 = 0$。\n\n**几何间隔的计算**\n几何间隔 $\\gamma$ 定义为从决策边界到最近训练样本的距离。对于硬间隔 SVM，此距离由 $\\gamma = \\frac{1}{\\|w\\|_2}$ 给出。\n当 $w = (1, 0)^{\\top}$ 时，欧几里得范数为：\n$$\n\\|w\\|_2 = \\sqrt{w_1^2 + w_2^2} = \\sqrt{1^2 + 0^2} = 1\n$$\n因此，几何间隔为：\n$$\n\\gamma = \\frac{1}{1} = 1\n$$\n\n**支持向量的确定**\n支持向量是那些正好位于间隔超平面上的数据点 $x_i$，即不等式约束变为等式（激活）的点：\n$$\ny_i (w^{\\top}x_i + b) = 1\n$$\n让我们用我们的解 $w=(1, 0)^{\\top}$ 和 $b=0$ 来检验这四个点：\n1.  样本 $1$：$y_1(w^{\\top}x_1 + b) = +1(1 \\cdot 1 + 0 \\cdot 1 + 0) = 1$。约束被激活。\n2.  样本 $2$：$y_2(w^{\\top}x_2 + b) = +1(1 \\cdot 1 + 0 \\cdot (-1) + 0) = 1$。约束被激活。\n3.  样本 $3$：$y_3(w^{\\top}x_3 + b) = -1(1 \\cdot (-1) + 0 \\cdot 1 + 0) = -1(-1) = 1$。约束被激活。\n4.  样本 $4$：$y_4(w^{\\top}x_4 + b) = -1(1 \\cdot (-1) + 0 \\cdot (-1) + 0) = -1(-1) = 1$。约束被激活。\n\n由于所有四个数据点的约束都被激活，所以这四个点都是支持向量。它们的索引是 $1, 2, 3, 4$。\n\n**最终答案的构建**\n要求的输出是一个行矩阵，包含几何间隔，后面跟着按升序排列的支持向量的索引。\n-   几何间隔：$1$\n-   支持向量索引：$1, 2, 3, 4$\n最终的行矩阵是 $\\begin{pmatrix} 1  1  2  3  4 \\end{pmatrix}$。", "answer": "$$\n\\boxed{\\begin{pmatrix} 1  1  2  3  4 \\end{pmatrix}}\n$$", "id": "4561510"}, {"introduction": "在实际的影像组学研究中，数据往往来自不同的设备或中心，由此产生的“批次效应”是模型性能的主要障碍。这个问题揭示了不恰当的数据处理方法会如何引入系统性偏差，即使是像标准化这样看似简单的步骤。通过对比一种“无监督”的合并标准化方法和一种“有监督”的、考虑了扫描仪来源的校正方法 [@problem_id:4561535]，本练习突显了在应用机器学习技术之前，理解并恰当处理数据异质性的极端重要性。", "problem": "在一项计算机断层扫描（CT）的放射组学研究中，体素强度以亨氏单位（Hounsfield Units, HU）来衡量。考虑两批患者：扫描仪 A 有 $n_A=70$ 名患者，扫描仪 B 有 $n_B=50$ 名患者。由于已知的硬件校准偏移，对于健康组织，扫描仪 B 相对于扫描仪 A 表现出 $\\delta=15$ HU 的全局强度漂移。假设在每台扫描仪内部，给定的放射组学强度特征 $X$ 服从一个分布，其扫描仪内标准差 $\\sigma$ 相同，而扫描仪特定的均值分别为 $\\mu_A$ 和 $\\mu_B=\\mu_A+\\delta$。令混合 $z$-分数归一化定义为 $z=(x-\\mu_{\\text{pool}})/s_{\\text{pool}}$，其中 $\\mu_{\\text{pool}}$ 和 $s_{\\text{pool}}$ 是根据合并的 $n_A+n_B$ 个观测值计算出的样本均值和样本标准差，计算时忽略扫描仪身份（无监督）。\n\n从 $z$-分数归一化的基本定义、全期望定律以及混合模型的全方差定律出发，推导在每个扫描仪队列中，混合 $z$-分数的期望均值和方差，从而量化当存在已知的扫描仪间漂移 $\\delta$ 时，混合归一化引入的偏差。然后，计算使用扫描仪标签（有监督）来消除扫描仪间漂移的、针对特定扫描仪的校正后标准化参数，并将这些参数仅用混合统计量 $\\mu_{\\text{pool}}$、$s_{\\text{pool}}$、样本量 $n_A$、$n_B$ 和已知的漂移 $\\delta$ 来表示。\n\n您的最终表达式必须消除未知的 $\\mu_A$ 和 $\\sigma$，并且只依赖于 $\\mu_{\\text{pool}}$、$s_{\\text{pool}}$、$n_A$、$n_B$ 和 $\\delta$。将最终答案以单行矩阵的形式给出，按顺序包含：\n- 扫描仪 A 中的期望混合归一化均值，$\\mathbb{E}[z \\mid A]$。\n- 扫描仪 A 中的混合归一化方差，$\\operatorname{Var}(z \\mid A)$。\n- 扫描仪 B 中的期望混合归一化均值，$\\mathbb{E}[z \\mid B]$。\n- 扫描仪 B 中的混合归一化方差，$\\operatorname{Var}(z \\mid B)$。\n- 扫描仪 A 的校正后扫描仪内均值，$\\mu_A^{\\text{corr}}$。\n- 扫描仪 A 的校正后扫描仪内标准差，$\\sigma_A^{\\text{corr}}$。\n- 扫描仪 B 的校正后扫描仪内均值，$\\mu_B^{\\text{corr}}$。\n- 扫描仪 B 的校正后扫描仪内标准差，$\\sigma_B^{\\text{corr}}$。\n\n用符号表示您的最终答案，并将给定的数值 $n_A=70$、$n_B=50$ 和 $\\delta=15$ 嵌入到适当的位置。不需要四舍五入。最终的方框表达式中不要包含单位。", "solution": "首先验证问题，以确保其具有科学依据、提法恰当且客观。\n\n### 步骤 1：提取已知条件\n-   扫描仪 A 患者数量：$n_A = 70$。\n-   扫描仪 B 患者数量：$n_B = 50$。\n-   总患者数量：$N = n_A + n_B = 120$。\n-   扫描仪 B 相对于 A 的强度漂移：$\\delta = 15$ HU。\n-   来自扫描仪 A 的放射组学特征 $X$ 是一个随机变量，其均值为 $\\mu_A$，标准差为 $\\sigma$。\n-   来自扫描仪 B 的相同特征 $X$ 是一个随机变量，其均值为 $\\mu_B = \\mu_A + \\delta$，标准差为 $\\sigma$。\n-   混合 $z$-分数归一化定义为 $z = (x - \\mu_{\\text{pool}}) / s_{\\text{pool}}$，其中 $\\mu_{\\text{pool}}$ 和 $s_{\\text{pool}}$ 是来自合并的 $n_A+n_B$ 个观测值的样本均值和样本标准差。\n-   任务是推导 $\\mathbb{E}[z \\mid A]$、$\\operatorname{Var}(z \\mid A)$、$\\mathbb{E}[z \\mid B]$、$\\operatorname{Var}(z \\mid B)$ 以及校正后的标准化参数 $\\mu_A^{\\text{corr}}$、$\\sigma_A^{\\text{corr}}$、$\\mu_B^{\\text{corr}}$、$\\sigma_B^{\\text{corr}}$ 的表达式。\n-   最终表达式必须以 $\\mu_{\\text{pool}}$、$s_{\\text{pool}}$、$n_A$、$n_B$ 和 $\\delta$ 表示。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题描述了医学影像数据分析中的一个现实场景，称为校正批次效应或扫描仪效应。其统计模型是一个标准的混合模型。均值、方差、$z$-分数归一化、全期望定律和全方差定律等概念都是基本的统计学原理。该问题定义明确、客观，并包含足够的信息，可以在样本统计量（$\\mu_{\\text{pool}}, s_{\\text{pool}}$）是混合分布真实总体矩的良好估计这一合理假设下，推导出唯一解。因此，该问题被认定为有效。\n\n### 步骤 3：结论与行动\n问题有效。将提供完整解答。\n\n### 推导过程\n设 $K$ 为表示扫描仪的随机变量，其取值为 $A$ 和 $B$。观测值来自每台扫描仪的概率即为样本比例：\n$$p_A = P(K=A) = \\frac{n_A}{n_A + n_B} = \\frac{70}{120} = \\frac{7}{12}$$\n$$p_B = P(K=B) = \\frac{n_B}{n_A + n_B} = \\frac{50}{120} = \\frac{5}{12}$$\n给定的条件矩为：\n$\\mathbb{E}[X \\mid K=A] = \\mu_A$\n$\\mathbb{E}[X \\mid K=B] = \\mu_B = \\mu_A + \\delta$\n$\\operatorname{Var}(X \\mid K=A) = \\operatorname{Var}(X \\mid K=B) = \\sigma^2$\n\n我们将未知参数 $\\mu_A$ 和 $\\sigma$ 与给定的混合样本统计量 $\\mu_{\\text{pool}}$ 和 $s_{\\text{pool}}$ 联系起来。我们使用的原理是，对于大样本，样本统计量是混合分布真实总体矩的可靠估计。\n\n首先，我们对混合数据应用全期望定律：\n$$\\mathbb{E}[X] = \\mathbb{E}[\\mathbb{E}[X \\mid K]] = \\mathbb{E}[X \\mid A] p_A + \\mathbb{E}[X \\mid B] p_B$$\n用 $\\mu_{\\text{pool}}$ 近似 $\\mathbb{E}[X]$：\n$$\\mu_{\\text{pool}} \\approx \\mu_A p_A + (\\mu_A + \\delta) p_B = \\mu_A (p_A + p_B) + \\delta p_B = \\mu_A + \\delta p_B$$\n由此，我们可以用已知量表示未知的 $\\mu_A$：\n$$\\mu_A \\approx \\mu_{\\text{pool}} - \\delta p_B = \\mu_{\\text{pool}} - \\delta \\frac{n_B}{n_A + n_B}$$\n\n接下来，我们应用全方差定律：\n$$\\operatorname{Var}(X) = \\mathbb{E}[\\operatorname{Var}(X \\mid K)] + \\operatorname{Var}(\\mathbb{E}[X \\mid K])$$\n用 $s_{\\text{pool}}^2$ 近似 $\\operatorname{Var}(X)$：\n第一项是扫描仪内方差的平均值：\n$$\\mathbb{E}[\\operatorname{Var}(X \\mid K)] = \\operatorname{Var}(X \\mid A) p_A + \\operatorname{Var}(X \\mid B) p_B = \\sigma^2 p_A + \\sigma^2 p_B = \\sigma^2$$\n第二项是条件期望的方差（扫描仪间方差）：\n$$\\operatorname{Var}(\\mathbb{E}[X \\mid K]) = \\mathbb{E}[(\\mathbb{E}[X \\mid K])^2] - (\\mathbb{E}[\\mathbb{E}[X \\mid K]])^2$$\n$$= (\\mu_A^2 p_A + \\mu_B^2 p_B) - (\\mu_{\\text{pool}})^2$$\n一个更直接的方法是：\n$$\\operatorname{Var}(\\mathbb{E}[X \\mid K]) = (\\mathbb{E}[X \\mid A] - \\mathbb{E}[X])^2 p_A + (\\mathbb{E}[X \\mid B] - \\mathbb{E}[X])^2 p_B$$\n$$ \\approx (\\mu_A - \\mu_{\\text{pool}})^2 p_A + (\\mu_B - \\mu_{\\text{pool}})^2 p_B$$\n代入 $\\mu_A \\approx \\mu_{\\text{pool}} - \\delta p_B$ 和 $\\mu_B = \\mu_A + \\delta \\approx \\mu_{\\text{pool}} + \\delta(1-p_B) = \\mu_{\\text{pool}} + \\delta p_A$：\n$$\\operatorname{Var}(\\mathbb{E}[X \\mid K]) \\approx (-\\delta p_B)^2 p_A + (\\delta p_A)^2 p_B = \\delta^2 p_B^2 p_A + \\delta^2 p_A^2 p_B = \\delta^2 p_A p_B (p_A + p_B) = \\delta^2 p_A p_B$$\n$$\\operatorname{Var}(\\mathbb{E}[X \\mid K]) \\approx \\delta^2 \\frac{n_A n_B}{(n_A + n_B)^2}$$\n合并各项得到总方差：\n$$s_{\\text{pool}}^2 \\approx \\sigma^2 + \\delta^2 \\frac{n_A n_B}{(n_A + n_B)^2}$$\n由此，我们可以用已知量表示未知的 $\\sigma^2$：\n$$\\sigma^2 \\approx s_{\\text{pool}}^2 - \\delta^2 \\frac{n_A n_B}{(n_A + n_B)^2}$$\n\n现在我们可以推导前四个所需的量。混合 $z$-分数变换为 $z(x) = (x - \\mu_{\\text{pool}}) / s_{\\text{pool}}$。\n\n1.  **扫描仪 A 中的期望混合归一化均值, $\\mathbb{E}[z \\mid A]$**:\n    $$\\mathbb{E}[z \\mid A] = \\mathbb{E}\\left[\\frac{X - \\mu_{\\text{pool}}}{s_{\\text{pool}}} \\mid A \\right] = \\frac{\\mathbb{E}[X \\mid A] - \\mu_{\\text{pool}}}{s_{\\text{pool}}} = \\frac{\\mu_A - \\mu_{\\text{pool}}}{s_{\\text{pool}}}$$\n    代入我们对 $\\mu_A$ 的表达式：\n    $$\\mathbb{E}[z \\mid A] \\approx \\frac{(\\mu_{\\text{pool}} - \\delta \\frac{n_B}{n_A+n_B}) - \\mu_{\\text{pool}}}{s_{\\text{pool}}} = -\\frac{\\delta}{s_{\\text{pool}}} \\frac{n_B}{n_A+n_B}$$\n\n2.  **扫描仪 A 中的混合归一化方差, $\\operatorname{Var}(z \\mid A)$**:\n    $$\\operatorname{Var}(z \\mid A) = \\operatorname{Var}\\left(\\frac{X - \\mu_{\\text{pool}}}{s_{\\text{pool}}} \\mid A \\right) = \\frac{\\operatorname{Var}(X \\mid A)}{s_{\\text{pool}}^2} = \\frac{\\sigma^2}{s_{\\text{pool}}^2}$$\n    代入我们对 $\\sigma^2$ 的表达式：\n    $$\\operatorname{Var}(z \\mid A) \\approx \\frac{s_{\\text{pool}}^2 - \\delta^2 \\frac{n_A n_B}{(n_A+n_B)^2}}{s_{\\text{pool}}^2} = 1 - \\frac{\\delta^2}{s_{\\text{pool}}^2} \\frac{n_A n_B}{(n_A+n_B)^2}$$\n\n3.  **扫描仪 B 中的期望混合归一化均值, $\\mathbb{E}[z \\mid B]$**:\n    $$\\mathbb{E}[z \\mid B] = \\frac{\\mathbb{E}[X \\mid B] - \\mu_{\\text{pool}}}{s_{\\text{pool}}} = \\frac{\\mu_B - \\mu_{\\text{pool}}}{s_{\\text{pool}}} = \\frac{(\\mu_A + \\delta) - \\mu_{\\text{pool}}}{s_{\\text{pool}}}$$\n    代入我们对 $\\mu_A$ 的表达式：\n    $$\\mathbb{E}[z \\mid B] \\approx \\frac{(\\mu_{\\text{pool}} - \\delta \\frac{n_B}{n_A+n_B} + \\delta) - \\mu_{\\text{pool}}}{s_{\\text{pool}}} = \\frac{\\delta(1 - \\frac{n_B}{n_A+n_B})}{s_{\\text{pool}}} = \\frac{\\delta}{s_{\\text{pool}}} \\frac{n_A}{n_A+n_B}$$\n\n4.  **扫描仪 B 中的混合归一化方差, $\\operatorname{Var}(z \\mid B)$**:\n    $$\\operatorname{Var}(z \\mid B) = \\frac{\\operatorname{Var}(X \\mid B)}{s_{\\text{pool}}^2} = \\frac{\\sigma^2}{s_{\\text{pool}}^2}$$\n    这与扫描仪 A 的方差相同：\n    $$\\operatorname{Var}(z \\mid B) \\approx 1 - \\frac{\\delta^2}{s_{\\text{pool}}^2} \\frac{n_A n_B}{(n_A+n_B)^2}$$\n\n结果表明，混合归一化在每个子组的均值中引入了偏差（$\\mathbb{E}[z \\mid A] \\neq 0$ 且 $\\mathbb{E}[z \\mid B] \\neq 0$），并减小了组内方差（$\\operatorname{Var}(z \\mid K)  1$），这是因为混合方差 $s_{\\text{pool}}^2$ 被扫描仪间的方差分量所夸大。\n\n最后，我们推导校正后的（有监督的）标准化参数。这些参数应对应于每个扫描仪队列内的真实均值和标准差。\n5.  **扫描仪 A 的校正后均值, $\\mu_A^{\\text{corr}}$**: 这即为 $\\mu_A$。\n    $$\\mu_A^{\\text{corr}} = \\mu_A \\approx \\mu_{\\text{pool}} - \\delta \\frac{n_B}{n_A + n_B}$$\n\n6.  **扫描仪 A 的校正后标准差, $\\sigma_A^{\\text{corr}}$**: 这即为 $\\sigma$。\n    $$\\sigma_A^{\\text{corr}} = \\sigma \\approx \\sqrt{s_{\\text{pool}}^2 - \\delta^2 \\frac{n_A n_B}{(n_A + n_B)^2}}$$\n\n7.  **扫描仪 B 的校正后均值, $\\mu_B^{\\text{corr}}$**: 这即为 $\\mu_B = \\mu_A + \\delta$。\n    $$\\mu_B^{\\text{corr}} = \\mu_A + \\delta \\approx \\left(\\mu_{\\text{pool}} - \\delta \\frac{n_B}{n_A + n_B}\\right) + \\delta = \\mu_{\\text{pool}} + \\delta \\frac{n_A}{n_A + n_B}$$\n\n8.  **扫描仪 B 的校正后标准差, $\\sigma_B^{\\text{corr}}$**: 这也等于 $\\sigma$，因为假定扫描仪内的标准差是相同的。\n    $$\\sigma_B^{\\text{corr}} = \\sigma \\approx \\sqrt{s_{\\text{pool}}^2 - \\delta^2 \\frac{n_A n_B}{(n_A + n_B)^2}}$$\n\n现在我们代入给定的数值：$n_A = 70$，$n_B = 50$，$N = n_A+n_B = 120$，以及 $\\delta = 15$。\n常数因子为：\n$\\frac{n_B}{N} = \\frac{50}{120} = \\frac{5}{12}$\n$\\frac{n_A}{N} = \\frac{70}{120} = \\frac{7}{12}$\n$\\frac{n_A n_B}{N^2} = \\frac{70 \\times 50}{120^2} = \\frac{3500}{14400} = \\frac{35}{144}$\n\n-   $\\mathbb{E}[z \\mid A] \\approx -\\frac{15}{s_{\\text{pool}}} \\left(\\frac{5}{12}\\right) = -\\frac{75}{12 s_{\\text{pool}}} = -\\frac{25}{4 s_{\\text{pool}}}$.\n-   $\\operatorname{Var}(z \\mid A) \\approx 1 - \\frac{15^2}{s_{\\text{pool}}^2} \\left(\\frac{35}{144}\\right) = 1 - \\frac{225 \\times 35}{144 s_{\\text{pool}}^2} = 1 - \\frac{7875}{144 s_{\\text{pool}}^2} = 1 - \\frac{875}{16 s_{\\text{pool}}^2}$.\n-   $\\mathbb{E}[z \\mid B] \\approx \\frac{15}{s_{\\text{pool}}} \\left(\\frac{7}{12}\\right) = \\frac{105}{12 s_{\\text{pool}}} = \\frac{35}{4 s_{\\text{pool}}}$.\n-   $\\operatorname{Var}(z \\mid B) \\approx 1 - \\frac{875}{16 s_{\\text{pool}}^2}$.\n-   $\\mu_A^{\\text{corr}} \\approx \\mu_{\\text{pool}} - 15 \\left(\\frac{5}{12}\\right) = \\mu_{\\text{pool}} - \\frac{75}{12} = \\mu_{\\text{pool}} - \\frac{25}{4}$.\n-   $\\sigma_A^{\\text{corr}} \\approx \\sqrt{s_{\\text{pool}}^2 - 15^2 \\left(\\frac{35}{144}\\right)} = \\sqrt{s_{\\text{pool}}^2 - \\frac{7875}{144}} = \\sqrt{s_{\\text{pool}}^2 - \\frac{875}{16}}$.\n-   $\\mu_B^{\\text{corr}} \\approx \\mu_{\\text{pool}} + 15 \\left(\\frac{7}{12}\\right) = \\mu_{\\text{pool}} + \\frac{105}{12} = \\mu_{\\text{pool}} + \\frac{35}{4}$.\n-   $\\sigma_B^{\\text{corr}} \\approx \\sqrt{s_{\\text{pool}}^2 - \\frac{875}{16}}$.\n\n这八个表达式构成了最终答案。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n-\\frac{25}{4 s_{\\text{pool}}}  1 - \\frac{875}{16 s_{\\text{pool}}^2}  \\frac{35}{4 s_{\\text{pool}}}  1 - \\frac{875}{16 s_{\\text{pool}}^2}  \\mu_{\\text{pool}} - \\frac{25}{4}  \\sqrt{s_{\\text{pool}}^2 - \\frac{875}{16}}  \\mu_{\\text{pool}} + \\frac{35}{4}  \\sqrt{s_{\\text{pool}}^2 - \\frac{875}{16}}\n\\end{pmatrix}\n}\n$$", "id": "4561535"}]}