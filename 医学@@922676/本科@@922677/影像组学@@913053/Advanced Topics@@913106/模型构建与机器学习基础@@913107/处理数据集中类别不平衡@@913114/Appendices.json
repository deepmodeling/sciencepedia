{"hands_on_practices": [{"introduction": "在处理类别不平衡问题时，首要任务是理解不平衡如何从根本上影响分类模型的决策过程。本练习将引导你通过一个经典的统计模型——线性判别分析（LDA），来从数学上推导并应用先验概率。通过这个实践，你将亲手揭示类别比例如何直接调整决策边界，这是许多先进的成本敏感学习算法的理论基石 [@problem_id:4543135]。", "problem": "建立一个放射组学分类器，用以区分两种肿瘤表型。该分类器使用两个标准化特征，记作特征向量 $\\mathbf{x} \\in \\mathbb{R}^{2}$。由于数据集中侵袭性肿瘤比惰性肿瘤更为罕见，因此必须通过分类器中的先验几率来考虑类别不平衡问题。假设基础模型如下：\n\n- 两个类条件分布 $p(\\mathbf{x}\\,|\\,y=k)$（其中 $k \\in \\{0,1\\}$）是具有公共协方差矩阵的多元正态分布，即 $p(\\mathbf{x}\\,|\\,y=k) = \\mathcal{N}(\\boldsymbol{\\mu}_{k}, \\boldsymbol{\\Sigma})$，其中两个类别的 $\\boldsymbol{\\Sigma}$ 相同。\n- 在错分成本相等的情况下，Bayes决策规则选择具有较大概率 $p(y=k\\,|\\,\\mathbf{x})$ 的类别，这等效于使用一个包含类先验概率 $p(y=1)$ 和 $p(y=0)$ 的似然比检验。\n- 多元正态密度函数由下式给出\n$$\np(\\mathbf{x}\\,|\\,y=k) = \\frac{1}{(2\\pi)^{d/2} |\\boldsymbol{\\Sigma}|^{1/2}} \\exp\\!\\left(-\\frac{1}{2}(\\mathbf{x}-\\boldsymbol{\\mu}_{k})^{\\top}\\boldsymbol{\\Sigma}^{-1}(\\mathbf{x}-\\boldsymbol{\\mu}_{k})\\right),\n$$\n其中 $d=2$。\n\n任务1（推导）：仅从Bayes决策规则和上述具有公共$\\boldsymbol{\\Sigma}$的$p(\\mathbf{x}\\,|\\,y=k)$形式出发，推导明确包含先验几率 $p(y=1)/p(y=0)$ 的线性判别分析（LDA）决策规则。证明该规则可以写成“如果 $\\mathbf{w}^{\\top}\\mathbf{x} \\ge t$ 则判定为 $y=1$，否则判定为 $y=0$”的形式，并用 $\\boldsymbol{\\mu}_{0}$、$\\boldsymbol{\\mu}_{1}$、$\\boldsymbol{\\Sigma}$ 以及先验概率 $p(y=1)$ 和 $p(y=0)$ 来表示 $\\mathbf{w}$ 和 $t$。简要解释先验几率如何移动阈值。\n\n任务2（计算）：在某项具体的放射组学研究中，从训练中估计出的参数为\n$$\n\\boldsymbol{\\mu}_{1} = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix},\\quad\n\\boldsymbol{\\mu}_{0} = \\begin{pmatrix} 0 \\\\ \\tfrac{1}{2} \\end{pmatrix},\\quad\n\\boldsymbol{\\Sigma} = \\begin{pmatrix} \\tfrac{3}{2}  0 \\\\ 0  \\tfrac{1}{2} \\end{pmatrix},\n$$\n估计的类先验概率（反映了类别不平衡）为 $p(y=1) = 0.15$ 和 $p(y=0) = 0.85$。使用您在任务1中的推导，计算一维判别式 $y = \\mathbf{w}^{\\top}\\mathbf{x}$ 中的标量阈值 $t$。将您的最终数值结果四舍五入到四位有效数字。答案中不要包含任何单位。", "solution": "该问题经评估是有效的。它在统计模式识别方面有科学依据，提法恰当，信息充分且一致，并且陈述客观。它构成了线性判别分析（LDA）的标准推导和应用。\n\n任务1：LDA决策规则的推导\n\nBayes决策规则规定，我们应该选择使后验概率 $p(y=k\\,|\\,\\mathbf{x})$ 最大化的类别 $k$。为了区分类别 $y=1$ 和 $y=0$，如果类别 $y=1$ 的后验概率大于或等于类别 $y=0$ 的后验概率，我们则判定为 $y=1$。（根据问题中决策规则的形式 $\\mathbf{w}^{\\top}\\mathbf{x} \\ge t$，边界情况 $p(y=1\\,|\\,\\mathbf{x}) = p(y=0\\,|\\,\\mathbf{x})$ 被划分给类别1）。\n规则是：如果 $p(y=1\\,|\\,\\mathbf{x}) \\ge p(y=0\\,|\\,\\mathbf{x})$，则判定为 $y=1$。\n\n使用Bayes定理 $p(y=k\\,|\\,\\mathbf{x}) = \\frac{p(\\mathbf{x}\\,|\\,y=k)p(y=k)}{p(\\mathbf{x})}$，决策规则变为：\n$$\n\\frac{p(\\mathbf{x}\\,|\\,y=1)p(y=1)}{p(\\mathbf{x})} \\ge \\frac{p(\\mathbf{x}\\,|\\,y=0)p(y=0)}{p(\\mathbf{x})}\n$$\n证据项 $p(\\mathbf{x})$ 是一个正的公共因子，可以被消去，从而得到一个基于似然和先验的规则：\n$$\np(\\mathbf{x}\\,|\\,y=1)p(y=1) \\ge p(\\mathbf{x}\\,|\\,y=0)p(y=0)\n$$\n为了简化表达式，我们对两边取自然对数。由于对数是单调递增函数，这不会改变决策边界。\n$$\n\\ln(p(\\mathbf{x}\\,|\\,y=1)) + \\ln(p(y=1)) \\ge \\ln(p(\\mathbf{x}\\,|\\,y=0)) + \\ln(p(y=0))\n$$\n多元正态分布的类条件概率密度函数如下：\n$$\np(\\mathbf{x}\\,|\\,y=k) = \\frac{1}{(2\\pi)^{d/2} |\\boldsymbol{\\Sigma}|^{1/2}} \\exp\\!\\left(-\\frac{1}{2}(\\mathbf{x}-\\boldsymbol{\\mu}_{k})^{\\top}\\boldsymbol{\\Sigma}^{-1}(\\mathbf{x}-\\boldsymbol{\\mu}_{k})\\right)\n$$\n该密度函数的自然对数是：\n$$\n\\ln(p(\\mathbf{x}\\,|\\,y=k)) = -\\ln\\left((2\\pi)^{d/2} |\\boldsymbol{\\Sigma}|^{1/2}\\right) - \\frac{1}{2}(\\mathbf{x}-\\boldsymbol{\\mu}_{k})^{\\top}\\boldsymbol{\\Sigma}^{-1}(\\mathbf{x}-\\boldsymbol{\\mu}_{k})\n$$\n将此式代入决策不等式，常数项 $-\\ln\\left((2\\pi)^{d/2} |\\boldsymbol{\\Sigma}|^{1/2}\\right)$ 对两个类别是相同的（因为 $\\boldsymbol{\\Sigma}$ 是公共的），因此可以消去：\n$$\n-\\frac{1}{2}(\\mathbf{x}-\\boldsymbol{\\mu}_{1})^{\\top}\\boldsymbol{\\Sigma}^{-1}(\\mathbf{x}-\\boldsymbol{\\mu}_{1}) + \\ln(p(y=1)) \\ge -\\frac{1}{2}(\\mathbf{x}-\\boldsymbol{\\mu}_{0})^{\\top}\\boldsymbol{\\Sigma}^{-1}(\\mathbf{x}-\\boldsymbol{\\mu}_{0}) + \\ln(p(y=0))\n$$\n现在，我们展开二次型 $(\\mathbf{x}-\\boldsymbol{\\mu}_{k})^{\\top}\\boldsymbol{\\Sigma}^{-1}(\\mathbf{x}-\\boldsymbol{\\mu}_{k})$：\n$$\n(\\mathbf{x}-\\boldsymbol{\\mu}_{k})^{\\top}\\boldsymbol{\\Sigma}^{-1}(\\mathbf{x}-\\boldsymbol{\\mu}_{k}) = \\mathbf{x}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\mathbf{x} - 2\\boldsymbol{\\mu}_{k}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\mathbf{x} + \\boldsymbol{\\mu}_{k}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_{k}\n$$\n将这些展开式代入不等式得到：\n$$\n-\\frac{1}{2}\\left(\\mathbf{x}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\mathbf{x} - 2\\boldsymbol{\\mu}_{1}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\mathbf{x} + \\boldsymbol{\\mu}_{1}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_{1}\\right) + \\ln(p(y=1)) \\ge -\\frac{1}{2}\\left(\\mathbf{x}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\mathbf{x} - 2\\boldsymbol{\\mu}_{0}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\mathbf{x} + \\boldsymbol{\\mu}_{0}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_{0}\\right) + \\ln(p(y=0))\n$$\n$\\mathbf{x}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\mathbf{x}$ 项在不等式两边都存在，因此可以消去。正是这次消去使得决策边界是线性的。我们剩下：\n$$\n\\boldsymbol{\\mu}_{1}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\mathbf{x} - \\frac{1}{2}\\boldsymbol{\\mu}_{1}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_{1} + \\ln(p(y=1)) \\ge \\boldsymbol{\\mu}_{0}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\mathbf{x} - \\frac{1}{2}\\boldsymbol{\\mu}_{0}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_{0} + \\ln(p(y=0))\n$$\n重新整理，将包含 $\\mathbf{x}$ 的项组合到左侧，所有其他（常数）项组合到右侧：\n$$\n(\\boldsymbol{\\mu}_{1}^{\\top}\\boldsymbol{\\Sigma}^{-1} - \\boldsymbol{\\mu}_{0}^{\\top}\\boldsymbol{\\Sigma}^{-1})\\mathbf{x} \\ge \\frac{1}{2}\\boldsymbol{\\mu}_{1}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_{1} - \\frac{1}{2}\\boldsymbol{\\mu}_{0}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_{0} + \\ln(p(y=0)) - \\ln(p(y=1))\n$$\n这可以改写为：\n$$\n(\\boldsymbol{\\mu}_{1} - \\boldsymbol{\\mu}_{0})^{\\top}\\boldsymbol{\\Sigma}^{-1}\\mathbf{x} \\ge \\frac{1}{2}(\\boldsymbol{\\mu}_{1}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_{1} - \\boldsymbol{\\mu}_{0}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_{0}) + \\ln\\left(\\frac{p(y=0)}{p(y=1)}\\right)\n$$\n这个表达式是所需的形式 $\\mathbf{w}^{\\top}\\mathbf{x} \\ge t$。我们可以确定线性判别向量 $\\mathbf{w}$ 和标量阈值 $t$。\n从表达式 $(\\boldsymbol{\\mu}_{1} - \\boldsymbol{\\mu}_{0})^{\\top}\\boldsymbol{\\Sigma}^{-1}\\mathbf{x}$，我们有 $\\mathbf{w}^{\\top} = (\\boldsymbol{\\mu}_{1} - \\boldsymbol{\\mu}_{0})^{\\top}\\boldsymbol{\\Sigma}^{-1}$。取转置并注意到 $\\boldsymbol{\\Sigma}^{-1}$ 是对称的（因为 $\\boldsymbol{\\Sigma}$ 是对称的），我们得到：\n$$\n\\mathbf{w} = \\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{\\mu}_{1} - \\boldsymbol{\\mu}_{0})\n$$\n阈值 $t$ 是不等式的整个右侧：\n$$\nt = \\frac{1}{2}(\\boldsymbol{\\mu}_{1}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_{1} - \\boldsymbol{\\mu}_{0}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_{0}) + \\ln\\left(\\frac{p(y=0)}{p(y=1)}\\right)\n$$\n先验几率 $\\frac{p(y=1)}{p(y=0)}$ 通过项 $\\ln\\left(\\frac{p(y=0)}{p(y=1)}\\right) = -\\ln\\left(\\frac{p(y=1)}{p(y=0)}\\right)$ 被引入。这一项直接移动决策阈值 $t$。如果类别1是少数类，那么 $p(y=1)  p(y=0)$，这使得比率 $\\frac{p(y=0)}{p(y=1)} > 1$ 且其对数为正。这个对数几率项的正值会增加阈值 $t$。更高的阈值意味着投影值 $\\mathbf{w}^{\\top}\\mathbf{x}$ 必须更大才能将一个观测值分类到类别1。这有效地缩小了少数类的决策区域，需要来自数据更强的证据（似然项）来克服低的先验概率。\n\n任务2：阈值 $t$ 的计算\n\n给定参数为：\n$$\n\\boldsymbol{\\mu}_{1} = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}, \\quad \\boldsymbol{\\mu}_{0} = \\begin{pmatrix} 0 \\\\ \\frac{1}{2} \\end{pmatrix}, \\quad \\boldsymbol{\\Sigma} = \\begin{pmatrix} \\frac{3}{2}  0 \\\\ 0  \\frac{1}{2} \\end{pmatrix}\n$$\n$$\np(y=1) = 0.15, \\quad p(y=0) = 0.85\n$$\n我们必须使用推导出的公式来计算阈值 $t$。首先，我们求协方差矩阵 $\\boldsymbol{\\Sigma}$ 的逆矩阵。由于 $\\boldsymbol{\\Sigma}$ 是一个对角矩阵，它的逆矩阵是对角线上元素为原对角元素倒数的对角矩阵：\n$$\n\\boldsymbol{\\Sigma}^{-1} = \\begin{pmatrix} (\\frac{3}{2})^{-1}  0 \\\\ 0  (\\frac{1}{2})^{-1} \\end{pmatrix} = \\begin{pmatrix} \\frac{2}{3}  0 \\\\ 0  2 \\end{pmatrix}\n$$\n接下来，我们计算表达式 $t$ 中的两个二次型项：\n$$\n\\boldsymbol{\\mu}_{1}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_{1} = \\begin{pmatrix} 2  1 \\end{pmatrix} \\begin{pmatrix} \\frac{2}{3}  0 \\\\ 0  2 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = 2 \\cdot \\frac{2}{3} \\cdot 2 + 1 \\cdot 2 \\cdot 1 = \\frac{8}{3} + 2 = \\frac{14}{3}\n$$\n$$\n\\boldsymbol{\\mu}_{0}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_{0} = \\begin{pmatrix} 0  \\frac{1}{2} \\end{pmatrix} \\begin{pmatrix} \\frac{2}{3}  0 \\\\ 0  2 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ \\frac{1}{2} \\end{pmatrix} = 0 \\cdot \\frac{2}{3} \\cdot 0 + \\frac{1}{2} \\cdot 2 \\cdot \\frac{1}{2} = \\frac{1}{2}\n$$\n现在，我们计算阈值 $t$ 的第一部分：\n$$\n\\frac{1}{2}(\\boldsymbol{\\mu}_{1}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_{1} - \\boldsymbol{\\mu}_{0}^{\\top}\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_{0}) = \\frac{1}{2}\\left(\\frac{14}{3} - \\frac{1}{2}\\right) = \\frac{1}{2}\\left(\\frac{28-3}{6}\\right) = \\frac{1}{2}\\left(\\frac{25}{6}\\right) = \\frac{25}{12}\n$$\n接下来，我们计算对数先验几率项：\n$$\n\\ln\\left(\\frac{p(y=0)}{p(y=1)}\\right) = \\ln\\left(\\frac{0.85}{0.15}\\right) = \\ln\\left(\\frac{17}{3}\\right)\n$$\n最后，我们将这两部分相加得到阈值 $t$：\n$$\nt = \\frac{25}{12} + \\ln\\left(\\frac{17}{3}\\right)\n$$\n为了获得数值，我们计算这两项：\n$$\n\\frac{25}{12} \\approx 2.08333...\n$$\n$$\n\\ln\\left(\\frac{17}{3}\\right) \\approx 1.73460...\n$$\n$$\nt \\approx 2.08333 + 1.73460 = 3.81793...\n$$\n将结果四舍五入到四位有效数字，得到 $t = 3.818$。", "answer": "$$\\boxed{3.818}$$", "id": "4543135"}, {"introduction": "在机器学习流程中，遵循正确的操作顺序至关重要，尤其是在处理不平衡数据集时。一个常见的严重错误是在进行交叉验证切分之前就对整个数据集进行过采样，这会导致数据泄露。本练习通过一个假设场景，让你从第一性原理出发，定量分析这种错误操作如何人为地夸大模型性能指标（如AUC），从而让你深刻理解维持数据独立性的重要性 [@problem_id:4543122]。", "problem": "在一项影像组学研究中，您正在构建一个二分类器，使用定量图像特征来区分恶性与良性病变。阳性（恶性）类别是少数类。您使用$k$折交叉验证和受试者工作特征曲线下面积（AUC）来评估模型。一个实现错误在交叉验证分割之前应用了合成少数类过采样技术（SMOTE）进行过采样，导致源自验证集中阳性样本的合成样本进入了训练折。结果，训练好的模型部分记忆了某些验证集阳性样本的模式，导致其预测的实值边界分数出现加性增加。\n\n假设如下：\n1. 在没有任何泄露的情况下，阳性案例和阴性案例的验证分数是独立的，并且服从方差相等的正态分布：阳性分数为 $S_{\\text{pos}} \\sim \\mathcal{N}(\\mu_{p}, \\sigma^{2})$，阴性分数为 $S_{\\text{neg}} \\sim \\mathcal{N}(\\mu_{n}, \\sigma^{2})$。\n2. 由于不正确的过采样顺序，比例为 $\\alpha$ 的验证集阳性案例在训练折中有了合成克隆。对于这些阳性案例，训练后模型的验证分数向上移动了一个加性常数 $\\delta$，因此它们的分数服从 $\\mathcal{N}(\\mu_{p}+\\delta, \\sigma^{2})$ 分布。剩余比例为 $1-\\alpha$ 的阳性案例的分数仍服从 $\\mathcal{N}(\\mu_{p}, \\sigma^{2})$ 分布。阴性案例的分数仍服从 $\\mathcal{N}(\\mu_{n}, \\sigma^{2})$ 分布，并与阳性案例独立。\n3. 将AUC视为在相应的分数分布下，一个随机抽取的阳性案例的分数高于一个随机抽取的阴性案例的分数的概率。\n\n假设参数为 $\\mu_{p}-\\mu_{n}=1$, $\\sigma=1$, $\\delta=1$, 以及 $\\alpha=0.2$。在这些假设下，从第一性原理推导无泄露时的期望AUC和有泄露时的期望AUC，然后计算定义为含有泄露的AUC与干净的AUC之差的期望AUC膨胀值。将最终结果表示为小数，并四舍五入至四位有效数字。", "solution": "该问题要求计算在影像组学分类任务中，由于特定数据泄露场景导致的受试者工作特征曲线下面积（AUC）的期望膨胀值。该泄露是由于在为$k$折交叉验证分割数据之前应用了合成少数类过采样技术（SMOTE）。我们将首先推导在无泄露情况下的AUC表达式，然后推导有泄露情况下的AUC，最后计算它们的差值。\n\n设 $S_{\\text{pos}}$ 为阳性案例的分数，$S_{\\text{neg}}$ 为阴性案例的分数。AUC定义为随机抽取的阳性案例分数高于随机抽取的阴性案例分数的概率，即 $AUC = P(S_{\\text{pos}}  S_{\\text{neg}})$。这等同于计算 $P(S_{\\text{pos}} - S_{\\text{neg}}  0)$。\n\n**1. 无泄露时的期望AUC ($AUC_{\\text{clean}}$)**\n\n根据问题陈述，在无泄露的场景下，分数分布如下：\n$S_{\\text{pos}} \\sim \\mathcal{N}(\\mu_{p}, \\sigma^{2})$\n$S_{\\text{neg}} \\sim \\mathcal{N}(\\mu_{n}, \\sigma^{2})$\n\n令差值为 $D = S_{\\text{pos}} - S_{\\text{neg}}$。由于 $S_{\\text{pos}}$ 和 $S_{\\text{neg}}$ 是独立的服从正态分布的随机变量，它们的差值 $D$ 也服从正态分布。\n差值的均值为 $E[D] = E[S_{\\text{pos}}] - E[S_{\\text{neg}}] = \\mu_{p} - \\mu_{n}$。\n差值的方差为 $\\text{Var}(D) = \\text{Var}(S_{\\text{pos}}) + \\text{Var}(S_{\\text{neg}}) = \\sigma^{2} + \\sigma^{2} = 2\\sigma^{2}$。\n所以，$D \\sim \\mathcal{N}(\\mu_{p} - \\mu_{n}, 2\\sigma^{2})$。\n\n干净的AUC是概率 $P(D  0)$。为了计算这个概率，我们对变量 $D$ 进行标准化：\n$$\nAUC_{\\text{clean}} = P(D  0) = P\\left(\\frac{D - (\\mu_{p} - \\mu_{n})}{\\sqrt{2\\sigma^{2}}}  \\frac{0 - (\\mu_{p} - \\mu_{n})}{\\sqrt{2\\sigma^{2}}}\\right)\n$$\n令 $Z = \\frac{D - (\\mu_{p} - \\mu_{n})}{\\sqrt{2}\\sigma}$ 为一个标准正态变量，$Z \\sim \\mathcal{N}(0, 1)$。\n$$\nAUC_{\\text{clean}} = P\\left(Z  -\\frac{\\mu_{p} - \\mu_{n}}{\\sqrt{2}\\sigma}\\right)\n$$\n使用标准正态累积分布函数（CDF）$\\Phi(z)$ 的性质 $P(Z  -z) = P(Z  z) = \\Phi(z)$，我们得到：\n$$\nAUC_{\\text{clean}} = \\Phi\\left(\\frac{\\mu_{p} - \\mu_{n}}{\\sqrt{2}\\sigma}\\right)\n$$\n\n**2. 有泄露时的期望AUC ($AUC_{\\text{leaky}}$)**\n\n在有数据泄露的情况下，比例为 $\\alpha$ 的阳性样本的分数从 $\\mathcal{N}(\\mu_{p}+\\delta, \\sigma^{2})$ 中抽取，而剩余比例为 $1-\\alpha$ 的样本分数从 $\\mathcal{N}(\\mu_{p}, \\sigma^{2})$ 中抽取。阴性样本的分数仍然服从 $\\mathcal{N}(\\mu_{n}, \\sigma^{2})$ 分布。\n\n设 $S'_{\\text{pos}}$ 为在含有泄露的场景下随机选择的阳性案例的分数。其分布是一个双组分混合分布。我们可以使用全概率公式，以阳性样本是否来自受影响组为条件，来计算含有泄露的AUC，$AUC_{\\text{leaky}} = P(S'_{\\text{pos}}  S_{\\text{neg}})$。\n\n$$\nAUC_{\\text{leaky}} = P(S'_{\\text{pos}}  S_{\\text{neg}} | \\text{受影响})P(\\text{受影响}) + P(S'_{\\text{pos}}  S_{\\text{neg}} | \\text{未受影响})P(\\text{未受影响})\n$$\n\n这里，$P(\\text{受影响}) = \\alpha$ 且 $P(\\text{未受影响}) = 1-\\alpha$。\n\n对于未受影响的阳性样本的项与干净情况相同：\n$P(S'_{\\text{pos}}  S_{\\text{neg}} | \\text{未受影响}) = \\Phi\\left(\\frac{\\mu_{p} - \\mu_{n}}{\\sqrt{2}\\sigma}\\right)$。\n\n对于受影响的阳性样本，其分数为 $S_{\\text{pos, aff}} \\sim \\mathcal{N}(\\mu_{p}+\\delta, \\sigma^{2})$。差值为 $D_{\\text{aff}} = S_{\\text{pos, aff}} - S_{\\text{neg}}$。\n该差值的分布为 $D_{\\text{aff}} \\sim \\mathcal{N}((\\mu_{p}+\\delta) - \\mu_{n}, 2\\sigma^{2})$。\n相应的AUC分量为：\n$P(D_{\\text{aff}}  0) = \\Phi\\left(\\frac{(\\mu_{p} - \\mu_{n}) + \\delta}{\\sqrt{2}\\sigma}\\right)$。\n\n将这些结合起来，总的含有泄露的AUC为：\n$$\nAUC_{\\text{leaky}} = \\alpha \\cdot \\Phi\\left(\\frac{(\\mu_{p} - \\mu_{n}) + \\delta}{\\sqrt{2}\\sigma}\\right) + (1-\\alpha) \\cdot \\Phi\\left(\\frac{\\mu_{p} - \\mu_{n}}{\\sqrt{2}\\sigma}\\right)\n$$\n\n**3. AUC膨胀值 ($\\Delta \\text{AUC}$)**\n\nAUC的膨胀值是含有泄露的AUC与干净的AUC之差：\n$\\Delta \\text{AUC} = AUC_{\\text{leaky}} - AUC_{\\text{clean}}$\n$$\n\\Delta \\text{AUC} = \\left[ \\alpha \\Phi\\left(\\frac{(\\mu_{p} - \\mu_{n}) + \\delta}{\\sqrt{2}\\sigma}\\right) + (1-\\alpha) \\Phi\\left(\\frac{\\mu_{p} - \\mu_{n}}{\\sqrt{2}\\sigma}\\right) \\right] - \\Phi\\left(\\frac{\\mu_{p} - \\mu_{n}}{\\sqrt{2}\\sigma}\\right)\n$$\n$$\n\\Delta \\text{AUC} = \\alpha \\Phi\\left(\\frac{(\\mu_{p} - \\mu_{n}) + \\delta}{\\sqrt{2}\\sigma}\\right) + \\Phi\\left(\\frac{\\mu_{p} - \\mu_{n}}{\\sqrt{2}\\sigma}\\right) - \\alpha \\Phi\\left(\\frac{\\mu_{p} - \\mu_{n}}{\\sqrt{2}\\sigma}\\right) - \\Phi\\left(\\frac{\\mu_{p} - \\mu_{n}}{\\sqrt{2}\\sigma}\\right)\n$$\n$$\n\\Delta \\text{AUC} = \\alpha \\left[ \\Phi\\left(\\frac{(\\mu_{p} - \\mu_{n}) + \\delta}{\\sqrt{2}\\sigma}\\right) - \\Phi\\left(\\frac{\\mu_{p} - \\mu_{n}}{\\sqrt{2}\\sigma}\\right) \\right]\n$$\n\n**4. 数值计算**\n\n我们已知的参数值为：$\\mu_{p}-\\mu_{n}=1$, $\\sigma=1$, $\\delta=1$, 和 $\\alpha=0.2$。将这些值代入 $\\Delta \\text{AUC}$ 的表达式中：\n$$\n\\Delta \\text{AUC} = 0.2 \\left[ \\Phi\\left(\\frac{1 + 1}{\\sqrt{2} \\cdot 1}\\right) - \\Phi\\left(\\frac{1}{\\sqrt{2} \\cdot 1}\\right) \\right]\n$$\n$$\n\\Delta \\text{AUC} = 0.2 \\left[ \\Phi\\left(\\frac{2}{\\sqrt{2}}\\right) - \\Phi\\left(\\frac{1}{\\sqrt{2}}\\right) \\right]\n$$\n$$\n\\Delta \\text{AUC} = 0.2 \\left[ \\Phi(\\sqrt{2}) - \\Phi\\left(\\frac{1}{\\sqrt{2}}\\right) \\right]\n$$\n现在我们计算自变量的数值：\n$\\sqrt{2} \\approx 1.41421$\n$1/\\sqrt{2} \\approx 0.70711$\n\n使用标准正态CDF值：\n$\\Phi(\\sqrt{2}) \\approx \\Phi(1.41421) \\approx 0.92135$\n$\\Phi(1/\\sqrt{2}) \\approx \\Phi(0.70711) \\approx 0.76025$\n\n将这些值代入 $\\Delta \\text{AUC}$ 的表达式中：\n$$\n\\Delta \\text{AUC} \\approx 0.2 \\times (0.92135 - 0.76025)\n$$\n$$\n\\Delta \\text{AUC} \\approx 0.2 \\times 0.16110\n$$\n$$\n\\Delta \\text{AUC} \\approx 0.03222\n$$\n题目要求答案四舍五入到四位有效数字。计算出的值为 $0.03222$。第一位有效数字是 $3$，后面跟着 $2$, $2$, 和 $2$。第五位有效数字（未写出）小于 $5$，因此结果保持为 $0.03222$。\n\n为了获得更高的精度：\n$\\Phi(\\sqrt{2}) \\approx 0.921354541$\n$\\Phi(1/\\sqrt{2}) \\approx 0.760250107$\n$\\Delta\\text{AUC} = 0.2 \\times (0.921354541 - 0.760250107) = 0.2 \\times 0.161104434 = 0.0322208868$。\n四舍五入到四位有效数字得到 $0.03222$。", "answer": "$$\n\\boxed{0.03222}\n$$", "id": "4543122"}, {"introduction": "当面对不平衡且样本量较小的数据集时，单一的性能评估指标（如敏感度）可能存在很大的随机性，无法可靠地反映模型的真实性能。本练习将指导你完成一项高级但非常实用的编程任务：实现偏差校正和加速（BCa）自助法（bootstrap）。通过这项实践，你将学会如何为关键性能指标估计置信区间，从而对模型的能力给出一个更稳健、更可信的评估 [@problem_id:4543151]。", "problem": "给定一个小型、不平衡的放射组学队列，其中少数类对应于具有特定结果的患者，标记为阳性类。任务是实现一个偏差校正和加速（BCa）自举程序（bootstrap procedure），以估计少数类敏感度指标的置信区间。少数类敏感度（也称为真阳性率）对于二元预测定义为被正确预测为阳性的少数类患者的比例。您的程序必须是一个完整、可运行的程序，并为指定的测试套件生成所要求的输出。\n\n使用的基本基础和定义：\n- 设二元真实标签表示为 $\\mathbf{y} = (y_1,\\dots,y_n)$，其中 $y_i \\in \\{0,1\\}$，$y_i=1$ 表示属于少数类（阳性类），$y_i=0$ 表示属于多数类（阴性类）。\n- 设二元预测表示为 $\\hat{\\mathbf{y}} = (\\hat{y}_1,\\dots,\\hat{y}_n)$，其中 $\\hat{y}_i \\in \\{0,1\\}$。\n- 少数类敏感度 $S$ 定义为\n$$\nS(\\mathbf{y}, \\hat{\\mathbf{y}}) \\equiv \\frac{\\sum_{i=1}^{n} \\mathbb{1}\\{y_i=1 \\text{ and } \\hat{y}_i=1\\}}{\\sum_{i=1}^{n} \\mathbb{1}\\{y_i=1\\}},\n$$\n其中 $\\mathbb{1}\\{\\cdot\\}$ 是指示函数。$S$ 的值必须表示为小数（而非百分比）。\n- 非参数自举原则要求从经验数据中有放回地抽样，以近似统计量的抽样分布。在不平衡的情况下，使用分层重抽样，以使每个自举复制中的少数类和多数类样本数量等于其原始计数，从而保持类别不平衡结构。\n- 偏差校正和加速（BCa）方法使用两个量来调整百分位置信区间：\n  - 偏差校正参数 $z_0$，源自小于观测统计量的自举复制的比例。\n  - 加速参数 $a$，源自通过每次留出一个观测值计算出的刀切法（jackknife）影响值。\n- 标准正态分布及其累积分布函数 $\\Phi(\\cdot)$ 和分位数函数 $\\Phi^{-1}(\\cdot)$ 是用于调整的经过充分检验的事实。\n\nBCa 区间构建：\n1. 计算观测统计量 $t = S(\\mathbf{y}, \\hat{\\mathbf{y}})$。\n2. 生成 $B$ 个分层自举复制以获得 $\\{t^{\\ast}_b\\}_{b=1}^{B}$ 并计算\n$$\nz_0 = \\Phi^{-1}\\left(\\frac{1}{B}\\sum_{b=1}^{B} \\mathbb{1}\\{t^{\\ast}_b  t\\}\\right).\n$$\n3. 计算刀切法留一法估计 $\\{t_{(i)}\\}_{i=1}^{n}$，并令 $\\bar{t}_{(\\cdot)}$ 为其平均值。加速参数为\n$$\na = \\frac{\\sum_{i=1}^{n} \\left(\\bar{t}_{(\\cdot)} - t_{(i)}\\right)^3}{6\\left[\\sum_{i=1}^{n} \\left(\\bar{t}_{(\\cdot)} - t_{(i)}\\right)^2\\right]^{3/2}}.\n$$\n如果分母为零或刀切法未明确定义（例如，少数类计数为 $1$），则设 $a=0$。\n4. 对于名义置信水平 $1-\\alpha$，定义 $z_{\\alpha/2} = \\Phi^{-1}(\\alpha/2)$ 和 $z_{1-\\alpha/2} = \\Phi^{-1}(1-\\alpha/2)$。BCa 调整后的累积概率为\n$$\n\\alpha_{1}^{\\text{adj}} = \\Phi\\!\\left(z_0 + \\frac{z_0 + z_{\\alpha/2}}{1 - a\\,(z_0 + z_{\\alpha/2})}\\right), \\quad\n\\alpha_{2}^{\\text{adj}} = \\Phi\\!\\left(z_0 + \\frac{z_0 + z_{1-\\alpha/2}}{1 - a\\,(z_0 + z_{1-\\alpha/2})}\\right).\n$$\nBCa 置信区间端点是 $\\{t^{\\ast}_b\\}$ 在 $\\alpha_{1}^{\\text{adj}}$ 和 $\\alpha_{2}^{\\text{adj}}$ 处的经验分位数。如果所有自举复制都与 $t$ 相同，则返回退化区间 $[t,t]$。\n\n科学真实性要求：\n- 使用二元预测和标签；敏感度仅取决于少数类子集。分层重抽样保持了不平衡队列结构，这对于样本量小的放射组学队列至关重要。\n\n单位和格式：\n- 敏感度值和置信区间端点必须表示为小数。\n- 本问题不使用角度。\n- 您的程序应生成一行输出，其中包含用方括号括起来的逗号分隔的结果列表。对于每个测试用例，按顺序列出 BCa 的下限和上限端点，扁平化为单个列表。将每个端点四舍五入到六位小数。例如，输出格式为 $[\\text{low}_1,\\text{high}_1,\\text{low}_2,\\text{high}_2,\\dots]$。\n\n测试套件和参数：\n- 对所有测试用例使用 $B=2000$ 个自举复制和 $\\alpha=0.05$（名义 $95\\%$ 置信水平，以小数表示为 $1-\\alpha=0.95$）。\n\n提供以下三个测试用例：\n1. 正常情况中度不平衡：\n   - 真实标签 $\\mathbf{y}^{(1)} = [1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0]$。\n   - 预测 $\\hat{\\mathbf{y}}^{(1)} = [1,1,0,1,0,1,1,0,0,1,0,0,0,1,0,0,0,0,0,1]$。\n2. 边界条件（高观测敏感度）：\n   - 真实标签 $\\mathbf{y}^{(2)} = [1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]$。\n   - 预测 $\\hat{\\mathbf{y}}^{(2)} = [1,1,1,1,1,0,0,0,1,0,1,0,0,0,0,0,0,1,0,0]$。\n3. 边缘情况（极少数类计数和低敏感度）：\n   - 真实标签 $\\mathbf{y}^{(3)} = [1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]$。\n   - 预测 $\\hat{\\mathbf{y}}^{(3)} = [1,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0]$。\n\n输出规范：\n- 您的程序应生成一行输出，其中包含用方括号括起来的逗号分隔的结果列表。该列表必须包含 $6$ 个浮点数：测试用例 $1$ 的 BCa 下限和上限端点，然后是测试用例 $2$ 的，最后是测试用例 $3$ 的。每个浮点数必须四舍五入到六位小数。最终格式必须完全为 $[\\text{low}_1,\\text{high}_1,\\text{low}_2,\\text{high}_2,\\text{low}_3,\\text{high}_3]$。", "solution": "该问题要求实现偏差校正和加速（BCa）自举程序，以根据给定的真实标签集和二元预测集，计算少数类敏感度指标的置信区间。\n\n### 步骤 1：问题陈述的验证\n\n首先，根据指定标准对问题进行仔细验证。\n\n#### 提取已知条件\n- **关注的统计量**：少数类敏感度，$S(\\mathbf{y}, \\hat{\\mathbf{y}}) \\equiv \\frac{\\sum_{i=1}^{n} \\mathbb{1}\\{y_i=1 \\text{ and } \\hat{y}_i=1\\}}{\\sum_{i=1}^{n} \\mathbb{1}\\{y_i=1\\}}$，其中 $\\mathbf{y}$ 是真实标签，$\\hat{\\mathbf{y}}$ 是预测。\n- **自举方法**：分层重抽样，使用 $B=2000$ 个复制。\n- **置信水平**：$1-\\alpha = 0.95$，因此 $\\alpha=0.05$。\n- **BCa 参数**：\n  - 偏差校正：$z_0 = \\Phi^{-1}\\left(\\frac{1}{B}\\sum_{b=1}^{B} \\mathbb{1}\\{t^{\\ast}_b  t\\}\\right)$，其中 $t$ 是观测统计量，$t^*_b$ 是自举复制的统计量。\n  - 加速：$a = \\frac{\\sum_{i=1}^{n} \\left(\\bar{t}_{(\\cdot)} - t_{(i)}\\right)^3}{6\\left[\\sum_{i=1}^{n} \\left(\\bar{t}_{(\\cdot)} - t_{(i)}\\right)^2\\right]^{3/2}}$，其中 $t_{(i)}$ 是统计量的刀切法留一法估计，$\\bar{t}_{(\\cdot)}$ 是它们的均值。\n- **BCa 端点**：自举分布 $\\{t^{\\ast}_b\\}$ 在调整水平 $\\alpha_{1}^{\\text{adj}}$ 和 $\\alpha_{2}^{\\text{adj}}$ 处的经验分位数，其中：\n  $$ \\alpha_{1}^{\\text{adj}} = \\Phi\\!\\left(z_0 + \\frac{z_0 + z_{\\alpha/2}}{1 - a\\,(z_0 + z_{\\alpha/2})}\\right) $$\n  $$ \\alpha_{2}^{\\text{adj}} = \\Phi\\!\\left(z_0 + \\frac{z_0 + z_{1-\\alpha/2}}{1 - a\\,(z_0 + z_{1-\\alpha/2})}\\right) $$\n  其中 $z_{\\alpha/2} = \\Phi^{-1}(\\alpha/2)$ 且 $z_{1-\\alpha/2} = \\Phi^{-1}(1-\\alpha/2)$。\n- **边缘情况规则**：\n  1. 如果用于计算 $a$ 的刀切法分母为零，或少数类计数为 $1$，则设 $a=0$。\n  2. 如果所有自举复制都与 $t$ 相同，则置信区间为 $[t,t]$。\n- **测试数据**：三个测试用例，包含指定的 $\\mathbf{y}$ 和 $\\hat{\\mathbf{y}}$ 向量。\n- **输出格式**：一个扁平化的列表，包含三个测试用例的置信区间下限和上限，四舍五入到六位小数，格式为 $[\\text{low}_1,\\text{high}_1,\\text{low}_2,\\text{high}_2,\\text{low}_3,\\text{high}_3]$。\n\n#### 验证结论\n该问题是**有效的**。\n1.  **科学上是合理的**：BCa自举法是统计推断中一个标准且成熟的方法。敏感度的定义以及对不平衡数据使用分层重抽样，对于所述的放射组学背景是正确且恰当的。所有提供的公式都是统计文献中的标准定义。\n2.  **定义明确的**：该问题在算法上是完整的。它提供了所有必要的数据、参数和明确的公式。它还定义了对潜在边缘情况的处理，确保可以计算出唯一、稳定且有意义的解。\n3.  **客观的**：该问题使用精确的数学定义和客观要求进行陈述，没有主观或模糊的语言。\n\n### 步骤 2：解决方案设计与实现原理\n\n解决方案将是一个 Python 程序，为每个测试用例实现 BCa 程序。核心逻辑封装在一个函数中，该函数遵循问题陈述中定义的步骤。\n\n1.  **敏感度计算**：一个辅助函数计算敏感度 $S(\\mathbf{y}, \\hat{\\mathbf{y}})$。它分离出少数类样本（其中 $y_i=1$），并计算其中被正确预测的比例（其中 $\\hat{y}_i=1$）。如果没有少数类样本，该统计量未定义；我们通过返回 `np.nan` 来处理这种情况，尽管所提供的测试用例中主要统计量不会遇到此情况。\n\n2.  **观测统计量**：对于每个测试用例，在完整数据集上计算观测敏感度 $t = S(\\mathbf{y}, \\hat{\\mathbf{y}})$。\n\n3.  **分层自举**：生成 $B=2000$ 个自举复制。对于每个复制：\n    - 识别少数类（$P$）和多数类（$N$）的索引。\n    - 通过从少数类索引中有放回地抽样以填充 $|P|$ 个位置，以及从多数类索引中有放回地抽样以填充 $|N|$ 个位置，来创建一组新的索引。这保留了原始的类别分布。\n    - 在此自举样本上计算敏感度 $t^*_b$。\n    集合 $\\{t_b^*\\}_{b=1}^{B}$ 构成了经验自举分布。会进行特殊检查，看是否所有 $t_b^*$ 都与 $t$ 相同；如果是，则程序终止并按指示返回退化区间 $[t,t]$。\n\n4.  **偏差校正参数 ($z_0$)**：通过找到严格小于观测统计量 $t$ 的自举统计量 $t^*_b$ 的比例，然后应用标准正态分位数函数 $\\Phi^{-1}$，来计算偏差校正参数 $z_0$。这衡量了自举分布的中位数偏差。\n\n5.  **加速参数 ($a$)**：加速参数 $a$ 校正了统计量的标准误差相对于真实参数值的变化率。它使用刀切法留一法重抽样来估计。\n    - 根据问题的规则，如果原始少数类计数小于或等于 $1$，则认为刀切法程序定义不明确，将 $a$ 设为 $0$。\n    - 否则，对于每个观测值 $i \\in \\{1, \\dots, n\\}$，通过移除第 $i$ 个数据点 $(\\mathbf{y}_{(i)}, \\hat{\\mathbf{y}}_{(i)})$ 来创建一个刀切法复制。\n    - 为这 $n$ 个刀切法数据集中的每一个计算敏感度 $t_{(i)}$。\n    - 刀切法值集合 $\\{t_{(i)}\\}$ 用于通过提供的公式计算 $a$，该公式是刀切法影响值偏度的函数。包含对 $a$ 的公式中分母为零的检查，若发生则将 $a$ 设为 $0$。\n\n6.  **置信区间端点**：\n    - 为 $\\alpha=0.05$ 计算标准正态分位数 $z_{\\alpha/2}$ 和 $z_{1-\\alpha/2}$。\n    - 这些值与 $z_0$ 和 $a$ 一起用于 BCa 公式中，以计算调整后的百分位水平 $\\alpha_{1}^{\\text{adj}}$ 和 $\\alpha_{2}^{\\text{adj}}$。\n    - 最终的置信区间是通过找到排序后的自举分布 $\\{t^*_b\\}$ 的 $\\alpha_{1}^{\\text{adj}}$ 和 $\\alpha_{2}^{\\text{adj}}$ 经验分位数获得的。`numpy.quantile` 函数为此提供了一种标准的、基于插值的方法。\n\n将整个程序应用于三个测试用例中的每一个，以生成所需的六个输出值。为了保证自举抽样的可复现性，使用了一个固定的随机种子。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Main function to solve the BCa bootstrap problem for the given test suite.\n    \"\"\"\n    \n    # Define test cases as per the problem statement\n    test_cases = [\n        {\n            \"y_true\": np.array([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n            \"y_pred\": np.array([1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]),\n        },\n        {\n            \"y_true\": np.array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n            \"y_pred\": np.array([1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0]),\n        },\n        {\n            \"y_true\": np.array([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n            \"y_pred\": np.array([1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n        }\n    ]\n\n    B = 2000\n    alpha = 0.05\n    # Use a fixed random seed for reproducibility of bootstrap results\n    rng = np.random.default_rng(42)\n\n    results = []\n\n    for case in test_cases:\n        y_true = case[\"y_true\"]\n        y_pred = case[\"y_pred\"]\n        \n        ci_lower, ci_upper = bca_confidence_interval(\n            y_true, y_pred, B, alpha, rng\n        )\n        \n        results.extend([ci_lower, ci_upper])\n\n    # Format the final output as a comma-separated list of floats rounded to 6 decimal places\n    formatted_results = [f\"{x:.6f}\" for x in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\n\ndef sensitivity(y_true, y_pred):\n    \"\"\"Computes minority class sensitivity.\"\"\"\n    minority_indices = np.where(y_true == 1)[0]\n    if len(minority_indices) == 0:\n        return np.nan  # Sensitivity is undefined if there are no positive cases\n    \n    true_positives = np.sum(y_pred[minority_indices] == 1)\n    return true_positives / len(minority_indices)\n\n\ndef bca_confidence_interval(y_true, y_pred, B, alpha, rng):\n    \"\"\"\n    Computes the BCa bootstrap confidence interval for sensitivity.\n    \"\"\"\n    n = len(y_true)\n    t_obs = sensitivity(y_true, y_pred)\n\n    # Stratified bootstrap\n    minority_indices = np.where(y_true == 1)[0]\n    majority_indices = np.where(y_true == 0)[0]\n    \n    t_star = np.zeros(B)\n    for i in range(B):\n        # Stratified resampling of indices\n        resampled_minority_indices = rng.choice(minority_indices, size=len(minority_indices), replace=True)\n        resampled_majority_indices = rng.choice(majority_indices, size=len(majority_indices), replace=True)\n        \n        resampled_indices = np.concatenate((resampled_minority_indices, resampled_majority_indices))\n        \n        y_true_boot = y_true[resampled_indices]\n        y_pred_boot = y_pred[resampled_indices]\n        \n        t_star[i] = sensitivity(y_true_boot, y_pred_boot)\n    \n    # Handle degenerate case where all bootstrap stats are identical\n    if np.all(t_star == t_obs):\n        return t_obs, t_obs\n\n    # Bias-correction parameter z0\n    prop_less = np.mean(t_star  t_obs)\n    # Handle cases where proportion is 0 or 1 to avoid inf from norm.ppf\n    if prop_less == 0.0: prop_less = np.finfo(float).eps\n    if prop_less == 1.0: prop_less = 1.0 - np.finfo(float).eps\n    z0 = norm.ppf(prop_less)\n\n    # Acceleration parameter a (from jackknife)\n    if len(minority_indices) = 1:\n        # Jackknife is ill-defined as per problem statement\n        a = 0.0\n    else:\n        t_jack = np.zeros(n)\n        for i in range(n):\n            y_jack = np.delete(y_true, i)\n            y_pred_jack = np.delete(y_pred, i)\n            t_jack[i] = sensitivity(y_jack, y_pred_jack)\n        \n        t_jack_mean = np.mean(t_jack)\n        devs = t_jack_mean - t_jack\n        \n        numerator = np.sum(devs**3)\n        denominator_base = np.sum(devs**2)\n        \n        if denominator_base == 0:\n            a = 0.0\n        else:\n            denominator = 6 * (denominator_base**1.5)\n            a = numerator / denominator\n\n    # BCa adjusted alpha levels\n    z_alpha_half = norm.ppf(alpha / 2)\n    z_1_minus_alpha_half = norm.ppf(1 - alpha / 2)\n\n    # Numerator for alpha1_adj\n    num1 = z0 + z_alpha_half\n    # Denominator for alpha1_adj\n    den1 = 1 - a * num1\n    if den1 == 0: den1 = np.finfo(float).eps\n    alpha1_adj = norm.cdf(z0 + num1 / den1)\n\n    # Numerator for alpha2_adj\n    num2 = z0 + z_1_minus_alpha_half\n    # Denominator for alpha2_adj\n    den2 = 1 - a * num2\n    if den2 == 0: den2 = np.finfo(float).eps\n    alpha2_adj = norm.cdf(z0 + num2 / den2)\n\n    # Confidence interval from empirical quantiles of bootstrap distribution\n    t_star_sorted = np.sort(t_star)\n\n    ci_lower, ci_upper = np.quantile(t_star_sorted, [alpha1_adj, alpha2_adj])\n\n    return ci_lower, ci_upper\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "4543151"}]}