{"hands_on_practices": [{"introduction": "放射组学研究的第一步是将医学图像中蕴含的生物学信息转化为可计算的定量数据。纹理特征，例如从灰度游程矩阵（GLRLM）中提取的特征，是描述肿瘤异质性的有力工具。本练习 [@problem_id:4557656] 将指导您在一个简化的三维感兴趣区域（ROI）中，从头开始计算短游程强调（SRE）和长游程强调（LRE）这两个经典的纹理特征，从而将“纹理”这一抽象概念具体化为精确的数值。", "problem": "在一个将图像衍生纹理与信使核糖核酸 (mRNA) 表达相关联的放射基因组学工作流程中，从磁共振成像 (MRI) 扫描中提取一个三维 (3D) 感兴趣区域 (ROI)，并将其强度量化为离散的灰度级。考虑以下合成的3D ROI，其中每个体素都属于该ROI。体素坐标由 $(x,y,z)$ 索引，其中 $x \\in \\{1,2,3\\}$, $y \\in \\{1,2\\}$, $z \\in \\{1,2\\}$。强度已被量化为灰度级 $\\{1,2,3\\}$。\n\n切片 $z=1$：\n- 行 $y=1$：$[1\\ 1\\ 2]$ 对于 $x=1,2,3$\n- 行 $y=2$：$[2\\ 2\\ 2]$ 对于 $x=1,2,3$\n\n切片 $z=2$：\n- 行 $y=1$：$[3\\ 1\\ 1]$ 对于 $x=1,2,3$\n- 行 $y=2$：$[1\\ 3\\ 3]$ 对于 $x=1,2,3$\n\n使用灰度游程矩阵 (GLRLM) 的定义，其中一个游程 (run) 是指沿着指定方向具有相同灰度级的连续、共线体素的最大序列，仅在 $+\\hat{x}$ 方向上构建此ROI的GLRLM（即，在每个固定的 $(y,z)$ 线内，沿 $x$ 递增方向追踪游程；没有环绕或跨线延续）。然后，从此GLRLM计算短游程强调 (SRE) 和长游程强调 (LRE) 特征，其中SRE给予较短的游程更高的权重，LRE给予较长的游程更高的权重，两者都通过游程总数进行归一化。\n\n在代入数字之前，以符号形式陈述您推导的任何量，并将您的推导基于游程计数和从GLRLM构建特征的核心定义。将最终的SRE和LRE表示为无单位实数，四舍五入到四位有效数字。按 $\\text{SRE}$、$\\text{LRE}$ 的顺序列出您的最终答案。", "solution": "问题陈述经评估有效。它在放射组学领域具有科学依据，提法明确，提供了所有必要的数据和定义，并且其表述是客观的。我们可以继续进行解答。\n\n问题要求从灰度游程矩阵 (GLRLM) 计算两个纹理特征：短游程强调 (SRE) 和长游程强调 (LRE)。第一步是为给定的三维感兴趣区域 (ROI) 在指定方向上构建GLRLM。\n\nROI由坐标为 $x \\in \\{1,2,3\\}$，$y \\in \\{1,2\\}$ 和 $z \\in \\{1,2\\}$ 的体素强度 $I(x,y,z)$ 定义。灰度级为 $G \\in \\{1,2,3\\}$。数据如下：\n切片 $z=1$：\n$I(x, y=1, z=1) = [1, 1, 2]$\n$I(x, y=2, z=1) = [2, 2, 2]$\n切片 $z=2$：\n$I(x, y=1, z=2) = [3, 1, 1]$\n$I(x, y=2, z=2) = [1, 3, 3]$\n\n一个游程是具有相同灰度级的连续、共线体素的最大序列。我们被要求仅在 $+\\hat{x}$ 方向上寻找游程。这需要分析每一条 $y$ 和 $z$ 固定而 $x$ 变化的体素线。这个ROI中有 $2 \\times 2 = 4$ 条这样的线。\n\n1.  **线 1: $(y=1, z=1)$**\n    强度序列为 $[1, 1, 2]$。我们识别出两个游程：\n    - 一个灰度级为 $g=1$、长度为 $l=2$ 的游程。\n    - 一个灰度级为 $g=2$、长度为 $l=1$ 的游程。\n\n2.  **线 2: $(y=2, z=1)$**\n    强度序列为 $[2, 2, 2]$。我们识别出一个游程：\n    - 一个灰度级为 $g=2$、长度为 $l=3$ 的游程。\n\n3.  **线 3: $(y=1, z=2)$**\n    强度序列为 $[3, 1, 1]$。我们识别出两个游程：\n    - 一个灰度级为 $g=3$、长度为 $l=1$ 的游程。\n    - 一个灰度级为 $g=1$、长度为 $l=2$ 的游程。\n\n4.  **线 4: $(y=2, z=2)$**\n    强度序列为 $[1, 3, 3]$。我们识别出两个游程：\n    - 一个灰度级为 $g=1$、长度为 $l=1$ 的游程。\n    - 一个灰度级为 $g=3$、长度为 $l=2$ 的游程。\n\n接下来，我们构建GLRLM，用矩阵 $P$ 表示。元素 $P(i,j)$ 表示灰度级为 $i$、长度为 $j$ 的游程数量。灰度级数为 $N_g=3$，观察到的最大游程长度为 $N_s=3$。\n\n统计每个灰度级的游程：\n- **灰度级 $i=1$**：\n    - 来自线1的一个长度为 $j=2$ 的游程。\n    - 来自线3的一个长度为 $j=2$ 的游程。\n    - 来自线4的一个长度为 $j=1$ 的游程。\n    - 总计：$P(1,1)=1$, $P(1,2)=2$, $P(1,3)=0$。\n\n- **灰度级 $i=2$**：\n    - 来自线1的一个长度为 $j=1$ 的游程。\n    - 来自线2的一个长度为 $j=3$ 的游程。\n    - 总计：$P(2,1)=1$, $P(2,2)=0$, $P(2,3)=1$。\n\n- **灰度级 $i=3$**：\n    - 来自线3的一个长度为 $j=1$ 的游程。\n    - 来自线4的一个长度为 $j=2$ 的游程。\n    - 总计：$P(3,1)=1$, $P(3,2)=1$, $P(3,3)=0$。\n\n由此得到的GLRLM, $P$, 是一个 $3 \\times 3$ 的矩阵：\n$$\nP = \\begin{pmatrix}\nP(1,1)  P(1,2)  P(1,3) \\\\\nP(2,1)  P(2,2)  P(2,3) \\\\\nP(3,1)  P(3,2)  P(3,3)\n\\end{pmatrix} = \\begin{pmatrix}\n1  2  0 \\\\\n1  0  1 \\\\\n1  1  0\n\\end{pmatrix}\n$$\n\n游程总数 $N_R$ 是 $P$ 中所有元素的和：\n$$\nN_R = \\sum_{i=1}^{N_g} \\sum_{j=1}^{N_s} P(i,j) = (1+2+0) + (1+0+1) + (1+1+0) = 3 + 2 + 2 = 7\n$$\n\n现在我们可以计算SRE和LRE特征。\n\n**短游程强调 (SRE)**：此特征给予较短的游程更高的权重。其定义为：\n$$\n\\text{SRE} = \\frac{1}{N_R} \\sum_{i=1}^{N_g} \\sum_{j=1}^{N_s} \\frac{P(i,j)}{j^2}\n$$\n代入我们的GLRLM $P$ 的值：\n$$\n\\text{SRE} = \\frac{1}{7} \\left( \\frac{P(1,1)}{1^2} + \\frac{P(1,2)}{2^2} + \\frac{P(2,1)}{1^2} + \\frac{P(2,3)}{3^2} + \\frac{P(3,1)}{1^2} + \\frac{P(3,2)}{2^2} \\right)\n$$\n$$\n\\text{SRE} = \\frac{1}{7} \\left( \\frac{1}{1} + \\frac{2}{4} + \\frac{1}{1} + \\frac{1}{9} + \\frac{1}{1} + \\frac{1}{4} \\right)\n$$\n$$\n\\text{SRE} = \\frac{1}{7} \\left( 1 + \\frac{1}{2} + 1 + \\frac{1}{9} + 1 + \\frac{1}{4} \\right) = \\frac{1}{7} \\left( 3 + \\frac{1}{2} + \\frac{1}{4} + \\frac{1}{9} \\right)\n$$\n为了对分数求和，我们找到一个公分母，即 $36$：\n$$\n\\text{SRE} = \\frac{1}{7} \\left( 3 + \\frac{18}{36} + \\frac{9}{36} + \\frac{4}{36} \\right) = \\frac{1}{7} \\left( 3 + \\frac{31}{36} \\right) = \\frac{1}{7} \\left( \\frac{108+31}{36} \\right) = \\frac{1}{7} \\left( \\frac{139}{36} \\right) = \\frac{139}{252}\n$$\n数值上，这等于：\n$$\n\\text{SRE} \\approx 0.5515873...\n$$\n四舍五入到四位有效数字，我们得到 $\\text{SRE} \\approx 0.5516$。\n\n**长游程强调 (LRE)**：此特征给予较长的游程更高的权重。其定义为：\n$$\n\\text{LRE} = \\frac{1}{N_R} \\sum_{i=1}^{N_g} \\sum_{j=1}^{N_s} j^2 P(i,j)\n$$\n代入我们的GLRLM $P$ 的值：\n$$\n\\text{LRE} = \\frac{1}{7} \\left( 1^2 P(1,1) + 2^2 P(1,2) + 1^2 P(2,1) + 3^2 P(2,3) + 1^2 P(3,1) + 2^2 P(3,2) \\right)\n$$\n$$\n\\text{LRE} = \\frac{1}{7} \\left( 1(1) + 4(2) + 1(1) + 9(1) + 1(1) + 4(1) \\right)\n$$\n$$\n\\text{LRE} = \\frac{1}{7} (1 + 8 + 1 + 9 + 1 + 4) = \\frac{1}{7} (24) = \\frac{24}{7}\n$$\n数值上，这等于：\n$$\n\\text{LRE} \\approx 3.4285714...\n$$\n四舍五入到四位有效数字，我们得到 $\\text{LRE} \\approx 3.429$。\n\nSRE和LRE的最终计算值分别约为 $0.5516$ 和 $3.429$。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.5516  3.429\n\\end{pmatrix}\n}\n$$", "id": "4557656"}, {"introduction": "一旦从图像中提取出特征，放射基因组学的核心任务便是在这些影像特征与基因组数据（如基因表达水平）之间建立有意义的关联。典范相关性分析（CCA）是一种强大的多元统计方法，旨在发现两组变量之间的最大线性相关性。通过这个实践 [@problem_id:4557615]，您将从基本原理出发，在一个简化的数据集上实施CCA，从而深入理解该方法如何揭示影像与基因之间的潜在联系。", "problem": "你将处理一个玩具放射基因组学场景，其中两个放射组学影像特征与一个小样本群中的两个基因表达水平相关联。目标是根据典范相关分析 (CCA) 计算典范变量和典范相关。CCA 是一种多变量方法，旨在寻找两组变量中相关性最大的线性组合。请使用以下基本定义作为基础：给定中心化的数据矩阵 $\\mathbf{X} \\in \\mathbb{R}^{n \\times p}$ 和 $\\mathbf{Y} \\in \\mathbb{R}^{n \\times q}$，它们的样本协方差矩阵是 $\\mathbf{S}_{\\mathbf{X}\\mathbf{X}} = \\frac{1}{n-1}\\mathbf{X}^\\top \\mathbf{X}$、$\\mathbf{S}_{\\mathbf{Y}\\mathbf{Y}} = \\frac{1}{n-1}\\mathbf{Y}^\\top \\mathbf{Y}$ 和 $\\mathbf{S}_{\\mathbf{X}\\mathbf{Y}} = \\frac{1}{n-1}\\mathbf{X}^\\top \\mathbf{Y}$。典范相关定义为线性组合 $\\mathbf{X}\\mathbf{a}$ 和 $\\mathbf{Y}\\mathbf{b}$ 之间的最大皮尔逊相关系数，约束条件为 $\\mathrm{Var}(\\mathbf{X}\\mathbf{a}) = 1$ 和 $\\mathrm{Var}(\\mathbf{Y}\\mathbf{b}) = 1$。你的任务是从第一性原理出发计算这些量，不使用任何内置的典范相关函数。\n\n构建以下固定的、确定性的测试套件。所有向量的长度为 $n = 5$，并且所有列都已经均值中心化。从两个列向量 $\\mathbf{u}$ 和 $\\mathbf{v}$ 定义共享的影像特征矩阵 $\\mathbf{X}$ 如下：\n$$\n\\mathbf{u} = \\begin{bmatrix} -2 \\\\ -1 \\\\ 0 \\\\ 1 \\\\ 2 \\end{bmatrix}, \\quad\n\\mathbf{v} = \\begin{bmatrix} 2 \\\\ -1 \\\\ 0 \\\\ 1 \\\\ -2 \\end{bmatrix}, \\quad\n\\mathbf{X} = \\begin{bmatrix} \\mathbf{u}  \\mathbf{v} \\end{bmatrix}.\n$$\n定义与 $\\mathbf{u}$ 和 $\\mathbf{v}$ 均正交（在样本内积意义上）且均值为零的辅助向量：\n$$\n\\mathbf{w}_1 = \\begin{bmatrix} 1 \\\\ 0 \\\\ -2 \\\\ 0 \\\\ 1 \\end{bmatrix}, \\quad\n\\mathbf{w}_2 = \\begin{bmatrix} 0 \\\\ 1 \\\\ -2 \\\\ 1 \\\\ 0 \\end{bmatrix}.\n$$\n现在定义三个基因表达矩阵 $\\mathbf{Y}$ 以探究不同的情况：\n- 测试用例 1（两个维度上完全线性关联）：令\n$$\n\\mathbf{A} = \\begin{bmatrix} 2  1 \\\\ -1  3 \\end{bmatrix}, \\quad \\mathbf{Y}_1 = \\mathbf{X}\\mathbf{A}.\n$$\n- 测试用例 2（两个维度上均无线性关联）：令\n$$\n\\mathbf{Y}_2 = \\begin{bmatrix} \\mathbf{w}_1  \\mathbf{w}_2 \\end{bmatrix}.\n$$\n- 测试用例 3（一个关联维度和一个非关联维度）：令\n$$\n\\mathbf{Y}_3 = \\begin{bmatrix} \\mathbf{u}  \\mathbf{w}_1 \\end{bmatrix}.\n$$\n\n程序要求：\n- 对于每个测试用例，计算由上述 CCA 优化问题所隐含的前两个典范相关。在每种情况下，也计算相应的典范变量（线性组合），以确保你的程序逻辑忠实于基于原理的定义，但你不需要打印典范变量向量。使用样本协方差定义 $\\mathbf{S}_{\\mathbf{X}\\mathbf{X}}$、$\\mathbf{S}_{\\mathbf{Y}\\mathbf{Y}}$、$\\mathbf{S}_{\\mathbf{X}\\mathbf{Y}}$，其中因子为 $\\frac{1}{n-1}$ 且 $n = 5$。\n- 通过对 $\\mathbf{S}_{\\mathbf{X}\\mathbf{X}}$、$\\mathbf{S}_{\\mathbf{Y}\\mathbf{Y}}$ 和 $\\mathbf{S}_{\\mathbf{X}\\mathbf{Y}}$ 进行适定线性代数运算来处理计算。不要使用任何黑箱典范相关例程。\n- 数值输出规范：对于每个测试用例 $k \\in \\{1,2,3\\}$，令 $c_{k,1}$ 和 $c_{k,2}$ 分别表示第一个和第二个典范相关。将每个 $c_{k,j}$ 四舍五入到 6 位小数。你的程序应产生单行输出，包含所有结果，格式为方括号内的逗号分隔列表，顺序为 $[c_{1,1}, c_{1,2}, c_{2,1}, c_{2,2}, c_{3,1}, c_{3,2}]$。\n- 不涉及角度，也没有物理单位。所有数值输出必须是精确到小数点后 6 位的小数。\n\n测试套件覆盖范围的基本原理：\n- 测试用例 1 探究 $\\mathbf{Y}$ 是 $\\mathbf{X}$ 的满秩线性变换的情况，这应该产生最强的可能关联。\n- 测试用例 2 探究影像和基因组子空间关于样本内积是正交的情况，测试无线性关联的边界情况。\n- 测试用例 3 探究一种混合情况，其中影像和基因组空间之间只共享一个维度。\n\n最终输出格式：\n- 你的程序应产生单行输出，包含结果，格式为方括号内的逗号分隔列表（例如，$[c_{1,1},c_{1,2},c_{2,1},c_{2,2},c_{3,1},c_{3,2}]$），每个条目精确到小数点后 6 位。", "solution": "用户提供的问题陈述已经过验证。\n\n### 第 1 步：提取已知条件\n- **数据矩阵**：$\\mathbf{X} \\in \\mathbb{R}^{n \\times p}$ 和 $\\mathbf{Y} \\in \\mathbb{R}^{n \\times q}$ 是中心化的数据矩阵。\n- **样本大小**：$n = 5$。\n- **影像特征向量**：\n$$\n\\mathbf{u} = \\begin{bmatrix} -2 \\\\ -1 \\\\ 0 \\\\ 1 \\\\ 2 \\end{bmatrix}, \\quad\n\\mathbf{v} = \\begin{bmatrix} 2 \\\\ -1 \\\\ 0 \\\\ 1 \\\\ -2 \\end{bmatrix}\n$$\n- **影像特征矩阵**：$\\mathbf{X} = \\begin{bmatrix} \\mathbf{u}  \\mathbf{v} \\end{bmatrix}$。\n- **辅助向量**：\n$$\n\\mathbf{w}_1 = \\begin{bmatrix} 1 \\\\ 0 \\\\ -2 \\\\ 0 \\\\ 1 \\end{bmatrix}, \\quad\n\\mathbf{w}_2 = \\begin{bmatrix} 0 \\\\ 1 \\\\ -2 \\\\ 1 \\\\ 0 \\end{bmatrix}\n$$\n- **基因表达矩阵（测试用例）**：\n  1. $\\mathbf{A} = \\begin{bmatrix} 2  1 \\\\ -1  3 \\end{bmatrix}, \\quad \\mathbf{Y}_1 = \\mathbf{X}\\mathbf{A}$。\n  2. $\\mathbf{Y}_2 = \\begin{bmatrix} \\mathbf{w}_1  \\mathbf{w}_2 \\end{bmatrix}$。\n  3. $\\mathbf{Y}_3 = \\begin{bmatrix} \\mathbf{u}  \\mathbf{w}_1 \\end{bmatrix}$。\n- **协方差定义**：$\\mathbf{S}_{\\mathbf{X}\\mathbf{X}} = \\frac{1}{n-1}\\mathbf{X}^\\top \\mathbf{X}$、$\\mathbf{S}_{\\mathbf{Y}\\mathbf{Y}} = \\frac{1}{n-1}\\mathbf{Y}^\\top \\mathbf{Y}$ 和 $\\mathbf{S}_{\\mathbf{X}\\mathbf{Y}} = \\frac{1}{n-1}\\mathbf{X}^\\top \\mathbf{Y}$。\n- **CCA 目标**：在约束条件 $\\mathrm{Var}(\\mathbf{X}\\mathbf{a}) = 1$ 和 $\\mathrm{Var}(\\mathbf{Y}\\mathbf{b}) = 1$ 下，最大化 $\\mathrm{Corr}(\\mathbf{X}\\mathbf{a}, \\mathbf{Y}\\mathbf{b})$。\n- **输出要求**：对于每个用例，计算两个典范相关，四舍五入到 6 位小数，并以单个逗号分隔列表形式呈现：$[c_{1,1}, c_{1,2}, c_{2,1}, c_{2,2}, c_{3,1}, c_{3,2}]$。\n\n### 第 2 步：使用提取的已知条件进行验证\n1.  **科学依据**：该问题是典范相关分析 (CCA) 的标准应用，CCA 是多变量统计中的一种基本方法。指定的背景，即放射基因组学，是一个使用此类方法的有效科学领域。数学公式是正确的。\n2.  **适定性**：该问题提供了所有必要的数据和定义。给定的向量已确认为均值中心化的。构造的矩阵是良态的（例如，$\\mathbf{S}_{\\mathbf{X}\\mathbf{X}}$ 是可逆的），确保存在唯一解。测试用例系统地探究了线性关联的不同情况，这表明这是一个设计良好的问题。\n3.  **客观性**：该问题以精确、客观的数学语言陈述，没有歧义或主观性陈述。\n\n### 第 3 步：结论与行动\n问题是**有效的**。将推导并实现一个基于第一性原理的解决方案。\n\n### 基于原理的解决方案\n典范相关分析 (CCA) 的目标是找到权重向量 $\\mathbf{a}$ 和 $\\mathbf{b}$，以最大化典范变量 $\\mathbf{U} = \\mathbf{X}\\mathbf{a}$ 和 $\\mathbf{V} = \\mathbf{Y}\\mathbf{b}$ 之间的相关性 $\\rho$。相关性定义为：\n$$\n\\rho = \\frac{\\mathrm{Cov}(\\mathbf{X}\\mathbf{a}, \\mathbf{Y}\\mathbf{b})}{\\sqrt{\\mathrm{Var}(\\mathbf{X}\\mathbf{a}) \\mathrm{Var}(\\mathbf{Y}\\mathbf{b})}}\n$$\n鉴于数据是中心化的，并使用提供的协方差定义，我们有：\n-   $\\mathrm{Var}(\\mathbf{X}\\mathbf{a}) = \\mathbf{a}^\\top \\mathbf{S}_{\\mathbf{X}\\mathbf{X}} \\mathbf{a}$\n-   $\\mathrm{Var}(\\mathbf{Y}\\mathbf{b}) = \\mathbf{b}^\\top \\mathbf{S}_{\\mathbf{Y}\\mathbf{Y}} \\mathbf{b}$\n-   $\\mathrm{Cov}(\\mathbf{X}\\mathbf{a}, \\mathbf{Y}\\mathbf{b}) = \\mathbf{a}^\\top \\mathbf{S}_{\\mathbf{X}\\mathbf{Y}} \\mathbf{b}$\n\n优化问题是在归一化约束 $\\mathbf{a}^\\top \\mathbf{S}_{\\mathbf{X}\\mathbf{X}} \\mathbf{a} = 1$ 和 $\\mathbf{b}^\\top \\mathbf{S}_{\\mathbf{Y}\\mathbf{Y}} \\mathbf{b} = 1$ 条件下，最大化 $\\rho = \\mathbf{a}^\\top \\mathbf{S}_{\\mathbf{X}\\mathbf{Y}} \\mathbf{b}$。这个问题可以使用拉格朗日乘子法解决，它将其转换为一个广义特征值问题。该解导致两个等价的久期方程。我们将使用求解权重向量 $\\mathbf{b}$ 的形式：\n$$\n(\\mathbf{S}_{\\mathbf{Y}\\mathbf{Y}}^{-1} \\mathbf{S}_{\\mathbf{Y}\\mathbf{X}} \\mathbf{S}_{\\mathbf{X}\\mathbf{X}}^{-1} \\mathbf{S}_{\\mathbf{X}\\mathbf{Y}}) \\mathbf{b} = \\rho^2 \\mathbf{b}\n$$\n其中 $\\mathbf{S}_{\\mathbf{Y}\\mathbf{X}} = \\mathbf{S}_{\\mathbf{X}\\mathbf{Y}}^\\top$。这是一个标准特征值问题。特征值 $\\lambda_i = \\rho_i^2$ 是典范相关的平方。典范相关 $\\rho_i$ 是这些特征值的正平方根。相应的特征向量 $\\mathbf{b}_i$ 是 Y 变量的典范权重向量。非零典范相关的数量最多为 $\\min(\\dim(\\mathbf{X}), \\dim(\\mathbf{Y}))$。在这里，$\\mathbf{X}$ 和 $\\mathbf{Y}$ 分别有 $p=2$ 和 $q=2$ 列，所以我们将在每种情况下找到两个典范相关。\n\n计算过程如下：\n1.  为每个测试用例 $k \\in \\{1, 2, 3\\}$ 构建数据矩阵 $\\mathbf{X}$ 和 $\\mathbf{Y}_k$。\n2.  使用因子 $\\frac{1}{n-1} = \\frac{1}{4}$ 计算样本协方差矩阵 $\\mathbf{S}_{\\mathbf{X}\\mathbf{X}}$、$\\mathbf{S}_{\\mathbf{Y}_k\\mathbf{Y}_k}$ 和 $\\mathbf{S}_{\\mathbf{X}\\mathbf{Y}_k}$。\n3.  计算矩阵 $\\mathbf{K}_k = \\mathbf{S}_{\\mathbf{Y}_k\\mathbf{Y}_k}^{-1} \\mathbf{S}_{\\mathbf{X}\\mathbf{Y}_k}^\\top \\mathbf{S}_{\\mathbf{X}\\mathbf{X}}^{-1} \\mathbf{S}_{\\mathbf{X}\\mathbf{Y}_k}$。\n4.  计算 $\\mathbf{K}_k$ 的特征值。\n5.  典范相关是这些特征值的平方根，按降序排序。\n\n首先，我们计算公共矩阵 $\\mathbf{S}_{\\mathbf{X}\\mathbf{X}}$ 及其逆矩阵。\n$$\n\\mathbf{X}^\\top\\mathbf{X} = \\begin{bmatrix} \\mathbf{u}^\\top\\mathbf{u}  \\mathbf{u}^\\top\\mathbf{v} \\\\ \\mathbf{v}^\\top\\mathbf{u}  \\mathbf{v}^\\top\\mathbf{v} \\end{bmatrix} = \\begin{bmatrix} 10  -6 \\\\ -6  10 \\end{bmatrix}\n$$\n$$\n\\mathbf{S}_{\\mathbf{X}\\mathbf{X}} = \\frac{1}{4} \\begin{bmatrix} 10  -6 \\\\ -6  10 \\end{bmatrix} = \\begin{bmatrix} 2.5  -1.5 \\\\ -1.5  2.5 \\end{bmatrix}\n$$\n$$\n\\mathbf{S}_{\\mathbf{X}\\mathbf{X}}^{-1} = \\frac{1}{2.5^2 - (-1.5)^2} \\begin{bmatrix} 2.5  1.5 \\\\ 1.5  2.5 \\end{bmatrix} = \\frac{1}{4} \\begin{bmatrix} 2.5  1.5 \\\\ 1.5  2.5 \\end{bmatrix} = \\begin{bmatrix} 0.625  0.375 \\\\ 0.375  0.625 \\end{bmatrix}\n$$\n\n**测试用例 1：$\\mathbf{Y}_1 = \\mathbf{X}\\mathbf{A}$**\n在这里，$\\mathbf{Y}_1$ 是 $\\mathbf{X}$ 的满秩线性变换。这种关系应该是完全可发现的。\n$\\mathbf{S}_{\\mathbf{X}\\mathbf{Y}_1} = \\frac{1}{n-1}\\mathbf{X}^\\top(\\mathbf{X}\\mathbf{A}) = \\mathbf{S}_{\\mathbf{X}\\mathbf{X}}\\mathbf{A}$。\n$\\mathbf{S}_{\\mathbf{Y}_1\\mathbf{Y}_1} = \\frac{1}{n-1}(\\mathbf{X}\\mathbf{A})^\\top(\\mathbf{X}\\mathbf{A}) = \\mathbf{A}^\\top \\mathbf{S}_{\\mathbf{X}\\mathbf{X}} \\mathbf{A}$。\n矩阵 $\\mathbf{K}_1$ 变为：\n$$\n\\mathbf{K}_1 = (\\mathbf{A}^\\top \\mathbf{S}_{\\mathbf{X}\\mathbf{X}} \\mathbf{A})^{-1} (\\mathbf{S}_{\\mathbf{X}\\mathbf{X}}\\mathbf{A})^\\top \\mathbf{S}_{\\mathbf{X}\\mathbf{X}}^{-1} (\\mathbf{S}_{\\mathbf{X}\\mathbf{X}}\\mathbf{A}) = \\mathbf{A}^{-1}\\mathbf{S}_{\\mathbf{X}\\mathbf{X}}^{-1}(\\mathbf{A}^\\top)^{-1} \\mathbf{A}^\\top\\mathbf{S}_{\\mathbf{X}\\mathbf{X}} \\mathbf{S}_{\\mathbf{X}\\mathbf{X}}^{-1} \\mathbf{S}_{\\mathbf{X}\\mathbf{X}}\\mathbf{A} = \\mathbf{I}\n$$\n$2 \\times 2$ 单位矩阵 $\\mathbf{I}$ 的特征值为 1 和 1。因此，典范相关的平方为 $\\rho_1^2 = 1.0$ 和 $\\rho_2^2 = 1.0$。典范相关为 $c_{1,1} = 1.0$ 和 $c_{1,2} = 1.0$。\n\n**测试用例 2：$\\mathbf{Y}_2 = [\\mathbf{w}_1, \\mathbf{w}_2]$**\n向量 $\\mathbf{w}_1$ 和 $\\mathbf{w}_2$ 被构造为与 $\\mathbf{X}$ 的列空间正交。\n$\\mathbf{u}^\\top\\mathbf{w}_1 = 0$、$\\mathbf{v}^\\top\\mathbf{w}_1 = 0$、$\\mathbf{u}^\\top\\mathbf{w}_2 = 0$、$\\mathbf{v}^\\top\\mathbf{w}_2 = 0$。\n这意味着 $\\mathbf{X}^\\top\\mathbf{w}_1 = \\mathbf{0}$ 和 $\\mathbf{X}^\\top\\mathbf{w}_2 = \\mathbf{0}$。\n因此，互协方差矩阵为空：\n$$\n\\mathbf{S}_{\\mathbf{X}\\mathbf{Y}_2} = \\frac{1}{n-1}\\mathbf{X}^\\top\\mathbf{Y}_2 = \\frac{1}{4} [\\mathbf{X}^\\top\\mathbf{w}_1, \\mathbf{X}^\\top\\mathbfw_2] = \\begin{bmatrix} 0  0 \\\\ 0  0 \\end{bmatrix}\n$$\n因此，矩阵 $\\mathbf{K}_2$ 也是零矩阵：\n$$\n\\mathbf{K}_2 = \\mathbf{S}_{\\mathbf{Y}_2\\mathbf{Y}_2}^{-1} \\mathbf{0}^\\top \\mathbf{S}_{\\mathbf{X}\\mathbf{X}}^{-1} \\mathbf{0} = \\mathbf{0}\n$$\n零矩阵的特征值为 0 和 0。典范相关为 $c_{2,1} = 0.0$ 和 $c_{2,2} = 0.0$。\n\n**测试用例 3：$\\mathbf{Y}_3 = [\\mathbf{u}, \\mathbf{w}_1]$**\n这是一个混合情况。$\\mathbf{Y}_3$ 的一个维度在 $\\mathbf{X}$ 的空间中，另一个维度是正交的。\n$$\n\\mathbf{S}_{\\mathbf{X}\\mathbf{Y}_3} = \\frac{1}{4} \\mathbf{X}^\\top [\\mathbf{u}, \\mathbf{w}_1] = \\frac{1}{4} \\begin{bmatrix} \\mathbf{u}^\\top\\mathbf{u}  \\mathbf{u}^\\top\\mathbf{w}_1 \\\\ \\mathbf{v}^\\top\\mathbf{u}  \\mathbf{v}^\\top\\mathbf{w}_1 \\end{bmatrix} = \\frac{1}{4} \\begin{bmatrix} 10  0 \\\\ -6  0 \\end{bmatrix} = \\begin{bmatrix} 2.5  0 \\\\ -1.5  0 \\end{bmatrix}\n$$\n$$\n\\mathbf{S}_{\\mathbf{Y}_3\\mathbf{Y}_3} = \\frac{1}{4} \\begin{bmatrix} \\mathbf{u}^\\top\\mathbf{u}  \\mathbf{u}^\\top\\mathbf{w}_1 \\\\ \\mathbf{w}_1^\\top\\mathbf{u}  \\mathbf{w}_1^\\top\\mathbf{w}_1 \\end{bmatrix} = \\frac{1}{4} \\begin{bmatrix} 10  0 \\\\ 0  6 \\end{bmatrix} = \\begin{bmatrix} 2.5  0 \\\\ 0  1.5 \\end{bmatrix}\n$$\n$$\n\\mathbf{S}_{\\mathbf{Y}_3\\mathbf{Y}_3}^{-1} = \\begin{bmatrix} 1/2.5  0 \\\\ 0  1/1.5 \\end{bmatrix} = \\begin{bmatrix} 0.4  0 \\\\ 0  2/3 \\end{bmatrix}\n$$\n我们计算中间产物 $\\mathbf{M} = \\mathbf{S}_{\\mathbf{X}\\mathbf{X}}^{-1} \\mathbf{S}_{\\mathbf{X}\\mathbf{Y}_3}$：\n$$\n\\mathbf{M} = \\begin{bmatrix} 0.625  0.375 \\\\ 0.375  0.625 \\end{bmatrix} \\begin{bmatrix} 2.5  0 \\\\ -1.5  0 \\end{bmatrix} = \\begin{bmatrix} 1  0 \\\\ 0  0 \\end{bmatrix}\n$$\n现在我们计算 $\\mathbf{K}_3 = \\mathbf{S}_{\\mathbf{Y}_3\\mathbf{Y}_3}^{-1} \\mathbf{S}_{\\mathbf{X}\\mathbf{Y}_3}^\\top \\mathbf{M}$：\n$$\n\\mathbf{S}_{\\mathbf{X}\\mathbf{Y}_3}^\\top \\mathbf{M} = \\begin{bmatrix} 2.5  -1.5 \\\\ 0  0 \\end{bmatrix} \\begin{bmatrix} 1  0 \\\\ 0  0 \\end{bmatrix} = \\begin{bmatrix} 2.5  0 \\\\ 0  0 \\end{bmatrix}\n$$\n$$\n\\mathbf{K}_3 = \\begin{bmatrix} 0.4  0 \\\\ 0  2/3 \\end{bmatrix} \\begin{bmatrix} 2.5  0 \\\\ 0  0 \\end{bmatrix} = \\begin{bmatrix} 1  0 \\\\ 0  0 \\end{bmatrix}\n$$\n$\\mathbf{K}_3$ 的特征值为 1 和 0。典范相关为 $c_{3,1} = \\sqrt{1} = 1.0$ 和 $c_{3,2} = \\sqrt{0} = 0.0$。\n\n**结果摘要**：\n-   用例 1 相关：$1.0, 1.0$\n-   用例 2 相关：$0.0, 0.0$\n-   用例 3 相关：$1.0, 0.0$\n结果将按照问题陈述中的要求排序。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes canonical correlations for a toy radiogenomics scenario.\n\n    The function implements Canonical Correlation Analysis (CCA) from first principles\n    to find the linear relationships between two sets of variables, X (imaging features)\n    and Y (gene expression levels), across three distinct test cases.\n    \"\"\"\n\n    # Define shared data matrices and constants as specified in the problem.\n    n = 5.0\n    u = np.array([-2, -1, 0, 1, 2], dtype=float).reshape(-1, 1)\n    v = np.array([2, -1, 0, 1, -2], dtype=float).reshape(-1, 1)\n    X = np.hstack([u, v])\n\n    w1 = np.array([1, 0, -2, 0, 1], dtype=float).reshape(-1, 1)\n    w2 = np.array([0, 1, -2, 1, 0], dtype=float).reshape(-1, 1)\n\n    # Test Case 1: Perfect linear linkage\n    # Y1 is a full-rank linear transformation of X.\n    A = np.array([[2, 1], [-1, 3]], dtype=float)\n    Y1 = X @ A\n\n    # Test Case 2: No linear linkage\n    # The column space of Y2 is orthogonal to the column space of X.\n    Y2 = np.hstack([w1, w2])\n\n    # Test Case 3: One linked and one unlinked dimension\n    # One column of Y3 is a column of X, the other is orthogonal to X's space.\n    Y3 = np.hstack([u, w1])\n\n    # Store test cases in a list for iterative processing.\n    test_cases = [\n        {'X': X, 'Y': Y1},\n        {'X': X, 'Y': Y2},\n        {'X': X, 'Y': Y3},\n    ]\n\n    all_correlations = []\n\n    for case in test_cases:\n        X_case = case['X']\n        Y_case = case['Y']\n        \n        # Step 1: Compute sample covariance matrices (with n-1 denominator).\n        # Data is already centered as per problem statement.\n        S_XX = (X_case.T @ X_case) / (n - 1)\n        S_YY = (Y_case.T @ Y_case) / (n - 1)\n        S_XY = (X_case.T @ Y_case) / (n - 1)\n        \n        # Step 2: Compute matrix inverses required for the eigenvalue problem.\n        # The problem is constructed such that these matrices are invertible.\n        try:\n            S_XX_inv = np.linalg.inv(S_XX)\n            S_YY_inv = np.linalg.inv(S_YY)\n        except np.linalg.LinAlgError:\n            # This path should not be taken in this problem, but is good practice.\n            # Handle singular covariance matrices if they occur, e.g., by using pinv\n            # or by recognizing that correlations may be undefined or trivial.\n            # For this problem, if S_XX or S_YY is singular, there are no non-trivial\n            # correlations to find. Assume correlations are 0.\n            all_correlations.extend([0.0, 0.0])\n            continue\n            \n        # Step 3: Form the matrix K for the eigenvalue problem.\n        # K = inv(S_YY) * S_YX * inv(S_XX) * S_XY, where S_YX = S_XY.T\n        S_YX = S_XY.T\n        K = S_YY_inv @ S_YX @ S_XX_inv @ S_XY\n        \n        # Step 4: Compute the eigenvalues of K.\n        # These are the squared canonical correlations.\n        eigenvalues = np.linalg.eigvals(K)\n        \n        # Step 5: Calculate the canonical correlations.\n        # Take the square root of the eigenvalues.\n        # Use np.maximum with 0 to handle potential small negative values from\n        # floating-point inaccuracies for eigenvalues that should be zero.\n        squared_correlations = np.maximum(eigenvalues.real, 0)\n        correlations = np.sqrt(squared_correlations)\n        \n        # Step 6: Sort correlations in descending order to get the leading ones.\n        correlations.sort()\n        sorted_correlations = correlations[::-1]\n        \n        all_correlations.extend(sorted_correlations)\n        \n    # Format the results to 6 decimal places and print in the specified format.\n    formatted_results = [f\"{c:.6f}\" for c in all_correlations]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "4557615"}, {"introduction": "在放射基因组学研究中，研究人员通常需要进行成千上万次假设检验（例如，检验每个影像特征与每个基因之间的关联），这极大地增加了出现假阳性的风险。为了从海量检验结果中筛选出真正具有统计学意义的发现，控制假发现率（FDR）至关重要。本练习 [@problem_id:4557666] 要求您实现经典的Benjamini-Hochberg（BH）程序，这是一个在任何高通量组学研究中都不可或缺的基本技能，它能帮助我们以严谨的方式将真实信号与随机噪声区分开来。", "problem": "放射基因组学通过执行大量的统计假设检验（每个特征-基因对进行一次检验），将定量影像特征与基因组变量关联起来。在经典的频率派假设检验中，$p$值是在原假设成立的情况下，观测到至少与实际观测值一样极端的检验统计量的概率。在原假设和适当的正则性条件下，$p$值在$[0,1]$上呈均匀分布。当进行多重检验时，控制在所有声称的阳性结果中假阳性的预期比例至关重要。错误发现率 (FDR) 定义为假阳性数量与总阳性数量之比的期望值，并约定当没有阳性结果时该比率为$0$。Benjamini–Hochberg (BH) 程序在各检验独立或存在某些正相关形式的条件下，将FDR控制在目标水平 $ \\alpha $。\n\n您的任务是根据第一性原理，实现BH程序，从一个给定的$p$值列表计算出校正后的$q$值。对于一个检验而言，其校正后的$q$值是指通过BH程序判定该检验为显著时所需的最低FDR水平。您必须：\n- 接受一个包含$m$个$p$值的列表（其中$m$是检验总数），计算与原始检验顺序对齐的、经BH校正的$q$值。\n- 通过将计算出的$q$值与目标FDR水平 $ \\alpha $进行比较，识别出显著的发现集合。请使用未四舍五入的$q$值进行此决策。\n- 将每个报告的$q$值四舍五入到$6$位小数进行输出。此问题不涉及物理单位。\n- 为每个测试用例返回一个包含两部分的配对：第一部分是四舍五入后的$q$值列表（与原始$p$值顺序对齐），第二部分是未四舍五入的$q$值小于或等于 $ \\alpha $的发现的索引列表（使用基于$0$的索引）。索引必须按升序排序。\n\n设计您的实现时，请从上述基本定义出发，并对BH算法所需的排序和单调性进行推理。避免使用任何未从基本原理推导出的快捷公式。通过将所有$p$值视为$[0,1]$区间的元素，并在算法设计中反映独立性假设，来确保科学真实性。\n\n测试套件：\n对于每个测试用例，输入是$p$值列表和目标FDR水平 $ \\alpha $。您的程序必须处理以下五个测试用例：\n\n- 用例 1：$m = 10$，$p$值 $[0.001, 0.04, 0.2, 0.5, 0.03, 0.8, 0.07, 0.002, 0.9, 0.15]$，目标 $\\alpha = 0.1$。\n- 用例 2：$m = 8$，$p$值 $[0.05, 0.05, 0.05, 0.05, 0.2, 0.2, 0.9, 0.9]$，目标 $\\alpha = 0.05$。\n- 用例 3：$m = 6$，$p$值 $[0.0, 0.0, 0.01, 0.05, 0.5, 1.0]$，目标 $\\alpha = 0.0$。\n- 用例 4：$m = 5$，$p$值 $[0.6, 0.7, 0.8, 0.9, 1.0]$，目标 $\\alpha = 0.5$。\n- 用例 5：$m = 12$，$p$值 $[0.12, 0.034, 0.0005, 0.48, 0.051, 0.33, 0.42, 0.0021, 0.77, 0.090, 0.16, 0.25]$，目标 $\\alpha = 0.05$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表，列表中的每个元素对应一个测试用例，并且本身是一个包含两个元素的列表：第一个元素是四舍五入后的$q$值列表，第二个元素是发现的索引列表。例如，格式必须是\n[[[q_1, q_2, \\dots, q_m], [i_1, i_2, \\dots]], \\dots]，\n其中的数值和索引如上所述。", "solution": "用户提供的问题已经过验证，被认定是合理的。它在科学上基于已建立的统计理论，问题陈述清晰，目标明确，数据充分，并且没有矛盾或含糊之处。任务是从第一性原理出发，实现用于控制错误发现率（FDR）的Benjamini-Hochberg（BH）程序。\n\n### 基于原理的推导与算法设计\n\n核心任务是为$m$个假设检验的列表计算校正后的$p$值（称为$q$值），然后确定在给定的FDR控制水平$\\alpha$下哪些检验是显著的。\n\n#### 1. 基本定义\n\n设有$m$个原假设，$H_1, H_2, \\dots, H_m$，及其对应的$p$值，$P = [p_1, p_2, \\dots, p_m]$。\n\n用于在水平$\\alpha \\in [0, 1]$上控制FDR的Benjamini-Hochberg (BH) 程序如下：\n1.  将$p$值按非递减顺序排序：$p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(m)}$。设$H_{(i)}$是与$p$值$p_{(i)}$对应的原假设。\n2.  找到最大的整数秩$k$（其中$k \\in \\{1, 2, \\dots, m\\}$），使得对应的已排序$p$值，$p_{(k)}$，满足条件：\n    $$p_{(k)} \\le \\frac{k}{m}\\alpha$$\n3.  如果存在这样的$k$，则拒绝所有$i = 1, 2, \\dots, k$的原假设$H_{(i)}$。如果不存在这样的$k$，则不拒绝任何假设。\n\n#### 2. 校正后$q$值的推导\n\n问题将特定检验的校正后$q$值定义为该检验被判定为显著时所需的最低FDR水平$\\alpha$。让我们来推导与第$i$个排序后的$p$值$p_{(i)}$相对应的$q$值的公式。\n\n为了使与$p_{(i)}$对应的检验被判定为显著，其假设$H_{(i)}$必须被拒绝。根据BH程序，当存在某个秩$k \\ge i$满足条件$p_{(k)} \\le \\frac{k}{m}\\alpha$时，这一情况就会发生。这个不等式可以重新整理以求解$\\alpha$：\n$$\\alpha \\ge \\frac{m \\cdot p_{(k)}}{k}$$\n对于一个固定的检验$H_{(i)}$，我们寻找能导致其被拒绝的*最小*$\\alpha$。这需要找到一个$\\alpha$，它至少对一个$k \\ge i$满足该不等式。因此，这样的最小$\\alpha$是所有从$i$到$m$的秩对应的所有可能右侧值的最小值。\n\n因此，第$i$个排序后检验的校正后$q$值，记为$q_{(i)}$，是：\n$$q_{(i)} = \\min_{k=i, \\dots, m} \\left( \\frac{m \\cdot p_{(k)}}{k} \\right)$$\n作为此定义的直接结果，排序后的$q$值序列必须是非递减的，即$q_{(1)} \\le q_{(2)} \\le \\dots \\le q_{(m)}$。这是因为计算$q_{(i)}$时取最小值的项集合是计算$q_{(i+1)}$时项集合的超集，因此其最小值必须小于或等于$q_{(i+1)}$的最小值。这个性质可以表示为一个递推关系：\n$$q_{(i)} = \\min\\left( \\frac{m \\cdot p_{(i)}}{i}, q_{(i+1)} \\right)$$\n\n#### 3. 算法实现\n\n该递推关系提供了一种高效的计算方法。我们可以从最大的$p$值开始，向后计算$q$值。\n\n完整的算法如下：\n1.  **准备**：给定包含$m$个$p$值的输入列表，我们必须保留它们的原始索引以便重构最终输出。我们为所有$m$个检验创建一个元组列表 `(p_value, original_index)`。\n2.  **排序**：根据$p$值按升序对此元组列表进行排序。这将得到排序后的$p$值$p_{(1)}, p_{(2)}, \\dots, p_{(m)}$及其对应的原始索引。$p_{(i)}$的秩为$i$（在公式中使用基于1的索引）。\n3.  **$q$值的反向计算**：我们按秩的逆序计算排序后的$q$值，$q_{(1)}, \\dots, q_{(m)}$，以高效地强制执行单调性属性。\n    -   最大$p$值$p_{(m)}$的$q$值就是$p_{(m)}$本身，这对应于定义中$k=m$的情况：\n        $$q_{(m)} = \\frac{m \\cdot p_{(m)}}{m} = p_{(m)}$$\n    -   对于从$m-1$到$1$的$i$，我们应用递推公式：\n        $$q_{(i)} = \\min\\left( \\frac{m \\cdot p_{(i)}}{i}, q_{(i+1)} \\right)$$\n    -   此外，由于$q$值代表FDR水平，它们不应超过$1$。虽然源$p$值在$[0, 1]$区间内，但项$\\frac{m \\cdot p_{(i)}}{i}$可能大于$1$。标准的BH校正会将得到的q值上限设为$1$。如果$p_{(m)} \\le 1$并且后续的$\\frac{m \\cdot p_{(i)}}{i}$值在`min`操作前也被限制在$1$以内，或者如果最终列表被限制，我们的递推关系可以自然地处理这一点。后者更简单：$q_{(i)} \\leftarrow \\min(1.0, q_{(i)})$。所提供的递推关系能自动正确地传播小于或等于$1$的值。例如，如果$q_{(i+1)} \\le 1$且$\\frac{m \\cdot p_{(i)}}{i} > 1$，则最小值为$q_{(i+1)}$，从而保持该性质。\n4.  **恢复顺序**：创建一个新列表来存放最终的$q$值。使用排序步骤中存储的原始索引，我们将每个计算出的$q_{(i)}$放回其原始位置。\n5.  **识别发现**：得到原始顺序的最终（未四舍五入的）$q$值后，我们遍历它们。对于每个检验$j$，如果其$q$值$q_j$满足$q_j \\le \\alpha$，则将其原始索引$j$添加到一个发现列表中。该列表必须按要求升序排序。\n6.  **最终格式化**：将计算出的$q$值四舍五入到$6$位小数。每个测试用例的最终结果是一个包含两部分的配对：四舍五入后的$q$值列表和排序后的发现索引列表。\n\n这个从第一性原理推导出的分步过程，确保了对Benjamini-Hochberg校正$q$值计算的正确和稳健的实现。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Benjamini-Hochberg q-value problem for the given test suite.\n    \"\"\"\n\n    test_cases = [\n        {'p_values': [0.001, 0.04, 0.2, 0.5, 0.03, 0.8, 0.07, 0.002, 0.9, 0.15], 'alpha': 0.1},\n        {'p_values': [0.05, 0.05, 0.05, 0.05, 0.2, 0.2, 0.9, 0.9], 'alpha': 0.05},\n        {'p_values': [0.0, 0.0, 0.01, 0.05, 0.5, 1.0], 'alpha': 0.0},\n        {'p_values': [0.6, 0.7, 0.8, 0.9, 1.0], 'alpha': 0.5},\n        {'p_values': [0.12, 0.034, 0.0005, 0.48, 0.051, 0.33, 0.42, 0.0021, 0.77, 0.090, 0.16, 0.25], 'alpha': 0.05},\n    ]\n\n    all_results = []\n    for case in test_cases:\n        p_values = np.array(case['p_values'])\n        alpha = case['alpha']\n        m = len(p_values)\n\n        # Step 1  2: Get the sorting order of p-values\n        # argsort provides the indices that would sort the array.\n        # This preserves the original index information implicitly.\n        sorted_indices = np.argsort(p_values)\n        \n        # Create a sorted version of p-values\n        p_values_sorted = p_values[sorted_indices]\n\n        # Step 3: Backward calculation of q-values\n        # Create an array to hold the sorted q-values.\n        q_values_sorted = np.zeros(m)\n        \n        # The q-value for the largest p-value is the p-value itself.\n        if m > 0:\n            q_values_sorted[m - 1] = p_values_sorted[m - 1]\n\n        # Iterate backwards from the second to last p-value.\n        # i is the 0-based index in the sorted array.\n        for i in range(m - 2, -1, -1):\n            # Rank is (i + 1) for 1-based indexing.\n            rank = i + 1\n            \n            # Calculate the BH comparison value for the current p-value.\n            bh_p_val = (m / rank) * p_values_sorted[i]\n            \n            # The q-value is the minimum of its BH value and the next q-value in the sorted list.\n            # This enforces the non-decreasing (monotonicity) property of q-values.\n            q_values_sorted[i] = min(bh_p_val, q_values_sorted[i + 1])\n        \n        # Ensure q-values are capped at 1.0.\n        q_values_sorted = np.minimum(q_values_sorted, 1.0)\n        \n        # Step 4: Unsort the q-values to match the original p-value order.\n        # Create an empty array for the final q-values.\n        q_values_unrounded = np.zeros(m)\n        if m > 0:\n            # Place the sorted q-values back into their original positions.\n            # This is a powerful numpy feature for reordering.\n            q_values_unrounded[sorted_indices] = q_values_sorted\n\n        # Step 5: Identify discoveries\n        # Compare the unrounded q-values to the alpha level.\n        discoveries = [i for i, q in enumerate(q_values_unrounded) if q = alpha]\n        # Sort indices as required by the problem statement.\n        discoveries.sort()\n\n        # Step 6: Round q-values for the final report\n        q_values_rounded = [round(q, 6) for q in q_values_unrounded]\n\n        all_results.append([q_values_rounded, discoveries])\n\n    # Format the final output string exactly as specified.\n    case_strings = []\n    for res in all_results:\n        q_vals_str = f\"[{','.join(map(str, res[0]))}]\"\n        indices_str = f\"[{','.join(map(str, res[1]))}]\"\n        case_strings.append(f\"[{q_vals_str},{indices_str}]\")\n    \n    print(f\"[{','.join(case_strings)}]\")\n\nsolve()\n```", "id": "4557666"}]}