## 引言
深度学习的兴起正在彻底改变医学图像分析，尤其是在自动分割领域。精确的图像分割是放射组学、疾病诊断和治疗规划的基石，但手动分割耗时、费力且观察者间差异大，这构成了临床工作流程中的一个主要瓶颈。本文旨在系统性地解决这一挑战，为读者提供一个关于[深度学习](@entry_id:142022)自动分割的全面指南。

在接下来的内容中，我们将分三步深入探索这一领域。首先，在“原理与机制”一章中，我们将剖析[U-Net](@entry_id:635895)等核心[网络架构](@entry_id:268981)，探讨不同的[损失函数](@entry_id:136784)选择，并分析从2D到3D模型的演进。接着，在“应用与跨学科连接”一章中，我们将展示这些技术如何在放射组学、神经科学和计算病理学等多个领域发挥作用，并讨论[领域偏移](@entry_id:637840)、不确定性量化等现实世界的挑战。最后，在“动手实践”部分，我们将通过具体练习，巩固您对网络构建、训练和评估的理解。通过本次学习，您将掌握将深度学习[分割模](@entry_id:138050)型从理论概念转化为可靠临床工具所需的关键知识。

## 原理与机制

在上一章中，我们概述了[深度学习](@entry_id:142022)在自动分割领域的崛起及其在放射组学中的变革性作用。本章将深入探讨驱动这些先进模型的核心原理与机制。我们将剖析其架构设计、训练动态以及在现实世界临床环境中部署时面临的挑战。我们的目标是建立一个坚实的理论基础，使我们能够理解、评估并有效应用这些强大的工具。

### 分割任务的精确定义

从根本上说，自动分割是一项**密集预测 (dense prediction)** 任务。与旨在为整个图像或图像区域分配单一标签的**分类 (classification)** 任务不同，分割的目标是为图像中的每一个体素（或像素）分配一个类别标签。形式上，给定一个定义在体素格点 $\Omega$ 上的标量图像[强度函数](@entry_id:755508) $I: \Omega \to \mathbb{R}$，一个[分类任务](@entry_id:635433)旨在学习一个函数 $c: \mathcal{I} \to \{1, \dots, K\}$，它将整个图像 $I \in \mathcal{I}$ 映射到一个类别。而一个分割任务则旨在学习一个函数 $s: \Omega \to \{0, 1, \dots, K\}$，它为每个体素 $x \in \Omega$ 精确地分配一个标签。

这种体素级别的精确性对于放射组学至关重要。放射组学特征是从特定的**感兴趣区域 (Region of Interest, ROI)** 中提取的，该区域由分割结果定义，即 $\text{ROI} = \{x \in \Omega : s(x) = \ell\}$（其中 $\ell$ 是目标类别，如“肿瘤”）。分割的任何不精确性都会直接污染 ROI，从而扭曲提取的特征，最终影响下游预测模型的性能。

为了具体理解这一点，我们可以构建一个简化的思想实验 [@problem_id:4535934]。假设在一个肿瘤与背景的二元分割任务中，真实肿瘤体素的强度遵循正态分布 $\mathcal{N}(\mu_T, \sigma_T^2)$，而背景体素的强度遵循 $\mathcal{N}(\mu_B, \sigma_B^2)$，且 $\mu_T \neq \mu_B$。现在，假设一个分割网络产生了一个预测的 ROI，我们称之为 $\widehat{\text{ROI}}$。这个预测区域存在错误，具体来说，它错误地包含了一部分比例为 $\varepsilon$ 的背景体素（即**[假阳性](@entry_id:635878)**或伪影），但为简单起见，我们假设它没有漏掉任何真实的肿瘤体素（即没有**假阴性**）。

如果我们在这个被污染的 $\widehat{\text{ROI}}$ 上计算一个基本的一阶放射组学特征，例如平均强度 $\hat{\mu}$，那么这个特征的[期望值](@entry_id:150961)将会发生偏移。$\widehat{\text{ROI}}$ 中的体素实际上是一个[混合分布](@entry_id:276506)，其中 $(1-\varepsilon)$ 的部分来自真实肿瘤，$\varepsilon$ 的部分来自背景。因此，$\hat{\mu}$ 的[期望值](@entry_id:150961)为：
$$
E[\hat{\mu}] = (1-\varepsilon)\mu_T + \varepsilon\mu_B
$$
这个估计值相对于真实肿瘤平均强度 $\mu_T$ 的**系统性偏差 (systematic bias)** 为：
$$
\text{Bias}(\hat{\mu}) = E[\hat{\mu}] - \mu_T = \varepsilon(\mu_B - \mu_T)
$$
这个偏差直接与污染比例 $\varepsilon$ 成正比。此外，这种混合还导致了特征**方差的膨胀 (variance inflation)**。可以证明，相对于无污染情况，$\hat{\mu}$ 的方差增加了一个与 $\varepsilon(1-\varepsilon)(\mu_T - \mu_B)^2$ 成正比的项 [@problem_id:4535934]。这意味着分割不准确不仅会引入系统性偏差，还会降低特征的稳定性和可重复性。因此，实现高精度的体素级分割是可靠放射组学分析的基石，任何分割错误都会直接传播并损害后续模型的准确性和泛化能力。

根据分割任务输出的粒度，我们可以进一步将其细分为三种主要类型 [@problem_id:4535990]：

1.  **[语义分割](@entry_id:637957) (Semantic Segmentation)**：这是最基础的分割形式。它为图像中的每个体素分配一个语义类别标签（如“肝脏”、“肿瘤”、“血管”），但不区分同一类别的不同实例。例如，如果肝脏内有三个独立的转移瘤，[语义分割](@entry_id:637957)会将所有这些转移瘤的体素都标记为“肿瘤”，而不会将它们区分为三个独立的实体。其输出是一个单一的类别图 $S: \Omega \to \mathcal{C}$，其中 $\mathcal{C}$ 是预定义的类别集合。

2.  **[实例分割](@entry_id:634371) (Instance Segmentation)**：此任务更进一步，旨在检测并描绘出图像中每个独立的对象实例。它不仅告诉我们一个体素属于哪个类别，还告诉我们它属于该类别的哪个特定实例。例如，它会为每个肺结节生成一个独立的、不重叠的掩模。这对于需要计数（如病灶数量）或对每个实例进行独立特征分析的放射组学应用至关重要。其输出通常是一组对象实例的集合 $\{(R_k, c_k)\}_{k=1}^{K}$，其中 $R_k \subset \Omega$ 是第 $k$ 个实例的掩模，而 $c_k \in \mathcal{C}$ 是其类别。

3.  **[全景分割](@entry_id:637098) (Panoptic Segmentation)**：该任务统一了[语义分割](@entry_id:637957)和[实例分割](@entry_id:634371)，旨在为图像中的每一个体素提供一个全面且无[歧义](@entry_id:276744)的解析。它将类别分为两类：“事物”（things），即可数的独立对象（如器官、病灶）；以及“材料”（stuff），即无定形的、不可数的背景区域（如脂肪、[肌肉组织](@entry_id:145481)）。[全景分割](@entry_id:637098)为每个体素分配一个类别标签和一个实例ID。如果体素属于“事物”类，它会获得一个唯一的正实例ID；如果属于“材料”类，则实例ID为零或空。其输出是一个函数 $P: \Omega \to \mathcal{C} \times \mathbb{N}$，确保每个体素都恰好属于一个语义类别和一个实例，从而提供最完整的场景理解。

### 核心架构：[U-Net](@entry_id:635895)及其[编码器-解码器](@entry_id:637839)结构

为了完成上述的密集预测任务，一种被称为**[编码器-解码器](@entry_id:637839) (encoder-decoder)** 的[网络架构](@entry_id:268981)应运而生，其中最著名和应用最广泛的当属 **[U-Net](@entry_id:635895)**。[U-Net](@entry_id:635895) 的设计巧妙地解决了[语义分割](@entry_id:637957)中的一个核心矛盾：既要理解“是什么”（全局语义信息），又要精确定位“在哪里”（局部空间信息）。

让我们从第一性原理出发，剖析其工作机制 [@problem_id:4535954]。[网络结构](@entry_id:265673)主要分为两部分：

1.  **编码器（收缩路径）**：编码器的作用是捕捉图像的上下文信息。它由一系列卷积层和**[下采样](@entry_id:265757) (downsampling)** 操作（如[最大池化](@entry_id:636121)）组成。[离散卷积](@entry_id:160939)是基本的[特征提取](@entry_id:164394)单元，它通过一个小的学习**核 (kernel)** 在输入上滑动来生成[特征图](@entry_id:637719)。从数学上讲，二维[离散卷积](@entry_id:160939)定义为 $y[i,j] = \sum_{u}\sum_{v} x[i-u, j-v] k[u,v]$（实际上大多数深度学习框架实现的是**[互相关](@entry_id:143353) (cross-correlation)**，它省略了核的翻转步骤，即 $y[i,j] = \sum_{u}\sum_{v} x[i+u, j+v] k[u,v]$；由于核是可学习的，这种差异不影响网络的[表达能力](@entry_id:149863)，网络可以学习到一个翻转的核来达到同样的效果 [@problem_id:4535908]）。

    通过堆叠卷积层和[下采样](@entry_id:265757)层，编码器逐步减小特征图的空间分辨率（例如，每层减半），同时增加通道数。[下采样](@entry_id:265757)操作（如 $2 \times 2$ 的[最大池化](@entry_id:636121)）极大地扩展了后续卷积层的**[感受野](@entry_id:636171) (receptive field)**——即输出特征图中的一个点所能“看到”的输入图像区域。随着[网络深度](@entry_id:635360)的增加，编码器深层特征的[感受野](@entry_id:636171)变得非常大，使其能够整合广阔的上下文，从而理解高级语义信息，例如识别一个物体是器官还是病灶。

2.  **解码器（扩展路径）**：解码器的作用是逐步恢复空间分辨率，以生成与输入图像大小相同的分割图。它通过**[上采样](@entry_id:275608) (upsampling)** 操作（如[转置卷积](@entry_id:636519)）和卷积层来实现。[上采样](@entry_id:275608)将低分辨率的、富含语义信息的[特征图](@entry_id:637719)放大。

然而，这里存在一个关键问题：[下采样](@entry_id:265757)是一个“多对一”的映射，它必然会丢弃高频的、精细的空间信息，例如物体的精确边界。单纯依靠解码器从粗糙的语义特征图中[上采样](@entry_id:275608)，无法凭空恢复这些已经丢失的细节，其结果往往是模糊不清的边界。

[U-Net](@entry_id:635895) 的精髓在于**[跳跃连接](@entry_id:637548) (skip connections)** 的引入。这些连接将编码器中每个分辨率层级的[特征图](@entry_id:637719)直接“跳跃”并拼接（concatenate）到解码器中相应分辨率的层级上。这样一来，解码器在每个阶段都同时拥有两种信息：来自解码器路径下一层的、经过[上采样](@entry_id:275608)的、包含全局上下文的粗糙特征；以及来自编码器路径的、未经深度[下采样](@entry_id:265757)的、包含高频空间细节的精细特征。解码器中的卷积层随后学习如何将这两种信息进行有效融合，利用上下文信息来判断“是什么”，并利用空间细节信息来精确定位“在哪里”。正是这种[编码器-解码器](@entry_id:637839)结构与[跳跃连接](@entry_id:637548)的结合，使得 [U-Net](@entry_id:635895) 能够同时实现准确的语义识别和精确的边界定位，成为[医学图像分割](@entry_id:636215)的黄金标准。

### 处理三维数据：从2D到3D的演进

医学图像本质上通常是三维（容积）数据，例如 CT 和 MRI 扫描。如何将 [U-Net](@entry_id:635895) 架构有效地应用于这些数据是一个关键的实践问题。主要有三种策略 [@problem_id:4535960]：

-   **2D [U-Net](@entry_id:635895)**：这是最简单的方法。它将三维容积视为一系列独立的二维切片（例如，轴向切片），然后对每个切片独立应用一个标准的 2D [U-Net](@entry_id:635895) 进行分割。这种方法的优点是计算和内存效率高，并且可以利用在大型 2D 图像数据集（如 ImageNet）上预训练的模型。然而，其致命弱点是完全忽略了切片间的上下文信息（即 $z$ 轴方向的关联性）。对于每个输出体素，其感受野在 $z$ 轴方向的范围始终为 $1$，这对于那些在三维空间中具有连续形态的结构（如血管或细长的肿瘤）的分割是不利的。

-   **2.5D [U-Net](@entry_id:635895)**：这是一种折衷方案。它不是输入单个切片，而是输入一个包含目标切片及其前后相邻切片的薄“切片堆”（例如，3 或 5 个切片）。这些切片通常被堆叠在通道维度上，然后输入到一个 2D [U-Net](@entry_id:635895) 中。这种方法能够在一定程度上利用相邻切片的信息，但其 $z$ 轴方向的上下文仍然是局部的，并且在网络中不会随着深度而增长。它在计算成本和上下文利用之间取得了平衡。

-   **3D [U-Net](@entry_id:635895)**：这是最直接、理论上最强大的方法。它将所有的卷积、池化和[上采样](@entry_id:275608)操作都从二维扩展到三维（例如，使用 $3 \times 3 \times 3$ 的[卷积核](@entry_id:635097)和 $2 \times 2 \times 2$ 的池化）。这使得网络能够在所有三个维度上自由地学习和整合信息，其[感受野](@entry_id:636171)在 $x, y, z$ 三个方向上都会随[网络深度](@entry_id:635360)而增长。因此，3D [U-Net](@entry_id:635895) 能够完全捕捉三维空间中的复杂形态和上下文。然而，这种方法的代价是巨大的。假设特征通道数相同，一个 $256 \times 256 \times 128$ 的 3D [U-Net](@entry_id:635895) 在早期层的激活张量内存消耗大约是处理单张 $256 \times 256$ 切片的 2D [U-Net](@entry_id:635895) 的 $128$ 倍。这种高昂的计算和内存需求限制了其可以处理的输入容积大小和[网络深度](@entry_id:635360)。例如，一个具有三层[下采样](@entry_id:265757)的典型 3D [U-Net](@entry_id:635895)，其在瓶颈处的[感受野](@entry_id:636171)可能仍小于输入容积的完整深度，意味着它仍然无法在单一前向传播中看到完整的全局上下文 [@problem_id:4535960]。

### 解码器中的关键技术：上采样方法

解码器路径中的[上采样](@entry_id:275608)是恢复空间分辨率的核心，其实现方式对最终分割质量有显著影响。主要有以下几种方法 [@problem_id:4535975]：

-   **[转置卷积](@entry_id:636519) (Transposed Convolution)**：也常被误称为“[反卷积](@entry_id:141233)”(deconvolution)。它可以被看作是一种可学习的[上采样](@entry_id:275608)。从信号处理的角度来看，它类似于先通过“插零”扩大特征图，然后在扩大的图上进行一次标准的卷积。这个[卷积核](@entry_id:635097)是可学习的，理论上可以学习到最优的重建滤波器。然而，当卷积核大小不能被步长整除时（例如，核大小为 $3 \times 3$，步长为 $2$），会导致核在输出网格上的重叠不均匀，从而产生棋盘状的伪影 (checkerboard artifacts)，这是一种[空间混叠](@entry_id:275674) (aliasing) 现象。

-   **插值后卷积 (Interpolation followed by Convolution)**：这种方法分两步走。首先，使用一种固定的、非学习的插值算法（如最近邻或[双线性插值](@entry_id:170280)）将特征图放大到目标尺寸。然后，应用一个标准的卷积层来对放大的特征图进行[特征学习](@entry_id:749268)和细化。[双线性插值](@entry_id:170280)本质上是一种低通滤波，它能有效抑制[上采样](@entry_id:275608)过程中产生的[频谱](@entry_id:276824)镜像，从而减少混叠伪影，使特征图更平滑。但代价是可能会模糊掉一些高频的边缘细节。

-   **子像素卷积 (Sub-pixel Convolution)**：也称为“像素重排”(pixel shuffle)。这是一种高效且优雅的上采样方法。它首先在低分辨率[特征图](@entry_id:637719)上应用一个标准卷积，但这个卷积的输出通道数是所需[上采样](@entry_id:275608)因子平方的倍数（例如，[上采样](@entry_id:275608) $2$ 倍，则输出 $4$ 倍通道）。然后，通过一个确定的重排操作，将这些额外的通道维度上的信息重新排列到空间维度上，从而在不增加计算复杂度的情况下实现分辨率的提升。这种方法避免了[转置卷积](@entry_id:636519)的重叠问题，但如果学习到的低分辨率[滤波器组](@entry_id:266441)之间缺乏相位一致性，也可能引入新的伪影。

总结来说，这些方法在学习能力、计算效率和伪影抑制之间存在权衡。[转置卷积](@entry_id:636519)最灵活但也最容易产生伪影；插值法最稳定但也可能过于平滑；子像素卷积则提供了一种高效的替代方案。

### 训练动态与[损失函数](@entry_id:136784)的选择

训练分割网络的核心在于定义一个合适的**[损失函数](@entry_id:136784) (loss function)**，它能够量化模型预测与真实标签之间的差距，并为网络参数的更新提供有效的梯度信号。

#### 类别不平衡的挑战

[医学图像分割](@entry_id:636215)任务普遍存在严重的**[类别不平衡](@entry_id:636658) (class imbalance)** 问题。例如，在肿瘤分割中，肿瘤体素可能只占整个图像或批次中体素总数的极小一部分（例如，少于 1%）。这对训练过程构成了巨大挑战 [@problem_id:4535944]。

考虑标准的**[二元交叉熵](@entry_id:636868) (Binary Cross-Entropy, BCE)** [损失函数](@entry_id:136784)：
$$
L_{\text{BCE}} = -\frac{1}{N} \sum_{i=1}^{N} \left[ y_i \log p_i + (1 - y_i)\log(1 - p_i) \right]
$$
其中 $y_i \in \{0,1\}$ 是真实标签，$p_i$ 是模型预测为类别 $1$ 的概率，$N$ 是体素总数。其对网络输出（逻辑值 $z_i$，其中 $p_i = \sigma(z_i)$）的梯度可以简化为 $p_i - y_i$。在训练初期，模型输出的概率 $p_i$ 往往接近 $0.5$。对于一个前景（肿瘤）体素 ($y_i=1$)，其梯度贡献约为 $0.5 - 1 = -0.5$；对于一个背景体素 ($y_i=0$)，其梯度贡献约为 $0.5 - 0 = 0.5$。

虽然单个体素的梯度幅度相似，但由于背景体素的数量远超前景体素，总梯度的计算将被背景体素所主导。这会导致模型迅速学会将所有体素都预测为背景，因为这样做可以轻易地降低绝大多数体素的损失，从而陷入一个无用的局部最优解。

#### 应对挑战的[损失函数](@entry_id:136784)

为了解决类别不平衡和其他特定需求，研究者们设计了多种[损失函数](@entry_id:136784)：

-   **加权[交叉熵](@entry_id:269529) (Weighted Cross-Entropy)**：这是最直接的修正方法。通过为不同类别的损失项分配不同的权重，可以平衡它们的梯度贡献。例如，为前景类别（正样本）的损失项乘以一个较大的权重 $w > 1$，可以有效放大前景体素的梯度，使其在总梯度中不被淹没 [@problem_id:4535944]。

-   **Focal Loss**：Focal Loss 是对[交叉熵](@entry_id:269529)的进一步改进。它引入一个调制因子，动态地降低那些“容易”分类样本的权重。对于大量的、被模型轻易正确分类为背景的体素，它们的损失贡献会被大幅削减。这样，训练过程就能自动地将注意力集中在那些难以分类的“硬”样本上（通常是稀有的前景体素或边界体素），从而更有效地学习区分特征 [@problem_id:4535944] [@problem_id:4535917]。

-   **Dice Loss**：这类[损失函数](@entry_id:136784)直接优化分割任务中常用的评估指标——**Dice相似系数 (Dice Similarity Coefficient, DSC)**。DSC 是一个基于区域重叠的指标。其软化、可微的版本（Soft-DSC）可以写为：
    $$
    \text{Soft-DSC} = \frac{2 \sum_i p_i g_i}{\sum_i p_i + \sum_i g_i}
    $$
    其中 $p_i$ 是预测概率，$g_i$ 是真实标签。**Dice Loss** 定义为 $L_{\text{Dice}} = 1 - \text{Soft-DSC}$。有趣的是，DSC 在离散情况下与另一个常用的[分类指标](@entry_id:637806) **F1-score** 是完[全等](@entry_id:194418)价的 [@problem_id:4535970]。由于 Dice Loss 的计算只涉及前景类别的预测和标签（真阳性、[假阳性](@entry_id:635878)、假阴性），它天然地忽略了大量的真阴性（正确分类的背景），因此对类别不平衡问题非常鲁棒。

-   **Tversky Loss**：这是 Dice Loss 的一个推广。它引入了两个参数 $\alpha$ 和 $\beta$，分别用于调整对[假阳性](@entry_id:635878) (FP) 和假阴性 (FN) 的惩罚权重。Tversky 指数定义为 $TI = \frac{\text{TP}}{\text{TP} + \alpha \text{FP} + \beta \text{FN}}$。通过设置 $\beta > \alpha$，可以使[损失函数](@entry_id:136784)对漏报（假阴性）更加敏感，这在许多临床场景下至关重要，例如，宁可错报一些区域也不愿错过任何一个微小的病灶 [@problem_id:4535917]。

-   **边界损失 (Boundary Loss)**：当分割的边界精度至关重要时（例如，用于手术规划），可以引入专门的边界损失。这类损失通常通过计算预测边界与真实边界之间的距离（如[豪斯多夫距离](@entry_id:152367)）来施加惩罚，从而迫使网络学习更清晰、更准确的轮廓。通常，边界损失会与一个区域型损失（如 Dice 或交叉熵）结合使用，以获得既有良好区域重叠又有精确边界的分割结果 [@problem_id:4535917]。

选择哪种[损失函数](@entry_id:136784)取决于具体的应用场景：对于严重不平衡且区域重叠是主要指标的任务，Dice 或 Tversky Loss 是不错的选择；当需要调整[假阳性](@entry_id:635878)和假阴性的权衡时，Tversky Loss 提供了更大的灵活性；当模型[概率校准](@entry_id:636701)很重要且类别相对平衡时，[交叉熵](@entry_id:269529)是首选；当边界精度是首要任务时，则应考虑引入边界损失。

### 泛化与部署：[领域偏移](@entry_id:637840)的挑战

在实验室中训练出一个表现优异的模型只是第一步，将其成功部署到真实的临床环境中则面临着一个巨大的挑战——**[领域偏移](@entry_id:637840) (domain shift)** [@problem_id:4535946]。[领域偏移](@entry_id:637840)指的是训练数据（源域）的[统计分布](@entry_id:182030)与测试或部署数据（目标域）的[统计分布](@entry_id:182030)不一致。形式上，如果用 $(X, Y)$ 表示图像和其对应的标签对，[领域偏移](@entry_id:637840)意味着 $P_{\text{源}}(X, Y) \neq P_{\text{目标}}(X, Y)$。

在[医学影像](@entry_id:269649)中，[领域偏移](@entry_id:637840)的来源多种多样：

-   **扫描仪和硬件差异**：不同厂商（如西门子、GE、飞利浦）的 MRI 或 CT 扫描仪，其硬件、磁场强度、线圈设计均不相同，导致生成的图像在[信噪比](@entry_id:271196)、对比度和伪影模式上存在系统性差异。

-   **采集协议变化**：即使是同一台扫描仪，不同的采集协议（如回波时间 (TE)、重复时间 (TR)、翻转角、层厚、重建算法）也会产生外观迥异的图像。

-   **患者群体异质性**：不同医院、不同地区的患者在年龄、性别、种族、疾病谱和解剖结构上存在差异。这种生物学上的变异性会直接反映在图像数据上。

[领域偏移](@entry_id:637840)可以进一步细分为两种主要类型：

1.  **[协变量偏移](@entry_id:636196) (Covariate Shift)**：指输入图像的边缘分布发生变化，即 $P_{\text{源}}(X) \neq P_{\text{目标}}(X)$，但图像内容与正确标签之间的条件关系保持不变，即 $P_{\text{源}}(Y|X) = P_{\text{目标}}(Y|X)$。这通常是由扫描仪或协议差异引起的。例如，即使两个医院的放射科医生遵循完全相同的肝脏勾画指南（$P(Y|X)$ 不变），但由于扫描仪不同，肝脏在图像中的“样子”（$P(X)$）却发生了改变。

2.  **概念偏移 (Concept Shift)**：指图像与标签之间的条件关系发生了变化，即 $P_{\text{源}}(Y|X) \neq P_{\text{目标}}(Y|X)$。这通常源于标注标准或临床定义的变化。例如，一个医院的标注指南要求将肝门结构包含在肝脏分割内，而另一个医院则要求排除。此时，对于完全相同的图像 $X$，其“正确”的标签 $Y$ 却是不同的。

无论是哪种形式的偏移，都会导致在源域上训练好的模型在目标域上的性能显著下降。这是因为模型学习到的[特征和](@entry_id:189446)决策边界可能对源域数据产生了“[过拟合](@entry_id:139093)”，无法很好地泛化到具有不同统计特性的新数据上。因此，开发能够适应[领域偏移](@entry_id:637840)的鲁棒模型，或在部署前对模型进行[领域自适应](@entry_id:637871)微调，是实现深度学习模型临床转化的关键环节。