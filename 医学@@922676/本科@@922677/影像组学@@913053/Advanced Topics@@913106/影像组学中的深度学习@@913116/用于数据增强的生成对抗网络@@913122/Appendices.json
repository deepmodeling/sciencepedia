{"hands_on_practices": [{"introduction": "在着手构建复杂的生成对抗网络（GAN）之前，理解数据增强的量化目标至关重要。本练习将引导您完成一项基础的推导，计算生成合成的少数类样本如何直接影响数据集的类别不平衡比率和类别先验概率。掌握这种分析能力，可以帮助您在决定需要生成多少数据以达到理想的平衡状态时，做出更有依据的决策 [@problem_id:4541978]。", "problem": "在一个基于放射组学的二元病变分类任务中，该任务旨在区分恶性与良性病变。假设训练数据集最初包含总共 $T_{0}$ 个病变，这些病变被划分为少数类和多数类。设初始类别不平衡比定义为 $r = n_{\\min,0}/n_{\\maj,0}$，其中 $n_{\\min,0}$ 和 $n_{\\maj,0}$ 分别表示少数类和多数类病变的初始数量。使用生成对抗网络 (Generative Adversarial Network, GAN) 来合成并向训练集中添加 $N$ 个额外的少数类病变。假设所有合成的病变都被接纳到数据集中，并被视为完全标记的样本，同时不改变多数类的数量。\n\n仅使用经验风险最小化中类别数量、类别不平衡比和类别先验的基本定义，推导以下各项的闭式表达式：\n- 类别平衡的预期变化，以少数类与多数类比例的差异 $\\Delta r = r_{\\text{new}} - r$ 来衡量，以及\n- 数据增强后新的少数类先验 $\\pi_{\\min,1}$。\n\n将两个结果纯粹用 $r$、$N$ 和 $T_{0}$ 表示。以一个两元行矩阵的形式提供您的最终答案，其中第一个元素等于 $\\Delta r$，第二个元素等于 $\\pi_{\\min,1}$。不需要数值近似，也不需要单位。如果您选择简化，请进行代数简化；不要引入任何额外的假设或参数。最终表达式必须是精确的，而非四舍五入。", "solution": "该问题陈述已经过严格验证，并被认为是有效的。它在科学上基于机器学习和统计学的原理，特别涉及针对类别不平衡的数据增强策略。该问题是适定的、客观的，并包含推导唯一且有意义解所需的所有必要信息。\n\n目标是推导数据集增强后类别不平衡比的变化量 $\\Delta r$ 和新的少数类先验 $\\pi_{\\min,1}$ 的表达式。结果必须仅用初始不平衡比 $r$、合成样本数 $N$ 和初始总样本数 $T_{0}$ 来表示。\n\n首先，我们必须用给定的参数 $T_{0}$ 和 $r$ 来表示初始少数类和多数类的数量，$n_{\\min,0}$ 和 $n_{\\maj,0}$。\n初始病变总数由下式给出：\n$$T_{0} = n_{\\min,0} + n_{\\maj,0}$$\n初始类别不平衡比定义为：\n$$r = \\frac{n_{\\min,0}}{n_{\\maj,0}}$$\n根据 $r$ 的定义，我们可以写出 $n_{\\min,0} = r \\cdot n_{\\maj,0}$。将此代入 $T_{0}$ 的方程中：\n$$T_{0} = r \\cdot n_{\\maj,0} + n_{\\maj,0} = (r+1)n_{\\maj,0}$$\n解出 $n_{\\maj,0}$ 可得：\n$$n_{\\maj,0} = \\frac{T_{0}}{r+1}$$\n随后，我们可以将此结果代回 $n_{\\min,0}$ 的表达式中求得 $n_{\\min,0}$：\n$$n_{\\min,0} = r \\cdot n_{\\maj,0} = \\frac{r T_{0}}{r+1}$$\n\n接下来，我们定义数据增强后的数量。问题陈述指出，添加了 $N$ 个合成的少数类病变，而多数类的数量保持不变。\n新的少数类数量 $n_{\\min,1}$ 为：\n$$n_{\\min,1} = n_{\\min,0} + N = \\frac{r T_{0}}{r+1} + N$$\n新的多数类数量 $n_{\\maj,1}$ 为：\n$$n_{\\maj,1} = n_{\\maj,0} = \\frac{T_{0}}{r+1}$$\n新的病变总数 $T_{1}$ 为：\n$$T_{1} = T_{0} + N$$\n\n现在我们可以计算新的类别不平衡比 $r_{\\text{new}}$。\n$$r_{\\text{new}} = \\frac{n_{\\min,1}}{n_{\\maj,1}} = \\frac{\\frac{r T_{0}}{r+1} + N}{\\frac{T_{0}}{r+1}}$$\n为简化此表达式，我们将分子和分母同乘以 $(r+1)$：\n$$r_{\\text{new}} = \\frac{(r T_{0}) + N(r+1)}{T_{0}} = \\frac{r T_{0}}{T_{0}} + \\frac{N(r+1)}{T_{0}}$$\n$$r_{\\text{new}} = r + \\frac{N(r+1)}{T_{0}}$$\n类别平衡比的变化量 $\\Delta r$ 定义为 $r_{\\text{new}} - r$。\n$$\\Delta r = \\left(r + \\frac{N(r+1)}{T_{0}}\\right) - r$$\n$$\\Delta r = \\frac{N(r+1)}{T_{0}}$$\n这是第一个要求的表达式。\n\n最后，我们推导新的少数类先验 $\\pi_{\\min,1}$ 的表达式。一个类别的先验是其相对频率，定义为该类别中的样本数除以总样本数。\n$$\\pi_{\\min,1} = \\frac{n_{\\min,1}}{T_{1}}$$\n代入 $n_{\\min,1}$ 和 $T_{1}$ 的表达式：\n$$\\pi_{\\min,1} = \\frac{\\frac{r T_{0}}{r+1} + N}{T_{0} + N}$$\n为简化分子，我们进行通分：\n$$\\frac{r T_{0}}{r+1} + N = \\frac{r T_{0}}{r+1} + \\frac{N(r+1)}{r+1} = \\frac{r T_{0} + N(r+1)}{r+1}$$\n将此代回 $\\pi_{\\min,1}$ 的表达式中：\n$$\\pi_{\\min,1} = \\frac{\\frac{r T_{0} + N(r+1)}{r+1}}{T_{0} + N}$$\n$$\\pi_{\\min,1} = \\frac{r T_{0} + N(r+1)}{(r+1)(T_{0} + N)}$$\n这是第二个要求的表达式，完全用 $r$、$N$ 和 $T_{0}$ 表示。\n\n推导出的两个表达式是：\n1. $\\Delta r = \\frac{N(r+1)}{T_{0}}$\n2. $\\pi_{\\min,1} = \\frac{r T_{0} + N(r+1)}{(r+1)(T_{0} + N)}$\n\n按要求，这些表达式以一个两元行矩阵的形式提供。", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{N(r+1)}{T_{0}} & \\frac{r T_{0} + N(r+1)}{(r+1)(T_{0} + N)} \\end{pmatrix}}$$", "id": "4541978"}, {"introduction": "深度学习模型的训练需要在各种现实世界的约束条件下进行权衡。本练习将让您扮演一位人工智能工程师，负责设计一个基于图像块（patch-based）的训练流程，同时要考虑图形处理器（GPU）有限的显存。您将学习如何确定最优的图像块尺寸和批次大小，以确保为灰度共生矩阵（GLCM）等放射组学纹理特征提供足够的空间上下文，同时严格遵守给定的显存预算 [@problem_id:4541955]。", "problem": "您的任务是为用于放射组学中数据增强的生成对抗网络 (GAN) 设计一个基于图像块的训练流程。关键要求是，图像块维度必须为计算源自灰度共生矩阵 (GLCM) 的纹理特征提供足够的空间上下文，同时确保总图形处理单元 (GPU) 内存使用量不超过指定的预算。\n\n请从以下基础出发：\n- 对于给定的偏移向量 $\\Delta = (d_x, d_y)$，灰度共生矩阵 (GLCM) 的定义是通过在一个离散图像中计数所有有序像素位置对 $(\\mathbf{p}, \\mathbf{q})$，使得 $\\mathbf{q} = \\mathbf{p} + \\Delta$，且位置对需在图像块边界内。对于一个高为 $H$、宽为 $W$ 的矩形图像块，偏移 $\\Delta$ 的有效位置对数量等于位置 $\\mathbf{p}$ 的数量，其移位后的位置 $\\mathbf{q}$ 仍在该图像块内。当 $H \\ge |d_y| + 1$ 和 $W \\ge |d_x| + 1$ 时，此计数为 $(H - |d_y|) \\cdot (W - |d_x|)$，否则为零。\n- 生成器和判别器在训练期间存储的数组所使用的总内存可以建模为单个样本的张量大小与一个聚合乘法因子的乘积，该因子考虑了前向激活、反向梯度和双网络存储。设此因子为 $\\gamma$。对于批量大小 $B$、图像块维度 $H \\times W$、通道数 $C$ 和每元素字节数 $b$，与激活相关的内存为 $\\gamma \\cdot B \\cdot H \\cdot W \\cdot C \\cdot b$。设两个网络的组合参数内存为 $P$。那么总内存为 $P + \\gamma \\cdot B \\cdot H \\cdot W \\cdot C \\cdot b$，该值不得超过可用预算 $M$ 字节。\n\n您的程序必须确定整数图像块维度 $H$ 和 $W$ 以及整数批量大小 $B$，满足以下条件：\n- 对于给定集合 $\\mathcal{O}$ 中的每个偏移 $\\Delta_i = (d_{x,i}, d_{y,i})$，有效 GLCM 对的数量 $(H - |d_{y,i}|) \\cdot (W - |d_{x,i}|)$ 至少为一个所需的最小值 $K$。\n- GPU 内存约束 $P + \\gamma \\cdot B \\cdot H \\cdot W \\cdot C \\cdot b \\le M$ 成立，所有内存量均以字节表示。\n- 如果在给定约束下不存在可行的 $(H, W, B)$，您必须为该测试用例输出三元组 $(0, 0, 0)$。\n\n为使选择唯一且确定，您必须根据以下规则选择 $(H, W, B)$：\n- 在所有满足给定偏移和 $K$ 的 GLCM 约束的 $(H, W)$ 中，选择使面积 $H \\cdot W$ 最小的对。\n- 通过选择绝对宽高比差异 $|H - W|$ 最小的对来打破平局。\n- 通过选择最小的 $H$ 来打破任何剩余的平局。\n- 给定选定的 $(H, W)$，选择内存预算允许的最大整数 $B$。如果 $B  1$，则通过输出 $(0, 0, 0)$ 来声明不可行。\n\n所有答案都必须是整数，所有内存量都必须以字节处理和表示。\n\n使用以下包含 $4$ 个测试用例的测试套件，每个测试用例由 $(M, P, \\gamma, C, b, \\mathcal{O}, K)$ 指定：\n\n- 测试用例 $1$ (一般情况):\n  - $M = 1{,}000{,}000{,}000$ 字节, $P = 200{,}000{,}000$ 字节, $\\gamma = 16$, $C = 1$, $b = 4$ 字节,\n  - $\\mathcal{O} = \\{(1, 0), (0, 1), (1, 1)\\}$,\n  - $K = 80{,}000$。\n\n- 测试用例 $2$ (边界内存情况):\n  - $M = 192$ 字节, $P = 64$ 字节, $\\gamma = 16$, $C = 1$, $b = 4$ 字节,\n  - $\\mathcal{O} = \\{(1, 0)\\}$,\n  - $K = 1$。\n\n- 测试用例 $3$ (因预算紧张和上下文要求大而不可行的情况):\n  - $M = 60{,}000{,}000$ 字节, $P = 50{,}000{,}000$ 字节, $\\gamma = 16$, $C = 1$, $b = 4$ 字节,\n  - $\\mathcal{O} = \\{(10, 10)\\}$,\n  - $K = 1{,}000{,}000$。\n\n- 测试用例 $4$ (预算适中且偏移各向异性的情况):\n  - $M = 300{,}000{,}000$ 字节, $P = 100{,}000{,}000$ 字节, $\\gamma = 16$, $C = 1$, $b = 4$ 字节,\n  - $\\mathcal{O} = \\{(7, 0), (0, 1)\\}$,\n  - $K = 20{,}000$。\n\n您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个测试用例的结果格式化为列表 $[H,W,B]$，且不含空格，例如 $[[H_1,W_1,B_1],[H_2,W_2,B_2],[H_3,W_3,B_3],[H_4,W_4,B_4]]$。", "solution": "该问题要求在放射组学背景下，为训练生成对抗网络（GAN）确定最佳的整数图像块维度 $H$ 和 $W$，以及整数批量大小 $B$。解决方案必须满足关于灰度共生矩阵（GLCM）统计充分性和总 GPU 内存使用量的约束，同时遵循一个确定性的多级优化准则。\n\n该问题可以分解为两个相继的子问题：\n1. 首先，找到满足 GLCM 要求和指定决胜规则的最佳图像块维度 $(H, W)$，此步骤与内存预算无关。\n2. 其次，给定最佳的 $(H, W)$，计算遵循 GPU 内存约束的最大可能整数批量大小 $B$。\n\n### 第 1 部分：确定最佳图像块维度 $(H, W)$\n\nGLCM 约束规定，对于一个大小为 $H \\times W$ 的图像块和给定集合 $\\mathcal{O}$ 中的每个偏移 $\\Delta_i = (d_{x,i}, d_{y,i})$，有效像素对的数量必须至少为 $K$。像素对的数量由 $(H - |d_{y,i}|) \\cdot (W - |d_{x,i}|)$ 给出。这导出一个不等式组：\n$$\n(H - |d_{y,i}|) \\cdot (W - |d_{x,i}|) \\ge K \\quad \\forall \\Delta_i \\in \\mathcal{O}\n$$\n此外，为使这些计数非零，必须满足对所有 $i$ 都有 $H  |d_{y,i}|$ 和 $W  |d_{x,i}|$。这等价于 $H \\ge d_{y,max} + 1$ 和 $W \\ge d_{x,max} + 1$，其中 $d_{y,max} = \\max_{i} |d_{y,i}|$ 且 $d_{x,max} = \\max_i |d_{x,i}|$。\n\n对于任何给定的宽度 $W  d_{x,max}$，高度 $H$ 必须满足：\n$$\nH \\ge |d_{y,i}| + \\frac{K}{W - |d_{x,i}|} \\quad \\forall i\n$$\n由于 $H$ 必须是整数，对于给定的 $W$，所需的最小高度（我们表示为 $H_{cand}(W)$）是：\n$$\nH_{cand}(W) = \\max \\left( \\{ d_{y,max} + 1 \\} \\cup \\left\\{ \\left\\lceil \\frac{K}{W - |d_{x,i}|} \\right\\rceil + |d_{y,i}| \\mid \\Delta_i \\in \\mathcal{O} \\right\\} \\right)\n$$\n对于给定的高度 $H  d_{y,max}$，存在一个关于最小宽度 $W_{cand}(H)$ 的对称公式。\n\n优化目标是找到一个整数对 $(H, W)$，它满足这些约束并：\n1. 最小化面积 $A = H \\cdot W$。\n2. 对于具有相同最小面积的对，最小化绝对宽高比差异 $|H - W|$。\n3. 对于仍然平局的对，最小化高度 $H$。\n\n最佳对 $(H, W)$ 必须位于可行区域的边界上，这意味着它将满足 $H = H_{cand}(W)$ 或 $W = W_{cand}(H)$。为确保找到全局最小值，我们必须沿着该边界进行搜索。搜索策略如下：\n\n1.  **建立搜索边界**：首先，我们找到一个初始可行解来界定搜索空间。一个简单且可证明可行的对是 $(H_0, W_0) = (d_{y,max} + \\lceil\\sqrt{K}\\rceil, d_{x,max} + \\lceil\\sqrt{K}\\rceil)$。该对的面积 $A_0 = H_0 \\cdot W_0$ 作为最小面积的初始上界。任何最优解 $(H, W)$ 都必须满足 $H \\cdot W \\le A_0$。这意味着我们只需将 $W$ 搜索到上限 $W_{limit} = \\lfloor A_0 / (d_{y,max}+1) \\rfloor$，并将 $H$ 搜索到上限 $H_{limit} = \\lfloor A_0 / (d_{x,max}+1) \\rfloor$，因为任何更大的值都会产生比 $A_0$ 更大的面积（因为 $H \\ge d_{y,max}+1$ 和 $W \\ge d_{x,max}+1$）。\n\n2.  **迭代搜索**：搜索最佳对 $(H, W)$ 的一个稳健方法是，迭代其中一个维度（例如 $W$）的可能值，从其最小值 $d_{x,max}+1$ 开始。对于每个 $W$ 值，计算满足所有 GLCM 约束所需的最小高度 $H_{cand}(W)$。然后，计算面积 $A = H_{cand}(W) \\cdot W$。我们维护一个迄今为止找到的最佳对的列表，该列表根据优化标准（最小面积、最小 $|H-W|$、最小 $H$）进行更新。当找到一个更优的解时，我们可以用它来收紧搜索范围，从而有效地剪枝搜索空间。例如，如果当前的最小面积是 $A_{min}$，那么就没有必要测试任何 $W$ 值，使得 $W \\cdot (d_{y,max}+1) > A_{min}$。\n\n3.  **决胜规则**：搜索完成后，我们得到一个列表，其中包含所有实现相同全局最小面积的 $(H,W)$ 对。我们对此列表应用决胜规则。我们首先按 $|H-W|$ 升序排序候选者，然后按 $H$ 升序排序。排序后列表中的第一个对是唯一的最佳解。\n\n### 第 2 部分：确定批量大小 $B$\n\n一旦确定了最佳图像块维度 $(H_{opt}, W_{opt})$，我们就找到满足内存约束的最大整数批量大小 $B$：\n$$\nP + \\gamma \\cdot B \\cdot H_{opt} \\cdot W_{opt} \\cdot C \\cdot b \\le M\n$$\n其中 $M$ 是内存预算， $P$ 是参数内存， $\\gamma$ 是内存因子， $C$ 是通道数， $b$ 是每元素的字节数。\n\n重新排列不等式以求解 $B$：\n$$\nB \\le \\frac{M - P}{\\gamma \\cdot H_{opt} \\cdot W_{opt} \\cdot C \\cdot b}\n$$\n令可用激活内存为 $M_{avail} = M - P$，批次中每样本的内存为 $M_{per\\_sample} = \\gamma \\cdot H_{opt} \\cdot W_{opt} \\cdot C \\cdot b$。最大整数批量大小为：\n$$\nB = \\left\\lfloor \\frac{M_{avail}}{M_{per\\_sample}} \\right\\rfloor\n$$\n如果 $M_{avail}  0$ 或计算出的 $B$ 小于 $1$，则对于给定的参数不存在可行解，输出必须是 $(0, 0, 0)$。否则，最终解是三元组 $(H_{opt}, W_{opt}, B)$。\n这种系统性的、两阶段的方法确保了所有约束和优化准则都得到满足，从而提供了一个正确且确定性的解决方案。", "answer": "```python\nimport math\n\ndef find_optimal_hw(O, K):\n    \"\"\"\n    Finds the optimal (H, W) pair based on GLCM constraints and tie-breaking rules.\n    This implementation uses a robust search strategy to find the global optimum.\n    \"\"\"\n    dx_max = max(abs(dx) for dx, dy in O) if O else 0\n    dy_max = max(abs(dy) for dx, dy in O) if O else 0\n\n    if K == 0:\n        return dy_max + 1, dx_max + 1\n\n    def ceil_div(a, b):\n        if b == 0: return float('inf')\n        return (a + b - 1) // b\n\n    def get_min_h_for_w(w):\n        if w = dx_max: return float('inf')\n        min_h = dy_max + 1\n        for dx, dy in O:\n            if w - abs(dx) = 0: return float('inf')\n            required_h = ceil_div(K, w - abs(dx)) + abs(dy)\n            min_h = max(min_h, required_h)\n        return min_h\n\n    # Initial heuristic for search bounds\n    s_k = math.isqrt(K - 1) + 1 if K > 0 else 0\n    w_init = dx_max + s_k\n    h_init_for_w_init = get_min_h_for_w(w_init)\n    \n    if h_init_for_w_init == float('inf'): # Should not happen with valid K>0\n        return None\n\n    best_area = h_init_for_w_init * w_init\n    best_pairs = [(h_init_for_w_init, w_init)]\n\n    # Search over W, with pruning\n    w_limit = best_area // (dy_max + 1) if (dy_max + 1) > 0 else best_area\n    for w_try in range(dx_max + 1, w_limit + 2): # +2 for safety at boundary\n        h_cand = get_min_h_for_w(w_try)\n        if h_cand == float('inf'): continue\n        \n        current_area = h_cand * w_try\n        \n        if current_area  best_area:\n            best_area = current_area\n            best_pairs = [(h_cand, w_try)]\n            # Update search limit dynamically\n            w_limit = best_area // (dy_max + 1) if (dy_max + 1) > 0 else best_area\n        elif current_area == best_area:\n            best_pairs.append((h_cand, w_try))\n\n    # To be fully robust, a symmetric search over H is also needed, as the boundary\n    # is not necessarily monotonic.\n    # We can perform a similar search by iterating H and finding min W.\n    def get_min_w_for_h(h):\n        if h = dy_max: return float('inf')\n        min_w = dx_max + 1\n        for dx, dy in O:\n            if h - abs(dy) = 0: return float('inf')\n            required_w = ceil_div(K, h - abs(dy)) + abs(dx)\n            min_w = max(min_w, required_w)\n        return min_w\n\n    h_limit = best_area // (dx_max + 1) if (dx_max + 1) > 0 else best_area\n    for h_try in range(dy_max + 1, h_limit + 2):\n        w_cand = get_min_w_for_h(h_try)\n        if w_cand == float('inf'): continue\n        \n        current_area = h_try * w_cand\n        \n        if current_area  best_area:\n            best_area = current_area\n            best_pairs = [(h_try, w_cand)]\n            h_limit = best_area // (dx_max + 1) if (dx_max + 1) > 0 else best_area\n        elif current_area == best_area:\n            best_pairs.append((h_try, w_cand))\n\n    # Apply tie-breaking rules to the collected best pairs\n    unique_pairs = sorted(list(set(best_pairs)))\n    if not unique_pairs: return None\n    unique_pairs.sort(key=lambda p: (p[0] * p[1], abs(p[0] - p[1]), p[0]))\n    \n    return unique_pairs[0]\n\ndef solve():\n    test_cases = [\n        (1_000_000_000, 200_000_000, 16, 1, 4, [(1, 0), (0, 1), (1, 1)], 80_000),\n        (192, 64, 16, 1, 4, [(1, 0)], 1),\n        (60_000_000, 50_000_000, 16, 1, 4, [(10, 10)], 1_000_000),\n        (300_000_000, 100_000_000, 16, 1, 4, [(7, 0), (0, 1)], 20_000),\n    ]\n\n    all_results = []\n    for M, P, gamma, C, b, O, K in test_cases:\n        optimal_hw = find_optimal_hw(O, K)\n        \n        if optimal_hw is None:\n            all_results.append([0, 0, 0])\n            continue\n        \n        H, W = optimal_hw\n        mem_avail = M - P\n        \n        if mem_avail  0:\n            all_results.append([0, 0, 0])\n            continue\n\n        mem_per_sample = gamma * H * W * C * b\n        if mem_per_sample == 0:\n            all_results.append([0, 0, 0])\n            continue\n\n        B = mem_avail // mem_per_sample\n        \n        if B  1:\n            all_results.append([0, 0, 0])\n        else:\n            all_results.append([H, W, int(B)])\n            \n    print(str(all_results).replace(\" \", \"\"))\n\nsolve()\n```", "id": "4541955"}, {"introduction": "生成数据只是成功的一半，确保其质量同样至关重要。本练习将介绍一个关键的后处理步骤：筛选合成数据，剔除那些与真实数据分布不符的异常样本。您将实现一个基于马氏距离（Mahalanobis distance）的滤波器，这是一种强大的统计工具，它能够考虑到特征之间的相关性，从而确保只有高质量、具有代表性的合成样本被最终加入训练集 [@problem_id:4541943]。", "problem": "给定一项用于在放射组学中进行基于生成对抗网络（GAN）的数据增强的事后筛选任务。放射组学特征向量是从医学图像中提取的标准化数值描述符。在使用生成对抗网络（GAN）生成合成特征向量后，您需要使用马氏距离筛选出那些相对于真实特征分布而言是异常值的合成样本。假设来自真实样本的标准化放射组学特征向量近似服从多元正态分布。\n\n从第一性原理出发，使用以下基本概念：样本均值、无偏样本协方差、马氏距离的定义，以及一个经过充分检验的事实，即在多元正态模型下，一个样本与真实均值和协方差的马氏距离平方服从卡方分布，其自由度等于特征维度。\n\n任务定义如下：\n- 令真实特征向量表示为 $\\mathbf{r}_i \\in \\mathbb{R}^d$（$i = 1, \\dots, n$），这些向量收集在一个矩阵 $R \\in \\mathbb{R}^{n \\times d}$ 中。\n- 令合成特征向量为 $\\mathbf{s}_j \\in \\mathbb{R}^d$（$j = 1, \\dots, m$），这些向量收集在一个矩阵 $S \\in \\mathbb{R}^{m \\times d}$ 中。\n- 从 $R$ 计算样本均值 $\\hat{\\boldsymbol{\\mu}}$ 和无偏样本协方差 $\\hat{\\Sigma}$。\n- 定义一个正则化协方差 $\\Sigma_\\lambda = \\hat{\\Sigma} + \\lambda I_d$，其中 $I_d$ 是 $d \\times d$ 单位矩阵，$\\lambda \\ge 0$ 是一个小的非负正则化参数，用以确保数值稳定性（尤其是在 $\\hat{\\Sigma}$ 是奇异或病态矩阵时）。\n- 对于每个合成向量 $\\mathbf{s}_j$，计算其马氏距离平方\n$$\nm^2(\\mathbf{s}_j) = (\\mathbf{s}_j - \\hat{\\boldsymbol{\\mu}})^\\top \\Sigma_\\lambda^{-1} (\\mathbf{s}_j - \\hat{\\boldsymbol{\\mu}}).\n$$\n- 令 $\\alpha \\in (0,1)$ 为指定的置信水平。在多元正态模型下，$m^2(\\mathbf{x})$ 近似服从自由度为 $d$ 的卡方分布。使用此性质来设置阈值\n$$\n\\tau = F^{-1}_{\\chi^2(d)}(\\alpha),\n$$\n其中 $F^{-1}_{\\chi^2(d)}$ 表示自由度为 $d$ 的卡方分布在概率 $\\alpha$ 处的逆累积分布函数（分位数函数）。\n- 事后筛选器在 $m^2(\\mathbf{s}_j) \\le \\tau$ 时保留 $\\mathbf{s}_j$，在 $m^2(\\mathbf{s}_j)  \\tau$ 时移除 $\\mathbf{s}_j$。将等式情况 $m^2(\\mathbf{s}_j) = \\tau$ 视为“保留”。\n\n请实现此筛选器，并将其应用于以下测试套件。对于每个测试用例，计算筛选器保留的合成样本数量。您的程序必须生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表。\n\n测试套件：\n- 测试用例 A（一般情况，$d = 2$）：\n    - 真实特征矩阵 $R_A$，其中 $n = 7$：\n      $$\n      R_A = \\begin{bmatrix}\n      0.0  0.0 \\\\\n      1.0  0.0 \\\\\n      0.0  1.0 \\\\\n      -1.0  0.0 \\\\\n      0.0  -1.0 \\\\\n      0.5  -0.5 \\\\\n      -0.5  0.5\n      \\end{bmatrix}\n      $$\n    - 合成特征矩阵 $S_A$，其中 $m = 7$：\n      $$\n      S_A = \\begin{bmatrix}\n      0.2  0.1 \\\\\n      3.5  0.0 \\\\\n      0.0  3.5 \\\\\n      -3.0  -3.0 \\\\\n      0.3  -0.4 \\\\\n      1.5  1.5 \\\\\n      -0.1  0.0\n      \\end{bmatrix}\n      $$\n    - 置信水平 $\\alpha_A = 0.95$ 和正则化参数 $\\lambda_A = 0.0$。\n- 测试用例 B（一维边界条件，$d = 1$）：\n    - 真实特征矩阵 $R_B$，其中 $n = 3$：\n      $$\n      R_B = \\begin{bmatrix}\n      -1.0 \\\\\n      0.0 \\\\\n      1.0\n      \\end{bmatrix}\n      $$\n      由此可以得到样本均值 $\\hat{\\mu}_B$ 和样本方差 $\\hat{\\sigma}^2_B$，使用无偏估计量从 $R_B$ 计算得出。\n    - 置信水平 $\\alpha_B = 0.95$ 和正则化参数 $\\lambda_B = 0.0$。\n    - 合成特征矩阵 $S_B$（$m = 3$）构造如下：\n      $$\n      S_B = \\begin{bmatrix}\n      \\hat{\\mu}_B \\\\\n      \\hat{\\mu}_B + \\sqrt{\\tau_B \\cdot \\hat{\\sigma}^2_B} \\\\\n      3.0\n      \\end{bmatrix}, \\quad \\text{其中} \\quad \\tau_B = F^{-1}_{\\chi^2(1)}(\\alpha_B).\n      $$\n      第二个合成样本的马氏距离平方恰好在阈值上，根据规则 $m^2 \\le \\tau$ 必须被保留。\n- 测试用例 C（边缘案例：高维近奇异协方差，$d = 4$）：\n    - 真实特征矩阵 $R_C$，其中 $n = 2$：\n      $$\n      R_C = \\begin{bmatrix}\n      1.0  1.0  1.0  1.0 \\\\\n      1.0  1.0  1.0  1.0\n      \\end{bmatrix}\n      $$\n      样本协方差是奇异的；需要使用正则化。\n    - 合成特征矩阵 $S_C$，其中 $m = 3$：\n      $$\n      S_C = \\begin{bmatrix}\n      1.05  0.95  1.0  1.1 \\\\\n      5.0  5.0  5.0  5.0 \\\\\n      0.0  0.0  0.0  0.0\n      \\end{bmatrix}\n      $$\n    - 置信水平 $\\alpha_C = 0.975$ 和正则化参数 $\\lambda_C = 0.1$。\n\n您的程序应生成单行输出，其中包含按测试用例 $[A, B, C]$ 顺序排列、用方括号括起来的、以逗号分隔的结果列表。每个结果必须是该测试用例保留的合成样本的整数数量。例如，您的输出格式必须为 $[\\text{count}_A,\\text{count}_B,\\text{count}_C]$。", "solution": "问题陈述已经过验证，被认为是合理的。它具有科学依据，定义明确，客观且自成体系，提供了一个清晰的算法任务和用于测试的具体数据。该方法基于马氏距离及其与卡方分布的关系，用于检测多元正态数据中的异常值，是一种标准且有效的统计技术。测试用例经过精心设计，涵盖了一般情况、边界条件以及涉及奇异协方差矩阵的边缘案例。\n\n任务是为合成的放射组学特征向量实现一个事后筛选器。该筛选器的设计基于真实特征向量的统计特性。我们假设真实特征向量的总体服从一个 $d$ 维多元正态分布 $\\mathcal{N}(\\boldsymbol{\\mu}, \\Sigma)$。我们使用从一组真实样本 $R \\in \\mathbb{R}^{n \\times d}$ 计算出的样本均值 $\\hat{\\boldsymbol{\\mu}}$ 和无偏样本协方差 $\\hat{\\Sigma}$ 来估计总体均值 $\\boldsymbol{\\mu}$ 和协方差 $\\Sigma$。\n\n核心公式如下：\n样本均值向量计算如下：\n$$\n\\hat{\\boldsymbol{\\mu}} = \\frac{1}{n} \\sum_{i=1}^{n} \\mathbf{r}_i\n$$\n无偏样本协方差矩阵计算如下：\n$$\n\\hat{\\Sigma} = \\frac{1}{n-1} \\sum_{i=1}^{n} (\\mathbf{r}_i - \\hat{\\boldsymbol{\\mu}})(\\mathbf{r}_i - \\hat{\\boldsymbol{\\mu}})^\\top\n$$\n为确保数值稳定性，使用正则化协方差矩阵 $\\Sigma_\\lambda$：\n$$\n\\Sigma_\\lambda = \\hat{\\Sigma} + \\lambda I_d\n$$\n其中 $\\lambda \\ge 0$ 是一个正则化参数，而 $I_d$ 是 $d \\times d$ 单位矩阵。\n\n对于任何合成特征向量 $\\mathbf{s}_j$，我们计算它与真实数据分布均值的马氏距离平方：\n$$\nm^2(\\mathbf{s}_j) = (\\mathbf{s}_j - \\hat{\\boldsymbol{\\mu}})^\\top \\Sigma_\\lambda^{-1} (\\mathbf{s}_j - \\hat{\\boldsymbol{\\mu}})\n$$\n在多元正态假设下，对于从该分布中抽取的向量 $\\mathbf{x}$，其量 $m^2(\\mathbf{x})$ 服从自由度为 $d$ 的卡方分布，记为 $\\chi^2(d)$。我们根据置信水平 $\\alpha \\in (0,1)$ 定义一个阈值 $\\tau$，使得比例为 $\\alpha$ 的真实数据其马氏距离平方期望小于或等于 $\\tau$。该阈值是 $\\chi^2(d)$ 分布在概率 $\\alpha$ 处的分位数函数（逆累积分布函数）的值：\n$$\n\\tau = F^{-1}_{\\chi^2(d)}(\\alpha)\n$$\n如果一个合成样本 $\\mathbf{s}_j$ 的马氏距离平方不超过此阈值，即 $m^2(\\mathbf{s}_j) \\le \\tau$，则将其保留。\n\n现在我们将此过程应用于每个测试用例。\n\n### 测试用例 A\n给定参数如下：\n- 维度 $d=2$，真实样本数 $n=7$。\n- 真实数据矩阵 $R_A$。\n- 合成数据矩阵 $S_A$。\n- 置信水平 $\\alpha_A = 0.95$。\n- 正则化参数 $\\lambda_A = 0.0$。\n\n1.  **计算样本均值 $\\hat{\\boldsymbol{\\mu}}_A$**：\n    $R_A$ 的列和为 $[0.0, 0.0]^\\top$。因此，均值为 $\\hat{\\boldsymbol{\\mu}}_A = \\frac{1}{7} [0.0, 0.0]^\\top = [0.0, 0.0]^\\top$。\n\n2.  **计算无偏样本协方差 $\\hat{\\Sigma}_A$**：\n    当 $n=7$ 且 $\\hat{\\boldsymbol{\\mu}}_A = \\mathbf{0}$ 时，$\\hat{\\Sigma}_A = \\frac{1}{6} \\sum_{i=1}^{7} \\mathbf{r}_i \\mathbf{r}_i^\\top = \\frac{1}{6} R_A^\\top R_A$。\n    $R_A^\\top R_A = \\begin{bmatrix} 2.5  -0.5 \\\\ -0.5  2.5 \\end{bmatrix}$。\n    $\\hat{\\Sigma}_A = \\frac{1}{6} \\begin{bmatrix} 2.5  -0.5 \\\\ -0.5  2.5 \\end{bmatrix} = \\begin{bmatrix} 5/12  -1/12 \\\\ -1/12  5/12 \\end{bmatrix}$。\n\n3.  **计算正则化协方差 $\\Sigma_{\\lambda, A}$ 及其逆矩阵**：\n    由于 $\\lambda_A = 0.0$，$\\Sigma_{\\lambda, A} = \\hat{\\Sigma}_A$。其行列式为 $\\det(\\hat{\\Sigma}_A) = (5/12)^2 - (-1/12)^2 = (25-1)/144 = 24/144 = 1/6$。\n    其逆矩阵为 $\\Sigma_{\\lambda, A}^{-1} = \\frac{1}{1/6} \\begin{bmatrix} 5/12  1/12 \\\\ 1/12  5/12 \\end{bmatrix} = 6 \\begin{bmatrix} 5/12  1/12 \\\\ 1/12  5/12 \\end{bmatrix} = \\begin{bmatrix} 2.5  0.5 \\\\ 0.5  2.5 \\end{bmatrix}$。\n\n4.  **计算阈值 $\\tau_A$**：\n    对于 $d=2$ 和 $\\alpha_A=0.95$，$\\tau_A = F^{-1}_{\\chi^2(2)}(0.95) \\approx 5.9915$。\n\n5.  **筛选合成样本**：\n    对于每个 $\\mathbf{s}_j \\in S_A$，我们计算 $m^2(\\mathbf{s}_j) = \\mathbf{s}_j^\\top \\Sigma_{\\lambda, A}^{-1} \\mathbf{s}_j$ 并与 $\\tau_A$ 比较。\n    - $\\mathbf{s}_1 = [0.2, 0.1]^\\top$：$m^2 = 0.145 \\le 5.9915$ (保留)。\n    - $\\mathbf{s}_2 = [3.5, 0.0]^\\top$：$m^2 = 30.625  5.9915$ (移除)。\n    - $\\mathbf{s}_3 = [0.0, 3.5]^\\top$：$m^2 = 30.625  5.9915$ (移除)。\n    - $\\mathbf{s}_4 = [-3.0, -3.0]^\\top$：$m^2 = 54.0  5.9915$ (移除)。\n    - $\\mathbf{s}_5 = [0.3, -0.4]^\\top$：$m^2 = 0.505 \\le 5.9915$ (保留)。\n    - $\\mathbf{s}_6 = [1.5, 1.5]^\\top$：$m^2 = 13.5  5.9915$ (移除)。\n    - $\\mathbf{s}_7 = [-0.1, 0.0]^\\top$：$m^2 = 0.025 \\le 5.9915$ (保留)。\n    保留的样本数量为 $3$。\n\n### 测试用例 B\n给定参数如下：\n- 维度 $d=1$，真实样本数 $n=3$，真实数据矩阵 $R_B = [-1.0, 0.0, 1.0]^\\top$。\n- 置信水平 $\\alpha_B = 0.95$，正则化参数 $\\lambda_B = 0.0$。\n\n1.  **计算样本均值 $\\hat{\\mu}_B$ 和方差 $\\hat{\\sigma}^2_B$**：\n    对于 $d=1$，我们计算标量均值和方差。\n    $\\hat{\\mu}_B = \\frac{1}{3}(-1.0 + 0.0 + 1.0) = 0.0$。\n    $\\hat{\\sigma}^2_B = \\frac{1}{3-1} [(-1.0-0.0)^2 + (0.0-0.0)^2 + (1.0-0.0)^2] = \\frac{1}{2}(1+0+1) = 1.0$。\n\n2.  **计算正则化方差及其逆**：\n    由于 $\\lambda_B = 0.0$，正则化方差为 $\\sigma^2_{\\lambda, B} = \\hat{\\sigma}^2_B = 1.0$。其逆为 $1.0$。\n\n3.  **计算阈值 $\\tau_B$**：\n    对于 $d=1$ 和 $\\alpha_B=0.95$，$\\tau_B = F^{-1}_{\\chi^2(1)}(0.95) \\approx 3.8415$。\n\n4.  **构造 $S_B$ 并进行筛选**：\n    $S_B$ 是根据这些统计量构造的。马氏距离平方为 $m^2(s_j) = (s_j - \\hat{\\mu}_B)^2 / \\sigma^2_{\\lambda, B} = (s_j - 0)^2 / 1 = s_j^2$。\n    - $\\mathbf{s}_1 = [\\hat{\\mu}_B] = [0.0]^\\top$：$m^2 = 0.0^2 = 0.0 \\le 3.8415$ (保留)。\n    - $\\mathbf{s}_2 = [\\hat{\\mu}_B + \\sqrt{\\tau_B \\cdot \\hat{\\sigma}^2_B}] = [\\sqrt{\\tau_B}]^\\top$：$m^2 = (\\sqrt{\\tau_B})^2 = \\tau_B \\le \\tau_B$ (保留)。这测试了边界条件。\n    - $\\mathbf{s}_3 = [3.0]^\\top$：$m^2 = 3.0^2 = 9.0  3.8415$ (移除)。\n    保留的样本数量为 $2$。\n\n### 测试用例 C\n给定参数如下：\n- 维度 $d=4$，真实样本数 $n=2$，真实数据 $R_C$ 有两个相同的行。\n- 合成数据矩阵 $S_C$。\n- 置信水平 $\\alpha_C = 0.975$。\n- 正则化参数 $\\lambda_C = 0.1$。\n\n1.  **计算样本均值 $\\hat{\\boldsymbol{\\mu}}_C$**：\n    $R_C$ 的两行都是 $[1, 1, 1, 1]$，所以均值为 $\\hat{\\boldsymbol{\\mu}}_C = [1.0, 1.0, 1.0, 1.0]^\\top$。\n\n2.  **计算无偏样本协方差 $\\hat{\\Sigma}_C$**：\n    两个样本与均值的偏差均为 $(\\mathbf{r}_i - \\hat{\\boldsymbol{\\mu}}_C) = \\mathbf{0}$。因此，无偏样本协方差矩阵是 $4 \\times 4$ 零矩阵：$\\hat{\\Sigma}_C = \\mathbf{0}_{4 \\times 4}$。该矩阵是奇异的。\n\n3.  **计算正则化协方差 $\\Sigma_{\\lambda, C}$ 及其逆矩阵**：\n    此处必须进行正则化。当 $\\lambda_C=0.1$ 时，\n    $\\Sigma_{\\lambda, C} = \\hat{\\Sigma}_C + \\lambda_C I_4 = \\mathbf{0}_{4 \\times 4} + 0.1 I_4 = 0.1 I_4$。\n    其逆矩阵为 $\\Sigma_{\\lambda, C}^{-1} = (0.1 I_4)^{-1} = 10 I_4$。\n\n4.  **计算阈值 $\\tau_C$**：\n    对于 $d=4$ 和 $\\alpha_C=0.975$，$\\tau_C = F^{-1}_{\\chi^2(4)}(0.975) \\approx 11.1433$。\n\n5.  **筛选合成样本**：\n    对于每个 $\\mathbf{s}_j \\in S_C$，我们计算 $m^2(\\mathbf{s}_j) = (\\mathbf{s}_j - \\hat{\\boldsymbol{\\mu}}_C)^\\top (10 I_4) (\\mathbf{s}_j - \\hat{\\boldsymbol{\\mu}}_C) = 10 ||\\mathbf{s}_j - \\hat{\\boldsymbol{\\mu}}_C||^2_2$。\n    - $\\mathbf{s}_1 = [1.05, 0.95, 1.0, 1.1]^\\top$：$\\mathbf{s}_1 - \\hat{\\boldsymbol{\\mu}}_C = [0.05, -0.05, 0.0, 0.1]^\\top$。\n      $m^2 = 10 (0.05^2 + (-0.05)^2 + 0.0^2 + 0.1^2) = 10(0.0025 + 0.0025 + 0.01) = 10(0.015) = 0.15 \\le 11.1433$ (保留)。\n    - $\\mathbf{s}_2 = [5.0, 5.0, 5.0, 5.0]^\\top$：$\\mathbf{s}_2 - \\hat{\\boldsymbol{\\mu}}_C = [4.0, 4.0, 4.0, 4.0]^\\top$。\n      $m^2 = 10 (4^2 + 4^2 + 4^2 + 4^2) = 10(64) = 640  11.1433$ (移除)。\n    - $\\mathbf{s}_3 = [0.0, 0.0, 0.0, 0.0]^\\top$：$\\mathbf{s}_3 - \\hat{\\boldsymbol{\\mu}}_C = [-1.0, -1.0, -1.0, -1.0]^\\top$。\n      $m^2 = 10 ((-1)^2 \\times 4) = 10(4) = 40  11.1433$ (移除)。\n    保留的样本数量为 $1$。\n\n测试用例 A、B 和 C 的最终结果分别为保留样本数 3、2 和 1。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef solve():\n    \"\"\"\n    Implements and tests a post-hoc filter for synthetic data based on Mahalanobis distance.\n    The function processes three distinct test cases and computes the number of synthetic\n    samples kept by the filter for each case.\n    \"\"\"\n    results = []\n\n    # Test Case A: General case, 2D\n    R_A = np.array([\n        [0.0, 0.0], [1.0, 0.0], [0.0, 1.0], [-1.0, 0.0],\n        [0.0, -1.0], [0.5, -0.5], [-0.5, 0.5]\n    ])\n    S_A = np.array([\n        [0.2, 0.1], [3.5, 0.0], [0.0, 3.5], [-3.0, -3.0],\n        [0.3, -0.4], [1.5, 1.5], [-0.1, 0.0]\n    ])\n    alpha_A = 0.95\n    lambda_A = 0.0\n    \n    n_A, d_A = R_A.shape\n    mu_hat_A = np.mean(R_A, axis=0)\n    cov_hat_A = np.cov(R_A, rowvar=False, ddof=1)\n    cov_reg_A = cov_hat_A + lambda_A * np.identity(d_A)\n    inv_cov_reg_A = np.linalg.inv(cov_reg_A)\n    tau_A = chi2.ppf(alpha_A, df=d_A)\n\n    count_A = 0\n    for s_j in S_A:\n        diff = s_j - mu_hat_A\n        m2 = diff.T @ inv_cov_reg_A @ diff\n        if m2 = tau_A:\n            count_A += 1\n    results.append(count_A)\n\n    # Test Case B: Boundary condition, 1D\n    R_B = np.array([\n        [-1.0], [0.0], [1.0]\n    ])\n    alpha_B = 0.95\n    lambda_B = 0.0\n    \n    n_B, d_B = R_B.shape\n    mu_hat_B = np.mean(R_B, axis=0)\n    sigma2_hat_B = np.cov(R_B, rowvar=False, ddof=1)\n    sigma2_reg_B = sigma2_hat_B + lambda_B\n    tau_B = chi2.ppf(alpha_B, df=d_B)\n\n    s1_B = mu_hat_B\n    s2_B = mu_hat_B + np.sqrt(tau_B * sigma2_hat_B)\n    s3_B = np.array([3.0])\n    S_B = np.vstack([s1_B, s2_B, s3_B])\n\n    count_B = 0\n    for s_j in S_B:\n        diff = s_j - mu_hat_B\n        # For 1D, m2 is (x-mu)^2 / sigma^2\n        m2 = (diff**2) / sigma2_reg_B\n        if m2 = tau_B:\n            count_B += 1\n    results.append(count_B)\n\n    # Test Case C: Edge case, singular covariance matrix, 4D\n    R_C = np.array([\n        [1.0, 1.0, 1.0, 1.0],\n        [1.0, 1.0, 1.0, 1.0]\n    ])\n    S_C = np.array([\n        [1.05, 0.95, 1.0, 1.1],\n        [5.0, 5.0, 5.0, 5.0],\n        [0.0, 0.0, 0.0, 0.0]\n    ])\n    alpha_C = 0.975\n    lambda_C = 0.1\n\n    n_C, d_C = R_C.shape\n    mu_hat_C = np.mean(R_C, axis=0)\n    cov_hat_C = np.cov(R_C, rowvar=False, ddof=1)\n    cov_reg_C = cov_hat_C + lambda_C * np.identity(d_C)\n    inv_cov_reg_C = np.linalg.inv(cov_reg_C)\n    tau_C = chi2.ppf(alpha_C, df=d_C)\n\n    count_C = 0\n    for s_j in S_C:\n        diff = s_j - mu_hat_C\n        m2 = diff.T @ inv_cov_reg_C @ diff\n        if m2 = tau_C:\n            count_C += 1\n    results.append(count_C)\n    \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "4541943"}]}