## 引言
在现代医疗信息学领域，如何将海量的电子健康记录（EHR）数据转化为有意义的临床洞见，是一个核心挑战。计算表型分析（Computational Phenotyping）正是应对这一挑战的关键技术，它致力于通过算法从复杂、异构的观测数据中精确地识别和定义患者的临床状态或特征（即“表型”）。然而，原始EHR数据与患者真实的临床真相之间存在着巨大的鸿沟，这源于数据的非结构化特性、记录偏差和内在噪声。本文旨在系统性地填补这一知识鸿沟，为读者提供一个从理论到实践的完整学习路径。

在接下来的内容中，您将踏上一段深入的探索之旅。第一章**“原理与机制”**将为您奠定坚实的理论基础，详细阐述计算表型分析的核心任务、数据源、方法论以及评估标准。随后，第二章**“应用与跨学科交叉”**将通过丰富的实例，展示这些技术如何在临床研究、遗传学、公共卫生等领域发挥巨大作用，并揭示其与多学科的深刻联系。最后，在**“动手实践”**部分，您将有机会通过解决具体问题，将所学知识付诸实践，巩固并深化您的理解。

## 原理与机制

本章旨在系统性阐述计算表型分析的核心原理与关键机制。我们将从计算表型分析的基本定义出发，逐步深入探讨其研究所依赖的数据源、构建“金标准”的方法论、核心算法范式、处理复杂[时序数据](@entry_id:636380)的设计原则，以及评估和部署表型算法时的关键考量。本章内容将为读者构建一个完整且严谨的知识框架，以应对在真实世界电子健康记录（EHR）数据中定义和识别人类可观测表型的挑战。

### 计算表型分析的核心任务：定义与辨析

计算表型分析的根本目标，是从充满噪声、异构且非结构化的观测性健康数据（如电子健康记录）中，推断出患者真实、潜在的临床状态。这项任务在本质上是一个[测量问题](@entry_id:189139)：我们如何利用可观测的数据（$X$）来精确测量一个不可观测的潜在变量（$Z$）。

为了更精确地理解其内涵，我们必须将其与医学信息学中其他几个相关但截然不同的任务进行区分 [@problem_id:4829815]。假设对于患者 $i$，我们在时间 $t$ 之前拥有一个高维、带时间戳的特征向量 $X_{i,t}$（例如，ICD编码、实验室检查值、临床文本记录）。我们关注的目标包括：

1.  **潜在疾病状态（表型） $Z_{i,t} \in \{0,1\}$**：代表在时间 $t$ 或之前，患者是否真实地处于某个目标疾病状态（例如，符合研究定义的当前或历史疾病）。这是一个**潜在变量**。
2.  **未来临床事件 $Y_{i,t+\Delta} \in \{0,1\}$**：代表在未来某个时间窗口 $\Delta > 0$ 内是否会发生某个临床事件（例如，在 $\Delta$ 天内住院）。

基于此，我们可以辨析以下四项任务：

-   **计算表型分析（Computational Phenotyping）**：其认知目标是推断患者**当前或历史**的潜在疾病状态 $Z_{i,t}$。这通常通过[概率建模](@entry_id:168598)或机器学习方法，从不完美的观测数据 $X_{i,t}$ 中学习后验概率 $P(Z_{i,t}=1 \mid X_{i,t})$ 或其确定性代理。这是一项在**个体患者层面**进行的**状态推断**任务。

-   **临床风险预测（Clinical Risk Prediction）**：其认知目标是预测**未来**将要发生的临床事件 $Y_{i,t+\Delta}$。它利用当前数据 $X_{i,t}$ 来估计[预测分布](@entry_id:165741) $P(Y_{i,t+\Delta}=1 \mid X_{i,t})$。虽然同样在个体患者层面进行，但其关注点是**未来事件的预测**，而非当前状态的推断。

-   **疾病监测（Disease Surveillance）**：其认知目标是估计**群体层面**的疾病参数，如特定时间 $t$ 的患病率 $\pi_t = P(Z_t=1)$ 或发病率 $\lambda_t$。它不关注单个患者的 $Z_{i,t}$，而是通过聚合个体数据来理解疾病在人口中的动态。这是一项在**群体层面**进行的**[参数估计](@entry_id:139349)**任务。

-   **病例注册库构建（Registry Ascertainment）**：其目标是设计一个纳入规则 $r(X_{i,t}) \in \{0,1\}$，以构建一个用于特定研究的队列。这项任务的重点是优化队列的操作特性，如在资源和验证成本的约束下，平衡阳性预测值（PPV, $P(Z_{i,t}=1 \mid r(X_{i,t})=1)$）和灵敏度（Se, $P(r(X_{i,t})=1 \mid Z_{i,t}=1)$）。这是一个**队列设计**或工程任务，其目标是优化规则的性能，而不是为每个患者估计疾病概率。

总之，计算表型分析的独特性在于其致力于通过算法手段，从复杂、间接的观测数据中，为每个个体还原一个更接近临床真实的、关于当前或历史健康状态的标签。

### 表型分析的原始材料：理解电子健康记录数据

构建任何表型算法的第一步是深刻理解其输入——电子健康记录（EHR）数据。EHR数据来源多样，每种数据类型（或称“模态”）都具有独特的信息粒度和典型的错误模式，这对[算法设计](@entry_id:634229)至关重要 [@problem_id:4829809]。

-   **结构化数据（Structured Data）**：
    -   **诊断编码（Conditions）**：使用国际疾病分类（ICD）或SNOMED CT等标准术语记录。它们通常是为计费或问题列表生成的分类抽象，信息粒度较低。其主要错误模式源于计费驱动的行为，如**向上编码（upcoding）**以获取更高补偿，或**记录不足（under-documentation）**。
    -   **实验室检查（Labs）**：使用LOINC等标准编码。这[类数](@entry_id:156164)据通常是带时间戳的数值型测量结果（如[糖化血红蛋白](@entry_id:150571)HbA1c值），信息粒度高。其错误模式主要包括分析和生物学变异，以及将连续值转换为二元标签时引入的**阈值误差**（例如，定义HbA1c $\ge 6.5\%$ 为阳性信号）。
    -   **药物处方（Medications）**：使用RxNorm等标准编码。它们反映了患者对特定成分、剂量和给药途径的暴露，但开具处方的**适应证（indication）**是推断出来的，可能存在**适应证混淆（confounding by indication）**（例如，某个药物也用于治疗其他疾病）或**标签外用药（off-label use）**的情况。
    -   **操作/程序编码（Procedures）**：使用CPT等标准编码。它们代表了特定的、有时间限定的医疗行为，通常与计费高度相关，因此特异性很高。但对于慢性病管理教育等事件，其发生频率可能很低，导致数据**稀疏（sparse）**。

-   **非结构化数据（Unstructured Data）**：
    -   **临床文本记录（Clinical Notes）**：如病程记录、出院小结等。它们包含最丰富、最细致的上下文信息，例如**时态**（“有...病史” vs “否认...症状”）、**严重程度**和**家族史**。然而，从中提取信息需要依赖自然语言处理（NLP）技术，这会引入其特有的**提取错误**，如对**否定词**（negation）或时态的误判。

理解这些数据源的特性是构建稳健表型算法的前提。例如，一个旨在最大化阳性预测值（PPV）的规则型表型，可能会选择联合使用两个高特异性的信号。假设我们有两个信号：诊断编码（灵敏度$Se_1=0.85$, 特异性$Sp_1=0.90$）和[HbA1c](@entry_id:150571)实验室检查（$Se_2=0.75$, $Sp_2=0.98$）。在条件独立假设下，将它们用逻辑“与”（AND）组合，会得到一个特异性极高的新信号（$Sp_{AND} = 1 - (1-Sp_1)(1-Sp_2) = 1 - (0.10)(0.02) = 0.998$），这通常能显著提升PPV，尽管会牺牲一部分灵敏度（$Se_{AND} = Se_1 \cdot Se_2 = 0.85 \cdot 0.75 = 0.6375$）。

### 构建“金标准”：人工标注与评估者间信度

无论是为了训练监督学习模型还是为了评估表型算法的性能，我们都需要一个“金标准”（ground truth）或[参考标准](@entry_id:754189)。在计算表型分析中，这通常是通过组织领域专家（即评估者或标注员）对患者的完整病历进行人工审阅来创建的。然而，人类的判断并非绝对一致，因此，量化和提升评估者之间的一致性至关重要 [@problem_id:4829960]。这一致性被称为**评估者间信度（Inter-Rater Reliability, IRR）**。

#### 核心IRR指标

两个最常用的IRR指标是Cohen's Kappa和Krippendorff's Alpha，它们都通过校正机遇一致性（chance agreement）来衡量真实的一致性水平。

-   **Cohen's Kappa ($\kappa$)**：用于衡量**两个**评估者对名义类别（nominal categories）进行分类时的一致性。其公式为：
    $$ \kappa = \frac{p_o - p_e}{1 - p_e} $$
    其中，$p_o$ 是观察到的一致[性比](@entry_id:172643)例（即两位评估者给出相同标签的样本比例），$p_e$ 是机遇导致的一致[性比](@entry_id:172643)例，计算方式为两位评估者各自对每个类别判断的[边际概率](@entry_id:201078)之积的和。

    例如，假设两位评估者A和B对10份病历进行分类（类别为阳性P、阴性N、不确定U），结果是：P/P 3例，N/N 2例，U/U 1例，以及P/N、P/U、N/U、U/N各1例。观察到的一致性为 $p_o = (3+2+1)/10 = 0.6$。根据各自的标注分布（A：5P, 3N, 2U；B：3P, 4N, 3U），计算出的机遇一致性为 $p_e = (\frac{5}{10}\cdot\frac{3}{10}) + (\frac{3}{10}\cdot\frac{4}{10}) + (\frac{2}{10}\cdot\frac{3}{10}) = 0.15 + 0.12 + 0.06 = 0.33$。因此，$\kappa \approx \frac{0.6 - 0.33}{1 - 0.33} \approx 0.403$。

-   **Krippendorff's Alpha ($\alpha$)**：这是一个更通用的指标，适用于任意数量的评估者、允许数据缺失，并且可以处理名义、有序、区间或比率等不同类型的数据。对于名义类别，其公式为：
    $$ \alpha = 1 - \frac{D_o}{D_e} $$
    其中，$D_o$ 是观察到的不一致性，定义为所有可比较的成对判断中意见不一致的比例。$D_e$ 是预期的机遇不一致性，基于所有标签的总体分布计算得出。$\alpha$ 能够优雅地处理缺失值，因为它只在有多个评分的样本内部计算成对比较。

#### 提升IRR的实践策略

一个低IRR值通常表明标注指南不明确或评估者理解不一致。提升IRR并保证标注质量的有效策略包括：
1.  **制定详尽的标注指南（Codebook）**：提供明确的操作化定义、纳入和排除标准，并附有典型的正例、反例和边界案例（anchored examples）。
2.  **开展校准试验（Calibration Rounds）**：在正式标注前，所有评估者对一小批样本进行试标注，然后召开共识会议，讨论并解决[分歧](@entry_id:193119)，以统一对指南的理解并修订模糊之处。
3.  **分析混淆点**：识别最常引起[分歧](@entry_id:193119)的类别或病例特征，并进行针对性再培训。
4.  **持续监控与仲裁**：在标注过程中定期计算IRR，并设立一个停止规则。对于存在[分歧](@entry_id:193119)的案例，通过独立双重标注和高级专家仲裁来达成最终一致的标签。
5.  **允许明确的弃权**：在指南中明确规定何时可以标注为“不确定”或“信息不足”（即缺失值），以避免强迫评估者进行猜测，从而引入噪声。

### 表型构建方法论：从规则到学习

一旦我们对数据和金标准有了清晰的认识，就可以开始构建表型算法。主要方法可分为三类：基于规则的系统、监督式机器学习和[弱监督](@entry_id:176812)方法。

#### 基于规则的表型分析

这是最传统也最透明的方法 [@problem_id:4829820]。一个**基于规则的表型（rule-based phenotype）**是通过一个[布尔逻辑](@entry_id:143377)公式 $\phi$ 来定义的。这个公式作用于一系列**谓词（predicates）** $p_i$ 之上，每个谓词用于检测患者记录中是否存在某个标准化的临床概念（如来自SNOMED CT或LOINC的特定编码），并可能附加时间或计数约束。最终的表型决策 $f(r)$ 就是将患者记录 $r$ 的谓词评估结果代入公式 $\phi$ 得到的值。

这种方法具有以下鲜明特点：
-   **[可解释性](@entry_id:637759)（Interpretability）**：由于规则由人类可读的临床概念和[逻辑连接词](@entry_id:146395)（与、或、非）构成，其决策路径完全透明，易于临床医生理解和验证。
-   **可移植性（Portability）**：使用标准化的词汇表和通用数据模型（如OMOP CDM）可以极大地[提升算法](@entry_id:635795)在不同医疗机构间的可移植性。然而，由于各机构特有的编码习惯、数据捕获流程差异以及映射差距，可移植性并非总能得到保证。
-   **脆弱性（Brittleness）**：规则系统，尤其是包含许多“与”（AND）条件的**合取规则**，表现得非常脆弱。任何一个条件的谓词因数据缺失或编码的微小变化而评估为假，都将导致整个规则判定为假，从而产生假阴性。

#### 监督式机器学习

随着机器学习技术的发展，**监督式表型分析（supervised phenotyping）**变得越来越普遍 [@problem_id:4829925]。该方法将表型分析任务形式化为一个标准的分类问题：从一组带标签的样本 $(X_i, \tilde{Y}_i)$ 中学习一个分类器 $f: \mathcal{X} \to \{0,1\}$，其中 $X_i$ 是患者的特征向量，$\tilde{Y}_i$ 是观察到的标签（通常来自人工病历审阅）。

学习过程通常遵循**[经验风险最小化](@entry_id:633880)（Empirical Risk Minimization, ERM）**原则，即寻找一个分类器 $f_n$ 来最小化在训练集上的[经验风险](@entry_id:633993)（或平均损失） $\hat{R}_n(f) = \frac{1}{n}\sum_{i=1}^{n}\ell(f(X_i), \tilde{Y}_i)$。

然而，EHR数据中的标签 $\tilde{Y}$ 往往是带噪声的，它们并不完[全等](@entry_id:194418)同于真实的临床状态 $Y$。一个核心的理论问题是：在存在[标签噪声](@entry_id:636605)的情况下，ERM能否学到一个对“干净”标签 $Y$ 有效的分类器？理论研究表明，这在特定假设下是可能的：
-   **类别条件噪声（Class-Conditional Noise, CCN）**：假设标签被错误标注的概率只依赖于其真实类别，而与特征 $X$ 无关。即 $P(\tilde{Y} \neq Y \mid Y, X)$ 是一个常数。在这种情况下，通过使用**噪声容忍的[损失函数](@entry_id:136784)**或对风险进行**校正**，可以使得最小化带噪风险等价于最小化干净风险。
-   **对称噪声（Symmetric Noise）**：这是一个更简单的特例，其中正类和负类标签以相同的概率 $\rho  0.5$ 被翻转。在这种情况下，可以证明，带噪数据的[贝叶斯最优分类器](@entry_id:164732)与干净数据的[贝叶斯最优分类器](@entry_id:164732)是相同的。因此，一个能够学习带噪数据最优分类器的算法，也就能学习到干净数据的最优分类器。

#### [弱监督](@entry_id:176812)方法

当获取大量人工标注的“金标准”标签成本过高时，**[弱监督](@entry_id:176812)（weak supervision）**提供了一种强大的替代方案 [@problem_id:4829829]。其核心思想是，利用领域专家的知识来编写多个**标签函数（Labeling Functions, LFs）** $\lambda_j$。每个标签函数都是一个程序化的[启发式](@entry_id:261307)规则，它会检查EHR中的原始数据（如ICD编码、药物处方）并输出一个标签（例如，$+1$表示阳性，$-1$表示阴性），或者在无法判断时选择**弃权（abstain）**（输出$0$）。

这些标签函数是“弱”的，因为它们可能不准确、相互冲突并且覆盖范围有限。[弱监督](@entry_id:176812)的关键在于，使用一个**生成式标签模型（generative label model）**来系统性地整合这些嘈杂、重叠的信号。该模型将真实标签 $Y$ 视为一个潜在变量，并通过分析标签函数在大量未标注数据上的协变关系，来估计每个标签函数的准确率和相关性。

在给定新患者时，该模型利用贝叶斯定理，结合所有标签函数的输出和学习到的准确率参数，来计算该患者真实标签的后验概率 $P(Y \mid \lambda_1, \dots, \lambda_k)$。这个后验概率随后可以作为“软标签”来训练一个下游的强分类器。

例如，假设我们有三个独立的标签函数，其输出为 $\lambda_1=+1, \lambda_2=0, \lambda_3=+1$。生成式模型会计算后验概率：
$$ P(Y=+1 \mid \Lambda) = \frac{P(\Lambda \mid Y=+1) P(Y=+1)}{P(\Lambda \mid Y=+1) P(Y=+1) + P(\Lambda \mid Y=-1) P(Y=-1)} $$
其中，$\Lambda$ 是标签函数输出向量，似然项 $P(\Lambda \mid Y)$ 在条件独立假设下可分解为 $P(\lambda_1 \mid Y)P(\lambda_2 \mid Y)P(\lambda_3 \mid Y)$。这个过程巧妙地将多个不完美的专家规则融合成了一个统一的概率性标签。

### 精准设计的关键：时序维度

EHR数据的核心特征之一是其纵向性或时序性。如何处理时间维度是表型[算法设计](@entry_id:634229)中至关重要的一环，它直接影响到研究结论的有效性，尤其是当试图提出因果声明时 [@problem_id:4829754]。

三个核心概念构成了时序设计的基础：
1.  **事件对齐（Event Alignment）**：将所有患者的时间线对齐到一个共同的**锚点事件（index event）**，例如首次疾病诊断时间 $\tau_i$。这确保了不同患者之间的可比性。
2.  **时序窗口（Temporal Windows）**：在对齐的时间线上定义用于衡量暴露（exposure）和结局（outcome）的特定时间区间，如 $[ \tau_i - a, \tau_i + b)$。
3.  **聚合函数（Aggregation Functions）**：将窗口内随时间变化的多个数据点（如多次用药记录）总结成一个固定的特征（如“窗口内是否曾用药”的指示变量）。

时序窗口的选择对结论的认知地位（epistemic status）具有决定性影响。一个基本原则是**时间优先（temporal precedence）**：原因必须发生在结果之前。因此，对于因果推断，暴露窗口必须严格地在结局观察窗口**之前**结束。

让我们通过一个研究非[甾体](@entry_id:146569)抗炎药（NSAID）暴露与急性肾损伤（AKI）结局之间关系的假想场景来说明这一点。结局窗口定义为高血压首次诊断（$\tau_i$）后的180天内，即 $[\tau_i, \tau_i+180]$。我们比较两种暴露窗口设计：
-   **设计A（事前窗口）**：暴露窗口为 $[\tau_i - 180, \tau_i)$。此设计严格遵守了时间优先原则。计算出的风险比（Risk Ratio）为 $2.0$，表明暴露与风险增加相关。
-   **设计B（围期窗口）**：暴露窗口为 $[\tau_i - 30, \tau_i + 30]$。此窗口与结局窗口在 $[\tau_i, \tau_i + 30]$ 区间重叠。计算出的风险比约为 $0.53$，表明暴露具有保护作用。

这种截然相反的结论源于设计B中的严重时序偏倚：
-   **反向因果（Reverse Causality）**：患者可能在 $\tau_i$ 之后不久出现AKI的早期症状，医生因此**避免**开具NSAID。这会导致正在发病的患者被错误地归入“未暴露组”，从而人为地降低了“暴露组”的风险。
-   **永生时间偏倚（Immortal Time Bias）**：要被定义为在 $\tau_i$ 之后暴露，患者必须“存活”到那个时间点而没有发生结局。这段“永生”的时间被错误地归因于暴露组，使得暴露组看起来比未暴露组更健康。

因此，不恰当的时序设计会产生完全错误的结论。设计A虽然不能完全排除所有混杂因素，但它为提出一个更可信的关联性甚至（在满足额外假设下）因果性声明提供了基本前提。而设计B的结论充其量是一个带有严重偏倚的关联，不具备因果解释力。

### 算法的评估与部署

一个表型算法在构建完成后，必须经过严格的评估才能部署于实际应用。评估和部署阶段有两个核心议题：模型性能的全面理解，以及算法在不同环境下的可移植性。

#### 性能度量：区分度与校准度

评估一个输出概率分数的表型模型时，我们必须区分两个重要的性能维度：**区分度（Discrimination）**和**校准度（Calibration）** [@problem_id:4829953]。

-   **区分度**：指模型将阳性样本和阴性样本正确分开的能力，即模型对患者进行风险排序的能力。最常用的度量是**受试者工作特征曲线下面积（[AUROC](@entry_id:636693)）**。一个高[AUROC](@entry_id:636693)值意味着模型能有效地将高风险患者排在低风险患者前面。区分度只关心排序，对分数的绝对值不敏感。

-   **校准度**：指模型的预测概率在多大程度上反映了真实的事件发生频率。一个完美校准的模型，其预测概率为 $p$ 的所有患者中，真实阳性病例的比例也恰好是 $p$。即 $\mathbb{E}[Y \mid \hat{p}=p] = p$。

在许多实际应用中，校准度至关重要。例如，一个医院计划根据模型分数对患者进行排序，并手动审阅分数最高的 $M$ 份病历。如果医院的资源规划（如人员配置、预算）是基于这 $M$ 位患者预测概率的总和（即预期的阳性病例数）来制定的，那么一个未校准的模型将导致严重的资源错配。

考虑一个场景，一个模型的区分度很高，但其概率输出存在系统性偏差，其真实概率与预测概率 $\hat{p}$ 之间的关系为 $\mathbb{E}[Y \mid \hat{p}=p] = 0.02 + 0.80p$。假设在需要审阅的1000名患者中，平均预测概率为 $\bar{p}=0.60$。天真的预期阳性病例数将是 $1000 \times 0.60 = 600$。然而，考虑到校准度偏差，真实的预期阳性病例数是 $\sum (\alpha + \beta \hat{p}_i) = M\alpha + \beta M\bar{p} = 1000 \times 0.02 + 0.80 \times (1000 \times 0.60) = 20 + 480 = 500$。这100例的巨大差距表明，仅有良好的区分度不足以支持运营决策；良好的校准度对于准确的**产出估算（yield estimation）**和资源配置是必不可少的。

#### 可移植性与标准化

在单个医疗机构成功开发的表型算法，能否直接应用于另一家机构？这个问题引出了**可移植性（transportability）**或**泛化性**的概念 [@problem_id:4829941]。当一个在源域（机构S）训练的算法被部署到目标域（机构T）时，其性能往往会下降。这种现象由**域移（domain shift）**导致，即源域和目标域的数据分布 $P(x,y)$ 不同。

域移的主要来源包括：
-   **协变量移位（Covariate Shift）**：输入特征的分布 $P(x)$ 发生变化。例如，不同机构使用不同的编码系统（如ICD-9 vs ICD-10），或者数据的**完整性**不同（如实验室数据缺失率从10%上升到50%），都会改变特征向量的分布。
-   **[先验概率](@entry_id:275634)移位（Prior Probability Shift）**：类别标签的分布 $P(y)$ 发生变化。例如，由于目标机构的患者人群更年轻，疾病的**患病率（prevalence）**从30%下降到10%。

即使算法的内在性能（即对真实临床状态的灵敏度和特异性）保持不变，[先验概率](@entry_id:275634)的移位也会严重影响其在应用中的表观性能，尤其是阳性预测值（PPV）。PPV的计算公式为：
$$ \text{PPV} = \frac{(\text{Sens})(\pi)}{(\text{Sens})(\pi) + (1 - \text{Spec})(1 - \pi)} $$
其中 $\pi$ 是患病率。从此公式可见，PPV对患病率高度敏感。在一个患病率较低的人群中，即使是高特异性的测试，其PPV也会显著下降。这就是为什么一个在某机构表现优异的算法，到另一家机构可能会产生大量[假阳性](@entry_id:635878)预测。

解决可移植性挑战的根本途径是**标准化（Standardization）** [@problem_id:4829898]。通过将不同机构的本地[异构数据](@entry_id:265660)，通过**提取-转换-加载（ETL）**过程，映射到一个共同的表示形式上，可以使得同一个算法在不同地点操作于语义一致的数据之上，从而实现可复现和可移植的分析。
-   **OMOP通用数据模型（OMOP Common Data Model, CDM）**：通过提供一个标准化的[关系型数据库](@entry_id:275066)模式（如person, condition_occurrence, drug_exposure等表）和一套标准化的概念词汇表（集成了SNOMED CT, LOINC, RxNorm等），实现了数据在**结构**和**语义**两个层面的统一。
-   **快速医疗保健[互操作性](@entry_id:750761)资源（FHIR）**：则为实时、API驱动的医疗数据**交换**定义了标准化的资源模型（如Observation, Condition, MedicationRequest等）。

通过采用这些标准，研究人员可以编写一次表型算法，并在一个由多个遵循相同标准的机构组成的网络中运行，从而极大地提升了医学信息学研究的规模和影响力。