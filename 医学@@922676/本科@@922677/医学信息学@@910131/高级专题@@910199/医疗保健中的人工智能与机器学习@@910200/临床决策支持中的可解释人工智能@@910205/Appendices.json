{"hands_on_practices": [{"introduction": "理解可解释人工智能（XAI）方法的最佳途径之一是从基本原理入手进行实践。此练习将引导您完成一个基础但至关重要的任务：为一个简单的线性模型手动计算 SHAP (SHapley Additive exPlanations) 值。通过将合作博弈论中的夏普利值（Shapley value）定义直接应用于一个具体的临床决策支持系统（CDSS）场景，您将深入理解 SHAP 如何公平地将模型的预测贡献归因于各个特征，为使用更复杂的 XAI 工具库打下坚实的概念基础。[@problem_id:4419874]", "problem": "一家医院部署了一个临床决策支持系统 (CDSS)，该系统使用一个双特征线性模型来计算脓毒症风险评分。根据医学伦理指南，为了进行安全审计，该模型必须向临床医生解释。该模型由 $f(x)=w_{1}x_{1}+w_{2}x_{2}+b$ 给出，其中 $x=(x_{1},x_{2})$ 是标准化的患者特征，因此零向量是一个有意义的参考。解释方法是 SHapley 加性解释 (SHAP)，通过合作博弈论的 Shapley 值来实现，并将基线输入设置为零向量。考虑一个特定患者，其特征为 $x_{1}=1.5$，$x_{2}=-0.5$，模型参数为 $w_{1}=2$，$w_{2}=-3$，$b=1$。\n\n仅使用合作博弈论中 Shapley 值的核心定义，以及 SHAP 值的定义（即当缺失特征被设置为其基线值时，一个特征在所有联盟上的期望边际贡献），计算实例 $x=(x_{1},x_{2})$ 的精确 SHAP 值 $\\phi_{1}$ 和 $\\phi_{2}$。然后，通过将归因值相加并与相对于基线的模型输出差异 $f(x)-f(0)$ 进行比较，来验证效率特性。最后，计算标量差异\n$$D=\\left(\\phi_{1}+\\phi_{2}\\right)-\\left(f(x)-f(0)\\right).$$\n将 $D$ 表示为一个精确数（无需四舍五入）。不需要单位。", "solution": "用户提供了一个问题，要求为一个双特征线性模型计算 SHapley 加性解释 (SHAP) 值。该问题定义明确，在合作博弈论和可解释性人工智能领域有科学依据。所有必要的参数和定义都已提供。该问题被认为是有效的。\n\n该模型是两个特征 $x_1$ 和 $x_2$ 的线性函数：\n$$f(x) = f(x_1, x_2) = w_1 x_1 + w_2 x_2 + b$$\n给定的参数为 $w_1 = 2$，$w_2 = -3$ 和 $b = 1$。特定的患者实例由特征向量 $x = (x_1, x_2) = (1.5, -0.5)$ 给出。\n\nSHAP 值是使用合作博弈论中的 Shapley 值定义的。这个博弈中的“参与者”是特征，$N = \\{1, 2\\}$。特征联盟 $S \\subseteq N$ 的“值”是当 $S$ 中的特征设置为实例 $x$ 的实际值，而不在 $S$ 中的特征设置为其基线值时的模型输出。问题指出基线是零向量，因此任何缺失的特征 $x_i$ 都被设置为 $0$。\n\n因此，值函数 $v(S)$ 被定义为模型输出 $f(x')$，其中如果 $i \\in S$，则 $x'_i = x_i$；如果 $i \\notin S$，则 $x'_i = 0$。让我们计算所有可能联盟的值：\n\\begin{itemize}\n    \\item 对于空联盟 $S = \\emptyset$：两个特征都处于其基线值 ($0$)。\n    $$v(\\emptyset) = f(0, 0) = w_1(0) + w_2(0) + b = b = 1$$\n    \\item 对于联盟 $S = \\{1\\}$：特征 $x_1$ 存在，$x_2$ 处于基线值。\n    $$v(\\{1\\}) = f(x_1, 0) = w_1 x_1 + w_2(0) + b = w_1(1.5) + b = 2(1.5) + 1 = 3 + 1 = 4$$\n    \\item 对于联盟 $S = \\{2\\}$：特征 $x_2$ 存在，$x_1$ 处于基线值。\n    $$v(\\{2\\}) = f(0, x_2) = w_1(0) + w_2 x_2 + b = w_2(-0.5) + b = (-3)(-0.5) + 1 = 1.5 + 1 = 2.5$$\n    \\item 对于大联盟 $S = \\{1, 2\\}$：两个特征都存在。\n    $$v(\\{1, 2\\}) = f(x_1, x_2) = w_1 x_1 + w_2 x_2 + b = 2(1.5) + (-3)(-0.5) + 1 = 3 + 1.5 + 1 = 5.5$$\n\\end{itemize}\n\n在一个有 $n$ 个参与者的博弈中，特征 $i$ 的 Shapley 值 $\\phi_i$ 被定义为其对所有可能联盟的边际贡献的加权平均值：\n$$\\phi_i = \\sum_{S \\subseteq N \\setminus \\{i\\}} \\frac{|S|!(n - |S| - 1)!}{n!} [v(S \\cup \\{i\\}) - v(S)]$$\n在我们的例子中，$n=2$，所以公式简化了。\n\n首先，我们计算特征 1 的 SHAP 值 $\\phi_1$。联盟 $S \\subseteq N \\setminus \\{1\\}$ 为 $S = \\emptyset$ 和 $S = \\{2\\}$。\n对于 $S = \\emptyset$：$|S|=0$。权重因子是 $\\frac{0!(2-0-1)!}{2!} = \\frac{1 \\cdot 1}{2} = \\frac{1}{2}$。边际贡献是 $v(\\{1\\}) - v(\\emptyset)$。\n对于 $S = \\{2\\}$：$|S|=1$。权重因子是 $\\frac{1!(2-1-1)!}{2!} = \\frac{1 \\cdot 0!}{2} = \\frac{1}{2}$。边际贡献是 $v(\\{1, 2\\}) - v(\\{2\\})$。\n将这些贡献相加得到 $\\phi_1$：\n$$\\phi_1 = \\frac{1}{2} [v(\\{1\\}) - v(\\emptyset)] + \\frac{1}{2} [v(\\{1, 2\\}) - v(\\{2\\})]$$\n代入计算出的值：\n$$\\phi_1 = \\frac{1}{2} [4 - 1] + \\frac{1}{2} [5.5 - 2.5] = \\frac{1}{2}(3) + \\frac{1}{2}(3) = 1.5 + 1.5 = 3$$\n\n接下来，我们计算特征 2 的 SHAP 值 $\\phi_2$。联盟 $S \\subseteq N \\setminus \\{2\\}$ 为 $S = \\emptyset$ 和 $S = \\{1\\}$。\n对于 $S = \\emptyset$：$|S|=0$。权重因子是 $\\frac{0!(2-0-1)!}{2!} = \\frac{1}{2}$。边际贡献是 $v(\\{2\\}) - v(\\emptyset)$。\n对于 $S = \\{1\\}$：$|S|=1$。权重因子是 $\\frac{1!(2-1-1)!}{2!} = \\frac{1}{2}$。边际贡献是 $v(\\{1, 2\\}) - v(\\{1\\})$。\n将这些贡献相加得到 $\\phi_2$：\n$$\\phi_2 = \\frac{1}{2} [v(\\{2\\}) - v(\\emptyset)] + \\frac{1}{2} [v(\\{1, 2\\}) - v(\\{1\\})]$$\n代入计算出的值：\n$$\\phi_2 = \\frac{1}{2} [2.5 - 1] + \\frac{1}{2} [5.5 - 4] = \\frac{1}{2}(1.5) + \\frac{1}{2}(1.5) = 0.75 + 0.75 = 1.5$$\n因此，SHAP 值为 $\\phi_1 = 3$ 和 $\\phi_2 = 1.5$。线性模型的一个已知属性是 $\\phi_i = w_i x_i$。我们来验证一下：$\\phi_1 = w_1 x_1 = 2(1.5) = 3$ 和 $\\phi_2 = w_2 x_2 = (-3)(-0.5) = 1.5$。我们使用基本定义进行的计算与此属性一致。\n\n下一步是验证效率特性，该特性指出 SHAP 值的总和等于给定实例的模型输出与基线输出之间的差：$\\phi_1 + \\phi_2 = f(x) - f(0)$。\nSHAP 值的总和是：\n$$\\phi_1 + \\phi_2 = 3 + 1.5 = 4.5$$\n模型输出的差异是：\n$$f(x) - f(0) = f(1.5, -0.5) - f(0, 0)$$\n我们已经将这些值计算为 $v(\\{1, 2\\})$ 和 $v(\\emptyset)$：\n$$f(x) - f(0) = 5.5 - 1 = 4.5$$\n由于 $4.5 = 4.5$，效率特性得到验证。\n\n最后，我们计算标量差异 $D$：\n$$D = (\\phi_1 + \\phi_2) - (f(x) - f(0))$$\n使用我们刚刚计算出的值：\n$$D = 4.5 - 4.5 = 0$$\n差异为零，这与 Shapley 值的效率特性所预期的一致。", "answer": "$$\n\\boxed{0}\n$$", "id": "4419874"}, {"introduction": "除了基于博弈论的 SHAP，另一类重要的归因方法是基于梯度。积分梯度（Integrated Gradients, IG）是其中的代表，它通过累积模型输入从基线到目标实例路径上的梯度来分配特征重要性。本练习将通过一个简化的非线性模型——修正线性单元（ReLU）网络，来帮助您从头计算积分梯度。这个过程不仅能阐明 IG 的数学核心，还能让您验证其关键的“完备性”公理，即所有特征的归因值之和恰好等于模型输出与基线输出之差。[@problem_id:4419848]", "problem": "在一个临床决策支持（CDS）场景下，一个简化的仅用于审计的模型被用来对来自两个标准化实验室特征的二元风险警报进行分流。为了确保符合医学伦理和人工智能（AI）安全规范的问责制，该系统必须通过积分梯度（Integrated Gradients, IG）提供解释。考虑模型 $f(x)=\\max(0,w^\\top x)$，其中 $x\\in\\mathbb{R}^2$ 是两个输入特征，$w\\in\\mathbb{R}^2$ 是固定权重。这是一个带单个线性预激活的修正线性单元（Rectified Linear Unit, ReLU）输出层。基线是 $x'=\\mathbf{0}$。假设临床输入 $x$ 位于激活区域，即 $w^\\top x0$。仅使用积分梯度的定义以及ReLU和线积分的性质，计算输入 $x$ 相对于基线 $x'$ 的积分梯度归因向量，并将其表示为 $w_1,w_2,x_1,x_2$ 的闭式解函数。然后，从第一性原理出发，验证该归因对于此模型和基线满足完备性属性。请将最终的归因向量以单行矩阵的形式给出。无需四舍五入。", "solution": "该问题是有效的，因为它在科学上基于可解释人工智能的原理，问题陈述清晰且提供了所有必要信息，并且可以用数学形式化。我们开始解题。\n\n对于输入向量 $x \\in \\mathbb{R}^n$ 中的第 $i$ 个特征 $x_i$，其相对于基线 $x' \\in \\mathbb{R}^n$ 的积分梯度（IG）归因定义为：\n$$IG_i(x) = (x_i - x'_i) \\int_{\\alpha=0}^{1} \\frac{\\partial f(x' + \\alpha(x - x'))}{\\partial x_i} \\, d\\alpha$$\n其中 $f$ 是模型函数。\n\n在本问题中，我们已知：\n- 模型：$f(x) = \\max(0, w^\\top x)$，其中 $x = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}$ 且 $w = \\begin{pmatrix} w_1 \\\\ w_2 \\end{pmatrix}$。\n- 输入 $x \\in \\mathbb{R}^2$。\n- 基线 $x' = \\mathbf{0} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$。\n- 输入位于ReLU的激活区域的条件，即 $w^\\top x = w_1 x_1 + w_2 x_2  0$。\n\n首先，我们定义积分路径。从基线 $x'$ 到输入 $x$ 的路径是一条由 $\\alpha \\in [0, 1]$ 参数化的直线：\n$$\\gamma(\\alpha) = x' + \\alpha(x - x') = \\mathbf{0} + \\alpha(x - \\mathbf{0}) = \\alpha x$$\n沿此路径计算的函数值为：\n$$f(\\gamma(\\alpha)) = f(\\alpha x) = \\max(0, w^\\top (\\alpha x)) = \\max(0, \\alpha (w^\\top x))$$\n根据条件 $w^\\top x  0$ 且在积分路径上 $\\alpha \\geq 0$，项 $\\alpha (w^\\top x)$ 总是非负的。\n$$ \\alpha (w^\\top x) \\geq 0 \\quad \\text{for } \\alpha \\in [0, 1] $$\n因此，对于路径上的任意点，$\\max$ 函数简化为：\n$$f(\\alpha x) = \\alpha (w^\\top x)$$\n此式对所有 $\\alpha \\in [0, 1]$ 成立。\n\n接下来，我们计算函数 $f$ 关于其参数的偏导数。设参数向量为 $y = \\begin{pmatrix} y_1 \\\\ y_2 \\end{pmatrix}$。函数为 $f(y) = \\max(0, w_1 y_1 + w_2 y_2)$。梯度 $\\nabla f(y)$ 为：\n$$\\frac{\\partial f(y)}{\\partial y_i} = \\frac{\\partial}{\\partial y_i} \\max(0, w^\\top y)$$\n使用链式法则，并注意到 $\\text{ReLU}(u)$ 的导数是亥维赛阶跃函数 $H(u)$（其中当 $u0$ 时 $H(u)=1$，当 $u0$ 时 $H(u)=0$），我们有：\n$$\\frac{\\partial f(y)}{\\partial y_i} = H(w^\\top y) \\cdot \\frac{\\partial}{\\partial y_i}(w^\\top y) = H(w^\\top y) \\cdot w_i$$\n我们需要在我们的积分路径上的点，即 $y = \\alpha x$ 处，计算这个偏导数。亥维赛函数的参数变为 $w^\\top (\\alpha x) = \\alpha (w^\\top x)$。由于 $w^\\top x  0$，对于所有 $\\alpha \\in (0, 1]$，该参数都严格为正。在 $\\alpha=0$ 时，它为 $0$，此时导数未定义。然而，这一个点不影响定积分的值。因此，对于积分域中几乎所有的 $\\alpha$，$H(\\alpha(w^\\top x)) = 1$。\n因此，沿路径计算的偏导数为：\n$$\\frac{\\partial f(\\alpha x)}{\\partial x_i} = w_i \\quad \\text{for } \\alpha \\in (0, 1]$$\nIG公式中的被积函数相对于 $\\alpha$ 是常数。\n\n现在我们计算每个分量 $i=1, 2$ 的IG归因。\n项 $(x_i - x'_i)$ 变为 $(x_i - 0) = x_i$。\n\n对于 $i=1$：\n$$IG_1(x) = (x_1 - 0) \\int_{\\alpha=0}^{1} \\frac{\\partial f(\\alpha x)}{\\partial x_1} \\, d\\alpha = x_1 \\int_{\\alpha=0}^{1} w_1 \\, d\\alpha$$\n$$IG_1(x) = x_1 w_1 \\int_{\\alpha=0}^{1} d\\alpha = x_1 w_1 [\\alpha]_{\\alpha=0}^{\\alpha=1} = x_1 w_1 (1 - 0) = w_1 x_1$$\n\n对于 $i=2$：\n$$IG_2(x) = (x_2 - 0) \\int_{\\alpha=0}^{1} \\frac{\\partial f(\\alpha x)}{\\partial x_2} \\, d\\alpha = x_2 \\int_{\\alpha=0}^{1} w_2 \\, d\\alpha$$\n$$IG_2(x) = x_2 w_2 \\int_{\\alpha=0}^{1} d\\alpha = x_2 w_2 [\\alpha]_{\\alpha=0}^{\\alpha=1} = x_2 w_2 (1 - 0) = w_2 x_2$$\n\n积分梯度归因向量为 $\\begin{pmatrix} IG_1(x)  IG_2(x) \\end{pmatrix} = \\begin{pmatrix} w_1 x_1  w_2 x_2 \\end{pmatrix}$。\n\n任务的第二部分是验证该归因满足完备性属性。完备性属性指出，所有特征归因的总和等于模型在输入 $x$ 处的输出与在基线 $x'$ 处输出之差：\n$$\\sum_{i=1}^{n} IG_i(x) = f(x) - f(x')$$\n在我们的例子中，$n=2$。我们必须验证：\n$$IG_1(x) + IG_2(x) = f(x) - f(x')$$\n\n我们来计算左侧（LHS）：\n$$\\text{LHS} = IG_1(x) + IG_2(x) = w_1 x_1 + w_2 x_2 = w^\\top x$$\n\n现在，我们来计算右侧（RHS）：\n模型在输入 $x$ 处的输出是 $f(x) = \\max(0, w^\\top x)$。根据条件 $w^\\top x  0$，这可以简化为：\n$$f(x) = w^\\top x$$\n模型在基线 $x' = \\mathbf{0}$ 处的输出是：\n$$f(x') = f(\\mathbf{0}) = \\max(0, w^\\top \\mathbf{0}) = \\max(0, 0) = 0$$\n因此，RHS为：\n$$\\text{RHS} = f(x) - f(x') = w^\\top x - 0 = w^\\top x$$\n\n比较两侧，我们发现：\n$$\\text{LHS} = w^\\top x$$\n$$\\text{RHS} = w^\\top x$$\n由于 LHS = RHS，因此在给定条件下，该模型和基线的完备性属性从第一性原理上得到了验证。归因向量是 $\\begin{pmatrix} w_1 x_1  w_2 x_2 \\end{pmatrix}$。", "answer": "$$ \\boxed{ \\begin{pmatrix} w_1 x_1  w_2 x_2 \\end{pmatrix} } $$", "id": "4419848"}, {"introduction": "在掌握了基本归因方法之后，让我们来探讨一个在临床实践中至关重要的挑战：全局解释与局部解释之间可能存在的差异。一个简单的线性模型可能提供全局的、易于理解的特征权重，但它是否能准确反映模型对特定“极端”病例的判断依据呢？此练习模拟了一个真实场景，要求您量化并解释一个全局线性模型和一个复杂的局部归因模型（通过 SHAP）在解释同一个高风险患者时的差异。通过这个对比分析，您将深刻体会到为什么对于复杂病例，高保真度的局部解释是不可或缺的。[@problem_id:4839506]", "problem": "一家医院正在评估一个全局线性分类器与一个局部解释方法在糖尿病风险预测方面的一致性，重点关注一个极端的患者画像。全局模型是一个正则化的逻辑回归模型，输出糖尿病发病的对数几率，其特征包括年龄（岁）、身体质量指数（BMI, $kg/m^2$）和糖化血红蛋白（HbA1c, 百分比）。模型参数为全局系数 $w_{\\text{age}} = 0.015$、$w_{\\text{BMI}} = 0.08$ 和 $w_{\\text{HbA1c}} = 0.9$ （单位均为每单位对数几率），以及一个截距项（此处不需要）。考虑一个队列参考特征向量（用作归因的基线）$x_{\\text{ref}} = (\\text{age}, \\text{BMI}, \\text{HbA1c}) = (50, 27, 6)$。对于一个极端患者，其特征向量为 $x^{\\ast} = (85, 42, 11)$。\n\n另外，一个梯度提升决策树风险模型通过 Shapley 加性解释 (SHAP) 生成局部归因，这些归因以相同的对数几率尺度报告，并相对于相同的基线。对于该患者，SHAP 归因向量为 $\\phi = (\\phi_{\\text{age}}, \\phi_{\\text{BMI}}, \\phi_{\\text{HbA1c}}) = (0.4, 1.1, 5.3)$。\n\n从核心定义出发，构建全局线性贡献向量 $g$，将全局线性模型视为相对于基线的加性归因，即对于每个特征 $i \\in \\{\\text{age}, \\text{BMI}, \\text{HbA1c}\\}$，$g_{i} = w_{i}\\,(x^{\\ast}_{i} - x_{\\text{ref},i})$。然后定义差异向量 $d = g - \\phi$。最后，计算差异的欧几里得范数，\n$$\nD = \\|d\\|_{2} = \\sqrt{d_{\\text{age}}^{2} + d_{\\text{BMI}}^{2} + d_{\\text{HbA1c}}^{2}}.\n$$\n报告 $D$ 的值，四舍五入到四位有效数字。在你的推理中，指出哪个特征对这种不匹配的贡献最大，并简要解释为什么在使用可解释人工智能（XAI）的临床决策支持中会出现这种不匹配。", "solution": "该问题要求计算并解释对于一个特定的患者画像，来自全局线性模型的特征归因与来自复杂非线性模型的局部归因之间的差异。\n\n首先，我们核对问题陈述。\n所有数据和定义都已明确给出：\n- 全局模型系数：$w = (w_{\\text{age}}, w_{\\text{BMI}}, w_{\\text{HbA1c}}) = (0.015, 0.08, 0.9)$。\n- 队列参考特征向量：$x_{\\text{ref}} = (50, 27, 6)$。\n- 极端患者特征向量：$x^{\\ast} = (85, 42, 11)$。\n- SHAP 归因向量：$\\phi = (\\phi_{\\text{age}}, \\phi_{\\text{BMI}}, \\phi_{\\text{HbA1c}}) = (0.4, 1.1, 5.3)$。\n- 全局线性贡献向量 $g$、差异向量 $d$ 和差异范数 $D$ 的定义。\n\n该问题在科学上植根于用于医学信息学的可解释人工智能（XAI）领域，问题设定良好，包含所有必要信息，且陈述客观。前提条件在事实上是合理的，场景是现实的。因此，该问题是有效的，我们开始求解。\n\n解题过程包括问题陈述中定义的三个连续计算步骤。\n\n1.  **构建全局线性贡献向量 $g$。**\n    在线性模型中，每个特征相对于基线 $x_{\\text{ref}}$ 的贡献是该特征的权重与其偏离基线的差值的乘积。首先，我们计算偏差向量 $\\Delta x = x^{\\ast} - x_{\\text{ref}}$。\n    $$\n    \\Delta x_{\\text{age}} = x^{\\ast}_{\\text{age}} - x_{\\text{ref,age}} = 85 - 50 = 35\n    $$\n    $$\n    \\Delta x_{\\text{BMI}} = x^{\\ast}_{\\text{BMI}} - x_{\\text{ref,BMI}} = 42 - 27 = 15\n    $$\n    $$\n    \\Delta x_{\\text{HbA1c}} = x^{\\ast}_{\\text{HbA1c}} - x_{\\text{ref,HbA1c}} = 11 - 6 = 5\n    $$\n    接下来，我们使用公式 $g_i = w_i \\, \\Delta x_i$ 计算全局线性贡献向量 $g$ 的分量。\n    $$\n    g_{\\text{age}} = w_{\\text{age}} \\cdot \\Delta x_{\\text{age}} = 0.015 \\times 35 = 0.525\n    $$\n    $$\n    g_{\\text{BMI}} = w_{\\text{BMI}} \\cdot \\Delta x_{\\text{BMI}} = 0.08 \\times 15 = 1.2\n    $$\n    $$\n    g_{\\text{HbA1c}} = w_{\\text{HbA1c}} \\cdot \\Delta x_{\\text{HbA1c}} = 0.9 \\times 5 = 4.5\n    $$\n    因此，全局线性贡献向量为 $g = (0.525, 1.2, 4.5)$。\n\n2.  **定义差异向量 $d$。**\n    差异向量 $d$ 是线性贡献向量 $g$ 和 SHAP 归因向量 $\\phi$ 之间的逐元素差。\n    $$\n    d = g - \\phi\n    $$\n    $$\n    d_{\\text{age}} = g_{\\text{age}} - \\phi_{\\text{age}} = 0.525 - 0.4 = 0.125\n    $$\n    $$\n    d_{\\text{BMI}} = g_{\\text{BMI}} - \\phi_{\\text{BMI}} = 1.2 - 1.1 = 0.1\n    $$\n    $$\n    d_{\\text{HbA1c}} = g_{\\text{HbA1c}} - \\phi_{\\text{HbA1c}} = 4.5 - 5.3 = -0.8\n    $$\n    差异向量为 $d = (0.125, 0.1, -0.8)$。\n\n3.  **计算差异的欧几里得范数 $D$。**\n    欧几里得范数 $D = \\|d\\|_2$ 的计算方法是 $d$ 各分量平方和的平方根。\n    $$\n    D = \\sqrt{d_{\\text{age}}^{2} + d_{\\text{BMI}}^{2} + d_{\\text{HbA1c}}^{2}}\n    $$\n    $$\n    D = \\sqrt{(0.125)^{2} + (0.1)^{2} + (-0.8)^{2}}\n    $$\n    $$\n    D = \\sqrt{0.015625 + 0.01 + 0.64}\n    $$\n    $$\n    D = \\sqrt{0.665625} \\approx 0.81585844...\n    $$\n    四舍五入到四位有效数字，我们得到：\n    $$\n    D \\approx 0.8159\n    $$\n\n最后，我们找出对不匹配贡献最大的特征并解释结果。差异向量的平方分量为 $d^2 = (0.015625, 0.01, 0.64)$。最大的分量 $0.64$ 对应于 $d_{\\text{HbA1c}}$。因此，**糖化血红蛋白（HbA1c）对不匹配的贡献最大**。\n\n对这种不匹配的解释在于两个模型之间的根本差异。全局线性模型假设每个特征都具有恒定的、可加性的效应。例如，它假设 HbA1c 每增加一个百分点，风险的对数几率就精确增加 $0.9$，而不管患者的年龄、BMI 或当前的 HbA1c 水平如何。向量 $g$ 代表了这种简化的线性归因。\n\n相比之下，梯度提升决策树模型能够学习复杂的非线性关系和特征交互。SHAP 归因向量 $\\phi$ 为这个复杂模型对特定患者 $x^{\\ast}$ 的预测提供了一个忠实的局部解释。巨大的差异，特别是对于 HbA1c 特征（$d_{\\text{HbA1c}} = -0.8$），表明线性模型的假设对于这个极端患者画像来说是严重不成立的。负号意味着线性模型的归因值（$4.5$）低估了 SHAP 的归因值（$5.3$）。这表明，对于一个 HbA1c 高达 $11\\%$ 且年龄和 BMI 也很高的患者，HbA1c 的真实风险贡献（正如更复杂的模型所学习到的）大于简单的线性外推所预测的值。这可能是由于在高 HbA1c 水平时风险的非线性加速，或是风险因素之间的交互效应，这两种现象在临床数据中都很常见，但简单的线性模型无法捕捉。这种差异凸显了 XAI 中的一个关键概念：一个全局性的、简单的解释可能无法忠实地反映复杂模型对局部（尤其是对于处于数据分布极端的个体）的预测。", "answer": "$$\n\\boxed{0.8159}\n$$", "id": "4839506"}]}