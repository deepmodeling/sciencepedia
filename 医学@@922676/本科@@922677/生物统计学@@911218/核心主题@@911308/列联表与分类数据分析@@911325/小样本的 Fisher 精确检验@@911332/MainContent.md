## 引言
在生物统计学和许多科学研究领域，分析[分类变量](@entry_id:637195)之间的关联是一项基本任务。[皮尔逊卡方检验](@entry_id:272929)是解决此类问题的常用工具，但其有效性依赖于一个关键前提：充足的样本量。当研究涉及小样本或罕见事件时——例如在探索性临床试验、罕见病研究或特定[基因突变](@entry_id:166469)分析中——[卡方检验](@entry_id:174175)的[近似理论](@entry_id:138536)便会失效，可能导致错误的结论。此时，我们需要一种不依赖大样本假设、能够在任何样本量下提供精确推断的方法。

Fisher[精确检验](@entry_id:178040)正是为应对这一挑战而生。它是一种基于[组合计数](@entry_id:141086)原理的[非参数统计](@entry_id:174479)方法，能够为[分类数据](@entry_id:202244)提供一个“精确”的[p值](@entry_id:136498)。本文旨在系统地介绍Fisher精确检验。在第一章“原理与机制”中，我们将深入探讨其背后的数学逻辑，从“条件化”思想出发，推导其所依赖的[超几何分布](@entry_id:193745)，并阐明p值的计算方法。接着，在第二章“应用与跨学科联系”中，我们将通过来自生物医学、遗传学和临床研究的真实案例，展示该检验在解决实际问题中的强大功能和广泛适用性。最后，在“动手实践”部分，我们将通过一系列精心设计的问题，巩固您对核心概念的理解并提升您的应用能力。通过本文的学习，您将掌握这一处理小样本数据的关键工具，并对统计推断的严谨性有更深刻的认识。

## 原理与机制

在上一章中，我们介绍了在分析[分类数据](@entry_id:202244)时，特别是在样本量较小或事件稀少的情况下，为何需要一种比传统卡方检验更为精确的统计方法。本章将深入探讨Fisher[精确检验](@entry_id:178040)的底层原理与核心机制。我们将从“为何需要”这一问题出发，逐步揭示其通过“条件化”思想解决问题的精妙之处，推导出其所依赖的[超几何分布](@entry_id:193745)，并系统阐述如何基于此计算[p值](@entry_id:136498)以进行[统计推断](@entry_id:172747)。

### 为何需要[精确检验](@entry_id:178040)：大样本方法的局限性

在生物统计学中，[皮尔逊卡方检验](@entry_id:272929)（Pearson's Chi-squared test）是分析$2 \times 2$或其他$R \times C$列联表中行变量与列变量是否独立的常用工具。该检验通过比较观测频数（Observed, $O$）与在零假设（即行、列变量相互独立）下计算出的期望频数（Expected, $E$）之间的差异来构建检验统计量 $\chi^2 = \sum \frac{(O_{ij} - E_{ij})^2}{E_{ij}}$。从理论上讲，当样本量足够大时，该统计量的抽样分布近似于一个自由度为 $(R-1)(C-1)$ 的[卡方分布](@entry_id:165213)。检验的[p值](@entry_id:136498)便是基于这个近似分布计算的。

然而，这一“大样本”近似的有效性有一个关键前提：所有单元格的期望频数都不能过低。一个广为流传的[经验法则](@entry_id:262201)是，所有期望频数 $E_{ij}$ 均应大于等于$5$。当样本量较小，或所研究的事件本身非常罕见时，这一条件往往无法满足。例如，在一项评估新药罕见不良事件的初步临床研究中，我们可能得到如下数据表：新药组8人中0人出现不良事件，而安慰剂组8人中5人出现 [@problem_id:4912060]。此处的样本量很小，且包含一个零观测值，计算出的部分期望频数会远小于5。

在这种情况下，卡方统计量的实际抽样分布与理论上的卡方分布会产生显著偏差。继续使用卡方检验或似然比卡方检验等依赖大样本近似的方法，会导致对[第一类错误](@entry_id:163360)（Type I error）率的控制失效，通常是使其膨胀。换言之，即使零假设为真（即处理与结局无关联），我们拒绝零假设的概率也会远超预设的显著性水平$\alpha$（如$0.05$）。这将导致我们得出错误的阳性结论，这在医学研究等领域是极其危险的。因此，我们需要一种不依赖于大样本近似、能够在小样本情况下提供精确推断的统计方法。Fisher[精确检验](@entry_id:178040)正是为此而生 [@problem_id:4776965]。

### Fisher[精确检验](@entry_id:178040)的核心思想：条件化

Fisher精确检验的巧妙之处在于它完全绕开了对抽样分布进行近似的需要，而是通过**条件化（conditioning）**的思想，推导出一个在零假设下精确的、无关于未知参数的概率分布。其核心是固定[列联表](@entry_id:162738)的行边缘总计与列边缘总计。

#### 条件化下的样本空间

让我们考虑一个标准的$2 \times 2$列联表，其单元格计数为 $a, b, c, d$，行总计为 $n_1, n_2$，列总计为 $m_1, m_2$，总样本量为 $N$。

| | 结局1 | 结局2 | 行总计 |
| :--- | :---: | :---: | :---: |
| **组1** | $a$ | $b$ | $n_1$ |
| **组2** | $c$ | $d$ | $n_2$ |
| **列总计** | $m_1$ | $m_2$ | $N$ |

当我们说“固定边缘总计”时，意味着我们只考虑所有具有相同行总计（$n_1, n_2$）和列总计（$m_1, m_2$）的可能表格。在这个约束下，表格的自由度并非4。一旦我们确定了任何一个单元格的计数值（例如 $a$），其他三个单元格的计数值将随之确定 [@problem_id:4912057]：
$b = n_1 - a$
$c = m_1 - a$
$d = n_2 - c = n_2 - (m_1 - a) = n_2 - m_1 + a$

由于所有单元格的计数值都必须是非负整数，这为 $a$ 的取值范围设定了界限：
1.  $a \ge 0$
2.  $b = n_1 - a \ge 0 \implies a \le n_1$
3.  $c = m_1 - a \ge 0 \implies a \le m_1$
4.  $d = n_2 - m_1 + a \ge 0 \implies a \ge m_1 - n_2$

综合这些不等式，我们得到 $a$ 的可行整数取值范围（即其支撑集）为：
$$ \max\{0, m_1 - n_2\} \le a \le \min\{n_1, m_1\} $$
因此，在固定边缘总计后，所有可能的[列联表](@entry_id:162738)构成了一个由单个变量 $a$ 的变化所定义的[离散样本空间](@entry_id:263580)。Fisher精确检验的本质，就是在所有这些可能的表格中，评估我们观测到的表格或更极端的表格出现的概率。

#### 条件化的原理

为何要进行条件化？答案是为了消除**[讨厌参数](@entry_id:171802)（nuisance parameters）**。考虑两组独立的二项分布样本，其成功概率分别为 $p_1$ 和 $p_2$。在检验独立性的零假设 $H_0: p_1 = p_2 = p$ 时，这个共同但未知的成功概率 $p$ 就是一个[讨厌参数](@entry_id:171802)。在不对 $p$ 作任何假设的前提下，直接计算观测数据的概率是困难的。

Fisher的解决方法是，在给定总成功数（即列总计 $m_1$）的条件下，分析这些成功在两组间的分布。从概率论角度看，我们是在计算单元格计数的条件概率。以两组独立的二项分布 $X \sim \mathrm{Bin}(n_1, p)$ 和 $Y \sim \mathrm{Bin}(n_2, p)$ 为例，在零假设 $H_0$ 下，我们想知道在总成功数为 $T = X+Y = t$ 的条件下，第一个样本中成功数为 $X=x$ 的概率。根据[条件概率](@entry_id:151013)定义：
$$ \mathbb{P}(X=x \mid T=t) = \frac{\mathbb{P}(X=x \text{ and } Y=t-x)}{\mathbb{P}(T=t)} $$
由于 $X$ 和 $Y$ 独立，分子是：
$$ \mathbb{P}(X=x)\mathbb{P}(Y=t-x) = \left[ \binom{n_1}{x} p^x (1-p)^{n_1-x} \right] \left[ \binom{n_2}{t-x} p^{t-x} (1-p)^{n_2-(t-x)} \right] = \binom{n_1}{x}\binom{n_2}{t-x} p^t (1-p)^{n_1+n_2-t} $$
分母是总成功数 $T$ 的概率。由于 $X$ 和 $Y$ 是具有相同 $p$ 的独立[二项分布](@entry_id:141181)，它们的和也服从二项分布 $T \sim \mathrm{Bin}(n_1+n_2, p)$。因此：
$$ \mathbb{P}(T=t) = \binom{n_1+n_2}{t} p^t (1-p)^{n_1+n_2-t} $$
将分子分母相除，我们可以看到包含[讨厌参数](@entry_id:171802) $p$ 的项 $p^t (1-p)^{n_1+n_2-t}$ 被完全约去 [@problem_id:4912010] [@problem_id:4776965]：
$$ \mathbb{P}(X=x \mid T=t) = \frac{\binom{n_1}{x}\binom{n_2}{t-x}}{\binom{n_1+n_2}{t}} $$
这个结果不依赖于任何未知参数，只与已知的边缘总计（$n_1, n_2, t$）有关。这就是“精确”的由来：它允许我们在不依赖任何近似的情况下，计算出给定边缘总计时任何特定表格出现的精确概率。

### 零假设与[超几何分布](@entry_id:193745)

如上所述，Fisher精确检验的零假设（$H_0$）是行变量与列变量之间无关联。根据研究设计的不同，这个零假设可以有等价的表述 [@problem_id:4912044]：
-   在比较两组的二元结局时（如随机对照试验），$H_0$ 意味着两组的成功概率相等，即 $H_0: p_1 = p_2$。
-   在分析关联性时，常用比值比（Odds Ratio, $\theta = \frac{ad}{bc}$）来度量。无关联等价于比值比为1，即 $H_0: \theta = 1$。

在固定边缘总计的条件下，并且在上述零假设成立的前提下，单元格 $a$ 的计数值 $A$ 的[条件概率分布](@entry_id:163069)为**[超几何分布](@entry_id:193745)（Hypergeometric Distribution）**。其[概率质量函数](@entry_id:265484)为：
$$ P(A=a) = \frac{\binom{m_1}{a} \binom{m_2}{n_1-a}}{\binom{N}{n_1}} $$
这个公式有一个非常直观的组合学解释 [@problem_id:4912007]：想象一个总体共 $N$ 个个体，其中 $m_1$ 个具有某种特征（例如，结局为“成功”），$m_2$ 个不具有该特征。我们从这个总体中**不放回地**随机抽取 $n_1$ 个个体（这对应于第1组）。那么，在抽出的 $n_1$ 个个体中，恰好有 $a$ 个具有该特征的概率，就由上述[超几何分布](@entry_id:193745)公式给出。分母 $\binom{N}{n_1}$ 是所有可能的抽样方式总数，分子 $\binom{m_1}{a} \binom{m_2}{n_1-a}$ 是我们关心的特定结果（$a$ 个成功，$n_1-a$ 个失败）的组合数。

### p值的计算

有了在零假设下每个可能表格的精确概率，我们就可以计算p值。p值定义为：在零假设为真的前提下，观测到与当前数据相同或“更极端”结果的概率之和。

#### [单侧检验](@entry_id:170263)

“更极端”的定义取决于备择假设（$H_1$）。对于[单侧检验](@entry_id:170263)，方向是明确的。
-   备择假设 $H_1: \theta > 1$（例如，处理组的效果优于[对照组](@entry_id:188599)）意味着我们预期单元格 $a$ 的值会偏大。因为在固定边缘总计的情况下，比值比 $\theta$ 是 $a$ 的单调递增函数，更大的 $a$ 对应于更大的 $\theta$ [@problem_id:4912025]。因此，“更极端”的表格就是那些 $A$ 的计数值大于或等于我们观测值 $A_{obs}$ 的表格。p值即为 $P(A \ge A_{obs}) = \sum_{k=A_{obs}}^{\max(A)} P(A=k)$。

-   备择假设 $H_1: \theta < 1$ 则意味着我们预期 $a$ 的值会偏小。此时，“更极端”的表格是那些 $A \le A_{obs}$ 的表格，[p值](@entry_id:136498)为 $P(A \le A_{obs}) = \sum_{k=\min(A)}^{A_{obs}} P(A=k)$。

**示例：** 假设一项研究得到如下$2 \times 2$表格：治疗组6人中有4名响应者，[对照组](@entry_id:188599)6人中有1名响应者。我们想检验治疗是否能提高[响应率](@entry_id:267762)（$H_1: \theta > 1$）[@problem_id:4912037]。

| | 响应 | 未响应 | 总计 |
| :--- | :---: | :---: | :---: |
| **治疗** | $a=4$ | $2$ | $6$ |
| **对照** | $1$ | $5$ | $6$ |
| **总计** | $5$ | $7$ | $12$ |

边缘总计为 $n_1=6, n_2=6, m_1=5, m_2=7$。单元格 $a$ 的可行取值范围为 $\max\{0, 5-6\} \le a \le \min\{6, 5\}$，即 $a \in \{0, 1, 2, 3, 4, 5\}$。
观测值为 $A_{obs}=4$。因为备择假设是 $H_1: \theta > 1$，所以我们需要计算 $P(A \ge 4) = P(A=4) + P(A=5)$。
使用[超几何概率](@entry_id:263667)公式 $P(A=a) = \frac{\binom{6}{a}\binom{6}{5-a}}{\binom{12}{5}}$：
$P(A=4) = \frac{\binom{6}{4}\binom{6}{1}}{\binom{12}{5}} = \frac{15 \times 6}{792} = \frac{90}{792}$
$P(A=5) = \frac{\binom{6}{5}\binom{6}{0}}{\binom{12}{5}} = \frac{6 \times 1}{792} = \frac{6}{792}$
单侧[p值](@entry_id:136498)为 $p = \frac{90}{792} + \frac{6}{792} = \frac{96}{792} \approx 0.121$。

#### 双侧检验

对于双侧检验（$H_1: \theta \neq 1$），如何定义“更极端”则不那么直观，因为[超几何分布](@entry_id:193745)（尤其在边缘总计不对称时）可能是[偏态](@entry_id:178163)的。存在多种定义双侧[p值](@entry_id:136498)的方法，其中两种最常见的是 [@problem_id:4912008]：

1.  **双倍最小单侧[p值](@entry_id:136498)法**：计算上[尾概率](@entry_id:266795) $P(A \ge A_{obs})$ 和下[尾概率](@entry_id:266795) $P(A \le A_{obs})$，取其中较小者的两倍作为p值。即 $p = 2 \times \min(P(A \ge A_{obs}), P(A \le A_{obs}))$，且p值不超过1。这种方法简单直观，但仅在分布对称时才具有理论上的优良性质。

2.  **小概率求和法**：将所有概率小于或等于观测表格概率的表格的概率相加。即 $p = \sum_{a: P(A=a) \le P(A=A_{obs})} P(A=a)$。这种方法更受理论家青睐，因为它直接基于概率本身来定义极端性。

在边缘总计不对称的情况下，这两种方法可能得出不同的p值。例如，对于一个行总计为(5, 7)、列总计为(2, 10)的表格，若观测值为 $A_{obs}=2$，其概率为 $\frac{10}{66}$。这是所有可能表格中概率最小的一个。按方法1，p值为 $2 \times \frac{10}{66} \approx 0.303$。按方法2，只有 $A=2$ 本身的概率小于等于 $\frac{10}{66}$，因此[p值](@entry_id:136498)就是 $\frac{10}{66} \approx 0.152$。这两种方法的差异在解释结果时需要予以注意。只有当边缘总计完全对称（即 $n_1=n_2$ 且 $m_1=m_2$）时，[超几何分布](@entry_id:193745)才是对称的，此时两种方法的结果才会一致 [@problem_id:4912008]。

### 扩展到 R x C [列联表](@entry_id:162738)

Fisher精确检验的原理并不局限于$2 \times 2$表格，它可以推广到任意的 $R \times C$ 表格。其核心思想依然是固定所有的行总计和列总计，然后在所有符合这些边缘总计的可能表格构成的[样本空间](@entry_id:275301)中，计算观测表格或更极端表格出现的精确概率 [@problem_id:4912029]。

在这种情况下，表格的概率由**多元[超几何分布](@entry_id:193745)（Multivariate Hypergeometric Distribution）**给出。对于一个 $R \times C$ 表格，其概率为：
$$ P(\{x_{ij}\}) = \frac{\prod_{i=1}^{R} n_i! \prod_{j=1}^{C} m_j!}{N! \prod_{i=1}^{R} \prod_{j=1}^{C} x_{ij}!} $$
其中 $x_{ij}$ 是第 $i$ 行第 $j$ 列的单元格计数，$n_i$ 是行总计，$m_j$ 是列总计。

计算 $R \times C$ 表格的[p值](@entry_id:136498)面临的主要挑战是定义“更极端”的表格。对于 $2 \times 2$ 表格，单元格 $a$ 的大小可以作为衡量极端性的自然排序。但对于更大的表格，没有单一的、公认的最佳排序标准。通常，研究者需要预先定义一个检验统计量（例如，特定单元格的计数值，或类似卡方值的度量），然后计算所有可能表格的该统计量的值，最后将统计量值大于或等于观测表格统计量值的那些表格的概率相加，得到p值。

例如，在一个 $2 \times 3$ 的表格中，若我们关心的是处理组在“改善”这一最佳结局上的富集情况，我们可以直接使用处理组中“改善”结局的计数值 $X_{11}$ 作为检验统计量。[p值](@entry_id:136498)就是所有 $X_{11} \ge x_{11, obs}$ 的可能表格的多元[超几何概率](@entry_id:263667)之和 [@problem_id:4912029]。这种计算在计算上可能非常复杂，通常需要借助专门的统计软件来完成。