## 引言
在生物统计学、流行病学及众多科学领域中，我们常常需要分析分类型变量之间的关系。例如，一种新的治疗方法是否能改变患者的康复率？某个基因型与特定疾病的患病风险是否相关？回答这些问题需要严谨的统计工具来分析列联表中的计数数据，而卡方检验正是解决这类问题的核心方法。

然而，“[卡方检验](@entry_id:174175)”并非单一概念，其背后蕴含着丰富而精妙的统计思想，其应用也远超基础的关联性判断。许多初学者常常在独立性与[同质性](@entry_id:636502)检验的选择上感到困惑，或在分析时忽略了关键的假设条件，导致结论出现偏差。本文旨在系统性地梳理[卡方检验](@entry_id:174175)的理论与实践，填补从理论知识到实际应用之间的鸿沟。

通过本文的学习，您将全面掌握[卡方检验](@entry_id:174175)的精髓。在“原理与机制”一章中，我们将深入探讨其统计学基础，明确独立性与[同质性](@entry_id:636502)检验的本质区别，并介绍统计量的构建与理论分布。接下来的“应用与跨学科联系”一章将通过遗传学、临床研究和数据科学等领域的真实案例，展示卡方检验及其扩展方法（如处理混杂因素的CMH检验）的强大威力。最后，在“动手实践”部分，您将有机会通过解决实际问题来巩固所学知识，提升数据分析能力。让我们一同开启这段探索[分类数据](@entry_id:202244)奥秘的旅程。

## 原理与机制

在生物统计学研究中，我们经常遇到需要探究两个[分类变量](@entry_id:637195)之间是否存在关联的问题。例如，一种新疗法是否与患者的康复状态有关？或者，某个基因型是否与某种疾病的易感性相关？为了回答这些问题，我们需要一套严谨的统计方法来分析列联表（contingency table）中的计数数据。[卡方检验](@entry_id:174175)（Chi-squared test）便是其中最核心与应用最广泛的工具之一。本章将深入剖析卡方检验背后的基本原理、统计机制及其理论延伸，重点阐述[独立性检验](@entry_id:165431)与[同质性](@entry_id:636502)检验的联系与区别。

### 核心问题：[分类数据](@entry_id:202244)中的关联性

想象一个 $r \times c$ 的列联表，它由两个分类变量交叉分类构成，其中一个变量有 $r$ 个水平（行变量），另一个有 $c$ 个水平（列变量）。表中的每一个单元格 $(i, j)$ 包含落入第 $i$ 行且第 $j$ 列类别的观测频数，我们记为 $O_{ij}$。

分析这类表格的核心问题是：这两个分类变量是否**独立**？从概率论的角度来看，如果两个变量是独立的，那么某个观测同时落入特定行和特定列的**联合概率**应该等于它们各自**[边际概率](@entry_id:201078)**的乘积。

让我们更形式化地定义这些概念。假设从一个大总体中随机抽取一个个体，令 $p_{ij}$ 为该个体同时属于行类别 $i$ 和列类别 $j$ 的真实概率。这些概率必须满足 $p_{ij} \ge 0$ 且 $\sum_{i=1}^{r}\sum_{j=1}^{c} p_{ij} = 1$。

行 $i$ 的**[边际概率](@entry_id:201078)** $p_{i+}$ 是该个体属于行类别 $i$ 的总概率，无论其属于哪个列类别。它通过对该行所有单元格的概率求和得到：
$$
p_{i+} = \sum_{j=1}^{c} p_{ij}
$$

类似地，列 $j$ 的**[边际概率](@entry_id:201078)** $p_{+j}$ 是该个体属于列类别 $j$ 的总概率：
$$
p_{+j} = \sum_{i=1}^{r} p_{ij}
$$

基于这些定义，[统计独立性](@entry_id:150300)的概念可以直接转化为关于这些概率的一个精确假设。两个分类变量相互独立的**原假设**（null hypothesis, $H_0$）可以表述为：对于所有的 $i$ 和 $j$，[联合概率](@entry_id:266356)等于[边际概率](@entry_id:201078)的乘积 [@problem_id:4899830]。

$H_0$: 对于所有 $i=1,\dots,r$ 和 $j=1,\dots,c$，均有 $p_{ij} = p_{i+} \cdot p_{+j}$。

这个简洁优雅的公式构成了[独立性检验](@entry_id:165431)的理论基石。检验的目的就是利用样本数据来判断我们是否有足够的证据拒绝这个原假设，即断定两个变量之间存在某种关联。

### 一体两面：[独立性检验](@entry_id:165431)与[同质性](@entry_id:636502)检验

虽然“卡方检验”常被笼统地提及，但它实际上涵盖了两种在概念上截然不同但计算上非常相似的检验：**[独立性检验](@entry_id:165431)**（test of independence）和**[同质性](@entry_id:636502)检验**（test of homogeneity）。它们的区别本质上源于研究设计和抽样方法的不同 [@problem_id:4899869]。

#### [独立性检验](@entry_id:165431)

**[独立性检验](@entry_id:165431)**通常应用于**横断面研究**（cross-sectional studies）或类似的抽样设计中。在这种设计下，我们从一个总体中抽取一个固定大小的样本（比如，总样本量为 $N$），然后同时根据两个变量对每个个体进行分类。

- **抽样模型**：整个 $r \times c$ [列联表](@entry_id:162738)的 $rc$ 个单元格的频数可以被看作来自一个总试验次数为 $N$、单元格概率为 $\{p_{ij}\}$ 的**[多项分布](@entry_id:189072)**（multinomial distribution）。在这种模型中，只有总样本量 $N$ 是事先固定的。所有的行边际总计（row totals）和列边际总计（column totals）都是随机变量，其值取决于抽样结果。

- **研究问题**：[独立性检验](@entry_id:165431)旨在回答：在**单个总体**中，这两个分类变量是否相互关联？例如，在一个随机抽取的成年人队列中，体力活动水平（低、中、高）和代谢综合征状态（是、否）是否独立？

- **假设**：原假设是变量间的独立性，即 $H_0: p_{ij} = p_{i+} p_{+j}$。

#### 同质性检验

**[同质性](@entry_id:636502)检验**则适用于不同的研究设计，例如**分层队列研究**（stratified cohort studies）或**随机对照试验**（randomized controlled trials）。在这种设计下，我们首先确定几个（比如 $r$ 个）不同的总体或组，然后从每个总体中独立地抽取一个固定大小的样本。

- **抽样模型**：这里我们有 $r$ 个独立的样本，其样本量 $n_1, n_2, \dots, n_r$ 是由研究设计固定的。因此，[列联表](@entry_id:162738)的行边际总计是固定的。每一行的数据可以被看作一个独立的**[多项分布](@entry_id:189072)**。例如，第 $i$ 行的频数向量 $(O_{i1}, \dots, O_{ic})$ 来自一个总次数为 $n_i$ 的[多项分布](@entry_id:189072)。这个模型也被称为**乘积[多项分布](@entry_id:189072)**（product-multinomial distribution）。

- **研究问题**：[同质性](@entry_id:636502)检验旨在回答：这 $r$ 个**不同总体**在某个[分类变量](@entry_id:637195)上的分布是否相同（即同质）？例如，一个生物统计学家在 $r$ 个不同的诊所各自招募了 $n_i$ 名患者，并将每位患者分为 $c$ 种生物标志物类别。他想知道，这些诊所的患者在生物标志物类别上的分布是否相同？[@problem_id:4899869]

- **假设**：原假设是各总体的分布是同质的。令 $p_{j|i}$ 表示从总体 $i$ 中抽取的个体属于类别 $j$ 的概率。[同质性](@entry_id:636502)假设即为：对于每个类别 $j$，这个概率不依赖于总体 $i$。也就是说，存在一个共同的[概率向量](@entry_id:200434) $(p_1, \dots, p_c)$，使得对于所有的 $i$ 和 $j$，都有 $p_{j|i} = p_j$。

尽管这两种检验的出发点和研究问题不同，但一个关键的结论是，它们最终会引导至相同的检验统计量计算过程和相同的[渐近分布](@entry_id:272575)。这使得[卡方检验](@entry_id:174175)成为一个极其通用和强大的工具。

### 量化偏差：卡方统计量

无论我们进行的是[独立性检验](@entry_id:165431)还是同质性检验，核心思想都是比较**观测频数**（Observed counts, $O_{ij}$）与在原假设成立前提下的**期望频数**（Expected counts, $E_{ij}$）。如果观测值与[期望值](@entry_id:150961)相差甚远，我们就有理由怀疑原假设的正确性。

#### 期望频数的推导

期望频数 $E_{ij}$ 是在原假设模型下，单元格 $(i, j)$ 中“应该”出现的频数。它是通过**[最大似然估计](@entry_id:142509)**（Maximum Likelihood Estimation, MLE）得到的。

在独立性或[同质性](@entry_id:636502)假设下，我们可以推导出期望频数的统一计算公式：
$$
E_{ij} = \frac{(\text{row } i \text{ total}) \times (\text{column } j \text{ total})}{\text{grand total}} = \frac{n_{i+} n_{+j}}{n}
$$
其中，$n_{i+}$ 是第 $i$ 行的观测总频数，$n_{+j}$ 是第 $j$ 列的观测总频数，$n$ 是总样本量。

这个估计量具有一些优良的性质，这些性质源于其作为MLE的身份 [@problem_id:4899831]。
1.  **非负性**：由于观测频数 $n_{i+}, n_{+j}, n$ 都是非负的，所以计算出的期望频数 $E_{ij}$ 也必然是非负的。这符合频数的现实意义。
2.  **边际匹配**：通过MLE推导出的期望频数，其行总和与列总和将精确匹配观测数据的行总和与列总和。即 $\sum_j E_{ij} = n_{i+}$ 和 $\sum_i E_{ij} = n_{+j}$。这本质上是[指数族](@entry_id:263444)分布MLE的一个普遍性质：拟合值会保留充分统计量（sufficient statistics）的观测值。在此背景下，边际总计就是模型的充分统计量，因此MLE保证了拟合的期望频数会再现这些边际总计。

#### 构建[检验统计量](@entry_id:167372)

有了期望频数，我们便可以构建统计量来衡量观测与期望之间的总体差异。

**皮尔逊卡方统计量 (Pearson's Chi-squared Statistic, $\chi^2$)**

这是最经典的卡方统计量，由 Karl Pearson 提出。它计算每个单元格的差异，将其标准化，然后求和：
$$
\chi^2 = \sum_{i=1}^{r} \sum_{j=1}^{c} \frac{(O_{ij} - E_{ij})^2}{E_{ij}}
$$
这个公式直观地表达了“偏差平方和”的思想。每个单元格的偏差 $(O_{ij} - E_{ij})$ 被其[期望值](@entry_id:150961) $E_{ij}$ 标准化。分母 $E_{ij}$ 的作用是调整尺度，因为对于[期望值](@entry_id:150961)较大的单元格，一个绝对值相同的偏差没有[期望值](@entry_id:150961)较小的单元格那么显著。

**[似然比](@entry_id:170863)统计量 (Likelihood Ratio Statistic, $G^2$)**

这是基于[似然比检验](@entry_id:268070)原理的另一个常用统计量，有时也称为G检验。它的定义如下：
$$
G^2 = 2 \sum_{i=1}^{r} \sum_{j=1}^{c} O_{ij} \ln\left(\frac{O_{ij}}{E_{ij}}\right)
$$
其中 $\ln$ 是自然对数。$G^2$ 在信息论中有着深刻的解释。它可以被看作是观测数据（[经验分布](@entry_id:274074)）与原假设下的模型（独立或同质模型）之间差异的一种度量。具体来说，$G^2$ 等于 $2n$ 乘以观测[联合分布](@entry_id:263960)与观测边际[乘积分布](@entry_id:269160)之间的**Kullback–Leibler (KL) 散度** [@problem_id:4899845]。KL散度是衡量两个概率分布之间差异的一种非对称度量，因此 $G^2$ 实质上量化了拒绝原假设所带来的“[信息增益](@entry_id:262008)”。

#### [渐近分布](@entry_id:272575)

统计理论中的一个重要成果，即[Wilks定理](@entry_id:169826)，表明在原假设成立且样本量足够大的条件下，$\chi^2$ 和 $G^2$ 这两个统计量都近似服从一个自由度（degrees of freedom, $df$）为 $(r-1)(c-1)$ 的**[卡方分布](@entry_id:165213)**（$\chi^2$ distribution）。

自由度 $(r-1)(c-1)$ 可以直观理解为：在一个 $r \times c$ 的表格中，一旦我们固定了行总计和列总计，我们能够自由填充的单元格数量。例如，在一个 $2 \times 2$ 表中，只要填好一个单元格，其余三个单元格的数值就因边际总计的限制而被唯一确定，因此自由度为 $(2-1)(2-1)=1$。

### 更深层的理论关联

卡方检验的美妙之处在于它能够从多个理论视角得到统一。

#### 对数线性模型视角

我们可以使用**对数线性模型**（log-linear models）来为[列联表](@entry_id:162738)中的期望频数 $\mu_{ij}$ 建模。一个基本的假设是单元格的观测频数 $X_{ij}$ 服从独立的泊松分布，其均值为 $\mu_{ij}$。

模型的[对数期](@entry_id:165031)望频数 $\log \mu_{ij}$ 被表示为不同效应的[线性组合](@entry_id:155091)。一个包含所有可能效应的**[饱和模型](@entry_id:150782)**（saturated model）如下：
$$
\log \mu_{ij} = \lambda + \lambda_i^R + \lambda_j^C + \lambda_{ij}^{RC}
$$
这里，$\lambda$ 是总均值项，$\lambda_i^R$ 是行 $i$ 的主效应，$\lambda_j^C$ 是列 $j$ 的主效应，而 $\lambda_{ij}^{RC}$ 是行与列之间的**[交互效应](@entry_id:164533)项**。

在这个框架下，变量独立的假设等价于**不存在[交互效应](@entry_id:164533)** [@problem_id:4899855]。因此，独立性的原假设对应于一个更简洁的模型：
$$
H_0: \quad \log \mu_{ij} = \lambda + \lambda_i^R + \lambda_j^C
$$
这个模型表明，[对数期](@entry_id:165031)望频数仅仅是行效应和列效应的简单相加。取指数后，我们得到 $\mu_{ij} = \exp(\lambda) \exp(\lambda_i^R) \exp(\lambda_j^C)$，这是一个乘法结构，与我们最初的独立性定义 $p_{ij} = p_{i+} p_{+j}$ 形式一致。可以证明，在此模型下通过最大似然估计得到的拟合值 $\hat{\mu}_{ij}$，其计算公式恰好就是我们之前看到的期望频数 $E_{ij} = \frac{n_{i+} n_{+j}}{n}$。这个视角将[独立性检验](@entry_id:165431)完美地融入了广义线性模型的框架中。

#### 不同抽样模型的统一

如前所述，[独立性检验](@entry_id:165431)和[同质性](@entry_id:636502)检验源于不同的抽样设计。更进一步，我们还可以考虑第三种情况：行总计和列总计均被视为固定，这在某些[精确检验](@entry_id:178040)的条件分析中出现。这三种情况分别对应三种不同的概率分布模型 [@problem_id:4899860]：

1.  **单一样本，总计 $n$ 固定**：观测频数服从**[多项分布](@entry_id:189072)**。这是典型的[独立性检验](@entry_id:165431)情景。
2.  **$r$ 个独立样本，行总计 $\{n_i\}$ 固定**：观测频数服从**乘积[多项分布](@entry_id:189072)**。这是典型的同质性检验情景。
3.  **行总计 $\{n_i\}$ 和列总计 $\{m_j\}$ 均固定**：在给定所有边际总计的条件下，观测频数服从**多元[超几何分布](@entry_id:193745)**（multivariate hypergeometric distribution）。

一个极其重要的理论结论是：尽管这三种抽样模型在有限样本下的精确分布完全不同，但在大样本的条件下，针对相应原假设的[皮尔逊卡方检验](@entry_id:272929)和[似然比检验](@entry_id:268070)都收敛到同一个[渐近分布](@entry_id:272575)——自由度为 $(r-1)(c-1)$ 的卡方分布。这一深刻的结果统一了不同研究设计下的关联性分析，解释了为什么一个简单的计算公式 $\chi^2 = \sum \frac{(O-E)^2}{E}$ 能够如此广泛地适用。

### 实际应用与结果解读

在应用[卡方检验](@entry_id:174175)时，除了计算[检验统计量](@entry_id:167372)和[p值](@entry_id:136498)，还有几个关键的实际问题需要考虑。

#### 卡方近似的有效性

卡方检验的p值是基于$\chi^2$和$G^2$统计量在大样本下近似服从卡方分布这一性质。如果样本量过小，这种近似可能不准确。**Cochran条件**为此提供了广为接受的实践指南 [@problem_id:4899859]：

1.  所有单元格的**期望频数** $E_{ij}$ 都不应小于1 ($E_{ij} \ge 1$)。
2.  最多只有20%的单元格的**期望频数**小于5。换言之，至少80%的单元格其 $E_{ij} \ge 5$。
3.  对于自由度为1的 $2 \times 2$ 表，要求更为严格，通常建议所有四个单元格的期望频数都大于等于5。

这些规则的根本原因在于，每个单元格的计数服从[离散分布](@entry_id:193344)（如泊松或[二项分布](@entry_id:141181)），只有当[期望值](@entry_id:150961)足够大时，它才能被正态分布很好地近似，而[卡方分布](@entry_id:165213)正是源于正态分布的二次型。当期望频数过小时，[离散分布](@entry_id:193344)的偏斜和离散性会破坏这种近似，导致计算出的[p值](@entry_id:136498)不可靠。

#### 超越p值：衡量关联强度

一个显著的[p值](@entry_id:136498)（例如 $p  0.05$）告诉我们两个变量之间可能存在关联，但它没有告诉我们这种关联有多强。一个在统计上显著的效应在实际中可能非常微弱。因此，报告一个**效应大小**（effect size）的度量至关重要。

对于[列联表](@entry_id:162738)，**Cramér's V** 是一个常用的效应大小度量。它基于皮尔逊 $\chi^2$ 统计量，但对其进行了标准化，使其值落在 $[0, 1]$ 区间内 [@problem_id:4899872]。

其定义为：
$$
V = \sqrt{\frac{\chi^2}{n \cdot \min(r-1, c-1)}}
$$
其中 $n$ 是总样本量，$r$ 和 $c$ 分别是行数和列数。
- $V=0$ 表示完全独立。
- $V=1$ 表示变量间的完全关联。

这个公式中的归一化因子 $\min(r-1, c-1)$ 是关键。理论上可以证明，$\chi^2$ 统计量的最大可[能值](@entry_id:187992)是 $n \cdot \min(r-1, c-1)$。因此，通过除以这个最大可[能值](@entry_id:187992)（的一部分），Cramér's V 确保了其上界为1，从而可以在不同大小的列联表之间进行有意义的比较。对于 $2 \times 2$ 表，$\min(r-1, c-1)=1$，此时 Cramér's V 退化为另一个称为 phi ($\phi$)系数的度量。

#### 探究关联来源：[残差分析](@entry_id:191495)

如果[卡方检验](@entry_id:174175)的结果是显著的，意味着我们拒绝了“变量间无关联”的原假设。那么下一个自然的问题是：具体是哪些单元格的偏差导致了这种关联？**[残差分析](@entry_id:191495)**（residual analysis）可以帮助我们回答这个问题。

**皮尔逊残差**（Pearson residuals）定义为：
$$
r_{ij} = \frac{O_{ij} - E_{ij}}{\sqrt{E_{ij}}}
$$
皮尔逊 $\chi^2$ 统计量正是这些残差的平方和。然而，由于 $E_{ij}$ 是用数据估计出来的，这些残差的方差实际上并不等于1。

为了进行更准确的诊断，我们使用**[标准化残差](@entry_id:634169)**（standardized residuals），它对估计边际带来的方差缩减进行了校正 [@problem_id:4899837]：
$$
z_{ij} = \frac{O_{ij} - E_{ij}}{\sqrt{E_{ij} (1 - \hat{p}_{i+})(1 - \hat{p}_{+j})}}
$$
其中 $\hat{p}_{i+} = n_{i+}/n$ 和 $\hat{p}_{+j} = n_{+j}/n$ 是观测到的边际比例。在原假设下，这些[标准化残差](@entry_id:634169)近似服从标准正态分布 $\mathcal{N}(0, 1)$。因此，我们可以通过检查哪些单元格的 $z_{ij}$ 值在绝对值上较大（例如，大于1.96或2）来识别那些“出乎意料”的单元格，即对整体关联性贡献最大的地方。

#### 当[渐近方法](@entry_id:177759)失效：精确检验

如果样本量很小，以至于Cochran条件无法满足，那么基于卡方分布的[p值](@entry_id:136498)就不可信。在这种情况下，我们应该诉诸于**精确检验**（exact tests）。

对于 $2 \times 2$ 表，最著名的[精确检验](@entry_id:178040)是**Fisher[精确检验](@entry_id:178040)**（Fisher's Exact Test）。它不依赖于任何大样本近似。其逻辑是：在给定所有行、列边际总计的条件下，单元格频数的分布服从**[超几何分布](@entry_id:193745)** [@problem_id:4899807]。

例如，在一个比较疗法（$n_T$人）与安慰剂（$n_C$人）[血清转化](@entry_id:195698)率的研究中，若观测到总共有 $K$ 人发生[血清转化](@entry_id:195698)。在零假设（两组转化率相同）下，我们可以计算出在疗法组观测到恰好 $a$ 例[血清转化](@entry_id:195698)的精确概率：
$$
P(A=a \mid \text{margins}) = \frac{\binom{n_T}{a} \binom{n_C}{K-a}}{\binom{N}{K}}
$$
检验的p值是通过将所有“至少与观测结果一样极端”的表格的精确概率相加得到的。这种方法避免了对分布的任何近似，因此结果是“精确的”。对于更大的 $r \times c$ 表格，Fisher[精确检验](@entry_id:178040)在计算上会变得非常复杂，但现代统计软件已经可以处理。

总之，卡方检验及其相关概念为分析[分类数据](@entry_id:202244)提供了一个强大而灵活的框架。理解其从抽样设计到假设构建，再到统计量计算和结果解读的全过程，是进行严谨生物统计学分析的关键。