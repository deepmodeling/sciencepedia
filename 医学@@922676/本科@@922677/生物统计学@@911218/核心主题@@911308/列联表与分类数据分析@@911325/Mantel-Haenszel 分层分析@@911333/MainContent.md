## 引言
在生物统计学和流行病学研究中，准确评估暴露与结局之间的关联是探索疾病病因和评价干预效果的核心。然而，直接观察到的“粗略”关联往往会受到第三变量的干扰，即“混淆”，从而导致错误的科学结论，[辛普森悖论](@entry_id:136589)便是其极端体现。如何拨开混淆的迷雾，探寻真实的效应大小？曼特尔-汉塞尔（Mantel-Haenszel, MH）分层分析为此提供了一套经典而强大的解决方案。它通过“[分而治之](@entry_id:139554)，再而合之”的策略，使研究者能够获得一个不受混淆因素扭曲的、更为纯粹的关联度量。

本文将引导您系统地掌握MH分层分析。在“原理与机制”一章中，我们将深入探讨分层控制混淆的根本逻辑，揭示MH估计量和检验背后的统计学基石，并辨析效应修饰等关键概念。接下来，在“应用与跨学科联系”一章中，我们将通过来自临床医学、遗传学和因果推断等领域的丰富案例，展示MH方法在不同研究设计和前沿科学问题中的具体应用。最后，“动手实践”部分将提供练习机会，帮助您将理论知识转化为解决实际问题的能力。让我们从理解其核心原理开始，踏上这段严谨的数据分析之旅。

## 原理与机制

在上一章中，我们介绍了分层分析的基本概念及其在生物统计学和流行病学中的重要性。本章将深入探讨支持分层分析，特别是 Mantel-Haenszel 方法的统计学原理和核心机制。我们将从为何需要分层（即控制混淆）出发，系统地阐述 Mantel-Haenszel 估计量和检验的构建方式，并最后讨论在实践中至关重要的几个高级概念，包括效应修饰和比值比的不可合并性。

### 分层分析的原理：控制混淆

分层分析的核心目的在于获得一个未被“第三变量”扭曲的、关于暴露与结局之间关联的纯粹度量。这个“第三变量”如果同时与暴露和结局相关，并且不位于暴露与结局的因果路径上，我们称之为**[混淆变量](@entry_id:199777) (confounder)**。当混淆存在时，直接计算得到的暴露与结局的**粗略关联 (crude association)** 会产生误导，因为它混合了暴露的真实效应和[混淆变量](@entry_id:199777)的效应。

**混淆 (confounding)** 的本质是，由于[混淆变量](@entry_id:199777)在暴露组和非暴露组中的分布不均衡，导致比较的起点本身就不公平。分层分析通过在[混淆变量](@entry_id:199777)的每个水平（即“层”）内部分别评估暴露与结局的关联，从而解决了这个问题。在每一层内部，[混淆变量](@entry_id:199777)的值是恒定的，因此它无法再对该层内的关联产生混淆作用。[@problem_id:4808923]

让我们通过一个经典的例子来理解混淆的威力。假设一项研究旨在评估某暴露 $E$ 与某疾病 $D$ 的关联，而研究人群可根据一个二[分类变量](@entry_id:637195) $Z$（如年龄组：年轻 vs. 年老）分为两层。我们可能会观察到一种极端情况，即**[辛普森悖论](@entry_id:136589) (Simpson's Paradox)**。在这种情况下，在每个独立的层内，暴露都显示出与疾病存在正向关联（例如，增加患病风险），但将所有数据合并后，计算出的粗略关联却显示为负向关联（表现为保护效应）。[@problem_id:4924622]

**例**：假设在 $Z=0$ 层（如年轻组），暴露者的患病比值比 (Odds Ratio, OR) 为 $2.0$；在 $Z=1$ 层（如年老组），暴露者的患病比值比同样为 $2.0$。这表明在控制了年龄后，暴露会使患病的比值增加一倍。然而，如果暴露在年老组中更普遍，而年老本身又是疾病的高风险因素，那么在合并数据时，大量的年老暴露者会拉高暴露组的整体患病率，而大量的年轻非暴露者则会拉低非暴露组的整体患病率。这种由[混淆变量](@entry_id:199777) $Z$ 造成的组间构成差异，可能导致计算出的粗略比值比远小于 $2.0$，甚至小于 $1.0$，从而得出暴露是“保护性”的错误结论。[@problem_id:4924622]

从因果推断的角度看，[混淆变量](@entry_id:199777) $Z$ 构成了一条从暴露 $E$ 到结局 $D$ 的“后门路径” ($E \leftarrow Z \rightarrow D$)。分层（或在[统计模型](@entry_id:755400)中进行调整）等同于对 $Z$ 进行**条件化 (conditioning)**，其作用是阻断这条后门路径。因此，在“无暴露的因果效应”这一零假设下，一旦我们对所有[混淆变量](@entry_id:199777)进行分层控制，暴露与结局在各层内应**条件独立 (conditionally independent)**，即 $E \perp D \mid Z$。[@problem_id:4808923]

### Mantel-Haenszel 估计：汇总效应的机制

当我们确认了各层内的关联度量（如比值比）摆脱了混淆的影响后，下一个问题便是：如果各层内的关联强度是相似的，我们应如何将这些层特异性的信息合并，以得到一个单一、稳定且精确的汇总效应估计值？这正是 Mantel-Haenszel (MH) 方法所要解决的核心问题。

#### 条件推断的基石：[超几何分布](@entry_id:193745)

Mantel-Haenszel 方法的理论根基在于**条件推断 (conditional inference)**。在分析每个 $2 \times 2$ 列联表时，我们假定其所有**边缘总计 (marginal totals)** 是固定的。在一个典型的分层 $2 \times 2$ 表中，对于第 $i$ 层，这些边缘总计包括暴露组人数 ($n_{1i} = a_i+b_i$)、非暴露组人数 ($n_{0i} = c_i+d_i$)、病例数 ($m_{1i} = a_i+c_i$) 和非病例数 ($m_{0i} = b_i+d_i$)。[@problem_id:4808962]

为什么要以边缘总计为条件？这样做可以将与各层基线风险和暴露比例相关的**滋扰参数 (nuisance parameters)** 从分析中消除，使我们能够专注于估计我们唯一感兴趣的参数——关联度量，如比值比。

一旦边缘总计被固定，整个 $2 \times 2$ 表的四个单元格数值就不再是完全自由的。事实上，只要确定了其中任何一个单元格的数值（通常选择暴露病例数 $a_i$），其他三个单元格的数值也就随之确定。[@problem_id:4924690] 在此条件下，我们可以把问题想象成一个经典的抽样模型：在一个罐子里装有 $n_i$ 个球，其中 $m_{1i}$ 个是“病例”球，$m_{0i}$ 个是“非病例”球。我们从中不放回地抽取 $n_{1i}$ 个球（代表暴露组）。那么，抽出的这 $n_{1i}$ 个球中恰好有 $a_i$ 个是“病例”球的概率是多少？

这个概率由**[超几何分布](@entry_id:193745) (hypergeometric distribution)** 描述。在暴露与结局无关联的零假设（即 $OR=1$）下，观察到 $a_i$ 个暴露病例的概率为：
$$ P(A_i = a_i \mid n_{1i}, m_{1i}, n_i; OR=1) = \frac{\binom{m_{1i}}{a_i} \binom{m_{0i}}{n_{1i}-a_i}}{\binom{n_i}{n_{1i}}} $$
这个分布完全由边缘总计决定，不依赖任何未知参数。它为 Mantel-Haenszel 检验和估计提供了计算[期望值](@entry_id:150961)和方差的理论基础。[@problem_id:4808962] [@problem_id:4924690]

#### 常见效应指标的 Mantel-Haenszel 估计量

Mantel-Haenszel 方法的一个核心前提是假定各层间的效应度量是**同质的 (homogeneous)**，即存在一个跨层恒定的**共同效应 (common effect)**。MH 估计量正是为了估计这个共同效应而设计的。

**共同比值比 (Common Odds Ratio, $OR_{MH}$)**

MH 共同比值比的估计公式如下：
$$ \hat{OR}_{MH} = \frac{\sum_{i=1}^{K} \frac{a_i d_i}{n_i}}{\sum_{i=1}^{K} \frac{b_i c_i}{n_i}} $$
其中，$a_i, b_i, c_i, d_i$ 是第 $i$ 层的四个单元格频数，$n_i$ 是该层的总人数，$K$ 是总层数。[@problem_id:4809013]

这个公式并非简单地对各层的比值比 $\hat{OR}_i = \frac{a_i d_i}{b_i c_i}$ 进行算术平均。实际上，$\hat{OR}_{MH}$ 是一个加权平均值。通过简单的代数变换可以发现，其权重 $w_i$ 正比于 $\frac{b_i c_i}{n_i}$。这意味着，那些包含更多“不一致”配对信息（即暴露的非病例和非暴露的病例）且样本量较大的层，在汇总估计中会获得更大的权重。因此，$\hat{OR}_{MH}$ 通常不等于各层比值比的简单平均值。[@problem_id:4924587]

**共同风险比 (Common Risk Ratio, $RR_{MH}$) 和共同风险差 (Common Risk Difference, $RD_{MH}$)**

Mantel-Haenszel 的思想同样可以推广到其他效应度量。

对于**共同风险比**，其标准公式如下：
$$ \hat{RR}_{MH} = \frac{\sum_{i=1}^{K} a_i n_{0i} / n_i}{\sum_{i=1}^{K} c_i n_{1i} / n_i} $$
这里，$n_{1i}$ 和 $n_{0i}$ 分别是第 $i$ 层暴露组和非暴露组的人数。[@problem_id:4924662]

对于**共同风险差**，其估计量是一个对层特异性风险差 $(\frac{a_i}{n_{1i}} - \frac{c_i}{n_{0i}})$ 的加权平均。其权重 $w_i = \frac{n_{1i}n_{0i}}{n_{1i}+n_{0i}}$ 源于对最优“逆方差权重”的一种稳健近似。这种权重仅依赖于样本量，避免了在小样本中因[估计风险](@entry_id:139340)不稳所带来的问题。[@problem_id:4924619]
$$ \hat{RD}_{MH} = \frac{\sum_{i=1}^{K} \left(\frac{n_{1i} n_{0i}}{n_{1i}+n_{0i}}\right) \left(\frac{a_i}{n_{1i}} - \frac{c_i}{n_{0i}}\right)}{\sum_{i=1}^{K} \left(\frac{n_{1i} n_{0i}}{n_{1i}+n_{0i}}\right)} $$

### Cochran-Mantel-Haenszel 检验：关联性的假设检验

除了估计汇总效应的大小，我们通常还需要检验该效应是否存在统计学意义。**Cochran-Mantel-Haenszel (CMH) 检验**正是为此设计的，它用于检验在控制了分层变量后，暴露与结局之间是否存在关联。其零假设是共同比值比为 $1$（$H_0: OR=1$）。

CMH 检验的核心思想是比较在所有层中观察到的暴露病例总数 ($\sum a_i$) 与在零假设下期望的暴露病例总数 ($\sum E[a_i]$) 之间的差异。检验统计量 $T$ 的构造如下：
$$ T = \frac{\left( \sum_{i=1}^{K} (a_i - E[a_i]) \right)^2}{\sum_{i=1}^{K} \operatorname{Var}(a_i)} $$
这里，[期望值](@entry_id:150961) $E[a_i]$ 和方差 $\operatorname{Var}(a_i)$ 是在以边缘总计为条件的[超几何分布](@entry_id:193745)下计算的：[@problem_id:4809039]
- **[期望值](@entry_id:150961)**: $E[a_i] = \frac{n_{1i} m_{1i}}{n_i}$
- **方差**: $\operatorname{Var}(a_i) = \frac{n_{1i} n_{0i} m_{1i} m_{0i}}{n_i^2 (n_i - 1)}$

统计量 $T$ 的分子是在汇总了所有层的“观测值减[期望值](@entry_id:150961)”的偏差之后再进行平方，这体现了对各层关联方向一致性的考量。分母则是这些偏差总和的方差。根据[中心极限定理](@entry_id:143108)，在样本量足够大时，该统计量近似服从自由度为 $1$ 的**卡方分布 ($\chi^2_1$)**。我们可以通过将计算出的 $T$ 值与 $\chi^2_1$ 分布进行比较来获得 $p$ 值。一个显著的 $p$ 值意味着我们有理由拒绝零假设，认为暴露与结局之间存在统计学上显著的关联。[@problem_id:4809039]

这个检验的逻辑与以下事实紧密相关：在零假设下，层内交叉乘积之差的[期望值](@entry_id:150961)为零，即 $E[a_i d_i - b_i c_i] = 0$。这为比较观测值 $a_i$ 与其[期望值](@entry_id:150961)提供了另一种理论支持。[@problem_id:4808923]

### 关键议题与高级概念

正确应用 Mantel-Haenszel 方法需要理解其前提假设和一些微妙的统计学特性。

#### 效应修饰与混淆的辨析

到目前为止，我们都假设各层间的效应是同质的。然而，在现实中，暴露与结局之间的关联强度很可能随第三变量（即分层变量）的水平而变化。这种情况被称为**效应修饰 (effect modification)** 或**[交互作用](@entry_id:164533) (interaction)**。

效应修饰和混淆是两个截然不同的概念：
- **混淆**是一种需要被消除的**偏倚 (bias)**。
- **效应修饰**是描述关联本质的一种**真实特征**，是我们希望发现和报告的重要科学现象。

例如，某药物对高危人群的保护效果可能远大于其对低危人群的效果。在这种情况下，基因型、年龄等变量就是效应修饰因子。我们观察到的层特异[性比](@entry_id:172643)值比（或风险比）存在显著差异，例如在一层中 $OR=4.0$，而在另一层中 $OR=2.0$。[@problem_id:4808966]

当存在显著的效应修饰时，计算一个像 $\hat{OR}_{MH}$ 这样的汇总效应估计值是没有意义的，甚至是误导性的，因为它掩盖了效应在不同亚组间的真实差异。此时，正确的做法是分别报告各个层特异性的效应估计值，并承认该关联的异质性。[@problem_id:4808966]

#### 效应[同质性](@entry_id:636502)的检验：Breslow-Day 检验

我们如何从数据中判断是否存在效应修饰呢？**Breslow-Day 检验**提供了一个正式的[假设检验](@entry_id:142556)方法，用于评估各层比值比的同质性。其零假设为：
$$ H_0: OR_1 = OR_2 = \dots = OR_K $$
该检验的基本思想是，在假定存在一个共同比值比（通常用 $\hat{OR}_{MH}$ 来估计）的前提下，计算每个单元格的期望频数，然后将观测频数与期望频数进行比较。其[检验统计量](@entry_id:167372) $Q_{BD}$ 类似于一个 Pearson 卡方统计量，由各层“观测值-[期望值](@entry_id:150961)”的标准化平方和构成。在零假设下，$Q_{BD}$ 近似服从自由度为 $K-1$ 的[卡方分布](@entry_id:165213)。[@problem_id:4809007]

Breslow-Day 检验的 $p$ 值如果很小（例如，小于 $0.05$），则表明我们有证据拒绝同质性假设，即效应修饰很可能存在。反之，一个不显著的 $p$ 值则支持使用 Mantel-Haenszel 方法来计算一个共同效应的汇总估计。因此，在进行分层分析时，一个标准的流程是：首先进行[同质性](@entry_id:636502)检验，然后根据检验结果决定是报告汇总效应还是层特异性效应。[@problem_id:4808966]

#### 比值比的不可合并性

最后，我们需要了解比值比的一个独特的数学特性，即**不可合并性 (non-collapsibility)**。这意味着，即使在**完全没有混淆**的情况下，只要层间的基线风险不同且共同比值比不等于 $1$，粗略比值比也通常不等于层特异性的共同比值比。

考虑一个特殊场景：分层变量 $Z$ 与暴露 $E$ 完全无关，因此 $Z$ 不是一个[混淆变量](@entry_id:199777)。然而，如果 $Z$ 与结局 $D$ 相关（即各层的基线风险不同），我们会发现，从合并数据中计算出的粗略比值比仍然会偏离层内那个恒定的共同比值比。这种偏差并非源于混淆，而是比值比这一数学度量自身的非线性特性所致。[@problem_id:4809042]

相比之下，风险比 (RR) 和风险差 (RD) 在没有混淆的情况下是**可合并的 (collapsible)**。这一特性使得比值比的解释有时会更加复杂。在报告一个经调整的 Mantel-Haenszel 比值比时，我们必须清楚，它所估计的是在特定分层条件下的条件效应，这个值即使在理想情况下也可能与未分层的[边际效应](@entry_id:634982)有所不同。

综上所述，Mantel-Haenszel 分层分析是一个强大而精妙的工具。它不仅提供了一种控制混淆的有效方法，还促使我们深入思考效应同质性、效应修饰以及不同关联度量自身独特的数学属性。掌握这些原理与机制，是进行严谨、准确的流行病学与生物统计学研究的关键。