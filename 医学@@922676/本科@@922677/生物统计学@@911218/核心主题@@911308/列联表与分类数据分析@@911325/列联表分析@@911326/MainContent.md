## 引言
在生物统计学及众多科学领域中，我们常常需要探究分类变量之间的关系，例如，一种新疗法（治疗组/[对照组](@entry_id:188599)）是否与患者的康复状况（康复/未康复）相关联？**列联表分析**（Contingency Table Analysis）正是为解决这类问题而设计的核心统计方法。它提供了一个强大而灵活的框架，用于组织、总结和分析[分类数据](@entry_id:202244)，从而揭示变量间潜在的依赖关系。然而，表面上的关联可能具有误导性，背后可能隐藏着混杂因素或更复杂的[交互作用](@entry_id:164533)，这构成了数据分析中的一个关键挑战。本文旨在系统性地引导您掌握列联表分析的精髓。在“**原理与机制**”一章中，您将学习列联表的基本结构、关联与独立性的概念，以及执行[卡方检验](@entry_id:174175)和Fisher精确检验等核心统计推断的方法。接着，在“**应用与跨学科联系**”一章中，我们将展示这些方法如何在流行病学、生存分析、基因组学和机器学习等前沿领域中解决实际问题。最后，“**动手实践**”部分将通过具体的练习，巩固您从理论到实践的分析能力。

## 原理与机制

### [列联表](@entry_id:162738)的结构与解释

在生物统计学分析中，我们经常遇到需要研究两个或多个分类变量之间关系的情况。组织这类数据的标准方法是使用**[列联表](@entry_id:162738)**（contingency table）。本节将阐述列联表的基本结构及其解释。

#### 单元格计数与边际计数

假设我们有一个包含 $n$ 个独立观测值的样本，每个观测值都根据两个分类变量进行交叉分类。第一个变量有 $r$ 个水平（构成表的行），第二个变量有 $c$ 个水平（构成表的列）。

- **单元格计数（Cell Counts）**: 计数值 $n_{ij}$ 表示同时属于行变量第 $i$ 个类别和列变量第 $j$ 个类别的观测数量。由于 $n_{ij}$ 是计数，它必须是非负整数。

- **边际计数（Marginal Counts）**:
    - **行和（Row Margins）**: 第 $i$ 行的总计数，记为 $n_{i+}$，是通过对该行所有单元格的计数求和得到的：$n_{i+} = \sum_{j=1}^{c} n_{ij}$。它表示属于行变量第 $i$ 个类别的观测总数，无论其列类别如何。
    - **列和（Column Margins）**: 第 $j$ 列的总计数，记为 $n_{+j}$，是通过对该列所有单元格的计数求和得到的：$n_{+j} = \sum_{i=1}^{r} n_{ij}$。它表示属于列变量第 $j$ 个类别的观测总数，无论其行类别如何。

- **总计数（Grand Total）**: 样本的总大小 $n$ 是所有单元格计数的总和。同样，它也等于所有行和的总和，或所有列和的总和。这些关系是列联表结构的基本约束 [@problem_id:4905077]。
$$ n = \sum_{i=1}^{r} \sum_{j=1}^{c} n_{ij} = \sum_{i=1}^{r} n_{i+} = \sum_{j=1}^{c} n_{+j} $$

#### 联合比例与条件比例

原始计数对于理解数据的分布至关重要，但将它们转换为比例有助于比较不同大小的样本或组。我们可以计算三种主要类型的比例 [@problem_id:4905114]。

- **联合比例（Joint Proportions）**: 单元格 $(i,j)$ 的联合比例 $\hat{p}_{ij}$ 是其计数 $n_{ij}$ 除以总计数 $n$：
$$ \hat{p}_{ij} = \frac{n_{ij}}{n} $$
这个比例估计了从总体中随机抽取一个个体，其同时属于行类别 $i$ 和列类别 $j$ 的概率。所有联合比例的总和为 1。对类别进行重新标记或交换行列变量的角色（即转置表格）不会改变联合比例值的集合，只会改变它们的排列方式。

- **条件比例（Conditional Proportions）**: 当我们想要研究一个变量在另一个变量的特定水平下的分布时，条件比例非常有用。
    - **行条件比例（Row-Conditional Proportions）**: 给定观测值属于行 $i$，它属于列 $j$ 的条件比例为：
    $$ \hat{p}_{j|i} = \frac{n_{ij}}{n_{i+}} $$
    这估计了条件概率 $P(\text{列}=j | \text{行}=i)$。对于每一行 $i$，这些比例的总和为 1 ($\sum_{j=1}^{c} \hat{p}_{j|i} = 1$)。行条件分布在比较不同行类别之间的列变量分布时特别有用。例如，在比较不同治疗组（行）的疾病结果（列）时。
    - **列条件比例（Column-Conditional Proportions）**: 给定观测值属于列 $j$，它属于行 $i$ 的条件比例为：
    $$ \hat{p}_{i|j} = \frac{n_{ij}}{n_{+j}} $$
    这估计了[条件概率](@entry_id:151013) $P(\text{行}=i | \text{列}=j)$。对于每一列 $j$，这些比例的总和为 1 ($\sum_{i=1}^{r} \hat{p}_{i|j} = 1$)。列条件分布在比较不同列类别之间的行变量分布时很有用，例如，在病例对照研究中比较病例组和[对照组](@entry_id:188599)（列）的暴露状态（行）分布。

重要的是要认识到，行条件比例和列条件比例回答了不同的科学问题，并且通常不相等。例如，在一项研究吸烟与呼吸系统疾病的关联中，吸烟者中患病的比例（行条件比例）与患病者中吸烟的比例（列条件比例）是两个不同的概念。将表格[转置](@entry_id:142115)会使行条件分布与列条件分布的角色互换 [@problem_id:4905114]。

### 关联与独立性的概念

[列联表](@entry_id:162738)分析的核心目标是确定两个分类变量之间是否存在**关联（association）**。关联的反面是**[统计独立性](@entry_id:150300)（statistical independence）**。

#### [统计独立性](@entry_id:150300)的定义

从概率论的角度来看，两个分类变量 $X$（行）和 $Y$（列）是独立的，当且仅当它们的联合概率等于它们各自[边际概率](@entry_id:201078)的乘积。令 $p_{ij} = P(X=i, Y=j)$ 为总体中的联合概率，$p_{i+} = P(X=i)$ 和 $p_{+j} = P(Y=j)$ 为[边际概率](@entry_id:201078)。独立性意味着 [@problem_id:4905059]：
$$ p_{ij} = p_{i+} p_{+j} \quad \text{对于所有 } i, j $$
直观地，这表示一个变量的概率分布不受另一个变量水平的影响。例如，如果 $X$ 和 $Y$ 独立，那么在给定 $X=i$ 的条件下 $Y=j$ 的条件概率就等于 $Y=j$ 的[边际概率](@entry_id:201078)：
$$ P(Y=j | X=i) = \frac{p_{ij}}{p_{i+}} = \frac{p_{i+} p_{+j}}{p_{i+}} = p_{+j} $$

#### 关联的度量：风险差、风险比与优势比

当变量不独立时，我们就说它们之间存在关联。对于流行病学研究中常见的 $2 \times 2$ 表，有三种主要的关联度量，用于量化暴露（例如，治疗组与[对照组](@entry_id:188599)）与[二元结果](@entry_id:173636)（例如，成功与失败）之间的关联强度 [@problem_id:4905101]。

假设我们有两个组（$g=1$ 为暴露组，$g=0$ 为非暴露组），以及它们发生某个结果的风险（概率）分别为 $p_1$ 和 $p_0$。在一个样本量为 $n_1=a+b$ 的暴露组中，有 $a$ 个结果和 $b$ 个非结果；在一个样本量为 $n_0=c+d$ 的非暴露组中，有 $c$ 个结果和 $d$ 个非结果。

1.  **风险差（Risk Difference, RD）**:
    - 总体定义: $\text{RD} = p_1 - p_0$
    - 样本估计: $\widehat{\text{RD}} = \frac{a}{a+b} - \frac{c}{c+d}$
    - 风险差衡量的是绝对效应大小。它的取值范围是 $[-1, 1]$。$\text{RD}=0$ 表示没有关联。

2.  **风险比（Risk Ratio, RR）**，也称为相对风险:
    - 总体定义: $\text{RR} = \frac{p_1}{p_0}$
    - 样本估计: $\widehat{\text{RR}} = \frac{a/(a+b)}{c/(c+d)}$
    - 风险比衡量的是相对效应大小。它的取值范围是 $[0, \infty]$。$\text{RR}=1$ 表示没有关联。

3.  **优势比（Odds Ratio, OR）**:
    - 总体定义: $\text{OR} = \frac{p_1/(1-p_1)}{p_0/(1-p_0)}$
    - 样本估计: $\widehat{\text{OR}} = \frac{ad}{bc}$
    - **优势（Odds）**是事件发生的概率与不发生的概率之比，即 $p/(1-p)$。优势比是暴露组的优势与非暴露组的优势之比。它的取值范围也是 $[0, \infty]$，$\text{OR}=1$ 表示没有关联。优势比在病例对照研究中尤为重要，并且具有良好的数学性质，例如在对数尺度上对称。

#### 独立性的对数[线性模型](@entry_id:178302)视角

理解关联的另一个强大框架是**对数[线性模型](@entry_id:178302)（loglinear model）**。该模型将[联合概率](@entry_id:266356) $p_{ij}$ 的对数表示为各个效应的总和：
$$ \ln(p_{ij}) = \mu + \lambda_{i}^{X} + \lambda_{j}^{Y} + \lambda_{ij}^{XY} $$
其中 $\mu$ 是总均值项，$\lambda_{i}^{X}$ 和 $\lambda_{j}^{Y}$ 分别是变量 $X$ 和 $Y$ 的**主效应（main effects）**，而 $\lambda_{ij}^{XY}$ 是**[交互效应](@entry_id:164533)（interaction effect）**项。

[统计独立性](@entry_id:150300)的定义 $p_{ij} = p_{i+}p_{+j}$ 在对数尺度上变为 $\ln(p_{ij}) = \ln(p_{i+}) + \ln(p_{+j})$。这个方程的形式表明，$\ln(p_{ij})$ 可以表示为一个只依赖于 $i$ 的项与一个只依赖于 $j$ 的项之和。这与对数线性模型中[交互效应](@entry_id:164533)项 $\lambda_{ij}^{XY}$ 全部为零的情况完[全等](@entry_id:194418)价。因此，检验独立性就等同于检验对数[线性模型](@entry_id:178302)中的[交互效应](@entry_id:164533)是否为零 [@problem_id:4905059]。

### 独立性假设检验

在实践中，我们很少能直接观察到总体概率。相反，我们使用样本数据来检验独立性假设。这个过程的核心是将观测到的数据与在“无关联”（即独立）的零假设下预期的数据进行比较。

#### 零假设与[期望计数](@entry_id:162854)

[独立性检验](@entry_id:165431)的**零假设（null hypothesis, $H_0$）**是两个[分类变量](@entry_id:637195)在总体中是相互独立的。如上所述，这意味着 $p_{ij} = p_{i+}p_{+j}$。

要在样本数据中应用这一原则，我们首先需要估计未知的[边际概率](@entry_id:201078) $p_{i+}$ 和 $p_{+j}$。在多项式抽样模型下，这些概率的**最大似然估计（Maximum Likelihood Estimates, MLEs）**就是样本的边际比例 [@problem_id:4905091]：
$$ \hat{p}_{i+} = \frac{n_{i+}}{n} \quad \text{和} \quad \hat{p}_{+j} = \frac{n_{+j}}{n} $$
将这些估计值代入独立性公式，我们得到在零假设下单元格 $(i,j)$ 的**[期望计数](@entry_id:162854)（expected count）**的估计值，记为 $E_{ij}$：
$$ E_{ij} = n \times \hat{p}_{i+} \times \hat{p}_{+j} = n \left( \frac{n_{i+}}{n} \right) \left( \frac{n_{+j}}{n} \right) = \frac{n_{i+} n_{+j}}{n} $$
这个公式的有效性建立在以下假设之上：(1) 总体满足行变量和列变量的独立性；(2) 样本由 $n$ 个独立观测组成。此公式的推导不要求行或列的总数在研究设计中被预先固定 [@problem_id:4905091]。

#### [Pearson卡方检验](@entry_id:272929)与[似然比检验](@entry_id:268070)

一旦我们有了观测计数 $n_{ij}$ 和[期望计数](@entry_id:162854) $E_{ij}$，我们就可以量化它们之间的差异。两种最常见的[检验统计量](@entry_id:167372)是Pearson卡方统计量和[似然比](@entry_id:170863)统计量 [@problem_id:4905105]。

1.  **Pearson卡方统计量 ($X^2$)**: 该统计量计算每个单元格中观测值与[期望值](@entry_id:150961)之差的平方，并用[期望值](@entry_id:150961)进行标准化，然后将所有单元格的这些值相加：
    $$ X^2 = \sum_{i=1}^{r} \sum_{j=1}^{c} \frac{(n_{ij} - E_{ij})^2}{E_{ij}} $$
    $X^2$ 值越大，表示观测数据与独立性假设的偏离越大。

2.  **似然比统计量 ($G^2$)**: 该统计量源于[似然比检验](@entry_id:268070)理论，比较了[饱和模型](@entry_id:150782)（允许关联存在）与独立模型（强制无关联）的[拟合优度](@entry_id:637026)。其计算公式为：
    $$ G^2 = 2 \sum_{i=1}^{r} \sum_{j=1}^{c} n_{ij} \ln\left(\frac{n_{ij}}{E_{ij}}\right) $$
    其中 $\ln$ 是自然对数。与 $X^2$ 类似，$G^2$ 值越大，反对独立性假设的证据就越强。

在零假设成立的条件下，当样本量足够大时，这两个统计量都近似服从**卡方（chi-squared, $\chi^2$）分布**。对于一个 $r \times c$ 的列联表，这个分布的**自由度（degrees of freedom, df）**为：
$$ \text{df} = (r-1)(c-1) $$
我们可以将计算出的 $X^2$ 或 $G^2$ 值与具有相应自由度的 $\chi^2$ 分布的临界值进行比较，以获得一个 p 值，从而判断关联的统计显著性。

例如，考虑一个 $2 \times 3$ 的表格，其行和分别为 $30, 30$，列和分别为 $15, 21, 24$，总样本量为 $60$。[期望计数](@entry_id:162854)可以通过 $E_{ij} = n_{i+}n_{+j}/n$ 计算。例如，$E_{11} = (30 \times 15) / 60 = 7.5$。如果观测计数为 $n_{11}=8, n_{12}=12, n_{13}=10$ 和 $n_{21}=7, n_{22}=9, n_{23}=14$，我们可以计算出 $X^2 \approx 1.162$ 和 $G^2 \approx 1.167$。这两个值都应与自由度为 $(2-1)(3-1)=2$ 的 $\chi^2$ 分布进行比较 [@problem_id:4905105]。

#### Fisher[精确检验](@entry_id:178040)

卡方检验是**渐近（asymptotic）**检验，其有效性依赖于大样本量。具体来说，当[期望计数](@entry_id:162854) $E_{ij}$ 很小时（通常以小于 5 为准则），$\chi^2$ 近似可能不准确。在这种情况下，特别是在 $2 \times 2$ 表中，应使用**Fisher[精确检验](@entry_id:178040)（Fisher's exact test）**。

Fisher[精确检验](@entry_id:178040)不依赖于[渐近理论](@entry_id:162631)。它通过将行和与列和都视为固定，来计算在零假设（无关联）下观察到当前表格或“更极端”表格的确切概率。在给定的边际和下，单元格 $(1,1)$ 的计数 $a$ 服从**[超几何分布](@entry_id:193745)（hypergeometric distribution）** [@problem_id:4905055]。

对于一个 $2 \times 2$ 表，其行和为 $r_1, r_2$，列和为 $c_1, c_2$，总数为 $N$，观察到单元格 $(1,1)$ 计数为 $a$ 的概率是：
$$ P(A=a) = \frac{\binom{r_1}{a} \binom{r_2}{c_1-a}}{\binom{N}{c_1}} $$
**p 值（p-value）**是通过将与观测结果同样极端或更极端的所有可能表格的概率相加来计算的。“更极端”的方向取决于备择假设。
- **单侧 p 值**: 如果[备择假设](@entry_id:167270)是正向关联（例如，OR > 1），则 p 值是观察到当前计数值 $a_{obs}$ 或更大值的概率之和：$P(A \ge a_{obs})$。
- **双侧 p 值**: 计算双侧 p 值有几种方法。一种常见的方法是，将所有概率小于或等于观测表格概率的表格的概率相加。

Fisher精确检验提供了关于关联显著性的精确推断，无需样本量假设，是小样本分析的黄金标准。

### 关联强度的量化

虽然假设检验告诉我们关联是否可能由随机机会引起，但它并未衡量关联的强度。为此，我们需要关联度量。

对于 $2 \times 2$ 表，我们已经讨论了 RD、RR 和 OR。对于更一般的 $r \times c$ 表，一些常用的度量是基于 $X^2$ 统计量 [@problem_id:4905099]。

- **Phi 系数 ($\phi$)**: 专为 $2 \times 2$ 表设计，定义为：
$$ \phi = \sqrt{\frac{X^2}{n}} $$
$\phi$ 的值在 $-1$ 和 $1$ 之间，类似于相关系数。

- **Cramér's V**: 这是 $\phi$ 系数对 $r \times c$ 表的推广。它通过将 $X^2$ 除以其可能的最大值进行标准化，取值范围为 0 到 1，其中 0 表示无关联，1 表示完全关联。
$$ V = \sqrt{\frac{X^2}{n \min(r-1, c-1)}} $$
对于 $2 \times 2$ 表，$\min(r-1, c-1) = 1$，因此 $V = \phi$。这些度量的一个重要特性是，它们对样本量具有不变性。例如，如果将[列联表](@entry_id:162738)中的所有单元格计数加倍，总样本量 $n$ 和 $X^2$ 值都会加倍，但 $\phi$ 和 $V$ 的值保持不变 [@problem_id:4905099]。

- **[互信息](@entry_id:138718)（Mutual Information, $I$）**: 这个来[自信息](@entry_id:262050)论的度量，量化了一个变量的信息能够减少另一个变量不确定性的程度。其样本估计值为：
$$ I = \sum_{i,j} \hat{p}_{ij} \ln\left(\frac{\hat{p}_{ij}}{\hat{p}_{i+}\hat{p}_{+j}}\right) $$
$I=0$ 表示独立，值越大表示关联越强。

### 分层分析：混杂与效应修饰

在许多研究中，两个变量之间的关系可能会受到第三个变量（或多个变量）的影响。忽略这样一个变量可能会导致错误的结论。**分层（stratification）**是一种基本策略，通过在第三个变量的每个水平上分别检查原始关联来进行控制。

假设我们正在研究暴露 $E$ 和疾病 $D$ 之间的关联，并且我们怀疑第三个变量 $Z$ 可能在起作用。我们可以根据 $Z$ 的每个水平（或 stratum）将数据分成多个列联表。这种分析可以揭示两种重要现象：**混杂（confounding）**和**效应修饰（effect modification）**。我们通常使用优势比（OR）来评估这些现象 [@problem_id:4905058]。

#### 效应修饰

当 $E$ 与 $D$ 之间的关联强度或方向在 $Z$ 的不同水平上发生变化时，就存在**效应修饰**（也称为**[交互作用](@entry_id:164533), interaction**）。

- **识别**: 我们计算每个 stratum 内的特定优势比（stratum-specific ORs）。如果这些 OR 值彼此之间存在显著差异，我们就得出结论，$Z$ 是一个效应修饰因子。这违反了**效应[同质性](@entry_id:636502)（homogeneity of effect）**的假设。
- **处理**: 如果存在效应修饰，报告一个单一的、汇总的关联度量是具有误导性的。正确的做法是分别报告每个 stratum 的关联度量，以充分描述这种复杂的相互作用。例如，在数据集 $\mathcal{B}$ 的一项假设研究中，一个 stratum 的 OR 可能为 0.26（保护性），而另一个 stratum 的 OR 为 2.25（风险性），这清楚地表明效应修饰 [@problem_id:4905058]。

#### 混杂

当第三个变量 $Z$ 同时与暴露 $E$ 和结果 $D$ 相关，并且不是 $E$ 到 $D$ 因果路径上的中间环节时，就会发生**混杂**。混杂因子会扭曲 $E$ 和 $D$ 之间的表观关联。

- **识别**: 如果各 stratum 的优势比是相似的（即满足效应同质性），但它们与忽略分层而计算出的**粗略优势比（crude OR）**显著不同，那么就存在混杂。
- **处理**: 分层是一种控制混杂的方法。通过计算一个**调整后的（adjusted）**或**汇总的（pooled）**优势比（例如 Mantel-Haenszel 优势比），我们可以得到一个不受[混杂变量](@entry_id:199777) $Z$ 扭曲的关联度量。例如，在数据集 $\mathcal{A}$ 的一项假设研究中，每个 stratum 内的 OR 均为 1.0（无关联），但粗略的 OR 却约为 3.48。这种差异是混杂的典型标志。调整后的估计值（1.0）揭示了真实的潜在关系 [@problem_id:4905058]。

#### 辛普森悖论

**辛普森悖论（Simpson's Paradox）**是混杂的一个极端且引人注目的例子。当在每个子组（stratum）中都表现出某种方向的关联，但在汇总（聚合）数据时，该关联却逆转方向时，就会发生这种悖论 [@problem_id:4905112]。

例如，考虑一项评估某种治疗（T）与对照（C）对成功结果（Y=1）影响的研究，并按基线风险（Z=L 为低风险，Z=H 为高风险）分层。
- 在低风险组（Z=L）中，治疗组的成功率可能高于[对照组](@entry_id:188599)（例如，OR = 1.71 > 1）。
- 在高风险组（Z=H）中，治疗组的成功率也可能高于[对照组](@entry_id:188599)（例如，OR = 1.5 > 1）。

然而，当汇总数据时，我们可能会发现治疗组的总成功率低于[对照组](@entry_id:188599)（例如，OR = 0.56  1），似乎治疗是有害的。

这种逆转之所以发生，是因为[混杂变量](@entry_id:199777) $Z$ 的分布在治疗组和[对照组](@entry_id:188599)之间极不平衡。在 [@problem_id:4905112] 的例子中，大多数接受治疗的患者属于低风险组，而大多数[对照组](@entry_id:188599)患者属于高风险组。因此，粗略的比较实际上是在将“低风险的治疗组”与“高风险的[对照组](@entry_id:188599)”进行比较，这种比较存在严重偏差，并产生了误导性的结论。辛普森悖论有力地说明了在分析观察性数据时，仔细考虑和控制潜在[混杂变量](@entry_id:199777)的至关重要性。