## 引言
在随机对照试验（RCT）的领域中，一个核心的挑战在于如何处理理论设计与现实执行之间的鸿沟。研究者精心设计了治疗方案并随机分配给受试者，但在实际过程中，受试者可能因为各种原因未能完全遵守——他们可能中断治疗、更换药物或依从性不佳。这种“不依从性”引出了一个关键的分析难题：我们应该评估“被指定接受某种治疗”这一公共卫生策略的效果，还是应该评估“实际接受并完成治疗”所带来的纯粹生物学效应？这两个截然不同的科学问题，分别催生了两种基本但至关重要的分析方法：意向性治疗（Intention-to-Treat, ITT）分析与遵循研究方案（Per-Protocol, PP）分析。

本文旨在系统性地剖析这两种分析方法。通过本文的学习，你将能够区分它们背后的核心逻辑，理解它们在不同研究场景下的优势与陷阱，并掌握如何正确解读其结果。
*   在**“原则与机制”**一章中，我们将深入探讨ITT原则如何作为维护随机化的基石，以及为何朴素的PP分析会受到选择偏倚的严重困扰。我们还将介绍因果推断框架（如潜在结局和estimands）如何帮助我们精确定义这两种分析所要估计的目标。
*   接下来，在**“应用与跨学科联系”**一章，我们将把理论付诸实践，探讨ITT和PP在优效性与[非劣效性试验](@entry_id:176667)中的不同角色，以及它们在生存分析、整群随机试验等复杂设计中的扩展应用，从而连接生物统计学、临床医学与公共卫生等多个领域。
*   最后，在**“动手实践”**部分，你将有机会通过具体问题，运用所学知识推导关键统计量，分析复杂情境，并深化对数据缺失等现实问题的理解。

通过这三个层次的递进学习，本文将为你构建一个关于ITT与PP分析的坚实知识体系，使你能够更批判性、更准确地评估临床研究的证据。

## 原则与机制

在临床试验的数据分析中，一个核心的挑战源于理想方案与现实世界行为之间的差异。研究人员随机分配受试者到不同的干预组，但受试者可能不会完全遵守分配给他们的方案。这种不依从性（non-adherence）引出了一个根本性的二元问题：我们是应该评估“分配”这一干预策略的效果，还是应该评估“实际接受”干预措施的生物学效果？这两种不同的科学问题分别导向了两种核心的分析原则：**意向性治疗（Intention-to-Treat, ITT）**和**遵循研究方案（Per-Protocol, PP）**分析。本章将深入探讨这两种原则的理论基础、机制、解释及其在现代临床试验框架下的应用。

### 意向性治疗（ITT）原则：维护随机化的基石

意向性治疗原则是随机对照试验（RCT）分析的黄金标准。其核心思想简洁而强大：**“以随机化分组为准进行分析”（analyze as you randomize）**。这意味着所有被随机化的受试者都必须在他们最初被分配的组中进行分析，无论他们实际上是否接受了分配的治疗、是否完成了治疗过程，或者是否转而接受了其他治疗。

#### ITT的原理与因果 estimand

ITT原则的首要目标是**维护随机化的完整性**。随机化的目的是在试验基线时，创造出在所有已知和未知的预后因素上平均可比的组。这种可比性，即**[交换性](@entry_id:140240)（exchangeability）**，是做出无偏因果推断的基础。任何基于受试者在随机化之后的行为（如依从性）来剔除或移动受试者的分析，都会破坏这种基线可比性，从而引入偏倚。

为了更精确地理解这一点，我们引入**潜在结局（potential outcomes）**框架。对于每个受试者，我们定义 $A \in \{0, 1\}$ 为随机分配的干预（例如，$A=1$ 为试验药物，$A=0$ 为安慰剂），$Y$ 为最终的结局。$Y^{A=a}$ 表示如果受试者被分配到组 $a$ 将会观察到的潜在结局。ITT分析旨在估计的因果量（estimand）是分配策略的**平均因果效应（Average Causal Effect, ACE）**，定义为：
$$ \Delta_{\text{ITT}} = E[Y^{A=1} - Y^{A=0}] $$
由于随机化保证了分配 $A$ 与潜在结局 $\{Y^{A=1}, Y^{A=0}\}$ 的独立性（即 $A \perp (Y^{A=1}, Y^{A=0})$），我们可以推导出：
$$ E[Y^{A=1}] = E[Y^{A=1} \mid A=1] \quad \text{和} \quad E[Y^{A=0}] = E[Y^{A=0} \mid A=0] $$
根据**一致性（consistency）**假设（即 $Y = Y^{A=a}$ 当 $A=a$ 时），观察到的组间均值差异的[期望值](@entry_id:150961)就等于该因果效应：
$$ E[Y \mid A=1] - E[Y \mid A=0] = E[Y^{A=1} \mid A=1] - E[Y^{A=0} \mid A=0] = E[Y^{A=1}] - E[Y^{A=0}] = \Delta_{\text{ITT}} $$
因此，通过比较各随机化组的结局均值，我们可以得到分配策略效果的一个无偏估计。这个估计的效力不受试验期间发生的非依从性或方案偏离的影响，因为它所评估的正是“推荐接受治疗A”与“推荐接受治疗B”这两种公共卫生或临床策略的实际效果。

#### ITT与“治疗策略”estimand

国际协调会议指导原则ICH E9(R1)的estimand框架为精确定义临床试验的科学问题提供了标准化语言。在此框架下，一个estimand由五个要素构成：**人群（population）**、**变量（variable）**、**干预（intervention）**、**对伴随事件（intercurrent events）的处理策略**和**汇总指标（summary measure）**。

ITT分析完美地对应于一种**“治疗策略”（treatment policy）** estimand。在这种策略下，诸如停药、使用补救治疗等伴随事件被视为治疗策略本身的结果，并被纳入结局的测量中。例如，在一个评估新型降糖药的糖尿病试验中，一个基于治疗策略的ITT estimand可以被定义为：

*   **人群**：所有被随机化的[2型糖尿病](@entry_id:154880)患者。
*   **变量**：从基线到第24周的糖化血红蛋白（[HbA1c](@entry_id:150571)）变化值。
*   **伴随事件处理**：采用“治疗策略”。无论患者是否停药或使用了补救治疗，都使用其在第24周观察到的HbA1c值。
*   **汇总指标**：两个随机化组之间，人群平均变化值的差异。

这种方法回答了一个非常务实的问题：“在一个存在真实世界依从性模式的群体中，实施‘开始使用新药’这一策略，相比‘开始使用安慰剂’，对结局有什么影响？”。

#### ITT效应的解释

ITT效应量化的是一种治疗**意图**或**策略**的效果，而非药物本身的纯粹生物学效应。当试验中存在非依从性时（例如，治疗组的一些人未服药，安慰剂组的一些人从外部获得了药物），ITT效应的大小通常会被“稀释”或减弱。它反映的是随机分组后所有事件（包括依从行为）共同作用下的净效应。

在某些假设下，ITT效应与依从者的平均因果效应（Complier Average Causal Effect, CACE）之间存在一个简单的关系：ITT效应等于CACE乘以依从者在人群中所占的比例。这意味着，依从性越差，ITT效应相比于药物在真正服药者身上的效应就越小。尽管如此，由于其无偏性和对现实世界的反映，ITT分析仍然是评估干预有效性的首选和主要分析。

### 遵循研究方案（PP）分析：后随机化选择的陷阱

与ITT分析相反，研究者常常希望了解干预措施在“理想”条件下的效果，即在那些完全遵循了研究方案的受试者中所产生的效果。这种探索药物**效能（efficacy）**的愿望催生了**遵循研究方案（Per-Protocol, PP）**分析或**依从者分析（as-treated）**。PP分析通常只包括那些被认为“依从”了方案的受试者，而依从者分析则根据受试者实际接受的治疗（而非被分配的治疗）来对他们进行分组比较。

#### PP分析的内在偏倚机制

尽管PP分析的目标在生物学上很有吸[引力](@entry_id:189550)，但其方法在统计学上存在严重缺陷。问题在于，**依从性本身是一个发生在随机化之后的行为**，它可能与患者的预后状况直接相关。例如，病情更重或对药物产生副作用的患者可能更倾向于停药，而感觉良好或更具健康意识的患者则可能更倾向于坚持服药。

当分析仅限于“依从者”时，我们实际上是在一个经事[后选择](@entry_id:154665)的子集上进行比较。这个选择过程破坏了最初由随机化建立的组间可比性，引入了**选择偏倚（selection bias）**。

使用**有向无环图（Directed Acyclic Graphs, DAGs）**可以清晰地揭示这一偏倚的机制。假设存在一个未测量的变量 $U$（如患者的健康状况或对药物的耐受性），它既影响患者的依从性 $S$，也影响最终的结局 $Y$。随机分配的治疗 $A$ 会影响依从性 $S$。此时，存在一条路径 $A \rightarrow S \leftarrow U \rightarrow Y$。在这个路径中，$S$ 是一个**对撞节点（collider）**，因为它同时被 $A$ 和 $U$ 的箭头指向。在不对 $S$ 进行控制时，这条路径是封闭的， $A$ 和 $U$ 是独立的（由随机化保证）。然而，当我们通过限制分析人群（例如，只分析 $S=1$ 的依从者）来对 $S$ 进行**“控制”（conditioning）**时，这个对撞节点被打开了。这会在 $A$ 和 $U$ 之间产生一个虚假的统计关联。因为 $U$ 本身是 $Y$ 的一个原因，这就人为地在 $A$ 和 $Y$ 之间打开了一条非因果的“后门路径”，导致对治疗效果的估计产生偏倚。

因此，一个看似无害的、旨在获得“更纯粹”效果估计的分析步骤，实际上可能引入了比非依从性本身更难处理的混杂偏倚。

#### 定义“方案依从性”的复杂性

“依从”或“不依从”并非一个简单的二元概念。在实际试验中，方案偏离（protocol deviation）的形式多种多样。我们可以定义一个随时间变化的依从性指标 $S(t)$，其中 $S(t)=1$ 表示在时间 $t$ 依从方案，否则为 $0$。以下情况都可能导致 $S(t)$ 变为 $0$：

*   **从未开始治疗（Never-start）**：受试者从未服用分配的药物，其 $S(t)$ 在整个试验期间始终为 $0$。
*   **永久停药（Permanent discontinuation）**：在某个时间点 $t_d$ 停止治疗并不再恢复，其 $S(t)$ 在 $[t_d, T]$ 区间内为 $0$。
*   **暂时中断（Temporary interruption）**：在一段时间内暂停治疗后又恢复，其 $S(t)$ 在中断期间为 $0$。
*   **剂量减少（Dose reduction）**：服用的剂量低于方案规定的最低有效剂量。
*   **交叉（Crossover）**：被分配到A组的患者开始服用B组的治疗。
*   **使用违禁的伴随用药（Prohibited concomitant medication）**。

这种复杂性表明，简单地将患者分为“依从者”和“非依从者”两类，本身就是一种过度简化，并可能掩盖了不同偏离行为背后的不同原因和后果。

### 现代方法：从精确定义到统计校正

鉴于朴素PP分析的内在缺陷，现代生物统计学发展了一系列更严谨的方法来回答关于药物效能的问题。这些方法的核心思想是：首先精确地定义我们想要估计的目标（estimand），然后采用合适的因果推断方法来估计它，而不是简单地对数据进行子集划分。

#### Estimand优先：区分“目标”与“方法”

ICH E9(R1)框架强调，任何分析都应始于一个明确的estimand。一个分析集（例如，PP人群）的选择只是估计方法的一部分，它本身并不能完整定义科学问题。

要严谨地定义一个“遵循方案”的效果，我们必须明确如何处理伴随事件。一种现代的方法是定义一个**“假设性”estimand（hypothetical estimand）**。它回答这样一个问题：“假如（与事实可能相反）所有受试者都能完美地依从分配给他们的治疗方案直到研究结束，那么治疗效果会是多少？” 这个estimand的目标是在整个随机化人群中估计这种假设情景下的平均因果效应。它的目标人群仍然是全部随机化受试者，从而保留了随机化的优势，但它所评估的变量（结局）是在一个反事实的、无伴随事件的假设世界中的值。

#### 主要分层（Principal Stratification）

**主要分层**是另一个处理此类问题的强大框架。它根据受试者在所有潜在治疗分配下的依从行为，将人群分为不同的“主要层次”。例如，对于依从性指标 $S(z)$（在分配 $z$ 下的依从状态），我们可以定义：

*   **始终依从者（Always-adherers）**：$S(1)=1$ 且 $S(0)=1$。
*   **依从者（Compliers）**：$S(1)=1$ 且 $S(0)=0$。
*   **逆反者（Defiers）**：$S(1)=0$ 且 $S(0)=1$。
*   **从不依从者（Never-adherers）**：$S(1)=0$ 且 $S(0)=0$。

这些分层是基于潜在（反事实）行为的，因此在随机化之前就已经确定，不受实际治疗分配的影响。一个定义良好的P[P类](@entry_id:262479)estimand可以是特定层次内的因果效应，例如，在“始终依从者”中的平均因果效应：
$$ E[Y(1) - Y(0) \mid S(1)=1, S(0)=1] $$
这种方法的挑战在于，个体的层次归属是**潜在的（latent）**，我们无法直接观测到。例如，在治疗组观察到的一个依从者，他可能是一个“始终依从者”，也可能是一个“依从者”。因此，识别并估计这些层次特异性的效应通常需要额外的假设（如“无逆反者”的**[单调性](@entry_id:143760)假设**）和更复杂的[统计模型](@entry_id:755400)。

#### 统计校正：逆概率加权

当我们的目标是估计在依从者子集中的治疗效果，同时又想避免选择偏倚时，**[逆概率](@entry_id:196307)加权（Inverse Probability Weighting, IPW）**是一种常用的统计校正方法。其基本思想是：通过对观察到的依从者进行加权，重新构建一个“伪人群”，在这个伪人群中，治疗组和[对照组](@entry_id:188599)的基线协变量分布恢复到与原始随机化人群中相同的平衡状态。

具体来说，对于每一个被纳入PP分析的受试者（即观察到 $S=1$ 的人），我们可以计算一个权重 $w$。一个**稳定的（stabilized）**权重定义为：
$$ w_{\text{stab}}(A, X) = \frac{P(S=1 \mid A)}{P(S=1 \mid A, X)} $$
其中，$X$ 是基线协变量的集合。分母是在给定治疗分配 $A$ 和协变量 $X$ 的条件下，受试者依从的概率。分母越小，说明这类特征的受试者越不容易依从，因此在PP分析中他们的代表性不足，需要被赋予更高的权重。分子是仅在给定治疗分配 $A$ 的条件下依从的[边际概率](@entry_id:201078)，用于稳定权重的方差。

**计算示例**：假设我们通过逻辑[回归模型](@entry_id:163386)得到了依从概率的模型参数。对于一个分配到治疗组（$A=1$），其基线协变量为 $X=0.75$ 的受试者，其分子概率（仅依赖于 $A$）和分母概率（依赖于 $A$ 和 $X$）的[线性预测](@entry_id:180569)值分别为 $-0.4$ 和 $-0.2$。那么，其分子和分母概率分别为：
$$ p_n(1) = P(S=1 \mid A=1) = \frac{1}{1+\exp(0.4)} $$
$$ p_d(1, 0.75) = P(S=1 \mid A=1, X=0.75) = \frac{1}{1+\exp(0.2)} $$
该受试者的稳定权重即为两者的比值：
$$ w_{\text{stab}}(1, 0.75) = \frac{p_n(1)}{p_d(1, 0.75)} = \frac{1+\exp(0.2)}{1+\exp(0.4)} \approx \frac{1+1.2214}{1+1.4918} \approx 0.8915 $$
通过对PP分析集中的每个个体应用这样的权重，我们可以在一定程度上校正因依从[性选择](@entry_id:138426)所带来的偏倚，从而得到一个更可靠的效能估计。

### 结论

总之，ITT和PP代表了[临床试验分析](@entry_id:172914)中两种不同的哲学思想和科学问题。ITT分析通过严格遵守随机化分组，为评估治疗策略的“有效性”（effectiveness）提供了无偏的估计，是所有确证性试验的基石。而对药物“效能”（efficacy）的探索，虽然极具价值，但必须谨慎处理，因为朴素的PP分析会因破坏随机化平衡而引入严重偏倚。现代因果推断方法，如精确的estimand定义、主要分层和[逆概率](@entry_id:196307)加权等，为我们提供了更严谨的工具，以探索在理想条件下的治疗效果，同时正视和处理由非依从性带来的复杂统计挑战。