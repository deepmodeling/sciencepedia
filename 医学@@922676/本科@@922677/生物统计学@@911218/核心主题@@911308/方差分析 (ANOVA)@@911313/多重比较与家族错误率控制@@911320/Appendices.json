{"hands_on_practices": [{"introduction": "我们从控制族状总错误率（Family-Wise Error Rate, FWER）最直接的方法——Bonferroni校正开始。虽然它有时可能过于保守，但其简单的原理和坚实的理论基础（布尔不等式）使其成为理解多重比较问题的完美起点。通过这个练习，你将从基本概率原理出发，推导并应用Bonferroni校正，从而牢固掌握FWER控制的核心思想。[@problem_id:4930328]", "problem": "一项转化肿瘤学研究评估了五种预先指定的血清生物标志物在病例组和对照组之间是否存在水平差异。对于每种生物标志物，通过一次假设检验得出一个未经校正的 $p$ 值。这一系列的检验需要进行联合解释，研究者希望使用 Bonferroni 原则将族错误率 (FWER) 控制在 $\\alpha=0.05$ 的水平。\n\n现给出 $m=5$ 个未经校正的 $p$ 值，按生物标志物 1 到 5 的顺序排列为：$(0.003, 0.01, 0.02, 0.04, 0.06)$。\n\n从族错误率 (FWER) 的定义（即在 $m$ 个原假设中犯至少一个 I 型错误的概率）出发，利用基本概率原理来证明一个能将 FWER 控制在水平 $\\alpha$ 的 Bonferroni 决策规则的合理性，并确定哪些原假设被拒绝。然后，计算每种生物标志物经 Bonferroni 校正后的 $p$ 值。\n\n将你的最终答案以一个包含 10 个条目的单行矩阵形式报告：前五个条目是生物标志物 1 到 5（按给定顺序）经 Bonferroni 校正后的 $p$ 值，后五个条目是使用 Bonferroni 规则在族水平 $\\alpha$ 下的拒绝指示符，其中 1 表示“拒绝”，0 表示“不拒绝”。无需四舍五入。", "solution": "此问题经评估是有效的。它在科学上基于生物统计学原理，特别是多重假设检验。问题提法得当，提供了所有必要的数据，并且使用了清晰准确的语言，因此是客观的。\n\n任务是从族错误率 (FWER) 的定义出发，证明 Bonferroni 校正的合理性，将其应用于一组给定的 $p$ 值以确定哪些原假设被拒绝，并计算相应的 Bonferroni 校正后的 $p$ 值。\n\n假设有 $m$ 个原假设，$H_{0,1}, H_{0,2}, \\dots, H_{0,m}$。对于每个假设检验 $i$，我们得到一个 $p$ 值 $p_i$。族错误率 (FWER) 定义为在 $m$ 个检验的整个族中犯至少一个 I 型错误（即拒绝一个真实的原假设）的概率。设 $E_i$ 为对第 $i$ 个假设犯 I 型错误的事件。FWER 是这些事件并集的概率：\n$$\n\\text{FWER} = P\\left(\\bigcup_{i \\in I_0} E_i\\right)\n$$\n其中 $I_0$ 是真实原假设的索引集。为了控制 FWER，我们考虑所有原假设都为真的最坏情况，即 $I_0 = \\{1, 2, \\dots, m\\}$。在这种情况下，\n$$\n\\text{FWER} = P\\left(\\bigcup_{i=1}^{m} E_i\\right)\n$$\n根据布尔不等式（也称为并集上界），事件并集的概率小于或等于它们各自概率的总和：\n$$\nP\\left(\\bigcup_{i=1}^{m} E_i\\right) \\leq \\sum_{i=1}^{m} P(E_i)\n$$\n当原假设 $H_{0,i}$ 为真时，如果我们拒绝它，就会发生第 $i$ 个检验的 I 型错误。单个检验的决策规则是，如果其 $p$ 值 $p_i$ 小于或等于某个显著性水平（我们称之为 $\\alpha_{ind}$，代表“单个”），则拒绝 $H_{0,i}$。在 $H_{0,i}$ 为真的情况下，此事件的概率就是该检验的显著性水平的定义：$P(E_i) = P(p_i \\leq \\alpha_{ind} | H_{0,i} \\text{ 为真}) = \\alpha_{ind}$。\n\n将此代入不等式，我们得到：\n$$\n\\text{FWER} \\leq \\sum_{i=1}^{m} \\alpha_{ind}\n$$\nBonferroni 方法对所有检验使用相同的单个显著性水平，因此对于所有 $i=1, \\dots, m$，$\\alpha_{ind}$ 是一个常数。不等式简化为：\n$$\n\\text{FWER} \\leq m \\cdot \\alpha_{ind}\n$$\n为了将 FWER 控制在预先指定的水平 $\\alpha$，我们必须确保不等式的右侧不大于 $\\alpha$。我们设定 $m \\cdot \\alpha_{ind} \\leq \\alpha$，这得出 $\\alpha_{ind} \\leq \\frac{\\alpha}{m}$。为了使检验力尽可能大（即使用尽可能大的单个显著性水平），我们选择 $\\alpha_{ind} = \\frac{\\alpha}{m}$。\n\n这就得到了 Bonferroni 决策规则：如果原假设 $H_{0,i}$ 的未经校正的 $p$ 值 $p_i$ 小于或等于经 Bonferroni 校正后的显著性阈值 $\\frac{\\alpha}{m}$，则拒绝该原假设。此过程保证了 $\\text{FWER} \\leq \\alpha$。\n\n现在，我们将此规则应用于给定的问题。\n假设检验的数量为 $m=5$。\n期望的族错误率为 $\\alpha=0.05$。\n经 Bonferroni 校正后的显著性阈值为 $\\alpha_{adj} = \\frac{\\alpha}{m} = \\frac{0.05}{5} = 0.01$。\n\n给出的未经校正的 $p$ 值为 $p_1=0.003$, $p_2=0.01$, $p_3=0.02$, $p_4=0.04$, $p_5=0.06$。我们将每个 $p$ 值与 $\\alpha_{adj} = 0.01$ 进行比较。\n\n1.  对于生物标志物 1：$p_1 = 0.003$。因为 $0.003 \\leq 0.01$，所以我们拒绝原假设 $H_{0,1}$。\n2.  对于生物标志物 2：$p_2 = 0.01$。因为 $0.01 \\leq 0.01$，所以我们拒绝原假设 $H_{0,2}$。\n3.  对于生物标志物 3：$p_3 = 0.02$。因为 $0.02  0.01$，所以我们不拒绝原假设 $H_{0,3}$。\n4.  对于生物标志物 4：$p_4 = 0.04$。因为 $0.04  0.01$，所以我们不拒绝原假设 $H_{0,4}$。\n5.  对于生物标志物 5：$p_5 = 0.06$。因为 $0.06  0.01$，所以我们不拒绝原假设 $H_{0,5}$。\n\n生物标志物 1 到 5 的拒绝指示符（1 表示拒绝，0 表示不拒绝）为 $(1, 1, 0, 0, 0)$。\n\n接下来，我们计算经 Bonferroni 校正后的 $p$ 值，记为 $\\tilde{p}_i$。校正后 $p$ 值的定义是，如果 $\\tilde{p}_i \\leq \\alpha$，就可以拒绝 $H_{0,i}$。原始的拒绝规则是 $p_i \\leq \\frac{\\alpha}{m}$。整理该式可得 $m \\cdot p_i \\leq \\alpha$。因此，校正后的 $p$ 值 $\\tilde{p}_i$ 是 $m \\cdot p_i$。由于概率不能超过 1，其正式定义为：\n$$\n\\tilde{p}_i = \\min(m \\cdot p_i, 1)\n$$\n我们用 $m=5$ 为每个生物标志物计算这个值：\n\n1.  $\\tilde{p}_1 = \\min(5 \\times 0.003, 1) = \\min(0.015, 1) = 0.015$.\n2.  $\\tilde{p}_2 = \\min(5 \\times 0.01, 1) = \\min(0.05, 1) = 0.05$.\n3.  $\\tilde{p}_3 = \\min(5 \\times 0.02, 1) = \\min(0.10, 1) = 0.1$.\n4.  $\\tilde{p}_4 = \\min(5 \\times 0.04, 1) = \\min(0.20, 1) = 0.2$.\n5.  $\\tilde{p}_5 = \\min(5 \\times 0.06, 1) = \\min(0.30, 1) = 0.3$.\n\n生物标志物 1 到 5 的校正后 $p$ 值为 $(0.015, 0.05, 0.1, 0.2, 0.3)$。我们可以使用这些校正后的 $p$ 值与 $\\alpha=0.05$ 比较来验证拒绝决策：\n- $\\tilde{p}_1 = 0.015 \\leq 0.05 \\implies$ 拒绝。\n- $\\tilde{p}_2 = 0.05 \\leq 0.05 \\implies$ 拒绝。\n- $\\tilde{p}_3 = 0.1  0.05 \\implies$ 不拒绝。\n- $\\tilde{p}_4 = 0.2  0.05 \\implies$ 不拒绝。\n- $\\tilde{p}_5 = 0.3  0.05 \\implies$ 不拒绝。\n这证实了之前的结论。\n\n最终答案要求一个单行矩阵，其中包含五个校正后的 $p$ 值，后跟五个拒绝指示符。\n校正后的 $p$ 值：$(0.015, 0.05, 0.1, 0.2, 0.3)$。\n拒绝指示符：$(1, 1, 0, 0, 0)$。\n\n组合后的行矩阵是 $(0.015, 0.05, 0.1, 0.2, 0.3, 1, 1, 0, 0, 0)$。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.015  0.05  0.1  0.2  0.3  1  1  0  0  0\n\\end{pmatrix}\n}\n$$", "id": "4930328"}, {"introduction": "掌握了Bonferroni校正后，我们来学习一种更强大的方法——Holm逐步递减（step-down）程序。与对所有检验使用统一严格阈值的Bonferroni方法不同，Holm方法会根据p值的大小顺序智能地调整显著性水平，从而在不增加犯第一类错误风险的前提下，提高我们正确拒绝虚假的原假设的能力。这个练习将引导你理解并实施这种更精细的序贯检验逻辑。[@problem_id:4930339]", "problem": "一位生物统计学研究者分析了$m=4$个预先指定的生物标志物与临床结局的关联，得到了排序后的$p$值：$p_{(1)}=0.004$、$p_{(2)}=0.012$、$p_{(3)}=0.02$和$p_{(4)}=0.08$。目标是使用Holm的序列拒绝降阶程序，在$\\alpha=0.05$的水平上控制族系误差率 (FWER)。请从族系误差率（至少一次错误拒绝的概率）的定义出发，并结合Bonferroni不等式以及按$p$值升序筛选假设的降阶程序的逻辑，推导出确保在$\\alpha$水平上对族系误差率进行强控制所需的逐步临界值。将您推导出的程序应用于给定的有序$p$值，以确定有多少个原假设被拒绝。请以被拒绝的原假设的整数数量$k$报告您的最终答案。", "solution": "该问题被评估为有效，因为它具有科学依据、问题明确、客观且完整。它提出了一个基于既定原则的标准生物统计学任务。\n\n任务是为用于控制族系误差率 (FWER) 的Holm序列拒绝程序推导临界值，然后将其应用于给定的数据集。\n\n**第一部分：Holm程序的推导**\n\n族系误差率 (FWER) 定义为在所有检验的假设中犯一次或多次I类错误（错误拒绝）的概率。设存在$m$个原假设 $H_1, H_2, \\dots, H_m$，其对应的$p$值为 $p_1, p_2, \\dots, p_m$。我们的目标是确保对于一个预先指定的显著性水平$\\alpha$，$FWER \\le \\alpha$。这被称为对FWER的强控制，因为它必须对任何真原假设和假原假设的组合都成立。设$V$为被错误拒绝的真原假设的数量。那么FWER就是$P(V \\ge 1)$。\n\n设$I_0$是$m_0$个真正为真的原假设的索引集。与这些假设相对应的$p$值$\\{p_i : i \\in I_0\\}$，在它们各自的原假设下，是独立同分布于Uniform$(0,1)$的随机变量。\n\nHolm程序是一种降阶法。首先，将$p$值从小到大排序：$p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(m)}$。设与这些排序后的$p$值相对应的假设为 $H_{(1)}, H_{(2)}, \\dots, H_{(m)}$。该程序如下：\n对于 $j = 1, 2, \\dots, m$，将第$j$个排序的$p$值$p_{(j)}$与临界值 $\\alpha_j = \\frac{\\alpha}{m-j+1}$进行比较。\n- 如果$p_{(1)}  \\frac{\\alpha}{m}$，则停止并且不拒绝任何假设。\n- 否则，拒绝$H_{(1)}$并继续检验$H_{(2)}$。\n- 如果$p_{(2)}  \\frac{\\alpha}{m-1}$，则停止并只拒绝$H_{(1)}$。\n- 否则，拒绝$H_{(2)}$并继续检验$H_{(3)}$。\n- 这个过程继续进行。在第$j$步，如果$p_{(j)}  \\frac{\\alpha}{m-j+1}$，程序停止，并且只拒绝假设$H_{(1)}, \\dots, H_{(j-1)}$。如果$p_{(j)} \\le \\frac{\\alpha}{m-j+1}$，则拒绝$H_{(j)}$，程序继续到第$j+1$步。\n\n为了推导和证明该程序在$\\alpha$水平上强控制FWER，我们必须证明对于任何真原假设的子集$I_0$，$P(V \\ge 1) \\le \\alpha$。\n\n设$I_0$是$m_0$个真原假设的索引集。如果我们拒绝了至少一个$i \\in I_0$的假设$H_i$，就发生了I类错误。\n设$p_{\\min,0} = \\min_{i \\in I_0} \\{p_i\\}$是所有真原假设中最小的$p$值。\n设这个特定的$p$值在整体排序列表中的秩为$k$，因此$p_{\\min,0} = p_{(k)}$。根据其定义，$H_{(k)}$是排序列表中的第一个真原假设（即假设$H_{(1)}, \\dots, H_{(k-1)}$必定是假原假设）。\n\n要发生任何I类错误，至少必须拒绝一个真原假设。因为Holm程序是序列性的，并且在第一次未能拒绝时停止，所以如果要拒绝任何真原假设$H_{(l)}$（其中$l \\ge k$），那么所有在它之前的假设，包括$H_{(k)}$，也必须已经被拒绝。因此，发生至少一次I类错误的事件等价于$H_{(k)}$被拒绝的事件。\n\n当且仅当对于所有的$j=1, \\dots, k$都有$p_{(j)} \\le \\frac{\\alpha}{m-j+1}$时，该程序才会拒绝$H_{(k)}$。\n这必然意味着$p_{(k)} \\le \\frac{\\alpha}{m-k+1}$。\n所以，如果发生I类错误，必然有$p_{(k)} \\le \\frac{\\alpha}{m-k+1}$。\n\n现在，我们将这个条件与真原假设的数量$m_0$联系起来。\n根据$p_{(k)}$是来自真原假设的最小$p$值的定义，所有$m_0$个真原假设都必须在集合$\\{H_{(k)}, H_{(k+1)}, \\dots, H_{(m)}\\}$中。这个集合的大小是$m-k+1$。\n因此，真原假设的数量不能超过这个集合的大小，这就得出了不等式$m_0 \\le m-k+1$。\n这个不等式可以重新排列为$\\frac{1}{m-k+1} \\le \\frac{1}{m_0}$。\n\n综合这些发现，发生I类错误的条件意味着：\n$p_{(k)} \\le \\frac{\\alpha}{m-k+1} \\le \\frac{\\alpha}{m_0}$。\n设$E$为发生至少一次I类错误的事件。我们已经证明了$E$的发生意味着条件$p_{(k)} \\le \\frac{\\alpha}{m_0}$成立。这意味着$E$是事件$\\{p_{(k)} \\le \\frac{\\alpha}{m_0}\\}$的一个子集。\n因此，$FWER = P(E) \\le P(p_{(k)} \\le \\frac{\\alpha}{m_0})$。\n\n回顾一下，$p_{(k)}$是来自$m_0$个真原假设的$p$值$\\{p_i : i \\in I_0\\}$中的最小值。因此，事件$\\{p_{(k)} \\le \\frac{\\alpha}{m_0}\\}$等价于这$m_0$个$p$值中至少有一个小于或等于$\\frac{\\alpha}{m_0}$的事件。我们可以将其表示为事件的并集：\n$P(p_{(k)} \\le \\frac{\\alpha}{m_0}) = P\\left( \\bigcup_{i \\in I_0} \\left\\{p_i \\le \\frac{\\alpha}{m_0}\\right\\} \\right)$。\n\n我们现在应用Bonferroni不等式（也称为Boole不等式），它指出对于任何事件集合$A_1, \\dots, A_n$，$P(\\cup_{i=1}^n A_i) \\le \\sum_{i=1}^n P(A_i)$。\n将此应用于我们的情况：\n$P\\left( \\bigcup_{i \\in I_0} \\left\\{p_i \\le \\frac{\\alpha}{m_0}\\right\\} \\right) \\le \\sum_{i \\in I_0} P\\left(p_i \\le \\frac{\\alpha}{m_0}\\right)$。\n\n对于每个真原假设$H_i$，$p$值$p_i$服从$U(0,1)$分布。因此，对于任何值$x \\in [0,1]$，$P(p_i \\le x) = x$。设$x=\\frac{\\alpha}{m_0}$，我们得到$P(p_i \\le \\frac{\\alpha}{m_0}) = \\frac{\\alpha}{m_0}$。\n将此代入总和：\n$\\sum_{i \\in I_0} P\\left(p_i \\le \\frac{\\alpha}{m_0}\\right) = \\sum_{i \\in I_0} \\frac{\\alpha}{m_0} = m_0 \\times \\frac{\\alpha}{m_0} = \\alpha$。\n\n综上所述，我们已经证明：\n$FWER = P(E) \\le P(p_{(k)} \\le \\frac{\\alpha}{m_0}) \\le \\alpha$。\n这证明了Holm程序在$\\alpha$水平上强控制FWER。推导出的逐步临界值确实是$\\alpha_j = \\frac{\\alpha}{m-j+1}$，其中$j=1, \\dots, m$。\n\n**第二部分：在给定问题上的应用**\n\n给定：\n- 假设数量：$m=4$。\n- FWER控制水平：$\\alpha=0.05$。\n- 排序后的$p$值：$p_{(1)}=0.004$，$p_{(2)}=0.012$，$p_{(3)}=0.02$，以及$p_{(4)}=0.08$。\n\n我们一步步地应用Holm程序。\n\n**第1步 ($j=1$):**\n- 检验假设$H_{(1)}$，其$p$值为$p_{(1)} = 0.004$。\n- 临界值为$\\alpha_1 = \\frac{\\alpha}{m-1+1} = \\frac{0.05}{4} = 0.0125$。\n- 我们将$p_{(1)}$与$\\alpha_1$进行比较：$0.004 \\le 0.0125$。\n- 条件满足，因此我们拒绝$H_{(1)}$并进入下一步。\n\n**第2步 ($j=2$):**\n- 检验假设$H_{(2)}$，其$p$值为$p_{(2)} = 0.012$。\n- 临界值为$\\alpha_2 = \\frac{\\alpha}{m-2+1} = \\frac{0.05}{3} \\approx 0.01667$。\n- 我们将$p_{(2)}$与$\\alpha_2$进行比较：$0.012 \\le \\frac{0.05}{3}$。\n- 条件满足，因此我们拒绝$H_{(2)}$并进入下一步。\n\n**第3步 ($j=3$):**\n- 检验假设$H_{(3)}$，其$p$值为$p_{(3)} = 0.02$。\n- 临界值为$\\alpha_3 = \\frac{\\alpha}{m-3+1} = \\frac{0.05}{2} = 0.025$。\n- 我们将$p_{(3)}$与$\\alpha_3$进行比较：$0.02 \\le 0.025$。\n- 条件满足，因此我们拒绝$H_{(3)}$并进入下一步。\n\n**第4步 ($j=4$):**\n- 检验假设$H_{(4)}$，其$p$值为$p_{(4)} = 0.08$。\n- 临界值为$\\alpha_4 = \\frac{\\alpha}{m-4+1} = \\frac{0.05}{1} = 0.05$。\n- 我们将$p_{(4)}$与$\\alpha_4$进行比较：$0.08  0.05$。\n- 条件不满足。我们未能拒绝$H_{(4)}$并停止程序。\n\n根据此程序，我们拒绝了与三个最小$p$值相对应的原假设：$H_{(1)}$、$H_{(2)}$和$H_{(3)}$。被拒绝的原假设总数为$k=3$。", "answer": "$$\\boxed{3}$$", "id": "4930339"}, {"introduction": "最后，我们转向一种现代且极其灵活的计算密集型方法——基于重抽样的置换检验（permutation test）。当检验统计量的理论分布未知或难以满足其假设时，置换检验通过数据自身的重抽样来模拟原假设下的分布，从而避免了对复杂数学公式的依赖。这个练习将带你进入计算统计学的世界，体会如何利用计算机的强大能力来解决复杂的多重检验问题。[@problem_id:4930335]", "problem": "您正在分析 $m$ 个同时进行的统计检验（原假设为 $H_1,\\dots,H_m$），其观测到的检验统计量为 $t_1,\\dots,t_m$。为了控制族错误率 (FWER)，您将使用最大统计量置换法。在完全原假设下，并假设检验统计量在标签置换下具有可交换性，所有 $m$ 个检验中的最大检验统计量（表示为 $M=\\max\\{T_1,\\dots,T_m\\}$）的分布，可以通过执行 $B$ 次标签置换并记录观测到的最大值 $M^{(1)},\\dots,M^{(B)}$ 来近似。\n\n使用的基本定义：\n- 族错误率 (FWER) 定义为在 $H_1,\\dots,H_m$ 中至少做出一次错误拒绝的概率：$FWER=\\mathbb{P}(\\text{至少有一次错误拒绝})$。\n- 在完全原假设和可交换性下，最大检验统计量 $M$ 的置换分布是最大值零分布的有效近似。\n- 对于任何检验 $j\\in\\{1,\\dots,m\\}$，校正的 $p$ 值定义为在 $M$ 的零分布下，$M$ 至少与观测值 $t_j$ 一样极端的概率。\n\n任务：\n1. 从检验 $j$ 的校正 $p$ 值的定义（即最大统计量在阈值 $t_j$ 处的零分布尾部概率）出发，推导一个基于 $B$ 个等可能的置换最大值 $M^{(1)},\\dots,M^{(B)}$ 的可计算估计量。您的推导必须从概率作为指示函数期望的定义以及完全原假设下的可交换性假设开始。估计量必须表示为 $[0,1]$ 范围内的十进制数值，不使用百分比。\n2. 使用您推导出的估计量，实现一个算法，该算法对于每个 $j\\in\\{1,\\dots,m\\}$，通过将观测值 $t_j$ 与置换最大值 $M^{(1)},\\dots,M^{(B)}$ 进行比较来计算校正的 $p$ 值。相等情况必须包含性地处理，即等于阈值的值应计为至少一样极端。\n3. 将您的算法应用于以下测试套件。每个测试用例提供 $(m, t_1,\\dots,t_m)$ 和 $(B, M^{(1)},\\dots,M^{(B)})$：\n   - 测试用例 1（一般情况）：$m=4$，$(t_1,t_2,t_3,t_4)=(2.1,1.5,3.0,0.8)$；$B=10$，$(M^{(1)},\\dots,M^{(10)})=(1.9,2.2,3.1,2.8,2.4,1.7,2.0,3.0,2.6,2.3)$。\n   - 测试用例 2（处理相等情况）：$m=3$，$(t_1,t_2,t_3)=(2.3,2.0,3.0)$；$B=3$，$(M^{(1)},M^{(2)},M^{(3)})=(2.3,2.3,2.3)$。\n   - 测试用例 3（边界情况 $B=1$）：$m=3$, $(t_1,t_2,t_3)=(1.0,2.5,3.0)$；$B=1$，$(M^{(1)})=(2.5)$。\n   - 测试用例 4（负值和极端边界值）：$m=4$，$(t_1,t_2,t_3,t_4)=(-1.0,-0.3,0.0,0.5)$；$B=4$，$(M^{(1)},\\dots,M^{(4)})=(-0.5,-0.2,0.0,-0.1)$。\n4. 最终输出必须是单行文本，包含四个校正 $p$ 值列表，每个测试用例一个列表，表示为小数，并格式化为一个用方括号括起来的逗号分隔列表，其中每个内部列表本身也用方括号括起来。例如，输出应类似于 $[[a_1,\\dots,a_m],[b_1,\\dots,b_m],[c_1,\\dots,c_m],[d_1,\\dots,d_m]]$，其中每个元素都是 $[0,1]$ 范围内的实数。\n\n您的程序必须是自包含的，不需要任何输入，并且只打印所述的最终格式化结果。", "solution": "该问题陈述已经过验证，被确定为是合理、适定且客观的。它提出了计算统计学中的一个标准任务，即使用基于置换的方法控制族错误率 (FWER)。所提供的定义和数据是一致且充分的，足以用于推导和实现解决方案。\n\n解决方案分两部分进行。首先，我将从基本统计原理推导出校正 $p$ 值的计算公式。其次，我将描述应用此公式于所提供数据的算法。\n\n### 第 1 部分：校正 $p$ 值估计量的推导\n\n目标是为与原假设 $H_j$ 的观测检验统计量 $t_j$ 相关联的校正 $p$ 值 $p_j^{\\text{adj}}$ 推导一个可计算的估计量。\n\n问题将检验 $j$ 的校正 $p$ 值定义为在完全原假设 $H_0^C$ 下，最大检验统计量 $M = \\max\\{T_1, \\dots, T_m\\}$ 至少与观测值 $t_j$ 一样极端的概率。形式上，这写为：\n$$\np_j^{\\text{adj}} = \\mathbb{P}(M \\ge t_j \\mid H_0^C)\n$$\n在这里，$T_1, \\dots, T_m$ 是对应于检验统计量的随机变量，它们的联合分布是在完全原假设（即所有 $H_j$ 均为真）下考虑的。\n\n概率可以表示为指示函数的期望。令 $\\mathbb{I}(\\cdot)$ 为指示函数，如果其参数为真，则其值为 $1$，否则为 $0$。校正 $p$ 值的定义可以重写为：\n$$\np_j^{\\text{adj}} = \\mathbb{E}[\\mathbb{I}(M \\ge t_j) \\mid H_0^C]\n$$\n其中期望 $\\mathbb{E}[\\cdot]$ 是在完全原假设下对 $M$ 的分布取的。\n\n在实践中，$M$ 的真实零分布通常是未知的。问题陈述我们使用基于置换的方法来近似此分布。通过对样本标签执行 $B$ 次置换，并为每次置换重新计算最大检验统计量，我们得到一组 $B$ 个值，即 $\\{M^{(1)}, M^{(2)}, \\dots, M^{(B)}\\}$。在完全原假设和可交换性的假设下，每个 $M^{(b)}$ 都是从 $M$ 的真实零分布中抽取的一个样本。问题陈述这些样本是等可能的。\n\n蒙特卡洛估计原理允许我们通过从分布中随机抽样的函数样本均值来近似期望。因此，我们可以通过对我们的 $B$ 个置换样本上评估的指示函数取平均值来估计期望 $\\mathbb{E}[\\mathbb{I}(M \\ge t_j) \\mid H_0^C]$。令 $\\hat{p}_j^{\\text{adj}}$ 为 $p_j^{\\text{adj}}$ 的估计量。\n$$\n\\hat{p}_j^{\\text{adj}} = \\frac{1}{B} \\sum_{b=1}^{B} \\mathbb{I}(M^{(b)} \\ge t_j)\n$$\n求和项 $\\sum_{b=1}^{B} \\mathbb{I}(M^{(b)} \\ge t_j)$ 精确地是大于或等于观测检验统计量 $t_j$ 的置换最大值 $M^{(b)}$ 的数量。包含性地处理相等情况（“至少一样极端”）的指令自然地由大于等于运算符 $\\ge$ 体现。\n\n因此，校正 $p$ 值的最终可计算估计量是：\n$$\n\\hat{p}_j^{\\text{adj}} = \\frac{\\text{满足 } M^{(b)} \\ge t_j \\text{ 的 } M^{(b)} \\text{ 的数量}}{B}\n$$\n该公式基于从置换获得的最大统计量的经验分布，提供了一个校正 $p$ 值的直接、非参数估计。其值是按要求在 $[0, 1]$ 范围内的十进制数。\n\n### 第 2 部分：算法与应用\n\n为给定测试用例计算校正 $p$ 值的算法直接源自推导出的估计量。\n\n对于每个测试用例，我们被给定：\n- 检验数量 $m$。\n- 观测检验统计量向量 $t = (t_1, t_2, \\dots, t_m)$。\n- 置换次数 $B$。\n- 置换最大值向量 $M_{\\text{perm}} = (M^{(1)}, M^{(2)}, \\dots, M^{(B)})$。\n\n算法如下：\n1. 初始化一个空列表 `p_adjusted`，用于存储 $m$ 个检验的结果。\n2. 对于每个观测统计量 $t_j$（其中 $j$ 从 $1$ 到 $m$）：\n    a. 初始化一个计数器 `count_ge` 为 $0$。\n    b. 遍历向量 $M_{\\text{perm}}$ 中的每个置换最大值 $M^{(b)}$（其中 $b$ 从 $1$ 到 $B$）。\n    c. 在每次迭代中，比较 $M^{(b)}$ 和 $t_j$。如果 $M^{(b)} \\ge t_j$，则将 `count_ge` 加 $1$。\n    d. 遍历所有 $B$ 个置换最大值后，计算检验 $j$ 的校正 $p$ 值为 $\\hat{p}_j^{\\text{adj}} = \\frac{\\text{count\\_ge}}{B}$。\n    e. 将 $\\hat{p}_j^{\\text{adj}}$ 附加到 `p_adjusted` 列表中。\n3. 处理完所有 $m$ 个统计量后，列表 `p_adjusted` 包含该测试用例所需的一组校正 $p$ 值。\n\n对问题陈述中提供的四个测试用例中的每一个重复此过程。实现将使用数值计算库来高效地进行比较和计数的向量化计算，这在计算上等效于所描述的迭代算法。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes adjusted p-values using a max-statistic permutation approach\n    for a suite of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: ((t_1..t_m), (M_1..M_B))\n    test_cases = [\n        # Test case 1 (general case)\n        (\n            (2.1, 1.5, 3.0, 0.8),\n            (1.9, 2.2, 3.1, 2.8, 2.4, 1.7, 2.0, 3.0, 2.6, 2.3)\n        ),\n        # Test case 2 (tie-handling)\n        (\n            (2.3, 2.0, 3.0),\n            (2.3, 2.3, 2.3)\n        ),\n        # Test case 3 (boundary B=1)\n        (\n            (1.0, 2.5, 3.0),\n            (2.5,)\n        ),\n        # Test case 4 (negative values and edge extremes)\n        (\n            (-1.0, -0.3, 0.0, 0.5),\n            (-0.5, -0.2, 0.0, -0.1)\n        )\n    ]\n\n    all_results = []\n    for t_obs_tuple, M_perm_tuple in test_cases:\n        # Convert tuples to numpy arrays for efficient computation\n        t_obs = np.array(t_obs_tuple)\n        M_perm = np.array(M_perm_tuple)\n        \n        # B is the number of permutation maxima\n        B = float(len(M_perm))\n\n        # Ensure B is not zero to avoid division by zero, though problem constraints\n        # imply B >= 1.\n        if B == 0:\n            # According to the formula, if B=0, the p-value is undefined.\n            # We can represent this as NaN or handle as an error.\n            # Assuming B>=1 based on the problem. \n            # For robustness, we could set p-values to 1.0 or NaN.\n            # Here we just proceed, as problem data has B >= 1.\n            pass\n\n        # Reshape t_obs for broadcasting.\n        # t_obs becomes a column vector of shape (m, 1).\n        # M_perm is a row vector of shape (1, B).\n        # The comparison M_perm >= t_obs[:, np.newaxis] results in a\n        # boolean matrix of shape (m, B). Each row corresponds to a t_j\n        # and contains the comparison result against all M^(b).\n        # The condition is M^(b) >= t_j, which means we compare the row vector M_perm\n        # against the column vector t_obs.\n        \n        # t_obs is (m,), M_perm is (B,). Reshape t_obs to (m, 1).\n        # The comparison M_perm (B,) >= t_obs[:, np.newaxis] (m, 1) broadcasts\n        # to a (m, B) boolean array.\n        comparison_matrix = M_perm >= t_obs[:, np.newaxis]\n        \n        # Sum the boolean values (True=1, False=0) along axis=1 (across permutations)\n        # to get the count of M^(b) >= t_j for each t_j.\n        counts = np.sum(comparison_matrix, axis=1)\n        \n        # Calculate the adjusted p-values by dividing counts by B.\n        adj_p_values = counts / B\n        \n        all_results.append(adj_p_values.tolist())\n\n    # Format the final output string exactly as specified in the problem.\n    # Example: [[a,b,c],[d,e],[f,g,h,i],[j,k]]\n    # 1. Convert each inner list of floats to a string of comma-separated values.\n    # 2. Enclose each of these strings in square brackets.\n    # 3. Join all these bracketed strings with commas.\n    # 4. Enclose the final joined string in square brackets.\n    \n    inner_strings = []\n    for res_list in all_results:\n        inner_strings.append(f\"[{','.join(map(str, res_list))}]\")\n    \n    final_output_string = f\"[{','.join(inner_strings)}]\"\n    \n    # The final print statement must produce only the single-line format.\n    print(final_output_string)\n\nsolve()\n```", "id": "4930335"}]}