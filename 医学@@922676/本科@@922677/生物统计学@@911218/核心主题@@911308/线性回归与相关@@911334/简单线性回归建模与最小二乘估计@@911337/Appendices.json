{"hands_on_practices": [{"introduction": "在拟合回归模型后，仅仅得到系数的估计值（点估计）是不够的。我们还必须量化我们对这些估计值的信心，这正是标准误（standard error）的作用。本练习将指导您从最小二乘法的基本原理出发，推导并计算斜率和截距估计量的标准误，从而揭示影响模型精度的关键因素，如数据点的离散程度和残差的大小。[@problem_id:4952531]", "problem": "一个临床生物统计学团队研究收缩压与年龄之间的关系。设响应变量为以毫米汞柱 (mmHg) 为单位的收缩压 $y_i$，预测变量为以年为单位的年龄 $x_i$。假设采用经典的简单线性回归模型，其误差为独立同分布的正态分布，\n$$\nY_i \\;=\\; \\beta_0 \\;+\\; \\beta_1 x_i \\;+\\; \\varepsilon_i,\\quad \\varepsilon_i \\sim \\text{Normal}(0,\\sigma^2),\\quad i=1,\\dots,n,\n$$\n并且参数通过普通最小二乘法 (OLS) 进行估计。\n\n对于 $n=8$ 个个体的观测数据如下：\n$$\n(x_i,y_i) \\in \\{(20,113),\\,(30,117),\\,(40,118.5),\\,(50,126),\\,(60,129),\\,(70,136.5),\\,(80,138),\\,(90,142)\\}.\n$$\n\n任务：\n- 从模型定义和最小化 $\\sum_{i=1}^{n}(y_i-\\beta_0-\\beta_1 x_i)^2$ 所蕴含的正规方程出发，在所述假设下推导 OLS 斜率和截距估计量的抽样方差，并由此推导出它们的标准误。用量 $n$、$\\bar{x}$ 和 $\\sum_{i=1}^{n}(x_i-\\bar{x})^2$ 来表示你的推导过程。解释每个项对标准误大小的贡献。\n- 然后，对于给定的数据集，使用无偏误差方差估计量\n$$\n\\hat{\\sigma}^2 \\;=\\; \\frac{\\sum_{i=1}^{n} e_i^2}{n-2},\\quad e_i = y_i - \\hat{y}_i,\n$$\n计算标准误的数值，其中 $\\hat{y}_i$ 是 OLS 拟合值。报告斜率的标准误（单位：毫米汞柱/年）和截距的标准误（单位：毫米汞柱）。将你的两个数值答案四舍五入到四位有效数字。以有序对 $(SE(\\hat{\\beta}_1),\\,SE(\\hat{\\beta}_0))$ 的形式提供你的最终数值答案。", "solution": "该问题具有科学依据，提法明确，客观，并包含了推导所需公式和计算数值所需的全部信息。我们开始解答，解答过程分为理论推导和数值计算两部分。\n\n### 第1部分：抽样方差和标准误的推导\n\n经典的简单线性回归模型由下式给出\n$$Y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i$$\n其中误差 $\\varepsilon_i$ 对于 $i=1,\\dots,n$ 是独立同分布 (i.i.d.) 的，服从 $\\text{Normal}(0,\\sigma^2)$。普通最小二乘法 (OLS) 估计量 $\\hat{\\beta}_0$ 和 $\\hat{\\beta}_1$ 是使残差平方和 $S(\\beta_0, \\beta_1) = \\sum_{i=1}^{n} (y_i - \\beta_0 - \\beta_1 x_i)^2$ 最小化的 $\\beta_0$ 和 $\\beta_1$ 的值。\n\n为求最小值，我们将 $S$ 对 $\\beta_0$ 和 $\\beta_1$ 求偏导数并令其为零。这得到正规方程：\n$$ \\frac{\\partial S}{\\partial \\beta_0} = -2 \\sum_{i=1}^{n} (y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i) = 0 \\implies \\sum_{i=1}^{n} y_i = n \\hat{\\beta}_0 + \\hat{\\beta}_1 \\sum_{i=1}^{n} x_i $$\n$$ \\frac{\\partial S}{\\partial \\beta_1} = -2 \\sum_{i=1}^{n} x_i(y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i) = 0 \\implies \\sum_{i=1}^{n} x_i y_i = \\hat{\\beta}_0 \\sum_{i=1}^{n} x_i + \\hat{\\beta}_1 \\sum_{i=1}^{n} x_i^2 $$\n\n从第一个正规方程两边除以 $n$ 可得 $\\bar{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\bar{x}$，这给出了作为斜率估计量函数的截距估计量：\n$$ \\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x} $$\n\n将 $\\hat{\\beta}_0$ 的这个表达式代入第二个正规方程：\n$$ \\sum x_i y_i = (\\bar{y} - \\hat{\\beta}_1 \\bar{x}) \\sum x_i + \\hat{\\beta}_1 \\sum x_i^2 $$\n$$ \\sum x_i y_i = \\bar{y} (n\\bar{x}) - \\hat{\\beta}_1 \\bar{x} (n\\bar{x}) + \\hat{\\beta}_1 \\sum x_i^2 $$\n$$ \\sum x_i y_i - n\\bar{x}\\bar{y} = \\hat{\\beta}_1 \\left( \\sum x_i^2 - n\\bar{x}^2 \\right) $$\n使用记号 $S_{xy} = \\sum (x_i-\\bar{x})(y_i-\\bar{y}) = \\sum x_i y_i - n\\bar{x}\\bar{y}$ 和 $S_{xx} = \\sum (x_i-\\bar{x})^2 = \\sum x_i^2 - n\\bar{x}^2$，我们解出 $\\hat{\\beta}_1$：\n$$ \\hat{\\beta}_1 = \\frac{\\sum (x_i-\\bar{x})(y_i-\\bar{y})}{\\sum (x_i-\\bar{x})^2} = \\frac{S_{xy}}{S_{xx}} $$\n\n为求 $\\hat{\\beta}_1$ 的方差，我们将其表示为随机变量 $Y_i$ 的线性组合。注意 $\\sum (x_i-\\bar{x})\\bar{Y} = \\bar{Y} \\sum(x_i-\\bar{x}) = 0$。\n$$ \\hat{\\beta}_1 = \\frac{\\sum (x_i-\\bar{x})(Y_i-\\bar{Y})}{S_{xx}} = \\frac{\\sum (x_i-\\bar{x})Y_i - \\sum (x_i-\\bar{x})\\bar{Y}}{S_{xx}} = \\frac{\\sum (x_i-\\bar{x})Y_i}{S_{xx}} = \\sum_{i=1}^{n} c_i Y_i $$\n其中常数为 $c_i = \\frac{x_i-\\bar{x}}{S_{xx}}$。\n由于 $Y_i$ 是独立的且 $\\text{Var}(Y_i) = \\sigma^2$，$\\hat{\\beta}_1$ 的方差为：\n$$ \\text{Var}(\\hat{\\beta}_1) = \\text{Var}\\left(\\sum_{i=1}^{n} c_i Y_i\\right) = \\sum_{i=1}^{n} c_i^2 \\text{Var}(Y_i) = \\sigma^2 \\sum_{i=1}^{n} c_i^2 $$\n我们计算常数的平方和：\n$$ \\sum_{i=1}^{n} c_i^2 = \\sum_{i=1}^{n} \\left( \\frac{x_i-\\bar{x}}{S_{xx}} \\right)^2 = \\frac{1}{S_{xx}^2} \\sum_{i=1}^{n} (x_i-\\bar{x})^2 = \\frac{S_{xx}}{S_{xx}^2} = \\frac{1}{S_{xx}} $$\n因此，斜率估计量的抽样方差为：\n$$ \\text{Var}(\\hat{\\beta}_1) = \\frac{\\sigma^2}{\\sum_{i=1}^n (x_i - \\bar{x})^2} $$\n\n接下来，我们求 $\\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1 \\bar{x}$ 的方差。\n$$ \\text{Var}(\\hat{\\beta}_0) = \\text{Var}(\\bar{Y} - \\hat{\\beta}_1\\bar{x}) = \\text{Var}(\\bar{Y}) + \\bar{x}^2 \\text{Var}(\\hat{\\beta}_1) - 2\\bar{x} \\text{Cov}(\\bar{Y}, \\hat{\\beta}_1) $$\n我们有 $\\text{Var}(\\bar{Y}) = \\text{Var}(\\frac{1}{n}\\sum Y_i) = \\frac{1}{n^2} \\sum \\text{Var}(Y_i) = \\frac{n\\sigma^2}{n^2} = \\frac{\\sigma^2}{n}$。\n协方差项为：\n$$ \\text{Cov}(\\bar{Y}, \\hat{\\beta}_1) = \\text{Cov}\\left(\\sum_{i=1}^n \\frac{1}{n} Y_i, \\sum_{j=1}^n c_j Y_j\\right) = \\sum_{i=1}^n \\frac{1}{n} c_i \\text{Var}(Y_i) = \\frac{\\sigma^2}{n} \\sum_{i=1}^n c_i $$\n因为当 $i \\neq j$ 时 $\\text{Cov}(Y_i, Y_j)=0$。常数 $c_i$ 的和为：\n$$ \\sum_{i=1}^n c_i = \\sum_{i=1}^n \\frac{x_i-\\bar{x}}{S_{xx}} = \\frac{1}{S_{xx}} \\sum_{i=1}^n (x_i-\\bar{x}) = 0 $$\n因此，$\\text{Cov}(\\bar{Y}, \\hat{\\beta}_1) = 0$。斜率估计量 $\\hat{\\beta}_1$ 与响应变量的样本均值 $\\bar{Y}$ 不相关。\n将这些结果代回 $\\hat{\\beta}_0$ 的方差公式：\n$$ \\text{Var}(\\hat{\\beta}_0) = \\frac{\\sigma^2}{n} + \\bar{x}^2 \\frac{\\sigma^2}{\\sum (x_i-\\bar{x})^2} = \\sigma^2 \\left( \\frac{1}{n} + \\frac{\\bar{x}^2}{\\sum_{i=1}^n (x_i-\\bar{x})^2} \\right) $$\n\n估计量的标准误 ($SE$) 是其估计抽样方差的平方根。方差 $\\sigma^2$ 是未知的，通过无偏估计量 $\\hat{\\sigma}^2 = \\frac{\\sum e_i^2}{n-2}$ 来估计，其中 $e_i = y_i - \\hat{y}_i$ 是残差。\n斜率估计量的标准误是：\n$$ SE(\\hat{\\beta}_1) = \\sqrt{\\frac{\\hat{\\sigma}^2}{\\sum_{i=1}^n (x_i-\\bar{x})^2}} = \\frac{\\hat{\\sigma}}{\\sqrt{\\sum_{i=1}^n (x_i-\\bar{x})^2}} $$\n截距估计量的标准误是：\n$$ SE(\\hat{\\beta}_0) = \\sqrt{\\hat{\\sigma}^2 \\left( \\frac{1}{n} + \\frac{\\bar{x}^2}{\\sum_{i=1}^n (x_i-\\bar{x})^2} \\right)} = \\hat{\\sigma} \\sqrt{\\frac{1}{n} + \\frac{\\bar{x}^2}{\\sum_{i=1}^n (x_i-\\bar{x})^2}} $$\n\n各项的解释：\n- 对于 $SE(\\hat{\\beta}_0)$ 和 $SE(\\hat{\\beta}_1)$，标准误都与误差项的估计标准差 $\\hat{\\sigma}$ 成正比。回归线周围较大的残差变异性意味着参数估计中更大的不确定性。\n- 对于 $SE(\\hat{\\beta}_1)$，分母中的项是 $\\sum (x_i-\\bar{x})^2$。该项度量了预测变量值 $x_i$ 的离散程度。$x_i$ 的离散程度越大，为估计斜率提供了更稳定的“杠杆臂”，从而减小其标准误。\n- 对于 $SE(\\hat{\\beta}_0)$，$\\frac{1}{n}$ 项反映了估计平均响应水平的不确定性；这种不确定性随着样本量 $n$ 的增加而减小。$\\frac{\\bar{x}^2}{\\sum (x_i-\\bar{x})^2}$ 项反映了将回归线从数据中心 ($\\bar{x}$) 外推到 y 轴 ($x=0$) 所产生的不确定性。当 $\\bar{x}$ 远离 0 时，此外推误差较大；当 $x_i$ 的离散程度较大时，此外推误差较小。\n\n### 第2部分：针对给定数据集的数值计算\n\n首先，我们从数据中计算必要的汇总统计量，其中 $n=8$。\n$$ x_i: \\{20, 30, 40, 50, 60, 70, 80, 90\\} $$\n$$ y_i: \\{113, 117, 118.5, 126, 129, 136.5, 138, 142\\} $$\n\n$$ \\sum_{i=1}^8 x_i = 440 \\implies \\bar{x} = \\frac{440}{8} = 55 \\text{ 年} $$\n$$ \\sum_{i=1}^8 y_i = 1020 \\implies \\bar{y} = \\frac{1020}{8} = 127.5 \\text{ mmHg} $$\n\n接下来，我们计算平方和：\n$$ S_{xx} = \\sum_{i=1}^8 (x_i - \\bar{x})^2 = \\sum x_i^2 - n\\bar{x}^2 = (20^2 + \\dots + 90^2) - 8(55^2) = 28400 - 8(3025) = 28400 - 24200 = 4200 $$\n$$ S_{xy} = \\sum_{i=1}^8 (x_i - \\bar{x})(y_i - \\bar{y}) = \\sum x_i y_i - n\\bar{x}\\bar{y} = (20 \\cdot 113 + \\dots + 90 \\cdot 142) - 8(55)(127.5) = 57925 - 56100 = 1825 $$\n$$ S_{yy} = \\sum_{i=1}^8 (y_i - \\bar{y})^2 = \\sum y_i^2 - n\\bar{y}^2 = (113^2 + \\dots + 142^2) - 8(127.5^2) = 130857.5 - 8(16256.25) = 130857.5 - 130050 = 807.5 $$\n\n现在，计算 OLS 估计值：\n$$ \\hat{\\beta}_1 = \\frac{S_{xy}}{S_{xx}} = \\frac{1825}{4200} = \\frac{73}{168} \\approx 0.43452 $$\n$$ \\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x} = 127.5 - \\left(\\frac{1825}{4200}\\right)(55) \\approx 103.601 $$\n\n接下来，计算误差平方和 ($SSE$) 和误差方差的无偏估计量 $\\hat{\\sigma}^2$：\n$$ SSE = \\sum e_i^2 = S_{yy} - \\frac{S_{xy}^2}{S_{xx}} = 807.5 - \\frac{(1825)^2}{4200} = 807.5 - \\frac{3330625}{4200} \\approx 807.5 - 792.9940476 = 14.5059524 $$\n为保证精度，使用分数计算：\n$$ SSE = \\frac{1615}{2} - \\frac{133225}{168} = \\frac{135660 - 133225}{168} = \\frac{2435}{168} $$\n无偏方差估计量为：\n$$ \\hat{\\sigma}^2 = \\frac{SSE}{n-2} = \\frac{2435/168}{8-2} = \\frac{2435}{168 \\times 6} = \\frac{2435}{1008} \\approx 2.41567 $$\n\n最后，我们计算标准误：\n对于斜率 $\\hat{\\beta}_1$：\n$$ SE(\\hat{\\beta}_1) = \\sqrt{\\frac{\\hat{\\sigma}^2}{S_{xx}}} = \\sqrt{\\frac{2435/1008}{4200}} = \\sqrt{\\frac{2435}{1008 \\times 4200}} = \\sqrt{\\frac{2435}{4233600}} \\approx 0.0239825 $$\n四舍五入到四位有效数字，$SE(\\hat{\\beta}_1) \\approx 0.02398$ mmHg/年。\n\n对于截距 $\\hat{\\beta}_0$：\n$$ SE(\\hat{\\beta}_0) = \\sqrt{\\hat{\\sigma}^2 \\left(\\frac{1}{n} + \\frac{\\bar{x}^2}{S_{xx}}\\right)} = \\sqrt{\\frac{2435}{1008} \\left(\\frac{1}{8} + \\frac{55^2}{4200}\\right)} $$\n$$ SE(\\hat{\\beta}_0) = \\sqrt{\\frac{2435}{1008} \\left(\\frac{1}{8} + \\frac{3025}{4200}\\right)} = \\sqrt{\\frac{2435}{1008} \\left(\\frac{525+3025}{4200}\\right)} = \\sqrt{\\frac{2435}{1008} \\left(\\frac{3550}{4200}\\right)} = \\sqrt{\\frac{2435}{1008} \\left(\\frac{71}{84}\\right)} $$\n$$ SE(\\hat{\\beta}_0) = \\sqrt{\\frac{172885}{84672}} \\approx \\sqrt{2.04185} \\approx 1.428933 $$\n四舍五入到四位有效数字，$SE(\\hat{\\beta}_0) \\approx 1.429$ mmHg。\n\n所求的有序对为 $(SE(\\hat{\\beta}_1), SE(\\hat{\\beta}_0))$。", "answer": "$$ \\boxed{\\begin{pmatrix} 0.02398  1.429 \\end{pmatrix}} $$", "id": "4952531"}, {"introduction": "上一节我们学习了如何量化估计量的不确定性，本节将探讨如何通过数据变换来主动优化模型的性质。我们将研究对预测变量进行平移（或中心化）会如何影响模型的参数，并找出一个最优的中心点，使得截距项的估计方差达到最小。这项练习不仅能加深对截距项物理意义的理解，还展示了构建更稳定、更易解释模型的一种重要策略。[@problem_id:4952529]", "problem": "一项生物统计学研究调查了 $n$ 个个体中连续生物标志物响应 $Y$ 与连续暴露 $x$ 之间的线性关系。假设简单线性回归模型为\n$$\nY_i \\;=\\; \\beta_0 \\;+\\; \\beta_1 x_i \\;+\\; \\varepsilon_i,\\quad i=1,\\dots,n,\n$$\n其中 $\\varepsilon_i$ 独立同分布 (i.i.d.)，且 $\\mathbb{E}[\\varepsilon_i]=0$ 和 $\\operatorname{Var}(\\varepsilon_i)=\\sigma^2$。令 $\\bar{x}=\\frac{1}{n}\\sum_{i=1}^n x_i$ 且 $S_{xx}=\\sum_{i=1}^n (x_i-\\bar{x})^2$。考虑在一个任意常数 $c\\in\\mathbb{R}$ 处对预测变量进行中心化后重新拟合模型，方法是定义 $z_i=x_i-c$ 并估计\n$$\nY_i \\;=\\; \\alpha_c \\;+\\; \\beta_1^{(c)} z_i \\;+\\; \\varepsilon_i.\n$$\n仅从最小二乘法的定义和所述假设出发，推导重新拟合的截距 $\\hat{\\alpha}_c$ 和斜率 $\\hat{\\beta}_1^{(c)}$ 与原始最小二乘估计量 $\\hat{\\beta}_0$ 和 $\\hat{\\beta}_1$ 之间的关系，并解释 $\\hat{\\alpha}_c$ 在条件均值 $\\mathbb{E}[Y\\mid x=c]$ 方面的含义。然后，求出 $\\operatorname{Var}(\\hat{\\alpha}_c)$ 作为 $c$、$\\bar{x}$、$S_{xx}$、$n$ 和 $\\sigma^2$ 的函数的显式表达式，并确定在所有实数 $c$ 中使 $\\operatorname{Var}(\\hat{\\alpha}_c)$ 最小化的中心化值 $c$。\n\n您的最终答案必须是使 $\\operatorname{Var}(\\hat{\\alpha}_c)$ 最小化的 $c$ 值的单一解析表达式。不需要数值四舍五入，最终答案中也不应包含单位。", "solution": "首先将根据指定标准对问题陈述进行验证。\n\n### 问题验证\n\n#### 第1步：提取已知条件\n已知条件如下：\n- 原始简单线性回归模型：$Y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i$，其中 $i=1,\\dots,n$。\n- 误差项 $\\varepsilon_i$ 是独立同分布 (i.i.d.) 的。\n- 误差项的期望值：$\\mathbb{E}[\\varepsilon_i]=0$。\n- 误差项的方差：$\\operatorname{Var}(\\varepsilon_i)=\\sigma^2$。\n- 预测变量的样本均值：$\\bar{x}=\\frac{1}{n}\\sum_{i=1}^n x_i$。\n- 预测变量的离差平方和：$S_{xx}=\\sum_{i=1}^n (x_i-\\bar{x})^2$。\n- 重新拟合的模型使用中心化的预测变量 $z_i=x_i-c$，其中 $c\\in\\mathbb{R}$ 是一个任意常数。\n- 重新拟合的模型方程：$Y_i = \\alpha_c + \\beta_1^{(c)} z_i + \\varepsilon_i$。\n- 任务是从最小二乘法的定义出发，推导估计量之间的关系，解释新截距的含义，推导其方差，并找到使该方差最小化的 $c$ 值。\n\n#### 第2步：使用提取的已知条件进行验证\n该问题根据其科学性、适定性和客观性标准进行评估。\n- **科学性**：该问题是线性模型理论的核心，是生物统计学和统计学中的一个基本主题。它探讨了最小二乘估计量在简单重参数化（平移预测变量）下的性质。所有假设，如独立同分布、零均值和等方差的误差，在该背景下都是标准的。该问题在科学上和数学上都是合理的。\n- **适定性**：问题定义清晰。它要求推导估计量之间的关系、参数的统计解释、方差函数的推导以及该函数的优化。这些都是线性回归理论中标准的、可回答的问题。存在一个唯一且有意义的解，并且可以从提供的信息中推导出来。\n- **客观性**：问题使用精确、形式化的数学语言陈述。它没有任何模糊性、主观性或基于观点的断言。\n\n#### 第3步：结论与行动\n问题有效。这是一个线性回归理论中标准的、适定的练习。现在开始解题过程。\n\n### 解题过程\n\n第一步是写出原始模型 $Y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i$ 参数的普通最小二乘 (OLS) 估计量。OLS估计量（记为 $\\hat{\\beta}_0$ 和 $\\hat{\\beta}_1$）是使残差平方和 $S(\\beta_0, \\beta_1) = \\sum_{i=1}^n (Y_i - \\beta_0 - \\beta_1 x_i)^2$ 最小化的值。从正规方程组 $\\frac{\\partial S}{\\partial \\beta_0}=0$ 和 $\\frac{\\partial S}{\\partial \\beta_1}=0$ 推导出的标准解是：\n$$\n\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(Y_i - \\bar{Y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2} = \\frac{S_{xy}}{S_{xx}}\n$$\n$$\n\\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1 \\bar{x}\n$$\n其中 $\\bar{Y} = \\frac{1}{n}\\sum_{i=1}^n Y_i$ 且 $S_{xy} = \\sum_{i=1}^n (x_i - \\bar{x})(Y_i - \\bar{Y})$。\n\n接下来，我们考虑重新拟合的模型 $Y_i = \\alpha_c + \\beta_1^{(c)} z_i + \\varepsilon_i$，其中 $z_i = x_i - c$。该模型的OLS估计量 $\\hat{\\alpha}_c$ 和 $\\hat{\\beta}_1^{(c)}$ 是通过最小化 $S(\\alpha_c, \\beta_1^{(c)}) = \\sum_{i=1}^n (Y_i - \\alpha_c - \\beta_1^{(c)} z_i)^2$ 得到的。遵循相同的步骤，估计量为：\n$$\n\\hat{\\beta}_1^{(c)} = \\frac{\\sum_{i=1}^n (z_i - \\bar{z})(Y_i - \\bar{Y})}{\\sum_{i=1}^n (z_i - \\bar{z})^2}\n$$\n$$\n\\hat{\\alpha}_c = \\bar{Y} - \\hat{\\beta}_1^{(c)} \\bar{z}\n$$\n其中 $\\bar{z} = \\frac{1}{n} \\sum_{i=1}^n z_i = \\frac{1}{n} \\sum_{i=1}^n (x_i - c) = (\\frac{1}{n} \\sum_{i=1}^n x_i) - c = \\bar{x} - c$。\n\n为了关联这些估计量，我们注意到离差项 $z_i - \\bar{z}$ 是 $(x_i - c) - (\\bar{x} - c) = x_i - \\bar{x}$。将此代入 $\\hat{\\beta}_1^{(c)}$ 的表达式中：\n$$\n\\hat{\\beta}_1^{(c)} = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(Y_i - \\bar{Y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2} = \\hat{\\beta}_1\n$$\n这表明斜率系数的最小二乘估计量对于预测变量的位置平移是不变的。\n\n现在，我们求出截距估计量 $\\hat{\\alpha}_c$ 的关系：\n$$\n\\hat{\\alpha}_c = \\bar{Y} - \\hat{\\beta}_1^{(c)} \\bar{z} = \\bar{Y} - \\hat{\\beta}_1 (\\bar{x} - c) = (\\bar{Y} - \\hat{\\beta}_1 \\bar{x}) + \\hat{\\beta}_1 c\n$$\n注意到 $\\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1 \\bar{x}$，我们有：\n$$\n\\hat{\\alpha}_c = \\hat{\\beta}_0 + \\hat{\\beta}_1 c\n$$\n重新拟合模型的截距是原始截距、原始斜率和中心化常数 $c$ 的线性函数。\n\n$\\hat{\\alpha}_c$ 的解释源于其定义。在模型 $Y_i = \\alpha_c + \\beta_1^{(c)} z_i + \\varepsilon_i$ 中，截距 $\\hat{\\alpha}_c$ 是当预测变量 $z$ 为零时响应 $Y$ 的预测值。条件 $z=0$ 等价于 $x-c=0$，即 $x=c$。因此，$\\hat{\\alpha}_c$ 是在 $x=c$ 处 $Y$ 的预测值。这可以从原始拟合的回归线 $\\hat{Y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 x$ 中看出。在 $x=c$ 处计算该式，得到 $\\hat{Y}|_{x=c} = \\hat{\\beta}_0 + \\hat{\\beta}_1 c$，这正是我们推导出的 $\\hat{\\alpha}_c$ 的表达式。因此，$\\hat{\\alpha}_c$ 是在给定 $x=c$ 时 $Y$ 的条件均值的估计量，即 $\\hat{\\alpha}_c = \\hat{\\mathbb{E}}[Y \\mid x=c]$。\n\n为了求出 $\\hat{\\alpha}_c$ 的方差，我们使用表达式 $\\hat{\\alpha}_c = \\hat{\\beta}_0 + c \\hat{\\beta}_1$。其方差为：\n$$\n\\operatorname{Var}(\\hat{\\alpha}_c) = \\operatorname{Var}(\\hat{\\beta}_0 + c \\hat{\\beta}_1) = \\operatorname{Var}(\\hat{\\beta}_0) + c^2 \\operatorname{Var}(\\hat{\\beta}_1) + 2c \\operatorname{Cov}(\\hat{\\beta}_0, \\hat{\\beta}_1)\n$$\n我们需要 OLS 估计量 $\\hat{\\beta}_0$ 和 $\\hat{\\beta}_1$ 的方差和协方差。将预测变量 $x_i$ 视为固定常数，则估计量是随机变量 $Y_i$ 的线性组合。\n$\\hat{\\beta}_1 = \\sum_{i=1}^n k_i Y_i$，其中 $k_i = \\frac{x_i - \\bar{x}}{S_{xx}}$。\n$$\n\\operatorname{Var}(\\hat{\\beta}_1) = \\operatorname{Var}\\left(\\sum_{i=1}^n k_i Y_i\\right) = \\sum_{i=1}^n k_i^2 \\operatorname{Var}(Y_i) = \\sum_{i=1}^n k_i^2 \\sigma^2 = \\sigma^2 \\sum_{i=1}^n \\left(\\frac{x_i - \\bar{x}}{S_{xx}}\\right)^2 = \\frac{\\sigma^2}{S_{xx}^2} \\sum_{i=1}^n (x_i - \\bar{x})^2 = \\frac{\\sigma^2 S_{xx}}{S_{xx}^2} = \\frac{\\sigma^2}{S_{xx}}\n$$\n$\\hat{\\beta}_0 = \\bar{Y} - \\bar{x}\\hat{\\beta}_1$。\n$\\bar{Y}$ 和 $\\hat{\\beta}_1$ 之间的协方差为：\n$$\n\\operatorname{Cov}(\\bar{Y}, \\hat{\\beta}_1) = \\operatorname{Cov}\\left(\\frac{1}{n}\\sum_{j=1}^n Y_j, \\sum_{i=1}^n k_i Y_i\\right) = \\frac{1}{n} \\sum_{i=1}^n k_i \\operatorname{Var}(Y_i) = \\frac{\\sigma^2}{n} \\sum_{i=1}^n k_i = \\frac{\\sigma^2}{n} \\frac{\\sum_{i=1}^n(x_i - \\bar{x})}{S_{xx}} = 0\n$$\n因为 $\\operatorname{Cov}(\\bar{Y}, \\hat{\\beta}_1) = 0$，所以 $\\bar{Y}$ 和 $\\hat{\\beta}_1$ 不相关。这简化了余下的计算。\n$$\n\\operatorname{Var}(\\hat{\\beta}_0) = \\operatorname{Var}(\\bar{Y} - \\bar{x}\\hat{\\beta}_1) = \\operatorname{Var}(\\bar{Y}) + \\bar{x}^2 \\operatorname{Var}(\\hat{\\beta}_1) - 2\\bar{x}\\operatorname{Cov}(\\bar{Y}, \\hat{\\beta}_1) = \\frac{\\sigma^2}{n} + \\bar{x}^2 \\frac{\\sigma^2}{S_{xx}} - 0 = \\sigma^2 \\left(\\frac{1}{n} + \\frac{\\bar{x}^2}{S_{xx}}\\right)\n$$\n协方差为：\n$$\n\\operatorname{Cov}(\\hat{\\beta}_0, \\hat{\\beta}_1) = \\operatorname{Cov}(\\bar{Y} - \\bar{x}\\hat{\\beta}_1, \\hat{\\beta}_1) = \\operatorname{Cov}(\\bar{Y}, \\hat{\\beta}_1) - \\bar{x}\\operatorname{Var}(\\hat{\\beta}_1) = 0 - \\bar{x}\\frac{\\sigma^2}{S_{xx}} = -\\frac{\\sigma^2 \\bar{x}}{S_{xx}}\n$$\n将这些表达式代入 $\\operatorname{Var}(\\hat{\\alpha}_c)$ 的公式中：\n$$\n\\operatorname{Var}(\\hat{\\alpha}_c) = \\sigma^2 \\left(\\frac{1}{n} + \\frac{\\bar{x}^2}{S_{xx}}\\right) + c^2 \\left(\\frac{\\sigma^2}{S_{xx}}\\right) + 2c \\left(-\\frac{\\sigma^2 \\bar{x}}{S_{xx}}\\right)\n$$\n$$\n\\operatorname{Var}(\\hat{\\alpha}_c) = \\sigma^2 \\left[ \\frac{1}{n} + \\frac{\\bar{x}^2}{S_{xx}} - \\frac{2c\\bar{x}}{S_{xx}} + \\frac{c^2}{S_{xx}} \\right]\n$$\n$$\n\\operatorname{Var}(\\hat{\\alpha}_c) = \\sigma^2 \\left[ \\frac{1}{n} + \\frac{c^2 - 2c\\bar{x} + \\bar{x}^2}{S_{xx}} \\right]\n$$\n这可以简化为显式表达式：\n$$\n\\operatorname{Var}(\\hat{\\alpha}_c) = \\sigma^2 \\left[ \\frac{1}{n} + \\frac{(c - \\bar{x})^2}{S_{xx}} \\right]\n$$\n最后，为了找到使 $\\operatorname{Var}(\\hat{\\alpha}_c)$ 最小的 $c$ 值，我们分析这个关于 $c$ 的函数。$\\sigma^2$、$n$ 和 $S_{xx}$ 都是正常数（假设 $S_{xx} > 0$，即并非所有 $x_i$ 都相同，这是拟合斜率的必要条件）。第一项 $\\sigma^2/n$ 相对于 $c$ 是一个常数。第二项 $\\sigma^2 \\frac{(c - \\bar{x})^2}{S_{xx}}$ 依赖于 $c$。由于 $(c - \\bar{x})^2 \\ge 0$，该项是非负的，其最小值为 $0$。当 $c - \\bar{x} = 0$ 时达到最小值，这意味着 $c = \\bar{x}$。\n或者，我们可以使用微积分。设 $f(c) = \\operatorname{Var}(\\hat{\\alpha}_c)$。我们求其关于 $c$ 的导数：\n$$\n\\frac{d}{dc}f(c) = \\frac{d}{dc} \\left( \\sigma^2 \\left[ \\frac{1}{n} + \\frac{(c - \\bar{x})^2}{S_{xx}} \\right] \\right) = \\frac{\\sigma^2}{S_{xx}} \\cdot 2(c-\\bar{x})\n$$\n将导数设为零以找到临界点：\n$$\n\\frac{2\\sigma^2}{S_{xx}}(c-\\bar{x}) = 0\n$$\n这意味着 $c - \\bar{x} = 0$，所以 $c = \\bar{x}$。二阶导数为 $\\frac{d^2}{dc^2}f(c) = \\frac{2\\sigma^2}{S_{xx}} > 0$，这证实了 $c=\\bar{x}$ 对应一个最小值。\n因此，当预测变量在其样本均值 $\\bar{x}$ 处中心化时，估计截距的方差最小。", "answer": "$$\\boxed{\\bar{x}}$$", "id": "4952529"}, {"introduction": "理论模型常常假设数据是“表现良好”的，但真实世界的数据集可能包含一些会不成比例地影响我们分析结果的极端观测值。本练习将通过一个具体案例，生动地展示一个“强影响点”如何能够完全扭转模型的结论。我们将学习使用杠杆值（leverage）和库克距离（Cook's distance）等核心诊断工具，来识别并量化这些数据点的影响，这是任何数据分析师都必须掌握的关键技能。[@problem_id:4952475]", "problem": "一位生物统计学家正在使用带截距的简单线性回归模型来建模标准化日钠摄入量与标准化收缩压之间的关系。设模型为 $Y = \\beta_{0} + \\beta_{1} X + \\varepsilon$，其中 $Y$ 是标准化收缩压，$X$ 是标准化日钠摄入量（z-score），$\\varepsilon$ 是一个均值为 $0$ 且方差恒定的随机误差项。该生物统计学家从 $5$ 名受试者的数据开始：\n- 受试者 1：$(x_{1}, y_{1}) = (-1, -1)$\n- 受试者 2：$(x_{2}, y_{2}) = \\left(-\\frac{1}{2}, -\\frac{1}{2}\\right)$\n- 受试者 3：$(x_{3}, y_{3}) = (0, 0)$\n- 受试者 4：$(x_{4}, y_{4}) = \\left(\\frac{1}{2}, \\frac{1}{2}\\right)$\n- 受试者 5：$(x_{5}, y_{5}) = (1, 1)$\n\n她将简单线性回归模型拟合到这 $5$ 名受试者的数据上，并记录了斜率估计值 $\\hat{\\beta}_{1}^{(5)}$。\n\n之后，她增加了一个钠摄入量极端但血压较低的第 $6$ 名受试者：\n- 受试者 6：$(x_{6}, y_{6}) = (4, -2)$\n\n她对所有 $6$ 名受试者的数据重新拟合模型，并记录了新的斜率 $\\hat{\\beta}_{1}^{(6)}$。使用帽子矩阵和库克距离（Cook's $D$）的标准定义，计算在 $6$ 名受试者拟合下第 $6$ 名受试者的杠杆值 $h_{66}$ 以及量化第 $6$ 名受试者影响力的库克距离 $D_{6}$。\n\n提供精确值（不要四舍五入），并以行矩阵的形式表示您的最终答案，矩阵中依次包含 $\\hat{\\beta}_{1}^{(5)}$、$\\hat{\\beta}_{1}^{(6)}$、$h_{66}$ 和 $D_{6}$。", "solution": "题目陈述是生物统计学中一个表述清晰且标准的练习，特别是在简单线性回归诊断的应用方面。它提供了所有必要的数据，并明确定义了需要计算的量。该问题具有科学依据，客观，且不包含内部矛盾或模糊之处。因此，这是一个有效的问题。\n\n任务是计算四个量：初始 $5$ 名受试者的回归斜率 $\\hat{\\beta}_{1}^{(5)}$；所有 $6$ 名受试者的斜率 $\\hat{\\beta}_{1}^{(6)}$；第 $6$ 名受试者的杠杆值 $h_{66}$；以及第 $6$ 名受试者的库克距离 $D_{6}$。\n\n**第1部分：计算初始5名受试者的斜率 $\\hat{\\beta}_{1}^{(5)}$**\n\n简单线性回归模型为 $Y = \\beta_{0} + \\beta_{1} X + \\varepsilon$。斜率 $\\hat{\\beta}_{1}$ 的最小二乘估计由以下公式给出：\n$$ \\hat{\\beta}_{1} = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2} $$\n对于前 $n=5$ 名受试者，数据为 $(x_1, y_1) = (-1, -1)$、$(x_2, y_2) = (-\\frac{1}{2}, -\\frac{1}{2})$、$(x_3, y_3) = (0, 0)$、$(x_4, y_4) = (\\frac{1}{2}, \\frac{1}{2})$ 和 $(x_5, y_5) = (1, 1)$。\n\n首先，我们计算样本均值 $\\bar{x}^{(5)}$ 和 $\\bar{y}^{(5)}$：\n$$ \\bar{x}^{(5)} = \\frac{1}{5} \\sum_{i=1}^{5} x_i = \\frac{1}{5} \\left( -1 - \\frac{1}{2} + 0 + \\frac{1}{2} + 1 \\right) = \\frac{0}{5} = 0 $$\n$$ \\bar{y}^{(5)} = \\frac{1}{5} \\sum_{i=1}^{5} y_i = \\frac{1}{5} \\left( -1 - \\frac{1}{2} + 0 + \\frac{1}{2} + 1 \\right) = \\frac{0}{5} = 0 $$\n由于均值为零，斜率估计的公式简化为：\n$$ \\hat{\\beta}_{1}^{(5)} = \\frac{\\sum_{i=1}^{5} x_i y_i}{\\sum_{i=1}^{5} x_i^2} $$\n我们计算必要的总和：\n$$ \\sum_{i=1}^{5} x_i y_i = (-1)(-1) + \\left(-\\frac{1}{2}\\right)\\left(-\\frac{1}{2}\\right) + (0)(0) + \\left(\\frac{1}{2}\\right)\\left(\\frac{1}{2}\\right) + (1)(1) = 1 + \\frac{1}{4} + 0 + \\frac{1}{4} + 1 = \\frac{5}{2} $$\n$$ \\sum_{i=1}^{5} x_i^2 = (-1)^2 + \\left(-\\frac{1}{2}\\right)^2 + 0^2 + \\left(\\frac{1}{2}\\right)^2 + 1^2 = 1 + \\frac{1}{4} + 0 + \\frac{1}{4} + 1 = \\frac{5}{2} $$\n因此，斜率为：\n$$ \\hat{\\beta}_{1}^{(5)} = \\frac{5/2}{5/2} = 1 $$\n\n**第2部分：计算所有6名受试者的斜率 $\\hat{\\beta}_{1}^{(6)}$**\n\n现在我们加入第 $6$ 名受试者 $(x_6, y_6) = (4, -2)$。数据集有 $n=6$ 个点。我们计算新的样本均值：\n$$ \\bar{x}^{(6)} = \\frac{1}{6} \\sum_{i=1}^{6} x_i = \\frac{1}{6} \\left( (\\sum_{i=1}^{5} x_i) + x_6 \\right) = \\frac{1}{6}(0 + 4) = \\frac{4}{6} = \\frac{2}{3} $$\n$$ \\bar{y}^{(6)} = \\frac{1}{6} \\sum_{i=1}^{6} y_i = \\frac{1}{6} \\left( (\\sum_{i=1}^{5} y_i) + y_6 \\right) = \\frac{1}{6}(0 - 2) = -\\frac{2}{6} = -\\frac{1}{3} $$\n我们需要 $\\sum_{i=1}^{6} (x_i - \\bar{x}^{(6)})(y_i - \\bar{y}^{(6)})$ 和 $\\sum_{i=1}^{6} (x_i - \\bar{x}^{(6)})^2$ 这两项。我们可以使用计算公式 $\\sum(x_i-\\bar{x})(y_i-\\bar{y}) = \\sum x_iy_i - n\\bar{x}\\bar{y}$。\n$$ \\sum_{i=1}^{6} x_i y_i = \\left( \\sum_{i=1}^{5} x_i y_i \\right) + x_6 y_6 = \\frac{5}{2} + (4)(-2) = \\frac{5}{2} - 8 = -\\frac{11}{2} $$\n$\\hat{\\beta}_{1}^{(6)}$ 的分子是：\n$$ \\sum_{i=1}^{6} (x_i - \\bar{x}^{(6)})(y_i - \\bar{y}^{(6)}) = \\sum_{i=1}^{6} x_i y_i - 6 \\bar{x}^{(6)} \\bar{y}^{(6)} = -\\frac{11}{2} - 6 \\left(\\frac{2}{3}\\right) \\left(-\\frac{1}{3}\\right) = -\\frac{11}{2} + \\frac{12}{9} = -\\frac{11}{2} + \\frac{4}{3} = \\frac{-33+8}{6} = -\\frac{25}{6} $$\n对于分母，我们使用 $\\sum(x_i-\\bar{x})^2 = \\sum x_i^2 - n\\bar{x}^2$：\n$$ \\sum_{i=1}^{6} x_i^2 = \\left( \\sum_{i=1}^{5} x_i^2 \\right) + x_6^2 = \\frac{5}{2} + 4^2 = \\frac{5}{2} + 16 = \\frac{37}{2} $$\n$\\hat{\\beta}_{1}^{(6)}$ 的分母是：\n$$ \\sum_{i=1}^{6} (x_i - \\bar{x}^{(6)})^2 = \\sum_{i=1}^{6} x_i^2 - 6 (\\bar{x}^{(6)})^2 = \\frac{37}{2} - 6 \\left(\\frac{2}{3}\\right)^2 = \\frac{37}{2} - 6 \\left(\\frac{4}{9}\\right) = \\frac{37}{2} - \\frac{8}{3} = \\frac{111 - 16}{6} = \\frac{95}{6} $$\n新的斜率为：\n$$ \\hat{\\beta}_{1}^{(6)} = \\frac{-25/6}{95/6} = -\\frac{25}{95} = -\\frac{5}{19} $$\n\n**第3部分：计算第6名受试者的杠杆值 $h_{66}$**\n\n第 $i$ 个数据点的杠杆值 $h_{ii}$ 衡量其对拟合值的影响。对于简单线性回归，它由以下公式给出：\n$$ h_{ii} = \\frac{1}{n} + \\frac{(x_i - \\bar{x})^2}{\\sum_{j=1}^{n} (x_j - \\bar{x})^2} $$\n我们需要为 $n=6$ 数据集中的第 $6$ 名受试者（$i=6$）计算这个值。\n使用在第2部分中计算的值：\n- $n = 6$\n- $x_6 = 4$\n- $\\bar{x}^{(6)} = \\frac{2}{3}$\n- $\\sum_{j=1}^{6} (x_j - \\bar{x}^{(6)})^2 = \\frac{95}{6}$\n首先，我们求 $(x_6 - \\bar{x}^{(6)})^2$：\n$$ (x_6 - \\bar{x}^{(6)})^2 = \\left(4 - \\frac{2}{3}\\right)^2 = \\left(\\frac{12-2}{3}\\right)^2 = \\left(\\frac{10}{3}\\right)^2 = \\frac{100}{9} $$\n现在我们计算 $h_{66}$：\n$$ h_{66} = \\frac{1}{6} + \\frac{100/9}{95/6} = \\frac{1}{6} + \\frac{100}{9} \\cdot \\frac{6}{95} = \\frac{1}{6} + \\frac{100 \\cdot 2}{3 \\cdot 95} = \\frac{1}{6} + \\frac{200}{285} $$\n将第二项的分子和分母同除以 $5$ 进行化简：$\\frac{200}{285} = \\frac{40}{57}$。\n$$ h_{66} = \\frac{1}{6} + \\frac{40}{57} = \\frac{19}{114} + \\frac{80}{114} = \\frac{99}{114} $$\n将分数同除以 $3$ 进行化简：\n$$ h_{66} = \\frac{33}{38} $$\n\n**第4部分：计算第6名受试者的库克距离 $D_6$**\n\n库克距离 $D_i$ 衡量删除第 $i$ 个观测值对回归系数的影响。一个标准公式是：\n$$ D_i = \\frac{e_i^2}{p \\cdot \\text{MSE}} \\frac{h_{ii}}{(1-h_{ii})^2} $$\n其中 $e_i$ 是第 $i$ 个点的残差，$p$ 是估计参数的数量（对于 $\\beta_0, \\beta_1$，$p=2$），MSE 是均方误差。\n\n首先，我们需要 $n=6$ 的拟合模型来计算残差 $e_6$。截距估计值为：\n$$ \\hat{\\beta}_{0}^{(6)} = \\bar{y}^{(6)} - \\hat{\\beta}_{1}^{(6)} \\bar{x}^{(6)} = -\\frac{1}{3} - \\left(-\\frac{5}{19}\\right)\\left(\\frac{2}{3}\\right) = -\\frac{1}{3} + \\frac{10}{57} = \\frac{-19+10}{57} = -\\frac{9}{57} = -\\frac{3}{19} $$\n拟合的回归线是 $\\hat{y} = -\\frac{3}{19} - \\frac{5}{19}x$。\n对于 $x_6=4$ 的拟合值为：\n$$ \\hat{y}_6 = -\\frac{3}{19} - \\frac{5}{19}(4) = -\\frac{3}{19} - \\frac{20}{19} = -\\frac{23}{19} $$\n第 $6$ 名受试者的残差是：\n$$ e_6 = y_6 - \\hat{y}_6 = -2 - \\left(-\\frac{23}{19}\\right) = \\frac{-38+23}{19} = -\\frac{15}{19} $$\n接下来，我们计算误差平方和（SSE）和均方误差（MSE）。\n$$ \\text{SSE} = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 = \\sum_{i=1}^{6} (y_i - \\bar{y}^{(6)})^2 - (\\hat{\\beta}_{1}^{(6)})^2 \\sum_{i=1}^{6} (x_i - \\bar{x}^{(6)})^2 $$\n我们需要 $\\sum_{i=1}^{6} (y_i - \\bar{y}^{(6)})^2 = \\sum y_i^2 - n(\\bar{y}^{(6)})^2$。\n$$ \\sum_{i=1}^{6} y_i^2 = \\left(\\sum_{i=1}^{5} y_i^2\\right) + y_6^2 = \\left( (-1)^2 + (-\\frac{1}{2})^2 + 0^2 + (\\frac{1}{2})^2 + 1^2 \\right) + (-2)^2 = \\left(1 + \\frac{1}{4} + 0 + \\frac{1}{4} + 1\\right) + 4 = \\frac{5}{2} + 4 = \\frac{13}{2} $$\n$$ \\sum_{i=1}^{6} (y_i - \\bar{y}^{(6)})^2 = \\frac{13}{2} - 6\\left(-\\frac{1}{3}\\right)^2 = \\frac{13}{2} - 6\\left(\\frac{1}{9}\\right) = \\frac{13}{2} - \\frac{2}{3} = \\frac{39-4}{6} = \\frac{35}{6} $$\n现在，为了精确起见，使用另一个公式计算SSE：\n$$ \\text{SSE} = \\sum_{i=1}^{6} (y_i - \\bar{y}^{(6)})^2 - \\hat{\\beta}_{1}^{(6)} \\sum_{i=1}^{6} (x_i - \\bar{x}^{(6)})(y_i - \\bar{y}^{(6)}) = \\frac{35}{6} - \\left(-\\frac{5}{19}\\right) \\left(-\\frac{25}{6}\\right) = \\frac{35}{6} - \\frac{125}{114} = \\frac{35 \\times 19}{114} - \\frac{125}{114} = \\frac{665 - 125}{114} = \\frac{540}{114} = \\frac{90}{19} $$\nMSE 是 SSE 除以自由度（$n-p = 6-2 = 4$）：\n$$ \\text{MSE} = \\frac{\\text{SSE}}{n-p} = \\frac{90/19}{4} = \\frac{90}{76} = \\frac{45}{38} $$\n我们有了计算 $D_6$ 的所有组成部分：\n- $e_6^2 = \\left(-\\frac{15}{19}\\right)^2 = \\frac{225}{361}$\n- $p=2$\n- $\\text{MSE} = \\frac{45}{38}$\n- $h_{66} = \\frac{33}{38}$\n- $1-h_{66} = 1 - \\frac{33}{38} = \\frac{5}{38}$\n- $(1-h_{66})^2 = \\left(\\frac{5}{38}\\right)^2 = \\frac{25}{1444}$\n\n将这些值代入库克距离公式：\n$$ D_6 = \\frac{e_6^2}{p \\cdot \\text{MSE}} \\frac{h_{66}}{(1-h_{66})^2} = \\frac{\\frac{225}{361}}{2 \\cdot \\frac{45}{38}} \\cdot \\frac{\\frac{33}{38}}{\\frac{25}{1444}} $$\n让我们计算各个部分。注意 $361 = 19^2$，$38=2 \\times 19$，以及 $1444=38^2=(2 \\times 19)^2$。\n$$ D_6 = \\frac{\\frac{225}{19^2}}{\\frac{90}{38}} \\cdot \\frac{\\frac{33}{38}}{\\frac{25}{38^2}} = \\left(\\frac{225}{19^2} \\cdot \\frac{38}{90}\\right) \\cdot \\left(\\frac{33}{38} \\cdot \\frac{38^2}{25}\\right) $$\n$$ D_6 = \\left(\\frac{225}{19^2} \\cdot \\frac{2 \\cdot 19}{90}\\right) \\cdot \\left(\\frac{33 \\cdot 38}{25}\\right) = \\left(\\frac{225 \\cdot 2}{19 \\cdot 90}\\right) \\cdot \\left(\\frac{33 \\cdot 38}{25}\\right) $$\n由于 $225 = 2.5 \\times 90$，第一个括号内变为 $\\frac{2.5 \\times 2}{19} = \\frac{5}{19}$。\n$$ D_6 = \\frac{5}{19} \\cdot \\frac{33 \\cdot 38}{25} = \\frac{5}{19} \\cdot \\frac{33 \\cdot (2 \\cdot 19)}{25} = \\frac{5 \\cdot 33 \\cdot 2}{25} = \\frac{10 \\cdot 33}{25} = \\frac{2 \\cdot 33}{5} = \\frac{66}{5} $$\n\n**结果总结**\n四个所需的值是：\n1. $\\hat{\\beta}_{1}^{(5)} = 1$\n2. $\\hat{\\beta}_{1}^{(6)} = -\\frac{5}{19}$\n3. $h_{66} = \\frac{33}{38}$\n4. $D_6 = \\frac{66}{5}$\n这些将按要求以行矩阵的形式呈现。", "answer": "$$ \\boxed{ \\begin{pmatrix} 1  -\\frac{5}{19}  \\frac{33}{38}  \\frac{66}{5} \\end{pmatrix} } $$", "id": "4952475"}]}