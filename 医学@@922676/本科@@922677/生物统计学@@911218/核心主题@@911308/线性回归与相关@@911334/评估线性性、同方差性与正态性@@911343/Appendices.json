{"hands_on_practices": [{"introduction": "在进行回归诊断时，一个常见且关键的误解是混淆了响应变量 $Y$ 的正态性与模型误差 $\\varepsilon$ 的正态性。本练习旨在通过具体的反例，帮助你从根本上理解线性回归的正态性假设究竟指向何者[@problem_id:4894614]。厘清这一点是正确应用和解释回归模型诊断工具的基础。", "problem": "一位生物统计学家正在使用简单线性回归模型，分析一个结局变量 $Y$（例如，一个连续的生物标志物）与一个单一预测变量 $X$（例如，一个二元基因型指示变量或一个连续暴露量）之间的函数关系。建模的目标是以支持对回归斜率进行有效推断的方式，来检验线性、同方差性和正态性。\n\n根据经典线性模型的基本原理，其核心假设是：给定 $X$ 时 $Y$ 的条件均值是线性的，给定 $X$ 时 $Y$ 的条件方差是恒定的，并且误差在给定条件下是独立同分布的，服从一个指定的分布。具体来说，设模型为 $Y=\\beta_0+\\beta_1 X+\\varepsilon$，其中 $\\mathbb{E}(\\varepsilon\\mid X)=0$ 且 $\\operatorname{Var}(\\varepsilon\\mid X)=\\sigma^2$；当作出正态性假设时，该假设是指 $\\varepsilon\\mid X\\sim \\mathcal{N}(0,\\sigma^2)$ 且独立于 $X$。\n\n选择所有正确的陈述。你的选择应能正确区分误差的正态性与 $Y$ 的正态性，并能识别出一个具体案例，在该案例中，即使误差在以 $X$ 为条件时是正态的，$Y$ 却是非正态的，同时还应包括对线性关系和同方差性的恰当评估方法。\n\nA. 经典线性模型中的正态性假设指的是误差 $\\varepsilon=Y-\\mathbb{E}(Y\\mid X)$ 的条件分布（等价于 $Y\\mid X$ 围绕其均值的分布），而非 $Y$ 的边缘分布。\n\nB. 如果 $X\\in\\{0,1\\}$ 且 $\\mathbb{P}(X=1)=0.5$，$\\beta_1\\neq 0$，并且 $\\varepsilon\\mid X\\sim \\mathcal{N}(0,\\sigma^2)$ 独立于 $X$，那么 $Y$ 的边缘分布是正态分布，其方差为 $\\sigma^2+0.25\\,\\beta_1^2$。\n\nC. 如果 $X\\in\\{0,1\\}$ 且 $\\mathbb{P}(X=1)=p\\in(0,1)$，$\\beta_1\\neq 0$，并且 $\\varepsilon\\mid X\\sim \\mathcal{N}(0,\\sigma^2)$ 独立于 $X$，那么 $Y$ 的边缘分布是一个双组分正态混合分布，通常是非正态的；尽管如此，条件误差是正态且同方差的。\n\nD. 线性模型中的同方差性意味着 $\\operatorname{Var}(Y\\mid X=x)$ 对于 $x$ 是一个常数，因此如果该假设成立，残差对拟合值图应不显示系统性的扇形散布或曲率。\n\nE. 为了评估线性回归中作为 $t$ 检验和置信区间基础的正态性假设，检查原始响应变量 $Y$ 的分位数-分位数（Q–Q）图并对其进行 Shapiro–Wilk 检验就足够了，因为如果 $Y$ 是正态的，那么误差也必须是正态的。\n\nF. 在模型 $Y=\\beta_0+\\beta_1 X+\\varepsilon$ 中，若 $\\varepsilon\\mid X\\sim \\mathcal{N}(0,\\sigma^2)$，如果 $X$ 是连续且非正态的（例如，$X\\sim \\operatorname{Uniform}[0,1]$）并且独立于 $\\varepsilon$，那么即使条件误差是正态的，$Y$ 的边缘分布通常也是非正态的。\n\n选择所有适用的选项。", "solution": "问题陈述为简单线性回归模型及其基本假设提供了正确且标准的定义。设模型为 $Y=\\beta_0+\\beta_1 X+\\varepsilon$。用于推断的核心假设是：\n1.  **线性 (Linearity)**：$\\mathbb{E}(Y \\mid X=x) = \\beta_0 + \\beta_1 x$。这等价于陈述 $\\mathbb{E}(\\varepsilon \\mid X) = 0$。\n2.  **同方差性 (Homoscedasticity)**：对所有 $x$，$\\operatorname{Var}(Y \\mid X=x) = \\sigma^2$。这等价于陈述 $\\operatorname{Var}(\\varepsilon \\mid X) = \\sigma^2$，一个常数。\n3.  **误差的正态性 (Normality of Errors)**：误差在以 $X$ 为条件下呈正态分布。即 $\\varepsilon \\mid X \\sim \\mathcal{N}(0, \\sigma^2)$。这意味着 $Y \\mid X \\sim \\mathcal{N}(\\beta_0 + \\beta_1 X, \\sigma^2)$。\n4.  **独立性 (Independence)**：不同观测值的误差 $\\varepsilon_i$ 是独立的。\n\n该问题具有科学依据，表述清晰且客观。我们可以根据这些原则来评估每个陈述。\n\n**A. 经典线性模型中的正态性假设指的是误差 $\\varepsilon=Y-\\mathbb{E}(Y\\mid X)$ 的条件分布（等价于 $Y\\mid X$ 围绕其均值的分布），而非 $Y$ 的边缘分布。**\n\n模型为 $Y = \\mathbb{E}(Y \\mid X) + \\varepsilon$。根据定义，误差项为 $\\varepsilon = Y - \\mathbb{E}(Y \\mid X)$。正态性假设是小样本中 $t$ 检验和置信区间有效性的关键，它是针对这个误差项指定的。具体来说，该假设是指对于预测变量 $X$ 的任何给定值，误差都从一个均值为 0、方差为 $\\sigma^2$ 的正态分布中抽取。这正是条件分布 $\\varepsilon \\mid X$。\n\n等价地，由于 $Y \\mid X = \\mathbb{E}(Y \\mid X) + (\\varepsilon \\mid X)$，并且对于给定的 $X$，$\\mathbb{E}(Y \\mid X)$ 是固定的，因此给定 $X$ 的 $Y$ 的条件分布是一个被其均值 $\\mathbb{E}(Y \\mid X)$ 平移的正态分布。所以，$Y \\mid X \\sim \\mathcal{N}(\\mathbb{E}(Y \\mid X), \\sigma^2)$。\n\n该假设与 $Y$ 的边缘分布（忽略 $X$ 的 $Y$ 的分布）无关，我们将会看到，该边缘分布通常是非正态的。这个陈述是对正态性假设的正确且基本的阐述。\n\n结论：**正确**。\n\n**B. 如果 $X\\in\\{0,1\\}$ 且 $\\mathbb{P}(X=1)=0.5$，$\\beta_1\\neq 0$，并且 $\\varepsilon\\mid X\\sim \\mathcal{N}(0,\\sigma^2)$ 独立于 $X$，那么 $Y$ 的边缘分布是正态分布，其方差为 $\\sigma^2+0.25\\,\\beta_1^2$。**\n\n我们来确定 $Y$ 的边缘分布和方差。$Y$ 的分布是其条件分布的混合。\n-   如果 $X=0$（概率为 0.5），则 $Y \\mid (X=0) = \\beta_0 + \\varepsilon \\sim \\mathcal{N}(\\beta_0, \\sigma^2)$。\n-   如果 $X=1$（概率为 0.5），则 $Y \\mid (X=1) = \\beta_0 + \\beta_1 + \\varepsilon \\sim \\mathcal{N}(\\beta_0+\\beta_1, \\sigma^2)$。\n\n$Y$ 的边缘概率密度函数由全概率定律给出：\n$f_Y(y) = f_{Y \\mid X}(y \\mid 0)\\mathbb{P}(X=0) + f_{Y \\mid X}(y \\mid 1)\\mathbb{P}(X=1)$\n$f_Y(y) = 0.5 \\cdot \\phi(y; \\beta_0, \\sigma^2) + 0.5 \\cdot \\phi(y; \\beta_0+\\beta_1, \\sigma^2)$，其中 $\\phi(y; \\mu, \\sigma^2)$ 是正态概率密度函数（PDF）。\n这是一个具有不同均值的两个正态分布的混合（因为 $\\beta_1 \\neq 0$）。两个不同正态分布的混合不是一个正态分布。因此，“$Y$ 的边缘分布是正态的”这一说法是错误的。\n\n现在我们使用全方差定律来计算 $Y$ 的边缘方差：$\\operatorname{Var}(Y) = \\mathbb{E}[\\operatorname{Var}(Y \\mid X)] + \\operatorname{Var}[\\mathbb{E}(Y \\mid X)]$。\n-   条件方差为 $\\operatorname{Var}(Y \\mid X) = \\operatorname{Var}(\\beta_0 + \\beta_1 X + \\varepsilon \\mid X) = \\operatorname{Var}(\\varepsilon \\mid X) = \\sigma^2$。这是一个常数，所以 $\\mathbb{E}[\\operatorname{Var}(Y \\mid X)] = \\sigma^2$。\n-   条件期望为 $\\mathbb{E}(Y \\mid X) = \\beta_0 + \\beta_1 X$。\n-   我们需要计算这一项的方差：$\\operatorname{Var}[\\mathbb{E}(Y \\mid X)] = \\operatorname{Var}(\\beta_0 + \\beta_1 X) = \\beta_1^2 \\operatorname{Var}(X)$。\n-   对于 $X \\sim \\text{Bernoulli}(p=0.5)$，$\\operatorname{Var}(X) = p(1-p) = 0.5(1-0.5) = 0.25$。\n-   所以，$\\operatorname{Var}[\\mathbb{E}(Y \\mid X)] = \\beta_1^2 (0.25) = 0.25 \\beta_1^2$。\n-   综合起来：$\\operatorname{Var}(Y) = \\sigma^2 + 0.25 \\beta_1^2$。\n\n方差的计算是正确的，但该陈述声称 $Y$ 的边缘分布是正态的，这是不正确的。一个陈述必须完全正确。\n\n结论：**不正确**。\n\n**C. 如果 $X\\in\\{0,1\\}$ 且 $\\mathbb{P}(X=1)=p\\in(0,1)$，$\\beta_1\\neq 0$，并且 $\\varepsilon\\mid X\\sim \\mathcal{N}(0,\\sigma^2)$ 独立于 $X$，那么 $Y$ 的边缘分布是一个双组分正态混合分布，通常是非正态的；尽管如此，条件误差是正态且同方差的。**\n\n这个陈述是 B 中设置的推广。\n-   $Y$ 的边缘分布是 $\\mathcal{N}(\\beta_0, \\sigma^2)$（权重为 $1-p$）和 $\\mathcal{N}(\\beta_0+\\beta_1, \\sigma^2)$（权重为 $p$）的混合。由于 $p \\in (0,1)$ 且 $\\beta_1 \\neq 0$，这两个组分是不同的，并且都具有非零权重。这样的混合分布不是正态分布。所以，陈述的第一部分是正确的。\n-   问题陈述了 $\\varepsilon\\mid X\\sim \\mathcal{N}(0,\\sigma^2)$。这直接意味着条件误差是正态的。\n-   条件误差的方差是 $\\operatorname{Var}(\\varepsilon \\mid X) = \\sigma^2$。由于 $\\sigma^2$ 是一个不依赖于 $X$ 值的常数，所以误差是同方差的。\n\n这个陈述的所有部分都是正确的。它准确地描述了一个回归模型假设成立，但结局变量的边缘分布却非正态的情景。\n\n结论：**正确**。\n\n**D. 线性模型中的同方差性意味着 $\\operatorname{Var}(Y\\mid X=x)$ 对于 $x$ 是一个常数，因此如果该假设成立，残差对拟合值图应不显示系统性的扇形散布或曲率。**\n\n陈述的第一部分，“同方差性...意味着 $\\operatorname{Var}(Y\\mid X=x)$ 对于 $x$ 是一个常数”，是正确的定义。\n第二部分是一个推论：“因此如果该假设成立，残差对拟合值图应不显示系统性的扇形散布或曲率。”\n我们来分析这个诊断图的组成部分。\n-   **扇形散布 (Fanning)**：残差对拟合值图中的“扇形”或“锥形”形状意味着残差的方差随着拟合值的水平而变化。没有扇形散布是同方差性的图形证据。所以，如果同方差性成立，我们期望没有系统性的扇形散布。\n-   **曲率 (Curvature)**：残差对拟合值图中的“曲率”或任何非随机模式表明线性假设被违反（$\\mathbb{E}(Y \\mid X)$ 不是 $X$ 的线性函数）。\n该陈述声称如果同方差性成立，则应该*没有曲率*。这是错误的。一个模型可以在违反线性假设的同时保持同方差性。例如，如果真实模型是 $Y = \\beta_0 + \\beta_1 X^2 + \\varepsilon$ 且 $\\operatorname{Var}(\\varepsilon)=\\sigma^2$，而我们错误地拟合了 $Y = \\alpha_0 + \\alpha_1 X + \\eta$，那么误差是同方差的，但残差图将显示出一条明显的抛物线曲线。同方差性并不意味着线性。因此，同方差性的存在并不能保证残差图中没有曲率。\n\n结论：**不正确**。\n\n**E. 为了评估线性回归中作为 $t$ 检验和置信区间基础的正态性假设，检查原始响应变量 $Y$ 的分位数-分位数（Q–Q）图并对其进行 Shapiro–Wilk 检验就足够了，因为如果 $Y$ 是正态的，那么误差也必须是正态的。**\n\n线性回归推断的正态性假设是关于误差 $\\varepsilon$ 的，而不是响应变量 $Y$。正确的程序是评估估计残差 $\\hat{\\varepsilon}_i = y_i - \\hat{y}_i$ 的正态性，例如，对这些残差使用 Q-Q 图或 Shapiro-Wilk 检验。检验原始响应变量 $Y$ 是根本错误的，正如选项 C 和 F 中所展示的。即使模型假设完全满足，$Y$ 的边缘分布也常常是非正态的。\n\n所提供的理由，“因为如果 $Y$ 是正态的，那么误差也必须是正态的”，也是有缺陷且不相关的。关系是 $\\varepsilon = Y - (\\beta_0 + \\beta_1 X)$。$\\varepsilon$ 是否正态取决于 $Y$ 和 $X$ 两者的分布。例如，如果 $Y \\sim \\mathcal{N}$ 且 $X \\sim \\text{Bernoulli}$，那么 $\\varepsilon$ 将是两个正态分布的混合，因而不是正态的。这个推论通常不成立。但更重要的是，检验 $Y$ 的前提从一开始就是错误的。\n\n结论：**不正确**。\n\n**F. 在模型 $Y=\\beta_0+\\beta_1 X+\\varepsilon$ 中，若 $\\varepsilon\\mid X\\sim \\mathcal{N}(0,\\sigma^2)$，如果 $X$ 是连续且非正态的（例如，$X\\sim \\operatorname{Uniform}[0,1]$）并且独立于 $\\varepsilon$，那么即使条件误差是正态的，$Y$ 的边缘分布通常也是非正态的。**\n\n这个陈述提出了另一个具体的反例，反驳了结局变量 $Y$ 必须是正态的观点。\n-   给定了假设 $\\varepsilon \\mid X \\sim \\mathcal{N}(0,\\sigma^2)$，并且由于 $\\varepsilon$ 也独立于 $X$，这等价于 $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^2)$。条件误差确实是正态的。\n-   变量 $Y$ 是两个独立随机变量之和：$\\varepsilon$ 和 $(\\beta_0 + \\beta_1 X)$。\n-   我们以 $X \\sim \\operatorname{Uniform}[0,1]$ 为例。那么，假设 $\\beta_1 \\neq 0$，变量 $(\\beta_0 + \\beta_1 X)$ 服从均匀分布。\n-   一个正态分布变量与一个独立的、均匀分布的变量之和，可以通过对其概率密度函数进行卷积来求得。概率论中一个著名的结果（与 Cramér 分解定理相关）指出，两个独立随机变量之和为正态分布的充要条件是两个原始变量都是正态分布。\n-   由于均匀分布不是正态分布，和 $Y = (\\beta_0 + \\beta_1 X) + \\varepsilon$ 将不服从正态分布。\n这提供了一个有效的例子，说明模型假设（包括正态误差）可以成立，而 $Y$ 的边缘分布却非正态。\n\n结论：**正确**。\n\n最终正确选项总结：A, C, F。", "answer": "$$\\boxed{ACF}$$", "id": "4894614"}, {"introduction": "掌握了核心概念后，下一步便是亲手实践。本练习提供了一个编程挑战，要求你在不同数据情境下，从头开始构建一个完整的回归诊断流程[@problem_id:4894622]。通过实现包括线性、同方差性和正态性（使用自助法校准）在内的检验，你将不仅学会如何使用诊断工具，更能深刻理解其背后的统计原理。", "problem": "考虑经典固定设计线性模型：对于索引为 $i \\in \\{1,\\dots,n\\}$ 的观测值，设 $y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i$，其中 $\\varepsilon_i$ 是未观测到的误差。普通最小二乘（OLS）估计量通过最小化残差平方和计算得出，从而产生残差 $e_i = y_i - \\hat{y}_i$ 和拟合值 $\\hat{y}_i$。设 $X$ 表示 $n \\times p$ 的设计矩阵，包含一个截距列和预测变量，在基础线性拟合中 $p=2$。设 $H = X(X^\\top X)^{-1}X^\\top$ 为帽子矩阵，其对角元素为 $h_{ii}$。无偏残差方差估计量为 $\\hat{\\sigma}^2 = \\text{RSS}/(n - p)$，其中 $\\text{RSS} = \\sum_{i=1}^n e_i^2$。内学生化残差为 $r_i = e_i / (\\hat{\\sigma}\\sqrt{1 - h_{ii}})$。全文假设 $X$ 是满列秩的。\n\n您的任务是设计并实现一个程序，针对每个指定的测试用例，通过从拟合的线性模型中进行模拟，对小样本中的回归误差进行正态性检验的 bootstrap 校准。该校准必须根据以下第一性原理推导得出：\n\n1. 使用指定的 $X$ 和观测到的 $y$ 拟合 OLS 模型 $y = X\\beta + \\varepsilon$，从包含 $p=2$（截距和单个预测变量 $x$）的基础模型中获得 $r_i$，并对 $\\{r_i\\}_{i=1}^n$ 计算一个单变量正态性检验统计量（使用指定环境中任何可用的标准正态性检验统计量；此处不假设任何渐近分布）。\n\n2. 为了在正态误差的原假设下近似所选检验统计量的有限样本零分布，使用基于拟合线性模型的残差 bootstrap 方法：对于每个 bootstrap 复制 $b \\in \\{1,\\dots,B\\}$，从 $y^{(b)} = X\\hat{\\beta} + \\tilde{\\varepsilon}^{(b)}$ 中模拟一个伪响应向量 $y^{(b)}$，其中 $\\tilde{\\varepsilon}^{(b)}_i$ 是从均值为 $0$、方差为 $\\hat{\\sigma}^2$ 的正态分布中独立抽取的。对于每个 $y^{(b)}$，在 $(X, y^{(b)})$ 上重新拟合相同的 OLS 模型，计算相应的内学生化残差 $r^{(b)}_i$，对 $\\{r^{(b)}_i\\}_{i=1}^n$ 评估相同的正态性检验统计量，并收集这 $B$ 个 bootstrap 值。\n\n3. 将观测到的检验统计量与其在原假设下的 bootstrap 分布进行比较，以经验尾部概率的形式构成 bootstrap 校准的小样本 $p$ 值。如果所选的检验在统计量值较小时拒绝原假设，则使用经验累积分布函数 $p_{\\text{boot}} = \\frac{1 + \\#\\{b: T^{(b)} \\le T_{\\text{obs}}\\}}{B + 1}$，其中 $T_{\\text{obs}}$ 是观测到的统计量，$T^{(b)}$ 是 bootstrap 统计量。使用此 $p$ 值在水平 $\\alpha$ 下做出拒绝决策。\n\n除了对正态性进行 bootstrap 校准评估外，还需对每个测试用例执行以下操作：\n\n- 通过增加一个二次项来评估线性度，并检验 $x^2$ 的系数是否为零。具体来说，拟合 $y = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\varepsilon$ 并对 $H_0: \\beta_2 = 0$ 进行双边 $t$ 检验（水平为 $\\alpha$）。报告线性度是否被接受（如果不被拒绝则为布尔值 true）。\n\n- 通过 Breusch–Pagan 拉格朗日乘子检验来评估同方差性：将基础线性拟合的 $e_i^2$ 对基础设计（包括截距）进行回归，计算该辅助回归的 $R^2$，并构成 $\\text{LM} = n R^2$。在方差恒定的原假设下，$\\text{LM}$ 近似服从 $\\chi^2$ 分布，其自由度等于非截距项回归变量的数量。报告同方差性是否被接受（如果在水平 $\\alpha$ 下不被拒绝则为布尔值 true）。\n\n在您的推导和算法设计中应使用的基本依据包括线性模型的核心定义、最小二乘估计、帽子矩阵的构造、残差的性质，以及关于 bootstrap 近似抽样分布和 Breusch–Pagan 检验统计量在原假设下性质的经过充分检验的事实。\n\n为以下小样本情景测试套件实现上述过程。在每种情况下，设计点固定为 $x_i = \\frac{i-1}{n-1}$，其中 $i = 1,\\dots,n$；响应值根据指定的数据生成机制和独立误差生成。所有种子和参数都已给出；您必须精确使用它们以确保结果的确定性。bootstrap 校准必须使用指定的复制次数 $B$ 和给定的 bootstrap 种子。\n\n- 案例 A（理想情况，线性、同方差、正态误差）：$n = 12$，$\\beta_0 = 0.5$，$\\beta_1 = 1.2$，同方差正态误差，标准差 $\\sigma = 0.4$，数据生成种子 $202311$，bootstrap 复制次数 $B = 400$，bootstrap 种子 $777001$，检验水平 $\\alpha = 0.05$。\n\n- 案例 B（线性、同方差、重尾误差）：$n = 12$，$\\beta_0 = 0.5$，$\\beta_1 = 1.2$，误差服从自由度为 $\\nu = 3$ 的学生 $t$ 分布，经缩放后标准差为 $\\sigma = 0.4$，数据生成种子 $202312$，bootstrap 复制次数 $B = 400$，bootstrap 种子 $777002$，检验水平 $\\alpha = 0.05$。\n\n- 案例 C（线性均值、随 $x$ 递增的异方差正态误差）：$n = 12$，$\\beta_0 = 0.5$，$\\beta_1 = 1.2$，误差 $\\varepsilon_i \\sim \\mathcal{N}\\!\\left(0, \\sigma^2 (1 + x_i)^2\\right)$，其中 $\\sigma = 0.25$，数据生成种子 $202313$，bootstrap 复制次数 $B = 400$，bootstrap 种子 $777003$，检验水平 $\\alpha = 0.05$。\n\n- 案例 D（非线性均值、同方差正态误差）：$n = 12$，均值函数 $m(x) = \\beta_0 + \\beta_1 x + \\gamma x^2$，其中 $\\beta_0 = 0.5$，$\\beta_1 = 1.2$，$\\gamma = 0.8$，误差 $\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$，其中 $\\sigma = 0.4$，数据生成种子 $202314$，bootstrap 复制次数 $B = 400$，bootstrap 种子 $777004$，检验水平 $\\alpha = 0.05$。\n\n对于每个案例，您的程序必须：\n\n- 拟合包含截距和 $x$ 的基础线性模型。\n- 计算内学生化残差 $r_i$，并对 $\\{r_i\\}_{i=1}^n$ 评估一个标准的单变量正态性检验统计量及其名义 $p$ 值。\n- 使用指定的 $B$ 和 bootstrap 种子，在拟合的线性模型下执行 bootstrap 校准，并按上文所述计算 bootstrap 校准的 $p$ 值 $p_{\\text{boot}}$。\n- 使用 $p_{\\text{boot}}$ 在水平 $\\alpha$ 下做出 bootstrap 拒绝决策。\n- 通过二次项检验线性度，并报告一个表示接受的布尔值（true 表示未被拒绝，水平为 $\\alpha$）。\n- 通过 Breusch–Pagan 检验检验同方差性，并报告一个表示接受的布尔值（true 表示未被拒绝，水平为 $\\alpha$）。\n\n答案规范和最终输出格式：\n\n- 对于每个案例，生成一个包含五个条目的列表，顺序完全一致：bootstrap 校准的 $p$ 值（四舍五入到四位小数）、bootstrap 决策（布尔值，true 表示不拒绝正态性）、所选正态性检验的名义未校准 $p$ 值（四舍五入到四位小数）、线性度接受布尔值和同方差性接受布尔值。\n- 您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的每个元素对应 A、B、C、D 案例中的一个，且每个元素本身就是上述的五元条目列表。例如，输出必须类似于：$[ [p_{\\text{boot},A}, \\text{decision}_A, p_{\\text{naive},A}, \\text{linOK}_A, \\text{homoOK}_A], [p_{\\text{boot},B}, \\text{decision}_B, p_{\\text{naive},B}, \\text{linOK}_B, \\text{homoOK}_B], [\\dots], [\\dots] ]$，其中浮点数条目四舍五入到四位小数，布尔值拼写为 $True$ 或 $False$。", "solution": "该问题要求在各种小样本情景下，对一个简单线性回归模型进行全面的诊断分析。该分析涉及评估经典线性模型的三个关键假设：均值函数的线性性、误差的同方差性（恒定方差）以及误差的正态性。任务的核心是为正态性检验实现一个 bootstrap 校准，以便在小样本（$n=12$）情境下获得可靠的 $p$ 值，在这种情境下，检验统计量分布的渐近近似可能效果不佳。整个过程将针对四个不同的数据生成过程进行实现，以说明其在假设被满足和被违反的条件下的行为。\n\n首先，对于每个测试用例，我们必须生成数据。在所有案例中，预测变量 $x$ 均固定为区间 $[0, 1]$ 上的 $n=12$ 个等距点，具体为 $x_i = \\frac{i-1}{n-1}$，其中 $i \\in \\{1, \\dots, n\\}$。响应变量 $y_i$ 根据指定的模型生成，该模型因案例而异。\n\n基础步骤是拟合简单线性回归模型 $y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i$。设 $X$ 为 $n \\times 2$ 的设计矩阵，其第一列为全1，第二列为预测值 $\\{x_i\\}$。假设 $X$ 具有满列秩，则系数向量 $\\beta = [\\beta_0, \\beta_1]^\\top$ 的普通最小二乘（OLS）估计由 $\\hat{\\beta} = (X^\\top X)^{-1} X^\\top y$ 给出。由此，我们计算拟合值 $\\hat{y} = X\\hat{\\beta}$ 和残差 $e = y - \\hat{y}$。\n\n误差方差 $\\sigma^2$ 的一个无偏估计量是 $\\hat{\\sigma}^2 = \\frac{e^\\top e}{n-p}$，其中 $p=2$ 是基础模型中的参数数量。为正确评估正态性，我们分析内学生化残差，定义为 $r_i = \\frac{e_i}{\\hat{\\sigma}\\sqrt{1-h_{ii}}}$。此处，$h_{ii}$ 是帽子矩阵 $H = X(X^\\top X)^{-1} X^\\top$ 的对角元素。假设模型正确，这些残差经过缩放后具有近似恒定的方差。\n\n对三个假设的评估过程如下：\n\n1.  **误差的正态性**：通过对学生化残差 $\\{r_i\\}$ 应用正式的统计检验来检验底层误差 $\\varepsilon_i$ 的正态性。Shapiro-Wilk 检验因其高效能（尤其是在小样本量下）而成为一个合适的选择。设 $T_{\\text{obs}}$ 为从观测到的 $\\{r_i\\}$ 计算出的 Shapiro-Wilk 检验统计量，并设 $p_{\\text{nominal}}$ 为其基于该检验的标准渐近或近似零分布的对应名义 $p$ 值。\n\n    为了在小样本量下获得更准确的 $p$ 值，我们执行基于模型（或参数）的 bootstrap。该过程在假设拟合模型正确且误差确实为正态的前提下，模拟检验统计量的零分布。对于 $B$ 个 bootstrap 复制中的每一个：\n    a. 从均值为 $0$、方差为 $\\hat{\\sigma}^2$ 的正态分布中抽取一个 bootstrap 误差向量 $\\tilde{\\varepsilon}^{(b)}$，即 $\\tilde{\\varepsilon}^{(b)}_i \\sim \\mathcal{N}(0, \\hat{\\sigma}^2)$。\n    b. 生成一个伪响应向量 $y^{(b)} = X\\hat{\\beta} + \\tilde{\\varepsilon}^{(b)}$。\n    c. 使用 $(X, y^{(b)})$ 重新拟合 OLS 模型，以获得新的估计值、残差、新的方差估计 $\\hat{\\sigma}^{2(b)}$ 以及新的学生化残差 $\\{r^{(b)}_i\\}$。\n    d. 从 $\\{r^{(b)}_i\\}$ 计算 Shapiro-Wilk 检验统计量 $T^{(b)}$。\n\n    集合 $\\{T^{(b)}\\}_{b=1}^B$ 构成了检验统计量零分布的一个经验近似。Shapiro-Wilk 检验在其统计量值较小时拒绝原假设。因此，bootstrap 校准的 $p$ 值计算为 $p_{\\text{boot}} = \\frac{1 + \\#\\{b: T^{(b)} \\le T_{\\text{obs}}\\}}{B + 1}$。如果在显著性水平 $\\alpha$ 下 $p_{\\text{boot}} \\le \\alpha$，则拒绝正态性的原假设。\n\n2.  **均值函数的线性性**：通过检验是否存在特定形式的非线性来评估 $y$ 的均值是 $x$ 的线性函数这一假设。我们用一个二次项来增强基础模型，拟合 $y_i = \\beta_0 + \\beta_1 x_i + \\beta_2 x_i^2 + \\varepsilon_i$。线性性的原假设对应于 $H_0: \\beta_2 = 0$。这个假设使用双边 $t$ 检验进行检验。检验统计量为 $t = \\frac{\\hat{\\beta}_2}{\\text{se}(\\hat{\\beta}_2)}$，其中 $\\hat{\\beta}_2$ 是 $x^2$ 系数的 OLS 估计，$\\text{se}(\\hat{\\beta}_2)$ 是其标准误。在 $H_0$ 下，该统计量服从自由度为 $n-3$ 的学生 $t$ 分布。如果得到的 $p$ 值大于 $\\alpha$，则不拒绝线性性的原假设。\n\n3.  **误差的同方差性**：使用 Breusch-Pagan 拉格朗日乘子（LM）检验来检验误差方差恒定（同方差性）的假设。该检验检查误差的方差是否与预测变量相关。过程如下：\n    a. 从基础线性模型拟合中获得平方残差 $e_i^2$。\n    b. 执行一个辅助回归，将 $e_i^2$ 对原始预测变量（一个截距和 $x$）进行回归。\n    c. 计算该辅助回归的决定系数 $R^2$。\n    d. LM 检验统计量为 $\\text{LM} = n R^2$。\n\n    在同方差性的原假设下，该统计量渐近服从卡方分布 $\\chi^2_k$，其中 $k$ 是辅助回归中非截距项预测变量的数量。在本问题中，$k=1$。如果 $p$ 值 $P(\\chi^2_1 > \\text{LM})$ 大于 $\\alpha$，则不拒绝同方差性的原假设。\n\n这三项评估为模型假设提供了稳健的诊断检验。每个检验的结果都以布尔值的形式报告，表示该假设是否被接受（即原假设未被拒绝）。对于正态性，将报告 bootstrap 校准的 $p$ 值及其对应的决策，同时提供名义 $p$ 值以供比较。实现将忠实地为每个指定的测试用例执行这些步骤，使用提供的种子以确保可复现性。", "answer": "```python\nimport numpy as np\nfrom scipy import stats\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n\n    def process_case(n, model_params, error_spec, data_seed, B, boot_seed, alpha):\n        \"\"\"\n        Processes a single test case according to the problem description.\n        \"\"\"\n        # 1. Setup and Data Generation\n        data_rng = np.random.default_rng(data_seed)\n        \n        x = np.linspace(0.0, 1.0, n)\n        X_base = np.vstack([np.ones(n), x]).T\n        p_base = X_base.shape[1]\n\n        # Generate errors based on specification\n        if error_spec['type'] == 'normal':\n            sigma = error_spec['sigma']\n            errors = data_rng.normal(loc=0.0, scale=sigma, size=n)\n        elif error_spec['type'] == 'student-t':\n            nu = error_spec['nu']\n            sigma_target = error_spec['sigma']\n            # Variance of t(nu) is nu/(nu-2) for nu > 2\n            t_std_dev = np.sqrt(nu / (nu - 2.0))\n            scale_factor = sigma_target / t_std_dev\n            errors = stats.t.rvs(df=nu, size=n, random_state=data_rng) * scale_factor\n        elif error_spec['type'] == 'hetero-normal':\n            sigma = error_spec['sigma']\n            # Error variance is sigma^2 * (1+x)^2\n            error_std_devs = sigma * (1.0 + x)\n            errors = data_rng.normal(loc=0.0, scale=error_std_devs, size=n)\n        else:\n            raise ValueError(\"Unknown error specification type\")\n\n        # Generate response variable y\n        beta0, beta1 = model_params['beta0'], model_params['beta1']\n        true_mean = beta0 + beta1 * x\n        if 'gamma' in model_params: # Case D, nonlinear mean\n            true_mean += model_params['gamma'] * x**2\n        y = true_mean + errors\n\n        # 2. Base Linear Model Fit\n        beta_hat, rss_arr, _, _ = np.linalg.lstsq(X_base, y, rcond=None)\n        rss = rss_arr[0]\n        residuals = y - X_base @ beta_hat\n        \n        df_resid = n - p_base\n        sigma2_hat = rss / df_resid\n        sigma_hat = np.sqrt(sigma2_hat)\n\n        # Hat matrix diagonals h_ii using QR decomposition\n        Q, _ = np.linalg.qr(X_base)\n        h_ii = np.sum(Q**2, axis=1)\n\n        studentized_residuals = residuals / (sigma_hat * np.sqrt(1.0 - h_ii))\n\n        # 3. Normality Test (Observed Data)\n        T_obs, p_nominal = stats.shapiro(studentized_residuals)\n\n        # 4. Bootstrap Calibration\n        boot_rng = np.random.default_rng(boot_seed)\n        T_boot_values = np.zeros(B)\n        \n        y_fit_base = X_base @ beta_hat\n\n        for b in range(B):\n            # Generate bootstrap pseudo-response\n            eps_boot = boot_rng.normal(loc=0.0, scale=sigma_hat, size=n)\n            y_boot = y_fit_base + eps_boot\n            \n            # Refit OLS model\n            _, rss_b_arr, _, _ = np.linalg.lstsq(X_base, y_boot, rcond=None)\n            residuals_b = y_boot - X_base @ np.linalg.lstsq(X_base, y_boot, rcond=None)[0]\n            \n            sigma2_hat_b = rss_b_arr[0] / df_resid\n            sigma_hat_b = np.sqrt(sigma2_hat_b)\n            \n            # Avoid division by zero if sigma_hat_b is tiny\n            if sigma_hat_b > 1e-9:\n                studentized_residuals_b = residuals_b / (sigma_hat_b * np.sqrt(1.0 - h_ii))\n                T_boot_values[b], _ = stats.shapiro(studentized_residuals_b)\n            else: # Practically zero variance, residuals are ~0, max normality statistic\n                T_boot_values[b] = 1.0\n\n        # Calculate bootstrap p-value\n        count_le = np.sum(T_boot_values = T_obs)\n        p_boot = (1.0 + count_le) / (B + 1.0)\n        \n        normality_accepted_boot = p_boot > alpha\n\n        # 5. Linearity Test (Augmented Model with x^2)\n        x_sq = x**2\n        X_quad = np.vstack([np.ones(n), x, x_sq]).T\n        p_quad = X_quad.shape[1]\n\n        beta_quad_hat, rss_quad_arr, _, _ = np.linalg.lstsq(X_quad, y, rcond=None)\n        df_resid_quad = n - p_quad\n        sigma2_hat_quad = rss_quad_arr[0] / df_resid_quad\n        \n        cov_beta_quad = sigma2_hat_quad * np.linalg.inv(X_quad.T @ X_quad)\n        se_beta2 = np.sqrt(cov_beta_quad[2, 2])\n        \n        t_stat_beta2 = beta_quad_hat[2] / se_beta2\n        \n        p_linearity = 2.0 * stats.t.sf(np.abs(t_stat_beta2), df=df_resid_quad)\n        \n        linearity_accepted = p_linearity > alpha\n\n        # 6. Homoscedasticity Test (Breusch-Pagan)\n        e_sq = residuals**2\n        \n        _, rss_aux_arr, _, _ = np.linalg.lstsq(X_base, e_sq, rcond=None)\n        tss_aux = np.sum((e_sq - np.mean(e_sq))**2)\n        \n        if tss_aux > 1e-12:\n            r2_aux = 1.0 - rss_aux_arr[0] / tss_aux\n        else:\n            r2_aux = 0.0\n        \n        lm_stat = n * r2_aux\n        \n        df_bp = p_base - 1\n        p_homo = stats.chi2.sf(lm_stat, df=df_bp)\n        \n        homoscedasticity_accepted = p_homo > alpha\n\n        # 7. Collate and Format Results\n        return [\n            round(p_boot, 4),\n            normality_accepted_boot,\n            round(p_nominal, 4),\n            linearity_accepted,\n            homoscedasticity_accepted\n        ]\n\n    test_cases = [\n        { # Case A\n            \"n\": 12,\n            \"model_params\": {\"beta0\": 0.5, \"beta1\": 1.2},\n            \"error_spec\": {\"type\": \"normal\", \"sigma\": 0.4},\n            \"data_seed\": 202311,\n            \"B\": 400,\n            \"boot_seed\": 777001,\n            \"alpha\": 0.05\n        },\n        { # Case B\n            \"n\": 12,\n            \"model_params\": {\"beta0\": 0.5, \"beta1\": 1.2},\n            \"error_spec\": {\"type\": \"student-t\", \"nu\": 3, \"sigma\": 0.4},\n            \"data_seed\": 202312,\n            \"B\": 400,\n            \"boot_seed\": 777002,\n            \"alpha\": 0.05\n        },\n        { # Case C\n            \"n\": 12,\n            \"model_params\": {\"beta0\": 0.5, \"beta1\": 1.2},\n            \"error_spec\": {\"type\": \"hetero-normal\", \"sigma\": 0.25},\n            \"data_seed\": 202313,\n            \"B\": 400,\n            \"boot_seed\": 777003,\n            \"alpha\": 0.05\n        },\n        { # Case D\n            \"n\": 12,\n            \"model_params\": {\"beta0\": 0.5, \"beta1\": 1.2, \"gamma\": 0.8},\n            \"error_spec\": {\"type\": \"normal\", \"sigma\": 0.4},\n            \"data_seed\": 202314,\n            \"B\": 400,\n            \"boot_seed\": 777004,\n            \"alpha\": 0.05\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        result = process_case(**case)\n        results.append(result)\n\n    print(f\"[[{result[0]}, {str(result[1])}, {result[2]}, {str(result[3])}, {str(result[4])}] for result in results]\".replace(\"'\", \"\"))\n    # A bit of a hack to get the exact string format without quotes around booleans\n    # Proper way would be json.dumps but it uses double quotes. The requested output is specific.\n    output_str = \"[\"\n    for i, res in enumerate(results):\n        res_str = f\"[{res[0]}, {res[1]}, {res[2]}, {res[3]}, {res[4]}]\"\n        output_str += res_str\n        if i  len(results) - 1:\n            output_str += \", \"\n    output_str += \"]\"\n    # Manual replacement for boolean string format\n    output_str = output_str.replace(\"True\", \"True\").replace(\"False\", \"False\")\n    print(str(results).replace(\"'\", \"\"))\n\n\nsolve()\n```", "id": "4894622"}, {"introduction": "诊断出模型假设被违反只是第一步，更重要的是知道如何应对。本练习模拟了一个真实世界中的生物统计学挑战：在小样本和非理想数据（如偏态、异方差）的情况下，如何获得可靠的统计推断[@problem_id:4894646]。它将考验你选择最合适的补救措施（如自助法）的能力，这是从数据分析员成长为应用统计学家的关键一步。", "problem": "一位临床研究员研究2型糖尿病患者中尿白蛋白与肌酐比值 $Y$ (mg/g) 与收缩压 $X$ (mmHg) 之间的线性关联。该研究员对 $i = 1, \\dots, n$ 拟合了简单线性回归模型 $Y_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i$，其中 $n = 12$, $E[\\varepsilon_i] = 0$，并且在经典模型下假定 $\\text{Var}(\\varepsilon_i)$ 为常数。目的是估计斜率 $\\beta_1$ 的95%置信区间。标准做法通常依赖于普通最小二乘法 (OLS) 中的残差正态性和同方差性诊断来构建此类区间。然而，在该数据集中，诊断图显示如下：残差对拟合值图呈现出漏斗形状（方差随拟合值增大而增大），分位数-分位数 (Q-Q) 图表明存在重右尾，而 Shapiro–Wilk (SW) 检验得出的 $p$ 值为0.12（未拒绝正态性，但由于 $n$ 较小，检验效力有限）。此外，对 $\\log(Y)$ 进行分析的初步尝试并未解决这些问题：残差仍然是右偏的，并且残差对拟合值图显示出轻微的曲率，这引发了即使在变换后的尺度上对线性和同方差性的担忧。\n\n从第一性原理出发，在正态误差假设下推导出的置信区间依赖于某些分布结果，而这些结果在小样本 $n$ 且残差有偏、方差非恒定的情况下可能不成立。在这些条件下，研究员必须选择一种方法来获得对 $\\beta_1$ 更可靠的区间估计。\n\n在这种情况下，哪种方法最适合用来纠正为获得 $\\beta_1$ 置信区间而对残差正态性和同方差性的误导性依赖？\n\nA. 继续使用来自OLS的标准基于t分布的置信区间，理由是 Shapiro–Wilk 检验未拒绝正态性。\n\nB. 对 $Y$ 应用对数变换，重新拟合线性模型，并在重新检查诊断后，在变换后的尺度上构建常规的基于t分布的区间。\n\nC. 通过对观测到的配对 $(X_i, Y_i)$ 进行有放回的重抽样来近似斜率的抽样分布，从而为 $\\beta_1$ 构建一个非参数自助法置信区间，并使用自助法斜率的经验分位数（例如，百分位法或偏差校正和加速 (BCa) 法）来形成95%置信区间。\n\nD. 移除两个最大的残差观测值以恢复对称性，并重新计算标准的OLS基于t分布的区间。\n\nE. 依赖OLS斜率估计量的大样本渐近正态性，并使用基于正态分布的区间，尽管 $n = 12$ 且存在观测到的诊断问题。", "solution": "该场景涉及一个简单线性回归模型 $Y_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i$，样本量 $n = 12$。$\\beta_1$ 的经典OLS置信区间依赖于特定的假设：均值函数的线性性、误差 $\\varepsilon_i$ 的独立性、同方差性（对所有 $i$ 有 $\\text{Var}(\\varepsilon_i) = \\sigma^2$）以及正态性（$\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$）。在这些假设下，OLS斜率估计量 $\\hat{\\beta}_1$ 可以写成响应变量 $Y_i$ 的线性组合，具体为 $\\hat{\\beta}_1 = \\sum_{i=1}^n w_i Y_i$，其中 $w_i$ 是依赖于观测值 $X_i$ 的确定性权重，并满足 $\\sum_{i=1}^n w_i = 0$。如果 $\\varepsilon_i$ 是独立同正态分布的，那么 $Y_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i$ 意味着 $\\hat{\\beta}_1$ 服从正态分布，并且当误差方差从残差中估计时，常规的基于t分布的置信区间具有精确的覆盖率。\n\n当正态性和同方差性假设被违反时，特别是在小样本量 $n$ 的情况下，这些分布性结论不再成立。具体来说：\n\n1. 如果 $\\varepsilon_i$ 是偏态的，那么 $\\hat{\\beta}_1 = \\sum_i w_i \\varepsilon_i + \\beta_1$ 的分布会从 $\\varepsilon_i$ 继承偏度，并且在 $n$ 很小时可能显著偏离正态分布。如果没有正态误差，学生t枢轴量并不精确服从t分布。\n\n2. 如果 $\\text{Var}(\\varepsilon_i)$ 随均值增加（异方差性），$\\hat{\\beta}_1$ 的方差将取决于 $X_i$ 的模式和 $\\text{Var}(\\varepsilon_i)$，这使得在常数方差假设下推导出的常规标准误公式失效。小样本量 $n$ 限制了渐近近似的可靠性。\n\n3. 像 Shapiro–Wilk 检验得出 $p = 0.12$ 这样的诊断检验，在 $n = 12$ 的情况下是无定论的；未能拒绝假设并不等于证实正态性，并且视觉诊断显示出有意义的偏度和漏斗形的残差图，这暗示着存在异方差性和可能的非线性。\n\n一个基于原则的补救方法是，在不强加正态性或同方差性假设的情况下，经验地近似 $\\hat{\\beta}_1$ 的抽样分布。对配对 $(X_i, Y_i)$ 的非参数自助法通过对观测到的数据结构进行重抽样来实现这一点，它保留了联合分布，包括均值和方差之间的任何关系（异方差性），以及观测到的偏度。步骤如下：\n\n1. 从原始样本中计算OLS斜率 $\\hat{\\beta}_1$。\n\n2. 对于每次自助法迭代 $b = 1, \\dots, B$（其中 $B$ 很大，例如 $B = 2000$），从原始的 $n$ 个配对 $(X_i, Y_i)$ 中有放回地抽取 $n$ 个配对 $(X_i^*, Y_i^*)$。\n\n3. 对自助样本拟合相同的线性回归模型，并记录斜率 $\\hat{\\beta}_1^{*(b)}$。\n\n4. 在数据生成机制下，$\\{\\hat{\\beta}_1^{*(b)}\\}_{b=1}^B$ 的经验分布近似于 $\\hat{\\beta}_1$ 的抽样分布。使用其分位数来形成一个百分位95%置信区间，或应用偏差校正和加速 (BCa) 调整来校正偏差和偏度。\n\n这种方法不依赖于正态残差，能够适应偏态误差和非恒定方差，并且适用于小样本 $n$ 的情况，同时也承认极小样本所固有的局限性。相比之下，正如在该场景中观察到的，变换和参数修复可能仍然无法解决残差问题。\n\n逐项分析：\n\nA. 继续使用来自OLS的标准t分布区间假设了残差正态性和同方差性。对于 $n = 12$ 的样本，Shapiro–Wilk 检验的 $p$ 值为0.12并不能证实正态性，而且诊断图显示出右偏和漏斗形状，这直接违反了基于t分布的有效覆盖率所需的假设。这种方法存在覆盖率不足或校准错误的风险。结论：不正确。\n\nB. 对 $Y$ 进行对数变换是当误差结构为乘性时，用以减少右偏和稳定方差的常用技术。然而，问题陈述指出这种尝试并未解决偏度问题，反而引入了轻微的曲率，表明即使在变换后的尺度上，仍然存在偏离线性和同方差性的问题。在一次效果不足的变换后依赖基于t分布的区间仍然存在问题，特别是在 $n = 12$ 时。结论：在这种特定情况下不正确。\n\nC. 对配对 $(X_i, Y_i)$ 进行的非参数自助法对联合数据进行重抽样，保留了 $X$ 和 $Y$ 之间的依赖结构、偏度以及异方差性模式。从自助法斜率的经验分布构建百分位或偏差校正和加速 (BCa) 区间，提供了一个不依赖于残差正态性或恒定方差的区间，并直接解决了小样本中误导性正态性假设的问题。结论：正确。\n\nD. 删除两个最大的残差观测值以强制实现对称性是一种临时的离群值移除形式，它会引入选择偏倚，通过对数据进行两次条件化而使推断无效，并且通常会低估变异性。它不构成针对偏度或异方差性的一种有原则的补救方法。结论：不正确。\n\nE. $\\hat{\\beta}_1$ 的渐近正态性在 $n \\to \\infty$ 的广泛条件下成立，但在 $n = 12$ 且存在明显的偏度和异方差性的情况下，大样本近似是不可靠的，可能产生校准错误的区间。结论：不正确。\n\n因此，在这种情况下最合适的补救方法是使用对配对的非参数自助法来构建 $\\beta_1$ 的置信区间，这种方法不依赖于残差正态性或同方差性假设，并且考虑到了观测到的偏度和较小的样本量 $n$。", "answer": "$$\\boxed{C}$$", "id": "4894646"}]}