{"hands_on_practices": [{"introduction": "要想真正掌握集成模型，我们必须首先理解其基本构建单元。本练习将带您深入了解单个回归树的内部，展示如何根据减少不纯度的能力来评估一次分裂。通过亲手计算实证风险的降低量，您将对驱动决策树生长的贪心算法有一个具体的认识。[@problem_id:4910518]", "problem": "一个医院的生物统计团队正在构建一个随机森林（RF）模型中的回归树集成，用于根据协变量 $\\left(X_{1},\\dots,X_{p}\\right)$ 预测成年人的收缩压。对于一棵特定树的当前根节点，该团队考虑在协变量 $X_{2}$（身体质量指数）上进行一个候选分裂。结果 $Y$ 是以毫米汞柱（mmHg）为单位的收缩压。使用平方损失。此节点的数据集包含 $n=10$ 名患者，其观测对 $\\left(X_{2}, Y\\right)$ 如下：\n- 患者 $1$：$\\left(X_{2}=22.0,\\;Y=118\\right)$\n- 患者 $2$：$\\left(X_{2}=24.5,\\;Y=130\\right)$\n- 患者 $3$：$\\left(X_{2}=29.0,\\;Y=142\\right)$\n- 患者 $4$：$\\left(X_{2}=26.0,\\;Y=126\\right)$\n- 患者 $5$：$\\left(X_{2}=31.0,\\;Y=150\\right)$\n- 患者 $6$：$\\left(X_{2}=27.5,\\;Y=134\\right)$\n- 患者 $7$：$\\left(X_{2}=28.0,\\;Y=138\\right)$\n- 患者 $8$：$\\left(X_{2}=23.0,\\;Y=120\\right)$\n- 患者 $9$：$\\left(X_{2}=34.0,\\;Y=160\\right)$\n- 患者 $10$：$\\left(X_{2}=25.0,\\;Y=132\\right)$\n\n候选分裂的阈值为 $t=27.0$，将 $X_{2}\\leq t$ 的观测值发送到左子节点 $L$，将 $X_{2}>t$ 的观测值发送到右子节点 $R$。在平方损失下，任何节点 $N$ 的经验风险定义为\n$$\nR_{N} \\;=\\; \\frac{1}{n_{N}}\\sum_{i\\in N}\\left(Y_{i}-\\bar{Y}_{N}\\right)^{2},\n$$\n其中 $n_{N}$ 是节点 $N$ 中的观测数量，$\\bar{Y}_{N}$ 是节点 $N$ 中 $Y$ 的样本均值。由分裂引起的经验风险减少量为\n$$\n\\Delta \\;=\\; R_{\\text{parent}} \\;-\\; \\left(\\frac{n_{L}}{n}R_{L}\\;+\\;\\frac{n_{R}}{n}R_{R}\\right).\n$$\n\n假设随机森林使用的最小不纯度减少参数为 $\\lambda=10$（单位：平方毫米汞柱/样本），因此当且仅当 $\\Delta>\\lambda$ 时，该分裂才被接受。计算在 $t=27.0$ 处对此候选分裂在 $X_{2}$ 上的净增益\n$$\nG \\;=\\; \\Delta \\;-\\; \\lambda,\n$$\n将 $G$ 的最终数值答案以平方毫米汞柱/样本为单位表示，并四舍五入到四位有效数字。", "solution": "我们从平方损失下的经验风险定义开始。对于一个节点 $N$，经验风险是\n$$\nR_{N} \\;=\\; \\frac{1}{n_{N}}\\sum_{i\\in N}\\left(Y_{i}-\\bar{Y}_{N}\\right)^{2}.\n$$\n这是节点内的均方误差（MSE）。将 $\\frac{1}{n_{N}}\\sum_{i\\in N}\\left(Y_{i}-\\mu\\right)^{2}$ 对 $\\mu$ 最小化的值是样本均值 $\\bar{Y}_{N}$。这可以通过对 $\\mu$ 求导得出：\n$$\n\\frac{\\partial}{\\partial \\mu}\\left[\\frac{1}{n_{N}}\\sum_{i\\in N}\\left(Y_{i}-\\mu\\right)^{2}\\right]\n\\;=\\; \\frac{1}{n_{N}}\\sum_{i\\in N}\\left(-2\\right)\\left(Y_{i}-\\mu\\right)\n\\;=\\; -\\frac{2}{n_{N}}\\left(\\sum_{i\\in N}Y_{i}-n_{N}\\mu\\right),\n$$\n令其为零可得 $\\mu=\\bar{Y}_{N}$。因此，计算 $R_{N}$ 需要 $\\bar{Y}_{N}$ 和离差平方和。\n\n为了高效地计算离差平方和，我们使用以下恒等式\n$$\n\\sum_{i\\in N}\\left(Y_{i}-\\bar{Y}_{N}\\right)^{2}\n\\;=\\;\n\\sum_{i\\in N}Y_{i}^{2} \\;-\\; n_{N}\\,\\bar{Y}_{N}^{2},\n$$\n该恒等式通过展开平方并利用 $\\sum_{i\\in N} (Y_{i}-\\bar{Y}_{N}) = 0$ 得出。\n\n我们首先根据 $X_{2}$ 上的分裂阈值 $t=27.0$ 对数据进行分区：\n- 左子节点 $L$ ($X_{2}\\leq 27.0$)：患者 $1,2,4,8,10$，其 $Y$ 值为 $\\{118,130,126,120,132\\}$，且 $n_{L}=5$。\n- 右子节点 $R$ ($X_{2}>27.0$)：患者 $3,5,6,7,9$，其 $Y$ 值为 $\\{142,150,134,138,160\\}$，且 $n_{R}=5$。\n父节点包含所有 $n=10$ 名患者。\n\n计算父节点的均值 $\\bar{Y}_{\\text{parent}}$：\n$$\n\\sum_{i=1}^{10} Y_{i} \\;=\\; 118+130+142+126+150+134+138+120+160+132 \\;=\\; 1350,\n$$\n所以\n$$\n\\bar{Y}_{\\text{parent}} \\;=\\; \\frac{1350}{10} \\;=\\; 135.\n$$\n计算父节点的 $\\sum Y_{i}^{2}$：\n$$\n118^{2}=13924,\\;\\;130^{2}=16900,\\;\\;142^{2}=20164,\\;\\;126^{2}=15876,\\;\\;150^{2}=22500,\n$$\n$$\n134^{2}=17956,\\;\\;138^{2}=19044,\\;\\;120^{2}=14400,\\;\\;160^{2}=25600,\\;\\;132^{2}=17424.\n$$\n将这些值相加，\n$$\n\\sum_{i=1}^{10} Y_{i}^{2} \\;=\\; 183788.\n$$\n因此，父节点的离差平方和（误差平方和，$\\text{SSE}_{\\text{parent}}$）为\n$$\n\\text{SSE}_{\\text{parent}} \\;=\\; \\sum_{i=1}^{10} Y_{i}^{2} - n\\,\\bar{Y}_{\\text{parent}}^{2}\n\\;=\\; 183788 \\;-\\; 10\\times 135^{2}\n\\;=\\; 183788 \\;-\\; 182250\n\\;=\\; 1538.\n$$\n因此父节点的风险为\n$$\nR_{\\text{parent}} \\;=\\; \\frac{\\text{SSE}_{\\text{parent}}}{n} \\;=\\; \\frac{1538}{10} \\;=\\; 153.8.\n$$\n\n计算左子节点的均值和 $\\text{SSE}_{L}$：\n$$\n\\sum_{i\\in L} Y_{i} \\;=\\; 118+130+126+120+132 \\;=\\; 626,\n\\quad\n\\bar{Y}_{L} \\;=\\; \\frac{626}{5} \\;=\\; 125.2,\n$$\n$$\n\\sum_{i\\in L} Y_{i}^{2} \\;=\\; 13924+16900+15876+14400+17424 \\;=\\; 78524,\n$$\n所以\n$$\n\\text{SSE}_{L} \\;=\\; 78524 \\;-\\; 5\\times (125.2)^{2}.\n$$\n计算 $(125.2)^{2}$：\n$$\n(125.2)^{2} \\;=\\; 15675.04,\n$$\n因此\n$$\n\\text{SSE}_{L} \\;=\\; 78524 \\;-\\; 5\\times 15675.04 \\;=\\; 78524 \\;-\\; 78375.2 \\;=\\; 148.8,\n$$\n且\n$$\nR_{L} \\;=\\; \\frac{\\text{SSE}_{L}}{n_{L}} \\;=\\; \\frac{148.8}{5} \\;=\\; 29.76.\n$$\n\n计算右子节点的均值和 $\\text{SSE}_{R}$：\n$$\n\\sum_{i\\in R} Y_{i} \\;=\\; 142+150+134+138+160 \\;=\\; 724,\n\\quad\n\\bar{Y}_{R} \\;=\\; \\frac{724}{5} \\;=\\; 144.8,\n$$\n$$\n\\sum_{i\\in R} Y_{i}^{2} \\;=\\; 20164+22500+17956+19044+25600 \\;=\\; 105264,\n$$\n所以\n$$\n\\text{SSE}_{R} \\;=\\; 105264 \\;-\\; 5\\times (144.8)^{2}.\n$$\n计算 $(144.8)^{2}$：\n$$\n(144.8)^{2} \\;=\\; 20967.04,\n$$\n因此\n$$\n\\text{SSE}_{R} \\;=\\; 105264 \\;-\\; 5\\times 20967.04 \\;=\\; 105264 \\;-\\; 104835.2 \\;=\\; 428.8,\n$$\n且\n$$\nR_{R} \\;=\\; \\frac{\\text{SSE}_{R}}{n_{R}} \\;=\\; \\frac{428.8}{5} \\;=\\; 85.76.\n$$\n\n计算经验风险的减少量 $\\Delta$：\n$$\n\\Delta \\;=\\; R_{\\text{parent}} \\;-\\; \\left(\\frac{n_{L}}{n}R_{L}\\;+\\;\\frac{n_{R}}{n}R_{R}\\right)\n\\;=\\; 153.8 \\;-\\; \\left(\\frac{5}{10}\\times 29.76 \\;+\\; \\frac{5}{10}\\times 85.76\\right).\n$$\n计算加权的子节点风险：\n$$\n\\frac{5}{10}\\times 29.76 \\;=\\; 14.88,\\qquad \\frac{5}{10}\\times 85.76 \\;=\\; 42.88,\n$$\n所以\n$$\n\\frac{n_{L}}{n}R_{L}\\;+\\;\\frac{n_{R}}{n}R_{R} \\;=\\; 14.88+42.88 \\;=\\; 57.76,\n$$\n且\n$$\n\\Delta \\;=\\; 153.8 \\;-\\; 57.76 \\;=\\; 96.04.\n$$\n\n在最小不纯度减少参数 $\\lambda=10$ 的情况下，净增益为\n$$\nG \\;=\\; \\Delta \\;-\\; \\lambda \\;=\\; 96.04 \\;-\\; 10 \\;=\\; 86.04.\n$$\n由于 $G>0$，根据随机森林的标准，该分裂将被接受。根据题目要求，我们报告保留四位有效数字的 $G$ 值。值 $86.04$ 已有四位有效数字。", "answer": "$$\\boxed{86.04}$$", "id": "4910518"}, {"introduction": "随机森林最巧妙的特性之一是利用袋外（OOB）数据进行模型评估。这个编程练习要求您利用OOB预测，从零开始实现性能指标，并聚焦于评估模型在不同人群亚组之间公平性这一至关重要的任务。通过这项实践，您将把理论与实际应用联系起来，学习如何审查模型是否存在潜在的偏见。[@problem_id:4910502]", "problem": "您正在处理一个二元分类问题，该问题源于一个决策树集成模型，例如随机森林。每个观测值都有一个正类的袋外（OOB）预测概率、一个真实的二元标签以及一个分类人口子群标签。您的任务是编写一个完整、可运行的程序，该程序从基本原理出发，使用基于混淆矩阵的比率和均方损失的定义，根据袋外（OOB）预测概率计算分群的性能指标，然后计算两个指定人口子群之间的绝对差异。\n\n在您的推理和实现中需使用以下定义：\n- 对于一个观测值，其袋外（OOB）预测概率是在自助采样（bootstrap sampling）过程中，未在该观测值上训练的那些树的平均预测概率，它被视为对该观测值预测的无偏估计。\n- 给定一个分类阈值 $\\tau$，通过规则 $\\hat{y}_i = 1$（如果 $p_i \\ge \\tau$）和 $\\hat{y}_i = 0$（其他情况），将袋外（OOB）预测概率 $p_i$ 转换为预测类别 $\\hat{y}_i$。\n- 对于任何子群，根据仅限于该子群的 $\\{\\hat{y}_i, y_i\\}$ 来定义混淆矩阵的计数：真正例、假正例、真负例和假负例。根据这些计数，使用其标准定义推导出真正例率、假正例率和正预测值。\n- 将任何子群的 Brier 分数定义为该子群内预测概率与真实标签之间的均方误差。\n\n您的程序必须实现以下内容，并应用于下面提供的每个测试用例：\n1. 分别为子群 $\\mathrm{A}$ 和子群 $\\mathrm{B}$ 计算以下四个指标：\n   - 真正例率，\n   - 假正例率，\n   - 正预测值，\n   - Brier 分数。\n2. 计算子群 $\\mathrm{A}$ 和子群 $\\mathrm{B}$ 之间每个指标的绝对差异（即子群指标之差的绝对值）。\n3. 需强制执行的边界情况约定：\n   - 如果某个子群的比率定义中任何分母为零，则将该子群的该比率定义为 $0$。\n   - 所有绝对差异必须是非负实数。\n\n输入规范在程序中是固定的（无用户输入）。请使用以下测试套件，其中数组按袋外（OOB）预测概率、真实标签、子群标签和阈值 $\\tau$ 的顺序给出：\n- 测试用例 $1$：\n  - OOB 预测概率：$[0.9, 0.4, 0.7, 0.2, 0.8, 0.3]$\n  - 真实标签：$[1, 0, 1, 0, 1, 0]$\n  - 子群：$[\\mathrm{A}, \\mathrm{A}, \\mathrm{A}, \\mathrm{B}, \\mathrm{B}, \\mathrm{B}]$\n  - 阈值：$\\tau = 0.5$\n- 测试用例 $2$：\n  - OOB 预测概率：$[0.6, 0.2, 0.7, 0.9, 0.1]$\n  - 真实标签：$[0, 0, 1, 1, 0]$\n  - 子群：$[\\mathrm{A}, \\mathrm{A}, \\mathrm{B}, \\mathrm{B}, \\mathrm{B}]$\n  - 阈值：$\\tau = 0.5$\n- 测试用例 $3$：\n  - OOB 预测概率：$[0.4, 0.6, 0.3, 0.9, 0.2]$\n  - 真实标签：$[0, 1, 0, 1, 0]$\n  - 子群：$[\\mathrm{A}, \\mathrm{A}, \\mathrm{B}, \\mathrm{B}, \\mathrm{B}]$\n  - 阈值：$\\tau = 0.0$\n- 测试用例 $4$：\n  - OOB 预测概率：$[1.0, 0.8, 0.2, 0.7, 0.99, 0.95]$\n  - 真实标签：$[1, 0, 0, 0, 1, 1]$\n  - 子群：$[\\mathrm{A}, \\mathrm{A}, \\mathrm{A}, \\mathrm{B}, \\mathrm{B}, \\mathrm{B}]$\n  - 阈值：$\\tau = 1.0$\n\n对于每个测试用例，您的程序必须按以下顺序输出一个包含四个浮点数的列表：\n$[$ 子群 $\\mathrm{A}$ 和 $\\mathrm{B}$ 之间真正例率的绝对差异，假正例率的绝对差异，正预测值的绝对差异，Brier 分数的绝对差异 $]$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。所有测试用例的结果按顺序连接成一个扁平列表。每个浮点结果必须精确四舍五入到小数点后 $6$ 位。例如，一个包含两个测试用例的有效输出应如下所示：$[0.125000,0.500000,0.000000,0.031250,0.333333,0.000000,0.200000,0.100000]$。", "solution": "该问题是有效的。它提出了一个在生物统计学和机器学习模型评估中定义明确的任务，该任务基于标准的、可形式化的定义。所有必要的数据和参数都已提供，约束条件一致，并且没有科学或逻辑上的缺陷。\n\n该问题要求计算一个二元分类器按人口子群分层的几个标准性能指标，并随后计算这些指标在标记为 $\\mathrm{A}$ 和 $\\mathrm{B}$ 的两个群组之间的绝对差异。这些指标是真正例率（$TPR$）、假正例率（$FPR$）、正预测值（$PPV$）和 Brier 分数（$BS$）。\n\n首先，我们对定义进行形式化。假设子群 $G$ 的数据集包含 $N_G$ 个观测值，其中每个观测值 $i$ 都有一个袋外（OOB）预测概率 $p_i$、一个真实标签 $y_i \\in \\{0, 1\\}$ 和一个子群标签。对于给定的分类阈值 $\\tau$，预测标签 $\\hat{y}_i$ 由以下规则确定：\n$$\n\\hat{y}_i = \\begin{cases} 1 & \\text{if } p_i \\ge \\tau \\\\ 0 & \\text{if } p_i < \\tau \\end{cases}\n$$\n\n子群 $G$ 的性能指标由真正例（$TP_G$）、假正例（$FP_G$）、真负例（$TN_G$）和假负例（$FN_G$）的计数推导得出：\n- $TP_G = \\sum_{i \\in G} \\mathbf{1}(y_i = 1 \\text{ and } \\hat{y}_i = 1)$\n- $FP_G = \\sum_{i \\in G} \\mathbf{1}(y_i = 0 \\text{ and } \\hat{y}_i = 1)$\n- $TN_G = \\sum_{i \\in G} \\mathbf{1}(y_i = 0 \\text{ and } \\hat{y}_i = 0)$\n- $FN_G = \\sum_{i \\in G} \\mathbf{1}(y_i = 1 \\text{ and } \\hat{y}_i = 0)$\n其中 $\\mathbf{1}(\\cdot)$ 是指示函数。\n\n然后，这些比率定义如下：\n- **真正例率（灵敏度/召回率）**：$TPR_G = \\frac{TP_G}{TP_G + FN_G}$。分母是子群 $G$ 中实际正例的总数。\n- **假正例率**：$FPR_G = \\frac{FP_G}{FP_G + TN_G}$。分母是子群 $G$ 中实际负例的总数。\n- **正预测值（精确率）**：$PPV_G = \\frac{TP_G}{TP_G + FP_G}$。分母是子群 $G$ 中预测为正例的总数。\n\n根据问题规范，如果这些分母中的任何一个为零，则相应的比率定义为 $0$。\n\n对于子群 $G$ 的 **Brier 分数**，是预测概率与真实标签之间的均方误差：\n$$\nBS_G = \\frac{1}{N_G} \\sum_{i \\in G} (p_i - y_i)^2\n$$\n其中 $N_G$ 是子群 $G$ 中的个体数量。\n\n最后，每个指标 $M \\in \\{TPR, FPR, PPV, BS\\}$ 的绝对差异计算为 $\\Delta_{M} = |M_A - M_B|$。\n\n我们现在将这些定义应用于每个测试用例。\n\n**测试用例 1**：\n- 数据：$p = [0.9, 0.4, 0.7, 0.2, 0.8, 0.3]$, $y = [1, 0, 1, 0, 1, 0]$, 子群 = $[\\mathrm{A}, \\mathrm{A}, \\mathrm{A}, \\mathrm{B}, \\mathrm{B}, \\mathrm{B}]$, $\\tau = 0.5$。\n- 子群 A 数据：$p_A = [0.9, 0.4, 0.7]$, $y_A = [1, 0, 1]$。当 $\\tau=0.5$ 时，$\\hat{y}_A=[1, 0, 1]$。\n- A 的计数：$TP_A=2, FP_A=0, TN_A=1, FN_A=0$。\n- A 的指标：$TPR_A = \\frac{2}{2+0} = 1$。$FPR_A = \\frac{0}{0+1} = 0$。$PPV_A = \\frac{2}{2+0} = 1$。$BS_A = \\frac{1}{3}((0.9-1)^2 + (0.4-0)^2 + (0.7-1)^2) = \\frac{0.01+0.16+0.09}{3} = \\frac{0.26}{3}$。\n- 子群 B 数据：$p_B = [0.2, 0.8, 0.3]$, $y_B = [0, 1, 0]$。当 $\\tau=0.5$ 时，$\\hat{y}_B=[0, 1, 0]$。\n- B 的计数：$TP_B=1, FP_B=0, TN_B=2, FN_B=0$。\n- B 的指标：$TPR_B = \\frac{1}{1+0} = 1$。$FPR_B = \\frac{0}{0+2} = 0$。$PPV_B = \\frac{1}{1+0} = 1$。$BS_B = \\frac{1}{3}((0.2-0)^2 + (0.8-1)^2 + (0.3-0)^2) = \\frac{0.04+0.04+0.09}{3} = \\frac{0.17}{3}$。\n- 差异：$\\Delta_{TPR} = |1-1|=0$。$\\Delta_{FPR} = |0-0|=0$。$\\Delta_{PPV} = |1-1|=0$。$\\Delta_{BS} = |\\frac{0.26}{3} - \\frac{0.17}{3}| = \\frac{0.09}{3} = 0.03$。\n\n**测试用例 2**：\n- 数据：$p = [0.6, 0.2, 0.7, 0.9, 0.1]$, $y = [0, 0, 1, 1, 0]$, 子群 = $[\\mathrm{A}, \\mathrm{A}, \\mathrm{B}, \\mathrm{B}, \\mathrm{B}]$, $\\tau = 0.5$。\n- 子群 A 数据：$p_A = [0.6, 0.2]$, $y_A = [0, 0]$。当 $\\tau=0.5$ 时，$\\hat{y}_A=[1, 0]$。\n- A 的计数：$TP_A=0, FP_A=1, TN_A=1, FN_A=0$。\n- A 的指标：实际正例 $TP_A+FN_A=0 \\implies TPR_A=0$。$FPR_A=\\frac{1}{1+1}=0.5$。$PPV_A=\\frac{0}{0+1}=0$。$BS_A = \\frac{1}{2}((0.6-0)^2 + (0.2-0)^2) = \\frac{0.36+0.04}{2} = 0.2$。\n- 子群 B 数据：$p_B = [0.7, 0.9, 0.1]$, $y_B = [1, 1, 0]$。当 $\\tau=0.5$ 时，$\\hat{y}_B=[1, 1, 0]$。\n- B 的计数：$TP_B=2, FP_B=0, TN_B=1, FN_B=0$。\n- B 的指标：$TPR_B = \\frac{2}{2+0}=1$。$FPR_B = \\frac{0}{0+1}=0$。$PPV_B=\\frac{2}{2+0}=1$。$BS_B = \\frac{1}{3}((0.7-1)^2 + (0.9-1)^2 + (0.1-0)^2) = \\frac{0.09+0.01+0.01}{3} = \\frac{0.11}{3}$。\n- 差异：$\\Delta_{TPR} = |0-1|=1$。$\\Delta_{FPR} = |0.5-0|=0.5$。$\\Delta_{PPV} = |0-1|=1$。$\\Delta_{BS} = |0.2 - \\frac{0.11}{3}| = |\\frac{0.6-0.11}{3}| = \\frac{0.49}{3} \\approx 0.163333$。\n\n**测试用例 3**：\n- 数据：$p = [0.4, 0.6, 0.3, 0.9, 0.2]$, $y = [0, 1, 0, 1, 0]$, 子群 = $[\\mathrm{A}, \\mathrm{A}, \\mathrm{B}, \\mathrm{B}, \\mathrm{B}]$, $\\tau = 0.0$。\n- 由于所有概率都 $\\ge 0$，所以所有 $\\hat{y_i}=1$。\n- 子群 A 数据：$p_A=[0.4, 0.6]$, $y_A=[0, 1]$。$\\hat{y}_A=[1, 1]$。\n- A 的计数：$TP_A=1, FP_A=1, TN_A=0, FN_A=0$。\n- A 的指标：$TPR_A=\\frac{1}{1+0}=1$。$FPR_A=\\frac{1}{1+0}=1$。$PPV_A=\\frac{1}{1+1}=0.5$。$BS_A = \\frac{1}{2}((0.4-0)^2+(0.6-1)^2) = \\frac{0.16+0.16}{2}=0.16$。\n- 子群 B 数据：$p_B=[0.3, 0.9, 0.2]$, $y_B=[0, 1, 0]$。$\\hat{y}_B=[1, 1, 1]$。\n- B 的计数：$TP_B=1, FP_B=2, TN_B=0, FN_B=0$。\n- B 的指标：$TPR_B=\\frac{1}{1+0}=1$。$FPR_B=\\frac{2}{2+0}=1$。$PPV_B=\\frac{1}{1+2}=\\frac{1}{3}$。$BS_B = \\frac{1}{3}((0.3-0)^2+(0.9-1)^2+(0.2-0)^2) = \\frac{0.09+0.01+0.04}{3} = \\frac{0.14}{3}$。\n- 差异：$\\Delta_{TPR} = |1-1|=0$。$\\Delta_{FPR} = |1-1|=0$。$\\Delta_{PPV} = |0.5 - \\frac{1}{3}| = \\frac{1}{6} \\approx 0.166667$。$\\Delta_{BS} = |0.16 - \\frac{0.14}{3}| = |\\frac{0.48-0.14}{3}| = \\frac{0.34}{3} \\approx 0.113333$。\n\n**测试用例 4**：\n- 数据：$p = [1.0, 0.8, 0.2, 0.7, 0.99, 0.95]$, $y = [1, 0, 0, 0, 1, 1]$, 子群 = $[\\mathrm{A}, \\mathrm{A}, \\mathrm{A}, \\mathrm{B}, \\mathrm{B}, \\mathrm{B}]$, $\\tau = 1.0$。\n- 仅当 $p \\ge 1.0$ 时预测为 $1$。\n- 子群 A 数据：$p_A=[1.0, 0.8, 0.2]$, $y_A=[1, 0, 0]$。$\\hat{y}_A=[1, 0, 0]$。\n- A 的计数：$TP_A=1, FP_A=0, TN_A=2, FN_A=0$。\n- A 的指标：$TPR_A=\\frac{1}{1+0}=1$。$FPR_A=\\frac{0}{0+2}=0$。$PPV_A=\\frac{1}{1+0}=1$。$BS_A = \\frac{1}{3}((1.0-1)^2+(0.8-0)^2+(0.2-0)^2) = \\frac{0+0.64+0.04}{3} = \\frac{0.68}{3}$。\n- 子群 B 数据：$p_B=[0.7, 0.99, 0.95]$, $y_B=[0, 1, 1]$。$\\hat{y}_B=[0, 0, 0]$。\n- B 的计数：$TP_B=0, FP_B=0, TN_B=1, FN_B=2$。\n- B 的指标：$TPR_B=\\frac{0}{0+2}=0$。$FPR_B=\\frac{0}{0+1}=0$。预测正例 $TP_B+FP_B=0 \\implies PPV_B=0$。$BS_B = \\frac{1}{3}((0.7-0)^2+(0.99-1)^2+(0.95-1)^2) = \\frac{0.49+0.0001+0.0025}{3} = \\frac{0.4926}{3}$。\n- 差异：$\\Delta_{TPR} = |1-0|=1$。$\\Delta_{FPR} = |0-0|=0$。$\\Delta_{PPV} = |1-0|=1$。$\\Delta_{BS} = |\\frac{0.68}{3} - \\frac{0.4926}{3}| = \\frac{0.1874}{3} \\approx 0.062467$。\n\n以下程序实现了这些计算。", "answer": "```python\nimport numpy as np\n\ndef calculate_metrics(probs, labels, threshold):\n    \"\"\"\n    Computes performance metrics for a single subgroup.\n\n    Args:\n        probs (np.ndarray): Predicted probabilities for the positive class.\n        labels (np.ndarray): True binary labels (0 or 1).\n        threshold (float): Classification threshold.\n\n    Returns:\n        tuple: A tuple containing (tpr, fpr, ppv, brier_score).\n    \"\"\"\n    if len(labels) == 0:\n        return 0.0, 0.0, 0.0, 0.0\n\n    # Brier Score computation\n    brier_score = np.mean((probs - labels) ** 2)\n\n    # Convert probabilities to predicted labels\n    predicted_labels = (probs >= threshold).astype(int)\n\n    # Confusion matrix counts\n    tp = np.sum((predicted_labels == 1)  (labels == 1))\n    fp = np.sum((predicted_labels == 1)  (labels == 0))\n    tn = np.sum((predicted_labels == 0)  (labels == 0))\n    fn = np.sum((predicted_labels == 0)  (labels == 1))\n\n    # Denominators for the rates\n    actual_positives = tp + fn\n    actual_negatives = fp + tn\n    predicted_positives = tp + fp\n\n    # True Positive Rate (TPR)\n    tpr = tp / actual_positives if actual_positives > 0 else 0.0\n\n    # False Positive Rate (FPR)\n    fpr = fp / actual_negatives if actual_negatives > 0 else 0.0\n\n    # Positive Predictive Value (PPV)\n    ppv = tp / predicted_positives if predicted_positives > 0 else 0.0\n\n    return tpr, fpr, ppv, brier_score\n\ndef solve():\n    \"\"\"\n    Main function to process test cases and compute disparities.\n    \"\"\"\n    test_cases = [\n        (np.array([0.9, 0.4, 0.7, 0.2, 0.8, 0.3]),\n         np.array([1, 0, 1, 0, 1, 0]),\n         np.array(['A', 'A', 'A', 'B', 'B', 'B']),\n         0.5),\n        (np.array([0.6, 0.2, 0.7, 0.9, 0.1]),\n         np.array([0, 0, 1, 1, 0]),\n         np.array(['A', 'A', 'B', 'B', 'B']),\n         0.5),\n        (np.array([0.4, 0.6, 0.3, 0.9, 0.2]),\n         np.array([0, 1, 0, 1, 0]),\n         np.array(['A', 'A', 'B', 'B', 'B']),\n         0.0),\n        (np.array([1.0, 0.8, 0.2, 0.7, 0.99, 0.95]),\n         np.array([1, 0, 0, 0, 1, 1]),\n         np.array(['A', 'A', 'A', 'B', 'B', 'B']),\n         1.0)\n    ]\n\n    all_results = []\n    for probs, labels, subgroups, threshold in test_cases:\n        # Filter data for subgroup A\n        mask_a = subgroups == 'A'\n        probs_a = probs[mask_a]\n        labels_a = labels[mask_a]\n\n        # Filter data for subgroup B\n        mask_b = subgroups == 'B'\n        probs_b = probs[mask_b]\n        labels_b = labels[mask_b]\n\n        # Calculate metrics for each subgroup\n        tpr_a, fpr_a, ppv_a, bs_a = calculate_metrics(probs_a, labels_a, threshold)\n        tpr_b, fpr_b, ppv_b, bs_b = calculate_metrics(probs_b, labels_b, threshold)\n\n        # Calculate absolute disparities\n        disp_tpr = abs(tpr_a - tpr_b)\n        disp_fpr = abs(fpr_a - fpr_b)\n        disp_ppv = abs(ppv_a - ppv_b)\n        disp_bs = abs(bs_a - bs_b)\n        \n        case_results = [disp_tpr, disp_fpr, disp_ppv, disp_bs]\n        all_results.extend(case_results)\n\n    # Format the final output string\n    formatted_results = [f\"{res:.6f}\" for res in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "4910502"}, {"introduction": "一个强大的模型也伴随着理解其局限性的责任。本练习探讨了随机森林的一个关键弱点——其无法进行外推预测——并介绍了部分依赖图（PDP）作为一种解释工具。通过分析模型在训练数据范围之外的行为，您将学会为何在解释和部署基于树的模型进行预测时，保持谨慎是至关重要的。[@problem_id:4910532]", "problem": "一项生物统计学研究使用回归随机森林，根据协变量 $X=(X_{1},\\dots,X_{p})$ 对连续临床结果 $Y$（例如，收缩压）进行建模。每棵树都由 Classification And Regression Trees (CART) 构建，其中树通过轴对齐的阈值来划分协变量空间，终端节点中的预测是该节点内袋内训练结果的样本均值。随机森林预测器定义为 $T$ 棵树的平均值，即 $\\hat{f}_{\\mathrm{RF}}(x)=\\frac{1}{T}\\sum_{t=1}^{T}\\hat{f}_{t}(x)$，其中每个 $\\hat{f}_{t}$ 是由树的叶节点决定的分段常数函数。考虑一个主要协变量 $X_{1}$（例如，年龄），其经验训练支撑集为闭区间 $[\\min_{i}X_{1}^{(i)},\\max_{i}X_{1}^{(i)}]$，其中 $\\min_{i}X_{1}^{(i)}=45$ 岁，$\\max_{i}X_{1}^{(i)}=80$ 岁。在实践中，生物统计学家通常通过部分依赖函数来可视化 $Y$ 和协变量之间的关系。对于特征索引 $j\\in\\{1,\\dots,p\\}$，部分依赖函数定义为 $PD_{j}(x)=\\mathbb{E}_{X_{-j}}[\\hat{f}_{\\mathrm{RF}}(x,X_{-j})]$，并且通常通过 $\\frac{1}{n}\\sum_{i=1}^{n}\\hat{f}_{\\mathrm{RF}}(x,X_{-j}^{(i)})$ 来近似，其中 $X_{-j}$ 表示除 $X_{j}$ 之外的所有特征。仅使用这些基本定义和事实，推断在经验支撑集 $[45,80]$ 之外的 $x$ 值下 $\\hat{f}_{\\mathrm{RF}}(x)$ 和 $PD_{1}(x)$ 的行为，并提出科学上合理的保障措施来监控训练支撑集之外的部分依赖性。选择所有正确的陈述。\n\nA. 在一个由 CART 构建的回归随机森林中，对于经验支撑集为 $[\\min_{i}X_{1}^{(i)},\\max_{i}X_{1}^{(i)}]$ 的单个连续特征 $X_{1}$，对于任何 $x\\max_{i}X_{1}^{(i)}$，其预测值 $\\hat{f}_{\\mathrm{RF}}(x)$ 等于所有树中最右侧终端节点均值的平均值，并且当 $x$ 进一步增加时保持不变。\n\nB. 因为随机森林是许多树的平均，所以当潜在关系是单调时，它们可以可靠地在训练范围之外进行线性外推，因此 $\\hat{f}_{\\mathrm{RF}}(x)$ 将在 $x=80$ 之后延续学习到的趋势。\n\nC. 在 $X_{1}$ 的经验密度为零的 $x$ 值（例如 $x  45$ 或 $x80$）处评估的部分依赖 $PD_{1}(x)=\\mathbb{E}_{X_{-1}}[\\hat{f}_{\\mathrm{RF}}(x,X_{-1})]$ 使用了位于观测支撑集之外的组合 $(x,X_{-1}^{(i)})$；一个实际的保障措施是监控核密度估计 $\\hat{f}_{X_{1}}(x)$，并在 $\\hat{f}_{X_{1}}(x)$ 接近 0 时标记 $PD_{1}(x)$，或将可视化限制在经验分位数区间内，例如 $[q_{0.01}(X_{1}),q_{0.99}(X_{1})]$。\n\nD. 增加树的数量 $T$ 会消除外推限制，因为根据大数定律，$\\hat{f}_{\\mathrm{RF}}(x)$ 会收敛到一个在训练支撑集之外进行外推的光滑函数。\n\nE. 在多元设置中，一个保障措施是通过根据 $\\omega_{i}(x)\\propto\\mathbf{1}\\{|X_{1}^{(i)}-x|\\leq\\epsilon\\}$（对于一个小的 $\\epsilon0$）对训练观测值进行加权来近似条件部分依赖，即 $PD_{1}^{\\mathrm{cond}}(x)\\approx\\frac{\\sum_{i=1}^{n}\\omega_{i}(x)\\hat{f}_{\\mathrm{RF}}(x,X_{-1}^{(i)})}{\\sum_{i=1}^{n}\\omega_{i}(x)}$，并在 $\\sum_{i=1}^{n}\\omega_{i}(x)$ 很小（表明支撑集稀疏）时标记 $x$。\n\nF. 随机森林训练中使用的自助法重采样将协变量 $X_{1}$ 的支撑集扩展到 $[45,80]$ 之外，使得在 $x80$ 处的 $PD_{1}(x)$ 无需额外监控即可信。\n\n选择所有正确的选项。", "solution": "用户提供了一个问题陈述，内容涉及回归随机森林的外推行为以及在训练数据支撑集之外对部分依赖函数的解释。\n\n### 第一步：提取已知条件\n- **模型：** 基于协变量 $X=(X_{1},\\dots,X_{p})$ 的连续结果 $Y$ 的回归随机森林。\n- **基学习器：** Classification And Regression Trees (CART)。\n- **CART 预测机制：** 树通过轴对齐的分割来划分协变量空间。任何终端节点（叶节点）中的预测是落入该节点的数据点的袋内训练结果的样本均值。\n- **随机森林预测器：** $\\hat{f}_{\\mathrm{RF}}(x)=\\frac{1}{T}\\sum_{t=1}^{T}\\hat{f}_{t}(x)$，其中 $\\hat{f}_{t}$ 是第 $t$ 棵树的预测，是一个分段常数函数。\n- **感兴趣的协变量：** $X_{1}$，表示像年龄这样的变量。\n- **$X_{1}$ 的经验训练支撑集：** 闭区间 $[\\min_{i}X_{1}^{(i)},\\max_{i}X_{1}^{(i)}]$，给定为 $[45, 80]$ 岁。\n- **部分依赖函数 (PDF)：** 对于特征 $j$，$PD_{j}(x)=\\mathbb{E}_{X_{-j}}[\\hat{f}_{\\mathrm{RF}}(x,X_{-j})]$。\n- **经验 PDF 近似：** $\\frac{1}{n}\\sum_{i=1}^{n}\\hat{f}_{\\mathrm{RF}}(x,X_{-j}^{(i)})$，其中 $X_{-j}$ 表示除 $X_{j}$ 之外的所有特征。\n- **目标：** 推断第一个协变量（我们称其参数为 $x_1$）在 $x_1 \\notin [45, 80]$ 的值下 $\\hat{f}_{\\mathrm{RF}}(x)$ 和 $PD_{1}(x)$ 的行为，并评估所提出的保障措施。\n\n### 第二步：使用提取的已知条件进行验证\n问题陈述在科学上是合理的、适定的和客观的。它基于随机森林（作为 CART 树的集成）和部分依赖函数的标准、形式化定义，这些都是现代统计学习和生物统计学中的基本概念。前提在事实上是可靠的，并且内部一致。问题没有未明确规定之处，因为它提供了推断模型行为所需的所有必要定义。该场景是生物统计学中的一个现实应用。没有逻辑谬误或歧义。\n\n### 第三步：结论和行动\n问题陈述是**有效的**。我将对每个选项进行详细的推导和评估。\n\n### 推导与选项评估\n\n问题的核心在于理解基于 CART 的回归树的外推行为。CART 树通过划分特征空间来生成预测。分割的形式为 $X_j \\leq c$。一个关键但通常是隐含的细节是，分割点 $c$ 是从特征 $X_j$ 的训练数据中观测到的值中选择的。因此，对于训练数据支撑集为 $[45, 80]$ 的特征 $X_1$，任何树中关于 $X_1$ 的所有分割点都将位于此区间内。\n\n考虑一棵树 $\\hat{f}_t$ 和一个新的数据点 $(x_1, x_{-1})$，其中 $x_1 > 80$。当这个点沿着树向下传递时，在任何涉及 $X_1$ 分割的决策节点（例如 $X_1 \\leq c_k$ 其中 $c_k \\leq 80$），该条件将始终为假。因此，该点将被路由到“右”子节点。这意味着对于任何 $x_1 > 80$，该点将沿着与 $x_1 = 80$（或者更精确地说，任何略大于该树中 $X_1$ 最大分割点的值）的点相同的路径穿过树。它将落入相对于 $X_1$ 轴的“最右侧”终端节点。所有这些点的预测值是与此终端节点相关联的常数值（即落入其中的袋内训练样本的均值）。对称地，对于任何 $x_1  45$，该点将落入“最左侧”的终端节点。\n\n随机森林预测器 $\\hat{f}_{\\mathrm{RF}}$ 是这些树预测器的平均值。由于每个 $\\hat{f}_t$ 在 $x_1 > 80$ 时是常数，它们的平均值 $\\hat{f}_{\\mathrm{RF}}$ 在 $x_1 > 80$ 时也必须是常数。随机森林模型无法将学习到的趋势外推到训练数据支撑集之外；它只能输出一个由支撑集边界处的预测决定的常数值。\n\n部分依赖函数 $PD_1(x_1)$ 是在 $X_{-1}$ 的经验分布上对预测值 $\\hat{f}_{\\mathrm{RF}}(x_1, X_{-1}^{(i)})$ 的平均。由于对于任何固定的 $X_{-1}^{(i)}$，$\\hat{f}_{\\mathrm{RF}}$ 在 $x_1 > 80$ 时是常数，因此对 $i$ 的平均在 $x_1 > 80$ 时也将是常数。\n\n在确立了这些原则之后，我将评估每个选项。\n\n**A. 在一个由 CART 构建的回归随机森林中，对于经验支撑集为 $[\\min_{i}X_{1}^{(i)},\\max_{i}X_{1}^{(i)}]$ 的单个连续特征 $X_{1}$，对于任何 $x\\max_{i}X_{1}^{(i)}$，其预测值 $\\hat{f}_{\\mathrm{RF}}(x)$ 等于所有树中最右侧终端节点均值的平均值，并且当 $x$ 进一步增加时保持不变。**\n- 如上所述，对于给定的树 $t$ 和任何 $x_1 > \\max_{i}X_{1}^{(i)}$，预测值 $\\hat{f}_t(x_1, x_{-1})$ 是一个常数。这个常数是相对于 $X_1$ 的分割而言“最右侧”的终端节点中训练结果的均值。\n- 随机森林的预测值 $\\hat{f}_{\\mathrm{RF}}(x)$ 是这些单个树预测的平均值。因此，对于 $x_1 > \\max_{i}X_{1}^{(i)}$，$\\hat{f}_{\\mathrm{RF}}(x)$ 是来自这些最右侧节点的预测的平均值。由于每棵树的预测在该区域内都是常数，所以平均值也是常数。\n- 该陈述是对模型行为的精确和正确的描述。\n- **结论：正确。**\n\n**B. 因为随机森林是许多树的平均，所以当潜在关系是单调时，它们可以可靠地在训练范围之外进行线性外推，因此 $\\hat{f}_{\\mathrm{RF}}(x)$ 将在 $x=80$ 之后延续学习到的趋势。**\n- 这个陈述是根本错误的。基学习器，即 CART 树，是分段常数函数。分段常数函数的平均不能产生线性外推。正如选项 A 的分析所确立的，预测函数 $\\hat{f}_{\\mathrm{RF}}$ 在训练数据支撑集之外变得平坦。平均化降低了方差，但没有改变基学习器固有的结构性限制。\n- **结论：不正确。**\n\n**C. 在 $X_{1}$ 的经验密度为零的 $x$ 值（例如 $x  45$ 或 $x80$）处评估的部分依赖 $PD_{1}(x)=\\mathbb{E}_{X_{-1}}[\\hat{f}_{\\mathrm{RF}}(x,X_{-1})]$ 使用了位于观测支撑集之外的组合 $(x,X_{-1}^{(i)})$；一个实际的保障措施是监控核密度估计 $\\hat{f}_{X_{1}}(x)$，并在 $\\hat{f}_{X_{1}}(x)$ 接近 0 时标记 $PD_{1}(x)$，或将可视化限制在经验分位数区间内，例如 $[q_{0.01}(X_{1}),q_{0.99}(X_{1})]$。**\n- 计算 $PD_1(x_1)$ 涉及为 $i=1, \\dots, n$ 创建合成数据点 $(x_1, X_{-1}^{(i)})$。如果 $x_1$ 位于 $X_1$ 的边际密度为零的区域（例如 $x_1 > 80$），那么这些合成点就位于训练数据的联合支撑集之外。模型对于这些未观测到的特征组合的预测可能没有意义。这个前提是正确的。\n- 提供关于数据密度的视觉提示是负责任的模型解释的一个关键方面。将地毯图或核密度估计 $\\hat{f}_{X_{1}}(x_1)$ 与 $PD_1(x_1)$ 图绘制在同一坐标轴上，是一种标准且科学合理的方法，用以警告用户 PDP 因缺乏数据而不可靠的区域。\n- 将图表限制在高密度区间内，例如在第1和第99百分位数之间，是另一种常见且有效的技术，以避免显示 PDP 中误导性的、平坦的部分。这两种提出的保障措施都是最先进的最佳实践。\n- **结论：正确。**\n\n**D. 增加树的数量 $T$ 会消除外推限制，因为根据大数定律，$\\hat{f}_{\\mathrm{RF}}(x)$ 会收敛到一个在训练支撑集之外进行外推的光滑函数。**\n- 当 $T \\rightarrow \\infty$ 时，随机森林预测器 $\\hat{f}_{\\mathrm{RF}}(x)$ 收敛于其期望值 $\\mathbb{E}[\\hat{f}_{t}(x)]$。然而，这个极限函数继承了其构成树的结构特性。由于每个 $\\hat{f}_t(x)$ 在 $x_1 > \\max_i X_1^{(i)}$ 时是常数，它们的期望值 $\\mathbb{E}[\\hat{f}_t(x)]$ 在该区域内也将是常数。大数定律确保了收敛性，但它不改变收敛到的函数的性质。增加 $T$ 并不会赋予外推趋势的新能力；它只会稳定预测。声称极限是一个“可以外推的光滑函数”是错误的。\n- **结论：不正确。**\n\n**E. 在多元设置中，一个保障措施是通过根据 $\\omega_{i}(x)\\propto\\mathbf{1}\\{|X_{1}^{(i)}-x|\\leq\\epsilon\\}$（对于一个小的 $\\epsilon0$）对训练观测值进行加权来近似条件部分依赖，即 $PD_{1}^{\\mathrm{cond}}(x)\\approx\\frac{\\sum_{i=1}^{n}\\omega_{i}(x)\\hat{f}_{\\mathrm{RF}}(x,X_{-1}^{(i)})}{\\sum_{i=1}^{n}\\omega_{i}(x)}$，并在 $\\sum_{i=1}^{n}\\omega_{i}(x)$ 很小（表明支撑集稀疏）时标记 $x$。**\n- 这个陈述描述了一种估计局部化或条件性部分依赖的方法。它旨在解决标准 PDP 对所有 $X_{-1}^{(i)}$ 值进行平均的问题，即使这些值在给定特定 $X_1=x_1$ 值的情况下是不现实的。通过仅对 $X_1^{(i)}$ 接近 $x_1$ 的观测值进行加权，平均值是在一个更相关的、$X_{-1}$ 的局部分布上计算的。这是一种有效且更细致的理解特征效应的方法。\n- 项 $\\sum_{i=1}^{n}\\omega_{i}(x)$ 是 $x_1$ 的一个小邻域内的训练点数量。这个总和的一个小值直接表明 $x_1$ 周围数据的稀缺性。当这个计数很低时，标记或不报告 $PD_{1}^{\\mathrm{cond}}(x_1)$ 是一种直接且合理的方法，以确保估计是基于充分的证据。\n- 所提议的程序是一个科学上合理的保障措施。\n- **结论：正确。**\n\n**F. 随机森林训练中使用的自助法重采样将协变量 $X_{1}$ 的支撑集扩展到 $[45,80]$ 之外，使得在 $x80$ 处的 $PD_{1}(x)$ 无需额外监控即可信。**\n- 自助法重采样涉及从原始训练数据集中*有放回地*抽取样本。任何自助样本中出现的唯一值集合都是原始数据集中唯一值集合的子集。对于协变量 $X_1$，任何自助样本包中的最小值都将大于或等于 45，最大值将小于或等于 80。\n- 自助法扩展了支撑集的这个前提在事实上是不正确的。它起到了相反的作用，或者充其量只是维持了它。它不能创建原始训练集中不存在的数据值。因此，认为这使得 PDP 在原始支撑集之外可信的结论是错误的。\n- **结论：不正确。**", "answer": "$$\\boxed{ACE}$$", "id": "4910532"}]}