{"hands_on_practices": [{"introduction": "在评估模型的整体性能之前，理解模型对每个独立数据点的拟合情况至关重要。偏差残差（Deviance residuals）为此类精细诊断提供了强有力的工具，能有效识别模型未能充分解释的观测点。[@problem_id:4914512] 这项练习将指导你计算这些残差，并解读其数值大小，从而定位模型拟合中的具体失效点。", "problem": "一项生物统计学研究使用逻辑回归对给定协变量 $x_i$ 的二元结果 $Y_i \\in \\{0,1\\}$ 进行建模，为 $i=1,\\dots,n$ 得出拟合概率 $\\hat{p}_i = \\Pr(Y_i=1 \\mid x_i)$。考虑 $n=8$ 个具有结果和拟合概率的独立观测值：\n- $(y_1,\\hat{p}_1)=(1,0.8)$，\n- $(y_2,\\hat{p}_2)=(0,0.8)$，\n- $(y_3,\\hat{p}_3)=(1,0.2)$，\n- $(y_4,\\hat{p}_4)=(0,0.2)$，\n- $(y_5,\\hat{p}_5)=(1,0.95)$，\n- $(y_6,\\hat{p}_6)=(0,0.95)$，\n- $(y_7,\\hat{p}_7)=(1,0.05)$，\n- $(y_8,\\hat{p}_8)=(0,0.05)$。\n\n从伯努利对数似然和模型偏差（定义为饱和对数似然与拟合对数似然之差的两倍）的定义出发，推导每个观测值 $i=1,\\dots,8$ 的单个偏差残差 $r_i$。然后，计算这 8 个观测值的偏差残差的均方根。简要解释残差的大小在拟合优度方面的意义，并说明它们如何与校准评估（如 Hosmer–Lemeshow 拟合优度检验，HL）以及分类指标（如准确率和受试者工作特征（ROC）曲线）相关联。将您的最终数值答案（偏差残差的均方根）四舍五入到四位有效数字。", "solution": "### 解答推导\n\n分析始于来自伯努利分布的单个观测值 $i$ 的对数似然函数，这是逻辑回归的基础。给定二元结果 $y_i \\in \\{0, 1\\}$ 和模型预测的概率 $p_i = \\Pr(Y_i=1)$，对数似然为：\n$$\nl(p_i; y_i) = y_i \\ln(p_i) + (1-y_i)\\ln(1-p_i)\n$$\n在 $n$ 个观测值上，拟合模型的总对数似然是在拟合概率 $\\hat{p}_i$ 处评估的各个对数似然之和：\n$$\nL(\\hat{\\mathbf{p}}) = \\sum_{i=1}^n \\left[ y_i \\ln(\\hat{p}_i) + (1-y_i)\\ln(1-\\hat{p}_i) \\right]\n$$\n饱和模型是能完美拟合数据的模型。对于二元数据，这是通过将每个观测值的预测概率设置为其观测结果来实现的，即 $\\hat{p}_i^{\\text{sat}} = y_i$。饱和模型的对数似然为：\n$$\nL(\\mathbf{y}) = \\sum_{i=1}^n \\left[ y_i \\ln(y_i) + (1-y_i)\\ln(1-y_i) \\right]\n$$\n对于任何 $y_i \\in \\{0,1\\}$，和中的项是 $1\\ln(1) + (1-1)\\ln(0)$ 或 $0\\ln(0) + (1-0)\\ln(1)$。由于 $\\lim_{x\\to 0} x\\ln(x) = 0$，和中的每一项都是 $0$。因此，饱和模型的对数似然是 $L(\\mathbf{y}) = 0$。\n\n模型偏差 $D$ 定义为饱和模型和拟合模型的对数似然之差的两倍。它衡量了拟合模型偏离饱和模型完美拟合的程度。\n$$\nD = 2[L(\\mathbf{y}) - L(\\hat{\\mathbf{p}})] = 2[0 - L(\\hat{\\mathbf{p}})] = -2 \\sum_{i=1}^n \\left[ y_i \\ln(\\hat{p}_i) + (1-y_i)\\ln(1-\\hat{p}_i) \\right]\n$$\n总偏差 $D$ 是每个观测值的单个偏差分量 $d_i$ 的总和，其中 $D = \\sum_{i=1}^n d_i$。单个偏差分量由下式给出：\n$$\nd_i = -2 \\left[ y_i \\ln(\\hat{p}_i) + (1-y_i)\\ln(1-\\hat{p}_i) \\right]\n$$\n偏差残差 $r_i$ 是单个偏差分量的带符号平方根。符号由原始残差 $y_i - \\hat{p}_i$ 的符号决定。这确保了对于意外的成功（$y_i=1$ 且 $\\hat{p}_i$ 较小），残差为正；对于意外的失败（$y_i=0$ 且 $\\hat{p}_i$ 较大），残差为负。\n$$\nr_i = \\text{sign}(y_i - \\hat{p}_i) \\sqrt{d_i}\n$$\n我们可以为两种可能的结果写出这个公式：\n-   如果 $y_i=1$：$d_i = -2 \\ln(\\hat{p}_i)$。由于 $0  \\hat{p}_i  1$，$\\text{sign}(1-\\hat{p}_i) = +1$。残差为 $r_i = \\sqrt{-2\\ln(\\hat{p}_i)}$。\n-   如果 $y_i=0$：$d_i = -2 \\ln(1-\\hat{p}_i)$。由于 $0  \\hat{p}_i  1$，$\\text{sign}(0-\\hat{p}_i) = -1$。残差为 $r_i = -\\sqrt{-2\\ln(1-\\hat{p}_i)}$。\n\n现在，我们将这些公式应用于提供的 $n=8$ 个观测值。\n\n-   对于 $(y_1, \\hat{p}_1) = (1, 0.8)$：$r_1 = \\sqrt{-2\\ln(0.8)} \\approx \\sqrt{-2(-0.22314)} \\approx \\sqrt{0.44629} \\approx 0.6680$\n-   对于 $(y_2, \\hat{p}_2) = (0, 0.8)$：$r_2 = -\\sqrt{-2\\ln(1-0.8)} = -\\sqrt{-2\\ln(0.2)} \\approx -\\sqrt{-2(-1.60944)} \\approx -\\sqrt{3.21888} \\approx -1.7941$\n-   对于 $(y_3, \\hat{p}_3) = (1, 0.2)$：$r_3 = \\sqrt{-2\\ln(0.2)} \\approx \\sqrt{3.21888} \\approx 1.7941$\n-   对于 $(y_4, \\hat{p}_4) = (0, 0.2)$：$r_4 = -\\sqrt{-2\\ln(1-0.2)} = -\\sqrt{-2\\ln(0.8)} \\approx -\\sqrt{0.44629} \\approx -0.6680$\n-   对于 $(y_5, \\hat{p}_5) = (1, 0.95)$：$r_5 = \\sqrt{-2\\ln(0.95)} \\approx \\sqrt{-2(-0.05129)} \\approx \\sqrt{0.10259} \\approx 0.3203$\n-   对于 $(y_6, \\hat{p}_6) = (0, 0.95)$：$r_6 = -\\sqrt{-2\\ln(1-0.95)} = -\\sqrt{-2\\ln(0.05)} \\approx -\\sqrt{-2(-2.99573)} \\approx -\\sqrt{5.99146} \\approx -2.4477$\n-   对于 $(y_7, \\hat{p}_7) = (1, 0.05)$：$r_7 = \\sqrt{-2\\ln(0.05)} \\approx \\sqrt{5.99146} \\approx 2.4477$\n-   对于 $(y_8, \\hat{p}_8) = (0, 0.05)$：$r_8 = -\\sqrt{-2\\ln(1-0.05)} = -\\sqrt{-2\\ln(0.95)} \\approx -\\sqrt{0.10259} \\approx -0.3203$\n\n下一步是计算这些偏差残差的均方根（RMS）。RMS 定义为：\n$$\n\\text{RMS} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n r_i^2}\n$$\n由于 $r_i^2 = d_i$，总和 $\\sum_{i=1}^n r_i^2$ 就是总偏差 $D$。因此，$\\text{RMS} = \\sqrt{D/n}$。\n让我们通过对单个残差的平方（$d_i=r_i^2$）求和来计算总偏差 $D$：\n$D = r_1^2+r_2^2+r_3^2+r_4^2+r_5^2+r_6^2+r_7^2+r_8^2$\n$D = (-2\\ln(0.8)) + (-2\\ln(0.2)) + (-2\\ln(0.2)) + (-2\\ln(0.8)) + (-2\\ln(0.95)) + (-2\\ln(0.05)) + (-2\\ln(0.05)) + (-2\\ln(0.95))$\n$D = -4(\\ln(0.8) + \\ln(0.2) + \\ln(0.95) + \\ln(0.05))$\n$D \\approx 0.44629 + 3.21888 + 3.21888 + 0.44629 + 0.10259 + 5.99146 + 5.99146 + 0.10259 \\approx 19.5184$\n\n当 $n=8$ 时，RMS 是：\n$$\n\\text{RMS} = \\sqrt{\\frac{19.5184}{8}} \\approx \\sqrt{2.4398} \\approx 1.5620499\n$$\n四舍五入到四位有效数字，偏差残差的均方根为 $1.562$。\n\n### 解释\n偏差残差的大小提供了对模型在个体和总体层面上的拟合优度的洞察。对于一个拟合良好的模型，偏差残差近似服从标准正态分布，因此绝对值大于 $2$ 的值被认为是大的，表明该特定观测值的拟合不佳。\n\n-   观测值 $1$、$4$、$5$ 和 $8$ 的残差很小（$|r_i|  1$），表明模型对这些结果的预测是合理的（例如，对于观测值 1，$\\hat{p}_1=0.8$ 且 $y_1=1$）。\n-   观测值 $2$ 和 $3$ 的残差中等偏大（$|r_i| \\approx 1.79$），表明预测和结果之间存在显著差异（例如，对于观测值 3，模型为一个已发生的事件预测了低概率 $\\hat{p}_3=0.2$，$y_3=1$）。\n-   观测值 $6$ 和 $7$ 的残差很大（$|r_i| \\approx 2.45$），突显了严重的拟合不足。对于这些情况，模型对其预测非常自信（例如，$\\hat{p}_6=0.95$），但结果却与预期相反（$y_6=0$）。这些点对模型来说是“意外的”，并对总偏差有很大贡献。\n\n**与校准和 Hosmer-Lemeshow (HL) 检验的关系：**\n拟合优度评估主要关注**校准**，即模型产生与观测事件率相匹配的预测概率的能力。HL 检验通过按预测风险对受试者进行分组，并比较每组中的观测事件数与预期事件数来形式化这一过程。我们观察到的大残差，特别是观测值 $6$ 和 $7$ 的残差，表明校准不佳。模型在接近边界（$0.05$ 和 $0.95$）处预测的概率，其结果却相反。如果这些观测值是 HL 检验的一部分，它们将在相应的风险组中造成观测计数和预期计数之间的巨大差异，导致大的 HL 卡方统计量和小的 p 值，表明模型校准不佳。大的总体 RMS 偏差残差（$1.562$）也表明整体拟合不足。\n\n**与分类指标（准确率，ROC 曲线）的关系：**\n分类指标评估**区分度**，即模型区分两种结果类别（$Y=1$ vs. $Y=0$）的能力。这与校准是不同的。\n-   **准确率**：使用标准的 $0.5$ 阈值，模型在 $8$ 个观测值中仅正确分类了 $4$ 个（正确：$1,4,5,8$；不正确：$2,3,6,7$），准确率为 $50\\%$。这不比随机猜测好。\n-   **ROC 曲线**：ROC 曲线是通过在所有可能的阈值下绘制真阳性率对假阳性率而生成的。该曲线下面积（AUC）量化了区分度。$y=1$ 的受试者的预测概率集合是 $\\{\\hat{p}_1, \\hat{p}_3, \\hat{p}_5, \\hat{p}_7\\} = \\{0.8, 0.2, 0.95, 0.05\\}$。$y=0$ 的受试者的预测概率集合是 $\\{\\hat{p}_2, \\hat{p}_4, \\hat{p}_6, \\hat{p}_8\\} = \\{0.8, 0.2, 0.95, 0.05\\}$。两类别的预测概率分布是相同的。这意味着该模型完全没有能力区分病例和对照。ROC 曲线将位于无区分度的对角线上，AUC 恰好为 $0.5$。\n\n总之，偏差残差揭示了一个具有严重病态的模型。大的残差值指向校准不佳（拟合优度的失败），而数据的特定结构也显示出区分能力的完全失效。该模型对于预测和分类实际上是无用的。", "answer": "$$\n\\boxed{1.562}\n$$", "id": "4914512"}, {"introduction": "虽然单个残差提供了丰富的信息，但我们通常需要对整个数据集的模型性能进行总结。这项练习聚焦于评估模型校准度（calibration）的聚合度量，即模型预测的事件发生率与观测频率的匹配程度。[@problem_id:4914555] 你将通过对受试者分组来计算著名的 Hosmer-Lemeshow 统计量，同时也会计算如 Brier 分数和对数损失等整体性能指标，从而更深入地理解模型准确性的不同方面。", "problem": "一个生物统计学团队对 $n=20$ 名患者的二元临床结局 $y_{i} \\in \\{0,1\\}$ 拟合了一个逻辑回归模型，并获得了预测概率 $\\hat{p}_{i} \\in (0,1)$。该模型使用从第一性原理推导出的拟合优度和分类质量指标进行评估。\n\n从独立观测的伯努利似然及其对数出发，将基于熵的分类质量度量定义为每个观测的负平均对数似然。同时考虑预测概率与结局之间的均方误差。利用这些基础，为以下数据集计算这两种指标，并通过二次近似讨论它们的局部关系。\n\n此外，通过将患者按 $\\hat{p}_{i}$ 排序后分为 $G=5$ 个等大规模的风险组，并比较每组内的观测事件数与期望事件数，使用 Hosmer–Lemeshow (HL) 拟合优度统计量来评估模型校准。使用标准的HL分组程序和Pearson型分组统计量。\n\n数据集以有序对 $(\\hat{p}_{i}, y_{i})$ 的形式给出，对应于患者 $i=1,\\dots,20$：\n$(0.05,0)$, $(0.08,0)$, $(0.10,0)$, $(0.12,1)$, $(0.18,0)$, $(0.22,0)$, $(0.25,1)$, $(0.28,0)$, $(0.32,0)$, $(0.35,1)$, $(0.45,1)$, $(0.50,0)$, $(0.55,1)$, $(0.60,1)$, $(0.65,0)$, $(0.70,1)$, $(0.78,1)$, $(0.82,1)$, $(0.88,1)$, $(0.92,1)$.\n\n任务：\n- 从伯努利似然推导基于熵的每个观测的负平均对数似然，并为该数据集计算其值。\n- 将Brier分数定义为 $\\hat{p}_{i}$ 和 $y_{i}$ 之间的均方差，并为该数据集计算其值。\n- 使用围绕正确分类的二阶泰勒展开，解释基于熵的度量与Brier分数之间的局部关系。\n- 计算 $G=5$ 个等大规模组（按 $\\hat{p}_{i}$ 排序）的 Hosmer–Lemeshow 统计量，显示期望计数、观测计数以及每组对该统计量的贡献。\n\n最后，报告单个量 $R$，定义为基于熵的负平均对数似然与Brier分数之比。将 $R$ 四舍五入到四位有效数字。无需单位，并将任何中间比例或概率以小数形式表示，而不是百分比。", "solution": "### 第1部分：基于熵的负平均对数似然\n\n该模型针对 $i=1, \\dots, n$ 个独立患者的二元结局 $y_i \\in \\{0, 1\\}$。事件 ($y_i=1$) 的预测概率为 $\\hat{p}_i$。观测到结局 $y_i$ 的概率由伯努利概率质量函数给出：\n$$ P(Y_i = y_i | \\hat{p}_i) = \\hat{p}_i^{y_i} (1-\\hat{p}_i)^{1-y_i} $$\n对于 $n$ 个独立观测，总似然是个体概率的乘积：\n$$ L(\\{\\hat{p}_i\\}; \\{y_i\\}) = \\prod_{i=1}^{n} \\hat{p}_i^{y_i} (1-\\hat{p}_i)^{1-y_i} $$\n对数似然 $\\ell$ 是似然的自然对数：\n$$ \\ell = \\ln(L) = \\sum_{i=1}^{n} \\ln\\left( \\hat{p}_i^{y_i} (1-\\hat{p}_i)^{1-y_i} \\right) = \\sum_{i=1}^{n} [y_i \\ln(\\hat{p}_i) + (1-y_i) \\ln(1-\\hat{p}_i)] $$\n基于熵的分类质量度量，我们记为 $E$，定义为每个观测的负平均对数似然。这也被称为交叉熵损失。\n$$ E = -\\frac{1}{n} \\ell = -\\frac{1}{n} \\sum_{i=1}^{n} [y_i \\ln(\\hat{p}_i) + (1-y_i) \\ln(1-\\hat{p}_i)] $$\n为了计算其在给定数据集上的值，我们有 $n=20$。我们将总和分为两部分：一部分用于 $y_i=1$ 的观测，另一部分用于 $y_i=0$ 的观测。\n\n对于 $y_i=1$ 的情况（11个观测）：\n$$ \\sum_{y_i=1} \\ln(\\hat{p}_i) = \\ln(0.12) + \\ln(0.25) + \\ln(0.35) + \\ln(0.45) + \\ln(0.55) + \\ln(0.60) + \\ln(0.70) + \\ln(0.78) + \\ln(0.82) + \\ln(0.88) + \\ln(0.92) \\approx -7.478345 $$\n对于 $y_i=0$ 的情况（9个观测）：\n$$ \\sum_{y_i=0} \\ln(1-\\hat{p}_i) = \\ln(1-0.05) + \\ln(1-0.08) + \\ln(1-0.10) + \\ln(1-0.18) + \\ln(1-0.22) + \\ln(1-0.28) + \\ln(1-0.32) + \\ln(1-0.50) + \\ln(1-0.65) \\approx -3.144083 $$\n总对数似然为 $\\ell \\approx -7.478345 - 3.144083 = -10.622428$。\n基于熵的度量为：\n$$ E = -\\frac{1}{20} (-10.622428) \\approx 0.5311214 $$\n\n### 第2部分：Brier分数（均方误差）\n\nBrier分数 $BS$ 定义为预测概率 $\\hat{p}_i$ 与实际结局 $y_i$ 之间的均方差。\n$$ BS = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{p}_i)^2 $$\n为该数据集（$n=20$）计算其值：\n对于 $y_i=1$ 的情况：\n$$ \\sum_{y_i=1} (1-\\hat{p}_i)^2 = (1-0.12)^2 + (1-0.25)^2 + \\dots + (1-0.92)^2 = 0.88^2 + 0.75^2 + 0.65^2 + 0.55^2 + 0.45^2 + 0.40^2 + 0.30^2 + 0.22^2 + 0.18^2 + 0.12^2 + 0.08^2 = 2.616 $$\n对于 $y_i=0$ 的情况：\n$$ \\sum_{y_i=0} (0-\\hat{p}_i)^2 = (0.05)^2 + (0.08)^2 + \\dots + (0.65)^2 = 0.05^2 + 0.08^2 + 0.10^2 + 0.18^2 + 0.22^2 + 0.28^2 + 0.32^2 + 0.50^2 + 0.65^2 = 0.953 $$\n总平方和为 $2.616 + 0.953 = 3.569$。\nBrier分数为：\n$$ BS = \\frac{1}{20} (3.569) = 0.17845 $$\n\n### 第3部分：熵与Brier分数的局部关系\n\n我们来分析每个观测的熵度量损失 $E_i$ 和Brier分数损失 $BS_i$。\n$$ E_i = -[y_i \\ln(\\hat{p}_i) + (1-y_i) \\ln(1-\\hat{p}_i)] $$\n$$ BS_i = (y_i - \\hat{p}_i)^2 $$\n我们研究 $E_i$ 在“正确分类”附近的局部行为，这意味着预测概率 $\\hat{p}_i$ 非常接近真实结局 $y_i$。设偏差为 $\\epsilon = |y_i - \\hat{p}_i|$，其中 $\\epsilon \\to 0^+$。\n\n情况1：$y_i=1$。正确分类意味着 $\\hat{p}_i \\to 1$。设 $\\hat{p}_i = 1-\\epsilon$。\n熵损失为 $E_i = -\\ln(1-\\epsilon)$。\nBrier分数为 $BS_i = (1 - (1-\\epsilon))^2 = \\epsilon^2$。\n使用 $-\\ln(1-\\epsilon)$ 在 $\\epsilon=0$ 附近的二阶泰勒展开：\n$$ E_i = - \\left( -\\epsilon - \\frac{\\epsilon^2}{2} - O(\\epsilon^3) \\right) = \\epsilon + \\frac{\\epsilon^2}{2} + O(\\epsilon^3) $$\n情况2：$y_i=0$。正确分类意味着 $\\hat{p}_i \\to 0$。设 $\\hat{p}_i = \\epsilon$。\n熵损失为 $E_i = -\\ln(1-\\epsilon)$。\nBrier分数为 $BS_i = (0 - \\epsilon)^2 = \\epsilon^2$。\n泰勒展开是相同的：\n$$ E_i = \\epsilon + \\frac{\\epsilon^2}{2} + O(\\epsilon^3) $$\n在这两种情况下，对于一个小的偏差 $\\epsilon = |y_i - \\hat{p}_i|$，我们有 $BS_i = \\epsilon^2$。将 $\\epsilon = \\sqrt{BS_i}$ 代入 $E_i$ 的展开式中：\n$$ E_i \\approx \\sqrt{BS_i} + \\frac{1}{2} BS_i $$\n这种关系表明，对于非常接近真实结局的预测，熵损失由一个关于 $\\epsilon$ 的线性项（$\\sqrt{BS_i}$）主导，而Brier分数是二次的（$\\epsilon^2$）。这意味着熵损失比Brier分数更严厉地惩罚小的预测误差。\n\n### 第4部分：Hosmer–Lemeshow 统计量\n\n我们将患者按 $\\hat{p}_i$ 排序，并形成 $G=5$ 个等大规模的组，每组大小为 $n_g = 20/5=4$。对于每组 $g$，我们计算观测到的事件数（$O_g = \\sum y_i$）和期望的事件数（$E_g = \\sum \\hat{p}_i$）。Hosmer-Lemeshow 统计量 $H$ 是一个根据这些计数计算的Pearson型卡方统计量：\n$$ H = \\sum_{g=1}^{G} \\left[ \\frac{(O_g - E_g)^2}{E_g} + \\frac{((n_g - O_g) - (n_g - E_g))^2}{n_g - E_g} \\right] $$\n计算结果总结在下表中。\n\n| 组 (g) | 患者（按索引 $i$） | 预测概率 ($\\hat{p}_i$) | 结局 ($y_i$) | $n_g$ | $O_g$ | $E_g$ | $O_g-E_g$ | 对 $H$ 的贡献 |\n| :---: | :---: | :--- | :--- | :---: | :---: | :---: | :---: | :---: |\n| 1 | 1-4 | $0.05, 0.08, 0.10, 0.12$ | $0, 0, 0, 1$ | 4 | 1 | 0.35 | 0.65 | $\\frac{0.65^2}{0.35} + \\frac{(-0.65)^2}{3.65} \\approx 1.32290$ |\n| 2 | 5-8 | $0.18, 0.22, 0.25, 0.28$ | $0, 0, 1, 0$ | 4 | 1 | 0.93 | 0.07 | $\\frac{0.07^2}{0.93} + \\frac{(-0.07)^2}{3.07} \\approx 0.00687$ |\n| 3 | 9-12 | $0.32, 0.35, 0.45, 0.50$ | $0, 1, 1, 0$ | 4 | 2 | 1.62 | 0.38 | $\\frac{0.38^2}{1.62} + \\frac{(-0.38)^2}{2.38} \\approx 0.14981$ |\n| 4 | 13-16 | $0.55, 0.60, 0.65, 0.70$ | $1, 1, 0, 1$ | 4 | 3 | 2.50 | 0.50 | $\\frac{0.50^2}{2.50} + \\frac{(-0.50)^2}{1.50} \\approx 0.26667$ |\n| 5 | 17-20 | $0.78, 0.82, 0.88, 0.92$ | $1, 1, 1, 1$ | 4 | 4 | 3.40 | 0.60 | $\\frac{0.60^2}{3.40} + \\frac{(-0.60)^2}{0.60} \\approx 0.70588$ |\n\n将各组的贡献相加：\n$$ H \\approx 1.32290 + 0.00687 + 0.14981 + 0.26667 + 0.70588 \\approx 2.45213 $$\n\n### 第5部分：最终比率计算\n\n最后的任务是计算基于熵的负平均对数似然与Brier分数之比 $R$。\n$$ R = \\frac{E}{BS} = \\frac{0.5311214}{0.17845} \\approx 2.976296 $$\n四舍五入到四位有效数字，我们得到：\n$$ R \\approx 2.976 $$", "answer": "$$\n\\boxed{2.976}\n$$", "id": "4914555"}, {"introduction": "在建模过程中一个常见的问题是：“我的模型相比简单的猜测好多少？” 伪 $R^2$（Pseudo-$R^2$）统计量，例如由 Cox-Snell 和 Nagelkerke 提出的那些，通过量化模型相对于基线零模型（null model）在拟合优度上的改进，为这个问题提供了答案。[@problem_id:4914507] 本练习将深入探讨这些度量的推导和解释，阐明它们为何对于总结模型的整体解释能力至关重要。", "problem": "一家医院的生物统计团队拟合了一个逻辑回归模型，用于一个二元结果，该结果指示患者是否出现术后并发症。他们使用最大似然估计（MLE）方法，估计了一个仅含截距的模型（零模型）和一个富含预测变量的模型（拟合模型）。假设结果是独立的伯努利分布。样本量为 $n=200$，零模型的对数似然为 $\\ell_{0}=-138.4$，拟合模型的对数似然为 $\\ell_{m}=-124.1$。\n\n从独立伯努利似然的定义 $L=\\prod_{i=1}^{n} p_{i}^{y_{i}}(1-p_{i})^{1-y_{i}}$ 及其对数出发，推导 Cox–Snell 伪 $R^{2}$ 和 Nagelkerke 伪 $R^{2}$ 关于 $n$、$\\ell_{0}$ 和 $\\ell_{m}$ 的表达式。利用这些定义和饱和模型的概念，解释为什么在逻辑回归中 Cox–Snell 的度量上限不为 $1$，而 Nagelkerke 的度量上限为 $1$。\n\n然后，使用你推导出的公式和给定的 $n$、$\\ell_{0}$ 和 $\\ell_{m}$ 值，计算 Nagelkerke 伪 $R^{2}$。将最终数值答案四舍五入至四位有效数字，并以小数形式表示（不要使用百分号）。", "solution": "分析的基础是 $n$ 次独立伯努利试验的似然函数。给定观测结果 $y_i \\in \\{0, 1\\}$ 和模型预测的概率 $p_i$，似然函数 $L$ 为：\n$$L = \\prod_{i=1}^{n} p_{i}^{y_{i}}(1-p_{i})^{1-y_{i}}$$\n对数似然函数（记为 $\\ell$）是似然函数的自然对数：\n$$\\ell = \\ln(L) = \\sum_{i=1}^{n} [y_i \\ln(p_i) + (1-y_i) \\ln(1-p_i)]$$\n问题提供了两个模型的最大化对数似然：对于样本量 $n=200$，零模型（仅含截距）的对数似然为 $\\ell_0 = -138.4$，拟合模型的对数似然为 $\\ell_m = -124.1$。\n\n首先，我们推导 Cox–Snell 和 Nagelkerke 伪 $R^2$ 度量的表达式。这些度量旨在通过比较拟合模型（$L_m$）和零模型（$L_0$）的似然，来模仿线性回归中的决定系数 $R^2$。\n\nCox–Snell 伪 $R^2$（记为 $R^2_{CS}$）定义为：\n$$R^2_{CS} = 1 - \\left(\\frac{L_0}{L_m}\\right)^{2/n}$$\n为了用给定的对数似然来表示它，我们使用性质 $\\ln(L_0/L_m) = \\ell_0 - \\ell_m$。对两边取指数，得到 $L_0/L_m = \\exp(\\ell_0 - \\ell_m)$。将此代入 $R^2_{CS}$ 的定义中：\n$$R^2_{CS} = 1 - \\left(\\exp(\\ell_0 - \\ell_m)\\right)^{2/n} = 1 - \\exp\\left(\\frac{2(\\ell_0 - \\ell_m)}{n}\\right)$$\n这就是 Cox–Snell 伪 $R^2$ 关于 $n$、$\\ell_0$ 和 $\\ell_m$ 的所求表达式。\n\n接下来，我们解释为什么 Cox–Snell 度量的上限不为 $1$。任何伪 $R^2$ 度量的上限是在拟合模型为“饱和模型”时达到的，饱和模型是能完美拟合数据的模型。对于 $n$ 个独立的伯努利结果，饱和模型将拥有与观测值一样多的参数，从而实现完美拟合。在此类模型中，每个观测值 $y_i$ 的预测概率 $p_i$ 将是 $p_i=y_i$。单个观测值的似然是 $p_i^{y_i}(1-p_i)^{1-y_i}$。如果 $y_i=1$，该项为 $1^1(0)^0$。如果 $y_i=0$，该项为 $0^0(1)^1$。按照 $0^0=1$ 的惯例，饱和模型中每个观测值的似然都是 $1$。因此，饱和模型的总似然为 $L_{sat} = \\prod_{i=1}^{n} 1 = 1$。相应的对数似然为 $\\ell_{sat} = \\ln(1) = 0$。\n\n$L_m$ 的最大可能值为 $L_{sat} = 1$。将此代入 $R^2_{CS}$ 的定义，得到该度量可达到的最大值：\n$$\\max(R^2_{CS}) = 1 - \\left(\\frac{L_0}{L_{sat}}\\right)^{2/n} = 1 - \\left(\\frac{L_0}{1}\\right)^{2/n} = 1 - (L_0)^{2/n}$$\n由于零模型（假设所有结果具有单一概率）不能完美拟合数据，其似然 $L_0$ 严格小于 $1$。因此，$(L_0)^{2/n}$ 是一个正值，这意味着 $\\max(R^2_{CS})  1$。这就是为什么 Cox–Snell 度量的上限不为 $1$；其可达到的最大值取决于数据，且始终小于 $1$。\n\nNagelkerke 伪 $R^2$（记为 $R^2_N$）被提出来纠正这个局限性，它通过将 Cox–Snell 度量除以其最大可能值来进行归一化：\n$$R^2_N = \\frac{R^2_{CS}}{\\max(R^2_{CS})} = \\frac{1 - (L_0/L_m)^{2/n}}{1 - (L_0)^{2/n}}$$\n根据这个构造，当拟合模型是饱和模型（$L_m = 1$）时，分子等于分母，因此 $R^2_N = 1$。因此，Nagelkerke 度量的上限为 $1$，其取值范围是 $[0, 1]$。\n\n为了推导 $R^2_N$ 关于对数似然的表达式，我们代入指数形式：\n$$(L_0/L_m)^{2/n} = \\exp\\left(\\frac{2(\\ell_0 - \\ell_m)}{n}\\right)$$\n$$(L_0)^{2/n} = (\\exp(\\ell_0))^{2/n} = \\exp\\left(\\frac{2\\ell_0}{n}\\right)$$\n将这些代入 $R^2_N$ 的公式中，得到：\n$$R^2_N = \\frac{1 - \\exp\\left(\\frac{2(\\ell_0 - \\ell_m)}{n}\\right)}{1 - \\exp\\left(\\frac{2\\ell_0}{n}\\right)}$$\n这就是所求的 Nagelkerke 伪 $R^2$ 的表达式。\n\n最后，我们使用给定的数据计算 $R^2_N$ 的数值：$n=200$，$\\ell_0=-138.4$，以及 $\\ell_m=-124.1$。\n\n首先，我们计算指数中的项：\n- 分子指数项：$\\frac{2(\\ell_0 - \\ell_m)}{n} = \\frac{2(-138.4 - (-124.1))}{200} = \\frac{2(-14.3)}{200} = \\frac{-28.6}{200} = -0.143$\n- 分母指数项：$\\frac{2\\ell_0}{n} = \\frac{2(-138.4)}{200} = \\frac{-276.8}{200} = -1.384$\n\n现在，将这些值代入 $R^2_N$ 的公式中：\n$$R^2_N = \\frac{1 - \\exp(-0.143)}{1 - \\exp(-1.384)}$$\n我们计算指数函数的值：\n$$\\exp(-0.143) \\approx 0.8667528$$\n$$\\exp(-1.384) \\approx 0.2505705$$\n将这些数值代回 $R^2_N$ 的表达式中：\n$$R^2_N \\approx \\frac{1 - 0.8667528}{1 - 0.2505705} = \\frac{0.1332472}{0.7494295} \\approx 0.1778005$$\n将结果四舍五入到四位有效数字，得到 $0.1778$。", "answer": "$$\\boxed{0.1778}$$", "id": "4914507"}]}