## 引言
在生物统计学和相关领域，我们经常遇到具有两个以上类别的结局变量，例如疾病亚型、严重程度分级或治疗反应。标准的二元逻辑回归无法处理这类数据，这便引出了一个核心问题：我们如何为这些多分类结局变量构建既准确又具有解释力的[统计模型](@entry_id:755400)？简单地将问题拆解为多个二元回归往往会导致不一致甚至矛盾的结论。因此，理解和掌握专门为多[分类数据](@entry_id:202244)设计的模型至关重要。

本篇文章将系统性地介绍两种广义逻辑回归模型：[多项逻辑回归](@entry_id:275878)（用于名义型结局）和有序逻辑回归（用于有序型结局）。在接下来的内容中，我们将分三步深入探讨：首先，在“原理与机制”一章中，我们将剖析这两种模型的数学基础、核心假设以及参数解释，并探讨模型选择中的关键权衡。接着，在“应用与跨学科联系”一章中，我们将通过生物统计学、流行病学和生物信息学等领域的具体案例，展示这些模型如何解决实际科学问题。最后，“动手实践”部分将提供练习，帮助您巩固理论知识。让我们从深入理解这些模型的基本原理与机制开始。

## 原理与机制

在处理具有两个以上类别的分类结局变量时，标准的二元逻辑回归模型不再适用。我们需要更广义的模型框架来处理多类别问题。根据结局变量类别的内在性质，这些模型主要分为两大类：用于处理无序类别（名义变量）的模型，以及用于处理有序类别的模型。本章将深入探讨这两类模型的核心原理与机制，重点介绍名义逻辑回归（Multinomial Logistic Regression）和有序逻辑回归（Ordinal Logistic Regression）的构建、假设、参数解释以及它们之间的权衡。

### 名义、有序和模型选择

选择正确的模型始于对结局变量的深刻理解。一个[分类变量](@entry_id:637195)可以是**名义的 (nominal)**，意味着其类别之间没有内在的顺序或等级。例如，患者入院的主要原因（如心脏科、肺科、神经科）或疫苗接种后的不良事件类型（如无、皮疹、恶心、发烧）都是名义变量。对于这类数据，类别仅仅是标签，交换它们的顺序不会改变数据的含义。

与此相对，一个分类变量可以是**有序的 (ordinal)**，意味着其类别之间存在明确的等级关系。例如，癌症分期（I期、II期、III期、IV期）、疼痛严重程度（轻度、中度、重度）或美国麻醉医师协会（ASA）身体状况分级，都是有序变量。在这里，类别标签不仅是标识，还蕴含了“或多或少”的量级信息。

这种根本区别决定了恰当的[统计建模](@entry_id:272466)策略 [@problem_id:4929803]。对于名义结局，我们应使用不预设类别间任何顺序关系的模型。最经典的模型是**基线类别名义逻辑回归 (baseline-category multinomial logistic regression)**。该模型通过将每个非基线类别与一个选定的基线类别进行比较来建立关系，它对类别间的关系保持了最大的灵活性。

而对于有序结局，忽略其内在的顺序信息将导致[统计效率](@entry_id:164796)的损失。因此，我们优先选择能够利用这种顺序信息的模型。应用最广泛的是**累积链接模型 (cumulative link models)**，尤其是**比例[优势模](@entry_id:263463)型 (proportional odds model)**。该模型不直接对单个类别的[概率建模](@entry_id:168598)，而是对累积概率（即结局小于或等于某个特定类别的概率）进行建模，从而有效地利用了类别的顺序性。

### 名义逻辑[回归模型](@entry_id:163386)

当结局变量 $Y$ 包含 $K$ 个无序的类别（记为 $1, 2, \dots, K$）时，名义逻辑[回归模型](@entry_id:163386)成为我们的首选工具。其核心思想是建立一个统一的概率模型，该模型能够同时预测每个类别发生的概率，并确保所有类别的概率之和为1。

#### 基线类别[对数几率](@entry_id:141427)模型

该模型最常见的形式是基线类别对数几率模型。我们首先选择一个类别作为**基线 (baseline)** 或**参照 (reference)** 类别，例如类别 $K$。然后，模型针对每个非基线类别 $i \in \{1, \dots, K-1\}$，构建其与基线类别 $K$ 的**对数几率 (log-odds)**，并假设该对数几率是协变量向量 $\mathbf{x}$ 的线性函数。

具体而言，对于每个非基线类别 $i$，模型设定如下关系 [@problem_id:4929808] [@problem_id:4929773]：
$$
\ln\left(\frac{P(Y=i \mid \mathbf{x})}{P(Y=K \mid \mathbf{x})}\right) = \mathbf{x}^{\top}\beta_i
$$
这里，$\mathbf{x}$ 是一个包含截距项的 $p$ 维协变量列向量，$\beta_i$ 是一个 $p$ 维的系数向量，它特定于类别 $i$ 与基线类别 $K$ 的对比。这个模型共包含 $K-1$ 个这样的方程，每个方程都有一套独立的系数 $\beta_i$。

从这个基本的对数几率定义出发，结合所有类别概率之和必须为1（即 $\sum_{k=1}^{K} P(Y=k \mid \mathbf{x}) = 1$）这一公理，我们可以推导出每个类别概率的显式表达式。首先，通过对上式取指数，我们得到：
$$
P(Y=i \mid \mathbf{x}) = P(Y=K \mid \mathbf{x}) \cdot \exp(\mathbf{x}^{\top}\beta_i) \quad \text{for } i \in \{1, \dots, K-1\}
$$
将这些表达式代入概率求和约束 $\sum_{i=1}^{K-1} P(Y=i \mid \mathbf{x}) + P(Y=K \mid \mathbf{x}) = 1$，我们可以解出基线类别的概率：
$$
P(Y=K \mid \mathbf{x}) = \frac{1}{1 + \sum_{j=1}^{K-1}\exp(\mathbf{x}^{\top}\beta_j)}
$$
进而，我们可以得到任意非基线类别 $i$ 的概率：
$$
P(Y=i \mid \mathbf{x}) = \frac{\exp(\mathbf{x}^{\top}\beta_i)}{1 + \sum_{j=1}^{K-1}\exp(\mathbf{x}^{\top}\beta_j)}
$$
这些公式构成了基线类别名义逻辑回归模型的核心 [@problem_id:4929808]。

#### [模型识别](@entry_id:139651)与参数解释

你可能想知道，为什么我们必须选择一个基线类别？这个选择是出于模型**可识别性 (identifiability)** 的需要，而非实质性的科学假设 [@problem_id:4929775]。一个更对称的模型形式，称为**softmax函数**，可以帮助我们理解这一点。该形式为所有 $K$ 个类别都定义了一个线性预测器 $\eta_i(\mathbf{x}) = \mathbf{x}^{\top}\beta_i$，并将概率表示为：
$$
P(Y=i \mid \mathbf{x}) = \frac{\exp(\eta_i(\mathbf{x}))}{\sum_{j=1}^{K}\exp(\eta_j(\mathbf{x}))}
$$
在这个对称形式中，如果我们给每个[线性预测](@entry_id:180569)器 $\eta_j(\mathbf{x})$ 都加上一个任意的常数或函数 $c(\mathbf{x})$，分母和分子会同乘以 $\exp(c(\mathbf{x}))$，最终的概率 $P(Y=i \mid \mathbf{x})$ 保持不变。这意味着模型的参数（即 $\beta_j$）不是唯一可确定的。为了得到唯一的[参数估计](@entry_id:139349)，我们必须施加一个约束。最常见的约束就是选择一个基线类别（例如类别 $K$）并将其线性预测器固定为零，即 $\eta_K(\mathbf{x}) \equiv 0$，这等价于设定 $\beta_K = \mathbf{0}$。施加这个约束后，softmax公式就自然地简化为我们之前推导的基线类别模型公式。

重要的是，基线的选择不会影响模型所做的预测。无论选择哪个类别作为基线，最终计算出的每个类别的概率 $P(Y=i \mid \mathbf{x})$ 都是完全相同的。改变基线只会改变系数 $\beta_i$ 的估计值和解释方式，因为它们是相对于不同参照进行度量的。

参数 $\beta_i$ 的解释直接源于模型的定义：$\exp(\beta_{ij})$（即 $\beta_i$ 中与协变量 $x_j$ 对应的系数的指数）是在其他协变量保持不变的情况下，$x_j$ 每增加一个单位，类别 $i$ 与基线类别 $K$ 发生比值的变化倍数（即几率比）。

此外，该模型结构具有一个重要的**[传递性](@entry_id:141148) (transitivity)** 特征。任意两个非基线类别 $i$ 和 $j$ 之间的对数几率可以表示为：
$$
\ln\left(\frac{P(Y=i \mid \mathbf{x})}{P(Y=j \mid \mathbf{x})}\right) = \ln\left(\frac{P(Y=i \mid \mathbf{x})/P(Y=K \mid \mathbf{x})}{P(Y=j \mid \mathbf{x})/P(Y=K \mid \mathbf{x})}\right) = \mathbf{x}^{\top}\beta_i - \mathbf{x}^{\top}\beta_j = \mathbf{x}^{\top}(\beta_i - \beta_j)
$$
这意味着任意两个类别之间的对数几率也是协变量的线性函数，其系数是各自与基线比较的系数之差。这个性质保证了模型内部的[逻辑一致性](@entry_id:637867)。例如，对于类别1、2、3，我们有 $O_{13} = O_{12} \times O_{23}$，其中 $O_{ab}$ 是类别 $a$ 相对于 $b$ 的几率。这与另一种看似合理但有缺陷的方法——为每对类别 $(i,j)$ 单独拟合一个二元逻辑回归模型——形成鲜明对比。后者由于在不同的数据子集上独立估计参数，通常无法满足传递性，可能导致逻辑上矛盾的预测结果 [@problem_id:4929773]。

**示例计算：** 假设我们对一个三分类结局（$K=3$）进行建模，以类别3为基线。对于某个体，其协变量向量为 $\mathbf{x} = \begin{pmatrix} 1 & 2 & -1 \end{pmatrix}^{\top}$（包含截距）。如果类别1相对于类别3的估计系数向量为 $\beta_1 = \begin{pmatrix} 0.3 & -0.2 & 0.5 \end{pmatrix}^{\top}$，那么该个体发生类别1相对于类别3的[对数几率](@entry_id:141427)为：
$$
\ln\left(\frac{P(Y=1 \mid \mathbf{x})}{P(Y=3 \mid \mathbf{x})}\right) = \mathbf{x}^{\top}\beta_1 = (1)(0.3) + (2)(-0.2) + (-1)(0.5) = 0.3 - 0.4 - 0.5 = -0.6000
$$
这意味着，对于这个个体，其属于类别1的几率是属于类别3的 $\exp(-0.6) \approx 0.55$ 倍 [@problem_id:4929773]。

#### 独立无关备择项 (IIA) 属性

名义逻辑[回归模型](@entry_id:163386)的一个著名且备受争议的特性是**独立无关备择项 (Independence of Irrelevant Alternatives, IIA)** 属性 [@problem_id:4929843]。从上面的推导中我们可以看到，两个类别 $i$ 和 $j$ 的概率比 $P(Y=i \mid \mathbf{x}) / P(Y=j \mid \mathbf{x})$ 仅依赖于与这两个类别相关的量，而与任何其他“无关”类别（如是否存在、其属性如何）完全无关。

从统计学角度看，IIA属性源于该模型的一个深层假设。名义逻辑回归可以从一个**随机效用模型 (Random Utility Model)** 推导出来，该模型假设个体为每个选项 $j$ 赋予一个效用 $U_j = \mathbf{x}^{\top}\beta_j + \epsilon_j$，并选择效用最高的选项。其中，$\mathbf{x}^{\top}\beta_j$ 是可观测的系统效用，$\epsilon_j$ 是不可观测的[随机误差](@entry_id:144890)项。如果假设所有误差项 $\epsilon_j$ 是相互独立且服从相同的I型[极值分布](@entry_id:174061)（[Gumbel分布](@entry_id:268317)），那么选择概率就精确地呈现为名义逻辑回归的softmax形式。误差项的**独立性**假设是IIA属性的直接来源。

从[行为学](@entry_id:145487)角度看，IIA意味着“成比例替代”模式。当一个新的选项加入选择集时，它会从所有现有选项中按其原有概率成比例地“窃取”市场份额。这在某些情况下是不符合直觉的。经典的“红蓝巴士”悖论说明了这一点：假设通勤者在“汽车”和“红色巴士”之间选择，概率各为0.5。现在，引入一个与红色巴士几乎完全相同的“蓝色巴士”。IIA属性要求“汽车”与“红色巴士”的几率比保持不变，模型会预测三者的选择概率均为1/3。但直觉上，“蓝色巴士”的引入应主要分流“红色巴士”的乘客，而对“汽车”的选择概率影响甚微。当选项间存在不同的替代性（即某些选项比其他选项更相似）时，IIA假设可能被违背。

### 有序逻辑[回归模型](@entry_id:163386)

当结局变量的 $K$ 个类别具有内在顺序时，忽略这一信息而去拟合名义逻辑[回归模型](@entry_id:163386)虽然在技术上可行，但通常会导致[统计效率](@entry_id:164796)的降低。有序模型通过利用数据的顺序结构，能以更少的参数提供更精确的估计。

#### 比例[优势模](@entry_id:263463)型 (累积Logit模型)

在有序[回归模型](@entry_id:163386)中，最常用的是**比例[优势模](@entry_id:263463)型 (Proportional Odds Model)**，也称为**累积Logit模型 (Cumulative Logit Model)**。其巧妙之处在于，它不对单个类别 $Y=k$ 的[概率建模](@entry_id:168598)，而是对**累积概率** $P(Y \le k \mid \mathbf{x})$ 建模。对于一个有 $K$ 个类别的有序变量，我们可以定义 $K-1$ 个累积切分点。模型对每个切分点 $k \in \{1, \dots, K-1\}$ 的累积几率的对数（即累积logit）进行建模：
$$
\text{logit}[P(Y \le k \mid \mathbf{x})] = \ln\left(\frac{P(Y \le k \mid \mathbf{x})}{P(Y > k \mid \mathbf{x})}\right) = \theta_k - \mathbf{x}^{\top}\beta
$$
(注意：某些软件可能使用 $\theta_k + \mathbf{x}^{\top}\beta$ 的形式，这会改变 $\beta$ 的符号解释。这里，正的 $\beta$ 意味着协变量值的增加与更高的结局类别相关联)。

这个模型有两个关键组成部分 [@problem_id:4929770]：
1.  **截距/切点 (Intercepts/Cutpoints) $\theta_k$**：每个累积切分点 $k$ 都有一个自己专属的截距项 $\theta_k$。为了保证模型在概率上是一致的（即 $P(Y \le 1) \le P(Y \le 2) \dots$），这些截距必须是严格有序的：$\theta_1 < \theta_2 < \dots < \theta_{K-1}$。
2.  **共同斜率 (Common Slope) $\beta$**：所有 $K-1$ 个累积logit方程共享同一个斜率向量 $\beta$。这是该模型的核心，即**比例优势假设**。它意味着协变量 $\mathbf{x}$ 对累积[对数几率](@entry_id:141427)的影响在所有切分点上都是相同的。

这种结构也常被称为**[平行线](@entry_id:169007)模型 (parallel lines model)**。如果我们绘制任何一个协变量 $x_j$ 与累积对数几率的关系图，我们会得到一组斜率均为 $-\beta_j$ 的[平行线](@entry_id:169007)，每条线对应一个切分点 $k$，其截距不同 [@problem_id:4976130]。

比例优势假设极大地简化了模型，并带来了清晰的参数解释 [@problem_id:4929862] [@problem_id:4976130]。考虑协变量 $x_j$ 增加一个单位（其他协变量不变）对累积几率比的影响。对于任意切分点 $k$，对数几率比为：
$$
\log(\text{OR}_k) = (\theta_k - (\dots + \beta_j(x_j+1) + \dots)) - (\theta_k - (\dots + \beta_j x_j + \dots)) = -\beta_j
$$
取指数后得到几率比 (OR)：
$$
\text{OR}_k = \exp(-\beta_j)
$$
（若模型形式为 $\theta_k + \mathbf{x}^{\top}\beta$，则OR为 $\exp(\beta_j)$）。关键在于，这个几率比不依赖于切分点 $k$。因此，系数 $\beta_j$ 有一个统一的解释：$\exp(-\beta_j)$ 是协变量 $x_j$ 每增加一个单位，结局类别**更低**（即 $Y \le k$）对比**更高**（即 $Y > k$）的共同几率比，这个几率比对于所有的 $k$ 都是相同的。这一解释的有效性完全取决于比例优势假设是否成立、结局类别是否有序以及模型是否使用了logit链接 [@problem_id:4929862]。

#### 其他有序模型：邻接类别与连续比

比例[优势模](@entry_id:263463)型虽然常用，但并非唯一的有序回归模型。根据[对数几率](@entry_id:141427)构建方式的不同，还存在其他模型，其参数 $\beta$ 的解释也随之改变 [@problem_id:4929839]。

1.  **邻接类别Logit模型 (Adjacent-Category Logit Model)**：此[模型比较](@entry_id:266577)相邻两个类别的对数几率：
    $$
    \ln\left(\frac{P(Y=j \mid \mathbf{x})}{P(Y=j+1 \mid \mathbf{x})}\right) = \alpha_j + \beta \mathbf{x}
    $$
    在这里，$\exp(\beta)$ 的解释变为：协变量每增加一个单位，结局为类别 $j$ 相对于类别 $j+1$ 的共同几率比。这个几率比与累积几率比在数学上是不同的。

2.  **连续比Logit模型 (Continuation-Ratio Logit Model)**：此模型对条件概率建模，即在已知结局至少为 $j$ 的情况下，“停在”类别 $j$ 与“继续到”更高类别的[对数几率](@entry_id:141427)：
    $$
    \ln\left(\frac{P(Y=j \mid Y \ge j, \mathbf{x})}{P(Y>j \mid Y \ge j, \mathbf{x})}\right) = \ln\left(\frac{P(Y=j \mid \mathbf{x})}{P(Y>j \mid \mathbf{x})}\right) = \alpha_j + \beta \mathbf{x}
    $$
    此时，$\exp(\beta)$ 表示协变量每增加一个单位，在达到至少类别 $j$ 的个体中，结局为 $j$ 相对于大于 $j$ 的共同几率比。

这三种模型对 $\beta$ 的解释截然不同，凸显了在解释有序回归结果时，准确理解所用模型具体形式的重要性。

### [模型选择](@entry_id:155601)的权衡：有序性假设的意义

既然存在专门的有序模型，那么当结局为有序时，是否总应使用它们？如果使用了更灵活但忽略顺序的名义模型，会发生什么？这涉及到统计建模中经典的**偏倚-方差权衡 (bias-variance trade-off)** [@problem_id:4929859]。

**情景1：比例优势假设成立**

如果数据的真实生成过程确实遵循比例优势假设（即协变量对所有累积对数几率的影响是恒定的），那么：
*   **比例[优势模](@entry_id:263463)型**是正确指定的、最简约的模型。它通过“汇集”来自所有 $K-1$ 个切分点的信息来估计一个共同的斜率 $\beta$，从而实现最高的[统计效率](@entry_id:164796)。其参数估计的[标准误](@entry_id:635378)最小。
*   **名义逻辑[回归模型](@entry_id:163386)**虽然也是一致的（因为它更通用，包含了比例[优势模](@entry_id:263463)型作为特例），但它会估计 $K-1$ 个独立的斜率参数。这种做法没有利用到斜率相等的真实信息，因此是低效的。它会“浪费”样本信息去估计本不必要的参数，导致参数估计的标准误增大，降低了检验效力 [@problem_id:4929859]。

**情景2：比例优势假设不成立**

如果协变量的真实影响随类别阈值而变化（例如，某个药物只对预防重症有效，而对预防轻症无效），那么比例优势假设被违背。此时：
*   **比例[优势模](@entry_id:263463)型**是**错误指定**的。它强加了一个不符合事实的“共同斜率”约束。因此，它对 $\beta$ 的估计将是**有偏的**，它会得到一个真实变化的效应的某种“平均值”。
*   **名义逻辑[回归模型](@entry_id:163386)**由于其灵活性，能够估计出每个类别特定的效应，从而得到对真实效应的（渐进）无偏估计。虽然名义模型通常方差更大，但它避免了比例[优势模](@entry_id:263463)型的设定偏倚。

在这种情况下，我们必须权衡偏倚和方差。一个有偏但方差小的估计量（来自比例[优势模](@entry_id:263463)型）与一个无偏但方差大的估计量（来自名义模型）相比，哪个更好？这通常通过比较**均方误差 (Mean Squared Error, MSE)** 来判断，其中 $MSE = \text{Variance} + (\text{Bias})^2$。当比例优势假设的违背很严重时，比例[优势模](@entry_id:263463)型的偏倚会非常大，导致其MSE可能远大于更灵活的名义模型。因此，通过拟合名义模型来“忽略”有序性，有时反而能通过消除偏倚来获得更准确的效应估计 [@problem_id:4929859]。

总之，[模型选择](@entry_id:155601)并非一成不变。比例[优势模](@entry_id:263463)型在假设成立时更强大、更精确。而名义模型则更稳健，能应对比例优势假设不成立的情况，但代价是参数更多、效率可能更低。在实践中，检验比例优势假设（例如使用Bran[t检验](@entry_id:272234)）是决定采用哪种策略的关键一步。