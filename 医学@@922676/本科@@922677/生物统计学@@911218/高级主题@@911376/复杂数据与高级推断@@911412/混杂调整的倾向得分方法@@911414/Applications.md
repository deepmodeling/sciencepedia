## 应用与跨学科联系

在前面的章节中，我们已经详细阐述了倾向性评分（Propensity Score, PS）方法的理论基础、核心原理与机制。我们理解到，倾向性评分作为一种在给定协变量条件下接受特定处理的概率，其关键的平衡属性使得我们能够在[观察性研究](@entry_id:174507)中模拟随机对照试验（RCT）的核心特征，从而控制混杂偏倚。然而，理论的价值最终体现在其应用之中。本章的使命是超越理论的抽象层面，通过一系列源于真实世界研究问题的应用场景，展示倾向性评分方法如何在生物统计学、流行病学、临床医学、公共卫生乃至数据科学等多个领域中发挥其强大的作用。

本章我们并非要重复讲解倾向性评分的基本概念，而是要深入探讨这些核心原理如何被扩展、应用和整合，以应对更加复杂和细致的科学问题。我们将探索从研究设计之初的概念辨析，到模型构建、方法选择、诊断与敏感性分析的完整工作流程。此外，我们还将考察倾向性评分方法如何被推广应用于多种处理、纵向数据、生存分析等复杂数据结构，以及如何适应不同的研究设计（如病例-对照研究）和研究目标（如结果的可推广性）。通过本章的学习，读者将能够深刻理解倾向性评分不仅是一种统计技术，更是一个灵活且强大的因果推断思维框架。

### 观察性研究中的核心应用流程

在任何严谨的观察性研究中，应用倾向性评分方法都遵循一个系统性的工作流程。这个流程始于对研究问题的精确界定，终于对结果稳健性的审慎评估。

#### 界定因果问题：区分混杂与选择偏倚

在应用任何调整方法之前，首要任务是清晰地界定所要解决的偏倚类型。在临床研究中，两种常见的偏倚是**指示混杂 (confounding by indication)** 和**选择偏倚 (selection bias)**。指示混杂是[观察性研究](@entry_id:174507)的内生挑战，它指的是临床医生会根据患者的预后信息（即指示）来决定治疗方案。例如，在比较一种新型抗凝药与标准疗法的研究中，病情更严重的患者可能更倾向于被给予新型药物。这样，治疗组和[对照组](@entry_id:188599)在基线时的潜在结局分布就存在系统性差异，即不满足[交换性](@entry_id:140240)。倾向性评分方法的核心目标正是通过对这些影响治疗决策的基线预后因素（即[混杂变量](@entry_id:199777) $X$）进行调整，来实现条件[交换性](@entry_id:140240)，即 $(Y(0), Y(1)) \perp A \mid X$。

然而，倾向性评分方法通常无法直接解决选择偏倚。选择偏倚源于研究样本的纳入过程。例如，如果研究只纳入了在治疗后完成随访的患者，而随访行为本身又同时受到治疗（如药物副作用）和结局（如病情恶化）的影响，那么在已纳入的样本上进行分析就会引入偏倚。即使对基线[混杂变量](@entry_id:199777) $X$ 进行了完美调整，这种由样本选择过程引入的偏倚依然存在。解决这类偏倚需要更复杂的方法，如对选择过程进行建模并应用逆选择概率加权（Inverse Probability of Selection Weighting, IPSW）。因此，研究者必须首先厘清研究中的主要偏倚来源，以确保选择了正确的分析策略 [@problem_id:4830539]。

一个经典的指示混杂例子是关于足月单胎臀位分娩方式的研究。原始数据显示，计划性剖宫产组的新生儿严重发病风险高于计划性阴道分娩组。然而，这是因为临床医生倾向于为具有高危特征（如胎儿过小、胎头过度仰伸）的产妇选择剖宫产。这些高危特征本身就是新生儿不良结局的强预测因子。当按“高危”和“低危”进行分层后，在每个亚组内，计划性剖宫产的风险实际上都更低。这种效应方向的反转，即辛普森悖论（Simpson's paradox），正是指示混杂的直接体现。通过分层或更复杂的倾向性评分方法（如匹配或加权）进行调整，可以消除这种混杂，从而得到一个更接近真实因果效应的估计 [@problem_id:4408686]。

#### 倾向性评分的建模与估计

倾向性评分本身是一个[条件概率](@entry_id:151013)，需要通过[统计模型](@entry_id:755400)从数据中估计得出。最常用的模型是逻辑斯蒂回归（logistic regression），其中二元治疗变量 $A$ 作为结局，一系列基线协变量 $X$ 作为预测变量。该模型的建立基于最大似然估计（Maximum Likelihood Estimation, MLE）原理。通过构建关于治疗分配的伯努利分布[似然函数](@entry_id:141927)，并对其对数形式求导，可以得到分数方程（score equations）。求解该方程组即可得到模型参数 $\boldsymbol{\beta}$ 的估计值，进而计算出每个个体的倾向性评分 $\hat{e}(\mathbf{X})$ [@problem_id:4943106]。

在构建倾向性评分模型时，一个至关重要的原则是：**模型中只能包含治疗前的基线协变量**。纳入治疗后测量的变量，即使它们能极大地提高对治疗分配的预测准确性，也可能引入严重偏倚。例如，在评估围产期抗抑郁药使用的研究中，如果在倾向性评分模型中纳入了治疗后测量的孕中期情绪评分或用药依从性，这些变量可能是治疗与结局之间的中介变量或碰撞变量（collider），对它们进行调整会阻断部分因果路径或引入新的偏倚。因此，正确的做法是仅使用治疗决策前可获得的变量，如基线抑郁严重程度、既往病史、社会经济状况等，来构建[倾向分数](@entry_id:635864)模型 [@problem_id:4738455]。

#### 实施调整策略与选择目标估计量

估计出倾向性评分后，研究者可以通过多种方式来利用它控制混杂，主要包括匹配（matching）、分层（stratification）和[逆概率](@entry_id:196307)加权（Inverse Probability Weighting, IPW）。

**倾向性评分匹配（PSM）** 旨在为每个接受治疗的个体（处理组）从不接受治疗的个体（[对照组](@entry_id:188599)）中找到一个或多个具有相似倾向性评分的“反事实副本”。一种常见的策略是**最近邻匹配（nearest neighbor matching）**。为了提高匹配质量，实践中通常在倾向性评分的**logit转换**（即 $\ln(\frac{e(\mathbf{X})}{1-e(\mathbf{X})})$）上进行匹配，而非原始评分。这是因为原始评分在接近 $0$ 或 $1$ 的区域会被压缩，导致评分数值上很小的差异可能对应着协变量分布上很大的不同，而 logit 转换后的尺度更为均匀。此外，研究者常会设定一个**卡尺（caliper）**，即允许的最大倾向性评分（或其logit）差异，以避免将特征差异过大的个体匹配在一起，从而减少残余偏倚 [@problem_id:4943113]。

不同的调整策略可能对应着不同的**目标估计量（estimand）**。
- **平均治疗效应（Average Treatment Effect, ATE）**，即 $E[Y(1) - Y(0)]$，衡量的是在整个目标人群中，如果每个人都接受治疗与每个人都不接受治疗相比，结局的平均差异。
- **处理组平均治疗效应（Average Treatment Effect on the Treated, ATT）**，即 $E[Y(1) - Y(0) \mid A=1]$，衡量的是在那些实际接受了治疗的人群中，治疗所带来的平均效应。

方法的选择会影响目标估计量：
- **IPW** 通过为每个个体赋予其接受所观察到治疗的概率的倒数作为权重，创建一个协变量分布与治疗分配无关的伪人群。该方法通常旨在估计**ATE**。
- **PSM**，特别是当以处理组为基准进行匹配时（即为每个处理组个体寻找对照），其创建的[对照组](@entry_id:188599)在协变量分布上模仿了处理组。因此，这种方法自然地估计了**ATT**。
- **倾向性评分分层** 将个体按倾向性评分的五[分位数](@entry_id:178417)或十[分位数](@entry_id:178417)分为若干层，在层内比较结局，然后汇总各层效应。如果汇总时根据各层在总样本中的比例加权，则近似于**ATE**；如果根据各层在处理组中的比例加权，则近似于**ATT**。

在实践中，这些方法的稳健性也不同。IPW直接使用倾向性评分的数值，因此对极端权重（即倾向性评分接近 $0$ 或 $1$）非常敏感，对模型的精确设定要求较高。相比之下，匹配和分层在一定程度上只依赖于倾向性评分的排序性质，对模型的轻度错误设定通常具有更强的稳健性 [@problem_id:5001924]。

#### 关键诊断与敏感性分析

成功应用倾向性评分方法的最后一步，也是最关键的一步，是进行严格的诊断检查和[敏感性分析](@entry_id:147555)。**调整的效果绝不能通过观察调整后的结局来判断**，这样做会引入循[环论](@entry_id:143825)证，使所有推断失效。评估倾向性评分模型的充分性，必须在不接触结局数据的情况下完成。

- **[模型诊断](@entry_id:136895)**：核心诊断包括：
    1.  **重叠性（Overlap）或正性（Positivity）检查**：通过绘制处理组和[对照组](@entry_id:188599)倾向性评分的分布图（如[直方图](@entry_id:178776)或密度图），检查两组间是否存在足够的重叠区域。如果某个协变量组合的个体几乎全部在处理组（或[对照组](@entry_id:188599)），则倾向性评分会趋近于 $1$（或 $0$），导致权重极端化或无法匹配，违反了正性假设。
    2.  **协变量平衡性检查**：这是最重要的诊断步骤。通过计算调整前后各协变量在处理组和[对照组](@entry_id:188599)间的**标准化均数差（Standardized Mean Difference, SMD）**，来量化平衡改善的程度。通常认为，调整后SMD的绝对值小于 $0.1$ 表示协变量达到了良好的平衡。
    3.  **校准度（Calibration）检查**：通过比较倾向性评分模型预测的治疗概率与在评分分层中观察到的实际治疗比例，可以评估模型的拟合优度。一个校准良好的模型，其预测值与观测值应接近于一条 $45$ 度线。

一个常见的误区是追求倾向性评分模型的最高预测能力（例如，最高的ROC曲线下面积，AUC）。事实上，一个极高的AUC（如 $0.90$ 以上）通常是重叠性差的危险信号，意味着两组人群基线特征差异巨大，难以进行有效比较。倾向性评分的目标是**平衡协变量**，而非**预测治疗** [@problem_id:4548969]。

- **对未测混杂的敏感性分析**：由于倾向性评分只能调整已测量的混杂因素，因此评估结果对潜在的未测混杂的稳健性至关重要。
    1.  **阴性对照（Negative Controls）**：这是一种强大的诊断工具，通过检验已知无因果关系的“暴露-结局”对，来探测残余混杂。例如，我们可以使用一个**阴性对照结局**，即一个已知不受研究暴露影响的结局。如果在对协变量进行倾向性评分调整后，暴露与该阴性对照结局之间仍然存在关联，这强烈暗示了存在未测混杂。同样，我们也可以使用一个**阴性对照暴露**，即一个已知不影响研究结局的暴露。如果在调整协变量后，该阴性对照暴露与研究结局存在关联，也说明可能存在残余混杂。这种方法的有效性取决于阴性对照变量与主要研究变量共享相似的混杂结构 [@problem_id:5221131]。
    2.  **E-值（E-value）**：E-值是一种量化[敏感性分析](@entry_id:147555)的方法。它计算的是，一个未测混杂因素需要同时与暴露和结局都具有多强的关联（以风险比 RR 衡量），才能将观察到的效应完全“解释掉”（即让真实效应变为无效）。例如，对于一个观察到的风险比为 $1.45$，计算出的E值为 $2.26$，这意味着一个未测混杂因素需要与暴露和结局的关联强度（风险比）都至少达到 $2.26$ 倍，才可能将观察到的关联完全归因于混杂。E-值为我们评估观察到的关联在多大程度上对未测混杂具有稳健性提供了一个具体的量化指标 [@problem_id:4943084]。

### 扩展到高级应用场景与[数据结构](@entry_id:262134)

倾向性评分方法的思想框架具有高度的灵活性，可以被扩展以应对更为复杂的[数据结构](@entry_id:262134)和研究问题。

#### 多处理组比较

当研究涉及两个以上的治疗组（例如，比较药物A、药物B和安慰剂）时，二元的倾向性评分概念可以推广为**多项式倾向性评分（multinomial propensity score）**。此时，每个个体将拥有一个倾向性评分向量 $\mathbf{e}(\mathbf{X}) = (e_1(\mathbf{X}), \dots, e_K(\mathbf{X}))$，其中 $e_k(\mathbf{X}) = P(A=k \mid \mathbf{X})$ 是接受第 $k$ 种治疗的条件概率。这个向量整体构成了平衡分数，即在给定 $\mathbf{e}(\mathbf{X})$ 的条件下，协变量 $\mathbf{X}$ 的分布在所有 $K$ 个治疗组中是平衡的。基于此，IPW方法可以直接推广，通过使用权重 $w_i = 1/e_{A_i}(\mathbf{X}_i)$ 来创建一个所有治疗组协变量分布都与总人群一致的伪人群。此外，也可以进行两两比较。例如，在比较处理 $k$ 和处理 $l$ 时，可以在仅包含这两组人群的子集中，构建一个新的二元倾向性评分 $P(A=k \mid A \in \{k,l\}, \mathbf{X}) = \frac{e_k(\mathbf{X})}{e_k(\mathbf{X}) + e_l(\mathbf{X})}$，然后应用标准的二元倾向性评分方法 [@problem_id:4943107]。

#### 纵向数据与时依性混杂

在纵向研究中，患者的治疗和协变量状态可能随时间变化。一个特别棘手的挑战是**时依性混杂（time-varying confounding）**，即一个变量既是过去治疗的结局，又是未来治疗的预测因子（混杂因素）。例如，在HIV研究中，病毒载量既受上一阶段抗病毒治疗的影响，又会影响医生在下一阶段是否调整治疗方案。对这种同时作为中介变量和混杂因素的变量进行常规调整会引入偏倚。

**边际结构模型（Marginal Structural Models, MSMs）** 是一种专门用于处理此类问题的先进方法，而其核心技术正是基于倾向性评分的**时依性逆概率加权（time-varying IPTW）**。其思路是，在每个时间点 $t$，根据患者截至该时间点的完整协变量和治疗史，计算其接受当前治疗 $A_t$ 的概率。然后，通过将每个时间点的[逆概率](@entry_id:196307)连乘，为每个患者计算一个随时间累积的权重。为了提高稳定性，实践中通常使用**稳定化权重（stabilized weights）**，其分子是基于简化的（如仅包含基线变量或过去治疗史）历史计算的治疗概率，分母则是基于完整历史计算的概率。通过这些权重，MSMs可以有效地创建一个伪人群，其中时依性混杂路径被切断，从而能够无偏地估计特定治疗策略（如“始终治疗”vs.“永不治疗”）的边际因果效应 [@problem_id:4943110]。

#### [生存数据分析](@entry_id:190868)

当结局是事件发生时间（如死亡或疾病复发）时，数据常会存在删失（censoring）。倾向性评分方法可以与生存分析技术无缝结合。具体而言，IPW可以用来创建一个伪人群，在这个人群中，处理组和[对照组](@entry_id:188599)的基线协变量分布是平衡的。然后，可以在这个加权的伪人群上应用标准的生存分析方法。例如，**[逆概率](@entry_id:196307)加权Kaplan-Meier估计**通过在计算每个事件时间点的风险集和事件数时，对个体进行加权，从而估计出不同治疗策略下的边际生存曲线。这种方法在控制基线混杂的同时，保留了对整个生存时间过程的描述。需要注意的是，这种方法本身不处理信息性删失，其有效性依赖于在给定协变量的条件下删失与事件时间相互独立的假设 [@problem_id:4943079]。

#### 大数据与药物流行病学

在利用大型管理数据库（如电子病历或医保理赔数据）进行的药物流行病学研究中，研究者面临着成千上万个潜在的[混杂变量](@entry_id:199777)（如诊断编码、用药记录、操作编码）。传统的[变量选择方法](@entry_id:756429)在这种高维场景下可能力不从心。**高维倾向性评分（High-dimensional Propensity Score, hdPS）** 是一种算法驱动的策略，旨在经验性地从海量数据中筛选出与治疗和结局都相关的变量作为代理混杂因素，从而更全面地控制混杂。其优势在于能够捕捉到传统方法可能忽略的复杂混杂模式。然而，hdPS也存在局限性。例如，纳入过多仅与治疗强相关但与结局无关的变量（所谓的“工具变量”）可能会放大权重差异，增加估计的方差，甚至在存在未测混杂时加剧偏倚。因此，在使用hdPS时，仍需进行严格的平衡性诊断和对极端权重的处理 [@problem_id:4620082]。

### 在不同研究设计与目标中的应用

倾向性评分的原理不仅限于标准的前瞻性队列研究，还能巧妙地应用于其他研究设计和更广泛的因果推断目标。

#### 病例-对照研究中的应用

在病例-对照研究中，研究对象是根据其最终的疾病状态（结局）进行抽样的。这种**依结局抽样**的设计导致在样本中直接估计的倾向性评分 $P(A=1 \mid X, \text{在样本中})$ 并不等于目标人群中的真实倾向性评分 $P(A=1 \mid X)$。直接在病例-对照样本上拟合倾向性评分模型会得到有偏的估计。

有几种策略可以解决这个问题：
1.  **逆抽样概率加权（IPSW）**：如果病例和对照在源人群中的抽样比例已知，可以先通过对每个个体赋予其抽样概率的倒数作为权重，将病例-对照样本“还原”成一个近似的源人群队列，然后再在这个加权样本上估计倾向性评分。
2.  **仅使用[对照组](@entry_id:188599)估计**：在“罕见病假设”下，源人群中[对照组](@entry_id:188599)（$Y=0$）的协变量分布近似于整个源人群的协变量分布。因此，在病例-对照研究的[对照组](@entry_id:188599)中估计的 $P(A=1 \mid X, Y=0)$ 可以作为对真实倾向性评分 $P(A=1 \mid X)$ 的一个良好近似。
这两种方法都允许研究者在病例-对照设计中有效地利用倾向性评分来控制混杂 [@problem_id:4943119]。

#### 效应的可推广性与可输送性

一项研究（如RCT）得出的因果效应是否能推广到我们感兴趣的某个特定目标人群？这是一个关于**可推广性（generalizability）**或**可输送性（transportability）** 的问题。当研究样本（如RCT入组人群）与目标人群在影响治疗效果的基线特征上存在差异时，直接应用研究结果可能会产生误导。

与倾向性评分思想类似，我们可以通过加权来解决这个问题。此时，我们构建一个“抽样评分” $s(X) = P(S=1 \mid X)$，即具有协变量 $X$ 的个体被纳入研究样本（$S=1$）的概率。通过为研究样本中的每个个体赋予权重 $w(X) \propto \frac{P(S=0 \mid X)}{P(S=1 \mid X)}$，我们可以创建一个在协变量分布上与目标人群（$S=0$）一致的伪人群。然后，在这个加权的伪人群上估计的治疗效应，就是在满足一定可交换性假设（即在给定协变量 $X$ 的条件下，潜在结局与是否被抽样无关）的前提下，对目标人群因果效应的有效估计。这个框架使得我们可以将从一个（可能是高度选择性的）研究中获得的因果知识，严谨地“输送”到另一个更具代表性或更重要的目标人群中去 [@problem_id:4943094]。

### 结论

本章通过一系列跨学科的应用案例，系统地展示了倾向性评分方法的广度和深度。从处理临床研究中最常见的指示混杂，到应对时依性混杂、多处理组、复杂数据结构等高级挑战，再到适应不同研究设计和实现结果的外部推广，倾向性评分都提供了一个统一且强大的概念与分析框架。它不仅仅是一套技术操作，更是一种促使研究者在设计、分析和解释[观察性研究](@entry_id:174507)时进行严谨因果思考的催化剂。深刻理解并熟练运用这些应用与扩展，是每一位致力于从观察数据中探寻因果关系的研究者的必备技能。