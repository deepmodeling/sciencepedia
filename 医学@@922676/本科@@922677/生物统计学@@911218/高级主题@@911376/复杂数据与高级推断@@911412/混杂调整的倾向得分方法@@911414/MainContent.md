## 引言
在生物统计学和流行病学等领域，从观测数据中推断因果关系是核心目标，但也面临着巨大挑战。与处理分配随机化的临床试验不同，观测性研究中的处理组和[对照组](@entry_id:188599)往往因“指示混杂”等因素而缺乏可比性，直接比较其结局会产生误导性的结论。这正是倾向性评分（Propensity Score）方法旨在解决的核心知识缺口：如何在非随机化的数据中，科学地调整混杂因素，以获得更可靠的因果效应估计？

本文将系统性地引导您掌握这一强大工具。在“原理与机制”一章中，我们将深入因果推断的潜在结局框架，阐明倾向性评分的理论基础、关键假设和平衡性质。接着，在“应用与跨学科联系”一章中，我们将展示如何通过匹配、分层和加权等方法在真实世界研究中应用倾向性评分，并探讨其在处理多处理组、时依性混杂及[生存数据](@entry_id:165675)等复杂场景下的扩展。最后，“动手实践”一章将通过编程练习，让您将理论知识转化为实际分析能力。

通过本系列的学习，您将能够自信地在自己的研究中应用倾向性评分方法来控制混杂。现在，让我们从理解其根本原理与核心机制开始。

## 原理与机制

在观测性研究中，推断处理（treatment）与结局（outcome）之间的因果关系面临一个核心挑战：**混杂（confounding）**。与处理组和[对照组](@entry_id:188599)由随机分配构成的随机对照试验（RCTs）不同，观测性研究中的这两个组在接受处理之前可能就存在系统性差异。这些差异，如果同时与处理选择和研究结局相关，就会成为混杂因素，扭曲我们对[处理效应](@entry_id:636010)的真实估计。倾向性评分（propensity score）方法是现代流行病学和生物统计学中用于解决混杂问题的强大工具。本章将深入探讨倾向性评分方法的根本原理与核心机制，从因果推断的基本概念出发，系统阐述其理论基础、关键假设、实施方法及诊断评估。

### 因果推断与混杂的潜在结局框架

为了精确地定义和理解混杂，我们首先需要引入**潜在结局（potential outcomes）**框架，这也被称为Rubin因果模型（Rubin Causal Model）。考虑一个二元处理，用 $A$ 表示，其中 $A=1$ 代表接受处理，$A=0$ 代表接受对照。对于每一个研究个体 $i$，我们设想存在两个潜在结局：$Y_i(1)$，表示该个体如果接受处理（$A=1$）将会观察到的结局；以及 $Y_i(0)$，表示该同一个体如果接受对照（$A=0$）将会观察到的结局。个体层面的因果效应（individual causal effect）即为 $Y_i(1) - Y_i(0)$。然而，在现实中，我们永远无法同时观测到同一个人的这两个潜在结局，这个问题被称为“因果推断的根本问题”。因此，我们的目标通常是估计群体层面的平均因果效应（Average Treatment Effect, ATE），即 $E[Y(1) - Y(0)]$。

在理想的随机对照试验中，处理分配 $A$ 是完全随机的，这意味着它独立于任何个体特征，包括其潜在结局。这种独立性，记为 $(Y(1), Y(0)) \perp A$，保证了处理组和[对照组](@entry_id:188599)在所有基线特征上是（在期望上）可比的。因此，观察到的结局均值之差 $E[Y \mid A=1] - E[Y \mid A=0]$ 可以无偏地估计ATE。

然而，在观测性研究中，处理分配通常不是随机的。个体接受何种处理可能取决于其基线特征。例如，病情更严重的患者可能更有可能接受一种新的、有风险但可能更有效的治疗。在这种情况下，处理分配 $A$ 与潜在结局 $Y(a)$ 不再独立。这种非独立性，即 $Y(a) \not\perp A$，就是**混杂**的正式定义 [@problem_id:4943089]。它意味着处理组和[对照组](@entry_id:188599)在接受处理前就已存在差异，而这些差异本身就会影响结局，导致观察到的结局差异并不能真实反映处理的因果效应。

为了将我们观察到的数据与潜在结局联系起来，还需要两个基本假设 [@problem_id:4943091]：

1.  **稳定单位处理价值假设（Stable Unit Treatment Value Assumption, SUTVA）**：此假设包含两个方面。其一，**无干扰（no interference）**，即一个个体的潜在结局不受其他个体所接受的处理的影响。其二，**处理变异一致性（no hidden variations of treatment）**，即对于任何处理水平 $a$，其对应的潜在结局 $Y(a)$ 都是唯一的，不存在不同版本的处理方式导致不同结局的情况。SUTVA确保了每个个体的潜在结局 $Y_i(1)$ 和 $Y_i(0)$ 都是明确定义的。

2.  **一致性（Consistency）**：此假设将潜在结局与观测结局联系起来。它指出，一个个体实际观察到的结局，是在其所接受的处理水平下的潜在结局。形式上，如果个体 $i$ 接受的处理是 $A_i=a$，那么其观察结局 $Y_i$ 就等于 $Y_i(a)$。这个假设使得我们能利用观测数据对潜在结局的分布进行学习。

SUTVA和一致性是所有因果推断方法的基石，包括倾向性评分方法。它们保证了我们所要估计的因果量（如ATE）是有意义的，并且我们收集的观测数据与这些因果量相关。

### 通过条件化控制混杂

既然混杂源于处理组和[对照组](@entry_id:188599)的不可比性，一个直观的想法是：如果我们能够识别并测量出所有造成这种不可比性的共同原因，即**混杂因素（confounders）**，我们或许可以通过在这些因素的相同水平内进行比较来消除混杂。

这个想法被形式化为**条件可交换性（Conditional Exchangeability）**或称**无混杂（unconfoundedness / ignobility）**假设。该假设指出，在给定一组足够充分的基线协变量 $\mathbf{X}$ 的条件下，处理分配 $A$ 与潜在结局 $(Y(1), Y(0))$ 是独立的。形式上记为：

$(Y(1), Y(0)) \perp A \mid \mathbf{X}$

这个假设意味着，在协变量 $\mathbf{X}$ 取值相同的个体组成的亚组（stratum）内，处理分配是“仿佛”随机的。因此，在每个亚组内，我们可以直接比较处理组和[对照组](@entry_id:188599)的结局来估计该亚组的因果效应。然后，通过对所有亚组的效应进行加权平均，就可以得到总体的因果效应。

#### 协[变量选择](@entry_id:177971)的原则

要使条件可交换性假设成立，选择一个“足够充分”的协变量集合 $\mathbf{X}$ 至关重要。利用**有向无环图（Directed Acyclic Graphs, DAGs）**可以清晰地指导我们进行协变量选择 [@problem_id:4943072]。基本原则是，所选的协变量集 $\mathbf{X}$ 必须能够阻断（block）所有从处理 $A$ 到结局 $Y$ 的“后门路径（backdoor paths）”。后门路径是指一条连接 $A$ 和 $Y$ 但起始于一个指向 $A$ 的箭头的路径，它代表了混杂的来源。

根据这一原则，协变量选择的策略如下：

*   **必须纳入**：所有同时影响处理选择和结局的**[共同原因](@entry_id:266381)（confounders）**，以及这些不可测量的[共同原因](@entry_id:266381)的**代理变量（proxies）**。例如，在药物研究中，疾病严重程度（$C$）既影响医生开具新药（$A$）的决策，也直接影响患者的生存结局（$Y$），因此必须纳入模型。
*   **建议纳入**：只影响结局但不影响处理的变量。这类变量虽然不是混杂因素，但将其纳入模型可以提高因果效应估计的精度。
*   **必须排除**：
    *   **中介变量（mediators）**：位于从 $A$ 到 $Y$ 的因果路径上的变量（$A \rightarrow M \rightarrow Y$）。调整中介变量会阻断部分我们想要研究的因果效应，导致我们估计的是直接效应而非总效应。
    *   **对撞因子（colliders）**：一个变量如果同时被处理 $A$ 和另一个影响结局 $Y$ 的因素所影响（例如 $A \rightarrow L \leftarrow U \rightarrow Y$），那么它就是对撞因子。在分析中调整（即“条件化于”）对撞因子，会人为地在 $A$ 和 $Y$ 之间引入虚假的关联，导致**[对撞偏倚](@entry_id:163186)（collider bias）**。
    *   任何**受处理影响的变量**（post-treatment variables）都应被排除，因为它们可能是中介变量或对撞因子。所有用于调整的协变量都必须是在处理发生前测量的。
*   **可以排除**：**工具变量（instruments）**，即只影响处理选择而不通过其他途径影响结局的变量。虽然将其纳入倾向性评分模型通常不会引入偏倚，但可能会因为造成某些个体接受处理的概率接近0或1而破坏可比性（违反“正性”假设），并可能放大由未测混杂因素引起的残余偏倚。

### 倾向性评分：理论与性质

当协变量向量 $\mathbf{X}$ 的维度很高时，通过对 $\mathbf{X}$ 的所有可能组合进行分层或匹配变得不可行，这就是所谓的“[维数灾难](@entry_id:143920)”。**倾向性评分（Propensity Score）**正是为了解决这一问题而提出的。

倾向性评分 $e(\mathbf{X})$ 定义为在给定基线协变量 $\mathbf{X}$ 的条件下，个体接受处理（$A=1$）的[条件概率](@entry_id:151013)：

$e(\mathbf{X}) = P(A=1 \mid \mathbf{X})$

倾向性评分有两个至关重要的性质，使其成为控制混杂的有力工具：

1.  **平衡性质（Balancing Property）**：在倾向性评分 $e(\mathbf{X})$ 取值相同的个体中，处理分配 $A$ 与基线协变量 $\mathbf{X}$ 是相互独立的。形式上，$\mathbf{X} \perp A \mid e(\mathbf{X})$。这意味着，在倾向性评分相同的亚组内，处理组和[对照组](@entry_id:188599)的基线协变量分布是相同的。因此，倾向性评分作为一个单一维度的变量，可以像“天平”一样平衡所有被纳入其计算的协变量。任何满足此性质的函数 $b(\mathbf{X})$ 都被称为**平衡分数（balancing score）** [@problem_id:4943085]。

2.  **充分性（Sufficiency）**：如果条件[可交换性](@entry_id:263314)在给定 $\mathbf{X}$ 时成立（即 $(Y(1), Y(0)) \perp A \mid \mathbf{X}$），那么它在给定倾向性评分 $e(\mathbf{X})$ 时也同样成立（即 $(Y(1), Y(0)) \perp A \mid e(\mathbf{X})$）。这个性质是革命性的，因为它表明，为了控制由高维协变量 $\mathbf{X}$ 引起的混杂，我们不必对 $\mathbf{X}$ 本身进行调整，而只需对一维的标量——倾向性评分——进行调整即可 [@problem_id:4943089] [@problem_id:4515359]。

此外，值得注意的是，任何对倾向性评分的[一对一变换](@entry_id:148028)（例如，常用的[logit变换](@entry_id:272173) $\ln(\frac{e(\mathbf{X})}{1-e(\mathbf{X})})$）也同样是一个平衡分数，并保留了充分性。这是因为[一对一变换](@entry_id:148028)没有丢失任何信息，条件化于变换后的分数等价于条件化于原始分数 [@problem_id:4943085]。

### 关键假设：正性（Positivity）

除了SUTVA、一致性和条件可交换性，倾向性评分方法还依赖于第四个关键假设：**正性（Positivity）**，或称**重叠（Overlap）**。该假设要求，对于任何一个具有特定协变量组合 $\mathbf{X}$ 的个体，其接受处理或接受对照的概率都必须严格大于0且小于1。形式上：

$0  P(A=1 \mid \mathbf{X}=\mathbf{x})  1$

对于所有在研究人群中存在的协变量值 $\mathbf{x}$ 均成立。

正性假设保证了对于任何协变量特征的个体，人群中都同时存在接受处理者和未接受处理者，从而使得比较成为可能。如果这个假设被违反，例如，对于某个亚组（如所有80岁以上的男性），所有人都接受了处理（即 $P(A=1 \mid \mathbf{X}=\mathbf{x}_{80+}) = 1$），那么我们就无法从数据中得知这个亚组的个体如果不接受处理会有什么结局（即 $E[Y(0) \mid \mathbf{X}=\mathbf{x}_{80+}]$ 无法被识别）。

当正性假设被严重违反时（即倾向性评分为0或1），逆概率加权等方法会因为分母为零而失效。即使是近似违反（倾向性评分非常接近0或1），也会导致权重过大，从而使估计结果极不稳定、方差剧增 [@problem_id:4943066]。在实践中，如果发现存在正性假设违规，研究者可能需要将分析限制在一个满足重叠条件的亚群中（例如，通过“修剪”掉倾向性评分极端的研究对象），但这会将推断的目标从全体人群的平均因果效应（ATE）改变为该亚群的因果效应 [@problem_id:4943066]。

### 倾向性评分的应用机制

在满足上述四个核心假设的前提下，我们可以应用倾向性评分来调整混杂。常见的方法包括匹配、分层和加权。

#### 分层（Subclassification）

分层是最直观的方法之一。它将研究人群根据倾向性评分的取值范围（如五分位数）分为若干个（例如5个）亚组。其背后的逻辑是，在每个亚组内部，个体的倾向性评分相似，因此他们的基线协变量分布也应该是平衡的。于是，我们可以在每个亚组内部分别计算处理组和[对照组](@entry_id:188599)的结局均值之差，得到该亚组的因果效应估计。最后，将各亚组的效应估计值按照各亚组在总人群中的比例进行加权平均，即可得到总体的平均因果效应（ATE）。

从理论上讲，只要亚组数量足够多，使得每个亚组内的倾向性评分差异趋于零，这种方法就能渐进地消除混杂偏倚 [@problem_id:4943134]。

#### 逆概率加权（Inverse Probability of Treatment Weighting, IPTW）

IPTW是一种更为灵活和强大的方法。其核心思想是通过加权来构建一个“伪人群”（pseudo-population），在这个伪人群中，协变量分布在处理组和[对照组](@entry_id:188599)之间是平衡的，从而消除了处理分配与协变量之间的关联。

权重的设定取决于我们希望估计的因果效应类型（estimand）[@problem_id:4943120]：

1.  **平均[处理效应](@entry_id:636010)（ATE, Average Treatment Effect）**: $E[Y(1) - Y(0)]$
    ATE代表了整个目标人群的平均因果效应。为了估计ATE，我们给每个接受处理（$A=1$）的个体赋予权重 $w_i = 1/e(\mathbf{X}_i)$，给每个未接受处理（$A=0$）的个体赋予权重 $w_i = 1/(1-e(\mathbf{X}_i))$。这种加权方式使得处理组和[对照组](@entry_id:188599)的协变量分布都重构为与总体人群的协变量分布一致。

2.  **处理组平均[处理效应](@entry_id:636010)（ATT, Average Treatment Effect on the Treated）**: $E[Y(1) - Y(0) \mid A=1]$
    ATT代表了在实际接受了处理的人群中的平均因果效应。这在评估一个已被广泛应用的干预措施时尤其有意义。为了估计ATT，我们将处理组个体的权重设为 $1$，而将[对照组](@entry_id:188599)个体的权重设为 $w_i = e(\mathbf{X}_i) / (1-e(\mathbf{X}_i))$。这种加权方式使得[对照组](@entry_id:188599)的协变量分布被重构为与处理组的协变量分布一致，从而使[对照组](@entry_id:188599)成为处理组的一个合适的“反事实”参照。

3.  **[对照组](@entry_id:188599)平均[处理效应](@entry_id:636010)（ATC, Average Treatment Effect on the Controls）**: $E[Y(1) - Y(0) \mid A=0]$
    ATC代表了在实际未接受处理的人群中的平均因果效应。为了估计ATC，我们将[对照组](@entry_id:188599)个体的权重设为 $1$，而将处理组个体的权重设为 $w_i = (1-e(\mathbf{X}_i)) / e(\mathbf{X}_i)$。

在获得权重后，因果效应可以通过计算加权后的处理组和[对照组](@entry_id:188599)结局均值之差来估计。

### 实践中的诊断与评估

倾向性评分模型的构建和应用不是一个“一键完成”的过程，它需要仔细的评估和诊断，以确保混杂得到了充分控制。

#### 评估倾向性评分模型

一个常见的误区是，认为一个能很好预测处理分配的模型（例如，具有很高的C-统计量或AUC）就是一个好的倾向性评分模型。这种看法是错误的 [@problem_id:4943097]。倾向性评分模型的目标**不是**完美预测，而是**实现平衡**。事实上，一个C-统计量非常高（例如 $0.9$）的模型往往意味着处理组和[对照组](@entry_id:188599)的基线特征差异巨大，重叠区域很小，这使得因果推断变得非常困难甚至不可能。因此，模型的预测能力指标不应用于评估倾向性评分模型的优劣。

#### 评估协变量平衡

评估倾向性评分方法是否成功的关键在于**检查调整后的协变量平衡性**。这是最重要的诊断步骤。我们必须比较在匹配、分层或加权**之后**，处理组和[对照组](@entry_id:188599)的基线协变量分布是否相似。

最常用的平衡性诊断指标是**标准化均数差（Standardized Mean Difference, SMD）** [@problem_id:4943098]。对于一个连续性协变量 $X$，其SMD计算公式为：

$$ \text{SMD} = \frac{\bar{X}_{1} - \bar{X}_{0}}{\sqrt{\frac{s_{1}^{2} + s_{0}^{2}}{2}}} $$

其中，$\bar{X}_{1}$ 和 $\bar{X}_{0}$ 分别是处理组和[对照组](@entry_id:188599)中该协变量的（加权）均值，$s_{1}^{2}$ 和 $s_{0}^{2}$ 是对应的（加权）方差。SMD的优点在于它是一个无量纲的指标，且不受样本量的影响，这与依赖于样本量的p值相比，更能真实地反映两组间差异的大小。

在实践中，通常认为调整后所有协变量的绝对SM[D值](@entry_id:168396)都**小于 $0.1$** 时，表明达到了良好的平衡。SM[D值](@entry_id:168396)在 $0.1$ 到 $0.2$ 之间可能表示存在轻微的残余不平衡，而大于 $0.2$ 则通常被认为是平衡性不佳的信号 [@problem_id:4943098]。除了SMD，还应检查[方差比](@entry_id:162608)（对于连续变量，应接近1）以及通过图表（如加权后的直方图、密度图）直观比较协变量的分布 [@problem_id:4943097] [@problem_id:4515359]。

如果发现平衡性不佳，研究者需要返回修改倾向性评分模型，例如，通过添加协变量的交互项或高次项，直到在调整后的样本中实现满意的平衡。这一迭代过程是倾向性评分分析的核心。