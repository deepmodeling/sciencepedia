{"hands_on_practices": [{"introduction": "Egger检验是检测发表偏倚的有力工具，但与任何统计方法一样，它容易受到个别影响力数据点的影响。一项精度极高的研究（即标准误极小的离群点）可能会对回归分析产生不成比例的影响，可能导致错误的偏倚信号或掩盖真实的偏倚。本练习 [@problem_id:4943807] 提供了一个具体而鲜明的案例，通过对比包含与排除该影响力离群点后的分析结果，您将更深入、更批判性地理解回归诊断的重要性，并学会超越简单的p值，对数据进行审慎的可视化检查。", "problem": "元分析收集研究特定的效应估计值 $\\hat{\\theta}_i$ 及其标准误 (SE) $\\mathrm{SE}_i$。漏斗图将 $\\hat{\\theta}_i$ 置于横轴，将 $\\mathrm{SE}_i$ 置于纵轴；在没有小样本研究效应的情况下，散点图应大致对称于合并效应，并随着 $\\mathrm{SE}_i$ 的减小而变窄。Egger 检验通过将标准化正态离差对精确度进行回归，并检验拟合的截距是否与零有差异，来评估漏斗图的不对称性。\n\n考虑以下 $10$ 项研究及其 $(\\hat{\\theta}_i, \\mathrm{SE}_i)$ 对：\n- 研究 $1$：$(0.20, 0.35)$\n- 研究 $2$：$(0.20, 0.33)$\n- 研究 $3$：$(0.20, 0.31)$\n- 研究 $4$：$(0.20, 0.29)$\n- 研究 $5$：$(0.20, 0.34)$\n- 研究 $6$：$(0.20, 0.32)$\n- 研究 $7$：$(0.20, 0.30)$\n- 研究 $8$：$(0.20, 0.36)$\n- 研究 $9$：$(0.20, 0.28)$\n- 研究 $10$：$(0.45, 0.05)$\n\n任务：\n- 使用最小二乘法的基本原理，计算包含全部 $10$ 项研究的数据集和排除研究 $10$ 的子集的 Egger 回归截距。在拟合回归之前，明确用 $(\\hat{\\theta}_i, \\mathrm{SE}_i)$ 定义标准化正态离差 $z_i$ 和精确度 $x_i$。\n- 基于这些计算和最小二乘法的几何原理，定性解释单个极小的 $\\mathrm{SE}_i$ 如何能够在视觉上锚定漏斗图（通过设定纵轴刻度和造成明显的不对称性），并在 Egger 回归中施加高杠杆作用。\n- 选择所有关于高精度离群值的影响以及评估和减轻夸大的不对称性的稳健可视化策略的正确陈述。\n\n选项：\nA. 在包含全部 $10$ 项研究的数据集中，Egger 截距显著不为 $0$，而移除高精度离群值会使截距更接近 $0$；这表明锚定作用如何夸大了表观的不对称性。\n\nB. 使用漏斗图的留一法叠加图，并固定各分图中的 SE 轴范围，是稳健的可视化策略，它们通过防止单个极端的 $\\mathrm{SE}_i$ 决定刻度并揭示影响，从而减少锚定作用。\n\nC. 将漏斗图的 SE 轴转换为对数刻度可以完全消除极端 $\\mathrm{SE}_i$ 对 Egger 检验的影响，因为 Egger 回归是在对数量上执行的。\n\nD. 绘制 $\\hat{\\theta}_i/\\mathrm{SE}_i$ 对 $1/\\mathrm{SE}_i$ 的径向图（Galbraith 图），可以直观地标记出单个具有影响的高精度点，并为小样本研究效应提供了比标准漏斗图更稳健的替代视角。\n\nE. 从图示和所有分析中剔除离群值是一种客观的解决方案，因为离群值总是伪迹。", "solution": "该问题是生物统计学领域一个有效的练习，具体涉及元分析的诊断。它具有科学依据，问题提出得很好，并且是客观的。所有进行必要计算和解释所需的数据和定义都已提供。\n\n任务是分析一项高精度研究对元分析的影响，重点关注漏斗图和用于检验小样本研究效应的 Egger 检验。\n\n首先，我们为 Egger 线性回归定义变量。该回归模型评估研究特定的效应大小与其精确度之间的关系。\n因变量是标准化正态离差，即效应估计值除以其标准误：\n$$z_i = \\frac{\\hat{\\theta}_i}{\\mathrm{SE}_i}$$\n自变量是效应估计值的精确度，即标准误的倒数：\n$$x_i = \\frac{1}{\\mathrm{SE}_i}$$\nEgger 回归模型是一个简单的 $z_i$ 对 $x_i$ 的线性回归，使用普通最小二乘法 (OLS)：\n$$z_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i$$\nEgger 检验正式检验原假设 $H_0: \\beta_0 = 0$。非零截距 $\\beta_0$ 被视为存在小样本研究效应（如发表偏倚）的证据。截距的 OLS 估计值为 $\\hat{\\beta}_0 = \\bar{z} - \\hat{\\beta}_1 \\bar{x}$，其中 $$\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(z_i - \\bar{z})}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}$$。\n\n**对全部 $10$ 项研究的计算**\n\n我们首先为所有 $n=10$ 项研究计算 $(x_i, z_i)$ 对。\n- 研究 1: $(x_1, z_1) = (1/0.35, 0.20/0.35) \\approx (2.857, 0.571)$\n- 研究 2: $(x_2, z_2) = (1/0.33, 0.20/0.33) \\approx (3.030, 0.606)$\n- 研究 3: $(x_3, z_3) = (1/0.31, 0.20/0.31) \\approx (3.226, 0.645)$\n- 研究 4: $(x_4, z_4) = (1/0.29, 0.20/0.29) \\approx (3.448, 0.690)$\n- 研究 5: $(x_5, z_5) = (1/0.34, 0.20/0.34) \\approx (2.941, 0.588)$\n- 研究 6: $(x_6, z_6) = (1/0.32, 0.20/0.32) \\approx (3.125, 0.625)$\n- 研究 7: $(x_7, z_7) = (1/0.30, 0.20/0.30) \\approx (3.333, 0.667)$\n- 研究 8: $(x_8, z_8) = (1/0.36, 0.20/0.36) \\approx (2.778, 0.556)$\n- 研究 9: $(x_9, z_9) = (1/0.28, 0.20/0.28) \\approx (3.571, 0.714)$\n- 研究 10: $(x_{10}, z_{10}) = (1/0.05, 0.45/0.05) = (20.000, 9.000)$\n\n使用这些值，我们计算 OLS 回归的汇总统计量：\n- $\\sum_{i=1}^{10} x_i \\approx 48.309$, 所以 $\\bar{x} \\approx 4.831$\n- $\\sum_{i=1}^{10} z_i \\approx 14.662$, 所以 $\\bar{z} \\approx 1.466$\n- $\\sum_{i=1}^{10} (x_i - \\bar{x})^2 \\approx 232.06$\n- $\\sum_{i=1}^{10} (x_i - \\bar{x})(z_i - \\bar{z}) \\approx 115.42$\n\n现在我们可以计算斜率和截距：\n- $\\hat{\\beta}_1 = \\frac{115.42}{232.06} \\approx 0.4974$\n- $\\hat{\\beta}_0 = \\bar{z} - \\hat{\\beta}_1 \\bar{x} \\approx 1.466 - (0.4974 \\times 4.831) \\approx 1.466 - 2.403 = -0.937$\n\n包含全部 $10$ 项研究的数据集的 Egger 截距约为 $-0.94$。\n\n**对排除研究 $10$ 的子集的计算**\n\n对于前 $9$ 项研究，存在一个特殊情况：效应估计值 $\\hat{\\theta}_i$ 恒为 $0.20$。\n我们来分析这个子集（$i=1, \\dots, 9$）中 $z_i$ 和 $x_i$ 之间的关系：\n$$z_i = \\frac{\\hat{\\theta}_i}{\\mathrm{SE}_i} = \\frac{0.20}{\\mathrm{SE}_i} = 0.20 \\times \\left(\\frac{1}{\\mathrm{SE}_i}\\right) = 0.20 x_i$$\n这意味着所有 $9$ 个数据点 $(x_i, z_i)$ 都完全位于一条穿过原点 $(0,0)$、斜率为 $0.20$ 的直线上。当数据点完全落在一条直线上时，OLS 回归将恢复那条精确的直线。模型是 $z_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i$。残差平方和 $\\sum (z_i - (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i))^2$ 被最小化。如果我们代入真实关系，得到 $\\sum (0.20 x_i - (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i))^2$。如果我们选择 $\\hat{\\beta}_0 = 0$ 和 $\\hat{\\beta}_1 = 0.20$，这个和恰好为零。由于平方和不能为负，这是唯一的最小值。\n因此，对于研究 $1-9$ 的子集，Egger 截距恰好为 $\\hat{\\beta}_0 = 0$。\n\n**影响的定性解释**\n\n像研究 $10$（$\\mathrm{SE}_{10} = 0.05$）这样具有极小标准误的单个研究会产生深远的影响。\n- **漏斗图中的视觉锚定：** 标准漏斗图将 $\\hat{\\theta}_i$（x轴）对 $\\mathrm{SE}_i$（y轴）作图。研究 $1-9$ 的 $\\mathrm{SE}_i$ 值聚集在 $0.28$ 到 $0.36$ 之间。研究 $10$ 的 $\\mathrm{SE}_{10} = 0.05$。为了显示所有点，y轴必须从低于 $0.05$ 延伸到高于 $0.36$。这迫使九项研究挤在图的顶部一个狭窄的带状区域内，而研究 $10$ 则独自位于底部。由于 $\\hat{\\theta}_{10}=0.45$ 与 $\\hat{\\theta}_{1-9}=0.20$ 不同，这个位于 $(0.45, 0.05)$ 的单一点造成了视觉上剧烈的不对称性，给人一种漏斗图歪斜的印象。\n- **Egger 回归中的高杠杆作用：** 回归中的杠杆作用指的是数据点的 x 值的影响力。x 值远离均值 $\\bar{x}$ 的点具有高杠杆作用。在 Egger 回归中，$x_i=1/\\mathrm{SE}_i$。对于研究 $1-9$，$x_i$ 的范围大约从 $2.78$ 到 $3.57$。对于研究 $10$，$x_{10} = 1/0.05 = 20$。这个值与其他点的聚类相距甚远，赋予了研究 $10$ 极高的杠杆作用。OLS 回归线被强烈地拉向这个高杠杆点。正如我们计算的，其他 $9$ 个点意味着截距为 $0$。而这个高杠杆点 $(20, 9)$ 将回归线向下拉，迫使截距变为显著的负值（$\\approx -0.94$）。因此，这一个研究在其他研究中本不存在不对称性的情况下，制造了不对称性的强烈统计证据。\n\n**选项评估**\n\nA. **在包含全部 $10$ 项研究的数据集中，Egger 截距显著不为 $0$，而移除高精度离群值会使截距更接近 $0$；这表明锚定作用如何夸大了表观的不对称性。**\n我们的计算表明，完整数据集的截距为 $\\hat{\\beta}_0 \\approx -0.94$，这显著不为 $0$。移除研究 $10$ 后，截距变为恰好为 $0$。该陈述正确地将这一数学结果与锚定作用和夸大的不对称性概念联系起来。\n**结论：正确。**\n\nB. **使用漏斗图的留一法叠加图，并固定各分图中的 SE 轴范围，是稳健的可视化策略，它们通过防止单个极端的 $\\mathrm{SE}_i$ 决定刻度并揭示影响，从而减少锚定作用。**\n留一法分析是识别有影响的数据点的标准方法。通过依次省略每个研究来生成图表或统计数据，可以量化每个研究的影响。在这些诊断图中固定坐标轴范围至关重要；它可以防止在移除有影响的点时图表重新调整刻度，从而使其对整体视觉模式的影响立即显现出来。这些确实是诊断影响的稳健策略。\n**结论：正确。**\n\nC. **将漏斗图的 SE 轴转换为对数刻度可以完全消除极端 $\\mathrm{SE}_i$ 对 Egger 检验的影响，因为 Egger 回归是在对数量上执行的。**\n该陈述在两个方面是错误的。首先，虽然在对数刻度上绘制 $\\mathrm{SE}_i$ 可以通过展开具有小 $\\mathrm{SE}_i$ 的点来改善可视化效果，但它不会改变用于 Egger 检验计算的底层数据。Egger 回归是在 $z_i=\\hat{\\theta}_i/\\mathrm{SE}_i$ 和 $x_i=1/\\mathrm{SE}_i$ 上执行的，而不是在它们的对数或 $\\mathrm{SE}_i$ 的对数上。因此，改变绘图刻度并不能“消除对统计检验的影响”。其次，声称回归是在对数量上执行的，对于标准的 Egger 检验来说是错误的。\n**结论：不正确。**\n\nD. **绘制 $\\hat{\\theta}_i/\\mathrm{SE}_i$ 对 $1/\\mathrm{SE}_i$ 的径向图（Galbraith 图），可以直观地标记出单个具有影响的高精度点，并为小样本研究效应提供了比标准漏斗图更稳健的替代视角。**\n假设 $y_i$ 是效应估计值 $\\hat{\\theta}_i$ 的通用符号，该陈述描述的是 $z_i=\\hat{\\theta}_i/\\mathrm{SE}_i$ 对 $x_i=1/\\mathrm{SE}_i$ 的图。这正是执行 Egger 回归所依据的图，也称为 Galbraith 图或径向图。在这样的图中，像研究 $10$ 这样的高精度点将具有非常大的 x 坐标（$x_{10}=20$），使其在横轴上成为一个明显的离群点。这使其高杠杆作用在视觉上显而易见。与标准漏斗图相比，该图是评估异质性和元回归模型拟合度的稳健且通常更受青睐的替代方法。\n**结论：正确。**\n\nE. **从图示和所有分析中剔除离群值是一种客观的解决方案，因为离群值总是伪迹。**\n该陈述提出了一个强烈且错误的论断。自动移除离群值不是一种客观的做法。它可能等同于数据操纵。离群值可能是错误的结果，但也可能是一个有效且信息量极高的结果（例如，来自一项大型、高质量的试验）。“离群值总是伪迹”的断言在科学上是毫无根据的。正确的程序是进行敏感性分析——报告包含和不包含有影响点时的结果——并调查其极端性的原因，而不是毫无理由地丢弃它。\n**结论：不正确。**\n\n最终正确的陈述是 A、B 和 D。", "answer": "$$\\boxed{ABD}$$", "id": "4943807"}, {"introduction": "虽然标准的Egger检验在处理连续性结局时表现良好，但临床研究中的荟萃分析（meta-analysis）通常涉及二元结局（如成功/失败，生存/死亡），其效应量采用比值比（odds ratio）等指标。在这种情况下，需要一种更专门的方法来确保统计有效性。本练习 [@problem_id:4943837] 深入探讨了专为二元数据设计的Harbord's Egger检验变体。您将从似然理论的第一性原理出发，推导其背后的回归模型，从而将抽象的统计理论与实用的分析工具联系起来。这个练习不仅能巩固您对荟萃分析技术的掌握，还能加深您对如何根据不同数据类型定制统计检验的理解。", "problem": "对于具有二元结局的随机对照试验的元分析，通常使用 Egger 检验，通过将标准化效应对其精度进行回归来诊断小样本效应。对于对数优势比等二元结局，Harbord 修正用一个根据每个研究的 $2\\times 2$ 表格构建的标准化有效得分来代替标准化效应 $Z_i$。从似然理论的基本原理出发，考虑研究 $i$ 的对数优势比参数 $\\theta$ 和有效得分 $U_i(\\theta)$，其 Fisher 信息为 $I_i(\\theta)$。在共同效应模型下，当 $\\theta$ 接近 $0$ 时，经过充分检验的关系式 $E[U_i(\\theta)] \\approx \\theta\\,I_i(0)$ 和 $\\mathrm{Var}[U_i(0)] = I_i(0)$ 成立。对于单元格计数为 $(a_i,b_i;c_i,d_i)$ 的单个 $2\\times 2$ 研究，定义在 $\\theta=0$ 时的 Cochran–Mantel–Haenszel (CMH) 有效得分及其方差为\n$$\nS_i \\equiv a_i - \\frac{n_{1i} y_i}{n_i},\\quad\nV_i \\equiv \\frac{n_{1i} n_{0i}\\, y_i\\, (n_i - y_i)}{n_i^{2}\\,(n_i - 1)},\n$$\n其中 $n_{1i} = a_i + b_i$，$n_{0i} = c_i + d_i$，$n_i = n_{1i} + n_{0i}$，以及 $y_i = a_i + c_i$。使用这些事实，用 $\\theta$ 和 $V_i$ 来推导标准化得分 $Z_i \\equiv S_i/\\sqrt{V_i}$ 的期望，并解释这如何启发我们通过一个截距来评估小样本效应，即对 $Z_i$ 关于 $V_i$ 的一个函数进行线性回归。然后，使用以下六项研究的数据，计算推导出的 Harbord 型回归的普通最小二乘截距 $\\hat{\\alpha}$。将最终答案四舍五入至四位有效数字。\n\n六项试验的数据（每个项目符号给出 $(a_i,b_i;c_i,d_i)$）：\n- 研究 $1$：$(20,30;\\,15,35)$\n- 研究 $2$：$(28,52;\\,14,56)$\n- 研究 $3$：$(18,42;\\,8,32)$\n- 研究 $4$：$(45,45;\\,44,66)$\n- 研究 $5$：$(21,49;\\,34,46)$\n- 研究 $6$：$(10,30;\\,12,48)$", "solution": "本题要求做两件事：首先，推导标准化有效得分 $Z_i$ 的期望值，并解释这如何启发我们使用线性回归来检验小样本效应（Harbord 检验）；其次，根据给定的六项研究的数据集，计算该回归的截距。\n\n首先，我们来解决推导和动机部分。研究 $i$ 的标准化得分定义为 $Z_i \\equiv S_i/\\sqrt{V_i}$。我们希望求其期望 $E[Z_i]$。在用于 $2 \\times 2$ 表格的条件似然框架中，方差 $V_i$ 仅取决于表格的边际总和。这些边际总和被视为辅助统计量，意味着在对优势比 $\\theta$ 进行推断时，它们被认为是固定的。因此，我们可以将比值的期望近似为期望的比值：\n$$ E[Z_i] = E\\left[\\frac{S_i}{\\sqrt{V_i}}\\right] \\approx \\frac{E[S_i]}{\\sqrt{V_i}} $$\n题目指出 $S_i$ 是在 $\\theta=0$ 时的 Cochran–Mantel–Haenszel (CMH) 有效得分，这对应于似然理论中的有效得分 $U_i(0)$。期望 $E[S_i]$ 应在真实的、可能非零的共同效应大小 $\\theta$ 下计算。似然理论中的一个标准结果（通过对得分函数进行一阶泰勒级数展开得到）表明，在真实参数值 $\\theta$ 下，于零假设值（此处为 $\\theta=0$）处评估的得分函数的期望，近似地与 $\\theta$ 成正比。题目将此关系表述为 $E[U_i(\\theta)] \\approx \\theta\\,I_i(0)$。这个记法略有歧义；标准结果是，在真实参数下，零假设处的得分期望为 $E_{\\theta}[U_i(0)] \\approx \\theta I_i(0)$，其中 $I_i(0)$ 是在零假设处评估的 Fisher 信息。我们采用这种标准解释。\n\n由于 $S_i$ 等同于 $U_i(0)$，我们有：\n$$ E[S_i] \\approx \\theta I_i(0) $$\n题目还提供了两个关键事实：$\\mathrm{Var}[U_i(0)] = I_i(0)$，以及 $V_i$ 的公式，它是 $S_i$ 在零假设（$\\theta=0$）下以表格边际为条件的精确方差。因此，在这种情况下，$V_i$ 是 $I_i(0)$ 的自然估计量。将 $I_i(0)$ 替换为 $V_i$：\n$$ E[S_i] \\approx \\theta V_i $$\n现在，我们可以求出标准化得分 $Z_i$ 的期望：\n$$ E[Z_i] \\approx \\frac{\\theta V_i}{\\sqrt{V_i}} = \\theta \\sqrt{V_i} $$\n这个推导出的关系是启发该回归的核心。它表明，在没有偏倚的情况下，标准化得分 $Z_i$ 的期望值与 $\\sqrt{V_i}$ 成正比。$\\sqrt{V_i}$ 这一项可以解释为研究的精度，因为它是对数优势比近似标准误（$1/\\sqrt{I_i(0)}$）的倒数。\n\n小样本效应（如发表偏倚）假定，研究中观察到的效应可能与其规模或精度系统性相关。例如，较小的研究（精度较低）如果显示出夸大的效应，则可能更容易被发表。这引入了一种偏倚，可以通过在关系式中添加一个常数项来建模。因此，我们提出以下线性回归模型：\n$$ E[Z_i] = \\alpha + \\beta \\sqrt{V_i} $$\n在这个模型中，$\\beta$ 对应于总体治疗效应 $\\theta$。截距 $\\alpha$ 代表系统性偏倚。如果没有小样本效应，我们期望 $\\alpha=0$，并且回归线应通过原点。一个统计上显著的非零截距 $\\hat{\\alpha}$ 被解释为存在小样本效应的证据。这种将标准化得分 $Z_i$ 对其精度 $\\sqrt{V_i}$ 进行的回归，是针对二元结局小样本效应的 Harbord 检验的基础。\n\n接下来，我们使用提供的六项研究数据，为该回归计算普通最小二乘（OLS）截距 $\\hat{\\alpha}$。对于每项研究 $i$，我们必须计算必要的量。设 $X_i = \\sqrt{V_i}$ 为自变量，$Y_i = Z_i = S_i/\\sqrt{V_i}$ 为因变量。\n\n对 $N=6$ 项研究的计算总结如下：\n1.  研究 $1$：$(a_1,b_1;c_1,d_1) = (20,30;15,35)$。$n_{11}=50, n_{01}=50, n_1=100, y_1=35$。\n    $S_1 = 20 - \\frac{50 \\times 35}{100} = 2.5$。\n    $V_1 = \\frac{50 \\times 50 \\times 35 \\times 65}{100^2 \\times 99} \\approx 5.74495$。\n    $X_1 = \\sqrt{V_1} \\approx 2.39686$。$Y_1 = Z_1 = S_1/X_1 \\approx 1.04303$。\n2.  研究 $2$：$(a_2,b_2;c_2,d_2) = (28,52;14,56)$。$n_{12}=80, n_{02}=70, n_2=150, y_2=42$。\n    $S_2 = 28 - \\frac{80 \\times 42}{150} = 5.6$。\n    $V_2 = \\frac{80 \\times 70 \\times 42 \\times 108}{150^2 \\times 149} \\approx 7.57690$。\n    $X_2 = \\sqrt{V_2} \\approx 2.75262$。$Y_2 = Z_2 = S_2/X_2 \\approx 2.03442$。\n3.  研究 $3$：$(a_3,b_3;c_3,d_3) = (18,42;8,32)$。$n_{13}=60, n_{03}=40, n_3=100, y_3=26$。\n    $S_3 = 18 - \\frac{60 \\times 26}{100} = 2.4$。\n    $V_3 = \\frac{60 \\times 40 \\times 26 \\times 74}{100^2 \\times 99} \\approx 4.66424$。\n    $X_3 = \\sqrt{V_3} \\approx 2.15969$。$Y_3 = Z_3 = S_3/X_3 \\approx 1.11127$。\n4.  研究 $4$：$(a_4,b_4;c_4,d_4) = (45,45;44,66)$。$n_{14}=90, n_{04}=110, n_4=200, y_4=89$。\n    $S_4 = 45 - \\frac{90 \\times 89}{200} = 4.95$。\n    $V_4 = \\frac{90 \\times 110 \\times 89 \\times 111}{200^2 \\times 199} \\approx 12.27524$。\n    $X_4 = \\sqrt{V_4} \\approx 3.50360$。$Y_4 = Z_4 = S_4/X_4 \\approx 1.41284$。\n5.  研究 $5$：$(a_5,b_5;c_5,d_5) = (21,49;34,46)$。$n_{15}=70, n_{05}=80, n_5=150, y_5=55$。\n    $S_5 = 21 - \\frac{70 \\times 55}{150} = -\\frac{14}{3} \\approx -4.66667$。\n    $V_5 = \\frac{70 \\times 80 \\times 55 \\times 95}{150^2 \\times 149} \\approx 8.72782$。\n    $X_5 = \\sqrt{V_5} \\approx 2.95429$。$Y_5 = Z_5 = S_5/X_5 \\approx -1.57963$。\n6.  研究 $6$：$(a_6,b_6;c_6,d_6) = (10,30;12,48)$。$n_{16}=40, n_{06}=60, n_6=100, y_6=22$。\n    $S_6 = 10 - \\frac{40 \\times 22}{100} = 1.2$。\n    $V_6 = \\frac{40 \\times 60 \\times 22 \\times 78}{100^2 \\times 99} = 4.16$。\n    $X_6 = \\sqrt{V_6} \\approx 2.03961$。$Y_6 = Z_6 = S_6/X_6 \\approx 0.58835$。\n\n我们需要以下总和来进行 OLS 计算（$N=6$）：\n$\\sum_{i=1}^N X_i \\approx 15.80667$\n$\\sum_{i=1}^N Y_i \\approx 4.61028$\n$\\sum_{i=1}^N X_i^2 = \\sum_{i=1}^N V_i \\approx 43.14915$\n$\\sum_{i=1}^N X_i Y_i = \\sum_{i=1}^N (\\sqrt{V_i}) (S_i/\\sqrt{V_i}) = \\sum_{i=1}^N S_i = 2.5 + 5.6 + 2.4 + 4.95 - \\frac{14}{3} + 1.2 \\approx 11.98333$\n\n均值为：\n$\\bar{X} = \\frac{1}{N} \\sum X_i \\approx \\frac{15.80667}{6} \\approx 2.63444$\n$\\bar{Y} = \\frac{1}{N} \\sum Y_i \\approx \\frac{4.61028}{6} \\approx 0.76838$\n\nOLS 斜率估计 $\\hat{\\beta}$ 为：\n$$ \\hat{\\beta} = \\frac{\\sum (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum (X_i - \\bar{X})^2} = \\frac{(\\sum X_i Y_i) - N \\bar{X} \\bar{Y}}{(\\sum X_i^2) - N \\bar{X}^2} $$\n$$ \\hat{\\beta} \\approx \\frac{11.98333 - 6 \\times (2.63444) \\times (0.76838)}{43.14915 - 6 \\times (2.63444)^2} \\approx \\frac{11.98333 - 12.14545}{43.14915 - 41.64195} = \\frac{-0.16212}{1.50720} \\approx -0.10756 $$\nOLS 截距估计 $\\hat{\\alpha}$ 为：\n$$ \\hat{\\alpha} = \\bar{Y} - \\hat{\\beta} \\bar{X} $$\n$$ \\hat{\\alpha} \\approx 0.76838 - (-0.10756) \\times (2.63444) \\approx 0.76838 + 0.28335 \\approx 1.05173 $$\n将结果四舍五入到四位有效数字，我们得到 $1.052$。", "answer": "$$\\boxed{1.052}$$", "id": "4943837"}, {"introduction": "在使用漏斗图或Egger检验检测到潜在的发表偏倚后，一个关键的后续问题是：“这种偏倚可能在多大程度上影响我们的总体结论？”仅仅指出偏倚的存在通常是不够的，我们还需要量化其潜在影响。剪补法（trim-and-fill procedure）是一种广泛使用且直观的方法，用于估计并调整由发表偏倚引起的缺失研究。这项动手练习 [@problem_id:4943871] 将引导您完成这种非参数技术的各个步骤。通过亲手计算，您将对如何进行敏感性分析以评估荟萃分析结果在面对潜在发表偏倚时的稳健性，获得切实而深入的理解。", "problem": "一位研究者对 $k=8$ 项研究进行了一项固定效应荟萃分析，这些研究报告了观测到的效应估计值 $\\hat{\\theta}_{i}$ 和相应的标准误 $\\text{SE}_{i}$。这些估计值和标准误如下：\n\n- 研究 $1$：$\\hat{\\theta}_{1}=0.20$，$\\text{SE}_{1}=0.05$\n- 研究 $2$：$\\hat{\\theta}_{2}=0.22$，$\\text{SE}_{2}=0.06$\n- 研究 $3$：$\\hat{\\theta}_{3}=0.18$，$\\text{SE}_{3}=0.08$\n- 研究 $4$：$\\hat{\\theta}_{4}=0.24$，$\\text{SE}_{4}=0.10$\n- 研究 $5$：$\\hat{\\theta}_{5}=0.30$，$\\text{SE}_{5}=0.12$\n- 研究 $6$：$\\hat{\\theta}_{6}=0.40$，$\\text{SE}_{6}=0.15$\n- 研究 $7$：$\\hat{\\theta}_{7}=0.50$，$\\text{SE}_{7}=0.20$\n- 研究 $8$：$\\hat{\\theta}_{8}=0.55$，$\\text{SE}_{8}=0.25$\n\n假设采用带有反方差权重的固定效应模型，并考虑用于检验小样本效应的 Egger 回归检验以及漏斗图对称性概念。应用剪补法（trim-and-fill procedure），如果 Egger 回归表明存在与缺失较小负效应研究相一致的不对称性，则在右侧进行修剪，从修剪后的数据集中估计中心，并通过补入与被修剪研究具有相同 $\\text{SE}_{i}$ 的镜像研究来进行填充。然后，在增广数据集（所有观测研究加上补入的填充研究）上重新计算合并估计值。\n\n使用上述数据计算剪补法调整后的合并效应。将最终的调整后合并效应四舍五入至四位有效数字。效应量无需物理单位。在你的推理过程中，讨论剪补法调整相对于漏斗图不对称性和 Egger 检验的偏倚特性。", "solution": "用户提供了一个生物统计学问题，该问题要求应用剪补法对一个荟萃分析数据集进行处理，以校正潜在的发表偏倚。\n\n### 步骤 1：提取已知条件\n- 研究数量：$k=8$\n- 模型：采用反方差权重的固定效应荟萃分析。\n- 偏倚检验：Egger 回归。\n- 校正程序：剪补法。\n- $i=1, \\dots, 8$ 的数据：\n  - 研究 $1$：$\\hat{\\theta}_{1}=0.20$，$\\text{SE}_{1}=0.05$\n  - 研究 $2$：$\\hat{\\theta}_{2}=0.22$，$\\text{SE}_{2}=0.06$\n  - 研究 $3$：$\\hat{\\theta}_{3}=0.18$，$\\text{SE}_{3}=0.08$\n  - 研究 $4$：$\\hat{\\theta}_{4}=0.24$，$\\text{SE}_{4}=0.10$\n  - 研究 $5$：$\\hat{\\theta}_{5}=0.30$，$\\text{SE}_{5}=0.12$\n  - 研究 $6$：$\\hat{\\theta}_{6}=0.40$，$\\text{SE}_{6}=0.15$\n  - 研究 $7$：$\\hat{\\theta}_{7}=0.50$，$\\text{SE}_{7}=0.20$\n  - 研究 $8$：$\\hat{\\theta}_{8}=0.55$，$\\text{SE}_{8}=0.25$\n- 最终答案精度：四舍五入至四位有效数字。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题具有科学依据，提法明確且客观。它概述了荟萃分析中评估和调整发表偏倚的标准程序。所提供的数据是完整且一致的。“剪补法”（trim-and-fill procedure）一词指的是 Duval 和 Tweedie 提出的一个成熟算法，并且问题提供了足够的信息来应用它。“如果 Egger 回归表明存在不对称性，则在右侧进行修剪”的指令与数据中效应量和标准误之间的正相关性相符，这表明漏斗图的左侧（负效应或不显著效应）存在缺失的研究。该问题有效。\n\n### 步骤 3：结论与行动\n该问题有效。我将继续进行解答。\n\n### 详细解答\n\n剪补法是一种非参数方法，用于估计发表偏倚对荟萃分析的影响。它的操作方式是估计漏斗图中缺失的研究数量，补入它们的值，然后重新计算合并效应。\n\n**第 1 部分：初始合并效应与不对称性评估**\n\n首先，我们使用反方差固定效应模型计算初始合并效应估计值 $\\hat{\\theta}_{FE}$。每个研究 $i$ 的权重是其方差的倒数，$w_i = 1/\\text{SE}_i^2$。合并效应为 $\\hat{\\theta}_{FE} = \\frac{\\sum_{i=1}^{k} w_i \\hat{\\theta}_i}{\\sum_{i=1}^{k} w_i}$。\n\n权重如下：\n- $w_1 = 1/0.05^2 = 400$\n- $w_2 = 1/0.06^2 \\approx 277.78$\n- $w_3 = 1/0.08^2 = 156.25$\n- $w_4 = 1/0.10^2 = 100$\n- $w_5 = 1/0.12^2 \\approx 69.44$\n- $w_6 = 1/0.15^2 \\approx 44.44$\n- $w_7 = 1/0.20^2 = 25$\n- $w_8 = 1/0.25^2 = 16$\n\n权重总和为 $\\sum w_i \\approx 400 + 277.78 + 156.25 + 100 + 69.44 + 44.44 + 25 + 16 \\approx 1088.91$。\n加权效应总和为 $\\sum w_i \\hat{\\theta}_i \\approx 400(0.20) + 277.78(0.22) + \\dots + 16(0.55) \\approx 253.15$。\n初始合并效应为 $\\hat{\\theta}_{FE} \\approx 253.15 / 1088.91 \\approx 0.23248$。\n\n问题指出，Egger 回归表明存在与缺失较小负效应研究相一致的不对称性。这对应于标准化效应与精度进行 Egger 回归时得到的正截距，表明精度较低（即 $\\text{SE}$ 较大）的研究倾向于报告较大的正效应。这为通过从效应分布的右侧（正侧）修剪研究来应用剪补法提供了依据。\n\n**第 2 部分：估计要修剪的研究数量 ($k_0$)**\n\n标准的剪补算法使用一个基于秩的估计量 $L_0$ 来确定要修剪的研究数量 $k_0$。\n1. 以初始合并估计值为中心对效应量进行中心化：$\\hat{\\theta}_i^* = \\hat{\\theta}_i - \\hat{\\theta}_{FE}$。\n    - $\\hat{\\theta}_1^* = 0.20 - 0.23248 = -0.03248$\n    - $\\hat{\\theta}_2^* = 0.22 - 0.23248 = -0.01248$\n    - $\\hat{\\theta}_3^* = 0.18 - 0.23248 = -0.05248$\n    - $\\hat{\\theta}_4^* = 0.24 - 0.23248 = 0.00752$\n    - $\\hat{\\theta}_5^* = 0.30 - 0.23248 = 0.06752$\n    - $\\hat{\\theta}_6^* = 0.40 - 0.23248 = 0.16752$\n    - $\\hat{\\theta}_7^* = 0.50 - 0.23248 = 0.26752$\n    - $\\hat{\\theta}_8^* = 0.55 - 0.23248 = 0.31752$\n2. 根据中心化效应的绝对值 $|\\hat{\\theta}_i^*|$ 对研究进行排序：\n    - 秩 1：$|\\hat{\\theta}_4^*|=0.00752$\n    - 秩 2：$|\\hat{\\theta}_2^*|=0.01248$\n    - 秩 3：$|\\hat{\\theta}_1^*|=0.03248$\n    - 秩 4：$|\\hat{\\theta}_3^*|=0.05248$\n    - 秩 5：$|\\hat{\\theta}_5^*|=0.06752$\n    - 秩 6：$|\\hat{\\theta}_6^*|=0.16752$\n    - 秩 7：$|\\hat{\\theta}_7^*|=0.26752$\n    - 秩 8：$|\\hat{\\theta}_8^*|=0.31752$\n3. 对具有正中心化效应的研究（$\\hat{\\theta}_4^*, \\hat{\\theta}_5^*, \\hat{\\theta}_6^*, \\hat{\\theta}_7^*, \\hat{\\theta}_8^*$）的秩次求和：\n    $T^+ = \\text{Rank}(\\hat{\\theta}_4^*) + \\text{Rank}(\\hat{\\theta}_5^*) + \\text{Rank}(\\hat{\\theta}_6^*) + \\text{Rank}(\\hat{\\theta}_7^*) + \\text{Rank}(\\hat{\\theta}_8^*) = 1 + 5 + 6 + 7 + 8 = 27$。\n4. 计算估计量 $L_0$：\n    $$ L_0 = \\frac{4T^+ - k(k+1)}{2k-1} = \\frac{4(27) - 8(8+1)}{2(8)-1} = \\frac{108 - 72}{15} = \\frac{36}{15} = 2.4 $$\n5. 要修剪的研究数量 $k_0$ 是与 $L_0$ 最接近的整数。如果 $L_0  0$，则 $k_0=0$。此处，$k_0 = \\text{round}(2.4) = 2$。\n\n**第 3 部分：修剪、填充与重新估计合并效应**\n\n当 $k_0=2$ 时，我们从分布的右侧修剪掉两个具有最极端正效应量的研究。它们是研究 7（$\\hat{\\theta}_7=0.50$）和研究 8（$\\hat{\\theta}_8=0.55$）。\n\n接下来，我们使用余下的 $k - k_0 = 6$ 项研究（研究 1-6）计算调整后的合并效应 $\\hat{\\theta}_{adj}$。\n修剪后数据集（研究 1-6）的权重总和为：\n$\\sum_{i=1}^6 w_i = 400 + \\frac{1}{0.06^2} + 156.25 + 100 + \\frac{1}{0.12^2} + \\frac{1}{0.15^2} = \\frac{12575}{12} \\approx 1047.9167$\n修剪后数据集的加权效应总和为：\n$\\sum_{i=1}^6 w_i \\hat{\\theta}_i = 400(0.2) + \\frac{0.22}{0.06^2} + 156.25(0.18) + 100(0.24) + \\frac{0.30}{0.12^2} + \\frac{0.40}{0.15^2} = \\frac{16693}{72} \\approx 231.8472$\n基于修剪后数据集的调整后合并效应为：\n$$ \\hat{\\theta}_{adj} = \\frac{\\sum_{i=1}^6 w_i \\hat{\\theta}_i}{\\sum_{i=1}^6 w_i} = \\frac{16693/72}{12575/12} = \\frac{16693}{6 \\times 12575} = \\frac{16693}{75450} \\approx 0.2212458 $$\n该程序现在通过补入 $k_0=2$ 个缺失的研究来“填充”漏斗图。补入的研究与被修剪的研究具有相同的标准误，但其效应量围绕 $\\hat{\\theta}_{adj}$ 呈镜像对称。\n- 补入研究 1（对应被修剪的研究 7）：$\\text{SE}_{\\text{fill},1} = 0.20$，$\\hat{\\theta}_{\\text{fill},1} = 2\\hat{\\theta}_{adj} - \\hat{\\theta}_7 \\approx 2(0.221246) - 0.50 = -0.057508$\n- 补入研究 2（对应被修剪的研究 8）：$\\text{SE}_{\\text{fill},2} = 0.25$，$\\hat{\\theta}_{\\text{fill},2} = 2\\hat{\\theta}_{adj} - \\hat{\\theta}_8 \\approx 2(0.221246) - 0.55 = -0.107508$\n\n最终调整后的合并效应是根据包含所有 8 个原始研究和 2 个补入研究的增广数据集计算的。剪补法的一个重要特性是，这个包含 $k+k_0$ 项研究的增广数据集的最终合并效应，在数学上与从包含 $k-k_0$ 项研究的修剪后数据集计算出的合并效应是相同的。因此，最终调整后的合并效应就是 $\\hat{\\theta}_{adj}$。\n\n$$ \\hat{\\theta}_{\\text{final}} = \\hat{\\theta}_{adj} \\approx 0.2212458 $$\n四舍五入至四位有效数字，调整后的合并效应为 $0.2212$。\n\n**关于偏倚特性的讨论**\n初始合并效应 $\\hat{\\theta}_{FE} \\approx 0.2325$ 可能因发表偏倚而被夸大，发表偏倚是一种系统性倾向，即倾向于发表具有统计学显著性结果的研究，而非不显著结果的研究。这种偏倚常常导致较大效应量的过度呈现，尤其是在统计功效较低的小型研究中，从而引起漏斗图不对称。Egger 检验可正式检测这种不对称性。\n\n剪补法试图校正这种偏倚。通过识别并修剪图中过度呈现一侧的最极端研究，并在另一侧补入其“缺失”的对应研究，该方法创建了一个更对称的效应分布。调整后的合并估计值 $\\hat{\\theta}_{\\text{final}} \\approx 0.2212$ 低于初始估计值，这反映了对假定的向上偏倚的校正。假设观察到的不对称性确实是由发表偏倚引起的，那么这个调整后的值被认为是真实潜在效应的一个更合理的估计。然而，剪补法本身并非没有局限性；其准确性取决于其假设的有效性。如果漏斗图的不对称性是由发表偏倚以外的因素（例如，真实的异质性）引起的，该方法可能会产生误导性的“校正”。因此，最好将其视为一种敏感性分析，用以衡量发表偏倚的潜在影响。", "answer": "$$\n\\boxed{0.2212}\n$$", "id": "4943871"}]}