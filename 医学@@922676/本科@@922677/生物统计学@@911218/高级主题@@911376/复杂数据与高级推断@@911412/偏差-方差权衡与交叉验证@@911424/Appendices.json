{"hands_on_practices": [{"introduction": "理论上的偏差-方差权衡是预测建模的基石，但通过实践来直观地理解它更为重要。这个练习将指导您设计一个模拟研究，在这里您将亲手创建一个过拟合的场景。通过比较一个简单模型和一个复杂多项式模型的表现，您将直接观察到模型复杂性如何导致更低的训练误差，但却以更高的模型方差为代价，最终导致泛化能力的下降，正如通过交叉验证所估计的那样。[@problem_id:4897610]", "problem": "您需要设计并实现一个完整的模拟研究，该研究使用多项式回归模型，在一个真实的数据生成机制下，揭示偏差-方差权衡，并使用交叉验证（CV）来估计期望测试误差。目标是构建这样的情景：一个参数更多的模型获得了更低的训练误差，但期望测试误差却更差，并证明这种行为是由显式方差项的增加所驱动的。\n\n基本基础和设置：\n- 设预测变量为一个实值协变量 $x \\in [-1,1]$，其分布为 $x \\sim \\mathrm{Uniform}([-1,1])$。\n- 设响应变量由 $y = f(x) + \\epsilon$ 生成，其中 $f(x)$ 是一个确定性函数，而 $\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)$ 是方差为 $\\sigma^2$ 的独立噪声。\n- 定义真实信号 $f(x)$ 为 $f(x) = \\alpha \\sin(\\pi x) + \\beta x$，其中 $\\alpha$ 和 $\\beta$ 是固定的实数常数。\n- 考虑d次多项式回归模型（包括截距项），该模型通过对训练数据使用最小二乘法来估计函数 $\\hat{f}_d(x)$。“简单”模型使用次数 $d_s$，“复杂”模型使用次数 $d_c$，且 $d_c > d_s$。\n\n使用的核心定义：\n- 对于一个大小为 $n$ 的训练数据集，训练均方误差（MSE）为 $\\frac{1}{n}\\sum_{i=1}^{n}\\left(y_i - \\hat{f}(x_i)\\right)^2$。\n- 期望测试MSE的K折交叉验证估计量，是通过将训练数据集划分为 $K$ 折后，对留出折的MSE求平均得到的。\n- 在数据生成模型 $y = f(x) + \\epsilon$下，固定点 $x$ 处的偏差-方差分解表明\n$$\n\\mathbb{E}\\left[(\\hat{f}(x) - y)^2\\right] = \\left(\\mathbb{E}[\\hat{f}(x)] - f(x)\\right)^2 + \\mathrm{Var}(\\hat{f}(x)) + \\sigma^2,\n$$\n其中期望和方差是针对训练样本中的随机性（以及适用时的 $\\epsilon$）计算的。在此模拟中，您将通过蒙特卡洛重复实验显式地估计方差项 $\\mathrm{Var}(\\hat{f}(x))$。\n\n任务要求：\n1. 对于每个指定的测试用例，根据 $x \\sim \\mathrm{Uniform}([-1,1])$ 和 $y = f(x) + \\epsilon$（其中 $\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)$ 和固定的 $f(x) = \\alpha \\sin(\\pi x) + \\beta x$）生成 $B$ 个大小为 $n$ 的独立训练数据集。使用 $\\alpha = 1.5$ 和 $\\beta = 0.5$。\n2. 对于每个数据集和每个模型次数 $d \\in \\{d_s, d_c\\}$：\n   - 拟合次数为 $d$ 的最小二乘多项式模型。\n   - 计算训练 MSE。\n   - 计算 K 折交叉验证 MSE，其中 K=5 折。\n3. 为了估计每个次数 $d$ 的方差项 $\\mathrm{Var}(\\hat{f}(x))$，构建一个覆盖 $[-1,1]$ 的包含 $m$ 个点的固定网格 $\\{x_j\\}_{j=1}^m$，为每次蒙特卡洛重复实验 $b \\in \\{1,\\dots,B\\}$ 计算 $\\hat{f}_d^{(b)}(x_j)$，然后通过重复实验间的样本方差来估计 $\\mathrm{Var}(\\hat{f}(x_j))$。将这些方差在网格上求平均，以获得单一标量摘要\n$$\nV_d = \\frac{1}{m} \\sum_{j=1}^m \\widehat{\\mathrm{Var}}\\left(\\hat{f}_d(x_j)\\right).\n$$\n4. 对于每个测试用例，汇总 $B$ 次重复实验的结果以计算：\n   - 简单模型和复杂模型的平均训练 MSE。\n   - 简单模型和复杂模型的平均 K 折 CV MSE。\n   - 方差摘要 $V_{d_s}$ 和 $V_{d_c}$。\n5. 为一个测试用例定义过拟合表现指标，如果以下所有三个条件都成立，则为 $1$ (true)，否则为 $0$ (false)：\n   - 复杂模型的平均训练 MSE 严格小于简单模型的平均训练 MSE。\n   - 复杂模型的平均 K 折 CV MSE 严格大于简单模型的平均 K 折 CV MSE。\n   - 方差摘要 $V_{d_c}$ 严格大于 $V_{d_s}$。\n\n参数值（测试套件）：\n- 使用 $B = 200$ 和 $m = 201$ 个网格点。\n- 使用 $K = 5$ 折。\n- 使用以下三个测试用例，它们共同探讨一个一般场景、一个大样本边界和一个无噪声边缘情况：\n  1. 用例 A (理想路径): $n = 60$, $\\sigma = 0.5$, $d_s = 3$, $d_c = 18$。\n  2. 用例 B (大样本边界): $n = 400$, $\\sigma = 0.5$, $d_s = 3$, $d_c = 18$。\n  3. 用例 C (无噪声边缘情况): $n = 60$, $\\sigma = 0$, $d_s = 3$, $d_c = 18$。\n\n要求的最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$[result1,result2,result3]$）的结果，其中每个 $resultk$ 是根据上述指标评估的第 $k$ 个测试用例的整数 $0$ 或 $1$。不应打印任何其他输出或文本。", "solution": "该问题提出了一个在生物统计学领域内有效且适定的模拟研究，旨在利用多项式回归探讨偏差-方差权衡。所有参数和步骤都定义清晰，以既定的统计学原理为科学依据，并且计算上是可行的。该问题客观且无歧义，满足所有验证标准。\n\n该任务的核心是从一个已知的真实函数模拟数据，拟合不同复杂度的模型，并评估其性能以阐释过拟合的概念。模拟框架定义如下：\n\n数据生成过程基于一个从区间 $[-1, 1]$ 均匀采样的预测变量 $x$，即 $x \\sim \\mathrm{Uniform}([-1,1])$。相应的响应变量 $y$ 由模型 $y = f(x) + \\epsilon$ 生成，其中 $f(x)$ 是确定性的真实信号，$\\epsilon$ 是一个随机噪声项。信号由函数 $f(x) = \\alpha \\sin(\\pi x) + \\beta x$ 给出，其中指定常数 $\\alpha = 1.5$ 和 $\\beta = 0.5$。噪声服从正态分布，$\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$，其方差 $\\sigma^2$ 是模拟的参数之一。\n\n我们比较两个模型：一个次数为 $d_s$ 的“简单”多项式回归模型和一个次数为 $d_c$ 的“复杂”模型，其中 $d_c > d_s$。对于每个大小为 $n$ 的训练数据集，我们通过最小化残差平方和（普通最小二乘法）来拟合模型 $\\hat{f}_{d_s}(x)$ 和 $\\hat{f}_{d_c}(x)$。\n\n对于提供的三个测试用例中的每一个，模拟协议都执行 $B=200$ 次蒙特卡洛重复实验。每次重复实验包括以下步骤：\n1.  **数据生成**：根据指定的数据生成过程，创建一个新的大小为 $n$ 的训练数据集 $\\{(x_i, y_i)\\}_{i=1}^n$。\n2.  **模型拟合与评估**：对于每个次数 $d \\in \\{d_s, d_c\\}$：\n    -   将多项式模型 $\\hat{f}_d(x)$ 拟合到训练数据上。\n    -   **训练均方误差 (MSE)** 计算为 $\\mathrm{MSE}_{\\text{train}} = \\frac{1}{n}\\sum_{i=1}^{n}\\left(y_i - \\hat{f}_d(x_i)\\right)^2$。这衡量了模型对其训练数据的拟合程度。\n    -   使用 **K 折交叉验证 (CV)** 来估计期望测试 MSE，其中 $K=5$。训练集被划分为 $K$ 个不相交的子集（折）。对于每一折，在其余的 $K-1$ 折上训练一个模型，并在留出的那一折上进行测试。CV 误差 $\\mathrm{MSE}_{\\text{CV}}$ 是这 $K$ 个验证折的 MSE 的平均值。该指标为模型在未见数据上的泛化性能提供了一个更稳健的估计。\n\n3.  **显式方差估计**：模型本身的方差是偏差-方差权衡的一个关键组成部分。我们通过蒙特卡洛模拟直接估计它。在域 $[-1,1]$ 上建立一个包含 $m=201$ 个点的固定网格 $\\{x_j\\}_{j=1}^m$。对于每次重复实验 $b$ 和每个模型次数 $d$，我们在此网格上计算预测值 $\\hat{f}_d^{(b)}(x_j)$。估计器在点 $x_j$ 处的方差通过该点在所有 $B$ 次重复实验中的预测值的样本方差来估计。然后通过对整个网格上的这些逐点方差估计值求平均，计算出模型方差的单一标量摘要 $V_d$：$V_d = \\frac{1}{m} \\sum_{j=1}^m \\widehat{\\mathrm{Var}}\\left(\\hat{f}_d(x_j)\\right)$。\n\n在所有 $B$ 次重复实验完成后，将收集到的指标进行平均，以得出简单模型和复杂模型的 $\\overline{\\mathrm{MSE}}_{\\text{train}}$、$\\overline{\\mathrm{MSE}}_{\\text{CV}}$ 和聚合方差项 $V_d$。\n\n最后，为每个测试用例计算一个**过拟合表现指标**。当且仅当以下三个条件同时满足时，此二元指标设置为 $1$ (true)，否则设置为 $0$ (false)：\n1.  $\\overline{\\mathrm{MSE}}_{\\text{train}, d_c}  \\overline{\\mathrm{MSE}}_{\\text{train}, d_s}$：复杂模型在训练数据上实现了更低的误差。\n2.  $\\overline{\\mathrm{MSE}}_{\\text{CV}, d_c} > \\overline{\\mathrm{MSE}}_{\\text{CV}, d_s}$：复杂模型表现出更高的估计测试误差，表明泛化能力差（过拟合）。\n3.  $V_{d_c} > V_{d_s}$：复杂模型比简单模型更具变异性（稳定性更差）。\n\n此结构化分析应用于三个不同的测试用例，以探究模型在不同样本量和噪声水平条件下的行为。实施过程将系统地执行此模拟 design，并报告生成的指标值列表。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Runs a simulation study to demonstrate the bias-variance tradeoff\n    and computes an overfitting indicator for three test cases.\n    \"\"\"\n    # Set a random seed for reproducibility of the simulation results.\n    np.random.seed(42)\n\n    # --- Simulation parameters from the problem statement ---\n    B = 200      # Number of Monte Carlo replicates\n    m = 201      # Number of grid points for variance estimation\n    K = 5        # Number of folds for cross-validation\n    alpha = 1.5  # Parameter for the true function f(x)\n    beta = 0.5   # Parameter for the true function f(x)\n\n    # Test cases: (n, sigma, d_s, d_c)\n    test_cases = [\n        (60, 0.5, 3, 18),   # Case A: Canonical overfitting scenario\n        (400, 0.5, 3, 18),  # Case B: Large sample size scenario\n        (60, 0.0, 3, 18),   # Case C: Noise-free scenario\n    ]\n\n    def calculate_cv_mse(x, y, d, k_folds):\n        \"\"\"\n        Calculates the K-fold cross-validation MSE for a polynomial model.\n        \"\"\"\n        fold_mses = []\n        n_samples = len(x)\n        indices = np.arange(n_samples)\n        \n        # Shuffle indices to ensure random distribution of data across folds.\n        np.random.shuffle(indices)\n        \n        # Split indices into k_folds.\n        fold_indices = np.array_split(indices, k_folds)\n\n        for k in range(k_folds):\n            val_idx = fold_indices[k]\n            train_idx = np.concatenate([fold_indices[i] for i in range(k_folds) if i != k])\n\n            x_fold_train, y_fold_train = x[train_idx], y[train_idx]\n            x_fold_val, y_fold_val = x[val_idx], y[val_idx]\n\n            # Fit model on the training part of the fold.\n            # numpy might issue a RankWarning for high-degree polynomials, \n            # which is expected and can be ignored for this problem.\n            coeffs = np.polyfit(x_fold_train, y_fold_train, d)\n            \n            # Predict on the validation part.\n            y_pred_val = np.polyval(coeffs, x_fold_val)\n\n            # Calculate and store MSE for the fold.\n            fold_mse = np.mean((y_fold_val - y_pred_val)**2)\n            fold_mses.append(fold_mse)\n        \n        return np.mean(fold_mses)\n\n    final_results = []\n\n    for case in test_cases:\n        n, sigma, d_s, d_c = case\n\n        # Accumulators for metrics over B replicates\n        train_mses_s, train_mses_c = [], []\n        cv_mses_s, cv_mses_c = [], []\n        \n        # Grid for variance estimation\n        grid = np.linspace(-1, 1, m)\n        \n        # Storage for predictions on the grid across all replicates\n        all_preds_s = np.zeros((B, m))\n        all_preds_c = np.zeros((B, m))\n\n        for b in range(B):\n            # 1. Generate data for the current replicate\n            x_train = np.random.uniform(-1, 1, n)\n            y_true = alpha * np.sin(np.pi * x_train) + beta * x_train\n            if sigma  0:\n                noise = np.random.normal(0, sigma, n)\n                y_train = y_true + noise\n            else:\n                y_train = y_true\n\n            # 2. Process simple model (degree d_s)\n            coeffs_s = np.polyfit(x_train, y_train, d_s)\n            y_pred_train_s = np.polyval(coeffs_s, x_train)\n            train_mses_s.append(np.mean((y_train - y_pred_train_s)**2))\n            cv_mses_s.append(calculate_cv_mse(x_train, y_train, d_s, K))\n            all_preds_s[b, :] = np.polyval(coeffs_s, grid)\n\n            # 3. Process complex model (degree d_c)\n            coeffs_c = np.polyfit(x_train, y_train, d_c)\n            y_pred_train_c = np.polyval(coeffs_c, x_train)\n            train_mses_c.append(np.mean((y_train - y_pred_train_c)**2))\n            cv_mses_c.append(calculate_cv_mse(x_train, y_train, d_c, K))\n            all_preds_c[b, :] = np.polyval(coeffs_c, grid)\n\n        # 4. Aggregate results across B replicates\n        avg_train_mse_s = np.mean(train_mses_s)\n        avg_train_mse_c = np.mean(train_mses_c)\n        avg_cv_mse_s = np.mean(cv_mses_s)\n        avg_cv_mse_c = np.mean(cv_mses_c)\n\n        # Calculate variance summary V_d using sample variance (ddof=1)\n        V_s = np.mean(np.var(all_preds_s, axis=0, ddof=1))\n        V_c = np.mean(np.var(all_preds_c, axis=0, ddof=1))\n        \n        # 5. Apply the overfitting manifestation indicator logic\n        cond1 = avg_train_mse_c  avg_train_mse_s\n        cond2 = avg_cv_mse_c  avg_cv_mse_s\n        cond3 = V_c  V_s\n        \n        indicator = 1 if (cond1 and cond2 and cond3) else 0\n        final_results.append(indicator)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```", "id": "4897610"}, {"introduction": "在理解了偏差-方差权衡之后，下一步是学习如何使用交叉验证（CV）来可靠地估计模型的泛化误差。然而，一个常见的陷阱——“数据泄漏”——可能会完全破坏这一过程的有效性。这个练习揭示了一个在实践中至关重要的教训：在交叉验证循环之外使用整个数据集进行特征选择，会导致对模型性能的严重过度乐观的估计。通过分析推导这种偏差，您将深刻理解为何必须将包括特征选择在内的所有模型构建步骤都严格置于交叉验证的框架之内。[@problem_id:4897575]", "problem": "一个生物统计学团队正在评估一个用于预测标准化数量表型的线性预测器。对于每个受试者 $i \\in \\{1,\\dots,n\\}$ 和每个生物标志物 $j \\in \\{1,\\dots,p\\}$，假设在一个没有真实关联的零模型下，数据生成过程如下：\n- $y_i \\sim \\mathcal{N}(0,1)$，对所有 $i$ 独立。\n- $x_{ij} \\sim \\mathcal{N}(0,1)$，对所有 $i$ 和 $j$ 独立，且与 $y_i$ 独立。\n\n他们错误地在模型评估之前，使用完整数据集执行特征选择，步骤如下。\n- 步骤 $1$（在完整数据上进行有信息泄露的特征选择）：对完整数据集中的每个生物标志物 $j$，计算样本相关性 $r_j = \\frac{1}{n}\\sum_{i=1}^{n} x_{ij} y_i$，并选择绝对相关性最大的单个生物标志物 $j^{\\star}$，即 $j^{\\star} \\in \\arg\\max_{1 \\leq j \\leq p} |r_j|$。\n- 步骤 $2$（通过交叉验证重用已选特征进行评估）：通过留一法交叉验证（LOOCV）估计均方预测误差，在每一折中，在大小为 $n-1$ 的训练集上重新拟合不带截距项的普通最小二乘法，为固定的生物标志物 $x_{ij^{\\star}}$ 获得系数 $\\hat{\\beta}_{(-i)}$，并为留出的受试者 $i$ 预测 $\\hat{y}_i = \\hat{\\beta}_{(-i)} x_{ij^{\\star}}$。\n\n令 $\\widehat{\\mathrm{MSE}}_{\\mathrm{LOOCV, leak}}$ 表示由上述易泄露过程产生的LOOCV均方误差估计值，并令 $\\mathrm{MSE}_{\\mathrm{test}}$ 表示当该过程在 $n$ 个观测值上训练后应用于一个新的独立受试者时（仍然使用如上所述在全部 $n$ 个训练观测值上选择的特征 $j^{\\star}$）的真实期望均方预测误差。定义偏差\n$$\nB(n,p) \\equiv \\mathbb{E}\\!\\left[\\widehat{\\mathrm{MSE}}_{\\mathrm{LOOCV, leak}}\\right] \\;-\\; \\mathbb{E}\\!\\left[\\mathrm{MSE}_{\\mathrm{test}}\\right].\n$$\n\n假设 $n$ 很大，$p$ 可能随 $n$ 增长且满足 $\\ln p = o(n)$，并忽略所有比 $\\frac{\\ln p}{n}$ 低阶的项。从基本定义和标准大样本近似出发，推导在所述零模型下 $B(n,p)$ 作为 $n$ 和 $p$ 的函数的主阶渐近表达式。请以单个闭式解析表达式的形式提供您的答案。不需要四舍五入，也不需要单位。", "solution": "用户希望找到偏差 $B(n,p) = \\mathbb{E}[\\widehat{\\mathrm{MSE}}_{\\mathrm{LOOCV, leak}}] - \\mathbb{E}[\\mathrm{MSE}_{\\text{test}}]$ 的主阶渐近表达式。我们将分别推导这两个期望的表达式，然后计算它们的差值。\n\n### 步骤1：初步定义和近似\n\n令 $X$ 为 $n \\times p$ 的生物标志物数据矩阵，$y$ 为 $n \\times 1$ 的表型数据向量。元素 $x_{ij}$ 和 $y_i$ 是独立同分布的 $\\mathcal{N}(0,1)$。\n生物标志物 $j$ 的样本相关性是 $r_j = \\frac{1}{n}\\sum_{i=1}^{n} x_{ij} y_i$。令 $C_j = \\sum_{i=1}^{n} x_{ij} y_i = n r_j$。\n预测变量 $j$ 的平方和是 $S_j = \\sum_{i=1}^{n} x_{ij}^2$。根据大数定律，当 $n$ 很大时，$S_j/n \\to \\mathbb{E}[x_{ij}^2] = 1$。我们将使用近似 $S_j \\approx n$。这对所有 $j$ 都成立，包括被选中的 $j^{\\star}$。\n特征选择规则是 $j^{\\star} = \\arg\\max_{1 \\leq j \\leq p} |r_j| = \\arg\\max_{1 \\leq j \\leq p} |C_j|$。\n\n为了分析选择过程，我们定义归一化变量 $\\tilde{r}_j = C_j / \\sqrt{S_j}$。在给定 $X$ 的条件下，每个 $\\tilde{r}_j$ 都是独立同分布标准正态变量 $y_i$ 的线性组合：$\\tilde{r}_j = \\sum_i (x_{ij}/\\sqrt{S_j}) y_i$。因此，$\\mathbb{E}[\\tilde{r}_j|X] = 0$ 且 $\\mathrm{Var}(\\tilde{r}_j|X) = \\sum_i (x_{ij}/\\sqrt{S_j})^2 \\mathrm{Var}(y_i) = S_j/S_j = 1$。所以，$\\tilde{r}_j | X \\sim \\mathcal{N}(0,1)$。\n协方差是 $\\mathrm{Cov}(\\tilde{r}_j, \\tilde{r}_k|X) = \\frac{\\sum_i x_{ij}x_{ik}}{\\sqrt{S_j S_k}}$，当 $n$ 很大时，对于 $j \\neq k$，它收敛于 $0$。因此，当 $n$ 很大时，变量 $\\{\\tilde{r}_j\\}_{j=1}^p$ 可以被视为独立同分布的 $\\mathcal{N}(0,1)$ 随机变量。\n\n选择规则 $j^{\\star} = \\arg\\max_j |C_j| = \\arg\\max_j |\\sqrt{S_j} \\tilde{r}_j|$ 近似等价于 $j^{\\star} \\approx \\arg\\max_j |\\tilde{r}_j|$，因为对所有 $j$ 都有 $S_j \\approx n$。令 $M_p^2 = \\max_{1 \\leq j \\leq p} \\tilde{r}_j^2$。当 $p$ 很大时，$p$ 个独立同分布的 $\\chi^2(1)$ 变量的最大值的期望可以很好地近似为 $\\mathbb{E}[M_p^2] \\approx 2 \\ln p$。\n\n### 步骤2：$\\mathbb{E}[\\mathrm{MSE}_{\\text{test}}]$ 的推导\n\n真实的测试误差 $\\mathrm{MSE}_{\\text{test}}$ 是对于一个从相同分布中抽样的新受试者 $(x_{\\text{new}}, y_{\\text{new}})$（该受试者独立于训练数据）的期望平方预测误差。预测值为 $\\hat{y}_{\\text{new}} = \\hat{\\beta} x_{\\text{new}, j^{\\star}}$，其中 $\\hat{\\beta}$ 是从大小为 $n$ 的完整训练集上估计出的普通最小二乘（OLS）系数。\n$$\n\\mathrm{MSE}_{\\text{test}} = \\mathbb{E}_{\\text{new}}[(y_{\\text{new}} - \\hat{\\beta} x_{\\text{new}, j^{\\star}})^2 | X, y]\n$$\n展开此式并利用新受试者的独立性（$\\mathbb{E}[y_{\\text{new}}] = 0$，$\\mathbb{E}[y_{\\text{new}}^2]=1$，$\\mathbb{E}[x_{\\text{new}, j^{\\star}}^2]=1$）：\n$$\n\\mathrm{MSE}_{\\text{test}} = \\mathbb{E}_{\\text{new}}[y_{\\text{new}}^2] - 2\\hat{\\beta}\\mathbb{E}_{\\text{new}}[y_{\\text{new}}x_{\\text{new}, j^{\\star}}] + \\hat{\\beta}^2\\mathbb{E}_{\\text{new}}[x_{\\text{new}, j^{\\star}}^2] = 1 - 0 + \\hat{\\beta}^2 = 1 + \\hat{\\beta}^2\n$$\n不带截距项的OLS估计是 $\\hat{\\beta} = \\frac{\\sum_i x_{ij^{\\star}}y_i}{\\sum_i x_{ij^{\\star}}^2} = \\frac{C_{j^{\\star}}}{S_{j^{\\star}}}$。\n因此，$\\mathrm{MSE}_{\\text{test}} = 1 + \\frac{C_{j^{\\star}}^2}{S_{j^{\\star}}^2}$。\n我们需要计算在训练数据分布上的期望：\n$$\n\\mathbb{E}[\\mathrm{MSE}_{\\text{test}}] = 1 + \\mathbb{E}\\left[\\frac{C_{j^{\\star}}^2}{S_{j^{\\star}}^2}\\right]\n$$\n使用近似 $S_{j^{\\star}} \\approx n$：\n$$\n\\mathbb{E}[\\mathrm{MSE}_{\\text{test}}] \\approx 1 + \\frac{1}{n^2}\\mathbb{E}[C_{j^{\\star}}^2]\n$$\n我们有 $C_{j^{\\star}} = \\sqrt{S_{j^{\\star}}} \\tilde{r}_{j^{\\star}}$，其中 $|\\tilde{r}_{j^{\\star}}|^2 \\approx M_p^2$。所以，$\\mathbb{E}[C_{j^{\\star}}^2] = \\mathbb{E}[S_{j^{\\star}} \\tilde{r}_{j^{\\star}}^2] \\approx \\mathbb{E}[S_{j^{\\star}}] \\mathbb{E}[\\tilde{r}_{j^{\\star}}^2] \\approx n \\mathbb{E}[M_p^2]$。\n使用 $\\mathbb{E}[M_p^2] \\approx 2 \\ln p$，我们得到 $\\mathbb{E}[C_{j^{\\star}}^2] \\approx 2n \\ln p$。\n将此代入期望测试误差的表达式中：\n$$\n\\mathbb{E}[\\mathrm{MSE}_{\\text{test}}] \\approx 1 + \\frac{1}{n^2}(2n \\ln p) = 1 + \\frac{2 \\ln p}{n}\n$$\n\n### 步骤3：$\\mathbb{E}[\\widehat{\\mathrm{MSE}}_{\\mathrm{LOOCV, leak}}]$ 的推导\n\nLOOCV误差估计值为 $\\widehat{\\mathrm{MSE}}_{\\mathrm{LOOCV, leak}} = \\frac{1}{n}\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$，其中 $\\hat{y}_i = \\hat{\\beta}_{(-i)} x_{ij^{\\star}}$。\nOLS的一个标准结果将LOOCV残差与完整模型拟合的残差联系起来。对于无截距项模型，这个恒等式是：\n$$\ny_i - \\hat{y}_i = \\frac{y_i - \\hat{\\beta} x_{ij^{\\star}}}{1 - h_{ii}}\n$$\n其中 $h_{ii}$ 是帽子矩阵 $H = x_{j^{\\star}}(x_{j^{\\star}}^Tx_{j^{\\star}})^{-1}x_{j^{\\star}}^T$ 的第 $i$ 个对角元素。\n$h_{ii} = \\frac{x_{ij^{\\star}}^2}{\\sum_{k=1}^n x_{kj^{\\star}}^2} = \\frac{x_{ij^{\\star}}^2}{S_{j^{\\star}}}$。\n当 $n$ 很大时，$S_{j^{\\star}} \\approx n$，所以 $h_{ii} = O_p(1/n)$。\nLOOCV估计值可以写为：\n$$\n\\widehat{\\mathrm{MSE}}_{\\mathrm{LOOCV, leak}} = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{(y_i - \\hat{\\beta}x_{ij^{\\star}})^2}{(1-h_{ii})^2}\n$$\n令 $\\widehat{\\mathrm{MSE}}_{\\text{in}} = \\frac{1}{n}\\sum_{i=1}^n (y_i - \\hat{\\beta}x_{ij^{\\star}})^2$ 为样本内（训练）均方误差（MSE）。使用展开式 $(1-h_{ii})^{-2} = 1 + 2h_{ii} + O_p(h_{ii}^2)$：\n$$\n\\widehat{\\mathrm{MSE}}_{\\mathrm{LOOCV, leak}} \\approx \\frac{1}{n}\\sum_{i=1}^{n} (y_i - \\hat{\\beta}x_{ij^{\\star}})^2(1+2h_{ii}) = \\widehat{\\mathrm{MSE}}_{\\text{in}} + \\frac{2}{n}\\sum_{i=1}^{n} (y_i - \\hat{\\beta}x_{ij^{\\star}})^2 h_{ii}\n$$\n首先，我们计算样本内MSE的期望：\n$$\n\\mathbb{E}[\\widehat{\\mathrm{MSE}}_{\\text{in}}] = \\mathbb{E}\\left[\\frac{1}{n}\\sum_i(y_i - \\hat{\\beta}x_{ij^{\\star}})^2\\right] = \\frac{1}{n}\\mathbb{E}\\left[\\sum_i y_i^2 - \\hat{\\beta}^2 S_{j^{\\star}}\\right]\n$$\n这利用了OLS残差的正交性。$\\mathbb{E}[\\sum y_i^2]=n$。\n$\\hat{\\beta}^2 S_{j^{\\star}} = (\\frac{C_{j^{\\star}}}{S_{j^{\\star}}})^2 S_{j^{\\star}} = \\frac{C_{j^{\\star}}^2}{S_{j^{\\star}}}$。\n$\\mathbb{E}[\\widehat{\\mathrm{MSE}}_{\\text{in}}] = \\frac{1}{n}\\left(n - \\mathbb{E}\\left[\\frac{C_{j^{\\star}}^2}{S_{j^{\\star}}}\\right]\\right) = 1 - \\frac{1}{n}\\mathbb{E}\\left[\\frac{C_{j^{\\star}}^2}{S_{j^{\\star}}}\\right]$。\n如前所述，$\\frac{C_{j^{\\star}}^2}{S_{j^{\\star}}} \\approx M_p^2$，所以 $\\mathbb{E}[\\frac{C_{j^{\\star}}^2}{S_{j^{\\star}}}] \\approx 2 \\ln p$。\n因此，期望的样本内误差是高度乐观的：\n$$\n\\mathbb{E}[\\widehat{\\mathrm{MSE}}_{\\text{in}}] \\approx 1 - \\frac{2 \\ln p}{n}\n$$\n接下来，考虑修正项 $\\frac{2}{n}\\mathbb{E}[\\sum_i (y_i - \\hat{\\beta}x_{ij^{\\star}})^2 h_{ii}]$。根据对称性，这等于 $2\\mathbb{E}[(y_1 - \\hat{\\beta}x_{1j^{\\star}})^2 h_{11}]$。\n$h_{11} = x_{1j^{\\star}}^2/S_{j^{\\star}} \\approx x_{1j^{\\star}}^2/n$。该项为 $\\frac{2}{n}\\mathbb{E}[(y_1 - \\hat{\\beta}x_{1j^{\\star}})^2 x_{1j^{\\star}}^2]$。\n当 $n$ 很大时，$\\hat{\\beta} = O_p(\\sqrt{\\ln p / n})$ 趋向于 $0$。因此，$y_1 - \\hat{\\beta}x_{1j^{\\star}} \\approx y_1$。期望变为 $\\frac{2}{n}\\mathbb{E}[y_1^2 x_{1j^{\\star}}^2]$。由于 $y_1$ 和 $x_{1j^{\\star}}$ 是独立的标准正态变量（对于任何单行，选择 $j^{\\star}$ 是一个小概率事件），$\\mathbb{E}[y_1^2 x_{1j^{\\star}}^2] = \\mathbb{E}[y_1^2]\\mathbb{E}[x_{1j^{\\star}}^2]=1$。\n所以修正项大约是 $2/n$。\n合并期望的LOOCV误差的各项：\n$$\n\\mathbb{E}[\\widehat{\\mathrm{MSE}}_{\\mathrm{LOOCV, leak}}] \\approx \\mathbb{E}[\\widehat{\\mathrm{MSE}}_{\\text{in}}] + \\frac{2}{n} \\approx \\left(1 - \\frac{2 \\ln p}{n}\\right) + \\frac{2}{n}\n$$\n\n### 步骤4：偏差 $B(n,p)$ 的计算\n\n偏差是两个推导出的期望之差。\n$$\nB(n,p) = \\mathbb{E}[\\widehat{\\mathrm{MSE}}_{\\mathrm{LOOCV, leak}}] - \\mathbb{E}[\\mathrm{MSE}_{\\text{test}}]\n$$\n代入推导出的表达式：\n$$\nB(n,p) \\approx \\left(1 - \\frac{2 \\ln p}{n} + \\frac{2}{n}\\right) - \\left(1 + \\frac{2 \\ln p}{n}\\right)\n$$\n$$\nB(n,p) \\approx -\\frac{4 \\ln p}{n} + \\frac{2}{n}\n$$\n问题要求的是主阶渐近表达式，并忽略比 $\\frac{\\ln p}{n}$ 低阶的项。假设 $p$ 足够大或随 $n$ 增长以至于 $\\ln p \\to \\infty$，那么 $\\frac{2}{n}$ 项比 $\\frac{4 \\ln p}{n}$ 项是低阶的。因此我们将其舍去。\n偏差的主阶渐近表达式是：\n$$\nB(n,p) \\approx -\\frac{4 \\ln p}{n}\n$$\n这个负偏差表明，存在信息泄露的交叉验证过程是显著乐观的，它低估了真实的预测误差，这是由于在交叉验证之前对完整数据集执行了特征选择所导致的。", "answer": "$$\n\\boxed{-\\frac{4 \\ln(p)}{n}}\n$$", "id": "4897575"}, {"introduction": "真实世界的生物统计学问题往往超越了简单的均方误差回归。这个练习将挑战您为一个常见的临床场景设计一个完整的解决方案：在一个不平衡的病例对照研究中，根据特定的临床目标来优化一个分类器。您需要从基本定义出发，设计一个稳健的分层重复交叉验证方案，并推导出一个自定义的惩罚损失函数，以在满足特定特异性要求的同时最大化灵敏度。这项任务将您的技能从理解标准程序提升到为复杂目标量身定制评估和调优策略。[@problem_id:4897592]", "problem": "一个生物统计学团队正在为一项非平衡病例-对照研究构建一个二元风险分类器，其中病例表示为 $Y=1$，对照表示为 $Y=0$。对于每个受试者 $i \\in \\{1,\\dots,n\\}$，一个模型会产生一个实值分数 $\\hat f(X_i)$，该分数旨在使病例的分数高于对照。分类器将通过在一个可调阈值 $\\tau \\in \\mathbb{R}$ 处对该分数进行阈值处理来实现，规则为：如果 $\\hat f(X_i) \\ge \\tau$，则预测为 $1$，否则预测为 $0$。临床目标是选择 $\\tau$ 以在特异性至少达到目标值 $\\alpha \\in (0,1)$ 的约束下最大化敏感性。该团队希望使用分层重复 $K$ 折交叉验证 (CV) 来评估性能和调整 $\\tau$，其中有 $K \\in \\{2,3,\\dots\\}$ 折和 $R \\in \\{1,2,\\dots\\}$ 次独立重复。\n\n从敏感性和特异性的定义以及 $K$ 折交叉验证的定义出发，设计一个适用于非平衡病例-对照数据的分层重复 CV 方案，该方案仅使用折外预测，并以控制方差的方式汇总各次重复的性能评估。然后，仅使用这些基本定义并避免任何样本内重用，推导一个适用于阈值调整的经验损失函数 $\\widehat{L}(\\tau)$，该函数通过一个单边线性惩罚来编码“在特异性至少为 $\\alpha$ 的约束下最大化敏感性”这一目标，当满足特异性约束时，该惩罚为零，而在违反约束时，该惩罚随不足量线性增加。您的损失函数必须用指示函数、来自重复分层 $K$ 折 CV 方案的折外预测、以及量 $n$、$K$、$R$ 和 $\\alpha$，连同一个控制约束强度的惩罚权重 $\\lambda0$ 来明确表示。\n\n假设与约定：\n- 对于每次重复 $r \\in \\{1,\\dots,R\\}$，将数据索引 $\\{1,\\dots,n\\}$ 划分为 $K$ 个折，并在 $Y$ 上进行分层，以便每个折尽可能地保持经验类别比例。对于重复 $r$ 中验证折内的每个受试者 $i$，令 $\\hat f^{(-i,r)}(X_i)$ 表示在重复 $r$ 中使用 $K-1$ 个训练折（排除包含 $i$ 的折）训练模型并在 $X_i$ 上进行预测所产生的分数。\n- 使用所有重复中所有折外预测的微观平均汇总来评估敏感性和特异性。\n- 在评估折外预测时，使用分类规则“当且仅当 $\\hat f^{(-i,r)}(X_i) \\ge \\tau$ 时预测为 $1$”。\n\n请提供您的最终答案，作为交叉验证的惩罚损失 $\\widehat{L}(\\tau)$ 的单个闭式解析表达式，使用 $\\mathbb{1}\\{\\cdot\\}$ 表示指示函数，并使用 $(x)_{+}=\\max\\{x,0\\}$。无需进行数值计算，也无单位适用。", "solution": "该问题是有效的，因为它具有科学依据、是适定的且客观的。它提出了生物统计建模中一个标准但并非微不足道的任务：基于分层重复交叉验证的性能评估，推导用于调整分类器阈值的惩罚损失函数。所有定义和约束都清晰、一致，并足以推导出唯一的解析解。\n\n该解分三步进行。首先，我们概述指定的分层重复交叉验证 (CV) 和汇总方案。其次，我们基于此方案的折外预测，将敏感性和特异性的微观平均评估形式化。最后，我们构建惩罚经验损失函数 $\\widehat{L}(\\tau)$，该函数编码了指定的优化目标。\n\n**第 1 步：分层重复 K 折交叉验证方案**\n\n问题要求一个分层重复 $K$ 折 CV 方案。此过程旨在产生可靠的样本外性能评估，尤其是在数据不平衡的情况下。设 $n$ 为受试者总数，其中有 $N_1 = \\sum_{i=1}^n \\mathbb{1}\\{Y_i=1\\}$ 个病例 ($Y=1$) 和 $N_0 = \\sum_{i=1}^n \\mathbb{1}\\{Y_i=0\\}$ 个对照 ($Y=0$)。\n\n该过程如下：\n1.  整个过程重复 $R$ 次，由 $r \\in \\{1,\\dots,R\\}$ 索引。每次重复都涉及对数据进行一次新的、独立的随机划分。\n2.  对于每次重复 $r$，包含 $n$ 个受试者的数据集被划分为 $K$ 个不相交的折。该划分按结果变量 $Y$ 进行分层。这确保了 $K$ 个折中的每一个都具有与完整数据集大致相同的病例和对照比例，即每个折大约包含 $N_1/K$ 个病例和 $N_0/K$ 个对照。\n3.  对于重复 $r$ 中的每个折 $k \\in \\{1,\\dots,K\\}$，该折中的受试者被指定为验证集，而其余 $K-1$ 个折中的受试者构成训练集。\n4.  在训练集上训练一个模型。然后用该模型为相应验证集中的每个受试者 $i$ 生成一个实值分数 $\\hat f(X_i)$。根据问题的符号表示，我们将受试者 $i$ 在重复 $r$ 中的这个折外分数表示为 $\\hat f^{(-i,r)}(X_i)$。\n5.  在所有 $R$ 次重复中的所有 $K$ 个折上完成此过程后，我们总共获得 $n \\times R$ 个折外预测。对于每个受试者 $i$，有 $R$ 个预测，即 $\\{\\hat f^{(-i,1)}(X_i), \\dots, \\hat f^{(-i,R)}(X_i)\\}$，每次重复产生一个。\n\n**第 2 步：微观平均性能指标**\n\n问题指定了微观平均汇总。这意味着我们在计算性能指标之前，汇集所有 $n \\times R$ 个折外预测及其真实标签。这等同于对所有预测的真阳性 (TP)、真阴性 (TN)、假阳性 (FP) 和假阴性 (FN) 的计数求和。\n\n对于给定的阈值 $\\tau$，分类规则是如果受试者的分数大于或等于 $\\tau$，则将其预测为病例 (1)。\n- 预测为阳性：$\\hat f^{(-i,r)}(X_i) \\ge \\tau$\n- 预测为阴性：$\\hat f^{(-i,r)}(X_i)  \\tau$\n\n我们可以通过对所有受试者 $i \\in \\{1,\\dots,n\\}$ 和所有重复 $r \\in \\{1,\\dots,R\\}$ 求和，将 TP、FN、TN 和 FP 的总计数定义为 $\\tau$ 的函数：\n- 总真阳性数：$\\text{TP}(\\tau) = \\sum_{r=1}^R \\sum_{i=1}^n \\mathbb{1}\\{Y_i=1 \\text{ and } \\hat f^{(-i,r)}(X_i) \\ge \\tau\\} = \\sum_{r=1}^R \\sum_{i=1}^n \\mathbb{1}\\{Y_i=1\\}\\mathbb{1}\\{\\hat f^{(-i,r)}(X_i) \\ge \\tau\\}$\n- 总真阴性数：$\\text{TN}(\\tau) = \\sum_{r=1}^R \\sum_{i=1}^n \\mathbb{1}\\{Y_i=0 \\text{ and } \\hat f^{(-i,r)}(X_i)  \\tau\\} = \\sum_{r=1}^R \\sum_{i=1}^n \\mathbb{1}\\{Y_i=0\\}\\mathbb{1}\\{\\hat f^{(-i,r)}(X_i)  \\tau\\}$\n\n所有重复中的病例实例总数为 $R \\cdot N_1 = R \\sum_{j=1}^n \\mathbb{1}\\{Y_j=1\\}$。\n所有重复中的对照实例总数为 $R \\cdot N_0 = R \\sum_{j=1}^n \\mathbb{1}\\{Y_j=0\\}$。\n\n微观平均敏感性 $\\widehat{\\text{Sens}}(\\tau)$ 是总真阳性数与总实际阳性数的比率：\n$$ \\widehat{\\text{Sens}}(\\tau) = \\frac{\\text{TP}(\\tau)}{R \\sum_{j=1}^n \\mathbb{1}\\{Y_j=1\\}} = \\frac{\\sum_{r=1}^R \\sum_{i=1}^n \\mathbb{1}\\{Y_i=1\\}\\mathbb{1}\\{\\hat f^{(-i,r)}(X_i) \\ge \\tau\\}}{R \\sum_{j=1}^n \\mathbb{1}\\{Y_j=1\\}} $$\n微观平均特异性 $\\widehat{\\text{Spec}}(\\tau)$ 是总真阴性数与总实际阴性数的比率：\n$$ \\widehat{\\text{Spec}}(\\tau) = \\frac{\\text{TN}(\\tau)}{R \\sum_{j=1}^n \\mathbb{1}\\{Y_j=0\\}} = \\frac{\\sum_{r=1}^R \\sum_{i=1}^n \\mathbb{1}\\{Y_i=0\\}\\mathbb{1}\\{\\hat f^{(-i,r)}(X_i)  \\tau\\}}{R \\sum_{j=1}^n \\mathbb{1}\\{Y_j=0\\}} $$\n\n**第 3 步：惩罚损失函数的推导**\n\n目标是在特异性至少为 $\\alpha$ 的约束下最大化敏感性。这是一个约束优化问题。我们可以通过最小化一个惩罚损失函数将其重新表述为一个无约束问题。最大化敏感性等价于最小化负敏感性。约束条件为 $\\widehat{\\text{Spec}}(\\tau) \\ge \\alpha$。当此约束被违反时，即当 $\\widehat{\\text{Spec}}(\\tau)  \\alpha$ 时，应施加惩罚。\n\n损失函数 $\\widehat{L}(\\tau)$ 将具有以下形式：\n$$ \\widehat{L}(\\tau) = (\\text{目标项}) + (\\text{惩罚项}) $$\n目标项对应于最小化负敏感性：$-\\widehat{\\text{Sens}}(\\tau)$。\n当 $\\alpha - \\widehat{\\text{Spec}}(\\tau)  0$ 时，惩罚项被激活。问题要求对不足量施加线性惩罚，因此惩罚项为 $\\lambda \\cdot \\max\\{0, \\alpha - \\widehat{\\text{Spec}}(\\tau)\\}$，其中 $\\lambda  0$ 是一个惩罚权重。使用符号 $(x)_+ = \\max\\{x,0\\}$，这可以表示为 $\\lambda (\\alpha - \\widehat{\\text{Spec}}(\\tau))_+$。\n\n因此，损失函数为：\n$$ \\widehat{L}(\\tau) = -\\widehat{\\text{Sens}}(\\tau) + \\lambda (\\alpha - \\widehat{\\text{Spec}}(\\tau))_+ $$\n使用假阳性率 (FPR) 通常更为方便，其中 $\\text{Spec} = 1 - \\text{FPR}$。约束 $\\widehat{\\text{Spec}}(\\tau) \\ge \\alpha$ 等价于 $1 - \\widehat{\\text{FPR}}(\\tau) \\ge \\alpha$，或 $\\widehat{\\text{FPR}}(\\tau) \\le 1-\\alpha$。\n惩罚项可以用 FPR 重写：\n$$ (\\alpha - \\widehat{\\text{Spec}}(\\tau))_+ = (\\alpha - (1 - \\widehat{\\text{FPR}}(\\tau)))_+ = (\\widehat{\\text{FPR}}(\\tau) - (1-\\alpha))_+ $$\n估计的假阳性率 $\\widehat{\\text{FPR}}(\\tau)$ 是被错误分类为病例的对照的比例：\n$$ \\widehat{\\text{FPR}}(\\tau) = \\frac{\\text{FP}(\\tau)}{R \\sum_{j=1}^n \\mathbb{1}\\{Y_j=0\\}} = \\frac{\\sum_{r=1}^R \\sum_{i=1}^n \\mathbb{1}\\{Y_i=0\\}\\mathbb{1}\\{\\hat f^{(-i,r)}(X_i) \\ge \\tau\\}}{R \\sum_{j=1}^n \\mathbb{1}\\{Y_j=0\\}} $$\n这种形式在计算上更直接，因为它和敏感性一样，依赖于对超过阈值 $\\tau$ 的分数进行计数。\n\n代入 $-\\widehat{\\text{Sens}}(\\tau)$ 和基于 FPR 的惩罚项的表达式，我们得到经验损失函数 $\\widehat{L}(\\tau)$ 的最终表达式：\n$$ \\widehat{L}(\\tau) = - \\frac{\\sum_{r=1}^R \\sum_{i=1}^n \\mathbb{1}\\{Y_i=1\\}\\mathbb{1}\\{\\hat f^{(-i,r)}(X_i) \\ge \\tau\\}}{R \\sum_{j=1}^n \\mathbb{1}\\{Y_j=1\\}} + \\lambda \\left( \\frac{\\sum_{r=1}^R \\sum_{i=1}^n \\mathbb{1}\\{Y_i=0\\}\\mathbb{1}\\{\\hat f^{(-i,r)}(X_i) \\ge \\tau\\}}{R \\sum_{j=1}^n \\mathbb{1}\\{Y_j=0\\}} - (1-\\alpha) \\right)_{+} $$\n该表达式满足问题陈述的所有要求。对该损失函数关于 $\\tau$ 进行最小化将产生一个最优阈值，该阈值在最大化敏感性的主要目标与对特异性的临床约束之间取得平衡。参数 $\\lambda$ 控制约束的硬度：当 $\\lambda \\to \\infty$ 时，任何对特异性约束的违反都将变得代价无限大，从而迫使解满足 $\\widehat{\\text{Spec}}(\\tau) \\ge \\alpha$。", "answer": "$$\\boxed{- \\frac{\\sum_{r=1}^R \\sum_{i=1}^n \\mathbb{1}\\{Y_i=1\\} \\mathbb{1}\\{\\hat f^{(-i,r)}(X_i) \\ge \\tau\\}}{R \\sum_{j=1}^n \\mathbb{1}\\{Y_j=1\\}} + \\lambda \\left( \\frac{\\sum_{r=1}^R \\sum_{i=1}^n \\mathbb{1}\\{Y_i=0\\} \\mathbb{1}\\{\\hat f^{(-i,r)}(X_i) \\ge \\tau\\}}{R \\sum_{j=1}^n \\mathbb{1}\\{Y_j=0\\}} - (1-\\alpha) \\right)_{+}}$$", "id": "4897592"}]}