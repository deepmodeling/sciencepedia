## 引言
在生物医学、公共卫生和众多科学研究领域中，纵向数据——即对同一组受试者进行多次重复测量所获得的数据——无处不在。从评估新药疗效的临床试验到追踪儿童成长的流行病学研究，分析这[类数](@entry_id:156164)据对于理解动态变化过程至关重要。然而，纵向数据的核心特征，即源自同一个体的重复观测值之间存在内在相关性，给传统统计方法（如普通最小二乘法）带来了巨大挑战。忽略这种相关性会导致[标准误](@entry_id:635378)估计错误，从而可能得出错误的科学结论。

为了应对这一挑战，混合效应模型（Mixed-effects Models）应运而生，并发展成为分析纵向和层次化数据的黄金标准。它提供了一个强大而灵活的框架，能够同时对数据的平均趋势和个体间的异质性进行建模，并恰当地处理复杂的协方差结构。本文旨在系统性地介绍纵向数据分析与混合效应模型。我们将首先在“原理与机制”一章中，深入剖析其统计学基础，理解模型如何将变异分解为固定效应和随机效应，以及如何通过[协方差建模](@entry_id:747988)来捕捉数据的内在关联。随后，在“应用与跨学科连接”一章中，我们将展示这些模型在临床研究、流行病学、生物信息学等领域的广泛应用，并探讨其高级扩展形式。最后，通过“动手实践”部分提供具体问题，巩固您对理论知识的掌握。通过本次学习，您将能够理解并运用混合效应模型，从复杂的纵向数据中发掘深刻的科学见解。

## 原理与机制

在“引言”章节之后，我们现在深入探讨纵向数据分析与混合效应模型的数学原理和统计机制。本章旨在系统性地阐述这些模型为何是分析重复测量数据的有力工具，它们如何构建，以及如何解释其参数。

### 纵向数据的结构：关联性与独立性

纵向数据的核心特征在于其层次化结构：重复测量嵌套于独立的受试者内部。理解这种结构是选择正确分析方法的第一步。形式上，我们用 $y_{it}$ 表示受试者 $i$ 在时间点 $t$ 的观测值。纵向数据分析的一个基本假设是 **受试者之间相互独立**，而 **同一受试者内部的重复测量是相关的**。

我们可以使用协方差符号来精确地表述这一结构。对于任意两个不同的受试者 $i$ 和 $j$（即 $i \neq j$），他们在任何时间点 $t$ 和 $s$ 的测量值都是不相关的：

$$
\operatorname{cov}(y_{it}, y_{js}) = 0
$$

然而，对于同一个受试者 $i$，在不同时间点 $t$ 和 $s$ 的测量值通常是相关的，其协方差不为零：

$$
\operatorname{cov}(y_{it}, y_{is}) \neq 0 \quad (\text{对于 } t \neq s)
$$

这种受试者内部的关联性通常被称为 **[自相关](@entry_id:138991)** 或 **序列相关**，它反映了这样一个事实：一个受试者在某个时间点的状态，与其在邻近时间点的状态并非毫无关联。例如，一个人的血压不会在一天之内随机剧烈波动。将这种结构与经典的时间序列数据对比，后者只包含单个观测单元（如一个国家多年的GDP），而纵向数据则包含多个独立的“时间序列”（每个受试者一个）[@problem_id:4924283]。

在实践中，纵向数据的收集很少是完美的。一个 **平衡设计 (balanced design)** 指的是每个受试者都在完全相同的时间点被测量，并且没有任何缺失。然而，在真实的临床研究中，由于日程安排的冲突或受试者失访，我们通常会得到 **非平衡数据 (unbalanced data)**。这意味着不同受试者可能在不同的时间点被测量，或者测量的次数不同 [@problem_id:4924233]。例如，一个研究计划在第0、6、12个月进行访视，但实际观测时间可能是第0、5、13个月，甚至有的受试者错过了第6个月的访视。这种不规则性和不完整性给数据分析带来了挑战，也是混合效应模型大放异彩的领域。

### 传统方法的局限性：为何需要混合效应模型

面对纵向数据，一个初步的想法可能是忽略其内部相关性，将所有观测数据汇集起来，应用传统的 **[普通最小二乘法](@entry_id:137121) (Ordinary Least Squares, OLS)** 进行回归分析。例如，假设我们想研究某个生物指标随时间变化的平均趋势，模型可以设为 $y_{it} = \mu(t) + \epsilon_{it}$，其中 $\mu(t)$ 是一个关于时间的函数（如 $\mu(t) = \beta_0 + \beta_1 t$），而 $\epsilon_{it}$ 是误差项。

如果数据确实存在受试者内部的相关性（例如，误差项 $\epsilon_{it}$ 遵循一个[自回归过程](@entry_id:264527) $\epsilon_{i,t} = \phi\epsilon_{i,t-1} + u_{i,t}$），那么OLS会带来什么后果呢？[@problem_id:4924272] 研究表明，在某些标准条件下（例如，回归变量是时间 $t$ 这样的非随机变量），OLS对固定效应参数（如 $\beta_0, \beta_1$）的估计仍然是 **无偏 (unbiased)** 和 **一致 (consistent)** 的。这意味着随着样本量的增大，我们的估计值会趋近于真实值。

然而，真正的问题出在 **[标准误](@entry_id:635378) (standard errors)** 的估计上。OLS的标准误计算公式假设所有误差项 $\epsilon_{it}$ 都是独立的。当这个假设被违背时，计算出的[标准误](@entry_id:635378)就是错误的。通常，在存在正[自相关](@entry_id:138991)（即 $\phi > 0$）的情况下，OLS会低估真实的[标准误](@entry_id:635378)。这会导致t[检验统计量](@entry_id:167372)被人为地夸大，[置信区间](@entry_id:138194)过窄，从而使我们得出错误的结论——例如，更容易拒绝一个实际上成立的原假设（即[第一类错误](@entry_id:163360)率膨胀）。此外，由于未能有效利用数据的相关结构，OLS估计的 **效率 (efficiency)** 也不是最优的。**[广义最小二乘法](@entry_id:272590) (Generalized Least Squares, GLS)** 是一个更有效的替代方案，但它要求我们预先知道或能够很好地估计数据的协方差结构。这自然而然地引出了一个更通用、更灵活的框架——混合效应模型。

### 线性混合效应模型的核心框架

**线性混合效应模型 (Linear Mixed-Effects Model, LMM)** 提供了一个优雅而强大的框架，用以同时建模数据的平均趋势和复杂的协方差结构。其核心思想是将观测值的变异分解为两个主要来源：**固定效应 (fixed effects)** 和 **随机效应 (random effects)**。

模型的通用矩阵形式为 [@problem_id:4924280]：

$$
y = X\beta + Zb + \epsilon
$$

让我们系统地解析这个公式的每个组成部分：

*   $y$: 一个 $n \times 1$ 的响应向量，由所有 $N$ 个受试者的所有观测值 ($n = \sum_{i=1}^N n_i$) 堆叠而成。
*   $\beta$: 一个 $p \times 1$ 的向量，包含 $p$ 个 **固定效应** 参数。这些参数代表了群体的平均效应，是我们通常最感兴趣的估计量，例如时间的平均影响或治疗组间的平[均差](@entry_id:138238)异。
*   $X$: 一个 $n \times p$ 的设计矩阵，对应于固定效应。它的每一行包含了特定观测值的协变量信息。
*   $b$: 一个 $q \times 1$ 的向量，包含 $q$ 个 **随机效应** 参数。这些参数被视为来自某个概率分布的随机变量，用于捕捉个体间的异质性。例如，每个受试者可能有自己独特的变化轨迹，随机效应就用来描述这些个体轨迹相对于群体平均轨迹的偏离。
*   $Z$: 一个 $n \times q$ 的设计矩阵，对应于随机效应。它指明了随机效应如何影响每一个观测值。
*   $\epsilon$: 一个 $n \times 1$ 的向量，代表 **残差误差**。它包含了未被固定效应和随机效应解释的、受试者内部的随机波动。

该模型的核心在于对随机部分 $Zb + \epsilon$ 的假设：

1.  **随机效应的分布**: 随机效应 $b$ 被假定服从一个均值为 $\mathbf{0}$，协方差矩阵为 $G$ 的[多元正态分布](@entry_id:175229)，即 $b \sim \mathcal{N}(0, G)$。协方差矩阵 $G$ 是一个 **[块对角矩阵](@entry_id:145530)**，每个块对应一个受试者的随机效应协方差，反映了受试者间的独立性。
2.  **残差的分布**: 残差 $\epsilon$ 被假定服从一个均值为 $\mathbf{0}$，协方差矩阵为 $R$ 的[多元正态分布](@entry_id:175229)，即 $\epsilon \sim \mathcal{N}(0, R)$。与 $G$ 类似，$R$ 通常也是[块对角矩阵](@entry_id:145530)。
3.  **独立性**: 最关键的假设是，随机效应 $b$ 和残差 $\epsilon$ 相互独立。

基于这些假设，我们可以推导出响应向量 $y$ 的 **[边际分布](@entry_id:264862) (marginal distribution)**。$y$ 的均值由固定效应决定：

$$
E[y] = E[X\beta + Zb + \epsilon] = X\beta + Z E[b] + E[\epsilon] = X\beta
$$

$y$ 的协方差矩阵 $V$ 则由随机效应和残差的方差共同构成：

$$
V = \operatorname{Var}(y) = \operatorname{Var}(Zb + \epsilon) = \operatorname{Var}(Zb) + \operatorname{Var}(\epsilon) = Z \operatorname{Var}(b) Z^\top + \operatorname{Var}(\epsilon)
$$

因此，我们得到 $y$ 的边际协方差矩阵：

$$
V = Z G Z^\top + R
$$

这个公式是LMM的精髓所在。它表明，观测数据的总协方差 $V$ 可以分解为两部分：一部分是由随机效应引起的个体间变异 ($Z G Z^\top$)，另一部分是受试者内部的残差变异 ($R$)。通过对 $G$ 和 $R$ 矩阵的结构进行建模，我们可以灵活地捕捉纵向数据中各种复杂的关联模式 [@problem_id:4924280]。

### [协方差建模](@entry_id:747988) I：通过随机效应解释个体异质性 (G矩阵)

$G$ 矩阵描述了随机效应的方差和协方差，它直接关系到我们如何为不同受试者设定个体化的模型。

最简单的[随机效应模型](@entry_id:143279)是 **随机截距模型 (random intercept model)**。该模型假设每个受试者仅在他们的基线水平（截距）上有所不同。模型可以写作 $y_{it} = (\beta_0 + b_{i0}) + \beta_1 t + \epsilon_{it}$，其中 $b_{i0}$ 是受试者 $i$ 的随机截距。在这种情况下，$G$ 矩阵是一个 $1 \times 1$ 矩阵，即一个标量 $\sigma_{b0}^2 = \operatorname{Var}(b_{i0})$。

一个更灵活、更常用的模型是 **随机截距和随机斜率模型 (random intercept and slope model)**。该模型允许每个受试者不仅有自己的基线水平，还有自己独特的变化速率（斜率）。模型如下 [@problem_id:49259] [@problem_id:4924256]：

$$
y_{it} = (\beta_0 + b_{i0}) + (\beta_1 + b_{i1})t + \epsilon_{it}
$$

这里，$(b_{i0}, b_{i1})$ 是受试者 $i$ 的随机效应向量，代表其个人截距和斜率与群体平均值的偏离。它们的协方差矩阵 $G$（有时也写作 $D$）是一个 $2 \times 2$ 矩阵：

$$
G = \begin{pmatrix} \operatorname{Var}(b_{i0})  \operatorname{Cov}(b_{i0}, b_{i1}) \\ \operatorname{Cov}(b_{i1}, b_{i0})  \operatorname{Var}(b_{i1}) \end{pmatrix} = \begin{pmatrix} \sigma_{b0}^2  \sigma_{b0b1} \\ \sigma_{b0b1}  \sigma_{b1}^2 \end{pmatrix}
$$

其中，$\sigma_{b0}^2$ 是随机截距的方差，$\sigma_{b1}^2$ 是随机斜率的方差，而 $\sigma_{b0b1}$ 是截距和斜率之间的协方差。例如，一个负的 $\sigma_{b0b1}$ 可能意味着基线水平较高的受试者其指标随时间增长得更慢（“趋均数回归”现象）。

这个模型诱导了一个非常有趣的协方差结构。对于同一个受试者 $i$ 在时间点 $t$ 和 $s$ 的观测值，其方差和协方差可以通过基本[概率法则](@entry_id:268260)推导得出：

$$
\operatorname{Var}(y_{it}) = \sigma_{b0}^2 + 2t\sigma_{b0b1} + t^2\sigma_{b1}^2 + \sigma_{\epsilon}^2
$$
$$
\operatorname{Cov}(y_{it}, y_{is}) = \sigma_{b0}^2 + (t+s)\sigma_{b0b1} + ts\sigma_{b1}^2 \quad (\text{对于 } t \neq s)
$$

这个结果揭示了两个重要特性 [@problem_id:4924259]：
1.  **异方差性 (Heteroscedasticity)**: 只要随机斜率方差 $\sigma_{b1}^2$ 不为零，观测值的方差 $\operatorname{Var}(y_{it})$ 就会随时间 $t$ 变化（通常是增加）。这非常符合直觉：随着时间的推移，拥有不同变化速率的个体之间的差异会越来越大。
2.  **[非平稳性](@entry_id:180513) (Non-stationarity)**: 协方差 $\operatorname{Cov}(y_{it}, y_{is})$ 不仅仅依赖于时间差 $|t-s|$，还依赖于具体的时间点 $t$ 和 $s$。这意味着相关性结构是随时间演变的。

这种由随机效应诱导的协方差结构非常灵活，能够真实地反映许多生物学过程的动态变化。

### [协方差建模](@entry_id:747988) II：模拟受试者内部的[残差相关](@entry_id:754268)性 ([R矩阵](@entry_id:142757))

随机效应捕捉了个体轨迹的异质性，但这可能不是受试者内部相关性的全部来源。有时，即使在考虑了个体轨迹后，一个受试者在某个时间点的测量值仍然与其邻近时间点的测量值存在短暂的、序列性的相关。这种相关性可以通过对残差协方差矩阵 $R$ 进行建模来捕捉。

$R$ 矩阵描述了在给定受试者的随机效应之后，剩余误差 $\epsilon_{it}$ 的协方差结构。以下是一些常用的 $R$ 矩阵结构 [@problem_id:4924258]：

*   **独立 (Independence)**: $R_i = \sigma_\epsilon^2 I$。这是最简单的结构，假设残差是不相关的。所有的受试者内相关性都完全由随机效应 $G$ 来解释。
*   **复合对称 (Compound Symmetry, CS)**: 这种结构假设任何两个不同时间点之间的[残差相关](@entry_id:754268)性是恒定的，$\operatorname{Corr}(\epsilon_{it}, \epsilon_{is}) = \rho$。对应的协方差矩阵对角[线元](@entry_id:196833)素为 $\sigma^2$，非对角[线元](@entry_id:196833)素为 $\sigma^2\rho$。要使该矩阵为[正定矩阵](@entry_id:155546)，相关系数 $\rho$ 必须满足 $-1/(n_i-1)  \rho  1$。
*   **一阶自回归 (Autoregressive(1), AR(1))**: 这种结构假设相关性随时间间隔的增加而呈指数衰减。对于等间隔的测量，$\operatorname{Cov}(\epsilon_{it}, \epsilon_{is}) = \sigma^2 \rho^{|t-s|}$。相关参数 $\rho$ 必须在 $(-1, 1)$ 之间以保证[平稳性](@entry_id:143776)和[正定性](@entry_id:149643)。这种结构非常适合描述“记忆”会随时间减弱的过程。对于非等间隔的数据，可以使用其连续时间版本（如 CAR(1)），其中衰减率取决于实际的时间差 $|t_{ij}-t_{ik}|$，而不是访视次数的差 [@problem_id:4924233]。
*   **非结构化 (Unstructured, UN)**: 这是最灵活的结构，它不对协方差矩阵施加任何模式，而是为每个方差和[协方差估计](@entry_id:145514)一个独立的参数。对于有 $n_i$ 次测量的受试者，这需要估计 $n_i(n_i+1)/2$ 个参数。虽然它提供了最佳的数据拟合，但也最容易[过拟合](@entry_id:139093)，且只适用于测量次数较少的情况。

在实践中，模型选择通常涉及比较包含不同 $G$ 和 $R$ 结构的模型，并使用[信息准则](@entry_id:636495)（如AIC或BIC）来找到最能平衡[拟合优度](@entry_id:637026)和模型[简约性](@entry_id:141352)的组合。

### 高级主题与[模型解释](@entry_id:637866)

掌握了LMM的基[本构建模](@entry_id:183370)块后，我们可以探讨一些更高级的应用和解释上的细微差别。

#### 区分受试者内部与受试者之间的效应

当模型中包含随时间变化的协变量 $x_{it}$（如每日用药剂量）时，一个关键问题是该变量与结果 $y_{it}$ 的关联是反映了个体内部的变化（例如，增加用药剂量是否会降低我自己的血压？），还是反映了不同个体间的差异（例如，平均用药剂量较高的人群是否血压也较低？）。这两个效应可能完全不同，将它们混为一谈可能导致错误的推论。

一种强大的技术是在模型中同时估计这两种效应。这可以通过将协变量 $x_{it}$ 分解为其 **受试者均值** $x_{\cdot i} = \frac{1}{T_i}\sum_{t=1}^{T_i} x_{it}$ 和 **受试者内部的离差** $(x_{it} - x_{\cdot i})$ 来实现。模型构建如下 [@problem_id:4924235]：

$$
y_{it} = \beta_0 + \beta_w (x_{it} - x_{\cdot i}) + \beta_b x_{\cdot i} + b_{0i} + \varepsilon_{it}
$$

在这个所谓的“[混合模型](@entry_id:266571)”或“组内-组间模型”中，系数的解释变得非常清晰：
*   $\beta_w$: 估计的是 **受试者内部效应 (within-subject effect)**。它表示，对于同一个受试者，当 $x_{it}$ 变化一个单位时，$y_{it}$ 的期望变化量。
*   $\beta_b$: 估计的是 **受试者之间效应 (between-subject effect)**。它表示，比较两个平均协变量 $x_{\cdot i}$ 相差一个单位的受试者，他们平均响应 $y$ 的期望差异。

这种方法不仅可以提供更丰富的科学见解，而且 $\beta_w$ 的估计值在数值上等同于[固定效应模型](@entry_id:142997)（fixed-effects model）的估计值，从而能够稳健地处理由不随时间变化的、未观测的混杂因素（这些因素被吸收到 $b_{0i}$ 中）引起的一些偏误。

#### 扩展至非正态数据：广义线性混合模型

线性混合效应模型假设响应变量是连续且近似正态分布的。当结果是二元的（如存活/死亡）、计数的（如疾病发作次数）或其他非正态类型时，我们需要将LMM推广到 **广义线性混合模型 (Generalized Linear Mixed Models, GLMM)** 的框架。

GLMM通过一个 **联结函数 (link function)** $g(\cdot)$ 来关联响应的[期望值](@entry_id:150961)与[线性预测](@entry_id:180569)器 [@problem_id:4924270]：

$$
g(E(y_{it} \mid b_i)) = x_{it}^\top\beta + z_{it}^\top b_i
$$

例如，对于[二元结果](@entry_id:173636)，我们通常使用`logit`联结函数，模型就变成了逻辑回归的混合效应版本。

在解释GLMM的系数时，必须格外小心。对于非线性的联结函数（如`logit`或`log`），固定效应系数 $\beta$ 的解释是 **条件性的 (conditional)** 或 **受试者特异性的 (subject-specific)**。它描述的是，在保持特定受试者的随机效应 $b_i$ 不变的情况下，协变量变化一个单位对转换后的期望响应的影响。

这与 **边际性的 (marginal)** 或 **群体平均的 (population-averaged)** 解释形成对比，后者描述的是协变量变化对整个群体平均响应的影响。在非线性模型中，由于[Jensen不等式](@entry_id:144269)的作用 ($E[g^{-1}(X)] \neq g^{-1}(E[X])$)，条件效应和[边际效应](@entry_id:634982)通常不相等（[边际效应](@entry_id:634982)的幅度通常更小）。LMM是唯一的特例：由于其联结函数是[恒等函数](@entry_id:152136)（线性），其系数 $\beta$ 同时具有条件性和边际性的双重解释。这一区别至关重要，因为另一类流行的纵向数据方法——**广义估计方程 (Generalized Estimating Equations, GEE)**——直接对边际均值建模，其系数因此具有群体平均的解释。

#### 处理[缺失数据](@entry_id:271026)：混合效应模型的关键优势

纵向研究中，数据缺失是常态而非例外。处理缺失数据的有效性是评估一种统计方法的关键标准。根据Rubin的分类框架，缺失机制可分为三类 [@problem_id:4924226]：

1.  **[完全随机缺失](@entry_id:170286) (Missing Completely At Random, MCAR)**: 缺失的发生与任何已观测或未观测的数据都无关。
2.  **[随机缺失](@entry_id:168632) (Missing At Random, MAR)**: 缺失的发生仅依赖于已观测的数据。例如，病情较差（根据已有的测量值判断）的患者更有可能退出研究。
3.  **[非随机缺失](@entry_id:163489) (Missing Not At Random, MNAR)**: 缺失的发生依赖于未观测到的数据本身。例如，患者因为感到极度不适而缺席访视，而这种不适正是该次访视想要测量的。

许多简单的[缺失数据](@entry_id:271026)处理方法（如仅分析完整数据，即[列表删除法](@entry_id:637836)）仅在最严格且不切实际的MCAR假设下才能给出无偏估计。

混合效应模型的一个巨大优势在于，其基于 **[最大似然](@entry_id:146147) (Maximum Likelihood, ML)** 的估计方法在 **MCAR和MAR** 假设下都能提供渐近无偏的参数估计，只要模型本身设定正确。这是因为似然函数是通过对每个受试者的所有潜在数据（包括缺失值）的[联合分布](@entry_id:263960)进行积分（或求和）来构建的，从而有效地利用了所有可用的信息。只要缺失的原因被已有的观测数据所捕捉（MAR的定义），这个过程就能自我修正。这种稳健性使得混合效应模型成为处理真实世界中不完美纵向数据的首选工具之一。然而，对于MNAR，标准的LMM/GLMM分析通常会产生偏误，需要更高级的、联合建模结果和缺失过程的模型。