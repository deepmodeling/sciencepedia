{"hands_on_practices": [{"introduction": "理论学习的最佳方式莫过于亲手实践。本节的第一个练习将引导你处理贝叶斯统计中的一个经典且优雅的案例：共轭先验。你将通过泊松-伽马模型，一步步推导后验分布和后验预测分布，这不仅能让你掌握贝叶斯更新的核心数学过程，还能让你深刻理解如何将先验知识诠释为“伪数据”，并观察它如何与观测数据相结合。这个练习是理解贝叶斯推断如何运作的基石。[@problem_id:4912491]", "problem": "一家医院的流行病学部门监测各个病房中耐甲氧西林金黄色葡萄球菌定植的事件计数。对于病房 $i$，在 $t_{i}$ 人天的暴露量下，观察到的计数为 $y_{i}$。假设每人天的发病率 $\\lambda$ 是一个常数，并且在给定 $\\lambda$ 的条件下，各计数是独立的，服从 $y_{i} \\sim \\mathrm{Poisson}(\\lambda t_{i})$ 分布，其中 $i = 1, \\dots, n$。$\\lambda$ 的先验分布为 $\\mathrm{Gamma}(\\alpha_{0}, \\beta_{0})$，其形状参数为 $\\alpha_{0} > 0$，率参数为 $\\beta_{0} > 0$，即其密度函数为 $p(\\lambda) = \\frac{\\beta_{0}^{\\alpha_{0}}}{\\Gamma(\\alpha_{0})} \\lambda^{\\alpha_{0}-1} \\exp(-\\beta_{0} \\lambda)$，其中 $\\lambda > 0$。\n\n从贝叶斯定理以及泊松和伽马分布的密度函数定义出发（不提供其他公式），推导后验分布 $p(\\lambda \\mid y_{1:n}, t_{1:n})$ 以及在新的暴露量 $t_{\\mathrm{new}} > 0$ 下未来计数 $y_{\\mathrm{new}}$ 的后验预测分布 $p(y_{\\mathrm{new}} \\mid y_{1:n}, t_{1:n}, t_{\\mathrm{new}})$。然后，根据 $\\alpha_{0}$ 和 $\\beta_{0}$ 如何与观测数据结合，将它们解释为伪计数和伪时间。\n\n用包含伽马函数的封闭形式解析表达式来表示 $y_{\\mathrm{new}}$ 的后验预测概率质量函数，该表达式应使用 $\\alpha_{0}$、$\\beta_{0}$、$\\sum_{i=1}^{n} y_{i}$、$\\sum_{i=1}^{n} t_{i}$ 和 $t_{\\mathrm{new}}$ 表示。无需进行四舍五入。", "solution": "该问题是一个标准的贝叶斯推断练习，涉及泊松似然和伽马先验。在进行求解之前，必须对问题陈述进行验证。\n\n### 问题验证\n\n**步骤1：提取已知条件**\n-   病房 $i$ 的观察计数：$y_i$\n-   病房 $i$ 的暴露量：$t_i$ 人天\n-   计数模型：$y_{i} \\sim \\mathrm{Poisson}(\\lambda t_{i})$，在给定 $\\lambda$ 的条件下，其中 $i = 1, \\dots, n$。\n-   各计数是独立的。\n-   发病率参数：$\\lambda > 0$。\n-   $\\lambda$ 的先验分布：$\\mathrm{Gamma}(\\alpha_{0}, \\beta_{0})$。\n-   先验形状参数：$\\alpha_{0} > 0$。\n-   先验率参数：$\\beta_{0} > 0$。\n-   先验概率密度函数 (PDF)：$p(\\lambda) = \\frac{\\beta_{0}^{\\alpha_{0}}}{\\Gamma(\\alpha_{0})} \\lambda^{\\alpha_{0}-1} \\exp(-\\beta_{0} \\lambda)$。\n-   未来计数：$y_{\\mathrm{new}}$。\n-   新的暴露量：$t_{\\mathrm{new}} > 0$。\n-   未来计数模型：$y_{\\mathrm{new}} \\sim \\mathrm{Poisson}(\\lambda t_{\\mathrm{new}})$。\n\n**步骤2：使用提取的已知条件进行验证**\n-   **科学依据：** 该问题牢固地植根于生物统计学和贝叶斯推断的既定原则。使用泊松分布对计数数据进行建模是流行病学中的标准做法。使用伽马分布作为泊松率参数的先验是共轭先验的一个典型例子，这是贝叶斯统计中的一个基本概念。\n-   **适定性：** 该问题是适定的。它提供了似然函数和先验分布的完整规范，通过标准的数学程序可以唯一地推导出后验分布和后验预测分布。\n-   **客观性：** 该问题以精确、客观的数学语言陈述。它不包含主观论断或歧义。\n\n问题陈述没有违反任何无效性标准。这是一个科学合理、适定且客观的问题表述。\n\n**步骤3：结论与行动**\n问题有效。将推导完整的解答。\n\n### 后验分布和后验预测分布的推导\n\n求解过程包括三个主要步骤：\n1.  推导发病率 $\\lambda$ 的后验分布。\n2.  解释先验参数 $\\alpha_0$ 和 $\\beta_0$。\n3.  推导新观测值 $y_{\\mathrm{new}}$ 的后验预测分布。\n\n**1. $\\lambda$ 的后验分布**\n\n我们从贝叶斯定理开始，该定理指出后验分布正比于似然与先验分布的乘积：\n$$p(\\lambda \\mid y_{1:n}, t_{1:n}) \\propto p(y_{1:n} \\mid \\lambda, t_{1:n}) p(\\lambda)$$\n让我们用 $D = \\{y_{1:n}, t_{1:n}\\}$ 来表示数据。\n\n**似然：**\n观测值 $y_i$ 被假定为来自泊松分布的独立抽样，因此联合似然是各个概率质量函数（PMF）的乘积：\n$$p(D \\mid \\lambda) = \\prod_{i=1}^{n} p(y_i \\mid \\lambda, t_i)$$\n均值为 $\\lambda t_i$ 的泊松分布的概率质量函数为 $p(y_i \\mid \\lambda, t_i) = \\frac{(\\lambda t_i)^{y_i} \\exp(-\\lambda t_i)}{y_i!}$。\n因此，联合似然为：\n$$p(D \\mid \\lambda) = \\prod_{i=1}^{n} \\frac{(\\lambda t_i)^{y_i} \\exp(-\\lambda t_i)}{y_i!} = \\left( \\prod_{i=1}^{n} \\frac{t_i^{y_i}}{y_i!} \\right) \\left( \\prod_{i=1}^{n} \\lambda^{y_i} \\right) \\left( \\prod_{i=1}^{n} \\exp(-\\lambda t_i) \\right)$$\n合并各项，我们得到：\n$$p(D \\mid \\lambda) = \\left( \\prod_{i=1}^{n} \\frac{t_i^{y_i}}{y_i!} \\right) \\lambda^{\\sum_{i=1}^{n} y_i} \\exp\\left(-\\lambda \\sum_{i=1}^{n} t_i\\right)$$\n作为 $\\lambda$ 的函数，似然正比于：\n$$p(D \\mid \\lambda) \\propto \\lambda^{\\sum_{i=1}^{n} y_i} \\exp\\left(-\\lambda \\sum_{i=1}^{n} t_i\\right)$$\n\n**先验：**\n$\\lambda$ 的先验分布给定为伽马分布 $\\mathrm{Gamma}(\\alpha_0, \\beta_0)$：\n$$p(\\lambda) = \\frac{\\beta_{0}^{\\alpha_{0}}}{\\Gamma(\\alpha_{0})} \\lambda^{\\alpha_{0}-1} \\exp(-\\beta_{0} \\lambda)$$\n作为 $\\lambda$ 的函数，先验正比于：\n$$p(\\lambda) \\propto \\lambda^{\\alpha_{0}-1} \\exp(-\\beta_{0} \\lambda)$$\n\n**后验：**\n现在，我们将似然与先验相乘：\n$$p(\\lambda \\mid D) \\propto \\left( \\lambda^{\\sum_{i=1}^{n} y_i} \\exp\\left(-\\lambda \\sum_{i=1}^{n} t_i\\right) \\right) \\left( \\lambda^{\\alpha_{0}-1} \\exp(-\\beta_{0} \\lambda) \\right)$$\n$$p(\\lambda \\mid D) \\propto \\lambda^{\\alpha_{0} + \\sum_{i=1}^{n} y_i - 1} \\exp\\left(-(\\beta_{0} + \\sum_{i=1}^{n} t_i) \\lambda\\right)$$\n这个函数形式是伽马分布的核。我们可以确定后验分布的更新参数：\n-   后验形状参数：$\\alpha_n = \\alpha_0 + \\sum_{i=1}^{n} y_i$\n-   后验率参数：$\\beta_n = \\beta_0 + \\sum_{i=1}^{n} t_i$\n\n因此，$\\lambda$ 的后验分布是一个伽马分布：\n$$\\lambda \\mid D \\sim \\mathrm{Gamma}\\left(\\alpha_0 + \\sum_{i=1}^{n} y_i, \\beta_0 + \\sum_{i=1}^{n} t_i\\right)$$\n完整的后验概率密度函数为：\n$$p(\\lambda \\mid D) = \\frac{(\\beta_0 + \\sum_{i=1}^{n} t_i)^{\\alpha_0 + \\sum_{i=1}^{n} y_i}}{\\Gamma(\\alpha_0 + \\sum_{i=1}^{n} y_i)} \\lambda^{\\alpha_0 + \\sum_{i=1}^{n} y_i - 1} \\exp\\left(-(\\beta_0 + \\sum_{i=1}^{n} t_i) \\lambda\\right)$$\n\n**2. 先验参数的解释**\n\n后验参数 $\\alpha_n$ 和 $\\beta_n$ 的形式为先验参数 $\\alpha_0$ 和 $\\beta_0$ 提供了清晰的解释。后验形状参数 $\\alpha_n$ 是先验形状参数 $\\alpha_0$ 与观测到的事件总数 $\\sum y_i$ 的和。后验率参数 $\\beta_n$ 是先验率参数 $\\beta_0$ 与观测到的总暴露时间 $\\sum t_i$ 的和。\n这种加性更新结构意味着 $\\alpha_0$ 可以被解释为来自先验知识或先前假设实验的事件**伪计数**。类似地，$\\beta_0$ 可以被解释为这 $\\alpha_0$ 个事件被“观测”到时所对应的**伪时间**（或伪暴露量）。先验信念的强度由 $\\alpha_0$ 和 $\\beta_0$ 的大小决定；较大的值代表更强的先验信息，需要更多的数据才能被克服。\n\n**3. $y_{\\mathrm{new}}$ 的后验预测分布**\n\n对于一个新的观测值 $y_{\\mathrm{new}}$，在给定观测数据 $D$ 和新的暴露时间 $t_{\\mathrm{new}}$ 的情况下，其后验预测分布是通过将 $y_{\\mathrm{new}}$ 的似然对 $\\lambda$ 的后验分布进行积分得到的：\n$$p(y_{\\mathrm{new}} \\mid D, t_{\\mathrm{new}}) = \\int_{0}^{\\infty} p(y_{\\mathrm{new}} \\mid \\lambda, t_{\\mathrm{new}}) p(\\lambda \\mid D) d\\lambda$$\n我们代入各自的分布：\n-   $p(y_{\\mathrm{new}} \\mid \\lambda, t_{\\mathrm{new}}) = \\frac{(\\lambda t_{\\mathrm{new}})^{y_{\\mathrm{new}}} \\exp(-\\lambda t_{\\mathrm{new}})}{y_{\\mathrm{new}}!}$\n-   $p(\\lambda \\mid D) = \\frac{\\beta_n^{\\alpha_n}}{\\Gamma(\\alpha_n)} \\lambda^{\\alpha_n - 1} \\exp(-\\beta_n \\lambda)$，其中 $\\alpha_n = \\alpha_0 + \\sum y_i$ 且 $\\beta_n = \\beta_0 + \\sum t_i$。\n\n积分变为：\n$$p(y_{\\mathrm{new}} \\mid D, t_{\\mathrm{new}}) = \\int_{0}^{\\infty} \\left( \\frac{(\\lambda t_{\\mathrm{new}})^{y_{\\mathrm{new}}} \\exp(-\\lambda t_{\\mathrm{new}})}{y_{\\mathrm{new}}!} \\right) \\left( \\frac{\\beta_n^{\\alpha_n}}{\\Gamma(\\alpha_n)} \\lambda^{\\alpha_n - 1} \\exp(-\\beta_n \\lambda) \\right) d\\lambda$$\n我们将不依赖于 $\\lambda$ 的项移到积分符号外。我们还使用恒等式 $y_{\\mathrm{new}}! = \\Gamma(y_{\\mathrm{new}}+1)$：\n$$p(y_{\\mathrm{new}} \\mid D, t_{\\mathrm{new}}) = \\frac{t_{\\mathrm{new}}^{y_{\\mathrm{new}}}}{\\Gamma(y_{\\mathrm{new}}+1)} \\frac{\\beta_n^{\\alpha_n}}{\\Gamma(\\alpha_n)} \\int_{0}^{\\infty} \\lambda^{y_{\\mathrm{new}}} \\exp(-\\lambda t_{\\mathrm{new}}) \\lambda^{\\alpha_n - 1} \\exp(-\\beta_n \\lambda) d\\lambda$$\n合并积分内的含 $\\lambda$ 的项：\n$$p(y_{\\mathrm{new}} \\mid D, t_{\\mathrm{new}}) = \\frac{t_{\\mathrm{new}}^{y_{\\mathrm{new}}} \\beta_n^{\\alpha_n}}{\\Gamma(y_{\\mathrm{new}}+1) \\Gamma(\\alpha_n)} \\int_{0}^{\\infty} \\lambda^{(y_{\\mathrm{new}} + \\alpha_n) - 1} \\exp(-(\\beta_n + t_{\\mathrm{new}}) \\lambda) d\\lambda$$\n该积分具有未归一化的伽马概率密度函数的形式。我们使用恒等式 $\\int_0^{\\infty} x^{a-1} \\exp(-bx) dx = \\frac{\\Gamma(a)}{b^a}$。\n这里，$a = y_{\\mathrm{new}} + \\alpha_n$ 且 $b = \\beta_n + t_{\\mathrm{new}}$。所以积分的计算结果为：\n$$\\int_{0}^{\\infty} \\lambda^{(y_{\\mathrm{new}} + \\alpha_n) - 1} \\exp(-(\\beta_n + t_{\\mathrm{new}}) \\lambda) d\\lambda = \\frac{\\Gamma(y_{\\mathrm{new}} + \\alpha_n)}{(\\beta_n + t_{\\mathrm{new}})^{y_{\\mathrm{new}} + \\alpha_n}}$$\n将此结果代回到我们的预测概率表达式中：\n$$p(y_{\\mathrm{new}} \\mid D, t_{\\mathrm{new}}) = \\frac{t_{\\mathrm{new}}^{y_{\\mathrm{new}}} \\beta_n^{\\alpha_n}}{\\Gamma(y_{\\mathrm{new}}+1) \\Gamma(\\alpha_n)} \\frac{\\Gamma(y_{\\mathrm{new}} + \\alpha_n)}{(\\beta_n + t_{\\mathrm{new}})^{y_{\\mathrm{new}} + \\alpha_n}}$$\n整理各项，得到后验预测概率质量函数的最终表达式：\n$$p(y_{\\mathrm{new}} \\mid D, t_{\\mathrm{new}}) = \\frac{\\Gamma(y_{\\mathrm{new}} + \\alpha_n)}{\\Gamma(y_{\\mathrm{new}}+1) \\Gamma(\\alpha_n)} \\frac{t_{\\mathrm{new}}^{y_{\\mathrm{new}}} \\beta_n^{\\alpha_n}}{(\\beta_n + t_{\\mathrm{new}})^{y_{\\mathrm{new}} + \\alpha_n}}$$\n这是负二项分布的概率质量函数。最后，我们代回 $\\alpha_n$ 和 $\\beta_n$ 的定义：\n$$p(y_{\\mathrm{new}} \\mid D, t_{\\mathrm{new}}) = \\frac{\\Gamma(y_{\\mathrm{new}} + \\alpha_0 + \\sum_{i=1}^{n} y_i)}{\\Gamma(y_{\\mathrm{new}}+1) \\Gamma(\\alpha_0 + \\sum_{i=1}^{n} y_i)} \\frac{t_{\\mathrm{new}}^{y_{\\mathrm{new}}} (\\beta_0 + \\sum_{i=1}^{n} t_i)^{\\alpha_0 + \\sum_{i=1}^{n} y_i}}{(\\beta_0 + \\sum_{i=1}^{n} t_i + t_{\\mathrm{new}})^{y_{\\mathrm{new}} + \\alpha_0 + \\sum_{i=1}^{n} y_i}}$$\n这就是所要求的后验预测概率质量函数的封闭形式解析表达式。", "answer": "$$\n\\boxed{\\frac{\\Gamma(y_{\\mathrm{new}} + \\alpha_{0} + \\sum_{i=1}^{n} y_{i})}{\\Gamma(y_{\\mathrm{new}}+1) \\Gamma(\\alpha_{0} + \\sum_{i=1}^{n} y_{i})} \\frac{t_{\\mathrm{new}}^{y_{\\mathrm{new}}} (\\beta_{0} + \\sum_{i=1}^{n} t_{i})^{\\alpha_{0} + \\sum_{i=1}^{n} y_{i}}}{(\\beta_{0} + \\sum_{i=1}^{n} t_{i} + t_{\\mathrm{new}})^{y_{\\mathrm{new}} + \\alpha_{0} + \\sum_{i=1}^{n} y_{i}}}}\n$$", "id": "4912491"}, {"introduction": "在掌握了共轭先验的便利性后，我们自然会思考一个问题：当我们缺乏先验信息，或者希望让数据“自己说话”时，该如何选择先验？这个练习将带你探索“无信息先验”的世界，特别是著名的 Jeffreys 先验。你将亲自推导出一个伯努利模型的 Jeffreys 先验，并将其与看似“中立”的均匀先验进行比较，从而发现不同的“无信息”先验假设会对预测结果产生实质性影响，尤其是在小样本情况下。[@problem_id:4912591]", "problem": "一项生物统计学预研究考虑了一种新疗法的二元临床终点，该终点被建模为参数为 $\\theta \\in (0,1)$ 的伯努利随机变量。目标是使用一个反映参数化不变性的先验，并将其先验预测行为与均匀先验在小样本量下的情况进行比较。从基本原理出发，将数据 $X \\in \\{0,1\\}$ 视为具有似然的单次伯努利试验，并推导 $\\theta$ 的费雪信息。利用此信息定义伯努利参数的Jeffreys先验。然后，考虑一个大小为 $n=3$ 的样本，并计算在Jeffreys先验下观测到3个响应者（全部成功）的先验预测概率。同时计算在$\\mathrm{Beta}(1,1)$先验下观测到3个响应者的先验预测概率。最后，将这两个先验预测概率的比率（Jeffreys先验除以$\\mathrm{Beta}(1,1)$先验）报告为一个单一的精确值。不要四舍五入；以最简分数的形式提供精确比率。", "solution": "用户希望解决一个贝叶斯生物统计学问题。我将首先验证问题陈述。\n\n### 第1步：提取已知条件\n-   **模型**：数据来自一个二元临床终点，建模为伯努利随机变量。\n-   **参数**：伯努利参数为 $\\theta \\in (0,1)$。\n-   **用于费雪信息的数据**：单次伯努利试验 $X \\in \\{0,1\\}$，其似然为 $P(X=x|\\theta)$。\n-   **用于预测概率的数据**：样本量为 $n=3$ 的样本。\n-   **关心事件**：在大小为 $n=3$ 的样本中观测到 $k=3$ 个响应者（成功）。\n-   **任务1**：推导伯努利参数的费雪信息 $I(\\theta)$。\n-   **任务2**：使用 $I(\\theta)$ 定义 $\\theta$ 的Jeffreys先验。\n-   **任务3**：计算在Jeffreys先验下，$n=3$ 次试验中出现 $k=3$ 次成功的先验预测概率，我们称之为 $P_J(Y=3|n=3)$。\n-   **任务4**：计算在$\\mathrm{Beta}(1,1)$先验下，$n=3$ 次试验中出现 $k=3$ 次成功的先验预测概率，我们称之为 $P_U(Y=3|n=3)$。\n-   **任务5**：计算比率 $\\frac{P_J(Y=3|n=3)}{P_U(Y=3|n=3)}$。\n-   **要求格式**：最终答案必须是一个精确的最简分数。\n\n### 第2步：使用提取的已知条件进行验证\n该问题具有科学依据。伯努利试验、费雪信息、Jeffreys先验、Beta先验和先验预测分布等概念在贝叶斯统计学及其在生物统计学中的应用中是基础且标准的。该问题是适定的，通过一系列清晰的计算可以得出一个唯一的、确定性的结果。语言客观而精确。问题是自洽的，不包含任何矛盾或歧义。这是理论统计学中的一个标准的、非平凡的练习。\n\n### 第3步：结论与行动\n问题有效。我将继续进行完整解答。\n\n### 解题推导\n\n该问题要求从费雪信息开始，逐步推导，直至最终的先验预测概率比率。\n\n**1. 伯努利参数的费雪信息**\n\n成功参数为 $\\theta$ 的单次伯努利试验的概率质量函数为 $P(X=x|\\theta) = \\theta^x (1-\\theta)^{1-x}$，其中 $x \\in \\{0, 1\\}$。单个观测值 $x$ 的似然函数为 $L(\\theta|x) = \\theta^x (1-\\theta)^{1-x}$。\n\n对数似然为 $\\ell(\\theta|x) = \\ln L(\\theta|x) = x \\ln(\\theta) + (1-x) \\ln(1-\\theta)$。\n\n为了找到费雪信息 $I(\\theta)$，我们计算对数似然函数关于 $\\theta$ 的二阶导数的负期望。\n\n一阶导数：\n$$ \\frac{\\partial \\ell}{\\partial \\theta} = \\frac{x}{\\theta} - \\frac{1-x}{1-\\theta} $$\n\n二阶导数：\n$$ \\frac{\\partial^2 \\ell}{\\partial \\theta^2} = -\\frac{x}{\\theta^2} - \\frac{1-x}{(1-\\theta)^2} $$\n\n单个观测值的费雪信息为 $I(\\theta) = -E\\left[\\frac{\\partial^2 \\ell}{\\partial \\theta^2}\\right]$。期望是关于 $X$ 的分布计算的，其中 $E[X] = \\theta$。\n$$ I(\\theta) = -E\\left[ -\\frac{X}{\\theta^2} - \\frac{1-X}{(1-\\theta)^2} \\right] = E\\left[ \\frac{X}{\\theta^2} \\right] + E\\left[ \\frac{1-X}{(1-\\theta)^2} \\right] $$\n$$ I(\\theta) = \\frac{E[X]}{\\theta^2} + \\frac{1-E[X]}{(1-\\theta)^2} = \\frac{\\theta}{\\theta^2} + \\frac{1-\\theta}{(1-\\theta)^2} = \\frac{1}{\\theta} + \\frac{1}{1-\\theta} $$\n化简后，我们得到：\n$$ I(\\theta) = \\frac{1-\\theta+\\theta}{\\theta(1-\\theta)} = \\frac{1}{\\theta(1-\\theta)} $$\n\n**2. 伯努利参数的Jeffreys先验**\n\nJeffreys先验 $p_J(\\theta)$ 定义为与费雪信息平方根成正比：\n$$ p_J(\\theta) \\propto \\sqrt{I(\\theta)} = \\sqrt{\\frac{1}{\\theta(1-\\theta)}} = \\theta^{-1/2} (1-\\theta)^{-1/2} $$\n这是Beta分布的核，$p(\\theta|\\alpha, \\beta) \\propto \\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}$。通过比较指数，我们有 $\\alpha-1 = -1/2$ 和 $\\beta-1 = -1/2$，这得出 $\\alpha = 1/2$ 和 $\\beta = 1/2$。因此，伯努利参数的Jeffreys先验是一个 $\\mathrm{Beta}(1/2, 1/2)$ 分布。归一化的概率密度函数是：\n$$ p_J(\\theta) = \\frac{\\theta^{1/2-1} (1-\\theta)^{1/2-1}}{B(1/2, 1/2)} = \\frac{\\theta^{-1/2} (1-\\theta)^{-1/2}}{\\frac{\\Gamma(1/2)\\Gamma(1/2)}{\\Gamma(1)}} = \\frac{1}{\\pi} \\theta^{-1/2} (1-\\theta)^{-1/2} $$\n其中我们使用了 $\\Gamma(1/2) = \\sqrt{\\pi}$ 和 $\\Gamma(1) = 1$。\n\n**3. Jeffreys先验下的先验预测概率**\n\n我们考虑一个大小为 $n=3$ 的样本，并观测到 $k=3$ 次成功。设 $Y$ 为成功次数。该观测值的似然由二项概率质量函数给出：\n$$ P(Y=3|\\theta, n=3) = \\binom{3}{3} \\theta^3 (1-\\theta)^{3-3} = \\theta^3 $$\n先验预测概率 $P_J(Y=3|n=3)$ 是数据的边际概率，通过将似然函数对先验分布进行积分得到：\n$$ P_J(Y=3|n=3) = \\int_0^1 P(Y=3|\\theta, n=3) p_J(\\theta) d\\theta $$\n$$ P_J(Y=3|n=3) = \\int_0^1 \\theta^3 \\left( \\frac{1}{\\pi} \\theta^{-1/2} (1-\\theta)^{-1/2} \\right) d\\theta = \\frac{1}{\\pi} \\int_0^1 \\theta^{5/2} (1-\\theta)^{-1/2} d\\theta $$\n该积分是Beta函数的形式，$B(a, b) = \\int_0^1 t^{a-1} (1-t)^{b-1} dt = \\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}$。\n此处，$a-1 = 5/2 \\Rightarrow a=7/2$ 且 $b-1 = -1/2 \\Rightarrow b=1/2$。\n该积分为 $B(7/2, 1/2)$。我们使用伽马函数的性质 $\\Gamma(z+1)=z\\Gamma(z)$ 和 $\\Gamma(n)=(n-1)!$（对于整数 $n$）来计算它。\n$$ \\Gamma(7/2) = \\frac{5}{2}\\Gamma(5/2) = \\frac{5}{2}\\frac{3}{2}\\Gamma(3/2) = \\frac{5}{2}\\frac{3}{2}\\frac{1}{2}\\Gamma(1/2) = \\frac{15}{8}\\sqrt{\\pi} $$\n$$ \\Gamma(1/2) = \\sqrt{\\pi} $$\n$$ \\Gamma(7/2 + 1/2) = \\Gamma(4) = 3! = 6 $$\n所以，$B(7/2, 1/2) = \\frac{\\Gamma(7/2)\\Gamma(1/2)}{\\Gamma(4)} = \\frac{(\\frac{15}{8}\\sqrt{\\pi})(\\sqrt{\\pi})}{6} = \\frac{15\\pi}{48} = \\frac{5\\pi}{16}$。\n将此结果代回先验预测概率的表达式中：\n$$ P_J(Y=3|n=3) = \\frac{1}{\\pi} B(7/2, 1/2) = \\frac{1}{\\pi} \\left( \\frac{5\\pi}{16} \\right) = \\frac{5}{16} $$\n\n**4. $\\mathrm{Beta}(1,1)$先验下的先验预测概率**\n\n$\\mathrm{Beta}(1,1)$先验是$(0,1)$上的均匀先验，其概率密度函数为 $p_U(\\theta) = 1$，$\\theta \\in (0,1)$。\n先验预测概率 $P_U(Y=3|n=3)$ 为：\n$$ P_U(Y=3|n=3) = \\int_0^1 P(Y=3|\\theta, n=3) p_U(\\theta) d\\theta $$\n$$ P_U(Y=3|n=3) = \\int_0^1 \\theta^3 \\cdot 1 d\\theta = \\left[ \\frac{\\theta^4}{4} \\right]_0^1 = \\frac{1}{4} - 0 = \\frac{1}{4} $$\n\n**5. 先验预测概率的比率**\n\n最后，我们计算Jeffreys先验下的先验预测概率与$\\mathrm{Beta}(1,1)$先验下的先验预测概率的比率。\n$$ \\text{比率} = \\frac{P_J(Y=3|n=3)}{P_U(Y=3|n=3)} = \\frac{5/16}{1/4} $$\n$$ \\text{比率} = \\frac{5}{16} \\times \\frac{4}{1} = \\frac{20}{16} = \\frac{5}{4} $$\n这个比率表明，与均匀先验相比，Jeffreys先验为极端结果（全部成功或全部失败）分配了更高的概率。", "answer": "$$\n\\boxed{\\frac{5}{4}}\n$$", "id": "4912591"}, {"introduction": "前面的练习为你打下了坚实的理论基础，现在是时候将这些知识应用于更接近真实世界生物统计分析的场景了。在这个综合性练习中，你将为逻辑回归模型构建一个完整的贝叶斯分析流程。你将通过实现一个先验敏感性分析来评估不同强度的先验信念对模型结论的影响，这是任何严谨贝叶斯分析中不可或缺的一步。通过这个实践，你将学会如何评估模型的稳健性，并理解先验选择在实际建模中的重要性和责任。[@problem_id:4912456]", "problem": "考虑一个用于生物统计学的二元结果模型，其中独立观测值 $\\{(y_i, \\mathbf{x}_i)\\}_{i=1}^n$ 满足 $y_i \\in \\{0,1\\}$，$\\mathbf{x}_i \\in \\mathbb{R}^p$ 表示一个包含截距的预测变量向量。假设一个逻辑斯蒂回归似然，其中以系数 $\\boldsymbol{\\beta} \\in \\mathbb{R}^p$ 为条件，响应变量是独立的伯努利分布，其概率为 $p_i = \\sigma(\\eta_i)$，$\\eta_i = \\mathbf{x}_i^\\top \\boldsymbol{\\beta}$ 且 $\\sigma(z) = \\frac{1}{1 + e^{-z}}$。为每个系数采用独立的零均值正态先验：$\\beta_j \\overset{\\text{ind}}{\\sim} \\mathcal{N}(0, \\tau^2)$，对于 $j = 1,\\dots,p$，其中 $\\tau > 0$ 是在所有系数间共享的先验尺度超参数。\n\n从贝叶斯定理和上述定义出发，后验密度正比于似然与先验的乘积，即 $\\pi(\\boldsymbol{\\beta} \\mid \\mathbf{y}, X) \\propto L(\\boldsymbol{\\beta}; \\mathbf{y}, X) \\, \\pi(\\boldsymbol{\\beta}; \\tau)$。您必须从第一性原理推导对数后验函数及其关于 $\\boldsymbol{\\beta}$ 的梯度和海森矩阵，然后使用二阶方法找到后验众数。使用以众数为中心的拉普拉斯（正态）近似，您必须计算与单个生物标志物预测变量相关的斜率系数的后验摘要：近似后验均值（在正态近似下等于众数）和基于正态近似的近似对称 $0.95$ 可信区间。\n\n推导必须从以下几点开始：\n- 贝叶斯定理，$\\pi(\\boldsymbol{\\beta} \\mid \\mathbf{y}, X) \\propto L(\\boldsymbol{\\beta}; \\mathbf{y}, X) \\, \\pi(\\boldsymbol{\\beta}; \\tau)$。\n- 逻辑斯蒂链接下的伯努利似然，$L(\\boldsymbol{\\beta}; \\mathbf{y}, X) = \\prod_{i=1}^n p_i^{y_i} (1-p_i)^{1-y_i}$，其中 $p_i = \\sigma(\\mathbf{x}_i^\\top \\boldsymbol{\\beta})$。\n- 独立正态先验，$\\pi(\\boldsymbol{\\beta}; \\tau) \\propto \\exp\\!\\left(-\\frac{1}{2\\tau^2} \\boldsymbol{\\beta}^\\top \\boldsymbol{\\beta}\\right)$。\n\n您不能使用预先推导的快捷公式。解答应表达对数后验，并从上述定义推导其梯度和海森矩阵。然后，设计一个使用牛顿类型更新的算法来定位后验众数，并使用在众数处的负海森矩阵的逆进行拉普拉斯近似，以形成近似后验协方差矩阵。使用这些来计算斜率系数的后验均值和 $0.95$ 可信区间。\n\n通过在指定的测试套件上改变先验尺度 $\\tau$ 来进行先验敏感性分析。使用单个预测变量加截距（$p=2$）和两个数据集：\n\n- 数据集 A（非可分）：$n = 11$ 个观测值，预测变量值为 $x \\in \\{-2.0, -1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0\\}$，结果为\n  $y \\in \\{0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1\\}$。\n  设计矩阵 $X$ 由一列全为1的截距项和第二列等于 $x$ 构成。\n\n- 数据集 B（近乎可分）：$n = 11$ 个观测值，具有相同的预测变量值 $x \\in \\{-2.0, -1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0\\}$，结果为\n  $y \\in \\{0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1\\}$。\n  设计矩阵 $X$ 的构造方式相同。\n\n将先验尺度超参数测试套件定义为 $\\tau \\in \\{0.001, 0.1, 1.0, 1000.0\\}$。对于测试套件中的每个数据集和每个 $\\tau$，计算：\n- 斜率系数（对应于生物标志物预测变量的第二个系数）的近似后验均值。\n- 近似 $0.95$ 可信区间的下端点和上端点，其获得方式为后验均值加减 $z_{0.975} \\sqrt{\\text{Var}}$，其中 $z_{0.975}$ 是标准正态分布的 $0.975$ 分位数，$\\text{Var}$ 是从拉普拉斯近似得到的斜率系数的近似后验方差。\n\n不涉及物理单位或角度单位。不要将任何量表示为百分比；所有报告的值必须为十进制形式。\n\n您的程序必须产生单行输出，该输出包含一个用方括号括起来的逗号分隔列表形式的结果。列表中的每个元素本身必须是一个包含三个浮点数的列表，顺序为 $[\\text{posterior\\_mean}, \\text{lower\\_CI}, \\text{upper\\_CI}]$，代表斜率系数。元素的排序必须首先按数据集 A 的四个 $\\tau$ 值（按 $0.001, 0.1, 1.0, 1000.0$ 的顺序），然后按数据集 B 的相同四个 $\\tau$ 值。例如，最终输出格式为\n$[[m_1,\\ell_1,u_1],[m_2,\\ell_2,u_2],\\dots,[m_8,\\ell_8,u_8]]$，\n其中 $m_k$ 是案例 $k$ 的斜率系数的后验均值，$\\ell_k, u_k$ 是对应的 $0.95$ 可信区间的下端点和上端点。", "solution": "用户在贝叶斯生物统计学领域提供了一个有效的问题陈述。该问题具有科学依据、提法恰当，且解决问题所需的所有组成部分均已指定。我现在将进行推导和求解。\n\n目标是对逻辑斯蒂回归模型进行贝叶斯分析。这包括推导模型参数 $\\boldsymbol{\\beta}$ 的后验分布，找到后验众数，并使用拉普拉斯近似来计算特定系数的汇总统计量。\n\n### 1. 对数后验分布\n\n根据贝叶斯定理，参数 $\\boldsymbol{\\beta}$ 在给定数据 $(\\mathbf{y}, X)$ 下的后验概率密度正比于数据在给定参数下的似然与参数先验概率的乘积：\n$$\n\\pi(\\boldsymbol{\\beta} \\mid \\mathbf{y}, X) \\propto L(\\boldsymbol{\\beta}; \\mathbf{y}, X) \\, \\pi(\\boldsymbol{\\beta}; \\tau)\n$$\n问题指定了逻辑斯蒂回归模型，因此 $n$ 次独立伯努利试验的似然为：\n$$\nL(\\boldsymbol{\\beta}; \\mathbf{y}, X) = \\prod_{i=1}^n p_i^{y_i} (1-p_i)^{1-y_i}\n$$\n其中 $y_i \\in \\{0, 1\\}$ 是观测结果，$p_i$ 是第 $i$ 次观测成功的概率。这个概率通过逻辑斯蒂函数建模，$p_i = \\sigma(\\eta_i)$，其中 $\\sigma(z) = \\frac{1}{1+e^{-z}}$ 是S型函数，$\\eta_i = \\mathbf{x}_i^\\top \\boldsymbol{\\beta}$ 是线性预测器。\n\n系数 $\\beta_j$ 的先验分布被给定为独立的零均值正态分布：$\\beta_j \\sim \\mathcal{N}(0, \\tau^2)$。对于整个参数向量 $\\boldsymbol{\\beta} \\in \\mathbb{R}^p$，联合先验密度为：\n$$\n\\pi(\\boldsymbol{\\beta}; \\tau) = \\prod_{j=1}^p \\frac{1}{\\sqrt{2\\pi\\tau^2}} \\exp\\left(-\\frac{\\beta_j^2}{2\\tau^2}\\right) \\propto \\exp\\left(-\\frac{1}{2\\tau^2} \\sum_{j=1}^p \\beta_j^2\\right) = \\exp\\left(-\\frac{1}{2\\tau^2} \\boldsymbol{\\beta}^\\top \\boldsymbol{\\beta}\\right)\n$$\n为了分析和计算上的方便，我们处理后验分布的对数，$\\ell_p(\\boldsymbol{\\beta}) = \\log \\pi(\\boldsymbol{\\beta} \\mid \\mathbf{y}, X)$。省略不依赖于 $\\boldsymbol{\\beta}$ 的常数：\n$$\n\\ell_p(\\boldsymbol{\\beta}) = \\log L(\\boldsymbol{\\beta}; \\mathbf{y}, X) + \\log \\pi(\\boldsymbol{\\beta}; \\tau) + C\n$$\n对数似然项为：\n$$\n\\log L(\\boldsymbol{\\beta}) = \\sum_{i=1}^n \\left[ y_i \\log(p_i) + (1-y_i)\\log(1-p_i) \\right]\n$$\n利用逻辑斯蒂链接函数的性质，$\\eta_i = \\log(p_i/(1-p_i))$ 和 $\\log(1-p_i) = -\\log(1+e^{\\eta_i})$，我们可以简化对数似然：\n$$\n\\log L(\\boldsymbol{\\beta}) = \\sum_{i=1}^n \\left[ y_i \\log\\left(\\frac{p_i}{1-p_i}\\right) + \\log(1-p_i) \\right] = \\sum_{i=1}^n \\left[ y_i \\eta_i - \\log(1+e^{\\eta_i}) \\right]\n$$\n代入 $\\eta_i = \\mathbf{x}_i^\\top \\boldsymbol{\\beta}$，完整的对数后验函数（相差一个加法常数）为：\n$$\n\\ell_p(\\boldsymbol{\\beta}) = \\sum_{i=1}^n \\left[ y_i (\\mathbf{x}_i^\\top \\boldsymbol{\\beta}) - \\log(1 + e^{\\mathbf{x}_i^\\top \\boldsymbol{\\beta}}) \\right] - \\frac{1}{2\\tau^2} \\boldsymbol{\\beta}^\\top \\boldsymbol{\\beta}\n$$\n\n### 2. 对数后验的梯度和海森矩阵\n\n为了找到后验众数（最大后验估计或MAP估计），我们必须找到使 $\\ell_p(\\boldsymbol{\\beta})$ 最大化的 $\\boldsymbol{\\beta}$ 值。这可以通过找到对数后验梯度 $\\nabla \\ell_p(\\boldsymbol{\\beta})$ 的根来实现。牛顿类型的优化方法还需要海森矩阵 $\\nabla^2 \\ell_p(\\boldsymbol{\\beta})$。\n\n**梯度：**\n梯度 $\\nabla \\ell_p(\\boldsymbol{\\beta})$ 是偏导数 $\\frac{\\partial \\ell_p}{\\partial \\beta_j}$（对于 $j=1, \\dots, p$）的向量。\n我们使用链式法则和S型函数的导数，$\\frac{d\\sigma(z)}{dz} = \\sigma(z)(1-\\sigma(z))$。\n对数似然项关于 $\\beta_j$ 的导数是：\n$$\n\\frac{\\partial}{\\partial \\beta_j} \\sum_{i=1}^n \\left[ y_i \\eta_i - \\log(1+e^{\\eta_i}) \\right] = \\sum_{i=1}^n \\left[ y_i \\frac{\\partial \\eta_i}{\\partial \\beta_j} - \\frac{e^{\\eta_i}}{1+e^{\\eta_i}}\\frac{\\partial \\eta_i}{\\partial \\beta_j} \\right] = \\sum_{i=1}^n \\left[ y_i x_{ij} - p_i x_{ij} \\right] = \\sum_{i=1}^n (y_i - p_i) x_{ij}\n$$\n以向量形式，对数似然的梯度是 $\\nabla \\ell(\\boldsymbol{\\beta}) = X^\\top(\\mathbf{y} - \\mathbf{p})$，其中 $\\mathbf{p}$ 是概率 $p_i$ 的向量。\n对数先验项的梯度是：\n$$\n\\nabla \\left(-\\frac{1}{2\\tau^2} \\boldsymbol{\\beta}^\\top \\boldsymbol{\\beta}\\right) = -\\frac{1}{\\tau^2} \\boldsymbol{\\beta}\n$$\n结合这些，完整的对数后验梯度是：\n$$\n\\nabla \\ell_p(\\boldsymbol{\\beta}) = X^\\top(\\mathbf{y} - \\mathbf{p}) - \\frac{1}{\\tau^2} \\boldsymbol{\\beta}\n$$\n\n**海森矩阵：**\n海森矩阵 $H(\\boldsymbol{\\beta}) = \\nabla^2 \\ell_p(\\boldsymbol{\\beta})$ 是二阶偏导数矩阵，$H_{jk} = \\frac{\\partial^2 \\ell_p}{\\partial \\beta_j \\partial \\beta_k}$。\n对数似然项的二阶导数是：\n$$\n\\frac{\\partial^2 \\ell(\\boldsymbol{\\beta})}{\\partial \\beta_k \\partial \\beta_j} = \\frac{\\partial}{\\partial \\beta_k} \\sum_{i=1}^n (y_i - p_i) x_{ij} = \\sum_{i=1}^n -x_{ij} \\frac{\\partial p_i}{\\partial \\beta_k} = \\sum_{i=1}^n -x_{ij} \\left[p_i(1-p_i)\\frac{\\partial \\eta_i}{\\partial \\beta_k}\\right] = \\sum_{i=1}^n -x_{ij} [p_i(1-p_i) x_{ik}]\n$$\n以矩阵形式，令 $W$ 为一个对角矩阵，其对角线元素为 $W_{ii} = p_i(1-p_i)$。对数似然的海森矩阵是 $\\nabla^2 \\ell(\\boldsymbol{\\beta}) = -X^\\top W X$。\n对数先验项的海森矩阵是：\n$$\n\\nabla^2 \\left(-\\frac{1}{2\\tau^2} \\boldsymbol{\\beta}^\\top \\boldsymbol{\\beta}\\right) = -\\frac{1}{\\tau^2} I_p\n$$\n其中 $I_p$ 是 $p \\times p$ 的单位矩阵。\n完整的对数后验海森矩阵是：\n$$\nH(\\boldsymbol{\\beta}) = \\nabla^2 \\ell_p(\\boldsymbol{\\beta}) = -X^\\top W X - \\frac{1}{\\tau^2} I_p\n$$\n由于 $W_{ii} = p_i(1-p_i) \\ge 0$，矩阵 $X^\\top W X$ 是半正定的。对于 $\\tau > 0$，先验项 $-\\frac{1}{\\tau^2} I_p$ 是严格负定的。因此，海森矩阵 $H(\\boldsymbol{\\beta})$ 是严格负定的，这意味着对数后验分布 $\\ell_p(\\boldsymbol{\\beta})$ 是严格凹的。这保证了唯一的后验众数。\n\n### 3. 数值优化与拉普拉斯近似\n\n**牛顿法：**\n我们通过迭代应用牛顿-拉夫逊更新规则直到收敛来找到后验众数 $\\hat{\\boldsymbol{\\beta}}_{\\text{MAP}}$。从一个初始猜测 $\\boldsymbol{\\beta}^{(0)}$ 开始，第 $t$ 步的更新是：\n$$\n\\boldsymbol{\\beta}^{(t+1)} = \\boldsymbol{\\beta}^{(t)} - [H(\\boldsymbol{\\beta}^{(t)})]^{-1} \\nabla \\ell_p(\\boldsymbol{\\beta}^{(t)})\n$$\n算法按以下步骤进行：\n1. 初始化 $\\boldsymbol{\\beta}^{(0)}$，例如，设为一个零向量。\n2. 对于 $t=0, 1, 2, \\dots$ 直到收敛：\n   a. 使用 $\\boldsymbol{\\beta}^{(t)}$ 计算概率 $\\mathbf{p}^{(t)}$ 和权重矩阵 $W^{(t)}$。\n   b. 计算梯度 $\\nabla \\ell_p(\\boldsymbol{\\beta}^{(t)})$ 和海森矩阵 $H(\\boldsymbol{\\beta}^{(t)})$。\n   c. 计算更新步长 $\\Delta\\boldsymbol{\\beta} = -[H(\\boldsymbol{\\beta}^{(t)})]^{-1} \\nabla \\ell_p(\\boldsymbol{\\beta}^{(t)})$。这在数值上通过求解线性系统 $H(\\boldsymbol{\\beta}^{(t)}) \\Delta\\boldsymbol{\\beta} = -\\nabla \\ell_p(\\boldsymbol{\\beta}^{(t)})$ 来实现。\n   d. 更新参数：$\\boldsymbol{\\beta}^{(t+1)} = \\boldsymbol{\\beta}^{(t)} + \\Delta\\boldsymbol{\\beta}$。\n3. 当更新步长的范数 $||\\Delta\\boldsymbol{\\beta}||$ 小于预定义的容差时，达到收敛。最终的向量是MAP估计 $\\hat{\\boldsymbol{\\beta}}_{\\text{MAP}}$。\n\n**拉普拉斯近似：**\n拉普拉斯近似指出，一个分布可以用一个以其众数为中心的正态分布来近似。我们将后验分布 $\\pi(\\boldsymbol{\\beta} \\mid \\mathbf{y}, X)$ 近似为：\n$$\n\\boldsymbol{\\beta} \\mid \\mathbf{y}, X \\approx \\mathcal{N}(\\hat{\\boldsymbol{\\beta}}_{\\text{MAP}}, \\Sigma_{\\text{post}})\n$$\n协方差矩阵 $\\Sigma_{\\text{post}}$ 是在众数处评估的对数后验的海森矩阵的负逆：\n$$\n\\Sigma_{\\text{post}} = [-H(\\hat{\\boldsymbol{\\beta}}_{\\text{MAP}})]^{-1} = [X^\\top \\hat{W} X + \\frac{1}{\\tau^2} I_p]^{-1}\n$$\n其中 $\\hat{W}$ 是使用在 $\\hat{\\boldsymbol{\\beta}}_{\\text{MAP}}$ 处评估的概率计算出的权重矩阵 $W$。\n\n### 4. 斜率系数的后验推断\n\n在这个问题中，$p=2$ 且 $\\boldsymbol{\\beta} = (\\beta_0, \\beta_1)^\\top$，其中 $\\beta_1$ 是生物标志物的斜率系数。拉普拉斯近似为 $(\\beta_0, \\beta_1)$ 的联合后验提供了一个二元正态近似。\n斜率系数 $\\beta_1$ 的边际后验也近似为正态分布：\n$$\n\\beta_1 \\mid \\mathbf{y}, X \\approx \\mathcal{N}((\\hat{\\boldsymbol{\\beta}}_{\\text{MAP}})_1, (\\Sigma_{\\text{post}})_{11})\n$$\n- $\\beta_1$ 的近似后验均值是众数向量的第二个分量，$(\\hat{\\boldsymbol{\\beta}}_{\\text{MAP}})_1$。\n- $\\beta_1$ 的近似后验方差是协方差矩阵的第二个对角元素，$(\\Sigma_{\\text{post}})_{11}$。\n\n$\\beta_1$ 的一个近似对称 $0.95$ 可信区间构造如下：\n$$\n\\text{后验均值} \\pm z_{0.975} \\times \\text{后验标准差}\n$$\n$$\n(\\hat{\\boldsymbol{\\beta}}_{\\text{MAP}})_1 \\pm z_{0.975} \\sqrt{(\\Sigma_{\\text{post}})_{11}}\n$$\n其中 $z_{0.975} \\approx 1.96$ 是标准正态分布的 $0.975$ 分位数。下面的代码为指定的数据集和先验敏感性分析实现了这个过程。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Performs Bayesian logistic regression analysis for two datasets under\n    different prior specifications, calculating the posterior mean and 95%\n    credible interval for the slope coefficient using a Laplace approximation.\n    \"\"\"\n\n    # --- Problem Data Definition ---\n\n    # Dataset A (non-separable)\n    x_A = np.array([-2.0, -1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0])\n    y_A = np.array([0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1])\n    X_A = np.vstack([np.ones(x_A.shape[0]), x_A]).T\n\n    # Dataset B (nearly separable)\n    x_B = np.array([-2.0, -1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0])\n    y_B = np.array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n    X_B = np.vstack([np.ones(x_B.shape[0]), x_B]).T\n    \n    # Prior hyperparameter test suite\n    taus = [0.001, 0.1, 1.0, 1000.0]\n\n    # Assemble test cases\n    test_cases = []\n    datasets = [(X_A, y_A), (X_B, y_B)]\n    for X, y in datasets:\n        for tau in taus:\n            test_cases.append((X, y, tau))\n\n    # --- Main Calculation ---\n\n    results = []\n    \n    # Quantile for 95% credible interval\n    z_crit = norm.ppf(0.975)\n\n    for case in test_cases:\n        X, y, tau = case\n        \n        # --- Newton-Raphson for Posterior Mode ---\n        p_dim = X.shape[1]\n        beta = np.zeros(p_dim)\n        max_iter = 100\n        tolerance = 1e-9\n\n        for _ in range(max_iter):\n            # Linear predictor\n            eta = X @ beta\n            # Probabilities using sigmoid function\n            p_vec = 1.0 / (1.0 + np.exp(-eta))\n            \n            # Gradient of the log-posterior\n            grad = X.T @ (y - p_vec) - (1.0 / tau**2) * beta\n\n            # Hessian of the log-posterior\n            weights = p_vec * (1.0 - p_vec)\n            W = np.diag(weights)\n            hessian = -X.T @ W @ X - (1.0 / tau**2) * np.identity(p_dim)\n\n            # Newton-Raphson update step, solving H * update = -grad\n            update = np.linalg.solve(hessian, -grad)\n            beta += update\n\n            # Convergence check\n            if np.linalg.norm(update)  tolerance:\n                break\n        \n        beta_map = beta\n\n        # --- Laplace Approximation ---\n        # Re-compute Hessian at the mode\n        eta_map = X @ beta_map\n        p_map = 1.0 / (1.0 + np.exp(-eta_map))\n        weights_map = p_map * (1.0 - p_map)\n        W_map = np.diag(weights_map)\n        hessian_map = -X.T @ W_map @ X - (1.0 / tau**2) * np.identity(p_dim)\n\n        # Approximate posterior covariance matrix\n        post_cov = -np.linalg.inv(hessian_map)\n\n        # --- Extract Summaries for the Slope Coefficient ---\n        # Slope is the second coefficient (index 1)\n        post_mean_slope = beta_map[1]\n        post_var_slope = post_cov[1, 1]\n        post_sd_slope = np.sqrt(post_var_slope)\n\n        lower_ci = post_mean_slope - z_crit * post_sd_slope\n        upper_ci = post_mean_slope + z_crit * post_sd_slope\n\n        results.append([post_mean_slope, lower_ci, upper_ci])\n\n    # --- Final Output Formatting ---\n    # The string representation of a list of lists needs to be precise.\n    # The prompt shows `[[m1,l1,u1],[m2,l2,u2],...]`\n    # Python's `str()` on a list adds spaces, so we build the string manually.\n    inner_strs = [f\"[{r[0]},{r[1]},{r[2]}]\" for r in results]\n    final_output = f\"[{','.join(inner_strs)}]\"\n    \n    # Correction: The prompt's example implies `','.join(map(str, results))` is acceptable.\n    # Let's re-verify. `str([[1,2,3],[4,5,6]])` is `'[[1, 2, 3], [4, 5, 6]]'`. This has spaces.\n    # The prompt output `[[m_1,\\ell_1,u_1],[m_2,\\ell_2,u_2],\\dots,[m_8,\\ell_8,u_8]]` is ambiguous about spaces.\n    # The example `','.join(map(str, results))` is a clearer instruction.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "4912456"}]}