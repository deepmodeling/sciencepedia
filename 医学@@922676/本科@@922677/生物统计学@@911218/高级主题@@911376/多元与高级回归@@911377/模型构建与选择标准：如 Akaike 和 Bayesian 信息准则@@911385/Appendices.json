{"hands_on_practices": [{"introduction": "像AIC和BIC这样的模型选择准则的准确性，取决于我们能否正确确定模型中被估计的参数数量 $k$。这个基础练习 [@problem_id:4928632] 将考验你在广义线性模型中确定有效参数数量的能力，这种情况因可识别性约束和偏移量等常见特征而变得复杂。掌握这项技能是进行可靠模型比较的首要基本步骤。", "problem": "一项临床监测研究使用带对数连接的泊松广义线性模型来建模 $J=5$ 家医院的院内感染计数。对于医院 $j$ 的患者 $i$，平均计数 $ \\mu_{ij} $ 通过以下方式建模：\n$$\n\\log(\\mu_{ij}) = \\alpha + \\beta X_{ij} + \\gamma_j + \\log(E_{ij}),\n$$\n其中，$X_{ij}$ 是测量的风险评分，$E_{ij}$ 是暴露时间（一个作为偏移量并入的已知量），$\\gamma_j$ 是受和为零可识别性约束 $\\sum_{j=1}^{5} \\gamma_j = 0$ 影响的医院特定效应，$\\alpha$ 是全局截距。第二个候选模型利用先前的监测知识，通过将一个已知常数 $r_0$ 并入偏移量并移除截距来固定基线率：\n$$\n\\log(\\mu_{ij}) = \\beta X_{ij} + \\gamma_j + \\log(E_{ij}) + \\log(r_0),\n$$\n$\\gamma_j$ 同样受和为零约束。两个模型都通过最大似然法进行拟合。\n\n设第一个模型的最大对数似然为 $\\hat{\\ell}_1 = -120.3$，第二个模型的最大对数似然为 $\\hat{\\ell}_2 = -119.1$。对于每个模型，生物统计学家必须确定反映在所述约束和偏移量处理下参数空间有效维数的适当参数个数 $k$，然后计算赤池信息准则 (AIC) 以比较模型。\n\n哪个选项正确地指出了两个模型的有效参数个数 $k$ 以及相应的 AIC 值？\n\nA) 模型1: $k=6$, $\\mathrm{AIC}_1 = 252.6$; 模型2: $k=5$, $\\mathrm{AIC}_2 = 248.2$。\n\nB) 模型1: $k=7$ (将偏移量计为一个参数), $\\mathrm{AIC}_1 = 254.6$; 模型2: $k=6$, $\\mathrm{AIC}_2 = 250.2$。\n\nC) 模型1: $k=5$ (和为零施加了两个约束), $\\mathrm{AIC}_1 = 250.6$; 模型2: $k=4$, $\\mathrm{AIC}_2 = 246.2$。\n\nD) 模型1: $k=6$, $\\mathrm{AIC}_1 = 252.6$; 模型2: $k=6$ (尽管截距已固定在偏移量中，但仍计算在内), $\\mathrm{AIC}_2 = 250.2$。", "solution": "### 第1步：提取已知信息\n问题提供了以下信息：\n-   医院数量：$J=5$。\n-   模型1（带截距 $\\alpha$）：\n    $$ \\log(\\mu_{ij}) = \\alpha + \\beta X_{ij} + \\gamma_j + \\log(E_{ij}) $$\n-   模型2（不带截距 $\\alpha$，使用已知常数 $r_0$）：\n    $$ \\log(\\mu_{ij}) = \\beta X_{ij} + \\gamma_j + \\log(E_{ij}) + \\log(r_0) $$\n-   对于两个模型，医院特定效应都存在一个和为零的可识别性约束：\n    $$ \\sum_{j=1}^{5} \\gamma_j = 0 $$\n-   $E_{ij}$ 是一个已知量，$\\log(E_{ij})$ 是一个偏移量。\n-   $r_0$ 是一个已知常数。\n-   模型通过最大似然法拟合。\n-   模型1的最大对数似然：$\\hat{\\ell}_1 = -120.3$。\n-   模型2的最大对数似然：$\\hat{\\ell}_2 = -119.1$。\n-   任务是为每个模型找出有效参数个数 $k$，并计算赤池信息准则 (AIC)。\n\n### 第2步：使用提取的已知信息进行验证\n问题陈述具有科学依据、定义明确且客观。\n-   **科学依据**：问题描述了一个标准的生物统计学分析，使用了泊松广义线性模型，这是计数数据建模的基石。对数连接、用于暴露的偏移量、为保证可识别性而设的和为零约束的固定效应，以及使用AIC进行模型比较等概念，在统计学领域都是基础且公认的。\n-   **定义明确**：问题提供了得出唯一解所需的所有要素。模型、约束和最大对数似然值都已明确指定。AIC的定义是标准的。核心任务——确定有效参数个数——是一个定义明确的统计学问题。\n-   **客观性**：问题使用统计学中常见、精确、无歧义的术语进行陈述。不存在主观或基于意见的元素。\n\n问题不违反任何无效性标准。这是一个在生物统计学中有效、可解的问题。\n\n### 第3步：推导解答\n\n赤池信息准则 (AIC) 定义为：\n$$ \\mathrm{AIC} = -2\\hat{\\ell} + 2k $$\n其中 $k$ 是模型中估计参数的数量，$\\hat{\\ell}$ 是对数似然函数的最大值。解决此问题的关键是正确确定每个模型的有效参数数量 $k$。\n\n**模型1分析**\n\n第一个模型是：\n$$ \\log(\\mu_{ij}) = \\alpha + \\beta X_{ij} + \\gamma_j + \\log(E_{ij}) $$\n需要通过最大似然估计的参数是：\n1.  全局截距 $\\alpha$。这是1个参数。\n2.  风险评分的系数 $\\beta$。这是1个参数。\n3.  医院特定效应 $\\gamma_1, \\gamma_2, \\gamma_3, \\gamma_4, \\gamma_5$。共有 $J=5$ 个这样的项。\n\n简单地看，这似乎是 $1 + 1 + 5 = 7$ 个参数。然而，这些参数受到约束 $\\sum_{j=1}^{5} \\gamma_j = 0$ 的限制。这是一个单一的线性约束，它将自由参数的数量减少了1。如果我们知道任意4个 $\\gamma_j$ 的值，第5个就自动确定了。例如，$\\gamma_5 = -(\\gamma_1 + \\gamma_2 + \\gamma_3 + \\gamma_4)$。因此，这5个医院效应 $\\gamma_j$ 只对模型贡献了 $J-1 = 5-1=4$ 个有效参数。\n\n$\\log(E_{ij})$ 项是一个偏移量。根据定义，偏移量是一个系数固定为1的预测变量，其值不是从数据中估计的。因此，它不计入估计参数的数量 $k$。\n\n模型1的总有效参数数量为：\n$$ k_1 = (\\text{用于 } \\alpha) + (\\text{用于 } \\beta) + (\\text{用于 } \\gamma_j \\text{ 集合}) = 1 + 1 + (5-1) = 6 $$\n当 $k_1 = 6$ 且给定的最大对数似然 $\\hat{\\ell}_1 = -120.3$ 时，模型1的 AIC 为：\n$$ \\mathrm{AIC}_1 = -2\\hat{\\ell}_1 + 2k_1 = -2(-120.3) + 2(6) = 240.6 + 12 = 252.6 $$\n\n**模型2分析**\n\n第二个模型是：\n$$ \\log(\\mu_{ij}) = \\beta X_{ij} + \\gamma_j + \\log(E_{ij}) + \\log(r_0) $$\n在这个模型中，截距 $\\alpha$ 被移除了。增加了 $\\log(r_0)$ 项，其中 $r_0$ 是一个已知常数。这意味着 $\\log(r_0)$ 不是一个待估计的参数；它是偏移量的一部分，现在的偏移量是 $\\log(E_{ij}) + \\log(r_0)$。\n\n需要通过最大似然估计的参数是：\n1.  风险评分的系数 $\\beta$。这是1个参数。\n2.  医院特定效应 $\\gamma_1, \\ldots, \\gamma_5$，它们仍然受到约束 $\\sum_{j=1}^{5} \\gamma_j = 0$ 的限制。与模型1一样，它们贡献了 $J-1 = 4$ 个有效参数。\n\n模型2的总有效参数数量为：\n$$ k_2 = (\\text{用于 } \\beta) + (\\text{用于 } \\gamma_j \\text{ 集合}) = 1 + (5-1) = 5 $$\n当 $k_2 = 5$ 且给定的最大对数似然 $\\hat{\\ell}_2 = -119.1$ 时，模型2的 AIC 为：\n$$ \\mathrm{AIC}_2 = -2\\hat{\\ell}_2 + 2k_2 = -2(-119.1) + 2(5) = 238.2 + 10 = 248.2 $$\n\n**结果总结：**\n-   对于模型1：$k_1 = 6$，$\\mathrm{AIC}_1 = 252.6$。\n-   对于模型2：$k_2 = 5$，$\\mathrm{AIC}_2 = 248.2$。\n\n### 逐项分析\n\n**A) 模型1: $k=6$, $\\mathrm{AIC}_1 = 252.6$; 模型2: $k=5$, $\\mathrm{AIC}_2 = 248.2$。**\n这个选项与我们为两个模型推导出的结果完全匹配。\n-   模型1: $k_1 = 1(\\alpha) + 1(\\beta) + (5-1)(\\gamma_j) = 6$。$\\mathrm{AIC}_1 = 2(6) - 2(-120.3) = 252.6$。\n-   模型2: $k_2 = 1(\\beta) + (5-1)(\\gamma_j) = 5$。$\\mathrm{AIC}_2 = 2(5) - 2(-119.1) = 248.2$。\n**结论：正确。**\n\n**B) 模型1: $k=7$ (将偏移量计为一个参数), $\\mathrm{AIC}_1 = 254.6$; 模型2: $k=6$, $\\mathrm{AIC}_2 = 250.2$。**\n这个选项基于对什么是估计参数的误解。偏移量是一个系数固定为1的已知量；它不是被估计的，因此不计入 $k$。该选项也错误地计算了 $\\gamma_j$ 集合的参数数量，因为它忽略了和为零的约束。对于模型1，它似乎计算 $k_1 = 1(\\alpha) + 1(\\beta) + 5(\\gamma_j) = 7$。对于模型2，它计算 $k_2 = 1(\\beta) + 5(\\gamma_j) = 6$。两个计数都是错误的。\n**结论：错误。**\n\n**C) 模型1: $k=5$ (和为零施加了两个约束), $\\mathrm{AIC}_1 = 250.6$; 模型2: $k=4$, $\\mathrm{AIC}_2 = 246.2$。**\n这个选项错误地指出和为零约束施加了两个约束。方程 $\\sum_{j=1}^{5} \\gamma_j = 0$ 是一个单一的线性约束，它将自由度减少1，而不是2。因此，参数计数 $k_1=5$ 和 $k_2=4$ 是错误的。\n**结论：错误。**\n\n**D) 模型1: $k=6$, $\\mathrm{AIC}_1 = 252.6$; 模型2: $k=6$ (尽管截距已固定在偏移量中，但仍计算在内), $\\mathrm{AIC}_2 = 250.2$。**\n这个选项正确地分析了模型1。然而，它对模型2的分析是有缺陷的。理由“尽管截距已固定在偏移量中，但仍计算在内”是毫无意义的。在模型2中，参数 $\\alpha$ 被移除，并被一个已知常数 $\\log(r_0)$ 所取代。一个已知常数不是一个估计参数，不计入 $k$。模型2的正确参数计数是 $k_2=5$，而不是 $k_2=6$。\n**结论：错误。**", "answer": "$$\\boxed{A}$$", "id": "4928632"}, {"introduction": "虽然AIC为模型选择提供了强大的工具，但在数据有限的研究中其表现可能并非最佳。本练习 [@problem_id:4928685] 介绍了校正后的赤池信息量准则（AICc），它在小样本情况下对模型的复杂性施加了更严格的惩罚。通过解决这个问题，你将理解在何种情况下以及为何这种校正是避免过拟合的关键。", "problem": "一位生物统计学家使用逻辑连接函数拟合了一个广义线性模型（GLM），以分析一项关于独立受试者研究中的二元结果。样本量为 $n=60$。该模型包含 $k=10$ 个未知参数（包括截距项）。拟合模型的最大化对数似然值为 $\\hat{\\ell}=-36.7$。使用连接模型选择与预期 Kullback–Leibler 散度的核心原理，确定该模型的赤池信息准则（AIC）和修正的赤池信息准则（AICc）。然后，对于此模型规模和样本量，量化 AICc 相对于 AIC 所隐含的惩罚项之间的差异。将此惩罚项差异作为您的最终答案，并四舍五入到四位有效数字。", "solution": "该问题要求计算对于一个给定的广义线性模型，修正的赤池信息准则（AICc）和标准赤池信息准则（AIC）的惩罚项之间的差异。\n\n首先，我们来定义 AIC。赤池信息准则是一种广泛用于模型选择的度量标准。它建立在估计拟合模型与未知的真实数据生成过程之间的预期相对 Kullback–Leibler (KL) 散度的原理之上。AIC 的公式由下式给出：\n$$\nAIC = -2 \\hat{\\ell} + 2k\n$$\n其中 $\\hat{\\ell}$ 是模型对数似然函数的最大化值，$k$ 是模型中估计参数的数量。项 $-2 \\hat{\\ell}$ 是拟合优度的度量，而项 $2k$ 是对模型复杂度的惩罚。因此，AIC 的惩罚项是：\n$$\nP_{AIC} = 2k\n$$\n\nAIC 是预期 KL 散度的一个渐近无偏估计量。然而，对于小样本量，其性能可能不是最优的。修正的赤池信息准则（AICc）通过引入一个更大的惩罚项来调整这种小样本偏差。AICc 的公式为：\n$$\nAICc = AIC + \\frac{2k(k+1)}{n-k-1}\n$$\n其中 $n$ 是样本量。通过代入 AIC 的表达式，我们可以将 AICc 写为：\n$$\nAICc = -2 \\hat{\\ell} + 2k + \\frac{2k(k+1)}{n-k-1}\n$$\n从这个表达式中，我们可以确定 AICc 的总惩罚项是加到拟合优度项 $-2 \\hat{\\ell}$ 上的量：\n$$\nP_{AICc} = 2k + \\frac{2k(k+1)}{n-k-1}\n$$\n当样本量与参数数量的比率 $n/k$ 很小时（一个常见的经验法则是当 $n/k  40$ 时），该修正项的影响会更大。\n\n问题要求计算 AICc 相对于 AIC 所隐含的惩罚项的差异。这个差异，我们记为 $\\Delta P$，是：\n$$\n\\Delta P = P_{AICc} - P_{AIC}\n$$\n代入惩罚项的表达式：\n$$\n\\Delta P = \\left( 2k + \\frac{2k(k+1)}{n-k-1} \\right) - (2k)\n$$\n这可以简化为修正项本身：\n$$\n\\Delta P = \\frac{2k(k+1)}{n-k-1}\n$$\n\n问题提供了以下值：\n- 样本量：$n = 60$\n- 未知参数数量：$k = 10$\n- 最大化对数似然：$\\hat{\\ell} = -36.7$\n\n注意，计算惩罚项的差异不需要最大化对数似然值 $\\hat{\\ell}$，因为这个差异仅取决于 $n$ 和 $k$。\n\n现在我们可以将给定的 $n$ 和 $k$ 值代入 $\\Delta P$ 的表达式中：\n$$\n\\Delta P = \\frac{2(10)(10+1)}{60-10-1}\n$$\n$$\n\\Delta P = \\frac{2(10)(11)}{49}\n$$\n$$\n\\Delta P = \\frac{220}{49}\n$$\n现在，我们计算其数值：\n$$\n\\Delta P \\approx 4.489795918...\n$$\n问题要求答案四舍五入到四位有效数字。前四位有效数字是 $4$、$4$、$8$ 和 $9$。第五位数字是 $7$，大于或等于 $5$，所以我们将第四位有效数字向上取整。将 $9$ 向上取整得到 $0$，并向前一位进 $1$。\n$$\n\\Delta P \\approx 4.490\n$$\n末尾的零是有效数字，必须包含以表示四位有效数字的精度。这个值代表了对于一个包含 $k=10$ 个参数且样本量为 $n=60$ 的模型，AICc 相对于 AIC 施加的额外惩罚。", "answer": "$$\n\\boxed{4.490}\n$$", "id": "4928685"}, {"introduction": "我们应该选择一个具有更强预测能力的模型，还是一个更能代表真实数据生成过程的模型？这个问题是AIC与BIC之争的核心。这个高级练习 [@problem_id:4815010] 要求你将这两种准则应用于一个生存分析问题，并根据它们各自的理论目标——AIC的预测性和BIC的识别性——来解释它们的模型选择结果。", "problem": "一项生物银行队列研究使用 Cox 比例风险模型来研究心血管事件的发生时间结局。在包含 $n=600$ 个观测事件的同一数据集上拟合了两个嵌套模型。模型 $\\mathcal{M}_1$ 包含 $k_1=8$ 个协变量；模型 $\\mathcal{M}_2$ 在 $\\mathcal{M}_1$ 的基础上增加了 $4$ 个协变量，总共有 $k_2=12$ 个。最大化的对数偏似然分别为 $\\ell_{p,1}=-420.5$ 和 $\\ell_{p,2}=-418.0$。假设最大似然估计和模型选择的常规渐近正则性条件成立。\n\n从第一性原理出发：\n- 使用 Kullback-Leibler (KL) 散度作为预期样本外预测差异的度量，以及经典的偏差校正论证，来推导旨在最小化基于似然的模型的预期预测损失的大样本准则。\n- 使用贝叶斯边际似然（模型证据）、正则先验和拉普拉斯近似，通过将对数证据近似到一个在所有模型中都相同的加性常数，来推导旨在模型识别的大样本准则。\n\n在 Cox 模型设定中，将偏似然的有效样本量取为事件数，因此在任何与样本量相关的项中使用 $n=600$，并将 $k$ 取为线性预测器中回归系数的数量（不包括基线风险）。使用它们的最大化对数偏似然和参数计数，为 $\\mathcal{M}_1$ 和 $\\mathcal{M}_2$ 计算这两种准则。然后，说明每种准则偏好哪个模型，并从预测与识别的目标角度解释，如何解读两种准则不一致的情况。\n\n将您的数值结果以行向量 $(\\mathrm{AIC}_1,\\mathrm{AIC}_2,\\mathrm{BIC}_1,\\mathrm{BIC}_2)$ 的形式报告，四舍五入到 $4$ 位有效数字。", "solution": "该问题要求从第一性原理推导赤池信息准则 (AIC) 和贝叶斯信息准则 (BIC)，将它们应用于两个嵌套的 Cox 比例风险模型，并解释它们各自的目标。该问题陈述清晰且具有科学依据。\n\n问题的已知条件是：\n- 有效样本量（事件数）：$n=600$。\n- 模型 $\\mathcal{M}_1$：协变量数量 $k_1=8$。\n- 模型 $\\mathcal{M}_2$：协变量数量 $k_2=12$。\n- $\\mathcal{M}_1$ 的最大化对数偏似然：$\\ell_{p,1} = -420.5$。\n- $\\mathcal{M}_2$ 的最大化对数偏似然：$\\ell_{p,2} = -418.0$。\n\n**赤池信息准则 (AIC) 的推导**\n\nAIC 的目标是选择一个能为新数据提供最佳预测性能的模型。这被表述为找到一个模型，该模型能最小化真实数据生成分布与拟合模型之间的预期信息损失，该损失由 Kullback-Leibler (KL) 散度度量。\n\n设数据的真实未知概率分布为 $f(x)$。设 $g(x|\\theta)$ 是一个由维度为 $k$ 的向量 $\\theta$ 参数化的模型族。从 $g$ 到 $f$ 的 KL 散度定义为：\n$$ D_{KL}(f || g(\\cdot|\\theta)) = \\int f(x) \\ln\\left(\\frac{f(x)}{g(x|\\theta)}\\right) dx = \\mathbb{E}_{f}[\\ln f(x)] - \\mathbb{E}_{f}[\\ln g(x|\\theta)] $$\n由于 $\\mathbb{E}_{f}[\\ln f(x)]$ 相对于模型 $g$ 是一个常数，因此最小化 KL 散度等价于最大化模型的期望对数似然 $\\mathbb{E}_{f}[\\ln g(x|\\theta)]$。\n\n设 $\\hat{\\theta}_{obs}$ 是从大小为 $n$ 的观测数据集 $y_{obs}$ 中获得的 $\\theta$ 的最大似然估计 (MLE)。我们希望估计的量是这个拟合模型在一个从相同真实分布 $f$ 中抽取的新独立数据集 $y_{new}$ 上的预期预测准确性。即 $\\mathbb{E}_{y_{new}}[\\ln g(y_{new}|\\hat{\\theta}_{obs})]$。\n\n样本内最大化对数似然 $\\ell(\\hat{\\theta}_{obs}) = \\ln g(y_{obs}|\\hat{\\theta}_{obs})$ 是对这个目标量的一个乐观偏差估计。作为 AIC 核心的偏差校正论证量化了这种乐观性。在标准正则性条件下，对于大样本 $n$，Hirotugu Akaike 证明了：\n$$ \\mathbb{E}_{y_{obs}} \\left[ \\mathbb{E}_{y_{new}}[\\ln g(y_{new}|\\hat{\\theta}_{obs})] - \\ell(\\hat{\\theta}_{obs}) \\right] \\approx -k $$\n左边的项是样本内对数似然作为样本外预测对数似然估计量的预期乐观性。期望 $\\mathbb{E}_{y_{obs}}$ 是对所有可能的、大小为 $n$ 的训练集取的。这表明，对于数据的单次实现，目标预测量 $\\mathbb{E}_{y_{new}}[\\ln g(y_{new}|\\hat{\\theta}_{obs})]$ 的一个近似无偏估计量是偏差校正后的对数似然：\n$$ \\ell(\\hat{\\theta}_{obs}) - k $$\nAIC 的定义是将这个量乘以 $-2$。乘以 $-2$ 将 AIC 置于偏差尺度上，因此较小的值表示相对于复杂性而言更好的模型拟合度。\n$$ \\mathrm{AIC} = -2 (\\ell(\\hat{\\theta}_{obs}) - k) = -2\\ell(\\hat{\\theta}_{obs}) + 2k $$\n在 Cox 模型的背景下，对数似然被最大化对数偏似然 $\\ell_p$ 所取代。\n\n**贝叶斯信息准则 (BIC) 的推导**\n\nBIC 的目标是基于后验概率，从一组候选模型中识别出“真实”的数据生成模型。根据贝叶斯定理，给定数据 $y$ 时模型 $\\mathcal{M}_i$ 的后验概率为：\n$$ P(\\mathcal{M}_i|y) = \\frac{P(y|\\mathcal{M}_i) P(\\mathcal{M}_i)}{\\sum_j P(y|\\mathcal{M}_j) P(\\mathcal{M}_j)} $$\n假设所有模型的先验概率相等 ($P(\\mathcal{M}_i) = P(\\mathcal{M}_j)$)，选择后验概率最高的模型等价于选择边际似然或“模型证据” $P(y|\\mathcal{M})$ 最高的模型。BIC 是对 $-2 \\ln P(y|\\mathcal{M})$ 的大样本近似。\n\n边际似然是通过将似然对给定模型 $\\mathcal{M}$ 的参数 $\\theta$（维度为 $k$）的先验分布进行积分得到的：\n$$ P(y|\\mathcal{M}) = \\int P(y|\\theta, \\mathcal{M}) P(\\theta|\\mathcal{M}) d\\theta = \\int \\exp(\\ln(P(y|\\theta, \\mathcal{M})P(\\theta|\\mathcal{M}))) d\\theta $$\n令 $q(\\theta) = \\ln(P(y|\\theta, \\mathcal{M})P(\\theta|\\mathcal{M})) = \\ell(\\theta|y) + \\ln P(\\theta|\\mathcal{M})$，其中 $\\ell(\\theta|y)$ 是对数似然。我们使用拉普拉斯近似来评估大样本量 $n$ 下的这个积分。我们将 $q(\\theta)$ 在其众数周围展开为泰勒级数，对于大样本 $n$，该众数可由 MLE $\\hat{\\theta}$ 近似：\n$$ q(\\theta) \\approx q(\\hat{\\theta}) + (\\theta - \\hat{\\theta})^T \\nabla q(\\hat{\\theta}) + \\frac{1}{2}(\\theta - \\hat{\\theta})^T \\nabla^2 q(\\hat{\\theta}) (\\theta - \\hat{\\theta}) $$\n在 MLE $\\hat{\\theta}$ 处，对数似然的梯度为零。假设先验是正则的且其影响很小，则 $\\nabla q(\\hat{\\theta}) \\approx 0$。展开式简化为：\n$$ q(\\theta) \\approx q(\\hat{\\theta}) - \\frac{1}{2}(\\theta - \\hat{\\theta})^T H (\\theta - \\hat{\\theta}) $$\n其中 $H = -\\nabla^2 q(\\hat{\\theta})$ 是在众数处求值的黑塞矩阵的负数。对于大样本 $n$，$H$ 可以由观测到的费雪信息矩阵 $I(\\hat{\\theta})$ 很好地近似。\n积分变为：\n$$ P(y|\\mathcal{M}) \\approx \\exp(q(\\hat{\\theta})) \\int \\exp\\left(-\\frac{1}{2}(\\theta - \\hat{\\theta})^T H (\\theta - \\hat{\\theta})\\right) d\\theta $$\n该积分是多元高斯分布的归一化常数，即 $(2\\pi)^{k/2} (\\det H)^{-1/2}$。因此：\n$$ P(y|\\mathcal{M}) \\approx P(y|\\hat{\\theta}, \\mathcal{M}) P(\\hat{\\theta}|\\mathcal{M}) (2\\pi)^{k/2} (\\det H)^{-1/2} $$\n取对数：\n$$ \\ln P(y|\\mathcal{M}) \\approx \\ell(\\hat{\\theta}) + \\ln P(\\hat{\\theta}|\\mathcal{M}) + \\frac{k}{2} \\ln(2\\pi) - \\frac{1}{2} \\ln(\\det H) $$\n对于大样本 $n$，费雪信息矩阵 $I(\\hat{\\theta})$ 的元素是 $O(n)$ 阶的，所以其行列式 $\\det H \\approx \\det I(\\hat{\\theta})$ 是 $O(n^k)$ 阶的。因此，$\\ln(\\det H) \\approx k \\ln(n) + O(1)$。先验项 $\\ln P(\\hat{\\theta}|\\mathcal{M})$ 和 $\\ln(2\\pi)$ 项是 $O(1)$ 阶的。舍去所有不随 $n$ 增长（或增长慢于 $\\ln(n)$）的项，我们得到近似式：\n$$ \\ln P(y|\\mathcal{M}) \\approx \\ell(\\hat{\\theta}) - \\frac{k}{2}\\ln(n) $$\nBIC 的定义是将其乘以 $-2$：\n$$ \\mathrm{BIC} = -2\\ell(\\hat{\\theta}) + k\\ln(n) $$\n同样，对于 Cox 模型，$\\ell(\\hat{\\theta})$ 被 $\\ell_p$ 所取代。\n\n**模型 $\\mathcal{M}_1$ 和 $\\mathcal{M}_2$ 的计算**\n\n给定 $n=600$, $k_1=8$, $\\ell_{p,1}=-420.5$, $k_2=12$ 和 $\\ell_{p,2}=-418.0$。\n首先，我们计算 $\\ln(n) = \\ln(600) \\approx 6.3969$。\n\n对于模型 $\\mathcal{M}_1$：\n$$ \\mathrm{AIC}_1 = -2\\ell_{p,1} + 2k_1 = -2(-420.5) + 2(8) = 841.0 + 16 = 857.0 $$\n$$ \\mathrm{BIC}_1 = -2\\ell_{p,1} + k_1\\ln(n) = -2(-420.5) + 8\\ln(600) \\approx 841.0 + 8(6.3969) \\approx 841.0 + 51.1752 = 892.1752 $$\n\n对于模型 $\\mathcal{M}_2$：\n$$ \\mathrm{AIC}_2 = -2\\ell_{p,2} + 2k_2 = -2(-418.0) + 2(12) = 836.0 + 24 = 860.0 $$\n$$ \\mathrm{BIC}_2 = -2\\ell_{p,2} + k_2\\ln(n) = -2(-418.0) + 12\\ln(600) \\approx 836.0 + 12(6.3969) \\approx 836.0 + 76.7628 = 912.7628 $$\n\n将结果四舍五入到 $4$ 位有效数字，我们有：\n$\\mathrm{AIC}_1 = 857.0$\n$\\mathrm{AIC}_2 = 860.0$\n$\\mathrm{BIC}_1 = 892.2$\n$\\mathrm{BIC}_2 = 912.8$\n\n**模型偏好与解释**\n\n对于 AIC 和 BIC，值越小表示模型越优。\n- **AIC 偏好**：由于 $\\mathrm{AIC}_1=857.0  \\mathrm{AIC}_2=860.0$，AIC 准则偏好更简单的模型 $\\mathcal{M}_1$。\n- **BIC 偏好**：由于 $\\mathrm{BIC}_1=892.2  \\mathrm{BIC}_2=912.8$，BIC 准则也偏好更简单的模型 $\\mathcal{M}_1$。\n\n在这种情况下，两种准则达成一致。然而，问题要求解释如何解读它们可能不一致的情况。不一致通常发生在 AIC 偏好更复杂的模型，而 BIC 偏好更简单的模型时。这是因为对于任何样本量 $n > e^2 \\approx 7.39$，BIC 的惩罚项 $k\\ln(n)$ 都大于 AIC 的惩罚项 $2k$。在本问题中，$\\ln(600) \\approx 6.4$，所以 BIC 对复杂度的惩罚比 AIC 严苛三倍以上。\n\n- **AIC 目标的解释（预测）**：AIC 旨在选择一个在未来数据上具有最佳预测准确性的模型。它是渐近有效的，这意味着如果真实的底层现实是无限维的（即，没有简单的有限参数模型是完全“真实”的），AIC 倾向于选择提供最佳有限维近似的模型。即使某个参数不属于假设的“真实”生成模型的一部分，如果它能为预测能力带来微小但真实的改进，AIC 也可能在模型中保留该参数。\n\n- **BIC 目标的解释（识别）**：BIC 旨在从候选集合中识别出“真实”模型。它是一致的，这意味着随着样本量 $n \\to \\infty$，BIC 选择真实模型（如果它在候选集中）的概率趋近于 $1$。其更强的惩罚反映了更高的举证责任：数据中必须有充分的证据（似然的大幅增加）才能证明增加更多参数是合理的，并得出更复杂的模型是真实模型的结论。\n\n- **解读不一致**：如果 AIC 选择了 $\\mathcal{M}_2$ 而 BIC 选择了 $\\mathcal{M}_1$，这将意味着 $\\mathcal{M}_2$ 中增加的 4 个协变量足以改善对数似然，从而被认为对预测有用（根据 AIC），但不足以提供强有力的证据表明 $\\mathcal{M}_2$ 是对真实底层数据生成过程更好的表征（根据 BIC）。它们之间的选择将取决于研究目标：如果目标是构建最佳的预测风险评分，可能会选择 AIC 偏好的模型。如果目标是得到一个更简约、更具解释性的模型，仅识别那些得到最有力支持的风险因素，那么 BIC 偏好的模型将是首选。", "answer": "$$ \\boxed{ \\begin{pmatrix} 857.0  860.0  892.2  912.8 \\end{pmatrix} } $$", "id": "4815010"}]}