{"hands_on_practices": [{"introduction": "要真正掌握多元回归，最有效的方法之一就是从其基本原理出发进行推导。本练习将指导你通过最小化残差平方和这一核心思想，亲手计算出普通最小二乘法（OLS）的系数估计值。通过这个过程，你将不仅得到一个数值答案，更会深刻理解这些估计值是如何从数据中产生的，并验证作为其基础的正交性条件[@problem_id:4915381]。", "problem": "一位生物统计学家在一个包含四名成年参与者的小型预试验数据集中，研究一个经过对数转换的炎症标志物与两个标准化协变量之间的关联。多元线性回归模型设定为 $y_{i} = \\beta_{0} + \\beta_{1} x_{1i} + \\beta_{2} x_{2i} + \\varepsilon_{i}$，其中 $y_{i}$ 是对数标志物，$x_{1i}$ 是一个中心化的体重指数对比，$x_{2i}$ 是一个中心化的体力活动对比，$\\varepsilon_{i}$ 是误差项。普通最小二乘法 (OLS) 估计量是通过在设计矩阵为满列秩的条件下，最小化残差平方和 $S(\\boldsymbol{\\beta}) = \\sum_{i=1}^{n} \\left(y_{i} - \\beta_{0} - \\beta_{1} x_{1i} - \\beta_{2} x_{2i}\\right)^{2}$ 来定义的。观测到的设计矩阵 $X$ 和结果向量 $\\boldsymbol{y}$ 如下：\n$$\nX \\;=\\; \\begin{pmatrix}\n1  -1  -1 \\\\\n1  -1  1 \\\\\n1  1  -1 \\\\\n1  1  1\n\\end{pmatrix}, \n\\qquad\n\\boldsymbol{y} \\;=\\; \\begin{pmatrix}\n1 \\\\ 3 \\\\ 5 \\\\ 7\n\\end{pmatrix}.\n$$\n仅使用 OLS 作为 $S(\\boldsymbol{\\beta})$ 最小化者的基本定义，从第一性原理推导估计量 $\\hat{\\boldsymbol{\\beta}}$ 并计算其精确数值。然后，通过明确计算 $X^{\\top} \\hat{\\boldsymbol{\\varepsilon}}$（其中 $\\hat{\\boldsymbol{\\varepsilon}} = \\boldsymbol{y} - X \\hat{\\boldsymbol{\\beta}}$）来验证残差正交条件，并检查其每个分量是否为 $0$。以精确值（不进行四舍五入）表示最终的系数估计值，并将其报告为单个行向量。最终报告的值不需要单位。", "solution": "该问题要求推导和计算一个多元线性回归模型的普通最小二乘法 (OLS) 估计量，然后验证残差正交条件。推导必须从 OLS 的基本定义开始，即最小化残差平方和 $S(\\boldsymbol{\\beta})$。\n\n模型由 $y_{i} = \\beta_{0} + \\beta_{1} x_{1i} + \\beta_{2} x_{2i} + \\varepsilon_{i}$ 给出。其矩阵形式为 $\\boldsymbol{y} = X\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}$，其中 $\\boldsymbol{y}$ 是 $n \\times 1$ 的结果向量，$X$ 是 $n \\times (p+1)$ 的设计矩阵，$\\boldsymbol{\\beta}$ 是 $(p+1) \\times 1$ 的系数向量，$\\boldsymbol{\\varepsilon}$ 是 $n \\times 1$ 的误差向量。此处，$n=4$ 且 $p=2$。\n\n设计矩阵 $X$ 和结果向量 $\\boldsymbol{y}$ 如下：\n$$\nX = \\begin{pmatrix}\n1  -1  -1 \\\\\n1  -1  1 \\\\\n1  1  -1 \\\\\n1  1  1\n\\end{pmatrix},\n\\qquad\n\\boldsymbol{y} = \\begin{pmatrix}\n1 \\\\ 3 \\\\ 5 \\\\ 7\n\\end{pmatrix}\n$$\n系数向量为 $\\boldsymbol{\\beta} = (\\beta_0, \\beta_1, \\beta_2)^{\\top}$。\n\n残差平方和 $S(\\boldsymbol{\\beta})$ 定义为：\n$$\nS(\\boldsymbol{\\beta}) = \\sum_{i=1}^{n} (y_i - (\\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i}))^2\n$$\n用矩阵表示法，这等价于残差向量 $\\boldsymbol{\\varepsilon} = \\boldsymbol{y} - X\\boldsymbol{\\beta}$ 的欧几里得范数的平方：\n$$\nS(\\boldsymbol{\\beta}) = (\\boldsymbol{y} - X\\boldsymbol{\\beta})^{\\top} (\\boldsymbol{y} - X\\boldsymbol{\\beta})\n$$\n展开此表达式得到：\n$$\nS(\\boldsymbol{\\beta}) = (\\boldsymbol{y}^{\\top} - \\boldsymbol{\\beta}^{\\top}X^{\\top}) (\\boldsymbol{y} - X\\boldsymbol{\\beta}) = \\boldsymbol{y}^{\\top}\\boldsymbol{y} - \\boldsymbol{y}^{\\top}X\\boldsymbol{\\beta} - \\boldsymbol{\\beta}^{\\top}X^{\\top}\\boldsymbol{y} + \\boldsymbol{\\beta}^{\\top}X^{\\top}X\\boldsymbol{\\beta}\n$$\n由于项 $\\boldsymbol{\\beta}^{\\top}X^{\\top}\\boldsymbol{y}$ 是一个标量，它等于其转置，即 $(\\boldsymbol{\\beta}^{\\top}X^{\\top}\\boldsymbol{y})^{\\top} = \\boldsymbol{y}^{\\top}X\\boldsymbol{\\beta}$。因此，我们可以合并中间两项：\n$$\nS(\\boldsymbol{\\beta}) = \\boldsymbol{y}^{\\top}\\boldsymbol{y} - 2\\boldsymbol{\\beta}^{\\top}X^{\\top}\\boldsymbol{y} + \\boldsymbol{\\beta}^{\\top}X^{\\top}X\\boldsymbol{\\beta}\n$$\n为了找到最小化 $S(\\boldsymbol{\\beta})$ 的系数向量 $\\hat{\\boldsymbol{\\beta}}$，我们求 $S(\\boldsymbol{\\beta})$ 对 $\\boldsymbol{\\beta}$ 的梯度，并将其设为零向量。根据标准矩阵微积分的求导法则，我们有：\n$$\n\\frac{\\partial S(\\boldsymbol{\\beta})}{\\partial \\boldsymbol{\\beta}} = \\frac{\\partial}{\\partial \\boldsymbol{\\beta}} (\\boldsymbol{y}^{\\top}\\boldsymbol{y} - 2\\boldsymbol{\\beta}^{\\top}X^{\\top}\\boldsymbol{y} + \\boldsymbol{\\beta}^{\\top}X^{\\top}X\\boldsymbol{\\beta}) = -2X^{\\top}\\boldsymbol{y} + 2X^{\\top}X\\boldsymbol{\\beta}\n$$\n将梯度设为零以求得 OLS 估计量 $\\hat{\\boldsymbol{\\beta}}$：\n$$\n-2X^{\\top}\\boldsymbol{y} + 2X^{\\top}X\\hat{\\boldsymbol{\\beta}} = \\mathbf{0}\n$$\n$$\nX^{\\top}X\\hat{\\boldsymbol{\\beta}} = X^{\\top}\\boldsymbol{y}\n$$\n这就是被称为正规方程组的线性方程组。由于问题声明设计矩阵具有满列秩，矩阵 $X^{\\top}X$ 是可逆的。因此，我们可以通过左乘 $X^{\\top}X$ 的逆矩阵来求解 $\\hat{\\boldsymbol{\\beta}}$：\n$$\n\\hat{\\boldsymbol{\\beta}} = (X^{\\top}X)^{-1}X^{\\top}\\boldsymbol{y}\n$$\n至此，完成了从第一性原理推导 OLS 估计量的过程。\n\n接下来，我们计算数值。首先，计算 $X^{\\top}X$：\n$$\nX^{\\top}X = \\begin{pmatrix} 1  1  1  1 \\\\ -1  -1  1  1 \\\\ -1  1  -1  1 \\end{pmatrix} \\begin{pmatrix} 1  -1  -1 \\\\ 1  -1  1 \\\\ 1  1  -1 \\\\ 1  1  1 \\end{pmatrix} = \\begin{pmatrix} 4  0  0 \\\\ 0  4  0 \\\\ 0  0  4 \\end{pmatrix} = 4I_{3}\n$$\n计算表明 $X$ 的列是正交的，这使得 $X^{\\top}X$ 简化为一个对角矩阵。其逆矩阵可以很容易地计算出来：\n$$\n(X^{\\top}X)^{-1} = (4I_{3})^{-1} = \\frac{1}{4}I_{3} = \\begin{pmatrix} \\frac{1}{4}  0  0 \\\\ 0  \\frac{1}{4}  0 \\\\ 0  0  \\frac{1}{4} \\end{pmatrix}\n$$\n现在，我们计算 $X^{\\top}\\boldsymbol{y}$：\n$$\nX^{\\top}\\boldsymbol{y} = \\begin{pmatrix} 1  1  1  1 \\\\ -1  -1  1  1 \\\\ -1  1  -1  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 3 \\\\ 5 \\\\ 7 \\end{pmatrix} = \\begin{pmatrix} 1+3+5+7 \\\\ -1-3+5+7 \\\\ -1+3-5+7 \\end{pmatrix} = \\begin{pmatrix} 16 \\\\ 8 \\\\ 4 \\end{pmatrix}\n$$\n最后，我们计算 $\\hat{\\boldsymbol{\\beta}}$：\n$$\n\\hat{\\boldsymbol{\\beta}} = (X^{\\top}X)^{-1}X^{\\top}\\boldsymbol{y} = \\begin{pmatrix} \\frac{1}{4}  0  0 \\\\ 0  \\frac{1}{4}  0 \\\\ 0  0  \\frac{1}{4} \\end{pmatrix} \\begin{pmatrix} 16 \\\\ 8 \\\\ 4 \\end{pmatrix} = \\begin{pmatrix} \\frac{16}{4} \\\\ \\frac{8}{4} \\\\ \\frac{4}{4} \\end{pmatrix} = \\begin{pmatrix} 4 \\\\ 2 \\\\ 1 \\end{pmatrix}\n$$\n因此，估计的系数为 $\\hat{\\beta}_0 = 4$，$\\hat{\\beta}_1 = 2$ 和 $\\hat{\\beta}_2 = 1$。\n\n最后一项任务是验证残差正交条件 $X^{\\top}\\hat{\\boldsymbol{\\varepsilon}} = \\mathbf{0}$，其中 $\\hat{\\boldsymbol{\\varepsilon}} = \\boldsymbol{y} - X\\hat{\\boldsymbol{\\beta}}$。首先，我们计算预测值向量 $\\hat{\\boldsymbol{y}} = X\\hat{\\boldsymbol{\\beta}}$：\n$$\n\\hat{\\boldsymbol{y}} = X\\hat{\\boldsymbol{\\beta}} = \\begin{pmatrix} 1  -1  -1 \\\\ 1  -1  1 \\\\ 1  1  -1 \\\\ 1  1  1 \\end{pmatrix} \\begin{pmatrix} 4 \\\\ 2 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1(4) - 1(2) - 1(1) \\\\ 1(4) - 1(2) + 1(1) \\\\ 1(4) + 1(2) - 1(1) \\\\ 1(4) + 1(2) + 1(1) \\end{pmatrix} = \\begin{pmatrix} 4-2-1 \\\\ 4-2+1 \\\\ 4+2-1 \\\\ 4+2+1 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 3 \\\\ 5 \\\\ 7 \\end{pmatrix}\n$$\n接下来，我们计算残差向量 $\\hat{\\boldsymbol{\\varepsilon}}$：\n$$\n\\hat{\\boldsymbol{\\varepsilon}} = \\boldsymbol{y} - \\hat{\\boldsymbol{y}} = \\begin{pmatrix} 1 \\\\ 3 \\\\ 5 \\\\ 7 \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ 3 \\\\ 5 \\\\ 7 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\mathbf{0}_{4 \\times 1}\n$$\n残差向量是零向量，这表明模型对数据实现了完全拟合。这是由问题中提供的特定数值所导致的一种特殊情况。\n\n现在我们验证正交条件：\n$$\nX^{\\top}\\hat{\\boldsymbol{\\varepsilon}} = \\begin{pmatrix} 1  1  1  1 \\\\ -1  -1  1  1 \\\\ -1  1  -1  1 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1(0) + 1(0) + 1(0) + 1(0) \\\\ -1(0) - 1(0) + 1(0) + 1(0) \\\\ -1(0) + 1(0) - 1(0) + 1(0) \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\n所得向量 $X^{\\top}\\hat{\\boldsymbol{\\varepsilon}}$ 的每个分量都为 $0$。这明确地验证了残差正交条件，该条件是由推导出 $\\hat{\\boldsymbol{\\beta}}$ 的正规方程组直接得出的推论。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n4  2  1\n\\end{pmatrix}\n}\n$$", "id": "4915381"}, {"introduction": "在建立了回归模型之后，下一个关键步骤是正确地解读其系数。当模型包含交互项时，对系数的解读变得尤为精妙，单个系数不再代表一个变量的“独立”效应。本练习将引导你推导出在一个包含交互项的模型中，一个预测变量的条件效应，从而揭示其真实影响是如何依赖于另一个变量的水平的[@problem_id:4915325]。", "problem": "一个生物统计学团队正在对循环细胞因子的期望对数浓度（记为 $y$）进行建模，该浓度是每个参与者测量的两个连续暴露变量 $x_{j}$（例如，标准化剂量）和 $x_{k}$（例如，标准化体力活动）的函数，且两者之间存在交互作用。他们拟合了一个包含交互项的多元线性回归模型，该模型可能还包括其他不涉及 $x_{j}$ 或 $x_{k}$ 的协变量。对于一个普通参与者，其模型为\n$$\ny \\;=\\; \\beta_{0} \\;+\\; \\beta_{j}\\,x_{j} \\;+\\; \\beta_{k}\\,x_{k} \\;+\\; \\beta_{jk}\\,x_{j}\\,x_{k} \\;+\\; \\sum_{\\ell \\in \\mathcal{S}} \\beta_{\\ell}\\,x_{\\ell} \\;+\\; \\varepsilon,\n$$\n其中 $\\varepsilon$ 是一个均值为零且独立于预测变量的误差项，$\\mathcal{S}$ 是不同于 $j$ 和 $k$ 的附加协变量的索引。在一般线性模型的假设下，给定预测变量时 $y$ 的条件期望是通过移除 $\\varepsilon$ 得到的回归函数。\n\n仅使用 (i) 线性模型下条件期望的定义和 (ii) 在保持其他参数固定的情况下的偏导数定义，推导在固定 $x_{k}$ 时 $x_{j}$ 对期望结果的条件效应，即计算\n$$\n\\frac{\\partial\\, E\\!\\left[y \\,\\middle|\\, x_{j}, x_{k}, \\{x_{\\ell}\\}_{\\ell \\in \\mathcal{S}} \\right]}{\\partial x_{j}}\n$$\n并将其表示为关于 $\\beta_{j}$、$\\beta_{k}$、$\\beta_{jk}$、$x_{j}$ 和 $x_{k}$ 的封闭形式代数表达式。\n\n您的最终答案必须是单个符号表达式。不应包含单位。不应提供不等式或方程式。不要进行四舍五入。", "solution": "在尝试解答之前，对问题陈述进行验证。\n\n### 第1步：提取已知条件\n- 对于一个普通参与者，结果 $y$ 的模型为：\n$y \\;=\\; \\beta_{0} \\;+\\; \\beta_{j}\\,x_{j} \\;+\\; \\beta_{k}\\,x_{k} \\;+\\; \\beta_{jk}\\,x_{j}\\,x_{k} \\;+\\; \\sum_{\\ell \\in \\mathcal{S}} \\beta_{\\ell}\\,x_{\\ell} \\;+\\; \\varepsilon$\n- $y$ 是循环细胞因子的对数浓度。\n- $x_j$ 和 $x_k$ 是两个连续暴露变量。\n- $\\{x_{\\ell}\\}_{\\ell \\in \\mathcal{S}}$ 是其他协变量，其中索引集 $\\mathcal{S}$ 不同于 $\\{j, k\\}$。\n- $\\beta_{0}, \\beta_{j}, \\beta_{k}, \\beta_{jk}, \\beta_{\\ell}$ 是回归系数。\n- $\\varepsilon$ 是一个误差项，满足 $E[\\varepsilon] = 0$。\n- $\\varepsilon$ 独立于所有预测变量 $\\{x_j, x_k, \\{x_{\\ell}\\}_{\\ell \\in \\mathcal{S}}\\}$。\n- 一般线性模型的假设成立。\n- 条件期望 $E\\!\\left[y \\,\\middle|\\, \\text{预测变量} \\right]$ 是回归函数（即不含 $\\varepsilon$ 的模型）。\n- 任务是计算 $\\frac{\\partial\\, E\\!\\left[y \\,\\middle|\\, x_{j}, x_{k}, \\{x_{\\ell}\\}_{\\ell \\in \\mathcal{S}} \\right]}{\\partial x_{j}}$。\n- 推导过程必须仅使用 (i) 线性模型下条件期望的定义和 (ii) 偏导数的定义。\n- 最终答案必须是一个用 $\\beta_{j}$、$\\beta_{k}$、$\\beta_{jk}$、$x_{j}$ 和 $x_{k}$ 表示的封闭形式代数表达式。\n\n### 第2步：使用提取的已知条件进行验证\n对问题的有效性进行评估。\n- **科学依据**：该问题使用了一个带有交互项的标准多元线性回归模型，这是生物统计学和许多其他科学领域的基本工具。该设置在科学上是合理的，并基于已建立的统计理论。\n- **适定性**：问题陈述清晰。它提供了一个具体的模型，并要求基于该模型推导一个特定的量（偏导数）。所有必要的组成部分和假设（例如，均值为零的误差、独立性）都已提供，以得出一个唯一的数学解。\n- **客观性**：问题以精确、客观的数学和统计语言陈述。它没有歧义、主观性或观点。\n\n该问题没有表现出说明中列出的任何缺陷（例如，事实不成立、不完整、有歧义）。这是一个标准的、适定的练习，用于解释存在交互作用时回归系数的含义。\n\n### 第3步：结论与行动\n问题被判定为**有效**。将按要求推导解答。\n\n### 推导过程\n目标是计算 $y$ 的条件期望关于预测变量 $x_{j}$ 的偏导数。推导过程按问题陈述的要求分两步进行。\n\n首先，我们确定给定全套预测变量时 $y$ 的条件期望。给定的模型是：\n$$\ny \\;=\\; \\beta_{0} \\;+\\; \\beta_{j}\\,x_{j} \\;+\\; \\beta_{k}\\,x_{k} \\;+\\; \\beta_{jk}\\,x_{j}\\,x_{k} \\;+\\; \\sum_{\\ell \\in \\mathcal{S}} \\beta_{\\ell}\\,x_{\\ell} \\;+\\; \\varepsilon\n$$\n给定所有预测变量集合（我们记为 $\\mathbf{X} = \\{x_{j}, x_{k}, \\{x_{\\ell}\\}_{\\ell \\in \\mathcal{S}}\\}$）时 $y$ 的条件期望是：\n$$\nE\\!\\left[y \\,\\middle|\\, \\mathbf{X} \\right] \\;=\\; E\\!\\left[ \\beta_{0} \\;+\\; \\beta_{j}\\,x_{j} \\;+\\; \\beta_{k}\\,x_{k} \\;+\\; \\beta_{jk}\\,x_{j}\\,x_{k} \\;+\\; \\sum_{\\ell \\in \\mathcal{S}} \\beta_{\\ell}\\,x_{\\ell} \\;+\\; \\varepsilon \\,\\middle|\\, \\mathbf{X} \\right]\n$$\n根据期望算子的线性性质，我们可以写出：\n$$\nE\\!\\left[y \\,\\middle|\\, \\mathbf{X} \\right] \\;=\\; E\\!\\left[ \\beta_{0} \\;+\\; \\beta_{j}\\,x_{j} \\;+\\; \\beta_{k}\\,x_{k} \\;+\\; \\beta_{jk}\\,x_{j}\\,x_{k} \\;+\\; \\sum_{\\ell \\in \\mathcal{S}} \\beta_{\\ell}\\,x_{\\ell} \\,\\middle|\\, \\mathbf{X} \\right] \\;+\\; E\\!\\left[ \\varepsilon \\,\\middle|\\, \\mathbf{X} \\right]\n$$\n整个回归函数由常数（$\\beta$ 系数）和给定的预测变量值组成，因此相对于期望而言，它被视为一个常数。也就是说，对于函数 $g(\\mathbf{X})$，$E[g(\\mathbf{X})|\\mathbf{X}] = g(\\mathbf{X})$。因此：\n$$\nE\\!\\left[ \\beta_{0} \\;+\\; \\beta_{j}\\,x_{j} \\;+\\; \\beta_{k}\\,x_{k} \\;+\\; \\beta_{jk}\\,x_{j}\\,x_{k} \\;+\\; \\sum_{\\ell \\in \\mathcal{S}} \\beta_{\\ell}\\,x_{\\ell} \\,\\middle|\\, \\mathbf{X} \\right] \\;=\\; \\beta_{0} \\;+\\; \\beta_{j}\\,x_{j} \\;+\\; \\beta_{k}\\,x_{k} \\;+\\; \\beta_{jk}\\,x_{j}\\,x_{k} \\;+\\; \\sum_{\\ell \\in \\mathcal{S}} \\beta_{\\ell}\\,x_{\\ell}\n$$\n此外，问题陈述指出误差项 $\\varepsilon$ 独立于预测变量且均值为零。$\\varepsilon$ 与 $\\mathbf{X}$ 的独立性意味着 $E[\\varepsilon | \\mathbf{X}] = E[\\varepsilon]$。由于 $E[\\varepsilon] = 0$，因此可推断出 $E[\\varepsilon | \\mathbf{X}] = 0$。\n\n将这些结果代回，我们得到 $y$ 的条件期望表达式：\n$$\nE\\!\\left[y \\,\\middle|\\, x_{j}, x_{k}, \\{x_{\\ell}\\}_{\\ell \\in \\mathcal{S}} \\right] \\;=\\; \\beta_{0} \\;+\\; \\beta_{j}\\,x_{j} \\;+\\; \\beta_{k}\\,x_{k} \\;+\\; \\beta_{jk}\\,x_{j}\\,x_{k} \\;+\\; \\sum_{\\ell \\in \\mathcal{S}} \\beta_{\\ell}\\,x_{\\ell}\n$$\n这就完成了所要求推导的第一部分。\n\n其次，我们计算该条件期望关于 $x_j$ 的偏导数，同时保持所有其他预测变量（$x_k$ 和 $\\{x_{\\ell}\\}_{\\ell \\in \\mathcal{S}}$）固定。\n$$\n\\frac{\\partial}{\\partial x_{j}} E\\!\\left[y \\,\\middle|\\, x_{j}, x_{k}, \\{x_{\\ell}\\}_{\\ell \\in \\mathcal{S}} \\right] \\;=\\; \\frac{\\partial}{\\partial x_{j}} \\left( \\beta_{0} \\;+\\; \\beta_{j}\\,x_{j} \\;+\\; \\beta_{k}\\,x_{k} \\;+\\; \\beta_{jk}\\,x_{j}\\,x_{k} \\;+\\; \\sum_{\\ell \\in \\mathcal{S}} \\beta_{\\ell}\\,x_{\\ell} \\right)\n$$\n我们应用求导的加法法则，对表达式逐项关于 $x_j$ 求导：\n$$\n\\frac{\\partial}{\\partial x_{j}} (\\beta_{0}) \\;+\\; \\frac{\\partial}{\\partial x_{j}} (\\beta_{j}\\,x_{j}) \\;+\\; \\frac{\\partial}{\\partial x_{j}} (\\beta_{k}\\,x_{k}) \\;+\\; \\frac{\\partial}{\\partial x_{j}} (\\beta_{jk}\\,x_{j}\\,x_{k}) \\;+\\; \\frac{\\partial}{\\partial x_{j}} \\left(\\sum_{\\ell \\in \\mathcal{S}} \\beta_{\\ell}\\,x_{\\ell}\\right)\n$$\n我们计算每一项的导数：\n- 系数 $\\beta_0$ 是一个常数，所以其导数为零：$\\frac{\\partial}{\\partial x_{j}} (\\beta_{0}) = 0$。\n- 对于项 $\\beta_{j}\\,x_{j}$，其关于 $x_j$ 的导数是常数系数 $\\beta_j$：$\\frac{\\partial}{\\partial x_{j}} (\\beta_{j}\\,x_{j}) = \\beta_j$。\n- 对于项 $\\beta_{k}\\,x_{k}$，在对 $x_j$ 求导时，$\\beta_k$ 和 $x_k$ 都被视为常数，所以该项的导数为零：$\\frac{\\partial}{\\partial x_{j}} (\\beta_{k}\\,x_{k}) = 0$。\n- 对于交互项 $\\beta_{jk}\\,x_{j}\\,x_{k}$，系数 $\\beta_{jk}$ 和变量 $x_k$ 被视为常数。因此其导数为 $\\frac{\\partial}{\\partial x_{j}} ((\\beta_{jk}\\,x_{k}) x_{j}) = \\beta_{jk}\\,x_{k}$。\n- 对于求和项 $\\sum_{\\ell \\in \\mathcal{S}} \\beta_{\\ell}\\,x_{\\ell}$，索引集 $\\mathcal{S}$ 不同于 $\\{j, k\\}$。因此，对于每个 $\\ell \\in \\mathcal{S}$，在对 $x_j$ 求偏导数时，$x_\\ell$ 保持不变。整个和的导数为零：$\\frac{\\partial}{\\partial x_{j}} \\left(\\sum_{\\ell \\in \\mathcal{S}} \\beta_{\\ell}\\,x_{\\ell}\\right) = \\sum_{\\ell \\in \\mathcal{S}} \\frac{\\partial}{\\partial x_{j}} (\\beta_{\\ell}\\,x_{\\ell}) = \\sum_{\\ell \\in \\mathcal{S}} 0 = 0$。\n\n将这些结果相加，得到 $x_{j}$ 的条件效应的最终表达式：\n$$\n\\frac{\\partial E[y | \\mathbf{X}]}{\\partial x_{j}} = 0 + \\beta_{j} + 0 + \\beta_{jk}\\,x_{k} + 0 = \\beta_{j} + \\beta_{jk}\\,x_{k}\n$$\n该表达式表示，在 $x_k$ 和所有其他协变量取特定值的条件下，$x_j$ 每增加一个单位，$y$ 的期望值发生的变化。这表明，在存在交互项的情况下，一个预测变量的效应不是恒定的，而是线性地依赖于另一个预测变量的水平。", "answer": "$$\\boxed{\\beta_{j} + \\beta_{jk}x_{k}}$$", "id": "4915325"}, {"introduction": "任何统计模型的结论都依赖于其底层假设的有效性。在多元回归中，一个关键的假设是同方差性，即误差项的方差是恒定的。本练习将带你应用 Breusch-Pagan 检验，这是一种诊断异方差性的标准方法，你将学习如何通过辅助回归来评估模型是否满足这一重要假设[@problem_id:4915358]。", "problem": "一项临床研究旨在调查 $n=50$ 名成年人的血清甘油三酯水平（记为 $Y$）是否可以用年龄和身体质量指数的线性函数来建模。拟合的主要普通最小二乘（OLS）模型为\n$$\nY_i=\\beta_0+\\beta_1 \\,\\text{Age}_i+\\beta_2 \\,\\text{BMI}_i+\\varepsilon_i,\\quad i=1,\\dots,50,\n$$\n其中，在原假设下，经典线性模型假设成立，即 $E(\\varepsilon_i\\mid \\text{Age}_i,\\text{BMI}_i)=0$ 和 $\\operatorname{Var}(\\varepsilon_i\\mid \\text{Age}_i,\\text{BMI}_i)=\\sigma^2$（对于某个常数 $\\sigma^2$），并且 $\\varepsilon_i$ 独立同分布于正态分布。\n\n为了评估误差方差恒定的假设，要求你应用 Breusch–Pagan 检验，方法是将主模型的 OLS 残差平方对原始预测变量进行回归。具体来说，拟合了一个形式为\n$$\ne_i^2=\\gamma_0+\\gamma_1 \\,\\text{Age}_i+\\gamma_2 \\,\\text{BMI}_i+\\eta_i\n$$\n的辅助回归，其中 $e_i$ 是主 OLS 拟合的残差。从这个辅助回归中，报告的回归平方和（可解释平方和）为 $\\text{SSR}=30.0$，关于 $e_i^2$ 均值的总平方和为 $\\text{SST}=250.0$。辅助模型包含一个截距项和两个预测变量 Age 和 BMI。\n\n仅使用给定的信息和适用于同方差性原假设下检验的适当大样本分布理论，计算 Breusch–Pagan 检验统计量及其对应的 p 值。将 p 值作为你的最终答案报告。将答案四舍五入到四位有效数字。将 p 值表示为纯小数（不要使用百分号）。", "solution": "用户提供了一个问题，要求计算 Breusch–Pagan 检验统计量及其对应的 p 值，以评估多元线性回归模型中的同方差性假设。\n\n首先验证问题的正确性和完整性。\n\n**步骤 1：提取给定信息**\n- 样本量: $n=50$。\n- 主模型: $Y_i=\\beta_0+\\beta_1 \\,\\text{Age}_i+\\beta_2 \\,\\text{BMI}_i+\\varepsilon_i$。\n- 原假设 ($H_0$) 下的假设：经典线性模型假设成立，具体而言，误差 $\\varepsilon_i$ 独立同分布于 $N(0, \\sigma^2)$，这意味着同方差性，即 $\\operatorname{Var}(\\varepsilon_i \\mid \\text{Age}_i, \\text{BMI}_i) = \\sigma^2$。\n- 用于 Breusch–Pagan 检验的辅助回归模型：$e_i^2=\\gamma_0+\\gamma_1 \\,\\text{Age}_i+\\gamma_2 \\,\\text{BMI}_i+\\eta_i$，其中 $e_i$ 是主模型的普通最小二乘（OLS）残差。\n- 辅助回归结果：\n  - 回归平方和：$\\text{SSR}=30.0$。\n  - 总平方和：$\\text{SST}=250.0$。\n- 辅助模型有 $p=2$ 个预测变量（Age 和 BMI），不包括截距项。\n- 问题要求使用大样本分布理论。\n\n**步骤 2：使用提取的信息进行验证**\n这个问题具有科学依据，因为 Breusch–Pagan 检验是计量经济学和生物统计学中用于检测异方差性的标准程序。这个问题提法得当，提供了计算检验统计量及其 p 值所需的所有必要信息（$\\text{SSR}$、$\\text{SST}$、$n$、$p$）。提供的数据是一致的（$\\text{SSR} \\le \\text{SST}$）。术语精确且客观。该问题被认为是有效的。\n\n**步骤 3：求解**\n\nBreusch–Pagan 检验用于检验线性回归模型中的同方差性。原假设 $H_0$ 是误差方差是恒定的（同方差）。备择假设 $H_A$ 是误差方差是模型中一个或多个预测变量的函数。在所提供的辅助回归的背景下，假设为：\n$H_0: \\gamma_1 = \\gamma_2 = 0$（误差方差不依赖于 Age 和 BMI）。\n$H_A: \\gamma_1, \\gamma_2 \\text{ 中至少有一个不为零}$（误差方差依赖于 Age 和/或 BMI）。\n\n问题指定使用大样本分布理论。这指向了 Breusch–Pagan 检验统计量的拉格朗日乘子（LM）形式。LM 统计量计算如下：\n$$\nLM = n R^2\n$$\n其中 $n$ 是样本量，$R^2$ 是 OLS 残差平方对原始预测变量进行辅助回归得到的决定系数。\n\n决定系数 $R^2$ 是回归平方和（$\\text{SSR}$）与总平方和（$\\text{SST}$）的比值。使用辅助回归中的值：\n$$\nR^2 = \\frac{\\text{SSR}}{\\text{SST}} = \\frac{30.0}{250.0} = 0.12\n$$\n\n给定的样本量为 $n=50$。现在我们可以计算 $LM$ 统计量：\n$$\nLM = n R^2 = 50 \\times 0.12 = 6.0\n$$\n\n在同方差性的原假设下，$LM$ 检验统计量渐近服从卡方（$\\chi^2$）分布。该分布的自由度等于辅助回归中预测变量的数量（不包括截距项）。在本例中，有 $p=2$ 个预测变量（Age 和 BMI）。因此，在 $H_0$ 下，$LM \\sim \\chi^2(2)$。\n\n检验的 p 值是在原假设为真的前提下，观测到等于或比计算出的检验统计量更极端的 $\\chi^2$ 值的概率。这对应于 $\\chi^2(2)$ 分布的上尾概率：\n$$\n\\text{p-value} = P(\\chi^2(2) \\ge 6.0)\n$$\n\n自由度为 2 的卡方分布是一个特例；它等价于率参数 $\\lambda = \\frac{1}{2}$ 的指数分布。其概率密度函数为 $f(x) = \\frac{1}{2}\\exp(-\\frac{x}{2})$（对于 $x \\ge 0$）。其累积分布函数 (CDF) 为 $F(x) = 1 - \\exp(-\\frac{x}{2})$。\n\np 值是生存函数在 $x=6.0$ 处的值：\n$$\n\\text{p-value} = 1 - F(6.0) = 1 - \\left(1 - \\exp\\left(-\\frac{6.0}{2}\\right)\\right) = \\exp(-3.0)\n$$\n\n现在，我们计算 p 值的数值：\n$$\n\\text{p-value} = \\exp(-3.0) \\approx 0.049787068...\n$$\n\n问题要求答案四舍五入到四位有效数字。第一位有效数字是 $4$，其后是 $9$、$7$ 和 $8$。第五位有效数字是 $7$，大于或等于 $5$，所以我们将第四位有效数字向上取整。\n$$\n\\text{p-value} \\approx 0.04979\n$$\n这是最终报告的 p 值。", "answer": "$$\n\\boxed{0.04979}\n$$", "id": "4915358"}]}