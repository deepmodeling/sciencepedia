## 引言
在生物统计学的严谨世界中，任何可靠的结论都建立在一个基本前提之上：正确识别分析的[基本单位](@entry_id:148878)。从临床试验到公共卫生调查，我们总是在不同层级的实体上进行干预、观察和测量。**研究单位（study unit）**与**观测单位（observational unit）**这两个核心概念的区分，正是连接研究设计与有效统计推断的桥梁。然而，在实践中，研究者常常无意中混淆二者，导致分析模型错误，最终得出具有误导性甚至完全错误的结论。

本文旨在系统性地解决这一知识鸿沟。我们将深入探讨研究单位与观测单位的定义、区别及其在统计推断中的根本重要性。通过本文的学习，读者将能够：

- 在“**原理与机制**”一章中，掌握这两个单位的基本定义，理解组内相关性的本质，并认识到[伪重复](@entry_id:176246)和生态学谬误等错误的严重后果。
- 在“**应用与跨学科联系**”一章中，通过来自流行病学、基因组学和生态学等多个领域的真实案例，看到这些原则在复杂研究设计中的具体应用。
- 在“**动手实践**”一章中，通过解决实际问题来巩固所学知识，学会运用正确的统计方法处理分层数据。

让我们首先从最基本的原理出发，深入理解这两个单位的定义以及它们为何如此关键。

## 原理与机制

在生物统计学的研究设计与分析中，最基本也是最关键的一项任务是准确识别分析的基本单元。研究问题的提出、实验处理的分配以及最终测量值的获取，可能发生在不同层级的实体上。未能正确区分这些层级会导致严重的[统计推断](@entry_id:172747)错误。本章将深入探讨两个核心概念：**研究单位（study unit）**和**观测单位（observational unit）**。我们将阐明它们的定义，解释为什么它们之间的区别至关重要，并系统地介绍因混淆二者而产生的常见谬误，最后概述处理此类分层数据的正确分析策略。

### 基本定义：研究单位、观测单位与抽样单位

为了建立一个严谨的分析框架，我们必须首先精确定义研究中的各种“单位”。

#### 研究单位与随机化单位

**研究单位**，又称**实验单位（experimental unit）**，是能够被独立分配到不同处理或干预条件下的最小实体。统计推断的主要假设，尤其是独立性假设，是基于研究单位的。因此，研究的主要科学问题和目标参数通常是针对研究单位构成的群体来定义的。研究单位的数量直接决定了比较处理效应时统计检验的自由度，从而影响研究的统计功效。

例如，在一项评估新疗法的**整群随机试验（cluster-randomized trial）**中，研究人员将 $n=20$ 个诊所（群组）随机分配到干预组或[对照组](@entry_id:188599)，然后在每个诊所内招募患者并测量其健康结局。在这种情况下，尽管最终的测量是在患者身上进行的，但处理分配的独立实体是**诊所**。因此，诊所是这项研究的研究单位 [@problem_id:4955031]。整个研究设计的目的在于比较接受干预的诊所群体与未接受干预的诊所群体的差异。

在因果推断的框架下，研究单位与**随机化单位（randomization unit）**的概念紧密相连。随机化单位是指在实验设计中被概率性地分配处理的实体。为了对研究单位层面的平均[处理效应](@entry_id:636010)（Average Treatment Effect, ATE）进行无偏估计，研究单位的处理分配必须完全由随机化单位的分配决定。换言之，研究单位要么本身就是随机化单位（如在个体随机试验中），要么其接受的处理必须明确且唯一地与其所属的更高层级的随机化单位挂钩。例如，在上述诊所随机试验中，要估计对患者层面的因果效应 $\tau = E[Y_i(1) - Y_i(0)]$，必须满足以下条件：患者 $i$ 的处理状态 $T_i$ 完全由其所在诊所 $c(i)$ 的随机化分配 $Z_{c(i)}$ 决定（即 $T_i = Z_{c(i)}$），并且诊所的分配 $Z_{c(i)}$ 与患者的所有潜在结局 $(Y_i(1), Y_i(0))$ 相互独立 [@problem_id:4955026]。这个由随机化过程保证的独立性是进行因果推断的基石。

#### 观测单位

**观测单位**是指直接获取测量值的实体。在许多研究中，观测单位和研究单位是相同的。例如，在一个个体随机试验中，患者既是接受随机分配的研究单位，也是被测量结局的观测单位。

然而，在许多复杂的设计中，两者并不一致。在上述的诊所随机试验中，结局指标 $Y_{ij}$ 是在诊所 $i$ 内的患者 $j$ 身上测量的。因此，**患者**是观测单位 [@problem_id:4955031]。同样，在一项**纵向队列研究（longitudinal cohort study）**中，研究人员招募 $N$ 名参与者，并在多年内对每人进行多次随访。这项研究的推断目标是关于“人”的，因此**人**是研究单位。但是，每一次的测量（如血压、体重）都发生在特定的“人-次”组合上，因此**人-次（person-visit）**是观测单位 [@problem_id:4955005]。在生存分析中，我们可能将每个参与者的随访时间分割成多个“人-时（person-time）”区间来建模，此时**人**是研究单位，而**人-时区间**是观测单位 [@problem_id:4955009]。

#### 抽样单位

在调查研究中，我们还需区分**抽样单位（sampling units）**。在复杂的多阶段抽样设计中，抽样过程分步进行。例如，一项公共卫生调查可能首先随机抽取若干个诊所（**初级抽样单位，Primary Sampling Units, PSUs**），然后在每个被抽中的诊所内再随机抽取一定数量的患者（**次级抽样单位，Secondary Sampling Units, SSUs**）。在这种**两阶段抽样**设计中，尽管最终的推断目标是关于患者群体（研究单位），但抽样单位是分层级的 [@problem_id:4955062]。在这种情况下，研究单位和观测单位都是患者，但抽样单位包括了诊所和患者两个层级。

### 核心问题：研究单位内部的依赖性

当观测单位嵌套在研究单位内部时（例如，患者嵌套在诊所内，重复测量嵌套在个人内），一个核心的统计问题便出现了：**同一研究单位内的观测单位通常不是相互独立的**。

在诊所随机试验中，来自同一诊所的患者共享相同的医生团队、管理政策和地理环境，这些共同因素会导致他们的结局比来自不同诊所的患者更为相似。在纵向研究中，同一个人在不同时间点的测量值会因为其稳定的生理特征、遗传背景和生活习惯而相互关联。这种由于数据分层结构引起的相关性，称为**组内相关（intracluster correlation）**。

#### 独立性与可交换性

在统计学上，我们通常假设研究单位之间是独立的。例如，在一个设计良好的队列研究中，我们可以合理地假设参与者 $\mathbf{Y}_i$ 的测量向量与参与者 $\mathbf{Y}_j$ 的测量向量是相互独立的（记为 $\mathbf{Y}_i \perp \mathbf{Y}_j$）。然而，我们不能假设同一参与者内部的测量值 $Y_{it}$ 和 $Y_{is}$（当 $t \neq s$时）是独立的。这种区分至关重要。将研究单位层面的独立性（$\mathbf{Y}_i \perp \mathbf{Y}_j$）与观测单位层面的独立性（$Y_{it} \perp Y_{js}$ 对所有 $(i,t) \neq (j,s)$ 成立）相混淆是一个根本性错误 [@problem_id:4955048]。

一个比独立性更弱的条件是**[可交换性](@entry_id:263314)（exchangeability）**。在研究单位层面，[可交换性](@entry_id:263314)意味着研究单位的联合概率分布在其索引的任意排列下保持不变。也就是说，我们无法仅凭标签来区分这些研究单位。[独立同分布](@entry_id:169067)（i.i.d.）的单位必然是可交换的，但反之不成立。重要的是，研究单位之间的可交换性并不意味着其内部观测单位之间是独立的 [@problem_id:4955048]。

#### 组内[相关系数](@entry_id:147037) (ICC)

衡量组内相关程度的关键指标是**组内相关系数（Intraclass Correlation Coefficient, ICC）**，通常用 $\rho$ 表示。在一个随机效应模型中，总方差可以分解为[组间方差](@entry_id:175044)（between-cluster variance） $\sigma_b^2$ 和[组内方差](@entry_id:177112)（within-cluster variance） $\sigma_w^2$。ICC 定义为[组间方差](@entry_id:175044)占总方差的比例：
$$
\rho = \frac{\sigma_b^2}{\sigma_b^2 + \sigma_w^2}
$$
ICC 的取值范围为 $[0, 1]$。$\rho=0$ 表示不存在组内相关性，所有观测值都是独立的。$\rho > 0$ 表示同一组内的观测值存在正相关。$\rho$ 越大，组内相似性越高，观测值的依赖性越强。

### 严重后果：混淆单位的谬误

如果分析师未能认识到研究单位和观测单位的区别，并错误地将所有观测单位视为独立的研究单位，将会导致一系列严重的统计谬误。

#### [伪重复](@entry_id:176246)与[第一类错误](@entry_id:163360)膨胀

这种错误被称为**[伪重复](@entry_id:176246)（pseudo-replication）**。它是指将来自同一研究单位的多个依赖的观测单位当作独立的重复样本进行分析。这样做会人为地夸大样本量和统计检验的自由度。

例如，在一项干[预研究](@entry_id:172791)中，研究人员将 $K=10$ 个养老院随机分组，并在每个养老院内观察 $\bar{m}=20$ 名住户。这项研究的真实独立重复次数是 $10$（研究单位的数量），而不是 $10 \times 20 = 200$。如果分析师将这 $200$ 名住户视为独立样本，就犯了[伪重复](@entry_id:176246)的错误 [@problem_id:4955022]。

[伪重复](@entry_id:176246)的直接后果是严重低估参数[估计量的方差](@entry_id:167223)。这种方差低估的程度可以通过**设计效应（design effect, DEFF）**来量化：
$$
\text{DEFF} = 1 + (\bar{m}-1)\rho
$$
其中 $\bar{m}$ 是平均组内样本量，$\rho$ 是 ICC。在上述养老院的例子中，如果 ICC 经估算为 $\rho \approx 0.20$（即[组间方差](@entry_id:175044) $\hat{\sigma}_b^2 = 22$，[组内方差](@entry_id:177112) $\hat{\sigma}_w^2 = 88$），那么设计效应为 $1 + (20-1) \times 0.20 = 4.8$。这意味着，幼稚的分析会把真实方差低估近 $5$ 倍，从而导致标准误被低估约 $\sqrt{4.8} \approx 2.2$ 倍。这将产生过窄的[置信区间](@entry_id:138194)和极易犯**第一类错误**（即错误地拒绝零假设，得出[假阳性](@entry_id:635878)结论）的 $p$ 值 [@problem_id:4955022]。

#### [方差估计](@entry_id:268607)的偏倚

我们可以通过一个简单的反例来清晰地展示这种偏倚。假设我们想估计某生物标志物在人群中的均值。我们随机抽取了 $G=2$ 位患者（研究单位），并对每位患者进行了 $m=5$ 次重复测量（观测单位）。假设测量非常精确，同位患者的 $5$ 次测量结果完全相同：患者1的所有测量值为 $100$，患者2的所有测量值为 $140$ [@problem_id:4955027]。

- **幼稚的分析**：分析师将这 $n=10$ 个观测值（五个 $100$ 和五个 $140$）视为独立同分布样本。样本均值为 $\bar{y} = 120$。样本方差 $s^2_{\text{naive}} = \frac{1}{9}[5(100-120)^2 + 5(140-120)^2] = \frac{4000}{9}$。因此，均值的[方差估计](@entry_id:268607)为 $\widehat{\mathrm{Var}}_{\text{naive}}(\bar{y}) = \frac{s^2_{\text{naive}}}{n} = \frac{4000/9}{10} = \frac{400}{9}$。[标准误](@entry_id:635378)为 $\widehat{\mathrm{SE}}_{\text{naive}} = \sqrt{400/9} = \frac{20}{3} \approx 6.67$。

- **正确的分析**：我们认识到只有 $G=2$ 个独立的信息来源，即两位患者。我们将数据在研究单位层面进行汇总，得到两位患者的均值：$\bar{y}_1=100$ 和 $\bar{y}_2=140$。基于这两个独立的均值来估计总体均值的方差。这两个值的样本方差为 $s^2_{\text{correct}} = \frac{1}{2-1}[(100-120)^2 + (140-120)^2] = 800$。因此，均值的[方差估计](@entry_id:268607)为 $\widehat{\mathrm{Var}}_{\text{correct}}(\bar{y}) = \frac{s^2_{\text{correct}}}{G} = \frac{800}{2} = 400$。[标准误](@entry_id:635378)为 $\widehat{\mathrm{SE}}_{\text{correct}} = \sqrt{400} = 20$。

比较两种结果，幼稚分析得到的[标准误](@entry_id:635378)（$6.67$）仅为正确标准误（$20$）的三分之一，而方差则被低估了 $9$ 倍。这个极端的例子揭示了，当组内相关性很高时（本例中 $\rho=1$），增加组内观测数量并不能有效增加关于总体均值的信息。

#### 生态学谬误

**生态学谬误（ecological fallacy）**是另一种因混淆分析层级而产生的严重偏误。它指的是在**汇总（或称生态）层面**观察到的关联性与**个体层面**的真实关联性不符，甚至完全相反。

这种偏误的产生，是因为汇总数据掩盖了个体层面的变异，并可能引入了组层面的混杂因素。考虑这样一个例子：研究者想了解个体暴露 $x_{ij}$ 与结局 $y_{ij}$ 之间的关系。真实的个体层面数据生成机制为 $y_{ij} = 100 + \delta_j + 2x_{ij}$，其中 $\delta_j$ 是诊所 $j$ 特有的效应。很明显，在个体层面，$x$ 每增加一个单位，$y$ 增加 $2$ 个单位。然而，假设存在三个诊所，其平均暴露水平 $\bar{x}_j$ 与诊所效应 $\delta_j$ 恰好呈负相关。例如 [@problem_id:4955040]：
- 诊所1: $\bar{x}_1 = 2.5$, $\delta_1 = 20 \implies \bar{y}_1 = 125$
- 诊所2: $\bar{x}_2 = 6.5$, $\delta_2 = 0 \implies \bar{y}_2 = 113$
- 诊所3: $\bar{x}_3 = 10.5$, $\delta_3 = -20 \implies \bar{y}_3 = 101$

如果分析师错误地对这三个诊所的均值数据 $(\bar{x}_j, \bar{y}_j)$ 进行[回归分析](@entry_id:165476)，他会发现，随着平均暴露从 $2.5$ 增加到 $10.5$，平均结局反而从 $125$ 下降到 $101$。计算出的斜率将是 $-3$。这个在汇总层面观察到的负向关联（$-3$）与个体层面的真实正向关联（$+2$）截然相反。这就是生态学谬误。其根源在于，诊所层面的变量 $\delta_j$ 是一个混杂因素，它既与诊所的平均暴露水平相关，也与结局相关，而汇总分析无法对其进行控制。

### 正确的分析策略

既然我们已经了解了问题的严重性，那么应该如何正确地分析这类分层数据呢？主要有两大类策略。

#### 在研究单位层面进行分析

最直接的方法是将数据汇总到研究单位层面，然后对这些汇总后的[独立数](@entry_id:260943)据点进行分析。例如，在前面提到的两患者反例中，我们可以计算每个患者的平均值，然后用这两个平均值进行 $t$ 检验或计算[置信区间](@entry_id:138194) [@problem_id:4955027]。虽然这种方法简单且有效，但当组内观测次数不等或存在随时间变化的协变量时，可能会损失信息或变得复杂。

#### 对依赖结构进行建模

更先进和灵活的方法是使用能够直接处理依赖结构的[统计模型](@entry_id:755400)。

1.  **混合效应模型（Mixed-Effects Models）**：也称为分层模型或[多水平模型](@entry_id:171741)，这类模型通过引入**随机效应（random effects）**来显式地对组间异质性建模。例如，在纵向数据分析中，我们可以为每个人设定一个随机截距 $b_i$，模型形式如 $E[Y_{it} | X_{it}, b_i] = g^{-1}(\alpha + b_i + \beta X_{it})$。这里的 $b_i$ 捕捉了每个人的基线水平差异。在给定 $b_i$ 的条件下，同一人内部的观测被假定为独立的。通过对 $b_i$ 的分布进行建模，模型就能够恰当地解释组内相关性 [@problem_id:4955005]。

2.  **广义估计方程（Generalized Estimating Equations, GEE）**：GEE 是一种处理相关性数据的“半参数”方法。与混合模型不同，它不直接对相关性的来源进行建模，而是关注**边际均值**（即平均而言，结局与协变量的关系）。GEE 需要分析师为组内相关性指定一个“工作[相关矩阵](@entry_id:262631)”，但其出色之处在于，即使这个工作[相关矩阵](@entry_id:262631)指定不正确，只要均值模型设定正确，它所得到的[参数估计](@entry_id:139349) $\hat{\boldsymbol{\beta}}$ 仍然是一致的。更重要的是，GEE 配备了一种**整群稳健“三明治”夹心[方差估计](@entry_id:268607)量（cluster-robust "sandwich" variance estimator）**，该估计量即使在工作相关结构设定错误的情况下，也能提供对 $\hat{\boldsymbol{\beta}}$ 方差的有效估计 [@problem_id:4955005]。

#### 整群稳健“三明治”夹心[方差估计](@entry_id:268607)量

这个方差估计量是现代生物统计学中处理分层数据的基石。对于一个通过求解估计方程 $\sum_{g=1}^{G}\sum_{i=1}^{n_g} \boldsymbol{\psi}_{gi}(\boldsymbol{\beta}) = \mathbf{0}$ 得到的估计量 $\hat{\boldsymbol{\beta}}$，其整群稳健方差估计量的一般形式为：
$$
\widehat{\mathrm{Var}}(\hat{\boldsymbol{\beta}}) = \hat{\mathbf{A}}^{-1} \left( \sum_{g=1}^{G} \hat{\mathbf{U}}_{g}\hat{\mathbf{U}}_{g}^{\top} \right) \hat{\mathbf{A}}^{-1}
$$
其中：
- $\hat{\mathbf{A}}$ 是所谓的“面包”，代表了模型敏感性的经验估计，$\hat{\mathbf{A}} = \sum_{g,i} \frac{\partial \boldsymbol{\psi}_{gi}(\hat{\boldsymbol{\beta}})}{\partial \boldsymbol{\beta}^{\top}}$。
- 中间的 $\left( \sum_{g=1}^{G} \hat{\mathbf{U}}_{g}\hat{\mathbf{U}}_{g}^{\top} \right)$ 是“肉”，是这个估计量的关键所在。
- $\hat{\mathbf{U}}_{g} = \sum_{i=1}^{n_g}\boldsymbol{\psi}_{gi}(\hat{\boldsymbol{\beta}})$ 是第 $g$ 个研究单位（群组）内所有观测单位的得分函数贡献之和。

这个公式的精妙之处在于，它首先将每个独立的研究单位内的信息进行汇总（计算 $\hat{\mathbf{U}}_g$），然后再计算这些汇总量之间的方差。通过对 $\hat{\mathbf{U}}_g$ 求外积并求和，它非参数地捕捉了每个群组内部任意形式的相关和异方差结构，而仅仅依赖于研究单位（群组）之间的独立性假设。因此，它能够在不确切知道组内相关结构的情况下，提供有效的方差估计和可靠的[统计推断](@entry_id:172747) [@problem_id:4955014]。

### 高级考量：分层数据中的缺失机制

研究单位和观测单位的区分对于理解和处理缺失数据也至关重要。在纵向研究中，我们必须区分两种缺失模式 [@problem_id:4955011]：

- **观测单位层面的缺失**：指某个参与者在某个特定访视点的数据缺失，但该参与者可能在后续的访视中继续提供数据。这通常被称为**间断性缺失（intermittent missingness）**。
- **研究单位层面的缺失**：指某个参与者在某个时间点后永久性地退出了研究，不再提供任何后续数据。这被称为**退出（dropout）**或**单调缺失（monotone missingness）**。

对于这两种模式，我们都可以应用标准的三种缺失机制来进行分类：

1.  **[完全随机缺失](@entry_id:170286)（Missing Completely At Random, MCAR）**：缺失的概率与任何（观测到的或未观测到的）数据都无关。例如，样本丢失是因为实验室设备随机故障。
2.  **[随机缺失](@entry_id:168632)（Missing At Random, MAR）**：缺失的概率可以依赖于已观测到的数据，但在给定已观测数据后，与未观测到的数据（即缺失值本身）无关。例如，在 dropout 的情境下，如果一个患者是否退出的决定仅取决于他*已经观测到*的病史，而与他*未来*的健康状况无关，那么这种缺失就是 MAR。
3.  **[非随机缺失](@entry_id:163489)（Missing Not At Random, MNAR）**：缺失的概率依赖于缺失值本身，即使在控制了所有已观测数据之后依然如此。例如，一个患者因为当天感觉血压特别高（一个未被测量到的值）而决定不参加访视，这就是 MNAR。

正确识别缺失发生的层级（观测单位 vs. 研究单位）和其背后的机制（MCAR, MAR, MNAR）是选择恰当的缺失数据处理方法（如[多重插补](@entry_id:177416)、似然基础模型等）并获得有效推断的前提 [@problem_id:4955011]。

总之，准确识别研究单位和观测单位是任何严谨生物统计学分析的起点。它不仅决定了样本量的真实大小和[统计推断](@entry_id:172747)的有效性，还深刻影响着我们如何处理数据中的相关性、偏误和缺失，是连接研究设计与[统计模型](@entry_id:755400)的关键桥梁。