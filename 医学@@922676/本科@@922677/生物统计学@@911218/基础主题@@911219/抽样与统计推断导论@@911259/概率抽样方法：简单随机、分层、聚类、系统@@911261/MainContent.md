## 引言
在生物统计学及众多科学领域，我们常常希望了解一个庞大群体的特征，但对每一个体进行研究既不经济也不可行。因此，从总体中科学地选取一部分代表性个体——即样本——来推断总体特征，便成为不可或缺的研究手段。然而，如何确保样本能够真实地反映总体，避免因选择不当而产生误导性结论？这正是概率抽样所要解决的核心问题。概率抽样提供了一套严谨的、基于随机化原则的框架，它不仅保证了每个个体都有已知的被选中机会，也为量化抽样带来的不确定性（即抽样误差）提供了理论基础。

本文旨在系统性地介绍概率抽样的基本原理、关键方法及其在现实世界中的复杂应用。通过学习，您将能够理解不同[抽样策略](@entry_id:188482)背后的统计学思想，并为具体的研究问题选择和设计最合适的抽样方案。我们将分为三个核心章节展开：

第一章“原理与机制”，将深入剖析简单[随机抽样](@entry_id:175193)、[分层抽样](@entry_id:138654)、整群抽样及系统抽样等核心方法的理论基础、操作流程和统计特性，揭示它们各自的优势与局限。第二章“应用与跨学科联系”，将通过来自流行病学、公共管理、生态学乃至人工智能等领域的丰富案例，展示这些抽样方法如何被灵活运用于解决实际问题，以及如何识别和处理抽样过程中可能出现的偏差。最后，在“动手实践”部分，您将有机会通过具体的计算和编程练习，巩固所学知识，将理论真正转化为解决问题的能力。

## 原理与机制

本章在前一章介绍背景知识的基础上，深入探讨概率抽样的核心原理与关键机制。我们将系统性地剖析各种主要的[抽样方法](@entry_id:141232)，阐明其理论基础、操作流程以及在生物统计学研究中的适用场景、优势与潜在风险。

### 概率抽样的基础

概率抽样的基石在于，目标总体中的每一个单元都有一个已知的、非零的被抽中概率。这一原则保证了样本的代表性，并为基于样本数据对总体参数进行无偏或一致的推断提供了理论依据。

为了实施概率抽样，我们首先需要一个**抽样框 (sampling frame)**，即一个包含了所有目标总体单元的列表或地图。一个理想的抽样框与目标总体之间存在完美的[一一对应](@entry_id:143935)关系：总体中的每个单元在抽样框上不多不少恰好出现一次。在实践中，完美的抽样框极为罕见，抽样框与目标总体之间的不匹配会导致**覆盖误差 (coverage error)**。覆盖误差会直接破坏我们为每个单元设定的“已知”抽样概率（即**包含概率** $\pi_i$）的有效性。

设想一项全国免疫研究，研究人员从一个包含 $N=10,000$ 户家庭的登记册中抽样。要使这个登记册成为一个有效的概率抽样框，必须满足一系列条件，并且要警惕几种具体的覆盖误差 [@problem_id:4942775]。主要的覆盖误差类型包括：

1.  **覆盖不足 (Undercoverage)**：目标总体的某些单元未能出现在抽样框中。例如，新建的合格家庭未被及时纳入登记册。这些被遗漏的单元，其真实的包含概率为 $0$，这违背了概率抽样中 $\pi_i > 0$ 的基本要求。

2.  **过度覆盖 (Overcoverage)**：抽样框中包含了一些不属于目标总体的单元。例如，登记册上依然保留着已被拆除的房屋或不合格的商业地址。抽取这些单元会浪费研究资源，并可能引入偏差。

3.  **重复 (Multiplicity/Duplication)**：目标总体中的同一个单元在抽样框中出现多次。例如，一个多单元住宅的每个单元都被独立登记，导致该住宅作为一个整体有多次被抽中的机会。如果不加以识别和处理，这类单元的真实包含概率将是其在抽样框中各条记录的包含概率之和，从而高于名义上的计算值。

因此，任何一项严谨的抽样调查，其设计的首要步骤都是评估和处理抽样框的覆盖误差，以确保计算出的包含概率尽可能接近真实的包含概率。

### 简单[随机抽样](@entry_id:175193)：基准方法

**简单随机抽样 (Simple Random Sampling, SRS)** 是最基础的概率[抽样方法](@entry_id:141232)，也是衡量其他更复杂抽样设计效率的基准。它分为两种[基本类](@entry_id:158335)型：

-   **有放回简单随机抽样 (SRSWR)**：每次抽取一个单元后，将其放回总体中，因此同一个单元可能被多次抽中。在SRSWR中，每次抽样都是独立的。
-   **无放回简单随机抽样 (SRSWOR)**：抽中的单元不再放回，样本中的所有单元都是唯一的。这是在实践中更常用的方法。

两种方法的主要区别在于样本单元之间的独立性，这直接影响了[估计量方差](@entry_id:263211)的计算。以样本比例 $\hat{p}$ 为例，其在SRSWR下的方差为 $\operatorname{Var}_{\mathrm{WR}}(\hat{p}) = \frac{p(1-p)}{n}$，其中 $p$ 是总体比例，$n$ 是样本量。

#### [有限总体校正](@entry_id:270862)

当从一个**有限总体 (finite population)** 中进行[无放回抽样](@entry_id:276879)时，每抽取一个单元都会减少剩余总体的不确定性。这种信息上的增益体现在[估计量方差](@entry_id:263211)的减小上。与SRSWR相比，SRSWOR的方差更小。描述这种方差缩减的因子被称为**[有限总体校正](@entry_id:270862) (Finite Population Correction, FPC)**。

对于从规模为 $N$ 的总体中抽取容量为 $n$ 的样本，SRSWOR下样本均值 $\bar{y}$ 的方差为：
$$
\operatorname{Var}_{\mathrm{WOR}}(\bar{y}) = \left(1 - \frac{n}{N}\right) \frac{S^2}{n}
$$
其中 $S^2$ 是总体方差。这里的 $(1 - \frac{n}{N})$ 就是FPC因子。当抽样分数 $f = n/N$ 较小时，FPC接近1，SRSWOR与SRSWR的[方差近似](@entry_id:268585)相等。然而，当抽样分数不可忽略时，FPC的作用就变得显著。

我们可以通过一个具体的例子来量化FPC的影响。假设一个生物统计学家计划从一个 $N=2000$ 人的有限患者登记库中抽取 $n=400$ 的样本 [@problem_id:4942763]。抽样分数 $f = 400/2000 = 0.2$。基于[正态近似](@entry_id:261668)的[置信区间](@entry_id:138194)，其半宽度 $h$ 正比于估计量标准误的平方根，即 $h \propto \sqrt{\operatorname{Var}(\text{estimator})}$。

包含FPC（即SRSWOR）的半宽度与不包含FPC（即SRSWR近似）的半宽度之比为：
$$
\frac{h_{\text{with FPC}}}{h_{\text{without FPC}}} = \frac{\sqrt{\left(1 - \frac{n}{N}\right) \frac{S^2}{n}}}{\sqrt{\frac{S^2}{n}}} = \sqrt{1 - \frac{n}{N}}
$$
在这个例子中，该比值为 $\sqrt{1 - 0.2} = \sqrt{0.8} \approx 0.8944$。这意味着，由于考虑了有限总体进行[无放回抽样](@entry_id:276879)，[置信区间](@entry_id:138194)的半宽度缩减了。相对缩减量为 $R(N, n) = 1 - \sqrt{1 - n/N} \approx 1 - 0.8944 = 0.1056$，即约10.6%的缩减。无论估计的是总体均值还是总体比例，这个相对缩减量都是相同的 [@problem_id:4942763]。这个问题也说明，即使样本量看起来不大，但只要抽样分数达到一定水平（通常经验法则是5%或10%），FPC就应该被纳入方差计算，以获得更精确的推断。[@problem_id:4942762]

### 提升效率：[分层抽样](@entry_id:138654)

虽然简单随机抽样易于实施和分析，但当我们可以获取有关总体的辅助信息时，它往往不是最高效的[抽样方法](@entry_id:141232)。**[分层抽样](@entry_id:138654) (Stratified Sampling)** 是一种通过利用这类辅助信息来提高估计精度（即减小[估计量方差](@entry_id:263211)）的强大技术。

#### 分层原理

[分层抽样](@entry_id:138654)的核心思想是，在抽样前，将异质性较大的总体划分为若干个内部同质性较高的子总体，这些子总体称为**层 (strata)**。然后，在每个层内独立地进行抽样。

分层的目标是使得“层内”的变异尽可能小，“层间”的变异尽可能大。如果能够成功实现这一点，那么通过对各层样本的估计值进行适当加权合并，所得到的[总体估计](@entry_id:200993)量将比同样样本量的简单[随机抽样](@entry_id:175193)得到的估计量具有更小的方差。

设想一个场景：一个卫生系统希望估计患者群体中某种生物标志物 $y$ 的平均水平。同时，对于登记库中的所有 $N$ 名患者，系统还有一个根据电子病历计算出的连续风险评分 $x$，且历史数据表明 $x$ 和 $y$ 高度相关（例如，[相关系数](@entry_id:147037) $r \approx 0.85$）[@problem_id:4942749]。在这种情况下，SRS的效率会很低，因为它没有利用 $x$ 和 $y$ 之间的强相关性。一个随机样本可能偶然抽中了过多高风险评分或低风险评分的患者，导致样本均值偏离总体均值。

一个有效的策略就是利用风险评分 $x$ 进行分层。我们可以根据 $x$ 的[分位数](@entry_id:178417)将患者分为几个层（如低风险、中风险、高风险）。由于 $x$ 和 $y$ 高度相关，每个层在 $x$ 上的[同质性](@entry_id:636502)也意味着它们在 $y$ 上的同质性，即每个层内的方差 $S_h^2$ 会远小于整个总体的方差 $S_y^2$。

#### 分层机制与样本分配

[分层抽样](@entry_id:138654)中，[总体均值](@entry_id:175446)的估计量 $\bar{y}_{st}$ 是各层样本均值 $\bar{y}_h$ 的加权平均：
$$
\bar{y}_{st} = \sum_{h=1}^{H} W_h \bar{y}_h
$$
其中 $H$ 是层的数量，$W_h = N_h/N$ 是第 $h$ 层的权重（即该层在总体中所占的比例）。由于各层是独立抽样的，其方差为：
$$
\operatorname{Var}(\bar{y}_{st}) = \sum_{h=1}^{H} W_h^2 \operatorname{Var}(\bar{y}_h) = \sum_{h=1}^{H} W_h^2 \left(1 - \frac{n_h}{N_h}\right) \frac{S_h^2}{n_h}
$$
这里的 $n_h$ 和 $S_h^2$ 分别是第 $h$ 层的样本量和总体方差。这个公式清晰地显示，$\operatorname{Var}(\bar{y}_{st})$ 取决于层内方差 $S_h^2$，而不是总体总方差。

在总样本量 $n = \sum n_h$ 固定的前提下，如何将样本分配到各个层（即确定 $n_h$）是分层设计的关键。

1.  **[比例分配](@entry_id:634725) (Proportional Allocation)**：这是一种常见且直观的方法，即各层的样本量与其在总体中的大小成正比：$n_h = n \cdot W_h = n \cdot \frac{N_h}{N}$。例如，一项公共卫生研究将某市划分为三个层，其人口规模分别为 $N_1=2000, N_2=5000, N_3=3000$（总人口 $N=10000$），总样本量为 $n=600$。采用[比例分配](@entry_id:634725)，样本量将是 $n_1=120, n_2=300, n_3=180$ [@problem_id:4942760]。

2.  **最优分配 (Optimal Allocation) / Neyman 分配**：为了在固定总样本量 $n$ 的情况下最小化 $\operatorname{Var}(\bar{y}_{st})$，最优的策略是向那些规模更大 ($N_h$ 大) 且内部变异也更大 ($S_h$ 大) 的层分配更多的样本。这种分配方式称为**[Neyman分配](@entry_id:634618)**，其公式为：
    $$
    n_h = n \frac{N_h S_h}{\sum_{k=1}^{H} N_k S_k}
    $$
    设想一项生物统计调查，有4个规模相等 ($N_h=1000$) 的临床患者组作为分层，但其内部生物标志物的标准差差异显著，分别为 $(S_h)=(2, 4, 1, 5)$。如果总样本量为 $n=400$，[比例分配](@entry_id:634725)会给每个层分配100个样本。但[Neyman分配](@entry_id:634618)则会向标准差为5的层分配更多样本，而向标准差为1的层分配更少样本。通过计算可以证明，[Neyman分配](@entry_id:634618)下的[估计量方差](@entry_id:263211)显著低于[比例分配](@entry_id:634725) [@problem_id:4942764]，在这个具体例子中，[方差比](@entry_id:162608)率约为0.7585，即[Neyman分配](@entry_id:634618)的[方差比](@entry_id:162608)[比例分配](@entry_id:634725)低了近25%。

### 关注成本与可行性：整群抽样

与[分层抽样](@entry_id:138654)旨在提高效率不同，**整群抽样 (Cluster Sampling)** 的主要动机通常是降低成本和提高操作可行性。在许多实际情况下，我们无法获得完整的总体单元列表，或者总体单元在地理上分布广泛，对它们进行简单[随机抽样](@entry_id:175193)在经济上是不可行的。

整群抽样的做法是将总体划分为若干个**群 (clusters)**（如城市街区、学校、医院），然后随机抽取一部分群，并对抽中群内的所有单元（单阶段整群抽样）或部分单元（多阶段整群抽样）进行调查。

#### 整群抽样的偏差风险

当群的大小（即群内单元数）不相等时，整群抽样的分析需要特别注意。一个常见的严重错误是忽略群的规模，对抽中群的指标（如群内均值或比例）进行简单算术平均。这种未加权的估计量几乎总是**有偏的**。

考虑一个评估高血压患病率的研究，抽样单位是初级保健诊所（群）。假设有两类诊所：40家小型诊所，每家有50名患者，患病率为0.18；以及20家大型诊所，每家有200名患者，患病率为0.30。真实的总体患病率 $\mu$ 是所有患者中高血压患者的比例，这是一个以患者人数为权重的加权平均。如果我们随机抽取10家诊所，然后计算这10家诊所患病率的简单平均值作为 $\mu$ 的估计，那么这个估计量的[期望值](@entry_id:150961)将是所有诊所患病率的简单平均值，而不是真实的总体患病率 $\mu$。在这个例子中，未加权的估计量会低估真实的患病率，因为占总人口大部分的大型诊所（患病率更高）在诊所层面的简单平均中没有得到应有的权重。计算表明，这种偏差的绝对值可达0.04，这是一个相当大的误差 [@problem_id:4942739]。

正确的做法是使用加权估计，例如Horvitz-Thompson估计量（后文将详述），或者其他考虑了不等规模的模型。

#### 设计效应与组内[相关系数](@entry_id:147037)

整群抽样的一个主要统计后果是，对于相同数量的最终样本单元，其[估计量的方差](@entry_id:167223)通常高于简单随机抽样。这是因为同一群内的单元往往比随机选择的单元更相似。这种相似性用**组内相关系数 (Intracluster Correlation Coefficient, ICC)** 来衡量，通常用 $\rho$ 表示。

ICC定义为同一群内两个不同个体的观测值之间的相关性。它的取值范围通常在0到1之间。$\rho$ 越大，表示群内[同质性](@entry_id:636502)越高，群间差异越大。

在一个将群特定比例 $p_k$ 视为随机变量的模型中，可以从第一性原理推导出，对于[二元结果](@entry_id:173636)，ICC可以表示为 [@problem_id:4942736]：
$$
\rho = \frac{\operatorname{Var}(p_k)}{p(1-p)}
$$
这里，$\operatorname{Var}(p_k)$ 是群比例的方差（即“群间”方差），而 $p(1-p)$ 是基于总体边际比例 $p$ 的总方差。这个公式直观地表明，ICC是群间变异在总变异中所占的比例。例如，对于一组群比例 $(0.12, 0.18, 0.20, 0.25, 0.15)$，可以计算出ICC约为0.01328 [@problem_id:4942736]。

整群抽样相对于简单[随机抽样](@entry_id:175193)在方差上的增加程度，可以用**设计效应 (Design Effect, DEFF)** 来量化。对于单阶段等大规模整群抽样，设计效应的近似公式为：
$$
DEFF \approx 1 + (\bar{M}-1)\rho
$$
其中 $\bar{M}$ 是平均群规模。即使ICC $\rho$ 很小，只要群规模 $\bar{M}$ 较大，设计效应也可能非常大，这意味着方差会显著膨胀。因此，在设计整群抽样时，需要在成本节约与方差增加之间做出权衡。

### 操作简便的抽样方法：系统抽样

**系统抽样 (Systematic Sampling)** 是一种操作上非常简便的抽样方法。在拥有一个有序抽样框（即总体单元被编号为 $1, 2, \dots, N$）时，我们首先计算抽样间隔 $k = N/n$。然后，从前 $k$ 个单元中随机选择一个作为起点（称为**随机起点**），之后每隔 $k$ 个单元抽取一个个体。

如果抽样框中的单元排列是随机的，那么系统抽样的效果近似于简单[随机抽样](@entry_id:175193)。如果抽样框的排列与研究变量相关（例如，按年龄或收入排序），系统抽样通常能提供比简单[随机抽样](@entry_id:175193)更精确的估计，因为它能隐式地保证样本在整个排序范围内的均匀分布，类似于一种隐性的分层。

#### 系统抽样的陷阱：周期性

然而，系统抽样有一个致命的弱点：当抽样框的排列中存在与抽样间隔 $k$ 相吻合的**周期性 (periodicity)** 时，它可能导致严重的偏差和/或极高的方差。

设想一个场景，一个诊所的患者生物标志物数据按就诊日期排列，并且由于诊所操作流程，数据呈现出周期性。例如，每 $k$ 天为一个周期，周期中的第一天，患者的生物标志物值会有一个固定的上移 $d$。如果研究者采用一个固定的、非随机的起点（例如，总是从第1个单元开始），并使用与数据周期完全相同的抽样间隔 $k$ 进行抽样，那么所有抽中的样本将全部来自周期中具有特殊值的“第一天” [@problem_id:4942776]。

在这种情况下，样本均值将是 $\mu+d$，而真实的[总体均值](@entry_id:175446)是 $\mu + d/k$。这个固定起点的系统抽样设计得到的估计量是有偏的，偏差为 $d(1 - 1/k)$。如果 $k$ 很大，这个偏差会接近 $d$，可能导致完全错误的结论。

这个例子揭示了系统抽样的两个关键原则：
1.  **必须使用随机起点**。随机选择起点保证了每个总体单元都有一个已知的包含概率 ($1/k$)，从而使系统抽样成为一种真正的概率抽样方法，并使得样本均值成为总体均值的[无偏估计量](@entry_id:756290)。
2.  在应用系统抽样之前，必须仔细检查抽样框是否存在任何潜在的周期性。如果怀疑存在周期性，可以考虑随机打乱抽样框顺序，或者改用其他抽样方法。

### 高级主题：不等概率抽样

我们之前讨论的所有方法（SRS、分层、系统）在最基本的形式下都属于等概率抽样（或在层内等概率）。然而，在某些情况下，特别是多阶段抽样中，采用**不等概率抽样 (Unequal Probability Sampling)** 会更加高效。

#### 按规模大小成比例的概率抽样与Horvitz-Thompson估计量

**按规模大小成比例的概率抽样 (Probability Proportional to Size, PPS)** 是一种重要的不等概率[抽样方法](@entry_id:141232)。其核心思想是，在抽样时赋予“较大”的抽样单元更高的被抽中概率。这里的“大小”由一个与研究变量相关的辅助变量（**规模度量 (size measure)**，$M_k$）来定义。例如，在对诊所进行抽样时，诊所的年接诊患者数可以作为其规模度量。

对于一个固定样本量为 $n$ 的无放回PPS（PPSWOR）设计，第 $k$ 个单元的（一阶）包含概率 $\pi_k$ 与其规模度量 $M_k$ 成正比。可以推导出 [@problem_id:4942745]：
$$
\pi_k = n \frac{M_k}{\sum_{j=1}^{C} M_j}
$$
其中 $C$ 是总体中的单元总数。

由于每个单元的包含概率不同，我们不能再使用简单的样本均值或总和来估计总体参数。为了修正这种不等概率选择所带来的偏差，我们需要对每个抽中的单元进行加权，其权重是其包含概率的倒数，即 $w_k = 1/\pi_k$。这个想法引出了**Horvitz-Thompson (HT) 估计量**。

HT总体总值估计量定义为：
$$
\widehat{T}_{HT} = \sum_{k \in s} \frac{y_k}{\pi_k}
$$
其中 $s$ 是抽中的样本集合，$y_k$ 是第 $k$ 个单元的观测值。HT估计量的直观含义是，每个被抽中的单元 $k$ 不仅代表它自己，还代表了总体中其他 $w_k - 1$ 个“类似”但未被抽中的单元。包含概率越小的单元，一旦被抽中，其代表性就越强，获得的权重也越大。在恰当的设计下，HT估计量是总体总值的[无偏估计量](@entry_id:756290)。

例如，在一项全国生物统计调查中，从一个包含6个诊所（PSU）的抽样框中抽取 $n=3$ 个。各诊所的年患者数 $(M_k)$ 分别为 $(120, 60, 90, 30, 150, 50)$。使用上述公式可以计算出每个诊所的包含概率 $\pi_k$。如果抽中的样本是诊所1、3、5，其观测到的[免疫接种](@entry_id:193800)总数 $(y_k)$ 分别为 $(4800, 3600, 6000)$，那么HT估计的总接种数就是 $\frac{4800}{\pi_1} + \frac{3600}{\pi_3} + \frac{6000}{\pi_5}$。通过具体计算，可以得到一个对总体总数的有效估计 [@problem_id:4942745]。

不等概率抽样及其相应的HT估计量是现代抽样调查理论的基石，特别是在处理复杂的多阶段调查设计（如大型[公共卫生监测](@entry_id:170581)项目）时不可或缺。