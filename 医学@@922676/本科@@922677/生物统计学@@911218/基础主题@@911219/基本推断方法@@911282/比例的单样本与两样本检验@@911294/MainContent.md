## 引言
在生物统计学和生命科学研究中，我们经常需要处理二元分类结果——患者是否康复、基因是否突变、干预是否有效。对这些以“比例”形式呈现的数据进行严谨的推断和比较，是得出科学结论的基础。比例的单样本与双样本检验正是为此类问题设计的核心统计工具，其重要性不言而喻。然而，初学者常常在何时使用精确检验与近似检验、如何处理复杂研究设计（如混杂因素或[数据相关性](@entry_id:748197)）等问题上感到困惑，这构成了从理论学习到实际应用的一道鸿沟。

本文旨在系统性地填补这一知识缺口。我们将引导读者深入理解比例检验的内在逻辑和统计机制，掌握其在不同研究场景下的正确应用，并认识到其局限性与扩展性。通过学习本文，你将能够自信地为你的研究问题选择、实施并解读最合适的比例检验方法。

文章主体分为三个章节。在 **“原理与机制”** 中，我们将从伯努利与二项分布出发，奠定比例[数据建模](@entry_id:141456)的理论基础，详细剖析单样本与双样本检验的精确方法（如Fisher[精确检验](@entry_id:178040)）和近似方法（如[Z检验](@entry_id:169390)），并审视其背后的关键假设。接下来，在 **“应用与跨学科联系”** 中，我们将通过丰富的实例，展示这些检验如何在临床试验（包括非劣效性检验）、观察性研究（处理混杂与聚[类数](@entry_id:156164)据）以及前沿的基因组学分析中发挥关键作用。最后，在 **“动手实践”** 部分，你将通过解决具体问题来巩固所学知识，将理论应用于实际计算与研究设计中。

## 原理与机制

本章将深入探讨比例的单样本和双样本检验背后的核心原理与统计机制。我们将从对[二元结果](@entry_id:173636)进行建[模的基](@entry_id:156416)础出发，系统地建立[假设检验](@entry_id:142556)的框架，区分精确检验和近似检验，并阐明这些方法所依赖的关键假设。

### 比例的统计建模基础

在生物统计学中，许多研究终点本质上是二元的：例如，患者是否出现临床缓解、疫苗是否诱导[血清转化](@entry_id:195698)、个体是否被某种菌株定植。对这类结果进行严谨的推断，始于一个清晰的[概率模型](@entry_id:265150)。

#### 伯努利分布与[二项分布](@entry_id:141181)

最基本的[二元结果](@entry_id:173636)模型是 **[伯努利分布](@entry_id:266933) (Bernoulli distribution)**。对于单个受试者 $i$，其结果 $Y_i$ 是一个随机变量，取值为 $1$（表示“成功”或事件发生）或 $0$（表示“失败”或事件未发生）。该分布由单一参数 $p$ 完全定义，即成功的概率：

$p = \Pr(Y_i=1)$

其中 $p$ 的值在 $[0, 1]$ 区间内。相应地，失败的概率为 $\Pr(Y_i=0) = 1-p$。参数 $p$ 同时也是结果的[总体均值](@entry_id:175446)，因为 $E[Y_i] = 1 \cdot p + 0 \cdot (1-p) = p$。

在临床研究中，我们通常观察一个由 $n$ 个受试者组成的样本。如果我们假设每个受试者的结果是 **[独立同分布](@entry_id:169067) (independent and identically distributed, i.i.d.)** 的，这意味着每个受试者都遵循参数为 $p$ 的相同[伯努利分布](@entry_id:266933)，并且他们的结果互不影响，那么样本中成功的总数 $X = \sum_{i=1}^n Y_i$ 就遵循 **二项分布 (Binomial distribution)**，记为 $X \sim \mathrm{Bin}(n, p)$。其概率质量函数 (probability mass function, PMF) 为：

$\Pr(X=k) = \binom{n}{k} p^k (1-p)^{n-k}, \quad k \in \{0, 1, \dots, n\}$

这个i.i.d.假设是推断的基础。如果个体间的成功概率不同（即不满足“同分布”），或者结果相互关联（即不满足“独立”），那么总数 $X$ 将不再遵循标准的[二项分布](@entry_id:141181)，这将对后续的检验产生深远影响 [@problem_id:4934204]。

#### 充分统计量与参数可识别性

在[二项模型](@entry_id:275034)中，一个至关重要的概念是 **充分统计量 (sufficient statistic)**。一个统计量之所以“充分”，是因为它包含了样本中关于未知参数的所有信息。对于二项分布的参数 $p$，成功总数 $X$ 就是一个充分统计量。根据 **Fisher-Neyman[因子分解定理](@entry_id:749213) (Fisher–Neyman factorization theorem)**，一个统计量 $T(\mathbf{Y})$ 是参数 $\theta$ 的充分统计量，当且仅当样本 $\mathbf{Y}=(Y_1, \dots, Y_n)$ 的[联合概率函数](@entry_id:272740)可以分解为一个仅通过 $T(\mathbf{Y})$ 依赖于 $\theta$ 的函数和另一个不依赖于 $\theta$ 的函数的乘积。

对于i.i.d.的伯努利试验，样本的[联合概率](@entry_id:266356)为：

$\Pr(Y_1=y_1, \dots, Y_n=y_n) = \prod_{i=1}^n p^{y_i}(1-p)^{1-y_i} = p^{\sum y_i} (1-p)^{n-\sum y_i} = p^x (1-p)^{n-x}$

其中 $x = \sum y_i$ 是观测到的成功总数。此联合概率仅通过总数 $x$ 依赖于参数 $p$。这意味着，一旦我们知道了样本中有多少个成功案例，这些成功案例具体是哪些受试者贡献的（即成功的顺序）对于推断 $p$ 而言，不提供任何额外信息 [@problem_id:4934177]。这个性质极大地简化了统计推断。

另一个基础概念是 **参数可识别性 (parameter identifiability)**。在已知试验次数 $n$ 的[二项模型](@entry_id:275034) $X \sim \mathrm{Bin}(n, p)$ 中，参数 $p$ 是可识别的。这意味着不同的 $p$ 值会产生不同的 $X$ 的概率分布。如果 $p_1 \neq p_2$，那么至少对于某个 $k$ 值，$\Pr(X=k|p_1) \neq \Pr(X=k|p_2)$。这保证了我们可以从数据中唯一地学习或估计 $p$ [@problem_id:4934204]。

### 单样本比例的假设检验

当我们的研究目标是检验单个群体的未知比例 $p$ 是否等于某个预先设定的基准值 $p_0$ 时，就需要进行单样本比例检验。这可以表述为检验一个零假设 $H_0: p = p_0$。

#### [精确二项检验](@entry_id:170573)

最直接、最基本的方法是 **[精确二项检验](@entry_id:170573) (exact binomial test)**。该方法不依赖于任何大样本近似，而是直接利用在 $H_0$ 为真时 $X$ 的确切分布，即 $X \sim \mathrm{Bin}(n, p_0)$。

$p$ 值被定义为在 $H_0$ 为真的前提下，观测到与当前样本一样极端或更极端结果的概率。对于[单侧检验](@entry_id:170263)，例如 $H_A: p > p_0$，极端性方向是明确的。如果观测到 $x$ 次成功，则 $p$ 值为 $\Pr(X \ge x) = \sum_{k=x}^n \binom{n}{k} p_0^k (1-p_0)^{n-k}$。

对于双侧检验 $H_A: p \neq p_0$，定义“极端性”则更为微妙，特别是在 $p_0 \neq 0.5$ 导致[二项分布](@entry_id:141181)不对称时。一个有原则且被广泛接受的方法是 **“小概率法” (method of small probabilities)**。该方法将所有在 $H_0$ 下发生概率不大于观测结果 $x$ 的概率的那些结果，都视为“至少一样极端”。因此，双侧 $p$ 值的计算方式为：

$p\text{-value} = \sum_{k: \Pr(X=k|p_0) \le \Pr(X=x|p_0)} \Pr(X=k|p_0)$

这种定义方式确保了检验的接受域由 $H_0$ 下最可能发生的结果组成，从而构成了一个有效的精确检验 [@problem_id:4934203]。

#### 基于[正态近似](@entry_id:261668)的[Z检验](@entry_id:169390)

当样本量 $n$ 足够大时，根据 **[中心极限定理](@entry_id:143108) (Central Limit Theorem, CLT)**，二项分布可以用正态分布进行很好的近似。具体来说，样本比例 $\hat{p} = X/n$ 的[抽样分布](@entry_id:269683)近似为均值为 $p$、方差为 $p(1-p)/n$ 的正态分布。这为构建大样本 **[Z检验](@entry_id:169390) (z-test)** 提供了理论基础。

检验统计量的通用形式为 $Z = (\text{估计值} - \text{零假设值}) / \text{标准误}$。在构建检验统计量时，分母中标准误的计算方式是一个关键选择，这导致了两种常见的检验形式：

1.  **[得分检验](@entry_id:171353) (Score Test)**: [检验统计量](@entry_id:167372)为
    $Z = \frac{\hat{p} - p_0}{\sqrt{p_0(1-p_0)/n}}$
    该检验的特点是在分母中使用了零假设下的比例 $p_0$ 来计算标准误。这是进行[假设检验](@entry_id:142556)时的首选方法，因为整个统计量都是在 $H_0$ 为真的前提下构建的。这种做法确保了检验在原假设下具有渐近正确的 **检验水平 (size)**，即[第一类错误](@entry_id:163360)的概率在理论上能够得到良好控制 [@problem_id:4934192]。

2.  **沃尔德检验 (Wald Test)**: 检验统计量为
    $Z = \frac{\hat{p} - p_0}{\sqrt{\hat{p}(1-\hat{p})/n}}$
    该检验在分母中使用了样本估计的比例 $\hat{p}$。虽然根据[Slutsky定理](@entry_id:181685)，该统计量在 $H_0$ 下也渐近服从标准正态分布，但在有限样本中，其表现可能不如[得分检验](@entry_id:171353)。使用随机的 $\hat{p}$ 替代固定的 $p_0$ 会改变[拒绝域](@entry_id:172793)，有时可能导致实际的[第一类错误](@entry_id:163360)率显著高于设定的名义水平 $\alpha$ [@problem_id:4934192]。

**[正态近似](@entry_id:261668)的有效性条件**
[Z检验](@entry_id:169390)的有效性严重依赖于[正态近似](@entry_id:261668)的质量。一个常见的误解是只要样本量 $n \ge 30$ 就足够了。然而，对于比例数据，近似的质量同时取决于 $n$ 和 $p$。当 $p$ 接近 $0$ 或 $1$ 时，[二项分布](@entry_id:141181)会变得高度偏斜，即使 $n$ 较大，[正态近似](@entry_id:261668)也可能很差。

为了保证近似的合理性，我们需要确保分布足够“对称”，远离其边界 $0$ 和 $n$。一个广泛使用的实践准则是，在零假设 $p=p_0$ 下，预期的成功次数和失败次数都应足够大。通常的规则是：

$n p_0 \ge 10 \quad \text{且} \quad n (1-p_0) \ge 10$

这个条件确保了[二项分布](@entry_id:141181)的[偏度](@entry_id:178163)得到有效控制，使得对称的正态分布成为一个合理的近似 [@problem_id:4934213]。

### 双样本比例的[假设检验](@entry_id:142556)

生物统计学中更常见的情形是比较两个独立群体的比例，例如，比较两种疗法的有效率或两种疫苗的[血清转化](@entry_id:195698)率。

#### 问题设定与效应度量

假设我们有两个独立的样本：第一组有 $n_1$ 个受试者，成功事件数为 $X_1 \sim \mathrm{Bin}(n_1, p_1)$；第二组有 $n_2$ 个受试者，成功事件数为 $X_2 \sim \mathrm{Bin}(n_2, p_2)$。我们的目标是检验零假设 $H_0: p_1 = p_2$。

在比较 $p_1$ 和 $p_2$ 时，有三种主要的 **效应度量 (effect measures)**：

- **风险差 (Risk Difference, RD)**: $\Delta = p_1 - p_2$
- **风险比 (Risk Ratio, RR)**: $RR = p_1 / p_2$
- **比值比 (Odds Ratio, OR)**: $OR = \frac{p_1/(1-p_1)}{p_2/(1-p_2)}$

尽管这三个度量从不同角度量化了效应的大小，但它们的零假设是等价的。也就是说，$p_1 = p_2$ 的条件等价于 $\Delta=0$、 $RR=1$ 和 $OR=1$。因此，检验“无差异”的假设在参数设定上是统一的 [@problem_id:4934161]。

#### 基于[正态近似](@entry_id:261668)的合并[Z检验](@entry_id:169390)

与单样本情况类似，当两个样本的样本量都足够大时，我们可以使用[Z检验](@entry_id:169390)。检验 $H_0: p_1 = p_2$ 的标准方法是 **合并[Z检验](@entry_id:169390) (pooled z-test)**。

考虑一个旨在检验疫苗A的[血清转化](@entry_id:195698)率 ($p_1$)是否高于疫苗B ($p_2$)的临床试验，即检验 $H_A: p_1 > p_2$。零假设为 $H_0: p_1 \le p_2$，我们通常在边界 $p_1=p_2$ 上构建检验统计量 [@problem_id:4934219]。

在 $H_0: p_1 = p_2 = p$ 成立的条件下，比例差 $\hat{p}_1 - \hat{p}_2$ 的方差为：

$\mathrm{Var}(\hat{p}_1 - \hat{p}_2) = \frac{p(1-p)}{n_1} + \frac{p(1-p)}{n_2} = p(1-p) \left(\frac{1}{n_1} + \frac{1}{n_2}\right)$

这里的共同比例 $p$ 是未知的，它是一个 **滋扰参数 (nuisance parameter)**。为了构建检验，我们需要估计它。在 $H_0$ 成立的假设下，对 $p$ 最有效的估计量是将两个样本的数据合并得到的 **合并比例 (pooled proportion)**：

$\hat{p}_{\text{pool}} = \frac{X_1 + X_2}{n_1 + n_2}$

这个合并估计量是在 $H_0$ 约束下的[最大似然估计](@entry_id:142509) (MLE)，使用它来估计零假设下的方差，是[得分检验](@entry_id:171353)方法的核心思想 [@problem_id:4934202]。

因此，合并[Z检验](@entry_id:169390)的统计量为：

$Z = \frac{(\hat{p}_1 - \hat{p}_2) - 0}{\sqrt{\hat{p}_{\text{pool}}(1-\hat{p}_{\text{pool}})\left(\frac{1}{n_1} + \frac{1}{n_2}\right)}}$

例如，在一项疫苗研究中，疫苗A组240人中有42人[血清转化](@entry_id:195698) ($\hat{p}_1 = 0.175$)，疫苗B组260人中有26人[血清转化](@entry_id:195698) ($\hat{p}_2 = 0.1$)。合并比例为 $\hat{p}_{\text{pool}} = (42+26)/(240+260) = 0.136$。计算出的Z统计量约为 $2.44$，对应的单侧 $p$ 值约为 $0.007$，在 $\alpha=0.05$ 的水平下，我们有充分证据拒绝零假设，认为疫苗A的转化率更高 [@problem_id:4934219]。

同样，此检验的有效性条件也需满足。我们使用合并比例 $\hat{p}_{\text{pool}}$ 来检查每个组的预期成功和失败次数，即 $n_1\hat{p}_{\text{pool}}$, $n_1(1-\hat{p}_{\text{pool}})$, $n_2\hat{p}_{\text{pool}}$, $n_2(1-\hat{p}_{\text{pool}})$ 都应大于等于10 [@problem_id:4934213]。

#### Fisher[精确检验](@entry_id:178040)

当[Z检验](@entry_id:169390)的[正态近似](@entry_id:261668)条件不满足时——例如，样本量小，或者事件非常罕见（即某些单元格的计数非常小），[Z检验](@entry_id:169390)的p值会不准确。

设想一个比较两种抗逆转录病毒疗法的研究，A疗法组 $n_1=35$ 人中仅有 $x_1=1$ 人实现病毒抑制，而B疗法组 $n_2=420$ 人中有 $x_2=110$ 人。这里，A组的样本量小且事件数极少，[正态近似](@entry_id:261668)的条件显然不满足 [@problem_id:4934212]。

在这种情况下，我们需要使用不依赖于大样本近似的 **[精确检验](@entry_id:178040)**。对于比较两个比例（即分析 $2 \times 2$ [列联表](@entry_id:162738)），标准方法是 **Fisher[精确检验](@entry_id:178040) (Fisher's exact test)**。

该检验的巧妙之处在于通过 **条件化 (conditioning)** 来消除滋扰参数 $p$。在 $H_0: p_1=p_2$ 的假设下，总成功数 $T = X_1+X_2$ 是共同比例 $p$ 的充分统计量。Fisher[精确检验](@entry_id:178040)的思想是，在给定表格所有 **边际总和 (margins)**（即行总和与列总和）固定的条件下，计算单元格计数的概率。

这个[条件概率](@entry_id:151013)的推导是一个[组合计数](@entry_id:141086)问题。假设总共有 $N=n_1+n_2$ 个个体，其中 $C_1=X_1+X_2$ 人为“成功”，$C_2$ 人为“失败”。从这 $N$ 人中随机抽取 $n_1$ 人构成第一组，那么第一组中恰好有 $k$ 个成功者的概率是多少？这个概率遵循 **[超几何分布](@entry_id:193745) (hypergeometric distribution)**：

$\Pr(X_1=k | n_1, n_2, C_1, C_2) = \frac{\binom{C_1}{k} \binom{C_2}{n_1-k}}{\binom{N}{n_1}}$

这个分布不依赖于任何未知参数，因此可以用来计算“精确”的[p值](@entry_id:136498)。

例如，一项研究调查两个医院病房的细菌定植情况，数据如下：病房1有7人定植，0人未定植；病房2有2人定植，5人未定植。总计14人中，行总和为 $r_1=7, r_2=7$，列总和为 $c_1=9$ (定植), $c_2=5$ (未定植)。在固定所有边际总和的条件下，病房1的定植人数 $X_1$ 的分布为[超几何分布](@entry_id:193745)。观测值为 $X_1=7$。我们可以计算出 $\Pr(X_1 \ge 7)$ 作为单侧p值，以及通过小概率法计算双侧p值 [@problem_id:4934218]。

Fisher精确检验由于其离散性，通常是 **保守的 (conservative)**，即其实际的[第一类错误](@entry_id:163360)率往往小于名义水平 $\alpha$。从理论上看，合并[Z检验](@entry_id:169390)（[得分检验](@entry_id:171353)）可以被视为Fisher精确检验的一个大样本近似 [@problem_id:4934202]。

### 高级主题与模型假设的审视

统计检验的有效性根植于其 underlying assumptions。违反这些假设可能会导致错误的结论。

#### 检验的不变性

尽管 $\Delta=0, RR=1, OR=1$ 在参数上等价，但针对这些不同效应度量构建的检验在有限样本中可能并不等价。特别是，基于不同[参数化](@entry_id:265163)的沃尔德检验（例如，一个基于 $\hat{p}_1-\hat{p}_2$，另一个基于 $\ln(\hat{p}_1/\hat{p}_2)$）会产生不同的统计量和p值，因为沃尔德检验不具有 **[参数化](@entry_id:265163)不变性 (reparameterization invariance)**。相比之下，[得分检验](@entry_id:171353)和似然比检验具有这种不变性，对于检验 $p_1=p_2$ 这一根本问题，它们的结果是唯一的，不受效应度量选择的影响 [@problem_id:4934161]。

#### 独立同分布(i.i.d.)假设的重要性

我们推导的基础是i.i.d.的[伯努利试验](@entry_id:268355)。当这个假设被违反时：

- **异质性 (Heterogeneity)**: 如果受试者的成功概率 $p_i$ 不同（违反“同分布”），但仍然相互独立，则总成功数的方差会小于[二项分布](@entry_id:141181)的方差。具体而言，$\mathrm{Var}(X) = n\bar{p}(1-\bar{p}) - n\sigma_p^2$，其中 $\sigma_p^2$ 是个体概率的方差。标准检验忽略了 $\sigma_p^2 > 0$ 这一事实，高估了真实方差，从而导致检验变得 **保守**，降低了发现真实效应的能力 [@problem_id:4934204]。

- **相关性 (Correlation) / 聚类 (Clustering)**: 如果受试者结果不独立，例如，在多中心临床试验中，来自同一中心的患者可能更相似（违反“独立”），这会导致 **组内相关 (intraclass correlation)**。正的组内相关会增加样本比例的方差。标准[Z检验](@entry_id:169390)忽略了这种方差的增加（即设计效应 $\text{DEFF} > 1$），从而低估了真实的[标准误](@entry_id:635378)。这会导致[检验统计量](@entry_id:167372)被人为地放大，使得检验变得 **反保守 (anti-conservative)** 或 **自由 (liberal)**，即第一类错误率会膨胀，远高于名义水平 $\alpha$。这是一个在实践中非常严重且常见的问题 [@problem_id:4934204]。

值得注意的是，Fisher[精确检验](@entry_id:178040)的有效性也依赖于个体间的 **[可交换性](@entry_id:263314) (exchangeability)**，这一假设在存在聚类效应时同样被打破。因此，面对相关数据时，需要使用更高级的模型，如广义估计方程(GEE)或混合效应模型来处理。