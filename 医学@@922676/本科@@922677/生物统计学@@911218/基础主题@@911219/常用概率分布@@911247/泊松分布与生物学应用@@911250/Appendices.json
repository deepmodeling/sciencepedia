{"hands_on_practices": [{"introduction": "在生物学研究中，我们通常更关心事件发生的速率，而不仅仅是原始计数。本练习将向您展示如何在泊松广义线性模型中使用“偏移量”项来考虑不同的观测强度，并从零开始推导出模型参数的估计值。通过这个实践，您将掌握模型拟合的基本技能，并理解统计软件背后的工作原理。[@problem_id:4960760]", "problem": "一项野外研究监测了两个栖息地中一种寄生虫感染的发生率，各个抽样单元的观测投入不均。令 $Y_{i}$ 表示单元 $i$ 的新增感染计数，令 $E_{i}$ 表示该单元的观测投入（暴露度）。假设 $Y_{i}$ 相互独立，并服从一个适用于稀有事件计数的泊松模型，该模型使用对数连接函数和暴露度偏移量：\n$$\n\\log(\\mu_{i}) \\;=\\; \\log(E_{i}) \\;+\\; \\alpha \\;+\\; \\beta x_{i},\n$$\n其中 $\\mu_{i} = \\mathbb{E}[Y_{i}]$，$x_{i} \\in \\{0,1\\}$ 是一个表示栖息地的二元预测变量（$x_{i}=0$ 代表栖息地 A，$x_{i}=1$ 代表栖息地 B），$\\alpha$ 是截距项，$\\beta$ 是栖息地效应的系数。由于 $x_i$ 的两个水平都有观测值，因此不存在协变量共线性问题。数据如下：\n- 栖息地 A ($x_{i}=0$): $(E_{i},Y_{i}) \\in \\{(1.2,3),(0.8,1),(1.5,2),(0.5,0)\\}$,\n- 栖息地 B ($x_{i}=1$): $(E_{i},Y_{i}) \\in \\{(1.0,5),(2.0,9),(1.3,4),(0.7,3)\\}$.\n\n任务：\n1. 从泊松概率质量函数以及带有对数连接和偏移量的广义线性模型（GLM）的定义出发，通过对对数似然函数求偏导数并令其为零，构建 $(\\alpha,\\beta)$ 的得分方程。\n2. 将得分方程应用于单个二元预测变量 $x_{i}\\in\\{0,1\\}$ 的情况，并根据 $Y_{i}$ 和 $E_{i}$ 的分组总和，推导出最大似然估计量（MLEs）$\\widehat{\\alpha}$ 和 $\\widehat{\\beta}$ 的闭式表达式。\n3. 使用所提供的数据，计算最大似然估计量 $\\widehat{\\beta}$ 的数值。将您的答案四舍五入到四位有效数字。在最终报告的数字中不要包含单位。", "solution": "问题陈述经评估是有效的。它在科学上植根于广义线性模型（GLM）理论，这是现代统计学的基石之一，并且其在生物计数数据上的应用是恰当的。该问题提法恰当，提供了所有必要信息、清晰的模型设定以及足以进行所要求的推导和计算的数据集。术语精确客观，该任务是统计理论与应用中一个标准的、非平凡的练习。因此，有必要提供一个完整的解答。\n\n### 1. 得分方程的推导\n\n第一个任务是构建参数 $(\\alpha, \\beta)$ 的得分方程。得分方程通过将对数似然函数关于参数的一阶偏导数设为零来获得。\n\n设 $Y_i$ 是单元 $i$ 的观测计数，假设其服从均值为 $\\mu_i$ 的泊松分布，即 $Y_i \\sim \\text{Poisson}(\\mu_i)$。单个观测值 $Y_i=y_i$ 的概率质量函数（PMF）为：\n$$\nP(Y_i = y_i | \\mu_i) = \\frac{\\mu_i^{y_i} \\exp(-\\mu_i)}{y_i!}\n$$\n单个观测值的对数似然 $\\ell_i$ 是概率质量函数的自然对数：\n$$\n\\ell_i(\\mu_i | y_i) = \\log\\left( P(Y_i = y_i | \\mu_i) \\right) = y_i \\log(\\mu_i) - \\mu_i - \\log(y_i!)\n$$\n问题指定了一个带有对数连接函数和暴露度 $E_i$ 偏移项的广义线性模型。线性预测器为 $\\eta_i = \\log(E_i) + \\alpha + \\beta x_i$。连接函数将均值 $\\mu_i$ 与线性预测器关联起来：\n$$\n\\log(\\mu_i) = \\eta_i = \\log(E_i) + \\alpha + \\beta x_i\n$$\n由此，我们可以将 $\\mu_i$ 表示为：\n$$\n\\mu_i = \\exp(\\log(E_i) + \\alpha + \\beta x_i) = E_i \\exp(\\alpha + \\beta x_i)\n$$\n将 $\\log(\\mu_i)$ 和 $\\mu_i$ 代入 $\\ell_i$ 的表达式，我们得到用参数 $\\alpha$ 和 $\\beta$ 表示的观测值 $i$ 的对数似然：\n$$\n\\ell_i(\\alpha, \\beta) = y_i (\\log(E_i) + \\alpha + \\beta x_i) - E_i \\exp(\\alpha + \\beta x_i) - \\log(y_i!)\n$$\n假设 $n$ 个观测值是独立的，总对数似然 $L(\\alpha, \\beta)$ 是各个对数似然之和：\n$$\nL(\\alpha, \\beta) = \\sum_{i=1}^{n} \\ell_i(\\alpha, \\beta) = \\sum_{i=1}^{n} \\left[ y_i (\\log(E_i) + \\alpha + \\beta x_i) - E_i \\exp(\\alpha + \\beta x_i) - \\log(y_i!) \\right]\n$$\n得分向量由 $L(\\alpha, \\beta)$ 分别对 $\\alpha$ 和 $\\beta$ 的偏导数组成。\n\n对 $\\alpha$ 的偏导数是：\n$$\n\\frac{\\partial L}{\\partial \\alpha} = \\sum_{i=1}^{n} \\frac{\\partial}{\\partial \\alpha} \\left[ y_i \\alpha - E_i \\exp(\\alpha + \\beta x_i) \\right] = \\sum_{i=1}^{n} \\left[ y_i - E_i \\exp(\\alpha + \\beta x_i) \\right]\n$$\n回顾 $\\mu_i = E_i \\exp(\\alpha + \\beta x_i)$，上式简化为：\n$$\n\\frac{\\partial L}{\\partial \\alpha} = \\sum_{i=1}^{n} (y_i - \\mu_i)\n$$\n对 $\\beta$ 的偏导数是：\n$$\n\\frac{\\partial L}{\\partial \\beta} = \\sum_{i=1}^{n} \\frac{\\partial}{\\partial \\beta} \\left[ y_i \\beta x_i - E_i \\exp(\\alpha + \\beta x_i) \\right] = \\sum_{i=1}^{n} \\left[ y_i x_i - E_i x_i \\exp(\\alpha + \\beta x_i) \\right]\n$$\n这可以简化为：\n$$\n\\frac{\\partial L}{\\partial \\beta} = \\sum_{i=1}^{n} x_i (y_i - \\mu_i)\n$$\n将这些偏导数设为零即可得到得分方程。令 $\\widehat{\\alpha}$ 和 $\\widehat{\\beta}$ 表示最大似然估计量（MLEs）。得分方程为：\n$$\n\\sum_{i=1}^{n} (Y_i - E_i \\exp(\\widehat{\\alpha} + \\widehat{\\beta} x_i)) = 0\n$$\n$$\n\\sum_{i=1}^{n} x_i (Y_i - E_i \\exp(\\widehat{\\alpha} + \\widehat{\\beta} x_i)) = 0\n$$\n\n### 2. 闭式最大似然估计量的推导\n\n第二个任务是针对 $x_i$ 是二元预测变量 $x_i \\in \\{0, 1\\}$ 的特定情况，求出 $\\widehat{\\alpha}$ 和 $\\widehat{\\beta}$ 的闭式表达式。我们将得分方程中的求和项分为两组：$x_i=0$（栖息地 A）和 $x_i=1$（栖息地 B）。\n\n令 $I_0 = \\{i | x_i = 0\\}$ 且 $I_1 = \\{i | x_i = 1\\}$。\n\n第一个得分方程变为：\n$$\n\\sum_{i \\in I_0} (Y_i - E_i \\exp(\\widehat{\\alpha} + \\widehat{\\beta} \\cdot 0)) + \\sum_{i \\in I_1} (Y_i - E_i \\exp(\\widehat{\\alpha} + \\widehat{\\beta} \\cdot 1)) = 0\n$$\n$$\n\\implies \\sum_{i \\in I_0} (Y_i - E_i \\exp(\\widehat{\\alpha})) + \\sum_{i \\in I_1} (Y_i - E_i \\exp(\\widehat{\\alpha} + \\widehat{\\beta})) = 0\n$$\n第二个得分方程包含项 $x_i$，对于第一组，$x_i$ 为零：\n$$\n\\sum_{i \\in I_0} 0 \\cdot (Y_i - E_i \\exp(\\widehat{\\alpha})) + \\sum_{i \\in I_1} 1 \\cdot (Y_i - E_i \\exp(\\widehat{\\alpha} + \\widehat{\\beta})) = 0\n$$\n$$\n\\implies \\sum_{i \\in I_1} (Y_i - E_i \\exp(\\widehat{\\alpha} + \\widehat{\\beta})) = 0\n$$\n从这个简化的第二个方程，我们可以解出项 $\\exp(\\widehat{\\alpha} + \\widehat{\\beta})$：\n$$\n\\sum_{i \\in I_1} Y_i = \\sum_{i \\in I_1} E_i \\exp(\\widehat{\\alpha} + \\widehat{\\beta}) = \\exp(\\widehat{\\alpha} + \\widehat{\\beta}) \\sum_{i \\in I_1} E_i\n$$\n$$\n\\implies \\exp(\\widehat{\\alpha} + \\widehat{\\beta}) = \\frac{\\sum_{i \\in I_1} Y_i}{\\sum_{i \\in I_1} E_i}\n$$\n现在将第二个方程的结果代回第一个方程。注意到第一个方程的第二部分 $\\sum_{i \\in I_1} (Y_i - E_i \\exp(\\widehat{\\alpha} + \\widehat{\\beta}))$ 正是第二个得分方程所设为零的项。因此，第一个方程简化为：\n$$\n\\sum_{i \\in I_0} (Y_i - E_i \\exp(\\widehat{\\alpha})) = 0\n$$\n解出 $\\exp(\\widehat{\\alpha})$：\n$$\n\\sum_{i \\in I_0} Y_i = \\sum_{i \\in I_0} E_i \\exp(\\widehat{\\alpha}) = \\exp(\\widehat{\\alpha}) \\sum_{i \\in I_0} E_i\n$$\n$$\n\\implies \\exp(\\widehat{\\alpha}) = \\frac{\\sum_{i \\in I_0} Y_i}{\\sum_{i \\in I_0} E_i}\n$$\n对两个表达式取自然对数，即可得到闭式的最大似然估计量。令 $Y_A = \\sum_{i \\in I_0} Y_i$，$E_A = \\sum_{i \\in I_0} E_i$，$Y_B = \\sum_{i \\in I_1} Y_i$，以及 $E_B = \\sum_{i \\in I_1} E_i$。\n$\\alpha$ 的最大似然估计量是：\n$$\n\\widehat{\\alpha} = \\ln\\left( \\frac{\\sum_{i: x_i=0} Y_i}{\\sum_{i: x_i=0} E_i} \\right) = \\ln\\left( \\frac{Y_A}{E_A} \\right)\n$$\n这代表栖息地 A 的背景发生率的对数。\n我们还有：\n$$\n\\widehat{\\alpha} + \\widehat{\\beta} = \\ln\\left( \\frac{\\sum_{i: x_i=1} Y_i}{\\sum_{i: x_i=1} E_i} \\right) = \\ln\\left( \\frac{Y_B}{E_B} \\right)\n$$\n$\\beta$ 的最大似然估计量通过相减得到：\n$$\n\\widehat{\\beta} = (\\widehat{\\alpha} + \\widehat{\\beta}) - \\widehat{\\alpha} = \\ln\\left( \\frac{Y_B}{E_B} \\right) - \\ln\\left( \\frac{Y_A}{E_A} \\right) = \\ln\\left( \\frac{Y_B/E_B}{Y_A/E_A} \\right)\n$$\n这是栖息地 B 与栖息地 A 之间发生率比值的对数，也称为对数率比。\n\n### 3. $\\beta$ 的最大似然估计量的计算\n\n最后一个任务是使用所提供的数据计算 $\\widehat{\\beta}$ 的数值。\n\n栖息地 A ($x_i=0$) 的数据： $(E_i, Y_i) \\in \\{(1.2,3), (0.8,1), (1.5,2), (0.5,0)\\}$。\n- 栖息地 A 的总观测计数： $Y_A = 3 + 1 + 2 + 0 = 6$。\n- 栖息地 A 的总观测投入： $E_A = 1.2 + 0.8 + 1.5 + 0.5 = 4.0$。\n\n栖息地 B ($x_i=1$) 的数据： $(E_i, Y_i) \\in \\{(1.0,5), (2.0,9), (1.3,4), (0.7,3)\\}$。\n- 栖息地 B 的总观测计数： $Y_B = 5 + 9 + 4 + 3 = 21$。\n- 栖息地 B 的总观测投入： $E_B = 1.0 + 2.0 + 1.3 + 0.7 = 5.0$。\n\n现在我们计算每个栖息地的估计发生率。\n- 栖息地 A 的估计发生率： $\\frac{Y_A}{E_A} = \\frac{6}{4.0} = 1.5$。\n- 栖息地 B 的估计发生率： $\\frac{Y_B}{E_B} = \\frac{21}{5.0} = 4.2$。\n\n使用推导出的 $\\widehat{\\beta}$ 公式：\n$$\n\\widehat{\\beta} = \\ln\\left( \\frac{Y_B/E_B}{Y_A/E_A} \\right) = \\ln\\left( \\frac{4.2}{1.5} \\right) = \\ln(2.8)\n$$\n计算其数值：\n$$\n\\widehat{\\beta} \\approx 1.029619417...\n$$\n四舍五入到四位有效数字，我们注意到第五位有效数字是 $6$，所以我们将第四位数字 ($9$) 向上舍入。这会引起进位。\n$$\n\\widehat{\\beta} \\approx 1.030\n$$\n末尾的零是有效数字，必须保留。", "answer": "$$\\boxed{1.030}$$", "id": "4960760"}, {"introduction": "泊松分布一个核心假设是均值与方差相等，即等离散性，但生物学过程的变异性常常超出此假设，导致所谓的“过度离散”。本练习将教您如何使用皮尔逊卡方统计量（Pearson chi-squared statistic）对过度离散进行形式化检验。这是模型验证中至关重要的一步，能确保您的统计推断建立在可靠的基础之上。[@problem_id:4960753]", "problem": "一项实地研究量化了在具有不同环境条件的湿地中放置的 $n$ 个独立捕蚊器中每个捕蚊器的蚊子幼虫数量。研究人员拟合了一个具有泊松响应的对数线性广义线性模型 (GLM)，使用 $p$ 个回归参数（包括截距）来解释第 $i$ 个捕蚊器的平均计数 $\\mu_i$。在泊松分布的等离散性质下，每个计数满足 $\\operatorname{Var}(Y_i)=\\mu_i$ 和 $\\mathbb{E}(Y_i)=\\mu_i$，且 $Y_i$ 在不同捕蚊器之间是独立的。通过最大似然法拟合 GLM 后，获得了估计的均值 $\\hat{\\mu}_i$ 和回归参数。考虑 Pearson 统计量\n$$\nX_P^2=\\sum_{i=1}^{n}\\frac{(Y_i-\\hat{\\mu}_i)^2}{\\hat{\\mu}_i}.\n$$\n要求您使用离散度估计 $\\hat{\\phi}_P=X_P^2$ 除以其自由度来构建一个过度离散检验，并分析其在等离散下的零分布。\n\n从泊松分布的定义性质和最大似然估计量的大样本行为出发，推导在正确指定的泊松 GLM 下 $X_P^2$ 的大样本零分布，并由此推导 $\\hat{\\phi}_P=X_P^2/(n-p)$ 的近似零分布。利用此结果提出一个针对备择假设 $\\phi>1$ 的过度离散的渐近单侧检验，并解释如何计算其 $p$ 值。\n\n然后，将您的检验应用于以下来自蚊子幼虫数据的拟合模型摘要：捕蚊器数量为 $n=120$，拟合的回归参数数量为 $p=6$，计算出的 Pearson 统计量为 $X_P^2=180$。根据您的推导，在以下选项中确定正确的陈述，该陈述指定了适当的检验统计量、其在等离散下的零分布、正确的自由度以及检验过度离散所得的 $p$ 值。\n\n选择一个选项：\n\nA. 该检验使用 $\\hat{\\phi}_P=X_P^2/(n-p)$，备择假设为单侧的 $\\phi>1$。在等离散条件下，$X_P^2$ 近似服从自由度为 $n-p$ 的 $\\chi^2$ 分布，因此 $\\mathbb{E}(\\hat{\\phi}_P)\\approx 1$ 且 $\\operatorname{Var}(\\hat{\\phi}_P)\\approx 2/(n-p)$。$p$ 值为 $P\\!\\left(\\chi^2_{114}\\ge 180\\right)$，等价于 $P\\!\\left(Z\\ge \\dfrac{180-114}{\\sqrt{2\\cdot 114}}\\right)$，约等于 $6\\times 10^{-6}$。\n\nB. 该检验使用偏差(deviance)除以 $n$，备择假设为双侧的。在等离散条件下，该比率精确服从均值为 $1$、方差为 $1/n$ 的泊松分布，因此对于 $n=120$，$p$ 值约为 $0.05$。\n\nC. 该检验使用 $\\hat{\\phi}_P=X_P^2/n$ 并将其与自由度为 $n-p$ 的学生 $t$ 分布进行比较；对于 $n=120, p=6$，$p$ 值为 $P\\!\\left(t_{114}\\ge 1.58\\right)\\approx 0.06$。\n\nD. 该检验使用 $X_P^2$，备择假设为双侧的，并将其与自由度为 $n$ 的 $\\chi^2$ 分布进行比较；对于 $n=120$ 和 $X_P^2=180$，$p$ 值约为 $0.02$。\n\nE. 该检验使用 $\\hat{\\phi}_P=X_P^2/(n-p)$，并假设在等离散条件下 $\\sqrt{X_P^2/(n-p)}$ 服从标准正态分布；对于 $n=120, p=6$，$p$ 值约为 $0.08$。", "solution": "用户希望我验证问题陈述，如果有效，则为一个关于泊松广义线性模型 (GLM) 中过度离散检验的生物统计学问题推导解决方案。\n\n### 问题验证\n\n**步骤1：提取已知条件**\n\n*   **研究数据**：来自 $n$ 个独立捕蚊器的蚊子幼虫计数 $Y_i$。\n*   **模型**：一个具有泊松响应和 $p$ 个回归参数（包括截距）的对数线性 GLM。\n*   **均值和方差（在零假设下）**：对于每个计数 $Y_i$，模型假设等离散，即 $\\mathbb{E}(Y_i) = \\mu_i$ 且 $\\operatorname{Var}(Y_i) = \\mu_i$。\n*   **估计值**：最大似然拟合提供了估计的均值 $\\hat{\\mu}_i$。\n*   **Pearson 统计量**：$X_P^2 = \\sum_{i=1}^{n}\\frac{(Y_i-\\hat{\\mu}_i)^2}{\\hat{\\mu}_i}$。\n*   **离散度估计**：$\\hat{\\phi}_P = X_P^2$ 除以其自由度。\n*   **任务**：\n    1.  在正确指定的泊松 GLM 下，推导 $X_P^2$ 的大样本零分布。\n    2.  推导 $\\hat{\\phi}_P = X_P^2/(n-p)$ 的近似零分布。\n    3.  提出一个针对过度离散 ($\\phi > 1$) 的渐近单侧检验。\n    4.  将该检验应用于具体案例：$n=120$, $p=6$, $X_P^2=180$。\n*   **问题**：确定关于检验统计量、零分布、自由度和 p 值的正确陈述。\n\n**步骤2：使用提取的已知条件进行验证**\n\n1.  **科学依据**：该问题基于广义线性模型的成熟统计理论，特别是泊松回归和过度离散的诊断。这些是生物统计学和生态学中的标准和关键主题。该问题在科学上是合理的。\n2.  **良态问题(Well-Posed)**：问题定义清晰。它要求推导一个标准的统计检验并将其应用于给定的数据集。所有必要的组成部分都已提供：模型、统计量、零假设（等离散，$\\phi=1$）、备择假设（过度离散，$\\phi > 1$），以及 $n$、$p$ 和 $X_P^2$ 的数值。基于大样本统计理论存在唯一解。\n3.  **客观性**：问题以精确、客观和定量的语言陈述。它没有歧义和主观断言。\n4.  **缺陷清单**：该问题不违反任何列出的无效标准。它在科学上是合理的、可形式化的、完整的、现实的和良态的。\n\n**步骤3：结论和行动**\n\n问题陈述是有效的。我将继续进行推导和求解。\n\n### 推导与求解\n\n该问题要求分析泊松 GLM 中的过度离散检验。当数据中观察到的方差大于模型预测的方差时，就会发生过度离散。对于泊松分布，方差等于均值（$\\operatorname{Var}(Y_i) = \\mathbb{E}(Y_i) = \\mu_i$）。对过度离散建模的一种常用方法是假设 $\\operatorname{Var}(Y_i) = \\phi \\mu_i$，其中 $\\phi$ 是离散参数。等离散的零假设对应于 $H_0: \\phi = 1$，过度离散的备择假设是 $H_A: \\phi > 1$。\n\n**1. Pearson 统计量 $X_P^2$ 的分布**\n\nPearson 统计量由 $X_P^2 = \\sum_{i=1}^{n}\\frac{(Y_i-\\hat{\\mu}_i)^2}{\\hat{\\mu}_i}$ 给出。该统计量衡量观测计数 $Y_i$ 与拟合均值 $\\hat{\\mu}_i$ 之间的平方差，并按拟合均值（即泊松假设下的估计方差）进行缩放。\n\nGLM 理论的一个基本结果指出，对于一个被正确指定并通过最大似然法拟合的模型，在大样本量 $n$ 的情况下，Pearson 统计量 $X_P^2$ 渐近服从卡方 ($\\chi^2$) 分布。\n\n该分布的自由度 ($df$) 是观测数 $n$ 减去估计的回归参数个数 $p$。这是因为估计 $p$ 个参数会对残差 ($Y_i - \\hat{\\mu}_i$) 引入 $p$ 个约束，从而将自由度从 $n$ 减少到 $n-p$。\n\n因此，在零假设 $H_0: \\phi = 1$ 下，Pearson 统计量的大样本分布为：\n$$X_P^2 \\sim \\chi^2_{n-p}$$\n\n**2. 离散度估计 $\\hat{\\phi}_P$ 的分布**\n\n问题将离散度估计 $\\hat{\\phi}_P$ 定义为 Pearson 统计量除以其自由度。根据上文，自由度为 $n-p$。因此，\n$$\\hat{\\phi}_P = \\frac{X_P^2}{n-p}$$\n该量也称为单位自由度的 Pearson 卡方统计量。它可作为离散参数 $\\phi$ 的样本估计。\n\n为了找到 $\\hat{\\phi}_P$ 的近似零分布，我们使用 $\\chi^2$ 分布的性质。对于随机变量 $W \\sim \\chi^2_k$，其期望值为 $\\mathbb{E}(W) = k$，方差为 $\\operatorname{Var}(W) = 2k$。\n\n将此应用于 $X_P^2 \\sim \\chi^2_{n-p}$：\n在 $H_0$ 下 $\\hat{\\phi}_P$ 的期望值为：\n$$\\mathbb{E}(\\hat{\\phi}_P) = \\mathbb{E}\\left(\\frac{X_P^2}{n-p}\\right) = \\frac{1}{n-p}\\mathbb{E}(X_P^2) \\approx \\frac{n-p}{n-p} = 1$$\n在 $H_0$ 下 $\\hat{\\phi}_P$ 的方差为：\n$$\\operatorname{Var}(\\hat{\\phi}_P) = \\operatorname{Var}\\left(\\frac{X_P^2}{n-p}\\right) = \\frac{1}{(n-p)^2}\\operatorname{Var}(X_P^2) \\approx \\frac{2(n-p)}{(n-p)^2} = \\frac{2}{n-p}$$\n在零假设下，我们期望离散度估计 $\\hat{\\phi}_P$ 接近于 $1$。\n\n**3. 过度离散检验**\n\n假设检验为：\n$H_0: \\phi = 1$ (等离散)\n$H_A: \\phi > 1$ (过度离散)\n\n检验是单侧的，因为低度离散 ($\\phi  1$) 在实践中很少见，而过度离散是主要关注点。一个显著大于 $1$ 的 $\\hat{\\phi}_P$ 值提供了反对 $H_0$ 的证据。\n\n该检验可以通过将观测到的 $X_P^2$ 值与其零分布 $\\chi^2_{n-p}$ 进行比较来执行。p 值是在假设零假设为真的情况下，观测到与从数据中计算出的检验统计量一样极端或更极端的检验统计量的概率。\n$$p\\text{值} = P(X \\ge X_P^2_{\\text{obs}}), \\quad \\text{其中 } X \\sim \\chi^2_{n-p}$$\n\n对于大的自由度 $k$，$\\chi^2_k$ 分布可以由正态分布 $N(k, 2k)$ 近似。这允许使用标准正态 ($Z$) 分布来计算 p 值：\n$$Z = \\frac{\\chi^2_k - k}{\\sqrt{2k}} \\sim N(0, 1)$$\n因此，p 值可以近似为：\n$$p\\text{值} \\approx P\\left(Z \\ge \\frac{X_P^2_{\\text{obs}} - (n-p)}{\\sqrt{2(n-p)}}\\right)$$\n\n**4. 应用于数据**\n\n我们已知：\n*   捕蚊器数量, $n = 120$\n*   参数数量, $p = 6$\n*   观测到的 Pearson 统计量, $X_P^2_{\\text{obs}} = 180$\n\n首先，计算自由度：\n$df = n-p = 120 - 6 = 114$\n\n检验统计量为 $X_P^2 = 180$，在 $H_0$ 下，其分布近似为 $\\chi^2_{114}$。离散度估计为 $\\hat{\\phi}_P = \\frac{180}{114} \\approx 1.579$。这个值显著大于 $1$，表明存在过度离散的证据。\n\n为了量化这一证据，我们计算 p 值：\n$$p\\text{值} = P(\\chi^2_{114} \\ge 180)$$\n\n由于自由度 ($df=114$) 很大，我们可以使用正态近似：\n$$Z = \\frac{180 - 114}{\\sqrt{2 \\times 114}} = \\frac{66}{\\sqrt{228}}$$\n$$\\sqrt{228} \\approx 15.0997$$\n$$Z \\approx \\frac{66}{15.0997} \\approx 4.371$$\np 值是标准正态分布右尾的面积：\n$$p\\text{值} \\approx P(Z \\ge 4.371)$$\n这是一个非常小的概率。例如，$P(Z > 3.5) \\approx 0.00023$。4.371 的 Z 分数对应一个极小的 p 值，数量级为 $10^{-6}$。值 $6 \\times 10^{-6}$ 是对此概率的合理近似。\n\n### 逐项分析选项\n\n*   **A. 该检验使用 $\\hat{\\phi}_P=X_P^2/(n-p)$，备择假设为单侧的 $\\phi>1$。在等离散条件下，$X_P^2$ 近似服从自由度为 $n-p$ 的 $\\chi^2$ 分布，因此 $\\mathbb{E}(\\hat{\\phi}_P)\\approx 1$ 且 $\\operatorname{Var}(\\hat{\\phi}_P)\\approx 2/(n-p)$。$p$ 值为 $P\\!\\left(\\chi^2_{114}\\ge 180\\right)$，等价于 $P\\!\\left(Z\\ge \\dfrac{180-114}{\\sqrt{2\\cdot 114}}\\right)$，约等于 $6\\times 10^{-6}$。**\n    该陈述正确地指出了针对过度离散的单侧备择假设。它正确地陈述了在零假设下 $X_P^2 \\sim \\chi^2_{n-p}$。它正确地推导了离散度估计量 $\\hat{\\phi}_P$ 的近似期望和方差。它正确地构建了 p 值的计算，既使用了具有正确自由度（114）的 $\\chi^2$ 分布，也使用了其正态近似。p 值的数值与计算结果一致。此陈述的所有部分都与统计理论一致。\n    **结论：正确。**\n\n*   **B. 该检验使用偏差(deviance)除以 $n$，备择假设为双侧的。在等离散条件下，该比率精确服从均值为 $1$、方差为 $1/n$ 的泊松分布，因此对于 $n=120$，$p$ 值约为 $0.05$。**\n    该陈述在多个方面都是不正确的。首先，离散度的检验统计量不保证服从泊松分布。Pearson 统计量和偏差近似服从 $\\chi^2$ 分布。其次，分母应该是自由度 ($n-p$)，而不是样本量 ($n$)。第三，过度离散的备择假设通常是单侧的 ($\\phi > 1$)，而不是双侧的。第四，“精确服从泊松分布”的说法是错误的。\n    **结论：不正确。**\n\n*   **C. 该检验使用 $\\hat{\\phi}_P=X_P^2/n$ 并将其与自由度为 $n-p$ 的学生 $t$ 分布进行比较；对于 $n=120, p=6$，$p$ 值为 $P\\!\\left(t_{114}\\ge 1.58\\right)\\approx 0.06$。**\n    该陈述不正确。离散度估计量 $\\hat{\\phi}_P$ 的定义中分母是 $n-p$，而不是 $n$。检验统计量的零分布基于 $\\chi^2$ 分布，而不是学生 $t$ 分布。在这种情况下，$t$ 分布与检验整体拟合优度或离散度无关。\n    **结论：不正确。**\n\n*   **D. 该检验使用 $X_P^2$，备择假设为双侧的，并将其与自由度为 $n$ 的 $\\chi^2$ 分布进行比较；对于 $n=120$ 和 $X_P^2=180$，$p$ 值约为 $0.02$。**\n    该陈述不正确。$\\chi^2$ 分布的自由度是 $n-p = 114$，而不是 $n=120$。此外，我们感兴趣的备择假设是单侧的。最后，$P(\\chi^2_{120} > 180)$ 的 p 值约为 $1.8 \\times 10^{-4}$，而不是 $0.02$。\n    **结论：不正确。**\n\n*   **E. 该检验使用 $\\hat{\\phi}_P=X_P^2/(n-p)$，并假设在等离散条件下 $\\sqrt{X_P^2/(n-p)}$ 服从标准正态分布；对于 $n=120, p=6$，$p$ 值约为 $0.08$。**\n    该陈述不正确。离散度估计量 $\\hat{\\phi}_P$ 是一个经过缩放的 $\\chi^2$ 变量，它总是非负的。它的平方根不可能是标准正态的，因为标准正态变量的均值为 $0$ 并且可以取正值和负值。正确的标准化方法是减去均值并除以标准差，如选项 A 的推导中所述，这会得到一个 Z 分数，而不是假设 $\\sqrt{\\hat{\\phi}_P}$ 是一个 Z 分数。\n    **结论：不正确。**", "answer": "$$\\boxed{A}$$", "id": "4960753"}, {"introduction": "在生态学和医学数据中，观测到零值的频率常常远高于标准泊松模型的预测，这种现象被称为“零膨胀”。本练习将介绍零膨胀泊松（ZIP）模型作为一种优雅的解决方案，并指导您推导期望最大化（EM）算法来估计其参数。通过这个高级实践，您将学会处理具有潜在复杂结构的生物数据，并掌握一种功能强大的现代统计估计方法。[@problem_id:4960764]", "problem": "一位生态学家研究宿主种群粪便样本中每个视野下的寄生虫卵的显微镜计数。许多视野显示没有虫卵，这可能是因为一些宿主确实未受感染（结构性零），也可能是因为受感染的宿主由于抽样变异性而在某个视野中偶尔产生零计数（抽样零）。为了反映这种生物学机制，将视野 $i$ 的计数建模为一个零膨胀泊松（ZIP）随机变量：计数有 $p$ 的概率确定性地为 $0$（结构性零），有 $1-p$ 的概率从均值为 $\\lambda0$ 的泊松分布中抽取。假设各个视野的观测是独立同分布的，并将观测计数记为 $\\{y_i\\}_{i=1}^{n}$，其中每个 $y_i \\in \\{0,1,2,\\dots\\}$。令 $\\theta=(p,\\lambda)$ 表示参数向量，其中 $p \\in (0,1)$ 且 $\\lambda \\in (0,\\infty)$。\n\n仅使用混合模型的基本定义、泊松分布的概率质量函数以及期望最大化（EM）算法的一般构造（期望最大化（EM）是一个迭代过程，它在计算给定观测数据和当前参数下完全数据对数似然的条件期望，以及在参数空间上最大化该期望之间交替进行），完成以下任务：\n\n- 推导观测数据似然 $L(\\theta;\\{y_i\\}_{i=1}^{n})$，用 $p$、$\\lambda$ 和 $\\{y_i\\}$ 表示ZIP模型。你的推导必须从独立性假设和混合解释出发，并且必须使用泊松概率质量函数 $\\mathbb{P}(Y=y)=\\exp(-\\lambda)\\lambda^{y}/y!$（对于 $y\\in\\{0,1,2,\\dots\\}$）。\n- 引入一个潜变量指示符 $Z_i \\in \\{0,1\\}$，用于编码 $y_i$ 是源自结构性零部分（$Z_i=1$）还是泊松部分（$Z_i=0$）。写出完全数据对数似然 $\\ln L_{\\mathrm{c}}(\\theta;\\{y_i,Z_i\\}_{i=1}^{n})$，然后通过计算条件期望 $\\mathbb{E}[Z_i \\mid y_i,\\theta^{(t)}]$ 的闭合形式（作为 $y_i$、$p^{(t)}$ 和 $\\lambda^{(t)}$ 的函数），推导EM算法的E步。\n- 通过最大化期望完全数据对数似然（关于 $p$ 和 $\\lambda$，并受限于 $p \\in (0,1)$ 和 $\\lambda0$），推导EM算法的M步对 $p$ 和 $\\lambda$ 的更新。\n- 陈述并证明在何种条件下，观测数据似然 $L(\\theta;\\{y_i\\})$ 能保证在EM迭代过程中单调不减，即 $L(\\theta^{(t+1)};\\{y_i\\}) \\geq L(\\theta^{(t)};\\{y_i\\})$，并将你的论证与E步和M步的性质明确联系起来。\n\n将你的最终答案表示为关于 $p^{(t+1)}$ 和 $\\lambda^{(t+1)}$ 的两个明确的解析更新公式。将这两个表达式一起以单个行矩阵的形式呈现。不需要进行数值计算，参数或计数也没有单位。不要四舍五入；请提供精确的解析表达式。", "solution": "该问题是有效的，因为它在生物统计学上有科学依据，提法恰当，客观，并为推导零膨胀泊松（ZIP）模型的期望最大化（EM）算法提供了一个完整且一致的框架。所有必要的定义和假设都已给出。我现在将进行完整的推导。\n\n问题要求关于零膨胀泊松（ZIP）模型和EM算法的四个主要推导，以及最终的更新方程。\n\n**1. 观测数据似然的推导**\n\nZIP模型指定观测值 $Y_i$ 是一个两阶段过程的结果。首先，一个概率为 $p$ 的试验导致结构性零，概率为 $1-p$ 的试验导致从均值为 $\\lambda$ 的泊松分布中抽样。泊松分布的概率质量函数（PMF）给出为 $\\mathbb{P}(Y=y) = \\frac{\\exp(-\\lambda)\\lambda^{y}}{y!}$，对于 $y \\in \\{0, 1, 2, \\dots\\}$。\n\n让我们推导单个ZIP随机变量 $Y_i$ 的PMF。我们考虑观测计数 $y_i$ 的两种情况：\n\n情况1：$y_i  0$。大于零的观测值只能来自混合模型中的泊松部分。这发生的概率为 $1-p$。给定它来自泊松部分，观测到 $y_i$ 的条件概率是 $\\frac{\\exp(-\\lambda)\\lambda^{y_i}}{y_i!}$。因此，总概率是：\n$$ \\mathbb{P}(Y_i = y_i) = (1-p) \\frac{\\exp(-\\lambda)\\lambda^{y_i}}{y_i!}, \\quad \\text{对于 } y_i \\in \\{1, 2, 3, \\dots\\} $$\n\n情况2：$y_i = 0$。观测值为零可能通过两种互斥的方式产生：\n- 它是结构性零，发生的概率为 $p$。\n- 它是来自泊松部分的抽样零。这发生的概率为 $1-p$，而从泊松($\\lambda$)分布得到零的概率是 $\\mathbb{P}(Y=0) = \\frac{\\exp(-\\lambda)\\lambda^0}{0!} = \\exp(-\\lambda)$。\n观测到零的总概率是这两个事件概率的总和：\n$$ \\mathbb{P}(Y_i = 0) = p + (1-p)\\exp(-\\lambda) $$\n\n我们可以使用指示函数 $I(y_i=0)$（如果 $y_i=0$ 则为 $1$，否则为 $0$）将这两种情况合并为一个表达式。\n$$ \\mathbb{P}(Y_i = y_i; \\theta) = \\left[p + (1-p)\\exp(-\\lambda)\\right]^{I(y_i=0)} \\left[(1-p)\\frac{\\exp(-\\lambda)\\lambda^{y_i}}{y_i!}\\right]^{1-I(y_i=0)} $$\n观测数据似然函数 $L(\\theta; \\{y_i\\}_{i=1}^{n})$ 是在给定参数 $\\theta=(p, \\lambda)$ 的情况下，每个独立观测概率的乘积：\n$$ L(\\theta; \\{y_i\\}_{i=1}^{n}) = \\prod_{i=1}^{n} \\mathbb{P}(Y_i = y_i; \\theta) $$\n令 $n_0$ 为 $y_i=0$ 的观测数量（即 $n_0 = \\sum_{i=1}^n I(y_i=0)$），$n_{0}$ 为 $y_i0$ 的观测数量。通过将乘积分为零计数和非零计数，似然可以写成：\n$$ L(\\theta; \\{y_i\\}_{i=1}^{n}) = \\left(\\prod_{i:y_i=0} [p + (1-p)\\exp(-\\lambda)]\\right) \\left(\\prod_{i:y_i0} \\left[(1-p)\\frac{\\exp(-\\lambda)\\lambda^{y_i}}{y_i!}\\right]\\right) $$\n$$ L(\\theta; \\{y_i\\}_{i=1}^{n}) = [p + (1-p)\\exp(-\\lambda)]^{n_0} \\prod_{i:y_i0} \\left((1-p)\\frac{\\exp(-\\lambda)\\lambda^{y_i}}{y_i!}\\right) $$\n这就是ZIP模型的观测数据似然函数。\n\n**2. 完全数据对数似然和E步推导**\n\nEM算法通过引入潜变量来简化最大化过程。令 $Z_i \\in \\{0, 1\\}$ 为每个观测值 $y_i$ 的潜变量指示符。\n- $Z_i = 1$：$y_i$ 是一个结构性零（来自零膨胀部分）。这发生的先验概率为 $\\mathbb{P}(Z_i=1)=p$。如果 $Z_i=1$，则 $y_i$ 必须为 $0$。\n- $Z_i = 0$：$y_i$ 来自泊松部分。这发生的先验概率为 $\\mathbb{P}(Z_i=0)=1-p$。如果 $Z_i=0$，则 $y_i \\sim \\text{Poisson}(\\lambda)$。\n\n观测 $i$ 的完全数据是 $(y_i, Z_i)$。联合概率质量函数 $p(y_i, z_i; \\theta)$ 是：\n- 如果 $z_i=1$：计数必须为 $0$。$\\mathbb{P}(y_i, Z_i=1) = \\mathbb{P}(y_i|Z_i=1)\\mathbb{P}(Z_i=1) = I(y_i=0) \\cdot p$。\n- 如果 $z_i=0$：计数服从泊松分布。$\\mathbb{P}(y_i, Z_i=0) = \\mathbb{P}(y_i|Z_i=0)\\mathbb{P}(Z_i=0) = \\frac{\\exp(-\\lambda)\\lambda^{y_i}}{y_i!} \\cdot (1-p)$。\n\n整个数据集 $\\{y_i, Z_i\\}_{i=1}^{n}$ 的完全数据似然是：\n$$ L_{\\mathrm{c}}(\\theta; \\{y_i, Z_i\\}) = \\prod_{i=1}^{n} [p \\cdot I(y_i=0)]^{Z_i} \\left[ (1-p)\\frac{\\exp(-\\lambda)\\lambda^{y_i}}{y_i!} \\right]^{1-Z_i} $$\n完全数据对数似然 $\\ln L_{\\mathrm{c}}(\\theta)$ 是：\n$$ \\ln L_{\\mathrm{c}}(\\theta) = \\sum_{i=1}^{n} \\left\\{ Z_i \\ln(p) + Z_i\\ln(I(y_i=0)) + (1-Z_i)\\left[\\ln(1-p) - \\lambda + y_i \\ln(\\lambda) - \\ln(y_i!)\\right] \\right\\} $$\n如果 $y_i=0$，$Z_i\\ln(I(y_i=0))$ 项为 $0$（因为 $\\ln(1)=0$）。如果 $y_i0$，为了使似然不为零，$Z_i$ 必须为 $0$，所以该项实际上也为零。我们可以将依赖于参数的对数似然写为：\n$$ \\ln L_{\\mathrm{c}}(\\theta) \\propto \\sum_{i=1}^{n} \\left\\{ Z_i \\ln(p) + (1-Z_i)\\ln(1-p) + (1-Z_i)[y_i \\ln(\\lambda) - \\lambda] \\right\\} $$\n\n**E步（期望步）：** 在E步中，我们计算完全数据对数似然关于给定观测数据和当前参数估计 $\\theta^{(t)}=(p^{(t)}, \\lambda^{(t)})$ 下潜变量的条件分布的期望。这等价于计算每个 $Z_i$ 的条件期望。令 $w_i^{(t)} = \\mathbb{E}[Z_i \\mid y_i, \\theta^{(t)}]$。\n\n- 如果 $y_i  0$：观测值不可能是结构性零。因此，$Z_i$ 必须为 $0$。\n$$ w_i^{(t)} = \\mathbb{E}[Z_i \\mid y_i  0, \\theta^{(t)}] = \\mathbb{P}(Z_i=1 \\mid y_i0, \\theta^{(t)}) = 0 $$\n- 如果 $y_i = 0$：观测值可能是结构性零（$Z_i=1$）或抽样零（$Z_i=0$）。我们使用贝叶斯定理：\n$$ w_i^{(t)} = \\mathbb{P}(Z_i=1 \\mid y_i=0, \\theta^{(t)}) = \\frac{\\mathbb{P}(y_i=0 \\mid Z_i=1, \\theta^{(t)})\\mathbb{P}(Z_i=1 \\mid \\theta^{(t)})}{\\mathbb{P}(y_i=0 \\mid \\theta^{(t)})} $$\n各分量为：\n- $\\mathbb{P}(y_i=0 \\mid Z_i=1, \\theta^{(t)}) = 1$。\n- $\\mathbb{P}(Z_i=1 \\mid \\theta^{(t)}) = p^{(t)}$。\n- $\\mathbb{P}(y_i=0 \\mid \\theta^{(t)}) = p^{(t)} + (1-p^{(t)})\\exp(-\\lambda^{(t)})$。\n因此，对于 $y_i=0$：\n$$ w_i^{(t)} = \\frac{1 \\cdot p^{(t)}}{p^{(t)} + (1-p^{(t)})\\exp(-\\lambda^{(t)})} $$\n使用指示函数 $I(y_i=0)$ 结合两种情况：\n$$ w_i^{(t)} = \\mathbb{E}[Z_i \\mid y_i, \\theta^{(t)}] = I(y_i=0) \\frac{p^{(t)}}{p^{(t)} + (1-p^{(t)})\\exp(-\\lambda^{(t)})} $$\n期望完全数据对数似然，记为 $Q(\\theta \\mid \\theta^{(t)})$，是：\n$$ Q(\\theta \\mid \\theta^{(t)}) = \\sum_{i=1}^{n} \\left\\{ w_i^{(t)} \\ln(p) + (1-w_i^{(t)})\\ln(1-p) + (1-w_i^{(t)})[y_i \\ln(\\lambda) - \\lambda] \\right\\} + \\text{const.} $$\n\n**3. M步推导**\n\n**M步（最大化步）：** 在M步中，我们找到使 $Q(\\theta \\mid \\theta^{(t)})$ 最大化的参数 $\\theta^{(t+1)}=(p^{(t+1)}, \\lambda^{(t+1)})$。$Q$ 中关于 $p$ 和 $\\lambda$ 的项是分开的，因此我们可以独立地对它们进行最大化。\n\n关于 $p$ 的最大化：\n$$ \\frac{\\partial Q}{\\partial p} = \\sum_{i=1}^n \\left( \\frac{w_i^{(t)}}{p} - \\frac{1-w_i^{(t)}}{1-p} \\right) = 0 $$\n$$ \\frac{1}{p}\\sum_{i=1}^n w_i^{(t)} = \\frac{1}{1-p}\\sum_{i=1}^n (1-w_i^{(t)}) = \\frac{n - \\sum_{i=1}^n w_i^{(t)}}{1-p} $$\n$$ (1-p)\\sum_{i=1}^n w_i^{(t)} = p(n - \\sum_{i=1}^n w_i^{(t)}) $$\n$$ \\sum_{i=1}^n w_i^{(t)} = pn $$\n求解 $p$ 得到更新规则：\n$$ p^{(t+1)} = \\frac{1}{n}\\sum_{i=1}^n w_i^{(t)} $$\n\n关于 $\\lambda$ 的最大化：\n$$ \\frac{\\partial Q}{\\partial \\lambda} = \\sum_{i=1}^n (1-w_i^{(t)})\\left( \\frac{y_i}{\\lambda} - 1 \\right) = 0 $$\n$$ \\frac{1}{\\lambda}\\sum_{i=1}^n (1-w_i^{(t)})y_i = \\sum_{i=1}^n (1-w_i^{(t)}) $$\n求解 $\\lambda$ 得到更新规则：\n$$ \\lambda^{(t+1)} = \\frac{\\sum_{i=1}^n (1-w_i^{(t)})y_i}{\\sum_{i=1}^n (1-w_i^{(t)})} $$\n我们可以简化分子。项 $w_i^{(t)}$ 仅在 $y_i=0$ 时非零。因此，对于所有的 $i$，乘积 $w_i^{(t)}y_i$ 恒为零。\n$$ \\sum_{i=1}^n (1-w_i^{(t)})y_i = \\sum_{i=1}^n y_i - \\sum_{i=1}^n w_i^{(t)}y_i = \\sum_{i=1}^n y_i - 0 = \\sum_{i=1}^n y_i $$\n$\\lambda$ 的更新简化为：\n$$ \\lambda^{(t+1)} = \\frac{\\sum_{i=1}^n y_i}{\\sum_{i=1}^n (1-w_i^{(t)})} $$\n\n**4. 似然单调不减的证明**\n\n观测数据的对数似然为 $\\ln L(\\theta; \\{y_i\\}) = \\ln \\left(\\sum_{\\{Z_i\\}} L_{\\mathrm{c}}(\\theta; \\{y_i, Z_i\\})\\right)$。EM算法的一个基本性质是，观测数据的似然在每次迭代中是不减的，即 $L(\\theta^{(t+1)}; \\{y_i\\}) \\geq L(\\theta^{(t)}; \\{y_i\\})$。\n\n这可以通过考虑对数似然的差来证明：\n$$ \\ln L(\\theta^{(t+1)}) - \\ln L(\\theta^{(t)}) = \\left[ Q(\\theta^{(t+1)} \\mid \\theta^{(t)}) - Q(\\theta^{(t)} \\mid \\theta^{(t)}) \\right] + D_{KL}\\left(p(Z|\\{y_i\\}, \\theta^{(t)}) \\parallel p(Z|\\{y_i\\}, \\theta^{(t+1)})\\right) $$\n其中 $Z = \\{Z_i\\}_{i=1}^n$，而 $D_{KL}$ 是Kullback-Leibler散度。\n\n似然不减的保证依赖于与EM步骤相关的两个关键性质：\n1.  **M步性质**：M步被定义为选择 $\\theta^{(t+1)}$ 来最大化（或至少不减小）$Q$ 函数：\n    $$ \\theta^{(t+1)} = \\arg\\max_{\\theta} Q(\\theta \\mid \\theta^{(t)}) $$\n    根据这个构造，我们保证了 $Q(\\theta^{(t+1)} \\mid \\theta^{(t)}) \\geq Q(\\theta^{(t)} \\mid \\theta^{(t)})$。因此，差分方程中的第一项是非负的。在我们的具体推导中，我们找到了 $Q$ 关于 $p$ 和 $\\lambda$ 的唯一全局最大值，因此这个条件是严格满足的。\n2.  **Kullback-Leibler散度性质**：根据吉布斯不等式，KL散度总是非负的。$D_{KL}(P \\parallel Q) \\geq 0$，当且仅当 $P=Q$ 时等号成立。因此，差分方程中的第二项也是非负的。\n\n由于两项都是非负的，它们的和也是非负的，这意味着 $\\ln L(\\theta^{(t+1)}) \\geq \\ln L(\\theta^{(t)})$。这确保了观测数据的似然在每次EM迭代中单调不减，收敛到似然曲面的一个局部最大值或鞍点。这个保证的条件是正确执行E步（计算条件期望以形成 $Q$）和M步（最大化 $Q$），这两步我们都已解析地完成。\n\n最后，将E步中 $w_i^{(t)}$ 的表达式代入M步的更新规则，得到最终的显式公式。\n$p^{(t+1)}$ 的更新变为：\n$$ p^{(t+1)} = \\frac{1}{n}\\sum_{i=1}^{n} \\left(I(y_i=0) \\frac{p^{(t)}}{p^{(t)} + (1-p^{(t)})\\exp(-\\lambda^{(t)})}\\right) $$\n$\\lambda^{(t+1)}$ 的更新变为：\n$$ \\lambda^{(t+1)} = \\frac{\\sum_{i=1}^{n} y_i}{\\sum_{i=1}^{n} \\left(1 - I(y_i=0) \\frac{p^{(t)}}{p^{(t)} + (1-p^{(t)})\\exp(-\\lambda^{(t)})}\\right)} $$\n这些是问题所要求的最终更新公式。", "answer": "$$ \\boxed{ \\begin{pmatrix} \\frac{1}{n} \\sum_{i=1}^{n} \\left(I(y_i=0) \\frac{p^{(t)}}{p^{(t)} + (1-p^{(t)})\\exp(-\\lambda^{(t)})}\\right),  \\frac{\\sum_{i=1}^{n} y_i}{\\sum_{i=1}^{n} \\left( 1 - I(y_i=0) \\frac{p^{(t)}}{p^{(t)} + (1-p^{(t)})\\exp(-\\lambda^{(t)})} \\right)} \\end{pmatrix} } $$", "id": "4960764"}]}