## 引言
虚拟显微镜和数字病理学正深刻地改变着我们观察、分析和理解组织学与病理学的方式，将传统的玻璃载玻片转变为一个充满无限可能性的数字世界。这场技术革命的核心不仅仅是将图像数字化，更在于解锁隐藏在像素中的海量定量信息，从而克服传统显微镜检查的主观性和局限性。然而，从一张物理切片到一个可信赖的诊断或科学发现，其间的路径充满了复杂的技术挑战和跨学科的精妙融合。本文旨在填补这一知识鸿沟，为读者提供一个从基础原理到前沿应用的全面指南。

本文将通过三个章节，系统地引导您深入数字病理学的世界。在“原理与机制”一章中，我们将解构全玻片成像的完整工作流程，从[光学物理](@entry_id:175533)到[数字采样](@entry_id:140476)理论，再到[数据压缩](@entry_id:137700)和存储策略，揭示一张清晰、可交互的虚拟载玻片是如何诞生的。接着，在“应用与跨学科交叉”一章，我们将探索这些技术如何赋能现代生物医学研究和临床实践，涵盖从精确的细胞计数、复杂的三维组织重建，到人工智能在诊断、预后预测以及[多模态数据](@entry_id:635386)整合中的变革性作用。最后，“动手实践”部分将提供具体的计算问题，帮助您巩固关键概念。

我们这场从物理载玻片到计算洞见的探索之旅，始于理解其最根本的原理与机制。

## 原理与机制

本章旨在深入探讨虚拟显微镜和数字病理学背后的核心科学原理与技术机制。我们将遵循一条从物理到数字，再到分析的逻辑路径，剖析一张玻璃载玻片如何转化为一个可交互、可分析的丰富数据集。我们将从生成高质量图像所需的光学基础开始，探索数字化采集过程中的关键权衡，研究高效存储和导航虚拟载玻片的数据结构，并最终触及驱动现代计算病理学发展的前沿概念。

### 从玻璃载玻片到[数字图像](@entry_id:275277)：全载玻片成像工作流程

全载玻片成像（Whole-Slide Imaging, WSI）的目标是创建一个物理载玻片的忠实数字副本。这个过程远不止是简单地“拍照”；它是一个涉及精密光学、机械控制和计算科学的复杂工作流程。本节将阐明构建这一数字副本所依赖的基础原理。

#### 光学基础：高保真成像的基石

任何[数字图像](@entry_id:275277)的质量都取决于其源头——光学系统所成的像。在明场显微镜中，实现均匀、高对比度的照明是首要任务。**柯勒照明（Köhler illumination）** 是实现这一目标的黄金标准。其核心思想是建立两套独立共轭的光学平面：一套是**视场平面（field planes）**，包括[视场光阑](@entry_id:174952)、样本平面和相机传感器；另一套是**[孔径](@entry_id:172936)平面（aperture planes）**，包括光源、聚光镜[孔径光阑](@entry_id:173170)和物镜后焦面。通过将[视场光阑](@entry_id:174952)精确成像于样本平面，柯勒照明确保了整个[视场](@entry_id:175690)的[照度](@entry_id:166905)均匀。同时，通过将光源成像于物镜后焦面，它确保了样本上的每一点都由相同角度范围的光锥所照明，实现了角度均匀性。这种均匀的背景是准确解读由组织染色产生的对比度的前提。[@problem_id:4948977]

在组织病理学中，对比度主要源于染料对特定波长光的选择性吸收。以标准的苏木精和伊红（H&E）染色为例，其吸收特性遵循**比尔-朗伯定律（Beer–Lambert law）**，即[吸光度](@entry_id:176309) $A$ 与[摩尔吸光系数](@entry_id:148758) $\epsilon$、染料浓度 $c$ 和光程长度 $l$（即组织切片厚度）成正比，即 $A = \epsilon c l$。当光线通过染色组织时，[透射率](@entry_id:168546) $T$ 按指数规律衰减，$T(\lambda) = \exp(-\mu(\lambda)cL)$，其中 $\mu(\lambda)$ 是与波长相关的衰减系数。对于弱吸收情况，这可以近似为线性关系 $T(\lambda) \approx 1-\mu(\lambda)cL$。

最终记录的图像信号，尤其是亮度通道，取决于光源的光谱 $S(\lambda)$、样本的[透射率](@entry_id:168546) $T(\lambda)$ 和相机传感器的光谱响应 $R(\lambda)$ 的乘积积分。$R(\lambda)$ 通常模拟人眼的明视响应（photopic response），其峰值位于绿光区域（约 $555\,\mathrm{nm}$）。伊红的吸收峰（约 $520-530\,\mathrm{nm}$）与此高度重叠，因此在亮度图像中，嗜酸性的细胞质会显得相对较暗。相比之下，苏木精的吸收峰位于黄橙光区（约 $580-600\,\mathrm{nm}$），偏离了亮度响应的峰值。因此，在苏木精染色较弱的情况下，细胞核可能不会产生强烈的对比度，其亮度甚至可能与嗜伊红的细胞质相当或更亮。此外，将聚光镜[孔径光阑](@entry_id:173170)适当关闭（例如，设置为物镜[数值孔径](@entry_id:138876)的 $2/3$）是一种常见的实践，它以牺牲部分分辨率为代价，通过限制照明光锥的角度来增强图像的振幅对比度。[@problem_id:4948977]

除了对比度，图像的细节分辨能力由**[光学分辨率](@entry_id:172575)**决定。其关键参数是**[数值孔径](@entry_id:138876)（Numerical Aperture, NA）**，定义为 $NA = n\sin\theta$，其中 $n$ 是物镜与样本之间介质的折射率，$\theta$ 是[物镜](@entry_id:167334)收集光线的最大半角。NA 决定了[物镜](@entry_id:167334)的集光能力和分辨能力。一个理想的点光源经过衍射限制的光学系统后，其图像不再是一个点，而是一个弥散的[强度分布](@entry_id:163068)，称为**点扩展函数（Point Spread Function, PSF）**。对于圆形光瞳的显微镜，PSF 表现为[艾里斑](@entry_id:167572)（Airy pattern）。PSF 的尺寸表征了系统的模糊程度。根据**[瑞利判据](@entry_id:269526)（Rayleigh criterion）**，两个等强度的点光源恰好能被分辨的最小距离 $d$ 是指一个艾里斑的中心恰好落在另一个艾里斑的第一个暗环处。对于非[相干照明](@entry_id:185438)的显微镜，这个衍射极限分辨率由下式给出：
$$ d_{\mathrm{opt}} \approx \frac{0.61 \lambda}{NA} $$
其中 $\lambda$ 是光的波长。这是光学系统本身能够分辨的最小细节。[@problem_id:4948981, 4948986]

#### 数字化：连接光学与数据的桥梁

光学系统形成的模拟图像必须通过数字传感器（如 CCD 或 [CMOS](@entry_id:178661) 相机）进行采样，才能转化为数字数据。这个过程引入了另一个分辨率的维度——[数字采样](@entry_id:140476)分辨率。相机传感器上的每个像素对应于样本平面的一个微小区域，其尺寸称为**样本平面像素尺寸（pixel size at the specimen plane）**，记为 $s_{\mathrm{spec}}$。它由传感器上的物理像素间距 $p_{\mathrm{sensor}}$ 和系统的总放大倍率 $M_{\mathrm{tot}}$ 决定：
$$ s_{\mathrm{spec}} = \frac{p_{\mathrm{sensor}}}{M_{\mathrm{tot}}} $$
例如，一个像素间距为 $6.5\,\mu\mathrm{m}$ 的相机，在 $20\times$ 放大倍率下，其样本平面像素尺寸为 $s_{\mathrm{spec}} = 6.5\,\mu\mathrm{m} / 20 = 0.325\,\mu\mathrm{m}$。[@problem_id:4948986]

为了无损地捕获光学系统提供的所有细节，[数字采样](@entry_id:140476)必须足够精细。**[奈奎斯特-香农采样定理](@entry_id:262499)（Nyquist-Shannon sampling theorem）** 指出，采样频率必须至少是信号最高频率的两倍，才能避免信息丢失和**混叠（aliasing）**——即高频信息被错误地表示为低频信号。在空间成像中，这意味着采样间隔（$s_{\mathrm{spec}}$）必须小于或等于光学系统所能分辨的最小细节（$d_{\mathrm{opt}}$）的一半。因此，奈奎斯特采样判据为：
$$ s_{\mathrm{spec}} \le \frac{d_{\mathrm{opt}}}{2} $$
一个设计良好的成像系统应该满足这个条件。如果 $s_{\mathrm{spec}} > d_{\mathrm{opt}}/2$，系统就存在**[欠采样](@entry_id:272871)（undersampling）**，最终图像的分辨率将受限于像素尺寸，而不是光学性能，这种情况称为**采样受限（sampling-limited）**。此时，[数字图像](@entry_id:275277)的有效分辨率约为 $2 \times s_{\mathrm{spec}}$。反之，如果满足[奈奎斯特判据](@entry_id:139561)，系统则为**光学受限（optics-limited）**，最终分辨率由 $d_{\mathrm{opt}}$ 决定。[@problem_id:4948986]

更严谨地，我们可以从频域角度理解。一个非相干衍射限制系统的[光学传递函数](@entry_id:172898)（OTF）存在一个截止频率 $f_c$，超过此频率的空间频率信息无法通过该系统。该截止频率为 $f_c = 2 \times NA / \lambda$。[奈奎斯特采样定理](@entry_id:268107)要求采样频率 $f_s = 1/s_{\mathrm{spec}}$ 至少为信号带宽的两倍，但在二维图像中，这意味着每个方向的采样间隔 $p_{\mathrm{spec}}$ 必须满足 $p_{\mathrm{spec}} \le 1/(2f_c)$。将 $f_c$ 代入，我们得到 $p_{\mathrm{spec}} \le \lambda/(4 \times NA)$。以一个 $NA=0.75$，波长 $\lambda=550\,\mathrm{nm}$ 的系统为例，其[光学分辨率](@entry_id:172575) $d_{\mathrm{opt}} \approx 0.45\,\mu\mathrm{m}$，OTF 截止频率 $f_c \approx 2.73\,\mathrm{cycles}/\mu\mathrm{m}$。奈奎斯特采样要求像素尺寸 $p_{\mathrm{spec}} \le 1/(2f_c) \approx 0.18\,\mu\mathrm{m}$。若一个系统实际的像素尺寸为 $0.1625\,\mu\mathrm{m}$，由于 $0.1625\,\mu\mathrm{m}  0.18\,\mu\mathrm{m}$，该系统满足[奈奎斯特判据](@entry_id:139561)，为光学受限。[@problem_id:4948981]

#### 采集过程：拼接数字马赛克

由于显微镜的[视场](@entry_id:175690)远小于整个载玻片，WSI 系统采用**基于图块的扫描（tile-based scanning）** 方法。电动载物台载着载玻片在物镜下移动，顺序采集一个图块网格。为了后续的拼接，相邻图块之间会设置一个**重叠（overlap）**区域。**拼接（stitching）**算法利用这个重叠区域中的共同特征来估计和校正每个图块的几何位置，最终将所有图块融合成一幅无缝的虚拟载玻片。[@problem_id:4948952]

然而，这个机械和光学的组合过程会引入特有的伪影。
- **视差伪影（Parallax artifacts）**：当物镜不是理想的远心（telecentric）光学系统时，物体的表观横向位置会随其深度（$z$ 轴位置）而改变。由于组织切片具有三维结构（例如，细胞核位于不同深度），当从两个相邻的视点（即采集两个相邻图块时物镜的位置）观察时，不同深度的物体会产生不同的相对位移。拼接算法通常假设一个二维平面，因此无法同时完美对齐所有深度的特征，导致在图块接缝处出现重影或结构不连续。[@problem_id:4948952]
- **载物台[背隙](@entry_id:270611)伪影（Stage backlash artifacts）**：机械传动系统存在**[背隙](@entry_id:270611)（backlash）**，即在改变运动方向时产生的滞后。当扫描采用“蛇形”路径（即一行向右，下一行向左）时，每次 $x$ 轴方向反转，[背隙](@entry_id:270611)都会导致该行所有图块的起始位置产生一个系统性的偏移。这会在行与行之间造成周期性的垂直错位伪影，即使有足够的重叠也难以完全消除。[@problem_id:4948952]

除了扫描过程引入的数字伪影，切片制备过程中的物理缺陷也会在虚拟载玻片中留下[数字签名](@entry_id:269311)。常见的**制片伪影**包括：
- **震颤纹（Chatter）**：由切片刀或组织块在切片过程中的高频振动引起，导致切片厚度产生周期性变化。根据比尔-朗伯定律，厚度变化直接转化为吸光度变化，在 WSI 中表现为与切片方向垂直的、明暗交替的平行条带。[@problem_id:4949022]
- **皱褶（Folds）**：组织切片在漂浮或贴片过程中自身重叠形成的区域。在皱褶处，光程长度 $l$ 加倍，导致吸光度显著增加，颜色变深。由于 WSI 通常采用单焦平面扫描，无法同时对焦于两个不同深度的组织层面，因此皱褶区域常伴有部分模糊。[@problem_id:4949022]
- **刀痕（Knife marks）**：由切片刀刀刃上的微小缺口或污染物造成。它会在组织上划出与切片方向平行的、直的、[非周期性](@entry_id:275873)的线状缺陷，主要表现为[组织结构](@entry_id:146183)的几何错位或断裂，而非系统性的颜色或焦点变化。[@problem_id:4949022]

### 数字载玻片：结构、存储与导航

一旦采集完成，海量的图块数据必须被组织成一种高效的格式，以便于存储、传输和交互式查看。

#### 虚拟载玻片的结构：金字塔式瓦片格式

一个典型的 WSI 原始数据可达数十亿像素，若存为单个巨幅图像，将完全不适用于网络传输和实时交互。解决方案是采用**金字塔式瓦片文件格式（pyramidal, tiled file format）**。这种结构有两个关键特征：
- **金字塔（Pyramid）**：图像被预先计算并存储为多个分辨率层次。塔基是最高分辨率的[原始图](@entry_id:262918)像（Level 0），其上各层是逐级**[下采样](@entry_id:265757)（downsampling）**生成的低分辨率版本。为避免[下采样](@entry_id:265757)过程中产生混叠伪影，正确的做法是在抽取像素前，先对高分辨率图像进行**低通滤波**，以满足[奈奎斯特-香农采样定理](@entry_id:262499)。[@problem_id:4948990]
- **瓦片/图块（Tiles）**：在金字塔的每一层，图像都被分割成大小规整的小块（如 $512 \times 512$ 像素）。这样，浏览器只需按需请求和加载当前视窗内可见的图块，极大地节省了内存和带宽。[@problem_id:4948990]

常见的 WSI 文件格式包括一些厂商特有的格式（如 Aperio 的 SVS，Hamamatsu 的 NDPI），它们本质上是 TIFF 格式的变体，内嵌了多分辨率金字塔。此外，开放的 **OME-TIFF** 格式提供了一个标准化的、富含元数据的框架，同样支持金字塔结构，具有更好的[互操作性](@entry_id:750761)。[@problem_id:4948990]

#### 高效导航与查看

金字塔结构是实现流畅缩放和平移的关键。当用户进行缩放操作时，WSI 查看器会智能地选择金字塔中像素尺寸 $p_L$ 与当前屏幕显示所需有效像素尺寸 $p_d$ 最接近的层级。这样，实时图像插值的[比例因子](@entry_id:266678)接近 1，从而最大限度地减少了计算负担和重采样伪影。[@problem_id:4948990]

在**远程病理学（telepathology）**——即通过电信网络进行远程诊断——的场景下，虚拟显微镜的**导航人机工程学（navigation ergonomics）**变得至关重要。诊断效率，即单位时间内检查的组织面积，直接受到系统性能和用户交互模式的影响。我们可以建立一个简单的模型来分析这个问题。处理单个视窗（图块）的总时间 $T_{\mathrm{cycle}}$ 是平移到该视窗的时间和检查该视窗的时间之和。平移时间包括用户的运动时间 $T_{\mathrm{move}}$ 和系统的响应延迟，主要是**[网络延迟](@entry_id:752433)（L）**。检查时间为认知[停留时间](@entry_id:263953) $t_d$。因此，$T_{\mathrm{cycle}} = T_{\mathrm{move}} + L + t_d$。单位时间内检查的面积 $R_{\mathrm{area}}$ 为：
$$ R_{\mathrm{area}} = \frac{F}{T_{\mathrm{cycle}}} = \frac{F}{T_{\mathrm{move}} + L + t_d} $$
其中 $F$ 是单个视窗覆盖的物理面积。从这个模型可以清楚地看出，增加[网络延迟](@entry_id:752433) $L$ 或减小视窗面积 $F$ 都会显著降低单位时间内的扫视面积，从而降低发现病变特征的预期速率。面对高延迟，用户的[最优策略](@entry_id:138495)是减少平[移频](@entry_id:266447)率以摊销每次平移的时间成本，例如采用更长的[停留时间](@entry_id:263953)或更有条理的条带式扫描，而非频繁的、小范围的快速平移。[@problem_id:4948976]

#### 存储数据：压缩

WSI 的巨大文件体积使其存储和传输成本高昂，因此[图像压缩](@entry_id:156609)是必不可少的。压缩算法分为两类：
- **[无损压缩](@entry_id:271202)（Lossless compression）**：允许从压缩数据中完美地、逐字节地重建[原始图](@entry_id:262918)像。它通过识别并消除数据的统计冗余来实现压缩，不丢弃任何信息。因此，[无损压缩](@entry_id:271202)能完全保留图像中直至奈奎斯特极限的所有高频细节。
- **[有损压缩](@entry_id:267247)（Lossy compression）**：为了获得更高的压缩率，不可逆地丢弃部分信息。这是 WSI 中最常用的压缩方式。

主流的[有损压缩](@entry_id:267247)标准如 **JPEG** 和 **JPEG 2000** 都采用变换编码的原理。它们先将图像数据从空间域变换到频率域或尺度域，然后对变换后的系数进行**量化（quantization）**——这是信息丢失的关键步骤。通常，代表人眼不敏感的高频细节（如精细的染色质纹理、锐利的细胞核边缘）的系数会被更粗略地量化，甚至直接置零。不同的变换方法导致了不同的伪影特征：
- **JPEG**：基于 $8 \times 8$ 像素块的[离散余弦变换](@entry_id:748496)（DCT），其典型的伪影是在高压缩率下出现的**块效应（blocking artifacts）**，即图块边界变得可见。
- **JPEG 2000**：基于[小波变换](@entry_id:177196)（DWT），它避免了块效应，但在高压缩率下可能产生**[振铃效应](@entry_id:147177)（ringing artifacts）**（在锐利边缘附近的微弱波纹）和更普遍的模糊。[@problem_id:4948969]

### 从像素到预测：计算病理学基础

数字病理学不仅改变了图像的查看方式，更催生了计算病理学——利用计算机算法从图像中提取定量信息并辅助诊断决策。

#### 表观归一化：颜色去卷积与标准化

来自不同实验室、不同批次染色或不同扫描仪的 WSI 图像常常存在显著的颜[色差](@entry_id:174838)异，这严重影响了人类观察的一致性和[机器学习模型](@entry_id:262335)的泛化能力。为了解决这个问题，需要进行颜色归一化。基于[比尔-朗伯定律](@entry_id:192870)，颜色分析和校正的最佳空间是**[光密度](@entry_id:189768)（Optical Density, OD）空间**，其定义为 $ \mathbf{o}=-\log_{10}(\mathbf{i}/\mathbf{i}_{0}) $，其中 $\mathbf{i}$ 是测量的像素 RGB 强度，$\mathbf{i}_{0}$ 是背景白光的强度。在 OD 空间中，不同染料的吸光度是线性叠加的。

**颜色去卷积（color deconvolution）** 是一种基于该物理模型的归一化方法。它将一个像素的 OD 向量 $\mathbf{o}$ 建模为染料 OD 向量（构成**染料矩阵 M**）和染料浓度向量 $\mathbf{c}$ 的[线性组合](@entry_id:155091)：$\mathbf{o} = M\mathbf{c}$。通过求解这个方程，可以分离出每种染料的浓度图，然后使用一个标准化的染料矩阵重新合成图像。学术界提出了多种颜色归一化方法，它们在如何估计染料矩阵和处理颜色变化上做出了不同的假设：
- **Reinhard 方法**：一种纯统计方法，它不依赖于物理模型。它将图像转换到 CIE $L^{*}a^{*}b^{*}$ 颜色空间，然后通过匹配源图像和目标图像在该空间各通道的均值和标准差来实现颜色迁移。它假设颜色变化可以被全局颜色统计充分描述。
- **Macenko 方法**：一种基于物理模型的自适应方法。它在 OD 空间中，利用奇异值分解（SVD）找到数据方差最大的平面，并假设染料向量就位于该平面内数据分布的极端角度方向。它为每张图像估计一个特定的染料矩阵，不强制要求染料向量正交。
- **Vahadane 方法**：同样是一种基于物理模型的自适应方法。它使用稀疏**[非负矩阵分解](@entry_id:635553)（Non-negative Matrix Factorization, NMF）**来估计染料矩阵和浓度。这种方法加入了物理上合理的约束：染料的吸光度和浓度都必须是非负的，并且假设在单个像素点，染料浓度是稀疏的（即通常只由少数几种染料构成）。[@problem_id:4949016]

#### 泛化挑战：域偏移

当将在一个数据集（或“域”）上训练的机器学习模型应用到另一个来源不同的数据集时，其性能往往会下降。这种现象称为**域偏移（domain shift）**，即训练数据和测试数据的[联合概率分布](@entry_id:171550)不一致，$p_{\text{train}}(x,y) \neq p_{\text{test}}(x,y)$。在数字病理学中，域偏移是普遍存在的。它可以细分为几种类型：
- **[协变量偏移](@entry_id:636196)（Covariate Shift）**：输入特征的分布发生变化，但特征与标签之间的关系保持不变。即 $p(x)$ 改变，而 $p(y|x)$ 不变。这在数字病理学中非常常见，例如，不同医院使用不同的扫描仪或染色方案，导致图像的颜色和纹理统计（$x$）发生变化，但诊断标准（$y|x$）是统一的。[@problem_id:4949007]
- **标签偏移（Label Shift）**：标签的[边际分布](@entry_id:264862)发生变化，但给定标签下特征的条件分布保持不变。即 $p(y)$ 改变，而 $p(x|y)$ 不变。例如，两个地点的患者人群不同，导致某种疾病的患病率（$y$ 的分布）不同，但相同疾病等级的组织形态学表现（$x|y$）是相似的。[@problem_id:4949007]
- **概念偏移（Concept Shift）**：特征与标签之间的映射关系本身发生了变化。即 $p(y|x)$ 改变。例如，病理学界更新了肿瘤分级的诊断标准，导致对于完全相同的组织形态（$x$），在不同时间或不同指南下会被赋予不同的病理分级（$y$）。[@problem_id:4949007]

#### 构建可信赖模型：[量化不确定性](@entry_id:272064)

一个理想的 AI 诊断模型不仅应给出预测结果，还应提供其预测的[置信度](@entry_id:267904)。模型预测的不确定性可以分解为两种类型：
- **[偶然不确定性](@entry_id:154011)（Aleatoric Uncertainty）**：也称数据不确定性，是数据生成过程中固有的、不可约减的随机性或模糊性。即使拥有无限的训练数据，这种不确定性依然存在。在组织病理学中，它的来源包括扫描仪噪声、染色不均，以及某些病变本身就存在的、连病理专家也难以明确分类的模糊形态。[@problem_id:4949006]
- **[认知不确定性](@entry_id:149866)（Epistemic Uncertainty）**：也称[模型不确定性](@entry_id:265539)，源于我们对模型参数知识（knowledge）的不足，通常是由于训练数据有限或不具代表性。当模型遇到与训练数据差异很大的输入（即分布外样本）或训练数据稀疏的区域时，认知不确定性会很高。与[偶然不确定性](@entry_id:154011)不同，认知不确定性可以通过增加训练数据的数量和多样性来降低。[@problem_id:4949006]

在深度学习中，精确计算[认知不确定性](@entry_id:149866)（需要对模型参数的后验分布进行积分）通常是困难的。**蒙特卡洛 Dropout（[Monte Carlo Dropout](@entry_id:636300), MC Dropout）** 提供了一种实用的近似方法。其核心思想是在**模型推理（测试）时**保持 Dropout 激活，对同一个输入样本进行多次（例如 $T$ 次）随机前向传播。每一次[前向传播](@entry_id:193086)由于随机失活的神经元不同，相当于从模型参数的后验分布中进行了一次近似采样。这样，我们会得到一个预测结果的分布 $\\{p_t(y | x)\\}_{t=1}^{T}$。这个分布的**离散程度**（例如，方差或熵）就反映了模型对该输入预测的[认知不确定性](@entry_id:149866)。高方差意味着模型对这个预测“不确定”，这对于识别模型可能出错的案例至关重要。[@problem_id:4949006]