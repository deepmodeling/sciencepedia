## 引言
随着大数据和机器学习的兴起，预测分析正在深刻改变医疗健康领域，为个性化治疗和精准公共卫生带来了前所未有的机遇。然而，这些强大的算法工具也带来了一个严峻的挑战：如果设计和使用不当，它们可能会无意中学习并固化现实世界中已存在的社会偏见，从而加剧健康不平等，而非缓解。因此，确保算法的公平性已成为构建可信赖医疗AI系统的核心议题。本文旨在为理解和应对这一挑战提供一个系统性的框架。我们将从第一章**“原理与机制”**开始，深入探讨[预测建模](@entry_id:166398)的流程、数据中偏见的各种来源、超越传统准确率的模型评估方法，以及形式化定义和评估公平性的多种标准。随后，在第二章**“应用与跨学科连接”**中，我们将理论付诸实践，通过案例分析探讨算法在临床决策、资源分配中的实际应用，并揭示其与伦理、法律和社会科学的复杂交叉。最后，在第三章**“动手实践”**中，您将通过具体问题演练，将所学知识应用于解决模拟的公平性挑战，从而巩固核心概念。通过这一结构化的学习路径，读者将能够全面掌握预测分析与算法公平性的关键知识，为在实践中负责任地开发和部署医疗AI技术奠定坚实基础。

## 原理与机制

### 从数据到预测：建模流程

在医疗健康领域应用预测分析，其起点并非算法本身，而在于对临床问题的精确定义以及对数据生成过程的深刻理解。一个成功的预测模型，必须建立在坚实的统计学和临床基础之上。

#### 定义预测任务

构建任何预测模型的第一步，是精确地定义其预测目标（outcome target）。这个目标必须是一个具有明确临床意义的事件，而非一个模糊或代理性的过程指标。一个定义不清的目标变量，将导致模型从根本上偏离其预设的临床应用场景。

以一个在医疗系统中常见的任务为例：构建一个二元分类器，用于在患者出院时，预测其在未来$30$天内是否会发生非计划性再入院。为了使模型具有临床实用性，我们必须对“非计划性再入院”这一事件进行严格界定。首先，它必须是一次入住急性护理医院的事件，且为“非计划性”，这意味着需要排除那些预先安排好的选择性手术或治疗。其次，必须将其与其他类型的医疗服务利用区分开来。例如，门诊复查、远程医疗咨询、未转化为住院的急诊就诊，以及在观察室停留但未被编码或计费为正式住院的情况，都不应被计为目标事件。将这些不同性质的事件混为一谈，会使预测目标变得模糊，模型将预测的是宽泛的“医疗利用”，而非特指的、作为医疗质量和安全关键指标的“非计划性再入院”。

此外，还必须警惕使用**过程代理（process proxies）**作为目标。例如，我们可能会发现，出院后按时复诊的患者，其再入院率较低。因此，可能会有人提议直接预测“患者是否会在$30$天内参加预定的复诊”。尽管这种做法在数据提取上可能更为便捷，但它犯了一个根本性错误。复诊参与度是一个反映医疗服务可及性、患者依从性等过程的指标，而非临床结局本身。一个预测复诊参与度的模型，并不能等同于一个预测临床不良事件的模型 [@problem_id:4390071]。

#### 数据生成过程及其假设

在定义了清晰的预测目标后，下一步是理解我们从中提取[特征和](@entry_id:189446)标签的电子健康记录（EHR）数据。在[统计学习](@entry_id:269475)中，一个普遍且基础的假设是样本数据是**[独立同分布](@entry_id:169067)（Independent and Identically Distributed, IID）**的。这意味着每个数据样本$(X_i, Y_i)$（其中$X_i$是特征，$Y_i$是结局）都是从同一个固定的概率分布$P(X, Y)$中独立抽取的。

然而，原始的EHR数据很少直接满足IID假设。为了合理地应用依赖此假设的[机器学习算法](@entry_id:751585)，我们必须明确阐述我们对数据生成过程所做的假设，并采取相应的数据处理步骤。

-   **独立性（Independence）**：EHR数据本质上是以患者为中心的纵向记录。同一个患者在不同时间点可能会有多次出院记录，这些记录显然不是相互独立的，因为它们共享该患者固有的健康状况和行为模式。为了近似满足独立性，一种常见的策略是在研究期间为每位患者只选取一次（例如，第一次）符合条件的出院记录作为样本。或者，可以使用更复杂的[统计模型](@entry_id:755400)（如混合效应模型）来直接对患者内的相关性进行建模。简单地将每一次出院都视为一个独立样本，会严重违反独立性假设，导致模型对其性能的估计过于乐观（例如，低估了[预测误差](@entry_id:753692)的方差）。

-   **同分布性（Identically Distributed）**：该假设要求所有样本来自同一个联合分布$P(X, Y)$。在实践中，这意味着数据的底层生成机制在研究期间是**平稳的（stationary）**。如果医院的临床实践、记录方式或患者群体在数年间发生了显著变化，那么早期和晚期的数据可能就不再是同分布的。因此，我们需要假设特征的定义和结局的判定规则在整个研究期间和所有参与的医疗中心都是一致的。

-   **结局的完整可及性（Complete Outcome Ascertainment）**：预测模型的标签$Y_i$必须被准确无误地观察到。在预测$30$天再入院的任务中，一个核心挑战是患者可能会在原始医疗系统之外的医院再入院。如果我们的数据仅限于系统内部，那么对于那些在别处就医的患者，他们的结局将被错误地标记为“未再入院”（$Y_i=0$）。这种**信息性失访（informative loss to follow-up）**会引入严重的偏倚，因为去系统外就医的行为本身可能与患者的健康状况、社会经济地位等因素相关。一个严谨的研究设计需要通过跨机构的数据链接（如通过健康信息交换网络）来确保对结局的完整捕捉 [@problem_id:4390071]。

### 医疗健康数据中的偏倚来源

算法的公正性问题，其根源往往不在于算法本身，而在于训练算法的数据。医疗场景中的数据，由于其复杂的生成过程，天然地蕴含着多种系统性偏倚。理解这些偏倚的类型和机制，是构建和评估公平预测模型的先决条件。我们将偏倚正式定义为估计量与其目标之间的系统性偏差，即$\text{Bias}(\hat{\theta}) = \mathbb{E}[\hat{\theta}] - \theta$。

#### 测量偏倚 (Measurement Bias)

**测量偏倚**指的是观测到的协变量$\tilde{X}$与真实协变量$X$之间存在系统性误差，且这种误差可能依赖于患者的受保护属性$A$。形式上，这意味着$\mathbb{E}[\tilde{X}\mid X, A] \neq X$。

一个在临床中广为人知的例子是脉搏血氧饱和度仪。大量研究证实，对于肤色较深的患者，[脉搏血氧仪](@entry_id:202030)倾向于高估其真实的动脉血氧饱和度。在这里，$A$代表患者的肤色，$X$是真实的血氧饱和度，而$\tilde{X}$是仪器读数。这种差异性的测量误差，即$\mathbb{E}[\tilde{X}\mid X, A=\text{肤色较深}] > X$，会导致模型在训练时学习到一个有偏的关系，可能因此低估肤色较深患者发生低氧血症的真实风险，从而延迟必要的临床干预 [@problem_id:4390064]。与此相对，随机的、均值为零的测量噪声主要影响模型的精度（增加方差），而非系统性地偏向某个方向。

#### 样本选择偏倚 (Sample Selection Bias)

当用于训练模型的数据集不是目标应用人群的[代表性样本](@entry_id:201715)时，就会出现**样本选择偏倚**。这种情况发生在样本的入选机制（用指示变量$S$表示）与模型变量（如特征$X$、结局$Y$或受保护属性$A$）相关时。形式上，这意味着训练数据的分布$P(X, A, Y\mid S=1)$与目标总体的分布$P(X, A, Y)$不一致。

例如，一个预测模型如果只在过去一年中有过住院记录的患者（$S=1$）身上进行训练，那么它将排除那些因各种原因（如交通不便、缺乏保险、倾向于使用其他医疗系统）而无法获得住院服务的个体。这些被排除的个体在[人口统计学](@entry_id:143605)特征、健康状况和疾病结局上可能与被纳入的群体有系统性差异。因此，基于这个有偏样本训练出的模型，其性能和公平性在推广到整个社区人群时是存疑的 [@problem_id:4390064]。

#### 标签偏倚 (Label Bias)

**标签偏倚**指的是我们用于训练和评估模型的观测标签$\tilde{Y}$与真实的临床结局$Y$之间存在系统性误差，并且这种误差在不同群体间存在差异。形式上，这意味着给定真实结局$Y$，获得观测标签$\tilde{Y}$的概率依赖于受保护属性$A$，即$P(\tilde{Y}\mid Y, A) \neq P(\tilde{Y}\mid Y)$。

以脓毒症（Sepsis）的预测为例。在回顾性研究中，真实的脓毒症发作（$Y$）难以精确判断。研究者通常会使用一些代理定义，例如，将国际疾病分类（ICD）编码中存在脓毒症诊断，并且在相应时间段内有抗生素使用记录，定义为观测标签$\tilde{Y}=1$。然而，这种标签的生成过程本身就可能存在偏倚。不同医院的编码实践可能不同；不同背景的临床医生在面对症状相似的患者时，开具抗生素的阈值也可能不同。如果这些实践和阈值与患者的种族或社会经济地位（$A$）相关，那么即使在真实脓毒症发病率相同的两个群体中，他们被贴上“脓毒症”标签的概率也可能不同。这将导致偏倚被直接编码进模型的训练目标中 [@problem_id:4390064]。

#### 混杂偏倚 (Confounding)

在流行病学和因果推断中，**混杂**是一个经典问题。当一个第三变量$C$（混杂因素）同时影响了我们关心的“暴露”（或特征$X$）和“结局”$Y$时，就会在$X$和$Y$之间产生虚假的关联。在评估算法关于某个受保护属性$A$的公平性时，我们常常将$A$视为一种“暴露”。

例如，在研究种族（$A$）与阿片类药物处方（$Y$）之间的关联时，疼痛的严重程度（$C$）是一个潜在的混杂因素。一方面，疼痛严重程度直接影响医生的处方决策（$C \rightarrow Y$）。另一方面，疼痛严重程度的分布、患者对疼痛的表达方式、或医生对患者疼痛主诉的解读，都可能与患者的种族背景相关（$A \leftarrow C$或$A \rightarrow C$）。如果在分析中不控制疼痛严重程度这个混杂因素，我们观察到的种族与阿片类药物处方之间的任何关联都可能是虚假的或被扭曲的，这会严重误导我们对是否存在处方偏倚的判断 [@problem_id:4390064]。

### 评估预测模型：超越基础准确率

一个预测模型构建完成后，必须经过严格的评估才能投入临床使用。评估不能仅仅停留在简单的准确率上，而需要从多个维度深入考察模型的性能，特别是其排序能力和概率预测的可靠性。

#### 评估的核心支柱：区分度与校准度

模型评估有两个相互独立但同等重要的核心概念：**区分度（Discrimination）**和**校准度（Calibration）**。

**区分度**指的是模型将真正会发生事件的个体（cases, $Y=1$）与不会发生事件的个体（controls, $Y=0$）区分开来的能力。它关心的是“排序”的正确性：模型是否能给高风险的个体赋予比低风险个体更高的风险评分。区分度最常用的衡量指标是**[受试者工作特征曲线下面积](@entry_id:636693)（Area Under the Receiver Operating Characteristic curve, AUC）**。AUC有一个直观的概率解释：它等于从$Y=1$的群体中随机抽取一个个体，其风险评分高于从$Y=0$的群体中随机抽取的另一个个体的风险评分的概率（评分相同时贡献$0.5$的概率）。一个AUC为$1.0$的模型是完美的区分器，而AUC为$0.5$的模型则与随机猜测无异。

**校准度**指的是模型预测的概率与真实观测到的事件频率之间的一致性。它关心的是概率的“绝对值”是否可信。如果一个模型是完美校准的，那么在我们收集到的所有被预测风险为$p$的个体中，应该有接近$p$比例的个体最终真正发生了事件。例如，在一组被模型预测有$70\%$死亡风险的患者中，我们期望实际的死亡率也接近$70\%$。

区分度和校准度是两个不同的维度，一个模型可以在一个维度上表现优异，而在另一个维度上表现糟糕。思考一个用于预测$30$天再入院风险的场景，我们对比两个模型，模型D和模型C。假设有一组包含$5$个再入院患者（$Y=1$）和$7$个未再入院患者（$Y=0$）的数据 [@problem_id:4390055]。

-   **模型D** 为所有$Y=1$的患者给出的风险评分都高于所有$Y=0$的患者（例如，前者的评分范围是$[0.70, 0.92]$，后者的范围是$[0.45, 0.65]$）。这使得模型D的AUC为$1.0$，具有完美的区分度。然而，它给出的平均预测概率为$0.675$，而样本中的真实再入院率仅为$5/12 \approx 0.417$。这表明模型D系统性地高估了风险，其校准度很差。

-   **模型C** 给出的风险评分则存在一些重叠，其AUC计算出来可能只有$0.67$左右，区分度较弱。但是，它给出的平均预测概率为$0.453$，与真实再入院率$0.417$非常接近，表明其“宏观”校准度更好。

在临床决策中，两者缺一不可。如果我们只关心对患者进行风险排序以优先分配有限的干预资源，那么高区分度（高AUC）至关重要。但如果我们的决策依赖于一个具体的风险阈值（例如，对所有预测风险超过$60\%$的患者进行干预），那么校准度就变得至关重要。一个像模型D这样未校准的模型，其$60\%$的风险阈值在现实中可能对应着完全不同的真实风险水平，这使得决策变得武断，也无法用于可靠的资源规划。一个公平的模型必须保证其风险评分对于来自不同群体的患者都具有相同的含义，而这正是校准度所要确保的 [@problem_id:4390055]。

#### 量化校准误差

为了更精确地评估模型的校准度，我们可以使用一些量化指标。这些指标通常基于比较预测概率和观测频率。

一个基础且重要的指标是**布里尔分数（Brier Score）**。它被定义为预测概率$p_i$与实际结局$y_i$（编码为0或1）之间均方误差：
$$ BS = \frac{1}{N} \sum_{i=1}^{N} (p_i - y_i)^2 $$
布里尔分数是一个**固有评分规则（proper scoring rule）**，这意味着一个模型为了最小化布里尔分数，其最优策略是报告其对事件发生的真实信念。这个分数同时捕捉了模型的校准度和区分度。一个完美模型（既完美校准又完美区分）的布里尔分数为$0$。

为了专门评估校准度，我们可以采用[分箱](@entry_id:264748)（binning）的方法。我们将预测概率的$[0,1]$[区间划分](@entry_id:264619)为$M$个不相交的箱（bins），例如$[0, 0.2), [0.2, 0.4), \dots$。对于每个箱$B_m$，我们计算：
-   箱内样本的平均预测概率（或称置信度, confidence）：$\text{conf}(B_m) = \frac{1}{n_m} \sum_{i \in B_m} p_i$，其中$n_m$是箱$m$中的样本数。
-   箱内样本的真实事件发生率（或称准确率, accuracy）：$\text{acc}(B_m) = \frac{1}{n_m} \sum_{i \in B_m} y_i$。

基于此，可以定义两个常用的校准[误差指标](@entry_id:173250)：

-   **期望校准误差（Expected Calibration Error, ECE）**：它是每个箱中[置信度](@entry_id:267904)与准确率之差的绝对值的加权平均，权重为每个箱的样本比例。
    $$ \text{ECE} = \sum_{m=1}^{M} \frac{n_m}{N} |\text{acc}(B_m) - \text{conf}(B_m)| $$
    ECE衡量的是模型在所有风险区间的平均校准偏离程度。

-   **最大校准误差（Maximum Calibration Error, MCE）**：它是所有箱中[置信度](@entry_id:267904)与准确率之差的绝对值的最大值。
    $$ \text{MCE} = \max_{m} |\text{acc}(B_m) - \text{conf}(B_m)| $$
    MCE衡量的是模型在“最不准”的那个风险区间的校准偏离程度，反映了最坏情况下的误差。

假设一个死亡风险模型对$12$名患者进行了预测，我们将其分为三个风险箱：$[0,0.2)$, $[0.2,0.5)$, $[0.5,1]$。通过计算每个箱内的平均预测概率和实际死亡率，我们可以得到每个箱的校准误差。例如，对于第一个箱$[0,0.2)$，若平均预测概率为$0.11$，而实际死亡率为$1/3 \approx 0.333$，则该箱的校准误差为$|0.333-0.11| \approx 0.223$。ECE将是所有箱误差的加权平均，而MCE将是所有箱误差中的最大值。这些指标的计算结果依赖于[分箱](@entry_id:264748)策略，但它们为我们提供了比单一布里尔分数更具解释性的关于校准度的洞见。在进行公平性审计时，即使一个模型的总体ECE或布里尔分数看起来不错，我们也必须检查它在不同受保护亚组内的校准度，因为一个模型可能在一个群体中校准良好，但在另一个群体中严重失准 [@problem_id:4390059]。

#### 分解[预测误差](@entry_id:753692)：偏倚-方差权衡

为了更深入地理解模型性能的来源，我们可以从理论上分解其预测误差。对于一个给定的特征向量$x$，模型输出的预测概率为$\hat{p}(x; \mathcal{D})$，它依赖于我们用于训练的随机数据集$\mathcal{D}$。真实（但未知）的[条件概率](@entry_id:151013)为$p^{\star}(x) = \mathbb{P}(Y=1 \mid X=x)$。使用[平方误差损失](@entry_id:178358)$(Y-\hat{p}(x; \mathcal{D}))^2$，其在所有可能的训练集$\mathcal{D}$和结局$Y$上的期望可以被分解为三个部分：

$$ \mathbb{E}_{Y,\mathcal{D}}[(Y - \hat{p}(x;\mathcal{D}))^2] = \underbrace{p^{\star}(x)(1-p^{\star}(x))}_{\text{不可约误差}} + \underbrace{\left(\mathbb{E}_{\mathcal{D}}[\hat{p}(x;\mathcal{D})] - p^{\star}(x)\right)^2}_{\text{偏倚的平方}} + \underbrace{\mathrm{Var}_{\mathcal{D}}(\hat{p}(x;\mathcal{D}))}_{\text{方差}} $$

-   **不可约误差（Irreducible Error）**：$p^{\star}(x)(1-p^{\star}(x))$是给定特征$x$时，二元结局$Y$自身的随机性（伯努利分布的方差）。这是任何模型都无法消除的[固有噪声](@entry_id:261197)。

-   **偏倚（Bias）**：$\mathbb{E}_{\mathcal{D}}[\hat{p}(x;\mathcal{D})] - p^{\star}(x)$衡量的是，在所有可能的[训练集](@entry_id:636396)上训练出的模型的平均预测值与真实值之间的差距。高偏倚的模型（通常是简单模型）系统性地偏离真相，存在“欠拟合”。

-   **方差（Variance）**：$\mathrm{Var}_{\mathcal{D}}(\hat{p}(x;\mathcal{D}))$衡量的是，当[训练集](@entry_id:636396)$\mathcal{D}$发生变化时，模型预测值的波动程度。高方差的模型（通常是复杂模型）对训练数据的微小变化非常敏感，存在“[过拟合](@entry_id:139093)”。

在处理高维度的EHR数据时（例如，特征数量$p$远大于样本量$n$），模型极易出现高方差（[过拟合](@entry_id:139093)）。**正则化（Regularization）**是一种常用的技术，用于控制模型复杂度以降低方差。例如，$\ell_2$正则化（岭回归）通过在[损失函数](@entry_id:136784)中增加一个惩罚项来惩罚过大的模型系数。增加正则化的强度通常会降低模型的方差，因为它使模型对训练数据的依赖性降低。然而，这种对模型的约束也可能使其无法捕捉到数据中真实存在的复杂关系，从而增加其偏倚。因此，模型训练的艺术就在于通过调整正则化参数，在偏倚和方差之间找到一个最佳的**权衡（trade-off）**，以最小化总的可约误差（偏倚的平方 + 方差）[@problem_id:4390072]。

### 形式化算法公平性

当我们将预测模型应用于不同的人群时，就必须考虑其公平性。为了能够客观地讨论和评估公平性，我们需要一套形式化的语言和标准。

#### 公平性标准的词典

在[算法公平性](@entry_id:143652)领域，已经发展出多种衡量标准，它们从不同角度定义了“公平”。以下是一些核心的群体公平性标准，假设我们有一个受保护属性$A$（如种族，分为$A=0$和$A=1$两组），一个真实结局$Y$，以及一个模型做出的二元预测$\hat{Y}$。

-   **人口统计学均等（Demographic Parity）**：此标准要求模型做出阳性预测（$\hat{Y}=1$）的比例在不同群体间是相等的。
    $$ P(\hat{Y} = 1 \mid A = 0) = P(\hat{Y} = 1 \mid A = 1) $$
    它只关注决策结果的均等，而不考虑个体的真实风险。例如，在脓毒症预警场景中，这意味着无论哪个种族群体，收到预警的患者比例应该相同。这个标准有时被称为“群体公平”或“统计均等”。

-   **[机会均等](@entry_id:637428)（Equal Opportunity）**：此标准关注的是模型在真正需要干预的群体（$Y=1$）中的表现。它要求在所有群体中，**真阳性率（True Positive Rate, TPR）**或称**敏感度（Sensitivity）**是相等的。
    $$ P(\hat{Y} = 1 \mid Y = 1, A = 0) = P(\hat{Y} = 1 \mid Y = 1, A = 1) $$
    在脓毒症预警中，这意味着对于真正会发生脓毒症的患者，无论其属于哪个群体，他们被模型正确识别（收到预警）的机会是均等的。这确保了模型带来的“好处”被公平地分配。

-   **[均等化赔率](@entry_id:637744)（Equalized Odds）**：这是[机会均等](@entry_id:637428)的加强版。它不仅要求相等的真阳性率（TPR），还要求相等的**[假阳性率](@entry_id:636147)（False Positive Rate, FPR）**。
    $$ P(\hat{Y} = 1 \mid Y = 1, A = 0) = P(\hat{Y} = 1 \mid Y = 1, A = 1) \quad \text{and} \quad P(\hat{Y} = 1 \mid Y = 0, A = 0) = P(\hat{Y} = 1 \mid Y = 0, A = 1) $$
    相等的FPR意味着，对于那些实际上不会发生脓毒症的患者，他们被错误地打上预警标签（受到不必要干预的“坏处”）的概率在所有群体中是均等的。[均等化赔率](@entry_id:637744)可以用条件独立性简洁地表示为：$\hat{Y} \perp A \mid Y$。

-   **预测值均等（Predictive Parity）**：此标准关注的是模型预测的“意义”。它要求当模型做出阳性预测时，该预测的准确性在不同群体间是相等的。这等同于要求**阳性预测值（Positive Predictive Value, PPV）**在各群体间相等。
    $$ P(Y = 1 \mid \hat{Y} = 1, A = 0) = P(Y = 1 \mid \hat{Y} = 1, A = 1) $$
    在脓毒症预警中，这意味着当警报响起时，患者确实患有脓毒症的概率，不应因其群体身份而异。这确保了决策者（如临床医生）可以同等地信任来自不同群体的警报。

-   **组内校准度（Calibration within Groups）**：此标准要求模型的连续风险评分$S$在每个群体内部都是良好校准的。形式上，对于每个群体$g$和几乎所有的风险分值$s$，都应满足：
    $$ P(Y = 1 \mid S = s, A = g) = s $$
    这意味着一个$70\%$的风险评分，无论对于哪个群体的患者，都真实地对应着$70\%$的事件发生概率 [@problem_id:4390092]。

#### 决策阈值的作用

预测模型本身（尤其是经过校准的[概率模型](@entry_id:265150)）输出的是一个连续的风险评分$s(X)$，它估计的是个体化的条件风险$P(Y=1 \mid X)$。然而，在临床实践中，我们通常需要基于这个风险评分做出一个二元的行动决策（例如，是启动抗生素治疗，还是继续观察）。这个从连续风险到二元行动的映射，是通过设定一个**决策阈值（decision threshold）** $t$ 来完成的：如果$s(X) \ge t$，则采取行动。

一个至关重要且常被误解的观点是：**决策阈值$t$的选择不是模型自身的属性，而是决策者[效用函数](@entry_id:137807)（utility function）的体现**。阈值的设定反映了我们对不同类型错误（[假阳性](@entry_id:635878)和假阴性）的权衡。

让我们再次考虑脓毒症的例子。假设我们为两种错误定义了成本（或损失）：
-   **假阴性（False Negative）**的成本，$c_{\text{FN}}$：错过了真正需要治疗的脓毒症患者，可能导致病情恶化甚至死亡。
-   **[假阳性](@entry_id:635878)（False Positive）**的成本，$c_{\text{FP}}$：对没有脓毒症的患者使用了广谱抗生素，可能导致副作用、抗生素耐药性和不必要的医疗开支。

对于一个风险评分为$s(X)$的患者，采取行动（治疗）的期望损失是$(1-s(X)) \cdot c_{\text{FP}}$，而不采取行动（观察）的期望损失是$s(X) \cdot c_{\text{FN}}$。为了最小化期望损失，我们应该在“治疗损失”小于“观察损失”时选择治疗，即：
$$ (1-s(X)) \cdot c_{\text{FP}}  s(X) \cdot c_{\text{FN}} $$
整理此不等式，我们得到采取行动的条件是：
$$ s(X) > \frac{c_{\text{FP}}}{c_{\text{FP}} + c_{\text{FN}}} $$
因此，最优的决策阈值$t_{\text{optimal}}$完全由两种错误的相对成本决定：
$$ t_{\text{optimal}} = \frac{c_{\text{FP}}}{c_{\text{FP}} + c_{\text{FN}}} $$
这个推导清晰地表明，阈值$t$是由外部的价值判断（即$c_{\text{FN}}$和$c_{\text{FP}}$的比值）决定的，它是一个策略参数。模型的工作是提供尽可能准确的个体风险$s(X)$，而如何使用这个风险则是一个独立的决策问题。人群中的事件患病率$P(Y=1)$虽然对模型的训练和评估很重要，但它并不直接决定个体最优决策的阈值 [@problem_id:4390109]。

### 固有的权衡：公平性的极限

在追求[算法公平性](@entry_id:143652)的过程中，我们很快就会发现，不同的公平性标准之间往往存在冲突。这些冲突并非偶然，而是有着深刻的数学根源。

#### 同时实现公平的不可能性

由研究者Alexandra Chouldechova和Jon Kleinberg等人揭示的**不可能性定理（impossibility theorems）**，是算法公平性领域的一个里程碑式的发现。其核心结论可以通俗地表述为：

**当不同群体的结局基线率（base rates）不同，且预测模型不完美时，你不可能同时满足校准度、[均等化赔率](@entry_id:637744)和预测值均等这三个公平性标准。**

让我们来理解这背后的逻辑。假设两个群体A和B的脓毒症真实患病率不同，即$p_A = P(Y=1 \mid G=A) \neq p_B = P(Y=1 \mid G=B)$。
-   如果我们要求模型满足**[均等化赔率](@entry_id:637744)**，这意味着真阳性率（TPR）和[假阳性率](@entry_id:636147)（FPR）在两个群体中都相等。
-   在这种情况下，我们可以通过[贝叶斯定理](@entry_id:151040)推导出每个群体的阳性预测值（PPV）：
    $$ \text{PPV}_g = \frac{\text{TPR} \cdot p_g}{\text{TPR} \cdot p_g + \text{FPR} \cdot (1-p_g)} $$
-   从这个公式可以看出，即使TPR和FPR在各组间相等，只要基线率$p_g$不同，$\text{PPV}_g$的值就会依赖于$p_g$。因此，如果$p_A \neq p_B$，那么必然会有$\text{PPV}_A \neq \text{PPV}_B$。
-   这就意味着，**预测值均等**无法被满足。

唯一的例外是当模型是“完美”的（例如，FPR=0且TPR=1），但在现实世界的医疗应用中，这几乎是不可能的。Kleinberg等人的工作进一步表明，在基线率不同的情况下，组内校准度也与[均等化赔率](@entry_id:637744)不兼容。

这些不可能性定理告诉我们，公平性不是一个可以“一劳永逸”解决的技术问题。它要求我们必须在多个有价值但相互冲突的目标之间做出选择和权衡。例如，我们可能需要决定，是优先确保模型对所有群体的预测错误率相同（[均等化赔率](@entry_id:637744)），还是优先确保模型警报的意义对所有群体都一样（预测值均等） [@problem_id:4390113]。

#### [数据质量](@entry_id:185007)问题如何使公平性复杂化

不可能性定理的触发条件是“结局基线率不同”。然而，在实际操作中，我们观测到的基线率可能并非真实的基线率，它本身就可能受到前述**标签偏倚**的影响。这使得公平性的评估变得更加复杂。

思考一个急性疼痛干预的风险模型。假设在真实世界中，两个群体A和B的急性疼痛真实发生率（$Y=1$）是相同的，即$\pi_A = \pi_B$。在这种情况下，不可能性定理的条件不成立，我们原则上可以找到一个同时满足[均等化赔率](@entry_id:637744)和预测值均等的模型。

然而，假设由于文化、语言或系统性原因，群体B的疼痛评估存在系统性的**低估（underassessment）**。这表现为一种标签偏倚：群体B中真正疼痛的患者被正确记录为疼痛的概率（即标签敏感度$s_B$），低于群体A（$s_B  s_A$）。

这种差异性的[标签噪声](@entry_id:636605)会改变我们**观测到**的基线率$\tilde{\pi}_g = P(\tilde{Y}=1 \mid A=g)$。即使真实基线率$\pi_g$相等，由于群体B的疼痛事件更容易被“漏掉”，我们会观测到$\tilde{\pi}_B  \tilde{\pi}_A$。

这样一来，标签偏倚人为地制造出了一个“观测到的基线率差异”。当我们使用带有噪声的标签$\tilde{Y}$来评估公平性时，不可能性定理的条件就被触发了。原本在真实标签$Y$下可以共存的公平性标准（如[均等化赔率](@entry_id:637744)和预测值均等），在观测标签$\tilde{Y}$下变得不再可能共存。

形式上，从真实[公平性指标](@entry_id:634499)（如TPR, FPR）到观测[公平性指标](@entry_id:634499)（$\widetilde{\text{TPR}}, \widetilde{\text{FPR}}$）的转换，是一个依赖于群体、基线率和[标签噪声](@entry_id:636605)参数的复杂[非线性映射](@entry_id:272931)。这个映射会“扭曲”公平性的可行性空间。这个例子深刻地揭示了数据质量与算法公平性之间的内在联系：解决[算法公平性](@entry_id:143652)问题，必须追溯到数据生成的源头 [@problem_id:4390056]。

### 模型的部署与维护：生命周期中的公平性

构建一个公平的预测模型并非终点。模型被部署到真实的临床环境中后，其性能和公平性可能会随着时间的推移而发生变化。因此，对模型进行持续的监控和维护，是确保其长期有效和公平的关键。

#### 部署模型中的[分布偏移](@entry_id:638064)

当一个在开发中心（分布为$P_0$）训练好的模型被部署到一个或多个目标中心（分布为$P_k$）时，我们经常会遇到**[分布偏移](@entry_id:638064)（distributional shift）**的问题，即$P_k(X,Y) \neq P_0(X,Y)$。这种偏移可以分为几种主要类型：

-   **[协变量偏移](@entry_id:636196)（Covariate Shift）**：指的是特征的边缘分布发生了变化，但特征与结局之间的条件关系保持不变。形式上，$P_k(X) \neq P_0(X)$，但$P_k(Y \mid X) = P_0(Y \mid X)$。例如，一个新部署的医院其患者的人口统计学构成或疾病严重程度分布与原始训练医院不同。
    *   **诊断**：由于[协变量偏移](@entry_id:636196)不涉及标签$Y$，我们可以使用无标签的目标中心数据进行诊断。方法包括：进行两样本检验（如[最大均值差异](@entry_id:636886)MMD检验）来判断$P_k(X)$和$P_0(X)$是否不同；或者训练一个“域分类器”来尝试区分来自中心$k$和中心$0$的样本，如果分类器的AUC显著高于$0.5$，则说明存在[协变量偏移](@entry_id:636196)。

-   **标签偏移（Label Shift）**：指的是结局的边缘分布（即基线率）发生了变化，但结局对特征的[条件分布](@entry_id:138367)保持不变。形式上，$P_k(Y) \neq P_0(Y)$，但$P_k(X \mid Y) = P_0(X \mid Y)$。例如，由于公共卫生干预，某个地区的疾病患病率下降了。
    *   **诊断**：在没有目标中心标签的情况下，可以通过专门的算法（如黑盒偏移检测，BBSD）来估计目标中心的标签分布$\pi_k$。这类方法利用源数据上训练好的模型，将其应用于目标中心的无标签数据，通过分析模型输出的分布来反推出$\pi_k$，并检验其是否与源分布$\pi_0$有显著差异。

-   **概念漂移（Concept Drift）**：这是最严重的一种偏移，指的是特征与结局之间的根本关系发生了变化。形式上，$P_k(Y \mid X) \neq P_0(Y \mid X)$。例如，一种新疗法的出现改变了疾病的自然病程，或者EHR系统的更新改变了数据的编码方式。
    *   **诊断**：诊断概念漂移必须依赖于有标签的目标中心数据。方法包括：在目标中心的小批量有标签数据上监控模型的性能（如准确率、AUC）和校准度，看其是否随时间下降；使用序列分析方法（如CUSUM检验）来检测模型损失（如[对数损失](@entry_id:637769)）的突变点。

在进行公平性监控时，上述所有诊断都应在不同的受保护亚组（由$S$定义）内部分别进行，以检测是否存在差异性的[分布偏移](@entry_id:638064)，这对于维护模型的长期公平性至关重要 [@problem_id:4390061]。

#### 新兴策略：公平性感知建模

面对上述挑战，研究社区正在开发新的建模策略，将公平性直接融入模型训练过程。一种思路是**公平性感知正则化（fairness-aware regularization）**。正如$\ell_2$正则化通过惩罚系数的大小来控制[模型复杂度](@entry_id:145563)以实现偏倚-方差权衡，我们也可以在模型的[损失函数](@entry_id:136784)中加入一个惩罚项，该惩罚项用于量化模型在不同群体间的不公平程度。

例如，这个惩罚项可以设计为随着不同群体错误率的差异增大而增大。在优化这个新的、包含公平性惩罚的[损失函数](@entry_id:136784)时，模型被迫在整体预测准确性与跨群体公平性之间做出权衡。通常，这可能会导致整体准确率有轻微的下降，但换来的是模型在不同群体（尤其是数据量较少的少数群体）之间表现得更加均衡和稳定。这种方法，本质上是接受用一点额外的“偏倚”（来自公平性约束）来换取在少数群体上更低的“方差”（更稳定的预测），从而提升模型在现实世界中的可靠性和公平性 [@problem_id:4390072]。