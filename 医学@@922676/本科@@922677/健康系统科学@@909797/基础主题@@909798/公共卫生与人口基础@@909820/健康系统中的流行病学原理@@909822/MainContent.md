## 引言
在复杂的卫生系统中，每一个决策——从引进一项新技术到实施一项[公共卫生政策](@entry_id:185037)——都应建立在坚实的证据之上。然而，如何科学地衡量问题、评估干预效果并最终改善人口健康？流行病学为此提供了核心的科学语言和分析工具箱。它是一门将观察转化为严谨测量，并将关联与因果区分开来的学科，是卫生系统科学不可或缺的基石。本文旨在系统性地介绍这些关键的流行病学原理，并展示其在解决现实世界卫生系统挑战中的强大应用。

本文旨在填补理论知识与实践应用之间的鸿沟，帮助读者掌握一套用于批判性思考和解决问题的分析框架。我们将带领您完成一个结构化的学习旅程：
*   在 **“原则与机制”** 一章中，我们将奠定基础，从量化疾病负担的基础测量方法入手，逐步深入到探求因果关系的核心挑战（如混杂）及其应对策略，包括潜在结局框架和高级纵向数据分析方法。
*   接着，在 **“应用与跨学科联系”** 一章中，我们将展示这些原理如何在现实世界中发挥作用，涵盖诊断与筛查项目评估、卫生政策的经济学分析、传染病动态建模，以及如何运用系统思维理解和干预复杂的健康问题。
*   最后，在 **“动手实践”** 部分，您将有机会通过具体的练习题，将所学知识应用于解决模拟的实际问题，从而巩固您的理解和分析技能。

通过学习本章内容，您将能够更有信心地解释健康数据，评估研究证据，并为设计更有效、更公平的卫生系统做出贡献。让我们从构建这套强大的分析工具开始。

## 原则与机制

本章深入探讨支撑卫生系统科学的流行病学核心原则与机制。我们将从量化疾病负担的基础测量方法入手，逐步过渡到评估干预措施效果的复杂因果推断方法。本章的目标是为您提供一套严谨的分析工具，用于解释、评估和改进卫生系统中的健康产出。

### 疾病发生率与关联性的测量

在评估卫生系统表现时，首要任务是准确地量化人群中的疾病状况。流行病学提供了标准化的指标来测量疾病的发生频率，并比较不同人群间的风险。

#### 量化负担：患病率与发病率

描述人群疾病负担的两个核心概念是 **患病率 (prevalence)** 和 **发病率 (incidence)**。

**患病率** 衡量在特定时间点，人群中存在某种疾病的个体所占的比例。它反映了疾病的存量或负担。**时点患病率 (point prevalence)** 是最常用的形式，其计算公式为：

$P = \frac{\text{特定时间点的现存病例数}}{\text{该时间点的总人口数}}$

例如，一项在3月1日进行的横断面普查发现，在 $1,200$ 名社区居民中，有 $70$ 人患有某种慢性病。那么，该日该社区的时点患病率约为 $70 / 1,200 \approx 0.058$。值得注意的是，患病率的分母包括了所有人，无论他们是否患病。它是一个无量纲的比例，反映了在该时间点随机抽取一个个体，其患有该疾病的概率 [@problem_id:4370312]。

与衡量存量的患病率不同，**发病率** 衡量在特定时期内，新发病例出现的频率或风险。它反映了疾病的“流动”或新发事件的速率。发病率主要有两种形式：累积发病率和发病率密度。

**累积发病率 (Cumulative Incidence)**，也常被称为 **风险 (Risk)**，是指在一个特定时期内，一群最初无该病的高危个体中出现新病例的比例。它最适用于 **封闭队列 (closed cohort)**，即研究期间没有新成员加入，也没有成员失访。其计算公式为：

$CI = \frac{\text{特定时期内的新发病例数}}{\text{研究开始时的无病高危个体数}}$

假设一个由 $1,000$ 名无病个体组成的封闭队列被随访一年，期间有 $50$ 人发病。那么，这一年的累积发病率为 $50 / 1,000 = 0.05$。这是一个无量纲的比例，表示该队列中个体在一年内发病的平均风险。由于队列是封闭的，分母在整个研究期间保持固定 [@problem_id:4370312]。

然而，在许多卫生系统监测场景中，人群是 **开放的 (open population)** 或动态的，个体随时加入和退出。在这种情况下，每个人的随访时间可能不同。此时，更合适的指标是 **发病率密度 (Incidence Rate or Incidence Density)**。它衡量的是单位“人-时间”内新发病例的速率。其计算公式为：

$IR = \frac{\text{特定时期内的新发病例数}}{\text{同一时期内所有高危个体的总人-时间}}$

**人-时间 (Person-time)** 是对所有个体随访时间的总和。例如，如果在一个开放人群中，一年内观察到 $40$ 例新发病例，而所有高危个体贡献的总随访时间为 $800$ 人-年，则发病率密度为 $40 / 800 = 0.05$ 病例/人-年。这个指标是一个真正的速率，其单位是时间的倒数（如“每人-年”），它精确地反映了疾病在新发病例出现的速度 [@problem_id:4370312]。

#### 比较风险：关联性测量

量化疾病发生频率后，下一步通常是比较不同暴露组（例如，接受不同治疗或服务的人群）的风险，以评估暴露与结局之间的关联。

**相对测量** 用于评估暴露组的风险相对于非暴露组增加了多少倍。
- **风险比 (Risk Ratio, RR)**：是暴露组与非暴露组累积发病率（风险）之比。令 $R_1$ 为暴露组的风险，$R_0$ 为非暴露组的风险，则 $RR = \frac{R_1}{R_0}$。
- **率比 (Rate Ratio, IRR)**：是暴露组与非暴露组发病率密度之比。令 $\lambda_1$ 为暴露组的发病率密度，$\lambda_0$ 为非暴露组的发病率密度，则 $IRR = \frac{\lambda_1}{\lambda_0}$。
- **优势比 (Odds Ratio, OR)**：是暴露组中事件发生的优势 (odds) 与非暴露组中事件发生的优势之比。一个事件的优势定义为事件发生的概率与不发生的概率之比，即 $R / (1-R)$。因此，$OR = \frac{R_1 / (1-R_1)}{R_0 / (1-R_0)}$。

优势比在病例对照研究中尤为重要，并且是逻辑[回归模型](@entry_id:163386)输出的自然结果。它与风险比的关系可以表示为 $OR = RR \times \frac{1-R_0}{1-R_1}$。从这个关系可以看出，当疾病在两个组中都非常罕见时（即 $R_1 \ll 1$ 且 $R_0 \ll 1$），则 $1-R_1 \approx 1$ 且 $1-R_0 \approx 1$，此时 $OR \approx RR$。这被称为 **“稀有疾病假设”**，是在特定条件下将优势比近似解释为风险比的理论基础 [@problem_id:4370316]。

**绝对测量** 则从绝对差异的角度描述暴露的影响。
- **风险差 (Risk Difference, RD)**：是暴露组与非暴露组风险的绝对差值，即 $RD = R_1 - R_0$。它量化了由暴露导致的每单位人群中超额发病的数量，对于公共卫生决策具有重要意义 [@problem_id:4370316]。

#### 评估诊断与筛查试验

卫生系统经常需要评估新的诊断或筛查工具的性能。这些评估基于将新测试的结果与“金标准”（一个公认的、最准确的诊断方法）进行比较。结果通常总结在一个 $2 \times 2$ 表格中，该表格交叉分类了真实疾病状态（存在或不存在）和测试结果（阳性或阴性）。

| | 检验阳性 | 检验阴性 | 总计 |
| :--- | :---: | :---: | :---: |
| **疾病存在** | [真阳性](@entry_id:637126) (TP) | 假阴性 (FN) | TP + FN |
| **疾病不存在** | [假阳性](@entry_id:635878) (FP) | 真阴性 (TN) | FP + TN |
| **总计** | TP + FP | FN + TN | N |

基于这个表格，我们可以定义四个关键的性能指标：

- **灵敏度 (Sensitivity)**：指在真正患病的人中，被测试正确识别为阳性的比例。它衡量测试检出患者的能力。其计算公式为 $P(T^+|D^+) = \frac{TP}{TP + FN}$。这是一个以真实疾病状态为条件的概率，是测试的内在属性。

- **特异度 (Specificity)**：指在真正未患病的人中，被测试正确识别为阴性的比例。它衡量测试排除非患者的能力。其计算公式为 $P(T^-|D^-) = \frac{TN}{FP + TN}$。与灵敏度一样，它也是测试的内在属性。

- **阳性预测值 (Positive Predictive Value, PPV)**：指在所有测试结果为阳性的人中，真正患病的比例。它回答了这样一个问题：“如果一个人的测试结果是阳性，他确实患病的概率有多大？”其计算公式为 $P(D^+|T^+) = \frac{TP}{TP + FP}$。

- **阴性预测值 (Negative Predictive Value, NPV)**：指在所有测试结果为阴性的人中，真正未患病的比例。它回答了这样一个问题：“如果一个人的测试结果是阴性，他确实未患病的概率有多大？”其计算公式为 $P(D^-|T^-) = \frac{TN}{FN + TN}$。

与灵敏度和特异度不同，**PPV和NPV严重依赖于被测人群中的疾病患病率**。例如，考虑一个灵敏度和特异度均为 $80\%$ 的测试。在一个疾病患病率为 $12.5\%$（$150/1200$）的人群中，[假阳性](@entry_id:635878)的数量可能相当可观。一项研究发现，在 $150$ 名患者中，测试检出 $120$ 名（TP）；在 $1,050$ 名非患者中，却错误地将 $210$ 名标记为阳性（FP）。此时，PPV为 $120 / (120+210) \approx 36.4\%$，意味着超过六成的阳性结果是错误的。然而，由于测试能正确识别大多数非患者，其NPV可能非常高，例如 $840 / (30+840) \approx 96.6\%$ [@problem_id:4370345]。这凸显了在临床实践中解释测试结果时，必须考虑人群背景的重要性。

### 对因果关系的探求

流行病学的最终目标之一是确定暴露与结局之间的因果关系，以便设计有效的干预措施。然而，从观察数据中推断因果关系充满挑战。

#### 核心挑战：混杂

在[观察性研究](@entry_id:174507)中，我们观察到的关联（例如，通过风险比测量）不一定等于因果效应。主要障碍是 **混杂 (confounding)**。当第三个变量（混杂因素）既与暴露有关，又与结局有关（并且不是暴露导致结局的中间环节）时，就会发生混杂。这个混杂因素会扭曲我们观察到的暴露与结局之间的关联。

让我们通过一个数值例子来理解 [@problem_id:4370339]。一个卫生系统评估一项新的护理协调计划（$A=1$ 代表参与， $A=0$ 代表未参与）对不良结局（$Y=1$）的影响。已知患者是否患有某种合并症（$C=1$ 代表有，$C=0$ 代表无）是一个潜在的混杂因素，因为病情更重的患者（更有可能 $C=1$）可能被优先纳入该计划，同时他们发生不良结局的基线风险也更高。

数据如下：
- 分层风险：$P(Y=1|A=1, C=1)=0.3$, $P(Y=1|A=0, C=1)=0.2$, $P(Y=1|A=1, C=0)=0.1$, $P(Y=1|A=0, C=0)=0.05$。
- 合并症在不同暴露组的分布：$P(C=1|A=1)=0.8$, $P(C=1|A=0)=0.2$。

首先，我们计算 **粗风险比 (crude risk ratio)**。通过[全概率公式](@entry_id:194231)，我们可以计算出总体的边际风险：
$P(Y=1|A=1) = (0.3)(0.8) + (0.1)(0.2) = 0.26$
$P(Y=1|A=0) = (0.2)(0.2) + (0.05)(0.8) = 0.08$
因此，粗风险比为 $\text{RR}_{\text{crude}} = 0.26 / 0.08 = 3.25$。这个结果表明，参与计划的人的风险是未参与者的 $3.25$ 倍，似乎该计划非常有害。

然而，这是被混杂扭曲的关联。在合并症患者（$C=1$）亚组中，风险比为 $0.3 / 0.2 = 1.5$。在无合并症患者（$C=0$）亚组中，风险比为 $0.1 / 0.05 = 2.0$。在这两个同质的亚组中，风险比都显示出风险增加，但远没有 $3.25$ 那么极端。粗风险比被夸大了，因为参与计划的组（$A=1$）中包含了远多于未参与组的高风险患者（$C=1$ 的比例为 $80\%$ vs $20\%$）。

为了得到一个未被混杂扭曲的效应估计，我们可以使用 **标准化 (standardization)** 方法计算 **调整风险比 (adjusted risk ratio)**。我们将两组的风险都调整到同一个标准人群的合并症分布上（例如，以非参与组为标准）。调整后的风险分别为：
$Risk_{adj}(A=1) = (0.3)(0.2) + (0.1)(0.8) = 0.14$
$Risk_{adj}(A=0) = (0.2)(0.2) + (0.05)(0.8) = 0.08$
调整风险比为 $\text{RR}_{\text{adj}} = 0.14 / 0.08 = 1.75$。这个值（$1.75$）更好地代表了在可比人群中该计划的效应，它介于两个分层风险比（$1.5$ 和 $2.0$）之间。

在极端情况下，混杂可能导致 **[辛普森悖论](@entry_id:136589) (Simpson's Paradox)**，即在分层分析中观察到的关联方向与在合并分析中观察到的方向完全相反。尽管在我们的例子中没有发生方向逆转，但它清楚地展示了混杂如何产生误导性的结论 [@problem_id:4370339]。

#### 一个正式的因果推断框架

为了更严谨地处理因果问题，流行病学家和统计学家使用 **潜在结局框架 (potential outcomes framework)**，也称为反事实框架。对于每个个体，我们设想其在不同暴露水平下的潜在结局。例如，$Y^a$ 表示如果一个个体（可能与事实相反地）接受暴露水平 $A=a$ 时，将会观察到的结局。

使用这个语言，个体层面的因果效应可以定义为不同潜在结局的差异，例如 $Y^1 - Y^0$。人群的 **平均因果效应 (Average Causal Effect, ACE)** 则是 $\Delta = \mathbb{E}[Y^1 - Y^0]$。

在理想的随机对照试验中，由于随机分配，暴露组和非暴露组是 **可交换的 (exchangeable)**，这意味着暴露分配与潜在结局无关，即 $(Y^0, Y^1) \perp\kern-5pt\perp A$。在这种情况下，观察到的关联等于因果效应。然而，在观察性研究中，这种无条件的可交换性通常不成立。混杂的正式定义就是 $Y^a \not\perp\kern-5pt\perp A$。

为了从观察数据（包括观察到的结局 $Y$、暴露 $A$ 和一系列协变量 $L$）中识别因果效应，我们需要三个核心的 **识别假设 (identification assumptions)** [@problem_id:4370292]：
1.  **一致性 (Consistency)**：一个个体观察到的结局，就是其在所接受的实际暴露水平下的潜在结局。即，如果 $A=a$，那么 $Y = Y^a$。
2.  **条件[可交换性](@entry_id:263314) (Conditional Exchangeability)**：在协变量 $L$ 的每个分层内，暴露分配与潜在结局无关。即 $Y^a \perp\kern-5pt\perp A \mid L$。这本质上是“无未测量混杂”的假设，意味着我们已经测量了所有重要的混杂因素 $L$。
3.  **正性 (Positivity)**：在所有协变量 $L$ 的分层中，接受每种暴露水平的概率都大于零。即 $0  P(A=a \mid L=l)  1$。这确保了在每个亚组中都有可比较的对象。

此外，一个常被隐含提及的重要假设是 **稳定单位处理值假设 (Stable Unit Treatment Value Assumption, SUTVA)**。SUTVA包含两个部分：
- **无干预 (No Interference)**：一个个体的潜在结局不受其他个体所接受的暴露的影响。这意味着我们可以将个体的潜在结局写为 $Y_i(A_i)$，而不是依赖于整个群体暴露向量的 $Y_i(\mathbf{A})$。
- **一致性**（如上所述，有时被视为SUTVA的一部分）：暴露的定义是清晰的，没有隐藏的不同版本。

在许多卫生系统干预中，特别是涉及[传染病](@entry_id:182324)或行为改变的干预，**无干预假设常常被违反**。例如，在一个学校疫苗接种计划中，一个未接种疫苗的学生（$Z_i=0$）的感染风险，会受到他周围同学是否接种疫苗（$\mathbf{Z}_{-i}$）的强烈影响。如果他的许多朋友都接种了疫苗，他会受到间接保护（一种溢出效应），即使他自己的暴露状态没有改变。这种现象称为 **干预 (interference)** 或 **溢出效应 (spillover effects)**，它使得简单的比较接种疫苗和未接种疫苗组的感染率会产生误导，因为它混合了疫苗的直接保护效应和间接的群体保护效应 [@problem_id:4370342]。

### 卫生系统评估的高级方法

当[数据结构](@entry_id:262134)变得更加复杂，例如涉及随时间变化的暴露和混杂因素时，需要更高级的方法。

#### 纵向数据的因果推断

许多卫生系统干预是在一段时间内进行的，研究人员会收集纵向数据。

**[双重差分法](@entry_id:636293) (Difference-in-Differences, DiD)** 是一种强大的准实验设计，用于评估在特定时间点引入的政策或干预的效果。它需要两组（受干预的“处理组”和未受干预的“[控制组](@entry_id:188599)”）在干预前和干预后的数据。DiD方法的目标通常是估计 **处理组的平均[处理效应](@entry_id:636010) (Average Treatment Effect on the Treated, ATT)**，其在潜在结局框架下的正式定义为：$\Delta^{ATT} = \mathbb{E}[Y_i(1,1) - Y_i(0,1) \mid D_i = 1]$。这里，$Y_i(d,t)$ 表示个体 $i$ 在时间 $t$ 和处理状态 $d$ 下的潜在结局，$D_i=1$ 表示属于处理组。这个公式的核心挑战在于反事实项 $\mathbb{E}[Y_i(0,1) \mid D_i = 1]$ 是不可观测的——即处理组在接受处理后，假如没有接受处理的话，其结局会是怎样。

DiD方法的关键识别假设是 **[平行趋势假设](@entry_id:633981) (parallel trends assumption)**。该假设指出，在没有干预的情况下，处理组和[控制组](@entry_id:188599)的结局随时间的变化趋势是相同的。用潜在结局表示为：$\mathbb{E}[Y_i(0,1) - Y_i(0,0) \mid D_i = 1] = \mathbb{E}[Y_i(0,1) - Y_i(0,0) \mid D_i = 0]$。这个假设允许我们使用[控制组](@entry_id:188599)观察到的变化趋势，来推断处理组的反事实变化趋势，从而识别出ATT [@problem_id:4370351]。

当暴露、结局和混杂因素都随时间变化时，情况会变得更加复杂。一个典型的挑战是 **受既往暴露影响的时变混杂 (time-varying confounding affected by prior treatment)**。在这种情况下，一个变量 $L_t$（如血压）既是未来治疗决策 $A_t$ 的混杂因素（$L_t \rightarrow A_t$, $L_t \rightarrow Y$），又受到过去治疗 $A_{t-1}$ 的影响（$A_{t-1} \rightarrow L_t$）。

在这种“治疗-混杂反馈”循环中，标准的统计方法（如[多元回归](@entry_id:144007)）会失效。对 $L_t$ 进行调整，一方面会错误地阻断了过去治疗 $A_{t-1}$ 通过 $L_t$ 影响结局 $Y$ 的部分因果路径；另一方面，如果存在未测量的共同原因 $U$（例如，社会压力）同时影响 $L_t$ 和 $Y$，调整 $L_t$ 会在 $A_{t-1}$ 和 $U$ 之间打开一个虚假的统计关联（称为 **对撞机分层偏倚 (collider stratification bias)**），从而引入新的偏倚 [@problem_id:4370352]。

为了解决这个问题，研究人员开发了 **边际结构模型 (Marginal Structural Models, MSM)**。MSM通过 **[逆概率](@entry_id:196307)处理加权 (Inverse Probability of Treatment Weighting, IPTW)** 来估计因果效应。IPTW为每个个体创建一个权重，该权重是其在每个时间点上，基于其过去的协变量历史，接受其实际所接受的治疗的概率的倒数。这种加权方法创建了一个“伪人群”，在这个伪人群中，治疗分配与测量的时变混杂因素无关，从而打破了治疗-混杂反馈循环。在满足**序贯[可交换性](@entry_id:263314) (sequential exchangeability)**（即每个时间点的治疗分配都与过去的测量历史条件独立）、正性和一致性等假设下，MSM可以提供对纵向治疗策略总因果效应的一致估计 [@problem_id:4370352]。

#### [传染病](@entry_id:182324)动力学建模

传染病流行是卫生系统面临的重大挑战，其动态过程可以用特定的流行病学模型来描述。
- **基本再生数 ($R_0$)**：定义为在一个完全易感的群体中，一个典型的感染者在其整个感染期内平均能传染的二代病例数。如果 $R_0 > 1$，疫情将传播；如果 $R_0  1$，疫情将自行消亡。
- **有效再生数 ($R_t$)**：是在时间 $t$ 的再生数，它考虑了人群中由于感染或疫苗接种而产生的免疫力以及行为改变等因素。一个常见的近似是 $R_t = R_0 \times S(t)$，其中 $S(t)$ 是 $t$ 时刻人群中的易感者比例。公共卫生干预的目标就是将 $R_t$ 降至 $1$ 以下。
- **代际时间 (Generation Time)**：指从原发病例感染到其续发病例感染的平均时间间隔。对于给定的 $R_0$，代际时间越短，疫情的指数增长速度越快，为病例发现和隔离等干预措施留下的时间窗口也越窄 [@problem_id:4370340]。
- **[群体免疫阈值](@entry_id:184932) (Herd Immunity Threshold, H)**：指要使疫情开始衰退（即 $R_t  1$），人群中需要具备免疫力的最低比例。在同质混合的假设下，该阈值由 $R_0$ 唯一确定：$H = 1 - 1/R_0$。例如，如果 $R_0 = 3$，则需要有 $1 - 1/3 = 2/3 \approx 66.7\%$ 的人具有免疫力才能达到群体免疫。一项覆盖率为 $50\%$、疫苗有效率为 $80\%$ 的接种计划，能产生的有效免疫人群比例为 $0.5 \times 0.8 = 0.4$（即$40\%$），这不足以达到 $66.7\%$ 的阈值 [@problem_id:4370340]。

### 卫生系统研究中的[数据质量](@entry_id:185007)

基于电子健康记录（EHR）的研究为卫生系统科学提供了前所未有的机会，但同时也带来了[数据质量](@entry_id:185007)方面的挑战，其中最普遍的就是 **数据缺失 (missing data)**。理解数据缺失的机制对于选择正确的分析方法至关重要。Rubin的框架将缺失机制分为三类：

1.  **[完全随机缺失](@entry_id:170286) (Missing Completely At Random, MCAR)**：缺失的概率与任何观察到的或未观察到的变量都无关。即 $P(R=1|Y, X) = P(R=1)$。例如，由于实验室信息系统与EHR之间的接口短暂、意外中断，导致一部分[流感](@entry_id:190386)检测结果未能上传。这种缺失影响了该时段内的所有患者，而与他们的个人特征或真实的检测结果无关 [@problem_id:4370335]。

2.  **[随机缺失](@entry_id:168632) (Missing At Random, MAR)**：缺失的概率与观察到的其他变量（$X$）有关，但在给定这些变量的条件下，与缺失变量（$Y$）本身的值无关。即 $P(R=1|Y, X) = P(R=1|X)$。例如，糖化血红蛋白的测量值在初级保健就诊次数较少和没有保险的患者中更常见缺失。如果在这两个已记录的变量（就诊次数和保险状况）的条件下，该值是否被记录与其真实的高低无关，那么这种缺失就是MAR [@problem_id:4370335]。

3.  **[非随机缺失](@entry_id:163489) (Missing Not At Random, MNAR)**：缺失的概率取决于缺失变量本身的值，即使在控制了所有观察到的变量之后也是如此。这是最难处理的一种情况。例如，由于社会污名化或工作流程的原因，当患者确实是吸烟者时，其吸烟状况记录更有可能被留空。即使在考虑了年龄、性别、诊所和医生等所有观察到的变量后，这种依赖关系仍然存在，那么这就是MNAR [@problem_id:4370335]。

正确识别缺失机制是进行有效[统计推断](@entry_id:172747)的前提，因为它决定了是否可以使用诸如完整病例分析、[多重插补](@entry_id:177416)等方法来处理缺失数据。