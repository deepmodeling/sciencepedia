## 引言
在现代医学中，任何新疗法的诞生与临床决策的制定都离不开坚实的科学证据。临床试验设计与循证医学正是连接创新理念与患者获益之间的关键桥梁，它们共同构成了评估医疗干预措施有效性与安全性的黄金标准。然而，从一个简单的“药物vs安慰剂”概念到一项能够产生可靠结论的严谨研究，其间充满了复杂的科学原理、统计方法与伦理考量。许多学习者了解临床试验的重要性，却对如何通过精妙设计来消除偏倚、如何正确解读统计结果以及如何将证据应用于多样化的临床场景缺乏系统性的认识。

本文旨在填补这一知识鸿沟，引领读者系统性地掌握临床试验设计与循证医学的核心。我们将通过三个章节的递进式学习，构建一个从理论到实践的完整知识体系。在**“原理与机制”**一章中，我们将深入探讨支撑现代临床试验的基石，包括伦理准则、因果推断的逻辑、随机化与盲法的力量，以及假设检验的统计学基础。随后，在**“应用与跨学科交叉”**一章中，我们将把这些原理置于真实世界的情境中，展示它们在药物研发全流程、特殊人群研究以及高级试验设计中的灵活运用，并讨论如何解读和转化证据以指导临床实践。最后，**“动手实践”**部分将提供具体的练习，让您亲手计算关键指标、评估设计选择并体验证据综合的过程，从而巩固所学知识。

现在，让我们从第一章开始，一同揭开临床试验背后严谨而精妙的科学世界。

## 原理与机制

本章旨在深入探讨构成临床试验设计与实施、以及循证医学实践核心的科学原理与统计机制。继引言之后，我们将从伦理基石出发，系统性地剖析如何通过严谨的设计来获取无偏的因果效应估计，并最终将证据进行综合，以指导临床决策。

### 伦理基石：临床均势

所有人体研究都必须建立在坚实的伦理基础之上。在随机对照试验（RCT）的语境中，最核心的伦理准则之一是**临床均势（clinical equipoise）**。这一原则并非指进行研究的单个研究者对其所比较的两种或多种疗法孰优孰劣感到个人不确定，而是指在相关的专家医学界内，对于这些疗法的相对治疗价值存在一种真实的、集体的未知状态或专业[分歧](@entry_id:193119)。只有当这种集体不确定性存在时，将患者随机分配到不同治疗组的做法才被认为是合乎伦理的。

临床均势原则对试验设计，尤其是[对照组](@entry_id:188599)的选择，具有深远的影响。伦理要求研究者必须为参与者提供当前最佳的、已证实的治疗方法。因此，当针对某种严重疾病（如心肌梗死或癌症）存在已证实有效的标准疗法时，任何新的试验性药物都应与这一**最佳标准疗法（best available standard-of-care）**进行比较。在这种情况下，设立一个仅接受安慰剂的[对照组](@entry_id:188599)是不道德的，因为它会剥夺患者已知的有效治疗，使他们面临可预见的、不必要的严重伤害风险。

例如，假设一个制药公司开发了一种新型抗血小板药物Thrombolax，用于治疗ST段抬高型心肌梗死（STEMI）。已有多项RCT证实，阿司匹林和P2Y12受体抑制剂的联合应用是STEMI的标准疗法，能显著降低早期死亡率。如果申办方提议进行一项试验，将患者随机分为单独使用Thrombolax组和单独使用安慰剂组，并停用所有背景抗血小板标准疗法，这将严重违反临床均势原则。因为专家界对于“标准疗法优于无治疗”这一点并无不确定性。在这种情况下，合乎伦理的设计方案应该是**活性药物对照试验**，即将Thrombolax与标准疗法进行比较，或者是**附加设计（add-on design）**，即所有患者都接受标准疗法，然后随机分配接受Thrombolax或安慰剂的附加治疗[@problem_id:4934267]。只有在尚无已证实有效疗法的疾病领域，或者在不剥夺患者有效治疗且不使其面临严重伤害风险的前提下（如附加设计），使用安慰剂作为对照才是可接受的。

### 核心问题：因果推断与混杂

临床试验的根本科学目标是估计一项干预措施（如药物）对临床结局的**因果效应（causal effect）**。在观察性研究中，我们常常发现治疗与结局之间存在关联，但这并不等同于因果关系。其主要障碍是**混杂（confounding）**。当某个既与治疗分配相关，又与结局相关的外部变量（即**混杂因素**）存在时，就会出现混杂。例如，在[观察性研究](@entry_id:174507)中，病情更重的患者可能更倾向于接受一种新的、有前景的治疗，同时他们的预后本身也更差。这种情况下，病情严重程度就是一个混杂因素，它会扭曲我们观察到的治疗与结局之间的关联。

为了更精确地定义混杂，我们引入**潜在结局（potential outcomes）**框架。对于每个个体，我们可以设想其在接受治疗（$A=1$）和未接受治疗（$A=0$）两种情况下的潜在结局，分别表示为 $Y^1$ 和 $Y^0$。因果效应即为这两种潜在结局的比较，例如平均因果效应 $E[Y^1] - E[Y^0]$。在实际中，我们只能观测到每个个体在其实际接受的治疗下的结局。混杂的本质是**不可交换性（non-exchangeability）**，即接受治疗组和未接受治疗组在治疗开始前就是不可比较的。用反事实符号表示，混杂存在即意味着潜在结局与实际接受的治疗不独立，即 $Y^a \not\perp\perp A$ (对于 $a \in \{0,1\}$)。

**[有向无环图](@entry_id:164045)（Directed Acyclic Graphs, DAGs）**为我们提供了一个直观的工具来理解混杂。在DAG中，混杂表现为从治疗（$A$）到结局（$Y$）的“后门路径（backdoor path）”——这是一条连接$A$和$Y$的、始于指向$A$的箭头的非因果路径。例如，在一个包含未测量因素$U$（如生活方式）和已测量协变量$L$（如风险评分）的DAG中，如果存在路径 $A \leftarrow L \rightarrow Y$ 和 $A \leftarrow U \rightarrow Y$，那么$L$和$U$就是混杂因素，它们打开了从$A$到$Y$的后门路径，造成了$A$和$Y$之间的伪关联。

**随机化（Randomization）**是解决混杂问题的最强有力工具。一个理想的随机化过程，确保了每个参与者被分配到何种治疗组完全由机遇决定，独立于其所有基线特征（无论是可测量的还是不可测量的）。在DAG的语言中，随机化这一干预措施从机制上**切断了所有指向治疗节点$A$的箭头**。这意味着，在上述例子中，箭头 $L \to A$ 和 $U \to A$ 被移除。如此一来，所有从$A$到$Y$的后门路径都被阻断了。由于$A$和$Y$之间不再有非因果的开放路径，两者之间任何剩余的关联都只能通过前向的因果路径 $A \to Y$ 来解释。因此，随机化通过在期望上实现组间的**可交换性**（即 $A \perp\perp (Y^0, Y^1, L, U)$），使得观察到的关联可以直接解释为因果效应[@problem_id:4934268]。

### 实施随机化：保证完整性与偏倚预防

随机化虽然在理论上是完美的，但其有效性取决于实施的严谨性。两个关键概念——分配隐藏和盲法——对于保护随机化的完整性和预防试验过程中的偏倚至关重要。

#### 分配隐藏

**分配隐藏（Allocation concealment）**是一系列程序，旨在确保在参与者被最终确认入组之前，研究者和参与者都无法预知即将到来的治疗分配序列。这与生成随机序列本身是两个不同的概念。随机序列可以提前生成，但必须被妥善隐藏。

分配隐藏的目的是为了防止**选择偏倚（selection bias）**。如果负责招募参与者的研究者能够预知下一个分配结果（例如，看到一张未被遮盖的分配列表），他们可能会有意识或无意识地影响哪些患者在哪个时间点入组。例如，当预知到下一个分配是试验药物时，研究者可能会推迟一位低风险患者的入组，而优先招募一位预后较差（如基线心血管风险评分$S$较高）的患者，期望新药能带来更好效果。反之，当下一个分配是安慰剂时，则可能优先招募低风险患者。这种行为会系统性地破坏组间的基线可比性，使得治疗分配与预后因素之间产生关联，从而引入选择偏倚，使随机化形同虚设[@problem_id:4934243]。

有效的分配隐藏方法包括：使用中心化的、自动化的随机系统（如电话或网络随机化服务），或者使用按顺序编号的、不透光的、密封的信封（SNOSE）。分配隐藏的成败是衡量一项RCT质量的根本标准之一。

#### 盲法

与在分配时刻保护随机化过程的分配隐藏不同，**盲法（Blinding 或 Masking）**是指在随机分配完成**之后**，使试验的一方或多方（参与者、研究者/临床医生、结局评估者、数据分析者等）不知道参与者具体接受了何种治疗的措施。

根据设盲对象的不同，试验通常分为：
*   **开放标签（Open-label）**：所有相关方都知道治疗分配。
*   **单盲（Single-blind）**：通常指参与者不知情，但研究团队知情。
*   **双盲（Double-blind）**：通常指参与者和研究者/临床医生/结局评估者均不知情。

盲法主要用于预防两种发生于随机化之后的偏倚：
1.  **实施偏倚（Performance bias）**：由于知晓治疗分配，不同组的参与者或研究者在行为上产生系统性差异。例如，得知自己服用的是安慰剂的患者可能会寻求其他辅助治疗，或者在生活方式上不如服用试验药物的患者积极；而知情的医生也可能给予服用试验药物的患者更多的关注和辅助护理。通过对参与者和临床医生设盲，可以最大限度地减少这种偏倚。
2.  **探察偏倚（Detection bias或Ascertainment bias）**：由于知晓治疗分配，结局评估者在测量或记录结局时产生系统性差异。这种偏倚的风险在**主观性结局**（如患者报告的头晕严重程度评分）中尤为突出，评估者的提问方式或解读都可能受到其预期的影响。而对于**客观性结局**，尤其是由自动化仪器测量的结局（如自动[血压计](@entry_id:140497)测量的血压值），探察偏倚的风险相对较小，但并非完全不存在。对结局评估者设盲是控制探察偏倚的关键[@problem_id:4934260]。

值得注意的是，即使在设计良好的双盲试验中，也可能存在**破盲（unblinding）**的风险。如果试验药物具有明显的、安慰剂所没有的副作用（如独特的皮疹或显著的头晕），参与者和研究者可能能够猜出治疗分配。这种非预期的破盲会削弱盲法对实施偏倚和探察偏倚的控制作用。例如，由药物副作用差异导致的依从性差异或伴随用药差异，本身就是一种残留的实施偏倚[@problem_id:4934260]。

最后必须强调，分配隐藏和盲法是两个完全独立、互为补充的概念。分配隐藏防止的是入组时的选择偏倚，而盲法防止的是入组后的实施和探察偏倚。一项试验可以是双盲的，但如果分配隐藏做得不好，其结果依然会因选择偏倚而不可信[@problem_id:4934243]。

### 设计试验：终点、假设与统计误差

一项严谨的临床试验始于一个清晰、明确且可回答的科学问题。这需要通过仔细定义研究终点、构建恰当的统计假设以及预先设定可接受的错误率来实现。

#### 定义研究问题：终点

临床试验的**终点（endpoint）**是用于评估干预措施效果的量化指标。根据其在试验中的核心地位，终点可分为：
*   **主要终点（Primary endpoint）**：这是能够为试验的主要目的提供最可信、最直接证据的单一终点。整个试验的设计（如样本量估算）都围绕着主要终点进行。试验成功与否，主要基于主要终点的结果来判断。
*   **次要终点（Secondary endpoints）**：这些是预先设定的、用于提供支持性证据或评估干预措施其他效果的额外终点。它们有助于更全面地理解药物的作用，但其结论的确定性低于主要终点。
*   **探索性终点（Exploratory endpoints）**：这些终点用于产生新的科学假设，供未来研究验证。对探索性终点的分析结果不应用于形成确证性结论。

当一项试验计划评估多个终点时，就产生了**多重性（multiplicity）**问题。每次[假设检验](@entry_id:142556)都有一定概率犯“[假阳性](@entry_id:635878)”错误（即[I型错误](@entry_id:163360)）。如果对多个终点进行独立的统计检验，那么在整个试验中至少出现一次[假阳性](@entry_id:635878)结论的概率（即**总体I型错误率, family-wise error rate, FWER**）将会显著膨胀。例如，若对5个独立的真实零假设分别进行$\alpha=0.05$水平的检验，则FWER会高达$1 - (1-0.05)^5 \approx 0.23$。

为了维护试验结论的科学严谨性，监管机构要求确证性试验必须将FWER严格控制在预设的$\alpha$水平（通常是$0.05$）之内。这需要采用预先设定的[多重性](@entry_id:136466)校正策略。一种常见的策略是**分层检验（hierarchical testing）**或**门禁（gatekeeping）**程序。例如，研究方案可以预先规定：只有当主要终点达到统计学显著性时（即“第一道门”打开），才对第一个次要终点进行正式的[假设检验](@entry_id:142556)；以此类推。这种策略通过预设的检验顺序，有效地控制了FWER，同时允许在主要疗效得到证实的基础上，对次要疗效做出确证性声明[@problem_id:4934241]。至关重要的是，所有终点的层级、检验顺序和统计分析计划都必须在试验开始和揭盲**之前**就已在方案中明确规定，以防止数据驱动的“P值挖掘（p-hacking）”。

#### 构建假设与平衡误差

假设检验是临床试验数据分析的核心。这个过程涉及两类统计误差：
*   **I型错误（Type I error）**：当零假设（$H_0$）为真时，错误地拒绝了它。其概率用 $\alpha$ 表示。在药物试验中，这对应于“[假阳性](@entry_id:635878)”——即宣布一种无效的药物有效。
*   **[II型错误](@entry_id:173350)（Type II error）**：当备择假设（$H_1$）为真时，未能拒绝错误的零假设。其概率用 $\beta$ 表示。这对应于“假阴性”——即未能发现一种真正有效的药物。
*   **统计功效（Power）**：正确地拒绝一个错误的零假设的概率，即功效 = $1 - \beta$。它代表了试验检测到预设大小的真实效应的能力。

在药物研发的监管实践中，对这两类错误的权衡至关重要。从公共卫生的角度看，批准一种无效甚至有害的药物上市（I型错误）的后果，通常被认为比未能批准一种有效药物（II型错误）更为严重。因此，监管机构对[I型错误](@entry_id:163360)率的控制极为严格，全球公认的标准是，对于确证性试验的单个主要终点，双侧检验的 $\alpha$ 水平应控制在 $0.05$。

与此同时，为了避免因试验规模不足而频繁错失有价值的新药，试验也必须具备足够的[统计功效](@entry_id:197129)。行业和监管机构普遍接受的最低功效标准是 $0.80$（即$\beta=0.20$），而 $0.90$ 或更高的功效在实践中也越来越常见。$\alpha=0.05$ 和 $\beta=0.20$ 的常规组合，隐含了一种价值判断，即一个[假阳性](@entry_id:635878)错误的严重性是假阴性错误的4倍（$\beta/\alpha = 0.20/0.05 = 4$）。

对于给定的效应大小和数据变异性，$\alpha$、功效和样本量三者之间是相互关联的。在样本量固定的情况下，降低 $\alpha$（如从$0.05$降至$0.01$）会使检验更严格，但这将以牺牲功效（即增加$\beta$）为代价。反之，提高 $\alpha$ 会增加功效，但会带来不可接受的更高[假阳性](@entry_id:635878)风险。因此，保证足够功效的正确途径是招募充足的样本量，而非放宽对I型错误的控制[@problem_id:4934251]。

#### 试验目标与相应的假设

根据研究目的的不同，与活性药物对照的试验通常可分为三种主要设计类型，其假设检验的构建方式也各不相同。设 $\theta = \mu_T - \mu_C$ 为试验药（T）与对照药（C）在某个疗效指标上的平均效应差异，$\theta > 0$ 表示试验药更优。

1.  **优效性试验（Superiority Trial）**
    *   **目标**：证明试验药优于对照药。
    *   **假设**：待证明的结论是备择假设 $H_1: \theta > 0$。零假设 $H_0$ 则是其反面，即试验药不优于对照药，$H_0: \theta \le 0$。我们需要收集足够的证据来拒绝 $H_0$。

2.  **非劣效性试验（Non-inferiority Trial）**
    *   **目标**：证明试验药的效果不比对照药差太多。这个“太多”由一个预先设定的**非劣效界值（non-inferiority margin）** $\Delta_{\mathrm{NI}}$ 来定义。该界值代表了临床上可以接受的最大疗效损失。$\Delta_{\mathrm{NI}}$ 的选择必须有充分的临床和历史数据依据。
    *   **假设**：待证明的结论（$H_1$）是试验药并非劣于对照药，即疗效差异 $\theta$ 大于负的界值， $H_1: \theta > -\Delta_{\mathrm{NI}}$。其零假设（$H_0$）则是试验药确实劣于对照药，即 $\theta \le -\Delta_{\mathrm{NI}}$。这是一个单侧的[假设检验](@entry_id:142556)，因为我们只关心疗效损失是否在可接受范围内；如果试验药碰巧优于对照药（$\theta > 0$），那更是理想的结果。

3.  **等效性试验（Equivalence Trial）**
    *   **目标**：证明试验药和对照药的疗效在临床上没有差别，即它们的效应差异在一个预先设定的、对称的**等效性界值（equivalence margin）** $[-\Delta_{\mathrm{EQ}}, \Delta_{\mathrm{EQ}}]$ 之内。
    *   **假设**：待证明的结论（$H_1$）是效应差异落在等效区间内，即 $|\theta|  \Delta_{\mathrm{EQ}}$。其零假设（$H_0$）则是效应差异在区间之外，即 $|\theta| \ge \Delta_{\mathrm{EQ}}$。在实践中，这通常通过**双[单侧检验](@entry_id:170263)程序（Two One-Sided Tests, TOST）**来完成：研究者必须同时拒绝两个零假设，$H_{01}: \theta \le -\Delta_{\mathrm{EQ}}$ 和 $H_{02}: \theta \ge \Delta_{\mathrm{EQ}}$，才能宣称等效。

正确区分并构建这三种试验的假设，对于试验设计和结果的正确解读至关重要[@problem_id:4934253]。

### 分析与解读试验数据

试验的设计和实施是为了产生高质量的数据，而从数据中提炼出可靠结论则依赖于恰当的分析原则和方法。

#### 定义分析人群

随机化赋予了试验独特的优势，但只有在分析时保持这种优势，结论才是可靠的。分析人群的选择直接关系到研究结果的解释。
*   **意向性治疗（Intention-to-Treat, ITT）分析**：这是RCT分析的黄金标准。ITT原则要求，所有被随机化的参与者都应被纳入其最初被分配的治疗组进行分析，无论他们是否真正接受了该治疗、是否完成了治疗方案，或者是否发生了方案偏离。ITT分析的核心思想是“按随机分组意向分析（analyze as you randomize）”。这样做最大限度地保留了随机化带来的基线可比性，避免了因治疗后事件（如因副作用停药）导致的偏倚。ITT分析得到的结果反映了将患者“意向”分配到某个治疗策略下的实际效果，这是一种更贴近临床实践的、**务实的（pragmatic）**估计。
*   **符合方案集（Per-Protocol, PP）分析**：PP分析只包括那些严格遵守了试验方案的参与者（例如，接受了规定剂量的药物、依从性良好且没有重大方案偏离）。这种分析可能会因为排除了特定参与者而引入偏倚，因为它破坏了随机化建立的组间可比性。然而，PP分析可以提供关于药物在理想条件下“生理学”效应的信息。
*   **改良的意向性治疗（Modified ITT, mITT）分析**：这是一个宽泛的术语，通常指对ITT人群进行了一些小的、预先定义的排除（例如，排除了随机化后从未接受过任何一次治疗的参与者）。任何mITT的定义和其合理性都必须在方案中预先明确。

现代临床试验设计越来越多地采用**研究目标（estimand）**框架（如ICH E9(R1)附录所倡导），它要求研究者精确定义“待估计的量”。一个完整的estimand包括：目标人群、目标变量、如何处理“中途事件”（如停药或使用补救治疗）的策略，以及汇总度量。当estimand采用**“治疗策略”（treatment policy）**来处理中途事件时，其目标是评估“无论后续依从性或停药如何，启动某项治疗策略的效应”。这种estimand与ITT分析原则完美契合[@problem_id:4934277]。

#### 处理缺失数据

在长期临床试验中，部分参与者可能因各种原因失访，导致其主要终点数据缺失。缺失数据的处理是试验分析中的一个关键挑战，因为不当的处理会引入严重偏倚。根据缺失发生的机制，可分为三类：
*   **[完全随机缺失](@entry_id:170286)（Missing Completely At Random, MCAR）**：缺失的发生与任何已观测或未观测的数据都无关。即缺失概率 $P(R=1 \mid Y, X, A)$ 是一个常数，其中$R=1$表示数据被观测到，$Y$是结局，$X$是协变量，$A$是治疗。这是最强的假设，但在现实中很少成立。
*   **[随机缺失](@entry_id:168632)（Missing At Random, MAR）**：缺失的发生仅与已观测的数据（如基线特征$X$、已有的中期测量值等）有关，而与[缺失数据](@entry_id:271026)$Y$本身的值无关。即 $P(R=1 \mid Y, X, A) = P(R=1 \mid X, A)$。这是一个比MCAR更弱、在某些情况下也更合理的假设。
*   **[非随机缺失](@entry_id:163489)（Missing Not At Random, MNAR）**：缺失的发生与[缺失数据](@entry_id:271026)本身的值有关，即使在控制了所有已观测数据之后依然如此。例如，血压控制得最差的患者可能因为感觉药物无效而停止访视。这是最难处理的情况。

这些机制对分析方法的影响巨大。一种简单的**仅限完整病例分析（complete-case analysis）**，即只分析数据完整的参与者，其无偏性高度依赖于缺失机制：
*   在**MCAR**下，完整病例是全体随机化人群的一个随机子样本，因此完整病例分析是无偏的。
*   在**MAR**下，由于缺失与协变量$X$相关，完整病例人群中$X$的分布会发生改变，导致简单的完整病例分析通常是**有偏的**。但是，如果采用基于完整病例的、能够正确调整这些协变量$X$的[统计模型](@entry_id:755400)（如[回归模型](@entry_id:163386)），则有可能得到无偏的估计。
*   在**MNAR**下，由于缺失与结局值本身相关，完整病例分析（无论是否调整）通常都是**有偏的**。处理MNAR需要更复杂的模型和无法被数据验证的额外假设[@problem_id:4934297]。

在实践中，多重填补（multiple imputation）等基于MAR假设的复杂统计方法，已成为处理[缺失数据](@entry_id:271026)的标准方法。

#### 综合证据：系统评价与Meta分析

循证医学不仅依赖于单项试验的结果，更强调对某一临床问题所有相关证据的系统性综合。**系统评价（Systematic Review）**是这一过程的核心工具。它采用预先设定的、明确的标准和可重复的方法，全面地检索、筛选、评价和综合所有与特定研究问题相关的合格研究。

当多项研究的结果可以进行定量合并时，系统评价中就会包含**Meta分析（Meta-analysis）**。这是一种统计技术，用于将来自不同研究的效应估计值融合成一个更精确、更稳健的汇总估计。进行Meta分析的关键步骤包括：
1.  **选择效应度量**：对于[二分类](@entry_id:142257)结局（如事件发生/未发生），常用的效应度量包括**风险比（Risk Ratio, RR）**、**比值比（Odds Ratio, OR）**或**风险差（Risk Difference, RD）**。当各研究的基线风险不同时，相对度量（RR或OR）通常比绝对度量（RD）更具同质性。
2.  **选择分析尺度**：比值度量（RR、OR）的[统计分布](@entry_id:182030)通常是[偏态](@entry_id:178163)的。通过对数转换（如 $\ln(RR)$），其[抽样分布](@entry_id:269683)更接近正态分布，方差也更稳定。因此，合并过程通常在对数尺度上进行。
3.  **权重分配**：Meta分析并非简单地对各研究结果取平均。为了得到最精确的汇总估计，每个研究的效应量都应根据其精度进行加权。标准的**反方差加权（inverse-variance weighting）**方法给予更精确的研究（通常是样本量更大、事件数更多的研究）更大的权重。研究 $i$ 的权重 $w_i$ 等于其效应量估计方差的倒数，即 $w_i = 1 / v_i$。
4.  **评估异质性**：**异质性（heterogeneity）**指不同研究的真实效应量存在差异。在合并结果之前，必须评估研究间的异质性。常用的统计量包括Cochran's [Q检验](@entry_id:182379)和$I^2$统计量。$I^2$表示总变异中由研究间真实差异所占的百分比。
5.  **选择模型**：如果异质性很小（例如$I^2$接近0），可以使用**[固定效应模型](@entry_id:142997)（fixed-effect model）**，该模型假设所有研究估计的是同一个真实的效应量。如果存在显著的异质性，则应使用**随机效应模型（random-effects model）**，该模型假设各研究的真实效应量在一个分布中波动，并在权重计算中同时考虑了研究内和研究间的变异。

让我们通过一个例子来阐明这个过程。假设有三项RCT评估了药物X相对于安慰剂预防心血管事件的有效性。通过对每项试验计算其对数风险比 $\ln(RR_i)$ 及其方差 $v_i$，并计算出权重 $w_i = 1/v_i$。在检验发现研究间异质性很低后，我们可以使用[固定效应模型](@entry_id:142997)计算汇总的对数风险比：
$$ \ln(RR_{\text{pooled}}) = \frac{\sum w_i \ln(RR_i)}{\sum w_i} $$
然后，通过指数转换得到汇总的风险比 $RR_{\text{pooled}} = \exp(\ln(RR_{\text{pooled}}))$，并计算其95%[置信区间](@entry_id:138194)。这个汇总的效应估计值，综合了所有可用证据，为临床决策提供了比任何单项研究都更可靠的依据[@problem_id:4934234]。