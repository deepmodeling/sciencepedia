{"hands_on_practices": [{"introduction": "在构建定量构效关系（QSPR）模型时，一个关键的初始步骤是特征工程。机器学习算法，特别是线性模型或基于距离的模型，其性能可能会受到输入特征尺度的巨大影响。本练习 [@problem_id:4563981] 将指导您处理一个常见场景：标准化具有不同物理单位和数值范围的理化描述符，例如酸度系数（$pK_a$）、分配系数（$\\log_{10} P$）和极性表面积（PSA）。通过从第一性原理推导并应用Z-score变换，您将掌握确保模型不会因特征尺度差异而产生隐性偏差的基本技能。", "problem": "临床药理学中的一项定量构效关系建模任务使用机器学习（ML）和人工智能（AI）根据理化描述符来预测血浆中的未结合分数。考虑了三个描述符：酸解离常数（$pK_{a}$）、辛醇-水分配系数（$\\log_{10} P$）和极性表面积（PSA）。经过常规整理后，该模型的训练数据集包含的分子，其描述符分量近似呈单峰和对称分布。您需要构建一个归一化方案，使下游的线性模型能够在可比较的尺度上处理每个描述符，从而避免因单位和范围不同而产生的隐式加权。\n\n从样本均值和样本标准差的核心定义以及随机变量仿射变换的一般原理开始。通过检查 $pK_{a}$（无量纲对数常数）、$\\log_{10} P$（无量纲对数比）和 PSA（以平方埃 $\\text{\\AA}^{2}$ 为单位的面积）的物理单位和典型范围，解释为什么将每个描述符分量中心化和缩放至无量纲的零均值和单位方差的变换方法对于药物发现和开发中的许多机器学习算法是合适的。然后，从第一性原理出发，推导出将任何描述符分量映射到训练集均值为零和训练集方差为一的仿射变换。\n\n现提供训练集的汇总统计数据和一个新化合物的描述符向量：\n- 训练集均值：$\\mu_{pK_{a}} = 6.80$，$\\mu_{\\log_{10} P} = 2.50$，$\\mu_{\\mathrm{PSA}} = 85.0$（PSA单位为 $\\text{\\AA}^{2}$）。\n- 训练集标准差：$\\sigma_{pK_{a}} = 1.20$，$\\sigma_{\\log_{10} P} = 1.10$，$\\sigma_{\\mathrm{PSA}} = 30.0$（PSA单位为 $\\text{\\AA}^{2}$）。\n- 新化合物描述符：$x_{pK_{a}} = 7.40$, $x_{\\log_{10} P} = 3.20$, $x_{\\mathrm{PSA}} = 78.0$（PSA单位为 $\\text{\\AA}^{2}$）。\n\n将您推导出的变换逐分量地应用于新化合物的描述符向量，以获得一个标准化的行向量。将每个分量四舍五入到四位有效数字。将最终的标准化向量表示为一个行矩阵。标准化后的分量是无量纲的；在最终表达式中不要包含单位。", "solution": "问题陈述经过了严格验证，被认为是有效的。它在科学上基于定量构效关系（QSPR）建模、临床药理学和机器学习等领域。该问题提法恰当、客观、自成体系，并描述了计算药物发现中的一个标准、现实的任务。所有必要的数据均已提供，不存在内部矛盾或不科学的前提。\n\n任务是论证并推导一个针对理化描述符的归一化方案，并将其应用于一个新的数据点。这些描述符是酸解离常数（$pK_{a}$）、辛醇-水分配系数（$\\log_{10} P$）和极性表面积（PSA）。它们被用来预测药物在血浆中的未结合分数。由于使用了下游的线性模型，因此有必要采用这样的方案。\n\n线性模型的预测值 $\\hat{y}$ 是输入特征 $x_i$ 的加权和：\n$$\n\\hat{y} = \\beta_0 + \\sum_{i=1}^{d} \\beta_i x_i\n$$\n其中 $d$ 是描述符的数量，系数 $\\beta_i$ 是从训练数据中学习得到的。系数 $\\beta_i$ 的大小取决于其对应特征 $x_i$ 的尺度。如果特征的尺度差异很大，系数就无法直接比较来衡量特征的重要性。此外，许多用于寻找最优系数的算法（例如基于梯度下降的算法）在特征处于相似尺度时收敛得更快。\n\n让我们检查一下所提供的描述符及其训练集统计数据：\n1.  $pK_a$：一个无量纲的对数常数，均值为 $\\mu_{pK_{a}} = 6.80$，标准差为 $\\sigma_{pK_{a}} = 1.20$。\n2.  $\\log_{10} P$：一个无量纲的对数比，均值为 $\\mu_{\\log_{10} P} = 2.50$，标准差为 $\\sigma_{\\log_{10} P} = 1.10$。\n3.  PSA：一个以平方埃（$\\text{\\AA}^{2}$）为单位测量的面积，均值为 $\\mu_{\\mathrm{PSA}} = 85.0 \\, \\text{\\AA}^{2}$，标准差为 $\\sigma_{\\mathrm{PSA}} = 30.0 \\, \\text{\\AA}^{2}$。\n\nPSA的数值范围比 $pK_{a}$ 和 $\\log_{10} P$ 大一个数量级。例如，PSA的均值（$85.0$）与另外两个描述符的均值（$6.80$ 和 $2.50$）差异巨大。$pK_{a}$ 中 $1.0$ 个单位的变化代表分子电离状态的显著变化，而 PSA 中 $1.0 \\, \\text{\\AA}^{2}$ 的变化仅是其表面性质的微小改变。线性模型会仅仅因为 PSA 较大的数值而对其变化不成比例地敏感，从而导致隐式的、不希望出现的加权。\n\n为了缓解这个问题，我们必须将特征转换到一个共同的尺度上。标准方法，即标准化或Z-score归一化，是将每个特征转换为均值为 $0$、方差为 $1$。这种转换在这里特别合适，因为问题陈述中提到描述符的分布是“近似单峰和对称的”，这意味着均值和标准差是描述数据中心和离散程度的有意义的统计量。由此得到的标准化特征是无量纲的，使它们可以直接比较。\n\n我们现在将从第一性原理推导所需的仿射变换。变量 $x$ 的仿射变换形式为 $z = ax + b$，其中 $a$ 和 $b$ 是常数。设 $X$ 是一个代表描述符的随机变量，其均值为 $E[X] = \\mu$，标准差为 $\\mathrm{StdDev}[X] = \\sigma$。我们寻求一个变换，将 $X$ 映射到一个新变量 $Z = aX + b$，使得 $E[Z] = 0$ 且 $\\mathrm{StdDev}[Z] = 1$。\n\n使用期望的性质，变换后变量的均值为：\n$$\nE[Z] = E[aX + b] = aE[X] + b = a\\mu + b\n$$\n为了使新的均值为零，我们必须有：\n$$\na\\mu + b = 0 \\implies b = -a\\mu\n$$\n使用方差的性质，变换后变量的方差为：\n$$\n\\mathrm{Var}(Z) = \\mathrm{Var}(aX + b) = a^2\\mathrm{Var}(X) = a^2\\sigma^2\n$$\n标准差是方差的平方根，$\\sigma_Z = \\sqrt{\\mathrm{Var}(Z)}$。由于我们要求新的标准差为 $1$，我们有：\n$$\n\\sigma_Z = \\sqrt{a^2\\sigma^2} = |a|\\sigma = 1\n$$\n假设描述符不是常数（$\\sigma > 0$），我们可以解出 $a$。按照惯例，我们选择正解，$a = \\frac{1}{\\sigma}$。\n\n将 $a$ 的这个表达式代入 $b$ 的方程中：\n$$\nb = -a\\mu = -\\frac{1}{\\sigma}\\mu = -\\frac{\\mu}{\\sigma}\n$$\n因此，将原始分布中的数据点 $x$ 映射到标准化值 $z$ 的仿射变换是：\n$$\nz = ax + b = \\left(\\frac{1}{\\sigma}\\right)x - \\frac{\\mu}{\\sigma} = \\frac{x - \\mu}{\\sigma}\n$$\n当此变换应用于特定描述符时，它使用从训练集中计算出的均值 $\\mu$ 和标准差 $\\sigma$。\n\n我们现在将此变换逐分量地应用于新化合物的描述符向量 $(x_{pK_{a}}, x_{\\log_{10} P}, x_{\\mathrm{PSA}}) = (7.40, 3.20, 78.0)$。训练集的统计数据如下：\n$\\mu_{pK_{a}} = 6.80$, $\\sigma_{pK_{a}} = 1.20$\n$\\mu_{\\log_{10} P} = 2.50$, $\\sigma_{\\log_{10} P} = 1.10$\n$\\mu_{\\mathrm{PSA}} = 85.0$, $\\sigma_{\\mathrm{PSA}} = 30.0$\n\n设标准化向量为 $(z_{pK_{a}}, z_{\\log_{10} P}, z_{\\mathrm{PSA}})$。\n\n1.  对于 $pK_a$：\n    $$\n    z_{pK_{a}} = \\frac{x_{pK_{a}} - \\mu_{pK_{a}}}{\\sigma_{pK_{a}}} = \\frac{7.40 - 6.80}{1.20} = \\frac{0.60}{1.20} = 0.5\n    $$\n    四舍五入到四位有效数字，结果是 $0.5000$。\n\n2.  对于 $\\log_{10} P$：\n    $$\n    z_{\\log_{10} P} = \\frac{x_{\\log_{10} P} - \\mu_{\\log_{10} P}}{\\sigma_{\\log_{10} P}} = \\frac{3.20 - 2.50}{1.10} = \\frac{0.70}{1.10} \\approx 0.636363...\n    $$\n    四舍五入到四位有效数字，结果是 $0.6364$。\n\n3.  对于 PSA：\n    $$\n    z_{\\mathrm{PSA}} = \\frac{x_{\\mathrm{PSA}} - \\mu_{\\mathrm{PSA}}}{\\sigma_{\\mathrm{PSA}}} = \\frac{78.0 - 85.0}{30.0} = \\frac{-7.0}{30.0} \\approx -0.233333...\n    $$\n    四舍五入到四位有效数字，结果是 $-0.2333$。\n\n新化合物的最终标准化描述符向量是 $(0.5000, 0.6364, -0.2333)$。这表示为一个行矩阵。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.5000  0.6364  -0.2333\n\\end{pmatrix}\n}\n$$", "id": "4563981"}, {"introduction": "在药物发现等高风险领域，一个机器学习模型的预测准确性固然重要，但其预测概率的可靠性同样至关重要。一个“校准良好”的模型所输出的概率能够真实反映事件发生的可能性，例如，对于所有被模型赋予80%毒性概率的化合物，其真实的毒性发生率也应接近80%。本练习 [@problem_id:4563969] 介绍期望校准误差（Expected Calibration Error, ECE）这一关键指标，并引导您亲手计算它，从而量化评估一个毒性预测模型的概率输出是否值得信赖。", "problem": "一个临床药理学小组正在利用人工智能（AI）中的机器学习（ML）技术，通过预测候选化合物引起药物性肝损伤的概率，来支持早期药物开发决策。一个概率分类器为每个化合物 $i$ 输出一个预测概率 $p_i \\in [0,1]$，该概率对应于表示临床上显著肝毒性的事件 $Y_i=1$。在一个大小为 $N$ 的留出评估队列中，该团队通过一个可靠性图来评估预测概率的校准度，该图将概率范围划分为 $M$ 个不相交的区间 $\\{B_m\\}_{m=1}^{M}$。\n\n作为一个基本原则，完美校准被定义为：对于任何概率水平 $p \\in [0,1]$，真实的条件事件概率等于预测概率，即 $\\mathbb{P}(Y=1 \\mid p_i = p) = p$。在实践中，人们通过将预测分箱，并在每个区间 $B_m$ 内比较经验事件率与该区间内的平均预测概率，来近似这一条件。令 $n_m$ 表示落入区间 $B_m$ 的预测数量，$\\operatorname{acc}(m)$ 表示区间 $B_m$ 内的经验事件率（即 $\\operatorname{acc}(m) = \\frac{1}{n_m}\\sum_{i \\in B_m} y_i$），$\\operatorname{conf}(m)$ 表示区间 $B_m$ 内的平均预测概率（即 $\\operatorname{conf}(m) = \\frac{1}{n_m}\\sum_{i \\in B_m} p_i$）。\n\n从上述校准原则以及测量经验事件率与平均预测概率之间的期望绝对偏差（跨区间聚合，并按经验区间频率加权）的概念出发，完成以下任务：\n- 推导期望校准误差（ECE）的封闭形式表达式，该表达式是 $M$、$\\{n_m\\}_{m=1}^{M}$、$\\{\\operatorname{acc}(m)\\}_{m=1}^{M}$、$\\{\\operatorname{conf}(m)\\}_{m=1}^{M}$ 和 $N$ 的函数。\n- 使用你的表达式，为从 $N = 1000$ 个预测和 $M = 8$ 个区间获得的以下校准直方图计算 ECE 的数值：\n\n区间摘要 (对于 $m = 1,\\dots,8$):\n- 区间 1：$n_1 = 90$，$\\operatorname{conf}(1) = 0.07$，$\\operatorname{acc}(1) = 0.05$。\n- 区间 2：$n_2 = 110$，$\\operatorname{conf}(2) = 0.18$，$\\operatorname{acc}(2) = 0.14$。\n- 区间 3：$n_3 = 130$，$\\operatorname{conf}(3) = 0.31$，$\\operatorname{acc}(3) = 0.28$。\n- 区间 4：$n_4 = 170$，$\\operatorname{conf}(4) = 0.43$，$\\operatorname{acc}(4) = 0.47$。\n- 区间 5：$n_5 = 180$，$\\operatorname{conf}(5) = 0.57$，$\\operatorname{acc}(5) = 0.52$。\n- 区间 6：$n_6 = 150$，$\\operatorname{conf}(6) = 0.69$，$\\operatorname{acc}(6) = 0.62$。\n- 区间 7：$n_7 = 110$，$\\operatorname{conf}(7) = 0.80$，$\\operatorname{acc}(7) = 0.74$。\n- 区间 8：$n_8 = 60$，$\\operatorname{conf}(8) = 0.92$，$\\operatorname{acc}(8) = 0.86$。\n\n将最终的 ECE 表示为一个无量纲数，并四舍五入到三位有效数字。", "solution": "所述问题在科学上是合理的、自洽的且提法得当。所提供的数据是内部一致的，因为每个区间中预测数量的总和 $\\sum_{m=1}^{M} n_m$ 等于总队列大小 $N$。具体来说，$\\sum_{m=1}^{8} n_m = 90 + 110 + 130 + 170 + 180 + 150 + 110 + 60 = 1000 = N$。所有提供的值都在其有效范围内。因此，可以推导出解决方案。\n\n任务的第一部分是根据其定义推导期望校准误差（ECE）的封闭形式表达式。问题将ECE描述为“经验事件率与平均预测概率之间的期望绝对偏差，跨区间聚合，并按经验区间频率加权”。我们将逐步形式化这个描述。\n\n设有 $M$ 个不相交的区间，记为 $\\{B_m\\}_{m=1}^{M}$。\n对于每个区间 $B_m$，我们已知：\n- 区间中的预测数量：$n_m$。\n- 经验事件率或准确率：$\\operatorname{acc}(m) = \\frac{1}{n_m}\\sum_{i \\in B_m} y_i$，其中 $y_i \\in \\{0, 1\\}$ 是预测 $i$ 的真实结果。\n- 平均预测概率或置信度：$\\operatorname{conf}(m) = \\frac{1}{n_m}\\sum_{i \\in B_m} p_i$，其中 $p_i \\in [0,1]$ 是预测 $i$ 的预测概率。\n\n总预测数量为 $N = \\sum_{m=1}^{M} n_m$。\n\n让我们来转换ECE的定义：\n1.  单个区间 $B_m$ 的“经验事件率与平均预测概率之间的绝对偏差”由绝对差 $|\\operatorname{acc}(m) - \\operatorname{conf}(m)|$ 给出。\n2.  该量必须“跨区间聚合”并“按经验区间频率加权”。区间 $B_m$ 的经验频率是落入此区间的总预测的比例，即 $\\frac{n_m}{N}$。\n3.  聚合是所有区间的加权和。在这种分箱估计器的背景下，ECE中的“期望”一词指的是对有限样本的这种加权平均。\n\n结合这些部分，得到ECE的表达式：\n$$\n\\text{ECE} = \\sum_{m=1}^{M} \\frac{n_m}{N} |\\operatorname{acc}(m) - \\operatorname{conf}(m)|\n$$\n这就是所要求的期望校准误差的封闭形式表达式。\n\n任务的第二部分是使用提供的 $N = 1000$ 个预测和 $M = 8$ 个区间的数据来计算 ECE 的数值。我们将计算每个区间对总 ECE 的贡献，然后将它们相加。区间 $m$ 的贡献是 $\\frac{n_m}{N} |\\operatorname{acc}(m) - \\operatorname{conf}(m)|$。\n\n- 对于区间 $m=1$：$\\frac{90}{1000} |0.05 - 0.07| = 0.09 \\times |-0.02| = 0.09 \\times 0.02 = 0.0018$。\n- 对于区间 $m=2$：$\\frac{110}{1000} |0.14 - 0.18| = 0.11 \\times |-0.04| = 0.11 \\times 0.04 = 0.0044$。\n- 对于区间 $m=3$：$\\frac{130}{1000} |0.28 - 0.31| = 0.13 \\times |-0.03| = 0.13 \\times 0.03 = 0.0039$。\n- 对于区间 $m=4$：$\\frac{170}{1000} |0.47 - 0.43| = 0.17 \\times |0.04| = 0.17 \\times 0.04 = 0.0068$。\n- 对于区间 $m=5$：$\\frac{180}{1000} |0.52 - 0.57| = 0.18 \\times |-0.05| = 0.18 \\times 0.05 = 0.0090$。\n- 对于区间 $m=6$：$\\frac{150}{1000} |0.62 - 0.69| = 0.15 \\times |-0.07| = 0.15 \\times 0.07 = 0.0105$。\n- 对于区间 $m=7$：$\\frac{110}{1000} |0.74 - 0.80| = 0.11 \\times |-0.06| = 0.11 \\times 0.06 = 0.0066$。\n- 对于区间 $m=8$：$\\frac{60}{1000} |0.86 - 0.92| = 0.06 \\times |-0.06| = 0.06 \\times 0.06 = 0.0036$。\n\n现在，我们将这些单独的贡献相加，以求得总 ECE：\n$$\n\\text{ECE} = 0.0018 + 0.0044 + 0.0039 + 0.0068 + 0.0090 + 0.0105 + 0.0066 + 0.0036\n$$\n$$\n\\text{ECE} = 0.0466\n$$\n问题要求最终答案四舍五入到三位有效数字。计算出的值为 $0.0466$。该值有三位有效数字（4、6、6），因此无需进一步舍入。", "answer": "$$\\boxed{0.0466}$$", "id": "4563969"}, {"introduction": "机器学习模型常被批评为“黑箱”，因为它们的决策过程不透明，这在需要高度信任和科学严谨性的临床药理学中是一个重大障碍。模型可解释性技术旨在打开这个“黑箱”，解释模型为何做出特定预测。本练习 [@problem_id:4563996] 聚焦于一种强大的、有坚实理论基础的方法——SHAP（Shapley Additive exPlanations）。您将通过一个简化的线性模型案例，推导并计算SHAP值，从而直观地理解如何将一个模型的预测分解为各个输入特征的贡献。", "problem": "一个临床药理学小组使用线性代理模型，基于物理化学描述符来预测口服小分子的成人肝清除率。设模型输出的清除率为 $f(x)$，单位为 $\\mathrm{L/h}$，其中描述符向量 $x \\in \\mathbb{R}^{3}$ 的分量为 $x_{1}$（pH $7.4$ 下的分配系数对数，$\\log P$）、$x_{2}$（分子量，单位为道尔顿）和 $x_{3}$（拓扑极性表面积，单位为 $\\text{\\AA}^{2}$）。该模型是带截距的线性模型，$f(x) = b + w^{\\top} x$，其中 $w \\in \\mathbb{R}^{3}$。\n\n为了解释模型输出，该小组采用了沙普利加性解释（Shapley Additive exPlanations, SHAP），其针对给定实例 $x$ 的定义遵循以下原则：\n- 局部准确性（可加性）：贡献度 $\\{\\phi_{j}\\}_{j=1}^{3}$ 和基线项 $\\phi_{0}$ 满足 $\\phi_{0} + \\sum_{j=1}^{3} \\phi_{j} = f(x)$，其中 $\\phi_{0} = \\mathbb{E}[f(X)]$ 是在 $X$ 的数据分布下的期望值。\n- 缺失性：在某个联盟中不存在的特征对该联盟的价值函数贡献为 $0$。\n- 一致性：如果模型的改变使得某个特征在所有联盟中的贡献都增加，那么该特征的贡献度不会减少。\n\n假设以下条件成立，这些条件在用于训练代理模型的描述符分布中得到了经验支持：\n- 描述符分布可分解，因此 $X_{1}$、$X_{2}$ 和 $X_{3}$ 是相互独立的。\n- 联盟价值函数是条件期望 $v(S) = \\mathbb{E}[f(X) \\mid X_{S} = x_{S}]$，适用于任何子集 $S \\subseteq \\{1,2,3\\}$。\n\n从 SHAP 公理和这些假设出发，推导 SHAP 贡献度 $\\phi_{j}$ 关于 $w_{j}$、$x_{j}$ 和 $\\mathbb{E}[X_{j}]$（对于 $j \\in \\{1,2,3\\}$）的闭式表达式，并说明 $\\phi_{0}$ 如何与 $b$、$w$ 和 $\\mathbb{E}[X]$ 相关。然后，对于一个特定的化合物，其描述符为 $x_{1} = 3.1$，$x_{2} = 420$ 和 $x_{3} = 60$，模型特征如下：\n- $w_{1} = 2.03$，$w_{2} = -0.01$，$w_{3} = -0.04$，\n- 截距 $b = 22.034$，\n- 描述符均值 $\\mathbb{E}[X_{1}] = 2.2$，$\\mathbb{E}[X_{2}] = 350$，$\\mathbb{E}[X_{3}] = 75$，\n\n计算 SHAP 贡献度 $\\phi_{1}$、$\\phi_{2}$、$\\phi_{3}$，基线值 $\\phi_{0}$ 以及预测的清除率 $f(x)$。仅报告最终预测的清除率（单位为 $\\mathrm{L/h}$）作为您的答案。将您的答案四舍五入到 $4$ 位有效数字，并以 $\\mathrm{L/h}$ 为单位表示该值。", "solution": "特征 $j$ 的 SHAP 值是其对输出的边际贡献在所有可能的特征联盟上的平均值。对于特征集 $F = \\{1, 2, \\dots, p\\}$，实例 $x$ 的 SHAP 值 $\\phi_j$ 为：\n$$ \\phi_j = \\sum_{S \\subseteq F \\setminus \\{j\\}} \\frac{|S|!(p - |S| - 1)!}{p!} [v(S \\cup \\{j\\}) - v(S)] $$\n此处，$v(S)$ 是联盟 $S$ 的价值函数，即在给定 $S$ 中特征值的条件下，模型的期望输出。题目说明使用条件期望 $v(S) = \\mathbb{E}[f(X) \\mid X_S = x_S]$。\n\n模型是线性的：$f(x) = b + \\sum_{i=1}^3 w_i x_i$。由于特征独立的假设，条件期望变为：\n$$ v(S) = \\mathbb{E}\\left[b + \\sum_{i=1}^3 w_i X_i \\mid X_S = x_S\\right] $$\n使用期望的线性性质：\n$$ v(S) = b + \\mathbb{E}\\left[\\sum_{i \\in S} w_i X_i \\mid X_S = x_S\\right] + \\mathbb{E}\\left[\\sum_{i \\notin S} w_i X_i \\mid X_S = x_S\\right] $$\n由于对于 $i \\in S$，$X_S = x_S$ 是给定的，而对于 $i \\notin S$，特征是独立的：\n$$ v(S) = b + \\sum_{i \\in S} w_i x_i + \\sum_{i \\notin S} w_i \\mathbb{E}[X_i] $$\n现在我们可以计算特征 $j \\notin S$ 的边际贡献 $[v(S \\cup \\{j\\}) - v(S)]$。\n$$ v(S \\cup \\{j\\}) = b + \\sum_{i \\in S \\cup \\{j\\}} w_i x_i + \\sum_{i \\notin S \\cup \\{j\\}} w_i \\mathbb{E}[X_i] $$\n$$ v(S \\cup \\{j\\}) = b + \\left(\\sum_{i \\in S} w_i x_i + w_j x_j\\right) + \\left(\\sum_{i \\notin S, i \\neq j} w_i \\mathbb{E}[X_i]\\right) $$\n而\n$$ v(S) = b + \\sum_{i \\in S} w_i x_i + \\left(w_j \\mathbb{E}[X_j] + \\sum_{i \\notin S, i \\neq j} w_i \\mathbb{E}[X_i]\\right) $$\n两者相减得到：\n$$ v(S \\cup \\{j\\}) - v(S) = (w_j x_j) - (w_j \\mathbb{E}[X_j]) = w_j(x_j - \\mathbb{E}[X_j]) $$\n这个边际贡献与联盟 $S$ 无关。这是具有独立特征的线性模型的一个关键特性。\n因此，SHAP 值 $\\phi_j$ 简化为：\n$$ \\phi_j = \\left( \\sum_{S \\subseteq F \\setminus \\{j\\}} \\frac{|S|!(p - |S| - 1)!}{p!} \\right) [w_j(x_j - \\mathbb{E}[X_j])] $$\n括号中的项是所有不包含特征 $j$ 的联盟的概率之和。沙普利公式中所有排列的权重之和为 1。因此，这个和也为 1。\n因此，我们得到简单的闭式表达式：\n$$ \\phi_j = w_j(x_j - \\mathbb{E}[X_j]) $$\n基线值 $\\phi_0$ 是模型的期望输出：\n$$ \\phi_0 = \\mathbb{E}[f(X)] = \\mathbb{E}\\left[b + \\sum_{j=1}^3 w_j X_j\\right] = b + \\sum_{j=1}^3 w_j \\mathbb{E}[X_j] = b + w^\\top \\mathbb{E}[X] $$\n现在，我们来计算给定问题的值。\n\n**给定数据：**\n- 模型权重: $w_1=2.03, w_2=-0.01, w_3=-0.04$\n- 截距: $b=22.034$\n- 特征值: $x_1=3.1, x_2=420, x_3=60$\n- 特征均值: $\\mathbb{E}[X_1]=2.2, \\mathbb{E}[X_2]=350, \\mathbb{E}[X_3]=75$\n\n首先，计算 SHAP 贡献度：\n- 对于特征 1 ($\\log P$): $\\phi_1 = w_1(x_1 - \\mathbb{E}[X_1]) = 2.03(3.1 - 2.2) = 2.03(0.9) = 1.827$\n- 对于特征 2 (分子量): $\\phi_2 = w_2(x_2 - \\mathbb{E}[X_2]) = -0.01(420 - 350) = -0.01(70) = -0.7$\n- 对于特征 3 (拓扑极性表面积): $\\phi_3 = w_3(x_3 - \\mathbb{E}[X_3]) = -0.04(60 - 75) = -0.04(-15) = 0.6$\n\n接着，计算基线值 $\\phi_0$：\n$$ \\phi_0 = b + w_1\\mathbb{E}[X_1] + w_2\\mathbb{E}[X_2] + w_3\\mathbb{E}[X_3] = 22.034 + 2.03(2.2) + (-0.01)(350) + (-0.04)(75) $$\n$$ \\phi_0 = 22.034 + 4.466 - 3.5 - 3.0 = 20.0 $$\n预测的清除率 $f(x)$ 可以通过两种方式计算以进行验证。\n\n1. 直接使用模型方程：\n$$ f(x) = b + w_1 x_1 + w_2 x_2 + w_3 x_3 = 22.034 + 2.03(3.1) + (-0.01)(420) + (-0.04)(60) $$\n$$ f(x) = 22.034 + 6.293 - 4.2 - 2.4 = 21.727 $$\n2. 使用 SHAP 的局部准确性属性：\n$$ f(x) = \\phi_0 + \\phi_1 + \\phi_2 + \\phi_3 = 20.0 + 1.827 + (-0.7) + 0.6 = 20.0 + 1.727 = 21.727 $$\n两种方法得出了相同的结果，证实了计算的正确性。\n\n最终预测的清除率为 $21.727 \\, \\mathrm{L/h}$。\n四舍五入到 4 位有效数字，答案为 $21.73 \\, \\mathrm{L/h}$。", "answer": "$$ \\boxed{21.73} $$", "id": "4563996"}]}