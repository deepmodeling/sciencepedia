{"hands_on_practices": [{"introduction": "在构建视觉预测检验（VPC）时，首要的关键决策之一是如何对数据进行分组或“分箱”。这个选择并非纯粹的技术操作，它能从根本上影响VPC结果的偏差和方差，从而决定了模型评估的可靠性。这项练习 [@problem_id:4601332] 旨在挑战您比较几种常见的分箱策略，并根据统计学原理和具体的数据特征，论证为何某种策略在特定场景下是最佳选择。", "problem": "在一个非线性混合效应药代动力学模型的视觉预测检验（VPC）中，您需要计算给定时间的观测浓度的分箱样本分位数，记为 $Q_{p}(t)$（其中 $p \\in \\{0.10, 0.50, 0.90\\}$），以便与模拟的预测区间进行比较。观测的采样时间 $t$呈强右偏分布：大约 $80\\%$ 的观测值位于 $t \\in [0,8]$ 小时内，具有密集的早期采样和多个方案驱动的时间点；而剩余的 $20\\%$ 位于 $t \\in (8,48]$ 小时内，采样更稀疏、不均匀且存在间隙。给定 $t$ 时浓度 $C$ 的条件分布是连续的，其分位数函数 $Q_{p}(t)$ 随 $t$ 平滑减小，在 $t$ 较小时下降更陡峭，在 $t$ 较大时则逐渐平坦。您必须为 $t$ 选择一种分箱策略，以计算VPC的分箱分位数估计，并使用 $B_{\\text{boot}}$ 次自助法重采样在每个箱内生成非参数自助法置信区间。\n\n考虑将 $t$ 轴划分为 $B$ 个箱的三种方法：\n- 等宽分箱：将 $t$ 的观测范围划分为 $B$ 个等长的区间。\n- 等计数分箱：将排序后的 $t$ 值划分为 $B$ 个相邻的箱，每个箱包含相同数量的观测值 $n_{b}$（最多有 $1$ 的舍入误差）。\n- 对 $t$ 进行 k-均值分箱：在标量 $t$ 上使用欧几里得距离和 $k=B$ 应用 k-均值聚类，将每个观测值分配到一个簇，并将每个簇在 $t$ 上的凸包作为一个箱。\n\n假设使用箱内非参数自助法重采样来量化分箱样本分位数的不确定性，重采样大小等于原始的箱内计数 $n_{b}$。仅使用分位数、混合分布以及样本分位数的大样本行为的基本性质，根据给定的 $t$ 和 $Q_{p}(t)$ 的分布特性，比较这三种分箱方法在分箱分位数估计量的偏差和方差以及自助法置信区间的稳定性方面的表现。哪种选择最适合此VPC，为什么？\n\n选择唯一的最佳选项。\n\nA. 等宽分箱最合适，因为每个箱具有相等的时间跨度，这既保证了分箱样本分位数的最小偏差，又保证了各箱间的方差近似相等，从而即使在 $t$ 右偏的情况下也能得到一致窄的自助法置信区间。\n\nB. 等计数分箱最合适，因为它使各箱的样本量 $n_{b}$ 均等，从而稳定了分箱分位数估计量及其自助法置信区间的方差；对于右偏的 $t$ 和在小 $t$ 处快速变化的 $Q_{p}(t)$，等计数分箱在早期会变得更窄（在曲率高的地方限制了偏差），在晚期会变得更宽（在曲率低的地方，保持偏差较小）。\n\nC. k-均值分箱最合适，因为它确保了 $t$ 上相等的箱宽和相等的箱内计数，同时最小化了分箱分位数的偏差和方差，并使自助法区间宽度均等。\n\nD. k-均值分箱最合适，因为在 $Q_{p}(t)$ 存在趋势的情况下，最小化 $t$ 的箱内平方距离直接最小化了分箱样本分位数的偏差，因此无论 $t$ 的偏度如何，都能在各箱间产生一致的方差和自助法区间宽度。", "solution": "目标是，在给定 $t$ 的强右偏分布以及一个在小 $t$ 处变化快、大 $t$ 处变化慢的平滑但非平稳的分位数函数 $Q_{p}(t)$ 的情况下，基于对分箱分位数估计量的偏差和方差以及对自助法置信区间稳定性的影响，比较用于视觉预测检验（VPC）的各种 $t$ 的分箱策略。\n\n我们从基本定义和经过充分检验的渐近结果出发：\n\n1. 分箱分位数目标及分箱所致偏差的定义。对于索引为 $b$ 的箱，其中 $t \\in I_{b}$，经验箱内分布为 $F_{t|b}$，箱内汇集的数据是从条件混合分布中抽取的样本：\n$$\nG_{b}(c) \\equiv \\int F_{C|t}(c \\mid t)\\,\\mathrm{d}F_{t|b}(t),\n$$\n其密度为\n$$\ng_{b}(c) \\equiv \\int f_{C|t}(c \\mid t)\\,\\mathrm{d}F_{t|b}(t).\n$$\n水平为 $p$ 的分箱样本分位数，记为 $\\widehat{Q}_{p,b}$，是混合分位数 $Q_{p,b}^{\\text{mix}}$ 的一个一致估计量，定义为 $G_{b}\\!\\left(Q_{p,b}^{\\text{mix}}\\right)=p$。用于可视化的科学相关目标是作为 $t$ 函数的逐点条件分位数 $Q_{p}(t)$。因此，如果 $Q_{p}(t)$ 在 $I_{b}$ 内变化，分箱就会引入偏差，因为对于 $I_{b}$ 中的一个通用 $t_{0}$，有 $Q_{p,b}^{\\text{mix}} \\neq Q_{p}(t_{0})$。对于小箱和平滑的 $Q_{p}(t)$，一阶近似表明偏差与 $t$ 的箱内变异以及 $Q_{p}(t)$ 的局部斜率或曲率成比例。因此，在 $|Q_{p}'(t)|$ 或 $|Q_{p}''(t)|$ 较大的地方使用更窄的箱可以减少偏差。\n\n2. 样本分位数的大样本方差。对于从一个在第 $p$ 个分位数 $Q_{p,b}^{\\text{mix}}$ 处密度 $g_{b}$ 为正的连续分布中抽取的 $n_{b}$ 个独立同分布样本，样本分位数的渐近方差满足经典结果\n$$\n\\mathrm{Var}\\!\\left(\\widehat{Q}_{p,b}\\right) \\approx \\frac{p(1-p)}{n_{b}\\,g_{b}\\!\\left(Q_{p,b}^{\\text{mix}}\\right)^{2}}.\n$$\n因此，对于固定的 $p$ 和各箱间相似的 $g_{b}\\!\\left(Q_{p,b}^{\\text{mix}}\\right)$，方差近似与 $1/n_{b}$ 成比例。因此，分箱样本量 $n_{b}$ 是各箱间方差异质性的主要驱动因素。每个箱内的非参数自助法重采样是对 $n_{b}$ 个观测值进行有放回的重采样，因此自助法分布和置信区间宽度主要反映了这种方差；小的 $n_{b}$ 会导致不稳定且宽的区间。\n\n3. $t$ 的箱内宽度（驱动偏差）与箱内计数 $n_{b}$（驱动方差）之间的权衡。在 $Q_{p}(t)$ 变化迅速的地方（小 $t$），控制偏差倾向于使用窄箱；在 $Q_{p}(t)$ 变化缓慢的地方（大 $t$），可以容忍更宽的箱而不会产生大的偏差。在 $t$ 稀疏的地方（大 $t$），等宽分箱可能会导致 $n_{b}$ 非常小，从而增大了方差并使自助法不稳定。\n\n在给定情景下：$t$ 呈强右偏，早期采样密集（$t \\in [0,8]$），晚期采样稀疏（$t \\in (8,48]$）。分位数函数 $Q_{p}(t)$ 在小 $t$ 处下降更陡峭，在大 $t$ 处趋于平坦。\n\n我们现在分析每种分箱方法。\n\n等宽分箱。等宽分箱对每个箱施加相同的时间跨度。在密集的早期区域，每个箱将包含许多观测值，因此 $n_{b}$ 会很大，$\\mathrm{Var}\\!\\left(\\widehat{Q}_{p,b}\\right)$ 会很小，从而产生窄的自助法区间。在稀疏的晚期区域，一些箱的 $n_{b}$ 会很小，增大了方差并加宽了自助法区间，如果 $n_{b}$ 对于极端分位数来说太小，甚至可能导致不稳定。关于偏差，等宽分箱统一控制了最大的箱内时间跨度；然而，由于 $Q_{p}(t)$ 在小 $t$ 处变化更快，对于固定的箱宽，那里的偏差仍然可能很可观，因为偏差是由 $|Q_{p}'(t)|$ 和 $|Q_{p}''(t)|$ 的大小驱动的。相比之下，在大 $t$ 处 $Q_{p}(t)$ 更平坦，等宽分箱产生的偏差较小。总的来说，由于 $t$ 的右偏分布，等宽分箱在各箱间产生了显著的方差异质性，导致晚期时间点的分位数和自助法区间具有高方差和不稳定性。这违背了在整个 $t$ 范围内获得稳定、可解释的VPC区间的目标。\n\n等计数分箱。等计数分箱强制使 $n_{b}$ 在各箱间几乎恒定，通过 $1/n_{b}$ 的缩放关系直接稳定了 $\\mathrm{Var}\\!\\left(\\widehat{Q}_{p,b}\\right)$，并导致自助法区间的宽度在整个 $t$ 范围内更加统一。因为 $t$ 在早期是密集的，所以等计数分箱在那里的 $t$ 宽度会很窄，这在 $Q_{p}(t)$ 变化迅速的地方减少了偏差。因为 $t$ 在晚期是稀疏的，等计数分箱会更宽，可能会增加偏差；然而，在所述情景中，$Q_{p}(t)$ 在大 $t$ 处趋于平坦，所以晚期时间点较宽箱带来的偏差惩罚被减弱了。净效应是：在关键地方（小 $t$）减少了偏差，在曲率低的地方（大 $t$）控制了偏差，并稳定了各箱间的方差和自助法区间宽度。\n\n对 $t$ 进行 k-均值分箱。在一维和欧几里得距离下，k-均值将 $t$ 划分为连续的区间（Voronoi 单元），其质心在观测值密集的地方更密集。这倾向于在密集的早期区域产生更窄的箱，在稀疏的晚期区域产生更宽的箱，这在性质上与等计数分箱的偏差控制相似。然而，k-均值不强制要求各箱计数 $n_{b}$ 相等，也不直接考虑 $Q_{p}(t)$ 或 $f_{C|t}$。因此，箱内样本量仍然可能变化，尤其是在 $t$ 存在间隙或簇的情况下，这会导致异质的方差和自助法区间宽度。此外，k-均值最小化的是 $t$ 的箱内平方距离，而不是直接最小化混合分位数的偏差；虽然减小 $t$ 的箱内离散度可以减少偏差，但当 $Q_{p}(t)$ 的曲率和采样密度以不同方式变化时，相对于等计数分箱，无法保证方差的稳定或偏差的最优性。\n\n综合分析。基本的方差关系 $\\mathrm{Var}\\!\\left(\\widehat{Q}_{p,b}\\right) \\approx p(1-p)/\\left(n_{b}\\,g_{b}\\!\\left(Q_{p,b}^{\\text{mix}}\\right)^{2}\\right)$ 凸显了 $n_{b}$ 是方差和自助法区间宽度的关键驱动因素。等计数分箱直接稳定了 $n_{b}$，其在 $t$ 上的自适应箱宽自然地匹配了在 $Q_{p}(t)$ 变化快的地方需要窄箱、在它平坦的地方需要宽箱的需求。等宽分箱在偏斜的 $t$ 分布下未能稳定方差，而 k-均值不保证相等的 $n_{b}$ 或统一的自助法稳定性。因此，对于给定的 $t$ 分布和 $Q_{p}(t)$ 行为，等计数分箱最好地平衡了偏差和方差。\n\n逐项分析：\n\nA. 声称等宽分箱在右偏的 $t$ 分布下既能产生最小偏差又能产生近似相等的箱间方差。这与方差随 $1/n_{b}$ 变化的规律相矛盾：等宽分箱在早期箱中产生大的 $n_{b}$，在晚期箱中产生小的 $n_{b}$，因此方差和自助法宽度是异质的。偏差并非统一最小，因为 $Q_{p}(t)$ 在小 $t$ 处变化迅速；固定的宽度可能在早期留下不可忽略的偏差。不正确。\n\nB. 指出等计数分箱稳定了 $n_{b}$，从而稳定了方差和自助法区间，并且较窄的早期箱在 $Q_{p}(t)$ 变化迅速的地方减少了偏差，而较宽的晚期箱在曲率低的地方产生的偏差较小。这与渐近方差关系和混合分布的偏差考虑相符。正确。\n\nC. 断言 k-均值确保了等宽和等计数。在一维 k-均值中，既不保证等宽也不保证等计数；计数和宽度会根据局部密度自适应，没有相等约束。因此，所述理由是错误的。不正确。\n\nD. 声称 k-均值直接最小化了分位数偏差，并无论偏度如何都能产生统一的方差和自助法宽度。k-均值最小化的是 $t$ 的箱内平方偏差，而不是分位数偏差，并且不保证相等的 $n_{b}$ 或统一的自助法宽度，尤其是在有偏斜的 $t$ 和间隙的情况下。不正确。\n\n因此，最合适的选择是等计数分箱。", "answer": "$$\\boxed{B}$$", "id": "4601332"}, {"introduction": "确定了VPC的设计策略后，下一步便是执行模拟。一个非常实际的问题随之而来：“需要多少次模拟或Bootstrap重复才能获得可靠的结果？”。此练习 [@problem_id:4601294] 将引导您从VPC的概念设计深入到其模拟过程的理论核心，推导蒙特卡洛误差如何随着重复次数 $B$ 的增加而减小。通过计算达到特定精度所需的 $B$ 值，您将对如何确保模拟结果的稳定性和可信度有更深刻的定量理解。", "problem": "在临床药理学中，对于群体药代动力学分析的视觉预测检验（VPC），假设使用一个模型在固定时间点 $t^{\\ast}$ 生成了 $B$ 次参数化自助法重复的预测药物浓度。对于给定的百分位数水平 $p \\in (0,1)$（例如，对于双侧 $95$ 置信区间，$p=0.025$ 或 $p=0.975$），在时间点 $t^{\\ast}$ 的自助法百分位置信区间（CI）端点是 $t^{\\ast}$ 时浓度预测分布的 $p$-分位数。设 $t^{\\ast}$ 时的真实累积分布函数为 $F(x)$，对应的概率密度函数为 $f(x)$，并设满足 $F(q_{p}) = p$ 的真实 $p$-分位数为 $q_{p}$。基于 $B$ 次重复的经验累积分布函数为 $F_{B}(x) = \\frac{1}{B} \\sum_{b=1}^{B} \\mathbf{1}\\{X_{b} \\leq x\\}$，其中 $X_{b}$ 表示在 $t^{\\ast}$ 时的第 $b$ 次自助法重复浓度，而经验 $p$-分位数（从 $B$ 次重复中估计的百分位置信区间端点）为 $\\hat{q}_{p}$，定义为 $F_{B}(\\hat{q}_{p}) = p$。\n\n仅从经验累积分布函数的二项方差和分位数函数的标准平滑性假设出发，推导百分位置信区间端点 $\\hat{q}_{p}$ 的蒙特卡洛误差关于 $B$ 的主阶渐近表达式，并证明其半宽度的缩放级别为 $\\mathcal{O}(B^{-1/2})$。然后，在置信水平为 $1-\\alpha$ 时，使用正态近似来处理 $\\hat{q}_{p}$ 的蒙特卡洛变异性，计算所需自助法重复次数 $B$ 的一个封闭形式表达式，以使 $\\hat{q}_{p}$ 的蒙特卡洛误差半宽度小于预设的容差 $\\epsilon > 0$。用 $p$、$f(q_{p})$、$\\epsilon$ 和标准正态分位数 $z_{1-\\alpha/2}$ 的符号形式表示您的最终答案，不要包含任何单位。不需要进行数值计算。", "solution": "首先对问题进行验证，以确保其科学上成立、定义明确且客观。\n\n### 第1步：提取已知条件\n- $B$：参数化自助法重复的次数。\n- $t^{\\ast}$：一个固定的时间点。\n- $p \\in (0,1)$：一个给定的百分位数水平。\n- $F(x)$：在 $t^{\\ast}$ 时浓度的真实累积分布函数（CDF）。\n- $f(x)$：在 $t^{\\ast}$ 时浓度的真实概率密度函数（PDF），其中 $f(x) = F'(x)$。\n- $q_{p}$：真实 $p$-分位数，定义为 $F(q_{p}) = p$。\n- $X_{b}$：在 $t^{\\ast}$ 时的第 $b$ 次自助法重复浓度。\n- $F_{B}(x) = \\frac{1}{B} \\sum_{b=1}^{B} \\mathbf{1}\\{X_{b} \\leq x\\}$：经验累积分布函数（ECDF）。\n- $\\hat{q}_{p}$：经验 $p$-分位数（百分位置信区间端点），定义为 $F_{B}(\\hat{q}_{p}) = p$。\n- $1-\\alpha$：蒙特卡洛变异性的置信水平。\n- $\\epsilon > 0$：蒙特卡洛误差半宽度的预设容差。\n- $z_{1-\\alpha/2}$：双侧置信区间的标准正态分位数。\n\n### 第2步：使用提取的已知条件进行验证\n- **科学上成立**：该问题位于临床药理学（VPC，群体药代动力学分析）和数理统计学（自助法，样本分位数的渐近分布）的交叉领域。所有概念都是标准且成熟的。该问题在科学上是合理的。\n- **定义明确**：该问题要求推导一个标准的渐近结果，并将其应用于样本量计算。根据给定的条件和“标准平滑性假设”（即 $f(x)$ 在 $q_p$ 处连续且为正），该问题是定义明确的，并且有唯一且有意义的解。\n- **客观**：该问题使用精确的数学定义和客观的语言进行陈述。它不含任何主观或基于观点的断言。\n\n该问题没有指令中列出的任何缺陷（例如，科学上不合理、不完整、模糊不清）。\n\n### 第3步：结论与行动\n该问题是**有效的**。现在开始求解过程。\n\n### 渐近误差的推导\n\n第一个目标是推导 $\\hat{q}_{p}$ 的蒙特卡洛误差的主阶渐近表达式。这个误差是由有限的蒙特卡洛重复次数 $B$ 产生的随机偏差 $\\hat{q}_{p} - q_{p}$。我们通过其方差或其标准差（标准误）来刻画这个误差。\n\n问题要求从经验CDF的二项方差开始。让我们在真实分位数 $q_p$ 处评估ECDF $F_B(x)$。\n$$F_B(q_p) = \\frac{1}{B} \\sum_{b=1}^{B} \\mathbf{1}\\{X_b \\le q_p\\}$$\n每个 $X_b$ 都是从具有CDF $F(x)$ 的真实预测分布中抽取的样本。因此，指示函数 $\\mathbf{1}\\{X_b \\le q_p\\}$ 是一个伯努利随机变量，其成功概率为 $P(X_b \\le q_p) = F(q_p) = p$。\n和 $\\sum_{b=1}^{B} \\mathbf{1}\\{X_b \\le q_p\\}$ 是 $B$ 次独立同分布的伯努利($p$)试验之和，因此它服从二项分布，即 $\\text{Binomial}(B,p)$。\nECDF $F_B(q_p)$ 是这些伯努利变量的平均值。其期望为 $E[F_B(q_p)] = p$，其方差为：\n$$\\text{Var}[F_B(q_p)] = \\text{Var}\\left(\\frac{1}{B} \\sum_{b=1}^{B} \\mathbf{1}\\{X_b \\le q_p\\}\\right) = \\frac{1}{B^2} \\times B p(1-p) = \\frac{p(1-p)}{B}$$\n这就是ECDF在 $q_p$ 处的二项方差。\n\n现在，我们必须将 $F_B(q_p)$ 的变异性与经验分位数 $\\hat{q}_p$ 的变异性联系起来。大样本理论中一个著名的结果是样本分位数的Bahadur表示，该结果在问题对 $F(x)$ 的平滑性假设（具体来说，$f(q_p) = F'(q_p)$ 存在且非零）下是合理的。它给出了样本分位数与真实分位数偏差的一阶近似：\n$$\\hat{q}_p - q_p \\approx \\frac{p - F_B(q_p)}{f(q_p)}$$\n在适当缩放后，当 $B \\to \\infty$ 时，这个近似变得精确。对两边取方差，得到 $\\hat{q}_p$ 的渐近方差：\n$$\\text{Var}(\\hat{q}_p) = \\text{Var}(\\hat{q}_p - q_p) \\approx \\text{Var}\\left(\\frac{p - F_B(q_p)}{f(q_p)}\\right)$$\n由于 $p$ 和 $f(q_p)$ 是常数，我们可以写出：\n$$\\text{Var}(\\hat{q}_p) \\approx \\frac{1}{(f(q_p))^2} \\text{Var}(p - F_B(q_p)) = \\frac{1}{(f(q_p))^2} \\text{Var}(-F_B(q_p)) = \\frac{1}{(f(q_p))^2} \\text{Var}(F_B(q_p))$$\n代入 $\\text{Var}(F_B(q_p))$ 的二项方差：\n$$\\text{Var}(\\hat{q}_p) \\approx \\frac{1}{(f(q_p))^2} \\left(\\frac{p(1-p)}{B}\\right) = \\frac{p(1-p)}{B (f(q_p))^2}$$\n“蒙特卡洛误差”通常通过标准误（SE）来量化，即方差的平方根。百分位置信区间端点 $\\hat{q}_p$ 的标准误的主阶渐近表达式为：\n$$\\text{SE}(\\hat{q}_p) = \\sqrt{\\text{Var}(\\hat{q}_p)} \\approx \\frac{\\sqrt{p(1-p)}}{f(q_p) \\sqrt{B}}$$\n$q_p$ 的置信区间的半宽度与其标准误成正比。由于标准误与 $1/\\sqrt{B}$ 成正比，因此半宽度的缩放级别为 $\\mathcal{O}(B^{-1/2})$，符合要求。\n\n### 所需重复次数的计算\n\n第二个目标是求出达到所需精度所需的重复次数 $B$。\n根据中心极限定理，对于大的 $B$，$\\hat{q}_p$ 的分布是渐近正态的：\n$$\\hat{q}_p \\sim \\mathcal{N}\\left(q_p, \\text{Var}(\\hat{q}_p)\\right) \\quad \\text{或} \\quad \\hat{q}_p \\sim \\mathcal{N}\\left(q_p, \\frac{p(1-p)}{B (f(q_p))^2}\\right)$$\n为了量化“$\\hat{q}_p$ 的蒙特卡洛变异性”，我们为真实分位数 $q_p$ 构建一个置信区间。在水平为 $1-\\alpha$ 的双侧置信区间由下式给出：\n$$\\hat{q}_p \\pm z_{1-\\alpha/2} \\times \\text{SE}(\\hat{q}_p)$$\n其中 $z_{1-\\alpha/2}$ 是标准正态分布的分位数，使得对于 $Z \\sim \\mathcal{N}(0,1)$，有 $P(Z \\le z_{1-\\alpha/2}) = 1-\\alpha/2$。\n\n该置信区间的半宽度（HW）为：\n$$HW = z_{1-\\alpha/2} \\times \\text{SE}(\\hat{q}_p) = z_{1-\\alpha/2} \\frac{\\sqrt{p(1-p)}}{f(q_p) \\sqrt{B}}$$\n问题要求这个半宽度小于预设的容差 $\\epsilon$。为了找到最小的重复次数，我们将半宽度设为等于 $\\epsilon$：\n$$\\epsilon = z_{1-\\alpha/2} \\frac{\\sqrt{p(1-p)}}{f(q_p) \\sqrt{B}}$$\n现在，我们求解 $B$：\n$$\\sqrt{B} = \\frac{z_{1-\\alpha/2} \\sqrt{p(1-p)}}{\\epsilon f(q_p)}$$\n两边平方，得到所需的自助法重复次数：\n$$B = \\left( \\frac{z_{1-\\alpha/2} \\sqrt{p(1-p)}}{\\epsilon f(q_p)} \\right)^2 = \\frac{z_{1-\\alpha/2}^2 p(1-p)}{\\epsilon^2 (f(q_p))^2}$$\n这就是用指定参数表示的 $B$ 的封闭形式表达式。", "answer": "$$\\boxed{\\frac{z_{1-\\alpha/2}^2 p(1-p)}{\\epsilon^2 (f(q_p))^2}}$$", "id": "4601294"}, {"introduction": "最后的这项练习 [@problem_id:4601305] 是一个综合性的顶点项目，它将前面练习中的概念融会贯通于一个完整的编码挑战中。您将亲手实现一个“部分VPC”（partial VPC），这是一种高级诊断技术，用于将模型评估的焦点放在药理学上特别关注的时间窗口内。这项任务要求您基于一个完整的药代动力学模型进行模拟，应用统计变异性，生成预测区间，并最终使用Bootstrap分析来评估模型的预测性能，从而完整地体验药理计量学家的端到端工作流程。", "problem": "在一个单室模型下，考虑具有一级吸收和一级消除的单剂量口服药代动力学场景。对于在时间 $t = 0$ 时给予的剂量 $D$，其结构浓度-时间函数由一个经过充分验证的公式给出，该公式是为具有一级吸收的单室模型根据质量平衡和线性处置推导出来的：\n$$\nC(t) = \\begin{cases}\n\\frac{D K_a}{V (K_a - k)} \\left( e^{-k t} - e^{-K_a t} \\right),  K_a \\neq k, \\\\\n\\frac{D}{V} K_a t e^{-k t},  K_a = k,\n\\end{cases}\n$$\n其中，$K_a$ 是一级吸收速率常数，单位为 $\\mathrm{h}^{-1}$；$CL$ 是清除率，单位为 $\\mathrm{L}\\,\\mathrm{h}^{-1}$；$V$ 是分布容积，单位为 $\\mathrm{L}$；$k = CL / V$ 是消除速率常数，单位为 $\\mathrm{h}^{-1}$。吸收半衰期为 $t_{1/2,a} = \\ln(2)/K_a$，消除半衰期为 $t_{1/2,e} = \\ln(2)/k$。在 $K_a \\neq k$ 条件下，达到最大浓度的时间为\n$$\nt_{\\max} = \\frac{\\ln(K_a/k)}{K_a - k}.\n$$\n\n视觉预测检验 (Visual Predictive Check, VPC) 是一种基于模拟的诊断方法，其中研究者在模型下生成多个模拟数据集，并将观测数据与模拟的分位数或预测区间进行比较。在此，我们进行部分 VPC，通过将评估限制在药理学上预定义的早期和晚期时间窗口，以避免择优挑选。这些窗口根据机理依据定义：\n- 早期窗口：$[0, n_a \\cdot t_{1/2,a}]$，其中 $n_a$ 是一个正标量。\n- 晚期窗口：$[t_{\\max} + n_e \\cdot t_{1/2,e}, \\infty)$，其中 $n_e$ 是一个正标量。\n\n为考虑变异性，使用对数正态模型对参数 $K_a$、$CL$ 和 $V$ 应用个体间变异，即 $K_a^{(i)} = K_a \\exp(\\eta_{K_a}^{(i)})$，$CL^{(i)} = CL \\exp(\\eta_{CL}^{(i)})$，以及 $V^{(i)} = V \\exp(\\eta_{V}^{(i)})$，其中 $\\eta$ 项从均值为 $0$、标准差为指定值 $\\omega_{K_a}$、$\\omega_{CL}$ 和 $\\omega_V$ 的正态分布中抽样。残差未释变异使用混合误差模型进行建模，使得模拟观测值 $\\tilde{C}(t)$ 为\n$$\n\\tilde{C}(t) = C(t)\\left(1 + \\epsilon_{\\mathrm{prop}}\\right) + \\epsilon_{\\mathrm{add}},\n$$\n其中 $\\epsilon_{\\mathrm{prop}} \\sim \\mathcal{N}(0, \\sigma_{\\mathrm{prop}})$ 和 $\\epsilon_{\\mathrm{add}} \\sim \\mathcal{N}(0, \\sigma_{\\mathrm{add}})$ 相互独立。\n\n对于名义覆盖率为 $1 - \\alpha$（例如，当 $\\alpha = 0.10$ 时为 $0.90$）的双侧预测区间，令 $q_{\\mathrm{low}}$ 和 $q_{\\mathrm{high}}$ 为在定义窗口内汇集所有重复模拟的浓度值的下分位数和上分位数。观测浓度使用群体参数（即无个体间变异）加上如上所述的残差误差生成一次。覆盖比例计算为落在 $[q_{\\mathrm{low}}, q_{\\mathrm{high}}]$ 区间内的窗口化观测浓度的分数。为量化观测覆盖率的不确定性，采用非参数自助法对窗口化观测浓度进行 $B$ 次有放回重抽样；每个自助样本产生一个覆盖比例，从而形成一个自助分布，从该分布中取 $0.025$ 和 $0.975$ 分位数得到双侧区间。如果名义目标 $1 - \\alpha$ 位于此自助区间内，则认为该测试用例通过。如果窗口内不包含任何观测时间点，则返回哨兵覆盖值 $-1.0$ 和通过指示符 $0$。\n\n实现一个程序，对每个指定的测试用例执行上述部分 VPC 和自助法程序。所有时间单位为 $\\mathrm{h}$，浓度单位为 $\\mathrm{mg}\\,\\mathrm{L}^{-1}$。程序必须使用固定的随机种子以保证可复现性。使用包含性的窗口边界。\n\n测试套件（每个用例提供参数并指定评估早期窗口还是晚期窗口）：\n- 用例 1（早期窗口，正常路径）：\n  - $D = 100$ $\\mathrm{mg}$，$K_a = 1.0$ $\\mathrm{h}^{-1}$，$CL = 5.0$ $\\mathrm{L}\\,\\mathrm{h}^{-1}$，$V = 50.0$ $\\mathrm{L}$。\n  - 观测时间点 $\\{0.25, 0.5, 1, 2, 4, 6, 8, 12, 24\\}$ $\\mathrm{h}$。\n  - $n_a = 3.0$，$n_e = 1.0$，窗口类型为早期。\n  - 个体间变异标准差 $\\omega_{K_a} = 0.2$，$\\omega_{CL} = 0.2$，$\\omega_V = 0.2$。\n  - 残差误差 $\\sigma_{\\mathrm{prop}} = 0.2$，$\\sigma_{\\mathrm{add}} = 0.05$ $\\mathrm{mg}\\,\\mathrm{L}^{-1}$。\n  - 模拟重复次数 $N_{\\mathrm{sim}} = 1000$，自助法重抽样次数 $B = 400$，$\\alpha = 0.10$。\n\n- 用例 2（晚期窗口，正常路径）：\n  - 与用例 1 相同，窗口类型为晚期，$n_e = 1.0$。\n\n- 用例 3（晚期窗口，无窗口内观测值的边缘情况）：\n  - 与用例 1 相同，窗口类型为晚期，$n_e = 100.0$。\n\n- 用例 4（早期窗口，边界条件包含性）：\n  - $D = 100$ $\\mathrm{mg}$，$K_a = \\ln(2)$ $\\mathrm{h}^{-1}$，$CL = 5.0$ $\\mathrm{L}\\,\\mathrm{h}^{-1}$，$V = 50.0$ $\\mathrm{L}$。\n  - 观测时间点 $\\{0.25, 0.5, 1, 2, 4, 6, 8, 12, 24\\}$ $\\mathrm{h}$。\n  - $n_a = 2.0$，$n_e = 1.0$，窗口类型为早期。\n  - 个体间变异和残差误差与用例 1 相同。\n  - $N_{\\mathrm{sim}} = 1000$，$B = 400$，$\\alpha = 0.10$。\n  - 注意：$n_a \\cdot t_{1/2,a} = 2.0$ $\\mathrm{h}$，因此必须包含边界时间点 $t = 2.0$ $\\mathrm{h}$。\n\n你的程序应生成单行输出，其中包含一个逗号分隔的列表，用方括号括起，结果顺序如下：\n$[覆盖率_1,通过_1,覆盖率_2,通过_2,覆盖率_3,通过_3,覆盖率_4,通过_4]$,\n其中覆盖率是一个在 $\\left[0,1\\right]$ 内的浮点数（如果无窗口内观测值则为 $-1.0$），通过是一个在 $\\{0,1\\}$ 内的整数。", "solution": "该问题要求实现一个在临床药理学中常见的模拟与分析工作流程，具体来说是一个带有自助法分析的部分视觉预测检验（VPC），用以评估模型预测性能的不确定性。该解决方案通过对所述的药代动力学模型、统计程序和评估标准进行算法上的形式化来设计。\n\n问题的核心在于一个具有一级吸收和消除的单室药代动力学模型。口服剂量 $D$ 后，在时间 $t$ 的药物浓度 $C(t)$ 由贝特曼函数描述：\n$$\nC(t) = \\begin{cases}\n\\frac{D K_a}{V (K_a - k)} \\left( e^{-k t} - e^{-K_a t} \\right),  K_a \\neq k, \\\\\n\\frac{D}{V} K_a t e^{-k t},  K_a = k,\n\\end{cases}\n$$\n其中 $K_a$ 是吸收速率常数，$V$ 是分布容积，$k = CL / V$ 是从清除率 $CL$ 派生出的消除速率常数。为保证数值稳定性，$K_a = k$ 的情况被单独处理，它代表了第一个表达式在 $K_a \\to k$ 时的数学极限。此函数是所有浓度预测的基础。\n\n该分析在特定的时间窗口内评估模型，这些窗口是根据机理定义的，用以区分药物处置的吸收和消除阶段。\n- 早期窗口，关注吸收过程，定义为 $[0, n_a \\cdot t_{1/2,a}]$，其中 $t_{1/2,a} = \\ln(2)/K_a$ 是吸收半衰期。\n- 晚期窗口，关注消除过程，定义为 $[t_{\\max} + n_e \\cdot t_{1/2,e}, \\infty)$，其中 $t_{1/2,e} = \\ln(2)/k$ 是消除半衰期，$t_{\\max}$ 是达到最大浓度的时间。$t_{\\max}$ 的计算方式如下：\n$$\nt_{\\max} = \\begin{cases}\n\\frac{\\ln(K_a/k)}{K_a - k},  K_a \\neq k, \\\\\n\\frac{1}{k},  K_a = k.\n\\end{cases}\n$$\n对这些计算使用群体参数，确保了对于给定模型，窗口定义是一致的。所有指定的观测时间点都经过筛选，只保留那些落在给定测试用例计算出的窗口的包含性边界内的时间点。如果没有时间点落在窗口内，则该用例的分析终止，返回哨兵值。\n\n模拟过程引入了变异性以反映真实世界的群体。个体间变异（IIV）通过假设个体特定参数围绕群体典型值呈对数正态分布来建模。对于一个通用参数 $P$，个体的参数 $P^{(i)}$ 通过 $P^{(i)} = P \\exp(\\eta_P^{(i)})$ 来模拟，其中 $\\eta_P^{(i)}$ 是从正态分布 $\\mathcal{N}(0, \\omega_P^2)$ 中抽样的随机偏差，$\\omega_P$ 是该参数 IIV 的指定标准差。这适用于 $K_a$、$CL$ 和 $V$。\n\n残差未释变异（RUV）解释了测量误差和模型设定误差。使用了一个混合比例和加性误差模型。一个模拟观测值 $\\tilde{C}(t)$ 是从真实的模型预测浓度 $C(t)$ 生成的：\n$$\n\\tilde{C}(t) = C(t)\\left(1 + \\epsilon_{\\mathrm{prop}}\\right) + \\epsilon_{\\mathrm{add}},\n$$\n其中 $\\epsilon_{\\mathrm{prop}}$ 和 $\\epsilon_{\\mathrm{add}}$ 分别独立地从正态分布 $\\mathcal{N}(0, \\sigma_{\\mathrm{prop}}^2)$ 和 $\\mathcal{N}(0, \\sigma_{\\mathrm{add}}^2)$ 中抽样。\n\nVPC 的核心是创建预测区间（PI）。这通过生成 $N_{\\mathrm{sim}}$ 组个体药代动力学曲线来实现。对于每个模拟的个体 $i=1, \\dots, N_{\\mathrm{sim}}$，我们首先抽样他们的个体参数 $K_a^{(i)}, CL^{(i)}, V^{(i)}$，然后在所有窗口化时间点计算他们的浓度曲线 $C^{(i)}(t)$。然后将 RUV 添加到这些预测中，得到模拟观测值 $\\tilde{C}^{(i)}(t)$。所有个体在窗口内所有时间点的所有模拟观测值被汇集到一个大的数据集中。PI 的下界和上界 $q_{\\mathrm{low}}$ 和 $q_{\\mathrm{high}}$ 通过计算这个汇集分布的 $\\alpha/2$ 和 $1 - \\alpha/2$ 分位数来确定，从而得到一个名义覆盖率为 $1 - \\alpha$ 的 PI。\n\n为了评估模型，会生成一个单一的“观测”数据集。这是通过使用群体典型参数（即无 IIV）计算浓度曲线，并在每个窗口化时间点添加一次 RUV 的实现来完成的。主要指标，即覆盖比例，是这些观测数据点落在 PI 内（即在区间 $[q_{\\mathrm{low}}, q_{\\mathrm{high}}]$ 中）的分数。\n\n为了量化这个观测覆盖比例的统计不确定性，采用了非参数自助法程序。对窗口内的观测浓度集进行有放回重抽样 $B$ 次，创建 $B$ 个自助样本，每个样本的大小与原始窗口化观测集相同。对于每个自助样本，使用原始固定的 PI $[q_{\\mathrm{low}}, q_{\\mathrm{high}}]$ 重新计算覆盖比例。这个过程会生成一个包含 $B$ 个覆盖比例的分布。然后通过从这个自助分布中取 $0.025$ 和 $0.975$ 分位数来构建覆盖比例的 $95\\%$ 置信区间。\n\n最后，如果目标名义覆盖率 $1 - \\alpha$ 位于这个 $95\\%$ 自助置信区间内，则一个测试用例被视为“通过”。这表明观测到的覆盖率与期望的覆盖率在统计上是一致的。整个过程被封装在一个程序中，该程序遍历每个测试用例，报告计算出的覆盖比例和二元的通过/失败指示符。固定的随机种子确保了模拟和分析中所有随机元素的可复现性。", "answer": "```python\nimport numpy as np\n\ndef _concentration(t, D, Ka, V, k):\n    \"\"\"Calculates concentration using the one-compartment oral absorption model.\"\"\"\n    if V == 0:\n        return np.inf\n    \n    # Use the appropriate formula based on whether Ka is close to k\n    # to maintain numerical stability.\n    if abs(Ka - k)  1e-9:\n        concentration = (D / V) * Ka * t * np.exp(-k * t)\n    else:\n        # Pre-calculate common terms for efficiency.\n        factor = D * Ka / (V * (Ka - k))\n        concentration = factor * (np.exp(-k * t) - np.exp(-Ka * t))\n    \n    return concentration\n\ndef _tmax(Ka, k):\n    \"\"\"Calculates time to maximum concentration.\"\"\"\n    if abs(Ka - k)  1e-9:\n        return 1.0 / k if k > 0 else 0.0\n    if Ka = 0 or k = 0:\n        return 0.0\n    return np.log(Ka / k) / (Ka - k)\n\ndef solve():\n    \"\"\"\n    Main function to run the VPC simulation and bootstrap analysis for all test cases.\n    \"\"\"\n    # Fixed random seed for reproducibility as required.\n    SEED = 0\n    rng = np.random.default_rng(SEED)\n\n    # Test suite definition as per the problem statement.\n    test_cases = [\n        # Case 1 (early window, happy path)\n        {'D': 100.0, 'Ka_pop': 1.0, 'CL_pop': 5.0, 'V_pop': 50.0,\n         'obs_times': np.array([0.25, 0.5, 1, 2, 4, 6, 8, 12, 24]),\n         'na': 3.0, 'ne': 1.0, 'window_type': 'early',\n         'omega_Ka': 0.2, 'omega_CL': 0.2, 'omega_V': 0.2,\n         'sigma_prop': 0.2, 'sigma_add': 0.05,\n         'N_sim': 1000, 'B': 400, 'alpha': 0.10},\n        # Case 2 (late window, happy path)\n        {'D': 100.0, 'Ka_pop': 1.0, 'CL_pop': 5.0, 'V_pop': 50.0,\n         'obs_times': np.array([0.25, 0.5, 1, 2, 4, 6, 8, 12, 24]),\n         'na': 3.0, 'ne': 1.0, 'window_type': 'late',\n         'omega_Ka': 0.2, 'omega_CL': 0.2, 'omega_V': 0.2,\n         'sigma_prop': 0.2, 'sigma_add': 0.05,\n         'N_sim': 1000, 'B': 400, 'alpha': 0.10},\n        # Case 3 (late window, edge case with no windowed observations)\n        {'D': 100.0, 'Ka_pop': 1.0, 'CL_pop': 5.0, 'V_pop': 50.0,\n         'obs_times': np.array([0.25, 0.5, 1, 2, 4, 6, 8, 12, 24]),\n         'na': 3.0, 'ne': 100.0, 'window_type': 'late',\n         'omega_Ka': 0.2, 'omega_CL': 0.2, 'omega_V': 0.2,\n         'sigma_prop': 0.2, 'sigma_add': 0.05,\n         'N_sim': 1000, 'B': 400, 'alpha': 0.10},\n        # Case 4 (early window, boundary condition inclusion)\n        {'D': 100.0, 'Ka_pop': np.log(2), 'CL_pop': 5.0, 'V_pop': 50.0,\n         'obs_times': np.array([0.25, 0.5, 1, 2, 4, 6, 8, 12, 24]),\n         'na': 2.0, 'ne': 1.0, 'window_type': 'early',\n         'omega_Ka': 0.2, 'omega_CL': 0.2, 'omega_V': 0.2,\n         'sigma_prop': 0.2, 'sigma_add': 0.05,\n         'N_sim': 1000, 'B': 400, 'alpha': 0.10},\n    ]\n\n    final_results = []\n\n    for case in test_cases:\n        # Unpack parameters for the current test case\n        k_pop = case['CL_pop'] / case['V_pop']\n        \n        # Calculate window boundaries based on population parameters\n        if case['window_type'] == 'early':\n            t_half_a = np.log(2) / case['Ka_pop'] if case['Ka_pop'] > 0 else 0\n            window_start, window_end = 0.0, case['na'] * t_half_a\n        else: # 'late'\n            tmax = _tmax(case['Ka_pop'], k_pop)\n            t_half_e = np.log(2) / k_pop if k_pop > 0 else np.inf\n            window_start, window_end = tmax + case['ne'] * t_half_e, np.inf\n\n        # Filter observation times to include only those within the window\n        obs_times_windowed = case['obs_times'][(case['obs_times'] >= window_start)  (case['obs_times'] = window_end)]\n\n        # Handle the case where no observations are in the window\n        if len(obs_times_windowed) == 0:\n            final_results.extend([-1.0, 0])\n            continue\n            \n        # Generate \"observed\" data: population pred + residual error\n        c_pop_windowed = _concentration(obs_times_windowed, case['D'], case['Ka_pop'], case['V_pop'], k_pop)\n        eps_prop_obs = rng.normal(0, case['sigma_prop'], size=len(obs_times_windowed))\n        eps_add_obs = rng.normal(0, case['sigma_add'], size=len(obs_times_windowed))\n        c_obs_windowed = c_pop_windowed * (1 + eps_prop_obs) + eps_add_obs\n        c_obs_windowed = np.maximum(0, c_obs_windowed) # Concentrations cannot be negative\n\n        # Perform simulation for Prediction Interval (PI)\n        simulated_concentrations = []\n        for _ in range(case['N_sim']):\n            # Sample inter-individual variability (IIV)\n            eta_Ka, eta_CL, eta_V = rng.normal(0, [case['omega_Ka'], case['omega_CL'], case['omega_V']], size=3)\n            Ka_ind = case['Ka_pop'] * np.exp(eta_Ka)\n            CL_ind = case['CL_pop'] * np.exp(eta_CL)\n            V_ind = case['V_pop'] * np.exp(eta_V)\n            k_ind = CL_ind / V_ind if V_ind > 0 else np.inf\n            \n            # Calculate individual concentration predictions\n            c_ind_pred = _concentration(obs_times_windowed, case['D'], Ka_ind, V_ind, k_ind)\n            \n            # Add residual unexplained variability (RUV)\n            eps_prop = rng.normal(0, case['sigma_prop'], size=len(obs_times_windowed))\n            eps_add = rng.normal(0, case['sigma_add'], size=len(obs_times_windowed))\n            c_ind_sim = c_ind_pred * (1 + eps_prop) + eps_add\n            \n            simulated_concentrations.extend(np.maximum(0, c_ind_sim))\n\n        # Calculate Prediction Interval from pooled simulated data\n        q_low, q_high = np.quantile(simulated_concentrations, [case['alpha']/2, 1 - case['alpha']/2])\n        \n        # Calculate observed coverage\n        in_interval = (c_obs_windowed >= q_low)  (c_obs_windowed = q_high)\n        observed_coverage = np.mean(in_interval)\n        \n        # Perform non-parametric bootstrap to find CI of coverage\n        n_obs_windowed = len(c_obs_windowed)\n        bootstrap_coverages = []\n        for _ in range(case['B']):\n            bootstrap_sample = rng.choice(c_obs_windowed, size=n_obs_windowed, replace=True)\n            bootstrap_coverage = np.mean((bootstrap_sample >= q_low)  (bootstrap_sample = q_high))\n            bootstrap_coverages.append(bootstrap_coverage)\n            \n        ci_low, ci_high = np.quantile(bootstrap_coverages, [0.025, 0.975])\n        \n        # Determine pass/fail status\n        target_coverage = 1 - case['alpha']\n        is_pass = 1 if ci_low = target_coverage = ci_high else 0\n        \n        final_results.extend([observed_coverage, is_pass])\n\n    # Format and print the final output as a single line\n    print(f\"[{','.join(f'{x:.6f}' if isinstance(x, float) else str(x) for x in final_results)}]\")\n\nsolve()\n```", "id": "4601305"}]}