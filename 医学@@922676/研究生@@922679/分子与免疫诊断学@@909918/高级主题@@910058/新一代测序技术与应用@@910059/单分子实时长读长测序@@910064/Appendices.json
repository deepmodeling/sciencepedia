{"hands_on_practices": [{"introduction": "在任何测序项目开始之前，一个关键的初始步骤是规划实验：需要收集多少数据才能充分覆盖目标基因组区域？本练习旨在通过第一性原理推导测序覆盖度的基本公式，并将该理论应用于实际的实验设计场景。通过解决这个问题 ([@problem_id:5163228])，您将掌握如何估算实现特定覆盖目标所需的仪器运行时间，这是测序实验成功的基础。", "problem": "一个临床免疫基因组学实验室计划使用单分子实时（SMRT）长读长测序来表征扩展的主要组织相容性复合体（MHC）区域。设目标区域长度为 $G$ 个碱基对。将随机选择的碱基处的期望覆盖度 $C$ 定义为覆盖该碱基的测序读长的期望数量，其标准假设为读长起始位点在区域内均匀分布，且由于 $G \\gg L$（其中 $L$ 为平均读长长度），边缘效应可忽略不计。从此定义出发，仅使用期望的线性性质和读长起始位点均匀分布的假设，推导一个用读长数量 $N$、平均读长长度 $L$ 和区域长度 $G$ 表示的 $C$ 的表达式。\n\n该实验室的检测靶向经典的人类白细胞抗原（HLA）区域，其长度为 $G = 3.9 \\times 10^{6}$ 个碱基对。为了在免疫诊断环境中实现稳健的单倍型定相，他们需要达到 $C^{\\star} = 47$ 的期望覆盖度。他们的 SMRT 仪器和文库制备平均每小时产生 $r_{N} = 2.5 \\times 10^{4}$ 条聚合酶读长，平均读长长度为 $L = 1.8 \\times 10^{4}$ 个碱基对。在经过质量过滤和考虑到杂交捕获特异性后，其中可用且靶向的比例 $f_{u} = 0.51$ 贡献于目标区域。假设读长产出率和可用比例随时间恒定，且与靶标无关。\n\n使用您推导的表达式和基本原理，计算在上述仪器性能下，要在长度为 $G$ 个碱基对的区域上达到目标期望覆盖度 $C^{\\star}$ 所需的总运行时间（以小时为单位）。将您的最终运行时间四舍五入至四位有效数字。以小时为单位表达您的答案。", "solution": "所述问题具有科学依据，提法明确，并包含得出唯一解所需的全部信息。所提供的参数对于所描述的免疫基因组学应用是符合实际的。我将继续进行推导和计算。\n\n问题分为两部分。首先，我们必须推导出期望覆盖度 $C$ 作为读长数量 $N$、平均读长长度 $L$ 和目标区域长度 $G$ 的函数表达式。其次，我们必须使用此表达式来计算达到特定目标覆盖度 $C^{\\star}$ 所需的仪器运行时间。\n\n第1部分：期望覆盖度公式的推导\n\n设目标区域由区间 $[0, G]$ 表示。考虑该区域内位置 $x$ 处的一个任意碱基。我们需要求出覆盖该位置 $x$ 的读长的期望数量。这就是期望覆盖度 $C$ 的定义。\n\n假设总共有 $N$ 条读长。我们考虑一条索引为 $i$ 的单一读长，其中 $i \\in \\{1, 2, ..., N\\}$。该读长的长度为 $L_i$。问题指出平均读长长度为 $L$，这意味着 $L = E[L_i] = \\frac{1}{N} \\sum_{i=1}^{N} L_i$。\n\n读长 $i$ 的起始位置（记为 $s_i$）被假定在目标区域上均匀分布。鉴于边缘效应可忽略的假设（$G \\gg L$），我们可以将起始位置建模为在区间 $[0, G]$ 上均匀分布。\n\n对于读长 $i$ 要覆盖位置 $x$ 处的碱基，其起始位置 $s_i$ 必须落在区间 $[x - L_i + 1, x]$ 内。这个有效起始位置区间的长度是 $L_i$。随机选择的起始位置 $s_i$ 落入此区间的概率 $p_i$ 是有效区间长度与起始位置所有可能区间长度的比值。\n$$p_i = P(\\text{read } i \\text{ covers } x) = \\frac{L_i}{G}$$\n\n让我们为每条读长定义一个指示随机变量 $I_i$：\n$$I_i = \\begin{cases} 1  \\text{if read } i \\text{ covers position } x \\\\ 0  \\text{otherwise} \\end{cases}$$\n这个指示变量的期望值是该事件发生的概率：\n$$E[I_i] = 1 \\cdot P(I_i=1) + 0 \\cdot P(I_i=0) = P(I_i=1) = p_i = \\frac{L_i}{G}$$\n\n位置 $x$ 处的总覆盖度（记为 $C_x$）是所有 $N$ 条读长的指示变量之和：\n$$C_x = \\sum_{i=1}^{N} I_i$$\n期望覆盖度 $C$ 是 $C_x$ 的期望。利用期望的线性性质（它允许我们将和的期望写为期望的和），我们得到：\n$$C = E[C_x] = E\\left[\\sum_{i=1}^{N} I_i\\right] = \\sum_{i=1}^{N} E[I_i]$$\n代入 $E[I_i]$ 的表达式：\n$$C = \\sum_{i=1}^{N} \\frac{L_i}{G} = \\frac{1}{G} \\sum_{i=1}^{N} L_i$$\n我们知道测序得到的总碱基数是 $\\sum_{i=1}^{N} L_i$。这个和可以用平均读长长度 $L$ 和总读长数 $N$ 来表示：\n$$\\sum_{i=1}^{N} L_i = N \\cdot L$$\n将此代入 $C$ 的表达式，我们便得到所需的公式：\n$$C = \\frac{N L}{G}$$\n这个表达式将期望覆盖度 $C$ 与读长数量 $N$、平均读长长度 $L$ 以及基因组或区域长度 $G$ 联系起来。\n\n第2部分：所需运行时间的计算\n\n目标是在长度为 $G = 3.9 \\times 10^{6}$ 个碱基对的区域上达到 $C^{\\star} = 47$ 的目标期望覆盖度。测序过程产生的平均读长长度为 $L = 1.8 \\times 10^{4}$ 个碱基对。\n\n首先，我们计算达到覆盖度 $C^{\\star}$ 所需的*可用且靶向的*读长总数，我们称之为 $N_{\\text{usable}}$。使用我们刚刚推导的公式：\n$$C^{\\star} = \\frac{N_{\\text{usable}} L}{G}$$\n重新整理以求解 $N_{\\text{usable}}$：\n$$N_{\\text{usable}} = \\frac{C^{\\star} G}{L}$$\n代入给定值：\n$$N_{\\text{usable}} = \\frac{47 \\cdot (3.9 \\times 10^{6})}{(1.8 \\times 10^{4})} = \\frac{183.3 \\times 10^{6}}{1.8 \\times 10^{4}} = 101.833... \\times 10^{2} = 10183.33...$$\n所以，大约需要 $10183$ 条可用读长。\n\n接下来，我们必须确定这些可用读长的生成速率。仪器每小时总共产生 $r_{N} = 2.5 \\times 10^{4}$ 条聚合酶读长。然而，其中只有 $f_{u} = 0.51$ 的比例是可用且靶向的。因此，可用读长的有效生成速率 $r_{\\text{usable}}$ 为：\n$$r_{\\text{usable}} = r_{N} \\cdot f_{u} = (2.5 \\times 10^{4} \\text{ reads/hour}) \\cdot 0.51 = 12750 \\text{ reads/hour}$$\n\n总运行时间 $T$ 是所需的可用读长总数除以它们的生成速率：\n$$T = \\frac{N_{\\text{usable}}}{r_{\\text{usable}}}$$\n代入 $N_{\\text{usable}}$ 和 $r_{\\text{usable}}$ 的表达式：\n$$T = \\frac{C^{\\star} G / L}{r_{N} f_{u}} = \\frac{C^{\\star} G}{L r_{N} f_{u}}$$\n现在，我们代入所有的数值：\n$$T = \\frac{47 \\cdot (3.9 \\times 10^{6})}{(1.8 \\times 10^{4}) \\cdot (2.5 \\times 10^{4}) \\cdot 0.51}$$\n$$T = \\frac{1.833 \\times 10^{8}}{(1.8 \\times 10^{4}) \\cdot (2.5 \\times 10^{4}) \\cdot 0.51} = \\frac{1.833 \\times 10^{8}}{(4.5 \\times 10^{8}) \\cdot 0.51} = \\frac{1.833 \\times 10^{8}}{2.295 \\times 10^{8}}$$\n$$T = \\frac{1.833}{2.295} \\approx 0.7986928... \\text{ hours}$$\n\n问题要求将最终运行时间四舍五入到四位有效数字。第五位有效数字是 $9$，所以我们将第四位数字进位。\n$$T \\approx 0.7987 \\text{ hours}$$", "answer": "$$\\boxed{0.7987}$$", "id": "5163228"}, {"introduction": "单分子实时测序的一大优势是能够通过环化模板进行多轮测序，生成高精度的环形一致性序列（Circular Consensus Sequence, CCS），即HiFi读长。尽管单次读取的错误率相对较高，但通过对多次独立读取的结果进行一致性投票，可以显著提高最终序列的准确性。这个练习 ([@problem_id:5163237]) 将指导您使用二项分布来量化这一过程，从而推导出单次读取错误率 $p$、测序遍数 $n$ 与最终一致性质控值 $QV$ 之间的关系。", "problem": "一家临床实验室正在评估使用单分子实时 (SMRT) 环形一致性测序技术进行单核苷酸变异基因分型检测。每一次聚合酶绕环形模板的遍历都会产生一个独立的子读段遍次（subread pass）。假设在某个给定的基因组位置，每个遍次独立地以概率 $(1-p)$ 检出正确碱基，并以概率 $p$ 检出错误碱基，其中 $0  p  1/2$。一致性碱基通过对所有 $n$ 个遍次进行简单的多数投票来确定，其中 $n$ 是一个奇数。如果大多数遍次检出的是错误碱基，则会发生一致性错误。Phred 质量值 (QV) 定义为 $QV = -10\\log_{10}(p_{c,n,p})$，其中 $p_{c,n,p}$ 是给定单遍次错误率 $p$ 和遍次数 $n$ 时的一致性错误率。一致性错误率的解析表达式 $p_{c,n,p}$ 是 $p_c(n, p) = \\sum_{k=\\frac{n+1}{2}}^{n} \\binom{n}{k} p^k (1-p)^{n-k}$。\n\n如果该实验室的 SMRT 测序的单遍次错误率是 $p=0.15$，并且他们要求用于临床报告的一致性序列碱基的 Phred 质量值至少为 $QV^{\\ast}=30$，他们必须生成的最小奇数遍次数 $n$ 是多少？", "solution": "该问题是有效的，因为它在科学上基于分子诊断学和概率论的原理，问题设定良好，目标明确，数据充分，并且没有任何事实或逻辑上的不一致。\n\n按照要求，任务分为两部分来解决。首先，推导一致性错误率 $p_c$ 的解析表达式。其次，计算为达到指定质量阈值所需的最小遍次数 $n$。\n\n第 1 部分：推导 $p_c$ 的解析表达式。\n\n在 $n$ 个独立遍次中确定单个基因组位置的碱基的过程，可以被建模为一系列 $n$ 次的伯努利试验。对于每次试验（遍次），有两种可能的结果：错误的碱基检出（一次“错误”）或正确的碱基检出（一次“成功”，意指得到正确的碱基）。\n\n设 $p$ 为任何单次遍次中检出错误碱基的概率。已知 $0  p  \\frac{1}{2}$。\n因此，检出正确碱基的概率是 $1-p$。\n\n设随机变量 $K$ 表示在 $n$ 次独立遍次中检出错误碱基的总次数。由于各遍次是独立的，且每次出错的概率 $p$ 是恒定的，所以 $K$ 服从参数为 $n$（试验次数）和 $p$（每次试验出错的概率）的二项分布。这记作 $K \\sim B(n, p)$。\n\n$K$ 的概率质量函数 (PMF) 由二项分布公式给出：\n$$P(K=k) = \\binom{n}{k} p^k (1-p)^{n-k}$$\n其中 $k$ 是一个整数，表示检出错误碱基的次数，$k \\in \\{0, 1, 2, \\dots, n\\}$。\n\n如果大多数遍次报告的是错误碱基，则会发生一致性错误。错误检出的次数是 $k$，正确检出的次数是 $n-k$。多数检出为错误意味着 $k > n-k$，这可以简化为 $2k > n$，即 $k > \\frac{n}{2}$。\n\n问题指定 $n$ 是一个奇数。设 $n = 2m+1$，其中 $m$ 为某个非负整数。发生错误的条件变为 $k > \\frac{2m+1}{2} = m + \\frac{1}{2}$。由于 $k$ 必须是整数，满足这个不等式的最小整数 $k$ 值是 $m+1$。代入 $m = \\frac{n-1}{2}$，发生一致性错误的条件是 $k \\ge \\frac{n-1}{2} + 1 = \\frac{n+1}{2}$。\n\n一致性错误率 $p_c$ 是所有一致性结果为错误的事件的总概率。这就是 $K$ 大于或等于 $\\frac{n+1}{2}$ 的概率。我们可以通过对所有相关的 $k$ 值求和来表示这个概率：\n$$p_c(n, p) = P\\left(K \\ge \\frac{n+1}{2}\\right) = \\sum_{k=\\frac{n+1}{2}}^{n} P(K=k)$$\n代入二项分布的 PMF，我们得到 $p_c$ 的最终解析表达式：\n$$p_c(n, p) = \\sum_{k=\\frac{n+1}{2}}^{n} \\binom{n}{k} p^k (1-p)^{n-k}$$\n\n第 2 部分：确定最小奇数 $n$。\n\n给定单遍次错误率 $p = 0.15$ 和目标 Phred 质量值 $QV^{\\ast} = 30$。质量值定义为 $QV = -10\\log_{10}(p_c)$。实验室要求一致性质量至少达到这个目标值，所以我们必须有 $QV \\ge QV^{\\ast}$。\n$$-10\\log_{10}(p_c) \\ge 30$$\n两边同除以 $-10$，不等号方向反转：\n$$\\log_{10}(p_c) \\le -3$$\n对两边应用以 10 为底的指数函数：\n$$p_c \\le 10^{-3}$$\n所以，我们必须找到最小的奇数 $n$，使得一致性错误率不大于 $0.001$。当 $p=0.15$ 时，正确遍次的概率是 $1-p = 0.85$。需要解的不等式是：\n$$p_c(n) = \\sum_{k=\\frac{n+1}{2}}^{n} \\binom{n}{k} (0.15)^k (0.85)^{n-k} \\le 0.001$$\n由于 $p=0.15  0.5$，增加遍次数 $n$ 会降低多数错误发生的概率。因此，$p_c(n)$ 是关于 $n$ 的单调递减函数。我们可以通过测试连续的奇数来找到最小的 $n$。\n\n对于 $n=1$，$p_c(1) = 0.15$，大于 $0.001$。\n对于 $n=3$，$p_c(3) \\approx 0.06075$，大于 $0.001$。\n我们继续测试 $n=5, 7, 9, 11, \\dots$。让我们检查阈值附近的值。\n\n对于 $n=13$：\n导致一致性失败所需的错误次数为 $k \\ge \\frac{13+1}{2} = 7$。\n$$p_c(13) = \\sum_{k=7}^{13} \\binom{13}{k} (0.15)^k (0.85)^{13-k}$$\n对这个和进行数值计算，即 $B(13, 0.15)$ 分布的尾部概率，得出：\n$$p_c(13) \\approx 0.001265$$\n由于 $0.001265 > 0.001$，$n=13$ 次遍次不足以满足质量要求。\n\n对于下一个奇数，$n=15$：\n导致一致性失败所需的错误次数为 $k \\ge \\frac{15+1}{2} = 8$。\n$$p_c(15) = \\sum_{k=8}^{15} \\binom{15}{k} (0.15)^k (0.85)^{15-k}$$\n对 $B(15, 0.15)$ 分布的这个和进行数值计算，得出：\n$$p_c(15) \\approx 0.000608$$\n由于 $0.000608 \\le 0.001$，$n=15$ 次遍次足以满足质量要求。\n\n鉴于 $p_c(n)$ 是随 $n$ 递增而递减的函数，并且已知 $n=13$ 不足而 $n=15$ 足够，因此所需的最小奇数遍次数为 $15$。", "answer": "$$\\boxed{15}$$", "id": "5163237"}, {"introduction": "长读长测序的一个关键优势是其能够跨越复杂的基因组区域，例如具有高度多态性的人类白细胞抗原（HLA）基因座，这些区域难以用单一的线性参考基因组准确表示。图基因组（Graph Genome）为表示这种复杂的群体变异提供了一个强大的框架。本练习 ([@problem_id:5163278]) 是一个高级的算法实践，要求您从动态规划的第一性原理出发，推导并实现部分有序比对（Partial Order Alignment）算法，将长读长序列比对到基于有向无环图的复杂基因组参考上。", "problem": "给定一个代表人类白细胞抗原 (HLA) 等位基因部分有序基因组的有向无环图 (DAG) 和一条单分子实时 (SMRT) 长读长序列。请从第一性原理出发，推导并实现一个部分有序比对程序，该程序将经典的全局比对推广到使用线性空位罚分的节点标记 DAG。你的推导必须基于动态规划的最优性原理，且不依赖任何预先推导的图比对公式。对于每个测试用例，你的实现必须计算两个量：(i) 读长序列与 DAG 中任意路径的最佳全局比对得分，以及 (ii) 下文定义的计算量的量化估计，以证实理论时间复杂度。\n\n使用的基本原理：\n- 动态规划中的最优子结构原理和贝尔曼最优性原理。\n- 当图是线性链时，Needleman–Wunsch 全局比对作为一种特例。\n- 线性空位模型，每次插入或删除都有恒定的罚分。\n- 有向无环图的拓扑排序。\n\n定义与约束：\n- 该图是一个节点标记的有向无环图，其中每个节点带有一个来自字母表 $\\{A,C,G,T\\}$ 的核苷酸。比对将读长序列映射到图中的一条路径，允许匹配、错配和空位（读长中的插入或图路径中的删除）。\n- 使用线性空位罚分模型：每次插入或删除都会产生一个恒定的罚分。\n- 令 $V$ 为节点数，$E$ 为有向边数，$L$ 为读长序列的长度。\n- 根据动态规划的第一性原理，为每个节点和读长位置定义三个动态规划状态：\n  - $M$：以消耗一个图节点和一个读长字符结束的比对，\n  - $I$：以消耗一个读长字符（图中的空位）结束的比对，\n  - $D$：以消耗一个图节点（读长中的空位）结束的比对。\n- 使用整个读长序列与 DAG 中路径的全局比对，对所有空位（包括两端的空位）应用线性罚分。\n\n计算量度量：\n- 将计算量定义为在所有动态规划状态转移中，为取最大值而评估的标量前驱状态候选者的确切数量，并在整个动态规划过程中求和。候选者计数如下：\n  - 对于每个节点 $v$ 和 $\\{0,1,\\dots,L\\}$ 中的位置 $j$，$D$ 状态在 $\\deg^{-}(v) > 0$ 时考虑 $\\deg^{-}(v)$ 个候选前驱节点，否则考虑 $1$ 个起始候选者。\n  - 对于每个节点 $v$ 和 $\\{1,\\dots,L\\}$ 中的位置 $j$，$I$ 状态考虑 $(v,j-1)$ 处的 $3$ 个前驱状态候选者。\n  - 对于每个节点 $v$ 和 $\\{1,\\dots,L\\}$ 中的位置 $j$，$M$ 状态在 $\\deg^{-}(v) > 0$ 时考虑 $3 \\cdot \\deg^{-}(v)$ 个前驱状态候选者，否则考虑 $1$ 个起始候选者。\n- 该度量不计算加法运算，仅计算在取最大值时比较的标量值的数量，如上规定。\n\n计分：\n- 匹配得分：$+2$。\n- 错配罚分：$-2$。\n- 空位罚分：$-3$。\n\n测试套件：\n- 测试用例 1 (SNP 气泡 DAG，类 HLA-A 外显子)：\n  - 节点 (索引到标签)：$0:A$, $1:C$, $2:G$, $3:T$, $4:A$, $5:C$, $6:G$。\n  - 有向边 $(u, v)$: $(0, 1)$, $(1, 2)$, $(1, 3)$, $(2, 4)$, $(3, 4)$, $(4, 5)$, $(5, 6)$。\n  - 读长序列：$ACGACG$，因此 $L = 6$。\n- 测试用例 2 (indel 气泡 DAG，跳过一个节点的备选路径)：\n  - 节点：$0:A$, $1:C$, $2:G$, $3:A$, $4:C$, $5:G$。\n  - 边：$(0, 1)$, $(1, 2)$, $(2, 3)$, $(3, 4)$, $(2, 4)$, $(4, 5)$。\n  - 读长序列：$ACGCG$，因此 $L = 5$。\n- 测试用例 3 (在测试用例 1 的 DAG 上进行错配密集的读长比对)：\n  - 使用与测试用例 1 相同的图。\n  - 读长序列：$TTTTTT$，因此 $L = 6$。\n\n任务：\n- 对每个测试用例，计算：\n  1. 使用上述计分规则的最佳全局比对得分（整数）。\n  2. 定义的计算量度量。\n- 理论复杂度：从第一性原理出发，推导你的动态规划程序的渐近时间复杂度（用 $V$、$E$ 和 $L$ 表示）。\n\n最终输出格式：\n- 你的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表。按顺序汇总所有测试用例的结果，将每对结果平铺为两个连续的整数。例如，输出必须类似于 $[s_1, c_1, s_2, c_2, s_3, c_3]$。", "solution": "该问题要求推导并实现一个部分有序比对 (POA) 算法，用于将一条 DNA 序列（读长）与一个部分有序图进行比对，该图表示为一个节点标记的有向无环图 (DAG)。该比对必须是全局的，覆盖整个读长，并且必须使用线性空位罚分模型。解决方案必须从动态规划 (DP) 的第一性原理推导得出，特别是最优性原理。\n\n### 1. 最优性原理与状态定义\n\n我们动态规划方法的基础是最优子结构原理，该原理指出，一个问题的最优解可以由其子问题的最优解构造而成。在序列比对的背景下，这意味着读长前缀与图路径的最优比对得分，可以通过扩展一个更小子问题的最优比对来计算。\n\n在任何给定点，读长与 DAG 中路径的比对可以以三种方式之一结束：\n1.  匹配或错配：读长前缀的最后一个字符与图路径的最后一个节点对齐。\n2.  插入：读长前缀的最后一个字符与一个空位对齐。\n3.  删除：图路径的最后一个节点与一个空位对齐。\n\n为了捕捉这些可能性，我们为图中的每个节点 $v$ 和读长中的每个位置 $j$（代表长度为 $j$ 的前缀，即 $read[1 \\dots j]$）定义三个 DP 状态。设 $V$ 为节点集合，$L$ 为读长长度。设 $g$ 为线性空位罚分，$s(c_1, c_2)$ 为字符 $c_1$ 与 $c_2$ 对齐的得分。\n\n-   $M(v, j)$：将读长前缀 $read[1 \\dots j]$ 与 DAG 中结束于节点 $v$ 的路径进行比对的最优得分，其中读长字符 $read[j]$ 与节点 $v$ 的字符标签对齐。\n-   $I(v, j)$：将 $read[1 \\dots j]$ 与结束于 $v$ 的路径进行比对的最优得分，其中 $read[j]$ 与一个空位对齐（相对于图路径的插入）。\n-   $D(v, j)$：将 $read[1 \\dots j]$ 与结束于 $v$ 的路径进行比对的最优得分，其中 $v$ 的字符标签与一个空位对齐（相对于读长的删除）。\n\n### 2. 递推关系的推导\n\n我们通过考虑如何扩展比对来推导每个状态的递推关系。设 $Pred(v)$ 为节点 $v$ 的直接前驱节点集合。\n\n**状态 $I(v, j)$（插入）：**一个在节点 $v$ 处以插入 $read[j]$ 结束的比对，必须扩展一个已经结束于节点 $v$ 的、对 $read[1 \\dots j-1]$ 的比对。这个先前的比对可能以匹配/错配（$M(v, j-1)$）、插入（$I(v, j-1)$）或删除（$D(v, j-1)$）结束。我们取这些可能性中的最大值，并加上空位罚分 $g$。\n$$I(v, j) = g + \\max \\left\\{ M(v, j-1), I(v, j-1), D(v, j-1) \\right\\}$$\n根据问题描述，此最大化操作的计算量为 $3$ 个候选者。\n\n**状态 $M(v, j)$（匹配/错配）：**一个以 $read[j]$ 与节点 $v$ 匹配结束的比对，必须扩展一个对 $read[1 \\dots j-1]$ 的、结束于前驱节点 $u \\in Pred(v)$ 的路径的比对。对于每个前驱节点 $u$，先前的比对可能是三种状态中的任意一种。我们取所有前驱节点和所有三种状态的最大值，并加上对齐字符的得分。\n$$M(v, j) = s(\\text{label}(v), read[j]) + \\max_{u \\in Pred(v)} \\left\\{ M(u, j-1), I(u, j-1), D(u, j-1) \\right\\}$$\n此操作的计算量为 $3 \\cdot \\deg^{-}(v)$ 个候选者，其中 $\\deg^{-}(v)$ 是 $v$ 的入度。如果 $v$ 是源节点（$\\deg^{-}(v) = 0$），则此转移作为特殊的基本情况处理。\n\n**状态 $D(v, j)$（删除）：**一个以节点 $v$ 相对于读长前缀 $read[1 \\dots j]$ 的删除结束的比对，必须扩展一个对相同读长前缀的、结束于前驱节点 $u \\in Pred(v)$ 的路径的比对。\n$$D(v, j) = g + \\max_{u \\in Pred(v)} \\left\\{ M(u, j), I(u, j), D(u, j) \\right\\}$$\n问题为此状态指定了 $\\deg^{-}(v)$ 个候选者的计算量。这意味着一个简化的递推关系，其中每个前驱节点只考虑一个最佳得分。设 $S(u,j) = \\max\\{M(u,j), I(u,j), D(u,j)\\}$。递推关系变为：\n$$D(v, j) = g + \\max_{u \\in Pred(v)} \\left\\{ S(u, j) \\right\\}$$\n这与指定的计算量计数一致。\n\n### 3. 拓扑排序与算法结构\n\n$D(v,j)$ 的计算依赖于前驱节点 $u$ 在相同读长位置 $j$ 的状态。这在给定 $j$ 的 DP 表“切片”内部创建了依赖关系。为解决此问题，必须按拓扑顺序处理节点。设拓扑排序后的节点为 $v_1, v_2, \\dots, v_{|V|}$。\n\n总体算法如下：\n1.  计算图节点的拓扑排序。\n2.  初始化 $j=0$ 时的 DP 表 $M$、$I$ 和 $D$。\n3.  从 $1$ 到 $L$ 迭代 $j$。在每次迭代中：\n4.  按拓扑顺序遍历节点 $v$。对于每个 $v$：\n5.  使用递推关系计算 $I(v, j)$，然后是 $M(v, j)$，最后是 $D(v, j)$。拓扑排序确保在计算 $v$ 的状态时，其所有前驱节点 $u$ 所需的状态都已可用。\n\n### 4. 初始化（基本情况）\n\n-   **DP 表初始化：**大小为 $|V| \\times (L+1)$ 的表 $M、I、D$ 被初始化为一个非常大的负数，代表 $-\\infty$。\n\n-   **与空读长的比对 ($j=0$)：**空读长与图路径的比对只能由删除组成。\n    -   对于源节点 $v$ ($\\deg^{-}(v)=0$)，长度为一的路径仅包含 $v$。将其与空读长对齐意味着一次删除。因此，$D(v, 0) = g$。遵循“起始候选者”的计算量度量规范，这可以概念化为 $D(v,0) = g + \\max\\{0\\}$，其中 $0$ 是虚拟起始状态的得分。\n    -   对于任何其他节点 $v$，以 $v$ 结束的删除路径必须扩展一条以其某个前驱节点结束的删除路径。\n      $$D(v, 0) = g + \\max_{u \\in Pred(v)} \\{D(u, 0)\\}$$\n    -   $M(v,0)$ 和 $I(v,0)$ 这两种状态是不可能的，保持为 $-\\infty$。\n\n-   **对于 $j>0$ 的源节点 ($\\deg^-(v)=0$)：**对于源节点 $v$，没有可供扩展的前驱节点。这对应于开始一条新的比对路径。\n    -   **$M(v,j)$：**比对从节点 $v$ 开始，匹配 $read[j]$。前面的读长字符 $read[1 \\dots j-1]$ 必须都是插入。得分为 $M(v,j) = s(\\text{label}(v), read[j]) + (j-1)g$。计算量为 $1$ 个起始候选者。\n    -   **$D(v,j)$：**在比对完 $read[1 \\dots j]$ 后删除 $v$，前缀 $read[1 \\dots j]$ 必须与空路径对齐（即全部是插入）。得分为 $D(v,j) = (j+1)g$。计算量为 $1$ 个起始候选者。\n\n### 5. 最终得分计算\n\n问题要求的是与 DAG 中*任意路径*的全局比对的最优得分。路径不一定从源节点延伸到汇点。因此，在填充完直到 $j=L$ 的 DP 表后，最终的最优得分是最终读长位置 $L$ 处所有节点的所有状态中的最大值。\n$$ \\text{Score}_{\\text{optimal}} = \\max_{v \\in V} \\{ M(v, L), I(v, L), D(v, L) \\} $$\n\n### 6. 计算复杂度分析\n\n1.  **拓扑排序：**可以使用 Kahn 算法或 DFS 在 $O(V+E)$ 时间内完成。\n2.  **初始化 ($j=0$)：**按拓扑顺序遍历所有节点。对于每个节点，我们遍历其前驱节点。前驱节点查找的总数是 $\\sum_{v \\in V} \\deg^-(v) = E$。此步骤的时间复杂度为 $O(V+E)$。\n3.  **主循环：**外层循环运行 $L$ 次。内层循环遍历所有 $V$ 个节点。\n    -   对于每个 $(v, j)$，计算 $I(v,j)$ 需要 $O(1)$ 时间。总计：$O(VL)$。\n    -   对于每个 $(v, j)$，计算 $M(v,j)$ 需要 $O(\\deg^{-}(v))$ 时间。对于固定的 $j$ 遍历所有 $v$，总时间为 $\\sum_{v \\in V} O(\\deg^{-}(v)) = O(E)$。总计：$O(EL)$。\n    -   类似地，计算 $D(v,j)$ 需要 $O(\\deg^{-}(v))$ 时间。总计：$O(EL)$。\n总时间复杂度由主循环主导，为 $O(VL + EL) = O(L(V+E))$。\n\n### 7. 计算量度量\n\n实现中将维护一个计数器 `effort`。在计算每个 DP 状态时，此计数器将严格按照问题陈述中指定的规则递增。这确保了所实现的递推关系和基本情况与问题的形式化定义完全匹配。对于源节点处没有明确 `max` 定义的基本情况，我们将其实现为对单个候选者的 `max`，以符合计算量度量的要求。", "answer": "```python\nimport numpy as np\n\ndef topological_sort(graph):\n    \"\"\"\n    Performs a topological sort on the graph using Kahn's algorithm.\n    \"\"\"\n    num_nodes = len(graph['nodes'])\n    in_degree = dict(graph['in_degree'])\n    queue = [i for i in range(num_nodes) if in_degree[i] == 0]\n    topo_order = []\n    \n    while queue:\n        u = queue.pop(0)\n        topo_order.append(u)\n        \n        for v in sorted(graph['adj'].get(u, [])): # sorted for determinism\n            in_degree[v] -= 1\n            if in_degree[v] == 0:\n                queue.append(v)\n                \n    if len(topo_order) != num_nodes:\n        raise ValueError(\"Graph has a cycle\")\n        \n    return topo_order\n\ndef partial_order_alignment(graph, read, match_score, mismatch_penalty, gap_penalty):\n    \"\"\"\n    Performs partial order alignment of a read to a DAG.\n    \"\"\"\n    V = len(graph['nodes'])\n    L = len(read)\n    g = gap_penalty\n    \n    # Initialize DP tables with a large negative number\n    NEG_INF = -10**9\n    M = np.full((V, L + 1), NEG_INF, dtype=np.int64)\n    I = np.full((V, L + 1), NEG_INF, dtype=np.int64)\n    D = np.full((V, L + 1), NEG_INF, dtype=np.int64)\n    \n    effort = 0\n    \n    topo_order = topological_sort(graph)\n    \n    # Initialization for j=0 (empty read prefix)\n    for v in topo_order:\n        preds = graph['pred'].get(v, [])\n        if not preds: # Source node\n            # Conceptually, D[v,0] = g + 0 (score from virtual start node)\n            max_pred_D0 = 0 \n            D[v, 0] = g + max_pred_D0\n            effort += 1 # 1 start candidate\n        else:\n            pred_scores = [D[u, 0] for u in preds]\n            if pred_scores:\n                max_pred_D0 = max(pred_scores)\n                if max_pred_D0  NEG_INF:\n                   D[v, 0] = g + max_pred_D0\n                effort += len(preds)\n\n    # Main DP loop\n    for j in range(1, L + 1):\n        for v in topo_order:\n            preds = graph['pred'].get(v, [])\n            \n            # State I: Insertion\n            prev_score_I = max(M[v, j-1], I[v, j-1], D[v, j-1])\n            if prev_score_I  NEG_INF:\n                I[v, j] = g + prev_score_I\n                effort += 3\n            \n            # State M: Match/Mismatch\n            v_char = graph['nodes'][v]\n            read_char = read[j-1]\n            score_s = match_score if v_char == read_char else mismatch_penalty\n            \n            max_pred_M = NEG_INF\n            if not preds: # Source node\n                # Alignment starts here, after j-1 insertions\n                max_pred_M = (j - 1) * g\n                effort += 1 # 1 start candidate\n            else:\n                pred_scores_M = []\n                for u in preds:\n                    pred_scores_M.extend([M[u, j-1], I[u, j-1], D[u, j-1]])\n                max_pred_M = max(pred_scores_M) if pred_scores_M else NEG_INF\n                effort += 3 * len(preds)\n            \n            if max_pred_M  NEG_INF:\n                M[v, j] = score_s + max_pred_M\n\n            # State D: Deletion\n            max_pred_D = NEG_INF\n            if not preds: # Source node\n                # To delete v, read[0...j-1] must all be insertions\n                max_pred_D = j * g\n                effort += 1 # 1 start candidate\n            else:\n                # Per effort spec, this takes max over a single score from each predecessor\n                S_u_j = []\n                for u in preds:\n                    s_val = max(M[u, j], I[u, j], D[u, j])\n                    if s_val  NEG_INF:\n                        S_u_j.append(s_val)\n                if S_u_j:\n                    max_pred_D = max(S_u_j)\n                effort += len(preds)\n            \n            if max_pred_D  NEG_INF:\n                D[v, j] = g + max_pred_D\n\n    # Final score is the max over all states at j=L for any node v\n    final_score = NEG_INF\n    if V  0:\n        final_scores = np.concatenate((M[:, L], I[:, L], D[:, L]))\n        final_score = np.max(final_scores)\n\n    return int(final_score), effort\n\n\ndef solve():\n    \"\"\"\n    Sets up and solves the partial order alignment problem for the given test cases.\n    \"\"\"\n    match_score = 2\n    mismatch_penalty = -2\n    gap_penalty = -3\n\n    def build_graph(nodes, edges):\n        num_nodes = len(nodes)\n        adj = {i: [] for i in range(num_nodes)}\n        pred = {i: [] for i in range(num_nodes)}\n        in_degree = {i: 0 for i in range(num_nodes)}\n        for u, v in edges:\n            adj[u].append(v)\n            pred[v].append(u)\n            in_degree[v] += 1\n        return {'nodes': nodes, 'adj': adj, 'pred': pred, 'in_degree': in_degree}\n\n    test_cases = [\n        {\n            \"nodes\": ['A', 'C', 'G', 'T', 'A', 'C', 'G'],\n            \"edges\": [(0, 1), (1, 2), (1, 3), (2, 4), (3, 4), (4, 5), (5, 6)],\n            \"read\": \"ACGACG\"\n        },\n        {\n            \"nodes\": ['A', 'C', 'G', 'A', 'C', 'G'],\n            \"edges\": [(0, 1), (1, 2), (2, 3), (3, 4), (2, 4), (4, 5)],\n            \"read\": \"ACGCG\"\n        },\n        {\n            \"nodes\": ['A', 'C', 'G', 'T', 'A', 'C', 'G'],\n            \"edges\": [(0, 1), (1, 2), (1, 3), (2, 4), (3, 4), (4, 5), (5, 6)],\n            \"read\": \"TTTTTT\"\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        graph = build_graph(case[\"nodes\"], case[\"edges\"])\n        score, effort = partial_order_alignment(graph, case[\"read\"], match_score, mismatch_penalty, gap_penalty)\n        results.extend([score, effort])\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "5163278"}]}