## 引言
人工智能（AI）和机器学习（ML）正在深刻地重塑分子与免疫诊断领域，使我们能够从日益复杂的[高通量数据](@entry_id:275748)中提取前所未有的洞见。然而，将这些强大的计算工具从算法概念转化为可靠、稳健且符合伦理的临床应用，是一个巨大的挑战。这不仅需要算法知识，更需要对从数据生成到临床决策的全流程有深入的理解，填补理论与实践之间的知识鸿沟。

本文旨在系统性地导航这一复杂领域。通过三个章节的递进式学习，读者将构建一个全面的知识框架。我们将在第一章“原理与机制”中，奠定评估、构建和验证诊断模型所需的基础理论；接着，在第二章“应用与跨学科连接”中，我们将这些原理置于真实的诊断场景中，探讨从信号处理到[多模态数据](@entry_id:635386)融合，再到伦理法规的实际应用；最后，在“动手实践”部分，您将有机会亲手应用所学到的关键概念。

让我们从构建诊断AI的基石——理解其核心原理与机制开始。

## 原理与机制

本章深入探讨了在诊断解读中应用人工智能（AI）和机器学习（ML）的核心原理与机制。我们将从评估诊断模型性能的基础度量标准出发，逐步深入到构建、训练和验证这些模型的算法核心。此外，我们还将讨论在真实世界临床数据中确保模型稳健性的关键考量，例如处理分层数据和技术变异。最后，本章将引入不确定性量化和因果推断等前沿概念，这些对于构建不仅准确而且可靠和可解释的诊断AI系统至关重要。

### 诊断性能的语言：概率度量

为了评估和比较诊断模型，我们需要一套严谨的、基于概率论的语言。所有[二元分类](@entry_id:142257)模型的性能评估都源于一个简单的概念：**[混淆矩阵](@entry_id:635058)（Confusion Matrix）**。对于一个旨在区分“疾病存在”（$D+$）和“疾病不存在”（$D-$）的诊断测试，其预测结果可能是“阳性”（$T+$）或“阴性”（$T-$）。由此产生四种可能的结果：

-   **[真阳性](@entry_id:637126)（True Positives, TP）**：模型正确预测疾病存在（$T+$ 且 $D+$）。
-   **[假阳性](@entry_id:635878)（False Positives, FP）**：模型错误预测疾病存在（$T+$ 且 $D-$），也称为I类错误。
-   **真阴性（True Negatives, TN）**：模型正确预测疾病不存在（$T-$ 且 $D-$）。
-   **假阴性（False Negatives, FN）**：模型错误预测疾病不存在（$T-$ 且 $D+$），也称为II类错误。

基于这些计数，我们可以定义一系列关键的性能度量，它们在概率论中具有精确的条件概率形式。

#### 固有性能度量：灵敏度与特异性

两个最基本的度量描述了诊断测试或模型本身的内在性能，而不受疾病在人群中流行程度的影响。

-   **灵敏度（Sensitivity）**，在机器学习领域也常被称为**召回率（Recall）**或**真阳性率（True Positive Rate, TPR）**，衡量的是模型在所有真正患病的个体中，能够正确识别出阳性的比例。它回答了这样一个问题：“如果一个人确实有病，测试呈阳性的概率是多少？”其数学定义为：
    $$ \text{灵敏度} = P(T+ \mid D+) = \frac{\mathrm{TP}}{\mathrm{TP} + \mathrm{FN}} $$

-   **特异性（Specificity）**，也称为**真阴性率（True Negative Rate, TNR）**，衡量的是模型在所有未患病的个体中，能够正确识别出阴性的比例。它回答了：“如果一个人确实没病，测试呈阴性的概率是多少？”其定义为：
    $$ \text{特异性} = P(T- \mid D-) = \frac{\mathrm{TN}}{\mathrm{TN} + \mathrm{FP}} $$

灵敏度和特异性是评估一项化验或一个分类器算法内在分辨能力的基石[@problem_id:5094060]。

#### 临床效用度量：预测价值

然而，在临床实践中，医生和患者面临的问题往往是相反的：“如果测试结果是阳性，我真的患病的概率有多大？”这类问题由预测价值来回答，它们将测试的内在性能与**疾病患病率（Prevalence）**，$P(D+)$，即疾病在目标人群中的基础概率，联系起来。

-   **阳性预测值（Positive Predictive Value, PPV）**，在机器学习中常被称为**精确率（Precision）**，定义为测试结果为阳性的个体中，真正患病的比例。其数学形式为：
    $$ \text{PPV} = P(D+ \mid T+) = \frac{\mathrm{TP}}{\mathrm{TP} + \mathrm{FP}} $$

-   **阴性预测值（Negative Predictive Value, NPV）** 定义为测试结果为阴性的个体中，真正未患病的比例。其数学形式为：
    $$ \text{NPV} = P(D- \mid T-) = \frac{\mathrm{TN}}{\mathrm{TN} + \mathrm{FN}} $$

与灵敏度和特异性不同，PPV和NPV严重依赖于患病率。通过[贝叶斯定理](@entry_id:151040)可以证明，在测试性能（灵敏度和特异性）固定的情况下，PPV是患病率 $P(D+)$ 的增函数，而NPV是其减函数[@problem_id:5094060]。这意味着，即使一个非常好的测试，当用于筛查一种罕见疾病时（患病率极低），其PPV也可能非常低。这个现象被称为**精确率悖论（Precision Paradox）**。例如，一个用于检测罕见[免疫缺陷](@entry_id:204322)的分类器，即使其灵敏度为$0.9$，特异性为$0.99$（即[假阳性率](@entry_id:636147)为$0.01$），在患病率仅为$0.001$的人群中，其精确率（PPV）大约只有$0.082$。这意味着在每100个被标记为阳性的患者中，大约只有8人真正患病[@problem_id:5094063]。这凸显了在解释诊断结果时考虑基础患病率的重要性。

#### 应对类别不平衡的度量

在许多诊断场景中，尤其是在罕见病筛查中，健康个体的数量远超患病个体，这种情况称为**[类别不平衡](@entry_id:636658)（Class Imbalance）**。在这种背景下，一些常见的度量标准可能会产生误导。

-   **准确率（Accuracy）**，即正确分类的样本占总样本的比例，$P(T+ \cap D+) + P(T- \cap D-)$，在类别不平衡时尤其不可靠。一个将所有样本都预测为“阴性”的平凡分类器，在患病率极低时可以达到非常高的准确率（例如99%），但其灵敏度为零，临床价值也为零。

为了解决这个问题，发展了一些对[类别不平衡](@entry_id:636658)更稳健的度量：

-   **[平衡准确率](@entry_id:634900)（Balanced Accuracy）** 是灵敏度和特异性的[算术平均值](@entry_id:165355)：
    $$ \text{平衡准确率} = \frac{\text{灵敏度} + \text{特异性}}{2} = \frac{P(T+ \mid D+) + P(T- \mid D-)}{2} $$
    这个度量给予了阳性类别和阴性类别同等的权重，避免了准确率被多数类主导的问题[@problem_id:5094060]。

-   **$F_{\beta}$分数（$F_{\beta}$ Score）** 是[精确率和召回率](@entry_id:633919)（灵敏度）的加权[调和平均](@entry_id:750175)数：
    $$ F_{\beta} = \frac{(1+\beta^{2}) \cdot \text{精确率} \cdot \text{召回率}}{\beta^{2} \cdot \text{精确率} + \text{召回率}} $$
    参数 $\beta$ 控制着[精确率和召回率](@entry_id:633919)之间的权衡。当 $\beta=1$ 时，即为 **$F_1$分数**，给予二者同等重要性。当 $\beta > 1$ 时（例如$F_2$分数），更强调召回率，这在那些漏诊后果严重的罕见病筛查场景中尤为适用。当 $0  \beta  1$ 时，则更强调精确率[@problem_id:5094063]。

#### 评估曲线：ROC与PR

单个的度量值是在分类器某个特定的**决策阈值（Decision Threshold）**下计算的。为了评估分类器在所有可能阈值下的整体性能，我们使用评估曲线。

-   **[受试者工作特征曲线](@entry_id:754147)（Receiver Operating Characteristic, ROC）** 绘制了真阳性率（灵敏度）与假阳性率（$FPR = 1 - \text{特异性}$）的关系。曲线下的面积（**Area Under the ROC Curve, AUROC 或 AUC**）衡量了分类器将一个随机选择的正样本排在随机选择的负样本之前的概率。AUROC的一个重要特性是它对类别患病率不敏感，因为它完全由[条件概率](@entry_id:151013)$P(T+|D+)$和$P(T+|D-)$决定[@problem_id:5094063]。

-   **[精确率-召回率曲线](@entry_id:637864)（Precision-Recall Curve, PRC）** 绘制了精确率与召回率（灵敏度）的关系。曲线下的面积（**Area Under the PR Curve, AUPRC**）则提供了另一种性能评估视角。与[AUROC](@entry_id:636693)不同，AUPRC对患病率高度敏感。因为精确率本身依赖于患病率，一个随机分类器的基准精确率就等于患病率。在类别极度不平衡的情况下（低患病率），即使一个分类器的AUROC看起来很高，它的P[R曲线](@entry_id:183670)也可能非常贴近x轴，AUPRC值很低。因此，AUPRC能够更真实地反映模型在罕见病检测等不平衡场景下的实际表现，而AUROC可能会掩盖模型在低精确率方面的不足[@problem_id:5094063]。

### 诊断模型的构建块：算法与学习原理

[机器学习模型](@entry_id:262335)的核心任务是从数据中学习一个函数，该函数可以将输入的特征（例如，分子和免疫诊断的测量值）映射到诊断结果。我们在此介绍两种代表性的算法，它们体现了不同的建模哲学。

#### 概率模型：逻辑回归

**逻辑回归（Logistic Regression）**是一种直接对类别后验[概率建模](@entry_id:168598)的方法。给定一个特征向量 $x \in \mathbb{R}^d$，逻辑[回归模型](@entry_id:163386)假定类别为阳性（$Y=1$）的条件概率 $P(Y=1 \mid x)$ 由一个**逻辑函数（logistic function）**或**sigmoid函数** $\sigma(z) = \frac{1}{1 + e^{-z}}$ 给出：
$$ P(Y=1 \mid x) = \sigma(w^\top x + b) $$
其中 $w \in \mathbb{R}^d$ 是权重向量，$b \in \mathbb{R}$ 是偏置项。这个模型的核心假设是，[对数几率](@entry_id:141427)（log-odds）是特征的线性函数：
$$ \log \frac{P(Y=1\mid x)}{P(Y=0\mid x)} = w^\top x + b $$
逻辑回归是一个**参数模型（parametric model）**，因为它的复杂度由固定的参数数量（$d+1$）决定，与训练数据量无关。模型的参数 $(w, b)$ 通常通过**最大似然估计（Maximum Likelihood Estimation, MLE）**来学习，这等价于最小化**[负对数似然](@entry_id:637801)（Negative Log-Likelihood）**，也称为**[交叉熵损失](@entry_id:141524)（Cross-Entropy Loss）**。由于该[损失函数](@entry_id:136784)是一个**严格正常计分规则（strictly proper scoring rule）**，如果模型假设正确，逻辑回归能够输出良好校准的概率，这对于需要进行成本效益分析或决策阈值选择的临床应用非常有价值[@problem_id:5094088]。

#### 几何模型：[支持向量机](@entry_id:172128)

与直接建模概率不同，**[支持向量机](@entry_id:172128)（Support Vector Machine, SVM）**是一种基于几何间隔最大化的方法。对于线性可分的数据，线性SVM的目标是在特征空间中找到一个**[超平面](@entry_id:268044)（hyperplane）** $w^\top x + b = 0$，使得不同类别的样本点到该平面的**间隔（margin）**最大。

当数据线性不可分时，SVM通过**[核技巧](@entry_id:144768)（kernel trick）**展现其威力。[核技巧](@entry_id:144768)通过一个**[核函数](@entry_id:145324)（kernel function）** $K(x, z)$，隐式地将数据从原始[特征空间](@entry_id:638014)映射到一个更高维（甚至无限维）的[特征空间](@entry_id:638014) $\mathcal{H}$，并在这个高维空间中寻找线性分隔超平面。这种映射使得原本在低维空间中复杂的非线性决策边界，在高维空间中可能变为简单的线性边界。例如，一个经典的非线性问题，其中分类标签由两个生物标志物读数 $x_1$ 和 $x_2$ 的乘积 $x_1 x_2$ 的符号决定，即 $y = \mathrm{sign}(x_1 x_2)$。这种关系无法被任何[线性分类器](@entry_id:637554)（如线性SVM）在原始的 $(x_1, x_2)$ 空间中正确划分。然而，通过一个二次多项式核 $K(x, z) = (x^\top z)^2$，数据被隐式地映射到了一个包含交叉项 $x_1 x_2$ 的新[特征空间](@entry_id:638014)。在这个新空间中，数据变得线性可分[@problem_id:5094093]。

SVM通常通过最小化**[铰链损失](@entry_id:168629)（hinge loss）**进行优化，这是一个为实现[最大间隔](@entry_id:633974)分类而设计的[损失函数](@entry_id:136784)。与逻辑回归不同，标准的SVM是一个**[非参数模型](@entry_id:201779)（non-parametric model）**，因为其决策函数的复杂度依赖于训练数据中的一部分——**[支持向量](@entry_id:638017)（support vectors）**。它本身不直接输出概率，但可以通过后处理方法（如Platt缩放）来校准其输出以获得概率估计[@problem_id:5094088]。

#### 学习的驱动力：[损失函数](@entry_id:136784)

所[有监督学习](@entry_id:161081)算法的核心都是通过最小化一个**[损失函数](@entry_id:136784)（Loss Function）**来学习模型参数。[损失函数](@entry_id:136784)量化了模型预测与真实标签之间的差异。

-   **[0-1损失](@entry_id:173640)（0-1 Loss）**：$\ell_{01}(y, s) = \mathbb{1}\{ys \le 0\}$（其中$y \in \{-1,+1\}$是真实标签，$s$是模型得分），它直接计算分类错误的个数。这是分类任务的“终极”目标，但由于其非凸、非连续的性质，直接优化它在计算上是不可行的。

因此，我们转而使用其**代理[损失函数](@entry_id:136784)（surrogate losses）**，它们通常是[凸函数](@entry_id:143075)，易于优化。

-   **逻辑损失（Logistic Loss）**：$\ell_{\log}(y,s) = \log(1+\exp(-ys))$，用于逻辑回归。它平滑地惩罚错误分类，并且对置信度高的错误预测给予更大的惩罚。

-   **[铰链损失](@entry_id:168629)（Hinge Loss）**：$\ell_{\mathrm{hinge}}(y,s) = \max\{0, 1-ys\}$，用于SVM。它只惩罚那些不满足间隔要求的样本点（即$ys  1$），对于已经正确且“足够置信”地分类的样本不施加惩罚。

一个理想的代理[损失函数](@entry_id:136784)应具有**分类校准（classification-calibrated）**的特性。这意味着最小化该代理[损失函数](@entry_id:136784)的分类器，其决策边界会收敛到最小化[0-1损失](@entry_id:173640)的[贝叶斯最优分类器](@entry_id:164732)。逻辑损失和[铰链损失](@entry_id:168629)都满足这个重要的性质[@problem_id:5094031]。

-   **[焦点损失](@entry_id:634901)（Focal Loss）**：$\ell_{\mathrm{focal}}(y,q) = -(1-p_t)^{\gamma} \log(p_t)$（其中$p_t$是模型对真实类别的预测概率，$\gamma \ge 0$是聚焦参数）。这是对标准[交叉熵损失](@entry_id:141524)的一种改进，旨在解决极端类别不平衡问题。通过引入因子 $(1-p_t)^\gamma$，它会自动降低那些已经被模型很好分类的“简单”样本的权重，从而使训练过程更专注于那些难以分类的“困难”样本[@problem_id:5094031]。

### 从单一模型到集成：降低偏差与方差

在机器学习中，模型的[预测误差](@entry_id:753692)可以分解为**偏差（Bias）**、**方差（Variance）**和不可约误差。
-   **偏差**衡量了模型预测的平均值与真实值之间的差距，高偏差意味着模型[欠拟合](@entry_id:634904)（underfitting）。
-   **方差**衡量了模型在不同训练数据集上预测结果的变化程度，高方差意味着[模型过拟合](@entry_id:153455)（overfitting）。

**[集成学习](@entry_id:637726)（Ensemble Learning）**通过构建并结合多个学习器来完成学习任务，其核心思想是，多个“弱”学习器的组合可以形成一个强大的学习器。[集成方法](@entry_id:635588)是改善[模型泛化](@entry_id:174365)能力、平衡偏差与方差的有效策略。

#### 装袋（[Bagging](@entry_id:145854)）：降低方差

**装袋（Bootstrap Aggregating, [Bagging](@entry_id:145854)）**是一种并行[集成方法](@entry_id:635588)。它通过对原始训练数据进行**自助法采样（bootstrap sampling）**（即有放回地抽样）来创建多个不同的训练子集。然后，在每个子集上独立地训练一个基学习器（通常是高方差的模型，如未剪枝的决策树）。最后，通过对所有基学习器的预测结果进行平均（回归任务）或投票（[分类任务](@entry_id:635433)）来得到最终预测。

由于每个基学习器都在略有不同的数据上训练，它们的误差在一定程度上是独立的。通过平均这些预测，可以有效地平滑掉单个模型的波动，从而显著**降低整体模型的方差**。[Bagging](@entry_id:145854)对基学习器的偏差影响很小。随机森林（Random Forest）是[Bagging](@entry_id:145854)的一个著名扩展，它在训练[决策树](@entry_id:265930)时进一步引入了特征的随机选择，以降低基学习器之间的相关性，从而更有效地降低方差[@problem_id:5094054]。

#### 提升（Boosting）：降低偏差

与[Bagging](@entry_id:145854)的并行训练不同，**提升（Boosting）**是一种串行[集成方法](@entry_id:635588)。它迭代地构建一系列基学习器（通常是低方差的“弱”学习器，如浅层[决策树](@entry_id:265930)），每一个新的学习器都专注于纠正前一个学习器犯下的错误。例如，在[梯度提升](@entry_id:636838)（Gradient Boosting）中，每个新模型都拟合前一阶段模型的残差（residual）。

通过这种方式，Boosting将许多[弱学习器](@entry_id:634624)组合成一个强学习器，逐步**降低整体模型的偏差**。然而，由于其专注于拟合残差，如果迭代次数过多而没有适当的正则化（如[学习率](@entry_id:140210)收缩或[早停](@entry_id:633908)），Boosting模型也可能变得过于复杂，导致方差增加和[过拟合](@entry_id:139093)[@problem_id:5094054]。

#### 堆叠（Stacking）：优化组合

**堆叠（Stacked Generalization, Stacking）**是一种更复杂的[集成方法](@entry_id:635588)，它旨在学习如何最优地组合多个（通常是异构的）基学习器。Stacking分为两层：第一层的多个基学习器对训练数据进行预测，然后第二层（称为**[元学习器](@entry_id:637377) meta-learner**）将第一层基学习器的输出作为新的特征进行训练，以做出最终的预测。

Stacking的一个关键技术细节是为了防止**信息泄漏**。如果[元学习器](@entry_id:637377)使用基学习器在同一份训练数据上的预测结果作为输入，那么这些预测会显得过于“完美”，导致[元学习器](@entry_id:637377)过拟合。正确的做法是使用**[折外预测](@entry_id:634847)（out-of-fold predictions）**来生成[元学习器](@entry_id:637377)的训练集。这通常通过交叉验证实现：将训练数据分成K折，对每一折，用在另外K-1折上训练好的基学习器进行预测。这样，[元学习器](@entry_id:637377)的每个训练样本都是由未见过该样本的基学习器生成的[@problem_id:5094054]。

### 严谨验证的原则：避免陷阱与泄漏

构建一个在实验室数据上表现优异的模型相对容易，但要确保它在未来未见过的患者身上同样有效，则需要极其严谨的验证策略。

#### 分层数据中的信息泄漏

在许多临床研究中，我们可能会从每个患者身上采集多个样本（例如，来自同一肿瘤的不同空间瓦片或不同时间点的血样）。这种数据结构被称为**分层数据（hierarchical data）**或**聚类数据（clustered data）**。来自同一患者的样本并非相互独立，它们共享该患者固有的生物学特性（由一个潜在的患者特异性变量$U_i$表示）[@problem_id:5094048]。

如果在这种数据上进行常规的**样本级随机划分（sample-level splitting）**来创建[训练集](@entry_id:636396)、验证集和[测试集](@entry_id:637546)，将会导致严重的**信息泄漏（information leakage）**。这意味着同一个患者的某些样本可能出现在训练集中，而另一些样本则出现在测试集中。当模型在训练中“看到”了某个患者，它便学习了该患者的特有模式。因此，在[测试集](@entry_id:637546)上对该患者的其他样本进行预测时，任务变得异常“简单”，不再是真正意义上的泛化。这会导致模型性能被严重高估，产生**乐观偏差（optimistic bias）**。例如，在一个每位患者有10个样本的数据集中，如果按80/10/10的比例进行样本级随机划分，一个给定患者同时有样本进入[训练集](@entry_id:636396)和[测试集](@entry_id:637546)的概率高达约65%[@problem_id:5094048]。

避免这种泄漏的唯一方法是进行**患者级划分（patient-level splitting）**。这意味着必须将所有来自同一患者的样本作为一个整体，全部分配到[训练集](@entry_id:636396)、验证集或测试集中的某一个。划分的基本单位是患者，而不是样本[@problem_id:5094048]。

#### 黄金标准：[嵌套交叉验证](@entry_id:176273)

为了在进行[超参数调优](@entry_id:143653)的同时获得对[模型泛化](@entry_id:174365)性能的[无偏估计](@entry_id:756289)，**[嵌套交叉验证](@entry_id:176273)（nested cross-validation）**是黄金标准协议。

-   **外层循环**：将整个数据集（按患者）划分为K个折。每次循环，取一折作为最终的[测试集](@entry_id:637546)，其余K-1折作为完整的模型开发集。外层循环的主要目的是**评估性能**。
-   **内层循环**：在每个外层循环的模型开发集上，再进行一次交叉验证（同样按患者划分），用于**选择超参数**。
-   最终报告的性能是K次外层循环测试结果的平均值。

这个过程确保了用于最终性能评估的测试集在整个模型构建过程（包括超参数选择）中都是完全“未见过”的，从而提供了一个对未来性能的无偏估计[@problem_id:5094048]。

#### 处理技术变异：批次效应

在分子和免疫诊断中，[高通量测量](@entry_id:200163)（如多重免疫分析、[下一代测序](@entry_id:141347)）通常分批次进行。不同批次之间（例如，不同的实验板、操作员或试剂批号）可能存在非生物性的系统性变异，这被称为**[批次效应](@entry_id:265859)（batch effect）**。

批次效应与**混杂（confounding）**是两个不同但常常纠缠在一起的概念。
-   **[批次效应](@entry_id:265859)**是一种**技术性**变异，指即使生物学条件（$X_i$）完全相同，测量值（$Y_{gi}$）的期望也因批次（$B_i$）不同而不同。其严格定义是 $E[Y_{gi} \mid X_i, B_i] \neq E[Y_{gi} \mid X_i]$。
-   **混杂**是一种**生物学**与实验设计的纠缠，指重要的生物学协变量（如疾病严重程度）在不同批次间的分布不均衡。

如果生物学变量与批次存在混杂，那么观察到的测量值与批次之间的关联，既可能源于真正的技术性批次效应，也可能仅仅反映了不同批次中生物样本的差异。简单地对每个批次进行均值中心化等“校正”，会错误地移除与批次相关的真实生物学信号。

识别和处理批次效应的原则性方法包括[@problem_id:5094064]：
1.  **实验设计**：通过**前瞻性随机化**，确保不同类型的生物样本均匀分布在各个批次中，从设计上打破混杂。
2.  **使用对照**：利用先验知识（如管家基因、技术重复、加标对照），这些对照的读数理论上不应受生物学变量影响。在这些对照上观察到的与批次的关联，可以明确归因于技术性[批次效应](@entry_id:265859)。
3.  **[统计建模](@entry_id:272466)**：在分析模型中同时包含生物学协变量和批次[指示变量](@entry_id:266428)作为协变量（例如，作为固定效应或在[经验贝叶斯](@entry_id:171034)框架如ComBat中）。这样可以在保留生物学信号的同时，对批次效应进行调整。

### 超越预测：不确定性与因果关系

最先进的诊断AI系统不仅应提供预测，还应告知我们预测的[置信度](@entry_id:267904)，并帮助我们理解变量之间的关系是关联还是因果。

#### 量化预测不确定性

一个模型的预测不确定性可以分为两种类型[@problem_id:5094081]：

-   **[偶然不确定性](@entry_id:154011)（Aleatoric Uncertainty）**：源于数据生成过程中固有的、不可约的随机性或噪声。例如，qPCR扩增效率的随机波动或[ELISA](@entry_id:189985)测量的内在误差。即使拥有无限多的训练数据，这种不确定性依然存在。在[回归模型](@entry_id:163386)中，可以通过**异方差回归（heteroscedastic regression）**来建模，即让模型不仅预测均值 $\mu(x)$，还预测一个依赖于输入的方差 $\sigma^2(x)$。

-   **[认知不确定性](@entry_id:149866)（Epistemic Uncertainty）**：源于我们对模型参数的知识有限，即模型本身的不确定性。这种不确定性是由于训练数据量有限造成的。随着训练数据的增加，[认知不确定性](@entry_id:149866)通常会减小。**[贝叶斯神经网络](@entry_id:746725)（Bayesian Neural Networks, BNN）**是建模认知不确定性的理论框架，它为模型权重赋予先验分布，并通过数据学习其后验分布。

**[蒙特卡洛丢弃](@entry_id:636300)（[Monte Carlo Dropout](@entry_id:636300), MC-Dropout）**是一种在实践中近似BNN的流行技术。通过在测试时多次（例如$M$次）启用dropout进行[前向传播](@entry_id:193086)，我们可以得到一系列不同的预测均值 $\{\mu_m(x)\}_{m=1}^M$ 和方差 $\{\sigma_m^2(x)\}_{m=1}^M$。总预测方差可以分解为：
$$ \hat{\sigma}^2_{\text{total}}(x) \approx \underbrace{\frac{1}{M} \sum_{m=1}^{M} \sigma_m^2(x)}_{\text{偶然不确定性}} + \underbrace{\text{Var}(\{\mu_m(x)\})}_{\text{认知不确定性}} $$
例如，对于某输入$x$，4次MC-dropout预测的均值为$\{10.0, 10.4, 9.8, 10.2\}$，预测的方差为$\{0.25, 0.16, 0.36, 0.25\}$。那么，[偶然不确定性](@entry_id:154011)估计为这四个方差的均值，即$0.255$。认知不确定性估计为这四个均值的样本方差，即$0.067$。总预测方差约为两者之和，$0.322$ [@problem_id:5094081]。

#### 区分关联与因果

标准的[机器学习模型](@entry_id:262335)本质上是强大的**关联发现器**。一个分类器学习的是条件概率 $P(D \mid B)$，即在观察到生物标志物 $B$ 的情况下，疾病 $D$ 发生的概率。这是一个**关联性**量度[@problem_id:5094055]。然而，临床决策和科学理解往往需要**因果性**知识，例如：“如果我们通过干预将生物标志物$B$的水平设定为某个值，疾病$D$的风险会如何变化？”这个问题对应于**干预性概率（interventional probability）** $P(D \mid do(B=b))$。

**因果图（Causal Diagrams）**，通常是**有向无环图（Directed Acyclic Graphs, DAGs）**，为我们提供了一种形式化语言来推理因果关系。在DAG中，箭头表示直接的因果影响。例如，一个简化的模型可能是：遗传因素（$G$）和年龄（$A$）同时影响疾病状态（$D$）和生物标志物（$B$）；疾病状态（$D$）本身也会影响生物标志物（$D \to B$）[@problem_id:5094051]。

关联不等于因果。$P(D \mid B)$ 和 $P(D \mid do(B=b))$ 通常不相等。它们之间的差异由**混杂偏倚（confounding bias）**（[共同原因](@entry_id:266381)，如$D \leftarrow G \to B$）和**逆向因果（reverse causation）**（如$D \to B$）等非因果路径造成。在DAG框架下，如果从$B$到$D$不存在任何有向路径，那么$B$对$D$没有因果效应。这意味着干预$B$不会改变$D$的概率，即 $P(D \mid do(B=b)) = P(D)$。然而，即使在这种情况下，$B$仍然可以是一个很好的**预测因子**，因为$P(D \mid B)$可能由于上述的非因果路径而包含大量关于$D$的信息[@problem_id:5094051]。

此外，DAGs还有助于识别和理解**选择偏倚（selection bias）**。例如，如果分析仅限于那些被医生下令检测了生物标志物$B$的患者，而下令检测这个行为本身又受到症状严重程度（$S$）的影响，而症状又由疾病（$D$）引起，那么这种选择行为可能会在$D$和其他影响$B$的因素之间引入虚假的[统计关联](@entry_id:172897)，使因果效应的估计变得复杂[@problem_id:5094051]。理解这些原理对于从观察性临床数据中得出可靠结论至关重要。