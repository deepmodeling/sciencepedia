{"hands_on_practices": [{"introduction": "理论学习的精髓在于实践。本节的第一个练习将带您回归基础，从第一性原理出发进行推导。我们将不直接使用已知的负二项分布公式，而是通过一个巧妙的技巧——将问题分解为一系列更简单的独立同分布的几何随机变量之和——来推导其期望和方差([@problem_id:4962576])。这种化繁为简的分解思想是概率论中解决复杂问题的一个核心策略。", "problem": "一家临床微生物学实验室监测患者的血培养抽样是否受到污染。每次抽样或者导致污染事件（失败），其概率为 $p \\in (0,1)$；或者得到洁净结果（成功），其概率为 $1-p$。假设在稳定条件下，抽样是依次独立进行的。该方案将持续进行，直到观察到 $r \\in \\mathbb{N}$ 次洁净结果（成功），此时采样停止。定义随机变量 $X$ 为在观察到第 $r$ 次洁净结果之前发生的污染事件（失败）的总数。\n\n从此类直至r次成功的失败次数停止规则出发，从独立伯努利试验以及随机变量的期望和方差的定义开始，且不借助任何关于负二项分布的预先推导出的公式，推导期望 $E[X]$ 和方差 $\\mathrm{Var}(X)$ 关于 $r$ 和 $p$ 的闭式解析表达式。请将最终答案表示为精确的符号表达式；无需进行数值四舍五入。", "solution": "首先对问题陈述进行验证。\n\n### 步骤1：提取已知条件\n- 进行一系列独立的伯努利试验。\n- 每次试验结果为“污染事件”（失败），概率为 $p$；或“洁净结果”（成功），概率为 $1-p$。\n- 失败概率指定为 $p \\in (0,1)$。\n- 过程在观察到第 $r$ 次成功时终止，其中 $r \\in \\mathbb{N}$。\n- 随机变量 $X$ 定义为在第 $r$ 次成功之前发生的失败总数。\n- 目标是推导期望 $E[X]$ 和方差 $\\mathrm{Var}(X)$ 关于 $r$ 和 $p$ 的表达式。\n- 推导过程不得依赖于负二项分布的预先推导公式，而必须从独立伯努利试验以及期望和方差的性质出发。\n\n### 步骤2：使用提取的已知条件进行验证\n该问题具有科学依据、提法恰当且客观。它描述了概率论中一个由负二项分布建模的经典场景。序列独立的伯努利试验设置是统计学中的一个基本概念。参数 $p$ 和 $r$ 有明确的定义和适当的定义域，确保了问题的自洽性和数学上的一致性。任务是从第一性原理进行推导，这是概率论中一个标准的、非平凡的练习。该问题不违反任何科学原理，没有歧义，并包含了获得唯一解所需的所有信息。\n\n### 步骤3：结论与行动\n该问题是有效的。将提供一个完整的、附有推理过程的解。\n\n### 推导\n该问题描述了一系列独立的伯努利试验，其中成功的概率为 $1-p$，失败的概率为 $p$。随机变量 $X$ 记录了在累积到 $r$ 次成功之前失败的总次数。\n\n为了从第一性原理推导 $X$ 的期望和方差，我们可以将 $X$ 分解为一些更简单的随机变量之和。设 $Y_i$ 为第 $(i-1)$ 次成功与第 $i$ 次成功之间的失败次数，其中 $i=1, 2, \\dots, r$。我们将第 $0$ 次成功定义为试验的开始。\n\n总失败次数 $X$ 是这些中间失败次数的总和：\n$$X = Y_1 + Y_2 + \\dots + Y_r$$\n因为各次试验是独立的，并且过程条件是稳定的，所以一次成功后的失败次数不影响下一次成功前的失败次数。因此，随机变量 $Y_1, Y_2, \\dots, Y_r$ 是独立同分布 (i.i.d.) 的。\n\n让我们确定其中任意一个变量（例如 $Y_i$）的概率分布。事件 $Y_i=k$（其中 $k \\in \\{0, 1, 2, \\dots\\}$）表示在第 $(i-1)$ 次成功之后，恰好有 $k$ 次失败，随后是一次成功。这个由 $k+1$ 次试验组成的特定序列的概率是 $p^k(1-p)$。因此，$Y_i$ 的概率质量函数 (PMF) 为：\n$$P(Y_i=k) = p^k(1-p) \\quad \\text{for } k = 0, 1, 2, \\dots$$\n这定义了一个在非负整数上的几何分布。\n\n**期望 $E[X]$ 的推导**\n\n根据期望的线性性，随机变量之和的期望等于它们各自期望之和：\n$$E[X] = E\\left[\\sum_{i=1}^{r} Y_i\\right] = \\sum_{i=1}^{r} E[Y_i]$$\n由于 $Y_i$ 是同分布的，所以对所有 $i$ 都有 $E[Y_i] = E[Y_1]$。因此：\n$$E[X] = r E[Y_1]$$\n我们直接根据定义计算 $E[Y_1]$：\n$$E[Y_1] = \\sum_{k=0}^{\\infty} k \\cdot P(Y_1=k) = \\sum_{k=0}^{\\infty} k p^k (1-p) = (1-p) \\sum_{k=0}^{\\infty} k p^k$$\n为了计算这个求和，我们使用几何级数及其导数的公式。对于 $|z|1$，我们有：\n$$\\sum_{k=0}^{\\infty} z^k = \\frac{1}{1-z}$$\n两边对 $z$ 求导，得到：\n$$\\frac{d}{dz} \\sum_{k=0}^{\\infty} z^k = \\sum_{k=1}^{\\infty} k z^{k-1} = \\frac{d}{dz} \\left(\\frac{1}{1-z}\\right) = \\frac{1}{(1-z)^2}$$\n乘以 $z$：\n$$\\sum_{k=1}^{\\infty} k z^k = \\frac{z}{(1-z)^2}$$\n由于 $\\sum k z^k$ 中 $k=0$ 的项为零，所以这也等于 $\\sum_{k=0}^{\\infty} k z^k$。代入 $z=p$（因为 $p \\in (0,1)$，所以有 $|p|1$）：\n$$\\sum_{k=0}^{\\infty} k p^k = \\frac{p}{(1-p)^2}$$\n现在，我们把这个结果代回到 $E[Y_1]$ 的表达式中：\n$$E[Y_1] = (1-p) \\left( \\frac{p}{(1-p)^2} \\right) = \\frac{p}{1-p}$$\n最后，$X$ 的期望是：\n$$E[X] = r E[Y_1] = \\frac{rp}{1-p}$$\n\n**方差 $\\mathrm{Var}(X)$ 的推导**\n\n由于随机变量 $Y_1, Y_2, \\dots, Y_r$ 是独立的，它们之和的方差等于它们各自方差之和：\n$$\\mathrm{Var}(X) = \\mathrm{Var}\\left(\\sum_{i=1}^{r} Y_i\\right) = \\sum_{i=1}^{r} \\mathrm{Var}(Y_i)$$\n由于 $Y_i$ 是同分布的，所以对所有 $i$ 都有 $\\mathrm{Var}(Y_i) = \\mathrm{Var}(Y_1)$。因此：\n$$\\mathrm{Var}(X) = r \\mathrm{Var}(Y_1)$$\n$Y_1$ 的方差由 $\\mathrm{Var}(Y_1) = E[Y_1^2] - (E[Y_1])^2$ 给出。我们已经求出了 $E[Y_1]$。现在我们需要计算 $E[Y_1^2]$：\n$$E[Y_1^2] = \\sum_{k=0}^{\\infty} k^2 \\cdot P(Y_1=k) = \\sum_{k=0}^{\\infty} k^2 p^k (1-p) = (1-p) \\sum_{k=0}^{\\infty} k^2 p^k$$\n为了计算 $\\sum k^2 p^k$，我们将级数 $\\sum k z^k = \\frac{z}{(1-z)^2}$ 对 $z$ 求导：\n$$\\frac{d}{dz} \\sum_{k=1}^{\\infty} k z^k = \\sum_{k=1}^{\\infty} k^2 z^{k-1} = \\frac{d}{dz} \\left( \\frac{z}{(1-z)^2} \\right)$$\n使用商法则：\n$$\\frac{d}{dz} \\left( \\frac{z}{(1-z)^2} \\right) = \\frac{(1)(1-z)^2 - z(2(1-z)(-1))}{((1-z)^2)^2} = \\frac{(1-z)^2 + 2z(1-z)}{(1-z)^4} = \\frac{1-z+2z}{(1-z)^3} = \\frac{1+z}{(1-z)^3}$$\n乘以 $z$：\n$$\\sum_{k=1}^{\\infty} k^2 z^k = \\frac{z(1+z)}{(1-z)^3}$$\n这等价于 $\\sum_{k=0}^{\\infty} k^2 z^k$。我们代入 $z=p$：\n$$\\sum_{k=0}^{\\infty} k^2 p^k = \\frac{p(1+p)}{(1-p)^3}$$\n现在我们计算 $E[Y_1^2]$：\n$$E[Y_1^2] = (1-p) \\left( \\frac{p(1+p)}{(1-p)^3} \\right) = \\frac{p(1+p)}{(1-p)^2}$$\n现在我们可以计算 $Y_1$ 的方差：\n$$\\mathrm{Var}(Y_1) = E[Y_1^2] - (E[Y_1])^2 = \\frac{p(1+p)}{(1-p)^2} - \\left(\\frac{p}{1-p}\\right)^2$$\n$$\\mathrm{Var}(Y_1) = \\frac{p+p^2}{(1-p)^2} - \\frac{p^2}{(1-p)^2} = \\frac{p+p^2-p^2}{(1-p)^2} = \\frac{p}{(1-p)^2}$$\n最后，$X$ 的方差是：\n$$\\mathrm{Var}(X) = r \\mathrm{Var}(Y_1) = \\frac{rp}{(1-p)^2}$$\n\n推导出的期望和方差的表达式为 $E[X] = \\frac{rp}{1-p}$ 和 $\\mathrm{Var}(X) = \\frac{rp}{(1-p)^2}$。", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{rp}{1-p}  \\frac{rp}{(1-p)^2} \\end{pmatrix}}$$", "id": "4962576"}, {"introduction": "在生物医学研究中，数据变换（如对数变换）是满足模型假设的常用手段。然而，将结果变换回原始尺度时，一个不容忽视的问题便是偏误的产生([@problem_id:4962594])。本练习将深入探讨这一现象，通过分析对数正态分布，揭示为何对均值的简单指数变换会产生一个有偏估计，并指导您如何推导出一个包含方差修正项的估计量。掌握这一技能对于准确解释模型结果至关重要。", "problem": "在一项抗炎治疗的纵向临床研究中，由于乘性生物变异性的存在，患者体内的生物标志物血浆浓度被建模为对数正态分布。具体来说，对于一个给定的时间点，假设 $Y$ 表示生物标志物的浓度（在原始尺度上测量），并令 $X = \\ln(Y)$。我们假设一个参数模型，其中 $X$ 在不同患者之间是独立同分布的，服从均值为 $\\mu$、方差为 $\\sigma^{2}$ 的正态分布，即 $X \\sim N(\\mu,\\sigma^{2})$。从一个观测样本 $\\{Y_{1},\\dots,Y_{n}\\}$ 中，定义 $X_{i} = \\ln(Y_{i})$，并将正态参数的最大似然估计量（MLE）表示为 $\\hat{\\mu} = \\frac{1}{n}\\sum_{i=1}^{n} X_{i}$ 和 $\\hat{\\sigma}^{2} = \\frac{1}{n}\\sum_{i=1}^{n}(X_{i} - \\hat{\\mu})^{2}$。期望浓度 $E[Y]$ 的一个广泛使用的“朴素”估计量是 $\\exp(\\hat{\\mu})$。\n\n仅使用期望的定义和正态分布的公认性质，请给出 $E[Y]$（用 $\\mu$ 和 $\\sigma^{2}$ 表示）的第一性原理推导，然后证明在该指定模型下，朴素估计量 $\\exp(\\hat{\\mu})$ 对于 $E[Y]$ 是有偏的。基于这些推导，提出并简化一个闭式、基于模型的置换估计量，该估计量可以在从观测样本估计 $E[Y]$ 时校正因变换引起的偏差，并仅用 $\\hat{\\mu}$ 和 $\\hat{\\sigma}^{2}$ 表示。您的最终答案必须是一个单一的闭式解析表达式。不需要进行四舍五入，且最终表达式中不应包含任何单位。", "solution": "问题要求推导一个对数正态分布随机变量的期望值，分析该期望值的朴素估计量的偏差，并构建一个校正后的置换估计量。对问题陈述的验证证实了其科学上的合理性、提法得当且客观。我们可以开始解答。\n\n问题定义了一个随机变量 $Y$，代表生物标志物浓度，使得 $X = \\ln(Y)$ 服从均值为 $\\mu$、方差为 $\\sigma^2$ 的正态分布。我们将其记为 $X \\sim N(\\mu, \\sigma^2)$。因此，随机变量 $Y$ 服从对数正态分布。\n\n首先，我们从第一性原理推导 $Y$ 的期望值，记为 $E[Y]$。由于 $Y = \\exp(X)$，其期望由 $\\exp(x)$ 乘以 $X$ 的概率密度函数（PDF）的积分给出。$X \\sim N(\\mu, \\sigma^2)$ 的概率密度函数为：\n$$f_X(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)$$\n于是 $Y$ 的期望为：\n$$E[Y] = E[\\exp(X)] = \\int_{-\\infty}^{\\infty} \\exp(x) f_X(x) dx = \\int_{-\\infty}^{\\infty} \\exp(x) \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right) dx$$\n我们可以合并指数函数的参数：\n$$E[Y] = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\int_{-\\infty}^{\\infty} \\exp\\left(x - \\frac{(x-\\mu)^2}{2\\sigma^2}\\right) dx$$\n为了求解这个积分，我们对指数中的项进行配方：\n$$x - \\frac{(x-\\mu)^2}{2\\sigma^2} = x - \\frac{x^2 - 2\\mu x + \\mu^2}{2\\sigma^2} = \\frac{2\\sigma^2 x - (x^2 - 2\\mu x + \\mu^2)}{2\\sigma^2}$$\n$$= -\\frac{1}{2\\sigma^2} [x^2 - 2\\mu x - 2\\sigma^2 x + \\mu^2] = -\\frac{1}{2\\sigma^2} [x^2 - 2(\\mu+\\sigma^2)x + \\mu^2]$$\n我们对关于 $x$ 的多项式进行配方：$x^2 - 2(\\mu+\\sigma^2)x + \\mu^2 = [x - (\\mu+\\sigma^2)]^2 - (\\mu+\\sigma^2)^2 + \\mu^2 = [x - (\\mu+\\sigma^2)]^2 - (\\mu^2 + 2\\mu\\sigma^2 + \\sigma^4) + \\mu^2 = [x - (\\mu+\\sigma^2)]^2 - 2\\mu\\sigma^2 - \\sigma^4$。\n将此代回指数中：\n$$-\\frac{1}{2\\sigma^2} \\left( [x - (\\mu+\\sigma^2)]^2 - 2\\mu\\sigma^2 - \\sigma^4 \\right) = -\\frac{[x - (\\mu+\\sigma^2)]^2}{2\\sigma^2} + \\frac{2\\mu\\sigma^2 + \\sigma^4}{2\\sigma^2} = -\\frac{[x - (\\mu+\\sigma^2)]^2}{2\\sigma^2} + \\mu + \\frac{\\sigma^2}{2}$$\n现在我们可以重写 $E[Y]$ 的积分：\n$$E[Y] = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\int_{-\\infty}^{\\infty} \\exp\\left(-\\frac{[x - (\\mu+\\sigma^2)]^2}{2\\sigma^2} + \\mu + \\frac{\\sigma^2}{2}\\right) dx$$\n项 $\\exp(\\mu + \\frac{\\sigma^2}{2})$ 相对于 $x$ 是一个常数，可以被提出来：\n$$E[Y] = \\exp\\left(\\mu + \\frac{\\sigma^2}{2}\\right) \\int_{-\\infty}^{\\infty} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{[x - (\\mu+\\sigma^2)]^2}{2\\sigma^2}\\right) dx$$\n该积分是均值为 $\\mu' = \\mu+\\sigma^2$、方差为 $\\sigma^2$ 的正态分布的概率密度函数下的总面积。该积分等于 $1$。\n因此，$Y$ 的期望值为：\n$$E[Y] = \\exp\\left(\\mu + \\frac{1}{2}\\sigma^2\\right)$$\n这个结果也可以通过认识到 $E[\\exp(X)]$ 是 $X$ 的矩生成函数（MGF） $M_X(t) = E[\\exp(tX)]$ 在 $t=1$ 处的值来获得。对于 $X \\sim N(\\mu, \\sigma^2)$，其矩生成函数为 $M_X(t) = \\exp(\\mu t + \\frac{1}{2}\\sigma^2 t^2)$。在 $t=1$ 处求值会得到相同的结果。\n\n接下来，我们讨论朴素估计量 $\\exp(\\hat{\\mu})$ 的偏差。$\\mu$ 的估计量是对数转换后数据的样本均值，即 $\\hat{\\mu} = \\frac{1}{n}\\sum_{i=1}^{n} X_i$。由于每个 $X_i$ 都是来自 $N(\\mu, \\sigma^2)$ 的独立随机变量，$\\hat{\\mu}$ 也服从正态分布。其均值为 $E[\\hat{\\mu}] = E[\\frac{1}{n}\\sum X_i] = \\frac{1}{n}\\sum E[X_i] = \\frac{1}{n}(n\\mu) = \\mu$。其方差为 $Var(\\hat{\\mu}) = Var(\\frac{1}{n}\\sum X_i) = \\frac{1}{n^2}\\sum Var(X_i) = \\frac{1}{n^2}(n\\sigma^2) = \\frac{\\sigma^2}{n}$。\n因此，$\\hat{\\mu} \\sim N(\\mu, \\frac{\\sigma^2}{n})$。\n\n为了评估估计量 $\\exp(\\hat{\\mu})$ 的偏差，我们计算它的期望 $E[\\exp(\\hat{\\mu})]$。这是 $\\hat{\\mu}$ 在 $t=1$ 处的矩生成函数的值。使用均值为 $\\mu$、方差为 $\\sigma^2/n$ 的正态变量的矩生成函数公式：\n$$E[\\exp(\\hat{\\mu})] = \\exp\\left(\\mu \\cdot 1 + \\frac{1}{2}\\left(\\frac{\\sigma^2}{n}\\right) \\cdot 1^2\\right) = \\exp\\left(\\mu + \\frac{\\sigma^2}{2n}\\right)$$\n估计量的偏差是其期望与被估量的真值之差：\n$$B(\\exp(\\hat{\\mu})) = E[\\exp(\\hat{\\mu})] - E[Y] = \\exp\\left(\\mu + \\frac{\\sigma^2}{2n}\\right) - \\exp\\left(\\mu + \\frac{\\sigma^2}{2}\\right)$$\n对于任何有限样本量 $n  1$ 和非零的生物变异性 $\\sigma^2  0$，我们有 $\\frac{\\sigma^2}{2n}  \\frac{\\sigma^2}{2}$。由于指数函数是严格单调递增的，所以 $\\exp(\\mu + \\frac{\\sigma^2}{2n})  \\exp(\\mu + \\frac{\\sigma^2}{2})$。因此，偏差非零（具体来说，是负的），并且估计量 $\\exp(\\hat{\\mu})$ 对于 $E[Y]$ 是有偏的。它系统性地低估了真实的平均浓度。这种偏差源于将非线性指数变换应用于对数尺度上的均值估计量，而忽略了方差的贡献（这是琴生不等式的一个推论）。这个“朴素”估计量实际上估计的是 $\\exp(\\mu)$，而不是正确的目标量 $\\exp(\\mu + \\frac{1}{2}\\sigma^2)$。\n\n最后，我们提出了一个基于模型的置换估计量，用以校正这种由变换引起的偏差。$E[Y]$ 的推导表明，对均值的正确估计需要同时考虑 $\\mu$ 和 $\\sigma^2$。对朴素估计量偏差的“校正”涉及到将方差项 $\\frac{1}{2}\\sigma^2$ 纳入表达式中。校正后的目标表达式是 $\\exp(\\mu + \\frac{1}{2}\\sigma^2)$。\n“置换”估计量是通过在目标量的表达式中用参数的估计量替代真参数来形成的。问题给出了 $\\mu$ 和 $\\sigma^2$ 的最大似然估计量（MLE）：\n$$\\hat{\\mu} = \\frac{1}{n}\\sum_{i=1}^{n} X_{i}$$\n$$\\hat{\\sigma}^{2} = \\frac{1}{n}\\sum_{i=1}^{n}(X_{i} - \\hat{\\mu})^{2}$$\n将这些估计量代入 $E[Y]$ 的表达式，就得到了基于模型的置换估计量，我们将其记为 $\\hat{E}[Y]$：\n$$\\hat{E}[Y] = \\exp\\left(\\hat{\\mu} + \\frac{1}{2}\\hat{\\sigma}^2\\right)$$\n该估计量明确地使用了模型结构（$Y$ 是对数正态分布），并通过包含方差项的估计来校正朴素估计量的主要缺陷。该表达式已经是关于指定的估计量 $\\hat{\\mu}$ 和 $\\hat{\\sigma}^2$ 的最简闭式形式。", "answer": "$$\\boxed{\\exp\\left(\\hat{\\mu} + \\frac{1}{2}\\hat{\\sigma}^{2}\\right)}$$", "id": "4962594"}, {"introduction": "当一个估计量的精确方差难以计算时，我们常需求助于近似方法。Delta方法就是这样一种强大工具，它利用泰勒展开来近似一个经过变换的估计量的方差([@problem_id:4962586])。本练习将指导您应用Delta方法，推导在生物统计中至关重要的logit变换的渐近方差，这对于理解和构建置信区间（例如在逻辑回归中）至关重要。", "problem": "在一项多中心心血管安全性监测研究中，假设每位入组患者在监测期间独立地经历一个二元结局，该结局指示是否发生了具有临床意义的心律失常，其真实概率为 $p$，其中 $0  p  1$。共招募了 $n$ 位患者，观察到发生心律失常的总人数为 $Y$。经验风险被估计为 $\\hat{p}=Y/n$。在逻辑回归等广义线性模型中，通常对风险的 logit 变换进行建模，定义为 $\\beta = \\ln\\left(\\frac{p}{1-p}\\right)$。相应的估计量为 $\\hat{\\beta} = \\ln\\left(\\frac{\\hat{p}}{1-\\hat{p}}\\right)$。\n\n运用中心极限定理和大样本理论，应用 delta 方法推导 $\\hat{\\beta}$ 的渐近方差 $\\text{AsyVar}(\\hat{\\beta})$ 的一个闭式解析表达式，该表达式应为关于 $n$ 和 $p$ 的函数。您的答案中不应包含任何单位。", "solution": "问题要求解 logit 变换后的经验风险 $\\hat{\\beta} = \\ln\\left(\\frac{\\hat{p}}{1-\\hat{p}}\\right)$ 的渐近方差，其中 $\\hat{p} = Y/n$ 是来自 $n$ 次独立伯努利试验的事件样本比例。推导过程将首先确定计数变量 $Y$ 和样本比例 $\\hat{p}$ 的统计特性，然后应用中心极限定理 (CLT)，最后使用 delta 方法求出变换后统计量 $\\hat{\\beta}$ 的渐近方差。\n\n**步骤 1：二项分布模型与 $\\hat{p}$ 的性质**\n\n发生心律失常的患者数 $Y$ 是 $n$ 次独立同分布的伯努利试验之和，每次试验的成功概率（发生心律失常的概率）为 $p$。因此，$Y$ 服从二项分布：\n$$Y \\sim \\text{Binomial}(n, p)$$\n$Y$ 的期望值和方差由下式给出：\n$$E[Y] = np$$\n$$\\text{Var}(Y) = np(1-p)$$\n经验风险 $\\hat{p}$ 定义为样本比例 $\\hat{p} = Y/n$。我们可以利用期望和方差的性质求出其精确的均值和方差：\n$$E[\\hat{p}] = E\\left[\\frac{Y}{n}\\right] = \\frac{1}{n}E[Y] = \\frac{np}{n} = p$$\n这表明 $\\hat{p}$ 是 $p$ 的无偏估计量。\n$$\\text{Var}(\\hat{p}) = \\text{Var}\\left(\\frac{Y}{n}\\right) = \\frac{1}{n^2}\\text{Var}(Y) = \\frac{np(1-p)}{n^2} = \\frac{p(1-p)}{n}$$\n\n**步骤 2：通过中心极限定理得到 $\\hat{p}$ 的大样本行为**\n\n中心极限定理 (CLT) 指出，对于大样本量 $n$，样本均值（或比例）$\\hat{p}$ 的分布近似为正态分布。更正式地，经过缩放和中心化的统计量在分布上收敛于一个标准正态随机变量：\n$$\\frac{\\hat{p} - E[\\hat{p}]}{\\sqrt{\\text{Var}(\\hat{p})}} = \\frac{\\hat{p} - p}{\\sqrt{\\frac{p(1-p)}{n}}} \\xrightarrow{d} N(0, 1) \\quad \\text{as } n \\to \\infty$$\n将分子和分母同乘以 $\\sqrt{n}$，我们可以将其表示为 delta 方法使用的标准形式：\n$$\\sqrt{n}(\\hat{p} - p) \\xrightarrow{d} N(0, p(1-p))$$\n该结果确立了 $\\hat{p}$ 的大样本行为，表明它是渐近正态的，其方差参数为 $p(1-p)$。\n\n**步骤 3：应用 Delta 方法**\n\nDelta 方法用于确定一个渐近正态随机变量的函数的渐近分布。设 $g(\\theta)$ 是一个连续可微函数，使得 $g'(\\theta) \\neq 0$。如果一个估计量 $\\hat{\\theta}_n$ 满足\n$$\\sqrt{n}(\\hat{\\theta}_n - \\theta) \\xrightarrow{d} N(0, \\sigma^2)$$\n那么变换后的估计量 $g(\\hat{\\theta}_n)$ 的分布由下式给出\n$$\\sqrt{n}(g(\\hat{\\theta}_n) - g(\\theta)) \\xrightarrow{d} N(0, [g'(\\theta)]^2 \\sigma^2)$$\n在我们的问题中，估计量是 $\\hat{\\theta}_n = \\hat{p}$，真实参数是 $\\theta = p$，并且根据中心极限定理，渐近方差参数是 $\\sigma^2 = p(1-p)$。变换是 logit 函数，$g(p) = \\ln\\left(\\frac{p}{1-p}\\right)$。我们感兴趣的统计量是 $\\hat{\\beta} = g(\\hat{p})$。\n\n首先，我们必须计算 $g(p)$ 的导数。为方便计算，可以先利用对数的性质重写 $g(p)$：\n$$g(p) = \\ln(p) - \\ln(1-p)$$\n关于 $p$ 的导数是：\n$$g'(p) = \\frac{d}{dp}[\\ln(p) - \\ln(1-p)] = \\frac{1}{p} - \\frac{1}{1-p} \\cdot (-1) = \\frac{1}{p} + \\frac{1}{1-p}$$\n将这些项通分合并后得到：\n$$g'(p) = \\frac{(1-p) + p}{p(1-p)} = \\frac{1}{p(1-p)}$$\n条件 $0  p  1$ 确保了该导数有良好定义且不为零。\n\n现在，我们可以应用 delta 方法的公式。$\\sqrt{n}(g(\\hat{p})-g(p))$ 的渐近分布的方差是 $[g'(p)]^2 \\sigma^2$：\n$$[g'(p)]^2 \\sigma^2 = \\left(\\frac{1}{p(1-p)}\\right)^2 \\cdot [p(1-p)] = \\frac{1}{[p(1-p)]^2} \\cdot p(1-p) = \\frac{1}{p(1-p)}$$\n因此，$\\hat{\\beta}$ 的渐近分布为：\n$$\\sqrt{n}(\\hat{\\beta} - \\beta) \\xrightarrow{d} N\\left(0, \\frac{1}{p(1-p)}\\right)$$\n其中 $\\beta = g(p)$ 是真实的 logit 变换后的风险。\n\n**步骤 4：推导 $\\hat{\\beta}$ 的渐近方差**\n\nDelta 方法的结果意味着，对于大的 $n$，$\\hat{\\beta}$ 的抽样分布可以由一个正态分布来近似：\n$$\\hat{\\beta} \\approx N\\left(\\beta, \\frac{1}{n}\\left(\\frac{1}{p(1-p)}\\right)\\right)$$\n术语“$\\hat{\\beta}$ 的渐近方差”，记为 $\\text{AsyVar}(\\hat{\\beta})$，指的是这个近似正态分布的方差。因此，我们有：\n$$\\text{AsyVar}(\\hat{\\beta}) = \\frac{1}{np(1-p)}$$\n这个表达式就是所求的闭式解析结果。它与样本量 $n$ 和单次伯努利试验的方差 $p(1-p)$ 均成反比。当 $p$ 接近 $0$ 或 $1$ 时，logit 函数最陡峭，估计量的方差最大；当 $p=0.5$ 时，估计量的方差最小。", "answer": "$$\n\\boxed{\\frac{1}{np(1-p)}}\n$$", "id": "4962586"}]}