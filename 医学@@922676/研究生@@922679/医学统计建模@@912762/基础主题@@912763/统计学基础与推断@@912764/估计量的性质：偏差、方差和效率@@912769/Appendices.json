{"hands_on_practices": [{"introduction": "这个练习将通过两个最常见的总体方差估计量来探讨经典的“偏误-方差权衡”。通过推导有偏的最大似然估计量 $\\hat{\\sigma}^{2}_{\\mathrm{MLE}}$ 和标准的无偏估计量 $\\hat{\\sigma}^{2}_{U}$ 的性质，您将看到为什么无偏估计量在均方误差（MSE）方面并不总是最高效的选择 [@problem_id:4831014]。这个练习对于理解统计估计的精妙目标至关重要。", "problem": "一个生物统计学团队在分析独立患者中连续生物标志物的变异性时，假设重复测量值$X_{1},\\dots,X_{n}$是从均值$\\mu$和方差$\\sigma^{2}$未知的正态分布$N(\\mu,\\sigma^{2})$中抽取的独立同分布样本。考虑方差的两个估计量：最大似然估计量(MLE)，定义为$\\hat{\\sigma}^{2}_{\\mathrm{MLE}}=\\frac{1}{n}\\sum_{i=1}^{n}\\left(X_{i}-\\bar{X}\\right)^{2}$，以及分母为$n-1$的无偏样本方差，定义为$\\hat{\\sigma}^{2}_{U}=\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(X_{i}-\\bar{X}\\right)^{2}$，其中$\\bar{X}=\\frac{1}{n}\\sum_{i=1}^{n}X_{i}$。从偏误、方差和均方误差的定义出发，并利用正态模型的标准分布性质（特别是中心化正态变量平方和的缩放形式服从卡方分布），推导$\\hat{\\sigma}^{2}_{\\mathrm{MLE}}$作为$n$和$\\sigma^{2}$的函数的精确有限样本偏误。然后，对于有限的$n$，比较$\\hat{\\sigma}^{2}_{\\mathrm{MLE}}$与$\\hat{\\sigma}^{2}_{U}$的均方误差，并讨论在均方误差意义下哪个估计量更有效，以及当$n\\to\\infty$时两个估计量是否都具有一致性。仅报告$\\hat{\\sigma}^{2}_{\\mathrm{MLE}}$的精确有限样本偏误作为最终答案。无需四舍五入。", "solution": "该问题是有效的，因为它具有科学依据，提法明确，客观且完整。这是一个关于正态分布方差估计量性质的数理统计标准问题。我们继续进行解答。\n\n设重复测量值为$X_{1}, \\dots, X_{n}$，它们是来自正态分布$N(\\mu, \\sigma^{2})$的独立同分布(i.i.d.)随机变量。样本均值为$\\bar{X} = \\frac{1}{n}\\sum_{i=1}^{n}X_{i}$。\n\n方差$\\sigma^{2}$的两个估计量如下所示：\n$1$. 最大似然估计量(MLE)：$\\hat{\\sigma}^{2}_{\\mathrm{MLE}} = \\frac{1}{n}\\sum_{i=1}^{n}(X_{i} - \\bar{X})^{2}$。\n$2$. 无偏样本方差：$\\hat{\\sigma}^{2}_{U} = \\frac{1}{n-1}\\sum_{i=1}^{n}(X_{i} - \\bar{X})^{2}$。\n\n我们将根据偏误、方差、均方误差(MSE)和一致性来分析这些估计量。参数$\\theta$的估计量$\\hat{\\theta}$的偏误定义为$\\text{Bias}(\\hat{\\theta}) = E[\\hat{\\theta}] - \\theta$。MSE定义为$\\text{MSE}(\\hat{\\theta}) = E[(\\hat{\\theta} - \\theta)^{2}]$，它可以分解为$\\text{MSE}(\\hat{\\theta}) = \\text{Var}(\\hat{\\theta}) + (\\text{Bias}(\\hat{\\theta}))^{2}$。\n\n统计理论中关于正态分布样本的一个基本结果（特别是Cochran定理的一个推论）是，量$\\frac{1}{\\sigma^{2}}\\sum_{i=1}^{n}(X_{i} - \\bar{X})^{2}$服从自由度为$n-1$的卡方分布。我们将其记为：\n$$ \\frac{\\sum_{i=1}^{n}(X_{i} - \\bar{X})^{2}}{\\sigma^{2}} \\sim \\chi^{2}_{n-1} $$\n一个服从自由度为$k$的卡方分布的随机变量$Y \\sim \\chi^{2}_{k}$，其期望值为$E[Y] = k$，方差为$\\text{Var}(Y) = 2k$。\n\n首先，我们推导$\\hat{\\sigma}^{2}_{\\mathrm{MLE}}$的精确有限样本偏误。为此，我们首先计算其期望值。\n$$ E[\\hat{\\sigma}^{2}_{\\mathrm{MLE}}] = E\\left[\\frac{1}{n}\\sum_{i=1}^{n}(X_{i} - \\bar{X})^{2}\\right] = \\frac{1}{n}E\\left[\\sum_{i=1}^{n}(X_{i} - \\bar{X})^{2}\\right] $$\n我们可以用服从$\\chi^{2}_{n-1}$分布的变量来重写平方和：\n$$ \\sum_{i=1}^{n}(X_{i} - \\bar{X})^{2} = \\sigma^{2} \\left( \\frac{\\sum_{i=1}^{n}(X_{i} - \\bar{X})^{2}}{\\sigma^{2}} \\right) $$\n这个和的期望值为：\n$$ E\\left[\\sum_{i=1}^{n}(X_{i} - \\bar{X})^{2}\\right] = \\sigma^{2} E\\left[ \\frac{\\sum_{i=1}^{n}(X_{i} - \\bar{X})^{2}}{\\sigma^{2}} \\right] = \\sigma^{2} (n-1) $$\n因为一个$\\chi^{2}_{n-1}$变量的期望值是其自由度$n-1$。\n将此结果代回$E[\\hat{\\sigma}^{2}_{\\mathrm{MLE}}]$的表达式中：\n$$ E[\\hat{\\sigma}^{2}_{\\mathrm{MLE}}] = \\frac{1}{n} (n-1)\\sigma^{2} = \\frac{n-1}{n}\\sigma^{2} $$\n因此，$\\hat{\\sigma}^{2}_{\\mathrm{MLE}}$的偏误为：\n$$ \\text{Bias}(\\hat{\\sigma}^{2}_{\\mathrm{MLE}}) = E[\\hat{\\sigma}^{2}_{\\mathrm{MLE}}] - \\sigma^{2} = \\frac{n-1}{n}\\sigma^{2} - \\sigma^{2} = \\left(\\frac{n-1}{n} - 1\\right)\\sigma^{2} = -\\frac{1}{n}\\sigma^{2} $$\n这就是所要求的MLE的有限样本偏误。它是一个有偏估计量，平均而言会低估真实方差。\n\n接下来，我们比较$\\hat{\\sigma}^{2}_{\\mathrm{MLE}}$和$\\hat{\\sigma}^{2}_{U}$的均方误差(MSE)。\n首先，我们验证$\\hat{\\sigma}^{2}_{U}$的无偏性：\n$$ E[\\hat{\\sigma}^{2}_{U}] = E\\left[\\frac{1}{n-1}\\sum_{i=1}^{n}(X_{i} - \\bar{X})^{2}\\right] = \\frac{1}{n-1}E\\left[\\sum_{i=1}^{n}(X_{i} - \\bar{X})^{2}\\right] = \\frac{1}{n-1}(n-1)\\sigma^{2} = \\sigma^{2} $$\n由于$E[\\hat{\\sigma}^{2}_{U}] = \\sigma^{2}$，其偏误为$\\text{Bias}(\\hat{\\sigma}^{2}_{U}) = 0$。\n\n为了计算MSE，我们需要估计量的方差。我们使用$\\text{Var}(\\chi^{2}_{k}) = 2k$这一事实。\n$\\hat{\\sigma}^{2}_{U}$的方差为：\n$$ \\text{Var}(\\hat{\\sigma}^{2}_{U}) = \\text{Var}\\left(\\frac{1}{n-1}\\sum_{i=1}^{n}(X_{i} - \\bar{X})^{2}\\right) = \\text{Var}\\left(\\frac{\\sigma^{2}}{n-1} \\cdot \\frac{\\sum_{i=1}^{n}(X_{i} - \\bar{X})^{2}}{\\sigma^{2}}\\right) $$\n$$ \\text{Var}(\\hat{\\sigma}^{2}_{U}) = \\left(\\frac{\\sigma^{2}}{n-1}\\right)^{2} \\text{Var}(\\chi^{2}_{n-1}) = \\frac{\\sigma^{4}}{(n-1)^{2}} \\cdot 2(n-1) = \\frac{2\\sigma^{4}}{n-1} $$\n由于$\\hat{\\sigma}^{2}_{U}$是无偏的，其MSE等于其方差：\n$$ \\text{MSE}(\\hat{\\sigma}^{2}_{U}) = \\text{Var}(\\hat{\\sigma}^{2}_{U}) + (\\text{Bias}(\\hat{\\sigma}^{2}_{U}))^{2} = \\frac{2\\sigma^{4}}{n-1} + 0^{2} = \\frac{2\\sigma^{4}}{n-1} $$\n\n现在来看$\\hat{\\sigma}^{2}_{\\mathrm{MLE}}$。注意$\\hat{\\sigma}^{2}_{\\mathrm{MLE}} = \\frac{n-1}{n}\\hat{\\sigma}^{2}_{U}$。\n$\\hat{\\sigma}^{2}_{\\mathrm{MLE}}$的方 variance为：\n$$ \\text{Var}(\\hat{\\sigma}^{2}_{\\mathrm{MLE}}) = \\text{Var}\\left(\\frac{n-1}{n}\\hat{\\sigma}^{2}_{U}\\right) = \\left(\\frac{n-1}{n}\\right)^{2} \\text{Var}(\\hat{\\sigma}^{2}_{U}) = \\frac{(n-1)^{2}}{n^{2}} \\cdot \\frac{2\\sigma^{4}}{n-1} = \\frac{2(n-1)\\sigma^{4}}{n^{2}} $$\n$\\hat{\\sigma}^{2}_{\\mathrm{MLE}}$的MSE是其方差与偏误平方的和：\n$$ \\text{MSE}(\\hat{\\sigma}^{2}_{\\mathrm{MLE}}) = \\text{Var}(\\hat{\\sigma}^{2}_{\\mathrm{MLE}}) + (\\text{Bias}(\\hat{\\sigma}^{2}_{\\mathrm{MLE}}))^{2} = \\frac{2(n-1)\\sigma^{4}}{n^{2}} + \\left(-\\frac{\\sigma^{2}}{n}\\right)^{2} $$\n$$ \\text{MSE}(\\hat{\\sigma}^{2}_{\\mathrm{MLE}}) = \\frac{2(n-1)\\sigma^{4}}{n^{2}} + \\frac{\\sigma^{4}}{n^{2}} = \\frac{(2n - 2 + 1)\\sigma^{4}}{n^{2}} = \\frac{(2n-1)\\sigma^{4}}{n^{2}} $$\n为了比较MSE，我们考察当$n \\ge 2$时两者的差$\\text{MSE}(\\hat{\\sigma}^{2}_{U}) - \\text{MSE}(\\hat{\\sigma}^{2}_{\\mathrm{MLE}})$：\n$$ \\frac{2\\sigma^{4}}{n-1} - \\frac{(2n-1)\\sigma^{4}}{n^{2}} = \\sigma^{4}\\left(\\frac{2}{n-1} - \\frac{2n-1}{n^{2}}\\right) = \\sigma^{4}\\left(\\frac{2n^{2} - (2n-1)(n-1)}{n^{2}(n-1)}\\right) $$\n$$ = \\sigma^{4}\\left(\\frac{2n^{2} - (2n^{2} - 3n + 1)}{n^{2}(n-1)}\\right) = \\sigma^{4}\\left(\\frac{3n - 1}{n^{2}(n-1)}\\right) $$\n对于任何样本量$n \\ge 2$，项$\\frac{3n-1}{n^{2}(n-1)}$都严格为正。因此，$\\text{MSE}(\\hat{\\sigma}^{2}_{U}) > \\text{MSE}(\\hat{\\sigma}^{2}_{\\mathrm{MLE}})$。这表明对于任何有限样本量，$\\hat{\\sigma}^{2}_{\\mathrm{MLE}}$的均方误差小于$\\hat{\\sigma}^{2}_{U}$。在MSE意义上，$\\hat{\\sigma}^{2}_{\\mathrm{MLE}}$是更有效的估计量。这说明了经典的偏误-方差权衡：通过接受一个小的偏误，MLE实现了更低的方差，从而导致整体上更小的MSE。\n\n最后，我们讨论一致性。如果估计量$\\hat{\\theta}_{n}$在$n \\to \\infty$时依概率收敛于$\\theta$，则称其对$\\theta$是一致的。一致性的一个充分条件是，当$n \\to \\infty$时，偏误和方差都趋于零。\n对于$\\hat{\\sigma}^{2}_{\\mathrm{MLE}}$：\n$$ \\lim_{n\\to\\infty} \\text{Bias}(\\hat{\\sigma}^{2}_{\\mathrm{MLE}}) = \\lim_{n\\to\\infty} \\left(-\\frac{\\sigma^{2}}{n}\\right) = 0 $$\n$$ \\lim_{n\\to\\infty} \\text{Var}(\\hat{\\sigma}^{2}_{\\mathrm{MLE}}) = \\lim_{n\\to\\infty} \\frac{2(n-1)\\sigma^{4}}{n^{2}} = \\lim_{n\\to\\infty} \\left(\\frac{2\\sigma^{4}}{n} - \\frac{2\\sigma^{4}}{n^{2}}\\right) = 0 $$\n由于其偏误和方差都趋于零，所以$\\hat{\\sigma}^{2}_{\\mathrm{MLE}}$是$\\sigma^{2}$的一个一致估计量。\n\n对于$\\hat{\\sigma}^{2}_{U}$：\n$$ \\lim_{n\\to\\infty} \\text{Bias}(\\hat{\\sigma}^{2}_{U}) = \\lim_{n\\to\\infty} 0 = 0 $$\n$$ \\lim_{n\\to\\infty} \\text{Var}(\\hat{\\sigma}^{2}_{U}) = \\lim_{n\\to\\infty} \\frac{2\\sigma^{4}}{n-1} = 0 $$\n由于其偏误恒为零且方差趋于零，所以$\\hat{\\sigma}^{2}_{U}$也是$\\sigma^{2}$的一个一致估计量。\n\n因此，两个估计量都是一致的。渐近地，当$n \\to \\infty$时，联系这两个估计量的因子$\\frac{n-1}{n}$趋近于$1$，所以它们变得等价。", "answer": "$$\\boxed{-\\frac{\\sigma^{2}}{n}}$$", "id": "4831014"}, {"introduction": "在偏误概念的基础上，这个练习展示了一个关键原则：无偏性在非线性变换下不一定保持。我们将从一个概率 $p$ 的无偏估计量 $\\hat{p}$ 开始，然后检验在医学统计学中常见的对数优势比（log-odds）变换后估计量 $\\hat{\\theta}$ 的偏误 [@problem_id:4981389]。本练习将引入泰勒级数展开作为一种强大的工具，用以近似变换后估计量的偏误，这在统计学中通常被称为 Delta 方法。", "problem": "一项医学安全性监测研究追踪 $n$ 名独立患者在固定随访期内是否经历了二元不良事件。令 $X_1,\\dots,X_n$ 为独立同分布随机变量，服从 $X_i \\sim \\text{Bernoulli}(p)$，其中 $p \\in (0,1)$ 是不良事件的真实概率。用于下游风险沟通的关注参数是对数优势比 $\\theta = \\ln\\!\\big(p/(1-p)\\big)$。最大似然估计量 (MLE) 为 $\\hat{p} = \\bar{X} = n^{-1} \\sum_{i=1}^{n} X_i$，对数优势比的插入式估计量为 $\\hat{\\theta} = \\ln\\!\\big(\\hat{p}/(1-\\hat{p})\\big)$。\n\n任务：\n1. 从期望和独立性的定义出发，证明 $\\hat{p}$ 是 $p$ 的无偏估计量。\n2. 假设 $p \\in (0,1)$ 并且只考虑事件 $0  \\hat{p}  1$，这样 $\\hat{\\theta}$ 才有良好定义；注意对于固定的 $p \\in (0,1)$，当 $n \\to \\infty$ 时，$\\mathbb{P}(0  \\hat{p}  1) \\to 1$。通过将变换 $g(x) = \\ln\\!\\big(x/(1-x)\\big)$ 在 $x=p$ 附近展开至二阶，并使用期望中的主导非零项，推导前导阶渐近偏误 $\\mathbb{E}[\\hat{\\theta}] - \\theta$ 至 $1/n$ 阶，并将其明确表示为 $p$ 和 $n$ 的符号函数。\n\n请提供前导阶渐近偏误的单一闭式解析表达式，以 $p$ 和 $n$ 表示。无需进行数值取整，也不涉及任何单位。", "solution": "该问题陈述已经过验证，被认为是统计理论中一个有效的、适定的问题。它具有科学依据、内容自洽且客观。因此，我们可以着手提供完整解答。\n\n该问题分为两个任务。我们将依次解决它们。\n\n**任务1：证明 $\\hat{p}$ 是 $p$ 的无偏估计量。**\n\n如果一个估计量的期望值等于真实参数值，则该估计量是无偏的。这里，我们必须证明 $\\mathbb{E}[\\hat{p}] = p$。\n\n$p$ 的估计量为样本均值，即 $\\hat{p} = \\bar{X} = n^{-1} \\sum_{i=1}^{n} X_i$。\n$\\hat{p}$ 的期望为：\n$$\n\\mathbb{E}[\\hat{p}] = \\mathbb{E}\\left[\\frac{1}{n} \\sum_{i=1}^{n} X_i\\right]\n$$\n根据期望算子的线性性质，我们可以将常数因子 $1/n$ 和求和符号移到期望之外：\n$$\n\\mathbb{E}[\\hat{p}] = \\frac{1}{n} \\sum_{i=1}^{n} \\mathbb{E}[X_i]\n$$\n问题陈述指出 $X_1, \\dots, X_n$ 是来自参数为 $p$ 的伯努利分布的独立同分布（i.i.d.）随机变量，即 $X_i \\sim \\text{Bernoulli}(p)$。对于一个伯努利随机变量，其概率质量函数为 $\\mathbb{P}(X_i = 1) = p$ 和 $\\mathbb{P}(X_i = 0) = 1-p$。根据定义，每个 $X_i$ 的期望值为：\n$$\n\\mathbb{E}[X_i] = 1 \\cdot \\mathbb{P}(X_i = 1) + 0 \\cdot \\mathbb{P}(X_i = 0) = 1 \\cdot p + 0 \\cdot (1-p) = p\n$$\n由于所有 $X_i$ 都是同分布的，所以对于所有 $i \\in \\{1, \\dots, n\\}$ 都有 $\\mathbb{E}[X_i] = p$。将此结果代回 $\\mathbb{E}[\\hat{p}]$ 的表达式中：\n$$\n\\mathbb{E}[\\hat{p}] = \\frac{1}{n} \\sum_{i=1}^{n} p\n$$\n该和包含 $n$ 个相同的项 $p$，所以 $\\sum_{i=1}^{n} p = n p$。\n$$\n\\mathbb{E}[\\hat{p}] = \\frac{1}{n} (n p) = p\n$$\n由于 $\\mathbb{E}[\\hat{p}] = p$，根据定义，估计量 $\\hat{p}$ 是参数 $p$ 的无偏估计量。这完成了第一个任务。\n\n**任务2：推导 $\\hat{\\theta}$ 的前导阶渐近偏误。**\n\n关注的参数是对数优势比 $\\theta = \\ln(p/(1-p))$，其估计量是 $\\hat{\\theta} = \\ln(\\hat{p}/(1-\\hat{p}))$。这可以写成 $\\hat{\\theta} = g(\\hat{p})$，其中变换函数是 $g(x) = \\ln(x/(1-x))$。\n\n$\\hat{\\theta}$ 的偏误定义为 $\\text{Bias}(\\hat{\\theta}) = \\mathbb{E}[\\hat{\\theta}] - \\theta$。为了找到该偏误的渐近表达式，我们使用函数 $g(\\hat{p})$ 在点 $\\hat{p} = p$ 附近的泰勒级数展开。问题指定展开到二阶。\n$$\ng(\\hat{p}) \\approx g(p) + g'(p)(\\hat{p}-p) + \\frac{1}{2}g''(p)(\\hat{p}-p)^2\n$$\n首先，我们必须求出 $g(x) = \\ln(x) - \\ln(1-x)$ 的一阶和二阶导数。\n一阶导数为：\n$$\ng'(x) = \\frac{d}{dx} [\\ln(x) - \\ln(1-x)] = \\frac{1}{x} - \\frac{1}{1-x}(-1) = \\frac{1}{x} + \\frac{1}{1-x} = \\frac{(1-x)+x}{x(1-x)} = \\frac{1}{x(1-x)}\n$$\n二阶导数为：\n$$\ng''(x) = \\frac{d}{dx} [x^{-1} + (1-x)^{-1}] = -x^{-2} + (-1)(1-x)^{-2}(-1) = -x^{-2} + (1-x)^{-2} = \\frac{1}{(1-x)^2} - \\frac{1}{x^2}\n$$\n合并 $g''(x)$ 的各项：\n$$\ng''(x) = \\frac{x^2 - (1-x)^2}{x^2(1-x)^2} = \\frac{x^2 - (1 - 2x + x^2)}{x^2(1-x)^2} = \\frac{2x-1}{x^2(1-x)^2}\n$$\n现在，我们在 $x=p$ 处计算这些导数的值：\n- $g(p) = \\ln(p/(1-p)) = \\theta$\n- $g'(p) = \\frac{1}{p(1-p)}$\n- $g''(p) = \\frac{2p-1}{p^2(1-p)^2}$\n\n将这些代入泰勒展开式中得到：\n$$\n\\hat{\\theta} = g(\\hat{p}) \\approx \\theta + \\left(\\frac{1}{p(1-p)}\\right)(\\hat{p}-p) + \\frac{1}{2}\\left(\\frac{2p-1}{p^2(1-p)^2}\\right)(\\hat{p}-p)^2\n$$\n为了求 $\\hat{\\theta}$ 的近似期望值，我们对此表达式求期望。问题假设我们处于事件 $0  \\hat{p}  1$ 上，在该事件中 $\\hat{\\theta}$ 有良好定义。\n$$\n\\mathbb{E}[\\hat{\\theta}] \\approx \\mathbb{E}\\left[\\theta + \\frac{1}{p(1-p)}(\\hat{p}-p) + \\frac{2p-1}{2p^2(1-p)^2}(\\hat{p}-p)^2\\right]\n$$\n利用期望的线性性质：\n$$\n\\mathbb{E}[\\hat{\\theta}] \\approx \\theta + \\frac{1}{p(1-p)}\\mathbb{E}[\\hat{p}-p] + \\frac{2p-1}{2p^2(1-p)^2}\\mathbb{E}[(\\hat{p}-p)^2]\n$$\n我们需要计算这两个期望项：\n- $\\mathbb{E}[\\hat{p}-p]$ 是 $\\hat{p}$ 的偏误。如任务1所示，$\\hat{p}$ 是无偏的，所以 $\\mathbb{E}[\\hat{p}] = p$。因此，$\\mathbb{E}[\\hat{p}-p] = \\mathbb{E}[\\hat{p}] - p = p - p = 0$。\n- $\\mathbb{E}[(\\hat{p}-p)^2]$ 根据定义是 $\\hat{p}$ 的方差，记作 $\\text{Var}(\\hat{p})$，因为其均值为 $p$。\n\n我们现在计算 $\\text{Var}(\\hat{p})$：\n$$\n\\text{Var}(\\hat{p}) = \\text{Var}\\left(\\frac{1}{n} \\sum_{i=1}^{n} X_i\\right) = \\frac{1}{n^2} \\text{Var}\\left(\\sum_{i=1}^{n} X_i\\right)\n$$\n由于 $X_i$ 是独立的，和的方差等于方差的和：\n$$\n\\text{Var}(\\hat{p}) = \\frac{1}{n^2} \\sum_{i=1}^{n} \\text{Var}(X_i)\n$$\n对于一个伯努利($p$)变量，其方差为 $\\text{Var}(X_i) = p(1-p)$。由于这些变量是同分布的：\n$$\n\\text{Var}(\\hat{p}) = \\frac{1}{n^2} \\sum_{i=1}^{n} p(1-p) = \\frac{1}{n^2} [n p(1-p)] = \\frac{p(1-p)}{n}\n$$\n将这些结果代回 $\\mathbb{E}[\\hat{\\theta}]$ 的近似表达式中：\n$$\n\\mathbb{E}[\\hat{\\theta}] \\approx \\theta + \\frac{1}{p(1-p)}(0) + \\frac{2p-1}{2p^2(1-p)^2}\\left(\\frac{p(1-p)}{n}\\right)\n$$\n化简第二项：\n$$\n\\mathbb{E}[\\hat{\\theta}] \\approx \\theta + \\frac{(2p-1)p(1-p)}{2n p^2(1-p)^2} = \\theta + \\frac{2p-1}{2n p(1-p)}\n$$\n渐近偏误为 $\\mathbb{E}[\\hat{\\theta}] - \\theta$。从上面的表达式中，我们得到偏误的前导阶项：\n$$\n\\text{Bias}(\\hat{\\theta}) = \\mathbb{E}[\\hat{\\theta}] - \\theta \\approx \\frac{2p-1}{2np(1-p)}\n$$\n这个表达式是 $1/n$ 阶的。泰勒展开中的更高阶项，例如涉及 $\\mathbb{E}[(\\hat{p}-p)^3]$ 的项，将贡献 $1/n^2$ 阶或更小阶的项，这证实了我们得到的是前导阶渐近偏误。\n\n所要求的最终答案就是此前导阶渐近偏误的闭式解析表达式。", "answer": "$$\\boxed{\\frac{2p-1}{2np(1-p)}}$$", "id": "4981389"}, {"introduction": "在理解了偏误如何以 $\\mathcal{O}(n^{-1})$ 的阶次出现之后，我们自然会问如何校正它。这个练习介绍刀切法（jackknife），这是一种功能强大且广泛应用的重采样技术，用于估计和减小估计量的偏误 [@problem_id:4981405]。通过将此方法应用于健康经济学中常见的比率统计量，您将学习到一种实用的非参数方法，以提高估计的准确性。", "problem": "一个卫生经济学团队正在分析来自多中心观察性队列的患者层面数据，以估计一个新的慢性病管理项目的增量成本效果比 (ICER)。对于每位患者 $i \\in \\{1,\\dots,n\\}$，令 $C_{i} \\in (0,\\infty)$ 表示年度总医疗成本，令 $Q_{i} \\in (0,\\infty)$ 表示以质量调整生命年 (QALY) 衡量的相应年度效果。假设 $\\{(C_{i},Q_{i})\\}_{i=1}^{n}$ 是从一个具有有限二阶矩和严格为正的均值的联合分布中抽取的独立同分布样本。考虑平滑统计量\n$$\n\\hat{\\theta} \\;=\\; \\frac{\\bar{C}}{\\bar{Q}}, \\quad \\text{其中} \\quad \\bar{C} \\;=\\; \\frac{1}{n}\\sum_{i=1}^{n} C_{i}, \\quad \\bar{Q} \\;=\\; \\frac{1}{n}\\sum_{i=1}^{n} Q_{i}.\n$$\n科学目标是在上述假设下，减少 $\\hat{\\theta}$ 的主阶偏误，同时保持其相合性和一阶有效性。\n\n定义留一法均值\n$$\n\\bar{C}_{(i)} \\;=\\; \\frac{1}{n-1}\\sum_{\\substack{j=1 \\\\ j \\neq i}}^{n} C_{j}, \n\\qquad\n\\bar{Q}_{(i)} \\;=\\; \\frac{1}{n-1}\\sum_{\\substack{j=1 \\\\ j \\neq i}}^{n} Q_{j},\n$$\n及相关的留一法副本\n$$\n\\hat{\\theta}_{(i)} \\;=\\; \\frac{\\bar{C}_{(i)}}{\\bar{Q}_{(i)}}, \n\\qquad\n\\bar{\\hat{\\theta}}_{(\\cdot)} \\;=\\; \\frac{1}{n}\\sum_{i=1}^{n} \\hat{\\theta}_{(i)}.\n$$\n从偏误的定义以及统计量映射 $(\\bar{C},\\bar{Q}) \\mapsto \\bar{C}/\\bar{Q}$ 的平滑性出发，推导 $\\hat{\\theta}$ 的 $\\mathcal{O}(n^{-1})$ 阶偏误的刀切估计，并用 $n$、$\\hat{\\theta}$ 和 $\\hat{\\theta}_{(i)}$ 表示。然后，使用此偏误估计来构建刀切法偏误校正估计量 $\\hat{\\theta}_{JK}$。将你的最终估计量表示为一个包含 $n$、$\\hat{\\theta}$ 和 $\\{\\hat{\\theta}_{(i)}\\}_{i=1}^{n}$ 的单一闭式解析表达式。不需要数值近似；请在最终答案框中提供精确表达式，不含任何单位。", "solution": "用户希望推导一个比率统计量的刀切法偏误校正估计量。\n\n### 第一步：提取已知条件\n- 数据：$\\{(C_{i},Q_{i})\\}_{i=1}^{n}$ 是独立同分布 (i.i.d.) 的随机变量。\n- 定义域：$C_{i} \\in (0,\\infty)$， $Q_{i} \\in (0,\\infty)$。\n- 矩：联合分布具有有限二阶矩。均值 $\\mu_C = E[C_i]$ 和 $\\mu_Q = E[Q_i]$ 严格为正。\n- 目标估计量：$\\hat{\\theta} \\;=\\; \\frac{\\bar{C}}{\\bar{Q}}$，其中 $\\bar{C} \\;=\\; \\frac{1}{n}\\sum_{i=1}^{n} C_{i}$ 且 $\\bar{Q} \\;=\\; \\frac{1}{n}\\sum_{i=1}^{n} Q_{i}$。\n- 留一法均值：$\\bar{C}_{(i)} \\;=\\; \\frac{1}{n-1}\\sum_{j \\neq i} C_{j}$ 和 $\\bar{Q}_{(i)} \\;=\\; \\frac{1}{n-1}\\sum_{j \\neq i} Q_{j}$。\n- 留一法副本：$\\hat{\\theta}_{(i)} \\;=\\; \\frac{\\bar{C}_{(i)}}{\\bar{Q}_{(i)}}$。\n- 副本均值：$\\bar{\\hat{\\theta}}_{(\\cdot)} \\;=\\; \\frac{1}{n}\\sum_{i=1}^{n} \\hat{\\theta}_{(i)}$。\n- 任务：推导 $\\hat{\\theta}$ 的 $\\mathcal{O}(n^{-1})$ 阶偏误的刀切估计，并用它来构建刀切法偏误校正估计量 $\\hat{\\theta}_{JK}$。\n\n### 第二步：使用提取的已知条件进行验证\n- **科学依据**：该问题在统计理论中有坚实的基础，特别是在用于估计量偏误-方差分析的重抽样方法领域。刀切法是一种标准的、严格定义的技术。其应用背景，即在卫生经济学中估计增量成本效果比 (ICER)，是比率估计量及其偏误校正的一个常见且恰当的用例。\n- **适定性**：该问题是适定的。所有术语都有数学定义。这些假设（独立同分布抽样、有限二阶矩、正均值）是标准的，并且足以进行所需的理论推导（例如，确保泰勒级数展开和大数定律的有效性）。目标是推导一个具有唯一解的特定公式。\n- **客观性**：该问题以精确、客观的数学语言陈述，没有任何主观或模糊不清的声明。\n\n该问题没有违反任何无效性标准。它是数理统计学中一个标准的、形式化的问题。\n\n### 第三步：结论与行动\n问题是 **有效的**。现在开始求解过程。\n\n### 刀切估计量的推导\n\n我们感兴趣的参数是真实均值的比率，$\\theta = \\frac{\\mu_C}{\\mu_Q} = \\frac{E[C_i]}{E[Q_i]}$。估计量 $\\hat{\\theta} = \\bar{C}/\\bar{Q}$ 是样本均值的函数。由于比率函数 $f(x,y)=x/y$ 的非线性，估计量的期望不等于期望的函数，即 $E[\\hat{\\theta}] \\neq E[\\bar{C}]/E[\\bar{Q}] = \\mu_C/\\mu_Q$。这种差异导致了偏误。\n\n对于像 $\\hat{\\theta}$ 这样基于样本量为 $n$ 的平滑统计量，其偏误可以通过 $n^{-1}$ 的幂的渐近展开来表示：\n$$\n\\text{Bias}(\\hat{\\theta}) = E[\\hat{\\theta}] - \\theta = \\frac{b_1}{n} + \\frac{b_2}{n^2} + \\mathcal{O}(n^{-3})\n$$\n其中 $b_1, b_2, \\dots$ 是依赖于 $(C_i, Q_i)$ 的基础分布的矩但不依赖于 $n$ 的常数。目标是估计并移除主阶偏误项 $\\frac{b_1}{n}$。\n\n刀切法通过每次系统地剔除一个观测值来生成估计量 $\\hat{\\theta}_{(i)}$ 的副本。每个 $\\hat{\\theta}_{(i)}$ 都是基于样本量为 $n-1$ 的 $\\theta$ 的估计量。因此，其偏误具有相同的函数形式，但 $n$ 被替换为 $n-1$：\n$$\n\\text{Bias}(\\hat{\\theta}_{(i)}) = E[\\hat{\\theta}_{(i)}] - \\theta = \\frac{b_1}{n-1} + \\frac{b_2}{(n-1)^2} + \\mathcal{O}((n-1)^{-3})\n$$\n由于原始数据 $\\{ (C_i, Q_i) \\}_{i=1}^n$ 是独立同分布的，所有留一法统计量 $\\hat{\\theta}_{(i)}$ 都是同分布的。因此，它们的期望值都相等。\n\n我们来考虑这些副本的均值 $\\bar{\\hat{\\theta}}_{(\\cdot)}$ 的期望：\n$$\nE[\\bar{\\hat{\\theta}}_{(\\cdot)}] = E\\left[\\frac{1}{n}\\sum_{i=1}^{n} \\hat{\\theta}_{(i)}\\right] = \\frac{1}{n}\\sum_{i=1}^{n} E[\\hat{\\theta}_{(i)}] = E[\\hat{\\theta}_{(1)}]\n$$\n代入偏误展开式，我们得到：\n$$\nE[\\bar{\\hat{\\theta}}_{(\\cdot)}] = \\theta + \\frac{b_1}{n-1} + \\mathcal{O}(n^{-2})\n$$\n\n刀切法通过考虑留一法估计量的平均值与全样本估计量之间的差异来估计 $\\hat{\\theta}$ 的偏误。偏误的刀切估计量定义为：\n$$\n\\widehat{\\text{Bias}}_{JK}(\\hat{\\theta}) = (n-1) \\left( \\bar{\\hat{\\theta}}_{(\\cdot)} - \\hat{\\theta} \\right)\n$$\n为了验证这是一个合理的偏误估计量，我们可以考察它的期望：\n$$\nE[\\widehat{\\text{Bias}}_{JK}(\\hat{\\theta})] = (n-1) \\left( E[\\bar{\\hat{\\theta}}_{(\\cdot)}] - E[\\hat{\\theta}] \\right)\n$$\n代入期望的展开式：\n$$\nE[\\widehat{\\text{Bias}}_{JK}(\\hat{\\theta})] = (n-1) \\left( \\left(\\theta + \\frac{b_1}{n-1} + \\mathcal{O}(n^{-2})\\right) - \\left(\\theta + \\frac{b_1}{n} + \\mathcal{O}(n^{-2})\\right) \\right)\n$$\n$$\nE[\\widehat{\\text{Bias}}_{JK}(\\hat{\\theta})] = (n-1) \\left( \\frac{b_1}{n-1} - \\frac{b_1}{n} \\right) + \\mathcal{O}(n^{-1})\n$$\n$$\nE[\\widehat{\\text{Bias}}_{JK}(\\hat{\\theta})] = (n-1) \\left( \\frac{b_1 n - b_1 (n-1)}{n(n-1)} \\right) + \\mathcal{O}(n^{-1})\n$$\n$$\nE[\\widehat{\\text{Bias}}_{JK}(\\hat{\\theta})] = (n-1) \\left( \\frac{b_1}{n(n-1)} \\right) + \\mathcal{O}(n^{-1}) = \\frac{b_1}{n} + \\mathcal{O}(n^{-1})\n$$\n由于 $E[\\widehat{\\text{Bias}}_{JK}(\\hat{\\theta})] = \\text{Bias}(\\hat{\\theta}) + \\mathcal{O}(n^{-2})$，这证实了 $\\widehat{\\text{Bias}}_{JK}(\\hat{\\theta})$ 是主阶偏误项的估计量，其自身的偏误为 $\\mathcal{O}(n^{-2})$ 阶。\n\n刀切法偏误校正估计量 $\\hat{\\theta}_{JK}$ 是通过从原始估计量中减去估计的偏误来构建的：\n$$\n\\hat{\\theta}_{JK} = \\hat{\\theta} - \\widehat{\\text{Bias}}_{JK}(\\hat{\\theta})\n$$\n$$\n\\hat{\\theta}_{JK} = \\hat{\\theta} - (n-1) \\left( \\bar{\\hat{\\theta}}_{(\\cdot)} - \\hat{\\theta} \\right)\n$$\n我们现在简化此表达式以获得最终的闭式形式。\n$$\n\\hat{\\theta}_{JK} = \\hat{\\theta} - (n-1)\\bar{\\hat{\\theta}}_{(\\cdot)} + (n-1)\\hat{\\theta}\n$$\n$$\n\\hat{\\theta}_{JK} = (1 + n - 1)\\hat{\\theta} - (n-1)\\bar{\\hat{\\theta}}_{(\\cdot)}\n$$\n$$\n\\hat{\\theta}_{JK} = n\\hat{\\theta} - (n-1)\\bar{\\hat{\\theta}}_{(\\cdot)}\n$$\n问题要求用 $n$、$\\hat{\\theta}$ 和副本集合 $\\{\\hat{\\theta}_{(i)}\\}_{i=1}^{n}$ 来表示最终答案。我们代入 $\\bar{\\hat{\\theta}}_{(\\cdot)}$ 的定义：\n$$\n\\bar{\\hat{\\theta}}_{(\\cdot)} = \\frac{1}{n}\\sum_{i=1}^{n} \\hat{\\theta}_{(i)}\n$$\n这就得到了刀切法偏误校正估计量的最终表达式：\n$$\n\\hat{\\theta}_{JK} = n\\hat{\\theta} - (n-1) \\left( \\frac{1}{n} \\sum_{i=1}^{n} \\hat{\\theta}_{(i)} \\right)\n$$\n$$\n\\hat{\\theta}_{JK} = n\\hat{\\theta} - \\frac{n-1}{n} \\sum_{i=1}^{n} \\hat{\\theta}_{(i)}\n$$\n这个估计量也可以解释为“伪值” $\\tilde{\\theta}_i = n\\hat{\\theta} - (n-1)\\hat{\\theta}_{(i)}$ 的平均值。根据其设计，$\\hat{\\theta}_{JK}$ 的偏误为 $\\mathcal{O}(n^{-2})$ 阶，这比原始估计量的 $\\mathcal{O}(n^{-1})$ 阶偏误有所改进。", "answer": "$$\\boxed{n\\hat{\\theta} - \\frac{n-1}{n}\\sum_{i=1}^{n} \\hat{\\theta}_{(i)}}$$", "id": "4981405"}]}