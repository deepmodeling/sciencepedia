## 引言
在医学研究的殿堂中，随机对照试验（RCT）被誉为评估干预措施有效性的“金标准”。然而，这一崇高地位并非凭空而来，而是建立在一套严谨的方法学基石之上，其中，随机化、分配隐藏与盲法构成了其核心铁三角。表面上，这些术语广为人知，但真正理解其背后的统计学原理、它们如何共同抵御各类偏倚的侵蚀，以及在复杂现实世界中如何巧妙应用，是区分普通研究者与卓越科学家的关键。许多研究因未能严格执行这些原则而得出错误结论，造成资源浪费甚至误导临床实践，这正是本文旨在弥补的知识鸿沟。

本文将带领读者进行一次系统性的深度探索。在第一章**“原则与机制”**中，我们将从因果推断的潜结果框架出发，揭示随机化为何是无偏估计的基石，并详细剖析各类随机化方案、分配隐藏与盲法的具体机制及其旨在防止的偏倚类型。随后的第二章**“应用与跨学科联系”**将视野从理论转向实践，通过药物研发、外科手术、高级试验设计（如整群随机试验）等真实案例，展示这些原则在不同学科和复杂情境下的灵活应用与扩展。最后，在第三章**“动手实践”**中，您将通过解决具体问题，将理论知识转化为可量化、可操作的分析技能。通过这一旅程，您将不仅掌握“做什么”，更将深刻理解“为什么这么做”，从而具备设计严谨研究和批判性评估科学证据的核心能力。

## 原则与机制

### 随机化：因果推断的基石

在临床研究中，我们的核心目标往往是进行因果推断——即确定某项干预措施（如一种新药或疗法）是否导致了观察到的结局变化。为严谨地实现这一目标，我们需要一个能够将相关性与因果性区分开来的框架。**潜结果框架 (Potential Outcomes Framework)** 为此提供了理论基础。

对于总体中的每个个体 $i$，我们设想存在两个潜在的结局：$Y_i(1)$，表示个体 $i$ 接受干预（治疗）时的结局；以及 $Y_i(0)$，表示该个体接受对照时的结局。对于任何一个个体，我们只能在某一时刻观察到这两个潜结果中的一个。个体层面的因果效应被定义为这两个潜结果的差值，即 $\tau_i = Y_i(1) - Y_i(0)$。在群体层面，我们通常关心**平均治疗效应 (Average Treatment Effect, ATE)**，即 $\mathrm{ATE} = \mathbb{E}[Y_i(1) - Y_i(0)]$。

根本性的挑战在于，我们永远无法同时观察到同一个体的 $Y_i(1)$ 和 $Y_i(0)$。那么，我们如何才能估计 ATE 呢？如果我们简单地比较接受治疗的患者群体和未接受治疗的患者群体的平均结局，即 $\mathbb{E}[Y | Z=1] - \mathbb{E}[Y | Z=0]$（其中 $Z$ 是实际接受的治疗），这个差值可能不仅包含治疗本身的效应，还包含了两个群体在接受治疗前就已存在的系统性差异（即选择偏倚）。

**随机化 (Randomization)** 是解决这一难题的强大工具。其核心思想是，通过一个概率机制（而非患者或医生的选择）来分配治疗方案。一个成功的随机化过程能够确保治疗分配 $Z_i$ 与患者的所有基线特征（无论是可测量的还是未测量的）在统计上是独立的。这意味着治疗分配与潜结果 $\{Y_i(1), Y_i(0)\}$ 也是独立的。这种独立性被称为**[可交换性](@entry_id:263314) (exchangeability)**，它保证了在治疗开始之前，治疗组和[对照组](@entry_id:188599)在所有预后特征上具有可比性。在这种情况下，观察到的结局差异可以归因于治疗本身：
$$
\mathbb{E}[Y | Z=1] - \mathbb{E}[Y | Z=0] = \mathbb{E}[Y(1) | Z=1] - \mathbb{E}[Y(0) | Z=0]
$$
由于随机化保证了 $Z$ 与 $Y(1)$ 和 $Y(0)$ 的独立性，我们有 $\mathbb{E}[Y(1) | Z=1] = \mathbb{E}[Y(1)]$ 和 $\mathbb{E}[Y(0) | Z=0] = \mathbb{E}[Y(0)]$。因此：
$$
\mathbb{E}[Y | Z=1] - \mathbb{E}[Y | Z=0] = \mathbb{E}[Y(1)] - \mathbb{E}[Y(0)] = \mathrm{ATE}
$$
随机化通过打破治疗选择与患者预后之间的潜在关联，为无偏的因果效应估计提供了理论保障。

### 随机化的机制

随机化并非单一概念，而是包括一系列具体的方法，每种方法都有其自身的概率结构和适用场景。将随机化机制形式化为一个关于分配序列 $\mathbf{Z} = (Z_1, \dots, Z_n)$ 的概率空间 $(\Omega, \mathcal{F}, \mathbb{P})$ 有助于我们精确理解它们的特性 [@problem_id:4982190]。

#### 简单随机化

**简单随机化 (Simple Randomization)** 是最基础的形式，相当于为每个入组的受试者抛掷一枚公平的硬币来决定其分组。对于一个双臂试验，每个受试者被分配到治疗组或[对照组](@entry_id:188599)的概率均为 $0.5$，且每次分配都独立于其他所有分配。

在这种机制下，包含 $n$ 名受试者的所有 $2^n$ 种可能的分配序列 $\mathbf{z} \in \{A, B\}^n$ 构成了[样本空间](@entry_id:275301) $\Omega$。由于每次分配是独立的，任何一个特定序列的概率都是 $(1/2)^n$。其优点是操作简单、完全不可预测。然而，缺点在于纯粹的几率可能导致两组样本量出现显著不平衡，尤其是在样本量较小的情况下。这种不平衡会降低统计功效。此外，试验过程中也可能出现长期的不平衡，例如连续多名患者被分入同一组。

#### 受限随机化

为了克服简单随机化的弊端，研究者开发了多种**受限随机化 (Restricted Randomization)** 方法，旨在保证或促进组间样本量的平衡。

**完全随机化 (Complete Randomization)**，也称为随机分配规则或瓮模型，是在试验开始前就固定两组的总样本量，分别为 $n_A$ 和 $n_B$ (其中 $n_A+n_B=n$)。这等同于从一个装有 $n_A$ 个 A 标签和 $n_B$ 个 B 标签的瓮中不放回地抽取。在这种机制下，[样本空间](@entry_id:275301) $\Omega$ 只包含那些恰好有 $n_A$ 个 A 和 $n_B$ 个 B 的分配序列。可能的序列总数为 $\binom{n}{n_A}$，每个序列的概率均等，为 $1/\binom{n}{n_A}$。这种方法确保了最终的样本量完全平衡，但分配之间不再是独立的。知道了一些受试者的分配情况，就可以推断其他受试者的分配概率 [@problem_id:4982190]。

**区组随机化 (Permuted Block Randomization)** 是一种应用更广泛的方法，它不仅能保证最终的平衡，还能确保在试验进行过程中的多个时间点上，组间样本量也保持接近。其操作方式是将受试者序列划分为若干个大小为 $b$ 的区组（或称“块”，block）。在每个区组内部，强制要求分配到 A 组和 B 组的受试者数量相等（例如，对于 1:1 分配，各占 $b/2$）。区组内部的分配顺序是随机排列的。例如，对于一个大小为 4 的区组（$b=4$），共有 $\binom{4}{2}=6$ 种可能的平衡分配方式（如 AABB, ABAB, ABBA, BBAA, BABA, BAAB），系统会随机选择其中一种用于该区组。不同区组之间的随机化是独立的。这种方法有效地防止了试验过程中的长期不平衡。为了增强分配的不可预测性，通常会使用变化的区组大小（例如，随机混合使用大小为 4 和 6 的区组）[@problem_id:4982190] [@problem_id:4982154]。

**[分层随机化](@entry_id:189937) (Stratified Randomization)** 用于处理已知的、可能强烈影响结局的重要基线预后因素（如疾病严重程度、研究中心）。其目的是确保这些关键因素在治疗组和[对照组](@entry_id:188599)之间实现平衡。具体操作是先根据这些因素将所有受试者分入不同的“层”（strata），然后在每个层内部独立进行受限随机化（通常是区组随机化）。例如，一个多中心试验可能会按研究中心和疾病严重度（轻度/重度）进行分层，为每个“中心-严重度”组合设立独立的随机化列表 [@problem_id:4982154]。

#### 协变量自适应随机化

当需要平衡的协变量数量较多时，[分层随机化](@entry_id:189937)会因分层数过多（即协变量所有水平组合的数量）而变得不切实际。**协变量自适应随机化 (Covariate-Adaptive Randomization)**，特别是 **Pocock-Simon 最小化算法 (Minimization)**，为此提供了解决方案。

最小化是一种动态分[配方法](@entry_id:265480)。每当有一名新患者入组时，该算法会评估将其分配到各个治疗组后可能产生的“不平衡”程度。具体步骤如下 [@problem_id:4982151]：
1.  **定义不平衡分数**: 对于每个治疗组 $g$，计算一个假设性的不平衡分数 $S_g$。该分数衡量的是如果将当前患者分配到 $g$ 组，各协变量在所有治疗组间的分布不平衡程度。标准的分数是基于各协变量各水平上治疗组间人数差异的绝对值之和，并可对不同协变量赋予不同权重 $w_k$。
    $$ S_g = \sum_{k=1}^K w_k \sum_{\ell=1}^{L_k} \left| \tilde N_{1,k,\ell}^{(g)} - \tilde N_{2,k,\ell}^{(g)} \right| $$
    其中 $\tilde N_{g',k,\ell}^{(g)}$ 是将当前患者分配到 $g$ 组后，$g'$ 组中协变量 $k$ 处于水平 $\ell$ 的假设人数。
2.  **确定最优分组**: 比较各组的不平衡分数 $S_g$，分数最低的组即为“最优”组，因为它能最大程度地减小边际不平衡。
3.  **概率性分配**: 为了避免分配完全确定（从而可被预测），算法采用“带偏硬币”的策略。以一定的高概率 $p$（如 $p=0.85$）将患者分配到最优组，以 $1-p$ 的概率分配到非最优组。如果各组分数相同，则以等概率（如 0.5）进行分配。

最小化算法在保证多个协变量边际平衡方面非常有效，但必须通过一个中心化的、自动化的系统来实施，以确保分配的[隐蔽](@entry_id:196364)性。

### 保护随机化：分配隐藏的关键作用

拥有一个出色的随机化方案本身并不足够；它的实施过程必须能抵抗有意识或无意识的人为干扰。**分配隐藏 (Allocation Concealment)** 是确保随机化方案完整性的关键程序性保障。

分配隐藏是指在受试者被最终确定纳入试验之前，阻止研究人员、临床医生及其他相关人员预知即将到来的治疗分配序列的过程。它与**设盲 (Blinding)** 是两个不同的概念：分配隐藏发生在随机化分配的**当时**，旨在防止**选择偏倚 (selection bias)**；而设盲发生在随机化分配**之后**，旨在防止**实施偏倚 (performance bias)** 和**观察偏倚 (detection bias)** [@problem_id:4982180]。

#### 分配隐藏失败的机制：选择偏倚

为何分配隐藏至关重要？其深层机制可以通过因果图和“碰撞体偏倚” (collider bias) 的概念来阐明 [@problem_id:4982163]。

假设在一个试验中，研究者可以预知下一个分配是治疗（$Z=1$）还是对照（$Z=0$）。当一个预后较差（由一系列因素 $U$ 决定）的患者前来入组时，研究者可能会倾向于将他/她纳入试验，如果他/她知道下一个分配是更“有希望”的干预组。反之，对于一个预后良好的患者，研究者可能更倾向于在他/她将被分配到[对照组](@entry_id:188599)时才将其纳入。

在这种情况下，患者的入组决策 $S$（$S=1$ 表示入组）同时受到了预后因素 $U$ 和预知的治疗分配 $Z$ 的影响。在因果[有向无环图 (DAG)](@entry_id:748452) 中，这表现为 $Z \to S \leftarrow U$。在这里，$S$ 成为了连接 $Z$ 和 $U$ 的路径上的一个**碰撞体 (collider)**。随机化设计的初衷是保证 $Z$ 和 $U$ 在整体人群中是独立的。然而，我们的分析对象是最终入组的受试者，这相当于对 $S=1$ 进行了“条件化”。在 DAG 中，对碰撞体进行条件化会打开原本被阻断的路径，从而在 $Z$ 和 $U$ 之间引入虚假的[统计关联](@entry_id:172897)。其结果是，在入组的样本中，治疗分配 $Z$（即 $A$）不再独立于预后因素 $U$。随机化所创造的基线可比性被彻底破坏，由此产生的偏倚即为选择偏倚。

#### 量化选择偏倚的后果

这种偏倚的实际影响可以是巨大的。设想一个场景，患者的基线风险由协变量 $X$ 表示（值越高风险越大），而由于分配方案可预测，招募者倾向于将低风险患者纳入治疗组。我们可以将这种选择性行为建模为治疗分配的概率依赖于 $X$，例如 $\mathbb{P}(T=1 | X=x) = \rho - \eta x$。在这种情况下，即使治疗本身是有效的，简单的组间均值比较 $\hat{\tau} = \bar{Y}_{T=1} - \bar{Y}_{T=0}$ 也会产生偏倚。可以推导出，这种偏倚的大小为 $\mathbb{E}[\hat{\tau}] - \mathrm{ATE} = \gamma (\mathbb{E}[X | T=1] - \mathbb{E}[X | T=0])$，其中 $\gamma$ 反映了基线风险与结局的关联强度。由于低风险患者被更多地分入治疗组（即 $\mathbb{E}[X|T=1]  \mathbb{E}[X|T=0]$），如果高风险意味着更差的结局（$\gamma > 0$），那么这将导致对治疗效果的乐观偏倚 [@problem_id:4982188]。这个例子清晰地展示了分配隐藏的失败如何直接转化为错误的试验结论。

#### 分配隐藏的实践

实现有效的分配隐藏需要严格的程序。最佳实践是使用一个中心化的、独立于研究现场的随机化系统，例如交互式语音应答系统 (IVRS) 或网络应答系统 (IWRS)。一个设计良好的中心化系统应遵循以下原则 [@problem_id:4982154]：
1.  **不可逆的顺序**: 必须在确认患者完全符合所有纳入/排除标准，并已签署知情同意书之后，才能联系随机化系统。这个顺序绝对不能颠倒。
2.  **必要信息的输入**: 研究人员向系统提供患者的唯一标识符、分层信息（如中心、疾病严重程度）以及身份验证信息。
3.  **有限信息的输出**: 系统仅返回当前这位患者的治疗分配结果（如“药物包编号 XYZ”）。系统绝不能透露区组大小、当前组内人数、或未来的分配序列。
4.  **完整的审计追踪**: 系统应记录所有交互的时间戳和细节，以备核查。

通过这种方式，将分配的生成和揭晓过程与研究人员的招募决策过程完全隔离，从而有效地保护了随机化过程的完整性。

### 保护随机化后的完整性：设盲的作用

随机化和分配隐藏保证了试验在“第零天”的公平性。然而，从患者接受第一次治疗开始，新的偏倚风险便随之而来。**设盲 (Blinding)** 或**遮蔽 (Masking)** 是一系列旨在通过对试验相关方隐藏治疗分配信息来最小化这些偏倚的方法。

#### 设盲的对象及其针对的偏倚

设盲的对象不同，其旨在防止的偏倚类型也不同。我们可以通过因果路径来理解其机制 [@problem_id:4982180]。

**参与者和干预提供者 (Participants and Providers)**
对参与者和医生进行设盲，主要是为了防止**实施偏倚 (Performance Bias)**。如果患者知道自己服用的是新药还是安慰剂，他们的心理预期、行为模式（如生活方式的改变）以及对症状的主观感受都可能发生变化（即安慰剂或反安慰剂效应）。如果医生知道患者所属的分组，他们可能会在辅助治疗、复诊频率或对患者的鼓励程度上有所不同。这些行为和干预上的差异，我们用 $C$ 表示，构成了除研究药物本身之外的另一条因果路径：$A \to K_{\text{pt/prov}} \to C \to Y$。其中 $K$ 代表知识， $Y$ 代表真实结局。设盲通过阻断 $A \to K$ 这一环节，确保两组的可比性在治疗过程中得以维持。

**结局评估者 (Outcome Assessors)**
对结局评估者设盲是为了防止**观察偏倚 (Detection Bias)**，也称检测偏倚。如果评估者知道患者的治疗分组，他们可能会在测量或解读结局时产生系统性的差异。这种偏倚对于依赖主观判断的结局（如疼痛评分、影像学判读、精神状态评估）尤为致命。这种偏倚影响的是结局的**测量过程** $M$，而非真实结局 $Y$。其因果路径为 $A \to K_{\text{assess}} \to M \to Y^*$，其中 $Y^*$ 是记录的结局。设盲通过阻断 $A \to K_{\text{assess}}$，来确保结局测量过程的客观性和一致性。

**量化观察偏倚**: 我们可以通过一个例子来精确理解观察偏倚的影响 [@problem_id:4982135]。假设一个试验的真实事件率在治疗组为 $p_T = 0.30$，[对照组](@entry_id:188599)为 $p_C = 0.45$，真实风险差为 $-0.15$。但由于评估者未设盲，他们对两组的诊断标准不同，这可以用不同的敏感性（正确识别事件的能力）和特异性（正确识别非事件的能力）来描述。例如，[对照组](@entry_id:188599)的敏感性更高（$0.95$ vs $0.85$），而治疗组的特异性更高（$0.95$ vs $0.90$）。通过计算，我们会发现观察到的风险差变为 $-0.1925$，与真实值相差 $-0.0425$。这个差值就是由不一致的结局评估所直接导致的观察偏倚。

**数据分析师 (Analysts)**
对分析师设盲，例如在分析阶段用 A/B 组等代码代替“治疗/对照”标签，可以减少**分析偏倚 (Analysis Bias)**。这可以防止分析师基于对治疗效果的期望而做出有偏的数据驱动决策，例如选择性地调整协变量、改变结局定义或在看到“不理想”结果时进行额外的亚组分析。需要强调的是，分析师设盲不能纠正上游已经发生的实施偏倚或观察偏倚 [@problem_id:4982180]。

### 从设计到推断：两种哲学视角

一个临床试验的设计（特别是其随机化方案）深刻地影响着后续[统计推断](@entry_id:172747)的逻辑基础和有效性。在统计学中，存在两种主要的推断范式：基于设计的推断和基于模型的推断 [@problem_id:4982192]。

#### 基于设计的推断 (Design-Based Inference)

基于设计的推断，也称为随机化推断，其哲学核心是：试验中唯一的随机性来源是研究者实施的物理随机化过程。受试者的潜结果被视为固定的、内在的常数，而非来自某个超总体的随机变量。

**Fisher 随机化检验**: 这种思想最经典的体现是 [R.A. Fisher](@entry_id:173478) 提出的随机化检验，它用于检验**[尖锐零假设](@entry_id:177768) (sharp null hypothesis)**，即 $H_0^{\text{Fisher}}: Y_i(1) = Y_i(0)$ 对所有个体 $i$ 都成立。该假设意味着干预对任何个体都没有任何效果。

检验的逻辑如下：如果[尖锐零假设](@entry_id:177768)为真，那么每个受试者观察到的结局 $Y_i^{\text{obs}}$ 就是其固有的、不随治疗分配而改变的数值。因此，整个试验的结局向量 $\mathbf{Y}^{\text{obs}}$ 是一个固定的数据集。我们所观察到的治疗分配 $\mathbf{Z}^{\text{obs}}$ 只是所有可能符合随机化方案的分配中的一种。检验的参照分布，就是通过枚举所有可能的治疗分配，并对每一种分配计算[检验统计量](@entry_id:167372)（如组间均值差 $T$）的值而形成的。P 值被定义为在该参照分布中，[检验统计量](@entry_id:167372)的值等于或比观测值更极端的比例。

例如，在一个包含 6 对匹配受试者的试验中，每对内一人接受治疗、一人接受对照，总共有 $2^6=64$ 种可能的分配方式。在[尖锐零假设](@entry_id:177768)下，每对受试者的两个结局是固定的。我们可以计算出在 64 种分配下，检验统计量的完整分布。只有那些结局不同的“[不一致对](@entry_id:166371)”(discordant pairs) 才会对统计量的变异做出贡献。该检验的 P 值是精确的，且不依赖于任何关于结局分布（如正态性）的假设 [@problem_id:4982128]。

#### 基于模型的推断 (Model-Based Inference)

基于模型的推断则采取不同的视角。它假定受试者是从一个更大的“超总体”中随机抽取的样本。随机性不仅来源于治疗分配，更主要地来源于这个抽样过程。这种方法通常会建立一个关于结局的[统计模型](@entry_id:755400)，例如[线性模型](@entry_id:178302)：
$$
Y_i = \beta_0 + \beta_1 Z_i + \varepsilon_i
$$
在这个模型中，$\beta_1$ 通常被解释为治疗效应。为了使这种解释具有因果意义，一个关键的假设是，回归量 $Z_i$ 与误差项 $\varepsilon_i$ 不相关，即 $\mathrm{Cov}(Z_i, \varepsilon_i) = 0$。这正是成功的随机化（包括有效的分配隐藏）所要保证的。如果分配隐藏失败，导致选择偏倚，那么 $Z_i$ 将与那些影响结局的未观测因素（包含在 $\varepsilon_i$ 中）相关，导致 $\beta_1$ 的估计有偏且不一致 [@problem_id:4982192] [@problem_id:4982163]。

#### 综合与效应异质性

这两种方法并非完全对立。J. Neyman 的工作为连接两者提供了桥梁。Neyman 在基于设计的框架下，考虑了更宽松的**弱零假设 (weak null hypothesis)**，即 $H_0^{\text{Neyman}}: \mathbb{E}[Y(1)-Y(0)] = 0$。这个假设允许个体效应 $\tau_i$ 存在（即**效应异质性 (effect heterogeneity)**），只要它们的平均值为零。

在效应异质性的背景下，Neyman 推导了组间均值差估计量 $\hat{\tau}$ 在完全随机化设计下的精确方差 [@problem_id:4982148]：
$$
\mathrm{Var}(\hat{\tau}) = \frac{S_1^2}{n_1} + \frac{S_0^2}{n_0} - \frac{S_\tau^2}{N}
$$
其中 $S_1^2$ 和 $S_0^2$ 是潜结果 $Y(1)$ 和 $Y(0)$ 在整个有限总体中的方差，$S_\tau^2$ 则是**个体治疗效应的方差**，而 $N$ 是总体大小。

这个公式揭示了一个深刻的结论。在实践中，我们通常使用样本方差 $s_1^2$ 和 $s_0^2$ 来估计 $S_1^2$ 和 $S_0^2$，并使用 $\frac{s_1^2}{n_1} + \frac{s_0^2}{n_0}$ 作为 $\hat{\tau}$ 的[方差估计](@entry_id:268607)。然而，这个常用的方差估计量忽略了第三项 $-S_\tau^2/N$。由于 $S_\tau^2$ 必然非负，当存在治疗效应异质性时（$S_\tau^2 > 0$），这个常用估计量会**系统性地高估**真实方差。这种高估被称为**保守的 (conservative)**，它会导致[置信区间](@entry_id:138194)过宽，[检验功效](@entry_id:175836)降低。

在基于模型的框架下，效应异质性会导致[回归模型](@entry_id:163386)中的误差项出现[异方差性](@entry_id:136378)。在这种情况下，使用 **Huber-White 稳健方差估计 (sandwich estimator)** 可以在大样本下提供对 $\beta_1$ [估计量方差](@entry_id:263211)的一致估计，而无需假设误差项为同方差或正态分布 [@problem_id:4982192]。这两种不同范式下的工具，最终都指向了同一个挑战：如何正确处理治疗效应的异质性。

### 超越 SUTVA：干扰的复杂性

到目前为止，我们的讨论都隐含了一个基本假设，即**稳定单元治疗价值假设 (Stable Unit Treatment Value Assumption, SUTVA)**。SUTVA 包含两个部分：(1) 治疗的定义是一致的；(2) 不存在**干扰 (interference)**，即一个个体的潜结果仅依赖于其自身的治疗分配，而不受其他个体治疗分配的影响。

在许多现实世界的试验中，“无干扰”这一假设可能不成立。例如，在疫苗试验中，一个人的接种会影响其邻居的感染风险；在教育试验中，一个班级里部分学生接受了新的教学法，可能会影响同班其他学生的学习氛围和表现。

**部分干扰 (Partial Interference)** 是一个更现实的假设，它假定总体可以被划分为互不相交的簇（如教室、诊所、家庭），干扰仅在簇内发生，而不在簇间发生 [@problem_id:4982198]。

让我们考虑一个在学校中进行的个体随机化试验，学生被嵌套在教室中。一个学生的结局可能不仅受其自身干预状态 $D_{ic}$ 的影响，还受到其所在班级 $c$ 的整体干预比例 $\bar{D}_c$ 的影响（即“溢出效应”）。这可以用一个结构模型来描述：
$$
Y_{ic} = \alpha + \tau D_{ic} + \lambda \bar{D}_{c} + \varepsilon_{ic}
$$
其中 $\tau$ 是直接的个[体效应](@entry_id:261475)，$\lambda$ 是溢出效应的强度。

在这种情况下，如果我们忽略这种聚类和干扰结构，而使用一个简单的、汇总所有学生的组间均值差估计量 $\hat{\Delta} = \bar{Y}_{\text{treated}} - \bar{Y}_{\text{control}}$，那么这个估计量是有偏的。可以证明，在大样本下，该估计量收敛于：
$$
\mathbb{E}[\hat{\Delta}] = \tau + \lambda \frac{C}{N}
$$
其中 $C$ 是教室数量，$N$ 是总样本量 [@problem_id:4982198]。这个结果表明，幼稚的分析方法会将直接效应 $\tau$ 与一部分溢出效应 $\lambda$ 混淆在一起。这提醒我们，在进行试验设计和分析时，必须仔细审视 SUTVA 的合理性，并在必要时采用更高级的设计（如整群随机试验）或分析方法来处理干扰问题。

总之，随机临床试验的有效性依赖于从随机化方案的选择，到分配隐藏和设盲的严格执行，再到与设计原则相匹配的统计分析策略等一系列环环相扣的原则和机制。对这些环节中任何一个的忽视都可能损害试验的科学严谨性，并导致错误的结论。