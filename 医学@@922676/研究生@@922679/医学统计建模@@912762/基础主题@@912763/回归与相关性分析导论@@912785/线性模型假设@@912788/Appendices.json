{"hands_on_practices": [{"introduction": "在医学研究中，我们常常无法精确测量真正的暴露变量（如长期钠摄入量），而只能依赖有噪声的生物标志物。这个练习将从第一性原理出发，推导当我们将结果变量对这个含噪声的测量值进行回归时，为什么会导致系数估计值偏向零，即所谓的“衰减偏倚”（attenuation bias）。通过这个实践 [@problem_id:4952742]，你将深刻理解数据质量假设的重要性，以及它如何直接影响我们对效应大小的结论。", "problem": "一项临床队列研究旨在将一个连续性临床结局（如收缩压，记为 $Y$）与一个连续性真实暴露（如日均钠摄入量，记为 $X$）联系起来。科学模型假定存在一个线性关系 $Y = \\beta_{0} + \\beta_{1} X + \\varepsilon$，其中 $\\varepsilon$ 是一个均值为零的随机误差，满足 $\\operatorname{E}[\\varepsilon \\mid X] = 0$ 且具有有限方差。然而，暴露量 $X$ 无法直接观测；而是记录了一个带有噪声的生物标志物 $W$，该标志物遵循经典测量误差模型 $W = X + U$，其中 $U$ 是一个均值为零的测量误差，与 $X$ 和 $\\varepsilon$ 相互独立，且具有有限方差。假设使用一个独立同分布 (i.i.d.) 的样本 $\\{(Y_{i}, W_{i})\\}_{i=1}^{n}$，通过普通最小二乘法 (OLS) 来拟合 $Y$ 对 $W$ 的工作线性回归模型。\n\n从协方差和方差的核心定义，以及简单线性回归中 OLS 斜率估计量的定义出发，推导在所述假设下将 $Y$ 对 $W$ 进行回归时 OLS 斜率的期望值，并由此推导该斜率相对于真实 $\\beta_{1}$ 的衰减偏倚。定义可靠性比率 $R$ 为 $R = \\frac{\\operatorname{Var}(X)}{\\operatorname{Var}(W)}$。提供衰减偏倚的最终闭式解析表达式，该表达式仅用 $R$ 和 $\\beta_{1}$ 表示。\n\n您的最终答案必须是一个单一的闭式解析表达式。不要提供数值近似。", "solution": "问题陈述已经过验证，被认为是统计理论中一个良定的、有科学依据的问题。我们可以开始推导。\n\n目标是推导当将连续结局 $Y$ 对一个带有噪声的预测变量 $W$（其中 $W$ 是真实预测变量 $X$ 的测量值）进行回归时，普通最小二乘法 (OLS) 斜率估计量的衰减偏倚。偏倚是估计量的期望值与真实参数 $\\beta_{1}$ 之间的差。\n\n真实的潜在科学模型被指定为：\n$$Y = \\beta_{0} + \\beta_{1} X + \\varepsilon$$\n其中 $\\operatorname{E}[\\varepsilon \\mid X] = 0$。这个条件意味着 $\\varepsilon$ 与 $X$ 不相关，因为 $\\operatorname{Cov}(X, \\varepsilon) = \\operatorname{E}[X\\varepsilon] - \\operatorname{E}[X]\\operatorname{E}[\\varepsilon]$。根据全期望定律，$\\operatorname{E}[\\varepsilon] = \\operatorname{E}[\\operatorname{E}[\\varepsilon \\mid X]] = \\operatorname{E}[0] = 0$。同样，$\\operatorname{E}[X\\varepsilon] = \\operatorname{E}[\\operatorname{E}[X\\varepsilon \\mid X]] = \\operatorname{E}[X\\operatorname{E}[\\varepsilon \\mid X]] = \\operatorname{E}[X \\cdot 0] = 0$。因此，$\\operatorname{Cov}(X, \\varepsilon) = 0$。\n\n真实预测变量 $X$ 未被观测到。相反，我们观测到来自经典测量误差模型的 $W$：\n$$W = X + U$$\n其中测量误差 $U$ 的均值为零，即 $\\operatorname{E}[U]=0$，且与 $X$ 和 $\\varepsilon$ 两者都独立。\n\n我们使用 OLS 拟合 $Y$ 对观测数据 $W$ 的简单线性回归模型。我们将 OLS 斜率估计量记为 $\\hat{\\beta}_{1,W}$，其公式为 $\\hat{\\beta}_{1,W} = \\frac{\\sum_{i=1}^{n} (W_i - \\bar{W})(Y_i - \\bar{Y})}{\\sum_{i=1}^{n} (W_i - \\bar{W})^2}$。在独立同分布 (i.i.d.) 样本的假设下，根据大数定律，该估计量依概率收敛于总体协方差与总体方差的比值：\n$$ \\text{plim}_{n \\to \\infty} \\hat{\\beta}_{1,W} = \\frac{\\operatorname{Cov}(Y, W)}{\\operatorname{Var}(W)} $$\n这个概率极限是我们的估计量所一致收敛到的量，并代表了该估计量在大样本下的期望值。我们将计算这个量来确定渐近偏倚。\n\n首先，我们推导协方差项 $\\operatorname{Cov}(Y, W)$。我们代入 $Y$ 和 $W$ 的表达式：\n$$ \\operatorname{Cov}(Y, W) = \\operatorname{Cov}(\\beta_{0} + \\beta_{1} X + \\varepsilon, X + U) $$\n利用协方差的双线性性质，我们可以展开此表达式：\n$$ \\operatorname{Cov(Y, W)} = \\operatorname{Cov}(\\beta_{0}, X) + \\operatorname{Cov}(\\beta_{0}, U) + \\operatorname{Cov}(\\beta_{1} X, X) + \\operatorname{Cov}(\\beta_{1} X, U) + \\operatorname{Cov}(\\varepsilon, X) + \\operatorname{Cov}(\\varepsilon, U) $$\n我们根据问题的假设评估每一项：\n1.  $\\operatorname{Cov}(\\beta_{0}, X) = 0$ 和 $\\operatorname{Cov}(\\beta_{0}, U) = 0$，因为常数与任何随机变量的协方差为零。\n2.  $\\operatorname{Cov}(\\beta_{1} X, X) = \\beta_{1} \\operatorname{Cov}(X, X) = \\beta_{1} \\operatorname{Var}(X)$。\n3.  $\\operatorname{Cov}(\\beta_{1} X, U) = \\beta_{1} \\operatorname{Cov}(X, U)$。由于 $X$ 和 $U$ 被陈述为相互独立，它们的协方差为零：$\\operatorname{Cov}(X, U) = 0$。\n4.  $\\operatorname{Cov}(\\varepsilon, X) = 0$，这是由假设 $\\operatorname{E}[\\varepsilon \\mid X] = 0$ 推出的，如前所示。\n5.  $\\operatorname{Cov}(\\varepsilon, U) = 0$，因为 $\\varepsilon$ 和 $U$ 被陈述为相互独立。\n\n将非零项相加，我们得到协方差：\n$$ \\operatorname{Cov}(Y, W) = \\beta_{1} \\operatorname{Var}(X) $$\n\n接下来，我们推导方差项 $\\operatorname{Var}(W)$。使用模型 $W = X + U$：\n$$ \\operatorname{Var}(W) = \\operatorname{Var}(X + U) $$\n由于 $X$ 和 $U$ 相互独立，它们的和的方差等于它们方差的和：\n$$ \\operatorname{Var}(W) = \\operatorname{Var}(X) + \\operatorname{Var}(U) $$\n\n现在，我们可以写出 OLS 斜率估计量的概率极限：\n$$ \\text{plim}_{n \\to \\infty} \\hat{\\beta}_{1,W} = \\frac{\\beta_{1} \\operatorname{Var}(X)}{\\operatorname{Var}(X) + \\operatorname{Var}(U)} $$\n这个表达式代表 OLS 斜率收敛到的值。我们可以看到，除非 $\\operatorname{Var}(U) = 0$（即没有测量误差），否则这个值不等于真实参数 $\\beta_{1}$。\n\n该估计量的渐近偏倚是其概率极限与真实参数值 $\\beta_{1}$ 之间的差：\n$$ \\text{Bias}(\\hat{\\beta}_{1,W}) = (\\text{plim}_{n \\to \\infty} \\hat{\\beta}_{1,W}) - \\beta_{1} $$\n$$ \\text{Bias}(\\hat{\\beta}_{1,W}) = \\frac{\\beta_{1} \\operatorname{Var}(X)}{\\operatorname{Var}(X) + \\operatorname{Var}(U)} - \\beta_{1} $$\n提取出因子 $\\beta_{1}$：\n$$ \\text{Bias}(\\hat{\\beta}_{1,W}) = \\beta_{1} \\left( \\frac{\\operatorname{Var}(X)}{\\operatorname{Var}(X) + \\operatorname{Var}(U)} - 1 \\right) $$\n$$ \\text{Bias}(\\hat{\\beta}_{1,W}) = \\beta_{1} \\left( \\frac{\\operatorname{Var}(X) - (\\operatorname{Var}(X) + \\operatorname{Var}(U))}{\\operatorname{Var}(X) + \\operatorname{Var}(U)} \\right) $$\n$$ \\text{Bias}(\\hat{\\beta}_{1,W}) = \\beta_{1} \\left( \\frac{-\\operatorname{Var}(U)}{\\operatorname{Var}(X) + \\operatorname{Var}(U)} \\right) $$\n这个表达式就是衰减偏倚。因为方差是非负的，所以乘以 $\\beta_{1}$ 的因子在 $-1$ 和 $0$ 之间（假设 $\\operatorname{Var}(U) > 0$）。这会使估计值偏向于零，这种现象被称为衰减或回归稀释。\n\n最后，我们用可靠性比率 $R$ 来表示这个偏倚，其定义为 $R = \\frac{\\operatorname{Var}(X)}{\\operatorname{Var}(W)}$。代入 $\\operatorname{Var}(W) = \\operatorname{Var}(X) + \\operatorname{Var}(U)$，我们有：\n$$ R = \\frac{\\operatorname{Var}(X)}{\\operatorname{Var}(X) + \\operatorname{Var}(U)} $$\n注意到估计量的概率极限可以写成：\n$$ \\text{plim}_{n \\to \\infty} \\hat{\\beta}_{1,W} = \\beta_{1} \\left( \\frac{\\operatorname{Var}(X)}{\\operatorname{Var}(X) + \\operatorname{Var}(U)} \\right) = \\beta_{1} R $$\n因此，衰减偏倚是：\n$$ \\text{Bias}(\\hat{\\beta}_{1,W}) = \\beta_{1} R - \\beta_{1} $$\n提取出因子 $\\beta_{1}$ 得到仅用 $R$ 和 $\\beta_{1}$ 表示的衰减偏倚的最终表达式：\n$$ \\text{Bias}(\\hat{\\beta}_{1,W}) = \\beta_{1}(R - 1) $$", "answer": "$$\\boxed{\\beta_{1}(R-1)}$$", "id": "4952742"}, {"introduction": "线性模型的另一个关键假设是误差项的独立性，但在重复测量或纵向医学数据中，来自同一患者的观测值通常是相关的。本练习 [@problem_id:4952775] 提供了一个非常实用的编码任务，指导你实现一个两步“可行广义最小二乘法”（FGLS）算法来处理这种自相关误差结构。掌握这项技能对于正确分析现代临床研究中常见的纵向数据集至关重要。", "problem": "一个医学研究团队正在研究在每个患者内部于等时间间隔的诊所就诊中获取的重复实验室测量数据，并将这些数据跨患者汇总。考虑一个跨患者堆叠观测值的线性模型，由 $y = X \\beta + \\varepsilon$ 给出，其中 $y$ 是一个 $n \\times 1$ 的响应向量，$X$ 是一个 $n \\times p$ 的设计矩阵，$\\beta$ 是一个 $p \\times 1$ 的系数向量，$\\varepsilon$ 是一个 $n \\times 1$ 的误差项向量。假设 $E[\\varepsilon] = 0$ 并且误差在患者之间是独立的。在每个患者内部，误差由一个平稳的一阶自回归过程（滞后一阶）生成，这意味着对于由 $|t-s|$ 次等间隔就诊分开的患者内时间指数 $t$ 和 $s$，协方差为 $\\text{Cov}(\\varepsilon_t,\\varepsilon_s) = \\sigma^2 \\rho^{|t-s|}$，其中 $|\\rho|  1$ 且 $\\sigma^2 > 0$。高斯-马尔可夫定理和广义最小二乘法理论表明，当协方差结构已知时，最小化均方误差的线性无偏估计器使用逆协方差对观测值进行加权。当相关参数未知但结构形式已指定时，一种可行的广义最小二乘法程序会从数据中估计相关参数，并将其代入加权最小二乘准则中。\n\n您的任务是，从第一性原理出发，推导并实现一个专门针对上述患者内自回归设定的两步可行广义最小二乘算法，并将其应用于三个固定的测试数据集。从线性无偏估计、高斯误差下的二次损失最小化以及一阶自回归相关的核心定义开始。不要依赖任何预编码的线性模型快捷方式。您必须显式地构建并应用一个患者内线性变换，如果代入的相关性是正确的，该变换将使误差不相关，然后在变换后的系统上计算普通最小二乘估计器。\n\n科学现实性约束：将每次就诊视为在每个患者内部等间隔的，将患者视为独立的聚类，将测量时间视为无单位的就诊指数。在 $X$ 中使用一个截距和一个单一的时间协变量。不允许有额外的协变量。\n\n待推导和实现的算法规范：\n- 构建包含两列的 $X$：一列全为 1（截距）和一列包含患者内就诊指数 $t \\in \\{0,1,2,\\dots\\}$。\n- 对未变换的堆叠数据进行初始普通最小二乘拟合以获得残差。\n- 通过最小化由一阶自回归在所有患者中引发的单步前向线性预测误差的平方和来估计自回归参数，仅聚合同一患者内的相邻对。将估计值约束在 $(-1,1)$ 区间内。\n- 使用代入的相关性估计，构建一个逐患者的线性变换，将原始模型映射到自回归模型下误差不相关的模型。将此变换应用于 $y$ 和 $X$。\n- 在变换后的系统上拟合普通最小二乘法，以获得 $\\beta$ 的可行广义最小二乘估计，并将残差方差估计计算为变换后的残差平方和除以 $n - p$。\n\n测试套件和数据：\n您必须在以下三个固定的数据集上运行您的实现。每个数据集由从 $t=0$ 开始的等间隔就诊的患者组成，按所列顺序堆叠。对于每个患者，响应值按就诊顺序列出。\n\n- 测试用例 1（包含 3 名患者，每名 5 次就诊的平衡面板数据）：\n  - 患者 1：响应 $\\{\\,\\$10.0\\$,\\$9.55\\$,\\$9.25\\$,\\$8.95\\$,\\$8.7\\$\\,\\}$\n  - 患者 2：响应 $\\{\\,\\$11.0\\$,\\$10.5\\$,\\$10.2\\$,\\$9.9\\$,\\$9.6\\$\\,\\}$\n  - 患者 3：响应 $\\{\\,\\$9.2\\$,\\$8.9\\$,\\$8.6\\$,\\$8.4\\$,\\$8.1\\$\\,\\}$\n\n- 测试用例 2（长度不一的非平衡面板数据）：\n  - 患者 1（就诊 $t = 0,1,2,3$）：响应 $\\{\\,\\$7.5\\$,\\$7.6\\$,\\$7.4\\$,\\$7.3\\$\\,\\}$\n  - 患者 2（就诊 $t = 0,1,2$）：响应 $\\{\\,\\$8.0\\$,\\$7.7\\$,\\$7.5\\$\\,\\}$\n  - 患者 3（就诊 $t = 0,1,2,3,4,5$）：响应 $\\{\\,\\$6.0\\$,\\$6.2\\$,\\$6.1\\$,\\$5.9\\$,\\$5.8\\$,\\$5.6\\$\\,\\}$\n\n- 测试用例 3（患者内部接近单位根的持续性）：\n  - 患者 1（就诊 $t = 0,1,2,3,4,5,6,7$）：响应 $\\{\\,\\$12.0\\$,\\$11.9\\$,\\$11.85\\$,\\$11.8\\$,\\$11.78\\$,\\$11.77\\$,\\$11.75\\$,\\$11.74\\$\\,\\}$\n  - 患者 2（就诊 $t = 0,1,2,3,4,5,6,7$）：响应 $\\{\\,\\$10.0\\$,\\$9.95\\$,\\$9.92\\$,\\$9.9\\$,\\$9.88\\$,\\$9.87\\$,\\$9.86\\$,\\$9.85\\$\\,\\}$\n\n在所有数据集中，使用 $X = [\\mathbf{1}, t]$，其中对于每个患者，$t$ 从 0 重新开始，并在患者内部每次就诊增加 1。将患者视为独立的聚类。\n\n输出规范：\n对于每个测试用例，按此顺序生成一个包含四个值的列表：代入的相关性估计 $\\hat{\\rho}$，可行广义最小二乘系数估计 $\\hat{\\beta}_0$（截距）和 $\\hat{\\beta}_1$（时间斜率），以及变换后残差的方差估计 $\\hat{\\sigma}^2$。将每个值四舍五入到 6 位小数。您的程序应生成单行输出，其中包含所有三个测试用例的结果，格式为一个由方括号括起来的列表的逗号分隔列表，例如 $[\\,[r\\_1, r\\_2, r\\_3, r\\_4], [\\dots], [\\dots]\\,]$，其中每个 $r\\_j$ 是一个四舍五入到 6 位小数的实数。\n\n边缘情况和边界要求：\n- 通过将 $(-1,1)$ 之外的任何估计值截断回最接近的内部值来强制执行 $|\\hat{\\rho}|  1$。\n- 如果患者只有一个观测值，则应用与较长序列的第一个观测值相同的第一行变换，并将其包含在变换后的拟合中。\n- 在计算 $\\hat{\\sigma}^2$ 的自由度时，对每个数据集使用 $p = 2$ 和相应的总 $n$。\n\n您的实现必须是一个完整、可运行的程序，该程序从提供的响应构建设计矩阵，精确执行一次可行广义最小二乘算法（无进一步迭代），并打印指定的单行输出。不允许用户输入或外部文件。所有量都必须报告为无单位的数字，并四舍五入到 6 位小数。", "solution": "该问题要求针对一个线性模型推导并实现一个两步可行广义最小二乘（FGLS）算法，该模型在独立的患者聚类内部存在序列相关的误差。误差结构被指定为一个一阶自回归过程，即 AR($1$) 过程。\n\n**1. 问题验证**\n\n首先，我将根据指定标准验证问题陈述。\n\n**第 1 步：提取的已知条件**\n- **模型：** $y = X \\beta + \\varepsilon$，其中 $y$ 是一个 $n \\times 1$ 的堆叠响应向量，$X$ 是一个 $n \\times p$ 的设计矩阵，$\\beta$ 是一个 $p \\times 1$ 的系数向量，$\\varepsilon$ 是一个 $n \\times 1$ 的误差项向量。\n- **误差假设：** $E[\\varepsilon] = 0$。误差在患者之间是独立的。在任何患者内部，对于时间 $t$ 和 $s$ 的观测值，协方差为 $\\text{Cov}(\\varepsilon_t,\\varepsilon_s) = \\sigma^2 \\rho^{|t-s|}$，其中 $|\\rho|  1$ 且 $\\sigma^2 > 0$。\n- **设计矩阵 ($X$)：** 一列全为 1（截距）和一列患者内就诊指数 $t \\in \\{0,1,2,\\dots\\}$。因此，$p=2$。\n- **算法规范：**\n    1.  计算初始普通最小二乘（OLS）残差。\n    2.  通过对所有患者内的相邻对进行残差对滞后残差的回归来估计 $\\rho$。估计值 $\\hat{\\rho}$ 必须被约束在 $(-1, 1)$ 内。\n    3.  使用 $\\hat{\\rho}$ 构建一个逐患者的线性变换矩阵，以消除误差的相关性（一个 Prais-Winsten 变换）。将其应用于 $y$ 和 $X$。\n    4.  对变换后的数据进行 OLS 拟合，以获得 $\\beta$ 的 FGLS 估计。\n    5.  估计残差方差为 $\\hat{\\sigma}^2 = \\frac{RSS^*}{n-p}$，其中 $RSS^*$ 是变换后模型的残差平方和。\n- **数据：** 提供了三个测试数据集，患者和就诊次数不同。\n- **输出：** 对于每个用例，报告 $[\\hat{\\rho}, \\hat{\\beta}_0, \\hat{\\beta}_1, \\hat{\\sigma}^2]$，四舍五入到 6 位小数。\n\n**第 2 步：使用提取的已知条件进行验证**\n- **科学依据：** 该问题描述了 FGLS 的应用，这是计量经济学和生物统计学中处理回归模型中序列相关误差的标准和基本技术。AR($1$) 误差结构是此类相关的典型模型。指定的两步程序（通常与 Cochrane-Orcutt 或 Prais-Winsten 相关联）是教科书内容。该问题在科学和统计上是合理的。\n- **适定性：** 问题陈述是自洽的。它提供了模型、误差结构、具体数据和一个清晰、分步的算法。所有术语在统计学中都有明确定义。预期有唯一解。\n- **客观性：** 问题以客观的数学语言表述，没有偏见或主观性陈述。\n\n该问题不违反任何无效性标准。它在科学上是合理的、适定的、客观的、完整的并且是计算可验证的。\n\n**第 3 步：结论和行动**\n该问题是有效的。我现在将进行推导和求解。\n\n**2. 可行广义最小二乘（FGLS）算法的推导**\n\n指定的线性模型是 $y = X \\beta + \\varepsilon$。观测值按患者聚类，观测值在患者之间独立，但在患者内部相关。对于具有 $n_i$ 个观测值的单个患者 $i$，模型为 $y_i = X_i \\beta + \\varepsilon_i$。误差向量 $\\varepsilon_i$ 的协方差矩阵为 $\\text{Cov}(\\varepsilon_i) = \\Omega_i = \\sigma^2 V_i$，其中 $V_i$ 是 $n_i \\times n_i$ 的相关矩阵，其元素为 $(V_i)_{ts} = \\rho^{|t-s|}$。\n\n广义最小二乘（GLS）估计器，即最佳线性无偏估计器（BLUE），由下式给出：\n$$\n\\hat{\\beta}_{GLS} = (X^T \\Omega^{-1} X)^{-1} X^T \\Omega^{-1} y\n$$\n由于 $\\Omega = \\sigma^2 V$，这可以简化为 $\\hat{\\beta}_{GLS} = (X^T V^{-1} X)^{-1} X^T V^{-1} y$。\n\nGLS 估计器可以作为变换后模型上的 OLS 估计器来计算。我们为整个系统寻找一个变换矩阵 $P$，使得变换后的误差 $P\\varepsilon$ 是同方差且不相关的，即 $\\text{Cov}(P\\varepsilon) = \\sigma_u^2 I$。由于误差在患者之间是独立的，全局变换矩阵 $P$ 是块对角矩阵，由特定于患者的变换矩阵 $P_i$ 组成。对于每个患者 $i$，我们需要 $P_i$ 使得 $\\text{Cov}(P_i \\varepsilon_i) = P_i (\\sigma^2 V_i) P_i^T = \\sigma_u^2 I_{n_i}$，其中 $I_{n_i}$ 是 $n_i \\times n_i$ 的单位矩阵。\n\nAR(1) 误差过程，$\\varepsilon_t = \\rho \\varepsilon_{t-1} + u_t$，其中 $u_t$ 是均值为 0、方差为 $\\sigma_u^2$ 的独立同分布随机变量，为该变换提供了基础。方差之间的关系是 $\\sigma^2 = \\text{Var}(\\varepsilon_t) = \\frac{\\sigma_u^2}{1-\\rho^2}$。\n\n对于观测值 $t = 1, \\dots, n_i-1$（使用从 0 开始的索引），我们可以通过作差来消除序列相关性：\n$$\n\\varepsilon_{i,t} - \\rho \\varepsilon_{i,t-1} = u_{i,t}\n$$\n这些变换后的误差的方差为 $\\sigma_u^2$。第一个误差项 $\\varepsilon_{i,0}$ 的方差为 $\\sigma^2 = \\frac{\\sigma_u^2}{1-\\rho^2}$。为了使其具有相同的方差 $\\sigma_u^2$，我们用 $\\sqrt{1-\\rho^2}$ 对其进行缩放：\n$$\n\\sqrt{1-\\rho^2} \\varepsilon_{i,0}\n$$\n这定义了 Prais-Winsten 变换。对于患者 $i$，变换矩阵 $P_i$ 为：\n$$\nP_i(\\rho) =\n\\begin{pmatrix}\n\\sqrt{1-\\rho^2}  0  0  \\dots  0 \\\\\n-\\rho  1  0  \\dots  0 \\\\\n0  -\\rho  1  \\dots  0 \\\\\n\\vdots   \\ddots   \\vdots \\\\\n0  \\dots  0  -\\rho  1\n\\end{pmatrix}\n$$\n将此变换应用于模型 $y_i = X_i \\beta + \\varepsilon_i$ 会得到患者 $i$ 的变换后模型：\n$$\nP_i y_i = (P_i X_i) \\beta + P_i \\varepsilon_i \\quad \\implies \\quad y_i^* = X_i^* \\beta + \\varepsilon_i^*\n$$\n变换后的误差向量 $\\varepsilon_i^*$ 的协方差矩阵为 $\\text{Cov}(\\varepsilon_i^*) = \\sigma^2(1-\\rho^2)I_{n_i} = \\sigma_u^2 I_{n_i}$。在将所有变换后的患者数据堆叠得到 $y^* = X^* \\beta + \\varepsilon^*$ 后，我们可以应用 OLS 来求解 $\\beta$。\n\n由于 $\\rho$ 未知，我们必须从数据中估计它。这就引出了两步 FGLS 程序。\n\n**第 1 步：初始 OLS 拟合**\n首先，我们忽略相关性，计算 $\\beta$ 的初始 OLS 估计：\n$$\n\\hat{\\beta}_{OLS} = (X^T X)^{-1} X^T y\n$$\n该拟合的残差 $e = y - X\\hat{\\beta}_{OLS}$ 可作为真实误差 $\\varepsilon$ 的一致估计。\n\n**第 2 步：估计自回归参数 $\\rho$**\n我们从 OLS 残差中的 AR(1) 关系估计 $\\rho$：$e_{i,t} \\approx \\rho e_{i,t-1} + \\text{noise}$。$\\rho$ 的最小二乘估计器是通过使用患者内部所有可用的相邻对，将 $e_{i,t}$ 对 $e_{i,t-1}$ 进行回归得到的：\n$$\n\\hat{\\rho} = \\frac{\\sum_{i=1}^N \\sum_{t=1}^{n_i-1} e_{i,t} e_{i,t-1}}{\\sum_{i=1}^N \\sum_{t=1}^{n_i-1} e_{i,t-1}^2}\n$$\n其中 $N$ 是患者数量。问题要求将此估计值严格约束在 $(-1, 1)$ 区间内，以确保平稳性条件和变换项 $\\sqrt{1-\\hat{\\rho}^2}$ 的有效性。超出此范围的任何估计都将被截断到区间内最接近的值，例如 $\\pm(1 - 10^{-9})$。\n\n**第 3 步：数据变换**\n使用估计的 $\\hat{\\rho}$，我们对每个患者 $i$ 的数据进行变换：\n- 第一个观测值 ($t=0$):\n  $y_{i,0}^* = \\sqrt{1-\\hat{\\rho}^2} \\, y_{i,0}$\n  $X_{i,0}^* = \\sqrt{1-\\hat{\\rho}^2} \\, X_{i,0}$\n- 后续观测值 ($t = 1, \\dots, n_i-1$):\n  $y_{i,t}^* = y_{i,t} - \\hat{\\rho} \\, y_{i,t-1}$\n  $X_{i,t}^* = X_{i,t} - \\hat{\\rho} \\, X_{i,t-1}$\n对于只有一个观测值的患者（$n_i=1$），仅应用第一个观测值的变换。然后将变换后的数据 $(y^*, X^*)$ 跨所有患者进行堆叠。\n\n**第 4 步：FGLS 估计和方差计算**\n$\\beta$ 的 FGLS 估计是通过对变换后的模型应用 OLS 获得的：\n$$\n\\hat{\\beta}_{FGLS} = ((X^*)^T X^*)^{-1} (X^*)^T y^*\n$$\n变换后的残差为 $e^* = y^* - X^* \\hat{\\beta}_{FGLS}$。残差平方和为 $RSS^* = (e^*)^T e^*$。\n问题指定最终的方差估计为变换后残差的方差，它估计的是 $\\sigma_u^2 = \\sigma^2(1-\\rho^2)$。虽然通常可能会对其进行缩放以估计 $\\sigma^2$，但指令是报告 $\\hat{\\sigma}^2 = \\frac{RSS^*}{n-p}$，其中 $n$ 是总观测数，$p=2$ 是模型参数的数量。我将遵循此明确指令。\n\n推导到此完成。实现将精确地遵循这些步骤。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the FGLS procedure on all test cases and print the results.\n    \"\"\"\n\n    test_cases = [\n        # Test case 1 (balanced panel)\n        [\n            [10.0, 9.55, 9.25, 8.95, 8.7],\n            [11.0, 10.5, 10.2, 9.9, 9.6],\n            [9.2, 8.9, 8.6, 8.4, 8.1]\n        ],\n        # Test case 2 (unbalanced panel)\n        [\n            [7.5, 7.6, 7.4, 7.3],\n            [8.0, 7.7, 7.5],\n            [6.0, 6.2, 6.1, 5.9, 5.8, 5.6]\n        ],\n        # Test case 3 (near-unit persistence)\n        [\n            [12.0, 11.9, 11.85, 11.8, 11.78, 11.77, 11.75, 11.74],\n            [10.0, 9.95, 9.92, 9.9, 9.88, 9.87, 9.86, 9.85]\n        ]\n    ]\n\n    def run_fgls(patient_data):\n        \"\"\"\n        Implements the two-step feasible generalized least squares algorithm for one dataset.\n        \"\"\"\n        # Step 1: Construct stacked y vector and X matrix from patient data\n        y_list = []\n        X_list = []\n        patient_indices = []\n        current_idx = 0\n        for responses in patient_data:\n            ni = len(responses)\n            y_list.extend(responses)\n            t = np.arange(ni)\n            X_patient = np.column_stack((np.ones(ni, dtype=float), t.astype(float)))\n            X_list.append(X_patient)\n            patient_indices.append((current_idx, current_idx + ni))\n            current_idx += ni\n\n        y = np.array(y_list)\n        X = np.vstack(X_list)\n        n = len(y)\n        p = X.shape[1]\n\n        # Step 2: Compute initial OLS fit to obtain residuals\n        try:\n            beta_ols = np.linalg.solve(X.T @ X, X.T @ y)\n        except np.linalg.LinAlgError:\n            # Fallback for singular matrix, though not expected with given data\n            beta_ols = np.linalg.pinv(X.T @ X) @ X.T @ y\n        \n        residuals = y - X @ beta_ols\n\n        # Step 3: Estimate the autoregressive parameter rho\n        e_current_list = []\n        e_lagged_list = []\n        for start, end in patient_indices:\n            if end - start > 1:\n                patient_residuals = residuals[start:end]\n                e_current_list.extend(patient_residuals[1:])\n                e_lagged_list.extend(patient_residuals[:-1])\n        \n        e_current = np.array(e_current_list)\n        e_lagged = np.array(e_lagged_list)\n\n        if len(e_lagged) == 0:\n            rho_hat_raw = 0.0\n        else:\n            denominator = e_lagged @ e_lagged\n            if np.isclose(denominator, 0):\n                rho_hat_raw = 0.0\n            else:\n                rho_hat_raw = (e_lagged @ e_current) / denominator\n\n        # Constrain rho to be strictly within (-1, 1)\n        rho_hat = np.clip(rho_hat_raw, -1.0 + 1e-9, 1.0 - 1e-9)\n\n        # Step 4: Apply the Prais-Winsten transformation to y and X\n        y_star_list = []\n        X_star_list = []\n        rho_transform_factor = np.sqrt(1.0 - rho_hat**2)\n\n        for i, (start, end) in enumerate(patient_indices):\n            y_patient = y[start:end]\n            X_patient = X[start:end, :]\n            ni = end - start\n\n            if ni >= 1:\n                # First observation transformation\n                y_star_first = rho_transform_factor * y_patient[0]\n                X_star_first = rho_transform_factor * X_patient[0, :]\n                y_star_list.append(y_star_first)\n                X_star_list.append(X_star_first)\n            \n            if ni > 1:\n                # Subsequent observations transformation\n                y_star_rest = y_patient[1:] - rho_hat * y_patient[:-1]\n                X_star_rest = X_patient[1:, :] - rho_hat * X_patient[:-1, :]\n                y_star_list.extend(y_star_rest)\n                X_star_list.extend(X_star_rest)\n\n        y_star = np.array(y_star_list)\n        X_star = np.array(X_star_list)\n\n        # Step 5: Fit OLS on the transformed system to get FGLS estimates\n        try:\n            beta_fgls = np.linalg.solve(X_star.T @ X_star, X_star.T @ y_star)\n        except np.linalg.LinAlgError:\n            beta_fgls = np.linalg.pinv(X_star.T @ X_star) @ X_star.T @ y_star\n\n        # Step 6: Compute the residual variance estimate\n        residuals_star = y_star - X_star @ beta_fgls\n        rss_star = residuals_star.T @ residuals_star\n        sigma_sq_hat = rss_star / (n - p)\n        \n        return [rho_hat, beta_fgls[0], beta_fgls[1], sigma_sq_hat]\n\n    # Process all test cases\n    all_results = [run_fgls(case_data) for case_data in test_cases]\n\n    # Format and print the final output string\n    list_of_list_strings = []\n    for single_case_results in all_results:\n        formatted_nums = [f\"{val:.6f}\" for val in single_case_results]\n        list_of_list_strings.append(f\"[{','.join(formatted_nums)}]\")\n    \n    final_output_str = f\"[{','.join(list_of_list_strings)}]\"\n    print(final_output_str)\n\nsolve()\n```", "id": "4952775"}, {"introduction": "模型拟合完成后，一个关键步骤是评估其稳健性，即检查是否存在对结果有过度影响的单个数据点。本练习 [@problem_id:4952702] 将精确推导删除单个观测值对回归系数产生的具体影响，揭示了残差和杠杆值是如何共同决定一个数据点的“影响力”的。这个推导为医学回归诊断中常用的影响力度量（如DFBETA）提供了坚实的理论基础。", "problem": "考虑一项多中心随机对照试验（RCT），其中收缩压通过线性预测器建模，并遵循经典的高斯-马尔可夫条件：条件均值的线性、设计矩阵的列满秩、误差 $\\varepsilon$ 独立同分布且均值为 $0$、方差为常数 $\\sigma^{2}$，以及协变量测量无误差。设设计矩阵为 $X \\in \\mathbb{R}^{n \\times p}$，其中 $p=3$，各列分别对应截距项、中心化的年龄和二元治疗指示变量。普通最小二乘估计量定义为 $\\hat{\\beta} = (X^{\\top}X)^{-1}X^{\\top}y$。\n\n删除单个患者 $j$，其数据由行向量 $x_{j} \\in \\mathbb{R}^{3}$ 表示，并观察其残差 $r_{j} = y_{j} - x_{j}^{\\top}\\hat{\\beta}$。从高斯-马尔可夫框架和普通最小二乘正规方程出发，并仅使用秩为1的Sherman–Morrison恒等式来更新矩阵的逆，推导因删除患者 $j$ 而导致的系数变化的精确解析表达式，即 $\\,\\hat{\\beta}_{(j)} - \\hat{\\beta}\\,$。该表达式需用 $x_{j}$、$(X^{\\top}X)^{-1}$、$r_{j}$ 和杠杆值 $h_{jj} = x_{j}^{\\top}(X^{\\top}X)^{-1}x_{j}$ 来表示。解释此表达式如何揭示杠杆值和残差在医学回归诊断中使用的标准影响度量中的作用。\n\n然后，对于一个特定的研究中心，假设在完整样本上已估计出以下量：\n$$\n(X^{\\top}X)^{-1} \\;=\\;\n\\begin{pmatrix}\n0.052  0  0 \\\\\n0  0.00225  0 \\\\\n0  0  0.008\n\\end{pmatrix},\n\\qquad\nx_{j} \\;=\\; \\begin{pmatrix} 1 \\\\ -0.3 \\\\ 1 \\end{pmatrix},\n\\qquad\nr_{j} \\;=\\; 2.1.\n$$\n计算因删除患者 $j$ 引起的治疗效应系数（$\\hat{\\beta}$ 的第三个分量）变化的数值。治疗效应系数的单位是毫米汞柱（mmHg）。将最终数值答案四舍五入至四位有效数字。请给出最终数值；在方框答案中不要包含单位。", "solution": "该问题要求在删除单个观测值后，推导普通最小二乘（OLS）回归系数的变化，然后进行数值计算。该过程从对问题陈述的形式化验证开始。\n\n### 步骤1：提取已知条件\n- **模型**：收缩压的线性回归模型。\n- **假设**：满足经典高斯-马尔可夫条件。\n- **设计矩阵**：$X \\in \\mathbb{R}^{n \\times p}$，其中 $p=3$。各列分别为截距项、中心化的年龄和二元治疗指示变量。\n- **OLS估计量**：$\\hat{\\beta} = (X^{\\top}X)^{-1}X^{\\top}y$。\n- **观测值删除**：删除患者 $j$，其数据由行向量 $x_{j} \\in \\mathbb{R}^{3}$ 表示。\n- **残差**：$r_{j} = y_{j} - x_{j}^{\\top}\\hat{\\beta}$。\n- **杠杆值**：$h_{jj} = x_{j}^{\\top}(X^{\\top}X)^{-1}x_{j}$。\n- **任务1（推导）**：使用Sherman–Morrison恒等式推导 $\\hat{\\beta}_{(j)} - \\hat{\\beta}$，并用 $x_{j}$、$(X^{\\top}X)^{-1}$、$r_{j}$ 和 $h_{jj}$ 表示。\n- **任务2（解释）**：解释推导出的表达式如何揭示杠杆值和残差在影响度量中的作用。\n- **任务3（计算）**：根据以下数据，计算第三个系数（治疗效应）变化的数值：\n$$ (X^{\\top}X)^{-1} = \\begin{pmatrix} 0.052  0  0 \\\\ 0  0.00225  0 \\\\ 0  0  0.008 \\end{pmatrix}, \\qquad x_{j} = \\begin{pmatrix} 1 \\\\ -0.3 \\\\ 1 \\end{pmatrix}, \\qquad r_{j} = 2.1 $$\n- **取整**：将最终数值答案四舍五入至四位有效数字。\n\n### 步骤2：使用提取的已知条件进行验证\n根据验证标准对问题进行评估。\n- **科学依据**：该问题设定在线性回归理论和诊断的标准、成熟的框架内。OLS、高斯-马尔可夫条件、残差、杠杆值和影响诊断（如本次推导产生的DFBETAS）等概念是统计建模的基础。医学试验的应用背景是恰当的。\n- **良构性**：问题陈述清晰。它要求一个特定的、标准的推导和一个随后的数值计算。两部分所需的所有信息都已提供。存在唯一、稳定且有意义的解。\n- **客观性**：问题以精确的数学和统计语言表达，没有歧义或主观内容。\n\n### 步骤3：结论与行动\n该问题具有科学合理性、良构性、客观性和完整性。因此，它被判定为**有效**。将继续进行解答。\n\n### 系数变化的推导\n设 $X$ 和 $y$ 为完整数据矩阵。OLS估计量是正规方程 $X^{\\top}X \\hat{\\beta} = X^{\\top}y$ 的解。\n设 $X_{(j)}$ 和 $y_{(j)}$ 表示移除了第 $j$ 个观测值的数据。新的估计量 $\\hat{\\beta}_{(j)}$ 由下式给出：\n$$ \\hat{\\beta}_{(j)} = (X_{(j)}^{\\top}X_{(j)})^{-1} X_{(j)}^{\\top}y_{(j)} $$\n对于删减后的数据集，其矩阵可以用完整数据集的矩阵和被删除观测值的数据 $x_j$ 和 $y_j$ 来表示：\n$$ X^{\\top}X = \\sum_{i=1}^{n} x_i x_i^{\\top} = X_{(j)}^{\\top}X_{(j)} + x_j x_j^{\\top} \\implies X_{(j)}^{\\top}X_{(j)} = X^{\\top}X - x_j x_j^{\\top} $$\n$$ X^{\\top}y = \\sum_{i=1}^{n} x_i y_i = X_{(j)}^{\\top}y_{(j)} + x_j y_j \\implies X_{(j)}^{\\top}y_{(j)} = X^{\\top}y - x_j y_j $$\n为了求 $X_{(j)}^{\\top}X_{(j)}$ 的逆，我们使用秩-1更新的Sherman–Morrison恒等式：$(A - uv^{\\top})^{-1} = A^{-1} + \\frac{A^{-1}uv^{\\top}A^{-1}}{1 - v^{\\top}A^{-1}u}$。\n令 $A = X^{\\top}X$，$u = x_j$，$v = x_j$。该恒等式变为：\n$$ (X^{\\top}X - x_j x_j^{\\top})^{-1} = (X^{\\top}X)^{-1} + \\frac{(X^{\\top}X)^{-1}x_j x_j^{\\top}(X^{\\top}X)^{-1}}{1 - x_j^{\\top}(X^{\\top}X)^{-1}x_j} $$\n注意到杠杆值 $h_{jj} = x_j^{\\top}(X^{\\top}X)^{-1}x_j$，我们有：\n$$ (X_{(j)}^{\\top}X_{(j)})^{-1} = (X^{\\top}X)^{-1} + \\frac{(X^{\\top}X)^{-1}x_j x_j^{\\top}(X^{\\top}X)^{-1}}{1 - h_{jj}} $$\n现在，我们将这些表达式代入 $\\hat{\\beta}_{(j)}$ 的公式中：\n$$ \\hat{\\beta}_{(j)} = \\left[ (X^{\\top}X)^{-1} + \\frac{(X^{\\top}X)^{-1}x_j x_j^{\\top}(X^{\\top}X)^{-1}}{1 - h_{jj}} \\right] (X^{\\top}y - x_j y_j) $$\n展开乘积得到四项：\n$$ \\hat{\\beta}_{(j)} = (X^{\\top}X)^{-1}(X^{\\top}y) - (X^{\\top}X)^{-1}x_j y_j + \\frac{(X^{\\top}X)^{-1}x_j x_j^{\\top}(X^{\\top}X)^{-1}(X^{\\top}y)}{1 - h_{jj}} - \\frac{(X^{\\top}X)^{-1}x_j x_j^{\\top}(X^{\\top}X)^{-1}x_j y_j}{1 - h_{jj}} $$\n我们简化每一项：\n1. $(X^{\\top}X)^{-1}(X^{\\top}y) = \\hat{\\beta}$\n2. $x_j^{\\top}(X^{\\top}X)^{-1}(X^{\\top}y) = x_j^{\\top}\\hat{\\beta} = \\hat{y}_j$（观测值 $j$ 的拟合值）\n3. $x_j^{\\top}(X^{\\top}X)^{-1}x_j = h_{jj}$（观测值 $j$ 的杠杆值）\n\n将这些代回：\n$$ \\hat{\\beta}_{(j)} = \\hat{\\beta} - (X^{\\top}X)^{-1}x_j y_j + \\frac{(X^{\\top}X)^{-1}x_j \\hat{y}_j}{1 - h_{jj}} - \\frac{(X^{\\top}X)^{-1}x_j h_{jj} y_j}{1 - h_{jj}} $$\n我们关心的是变化量 $\\hat{\\beta}_{(j)} - \\hat{\\beta}$：\n$$ \\hat{\\beta}_{(j)} - \\hat{\\beta} = - (X^{\\top}X)^{-1}x_j y_j + \\frac{(X^{\\top}X)^{-1}x_j (\\hat{y}_j - h_{jj} y_j)}{1 - h_{jj}} $$\n提出公因子向量 $(X^{\\top}X)^{-1}x_j$：\n$$ \\hat{\\beta}_{(j)} - \\hat{\\beta} = (X^{\\top}X)^{-1}x_j \\left[ -y_j + \\frac{\\hat{y}_j - h_{jj} y_j}{1 - h_{jj}} \\right] $$\n将方括号内的项通分合并：\n$$ \\left[ \\frac{-y_j(1 - h_{jj}) + \\hat{y}_j - h_{jj} y_j}{1 - h_{jj}} \\right] = \\left[ \\frac{-y_j + y_j h_{jj} + \\hat{y}_j - h_{jj} y_j}{1 - h_{jj}} \\right] = \\frac{\\hat{y}_j - y_j}{1 - h_{jj}} $$\n残差定义为 $r_j = y_j - \\hat{y}_j$，因此 $\\hat{y}_j - y_j = -r_j$。于是，方括号内的表达式简化为 $\\frac{-r_j}{1 - h_{jj}}$。\n将其代回，得到系数变化的最终表达式：\n$$ \\hat{\\beta}_{(j)} - \\hat{\\beta} = -\\frac{(X^{\\top}X)^{-1}x_j r_j}{1 - h_{jj}} $$\n\n### 影响力的解释\n这个精确的表达式，有时记为 DFBETA$_j$，量化了观测值 $j$ 对估计系数向量 $\\hat{\\beta}$ 的影响。它揭示了一个观测值的影响是两个关键量的函数：\n1.  **残差 ($r_j$)**：变化量与残差 $r_j$ 成正比。一个观测值只有在用完整数据拟合的模型对其预测效果不佳时才具有影响力。一个远离数据总体趋势的点（即 $|r_j|$ 很大）具有成为影响点的潜力。如果 $r_j=0$，那么无论其其他属性如何，该观测值对系数都没有影响。\n2.  **杠杆值 ($h_{jj}$)**：变化量被因子 $1/(1 - h_{jj})$ 放大。杠杆值 $h_{jj}$ 衡量一个观测值的协变量值 ($x_j$) 的异常或极端程度。由于 $0 \\le h_{jj} \\le 1$，分母 $1 - h_{jj}$ 总是非负的。当 $h_{jj} \\to 1$ 时，分母趋近于 $0$，对系数的影响可能变得任意大。因此，具有高杠杆值（协变量离群点）的点具有更大的潜力成为影响点。\n\n总之，如果一个观测值具有大残差（在响应维度上是离群点）和/或高杠杆值（在预测变量空间中是离群点），那么它就是有影响力的。推导出的公式表明，当一个观测值同时具有高杠杆值和大残差时，其影响力最大。\n\n### 数值计算\n我们需要计算第三个系数（治疗效应）的变化，我们将其记为 $(\\hat{\\beta}_{(j)} - \\hat{\\beta})_3$。完整的变化向量是：\n$$ \\hat{\\beta}_{(j)} - \\hat{\\beta} = -\\frac{r_j}{1 - h_{jj}} (X^{\\top}X)^{-1}x_j $$\n首先，我们计算杠杆值 $h_{jj}$：\n$$ h_{jj} = x_{j}^{\\top}(X^{\\top}X)^{-1}x_{j} $$\n$$ h_{jj} = \\begin{pmatrix} 1  -0.3  1 \\end{pmatrix} \\begin{pmatrix} 0.052  0  0 \\\\ 0  0.00225  0 \\\\ 0  0  0.008 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -0.3 \\\\ 1 \\end{pmatrix} $$\n由于 $(X^{\\top}X)^{-1}$ 是对角矩阵，计算简化为：\n$$ h_{jj} = (1)^2(0.052) + (-0.3)^2(0.00225) + (1)^2(0.008) $$\n$$ h_{jj} = 0.052 + (0.09)(0.00225) + 0.008 $$\n$$ h_{jj} = 0.052 + 0.0002025 + 0.008 = 0.0602025 $$\n接下来，我们计算向量 $(X^{\\top}X)^{-1}x_j$：\n$$ (X^{\\top}X)^{-1}x_j = \\begin{pmatrix} 0.052  0  0 \\\\ 0  0.00225  0 \\\\ 0  0  0.008 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -0.3 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 0.052 \\times 1 \\\\ 0.00225 \\times (-0.3) \\\\ 0.008 \\times 1 \\end{pmatrix} = \\begin{pmatrix} 0.052 \\\\ -0.000675 \\\\ 0.008 \\end{pmatrix} $$\n该向量的第三个分量是 $0.008$。\n现在，我们可以使用给定的 $r_j = 2.1$ 来计算第三个系数的变化：\n$$ (\\hat{\\beta}_{(j)} - \\hat{\\beta})_3 = -\\frac{r_j}{1 - h_{jj}} \\times \\left( (X^{\\top}X)^{-1}x_j \\right)_3 $$\n$$ (\\hat{\\beta}_{(j)} - \\hat{\\beta})_3 = -\\frac{2.1}{1 - 0.0602025} \\times 0.008 $$\n$$ (\\hat{\\beta}_{(j)} - \\hat{\\beta})_3 = -\\frac{2.1 \\times 0.008}{0.9397975} = -\\frac{0.0168}{0.9397975} $$\n$$ (\\hat{\\beta}_{(j)} - \\hat{\\beta})_3 \\approx -0.01787618... $$\n四舍五入到四位有效数字，我们得到 $-0.01788$。", "answer": "$$\\boxed{-0.01788}$$", "id": "4952702"}]}