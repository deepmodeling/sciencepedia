## 引言
在[统计建模](@entry_id:272466)中，[分类预测变量](@entry_id:636655)（例如在医学研究中的治疗方案、疾病分期）承载着至关重要的信息。然而，这些非数值数据无法直接被模型使用，如何将其转化为有效的数值形式是一个核心挑战。不恰当的编码会人为引入不存在的顺序或等距关系，导致模型偏倚和错误的科学结论，这构成了统计分析中的一个关键知识缺口。本文旨在系统性地解决这一问题，为各领域的研究者提供一套完整的理论与实践指南。

在接下来的内容中，我们将分三步深入探讨。**“原理与机制”**章节将从根本上阐明分类编码的必要性，区分名义与有序变量，并详细解析处理编码、效应编码等多项核心方案背后的线性代数基础及参数解释。随后，**“应用与跨学科联系”**章节将展示这些理论在广义线性模型（如逻辑回归与泊松回归）中的具体应用，如何解释[交互作用](@entry_id:164533)，并探讨其在[空间转录组学](@entry_id:270096)等前沿领域的应用，同时介绍处理高基数变量等复杂情况的高级策略。最后，**“动手实践”**部分将通过一系列精心设计的问题，帮助您将理论知识转化为解决实际问题的能力。

## 原理与机制

在[统计模型](@entry_id:755400)中，预测变量通常以数值形式输入。然而，在医学研究中，许多关键的预测信息本质上是分类的，例如患者的血型、疾病分期或所属的治疗组。将这些非数值信息转化为模型可以理解的数值形式，需要一套严谨的编码方案。本章将深入探讨[分类预测变量](@entry_id:636655)编码的根本原理、关键机制及其对[模型解释](@entry_id:637866)和可重复性的深远影响。我们将从编码的基本挑战开始，逐步介绍核心编码方案，探讨其在不同类型数据和研究问题中的应用，并最终讨论高级主题，如高[基数](@entry_id:754020)变量和模型病态问题。

### [分类变量](@entry_id:637195)的表示挑战

[分类预测变量](@entry_id:636655)可分为两大类：**名义变量 (nominal variables)** 和 **有序变量 (ordinal variables)**。正确区分这两者是选择合适编码方案的第一步，也是确保模型假设与数据内在结构相符的基础 [@problem_id:4955279]。

**名义变量** 的类别之间没有内在的顺序。例如，血型（A、B、AB、O）就是一个典型的名义变量。我们可以任意排列这些类别的顺序（如 O、A、B、AB），而不会丢失任何信息。因此，任何对名义变量的有效编码方案，其结果在理论上都应与类别的任意置换保持不变。一个常见的错误是将这些类别直接映射为任意整数，例如，令 $\text{O}=1, \text{A}=2, \text{B}=3, \text{AB}=4$，然后将这个单一的数值变量放入模型中。这种做法是根本上不恰当的，因为它人为地强加了一种不存在的顺序（例如，A < B < AB）和等距关系（例如，从 A 到 B 的效应变化等同于从 B 到 AB 的变化）。这种[模型设定错误](@entry_id:170325)会引入严重的偏倚，导致错误的科学结论 [@problem_id:4955279]。

相比之下，**有序变量** 的类别具有明确的内在顺序，但类别之间的“距离”不一定相等。例如，肿瘤分期（I、II、III、IV）是有序的，因为 II 期比 I 期严重，但从 I 期到 II 期的生物学进展或风险变化不一定等同于从 II 期到 III 期的变化。对于有序变量，我们可以选择忽略其顺序，将其当作名义变量处理；或者，我们也可以利用其顺序信息。一种利用顺序的方法是将其编码为单个数值变量（例如，1, 2, 3, 4）。但这同样引入了一个很强的假设，即效应在模型的尺度上（例如，对数优势比尺度）是线性变化的。这是否合理需要根据具体的科学背景来判断 [@problem_id:4955279]。

### 分类编码的线性代数基础：可识别性

为了在[广义线性模型 (GLM)](@entry_id:749787) 中正确地表示一个具有 $k$ 个水平的分类变量，我们需要构建一个**设计矩阵** $\mathbf{X}$。模型的[线性预测](@entry_id:180569)器 $\eta$ 由此矩阵和系数向量 $\boldsymbol{\beta}$ 的[内积](@entry_id:750660)给出：$\eta = \mathbf{X}\boldsymbol{\beta}$。

一个直观的想法是为每个类别创建一个**[指示变量](@entry_id:266428) (indicator variable)**，这种方法称为**[独热编码](@entry_id:170007) (one-hot encoding)**。对于一个有三个水平（A、B、C）的因子，我们可以创建三个[指示变量](@entry_id:266428)列：$c_A, c_B, c_C$。如果一个观测属于类别 A，则 $c_A$ 对应行的值为 1，其他为 0。然而，当模型中包含**截距项**（即[设计矩阵](@entry_id:165826)中包含一列全为 1 的向量，记为 $c_0$）时，这种“完全[独热编码](@entry_id:170007)”会引发一个致命问题：**[多重共线性](@entry_id:141597) (multicollinearity)** [@problem_id:4955253]。

由于每个观测必然属于 A、B、C 中的一个，这三个指示变量列之和恰好等于截距列：
$$
c_A + c_B + c_C = \mathbf{1}_n = c_0
$$
这表明设计矩阵的列之间存在线性依赖关系，导致矩阵 $\mathbf{X}$ 不是列满秩的。从代数角度看，这意味着 Gram 矩阵 $\mathbf{X}^{\top}\mathbf{X}$ 是奇异的（不可逆），其零空间 (null space) 非空。例如，对于上述三水平因子，向量 $v = \begin{pmatrix} 1  -1  -1  -1 \end{pmatrix}^{\top}$ 就位于 $\mathbf{X}^{\top}\mathbf{X}$ 的[零空间](@entry_id:171336)中，因为 $\mathbf{X}v = c_0 - c_A - c_B - c_C = \mathbf{0}$。这种线性依赖性意味着模型参数 $\boldsymbol{\beta}$ 不是唯一可识别的，存在无限多组 $\boldsymbol{\beta}$ 值可以产生完全相同的预测结果。因此，为了保证模型参数的唯一性和可解释性，我们必须引入约束。最常见的方法是为 $k$ 个水平的因子只使用 $k-1$ 个编码列，这也被称为**对比编码 (contrast coding)**。

### 基础编码方案及其解释

两种最基础且广泛使用的编码方案是处理编码和效应编码。它们通过不同的方式实现 $k-1$ 编码，从而解决了可识别性问题，但其系数的解释也因此而异。

#### 处理编码（虚拟编码）

**处理编码 (treatment coding)**，也常被称为**虚拟编码 (dummy coding)**，是其中一种最直观的方案。其策略是选择一个类别作为**基准水平 (reference level)** 或[对照组](@entry_id:188599)，然后为其余的 $k-1$ 个类别分别创建一个[指示变量](@entry_id:266428) [@problem_id:4955328]。

以一个有三个治疗组（$L_0$ 为标准疗法， $L_1$ 和 $L_2$ 为新疗法）的研究为例，如果我们选择 $L_0$ 作为基准，线性预测器 $\eta_i$ 可以写为：
$$
\eta_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2}
$$
其中 $x_{i1} = \mathbf{1}\{L_i=L_1\}$，$x_{i2} = \mathbf{1}\{L_i=L_2\}$。

[设计矩阵](@entry_id:165826)的行结构如下：
- 对于 $L_0$ 组的观测：$(x_{i1}, x_{i2}) = (0, 0)$
- 对于 $L_1$ 组的观测：$(x_{i1}, x_{i2}) = (1, 0)$
- 对于 $L_2$ 组的观测：$(x_{i1}, x_{i2}) = (0, 1)$

系数的解释取决于模型的连结函数 $g(\cdot)$。

- **对于高斯线性模型 (identity link)**：$\mathbb{E}(y_i) = \eta_i$。
  - $L_0$ 组的均值：$\mathbb{E}(y \mid L_0) = \beta_0$。
  - $L_1$ 组的均值：$\mathbb{E}(y \mid L_1) = \beta_0 + \beta_1$。
  - $L_2$ 组的均值：$\mathbb{E}(y \mid L_2) = \beta_0 + \beta_2$。
  由此可见，截距项 $\beta_0$ 代表了**基准组的均值**。系数 $\beta_1$ 代表了 **$L_1$ 组与基准组的均值之差**（$\mathbb{E}(y \mid L_1) - \mathbb{E}(y \mid L_0)$），而 $\beta_2$ 则是 **$L_2$ 组与基准组的均值之差** [@problem_id:4955328]。

- **对于逻辑回归模型 (logit link)**：$\ln(p_i/(1-p_i)) = \eta_i$。
  - $L_0$ 组的对数优势 (log-odds)：$\ln(p_0/(1-p_0)) = \beta_0$。
  - $L_1$ 组的对数优势：$\ln(p_1/(1-p_1)) = \beta_0 + \beta_1$。
  - $L_2$ 组的对数优势：$\ln(p_2/(1-p_2)) = \beta_0 + \beta_2$。
  在这种情况下，截距项 $\beta_0$ 代表了**基准组的对数优势**。系数 $\beta_1$ 代表了 **$L_1$ 组与基准组的对数优势之差**，这正是**对数优势比 (log-odds ratio)**。因此，$\exp(\beta_1)$ 就是 $L_1$ 组相对于 $L_0$ 组的优势比 (odds ratio)。例如，在一项临床试验中，如果观察到 $L_0$ 组的缓解率为 $0.3$，$L_2$ 组的缓解率为 $0.6$，那么 $\beta_2$ 的[最大似然估计值](@entry_id:165819)就是这两组对数优势的差：$\hat{\beta}_2 = \ln(\frac{0.6}{1-0.6}) - \ln(\frac{0.3}{1-0.3}) = \ln(3.5) \approx 1.253$ [@problem_id:4955328]。

#### 效应编码（和为零编码）

**效应编码 (effect coding)**，也称为**和为零编码 (sum-to-zero coding)**，采用不同的约束来解决可识别性问题。它要求所有类别效应的总和为零 [@problem_id:4955311]。对于一个有 $k$ 个水平的因子，模型可以写为：
$$
Y_i = \mu + \beta_{G_i} + \varepsilon_i, \quad \text{约束为} \quad \sum_{j=1}^{k} \beta_j = 0
$$
这里，$\mu$ 是一个总截距，$\beta_j$ 是第 $j$ 个类别的效应。

在这种[参数化](@entry_id:265163)下，可以证明普通最小二乘 (OLS) 估计量具有非常清晰的解释。各组的均值拟合为 $\hat{\mu} + \hat{\beta}_j = \bar{Y}_j$，结合和为零约束 $\sum \hat{\beta}_j = 0$，我们可以解出：
$$
\hat{\mu} = \frac{1}{k} \sum_{j=1}^{k} \bar{Y}_j
$$
$$
\hat{\beta}_j = \bar{Y}_j - \hat{\mu}
$$
这意味着，在效应编码下：
- 截距项 $\mu$ 代表了所有类别均值的**无加权平均值 (unweighted grand mean)**。
- 系数 $\beta_j$ 代表了**第 $j$ 组的均值与这个无加权总均值之间的偏差**。

例如，假设有三个诊所，样本量为 $(n_1,n_2,n_3)=(20,30,50)$，观察到的生物标志物均值为 $(\bar{Y}_1,\bar{Y}_2,\bar{Y}_3)=(10,14,18)$。使用效应编码，总截距的估计值为 $\hat{\mu} = (10+14+18)/3 = 14$。各诊所的效应估计为 $\hat{\beta}_1 = 10 - 14 = -4$, $\hat{\beta}_2 = 14 - 14 = 0$, $\hat{\beta}_3 = 18 - 14 = 4$。值得注意的是，这里的 $\hat{\mu}$ (14) 与样本量加权的总均值 $\frac{20(10)+30(14)+50(18)}{100} = 15.2$ 是不同的。效应编码的比较基准是一个概念上的“平均诊所”，而不是由样本量决定的“平均患者”[@problem_id:4955311] [@problem_id:4955275]。

### 再[参数化](@entry_id:265163)原理与可重复性

处理编码和效应编码看似不同，但它们描述的是同一个底层模型，只是从不同的角度进行[参数化](@entry_id:265163)。它们之间可以通过一个可逆的[线性变换矩阵](@entry_id:186379) $\mathbf{A}$ 相互转换 [@problem_id:4955310]。如果一个模型的系数向量是 $\boldsymbol{\beta}$，另一个是 $\boldsymbol{\beta}'$，那么它们的关系是 $\boldsymbol{\beta}' = \mathbf{A}^{-1}\boldsymbol{\beta}$。

这一事实带来了两个至关重要的推论：

1.  **[模型拟合](@entry_id:265652)和总体检验的不变性**：由于这只是参数的重新表达，模型的整体[拟合优度](@entry_id:637026)（如似然值）、所有观测的拟合概率 $\hat{p}_i$ 以及对整个[分类变量](@entry_id:637195)是否显著的**综合检验 (omnibus test)**（例如，检验所有 $k-1$ 个系数是否同时为零的 Wald 检验或似然比检验）都是**不变的**。无论你使用哪种全秩编码方案，对“治疗组之间是否存在差异”这个总体问题的回答是相同的 [@problem_id:4955297]。

2.  **系数解释和个体检验的依赖性**：与总体检验不同，对**单个系数**的解释和检验（例如，检验 $\beta_j=0$）则完全**依赖于所选的编码方案**。在处理编码下检验 $\beta_1=0$ 是在问“$L_1$ 组是否与基准组有差异”，而在效应编码下检验 $\beta_1=0$ 是在问“$L_1$ 组是否与总体平均水平有差异”。这是两个不同的科学问题，因此它们的[检验统计量](@entry_id:167372)和 p 值通常也不同 [@problem_id:4955297]。

这一原理对科学研究的**[可重复性](@entry_id:194541)**至关重要。如果一篇论文报告了模型系数或特定类别的优势比，但没有明确说明所使用的编码方案（包括软件默认设置、基准水平等），那么其他研究者几乎不可能精确复现这些数值，即使他们拥有完全相同的数据。这是因为不同的统计软件（或同一软件的不同设置）可能默认使用不同的编码方案 [@problem_id:4955310]。

因此，为了确保研究结果的透明度和[可重复性](@entry_id:194541)，一份完整的模型文档必须为每个[分类变量](@entry_id:637195)提供以下信息：
- 从原始数据到模型中各水平的映射（包括任何类别的合并或重编码）。
- 各水平的明确排序（软件通常按字母或数字顺序处理）。
- 对缺失值和稀有类别的处理方式。
- 所使用的确切**对比矩阵** $\mathbf{C}$，或足以重建该矩阵的软件和版本及其对比度设置说明。
- 指定的基准水平（如果适用）。
- 当包含**交互项**时，还需说明交互项的编码是如何从主效应编码中构建的（通常是列的乘积）[@problem_id:4955310] [@problem_id:4955265]。

### 有序因子的编码方案

对于有序因子，我们可以利用其内在的顺序信息来提出更具针对性的科学问题。

一种简单的方法是将其视为单个数值变量，但这隐含了效应在模型尺度上呈线性趋势的强假设。一种更灵活、更强大的方法是使用**[正交多项式](@entry_id:146918)对比 (orthogonal polynomial contrasts)** [@problem_id:4955275]。这种方法将类别间的趋势分解为几个相互正交的组成部分：**线性 (linear)**、**二次 (quadratic)**、**三次 (cubic)** 等。

- **线性分量**检验效应是否随类别顺序呈单调增加或减少的趋势，这对于评估“剂量-反应”关系非常有用。
- **二次分量**检验是否存在 U 形或倒 U 形的趋势。
- 更高阶的分量则捕捉更复杂的非单调模式。

这些对比向量可以通过对中心化的类别得分的多项式基 $\{1, t, t^2, \dots\}$ 应用 Gram-Schmidt 正交化过程来构建，确保它们在离散[内积](@entry_id:750660)下是正交的 [@problem_id:4955284]。通过检验这些多项式对比的系数是否显著，研究者可以深入探究响应变量随有序因子变化的具体模式，而不仅仅是判断各类别之间是否存在差异。

### 高级主题与[病态问题](@entry_id:137067)

在处理复杂的医学数据时，标准编码方法可能会遇到挑战。

#### 高[基数](@entry_id:754020)因子与[过拟合](@entry_id:139093)

当一个分类变量包含非常多的水平时（例如，数百个不同的医院或医生），我们称之为**高基数 (high-cardinality)** 因子。在这种情况下，使用传统的 $k-1$ [虚拟变量](@entry_id:138900)编码会向模型中引入大量参数。这不仅会大大增加计算负担，还极易导致**过拟合**：模型在训练数据上表现完美，但在新数据上预测性能很差。由于许多水平可能只包含极少数观测，其[系数估计](@entry_id:175952)的方差会非常大，结果极不稳定 [@problem_id:4955263]。

#### 分离问题

在逻辑回归等模型中，如果一个或一组预测变量能够完美地将成功（$Y=1$）和失败（$Y=0$）的观测分开，就会发生**分离 (separation)** 现象 [@problem_id:4955265]。对于分类变量，一个常见的场景是某个稀有类别中的所有观测都具有相同的结局（例如，某个病房的所有患者都发生了感染）。

从几何上看，这意味着在预测变量空间中，存在一个[超平面](@entry_id:268044)可以将两类结局完全或准完全地分开。从[最大似然估计](@entry_id:142509) (MLE) 的角度看，模型会试图将这些“完美预测”的观测的概率推向 0 或 1。为了实现这一点，对应于该稀有类别的系数 $\beta_j$ 必须趋向于正无穷或负无穷。结果是，该系数的 MLE 不存在有限解，导致算法不收敛和估计结果发散 [@problem_id:4955265]。需要强调的是，分离是数据本身的几何属性，改变编码方案（如从处理编码变为效应编码）并不能解决这个问题，只会改变系数发散的方式 [@problem_id:4955265]。

#### 正则化与层级模型方法

解决高基数和分离问题的一种现代方法是**正则化 (regularization)**。正则化通过在[似然函数](@entry_id:141927)上增加一个惩罚项来约束系数的大小，从而在引入少量偏倚的代价下，显著降低模型的方差。

- **[组套索](@entry_id:170889) (Group Lasso)**：这种方法将属于同一个[分类变量](@entry_id:637195)的所有[虚拟变量](@entry_id:138900)系数作为一个“组”进行惩罚，要么将整个组的系数都保留在模型中，要么将它们全部缩减为零。这可以用于变量选择，剔除对模型无贡献的整个因子。
- **层级收缩 (Hierarchical Shrinkage)**：这种方法，通常在贝叶斯框架下通过**随机效应 (random effects)** 实现，对来自同一因子的不同水平的效应进行“[部分池化](@entry_id:165928) (partial pooling)”。它假设各水平的效应本身是从一个共同的分布（例如，$\mathcal{N}(0, \tau^2)$）中抽取的。对于数据量少的稀有类别，其效应估计会向[总体平均值](@entry_id:175446)“收缩”，从而“借用”来自其他类别的信息，得到更稳定、更可靠的估计。这种方法在处理高[基数](@entry_id:754020)因子和防止分离问题上尤其有效 [@problem_id:4955263]。

总之，对[分类预测变量](@entry_id:636655)的编码远非简单的技术操作，它是一个涉及统计理论、模型假设和科学问题核心的决策过程。理解不同编码方案的原理、解释及其局限性，是构建可靠、可解释和可重复的[统计模型](@entry_id:755400)的关键。