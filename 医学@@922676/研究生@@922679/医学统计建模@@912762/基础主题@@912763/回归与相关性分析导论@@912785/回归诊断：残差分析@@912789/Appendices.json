{"hands_on_practices": [{"introduction": "在回归分析中，检验模型假设和识别异常观测值是至关重要的一步。本练习将指导您计算标准化残差，这是诊断线性模型拟合优度的基本工具。与原始残差不同，标准化残差经过尺度变换，近似服从标准正态分布，这使得我们可以使用如 $|r_i| > 2$ 这样的通用阈值来客观地识别潜在的离群点 ([@problem_id:4982808])。", "problem": "考虑一个临床流行病学中的队列研究，其中生物标志物C反应蛋白（CRP）以毫克/升为单位进行测量，然后进行对数转换以稳定方差。记对数转换后的CRP为 $y_i$，年龄（单位：年）为 $x_i$，吸烟状态指示符为 $z_i$，其中 $z_i \\in \\{0,1\\}$，$z_i=1$ 表示当前吸烟者，$z_i=0$ 表示非吸烟者。我们考虑一个适用于 $i=1,\\dots,n$ 的线性模型，定义为 $y_i = \\beta_0 + \\beta_1 x_i + \\beta_2 z_i + \\varepsilon_i$，其中误差 $\\varepsilon_i$ 假定为独立同分布，服从均值为 $0$、方差为 $\\sigma^2$ 的高斯分布。使用普通最小二乘法（OLS），从数据中获得拟合值和残差，帽子矩阵的对角元素 $h_{ii}$ 用以量化杠杆值。标准化残差 $r_i$ 用于回归诊断，以评估模型的充分性和离群值，而像 $|r_i|2$ 这样的数值阈值通常根据标准正态参考下的近似尾部概率来解释。\n\n根据高斯-马尔可夫假设的基本原理和OLS估计量的性质，实现一个算法，该算法能够：\n- 使用包含截距、年龄 $x_i$ 和吸烟指示符 $z_i$ 列的设计矩阵 $X$ 拟合线性模型，以获得 $\\hat{\\beta}$。\n- 计算残差 $e_i$ 和帽子矩阵 $H$ 以获得 $h_{ii}$。\n- 使用 $n-p$ 自由度，通过残差均方 $s^2$ 估计 $\\sigma^2$，其中 $p$ 是包括截距在内的回归系数数量（此处 $p=3$）。\n- 计算所有观测值的标准化残差 $r_i$。\n- 通过报告在标准正态参考下的近似双侧尾部概率 $2\\{1 - \\Phi(2)\\}$ 来解释阈值 $|r_i|2$，其中 $\\Phi(\\cdot)$ 是标准正态累积分布函数。此外，报告每个残差的近似双侧尾部概率 $p_i = 2\\Phi(-|r_i|)$。\n\n所有年龄 $x_i$ 必须以年为单位处理。由于 $y_i$ 是对数，输出是无单位的。\n\n您的程序必须将上述方法应用于以下三个数据集的测试套件，每个数据集指定为三元组 $(\\{x_i\\},\\{z_i\\},\\{y_i\\})$：\n\n- 测试用例1（典型变异性，$n=10$, $p=3$）：\n  - 年龄 $\\{x_i\\}$: $[22,34,47,51,36,63,41,55,29,68]$ (年)\n  - 吸烟指示符 $\\{z_i\\}$: $[0,1,0,1,0,1,0,1,0,1]$\n  - 对数CRP $\\{y_i\\}$: $[0.79,1.35,1.24,1.59,1.15,1.85,1.26,1.80,0.96,1.97]$\n\n- 测试用例2（一个高杠杆离群值，$n=8$, $p=3$）：\n  - 年龄 $\\{x_i\\}$: $[25,40,45,50,55,60,65,95]$ (年)\n  - 吸烟指示符 $\\{z_i\\}$: $[0,0,1,0,1,0,1,1]$\n  - 对数CRP $\\{y_i\\}$: $[0.93,1.16,1.61,1.41,1.70,1.62,1.95,0.80]$\n\n- 测试用例3（接近边界的小样本，$n=4$, $p=3$）：\n  - 年龄 $\\{x_i\\}$: $[30,50,70,60]$ (年)\n  - 吸烟指示符 $\\{z_i\\}$: $[0,1,0,1]$\n  - 对数CRP $\\{y_i\\}$: $[1.01,1.64,1.78,1.86]$\n\n对于每个测试用例，生成：\n- 标准化残差列表 $[r_1,\\dots,r_n]$，四舍五入到6位小数。\n- 近似双侧尾部概率列表 $[p_1,\\dots,p_n]$，其中 $p_i = 2\\Phi(-|r_i|)$，四舍五入到6位小数。\n- 残差满足 $|r_i|2$ 的整数计数 $c$。\n- 浮点数 $\\pi_2 = 2\\{1 - \\Phi(2)\\}$，四舍五入到6位小数。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个元素对应一个测试用例，其本身是按上述顺序排列的列表。例如，总体格式为 $[[\\text{用例1\\_残差},\\text{用例1\\_p值},c_1,\\pi_2],[\\text{用例2\\_残差},\\text{用例2\\_p值},c_2,\\pi_2],[\\text{用例3\\_残差},\\text{用例3\\_p值},c_3,\\pi_2]]$。所有概率必须表示为小数，而不是百分比符号。", "solution": "用户提供了一个关于统计回归诊断领域的问题，该问题要求实现一个算法来计算和解释多元线性回归模型的标准化残差。问题陈述已经过严格验证，并被确定为有效。\n\n### 验证结论：\n该问题是**有效的**。\n- **科学依据充分**：该问题基于线性模型、普通最小二乘法（OLS）估计和标准回归诊断的经典理论。所有概念，包括高斯-马尔可夫模型、帽子矩阵、杠杆值和标准化残差，都是统计学的基础。\n- **定义明确**：问题定义清晰，所有必要的数据和数学公式要么已提供，要么是该领域的标准。对于所提供的数据集，OLS解存在且唯一，因为设计矩阵具有满列秩（$np$ 且不存在完全共线性）。\n- **客观性**：问题使用精确无歧义的数学语言陈述，没有主观论断。\n- **完整且一致**：提供了所有三个测试用例所需的数据，并明确概述了算法的步骤。方差估计量 $s^2$ 及其自由度的定义与标准OLS理论一致。标准化残差的定义默认为标准定义 $r_i = e_i / (s \\sqrt{1-h_{ii}})$，这是恰当的。\n\n该问题是已建立的统计方法的直接应用，并且已完全指定，从而可以得到唯一且可验证的解。\n\n### 解题推导\n解决方案将遵循问题陈述中概述的算法步骤来实现，这些步骤基于普通最小二乘法（OLS）回归的原理。\n\n对于每个包含 $n$ 个观测值 $(y_i, x_i, z_i)$ 的数据集，我们将模型定义为：\n$y_i = \\beta_0 + \\beta_1 x_i + \\beta_2 z_i + \\varepsilon_i$，其中 $\\varepsilon_i \\sim \\text{i.i.d. } N(0, \\sigma^2)$。\n\n这可以用矩阵形式表示为 $y = X\\beta + \\varepsilon$，其中：\n- $y$ 是 $n \\times 1$ 的响应向量 $\\{y_i\\}$。\n- $X$ 是 $n \\times p$ 的设计矩阵，其中 $p=3$。$X$ 的列分别是1向量（对应截距 $\\beta_0$）、年龄向量 $\\{x_i\\}$ 和吸烟指示符向量 $\\{z_i\\}$。\n- $\\beta = (\\beta_0, \\beta_1, \\beta_2)^T$ 是系数向量。\n- $\\varepsilon$ 是误差项向量。\n\n算法流程如下：\n\n**1. $\\beta$ 的 OLS 估计**：\nOLS估计量 $\\hat{\\beta}$ 最小化残差平方和 $RSS = \\sum e_i^2 = (y - X\\beta)^T(y - X\\beta)$。解由正规方程给出：\n$$\n\\hat{\\beta} = (X^T X)^{-1} X^T y\n$$\n\n**2. 计算残差和帽子矩阵**：\n- 拟合值计算为 $\\hat{y} = X\\hat{\\beta}$。\n- 原始残差是观测值与拟合值之差：$e = y - \\hat{y}$。\n- 帽子矩阵 $H$ 将观测值 $y$ 投影到由 $X$ 的列张成的空间上以产生拟合值：$\\hat{y} = Hy$。它定义为：\n$$\nH = X(X^T X)^{-1} X^T\n$$\n- 帽子矩阵的对角元素 $h_{ii}$ 是每个观测值的杠杆分数。它们满足 $0 \\le h_{ii} \\le 1$ 和 $\\sum_{i=1}^n h_{ii} = p$。\n\n**3. 误差方差 $\\sigma^2$ 的估计**：\n未知误差方差 $\\sigma^2$ 通过残差均方 $s^2$ 来估计：\n$$\ns^2 = \\frac{RSS}{n-p} = \\frac{e^T e}{n-p}\n$$\n其中 $n-p$ 是残差自由度。误差标准差的估计量是 $s = \\sqrt{s^2}$。\n\n**4. 计算标准化残差**：\n第 $i$ 个原始残差 $e_i$ 的方差是 $\\text{Var}(e_i) = \\sigma^2(1-h_{ii})$。标准化残差 $r_i$ 是原始残差除以其估计的标准差：\n$$\nr_i = \\frac{e_i}{s \\sqrt{1 - h_{ii}}}\n$$\n在模型假设下，每个 $r_i$ 的均值约为 $0$，方差约为 $1$。对于大的 $n$，它们的分布可以很好地用标准正态分布 $N(0, 1)$ 来近似。\n\n**5. 概率计算**：\n- 阈值 $|r_i| > 2$ 的参考概率是在标准正态近似下计算的：\n$$\n\\pi_2 = P(|Z| > 2) = 2 \\cdot P(Z  -2) = 2 \\Phi(-2)\n$$\n其中 $Z \\sim N(0,1)$ 并且 $\\Phi(\\cdot)$ 是标准正态累积分布函数（CDF）。\n- 对于每个标准化残差 $r_i$，相应的近似双侧尾部概率是：\n$$\np_i = P(|Z| > |r_i|) = 2 \\Phi(-|r_i|)\n$$\n标准正态CDF是利用其与 `scipy.special` 中可用的误差函数 $\\text{erf}(x)$ 的关系来计算的：\n$$\n\\Phi(z) = \\frac{1}{2} \\left(1 + \\text{erf}\\left(\\frac{z}{\\sqrt{2}}\\right)\\right)\n$$\n这导出了双侧尾部概率的表达式：\n$$\np_i = 2(1 - \\Phi(|r_i|)) = 2\\left(1 - \\frac{1}{2}\\left(1 + \\text{erf}\\left(\\frac{|r_i|}{\\sqrt{2}}\\right)\\right)\\right) = 1 - \\text{erf}\\left(\\frac{|r_i|}{\\sqrt{2}}\\right)\n$$\n一个类似的公式对 $\\pi_2$ 也成立。实现将使用这种基于 `erf` 的计算。\n\n最后一步是计算 $|r_i| > 2$ 的残差数量 $c$，并将所有结果组合成指定的输出格式。这个完整的过程将应用于三个测试用例中的每一个。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import erf\n\ndef solve():\n    \"\"\"\n    Main function to process all test cases and print the final result.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1 (typical variability, n=10, p=3)\n        (\n            [22, 34, 47, 51, 36, 63, 41, 55, 29, 68],  # Ages {x_i}\n            [0, 1, 0, 1, 0, 1, 0, 1, 0, 1],          # Smoking indicators {z_i}\n            [0.79, 1.35, 1.24, 1.59, 1.15, 1.85, 1.26, 1.80, 0.96, 1.97] # Log-CRP {y_i}\n        ),\n        # Test case 2 (one high-leverage outlier, n=8, p=3)\n        (\n            [25, 40, 45, 50, 55, 60, 65, 95],         # Ages {x_i}\n            [0, 0, 1, 0, 1, 0, 1, 1],                 # Smoking indicators {z_i}\n            [0.93, 1.16, 1.61, 1.41, 1.70, 1.62, 1.95, 0.80] # Log-CRP {y_i}\n        ),\n        # Test case 3 (near-boundary small sample, n=4, p=3)\n        (\n            [30, 50, 70, 60],                         # Ages {x_i}\n            [0, 1, 0, 1],                             # Smoking indicators {z_i}\n            [1.01, 1.64, 1.78, 1.86]                  # Log-CRP {y_i}\n        )\n    ]\n\n    all_results = []\n    for case_data in test_cases:\n        result = process_case(case_data)\n        all_results.append(result)\n\n    # Format the final output string exactly as specified.\n    # The str() of a list automatically includes spaces, e.g., '[1, 2]'.\n    # To get a compact representation, we can build the string manually.\n    result_strings = []\n    for res in all_results:\n        r_list_str = f\"[{','.join(map(str, res[0]))}]\"\n        p_list_str = f\"[{','.join(map(str, res[1]))}]\"\n        c_str = str(res[2])\n        pi2_str = str(res[3])\n        result_strings.append(f\"[{r_list_str},{p_list_str},{c_str},{pi2_str}]\")\n    \n    # The problem example implies that str(list) is fine. Let's use the simpler approach.\n    print(str(all_results).replace(\" \", \"\"))\n\n\ndef process_case(case_data):\n    \"\"\"\n    Implements OLS regression and diagnostics for a single dataset.\n\n    Args:\n        case_data (tuple): A tuple containing lists for ages, smoking indicators,\n                           and log-CRP values.\n\n    Returns:\n        list: A list containing [standardized_residuals, tail_probabilities, count, pi_2].\n    \"\"\"\n    x_i, z_i, y_i = case_data\n    \n    # Convert input lists to numpy arrays for vector/matrix operations.\n    x_vec = np.array(x_i)\n    z_vec = np.array(z_i)\n    y_vec = np.array(y_i)\n    \n    n = len(y_vec)  # Number of observations\n    p = 3           # Number of parameters (beta_0, beta_1, beta_2)\n    \n    # Construct the n x p design matrix X.\n    X = np.ones((n, p))\n    X[:, 1] = x_vec\n    X[:, 2] = z_vec\n    \n    # Step 1: Fit the linear model using OLS to get beta_hat.\n    # beta_hat = (X'X)^-1 * X'y\n    XTX = X.T @ X\n    XTX_inv = np.linalg.inv(XTX)\n    XTY = X.T @ y_vec\n    beta_hat = XTX_inv @ XTY\n    \n    # Step 2: Compute residuals and hat matrix.\n    # Fitted values: y_hat = X * beta_hat\n    y_hat = X @ beta_hat\n    # Raw residuals: e = y - y_hat\n    residuals = y_vec - y_hat\n    # Hat matrix: H = X * (X'X)^-1 * X'\n    hat_matrix = X @ XTX_inv @ X.T\n    # Leverage values (diagonal of H): h_ii\n    leverages = np.diag(hat_matrix)\n    \n    # Step 3: Estimate error variance sigma^2.\n    # Residual Sum of Squares (RSS)\n    rss = residuals.T @ residuals\n    # Degrees of freedom for error\n    df = n - p\n    # Residual Mean Square (s^2)\n    s_squared = rss / df\n    # Residual standard error (s)\n    s = np.sqrt(s_squared)\n    \n    # Step 4: Compute standardized residuals.\n    # r_i = e_i / (s * sqrt(1 - h_ii))\n    denom = s * np.sqrt(1 - leverages)\n    # Avoid division by zero in case of h_ii=1 (not expected here)\n    # Adding a small epsilon would be robust, but not necessary for these test cases.\n    standardized_residuals = residuals / denom\n    \n    # Step 5  6: Compute tail probabilities and count.\n    # The two-sided tail probability is P(|Z|  |x|) = 2 * (1 - Phi(|x|))\n    # which simplifies to 1 - erf(|x|/sqrt(2)).\n    \n    # For the threshold |r_i|  2\n    pi_2 = 1.0 - erf(2.0 / np.sqrt(2.0))\n    \n    # For each standardized residual\n    tail_probabilities = 1.0 - erf(np.abs(standardized_residuals) / np.sqrt(2.0))\n    \n    # Count of residuals with absolute value greater than 2.\n    count_gt_2 = np.sum(np.abs(standardized_residuals)  2)\n\n    # Prepare the output lists and values, rounded to 6 decimal places.\n    r_list = np.round(standardized_residuals, 6).tolist()\n    p_vals_list = np.round(tail_probabilities, 6).tolist()\n    \n    return [r_list, p_vals_list, int(count_gt_2), round(pi_2, 6)]\n\n# Execute the solver\nsolve()\n```", "id": "4982808"}, {"introduction": "除了分析残差的大小，理解每个数据点对回归模型的影响力也同样重要。本练习聚焦于计算杠杆值，它衡量了单个观测在其预测变量空间中的极端程度。高杠杆点不一定是离群点，但它们有潜力对回归线的拟合产生巨大影响，因此识别它们是进行全面残差诊断的关键一环 ([@problem_id:4982819])。", "problem": "您正在研究一个儿科生长回归问题，其中线性模型假设遵循普通最小二乘框架：响应向量 $\\mathbf{y} \\in \\mathbb{R}^{n}$ 满足 $\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}$，其中 $\\boldsymbol{\\varepsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma^{2}\\mathbf{I}_{n})$，$\\mathbf{X} \\in \\mathbb{R}^{n \\times p}$ 是具有满列秩 $p$ 的设计矩阵。任意 $\\mathbf{y}$ 到 $\\mathbf{X}$ 列空间上的普通最小二乘投影由一个唯一的对称幂等矩阵确定，该矩阵的对角线元素即为杠杆值 $h_{ii}$。在医学研究的回归诊断中，一个常见的启发式方法是使用阈值 $h_{ii}  2p/n$ 来标记具有异常高杠杆值的观测值。您的任务是计算杠杆值，并为几个与儿科生长模型相关的设计矩阵，识别出杠杆值超过此阈值的观测值的索引。\n\n请仅使用线性模型和欧几里得空间中投影的定义及公认事实，实现一个程序，对于每个给定的设计矩阵 $\\mathbf{X}$：\n- 计算杠杆值 $\\{h_{ii}\\}_{i=1}^{n}$，即在欧几里得内積下，到 $\\mathbf{X}$ 列空间上的投影矩阵的对角线元素。\n- 使用 $\\mathbf{X}$ 的列数 $p$ 和行数 $n$ 计算阈值 $\\tau = 2p/n$。\n- 返回满足 $h_{ii} > \\tau$ 的从零开始的行索引 $i \\in \\{0,1,\\dots,n-1\\}$ 的列表。\n\n测试套件。请使用以下四个测试用例。在所有用例中，第一列都包含一个全为1的截距列，并将 $\\ln(\\cdot)$ 解释为自然对数。\n\n- 测试用例1（儿科年龄和对数体重，包含一个极端青少年样本的中等样本）：设 $n = 10$ 且 $p = 3$。通过列堆叠构造 $\\mathbf{X}_{1}$：\n  - 一个长度为10的全1截距列，\n  - 年龄（岁）：$[1,2,3,4,5,6,7,8,9,18]$，\n  - 体重（千克）的自然对数 $\\ln(\\text{weight in kilograms})$，其中体重为 $[10,12,14,16,20,25,30,35,40,75]$。\n  因此 $\\mathbf{X}_{1} \\in \\mathbb{R}^{10 \\times 3}$。\n\n- 测试用例2（仅截距模型，边界行为）：设 $n = 5$ 且 $p = 1$。构造 $\\mathbf{X}_{2}$ 为一个长度为5的全1列向量，此时所有杠杆值相等，阈值为 $\\tau = 2 \\cdot 1 / 5 = 0.4$。\n\n- 测试用例3（预测变量相对较多的小样本，阈值超过1）：设 $n = 6$ 且 $p = 4$。通过列堆叠构造 $\\mathbf{X}_{3}$：\n  - 一个长度为6的全1截距列，\n  - 一个预测变量向量 $[1,3,5,7,9,11]$，\n  - 一个预测变量向量 $[-1.5,-0.5,0.0,0.5,1.0,2.5]$，\n  - 一个预测变量向量 $[3.0,3.2,2.8,3.5,3.0,4.2]$。\n\n- 测试用例4（含极端协变量的简单线性回归）：设 $n = 8$ 且 $p = 2$。通过列堆叠构造 $\\mathbf{X}_{4}$：\n  - 一个长度为8的全1截距列，\n  - 一个预测变量向量 $[-3,-2,-1,0,1,2,3,6]$。\n\n输出规范。您的程序应生成单行输出，其中按顺序包含四个用例的标记索引列表。格式为一个由方括号括起来的逗号分隔列表，其中每个元素是对应测试用例的、由方括号括起来的、逗号分隔的从零开始的索引列表。例如，一个包含四个用例的有效输出应类似于 `[[i_0], [i_1], [i_2], [i_3]]`，其中每个 `[i_k]` 表示一个整数列表（可能为空）。实际的数字索引必须由您的计算得出。\n\n重要说明：\n- 仅使用欧几里得空间中投影矩阵的数学定义，将到 $\\mathbf{X}$ 列空间上的投影矩阵的对角线元素作为杠杆值进行计算。除了线性代数事实和普通最小二乘法的标准属性外，不要假设或使用任何未经证明的捷径。\n- 如果 $\\tau = 2p/n  1$，则没有杠杆值能够超过 $\\tau$，因为对于欧几里得投影有 $0 \\le h_{ii} \\le 1$，所以在这种情况下，标记集合应为空。\n- 所有数值结果都是无量纲的；不涉及物理单位或角度。", "solution": "该问题是有效的，因为它科学地基于线性回归分析的原理，问题陈述清晰且提供了所有必要信息，并以客观的数学语言表述。它代表了回归诊断中的一个标准计算任务。\n\n按照要求，解答过程遵循第一性原理。在普通最小二乘（OLS）线性模型中，我们有方程 $\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}$，其中 $\\mathbf{y} \\in \\mathbb{R}^{n}$ 是观测向量，$\\mathbf{X} \\in \\mathbb{R}^{n \\times p}$ 是秩为 $p$ 的设计矩阵，$\\boldsymbol{\\beta} \\in \\mathbb{R}^{p}$ 是模型系数向量，$\\boldsymbol{\\varepsilon} \\in \\mathbb{R}^{n}$ 是误差向量。\n\n$\\boldsymbol{\\beta}$ 的OLS估计量为 $\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}$。拟合值向量 $\\hat{\\mathbf{y}}$ 是通过将 $\\mathbf{y}$ 投影到 $\\mathbf{X}$ 的列空间（记为 $\\text{Col}(\\mathbf{X})$）上得到的。这个投影由一个投影矩阵 $\\mathbf{H}$ 完成：\n$$\n\\hat{\\mathbf{y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}} = \\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y} = \\mathbf{H}\\mathbf{y}\n$$\n矩阵 $\\mathbf{H} = \\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T$ 被称为“帽子矩阵”，因为它为 $\\mathbf{y}$“戴上了帽子”。根据其构造，$\\mathbf{H}$ 是将 $\\mathbb{R}^{n}$ 中任意向量投影到 $\\text{Col}(\\mathbf{X})$ 上的唯一的对称（$\\mathbf{H}^T = \\mathbf{H}$）且幂等（$\\mathbf{H}^2 = \\mathbf{H}$）的矩阵。\n\n第 $i$ 个观测值的杠杆值 $h_{ii}$ 是帽子矩阵 $\\mathbf{H}$ 的第 $i$ 个对角元素。它可以表示为 $h_{ii} = \\mathbf{e}_i^T \\mathbf{H} \\mathbf{e}_i$，其中 $\\mathbf{e}_i$ 是第 $i$ 个标准基向量。杠杆值 $h_{ii}$量化了观测值 $y_i$ 对其自身拟合值 $\\hat{y}_i$ 的影响，这可以从第 $i$ 个拟合值的表达式中看出：\n$$\n\\hat{y}_i = \\sum_{j=1}^{n} H_{ij}y_j = H_{ii}y_i + \\sum_{j \\neq i} H_{ij}y_j = h_{ii}y_i + \\sum_{j \\neq i} H_{ij}y_j\n$$\n一个较大的 $h_{ii}$ 值意味着第 $i$ 个观测值对其自身的预测有重大影响，这表明该点在预测变量空间中可能是一个有影响力的点和异常值。\n\n杠杆值具有 $0 \\le h_{ii} \\le 1$ 的性质，并且它们的总和等于帽子矩阵的迹，也就是列空间的秩：\n$$\n\\sum_{i=1}^{n} h_{ii} = \\text{tr}(\\mathbf{H}) = \\text{tr}(\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T) = \\text{tr}((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{X}) = \\text{tr}(\\mathbf{I}_p) = p\n$$\n因此，平均杠杆值为 $p/n$。一个常见的启发式方法是，如果观测值的杠杆值 $h_{ii}$ 是平均杠杆值的两倍以上，则将其标记为高杠杆值。这就给出了阈值 $\\tau$：\n$$\n\\tau = \\frac{2p}{n}\n$$\n满足 $h_{ii} > \\tau$ 的观测值被识别为高杠杆点。请注意，如果 $p/n  1/2$，那么 $\\tau  1$。由于 $h_{ii} \\le 1$ 恒成立，所以没有点可以超过这样的阈值。\n\n每个测试用例的计算过程如下：\n$1$. 构造指定的设计矩阵 $\\mathbf{X} \\in \\mathbb{R}^{n \\times p}$。\n$2$. 确定 $\\mathbf{X}$ 的维度 $n$（行数）和 $p$（列数）。\n$3$. 计算高杠杆阈值 $\\tau = 2p/n$。\n$4$. 如果 $\\tau  1$，则标记的索引集为空。否则，继续。\n$5$. 计算矩阵乘积 $\\mathbf{X}^T\\mathbf{X}$。\n$6$. 计算逆矩阵 $(\\mathbf{X}^T\\mathbf{X})^{-1}$。\n$7$. 杠杆值 $h_{ii}$ 是 $\\mathbf{H} = \\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T$ 的对角元素。一种只计算对角元素的有效方法是为 $\\mathbf{X}$ 的每个行向量 $\\mathbf{x}_i^T$ 计算 $\\mathbf{x}_i^T (\\mathbf{X}^T\\mathbf{X})^{-1} \\mathbf{x}_i$。向量化计算对应于 `sum((X @ inv(X.T @ X)) * X, axis=1)`。\n$8$. 识别所有满足 $h_{ii} > \\tau$ 的从零开始的索引 $i \\in \\{0, 1, \\dots, n-1\\}$。\n$9$. 将这些索引收集到一个列表中，用于最终输出。\n\n此过程应用于四个测试用例中的每一个。\n\n- **测试用例1**：$n = 10, p = 3$。矩阵 $\\mathbf{X}_1$ 由一个截距、一个年龄向量和一个对数转换后的体重向量构成。阈值为 $\\tau = 2(3)/10 = 0.6$。第十个观测值（索引为9）对应年龄18岁，是预测变量空间中的一个异常值，预计具有高杠杆值。\n- **测试用例2**：$n = 5, p = 1$。矩阵 $\\mathbf{X}_2$ 仅包含一个截距。阈值为 $\\tau = 2(1)/5 = 0.4$。对于仅截距模型，所有杠杆值都相等，$h_{ii} = 1/n = 1/5 = 0.2$。由于 $0.2 \\ngtr 0.4$，没有点被标记。\n- **测试用例3**：$n = 6, p = 4$。阈值为 $\\tau = 2(4)/6 \\approx 1.333$。由于 $\\tau  1$ 且所有 $h_{ii} \\le 1$，任何杠杆值都不可能超过该阈值。因此，得到的索引列表必须为空。\n- **测试用例4**：$n = 8, p = 2$。矩阵 $\\mathbf{X}_4$ 对应于一个简单线性回归。阈值为 $\\tau = 2(2)/8 = 0.5$。最后一个观测值（索引为7）的预测变量值为6，远大于其他值。预计该点具有高杠杆值。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of identifying high-leverage points for four different\n    design matrices from pediatric growth models.\n    \"\"\"\n\n    def compute_high_leverage_indices(X: np.ndarray) - list[int]:\n        \"\"\"\n        Computes leverage values for a design matrix X and returns the indices\n        of observations with leverage exceeding the 2p/n threshold.\n\n        Args:\n            X: The design matrix (n x p).\n\n        Returns:\n            A list of zero-based indices of high-leverage points.\n        \"\"\"\n        if X.ndim == 1:\n            X = X.reshape(-1, 1)\n\n        n, p = X.shape\n\n        # Check if X has full column rank\n        if np.linalg.matrix_rank(X)  p:\n            # This case is not expected based on the problem description\n            # but is good practice to handle.\n            return []\n\n        threshold = 2 * p / n\n\n        # If threshold is  1, no leverage value can exceed it since 0 = h_ii = 1.\n        if threshold >= 1.0:\n            return []\n\n        # Calculate leverage values.\n        # H = X @ inv(X.T @ X) @ X.T\n        # h_ii = x_i^T @ inv(X.T @ X) @ x_i\n        # A more efficient vectorized computation:\n        try:\n            XTX = X.T @ X\n            XTX_inv = np.linalg.inv(XTX)\n            \n            # This computes diag(X @ XTX_inv @ X.T) without forming the n x n matrix H\n            leverage_values = np.sum((X @ XTX_inv) * X, axis=1)\n\n        except np.linalg.LinAlgError:\n            # This can happen if X.T @ X is singular, i.e., X is not full rank.\n            return []\n\n        # Find indices where leverage exceeds the threshold.\n        high_leverage_indices = np.where(leverage_values > threshold)[0]\n\n        return high_leverage_indices.tolist()\n\n    # --- Define Test Cases ---\n\n    # Test Case 1: n=10, p=3\n    age_1 = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 18])\n    weight_1 = np.array([10, 12, 14, 16, 20, 25, 30, 35, 40, 75])\n    X1 = np.c_[np.ones(10), age_1, np.log(weight_1)]\n\n    # Test Case 2: n=5, p=1\n    X2 = np.ones((5, 1))\n\n    # Test Case 3: n=6, p=4\n    p2_3 = np.array([1, 3, 5, 7, 9, 11])\n    p3_3 = np.array([-1.5, -0.5, 0.0, 0.5, 1.0, 2.5])\n    p4_3 = np.array([3.0, 3.2, 2.8, 3.5, 3.0, 4.2])\n    X3 = np.c_[np.ones(6), p2_3, p3_3, p4_3]\n    \n    # Test Case 4: n=8, p=2\n    p2_4 = np.array([-3, -2, -1, 0, 1, 2, 3, 6])\n    X4 = np.c_[np.ones(8), p2_4]\n    \n    test_matrices = [X1, X2, X3, X4]\n    \n    results = []\n    for X in test_matrices:\n        indices = compute_high_leverage_indices(X)\n        results.append(indices)\n\n    # Format the output as specified: [[idx1,...],[idx2,...],...]\n    # Using str() on a list automatically creates the bracketed format.\n    output_str = f\"[{','.join(map(str, results))}]\".replace(\" \", \"\")\n    \n    print(output_str)\n\nsolve()\n```", "id": "4982819"}, {"introduction": "许多医学研究涉及非正态分布的结局变量，例如二元结局（存活/死亡），此时线性回归不再适用。本练习将残差分析的概念扩展到广义线性模型（GLM），特别是逻辑回归。您将从第一性原理推导并计算离差残差（deviance residuals），它在GLM中的作用类似于标准化残差在线性模型中的作用，为评估复杂模型的拟合情况提供了有力工具 ([@problem_id:4982785])。", "problem": "您正在使用逻辑回归对脓毒症的院内死亡率进行建模，这是一个二元结局，预测变量为年龄和序贯器官衰竭评估 (SOFA) 评分。设每个观测值的索引为 $i \\in \\{1,\\dots,n\\}$，其二元结局为 $y_i \\in \\{0,1\\}$。该回归模型假设 $Y_i \\mid \\mathbf{x}_i \\sim \\mathrm{Bernoulli}(\\pi_i)$，其中 $\\pi_i = \\mathbb{P}(Y_i = 1 \\mid \\mathbf{x}_i)$，典范链接函数为 $\\mathrm{logit}(\\pi_i) = \\eta_i = \\mathbf{x}_i^\\top \\boldsymbol{\\beta}$，其中 $\\mathbf{x}_i = (1, \\mathrm{age}_i, \\mathrm{sofa}_i)^\\top$，$\\boldsymbol{\\beta} = (\\beta_0,\\beta_1,\\beta_2)^\\top$。\n\n仅从以下基本要素出发：\n- 单个观测值的伯努利似然：$L_i(\\pi_i \\mid y_i) = \\pi_i^{y_i} (1-\\pi_i)^{1-y_i}$ 及其对数似然 $\\ell_i(\\pi_i \\mid y_i) = y_i \\log(\\pi_i) + (1-y_i)\\log(1-\\pi_i)$。\n- 广义线性模型 (GLM) 的偏差 (deviance) 定义为饱和模型（能完美拟合每个 $y_i$ 的模型）的对数似然与拟合模型的对数似然之差的两倍，并对所有观测值求和。\n\n您的任务是：\n1) 从第一性原理出发，推导逻辑回归中单个偏差残差 $r_i$ 的显式闭式表达式，该表达式应表示为每个观测值的偏差贡献的带符号平方根，并用 $y_i$ 和 $\\hat{\\pi}_i$ 表示，其中 $\\hat{\\pi}_i = \\mathrm{logistic}(\\hat{\\eta}_i)$ 且 $\\hat{\\eta}_i = \\mathbf{x}_i^\\top \\hat{\\boldsymbol{\\beta}}$。\n2) 然后，对于一个固定且已知的系数向量 $\\hat{\\boldsymbol{\\beta}} = (\\hat{\\beta}_0,\\hat{\\beta}_1,\\hat{\\beta}_2) = (-7.0, 0.04, 0.35)$，计算下面测试套件中每个观测值的偏差残差。年龄以年为单位，SOFA 为无单位分数。残差是无量纲的；报告的残差应四舍五入到六位小数。\n\n实现说明和数值安全要求：\n- 使用 logistic 函数 $\\mathrm{logistic}(z) = \\dfrac{1}{1+\\exp(-z)}$ 从 $\\hat{\\eta}_i$ 计算 $\\hat{\\pi}_i$。\n- 确保数值稳定性，避免对 $0$ 取对数。对于二元 $y_i \\in \\{0,1\\}$，您可以使用任何数学上等价的稳定形式来避免出现未定义项，同时保留偏差残差的精确定义。\n- 对于每个测试用例，按观测值列出的顺序计算并返回残差列表，并将每个残差四舍五入到六位小数。\n\n测试套件：\n- 测试用例 $1$（一般混合风险队列，$5$ 个观测值）：\n  - 观测值 $1$：年龄 $65$ 岁，SOFA $6$，结局 $y=1$。\n  - 观测值 $2$：年龄 $72$ 岁，SOFA $10$，结局 $y=1$。\n  - 观测值 $3$：年龄 $50$ 岁，SOFA $4$，结局 $y=0$。\n  - 观测值 $4$：年龄 $34$ 岁，SOFA $2$，结局 $y=0$。\n  - 观测值 $5$：年龄 $80$ 岁，SOFA $12$，结局 $y=1$。\n- 测试用例 $2$（用于探测稳定性的近边界概率，$5$ 个观测值）：\n  - 观测值 $1$：年龄 $22$ 岁，SOFA $0$，结局 $y=1$。\n  - 观测值 $2$：年龄 $90$ 岁，SOFA $18$，结局 $y=0$。\n  - 观测值 $3$：年龄 $85$ 岁，SOFA $20$，结局 $y=1$。\n  - 观测值 $4$：年龄 $25$ 岁，SOFA $1$，结局 $y=0$。\n  - 观测值 $5$：年龄 $78$ 岁，SOFA $22$，结局 $y=1$。\n- 测试用例 $3$（具有不一致结局的重复协变量，$4$ 个观测值）：\n  - 观测值 $1$：年龄 $60$ 岁，SOFA $8$，结局 $y=0$。\n  - 观测值 $2$：年龄 $60$ 岁，SOFA $8$，结局 $y=1$。\n  - 观测值 $3$：年龄 $40$ 岁，SOFA $5$，结局 $y=0$。\n  - 观测值 $4$：年龄 $40$ 岁，SOFA $5$，结局 $y=1$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个逗号分隔的列表，该列表包含三个测试用例的结果列表，并用一对单独的方括号括起来。例如，格式应如下所示：$[[a_{11},\\dots,a_{1m_1}],[a_{21},\\dots,a_{2m_2}],[a_{31},\\dots,a_{3m_3}]]$，其中每个 $a_{jk}$ 是一个四舍五入到六位小数的浮点数。不应打印任何额外文本。", "solution": "用户提供的问题被评估为有效。它在科学上基于广义线性模型 (GLM) 的理论，问题设定适定，提供了所有必要的数据和参数，并且陈述客观。该任务涉及逻辑回归中偏差残差的标准推导和应用，这是统计建模中的一个核心概念。\n\n### **第1部分：逻辑回归偏差残差的推导**\n\n广义线性模型 (GLM) 的偏差 (deviance) 定义为 $D = 2 \\sum_{i=1}^n [\\ell(\\boldsymbol{\\beta}_{sat}; y_i) - \\ell(\\hat{\\boldsymbol{\\beta}}; y_i)]$，其中 $\\ell(\\cdot)$ 是对数似然函数，$\\hat{\\boldsymbol{\\beta}}$ 是模型参数的最大似然估计，$\\boldsymbol{\\beta}_{sat}$ 表示*饱和*模型的参数。饱和模型是能完美拟合数据的模型，为每个观测值都设有一个参数。总偏差 $D$ 是单个偏差贡献之和，$d_i = 2 [\\ell(\\boldsymbol{\\beta}_{sat}; y_i) - \\ell(\\hat{\\boldsymbol{\\beta}}; y_i)]$。\n\n观测值 $i$ 的偏差残差，记为 $r_i$，定义为其对偏差的贡献的带符号平方根：\n$$\nr_i = \\mathrm{sign}(y_i - \\hat{\\pi}_i) \\sqrt{d_i}\n$$\n其中 $y_i$ 是观测结局，$\\hat{\\pi}_i$ 是从模型中得到的拟合概率。\n\n我们接下来推导逻辑回归中 $d_i$ 的形式，逻辑回归使用伯努利分布对二元结局 $y_i \\in \\{0, 1\\}$ 进行建模。\n\n**1. 饱和模型的对数似然**\n\n对于伯努利试验，观测值 $i$ 的对数似然由 $\\ell_i(\\pi_i \\mid y_i) = y_i \\log(\\pi_i) + (1-y_i)\\log(1-\\pi_i)$ 给出。饱和模型完美地解释了数据，意味着其对观测值 $i$ 的拟合概率，我们称之为 $\\tilde{\\pi}_i$，等于观测结局 $y_i$。因此，$\\tilde{\\pi}_i = y_i$。\n\n饱和模型对观测值 $i$ 的对数似然是对数似然函数的最大可能值，该值在 $\\pi_i=y_i$ 时取得。\n将 $\\pi_i = y_i$ 代入对数似然函数，得到：\n$$\n\\ell(\\boldsymbol{\\beta}_{sat}; y_i) = y_i \\log(y_i) + (1-y_i) \\log(1-y_i)\n$$\n如果 $y_i = 1$，表达式变为 $1 \\log(1) + 0 \\log(0)$。如果 $y_i=0$，则为 $0 \\log(0) + 1 \\log(1)$。根据约定 $\\lim_{x\\to 0} x \\log x = 0$，任何单个伯努利观测的饱和模型的对数似然都是 $0$。\n$$\n\\ell(\\boldsymbol{\\beta}_{sat}; y_i) = 0\n$$\n\n**2. 拟合模型的对数似然**\n\n拟合的逻辑回归模型为每个观测值提供了一个估计概率 $\\hat{\\pi}_i$，其中 $\\hat{\\pi}_i = \\mathrm{logistic}(\\mathbf{x}_i^\\top \\hat{\\boldsymbol{\\beta}})$。在拟合模型下，观测值 $i$ 的对数似然为：\n$$\n\\ell(\\hat{\\boldsymbol{\\beta}}; y_i) = y_i \\log(\\hat{\\pi}_i) + (1-y_i)\\log(1-\\hat{\\pi}_i)\n$$\n\n**3. 单个偏差贡献 ($d_i$)**\n\n结合对数似然，观测值 $i$ 的偏差贡献为：\n$$\nd_i = 2 [0 - (y_i \\log(\\hat{\\pi}_i) + (1-y_i)\\log(1-\\hat{\\pi}_i))]\n$$\n$$\nd_i = -2 [y_i \\log(\\hat{\\pi}_i) + (1-y_i)\\log(1-\\hat{\\pi}_i)]\n$$\n这是逻辑回归中单个观测值的偏差分量的一般表达式。\n\n**4. 偏差残差 ($r_i$)**\n\n我们现在构造偏差残差 $r_i = \\mathrm{sign}(y_i - \\hat{\\pi}_i) \\sqrt{d_i}$。为了获得显式形式，我们考虑二元结局 $y_i$ 的两种情况。\n\n- **情况 1：$y_i = 1$ (例如，发生死亡)**\n  在这种情况下，偏差贡献为 $d_i = -2 [1 \\cdot \\log(\\hat{\\pi}_i) + 0 \\cdot \\log(1-\\hat{\\pi}_i)] = -2 \\log(\\hat{\\pi}_i)$。\n  符号项为 $\\mathrm{sign}(1 - \\hat{\\pi}_i)$。由于 $\\hat{\\pi}_i \\in (0,1)$，此符号始终为 $+1$。\n  因此，残差为：\n  $$\n  r_i = \\sqrt{-2 \\log(\\hat{\\pi}_i)} \\quad \\text{对于 } y_i = 1\n  $$\n\n- **情况 2：$y_i = 0$ (例如，存活)**\n  在这种情况下，偏差贡献为 $d_i = -2 [0 \\cdot \\log(\\hat{\\pi}_i) + 1 \\cdot \\log(1-\\hat{\\pi}_i)] = -2 \\log(1 - \\hat{\\pi}_i)$。\n  符号项为 $\\mathrm{sign}(0 - \\hat{\\pi}_i)$。由于 $\\hat{\\pi}_i \\in (0,1)$，此符号始终为 $-1$。\n  因此，残差为：\n  $$\n  r_i = -\\sqrt{-2 \\log(1 - \\hat{\\pi}_i)} \\quad \\text{对于 } y_i = 0\n  $$\n\n这两个表达式提供了逻辑回归中偏差残差的显式闭式公式，符合题目要求。\n\n### **第2部分：偏差残差的计算**\n\n使用给定的系数向量 $\\hat{\\boldsymbol{\\beta}} = (-7.0, 0.04, 0.35)^\\top$，对每个观测值 $(\\mathrm{age}_i, \\mathrm{sofa}_i, y_i)$ 的计算过程如下：\n\n1.  **计算线性预测值 $\\hat{\\eta}_i$**：\n    $$\n    \\hat{\\eta}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\cdot \\mathrm{age}_i + \\hat{\\beta}_2 \\cdot \\mathrm{sofa}_i = -7.0 + 0.04 \\cdot \\mathrm{age}_i + 0.35 \\cdot \\mathrm{sofa}_i\n    $$\n2.  **计算拟合概率 $\\hat{\\pi}_i$**：\n    $$\n    \\hat{\\pi}_i = \\mathrm{logistic}(\\hat{\\eta}_i) = \\frac{1}{1 + \\exp(-\\hat{\\eta}_i)}\n    $$\n3.  **使用基于 $y_i$ 值的推导分段公式计算偏差残差 $r_i$**：\n    $$\n    r_i = \\begin{cases} \\sqrt{-2 \\log(\\hat{\\pi}_i)}  \\text{如果 } y_i=1 \\\\ -\\sqrt{-2 \\log(1-\\hat{\\pi}_i)}  \\text{如果 } y_i=0 \\end{cases}\n    $$\n4.  **将**结果四舍五入到六位小数。\n\n所提供的 Python 代码为给定测试套件中的每个观测值实现了此过程。通过使用标准的 `numpy` 函数，保证了数值稳定性，这些函数能稳健地处理本问题中遇到的输入范围的浮点运算。表达式 $\\log(\\hat{\\pi}_i)$ 和 $\\log(1-\\hat{\\pi}_i)$ 是良定义的，因为对于任何有限的 $\\hat{\\eta}_i$，$\\hat{\\pi}_i$ 都严格介于 $0$ 和 $1$ 之间。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes deviance residuals for logistic regression based on fixed coefficients.\n    \"\"\"\n    \n    # The given fixed coefficient vector beta_hat = (beta_0, beta_1, beta_2)\n    # corresponding to (intercept, age, sofa).\n    beta_hat = np.array([-7.0, 0.04, 0.35])\n\n    # Test suites as a list of lists of tuples. Each tuple is (age, sofa, y).\n    test_cases = [\n        # Test case 1: General mixed-risk cohort\n        [\n            (65, 6, 1),   # Observation 1\n            (72, 10, 1),  # Observation 2\n            (50, 4, 0),   # Observation 3\n            (34, 2, 0),   # Observation 4\n            (80, 12, 1)   # Observation 5\n        ],\n        # Test case 2: Near-boundary probabilities\n        [\n            (22, 0, 1),   # Observation 1\n            (90, 18, 0),  # Observation 2\n            (85, 20, 1),  # Observation 3\n            (25, 1, 0),   # Observation 4\n            (78, 22, 1)   # Observation 5\n        ],\n        # Test case 3: Duplicate covariates with discordant outcomes\n        [\n            (60, 8, 0),   # Observation 1\n            (60, 8, 1),   # Observation 2\n            (40, 5, 0),   # Observation 3\n            (40, 5, 1)    # Observation 4\n        ]\n    ]\n\n    all_results = []\n    for case_data in test_cases:\n        case_residuals = []\n        for age, sofa, y in case_data:\n            # Construct the design vector x_i with an intercept term\n            x_i = np.array([1, age, sofa])\n            \n            # Step 1: Compute the linear predictor eta_hat_i\n            eta_hat_i = x_i @ beta_hat\n            \n            # Step 2: Compute the fitted probability pi_hat_i\n            pi_hat_i = 1 / (1 + np.exp(-eta_hat_i))\n            \n            # Step 3: Compute the deviance residual r_i\n            # The piecewise formula derived in the solution is used.\n            if y == 1:\n                # Per-observation deviance for y=1\n                d_i = -2 * np.log(pi_hat_i)\n                # sign(y - pi_hat) is sign(1 - pi_hat) which is +1\n                residual = np.sqrt(d_i)\n            else: # y == 0\n                # Per-observation deviance for y=0.\n                # np.log1p(-pi_hat_i) is equivalent to np.log(1 - pi_hat_i) but\n                # can be more accurate for pi_hat_i close to 0. Here, 1-pi_hat_i\n                # is not extremely close to 1, so np.log is sufficient.\n                d_i = -2 * np.log(1 - pi_hat_i)\n                # sign(y - pi_hat) is sign(0 - pi_hat) which is -1\n                residual = -np.sqrt(d_i)\n\n            # Step 4: Round and store the result\n            case_residuals.append(round(residual, 6))\n        \n        all_results.append(case_residuals)\n\n    # Format the final output string as specified in the problem.\n    # e.g., [[-1.2,3.4],[5.6,7.8]]\n    output_str = f\"[{','.join([f'[{\",\".join(map(str, res))}]' for res in all_results])}]\"\n    \n    print(output_str)\n\nsolve()\n```", "id": "4982785"}]}