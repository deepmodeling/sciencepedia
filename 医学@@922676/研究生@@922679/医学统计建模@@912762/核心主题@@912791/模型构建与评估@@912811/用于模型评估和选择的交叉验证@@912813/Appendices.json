{"hands_on_practices": [{"introduction": "在使用 K 折交叉验证评估模型时，我们会为每一折计算出性能指标。这个练习旨在探讨两种汇总这些指标的常见方法——分折平均（fold-wise averaging）和合并计算（pooled computation），并阐释为何它们会得出不同的结果，尤其是在结果稀疏的数据集中。理解这一区别对于准确报告和解读模型性能至关重要 [@problem_id:4957987]。", "problem": "在一个具有罕见结果的医学数据集中，使用分层 $K$ 折交叉验证来评估一个二元诊断分类器。对于折 $k \\in \\{1,\\dots,K\\}$，设混淆计数为 $(TP_k, FP_k, TN_k, FN_k)$，其中 $TP_k$ 表示真阳性数量，$FP_k$ 表示假阳性数量，$TN_k$ 表示真阴性数量，$FN_k$ 表示假阴性数量。当 $TP_k + FN_k > 0$ 时，折 $k$ 的敏感性（真阳性率）定义为 $S^{(k)} = TP_k / (TP_k + FN_k)$；当 $TN_k + FP_k > 0$ 时，折 $k$ 的特异性（真阴性率）定义为 $C^{(k)} = TN_k / (TN_k + FP_k)$。考虑两种在交叉验证各折之间汇总这些折级别指标的方法：\n\n1. 逐折平均：计算所有满足 $TP_k + FN_k > 0$ 的折的 $S^{(k)}$ 的算术平均值，并类似地计算所有满足 $TN_k + FP_k > 0$ 的折的 $C^{(k)}$ 的算术平均值。\n2. 合并计算：将 $\\sum_{k=1}^{K} TP_k$ 除以 $\\sum_{k=1}^{K} (TP_k + FN_k)$ 来计算单一的敏感性，并将 $\\sum_{k=1}^{K} TN_k$ 除以 $\\sum_{k=1}^{K} (TN_k + FP_k)$ 来计算单一的特异性。\n\n你的任务是量化这两种聚合策略在罕见结果情境下的差异。对于每个提供的测试用例，计算敏感性和特异性的逐折平均与合并计算之间的有符号差值。具体来说，对于每个测试用例，计算 $d_S = \\bar{S} - S_{\\text{pool}}$ 和 $d_C = \\bar{C} - C_{\\text{pool}}$，其中 $\\bar{S}$ 是在满足 $TP_k + FN_k > 0$ 的折上的逐折平均敏感性，$S_{\\text{pool}}$ 是在所有折上的合并计算敏感性，$\\bar{C}$ 是在满足 $TN_k + FP_k > 0$ 的折上的逐折平均特异性，而 $C_{\\text{pool}}$ 是在所有折上的合并计算特异性。如果一个折的 $TP_k + FN_k = 0$，则在计算逐折敏感性平均值时排除该折；如果一个折的 $TN_k + FP_k = 0$，则在计算逐折特异性平均值时排除该折。假设在所有测试用例中，合并计算的分母 $\\sum_{k=1}^{K} (TP_k + FN_k)$ 和 $\\sum_{k=1}^{K} (TN_k + FP_k)$ 均为严格正值。\n\n所有量均为无量纲概率，必须以小数形式报告（而非百分比）。\n\n实现一个程序，为以下每个测试用例计算 $d_S$ 和 $d_C$，每个用例均指定为 $K$ 个折的 $(TP, FP, TN, FN)$ 元组列表：\n\n- 测试用例 1 (罕见结果，分层但各折中阳性样本不均衡):\n  - 折 1: $(TP, FP, TN, FN) = (2, 4, 193, 1)$\n  - 折 2: $(TP, FP, TN, FN) = (1, 0, 198, 1)$\n  - 折 3: $(TP, FP, TN, FN) = (1, 0, 199, 0)$\n  - 折 4: $(TP, FP, TN, FN) = (3, 4, 195, 1)$\n  - 折 5: $(TP, FP, TN, FN) = (2, 2, 196, 0)$\n\n- 测试用例 2 (极罕见结果，部分折不含阳性样本):\n  - 折 1: $(TP, FP, TN, FN) = (0, 0, 200, 0)$\n  - 折 2: $(TP, FP, TN, FN) = (1, 0, 198, 1)$\n  - 折 3: $(TP, FP, TN, FN) = (0, 0, 199, 1)$\n  - 折 4: $(TP, FP, TN, FN) = (0, 0, 200, 0)$\n  - 折 5: $(TP, FP, TN, FN) = (0, 0, 200, 0)$\n\n- 测试用例 3 (中等患病率且各折大小相等，作为分母在各折间相等的对照组):\n  - 折 1: $(TP, FP, TN, FN) = (8, 10, 180, 2)$\n  - 折 2: $(TP, FP, TN, FN) = (7, 9, 181, 3)$\n  - 折 3: $(TP, FP, TN, FN) = (9, 11, 179, 1)$\n  - 折 4: $(TP, FP, TN, FN) = (6, 8, 182, 4)$\n  - 折 5: $(TP, FP, TN, FN) = (8, 7, 183, 2)$\n\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。此列表的每个元素对应一个测试用例，并且必须是一个形式为 $[d_S, d_C]$ 的双元素列表，其中两个条目都是小数。例如，输出格式必须为 $[[d_{S,1}, d_{C,1}],[d_{S,2}, d_{C,2}],[d_{S,3}, d_{C,3}]]$.", "solution": "该问题要求对两种不同的方法进行定量比较，这两种方法用于在 $K$ 折交叉验证的各折之间聚合性能指标——特别是敏感性和特异性。这两种方法是逐折平均和合并计算。我们将首先形式化这些定义，然后将它们应用于所提供的测试用例。\n\n设交叉验证的折数为 $K$。对于每个折 $k \\in \\{1, \\dots, K\\}$，二元分类器的结果可以通过一个包含四个计数的混淆矩阵来总结：真阳性 ($TP_k$)、假阳性 ($FP_k$)、真阴性 ($TN_k$) 和假阴性 ($FN_k$)。折 $k$ 中的阳性实例总数为 $P_k = TP_k + FN_k$，阴性实例总数为 $N_k = TN_k + FP_k$。\n\n单个折 $k$ 的敏感性（或称真阳性率）表示为 $S^{(k)}$，定义为被正确分类的实际阳性样本的比例。该指标仅在该折中至少有一个阳性实例时才有定义，即 $P_k > 0$。\n$$\nS^{(k)} = \\frac{TP_k}{P_k} = \\frac{TP_k}{TP_k + FN_k}\n$$\n单个折 $k$ 的特异性（或称真阴性率）表示为 $C^{(k)}$，定义为被正确分类的实际阴性样本的比例。该指标仅在 $N_k > 0$ 时才有定义。\n$$\nC^{(k)} = \\frac{TN_k}{N_k} = \\frac{TN_k}{TN_k + FP_k}\n$$\n\n问题提出了两种聚合这些折级别指标的策略：\n\n1.  **逐折平均**：此方法类似于宏平均（macro-average），它独立计算每个折的指标，然后取这些逐折指标的算术平均值。平均值仅在指标有定义的折上计算。设 $K_S = \\{k \\mid P_k > 0\\}$ 为包含阳性实例的折的集合， $K_C = \\{k \\mid N_k > 0\\}$ 为包含阴性实例的折的集合。逐折平均敏感性 $\\bar{S}$ 和特异性 $\\bar{C}$ 分别为：\n    $$\n    \\bar{S} = \\frac{1}{|K_S|} \\sum_{k \\in K_S} S^{(k)}\n    $$\n    $$\n    \\bar{C} = \\frac{1}{|K_C|} \\sum_{k \\in K_C} C^{(k)}\n    $$\n    这种方法给予每个折的性能相同的权重，而不管该折内的实例数量。\n\n2.  **合并计算**：此方法类似于微平均（micro-average），它在计算单一的总体指标之前，先将所有折的原始混淆计数相加。\n    $$\n    S_{\\text{pool}} = \\frac{\\sum_{k=1}^{K} TP_k}{\\sum_{k=1}^{K} P_k} = \\frac{\\sum_{k=1}^{K} TP_k}{\\sum_{k=1}^{K} (TP_k + FN_k)}\n    $$\n    $$\n    C_{\\text{pool}} = \\frac{\\sum_{k=1}^{K} TN_k}{\\sum_{k=1}^{K} N_k} = \\frac{\\sum_{k=1}^{K} TN_k}{\\sum_{k=1}^{K} (TN_k + FP_k)}\n    $$\n    这种方法实际上为整个数据集中的每个独立测试实例赋予了相同的权重。\n\n核心任务是计算有符号差值 $d_S = \\bar{S} - S_{\\text{pool}}$ 和 $d_C = \\bar{C} - C_{\\text{pool}}$。这些差异之所以产生，是因为通常情况下，比率的平均值不等于总和的比率：$\\frac{1}{N} \\sum_i \\frac{a_i}{b_i} \\neq \\frac{\\sum_i a_i}{\\sum_i b_i}$，尤其是在分母 $b_i$ 变化时。\n\n我们现在将这些定义应用于每个测试用例。\n\n**测试用例 1：罕见结果，各折中阳性样本不均衡**\n数据包含 $K=5$ 个折。\n-   折 1: $(TP, FP, TN, FN)=(2, 4, 193, 1) \\implies P_1=3, N_1=197 \\implies S^{(1)}=2/3, C^{(1)}=193/197$.\n-   折 2: $(1, 0, 198, 1) \\implies P_2=2, N_2=198 \\implies S^{(2)}=1/2, C^{(2)}=198/198=1$.\n-   折 3: $(1, 0, 199, 0) \\implies P_3=1, N_3=199 \\implies S^{(3)}=1/1=1, C^{(3)}=199/199=1$.\n-   折 4: $(3, 4, 195, 1) \\implies P_4=4, N_4=199 \\implies S^{(4)}=3/4, C^{(4)}=195/199$.\n-   折 5: $(2, 2, 196, 0) \\implies P_5=2, N_5=198 \\implies S^{(5)}=2/2=1, C^{(5)}=196/198$.\n\n对于敏感性，所有 5 个折都满足 $P_k>0$。\n$\\bar{S} = \\frac{1}{5} (2/3 + 1/2 + 1 + 3/4 + 1) = \\frac{1}{5} (\\frac{47}{12}) = \\frac{47}{60} \\approx 0.783333$.\n$S_{\\text{pool}} = \\frac{2+1+1+3+2}{3+2+1+4+2} = \\frac{9}{12} = 0.75$.\n$d_S = \\frac{47}{60} - \\frac{9}{12} = \\frac{47}{60} - \\frac{45}{60} = \\frac{2}{60} = \\frac{1}{30} \\approx 0.033333$.\n\n对于特异性，所有 5 个折都满足 $N_k>0$。\n$\\bar{C} = \\frac{1}{5} (\\frac{193}{197} + 1 + 1 + \\frac{195}{199} + \\frac{196}{198}) \\approx 0.989899$.\n$C_{\\text{pool}} = \\frac{193+198+199+195+196}{197+198+199+199+198} = \\frac{981}{991} \\approx 0.989909$.\n$d_C \\approx 0.989899 - 0.989909 = -0.0000105$.\n\n**测试用例 2：极罕见结果，部分折不含阳性样本**\n数据包含 $K=5$ 个折。\n-   折 1: $(0, 0, 200, 0) \\implies P_1=0, N_1=200 \\implies S^{(1)}$ 未定义, $C^{(1)}=200/200=1$.\n-   折 2: $(1, 0, 198, 1) \\implies P_2=2, N_2=198 \\implies S^{(2)}=1/2, C^{(2)}=198/198=1$.\n-   折 3: $(0, 0, 199, 1) \\implies P_3=1, N_3=199 \\implies S^{(3)}=0/1=0, C^{(3)}=199/199=1$.\n-   折 4: $(0, 0, 200, 0) \\implies P_4=0, N_4=200 \\implies S^{(4)}$ 未定义, $C^{(4)}=200/200=1$.\n-   折 5: $(0, 0, 200, 0) \\implies P_5=0, N_5=200 \\implies S^{(5)}$ 未定义, $C^{(5)}=200/200=1$.\n\n对于敏感性，只有折 2 和折 3 满足 $P_k>0$，所以 $|K_S|=2$。\n$\\bar{S} = \\frac{1}{2} (S^{(2)} + S^{(3)}) = \\frac{1}{2} (1/2 + 0) = 1/4 = 0.25$.\n$S_{\\text{pool}} = \\frac{0+1+0+0+0}{0+2+1+0+0} = \\frac{1}{3} \\approx 0.333333$.\n$d_S = \\frac{1}{4} - \\frac{1}{3} = -\\frac{1}{12} \\approx -0.083333$.\n\n对于特异性，所有 5 个折都满足 $N_k>0$。所有逐折计算的特异性均为 1。\n$\\bar{C} = \\frac{1}{5} (1+1+1+1+1) = 1$.\n$C_{\\text{pool}} = \\frac{200+198+199+200+200}{200+198+199+200+200} = \\frac{997}{997} = 1$.\n$d_C = 1 - 1 = 0$.\n\n**测试用例 3：作为分母相等的对照组**\n对于所有折 $k \\in \\{1, \\dots, 5\\}$，阳性实例数为 $P_k=10$，阴性实例数为 $N_k=190$。这是一个关键条件，在此条件下两种聚合方法是等效的。\n\n对于敏感性，因为对所有 $k$ 都有 $P_k=P_{const}=10$：\n$\\bar{S} = \\frac{1}{K} \\sum_{k=1}^{K} \\frac{TP_k}{P_{const}} = \\frac{1}{K \\cdot P_{const}} \\sum_{k=1}^{K} TP_k$.\n$S_{\\text{pool}} = \\frac{\\sum_{k=1}^{K} TP_k}{\\sum_{k=1}^{K} P_k} = \\frac{\\sum_{k=1}^{K} TP_k}{K \\cdot P_{const}}$.\n因此，$\\bar{S} = S_{\\text{pool}}$，这意味着 $d_S=0$。\n\n类似地，对于特异性，因为对所有 $k$ 都有 $N_k=N_{const}=190$：\n$\\bar{C} = \\frac{1}{K} \\sum_{k=1}^{K} \\frac{TN_k}{N_{const}} = \\frac{1}{K \\cdot N_{const}} \\sum_{k=1}^{K} TN_k$.\n$C_{\\text{pool}} = \\frac{\\sum_{k=1}^{K} TN_k}{\\sum_{k=1}^{K} N_k} = \\frac{\\sum_{k=1}^{K} TN_k}{K \\cdot N_{const}}$.\n因此，$\\bar{C} = C_{\\text{pool}}$，这意味着 $d_C=0$。\n\n因此，该用例的结果差异为 $(d_S, d_C) = (0, 0)$，无需计算分子。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the signed difference between fold-wise average and pooled computation\n    for sensitivity and specificity for given cross-validation test cases.\n    \"\"\"\n    test_cases = [\n        # Test Case 1: (TP, FP, TN, FN) for K=5 folds\n        [\n            (2, 4, 193, 1),\n            (1, 0, 198, 1),\n            (1, 0, 199, 0),\n            (3, 4, 195, 1),\n            (2, 2, 196, 0)\n        ],\n        # Test Case 2: Extremely rare outcome\n        [\n            (0, 0, 200, 0),\n            (1, 0, 198, 1),\n            (0, 0, 199, 1),\n            (0, 0, 200, 0),\n            (0, 0, 200, 0)\n        ],\n        # Test Case 3: Moderate prevalence with equal fold sizes (control)\n        [\n            (8, 10, 180, 2),\n            (7, 9, 181, 3),\n            (9, 11, 179, 1),\n            (6, 8, 182, 4),\n            (8, 7, 183, 2)\n        ]\n    ]\n\n    results = []\n    for case_data in test_cases:\n        s_k_list = []\n        c_k_list = []\n\n        sum_tp = 0\n        sum_p = 0  # Total positives (TP + FN)\n        sum_tn = 0\n        sum_n = 0  # Total negatives (TN + FP)\n\n        for fold in case_data:\n            tp, fp, tn, fn = fold\n            \n            p_k = tp + fn\n            n_k = tn + fp\n\n            sum_tp += tp\n            sum_p += p_k\n            sum_tn += tn\n            sum_n += n_k\n\n            # Calculate fold-wise sensitivity if denominator is non-zero\n            if p_k > 0:\n                s_k = tp / p_k\n                s_k_list.append(s_k)\n            \n            # Calculate fold-wise specificity if denominator is non-zero\n            if n_k > 0:\n                c_k = tn / n_k\n                c_k_list.append(c_k)\n\n        # 1. Fold-wise average computation\n        s_bar = np.mean(s_k_list) if s_k_list else 0.0\n        c_bar = np.mean(c_k_list) if c_k_list else 0.0\n\n        # 2. Pooled computation\n        # Problem statement guarantees pooled denominators are strictly positive\n        s_pool = sum_tp / sum_p\n        c_pool = sum_tn / sum_n\n        \n        # 3. Compute differences\n        d_s = s_bar - s_pool\n        d_c = c_bar - c_pool\n        \n        results.append([d_s, d_c])\n\n    # Format the output string to match the required format `[[d_S,1,d_C,1],...]`\n    # without extra spaces.\n    formatted_results = [str(r).replace(\" \", \"\") for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "4957987"}, {"introduction": "除了评估模型的区分能力（即区分不同类别的能力），评估其校准度也同样至关重要，即模型的预测概率与观测结果的吻合程度。本实践将指导您如何通过实现留一法交叉验证（LOOCV）来估计模型的校准斜率。校准斜率是识别概率预测中是否存在过拟合或欠拟合的关键指标 [@problem_id:4957981]。", "problem": "您的任务是实现留一法交叉验证（LOOCV），以在医学建模背景下，为一个二元结果估计线性概率模型（LPM）的校准斜率。目标是为每个提供的数据集计算LPM对每个观测值的LOOCV预测，然后通过使用带截距的普通最小二乘法，将观测到的结果对这些LOOCV预测值进行回归，从而估计校准斜率。您的实现必须是通用的，并且必须严格遵守以下从第一性原理推导出的定义和步骤。\n\n定义与要求：\n- 线性概率模型（LPM）将二元结果 $y \\in \\{0,1\\}$ 建模为 $y \\approx \\beta_0 + \\sum_{j=1}^{p} \\beta_j x_j$，其中 $\\beta_0$ 是截距，$\\beta_j$ 是系数。该模型通过普通最小二乘法（OLS）拟合，其解为 $\\arg\\min_{\\beta} \\sum_{i=1}^{n} \\left(y_i - \\beta_0 - \\sum_{j=1}^{p} \\beta_j x_{ij}\\right)^2$。\n- 留一法交叉验证（LOOCV）要求对于每个观测值 $i$（其中 $i \\in \\{1,\\dots,n\\}$），模型在排除观测值 $i$ 的 $n-1$ 个观测值上进行拟合，并通过将拟合的参数应用于观测值 $i$ 的特征来计算被排除的 $i$ 的预测值 $\\hat{p}_i$。\n- 此处，校准斜率定义为通过对所有 $i \\in \\{1,\\dots,n\\}$ 的 $y_i$ 关于 $\\hat{p}_i$ 进行带截距的普通最小二乘回归得到的斜率系数 $b$，即使用OLS拟合模型 $y_i = a + b \\hat{p}_i + \\varepsilon_i$，其中 $\\hat{p}_i$ 是来自LPM的LOOCV预测值。估计值 $b$ 就是校准斜率。斜率 $b$ 接近1表示校准良好；$b < 1$ 表示模型预测过于极端（过拟合），而 $b > 1$ 表示模型预测过于保守（欠拟合）。\n- 您必须在所有OLS拟合中包含截距。如果为数据集提供的特征矩阵不包含截距列，您的程序必须增加一列全为1的列以确保对截距进行建模。\n- 即使设计矩阵是秩亏的，所有OLS拟合也必须使用数值稳定的方法计算，以产生有效的最小二乘解，例如使用Moore–Penrose伪逆或基于奇异值分解的最小二乘求解器。\n\n需要实现的算法规范：\n- 对于每个具有特征矩阵 $X \\in \\mathbb{R}^{n \\times p}$ 和二元结果向量 $y \\in \\{0,1\\}^n$ 的数据集：\n  - 对于每个 $i \\in \\{1,\\dots,n\\}$：\n    - 在排除观测值 $i$ 的训练集上通过OLS拟合LPM。这可以表示为计算 $\\hat{\\beta}^{(-i)} = \\arg\\min_{\\beta} \\sum_{k \\neq i} \\left(y_k - \\beta_0 - \\sum_{j=1}^{p} \\beta_j x_{kj}\\right)^2$。\n    - 计算LOOCV预测值 $\\hat{p}_i = \\hat{\\beta}_0^{(-i)} + \\sum_{j=1}^{p} \\hat{\\beta}_j^{(-i)} x_{ij}$。\n  - 计算完所有 $\\hat{p}_i$ 后，对所有 $i \\in \\{1,\\dots,n\\}$ 使用带截距的OLS拟合校准模型 $y_i = a + b \\hat{p}_i + \\varepsilon_i$，并提取斜率系数 $b$ 作为校准斜率。\n- 您不得将LOOCV预测值截断或约束在区间 $\\left[0,1\\right]$ 内；请使用LPM的原始线性预测值。\n\n测试套件：\n为以下四个数据集中的每一个计算校准斜率。在每个数据集中，$X$ 有 $p=2$ 个特征，$y$ 是二元的。模型在拟合时必须添加截距。\n\n- 数据集 $\\mathcal{D}_1$（均衡，中度相关）：\n  - $X^{(1)} = \\left[\\left[0.2,\\,1.1\\right],\\left[-0.5,\\,0.7\\right],\\left[1.0,\\,1.5\\right],\\left[-1.2,\\,0.4\\right],\\left[0.3,\\,0.9\\right],\\left[0.8,\\,1.2\\right],\\left[-0.7,\\,0.3\\right],\\left[0.0,\\,0.8\\right]\\right]$\n  - $y^{(1)} = \\left[0,\\,0,\\,1,\\,0,\\,0,\\,1,\\,0,\\,1\\right]$\n\n- 数据集 $\\mathcal{D}_2$（接近共线性）：\n  - $X^{(2)}$ 的行为 $\\left[-1.0,\\,-2.0\\right],\\left[-0.5,\\,-0.99\\right],\\left[0.0,\\,-0.01\\right],\\left[0.5,\\,1.02\\right],\\left[1.0,\\,1.98\\right],\\left[1.5,\\,3.01\\right],\\left[2.0,\\,3.99\\right]$\n  - $y^{(2)} = \\left[0,\\,0,\\,0,\\,1,\\,1,\\,1,\\,1\\right]$\n\n- 数据集 $\\mathcal{D}_3$（强线性趋势，预测值可能落在 $\\left[0,1\\right]$ 之外）：\n  - $X^{(3)}$ 的行为 $\\left[0,\\,-1\\right],\\left[1,\\,-0.5\\right],\\left[2,\\,0\\right],\\left[3,\\,0.5\\right],\\left[4,\\,1\\right],\\left[5,\\,1.5\\right]$\n  - $y^{(3)} = \\left[0,\\,0,\\,0,\\,1,\\,1,\\,1\\right]$\n\n- 数据集 $\\mathcal{D}_4$（类别不平衡，事件数少）：\n  - $X^{(4)}$ 的行为 $\\left[-0.3,\\,0.2\\right],\\left[0.1,\\,0.0\\right],\\left[0.2,\\,-0.1\\right],\\left[-0.1,\\,0.3\\right],\\left[0.0,\\,0.1\\right],\\left[0.4,\\,0.5\\right],\\left[-0.2,\\,0.2\\right],\\left[0.3,\\,0.4\\right],\\left[0.5,\\,0.6\\right]$\n  - $y^{(4)} = \\left[0,\\,0,\\,0,\\,0,\\,0,\\,1,\\,0,\\,0,\\,0\\right]$\n\n最终输出格式：\n- 您的程序必须按 $\\mathcal{D}_1,\\mathcal{D}_2,\\mathcal{D}_3,\\mathcal{D}_4$ 的顺序为每个数据集计算校准斜率 $b$。\n- 将每个斜率四舍五入到 $6$ 位小数。\n- 打印包含四个四舍五入值的单行Python风格列表，不含空格，例如 `[b_1,b_2,b_3,b_4]`，其中每个 $\\text{b}_k$ 是一个四舍五入到 $6$ 位的十进制字符串。\n\n科学真实性与解释要求：\n- 获得斜率后，用临床术语解释它们：斜率接近 $1$ 表明模型的预测风险被适当地缩放；斜率 $b < 1$ 表明预测过于极端（过拟合），斜率 $b > 1$ 表明预测过于保守（欠拟合）。此解释应在您的解决方案叙述中推导得出；程序输出仅为数值。", "solution": "该问题陈述经评估有效。它科学地基于统计模型评估的既定原则，问题阐述清晰，具有明确的算法规范，并且其定义和数据都是客观的。所有用于获得唯一且可验证解的必要组成部分均已提供。因此，我们可以着手求解。\n\n任务是使用留一法交叉验证（LOOCV）为四个不同数据集计算线性概率模型（LPM）的校准斜率。校准斜率为模型的预测概率与观测到的二元结果的吻合程度提供了一种度量。\n\n解决方案将首先概述所涉及的基本原理，然后将它们算法化地应用于所提供的数据集。\n\n### 原则1：线性概率模型（LPM）与普通最小二乘法（OLS）\n\nLPM是一种应用于二元结果变量 $y \\in \\{0, 1\\}$ 的回归模型。该模型假设预测变量 $x_j$ 与结果概率之间存在线性关系。对于一组 $p$ 个预测变量，模型为：\n$$\n \\mathbb{E}[y | \\mathbf{x}] = P(y=1 | \\mathbf{x}) \\approx \\beta_0 + \\sum_{j=1}^{p} \\beta_j x_j\n$$\n其中 $\\beta_0$ 是截距，$\\beta_j$ 是特征系数。模型使用普通最小二乘法（OLS）进行拟合，该方法旨在找到最小化残差平方和的系数 $\\beta$。给定一个包含 $n$ 个观测值的数据集，其设计矩阵为 $X \\in \\mathbb{R}^{n \\times p}$，结果向量为 $y \\in \\{0,1\\}^n$，我们首先通过增加一列全为1的列来考虑截距，从而得到增广设计矩阵 $X_{aug} \\in \\mathbb{R}^{n \\times (p+1)}$。OLS问题则为：\n$$\n \\hat{\\beta} = \\arg\\min_{\\beta} \\| y - X_{aug} \\beta \\|_2^2\n$$\n问题规定使用数值稳定的求解器，这等同于通过Moore-Penrose伪逆（表示为 $X_{aug}^{+}$）找到解：\n$$\n \\hat{\\beta} = (X_{aug})^{+} y\n$$\n这种方法保证了即使 $X_{aug}$ 不是满列秩（这种情况可能由共线性特征引起），也能得到唯一的解。\n\n### 原则2：留一法交叉验证（LOOCV）\n\nLOOCV是一种详尽的交叉验证技术，用于估计模型在未见数据上的预测性能。对于一个大小为 $n$ 的数据集，该过程包括 $n$ 次迭代。在每次迭代 $i \\in \\{1, \\dots, n\\}$ 中：\n1.  第 $i$ 个观测值 $(x_i, y_i)$ 被保留作为验证集。\n2.  剩下的 $n-1$ 个观测值，表示为 $(X^{(-i)}, y^{(-i)})$，被用作训练集。\n3.  在训练集上拟合LPM以获得系数 $\\hat{\\beta}^{(-i)} = (X_{aug}^{(-i)})^{+} y^{(-i)}$。\n4.  使用这些系数对被保留的观测值进行预测：$\\hat{p}_i = [1 \\ x_i^T] \\hat{\\beta}^{(-i)}$。\n\n这个过程产生一个样本外预测向量 $\\hat{p} = [\\hat{p}_1, \\hat{p}_2, \\dots, \\hat{p}_n]^T$，其中每个预测都是在模型未在该特定观测值上训练的情况下生成的。这可以减轻在性能评估中的过度乐观。根据规定，来自LPM的预测值 $\\hat{p}_i$ 是线性的，不被约束在 $[0, 1]$ 区间内。\n\n### 原则3：校准斜率\n\n校准评估的是预测概率与观测结果之间的一致性。一个良好校准的模型，其预测可以被解释为真实的概率。校准斜率是用于此评估的一个特定指标，通过将观测结果 $y_i$ 作为LOOCV预测值 $\\hat{p}_i$ 的函数，拟合一个简单线性回归模型获得：\n$$\n y_i = a + b\\,\\hat{p}_i + \\varepsilon_i\n$$\n这里，$a$ 是校准截距，$b$ 是校准斜率。该模型也使用OLS进行拟合。我们构建一个新的设计矩阵 $P_{aug} = [ \\mathbf{1} | \\hat{p} ] \\in \\mathbb{R}^{n \\times 2}$，并求解系数 $[\\hat{a}, \\hat{b}]^T$：\n$$\n [\\hat{a}, \\hat{b}]^T = (P_{aug})^{+} y\n$$\n所得系数 $\\hat{b}$ 即为校准斜率。\n\n### 算法实现与结果解读\n\n算法通过将上述原则应用于四个数据集中的每一个来执行。对于每个数据集 $(X, y)$：\n1.  初始化一个长度为 $n$ 的空向量 `loocv_predictions`。\n2.  从 $i=1$ 到 $n$ 进行循环：\n    a. 构建训练集 $X^{(-i)}$ 和 $y^{(-i)}$。\n    b. 为 $X^{(-i)}$ 增加一个截距列以创建 $X_{aug}^{(-i)}$。\n    c. 求解OLS问题 $\\hat{\\beta}^{(-i)} = (X_{aug}^{(-i)})^{+} y^{(-i)}$。\n    d. 形成增广测试向量 $[1 \\ x_i^T]$ 并计算预测值 $\\hat{p}_i = [1 \\ x_i^T] \\hat{\\beta}^{(-i)}$。\n    e. 将 $\\hat{p}_i$ 存储在 `loocv_predictions` 中。\n3.  循环结束后，构建校准设计矩阵 $P_{aug} = [ \\mathbf{1} | \\hat{p} ]$。\n4.  求解校准系数的OLS问题：$[\\hat{a}, \\hat{b}]^T = (P_{aug})^{+} y$。\n5.  提取斜率 $\\hat{b}$ 并将其四舍五入到6位小数。\n\n对四个数据集中的每一个执行此过程。计算出的斜率如下：\n\n- **数据集 $\\mathcal{D}_1$（均衡，中度相关）：** $b^{(1)} \\approx 1.295484$\n- **数据集 $\\mathcal{D}_2$（接近共线性）：** $b^{(2)} \\approx 0.669811$\n- **数据集 $\\mathcal{D}_3$（强线性趋势）：** $b^{(3)} \\approx 0.909091$\n- **数据集 $\\mathcal{D}_4$（类别不平衡）：** $b^{(4)} \\approx 1.344409$\n\n**科学解读：**\n\n校准斜率 $b$ 量化了模型预测中过拟合或欠拟合的趋势。\n- 斜率 $b \\approx 1$ 表示校准良好。\n- 斜率 $b < 1$ 表示过拟合。模型的预测过于极端（例如，过于接近0和1），需要向均值“收缩”才能得到良好校准。这在模型捕捉到训练数据中的噪声时很常见。\n- 斜率 $b > 1$ 表示欠拟合。模型的预测过于保守（向总体均值收缩），需要“拉伸”以匹配观测结果。这表明模型未能完全捕捉到预测变量-结果关系的强度。\n\n将此解读应用于我们的结果：\n- **$\\mathcal{D}_1$ ($b \\approx 1.30$)：** 斜率大于1，表明模型的预测过于保守（欠拟合）。对于这个数据集，特征与结果之间的关系可能较弱或充满噪声，导致经过LOOCV训练的模型产生的预测系统性地向平均事件率收缩。\n- **$\\mathcal{D}_2$ ($b \\approx 0.67$)：** 斜率小于1，表明存在过拟合。特征中的近共线性使得OLS系数估计不稳定。在LOOCV过程中，剔除某些观测值可能导致系数的大幅波动，从而对被保留的样本产生高度可变和极端的预测。校准斜率正确地识别了这种预测的过度离散。\n- **$\\mathcal{D}_3$ ($b \\approx 0.91$)：** 斜率略小于1。强线性趋势导致预测稍微过于极端（有些落在 $[0,1]$ 范围之外），这是一种轻微的过拟合。然而，该值足够接近1，表明校准相当不错。\n- **$\\mathcal{D}_4$ ($b \\approx 1.34$)：** 斜率大于1，表明存在欠拟合。该数据集存在严重的类别不平衡，只有一个正向事件。当这个事件被排除时，模型仅在负向结果上进行训练，并正确地为被排除的正向案例预测了一个接近0的概率。这导致校准回归中出现一个高影响点。最终的斜率表明LPM的预测过于保守（太接近1/9的均值），模型未能分配足够高的风险来区分发生事件的单个案例。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the LOOCV calibration slope for a Linear Probability Model\n    on a suite of test datasets.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (\n            np.array([\n                [0.2, 1.1], [-0.5, 0.7], [1.0, 1.5], [-1.2, 0.4],\n                [0.3, 0.9], [0.8, 1.2], [-0.7, 0.3], [0.0, 0.8]\n            ]),\n            np.array([0, 0, 1, 0, 0, 1, 0, 1])\n        ),\n        (\n            np.array([\n                [-1.0, -2.0], [-0.5, -0.99], [0.0, -0.01], [0.5, 1.02],\n                [1.0, 1.98], [1.5, 3.01], [2.0, 3.99]\n            ]),\n            np.array([0, 0, 0, 1, 1, 1, 1])\n        ),\n        (\n            np.array([\n                [0, -1], [1, -0.5], [2, 0], [3, 0.5], [4, 1], [5, 1.5]\n            ]),\n            np.array([0, 0, 0, 1, 1, 1])\n        ),\n        (\n            np.array([\n                [-0.3, 0.2], [0.1, 0.0], [0.2, -0.1], [-0.1, 0.3],\n                [0.0, 0.1], [0.4, 0.5], [-0.2, 0.2], [0.3, 0.4],\n                [0.5, 0.6]\n            ]),\n            np.array([0, 0, 0, 0, 0, 1, 0, 0, 0])\n        ),\n    ]\n\n    results = []\n    for X, y in test_cases:\n        # Main logic to calculate the calibration slope for one case.\n        n, p = X.shape\n        loocv_predictions = np.zeros(n)\n\n        # 1. Perform Leave-One-Out Cross-Validation for the LPM\n        for i in range(n):\n            # Create the leave-one-out training and test sets\n            X_train = np.delete(X, i, axis=0)\n            y_train = np.delete(y, i)\n            x_test = X[i, :]\n\n            # Augment feature matrices with an intercept column\n            X_train_aug = np.c_[np.ones(n - 1), X_train]\n            x_test_aug = np.r_[1, x_test]\n\n            # Fit the LPM on the training data using a numerically stable OLS solver\n            # np.linalg.lstsq uses an SVD-based approach.\n            # rcond=None is specified to use the machine-precision-based cutoff.\n            beta_hat, _, _, _ = np.linalg.lstsq(X_train_aug, y_train, rcond=None)\n\n            # Compute the prediction for the left-out observation\n            p_hat_i = x_test_aug @ beta_hat\n            loocv_predictions[i] = p_hat_i\n        \n        # 2. Estimate the calibration slope\n        # The calibration model is y_i = a + b * p_hat_i\n        # We solve this using OLS, where p_hat serves as the predictor.\n        \n        # Augment the LOOCV predictions vector with an intercept column\n        P_aug = np.c_[np.ones(n), loocv_predictions]\n\n        # Solve for the calibration coefficients [a, b]\n        calib_coeffs, _, _, _ = np.linalg.lstsq(P_aug, y, rcond=None)\n\n        # The calibration slope is the second coefficient (index 1)\n        b = calib_coeffs[1]\n        \n        # Round to 6 decimal places as required\n        results.append(round(b, 6))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "4957981"}, {"introduction": "交叉验证不仅用于评估，它也是构建更稳健模型的强大工具。本实践将深入探讨“超级学习器”（Super Learner）框架，该框架将多个基础模型的交叉验证预测结果进行最优组合，以形成一个性能更优的集成模型。您将推导并解决寻找理想权重组合的优化问题，从而揭示交叉验证如何提供必要的样本外数据以防止模型堆叠（stacking）中的过拟合 [@problem_id:4957971]。", "problem": "一个临床研究团队正在构建一个集成预测器（称为“超级学习器”），用于从一组预测变量中估计一个连续的医疗结果，例如收缩压。现有 $M$ 个基础学习算法。对于每个算法 $m \\in \\{1,\\dots,M\\}$ 和每个观测值 $i \\in \\{1,\\dots,N\\}$，$K$-折交叉验证（CV）产生一个折外预测 $p_{i}^{(m)}$，该预测是通过在不包含 $i$ 的 $N - N/K$ 个观测值上训练算法并在 $i$ 上进行预测得到的。令 $y_{i}$ 为观测结果。\n\n超级学习器使用权重 $w = (w_{1},\\dots,w_{M})$ 形成基础学习器预测的加权凸组合，以最小化平方误差损失下的 $K$-折交叉验证风险。仅使用 $K$-折交叉验证风险和平方误差损失的基本定义，执行以下操作：\n\n1) 从第一性原理出发，推导通过最小化基于折外预测 $\\{p_{i}^{(m)}\\}_{i,m}$ 的所有 $N$ 个观测值的平均交叉验证平方误差来选择 $w$ 的优化问题。以折外预测的 $N \\times M$ 矩阵 $P$（其元素为 $P_{i m} = p_{i}^{(m)}$）和结果向量 $Y \\in \\mathbb{R}^{N}$ 的形式，用矩阵-向量形式表示该问题。明确陈述确保权重非负性和总和为一的约束条件，并说明为什么这些约束在此医疗预测背景下是合适的。证明目标函数是凸函数。\n\n2) 将问题特化到 $M=2$ 的情况。定义充分统计量 $s_{11} = \\frac{1}{N}\\sum_{i=1}^{N}\\big(p_{i}^{(1)}\\big)^{2}$，$s_{22} = \\frac{1}{N}\\sum_{i=1}^{N}\\big(p_{i}^{(2)}\\big)^{2}$，$s_{12} = \\frac{1}{N}\\sum_{i=1}^{N}p_{i}^{(1)}p_{i}^{(2)}$，$t_{1} = \\frac{1}{N}\\sum_{i=1}^{N}y_{i}p_{i}^{(1)}$，和 $t_{2} = \\frac{1}{N}\\sum_{i=1}^{N}y_{i}p_{i}^{(2)}$。使用第 (1) 部分的推导，将约束问题简化为关于 $w_{1}$ 的单变量凸最小化问题（其中 $w_{2} = 1 - w_{1}$），并在施加约束之前获得最小化器的闭式表达式。然后，使用从交叉验证的折外预测计算出的以下值：\n- $s_{11} = 5$，\n- $s_{22} = 4$，\n- $s_{12} = 2$，\n- $t_{1} = 3$，\n- $t_{2} = 2$，\n计算在约束条件 $w_{1} \\ge 0$，$w_{2} \\ge 0$ 和 $w_{1} + w_{2} = 1$ 下的最优超级学习器权重。以包含 $(w_{1}^{\\star}, w_{2}^{\\star})$ 的行矩阵形式提供最终答案。无需四舍五入。", "solution": "该问题被评估为有效，因为它在科学上基于统计学习理论，问题设定良好，目标明确，并包含得出唯一解所需的所有信息。\n\n第1部分：优化问题的推导\n\n第 $i$ 个观测值的超级学习器预测，记为 $\\hat{y}_{i}(w)$，是来自 $M$ 个基础学习器的折外预测的凸组合。权重为 $w = (w_{1}, \\dots, w_{M})$。\n$$\n\\hat{y}_{i}(w) = \\sum_{m=1}^{M} w_{m} p_{i}^{(m)}\n$$\n目标是最小化平方误差损失下的 $K$-折交叉验证风险。该风险 $R_{CV}(w)$ 是所有 $N$ 个观测值的平方误差的平均值。\n$$\nR_{CV}(w) = \\frac{1}{N} \\sum_{i=1}^{N} \\left(y_{i} - \\hat{y}_{i}(w)\\right)^{2}\n$$\n代入 $\\hat{y}_{i}(w)$ 的表达式：\n$$\nR_{CV}(w) = \\frac{1}{N} \\sum_{i=1}^{N} \\left(y_{i} - \\sum_{m=1}^{M} w_{m} p_{i}^{(m)}\\right)^{2}\n$$\n为了用矩阵-向量形式表示，我们定义如下：\n- $Y$：一个 $N \\times 1$ 的观测结果列向量，其中第 $i$ 个元素是 $y_{i}$。\n- $P$：一个 $N \\times M$ 的折外预测矩阵，其中第 $i$ 行第 $m$ 列的元素是 $P_{i m} = p_{i}^{(m)}$。\n- $w$：一个 $M \\times 1$ 的权重列向量，其中第 $m$ 个元素是 $w_{m}$。\n\n所有 $N$ 个观测值的超级学习器预测向量 $\\hat{Y}(w)$ 可以写成矩阵-向量乘积 $Pw$。\n$$\n\\hat{Y}(w) = Pw\n$$\n平方误差之和是残差向量 $Y - Pw$ 的欧几里得范数的平方。\n$$\n\\sum_{i=1}^{N} \\left(y_{i} - \\sum_{m=1}^{M} w_{m} p_{i}^{(m)}\\right)^{2} = \\|Y - Pw\\|_{2}^{2} = (Y - Pw)^{T}(Y - Pw)\n$$\n因此，要最小化的目标函数是：\n$$\nR_{CV}(w) = \\frac{1}{N} \\|Y - Pw\\|_{2}^{2} = \\frac{1}{N} (Y - Pw)^{T}(Y - Pw)\n$$\n问题陈述要求权重形成一个凸组合。这施加了两个约束条件：\n1.  非负性：对于所有 $m \\in \\{1, \\dots, M\\}$，$w_{m} \\ge 0$。\n2.  总和为一：$\\sum_{m=1}^{M} w_{m} = 1$。\n\n完整的矩阵-向量形式的优化问题是：\n$$\n\\underset{w \\in \\mathbb{R}^{M}}{\\text{minimize}} \\quad \\frac{1}{N} (Y - Pw)^{T}(Y - Pw)\n$$\n$$\n\\text{subject to} \\quad w_{m} \\ge 0 \\quad \\text{for } m=1, \\dots, M \\quad \\text{and} \\quad \\mathbf{1}^{T}w = 1\n$$\n其中 $\\mathbf{1}$ 是一个 $M \\times 1$ 的全1向量。\n\n约束条件的理由：\n- 总和为一的约束 $\\sum_{m=1}^{M} w_{m} = 1$ 确保了超级学习器是基础学习器的加权平均。这提供了稳定性，因为对于一个观测值 $i$，最终的预测保证在基础预测的范围 $[\\min_{m} p_{i}^{(m)}, \\max_{m} p_{i}^{(m)}]$ 之内。这可以防止外推，并使模型更具鲁棒性。\n- 非负性约束 $w_{m} \\ge 0$ 在医疗背景下对于可解释性至关重要。每个权重 $w_{m}$ 可以解释为基础学习器 $m$ 对集成模型的正向贡献或重要性。负权重将难以解释，因为它意味着来自基础学习器的较高预测会导致来自集成模型的较低预测，这表明存在一种复杂的“反相关”关系，而这种关系通常不是预测中理想或稳定的特征。\n\n凸性证明：\n目标函数为 $f(w) = \\frac{1}{N} (Y - Pw)^{T}(Y - Pw)$。我们可以展开这个表达式：\n$$\nf(w) = \\frac{1}{N} (Y^{T} - w^{T}P^{T})(Y - Pw) = \\frac{1}{N} (Y^{T}Y - Y^{T}Pw - w^{T}P^{T}Y + w^{T}P^{T}Pw)\n$$\n由于 $w^{T}P^{T}Y$ 是一个标量，它等于其自身的转置，即 $(w^{T}P^{T}Y)^{T} = Y^{T}Pw$。因此，我们有：\n$$\nf(w) = \\frac{1}{N} (w^{T}(P^{T}P)w - 2Y^{T}Pw + Y^{T}Y)\n$$\n这是一个关于 $w$ 的二次函数。为了确定其凸性，我们计算其关于 $w$ 的海森矩阵。梯度为：\n$$\n\\nabla_{w} f(w) = \\frac{1}{N} (2(P^{T}P)w - 2P^{T}Y)\n$$\n海森矩阵 $H$ 是梯度的导数：\n$$\nH = \\nabla_{w}^{2} f(w) = \\frac{2}{N} P^{T}P\n$$\n如果一个函数的海森矩阵是半正定的，则该函数是凸函数。对于任何非零向量 $z \\in \\mathbb{R}^{M}$，我们检验条件 $z^{T}Hz \\ge 0$。\n$$\nz^{T} H z = z^{T} \\left(\\frac{2}{N} P^{T}P\\right) z = \\frac{2}{N} z^{T}P^{T}Pz = \\frac{2}{N} (Pz)^{T}(Pz) = \\frac{2}{N} \\|Pz\\|_{2}^{2}\n$$\n由于欧几里得范数的平方 $\\|Pz\\|_{2}^{2}$ 总是非负的，且 $\\frac{2}{N}$ 是一个正常数，我们有 $z^{T}Hz \\ge 0$。因此，海森矩阵 $H$ 是半正定的，目标函数 $f(w)$ 是凸函数。由线性约束定义的可行域是一个凸集（一个单纯形），因此这是一个凸优化问题。\n\n第2部分：特化到 $M=2$\n\n对于 $M=2$，权重为 $(w_{1}, w_{2})$，约束条件为 $w_{1} \\ge 0$, $w_{2} \\ge 0$, 且 $w_{1} + w_{2} = 1$。总和为一的约束使我们可以写出 $w_{2} = 1 - w_{1}$。对 $w_{1}$ 的约束变为 $w_{1} \\ge 0$ 和 $1-w_{1} \\ge 0$，简化为 $w_{1} \\in [0, 1]$。\n\n要最小化的目标函数是：\n$$\nR_{CV}(w_{1}, w_{2}) = \\frac{1}{N} \\sum_{i=1}^{N} (y_{i} - (w_{1}p_{i}^{(1)} + w_{2}p_{i}^{(2)}))^{2}\n$$\n代入 $w_{2}=1-w_{1}$：\n$$\nf(w_{1}) = \\frac{1}{N} \\sum_{i=1}^{N} (y_{i} - (w_{1}p_{i}^{(1)} + (1-w_{1})p_{i}^{(2)}))^{2} = \\frac{1}{N} \\sum_{i=1}^{N} (y_{i} - p_{i}^{(2)} - w_{1}(p_{i}^{(1)} - p_{i}^{(2)}))^{2}\n$$\n这是一个关于 $w_{1}$ 的二次函数，形式为 $Aw_{1}^{2} - 2Bw_{1} + C$。为了找到无约束最小化器，我们展开并组合包含 $w_{1}$ 的项：\n$$\nf(w_{1}) = w_{1}^{2} \\left(\\frac{1}{N}\\sum_{i=1}^{N}(p_{i}^{(1)} - p_{i}^{(2)})^{2}\\right) - 2w_{1} \\left(\\frac{1}{N}\\sum_{i=1}^{N}(y_{i} - p_{i}^{(2)})(p_{i}^{(1)} - p_{i}^{(2)})\\right) + \\text{const}\n$$\n让我们用给定的充分统计量来表示这些系数：\n$w_{1}^{2}$ 的系数是：\n$$\nA = \\frac{1}{N}\\sum_{i=1}^{N}((p_{i}^{(1)})^{2} - 2p_{i}^{(1)}p_{i}^{(2)} + (p_{i}^{(2)})^{2}) = s_{11} - 2s_{12} + s_{22}\n$$\n$-2w_{1}$ 的系数是：\n$$\nB = \\frac{1}{N}\\sum_{i=1}^{N}(y_{i}p_{i}^{(1)} - y_{i}p_{i}^{(2)} - p_{i}^{(1)}p_{i}^{(2)} + (p_{i}^{(2)})^{2}) = t_{1} - t_{2} - s_{12} + s_{22}\n$$\n为了找到无约束最小值，我们将 $f(w_{1})$ 对 $w_{1}$ 求导，并令结果为零：\n$$\n\\frac{df}{dw_{1}} = 2Aw_{1} - 2B = 0 \\implies w_{1} = \\frac{B}{A}\n$$\n无约束最小化器 $w_{1}^{\\text{unc}}$ 的闭式表达式为：\n$$\nw_{1}^{\\text{unc}} = \\frac{t_{1} - t_{2} - s_{12} + s_{22}}{s_{11} - 2s_{12} + s_{22}}\n$$\n现在，我们代入所提供的数值：\n- $s_{11} = 5$\n- $s_{22} = 4$\n- $s_{12} = 2$\n- $t_{1} = 3$\n- $t_{2} = 2$\n\n首先，计算 $A$ 和 $B$：\n$$\nA = 5 - 2(2) + 4 = 5 - 4 + 4 = 5\n$$\n$$\nB = 3 - 2 - 2 + 4 = 1 - 2 + 4 = 3\n$$\n无约束最小化器是：\n$$\nw_{1}^{\\text{unc}} = \\frac{3}{5}\n$$\n由于目标函数是凸函数（它是一个开口向上的抛物线，因为 $A=5 > 0$），在区间 $[0, 1]$ 上的最小值可以通过检查无约束最小化器是否位于此区间内来找到。\n值 $w_{1}^{\\text{unc}} = \\frac{3}{5}$ 确实在区间 $[0, 1]$ 内。因此，最优约束权重 $w_{1}^{\\star}$ 等于无约束最小化器。\n$$\nw_{1}^{\\star} = \\frac{3}{5}\n$$\n相应的最优权重 $w_{2}^{\\star}$ 是：\n$$\nw_{2}^{\\star} = 1 - w_{1}^{\\star} = 1 - \\frac{3}{5} = \\frac{2}{5}\n$$\n最优权重为 $(w_{1}^{\\star}, w_{2}^{\\star}) = (\\frac{3}{5}, \\frac{2}{5})$。我们验证它们满足约束条件：$w_{1}^{\\star} = \\frac{3}{5} \\ge 0$，$w_{2}^{\\star} = \\frac{2}{5} \\ge 0$，且它们的和为 1。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{3}{5} & \\frac{2}{5}\n\\end{pmatrix}\n}\n$$", "id": "4957971"}]}