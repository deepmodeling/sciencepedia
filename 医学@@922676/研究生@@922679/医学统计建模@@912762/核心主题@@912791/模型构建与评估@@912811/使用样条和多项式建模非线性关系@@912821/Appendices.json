{"hands_on_practices": [{"introduction": "要对非线性关系进行建模，一个有效的起点是多项式回归。该方法通过引入预测变量的高阶项来扩展线性回归，从而能够拟合数据的曲线趋势。第一个实践练习 [@problem_id:4974743] 将指导你完成构建三次多项式模型的关键步骤，并使用普通最小二乘法原理来估计其参数，为掌握更高级的技术奠定坚实的基础。", "problem": "在一项关于抗高血压治疗的临床药理学研究中，研究人员怀疑药物剂量与收缩压降低之间的剂量-反应关系是非线性的。设预测变量为药物剂量（单位：毫克），记为 $x$；响应变量为收缩压的降低值（单位：毫米汞柱），记为 $y$。受多项式非线性建模的启发，考虑使用一个关于标度化剂量变量 $z$（定义为 $z = x / 50$）的三次多项式来近似剂量-反应函数，以改善数值条件。具体来说，将平均响应建模为\n$$\n\\mu(z) = \\beta_{0} + \\beta_{1} z + \\beta_{2} z^{2} + \\beta_{3} z^{3},\n$$\n并假设经典线性模型 $y_{i} = \\mu(z_{i}) + \\varepsilon_{i}$，其中误差 $\\varepsilon_{i}$ 相互独立，满足 $\\mathbb{E}[\\varepsilon_{i}] = 0$ 和 $\\operatorname{Var}(\\varepsilon_{i}) = \\sigma^{2}$（对所有 $i$），$\\sigma^{2}$ 是一个有限正常数。\n\n任务：\n1) 对于 $n$ 个观测值 $\\{(x_{i}, y_{i})\\}_{i=1}^{n}$，使用基 $\\{1, z, z^{2}, z^{3}\\}$ 构建三次多项式模型的设计矩阵，并写出相应的矩阵形式线性模型。\n2) 从最小化残差平方和 $\\sum_{i=1}^{n} (y_{i} - \\mu(z_{i}))^{2}$ 的最小二乘准则出发，推导系数向量 $\\boldsymbol{\\beta} = (\\beta_{0}, \\beta_{1}, \\beta_{2}, \\beta_{3})^{\\top}$ 的普通最小二乘 (OLS) 估计量。\n3) 对于以下 $n = 4$ 个观测值，显式计算 OLS 估计值 $\\hat{\\boldsymbol{\\beta}}$：\n$$\n(x_{1}, y_{1}) = (0, 10), \\quad (x_{2}, y_{2}) = (50, 10), \\quad (x_{3}, y_{3}) = (100, 20), \\quad (x_{4}, y_{4}) = (150, 46).\n$$\n在构建设计矩阵时，使用标度化变量 $z_{i} = x_{i} / 50$。将您的最终答案报告为对应于 $z$ 的多项式的估计系数行向量，顺序为 $(\\hat{\\beta}_{0}, \\hat{\\beta}_{1}, \\hat{\\beta}_{2}, \\hat{\\beta}_{3})$。在最终的数值表达式中不要包含单位。无需四舍五入。", "solution": "首先根据所需准则对问题陈述进行验证。\n\n### 第1步：提取已知条件\n- 预测变量：药物剂量 $x$，单位为毫克。\n- 响应变量：收缩压降低值 $y$，单位为毫米汞柱。\n- 标度化预测变量：$z = x / 50$。\n- 平均响应模型：$\\mu(z) = \\beta_{0} + \\beta_{1} z + \\beta_{2} z^{2} + \\beta_{3} z^{3}$。\n- 统计模型：$y_{i} = \\mu(z_{i}) + \\varepsilon_{i}$，对于观测值 $i=1, \\dots, n$。\n- 误差假设：误差 $\\varepsilon_{i}$ 相互独立，且 $\\mathbb{E}[\\varepsilon_{i}] = 0$ 和 $\\operatorname{Var}(\\varepsilon_{i}) = \\sigma^{2}$，其中 $\\sigma^{2}$ 是一个有限正常数。\n- 系数向量：$\\boldsymbol{\\beta} = (\\beta_{0}, \\beta_{1}, \\beta_{2}, \\beta_{3})^{\\top}$。\n- 任务1：使用基 $\\{1, z, z^{2}, z^{3}\\}$ 构建设计矩阵，并以矩阵形式写出模型。\n- 任务2：通过最小化 $\\sum_{i=1}^{n} (y_{i} - \\mu(z_{i}))^{2}$ 来推导 $\\boldsymbol{\\beta}$ 的普通最小二乘 (OLS) 估计量。\n- 任务3：为 $n = 4$ 个观测值计算 OLS 估计值 $\\hat{\\boldsymbol{\\beta}}$：$(x_{1}, y_{1}) = (0, 10)$、$(x_{2}, y_{2}) = (50, 10)$、$(x_{3}, y_{3}) = (100, 20)$ 和 $(x_{4}, y_{4}) = (150, 46)$。\n\n### 第2步：使用提取的已知条件进行验证\n该问题具有科学依据，在一个合理的背景（药理学）下提出了一个应用统计学（多项式回归）中的标准问题。其假设（经典线性模型）是标准的。问题陈述清晰，提供了完成所要求任务所需的所有信息、定义和数据。问题是客观的，并且可以进行数学形式化。没有矛盾、歧义或事实上的不健全之处。在多项式回归中使用标度化变量是提高数值稳定性的常见且合理的做法。为最终计算所选择的数据点是不同的，这确保了设计矩阵是可逆的。\n\n### 第3步：结论和行动\n问题有效。将提供完整的解答。\n\n***\n\n**1) 设计矩阵和模型的矩阵形式**\n\n单个观测值 $y_i$ 的模型由下式给出：\n$$ y_{i} = \\beta_{0} + \\beta_{1} z_{i} + \\beta_{2} z_{i}^{2} + \\beta_{3} z_{i}^{3} + \\varepsilon_{i} $$\n这可以写成一个包含 $n$ 个线性方程的方程组。对于整个数据集 $\\{(z_{i}, y_{i})\\}_{i=1}^{n}$，我们有：\n$$\n\\begin{cases}\n    y_1 = \\beta_0 \\cdot 1 + \\beta_1 \\cdot z_1 + \\beta_2 \\cdot z_1^2 + \\beta_3 \\cdot z_1^3 + \\varepsilon_1 \\\\\n    y_2 = \\beta_0 \\cdot 1 + \\beta_1 \\cdot z_2 + \\beta_2 \\cdot z_2^2 + \\beta_3 \\cdot z_2^3 + \\varepsilon_2 \\\\\n    \\vdots \\\\\n    y_n = \\beta_0 \\cdot 1 + \\beta_1 \\cdot z_n + \\beta_2 \\cdot z_n^2 + \\beta_3 \\cdot z_n^3 + \\varepsilon_n\n\\end{cases}\n$$\n该方程组可以表示为矩阵形式 $\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}$，其中：\n- $\\mathbf{y} = (y_1, y_2, \\dots, y_n)^{\\top}$ 是观测值的 $n \\times 1$ 向量。\n- $\\boldsymbol{\\beta} = (\\beta_0, \\beta_1, \\beta_2, \\beta_3)^{\\top}$ 是系数的 $4 \\times 1$ 向量。\n- $\\boldsymbol{\\varepsilon} = (\\varepsilon_1, \\varepsilon_2, \\dots, \\varepsilon_n)^{\\top}$ 是随机误差的 $n \\times 1$ 向量。\n- $\\mathbf{X}$ 是 $n \\times 4$ 的设计矩阵，其列对应于在每个数据点 $z_i$ 处求值的基函数 $\\{1, z, z^2, z^3\\}$。$\\mathbf{X}$ 的第 $i$ 行是 $(1, z_i, z_i^2, z_i^3)$。\n\n因此，设计矩阵为：\n$$\n\\mathbf{X} = \\begin{pmatrix}\n1  z_1  z_1^2  z_1^3 \\\\\n1  z_2  z_2^2  z_2^3 \\\\\n\\vdots  \\vdots  \\vdots  \\vdots \\\\\n1  z_n  z_n^2  z_n^3\n\\end{pmatrix}\n$$\n线性模型的矩阵形式为：\n$$\n\\begin{pmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{pmatrix} =\n\\begin{pmatrix}\n1  z_1  z_1^2  z_1^3 \\\\\n1  z_2  z_2^2  z_2^3 \\\\\n\\vdots  \\vdots  \\vdots  \\vdots \\\\\n1  z_n  z_n^2  z_n^3\n\\end{pmatrix}\n\\begin{pmatrix} \\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\\\ \\beta_3 \\end{pmatrix} +\n\\begin{pmatrix} \\varepsilon_1 \\\\ \\varepsilon_2 \\\\ \\vdots \\\\ \\varepsilon_n \\end{pmatrix}\n$$\n\n**2) OLS 估计量的推导**\n\n普通最小二乘 (OLS) 估计量 $\\hat{\\boldsymbol{\\beta}}$ 是使残差平方和 $S(\\boldsymbol{\\beta})$ 最小化的系数向量。残差平方和定义为：\n$$ S(\\boldsymbol{\\beta}) = \\sum_{i=1}^{n} (y_i - \\mu(z_i))^2 = \\sum_{i=1}^{n} (y_i - (\\beta_0 + \\beta_1 z_i + \\beta_2 z_i^2 + \\beta_3 z_i^3))^2 $$\n在矩阵表示法中，残差向量为 $\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}$。残差平方和是该向量的欧几里得范数的平方：\n$$ S(\\boldsymbol{\\beta}) = (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^{\\top}(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}) $$\n展开此表达式可得：\n$$ S(\\boldsymbol{\\beta}) = (\\mathbf{y}^{\\top} - (\\mathbf{X}\\boldsymbol{\\beta})^{\\top})(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}) = \\mathbf{y}^{\\top}\\mathbf{y} - \\mathbf{y}^{\\top}\\mathbf{X}\\boldsymbol{\\beta} - (\\mathbf{X}\\boldsymbol{\\beta})^{\\top}\\mathbf{y} + (\\mathbf{X}\\boldsymbol{\\beta})^{\\top}(\\mathbf{X}\\boldsymbol{\\beta}) $$\n使用性质 $(\\mathbf{A}\\mathbf{B})^{\\top} = \\mathbf{B}^{\\top}\\mathbf{A}^{\\top}$，上式变为：\n$$ S(\\boldsymbol{\\beta}) = \\mathbf{y}^{\\top}\\mathbf{y} - \\mathbf{y}^{\\top}\\mathbf{X}\\boldsymbol{\\beta} - \\boldsymbol{\\beta}^{\\top}\\mathbf{X}^{\\top}\\mathbf{y} + \\boldsymbol{\\beta}^{\\top}\\mathbf{X}^{\\top}\\mathbf{X}\\boldsymbol{\\beta} $$\n由于 $\\mathbf{y}^{\\top}\\mathbf{X}\\boldsymbol{\\beta}$ 是一个 $1 \\times 1$ 矩阵（一个标量），它等于其转置 $(\\mathbf{y}^{\\top}\\mathbf{X}\\boldsymbol{\\beta})^{\\top} = \\boldsymbol{\\beta}^{\\top}\\mathbf{X}^{\\top}\\mathbf{y}$。因此，中间两项是相同的。\n$$ S(\\boldsymbol{\\beta}) = \\mathbf{y}^{\\top}\\mathbf{y} - 2\\boldsymbol{\\beta}^{\\top}\\mathbf{X}^{\\top}\\mathbf{y} + \\boldsymbol{\\beta}^{\\top}(\\mathbf{X}^{\\top}\\mathbf{X})\\boldsymbol{\\beta} $$\n为了找到最小值，我们计算 $S(\\boldsymbol{\\beta})$ 关于 $\\boldsymbol{\\beta}$ 的梯度，并将其设为零向量。对于对称矩阵 $\\mathbf{A}$，使用向量微分的标准结果 $\\frac{\\partial \\mathbf{a}^{\\top}\\mathbf{x}}{\\partial \\mathbf{x}} = \\mathbf{a}$ 和 $\\frac{\\partial \\mathbf{x}^{\\top}\\mathbf{A}\\mathbf{x}}{\\partial \\mathbf{x}} = 2\\mathbf{A}\\mathbf{x}$（注意 $\\mathbf{X}^{\\top}\\mathbf{X}$ 是对称的）：\n$$ \\frac{\\partial S(\\boldsymbol{\\beta})}{\\partial \\boldsymbol{\\beta}} = -2\\mathbf{X}^{\\top}\\mathbf{y} + 2(\\mathbf{X}^{\\top}\\mathbf{X})\\boldsymbol{\\beta} $$\n将梯度设为零向量以找到临界点，该点对应于 OLS 估计值 $\\hat{\\boldsymbol{\\beta}}$：\n$$ -2\\mathbf{X}^{\\top}\\mathbf{y} + 2(\\mathbf{X}^{\\top}\\mathbf{X})\\hat{\\boldsymbol{\\beta}} = \\mathbf{0} $$\n$$ (\\mathbf{X}^{\\top}\\mathbf{X})\\hat{\\boldsymbol{\\beta}} = \\mathbf{X}^{\\top}\\mathbf{y} $$\n这组方程被称为正规方程组。假设矩阵 $\\mathbf{X}^{\\top}\\mathbf{X}$ 是可逆的（如果 $\\mathbf{X}$ 的列线性无关，则该条件成立），我们可以通过左乘 $(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}$ 来求解 $\\hat{\\boldsymbol{\\beta}}$：\n$$ \\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{X}^{\\top}\\mathbf{y} $$\n这是 OLS 估计量的一般公式。$S(\\boldsymbol{\\beta})$ 的二阶导数（Hessian）矩阵是 $2\\mathbf{X}^{\\top}\\mathbf{X}$，如果 $\\mathbf{X}$ 是满列秩的，则该矩阵是正定的，这证实了此解对应于一个最小值。\n\n**3) OLS 估计值的计算**\n\n我们给定 $n=4$ 个数据点：$(0, 10)$、$(50, 10)$、$(100, 20)$、$(150, 46)$。\n首先，我们计算标度化预测变量 $z_i = x_i / 50$：\n$$\nz_1 = 0 / 50 = 0 \\\\\nz_2 = 50 / 50 = 1 \\\\\nz_3 = 100 / 50 = 2 \\\\\nz_4 = 150 / 50 = 3\n$$\n响应向量为 $\\mathbf{y} = (10, 10, 20, 46)^{\\top}$。\n观测数量为 $n=4$，三次模型中的参数数量为 $p=4$（对应 $\\beta_0, \\beta_1, \\beta_2, \\beta_3$）。由于 $n=p$，设计矩阵 $\\mathbf{X}$ 是一个方阵。\n$$\n\\mathbf{X} = \\begin{pmatrix}\n1  z_1  z_1^2  z_1^3 \\\\\n1  z_2  z_2^2  z_2^3 \\\\\n1  z_3  z_3^2  z_3^3 \\\\\n1  z_4  z_4^2  z_4^3\n\\end{pmatrix} = \\begin{pmatrix}\n1  0  0  0 \\\\\n1  1  1  1 \\\\\n1  2  4  8 \\\\\n1  3  9  27\n\\end{pmatrix}\n$$\n这是一个具有不同点 $z_i$ 的范德蒙矩阵，因此它是可逆的。在 $n=p$ 且 $\\mathbf{X}$ 可逆的特殊情况下，OLS 估计量公式简化为：\n$$ \\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{X}^{\\top}\\mathbf{y} = \\mathbf{X}^{-1}(\\mathbf{X}^{\\top})^{-1}\\mathbf{X}^{\\top}\\mathbf{y} = \\mathbf{X}^{-1}\\mathbf{y} $$\n这表示拟合的多项式将精确地穿过所有四个数据点（插值）。我们需要求 $\\mathbf{X}$ 的逆矩阵。使用诸如高斯-若尔当消元法等方法，求得逆矩阵为：\n$$ \\mathbf{X}^{-1} = \\begin{pmatrix} 1  0  0  0 \\\\ -\\frac{11}{6}   3  -\\frac{3}{2}  \\frac{1}{3} \\\\ 1  -\\frac{5}{2}  2  -\\frac{1}{2} \\\\ -\\frac{1}{6}  \\frac{1}{2}  -\\frac{1}{2}  \\frac{1}{6} \\end{pmatrix} $$\n现在我们计算 $\\hat{\\boldsymbol{\\beta}} = \\mathbf{X}^{-1}\\mathbf{y}$：\n$$\n\\hat{\\boldsymbol{\\beta}} = \\begin{pmatrix} \\hat{\\beta}_0 \\\\ \\hat{\\beta}_1 \\\\ \\hat{\\beta}_2 \\\\ \\hat{\\beta}_3 \\end{pmatrix} = \\begin{pmatrix} 1  0  0  0 \\\\ -\\frac{11}{6}   3  -\\frac{3}{2}  \\frac{1}{3} \\\\ 1  -\\frac{5}{2}  2  -\\frac{1}{2} \\\\ -\\frac{1}{6}  \\frac{1}{2}  -\\frac{1}{2}  \\frac{1}{6} \\end{pmatrix} \\begin{pmatrix} 10 \\\\ 10 \\\\ 20 \\\\ 46 \\end{pmatrix}\n$$\n执行矩阵-向量乘法：\n$$ \\hat{\\beta}_0 = 1 \\cdot 10 + 0 \\cdot 10 + 0 \\cdot 20 + 0 \\cdot 46 = 10 $$\n$$ \\hat{\\beta}_1 = -\\frac{11}{6} \\cdot 10 + 3 \\cdot 10 - \\frac{3}{2} \\cdot 20 + \\frac{1}{3} \\cdot 46 = -\\frac{110}{6} + 30 - 30 + \\frac{46}{3} = -\\frac{55}{3} + \\frac{46}{3} = -\\frac{9}{3} = -3 $$\n$$ \\hat{\\beta}_2 = 1 \\cdot 10 - \\frac{5}{2} \\cdot 10 + 2 \\cdot 20 - \\frac{1}{2} \\cdot 46 = 10 - 25 + 40 - 23 = 50 - 48 = 2 $$\n$$ \\hat{\\beta}_3 = -\\frac{1}{6} \\cdot 10 + \\frac{1}{2} \\cdot 10 - \\frac{1}{2} \\cdot 20 + \\frac{1}{6} \\cdot 46 = -\\frac{10}{6} + 5 - 10 + \\frac{46}{6} = -5 + \\frac{36}{6} = -5 + 6 = 1 $$\n系数向量的 OLS 估计值为 $\\hat{\\boldsymbol{\\beta}} = (10, -3, 2, 1)^{\\top}$。问题要求将结果表示为行向量。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n10  -3  2  1\n\\end{pmatrix}\n}\n$$", "id": "4974743"}, {"introduction": "尽管全局多项式很有用，但它们的刚性有时会成为一个缺点。样条通过在数据的不同区域拟合独立的低阶多项式，并在称为“节点”的点上平滑地连接它们，提供了一种更灵活、更具局部适应性的替代方案。这个高级编码练习 [@problem_id:4974778] 要求你从零开始实现自然三次样条，这是现代非参数回归中的一项基石技术，它能提供出色的拟合效果，同时确保在数据边缘具有合理的行为。", "problem": "给定患者年龄和空腹低密度脂蛋白胆固醇的成对观测值，记为 $\\{(x_i,y_i)\\}_{i=1}^n$。您将使用普通最小二乘法拟合一个以胆固醇为年龄函数的自然三次回归样条，其内部节点选择为年龄的经验分位数。目标是针对多个测试数据集，计算年龄为 $40$、$60$ 和 $80$ 岁时的胆固醇拟合值，单位为毫克/分升 (mg/dL)。\n\n基本基函数与模型设定：\n- 设 $f(x)$ 是一个回归函数，通过最小化残差平方和 $\\sum_{i=1}^n (y_i - f(x_i))^2$ 从数据中估计得出。\n- 考虑一个具有内部节点 $\\kappa_1, \\kappa_2, \\dots, \\kappa_K$ 的三次回归样条空间，其中 $\\kappa_j$ 是观测年龄的经验分位数。自然三次样条施加了边界条件，即函数在边界节点之外的二阶导数为零。\n- 使用以下表示法\n$$\nf(x) \\;=\\; \\beta_0 + \\beta_1 x \\;+\\; \\sum_{j=1}^{K} \\theta_j \\,(x - \\kappa_j)_+^3,\n$$\n并服从以下线性约束\n$$\n\\sum_{j=1}^{K} \\theta_j \\;=\\; 0, \\qquad \\sum_{j=1}^{K} \\theta_j \\,\\kappa_j \\;=\\; 0,\n$$\n这些约束强制施加了自然边界条件（即在两端节点之外二阶导数为零）。此处 $(\\cdot)_+ = \\max\\{\\cdot,0\\}$。\n- 通过普通最小二乘法，最小化 $\\sum_{i=1}^n (y_i - f(x_i))^2$ 来拟合参数，使用一种通过参数化满足约束的基构造方法。具体而言，记 $d_j(x) = (x-\\kappa_j)_+^3$，并设 $\\mathbf{A}$ 是一个 $2 \\times K$ 矩阵，其第一行为全1，第二行为 $(\\kappa_1,\\dots,\\kappa_K)$。设 $\\mathbf{N}$ 是任意一个 $K \\times (K-2)$ 矩阵，其列向量构成 $\\mathbf{A}$ 的零空间的一组基；等价地，$\\mathbf{A}\\mathbf{N} = \\mathbf{0}$。那么，自然三次样条的基可以取为 $\\{1, x, \\sum_{j=1}^K N_{j1} d_j(x), \\dots, \\sum_{j=1}^K N_{j,K-2} d_j(x)\\}$，这保证了对于任意系数，约束条件都成立。\n\n基于分位数的节点选择：\n- 使用年龄经验分位数的内部节点，其概率为 $0.2$、$0.4$、$0.6$ 和 $0.8$。\n- 如果出现重复的分位数，则简化为严格递增的唯一节点集合。如果去重后唯一的内部节点少于 $2$ 个（即 $K  2$），则自然三次样条退化为线性模型 $f(x) = \\beta_0 + \\beta_1 x$。\n\n数值计算细节：\n- 使用上述基函数构造设计矩阵，并通过普通最小二乘法估计参数。\n- 对每个数据集，计算并报告 $f(40)$、$f(60)$ 和 $f(80)$ 的值。\n- 所有报告的胆固醇值必须以毫克/分升 (mg/dL) 为单位。不要在打印输出中包含单位；此处的单位说明已足够。\n\n测试套件：\n实现您的程序以评估以下三个数据集，其中年龄单位为年，胆固醇单位为 mg/dL。对于每种情况，确定性地构造指定的 $\\{x_i\\}$ 和 $y_i$。\n\n- 测试用例A（一般平滑非线性，宽泛的年龄覆盖范围）：\n  - 年龄：$X_A = \\{30,31,32,\\dots,90\\}$（含端点），所以 $n = 61$。\n  - 胆固醇：对于每个 $x \\in X_A$，定义\n    $$\n    y \\;=\\; 180 \\;+\\; 0.6\\,(x-60) \\;-\\; 0.02\\,(x-60)^2 \\;+\\; 0.0003\\,(x-60)^3.\n    $$\n\n- 测试用例B（少数几个年龄点上有强重复值）：\n  - 年龄：$X_B$ 包含 $10$ 个 $40$ 的重复值、$10$ 个 $60$ 的重复值和 $10$ 个 $80$ 的重复值，所以 $n = 30$。\n  - 胆固醇：对于每个 $x \\in X_B$，定义\n    $$\n    y \\;=\\; 195 \\;+\\; 0.8\\,(x-60) \\;-\\; 0.015\\,(x-60)^2.\n    $$\n\n- 测试用例C（年龄聚集在两端，可能出现节点退化）：\n  - 年龄：$X_C$ 由 $25$ 个 $40$ 的重复值、$10$ 个 $41$ 的重复值、$5$ 个 $42$ 的重复值、$5$ 个 $78$ 的重复值、$10$ 个 $79$ 的重复值和 $25$ 个 $80$ 的重复值构成，所以 $n = 80$。\n  - 胆固醇：对于每个 $x \\in X_C$，定义\n    $$\n    y \\;=\\; 175 \\;+\\; 0.4\\,(x-60) \\;+\\; 0.002\\,(x-60)^3.\n    $$\n\n评估目标：\n- 对于每个测试用例，使用拟合的自然三次样条计算拟合值 $f(40)$、$f(60)$ 和 $f(80)$，其内部节点位于相应年龄样本的经验分位数 $0.2$、$0.4$、$0.6$ 和 $0.8$ 处，并按所述进行去重。如果剩余的唯一内部节点少于 $2$ 个，则拟合线性模型 $f(x) = \\beta_0 + \\beta_1 x$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含九个结果，按 $[f_A(40), f_A(60), f_A(80), f_B(40), f_B(60), f_B(80), f_C(40), f_C(60), f_C(80)]$ 的顺序排列，以逗号分隔的列表形式打印在方括号内，值为纯数字。这些是单位为 mg/dL 的胆固醇值。", "solution": "该问题被评估为有效。它在科学上基于样条回归理论，这是统计建模中的一个标准课题。该问题是良定的，所有数据、模型设定、节点选择标准和估计算法都得到了明确无误的定义。测试用例是确定性的，整个问题是客观且可验证的。\n\n任务是为三个不同的年龄和胆固醇数据集拟合自然三次回归样条，然后计算在年龄为 $40$、$60$ 和 $80$ 岁时的胆固醇拟合值。解决方案涉及几个步骤：为每个测试用例生成数据，基于经验分位数选择内部节点，为包含边界约束的自然三次样条构建合适的基，通过普通最小二乘法 (OLS) 估计模型参数，最后在目标年龄点进行预测。\n\n首先，对于每个测试用例，根据提供的公式生成成对观测值 $\\{(x_i, y_i)\\}_{i=1}^n$。这里，$x_i$ 代表年龄，$y_i$ 代表低密度脂蛋白胆固醇。\n\n第二步是确定内部节点 $\\{\\kappa_j\\}_{j=1}^K$。问题指定使用观测年龄 $\\{x_i\\}$ 在概率为 $0.2$、$0.4$、$0.6$ 和 $0.8$ 处的经验分位数。计算这些分位数后，去除重复值以得到一个由 $K$ 个唯一节点组成的严格递增集合。问题规定了一个退化条件：如果去重后剩余的节点少于 $2$ 个（即 $K  2$），则必须拟合一个简单的线性模型 $f(x) = \\beta_0 + \\beta_1 x$ 而不是样条模型。对于所提供的所有三个测试用例，这个条件都不满足，因此样条模型是适用的。\n\n问题的核心在于自然三次样条基的构建。自然三次样条是一种三次样条，它有一个附加约束，即函数在边界节点之外是线性的。这等同于二阶导数在边界处为零。模型表示为：\n$$\nf(x) = \\beta_0 + \\beta_1 x + \\sum_{j=1}^{K} \\theta_j d_j(x), \\quad \\text{其中 } d_j(x) = (x - \\kappa_j)_+^3\n$$\n符号 $(u)_+$ 代表 $u$ 的正部，即 $\\max\\{u, 0\\}$。对参数 $\\theta_j$ 的自然样条约束是：\n$$\n\\sum_{j=1}^{K} \\theta_j = 0 \\quad \\text{和} \\quad \\sum_{j=1}^{K} \\theta_j \\kappa_j = 0\n$$\n为了将这些约束直接纳入基中，我们使用重参数化。设 $\\boldsymbol{\\theta} = (\\theta_1, \\dots, \\theta_K)^T$。约束可以写成 $\\mathbf{A}\\boldsymbol{\\theta} = \\mathbf{0}$，其中 $\\mathbf{A}$ 是 $2 \\times K$ 矩阵：\n$$\n\\mathbf{A} = \\begin{pmatrix} 1  1  \\cdots  1 \\\\ \\kappa_1  \\kappa_2  \\cdots  \\kappa_K \\end{pmatrix}\n$$\n任何满足这些约束的向量 $\\boldsymbol{\\theta}$ 都必须位于 $\\mathbf{A}$ 的零空间中。设 $\\mathbf{N}$ 是一个 $K \\times (K-2)$ 矩阵，其列构成了这个零空间的一个基。那么我们可以写成 $\\boldsymbol{\\theta} = \\mathbf{N}\\boldsymbol{\\gamma}$，其中 $\\boldsymbol{\\gamma} = (\\gamma_1, \\dots, \\gamma_{K-2})^T$ 是一个新参数向量。将此代入模型方程得到：\n$$\nf(x) = \\beta_0 + \\beta_1 x + \\sum_{j=1}^{K} (\\mathbf{N}\\boldsymbol{\\gamma})_j d_j(x) = \\beta_0 + \\beta_1 x + \\sum_{k=1}^{K-2} \\gamma_k \\left( \\sum_{j=1}^K N_{jk} d_j(x) \\right)\n$$\n这定义了一组新的 $K-2$ 个基函数 $B_k(x) = \\sum_{j=1}^K N_{jk} d_j(x)$。模型的完整基函数集是 $\\{1, x, B_1(x), \\dots, B_{K-2}(x)\\}$。需要估计的参数总数为 $2 + (K-2) = K$。\n\n利用这个基，我们为 OLS 回归构建 $n \\times K$ 的设计矩阵 $\\mathbf{X}$。$\\mathbf{X}$ 的第 $i$ 行对应于观测值 $x_i$，由 $[1, x_i, B_1(x_i), \\dots, B_{K-2}(x_i)]$ 给出。设 $\\boldsymbol{\\beta} = (\\beta_0, \\beta_1, \\gamma_1, \\dots, \\gamma_{K-2})^T$ 为系数向量。我们通过最小化残差平方和 $\\|\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}\\|^2$ 来找到 OLS 估计 $\\hat{\\boldsymbol{\\beta}}$，其解为 $\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{\\dagger}\\mathbf{X}^T\\mathbf{y}$，其中 $(\\cdot)^{\\dagger}$ 表示 Moore-Penrose 伪逆，通常通过像奇异值分解这样的稳定数值方法来计算。\n\n最后，为了预测一个新年龄 $x_{new}$ 的胆固醇值，我们构建一个对应的行向量 $\\mathbf{x}_{new}^T = [1, x_{new}, B_1(x_{new}), \\dots, B_{K-2}(x_{new})]$，并计算拟合值 $\\hat{f}(x_{new}) = \\mathbf{x}_{new}^T \\hat{\\boldsymbol{\\beta}}$。对每个测试用例，该过程应用于 $x_{new} = 40, 60, 80$。\n\n- **测试用例 A**：年龄 $X_A = \\{30, 31, \\dots, 90\\}$。分位数计算得出 $K=4$ 个唯一节点，位于 $\\{42.0, 54.0, 66.0, 78.0\\}$。模型有 $K=4$ 个参数。\n- **测试用例 B**：年龄 $X_B$ 由 $\\{40, 60, 80\\}$ 各 $10$ 个重复值组成。分位数计算得出原始节点为 $\\{40.0, 60.0, 60.0, 80.0\\}$，去重后得到 $K=3$ 个唯一节点，位于 $\\{40.0, 60.0, 80.0\\}$。模型有 $K=3$ 个参数。由于数据中只有 $3$ 个唯一的年龄值，这个 $3$ 参数模型能够对这些年龄点的平均胆固醇值提供精确拟合。\n- **测试用例 C**：年龄 $X_C$ 是聚集的。分位数计算得出 $K=4$ 个唯一节点，位于 $\\{40.0, 41.0, 79.0, 80.0\\}$。模型有 $K=4$ 个参数。\n\n该实现使用 `numpy` 进行数值计算，并使用 `scipy.linalg.null_space` 来找到约束矩阵零空间的基 $\\mathbf{N}$。", "answer": "```python\nimport numpy as np\nfrom scipy.linalg import null_space\n\ndef fit_and_predict_spline(x_obs, y_obs, x_pred):\n    \"\"\"\n    Fits a natural cubic spline and predicts at new data points.\n    \n    Args:\n        x_obs (np.ndarray): Observed independent variable values (ages).\n        y_obs (np.ndarray): Observed dependent variable values (cholesterol).\n        x_pred (np.ndarray): Points at which to predict.\n\n    Returns:\n        np.ndarray: Predicted values at x_pred.\n    \"\"\"\n    knot_probs = [0.2, 0.4, 0.6, 0.8]\n    knots_raw = np.quantile(x_obs, knot_probs, method='linear')\n    unique_knots = sorted(list(set(knots_raw)))\n    K = len(unique_knots)\n\n    n_obs = len(x_obs)\n    n_pred = len(x_pred)\n\n    # Degeneracy condition: if K  2, fit a simple linear model.\n    if K  2:\n        # Design matrix for linear model (intercept and slope)\n        X_obs = np.vander(x_obs, 2, increasing=True)\n        # Solve for coefficients using least squares\n        coeffs, _, _, _ = np.linalg.lstsq(X_obs, y_obs, rcond=None)\n        # Prediction matrix\n        X_pred_mat = np.vander(x_pred, 2, increasing=True)\n        # Predict\n        y_pred = X_pred_mat @ coeffs\n        return y_pred\n\n    # Natural cubic spline model (K >= 2)\n    # The basis has K functions: {1, x, B_1(x), ..., B_{K-2}(x)}\n    \n    # Construct the D matrix from truncated power basis functions\n    # d_j(x) = (x - k_j)_+^3\n    knots_arr = np.array(unique_knots)\n    D_obs = np.maximum(0, x_obs[:, None] - knots_arr)**3\n    \n    # Construct constraint matrix A\n    A = np.ones((2, K))\n    A[1, :] = knots_arr\n    \n    # Find N, a basis for the null space of A.\n    # For K=2, N will be a 2x0 empty matrix.\n    if K > 2:\n        N = null_space(A)\n    else: # K=2\n        N = np.empty((K, 0))\n    \n    # Construct the full design matrix X\n    X_obs = np.zeros((n_obs, K))\n    X_obs[:, 0] = 1.0  # Intercept\n    X_obs[:, 1] = x_obs  # Linear term\n    if K > 2:\n        X_obs[:, 2:] = D_obs @ N  # Spline basis functions\n\n    # Solve for coefficients using least squares\n    coeffs, _, _, _ = np.linalg.lstsq(X_obs, y_obs, rcond=None)\n    \n    # Perform prediction\n    # Construct D matrix for prediction points\n    D_pred = np.maximum(0, x_pred[:, None] - knots_arr)**3\n    \n    # Construct prediction matrix\n    X_pred_mat = np.zeros((n_pred, K))\n    X_pred_mat[:, 0] = 1.0\n    X_pred_mat[:, 1] = x_pred\n    if K > 2:\n        X_pred_mat[:, 2:] = D_pred @ N\n\n    y_pred = X_pred_mat @ coeffs\n    return y_pred\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    eval_ages = np.array([40, 60, 80])\n    all_results = []\n\n    # Test Case A\n    x_a = np.arange(30, 91, dtype=float)\n    y_a = 180.0 + 0.6 * (x_a - 60.0) - 0.02 * (x_a - 60.0)**2 + 0.0003 * (x_a - 60.0)**3\n    results_a = fit_and_predict_spline(x_a, y_a, eval_ages)\n    all_results.extend(results_a)\n\n    # Test Case B\n    x_b = np.repeat([40.0, 60.0, 80.0], 10)\n    y_b = 195.0 + 0.8 * (x_b - 60.0) - 0.015 * (x_b - 60.0)**2\n    results_b = fit_and_predict_spline(x_b, y_b, eval_ages)\n    all_results.extend(results_b)\n\n    # Test Case C\n    x_c = np.concatenate([\n        np.repeat(40.0, 25),\n        np.repeat(41.0, 10),\n        np.repeat(42.0, 5),\n        np.repeat(78.0, 5),\n        np.repeat(79.0, 10),\n        np.repeat(80.0, 25)\n    ])\n    y_c = 175.0 + 0.4 * (x_c - 60.0) + 0.002 * (x_c - 60.0)**3\n    results_c = fit_and_predict_spline(x_c, y_c, eval_ages)\n    all_results.extend(results_c)\n\n    # Format and print the final output string\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "4974778"}, {"introduction": "拥有创建高度灵活模型的能力，也带来了选择合适复杂度和避免过拟合的关键挑战。我们如何在简单线性模型、三次多项式或更复杂的模型之间做出选择？最后的这个实践练习 [@problem_id:4974757] 将介绍K折交叉验证，这是一种用于估计模型样本外预测性能的基本而强大的技术。通过完成此练习，你将获得使用交叉验证为给定数据集选择最佳多项式次数的实践经验，这是任何建模从业者都必须掌握的关键技能。", "problem": "考虑在人群研究中将血红蛋白浓度建模为年龄的函数，这是在医学统计建模中探索非线性关系时的一项常见任务。你需要实现多项式回归模型，并使用$K$折交叉验证（KCV）对几种不同的$K$值评估其预测性能。\n\n给定一个年龄数组和一个相应的血红蛋白数组，这些数组由一个生理学上合理的非线性函数确定性地定义。设观测数量为$n=40$。年龄（单位：年）为\n$$\n\\{a_i\\}_{i=1}^{40} = [0.5, 1, 1.5, 2.5, 4, 6, 8, 10, 12, 14, 15, 16, 17, 18, 20, 22, 25, 28, 32, 36, 40, 45, 50, 52, 55, 58, 60, 62, 65, 68, 70, 72, 75, 78, 80, 82, 85, 88, 90, 92]。\n$$\n测得的血红蛋白（单位：克/分升，$\\mathrm{g/dL}$）对每个$i=1,\\dots,40$定义为\n$$\nh_i = 12.5 + \\frac{2}{1+\\exp\\!\\big(-0.35(a_i - 16)\\big)} - 0.0025 \\cdot \\max(0, a_i - 65)^2 + 0.35 \\sin(0.12 a_i) + 0.15 \\cos(0.27 a_i).\n$$\n此设计的目的是反映青春期前后的典型增长和老年时期的逐渐下降，同时保持在临床合理范围内。\n\n你必须将血红蛋白建模为年龄的多项式回归，其阶数$d \\in \\{1,2,3,4\\}$。对于给定的阶数$d$，模型为\n$$\n\\hat{f}_d(a) = \\beta_0 + \\beta_1 \\tilde{a} + \\beta_2 \\tilde{a}^2 + \\cdots + \\beta_d \\tilde{a}^d,\n$$\n其中$\\tilde{a}$是在每一折的训练集内计算的年龄的标准化版本，定义为\n$$\n\\mu_S = \\frac{1}{|S|}\\sum_{j\\in S} a_j, \\quad \\sigma_S = \\sqrt{\\frac{1}{|S|}\\sum_{j\\in S} (a_j - \\mu_S)^2}, \\quad \\tilde{a}_j = \\frac{a_j - \\mu_S}{\\sigma_S},\n$$\n其中$S$表示给定一折的训练索引。通过普通最小二乘法（OLS）拟合$\\{\\beta_k\\}_{k=0}^d$，即通过最小化训练数据上的残差平方和。将一组测试索引$T$的均方误差（MSE）定义为\n$$\n\\mathrm{MSE} = \\frac{1}{|T|}\\sum_{i\\in T} \\left(h_i - \\hat{f}_d(a_i)\\right)^2,\n$$\n其单位为$(\\mathrm{g/dL})^2$。\n\n使用$K$折交叉验证，并采用确定性分折规则\n$$\nF(i) = (i-1) \\bmod K,\n$$\n这意味着第$i$个观测（在此定义中使用从1开始的索引）属于第$F(i)$折，其中折的索引为$0,1,\\dots,K-1$。对于每一折$k$，在训练集$S_k = \\{i : F(i) \\neq k\\}$上拟合模型，并在测试集$T_k = \\{i : F(i) = k\\}$上进行评估。阶数为$d$、折数为$K$的交叉验证误差为\n$$\n\\mathrm{MSE}_{K,d} = \\frac{1}{n}\\sum_{k=0}^{K-1} \\sum_{i\\in T_k} \\left(h_i - \\hat{f}_{-k,d}(a_i)\\right)^2,\n$$\n其中$\\hat{f}_{-k,d}$表示仅使用训练数据$S_k$以及从$S_k$计算出的标准化参数$\\mu_{S_k}, \\sigma_{S_k}$所估计的模型。\n\n为$K$值的测试套件实现此过程：\n$$\nK \\in \\{2, 5, 10, 40\\},\n$$\n并为每个$K$计算阶数$d \\in \\{1,2,3,4\\}$的$\\mathrm{MSE}_{K,d}$。\n$$\nd \\in \\{1,2,3,4\\}.\n$$\n\n科学真实性和方法论严谨性要求：\n- 模型拟合必须仅基于训练折使用OLS。\n- 标准化参数$\\mu_S$和$\\sigma_S$必须在每一折内使用训练数据计算，然后应用于该折内相应的测试数据。\n- 分折必须严格遵守规则$F(i) = (i-1) \\bmod K$以确保确定性划分。\n- 所有交叉验证误差均以$(\\mathrm{g/dL})^2$表示。\n- $\\sin$和$\\cos$函数的角度单位必须是弧度。\n\n你的程序应产生单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，按$K$升序排列，并在每个$K$内按$d=1,2,3,4$的顺序排列。将输出格式化为列表的列表：\n$$\n[\\,[\\mathrm{MSE}_{2,1},\\mathrm{MSE}_{2,2},\\mathrm{MSE}_{2,3},\\mathrm{MSE}_{2,4}],\\,[\\mathrm{MSE}_{5,1},\\mathrm{MSE}_{5,2},\\mathrm{MSE}_{5,3},\\mathrm{MSE}_{5,4}],\\,[\\mathrm{MSE}_{10,1},\\mathrm{MSE}_{10,2},\\mathrm{MSE}_{10,3},\\mathrm{MSE}_{10,4}],\\,[\\mathrm{MSE}_{40,1},\\mathrm{MSE}_{40,2},\\mathrm{MSE}_{40,3},\\mathrm{MSE}_{40,4}]\\,],\n$$\n每个数值条目四舍五入到六位小数。例如，一个有效的输出可能看起来像\n$$\n[[x_{2,1},x_{2,2},x_{2,3},x_{2,4}],[x_{5,1},x_{5,2},x_{5,3},x_{5,4}],[x_{10,1},x_{10,2},x_{10,3},x_{10,4}],[x_{40,1},x_{40,2},x_{40,3},x_{40,4}]],\n$$\n其中每个$x_{K,d}$是一个代表$(\\mathrm{g/dL})^2$的浮点数。", "solution": "该问题是有效的，因为它具有科学依据，定义明确且自洽。所有数据、参数和程序都已明确定义，从而可以得到唯一且可验证的计算解。\n\n目标是评估多项式回归模型在根据年龄预测血红蛋白浓度方面的性能。评估使用$K$折交叉验证进行，针对一组多项式阶数$d \\in \\{1,2,3,4\\}$和一组折数$K \\in \\{2, 5, 10, 40\\}$。性能指标是交叉验证的均方误差（$\\mathrm{MSE}$）。\n\n首先，我们生成包含$n=40$个观测值的数据集。年龄$\\{a_i\\}_{i=1}^{40}$已提供。相应的血红蛋白浓度$\\{h_i\\}_{i=1}^{40}$使用以下确定性函数计算：\n$$\nh_i = 12.5 + \\frac{2}{1+\\exp(-0.35(a_i - 16))} - 0.0025 \\cdot \\max(0, a_i - 65)^2 + 0.35 \\sin(0.12 a_i) + 0.15 \\cos(0.27 a_i)\n$$\n其中三角函数$\\sin$和$\\cos$的角度单位为弧度。\n\n该方法的核心是$K$折交叉验证。对于给定的折数$K$，包含$n=40$个观测值的数据集被划分为$K$个不相交的子集，称为折。第$i$个观测（使用从$1$开始的索引）分配到哪一折由规则$F(i) = (i-1) \\bmod K$决定，其中折的索引从$0$到$K-1$。\n\n该过程是迭代的。对于每一折$k \\in \\{0, 1, \\dots, K-1\\}$，我们定义测试集$T_k = \\{i : F(i) = k\\}$和训练集$S_k$（包含所有其他观测值）。模型在$S_k$上训练，并在$T_k$上评估。对所有$K$折重复此过程。\n\n对于每一折$k$和多项式阶数$d$，执行以下步骤：\n1.  **数据标准化**：一个关键步骤是对预测变量——年龄进行标准化。年龄的均值$\\mu_{S_k}$和标准差$\\sigma_{S_k}$*仅*使用$S_k$中的训练数据计算：\n    $$\n    \\mu_{S_k} = \\frac{1}{|S_k|}\\sum_{j\\in S_k} a_j, \\quad \\sigma_{S_k} = \\sqrt{\\frac{1}{|S_k|}\\sum_{j\\in S_k} (a_j - \\mu_{S_k})^2}\n    $$\n    然后，这些参数用于标准化当前折的训练和测试年龄：$\\tilde{a}_j = (a_j - \\mu_{S_k}) / \\sigma_{S_k}$。这种严格区分训练和测试数据的方式可以防止信息泄露。\n\n2.  **模型构建**：血红蛋白浓度被建模为标准年龄$\\tilde{a}$的$d$阶多项式：\n    $$\n    \\hat{f}_{-k,d}(\\tilde{a}) = \\beta_0 + \\beta_1 \\tilde{a} + \\beta_2 \\tilde{a}^2 + \\cdots + \\beta_d \\tilde{a}^d = \\sum_{j=0}^{d} \\beta_j \\tilde{a}^j\n    $$\n    模型$\\hat{f}_{-k,d}$的索引为$-k$，表示它在训练时未使用第$k$折。\n\n3.  **模型拟合**：系数向量$\\boldsymbol{\\beta} = [\\beta_0, \\beta_1, \\dots, \\beta_d]^T$通过普通最小二乘法（OLS）确定。这涉及求解线性系统$X_{\\text{train}} \\boldsymbol{\\beta} = \\mathbf{h}_{\\text{train}}$，其中$\\mathbf{h}_{\\text{train}}$是训练集$S_k$中血红蛋白值的向量。设计矩阵$X_{\\text{train}}$是根据标准化的训练年龄构建的范德蒙矩阵：\n    $$\n    X_{\\text{train}} = \\begin{pmatrix}\n    1  \\tilde{a}_1  \\tilde{a}_1^2  \\cdots  \\tilde{a}_1^d \\\\\n    1  \\tilde{a}_2  \\tilde{a}_2^2  \\cdots  \\tilde{a}_2^d \\\\\n    \\vdots  \\vdots  \\vdots  \\ddots  \\vdots \\\\\n    1  \\tilde{a}_{|S_k|}  \\tilde{a}_{|S_k|}^2  \\cdots  \\tilde{a}_{|S_k|}^d\n    \\end{pmatrix}\n    $$\n    OLS解为$\\hat{\\boldsymbol{\\beta}} = (X_{\\text{train}}^T X_{\\text{train}})^{-1} X_{\\text{train}}^T \\mathbf{h}_{\\text{train}}$，该解通过稳定的线性最小二乘求解器进行数值计算。\n\n4.  **预测与误差计算**：由系数$\\hat{\\boldsymbol{\\beta}}$定义的拟合模型用于为测试集$T_k$中的每个观测$i$生成预测值$\\hat{h}_i$。每个预测的平方误差计算为$(h_i - \\hat{h}_i)^2$。\n\n在遍历所有$K$折的循环完成后，对于$n$个观测中的每一个，都已计算出一个平方误差，每次都是使用一个未在该特定观测上训练过的模型计算的。\n\n对于给定的$K$和$d$，最终的交叉验证均方误差是这$n$个单独平方误差的平均值：\n$$\n\\mathrm{MSE}_{K,d} = \\frac{1}{n}\\sum_{k=0}^{K-1} \\sum_{i\\in T_k} \\left(h_i - \\hat{f}_{-k,d}(a_i)\\right)^2 = \\frac{1}{n} \\sum_{i=1}^{n} (h_i - \\hat{h}_i)^2\n$$\n整个过程被嵌套在遍历指定的$K$和$d$值的循环中。收集得到的$\\mathrm{MSE}_{K,d}$值，四舍五入到六位小数，并格式化为指定的列表的列表结构。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes cross-validated Mean Squared Error for polynomial regression models\n    of hemoglobin vs. age, for various polynomial degrees and K-fold values.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = {\n        'K_values': [2, 5, 10, 40],\n        'd_values': [1, 2, 3, 4],\n        'ages': np.array([\n            0.5, 1, 1.5, 2.5, 4, 6, 8, 10, 12, 14, 15, 16, 17, 18, 20, 22, 25, 28, \n            32, 36, 40, 45, 50, 52, 55, 58, 60, 62, 65, 68, 70, 72, 75, 78, 80, \n            82, 85, 88, 90, 92\n        ])\n    }\n    \n    a = test_cases['ages']\n    n = a.shape[0]\n\n    # Calculate hemoglobin (h) values based on the deterministic formula\n    h = (12.5 + 2 / (1 + np.exp(-0.35 * (a - 16)))\n         - 0.0025 * np.maximum(0, a - 65)**2\n         + 0.35 * np.sin(0.12 * a)\n         + 0.15 * np.cos(0.27 * a))\n\n    K_values = test_cases['K_values']\n    d_values = test_cases['d_values']\n\n    master_results = []\n\n    # Main logic to calculate the results for each case.\n    # Iterate over K values for cross-validation\n    for K in K_values:\n        results_for_K = []\n        # Iterate over polynomial degrees\n        for d in d_values:\n            # This array will store the squared error for each observation,\n            # calculated from the fold where it was in the test set.\n            per_observation_squared_error = np.zeros(n)\n\n            # Iterate through each fold, treating it as the test set\n            for k in range(K):\n                # Deterministic fold assignment based on index\n                # F(i) = (i-1) mod K (1-based), or i mod K (0-based)\n                test_indices = np.arange(k, n, K)\n                train_indices = np.setdiff1d(np.arange(n), test_indices)\n\n                # Split data into training and testing sets for this fold\n                a_train, h_train = a[train_indices], h[train_indices]\n                a_test, h_test = a[test_indices], h[test_indices]\n                \n                # Standardize age based on training set statistics\n                mu_S = np.mean(a_train)\n                sigma_S = np.std(a_train)\n                \n                # Apply standardization to both training and testing predictor variables.\n                # A check for sigma_S == 0 is good practice but not expected to trigger\n                # given the diverse age data in any conceivable training fold here.\n                if sigma_S > 1e-9: # Use a small epsilon for floating point comparison\n                    a_train_std = (a_train - mu_S) / sigma_S\n                    a_test_std = (a_test - mu_S) / sigma_S\n                else: # Fallback for constant training data (highly unlikely)\n                    a_train_std = np.zeros_like(a_train, dtype=float)\n                    a_test_std = np.zeros_like(a_test, dtype=float)\n\n                # Construct the design matrix (Vandermonde matrix) for the training data.\n                # np.vander(x, N, increasing=True) creates columns [x^0, x^1, ..., x^(N-1)].\n                X_train = np.vander(a_train_std, d + 1, increasing=True)\n                \n                # Fit the polynomial model using Ordinary Least Squares.\n                # np.linalg.lstsq solves the equation X @ beta = h for beta.\n                coeffs, _, _, _ = np.linalg.lstsq(X_train, h_train, rcond=None)\n\n                # Construct the design matrix for the test data\n                X_test = np.vander(a_test_std, d + 1, increasing=True)\n                \n                # Predict hemoglobin values on the test set\n                h_pred = X_test @ coeffs\n                \n                # Calculate and store the squared errors for the current test fold\n                per_observation_squared_error[test_indices] = (h_test - h_pred)**2\n\n            # The cross-validated MSE is the mean of all out-of-fold squared errors\n            mse_K_d = np.mean(per_observation_squared_error)\n            results_for_K.append(round(mse_K_d, 6))\n\n        master_results.append(results_for_K)\n\n    # Format the final output string as a list of lists, with no spaces.\n    final_output_string = str(master_results).replace(\" \", \"\")\n    print(final_output_string)\n\nsolve()\n```", "id": "4974757"}]}