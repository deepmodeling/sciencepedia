{"hands_on_practices": [{"introduction": "第一个练习回归基础，要求你从第一性原理出发实现自助法程序。你将估计样本中位数的标准误，这是一个常用的稳健中心趋势度量。这项动手任务将巩固你对核心概念的理解：如何通过从经验分布函数（$\\hat{F}_n$）中重抽样，来近似一个统计量的抽样分布，而无需对潜在的总体分布做强假设。[@problem_id:4954777]", "problem": "给定一组独立同分布的患者生物标志物测量值，这些测量值被建模为来自未知连续分布 $F$ 的实现 $\\{x_1,\\dots,x_n\\}$。您的任务是实现一个基于核心定义的非参数重抽样程序，以近似样本中位数的抽样分布，并计算经验累积分布函数 (ECDF)。具体来说，您必须使用基于定义的经验分布 $\\hat F_n$ 作为重抽样机制，并通过从 $\\hat F_n$ 中有放回地抽取自助样本来模拟样本中位数的抽样分布。对于每个测试用例，您必须计算两个量：在指定的查询点上评估的 $\\hat F_n(x)$ 的值，以及样本中位数的标准误的自助估计。\n\n推导和算法设计的基础必须明确依赖于核心定义和事实：经验累积分布函数 (ECDF) 的定义、作为绝对偏差之和最小化器和顺序统计量的样本中位数的定义，以及通过从 $\\hat F_n$ 重抽样来近似抽样分布的自助法原理。\n\n为每个测试用例实现以下内容：\n- 计算在查询点列表处的 ECDF $\\hat F_n(x)$ 值。不调用任何快捷公式，通过应用其定义来获得 $\\hat F_n(x)$，该定义计算不超过 $x$ 的观测样本的比例。\n- 通过从观测样本中有放回地重复抽取 $n$ 个值（等效于从 $\\hat F_n$ 中抽样），计算每个重抽样样本的中位数，然后使用分母 $B-1$ 将这些自助中位数的样本标准差作为标准误的估计，来模拟样本中位数的自助抽样分布，其中 $B$ 是自助复制的次数。对于偶数 $n$，样本中位数必须定义为两个中央顺序统计量的平均值。\n- 使用指定的伪随机数生成器种子以确保可复现性。\n\n您的程序必须使用以下测试套件，每个测试用例由 $(\\text{sample}, \\text{queries}, B, \\text{seed})$ 描述：\n- 案例 1（一般偏态、正生物标志物值）：样本 $[1.8, 2.5, 3.0, 3.2, 4.1, 5.5, 7.0, 9.2, 14.8, 26.3]$，查询点 $[2.0, 4.0, 10.0, 20.0]$，$B=5000$，种子 $314159$。\n- 案例 2（偶数样本量，在零附近有相同值）：样本 $[0.12, 0.15, 0.15, 0.20, 0.22, 0.35]$，查询点 $[0.15, 0.21, 0.40]$，$B=7000$，种子 $271828$。\n- 案例 3（退化的常数值）：样本 $[5.0, 5.0, 5.0, 5.0, 5.0]$，查询点 $[4.9, 5.0, 5.1]$，$B=4000$，种子 $444$。\n- 案例 4（小样本，含严重离群值）：样本 $[1.0, 2.0, 100.0]$，查询点 $[1.0, 50.0, 100.0]$，$B=8000$，种子 $1234567$。\n\n所有生物标志物值和派生量均为无单位的实数。对于每个测试用例，产生两个输出：\n- 一个浮点数列表，包含按给定顺序在相应查询点上评估的 ECDF 值 $\\hat F_n(x)$。\n- 一个浮点数，即基于 $B$ 次复制的样本中位数标准误的自助估计。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，其中每个元素对应一个测试用例，并且本身是一个形式为 $[\\text{ecdf\\_values\\_list}, \\text{standard\\_error\\_float}]$ 的双元素列表。例如，最终输出格式必须是 $[[\\text{ecdf\\_case1}, \\text{se\\_case1}],[\\text{ecdf\\_case2}, \\text{se\\_case2}],\\dots]$，不含任何附加文本。", "solution": "该问题要求实现两个基本的非参数统计程序：计算经验累积分布函数 (ECDF) 和使用自助法估计样本中位数的标准误。本解决方案旨在严格遵守所提供的第一性原理和定义。\n\n**第一部分：经验累积分布函数 (ECDF) 的计算**\n\nECDF，表示为 $\\hat{F}_n(x)$，是真实潜在累积分布函数 $F(x)$ 的一个非参数估计。根据定义，对于一个大小为 $n$ 的给定样本 $\\{x_1, x_2, \\dots, x_n\\}$，在点 $x$ 处的 ECDF 是小于或等于 $x$ 的样本观测值的比例。这可以正式表示为：\n$$\n\\hat{F}_n(x) = \\frac{1}{n} \\sum_{i=1}^{n} I(x_i \\le x)\n$$\n其中 $I(\\cdot)$ 是指示函数，当其参数为真时值为 $1$，否则为 $0$。\n\n为查询点列表计算 $\\hat{F}_n(x)$ 的算法直接遵循此定义，符合要求。对于所提供列表中的每个查询点 $q$，该程序遍历样本中的所有数据点 $x_i$。对于每个满足条件 $x_i \\le q$ 的 $x_i$，计数器会递增。然后将最终计数除以总样本大小 $n$，得出 $\\hat{F}_n(q)$ 的值。对所有查询点重复此过程。该方法避免了任何特定于库的“快捷”函数，并从第一性原理实现了计数定义。\n\n**第二部分：样本中位数标准误的自助估计**\n\n第二个任务是估计样本中位数的标准误，这是衡量作为总体中位数估计量的样本中位数变异性的一个指标。当潜在的总体分布 $F$ 未知时，自助法是一种强大的重抽样技术，用于近似统计量的抽样分布。\n\n**样本中位数**\n我们感兴趣的统计量是样本中位数，记为 $\\hat{m}$。对于一个按非递减顺序排序的样本 $x_{(1)} \\le x_{(2)} \\le \\dots \\le x_{(n)}$，样本中位数根据样本大小 $n$ 定义。\n- 如果 $n$ 是奇数，中位数是中心值 $\\hat{m} = x_{(\\lceil n/2 \\rceil)}$。在基于 0 的索引中，这是 $x_{( (n-1)/2 )}$。\n- 如果 $n$ 是偶数，中位数是两个中心值的平均值 $\\hat{m} = \\frac{1}{2} (x_{(n/2)} + x_{(n/2+1)})$。在基于 0 的索引中，这对应于 $\\frac{1}{2}(x_{(n/2 - 1)} + x_{(n/2)})$。\n这个定义是标准的，并由 `numpy.median` 等函数实现。\n\n**自助法原理和算法**\n自助程序通过利用经验分布 $\\hat{F}_n$ 来近似未知的抽样分布。其核心假设是，从样本中重抽样类似于从总体中抽取新样本。该算法过程如下：\n$1$. **重抽样**：生成大量的自助样本，数量为 $B$。每个自助样本，记为 $\\{x_1^*, \\dots, x_n^*\\}$，是通过从原始样本 $\\{x_1, \\dots, x_n\\}$ 中*有放回地*抽取 $n$ 个元素创建的。这个过程等同于从原始样本点上的离散均匀分布中抽样，这也是由 $\\hat{F}_n$ 定义的机制。\n$2$. **统计量计算**：对 $B$ 个自助样本中的每一个，计算其样本中位数。这将得到一个包含 $B$ 个自助中位数的集合：$\\{m_1^*, m_2^*, \\dots, m_B^*\\}$。这个集合经验地近似了样本中位数的抽样分布。\n$3$. **标准误估计**：样本中位数的标准误是其抽样分布的标准差。此标准误的自助估计 $SE_{boot}(\\hat{m})$，是计算 $B$ 个自助中位数的样本标准差得到的。问题指定使用分母 $B-1$，这对应于方差的无偏估计公式：\n    $$\n    SE_{boot}(\\hat{m}) = \\sqrt{ \\frac{1}{B-1} \\sum_{j=1}^{B} (m_j^* - \\bar{m}^*)^2 }\n    $$\n    其中 $\\bar{m}^* = \\frac{1}{B} \\sum_{j=1}^{B} m_j^*$ 是自助中位数的平均值。\n\n**实现细节**\n实现使用 `numpy` 库进行高效的数值运算。一个伪随机数生成器，使用 `numpy.random.default_rng(seed)` 为每个测试用例以指定的种子进行初始化，确保了自助重抽样过程的可复现性。`rng.choice` 函数用于进行有放回抽样。`numpy.median` 函数用于计算每个自助样本的中位数，而带有参数 `ddof=1` 的 `numpy.std` 函数用于计算最终的标准误估计，从而正确地实现了 $B-1$ 分母。这种方法将自助法的理论原理与一个稳健且可复现的计算算法相结合。", "answer": "```python\nimport numpy as np\n# No other libraries are permitted.\n# scipy is listed in the problem preamble but not needed for this solution.\n\ndef compute_ecdf_values(sample, queries):\n    \"\"\"\n    Computes the ECDF for a set of query points based on a sample,\n    adhering to the definition of counting observations.\n\n    Args:\n        sample (np.ndarray): The observed data points.\n        queries (np.ndarray): The points at which to evaluate the ECDF.\n\n    Returns:\n        list: A list of floats representing the ECDF values at the query points.\n    \"\"\"\n    n = sample.shape[0]\n    if n == 0:\n        return [0.0] * len(queries)\n    \n    ecdf_vals = []\n    for x in queries:\n        # Count how many samples are less than or equal to x\n        count = np.sum(sample = x)\n        ecdf_vals.append(count / n)\n    return ecdf_vals\n\ndef compute_bootstrap_se_median(sample, B, seed):\n    \"\"\"\n    Computes the bootstrap standard error of the sample median.\n\n    Args:\n        sample (np.ndarray): The observed data points.\n        B (int): The number of bootstrap replicates.\n        seed (int): The seed for the pseudo-random number generator.\n\n    Returns:\n        float: The bootstrap estimate of the standard error of the sample median.\n    \"\"\"\n    n = sample.shape[0]\n    if n == 0:\n        return 0.0\n\n    # Initialize the random number generator for reproducibility\n    rng = np.random.default_rng(seed)\n    \n    # Store bootstrap medians\n    bootstrap_medians = np.zeros(B)\n    \n    # Perform B bootstrap resamples\n    for i in range(B):\n        # Draw a sample of size n with replacement from the original sample\n        bootstrap_sample = rng.choice(sample, size=n, replace=True)\n        # Compute and store the median of the bootstrap sample\n        bootstrap_medians[i] = np.median(bootstrap_sample)\n        \n    # The standard error is the sample standard deviation of the bootstrap medians.\n    # The parameter ddof=1 ensures the denominator in the variance calculation is B-1.\n    se = np.std(bootstrap_medians, ddof=1)\n    \n    return se\n\ndef solve():\n    \"\"\"\n    Main function to process all test cases and print the final result.\n    \"\"\"\n    test_cases = [\n        {'sample': [1.8, 2.5, 3.0, 3.2, 4.1, 5.5, 7.0, 9.2, 14.8, 26.3], 'queries': [2.0, 4.0, 10.0, 20.0], 'B': 5000, 'seed': 314159},\n        {'sample': [0.12, 0.15, 0.15, 0.20, 0.22, 0.35], 'queries': [0.15, 0.21, 0.40], 'B': 7000, 'seed': 271828},\n        {'sample': [5.0, 5.0, 5.0, 5.0, 5.0], 'queries': [4.9, 5.0, 5.1], 'B': 4000, 'seed': 444},\n        {'sample': [1.0, 2.0, 100.0], 'queries': [1.0, 50.0, 100.0], 'B': 8000, 'seed': 1234567},\n    ]\n\n    results = []\n    for case in test_cases:\n        # It's good practice to convert lists to numpy arrays for numerical processing\n        sample = np.array(case['sample'])\n        queries = np.array(case['queries'])\n        B = case['B']\n        seed = case['seed']\n        \n        # Task 1: Compute ECDF values\n        ecdf_results = compute_ecdf_values(sample, queries)\n        \n        # Task 2: Compute bootstrap standard error of the median\n        se_median = compute_bootstrap_se_median(sample, B, seed)\n        \n        results.append([ecdf_results, se_median])\n\n    # The required output format is a single line, comma-separated list of lists.\n    # str() on a list produces the desired representation '[...]'\n    # We join these string representations with commas.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "4954777"}, {"introduction": "在掌握了基础知识之后，本练习将转向一个在医学研究中的常见应用：评估诊断测试的性能。你将使用分层自助法重抽样技术，为受试者工作特征曲线下面积（AUC）构建百分位置信区间。通过这个练习，你将学会如何为结构化数据（如病例对照研究）调整自助法，并为一个复杂但至关重要的性能指标生成区间估计。[@problem_id:4954664]", "problem": "给定一个在医学研究中常见的两类诊断情境，其中包含患病个体和非患病个体的连续测试分数。目标是使用非参数、分层bootstrap重抽样方法，为受试者工作特征曲线下面积 (Area Under the Receiver Operating Characteristic Curve, AUC) 构建一个bootstrap置信区间。受试者工作特征曲线下面积 (AUC) 定义为：从患病群体中随机抽取一个个体，其分数超过从非患病群体中随机抽取的个体分数的概率，其中分数相等的情况（结）贡献一半的概率。请使用百分位数bootstrap方法来估计AUC的双侧置信区间，重抽样应在患者层面进行。\n\n你的推导应基于以下经过充分检验的定义和事实：\n- 受试者工作特征 (ROC) 曲线绘制了当决策阈值变化时，真阳性率 (True Positive Rate, TPR) 相对于假阳性率 (False Positive Rate, FPR) 的关系图；受试者工作特征曲线下面积 (AUC) 是患病和非患病个体测试分数联合分布的一个泛函，可以解释为ROC曲线下的积分，或关于成对比较的概率陈述。\n- 非参数bootstrap重抽样通过从经验分布中有放回地重复抽样，来近似一个统计量的抽样分布。在病例-对照医学研究中，重抽样应按类别分层，以保持类条件经验分布。\n\n实现以下任务：\n1. 对于每个测试用例，模拟患病和非患病个体的测试分数。对于患病个体，从均值为 $\\mu_1$、方差为 $\\sigma_1^2$ 的正态分布中抽取独立分数。对于非患病个体，从均值为 $\\mu_0$、方差为 $\\sigma_0^2$ 的正态分布中抽取独立分数。使用固定的随机种子 $s=12345$，以确保结果是可复现的。如果指定了四舍五入分辨率 $r$，则将每个模拟分数四舍五入到 $r$ 的最接近的倍数（这将引入结）。\n2. 使用成对比较的解释来计算经验AUC：它是所有患病与非患病配对中，患病分数大于非患病分数的比例，其中分数相等的情况贡献一半。该经验估计量必须与基于秩的Wilcoxon-Mann-Whitney公式一致，并且必须能适当地处理结。\n3. 使用百分位数方法构建一个 $(1-\\alpha)$ 的bootstrap置信区间：\n   - 执行 $B$ 次bootstrap复制。在每次复制中，在患病组内有放回地重抽样，得到大小为 $n_1$ 的样本；在非患病组内有放回地重抽样，得到大小为 $n_0$ 的样本（分层重抽样），然后为重抽样得到的数据计算AUC。\n   - 令 $\\hat{F}_B$ 为 $B$ 个bootstrap AUC值的经验分布。下界是 $\\hat{F}_B$ 的 $\\alpha/2$ 分位数，上界是 $\\hat{F}_B$ 的 $(1-\\alpha/2)$ 分位数。\n4. 对于每个测试用例，返回构成置信区间下界和上界的两个数字。将这两个数字表示为四舍五入到 $6$ 位小数的浮点数。\n\n你的程序应生成单行输出，其中包含一个由逗号分隔并用方括号括起来的列表，其中每个测试用例对应一个包含下界和上界的双元素列表。例如：$[ [\\text{lower}_1,\\text{upper}_1],[\\text{lower}_2,\\text{upper}_2],\\dots ]$。\n\n使用以下测试套件（所有数字都为保证可复现性和覆盖不同场景而指定）：\n- 测试用例 $1$（类别平衡和分离度适中的一般情况）：$n_1=120$, $n_0=150$, $\\mu_1=1.0$, $\\sigma_1=1.0$, $\\mu_0=0.0$, $\\sigma_0=1.0$, $B=4000$, $\\alpha=0.05$，无四舍五入。\n- 测试用例 $2$（类别高度不平衡，分离度一般）：$n_1=40$, $n_0=400$, $\\mu_1=0.8$, $\\sigma_1=1.2$, $\\mu_0=0.2$, $\\sigma_0=1.2$, $B=3000$, $\\alpha=0.05$，无四舍五入。\n- 测试用例 $3$（小样本量，通过四舍五入引入结）：$n_1=12$, $n_0=10$, $\\mu_1=0.0$, $\\sigma_1=1.0$, $\\mu_0=0.0$, $\\sigma_0=1.0$, 四舍五入分辨率 $r=0.1$, $B=5000$, $\\alpha=0.10$。\n- 测试用例 $4$（近乎完美的分离）：$n_1=60$, $n_0=60$, $\\mu_1=2.5$, $\\sigma_1=0.5$, $\\mu_0=-0.5$, $\\sigma_0=0.5$, $B=3000$, $\\alpha=0.05$，无四舍五入。\n\n所有浮点输出都必须四舍五入到 $6$ 位小数，并以小数形式表示（而非分数），不涉及任何物理单位。不涉及角度。最终打印的行必须严格为上述指定的单个方括号列表格式。", "solution": "该问题陈述已经过仔细验证，并被确定为有效。它具有科学依据、提法明确、客观，并包含进行求解所需的所有必要信息。未发现科学、逻辑或形式上的缺陷。\n\n目标是为受试者工作特征曲线下面积 (Area Under the Receiver Operating Characteristic Curve, AUC) 计算一个双侧 $(1-\\alpha)$ 百分位数bootstrap置信区间。这项任务在医学诊断测试评估中很常见，其中从一组患有某种疾病的个体（病例）和一组没有该疾病的个体（对照）收集测试分数。\n\n### 原理一：受试者工作特征曲线下面积 (AUC)\n\nAUC是诊断测试性能的一个汇总度量。来自患病个体的测试分数 $X$ 服从分布 $F_1$，而来自非患病个体的分数 $Y$ 服从分布 $F_0$。AUC正式定义为：随机选择一个患病个体的分数高于随机选择一个非患病个体的分数的概率。当可能出现分数相等（结）时，通常给予一半的权重。\n\n$$\nAUC = P(X  Y) + \\frac{1}{2} P(X = Y)\n$$\n\n给定来自患病个体的 $n_1$ 个分数样本 $\\{x_i\\}_{i=1}^{n_1}$ 和来自非患病个体的 $n_0$ 个分数样本 $\\{y_j\\}_{j=1}^{n_0}$，AUC的一个非参数估计量，记为 $\\widehat{AUC}$，是所有可能的 $(x_i, y_j)$ 配对中 $x_i$ 大于 $y_j$ 的比例，加上它们相等配对比例的一半。\n\n$$\n\\widehat{AUC} = \\frac{1}{n_1 n_0} \\sum_{i=1}^{n_1} \\sum_{j=1}^{n_0} \\Psi(x_i, y_j)\n$$\n\n其中评分函数 $\\Psi(a,b)$ 定义为：\n\n$$\n\\Psi(a,b) = \\begin{cases} 1  \\text{if } a  b \\\\ \\frac{1}{2}  \\text{if } a = b \\\\ 0  \\text{if } a  b \\end{cases}\n$$\n\n该估计量等价于标准化的Wilcoxon-Mann-Whitney U统计量。一种计算上高效的计算 $\\widehat{AUC}$ 的方法是使用秩。首先，将所有 $N = n_1 + n_0$ 个分数合并并从 $1$ 到 $N$ 进行排序。如果出现结，则为每个结中的分数分配平均秩（mid-rank）。令 $R_i$ 为第 $i$ 个患病分数 $x_i$ 在合并样本中的秩。患病组的U统计量 $U_1$ 是这些秩的总和，并根据最小可能秩和进行调整：\n\n$$\nU_1 = \\left( \\sum_{i=1}^{n_1} R_i \\right) - \\frac{n_1(n_1+1)}{2}\n$$\n\n然后，AUC估计量由下式给出：\n\n$$\n\\widehat{AUC} = \\frac{U_1}{n_1 n_0}\n$$\n\n这种基于秩的公式能够正确处理结，并且在计算上优于朴素的 $O(n_1 n_0)$ 成对比较方法，其复杂度通常为 $O(N \\log N)$，因为排序是秩计算的一部分。\n\n### 原理二：分层Bootstrap重抽样\n\nBootstrap是一种强大的重抽样技术，用于近似统计量的抽样分布。为了构建AUC的置信区间，我们需要理解 $\\widehat{AUC}$ 在从底层总体 $F_1$ 和 $F_0$ 抽取的不同样本中会如何变化。由于我们只能接触到经验分布 $\\hat{F}_1$（来自 $\\{x_i\\}$）和 $\\hat{F}_0$（来自 $\\{y_j\\}$），我们用它们作为真实分布的代理。\n\n对于病例-对照数据，使用**分层重抽样**至关重要。这意味着我们独立地从患病组和非患病组中进行重抽样，并保持每个组的原始样本量。这尊重了研究设计，并确保我们的bootstrap样本模拟了原始数据采集过程的结构。\n\nAUC的分层bootstrap程序如下：\n对于 $b = 1, 2, \\ldots, B$:\n1.  通过从原始样本 $\\{x_i\\}_{i=1}^{n_1}$ 中有放回地抽取 $n_1$ 个分数，生成一个患病分数的bootstrap样本 $X_b^*$。\n2.  通过从原始样本 $\\{y_j\\}_{j=1}^{n_0}$ 中有放回地抽取 $n_0$ 个分数，生成一个非患病分数的bootstrap样本 $Y_b^*$。\n3.  使用基于秩的方法对 $X_b^*$ 和 $Y_b^*$ 计算该bootstrap复制的AUC，即 $\\widehat{AUC}_b^*$。\n\n这个过程产生一个包含 $B$ 个bootstrap AUC值的集合，$\\{\\widehat{AUC}_1^*, \\widehat{AUC}_2^*, \\ldots, \\widehat{AUC}_B^*\\}$，它作为 $\\widehat{AUC}$ 抽样分布的一个经验近似。\n\n### 原理三：百分位数置信区间\n\n百分位数方法是一种从bootstrap分布直接构建置信区间的直接方法。一个 $(1-\\alpha)$ 的置信区间是通过取排序后的bootstrap复制的分位数构成的。\n\n-   置信区间的下界是bootstrap分布 $\\{\\widehat{AUC}_b^*\\}$ 的 $(\\alpha/2)$ 分位数。\n-   上界是 $(1-\\alpha/2)$ 分位数。\n\n例如，对于一个 $95\\%$ 的置信区间 ($\\alpha=0.05$)，其界限是排序后的bootstrap AUC列表的第 $2.5$ 个和第 $97.5$ 个百分位数。\n\n### 算法解决方案\n对于每个测试用例，整体算法流程如下：\n1.  **数据生成**：使用固定的随机种子 $s=12345$ 以保证可复现性，为患病组模拟 $n_1$ 个来自 $N(\\mu_1, \\sigma_1^2)$ 的分数，为非患病组模拟 $n_0$ 个来自 $N(\\mu_0, \\sigma_0^2)$ 的分数。如果指定了四舍五入分辨率 $r$，则每个分数都四舍五入到 $r$ 的最接近的倍数。此步骤明确地在数据中引入结，以测试AUC计算的稳健性。\n2.  **Bootstrap循环**：执行 $B$ 次迭代。在每次迭代中：\n    a.  执行分层有放回重抽样，为患病组和非患病组创建bootstrap样本。\n    b.  使用高效的基于秩的方法计算重抽样数据的 $\\widehat{AUC}$。\n    c.  存储计算出的 $\\widehat{AUC}_b^*$。\n3.  **置信区间计算**：完成 $B$ 次迭代后，计算收集到的bootstrap AUC值的 $\\alpha/2$ 和 $(1-\\alpha/2)$ 分位数。这些分位数构成了置信区间的下界和上界。\n4.  **格式化**：将得到的界限四舍五入到 $6$ 位小数并按指定格式输出。\n\n此程序能够稳健地估计AUC的置信区间，正确处理分层数据和结的存在。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\n\ndef solve():\n    \"\"\"\n    Solves the problem of constructing bootstrap confidence intervals for AUC\n    for a series of test cases.\n    \"\"\"\n\n    test_cases = [\n        # Test case 1 (general case with moderate class balance and separation)\n        {'n1': 120, 'n0': 150, 'mu1': 1.0, 'sigma1': 1.0, 'mu0': 0.0, 'sigma0': 1.0, 'B': 4000, 'alpha': 0.05, 'r': None},\n        # Test case 2 (high class imbalance, modest separation)\n        {'n1': 40, 'n0': 400, 'mu1': 0.8, 'sigma1': 1.2, 'mu0': 0.2, 'sigma0': 1.2, 'B': 3000, 'alpha': 0.05, 'r': None},\n        # Test case 3 (small sample size with ties induced by rounding)\n        {'n1': 12, 'n0': 10, 'mu1': 0.0, 'sigma1': 1.0, 'mu0': 0.0, 'sigma0': 1.0, 'r': 0.1, 'B': 5000, 'alpha': 0.10},\n        # Test case 4 (near perfect separation)\n        {'n1': 60, 'n0': 60, 'mu1': 2.5, 'sigma1': 0.5, 'mu0': -0.5, 'sigma0': 0.5, 'B': 3000, 'alpha': 0.05, 'r': None},\n    ]\n\n    # Fixed random seed for reproducibility\n    seed = 12345\n    rng = np.random.default_rng(seed)\n\n    def calculate_auc(diseased_scores, non_diseased_scores):\n        \"\"\"\n        Calculates the AUC using the Wilcoxon-Mann-Whitney U-statistic formulation,\n        which is efficient and correctly handles ties.\n        \"\"\"\n        n1 = len(diseased_scores)\n        n0 = len(non_diseased_scores)\n\n        if n1 == 0 or n0 == 0:\n            return 0.5\n\n        # Combine scores and calculate ranks\n        all_scores = np.concatenate((diseased_scores, non_diseased_scores))\n        ranks = stats.rankdata(all_scores, method='average')\n\n        # Sum of ranks for the diseased group\n        sum_ranks_diseased = np.sum(ranks[:n1])\n\n        # Calculate U statistic for the diseased group\n        u_stat = sum_ranks_diseased - (n1 * (n1 + 1)) / 2\n        \n        # AUC is the normalized U statistic\n        auc = u_stat / (n1 * n0)\n        return auc\n\n    results = []\n    for case in test_cases:\n        n1, n0 = case['n1'], case['n0']\n        mu1, sigma1 = case['mu1'], case['sigma1']\n        mu0, sigma0 = case['mu0'], case['sigma0']\n        B, alpha, r = case['B'], case['alpha'], case['r']\n        \n        # 1. Simulate test scores\n        diseased_scores = rng.normal(loc=mu1, scale=sigma1, size=n1)\n        non_diseased_scores = rng.normal(loc=mu0, scale=sigma0, size=n0)\n\n        # Apply rounding if resolution 'r' is specified\n        if r is not None and r > 0:\n            diseased_scores = np.round(diseased_scores / r) * r\n            non_diseased_scores = np.round(non_diseased_scores / r) * r\n\n        # 3. Construct bootstrap confidence interval\n        bootstrap_aucs = np.zeros(B)\n        for i in range(B):\n            # Stratified resampling with replacement\n            resampled_diseased = rng.choice(diseased_scores, size=n1, replace=True)\n            resampled_non_diseased = rng.choice(non_diseased_scores, size=n0, replace=True)\n            \n            # Compute AUC for the resampled data\n            bootstrap_aucs[i] = calculate_auc(resampled_diseased, resampled_non_diseased)\n            \n        # Calculate percentile confidence interval\n        lower_quantile = alpha / 2\n        upper_quantile = 1 - alpha / 2\n        \n        ci_lower = np.quantile(bootstrap_aucs, lower_quantile)\n        ci_upper = np.quantile(bootstrap_aucs, upper_quantile)\n        \n        results.append([ci_lower, ci_upper])\n\n    # Format the final output string to precisely 6 decimal places.\n    formatted_results = []\n    for lower, upper in results:\n        formatted_results.append(f\"[{lower:.6f},{upper:.6f}]\")\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "4954664"}, {"introduction": "对于任何数据科学家或统计学家来说，了解其工具的局限性是一项至关重要的技能。最后一个练习使用蒙特卡洛模拟来研究置信区间的一个关键属性：其覆盖概率。通过模拟来自对称和偏态分布的数据，检验样本中位数自助法百分位置信区间的性能，你将深刻洞察该方法在何种条件下值得信赖，以及何时可能产生误导性结果。[@problem_id:4954794]", "problem": "你需要编写一个完整、可运行的程序，使用蒙特卡洛模拟来评估当潜在分布为对称与偏态时，样本中位数的自助法百分位区间是否能达到名义覆盖率。该程序必须从第一性原理出发，仅使用概率论和统计学中的定义和经过充分检验的事实来实现以下内容。\n\n设样本是从一个未知的分布函数 $F$ 中抽取的独立同分布 (i.i.d.) 观测值。对于给定的样本量 $n$，将样本表示为 $\\{X_1,\\dots,X_n\\}$，样本中位数表示为 $\\hat{m}$。自助法原理通过从观测样本中进行有放回重抽样来近似 $\\hat{m}$ 的抽样分布。具体来说，给定一个观测样本，生成 $B$ 个独立同分布的自助重抽样样本，每个样本量均为 $n$，计算每个重抽样样本的样本中位数以获得 $\\{\\hat{m}^{\\ast}_1,\\dots,\\hat{m}^{\\ast}_B\\}$，然后通过取经验分位数形成名义水平为 $1-\\alpha$ 的百分位置信区间 (Confidence Interval, CI)：\n$$\n[\\hat{q}_{\\alpha/2},\\hat{q}_{1-\\alpha/2}],\n$$\n其中 $\\hat{q}_p$ 是 $\\{\\hat{m}^{\\ast}_b\\}_{b=1}^B$ 的经验 $p$-分位数。经验分位数将通过顺序统计量之间的标准线性插值计算：如果 $\\tilde{m}^{\\ast}_{(1)} \\le \\cdots \\le \\tilde{m}^{\\ast}_{(B)}$ 是排序后的自助法中位数，且 $p \\in (0,1)$，定义 $h=(B-1)p+1$，令 $k=\\lfloor h \\rfloor$, $t = h-k$，并设\n$$\n\\hat{q}_p = \\tilde{m}^{\\ast}_{(k)} + t\\left(\\tilde{m}^{\\ast}_{(k+1)} - \\tilde{m}^{\\ast}_{(k)}\\right),\n$$\n约定 $\\tilde{m}^{\\ast}_{(B+1)}=\\tilde{m}^{\\ast}_{(B)}$。水平为 $1-\\alpha$ 的覆盖率是指真实总体中位数 $m$ 落在随机区间 $[\\hat{q}_{\\alpha/2},\\hat{q}_{1-\\alpha/2}]$ 内的概率。\n\n你的任务是通过蒙特卡洛模拟，对几个真实中位数 $m$ 已知的分布，来近似这个覆盖概率。对于每个测试用例，执行以下操作：\n- 重复 $R$ 次：\n  - 从指定的分布中生成一个大小为 $n$ 的独立同分布样本。\n  - 使用 $B$ 个自助重抽样样本，按上述定义计算中位数的自助法百分位区间。\n  - 使用闭区间记录 $m$ 是否在 $[\\hat{q}_{\\alpha/2},\\hat{q}_{1-\\alpha/2}]$ 内，即如果 $m \\ge \\hat{q}_{\\alpha/2}$ 且 $m \\le \\hat{q}_{1-\\alpha/2}$，则计为覆盖。\n- 经验覆盖率即为这 $R$ 次重复中出现覆盖的比例。\n\n使用以下基本原理：\n- 从一个固定分布 $F$ 中进行独立同分布 (i.i.d.) 抽样。\n- 样本中位数的定义。\n- 作为对统计量抽样分布的经验近似的自助重抽样方案。\n- 通过分位数定义置信区间。\n- 基本极限定理，如大数定律，用于证明在 $R$ 很大时蒙特卡洛近似的质量（你无需证明这些定理）。\n\n为以下参数值的测试套件实现模拟，该套件涵盖对称轻尾、对称重尾和偏态分布，以及一个大样本场景：\n- 测试用例 $1$ (对称，轻尾)：均值为 $0$、标准差为 $1$ 的正态分布，记为 $\\mathcal{N}(0,1)$。使用 $n=40, \\alpha=0.05, B=300, R=400$。真实中位数为 $m=0$。\n- 测试用例 $2$ (对称，重尾)：位置为 $0$、尺度为 $1$ 的拉普拉斯分布。使用 $n=40, \\alpha=0.05, B=300, R=400$。真实中位数为 $m=0$。\n- 测试用例 $3$ (偏态，中小样本)：率参数为 $\\lambda=1$ 的指数分布。使用 $n=40, \\alpha=0.05, B=300, R=400$。真实中位数为 $m=(\\log 2)/\\lambda$。\n- 测试用例 $4$ (偏态，大样本)：率参数为 $\\lambda=1$ 的指数分布。使用 $n=120, \\alpha=0.05, B=200, R=300$。真实中位数为 $m=(\\log 2)/\\lambda$。\n\n所有随机变量的生成都必须使用固定的种子 $s=1729$ 以确保可复现性。不涉及角度。不适用物理单位。所有覆盖率结果均以 $[0,1]$ 内的小数表示。\n\n程序输入：无。程序输出：单行，包含一个由四个浮点数组成的列表，按顺序表示测试用例 $1$ 到 $4$ 的经验覆盖率，每个数值都四舍五入到恰好三位小数。格式必须为单行：\n\"[c1,c2,c3,c4]\"\n其中 $c1, c2, c3, c4$ 分别是四个测试用例的四舍五入后的经验覆盖率，无额外文本或空格。", "solution": "用户提供了一个来自计算统计学领域的有效、适定的问题陈述。该问题在科学上基于已建立的统计理论，即使用自助重抽样来构建置信区间，并使用蒙特卡洛模拟来评估其性能。所有参数、定义和过程都已足够精确地指定，以确保一个唯一且可复现的解。任务是实现此模拟，以评估在不同潜在分布下，样本中位数的自助法百分位区间的覆盖概率。\n\n按照要求，解决方案是从第一性原理出发开发的。该算法通过将统计定义直接转化为计算过程来构建。\n\n主要目标是估计置信区间的覆盖概率。对于一个为参数 $\\theta$ 构建 $(1-α)$ 置信区间的程序，其覆盖概率是指在重复抽样中，计算出的区间包含 $\\theta$ 真实值的概率。如果此概率等于 $1-α$，则称该程序达到了名义覆盖水平。\n\n我们感兴趣的参数是总体中位数，记为 $m$。此参数的估计量是样本中位数 $\\hat{m}$，它是从一个来自分布 $F$ 的独立同分布 (i.i.d.) 样本 $\\{X_1, \\dots, X_n\\}$ 计算得出的。\n\n置信区间是使用自助法百分位方法构建的。自助法的基本思想是通过模拟来近似某个统计量（例如 $\\hat{m}$）的抽样分布。由于真实的总体分布 $F$ 是未知的，我们使用从观测样本中导出的经验分布函数作为代理。该过程如下：\n1.  从原始样本 $\\{X_1, \\dots, X_n\\}$ 中，通过*有放回*抽样，抽取一个大小为 $n$ 的“自助重抽样样本” $\\{X_1^\\ast, \\dots, X_n^\\ast\\}$。\n2.  计算该重抽样样本的感兴趣统计量。在这里，我们计算样本中位数，记为 $\\hat{m}^\\ast$。\n3.  重复步骤 1 和 2 大量次数（$B$ 次），以获得一组自助法统计量 $\\{\\hat{m}^\\ast_1, \\dots, \\hat{m}^\\ast_B\\}$。该集合作为 $\\hat{m}$ 抽样分布的经验近似。\n\n$(1-\\alpha)$ 百分位置信区间是通过取自助法分布的经验 $\\alpha/2$ 和 $1-\\alpha/2$ 分位数形成的。设排序后的自助法中位数为 $\\tilde{m}^\\ast_{(1)} \\leq \\tilde{m}^\\ast_{(2)} \\leq \\dots \\leq \\tilde{m}^\\ast_{(B)}$。问题指定了一种通过线性插值计算经验 $p$-分位数 $\\hat{q}_p$ 的精确方法。给定一个概率 $p \\in (0,1)$，我们首先找到一个位置索引 $h = (B-1)p+1$。令 $k = \\lfloor h \\rfloor$ 为整数部分，$t = h - k$ 为小数部分。则分位数由下式给出：\n$$\n\\hat{q}_p = \\tilde{m}^\\ast_{(k)} + t(\\tilde{m}^\\ast_{(k+1)} - \\tilde{m}^\\ast_{(k)})\n$$\n问题指定了约定 $\\tilde{m}^\\ast_{(B+1)} = \\tilde{m}^\\ast_{(B)}$，这确保了当 $k=B$ 时公式是良定的。置信区间则由 $[\\hat{q}_{\\alpha/2}, \\hat{q}_{1-\\alpha/2}]$ 给出。\n\n为了评估该区间的性能，我们使用蒙特卡洛模拟来估计其覆盖概率。这引入了第二层模拟。对于单个测试用例的总体算法是：\n1.  初始化一个覆盖计数器为 $0$。固定参数：样本量 $n$、显著性水平 $\\alpha$、自助重抽样次数 $B$、蒙特卡洛重复次数 $R$、潜在分布 $F$ 及其真实中位数 $m$。\n2.  开始外层循环，该循环将运行 $R$ 次。每次迭代代表一个完整的实验。\n    a.  从真实分布 $F$ 中生成一个大小为 $n$ 的原始样本 $\\{X_1, \\dots, X_n\\}$。\n    b.  开始内层循环（自助法程序），该循环将运行 $B$ 次。\n        i. 通过从原始样本中有放回地抽取 $n$ 个元素来创建一个自助重抽样样本。\n        ii. 计算该重抽样样本的中位数。\n        iii. 存储这个自助法中位数。\n    c. 内层循环结束后，所有 $B$ 个自助法中位数 $\\{\\hat{m}^\\ast_1, \\dots, \\hat{m}^\\ast_B\\}$ 都已收集完毕。\n    d. 对自助法中位数进行排序，得到顺序统计量 $\\tilde{m}^\\ast_{(1)}, \\dots, \\tilde{m}^\\ast_{(B)}$。\n    e. 使用指定的线性插值公式计算置信区间的下界 $\\hat{q}_{\\alpha/2}$ 和上界 $\\hat{q}_{1-\\alpha/2}$。\n    f. 检查真实中位数 $m$ 是否包含在此计算出的区间内，即 $m \\in [\\hat{q}_{\\alpha/2}, \\hat{q}_{1-\\alpha/2}]$。\n    g. 如果发生覆盖，则将覆盖计数器加一。\n3.  外层循环完成后，估计的覆盖概率是覆盖计数器的总数除以蒙特卡洛重复次数 $R$。\n\n该模拟针对四个旨在揭示自助法百分位区间性质的测试用例进行：\n-   **用例 1：正态分布 $\\mathcal{N}(0,1)$**。这是一个对称的轻尾分布。中位数的抽样分布是对称的，预计自助法会表现良好。覆盖率应接近名义水平 $1-\\alpha = 0.95$。\n-   **用例 2：拉普拉斯分布**。这是一个对称的重尾分布。对于拉普拉斯分布的中心，样本中位数是一个特别有效的估计量。预计性能会很好。\n-   **用例 3：指数分布, $n=40$**。该分布是偏态的。中位数的抽样分布也将是偏态的。对于偏态分布，特别是样本量较小时，标准的百分位自助法区间通常会表现出系统性偏差和覆盖不足。我们预计覆盖率会显著低于 $0.95$。\n-   **用例 4：指数分布, $n=120$**。这是相同的偏态分布，但样本量更大。随着 $n$ 的增加，根据中心极限定理，中位数的抽样分布会变得更加对称。因此，我们预计自助法的性能会提高，覆盖率应比用例 3 更接近 $0.95$。\n\n使用一个固定的随机种子来确保为样本和重抽样样本生成的伪随机数的可复现性，从而得到一个确定性的最终输出。实现将使用 `numpy` 库进行数值运算和随机数生成。分位数的计算将按照问题定义明确实现，以确保完全忠实于规范。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Performs a Monte Carlo simulation to assess the coverage of bootstrap \n    percentile intervals for the sample median across different distributions.\n    \"\"\"\n\n    # Set the global random seed for reproducibility.\n    SEED = 1729\n    rng = np.random.default_rng(SEED)\n\n    def _calculate_quantile(sorted_data, p):\n        \"\"\"\n        Computes the empirical p-quantile using linear interpolation as specified.\n\n        Args:\n            sorted_data (np.ndarray): A 1D numpy array of data, already sorted.\n            p (float): The probability for the quantile, in (0, 1).\n\n        Returns:\n            float: The calculated quantile.\n        \"\"\"\n        B = len(sorted_data)\n        \n        # Calculate the position index h = (B-1)p + 1.\n        h = (B - 1) * p + 1.0\n        \n        # Get integer and fractional parts of h.\n        k = int(h)\n        t = h - k\n        \n        # Convert 1-based k to 0-based index.\n        idx_k = k - 1\n        \n        # Get the value at the k-th order statistic.\n        val_k = sorted_data[idx_k]\n        \n        # Handle the edge case where k is the last element index.\n        # The convention is m*(B+1) = m*(B), making the difference term zero.\n        if k == B:\n            return val_k\n        else:\n            # Get the value at the (k+1)-th order statistic.\n            idx_k_plus_1 = k\n            val_k_plus_1 = sorted_data[idx_k_plus_1]\n            \n            # Apply the linear interpolation formula.\n            return val_k + t * (val_k_plus_1 - val_k)\n\n    def run_simulation(dist_func, true_median, n, alpha, B, R, local_rng):\n        \"\"\"\n        Runs the full simulation for one test case.\n\n        Args:\n            dist_func (callable): A function that takes size n and returns a random sample.\n            true_median (float): The true population median.\n            n (int): The sample size.\n            alpha (float): The significance level.\n            B (int): The number of bootstrap resamples.\n            R (int): The number of Monte Carlo repetitions.\n            local_rng (np.random.Generator): The random number generator instance.\n\n        Returns:\n            float: The empirical coverage probability.\n        \"\"\"\n        coverage_count = 0\n        \n        # Outer loop for Monte Carlo replications.\n        for _ in range(R):\n            # 1. Generate an i.i.d. sample of size n.\n            sample = dist_func(n, local_rng)\n            \n            bootstrap_medians = np.empty(B)\n            \n            # Inner loop for bootstrap resampling.\n            for i in range(B):\n                # 2. Generate a bootstrap resample.\n                resample = local_rng.choice(sample, size=n, replace=True)\n                \n                # 3. Compute and store the median of the resample.\n                bootstrap_medians[i] = np.median(resample)\n            \n            # 4. Sort the bootstrap medians to get order statistics.\n            bootstrap_medians.sort()\n            \n            # 5. Compute the percentile confidence interval.\n            lower_quantile = alpha / 2.0\n            upper_quantile = 1.0 - (alpha / 2.0)\n            \n            ci_lower = _calculate_quantile(bootstrap_medians, lower_quantile)\n            ci_upper = _calculate_quantile(bootstrap_medians, upper_quantile)\n            \n            # 6. Check for coverage.\n            if ci_lower = true_median = ci_upper:\n                coverage_count += 1\n                \n        # 7. Calculate empirical coverage.\n        return coverage_count / R\n\n    # Define random variate generation functions\n    dist_normal = lambda size, r: r.normal(loc=0, scale=1, size=size)\n    dist_laplace = lambda size, r: r.laplace(loc=0, scale=1, size=size)\n    # Numpy's exponential uses scale = 1/lambda. Rate lambda=1 means scale=1.\n    dist_exponential = lambda size, r: r.exponential(scale=1, size=size)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: Normal(0, 1)\n        {'name': 'Normal', 'dist': dist_normal, 'median': 0.0, 'n': 40, 'alpha': 0.05, 'B': 300, 'R': 400},\n        # Case 2: Laplace(0, 1)\n        {'name': 'Laplace', 'dist': dist_laplace, 'median': 0.0, 'n': 40, 'alpha': 0.05, 'B': 300, 'R': 400},\n        # Case 3: Exponential(1), small n\n        {'name': 'Exponential_40', 'dist': dist_exponential, 'median': np.log(2), 'n': 40, 'alpha': 0.05, 'B': 300, 'R': 400},\n        # Case 4: Exponential(1), large n\n        {'name': 'Exponential_120', 'dist': dist_exponential, 'median': np.log(2), 'n': 120, 'alpha': 0.05, 'B': 200, 'R': 300},\n    ]\n\n    results = []\n    for case in test_cases:\n        coverage = run_simulation(\n            dist_func=case['dist'],\n            true_median=case['median'],\n            n=case['n'],\n            alpha=case['alpha'],\n            B=case['B'],\n            R=case['R'],\n            local_rng=rng\n        )\n        results.append(coverage)\n\n    # Format the results as specified: rounded to exactly three decimal places.\n    formatted_results = [f\"{res:.3f}\" for res in results]\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "4954794"}]}