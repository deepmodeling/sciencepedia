{"hands_on_practices": [{"introduction": "在掌握了赤池信息准则（AIC）的基本原理之后，一个关键的实践步骤是将其应用于实际的模型比较中。然而，AIC的推导基于大样本理论，当样本量 $n$ 相对于模型参数数量 $k$ 不大时（例如，当 $n/k < 40$），其对偏差的校正可能不足。这个练习将引导您计算AIC及其小样本校正版AICc，从而揭示在何种情况下需要进行这种校正，以及这种校正如何影响模型选择的最终决策 [@problem_id:4966101]。", "problem": "一个临床流行病学团队使用两个候选高斯线性模型对 $n=40$ 名成年人体内一种循环炎症生物标志物的对数进行建模，这两个模型都具有独立、同方差的误差。模型 $\\mathcal{M}_{1}$ 的似然函数中包含 $k_{1}=10$ 个自由估计参数（回归系数、截距和未知的误差方差），而模型 $\\mathcal{M}_{2}$ 包含 $k_{2}=7$ 个此类参数。在模型 $\\mathcal{M}_{1}$ 下观测到的残差平方和为 $\\mathrm{RSS}_{1}=270$，在模型 $\\mathcal{M}_{2}$ 下为 $\\mathrm{RSS}_{2}=320$。\n\n从以下基本点出发：通过信息准则进行模型选择旨在最小化由Kullback–Leibler散度衡量的预期样本外差异；并且在高斯线性模型下，最大化对数似然来自于方差由最大似然估计得到的正态密度。请推导出一个信息准则的表达式，该准则用于估计预期的样本外偏差及其小样本偏差校正。利用这些推导，计算模型 $\\mathcal{M}_{1}$ 和 $\\mathcal{M}_{2}$ 的Akaike信息准则（AIC）和小样本校正AIC（AICc）的数值，并确定每个准则偏好哪个模型（值越小表示越偏好）。\n\n以单一数字形式报告量\n$$\\Delta_{\\mathrm{AICc}} \\equiv \\mathrm{AICc}(\\mathcal{M}_{1}) - \\mathrm{AICc}(\\mathcal{M}_{2}),$$\n并四舍五入到四位有效数字。不需要单位。", "solution": "用户的要求是解决一个统计建模问题。我将首先验证问题陈述。\n\n### 步骤1：提取给定条件\n- **样本量**：$n = 40$ 名成年人\n- **模型类型**：具有独立、同方差误差的高斯线性模型。\n- **模型 $\\mathcal{M}_{1}$**：\n    - 自由估计参数数量：$k_{1}=10$\n    - 残差平方和：$\\mathrm{RSS}_{1}=270$\n- **模型 $\\mathcal{M}_{2}$**：\n    - 自由估计参数数量：$k_{2}=7$\n    - 残差平方和：$\\mathrm{RSS}_{2}=320$\n- **目标**：\n    1. 推导用于估计预期样本外偏差及其小样本偏差校正的信息准则表达式。这对应于推导高斯模型下的AIC和AICc形式。\n    2. 计算模型 $\\mathcal{M}_{1}$ 和 $\\mathcal{M}_{2}$ 的AIC和AICc。\n    3. 确定每个准则偏好哪个模型。\n    4. 计算最终的量 $\\Delta_{\\mathrm{AICc}} \\equiv \\mathrm{AICc}(\\mathcal{M}_{1}) - \\mathrm{AICc}(\\mathcal{M}_{2})$，并四舍五入到四位有效数字。\n\n### 步骤2：使用提取的给定条件进行验证\n- **科学依据**：该问题植根于基础统计理论，特别是应用于线性回归的信息论模型选择（Kullback-Leibler散度、AIC、AICc）。这是生物统计学和流行病学中一种标准且成熟的方法。其前提是科学合理的。\n- **适定性**：问题定义清晰，提供了进行所需推导和计算的所有必要数值（$n$, $k_1$, $k_2$, $\\mathrm{RSS}_1$, $\\mathrm{RSS}_2$）和理论背景。存在唯一解。\n- **客观性**：问题以精确、定量且无偏见的语言陈述。\n\n该问题没有任何科学不合理、不完整、矛盾或模糊等缺陷。这是一个应用统计学中有效且适定的问题。\n\n### 步骤3：结论与行动\n问题有效。我将进行完整的推导和求解。\n\n***\n\n### 推导与求解\n\n信息论模型选择的目标是确定一个能够最好地近似未知、真实数据生成过程的模型。从真实过程到模型的先验指定的“距离”或“差异”通常由Kullback-Leibler (KL) 散度来衡量。对于一个真实的概率密度 $f(y)$ 和一个模型近似 $g(y|\\theta)$，KL散度由下式给出：\n$$D_{\\mathrm{KL}}(f || g) = \\int f(y) \\ln\\left(\\frac{f(y)}{g(y|\\theta)}\\right) dy$$\n相对于模型最小化 $D_{\\mathrm{KL}}(f || g)$ 等价于最大化 $\\int f(y) \\ln(g(y|\\theta)) dy$ 项，因为 $\\int f(y) \\ln(f(y)) dy$ 是一个仅取决于真实（但未知）过程的常数。\n\n我们使用一个包含 $n$ 个观测值的数据集来估计模型参数，得到最大似然估计 (MLE)，$\\hat{\\theta}$。拟合模型的质量通过其在来自同一过程的新的、独立数据上的预期性能来判断。这就是预期的样本外KL散度，或者等效地，预期的样本外对数似然。Akaike (1973) 的一个基本结果表明，当前数据的最大化对数似然 $\\ln(L(\\hat{\\theta}|y))$ 是这个目标量的一个有偏估计量。Akaike 证明，通过校正这种偏差，可以获得预期相对KL散度的一个低偏差估计量。这就引出了Akaike信息准则 (AIC)。\n\nAIC是预期样本外对数似然乘以-2的估计量。其定义为：\n$$\\mathrm{AIC} = -2 \\ln(L(\\hat{\\theta})) + 2k$$\n其中 $L(\\hat{\\theta})$ 是最大化似然，$k$ 是模型中自由估计参数的数量。$2k$ 项是渐近偏差校正。\n\n对于指定的高斯线性模型，$n$ 个观测值的似然函数为：\n$$L(\\beta, \\sigma^2) = (2\\pi\\sigma^2)^{-n/2} \\exp\\left(-\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - x_i^T\\beta)^2\\right)$$\n对数似然为：\n$$\\ln(L(\\beta, \\sigma^2)) = -\\frac{n}{2}\\ln(2\\pi) - \\frac{n}{2}\\ln(\\sigma^2) - \\frac{1}{2\\sigma^2} \\mathrm{RSS}(\\beta)$$\n其中 $\\mathrm{RSS}(\\beta) = \\sum_{i=1}^n (y_i - x_i^T\\beta)^2$。回归系数的MLE $\\hat{\\beta}$ 最小化残差平方和，得到观测到的 $\\mathrm{RSS}$。方差的MLE是 $\\hat{\\sigma}^2 = \\frac{\\mathrm{RSS}}{n}$。将这些代入对数似然函数，得到最大化对数似然：\n$$\\ln(L(\\hat{\\theta})) = -\\frac{n}{2}\\ln(2\\pi) - \\frac{n}{2}\\ln\\left(\\frac{\\mathrm{RSS}}{n}\\right) - \\frac{n}{2}$$\n那么AIC为：\n$$\\mathrm{AIC} = -2\\left(-\\frac{n}{2}\\ln(2\\pi) - \\frac{n}{2}\\ln\\left(\\frac{\\mathrm{RSS}}{n}\\right) - \\frac{n}{2}\\right) + 2k$$\n$$\\mathrm{AIC} = n\\ln(2\\pi) + n\\ln\\left(\\frac{\\mathrm{RSS}}{n}\\right) + n + 2k$$\n为了进行模型比较，所有模型共有的常数项（如 $n\\ln(2\\pi)+n$）可以被省略。高斯模型的常规AIC形式为：\n$$\\mathrm{AIC} = n\\ln\\left(\\frac{\\mathrm{RSS}}{n}\\right) + 2k$$\n\nAIC的推导依赖于大样本理论。当样本量 $n$ 相对于参数数量 $k$ 不够大时，惩罚项 $2k$ 是不足的。Sugiura (1978) 以及 Hurvich 和 Tsai (1989) 为线性模型推导了一个更精确的二阶偏差校正，从而产生了小样本AIC，即AICc。该准则是通过寻找一个更精确的预期KL散度估计量而得出的。结果是AIC中的偏差校正项 $2k$ 应被一个更精细的项所取代。AICc由下式给出：\n$$\\mathrm{AICc} = -2\\ln(L(\\hat{\\theta})) + 2k \\frac{n}{n-k-1}$$\n这可以表示为与AIC的关系：\n$$\\mathrm{AICc} = \\left( -2\\ln(L(\\hat{\\theta})) + 2k \\right) - 2k + 2k \\frac{n}{n-k-1} = \\mathrm{AIC} + 2k\\left(\\frac{n}{n-k-1} - 1\\right)$$\n$$\\mathrm{AICc} = \\mathrm{AIC} + 2k\\left(\\frac{n - (n-k-1)}{n-k-1}\\right) = \\mathrm{AIC} + \\frac{2k(k+1)}{n-k-1}$$\n使用AIC的常规形式，我们有：\n$$\\mathrm{AICc} = n\\ln\\left(\\frac{\\mathrm{RSS}}{n}\\right) + 2k + \\frac{2k(k+1)}{n-k-1}$$\n当 $n/k < 40$ 时，推荐使用此校正。\n\n我们现在将这些公式应用于给定的模型。已知 $n=40$。\n\n**对于模型 $\\mathcal{M}_{1}$**：\n$k_{1}=10$, $\\mathrm{RSS}_{1}=270$。\n首先，我们计算 $\\mathcal{M}_{1}$ 的AIC：\n$$\\mathrm{AIC}(\\mathcal{M}_{1}) = n\\ln\\left(\\frac{\\mathrm{RSS}_{1}}{n}\\right) + 2k_1 = 40\\ln\\left(\\frac{270}{40}\\right) + 2(10)$$\n$$\\mathrm{AIC}(\\mathcal{M}_{1}) = 40\\ln(6.75) + 20 \\approx 40(1.90954) + 20 = 76.3817 + 20 = 96.3817$$\n由于 $n/k_1 = 40/10 = 4 < 40$，小样本校正是必要的。\n$$\\mathrm{AICc}(\\mathcal{M}_{1}) = \\mathrm{AIC}(\\mathcal{M}_{1}) + \\frac{2k_1(k_1+1)}{n-k_1-1} = 96.3817 + \\frac{2(10)(10+1)}{40-10-1}$$\n$$\\mathrm{AICc}(\\mathcal{M}_{1}) = 96.3817 + \\frac{2(10)(11)}{29} = 96.3817 + \\frac{220}{29} \\approx 96.3817 + 7.5862 = 103.9679$$\n\n**对于模型 $\\mathcal{M}_{2}$**：\n$k_{2}=7$, $\\mathrm{RSS}_{2}=320$。\n首先，我们计算 $\\mathcal{M}_{2}$ 的AIC：\n$$\\mathrm{AIC}(\\mathcal{M}_{2}) = n\\ln\\left(\\frac{\\mathrm{RSS}_{2}}{n}\\right) + 2k_2 = 40\\ln\\left(\\frac{320}{40}\\right) + 2(7)$$\n$$\\mathrm{AIC}(\\mathcal{M}_{2}) = 40\\ln(8) + 14 \\approx 40(2.07944) + 14 = 83.1777 + 14 = 97.1777$$\n由于 $n/k_2 = 40/7 \\approx 5.7 < 40$，小样本校正也是必要的。\n$$\\mathrm{AICc}(\\mathcal{M}_{2}) = \\mathrm{AIC}(\\mathcal{M}_{2}) + \\frac{2k_2(k_2+1)}{n-k_2-1} = 97.1777 + \\frac{2(7)(7+1)}{40-7-1}$$\n$$\\mathrm{AICc}(\\mathcal{M}_{2}) = 97.1777 + \\frac{2(7)(8)}{32} = 97.1777 + \\frac{112}{32} = 97.1777 + 3.5 = 100.6777$$\n\n### 模型偏好\n被偏好的模型是信息准则值较低的那个。\n- **使用AIC**：$\\mathrm{AIC}(\\mathcal{M}_{1}) \\approx 96.38$ 且 $\\mathrm{AIC}(\\mathcal{M}_{2}) \\approx 97.18$。由于 $\\mathrm{AIC}(\\mathcal{M}_{1}) < \\mathrm{AIC}(\\mathcal{M}_{2})$，AIC准则偏好更复杂的模型 $\\mathcal{M}_{1}$。\n- **使用AICc**：$\\mathrm{AICc}(\\mathcal{M}_{1}) \\approx 103.97$ 且 $\\mathrm{AICc}(\\mathcal{M}_{2}) \\approx 100.68$。由于 $\\mathrm{AICc}(\\mathcal{M}_{2}) < \\mathrm{AICc}(\\mathcal{M}_{1})$，AICc准则偏好更简单的模型 $\\mathcal{M}_{2}$。在小样本情境下，对复杂度的更大惩罚逆转了模型的偏好。\n\n### 最终计算\n问题要求计算 $\\Delta_{\\mathrm{AICc}} \\equiv \\mathrm{AICc}(\\mathcal{M}_{1}) - \\mathrm{AICc}(\\mathcal{M}_{2})$ 的值。\n$$\\Delta_{\\mathrm{AICc}} = 103.9679... - 100.6777... = 3.2902...$$\n四舍五入到四位有效数字，我们得到 $3.290$。", "answer": "$$\\boxed{3.290}$$", "id": "4966101"}, {"introduction": "在多元回归模型中，共线性是研究者经常遇到的一个棘手问题。当两个或多个预测变量高度相关时，我们如何判断是否应将它们都包含在模型中？信息准则通过其对模型复杂度的惩罚项，为我们提供了一个量化的决策框架。本练习通过一个包含高度共线性变量的假设场景，让您亲手计算并比较AIC和BIC的选择，从而深刻理解AIC的$2k$惩罚项与BIC的$k \\ln(n)$惩罚项在实践中的差异，特别是在处理冗余变量时的不同“偏好” [@problem_id:4966069]。", "problem": "一项基于医院的队列研究在线性回归框架下，使用高斯残差对一个连续的生物标志物结局进行建模。研究人员考虑了以下候选模型，这些模型均通过最大似然法对同一样本量为 $n=600$ 的数据集进行拟合：\n- $M_0$：截距、年龄、性别和一个合并症指数（包括截距在内共有 $p_0=4$ 个参数）。\n- $M_1$：$M_0$ 加上体重指数 (BMI)（$p_1=5$）。\n- $M_2$：$M_0$ 加上腰围 (WC)（$p_2=5$）。\n- $M_3$：$M_0$ 加上 BMI 和 WC（$p_3=6$）。\n\n在研究人群中，BMI 和 WC 高度相关，其皮尔逊相关系数 $\\rho=0.96$，反映了共线性问题。设每个拟合模型的残差平方和为：\n- $RSS_0=120000$，\n- $RSS_1=119400$，\n- $RSS_2=119380$，\n- $RSS_3=119360$。\n\n假设满足最大似然估计的标准正则性条件，并且所有模型都是可识别的、设定正确的，并具有同方差正态误差。仅利用信息准则权衡数据拟合度（通过最大化似然函数）与模型复杂度（自由参数的数量）这一基本思想，回答以下问题。关于共线性在赤池信息准则 (AIC) 和贝叶斯信息准则 (BIC) 下对模型选择的影响，以及在这种情况下会选择哪些模型，以下哪些陈述是正确的？\n\nA. 在 AIC 下，选择 $M_2$；在 BIC 下，选择 $M_0$。\n\nB. 在 AIC 下，$M_3$ 优于 $M_2$，因为增加参数时最大化对数似然不会减小，且 $M_2$ 和 $M_3$ 的惩罚项相同。\n\nC. 从 $M_2$ 到 $M_3$ 的微小增量改进是 BMI 和 WC 之间共线性的直接体现；在大样本量 $n$ 的情况下，BIC 对每个参数的更强惩罚使其比 AIC 更不可能包含此类冗余的预测变量。\n\nD. 如果样本量减少到 $n=60$ 而 $RSS$ 值保持不变，BIC 对额外参数的惩罚将小于 AIC，使其比 AIC 更愿意包含冗余的预测变量。", "solution": "在进行求解之前，首先对问题陈述的有效性进行严格评估。\n\n### 步骤1：提取已知条件\n-   **研究设计**：基于医院的队列研究。\n-   **统计框架**：使用高斯残差对连续生物标志物进行线性回归。\n-   **估计方法**：最大似然估计 (MLE)。\n-   **样本量**：$n=600$。\n-   **候选模型**：\n    -   $M_0$：截距、年龄、性别、合并症指数。回归参数数量 $p_0=4$。\n    -   $M_1$：$M_0$ + 体重指数 (BMI)。回归参数数量 $p_1=5$。\n    -   $M_2$：$M_0$ + 腰围 (WC)。回归参数数量 $p_2=5$。\n    -   $M_3$：$M_0$ + BMI + WC。回归参数数量 $p_3=6$。\n-   **预测变量相关性**：BMI 和 WC 之间的皮尔逊相关系数，$\\rho=0.96$。\n-   **残差平方和 (RSS)**：\n    -   $RSS_0=120000$\n    -   $RSS_1=119400$\n    -   $RSS_2=119380$\n    -   $RSS_3=119360$\n-   **假设**：满足 MLE 的标准正则性条件，模型可识别，设定正确，以及同方差正态误差。\n-   **任务**：评估关于使用赤池信息准则 (AIC) 和贝叶斯信息准则 (BIC) 进行模型选择的陈述，重点关注共线性的影响。\n\n### 步骤2：使用提取的已知条件进行验证\n1.  **科学依据**：该问题在标准统计理论中有充分的依据。线性回归、MLE、AIC、BIC 和共线性是统计建模的核心概念。该场景是医学研究中的一个现实应用。\n2.  **良构性**：该问题提供了计算 AIC 和 BIC 值并比较模型所需的所有必要数据（每个模型的 $n$、$p_i$、$RSS_i$）。问题明确无歧义。\n3.  **客观性**：问题陈述使用了精确、客观的语言和定量数据。\n4.  **一致性**：参数数量随模型复杂度的增加而逻辑地增加：$p_0=4$，$p_1=5$，$p_2=5$，$p_3=6$。随着参数的增加，RSS 值减小（$RSS_0 > RSS_1, RSS_2 > RSS_3$），这对于嵌套模型是数学上的必然。在添加高度相关的预测变量时，RSS 的微小下降与共线性现象一致。整个设定是内部一致的。\n\n### 步骤3：结论与行动\n该问题是有效的，因为它科学合理、良构、客观且内部一致。可以推导出解答。\n\n### 推导与选项分析\n\n信息准则的基本原理是在拟合优度与模型复杂度之间取得平衡。其一般形式为：\n-   赤池信息准则 (AIC)：$\\mathrm{AIC} = -2 \\ln(\\mathcal{L}_{max}) + 2k$\n-   贝叶斯信息准则 (BIC)：$\\mathrm{BIC} = -2 \\ln(\\mathcal{L}_{max}) + k \\ln(n)$\n\n其中 $\\mathcal{L}_{max}$ 是最大似然值，$k$ 是估计参数的总数，$n$ 是样本量。AIC 或 BIC 值最低的模型是首选模型。\n\n对于一个包含 $p$ 个回归系数（包括截距）并假设误差为同方差高斯分布的线性回归模型，方差 $\\sigma^2$ 也需要被估计。因此，估计参数的总数为 $k = p+1$。使用方差的 MLE 估计 $\\hat{\\sigma}^2 = RSS/n$，最大化对数似然由下式给出：\n$$ \\ln(\\mathcal{L}_{max}) = -\\frac{n}{2}\\left(\\ln(2\\pi) + 1 + \\ln\\left(\\frac{RSS}{n}\\right)\\right) $$\n将此代入 AIC 和 BIC 公式可得：\n$$ \\mathrm{AIC} = n(\\ln(2\\pi) + 1) + n\\ln\\left(\\frac{RSS}{n}\\right) + 2(p+1) $$\n$$ \\mathrm{BIC} = n(\\ln(2\\pi) + 1) + n\\ln\\left(\\frac{RSS}{n}\\right) + (p+1)\\ln(n) $$\n对于拟合到相同数据的模型进行比较时，常数项 $n(\\ln(2\\pi) + 1)$ 可以忽略。因此，我们可以使用以下成比例的量来比较模型：\n$\\mathrm{AIC}' \\propto n\\ln(RSS) + 2p$\n$\\mathrm{BIC}' \\propto n\\ln(RSS) + p\\ln(n)$\n注意，在惩罚项中使用 $p$ 而不是 $k=p+1$ 会得到相同的模型排序，因为任意两个模型之间惩罚项的差异保持不变。这里，$p$ 是回归系数的数量。我们将使用给定的 $p_i$ 值。\n\n给定 $n=600$，BIC 对每个参数的惩罚是 $\\ln(600) \\approx 6.397$。\n\n让我们为每个模型计算 $n\\ln(RSS)$、AIC 惩罚项 ($2p$) 和 BIC 惩罚项 ($p\\ln(n)$) 的值。我们将比较它们的和（与 AIC 和 BIC 成比例）。\n\n**模型 $M_0$**：$p_0=4$, $RSS_0=120000$\n-   $n\\ln(RSS_0) = 600 \\times \\ln(120000) \\approx 7017.15$\n-   $\\mathrm{AIC}_0 \\propto 7017.15 + 2(4) = 7025.15$\n-   $\\mathrm{BIC}_0 \\propto 7017.15 + 4 \\times \\ln(600) \\approx 7017.15 + 25.59 = 7042.74$\n\n**模型 $M_1$**：$p_1=5$, $RSS_1=119400$\n-   $n\\ln(RSS_1) = 600 \\times \\ln(119400) \\approx 7014.08$\n-   $\\mathrm{AIC}_1 \\propto 7014.08 + 2(5) = 7024.08$\n-   $\\mathrm{BIC}_1 \\propto 7014.08 + 5 \\times \\ln(600) \\approx 7014.08 + 31.98 = 7046.06$\n\n**模型 $M_2$**：$p_2=5$, $RSS_2=119380$\n-   $n\\ln(RSS_2) = 600 \\times \\ln(119380) \\approx 7013.98$\n-   $\\mathrm{AIC}_2 \\propto 7013.98 + 2(5) = 7023.98$\n-   $\\mathrm{BIC}_2 \\propto 7013.98 + 5 \\times \\ln(600) \\approx 7013.98 + 31.98 = 7045.96$\n\n**模型 $M_3$**：$p_3=6$, $RSS_3=119360$\n-   $n\\ln(RSS_3) = 600 \\times \\ln(119360) \\approx 7013.88$\n-   $\\mathrm{AIC}_3 \\propto 7013.88 + 2(6) = 7025.88$\n-   $\\mathrm{BIC}_3 \\propto 7013.88 + 6 \\times \\ln(600) \\approx 7013.88 + 38.38 = 7052.26$\n\n**模型选择总结**：\n-   **AIC 排序（越低越好）**：$\\mathrm{AIC}_2 (7023.98) < \\mathrm{AIC}_1 (7024.08) < \\mathrm{AIC}_0 (7025.15) < \\mathrm{AIC}_3 (7025.88)$。AIC 选择模型 $M_2$。\n-   **BIC 排序（越低越好）**：$\\mathrm{BIC}_0 (7042.74) < \\mathrm{BIC}_2 (7045.96) < \\mathrm{BIC}_1 (7046.06) < \\mathrm{BIC}_3 (7052.26)$。BIC 选择模型 $M_0$。\n\n基于这些结果，我们评估每个选项。\n\n**A. 在 AIC 下，选择 $M_2$；在 BIC 下，选择 $M_0$。**\n我们的计算表明，最小的 AIC 值属于模型 $M_2$，最小的 BIC 值属于模型 $M_0$。该陈述是对计算结果的直接且准确的报告。\n**结论：正确。**\n\n**B. 在 AIC 下，$M_3$ 优于 $M_2$，因为增加参数时最大化对数似然不会减小，且 $M_2$ 和 $M_3$ 的惩罚项相同。**\n该陈述存在一个关键性错误。$M_3$ 的最大化对数似然确实高于 $M_2$（因为 $RSS_3 < RSS_2$）。然而，“$M_2$ 和 $M_3$ 的惩罚项相同”这一说法是错误的。\n-   对于 $M_2$，参数数量为 $p_2=5$，因此 AIC 惩罚为 $2p_2=10$。\n-   对于 $M_3$，参数数量为 $p_3=6$，因此 AIC 惩罚为 $2p_3=12$。\n惩罚项是不同的。此外，我们的计算显示 $\\mathrm{AIC}_3 \\approx 7025.88 > \\mathrm{AIC}_2 \\approx 7023.98$，因此在 AIC 下 $M_2$ 优于 $M_3$，这与该陈述的主要主张相矛盾。\n**结论：不正确。**\n\n**C. 从 $M_2$ 到 $M_3$ 的微小增量改进是 BMI 和 WC 之间共线性的直接体现；在大样本量 $n$ 的情况下，BIC 对每个参数的更强惩罚使其比 AIC 更不可能包含此类冗余的预测变量。**\n该陈述包含两个部分。\n1.  “从 $M_2$ 到 $M_3$ 的微小增量改进是 BMI 和 WC 之间共线性的直接体现。”模型 $M_3$ 在模型 $M_2$ 的基础上增加了 BMI。RSS 的减少量为 $RSS_2 - RSS_3 = 119380 - 119360 = 20$。这是一个非常小的拟合改进，特别是与将 WC 添加到 $M_0$ 所带来的改进（$RSS_0 - RSS_2 = 120000 - 119380 = 620$）相比。当添加一个与模型中已有的预测变量（WC）高度相关的预测变量（BMI）时，这种微小的增量收益正是所预期的。这部分陈述是对数据的正确解读。\n2.  “在大样本量 $n$ 的情况下，BIC 对每个参数的更强惩罚使其比 AIC 更不可能包含此类冗余的预测变量。” AIC 对每个额外参数的惩罚是 $2$，而 BIC 是 $\\ln(n)$。给定 $n=600$，$\\ln(600) \\approx 6.397 > 2$。因此，BIC 的惩罚要强得多。这个更大的惩罚意味着 BIC 需要更大的似然改进来证明增加一个参数是合理的，这使得它更“简约”或保守。因此，它比 AIC 更不可能选择带有额外（尤其是冗余）参数的模型。这是关于 AIC 与 BIC 行为的一个基本且正确的概念性观点。这个普遍原则在本问题中得到了证明：AIC 增加了一个预测变量（选择 $M_2$ 而非 $M_0$），而 BIC 没有（选择 $M_0$ 而非 $M_2$）。\n陈述的两个部分在概念上和事实上都是正确的。\n**结论：正确。**\n\n**D. 如果样本量减少到 $n=60$ 而 $RSS$ 值保持不变，BIC 对额外参数的惩罚将小于 AIC，使其比 AIC 更愿意包含冗余的预测变量。**\n该陈述提出了一个假设情景。其关键主张是“BIC 对额外参数的惩罚将小于 AIC”。我们来验证一下。\n-   AIC 对每个参数的惩罚是一个常数，$2$。\n-   BIC 对每个参数的惩罚是 $\\ln(n)$。对于假设的 $n=60$，这将是 $\\ln(60) \\approx 4.094$。\n-   由于 $4.094 > 2$，BIC 的惩罚仍然大于 AIC 的惩罚。只有当 $\\ln(n) < 2$ 时，即 $n < e^2 \\approx 7.39$ 时，BIC 对每个参数的惩罚才会小于 AIC。\n-   该陈述的前提是错误的。因此，BIC会“更愿意”添加预测变量的结论也是错误的。\n**结论：不正确。**\n\n由于陈述 A 和 C 都是正确的，并且说明允许有多个正确选项，因此它们都必须包含在最终答案中。", "answer": "$$\\boxed{AC}$$", "id": "4966069"}, {"introduction": "模型选择的终点并非简单地在候选模型中选出一个“最佳”模型。一个更高级的实践是量化不同模型之间的证据强度。本练习将引导您超越简单的模型排序，学习如何利用AIC和BIC的差值（$\\Delta \\mathrm{AIC}$ 和 $\\Delta \\mathrm{BIC}$）来计算更有信息量的指标。您将推导并计算基于AIC的证据比（evidence ratio）和基于BIC的近似贝叶斯因子，从而学会如何衡量一个模型相对于另一个模型的支持程度，这为模型平均和更稳健的科学推断奠定了基础 [@problem_id:4966114]。", "problem": "一个临床团队正在比较两种用于预测重症监护室 $n=1200$ 名成年患者院内死亡率的逻辑斯蒂回归风险模型。模型 $\\mathcal{M}_{1}$ 包含 $k_{1}=15$ 个协变量（包括截距项），模型 $\\mathcal{M}_{2}$ 包含 $k_{2}=10$ 个协变量（包括截距项）。两个模型都是在伯努利抽样模型下，使用标准的logit链接函数，通过最大似然法进行拟合的。模型 $\\mathcal{M}_{1}$ 的最大化对数似然值（使用自然对数）为 $\\ell_{1}=-520.3$，模型 $\\mathcal{M}_{2}$ 的为 $\\ell_{2}=-523.1$。\n\n仅使用基本原理和定义，按如下步骤进行：\n\n1. 从 Kullback–Leibler 散度的定义、预期样本外预测性能的概念，以及模型比较应近似于最小化预期 Kullback–Leibler 风险的原则出发。以此为基础，推导赤池信息准则 (Akaike Information Criterion, AIC) 的差异如何引出相对模型支持度和证据比，并基于 AIC 差异计算模型 $\\mathcal{M}_{2}$ 相对于 $\\mathcal{M}_{1}$ 的证据比。\n\n2. 从基于边际似然的贝叶斯模型选择出发，在参数模型的正则性条件下应用拉普拉斯近似 (Laplace approximation)，将贝叶斯模型证据与一个渐近准则联系起来。以此为基础，推导贝叶斯信息准则 (Bayesian Information Criterion, BIC) 的差异如何近似贝叶斯因子 (Bayes factors)，并计算支持模型 $\\mathcal{M}_{2}$ 相对于 $\\mathcal{M}_{1}$ 的近似贝叶斯因子。\n\n假设两个模型都是正则的（即可识别，且 Fisher 信息矩阵非奇异），似然值在其最大似然估计处计算，并且全程使用自然对数。将最终数值结果表示为两个数：基于 AIC 的模型 $\\mathcal{M}_{2}$ 相对于 $\\mathcal{M}_{1}$ 的证据比，以及基于 BIC 的支持模型 $\\mathcal{M}_{2}$ 相对于 $\\mathcal{M}_{1}$ 的近似贝叶斯因子。将您的数值答案四舍五入到三位有效数字。无需物理单位。将这两个数按顺序放入最终答案中，作为一个单行矩阵。", "solution": "第一个任务的基本依据是 Kullback–Leibler 散度。对于一个真实的数据生成分布 $f$ 和一个参数模型 $g(\\cdot \\mid \\theta)$，从 $f$ 到 $g(\\cdot \\mid \\theta)$ 的 Kullback–Leibler 散度为\n$$\nD_{\\mathrm{KL}}(f \\,\\|\\, g_{\\theta}) \\;=\\; \\int f(x) \\ln\\!\\left(\\frac{f(x)}{g(x \\mid \\theta)}\\right) \\, dx \\;=\\; \\mathbb{E}_{f}\\!\\left[\\ln f(X) - \\ln g(X \\mid \\theta)\\right].\n$$\n通过最小化预期样本外 Kullback–Leibler 风险来进行模型选择，旨在寻找一个能最大化从 $f$ 中抽取的新数据的预期对数似然的模型。然而，由于过拟合，最大化的样本内对数似然 $\\ell(\\hat{\\theta})$ 会高估预期的样本外对数似然。在正则性条件下，Akaike 证明了这种偏差在渐近意义上等于自由参数的数量 $k$。因此，预期样本外负二倍对数似然的一个无偏估计量是\n$$\n\\mathrm{AIC} \\;=\\; 2k - 2\\ell(\\hat{\\theta}).\n$$\nAIC 的差异，定义为 $\\Delta_{i} = \\mathrm{AIC}_{i} - \\min_{j} \\mathrm{AIC}_{j}$，可以通过一种指数尺度变换转化为对模型的相对支持度，其动机是 AIC 差异与预期 Kullback–Leibler 风险差异的渐近等价性。由此产生的相对支持度权重（常被称为 Akaike 权重）为\n$$\nw_{i} \\;\\propto\\; \\exp\\!\\left(-\\frac{1}{2}\\Delta_{i}\\right),\n$$\n在候选模型集中进行归一化。对于两个模型，$\\mathcal{M}_{2}$ 相对于 $\\mathcal{M}_{1}$ 的证据比为\n$$\n\\frac{w_{2}}{w_{1}} \\;=\\; \\exp\\!\\left(-\\frac{1}{2}(\\Delta_{2} - \\Delta_{1})\\right) \\;=\\; \\exp\\!\\left(\\frac{1}{2}\\Delta_{1}\\right),\n$$\n因为当模型 $\\mathcal{M}_{2}$ 的 AIC 最小时，$\\Delta_{2}=0$。\n\n我们使用给定的对数似然值计算 AIC 值：\n$$\n\\mathrm{AIC}_{1} \\;=\\; 2k_{1} - 2\\ell_{1} \\;=\\; 2\\cdot 15 - 2(-520.3) \\;=\\; 30 + 1040.6 \\;=\\; 1070.6,\n$$\n$$\n\\mathrm{AIC}_{2} \\;=\\; 2k_{2} - 2\\ell_{2} \\;=\\; 2\\cdot 10 - 2(-523.1) \\;=\\; 20 + 1046.2 \\;=\\; 1066.2.\n$$\n因此，\n$$\n\\Delta_{2} \\;=\\; 0, \\qquad \\Delta_{1} \\;=\\; 1070.6 - 1066.2 \\;=\\; 4.4,\n$$\n并且基于 AIC 的模型 $\\mathcal{M}_{2}$ 相对于 $\\mathcal{M}_{1}$ 的证据比是\n$$\n\\frac{w_{2}}{w_{1}} \\;=\\; \\exp\\!\\left(\\frac{1}{2}\\cdot 4.4\\right) \\;=\\; \\exp(2.2).\n$$\n\n对于第二个任务，基本依据是通过边际似然进行的贝叶斯模型选择。给定一个参数为 $\\theta$、先验为 $\\pi(\\theta)$ 的模型 $\\mathcal{M}$，其边际似然为\n$$\np(\\mathbf{y} \\mid \\mathcal{M}) \\;=\\; \\int p(\\mathbf{y} \\mid \\theta, \\mathcal{M}) \\, \\pi(\\theta \\mid \\mathcal{M}) \\, d\\theta.\n$$\n比较模型 $\\mathcal{M}_{2}$ 与 $\\mathcal{M}_{1}$ 的贝叶斯因子 $\\mathrm{BF}_{21}$ 是\n$$\n\\mathrm{BF}_{21} \\;=\\; \\frac{p(\\mathbf{y} \\mid \\mathcal{M}_{2})}{p(\\mathbf{y} \\mid \\mathcal{M}_{1})}.\n$$\n在正则性条件下，且当 $n$ 很大时，拉普拉斯近似 (Laplace approximation) 得到\n$$\n\\ln p(\\mathbf{y} \\mid \\mathcal{M}) \\;\\approx\\; \\ell(\\hat{\\theta}) - \\frac{k}{2}\\ln n \\;+\\; C_{\\mathcal{M}},\n$$\n其中 $C_{\\mathcal{M}}$ 是一个依赖于模型的常数，当先验在 $\\sqrt{n}$ 的尺度上信息量不是过大时，该常数在求差时会相互抵消。乘以 $-2$ 并舍去常数项，得到贝叶斯信息准则 (Bayesian Information Criterion, BIC)，\n$$\n\\mathrm{BIC} \\;=\\; k \\ln n - 2 \\ell(\\hat{\\theta}),\n$$\n并且 BIC 的差异近似于对数贝叶斯因子的负二倍：\n$$\n-2 \\ln \\mathrm{BF}_{21} \\;\\approx\\; \\mathrm{BIC}_{2} - \\mathrm{BIC}_{1}.\n$$\n等价地，\n$$\n\\mathrm{BF}_{21} \\;\\approx\\; \\exp\\!\\left(-\\frac{1}{2}\\left[\\mathrm{BIC}_{2} - \\mathrm{BIC}_{1}\\right]\\right) \\;=\\; \\exp\\!\\left(\\frac{1}{2}\\left[\\mathrm{BIC}_{1} - \\mathrm{BIC}_{2}\\right]\\right).\n$$\n\n我们使用 $n=1200$ 计算 BIC 值：\n$$\n\\ln n \\;=\\; \\ln(1200) \\;=\\; \\ln(12) + \\ln(100) \\;=\\; 2.48490665 + 4.605170186 \\;=\\; 7.090076836,\n$$\n$$\n\\mathrm{BIC}_{1} \\;=\\; k_{1}\\ln n - 2\\ell_{1} \\;=\\; 15 \\cdot 7.090076836 - 2(-520.3) \\;=\\; 106.3511525 + 1040.6 \\;=\\; 1146.9511525,\n$$\n$$\n\\mathrm{BIC}_{2} \\;=\\; k_{2}\\ln n - 2\\ell_{2} \\;=\\; 10 \\cdot 7.090076836 - 2(-523.1) \\;=\\; 70.90076836 + 1046.2 \\;=\\; 1117.10076836.\n$$\n因此，\n$$\n\\mathrm{BIC}_{1} - \\mathrm{BIC}_{2} \\;=\\; 1146.9511525 - 1117.10076836 \\;=\\; 29.85038414,\n$$\n并且基于 BIC 的支持模型 $\\mathcal{M}_{2}$ 的近似贝叶斯因子是\n$$\n\\mathrm{BF}_{21} \\;\\approx\\; \\exp\\!\\left(\\frac{1}{2}\\cdot 29.85038414\\right) \\;=\\; \\exp(14.92519207).\n$$\n\n数值计算结果：\n- AIC 证据比：$\\exp(2.2) \\approx 9.025013$。\n- BIC 贝叶斯因子：$\\exp(14.92519207) \\approx 3.03 \\times 10^{6}$。\n\n将每个数值四舍五入到三位有效数字，所要求的数对（模型 $\\mathcal{M}_{2}$ 相对于 $\\mathcal{M}_{1}$ 的 AIC 证据比，支持 $\\mathcal{M}_{2}$ 的基于 BIC 的近似贝叶斯因子）为\n$$\n9.03 \\quad \\text{和} \\quad 3.03 \\times 10^{6}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix} 9.03 & 3.03 \\times 10^{6} \\end{pmatrix}}$$", "id": "4966114"}]}