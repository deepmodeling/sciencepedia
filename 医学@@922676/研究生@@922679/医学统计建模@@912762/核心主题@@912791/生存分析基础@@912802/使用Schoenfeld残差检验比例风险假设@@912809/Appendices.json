{"hands_on_practices": [{"introduction": "本练习关注Schoenfeld残差检验的一个关键组成部分：时间转换函数 $g(t)$ 的选择。通过探究不同 $g(t)$ 的选择如何影响检验的性质（例如对时间尺度变换的不变性），您将更深入地理解该检验的理论基础。这对于在不同情境下正确应用和解释检验结果至关重要。", "problem": "一项临床研究使用Cox比例风险模型对复合心血管终点事件的发生时间进行建模，该模型假定事件时间 $t$ 和协变量向量 $x$ 的风险函数为 $h(t \\mid x) = h_0(t) \\exp\\{x^\\top \\beta\\}$，其中基线风险 $h_0(t)$ 未指定。为评估单个协变量 $Z$ 的比例风险（PH）假设，一位研究者考虑了一个扩展模型，其中系数可能随时间变化：$\\beta_Z(t) = \\beta_Z + \\theta \\, g(t)$，其中 $g(t)$ 是事件时间的确定性函数，$\\theta$ 量化了对PH假设的偏离程度。可以通过检验协变量 $Z$ 在事件时间 $\\{t_j\\}$ 处的Schoenfeld残差（记为 $r_{jZ}$）与 $g(t_j)$ 的关联，来构建一个针对 $H_0: \\theta = 0$ 的得分检验。\n\n研究者正在为 $g(t)$ 从几个函数中进行选择：原始日历时间 $t$、对数转换后的时间 $\\log(t)$、事件秩次 $\\mathrm{rank}(t)$（即每个不同事件时间的顺序索引），以及估计的累积基线风险 $\\hat{H}_0(t)$（例如，通过Breslow估计量）。在Cox框架中，具有严格递增函数 $\\phi$ 的单调时间重参数化 $t' = \\phi(t)$ 不会改变风险集的排序，并且在这种重参数化下，真实的累积基线风险 $H_0(t)$ 满足恒等式 $H_0'(t') = H_0(t)$。\n\n关于 $g(t)$ 的选择以及基于Schoenfeld残差的PH检验的不变性，以下哪个陈述是正确的？\n\nA. 使用 $g(t) = \\mathrm{rank}(t)$ 会得到一个对时间尺度的任何严格递增变换都不变的检验，因为秩次仅取决于事件顺序，而偏似然仅取决于风险集的排序。\n\nB. 使用 $g(t) = t$ 和 $g(t) = \\log(t)$ 会得到相同的得分检验（在原假设和备择假设下均相同），因为 $t$ 和 $\\log(t)$ 都是 $t$ 的单调函数。\n\nC. 选择 $g(t) = \\hat{H}_0(t)$ 会得到一个对时间尺度的任何严格递增变换都渐近不变的检验，因为在Cox模型中，真实的累积基线风险 $H_0(t)$ 对时间的单调重参数化是不变的。\n\nD. 对于任何给定的 $g(t)$，若将其替换为 $g'(t) = a + b \\, g(t)$（其中常数 $a \\in \\mathbb{R}$ 且 $b > 0$），则针对 $H_0: \\theta = 0$ 的标准化得分检验保持不变。\n\nE. 在 $H_0: \\theta = 0$ 下，标准化得分检验的渐近零分布取决于 $g(t)$ 的选择；例如，使用 $g(t) = \\mathrm{rank}(t)$ 会得到与使用 $g(t) = t$ 不同的零分布自由度。\n\n选择所有适用的选项。", "solution": "我们从Cox模型的定义 $h(t \\mid x) = h_0(t) \\exp\\{x^\\top \\beta\\}$ 开始，其中 $h_0(t)$ 未指定。Cox偏似然是根据有序的事件时间 $\\{t_j\\}$ 和相应的风险集构建的，其值仅取决于事件的顺序（以及风险集中存在的协变量），而不取决于 $t$ 超出排序之外的实际数值大小。在每个不同的事件时间 $t_j$，协变量 $Z$ 的Schoenfeld残差为 $r_{jZ} = Z_{j}^{(\\text{event})} - \\mathbb{E}_{R_j}[Z]$，即事件发生者的协变量值减去风险集加权平均值，其中 $R_j$ 表示在 $t_j$ 时的风险集，期望是关于偏似然权重计算的。\n\n为了检验 $Z$ 的比例风险（PH）假设，我们考虑时变系数 $\\beta_Z(t) = \\beta_Z + \\theta \\, g(t)$，它定义了一个在对数风险比上具有结构化偏离的备择模型。在 $\\theta = 0$ 处评估的 $\\theta$ 的得分具有以下形式（在相差一个依赖于偏似然信息的常数因子的情况下）：\n$$\nU_\\theta = \\sum_{j} r_{jZ} \\, g(t_j),\n$$\n并且在 $H_0: \\theta = 0$ 下，一个标准化的得分检验（或等价地，将缩放后的Schoenfeld残差对 $g(t_j)$ 进行回归）会产生一个渐近正态的统计量。这个设置表明，该检验在时间变换和 $g(t)$ 变换下的性质可以从第一性原理推导出来。\n\n我们逐一分析每个选项：\n\nA. 使用 $g(t) = \\mathrm{rank}(t)$ 会产生对严格递增时间变换的不变性。如果 $t' = \\phi(t)$ 且 $\\phi$ 严格递增，则事件顺序保持不变，因此对所有 $j$，$\\mathrm{rank}(t_j)$ 等于 $\\mathrm{rank}(t'_j)$。偏似然以及Schoenfeld残差 $r_{jZ}$ 仅依赖于由事件顺序决定的风险集，而事件顺序不受此类 $\\phi$ 的影响。因此，$U_\\theta = \\sum_{j} r_{jZ} \\, \\mathrm{rank}(t_j)$ 在任何时间尺度的单调重参数化下都保持不变。所以，这个 $g(t)$ 的选择会得到一个对任何严格递增的时间变换都不变的检验。结论：正确。\n\nB. 使用 $g(t) = t$ 和 $g(t) = \\log(t)$ 会得到相同的得分检验，因为两者都是单调的。尽管 $t$ 和 $\\log(t)$ 都是 $t$ 的严格递增函数，但从 $t$到 $g(t)$ 的映射并非通过线性重缩放相关联；与 $t$ 相比，$\\log(t)$ 改变了事件时间之间的相对间距。将残差对 $g(t)$ 回归的标准化得分检验（例如，基于单参数斜率的 $t$-统计量或卡方统计量）对仿射变换 $g'(t) = a + b \\, g(t)$（其中 $b > 0$）是不变的，但通常对非线性的单调变换不是不变的。因此，使用 $g(t) = t$ 与使用 $g(t) = \\log(t)$ 会产生不同的检验统计量，并且对于特定的备择假设 $\\beta_Z(t) = \\beta_Z + \\theta \\, g(t)$ 会有不同的功效。结论：不正确。\n\nC. 选择 $g(t) = \\hat{H}_0(t)$ 会产生对单调时间变换的渐近不变性。在严格递增的重参数化 $t' = \\phi(t)$ 下，基线风险变换为 $h_0'(t') = h_0(t) \\, \\frac{dt}{dt'} = \\frac{h_0(t)}{\\phi'(t)}$。新时间尺度下的累积基线风险为\n$$\nH_0'(t') = \\int_0^{t'} h_0'(u') \\, du' = \\int_0^{t} \\frac{h_0(u)}{\\phi'(u)} \\, \\phi'(u) \\, du = \\int_0^{t} h_0(u) \\, du = H_0(t),\n$$\n因此真实的累积基线风险 $H_0(t)$ 对任何严格递增的时间重参数化都是不变的。如果我们设 $g(t) = H_0(t)$，那么在重参数化下 $g(t_j)$ 与 $g(t'_j)$ 完全相同，相应的得分 $U_\\theta$ 是精确不变的。使用估计的累积基线风险 $\\hat{H}_0(t)$（例如Breslow估计量）时，在正则性条件下 $\\hat{H}_0(t)$ 一致收敛于 $H_0(t)$，因此得到的检验对单调时间变换是渐近不变的。结论：正确。\n\nD. 将 $g(t)$ 替换为 $g'(t) = a + b \\, g(t)$（其中 $a \\in \\mathbb{R}$ 且 $b > 0$）会使标准化得分检验保持不变。得分为 $U_\\theta' = \\sum_j r_{jZ} \\, g'(t_j) = \\sum_j r_{jZ} \\, (a + b \\, g(t_j)) = a \\sum_j r_{jZ} + b \\sum_j r_{jZ} \\, g(t_j)$。在 $H_0: \\theta = 0$ 下，$\\sum_j r_{jZ}$ 的期望值为 $0$，在构建标准化检验时（例如，将残差对带有截距的 $g$ 进行回归，或对 $g$ 进行中心化），常数平移 $a$ 不会改变斜率估计值或其检验统计量。正向缩放 $b$ 会将斜率乘以 $b$，其标准误也乘以 $b$，从而使得标准化统计量（例如，$z$-分数或 $t$-统计量）在 $b > 0$ 时保持不变。因此，关于 $H_0: \\theta = 0$ 的决策对于具有正尺度因子的仿射变换是不变的。结论：正确。\n\nE. 在 $H_0: \\theta = 0$ 下，标准化得分检验的渐近零分布取决于 $g(t)$ 的选择；例如，使用 $g(t) = \\mathrm{rank}(t)$ 会得到与使用 $g(t) = t$ 不同的零分布自由度。在针对 $\\theta$ 的单参数得分检验中，只要满足正则性条件（例如，有限的信息量和非退化的方差），无论 $g(t)$ 的确定性选择如何，适当的标准化都会产生一个渐近标准正态统计量（或平方后为自由度为1的卡方统计量）。$g(t)$ 的选择会影响备择假设，从而影响检验的功效，但不会影响单参数检验的零分布自由度。因此，声称零分布或其自由度取决于 $g(t)$ 是不正确的。结论：不正确。\n\n总之，陈述 A、C 和 D 是正确的；陈述 B 和 E 是不正确的。", "answer": "$$\\boxed{ACD}$$", "id": "4986323"}, {"introduction": "真实世界的数据常常带来挑战，例如协变量之间的多重共线性。本实践问题提出了一个常见的诊断难题：比例风险的全局检验显著，而所有单个协变量的检验却不显著。通过分析此场景 [@problem_id:4986311]，您将学习多重共线性如何掩盖单个效应，并培养解读看似矛盾结果的关键技能。", "problem": "一项以医院为基础的队列研究，对 $n$ 名实体器官恶性肿瘤患者从治疗开始至死亡的时间进行了考察。研究拟合了一个Cox比例风险模型，其基线风险为 $h_0(t)$，协变量向量为 $X \\in \\mathbb{R}^p$，因此风险函数为 $h(t \\mid X) = h_0(t)\\exp\\{X^\\top \\beta\\}$。三个临床协变量 $X_1$、$X_2$ 和 $X_3$ 衡量了肿瘤负荷的不同但相关的方面，并且它们之间存在强相关性，方差膨胀因子（VIF）接近 $12$。比例风险（PH）假设规定，每个对数风险比不随时间变化。\n\n为评估PH假设，研究团队计算了每个协变量的缩放Schoenfeld残差，并通过检验这些残差是否与时间的某个函数相关来测试其时间依赖性。对 $X_1$、$X_2$ 和 $X_3$ 的单独检验得出的 $p$ 值均超过 $0.20$，而其余每个协变量的 $p$ 值均超过 $0.10$。然而，汇总所有协变量证据的全局检验在统计上是显著的，其 $p = 0.008$。\n\n假设模型在其他方面是正确设定的，并且 $X_1$、$X_2$ 和 $X_3$ 之间的相关性是真实的（而非数据伪影），哪种解释和后续策略最为恰当？\n\nA. 全局检验能够检测到沿着相关协变量的线性组合所表达的时变效应，即使每个单变量检验的功效较低。应将此解释为在由 $X_1$、$X_2$ 和 $X_3$ 张成的子空间中存在联合非比例效应的证据，并应继续进行时变效应的联合建模，例如检验分组时间交互作用，通过对 $\\{X_1, X_2, X_3\\}$ 进行主成分分析（PCA）后重新参数化，然后检验时间与主成分的交互作用，或使用惩罚性时变系数。\n\nB. 因为没有单个协变量的检验是显著的，所以显著的全局检验很可能是假阳性；可以认为比例风险假设成立。\n\nC. 全局Schoenfeld残差检验在存在多重共线性的情况下是无效的；应转而依赖鞅残差来检验比例风险假设。\n\nD. 为解决这一差异，应任意移除 $X_1$、$X_2$ 或 $X_3$ 中的一个以降低相关性，直到至少有一个单独的Schoenfeld残差检验变得显著为止；否则，忽略全局检验。\n\nE. 将 $X_1$、$X_2$ 和 $X_3$ 标准化，使其均值为 $0$、方差为 $1$，将通过消除多重共线性来消除全局信号；因此，如果标准化后单个检验仍然不显著，则可以接受比例风险假设。", "solution": "用户要求对问题陈述进行严格验证，如果陈述有效，则提供详细的解决方案。\n\n### 步骤1：提取已知信息\n- 为一项包含 $n$ 名患者的队列研究的生存时间数据指定了Cox比例风险模型。\n- 风险函数为 $h(t \\mid X) = h_0(t)\\exp\\{X^\\top \\beta\\}$，其中 $X$ 是 $\\mathbb{R}^p$ 中的协变量向量。\n- 三个协变量 $X_1$、$X_2$ 和 $X_3$ 强相关，其方差膨胀因子（VIF）接近 $12$。这些协变量代表了肿瘤负荷的相关方面。\n- 正在使用缩放Schoenfeld残差检验比例风险（PH）假设。该假设意味着任何协变量的对数风险比都随时间恒定。\n- 对于协变量 $X_1$、$X_2$ 和 $X_3$，检验其缩放Schoenfeld残差与时间之间是否存在非零相关的单独检验得出的 $p$ 值均大于 $0.20$。\n- 对于模型中的所有其他协变量，单独检验得出的 $p$ 值均大于 $0.10$。\n- 一个汇总了所有协变量违反PH假设证据的全局检验得出了统计上显著的结果，其 $p = 0.008$。\n- 假设模型在其他方面是正确设定的，且 $X_1$、$X_2$ 和 $X_3$ 之间的相关性是数据的真实特征。\n\n### 步骤2：使用提取的已知信息进行验证\n将根据科学性、良构性和客观性标准对问题陈述进行验证。\n\n- **科学性：** 该问题设置在生存分析的背景下，这是统计学的一个主要分支，在医学领域有广泛应用。Cox比例风险模型是一种标准工具。使用Schoenfeld残差检验比例风险假设是经典方法，最早由 D. Schoenfeld 提出，后由 P. Grambsch 和 T. Therneau 扩展。多重共线性问题（由高VIF值指示）及其对统计推断的影响是回归建模中的一个基本概念。所描述的情景——在存在多重共线性的情况下，全局检验显著而单个检验不显著——是实践中遇到的典型情况。该问题在科学上和统计上都是合理的。\n\n- **良构性：** 该问题是良构的。它提出了一个具体且不平凡的统计难题：单个检验结果与全局检验结果之间存在明显差异。有足够的信息来推断最可能的根本原因，并确定正确的行动方案。问题要求给出最恰当的解释和策略，基于统计理论，对此存在一个明确的答案。\n\n- **客观性：** 语言精确，使用了统计学领域的标准、明确的术语（例如，VIF、Schoenfeld残差、p值、比例风险）。该问题以一组需要解释的经验性发现的形式呈现，没有主观或带偏见的措辞。\n\n### 步骤3：结论与行动\n问题陈述是**有效的**。它在科学上合理、良构、客观，并提出了应用统计建模中一个现实而重要的挑战。可以继续进行求解过程。\n\n### 推导与选项分析\n\n问题的核心在于理解Schoenfeld残差检验的性质（包括其单变量和多变量（全局）形式），以及多重共线性如何影响它。\n\n对于一个协变量 $X_j$，比例风险（PH）假设意味着其相关系数 $\\beta_j$ 不随时间 $t$ 变化。违反此假设意味着 $\\beta_j$ 是时间的函数，即 $\\beta_j(t)$。基于 $X_j$ 的缩放Schoenfeld残差的检验旨在检测残差与时间关系中的非零斜率。它实际上是对假设 $\\beta_j(t) = \\beta_j$（一个常数）的检验。\n\n多重共线性，如 $X_1$、$X_2$ 和 $X_3$ 接近 $12$ 的高VIF值所示，意味着这些变量高度相关。这有两个关键后果：\n1.  单个系数的估计值 $\\hat{\\beta}_1$、$\\hat{\\beta}_2$ 和 $\\hat{\\beta}_3$ 变得不稳定，并且具有较大的标准误。这使得难以厘清每个变量的独特效应。\n2.  这种不稳定性延伸到对PH假设的检验。任何单个协变量（$X_1$、$X_2$ 或 $X_3$）的检验统计量的方差都会被放大。这导致统计功效的损失，使得即使存在时变效应，也很难拒绝比例性原假设。这就解释了为何单个 $p$ 值不显著（$p > 0.20$）。\n\n全局检验是一个多变量检验，它同时考虑所有 $p$ 个协变量的缩放Schoenfeld残差向量。它有能力检测那些可能不与任何单一协变量轴对齐的对PH假设的偏离。当一部分协变量之间存在强相关性时，时变效应可能存在于这些协变量的某个特定线性组合中，例如 $\\gamma(t) = c_1 \\beta_1(t) + c_2 \\beta_2(t) + c_3 \\beta_3(t)$。全局检验可以检测到 $\\gamma(t)$ 不是常数，即使该效应在每个单独协变量轴（$X_1$、$X_2$ 或 $X_3$）上的投影太弱，以至于无法被相应的单变量检验检测到。显著的全局检验（$p = 0.008$）是模型中某处违反了PH假设的强有力证据。鉴于相关性结构集中在 $\\{X_1, X_2, X_3\\}$ 中，且所有其他单个检验均不显著，这种违反最有可能存在于这三个协变量所张成的子空间内。\n\n基于此推理，我们评估每个选项：\n\n**A. 全局检验能够检测到沿着相关协变量的线性组合所表达的时变效应，即使每个单变量检验的功效较低。应将此解释为在由 $X_1$、$X_2$ 和 $X_3$ 张成的子空间中存在联合非比例效应的证据，并应继续进行时变效应的联合建模，例如检验分组时间交互作用，通过对 $\\{X_1, X_2, X_3\\}$ 进行主成分分析（PCA）后重新参数化，然后检验时间与主成分的交互作用，或使用惩罚性时变系数。**\n此选项正确描述了这一统计现象。全局检验对协变量线性组合中的效应具有功效，这解释了结果的差异。将其解释为“联合非比例效应”是准确的。建议的后续策略都是解决这一特定问题的标准且恰当的方法。PCA创建正交分量，解决了共线性问题，并允许对这些分量进行时间交互作用的检验（例如，对捕获了共同“肿瘤负荷”构念的第一主成分）。联合建模时变系数，可能加上惩罚项，是另一种先进且有效的方法。该选项在统计上是合理的，并提供了一条建设性的前进道路。\n**结论：正确。**\n\n**B. 因为没有单个协变量的检验是显著的，所以显著的全局检验很可能是假阳性；可以认为比例风险假设成立。**\n这种解释是不正确的。在没有令人信服的理由的情况下，将一个 $p = 0.008$ 的高度显著的p值视为假阳性，是一种糟糕的统计实践。此外，对于观察到的结果有一个明确的理论解释（由于多重共线性导致单个检验功效丧失），这使得“假阳性”的解释极不可能成立。忽略全局检验将意味着使用一个设定错误的模型。\n**结论：不正确。**\n\n**C. 全局Schoenfeld残差检验在存在多重共线性的情况下是无效的；应转而依赖鞅残差来检验比例风险假设。**\n这种说法是错误的。全局Schoenfeld残差检验在存在多重共线性的情况下是有效的；其检测联合效应的能力是一个关键特征。鞅残差主要用于其他诊断目的，例如评估协变量的函数形式或识别影响点。虽然可以将它们与时间作图以寻找系统性趋势，但用于PH假设的正式假设检验是基于Schoenfeld残差的。\n**结论：不正确。**\n\n**D. 为解决这一差异，应任意移除 $X_1$、$X_2$ 或 $X_3$ 中的一个以降低相关性，直到至少有一个单独的Schoenfeld残差检验变得显著为止；否则，忽略全局检验。**\n这是一个无原则且由数据驱动的过程，相当于“p值操纵”（p-hacking）。任意移除协变量可能导致遗漏变量偏误和信息损失，因为题目说明了这些协变量衡量了肿瘤负荷的不同方面。试图通过尝试不同的模型设定来“找到”一个显著结果，不是一个有效的科学方法。最后，忽略来自全局检验的强有力证据是不合理的。\n**结论：不正确。**\n\n**E. 将 $X_1$、$X_2$ 和 $X_3$ 标准化，使其均值为 $0$、方差为 $1$，将通过消除多重共线性来消除全局信号；因此，如果标准化后单个检验仍然不显著，则可以接受比例风险假设。**\n这个选项的前提存在根本性缺陷。标准化是一种线性变换，它重新调整了变量的尺度，但并不改变它们的相互关系结构。皮尔逊相关系数以及因此产生的VIF对于这种缩放是不变的。因此，标准化不会消除或减少多重共线性。该选项的整个推理都基于一个错误的统计前提。\n**结论：不正确。**\n\n总之，选项A为所描述的情况提供了唯一正确的解释和恰当的策略组合。", "answer": "$$\\boxed{A}$$", "id": "4986311"}, {"introduction": "检验理解程度的最终方式是能够从零开始构建一个概念。这项综合性练习 [@problem_id:4986345] 要求您实现检验比例风险假设的完整工作流程。您将模拟生存时间数据，使用基本原理拟合Cox模型，计算Schoenfeld残差，并执行最终的假设检验，从而将每个理论部分连接成一个可运行的整体。", "problem": "要求您实现一个完整的模拟与分析流程，在Cox模型用于事件时间数据的背景下，使用Schoenfeld残差来检验比例风险(PH)假设。您的程序必须是一个单一的可运行脚本，完全从基本原理和核心定义出发，不使用任何外部生存分析库代码来执行以下端到端的任务。\n\n从以下基本定义开始。\n\n1. 对于协变量向量为 $x$ 的个体，在时间 $t$ 的风险函数为 $h(t \\mid x)$，累积风险为 $\\Lambda(t \\mid x) = \\int_{0}^{t} h(u \\mid x)\\,du$。生存函数为 $S(t \\mid x) = \\exp\\{-\\Lambda(t \\mid x)\\}$。\n2. 在Cox模型中，风险为 $h(t \\mid x) = h_0(t) \\exp\\{\\beta(t)^{\\top} x\\}$，其中 $h_0(t)$ 是基线风险，$\\beta(t)$ 可能依赖于 $t$。比例风险(PH)假设对应于 $\\beta(t) \\equiv \\beta$，即一个常数向量，因此风险比不随时间变化。\n3. 为使用逆变换采样模拟事件时间，从 $U \\sim \\text{Uniform}(0,1)$ 中抽取样本，并在定义关系 $\\Lambda(T \\mid x) = -\\log U$ 中求解 $T$，其中 $\\Lambda(t \\mid x) = \\int_{0}^{t} h_0(u) \\exp\\{\\beta(u)^{\\top} x\\} \\, du$。\n4. 给定观测到的随访时间 $Y = \\min(T, C)$ 和事件指示符 $\\delta = \\mathbf{1}\\{T \\le C\\}$，以及独立的右删失时间 $C$，对于单个协变量和常数系数 $\\beta$ 的Cox偏似然是基于风险集的。如果事件时间为 $t_1  \\dots  t_J$，在时间 $t_j$ 有 $d_j$ 个事件，风险集为 $R_j = \\{ i : Y_i \\ge t_j \\}$，那么对于单个协变量 $x$，\n   - 偏对数似然为 $\\ell(\\beta) = \\sum_{j=1}^{J} \\left( \\sum_{i \\in D_j} \\beta x_i - d_j \\log \\sum_{i \\in R_j} e^{\\beta x_i} \\right)$，其中 $D_j$ 表示在 $t_j$ 时刻发生事件的个体。\n   - 得分函数为 $U(\\beta) = \\sum_{j=1}^{J} \\left( \\sum_{i \\in D_j} x_i - d_j \\frac{\\sum_{i \\in R_j} x_i e^{\\beta x_i}}{\\sum_{i \\in R_j} e^{\\beta x_i}} \\right)$。\n   - 观测信息为 $I(\\beta) = \\sum_{j=1}^{J} d_j \\left( \\frac{\\sum_{i \\in R_j} x_i^2 e^{\\beta x_i}}{\\sum_{i \\in R_j} e^{\\beta x_i}} - \\left(\\frac{\\sum_{i \\in R_j} x_i e^{\\beta x_i}}{\\sum_{i \\in R_j} e^{\\beta x_i}} \\right)^2 \\right)$。\n   Breslow近似法是在同一事件时间存在结(ties)时使用这些公式。\n5. 对于在时间 $t_j$ 发生事件的个体 $i$，其（未缩放的）Schoenfeld残差为 $r_i = x_i - \\mathbb{E}_{\\hat{\\beta}}[x \\mid R_j]$，其中期望是相对于风险集 $R_j$ 上与 $e^{\\hat{\\beta} x}$ 成正比的权重计算的。\n6. 检验PH假设（对于单个协变量）可以基于检查 $r_i$ 是否与 $t_j$ 独立。一种方法是对 $r_i$ 关于函数 $g(t_j)$ 进行普通最小二乘(OLS)回归，并检验斜率是否为零，例如使用双边t检验。在PH假设下，回归斜率预期接近于零。\n\n您的任务是：\n\n- 对于每个给定的测试用例，完成以下所有操作：\n  1. 模拟 $N$ 个独立个体。为每个个体生成一个二元协变量 $X \\in \\{0,1\\}$，其中 $P(X=1) = 0.5$。\n  2. 使用逆变换采样以及给定的 $h_0(t)$ 和 $\\beta(t)$ 模拟事件时间 $T$。然后模拟一个独立的右删失时间 $C$，并构成 $Y = \\min(T, C)$ 和 $\\delta = \\mathbf{1}\\{T \\le C\\}$。\n  3. 通过牛顿-拉弗森法最大化偏对数似然，并使用Breslow近似法处理结，来拟合一个具有单个常数系数 $\\beta$ 的Cox模型。不要使用任何生存分析包；在每次牛顿-拉弗森迭代中，直接根据定义计算得分和观测信息，直到收敛。\n  4. 使用拟合的 $\\hat{\\beta}$ 计算事件时间点的Schoenfeld残差。\n  5. 使用带截距的普通最小二乘(OLS)法，将Schoenfeld残差对观测到的事件时间进行回归，其中单变量回归量为 $g(t) = t$。对斜率使用显著性水平 $\\alpha = 0.05$ 的双边t检验，并为每个测试用例确定一个布尔决策：如果PH假设被拒绝，则返回 $\\text{True}$，否则返回 $\\text{False}$。\n\n为以下三个测试用例（即测试套件）实现上述步骤：\n\n- 案例 A（PH假设成立，常数基线风险，零斜率的线性系数）：\n  - 基线风险 $h_0(t) = \\lambda$，其中 $\\lambda = 0.1$。\n  - 时变系数 $\\beta(t) = \\beta_0 + \\beta_1 t$，其中 $\\beta_0 = 0.8$ 且 $\\beta_1 = 0$。\n  - 个体数量 $N = 600$。\n  - 删失分布 $C \\sim \\text{Uniform}(0, 15)$。\n  - 随机种子 $s = 13579$。\n\n- 案例 B（PH假设不成立，常数基线风险，正斜率的线性系数）：\n  - 基线风险 $h_0(t) = \\lambda$，其中 $\\lambda = 0.1$。\n  - 时变系数 $\\beta(t) = \\beta_0 + \\beta_1 t$，其中 $\\beta_0 = 0.2$ 且 $\\beta_1 = 0.3$。\n  - 个体数量 $N = 600$。\n  - 删失分布 $C \\sim \\text{Uniform}(0, 8)$。\n  - 随机种子 $s = 24680$。\n\n- 案例 C（PH假设成立，韦伯(Weibull)基线风险，常数系数）：\n  - 基线风险 $h_0(t) = \\lambda k t^{k-1}$，其中 $\\lambda = 0.01$ 且 $k = 2$。\n  - 时变系数 $\\beta(t) = \\beta_0$，其中 $\\beta_0 = 0.7$。\n  - 个体数量 $N = 300$。\n  - 删失分布 $C \\sim \\text{Uniform}(0, 10)$。\n  - 随机种子 $s = 11223$。\n\n重要的实现要求：\n\n- 您必须根据每个案例给定的 $h_0(t)$ 和 $\\beta(t)$，从定义 $\\Lambda(T \\mid x) = -\\log U$ 出发，通过逆变换方法推导出 $T$ 的模拟方法。在解析解可用的情况下，您可以使用解析求逆。\n- 在Cox拟合步骤中，为单个协变量情况明确实现牛顿-拉弗森算法，使用风险集和Breslow近似法计算得分和观测信息。\n- 使用拟合的 $\\hat{\\beta}$ 和事件发生前的风险集，计算每个事件时间点的Schoenfeld残差。\n- 对于残差对事件时间的OLS回归，应包含一个截距，并对斜率使用显著性水平为 $\\alpha = 0.05$ 的双边t检验。将每个案例的最终决策表示为布尔值。\n\n最终输出规范：\n\n- 您的程序应生成单行输出，其中包含一个由方括号括起来的、包含三个布尔值的逗号分隔列表，按A、B、C案例的顺序排列（例如，\"[False,True,False]\"）。\n- 不允许有其他输出。此问题不要求任何物理单位。", "solution": "该问题要求实现一个综合的统计流程，用于模拟事件时间数据、拟合Cox比例风险模型，并使用Schoenfeld残差检验其底层的比例风险(PH)假设。此过程将针对三个不同的测试用例执行，整个流程将从基本原理出发构建，不依赖于高级生存分析库。\n\n**1. 通过逆变换采样进行数据模拟**\n\n模拟的基础是应用于生存函数 $S(t \\mid x)$ 的逆变换采样方法。生存函数定义为 $S(t \\mid x) = \\exp\\{-\\Lambda(t \\mid x)\\}$，其中 $\\Lambda(t \\mid x)$ 是累积风险函数。为生成事件时间 $T$，我们从标准均匀分布 $U \\sim \\text{Uniform}(0,1)$ 中抽取一个随机变量 $U$，并解方程 $S(T \\mid x) = U$。这等价于解 $\\Lambda(T \\mid x) = -\\log(U)$。令 $E = -\\log(U)$，它服从速率为1的指数分布。任务是通过对每个测试用例的累积风险函数求逆来找到事件时间 $T$。$N$ 个个体中每个个体的协变量 $X$ 是从伯努利分布中抽取的二元变量，其中 $P(X=1) = 0.5$。\n\n*   **案例 A (PH假设成立):**\n    基线风险是常数，$h_0(t) = \\lambda = 0.1$。系数也是常数，$\\beta(t) = \\beta_0 = 0.8$。该模型满足PH假设。个体的风险为 $h(t \\mid x) = \\lambda \\exp(\\beta_0 x)$。累积风险为 $\\Lambda(t \\mid x) = \\int_0^t \\lambda \\exp(\\beta_0 x) \\,du = \\lambda t \\exp(\\beta_0 x)$。将其设为等于 $E$ 并求解 $T$ 可得：\n    $$T = \\frac{E}{\\lambda \\exp(\\beta_0 x)}$$\n\n*   **案例 B (PH假设不成立):**\n    基线风险是常数，$h_0(t) = \\lambda = 0.1$，但系数是时变的：$\\beta(t) = \\beta_0 + \\beta_1 t$，其中 $\\beta_0 = 0.2$ 且 $\\beta_1 = 0.3$。这违反了PH假设。累积风险是 $\\Lambda(t \\mid x) = \\int_0^t h_0(u) \\exp(\\beta(u)x) \\,du$。\n    对于 $x=0$ 的个体，$\\beta(t)x = 0$，所以 $\\Lambda(t|0) = \\int_0^t \\lambda \\,du = \\lambda t$。事件时间是 $T = E/\\lambda$。\n    对于 $x=1$ 的个体，$\\Lambda(t \\mid 1) = \\int_0^t \\lambda \\exp(\\beta_0 + \\beta_1 u) \\,du = \\lambda e^{\\beta_0} \\int_0^t e^{\\beta_1 u} \\,du = \\frac{\\lambda e^{\\beta_0}}{\\beta_1} (e^{\\beta_1 t} - 1)$。将其设为 $E$ 并求解 $T$ 可得：\n    $$T = \\frac{1}{\\beta_1} \\log\\left(1 + E \\frac{\\beta_1}{\\lambda e^{\\beta_0}}\\right)$$\n\n*   **案例 C (PH假设成立):**\n    基线风险服从韦伯(Weibull)分布，$h_0(t) = \\lambda k t^{k-1}$，其中 $\\lambda=0.01$ 且 $k=2$。系数是常数，$\\beta(t) = \\beta_0 = 0.7$，因此PH假设成立。累积基线风险是 $H_0(t) = \\int_0^t \\lambda k u^{k-1} \\,du = \\lambda t^k$。特定个体的累积风险是 $\\Lambda(t \\mid x) = H_0(t) \\exp(\\beta_0 x) = \\lambda t^k \\exp(\\beta_0 x)$。将其设为 $E$ 并求解 $T$ 可得：\n    $$T = \\left(\\frac{E}{\\lambda \\exp(\\beta_0 x)}\\right)^{1/k}$$\n\n模拟出事件时间 $T$ 后，从指定的均匀分布中抽取独立的右删失时间 $C$。观测到的随访时间为 $Y = \\min(T, C)$，事件指示符为 $\\delta = \\mathbf{1}\\{T \\le C\\}$。\n\n**2. 通过牛顿-拉弗森法拟合Cox模型**\n\nCox模型假设系数 $\\beta$ 为常数，从而得到偏对数似然函数 $\\ell(\\beta)$。我们通过运行牛顿-拉弗森算法来找到最大似然估计 $\\hat{\\beta}$，该算法使用得分函数 $U(\\beta) = \\frac{d\\ell}{d\\beta}$ 和观测信息 $I(\\beta) = -\\frac{d^2\\ell}{d\\beta^2}$ 来迭代更新估计值。单个参数的更新规则是：\n$$\\beta_{k+1} = \\beta_k + \\frac{U(\\beta_k)}{I(\\beta_k)}$$\n算法从一个初始猜测（例如 $\\beta_0=0$）开始，并迭代直到收敛。得分 $U(\\beta)$ 和信息 $I(\\beta)$ 是通过对每个唯一事件时间 $t_j$ 的贡献求和来计算的。设 $D_j$ 为在时间 $t_j$ 发生事件的个体集合，$d_j = |D_j|$，$R_j$ 为风险集（$Y_i \\ge t_j$ 的个体），则各分量为：\n$$U(\\beta) = \\sum_{j=1}^{J} \\left( \\sum_{i \\in D_j} x_i - d_j \\frac{\\sum_{k \\in R_j} x_k e^{\\beta x_k}}{\\sum_{k \\in R_j} e^{\\beta x_k}} \\right)$$\n$$I(\\beta) = \\sum_{j=1}^{J} d_j \\left( \\frac{\\sum_{k \\in R_j} x_k^2 e^{\\beta x_k}}{\\sum_{k \\in R_j} e^{\\beta x_k}} - \\left(\\frac{\\sum_{k \\in R_j} x_k e^{\\beta x_k}}{\\sum_{k \\in R_j} e^{\\beta x_k}} \\right)^2 \\right)$$\n这些公式使用Breslow近似法来处理事件时间中的结。为实现这一点，我们遍历唯一的事件时间，形成相应的风险集，并计算所需的总和，以在牛顿-拉弗森算法的每次迭代中更新得分和信息的总计。\n\n**3. Schoenfeld残差计算**\n\n拟合模型得到 $\\hat{\\beta}$ 后，我们评估PH假设。对于在时间 $t_j$ 经历事件的个体 $i$，其未缩放的Schoenfeld残差是其观测到的协变量值与该时刻风险集 $R_j$ 上的协变量期望值之差：\n$$r_i = x_i - \\mathbb{E}_{\\hat{\\beta}}[X \\mid R_j] = x_i - \\frac{\\sum_{k \\in R_j} x_k e^{\\hat{\\beta} x_k}}{\\sum_{k \\in R_j} e^{\\hat{\\beta} x_k}}$$\n如果PH假设成立，这些残差在对时间作图时不应显示出系统性趋势。如果假设被违反（例如，$x$ 的效应随时间变化），残差可能与时间相关。\n\n**4. 比例风险的假设检验**\n\n为了正式检验时间趋势，我们对Schoenfeld残差 $r$ 与对应的事件时间 $t$ 进行普通最小二乘(OLS)回归。模型为 $r = b_0 + b_1 t + \\epsilon$。我们检验原假设 $H_0: b_1 = 0$ 对备择假设 $H_a: b_1 \\neq 0$。斜率的OLS估计为 $\\hat{b}_1 = \\frac{\\sum (t_i - \\bar{t})(r_i - \\bar{r})}{\\sum (t_i - \\bar{t})^2}$。检验统计量是一个t统计量：\n$$t_{\\text{stat}} = \\frac{\\hat{b}_1}{\\text{SE}(\\hat{b}_1)}$$\n其中 $\\text{SE}(\\hat{b}_1)$ 是斜率估计的标准误。标准误计算为 $\\text{SE}(\\hat{b}_1) = \\sqrt{\\frac{s^2}{\\sum (t_i - \\bar{t})^2}}$，其中 $s^2 = \\frac{\\sum(r_i - \\hat{r}_i)^2}{n-2}$ 是误差方差 $\\sigma^2$ 的无偏估计，$n$ 是事件数。在原假设下，$t_{\\text{stat}}$ 服从自由度为 $n-2$ 的学生t分布。我们计算双边p值，如果p值小于显著性水平 $\\alpha = 0.05$，则拒绝 $H_0$。拒绝表明有证据反对PH假设。每个案例的最终输出是一个布尔值，指示PH假设是否被拒绝。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import t as t_dist\n\ndef fit_cox_model(Y, delta, X, tol=1e-6, max_iter=25):\n    \"\"\"\n    Fits a single-covariate Cox model using Newton-Raphson.\n    \"\"\"\n    # Sort data by time to process events chronologically.\n    sort_idx = np.argsort(Y)\n    Y, delta, X = Y[sort_idx], delta[sort_idx], X[sort_idx]\n\n    # Get unique event times\n    unique_event_times = np.unique(Y[delta == 1])\n    if len(unique_event_times) == 0:\n        return 0.0\n\n    beta = 0.0\n    for _ in range(max_iter):\n        score = 0.0\n        info = 0.0\n        \n        # Pre-compute for current beta\n        exp_beta_X = np.exp(beta * X)\n\n        # Iterate through unique event times to calculate score and info\n        for t_j in unique_event_times:\n            risk_set_mask = (Y >= t_j)\n            event_mask = (Y == t_j)  (delta == 1)\n\n            d_j = np.sum(delta[event_mask])\n            if d_j == 0:\n                continue\n\n            sum_X_deaths = np.sum(X[event_mask])\n\n            X_risk = X[risk_set_mask]\n            exp_beta_X_risk = exp_beta_X[risk_set_mask]\n\n            S0 = np.sum(exp_beta_X_risk)\n            S1 = np.sum(X_risk * exp_beta_X_risk)\n            S2 = np.sum(X_risk**2 * exp_beta_X_risk)\n\n            if S0 > 0:\n                E1 = S1 / S0\n                E2 = S2 / S0\n                \n                score += sum_X_deaths - d_j * E1\n                info += d_j * (E2 - E1**2)\n\n        if info = 0:\n            break\n\n        update = score / info\n        beta += update\n\n        if abs(update)  tol:\n            break\n            \n    return beta\n\ndef calculate_schoenfeld(Y, delta, X, beta_hat):\n    \"\"\"\n    Calculates unscaled Schoenfeld residuals.\n    \"\"\"\n    # Sort data by time\n    sort_idx = np.argsort(Y)\n    Y, delta, X = Y[sort_idx], delta[sort_idx], X[sort_idx]\n    \n    unique_event_times = np.unique(Y[delta == 1])\n    \n    residuals = []\n    event_times_for_residuals = []\n    \n    exp_beta_X = np.exp(beta_hat * X)\n    \n    for t_j in unique_event_times:\n        risk_set_mask = (Y >= t_j)\n        event_mask = (Y == t_j)  (delta == 1)\n        \n        X_risk = X[risk_set_mask]\n        exp_beta_X_risk = exp_beta_X[risk_set_mask]\n        \n        S0 = np.sum(exp_beta_X_risk)\n        S1 = np.sum(X_risk * exp_beta_X_risk)\n        \n        E_x = S1 / S0 if S0 > 0 else 0.0\n            \n        X_events = X[event_mask]\n        \n        for x_i in X_events:\n            residuals.append(x_i - E_x)\n            event_times_for_residuals.append(t_j)\n            \n    return np.array(residuals), np.array(event_times_for_residuals)\n\ndef test_ph(residuals, event_times, alpha=0.05):\n    \"\"\"\n    Performs OLS regression of residuals on time and a t-test on the slope.\n    \"\"\"\n    y = residuals\n    x = event_times\n    n = len(x)\n\n    if n  3: # Need at least 3 points for OLS with intercept and slope\n        return False\n\n    sum_x = np.sum(x)\n    sum_y = np.sum(y)\n    sum_xx = np.sum(x**2)\n    sum_xy = np.sum(x * y)\n\n    b1_denom = n * sum_xx - sum_x**2\n    if np.isclose(b1_denom, 0):\n        return False # All event times are the same\n\n    b1 = (n * sum_xy - sum_x * sum_y) / b1_denom\n    b0 = (sum_y / n) - b1 * (sum_x / n)\n\n    y_hat = b0 + b1 * x\n    SSE = np.sum((y - y_hat)**2)\n    \n    df = n - 2\n    if df = 0:\n        return False\n\n    s_sq = SSE / df\n\n    Sxx = sum_xx - (sum_x**2 / n)\n    if np.isclose(Sxx, 0):\n        return False\n\n    SE_b1 = np.sqrt(s_sq / Sxx)\n\n    if np.isclose(SE_b1, 0):\n        return np.abs(b1) > 1e-9 # Effectively infinite t-stat, reject\n\n    t_stat = b1 / SE_b1\n    p_value = 2 * t_dist.sf(np.abs(t_stat), df=df)\n\n    return p_value  alpha\n\ndef run_case(params):\n    \"\"\"\n    Runs one full simulation-and-analysis case.\n    \"\"\"\n    np.random.seed(params['seed'])\n    \n    N = params['N']\n    X = np.random.binomial(1, 0.5, size=N)\n    U = np.random.uniform(size=N)\n    E = -np.log(U) # Inverse transform via Exponential(1) variates\n    \n    T = np.zeros(N)\n    \n    if params['h0_type'] == 'const':\n        lam, beta0, beta1 = params['lambda'], params['beta0'], params['beta1']\n        if np.isclose(beta1, 0): # Case A (PH model)\n            hazard_multiplier = lam * np.exp(beta0 * X)\n            T = E / hazard_multiplier\n        else: # Case B (non-PH model)\n            idx_x0 = (X == 0)\n            T[idx_x0] = E[idx_x0] / lam\n            \n            idx_x1 = (X == 1)\n            term = E[idx_x1] * beta1 / (lam * np.exp(beta0))\n            T[idx_x1] = (1 / beta1) * np.log(1 + term)\n\n    elif params['h0_type'] == 'weibull': # Case C (PH model)\n        lam, k, beta0 = params['lambda'], params['k'], params['beta0']\n        base = E / (lam * np.exp(beta0 * X))\n        T = np.power(base, 1.0 / k)\n\n    c_low, c_high = params['c_dist']\n    C = np.random.uniform(c_low, c_high, size=N)\n    \n    Y = np.minimum(T, C)\n    delta = (T = C).astype(int)\n\n    beta_hat = fit_cox_model(Y, delta, X)\n    residuals, event_times = calculate_schoenfeld(Y, delta, X, beta_hat)\n    \n    is_rejected = test_ph(residuals, event_times, alpha=0.05)\n    \n    return is_rejected\n\ndef solve():\n    test_cases = [\n        # Case A: PH holds\n        {'h0_type': 'const', 'lambda': 0.1, 'k': None, 'beta0': 0.8, 'beta1': 0.0,\n         'N': 600, 'c_dist': (0, 15), 'seed': 13579},\n        # Case B: PH violated\n        {'h0_type': 'const', 'lambda': 0.1, 'k': None, 'beta0': 0.2, 'beta1': 0.3,\n         'N': 600, 'c_dist': (0, 8), 'seed': 24680},\n        # Case C: PH holds\n        {'h0_type': 'weibull', 'lambda': 0.01, 'k': 2.0, 'beta0': 0.7, 'beta1': 0.0,\n         'N': 300, 'c_dist': (0, 10), 'seed': 11223},\n    ]\n\n    results = []\n    for case_params in test_cases:\n        decision = run_case(case_params)\n        results.append(decision)\n\n    print(f\"[{','.join(map(str, results)).replace('True', 'True').replace('False', 'False')}]\")\n\nsolve()\n\n```", "id": "4986345"}]}