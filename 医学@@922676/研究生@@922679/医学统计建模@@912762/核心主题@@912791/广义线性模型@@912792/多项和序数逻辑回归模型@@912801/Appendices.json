{"hands_on_practices": [{"introduction": "一旦拟合了比例优势模型，其主要用途就是为新个体进行预测。本练习提供了一个动手实践的机会，将累积 logit 公式应用于特定患者的协变量，计算不同严重性等级的概率分布。掌握这一计算过程对于将模型参数转化为具有临床意义的风险评估至关重要。[@problem_id:4976153]", "problem": "一家医院采用了一个四级有序严重性量表来评估急性感染，编码为 $Y \\in \\{1,2,3,4\\}$，其中 $1=$ 无， $2=$ 轻度， $3=$ 中度， $4=$ 重度。一个比例优势（累积 logit）模型已拟合到一个队列研究中，使用了入院时测量的协变量：年龄（岁）、性别（男性指示变量）、血清 C 反应蛋白（单位 $\\mathrm{mg/L}$）和 Charlson 合并症指数。拟合后的模型使用了截点（也称为阈值）$\\alpha_1$、$\\alpha_2$、$\\alpha_3$ 和一个共同的斜率向量 $\\boldsymbol{\\beta}$，报告如下，其中协变量的标度是为了方便解释而指定的：\n\n- 截点：$\\alpha_1 = -1.5$，$\\alpha_2 = 0.0$，$\\alpha_3 = 1.5$。\n- 斜率：年龄每 $10$ 岁：$\\beta_{\\text{age}} = 0.25$；男性指示变量：$\\beta_{\\text{male}} = 0.40$；C 反应蛋白每 $50$ $\\mathrm{mg/L}$：$\\beta_{\\text{CRP}} = 0.60$；Charlson 合并症指数每点：$\\beta_{\\text{CCI}} = 0.15$。\n\n考虑一位具有以下协变量的患者：年龄 $45$ 岁，女性（男性指示变量为 $0$），C 反应蛋白 $20$ $\\mathrm{mg/L}$，Charlson 合并症指数 $0$。\n\n使用 logit 变换和 logistic 函数的定义，计算该患者在比例优势模型下的预测类别概率 $P(Y=1 \\mid \\mathbf{x})$、$P(Y=2 \\mid \\mathbf{x})$、$P(Y=3 \\mid \\mathbf{x})$ 和 $P(Y=4 \\mid \\mathbf{x})$，并从临床合理性的角度解释其在不同严重性等级上的分布。然后，计算该患者的预期严重性指数 $\\mathbb{E}[Y \\mid \\mathbf{x}]$。\n\n仅提供预期严重性指数作为最终答案，四舍五入到四位有效数字。不需要单位。", "solution": "对于一个具有 $K$ 个类别（这里 $K=4$）的有序结果 $Y$，比例优势（累积 logit）模型对累积概率 $P(Y \\le j \\mid \\mathbf{x})$ 进行建模，其中 $j=1, \\dots, K-1$。该模型定义为：\n$$\n\\text{logit}(P(Y \\le j \\mid \\mathbf{x})) = \\ln\\left(\\frac{P(Y \\le j \\mid \\mathbf{x})}{1 - P(Y \\le j \\mid \\mathbf{x})}\\right) = \\alpha_j - \\boldsymbol{\\beta}^\\top\\mathbf{x}\n$$\n这里，$\\alpha_j$ 是每个累积概率的截点（截距），$\\boldsymbol{\\beta}$ 是回归系数的向量，$\\mathbf{x}$ 是协变量的向量。风险因素（年龄、CRP、CCI）的正系数意味着这些协变量的增加会导致累积 logit 的减小，这意味着 $P(Y \\le j \\mid \\mathbf{x})$ 的减小，从而将概率质量推向更高的 $Y$ 值（更严重的级别）。这种表述是标准且恰当的。\n\n首先，我们为指定患者计算线性预测器 $\\eta = \\boldsymbol{\\beta}^\\top\\mathbf{x}$。协变量必须根据模型的规定进行缩放。该患者为 $45$ 岁的女性，C 反应蛋白（CRP）为 $20$ $\\mathrm{mg/L}$，Charlson 合并症指数（CCI）为 $0$。\n协变量向量 $\\mathbf{x}$ 构建如下：\n- 年龄：$x_{\\text{age}} = \\frac{45}{10} = 4.5$\n- 性别（男性指示变量）：$x_{\\text{male}} = 0$\n- C 反应蛋白：$x_{\\text{CRP}} = \\frac{20}{50} = 0.4$\n- Charlson 合并症指数：$x_{\\text{CCI}} = 0$\n\n线性预测器为：\n$$\n\\eta = \\boldsymbol{\\beta}^\\top\\mathbf{x} = \\beta_{\\text{age}}x_{\\text{age}} + \\beta_{\\text{male}}x_{\\text{male}} + \\beta_{\\text{CRP}}x_{\\text{CRP}} + \\beta_{\\text{CCI}}x_{\\text{CCI}}\n$$\n$$\n\\eta = (0.25)(4.5) + (0.40)(0) + (0.60)(0.4) + (0.15)(0)\n$$\n$$\n\\eta = 1.125 + 0 + 0.24 + 0 = 1.365\n$$\n\n接下来，我们通过应用逆 logit（logistic）函数来计算累积概率 $P(Y \\le j \\mid \\mathbf{x})$，该函数为 $f(z) = \\frac{1}{1 + \\exp(-z)}$。\n对于 $j=1$：\n$$\nP(Y \\le 1 \\mid \\mathbf{x}) = \\frac{1}{1 + \\exp(-(\\alpha_1 - \\eta))} = \\frac{1}{1 + \\exp(-(-1.5 - 1.365))} = \\frac{1}{1 + \\exp(2.865)}\n$$\n对于 $j=2$：\n$$\nP(Y \\le 2 \\mid \\mathbf{x}) = \\frac{1}{1 + \\exp(-(\\alpha_2 - \\eta))} = \\frac{1}{1 + \\exp(-(0.0 - 1.365))} = \\frac{1}{1 + \\exp(1.365)}\n$$\n对于 $j=3$：\n$$\nP(Y \\le 3 \\mid \\mathbf{x}) = \\frac{1}{1 + \\exp(-(\\alpha_3 - \\eta))} = \\frac{1}{1 + \\exp(-(1.5 - 1.365))} = \\frac{1}{1 + \\exp(-0.135)}\n$$\n此外，根据定义，$P(Y \\le 4 \\mid \\mathbf{x}) = 1$。\n\n现在，我们计算各个类别的概率 $P(Y=j \\mid \\mathbf{x})$：\n$P(Y=1 \\mid \\mathbf{x}) = P(Y \\le 1 \\mid \\mathbf{x}) \\approx 0.053914$\n$P(Y=2 \\mid \\mathbf{x}) = P(Y \\le 2 \\mid \\mathbf{x}) - P(Y \\le 1 \\mid \\mathbf{x}) \\approx 0.203430 - 0.053914 = 0.149516$\n$P(Y=3 \\mid \\mathbf{x}) = P(Y \\le 3 \\mid \\mathbf{x}) - P(Y \\le 2 \\mid \\mathbf{x}) \\approx 0.533700 - 0.203430 = 0.330270$\n$P(Y=4 \\mid \\mathbf{x}) = 1 - P(Y \\le 3 \\mid \\mathbf{x}) \\approx 1 - 0.533700 = 0.466300$\n\n该患者在不同严重性等级上的预测概率分布约为：$P(Y=1, \\text{无}) \\approx 5.4\\%$，$P(Y=2, \\text{轻度}) \\approx 15.0\\%$，$P(Y=3, \\text{中度}) \\approx 33.0\\%$，以及 $P(Y=4, \\text{重度}) \\approx 46.6\\%$。模型预测最可能的结果是‘重度’，这具有临床合理性。虽然该患者是女性且没有合并症（较低的风险因素），但她的年龄（$45$ 岁）和升高的 CRP 水平（$20$ $\\mathrm{mg/L}$）导致了正的线性预测器（$\\eta=1.365$），表明其风险状况远高于基线个体。这解释了概率质量向更高严重性类别转移的合理性。\n\n最后，我们计算预期严重性指数 $\\mathbb{E}[Y \\mid \\mathbf{x}]$。这是类别值的加权平均值，其中权重是类别概率：\n$$\n\\mathbb{E}[Y \\mid \\mathbf{x}] = \\sum_{j=1}^{4} j \\cdot P(Y=j \\mid \\mathbf{x})\n$$\n一个更直接的计算方法是使用累积概率：\n$$\n\\mathbb{E}[Y \\mid \\mathbf{x}] = \\sum_{j=1}^{K} P(Y \\ge j \\mid \\mathbf{x}) = 1 + \\sum_{j=1}^{K-1} P(Y  j \\mid \\mathbf{x}) = 1 + \\sum_{j=1}^{K-1} (1 - P(Y \\le j \\mid \\mathbf{x})) = K - \\sum_{j=1}^{K-1} P(Y \\le j \\mid \\mathbf{x})\n$$\n当 $K=4$ 时，我们有：\n$$\n\\mathbb{E}[Y \\mid \\mathbf{x}] = 4 - [P(Y \\le 1 \\mid \\mathbf{x}) + P(Y \\le 2 \\mid \\mathbf{x}) + P(Y \\le 3 \\mid \\mathbf{x})]\n$$\n让我们代入累积概率的数值：\n$P(Y \\le 1 \\mid \\mathbf{x}) \\approx 0.05391418$\n$P(Y \\le 2 \\mid \\mathbf{x}) \\approx 0.20343015$\n$P(Y \\le 3 \\mid \\mathbf{x}) \\approx 0.53369986$\n$$\n\\mathbb{E}[Y \\mid \\mathbf{x}] \\approx 4 - (0.05391418 + 0.20343015 + 0.53369986)\n$$\n$$\n\\mathbb{E}[Y \\mid \\mathbf{x}] \\approx 4 - 0.79104419 = 3.20895581\n$$\n题目要求答案四舍五入到四位有效数字。\n$$\n\\mathbb{E}[Y \\mid \\mathbf{x}] \\approx 3.209\n$$", "answer": "$$\n\\boxed{3.209}\n$$", "id": "4976153"}, {"introduction": "统计建模中的一个核心问题是预测变量是否对结果有显著影响。本实践将演示如何使用强大的似然比检验来回答多项逻辑回归模型中的这个问题。您将实现从数据模拟、通过最大似然估计进行模型拟合到执行统计检验的完整工作流程，从而深入理解在此背景下的假设检验。[@problem_id:4976107]", "problem": "考虑一个医学队列研究，其中分类结果代表具有$K$个互斥类别的疾病状态，并为每位患者测量一个连续的生物标志物。假设采用以下基线类别多项逻辑回归表示：对于相对于选定基线类别$0$的类别$k \\in \\{1,\\dots,K-1\\}$，类别$k$的线性预测器为$\\eta_k = \\alpha_k + \\beta_k x$，其中$x$是患者的生物标志物值，类别概率由逻辑联系函数定义。数据集由独立观测值$\\{(x_i, y_i)\\}_{i=1}^N$组成，其中$y_i \\in \\{0,1,\\dots,K-1\\}$，生物标志物值为$x_i \\in \\mathbb{R}$。建模目标是评估生物标志物是否对分配到任何非基线类别的几率有任何影响，即在原假设$H_0: \\beta_k = 0$（对所有$k \\in \\{1,\\dots,K-1\\}$）下，所有斜率参数是否均为零，相对于备择假设$H_1: \\exists k$ 使得 $\\beta_k \\ne 0$。\n\n仅从以下基础出发：\n- 独立分类结果的定义，其对每个观测值$i$的概率为$(p_{0i}, p_{1i}, \\dots, p_{(K-1)i})$，且$p_{0i} + \\sum_{k=1}^{K-1} p_{ki} = 1$。\n- 最大似然估计原理，即参数估计值使指定模型所蕴含的联合似然最大化（等价于使负对数似然最小化）。\n- 基线类别多项逻辑联系函数，它通过逻辑变换将线性预测器映射到概率，确保各类别概率有效且总和为一。\n- 广义似然比检验原理，该原理使用嵌套模型的最大化似然值进行比较，并通过由模型间维度差异决定的适当大样本分布来评估统计显著性。\n\n您的任务是实现一个程序，该程序：\n1. 使用指定的参数集和随机种子，在科学上合理的医学情景下构建合成数据集。\n2. 通过最大化相应的似然来拟合两个模型：允许$\\beta_k$在$k \\in \\{1,\\dots,K-1\\}$上自由变化的无约束模型，以及在$H_0$下$\\beta_k = 0$（对所有$k \\in \\{1,\\dots,K-1\\}$）的有约束模型（仅含截距）。\n3. 对每个数据集执行$H_0$对$H_1$的似然比检验，报告检验统计量、定义为无约束模型和有约束模型之间自由参数数量差异的自由度，以及使用适当的参考分布计算的相应大样本$p$值。$p$值必须以小数形式报告，而不是百分比。\n\n数据生成和测试套件：\n- 对于每个测试用例，生物标志物值$x_i$独立地从一个由均值和标准差指定的正态分布中抽取，然后根据具有给定真实参数的多项逻辑模型独立生成结果$y_i$。使用基线类别参数化，其中基线类别索引为$0$。\n- 使用以下测试套件，其中每个元组指定$(N, K, \\boldsymbol{\\alpha}, \\boldsymbol{\\beta}, \\mu_x, \\sigma_x, \\text{seed})$，且$\\boldsymbol{\\alpha} = (\\alpha_1,\\dots,\\alpha_{K-1})$和$\\boldsymbol{\\beta} = (\\beta_1,\\dots,\\beta_{K-1})$：\n    1. $(800, 4, (-1.2, 0.5, -0.3), (0.8, -0.5, 0.4), 2.0, 1.0, 42)$，代表一个四类别疾病状态，其中生物标志物在不同类别间显示出异质性效应。\n    2. $(600, 3, (-0.2, -1.0), (0.0, 0.0), 1.0, 0.8, 123)$，代表一个零效应情景，其中生物标志物对类别几率没有影响。\n    3. $(50, 3, (-1.5, -1.0), (1.5, 1.2), 0.0, 1.2, 999)$，代表一个具有显著生物标志物效应的小样本边界情况。\n    4. $(1200, 5, (-2.0, -1.0, -1.5, -3.0), (0.7, 0.3, -0.4, 0.9), 1.5, 0.7, 2023)$，代表一个五类别结果，包括一个罕见类别情景，生物标志物效应各不相同。\n\n算法和数值要求：\n- 使用基线类别多项逻辑联系函数下对数似然的数值稳定计算，为无约束模型和有约束模型实现最大似然估计。优化器应基于标准的拟牛顿法，并且不得依赖任何闭式解。\n- 通过使用指定的种子确保可复现性。\n- 程序应生成单行输出，包含所有测试用例的结果，形式为用方括号括起来的逗号分隔列表。对于每个测试用例，按$[T, \\text{df}, p]$的顺序输出一个包含三个值的列表，其中$T$是作为浮点数的似然比检验统计量，$\\text{df}$是作为整数的自由度，$p$是作为浮点数的$p$值。最终输出应为$[[T_1,\\text{df}_1,p_1],[T_2,\\text{df}_2,p_2],[T_3,\\text{df}_3,p_3],[T_4,\\text{df}_4,p_4]]$的形式。\n\n此问题不涉及任何物理单位或角度单位；所有输出均为无量纲量。", "solution": "该问题要求为多项逻辑回归模型实现一个似然比检验（LRT）。这涉及生成合成数据，在原假设下拟合一个完整（无约束）模型和一个简化（有约束）模型，然后比较它们的最大化对数似然以计算检验统计量。\n\n### 步骤1：问题验证\n根据指定标准对问题陈述进行严格评估。\n\n#### 步骤1.1：提取的已知条件\n- **模型：** 具有连续生物标志物预测变量$x$的基线类别多项逻辑回归。\n- **结果：** 一个具有$K$个互斥类别的分类变量，索引为$y_i \\in \\{0, 1, \\dots, K-1\\}$。类别$0$是基线。\n- **线性预测器：** 对于每个非基线类别$k \\in \\{1,\\dots,K-1\\}$，观测值$i$的线性预测器为$\\eta_{ik} = \\alpha_k + \\beta_k x_i$。基线类别的线性预测器为$\\eta_{i0} = 0$。\n- **概率：** 观测值$i$属于类别$k$的概率由softmax函数给出：$p_{ik} = \\frac{\\exp(\\eta_{ik})}{\\sum_{j=0}^{K-1} \\exp(\\eta_{ij})}$。每个观测值的概率总和为一：$\\sum_{k=0}^{K-1} p_{ik} = 1$。\n- **假设：** 原假设$H_0$陈述生物标志物没有效应，即对所有$k \\in \\{1,\\dots,K-1\\}$，$\\beta_k = 0$。备择假设$H_1$是至少有一个$\\beta_k \\neq 0$。\n- **核心原理：** 解决方案必须源于（1）独立分类结果的模型，（2）最大似然估计（MLE）原理，（3）指定的基线类别逻辑联系函数，以及（4）广义似然比检验原理。\n- **任务：** 对于几个合成数据集，拟合无约束模型和有约束模型，并执行LRT以获得检验统计量$T$、自由度$\\text{df}$和$p$值。\n- **数据生成：** 对于每个测试用例，从正态分布$\\mathcal{N}(\\mu_x, \\sigma_x^2)$中抽取$N$个生物标志物值$x_i$。然后根据真实模型参数$(\\boldsymbol{\\alpha}, \\boldsymbol{\\beta})$得出的概率，从多项分布中抽取结果$y_i$。为四个测试用例提供了$(N, K, \\boldsymbol{\\alpha}, \\boldsymbol{\\beta}, \\mu_x, \\sigma_x, \\text{seed})$的具体值。\n- **数值要求：** 必须使用拟牛顿优化方法执行MLE。计算必须数值稳定。\n\n#### 步骤1.2：验证与结论\n根据验证清单对问题进行评估：\n- **科学依据：** 该问题牢固地植根于经典统计理论。多项逻辑回归、MLE和LRT是生物统计学和其他科学领域中基本且广泛使用的方法。\n- **适定性：** 问题是自洽的，并提供了生成数据和执行指定分析所需的所有必要信息。该模型的目标函数（对数似然）是全局凹的，确保了数值优化是适定的，并将收敛到唯一的最大值。\n- **客观性：** 问题使用精确、正式且明确的数学和统计语言进行陈述。\n- **缺陷分析：** 问题没有表现出任何指定的缺陷。它在科学上是合理的、可形式化的、完整的、现实的并且是适定的。这是一个非平凡的计算任务，需要正确实现已建立的统计原理。\n\n**结论：** 该问题是**有效的**。\n\n### 步骤2：原理性解决方案设计\n\n#### 2.1：多项逻辑回归模型\n对于一个具有生物标志物值$x_i$的观测值$i$，该模型为非基线类别定义了$K-1$个线性预测器：\n$$ \\eta_{ik} = \\alpha_k + \\beta_k x_i \\quad \\text{for } k \\in \\{1, \\dots, K-1\\} $$\n为保证模型的可识别性，基线类别$k=0$的线性预测器固定为零，即$\\eta_{i0} = 0$。观测值$i$属于类别$k$的概率由softmax变换给出：\n$$ p_{ik} = P(y_i=k | x_i; \\boldsymbol{\\alpha}, \\boldsymbol{\\beta}) = \\frac{\\exp(\\eta_{ik})}{\\sum_{j=0}^{K-1} \\exp(\\eta_{ij})} $$\n\n#### 2.2：最大似然估计（MLE）\n模型的参数$\\boldsymbol{\\theta} = (\\alpha_1, \\dots, \\alpha_{K-1}, \\beta_1, \\dots, \\beta_{K-1})$通过最大化观测数据的对数似然来估计。给定$N$个独立观测值$\\{(x_i, y_i)\\}_{i=1}^N$，对数似然函数为：\n$$ \\ell(\\boldsymbol{\\theta}) = \\sum_{i=1}^N \\log P(y_i | x_i; \\boldsymbol{\\theta}) $$\n为方便计算，我们对结果使用独热编码，其中如果第$i$个观测值属于类别$k$，则$y_{ik} = 1$，否则$y_{ik} = 0$。对数似然可以写为：\n$$ \\ell(\\boldsymbol{\\theta}) = \\sum_{i=1}^{N} \\sum_{k=0}^{K-1} y_{ik} \\log(p_{ik}) $$\n代入$p_{ik}$的表达式：\n$$ \\ell(\\boldsymbol{\\theta}) = \\sum_{i=1}^{N} \\left( \\sum_{k=0}^{K-1} y_{ik}\\eta_{ik} - \\log\\left(\\sum_{j=0}^{K-1} \\exp(\\eta_{ij})\\right) \\right) $$\n由于$\\eta_{i0}=0$且$\\sum_{k=0}^{K-1} y_{ik}=1$，并注意到$y_{i0} \\eta_{i0} = 0$：\n$$ \\ell(\\boldsymbol{\\theta}) = \\sum_{i=1}^{N} \\left( \\sum_{k=1}^{K-1} y_{ik}\\eta_{ik} - \\log\\left(1 + \\sum_{j=1}^{K-1} \\exp(\\eta_{ij})\\right) \\right) $$\n直接计算$\\exp(\\eta_{ij})$可能导致数值溢出。使用`log-sum-exp`技巧进行稳定计算：$\\log(\\sum_j e^{z_j}) = M + \\log(\\sum_j e^{z_j-M})$，其中$M=\\max_j(z_j)$。通过使用拟牛顿法（L-BFGS-B）最小化负对数似然$-\\ell(\\boldsymbol{\\theta})$来进行优化。\n\n#### 2.3：似然比检验（LRT）\nLRT用于比较两个嵌套模型。\n- **无约束模型（$M_1$）：** 这是上述的完整模型，参数为$\\boldsymbol{\\theta}_1 = (\\alpha_1, \\dots, \\alpha_{K-1}, \\beta_1, \\dots, \\beta_{K-1})$。参数数量为$d_1 = 2(K-1)$。对此模型最大化似然得到最大化对数似然$\\ell_1^* = \\ell(\\hat{\\boldsymbol{\\theta}}_1)$。\n- **有约束模型（$M_0$）：** 该模型由原假设$H_0: \\beta_k = 0$（对所有$k$）指定。其线性预测器为$\\eta_{ik} = \\alpha_k$。参数为$\\boldsymbol{\\theta}_0 = (\\alpha_1, \\dots, \\alpha_{K-1})$。参数数量为$d_0 = K-1$。在此约束下最大化似然得到$\\ell_0^* = \\ell(\\hat{\\boldsymbol{\\theta}}_0)$。\n\n似然比检验统计量$T$定义为：\n$$ T = -2 (\\ell_0^* - \\ell_1^*) = 2(\\ell_1^* - \\ell_0^*) $$\n在原假设$H_0$下，对于足够大的样本量$N$，$T$渐近服从卡方分布（$\\chi^2$），其自由度等于两个模型参数数量之差：\n$$ \\text{df} = d_1 - d_0 = 2(K-1) - (K-1) = K-1 $$\n$p$值是在假设$H_0$为真的情况下，观测到至少与计算出的检验统计量一样大的值的概率：\n$$ p = P(\\chi^2_{\\text{df}} \\ge T) $$\n这使用$\\chi^2_{\\text{df}}$分布的生存函数来计算。\n\n#### 2.4：实现\n解决方案逻辑在Python程序中实现。对于每个测试用例：\n1.  使用`numpy.random`创建一个合成数据集。为保证可复现性，使用`default_rng`并设定种子。\n2.  定义两个目标函数`nll_m0`和`nll_m1`，分别计算有约束模型和无约束模型的负对数似然。这些函数设计为数值稳定。\n3.  使用`scipy.optimize.minimize`函数和`L-BFGS-B`方法，通过最小化各自的负对数似然来找到两个模型的最大似然估计。\n4.  从优化结果中提取最大化对数似然$\\ell_0^*$和$\\ell_1^*$。\n5.  如上所述计算LRT统计量$T$、自由度$\\text{df}$和$p$值，其中$p$值从`scipy.stats.chi2.sf`获得。\n6.  收集所有测试用例的结果，并将其格式化为所需的输出字符串。", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.special import softmax, logsumexp\nfrom scipy.stats import chi2\n\ndef solve():\n    \"\"\"\n    Main function to run the likelihood ratio test for multinomial logistic regression\n    on several synthetic datasets.\n    \"\"\"\n    test_cases = [\n        # (N, K, alpha_true, beta_true, mu_x, sigma_x, seed)\n        (800, 4, [-1.2, 0.5, -0.3], [0.8, -0.5, 0.4], 2.0, 1.0, 42),\n        (600, 3, [-0.2, -1.0], [0.0, 0.0], 1.0, 0.8, 123),\n        (50, 3, [-1.5, -1.0], [1.5, 1.2], 0.0, 1.2, 999),\n        (1200, 5, [-2.0, -1.0, -1.5, -3.0], [0.7, 0.3, -0.4, 0.9], 1.5, 0.7, 2023),\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        N, K, alphas_true, betas_true, mu_x, sigma_x, seed = case\n        \n        # 1. Generate synthetic data\n        rng = np.random.default_rng(seed)\n        x_data = rng.normal(loc=mu_x, scale=sigma_x, size=N)\n        \n        alphas_true_np = np.array(alphas_true)\n        betas_true_np = np.array(betas_true)\n\n        # Calculate true linear predictors (eta) for categories 1 to K-1\n        eta = alphas_true_np[None, :] + np.outer(x_data, betas_true_np)\n        \n        # Add baseline category's eta (which is 0)\n        eta_full = np.hstack([np.zeros((N, 1)), eta])\n        \n        # Convert to probabilities using softmax\n        probs = softmax(eta_full, axis=1)\n        \n        # Generate categorical outcomes\n        y_data = np.array([rng.choice(K, p=p_i) for p_i in probs])\n        \n        # One-hot encode the outcome variable for likelihood calculation\n        y_one_hot = np.zeros((N, K))\n        y_one_hot[np.arange(N), y_data] = 1\n\n        # 2. Fit models using MLE\n        \n        def nll_m0(params, x, y_oh, k_val):\n            \"\"\"Negative log-likelihood for the restricted model (M0: intercepts only).\"\"\"\n            n_obs = x.shape[0]\n            alphas = params\n            # Eta does not depend on x\n            eta_k = np.tile(alphas, (n_obs, 1))\n            eta_full = np.hstack([np.zeros((n_obs, 1)), eta_k])\n            \n            log_denominators = logsumexp(eta_full, axis=1)\n            log_probs = eta_full - log_denominators[:, None]\n            \n            nll = -np.sum(y_oh * log_probs)\n            return nll\n\n        def nll_m1(params, x, y_oh, k_val):\n            \"\"\"Negative log-likelihood for the unrestricted model (M1).\"\"\"\n            n_obs = x.shape[0]\n            alphas = params[:k_val - 1]\n            betas = params[k_val - 1:]\n            \n            eta_k = alphas[None, :] + np.outer(x, betas)\n            eta_full = np.hstack([np.zeros((n_obs, 1)), eta_k])\n\n            log_denominators = logsumexp(eta_full, axis=1)\n            log_probs = eta_full - log_denominators[:, None]\n\n            nll = -np.sum(y_oh * log_probs)\n            return nll\n\n        # Fit restricted model (M0)\n        initial_params_0 = np.zeros(K - 1)\n        res0 = minimize(nll_m0, initial_params_0, args=(x_data, y_one_hot, K), method='L-BFGS-B')\n        logL0 = -res0.fun\n\n        # Fit unrestricted model (M1)\n        initial_params_1 = np.zeros(2 * (K - 1))\n        res1 = minimize(nll_m1, initial_params_1, args=(x_data, y_one_hot, K), method='L-BFGS-B')\n        logL1 = -res1.fun\n\n        # 3. Perform Likelihood Ratio Test\n        # Test statistic T = 2 * (logL(M1) - logL(M0))\n        T = 2 * (logL1 - logL0)\n        \n        # Degrees of freedom = difference in number of parameters\n        df = (2 * (K - 1)) - (K - 1)\n        \n        # p-value from chi-squared distribution\n        p_value = chi2.sf(T, df)\n        \n        all_results.append([T, df, p_value])\n\n    # Format the final output string\n    # E.g., [[T1,df1,p1],[T2,df2,p2],...]\n    output_str = f\"[{','.join(f'[{t:.6f},{d},{p:.6f}]' for t, d, p in all_results)}]\"\n    print(output_str)\n\nsolve()\n```", "id": "4976107"}, {"introduction": "比例优势模型的有效性取决于其比例优势假设，而严谨的统计实践要求我们仔细审视这一假设。这个高级练习将指导您通过合并相邻的结果类别来进行敏感性分析，以观察参数估计和模型拟合度如何变化。将比例优势模型与更灵活的多项模型进行比较的这一过程，对于评估模型是否适当并确保结论的可靠性至关重要。[@problem_id:4976140]", "problem": "一位医学成果研究者正在对一个有序临床终点进行建模，例如按序数量表记录的疼痛严重程度，该终点是两个协变量的函数：一个二元治疗指示变量和一个连续年龄变量。其目标是通过执行敏感性分析来评估累积 logit 模型中比例优势假设的稳健性。该分析将合并相邻的结果类别，然后检验在比例优势模型和更灵活的基线类别多项式模型下，参数估计和拟合优度诊断如何变化。\n\n您必须实现一个完整的程序，仅使用确定性输入和计算来执行以下端到端过程。\n\n基本基础和模型定义：\n- 设响应为一个有序变量，类别为 $\\{1,2,\\dots,K\\}$，其中 $K \\ge 2$。累积 logit（比例优势）模型指定为\n$$\\Pr(Y \\le k \\mid \\mathbf{x}) = \\sigma(\\alpha_k - \\mathbf{x}^{\\top}\\boldsymbol{\\beta}), \\quad k=1,\\dots,K-1,$$\n其中 $\\sigma(z) = \\frac{1}{1 + e^{-z}}$ 是逻辑函数，$\\{\\alpha_k\\}$ 是严格递增的类别阈值，$\\alpha_1  \\cdots  \\alpha_{K-1}$，$\\boldsymbol{\\beta}$ 是不依赖于 $k$ 的斜率向量（比例优势假设）。\n- 类别 $k$ 的概率质量函数为\n$$\\Pr(Y=k \\mid \\mathbf{x}) =\n\\begin{cases}\n\\sigma(\\alpha_1 - \\eta),  k=1, \\\\\n\\sigma(\\alpha_k - \\eta) - \\sigma(\\alpha_{k-1} - \\eta),  k=2,\\dots,K-1, \\\\\n1 - \\sigma(\\alpha_{K-1} - \\eta),  k=K,\n\\end{cases}$$\n其中 $\\eta = \\mathbf{x}^{\\top}\\boldsymbol{\\beta}$。\n- 对于具有 $K$ 个类别的基线类别多项式逻辑回归，将类别 $K$ 指定为基线。对于 $k=1,\\dots,K-1$，\n$$\\ln \\frac{\\Pr(Y=k \\mid \\mathbf{x})}{\\Pr(Y=K \\mid \\mathbf{x})} = c_k + \\mathbf{x}^{\\top}\\boldsymbol{b}_k,$$\n具有类别特定的截距 $c_k$ 和斜率 $\\boldsymbol{b}_k$。那么 $p_k(\\mathbf{x}) = \\Pr(Y=k \\mid \\mathbf{x})$ 由 softmax 函数给出：\n$$p_k(\\mathbf{x}) = \\frac{\\exp(c_k + \\mathbf{x}^{\\top}\\boldsymbol{b}_k)}{1 + \\sum_{j=1}^{K-1} \\exp(c_j + \\mathbf{x}^{\\top}\\boldsymbol{b}_j)}, \\quad k=1,\\dots,K-1,$$\n且\n$$p_K(\\mathbf{x}) = \\frac{1}{1 + \\sum_{j=1}^{K-1} \\exp(c_j + \\mathbf{x}^{\\top}\\boldsymbol{b}_j)}.$$\n\n似然与诊断：\n- 给定独立观测值 $\\{(y_i,\\mathbf{x}_i)\\}_{i=1}^n$，在任何具有类别概率 $\\{p_{i,k}\\}$ 的模型下，对数似然为\n$$\\ell = \\sum_{i=1}^n \\log p_{i,y_i}.$$\n- 偏差（对于这些完全观测的分类结果）定义为\n$$D = -2 \\,\\ell.$$\n- 赤池信息准则（Akaike Information Criterion，AIC）为\n$$\\mathrm{AIC} = 2\\,d - 2\\,\\ell,$$\n其中 $d$ 是模型的自由参数数量。贝叶斯信息准则（Bayesian Information Criterion，BIC）为\n$$\\mathrm{BIC} = \\log(n)\\, d - 2\\,\\ell.$$\n\n确定性合成数据构建：\n- 设 $n = 200$。观测值索引为 $i \\in \\{1,\\dots,n\\}$。\n- 定义两个协变量：\n  - 治疗 $T_i \\in \\{0,1\\}$ 确定性地定义为：若 $i$ 为偶数，则 $T_i = 1$；若 $i$ 为奇数，则 $T_i = 0$。\n  - 年龄 $A_i$ 确定性地定义为 $A_i = 30 + 0.1\\, i$。\n- 设标准化年龄为 $Z_i = \\frac{A_i - \\bar{A}}{s_A}$，其中 $\\bar{A}$ 和 $s_A$ 分别是 $\\{A_i\\}_{i=1}^n$ 的样本均值和样本标准差。\n- 设 $K=4$，真实阈值为 $\\boldsymbol{\\alpha}^{\\star} = (-0.5, 0.8, 1.8)$，真实斜率为 $\\boldsymbol{\\beta}^{\\star} = (\\beta_T^{\\star}, \\beta_Z^{\\star}) = (-0.8, 0.5)$。对每个 $i$，计算线性预测器 $\\eta_i^{\\star} = \\beta_T^{\\star} T_i + \\beta_Z^{\\star} Z_i$。\n- 在比例优势数据生成机制下计算累积概率：$c_{i,k} = \\sigma(\\alpha_k^{\\star} - \\eta_i^{\\star})$，其中 $k=1,2,3$。然后类别概率为 $p_{i,1} = c_{i,1}$，$p_{i,2} = c_{i,2} - c_{i,1}$，$p_{i,3} = c_{i,3} - c_{i,2}$，以及 $p_{i,4} = 1 - c_{i,3}$。\n- 为分配确定性类别 $y_i \\in \\{1,2,3,4\\}$，计算 $u_i = \\{ i \\cdot \\varphi \\}$，即 $i \\cdot \\varphi$ 的小数部分，其中 $\\varphi = \\frac{\\sqrt{5}-1}{2}$。然后将 $y_i$ 设置为满足 $\\sum_{j=1}^k p_{i,j} \\ge u_i$ 的最小 $k$。\n\n模型拟合与参数化：\n- 对于具有 $K$ 个类别和 $p$ 个协变量的比例优势模型，使用上述对数似然并通过最大似然法进行估计。通过对阈值进行重参数化，使用无约束的 $\\gamma_1,\\dots,\\gamma_{K-1}$ 来强制执行排序约束 $\\alpha_1  \\cdots  \\alpha_{K-1}$：\n$$\\alpha_1 = \\gamma_1, \\quad \\alpha_k = \\alpha_{k-1} + \\exp(\\gamma_k) \\ \\text{for } k=2,\\dots,K-1.$$\n- 对于基线类别多项式模型，将类别 $K$ 作为基线，该模型具有 $(K-1)$ 个类别特定的截距和斜率。使用 softmax 概率模型和上述对数似然通过最大似然法进行估计。\n- 为了数值稳定性，在取对数时，必须通过将概率限制在一个小的正数下界来使其远离 $0$ 和 $1$。\n\n通过合并相邻类别进行敏感性分析：\n- 通过合并相邻的原始类别，构建三种合并后的结果：\n  - 情况 $\\mathcal{C}_{12}$：将类别 $1$ 和 $2$ 合并为单个第一类别，剩下类别 $(1+2), 3, 4$。\n  - 情况 $\\mathcal{C}_{23}$：将类别 $2$ 和 $3$ 合并，剩下类别 $1, (2+3), 4$。\n  - 情况 $\\mathcal{C}_{34}$：将类别 $3$ 和 $4$ 合并，剩下类别 $1, 2, (3+4)$。\n- 对于每个合并后的结果（具有新的 $K'$），重新拟合两种模型，并计算比例优势模型对治疗斜率的估计值 $\\widehat{\\beta}_T$ 以及拟合优度指标 $\\ell$、$D$、$\\mathrm{AIC}$ 和 $\\mathrm{BIC}$。\n- 同时，将比例优势模型拟合到未合并的结果（基线，$K=4$），并将其治疗斜率表示为 $\\widehat{\\beta}_T^{\\mathrm{base}}$，拟合优度指标也作相应记录。\n\n需报告的量和测试套件：\n- 按顺序将三种测试情况定义为合并方案 $\\mathcal{C}_{12}$、$\\mathcal{C}_{23}$ 和 $\\mathcal{C}_{34}$。\n- 对于每种情况 $\\mathcal{C}_{ab}$，计算：\n  - 在比例优势模型下，相较于对未合并的 $K=4$ 结果的基线拟合，估计的治疗斜率的变化：\n  $$\\Delta \\beta_T^{(ab)} = \\widehat{\\beta}_T^{(ab)} - \\widehat{\\beta}_T^{\\mathrm{base}}.$$\n  - 在同一数据集内，对合并后类别进行的多项式拟合与比例优势拟合之间的赤池信息准则差异：\n  $$\\Delta \\mathrm{AIC}_{\\mathrm{MN}-\\mathrm{PO}}^{(ab)} = \\mathrm{AIC}_{\\mathrm{MN}}^{(ab)} - \\mathrm{AIC}_{\\mathrm{PO}}^{(ab)}.$$\n- 按以下顺序将最终结果组合成一个包含 $6$ 个浮点数的列表\n$$\\big[\\Delta \\beta_T^{(12)}, \\ \\Delta \\mathrm{AIC}_{\\mathrm{MN}-\\mathrm{PO}}^{(12)}, \\ \\Delta \\beta_T^{(23)}, \\ \\Delta \\mathrm{AIC}_{\\mathrm{MN}-\\mathrm{PO}}^{(23)}, \\ \\Delta \\beta_T^{(34)}, \\ \\Delta \\mathrm{AIC}_{\\mathrm{MN}-\\mathrm{PO}}^{(34)}\\big].$$\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，例如 $[x_1,x_2,\\dots,x_6]$。\n- 每个浮点数必须表示为精确到 $6$ 位小数的十进制数，不带百分号。\n\n约束条件：\n- 使用数值优化器从合理的初始值开始，实现最大似然估计。对于比例优势模型中的阈值，使用上述重参数化方法以保证顺序。对于初始阈值，您可以使用边际结果分布的经验累积 logit；对于斜率，可以将其初始化为零。\n- 程序必须是自包含的，不应需要任何输入；它必须在内部生成确定性数据集并执行所有计算。\n\n测试套件和覆盖范围基本原理：\n- 三种合并方案 $\\mathcal{C}_{12}$、$\\mathcal{C}_{23}$ 和 $\\mathcal{C}_{34}$ 分别探究了低端合并、中心合并（可能最强烈地扰动中间阈值）和高端合并。这测试了在不同相邻类别合并情况下，比例优势斜率估计的敏感性以及多项式模型与比例优势模型之间相对拟合优度的变化。", "solution": "用户提供了一个在医学统计学中定义明确的计算问题。任务是通过合并结果类别对比例优势模型进行敏感性分析，并将其结果与更灵活的基线类别多项式模型进行比较。\n\n### **问题验证**\n\n问题陈述经过严格验证，并被确定为 **有效**。\n\n1.  **已知条件提取**：所有数据、变量和过程都已明确定义。这包括样本大小 $n=200$，生成协变量（$T_i, A_i$）和有序结果（$y_i$）的确定性规则，数据生成的真实参数（$\\boldsymbol{\\alpha}^{\\star}, \\boldsymbol{\\beta}^{\\star}$），比例优势模型和多项式逻辑回归模型的数学形式，拟合优度统计量（$\\ell$, $D$, $\\mathrm{AIC}$, $\\mathrm{BIC}$）的定义，有序阈值的重参数化方法，类别合并方案（$\\mathcal{C}_{12}, \\mathcal{C}_{23}, \\mathcal{C}_{34}$），以及待报告量的精确定义（$\\Delta \\beta_T^{(ab)}, \\Delta \\mathrm{AIC}_{\\mathrm{MN}-\\mathrm{PO}}^{(ab)}$）。\n\n2.  **验证检查**：\n    - **科学依据**：该问题基于生物统计学和其他领域使用的标准、成熟的统计模型（累积 logit 和多项式 logit 回归）。模型拟合（最大似然）、模型比较（$\\mathrm{AIC}$）和数据模拟的方法都是标准做法。\n    - **适定性**：该问题是确定性的和计算性的。所有步骤都已指定，从而导向一个唯一的、可验证的数值结果。\n    - **客观性**：语言精确且数学化，没有主观或含糊的陈述。\n    - 该问题不违反任何无效标准。它是计算统计学中一个实质性的、非平凡的任务。\n\n### **方法论**\n\n解决方案通过实现问题陈述中概述的步骤来进行。\n\n#### 1. 合成数据生成\n\n首先，构建一个大小为 $n=200$ 的确定性数据集。\n- 生成协变量：一个二元治疗指示变量 $T_i$ 和一个连续年龄变量 $A_i$。索引 $i$ 的范围是从 $1$ 到 $200$。\n    _ 若 $i$ 为偶数，则 $T_i = 1$；若 $i$ 为奇数，则 $T_i = 0$。\n    _ $A_i = 30 + 0.1 \\cdot i$。\n- 年龄变量 $A_i$ 被标准化为 $Z_i = (A_i - \\bar{A})/s_A$，其中 $\\bar{A}$ 和 $s_A$ 是 $A$ 的样本均值和标准差。设计矩阵为 $\\mathbf{X} = [\\mathbf{T}, \\mathbf{Z}]$。\n- 数据由一个真实的比例优势模型生成，该模型有 $K=4$ 个类别，真实阈值为 $\\boldsymbol{\\alpha}^{\\star} = (-0.5, 0.8, 1.8)$，真实斜率参数为 $\\boldsymbol{\\beta}^{\\star} = (\\beta_T^{\\star}, \\beta_Z^{\\star}) = (-0.8, 0.5)$。\n- 对于每个观测值 $i$，线性预测器为 $\\eta_i^{\\star} = \\mathbf{x}_i^{\\top}\\boldsymbol{\\beta}^{\\star}$。类别概率 $p_{i,k} = \\Pr(Y_i=k \\mid \\mathbf{x}_i)$ 使用比例优势公式计算：\n$$p_{i,1} = \\sigma(\\alpha_1^{\\star} - \\eta_i^{\\star})$$\n$$p_{i,k} = \\sigma(\\alpha_k^{\\star} - \\eta_i^{\\star}) - \\sigma(\\alpha_{k-1}^{\\star} - \\eta_i^{\\star}), \\quad \\text{for } k=2,3$$\n$$p_{i,4} = 1 - \\sigma(\\alpha_3^{\\star} - \\eta_i^{\\star})$$\n其中 $\\sigma(z) = (1+e^{-z})^{-1}$ 是逻辑 sigmoid 函数。\n- 使用低差异序列分配确定性结果 $y_i \\in \\{1,2,3,4\\}$。我们计算 $u_i = \\{i \\cdot \\varphi\\}$，即 $i \\cdot \\frac{\\sqrt{5}-1}{2}$ 的小数部分，并将 $y_i$ 设置为满足累积概率 $\\sum_{j=1}^k p_{i,j}$ 大于或等于 $u_i$ 的最小整数 $k$。\n\n#### 2. 模型拟合\n\n使用数值优化器（`BFGS` 算法）通过最大似然估计拟合两种类型的逻辑回归模型。优化器的目标函数是负对数似然，$\\ell = \\sum_{i=1}^n \\log p_{i,y_i}$。\n\n- **比例优势 (PO) 模型**：对数似然基于上述定义的类别概率。该模型有 $K-1$ 个阈值和 $p$ 个斜率。为确保阈值排序 $\\alpha_1  \\cdots  \\alpha_{K-1}$，我们对无约束参数 $\\gamma_1, \\dots, \\gamma_{K-1}$ 进行优化，其中：\n$$\\alpha_1 = \\gamma_1, \\quad \\alpha_k = \\alpha_{k-1} + \\exp(\\gamma_k) \\text{ for } k=2,\\dots,K-1.$$\n总参数数量为 $d_{\\mathrm{PO}} = (K-1) + p$。\n\n- **基线类别多项式 (MN) 模型**：以类别 $K$ 为基线，该模型有 $(K-1)$ 组参数，每组包含一个截距 $c_k$ 和一个斜率向量 $\\boldsymbol{b}_k$。概率由 softmax 函数给出：\n$$p_k(\\mathbf{x}) = \\frac{\\exp(c_k + \\mathbf{x}^{\\top}\\boldsymbol{b}_k)}{1 + \\sum_{j=1}^{K-1} \\exp(c_j + \\mathbf{x}^{\\top}\\boldsymbol{b}_j)}, \\quad k=1,\\dots,K-1$$\n$$p_K(\\mathbf{x}) = \\frac{1}{1 + \\sum_{j=1}^{K-1} \\exp(c_j + \\mathbf{x}^{\\top}\\boldsymbol{b}_j)}.$$\n总参数数量为 $d_{\\mathrm{MN}} = (K-1)(p+1)$。为了在优化过程中保持数值稳定性，在取对数之前将概率钳制在一个小的正值 $\\epsilon$，并在 softmax 计算中采用 log-sum-exp 技巧。\n\n#### 3. 敏感性分析\n\n分析过程如下：\n1.  **基线拟合**：将比例优势模型拟合到原始未合并的数据（$K=4$，结果 $y_i \\in \\{1,2,3,4\\}$）。这产生了治疗斜率的基线估计值 $\\widehat{\\beta}_T^{\\mathrm{base}}$。\n2.  **类别合并与重新拟合**：针对三种情况重复该分析，其中相邻类别被合并，从而产生一个新的具有 $K'=3$ 个类别的结果变量。\n    - **情况 $\\mathcal{C}_{12}$**：合并类别 $1$ 和 $2$。\n    - **情况 $\\mathcal{C}_{23}$**：合并类别 $2$ 和 $3$。\n    - **情况 $\\mathcal{C}_{34}$**：合并类别 $3$ 和 $4$。\n    对于每种情况，将比例优势模型和多项式模型都拟合到合并后的数据。\n3.  **指标计算**：对于每个合并情况 $\\mathcal{C}_{ab}$，我们计算：\n    - PO 模型估计的治疗斜率相对于基线的变化：$\\Delta \\beta_T^{(ab)} = \\widehat{\\beta}_T^{(ab)} - \\widehat{\\beta}_T^{\\mathrm{base}}$。\n    - 在*相同*合并数据集上拟合的两个模型之间的 AIC 差异：$\\Delta \\mathrm{AIC}_{\\mathrm{MN}-\\mathrm{PO}}^{(ab)} = \\mathrm{AIC}_{\\mathrm{MN}}^{(ab)} - \\mathrm{AIC}_{\\mathrm{PO}}^{(ab)}$，其中 $\\mathrm{AIC} = 2d - 2\\ell$。\n\n最终输出由这六个值组成，按合并情况排序。", "answer": "```python\n# The final answer must be a single, complete, standalone program.\n# Execution Environment: Python 3.12, numpy 1.23.5, scipy 1.11.4\n\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.special import expit as logistic_sigmoid\n\n# Small constant for numerical stability\nEPSILON = 1e-15\n\ndef generate_data():\n    \"\"\"Generates the deterministic synthetic dataset as per the problem description.\"\"\"\n    n = 200\n    i = np.arange(1, n + 1)\n\n    T = (i % 2 == 0).astype(int)\n    A = 30 + 0.1 * i\n\n    mean_A = np.mean(A)\n    std_A = np.std(A, ddof=1)\n    Z = (A - mean_A) / std_A\n\n    X = np.stack([T, Z], axis=1)\n\n    alpha_star = np.array([-0.5, 0.8, 1.8])\n    beta_star = np.array([-0.8, 0.5])\n    K = 4\n\n    eta_star = X @ beta_star\n\n    cum_probs = np.zeros((n, K - 1))\n    for k in range(K - 1):\n        cum_probs[:, k] = logistic_sigmoid(alpha_star[k] - eta_star)\n    \n    cat_probs = np.zeros((n, K))\n    cat_probs[:, 0] = cum_probs[:, 0]\n    for k in range(1, K - 1):\n        cat_probs[:, k] = cum_probs[:, k] - cum_probs[:, k-1]\n    cat_probs[:, K - 1] = 1 - cum_probs[:, K - 2]\n    \n    phi = (np.sqrt(5) - 1) / 2\n    u = (i * phi) % 1\n    \n    y = np.zeros(n, dtype=int)\n    cumulative_cat_probs = cat_probs.cumsum(axis=1) \n    for i_obs in range(n):\n        y[i_obs] = np.searchsorted(cumulative_cat_probs[i_obs, :], u[i_obs], side='left') + 1\n        \n    return X, y\n\ndef get_po_initial_params(y, K, p):\n    \"\"\"Computes initial parameters for the PO model.\"\"\"\n    n = len(y)\n    freqs = np.bincount(y - 1, minlength=K) / n\n    cum_freqs = np.cumsum(freqs)\n    \n    clipped_cum_freqs = np.clip(cum_freqs[:-1], EPSILON, 1 - EPSILON)\n    \n    try:\n        alpha_init = np.log(clipped_cum_freqs / (1 - clipped_cum_freqs))\n        gamma_init = np.zeros(K - 1)\n        gamma_init[0] = alpha_init[0]\n        if K > 2:\n            diffs = np.diff(alpha_init)\n            gamma_init[1:] = np.log(np.maximum(diffs, EPSILON))\n        if np.any(np.isnan(gamma_init)) or np.any(np.isinf(gamma_init)):\n            raise ValueError\n    except (ValueError, FloatingPointError):\n        gamma_init = np.linspace(-1, 1, K-1) \n\n    beta_init = np.zeros(p)\n    return np.concatenate([gamma_init, beta_init])\n    \ndef neg_log_lik_po(params, X, y, K):\n    \"\"\"Negative log-likelihood for the Proportional Odds model.\"\"\"\n    n, p = X.shape\n    gammas = params[:K-1]\n    betas = params[K-1:]\n    \n    alphas = np.zeros(K-1)\n    alphas[0] = gammas[0]\n    for k in range(1, K-1):\n        alphas[k] = alphas[k-1] + np.exp(gammas[k])\n        \n    eta = X @ betas\n    \n    cum_probs = np.zeros((n, K-1))\n    for k in range(K-1):\n        cum_probs[:, k] = logistic_sigmoid(alphas[k] - eta)\n\n    cat_probs = np.zeros((n, K))\n    cat_probs[:, 0] = cum_probs[:, 0]\n    if K > 2:\n        for k in range(1, K-1):\n            cat_probs[:, k] = cum_probs[:, k] - cum_probs[:, k-1]\n    cat_probs[:, K-1] = 1 - cum_probs[:, K-2]\n    \n    y_idx = y - 1\n    probs_obs = cat_probs[np.arange(n), y_idx]\n    \n    log_probs = np.log(np.maximum(probs_obs, EPSILON))\n    return -np.sum(log_probs)\n\ndef fit_po_model(X, y, K):\n    \"\"\"Fits the Proportional Odds model and returns results.\"\"\"\n    p = X.shape[1]\n    d = K - 1 + p\n    \n    initial_params = get_po_initial_params(y, K, p)\n\n    res = minimize(neg_log_lik_po, initial_params, args=(X, y, K), method='BFGS')\n    \n    log_lik = -res.fun\n    aic = 2 * d - 2 * log_lik\n    \n    beta_T_hat = res.x[K-1]\n    \n    return beta_T_hat, aic\n\ndef neg_log_lik_mn(params, X, y, K):\n    \"\"\"Negative log-likelihood for the Baseline-Category Multinomial model.\"\"\"\n    n, p = X.shape\n    \n    param_matrix = params.reshape((K-1, p+1))\n    X_aug = np.c_[np.ones(n), X]\n\n    scores = X_aug @ param_matrix.T\n    \n    # Log-sum-exp trick for stability\n    max_score_among_all = np.max(np.c_[scores, np.zeros(n)], axis=1, keepdims=True)\n    scores_stable = scores - max_score_among_all\n    \n    log_den = max_score_among_all.flatten() + np.log(np.sum(np.exp(scores_stable), axis=1) + np.exp(0 - max_score_among_all.flatten()))\n    \n    log_probs_k_minus_1 = scores - log_den[:, np.newaxis]\n    log_prob_K = -log_den\n    \n    log_cat_probs = np.c_[log_probs_k_minus_1, log_prob_K]\n\n    y_idx = y - 1\n    log_probs_obs = log_cat_probs[np.arange(n), y_idx]\n    \n    return -np.sum(log_probs_obs)\n\ndef fit_mn_model(X, y, K):\n    \"\"\"Fits the Baseline-Category Multinomial model and returns results.\"\"\"\n    p = X.shape[1]\n    d = (K-1) * (p+1)\n    \n    initial_params = np.zeros(d)\n\n    res = minimize(neg_log_lik_mn, initial_params, args=(X, y, K), method='BFGS', options={'gtol':1e-6})\n    \n    log_lik = -res.fun\n    aic = 2 * d - 2 * log_lik\n    \n    return aic\n\ndef solve():\n    \"\"\"Main function to perform the analysis and print results.\"\"\"\n    X, y_base = generate_data()\n    K_base = 4\n    \n    beta_T_base, _ = fit_po_model(X, y_base, K_base)\n    \n    results = []\n    \n    collapse_cases = [(1, 2), (2, 3), (3, 4)]\n    \n    for case in collapse_cases:\n        c1, c2 = case\n        y_collapsed = y_base.copy()\n        \n        if c1 == 1 and c2 == 2:\n            y_collapsed[y_collapsed == 2] = 1\n            y_collapsed[y_collapsed == 3] = 2\n            y_collapsed[y_collapsed == 4] = 3\n        elif c1 == 2 and c2 == 3:\n            y_collapsed[y_collapsed == 3] = 2\n            y_collapsed[y_collapsed == 4] = 3\n        elif c1 == 3 and c2 == 4:\n            y_collapsed[y_collapsed == 4] = 3\n            \n        K_collapsed = 3\n        \n        beta_T_hat_ab, aic_po_ab = fit_po_model(X, y_collapsed, K_collapsed)\n        aic_mn_ab = fit_mn_model(X, y_collapsed, K_collapsed)\n        \n        delta_beta_T = beta_T_hat_ab - beta_T_base\n        delta_aic = aic_mn_ab - aic_po_ab\n        \n        results.extend([delta_beta_T, delta_aic])\n\n    print(f\"[{','.join(f'{x:.6f}' for x in results)}]\")\n\nsolve()\n\n```", "id": "4976140"}]}