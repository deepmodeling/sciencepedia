{"hands_on_practices": [{"introduction": "在编写代码之前，建立对马尔可夫链蒙特卡洛（MCMC）采样器行为的直观理解至关重要。本练习将通过一个思想实验 [@problem_id:1932795]，探讨一个经典的MCMC挑战：从具有多个分离的概率峰值（即多峰分布）的分布中进行采样。我们将看到，一个看似合理的采样器参数选择，为何可能导致其完全无法探索整个概率空间，从而突显出批判性地评估MCMC输出的重要性。", "problem": "一位数据科学家正在使用马尔可夫链蒙特卡洛 (MCMC) 方法，从一个复杂的一维目标概率密度函数 $\\pi(x)$ 中抽取样本。已知目标分布是一个对称双峰分布，具体来说是两个高斯分布的等权重混合。其密度与两个高斯概率密度函数之和成正比：\n$$ \\pi(x) \\propto \\exp\\left(-\\frac{(x - \\mu_A)^2}{2\\sigma_{mode}^2}\\right) + \\exp\\left(-\\frac{(x - \\mu_B)^2}{2\\sigma_{mode}^2}\\right) $$\n给定参数为 $\\mu_A = -10$，$\\mu_B = 10$，以及 $\\sigma_{mode} = 1$。这种结构导致了两个狭窄且分离良好的概率模态，分别以 $x=-10$ 和 $x=10$ 为中心，它们之间存在一个概率密度极低的区域。\n\n该科学家使用随机游走 Metropolis 算法。在每一步，从以当前状态 $x_t$ 为中心的高斯分布中提议一个新状态 $x'$，即 $x' \\sim N(x_t, \\sigma_{step}^2)$。为了获得高接受率，该科学家选择了一个非常小的步长方差，设定 $\\sigma_{step} = 0.1$。MCMC 链在其中一个模态的峰值 $x_0 = -10$ 处初始化，并运行 $N=10^6$ 次迭代。\n\n下列哪个陈述最准确地描述了该 MCMC 采样器的行为以及所得样本集 $\\{x_1, x_2, \\dots, x_N\\}$ 的统计特性？\n\nA. 样本将分布在目标分布的真实均值 $x=0$ 附近。样本均值将接近 0，但样本方差将很大（大于 100），准确地反映了两个模态之间的显著分离。\n\nB. 提议移动的接受率将非常低（接近 0），因为步长没有根据目标分布的整体尺度进行良好调整。链将停留在其初始位置 $x_0 = -10$ 或其附近。\n\nC. 提议移动的接受率将非常高（接近 1）。生成的样本将充分探索对应于 $x=-10$ 处模态的区域，但链将无法转换到 $x=10$ 处的另一个模态。样本均值将约为 $-10$。\n\nD. 采样器将高效地探索整个状态空间。链将在两个模态之间频繁地来回跳跃，样本的直方图将正确地形成以 $x=-10$ 和 $x=10$ 为中心的两个不同的峰。\n\nE. 采样器的行为将像一个简单的随机游走，导致样本从起始点扩散开来。最终的样本集合将在以 $x=-10$ 为中心的宽区间上近似均匀分布。", "solution": "我们将目标建模为两个高斯密度的等权重混合，它们具有共同的标准差 $\\sigma_{mode}$ 和均值 $\\mu_{A}$、$\\mu_{B}$。在忽略比例常数的情况下，\n$$\n\\pi(x) \\propto \\exp\\!\\left(-\\frac{(x-\\mu_{A})^{2}}{2\\sigma_{mode}^{2}}\\right) + \\exp\\!\\left(-\\frac{(x-\\mu_{B})^{2}}{2\\sigma_{mode}^{2}}\\right).\n$$\n使用一个带有对称高斯提议 $q(x' \\mid x)=\\mathcal{N}(x,\\sigma_{step}^{2})$ 的随机游走 Metropolis 采样器，在状态 $x_{t}$ 对提议 $x'$ 的 Metropolis–Hastings 接受概率为\n$$\n\\alpha(x_{t},x')=\\min\\!\\left(1,\\frac{\\pi(x')}{\\pi(x_{t})}\\right).\n$$\n\n在 $x_{0}=\\mu_{A}$ 处初始化。因为模态是良好分离的，当 $x$ 接近 $\\mu_{A}$ 时，$\\pi(x)$ 中来自 $\\mu_{B}$ 分量的贡献相对于来自 $\\mu_{A}$ 分量的贡献可以忽略不计。对于一个小的提议增量 $\\epsilon:=x'-x$ 且满足 $|\\epsilon| \\ll \\sigma_{mode}$，主导比率近似给出\n$$\n\\frac{\\pi(x')}{\\pi(x)} \\approx \\frac{\\exp\\!\\left(-\\frac{(x'-\\mu_{A})^{2}}{2\\sigma_{mode}^{2}}\\right)}{\\exp\\!\\left(-\\frac{(x-\\mu_{A})^{2}}{2\\sigma_{mode}^{2}}\\right)}=\\exp\\!\\left(-\\frac{(x'-\\mu_{A})^{2}-(x-\\mu_{A})^{2}}{2\\sigma_{mode}^{2}}\\right).\n$$\n在 $x\\approx\\mu_{A}$ 处，对于小的 $\\epsilon$ 这简化为\n$$\n\\frac{\\pi(x')}{\\pi(x)} \\approx \\exp\\!\\left(-\\frac{\\epsilon^{2}}{2\\sigma_{mode}^{2}}\\right),\n$$\n所以当 $\\sigma_{step} \\ll \\sigma_{mode}$ 时，接受概率接近 $1$，因为典型的 $|\\epsilon|$ 与 $\\sigma_{step}$ 是同一数量级。因此，当链探索起始模态的邻域时，接受率非常高。\n\n在一次提议中从 $\\mu_{A}$ 的邻域直接跳跃到 $\\mu_{B}$ 的邻域，需要一个数量级为 $|\\mu_{B}-\\mu_{A}|$ 的位移。在方差为 $\\sigma_{step}^{2}$ 的高斯提议下，这种跳跃的概率数量级为\n$$\n\\exp\\!\\left(-\\frac{(\\mu_{B}-\\mu_{A})^{2}}{2\\sigma_{step}^{2}}\\right),\n$$\n当 $|\\mu_{B}-\\mu_{A}| \\gg \\sigma_{step}$ 时，这是可以忽略不计的。\n\n通过许多小的被接受的步长来穿过低密度区域，在有限次运行中也是极不可能的，因为谷底的平稳密度比峰值的平稳密度要指数级地小。在中点 $x^{\\star}=(\\mu_{A}+\\mu_{B})/2$ 处，目标密度为\n$$\n\\pi(x^{\\star}) \\propto 2\\exp\\!\\left(-\\frac{(\\mu_{B}-\\mu_{A})^{2}}{8\\sigma_{mode}^{2}}\\right),\n$$\n而在 $x=\\mu_{A}$ 附近，它是 $\\pi(\\mu_{A}) \\propto 1$（另一分量在那里可以忽略不计）。因此，比率\n$$\n\\frac{\\pi(x^{\\star})}{\\pi(\\mu_{A})} \\approx 2\\exp\\!\\left(-\\frac{(\\mu_{B}-\\mu_{A})^{2}}{8\\sigma_{mode}^{2}}\\right)\n$$\n当 $|\\mu_{B}-\\mu_{A}| \\gg \\sigma_{mode}$ 时是指数级小的。这意味着到达谷底或另一个模态的期望时间是指数级大的，与该比率的倒数是同一数量级，当分离很大且提议非常局部时，这远远超过给定的 $N$。\n\n因此，当 $\\sigma_{step}$ 相对于 $\\sigma_{mode}$ 选择得非常小，并且模态良好分离时，链具有非常高的接受率，充分探索起始模态 $x=\\mu_{A}$ 周围的局部盆地，在运行中基本上永远不会转换到另一个模态，并产生一个约等于 $\\mu_{A}$ 的样本均值。在这些选项中，这对应于陈述 C。", "answer": "$$\\boxed{C}$$", "id": "1932795"}, {"introduction": "在了解了潜在的陷阱之后，让我们来亲手构建一个有效的MCMC算法。本练习 [@problem_id:4971664] 将指导您为一个基础的贝叶斯模型（正态-正态模型）实现Metropolis-Hastings算法的核心步骤。您需要将理论上的接受概率公式转化为代码，并体验不同的提议机制（对称的随机游走与非对称的独立采样器）如何影响计算，从而为构建更复杂的定制MCMC采样器打下坚实基础。", "problem": "考虑一个常用于连续临床结局的单参数贝叶斯模型，其中观测响应是条件独立的，并围绕患者水平的治疗效果呈正态分布。假设数据由样本均值 $\\,\\bar{y}\\,$ 和样本量 $\\,n\\,$ 概括，观测方差 $\\,\\sigma^2\\,$ 已知。假设治疗效果参数 $\\,\\theta\\,$ 的先验分布为正态分布。具体来说：\n- 似然为 $\\,y_i \\mid \\theta \\sim \\mathcal{N}(\\theta,\\sigma^2)\\,$，对于 $\\,i=1,\\dots,n\\,$ 独立。\n- 先验为 $\\,\\theta \\sim \\mathcal{N}(\\mu_0,\\tau_0^2)\\,$。\n\n您将为此正态-正态模型在马尔可夫链蒙特卡洛 (MCMC) 中实现一个 Metropolis–Hastings (MH) 步骤。该算法必须在两种提议分布族下，为给定的当前状态 $\\,\\theta\\,$ 和建议状态 $\\,\\theta'\\,$ 计算 MH 接受概率：\n- 随机游走正态提议分布： $\\,q(\\theta' \\mid \\theta)=\\mathcal{N}(\\theta, s^2)\\,$。\n- 独立正态提议分布： $\\,q(\\theta' \\mid \\theta)=\\mathcal{N}(\\mu_q,\\sigma_q^2)\\,$。\n\n您的程序必须：\n1. 从贝叶斯后验与似然乘以先验成正比的基本定义出发，并从 Metropolis–Hastings 接受概率的定义出发，仅使用似然的充分统计量 $\\,\\bar{y}\\,$ 和 $\\,n\\,$ 来实现接受概率的数值计算。\n2. 计算对数接受率以保持数值稳定性，同时仔细考虑适用于指定提议分布族的 Hastings 修正 $\\,q(\\theta \\mid \\theta')/q(\\theta' \\mid \\theta)\\,$。\n3. 对于每个测试用例，将接受概率 $\\,\\alpha=\\min\\{1,\\exp(\\log \\alpha)\\}\\,$ 作为浮点数输出。\n\n使用以下参数集测试套件，每个集合都完整指定了 $\\,\\bar{y}\\,$, $\\,n\\,$, $\\,\\sigma^2\\,$, $\\,\\mu_0\\,$, $\\,\\tau_0^2\\,$, 当前状态 $\\,\\theta\\,$, 建议状态 $\\,\\theta'\\,$, 以及提议分布的细节：\n- 用例 $\\,1\\,$ (随机游走正态提议分布): $\\,\\bar{y}=1.2\\,$, $\\,n=50\\,$, $\\,\\sigma^2=16\\,$, $\\,\\mu_0=0\\,$, $\\,\\tau_0^2=100\\,$, $\\,\\theta=1.5\\,$, $\\,\\theta'=1.8\\,$, $\\,s^2=0.25\\,$.\n- 用例 $\\,2\\,$ (独立正态提议分布): $\\,\\bar{y}=8.4\\,$, $\\,n=5\\,$, $\\,\\sigma^2=4\\,$, $\\,\\mu_0=10\\,$, $\\,\\tau_0^2=1\\,$, $\\,\\theta=8\\,$, $\\,\\theta'=6\\,$, $\\,\\mu_q=9\\,$, $\\,\\sigma_q^2=9\\,$.\n- 用例 $\\,3\\,$ (独立正态提议分布，相同状态): $\\,\\bar{y}=0.3\\,$, $\\,n=10\\,$, $\\,\\sigma^2=1\\,$, $\\,\\mu_0=0\\,$, $\\,\\tau_0^2=4\\,$, $\\,\\theta=0.7\\,$, $\\,\\theta'=0.7\\,$, $\\,\\mu_q=0\\,$, $\\,\\sigma_q^2=9\\,$.\n- 用例 $\\,4\\,$ (随机游走正态提议分布，远离的提议): $\\,\\bar{y}=0.2\\,$, $\\,n=200\\,$, $\\,\\sigma^2=9\\,$, $\\,\\mu_0=0\\,$, $\\,\\tau_0^2=1000\\,$, $\\,\\theta=0.1\\,$, $\\,\\theta'=5.0\\,$, $\\,s^2=1.0\\,$.\n- 用例 $\\,5\\,$ (具有非平凡 Hastings 修正的独立正态提议分布): $\\,\\bar{y}=0.6\\,$, $\\,n=5\\,$, $\\,\\sigma^2=1\\,$, $\\,\\mu_0=0\\,$, $\\,\\tau_0^2=10\\,$, $\\,\\theta=0.0\\,$, $\\,\\theta'=0.8\\,$, $\\,\\mu_q=1.0\\,$, $\\,\\sigma_q^2=0.25\\,$.\n\n程序要求：\n- 完全基于 $\\,\\bar{y}\\,$, $\\,n\\,$, $\\,\\sigma^2\\,$, $\\,\\mu_0\\,$, $\\,\\tau_0^2\\,$, $\\,\\theta\\,$, $\\,\\theta'\\,$, 和提议分布参数来实现计算。不要使用超出基本定义之外的任何闭式后验。\n- 使用对数来稳定地计算接受率，然后将其转换为接受概率 $\\,\\alpha\\,$。\n- 对于随机游走正态提议分布，正确认识到 Hastings 修正由于对称性而简化；对于独立正态提议分布，根据指定的 $\\,\\mu_q\\,$ 和 $\\,\\sigma_q^2\\,$ 计算修正。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含五个用例的接受概率，格式为一个左方括号，后跟五个格式化为小数点后六位并用逗号分隔的值，最后是一个右方括号。\n- 输出为在 $[0,1]$ 范围内的无单位浮点数。", "solution": "该问题已经过验证，被认为是计算统计学中一个良构、科学合理且客观的问题。它要求为正态-正态贝叶斯模型实现一个 Metropolis-Hastings (MH) 步骤。\n\n从当前状态 $\\theta$ 转移到建议状态 $\\theta'$ 的 Metropolis-Hastings 接受概率 $\\alpha$ 由下式给出：\n$$ \\alpha(\\theta', \\theta) = \\min\\left(1, \\frac{\\pi(\\theta')}{\\pi(\\theta)} \\frac{q(\\theta \\mid \\theta')}{q(\\theta' \\mid \\theta)}\\right) $$\n其中 $\\pi(\\cdot)$ 是目标后验概率密度函数，而 $q(\\cdot \\mid \\cdot)$ 是提议概率密度函数。为了数值稳定性，计算在对数尺度上进行。对数接受率 $\\log R$ 为：\n$$ \\log R = \\log(\\pi(\\theta')) - \\log(\\pi(\\theta)) + \\log(q(\\theta \\mid \\theta')) - \\log(q(\\theta' \\mid \\theta)) $$\n接受概率则为 $\\alpha = \\min(1, \\exp(\\log R))$。\n\n目标后验密度 $\\pi(\\theta)$ 与似然 $L(\\theta \\mid \\mathbf{y})$ 和先验 $p(\\theta)$ 的乘积成正比。\n$$ \\pi(\\theta) \\propto L(\\theta \\mid \\mathbf{y}) \\times p(\\theta) $$\n\n**1. 似然和先验设定**\n\n对于 $n$ 个独立观测值 $y_i \\sim \\mathcal{N}(\\theta, \\sigma^2)$，其似然为：\n$$ L(\\theta \\mid \\mathbf{y}) = \\prod_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_i - \\theta)^2}{2\\sigma^2}\\right) $$\n按照要求，我们使用充分统计量 $\\bar{y}$ 和 $n$。指数中的平方和可以展开为 $\\sum_{i=1}^{n} (y_i - \\theta)^2 = \\sum_{i=1}^{n} (y_i - \\bar{y})^2 + n(\\bar{y} - \\theta)^2$。由于项 $\\sum (y_i - \\bar{y})^2$ 不依赖于 $\\theta$，它是一个比例常数。因此，作为 $\\theta$ 的函数，似然与以下表达式成正比：\n$$ L(\\theta \\mid \\bar{y}, n) \\propto \\exp\\left(-\\frac{n(\\bar{y} - \\theta)^2}{2\\sigma^2}\\right) $$\n$\\theta$ 的先验为 $\\theta \\sim \\mathcal{N}(\\mu_0, \\tau_0^2)$，所以先验密度与以下表达式成正比：\n$$ p(\\theta) \\propto \\exp\\left(-\\frac{(\\theta - \\mu_0)^2}{2\\tau_0^2}\\right) $$\n未归一化的后验 $\\pi(\\theta)$ 与这两个表达式的乘积成正比。对数后验在相差一个加性常数的情况下为：\n$$ \\log \\pi(\\theta) \\stackrel{c}{=} -\\frac{n(\\bar{y} - \\theta)^2}{2\\sigma^2} - \\frac{(\\theta - \\mu_0)^2}{2\\tau_0^2} $$\n将此函数记为 $\\text{log_target}(\\theta)$。对数接受率中的项 $\\log(\\pi(\\theta')) - \\log(\\pi(\\theta))$ 变为 $\\text{log_target}(\\theta') - \\text{log_target}(\\theta)$。\n\n**2. 提议密度与 Hastings 修正**\n\n我们分析指定的两种提议分布族，以确定 Hastings 修正项 $\\log(q(\\theta \\mid \\theta')) - \\log(q(\\theta' \\mid \\theta))$。\n\n**a. 随机游走正态提议分布**\n提议分布为 $q(\\theta' \\mid \\theta) = \\mathcal{N}(\\theta, s^2)$。忽略常数项，其对数提议密度为：\n$$ \\log q(\\theta' \\mid \\theta) \\stackrel{c}{=} -\\frac{(\\theta' - \\theta)^2}{2s^2} $$\n从 $\\theta'$ 到 $\\theta$ 的反向移动的密度为 $q(\\theta \\mid \\theta') = \\mathcal{N}(\\theta', s^2)$。其对数密度为：\n$$ \\log q(\\theta \\mid \\theta') \\stackrel{c}{=} -\\frac{(\\theta - \\theta')^2}{2s^2} $$\n由于 $(\\theta' - \\theta)^2 = (\\theta - \\theta')^2$，提议分布是对称的，即 $q(\\theta' \\mid \\theta) = q(\\theta \\mid \\theta')$。Hastings 修正项为 $\\log(1) = 0$。\n对数接受率简化为：\n$$ \\log R_{\\text{RW}} = \\text{log_target}(\\theta') - \\text{log_target}(\\theta) $$\n\n**b. 独立正态提议分布**\n提议分布为 $q(\\theta' \\mid \\theta) = \\mathcal{N}(\\mu_q, \\sigma_q^2)$，它不依赖于当前状态 $\\theta$。我们可以写成 $q(\\theta' \\mid \\theta) = q(\\theta')$。其对数提议密度为：\n$$ \\log q(\\theta' \\mid \\theta) = \\log q(\\theta') \\stackrel{c}{=} -\\frac{(\\theta' - \\mu_q)^2}{2\\sigma_q^2} $$\n反向提议密度为 $q(\\theta \\mid \\theta') = q(\\theta) = \\mathcal{N}(\\mu_q, \\sigma_q^2)$：\n$$ \\log q(\\theta \\mid \\theta') = \\log q(\\theta) \\stackrel{c}{=} -\\frac{(\\theta - \\mu_q)^2}{2\\sigma_q^2} $$\n对数 Hastings 修正为非零：\n$$ \\log\\left(\\frac{q(\\theta \\mid \\theta')}{q(\\theta' \\mid \\theta)}\\right) = \\log q(\\theta) - \\log q(\\theta') = \\left(-\\frac{(\\theta - \\mu_q)^2}{2\\sigma_q^2}\\right) - \\left(-\\frac{(\\theta' - \\mu_q)^2}{2\\sigma_q^2}\\right) = \\frac{(\\theta' - \\mu_q)^2 - (\\theta - \\mu_q)^2}{2\\sigma_q^2} $$\n完整的对数接受率为：\n$$ \\log R_{\\text{IND}} = (\\text{log_target}(\\theta') - \\text{log_target}(\\theta)) + \\frac{(\\theta' - \\mu_q)^2 - (\\theta - \\mu_q)^2}{2\\sigma_q^2} $$\n\n**3. 实现策略**\n\nPython 实现将定义一个函数，根据模型参数计算 $\\text{log_target}(\\theta)$。然后，它将遍历测试用例。对于每个用例，它将识别提议分布类型，并使用上面推导出的相应公式计算对数接受率 $\\log R$。最后，它将计算 $\\alpha = \\min(1, \\exp(\\log R))$ 并存储结果。\n\n特殊情况：对于用例 3，$\\theta = \\theta' = 0.7$。在这种情况下，$\\text{log_target}(\\theta') = \\text{log_target}(\\theta)$，并且无论提议分布族如何，Hastings 修正项的计算结果也为 0。因此，$\\log R = 0$，且 $\\alpha = \\min(1, \\exp(0)) = 1$。程序应能正确处理这种情况。\n对于用例 4，建议状态 $\\theta'=5.0$ 位于后验分布的尾部很远的位置，而后验分布集中在 $\\bar{y}=0.2$ 附近。这将导致一个很大的负值 $\\log R$ 和一个计算上为零的接受概率。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the Metropolis-Hastings acceptance probability for a Normal-Normal model\n    under two different proposal families for a series of test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            'case': 1, 'proposal_type': 'random_walk',\n            'params': {'y_bar': 1.2, 'n': 50, 'sigma2': 16, 'mu0': 0, 'tau02': 100},\n            'states': {'theta': 1.5, 'theta_prime': 1.8},\n            'proposal_params': {'s2': 0.25}\n        },\n        {\n            'case': 2, 'proposal_type': 'independence',\n            'params': {'y_bar': 8.4, 'n': 5, 'sigma2': 4, 'mu0': 10, 'tau02': 1},\n            'states': {'theta': 8, 'theta_prime': 6},\n            'proposal_params': {'mu_q': 9, 'sigma_q2': 9}\n        },\n        {\n            'case': 3, 'proposal_type': 'independence',\n            'params': {'y_bar': 0.3, 'n': 10, 'sigma2': 1, 'mu0': 0, 'tau02': 4},\n            'states': {'theta': 0.7, 'theta_prime': 0.7},\n            'proposal_params': {'mu_q': 0, 'sigma_q2': 9}\n        },\n        {\n            'case': 4, 'proposal_type': 'random_walk',\n            'params': {'y_bar': 0.2, 'n': 200, 'sigma2': 9, 'mu0': 0, 'tau02': 1000},\n            'states': {'theta': 0.1, 'theta_prime': 5.0},\n            'proposal_params': {'s2': 1.0}\n        },\n        {\n            'case': 5, 'proposal_type': 'independence',\n            'params': {'y_bar': 0.6, 'n': 5, 'sigma2': 1, 'mu0': 0, 'tau02': 10},\n            'states': {'theta': 0.0, 'theta_prime': 0.8},\n            'proposal_params': {'mu_q': 1.0, 'sigma_q2': 0.25}\n        }\n    ]\n\n    results = []\n\n    def log_target_density(theta, y_bar, n, sigma2, mu0, tau02):\n        \"\"\"\n        Computes the log of the unnormalized posterior density (likelihood * prior).\n        This is proportional to log(pi(theta)).\n        \"\"\"\n        log_likelihood = -n * (y_bar - theta)**2 / (2 * sigma2)\n        log_prior = -(theta - mu0)**2 / (2 * tau02)\n        return log_likelihood + log_prior\n\n    for case in test_cases:\n        params = case['params']\n        states = case['states']\n        proposal_params = case['proposal_params']\n        \n        theta = states['theta']\n        theta_prime = states['theta_prime']\n\n        # If current and proposed states are identical, acceptance probability is 1.\n        if theta == theta_prime:\n            results.append(1.0)\n            continue\n\n        # Calculate the log of the posterior ratio\n        log_pi_ratio = log_target_density(theta_prime, **params) - log_target_density(theta, **params)\n\n        log_hastings_correction = 0.0\n\n        if case['proposal_type'] == 'random_walk':\n            # For a symmetric random-walk proposal, q(theta|theta') = q(theta'|theta),\n            # so the Hastings correction is 1, and its log is 0.\n            pass  # log_hastings_correction is already 0.0\n\n        elif case['proposal_type'] == 'independence':\n            # For an independence sampler, q(theta'|theta) = q(theta'),\n            # so the Hastings correction is q(theta)/q(theta').\n            mu_q = proposal_params['mu_q']\n            sigma_q2 = proposal_params['sigma_q2']\n            \n            # log(q(theta)) - log(q(theta'))\n            # The constant terms cancel.\n            log_q_theta = -(theta - mu_q)**2 / (2 * sigma_q2)\n            log_q_theta_prime = -(theta_prime - mu_q)**2 / (2 * sigma_q2)\n\n            log_hastings_correction = log_q_theta - log_q_theta_prime\n\n        # Total log acceptance ratio\n        log_acceptance_ratio = log_pi_ratio + log_hastings_correction\n        \n        # Acceptance probability\n        alpha = min(1.0, np.exp(log_acceptance_ratio))\n        results.append(alpha)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```", "id": "4971664"}, {"introduction": "分层模型在医学统计中无处不在，常用于分析具有层级结构的数据（例如，不同医院内的患者）。然而，直接对这类模型进行参数估计，往往会导致MCMC采样器的混合（mixing）效率低下。这项高级实践 [@problem_id:3144797] 介绍了一种解决此问题的强大技术：非中心化重参数化。您将为一个分层模型实现并比较两种吉布斯采样器（Gibbs samplers），并量化重参数化在采样效率上带来的显著提升，这是任何应用统计学家都需掌握的专业技能。", "problem": "考虑一个分层正态模型，其中观测到的组级数据使用潜在的组均值和总体均值进行建模。目标是通过比较中心化参数化与非中心化参数化，分析重新参数化对马尔可夫链混合效果的影响，并量化总体均值参数自相关的差异。此比较必须在一个观测方差和组级方差已知的场景下，使用马尔可夫链蒙特卡洛（MCMC）方法，特别是吉布斯采样，来进行。\n\n基本原理：\n- 使用贝叶斯定理和正态-正态共轭性推导条件分布。\n- 使用马尔可夫链的定义和马尔可夫链蒙特卡洛（MCMC）的概念，其中构造链的转移使其目标后验分布为平稳分布。\n- 吉布斯采样是 MCMC 的一个特例，其中按顺序从每个变量的完全条件分布中进行采样。\n- 滞后为一的自相关定义为平稳时间序列连续样本之间的相关性。\n\n模型设定：\n- 对于每个组索引 $j \\in \\{1, \\dots, J\\}$，观测数据 $y_j$ 被建模为 $y_j \\mid \\mu_j \\sim \\mathcal{N}(\\mu_j, \\sigma^2)$，其中 $\\sigma^2$ 已知。\n- 潜在一组均值具有分层先验 $\\mu_j \\mid \\mu \\sim \\mathcal{N}(\\mu, \\tau^2)$，其中 $\\tau^2$ 已知。\n- 总体均值具有先验 $\\mu \\sim \\mathcal{N}(m_0, s_0^2)$，其中 $m_0$ 和 $s_0^2$ 已知。\n\n两种参数化：\n- 中心化参数化：直接使用 $\\mu$ 和 $\\{\\mu_j\\}_{j=1}^J$ 进行参数化。\n- 非中心化参数化：通过引入 $\\eta_j \\sim \\mathcal{N}(0,1)$ 并设置 $\\mu_j = \\mu + \\tau \\eta_j$ 进行重新参数化，从而使用 $\\mu$ 和 $\\{\\eta_j\\}_{j=1}^J$ 进行参数化。\n\n任务：\n- 根据贝叶斯定理和正态分布的性质，为两种参数化下的吉布斯采样推导所需的完全条件分布。不要使用快捷公式；从似然和先验的基本定义开始。\n- 实现分别对应于中心化和非中心化参数化的两个吉布斯采样器。\n- 对于每个采样器，收集总体均值 $\\mu$ 的样本，并为老化期后的 $\\mu$ 链计算滞后-1 自相关系数。对于时间序列 $\\{x_t\\}_{t=1}^N$，滞后-1 自相关定义为\n$$\n\\rho_1 = \\frac{\\sum_{t=1}^{N-1} (x_t - \\bar{x})(x_{t+1} - \\bar{x})}{\\sum_{t=1}^{N} (x_t - \\bar{x})^2},\n$$\n其中 $\\bar{x}$ 是 $\\{x_t\\}_{t=1}^N$ 的样本均值。\n- 通过为每个测试案例计算 $\\Delta = \\rho_{1,\\text{centered}} - \\rho_{1,\\text{non-centered}}$ 来量化自相关的差异。正的 $\\Delta$ 表示与非中心化参数化相比，中心化参数化具有更高的自相关，而负的 $\\Delta$ 表示相反情况。\n\n测试套件：\n使用以下案例，每个案例由 $(J, \\{y_j\\}_{j=1}^J, \\sigma, \\tau, m_0, s_0, N_{\\text{iter}}, N_{\\text{burn}}, \\text{seed})$ 指定，所有量都明确以数字形式给出。\n\n- 案例 1（弱数据，预期非中心化混合效果更好）：$J = 8$, $\\{y_j\\} = [5, 7, 3, -2, 0, 4, 6, 8]$, $\\sigma = 5$, $\\tau = 1$, $m_0 = 0$, $s_0 = 10$, $N_{\\text{iter}} = 10000$, $N_{\\text{burn}} = 2000$, $\\text{seed} = 123$。\n- 案例 2（强数据，预期中心化混合效果更好）：$J = 8$, $\\{y_j\\} = [5, 7, 3, -2, 0, 4, 6, 8]$, $\\sigma = 1$, $\\tau = 5$, $m_0 = 0$, $s_0 = 10$, $N_{\\text{iter}} = 10000$, $N_{\\text{burn}} = 2000$, $\\text{seed} = 456$。\n- 案例 3（单组边界情况）：$J = 1$, $\\{y_j\\} = [3]$, $\\sigma = 5$, $\\tau = 2$, $m_0 = 0$, $s_0 = 10$, $N_{\\text{iter}} = 10000$, $N_{\\text{burn}} = 2000$, $\\text{seed} = 789$。\n- 案例 4（多组，中等信息量）：$J = 50$，$y_j$ 由 $y_j = 0.3 \\times (j - 25.5)$ 确定性地定义，对于 $j = 1, \\dots, 50$，$\\sigma = 2$, $\\tau = 2$, $m_0 = 0$, $s_0 = 10$, $N_{\\text{iter}} = 10000$, $N_{\\text{burn}} = 2000$, $\\text{seed} = 987$。\n\n要求：\n- 实现两个吉布斯采样器，并为每个案例计算 $\\Delta$。\n- 使用提供的种子以确保确定性输出。\n- 此问题不涉及物理单位。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，按四个案例的顺序排列，例如 $[\\Delta_1,\\Delta_2,\\Delta_3,\\Delta_4]$。", "solution": "用户要求使用吉布斯采样来比较分层正态模型的中心化和非中心化参数化。主要目标是通过计算总体均值参数 $\\mu$ 的链的滞后-1 自相关，来分析马尔可夫链蒙特卡洛（MCMC）混合性质的差异。\n\n### 问题验证\n\n**步骤 1：提取已知条件**\n-   **模型：**\n    -   数据似然：$y_j \\mid \\mu_j \\sim \\mathcal{N}(\\mu_j, \\sigma^2)$ 对于 $j \\in \\{1, \\dots, J\\}$，$\\sigma^2$ 已知。\n    -   组均值的分层先验：$\\mu_j \\mid \\mu \\sim \\mathcal{N}(\\mu, \\tau^2)$，$\\tau^2$ 已知。\n    -   总体均值的先验：$\\mu \\sim \\mathcal{N}(m_0, s_0^2)$，其中 $m_0$ 和 $s_0^2$ 已知。\n-   **参数化：**\n    -   中心化：参数为 $\\mu$ 和 $\\{\\mu_j\\}_{j=1}^J$。\n    -   非中心化：通过 $\\eta_j \\sim \\mathcal{N}(0,1)$ 重新参数化，使得 $\\mu_j = \\mu + \\tau \\eta_j$。参数为 $\\mu$ 和 $\\{\\eta_j\\}_{j=1}^J$。\n-   **任务：**\n    1.  为两种参数化下的吉布斯采样推导完全条件分布。\n    2.  实现两个吉布斯采样器。\n    3.  为每个采样器计算 $\\mu$ 的老化期后链的滞后-1 自相关 $\\rho_1$。公式为 $\\rho_1 = \\frac{\\sum_{t=1}^{N-1} (x_t - \\bar{x})(x_{t+1} - \\bar{x})}{\\sum_{t=1}^{N} (x_t - \\bar{x})^2}$。\n    4.  为每个测试案例计算差异 $\\Delta = \\rho_{1,\\text{centered}} - \\rho_{1,\\text{non-centered}}$。\n-   **测试套件：**\n    -   案例 1：$(J, \\{y_j\\}, \\sigma, \\tau, m_0, s_0, N_{\\text{iter}}, N_{\\text{burn}}, \\text{seed}) = (8, [5, 7, 3, -2, 0, 4, 6, 8], 5, 1, 0, 10, 10000, 2000, 123)$。\n    -   案例 2：$(J, \\{y_j\\}, \\sigma, \\tau, m_0, s_0, N_{\\text{iter}}, N_{\\text{burn}}, \\text{seed}) = (8, [5, 7, 3, -2, 0, 4, 6, 8], 1, 5, 0, 10, 10000, 2000, 456)$。\n    -   案例 3：$(J, \\{y_j\\}, \\sigma, \\tau, m_0, s_0, N_{\\text{iter}}, N_{\\text{burn}}, \\text{seed}) = (1, [3], 5, 2, 0, 10, 10000, 2000, 789)$。\n    -   案例 4：$(J, \\{y_j\\}, \\sigma, \\tau, m_0, s_0, N_{\\text{iter}}, N_{\\text{burn}}, \\text{seed}) = (50, \\{0.3 \\times (j - 25.5)\\}_{j=1}^{50}, 2, 2, 0, 10, 10000, 2000, 987)$。\n\n**步骤 2：使用提取的已知条件进行验证**\n该问题具有科学依据、定义明确且客观。这是计算贝叶斯统计中的一个标准练习，重点关注 MCMC 的效率。\n-   **科学依据**：分层正态模型、吉布斯采样以及为改善混合而进行的重新参数化是贝叶斯统计和统计学习中的基本主题。所有模型和公式都基于已建立的概率论和统计学。\n-   **定义明确性**：该问题提供了所有必要的数据、参数和一个确定性程序（包括随机种子），以便为每个测试案例得出唯一、有意义的数值结果。\n-   **客观性**：语言精确且技术性强。没有主观因素。\n\n**步骤 3：结论与行动**\n问题有效。将提供一个完整的解决方案。\n\n### 完全条件分布的推导\n\n吉布斯采样器的核心是为每个参数从其完全条件分布中迭代抽取样本，该分布是该参数在所有其他参数和数据条件下的分布。我们使用贝叶斯定理为两种参数化推导这些分布，该定理指出后验概率正比于似然乘以先验，即 $p(\\theta|D) \\propto p(D|\\theta)p(\\theta)$。\n\n#### 1. 中心化参数化\n\n参数为 $\\theta_C = (\\mu, \\mu_1, \\dots, \\mu_J)$。联合后验分布为：\n$$p(\\mu, \\{\\mu_j\\}_{j=1}^J | \\{y_j\\}_{j=1}^J) \\propto p(\\{y_j\\} | \\{\\mu_j\\}) p(\\{\\mu_j\\} | \\mu) p(\\mu)$$\n$$p(\\mu, \\{\\mu_j\\} | \\{y_j\\}) \\propto \\left( \\prod_{j=1}^J \\mathcal{N}(y_j | \\mu_j, \\sigma^2) \\right) \\left( \\prod_{j=1}^J \\mathcal{N}(\\mu_j | \\mu, \\tau^2) \\right) \\mathcal{N}(\\mu | m_0, s_0^2)$$\n\n**$\\mu$ 的完全条件分布：**\n$\\mu$ 在所有其他参数条件下的分布仅取决于它在图形模型中作为父节点的那些参数，即 $\\{\\mu_j\\}$。\n$$p(\\mu | \\{\\mu_j\\}, \\{y_j\\}) \\propto p(\\mu | \\{\\mu_j\\}) \\propto p(\\{\\mu_j\\} | \\mu) p(\\mu)$$\n$$p(\\mu | \\{\\mu_j\\}) \\propto \\left( \\prod_{j=1}^J \\mathcal{N}(\\mu_j | \\mu, \\tau^2) \\right) \\mathcal{N}(\\mu | m_0, s_0^2)$$\n$$p(\\mu | \\{\\mu_j\\}) \\propto \\exp\\left( -\\frac{1}{2\\tau^2} \\sum_{j=1}^J (\\mu_j - \\mu)^2 \\right) \\exp\\left( -\\frac{1}{2s_0^2} (\\mu - m_0)^2 \\right)$$\n展开指数中关于 $\\mu$ 的二次项：\n$$-\\frac{1}{2}\\left[ \\mu^2 \\left(\\frac{J}{\\tau^2} + \\frac{1}{s_0^2}\\right) - 2\\mu \\left(\\frac{1}{\\tau^2}\\sum_{j=1}^J \\mu_j + \\frac{m_0}{s_0^2}\\right) + \\text{const} \\right]$$\n这是正态分布 $\\mathcal{N}(\\mu | M_{\\mu}, V_{\\mu})$ 的核。通过配方法或匹配项，我们找到后验方差 $V_{\\mu}$ 和均值 $M_{\\mu}$：\n$$V_{\\mu} = \\left(\\frac{J}{\\tau^2} + \\frac{1}{s_0^2}\\right)^{-1}$$\n$$M_{\\mu} = V_{\\mu} \\left(\\frac{\\sum_{j=1}^J \\mu_j}{\\tau^2} + \\frac{m_0}{s_0^2}\\right)$$\n因此，完全条件分布是 $\\mu | \\{\\mu_j\\} \\sim \\mathcal{N}(M_{\\mu}, V_{\\mu})$。\n\n**$\\mu_j$ 的完全条件分布：**\n由于模型中的条件独立性，$\\mu_j$ 的完全条件分布仅取决于 $y_j$ 和 $\\mu$。\n$$p(\\mu_j | \\mu, \\{\\mu_{k \\neq j}\\}, \\{y_k\\}) \\propto p(y_j | \\mu_j) p(\\mu_j | \\mu)$$\n$$p(\\mu_j | \\mu, y_j) \\propto \\mathcal{N}(y_j|\\mu_j, \\sigma^2) \\mathcal{N}(\\mu_j|\\mu, \\tau^2)$$\n$$p(\\mu_j | \\mu, y_j) \\propto \\exp\\left( -\\frac{(y_j - \\mu_j)^2}{2\\sigma^2} \\right) \\exp\\left( -\\frac{(\\mu_j - \\mu)^2}{2\\tau^2} \\right)$$\n展开指数中关于 $\\mu_j$ 的二次项：\n$$-\\frac{1}{2}\\left[ \\mu_j^2 \\left(\\frac{1}{\\sigma^2} + \\frac{1}{\\tau^2}\\right) - 2\\mu_j \\left(\\frac{y_j}{\\sigma^2} + \\frac{\\mu}{\\tau^2}\\right) + \\text{const} \\right]$$\n这是方差为 $V_j$、均值为 $M_j$ 的正态分布 $\\mathcal{N}(\\mu_j | M_j, V_j)$ 的核：\n$$V_j = \\left(\\frac{1}{\\sigma^2} + \\frac{1}{\\tau^2}\\right)^{-1}$$\n$$M_j = V_j \\left(\\frac{y_j}{\\sigma^2} + \\frac{\\mu}{\\tau^2}\\right)$$\n对于每个 $j \\in \\{1, \\dots, J\\}$，其完全条件分布是 $\\mu_j | \\mu, y_j \\sim \\mathcal{N}(M_j, V_j)$。\n\n#### 2. 非中心化参数化\n\n参数为 $\\theta_{NC} = (\\mu, \\eta_1, \\dots, \\eta_J)$，映射关系为 $\\mu_j = \\mu + \\tau \\eta_j$。现在的似然是 $y_j | \\mu, \\eta_j \\sim \\mathcal{N}(\\mu + \\tau\\eta_j, \\sigma^2)$。先验是 $\\eta_j \\sim \\mathcal{N}(0, 1)$ 和 $\\mu \\sim \\mathcal{N}(m_0, s_0^2)$。联合后验是：\n$$p(\\mu, \\{\\eta_j\\} | \\{y_j\\}) \\propto \\left( \\prod_{j=1}^J \\mathcal{N}(y_j | \\mu + \\tau\\eta_j, \\sigma^2) \\right) \\left( \\prod_{j=1}^J \\mathcal{N}(\\eta_j | 0, 1) \\right) \\mathcal{N}(\\mu | m_0, s_0^2)$$\n\n**$\\mu$ 的完全条件分布：**\n$$p(\\mu | \\{\\eta_j\\}, \\{y_j\\}) \\propto \\left( \\prod_{j=1}^J \\mathcal{N}(y_j | \\mu + \\tau\\eta_j, \\sigma^2) \\right) \\mathcal{N}(\\mu | m_0, s_0^2)$$\n$$p(\\mu | \\{\\eta_j\\}, \\{y_j\\}) \\propto \\exp\\left( -\\frac{1}{2\\sigma^2} \\sum_{j=1}^J (y_j - \\tau\\eta_j - \\mu)^2 \\right) \\exp\\left( -\\frac{(\\mu - m_0)^2}{2s_0^2} \\right)$$\n这是一个标准正态-正态共轭更新，我们有 $J$ 个观测值 $y'_j = y_j - \\tau\\eta_j$，每个观测值的均值为 $\\mu$，方差为已知的 $\\sigma^2$。$\\mu$ 的完全条件分布是 $\\mathcal{N}(\\mu | M_{\\mu, nc}, V_{\\mu, nc})$，其中：\n$$V_{\\mu, nc} = \\left(\\frac{J}{\\sigma^2} + \\frac{1}{s_0^2}\\right)^{-1}$$\n$$M_{\\mu, nc} = V_{\\mu, nc} \\left(\\frac{\\sum_{j=1}^J (y_j - \\tau\\eta_j)}{\\sigma^2} + \\frac{m_0}{s_0^2}\\right)$$\n\n**$\\eta_j$ 的完全条件分布：**\n$$p(\\eta_j | \\mu, \\{\\eta_{k \\neq j}\\}, \\{y_k\\}) \\propto p(y_j | \\mu, \\eta_j) p(\\eta_j)$$\n$$p(\\eta_j | \\mu, y_j) \\propto \\mathcal{N}(y_j|\\mu + \\tau\\eta_j, \\sigma^2) \\mathcal{N}(\\eta_j|0, 1)$$\n$$p(\\eta_j | \\mu, y_j) \\propto \\exp\\left( -\\frac{(y_j - \\mu - \\tau\\eta_j)^2}{2\\sigma^2} \\right) \\exp\\left( -\\frac{\\eta_j^2}{2} \\right)$$\n展开指数中关于 $\\eta_j$ 的二次项：\n$$-\\frac{1}{2}\\left[ \\eta_j^2 \\left(\\frac{\\tau^2}{\\sigma^2} + 1\\right) - 2\\eta_j \\frac{\\tau(y_j - \\mu)}{\\sigma^2} + \\text{const} \\right]$$\n这是正态分布 $\\mathcal{N}(\\eta_j | M_{\\eta_j}, V_{\\eta_j})$ 的核，其中：\n$$V_{\\eta_j} = \\left(\\frac{\\tau^2}{\\sigma^2} + 1\\right)^{-1}$$\n$$M_{\\eta_j} = V_{\\eta_j} \\left(\\frac{\\tau(y_j - \\mu)}{\\sigma^2}\\right)$$\n对于每个 $j \\in \\{1, \\dots, J\\}$，其完全条件分布是 $\\eta_j | \\mu, y_j \\sim \\mathcal{N}(M_{\\eta_j}, V_{\\eta_j})$。\n\n### MCMC 性能与实现\n\n这两种参数化在数学上是等价的，但可能具有截然不同的计算特性。\n-   **中心化参数化：**参数 $\\mu$ 和 $\\{\\mu_j\\}$ 在后验分布中通常高度相关，尤其是在数据稀疏（$\\sigma^2$ 大）且分层方差小（$\\tau^2$ 小）的情况下。这种依赖性意味着 $\\mu$ 的一次抽样会强烈约束后续对 $\\{\\mu_j\\}$ 的抽样，反之亦然。这种“粘性”导致吉布斯采样器在参数空间中移动缓慢，从而导致连续样本之间的高自相关。\n-   **非中心化参数化：**该方法旨在通过对 $\\mu$ 和一组独立的标准正态参数 $\\{\\eta_j\\}$进行采样来打破后验依赖性。依赖关系从先验转移到了似然中。这通常会减少被采样的参数块之间的后验相关性，从而导致更快的混合和更低的自相关，尤其是在上述稀疏数据场景中。\n-   相反，当数据信息丰富（$\\sigma^2$ 小）时，中心化参数化可能表现良好，因为每个 $y_j$ 的似然能精确地识别 $\\mu_j$，从而减少其对 $\\mu$ 的依赖。非中心化参数化在这种情况下可能会遇到困难，因为强约束 $y_j \\approx \\mu + \\tau\\eta_j$ 可能会在 $\\mu$ 和 $\\eta_j$ 之间引入高的后验相关性。\n\n实现将包括两个吉布斯采样器函数，每种参数化各一个。每个函数将从推导出的完全条件分布中迭代采样 $N_{\\text{iter}}$ 步。在丢弃前 $N_{\\text{burn}}$ 个样本（老化期）后，将计算 $\\mu$ 链的滞后-1 自相关。每个测试用例的最终结果是两个采样器自相关之间的差异 $\\Delta$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_autocorr_lag1(chain):\n    \"\"\"\n    Computes the lag-1 autocorrelation for a given MCMC chain.\n    \"\"\"\n    if len(chain)  2:\n        return np.nan\n    \n    x_bar = np.mean(chain)\n    dev = chain - x_bar\n    denominator = np.dot(dev, dev)\n    \n    if denominator == 0:\n        return 0.0\n        \n    numerator = np.dot(dev[:-1], dev[1:])\n    return numerator / denominator\n\ndef gibbs_centered(J, y, sigma, tau, m0, s0, N_iter, N_burn, seed):\n    \"\"\"\n    Gibbs sampler for the centered parameterization.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    y = np.array(y)\n    \n    sigma2 = sigma**2\n    tau2 = tau**2\n    s02 = s0**2\n    \n    # Initialize parameters\n    mu = float(m0)\n    mu_j = np.copy(y)\n    \n    mu_samples = np.zeros(N_iter)\n    \n    # Pre-compute conditional posterior variances (constant throughout sampling)\n    V_j = 1.0 / (1.0/sigma2 + 1.0/tau2)\n    V_mu = 1.0 / (J/tau2 + 1.0/s02)\n    \n    std_j = np.sqrt(V_j)\n    std_mu = np.sqrt(V_mu)\n\n    # Gibbs sampling loop\n    for i in range(N_iter):\n        # Update mu (population mean)\n        M_mu = V_mu * (np.sum(mu_j)/tau2 + m0/s02)\n        mu = rng.normal(loc=M_mu, scale=std_mu)\n        mu_samples[i] = mu\n\n        # Update mu_j (group means)\n        M_j = V_j * (y/sigma2 + mu/tau2)\n        mu_j = rng.normal(loc=M_j, scale=std_j)\n        \n    post_burn_in_samples = mu_samples[N_burn:]\n    return calculate_autocorr_lag1(post_burn_in_samples)\n\ndef gibbs_non_centered(J, y, sigma, tau, m0, s0, N_iter, N_burn, seed):\n    \"\"\"\n    Gibbs sampler for the non-centered parameterization.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    y = np.array(y)\n    \n    sigma2 = sigma**2\n    tau2 = tau**2\n    s02 = s0**2\n    \n    # Initialize parameters\n    mu = float(m0)\n    eta_j = np.zeros(J)\n    \n    mu_samples = np.zeros(N_iter)\n\n    # Pre-compute conditional posterior variances (constant throughout sampling)\n    V_mu_nc = 1.0 / (J/sigma2 + 1.0/s02)\n    V_eta_j = 1.0 / (tau2/sigma2 + 1.0)\n    \n    std_mu_nc = np.sqrt(V_mu_nc)\n    std_eta_j = np.sqrt(V_eta_j)\n\n    # Gibbs sampling loop\n    for i in range(N_iter):\n        # Update mu\n        M_mu_nc = V_mu_nc * (np.sum(y - tau * eta_j)/sigma2 + m0/s02)\n        mu = rng.normal(loc=M_mu_nc, scale=std_mu_nc)\n        mu_samples[i] = mu\n\n        # Update eta_j\n        M_eta_j = V_eta_j * (tau * (y - mu) / sigma2)\n        eta_j = rng.normal(loc=M_eta_j, scale=std_eta_j)\n        \n    post_burn_in_samples = mu_samples[N_burn:]\n    return calculate_autocorr_lag1(post_burn_in_samples)\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and compute the difference in autocorrelation.\n    \"\"\"\n    y_case4 = [0.3 * (j - 25.5) for j in range(1, 51)]\n\n    test_cases = [\n        # (J, {y_j}, sigma, tau, m0, s0, N_iter, N_burn, seed)\n        (8, [5, 7, 3, -2, 0, 4, 6, 8], 5, 1, 0, 10, 10000, 2000, 123),\n        (8, [5, 7, 3, -2, 0, 4, 6, 8], 1, 5, 0, 10, 10000, 2000, 456),\n        (1, [3], 5, 2, 0, 10, 10000, 2000, 789),\n        (50, y_case4, 2, 2, 0, 10, 10000, 2000, 987),\n    ]\n\n    results = []\n    for case in test_cases:\n        J, y, sigma, tau, m0, s0, N_iter, N_burn, seed = case\n        \n        # Run centered sampler\n        rho_centered = gibbs_centered(J, y, sigma, tau, m0, s0, N_iter, N_burn, seed)\n        \n        # Run non-centered sampler\n        rho_non_centered = gibbs_non_centered(J, y, sigma, tau, m0, s0, N_iter, N_burn, seed)\n        \n        # Compute the difference\n        delta_rho = rho_centered - rho_non_centered\n        results.append(delta_rho)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3144797"}]}