{"hands_on_practices": [{"introduction": "要真正掌握LASSO，理解其系数是如何在计算层面被估计出来的至关重要。坐标下降法为此提供了一个非常直观且高效的算法框架，它通过逐一优化单个系数同时固定其他系数的方式，迭代地逼近最优解。这项练习将带领你手动执行一轮完整的坐标下降更新 ([@problem_id:4990069])，通过这个过程，你将能亲手揭示LASSO优化背后的核心机制——软阈值操作，并深刻理解惩罚项是如何将不重要的系数“压缩”至零的。", "problem": "一位临床研究员正在研究一个由 $n=6$ 名患者组成的队列中的连续结果，该结果代表标准化的收缩压残差。研究收集了三个候选预测变量 $p=3$（标准化的实验室生物标志物）。设设计矩阵 $X \\in \\mathbb{R}^{6 \\times 3}$ 的各列已标准化，使得每列的均值为 $0$ 且对于 $j \\in \\{1,2,3\\}$ 满足 $(1/n)\\sum_{i=1}^{n} x_{ij}^{2} = 1$，并设响应向量 $y \\in \\mathbb{R}^{6}$ 已中心化至均值为 $0$。考虑最小绝对收缩和选择算子 (LASSO) 回归，它通过最小化带有平方损失和 $\\ell_{1}$ 惩罚项的惩罚平方误差目标函数来估计系数 $\\beta \\in \\mathbb{R}^{3}$。\n\n给定\n$$\nX = \n\\begin{pmatrix}\n1  1  1 \\\\\n1  -1  1 \\\\\n1  1  -1 \\\\\n-1  -1  -1 \\\\\n-1  1  1 \\\\\n-1  -1  -1\n\\end{pmatrix}, \n\\qquad\ny = \n\\begin{pmatrix}\n4 \\\\ 2 \\\\ 4 \\\\ -2 \\\\ -4 \\\\ -4\n\\end{pmatrix},\n\\qquad\n\\lambda = \\frac{3}{2}.\n$$\n验证 $X$ 的每一列均值为 $0$ 且 $(1/n)\\sum_{i=1}^{n} x_{ij}^{2} = 1$，并且 $y$ 的均值为 $0$。从中心化响应和标准化预测变量的线性回归的 LASSO 目标函数的核心定义出发，从初始系数向量 $\\beta^{(0)} = (0,0,0)$ 开始，对 $j=1,2,3$ 执行一轮完整的循环坐标下降。在每个坐标上，从第一性原理出发推导逐坐标更新法则，然后手动精确计算更新后的系数。\n\n将这一轮之后最终更新的系数向量以 $1 \\times 3$ 行向量的形式表示为精确有理数，不进行四舍五入。无需单位。", "solution": "该问题是适定的，有科学依据，并提供了进行求解所需的所有信息。首先，我们验证问题中陈述的前提条件。\n\n患者数量为 $n=6$。预测变量数量为 $p=3$。\n设计矩阵 $X$ 和响应向量 $y$ 如下所示：\n$$\nX = \n\\begin{pmatrix}\n1  1  1 \\\\\n1  -1  1 \\\\\n1  1  -1 \\\\\n-1  -1  -1 \\\\\n-1  1  1 \\\\\n-1  -1  -1\n\\end{pmatrix}, \n\\qquad\ny = \n\\begin{pmatrix}\n4 \\\\ 2 \\\\ 4 \\\\ -2 \\\\ -4 \\\\ -4\n\\end{pmatrix}\n$$\n\n验证 $X$ 的列均值：\n对于 $j=1$: $\\sum_{i=1}^{6} x_{i1} = 1 + 1 + 1 - 1 - 1 - 1 = 0$。均值为 $\\frac{0}{6} = 0$。\n对于 $j=2$: $\\sum_{i=1}^{6} x_{i2} = 1 - 1 + 1 - 1 + 1 - 1 = 0$。均值为 $\\frac{0}{6} = 0$。\n对于 $j=3$: $\\sum_{i=1}^{6} x_{i3} = 1 + 1 - 1 - 1 + 1 - 1 = 0$。均值为 $\\frac{0}{6} = 0$。\n\n验证 $X$ 的列标准化：\n对于 $j=1$: $\\frac{1}{n}\\sum_{i=1}^{6} x_{i1}^{2} = \\frac{1}{6}(1^2 + 1^2 + 1^2 + (-1)^2 + (-1)^2 + (-1)^2) = \\frac{6}{6} = 1$。\n对于 $j=2$: $\\frac{1}{n}\\sum_{i=1}^{6} x_{i2}^{2} = \\frac{1}{6}(1^2 + (-1)^2 + 1^2 + (-1)^2 + 1^2 + (-1)^2) = \\frac{6}{6} = 1$。\n对于 $j=3$: $\\frac{1}{n}\\sum_{i=1}^{6} x_{i3}^{2} = \\frac{1}{6}(1^2 + 1^2 + (-1)^2 + (-1)^2 + 1^2 + (-1)^2) = \\frac{6}{6} = 1$。\n\n验证 $y$ 的均值：\n$\\sum_{i=1}^{6} y_i = 4 + 2 + 4 - 2 - 4 - 4 = 0$。均值为 $\\frac{0}{6} = 0$。\n所有初始条件均已验证。\n\n对于标准化预测变量和中心化响应，LASSO 目标函数为：\n$$\nL(\\beta) = \\frac{1}{2n} \\sum_{i=1}^{n} \\left(y_i - \\sum_{k=1}^{p} x_{ik}\\beta_k\\right)^2 + \\lambda \\sum_{j=1}^{p} |\\beta_j|\n$$\n坐标下降法每次针对单个系数 $\\beta_j$ 优化目标函数，同时保持所有其他系数 $\\beta_k$ (对于 $k \\neq j$) 固定。\n让我们分离出 $L(\\beta)$ 中依赖于 $\\beta_j$ 的项：\n$$\nL(\\beta_j) = \\frac{1}{2n} \\sum_{i=1}^{n} \\left(y_i - \\sum_{k \\neq j} x_{ik}\\beta_k - x_{ij}\\beta_j\\right)^2 + \\lambda |\\beta_j| + \\text{const}\n$$\n定义偏残差 $r_{i,(-j)} = y_i - \\sum_{k \\neq j} x_{ik}\\beta_k$。需要关于 $\\beta_j$ 最小化的表达式变为：\n$$\nf(\\beta_j) = \\frac{1}{2n} \\sum_{i=1}^{n} (r_{i,(-j)} - x_{ij}\\beta_j)^2 + \\lambda |\\beta_j|\n$$\n展开平方项：\n$$\nf(\\beta_j) = \\frac{1}{2n} \\left( \\sum_{i=1}^{n} r_{i,(-j)}^2 - 2\\beta_j \\sum_{i=1}^{n} r_{i,(-j)}x_{ij} + \\beta_j^2 \\sum_{i=1}^{n} x_{ij}^2 \\right) + \\lambda |\\beta_j|\n$$\n使用标准化性质 $\\sum_{i=1}^{n} x_{ij}^2 = n$：\n$$\nf(\\beta_j) = \\frac{1}{2n} \\left( C - 2\\beta_j \\sum_{i=1}^{n} r_{i,(-j)}x_{ij} + n\\beta_j^2 \\right) + \\lambda |\\beta_j|\n$$\n其中 $C$ 是一个关于 $\\beta_j$ 的常数。忽略常数项，我们要最小化：\n$$\ng(\\beta_j) = \\frac{1}{2}\\beta_j^2 - \\left(\\frac{1}{n} \\sum_{i=1}^{n} r_{i,(-j)}x_{ij}\\right) \\beta_j + \\lambda |\\beta_j|\n$$\n设 $S_j = \\frac{1}{n} \\sum_{i=1}^{n} r_{i,(-j)}x_{ij} = \\frac{1}{n}X_j^T r_{(-j)}$，其中 $X_j$ 是 $X$ 的第 $j$ 列。我们最小化 $g(\\beta_j) = \\frac{1}{2}\\beta_j^2 - S_j \\beta_j + \\lambda |\\beta_j|$。\n这是一个凸函数。我们通过将其次梯度设为零来找到最小值。次梯度 $\\partial g(\\beta_j)$ 为：\n$$\n\\partial g(\\beta_j) = \\beta_j - S_j + \\lambda \\cdot \\partial|\\beta_j|\n$$\n其中，如果 $\\beta_j \\neq 0$，$\\partial|\\beta_j|$ 为 $\\text{sgn}(\\beta_j)$；如果 $\\beta_j = 0$，则为区间 $[-1, 1]$。\n将次梯度设为 $0$：\n1.  如果 $\\beta_j > 0$：$\\beta_j - S_j + \\lambda = 0 \\implies \\hat{\\beta}_j = S_j - \\lambda$。仅当 $S_j - \\lambda > 0$ 时有效，即 $S_j > \\lambda$。\n2.  如果 $\\beta_j  0$：$\\beta_j - S_j - \\lambda = 0 \\implies \\hat{\\beta}_j = S_j + \\lambda$。仅当 $S_j + \\lambda  0$ 时有效，即 $S_j  -\\lambda$。\n3.  如果 $\\hat{\\beta}_j = 0$：$0 - S_j + \\lambda \\cdot [-1, 1] = 0 \\implies S_j \\in [-\\lambda, \\lambda]$，即 $|S_j| \\le \\lambda$。\n\n这三种情况定义了软阈值函数：\n$$\n\\hat{\\beta}_j = \\text{ST}(S_j, \\lambda) = \\text{sgn}(S_j) \\max(0, |S_j| - \\lambda)\n$$\n给定 $\\lambda = \\frac{3}{2}$，我们从 $\\beta^{(0)} = (0, 0, 0)^T$ 开始。\n\n**坐标 1：更新 $\\beta_1$**\n我们在 $\\beta_2=0$ 和 $\\beta_3=0$ 的条件下更新 $\\beta_1$。偏残差为 $r_{(-1)} = y - X_2\\beta_2^{(0)} - X_3\\beta_3^{(0)} = y$。\n我们计算 $S_1 = \\frac{1}{n} \\sum_{i=1}^n x_{i1}y_i = \\frac{1}{n}X_1^T y$。\n$$\nX_1^T y = 1(4) + 1(2) + 1(4) + (-1)(-2) + (-1)(-4) + (-1)(-4) = 4 + 2 + 4 + 2 + 4 + 4 = 20\n$$\n$$\nS_1 = \\frac{20}{6} = \\frac{10}{3}\n$$\n我们有 $\\lambda = \\frac{3}{2}$。由于 $S_1 = \\frac{10}{3} > \\frac{3}{2}$（因为 $\\frac{20}{6} > \\frac{9}{6}$），我们使用更新法则 $\\hat{\\beta}_1 = S_1 - \\lambda$。\n$$\n\\beta_1^{(1)} = \\frac{10}{3} - \\frac{3}{2} = \\frac{20 - 9}{6} = \\frac{11}{6}\n$$\n当前系数向量为 $\\beta = (\\frac{11}{6}, 0, 0)^T$。\n\n**坐标 2：更新 $\\beta_2$**\n我们在 $\\beta_1 = \\beta_1^{(1)} = \\frac{11}{6}$ 和 $\\beta_3 = \\beta_3^{(0)} = 0$ 的条件下更新 $\\beta_2$。\n偏残差为 $r_{(-2)} = y - X_1\\beta_1^{(1)} - X_3\\beta_3^{(0)} = y - X_1\\frac{11}{6}$。\n我们计算 $S_2 = \\frac{1}{n}X_2^T r_{(-2)} = \\frac{1}{n}X_2^T(y - X_1\\frac{11}{6}) = \\frac{1}{n}X_2^T y - \\frac{1}{n}(X_2^T X_1)\\beta_1^{(1)}$。\n首先，我们计算必要的内积：\n$$\nX_2^T y = 1(4) + (-1)(2) + 1(4) + (-1)(-2) + 1(-4) + (-1)(-4) = 4 - 2 + 4 + 2 - 4 + 4 = 8\n$$\n$$\nX_2^T X_1 = 1(1) + (-1)(1) + 1(1) + (-1)(-1) + 1(-1) + (-1)(-1) = 1 - 1 + 1 + 1 - 1 + 1 = 2\n$$\n现在，我们计算 $S_2$：\n$$\nS_2 = \\frac{8}{6} - \\frac{2}{6} \\cdot \\frac{11}{6} = \\frac{4}{3} - \\frac{1}{3} \\cdot \\frac{11}{6} = \\frac{4}{3} - \\frac{11}{18} = \\frac{24 - 11}{18} = \\frac{13}{18}\n$$\n我们将 $|S_2| = \\frac{13}{18}$ 与 $\\lambda = \\frac{3}{2} = \\frac{27}{18}$ 进行比较。由于 $|S_2| \\le \\lambda$，更新值为 $\\hat{\\beta}_2 = 0$。\n$$\n\\beta_2^{(1)} = 0\n$$\n当前系数向量为 $\\beta = (\\frac{11}{6}, 0, 0)^T$。\n\n**坐标 3：更新 $\\beta_3$**\n我们在 $\\beta_1 = \\beta_1^{(1)} = \\frac{11}{6}$ 和 $\\beta_2 = \\beta_2^{(1)} = 0$ 的条件下更新 $\\beta_3$。\n偏残差为 $r_{(-3)} = y - X_1\\beta_1^{(1)} - X_2\\beta_2^{(1)} = y - X_1\\frac{11}{6}$。\n我们计算 $S_3 = \\frac{1}{n}X_3^T r_{(-3)} = \\frac{1}{n}X_3^T y - \\frac{1}{n}(X_3^T X_1)\\beta_1^{(1)} - \\frac{1}{n}(X_3^T X_2)\\beta_2^{(1)}$。\n由于 $\\beta_2^{(1)}=0$，该式简化为 $S_3 = \\frac{1}{n}X_3^T y - \\frac{1}{n}(X_3^T X_1)\\beta_1^{(1)}$。\n首先，我们计算必要的内积：\n$$\nX_3^T y = 1(4) + 1(2) + (-1)(4) + (-1)(-2) + 1(-4) + (-1)(-4) = 4 + 2 - 4 + 2 - 4 + 4 = 4\n$$\n$$\nX_3^T X_1 = 1(1) + 1(1) + (-1)(1) + (-1)(-1) + 1(-1) + (-1)(-1) = 1 + 1 - 1 + 1 - 1 + 1 = 2\n$$\n现在，我们计算 $S_3$：\n$$\nS_3 = \\frac{4}{6} - \\frac{2}{6} \\cdot \\frac{11}{6} = \\frac{2}{3} - \\frac{1}{3} \\cdot \\frac{11}{6} = \\frac{2}{3} - \\frac{11}{18} = \\frac{12 - 11}{18} = \\frac{1}{18}\n$$\n我们将 $|S_3| = \\frac{1}{18}$ 与 $\\lambda = \\frac{3}{2} = \\frac{27}{18}$ 进行比较。由于 $|S_3| \\le \\lambda$，更新值为 $\\hat{\\beta}_3 = 0$。\n$$\n\\beta_3^{(1)} = 0\n$$\n经过一轮完整的循环，更新后的系数向量为 $\\beta^{(1)} = (\\beta_1^{(1)}, \\beta_2^{(1)}, \\beta_3^{(1)}) = (\\frac{11}{6}, 0, 0)$。\n\n以 $1 \\times 3$ 行向量的形式，最终答案是 $(\\frac{11}{6} \\quad 0 \\quad 0)$。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{11}{6}  0  0\n\\end{pmatrix}\n}\n$$", "id": "4990069"}, {"introduction": "在实际应用中，我们通常不会只求解单个$\\lambda$值下的LASSO模型，而是通过计算一个“正则化路径”来考察模型在一系列$\\lambda$值下的表现。这个路径的起点，$\\lambda_{\\max}$，是一个特殊的阈值，高于此值的所有系数都将被精确地缩减为零。这项练习将指导你从LASSO的KKT最优性条件出发，推导出$\\lambda_{\\max}$的表达式并进行计算 ([@problem_id:4990123])，同时还将探讨如何构建一个合理的$\\lambda$网格，特别是解释为什么在变量刚刚进入模型的“活跃”区域加密网格点，对于理解变量选择过程和模型构建至关重要。", "problem": "一个临床研究团队正在一个成人患者队列中，使用最小绝对收缩和选择算子 (LASSO) 为一个连续生物标志物构建一个稀疏线性风险模型。设数据由响应向量 $y \\in \\mathbb{R}^{n}$ 和设计矩阵 $X \\in \\mathbb{R}^{n \\times p}$ 表示，其中 $n = 800$ 且 $p = 6$。矩阵 $X$ 的列被中心化和标准化，使其欧几里得范数为 $\\sqrt{n}$，响应 $y$ 也被中心化。该团队通过最小化以下目标函数来拟合 LASSO：\n$$\n\\frac{1}{2n}\\|y - X\\beta\\|_{2}^{2} + \\lambda \\|\\beta\\|_{1},\n$$\n其中 $\\beta \\in \\mathbb{R}^{p}$ 且 $\\lambda \\ge 0$。\n\n从电子健康记录提取的数据中，团队计算出经验内积为：\n$$\n\\frac{1}{n}X^{\\top}y = \\begin{pmatrix}0.238 \\\\ -0.411 \\\\ 0.527 \\\\ 0.105 \\\\ -0.367 \\\\ 0.492\\end{pmatrix}.\n$$\n\n从 LASSO 的一阶最优性条件（Karush–Kuhn–Tucker (KKT) 条件）出发，推导出一个表达式，用于计算使得零向量 $\\hat{\\beta}(\\lambda_{\\max}) = 0$ 成为最优解的最小正则化值 $\\lambda_{\\max}$。然后，使用提供的经验内积，计算 $\\lambda_{\\max}$ 的数值。\n\n接下来，构建一个包含 $K = 100$ 个正则化值的网格 $\\{\\lambda_{k}\\}_{k=1}^{K}$，该网格从 $\\lambda_{1} = \\lambda_{\\max}$ 延伸到 $\\lambda_{K} = \\lambda_{\\min}$，其中 $\\lambda_{\\min} = 10^{-3}\\lambda_{\\max}$，并使用公比为 $r \\in (0,1)$ 的等比数列 $\\lambda_{k} = \\lambda_{\\max} \\, r^{\\,k-1}$。基于 LASSO 解路径的结构和变量进入事件，解释为什么应将网格密度集中在预测变量开始进入模型的“活跃”区域附近。\n\n最后，报告这个包含 $K=100$ 个点的等比网格的公比 $r$，四舍五入到四位有效数字。你的最终答案必须是这个单一的实数（无单位）。", "solution": "首先验证用户提供的问题，以确保其在科学上合理、良定且客观。\n\n### 第 1 步：提取已知条件\n-   **数据表示**：响应向量 $y \\in \\mathbb{R}^{n}$，设计矩阵 $X \\in \\mathbb{R}^{n \\times p}$。\n-   **维度**：样本数 $n = 800$，预测变量数 $p = 6$。\n-   **数据预处理**：矩阵 $X$ 的列被中心化和标准化，使其欧几里得范数为 $\\sqrt{n}$。响应 $y$ 被中心化。\n-   **LASSO 目标函数**：关于 $\\beta \\in \\mathbb{R}^{p}$ 最小化 $\\frac{1}{2n}\\|y - X\\beta\\|_{2}^{2} + \\lambda \\|\\beta\\|_{1}$，其中正则化参数 $\\lambda \\ge 0$。\n-   **经验内积**：$\\frac{1}{n}X^{\\top}y = \\begin{pmatrix}0.238 \\\\ -0.411 \\\\ 0.527 \\\\ 0.105 \\\\ -0.367 \\\\ 0.492\\end{pmatrix}$。\n-   **任务 1**：找到使 $\\hat{\\beta}(\\lambda_{\\max}) = 0$ 成为最优解的最小正则化值 $\\lambda_{\\max}$。\n-   **任务 2**：构建一个包含 $K = 100$ 个正则化值的等比网格，从 $\\lambda_{1} = \\lambda_{\\max}$ 到 $\\lambda_{K} = \\lambda_{\\min} = 10^{-3}\\lambda_{\\max}$，其中 $\\lambda_{k} = \\lambda_{\\max} \\, r^{\\,k-1}$。\n-   **任务 3**：解释 LASSO 中网格密度的设置原理。\n-   **任务 4**：报告公比 $r$，四舍五入到四位有效数字。\n\n### 第 2 步：使用提取的已知条件进行验证\n该问题是统计学习中的一个标准练习，具体涉及 LASSO 估计量的性质。\n-   **科学依据**：该问题基于 LASSO 回归和凸优化的既定数学理论。目标函数、KKT 条件以及正则化路径的概念是该领域的基础。\n-   **良定性**：提供了推导 $\\lambda_{\\max}$ 和公比 $r$ 所需的所有数据和定义。问题具体，且有唯一、可验证的答案。\n-   **客观性**：问题以精确的数学语言陈述，没有主观性或模糊性。给定的数值是合理的。\n\n### 第 3 步：结论与行动\n该问题被判定为**有效**。将提供完整的解法。\n\n### $\\lambda_{\\max}$ 的推导与计算\nLASSO 目标函数为 $L(\\beta) = f(\\beta) + g(\\beta)$，其中 $f(\\beta) = \\frac{1}{2n}\\|y - X\\beta\\|_{2}^{2}$ 是可微的损失项，$g(\\beta) = \\lambda \\|\\beta\\|_{1}$ 是不可微的惩罚项。\n\n解 $\\hat{\\beta}$ 的一阶最优性条件，也称为 Karush-Kuhn-Tucker (KKT) 条件，表明零向量必须位于光滑部分梯度与非光滑部分次微分之和的集合中，并在 $\\hat{\\beta}$ 处求值：\n$$\n0 \\in \\nabla f(\\hat{\\beta}) + \\partial g(\\hat{\\beta})\n$$\n$f(\\beta)$ 的梯度为：\n$$\n\\nabla f(\\beta) = \\frac{1}{n} (X^{\\top}X\\beta - X^{\\top}y)\n$$\n$g(\\beta) = \\lambda \\sum_{j=1}^{p} |\\beta_j|$ 的次微分是向量集合 $s \\in \\mathbb{R}^p$，对每个分量 $j$ 满足：\n$$\ns_j = \\begin{cases} \\lambda \\, \\text{sgn}(\\beta_j)  \\text{if } \\beta_j \\neq 0 \\\\ \\in [-\\lambda, \\lambda]  \\text{if } \\beta_j = 0 \\end{cases}\n$$\n因此，KKT 条件等价于找到一个次梯度向量 $s \\in \\partial g(\\hat{\\beta})$ 使得 $\\nabla f(\\hat{\\beta}) + s = 0$，这意味着：\n$$\n\\frac{1}{n}(X^{\\top}y - X^{\\top}X\\hat{\\beta}) = s\n$$\n我们要寻找使零向量 $\\hat{\\beta} = 0$ 成为最优解的 $\\lambda_{\\max}$ 值。将 $\\hat{\\beta} = 0$ 代入 KKT 条件得到：\n$$\n\\frac{1}{n}X^{\\top}y = s\n$$\n对于 $\\hat{\\beta} = 0$，对次梯度向量 $s$ 的要求是，对所有分量 $j=1, \\dots, p$，都有 $s_j \\in [-\\lambda_{\\max}, \\lambda_{\\max}]$。这可以转化为分量形式的条件：\n$$\n\\left| \\left(\\frac{1}{n}X^{\\top}y\\right)_j \\right| \\le \\lambda_{\\max} \\quad \\text{for all } j=1, \\dots, p\n$$\n为使该不等式组成立，$\\lambda_{\\max}$ 必须大于或等于向量 $\\frac{1}{n}X^{\\top}y$ 中各分量的最大绝对值。因此，使 $\\hat{\\beta}=0$ 成为解的最小 $\\lambda$ 值是使该不等式取等的值。这就得到了 $\\lambda_{\\max}$ 的表达式：\n$$\n\\lambda_{\\max} = \\max_{j=1,\\dots,p} \\left| \\left(\\frac{1}{n}X^{\\top}y\\right)_j \\right| = \\left\\|\\frac{1}{n}X^{\\top}y\\right\\|_{\\infty}\n$$\n使用提供的数值数据：\n$$\n\\frac{1}{n}X^{\\top}y = \\begin{pmatrix}0.238 \\\\ -0.411 \\\\ 0.527 \\\\ 0.105 \\\\ -0.367 \\\\ 0.492\\end{pmatrix}\n$$\n我们计算每个分量的绝对值：\n$$\n\\begin{pmatrix}|0.238| \\\\ |-0.411| \\\\ |0.527| \\\\ |0.105| \\\\ |-0.367| \\\\ |0.492|\\end{pmatrix} = \\begin{pmatrix}0.238 \\\\ 0.411 \\\\ 0.527 \\\\ 0.105 \\\\ 0.367 \\\\ 0.492\\end{pmatrix}\n$$\n该向量中的最大值为 $0.527$。因此，\n$$\n\\lambda_{\\max} = 0.527\n$$\n\n### 正则化网格密度的原理\nLASSO 解路径追踪了系数向量 $\\hat{\\beta}(\\lambda)$ 随 $\\lambda$ 变化的轨迹，是理解模型选择过程的核心。对于任何 $\\lambda \\ge \\lambda_{\\max}$，所有系数均为零。在 $\\lambda = \\lambda_{\\max}$ 时，第一个预测变量进入模型。随着 $\\lambda$ 的进一步减小，更多的预测变量在特定的 $\\lambda$ 阈值处变为非零。这些变量进入非零系数“活跃集”的事件，是 LASSO 变量选择能力的决定性特征。\n\n模型结构最重要的变化——即预测变量的选择——发生在强正则化区域，即 $\\lambda$ 值接近 $\\lambda_{\\max}$ 的区域。正是在这个“活跃”区域，模型从一个空模型转变为一个包含最具影响力预测变量的稀疏模型。通过使用一组细粒度的 $\\lambda$ 值，将网格密度集中在该区域，可以精确地刻画变量进入模型的顺序以及它们的系数路径如何开始演变。这种详细的视图对于理解预测变量的相对重要性以及通过交叉验证等技术选择简约模型至关重要。相比之下，当 $\\lambda \\to 0$ 时，活跃预测变量的集合趋于稳定，系数的值收敛到其无惩罚的普通最小二乘估计值；这个区域的变化更多地是关于系数收缩而不是模型选择，因此一个较粗的网格就足够了。\n\n### 公比 $r$ 的计算\n问题指定了一个包含 $K=100$ 个正则化值的网格 $\\{\\lambda_k\\}_{k=1}^{100}$，由一个等比数列定义：\n$$\n\\lambda_k = \\lambda_{\\max} \\, r^{k-1}\n$$\n网格从 $\\lambda_1 = \\lambda_{\\max}$ 开始（因为 $r^{1-1} = r^0 = 1$），到 $\\lambda_{100} = \\lambda_{\\min}$ 结束。我们已知条件 $\\lambda_{\\min} = 10^{-3}\\lambda_{\\max}$。\n我们可以为网格中的最后一个点 $k=K=100$ 建立一个方程：\n$$\n\\lambda_{100} = \\lambda_{\\max} \\, r^{100-1} = \\lambda_{\\max} \\, r^{99}\n$$\n代入 $\\lambda_{100}$ 的给定关系：\n$$\n10^{-3}\\lambda_{\\max} = \\lambda_{\\max} \\, r^{99}\n$$\n假设 $\\lambda_{\\max} > 0$（我们已经证明这是成立的），我们可以将方程两边同除以 $\\lambda_{\\max}$：\n$$\nr^{99} = 10^{-3}\n$$\n为了解出公比 $r$，我们对两边取 99 次方根：\n$$\nr = (10^{-3})^{1/99} = 10^{-3/99} = 10^{-1/33}\n$$\n现在，我们计算其数值：\n$$\nr = 10^{-1/33} \\approx 0.93259101\n$$\n四舍五入到四位有效数字，我们得到：\n$$\nr \\approx 0.9326\n$$\n这就是该等比网格所要求的公比。", "answer": "$$\\boxed{0.9326}$$", "id": "4990123"}, {"introduction": "LASSO最吸引人的特性之一是它能够执行自动变量选择，但在什么条件下我们才能确信它选出的变量是“正确”的呢？这个问题的答案深植于LASSO的理论保证中，其中“不可表示条件”是确保模型选择一致性的一个核心准则。这项练习将让你深入探索LASSO的KKT条件，在一个给定的真实模型设定下，推导并计算一个关键量，该量直接决定了LASSO是否能够成功恢复出真实的特征集合 ([@problem_id:4990086])。通过这个计算，你将体会到数据中预测变量之间的相关性结构是如何深刻影响LASSO变量选择能力的。", "problem": "一个临床研究团队正在使用 $p=4$ 个标准化的生物标志物预测因子，对 $n=6$ 名患者构建一个用于连续心血管结局的线性风险评分。这些预测因子已被中心化至零均值并缩放至单位方差，因此经验格拉姆矩阵等于样本协方差矩阵 $\\Sigma = \\frac{1}{n} X^{\\top} X$。设计矩阵 $X \\in \\mathbb{R}^{6 \\times 4}$ 由下式给出\n$$\nX \\;=\\;\n\\begin{bmatrix}\n1  1  1  1 \\\\\n1  1  -1  -1 \\\\\n1  -1  1  -1 \\\\\n-1  -1  -1  1 \\\\\n-1  1  1  1 \\\\\n-1  -1  -1  -1\n\\end{bmatrix}.\n$$\n假设数据遵循固定设计线性模型 $y = X \\beta^{0} + \\varepsilon$，其中 $y \\in \\mathbb{R}^{n}$ 是结局，$\\beta^{0} \\in \\mathbb{R}^{p}$ 是真实系数向量，$\\varepsilon \\in \\mathbb{R}^{n}$ 是零均值噪声。科学先验表明，真实支撑集（非零系数的集合）为 $S = \\{1, 3\\}$，其符号为 $\\operatorname{sign}(\\beta^{0}_{1}) = +1$ 和 $\\operatorname{sign}(\\beta^{0}_{3}) = -1$。该团队打算使用最小绝对收缩和选择算子（LASSO）通过求解以下问题来进行变量选择\n$$\n\\min_{\\beta \\in \\mathbb{R}^{p}} \\;\\; \\frac{1}{2n} \\| y - X \\beta \\|_{2}^{2} + \\lambda \\|\\beta\\|_{1},\n$$\n其中 $\\lambda$ 是一个正的调节参数。利用凸优化的第一性原理和 Karush–Kuhn–Tucker (KKT) 条件，从固定设计模型和协方差结构 $\\Sigma$ 中推导出在渐近、固定设计体系中支配精确选择恢复的非活动集可行性量，并为给定的 $X$、声明的 $S$ 和符号模式计算其值。基于此值，评估在通常的正则性假设下（例如，信号有界远离零和噪声相关性消失）是否可以实现精确选择一致性。将计算出的量表示为单个精确实数。无需四舍五入。", "solution": "该问题要求推导和计算支配最小绝对收缩和选择算子（LASSO）精确支撑集恢复的非活动集可行性量。该量源于 LASSO 优化问题的 Karush–Kuhn–Tucker (KKT) 条件。\n\nLASSO 估计量 $\\hat{\\beta}$ 是以下凸优化问题的解：\n$$\n\\min_{\\beta \\in \\mathbb{R}^{p}} \\;\\; L(\\beta) = \\frac{1}{2n} \\| y - X \\beta \\|_{2}^{2} + \\lambda \\|\\beta\\|_{1}\n$$\n最优性条件是零向量必须位于解 $\\hat{\\beta}$ 处的目标函数 $L(\\beta)$ 的次梯度中，即 $0 \\in \\partial L(\\hat{\\beta})$。次梯度由下式给出：\n$$\n\\partial L(\\beta) = -\\frac{1}{n} X^{\\top}(y - X\\beta) + \\lambda \\partial \\|\\beta\\|_{1}\n$$\n其中 $\\partial \\|\\beta\\|_{1}$ 是 $\\ell_1$-范数的次梯度。其第 $j$ 个分量，记为 $(\\partial \\|\\beta\\|_{1})_j$，是：\n$$\n(\\partial \\|\\beta\\|_{1})_j = \\begin{cases} \\operatorname{sign}(\\beta_j)  \\text{if } \\beta_j \\neq 0 \\\\ [-1, 1]  \\text{if } \\beta_j = 0 \\end{cases}\n$$\n解 $\\hat{\\beta}$ 处的 KKT 条件可以表述为：\n1. 对于任何活动索引 $j \\in \\hat{S} = \\{k : \\hat{\\beta}_k \\neq 0\\}$，次梯度是唯一定义的，我们有平稳性条件：\n   $$ \\frac{1}{n} X_j^{\\top}(y - X\\hat{\\beta}) = \\lambda \\operatorname{sign}(\\hat{\\beta}_j) $$\n2. 对于任何非活动索引 $j \\in \\hat{S}^c = \\{k : \\hat{\\beta}_k = 0\\}$，次梯度必须包含零，这意味着可行性条件：\n   $$ \\left| \\frac{1}{n} X_j^{\\top}(y - X\\hat{\\beta}) \\right| \\leq \\lambda $$\n\n我们关心的是精确支撑集恢复的条件，即估计的支撑集 $\\hat{S}$ 与真实支撑集 $S = \\{1, 3\\}$ 完全相同。让我们假设 $\\hat{S} = S$ 并研究其含义。在这种情况下，对于 $j \\in S$，有 $\\hat{\\beta}_j \\neq 0$，而对于 $j \\in S^c = \\{2, 4\\}$，有 $\\hat{\\beta}_j = 0$。\n我们根据 $S$ 和 $S^c$ 对问题进行划分：$X = [X_S, X_{S^c}]$，$\\beta = (\\beta_S, \\beta_{S^c})$。由于 $\\hat{\\beta}_{S^c} = 0$，KKT 条件变为：\n1. 对于活动集 $S$：$\\frac{1}{n} X_S^{\\top}(y - X_S \\hat{\\beta}_S) = \\lambda z_S$，其中 $z_S = \\operatorname{sign}(\\hat{\\beta}_S)$。\n2. 对于非活动集 $S^c$：$|\\frac{1}{n} X_{S^c}^{\\top}(y - X_S \\hat{\\beta}_S)| \\leq \\lambda$（逐元素）。\n\n从第一个条件，我们可以解出 $\\hat{\\beta}_S$：\n$$\n\\frac{1}{n} X_S^{\\top}y - \\left(\\frac{1}{n} X_S^{\\top}X_S\\right) \\hat{\\beta}_S = \\lambda z_S\n$$\n$$\n\\Sigma_{SS} \\hat{\\beta}_S = \\frac{1}{n} X_S^{\\top}y - \\lambda z_S \\implies \\hat{\\beta}_S = \\Sigma_{SS}^{-1}\\left(\\frac{1}{n} X_S^{\\top}y - \\lambda z_S\\right)\n$$\n其中 $\\Sigma = \\frac{1}{n}X^{\\top}X$ 是样本协方差矩阵。\n代入真实模型 $y = X\\beta^0 + \\varepsilon = X_S \\beta^0_S + \\varepsilon$（因为 $\\beta^0_{S^c}=0$）：\n$$\n\\hat{\\beta}_S = \\Sigma_{SS}^{-1}\\left(\\frac{1}{n} X_S^{\\top}(X_S \\beta^0_S + \\varepsilon) - \\lambda z_S\\right) = \\beta^0_S + \\Sigma_{SS}^{-1}\\left(\\frac{1}{n} X_S^{\\top}\\varepsilon - \\lambda z_S\\right)\n$$\n为了在一定的 $\\lambda$ 范围内和典型的噪声假设下实现精确恢复，我们需要 $\\operatorname{sign}(\\hat{\\beta}_S) = \\operatorname{sign}(\\beta^0_S)$。令 $z_S^0 = \\operatorname{sign}(\\beta^0_S)$。假设此一致性成立，我们有 $z_S = z_S^0$。\n\n现在我们分析第二个（可行性）条件。绝对值内的参数是：\n$$\n\\frac{1}{n} X_{S^c}^{\\top}(y - X_S \\hat{\\beta}_S) = \\frac{1}{n} X_{S^c}^{\\top}(X_S \\beta^0_S + \\varepsilon - X_S \\hat{\\beta}_S)\n$$\n代入 $\\hat{\\beta}_S = \\beta^0_S + \\Sigma_{SS}^{-1}(\\frac{1}{n} X_S^{\\top}\\varepsilon - \\lambda z_S^0)$：\n$$\ny - X_S \\hat{\\beta}_S = X_S \\beta^0_S + \\varepsilon - X_S\\left(\\beta^0_S + \\Sigma_{SS}^{-1}\\left(\\frac{1}{n} X_S^{\\top}\\varepsilon - \\lambda z_S^0\\right)\\right) = \\varepsilon - X_S\\Sigma_{SS}^{-1}\\frac{1}{n} X_S^{\\top}\\varepsilon + \\lambda X_S\\Sigma_{SS}^{-1}z_S^0\n$$\n用 $\\frac{1}{n}X_{S^c}^{\\top}$ 左乘：\n$$\n\\frac{1}{n} X_{S^c}^{\\top}(y - X_S \\hat{\\beta}_S) = \\frac{1}{n}X_{S^c}^{\\top}\\left(I - X_S\\Sigma_{SS}^{-1}\\frac{1}{n} X_S^{\\top}\\right)\\varepsilon + \\lambda \\left(\\frac{1}{n}X_{S^c}^{\\top}X_S\\right)\\Sigma_{SS}^{-1}z_S^0\n$$\n$$\n\\frac{1}{n} X_{S^c}^{\\top}(y - X_S \\hat{\\beta}_S) = \\text{噪声项} + \\lambda \\Sigma_{S^c S} \\Sigma_{SS}^{-1}z_S^0\n$$\n可行性条件 $|\\frac{1}{n} X_{S^c}^{\\top}(y - X_S \\hat{\\beta}_S)| \\leq \\lambda$ 变为：\n$$\n|\\Sigma_{S^c S} \\Sigma_{SS}^{-1}z_S^0 + \\frac{1}{\\lambda}(\\text{噪声项})| \\leq 1\n$$\n在渐近、固定设计体系中，假定噪声项的影响会消失。为了使该条件稳健地成立，确定性部分必须满足严格的不等式。这导致了“不可表示条件”(Irrepresentable Condition)：\n$$\n\\| \\Sigma_{S^c S} \\Sigma_{SS}^{-1}z_S^0 \\|_{\\infty}  1\n$$\n要计算的量就是这个 $\\ell_{\\infty}$-范数，我们记为 $\\eta$。\n$\\eta = \\| \\Sigma_{S^c S} \\Sigma_{SS}^{-1}z_S^0 \\|_{\\infty}$。\n\n给定 $n=6$，$S=\\{1, 3\\}$，以及 $S^c=\\{2, 4\\}$。$S$ 的符号向量是 $z_S^0 = \\begin{pmatrix} \\operatorname{sign}(\\beta_1^0) \\\\ \\operatorname{sign}(\\beta_3^0) \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$。\n设计矩阵为 $X = \\begin{bmatrix} X_1  X_2  X_3  X_4 \\end{bmatrix}$。对应于 $S$ 和 $S^c$ 的 $X$ 的列是：\n$$\nX_S = \\begin{bmatrix} 1  1 \\\\ 1  -1 \\\\ 1  1 \\\\ -1  -1 \\\\ -1  1 \\\\ -1  -1 \\end{bmatrix}, \\quad X_{S^c} = \\begin{bmatrix} 1  1 \\\\ 1  -1 \\\\ -1  -1 \\\\ -1  1 \\\\ 1  1 \\\\ -1  -1 \\end{bmatrix}\n$$\n首先，我们计算 $\\Sigma_{SS} = \\frac{1}{n}X_S^{\\top}X_S$。由于 $X$ 的列是标准化的，$\\Sigma$ 的对角线元素为 1。\n$$\nX_1^{\\top}X_3 = 1(1) + 1(-1) + 1(1) + (-1)(-1) + (-1)(1) + (-1)(-1) = 1-1+1+1-1+1 = 2\n$$\n$$\n\\Sigma_{SS} = \\frac{1}{6} \\begin{bmatrix} 6  2 \\\\ 2  6 \\end{bmatrix} = \\begin{bmatrix} 1  1/3 \\\\ 1/3  1 \\end{bmatrix}\n$$\n接下来，我们计算逆矩阵 $\\Sigma_{SS}^{-1}$：\n$$\n\\det(\\Sigma_{SS}) = 1 \\cdot 1 - (\\frac{1}{3})^2 = 1 - \\frac{1}{9} = \\frac{8}{9}\n$$\n$$\n\\Sigma_{SS}^{-1} = \\frac{1}{8/9} \\begin{bmatrix} 1  -1/3 \\\\ -1/3  1 \\end{bmatrix} = \\frac{9}{8} \\begin{bmatrix} 1  -1/3 \\\\ -1/3  1 \\end{bmatrix} = \\begin{bmatrix} 9/8  -3/8 \\\\ -3/8  9/8 \\end{bmatrix}\n$$\n现在，我们计算 $\\Sigma_{S^c S} = \\frac{1}{n}X_{S^c}^{\\top}X_S$：\n$$\nX_2^{\\top}X_1 = 1(1) + 1(1) + (-1)(1) + (-1)(-1) + 1(-1) + (-1)(-1) = 1+1-1+1-1+1 = 2\n$$\n$$\nX_2^{\\top}X_3 = 1(1) + 1(-1) + (-1)(1) + (-1)(-1) + 1(1) + (-1)(-1) = 1-1-1+1+1+1 = 2\n$$\n$$\nX_4^{\\top}X_1 = 1(1) + (-1)(1) + (-1)(1) + 1(-1) + 1(-1) + (-1)(-1) = 1-1-1-1-1+1 = -2\n$$\n$$\nX_4^{\\top}X_3 = 1(1) + (-1)(-1) + (-1)(1) + 1(-1) + 1(1) + (-1)(-1) = 1+1-1-1+1+1 = 2\n$$\n$$\n\\Sigma_{S^c S} = \\frac{1}{6} \\begin{bmatrix} 2  2 \\\\ -2  2 \\end{bmatrix} = \\begin{bmatrix} 1/3  1/3 \\\\ -1/3  1/3 \\end{bmatrix}\n$$\n现在我们组合这些项来求 $\\eta$：\n$$\n\\Sigma_{SS}^{-1}z_S^0 = \\begin{bmatrix} 9/8  -3/8 \\\\ -3/8  9/8 \\end{bmatrix} \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} = \\begin{pmatrix} 9/8 - (-3/8) \\\\ -3/8 - 9/8 \\end{pmatrix} = \\begin{pmatrix} 12/8 \\\\ -12/8 \\end{pmatrix} = \\begin{pmatrix} 3/2 \\\\ -3/2 \\end{pmatrix}\n$$\n$$\n\\Sigma_{S^c S} (\\Sigma_{SS}^{-1}z_S^0) = \\begin{bmatrix} 1/3  1/3 \\\\ -1/3  1/3 \\end{bmatrix} \\begin{pmatrix} 3/2 \\\\ -3/2 \\end{pmatrix} = \\begin{pmatrix} (1/3)(3/2) + (1/3)(-3/2) \\\\ (-1/3)(3/2) + (1/3)(-3/2) \\end{pmatrix} = \\begin{pmatrix} 1/2 - 1/2 \\\\ -1/2 - 1/2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ -1 \\end{pmatrix}\n$$\n非活动集可行性量 $\\eta$ 是该向量的 $\\ell_{\\infty}$-范数：\n$$\n\\eta = \\left\\| \\begin{pmatrix} 0 \\\\ -1 \\end{pmatrix} \\right\\|_{\\infty} = \\max(|0|, |-1|) = 1\n$$\n计算出的值恰好是 $1$。由于这个值不满足严格不等式 $\\eta  1$，所以不可表示条件被违反了。这意味着对于此问题，无法保证精确选择一致性。该系统处于可恢复性的边界上，任何来自噪声的扰动都可能导致 LASSO 无法选择正确的预测因子集。具体来说，预测因子 $j=4$ 的值为 $|-1|=1$，表明它与模型残差（在无噪声极限下）的相关性与活动预测因子一样高，因此容易被错误地包含在模型中。\n问题要求计算这个量的值。\n该值为 $1$。", "answer": "$$\n\\boxed{1}\n$$", "id": "4990086"}]}