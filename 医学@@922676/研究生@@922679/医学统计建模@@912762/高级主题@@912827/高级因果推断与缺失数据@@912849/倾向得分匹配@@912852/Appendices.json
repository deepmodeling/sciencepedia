{"hands_on_practices": [{"introduction": "倾向性评分匹配的核心在于为每个接受治疗的个体寻找一个特征相似但未接受治疗的“对照”个体，从而模拟随机试验。本练习将引导你完成这一基本操作，通过对已配对的数据直接计算平均治疗效应（ATT），这有助于你深入理解匹配如何构建一个有效的反事实比较组。[@problem_id:4830538]", "problem": "一项基于医院的观察性队列研究评估了一种降脂治疗（$A=1$）相对于常规护理（$A=0$）在$6$个月内降低低密度脂蛋白胆固醇（LDL-C）的效果，单位为 $\\mathrm{mg/dL}$。设每个患者的潜在结果为 $Y(1)$ 和 $Y(0)$，并假设稳定单位处理值假设（SUTVA）和强可忽略性成立，即对于 $a \\in \\{0,1\\}$，$Y(a) \\perp A \\mid X$，并且在给定协变量 $X$ 的情况下不存在未测量的混杂因素。倾向性得分是 $e(X) = \\Pr(A=1 \\mid X)$，并且在共同支撑域上，通过对处理组单位的logit倾向性得分使用保守卡尺进行最近邻匹配。科学目标是估计处理组的平均处理效应（ATT）。\n\n从潜在结果框架的基本原理和倾向性得分的平衡性质出发，形式化通过对处理组单位进行匹配所针对的参数，并解释为什么在所述假设下，对估计的倾向性得分进行最近邻匹配（具有适当的共同支撑域和卡尺）可以识别该参数。然后，使用下面匹配的处理-对照配对，通过计算处理组单位的配对内结果差异的平均值，来计算该参数的样本匹配对估计量。\n\n该研究产生了 $n_T = 5$ 个匹配对（每个处理组单位对应一个对照组单位），观察到的$6$个月LDL-C降低值（单位：$\\mathrm{mg/dL}$）如下：\n- 第 $1$ 对：处理组 $Y^{\\mathrm{obs}} = 38.4$，匹配的对照组 $Y^{\\mathrm{obs}} = 25.6$。\n- 第 $2$ 对：处理组 $Y^{\\mathrm{obs}} = 22.1$，匹配的对照组 $Y^{\\mathrm{obs}} = 15.9$。\n- 第 $3$ 对：处理组 $Y^{\\mathrm{obs}} = 41.0$，匹配的对照组 $Y^{\\mathrm{obs}} = 27.3$。\n- 第 $4$ 对：处理组 $Y^{\\mathrm{obs}} = 35.2$，匹配的对照组 $Y^{\\mathrm{obs}} = 29.0$。\n- 第 $5$ 对：处理组 $Y^{\\mathrm{obs}} = 30.5$，匹配的对照组 $Y^{\\mathrm{obs}} = 18.1$。\n\n将最终估计值报告为处理组减去匹配对照组差异的标量平均值，单位为 $\\mathrm{mg/dL}$。将您的答案四舍五入到四位有效数字。", "solution": "该问题要求对处理组的平均处理效应（ATT）进行形式化定义，解释如何通过倾向性得分匹配来识别它，并计算一个样本估计值。该问题在因果推断的框架内是适定的且具有科学依据的。\n\n首先，我们形式化目标参数，即处理组的平均处理效应（ATT）。设 $Y(1)$ 是患者接受降脂治疗（$A=1$）时的潜在结果（LDL-C降低值），$Y(0)$ 是他们接受常规护理（$A=0$）时的潜在结果。ATT 被定义为实际接受处理的个体亚群中，处理的预期因果效应：\n$$\n\\text{ATT} = E[Y(1) - Y(0) \\mid A=1]\n$$\n根据期望的线性性质，这可以写成：\n$$\n\\text{ATT} = E[Y(1) \\mid A=1] - E[Y(0) \\mid A=1]\n$$\n第一项 $E[Y(1) \\mid A=1]$ 是处理组在接受处理后的预期结果。根据稳定单位处理值假设（SUTVA），对于一个接受处理的个体，其观察结果就是其在处理下的潜在结果，即如果 $A=1$，则 $Y^{\\mathrm{obs}} = Y(1)$。因此，这一项可以直接从数据中识别，并可以通过处理组中观察结果的样本均值来估计：$E[Y^{\\mathrm{obs}} \\mid A=1]$。\n\n第二项 $E[Y(0) \\mid A=1]$ 是处理组在接受对照处理下的预期结果。这是一个反事实量，因为我们无法观察到接受处理的个体在假如接受对照处理的情况下其结果会是怎样。它的识别是观察性研究中的核心挑战。\n\n识别是在强可忽略性假设下实现的，即 $Y(a) \\perp A \\mid X$ 对于 $a \\in \\{0,1\\}$，这意味着在给定一组观察到的协变量 $X$ 的条件下，处理分配 $A$ 与潜在结果 $Y(a)$ 是独立的。对于我们感兴趣的反事实均值，这意味着：\n$$\nE[Y(0) \\mid A=1, X] = E[Y(0) \\mid A=0, X]\n$$\n这个方程表明，在由协变量 $X$ 定义的层内，处理组和对照组在对照处理下的预期潜在结果是相同的。等式右边是可观察的，因为对于对照组（$A=0$），$Y^{\\mathrm{obs}} = Y(0)$。因此，$E[Y(0) \\mid A=0, X] = E[Y^{\\mathrm{obs}} \\mid A=0, X]$。\n\n为了获得处理人群的总体反事实均值，我们在处理组（$A=1$）中对协变量 $X$ 的分布进行平均：\n$$\nE[Y(0) \\mid A=1] = E_{X \\mid A=1} [E[Y(0) \\mid A=1, X]]\n$$\n代入从可忽略性假设得到的结果：\n$$\nE[Y(0) \\mid A=1] = E_{X \\mid A=1} [E[Y(0) \\mid A=0, X]] = E_{X \\mid A=1} [E[Y^{\\mathrm{obs}} \\mid A=0, X]]\n$$\n这个表达式表明，可以通过获取对照组受试者的结果，并对其进行重加权或标准化以匹配处理组受试者的协变量分布，来识别处理组的反事实均值。\n\n倾向性得分匹配是实现这种标准化的方法。倾向性得分 $e(X) = \\Pr(A=1 \\mid X)$ 有一个由 Rosenbaum 和 Rubin 建立的关键平衡性质：在倾向性得分的条件下，协变量 $X$ 在处理组和对照组之间的分布是相同的。这个性质允许我们用对标量 $e(X)$ 的条件来代替对多维 $X$ 的条件。强可忽略性假设 $Y(a) \\perp A \\mid X$ 意味着在倾向性得分的条件下也有类似的可忽略性：$Y(a) \\perp A \\mid e(X)$。\n\n因此，我们可以写出：\n$$\nE[Y(0) \\mid A=1, e(X)] = E[Y(0) \\mid A=0, e(X)] = E[Y^{\\mathrm{obs}} \\mid A=0, e(X)]\n$$\n对处理组进行匹配的工作方式是为每个处理组个体 $i$ 找到一个具有几乎相同倾向性得分的对照组个体 $j(i)$，即 $e(X_i) \\approx e(X_{j(i)})$。这个过程创建了一个匹配的对照组，由于其倾向性得分分布与处理组相似，因此其协变量 $X$ 的分布也相似。因此，这个匹配对照组结果的简单平均值提供了 $E_{X \\mid A=1} [E[Y^{\\mathrm{obs}} \\mid A=0, X]]$ 的无偏估计，这正是我们的目标反事实均值 $E[Y(0) \\mid A=1]$。\n\n因此，ATT 可以通过以下方式识别：\n$$\n\\text{ATT} = E[Y^{\\mathrm{obs}} \\mid A=1] - E[Y^{\\mathrm{obs}}_{\\text{matched controls}}]\n$$\nATT的样本匹配对估计量是该表达式的样本模拟。对于一组 $n_T$ 个处理组个体，每个个体都与一个唯一的对照组个体匹配，其估计量是配对内差异的平均值：\n$$\n\\widehat{\\text{ATT}} = \\frac{1}{n_T} \\sum_{i=1}^{n_T} (Y_i^{\\mathrm{obs, treated}} - Y_{j(i)}^{\\mathrm{obs, control}})\n$$\n其中 $Y_{j(i)}^{\\mathrm{obs, control}}$ 是与第 $i$ 个处理组单位匹配的对照组单位的观察结果。\n\n现在，我们使用所提供的 $n_T = 5$ 对数据来计算这个估计量。\n每对的差异为：\n- 第 $1$ 对：$\\Delta_1 = 38.4 - 25.6 = 12.8$\n- 第 $2$ 对：$\\Delta_2 = 22.1 - 15.9 = 6.2$\n- 第 $3$ 对：$\\Delta_3 = 41.0 - 27.3 = 13.7$\n- 第 $4$ 对：$\\Delta_4 = 35.2 - 29.0 = 6.2$\n- 第 $5$ 对：$\\Delta_5 = 30.5 - 18.1 = 12.4$\n\n样本 ATT 是这些差异的平均值：\n$$\n\\widehat{\\text{ATT}} = \\frac{1}{5} \\sum_{i=1}^{5} \\Delta_i = \\frac{12.8 + 6.2 + 13.7 + 6.2 + 12.4}{5}\n$$\n$$\n\\widehat{\\text{ATT}} = \\frac{51.3}{5} = 10.26\n$$\n问题要求将答案四舍五入到四位有效数字。计算出的值 $10.26$ 已经有四位有效数字。\n\n处理组的平均处理效应的最终估计值为 $10.26 \\, \\mathrm{mg/dL}$。", "answer": "$$\\boxed{10.26}$$", "id": "4830538"}, {"introduction": "除了逐一配对，倾向性评分还可用于分层分析，这是另一种强大的混杂控制方法。本练习将通过一个假设的临床研究，让你实践如何将样本按倾向性评分分层，计算各层内的治疗效应，并最终加权平均得到总体平均治疗效应（ATE）。这个过程不仅展示了分层法的操作步骤，也揭示了其与配对法在目标参数（ATE vs. ATT）上的区别。[@problem_id:4830519]", "problem": "一项临床有效性研究使用观察性队列数据来估计启动一种新的抗高血压治疗对 $6$ 个月内收缩压变化的因果效应。设二元处理指标为 $T \\in \\{0,1\\}$，基线协变量为 $X$，结局为 $Y$，定义为从基线到 $6$ 个月时收缩压的变化，单位为毫米汞柱 (mmHg)，负值表示降低。假设稳定单位处理值假设 (SUTVA) 和强可忽略性成立，即 $(Y(0),Y(1)) \\perp T \\mid X$ 和正性成立，其中 $Y(0)$ 和 $Y(1)$ 分别表示在控制和处理下的潜在结局。倾向性得分为 $e(X) = \\Pr(T=1 \\mid X)$。\n\n该研究估计了 $e(X)$，并使用估计的倾向性得分的五分位数将样本分层为 $K$ 个亚类 (因此 $K=5$)。在每个亚类 $k \\in \\{1,2,3,4,5\\}$ 中，处理组和控制组的样本量分别为 $N_{1k}$ 和 $N_{0k}$，处理组和控制组中观测到的 $Y$ 的样本均值分别为 $\\bar{Y}_{1k}$ 和 $\\bar{Y}_{0k}$。数据如下，其中所有计数和均值均具有科学合理性，并源自该队列：\n\n- 五分位数 $k=1$: $N_{1,1} = 40$, $N_{0,1} = 160$, $\\bar{Y}_{1,1} = -12.4$, $\\bar{Y}_{0,1} = -8.7$.\n- 五分位数 $k=2$: $N_{1,2} = 60$, $N_{0,2} = 140$, $\\bar{Y}_{1,2} = -10.2$, $\\bar{Y}_{0,2} = -7.9$.\n- 五分位数 $k=3$: $N_{1,3} = 110$, $N_{0,3} = 90$, $\\bar{Y}_{1,3} = -9.5$, $\\bar{Y}_{0,3} = -6.1$.\n- 五分位数 $k=4$: $N_{1,4} = 150$, $N_{0,4} = 50$, $\\bar{Y}_{1,4} = -8.0$, $\\bar{Y}_{0,4} = -5.0$.\n- 五分位数 $k=5$: $N_{1,5} = 180$, $N_{0,5} = 20$, $\\bar{Y}_{1,5} = -7.1$, $\\bar{Y}_{0,5} = -3.4$.\n\n设 $N_k = N_{1k} + N_{0k}$ 且 $N = \\sum_{k=1}^{5} N_k$。从观察性因果推断的基本原理出发，定义倾向性得分分层为 $K$ 个亚类（如五分位数）。使用这些原理，推导出亚类 $k$ 的层内均值差异估计量，以及针对研究样本中平均处理效应 (ATE) 的跨亚类加权汇总方法。然后使用所提供的数据计算得出的 ATE 估计值。最终答案以毫米汞柱 (mmHg) 表示，并四舍五入到四位有效数字。", "solution": "该问题陈述清晰，具有科学依据，并提供了使用倾向性得分分层估计平均处理效应 (ATE) 所需的所有信息。我们将首先从因果推断的基本原理推导出估计量，然后将其应用于所提供的数据。\n\n目标是估计平均处理效应 (ATE)，其定义为在整个群体中，处理下的潜在结局 ($Y(1)$) 与控制下的潜在结局 ($Y(0)$) 之间的期望差异：\n$$\n\\tau_{ATE} = E[Y(1) - Y(0)]\n$$\n在观察性研究中，我们无法直接观察到同一个体的 $Y(1)$ 和 $Y(0)$。对处理组和控制组进行简单比较，$E[Y \\mid T=1] - E[Y \\mid T=0]$，通常会因为混杂而产生偏倚，即影响处理分配 $T$ 的协变量 $X$ 同时也影响结局 $Y$。\n\n问题陈述了 **强可忽略性** 假设，该假设包含两部分：\n$1$. 无混杂性：$(Y(0), Y(1)) \\perp T \\mid X$。这意味着在给定基线协变量 $X$ 的条件下，处理分配 $T$ 与潜在结局是独立的。\n$2$. 正性 (或重叠)：$0  \\Pr(T=1 \\mid X)  1$。这确保对于任何协变量集合 $X$，被分配到处理组或控制组的概率都非零。\n\n在无混杂性假设下，我们可以识别条件期望潜在结局：\n$$\nE[Y(t) \\mid X] = E[Y(t) \\mid T=t, X] = E[Y \\mid T=t, X] \\quad \\text{for } t \\in \\{0,1\\}\n$$\nATE 随后可以表示为对协变量 $X$ 分布的期望：\n$$\n\\tau_{ATE} = E_X[E[Y(1) \\mid X] - E[Y(0) \\mid X]] = E_X[E[Y \\mid T=1, X] - E[Y \\mid T=0, X]]\n$$\n直接对高维向量 $X$ 进行条件化通常是不可行的。Rosenbaum 和 Rubin (1983) 表明，对一维的倾向性得分 $e(X) = \\Pr(T=1 \\mid X)$ 进行条件化足以消除混杂偏倚，因为倾向性得分是一个平衡得分。具体而言，如果 $(Y(0), Y(1)) \\perp T \\mid X$，那么 $(Y(0), Y(1)) \\perp T \\mid e(X)$ 也成立。\n\n**倾向性得分分层**\n该方法通过根据估计的倾向性得分 $\\hat{e}(X)$ 的分位数将群体划分为 $K$ 个层，来近似对连续倾向性得分 $e(X)$ 的条件化。在每个层 $k$ 内，个体的倾向性得分相似，因此处理组和控制组之间的协变量 $X$ 的分布预计是近似平衡的。\n\n**层内估计量**\n在给定的层 $k$ 内，无混杂性假设被认为近似成立。因此，层 $k$ 内的平均处理效应（记为 $\\tau_k$）可以通过该层中处理组和控制组受试者结局均值的简单差异来估计。\n$$\n\\tau_k = E[Y(1) - Y(0) \\mid \\text{subject in stratum } k]\n$$\n其基于样本的估计量是**层内均值差异估计量**：\n$$\n\\hat{\\tau}_k = \\bar{Y}_{1k} - \\bar{Y}_{0k}\n$$\n其中 $\\bar{Y}_{1k}$ 是层 $k$ 中处理单元的结局样本均值，而 $\\bar{Y}_{0k}$ 是层 $k$ 中控制单元的样本均值。\n\n**汇总以估计 ATE**\n总体 ATE 是各层特定处理效应的加权平均值，其中权重是每个层中样本量占总样本量的比例。\n根据全期望定律，ATE 可以写为：\n$$\n\\tau_{ATE} = \\sum_{k=1}^K \\Pr(\\text{stratum } k) \\cdot E[Y(1) - Y(0) \\mid \\text{stratum } k] = \\sum_{k=1}^K \\Pr(\\text{stratum } k) \\cdot \\tau_k\n$$\n我们通过用样本比例替代概率，用层特定估计量 $\\hat{\\tau}_k$ 替代 $\\tau_k$ 来估计此值。设 $N_k = N_{1k} + N_{0k}$ 为层 $k$ 中的受试者数量，$N = \\sum_{k=1}^K N_k$ 为总样本量。研究样本中 ATE 的估计量为：\n$$\n\\hat{\\tau}_{ATE} = \\sum_{k=1}^K \\frac{N_k}{N} \\hat{\\tau}_k = \\sum_{k=1}^K \\frac{N_{1k} + N_{0k}}{N} (\\bar{Y}_{1k} - \\bar{Y}_{0k})\n$$\n\n**计算**\n我们获得了 $K=5$ 个层（五分位数）的数据。首先，让我们计算每个层中的受试者总数和总样本量。\n- 层 $k=1$: $N_1 = N_{1,1} + N_{0,1} = 40 + 160 = 200$\n- 层 $k=2$: $N_2 = N_{1,2} + N_{0,2} = 60 + 140 = 200$\n- 层 $k=3$: $N_3 = N_{1,3} + N_{0,3} = 110 + 90 = 200$\n- 层 $k=4$: $N_4 = N_{1,4} + N_{0,4} = 150 + 50 = 200$\n- 层 $k=5$: $N_5 = N_{1,5} + N_{0,5} = 180 + 20 = 200$\n\n总样本量为 $N = \\sum_{k=1}^5 N_k = 200 + 200 + 200 + 200 + 200 = 1000$。\n\n每个层的权重为 $\\frac{N_k}{N} = \\frac{200}{1000} = \\frac{1}{5} = 0.2$。由于各层是五分位数且包含相同数量的受试者，因此所有权重都相等。\n\n接下来，我们计算层内均值差异 $\\hat{\\tau}_k$：\n- 层 $k=1$: $\\hat{\\tau}_1 = \\bar{Y}_{1,1} - \\bar{Y}_{0,1} = -12.4 - (-8.7) = -3.7$\n- 层 $k=2$: $\\hat{\\tau}_2 = \\bar{Y}_{1,2} - \\bar{Y}_{0,2} = -10.2 - (-7.9) = -2.3$\n- 层 $k=3$: $\\hat{\\tau}_3 = \\bar{Y}_{1,3} - \\bar{Y}_{0,3} = -9.5 - (-6.1) = -3.4$\n- 层 $k=4$: $\\hat{\\tau}_4 = \\bar{Y}_{1,4} - \\bar{Y}_{0,4} = -8.0 - (-5.0) = -3.0$\n- 层 $k=5$: $\\hat{\\tau}_5 = \\bar{Y}_{1,5} - \\bar{Y}_{0,5} = -7.1 - (-3.4) = -3.7$\n\n最后，我们计算 ATE 估计值，即这些层特定效应的加权平均值：\n$$\n\\hat{\\tau}_{ATE} = \\sum_{k=1}^5 \\frac{N_k}{N} \\hat{\\tau}_k = \\frac{1}{5} \\sum_{k=1}^5 \\hat{\\tau}_k\n$$\n$$\n\\hat{\\tau}_{ATE} = \\frac{1}{5} (-3.7 - 2.3 - 3.4 - 3.0 - 3.7)\n$$\n$$\n\\hat{\\tau}_{ATE} = \\frac{1}{5} (-16.1)\n$$\n$$\n\\hat{\\tau}_{ATE} = -3.22\n$$\n问题要求答案四舍五入到四位有效数字。计算值为 $-3.22$。为了用四位有效数字表示，我们将其写为 $-3.220$。负号表示该疗法与收缩压降低相关，这与预期相符。该疗法的估计平均因果效应是降低 $3.220$ mmHg。", "answer": "$$\n\\boxed{-3.220}\n$$", "id": "4830519"}, {"introduction": "构建倾向性评分模型时，一个常见的误区是“越多变量越好”，但这可能引入而非消除偏倚。本练习将通过计算机模拟，引导你探索一种被称为“M-偏倚”的现象，即当模型中包含一个“对撞因子”（collider）时所产生的偏倚。你将亲手构建一个包含对撞因子的数据生成过程，并比较包含与不包含该变量的倾向性评分模型所得出的结果，从而深刻理解为何变量选择必须基于因果理论，而不仅仅是统计关联。[@problem_id:3162896]", "problem": "您被要求在因果推断和统计学习的潜在结果框架内，设计并实现一个基于模拟的演示，以展示倾向得分匹配（PSM）中的 M-偏倚。请从以下基本概念出发：在潜在结果框架下，平均处理效应（ATE）被定义为处理组和控制组潜在结果之间的平均差异，而倾向得分则是在给定观测协变量的条件下接受处理的概率。对撞因子是一个由两个（或更多）变量引起的变量；对对撞因子进行条件化可能会在原本独立的两个原因之间引入伪统计关联（M-偏倚），如果这些原因沿着不同路径影响结果和处理，就会导致因果效应估计产生偏倚。\n\n使用有向无环图（DAG）概念，构建一个体现典型 M-偏倚结构的数据生成过程（DGP）。该 DAG 如下：存在潜变量 $U$ 和 $V$，使得 $U$ 影响处理 $T$ 但不影响结果 $Y$，$V$ 影响结果 $Y$ 但不影响处理 $T$，而对撞因子 $C$ 同时受 $U$ 和 $V$ 的影响。此外，还有一个观测协变量 $X$。结构方程如下：\n- 潜在原因：$U \\sim \\mathcal{N}(0,1)$, $V \\sim \\mathcal{N}(0,1)$。\n- 观测协变量：$X \\sim \\mathcal{N}(0,1)$。\n- 对撞因子：$C = \\gamma_U U + \\gamma_V V + \\varepsilon_C$，其中 $\\varepsilon_C \\sim \\mathcal{N}(0,1)$。\n- 处理分配：$T \\sim \\text{Bernoulli}(\\text{logit}^{-1}(\\alpha_0 + \\alpha_U U + \\alpha_X X))$，其中 $\\text{logit}^{-1}(z) = \\dfrac{1}{1 + e^{-z}}$。\n- 结果：$Y = \\beta_T T + \\beta_V V + \\beta_X X + \\varepsilon_Y$，其中 $\\varepsilon_Y \\sim \\mathcal{N}(0,1)$。\n\n在此 DGP 下，真实的平均处理效应（ATE）等于 $\\beta_T$。\n\n您的程序必须为每个测试用例执行以下操作：\n1. 根据上述 DGP 模拟 $N$ 个独立观测值。\n2. 使用逻辑斯谛回归（最大似然）估计两个关于 $T$ 的倾向得分模型，每个模型都包含一个截距项：\n   - 错误模型（包含对撞因子）：协变量 $\\{X, C\\}$。\n   - 正确模型（排除对撞因子）：协变量 $\\{X\\}$。\n3. 对每个拟合的倾向得分，在绝对倾向得分差异上使用有放回的最近邻匹配和卡尺（caliper）。具体来说：\n   - 对于每个处理单元，在倾向得分距离上找到最近的单个控制单元；如果距离小于或等于卡尺值，则包含该配对。\n   - 对于每个控制单元，在倾向得分距离上找到最近的单个处理单元；如果距离小于或等于卡尺值，则包含该配对。\n   - 通过对两个方向形成的所有可用匹配对差异 $Y_{\\text{treated}} - Y_{\\text{control}}$ 进行平均，计算平均处理效应的匹配估计值（这种对称匹配估计量近似于平均处理效应，而不仅仅是处理组的平均处理效应）。\n   - 如果没有配对满足卡尺条件，则不使用任何卡尺重新运行最近邻匹配（即，卡尺 $= +\\infty$）。\n4. 计算每个匹配估计量相对于真实 ATE 的偏倚：\n   - 包含对撞因子的偏倚：$b_{\\text{incl}} = \\widehat{\\text{ATE}}_{\\text{incl}} - \\beta_T$。\n   - 排除对撞因子的偏倚：$b_{\\text{excl}} = \\widehat{\\text{ATE}}_{\\text{excl}} - \\beta_T$。\n   - 因包含对撞因子而产生的额外绝对偏倚：$\\Delta = |b_{\\text{incl}}| - |b_{\\text{excl}}|$。\n5. 将所有测试用例的结果汇总到单行输出中，形式为以逗号分隔的每个用例的三元组列表，其中每个三元组是方括号内的列表 $[b_{\\text{incl}}, b_{\\text{excl}}, \\Delta]$。完整的输出必须用方括号括起来。例如：$[[b_1^{\\text{incl}}, b_1^{\\text{excl}}, \\Delta_1],[b_2^{\\text{incl}}, b_2^{\\text{excl}}, \\Delta_2]]$。\n\n测试套件与参数：\n为以下四个测试用例实现该过程。使用指定的随机种子以确保可复现性。\n\n- 用例 1（基线，中度对撞因子）：\n  - $N = 4000$, $\\alpha_0 = 0$, $\\alpha_U = 1.0$, $\\alpha_X = 0.5$, $\\beta_T = 2.0$, $\\beta_V = 1.0$, $\\beta_X = 0.0$, $\\gamma_U = 0.8$, $\\gamma_V = 0.8$, 卡尺 $= 0.05$, 种子 $= 42$。\n\n- 用例 2（边界情况，无对撞因子效应）：\n  - $N = 4000$, $\\alpha_0 = 0$, $\\alpha_U = 1.0$, $\\alpha_X = 0.5$, $\\beta_T = 2.0$, $\\beta_V = 1.0$, $\\beta_X = 0.0$, $\\gamma_U = 0.0$, $\\gamma_V = 0.0$, 卡尺 $= 0.05$, 种子 $= 1$。\n\n- 用例 3（强对撞因子影响）：\n  - $N = 4000$, $\\alpha_0 = 0$, $\\alpha_U = 1.2$, $\\alpha_X = 0.5$, $\\beta_T = 2.0$, $\\beta_V = 1.0$, $\\beta_X = 0.0$, $\\gamma_U = 2.5$, $\\gamma_V = 2.5$, 卡尺 $= 0.05$, 种子 $= 7$。\n\n- 用例 4（小样本，中度对撞因子）：\n  - $N = 600$, $\\alpha_0 = 0$, $\\alpha_U = 1.0$, $\\alpha_X = 0.5$, $\\beta_T = 2.0$, $\\beta_V = 1.0$, $\\beta_X = 0.0$, $\\gamma_U = 1.0$, $\\gamma_V = 1.0$, 卡尺 $= 0.07$, 种子 $= 123$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含结果，形式为以逗号分隔的每个用例的三元组列表，每个三元组本身是方括号内的逗号分隔列表，整个输出用方括号括起来。例如：$[[r_{11},r_{12},r_{13}],[r_{21},r_{22},r_{23}],[r_{31},r_{32},r_{33}],[r_{41},r_{42},r_{43}]]$. 每个 $r_{ij}$ 必须是浮点数。", "solution": "问题陈述已经过验证并被认为是有效的。它在因果推断和统计学习领域提出了一个定义明确、具有科学依据的模拟练习。其目标是在倾向得分匹配（PSM）的背景下，演示 M-偏倚，这是一种因对对撞因子变量进行条件化而产生的特定类型的偏倚。所有参数、模型和过程都已明确定义，从而可以实现可复现的计算解决方案。\n\n### 理论框架\n\n该问题植根于因果推断的潜在结果框架。目标是估计平均处理效应（ATE），定义为 $\\mathbb{E}[Y(1) - Y(0)]$，其中 $Y(1)$ 和 $Y(0)$ 分别是处理和控制下的潜在结果。数据生成过程（DGP）由一组与有向无环图（DAG）相对应的结构方程指定。该 DAG 的核心是“M-结构”：\n1. 一个未观测变量 $U$ 是处理 $T$ 的原因（$U \\rightarrow T$）。\n2. 另一个未观测变量 $V$ 是结果 $Y$ 的原因（$V \\rightarrow Y$）。\n3. $U$ 和 $V$ 是独立的，即它们之间没有路径。\n4. $U$ 和 $V$ 都是一个观测变量 $C$（对撞因子）的原因（$U \\rightarrow C \\leftarrow V$）。\n\n在此结构中，由于路径 $T \\leftarrow U \\rightarrow C \\leftarrow V \\rightarrow Y$ 被对撞因子 $C$ 阻断，所以 $T$ 和 $Y$ 并不通过涉及 $U$ 和 $V$ 的路径相关联。然而，如果对对撞因子 $C$ 进行条件化（例如，通过将其包含在回归模型中），这条路径就会被打开，从而在 $U$ 和 $V$ 之间产生伪统计关联。这种处理原因（$U$）和结果原因（$V$）之间的伪关联在 $T$ 和 $Y$ 之间产生了非因果的统计关联，导致因果效应的估计产生偏倚。\n\n指定的数据生成过程（DGP）如下：\n- 潜在原因：$U \\sim \\mathcal{N}(0,1)$, $V \\sim \\mathcal{N}(0,1)$。\n- 观测协变量：$X \\sim \\mathcal{N}(0,1)$。\n- 对撞因子：$C = \\gamma_U U + \\gamma_V V + \\varepsilon_C$，其中 $\\varepsilon_C \\sim \\mathcal{N}(0,1)$。\n- 处理分配：$T \\sim \\text{Bernoulli}(\\text{logit}^{-1}(\\alpha_0 + \\alpha_U U + \\alpha_X X))$。\n- 结果：$Y = \\beta_T T + \\beta_V V + \\beta_X X + \\varepsilon_Y$，其中 $\\varepsilon_Y \\sim \\mathcal{N}(0,1)$。\n\n真实 ATE 由系数 $\\beta_T$ 给出。变量 $X$ 作为处理的一个观测预测因子（$X \\rightarrow T$）被包含在内。在给定的测试用例中，$\\beta_X=0$，所以 $X$ 不是一个混杂因子（即，不存在开放的后门路径 $T \\leftarrow X \\rightarrow Y$）。尽管如此，将处理的预测因子包含在倾向得分模型中是标准做法。“正确”的倾向得分模型包括那些能够阻断 $T$ 和 $Y$ 之间所有后门路径且不会打开新路径的预测因子。在这里，这意味着要对 $X$ 进行调整，但关键是不能对对撞因子 $C$ 进行调整。\n\n### 模拟与估计过程\n\n对于每个测试用例，执行以下步骤：\n\n1.  **数据生成**：基于结构方程和指定参数，模拟一个包含 $N$ 个观测值的数据集。固定的随机种子确保了可复现性。变量 $U, V, X, \\varepsilon_C, \\varepsilon_Y$ 从标准正态分布中抽取。然后根据其定义构建对撞因子 $C$、二元处理 $T$ 和连续结果 $Y$。\n\n2.  **倾向得分估计**：倾向得分 $e(Z) = P(T=1|Z)$ 使用两个不同的逻辑斯谛回归模型进行估计，其中 $Z$ 是协变量集合。模型系数通过使用数值优化算法（BFGS）最大化对数似然函数来估计。\n    - **错误模型**：在协变量集合中包含对撞因子 $C$，即 $Z = \\{X, C\\}$。估计的倾向得分为 $\\hat{e}_{\\text{incl}}(X, C)$。由于对对撞因子进行了条件化，预计该模型会产生有偏倚的结果。\n    - **正确模型**：排除对撞因子，即 $Z = \\{X\\}$。估计的倾向得分为 $\\hat{e}_{\\text{excl}}(X)$。该模型避免了 M-偏倚。\n\n3.  **通过匹配估计 ATE**：对于两个估计的倾向得分中的每一个，使用对称的、有放回的、带卡尺的最近邻匹配来计算 ATE 的匹配估计值。\n    - **对称匹配**：为了估计 ATE（而不是 ATT 或 ATC），从两个方向寻找匹配。对于每个处理单元，找到距离最近的控制单元（以倾向得分距离衡量）。对称地，对于每个控制单元，找到距离最近的处理单元。\n    - **卡尺**：只有当一对单元的倾向得分绝对差值在指定的卡尺值之内时，才认为它们是有效的匹配。\n    - **后备方案**：如果没有配对满足卡尺条件，则以无限大的卡尺（即，无论距离多远都寻找最近邻）重复该过程。\n    - **估计量**：ATE 被估计为在两个匹配方向上找到的所有有效匹配对的结果差异 $Y_{\\text{treated}} - Y_{\\text{control}}$ 的简单算术平均值。\n\n4.  **偏倚分析**：通过计算每个估计量的偏倚来评估其性能，偏倚是估计值与真实 ATE（$\\beta_T$）之间的差异。\n    - 偏倚（包含对撞因子）：$b_{\\text{incl}} = \\widehat{\\text{ATE}}_{\\text{incl}} - \\beta_T$。\n    - 偏倚（排除对撞因子）：$b_{\\text{excl}} = \\widehat{\\text{ATE}}_{\\text{excl}} - \\beta_T$。\n    - 额外绝对偏倚：$\\Delta = |b_{\\text{incl}}| - |b_{\\text{excl}}|$。正的 $\\Delta$ 表明包含对撞因子放大了估计偏倚，从而证明了 M-偏倚的有害影响。\n\n模拟预期将显示，当对撞因子路径强度（$\\gamma_U, \\gamma_V$）非零时，$|b_{\\text{incl}}|$ 将显著大于 $|b_{\\text{excl}}|$，并且这个差异 $\\Delta$ 会随着对撞因子强度的增加而增加。当 $\\gamma_U = \\gamma_V = 0$ 时，M-结构不存在，两个模型应产生相似的、低偏倚的估计，导致 $\\Delta$ 接近于零。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.special import expit\n\ndef _logistic_regression(X_design, y_obs):\n    \"\"\"\n    Performs logistic regression using maximum likelihood estimation.\n    \"\"\"\n    def neg_log_likelihood(beta, X, y):\n        \"\"\"\n        Calculates the negative log-likelihood for a logistic model.\n        Uses np.logaddexp for numerical stability.\n        L = sum(y*z - log(1+exp(z))) where z = X @ beta\n        \"\"\"\n        linear_pred = X @ beta\n        log_likelihood = np.sum(y * linear_pred - np.logaddexp(0, linear_pred))\n        return -log_likelihood\n\n    initial_beta = np.zeros(X_design.shape[1])\n    result = minimize(\n        neg_log_likelihood,\n        initial_beta,\n        args=(X_design, y_obs),\n        method='BFGS'\n    )\n    return result.x\n\ndef _perform_matching(T, Y, ps, caliper):\n    \"\"\"\n    Performs symmetric nearest-neighbor matching and computes the ATE estimate.\n    \"\"\"\n    def find_matches(source_indices, target_indices, ps, T_full, Y_full, caliper_val):\n        \"\"\"Helper to find matches for a source group from a target group.\"\"\"\n        ps_source = ps[source_indices]\n        ps_target = ps[target_indices]\n        \n        # Sort target for efficient search\n        sort_map = np.argsort(ps_target)\n        ps_target_sorted = ps_target[sort_map]\n        \n        # Find insertion points for all source PSs into the sorted target PSs\n        insert_points = np.searchsorted(ps_target_sorted, ps_source)\n        \n        matched_diffs = []\n        for i, ps_s in enumerate(ps_source):\n            idx = insert_points[i]\n            \n            best_dist = np.inf\n            best_match_target_original_idx = -1\n\n            # Candidate 1: at insertion point\n            if idx  len(ps_target_sorted):\n                dist = np.abs(ps_s - ps_target_sorted[idx])\n                if dist  best_dist:\n                    best_dist = dist\n                    best_match_target_original_idx = target_indices[sort_map[idx]]\n\n            # Candidate 2: at insertion point - 1\n            if idx  0:\n                dist = np.abs(ps_s - ps_target_sorted[idx-1])\n                if dist  best_dist:\n                    best_dist = dist\n                    best_match_target_original_idx = target_indices[sort_map[idx-1]]\n\n            source_original_idx = source_indices[i]\n            if best_match_target_original_idx != -1 and best_dist = caliper_val:\n                if T_full[source_original_idx] == 1: # Source is treated\n                    y_diff = Y_full[source_original_idx] - Y_full[best_match_target_original_idx]\n                else: # Source is control\n                    y_diff = Y_full[best_match_target_original_idx] - Y_full[source_original_idx]\n                matched_diffs.append(y_diff)\n        return matched_diffs\n\n    treated_indices = np.where(T == 1)[0]\n    control_indices = np.where(T == 0)[0]\n\n    # Guard against empty treatment/control groups\n    if len(treated_indices) == 0 or len(control_indices) == 0:\n        return np.nan\n\n    # Run with the given caliper\n    all_diffs = []\n    # T - C matching\n    all_diffs.extend(find_matches(treated_indices, control_indices, ps, T, Y, caliper))\n    # C - T matching\n    all_diffs.extend(find_matches(control_indices, treated_indices, ps, T, Y, caliper))\n    \n    # If no matches found, re-run with infinite caliper\n    if not all_diffs:\n        all_diffs.extend(find_matches(treated_indices, control_indices, ps, T, Y, np.inf))\n        all_diffs.extend(find_matches(control_indices, treated_indices, ps, T, Y, np.inf))\n        \n    return np.mean(all_diffs) if all_diffs else np.nan\n\ndef solve():\n    \"\"\"\n    Main function to run the M-bias simulation across all test cases.\n    \"\"\"\n    test_cases = [\n        {'N': 4000, 'alpha_0': 0.0, 'alpha_U': 1.0, 'alpha_X': 0.5, 'beta_T': 2.0, \n         'beta_V': 1.0, 'beta_X': 0.0, 'gamma_U': 0.8, 'gamma_V': 0.8, \n         'caliper': 0.05, 'seed': 42},\n        {'N': 4000, 'alpha_0': 0.0, 'alpha_U': 1.0, 'alpha_X': 0.5, 'beta_T': 2.0, \n         'beta_V': 1.0, 'beta_X': 0.0, 'gamma_U': 0.0, 'gamma_V': 0.0, \n         'caliper': 0.05, 'seed': 1},\n        {'N': 4000, 'alpha_0': 0.0, 'alpha_U': 1.2, 'alpha_X': 0.5, 'beta_T': 2.0, \n         'beta_V': 1.0, 'beta_X': 0.0, 'gamma_U': 2.5, 'gamma_V': 2.5, \n         'caliper': 0.05, 'seed': 7},\n        {'N': 600, 'alpha_0': 0.0, 'alpha_U': 1.0, 'alpha_X': 0.5, 'beta_T': 2.0, \n         'beta_V': 1.0, 'beta_X': 0.0, 'gamma_U': 1.0, 'gamma_V': 1.0, \n         'caliper': 0.07, 'seed': 123}\n    ]\n\n    results = []\n    for params in test_cases:\n        # Set seed for reproducibility\n        rng = np.random.default_rng(params['seed'])\n        N = params['N']\n\n        # 1. Simulate data according to the DGP\n        U = rng.normal(size=N)\n        V = rng.normal(size=N)\n        X = rng.normal(size=N)\n        eps_C = rng.normal(size=N)\n        C = params['gamma_U'] * U + params['gamma_V'] * V + eps_C\n        \n        linear_pred_T = params['alpha_0'] + params['alpha_U'] * U + params['alpha_X'] * X\n        prob_T = expit(linear_pred_T)\n        T = rng.binomial(1, prob_T)\n        \n        eps_Y = rng.normal(size=N)\n        Y = params['beta_T'] * T + params['beta_V'] * V + params['beta_X'] * X + eps_Y\n\n        # 2. Estimate two propensity score models\n        # Incorrect model (including collider)\n        X_incl = np.c_[np.ones(N), X, C]\n        coeffs_incl = _logistic_regression(X_incl, T)\n        ps_incl = expit(X_incl @ coeffs_incl)\n\n        # Correct model (excluding collider)\n        X_excl = np.c_[np.ones(N), X]\n        coeffs_excl = _logistic_regression(X_excl, T)\n        ps_excl = expit(X_excl @ coeffs_excl)\n        \n        # 3. Perform matching and estimate ATE for both models\n        ate_incl = _perform_matching(T, Y, ps_incl, params['caliper'])\n        ate_excl = _perform_matching(T, Y, ps_excl, params['caliper'])\n        \n        # 4. Compute bias\n        true_ate = params['beta_T']\n        b_incl = ate_incl - true_ate\n        b_excl = ate_excl - true_ate\n        \n        # 5. Compute excess absolute bias\n        delta = np.abs(b_incl) - np.abs(b_excl)\n        \n        results.append([b_incl, b_excl, delta])\n\n    # Final print statement in the exact required format.\n    output_str = \",\".join([f\"[{r[0]},{r[1]},{r[2]}]\" for r in results])\n    print(f\"[{output_str}]\")\n\nsolve()\n```", "id": "3162896"}]}