## 引言
在观察性医学研究中，推断治疗或暴露与结局之间的因果关系是一项核心挑战。与随机对照试验不同，观察性数据的治疗组和[对照组](@entry_id:188599)往往在基线特征上存在系统性差异，这些差异即“混杂因素”，可能严重扭曲我们对真实效应的估计，导致错误的科学结论。因此，有效控制混杂偏倚是获得可信因果推断的先决条件。本文旨在深入探讨两种最基本且功能强大的混杂控制方法：分层与匹配。

本文将系统性地引导读者掌握这些关键技术。在第一部分“原理与机制”中，我们将奠定理论基础，阐明混杂的本质、控制混杂的核心思想以及分层与匹配的具体实现机制，包括现代的倾向性评分方法。随后，在第二部分“应用与跨学科联系”中，我们将展示这些方法如何在临床流行病学、基因组学等不同领域解决实际问题，并讨论如何诊断和优化分析过程。最后，第三部分“动手实践”将通过具体的计算练习，帮助读者将理论知识转化为实践技能。通过这一结构化的学习路径，读者将能够充满信心地在自己的研究中应用分层与匹配，以应对观察性数据带来的挑战。

## 原理与机制

在医学研究中，我们常常希望从观察性数据中推断治疗或暴露（Exposure）对结局（Outcome）的因果效应。然而，与随机对照试验（RCT）不同，[观察性研究](@entry_id:174507)中的治疗组和[对照组](@entry_id:188599)在诸多基线特征上可能存在系统性差异。某些特征既影响患者接受何种治疗，又影响其临床结局，这类特征被称为**混杂因素（Confounders）**。如果不对这些因素进行恰当控制，它们就会歪曲治疗与结局之间观察到的关联，产生**混杂偏倚（Confounding Bias）**，从而导致错误的因果推断。本章将深入探讨控制混杂偏倚的两个核心方法——分层与匹配——的基本原理、关键假设和实现机制。

### 混杂偏倚问题

为了精确地定义因果效应，我们引入**潜在结局（Potential Outcomes）**框架。对于一个个体，我们定义$Y(1)$为其接受治疗（以$A=1$表示）时的潜在结局，而$Y(0)$为其未接受治疗（以$A=0$表示）时的潜在结局。在人群层面，我们关心的**平均治疗效应（Average Treatment Effect, ATE）**是$E[Y(1) - Y(0)]$。然而，对于任何一个个体，我们最多只能观测到这两个潜在结局中的一个，这构成了因果推断的根本难题。

在[观察性研究](@entry_id:174507)中，直接比较观测结局的均值，即$E[Y | A=1] - E[Y | A=0]$，通常不能作为ATE的[无偏估计](@entry_id:756289)。这是因为治疗组和[对照组](@entry_id:188599)的选择并非随机，混杂因素的存在使得两组在治疗开始前就不具可比性。

我们可以借助**有向无环图（Directed Acyclic Graphs, DAGs）**来更直观地理解混杂。假设存在一个或一组基线变量$L$，它既是治疗决策$A$的原因（$L \rightarrow A$），也是结局$Y$的原因（$L \rightarrow Y$）。在这种结构中，$L$就是一个混杂因素，它构成了一条从$A$到$Y$的非因果路径，即所谓的**后门路径（Backdoor Path）**：$A \leftarrow L \rightarrow Y$。[@problem_id:4973487] [@problem_id:4973486] 这条路径的存在会诱导$A$和$Y$之间产生虚假的关联，从而污染我们对真实因果路径$A \rightarrow Y$效应的估计。控制混杂的本质，就是要设法“阻断”所有这样的后门路径。

### 控制混杂的核心思想：条件化

阻断后门路径的核心策略是**条件化（Conditioning）**，即在混杂因素$L$的特定水平上进行分析。其背后的思想是：如果我们将人群根据$L$的值进行划分，在每个$L$的子集（或称“层”）内，$L$不再变化，因此它无法再作为$A$和$Y$的共同原因来产生混杂。为了使这一策略在数学上严谨可行，我们需要满足三个核心的**可识别性假设（Identifiability Assumptions）**。[@problem_id:4973446]

1.  **条件[可交换性](@entry_id:263314)（Conditional Exchangeability）**：在给定混杂因素集$L$的条件下，潜在结局与实际接受的治疗是独立的，记作$(Y(1), Y(0)) \perp A \mid L$。这一假设也常被称为**可忽略性（Ignorability）**或**无未观测混杂（No Unmeasured Confounding）**。它的直观含义是：在任何一个由$L$定义的亚组内，接受治疗的个体与未接受治疗的个体，除了所受治疗不同外，在所有其他影响结局的方面都是可比的，就如同进行了一次小型的随机试验。这是控制混杂偏倚的基石。

2.  **正性（Positivity）**：对于$L$的每一个存在于目标人群中的值$l$，接受任意一种治疗水平的概率都严格大于零，即对于所有的$a \in \{0, 1\}$和所有满足$P(L=l) > 0$的$l$，都有$P(A=a \mid L=l) > 0$。这一假设也称为**重叠性（Overlap）**或**共同支撑（Common Support）**。它确保了在$L$的每一个层内，我们总能找到接受治疗和未接受治疗的个体，从而使得比较成为可能。

3.  **一致性（Consistency）**：一个个体实际观测到的结局$Y$，等于其在实际所接受的治疗水平下的潜在结局。如果一个个体接受了治疗$A=a$，那么其观测结局$Y$就等于$Y(a)$。这一假设将我们无法完全观测的潜在结局世界与我们能够观测到的现实数据联系起来。它通常与“无多版本治疗”和“无个体间干扰”等假设一同被归纳在稳定单位治疗价值假设（SUTVA）之下。

在满足这三个假设的前提下，我们就可以通过对观测数据进行条件化操作，来无偏地估计因果效应。

### 方法一：分层分析

**分层（Stratification）**是实现条件化最直接的方法。它将整个研究人群根据混杂因素$L$的不同取值（或取值范围）分割成若干个互不重叠的子群或“层”。

#### 原理与步骤

分层分析的逻辑十分清晰：在每个由$L=l_i$定义的第$i$层内部，混杂因素$L$是一个常数，因此后门路径$A \leftarrow L \rightarrow Y$被阻断。于是，在每一层内，治疗$A$与结局$Y$之间的关联就不再受到$L$的混杂。其具体步骤如下：[@problem_id:4973468]

1.  **构建分层列联表**：对于一个离散的混杂因素$L$（具有$K$个水平），我们将数据划分为$K$个层。在每个第$i$层（$L=l_i$）中，我们可以构建一个关于治疗$A$和结局$Y$的$2 \times 2$列联表，其单元格计数为$a_i, b_i, c_i, d_i$。

2.  **计算层内效应**：在每一层内，我们可以计算一个层特异性的效应量，例如风险差（Risk Difference, RD）、风险比（Risk Ratio, RR）或比值比（Odds Ratio, OR）。例如，第$i$层的风险差为$RD_i = P(Y=1|A=1, L=l_i) - P(Y=1|A=0, L=l_i)$。由于层内混杂已被控制，这个值可以作为该层因果效应的一致估计。

3.  **合并效应估计**：为了得到一个概括性的总体效应估计，我们需要将各层的效应量进行合并。一个常用的方法是**标准化（Standardization）**，即以某个标准人群中$L$的分布作为权重，对层特异性效应进行加权平均。例如，标准化的风险差可以计算为$\sum_{i=1}^{K} RD_i \times P(L=l_i)$，其中$P(L=l_i)$是$L$在目标人群中的分布。

#### [辛普森悖论](@entry_id:136589)：一个典型的混杂实例

分层分析的力量可以通过**[辛普森悖论](@entry_id:136589)（Simpson's Paradox）**得到生动展示。该悖论描述了在整体人群中观察到的关联方向，与在所有子群中观察到的方向完全相反的现象。这通常是严重混杂的标志。

考虑一项评估新型抗凝药（$A=1$）相对于不治疗（$A=0$）对房颤患者30天内卒中（$Y=1$）影响的[观察性研究](@entry_id:174507)。患者的基线严重程度评分$L$是一个混杂因素，因为病情更严重的患者（$L=1$）卒中风险更高，同时也更可能被医生给予新药治疗（即存在“因适应证混杂”）。研究数据可能呈现如下模式：[@problem_id:4973486]
- 在低风险组（$L=0$）中，治疗组的卒中风险（如2%）低于[对照组](@entry_id:188599)（如5%），表明治疗有益。
- 在高风险组（$L=1$）中，治疗组的卒中风险（如20%）也低于[对照组](@entry_id:188599)（如30%），同样表明治疗有益。

然而，当忽略$L$合并数据时，我们可能会发现治疗组的总体卒中风险（如18.2%）显著高于[对照组](@entry_id:188599)（如7.8%），得出治疗有害的错误结论。这种逆转的发生，正是因为治疗组中绝大多数是高风险患者，而[对照组](@entry_id:188599)中绝大多数是低风险患者。分层分析揭示了真实的、在同质风险人群中的治疗效应，而合并分析则被$L$的混杂效应严重误导。

#### 对正性假设的深入探讨

分层分析的有效性严重依赖于**正性假设**。如果该假设被违背，分层分析将无法进行。例如，在一项研究中，某种药物因其已知的副作用而对有严重肾功能损害（由$L$中的一个指标表示）的患者属于绝对禁忌症。这意味着，在“严重肾损害”这个层内，我们永远观测不到服药的患者，即$P(A=1 \mid L=\text{严重肾损害}) = 0$。[@problem_id:4973493]

这种**结构性违背（Structural Violation）**导致我们无法在该层内计算治疗效应，因为缺少对照数据。进而，我们也无法计算在全人群中的平均治疗效应（ATE）。一种务实的应对策略是**改变研究的目标estimand**。我们可以将分析人群限定在满足正性假设的子人群（例如，没有严重肾损害的患者）中，此时我们估计的就不再是全人群的ATE，而是在这个“重叠人群”中的ATE。

此外，即使正性假设在理论上成立，**实践中的近乎违背（Near-Violation）**也可能带来问题。如果在某一层中，治疗组（或[对照组](@entry_id:188599)）的个体非常少，那么该层效应的估计将会非常不稳定（即方差极大），这会影响到最终合并效应估计的精度。[@problem_id:4973493]

### 方法二：匹配

**匹配（Matching）**是另一种实现条件化的直观方法。其核心思想是为每个接受治疗的个体，从不接受治疗的个体中，寻找一个或多个在所有相关混杂因素$L$上与其“相似”或“相同”的个体，组成配对或匹配集。通过这种方式，我们旨在构建一个与治疗组在混杂因素分布上具有可比性的新[对照组](@entry_id:188599)。

#### 匹配的类型与分析策略

匹配策略多种多样，其选择会直接影响后续的分析方法。[@problem_id:4973505]

-   **个体匹配（Individual Matching）**，特别是**精确匹配（Exact Matching）**，要求为每个案例（或治疗者）找到一个或多个在所有匹配变量$L$上取值完全相同的对照。这相当于创建了许多极细的“层”，每个匹配集（如一个配对）就是一个独立的层。由于每个层内的个体极少，分析时必须采用**条件性方法（Conditional Methods）**，例如条件逻辑斯蒂回归。这种方法可以消除每个匹配集特有的基线风险（作为“滋扰参数”），从而得到无偏的效应估计。
-   **频率匹配（Frequency Matching）**则不要求个体间的精确配对。它旨在通过抽样，使得最终[对照组](@entry_id:188599)中混杂因素$L$的**[边际分布](@entry_id:264862)**与案例组（或治疗组）相同。例如，如果案例组中有20%的男性，那么就抽取对照者直至[对照组](@entry_id:188599)中男[性比](@entry_id:172643)例也达到20%。由于没有形成固定的匹配集，频率匹配后的数据通常采用标准的**非条件性方法（Unconditional Methods）**进行分析，例如，在多变量回归模型中将$L$作为协变量进行调整，或进行标准的分层分析（如Mantel-Haenszel方法）。

在病例-对照研究中，对匹配因素的处理尤为重要。如果进行了个体匹配，忽略匹配关系而进行非条件逻辑斯蒂回归，会导致效应估计偏向于零。正确的做法是使用条件逻辑斯蒂回归，其分析本质上仅利用那些在暴露状态上不一致的配对（即病例暴露而对照未暴露，或反之）来估计比值比。[@problem_id:4973468]

#### 高维挑战与倾向性评分

当混杂因素$L$的维度很高时（即包含许多变量），精确匹配几乎不可能实现，这就是所谓的**“[维度灾难](@entry_id:143920)”（Curse of Dimensionality）**。[@problem_id:4973440] 为了克服这一难题，Rosenbaum 和 Rubin 提出了**倾向性评分（Propensity Score）**。

倾向性评分$e(L)$定义为在给定基线协变量$L$的条件下，一个个体接受治疗的概率，即$e(L) = P(A=1 \mid L)$。它具有一个优美的性质：它是一个**平衡评分（Balancing Score）**。这意味着，在倾向性评分取值相同的个体之间，协变量$L$的分布在治疗组和[对照组](@entry_id:188599)之间是平衡的，即$L \perp A \mid e(L)$。因此，倾向性评分巧妙地将控制多个混杂因素$L$的高维问题，简化为控制一个一维标量$e(L)$的问题。[@problem_id:4973440]

基于倾向性评分，最常用的匹[配方法](@entry_id:265480)是**最近邻倾向性评分匹配（Nearest Neighbor Propensity Score Matching）**。[@problem_id:4973436] 其基本操作是：为每个治疗组个体$i$，在[对照组](@entry_id:188599)中寻找一个倾向性评分$e(X_j)$与其评分$e(X_i)$最接近的个体$j$。这一过程可以有不同变体：

-   **有放回匹配（Matching with Replacement）**：一个[对照组](@entry_id:188599)个体可以被重复匹配给多个治疗组个体。这种方法通常能为每个治疗者找到更好的匹配，从而降低偏倚，但由于某些对照者被多次使用，有效样本量减小，可能导致估计的方差增大。
-   **无放回匹配（Matching without Replacement）**：每个[对照组](@entry_id:188599)个体最多只能被使用一次。这保证了估计的方差较小，但可能因为优质对照者被“用掉”，导致后匹配的治疗者只能与次优的对照者配对，从而增加偏倚。
-   **卡尺（Caliper）**：为了避免质量极差的匹配，可以设置一个“卡尺”$\delta$，要求配对双方的倾向性评分之差不能超过$\delta$。找不到满足条件的匹配的个体将被丢弃。

匹配完成后，特别是对于有放回匹配，由于引入了复杂的样本相关性（多个治疗者共享同一个对照者），必须使用能够处理这种聚类结构的方差估计方法（如稳健性三明治方差估计），以获得有效的统计推断。[@problem_id:4973436]

### 高阶主题与实践考量

在应用分层与匹配时，还需注意一些更深层次的概念与实践问题。

#### 混杂与效应修饰的辨析

**效应修饰（Effect Modification）**是指治疗的因果效应大小本身依赖于第三个变量（效应修饰因子）的水平。例如，某药物对男性和女性的疗效不同。效应修饰描述的是效应的“异质性”，而混杂描述的是关联的“虚假性”。

在随机试验中，由于随机化保证了任何基线变量（包括潜在的效应修饰因子$L$）与治疗分配$A$相互独立，因此不存在混杂。此时，如果对一个效应修饰因子$L$进行匹配，并不会减少任何偏倚（因为原本就没有），但它会改变研究的目标estimand。原始的随机试验估计的是全人群的平均治疗效应$\mathbb{E}[Y^1 - Y^0]$。匹配后，我们得到的是一个新的人群（其$L$的分布已被改变）中的平均治疗效应$\mathbb{E}_m[Y^1 - Y^0]$。如果治疗效应确实随$L$变化（即$\beta_{AL} \ne 0$），那么这两个estimand将会不同。[@problem_id:4973423]

#### 如何选择正确的调整变量集：DAG 的应用

在更复杂的现实场景中，我们测量的变量可能不全是混杂因素。使用DAG和**[后门准则](@entry_id:637856)（Backdoor Criterion）**可以帮助我们识别一个**最小充分调整集（Minimal Sufficient Adjustment Set）**。该准则要求我们选择一个变量集，它能阻断所有$A$与$Y$之间的后门路径，并且该集合中的任何变量都不是$A$的后代。不恰当的调整会引入新的偏倚。[@problem_id:4973487]

-   **中介变量（Mediators）**：位于$A$到$Y$因果路径上的变量（如$A \rightarrow M \rightarrow Y$）。调整中介变量会阻断部分因果效应，导致对**总效应（Total Effect）**的估计产生偏倚。
-   **对撞因子（Colliders）**：作为两个变量共同效应的变量（如$A \rightarrow C \leftarrow U$）。调整对撞因子会打开一条原本被阻断的非因果路径，从而**引入**偏倚，这种现象称为对撞分层偏倚（collider-stratification bias）。
-   **[工具变量](@entry_id:142324)（Instruments）**：仅通过影响治疗选择$A$来影响结局的变量（如$Z \rightarrow A$）。在控制了所有混杂因素后，额外调整工具变量对于消除偏倚无益，但它会减少用于估计效应的治疗变量$A$的有效变异，从而**增大**效应估计量的方差，降低[统计效率](@entry_id:164796)。

#### 比值比的不可坍缩性

在效应度量中，比值比（OR）具有一个独特的数学性质——**不可坍缩性（Non-collapsibility）**。这意味着，即使在没有混杂的情况下（如随机试验中），如果存在一个与结局相关的协变量$X$（即预后因素），那么在$X$各层上恒定的条件OR，通常也不等于边际（即未调整的）OR。[@problem_id:4973471] 边际OR会被“拉向”无效值（1.0）。这并非一种偏倚，而是OR这一统计量本身的数学特性。理解这一点至关重要，因为它解释了为何在逻辑斯蒂[回归分析](@entry_id:165476)中，即使不存在混杂，引入一个强预后因素到模型中，也会改变治疗变量的系数（即对数OR）。

#### 估计倾向性评分的影响

最后，值得注意的是，在实践中倾向性评分是未知的，必须从数据中**估计**得到。使用估计的倾向性评分$\hat{e}(L)$会对最终效应估计的统计性质产生影响。如果使用传统的参数模型（如逻辑斯蒂回归）来估计$\hat{e}(L)$，它可能会给效应估计量带来额外的方差。[@problem_id:4973440] 如果使用更灵活的机器学习方法来估计，其较慢的[收敛速度](@entry_id:146534)可能导致[估计误差](@entry_id:263890)传递到最终的效应估计中，使其[统计推断](@entry_id:172747)失效。现代因果推断方法，如**交叉拟合（Cross-fitting）**，被提出来解决这类问题，以确保即使在使用复杂的[机器学习模型](@entry_id:262335)估计倾向性评分时，我们仍能对因果效应进行有效的[统计推断](@entry_id:172747)。[@problem_id:4973440]

综上所述，分层与匹配是通过条件化思想控制混杂的有力工具。它们的应用不仅需要对基本原理的深刻理解，还需要[对相关](@entry_id:203353)假设的审慎评估以及对各种实践细节的周全考虑。