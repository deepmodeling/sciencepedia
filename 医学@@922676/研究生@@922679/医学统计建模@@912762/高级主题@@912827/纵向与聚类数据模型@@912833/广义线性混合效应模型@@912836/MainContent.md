## 引言
在现代医学研究中，数据往往呈现出复杂的结构，例如来自多中心试验的分层数据、追踪患者病程的纵向数据，以及诸如感染状态（二元）或并发症次数（计数）等非正态分布的结果。传统的[线性模型](@entry_id:178302)或广义线性模型难以同时应对数据的相关性与[非正态性](@entry_id:752585)，这构成了一个显著的分析挑战。广义线性混合效应模型（GLMM）应运而生，它通过一个统一的框架整合了随机效应以处理相关性，并利用连结函数处理非正态结果，已成为医学统计领域不可或缺的工具。本文旨在为读者提供一个关于GLMM的系统性指南。在第一章“原理与机制”中，我们将解构GLMM的核心组件和统计特性。随后，在“应用与跨学科联系”一章中，我们将通过丰富的案例展示其在各种研究场景下的威力。最后，“动手实践”部分将通过具体问题巩固您的理解。现在，让我们从构建GLMM的基础——其核心原理与机制——开始探索。

## 原理与机制

在深入研究广义线性混合效应模型（Generalized Linear Mixed-effects Models, GLMMs）的应用之前，我们必须首先理解其核心的原理和机制。本章将解构 GLMM 的基本组成部分，阐明其如何处理非正态和相关的医学数据，并探讨其参数解释和计算方法中的关键概念。

### 广义线性混合效应模型的定义

广义线性混合效应模型（GLMM）是两个强大统计框架的融合：[广义线性模型](@entry_id:171019)（Generalized Linear Models, GLMs）和线性混合效应模型（Linear Mixed Models, LMMs）。GLM 扩展了经典[线性模型](@entry_id:178302)，以处理非正态的响应变量（如二元、计数或偏态连续数据），而 LMM 则通过引入随机效应来对数据中的相关性和聚类结构进行建模。GLMM 将这两者结合起来，为分析具有层次结构（例如，患者嵌套在医院中）且结果非正态的复杂医学数据提供了统一的框架。

#### 核心组成部分：线性预测器与随机效应

一个 GLMM 的核心在于其**线性预测器**（linear predictor）$ \eta $，它以加性方式组合了**固定效应**（fixed effects）和**随机效应**（random effects）。对于嵌套在聚类 $j$ 中的观测单元 $i$（例如，医院 $j$ 中的患者 $i$），其[线性预测](@entry_id:180569)器 $ \eta_{ij} $ 通常写为：

$ g(\mathbb{E}[Y_{ij} \mid \boldsymbol{b}]) = \eta_{ij} = \boldsymbol{x}_{ij}^{\top}\boldsymbol{\beta} + \boldsymbol{z}_{ij}^{\top}\boldsymbol{b}_j $

让我们仔细剖析这个表达式的每个部分：

1.  **响应变量与连结函数**：$ Y_{ij} $ 是观测结果。与 GLM 一样，我们不对 $ Y_{ij} $ 本身直接建模，而是对其在给定随机效应 $ \boldsymbol{b} $ 下的条件期望 $ \mathbb{E}[Y_{ij} \mid \boldsymbol{b}] $ 进行建模。**连结函数** (link function) $ g(\cdot) $ 将这个条件期望（例如，[二元结果](@entry_id:173636)的概率或计数结果的均值）映射到[线性预测](@entry_id:180569)器 $ \eta_{ij} $ 的尺度上。例如，对于二元感染结果，我们通常使用对数优势比（logit）连结函数，即 $ g(\mu) = \ln(\mu / (1-\mu)) $。

2.  **固定效应 ($ \boldsymbol{x}_{ij}^{\top}\boldsymbol{\beta} $)**：这部分代表了模型中具有普遍性、固定不变的效应。$ \boldsymbol{\beta} $ 是一个 $ p \times 1 $ 的系数向量，代表了人群平均水平上的效应大小。$ \boldsymbol{x}_{ij} $ 是一个 $ p \times 1 $ 的协变量向量，它构成了**固定效应[设计矩阵](@entry_id:165826)** $ \boldsymbol{X} $ 的一行。这个矩阵包含了所有我们希望估计其平均效应的变量，例如治疗分配、患者年龄、性别，甚至是聚类级别的协变量（如医院是否为教学医院）。通常，固定效应部分包含一个截距项（即 $ \boldsymbol{x}_{ij} $ 的第一个元素为 1），代表了基线水平的平均响应（在连结函数尺度上）。[@problem_id:4965312]

3.  **随机效应 ($ \boldsymbol{z}_{ij}^{\top}\boldsymbol{b}_j $)**：这部分是 GLMM 的精髓所在，用于捕捉数据中的相关性。$ \boldsymbol{b}_j $ 是一个 $ q \times 1 $ 的向量，代表了聚类 $j$ 特有的、未被固定效应解释的随机偏离。$ \boldsymbol{z}_{ij} $ 是一个 $ q \times 1 $ 的协变量向量，构成了**随机效应设计矩阵** $ \boldsymbol{Z} $ 的一部分，它指明了随机效应 $ \boldsymbol{b}_j $如何影响观测 $Y_{ij} $。

最常见的随机效应是**随机截距**（random intercept）。在这种模型中，每个聚类 $ j $ 都有一个自己独特的截距偏移量 $ b_j $ (此时 $ q=1 $)，该偏移量是对固定截距 $ \beta_0 $ 的调整。对于医院 $ j $ 中的所有患者 $ i $，他们共享同一个随机截距 $ b_j $。在这种情况下，随机效应设计向量 $ \boldsymbol{z}_{ij} $ 对于医院 $ j $ 中的所有患者都是一个常数 1，而整个设计矩阵 $ \boldsymbol{Z} $ 则是一个指示矩阵，其第 $j$ 列在对应于医院 $j$ 的患者的行上为 1，其他地方为 0。这种“[独热编码](@entry_id:170007)”结构确保了[线性预测](@entry_id:180569)器 $ \eta_{ij} $ 中包含了正确的医院特异性效应 $ b_j $。[@problem_id:4965312]

#### 随机效应的分布假设

我们不直接估计每个 $ b_j $，而是假设它们是从某个概率分布中抽取的随机变量。标准假设是，随机效应向量 $ \boldsymbol{b}_j $ 相互独立，且服从一个均值为零的[多元正态分布](@entry_id:175229)：

$ \boldsymbol{b}_j \sim \mathcal{N}(\boldsymbol{0}, \boldsymbol{G}) $

其中，$ \boldsymbol{G} $ 是一个 $ q \times q $ 的协方差矩阵，其对角[线元](@entry_id:196833)素代表了随机效应的方差（例如，随机截距的院间方差 $ \sigma_b^2 $），非对角线元素代表了不同随机效应之间的协方差（例如，随机截距和随机斜率之间的协方差）。这个看似武断的假设背后有深刻的理论依据：[@problem_id:4965339]

-   **可交换性 (Exchangeability)**：在建模之初，除了已知的协变量外，我们没有理由先验地认为某家医院会比另一家医院系统性地更好或更差。这种先验的不可区分性可以用**可交换性**来形式化，即如果我们交换医院的标签，它们的[联合概率分布](@entry_id:171550)应保持不变。根据 de Finetti 定理，可交换的随机变量可以被建模为从同一个共同分布中进行的[独立同分布](@entry_id:169067)（i.i.d.）抽样。这为假设所有 $ b_j $ 来自同一个分布提供了理论基础。

-   **中心极限定理启发 (Central Limit Theorem Heuristic)**：每个聚类的特异性效应 $ b_j $ 可以被看作是大量未观测到的、微小的、近似独立的因素（如特定员工的技能、未测量的设备质量、当地文化等）累加作用的结果。中心极限定理启发我们，大量[独立随机变量](@entry_id:273896)之和（在[线性预测](@entry_id:180569)器尺度上是加性的）的分布会趋向于正态分布。因此，假设 $ b_j $ 服从正态分布是合理且自然的。

-   **可识别性 (Identifiability)**：我们将随机效应的均值设定为零，是为了保证模型的**可识别性**。如果随机效应的均值 $ \mathbb{E}[\boldsymbol{b}_j] $ 不为零，那么这个均值将无法与固定效应的截距项 $ \beta_0 $ 区分开来。例如，在线性预测器 $ \beta_0 + b_j $ 中，我们可以将 $ \mathbb{E}[b_j] $ 的任意值从 $ b_j $ 移到 $ \beta_0 $ 中，而不会改变模型的拟合。通过强制 $ \mathbb{E}[\boldsymbol{b}_j] = \boldsymbol{0} $，我们确保了 $ \boldsymbol{\beta} $ 代表“人群平均”效应，而 $ \boldsymbol{b}_j $ 代表每个聚类相对于该平均水平的“零均值偏离”。

### 混合的后果：诱导相关性与过度离散

随机效应的引入深刻地改变了模型的结构特性。虽然我们通常假设在给定随机效应 $b_j$ 的条件下，同一聚类内的观测是独立的，但从边际（marginal）角度看，它们却是相关的。

#### 从条件独立到边际相关

这是理解 GLMM 运作机制的关键。随机效应 $b_j$ 如同一个聚类内所有观测共享的“背景环境”。来自同一家医院的两位患者，即使他们的协变量完全相同，他们的感染风险也可能因为共享了该医院的某些未观测特征（由 $b_j$ 捕捉）而趋同。

我们可以使用**全协方差定律**（Law of Total Covariance）来精确地描述这种现象。对于同一患者（聚类 $i$）在不同时间点（观测 $t$ 和 $s$）的两次观测 $Y_{it}$ 和 $Y_{is}$，其边际协方差为：

$ \mathrm{Cov}(Y_{it}, Y_{is}) = \mathbb{E}[\mathrm{Cov}(Y_{it}, Y_{is} \mid b_i)] + \mathrm{Cov}(\mathbb{E}[Y_{it} \mid b_i], \mathbb{E}[Y_{is} \mid b_i]) $

根据模型的条件独立假设，当 $t \neq s$ 时，第一项 $ \mathbb{E}[\mathrm{Cov}(Y_{it}, Y_{is} \mid b_i)] = 0 $。因此，所有的边际协方差都来自于第二项，即条件期望的协方差。因为两个时间点的[条件期望](@entry_id:159140) $ \mathbb{E}[Y_{it} \mid b_i] $ 和 $ \mathbb{E}[Y_{is} \mid b_i] $ 都依赖于同一个随机效应 $ b_i $，所以当 $ b_i $ 变化时，它们会一同变化，从而产生正的协方差。

在一个泊松对数连结的随机截距模型（$ \log(\mathbb{E}[Y_{it} | b_i]) = \boldsymbol{x}_{it}^{\top}\boldsymbol{\beta} + b_i $）中，可以推导出当 $ t \neq s $ 时：

$ \mathrm{Cov}(Y_{it}, Y_{is}) = \mu_{it}\mu_{is}(\exp(\sigma_b^2) - 1) $

其中 $ \mu_{it} $ 是 $ Y_{it} $ 的边际均值，而 $ \sigma_b^2 $ 是随机截距 $ b_i $ 的方差。只要 $ \sigma_b^2 > 0 $，这个协方差就是正的。重要的是，随机截距模型诱导出的是一种**可交换**（exchangeable）的相关结构，即同一聚类内任意两次观测之间的相关性是恒定的，不随时间间隔变化。这与某些其他方法（如使用 AR(1) 结构的广义估计方程 GEE）形成对比，后者可以指定相关性随时间滞后而衰减。[@problem_id:4965301]

#### 模拟过度离散

除了聚类间的相关性，GLMM 还能处理另一种常见的数据特征：**过度离散**（overdispersion）。过度离散是指数据的观测方差大于其理论方差。对于泊松分布，其定义特性是均值等于方差（$ \mathrm{Var}(Y) = \mathbb{E}(Y) $）。如果观测到的计数数据方差明显大于其均值，就存在过度离散。

[过度离散](@entry_id:263748)通常源于未被模型捕捉的异质性。即使在解释了聚类效应（如院间差异）后，过度离散仍可能存在，这表明在单个观测层面也存在异质性。GLMM 可以通过引入一个**观测层级随机效应**（observation-level random effect, OLRE）来优雅地处理这个问题。这相当于为每个观测 $Y_{ij}$ 添加一个独一无二的随机效应 $e_{ij}$：

$ \log(\mu_{ij}) = \boldsymbol{x}_{ij}^{\top}\boldsymbol{\beta} + b_j + e_{ij} $, 其中 $ e_{ij} \sim \mathcal{N}(0, \sigma_e^2) $

通过再次应用**[全方差定律](@entry_id:184705)**（Law of Total Variance），我们可以展示这种模型如何产生过度离散。边际方差 $ \mathrm{Var}(Y_{ij}) $ 可以分解为：

$ \mathrm{Var}(Y_{ij}) = \mathbb{E}[\mathrm{Var}(Y_{ij} \mid b_j, e_{ij})] + \mathrm{Var}(\mathbb{E}[Y_{ij} \mid b_j, e_{ij}]) $

由于条件分布是泊松的，第一项 $ \mathbb{E}[\mathrm{Var}(Y_{ij} \mid \dots)] $ 等于条件均值的期望，即 $ \mathbb{E}[\mu_{ij}] $，这正是边际均值 $ \mathbb{E}[Y_{ij}] $。第二项 $ \mathrm{Var}(\mu_{ij}) $ 是条件均值（现在是 $b_j$ 和 $e_{ij}$ 的函数）的方差。只要 $ \sigma_e^2 > 0 $，这一项就为正。因此，我们得到：

$ \mathrm{Var}(Y_{ij}) = \mathbb{E}[Y_{ij}] + \mathrm{Var}(\mu_{ij}) > \mathbb{E}[Y_{ij}] $

这表明，通过引入一个观测层级的随机效应，我们构建了一个[边际分布](@entry_id:264862)，其方差自然地大于其均值，从而恰当地描述了[过度离散](@entry_id:263748)的数据。[@problem_id:4965211]

### 模型参数的解释

对 GLMM 参数的正确解释至关重要，因为它与另一种流行的处理相关数据的方法——广义估计方程（GEE）——有着根本性的区别。

#### 条件效应 vs. [边际效应](@entry_id:634982)

GLMM 中的固定效应系数 $ \boldsymbol{\beta} $ 代表**条件**（conditional）或**特定主体**（subject-specific）的效应。它们描述的是，在保持特定聚类（例如，特定医院或特定患者）的随机效应 $b_j$ 恒定不变的情况下，协变量变化一个单位所引起的响应变化。例如，在logistic GLMM中，$\exp(\beta_{\text{trt}})$ 是一个**条件优势比**（conditional odds ratio）。它表示，对于*同一家医院*（或同一个患者），接受治疗相对于未接受治疗，其结局的优势比是多少。[@problem_id:4965293]

与此相对，GEE 等边际模型估计的是**边际**（marginal）或**人群平均**（population-averaged）的效应。[边际效应](@entry_id:634982)描述的是，在整个研究人群中，协变量变化一个单位所引起的平均响应变化。

对于非线性连结函数（如 logit 或 log），条件效应和[边际效应](@entry_id:634982)在数值上是不同的。这是因为期望算子和非线性函数不能交换顺序，即 $ \mathbb{E}[g(Y)] \neq g(\mathbb{E}[Y]) $。[边际效应](@entry_id:634982)是通过对所有随机效应的分布进行平均而得到的，这个平均过程会“稀释”或“衰减”效应，使其趋向于零。因此，通常情况下，[边际效应](@entry_id:634982)的大小会小于条件效应的大小，即 $|\beta_{\text{marginal}}|  |\beta_{\text{conditional}}|$。这意味着，由 logistic GLMM 得到的条件优势比通常会比由 GEE 得到的边际优势比更远离 1。[@problem_id:4965258]

选择哪种模型取决于研究问题：
-   如果问题是“一项干预对一个特定个体（或医院）的效果如何？”，那么 GLMM 的条件效应更具解释性。
-   如果问题是“一项干预在整个人群中推广，对人群的平均风险有什么影响？”，那么 GEE 的[边际效应](@entry_id:634982)更为直接。[@problem_id:4965258]

值得注意的是，对于线性混合模型（即使用恒等连结函数 $g(\mu)=\mu$），由于连结函数是线性的，条件效应和[边际效应](@entry_id:634982)是完全相同的。[@problem_id:4965258]

#### 报告与解释 GLMM 系数

基于上述区别，报告 GLMM 结果时必须清晰。对于一个估计出的 logistic GLMM 治疗效应系数 $ \hat{\beta}_{\text{trt}} $ 及其[标准误](@entry_id:635378) $ \text{SE}(\hat{\beta}_{\text{trt}}) $，正确的报告方式如下：[@problem_id:4965293]
1.  **[点估计](@entry_id:174544)**：计算条件优势比为 $ \widehat{\text{OR}}_{\text{cond}} = \exp(\hat{\beta}_{\text{trt}}) $。
2.  **[置信区间](@entry_id:138194)**：首先在[对数优势比](@entry_id:141427)尺度上构建 Wald [置信区间](@entry_id:138194) $ \hat{\beta}_{\text{trt}} \pm 1.96 \times \text{SE}(\hat{\beta}_{\text{trt}}) $，然后对区间的两个端点取指数，得到优势比的[置信区间](@entry_id:138194)。

例如，若 $ \hat{\beta}_{\text{trt}} = 0.35 $ 且 $ \text{SE}(\hat{\beta}_{\text{trt}}) = 0.18 $，则条件优势比为 $ \exp(0.35) \approx 1.42 $，其 95% [置信区间](@entry_id:138194)为 $ \exp(0.35 \pm 1.96 \times 0.18) $，即 $ [\exp(-0.0028), \exp(0.7028)] \approx [0.997, 2.019] $。解释为：“在控制了患者基线差异后，对于任意给定患者，接受治疗使其症状缓解的优势是未接受治疗的 1.42 倍”。

#### 预测聚类特异性效应：BLUPs 和[经验贝叶斯](@entry_id:171034)估计

GLMM 不仅能估计固定效应，还能提供关于未观测到的随机效应 $ b_j $ 的信息。这在需要评估或排序各个聚类（如医院绩效排名）时尤其有用。对 $ b_j $ 的预测值被称为**[经验贝叶斯](@entry_id:171034)（Empirical Bayes, EB）估计**。在线性混合模型的特殊情况下，它们被称为**最佳线性无偏预测（Best Linear Unbiased Predictors, BLUPs）**。[@problem_id:4965310]

EB 估计量是 $ b_j $ 的后验分布（即在给定数据 $ \boldsymbol{y}_j $ 和已估计的模型参数 $ \hat{\boldsymbol{\beta}}, \hat{\boldsymbol{G}} $ 后的分布 $ p(b_j \mid \boldsymbol{y}_j, \hat{\boldsymbol{\beta}}, \hat{\boldsymbol{G}}) $）的某个摘要统计量，通常是后验均值或[后验众数](@entry_id:174279)。从[决策论](@entry_id:265982)角度看，后验均值是[平方误差损失](@entry_id:178358)下的最优估计，而[后验中位数](@entry_id:174652)是[绝对误差损失](@entry_id:170764)下的最优估计。[@problem_id:4965310]

EB/BLUP 估计的一个标志性特征是**收缩**（shrinkage）。对 $ b_j $ 的估计本质上是两种信息的加权平均：来自聚类 $ j $ 自身数据的信息，和来自先验分布 $ \mathcal{N}(0, \boldsymbol{G}) $ 的信息（即所有聚类的总体平均水平，此处为 0）。对于数据量小或信息量少的聚类，其估计值会更多地“收缩”到总体均值 0；而对于数据量大的聚类，其估计值会更依赖于自身的数据。这种收缩特性能够稳定估计，防止因样本量小而产生极端的、不可靠的预测值。

从计算角度看，寻找 $ b_j $ 的[后验众数](@entry_id:174279)等价于最大化一个**惩罚似然**（penalized likelihood），其中惩罚项 $ -b_j^2 / (2\hat{\sigma}^2) $ 正是来自其正态先验分布的对[数密度](@entry_id:268986)。[@problem_id:4965310]

### 计算机制与挑战

拟合 GLMM 在计算上比拟合 GLM 或 LMM 更具挑战性。其核心困难在于模型似然函数的性质。

#### 棘手的似然函数

GLMM 的参数（$ \boldsymbol{\beta}, \boldsymbol{G} $）通常通过最大化观测数据的[边际似然](@entry_id:636856)函数来估计。由于随机效应 $ \boldsymbol{b} $ 是未观测到的，我们需要通过积分将其从[联合似然](@entry_id:750952)中“消掉”，以得到[边际似然](@entry_id:636856)。对于包含 $ m $ 个独立聚类的整个数据集，边际似然函数是每个聚类边际似然的乘积：

$ L(\boldsymbol{\beta},\boldsymbol{G}) = \prod_{i=1}^{m} L_i(\boldsymbol{\beta},\boldsymbol{G}) = \prod_{i=1}^{m} \int p(\boldsymbol{y}_i \mid \boldsymbol{b}_i; \boldsymbol{\beta}) \, p(\boldsymbol{b}_i; \boldsymbol{G}) \, \mathrm{d}\boldsymbol{b}_i $

这里的积分是针对随机效应 $ \boldsymbol{b}_i $ 的 $ q $ 维分布进行的。问题在于，对于非正态结果（即 GLMM 而非 LMM），这个积分通常没有**闭合解**（closed-form solution）。被积函数是条件似然 $ p(\boldsymbol{y}_i \mid \boldsymbol{b}_i; \boldsymbol{\beta}) $（例如，一串伯努利或泊松概率的乘积）与一个正态密度 $ p(\boldsymbol{b}_i; \boldsymbol{G}) $ 的乘积。这个组合通常不是任何标准分布的密度函数，因此无法解析地积分。[@problem_id:4965324]

这种似然函数的**难解性**（intractability）意味着我们必须依赖[数值近似方法](@entry_id:169303)来最大化它。

#### 近似方法

现代统计软件采用多种方法来近似上述积分：

1.  **[拉普拉斯近似](@entry_id:636859) (Laplace Approximation)**：这是一种经典方法，其基本思想是用一个[高斯函数](@entry_id:261394)来近似被积函数。具体来说，它在被积函数的对数（即 $ \log[p(\boldsymbol{y}_i, \boldsymbol{b}_i)] $）的峰值点（即 $ \boldsymbol{b}_i $ 的[后验众数](@entry_id:174279) $ \hat{\boldsymbol{b}}_i $）周围进行二阶[泰勒展开](@entry_id:145057)。由于在峰值点[一阶导数](@entry_id:749425)为零，这个展开式是一个二次函数，其指数形式就是一个[高斯函数](@entry_id:261394)的核。用这个[高斯函数](@entry_id:261394)代替原始被积函数，积分就变得可以解析计算。[@problem_id:4965202]

2.  **自适应[高斯-埃尔米特求积](@entry_id:145090) (Adaptive Gauss-Hermite Quadrature, AGHQ)**：这是一种更精确的数值积分技术。它通过一组精心选择的节点和权重来逼近积分值。其“自适应”之处在于，它不是在固定的 0 点周围进行求积，而是将求积的节点和权[重根](@entry_id:151486)据每个聚类 $ i $ 的后验分布的众数 $ \hat{\boldsymbol{b}}_i $ 和曲率进行居中和缩放。通过将数值计算的努力集中在被积函数质量最大的区域，AGHQ 能够以较少的求积点获得高精度的近似，尤其是在后验分布偏斜或聚类大小不均衡的情况下。[@problem_id:4965202]

#### 可识别性问题：完全分离

最后，即使有先进的计算工具，GLMM 的参数估计也可能遇到**可识别性**问题。一个典型的例子是在 logistic GLMM 中出现**完全分离**（complete separation）。当一个或多个固定效应协变量的[线性组合](@entry_id:155091)能够完美地预测[二元结果](@entry_id:173636)时（例如，所有 $ Y=1 $ 的观测其预测值都大于某个阈值，而所有 $ Y=0 $ 的观测其预测值都小于该阈值），就会发生完全分离。

在标准 logistic 回归中，这会导致固定效应系数的 MLE 发散到无穷大。一个常见的误解是，GLMM 中的随机效应能够通过“平滑”或“正则化”来解决这个问题。然而，事实并非如此。即使存在随机效应（只要其方差 $ \sigma_b^2 $ 是有限正数），当固定效应的预测因子发生完全分离时，GLMM 的[边际似然](@entry_id:636856)函数仍然会随着 $ \boldsymbol{\beta} $ 在分离方向上的范数趋于无穷而单调增加。似然函数的[上确界](@entry_id:140512)在[参数空间](@entry_id:178581)的边界处（$ ||\boldsymbol{\beta}|| \to \infty $）达到，但对于任何有限的 $ \boldsymbol{\beta} $ 都无法取到。因此，有限的 MLE 依然不存在，相关的固定效应参数是不可识别的。[@problem_id:4965215]

理解这些原理和机制，是有效运用 GLMM 进行严谨科学研究的基石。它们不仅指导我们如何构建和拟合模型，更重要的是，如何正确地解释其结果并认识到其潜在的局限性。