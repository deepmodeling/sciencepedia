{"hands_on_practices": [{"introduction": "虽然每百万转录本数（$TPM$）是一种广泛用于可视化表达量的RNA-seq数据归一化指标，但其组合性数据的性质使其不适合直接用于差异表达检验。本实践练习将通过模拟数据来揭示这一陷阱，您将看到固定的$TPM$总和如何在朴素的统计检验中引入虚假相关性，并导致假阳性和假阴性结果。通过构建这个反例，您将对为何需要使用专门的基于计数的模型进行稳健的差异表达分析获得具体而深刻的理解。[@problem_id:4370568]", "problem": "考虑一个简化的核糖核酸测序场景，用于系统生物医学中的基因水平定量，其目标是为“组学”数据进行归一化和差异表达分析。其基础是每百万转录本 (TPM) 的定义以及组成型数据在闭包约束下的性质。对于一个由 $s$ 索引的样本，其中有 $G$ 个基因，由 $i \\in \\{1,\\dots,G\\}$ 索引，设 $c_{i,s}$ 表示样本 $s$ 中基因 $i$ 的观测读取计数，并设 $\\ell_i$ 表示其有效转录本长度（以碱基对为单位）。样本 $s$ 中基因 $i$ 的 TPM 定义为\n$$\n\\mathrm{TPM}_{i,s} \\equiv 10^6 \\cdot \\frac{c_{i,s}/\\ell_i}{\\sum_{j=1}^{G} c_{j,s}/\\ell_j}.\n$$\n在这种归一化下，由于每个样本 $s$ 都满足闭包约束 $\\sum_{i=1}^{G} \\mathrm{TPM}_{i,s} = 10^6$，向量 $\\left(\\mathrm{TPM}_{1,s},\\dots,\\mathrm{TPM}_{G,s}\\right)$ 位于 $G$ 维单纯形上。在组成型数据分析中，对于受确定性约束 $\\sum_{i=1}^{G} X_i = K$ 的随机变量 $X_1,\\dots,X_G$，根据协方差的性质可得\n$$\n\\sum_{j=1}^{G} \\mathrm{cov}(X_i,X_j) = \\mathrm{cov}\\left(X_i,\\sum_{j=1}^{G}X_j\\right) = \\mathrm{cov}(X_i,K) = 0,\n$$\n这意味着 $\\sum_{j \\neq i} \\mathrm{cov}(X_i,X_j) = -\\mathrm{var}(X_i)$，从而在与其他组分的协方差中强制产生负平衡。这一原理表明，闭包在基因间的协方差和相关性中引入了一种结构，而这种结构与真实的生物共调控无关。\n\n你的任务是提供一个反例，证明在不显式地对组成型约束进行建模的情况下，TPM 归一化不能用于差异表达检验，并量化由闭包引起的基因间的引入相关性。实现一个程序，该程序在两种条件下为指定的基因集模拟测序计数，计算 TPM 值，对目标基因的 TPM 值执行朴素的 Welch's 双样本 $t$-检验以评估差异表达，并使用所有模拟样本的 TPM 值计算基因间的平均非对角 Pearson 相关性。\n\n假设使用以下对于批量核糖核酸测序是标准且科学上合理的模拟模型：\n- 对于一个给定的条件，将每个细胞每个基因的预期分子数定义为一个具有严格正值的向量 $\\mathbf{m} = (m_1,\\dots,m_G)$。\n- 对于一个文库大小为 $L$ 总读取数的样本，每个样本的基因概率与 $m_i \\ell_i$ 成正比，即\n$$\np_i = \\frac{m_i \\ell_i}{\\sum_{j=1}^{G} m_j \\ell_j}.\n$$\n- 观测计数是从多项分布 $(c_{1,s},\\dots,c_{G,s}) \\sim \\mathrm{Multinomial}(L; p_1,\\dots,p_G)$ 中为每个重复样本独立抽样的。\n\n以此为基础，构建以下测试套件，每个测试都需要一个可量化的输出：\n\n测试用例 1 (关于未改变基因出现假阳性的反例)：\n- 参数: $G=4$，$\\ell = (1000, 1000, 1000, 1000)$，条件 A 的分子数 $\\mathbf{m}^{(A)} = (1000, 1000, 1000, 1000)$，条件 B 的分子数 $\\mathbf{m}^{(B)} = (1000, 1000, 100000, 1000)$，每个条件的重复数 $R=12$，文库大小 $L = 2{,}000{,}000$，随机种子固定但在不同条件下不同，显著性水平 $\\alpha = 0.001$，目标基因索引 $i^\\star = 1$。\n- 任务：模拟条件 A 和 B 的计数，计算每个样本的 TPM，对 {$\\mathrm{TPM}_{i^\\star,s} : s \\in A$} 与 {$\\mathrm{TPM}_{i^\\star,s} : s \\in B$} 执行 Welch’s $t$-检验，并返回一个布尔值，该值表示对 TPM 的朴素差异表达检测与基因 $i^\\star$ 的绝对分子数未变的事实相矛盾。具体而言，如果检验的 $p$-值严格小于 $\\alpha$，并且条件 B 中的平均 TPM 严格小于条件 A 中的，即使 $m^{(A)}_{i^\\star} = m^{(B)}_{i^\\star}$，也返回 true。\n\n测试用例 2 (全局缩放下的假阴性反例)：\n- 参数: $G=4$，$\\ell = (800, 1000, 1200, 1500)$，条件 A 的分子数 $\\mathbf{m}^{(A)} = (1000, 2000, 3000, 4000)$，条件 B 的分子数 $\\mathbf{m}^{(B)} = 2 \\cdot \\mathbf{m}^{(A)}$ (所有基因全局增加两倍)，每个条件的重复数 $R=12$，文库大小 $L = 2{,}000{,}000$，随机种子固定但在不同条件下不同，显著性水平 $\\alpha = 0.001$，目标基因索引 $i^\\star = 1$。\n- 任务：模拟条件 A 和 B 的计数，计算每个样本的 TPM，对不同条件下的 $\\mathrm{TPM}_{i^\\star}$ 执行 Welch’s $t$-检验，并返回一个布尔值，该值表示朴素方法未能检测到由全局缩放引起的真实变化。具体而言，如果检验的 $p$-值大于或等于 $\\alpha$，即使目标基因的绝对分子数翻了一番，也返回 true。\n\n测试用例 3 (量化闭包引入的相关性)：\n- 重用测试用例 1 的参数，并合并两个条件下的所有 TPM 样本（总共 $2R$ 个样本）。\n- 任务：使用所有 $2R$ 个样本的 TPM 值，计算 $G$ 个基因间的 Pearson 相关矩阵。返回平均非对角相关性值，作为一个实数（浮点数），计算为所有 $i \\neq j$ 的成对相关性的均值。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含三个测试用例的结果，格式为方括号括起来的逗号分隔列表，顺序为：测试用例 1 的布尔值，测试用例 2 的布尔值，测试用例 3 的浮点数。例如，一个有效的输出可能看起来像“[true,true,-0.215432]”。布尔值请使用小写的“true”/“false”，浮点数请使用标准十进制表示法。不应打印任何额外的文本。", "solution": "该问题要求实现一个数值模拟，以展示在核糖核酸测序 (RNA-seq) 数据的差异表达分析中使用每百万转录本 (TPM) 归一化时产生的基本假象。核心科学原理是 TPM 值是组成性的，意味着它们是整体的一部分，其总和为一个固定常数 ($10^6$)。这种闭包性质会引入伪相关，并可能在未明确考虑数据组成性质的统计检验中导致错误的结论。该解决方案围绕三个测试用例设计，旨在突出这些问题：假阳性、假阴性和对引入的负相关的量化。\n\n算法设计结构如下：\n1.  一个基于科学上合理的生成模型来模拟 RNA-seq 计数的函数。\n2.  一个从原始计数计算 TPM 值的函数。\n3.  按照规定实现模拟、归一化和统计分析的三个测试用例序列。\n\n**1. RNA-seq 计数的模拟**\n\n分析的基础是对测序过程的真实模拟。我们将一个包含 $G$ 个基因的样本 $s$ 的读取计数建模为从多项分布中的一次抽样：\n$$\n(c_{1,s}, \\dots, c_{G,s}) \\sim \\mathrm{Multinomial}(L; p_1, \\dots, p_G)\n$$\n此处，$L$ 是总文库大小（样本的总读取数），而 $\\mathbf{p} = (p_1, \\dots, p_G)$ 是给定读取源自特定基因的概率向量。该模型捕捉了高通量测序的随机抽样特性。概率 $p_i$ 由每个基因的潜在真实分子丰度 $m_i$ 及其有效转录本长度 $\\ell_i$ 决定。更长或更丰富的转录本更有可能被抽样。因此，基因 $i$ 的概率与乘积 $m_i \\ell_i$ 成正比，并被归一化以使总和为一：\n$$\np_i = \\frac{m_i \\ell_i}{\\sum_{j=1}^{G} m_j \\ell_j}\n$$\n该模拟对每个实验条件（A 和 B）中的 $R$ 个重复样本独立执行，使用不同的分子丰度向量 $\\mathbf{m}^{(A)}$ 和 $\\mathbf{m}^{(B)}$，但为了可复现性使用固定的随机种子。\n\n**2. TPM 归一化**\n\n根据模拟的计数 $c_{i,s}$，我们计算 TPM 值。公式为：\n$$\n\\mathrm{TPM}_{i,s} = 10^6 \\cdot \\frac{c_{i,s}/\\ell_i}{\\sum_{j=1}^{G} c_{j,s}/\\ell_j}\n$$\n项 $c_{i,s}/\\ell_i$ 表示转录本每碱基的读取速率，它是转录本丰度的一个近似指标。归一化步骤包括将此速率除以样本中所有此类速率的总和，将其转换为相对比例，并将其缩放到一百万的总和。这个分母 $\\sum_{j=1}^{G} c_{j,s}/\\ell_j$ 是将样本内所有基因的 TPM 值耦合在一起的关键部分，从而施加了闭包约束 $\\sum_{i=1}^{G} \\mathrm{TPM}_{i,s} = 10^6$。\n\n**3. 测试用例和统计分析**\n\n**测试用例 1：假阳性检测**\n这个案例演示了一个基因的变化如何在一个不相关、未改变的基因中产生一个统计上显著但却是人为的变化。\n-   **原理**：我们将目标基因 ($i^\\star = 1$) 的真实分子丰度在条件 A ($\\mathbf{m}^{(A)}_{1} = 1000$) 和条件 B ($\\mathbf{m}^{(B)}_{1} = 1000$) 之间设置为相同。然而，在条件 B 中，我们大幅增加了另一个基因 ($i=3$) 的丰度。\n-   **机制**：$\\mathbf{m}^{(B)}_3$ 的大幅增加会极大地增加条件 B 样本中所有基因 TPM 计算的分母。因此，尽管基因 1 的原始计数可能与条件 A 中的相似（在采样噪声的影响下），其 TPM 值却被人为地压低了。\n-   **实现**：为每个条件的 $R=12$ 个重复样本模拟计数。为所有样本计算 TPM 值。在两个条件之间，对目标基因 ($i^\\star = 1$) 的 TPM 值执行 Welch's 双样本 $t$-检验。如果得出的 $p$-值小于显著性水平 $\\alpha=0.001$ 并且 B 中的平均 TPM 小于 A 中的平均 TPM，则该检验被认为是“假阳性”，这会被朴素地解释为下调。\n\n**测试用例 2：假阴性检测**\n这个案例说明了 TPM 无法检测影响所有基因的全局性、系统性变化。\n-   **原理**：我们模拟一个场景，其中与条件 A 相比，条件 B 中每个基因的真实分子丰度都增加了一倍，即 $\\mathbf{m}^{(B)} = 2 \\cdot \\mathbf{m}^{(A)}$。这代表了一个真实的、具有生物学意义的变化。\n-   **机制**：当所有 $m_i$ 都按一个常数因子 $k$（此处 $k=2$）进行缩放时，多项分布的概率 $p_i$ 保持不变：\n$$\np_i^{(B)} = \\frac{(k \\cdot m_i^{(A)}) \\ell_i}{\\sum_{j=1}^{G} (k \\cdot m_j^{(A)}) \\ell_j} = \\frac{k (m_i^{(A)} \\ell_i)}{k (\\sum_{j=1}^{G} m_j^{(A)} \\ell_j)} = p_i^{(A)}\n$$\n由于两个条件的抽样概率相同，因此计数的期望分布以及 TPM 的期望分布也相同。归一化完全掩盖了潜在的绝对丰度两倍的增加。\n-   **实现**：如前所述生成计数和 TPM。对目标基因 ($i^\\star=1$) 的 TPM 进行 Welch's $t$-检验，预计会产生一个高的 $p$-值，从而未能检测到真实的变化。如果 $p$-值大于或等于 $\\alpha = 0.001$，则该检验被认为是“假阴性”。\n\n**测试用例 3：量化引入的相关性**\n此测试衡量由闭包属性强制施加的负相关结构。\n-   **原理**：如问题所述，对于总和为常数的组成型数据 $X_i$，有 $\\sum_{j \\neq i} \\mathrm{cov}(X_i,X_j) = -\\mathrm{var}(X_i)$。这意味着平均而言，一个组分的增加必须由其他组分的减少来平衡，从而促成了负协方差和负相关，这些是归一化产生的数学假象，而不一定是生物共调控。\n-   **机制**：我们使用来自测试用例 1 的数据，其中条件 A 和 B 之间的显著差异（由基因 3 驱动）在 TPM 数据中产生了强烈的变异。这种变异为观察引入的相关性提供了良好的基础。\n-   **实现**：将来自测试用例 1 两个条件的 TPM 矩阵合并成一个包含 $2R=24$ 个样本的单一数据集。然后计算这 $G=4$ 个基因间的 Pearson 相关矩阵。最终输出是该相关矩阵所有非对角元素的平均值，该值量化了在这种特定情景下 TPM 归一化所引入的平均成对相关性。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import ttest_ind\n\ndef solve():\n    \"\"\"\n    Solves the three test cases related to RNA-seq data normalization and analysis.\n    \"\"\"\n\n    # Helper function to simulate RNA-seq counts using a multinomial model.\n    def simulate_counts(m, l, L, R, seed):\n        \"\"\"\n        Simulates counts for R replicates.\n        \n        Args:\n            m (np.array): Vector of molecule counts per gene.\n            l (np.array): Vector of gene lengths.\n            L (int): Library size (total reads).\n            R (int): Number of replicates.\n            seed (int): Random seed for reproducibility.\n\n        Returns:\n            np.array: An (R x G) matrix of simulated counts.\n        \"\"\"\n        rng = np.random.default_rng(seed)\n        # Calculate sampling probabilities proportional to molecule count * length\n        ml = m * l\n        # Check for sum of ml being zero to avoid division by zero, though unlikely.\n        sum_ml = np.sum(ml)\n        p = ml / sum_ml if sum_ml > 0 else np.zeros_like(ml)\n        \n        counts = rng.multinomial(n=L, pvals=p, size=R)\n        return counts\n\n    # Helper function to calculate TPM from a counts matrix.\n    def calculate_tpm(counts, l):\n        \"\"\"\n        Calculates Transcripts Per Million (TPM).\n\n        Args:\n            counts (np.array): An (R x G) matrix of counts.\n            l (np.array): Vector of gene lengths.\n\n        Returns:\n            np.array: An (R x G) matrix of TPM values.\n        \"\"\"\n        # rate = counts per kilobase\n        rate = counts / l\n        # sum of rates per sample\n        sum_of_rates = np.sum(rate, axis=1, keepdims=True)\n        # Avoid division by zero if a sample has all zero counts\n        sum_of_rates[sum_of_rates == 0] = 1\n        \n        tpm = 1e6 * (rate / sum_of_rates)\n        return tpm\n\n    results = []\n\n    # --- Test Case 1: Counterexample for false positive ---\n    params1 = {\n        'G': 4,\n        'l': np.array([1000, 1000, 1000, 1000], dtype=float),\n        'm_A': np.array([1000, 1000, 1000, 1000], dtype=float),\n        'm_B': np.array([1000, 1000, 100000, 1000], dtype=float),\n        'R': 12,\n        'L': 2_000_000,\n        'alpha': 0.001,\n        'target_gene_idx': 0,  # Gene i* = 1 is at index 0\n        'seed_A': 123,\n        'seed_B': 456\n    }\n    \n    counts_A1 = simulate_counts(params1['m_A'], params1['l'], params1['L'], params1['R'], params1['seed_A'])\n    counts_B1 = simulate_counts(params1['m_B'], params1['l'], params1['L'], params1['R'], params1['seed_B'])\n    \n    tpm_A1 = calculate_tpm(counts_A1, params1['l'])\n    tpm_B1 = calculate_tpm(counts_B1, params1['l'])\n\n    tpm_A1_target = tpm_A1[:, params1['target_gene_idx']]\n    tpm_B1_target = tpm_B1[:, params1['target_gene_idx']]\n\n    _, p_val1 = ttest_ind(tpm_A1_target, tpm_B1_target, equal_var=False)\n    \n    result1 = (p_val1  params1['alpha']) and (np.mean(tpm_B1_target)  np.mean(tpm_A1_target))\n    results.append(str(result1).lower())\n\n    # --- Test Case 2: Counterexample for false negative ---\n    params2 = {\n        'G': 4,\n        'l': np.array([800, 1000, 1200, 1500], dtype=float),\n        'm_A': np.array([1000, 2000, 3000, 4000], dtype=float),\n        'm_B': 2 * np.array([1000, 2000, 3000, 4000], dtype=float),\n        'R': 12,\n        'L': 2_000_000,\n        'alpha': 0.001,\n        'target_gene_idx': 0, # Gene i* = 1 is at index 0\n        'seed_A': 123,\n        'seed_B': 456\n    }\n\n    counts_A2 = simulate_counts(params2['m_A'], params2['l'], params2['L'], params2['R'], params2['seed_A'])\n    counts_B2 = simulate_counts(params2['m_B'], params2['l'], params2['L'], params2['R'], params2['seed_B'])\n    \n    tpm_A2 = calculate_tpm(counts_A2, params2['l'])\n    tpm_B2 = calculate_tpm(counts_B2, params2['l'])\n\n    tpm_A2_target = tpm_A2[:, params2['target_gene_idx']]\n    tpm_B2_target = tpm_B2[:, params2['target_gene_idx']]\n\n    _, p_val2 = ttest_ind(tpm_A2_target, tpm_B2_target, equal_var=False)\n    \n    result2 = p_val2 >= params2['alpha']\n    results.append(str(result2).lower())\n    \n    # --- Test Case 3: Quantifying closure-induced correlation ---\n    # Reuses TPM data from Test Case 1\n    all_tpm = np.vstack((tpm_A1, tpm_B1))\n    \n    # rowvar=False because genes are columns, samples are rows\n    corr_matrix = np.corrcoef(all_tpm, rowvar=False)\n    \n    G = params1['G']\n    # Sum of off-diagonal elements / number of off-diagonal elements\n    num_off_diagonal = G * G - G\n    sum_off_diagonal = np.sum(corr_matrix) - np.trace(corr_matrix)\n    avg_corr = sum_off_diagonal / num_off_diagonal if num_off_diagonal > 0 else 0.0\n    \n    # Format to 6 decimal places as in the example\n    results.append(f\"{avg_corr:.6f}\")\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "4370568"}, {"introduction": "现代RNA-seq分析流程通常在转录本水平上进行表达定量，但差异表达分析通常在基因水平上进行。这就引出了一个关键问题：我们如何正确地将转录本水平的数据汇总到基因水平？本实践将带您探索流行的`tximport`方法背后的逻辑，指导您推导并实现两种不同的基因水平汇总策略。您将直接观察到，在不同样本间正确地考虑有效转录本长度的变化，会如何显著改变最终计算出的对数倍数变化（log-fold change）估计值。[@problem_id:4370566]", "problem": "您将接触到一个用于系统生物医学中双样本比较的、来自核糖核酸测序（RNA-seq）的转录本定量的玩具但科学上连贯的抽象模型。对于每个样本，您拥有以每百万转录本数（TPM）为单位的每个转录本的丰度、以碱基对为单位的有效长度、一个转录本到基因的映射关系，以及映射上的片段总数（文库大小）。您的任务是推导、实现和比较两种与广泛使用的 tximport 流程原则一致的基因水平汇总策略，然后量化长度校正如何影响下游差异表达（DE）的对数倍数变化。\n\n使用的基本基础和定义：\n- 根据每百万转录本数（TPM）的定义，对于样本 $s$ 中的转录本 $t$，其片段计数为 $C_{t,s}$，有效长度为 $E_{t,s}$，其丰度 $a_{t,s}$ 与每碱基的片段数成正比，并归一化到 $10^6$。也就是说，$a_{t,s}$ 是通过在所有转录本上对 $\\frac{C_{t,s}}{E_{t,s}}$进行归一化得到的，使得所有转录本的总和等于 $10^6$。\n- 有效长度 $E_{t,s}$ 是一个长度参数（以碱基对为单位），反映了片段的有效起始位置数量，考虑了诸如片段长度分布等实验特异性因素。\n- 文库大小 $N_s$ 是样本 $s$ 的映射片段总数。\n\n您必须仅根据这些定义，为每个样本 $s$ 和基因 $g$ 推导并实现两种基因水平的计数汇总规则：\n1. 一种仅使用丰度和文库大小的文库大小缩放丰度规则。\n2. 一种长度缩放丰度规则，其给出的计数与预期片段生成过程成正比，该模型假设观察到片段的概率与每碱基丰度和有效长度均成正比。\n\n然后，对于每个基因 $g$，您应该计算两个样本 $s_A$ 和 $s_B$ 之间倍数变化的以2为底的对数。如果每个条件下有多个样本，则使用算术平均值（本任务中没有这种情况），否则使用单个样本的计数：\n- 对于给定的方法，设 $G_{g,s_A}$ 和 $G_{g,s_B}$ 为基因水平的计数；将对数倍数变化定义为 $\\log_2\\left(\\frac{G_{g,s_B}}{G_{g,s_A}}\\right)$。\n- 将感兴趣的量 $\\Delta_g$ 定义为同一基因 $g$ 的两种方法的对数倍数变化之差：即，如果两种方法产生 $\\mathrm{LFC}^{(1)}_g$ 和 $\\mathrm{LFC}^{(2)}_g$，则 $\\Delta_g = \\mathrm{LFC}^{(2)}_g - \\mathrm{LFC}^{(1)}_g$。\n\n实现一个程序，对每个测试用例，计算指定基因 $g^\\star$ 的 $\\Delta_{g^\\star}$。\n\n测试套件（三个独立案例）。在每个案例中，都恰好有两个转录本 $t \\in \\{t_1,t_2\\}$ 和两个样本 $s \\in \\{A,B\\}$，并且每个转录本属于一个不同的基因（$t_1 \\mapsto g_1$, $t_2 \\mapsto g_2$）。所有丰度都已按每个样本的TPM单位提供，并且在每个样本内总和为 $10^6$。所有有效长度以碱基对为单位，文库大小以片段为单位。\n\n- 案例1（感兴趣的基因长度发生变化，而丰度保持不变）：\n  - 映射关系：$t_1 \\to g_1$, $t_2 \\to g_2$；感兴趣的基因 $g^\\star = g_1$。\n  - 样本 $A$：$a_{t_1,A} = 500{,}000$，$a_{t_2,A} = 500{,}000$；$E_{t_1,A} = 2000$，$E_{t_2,A} = 1500$；$N_A = 10{,}000{,}000$。\n  - 样本 $B$：$a_{t_1,B} = 500{,}000$，$a_{t_2,B} = 500{,}000$；$E_{t_1,B} = 1000$，$E_{t_2,B} = 1500$；$N_B = 10{,}000{,}000$。\n\n- 案例2（样本间长度无变化；作为对照，两种方法在倍数变化上应达成一致）：\n  - 映射关系：$t_1 \\to g_1$, $t_2 \\to g_2$；感兴趣的基因 $g^\\star = g_1$。\n  - 样本 $A$：$a_{t_1,A} = 500{,}000$，$a_{t_2,A} = 500{,}000$；$E_{t_1,A} = 1500$，$E_{t_2,A} = 1500$；$N_A = 10{,}000{,}000$。\n  - 样本 $B$：$a_{t_1,B} = 500{,}000$，$a_{t_2,B} = 500{,}000$；$E_{t_1,B} = 1500$，$E_{t_2,B} = 1500$；$N_B = 10{,}000{,}000$。\n\n- 案例3（一个极端边缘案例，有效长度在样本间发生急剧交换）：\n  - 映射关系：$t_1 \\to g_1$, $t_2 \\to g_2$；感兴趣的基因 $g^\\star = g_1$。\n  - 样本 $A$：$a_{t_1,A} = 900{,}000$，$a_{t_2,A} = 100{,}000$；$E_{t_1,A} = 4000$，$E_{t_2,A} = 500$；$N_A = 10{,}000{,}000$。\n  - 样本 $B$：$a_{t_1,B} = 900{,}000$，$a_{t_2,B} = 100{,}000$；$E_{t_1,B} = 500$，$E_{t_2,B} = 4000$；$N_B = 10{,}000{,}000$。\n\n要求的输出：\n- 对于每个案例，计算如上定义的单个浮点数 $\\Delta_{g^\\star}$。\n- 您的程序应生成一行输出，其中包含三个结果，以逗号分隔的列表形式并用方括号括起来，按案例顺序排列，每个值四舍五入到六位小数，例如，“[x1,x2,x3]”。\n\n角度单位不适用。除了按原样使用所提供的碱基对作为有效长度和片段作为文库大小外，没有其他物理单位转换。输出是无量纲的浮点数（比率的对数）。\n\n澄清说明：\n- 您不能假设存在原始的估计片段计数 $C_{t,s}$。您必须仅根据上述定义，使用丰度、有效长度和文库大小来推导两种基因水平的汇总规则。\n- 没有缺失值，所有数组在数值上都表现良好，适合所述计算。", "solution": "我们使用RNA-seq片段的抽样模型将转录本水平的量与基因水平的计数联系起来。基本定义如下。对于样本 $s$ 中的转录本 $t$，设 $C_{t,s}$ 是映射到 $t$ 的片段数，$E_{t,s}$ 是以碱基对为单位的有效长度。每百万转录本数（TPM）丰度 $a_{t,s}$ 的定义是对所有转录本的每碱基片段数进行归一化，使其总和为 $10^6$：\n$$\na_{t,s} \\propto \\frac{C_{t,s}}{E_{t,s}}, \\quad \\text{with} \\quad \\sum_t a_{t,s} = 10^6.\n$$\n设 $N_s$ 为文库大小（样本 $s$ 中的总映射片段数）。\n\n我们推导两种与广泛使用的 tximport 策略一致的基因水平计数构建方法。\n\n1. 文库大小缩放丰度（scaledTPM）。其概念是仅使用相对丰度和文库大小为基因生成伪计数。对于基因 $g$，其转录本为 $t \\in g$，定义如下：\n$$\nG^{(\\mathrm{scaled})}_{g,s} = N_s \\cdot \\frac{\\sum_{t \\in g} a_{t,s}}{10^6}.\n$$\n这将基因占总TPM量的份额映射到文库大小的一个份额，而没有重新引入有效长度。它产生的计数与每碱基的表达量成正比（因为TPM已经是按碱基归一化的）。\n\n2. 长度缩放丰度（lengthScaledTPM）。这里我们想要的计数与片段生成过程成正比，该过程取决于每碱基的表达量和有效长度。我们从TPM的定义开始：\n$$\na_{t,s} = \\frac{10^6 \\cdot \\frac{C_{t,s}}{E_{t,s}}}{\\sum_u \\frac{C_{u,s}}{E_{u,s}}}.\n$$\n设 $Z_s = \\sum_u \\frac{C_{u,s}}{E_{u,s}}$。那么\n$$\n\\frac{C_{t,s}}{E_{t,s}} = \\frac{a_{t,s}}{10^6} \\cdot Z_s \\quad \\Rightarrow \\quad C_{t,s} = \\frac{a_{t,s}}{10^6} \\cdot Z_s \\cdot E_{t,s}.\n$$\n对所有转录本求和得到文库大小：\n$$\nN_s = \\sum_t C_{t,s} = \\frac{Z_s}{10^6} \\sum_t a_{t,s} E_{t,s} \\quad \\Rightarrow \\quad Z_s = \\frac{10^6 N_s}{\\sum_t a_{t,s} E_{t,s}}.\n$$\n代回以获得用丰度和有效长度表示的计数表达式：\n$$\nC_{t,s} = N_s \\cdot \\frac{a_{t,s} E_{t,s}}{\\sum_u a_{u,s} E_{u,s}}.\n$$\n基因水平的计数是其转录本的总和：\n$$\nG^{(\\mathrm{len})}_{g,s} = \\sum_{t \\in g} C_{t,s} = N_s \\cdot \\frac{\\sum_{t \\in g} a_{t,s} E_{t,s}}{\\sum_u a_{u,s} E_{u,s}}.\n$$\n这种构建方法生成的计数与一个抽样过程下的预期片段数成正比，该抽样过程在每碱基表达量和有效长度上都是线性的，这与适用于基于计数的DE方法的目标相匹配。\n\n对于差异表达，我们计算基因 $g$ 在两个样本 $A$ 和 $B$ 之间的以2为底的对数倍数变化：\n$$\n\\mathrm{LFC}^{(\\cdot)}_{g} = \\log_2\\left(\\frac{G^{(\\cdot)}_{g,B}}{G^{(\\cdot)}_{g,A}}\\right),\n$$\n然后两种方法之间的差异是\n$$\n\\Delta_g = \\mathrm{LFC}^{(\\mathrm{len})}_g - \\mathrm{LFC}^{(\\mathrm{scaled})}_g.\n$$\n\n我们现在将这些公式应用于测试套件。\n\n案例1：\n- 转录本：$t_1 \\to g_1$，$t_2 \\to g_2$。\n- 样本 $A$：$a_{t_1,A}=500{,}000$，$a_{t_2,A}=500{,}000$，$E_{t_1,A}=2000$，$E_{t_2,A}=1500$，$N_A=10{,}000{,}000$。\n- 样本 $B$：$a_{t_1,B}=500{,}000$，$a_{t_2,B}=500{,}000$，$E_{t_1,B}=1000$，$E_{t_2,B}=1500$，$N_B=10{,}000{,}000$。\n缩放法：\n$$\nG^{(\\mathrm{scaled})}_{g_1,A} = 10^7 \\cdot \\frac{500{,}000}{10^6} = 5 \\cdot 10^6,\\quad G^{(\\mathrm{scaled})}_{g_1,B} = 5 \\cdot 10^6,\n$$\n所以 $\\mathrm{LFC}^{(\\mathrm{scaled})}_{g_1} = \\log_2(1)=0$。\n长度缩放法分母：\n$$\n\\sum_u a_{u,A} E_{u,A} = 500{,}000 \\cdot 2000 + 500{,}000 \\cdot 1500 = 1.75 \\cdot 10^9,\n$$\n$$\n\\sum_u a_{u,B} E_{u,B} = 500{,}000 \\cdot 1000 + 500{,}000 \\cdot 1500 = 1.25 \\cdot 10^9.\n$$\n$g_1$ 的分子：\n$$\n\\sum_{t \\in g_1} a_{t,A} E_{t,A} = 1.0 \\cdot 10^9,\\quad \\sum_{t \\in g_1} a_{t,B} E_{t,B} = 0.5 \\cdot 10^9.\n$$\n因此\n$$\nG^{(\\mathrm{len})}_{g_1,A} = 10^7 \\cdot \\frac{1.0 \\cdot 10^9}{1.75 \\cdot 10^9} \\approx 5.7142857 \\cdot 10^6,\n$$\n$$\nG^{(\\mathrm{len})}_{g_1,B} = 10^7 \\cdot \\frac{0.5 \\cdot 10^9}{1.25 \\cdot 10^9} = 4.0 \\cdot 10^6.\n$$\n因此\n$$\n\\mathrm{LFC}^{(\\mathrm{len})}_{g_1} = \\log_2\\left(\\frac{4.0}{5.7142857}\\right) \\approx \\log_2(0.7) \\approx -0.514573,\n$$\n且 $\\Delta_{g_1} \\approx -0.514573 - 0 = -0.514573$。\n\n案例2：\n- 有效长度在样本间沒有变化，且每个样本内的丰度相等。\n- 对于 $g_1$，两种方法在样本间产生相同的计数，因此\n$$\n\\mathrm{LFC}^{(\\mathrm{scaled})}_{g_1} = \\mathrm{LFC}^{(\\mathrm{len})}_{g_1} = 0 \\quad \\Rightarrow \\quad \\Delta_{g_1} = 0.\n$$\n\n案例3：\n- 转录本：$t_1 \\to g_1$，$t_2 \\to g_2$。\n- 样本 $A$：$a_{t_1,A}=900{,}000$，$a_{t_2,A}=100{,}000$，$E_{t_1,A}=4000$，$E_{t_2,A}=500$，$N_A=10^7$。\n- 样本 $B$：$a_{t_1,B}=900{,}000$，$a_{t_2,B}=100{,}000$，$E_{t_1,B}=500$，$E_{t_2,B}=4000$，$N_B=10^7$。\n缩放法：\n$$\nG^{(\\mathrm{scaled})}_{g_1,A} = 10^7 \\cdot \\frac{900{,}000}{10^6} = 9 \\cdot 10^6, \\quad G^{(\\mathrm{scaled})}_{g_1,B} = 9 \\cdot 10^6,\n$$\n所以 $\\mathrm{LFC}^{(\\mathrm{scaled})}_{g_1} = 0$。\n长度缩放法分母：\n$$\n\\sum_u a_{u,A} E_{u,A} = 900{,}000 \\cdot 4000 + 100{,}000 \\cdot 500 = 3.65 \\cdot 10^9,\n$$\n$$\n\\sum_u a_{u,B} E_{u,B} = 900{,}000 \\cdot 500 + 100{,}000 \\cdot 4000 = 0.85 \\cdot 10^9.\n$$\n$g_1$ 的分子：\n$$\n\\sum_{t \\in g_1} a_{t,A} E_{t,A} = 3.6 \\cdot 10^9,\\quad \\sum_{t \\in g_1} a_{t,B} E_{t,B} = 0.45 \\cdot 10^9.\n$$\n因此\n$$\nG^{(\\mathrm{len})}_{g_1,A} = 10^7 \\cdot \\frac{3.6}{3.65} \\approx 9.8630137 \\cdot 10^6,\\quad\nG^{(\\mathrm{len})}_{g_1,B} = 10^7 \\cdot \\frac{0.45}{0.85} \\approx 5.2941176 \\cdot 10^6.\n$$\n因此\n$$\n\\mathrm{LFC}^{(\\mathrm{len})}_{g_1} = \\log_2\\left(\\frac{5.2941176}{9.8630137}\\right) \\approx \\log_2(0.5367647) \\approx -0.896,\n$$\n且 $\\Delta_{g_1} \\approx -0.896 - 0 = -0.896$。\n\n解释。在案例1和案例3中，感兴趣基因的有效长度在样本间存在差异。长度缩放法仅因长度差异而产生非零的对数倍数变化，这反映了基于片段的模型其计数会随有效长度而缩放。而文库大小缩放TPM方法，通过使用按碱基归一化的丰度，忽略了这些差异，并因为TPM未变而产生零对数倍数变化。在案例2中，由于长度没有变化，两种方法结果一致（差异为零）。这从机制上展示了长度校正如何影响DE结果：重新引入有效长度的方法产生的计数用于检验每个基因的总RNA分子数的变化，而保留每碱基归一化的方法则检验每碱基浓度的变化，因此在存在样本特异性有效长度变化的情况下，两者可能会产生差异。\n\n下面的程序对所提供的测试套件精确执行这些计算，并按要求的单行格式报告每个案例的 $\\Delta_{g^\\star}$，四舍五入到六位小数。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef scaledTPM_gene_counts(tpm, gene_ids, lib_size):\n    \"\"\"\n    Compute gene-level counts from TPM by scaling to library size.\n    tpm: array shape (T,) of TPM per transcript for one sample\n    gene_ids: array shape (T,) of integer gene identifiers (e.g., 0,1,...)\n    lib_size: scalar N (fragments)\n    Returns: dict {gene_id: count}\n    \"\"\"\n    # Sum TPM per gene\n    genes = np.unique(gene_ids)\n    gene_tpm = {g: float(np.sum(tpm[gene_ids == g])) for g in genes}\n    # Scale TPM to counts: counts = N * (TPM / 1e6)\n    gene_counts = {g: lib_size * (gene_tpm[g] / 1e6) for g in genes}\n    return gene_counts\n\ndef lengthScaledTPM_gene_counts(tpm, eff_len, gene_ids, lib_size):\n    \"\"\"\n    Compute gene-level counts proportional to fragment generation:\n    counts = N * sum_{t in gene} (TPM_t * E_t) / sum_{all t} (TPM_t * E_t)\n    tpm: array shape (T,)\n    eff_len: array shape (T,)\n    gene_ids: array shape (T,)\n    lib_size: scalar N\n    Returns: dict {gene_id: count}\n    \"\"\"\n    mass = float(np.sum(tpm * eff_len))\n    # Avoid division by zero (not expected in given test cases)\n    if mass == 0.0:\n        # If mass is zero, all counts are zero\n        genes = np.unique(gene_ids)\n        return {g: 0.0 for g in genes}\n    genes = np.unique(gene_ids)\n    gene_mass = {g: float(np.sum((tpm * eff_len)[gene_ids == g])) for g in genes}\n    gene_counts = {g: lib_size * (gene_mass[g] / mass) for g in genes}\n    return gene_counts\n\ndef log2_fold_change(count_B, count_A):\n    \"\"\"\n    Compute log2 fold change B/A. Assumes positive counts > 0 in given cases.\n    \"\"\"\n    return float(np.log2(count_B / count_A))\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case: dict with keys:\n    # - 'tpm_A', 'tpm_B': arrays of TPM for transcripts [t1, t2]\n    # - 'eff_A', 'eff_B': arrays of effective lengths for transcripts [t1, t2]\n    # - 'gene_ids': array mapping transcripts to gene IDs (integers)\n    # - 'N_A', 'N_B': library sizes for samples A and B\n    # - 'gene_of_interest': the integer gene ID to evaluate delta on\n    test_cases = [\n        {\n            \"tpm_A\": np.array([500000.0, 500000.0]),\n            \"tpm_B\": np.array([500000.0, 500000.0]),\n            \"eff_A\": np.array([2000.0, 1500.0]),\n            \"eff_B\": np.array([1000.0, 1500.0]),\n            \"gene_ids\": np.array([0, 1]),  # t1-g0, t2-g1\n            \"N_A\": 10_000_000.0,\n            \"N_B\": 10_000_000.0,\n            \"gene_of_interest\": 0\n        },\n        {\n            \"tpm_A\": np.array([500000.0, 500000.0]),\n            \"tpm_B\": np.array([500000.0, 500000.0]),\n            \"eff_A\": np.array([1500.0, 1500.0]),\n            \"eff_B\": np.array([1500.0, 1500.0]),\n            \"gene_ids\": np.array([0, 1]),\n            \"N_A\": 10_000_000.0,\n            \"N_B\": 10_000_000.0,\n            \"gene_of_interest\": 0\n        },\n        {\n            \"tpm_A\": np.array([900000.0, 100000.0]),\n            \"tpm_B\": np.array([900000.0, 100000.0]),\n            \"eff_A\": np.array([4000.0, 500.0]),\n            \"eff_B\": np.array([500.0, 4000.0]),\n            \"gene_ids\": np.array([0, 1]),\n            \"N_A\": 10_000_000.0,\n            \"N_B\": 10_000_000.0,\n            \"gene_of_interest\": 0\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        tpm_A = case[\"tpm_A\"]\n        tpm_B = case[\"tpm_B\"]\n        eff_A = case[\"eff_A\"]\n        eff_B = case[\"eff_B\"]\n        gene_ids = case[\"gene_ids\"]\n        N_A = case[\"N_A\"]\n        N_B = case[\"N_B\"]\n        g_star = case[\"gene_of_interest\"]\n\n        # Method 1: scaledTPM\n        counts_scaled_A = scaledTPM_gene_counts(tpm_A, gene_ids, N_A)\n        counts_scaled_B = scaledTPM_gene_counts(tpm_B, gene_ids, N_B)\n        lfc_scaled = log2_fold_change(counts_scaled_B[g_star], counts_scaled_A[g_star])\n\n        # Method 2: lengthScaledTPM\n        counts_len_A = lengthScaledTPM_gene_counts(tpm_A, eff_A, gene_ids, N_A)\n        counts_len_B = lengthScaledTPM_gene_counts(tpm_B, eff_B, gene_ids, N_B)\n        lfc_len = log2_fold_change(counts_len_B[g_star], counts_len_A[g_star])\n\n        delta = lfc_len - lfc_scaled\n\n        # Round to six decimals as required\n        results.append(f\"{delta:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "4370566"}, {"introduction": "一旦我们获得了适当的基因水平计数，下一步就是应用严谨的统计模型来检验差异表达。广义线性模型（Generalized Linear Model, $GLM$）为此提供了一个强大而灵活的框架，它允许我们同时考虑复杂的实验设计和归一化因子。在这个高级实践中，您将使用迭代重加权最小二乘法（Iteratively Reweighted Least Squares, $IRLS$）从头开始实现一个泊松$GLM$。您将学习如何构建设计矩阵来模拟处理条件和批次效应，并使用偏移量（offsets）进行文库大小的归一化。[@problem_id:4370596]", "problem": "给定一个系统生物医学背景下的高通量计数数据广义线性建模任务。目标是在存在批次效应的情况下计算条件特异性效应，同时通过偏移量对文库大小进行适当的归一化。模型必须基于泊松广义线性模型 (Poisson GLM) 的标准定义（使用对数连接函数和已知偏移量），从第一性原理推导和实现。\n\n从以下基本基础和定义开始。对于每个基因，其在各个样本中的观测计数值被建模为 $y_i \\sim \\text{Poisson}(\\mu_i)$，其中 $i \\in \\{1,\\dots,n\\}$，$n$ 是样本数量。具有对数连接函数和已知偏移量的泊松广义线性模型满足\n$$\n\\log \\mu_i \\;=\\; \\eta_i \\;=\\; x_i^\\top \\beta \\;+\\; o_i,\n$$\n其中 $x_i \\in \\mathbb{R}^p$ 是样本 $i$ 的协变量行向量，$\\beta \\in \\mathbb{R}^p$ 是待估计的回归系数，$o_i$ 是一个已知的偏移量。在此问题中，偏移量必须通过使用文库大小的自然对数来编码文库大小的归一化。为了数值稳定性和截距项的可解释性，请使用中心化偏移量，其公式为 $o_i \\;=\\; \\log L_i - \\frac{1}{n}\\sum_{j=1}^n \\log L_j$，其中 $L_i$ 是样本 $i$ 的文库大小。系统性组分使用一个截距项、一个条件指示变量和一个批次指示变量。条件特异性效应是对应于条件指示变量的系数，批次效应是对应于批次指示变量的系数。所有拟合必须通过最大似然估计进行，使用从具有对数连接和已知偏移量的泊松似然推导出的迭代重加权最小二乘法 (IRLS) 实现，不得依赖任何黑箱建模库。\n\n将条件效应的对比构建为一个线性泛函 $c^\\top \\beta$，其中 $c \\in \\mathbb{R}^p$ 用于选择条件系数，同时保持截距项和批次效应恒定。在没有交互作用的加性模型中，使用 $c = [0, 1, 0]^\\top$，其中系数的顺序是截距项、条件、批次。将 $c^\\top \\beta$ 解释为在校正了批次和文库大小后，条件效应在自然对数尺度上的估计对数速率比。通过除以 $\\log 2$ 将其转换为以 $2$ 为底的对数，以获得估计的 $\\log_2$ 倍数变化。\n\n实现要求。对于每个基因，使用标准的泊松广义线性模型工作响应和权重，通过IRLS求解 $\\beta$。具体来说，使用当前的 $\\beta$ 计算 $\\eta = X \\beta + o$、$\\mu = \\exp(\\eta)$、工作响应 $z = \\eta + \\frac{y - \\mu}{\\mu}$ 以及对角权重矩阵 $W = \\mathrm{diag}(\\mu)$。通过求解以 $W$ 为权重的加权最小二乘法正规方程来更新 $\\beta$，该方程为 $X \\beta \\approx z - o$，即，\n$$\n\\beta_{\\text{new}} \\;=\\; \\arg\\min_{\\beta \\in \\mathbb{R}^p} \\; \\sum_{i=1}^n \\mu_i \\,\\big(z_i - o_i - x_i^\\top \\beta\\big)^2.\n$$\n为确保在边界情况下的数值稳定性，在正规方程中加入一个小的岭回归正则化项 $\\lambda I_p$，其中 $\\lambda  0$ 是一个非常小的值（例如 $\\lambda = 10^{-6}$），$I_p$ 是 $p \\times p$ 的单位矩阵。迭代直至系数差异的欧几里得范数小于一个容差 $\\varepsilon$（例如 $\\varepsilon = 10^{-8}$）或达到最大迭代次数。最终估计值必须与应用于偏移量的任何常数平移无关（按规定对偏移量进行中心化可确保截距项具有良好的尺度）。\n\n设计矩阵和样本注释。共有 $n = 4$ 个样本，具有一个截距项、一个二元条件指示变量和一个二元批次指示变量。设计矩阵的列顺序为：截距项、条件、批次。样本注释如下：样本1的条件为0，批次为0；样本2的条件为0，批次为1；样本3的条件为1，批次为0；样本4的条件为1，批次为1。因此，$X$ 的行分别为 $[1,0,0]$、$[1,0,1]$、$[1,1,0]$ 和 $[1,1,1]$。\n\n测试套件。实现您的程序以处理以下三个独立的测试用例。在每个测试用例中，按基因给出的顺序，为每个基因计算条件效应的估计 $\\log_2$ 倍数变化。对于有4个样本的测试用例，偏移量必须计算为 $o_i = \\log L_i - \\frac{1}{4}\\sum_{j=1}^4 \\log L_j$。对比始终为 $c = [0,1,0]^\\top$。对于每个测试用例，设计矩阵和列顺序均如上所述。\n\n测试用例1（正常路径）：两个基因，四个样本，文库大小不同。\n- 文库大小 $L = [$ $10^6$, $5\\times 10^5$, $2\\times 10^6$, $1.5\\times 10^6$ $]$。\n- 基因1计数值 $y^{(1)} = [$ $10$, $5$, $42$, $26$ $]$。\n- 基因2计数值 $y^{(2)} = [$ $15$, $10$, $28$, $30$ $]$。\n\n测试用例2（包含零值和对比效应的边界情况）：三个基因，四个样本，文库大小与测试用例1相同。\n- 文库大小 $L = [$ $10^6$, $5\\times 10^5$, $2\\times 10^6$, $1.5\\times 10^6$ $]$。\n- 基因1计数值 $y^{(1)} = [$ $39$, $19$, $18$, $14$ $]$。\n- 基因2计数值 $y^{(2)} = [$ $8$, $7$, $15$, $19$ $]$。\n- 基因3计数值 $y^{(3)} = [$ $0$, $0$, $2$, $1$ $]$。\n\n测试用例3（文库大小相等且真实条件效应为零的边界情况）：一个基因，四个样本，文库大小相等。\n- 文库大小 $L = [$ $10^6$, $10^6$, $10^6$, $10^6$ $]$。\n- 基因1计数值 $y^{(1)} = [$ $12$, $18$, $12$, $18$ $]$。\n\n最终输出要求。您的程序必须生成一行输出，其中包含一个列表。该列表汇总了所有测试用例中估计的 $\\log_2$ 倍数变化，顺序如下：首先是测试用例1的所有基因（按基因顺序），然后是测试用G例2的所有基因（按基因顺序），最后是测试用例3的所有基因（按基因顺序）。每个值必须四舍五入到恰好4位小数，并以十进制数形式打印。输出格式必须为单行，内容是一个用方括号括起来的逗号分隔列表，例如 $[$ $x_1$, $x_2$, $\\dots$, $x_m$ $]$，其中 $m$ 是所有测试用例中基因特异性结果的总数。不得打印任何其他文本。", "solution": "该问题是有效的。它提出了一个清晰、有科学依据且定义明确的计算统计学任务，具体来说是实现一个泊松广义线性模型 (GLM) 用于分析高通量计数数据。所有必需的数据、模型规格和算法细节都已提供。\n\n根据要求，解决方案从第一性原理出发。我们将样本 $i$ 中每个基因的观测计数值 $y_i$ 建模为服从泊松分布，$y_i \\sim \\text{Poisson}(\\mu_i)$。GLM 的核心是期望计数值 $\\mu_i$ 与一组协变量之间的关系，该关系由一个连接函数和一个线性预测器定义。\n\n问题指定了对数连接函数，从而得到模型：\n$$\n\\log(\\mu_i) = \\eta_i = x_i^\\top \\beta + o_i\n$$\n此处，$\\eta_i$ 是线性预测器，$x_i^\\top$ 是设计矩阵 $X$ 的第 $i$ 行，编码了实验因素（截距项、条件、批次），$\\beta$ 是待估计的系数向量，$o_i$ 是一个已知的偏移量。偏移量对于归一化计数值以考虑样本间文库大小 ($L_i$) 的差异至关重要。指定的中心化偏移量 $o_i = \\log L_i - \\frac{1}{n}\\sum_{j=1}^n \\log L_j$ 确保了截距项系数 $\\beta_0$ 可以解释为具有平均文库大小的样本的基线对数率，同时不影响其他系数的估计值。\n\n系数 $\\beta$ 是通过最大似然估计 (MLE) 进行估计的。对于 GLM，似然函数最大化并非通过闭式解实现，而是通过迭代数值程序。其标准算法是迭代重加权最小二乘法 (IRLS)。IRLS 等价于用于寻找似然函数梯度（得分函数）根的牛顿-拉夫逊法或费雪评分法。\n\nIRLS 算法的每次迭代都涉及构建和解决一个加权最小二乘 (WLS) 问题，该问题局部逼近了 MLE 问题。根据规定，在给定的估计值 $\\beta_{\\text{old}}$ 下，我们为每个样本 $i=1, \\dots, n$ 计算以下量：\n1.  线性预测器：$\\eta_i = x_i^\\top \\beta_{\\text{old}} + o_i$。\n2.  估计均值：$\\mu_i = \\exp(\\eta_i)$。\n3.  对角权重矩阵：$W = \\mathrm{diag}(\\mu_1, \\dots, \\mu_n)$。对于具有对数连接的泊松模型，权重就是估计的均值。\n4.  工作响应：$z_i = \\eta_i + \\frac{y_i - \\mu_i}{\\mu_i}$。这个量在当前估计值附近对模型进行线性化。\n\n系数向量的更新值 $\\beta_{\\text{new}}$ 是通过求解一个 WLS 问题得到的，即将“工作残差” $z_i - o_i$ 以 $\\mu_i$ 为权重回归到协变量 $x_i$ 上。这对应于最小化加权平方和：\n$$\n\\beta_{\\text{new}} = \\arg\\min_{\\beta \\in \\mathbb{R}^p} \\sum_{i=1}^n \\mu_i (z_i - o_i - x_i^\\top \\beta)^2\n$$\n这个 WLS 问题的解由其正规方程给出。为增强数值稳定性，特别是在低计数值、数据分离或近似共线性的情况下，会添加一个小的岭回归正则化项 $\\lambda I_p$。因此，$\\beta$ 的更新是通过求解以下线性系统获得的：\n$$\n(X^\\top W X + \\lambda I_p) \\beta_{\\text{new}} = X^\\top W (z - o)\n$$\n其中 $z$ 和 $o$ 分别是工作响应和偏移量的列向量。\n\n实现将从 $\\beta$ 的一个初始猜测（例如 $\\beta = 0$）开始，并重复求解此线性系统，在每一步更新 $\\beta$。此过程持续进行，直到迭代间 $\\beta$ 向量的变化（以欧几里得范数 $\\|\\beta_{\\text{new}} - \\beta_{\\text{old}}\\|_2$ 衡量）低于指定的容差 $\\varepsilon = 10^{-8}$，或达到最大迭代次数。在实现中，计算工作响应 $z_i$ 时必须小心，因为 $\\mu_i$ 可能接近于零。一种常见的做法是，在分母 $\\mu_i$ 上加上一个很小的正常数以防止除以零，本实现将采纳此做法。\n\n收敛后，算法得出最大似然估计 $\\hat\\beta$。问题要求计算由对比 $c = [0, 1, 0]^\\top$ 定义的条件特异性效应。因此，条件的估计对数速率比（在自然对数尺度上）为 $c^\\top \\hat\\beta = \\hat\\beta_1$。为了将其表示为基因组学中常规的 $\\log_2$ 倍数变化，该值需除以 $\\log 2$：\n$$\n\\text{log}_2 \\text{FoldChange} = \\frac{\\hat\\beta_1}{\\log 2}\n$$\n此过程将独立应用于所提供测试套件中的每个基因，以计算所需的值。", "answer": "```python\nimport numpy as np\n\ndef irls_poisson_glm(y, X, L, lambda_reg, tol, max_iter):\n    \"\"\"\n    Fits a Poisson GLM with a log link and library size offsets using IRLS.\n\n    Args:\n        y (np.ndarray): Vector of observed counts.\n        X (np.ndarray): Design matrix.\n        L (np.ndarray): Vector of library sizes.\n        lambda_reg (float): Ridge regularization parameter.\n        tol (float): Convergence tolerance for the norm of beta difference.\n        max_iter (int): Maximum number of iterations.\n\n    Returns:\n        np.ndarray: The estimated coefficient vector beta.\n    \"\"\"\n    n_samples, n_coeffs = X.shape\n\n    # 1. Compute centered log-library size offsets\n    log_L = np.log(L)\n    offsets = log_L - np.mean(log_L)\n\n    # 2. Initialize beta coefficients to zero\n    beta = np.zeros(n_coeffs)\n\n    # 3. Perform Iteratively Reweighted Least Squares (IRLS)\n    for _ in range(max_iter):\n        beta_old = beta.copy()\n\n        # Compute linear predictor and mean response\n        eta = X @ beta + offsets\n        mu = np.exp(eta)\n\n        # Compute working response `z`\n        # A small constant is added to mu in the denominator for numerical stability,\n        # especially important for samples with zero counts where mu can be very small.\n        mu_safe_denominator = np.maximum(mu, 1e-12)\n        z = eta + (y - mu) / mu_safe_denominator\n\n        # Compute diagonal weight matrix W (as a vector for efficiency)\n        W_diag = mu\n        \n        # Solve the regularized normal equations for the WLS problem:\n        # (X^T W X + lambda*I) beta = X^T W (z - o)\n        \n        # Construct the left-hand side matrix, A\n        # Using element-wise multiplication for efficiency (avoids forming large W matrix)\n        A = X.T @ (X * W_diag[:, np.newaxis]) + lambda_reg * np.identity(n_coeffs)\n\n        # Construct the right-hand side vector, b\n        b_vec = W_diag * (z - offsets)\n        b = X.T @ b_vec\n\n        # Solve for the new beta\n        try:\n            beta = np.linalg.solve(A, b)\n        except np.linalg.LinAlgError:\n            # In case of a singular matrix despite regularization,\n            # we halt and return the last valid estimate.\n            return beta_old\n\n        # Check for convergence\n        if np.linalg.norm(beta - beta_old)  tol:\n            break\n\n    return beta\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final output.\n    \"\"\"\n    # Define the fixed design matrix for all test cases\n    # Columns: Intercept, Condition, Batch\n    X = np.array([\n        [1, 0, 0],\n        [1, 0, 1],\n        [1, 1, 0],\n        [1, 1, 1]\n    ], dtype=float)\n\n    # Parameters for the IRLS algorithm from the problem description\n    lambda_reg = 1e-6\n    tol = 1e-8\n    max_iter = 100\n\n    # Define the test suite\n    test_cases = [\n        # Test case 1\n        {\n            \"L\": np.array([1e6, 5e5, 2e6, 1.5e6]),\n            \"genes\": [\n                np.array([10, 5, 42, 26]),\n                np.array([15, 10, 28, 30])\n            ]\n        },\n        # Test case 2\n        {\n            \"L\": np.array([1e6, 5e5, 2e6, 1.5e6]),\n            \"genes\": [\n                np.array([39, 19, 18, 14]),\n                np.array([8, 7, 15, 19]),\n                np.array([0, 0, 2, 1])\n            ]\n        },\n        # Test case 3\n        {\n            \"L\": np.array([1e6, 1e6, 1e6, 1e6]),\n            \"genes\": [\n                np.array([12, 18, 12, 18])\n            ]\n        }\n    ]\n\n    all_results = []\n    \n    # Process each test case\n    for case in test_cases:\n        L = case[\"L\"]\n        for y_counts in case[\"genes\"]:\n            # Ensure count vector is a float array for calculations\n            y = np.array(y_counts, dtype=float)\n            \n            # Fit the GLM to get the beta coefficients\n            beta_hat = irls_poisson_glm(y, X, L, lambda_reg, tol, max_iter)\n            \n            # The condition effect coefficient is beta_hat[1]\n            # This corresponds to c^T * beta where c = [0, 1, 0]^T\n            log_rate_ratio = beta_hat[1]\n            \n            # Convert to log2 fold change\n            log2_fold_change = log_rate_ratio / np.log(2)\n            \n            all_results.append(log2_fold_change)\n\n    # Format results to 4 decimal places and create the output string\n    formatted_results = [f\"{val:.4f}\" for val in all_results]\n    \n    # Print the final output in the specified format\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "4370596"}]}