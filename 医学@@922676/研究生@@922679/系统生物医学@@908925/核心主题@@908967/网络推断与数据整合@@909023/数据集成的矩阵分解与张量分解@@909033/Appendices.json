{"hands_on_practices": [{"introduction": "掌握矩阵和张量分解的第一步是理解其最核心的算法。本练习将引导您从第一性原理出发，为非负矩阵分解（Nonnegative Matrix Factorization, NMF）推导其经典的乘法更新法则 [@problem_id:4360201]。通过应用Karush–Kuhn–Tucker (KKT) 条件，您不仅能理解算法的数学基础，还能深入洞察非负性约束是如何在迭代过程中得以保持的，这是处理生物数据中固有非负性的关键。", "problem": "在一个系统生物医学研究中，你正在通过使用非负矩阵分解（NMF）来近似一个非负数据矩阵，从而整合两种组学模态。设集成数据矩阵为 $X \\in \\mathbb{R}_{\\ge 0}^{m \\times n}$，在平方弗罗贝尼乌斯目标下，寻求一个分解 $X \\approx W H$，其中 $W \\in \\mathbb{R}_{\\ge 0}^{m \\times r}$ 且 $H \\in \\mathbb{R}_{\\ge 0}^{r \\times n}$。仅从平方弗罗贝尼乌斯范数的定义、标准矩阵微积分法则以及针对非负性约束的 Karush–Kuhn–Tucker (KKT) 条件出发：\n\n- 推导 $W$ 和 $H$ 的乘性更新法则，该法则能够单调递减目标函数同时保持非负性。\n- 陈述在何种条件下，这些乘性更新能保持非负性并导出一个非增的目标序列，并指明极限点的性质。\n\n然后，将你推导出的 $H$ 更新法则应用于一个具体的简单示例，其中 $m = 3$，$n = 3$，$r = 2$。考虑以下初始化和数据：\n$$\nX \\;=\\; \\begin{pmatrix}\n5  2  3 \\\\\n4  1  2 \\\\\n3  2  4\n\\end{pmatrix},\\quad\nW^{(0)} \\;=\\; \\begin{pmatrix}\n1  2 \\\\\n2  1 \\\\\n1  1\n\\end{pmatrix},\\quad\nH^{(0)} \\;=\\; \\begin{pmatrix}\n1  1  1 \\\\\n1  1  1\n\\end{pmatrix}.\n$$\n假设采用一种交替方案，首先在保持 $W$ 固定为 $W^{(0)}$ 的情况下，对 $H$ 进行一个完整的乘性更新步骤。使用你推导的法则，计算更新后的元素 $h_{1,2}^{(1)}$ 的值。请以精确分数形式（不要四舍五入）提供你的最终答案。最终答案必须是一个无单位的单个实数。", "solution": "### 乘性更新法则的推导\n\n问题是找到非负矩阵 $W$ 和 $H$，以最小化目标函数 $J$，该函数定义为近似误差的平方弗罗贝尼乌斯范数的一半：\n$$\nJ(W, H) = \\frac{1}{2} \\|X - WH\\|_F^2 = \\frac{1}{2} \\sum_{i=1}^{m} \\sum_{j=1}^{n} \\left(X_{ij} - \\sum_{k=1}^{r} W_{ik}H_{kj}\\right)^2\n$$\n该优化在所有索引 $i,j,k$ 满足 $W_{ik} \\ge 0$ 和 $H_{kj} \\ge 0$ 的约束下进行。由于目标函数 $J$ 对于 $W$ 和 $H$ 不是同时凸的，我们使用一种交替最小二乘法，即在固定一个矩阵的同时对另一个矩阵进行优化。\n\n目标函数可以使用迹算子写为：\n$$\nJ(W, H) = \\frac{1}{2} \\operatorname{tr}\\left((X-WH)^T(X-WH)\\right) = \\frac{1}{2} \\operatorname{tr}\\left(X^T X - X^T WH - H^T W^T X + H^T W^T W H\\right)\n$$\n我们将使用矩阵微积分的法则，具体为 $\\frac{\\partial}{\\partial A} \\operatorname{tr}(AB) = B^T$，$\\frac{\\partial}{\\partial A} \\operatorname{tr}(A^T B) = B$，以及 $\\frac{\\partial}{\\partial A} \\operatorname{tr}(A^T C A) = (C+C^T)A$。\n\n**1. H 的更新法则**\n\n固定 $W$，问题是在 $H \\ge 0$ 的约束下最小化 $J(H)$。这是一个约束凸优化问题。我们为非负性约束 $H \\ge 0$ 引入一个拉格朗日乘子矩阵 $\\Lambda \\in \\mathbb{R}_{\\ge 0}^{r \\times n}$。拉格朗日函数为：\n$$\n\\mathcal{L}(H, \\Lambda) = J(H) - \\operatorname{tr}(\\Lambda^T H)\n$$\n最优性的 Karush–Kuhn–Tucker (KKT) 条件是：\n-   平稳性：$\\nabla_H \\mathcal{L} = \\nabla_H J(H) - \\Lambda = 0$\n-   原始可行性：$H_{kj} \\ge 0$\n-   对偶可行性：$\\Lambda_{kj} \\ge 0$\n-   互补松弛性：对于所有 $k,j$，$\\Lambda_{kj} H_{kj} = 0$。\n\n首先，我们计算梯度 $\\nabla_H J(H)$。使用迹的表示法和矩阵微积分法则：\n$$\n\\nabla_H J = \\frac{\\partial J}{\\partial H} = \\frac{1}{2} \\left( -W^T X - W^T X + (W^T W + (W^T W)^T) H \\right) = -W^T X + W^T W H\n$$\nKKT 平稳性条件意味着 $\\Lambda = -W^T X + W^T W H$。互补松弛性条件变为：\n$$\n(-W^T X + W^T W H)_{kj} H_{kj} = 0\n$$\n这是一个不动点方程。乘性更新法则提供了一种迭代方法来找到满足此条件的解。它是通过考虑一个梯度下降步骤 $H \\leftarrow H - \\eta_H \\nabla_H J$ 并选择一个巧妙的、逐元素的学习率 $\\eta_H$ 来推导的。设单个元素的更新为：\n$$\nH_{kj} \\leftarrow H_{kj} - (\\eta_H)_{kj} \\left( - (W^T X)_{kj} + (W^T W H)_{kj} \\right)\n$$\n选择学习率 $(\\eta_H)_{kj} = \\frac{H_{kj}}{(W^T W H)_{kj}}$ 可得：\n$$\nH_{kj} \\leftarrow H_{kj} - \\frac{H_{kj}}{(W^T W H)_{kj}} \\left( - (W^T X)_{kj} + (W^T W H)_{kj} \\right) = H_{kj} \\left( 1 + \\frac{(W^T X)_{kj}}{(W^T W H)_{kj}} - 1 \\right) = H_{kj} \\frac{(W^T X)_{kj}}{(W^T W H)_{kj}}\n$$\n以矩阵形式，使用 $\\circ$ 表示哈达玛（逐元素）积和逐元素除法，H 的更新法则是：\n$$\nH \\leftarrow H \\circ \\frac{W^T X}{W^T W H}\n$$\n\n**2. W 的更新法则**\n\n通过对称性，W 的更新法则是通过固定 $H$ 并在 $W \\ge 0$ 的约束下最小化 $J(W)$ 来推导的。这等价于在 $W^T \\ge 0$ 的条件下最小化 $\\|X^T - H^T W^T\\|_F^2$。与 H 的推导类似，我们可以将 $X$ 替换为 $X^T$，将 $W$ 替换为 $H^T$，将 $H$ 替换为 $W^T$。\n$W^T$ 的更新法则是：\n$$\nW^T \\leftarrow W^T \\circ \\frac{(H^T)^T X^T}{(H^T)^T H^T W^T} = W^T \\circ \\frac{H X^T}{H H^T W^T}\n$$\n转置这个方程得到 W 的更新法则：\n$$\nW \\leftarrow \\left( W^T \\circ \\frac{H X^T}{H H^T W^T} \\right)^T = W \\circ \\left( \\frac{H X^T}{H H^T W^T} \\right)^T = W \\circ \\frac{(H X^T)^T}{(H H^T W^T)^T} = W \\circ \\frac{X H^T}{W H H^T}\n$$\n\n### 条件与收敛性\n\n-   **非负性保持**：如果初始矩阵 $W^{(0)}, H^{(0)}$ 和数据矩阵 $X$ 的元素均为非负，那么更新法则中分子（$W^T X$, $X H^T$）和分母（$W^T W H$, $W H H^T$）的所有项都将是非负的。更新只涉及非负矩阵的逐元素乘法和除法，因此 $W$ 和 $H$ 的非负性得以保持。为确保数值稳定性，避免分母为零，通常会在分母上加上一个小的正常数 $\\epsilon$。\n-   **非增目标函数**：可以证明，在这些更新法则的每一步下，目标函数 $J(W,H)$ 都是非递增的。由于目标函数有下界 $0$，由交替更新生成的目标值序列必然收敛。\n-   **极限点的性质**：该算法保证收敛到目标函数的一个稳定点，即满足 KKT 条件的点 $(W^*, H^*)$。然而，由于 $J(W,H)$ 在 $W$ 和 $H$ 上不是联合凸的，这个稳定点不保证是全局最小值。算法可能收敛到局部最小值或鞍点，具体的极限点取决于初始化。\n\n### 应用于简单示例\n\n题目要求我们使用推导出的 H 更新法则计算更新后的元素 $h_{1,2}^{(1)}$：\n$$\nH^{(1)} = H^{(0)} \\circ \\frac{(W^{(0)})^T X}{(W^{(0)})^T W^{(0)} H^{(0)}}\n$$\n特定元素 $h_{kj}^{(1)}$ 的值由下式给出：\n$$\nh_{kj}^{(1)} = h_{kj}^{(0)} \\times \\frac{((W^{(0)})^T X)_{kj}}{((W^{(0)})^T W^{(0)} H^{(0)})_{kj}}\n$$\n我们需要为 $k=1, j=2$ 计算这个值。给定的矩阵是：\n$$\nX \\;=\\; \\begin{pmatrix} 5  2  3 \\\\ 4  1  2 \\\\ 3  2  4 \\end{pmatrix},\\quad\nW^{(0)} \\;=\\; \\begin{pmatrix} 1  2 \\\\ 2  1 \\\\ 1  1 \\end{pmatrix},\\quad\nH^{(0)} \\;=\\; \\begin{pmatrix} 1  1  1 \\\\ 1  1  1 \\end{pmatrix}.\n$$\n\n首先，我们计算分子项 $(W^{(0)})^T X$：\n$$\n(W^{(0)})^T X = \\begin{pmatrix} 1  2  1 \\\\ 2  1  1 \\end{pmatrix} \\begin{pmatrix} 5  2  3 \\\\ 4  1  2 \\\\ 3  2  4 \\end{pmatrix} = \\begin{pmatrix} 1\\cdot5+2\\cdot4+1\\cdot3  & 1\\cdot2+2\\cdot1+1\\cdot2  & 1\\cdot3+2\\cdot2+1\\cdot4 \\\\ 2\\cdot5+1\\cdot4+1\\cdot3  & 2\\cdot2+1\\cdot1+1\\cdot2  & 2\\cdot3+1\\cdot2+1\\cdot4 \\end{pmatrix}\n$$\n$$\n(W^{(0)})^T X = \\begin{pmatrix} 5+8+3  & 2+2+2  & 3+4+4 \\\\ 10+4+3  & 4+1+2  & 6+2+4 \\end{pmatrix} = \\begin{pmatrix} 16  & 6  & 11 \\\\ 17  & 7  & 12 \\end{pmatrix}\n$$\n该矩阵的 $(1,2)$ 元素是 $((W^{(0)})^T X)_{1,2} = 6$。\n\n接下来，我们计算分母项 $(W^{(0)})^T W^{(0)} H^{(0)}$。首先，我们计算 $(W^{(0)})^T W^{(0)}$：\n$$\n(W^{(0)})^T W^{(0)} = \\begin{pmatrix} 1  2  1 \\\\ 2  1  1 \\end{pmatrix} \\begin{pmatrix} 1  2 \\\\ 2  1 \\\\ 1  1 \\end{pmatrix} = \\begin{pmatrix} 1\\cdot1+2\\cdot2+1\\cdot1  & 1\\cdot2+2\\cdot1+1\\cdot1 \\\\ 2\\cdot1+1\\cdot2+1\\cdot1  & 2\\cdot2+1\\cdot1+1\\cdot1 \\end{pmatrix} = \\begin{pmatrix} 1+4+1  & 2+2+1 \\\\ 2+2+1  & 4+1+1 \\end{pmatrix} = \\begin{pmatrix} 6  & 5 \\\\ 5  & 6 \\end{pmatrix}\n$$\n现在，我们将其乘以 $H^{(0)}$：\n$$\n(W^{(0)})^T W^{(0)} H^{(0)} = \\begin{pmatrix} 6  5 \\\\ 5  6 \\end{pmatrix} \\begin{pmatrix} 1  1  1 \\\\ 1  1  1 \\end{pmatrix} = \\begin{pmatrix} 6\\cdot1+5\\cdot1  & 6\\cdot1+5\\cdot1  & 6\\cdot1+5\\cdot1 \\\\ 5\\cdot1+6\\cdot1  & 5\\cdot1+6\\cdot1  & 5\\cdot1+6\\cdot1 \\end{pmatrix} = \\begin{pmatrix} 11  & 11  & 11 \\\\ 11  & 11  & 11 \\end{pmatrix}\n$$\n该矩阵的 $(1,2)$ 元素是 $((W^{(0)})^T W^{(0)} H^{(0)})_{1,2} = 11$。\n\n最后，我们求 $h_{1,2}^{(1)}$。从 $H^{(0)}$ 中，我们有 $h_{1,2}^{(0)} = 1$。\n$$\nh_{1,2}^{(1)} = h_{1,2}^{(0)} \\times \\frac{((W^{(0)})^T X)_{1,2}}{((W^{(0)})^T W^{(0)} H^{(0)})_{1,2}} = 1 \\times \\frac{6}{11} = \\frac{6}{11}\n$$", "answer": "$$\\boxed{\\frac{6}{11}}$$", "id": "4360201"}, {"introduction": "在真实世界的数据整合任务中，尤其是处理单细胞RNA测序（scRNA-seq）等生物医学数据时，我们面对的往往是计数数据而非连续值。本练习旨在展示如何将分解框架从标准的平方误差目标调整为更符合数据统计特性的泊松似然模型 [@problem_id:4360192]。通过推导泊松分解的对数似然函数及其梯度，您将学会如何为特定数据类型量身定制模型，这是进行有效多组学数据整合的一项关键技能。", "problem": "一个系统生物医学实验室正在通过拟合一个非负潜在因子模型来整合跨细胞的单细胞RNA测序（scRNA-seq）计数数据。设观测到的基因-细胞计数矩阵为 $X \\in \\mathbb{N}^{g \\times c}$，其中条目 $x_{ij}$ 表示基因 $i$ 在细胞 $j$ 中的独特分子标识符（UMI）计数。设 $k$ 为一个选定的潜在维度，并设 $W \\in \\mathbb{R}_{\\geq 0}^{g \\times k}$ 和 $H \\in \\mathbb{R}_{\\geq 0}^{k \\times c}$ 分别是代表基因载荷和细胞因子得分的非负矩阵。为了考虑异质的细胞测序深度，假设每个细胞 $j$ 有一个已知的正暴露度 $s_{j} \\in \\mathbb{R}_{>0}$，这些暴露度被收集到一个对角矩阵 $S \\in \\mathbb{R}^{c \\times c}$ 中，其中 $S_{jj} = s_{j}$ 且当 $j \\neq \\ell$ 时 $S_{j\\ell} = 0$。\n\n该模型假设在给定潜在因子和暴露度的情况下，计数是条件独立的，其单细胞RNA测序（scRNA-seq）的泊松分解由下式指定\n$$X_{ij} \\mid W,H,S \\sim \\mathrm{Poisson}\\!\\big(\\lambda_{ij}\\big), \\quad \\text{其中 } \\lambda_{ij} = \\big(W H S\\big)_{ij} = s_{j} \\sum_{a=1}^{k} W_{i a} H_{a j}.$$\n仅从泊松概率质量函数的定义以及跨 $i$ 和 $j$ 的独立性假设出发，执行以下操作：\n\n1. 推导上述模型的完整对数似然函数 $\\ell(W,H;X,S)$，包括所有加法项（不要舍去任何常数）。\n2. 推导分别关于 $W$ 和 $H$ 的梯度矩阵 $\\nabla_{W} \\ell$ 和 $\\nabla_{H} \\ell$，并使用矩阵运算紧凑地表示。你的推导必须尊重 $W$ 和 $H$ 的非负性，即它们是在 $W \\in \\mathbb{R}_{\\geq 0}^{g \\times k}$ 和 $H \\in \\mathbb{R}_{\\geq 0}^{k \\times c}$ 的模型下，对所述似然函数进行微分得到的。\n3. 简要陈述在 $W \\geq 0$ 和 $H \\geq 0$ 约束下的最大值的 Karush-Kuhn-Tucker (KKT) 条件，并根据最优解处梯度矩阵各项的符号进行解释。\n\n你可以定义逐元素除法运算符 $\\oslash$ 为 $(A \\oslash B)_{ij} = \\frac{A_{ij}}{B_{ij}}$（对于维数相容的矩阵 $A$ 和 $B$），以及全1矩阵 $\\mathbf{1}_{g \\times c}$ 为所有项都等于 $1$ 的 $g \\times c$ 矩阵。第1部分和第2部分的最终答案需以闭合形式表示。该问题不需要数值近似，也不涉及单位。最终答案必须是提供对数似然和两个梯度的单个解析表达式，并按以下顺序呈现：对数似然、$\\nabla_{W} \\ell$、$\\nabla_{H} \\ell$。", "solution": "该模型假设计数矩阵 $X$ 的每个条目 $X_{ij}$ 均独立地从泊松分布中抽取，其速率参数为 $\\lambda_{ij}$。对于均值为 $\\lambda$ 的泊松分布随机变量 $K$，其概率质量函数（PMF）由下式给出：\n$$P(K=k) = \\frac{\\lambda^k \\exp(-\\lambda)}{k!}$$\n鉴于计数的条件独立性，在给定参数 $W$、$H$ 和 $S$ 的情况下，观测到整个数据矩阵 $X$ 的总似然是每个条目 $X_{ij}$ 的单个泊松概率的乘积。\n\n**1. 完整对数似然函数的推导**\n\n似然函数 $L(W,H; X,S)$ 为：\n$$L = \\prod_{i=1}^{g} \\prod_{j=1}^{c} P(X_{ij} = x_{ij} \\mid \\lambda_{ij}) = \\prod_{i=1}^{g} \\prod_{j=1}^{c} \\frac{\\lambda_{ij}^{x_{ij}} \\exp(-\\lambda_{ij})}{x_{ij}!}$$\n其中 $x_{ij}$ 是观测到的计数。速率矩阵定义为 $\\Lambda = WHS$，其条目为 $\\lambda_{ij} = (WHS)_{ij} = s_{j} \\sum_{a=1}^{k} W_{ia} H_{aj}$。\n\n对数似然（记为 $\\ell(W,H; X,S)$）是似然函数 $L$ 的自然对数：\n$$\\ell = \\ln(L) = \\ln\\left( \\prod_{i=1}^{g} \\prod_{j=1}^{c} \\frac{\\lambda_{ij}^{x_{ij}} \\exp(-\\lambda_{ij})}{x_{ij}!} \\right)$$\n使用对数的性质，关于 $i$ 和 $j$ 的乘积变成了求和：\n$$\\ell = \\sum_{i=1}^{g} \\sum_{j=1}^{c} \\ln\\left( \\frac{\\lambda_{ij}^{x_{ij}} \\exp(-\\lambda_{ij})}{x_{ij}!} \\right)$$\n$$\\ell = \\sum_{i=1}^{g} \\sum_{j=1}^{c} \\left( \\ln(\\lambda_{ij}^{x_{ij}}) + \\ln(\\exp(-\\lambda_{ij})) - \\ln(x_{ij}!) \\right)$$\n这可以简化为：\n$$\\ell(W,H; X,S) = \\sum_{i=1}^{g} \\sum_{j=1}^{c} \\left( x_{ij} \\ln(\\lambda_{ij}) - \\lambda_{ij} - \\ln(x_{ij}!) \\right)$$\n将速率 $\\lambda_{ij}$ 的矩阵定义 $\\Lambda = WHS$ 代入，完整的对数似然函数是：\n$$\\ell(W,H; X,S) = \\sum_{i=1}^{g} \\sum_{j=1}^{c} \\left( X_{ij} \\ln\\left((WHS)_{ij}\\right) - (WHS)_{ij} - \\ln(X_{ij}!) \\right)$$\n项 $\\sum_{i,j} \\ln(X_{ij}!)$ 是一个关于 $W$ 和 $H$ 的常数，但根据问题要求，为得到完整的对数似然函数，我们将其包含在内。\n\n**2. 梯度矩阵的推导**\n\n为了找到梯度 $\\nabla_{W} \\ell$ 和 $\\nabla_{H} \\ell$，我们计算 $\\ell$ 关于 $W$ 和 $H$ 各个条目的偏导数。\n\n**关于 $W$ 的梯度：**\n让我们求 $\\ell$ 关于矩阵 $W$ 的单个元素 $W_{pq}$ 的偏导数。对数似然求和中依赖于 $W_{pq}$ 的项是那些 $\\lambda$ 的第一个索引为 $p$ 的项。\n$$\\frac{\\partial \\ell}{\\partial W_{pq}} = \\frac{\\partial}{\\partial W_{pq}} \\sum_{j=1}^{c} \\left( X_{pj} \\ln(\\lambda_{pj}) - \\lambda_{pj} \\right)$$\n使用链式法则：\n$$\\frac{\\partial \\ell}{\\partial W_{pq}} = \\sum_{j=1}^{c} \\left( \\frac{X_{pj}}{\\lambda_{pj}} \\frac{\\partial \\lambda_{pj}}{\\partial W_{pq}} - \\frac{\\partial \\lambda_{pj}}{\\partial W_{pq}} \\right) = \\sum_{j=1}^{c} \\left( \\frac{X_{pj}}{\\lambda_{pj}} - 1 \\right) \\frac{\\partial \\lambda_{pj}}{\\partial W_{pq}}$$\n速率为 $\\lambda_{pj} = s_j \\sum_{a=1}^{k} W_{pa} H_{aj}$。它关于 $W_{pq}$ 的导数是：\n$$\\frac{\\partial \\lambda_{pj}}{\\partial W_{pq}} = s_j H_{qj}$$\n将此代回到 $\\ell$ 的偏导数表达式中：\n$$\\frac{\\partial \\ell}{\\partial W_{pq}} = \\sum_{j=1}^{c} \\left( \\frac{X_{pj}}{(WHS)_{pj}} - 1 \\right) s_j H_{qj}$$\n此表达式代表梯度矩阵 $\\nabla_W \\ell$ 的第 $(p,q)$ 个条目。我们可以用矩阵表示法来表示它。设 $\\Lambda = WHS$。项 $\\frac{X_{pj}}{\\Lambda_{pj}} - 1$ 对应于矩阵 $X \\oslash \\Lambda - \\mathbf{1}_{g \\times c}$ 的第 $(p,j)$ 个条目。带有项 $s_j H_{qj} = (SH^T)_{jq}$ 的对 $j$ 的求和对应于一个矩阵乘法。\n$$(\\nabla_W \\ell)_{pq} = \\sum_{j=1}^{c} (X \\oslash \\Lambda - \\mathbf{1}_{g \\times c})_{pj} (SH^T)_{jq}$$\n这是矩阵乘积 $(X \\oslash \\Lambda - \\mathbf{1}_{g \\times c}) (SH^T)$ 的第 $(p,q)$ 个条目的定义。因此，梯度矩阵是：\n$$\\nabla_W \\ell = \\left( X \\oslash (WHS) - \\mathbf{1}_{g \\times c} \\right) S H^T$$\n注意，因为 $S$ 是对角矩阵，所以 $S^T=S$。\n\n**关于 $H$ 的梯度：**\n类似地，我们求 $\\ell$ 关于矩阵 $H$ 的元素 $H_{qr}$ 的偏导数。对数似然中依赖于 $H_{qr}$ 的项是那些 $\\lambda$ 的第二个索引为 $r$ 的项。\n$$\\frac{\\partial \\ell}{\\partial H_{qr}} = \\frac{\\partial}{\\partial H_{qr}} \\sum_{i=1}^{g} \\left( X_{ir} \\ln(\\lambda_{ir}) - \\lambda_{ir} \\right) = \\sum_{i=1}^{g} \\left( \\frac{X_{ir}}{\\lambda_{ir}} - 1 \\right) \\frac{\\partial \\lambda_{ir}}{\\partial H_{qr}}$$\n速率为 $\\lambda_{ir} = s_r \\sum_{a=1}^{k} W_{ia} H_{ar}$。它关于 $H_{qr}$ 的导数是：\n$$\\frac{\\partial \\lambda_{ir}}{\\partial H_{qr}} = s_r W_{iq}$$\n将此代回：\n$$\\frac{\\partial \\ell}{\\partial H_{qr}} = \\sum_{i=1}^{g} \\left( \\frac{X_{ir}}{(WHS)_{ir}} - 1 \\right) s_r W_{iq} = s_r \\sum_{i=1}^{g} W_{iq} \\left( \\frac{X_{ir}}{(WHS)_{ir}} - 1 \\right)$$\n此表达式代表梯度矩阵 $\\nabla_H \\ell$ 的第 $(q,r)$ 个条目。在矩阵表示法中，求和 $\\sum_{i=1}^{g} W_{iq} (\\dots)_{ir}$ 是乘积 $W^T (X \\oslash \\Lambda - \\mathbf{1}_{g \\times c})$ 的第 $(q,r)$ 个条目。因子 $s_r$ 应用于整个第 $r$ 列，这对应于右乘对角矩阵 $S$。\n因此，梯度矩阵是：\n$$\\nabla_H \\ell = W^T \\left( X \\oslash (WHS) - \\mathbf{1}_{g \\times c} \\right) S$$\n\n**3. Karush-Kuhn-Tucker (KKT) 条件**\n\n目标是在非负约束 $W_{ia} \\geq 0$ 和 $H_{aj} \\geq 0$（对所有索引）下最大化 $\\ell(W,H)$。KKT 条件是解在这些约束下为最优的必要一阶条件。设 $(W^*, H^*)$ 为一个最优解。KKT 条件可以表述如下：\n\n1.  **平稳性 (Stationarity)：** 对于 $W$ 中的任意条目 $(i,a)$ 和 $H$ 中的任意条目 $(a,j)$，拉格朗日函数的梯度必须为零。这导致了对数似然梯度上的条件。\n2.  **原始可行性 (Primal Feasibility)：** 解必须满足约束条件：$W^* \\geq 0$ 和 $H^* \\geq 0$（逐元素地）。\n3.  **对偶可行性 (Dual Feasibility)：** 与非负约束相关的拉格朗日乘子必须是非负的。\n4.  **互补松弛性 (Complementary Slackness)：** 对于每个约束，要么约束是活动的（变量为零），要么对应的拉格朗日乘子为零。\n\n结合这些条件，可以在最优解处根据梯度矩阵给出直接的解释：\n对于矩阵 $W$ 的每个条目 $(i,a)$：\n- 梯度条目必须是非正的：$(\\nabla_W \\ell)_{ia} \\leq 0$。\n- 如果最优值 $W_{ia}^*$ 严格为正，则相应的梯度条目必须为零：若 $W_{ia}^* > 0$，则 $(\\nabla_W \\ell)_{ia} = 0$。\n这可以总结为逐元素的条件：$\\nabla_W \\ell \\leq 0$ 和 $W^* \\odot (\\nabla_W \\ell) = 0$，其中 $\\odot$ 表示哈达玛（逐元素）积。\n\n类似地，对于矩阵 $H$ 的每个条目 $(a,j)$：\n- 梯度条目必须是非正的：$(\\nabla_H \\ell)_{aj} \\leq 0$。\n- 如果最优值 $H_{aj}^*$ 严格为正，则相应的梯度条目必须为零：若 $H_{aj}^* > 0$，则 $(\\nabla_H \\ell)_{aj} = 0$。\n这可以总结为：$\\nabla_H \\ell \\leq 0$ 和 $H^* \\odot (\\nabla_H \\ell) = 0$。\n\n简而言之，在一个约束最大值点，对数似然的梯度只能指向“进入”约束的方向（即对于最大化问题，指向负方向）。一个非约束元素（严格为正）必须使其对应的梯度分量为零，就像在无约束优化中一样。", "answer": "$$\\boxed{\\begin{pmatrix} \\sum_{i=1}^{g} \\sum_{j=1}^{c} \\left( X_{ij} \\ln\\left((WHS)_{ij}\\right) - (WHS)_{ij} - \\ln(X_{ij}!) \\right) \\\\ \\left( X \\oslash (WHS) - \\mathbf{1}_{g \\times c} \\right) S H^T \\\\ W^T \\left( X \\oslash (WHS) - \\mathbf{1}_{g \\times c} \\right) S \\end{pmatrix}}$$", "id": "4360192"}, {"introduction": "当数据结构超越二维矩阵时，例如，当我们需要同时整合样本、分子特征和时间点等多个维度时，就需要将分解思想推广到更高阶的张量。本练习将介绍高阶奇异值分解（Higher-Order Singular Value Decomposition, HOSVD），这是一种用于分解多维数组的强大工具 [@problem_id:4360195]。通过从头推导HOSVD的构造、证明其核心张量的正交性，并建立截断近似的误差界，您将掌握分析复杂多模态数据集的核心理论基础。", "problem": "考虑一个来源于系统生物医学的三阶数据张量 $\\mathcal{X} \\in \\mathbb{R}^{I_{1} \\times I_{2} \\times I_{3}}$，该张量是通过整合跨越患者、分子特征和时间的多组学测量数据得到的。令 $\\mathcal{X}_{(n)}$ 表示 $\\mathcal{X}$ 的模-$n$ 展开，并通过对每个展开矩阵执行奇异值分解 (SVD) 来定义 $\\mathcal{X}$ 的高阶奇异值分解 (HOSVD)。从任何实矩阵 $M$ 都存在奇异值分解 (SVD) $M = U \\Sigma V^{\\top}$（其中 $U$ 和 $V$ 的列是正交归一的，$\\Sigma$ 是对角矩阵且其对角元为非负的奇异值）这一基本定义出发，并利用张量与矩阵的 $n$-模积的定义，推导 $\\mathcal{X}$ 的 HOSVD，并描述所得因子矩阵和核心张量的正交性质。具体而言：\n\n1. 从基本原理出发，推导 HOSVD 的构造过程，其中因子矩阵 $U^{(n)}$ 是通过 $\\mathcal{X}_{(n)}$ 的左奇异向量得到的，而核心张量 $\\mathcal{G}$ 是通过将 $\\mathcal{X}$ 沿所有模投影到这些正交归一因子上得到的。\n2. 证明 HOSVD 核心张量的全正交性，即对于每个模 $n$，通过固定第 $n$ 个索引得到的子张量是相互正交的。\n3. 通过用展开矩阵的奇异值来界定近似的弗罗贝尼乌斯范数误差，为多线性秩为 $(r_{1}, r_{2}, r_{3})$ 的截断 HOSVD 建立一个有原则的近似保证。你的推导必须从正交投影的性质以及投影误差与奇异值的关系出发；不要直接使用任何已有的 HOSVD 误差界限的专用公式。\n\n最后，考虑一个特定的张量 $\\mathcal{X}$，其展开矩阵 $\\mathcal{X}_{(1)}$、$\\mathcal{X}_{(2)}$ 和 $\\mathcal{X}_{(3)}$ 的奇异值（按非增序排列）如下：\n$\\sigma^{(1)} = [14, 10, 6, 3, 1]$，\n$\\sigma^{(2)} = [13, 9, 5, 4, 2, 1]$，\n$\\sigma^{(3)} = [15, 7, 3, 2]$。\n使用你推导出的界限，计算当多线性秩为 $(r_{1}, r_{2}, r_{3}) = (2, 3, 2)$ 时，截断 HOSVD 近似的弗罗贝尼乌斯范数误差的最小保证上限。将最终的数值界限表示为一个实数，并将答案四舍五入到四位有效数字。不需要单位。", "solution": "### 1. HOSVD 构造的推导\n\n令 $\\mathcal{X} \\in \\mathbb{R}^{I_{1} \\times I_{2} \\times I_{3}}$ 为一个三阶张量。$\\mathcal{X}$ 的模-$n$ 展开，记为 $\\mathcal{X}_{(n)}$，是一个包含该张量所有元素的矩阵。对于 $n=1, 2, 3$，这些矩阵分别为 $\\mathcal{X}_{(1)} \\in \\mathbb{R}^{I_{1} \\times I_{2}I_{3}}$，$\\mathcal{X}_{(2)} \\in \\mathbb{R}^{I_{2} \\times I_{1}I_{3}}$ 和 $\\mathcal{X}_{(3)} \\in \\mathbb{R}^{I_{3} \\times I_{1}I_{2}}$。\n\nHOSVD 是通过对每个模-$n$ 展开矩阵进行奇异值分解 (SVD) 来构造的。实矩阵 $\\mathcal{X}_{(n)}$ 的 SVD 形式为：\n$$\n\\mathcal{X}_{(n)} = U^{(n)} \\Sigma^{(n)} (V^{(n)})^{\\top}\n$$\n其中 $U^{(n)} \\in \\mathbb{R}^{I_{n} \\times I_{n}}$ 是一个正交矩阵，其列是 $\\mathcal{X}_{(n)}$ 的左奇异向量。这些因子矩阵 $U^{(n)}$ 构成了 HOSVD 的正交基。\n\n核心张量 $\\mathcal{G}$ 定义为将 $\\mathcal{X}$ 投影到由这些因子矩阵构成的基上。该投影通过模-$n$ 积实现。张量 $\\mathcal{A}$ 与矩阵 $M$ 的模-$n$ 积为 $\\mathcal{B} = \\mathcal{A} \\times_n M$。为了将 $\\mathcal{X}$ 投影到由 $U^{(n)}$ 定义的基上，我们使用矩阵 $(U^{(n)})^{\\top}$。因此，核心张量 $\\mathcal{G}$ 是通过沿每个模应用此变换得到的：\n$$\n\\mathcal{G} = \\mathcal{X} \\times_1 (U^{(1)})^{\\top} \\times_2 (U^{(2)})^{\\top} \\times_3 (U^{(3)})^{\\top}\n$$\n为了证明该构造的有效性，我们必须能够从 $\\mathcal{G}$ 和因子矩阵重构出 $\\mathcal{X}$。我们对 $\\mathcal{G}$ 应用正向模积：\n$$\n\\mathcal{G} \\times_1 U^{(1)} \\times_2 U^{(2)} \\times_3 U^{(3)} = (\\mathcal{X} \\times_1 (U^{(1)})^{\\top} \\times_2 (U^{(2)})^{\\top} \\times_3 (U^{(3)})^{\\top}) \\times_1 U^{(1)} \\times_2 U^{(2)} \\times_3 U^{(3)}\n$$\n利用不同模上的模积可交换以及 $(\\mathcal{A} \\times_n B) \\times_n C = \\mathcal{A} \\times_n (CB)$ 的性质，我们将每个模的操作组合在一起：\n$$\n\\text{重构} = \\mathcal{X} \\times_1 ((U^{(1)})^{\\top}U^{(1)}) \\times_2 ((U^{(2)})^{\\top}U^{(2)}) \\times_3 ((U^{(3)})^{\\top}U^{(3)})\n$$\n由于每个 $U^{(n)}$ 都是正交矩阵，$(U^{(n)})^{\\top}U^{(n)} = I$ 是单位矩阵。表达式简化为：\n$$\n\\text{重构} = \\mathcal{X} \\times_1 I \\times_2 I \\times_3 I = \\mathcal{X}\n$$\n这证实了基本的 HOSVD 关系：\n$$\n\\mathcal{X} = \\mathcal{G} \\times_1 U^{(1)} \\times_2 U^{(2)} \\times_3 U^{(3)}\n$$\n这就完成了 HOSVD 构造的推导。\n\n### 2. 核心张量全正交性的证明\n\n全正交性指的是，对于任意模 $n$，通过固定第 $n$ 个索引得到的任意两个子张量 $\\mathcal{G}_{i_n=a}$ 和 $\\mathcal{G}_{i_n=b}$（其中 $a \\neq b$）是相互正交的。两个相同维度张量 $\\mathcal{A}$ 和 $\\mathcal{B}$ 的内积为 $\\langle \\mathcal{A}, \\mathcal{B} \\rangle = \\sum \\text{vec}(\\mathcal{A}) \\cdot \\text{vec}(\\mathcal{B})$。我们需要证明对于 $a \\neq b$，有 $\\langle \\mathcal{G}_{i_n=a}, \\mathcal{G}_{i_n=b} \\rangle = 0$。\n\n这等价于证明模-$n$ 展开矩阵 $\\mathcal{G}_{(n)}$ 的各行是正交的，即 $\\mathcal{G}_{(n)}(\\mathcal{G}_{(n)})^{\\top}$ 是对角矩阵。\n\n让我们使用 HOSVD 方程的展开形式：\n$$\n\\mathcal{X}_{(n)} = U^{(n)} \\mathcal{G}_{(n)} (U^{(n+2)} \\otimes U^{(n+1)})^{\\top}\n$$\n(下标循环解释)。\n\n我们构造矩阵 $\\mathcal{X}_{(n)}(\\mathcal{X}_{(n)})^{\\top}$：\n$$\n\\mathcal{X}_{(n)}(\\mathcal{X}_{(n)})^{\\top} = \\left( U^{(n)} \\mathcal{G}_{(n)} (U^{(n+2)} \\otimes U^{(n+1)})^{\\top} \\right) \\left( (U^{(n+2)} \\otimes U^{(n+1)}) \\mathcal{G}_{(n)}^{\\top} (U^{(n)})^{\\top} \\right)\n$$\n由于正交矩阵的克罗内克积也是正交矩阵，$(U^{(n+2)} \\otimes U^{(n+1)})^{\\top}(U^{(n+2)} \\otimes U^{(n+1)}) = I$。表达式简化为：\n$$\n\\mathcal{X}_{(n)}(\\mathcal{X}_{(n)})^{\\top} = U^{(n)} \\mathcal{G}_{(n)} \\mathcal{G}_{(n)}^{\\top} (U^{(n)})^{\\top}\n$$\n现在我们使用 $\\mathcal{X}_{(n)}$ 的 SVD：$\\mathcal{X}_{(n)} = U^{(n)} \\Sigma^{(n)} (V^{(n)})^{\\top}$。\n$$\n\\mathcal{X}_{(n)}(\\mathcal{X}_{(n)})^{\\top} = (U^{(n)} \\Sigma^{(n)} (V^{(n)})^{\\top}) (V^{(n)} (\\Sigma^{(n)})^{\\top} (U^{(n)})^{\\top}) = U^{(n)} (\\Sigma^{(n)}(\\Sigma^{(n)})^{\\top}) (U^{(n)})^{\\top}\n$$\n通过比较 $\\mathcal{X}_{(n)}(\\mathcal{X}_{(n)})^{\\top}$ 的两个表达式：\n$$\nU^{(n)} \\mathcal{G}_{(n)} \\mathcal{G}_{(n)}^{\\top} (U^{(n)})^{\\top} = U^{(n)} (\\Sigma^{(n)}(\\Sigma^{(n)})^{\\top}) (U^{(n)})^{\\top}\n$$\n两边分别左乘 $(U^{(n)})^{\\top}$ 并右乘 $U^{(n)}$，我们得到：\n$$\n\\mathcal{G}_{(n)} \\mathcal{G}_{(n)}^{\\top} = \\Sigma^{(n)}(\\Sigma^{(n)})^{\\top}\n$$\n右边的矩阵是一个对角矩阵，其对角元是平方奇异值 $(\\sigma_i^{(n)})^2$。$\\mathcal{G}_{(n)}(\\mathcal{G}_{(n)})^{\\top}$ 的第 $(a,b)$ 个元素是 $\\mathcal{G}_{(n)}$ 的第 $a$ 行和第 $b$ 行的内积，这对应于 $\\langle \\mathcal{G}_{i_n=a}, \\mathcal{G}_{i_n=b} \\rangle$。\n由于该矩阵是对角的，其非对角元为零。因此，对于 $a \\neq b$，$\\langle \\mathcal{G}_{i_n=a}, \\mathcal{G}_{i_n=b} \\rangle = 0$，证明了核心张量 $\\mathcal{G}$ 的全正交性。\n\n### 3. 截断 HOSVD 误差界的推导\n\n多线性秩为 $(r_{1}, r_{2}, r_{3})$ 的截断 HOSVD 由 $\\tilde{\\mathcal{X}}$ 给出，其中因子矩阵 $\\tilde{U}^{(n)}$ 仅包含 $U^{(n)}$ 的前 $r_n$ 列。近似张量 $\\tilde{\\mathcal{X}}$ 是将原始张量 $\\mathcal{X}$ 投影到由这些截断因子矩阵张成的子空间上得到的。\n\n我们想界定弗罗贝尼乌斯范数误差 $\\|\\mathcal{X} - \\tilde{\\mathcal{X}}\\|_F^2$。一个标准的误差界可以通过将总误差分解为一系列正交投影误差的和来推导。误差可以写成伸缩和的形式：\n$$\n\\mathcal{X} - \\tilde{\\mathcal{X}} = (\\mathcal{X} - \\mathcal{X} \\times_1 P_1) + (\\mathcal{X} \\times_1 P_1 - \\mathcal{X} \\times_1 P_1 \\times_2 P_2) + \\dots\n$$\n其中 $P_n = \\tilde{U}^{(n)}(\\tilde{U}^{(n)})^{\\top}$ 是到模-$n$ 子空间上的投影矩阵。利用弗罗贝尼乌斯范数在张量展开下的不变性，以及SVD的最佳低秩逼近性质，可以证明总误差的平方范数受每个模态中被截断的奇异值平方和的总和的限制。\n具体来说，将 $\\mathcal{X}$ 投影到由前 $r_n$ 个模-$n$ 奇异向量张成的子空间上所产生的误差的平方范数，等于被舍弃的奇异值的平方和。通过对所有模态的误差贡献求和，我们得到一个误差上界：\n$$\n\\|\\mathcal{X} - \\tilde{\\mathcal{X}}\\|_F^2 \\le \\sum_{n=1}^3 \\|\\mathcal{X} - \\mathcal{X} \\times_n P_n\\|_F^2\n$$\n利用范数不变性和SVD的性质，我们有：\n$$\n\\|\\mathcal{X} - \\mathcal{X} \\times_n P_n\\|_F^2 = \\|\\mathcal{X}_{(n)} - P_n\\mathcal{X}_{(n)}\\|_F^2 = \\sum_{i=r_n+1}^{I_n} (\\sigma_i^{(n)})^2\n$$\n因此，截断HOSVD的近似误差平方范数的一个（非紧）上界为：\n$$\n\\|\\mathcal{X} - \\tilde{\\mathcal{X}}\\|_F^2 \\le \\sum_{i=r_1+1}^{I_1} (\\sigma_i^{(1)})^2 + \\sum_{j=r_2+1}^{I_2} (\\sigma_j^{(2)})^2 + \\sum_{k=r_3+1}^{I_3} (\\sigma_k^{(3)})^2\n$$\n这个界为近似质量提供了一个有原则的保证。\n\n### 最终计算\n\n给定奇异值：\n$\\sigma^{(1)} = [14, 10, 6, 3, 1]$\n$\\sigma^{(2)} = [13, 9, 5, 4, 2, 1]$\n$\\sigma^{(3)} = [15, 7, 3, 2]$\n以及多线性秩 $(r_1, r_2, r_3) = (2, 3, 2)$。\n\n弗罗贝尼乌斯范数平方误差的上界，记为 $E^2$，是：\n$$\nE^2 \\le \\sum_{i=r_1+1}^{I_1} (\\sigma_i^{(1)})^2 + \\sum_{j=r_2+1}^{I_2} (\\sigma_j^{(2)})^2 + \\sum_{k=r_3+1}^{I_3} (\\sigma_k^{(3)})^2\n$$\n- 对于模 1 ($r_1=2$)： $\\sum_{i=3}^{5} (\\sigma_i^{(1)})^2 = 6^2 + 3^2 + 1^2 = 36 + 9 + 1 = 46$。\n- 对于模 2 ($r_2=3$)： $\\sum_{j=4}^{6} (\\sigma_j^{(2)})^2 = 4^2 + 2^2 + 1^2 = 16 + 4 + 1 = 21$。\n- 对于模 3 ($r_3=2$)： $\\sum_{k=3}^{4} (\\sigma_k^{(3)})^2 = 3^2 + 2^2 = 9 + 4 = 13$。\n\n平方误差的总上界为：\n$$\nE^2 \\le 46 + 21 + 13 = 80\n$$\n问题要求的是弗罗贝尼乌斯范数误差的上界，即该值的平方根：\n$$\nE \\le \\sqrt{80}\n$$\n计算数值：\n$$\n\\sqrt{80} = \\sqrt{16 \\times 5} = 4\\sqrt{5} \\approx 8.9442719...\n$$\n四舍五入到四位有效数字，结果是 $8.944$。", "answer": "$$\\boxed{8.944}$$", "id": "4360195"}]}