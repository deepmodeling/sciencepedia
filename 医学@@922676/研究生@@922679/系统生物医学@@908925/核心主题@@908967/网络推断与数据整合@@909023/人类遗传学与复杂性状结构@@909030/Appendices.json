{"hands_on_practices": [{"introduction": "对复杂性状的研究始于一个基本问题：个体间的性状差异在多大程度上是由基因决定的，又在多大程度上是由环境影响的？本练习将深入探讨经典的双生子研究，这是一个用于剖析此问题的强大自然实验。通过比较同卵（MZ）双生子和异卵（DZ）双生子的相似性，你将推导并应用ACE模型的关键公式，以估算狭义遗传力（$h^2$），这是数量遗传学的基石 [@problem_id:4352561]。本练习不仅能巩固你对变异组分的理解，还将引导你批判性地思考该模型的假设以及区分不同家族相似性来源的可识别性问题。", "problem": "在一个从单一随机交配群体中抽取的大型双生子登记库中，测量了一个复杂数量性状。假设遵循数量遗传学和经典双生子设计的以下基本前提：(i) 性状方差可以分解为加性遗传方差、共同环境方差和独特环境方差；(ii) 同卵（MZ）双生子在整个基因组中共享几乎所有因遗传而相同的分离等位基因，而异卵（DZ）双生子平均共享一半；(iii) 等环境假说（EEA）成立，且不存在选择性婚配、基因-环境相关或基因-环境交互作用；(iv) 测量误差是独特环境方差组分的一部分。设表型方差标准化为1。\n\n将加性遗传方差定义为 $V_{A}$，共同环境方差定义为 $V_{C}$，独特环境方差定义为 $V_{E}$。设观察到的同卵双生子性状对内相关性为 $r_{MZ} = 0.68$，异卵双生子为 $r_{DZ} = 0.44$。\n\n仅使用上述基本前提，在加性遗传-共同环境-独特环境（ACE）模型中，推导同卵和异卵双生子的期望对内相关性作为 $V_{A}$、$V_{C}$ 和 $V_{E}$ 的函数表达式，并由此获得以 $r_{MZ}$ 和 $r_{DZ}$ 表示的狭义遗传力 $h^{2}$ 的估计量。然后，使用给定的相关性计算 $h^{2}$ 的数值。将最终的遗传力表示为小数，并四舍五入到四位有效数字。\n\n最后，基于相同的前提，分析在仅有 $r_{MZ}$ 和 $r_{DZ}$ 可用时，共同环境方差 $V_{C}$ 与显性遗传方差 $V_{D}$ 的可识别性，并形式化描述 $r_{DZ}$ 相对于 $\\tfrac{1}{2} r_{MZ}$ 的模式在何种条件下能够为判断共同环境或显性遗传哪个是超出加性效应的额外相似性的更合理解释来源提供信息。在你的分析中，除了双生子相关性外，不要引入任何额外的数据源。", "solution": "问题陈述已经过验证，被认为是合理的。它科学地基于数量遗传学的原理，特别是经典双生子研究设计。该问题是良定的，提供了充分且一致的信息来推导所要求的量和分析。其语言客观，并采用了该领域的标准术语。\n\n该问题要求基于加性遗传-共同环境-独特环境（ACE）模型进行几项推导和一次计算，然后对模型的可识别性进行理论分析。\n\n**第一部分：ACE模型中双生子相关性的推导**\n\n个体表型 $P$ 的基础模型由其组成部分之和给出：\n$$ P = A + C + E $$\n其中 $A$ 代表加性遗传效应，$C$ 代表共享或共同环境效应，$E$ 代表独特或非共享环境效应。\n\n总表型方差 $V_P$ 是这些组分方差之和，根据问题陈述的前提，假设它们是不相关的：\n$$ V_P = V_A + V_C + V_E $$\n问题指定表型方差被标准化为1，所以 $V_P = 1$。这意味着：\n$$ V_A + V_C + V_E = 1 $$\n\n双生子对中两个成员（用下标 $1$ 和 $2$ 表示）之间性状的相关性定义为它们的表型协方差与总表型方差之比：\n$$ r = \\frac{\\text{Cov}(P_1, P_2)}{V_P} $$\n由于 $V_P = 1$，相关性就等于协方差：\n$$ r = \\text{Cov}(P_1, P_2) = \\text{Cov}(A_1 + C_1 + E_1, A_2 + C_2 + E_2) $$\n展开协方差，并利用 $A$、$C$ 和 $E$ 组分相互不相关的假设，我们得到：\n$$ r = \\text{Cov}(A_1, A_2) + \\text{Cov}(C_1, C_2) + \\text{Cov}(E_1, E_2) $$\n\n现在我们将此应用于同卵（MZ）和异卵（DZ）双生子。\n\n对于**同卵（MZ）双生子**，他们在遗传上是相同的，共享100%的等位基因。因此，他们加性遗传效应的协方差就是总加性遗传方差：\n$$ \\text{Cov}(A_1, A_2) = V_A $$\n根据共享环境的定义，他们完全共享这一组分。因此，他们共享环境效应的协方差就是总共享环境方差：\n$$ \\text{Cov}(C_1, C_2) = V_C $$\n根据定义，任何两个个体（包括双生子）之间的独特环境都是不相关的。\n$$ \\text{Cov}(E_1, E_2) = 0 $$\n将这些分量相加，得到同卵双生子的期望相关性：\n$$ r_{MZ} = V_A + V_C $$\n\n对于**异卵（DZ）双生子**，他们平均共享50%的分离等位基因，其加性遗传效应的协方差是加性遗传方差的一半：\n$$ \\text{Cov}(A_1, A_2) = \\frac{1}{2} V_A $$\n在等环境假说（EEA）下，假设异卵双生子与同卵双生子在相同程度上共享他们的共同环境。因此：\n$$ \\text{Cov}(C_1, C_2) = V_C $$\n他们的独特环境也是不相关的：\n$$ \\text{Cov}(E_1, E_2) = 0 $$\n将这些分量相加，得到异卵双生子的期望相关性：\n$$ r_{DZ} = \\frac{1}{2} V_A + V_C $$\n\n**第二部分：狭义遗传力（$h^2$）估计量的推导**\n\n狭义遗传力 $h^2$ 定义为总表型方差中可归因于加性遗传方差的比例：\n$$ h^2 = \\frac{V_A}{V_P} $$\n由于 $V_P = 1$，我们有 $h^2 = V_A$。我们可以通过求解上面推导出的线性方程组来获得 $V_A$ 的估计量：\n1. $r_{MZ} = V_A + V_C$\n2. $r_{DZ} = \\frac{1}{2} V_A + V_C$\n\n从第一个方程中减去第二个方程，可以消去 $V_C$：\n$$ r_{MZ} - r_{DZ} = (V_A + V_C) - \\left(\\frac{1}{2} V_A + V_C\\right) $$\n$$ r_{MZ} - r_{DZ} = V_A - \\frac{1}{2} V_A = \\frac{1}{2} V_A $$\n解出 $V_A$ 得到：\n$$ V_A = 2(r_{MZ} - r_{DZ}) $$\n因此，狭义遗传力的估计量为：\n$$ h^2 = 2(r_{MZ} - r_{DZ}) $$\n这通常被称为 Falconer 公式。\n\n**第三部分：$h^2$ 的数值计算**\n\n使用给定的相关性值 $r_{MZ} = 0.68$ 和 $r_{DZ} = 0.44$：\n$$ h^2 = 2(0.68 - 0.44) = 2(0.24) = 0.48 $$\n问题要求答案四舍五入到四位有效数字，即 $0.4800$。\n\n**第四部分：$V_C$ 与 $V_D$ 可识别性的分析**\n\n问题的最后一部分要求分析在仅有双生子相关性可用时，共享环境方差（$V_C$）与显性遗传方差（$V_D$）的可识别性。这需要将标准的ACE模型与一个替代模型——ADE模型进行比较，ADE模型包含显性效应但排除了共享环境。\n\n在ADE模型中，表型为 $P = A + D + E$，方差为 $V_P = V_A + V_D + V_E = 1$。相关性由协方差推导得出：\n- 同卵双生子共享100%的加性效应和100%的显性效应。因此，$r_{MZ} = \\text{Cov}(A_1, A_2) + \\text{Cov}(D_1, D_2) = V_A + V_D$。\n- 异卵双生子共享50%的加性效应。他们在某一基因座上共享两个因遗传而相同的等位基因的概率是 $\\frac{1}{4}$，所以他们显性效应的协方差是 $\\frac{1}{4}V_D$。因此，$r_{DZ} = \\frac{1}{2}V_A + \\frac{1}{4}V_D$。\n\n**可识别性问题**：仅有两个可观测量（$r_{MZ}$ 和 $r_{DZ}$），我们最多只能唯一求解两个未知参数。ACE模型估计 $V_A$ 和 $V_C$。ADE模型估计 $V_A$ 和 $V_D$。仅从同卵和异卵双生子数据中不可能同时估计 $V_A$、$V_C$ 和 $V_D$；这是双生子设计中的一个经典混淆问题。在一个完整的ACDE模型中，参数 $V_C$ 和 $V_D$ 是不可识别的。\n\n**形式化条件**：然而，我们可以利用相关性的模式来推断哪种模型（ACE或ADE）为数据提供了更合理的解释。这取决于将 $r_{DZ}$ 与 $\\frac{1}{2}r_{MZ}$ 进行比较。\n\n让我们分析每种模型的关系：\n\n情况1：**ACE模型**。我们有 $r_{MZ} = V_A + V_C$ 和 $r_{DZ} = \\frac{1}{2}V_A + V_C$。\n让我们用 $r_{MZ}$ 来表示 $r_{DZ}$：\n从第一个方程，有 $V_A = r_{MZ} - V_C$。代入第二个方程：\n$$ r_{DZ} = \\frac{1}{2}(r_{MZ} - V_C) + V_C = \\frac{1}{2}r_{MZ} - \\frac{1}{2}V_C + V_C = \\frac{1}{2}r_{MZ} + \\frac{1}{2}V_C $$\n由于方差必须为非负值（$V_C \\ge 0$），ACE模型意味着：\n$$ r_{DZ} \\ge \\frac{1}{2}r_{MZ} $$\n具体来说，如果共享环境效应对相似性有贡献（$V_C > 0$），那么 $r_{DZ}$ 将大于 $r_{MZ}$ 的一半。\n\n情况2：**ADE模型**。我们有 $r_{MZ} = V_A + V_D$ 和 $r_{DZ} = \\frac{1}{2}V_A + \\frac{1}{4}V_D$。\n让我们用 $r_{MZ}$ 来表示 $r_{DZ}$。一个直接的方法是比较 $r_{DZ}$ 和 $\\frac{1}{2}r_{MZ}$：\n$$ \\frac{1}{2}r_{MZ} = \\frac{1}{2}(V_A + V_D) = \\frac{1}{2}V_A + \\frac{1}{2}V_D $$\n现在，考虑它们的差值：\n$$ \\frac{1}{2}r_{MZ} - r_{DZ} = \\left(\\frac{1}{2}V_A + \\frac{1}{2}V_D\\right) - \\left(\\frac{1}{2}V_A + \\frac{1}{4}V_D\\right) = \\frac{1}{4}V_D $$\n由于显性方差必须为非负值（$V_D \\ge 0$），ADE模型意味着：\n$$ \\frac{1}{2}r_{MZ} - r_{DZ} \\ge 0 \\implies r_{DZ} \\le \\frac{1}{2}r_{MZ} $$\n具体来说，如果存在显性效应（$V_D > 0$），那么 $r_{DZ}$ 将小于 $r_{MZ}$ 的一半。\n\n**分析结论**：区分共享环境影响与遗传显性影响的条件是比较 $r_{DZ}$ 与 $\\frac{1}{2} r_{MZ}$。\n- 如果 $r_{DZ} > \\frac{1}{2} r_{MZ}$，双生子相似性模式表明存在共享环境效应（$V_C$）。\n- 如果 $r_{DZ}  \\frac{1}{2} r_{MZ}$，该模式表明存在显性遗传效应（$V_D$）。\n- 如果 $r_{DZ} = \\frac{1}{2} r_{MZ}$，数据与简单的AE模型一致，其中 $V_C$ 和 $V_D$ 都不是重要因素。\n\n对于所提供的数据（$r_{MZ} = 0.68$, $r_{DZ} = 0.44$），我们有 $\\frac{1}{2}r_{MZ} = \\frac{1}{2}(0.68) = 0.34$。由于 $r_{DZ} = 0.44 > 0.34$，数据强烈表明存在共享环境效应，这证明了使用ACE模型而非ADE模型是合理的。", "answer": "$$\n\\boxed{0.4800}\n$$", "id": "4352561"}, {"introduction": "一旦我们知道某个性状是可遗传的，我们如何定位导致这种遗传性的具体基因呢？全基因组关联研究（GWAS）之所以可行，是基于一种被称为连锁不平衡（LD）的群体遗传学现象，即等位基因之间的非随机关联。本练习将指导你直接从单倍型数据入手，计算连锁不平衡的基本度量指标 $D$ 和 $r^2$，并推导重组作用如何随时间削弱连锁不平衡的经典方程 [@problem_id:4352653]。这项基础练习对于理解GWAS的设计、精细定位因果变异的挑战以及人类基因组中遗传变异的整体架构至关重要。", "problem": "考虑一个大的随机交配群体中的两个双等位基因座，第一个基因座的等位基因为 $\\{A,a\\}$，第二个基因座的等位基因为 $\\{B,b\\}$。你对一个包含 $N$ 个单倍型的随机样本进行基因分型和定相，观察到以下单倍型计数：$n_{AB} = 210$，$n_{Ab} = 90$，$n_{aB} = 70$，$n_{ab} = 130$，因此 $N = 500$。设 $X$ 是一个指示随机变量，当一个抽样的单倍型携带等位基因 $A$ 时，$X$ 等于 $1$，否则等于 $0$；设 $Y$ 是一个指示随机变量，当一个抽样的单倍型携带等位基因 $B$ 时，$Y$ 等于 $1$，否则等于 $0$。仅使用二元随机变量的概率、期望、协方差和相关性的核心定义，以及标准的离散世代重组模型（随机交配，无选择、突变、迁移或基因转换），完成以下任务：\n\n1. 根据观察到的计数，计算样本单倍型频率、边际等位基因频率 $p_{A}$ 和 $p_{B}$，然后推导经典连锁不平衡（LD）系数 $D$，其定义为协方差 $\\operatorname{Cov}(X,Y)$。\n\n2. 从第一性原理出发，推导 $X$ 和 $Y$ 之间的平方相关系数 $r^{2}$，用 $D$、$p_{A}$ 和 $p_{B}$ 表示你的结果。\n\n3. 从离散世代重组过程和针对重组与非重组配子的全概率定律出发，推导 $t$ 代后的期望LD，$D_{t}$，作为初始LD和每代重组率 $c$ 的闭合形式函数。\n\n报告 $D$ 和 $r^{2}$ 的数值，保留四位有效数字，并将 $D_{t}$ 表示为包含 $c$ 和 $t$ 的解析表达式，其中初始 $D$ 的数值系数保留四位有效数字。本问题中的所有量都是无量纲的；在最终的数值答案中不要包含任何单位。", "solution": "该问题经检验具有科学依据、问题明确且客观。这是理论群体遗传学中的一个标准问题，提供了所有必要的数据和定义。我们着手提供完整解答。\n\n该问题分为三个部分。首先，我们根据提供的计数计算样本单倍型和等位基因频率，然后用这些频率计算连锁不平衡系数 $D$。其次，我们推导平方相关系数 $r^2$ 并计算其数值。第三，我们推导 $t$ 代后的期望连锁不平衡 $D_t$，作为初始不平衡和重组率 $c$ 的函数。\n\n**第一部分：频率和连锁不平衡系数 $D$ 的计算**\n\n抽样的单倍型总数为 $N$。给定的计数为 $n_{AB} = 210$，$n_{Ab} = 90$，$n_{aB} = 70$ 和 $n_{ab} = 130$。\n$$N = n_{AB} + n_{Ab} + n_{aB} + n_{ab} = 210 + 90 + 70 + 130 = 500$$\n样本单倍型频率 ($p_{uv}$) 通过观察到的计数除以总样本量来估计：\n$$p_{AB} = \\frac{n_{AB}}{N} = \\frac{210}{500} = 0.42$$\n$$p_{Ab} = \\frac{n_{Ab}}{N} = \\frac{90}{500} = 0.18$$\n$$p_{aB} = \\frac{n_{aB}}{N} = \\frac{70}{500} = 0.14$$\n$$p_{ab} = \\frac{n_{ab}}{N} = \\frac{130}{500} = 0.26$$\n这些频率的总和为 $0.42 + 0.18 + 0.14 + 0.26 = 1.00$，符合要求。\n\n等位基因 $A$ ($p_A$) 和 $B$ ($p_B$) 的边际等位基因频率是通过对携带它们的单倍型频率求和来计算的：\n$$p_A = P(X=1) = p_{AB} + p_{Ab} = 0.42 + 0.18 = 0.60$$\n$$p_B = P(Y=1) = p_{AB} + p_{aB} = 0.42 + 0.14 = 0.56$$\n备择等位基因 $a$ 和 $b$ 的频率为：\n$$p_a = P(X=0) = 1 - p_A = 1 - 0.60 = 0.40$$\n$$p_b = P(Y=0) = 1 - p_B = 1 - 0.56 = 0.44$$\n\n连锁不平衡系数 $D$ 定义为指示随机变量 $X$ 和 $Y$ 的协方差，$D = \\operatorname{Cov}(X,Y)$。根据定义，协方差为 $\\operatorname{Cov}(X,Y) = E[XY] - E[X]E[Y]$。\n对于指示变量 $X$，其期望为 $E[X] = 1 \\cdot P(X=1) + 0 \\cdot P(X=0) = P(X=1) = p_A$。\n同样，对于指示变量 $Y$，$E[Y] = p_B$。\n乘积 $XY$ 也是一个指示变量。当且仅当 $X=1$ 且 $Y=1$ 时，它等于 $1$，这对应于个体携带 $AB$ 单倍型。因此，其期望为 $E[XY] = 1 \\cdot P(X=1, Y=1) + 0 \\cdot P(\\text{not } (X=1,Y=1)) = P(X=1, Y=1) = p_{AB}$。\n将这些期望代入协方差公式，得到 $D$ 的标准表达式：\n$$D = p_{AB} - p_A p_B$$\n使用计算出的频率值：\n$$D = 0.42 - (0.60)(0.56) = 0.42 - 0.336 = 0.084$$\n保留四位有效数字，初始连锁不平衡（我们记为 $D_0$）为 $0.08400$。\n\n**第二部分：平方相关系数 $r^2$ 的推导与计算**\n\n两个随机变量 $X$ 和 $Y$ 之间的平方相关系数 $r^2$ 定义为：\n$$r^2 = \\frac{(\\operatorname{Cov}(X,Y))^2}{\\operatorname{Var}(X)\\operatorname{Var}(Y)}$$\n从第一部分可知，$\\operatorname{Cov}(X,Y) = D$。\n接下来，我们必须求出指示变量 $X$ 和 $Y$ 的方差。对于像 $X$ 这样的伯努利随机变量，方差为 $\\operatorname{Var}(X) = E[X^2] - (E[X])^2$。由于 $X$ 只取值 $0$ 和 $1$，因此 $X^2 = X$。所以，$E[X^2]=E[X]=p_A$。\n$X$ 的方差为：\n$$\\operatorname{Var}(X) = E[X] - (E[X])^2 = p_A - (p_A)^2 = p_A(1 - p_A)$$\n同样，$Y$ 的方差为：\n$$\\operatorname{Var}(Y) = p_B(1 - p_B)$$\n将协方差和方差代入 $r^2$ 的公式，得到用 $D$、$p_A$ 和 $p_B$ 表示的期望表达式：\n$$r^2 = \\frac{D^2}{p_A(1-p_A)p_B(1-p_B)}$$\n现在，我们使用计算出的参数来计算其数值：\n$$r^2 = \\frac{(0.084)^2}{(0.60)(1-0.60)(0.56)(1-0.56)} = \\frac{0.007056}{(0.60)(0.40)(0.56)(0.44)}$$\n$$r^2 = \\frac{0.007056}{(0.24)(0.2464)} = \\frac{0.007056}{0.059136} \\approx 0.119317...$$\n保留四位有效数字，$r^2$ 为 $0.1193$。\n\n**第三部分：连锁不平衡随世代衰减的推导**\n\n我们的目标是找到 $D_t$（第 $t$ 代的LD系数）的表达式，使其作为初始LD（$D_0$）和重组率 $c$ 的函数。在给定的模型假设（随机交配，无选择、突变或迁移）下，等位基因频率 $p_A$ 和 $p_B$ 随时间保持不变。\n\n设 $p_{AB}^{(t)}$ 为第 $t$ 代 $AB$ 单倍型的频率。第 $t$ 代的LD为 $D_t = p_{AB}^{(t)} - p_A p_B$。为了找到 $D_t$ 的一般形式，我们必须首先建立 $p_{AB}^{(t)}$ 的递推关系。\n下一代 $AB$ 单倍型的频率 $p_{AB}^{(t+1)}$ 由第 $t$ 代的频率和重组率 $c$ 决定。我们使用全概率定律。第 $t+1$ 代的 $AB$ 配子可以通过两种互斥的方式形成：\n1.  它是一个非重组配子。这发生的概率为 $1-c$。要产生一个 $AB$ 配子，亲本染色体必须是 $AB$ 单倍型。在第 $t$ 代的基因库中，这种染色体的频率是 $p_{AB}^{(t)}$。\n2.  它是一个重组配子。这发生的概率为 $c$。要产生一个 $AB$ 配子，亲本基因型必须从一条染色体提供一个 $A$ 等位基因，并从其同源染色体提供一个 $B$ 等位基因。在随机交配的群体中，抽到这些等位基因的概率就是它们频率的乘积，$p_A p_B$。\n\n结合这些可能性，我们得到单倍型频率的递推关系：\n$$p_{AB}^{(t+1)} = (1-c)p_{AB}^{(t)} + c p_A p_B$$\n现在，我们用LD系数来表示这个关系。根据定义，$p_{AB}^{(t)} = D_t + p_A p_B$ 且 $p_{AB}^{(t+1)} = D_{t+1} + p_A p_B$。将这些代入递推关系中：\n$$D_{t+1} + p_A p_B = (1-c)(D_t + p_A p_B) + c p_A p_B$$\n展开右侧：\n$$D_{t+1} + p_A p_B = (1-c)D_t + (1-c)p_A p_B + c p_A p_B$$\n$$D_{t+1} + p_A p_B = (1-c)D_t + p_A p_B$$\n从两边减去 $p_A p_B$ 得到 $D_t$ 的递推关系：\n$$D_{t+1} = (1-c)D_t$$\n这是一个简单的几何级数。从 $t=0$ 代的初始不平衡 $D_0$ 开始，我们可以展开这个递推关系：\n$$D_1 = (1-c)D_0$$\n$$D_2 = (1-c)D_1 = (1-c)^2 D_0$$\n通过归纳法，任意第 $t$ 代的解是：\n$$D_t = (1-c)^t D_0$$\n问题要求用初始LD系数 $D_0$ 的数值来表示这个表达式，我们计算出 $D_0$ 为 $0.084$。保留四位有效数字得到 $0.08400$。因此，最终表达式为：\n$$D_t = 0.08400(1-c)^t$$\n这个方程描述了由于重组导致的连锁不平衡随时间指数衰减的过程。", "answer": "$$\\boxed{\\begin{pmatrix} 0.08400  0.1193  0.08400(1-c)^{t} \\end{pmatrix}}$$", "id": "4352653"}, {"introduction": "一次成功的全基因组关联研究通常会鉴定出包含许多因连锁不平衡而相关的信号变异的基因组区域。接下来的关键挑战是从众多相关的“旁观者”变异中甄别出真正的因果变异——这一过程被称为精细定位（fine-mapping）。本练习将介绍贝叶斯精细定位，这是一个用于系统性剖析这些区域的强大统计框架。你将从基本原理出发，亲手实现一个精细定位分析，学习如何计算贝叶斯因子，并将其与不同类型的先验信息相结合，以计算每个变异是因果变异的后验概率 [@problem_id:4352607]。这个综合性的计算练习将使你掌握GWAS分析后最重要的任务之一的实用技能，阐明我们如何从广泛的关联信号转向关于因果机制的可检验假设。", "problem": "一个区域级别的精细定位问题（region-level fine-mapping problem）提出如下。考虑一个包含 $K$ 个双等位基因变异（单核苷酸多态性）的基因组区域。对于每个变异 $i \\in \\{1,\\dots,K\\}$，给定其边际关联Z-score（$z$-score）$z_i$、边际效应估计值 $\\hat{\\beta}_i$ 的估计标准误 $s_i$，以及一个成对连锁不平衡（linkage disequilibrium, LD）相关矩阵 $\\mathbf{R} \\in \\mathbb{R}^{K \\times K}$，其中条目 $R_{ij}$ 表示变异 $i$ 和 $j$ 的基因型剂量向量之间的皮尔逊相关系数（Pearson correlation）。假设区域内存在一个单因果变异生成模型，对于给定的真实效应 $\\beta_i$，$\\hat{\\beta}_i$ 的似然函数为高斯分布；在备择（非零）模型下，$\\beta_i$ 的先验分布为高斯分布，其先验方差参数为 $W > 0$。这些共同构成了一个正态-正态共轭贝叶斯框架。使用贝叶斯定理（Bayes' theorem）推导哪个变异是因果变异的后验分布。基于此后验分布，通过将后验包含概率（posterior inclusion probabilities）按降序排序并累加，直到达到指定的覆盖水平 $c \\in (0,1)$，计算出达到该覆盖水平的最小基数可信集（credible set）。所有覆盖率目标必须以 $[0,1]$ 区间内的小数形式指定。\n\n您的程序必须实现以下内容，从上述基本假设出发，且不依赖此处提供的任何快捷公式：\n- 对每个变异 $i$，使用正态-正态共轭模型计算贝叶斯因子（Bayes factor），以比较备择模型（非零效应）与零模型（零效应）。用于此计算的输入为 $z_i$、$s_i$ 和 $W$。\n- 在单因果变异假设下，将这些贝叶斯因子与因果变异身份的先验相结合，以获得后验包含概率（即每个变异是因果变异的后验模型概率），并进行归一化，使得 $K$ 个变异的后验包含概率之和为 $1$。\n- 通过将变异按后验包含概率降序排序，并取最小数量 $m$ 的变异，使得累积后验包含概率至少达到 $c$，来构建最小 $c$-可信集。\n- 通过为每种因果变异身份的先验计算以下两项，来量化不同先验下可信集大小与覆盖率之间的权衡：\n  1. 在覆盖水平 $c$ 下的最小可信集大小。\n  2. 当限制为后验包含概率最高的 $M$ 个变异时所达到的覆盖率，其中 $M$ 在下面的测试套件中是固定的。\n\n定义三种关于因果变异身份的先验：\n- 均匀先验：每个变异具有相等的先验概率 $p_i = 1/K$。\n- LD中心性降权先验：定义一个阈值 $\\tau \\in (0,1)$。令 $d_i$ 为变异 $i$ 的度，即满足 $\\lvert R_{ij} \\rvert \\ge \\tau$ 的 $j \\neq i$ 的数量。设置一个未归一化的权重 $w_i = 1/(1 + d_i)$，然后归一化为先验概率 $p_i = w_i / \\sum_{j=1}^K w_j$。\n- 功能性先验：给定非负分数 $f_i$，设置 $p_i = f_i / \\sum_{j=1}^K f_j$。\n\n您必须将该方法应用于以下测试套件，对所有测试用例使用相同的效应量先验方差和覆盖率参数：\n- 效应量先验方差：$W = 0.04$。\n- 覆盖率目标：$c = 0.95$。\n- 用于覆盖率评估的固定集合大小：$M = 2$。\n- LD中心性阈值：$\\tau = 0.8$。\n- 所有覆盖率必须以小数形式报告，并精确到 $6$ 位小数。\n\n测试套件：\n- 测试用例1：\n  - $K = 5$。\n  - $z = (\\,4.0,\\,3.9,\\,0.2,\\,2.0,\\,1.2\\,)$。\n  - $s = (\\,0.1,\\,0.1,\\,0.1,\\,0.1,\\,0.1\\,)$。\n  - $\\mathbf{R} =$ \n    $\n    \\begin{bmatrix}\n    1.0  0.9  0.3  0.1  0.0 \\\\\n    0.9  1.0  0.4  0.2  0.1 \\\\\n    0.3  0.4  1.0  0.3  0.2 \\\\\n    0.1  0.2  0.3  1.0  0.4 \\\\\n    0.0  0.1  0.2  0.4  1.0\n    \\end{bmatrix}\n    $。\n  - 功能性分数 $f = (\\,1.0,\\,1.0,\\,3.0,\\,0.5,\\,0.5\\,)$。\n- 测试用例2：\n  - $K = 4$。\n  - $z = (\\,3.8,\\,3.7,\\,3.6,\\,0.5\\,)$。\n  - $s = (\\,0.1,\\,0.1,\\,0.1,\\,0.1\\,)$。\n  - $\\mathbf{R} =$ \n    $\n    \\begin{bmatrix}\n    1.0  0.95  0.95  0.0 \\\\\n    0.95  1.0  0.95  0.0 \\\\\n    0.95  0.95  1.0  0.0 \\\\\n    0.0  0.0  0.0  1.0\n    \\end{bmatrix}\n    $。\n  - 功能性分数 $f = (\\,1.0,\\,1.0,\\,1.0,\\,2.0\\,)$。\n- 测试用例3：\n  - $K = 6$。\n  - $z = (\\,2.1,\\,2.0,\\,2.1,\\,0.1,\\,2.05,\\,0.05\\,)$。\n  - $s = (\\,0.1,\\,0.1,\\,0.1,\\,0.1,\\,0.1,\\,0.1\\,)$。\n  - $\\mathbf{R} =$ \n    $\n    \\begin{bmatrix}\n    1.0  0.2  0.85  0.0  0.85  0.0 \\\\\n    0.2  1.0  0.2  0.85  0.2  0.85 \\\\\n    0.85  0.2  1.0  0.1  0.85  0.1 \\\\\n    0.0  0.85  0.1  1.0  0.1  0.85 \\\\\n    0.85  0.2  0.85  0.1  1.0  0.1 \\\\\n    0.0  0.85  0.1  0.85  0.1  1.0\n    \\end{bmatrix}\n    $。\n  - 功能性分数 $f = (\\,1.5,\\,0.5,\\,1.5,\\,1.0,\\,2.0,\\,0.8\\,)$。\n\n要求的最终输出格式：\n- 对于每个测试用例（按顺序1, 2, 3），以及对于三种先验中的每一种（按顺序：均匀、LD中心性、功能性），生成：\n  - 在覆盖率 $c$ 下的最小可信集大小（整数）。\n  - 前 $M$ 个变异所达到的覆盖率（$[0,1]$ 区间内的小数，精确到 $6$ 位小数）。\n- 您的程序应生成单行输出，其中包含所有测试用例的串联结果，形式为方括号内由逗号分隔的列表。顺序必须是：\n  - 测试用例1：大小（均匀），大小（LD中心性），大小（功能性），覆盖率（均匀），覆盖率（LD中心性），覆盖率（功能性），\n  - 然后是测试用例2，顺序相同，\n  - 然后是测试用例3，顺序相同。\n所需结构的示例（使用占位符值）：“[1,2,3,0.900000,0.850000,0.920000, ...]”。", "solution": "用户提供的问题是统计遗传学中一个定义明確的任务，具体涉及在单因果变异假设下对单个基因组区域进行贝叶斯精细定位（Bayesian fine-mapping）。所有组成部分都具有科学依据和数学上的明确规定，因此可以直接明确无误地得出解决方案。\n\n总体目标是识别一个可能包含因果变异的可信变异集，并评估不同类型的先验信息如何影响这一推断。解决方案按几个逻辑步骤进行：首先，我们使用贝叶斯因子计算每个变异作为因果变异的证据；其次，我们将此证据与不同的先验信念相结合，以计算后验包含概率（PIPs）；第三，我们使用这些PIPs构建可信集并评估其属性。\n\n\\textbf{步骤1：贝叶斯因子计算}\n\n对于每个变异 $i \\in \\{1,\\dots,K\\}$，我们想要计算贝叶斯因子（$BF_i$），它比较的是备择假设（$H_{1,i}$，即变异 $i$ 对性状有非零效应）与零假设（$H_{0,i}$，即它具有零效应）。\n\n问题指定了在给定真实效应 $\\beta_i$ 和估计标准误 $s_i$ 的情况下，观测到的边际效应量估计值 $\\hat{\\beta}_i$ 的高斯似然函数：\n$$ p(\\hat{\\beta}_i | \\beta_i, s_i) = \\mathcal{N}(\\hat{\\beta}_i; \\beta_i, s_i^2) = \\frac{1}{\\sqrt{2\\pi s_i^2}} \\exp\\left(-\\frac{(\\hat{\\beta}_i - \\beta_i)^2}{2s_i^2}\\right) $$\n在零假设 $H_{0,i}$ 下，真实效应为零，即 $\\beta_i = 0$。因此，数据的似然函数为：\n$$ p(\\hat{\\beta}_i | H_{0,i}) = \\mathcal{N}(\\hat{\\beta}_i; 0, s_i^2) = \\frac{1}{\\sqrt{2\\pi s_i^2}} \\exp\\left(-\\frac{\\hat{\\beta}_i^2}{2s_i^2}\\right) $$\n在备择假设 $H_{1,i}$ 下，真实效应从一个方差为 $W$ 的高斯先验分布中抽取：\n$$ p(\\beta_i | H_{1,i}) = \\mathcal{N}(\\beta_i; 0, W) $$\n在 $H_{1,i}$ 下，数据的边际似然是通过对真实效应 $\\beta_i$ 的所有可能值进行积分得到的：\n$$ p(\\hat{\\beta}_i | H_{1,i}) = \\int p(\\hat{\\beta}_i | \\beta_i, s_i) p(\\beta_i | H_{1,i}) d\\beta_i $$\n这是两个高斯分布的卷积，其结果是另一个高斯分布，其方差是各个方差之和：\n$$ p(\\hat{\\beta}_i | H_{1,i}) = \\mathcal{N}(\\hat{\\beta}_i; 0, s_i^2 + W) = \\frac{1}{\\sqrt{2\\pi(s_i^2 + W)}} \\exp\\left(-\\frac{\\hat{\\beta}_i^2}{2(s_i^2 + W)}\\right) $$\n贝叶斯因子 $BF_i$ 是这两个边际似然的比值：\n$$ BF_i = \\frac{p(\\hat{\\beta}_i | H_{1,i})}{p(\\hat{\\beta}_i | H_{0,i})} = \\frac{\\frac{1}{\\sqrt{2\\pi(s_i^2 + W)}} \\exp\\left(-\\frac{\\hat{\\beta}_i^2}{2(s_i^2 + W)}\\right)}{\\frac{1}{\\sqrt{2\\pi s_i^2}} \\exp\\left(-\\frac{\\hat{\\beta}_i^2}{2s_i^2}\\right)} $$\n简化此表达式，我们得到：\n$$ BF_i = \\sqrt{\\frac{s_i^2}{s_i^2 + W}} \\exp\\left[ \\frac{\\hat{\\beta}_i^2}{2} \\left( \\frac{1}{s_i^2} - \\frac{1}{s_i^2 + W} \\right) \\right] = \\sqrt{\\frac{s_i^2}{s_i^2 + W}} \\exp\\left[ \\frac{\\hat{\\beta}_i^2}{2} \\frac{W}{s_i^2(s_i^2 + W)} \\right] $$\n问题提供了边际Z-score $z_i = \\hat{\\beta}_i / s_i$，这意味着 $\\hat{\\beta}_i^2 = z_i^2 s_i^2$。将此代入表达式，得到以给定输入表示的贝叶斯因子的最终公式：\n$$ BF_i = \\sqrt{\\frac{s_i^2}{s_i^2 + W}} \\exp\\left( \\frac{z_i^2 W}{2(s_i^2 + W)} \\right) $$\n\n\\textbf{步骤2：后验包含概率（PIP）计算}\n\n在单因果变异假设下，$K$ 个变异中恰好有一个是因果变异。令 $C_i$ 表示变异 $i$ 是因果变异的事件。给定数据，该事件的后验概率即后验包含概率（$PIP_i$）。使用贝叶斯定理，并用变异 $i$ 的边际证据来近似给定 $C_i$ 的完整数据的似然，我们发现 $PIP_i$ 与先验概率 $p_i = P(C_i)$ 和贝叶斯因子 $BF_i$ 的乘积成正比：\n$$ PIP_i = P(C_i | \\text{data}) \\propto p_i \\times BF_i $$\n为确保所有变异的后验概率之和为 $1$，我们对其进行归一化：\n$$ PIP_i = \\frac{p_i \\times BF_i}{\\sum_{j=1}^K p_j \\times BF_j} $$\n\n\\textbf{步骤3：先验概率模型}\n\n分析在三种不同的 $p_i$ 先验模型下进行：\n\n1.  \\textbf{均匀先验}：这是一种无信息先验，其中每个变异被先验地认为具有相同的因果可能性。\n    $$ p_i = \\frac{1}{K} $$\n2.  \\textbf{LD中心性降权先验}：该先验假设，与许多其他变异处于高度连锁不平衡（LD）状态的变异不太可能是因果变异，因为它们的关联信号可能是由于标记了附近一个真正的因果变异所致。变异 $i$ 的度 $d_i$ 是指绝对相关性 $|R_{ij}|$ 超过阈值 $\\tau$ 的其他变异 $j$ 的数量。先验概率与该度成反比。\n    $$ w_i = \\frac{1}{1 + d_i}, \\quad \\text{其中 } d_i = \\sum_{j \\neq i} \\mathbb{I}(|R_{ij}| \\ge \\tau) $$\n    $$ p_i = \\frac{w_i}{\\sum_{j=1}^K w_j} $$\n3.  \\textbf{功能性先验}：该先验结合了外部生物学信息，例如功能注释分数 $f_i$，这些分数可能表明一个变异是因果变异的可能性较高或较低。先验概率被设定为与这些分数成正比。\n    $$ p_i = \\frac{f_i}{\\sum_{j=1}^K f_j} $$\n\n\\textbf{步骤4：可信集构建与评估}\n\n在为给定先验计算出PIP后，我们执行两种分析：\n\n1.  \\textbf{最小 $c$-可信集大小}：一个 $c$-可信集是一组变异的集合，其PIP之和至少为 $c$。为了找到最小基数集，我们将变异按其PIP降序排序，并逐个添加到集合中，直到它们的累积PIP达到目标覆盖率 $c$。记录该集合的大小。\n\n2.  \\textbf{前 $M$ 个变异的覆盖率}：为了评估固定大小集合的覆盖率，我们再次按PIP对变异进行排序，并对前 $M$ 个变异的PIP求和。这给出了一个预定义大小集合所实现的后验概率覆盖率。\n\n下面的 Python 实现系统地将这些步骤应用于问题陈述中提供的每个测试用例，为三种先验模型中的每一种计算所需的指标。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the region-level fine-mapping problem for the given test suite.\n    \"\"\"\n    # Define global parameters from the problem statement.\n    W = 0.04\n    c = 0.95\n    M = 2\n    tau = 0.8\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"K\": 5,\n            \"z\": np.array([4.0, 3.9, 0.2, 2.0, 1.2]),\n            \"s\": np.full(5, 0.1),\n            \"R\": np.array([\n                [1.0, 0.9, 0.3, 0.1, 0.0],\n                [0.9, 1.0, 0.4, 0.2, 0.1],\n                [0.3, 0.4, 1.0, 0.3, 0.2],\n                [0.1, 0.2, 0.3, 1.0, 0.4],\n                [0.0, 0.1, 0.2, 0.4, 1.0]\n            ]),\n            \"f\": np.array([1.0, 1.0, 3.0, 0.5, 0.5])\n        },\n        {\n            \"K\": 4,\n            \"z\": np.array([3.8, 3.7, 3.6, 0.5]),\n            \"s\": np.full(4, 0.1),\n            \"R\": np.array([\n                [1.0, 0.95, 0.95, 0.0],\n                [0.95, 1.0, 0.95, 0.0],\n                [0.95, 0.95, 1.0, 0.0],\n                [0.0, 0.0, 0.0, 1.0]\n            ]),\n            \"f\": np.array([1.0, 1.0, 1.0, 2.0])\n        },\n        {\n            \"K\": 6,\n            \"z\": np.array([2.1, 2.0, 2.1, 0.1, 2.05, 0.05]),\n            \"s\": np.full(6, 0.1),\n            \"R\": np.array([\n                [1.0, 0.2, 0.85, 0.0, 0.85, 0.0],\n                [0.2, 1.0, 0.2, 0.85, 0.2, 0.85],\n                [0.85, 0.2, 1.0, 0.1, 0.85, 0.1],\n                [0.0, 0.85, 0.1, 1.0, 0.1, 0.85],\n                [0.85, 0.2, 0.85, 0.1, 1.0, 0.1],\n                [0.0, 0.85, 0.1, 0.85, 0.1, 1.0]\n            ]),\n            \"f\": np.array([1.5, 0.5, 1.5, 1.0, 2.0, 0.8])\n        }\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        K, z, s, R, f = case[\"K\"], case[\"z\"], case[\"s\"], case[\"R\"], case[\"f\"]\n\n        # Step 1: Compute Bayes Factors (BFs) for each variant.\n        s2 = s**2\n        bf_sqrt_term = np.sqrt(s2 / (s2 + W))\n        bf_exp_term = np.exp((z**2 * W) / (2 * (s2 + W)))\n        bfs = bf_sqrt_term * bf_exp_term\n\n        # Step 2: Define the three prior probability models.\n        # Uniform prior\n        p_uniform = np.full(K, 1.0 / K)\n\n        # LD-centrality downweighting prior\n        # Sum connections with |R_ij| = tau for each variant i, excluding self (j!=i)\n        degrees = np.sum(np.abs(R) = tau, axis=1) - 1\n        ld_weights = 1.0 / (1.0 + degrees)\n        p_ld_centrality = ld_weights / np.sum(ld_weights)\n\n        # Functional prior\n        p_functional = f / np.sum(f)\n\n        priors_to_process = [p_uniform, p_ld_centrality, p_functional]\n        \n        case_sizes = []\n        case_coverages = []\n\n        for p_i in priors_to_process:\n            # Step 3: Compute Posterior Inclusion Probabilities (PIPs).\n            unnormalized_pips = p_i * bfs\n            # The sum must be  0, as BFs and priors are non-negative, and BFs  0.\n            pips = unnormalized_pips / np.sum(unnormalized_pips)\n\n            # Step 4: Sort variants by PIP to construct credible sets.\n            sorted_indices = np.argsort(pips)[::-1]\n            sorted_pips = pips[sorted_indices]\n\n            # Calculate minimal credible set size for coverage c\n            cumulative_pips = np.cumsum(sorted_pips)\n            # Find the first index where cumulative sum reaches c, giving the number of variants.\n            # a[0] extracts the array of indices, [0] gets the first one. +1 for 1-based size.\n            credible_set_size = np.where(cumulative_pips = c)[0][0] + 1\n            \n            # Calculate achieved coverage for the top M variants\n            coverage_top_M = np.sum(sorted_pips[:M])\n\n            case_sizes.append(credible_set_size)\n            case_coverages.append(f\"{coverage_top_M:.6f}\")\n        \n        # Follow the required output order: sizes first, then coverages.\n        all_results.extend(case_sizes)\n        all_results.extend(case_coverages)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n\n```", "id": "4352607"}]}