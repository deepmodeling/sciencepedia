{"hands_on_practices": [{"introduction": "多组学数据，特别是蛋白质组学，常常面临数据缺失的挑战，而处理这些缺失值的策略对最终分析结果有深远影响。本练习将通过一个具体案例，量化“列表删除法”（listwise deletion）导致的样本量急剧下降，并从第一性原理出发，阐明为何基于潜变量模型的填充策略能够更有效地保留跨组学协方差信息。通过这个练习，您将深刻理解在处理不完美数据时，选择高级统计模型的必要性。[@problem_id:4389260]", "problem": "您正在对一个包含 $n$ 个个体的队列整合两个匹配的组学层：一个转录组模块 $X$ 和一个蛋白质组模块 $Y$。蛋白质组模块的个体边际缺失率为 $0.30$（即，特定个体的蛋白质组测量值缺失的概率为 $0.30$），而转录组模块的个体边际缺失率为 $0.05$。假设数据是完全随机缺失（MCAR），模块间和个体间的缺失是独立的，并且在列表删除法下，纳入一个个体的决策要求该个体的 $X$ 和 $Y$ 模块都被观测到。\n\na) 从初等概率论中的独立事件乘法法则和 MCAR 的定义出发，推导在列表删除法下被保留的个体的期望比例（即，跨两个模块的完整案例的期望比例），并计算其数值。将最终数值答案以小数形式报告，并四舍五入到三位有效数字。\n\nb) 现在考虑估计 $X$ 和 $Y$ 之间的跨组学协方差。使用一个线性共享潜变量模型，其中 $X$ 和 $Y$ 均由一个共同的低维潜在因子 $f$ 和独立的残差生成，从第一性原理出发，论证为何模块化潜在插补策略（例如，多组学因子分析（MOFA）式的估计）比列表删除法能更有效地恢复跨组学协方差。您的论证应明确联系 (i) 列表删除法下有效样本量的减少及其对估计量方差的影响，以及 (ii) 潜因子模型所蕴含的、能够从部分观测数据中一致性地恢复跨组学协方差的协方差分解。", "solution": "该问题要求对整合两个具有不同缺失率的组学数据模块 $X$（转录组）和 $Y$（蛋白质组）进行两部分分析。第一部分是概率计算，第二部分是基于统计建模原理的概念性论证。\n\n首先，我们来推导在列表删除法下被保留个体的期望比例。设 $O_{X,i}$ 为个体 $i$ 的转录组模块 $X$ 的数据被观测到的事件，设 $O_{Y,i}$ 为个体 $i$ 的蛋白质组模块 $Y$ 的数据被观测到的事件。问题给出了每个模块的边际缺失概率。\n转录组模块缺失的概率为 $P(M_{X,i}) = 0.05$。\n蛋白质组模块缺失的概率为 $P(M_{Y,i}) = 0.30$。\n\n观测到数据的事件是缺失事件的补集。因此，它们的概率是：\n$$P(O_{X,i}) = 1 - P(M_{X,i}) = 1 - 0.05 = 0.95$$\n$$P(O_{Y,i}) = 1 - P(M_{Y,i}) = 1 - 0.30 = 0.70$$\n\n问题指出，只有当数据模块 $X$ 和 $Y$ 都被观测到时，一个个体才会在列表删除法下被保留。这对应于联合事件 $O_{X,i} \\cap O_{Y,i}$。问题还明确指出缺失在模块间是独立的。这意味着事件 $O_{X,i}$ 和 $O_{Y,i}$ 是统计独立的。\n\n根据独立事件的乘法法则，联合事件的概率是各个事件概率的乘积：\n$$P(O_{X,i} \\cap O_{Y,i}) = P(O_{X,i}) \\times P(O_{Y,i})$$\n代入计算出的概率：\n$$P(\\text{individual } i \\text{ is retained}) = 0.95 \\times 0.70 = 0.665$$\n\n这个概率表示从队列中随机选择的任何单个个体是“完整案例”并被保留的概率。问题假设缺失在个体间是独立的。设 $R_i$ 是一个伯努利随机变量，如果个体 $i$ 被保留，则 $R_i=1$，否则 $R_i=0$。成功的概率为 $p = P(R_i=1) = 0.665$。在大小为 $n$ 的队列中，被保留的个体总数为 $N_{retained} = \\sum_{i=1}^n R_i$。被保留个体的期望数量是 $\\mathbb{E}[N_{retained}] = \\sum_{i=1}^n \\mathbb{E}[R_i] = \\sum_{i=1}^n p = np$。因此，被保留个体的期望比例是 $\\frac{\\mathbb{E}[N_{retained}]}{n} = \\frac{np}{n} = p$。\n\n因此，在列表删除法下被保留的个体的期望比例是 $0.665$。该值已经用三位有效数字表示。\n\n接下来，我们从第一性原理出发，论证为何模块化潜在插补策略比列表删除法更有效地估计跨组学协方差 $\\text{Cov}(X, Y)$。该论证建立在两大支柱之上：样本量减少对估计量方差的影响，以及潜变量模型的结构性优势。\n\n线性共享潜变量模型假定模块 $X$ 和 $Y$ 中的高维数据是由一个共同的低维潜在因子 $f$ 生成的。对于单个个体，该模型可表示为：\n$$x = W_X f + \\epsilon_X$$\n$$y = W_Y f + \\epsilon_Y$$\n其中 $x$ 和 $y$ 是个体的数据向量，$f$ 是潜在因子向量，$W_X$ 和 $W_Y$ 是将潜在空间映射到数据空间的载荷矩阵，$\\epsilon_X$ 和 $\\epsilon_Y$ 是独立的残差噪声项。一个关键假设是，潜在因子 $f$ 捕获了 $X$ 和 $Y$ 之间的所有共享变异，这意味着 $\\epsilon_X$ 和 $\\epsilon_Y$ 彼此独立，也与 $f$ 独立。\n\n(i) 样本量减少对估计量方差的影响：\n如上所计算，列表删除法仅保留了总个体数的期望比例 $0.665$。这意味着对于一个大小为 $n$ 的队列，任何下游分析（包括估计跨组学协方差矩阵）的有效样本量都减少到约 $n_{eff} \\approx 0.665n$。大多数统计估计量（包括样本协方差）的方差与样本量成反比。对于基于大小为 $N$ 的样本的参数 $\\theta$ 的估计量 $\\hat{\\theta}$，其方差通常具有 $\\text{Var}(\\hat{\\theta}) \\propto \\frac{1}{N}$ 的形式。因此，基于 $n_{eff}$ 个完整案例的 $\\text{Cov}(X, Y)$ 估计值将比能够利用所有 $n$ 个个体信息的估计值具有显著更高的方差。这种增加的方差意味着估计值更不可靠，更容易受到抽样噪声的影响，并产生更宽的置信区间。检测真实跨组学关联的统计功效也显著降低。\n\n(ii) 协方差分解和从部分观测数据中恢复：\n潜变量模型提供了一种克服数据丢失问题的机制。在该模型下，数据模块 $X$ 和 $Y$ 之间的交叉协方差可以被分解。假设数据已经中心化，协方差为：\n$$\\text{Cov}(X, Y) = \\mathbb{E}[xy^T] = \\mathbb{E}[(W_X f + \\epsilon_X)(W_Y f + \\epsilon_Y)^T]$$\n展开并利用 $f$、$\\epsilon_X$ 和 $\\epsilon_Y$ 的独立性，涉及残差的交叉项的期望为零：\n$$\\text{Cov}(X, Y) = \\mathbb{E}[W_X f f^T W_Y^T] = W_X \\mathbb{E}[f f^T] W_Y^T$$\n如果我们假设潜在因子是标准化的，即 $\\mathbb{E}[f f^T] = I$（单位矩阵），则交叉协方差简化为：\n$$\\text{Cov}(X, Y) = W_X W_Y^T$$\n这个分解至关重要。它表明整个跨组学协方差结构是由载荷矩阵 $W_X$ 和 $W_Y$ 决定的。模块化潜在插补策略，例如多组学因子分析（MOFA）中使用的策略，会估计这些载荷矩阵。估计过程（例如，最大化数据似然）使用所有可用的数据，而不仅仅是完整案例。\n- 对于只有模块 $X$ 被观测到的个体，其数据有助于估计 $W_X$ 和该个体的潜在因子 $f$。\n- 对于只有模块 $Y$ 被观测到的个体，其数据有助于估计 $W_Y$ 和该个体的潜在因子 $f$。\n- 对于两个模块都被观测到的个体，其数据为 $W_X$ 和 $W_Y$ 的估计以及它们共享的潜在因子 $f$ 提供了信息。\n\n通过汇集所有 $n$ 个个体的信息，该模型在整个数据集中“借用力量”。载荷矩阵 $W_X$ 是使用所有存在 $X$ 模块的个体数据（期望有 $0.95n$ 个个体）来估计的，而 $W_Y$ 是使用所有存在 $Y$ 模块的个体数据（期望有 $0.70n$ 个个体）来估计的。这些样本量明显大于列表删除法可用的 $0.665n$。一旦获得了载荷矩阵的稳健估计 $\\hat{W}_X$ 和 $\\hat{W}_Y$，就可以一致地重构跨组学协方差为 $\\widehat{\\text{Cov}}(X, Y) = \\hat{W}_X \\hat{W}_Y^T$。这个重构的协方差是基于从一个大得多的有效样本量中估计出的参数，因此与从严重缩减的完整案例数据集中获得的估计相比，其方差更低、更稳定、也更准确。", "answer": "$$\n\\boxed{0.665}\n$$", "id": "4389260"}, {"introduction": "在多组学整合中，一个核心任务是识别不同数据层之间共享的变异模式。偏最小二乘法（Partial Least Squares, PLS）是实现这一目标的经典监督降维方法。本练习将引导您通过一个具体的数值示例，亲手计算PLS的前两个成分，从而直观理解PLS如何通过最大化组学模块间潜变量的协方差来提取共有的生物信号。[@problem_id:4389264]", "problem": "考虑一项匹配的多组学研究，其中对 $n=3$ 个生物样本进行了分析，涵盖了两个转录本特征（信使核糖核酸表达）和两个代谢物特征（质谱强度）。令 $X \\in \\mathbb{R}^{3 \\times 2}$ 表示转录本数据块，$Y \\in \\mathbb{R}^{3 \\times 2}$ 表示代谢物数据块。两个数据块都按样本进行了均值中心化（即每列的样本均值为零）。矩阵为\n$$\nX = \\begin{pmatrix}\n1  -1 \\\\\n0  1 \\\\\n-1  0\n\\end{pmatrix},\n\\qquad\nY = \\begin{pmatrix}\n2  0 \\\\\n-1  1 \\\\\n-1  -1\n\\end{pmatrix}.\n$$\n在双数据块偏最小二乘法 (PLS) 中，第一对潜变量定义为 $t_{1} = X w_{1}$ 和 $u_{1} = Y c_{1}$，其中 $w_{1} \\in \\mathbb{R}^{2}$ 和 $c_{1} \\in \\mathbb{R}^{2}$ 是权重向量。第一个成分的目标是在权重向量的欧几里得范数为单位1的约束条件下，最大化 $t_{1}$ 和 $u_{1}$ 之间的样本协方差：\n$$\n\\text{maximize } \\operatorname{cov}(t_{1}, u_{1}) = \\frac{1}{n-1} t_{1}^{\\top} u_{1} = \\frac{1}{n-1} w_{1}^{\\top} X^{\\top} Y c_{1}\n\\quad \\text{subject to} \\quad \\|w_{1}\\|_{2} = 1, \\ \\|c_{1}\\|_{2} = 1.\n$$\n定义交叉协方差矩阵 $S = \\frac{1}{n-1} X^{\\top} Y \\in \\mathbb{R}^{2 \\times 2}$。第二对 PLS 潜变量 $t_{2} = X w_{2}$ 和 $u_{2} = Y c_{2}$ 的定义与此类似，但除了同样的单位范数约束外，还必须满足正交性约束 $w_{1}^{\\top} w_{2} = 0$ 和 $c_{1}^{\\top} c_{2} = 0$，并且它们最大化 $\\operatorname{cov}(t_{2}, u_{2})$。\n\n仅使用样本协方差、欧几里得范数、$\\mathbb{R}^{2}$ 中的正交性的定义，以及一个经过充分检验的性质——即对于任意固定的实矩阵 $S$，双线性形式 $w^{\\top} S c$ 在单位范数约束下的极值由 $S$ 的奇异值和奇异向量决定——来完成以下任务：\n\n1. 明确计算 $S = \\frac{1}{n-1} X^{\\top} Y$。\n2. 在约束条件 $\\|w_{1}\\|_{2} = 1$ 和 $\\|c_{1}\\|_{2} = 1$ 下，推导使 $\\operatorname{cov}(t_{1}, u_{1})$ 最大化的 $w_{1}$ 和 $c_{1}$，并计算最大化的协方差值 $\\operatorname{cov}(t_{1}, u_{1})$。\n3. 在约束条件 $w_{1}^{\\top} w_{2} = 0$ 和 $c_{1}^{\\top} c_{2} = 0$ 以及 $\\|w_{2}\\|_{2} = 1$ 和 $\\|c_{2}\\|_{2} = 1$ 下，推导使 $\\operatorname{cov}(t_{2}, u_{2})$ 最大化的 $w_{2}$ 和 $c_{2}$，并计算最大化的协方差值 $\\operatorname{cov}(t_{2}, u_{2})$。\n4. 通过第一性原理（例如，拉格朗日乘子法或双线性形式的奇异值分解性质）验证每对向量确实在给定约束下达到了所述的最大值。\n\n将两个最大化协方差之和 $\\operatorname{cov}(t_{1}, u_{1}) + \\operatorname{cov}(t_{2}, u_{2})$ 作为你的最终答案，以一个单一的闭式解析表达式报告。由于标准化，将所有量视为无量纲，并以精确形式（不进行四舍五入）表示最终答案。", "solution": "我们从定义开始。潜变量 $t = X w$ 和 $u = Y c$ 之间的样本协方差为\n$$\n\\operatorname{cov}(t,u) = \\frac{1}{n-1} t^{\\top} u = \\frac{1}{n-1} w^{\\top} X^{\\top} Y c.\n$$\n对于 $n=3$，$1/(n-1) = 1/2$。定义交叉协方差矩阵\n$$\nS = \\frac{1}{n-1} X^{\\top} Y = \\frac{1}{2} X^{\\top} Y.\n$$\n第1步：明确计算 $S$。首先计算 $X^{\\top} Y$：\n$$\nX^{\\top} Y =\n\\begin{pmatrix}\n1  0  -1 \\\\\n-1  1  0\n\\end{pmatrix}\n\\begin{pmatrix}\n2  0 \\\\\n-1  1 \\\\\n-1  -1\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n3  1 \\\\\n-3  1\n\\end{pmatrix}.\n$$\n因此，\n$$\nS = \\frac{1}{2} \\begin{pmatrix} 3  1 \\\\ -3  1 \\end{pmatrix}\n= \\begin{pmatrix} 1.5  0.5 \\\\ -1.5  0.5 \\end{pmatrix}.\n$$\n\n第2步：在约束条件 $\\|w_{1}\\|_{2} = 1$ 和 $\\|c_{1}\\|_{2} = 1$ 下，最大化 $\\operatorname{cov}(t_{1}, u_{1}) = w_{1}^{\\top} S c_{1}$。矩阵分析中一个经过充分检验的事实是，对于任意实矩阵 $S$，在单位向量 $w$ 和 $c$ 上 $w^{\\top} S c$ 的最大值是 $S$ 的最大奇异值 $\\sigma_{1}$，当 $c$ 是与 $\\sigma_{1}$ 相关联的右奇异向量且 $w$ 是相应的左奇异向量时取得该最大值。为了计算奇异值和奇异向量，考察 $S^{\\top} S$：\n$$\nS^{\\top} S = \n\\begin{pmatrix}\n1.5  -1.5 \\\\\n0.5  0.5\n\\end{pmatrix}\n\\begin{pmatrix}\n1.5  0.5 \\\\\n-1.5  0.5\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n4.5  0 \\\\\n0  0.5\n\\end{pmatrix}.\n$$\n因此 $S^{\\top} S$ 的特征值为 $\\lambda_{1} = 4.5$ 和 $\\lambda_{2} = 0.5$，所以奇异值为\n$$\n\\sigma_{1} = \\sqrt{4.5} = \\frac{3}{\\sqrt{2}}, \\qquad \\sigma_{2} = \\sqrt{0.5} = \\frac{1}{\\sqrt{2}}.\n$$\n由于 $S^{\\top} S$ 是对角矩阵，其归一化特征向量（右奇异向量）为 $c_{1} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ 和 $c_{2} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$。相应的左奇异向量由 $w_{i} = \\frac{S c_{i}}{\\|S c_{i}\\|_{2}}$ 给出。计算 $w_{1}$：\n$$\nS c_{1} = \\begin{pmatrix} 1.5 \\\\ -1.5 \\end{pmatrix}, \\quad \\|S c_{1}\\|_{2} = \\sqrt{(1.5)^{2} + (-1.5)^{2}} = \\sqrt{4.5} = \\frac{3}{\\sqrt{2}}.\n$$\n因此，\n$$\nw_{1} = \\frac{1}{\\sqrt{4.5}} \\begin{pmatrix} 1.5 \\\\ -1.5 \\end{pmatrix}\n= \\begin{pmatrix} \\frac{1.5}{\\sqrt{4.5}} \\\\ \\frac{-1.5}{\\sqrt{4.5}} \\end{pmatrix}\n= \\begin{pmatrix} \\frac{\\sqrt{2}}{2} \\\\ -\\frac{\\sqrt{2}}{2} \\end{pmatrix}\n= \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ -\\frac{1}{\\sqrt{2}} \\end{pmatrix}.\n$$\n根据构造，$\\|w_{1}\\|_{2} = 1$ 且 $\\|c_{1}\\|_{2} = 1$，并且\n$$\n\\operatorname{cov}(t_{1}, u_{1}) = w_{1}^{\\top} S c_{1} = \\|S c_{1}\\|_{2} = \\sigma_{1} = \\frac{3}{\\sqrt{2}}.\n$$\n\n第3步：施加约束 $w_{1}^{\\top} w_{2} = 0$ 和 $c_{1}^{\\top} c_{2} = 0$ 以及单位范数，并最大化 $w_{2}^{\\top} S c_{2}$。根据正交性约束 $c_{1}^{\\top} c_{2} = 0$ 和右奇异向量的结构，取 $c_{2} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$。那么\n$$\nS c_{2} = \\begin{pmatrix} 0.5 \\\\ 0.5 \\end{pmatrix}, \\quad \\|S c_{2}\\|_{2} = \\sqrt{(0.5)^{2} + (0.5)^{2}} = \\sqrt{0.5} = \\frac{1}{\\sqrt{2}},\n$$\n所以单位范数的左奇异向量为\n$$\nw_{2} = \\frac{S c_{2}}{\\|S c_{2}\\|_{2}} = \\begin{pmatrix} \\frac{0.5}{\\sqrt{0.5}} \\\\ \\frac{0.5}{\\sqrt{0.5}} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} \\end{pmatrix}.\n$$\n注意 $w_{1}^{\\top} w_{2} = \\frac{1}{\\sqrt{2}} \\cdot \\frac{1}{\\sqrt{2}} + \\left(-\\frac{1}{\\sqrt{2}}\\right) \\cdot \\frac{1}{\\sqrt{2}} = \\frac{1}{2} - \\frac{1}{2} = 0$，因此正交性成立。第二个成分的最大化协方差为\n$$\n\\operatorname{cov}(t_{2}, u_{2}) = w_{2}^{\\top} S c_{2} = \\|S c_{2}\\|_{2} = \\sigma_{2} = \\frac{1}{\\sqrt{2}}.\n$$\n\n第4步：最优性验证。对于任意单位向量 $w$ 和 $c$，双线性形式满足\n$$\n|w^{\\top} S c| \\leq \\sigma_{1},\n$$\n其中 $\\sigma_{1}$ 是 $S$ 的最大奇异值。这可以从奇异值分解的性质得出：将 $S$ 写为 $S = U \\Sigma V^{\\top}$，其中 $U, V$ 是正交矩阵，$\\Sigma = \\operatorname{diag}(\\sigma_{1}, \\sigma_{2})$，令 $\\tilde{w} = U^{\\top} w$ 和 $\\tilde{c} = V^{\\top} c$，两者均为单位向量，因此\n$$\nw^{\\top} S c = \\tilde{w}^{\\top} \\Sigma \\tilde{c} = \\sigma_{1} \\tilde{w}_{1} \\tilde{c}_{1} + \\sigma_{2} \\tilde{w}_{2} \\tilde{c}_{2}.\n$$\n根据柯西-施瓦茨不等式以及 $|\\tilde{w}_{i}| \\leq 1$, $|\\tilde{c}_{i}| \\leq 1$，最大值为 $\\sigma_{1}$，在 $\\tilde{w} = e_{1}$ 和 $\\tilde{c} = e_{1}$ 时取得，这等价于 $w$ 和 $c$ 分别是与 $\\sigma_{1}$ 相关联的左、右奇异向量，正如我们上面构造的那样。在附加的正交性约束 $c_{1}^{\\top} c_{2} = 0$ 和 $w_{1}^{\\top} w_{2} = 0$ 下，在受限于第一奇异方向的正交补空间内的单位向量上进行最大化，将得到下一个奇异值 $\\sigma_{2}$，该值由相应的奇异向量达到，而我们已经明确计算出了这些向量。因此，计算出的向量对 $(w_{1}, c_{1})$ 和 $(w_{2}, c_{2})$ 在约束问题中达到了全局最大值。\n\n最后，所要求的两个最大化协方差之和为\n$$\n\\operatorname{cov}(t_{1}, u_{1}) + \\operatorname{cov}(t_{2}, u_{2}) = \\frac{3}{\\sqrt{2}} + \\frac{1}{\\sqrt{2}} = \\frac{4}{\\sqrt{2}} = 2 \\sqrt{2}.\n$$", "answer": "$$\\boxed{2\\sqrt{2}}$$", "id": "4389264"}, {"introduction": "除了基于矩阵分解的方法，网络融合是另一种强大的多组学整合策略，尤其适用于识别患者亚型。相似性网络融合（Similarity Network Fusion, SNF）是其中的代表性算法。本练习将演示SNF的核心扩散过程，展示它如何通过迭代更新来增强不同组学数据中一致的样本相似性结构，并利用谱图理论中的“谱间隙”（spectral gap）概念来量化融合后网络群落结构的改善。[@problem_id:4389239]", "problem": "在系统生物医学中，一种常见的多组学数据整合策略是为每个组学构建样本-样本亲和网络，并在融合网络之前，在每个网络上迭代地扩散信息。相似性网络融合 (SNF) 对每个组学 $m$ 执行形式为 $W^{(m)} \\leftarrow S^{(m)} W^{(m)} S^{(m)\\top}$ 的扩散更新，其中 $S^{(m)}$ 是一个局部归一化、对称、行随机的样本相似性矩阵，而 $W^{(m)}$ 是该组学当前的亲和矩阵。考虑三个样本，它们在两个组学中的每个组学归一化相似性由以下对称、行随机的矩阵给出：\n$$\nS^{(1)} \\;=\\; \\begin{pmatrix}\n0.5  0.4  0.1 \\\\\n0.4  0.5  0.1 \\\\\n0.1  0.1  0.8\n\\end{pmatrix},\n\\qquad\nS^{(2)} \\;=\\; \\begin{pmatrix}\n0.55  0.35  0.10 \\\\\n0.35  0.55  0.10 \\\\\n0.10  0.10  0.80\n\\end{pmatrix}.\n$$\n假设 SNF 迭代对每个组学 $m \\in \\{1,2\\}$ 初始化 $W^{(m)} \\;=\\; S^{(m)}$，这与初始亲和度等于归一化相似性的标准做法一致。对每个组学执行一次扩散更新以获得 $W_{\\text{new}}^{(m)} \\;=\\; S^{(m)} W^{(m)} S^{(m)\\top}$，然后将融合图定义为简单平均值\n$$\nW_{\\text{fused}} \\;=\\; \\frac{1}{2}\\left(W_{\\text{new}}^{(1)} + W_{\\text{new}}^{(2)}\\right).\n$$\n使用谱图理论处理对称、行随机的扩散算子，令 $\\lambda_2\\!\\left(W_{\\text{fused}}\\right)$ 表示 $W_{\\text{fused}}$ 的第二大特征值，并将谱隙定义为 $\\gamma \\;=\\; 1 - \\lambda_2\\!\\left(W_{\\text{fused}}\\right)$。精确计算 $\\gamma$。在您的推导过程中，根据适当的基本原理（马尔可夫算子上的扩散以及对称行随机矩阵的特征结构）来论证每一步，并简要讨论扩散和融合如何相对于初始的各组学图改变社群结构。以精确算术形式报告 $\\gamma$ 的最终数值答案；无需四舍五入。", "solution": "该问题被验证为具有科学依据、良定且客观。它是线性代数和谱图理论在系统生物医学中成熟的相似性网络融合（SNF）算法上的直接应用。所有数据和定义都是自洽且一致的。\n\n该问题要求计算融合亲和矩阵 $W_{\\text{fused}}$ 的谱隙 $\\gamma$。该矩阵由两个各组学的相似性矩阵 $S^{(1)}$ 和 $S^{(2)}$ 构建。谱隙定义为 $\\gamma = 1 - \\lambda_2(W_{\\text{fused}})$，其中 $\\lambda_2$ 是第二大特征值。\n\n首先，我们分析给定相似性矩阵的性质。这些矩阵如下：\n$$\nS^{(1)} = \\begin{pmatrix} 0.5  0.4  0.1 \\\\ 0.4  0.5  0.1 \\\\ 0.1  0.1  0.8 \\end{pmatrix} = \\begin{pmatrix} 1/2  2/5  1/10 \\\\ 2/5  1/2  1/10 \\\\ 1/10  1/10  4/5 \\end{pmatrix}\n$$\n和\n$$\nS^{(2)} = \\begin{pmatrix} 0.55  0.35  0.10 \\\\ 0.35  0.55  0.10 \\\\ 0.10  0.10  0.80 \\end{pmatrix} = \\begin{pmatrix} 11/20  7/20  1/10 \\\\ 7/20  11/20  1/10 \\\\ 1/10  1/10  4/5 \\end{pmatrix}.\n$$\n两个矩阵都是对称且行随机的（每行之和为 $1$）。在谱图理论中，这样的矩阵代表图上可逆马尔可夫链的转移矩阵。任何行随机矩阵的一个基本性质是它有一个特征值 $\\lambda=1$，对应的特征向量为 $\\mathbf{v}_1 = [1, 1, ..., 1]^\\top$。对于对称矩阵，所有特征值都是实数，且位于区间 $[-1, 1]$ 内。\n\n问题指定了形式为 $W_{\\text{new}}^{(m)} = S^{(m)} W^{(m)} S^{(m)\\top}$ 的 SNF 扩散更新。迭代以 $W^{(m)} = S^{(m)}$ 初始化。由于 $S^{(m)}$ 是对称的，所以 $S^{(m)\\top} = S^{(m)}$。因此，第一次更新得出：\n$$\nW_{\\text{new}}^{(m)} = S^{(m)} S^{(m)} (S^{(m)})^\\top = S^{(m)} S^{(m)} S^{(m)} = \\left(S^{(m)}\\right)^3.\n$$\n此操作对应于信息在图上通过三步随机游走进行扩散，这倾向于加强高相似度的连接并减弱低相似度的连接。\n\n为了找到 $W_{\\text{new}}^{(m)}$ 的特征值，我们首先找到 $S^{(m)}$ 的特征值。如果矩阵 $A$ 有一个特征值 $\\lambda$ 和对应的特征向量 $\\mathbf{v}$，那么 $A^k$ 就有一个特征值 $\\lambda^k$ 和相同的特征向量 $\\mathbf{v}$。\n\n$S^{(1)}$ 和 $S^{(2)}$ 都具有共同的分块结构：\n$$\nS = \\begin{pmatrix} a  b  c \\\\ b  a  c \\\\ c  c  d \\end{pmatrix} \\quad \\text{其中} \\quad a+b+c=1 \\quad \\text{和} \\quad 2c+d=1.\n$$\n由于前两个样本之间的对称性，我们可以推导出特征向量的形式。\n1. 对应于 $\\lambda_1=1$ 的特征向量是 $\\mathbf{v}_1 = [1, 1, 1]^\\top$。\n2. 一个捕捉前两个样本之间差异的特征向量是 $\\mathbf{v}_2 = [1, -1, 0]^\\top$。将 $S$ 应用于 $\\mathbf{v}_2$：\n$$\nS \\mathbf{v}_2 = \\begin{pmatrix} a  b  c \\\\ b  a  c \\\\ c  c  d \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} a-b \\\\ b-a \\\\ 0 \\end{pmatrix} = (a-b) \\begin{pmatrix} 1 \\\\ -1 \\\\ 0 \\end{pmatrix}.\n$$\n所以，一个特征值是 $\\lambda = a-b$。\n3. 第三个特征向量 $\\mathbf{v}_3$ 必须与 $\\mathbf{v}_1$ 和 $\\mathbf{v}_2$ 正交。它与 $[1, 1, -2]^\\top$ 成比例。将 $S$ 应用于 $\\mathbf{v}_3$：\n$$\nS \\mathbf{v}_3 = \\begin{pmatrix} a  b  c \\\\ b  a  c \\\\ c  c  d_m \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ -2 \\end{pmatrix} = \\begin{pmatrix} a+b-2c \\\\ b+a-2c \\\\ 2c-2d \\end{pmatrix}.\n$$\n使用 $a+b=1-c$ 和 $d=1-2c$，这可以简化为：\n$$\nS \\mathbf{v}_3 = \\begin{pmatrix} 1-c-2c \\\\ 1-c-2c \\\\ 2c-2(1-2c) \\end{pmatrix} = \\begin{pmatrix} 1-3c \\\\ 1-3c \\\\ 6c-2 \\end{pmatrix} = (1-3c) \\begin{pmatrix} 1 \\\\ 1 \\\\ -2 \\end{pmatrix}.\n$$\n所以，另一个特征值是 $\\lambda = 1-3c$。\n\n现在我们为每个矩阵计算这些特征值：\n对于 $S^{(1)}$: $a=1/2$, $b=2/5$, $c=1/10$。\n- $\\lambda_1^{(1)} = 1$。\n- 来自 $\\mathbf{v}_2$ 的特征值: $a-b = 1/2 - 2/5 = 5/10 - 4/10 = 1/10$。\n- 来自 $\\mathbf{v}_3$ 的特征值: $1-3c = 1 - 3(1/10) = 7/10$。\n$S^{(1)}$ 的特征值为 $\\{1, 7/10, 1/10\\}$，按降序排列为 $1, 0.7, 0.1$。\n\n对于 $S^{(2)}$: $a=11/20$, $b=7/20$, $c=1/10$。\n- $\\lambda_1^{(2)} = 1$。\n- 来自 $\\mathbf{v}_2$ 的特征值: $a-b = 11/20 - 7/20 = 4/20 = 1/5$。\n- 来自 $\\mathbf{v}_3$ 的特征值: $1-3c = 1 - 3(1/10) = 7/10$。\n$S^{(2)}$ 的特征值为 $\\{1, 7/10, 1/5\\}$，按降序排列为 $1, 0.7, 0.2$。\n\n$W_{\\text{new}}^{(m)} = (S^{(m)})^3$ 的特征值是 $S^{(m)}$ 特征值的立方：\n- $W_{\\text{new}}^{(1)}$ 的特征值：$\\{1^3, (7/10)^3, (1/10)^3\\} = \\{1, 343/1000, 1/1000\\}$。\n- $W_{\\text{new}}^{(2)}$ 的特征值：$\\{1^3, (7/10)^3, (1/5)^3\\} = \\{1, 343/1000, 8/1000\\}$。\n\n融合矩阵为 $W_{\\text{fused}} = \\frac{1}{2}(W_{\\text{new}}^{(1)} + W_{\\text{new}}^{(2)})$。由于 $S^{(1)}$ 和 $S^{(2)}$ 共享同一组特征向量（$\\mathbf{v}_1, \\mathbf{v}_2, \\mathbf{v}_3$），因此 $W_{\\text{new}}^{(1)}$ 和 $W_{\\text{new}}^{(2)}$ 也共享它们。因此，$W_{\\text{fused}}$ 也共享这些特征向量。共享特征向量的矩阵之和的特征值是相应特征值之和。\n令 $\\lambda_i(M)$ 为矩阵 $M$ 的第 $i$ 个特征值。\n$$\n\\lambda_i(W_{\\text{fused}}) = \\frac{1}{2}\\left(\\lambda_i(W_{\\text{new}}^{(1)}) + \\lambda_i(W_{\\text{new}}^{(2)})\\right).\n$$\n特征值根据它们对应的特征向量进行匹配：\n- 对应于 $\\mathbf{v}_1 = [1,1,1]^\\top$：$\\lambda_1(W_{\\text{fused}}) = \\frac{1}{2}(1 + 1) = 1$。\n- 对应于 $\\mathbf{v}_3 = [1,1,-2]^\\top$：$S^{(1)}$ 和 $S^{(2)}$ 的特征值均为 $7/10$。因此，对于立方矩阵，该特征值为 $(7/10)^3$。其平均值为 $\\frac{1}{2}((7/10)^3 + (7/10)^3) = (7/10)^3 = 343/1000$。\n- 对应于 $\\mathbf{v}_2 = [1,-1,0]^\\top$：$S^{(1)}$ 和 $S^{(2)}$ 的特征值分别为 $1/10$ 和 $1/5$。因此对于 $W_{\\text{fused}}$，该特征值为 $\\frac{1}{2}((1/10)^3 + (1/5)^3) = \\frac{1}{2}(1/1000 + 8/1000) = \\frac{1}{2}(9/1000) = 9/2000$。\n\n$W_{\\text{fused}}$ 的特征值为 $\\{1, 343/1000, 9/2000\\}$。以小数形式表示，它们是 $\\{1, 0.343, 0.0045\\}$。\n最大特征值为 $\\lambda_1(W_{\\text{fused}}) = 1$。\n第二大特征值为 $\\lambda_2(W_{\\text{fused}}) = 343/1000$。\n\n谱隙 $\\gamma$ 的计算如下：\n$$\n\\gamma = 1 - \\lambda_2(W_{\\text{fused}}) = 1 - \\frac{343}{1000} = \\frac{1000 - 343}{1000} = \\frac{657}{1000}.\n$$\n\n关于社群结构的简要讨论：\n图的社群结构与其谱隙有关。较大的谱隙表示图可以更清晰地划分为不同的社群。与 $\\lambda_2$ 对应的特征向量（Fiedler 向量）可用于对图进行划分。对于本问题中的所有矩阵（$S^{(1)}, S^{(2)}, W_{\\text{fused}}$），与第二大特征值对应的特征向量是 $\\mathbf{v}_3 = [1,1,-2]^\\top$。这个向量表明社群结构将图划分为 $\\{sample_1, sample_2\\}$ 和 $\\{sample_3\\}$。\n\n各组学网络的初始谱隙为：\n- $\\gamma^{(1)} = 1 - \\lambda_2(S^{(1)}) = 1 - 7/10 = 3/10 = 0.3$.\n- $\\gamma^{(2)} = 1 - \\lambda_2(S^{(2)}) = 1 - 7/10 = 3/10 = 0.3$.\n\n融合网络的最终谱隙为 $\\gamma = 657/1000 = 0.657$。\n扩散步骤（$S \\to S^3$）和融合步骤（平均）将谱隙从 $0.3$ 显著增加到 $0.657$。这表明 SNF 过程成功地增强了两个组学中存在的共同社群结构。扩散步骤通过加强强链接和减弱弱链接来锐化网络内的社群边界。融合步骤则找到一个共识网络，其中这种共同结构得到加强，从而导致社群之间更清晰的分离（由更大的谱隙量化）。这体现了 SNF 的核心原则：整合多个数据层比任何单个数据层更能揭示出更稳健的潜在生物结构。", "answer": "$$\\boxed{\\frac{657}{1000}}$$", "id": "4389239"}]}