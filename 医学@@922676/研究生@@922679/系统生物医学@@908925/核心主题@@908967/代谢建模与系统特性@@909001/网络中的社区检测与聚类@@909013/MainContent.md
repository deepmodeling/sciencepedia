## 引言
在系统生物医学领域，网络不仅是描绘生命复杂性的蓝图，更是我们理解其内在组织和功能的关键。从基因的协同调控到蛋白质的相互作用，再到代谢物在细胞内的流动，这些复杂的相互关系构成了动态的生物网络。然而，仅仅构建出这张网络只是第一步；真正的挑战在于如何从海量、嘈杂的连接数据中识别出有意义的功能单元——即“社群”或“模块”。这些社群是网络中[紧密连接](@entry_id:170497)的子系统，它们的发现对于揭示细胞过程、识别疾病靶点和理解系统行为至关重要。

本文旨在系统性地解决这一挑战，为读者提供一套从理论到实践的完整知识体系。我们将深入探讨社群发现与聚类的核心原理、主流算法及其在生物医学领域的广泛应用。通过本文的学习，你将能够驾驭这些强大的分析工具，从看似混沌的网络数据中提取出清晰的生物学洞见。

为了实现这一目标，本文将分为三个核心章节。第一章“原理与机制”将奠定理论基础，详细阐述如何定义和量化社[群结构](@entry_id:146855)，并介绍关键的社群发现算法。第二章“应用与交叉学科联系”将展示这些方法在解决真实世界问题时的威力，特别是在分析基因共表达、蛋白质相互作用、单细胞数据以及动态和[多层网络](@entry_id:270365)中的应用。最后，在“动手实践”部分，你将通过具体的计算练习，将理论知识转化为解决问题的实践技能。

## 原理与机制

在系统生物医学中，网络是理解复杂生物过程的核心框架。从[基因调控](@entry_id:143507)到蛋白质相互作用，再到[代谢途径](@entry_id:139344)，生物实体及其相互关系形成了一个复杂的连接织物。然而，仅仅描绘出这个网络是不够的。真正的洞见往往来自于识别其功能单元或模块，即所谓的“社群”（communities）。这些社群是网络中连接紧密的节点子集，它们在内部的相互作用远比与网络其余部分的相互作用更为密集。本章旨在深入探讨网络中社群发现与聚类的核心原理和关键机制，为从复杂的生物网络数据中提取有意义的生物学模块提供理论基础和方法论指导。

### 定义社群：从特征空间到网络拓扑

在深入探讨社群发现算法之前，我们必须首先明确我们所寻找的“社群”是什么。这需要区分两种根本不同的数据组织形式：[特征空间](@entry_id:638014)中的聚类（clustering）和网络图空间中的社群发现（community detection）。

在许多生物学场景中，例如[基因表达分析](@entry_id:138388)，每个实体（如基因）由一个高维[向量表示](@entry_id:166424)，该向量的每个分量对应一个实验条件下的测量值（如表达水平）。这些向量存在于一个欧几里得[特征空间](@entry_id:638014)中。在这种情况下，聚类的目标是将在空间中彼此靠近的点分组。一个好的聚类通常具有高**[内聚性](@entry_id:188479)（cohesion）**和高**分离性（separation）**。

[内聚性](@entry_id:188479)意味着同一簇内的点应该紧密地聚集在一起。一个常用的度量是最小化**簇内平方和（within-cluster sum of squares）**，这也是经典的k-means算法的目标函数：
$$W=\sum_{k}\sum_{i\in C_{k}}\left\|x_{i}-\mu_{k}\right\|^{2}$$
其中，$x_{i}$是基因$i$的表达向量，$C_{k}$是第$k$个簇，$\mu_{k}$是该簇的[质心](@entry_id:138352)（即簇内所有向量的均值）。

分离性则意味着不同簇之间应该有明显的间距。**[轮廓系数](@entry_id:754846)（silhouette score）**是评估分离性的有力工具。对于每个数据点$i$，其[轮廓系数](@entry_id:754846)$s(i)$定义为：
$$s(i)=\frac{b(i)-a(i)}{\max\{a(i),\,b(i)\}}$$
这里，$a(i)$是点$i$到其所属簇内其他所有点的平均距离，而$b(i)$是点$i$到“下一个最近”簇中所有点的平均距离。$s(i)$的值接近$1$表示该点被很好地分配到了当前簇，接近$0$表示它位于两个簇的边界上，而负值则暗示该点可能被分配到了错误的簇。[@problem_id:4329215]

然而，当数据本身就是以网络形式存在时，例如蛋白质相互作用（PPI）网络，情况就发生了根本性的变化。在这里，我们拥有的不是点的坐标，而是节点之间的连接关系。社群的定义不再基于空间距离，而是基于连接的模式。社群是由密集的内部连接和稀疏的外部连接所定义的节点群组。

在进入社群发现的算法世界之前，最关键的第一步是构建一个能够忠实反映我们科学假设的[生物网络](@entry_id:267733)。这个构建过程本身就充满了重要的设计决策。例如，一项旨在识别[癌症治疗](@entry_id:139037)相关蛋白质模块的研究，可能同时拥有[蛋白质组学](@entry_id:155660)丰度数据和已知的[蛋白质-蛋白质相互作用](@entry_id:271521)（PPI）信息。[@problem_id:4329221] 科学假设可能是，有意义的生物模块由那些既物理上相互作用**又**在功能上协同调控的[蛋白质组](@entry_id:150306)成。

为了构建这样一个网络，我们必须做出以下选择：
1.  **节点（Nodes）**：研究的核心实体是什么？在这个例子中，是**蛋白质**。
2.  **边（Edges）**：如何定义节点间的连接？根据假设，一条边应该同时反映物理互作（来自PPI数据库，可能有置信度分数$c_{ij}$）和功能协同（来自蛋白质丰度数据的相关性，如皮尔逊相关系数$\rho_{ij}$）。简单地使用“或”逻辑（例如，只要$c_{ij}$或$|\rho_{ij}|$超过某个阈值就建立连接）会违背假设中的“与”逻辑。一个更优的方法是创建一个**加权网络**，其中边权重$A_{ij}$是一个综合分数，它仅在$c_{ij}$和$|\rho_{ij}|$都较高时才高，例如$A_{ij} = f(c_{ij}, |\rho_{ij}|)$。这种方法避免了因设置硬阈值而导致的信息损失。
3.  **方向性（Directionality）**：网络应该是有向的还是无向的？物理上的PPI本质上是无向的（$c_{ij}=c_{ji}$），而[皮尔逊相关](@entry_id:260880)性在定义上也是对称的（$\rho_{ij}=\rho_{ji}$）。从横断面数据的相关性推断出因果或调控方向（例如，因为$\rho_{ij} > 0$就认为$i$调控$j$）是一个严重的统计谬误。因此，除非有额外的时间序列或扰动实验证据，否则构建的网络应该是**无向的**。

这个构建过程凸显了一个核心原则：[网络表示](@entry_id:752440)必须与科学假设和数据内在的对称性与局限性保持一致。一个精心构建的网络是所有后续社群发现分析的坚实基础。

### 量化社[群结构](@entry_id:146855)：目标函数

一旦网络被构建，下一个问题就是：我们如何从数学上定义一个“好”的社群划分？社群发现算法通常通过优化一个**目标函数（objective function）**来工作，这个函数量化了给定节点划分的“社群性”有多好。下面我们介绍几种主流的社群质量度量。

#### 模块度：与[零模型](@entry_id:181842)的比较

**模块度（modularity）**是最流行和最具影响力的社群质量度量之一。其核心思想是，一个好的社群划分应该使得社群内部的[边密度](@entry_id:271104)显著高于在一个“随机”网络中的期望密度。这个“随机”网络通常采用**配置模型（configuration model）**，它在保持每个节点的度（或加权度/强度）不变的情况下，随机地重新连接网络中的边。

包含可调**分辨[率参数](@entry_id:265473)（resolution parameter）** $\gamma$ 的广义模块度$Q$定义如下：
$$Q(\gamma) = \frac{1}{2m}\sum_{i,j}\left(A_{ij}-\gamma \frac{k_i k_j}{2m}\right)\delta(c_i,c_j)$$

让我们解析这个公式的每个部分[@problem_id:4329225]：
*   $A_{ij}$是[邻接矩阵](@entry_id:151010)的元素，代表节点$i$和$j$之间的实际连接权重（对于无权网络，如果$i,j$相连则为1，否则为0）。
*   $k_i = \sum_j A_{ij}$ 是节点$i$的（加权）度，也称为节点强度。
*   $2m = \sum_i k_i$ 是网络中所有边权重的总和。
*   $\frac{k_i k_j}{2m}$ 是配置模型下的零假设：节点$i$和$j$之间期望的连接权重。这个[期望值](@entry_id:150961)与两个节点的度成正比，直观地反映了度数越高的节点越有可能相互连接。
*   $\delta(c_i, c_j)$ 是克罗内克函数，当节点$i$和$j$属于同一个社群时为1，否则为0。这确保了我们只对社群内部的连接进行加和。
*   $\gamma$ 是分辨[率参数](@entry_id:265473)。当$\gamma=1$时，我们得到标准的Newman-Girvan模块度。

[模块度优化](@entry_id:752101)的目标是找到一个节点划分，使得$Q$值最大化。一个高的$Q$值意味着社群内部的连接远比随机预期的要多，这正是我们对社群的直观定义。

然而，标准模块度（$\gamma=1$）存在一个著名的**[分辨率极限](@entry_id:200378)（resolution limit）**问题：在大型网络中，它可能无法识别出那些虽然结构上清晰但尺寸小于某个阈值的社群，而倾向于将它们合并到更大的社群中。[@problem_id:4329182]

引入分辨[率参数](@entry_id:265473)$\gamma$正是为了解决这个问题。通过调节$\gamma$，我们可以探索不同尺度下的社群结构。
*   **增大 $\gamma$**：会增强[零模型](@entry_id:181842)惩罚项的权重。这使得社群合并的条件变得更加苛刻。只有那些内部连接极其致密的节[点群](@entry_id:142456)才能被识别为独立的社群。因此，增大$\gamma$会**提高分辨率**，倾向于发现更小、更紧密的社群。
*   **减小 $\gamma$**：会减弱[零模型](@entry_id:181842)的影响，使得社群合并更容易发生。这会**降低分辨率**，倾向于发现更大、更宽泛的社群。当$\gamma=0$时，模块度退化为网络中社群内部边权重所占的比例。此时，为了最大化该值，最优解是将所有节点都划分到同一个社群中。[@problem_id:4329182]

我们可以通过一个具体的例子来理解$\gamma$的作用。考虑两个社群$C_1$和$C_2$，它们之间的连接总权重为$e_{12}$，社群的总度数分别为$K_1$和$K_2$。将它们合并是否会增加模块度，取决于不等式$e_{12} > \gamma\frac{K_1 K_2}{2m}$是否成立。在一个拥有$m=1000$条边、两个社群总度数均为$K_1=K_2=80$、且它们之间有$e_{12}=3$条边的网络中，为了使这两个社群保持分离（即合并是不利的），我们需要$\gamma > \frac{2m \cdot e_{12}}{K_1 K_2} = \frac{2 \cdot 1000 \cdot 3}{80 \cdot 80} = 0.9375$。这清晰地表明，通过选择合适的$\gamma$值，我们可以识别出在标准模块度下可能被错误合并的小社群。[@problem_id:4329182]

#### 图切割与电导：瓶颈原理

另一种定义社群质量的强大视角来自于图切割理论。其核心思想是，一个好的社群应该是一个**瓶颈（bottleneck）**，即社群内部的连接远多于其与外部的连接。

为了量化这一点，我们定义几个基本概念：
*   对于一个节点子集（即一个候选社群）$S$，它与网络其余部分$\bar{S}$之间的**切割（cut）**定义为连接$S$和$\bar{S}$的所有边的权重之和：$\mathrm{cut}(S,\bar{S})=\sum_{i\in S}\sum_{j\in \bar{S}}A_{ij}$。
*   $S$的**容量（volume）**定义为$S$中所有节点的度之和：$\mathrm{vol}(S)=\sum_{i\in S}k_{i}$。这代表了与$S$中节点相关联的所有边的总权重（包括内部和外部的边）。

一个简单的想法是寻找最小化$\mathrm{cut}(S,\bar{S})$的划分。然而，这种朴素的方法往往只会将网络中度数最低的几个孤立节点切分出去，这并不是我们想要的社群。为了避免这种[平凡解](@entry_id:155162)，我们需要对切割值进行归一化。

**电导（Conductance）**是一个被广泛使用的归一化切割度量，它通过社群的容量来平衡切割的大小：
$$\phi(S)=\frac{\mathrm{cut}(S,\bar{S})}{\min\{\mathrm{vol}(S),\,\mathrm{vol}(\bar{S})\}}$$

一个社群的电导值越低，说明它相对于其内部的总连接度而言，“泄露”到外部的连接越少。因此，低电导值对应于一个结构清晰、分离良好的社群。

电导有一个非常深刻的物理解释，它与网络上的随机游走动力学紧密相关。[@problem_id:4329194] 考虑一个在网络上随机游走的粒子，它在每个节点$i$以正比于边权重$w_{ij}$的概率移动到邻居$j$。可以证明，一个社群$S$的电导$\phi(S)$（在$\mathrm{vol}(S) \le \mathrm{vol}(\bar{S})$的情况下）精确地等于当随机游走达到[稳态](@entry_id:139253)后，从$S$内部随机选择一个起点，下一步就跳出$S$的**[条件概率](@entry_id:151013)**。因此，寻找低电导的社群，就等同于寻找网络中那些能够“困住”[随机游走过程](@entry_id:171699)的区域。在生物网络中，这可以被解释为寻找那些信息流、信号或代谢物倾向于在内部循环，而不是轻易泄露到其他功能模块的子系统。[@problem_id:4329194]

#### 信息论方法：地图方程

除了基于边计数和随机游走的模型，信息论也为社群发现提供了独特的视角。**地图方程（Map Equation）**框架将社群发现问题重新表述为一个编码优化问题。[@problem_id:4329291]

其核心思想是：一个好的社群划分应该能让我们以最简洁的方式（即用最短的编码长度）来描述网络上的信息流（同样以随机游走为模型）。想象一下，我们想用一个编码本来描述一个随机游走者的漫长旅程。如果网络有很好的社群结构，游走者大部分时间都会在某个社群内徘徊，偶尔才会跳到另一个社群。

地图方程利用这个特点设计了一种两级编码方案：
1.  **索引码本（Index Codebook）**：当游走者从一个社群跳到另一个社群时，我们使用这个码本来指明它进入了哪个新社群。经常被进入的社群会被分配较短的码字。
2.  **模块码本（Module Codebooks）**：对于每个社群，都有一个专门的码本。当游走者在社群内部移动时，我们使用这个码本来描述它访问了哪个节点。每个模块码本还包含一个特殊的“退出”码字，表示游走者即将离开当前社群。

一个给定的社群划分$M$所对应的平均每步描述长度$L(M)$由地图方程给出：
$$L(M)=q_{\curvearrowright} H(\mathcal{Q})+\sum_{i=1}^{m} p_{\circlearrowright}^{i} H(\mathcal{P}^{i})$$

该方程由两部分构成：
*   第一项$q_{\curvearrowright} H(\mathcal{Q})$是描述社群间跳转的成本。$q_{\curvearrowright}$是游走者穿越社群边界的总频率，而$H(\mathcal{Q})$是索引码本的熵（即描述一次跳转的平均比特数）。
*   第二项$\sum_{i=1}^{m} p_{\circlearrowright}^{i} H(\mathcal{P}^{i})$是描述社群内部移动的成本之和。对于每个社群$i$，$p_{\circlearrowright}^{i}$是其码本被使用的总频率（包括访问其内部节点和使用退出码），$H(\mathcal{P}^{i})$是该社群码本的熵。

社群发现的目标就是找到一个划分$M$，使得总描述长度$L(M)$最小。当一个划分能很好地捕捉到信息流被限制在某些区域时，游走者会长时间停留在社群内部，导致跨社群跳转的频率$q_{\curvearrowright}$非常低。这将极大地压缩轨迹的描述长度。因此，最小化$L(M)$的过程自然地揭示了网络中作为信息流动态单元的社[群结构](@entry_id:146855)。[@problem_id:4329291]

#### 生成模型：随机区组模型

与前述优化特定目标函数的方法不同，**随机区组模型（Stochastic Block Model, SBM）**提供了一种基于[统计推断](@entry_id:172747)的生成性方法。SBM假设网络中的社群结构是潜在的（latent），而我们观察到的网络连接是这个潜在结构的一个随机实现。

经典SBM的核心假设如下[@problem_id:4329303]：
1.  每个节点$i$都属于一个潜在的、未知的社群$z_i \in \{1, \dots, K\}$。
2.  存在一个$K \times K$的对称[概率矩阵](@entry_id:274812)$P$，其中元素$p_{rs}$表示一个来自社群$r$的节点与一个来自社群$s$的节点之间存在边的概率。
3.  网络中任意一对节点$\{i,j\}$之间是否存在边是一个独立的[伯努利试验](@entry_id:268355)，其成功概率为$p_{z_i z_j}$。

在SBM框架下，社群发现问题转化为一个[统计推断](@entry_id:172747)问题：给定观察到的[邻接矩阵](@entry_id:151010)$A$，我们需要推断出最可能的节点社群分配$\{z_i\}$以及概率矩阵$P$。

SBM的强大之处在于其灵活性。通过设定不同的概率矩阵$P$，它可以描述各种各样的宏观[网络结构](@entry_id:265673)。对于[生物网络](@entry_id:267733)中常见的模块化结构，一种特别重要的模式是**同配性（homophily）**或**社群内偏好**，即社群内部的连接概率高于社群之间的连接概率。在SBM中，这表现为对角线元素大于非对角[线元](@entry_id:196833)素：$p_{rr} > p_{rs}$ 对于所有$r \neq s$。这种设定意味着节点的连接模式主要由其所属的社群决定，同一社群的成员倾向于相互连接，形成功能模块，这与生物系统中功能特化的观察高度一致。[@problem_id:4329303]

### 算法方法：寻找社群

有了定义“好”社群的目标函数，我们还需要具体的算法机制来在巨大的划分空间中找到最优或接近最优的解。

#### 贪心优化：[Louvain算法](@entry_id:270022)

对于像模块度这样的目标函数，穷举所有可能的节点划分在计算上是不可行的。**[Louvain算法](@entry_id:270022)**是一种广泛使用的[贪心启发式算法](@entry_id:167880)，它能够快速地为大型网络找到高质量的模块度划分。[@problem_id:4329356] 该算法通过迭代执行以下两个阶段直至收敛：

1.  **局部移动阶段（Local Moving Phase）**：
    算法首先将每个节点初始化到其自身的社群中。然后，它依次遍历网络中的所有节点。对于每个节点$i$，算法会评估将其从当前社群移动到其每个**邻居所在社群**后，模块度$Q$的变化量$\Delta Q$。接着，节点$i$会被移动到那个能带来最大正向$\Delta Q$的社群中。如果没有任何移动能够增加模块度，节点$i$则保持不动。这个过程会重复遍历所有节点，直到没有单个节点的移动能够进一步提高模块度为止。此时，算法达到了一个模块度的局部最优解。

2.  **聚合阶段（Aggregation Phase）**：
    在局部移动阶段结束后，算法将第一阶段发现的所有社群“压缩”成新的“超级节点”。然后，一个新的、更小规模的加权网络被构建出来。超级节点之间的边权重等于原始节点社群之间的总边权重，而每个超级节点的[自环](@entry_id:274670)权重等于原始社群内部的总边权重。一个关键且优美的特性是，新构建的聚合网络的模块度（对于其超级节点的平凡划分）与原始网络在前一阶段找到的划分所对应的模块度是**完全相同**的。[@problem_id:4329356] 这意味着，我们可以在这个更小、更粗粒度的网络上重新开始执行第一阶段（局部移动），以进一步优化同一个全局模块度目标。

这两个阶段会交替进行。每次聚合后，网络规模减小，使得算法能够探索更大尺度的社群结构。当一次完整的两阶段迭代不再产生任何社群变化和模块度增加时，[算法终止](@entry_id:143996)，最终的社群结构就是各层级累积的划分结果。由于其贪心本质，[Louvain算法](@entry_id:270022)不能保证找到全局最优解，但实践证明它在速度和结果质量之间取得了出色的平衡。

#### 谱聚类：一种特征向量方法

**谱聚类（Spectral Clustering）**是一类基于图的拉普拉斯矩阵（Graph Laplacian）特征值和特征向量的强大算法。它与前面讨论的电导和归一化切割目标函数有深刻的数学联系。[@problem_id:4329165]

其基本思想是，将一个离散的、[NP难](@entry_id:264825)的[图划分](@entry_id:152532)问题（如最小化归一化切割）进行**谱松弛（spectral relaxation）**，转化为一个可以在连续空间中求解的线性代数问题。
1.  **构建拉普拉斯矩阵**：首先，需要构建图的拉普拉斯矩阵。对于处理度不均匀的真实世界网络（如生物网络），**对称归一化拉普拉斯矩阵** $L_{\mathrm{sym}}$ 通常是首选：
    $$L_{\mathrm{sym}} = I - D^{-1/2} A D^{-1/2}$$
    其中，$A$是加权[邻接矩阵](@entry_id:151010)，$D$是对角线上为节点度（强度）的度矩阵，$I$是单位矩阵。

2.  **计算特征向量**：接下来，计算$L_{\mathrm{sym}}$的最小的几个特征值及其对应的特征向量。[拉普拉斯矩阵](@entry_id:152110)的谱（特征值集合）包含了关于[图连通性](@entry_id:266834)的丰富信息。
    *   $L_{\mathrm{sym}}$的最小特征值总是$0$，其对应特征向量的个数等于图中连通分量的个数。对于一个[连通图](@entry_id:264785)，只有一个$0$特征值。因此，通过检查$0$特征值的数量，我们可以直接确定网络有多少个分离的组分。[@problem_id:4329165]
    *   对于社群发现，我们更关心的是那些与“近乎断开”的结构相对应的特征向量。这些信息蕴含在最小的**非零**特征值及其特征向量中。例如，对应第二小特征值（常被称为**Fiedler值**）的特征向量（**[Fiedler向量](@entry_id:148200)**）的元素正负号，可以为网络提供一个近似最优的二分划分。

3.  **节点嵌入与聚类**：为了将[网络划分](@entry_id:273794)为$k$个社群，我们取$L_{\mathrm{sym}}$的前$k$个特征向量（通常是对应最小的$k$个特征值的向量）。这些特征向量构成一个$n \times k$的矩阵$U$。该矩阵的每一行可以看作是原始网络中对应节点在$k$维欧几里得空间中的一个新坐标或**嵌入（embedding）**。在这个低维[嵌入空间](@entry_id:637157)中，原始网络中连接紧密的节点会彼此靠近。最后，我们在这个$k$维空间中对这$n$个点应用标准的[聚类算法](@entry_id:146720)（如k-means）来得到最终的社群划分。[@problem_id:4329165]

谱聚类将复杂的[图划分](@entry_id:152532)问题巧妙地转化为了一个更易于处理的向量聚类问题，其理论基础坚实，并且在实践中表现优异。

### 结果评估：内部与外部验证

在应用任何社群发现算法后，一个至关重要的问题是：我们得到的社群划分质量如何？评估方法分为两大类，取决于我们是否拥有一个可供参考的“基准真相”（ground truth）划分。[@problem_id:4329327]

#### 内部验证（无基准真相）

当没有外部[参考标准](@entry_id:754189)时（这是常态），我们必须仅根据[网络结构](@entry_id:265673)和划分本身来评估其质量。这类指标被称为**内部验证指标**。它们通常量化了我们在本章开头讨论的社群的[内聚性](@entry_id:188479)和分离性。
*   **模块度（Modularity）**：可以直接计算得到划分的$Q$值。较高的$Q$值通常表示较好的社[群结构](@entry_id:146855)。
*   **电导（Conductance）**：可以计算每个社群的电导。一个好的划分应该由许多低电导的社群组成，表明每个社群都是一个有效的“[信息瓶颈](@entry_id:263638)”。
*   **[轮廓系数](@entry_id:754846)（Silhouette Score）**：虽然源于欧几里得空间，但只要我们能在网络上定义一个合理的距离或相异性度量（例如，最短路径长度），就可以计算每个节点的[轮廓系数](@entry_id:754846)。平均[轮廓系数](@entry_id:754846)可以作为整个划分质量的度量。

#### 外部验证（有基准真相）

在某些情况下，我们可能拥有一个已知的、可信的参考划分。例如，在[基因网络](@entry_id:263400)中，我们可以使用来自KEGG或Gene Ontology等数据库的通路注释作为基准真相。**外部验证指标**通过比较算法找到的划分与参考划分的吻合程度来评估算法性能。
*   **调整兰德指数（Adjusted Rand Index, ARI）**：ARI衡量了两对节点在两个划分中被如何处理的一致性，并对随机情况进行了校正。其值域通常在$[-1, 1]$之间，1表示完全一致，0表示与随机划分的相似度，负值表示比随机情况更差。
*   **归一化互信息（Normalized Mutual Information, NMI）**：NMI源于信息论，它衡量了知道一个划分能在多大程度上减少关于另一个划分的不确定性。它被归一化到$[0, 1]$区间，1表示完美对应，0表示两个划分完全独立。

正确选择和使用这些评估指标至关重要。内部指标帮助我们[优化算法](@entry_id:147840)参数和比较不同算法在特定数据集上的内在表现，而外部指标则让我们能够在一个公认的生物学背景下，衡量算法发现的社群是否具有实际意义。[@problem_id:4329327]