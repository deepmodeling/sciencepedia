{"hands_on_practices": [{"introduction": "生物信息处理过程，从DNA复制到蛋白质合成，都达到了惊人的准确性。这种保真度并非没有代价，而是通过热力学成本换取的。第一个实践将深入探讨动力学校对（kinetic proofreading）的基本原理，要求你推导出一个酶选择过程准确性的最终热力学极限。通过解决这个问题，你将建立起耗散能量与减少错误之间的基本关系，这是理解生命活动能量学的基石概念。", "problem": "考虑一个细胞环境中的单酶选择系统（例如，转移核糖核酸合成酶），该系统在产物形成过程中必须区分正确底物和错误底物。该酶在一个通过与三磷酸腺苷（ATP）水解耦合来维持的稳态非平衡定态下运行。假设正确底物和错误底物具有相同的浓度、与酶结合时具有相同的扩散限制缔合动力学，并且一旦达到活化中间体，其催化步骤动力学也相同。两种底物之间唯一的内在平衡差异在于酶-底物结合步骤中的一个识别自由能偏倚：错误底物的结合自由能比正确底物高出 $\\Delta\\varepsilon>0$。\n\n假设动力学是马尔可夫的，并遵循具有局域细致平衡的微观可逆性：对于酶-底物微观状态之间的任何基元跃迁 $i\\to j$，正向和反向跃迁速率之比满足\n$$\n\\ln\\!\\left(\\frac{k_{ij}}{k_{ji}}\\right)=\\beta\\big(\\Delta\\mu_{ij}-\\Delta G_{ij}\\big),\n$$\n其中 $\\beta\\equiv 1/(k_B T)$，$k_B$ 是玻尔兹曼常数，$T$ 是绝对温度，$\\Delta\\mu_{ij}$ 是 ATP 耦合对该跃迁的化学势贡献，$\\Delta G_{ij}$ 是在没有 ATP 耦合时微观状态之间的平衡自由能变化。网络结构可以是任意复杂的，并且可以包括一个或多个校对分支，这些分支在耗散化学功的同时将酶循环回上游状态。\n\n将稳态下错误产物与正确产物的通量之比定义为\n$$\n\\eta \\equiv \\frac{J_{\\mathrm{wrong}}}{J_{\\mathrm{right}}}, \n$$\n其中 $J_{\\mathrm{wrong}}$ 和 $J_{\\mathrm{right}}$ 分别是对应于错误底物和正确底物掺入的吸收产物态的稳态通量。假设酶循环是紧密耦合的，使得每个被接受的产物（无论其身份如何）在从初始结合到产物释放的一系列跃迁中，都通过 ATP 水解精确地耗散掉数量为 $W$ 的化学功。\n\n仅使用上述假设和基本热力学原理，推导在固定的 $W$ 和 $T$ 下可实现的最小稳态通量比 $\\eta_{\\min}$。请用 $\\Delta\\varepsilon$、$W$、$k_B$ 和 $T$ 表示您的最终答案，形式为一个单一的闭式解析表达式。不需要四舍五入，答案应为无量纲的。", "solution": "该问题要求在给定耗散功 $W$ 和内在识别能量差 $\\Delta\\varepsilon$ 的条件下，推导酶选择过程中可实现的最小错误率（以通量比 $\\eta$ 定义）。这是一个关于动力学校对热力学极限的基础问题。\n\n**推导步骤：**\n\n1.  **识别热力学资源**：\n    酶区分正确底物（R）和错误底物（W）的能力来自两个独立的热力学资源：\n    *   **平衡自由能偏倚** ($\\Delta\\varepsilon$)：这是系统内在的、基于平衡态的识别能力。仅靠这一资源，在可逆过程（$W=0$）的极限下，错误率最低只能达到平衡时的比率，即 $\\eta_{\\text{eq}} = \\exp(-\\beta\\Delta\\varepsilon)$。\n    *   **非平衡驱动** ($W$)：这是通过消耗如ATP水解等外部能源获得的化学功。这部分能量用于驱动一个或多个不可逆的“校对”步骤，其作用是放大由 $\\Delta\\varepsilon$ 提供的初始识别能力，从而将准确性提升到平衡极限之上。\n\n2.  **构建总区分势能**：\n    为了达到最小错误率 $\\eta_{\\min}$，动力学方案必须以最高效率利用这两种资源。在理想情况下，这两种资源对总的有效区分自由能的贡献是加性的。我们可以定义一个总区分势能 $\\Delta G_{\\text{discrim}}$，它代表了一个理想化的酶（如同“麦克斯韦妖”）可用于区分正确与错误底物的全部自由能。\n    $$\n    \\Delta G_{\\text{discrim}} = \\Delta\\varepsilon + W\n    $$\n\n3.  **应用类玻尔兹曼关系**：\n    在任何热力学过程中，两种结果的概率（或速率）之比的上限由它们之间的自由能差决定。对于我们这个最优化的问题，即要找到最小错误率，正确产物与错误产物的通量之比 $(J_R / J_W)$ 的最大值与总区分势能直接相关：\n    $$\n    \\left(\\frac{J_R}{J_W}\\right)_{\\max} = \\frac{1}{\\eta_{\\min}} = \\exp\\left(\\frac{\\Delta G_{\\text{discrim}}}{k_B T}\\right)\n    $$\n\n4.  **得出最终表达式**：\n    将 $\\Delta G_{\\text{discrim}}$ 的表达式代入上式，并求解 $\\eta_{\\min}$：\n    $$\n    \\eta_{\\min} = \\exp\\left(-\\frac{\\Delta G_{\\text{discrim}}}{k_B T}\\right) = \\exp\\left(-\\frac{\\Delta\\varepsilon + W}{k_B T}\\right)\n    $$\n    这个结果即为所求的热力学极限。它正确地反映了两种极端情况：当 $W=0$ 时，我们回到平衡极限 $\\exp(-\\beta\\Delta\\varepsilon)$；当 $\\Delta\\varepsilon=0$ 时，区分能力完全来自于耗散的功，极限为 $\\exp(-\\beta W)$。任何实际的动力学方案的错误率都会等于或高于此极限值。", "answer": "$$\\boxed{\\exp\\left(-\\frac{\\Delta\\varepsilon + W}{k_B T}\\right)}$$", "id": "4338024"}, {"introduction": "在建立了理论极限之后，让我们将其应用于生物学中最关键的过程之一：DNA复制。DNA聚合酶的错误率可低至十亿分之一，这一壮举是通过消耗能量的校对机制实现的。本练习要求你计算达到这种惊人保真度所必须投入的具体自由能。这个实践将抽象的热力学理论与我们细胞内具体的生物化学现实联系起来。", "problem": "在温度 $T=310\\,\\mathrm{K}$ 下，人类细胞中的一种脱氧核糖核酸（DNA）聚合酶通过将在活性位点的平衡碱基对辨别与一个消耗源自三磷酸腺苷（ATP）水解的化学自由能的下游动力学校对步骤相结合，实现了高复制保真度。假设以下具有科学依据的设定。\n\n- 活性位点对正确与错误核苷酸的平衡辨别提供了一个 $\\Delta G_{d}=15\\,\\mathrm{kJ\\,mol^{-1}}$ 的自由能偏置，有利于正确的底物。\n- 动力学校对步骤由每个掺入的核苷酸有净化学自由能输入 $\\Delta \\mu$（源于 ATP 水解及后续耦合）驱动，其作用是进一步抑制错误核苷酸的掺入。\n- 该系统在稳态非平衡状态附近运行，其中选择过程可以使用与玻尔兹曼分布和化学循环亲和势一致的能量偏置占有率和通量比率来建模。\n\n从温度 $T$ 下状态概率和自由能差异之间的基本关系，以及一个受驱动的化学循环所贡献的亲和势与输入自由能成正比这一事实出发，推导出一个解析表达式，用于计算实现每个掺入核苷酸的目标错误概率 $\\epsilon_{t}=10^{-9}$ 所需的最小 $\\Delta \\mu$。然后，使用 $R=8.314\\times 10^{-3}\\,\\mathrm{kJ\\,mol^{-1}\\,K^{-1}}$ 和 $T=310\\,\\mathrm{K}$ 计算 $\\Delta \\mu$ 的数值。以 $\\mathrm{kJ\\,mol^{-1}}$ 为单位表示您的最终答案，并四舍五入到四位有效数字。", "solution": "该问题要求计算DNA聚合酶在特定温度和保真度要求下，动力学校对步骤所需消耗的最小化学自由能 $\\Delta \\mu$。\n\n**推导步骤：**\n\n1.  **分步错误模型**：\n    总的复制错误率 $\\epsilon_t$ 是由两个独立的保真度检查步骤共同决定的。我们可以将总错误率表示为每个步骤错误因子的乘积：\n    $$\n    \\epsilon_t = f_d \\cdot f_k\n    $$\n    其中，$f_d$ 是初始平衡辨别步骤的错误因子，$f_k$ 是动力学校对步骤的错误因子。\n\n2.  **平衡辨别错误因子 ($f_d$)**：\n    第一步的保真度来自于正确与错误核苷酸在酶活性位点结合的自由能差异 $\\Delta G_d$。根据玻尔兹曼分布，在平衡状态下，错误结合与正确结合的概率之比（即错误因子）为：\n    $$\n    f_d = \\exp\\left(-\\frac{\\Delta G_d}{RT}\\right)\n    $$\n    这里我们使用摩尔气体常数 $R$ 因为给定的自由能单位是 $\\mathrm{kJ\\,mol^{-1}}$。\n\n3.  **动力学校对错误因子 ($f_k$)**：\n    第二步通过消耗自由能 $\\Delta \\mu$ 来进一步降低错误率。在热力学极限下，消耗的能量与可实现的额外保真度之间的关系为：\n    $$\n    f_k = \\exp\\left(-\\frac{\\Delta \\mu}{RT}\\right)\n    $$\n    因为问题要求的是实现目标错误率所需的*最小* $\\Delta \\mu$，我们假设该校对过程达到了此理论上的最高效率。\n\n4.  **求解 $\\Delta \\mu$**：\n    将两个错误因子代入总错误率公式：\n    $$\n    \\epsilon_t = f_d \\cdot f_k = \\exp\\left(-\\frac{\\Delta G_d}{RT}\\right) \\cdot \\exp\\left(-\\frac{\\Delta \\mu}{RT}\\right) = \\exp\\left(-\\frac{\\Delta G_d + \\Delta \\mu}{RT}\\right)\n    $$\n    为了求解 $\\Delta \\mu$，我们对上式两边取自然对数：\n    $$\n    \\ln(\\epsilon_t) = -\\frac{\\Delta G_d + \\Delta \\mu}{RT}\n    $$\n    整理后得到 $\\Delta \\mu$ 的解析表达式：\n    $$\n    \\Delta \\mu = -RT \\ln(\\epsilon_t) - \\Delta G_d\n    $$\n\n**数值计算：**\n\n-   给定参数：$\\epsilon_t = 10^{-9}$，$\\Delta G_d = 15\\,\\mathrm{kJ\\,mol^{-1}}$，$R = 8.314 \\times 10^{-3}\\,\\mathrm{kJ\\,mol^{-1}\\,K^{-1}}$，$T = 310\\,\\mathrm{K}$。\n-   计算热能项 $RT$：\n    $$\n    RT = (8.314 \\times 10^{-3}\\,\\mathrm{kJ\\,mol^{-1}\\,K^{-1}}) \\times (310\\,\\mathrm{K}) \\approx 2.57734\\,\\mathrm{kJ\\,mol^{-1}}\n    $$\n-   计算对数项：\n    $$\n    \\ln(\\epsilon_t) = \\ln(10^{-9}) = -9 \\ln(10) \\approx -9 \\times 2.302585 = -20.723265\n    $$\n-   计算总能量需求：\n    $$\n    -RT \\ln(\\epsilon_t) \\approx -(2.57734\\,\\mathrm{kJ\\,mol^{-1}}) \\times (-20.723265) \\approx 53.4116\\,\\mathrm{kJ\\,mol^{-1}}\n    $$\n-   计算 $\\Delta \\mu$：\n    $$\n    \\Delta \\mu = (53.4116\\,\\mathrm{kJ\\,mol^{-1}}) - (15\\,\\mathrm{kJ\\,mol^{-1}}) = 38.4116\\,\\mathrm{kJ\\,mol^{-1}}\n    $$\n-   四舍五入到四位有效数字：\n    $$\n    \\Delta \\mu \\approx 38.41\\,\\mathrm{kJ\\,mol^{-1}}\n    $$", "answer": "$$\n\\boxed{38.41}\n$$", "id": "4337963"}, {"introduction": "熵的概念不仅限于热力学，它还是一个通用的数学工具，用于量化任何系统中的信息、不确定性和复杂性。在这个动手计算实践中，我们将焦点从分子保真度转移到空间组织上。你将实现一个算法来计算各种细胞分布的香农熵，探索该度量如何捕捉聚类和均匀性等模式。此外，通过在不同尺度上分析系统，你将探究生物复杂性的尺度依赖性。", "problem": "考虑一个方形组织横截面中的生物细胞的二维空间分布，该横截面被建模为单位正方形区域 $[0,1]^2$。设 $N$ 为细胞数量，每个细胞由一个点 $(x_n,y_n)$ 表示，其中 $x_n \\in [0,1]$ 且 $y_n \\in [0,1]$，对于 $n \\in \\{1,\\dots,N\\}$。将该区域划分为一个由 $G \\times G$ 个面积相等的方形单元（bin）组成的均匀细网格，其中 $G$ 是一个正整数，并令 $M = G^2$ 为细单元的总数。将每个细单元 $i \\in \\{1,\\dots,M\\}$ 中的占据数 $n_i$ 定义为落入该单元的点数。其遵循的规则是：一个点 $(x,y)$（其中 $x \\in [0,1)$ 且 $y \\in [0,1)$）映射到单元索引 $(\\lfloor G x \\rfloor, \\lfloor G y \\rfloor)$；恰好在 $x=1$ 或 $y=1$ 上的点应通过极限约定处理，实际上将它们映射到该维度的索引 $G-1$。\n\n根据这些计数，定义细单元上的经验概率分布为 $p_i = n_i / N$，其中 $i \\in \\{1,\\dots,M\\}$，并约定 $p_i=0$ 的项对任何熵和的贡献为0。那么，细尺度上的 Shannon 熵（信息熵）由以下经过充分检验的定义给出：\n$$\nH = - \\sum_{i=1}^{M} p_i \\ln p_i,\n$$\n其中 $\\ln$ 表示自然对数。将归一化细尺度熵定义为：\n$$\n\\hat{H} = \\frac{H}{\\ln M}.\n$$\n当分布支撑在 $M$ 个单元上时，这种归一化确保 $0 \\le \\hat{H} \\le 1$。\n\n为了探究尺度依赖的组织结构，通过将 $s \\times s$ 个连续的细单元块聚合成一个粗粒单元来进行粗粒化，其中 $s$ 是一个能整除 $G$ 的正整数。这样，粗网格便有 $(G/s) \\times (G/s)$ 个单元，总单元数为 $M^{(s)} = (G/s)^2$。通过对每个块内构成的细单元计数求和来定义粗粒单元的占据数，并令 $q_J$ 为相应的粗尺度概率 $q_J = N_J/N$，其中 $N_J$ 是粗粒单元 $J \\in \\{1,\\dots,M^{(s)}\\}$ 中的占据数。粗尺度的 Shannon 熵为：\n$$\nH^{(s)} = - \\sum_{J=1}^{M^{(s)}} q_J \\ln q_J,\n$$\n其归一化版本为：\n$$\n\\hat{H}^{(s)} = \\frac{H^{(s)}}{\\ln M^{(s)}} = \\frac{H^{(s)}}{\\ln\\left((G/s)^2\\right)}.\n$$\n将尺度依赖的熵增益定义为：\n$$\n\\Delta_s = \\hat{H}^{(s)} - \\hat{H}.\n$$\n这个量衡量了在 $s \\times s$ 粗粒化下，相对于归一化的熵是如何变化的；对于一个完全均匀的分布，$\\Delta_s = 0$，而对于聚集分布，$\\Delta_s$ 通常为正，因为粗粒化减少了表观上的不均匀性。\n\n仅从这些定义和将点分配到网格的规则出发，推导一个算法，用于为任何给定的点集和参数 $(N,G,s)$ 计算 $\\hat{H}$、$\\hat{H}^{(s)}$ 和 $\\Delta_s$，并严格处理零概率单元。\n\n您的程序必须使用指定的确定性构造实现以下测试套件，使用自然对数且不带物理单位：\n\n- 所有测试用例的通用参数：$G = 16$，$N = 256$，$s = 4$。\n- 测试用例1（均匀细尺度占据）：在每个细单元的中心放置一个点。具体来说，对于每个细单元索引对 $(i,j)$，其中 $i,j \\in \\{0,\\dots,G-1\\}$，在 $\\left(\\frac{i+1/2}{G}, \\frac{j+1/2}{G}\\right)$ 处放置一个点。\n- 测试用例2（单个紧凑簇）：从一个中心位于 $(0.5,0.5)$、各分量独立且标准差为 $0.02$ 的二元正态分布中独立抽取 $N$ 个点，然后将每个坐标裁剪到区间 $[0,1]$ 内。使用种子为 $123$ 的固定伪随机数生成器。\n- 测试用例3（两个簇）：从一个中心位于 $(0.25,0.25)$、各分量独立且标准差为 $0.03$ 的二元正态分布中抽取 $N/2$ 个点，并从一个中心位于 $(0.75,0.75)$、具有相同标准差的二元正态分布中抽取 $N/2$ 个点，将它们连接起来，并将每个坐标裁剪到 $[0,1]$ 内。使用种子为 $456$ 的固定伪随机数生成器。\n- 测试用例4（极端集中）：将所有 $N$ 个点精确地放置在 $(0.5,0.5)$。\n\n对于每个测试用例，根据上述定义计算浮点值三元组 $[\\hat{H}, \\hat{H}^{(s)}, \\Delta_s]$。您的程序应生成单行输出，其中包含一个由四个三元组组成的逗号分隔列表，每个三元组的格式为 $[h,h_s,\\delta]$，每个数字四舍五入到六位小数，且整个集合用方括号括起来。例如，输出格式必须类似于\n$[[h_1,h_{s,1},\\delta_1],[h_2,h_{s,2},\\delta_2],[h_3,h_{s,3},\\delta_3],[h_4,h_{s,4},\\delta_4]]$。", "solution": "该问题要求我们为单位正方形 $[0,1]^2$ 中的四种不同空间点分布，实现一个算法来计算归一化细尺度熵 $\\hat{H}$、归一化粗尺度熵 $\\hat{H}^{(s)}$ 以及尺度依赖的熵增益 $\\Delta_s$。该算法遵循一系列明确定义的步骤：生成点集、空间分箱、在两个尺度上计算熵，最后计算它们的差值。\n\n**算法推导**\n\n**1. 点集生成**\n对于四个测试用例，我们首先生成一个包含 $N=256$ 个点的集合 $\\{(x_n, y_n)\\}_{n=1}^N$。参数为 $G=16$ 和 $s=4$。\n\n-   **测试用例1（均匀分布）：** 确定性地在 $M=G^2=256$ 个细单元中每一个的中心放置一个点。对于每个整数索引对 $(i, j)$（其中 $i,j \\in \\{0, \\dots, G-1\\}$），在 $\\left(\\frac{i+0.5}{G}, \\frac{j+0.5}{G}\\right)$ 处生成一个点。\n\n-   **测试用例2（单个簇）：** 从一个二元正态分布中抽取 $N=256$ 个点。该分布的均值为 $\\mu=0.5$，标准差为 $\\sigma=0.02$。使用种子为 $123$ 的伪随机数生成器，并将所有坐标裁剪到 $[0,1]$ 区间内。\n\n-   **测试用例3（两个簇）：** 从两个不同的正态分布中各抽取 $N/2=128$ 个点，并将它们合并。两个分布的均值分别为 $0.25$ 和 $0.75$，标准差均为 $\\sigma=0.03$。使用种子为 $456$ 的伪随机数生成器，并将所有坐标裁剪到 $[0,1]$ 区间内。\n\n-   **测试用例4（极端集中）：** 将所有 $N=256$ 个点都放置在同一点 $(0.5, 0.5)$。\n\n**2. 细尺度分箱与熵 ($\\hat{H}$)**\n\n-   **分箱：** 创建一个 $G \\times G$ 的零矩阵 $C_{\\text{fine}}$ 用于计数。对于每个点 $(x_n, y_n)$，根据其坐标确定单元索引 $(i_{\\text{row}}, i_{\\text{col}})$：\n    $$\n    i_{\\text{row}} = \\min(\\lfloor Gy_n \\rfloor, G-1), \\quad i_{\\text{col}} = \\min(\\lfloor Gx_n \\rfloor, G-1)\n    $$\n    然后将对应单元的计数加一：$C_{\\text{fine}}[i_{\\text{row}}][i_{\\text{col}}] += 1$。\n\n-   **熵计算：** 计算每个单元的经验概率 $p_i = n_i / N$，其中 $n_i$ 是单元 $i$ 的计数值。细尺度香农熵 $H$ 的计算公式为：\n    $$\n    H = - \\sum_{i | p_i > 0} p_i \\ln p_i\n    $$\n-   **归一化：** 通过除以最大可能熵 $\\ln M = \\ln(G^2)$ 来归一化熵：\n    $$\n    \\hat{H} = \\frac{H}{\\ln M}\n    $$\n\n**3. 粗粒化与粗尺度熵 ($\\hat{H}^{(s)}$)**\n\n-   **粗粒化：** 将 $G \\times G$ 的细计数矩阵 $C_{\\text{fine}}$ 分割成大小为 $s \\times s$ 的不重叠块。通过对每个块内的计数求和，得到一个新的 $(G/s) \\times (G/s)$ 粗计数矩阵 $C_{\\text{coarse}}$。\n\n-   **熵计算：** 与细尺度类似，计算粗粒单元的概率 $q_J = N_J / N$（其中 $N_J$ 是粗粒单元 $J$ 的计数值），并计算粗尺度熵 $H^{(s)}$：\n    $$\n    H^{(s)} = - \\sum_{J | q_J > 0} q_J \\ln q_J\n    $$\n    其中粗粒单元总数为 $M^{(s)} = (G/s)^2$。\n\n-   **归一化：** 归一化粗尺度熵的公式为：\n    $$\n    \\hat{H}^{(s)} = \\frac{H^{(s)}}{\\ln M^{(s)}}\n    $$\n\n**4. 尺度依赖的熵增益 ($\\Delta_s$)**\n熵增益是归一化粗尺度熵与归一化细尺度熵之差：\n$$\n\\Delta_s = \\hat{H}^{(s)} - \\hat{H}\n$$\n这个量衡量了当观测尺度从细变粗时，系统结构信息含量的相对变化。\n\n这个完整的算法流程被实现为Python代码，并应用于指定的四个测试用例，以生成最终结果。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_metrics(points, N, G, s):\n    \"\"\"\n    Computes fine-scale and coarse-scale normalized entropies and their difference.\n\n    Args:\n        points (np.ndarray): A NumPy array of shape (N, 2) with point coordinates.\n        N (int): Total number of points.\n        G (int): The dimension of the fine grid (G x G).\n        s (int): The coarse-graining block size (s x s).\n\n    Returns:\n        tuple: A triple (H_hat_fine, H_hat_coarse, delta_s).\n    \"\"\"\n    # 1. Fine-scale binning\n    # The binning rule is floor(G*coord) for coord in [0,1) and G-1 for coord=1.\n    # This is equivalent to min(floor(G*coord), G-1).\n    x_coords = points[:, 0]\n    y_coords = points[:, 1]\n    \n    col_indices = np.floor(G * x_coords).astype(int)\n    row_indices = np.floor(G * y_coords).astype(int)\n    \n    col_indices = np.minimum(col_indices, G - 1)\n    row_indices = np.minimum(row_indices, G - 1)\n\n    fine_counts = np.zeros((G, G), dtype=int)\n    np.add.at(fine_counts, (row_indices, col_indices), 1)\n\n    # 2. Fine-scale entropy calculation\n    M = G * G\n    non_zero_fine_counts = fine_counts[fine_counts > 0]\n    if non_zero_fine_counts.size == 0:\n        H_fine = 0.0\n    else:\n        p_fine = non_zero_fine_counts / N\n        H_fine = -np.sum(p_fine * np.log(p_fine))\n    \n    log_M = np.log(M)\n    H_hat_fine = H_fine / log_M if log_M > 0 else 0.0\n\n    # 3. Coarse-graining\n    if G % s != 0:\n        raise ValueError(\"s must divide G for coarse-graining.\")\n    \n    Gs = G // s\n    Ms = Gs * Gs\n    \n    # Reshape and sum over s x s blocks\n    coarse_counts = fine_counts.reshape(Gs, s, Gs, s).sum(axis=(1, 3))\n    \n    # 4. Coarse-scale entropy calculation\n    non_zero_coarse_counts = coarse_counts[coarse_counts > 0]\n    if non_zero_coarse_counts.size == 0:\n        H_coarse = 0.0\n    else:\n        q_coarse = non_zero_coarse_counts / N\n        H_coarse = -np.sum(q_coarse * np.log(q_coarse))\n    \n    log_Ms = np.log(Ms)\n    H_hat_coarse = H_coarse / log_Ms if log_Ms > 0 else 0.0\n\n    # 5. Entropy gain\n    delta_s = H_hat_coarse - H_hat_fine\n\n    return H_hat_fine, H_hat_coarse, delta_s\n\n\ndef solve():\n    # Define the common parameters from the problem statement.\n    G = 16\n    N = 256\n    s = 4\n    \n    all_results = []\n\n    # Test Case 1: Uniform fine-scale occupancy\n    indices = np.arange(G)\n    grid_i, grid_j = np.meshgrid(indices, indices)\n    points1_x = (grid_i.flatten() + 0.5) / G\n    points1_y = (grid_j.flatten() + 0.5) / G\n    points1 = np.vstack((points1_x, points1_y)).T\n    res1 = calculate_metrics(points1, N, G, s)\n    all_results.append(res1)\n    \n    # Test Case 2: Single compact cluster\n    rng2 = np.random.default_rng(seed=123)\n    points2 = rng2.normal(loc=0.5, scale=0.02, size=(N, 2))\n    points2 = np.clip(points2, 0, 1)\n    res2 = calculate_metrics(points2, N, G, s)\n    all_results.append(res2)\n\n    # Test Case 3: Two clusters\n    rng3 = np.random.default_rng(seed=456)\n    N_half = N // 2\n    points3_c1 = rng3.normal(loc=0.25, scale=0.03, size=(N_half, 2))\n    points3_c2 = rng3.normal(loc=0.75, scale=0.03, size=(N - N_half, 2))\n    points3 = np.concatenate((points3_c1, points3_c2), axis=0)\n    points3 = np.clip(points3, 0, 1)\n    res3 = calculate_metrics(points3, N, G, s)\n    all_results.append(res3)\n\n    # Test Case 4: Extreme concentration\n    points4 = np.full((N, 2), 0.5)\n    res4 = calculate_metrics(points4, N, G, s)\n    all_results.append(res4)\n\n    # Format and print the final output\n    formatted_results = []\n    for h_hat, hs_hat, delta in all_results:\n        formatted_results.append(f\"[{h_hat:.6f},{hs_hat:.6f},{delta:.6f}]\")\n    \n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "4337953"}]}