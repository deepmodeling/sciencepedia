{"hands_on_practices": [{"introduction": "掌握敏感度分析首先要理解其最基本的形式：局部归一化敏感度。本练习将通过一个简单的一阶衰变模型，推导敏感度函数，并着重解释其符号和时间依赖性如何揭示系统的生物物理行为。这项实践旨在建立关于参数如何影响模型动态的基本直觉。[@problem_id:4385521]", "problem": "考虑一个均匀细胞区室中单一生物分子物种的简约一阶衰变模型，其中浓度 $x(t)$ 遵循常微分方程 $ \\dot{x}(t) = -k\\,x(t)$，初始条件为 $x(0) = x_{0}$，测量输出为 $y(t) = x(t)$。假设 $k  0$ 和 $x_{0}  0$，时间 $t$ 以秒为单位， $k$ 的单位为 $\\text{s}^{-1}$。使用动力系统中局部归一化参数敏感度的基本定义，其中对于输出 $y(t)$ 和参数 $k$，敏感度函数为\n$$\nS_{y,k}(t) \\equiv \\frac{k}{y(t)}\\,\\frac{\\partial y(t)}{\\partial k},\n$$\n推导给定模型的 $S_{y,k}(t)$ 的闭式解。然后，从第一性原理出发，解释 $S_{y,k}(t)$ 的符号和时间依赖性如何反映衰变参数 $k$ 的生物物理意义以及模型的动力学。将你最终的敏感度函数表示为单个解析表达式。无需数值取整，且最终表达式应为无量纲的。", "solution": "首先对问题陈述进行严格的验证过程。\n\n### 步骤1：提取已知条件\n已知条件如下：\n-   生物分子物种浓度 $x(t)$ 的常微分方程(ODE)：$\\dot{x}(t) = -k\\,x(t)$。\n-   初始条件：$x(0) = x_0$。\n-   测量输出：$y(t) = x(t)$。\n-   参数约束：$k  0$ 且 $x_0  0$。\n-   单位：时间 $t$ 的单位是秒($\\text{s}$)，速率常数 $k$ 的单位是 $\\text{s}^{-1}$。\n-   输出 $y(t)$ 相对于参数 $k$ 的局部归一化参数敏感度函数的定义：$S_{y,k}(t) \\equiv \\frac{k}{y(t)}\\,\\frac{\\partial y(t)}{\\partial k}$。\n\n### 步骤2：使用提取的已知条件进行验证\n根据验证标准对问题进行评估。\n-   **科学依据：** 模型 $\\dot{x} = -k\\,x$ 描述了一阶衰变，这是物理学、化学和生物学中一个基本且普遍存在的过程（例如，放射性衰变、单分子化学反应、蛋白质降解）。归一化敏感度的定义是系统理论和敏感度分析中的一个标准核心概念。该问题牢固地植根于既定的科学和数学原理。\n-   **适定性：** 该问题是一个适定的初值问题，待推导的量有标准定义。它提供了所有必要的信息（常微分方程、初始条件、输出定义和参数约束）以找到唯一、稳定且有意义的解。\n-   **客观性：** 语言正式、精确，没有任何主观或基于意见的陈述。\n-   设置是完整和一致的；没有缺失的数据或矛盾的约束。\n-   对于一个简化的生物分子衰变模型，这些条件在物理上是现实的。\n-   该问题需要推导和解释，这是一项实质性的任务，而非微不足道或同义反复的任务。\n\n### 步骤3：结论与行动\n该问题被判定为 **有效**。现在开始求解过程。\n\n第一步是求解输出 $y(t)$。该系统由线性一阶常微分方程 $\\frac{dx}{dt} = -k\\,x(t)$ 描述，初始条件为 $x(0) = x_0$。这是一个可分离变量的方程：\n$$\n\\frac{dx}{x} = -k\\,dt\n$$\n将两边从初始状态 $(0, x_0)$ 积分到一般状态 $(t, x(t))$，得到：\n$$\n\\int_{x_0}^{x(t)} \\frac{1}{\\xi}\\,d\\xi = \\int_{0}^{t} -k\\,d\\tau\n$$\n$$\n[\\ln|\\xi|]_{x_0}^{x(t)} = [-k\\,\\tau]_{0}^{t}\n$$\n鉴于 $x_0  0$ 且在生物物理背景下浓度 $x(t)$ 不能为负，我们可以去掉绝对值符号。\n$$\n\\ln(x(t)) - \\ln(x_0) = -k\\,t\n$$\n$$\n\\ln\\left(\\frac{x(t)}{x_0}\\right) = -k\\,t\n$$\n对两边取指数，得到 $x(t)$ 的解：\n$$\nx(t) = x_0 \\exp(-k\\,t)\n$$\n由于输出定义为 $y(t) = x(t)$，我们有：\n$$\ny(t) = x_0 \\exp(-k\\,t)\n$$\n接下来，我们必须计算输出 $y(t)$ 对参数 $k$ 的偏导数。初始条件 $x_0$ 被视为一个与 $k$ 无关的常数。\n$$\n\\frac{\\partial y(t)}{\\partial k} = \\frac{\\partial}{\\partial k} \\left( x_0 \\exp(-k\\,t) \\right)\n$$\n使用链式法则求导，其中 $\\exp(u)$ 的导数是 $\\exp(u)\\frac{du}{dk}$ 且 $u = -k\\,t$：\n$$\n\\frac{\\partial y(t)}{\\partial k} = x_0 \\exp(-k\\,t) \\cdot \\frac{\\partial}{\\partial k}(-k\\,t) = x_0 \\exp(-k\\,t) \\cdot (-t)\n$$\n$$\n\\frac{\\partial y(t)}{\\partial k} = -x_0\\,t\\,\\exp(-k\\,t)\n$$\n现在，将 $y(t)$ 和 $\\frac{\\partial y(t)}{\\partial k}$ 的表达式代入归一化敏感度函数 $S_{y,k}(t)$ 的定义中：\n$$\nS_{y,k}(t) \\equiv \\frac{k}{y(t)}\\,\\frac{\\partial y(t)}{\\partial k} = \\frac{k}{x_0 \\exp(-k\\,t)} \\left( -x_0\\,t\\,\\exp(-k\\,t) \\right)\n$$\n分子和分母中的 $x_0$ 和 $\\exp(-k\\,t)$ 项相互抵消：\n$$\nS_{y,k}(t) = k \\cdot (-t) = -k\\,t\n$$\n这是敏感度函数的闭式表达式。该表达式是无量纲的，因为 $k$（单位 $\\text{s}^{-1}$）和 $t$（单位 $\\text{s}$）的乘积是无量纲的，这与归一化敏感度的定义一致。\n\n从第一性原理出发的解释：\n敏感度函数 $S_{y,k}(t) = -k\\,t$ 提供了关于系统输出如何响应衰变速率参数 $k$ 的扰动的见解。其性质可以通过其符号和时间依赖性来分析。\n\n1.  **符号：** 对于所有 $t \\ge 0$（因为 $k  0$），敏感度函数 $S_{y,k}(t) \\le 0$。负的敏感度表示参数 $k$ 和输出 $y(t)$ 之间存在反比关系。具体来说，对于任何 $t0$，$k$ 的增加会导致 $y(t)$ 的减少。从生物物理学的角度来看，这是直观上正确的：参数 $k$ 代表衰变速率。一个较大的衰变速率常数意味着该物质的消耗更快，导致在任何给定的时间点 $t  0$，其浓度 $x(t) = y(t)$ 都低于具有较小 $k$ 值的系统。负号正式地捕捉了这种反向行为。\n\n2.  **时间依赖性：** 敏感度的幅度 $|S_{y,k}(t)| = k\\,t$ 随时间线性增加。\n    -   在 $t=0$ 时，$S_{y,k}(0) = 0$。这意味着在初始时刻，输出对 $k$ 的值完全不敏感。这是因为在 $t=0$ 时的输出是由初始条件 $y(0) = x_0$ 固定的，它独立于衰变过程本身，因此也独立于 $k$。\n    -   当 $t$ 从 0 开始增加时，敏感度的幅度无界增长。这种线性增长反映了衰变过程的累积性质。随着时间的推移，衰变速率 $k$ 的微小扰动对浓度 $y(t)$ 的相对影响会逐渐增大。对于较长的时间，系统的状态受衰变过程影响的时间更长，使得最终浓度高度依赖于 $k$ 的精确值。衰变进行得越久，不同 $k$ 值导致的最终结果差异就越显著。这种随时间增加的敏感度是这个简单动力学系统的一个关键特征。\n\n总而言之，推导得出的 $S_{y,k}(t) = -k\\,t$ 正确地捕捉了生物物理现实：更快的衰变速率($k$)导致更低的浓度($y(t)$)，并且这种效应随时间推移变得更加显著。", "answer": "$$\\boxed{-k\\,t}$$", "id": "4385521"}, {"introduction": "局部敏感度分析有其局限性，因为它只评估参数在某个特定点上的影响。本练习将介绍全局敏感度分析（GSA），这是一种更强大的方法，用于理解参数不确定性如何在整个参数空间中影响模型输出。我们将为一个线性模型推导一阶和全阶索伯尔指数（Sobol' indices），从而学习如何将输出方差分配给不同参数，并理解参数间交互作用的核心概念。[@problem_id:4385604]", "problem": "在一个通路控制的生物标志物的线性化系统生物医学模型中，可观测输出 $Y$ 在参考状态附近近似为 $Y=\\sum_{j=1}^{m} a_{j} p_{j}$，其中 $p_{j}$ 是独立的随机参数，代表对数转换后的反应速率常数的零均值波动，而 $a_{j}\\in\\mathbb{R}$ 是固定的局部灵敏度。参数满足 $\\mathbb{E}[p_{j}]=0$ 和 $\\operatorname{Var}(p_{j})=\\sigma_{j}^{2}$，其中所有 $\\sigma_{j}^{2}0$ 均为已知。假设没有测量噪声，并且为了灵敏度量化的目的，线性近似是精确的。\n\n使用随机变量的方差分解基础理论和全局灵敏度分析 (GSA) 的标准定义，即一阶指数 $S_{i}$ 衡量仅由参数 $p_{i}$ 引起的输出方差的比例，而全效应指数 $S_{T_{i}}$ 衡量由 $p_{i}$ 及其所有相互作用引起的输出方差的比例，推导对于一个固定指数 $i\\in\\{1,\\dots,m\\}$ 的 $S_{i}$ 和 $S_{T_{i}}$ 的解析表达式，用 $\\{a_{j}\\}$ 和 $\\{\\sigma_{j}^{2}\\}$ 表示。\n\n您的最终答案必须以闭式解析表达式的形式给出。无需四舍五入。指数是无量纲的；最终答案中不要包含单位。", "solution": "问题经验证是自洽的、有科学依据且定义明确的。我们可以继续推导一阶和全效应灵敏度指数。\n\n可观测输出 $Y$ 由线性模型 $Y=\\sum_{j=1}^{m} a_{j} p_{j}$ 给出，其中 $p_{j}$ 是独立的随机参数，满足 $\\mathbb{E}[p_{j}]=0$ 和 $\\operatorname{Var}(p_{j})=\\sigma_{j}^{2}$。系数 $a_{j}$ 是固定常数。\n\n首先，我们计算输出的总方差 $\\operatorname{Var}(Y)$。这个量作为灵敏度指数的归一化因子。$Y$ 的期望是 $\\mathbb{E}[Y] = \\mathbb{E}\\left[\\sum_{j=1}^{m} a_{j} p_{j}\\right] = \\sum_{j=1}^{m} a_{j} \\mathbb{E}[p_{j}] = \\sum_{j=1}^{m} a_{j} \\cdot 0 = 0$。\n$Y$ 的方差由下式给出：\n$$ \\operatorname{Var}(Y) = \\mathbb{E}[Y^2] - (\\mathbb{E}[Y])^2 = \\mathbb{E}[Y^2] = \\operatorname{Var}\\left(\\sum_{j=1}^{m} a_{j} p_{j}\\right) $$\n由于参数 $p_{j}$ 的独立性，和的方差等于方差的和：\n$$ \\operatorname{Var}(Y) = \\sum_{j=1}^{m} \\operatorname{Var}(a_{j} p_{j}) $$\n使用性质 $\\operatorname{Var}(cX) = c^2 \\operatorname{Var}(X)$，其中 $c$ 是一个常数，我们有：\n$$ \\operatorname{Var}(Y) = \\sum_{j=1}^{m} a_{j}^{2} \\operatorname{Var}(p_{j}) = \\sum_{j=1}^{m} a_{j}^{2} \\sigma_{j}^{2} $$\n由于所有 $\\sigma_{j}^{2}  0$ 且对于一个非平凡模型我们可以假设至少有一个 $a_j \\neq 0$，总方差 $\\operatorname{Var}(Y)  0$。\n\n接下来，我们推导一阶灵敏度指数 $S_{i}$。根据定义，$S_{i}$ 衡量了仅由参数 $p_{i}$ 的方差可以解释的总输出方差的比例。在数学上，它定义为：\n$$ S_{i} = \\frac{\\operatorname{Var}_{p_{i}}(\\mathbb{E}_{p_{\\sim i}}[Y | p_{i}])}{\\operatorname{Var}(Y)} $$\n其中 $p_{\\sim i}$ 表示除 $p_{i}$ 之外的所有参数集合。\n首先，我们计算条件期望 $\\mathbb{E}_{p_{\\sim i}}[Y | p_{i}]$。我们可以将 $Y$ 的表达式中的和拆分：\n$$ Y = a_{i}p_{i} + \\sum_{j \\neq i} a_{j}p_{j} $$\n对所有 $j \\neq i$ 的 $p_j$ 求期望，同时将 $p_i$ 视为常数：\n$$ \\mathbb{E}_{p_{\\sim i}}[Y | p_{i}] = \\mathbb{E}_{p_{\\sim i}}\\left[a_{i}p_{i} + \\sum_{j \\neq i} a_{j}p_{j}\\right] = a_{i}p_{i} + \\sum_{j \\neq i} a_{j}\\mathbb{E}[p_{j}] $$\n由于对所有 $j$ 都有 $\\mathbb{E}[p_{j}]=0$：\n$$ \\mathbb{E}_{p_{\\sim i}}[Y | p_{i}] = a_{i}p_{i} $$\n现在，我们计算这个量关于 $p_{i}$ 的方差：\n$$ \\operatorname{Var}_{p_{i}}(\\mathbb{E}_{p_{\\sim i}}[Y | p_{i}]) = \\operatorname{Var}_{p_{i}}(a_{i}p_{i}) = a_{i}^{2}\\operatorname{Var}(p_{i}) = a_{i}^{2}\\sigma_{i}^{2} $$\n将这个分子和总方差代入 $S_{i}$ 的定义，得到：\n$$ S_{i} = \\frac{a_{i}^{2}\\sigma_{i}^{2}}{\\sum_{j=1}^{m} a_{j}^{2}\\sigma_{j}^{2}} $$\n\n现在，我们推导全效应指数 $S_{T_{i}}$。该指数衡量了 $p_i$ 对输出方差的贡献，包括其主效应以及与其他参数的所有阶数的相互作用。它定义为：\n$$ S_{T_{i}} = \\frac{\\mathbb{E}_{p_{\\sim i}}[\\operatorname{Var}_{p_{i}}(Y | p_{\\sim i})]}{\\operatorname{Var}(Y)} $$\n首先，我们计算内部的条件方差 $\\operatorname{Var}_{p_{i}}(Y | p_{\\sim i})$。当以 $p_{\\sim i}$ 为条件时，所有 $j \\neq i$ 的参数 $p_{j}$ 都被视为固定常数。\n$$ \\operatorname{Var}_{p_{i}}(Y | p_{\\sim i}) = \\operatorname{Var}_{p_{i}}\\left(a_{i}p_{i} + \\sum_{j \\neq i} a_{j}p_{j} \\Bigg| p_{\\sim i}\\right) $$\n使用性质 $\\operatorname{Var}(X+c) = \\operatorname{Var}(X)$，其中项 $\\sum_{j \\neq i} a_{j}p_{j}$ 相相对于变量 $p_{i}$ 是常数：\n$$ \\operatorname{Var}_{p_{i}}(Y | p_{\\sim i}) = \\operatorname{Var}_{p_{i}}(a_{i}p_{i}) = a_{i}^{2}\\operatorname{Var}(p_{i}) = a_{i}^{2}\\sigma_{i}^{2} $$\n接下来，我们对这个结果求关于 $p_{\\sim i}$ 的期望：\n$$ \\mathbb{E}_{p_{\\sim i}}[\\operatorname{Var}_{p_{i}}(Y | p_{\\sim i})] = \\mathbb{E}_{p_{\\sim i}}[a_{i}^{2}\\sigma_{i}^{2}] $$\n因为 $a_{i}^{2}\\sigma_{i}^{2}$ 是一个常数，所以它的期望就是它本身：\n$$ \\mathbb{E}_{p_{\\sim i}}[a_{i}^{2}\\sigma_{i}^{2}] = a_{i}^{2}\\sigma_{i}^{2} $$\n最后，将这个分子和总方差代入 $S_{T_{i}}$ 的定义，得到：\n$$ S_{T_{i}} = \\frac{a_{i}^{2}\\sigma_{i}^{2}}{\\sum_{j=1}^{m} a_{j}^{2}\\sigma_{j}^{2}} $$\n\n结果表明，对于这个特定模型，$S_{i} = S_{T_{i}}$。这是该模型结构的直接结果。该模型是独立输入参数的线性组合。在此类“可加”模型中，参数之间没有相互作用项。全效应指数 $S_{T_{i}}$ 包含了 $p_{i}$ 的主效应以及所有涉及 $p_{i}$ 的相互作用效应。由于所有相互作用方差均为零，因此 $S_{T_{i}}$ 简化为一阶指数 $S_{i}$。一阶指数的和为 $\\sum_{i=1}^{m} S_{i} = \\sum_{i=1}^{m} \\frac{a_{i}^{2}\\sigma_{i}^{2}}{\\sum_{j=1}^{m} a_{j}^{2}\\sigma_{j}^{2}} = 1$，这证实了模型的方差完全由一阶效应的和来解释，这对于可加模型是符合预期的。", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{a_{i}^{2} \\sigma_{i}^{2}}{\\sum_{j=1}^{m} a_{j}^{2} \\sigma_{j}^{2}}  \\frac{a_{i}^{2} \\sigma_{i}^{2}}{\\sum_{j=1}^{m} a_{j}^{2} \\sigma_{j}^{2}} \\end{pmatrix}}\n$$", "id": "4385604"}, {"introduction": "敏感度分析是参数可辨识性分析的基石，后者旨在确定模型参数是否能从实验数据中唯一地估计出来。本练习将理论付诸实践，进入计算领域，通过实现参数剖面（parameter profiling）方法来评估参数的可辨识性。通过系统地探索代价函数的形状，我们可以在一个实际的生物医学二室模型中，直观地评估参数的实际可辨识性，这是一项在现代系统生物学研究中常见的任务。[@problem_id:4385525]", "problem": "给定一个在系统生物医学中常用的参数化动力学系统，用于模拟一个带消除的双室过程。设状态向量为 $x(t) = [x_1(t), x_2(t)]^\\top$，初始条件为 $x_1(0) = D$ 和 $x_2(0) = 0$。输入为弹丸式给药，因此在 $t=0$ 之后没有时变输入。状态动力学遵循线性质量平衡定律：\n$$\n\\frac{dx_1}{dt} = -k_{\\mathrm{el}} x_1 - k_{12} x_1 + k_{21} x_2,\n\\qquad\n\\frac{dx_2}{dt} = k_{12} x_1 - k_{21} x_2,\n$$\n其中参数 $k_{\\mathrm{el}}$、$k_{12}$ 和 $k_{21}$ 均为严格为正的。测量输出由一个线性观测模型给出\n$$\ny(t) = C_1 x_1(t),\n$$\n其中测量标度 $C_1$ 严格为正。令 $\\theta = [k_{\\mathrm{el}}, k_{12}, k_{21}, C_1]^\\top$ 表示完整参数向量。\n\n您将获得由模型在指定的采样时间 $t_j$ 生成的、带有加性噪声的合成数据 $\\{(t_j, y_j)\\}_{j=1}^m$。定义加权最小二乘代价函数\n$$\nJ(\\theta) = \\sum_{j=1}^m \\left( \\frac{y_j - C_1 x_1(t_j;\\, k_{\\mathrm{el}}, k_{12}, k_{21})}{\\sigma} \\right)^2,\n$$\n其中 $\\sigma$ 是一个已知的噪声标度，而 $x_1(t_j;\\, k_{\\mathrm{el}}, k_{12}, k_{21})$ 是通过对动力学系统进行数值积分得到的。\n\n考虑通过对冗余参数 $[k_{12}, k_{21}, C_1]^\\top$ 进行约束优化，来对目标参数 $k_{\\mathrm{el}}$ 进行参数剖面分析。对于一个固定的 $k_{\\mathrm{el}}$ 值，剖面代价定义为\n$$\nJ_{\\mathrm{prof}}(k_{\\mathrm{el}}) = \\min_{k_{12},\\,k_{21},\\,C_1} \\, J\\big([k_{\\mathrm{el}}, k_{12}, k_{21}, C_1]^\\top\\big)\n\\quad\n\\text{subject to}\n\\quad\nk_{12} \\ge 0, \\; k_{21} \\ge 0, \\; C_1 \\ge 0.\n$$\n沿剖面的冗余参数的最小化器由优化器路径表示\n$$\n[k_{12}^\\star(k_{\\mathrm{el}}),\\,k_{21}^\\star(k_{\\mathrm{el}}),\\,C_1^\\star(k_{\\mathrm{el}})]^\\top\n\\quad \\text{such that} \\quad\nJ_{\\mathrm{prof}}(k_{\\mathrm{el}}) = J\\big([k_{\\mathrm{el}}, k_{12}^\\star(k_{\\mathrm{el}}), k_{21}^\\star(k_{\\mathrm{el}}), C_1^\\star(k_{\\mathrm{el}})]^\\top\\big).\n$$\n\n您的任务是实现一个数值程序，该程序能够：\n- 在指定区间上为 $k_{\\mathrm{el}}$ 构建一个值网格。\n- 对每个网格值，求解约束优化问题以计算 $J_{\\mathrm{prof}}(k_{\\mathrm{el}})$，并记录相应的优化器路径 $[k_{12}^\\star(k_{\\mathrm{el}}), k_{21}^\\star(k_{\\mathrm{el}}), C_1^\\star(k_{\\mathrm{el}})]$。\n- 通过将每次优化的初始值设为前一个网格点的优化器结果，使用热启动来平滑地跟踪整个网格上的优化器路径。\n- 选择使剖面 $J_{\\mathrm{prof}}(k_{\\mathrm{el}})$ 最小化的网格值 $k_{\\mathrm{el}}^\\star$。\n\n为以下三个测试用例实现此程序。在每个用例中，通过使用指定的 $\\theta_{\\text{true}}$ 对模型进行积分，并添加均值为零、标准差为 $\\sigma$ 的独立高斯噪声来生成合成数据。为了保证可复现性，请使用固定的随机种子 $42$。所有用例中的剂量均为 $D=1$。\n\n测试用例 1 (理想路径):\n- 真实参数: $\\theta_{\\text{true}} = [0.25, 0.40, 0.20, 1.00]^\\top$。\n- 采样时间: 在 $[0, 10]$ 区间内均匀分布的 $m=21$ 个点。\n- 噪声标度: $\\sigma = 0.02$。\n- 剖面分析网格: $k_{\\mathrm{el}} \\in [0.05, 0.60]$，包含 $21$ 个均匀间隔的点。\n- 冗余参数的界限: $0.01 \\le k_{12} \\le 2.00$, $0.01 \\le k_{21} \\le 2.00$, $0.50 \\le C_1 \\le 1.50$。\n\n测试用例 2 (边界行为):\n- 真实参数: $\\theta_{\\text{true}} = [0.01, 0.30, 0.50, 1.00]^\\top$。\n- 采样时间: 在 $[0, 5]$ 区间内均匀分布的 $m=26$ 个点。\n- 噪声标度: $\\sigma = 0.02$。\n- 剖面分析网格: $k_{\\mathrm{el}} \\in [0.01, 0.20]$，包含 $21$ 个均匀间隔的点。\n- 冗余参数的界限: $0.05 \\le k_{12} \\le 2.00$, $0.05 \\le k_{21} \\le 2.00$, $0.80 \\le C_1 \\le 1.20$。\n\n测试用例 3 (稀疏且含噪数据，潜在的可辨识性问题):\n- 真实参数: $\\theta_{\\text{true}} = [0.50, 0.30, 0.10, 1.00]^\\top$。\n- 采样时间: $t_j = [0, 1, 2, 3, 4]$，因此 $m=5$。\n- 噪声标度: $\\sigma = 0.10$。\n- 剖面分析网格: $k_{\\mathrm{el}} \\in [0.10, 1.00]$，包含 $21$ 个均匀间隔的点。\n- 冗余参数的界限: $0.01 \\le k_{12} \\le 2.00$, $0.01 \\le k_{21} \\le 2.00$, $0.50 \\le C_1 \\le 1.50$。\n\n您的程序必须：\n- 为每个测试用例生成合成数据。\n- 对每个测试用例，使用约束优化和冗余参数的热启动路径跟踪，计算指定网格上的完整剖面 $J_{\\mathrm{prof}}(k_{\\mathrm{el}})$。\n- 对每个测试用例，返回使剖面 $J_{\\mathrm{prof}}(k_{\\mathrm{el}})$ 最小化的网格值 $k_{\\mathrm{el}}^\\star$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，“[result1,result2,result3]”），每个结果是相应测试用例的最小化 $k_{\\mathrm{el}}^\\star$ 值，表示为浮点数。", "solution": "该问题已经过验证并被认为是有效的。这是一个关于系统生物医学中常见房室模型的参数估计和可辨识性分析的、适定的、有科学依据的练习。所有必需的常数、方程和条件均已提供。\n\n问题的核心是为参数 $k_{\\mathrm{el}}$ 执行参数剖面似然分析。这涉及在固定的 $k_{\\mathrm{el}}$ 值下，为冗余参数重复求解一个约束优化问题。\n\n解决方案分为四个主要步骤：\n$1$. 推导常微分方程组 (ODEs) 的解析解，以实现高效计算。\n$2$. 构建数值优化问题，包括目标函数和热启动策略。\n$3$. 按照每个测试用例的规定生成合成数据。\n$4$. 实现完整的剖面分析程序，为每个用例找到最优的 $k_{\\mathrm{el}}^\\star$。\n\n### 1. 动力系统的解析解\n\n状态动力学由一个线性常微分方程组给出：\n$$\n\\frac{d}{dt} \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} = \\begin{pmatrix} -k_{\\mathrm{el}} - k_{12}  k_{21} \\\\ k_{12}  -k_{21} \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}\n$$\n这是 $\\dot{x} = A x$ 的形式，其中 $A$ 是 $2 \\times 2$ 的系统矩阵。解由 $x(t) = e^{At} x(0)$ 给出，其中 $x(0) = [D, 0]^\\top$。一个更直接的方法是使用 $A$ 的特征值和特征向量。特征方程为 $\\lambda^2 - \\mathrm{tr}(A)\\lambda + \\det(A) = 0$。\n\n$A$ 的迹和行列式为：\n$$\n\\mathrm{tr}(A) = -k_{\\mathrm{el}} - k_{12} - k_{21}\n$$\n$$\n\\det(A) = (-k_{\\mathrm{el}} - k_{12})(-k_{21}) - (k_{12})(k_{21}) = k_{\\mathrm{el}}k_{21} + k_{12}k_{21} - k_{12}k_{21} = k_{\\mathrm{el}}k_{21}\n$$\n特征值 $\\lambda_{1,2}$ 是特征多项式的根：\n$$\n\\lambda_{1,2} = \\frac{\\mathrm{tr}(A) \\pm \\sqrt{\\mathrm{tr}(A)^2 - 4\\det(A)}}{2} = \\frac{-(k_{\\mathrm{el}} + k_{12} + k_{21}) \\pm \\sqrt{(k_{\\mathrm{el}} + k_{12} + k_{21})^2 - 4k_{\\mathrm{el}}k_{21}}}{2}\n$$\n由于所有速率参数都严格为正，判别式 $\\Delta = (k_{\\mathrm{el}} + k_{12} + k_{21})^2 - 4k_{\\mathrm{el}}k_{21} = (k_{\\mathrm{el}} + k_{12} - k_{21})^2 + 4k_{12}k_{21}$ 严格为正。因此，特征值 $\\lambda_{1,2}$ 总是实数且不相等。此外，由于 $\\sqrt{\\Delta}  (k_{\\mathrm{el}} + k_{12} + k_{21})$，两个特征值都严格为负，对应一个稳定的系统。\n\n$x_1(t)$ 的通解是两个指数项之和，$x_1(t) = A_1 e^{\\lambda_1 t} + A_2 e^{\\lambda_2 t}$。通过应用初始条件 $x_1(0)=D$ 和 $x_2(0)=0$（这意味着 $\\dot{x_1}(0) = -D(k_{\\mathrm{el}}+k_{12})$），我们可以求解这些系数。一种更系统化的方法是使用特征向量来得到完整解。可以证明，第一个房室的解 $x_1(t)$ 为：\n$$\nx_1(t; k_{\\mathrm{el}}, k_{12}, k_{21}) = \\frac{D}{\\lambda_1 - \\lambda_2} \\left[ (k_{21} + \\lambda_1) e^{\\lambda_1 t} - (k_{21} + \\lambda_2) e^{\\lambda_2 t} \\right]\n$$\n观测输出则为 $y(t) = C_1 x_1(t)$。在优化循环中使用此解析公式可以避免数值积分，从而显著提高计算效率和准确性。\n\n### 2. 数值优化与剖面分析\n\n对于指定网格中一个固定的 $k_{\\mathrm{el}}$ 值，我们必须找到最小化代价函数 $J$ 的冗余参数 $\\psi = [k_{12}, k_{21}, C_1]^\\top$。代价函数为：\n$$\nJ(k_{\\mathrm{el}}, \\psi) = \\sum_{j=1}^m \\left( \\frac{y_j - y(t_j; k_{\\mathrm{el}}, \\psi)}{\\sigma} \\right)^2\n$$\n其中 $y(t_j; k_{\\mathrm{el}}, \\psi)$ 是模型预测值 $C_1 x_1(t_j; k_{\\mathrm{el}}, k_{12}, k_{21})$，而 $(t_j, y_j)$ 是合成数据点。\n\n这是一个约束非线性最小二乘问题。我们寻求：\n$$\n\\psi^\\star(k_{\\mathrm{el}}) = \\arg\\min_{\\psi} J(k_{\\mathrm{el}}, \\psi) \\quad \\text{subject to} \\quad \\psi_{lb} \\le \\psi \\le \\psi_{ub}\n$$\n其中 $\\psi_{lb}$ 和 $\\psi_{ub}$ 是每个测试用例中给出的冗余参数的下界和上界。\n\n对 $k_{\\mathrm{el}}$ 网格中的每个值都执行此优化。`scipy.optimize.minimize` 中可用的 `L-BFGS-B` 算法是一种拟牛顿法，它能有效处理箱型约束，非常适合此任务。\n\n该程序的一个关键部分是热启动策略。对于网格中的第一个 $k_{\\mathrm{el}}$ 值，优化使用一个中性初始值进行初始化，例如 $\\psi$ 允许范围的中点。对于后续的每个 $k_{\\mathrm{el}}$ 值，优化使用为前一个 $k_{\\mathrm{el}}$ 值找到的最优 $\\psi^\\star$ 进行初始化。这种路径跟踪方法提高了收敛速度，并帮助优化器沿着局部最小值的连续路径行进，这正是构建参数剖面的本质。\n\n剖面代价是所获得的最小代价值的集合，$J_{\\mathrm{prof}}(k_{\\mathrm{el}}) = J(k_{\\mathrm{el}}, \\psi^\\star(k_{\\mathrm{el}}))$。最后一步是找到与 $J_{\\mathrm{prof}}(k_{\\mathrm{el}})$ 的最小值相对应的网格值 $k_{\\mathrm{el}}^\\star$。\n\n### 3. 合成数据生成\n\n对于每个测试用例，合成数据按如下方式生成：\n1. 使用提供的`真`参数 $\\theta_{\\text{true}} = [k_{\\mathrm{el,true}}, k_{12,\\text{true}}, k_{21,\\text{true}}, C_{1,\\text{true}}]^\\top$ 求解模型，以获得无噪声输出 $y_{\\text{true}}(t_j) = C_{1,\\text{true}} x_1(t_j; \\theta_{\\text{true}})$。\n2. 将独立同分布的高斯噪声 $\\epsilon_j \\sim \\mathcal{N}(0, \\sigma^2)$ 添加到真实输出中。含噪数据为 $y_j = y_{\\text{true}}(t_j) + \\epsilon_j$。\n3. 为确保可复现性，使用固定值 $42$ 为随机数生成器设置种子。\n\n### 4. 实现摘要\n\n整个算法在一个 Python 脚本中实现。\n- 一个主函数 `solve` 遍历三个测试用例。\n- 对于每个用例，使用种子为 $42$ 的 `numpy.random.Generator` 生成含噪数据。\n- 一个辅助函数 `solve_analytical` 实现 $x_1(t)$ 的解析解并返回模型输出 $y(t)$。\n- 创建一个工厂函数 `make_cost_function` 来封装固定的数据、$k_{\\mathrm{el}}$ 值和其他常数，返回一个仅以冗余参数 $\\psi$ 为变量的代价函数。\n- 一个循环遍历 $k_{\\mathrm{el}}$ 网格。在循环内部，使用 `L-BFGS-B` 方法、适当的边界和热启动初始猜测值来调用 `scipy.optimize.minimize`。\n- 剖面分析循环的结果（最小代价）被存储起来。\n- 使用 `numpy.argmin` 找到最小剖面代价的索引，从而确定最优网格点 $k_{\\mathrm{el}}^\\star$。\n- 将三个用例得到的 $k_{\\mathrm{el}}^\\star$ 收集起来，并以指定格式打印。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Main function to run the parameter profiling for all test cases.\n    \"\"\"\n    \n    def solve_analytical(params, times, D):\n        \"\"\"\n        Calculates the model output using the analytical solution of the ODE.\n        \n        Args:\n            params (list or np.ndarray): vector of parameters [kel, k12, k21, C1].\n            times (np.ndarray): time points for evaluation.\n            D (float): initial dose in compartment 1.\n            \n        Returns:\n            np.ndarray: The predicted model output y(t).\n        \"\"\"\n        kel, k12, k21, C1 = params\n        \n        # Eigenvalue calculation\n        trace = -(kel + k12 + k21)\n        det = kel * k21\n        \n        # The discriminant is (kel + k12 - k21)^2 + 4*k12*k21, which is always > 0\n        # for strictly positive parameters, so eigenvalues are real and distinct.\n        sqrt_delta = np.sqrt(trace**2 - 4 * det)\n        \n        lambda1 = (trace + sqrt_delta) / 2.0\n        lambda2 = (trace - sqrt_delta) / 2.0\n        \n        if np.isclose(lambda1, lambda2):\n            # This case is theoretically not reached with positive params,\n            # but is a safeguard for numerical stability.\n            return np.full_like(times, np.inf)\n\n        # Coefficients from initial conditions x1(0)=D, x2(0)=0\n        # x1(t) = D/(l1-l2) * [ (k21+l1)exp(l1*t) - (k21+l2)exp(l2*t) ]\n        factor = D / (lambda1 - lambda2)\n        term1 = (k21 + lambda1) * np.exp(lambda1 * times)\n        term2 = (k21 + lambda2) * np.exp(lambda2 * times)\n        \n        x1_t = factor * (term1 - term2)\n        \n        return C1 * x1_t\n\n    def make_cost_function(fixed_kel, data_t, data_y, sigma, D):\n        \"\"\"\n        Factory function to create the cost function for a fixed kel.\n        The returned function takes only the nuisance parameters as input.\n        \"\"\"\n        def cost_function(nuisance_params):\n            k12, k21, C1 = nuisance_params\n            full_params = [fixed_kel, k12, k21, C1]\n            \n            y_model = solve_analytical(full_params, data_t, D)\n            \n            residuals = (data_y - y_model) / sigma\n            return np.sum(residuals**2)\n            \n        return cost_function\n\n    test_cases = [\n        {\n            \"theta_true\": [0.25, 0.40, 0.20, 1.00],\n            \"times\": np.linspace(0, 10, 21),\n            \"sigma\": 0.02,\n            \"kel_grid\": np.linspace(0.05, 0.60, 21),\n            \"bounds\": [(0.01, 2.00), (0.01, 2.00), (0.50, 1.50)],\n        },\n        {\n            \"theta_true\": [0.01, 0.30, 0.50, 1.00],\n            \"times\": np.linspace(0, 5, 26),\n            \"sigma\": 0.02,\n            \"kel_grid\": np.linspace(0.01, 0.20, 21),\n            \"bounds\": [(0.05, 2.00), (0.05, 2.00), (0.80, 1.20)],\n        },\n        {\n            \"theta_true\": [0.50, 0.30, 0.10, 1.00],\n            \"times\": np.array([0., 1., 2., 3., 4.]),\n            \"sigma\": 0.10,\n            \"kel_grid\": np.linspace(0.10, 1.00, 21),\n            \"bounds\": [(0.01, 2.00), (0.01, 2.00), (0.50, 1.50)],\n        }\n    ]\n\n    results = []\n    D_dose = 1.0  # Dose is 1 for all cases\n    \n    # Use a single RNG for all cases for consistency\n    rng = np.random.default_rng(42)\n\n    for case in test_cases:\n        # 1. Generate synthetic data\n        y_true = solve_analytical(case[\"theta_true\"], case[\"times\"], D_dose)\n        noise = rng.normal(loc=0.0, scale=case[\"sigma\"], size=len(case[\"times\"]))\n        y_data = y_true + noise\n\n        profile_costs = []\n        \n        # Warm-start initialization\n        # For the first point, use the midpoint of the bounds.\n        initial_guess = np.array([(b[0] + b[1]) / 2 for b in case[\"bounds\"]])\n        last_optimal_nuisance = initial_guess\n\n        # 2. Compute profile likelihood\n        for kel_val in case[\"kel_grid\"]:\n            # Create the cost function for the current k_el\n            cost_func = make_cost_function(kel_val, case[\"times\"], y_data, case[\"sigma\"], D_dose)\n            \n            # Solve the constrained optimization problem for nuisance parameters\n            res = minimize(\n                fun=cost_func,\n                x0=last_optimal_nuisance,\n                method='L-BFGS-B',\n                bounds=case[\"bounds\"],\n                options={'ftol': 1e-9, 'gtol': 1e-7} # Tighter tolerances for accuracy\n            )\n            \n            profile_costs.append(res.fun)\n            \n            # Update the guess for the next iteration (warm-start)\n            last_optimal_nuisance = res.x\n            \n        # 3. Find k_el that minimizes the profile\n        min_cost_idx = np.argmin(profile_costs)\n        best_kel = case[\"kel_grid\"][min_cost_idx]\n        results.append(best_kel)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "4385525"}]}