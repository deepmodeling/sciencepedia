## 引言
[深度学习](@entry_id:142022)正在系统生物医学领域掀起一场革命，它为分析前所未有的高维复杂生物数据提供了强大的工具。然而，将这些先进算法成功应用于解决实际生物医学问题，远非简单的“即插即用”。这项挑战要求我们不仅要掌握算法本身，更需要深刻理解生物系统的内在复杂性、数据的特有属性以及支撑所有模型的统计学和因果推断原理。本文旨在弥合[深度学习](@entry_id:142022)技术与系统生物医学应用之间的知识鸿沟。

为此，我们将通过三个章节系统地展开讨论。在第一章“原理与机制”中，我们将奠定理论基石，深入探讨核心建模范式、关键统计挑战以及针对不同生物数据模态的[深度学习架构](@entry_id:634549)。随后，在第二章“应用与交叉学科连接”中，我们将展示这些原理如何在从分子到临床的多个尺度上解决实际问题，彰显其跨学科的整合能力。最后，在第三章“动手实践”中，读者将有机会通过具体练习来巩固所学知识。

本文将带领读者踏上一段从理论基础到前沿应用的探索之旅，揭示[深度学习](@entry_id:142022)如何成为理解、模拟和干预复杂生命系统的下一代科学范式。让我们首先从构建这一切所必需的核心原理与机制开始。

## 原理与机制

在系统生物医学中，深度学习的应用并非简单地将现有算法应用于新数据集。相反，它要求我们深刻理解生物系统的内在复杂性、数据的生成过程以及支撑任何学习任务的统计学和因果推断基本原理。本章旨在阐述将[深度学习](@entry_id:142022)应用于系统生物医学时所需的核心原理和关键机制。我们将从高层次的建模范式对比出发，深入探讨从不[完美数](@entry_id:636981)据中学习的根本挑战，介绍为关键生物医学数据类型设计的特定架构，并以前沿主题作为结尾，包括生成式建模、因果推断和不确定性量化。

### 系统生物医学中的建模范式：机理驱动与数据驱动

在系统生物医学领域，旨在理解和预测[复杂疾病](@entry_id:261077)表型的计算模型大体上可分为两大范式：机理驱动模型（model-based）和数据驱动模型（data-driven）。

机理驱动模型，通常以[常微分方程](@entry_id:147024)（Ordinary Differential Equations, ODEs）或[偏微分](@entry_id:194612)方程（Partial Differential Equations, PDEs）的形式出现，旨在封装我们对[生物过程](@entry_id:164026)的先验知识。例如，一个控制[细胞因子](@entry_id:204039)释放的基因-蛋白质-代谢物网络可以通过一组ODE来描述，其形式为 $\frac{d\mathbf{x}}{dt} = S \cdot v(\mathbf{x}, \boldsymbol{\theta})$。在这里，$\mathbf{x}$ 代表网络中各物种（如蛋白质、代谢物）的浓度或活性，化学计量矩阵 $S$ 编码了网络的拓扑结构（即哪些物种参与了哪些反应），而[反应速率](@entry_id:185114)向量 $v(\mathbf{x}, \boldsymbol{\theta})$ 则根据生物化学和物理学原理（如米氏动力学）定义了[反应速率](@entry_id:185114)如何依赖于[物种浓度](@entry_id:197022)和一组动力学参数 $\boldsymbol{\theta}$（如[反应速率常数](@entry_id:187887)、结合亲和力）。这种方法的本质是**理论驱动**的：模型的结构是基于已知的生物学机制预先设定的。实验数据的作用是[校准模型](@entry_id:180554)，即推断未知参数 $\boldsymbol{\theta}$ 的值，例如通过贝叶斯方法估计其后验分布 $p(\boldsymbol{\theta} \mid D)$。这类模型的主要优势在于其**可解释性**，因为模型中的每个参数和变量都对应着一个可测量的物理量。此外，由于它们编码了因果机制，因此非常适合进行**外推**（extrapolation）和评估“反事实”情景（causal counterfactuals），例如预测基因敲除或药物干预（通过改变某个特定参数）的效果。

相对地，数据驱动模型，特别是**[深度神经网络](@entry_id:636170)**（Deep Neural Networks, DNNs），采取了截然不同的策略。一个典型的DNN，表示为 $g_{\boldsymbol{\phi}}$，被训练来学习从一组测量特征 $\mathbf{z}$（例如，来自多组学谱的测量值）到某个表型 $y$（例如，[细胞因子](@entry_id:204039)释放速率）的映射关系。其参数 $\boldsymbol{\phi}$（即网络的权重和偏置）通过在现有数据集上最小化预测误差来优化。这类模型是强大的**[通用函数逼近器](@entry_id:637737)**，擅长在与训练数据分布相似的数据上进行**内插**（interpolation）。然而，它们的“黑箱”特性使得直接的生物学解释变得困难，因为参数 $\boldsymbol{\phi}$ 通常不具备明确的生物学意义。更重要的是，由于它们主要学习输入和输出之间的相关性而非因果关系，因此在没有结构性先验知识约束的情况下，它们在外推到分布外（out-of-distribution）数据时的表现通常是不可靠的，并且不能直接用于评估因果反事实。[@problem_id:4332661]

理解这两种范式的区别对于在特定生物医学问题中选择合适的建模策略至关重要。机理模型利用深厚的领域知识，在数据稀疏时依然能提供洞见；而[深度学习模型](@entry_id:635298)则能在数据充足时，从高维复杂数据中发现新颖的、非线性的模式。一个令人兴奋的前沿方向是将这两者结合起来，创建**[混合模型](@entry_id:266571)**，我们将在后续章节中探讨（例如，[物理信息神经网络](@entry_id:145229)）。

### 从生物医学数据中学习：核心挑战与原则

无论采用何种建模范式，从真实世界的生物医学数据中学习都面临着一系列共同的挑战。有效的模型构建必须基于对[统计学习理论](@entry_id:274291)基本原则的深刻理解。

#### 泛化的目标：[经验风险](@entry_id:633993)与[期望风险](@entry_id:634700)

监督学习的最终目标是**泛化**（generalization）：从训练数据中学习一个函数 $h$，使其在来自相同数据生成分布 $\mathcal{D}$ 的未见新样本上表现良好。模型的真实性能由**[期望风险](@entry_id:634700)**（expected risk）$R(h) = \mathbb{E}_{(x,y) \sim \mathcal{D}}[\ell(h(x), y)]$ 来衡量，其中 $\ell$ 是一个[损失函数](@entry_id:136784)（例如，对于[分类任务](@entry_id:635433)，可以是[0-1损失](@entry_id:173640)）。由于我们无法直接计算[期望风险](@entry_id:634700)，实践中我们转而最小化在[训练集](@entry_id:636396)上的**[经验风险](@entry_id:633993)**（empirical risk）$\hat{R}_n(h) = \frac{1}{n} \sum_{i=1}^n \ell(h(x_i), y_i)$。

#### 控制复杂性：[经验风险最小化](@entry_id:633880)与[结构风险最小化](@entry_id:637483)

单纯地最小化[经验风险](@entry_id:633993)，即**[经验风险最小化](@entry_id:633880)**（Empirical Risk Minimization, ERM）原则，可能会导致**[过拟合](@entry_id:139093)**（overfitting）。当模型或假设类别（hypothesis class）$\mathcal{H}$ 的容量（capacity）过高时，模型可能会“记住”训练数据中的噪声和特异性，而不是学习到底层的真实规律，从而导致[期望风险](@entry_id:634700)很高。例如，在两个嵌套的假设类别 $\mathcal{H}_{\text{small}} \subset \mathcal{H}_{\text{large}}$（例如，浅层网络 vs. 深层网络）中，ERM原则会倾向于选择容量更大、能够达到更低[经验风险](@entry_id:633993)的 $\mathcal{H}_{\text{large}}$。

**[结构风险最小化](@entry_id:637483)**（Structural Risk Minimization, SRM）原则通过在[经验风险](@entry_id:633993)和模型复杂度之间进行权衡，为解决这一问题提供了理论框架。它旨在最小化[期望风险](@entry_id:634700)的一个概率[上界](@entry_id:274738)，该上界通常形如：
$R(h) \le \hat{R}_n(h) + \text{Complexity}(\mathcal{H}, n, \delta)$
其中，复杂度项 $\text{Complexity}(\mathcal{H}, n, \delta)$ 依赖于假设类别 $\mathcal{H}$ 的容量、样本量 $n$ 和[置信度](@entry_id:267904)参数 $\delta$。一个常用的容量度量是**Rademacher复杂度** $\mathfrak{R}_n(\mathcal{H})$。SRM原则会选择能够最小化这个上界的假设类别。

考虑一个临床预测任务，我们有两个模型类别，$\mathcal{H}_{\text{small}}$ 和 $\mathcal{H}_{\text{large}}$。假设 $\mathcal{H}_{\text{large}}$ 在[训练集](@entry_id:636396)上表现更好（例如，$\hat{R}_n(\mathcal{H}_{\text{large}}) = 0.14 \lt \hat{R}_n(\mathcal{H}_{\text{small}}) = 0.18$），但其复杂度也更高（例如，$\mathfrak{R}_n(\mathcal{H}_{\text{large}}) = 0.08 \gt \mathfrak{R}_n(\mathcal{H}_{\text{small}}) = 0.02$）。ERM会选择 $\mathcal{H}_{\text{large}}$。然而，SRM会比较它们的风险[上界](@entry_id:274738)，例如 $\hat{R}_n + 2\mathfrak{R}_n$。对于 $\mathcal{H}_{\text{small}}$，[上界](@entry_id:274738)为 $0.18 + 2(0.02) = 0.22$；对于 $\mathcal{H}_{\text{large}}$，上界为 $0.14 + 2(0.08) = 0.30$。由于 $0.22 \lt 0.30$，SRM原则会选择 $\mathcal{H}_{\text{small}}$，因为它提供了一个更优的泛化保证，尽管其在训练集上的拟合稍差。这个例子阐明了在模型选择中显式控制复杂性的重要性。[@problem_id:4332678]

#### [缺失数据](@entry_id:271026)的挑战：机制与影响

生物医学数据集，特别是来自电子健康记录（EHR）和多组学实验的数据，几乎总是存在**缺失值**。正确处理缺失数据要求我们首先理解其产生的机制。令 $(X, Y)$ 为完整数据， $R$ 为一个指示相应数据是否缺失的二元向量。缺失机制由[条件概率](@entry_id:151013) $p(R \mid X, Y, \psi)$ 描述。主要有三种机制：

1.  **[完全随机缺失](@entry_id:170286)**（Missing Completely At Random, **MCAR**）：缺失的概率与任何数据（无论是观测到的还是未观测到的）都无关，即 $p(R \mid X, Y) = p(R)$。在这种理想情况下，观测到的数据是完整数据的随机子样本，因此基于完整案例的分析（complete-case analysis）可以得到无偏的总体[参数估计](@entry_id:139349)。

2.  **[随机缺失](@entry_id:168632)**（Missing At Random, **MAR**）：缺失的概率只依赖于观测到的数据，而与未观测到的数据本身无关。形式上，$p(R \mid X, Y) = p(R \mid X_{\text{obs}}, Y_{\text{obs}})$。例如，在临床试验中，较健康的患者可能更倾向于跳过某次随访，这里的“健康”是可以通过已有的临床指标来衡量的。在MAR和参数可区分性的假设下，缺失机制对于基于似然的推断是**可忽略的**（ignorable）。这意味着我们可以通过最大化观测数据的[似然函数](@entry_id:141927)来获得对模型参数 $\theta$ 的一致估计，而无需对缺失机制的参数 $\psi$ 进行建模。实际操作中，可以通过[期望最大化算法](@entry_id:165054)（EM）、[多重插补](@entry_id:177416)（multiple imputation）或逆概率加权（inverse-probability weighting）等方法获得[无偏估计](@entry_id:756289)。

3.  **[非随机缺失](@entry_id:163489)**（Missing Not At Random, **MNAR**）：缺失的概率依赖于未观测到的数据本身。例如，如果一个血压测量值因为过高而被记录为缺失，那么缺失本身就提供了关于该值的信息。在这种情况下，$p(R \mid X, Y)$ 无法简化，缺失机制是不可忽略的。此时，完整案例分析或简单的插补方法通常会引入偏差。一致的估计通常需要对数据和缺失机制进行联合建模，例如通过选择模型（selection models）或[模式混合](@entry_id:197206)模型（pattern-mixture models）。[@problem_id:4332669]

在应用深度学习模型时，对缺失机制的正确判断至关重要，因为它决定了哪种处理策略（如简单插补、将缺失指示作为特征、或更复杂的[生成模型](@entry_id:177561)）是有效的。

#### [分布偏移](@entry_id:638064)的挑战：诊断与分类

深度学习模型在部署于真实世界（如另一家医院）时，常常面临**[领域偏移](@entry_id:637840)**（domain shift）或**[分布偏移](@entry_id:638064)**（distributional shift）的挑战，即测试数据的分布 $p_{\text{test}}(x,y)$ 与训练数据的分布 $p_{\text{train}}(x,y)$ 不同。这种偏移会严重影响模型的性能。理解并诊断偏移的类型对于采取正确的适应策略至关重要。

两种主要的偏移类型是：

1.  **[协变量偏移](@entry_id:636196)**（Covariate Shift）：特征的[边际分布](@entry_id:264862)发生变化，但标签对特征的条件分布保持不变。即 $p_{\text{train}}(x) \neq p_{\text{test}}(x)$，而 $p(y \mid x)$ 保持不变。例如，由于使用了不同的成像扫描仪，目标医院的组织病理学图像的亮度和对比度分布可能与源医院不同，但定义特定癌症阶段的细胞学特征保持不变。
    *   **诊断**：可以通过对源域和目标[域的特征](@entry_id:154386) $x$ 进行双样本检验来诊断[协变量偏移](@entry_id:636196)。方法包括计算**[最大均值差异](@entry_id:636886)**（Maximum Mean Discrepancy, MMD），或训练一个**分类器双样本检验**（Classifier Two-Sample Test, C2ST）。在C2ST中，我们训练一个分类器来区分源域和目标域的样本；如果该分类器的[AUROC](@entry_id:636693)显著高于0.5，则表明两个分布是可区分的，即存在[协变量偏移](@entry_id:636196)。

2.  **标签偏移**（Label Shift）：标签的[边际分布](@entry_id:264862)发生变化，但特征对标签的[条件分布](@entry_id:138367)保持不变。即 $p_{\text{train}}(y) \neq p_{\text{test}}(y)$，而 $p(x \mid y)$ 保持不变。例如，目标医院收治的患者群体中，不同癌症阶段的患病率与源医院不同，但每个阶段的病理图像形态是相似的。
    *   **诊断**：在只有未标记的目标数据的情况下，诊断标签偏移更具挑战性。一种有效的方法是**黑盒偏移检测**（Black Box Shift Detection, BBSD）。该方法利用一个在源域上训练好的、可输出校准概率 $\hat{p}_{\theta}(y \mid x)$ 的模型。基本思想是，目标域上的平均预测 $\mathbb{E}_{x \sim p_{\text{test}}(x)}[\hat{p}_{\theta}(y \mid x)]$ 与目标域的真实标签分布 $\vec{p}_{\text{test}}(y)$ 之间存在线性关系，该关系由源域上的[混淆矩阵](@entry_id:635058)所决定。通过求解这个[线性系统](@entry_id:163135)，可以估计出 $\vec{p}_{\text{test}}(y)$，然后通过统计检验（如卡方检验）将其与已知的源域标签分布 $\vec{p}_{\text{train}}(y)$ 进行比较。[@problem_id:4332682]

### 关键生物医学数据模态的架构

系统生物医学涉及多种[异构数据](@entry_id:265660)类型。深度学习的威力部分来自于其灵活的架构，可以被定制以适应特定数据的结构和挑战。

#### 整合[多组学](@entry_id:148370)数据

现代生物医学研究通常会从同一组样本中测量多个维度的生物信息，即**[多组学](@entry_id:148370)**（multi-omics）数据。这些数据层次反映了分子生物学的**中心法则**：从作为遗传蓝图的基因组（DNA），到转录表达的转录组（RNA），再到执行功能的蛋白质组（蛋白质），以及反映细胞状态的[代谢组](@entry_id:150409)（小分子代谢物）。此外，[表观基因组](@entry_id:272005)则通过对DNA和染色质的修饰来[调控基因](@entry_id:199295)表达。

整合这些[异构数据](@entry_id:265660)以预测临床表型是一个核心挑战。两种主要的整合策略是：

1.  **早期整合**（Early Integration），或称**特征级融合**（feature-level fusion）：在这种策略中，来自不同组学视图的特征在输入层面就被结合起来，例如通过简单的拼接（concatenation）形成一个大的联合特征向量。然后，一个单一的预测模型被训练在这个联合表示上。这种方法的优点是模型可以直接学习跨组学视图的复杂、非线性相互作用。然而，它要求仔细处理来自不同技术平台的特征（其尺度和分布可能迥异），通常需要进行标准化以避免某些组学视图因数值范围较大而主导模型。

2.  **晚期整合**（Late Integration），或称**决策级融合**（decision-level integration）：这种策略为每个组学视图训练一个独立的预测模型。然后，这些模型各自的输出（例如，预测概率或风险评分）被一个**[元学习器](@entry_id:637377)**（meta-learner）结合起来，以产生最终的预测。这种方法的优势在于其模块化和鲁棒性。每个基础模型可以独立处理其特定模态的特征和尺度，降低了特征协调的需求。此外，当某个受试者的某个组学数据完全缺失时，系统仍然可以利用其余可用的视图进行预测，而早期整合则需要进行显式的[数据插补](@entry_id:272357)。[@problem_id:4332646]

#### 分析生物医学图像

数字病理学和显微镜图像分析是深度学习在生物医学中取得巨大成功的领域之一。一个核心任务是**生物[图像分割](@entry_id:263141)**（bioimage segmentation），即为图像中的每个像素或体素分配一个标签。这可以进一步细分为两种主要类型：

1.  **[语义分割](@entry_id:637957)**（Semantic Segmentation）：其目标是为每个像素分配一个预定义的**类别**标签。例如，在一张组织病理学图像中，将每个像素分类为“肿瘤”、“基质”或“淋巴细胞”。其输出是一个与原始图像大小相同的类别图。

2.  **[实例分割](@entry_id:634371)**（Instance Segmentation）：这是一个更具挑战性的任务，它不仅要识别每个像素的类别，还要区分出属于同一类别的不同**对象实例**。例如，在一张包含两个相互接触的肿瘤细胞核的图像中，[实例分割](@entry_id:634371)的目标是为这两个细胞核生成两个独立的掩码（mask），即使它们都属于“肿瘤细胞核”这一类别。

[语义分割](@entry_id:637957)和[实例分割](@entry_id:634371)之间的区别至关重要。一个仅在像素级别上训练的[语义分割](@entry_id:637957)模型（例如，使用逐像素[交叉熵损失](@entry_id:141524)）无法保证分离相互接触的同类实例。即使该模型能够以100%的像素级准确率将所有肿瘤细胞核像素正确分类，它也可能会将两个接触的细胞核预测为一个大的连通区域。在这种情况下，虽然像素级评估指标很高，但面向实例的评估指标（如**全景质量**（Panoptic Quality, PQ）或**聚合杰卡德指数**（Aggregated Jaccard Index, AJI））会因为预测的实例数量（1）与真实的实例数量（2）不匹配而给出较低的分数。为了实现[实例分割](@entry_id:634371)，需要专门的架构（如[Mask R-CNN](@entry_id:635487)）或[损失函数](@entry_id:136784)（如边界预测损失或[度量学习](@entry_id:636905)损失），它们能够显式地学习区分不同实例。

从形式上看，[实例分割](@entry_id:634371)可以被精确地描述为一对映射：一个实例图 $i: \Omega \to \mathbb{N}$，它为每个像素 $x$ 分配一个唯一的实例ID；以及一个类别图 $c: \mathbb{N} \to \mathcal{C}$，它为每个实例ID分配一个类别标签。任何像素的类别都可以通过组合这两个映射 $c \circ i$ 得到，这恰好就是[语义分割](@entry_id:637957)图。[@problem_id:4332648]

#### 建模纵向临床数据

电子健康记录（EHR）提供了关于患者健康状况随时间变化的宝贵纵向数据。然而，这些数据通常是**不规则采样**的：观测（如生命体征、实验室检查）在非均匀的时间间隔发生，且不同变量的记录时间也不同。对这种[时间序列数据](@entry_id:262935)进行建模，需要能够妥善处理连续时间动态和可变时间间隔的架构。

1.  **离散时间循环模型**（Discrete-time Recurrent Models）：标准的**[循环神经网络](@entry_id:171248)**（Recurrent Neural Networks, RNNs）及其变体（如[LSTM](@entry_id:635790)和GRU）是为序列数据设计的。然而，它们的[循环结构](@entry_id:147026)是基于事件索引 $i$ 而非实际时间 $t$。如果不做修改，RNN会同等对待一个1小时的间隔和一个1周的间隔。为了处理不规则时间间隔 $\Delta t_i = t_{i+1} - t_i$，必须将时间信息显式地编码到模型中，例如，将 $\Delta t_i$ 作为循环单元的一个输入，或用它来[参数化](@entry_id:265163)状态衰减。在这种设置下，潜在状态 $\mathbf{h}$ 在两次观测之间是分段常数，仅在观测事件发生时更新。

2.  **连续时间动态模型**（Continuous-time Dynamic Models）：**神经普通[微分](@entry_id:158422)方程**（Neural Ordinary Differential Equations, Neural ODEs）模型提供了一种更自然的方式来处理连续时间动态。它假设存在一个连续的潜在状态轨迹 $\mathbf{h}(t)$，其演化由一个由神经网络 $f_{\theta}$ [参数化](@entry_id:265163)的ODE所控制：$\frac{d\mathbf{h}}{dt} = f_{\theta}(\mathbf{h}(t), t)$。给定在时间 $t_i$ 的状态 $\mathbf{h}(t_i)$，可以通过求解这个ODE（即积分）来获得在任意后续时间 $t_{i+1}$ 的状态：$\mathbf{h}(t_{i+1}) = \mathbf{h}(t_i) + \int_{t_i}^{t_{i+1}} f_{\theta}(\mathbf{h}(t), t) dt$。时间间隔 $\Delta t_i$ 的影响通过积分的范围自然地被包含了进来。在观测事件 $t_i$ 发生时，新的信息可以通过对潜在状态进行瞬时“跳跃”更新来融入。从某种意义上说，一个将时间步长 $\Delta t_i$ 显式纳入其更新规则的RNN（例如，[欧拉积分](@entry_id:271845)格式 $\mathbf{h}_{i+1} \approx \mathbf{h}_i + \Delta t_i \cdot g_{\theta}(\mathbf{h}_i)$）可以被看作是某个Neural ODE的离散近似。[@problem_id:4332687]

### 前沿主题：生成、因果与不确定性

随着基础架构的成熟，[深度学习](@entry_id:142022)在系统生物医学中的应用正转向更具挑战性和影响力的前沿领域：从发现模式到创造新设计，从预测关联到推断因果，以及从提供单一预测到量化可信度。

#### 用于设计的生成式建模

**生成式建模**的目标是学习一个数据分布 $p(x)$，然后从该分布中生成新的、与真实数据相似的样本。在系统生物医学中，一个令人振奋的应用是**分子和蛋白质的[从头设计](@entry_id:170778)**（de novo design），即生成具有特定结构或功能属性（例如，能结合特定靶点）的新型分子或蛋白质骨架。三种主要的[深度生成模型](@entry_id:748264)家族各有其独特的原理和训练目标：

1.  **[变分自编码器](@entry_id:177996)**（Variational Autoencoders, **VAEs**）：VAEs是基于[潜变量模型](@entry_id:174856)的显式[概率模型](@entry_id:265150)。它假设数据 $x$ 是由一个低维[潜变量](@entry_id:143771) $z$ 生成的。由于直接最大化数据的[边际似然](@entry_id:636856)函数 $\log p_{\theta}(x)$ 是难以计算的，VAEs通过引入一个编码器 $q_{\phi}(z \mid x)$ 来逼近真实的后验分布，并最大化**[证据下界](@entry_id:634110)**（Evidence Lower Bound, ELBO）。这个目标函数可以分解为两项：一项是**[重构损失](@entry_id:636740)**，鼓励解码器 $p_{\theta}(x \mid z)$ 能够从[潜变量](@entry_id:143771)中恢复原始数据；另一项是**KL散度正则项**，它约束近似后验 $q_{\phi}(z \mid x)$ 接近于[先验分布](@entry_id:141376) $p(z)$。

2.  **[生成对抗网络](@entry_id:634268)**（Generative Adversarial Networks, **GANs**）：GANs通过一个**二人[零和博弈](@entry_id:262375)**来学习数据分布。**生成器** $G_{\theta}(z)$ 试图将来自简单[先验分布](@entry_id:141376)的随机噪声 $z$ 转换为看起来像真实数据的样本，而**判别器** $D_{\psi}(x)$ 则努力区分真实样本和生成样本。训练过程是一个最小-最大博弈，其均衡点（在理想情况下）是生成器捕获了真实数据分布。在最优判别器的条件下，生成器的目标等价于最小化真实数据分布与生成数据分布之间的**[Jensen-Shannon散度](@entry_id:136492)**。GANs是隐式模型，它们不直接提供似然函数 $p_{\theta}(x)$。

3.  **[扩散模型](@entry_id:142185)**（Diffusion Models）：[扩散模型](@entry_id:142185)通过两个过程来学习数据分布。**[前向过程](@entry_id:634012)**是一个固定的马尔可夫链，它在多个步骤中逐渐向数据中添加高斯噪声，直到数据最终变成纯噪声。**反向过程**则是一个学习到的马尔可夫链，它从纯噪声出发，逐步[去噪](@entry_id:165626)以生成数据样本。这个反向过程由一个神经网络[参数化](@entry_id:265163)，该网络被训练来预测每一步中添加的噪声或等价地，噪声数据的**[分数函数](@entry_id:164520)**（score function）$\nabla_{x_t} \log p_t(x_t)$。其训练目标，即**[去噪](@entry_id:165626)[分数匹配](@entry_id:635640)**（denoising score matching），可以被证明等价于最大化数据似然的一个变分下界。对于蛋白质结构等具有[几何对称性](@entry_id:189059)的数据，使用尊重这些对称性（例如，对[旋转和平移](@entry_id:175994)不变的[SE(3)等变性](@entry_id:636578)）的[网络架构](@entry_id:268981)至关重要。[@problem_id:4332644]

#### 连接机理与数据：混合模型

正如本章开头所讨论的，机理模型和数据驱动模型各有优劣。**[物理信息神经网络](@entry_id:145229)**（Physics-Informed Neural Networks, **[PINNs](@entry_id:145229)**）代表了一种强大的混合建模方法，它将物理定律（通常以[微分](@entry_id:158422)方程的形式）直接嵌入到神经网络的训练过程中。

考虑一个药物的药代动力学（PK）模型，其中血浆药物浓度 $C(t)$ 的变化遵循一个由[质量守恒定律](@entry_id:147377)导出的一阶消除ODE：$\frac{dC(t)}{dt} = -k_e C(t)$，其中 $k_e$ 是消除[速率常数](@entry_id:140362)，并有初始条件 $C(0) = C_0$。一个纯数据驱动的模型会训练一个神经网络 $C_{\theta}(t)$ 来直接拟合稀疏、带噪声的观测数据 $\{(t_i, \hat{C}(t_i))\}$，而不考虑底层的ODE。这样的模型可能会很好地拟合数据点，但其在数据点之间的内插或在观测范围之外的外推可能完全不符合物理规律。

相比之下，PINN的[损失函数](@entry_id:136784)包含多个部分：
1.  **数据损失**：衡量网络预测与观测数据之间的差异，例如 $\sum_i (C_{\theta}(t_i) - \hat{C}(t_i))^2$。
2.  **物理损失**：惩罚网络对ODE的违反程度。这个损失是在一系列“[配置点](@entry_id:169000)”（collocation points）上计算的ODE残差的范数，例如 $\sum_j (\frac{dC_{\theta}(t_j)}{dt} + k_e C_{\theta}(t_j))^2$。网络对时间 $t$ 的导数 $\frac{dC_{\theta}}{dt}$ 可以通过自动微分精确计算。
3.  **边界/初始条件损失**：强制网络满足已知的条件，例如 $(C_{\theta}(0) - C_0)^2$。

通过最小化这些损失项的加权和，PINN能够学习一个既拟合数据又遵守底层药代动力学定律的函数。这种方法不仅能够提高模型在数据稀疏情况下的泛化能力，还能用于解决**[逆问题](@entry_id:143129)**，例如，将 $k_e$ 作为一个可训练参数，从数据中同时推断出浓度曲线和未知的物理参数。[@problem_id:4332685]

#### 超越预测：因果推断与[不确定性量化](@entry_id:138597)

在许多高风险的生物医学应用中，仅仅提供准确的预测是不够的。我们需要模型能够回答“如果……会怎样？”的因果问题，并且能够量化其预测的可信度。

##### 因果推断

从观察性数据（如EHR）中估计治疗的因果效应是一个核心挑战，因为“相关不等于因果”。**因果[有向无环图](@entry_id:164045)**（Causal Directed Acyclic Graphs, **DAGs**）为形式化因果假设和推理提供了一个强大的框架。在DAG中，节点代表变量，有向边代表直接的因果影响。

为了估计治疗 $T$ 对结果 $Y$ 的总因果效应，我们必须识别并阻断所有 $T$ 和 $Y$ 之间的**后门路径**（backdoor paths）。后门路径是一种非因果路径，它通常由[共同原因](@entry_id:266381)（**混杂因素**）引起。例如，在路径 $T \leftarrow S \rightarrow Y$ 中，基线疾病严重程度 $S$ 是一个混杂因素，它同时影响医生开具治疗 $T$ 的决策和患者未来的结果 $Y$。通过在统计分析中**调整**（conditioning on）一个充分的混杂因素集，我们可以阻断所有后门路径，从而得到因果效应的[无偏估计](@entry_id:756289)。这一原则被称为**[后门准则](@entry_id:637856)**。

然而，错误地调整变量也会引入偏差。调整**中介变量**（mediator），即位于因果路径 $T \rightarrow A \rightarrow Y$ 上的变量 $A$，会阻断部分因果效应，导致对总效应的估计产生偏差。同样，调整**对撞因子**（collider），即形如 $T \rightarrow B \leftarrow Y$ 的路径上的变量 $B$，会打开一条原本被阻断的非因果路径，引入所谓的[对撞偏倚](@entry_id:163186)。

[深度学习](@entry_id:142022)可以在因果推断中扮演辅助角色。例如，对于需要调整的高维协变量集 $X$，可以训练一个[深度神经网络](@entry_id:636170)来学习一个低维表示 $Z=f_{\theta}(X)$，该表示作为一个**平衡分数**（balancing score），例如倾向性得分 $p(T=1 \mid X)$。然后，可以使用基于这个学习到的表示的统计方法（如[逆概率](@entry_id:196307)加权）来估计因果效应。[@problem_id:4332657]

##### [不确定性量化](@entry_id:138597)

在临床决策支持等应用中，模型不仅需要做出预测，还需要告知我们预测的[置信度](@entry_id:267904)。预测的总不确定性可以分解为两种类型：

1.  **[偶然不确定性](@entry_id:154011)**（Aleatoric Uncertainty）：源于数据本身的内在随机性或噪声，例如[生物过程](@entry_id:164026)的随机变异或测量误差。这种不确定性是**不可约减的**，即使拥有无限多的数据也无法消除。

2.  **认知不确定性**（Epistemic Uncertainty）：源于我们对模型参数的知识有限，即由于训练数据量不足导致的模型不确定性。这种不确定性是**可约减的**，随着训练数据的增加，认知不确定性通常会减小。

在[深度学习](@entry_id:142022)中，量化这两种不确定性的常用方法包括：

- **[贝叶斯神经网络](@entry_id:746725)**（Bayesian Neural Networks, **BNNs**）：BNNs为模型的权重和偏置设置先验分布，并通过贝叶斯推断（通常是[变分推断](@entry_id:634275)等近似方法）来计算其后验分布。认知不确定性通过后验分布的方差来体现。通过让网络预测一个概率分布的参数（例如，高斯分布的均值和方差），BNNs也可以捕获[偶然不确定性](@entry_id:154011)。

- **[深度集成](@entry_id:636362)**（Deep Ensembles, **DE**）：这是一种更简单但非常有效的实用方法。它独立地训练多个（例如5-10个）具有相同架构但随机初始化不同的神经网络。在预测时，[认知不确定性](@entry_id:149866)可以通过集成成员之间预测结果的差异（例如方差）来估计。如果每个成员网络都预测一个方差，那么[偶然不确定性](@entry_id:154011)可以由这些方差的平均值来估计。[深度集成](@entry_id:636362)可以看作是对贝叶斯[后验预测分布](@entry_id:167931)的一种[蒙特卡洛近似](@entry_id:164880)。[@problem_id:4332667]

通过明确地区分和量化这两种不确定性，我们可以构建更值得信赖的生物医学AI系统，例如，当[认知不确定性](@entry_id:149866)高时，模型可以“拒绝”预测并请求人类专家干预。