{"hands_on_practices": [{"introduction": "在系统生物医学中，深度生成模型，特别是变分自编码器(VAE)，已成为分析单细胞RNA测序(scRNA-seq)数据的有力工具。为了准确捕捉基因表达计数的统计特性，如过度离散，我们通常不直接使用泊松分布，而是采用负二项分布。本练习将指导你从泊松-伽马混合的第一性原理出发，推导出负二项分布的对数似然，并计算其对于模型训练至关重要的梯度[@problem_id:4332692]。这对于理解和构建面向基因组计数数据的生成模型是关键一步。", "problem": "一个用于单细胞 RNA 测序 (scRNA-seq) 中唯一分子标识 (UMI) 计数的深度生成模型，通常假设每个细胞中每个基因的计数服从负二项分布，其动机是速率服从伽马分布的泊松过程。考虑单个细胞中的单个基因，其观测到的 UMI 计数为 $y \\in \\{0,1,2,\\ldots\\}$，模型参数为：由变分自编码器 (VAE) 的解码器生成的均值参数 $\\mu > 0$，以及一个控制过离散的逆离散参数 $\\theta > 0$。标准的混合构造是：抽取一个潜速率 $\\lambda \\sim \\operatorname{Gamma}(\\text{shape}=\\theta,\\ \\text{rate}=\\theta/\\mu)$，然后对观测计数进行采样 $y \\mid \\lambda \\sim \\operatorname{Poisson}(\\lambda)$。该构造确保了 $\\mathbb{E}[\\lambda]=\\mu$ 并为 $y$ 产生一个负二项边际分布。\n\n从泊松概率质量函数和伽马概率密度函数的定义出发，仅使用经过充分检验的伽马函数积分恒等式，推导由该混合构造所蕴含的 UMI 计数 $y$ 的边际对数似然 $\\log p(y \\mid \\mu,\\theta)$。然后，在保持 $\\theta$ 固定的情况下，计算梯度 $\\frac{\\partial}{\\partial \\mu}\\log p(y \\mid \\mu,\\theta)$。将你的最终答案表示为 $\\frac{\\partial}{\\partial \\mu}\\log p(y \\mid \\mu,\\theta)$ 的单个封闭形式表达式。无需四舍五入，也不涉及物理单位。", "solution": "该问题要求推导一个服从泊松-伽马混合分布的计数变量 $y$ 的边际对数似然，并随后计算其关于均值参数 $\\mu$ 的梯度。\n\n分层模型定义如下：\n$1$。潜速率 $\\lambda$ 从形状参数为 $\\theta > 0$、速率参数为 $\\theta/\\mu$ 的伽马分布中抽取，其中 $\\mu > 0$。$\\lambda$ 的概率密度函数 (PDF) 由下式给出：\n$$p(\\lambda \\mid \\mu, \\theta) = \\frac{(\\theta/\\mu)^\\theta}{\\Gamma(\\theta)} \\lambda^{\\theta-1} \\exp\\left(-\\frac{\\theta}{\\mu}\\lambda\\right)$$\n对于 $\\lambda > 0$。此处，$\\Gamma(\\cdot)$ 表示伽马函数。\n\n$2$。观测到的 UMI 计数 $y \\in \\{0, 1, 2, \\ldots\\}$ 从速率为 $\\lambda$ 的泊松分布中抽取。给定 $\\lambda$ 时 $y$ 的概率质量函数 (PMF) 为：\n$$p(y \\mid \\lambda) = \\frac{\\lambda^y \\exp(-\\lambda)}{y!}$$\n\n在给定参数 $\\mu$ 和 $\\theta$ 的条件下观测到计数 $y$ 的边际概率，记为 $p(y \\mid \\mu, \\theta)$，可以通过对联合概率 $p(y, \\lambda \\mid \\mu, \\theta) = p(y \\mid \\lambda) p(\\lambda \\mid \\mu, \\theta)$ 关于潜变量 $\\lambda$ 的所有可能值进行积分得到。\n$$p(y \\mid \\mu, \\theta) = \\int_0^\\infty p(y \\mid \\lambda) p(\\lambda \\mid \\mu, \\theta) \\, d\\lambda$$\n代入泊松 PMF 和伽马 PDF 的表达式：\n$$p(y \\mid \\mu, \\theta) = \\int_0^\\infty \\left( \\frac{\\lambda^y \\exp(-\\lambda)}{y!} \\right) \\left( \\frac{(\\theta/\\mu)^\\theta}{\\Gamma(\\theta)} \\lambda^{\\theta-1} \\exp\\left(-\\frac{\\theta}{\\mu}\\lambda\\right) \\right) \\, d\\lambda$$\n我们可以重新整理这些项，将关于 $\\lambda$ 的常数项移到积分符号外：\n$$p(y \\mid \\mu, \\theta) = \\frac{(\\theta/\\mu)^\\theta}{y! \\Gamma(\\theta)} \\int_0^\\infty \\lambda^y \\lambda^{\\theta-1} \\exp(-\\lambda) \\exp\\left(-\\frac{\\theta}{\\mu}\\lambda\\right) \\, d\\lambda$$\n$$p(y \\mid \\mu, \\theta) = \\frac{\\theta^\\theta}{\\mu^\\theta y! \\Gamma(\\theta)} \\int_0^\\infty \\lambda^{y+\\theta-1} \\exp\\left(-\\left(1 + \\frac{\\theta}{\\mu}\\right)\\lambda\\right) \\, d\\lambda$$\n该积分具有伽马函数的形式。具体来说，我们使用恒等式 $\\int_0^\\infty x^{k-1} \\exp(-\\beta x) \\, dx = \\frac{\\Gamma(k)}{\\beta^k}$。在我们的表达式中，形状为 $k = y+\\theta$，速率为 $\\beta = 1 + \\frac{\\theta}{\\mu} = \\frac{\\mu+\\theta}{\\mu}$。\n应用此恒等式，该积分的计算结果为：\n$$\\int_0^\\infty \\lambda^{y+\\theta-1} \\exp\\left(-\\left(\\frac{\\mu+\\theta}{\\mu}\\right)\\lambda\\right) \\, d\\lambda = \\frac{\\Gamma(y+\\theta)}{\\left(\\frac{\\mu+\\theta}{\\mu}\\right)^{y+\\theta}}$$\n将此结果代回 $p(y \\mid \\mu, \\theta)$ 的表达式中：\n$$p(y \\mid \\mu, \\theta) = \\frac{\\theta^\\theta}{\\mu^\\theta y! \\Gamma(\\theta)} \\cdot \\frac{\\Gamma(y+\\theta)}{\\left(\\frac{\\mu+\\theta}{\\mu}\\right)^{y+\\theta}}$$\n我们可以简化此表达式：\n$$p(y \\mid \\mu, \\theta) = \\frac{\\Gamma(y+\\theta)}{y! \\Gamma(\\theta)} \\frac{\\theta^\\theta}{\\mu^\\theta} \\frac{\\mu^{y+\\theta}}{(\\mu+\\theta)^{y+\\theta}}$$\n$$p(y \\mid \\mu, \\theta) = \\frac{\\Gamma(y+\\theta)}{y! \\Gamma(\\theta)} \\frac{\\theta^\\theta \\mu^y}{(\\mu+\\theta)^{y+\\theta}}$$\n这可以写成负二项分布 PMF 的可识别形式：\n$$p(y \\mid \\mu, \\theta) = \\frac{\\Gamma(y+\\theta)}{y! \\Gamma(\\theta)} \\left(\\frac{\\theta}{\\mu+\\theta}\\right)^\\theta \\left(\\frac{\\mu}{\\mu+\\theta}\\right)^y$$\n\n下一步是求边际对数似然 $\\log p(y \\mid \\mu, \\theta)$。对上面推导出的表达式取自然对数：\n$$\\log p(y \\mid \\mu, \\theta) = \\log\\left( \\frac{\\Gamma(y+\\theta)}{y! \\Gamma(\\theta)} \\right) + \\log\\left( \\left(\\frac{\\theta}{\\mu+\\theta}\\right)^\\theta \\right) + \\log\\left( \\left(\\frac{\\mu}{\\mu+\\theta}\\right)^y \\right)$$\n使用对数的性质，$\\log(a^b) = b\\log(a)$ 和 $\\log(a/b) = \\log(a) - \\log(b)$：\n$$\\log p(y \\mid \\mu, \\theta) = \\log(\\Gamma(y+\\theta)) - \\log(y!) - \\log(\\Gamma(\\theta)) + \\theta \\log\\left(\\frac{\\theta}{\\mu+\\theta}\\right) + y \\log\\left(\\frac{\\mu}{\\mu+\\theta}\\right)$$\n$$\\log p(y \\mid \\mu, \\theta) = \\log(\\Gamma(y+\\theta)) - \\log(y!) - \\log(\\Gamma(\\theta)) + \\theta(\\log\\theta - \\log(\\mu+\\theta)) + y(\\log\\mu - \\log(\\mu+\\theta))$$\n合并各项：\n$$\\log p(y \\mid \\mu, \\theta) = \\log(\\Gamma(y+\\theta)) - \\log(y!) - \\log(\\Gamma(\\theta)) + \\theta\\log\\theta + y\\log\\mu - (y+\\theta)\\log(\\mu+\\theta)$$\n\n最后，我们计算对数似然关于 $\\mu$ 的梯度，并保持 $\\theta$ 固定。我们对 $\\log p(y \\mid \\mu, \\theta)$ 的表达式关于 $\\mu$ 求导。$\\log(\\Gamma(y+\\theta))$、$\\log(y!)$、$\\log(\\Gamma(\\theta))$ 和 $\\theta\\log\\theta$ 这些项不依赖于 $\\mu$，因此它们的导数为 $0$。\n$$\\frac{\\partial}{\\partial \\mu}\\log p(y \\mid \\mu,\\theta) = \\frac{\\partial}{\\partial \\mu} \\left[ y\\log\\mu - (y+\\theta)\\log(\\mu+\\theta) \\right]$$\n应用求导法则，$\\frac{d}{dx}\\log(x) = \\frac{1}{x}$ 和链式法则：\n$$\\frac{\\partial}{\\partial \\mu} (y\\log\\mu) = \\frac{y}{\\mu}$$\n$$\\frac{\\partial}{\\partial \\mu} (-(y+\\theta)\\log(\\mu+\\theta)) = -(y+\\theta) \\cdot \\frac{1}{\\mu+\\theta} \\cdot \\frac{\\partial}{\\partial \\mu}(\\mu+\\theta) = -(y+\\theta) \\cdot \\frac{1}{\\mu+\\theta} \\cdot 1 = -\\frac{y+\\theta}{\\mu+\\theta}$$\n结合这些结果，得到梯度：\n$$\\frac{\\partial}{\\partial \\mu}\\log p(y \\mid \\mu,\\theta) = \\frac{y}{\\mu} - \\frac{y+\\theta}{\\mu+\\theta}$$\n为了将其表示为单个分数，我们找到一个公分母，即 $\\mu(\\mu+\\theta)$：\n$$\\frac{\\partial}{\\partial \\mu}\\log p(y \\mid \\mu,\\theta) = \\frac{y(\\mu+\\theta) - \\mu(y+\\theta)}{\\mu(\\mu+\\theta)}$$\n$$= \\frac{y\\mu + y\\theta - \\mu y - \\mu\\theta}{\\mu(\\mu+\\theta)}$$\n$$= \\frac{y\\theta - \\mu\\theta}{\\mu(\\mu+\\theta)}$$\n从分子中提出因子 $\\theta$ 得到最终的封闭形式表达式：\n$$\\frac{\\partial}{\\partial \\mu}\\log p(y \\mid \\mu,\\theta) = \\frac{\\theta(y-\\mu)}{\\mu(\\mu+\\theta)}$$\n该表达式表示模型的对数似然相对于其均值参数 $\\mu$ 的变化率，这是对 VAE 解码器进行基于梯度的优化所必需的量。", "answer": "$$\\boxed{\\frac{\\theta(y-\\mu)}{\\mu(\\mu+\\theta)}}$$", "id": "4332692"}, {"introduction": "U-Net及其变体是生物医学图像分割任务的基石架构，尤其在数字病理学等领域中发挥着核心作用。要成功设计和实现一个U-Net，精确计算网络中各层特征图的空间尺寸是必不可少的。本练习将带你逐层解构一个典型的U-Net，计算从编码器到解码器每一阶段的输出尺寸，并探讨填充策略对结果的影响[@problem_id:4332691]。掌握这项技能是构建稳健的图像分析流水线的基础。", "problem": "在一个用于全切片组织病理学分析的系统生物医学流程中，一个U-Net家族的卷积编码器-解码器网络被用来分割多重免疫荧光图像中的细胞区室。考虑一个具有$3$个下采样阶段和$3$个上采样阶段的二维U-Net。我们只关心其空间维度。输入图像的空间尺寸为$(H, W)$，其中$H$和$W$是正整数。该架构如下，并精确指定了空间操作：\n\n- 编码器阶段$1$：两个卷积层，卷积核大小为$3 \\times 3$，步幅为$1$，扩张率为$1$，并选择零填充以在每次卷积时保持空间尺寸（“same”填充）；然后是一个最大池化层，池化核大小为$2 \\times 2$，步幅为$2$，零填充为$0$。\n- 编码器阶段$2$：两个卷积层，卷积核大小为$3 \\times 3$，步幅为$1$，扩张率为$1$，并采用“same”填充；然后是一个最大池化层，池化核大小为$2 \\times 2$，步幅为$2$，零填充为$0$。\n- 编码器阶段$3$：两个卷积层，卷积核大小为$3 \\times 3$，步幅为$1$，扩张率为$1$，并采用“same”填充；然后是一个最大池化层，池化核大小为$2 \\times 2$，步幅为$2$，零填充为$0$。\n- 瓶颈层：两个卷积层，卷积核大小为$3 \\times 3$，步幅为$1$，扩张率为$1$，并采用“same”填充。\n- 解码器阶段$3$：一个转置卷积（“上卷积”），卷积核大小为$2 \\times 2$，步幅为$2$，零填充为$0$，输出填充为$0$；与编码器阶段$3$的特征图（取自其两个“same”填充卷积之后、最大池化之前）进行拼接（如果空间尺寸不完全匹配，则对跳跃连接的特征图进行对称中心裁剪）；然后是两个卷积层，卷积核大小为$3 \\times 3$，步幅为$1$，扩张率为$1$，并采用“same”填充。\n- 解码器阶段$2$：一个转置卷积，卷积核大小为$2 \\times 2$，步幅为$2$，零填充为$0$，输出填充为$0$；与编码器阶段$2$的特征图（取自其两个“same”填充卷积之后、最大池化之前）进行拼接（如果需要，进行对称中心裁剪）；然后是两个卷积层，卷积核大小为$3 \\times 3$，步幅为$1$，扩张率为$1$，并采用“same”填充。\n- 解码器阶段$1$：一个转置卷积，卷积核大小为$2 \\times 2$，步幅为$2$，零填充为$0$，输出填充为$0$；与编码器阶段$1$的特征图（取自其两个“same”填充卷积之后、最大池化之前）进行拼接（如果需要，进行对称中心裁剪）；然后是两个卷积层，卷积核大小为$3 \\times 3$，步幅为$1$，扩张率为$1$，并采用“same”填充。\n- 最终预测层：一个$1 \\times 1$卷积，步幅为$1$。\n\n假设所有操作在$H$和$W$维度上都是相同且独立地应用的；通道数不影响空间尺寸，可以忽略。拼接不改变空间尺寸，并且仅在通过如上所述的对称裁剪跳跃连接特征图以精确匹配空间尺寸后才执行。\n\n任务：\n- 仅使用离散卷积、步幅、填充和池化的基本定义，计算编码器和解码器中每个空间操作输出的空间尺寸，作为$(H, W)$的函数，并在适用时说明舍入是如何产生的。明确指出需要对称裁剪跳跃连接的任何点，并量化每个跳跃连接处的不匹配度，作为$H$和$W$的函数。\n- 在上述架构和裁剪规则下，推导最终分割图空间尺寸关于$(H, W)$的闭式解析表达式。\n- 简要讨论卷积层中填充选择（“same”与“valid”）将如何改变逐层的尺寸和最终输出尺寸，并论证哪种填充策略更适合基于切片的组织病理学推断以减轻边界伪影，从离散卷积和采样理论的第一性原理出发证明你的答案。\n\n将你最终的闭式最终空间尺寸作为包含高度和宽度表达式的行矩阵提供。不需要单位。如果你选择表示中间的舍入，请使用向下取整函数表示法。最终答案框中不要包含任何文本。", "solution": "该问题陈述定义明确，科学上基于深度学习架构的原理，并且内部一致。它描述了一个具有特定层参数的标准U-Net架构，为计算和分析提供了清晰的基础。任务是客观的，可以使用所提供的信息解决。因此，该问题是有效的。\n\n我们将分析空间维度$(H, W)$如何通过指定的U-Net架构的各层进行变换。对高度维度$H$和宽度维度$W$的操作是相同且独立的。我们将推导$H$的表达式，而$W$的结果可以类推得出。\n\n给定输入尺寸$S_{in}$、卷积核大小$k$、步幅$s$、填充$p$和扩张率$d$，输出尺寸$S_{out}$的基本公式为：\n- 对于标准二维卷积：$S_{out} = \\lfloor \\frac{S_{in} + 2p - d(k-1) - 1}{s} \\rfloor + 1$。\n- 对于最大池化层：$S_{out} = \\lfloor \\frac{S_{in} + 2p - k}{s} \\rfloor + 1$。\n- 对于转置卷积：$S_{out} = (S_{in} - 1)s - 2p + k + p_{out}$，其中$p_{out}$是输出填充。\n\n让我们将这些公式应用于指定的架构。\n\n**1. 逐层空间尺寸计算**\n\n设输入图像尺寸为$(H, W)$。令$f_{down}(x) = \\lfloor x/2 \\rfloor$。\n\n**编码器路径**\n- **输入：** 初始空间尺寸为$(H, W)$。\n\n- **编码器阶段1：**\n  - 两个卷积层，卷积核大小$k=3$，步幅$s=1$，扩张率$d=1$，以及“same”填充。“Same”填充被定义为保持空间尺寸。对于$k=3, s=1, d=1$，这需要$p=1$。这两个卷积后的尺寸保持为$(H, W)$。此特征图表示为$S_1$，被传递给跳跃连接。\n  - 一个最大池化层，参数为$k=2, s=2, p=0$。输出尺寸为$S_{out} = \\lfloor \\frac{S_{in} - 2}{2} \\rfloor + 1 = \\lfloor S_{in}/2 - 1 \\rfloor + 1 = \\lfloor S_{in}/2 \\rfloor = f_{down}(S_{in})$。\n  - 阶段1的输出尺寸：$(f_{down}(H), f_{down}(W))$。\n\n- **编码器阶段2：**\n  - 输入尺寸：$(f_{down}(H), f_{down}(W))$。\n  - 两个“same”填充的卷积保持尺寸不变。用于跳跃连接的特征图$S_2$的尺寸为$(f_{down}(H), f_{down}(W))$。\n  - 一个最大池化层减小尺寸。\n  - 阶段2的输出尺寸：$(f_{down}(f_{down}(H)), f_{down}(f_{down}(W)))$。\n\n- **编码器阶段3：**\n  - 输入尺寸：$(f_{down}(f_{down}(H)), f_{down}(f_{down}(W)))$。\n  - 两个“same”填充的卷积保持尺寸不变。用于跳跃连接的特征图$S_3$的尺寸为$(f_{down}(f_{down}(H)), f_{down}(f_{down}(W)))$。\n  - 一个最大池化层减小尺寸。\n  - 阶段3的输出尺寸：$(f_{down}(f_{down}(f_{down}(H))), f_{down}(f_{down}(f_{down}(W)))))$。\n\n**瓶颈层**\n- 输入尺寸：$(f_{down}(f_{down}(f_{down}(H))), f_{down}(f_{down}(f_{down}(W)))))$。\n- 两个“same”填充的卷积保持尺寸不变。\n- 瓶颈层的输出尺寸：$(f_{down}(f_{down}(f_{down}(H))), f_{down}(f_{down}(f_{down}(W)))))$。我们将其表示为$(H_b, W_b)$。\n\n**解码器路径和跳跃连接不匹配问题**\n令$f_{up}(x) = 2x$。\n\n- **解码器阶段3：**\n  - 来自瓶颈层的输入：$(H_b, W_b) = (f_{down}(f_{down}(f_{down}(H))), f_{down}(f_{down}(f_{down}(W)))))$。\n  - 一个转置卷积，参数为$k=2, s=2, p=0, p_{out}=0$。输出尺寸为$S_{out} = (S_{in}-1) \\cdot 2 - 0 + 2 + 0 = 2S_{in}$。尺寸变为$(2H_b, 2W_b)$。我们称之为$(H_{u3}, W_{u3})$。\n  - 跳跃连接$S_3$的尺寸：$(f_{down}(f_{down}(H)), f_{down}(f_{down}(W)))$。\n  - **H维度的不匹配：** 不匹配度为$\\Delta H_3 = f_{down}(f_{down}(H)) - 2H_b = f_{down}(f_{down}(H)) - 2 f_{down}(f_{down}(f_{down}(H)))$。\n    这个差值是$f_{down}(f_{down}(H)) \\pmod 2$，如果$f_{down}(f_{down}(H))$是偶数，则为$0$；如果是奇数，则为$1$。如果此不匹配度非零，则需要对$S_3$进行对称裁剪。宽度不匹配度$\\Delta W_3$也类似。\n  - 裁剪和拼接后，尺寸为$(2H_b, 2W_b)$。\n  - 两个“same”卷积保持尺寸不变。\n  - 解码器阶段3的输出尺寸：$(H_{d3}, W_{d3}) = (2H_b, 2W_b)$。\n\n- **解码器阶段2：**\n  - 来自解码器阶段3的输入：$(H_{d3}, W_{d3}) = (2H_b, 2W_b)$。\n  - 一个转置卷积将尺寸加倍为$(2 H_{d3}, 2 W_{d3}) = (4H_b, 4W_b)$。我们称之为$(H_{u2}, W_{u2})$。\n  - 跳跃连接$S_2$的尺寸：$(f_{down}(H), f_{down}(W))$。\n  - **H维度的不匹配：** $\\Delta H_2 = f_{down}(H) - 4H_b = f_{down}(H) - 4 f_{down}(f_{down}(f_{down}(H)))$。需要对$S_2$进行对称裁剪以匹配尺寸$(4H_b, 4W_b)$。\n  - 裁剪和拼接后，尺寸为$(4H_b, 4W_b)$。\n  - 两个“same”卷积保持尺寸不变。\n  - 解码器阶段2的输出尺寸：$(H_{d2}, W_{d2}) = (4H_b, 4W_b)$。\n\n- **解码器阶段1：**\n  - 来自解码器阶段2的输入：$(H_{d2}, W_{d2}) = (4H_b, 4W_b)$。\n  - 一个转置卷积将尺寸加倍为$(2 H_{d2}, 2 W_{d2}) = (8H_b, 8W_b)$。我们称之为$(H_{u1}, W_{u1})$。\n  - 跳跃连接$S_1$的尺寸：$(H, W)$。\n  - **H维度的不匹配：** $\\Delta H_1 = H - 8H_b = H - 8 f_{down}(f_{down}(f_{down}(H)))$。需要对$S_1$进行对称裁剪以匹配尺寸$(8H_b, 8W_b)$。\n  - 裁剪和拼接后，尺寸为$(8H_b, 8W_b)$。\n  - 两个“same”卷积保持尺寸不变。\n  - 解码器阶段1的输出尺寸：$(H_{d1}, W_{d1}) = (8H_b, 8W_b)$。\n\n**最终预测层**\n- 输入尺寸：$(8H_b, 8W_b)$。\n- 一个$1 \\times 1$卷积，步幅为$1$，保持空间尺寸不变。\n- 最终输出尺寸：$(H_{out}, W_{out}) = (8H_b, 8W_b)$。\n\n**2. 最终尺寸的闭式表达式**\n\n最终输出高度由以下公式给出：\n$$ H_{out} = 8 H_b = 8 \\cdot f_{down}(f_{down}(f_{down}(H))) = 8 \\left\\lfloor \\frac{\\lfloor \\frac{\\lfloor H/2 \\rfloor}{2} \\rfloor}{2} \\right\\rfloor $$\n这个表达式可以简化。向下取整函数的一个性质是 $\\lfloor \\lfloor x/n \\rfloor / m \\rfloor = \\lfloor x/(nm) \\rfloor$。迭代应用此性质：\n$$ H_{out} = 8 \\left\\lfloor \\frac{\\lfloor H/4 \\rfloor}{2} \\right\\rfloor = 8 \\left\\lfloor \\frac{H}{8} \\right\\rfloor $$\n这个表达式计算的是小于或等于$H$的最大的8的倍数。\n同样的逻辑也适用于宽度维度$W$。因此，分割图的最终空间尺寸为：\n$$ (H_{out}, W_{out}) = \\left( 8 \\left\\lfloor \\frac{H}{8} \\right\\rfloor, 8 \\left\\lfloor \\frac{W}{8} \\right\\rfloor \\right) $$\n\n**3. 填充策略的讨论**\n\n卷积层中填充的选择显著影响网络的行为，特别是对于基于切片的分析。\n\n- **“Same”填充（如指定）：** 使用“same”填充时，每个编码器和解码器块内的卷积不会缩小特征图。尺寸减小仅发生在最大池化层。这简化了架构，但如上所示，导致了下采样路径（$S_{out} = \\lfloor S_{in}/2 \\rfloor$）和上采样路径（$S_{out} = 2S_{in}$）之间的不对称性。这种不对称性需要在拼接前对来自跳跃连接的高分辨率特征图进行裁剪。除非输入维度是$2^D$的倍数（其中$D=3$是下采样阶段的数量），否则最终输出的尺寸会小于输入。在处理切片时，输出切片也存在同样的尺寸问题。虽然如果仔细选择输入尺寸（例如，8的倍数），这使得拼接在概念上看起来很简单，但每个输出切片边界处的预测本质上是不可靠的。这是因为这些输出像素的感受野延伸到了原始输入切片的零填充区域，而零填充是人工数据。简单地拼接这些切片将在最终的全切片分割中产生一个充满伪影的网格状接缝。因此，需要一个明确的后处理步骤来从每个输出切片中裁剪掉不可靠的边界。\n\n- **“Valid”填充：** 使用“valid”填充（$p=0$）时，每次卷积都会减小空间尺寸。对于一个$3 \\times 3$的卷积核，每层的尺寸会减小2（$S_{out} = S_{in} - 2$）。一个包含两个卷积的块会将尺寸减小4。这将在跳跃连接处造成更大的尺寸差异，需要更大幅度的裁剪。网络的最终输出将显著小于输入。\n  在基于切片的组织病理学推断的背景下，这通常是更可取的策略。“重叠切片”法是减轻边界伪影的标准技术。该方法从全切片图像中提取重叠的输入切片，将每个切片通过网络处理，然后在拼接有效的中心部分之前，丢弃每个输出预测图的不可靠边界区域。一个带有“valid”卷积的U-Net自然地实现了边界的丢弃。特征图的缩小意味着最终较小输出图中的每个像素都是基于完全包含在输入切片的有效（非填充）区域内的感受野计算出来的。从采样理论的角度来看，这确保了每个输出都仅是真实图像信号的函数，而不是人工填充的函数。这提高了结果的保真度并简化了拼接逻辑，因为网络架构本身定义了输出的“有效”区域，从而无需在后处理中设置一个单独的手动裁剪参数。因此，为了从切片生成高质量、无缝的大图像分割，“valid”填充是更符合原理且更稳健的选择。", "answer": "$$ \\boxed{ \\begin{pmatrix} 8 \\left\\lfloor \\frac{H}{8} \\right\\rfloor & 8 \\left\\lfloor \\frac{W}{8} \\right\\rfloor \\end{pmatrix} } $$", "id": "4332691"}, {"introduction": "在临床等高风险医疗应用中，“黑箱”模型的可解释性至关重要。本练习将从微积分基本定理出发，推导积分梯度(Integrated Gradients)这一重要归因方法的原理，并将其应用于一个简单的线性模型以建立直观理解[@problem_id:4332698]。这有助于我们打开模型的“黑箱”，理解预测背后的生物学或临床驱动因素。", "problem": "一个系统生物医学流程使用一个可微标量预测模型 $F:\\mathbb{R}^{n}\\rightarrow\\mathbb{R}$，将一个标准化分子特征向量（例如，转录本丰度或蛋白质标记物）$x\\in\\mathbb{R}^{n}$ 映射到一个疾病活动评分。为了解释特征的贡献，我们考虑积分梯度（IG），该方法是为代表健康稳态的基线 $x'\\in\\mathbb{R}^{n}$ 以及从 $x'$ 到 $x$ 的直线路径定义的。请仅从梯度定义、链式法则和保守向量场的线积分基本定理（即，对于一个可微标量场 $F$，$\\nabla F$ 沿任意两点间平滑路径的积分等于 $F$ 在这两个端点处的值的差）出发，推导沿从 $x'$ 到 $x$ 的直线路径分配给特征 $i$ 的归因值的解析表达式。然后，将您的表达式特化到线性模型 $F(x)=w^{\\top}x+b$，并根据以下数值计算特征 $i=2$ 的归因值：\n- $w=\\left(0.92,\\,-0.68,\\,0.11,\\,0.35\\right)$,\n- $x=\\left(0.50,\\,1.25,\\,-0.30,\\,0.80\\right)$,\n- $x'=\\left(0.10,\\,0.15,\\,-0.30,\\,0.20\\right)$.\n请提供特征 $i=2$ 归因值的最终数值，作为一个精确数；无需四舍五入。不要包含单位。", "solution": "题目要求从基本原理出发，推导特征 $i$ 的积分梯度（IG）归因的解析表达式。然后，必须将此表达式特化用于线性模型，并用它来计算一个具体的数值。\n\n首先，我们推导归因的一般表达式。题目指出，我们应该使用保守向量场的线积分基本定理。对于一个可微标量场 $F:\\mathbb{R}^{n}\\rightarrow\\mathbb{R}$，其梯度 $\\nabla F$ 是一个保守向量场。该定理指出，$\\nabla F$ 沿从点 $x'$ 到点 $x$ 的任意平滑路径 $\\gamma$ 的积分，等于该标量场在两个端点处的值的差：\n$$F(x) - F(x') = \\int_{\\gamma} \\nabla F(\\mathbf{r}) \\cdot d\\mathbf{r}$$\n题目指定了一条从基线 $x'$到输入 $x$ 的直线路径。我们可以将此路径参数化为 $\\gamma(\\alpha) = x' + \\alpha(x - x')$，其中参数 $\\alpha \\in [0, 1]$。当 $\\alpha=0$ 时，我们有 $\\gamma(0) = x'$；当 $\\alpha=1$ 时，我们有 $\\gamma(1) = x' + (x - x') = x$。微分路径元为 $d\\mathbf{r} = \\frac{d\\gamma}{d\\alpha}d\\alpha = (x - x')d\\alpha$。\n\n将此参数化代入线积分，得到：\n$$F(x) - F(x') = \\int_{0}^{1} \\nabla F(\\gamma(\\alpha)) \\cdot \\frac{d\\gamma}{d\\alpha} d\\alpha$$\n$$F(x) - F(x') = \\int_{0}^{1} \\nabla F(x' + \\alpha(x - x')) \\cdot (x - x') d\\alpha$$\n梯度向量为 $\\nabla F(\\mathbf{r}) = \\left(\\frac{\\partial F}{\\partial x_1}, \\frac{\\partial F}{\\partial x_2}, \\dots, \\frac{\\partial F}{\\partial x_n}\\right)$，向量 $(x - x')$ 为 $(x_1 - x'_1, x_2 - x'_2, \\dots, x_n - x'_n)$。被积函数中的点积为：\n$$\\nabla F(x' + \\alpha(x - x')) \\cdot (x - x') = \\sum_{i=1}^{n} \\frac{\\partial F}{\\partial x_i}\\bigg|_{\\mathbf{r}=x' + \\alpha(x - x')} (x_i - x'_i)$$\n其中 $\\frac{\\partial F}{\\partial x_i}\\big|_{\\mathbf{r}=\\dots}$ 表示在路径上的点 $\\mathbf{r}$ 处计算的偏导数。\n\n将此和式代入 $F$ 的总变化量的积分表达式中：\n$$F(x) - F(x') = \\int_{0}^{1} \\sum_{i=1}^{n} \\frac{\\partial F}{\\partial x_i}\\bigg|_{x' + \\alpha(x - x')} (x_i - x'_i) d\\alpha$$\n由于和是有限的，我们可以交换求和和积分算子：\n$$F(x) - F(x') = \\sum_{i=1}^{n} \\int_{0}^{1} \\frac{\\partial F}{\\partial x_i}\\bigg|_{x' + \\alpha(x - x')} (x_i - x'_i) d\\alpha$$\n项 $(x_i - x'_i)$ 相对于积分变量 $\\alpha$ 是一个常数，因此可以移到积分号外：\n$$F(x) - F(x') = \\sum_{i=1}^{n} (x_i - x'_i) \\int_{0}^{1} \\frac{\\partial F}{\\partial x_i}\\bigg|_{x' + \\alpha(x - x')} d\\alpha$$\n积分梯度框架将特征 $i$ 的归因值（记为 $IG_i(x, x')$）定义为该求和式中的第 $i$ 项。这确保了所有特征的归因值之和等于总变化量 $F(x) - F(x')$。因此，分配给特征 $i$ 的归因值的解析表达式为：\n$$IG_i(x, x') = (x_i - x'_i) \\int_{0}^{1} \\frac{\\partial F}{\\partial x_i}\\bigg|_{x' + \\alpha(x - x')} d\\alpha$$\n这就完成了问题的第一部分。\n\n接下来，我们将此表达式特化用于线性模型 $F(x) = w^{\\top}x + b$，该模型可以写成 $F(x) = \\sum_{j=1}^{n} w_j x_j + b$。我们需要求 $F$ 关于特征 $x_i$ 的偏导数：\n$$\\frac{\\partial F}{\\partial x_i} = \\frac{\\partial}{\\partial x_i} \\left(\\sum_{j=1}^{n} w_j x_j + b\\right) = w_i$$\n值得注意的是，对于线性模型，偏导数 $\\frac{\\partial F}{\\partial x_i}$ 是一个常数 $w_i$，不依赖于输入向量 $x$。因此，它在整个积分路径上的值是恒定的。\n\n将此代入通用的归因公式：\n$$IG_i(x, x') = (x_i - x'_i) \\int_{0}^{1} w_i d\\alpha$$\n常数 $w_i$ 在区间 $[0, 1]$ 上的积分为：\n$$\\int_{0}^{1} w_i d\\alpha = w_i [\\alpha]_{0}^{1} = w_i (1 - 0) = w_i$$\n因此，对于线性模型，特征 $i$ 的归因值简化为：\n$$IG_i(x, x') = w_i (x_i - x'_i)$$\n\n最后，我们使用给定的数值计算特征 $i=2$ 的归因值：\n- 权重向量：$w=\\left(0.92,\\,-0.68,\\,0.11,\\,0.35\\right)$，所以特征2的权重是 $w_2 = -0.68$。\n- 输入特征向量：$x=\\left(0.50,\\,1.25,\\,-0.30,\\,0.80\\right)$，所以特征2的值是 $x_2 = 1.25$。\n- 基线特征向量：$x'=\\left(0.10,\\,0.15,\\,-0.30,\\,0.20\\right)$，所以特征2的基线值是 $x'_2 = 0.15$。\n\n使用线性模型的特化公式：\n$$IG_2(x, x') = w_2 (x_2 - x'_2)$$\n代入数值：\n$$IG_2(x, x') = (-0.68) \\times (1.25 - 0.15)$$\n$$IG_2(x, x') = (-0.68) \\times (1.10)$$\n$$IG_2(x, x') = -0.748$$\n特征 $i=2$ 的归因值为 $-0.748$。", "answer": "$$\\boxed{-0.748}$$", "id": "4332698"}]}