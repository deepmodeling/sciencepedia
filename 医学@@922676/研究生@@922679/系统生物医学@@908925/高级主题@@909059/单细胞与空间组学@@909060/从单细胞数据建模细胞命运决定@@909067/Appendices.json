{"hands_on_practices": [{"introduction": "在比较单细胞的基因表达谱之前，一个关键的预处理步骤是校正技术差异，尤其是测序深度或文库大小的变化。直接比较原始计数值会产生误导，因为它会将技术变异与真实的生物学差异混淆。本练习将指导您从第一性原理出发，推导一种稳健的归一化方法，从而深入理解我们如何能够在消除采样偏差的同时，保留对推断细胞命运至关重要的细胞内相对表达模式 [@problem_id:4361230]。", "problem": "从单细胞RNA测序 (scRNA-seq) 数据中建模细胞命运决定的一个核心任务是，在保留每个细胞内基因间具有生物学意义的相对表达模式的同时，去除技术性的采样深度变异。考虑 $n$ 个单细胞，索引为 $i \\in \\{1,\\dots,n\\}$，以及 $G$ 个基因，索引为 $g \\in \\{1,\\dots,G\\}$。令 $x_{ig} \\in \\mathbb{N}$ 表示在细胞 $i$ 中基因 $g$ 的观测唯一分子标识符 (UMI) 计数。假设一个生成模型，在该模型中，以潜藏表达和采样深度为条件，计数可以很好地近似为独立的泊松变量，\n$$\nx_{ig} \\sim \\text{Poisson}\\!\\left(s_{i}\\,\\theta_{ig}\\right),\n$$\n其中 $s_{i} > 0$ 是一个细胞特异性采样深度（文库大小），$\\theta_{ig} > 0$ 是细胞 $i$ 中基因 $g$ 的潜在预期表达水平。为了将 $\\theta_{ig}$ 与命运决定的程序关联起来，假设 $\\theta_{ig} = \\phi_{g}\\,r_{ig}$，其中 $\\phi_{g} > 0$ 是一个基因特异性基线，$r_{ig} > 0$ 捕捉了细胞 $i$ 中基因 $g$ 的细胞状态依赖的相对表达。目的是以一种能够消除 $s_{i}$ 的混杂效应，同时最小化对基因间 $r_{ig}$ 分布的扭曲的方式来估计 $s_{i}$，从而保留推断命运决定所需的细胞内相对表达。\n\n从这个模型和“对于大的总计数，多项式采样的泊松近似成立”这一经过充分检验的观察出发，基于最小化各基因在对数空间中相对于一个仅由观测计数构建的基因伪参照的绝对偏差之和，从第一性原理推导出一个 $s_{i}$ 的稳健估计量。具体来说，对于每个基因 $g$，将其伪参照水平设为它在所有 $n$ 个细胞中计数的几何平均值。将注意力限制在所有细胞中计数都严格为正的基因上，以确保对数是良定义的。使用此设置推导出估计量 $s_{i}$ 仅用观测计数 $x_{ig}$ 表示的解析表达式，并解释为什么用这个 $s_{i}$ 对 $x_{ig}$ 进行缩放能够近似地消除采样深度混杂因子 $s_{i}$，而不扭曲基因间的细胞内相对表达。\n\n请以一个仅用 $\\{x_{ig}\\}_{g=1}^{G}$ 和 $\\{x_{jg}\\}_{j=1}^{n}$ 表示的 $s_{i}$ 的单一闭式解析表达式的形式提供您的最终结果，不带单位。无需四舍五入。", "solution": "我们首先正式陈述针对单个细胞 $i$ 的问题。目标是通过最小化一个特定的目标函数来找到细胞特异性采样深度 $s_i$ 的估计量。问题要求我们最小化对数空间中的绝对偏差之和。对于每个基因 $g$，偏差被定义为细胞 $i$ 的归一化计数的对数与该基因的伪参照水平的对数之差。\n\n让我们定义各个组成部分：\n1.  细胞 $i$ 中基因 $g$ 的观测计数是 $x_{ig}$。\n2.  细胞 $i$ 的采样深度的估计量表示为 $\\hat{s_i}$。\n3.  经采样深度校正后的归一化计数是 $x_{ig} / \\hat{s_i}$。在对数空间中，这是 $\\ln(x_{ig}) - \\ln(\\hat{s_i})$。\n4.  如问题中所定义，基因 $g$ 的伪参照是其在所有 $n$ 个细胞中计数的几何平均值。我们称之为 $p_g$。\n    $$\n    p_g = \\left( \\prod_{j=1}^{n} x_{jg} \\right)^{1/n}\n    $$\n    在对数空间中，伪参照是：\n    $$\n    \\ln(p_g) = \\ln\\left( \\left( \\prod_{j=1}^{n} x_{jg} \\right)^{1/n} \\right) = \\frac{1}{n} \\sum_{j=1}^{n} \\ln(x_{jg})\n    $$\n    问题指明我们只考虑在所有 $j \\in \\{1,\\dots,n\\}$ 中都有 $x_{jg} > 0$ 的基因，这确保了 $p_g$ 是良定义且为正的。\n\n基因 $g$ 在对数空间中的偏差是归一化对数计数与参照对数计数之差：\n$$\nd_{ig} = (\\ln(x_{ig}) - \\ln(\\hat{s_i})) - \\ln(p_g)\n$$\n目标是找到能最小化对于一个固定细胞 $i$ 在所有 $G$ 个基因上这些偏差绝对值之和的 $\\hat{s_i}$ 的值。我们将损失函数 $L(\\hat{s_i})$ 定义为：\n$$\nL(\\hat{s_i}) = \\sum_{g=1}^{G} |d_{ig}| = \\sum_{g=1}^{G} \\left| (\\ln(x_{ig}) - \\ln(p_g)) - \\ln(\\hat{s_i}) \\right|\n$$\n我们寻求最小化 $L(\\hat{s_i})$ 的 $\\hat{s_i}$ 值。令 $c_{ig} = \\ln(x_{ig}) - \\ln(p_g)$ 且令 $l_i = \\ln(\\hat{s_i})$。问题转化为寻找最小化以下表达式的 $l_i$ 值：\n$$\nL(l_i) = \\sum_{g=1}^{G} | c_{ig} - l_i |\n$$\n这是稳健统计学中的一个经典问题。当 $l_i$ 是值集合 $\\{c_{ig}\\}_{g=1}^{G}$ 的中位数时，数量 $\\sum_{g=1}^{G} |c_{ig} - l_i|$ 达到最小值。\n因此，我们记为 $\\ln(\\hat{s_i})$ 的采样深度对数的估计量是：\n$$\n\\ln(\\hat{s_i}) = \\text{median}_{g \\in \\{1,\\dots,G\\}} \\{ c_{ig} \\} = \\text{median}_{g \\in \\{1,\\dots,G\\}} \\{ \\ln(x_{ig}) - \\ln(p_g) \\}\n$$\n代入 $\\ln(p_g)$ 的表达式：\n$$\n\\ln(\\hat{s_i}) = \\text{median}_{g \\in \\{1,\\dots,G\\}} \\left\\{ \\ln(x_{ig}) - \\frac{1}{n} \\sum_{j=1}^{n} \\ln(x_{jg}) \\right\\}\n$$\n为了找到估计量 $\\hat{s_i}$ 本身，我们对结果取指数：\n$$\n\\hat{s_i} = \\exp\\left( \\ln(\\hat{s_i}) \\right) = \\exp\\left( \\text{median}_{g \\in \\{1,\\dots,G\\}} \\left\\{ \\ln(x_{ig}) - \\frac{1}{n} \\sum_{j=1}^{n} \\ln(x_{jg}) \\right\\} \\right)\n$$\n指数函数 $\\exp(\\cdot)$ 是严格单调的。这个性质意味着一组数的中位数的指数等于这些数的指数的中位数。即 $\\exp(\\text{median}\\{y_k\\}) = \\text{median}\\{\\exp(y_k)\\}$。应用这个规则，我们可以将指数函数移到中位数算子内部：\n$$\n\\hat{s_i} = \\text{median}_{g \\in \\{1,\\dots,G\\}} \\left\\{ \\exp\\left( \\ln(x_{ig}) - \\frac{1}{n} \\sum_{j=1}^{n} \\ln(x_{jg}) \\right) \\right\\}\n$$\n利用对数和指数的性质，$\\exp(a-b) = \\exp(a)/\\exp(b)$ 和 $\\exp(\\ln(a)) = a$，我们可以简化中位数内的项：\n$$\n\\exp\\left( \\ln(x_{ig}) - \\frac{1}{n} \\sum_{j=1}^{n} \\ln(x_{jg}) \\right) = \\frac{\\exp(\\ln(x_{ig}))}{\\exp\\left(\\frac{1}{n} \\sum_{j=1}^{n} \\ln(x_{jg})\\right)} = \\frac{x_{ig}}{\\left(\\prod_{j=1}^{n} x_{jg}\\right)^{1/n}}\n$$\n将此代回 $\\hat{s_i}$ 的表达式，得到估计量的最终解析形式：\n$$\n\\hat{s_i} = \\text{median}_{g \\in \\{1,\\dots,G\\}} \\left\\{ \\frac{x_{ig}}{\\left(\\prod_{j=1}^{n} x_{jg}\\right)^{1/n}} \\right\\}\n$$\n如要求，该估计量仅依赖于观测计数 $\\{x_{ig}\\}_{g=1}^{G}$ 和 $\\{x_{jg}\\}_{j=1, g=1}^{n, G}$。\n\n现在，我们解释为什么这个估计量能实现所期望的性质。\n\n首先，它消除了采样深度混杂因子。归一化程序将原始计数 $x_{ig}$ 替换为缩放后的计数 $x'_{ig} = x_{ig} / \\hat{s_i}$。该估计量的逻辑基于模型 $x_{ig} \\sim \\text{Poisson}(s_i \\phi_g r_{ig})$ 的假设，这意味着比率 $x_{ig} / (s_i \\phi_g)$ 的期望值以 $r_{ig}$ 为中心。项 $\\left(\\prod_{j=1}^{n} x_{jg}\\right)^{1/n}$ 作为与基因特异性基线 $\\phi_g$ 成正比的量的估计。因此，对于每个基因 $g$，比率 $x_{ig} / \\left(\\prod_{j=1}^{n} x_{jg}\\right)^{1/n}$ 是与 $s_i$ 成正比的量的估计。通过对所有基因的这些比率取中位数，我们获得了采样深度 $s_i$ 的一个稳健估计 $\\hat{s_i}$（相差一个全局缩放常数）。将 $x_{ig}$ 除以 $\\hat{s_i}$ 能有效地去除细胞特异性因子 $s_i$，将所有细胞置于一个可比较的表达尺度上。使用中位数确保了该估计不会被少数具有非常高或非常低的细胞状态依赖性表达（即 $r_{ig} \\ll 1$ 或 $r_{ig} \\gg 1$）的基因所扭曲，而这些基因在细胞命运决定期间是预期会出现的。\n\n其次，它保留了细胞内的相对表达。单个细胞 $i$ 内的相对表达模式由不同基因的表达水平之比决定，例如 $\\theta_{ig_1} / \\theta_{ig_2}$。对此的一个经验代理是观测计数的比率，$x_{ig_1} / x_{ig_2}$。当我们应用归一化时，同一细胞 $i$ 内两个基因 $g_1$ 和 $g_2$ 的缩放后计数的比率是：\n$$\n\\frac{x'_{ig_1}}{x'_{ig_2}} = \\frac{x_{ig_1}/\\hat{s_i}}{x_{ig_2}/\\hat{s_i}} = \\frac{x_{ig_1}}{x_{ig_2}}\n$$\n由于归一化因子 $\\hat{s_i}$ 对于给定细胞 $i$ 内的所有基因都是恒定的，因此它在任何细胞内比率中都完全抵消了。因此，细胞内基因转录本的相对丰度得以保留，这对于基于其独特的基因表达特征来识别细胞类型和状态至关重要。", "answer": "$$\n\\boxed{\\text{median}_{g \\in \\{1,\\dots,G\\}} \\left\\{ \\frac{x_{ig}}{\\left(\\prod_{j=1}^{n} x_{jg}\\right)^{1/n}} \\right\\}}\n$$", "id": "4361230"}, {"introduction": "在单细胞分析中，一个常见的挑战是如何处理不感兴趣的生物变异来源，例如细胞周期，它可能掩盖我们试图研究的细胞命运决定过程。虽然回归校正是一种常用的策略，但它也伴随着风险，特别是当细胞周期信号与命运决定信号不完全正交时。本练习通过一个简化的线性模型，让您定量地探索回归强度如何影响命运相关信号的保留，从而揭示过度校正可能无意中消除关键生物学信息的风险 [@problem_id:4361350]。", "problem": "您正在建模，分析从单细胞RNA测序（scRNA-seq）基因表达测量值中回归去除细胞周期效应，对一维细胞命运信号可恢复性的影响。假设在 $G$ 维基因空间中，对于每个细胞索引 $i \\in \\{1,\\dots,N\\}$，其基因表达向量的线性生成模型如下：\n$$\nx_i = z_i\\, b_f + c_i\\, b_c + \\varepsilon_i,\n$$\n其中 $x_i \\in \\mathbb{R}^G$，$z_i \\in \\mathbb{R}$ 是一个标量潜命运坐标，$c_i \\in \\mathbb{R}$ 是一个标量潜细胞周期坐标，$b_f \\in \\mathbb{R}^G$ 是一个固定的命运载荷向量，$b_c \\in \\mathbb{R}^G$ 是一个固定的细胞周期载荷向量，而 $\\varepsilon_i \\in \\mathbb{R}^G$ 是零均值噪声。您应用一个线性回归步骤，通过线性算子\n$$\nR_\\alpha = I - \\alpha\\, u u^\\top,\n$$\n减去 $x_i$ 沿着单位细胞周期方向 $u \\in \\mathbb{R}^G$ 的分量，以移除细胞周期，其中 $I$ 是 $G \\times G$ 单位矩阵，$u^\\top u = 1$，且 $\\alpha \\in \\mathbb{R}$ 是一个控制回归强度的标量。回归后的表达为 $x_i' = R_\\alpha x_i$。考虑一个理想化情况，其中 $u$ 是真实细胞周期载荷的精确单位方向，即 $u = b_c / \\|b_c\\|$，并关注回归如何影响与命运相关的分量。\n\n从上述定义出发，利用正交投影的线性代数性质，推导一个表达式，表示回归后保留的与命运相关的线性变异的比例，该比例是回归强度 $\\alpha$ 和 $b_f$与$b_c$之间的夹角 $\\phi \\in [0,\\pi]$ 的函数，其中 $\\cos \\phi = \\dfrac{b_f^\\top b_c}{\\|b_f\\| \\,\\|b_c\\|}$。保留的比例应定义为回归后命运载荷向量的平方范数与其原始平方范数之比，即：\n$$\nF(\\alpha,\\phi) \\equiv \\frac{\\|R_\\alpha b_f\\|^2}{\\|b_f\\|^2}.\n$$\n您的推导必须从上述模型和投影定义开始，并且除了标准线性代数之外，不得假设任何专门的公式。\n\n通过在以下参数值测试集上评估 $F(\\alpha,\\phi)$ 来进行敏感性分析，该测试集探索了典型、边界和边缘情况。角度以弧度为单位。\n\n- 测试用例1：$\\phi = \\pi/4$, $\\alpha = 1.0$。\n- 测试用例2：$\\phi = \\pi/2$, $\\alpha = 1.0$。\n- 测试用例3：$\\phi = 0$, $\\alpha = 1.0$。\n- 测试用例4：$\\phi = \\pi/6$, $\\alpha = 1.5$。\n- 测试用例5：$\\phi = \\pi/3$, $\\alpha = 2.0$。\n- 测试用例6：$\\phi = \\pi/8$, $\\alpha = 0.0$。\n\n您的程序必须为每个测试用例计算 $F(\\alpha,\\phi)$，并报告四舍五入到小数点后六位的值。最终输出格式必须是单行，其中包含一个由方括号括起来的、用逗号分隔的六个结果列表，例如 $[r_1,r_2,r_3,r_4,r_5,r_6]$，其中每个 $r_k$ 是一个小数点后有六位的浮点数。", "solution": "我们从线性生成模型和回归算子的定义开始。细胞周期回归算子定义为 $R_\\alpha = I - \\alpha u u^\\top$，其中 $u \\in \\mathbb{R}^G$ 是表示细胞周期方向的单位向量，即 $u^\\top u = 1$。将 $R_\\alpha$ 应用于任何向量会减去该向量沿着 $u$ 方向并按 $\\alpha$ 缩放的分量。命运载荷向量为 $b_f \\in \\mathbb{R}^G$。我们寻求回归后保留的与命运相关的线性变异的比例：\n$$\nF(\\alpha,\\phi) \\equiv \\frac{\\|R_\\alpha b_f\\|^2}{\\|b_f\\|^2}.\n$$\n\n基本依据和假设：\n- 该模型假设命运和细胞周期的贡献是加性的，这是系统生物医学中广泛使用的线性近似。线性回归通过正交投影移除沿指定方向的贡献。\n- 根据题意，$u = b_c / \\|b_c\\|$，因此 $u$ 正是细胞周期的单位方向。我们用 $\\phi$ 表示 $b_f$ 和 $b_c$ 之间的夹角，所以 $\\cos \\phi = \\dfrac{b_f^\\top b_c}{\\|b_f\\| \\,\\|b_c\\|}$。因为 $u$ 与 $b_c$ 共线，我们也有 $u^\\top b_f = \\|b_f\\| \\cos \\phi$。\n\n步骤1：将命运载荷向量分解为平行于 $u$ 和正交于 $u$ 的分量。令\n$$\nb_{f,\\parallel} = (u^\\top b_f)\\, u, \\quad b_{f,\\perp} = b_f - b_{f,\\parallel}.\n$$\n根据构造，$b_{f,\\perp}$ 与 $u$ 正交，即 $u^\\top b_{f,\\perp} = 0$，并且 $b_f = b_{f,\\parallel} + b_{f,\\perp}$。\n\n步骤2：将回归算子应用于 $b_f$。使用 $R_\\alpha = I - \\alpha u u^\\top$ 和分解式，\n$$\nR_\\alpha b_f = (I - \\alpha u u^\\top)(b_{f,\\parallel} + b_{f,\\perp}) = (I - \\alpha u u^\\top) b_{f,\\parallel} + (I - \\alpha u u^\\top) b_{f,\\perp}.\n$$\n因为 $b_{f,\\parallel}$ 与 $u$ 共线，我们有 $u u^\\top b_{f,\\parallel} = b_{f,\\parallel}$，又因为 $b_{f,\\perp}$ 与 $u$ 正交，我们有 $u u^\\top b_{f,\\perp} = 0$。因此，\n$$\nR_\\alpha b_f = (1 - \\alpha) b_{f,\\parallel} + b_{f,\\perp}.\n$$\n\n步骤3：计算 $R_\\alpha b_f$ 的平方范数。平行分量和垂直分量是正交的，所以\n$$\n\\|R_\\alpha b_f\\|^2 = \\|(1 - \\alpha) b_{f,\\parallel} + b_{f,\\perp}\\|^2 = (1 - \\alpha)^2 \\|b_{f,\\parallel}\\|^2 + \\|b_{f,\\perp}\\|^2.\n$$\n\n步骤4：将分量的范数与角度 $\\phi$ 联系起来。我们有 $u^\\top b_f = \\|b_f\\| \\cos \\phi$，所以 $\\|b_{f,\\parallel}\\| = |u^\\top b_f| = \\|b_f\\| |\\cos \\phi|$。因此，\n$$\n\\|b_{f,\\parallel}\\|^2 = \\|b_f\\|^2 \\cos^2 \\phi.\n$$\n根据勾股分解，\n$$\n\\|b_{f,\\perp}\\|^2 = \\|b_f\\|^2 - \\|b_{f,\\parallel}\\|^2 = \\|b_f\\|^2 \\left(1 - \\cos^2 \\phi\\right) = \\|b_f\\|^2 \\sin^2 \\phi.\n$$\n\n步骤5：代入保留比例 $F(\\alpha,\\phi)$。使用以上表达式，\n$$\nF(\\alpha,\\phi) = \\frac{(1 - \\alpha)^2 \\|b_{f,\\parallel}\\|^2 + \\|b_{f,\\perp}\\|^2}{\\|b_f\\|^2} = (1 - \\alpha)^2 \\cos^2 \\phi + \\sin^2 \\phi.\n$$\n在代数上，这也可以写作\n$$\nF(\\alpha,\\phi) = 1 - \\left(2\\alpha - \\alpha^2\\right) \\cos^2 \\phi,\n$$\n这是通过 $\\sin^2 \\phi = 1 - \\cos^2 \\phi$ 以及展开 $(1 - \\alpha)^2 \\cos^2 \\phi$ 得出的。\n\n对敏感性分析的解释：\n- 当 $\\alpha = 0$ (无回归)时，$F(0,\\phi) = 1$，意味着与命运相关的变异没有损失。\n- 当 $\\alpha = 1$ (完全投影减法)时，$F(1,\\phi) = \\sin^2 \\phi$，意味着任何与 $u$ 对齐的命运分量被完全移除；如果 $\\phi = 0$ (共线)，则 $F(1,0) = 0$ (完全擦除)，而如果 $\\phi = \\pi/2$ (正交)，则 $F(1,\\pi/2) = 1$ (无损失)。\n- 当 $\\alpha = 2$ 时，$F(2,\\phi) = 1$，因为平行分量的符号被反转，但其大小被恢复；这表明保留的线性变异大小等于原始大小，尽管平行分量的符号被翻转。\n\n现在在指定的测试集上评估 $F(\\alpha,\\phi)$：\n\n- 测试用例1：$\\phi = \\pi/4$, $\\alpha = 1.0$。我们有 $\\cos^2(\\pi/4) = \\left(\\frac{\\sqrt{2}}{2}\\right)^2 = \\frac{1}{2}$。然后 $2\\alpha - \\alpha^2 = 2 \\cdot 1 - 1^2 = 1$。所以\n$$\nF = 1 - 1 \\cdot \\frac{1}{2} = \\frac{1}{2} = 0.5.\n$$\n- 测试用例2：$\\phi = \\pi/2$, $\\alpha = 1.0$。我们有 $\\cos^2(\\pi/2) = 0$。因此\n$$\nF = 1 - 1 \\cdot 0 = 1.0.\n$$\n- 测试用例3：$\\phi = 0$, $\\alpha = 1.0$。我们有 $\\cos^2(0) = 1$。因此\n$$\nF = 1 - 1 \\cdot 1 = 0.0.\n$$\n- 测试用例4：$\\phi = \\pi/6$, $\\alpha = 1.5$。我们有 $\\cos^2(\\pi/6) = \\left(\\frac{\\sqrt{3}}{2}\\right)^2 = \\frac{3}{4}$。并且 $2\\alpha - \\alpha^2 = 3 - 2.25 = 0.75 = \\frac{3}{4}$。因此\n$$\nF = 1 - \\frac{3}{4} \\cdot \\frac{3}{4} = 1 - \\frac{9}{16} = \\frac{7}{16} = 0.4375.\n$$\n- 测试用例5：$\\phi = \\pi/3$, $\\alpha = 2.0$。我们有 $\\cos^2(\\pi/3) = \\left(\\frac{1}{2}\\right)^2 = \\frac{1}{4}$。并且 $2\\alpha - \\alpha^2 = 4 - 4 = 0$。因此\n$$\nF = 1 - 0 \\cdot \\frac{1}{4} = 1.0.\n$$\n- 测试用例6：$\\phi = \\pi/8$, $\\alpha = 0.0$。我们有 $2\\alpha - \\alpha^2 = 0$。因此对于任何 $\\phi$，\n$$\nF = 1 - 0 \\cdot \\cos^2 \\phi = 1.0.\n$$\n\n因此，要报告的六个结果，每个都四舍五入到小数点后六位，是 $[0.5, 1.0, 0.0, 0.4375, 1.0, 1.0]$，以六位定点小数格式表示为 $[0.500000, 1.000000, 0.000000, 0.437500, 1.000000, 1.000000]$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef preserved_fraction(alpha: float, phi: float) -> float:\n    \"\"\"\n    Compute F(alpha, phi) = 1 - (2*alpha - alpha**2) * cos(phi)**2,\n    the fraction of fate-related linear variation preserved after regression.\n    \"\"\"\n    cos_phi = np.cos(phi)\n    return 1.0 - (2.0 * alpha - alpha ** 2) * (cos_phi ** 2)\n\ndef solve():\n    # Define the test cases from the problem statement as (phi, alpha).\n    test_cases = [\n        (np.pi / 4.0, 1.0),   # Test case 1\n        (np.pi / 2.0, 1.0),   # Test case 2\n        (0.0, 1.0),           # Test case 3\n        (np.pi / 6.0, 1.5),   # Test case 4\n        (np.pi / 3.0, 2.0),   # Test case 5\n        (np.pi / 8.0, 0.0),   # Test case 6\n    ]\n\n    results = []\n    for phi, alpha in test_cases:\n        F = preserved_fraction(alpha, phi)\n        # Round to six decimal places as required\n        results.append(f\"{F:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "4361350"}, {"introduction": "为了真正对细胞命运决定进行建模，我们必须超越静态快照，捕捉其动态过程。RNA速度等前沿方法通过利用未剪接和已剪接mRNA的相对丰度来推断细胞状态的瞬时变化。本练习将引导您为一个描述RNA动力学的混合物模型推导并实现期望最大化（EM）算法，以估计关键的动力学参数，让您亲身体验如何将复杂的动态模型拟合到异质的单细胞数据中 [@problem_id:4361243]。", "problem": "考虑一个单细胞群体，其中信使核糖核酸 (mRNA) 分子通过转录生成未剪接的转录本，然后以一级速率进行剪接，并作为剪接后的转录本被降解。对于单个基因，在以下经过充分检验的动力学假设下，对每个细胞的未剪接和剪接计数进行建模：未剪接丰度根据 $du/dt = \\alpha_z - \\beta u$ 演变，剪接丰度根据 $ds/dt = \\beta u - \\gamma s$ 演变，且未剪接分子的降解可以忽略不计。这里，$\\alpha_z$ 是依赖于离散潜在命运状态 $z \\in \\{A,B\\}$ 的转录速率，$\\beta$ 是剪接速率，$\\gamma$ 是剪接本降解速率。假设在每种命运状态内都处于稳态，因此稳态均值满足 $u^\\star = \\alpha_z / \\beta$ 和 $s^\\star = \\alpha_z / \\gamma$。\n\n每个细胞 $i$ 都有一个已知的文库大小因子 $\\ell_i > 0$，该因子用于缩放其期望计数。在给定潜在命运 $z$ 的条件下，观测到的未剪接计数 $U_i$ 和剪接计数 $S_i$ 被建模为条件独立的泊松随机变量，其均值分别为 $\\mathbb{E}[U_i \\mid z] = \\ell_i \\, u^\\star$ 和 $\\mathbb{E}[S_i \\mid z] = \\ell_i \\, s^\\star$。在所有细胞中，设潜在命运是一个混合模型，状态 $A$ 的混合比例为 $\\pi \\in (0,1)$，状态 $B$ 的混合比例为 $1-\\pi$。动力学速率 $\\beta$ 和 $\\gamma$ 被视为已知常数，需要估计的参数是特定于状态的转录速率 $\\alpha_A > 0$、$\\alpha_B > 0$ 以及混合比例 $\\pi$。\n\n您的任务是：\n- 根据 $\\alpha_A$、$\\alpha_B$ 和 $\\pi$ 构建此动力学混合模型下观测数据的似然函数。\n- 从泊松分布的基本定义和细胞独立性的假设出发，推导一个基于期望最大化 (Expectation-Maximization, EM) 或变分推断 (Variational Inference, VI) 的原则性算法，以得出 $\\alpha_A$、$\\alpha_B$ 和 $\\pi$ 的最大似然估计或变分估计。推导必须从包含潜在分配的完整数据对数似然开始，并导出能够保证证据下界或似然非递减的显式更新方程。\n- 实现所推导的算法，为下面定义的测试套件中的每个数据集估计 $\\alpha_A$、$\\alpha_B$ 和 $\\pi$。在责任更新中，使用对数域中的数值稳定计算。收敛条件为：观测数据对数似然的相对改善小于收敛容差 $\\varepsilon = 10^{-9}$，或达到最大迭代次数 $T_{\\max} = 1000$ 次，以先发生者为准。\n\n测试套件和要求的输出：\n对于下面的三个数据集，使用提供的已知动力学速率 $(\\beta, \\gamma)$、观测到的未剪接计数 $\\{U_i\\}$、观测到的剪接计数 $\\{S_i\\}$、文库大小 $\\{\\ell_i\\}$ 和初始化值 $(\\alpha_A^{(0)}, \\alpha_B^{(0)}, \\pi^{(0)})$。对每个数据集，运行您的算法直到收敛，并返回最终估计值 $(\\hat{\\alpha}_A, \\hat{\\alpha}_B, \\hat{\\pi})$ 以及在这些估计值下计算出的最终观测数据对数似然 $\\mathcal{L}$。最终输出中的所有浮点数必须四舍五入到六位小数。最终输出必须是单行文本，包含一个外部列表和三个内部列表，每个内部列表对应一个数据集，且必须按 $(\\hat{\\alpha}_A, \\hat{\\alpha}_B, \\hat{\\pi}, \\mathcal{L})$ 的顺序包含四个数字。\n\n数据集 1 (命运状态均衡，中等计数):\n- 已知动力学速率: $\\beta = 0.5$, $\\gamma = 0.25$。\n- 文库大小: $\\ell = [1.0,\\,0.8,\\,1.2,\\,0.9,\\,1.1,\\,0.7,\\,1.3,\\,1.0]$。\n- 未剪接计数: $U = [5,\\,3,\\,5,\\,4,\\,14,\\,8,\\,16,\\,13]$。\n- 剪接计数: $S = [9,\\,7,\\,10,\\,7,\\,27,\\,17,\\,30,\\,22]$。\n- 初始化: $\\alpha_A^{(0)} = 1.0$, $\\alpha_B^{(0)} = 5.0$, $\\pi^{(0)} = 0.5$。\n\n数据集 2 (状态 A 占主导，剪接速率较高):\n- 已知动力学速率: $\\beta = 0.7$, $\\gamma = 0.35$。\n- 文库大小: $\\ell = [1.0,\\,0.6,\\,1.4,\\,0.9,\\,1.1,\\,0.5,\\,1.2,\\,0.8,\\,1.3,\\,1.0]$。\n- 未剪接计数: $U = [4,\\,3,\\,6,\\,4,\\,5,\\,2,\\,5,\\,3,\\,17,\\,13]$。\n- 剪接计数: $S = [9,\\,5,\\,12,\\,8,\\,9,\\,5,\\,11,\\,7,\\,33,\\,26]$。\n- 初始化: $\\alpha_A^{(0)} = 2.0$, $\\alpha_B^{(0)} = 10.0$, $\\pi^{(0)} = 0.8$。\n\n数据集 3 (低计数且速率相等的边缘情况):\n- 已知动力学速率: $\\beta = 1.0$, $\\gamma = 1.0$。\n- 文库大小: $\\ell = [0.5,\\,1.0,\\,0.3,\\,1.2,\\,0.7,\\,0.4]$。\n- 未剪接计数: $U = [0,\\,0,\\,0,\\,3,\\,1,\\,1]$。\n- 剪接计数: $S = [0,\\,1,\\,0,\\,2,\\,2,\\,1]$。\n- 初始化: $\\alpha_A^{(0)} = 0.8$, $\\alpha_B^{(0)} = 1.5$, $\\pi^{(0)} = 0.5$。\n\n实现和输出要求：\n- 您的算法必须从第一性原理推导，并且在实现时不使用任何预构建的混合模型例程。它必须在对数域中计算责任以防止数值下溢，并且必须在泊松模型下精确评估观测数据对数似然 $\\mathcal{L}$。\n- 所有计算都必须是无单位的，因为计数是无量纲的，缩放因子 $\\ell_i$ 也是无量纲的。不要引入物理单位。\n- 您的程序应生成单行输出，其中包含一个外部列表和三个内部列表形式的结果。每个内部列表必须按 $(\\hat{\\alpha}_A, \\hat{\\alpha}_B, \\hat{\\pi}, \\mathcal{L})$ 的顺序排列，并且所有值都必须四舍五入到六位小数。输出必须打印为单行，例如一个外部列表，其中包含恰好三个内部列表，无任何附加文本。", "solution": "### 似然公式构建\n设 $\\Theta = \\{\\alpha_A, \\alpha_B, \\pi\\}$ 是待估计的参数集。$N$ 个细胞的观测数据为 $D = \\{(U_i, S_i)\\}_{i=1}^N$。对于每个细胞 $i$，设 $Z_i \\in \\{A, B\\}$ 是指示其命运的潜在变量。\n\n根据模型，对于处于命运状态 $z \\in \\{A, B\\}$ 的细胞 $i$，观测到的计数 $U_i$ 和 $S_i$ 是独立的泊松随机变量，其均值为：\n$$ \\lambda_{i,U,z} = \\ell_i u^\\star_z = \\ell_i \\frac{\\alpha_z}{\\beta} $$\n$$ \\lambda_{i,S,z} = \\ell_i s^\\star_z = \\ell_i \\frac{\\alpha_z}{\\gamma} $$\n给定细胞处于命运状态 $z$ 时，观测到 $(U_i, S_i)$ 的概率为：\n$$ P(U_i, S_i | Z_i=z, \\Theta) = \\text{Poisson}(U_i; \\lambda_{i,U,z}) \\cdot \\text{Poisson}(S_i; \\lambda_{i,S,z}) $$\n根据全概率定律，观测到 $(U_i, S_i)$ 的边缘概率是每种命运状态概率的混合：\n$$ P(U_i, S_i | \\Theta) = P(Z_i=A)P(U_i, S_i | Z_i=A, \\Theta) + P(Z_i=B)P(U_i, S_i | Z_i=B, \\Theta) $$\n$$ P(U_i, S_i | \\Theta) = \\pi P(U_i, S_i | Z_i=A, \\Theta) + (1-\\pi) P(U_i, S_i | Z_i=B, \\Theta) $$\n由于细胞是独立的，观测数据 $D$ 的总似然是各个似然的乘积：\n$$ \\mathcal{L}(\\Theta | D) = \\prod_{i=1}^N P(U_i, S_i | \\Theta) $$\n我们旨在最大化的观测数据对数似然是：\n$$ \\log \\mathcal{L}(\\Theta | D) = \\sum_{i=1}^N \\log \\left[ \\pi P(U_i, S_i | A) + (1-\\pi) P(U_i, S_i | B) \\right] $$\n由于对数内含有和，直接最大化此表达式很困难。期望最大化 (EM) 算法非常适合解决这个问题。\n\n### 期望最大化 (EM) 算法推导\nEM 算法通过在期望 (E) 步和最大化 (M) 步之间交替，迭代地寻找最大似然估计。它使用完整数据对数似然，其中包含了潜在变量 $Z = \\{Z_i\\}_{i=1}^N$。\n\n我们定义一个二元指示变量 $z_{ik}$，如果细胞 $i$ 处于状态 $k \\in \\{A, B\\}$，则 $z_{ik}=1$，否则 $z_{ik}=0$。完整数据对数似然为：\n$$ \\mathcal{L}_c(\\Theta | D, Z) = \\sum_{i=1}^N \\sum_{k \\in \\{A,B\\}} z_{ik} \\log \\left[ P(Z_i=k) P(U_i, S_i | Z_i=k, \\Theta) \\right] $$\n$$ \\mathcal{L}_c(\\Theta | D, Z) = \\sum_{i=1}^N \\left[ z_{iA} (\\log \\pi + \\log P(U_i, S_i | A)) + z_{iB} (\\log(1-\\pi) + \\log P(U_i, S_i | B)) \\right] $$\n对数概率项 $\\log P(U_i, S_i | k)$ 可以展开为：\n$$ \\log P(U_i, S_i | k) = \\log\\text{Poisson}(U_i; \\ell_i \\alpha_k/\\beta) + \\log\\text{Poisson}(S_i; \\ell_i \\alpha_k/\\gamma) $$\n$$ = \\left( U_i \\log(\\ell_i \\alpha_k/\\beta) - \\ell_i \\alpha_k/\\beta \\right) + \\left( S_i \\log(\\ell_i \\alpha_k/\\gamma) - \\ell_i \\alpha_k/\\gamma \\right) - \\log(U_i!) - \\log(S_i!) $$\n按参数对各项进行分组：\n$$ \\log P(U_i, S_i | k) = (U_i+S_i)\\log(\\alpha_k) - \\alpha_k \\ell_i \\left( \\frac{1}{\\beta} + \\frac{1}{\\gamma} \\right) + C_i $$\n其中 $C_i$ 包含与参数 $\\alpha_k$ 和 $\\pi$ 无关的项。\n\n**1. E步（期望）**\n在E步中，我们计算完整数据对数似然关于潜在变量 $Z$ 的后验分布的期望，给定观测数据 $D$ 和当前参数估计 $\\Theta^{(t)}$：\n$$ Q(\\Theta | \\Theta^{(t)}) = E_{Z|D, \\Theta^{(t)}}[\\mathcal{L}_c(\\Theta | D, Z)] $$\n这通过将潜在指示变量 $z_{ik}$ 替换为其后验概率（称为责任）$\\gamma_{ik}$ 来实现：\n$$ \\gamma_{ik}^{(t)} = E[z_{ik} | D, \\Theta^{(t)}] = P(Z_i=k | U_i, S_i, \\Theta^{(t)}) $$\n使用贝叶斯定理：\n$$ \\gamma_{iA}^{(t)} = \\frac{\\pi^{(t)} P(U_i, S_i | A, \\Theta^{(t)})}{\\pi^{(t)} P(U_i, S_i | A, \\Theta^{(t)}) + (1-\\pi^{(t)}) P(U_i, S_i | B, \\Theta^{(t)})} $$\n并且 $\\gamma_{iB}^{(t)} = 1 - \\gamma_{iA}^{(t)}$。为了数值稳定性，这些值使用 log-sum-exp 技巧在对数域中计算。设 $\\log p_{ik} = \\log P(U_i, S_i | k, \\Theta^{(t)})$。\n$$ \\log \\gamma_{ik}^{(t)} = \\log \\pi_k^{(t)} + \\log p_{ik} - \\log\\left( \\sum_{j \\in \\{A,B\\}} \\pi_j^{(t)} P(U_i, S_i | j, \\Theta^{(t)}) \\right) $$\n\n**2. M步（最大化）**\n在M步中，我们找到使 $Q$ 函数最大化的参数 $\\Theta^{(t+1)}$：\n$$ \\Theta^{(t+1)} = \\arg\\max_{\\Theta} Q(\\Theta | \\Theta^{(t)}) $$\n需要最大化的 $Q$ 函数是：\n$$ Q(\\Theta | \\Theta^{(t)}) = \\sum_{i=1}^N \\sum_{k \\in \\{A,B\\}} \\gamma_{ik}^{(t)} \\left[ \\log \\pi_k + (U_i+S_i)\\log\\alpha_k - \\alpha_k \\ell_i(\\frac{1}{\\beta}+\\frac{1}{\\gamma}) \\right] + \\text{const.} $$\n我们分别对 $\\pi$、$\\alpha_A$ 和 $\\alpha_B$ 进行最大化。\n\n**$\\pi$ 的更新**：在约束 $\\pi \\in (0,1)$ 下最大化 $\\sum_i [\\gamma_{iA}^{(t)} \\log \\pi + \\gamma_{iB}^{(t)} \\log(1-\\pi)]$ 得到标准的混合比例更新：\n$$ \\pi^{(t+1)} = \\frac{\\sum_i \\gamma_{iA}^{(t)}}{N} $$\n\n**$\\alpha_k$ 的更新**：我们最大化涉及 $\\alpha_k$ 的项。对于 $\\alpha_A$：\n$$ \\frac{\\partial Q}{\\partial \\alpha_A} = \\sum_{i=1}^N \\gamma_{iA}^{(t)} \\left[ \\frac{U_i+S_i}{\\alpha_A} - \\ell_i\\left(\\frac{1}{\\beta}+\\frac{1}{\\gamma}\\right) \\right] = 0 $$\n求解 $\\alpha_A$ 得到更新规则：\n$$ \\alpha_A^{(t+1)} = \\frac{\\sum_{i=1}^N \\gamma_{iA}^{(t)}(U_i+S_i)}{(\\frac{1}{\\beta}+\\frac{1}{\\gamma})\\sum_{i=1}^N \\gamma_{iA}^{(t)}\\ell_i} $$\n$\\alpha_B$ 的更新是类似的：\n$$ \\alpha_B^{(t+1)} = \\frac{\\sum_{i=1}^N \\gamma_{iB}^{(t)}(U_i+S_i)}{(\\frac{1}{\\beta}+\\frac{1}{\\gamma})\\sum_{i=1}^N \\gamma_{iB}^{(t)}\\ell_i} $$\n\n### 算法实现\n该算法按以下步骤进行：\n1. 初始化参数 $\\Theta^{(0)} = (\\alpha_A^{(0)}, \\alpha_B^{(0)}, \\pi^{(0)})$。\n2. 对 $t = 0, 1, 2, \\ldots, T_{\\max}-1$ 进行迭代：\n   a. 计算观测数据对数似然 $\\mathcal{L}(\\Theta^{(t)}|D)$ 以监控收敛。\n   b. 检查收敛性：如果对数似然的相对增量 $( \\mathcal{L}^{(t)} - \\mathcal{L}^{(t-1)} ) / |\\mathcal{L}^{(t-1)}|$ 低于容差 $\\varepsilon=10^{-9}$，则终止。\n   c. **E步**：使用当前参数 $\\Theta^{(t)}$，为所有细胞 $i=1,\\ldots,N$ 计算责任 $\\gamma_{iA}^{(t)}$ 和 $\\gamma_{iB}^{(t)}$。此操作在对数空间中完成以防止下溢。\n   d. **M步**：使用推导出的更新规则和E步得到的责任，将参数更新为 $\\Theta^{(t+1)} = (\\alpha_A^{(t+1)}, \\alpha_B^{(t+1)}, \\pi^{(t+1)})$。\n   e. 对组分坍缩的特殊处理：如果某个组分的总责任（例如 $\\sum_i \\gamma_{iA}^{(t)}\\ell_i$）实际上为零，则其对应的 $\\alpha$ 参数不会更新，因为它变得无定义。\n3. 终止时，报告最终的参数估计值和观测数据对数似然的最终值。\n\n以下 Python 代码实现了此算法。它使用 `numpy` 进行向量化计算，并使用 `scipy.special.gammaln` 计算泊松概率质量函数 (PMF) 中的对数阶乘项，这对于计算真实的对数似然是必要的。", "answer": "```python\nimport numpy as np\nfrom scipy.special import gammaln\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    \"\"\"\n\n    # --- Test Cases ---\n    test_cases = [\n        {\n            # Dataset 1\n            \"beta\": 0.5, \"gamma\": 0.25,\n            \"l\": np.array([1.0, 0.8, 1.2, 0.9, 1.1, 0.7, 1.3, 1.0]),\n            \"U\": np.array([5, 3, 5, 4, 14, 8, 16, 13]),\n            \"S\": np.array([9, 7, 10, 7, 27, 17, 30, 22]),\n            \"init\": (1.0, 5.0, 0.5)\n        },\n        {\n            # Dataset 2\n            \"beta\": 0.7, \"gamma\": 0.35,\n            \"l\": np.array([1.0, 0.6, 1.4, 0.9, 1.1, 0.5, 1.2, 0.8, 1.3, 1.0]),\n            \"U\": np.array([4, 3, 6, 4, 5, 2, 5, 3, 17, 13]),\n            \"S\": np.array([9, 5, 12, 8, 9, 5, 11, 7, 33, 26]),\n            \"init\": (2.0, 10.0, 0.8)\n        },\n        {\n            # Dataset 3\n            \"beta\": 1.0, \"gamma\": 1.0,\n            \"l\": np.array([0.5, 1.0, 0.3, 1.2, 0.7, 0.4]),\n            \"U\": np.array([0, 0, 0, 3, 1, 1]),\n            \"S\": np.array([0, 1, 0, 2, 2, 1]),\n            \"init\": (0.8, 1.5, 0.5)\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_em_algorithm(\n            U=case[\"U\"],\n            S=case[\"S\"],\n            l=case[\"l\"],\n            beta=case[\"beta\"],\n            gamma=case[\"gamma\"],\n            init_params=case[\"init\"],\n            tol=1e-9,\n            max_iter=1000\n        )\n        results.append(result)\n\n    # Format the final output string\n    output_str = \"[\"\n    for i, res in enumerate(results):\n        alpha_A, alpha_B, pi, log_lik = res\n        output_str += f\"[{alpha_A:.6f},{alpha_B:.6f},{pi:.6f},{log_lik:.6f}]\"\n        if i  len(results) - 1:\n            output_str += \",\"\n    output_str += \"]\"\n\n    print(output_str)\n\ndef log_poisson_pmf(k, lam):\n    \"\"\"\n    Computes the log of the Poisson probability mass function in a numerically stable way.\n    Handles k and lam as numpy arrays.\n    \"\"\"\n    k = np.asarray(k)\n    lam = np.asarray(lam)\n    \n    # Create result array, default to -inf\n    res = np.full(np.broadcast(k, lam).shape, -np.inf, dtype=np.float64)\n\n    # Where lam > 0\n    mask_lam_pos = lam > 0\n    if np.any(mask_lam_pos):\n      k_pos = k[mask_lam_pos]\n      lam_pos = lam[mask_lam_pos]\n      res[mask_lam_pos] = k_pos * np.log(lam_pos) - lam_pos - gammaln(k_pos + 1)\n    \n    # Where lam == 0, log PMF is 0 if k=0, -inf otherwise\n    mask_lam_zero = lam == 0\n    if np.any(mask_lam_zero):\n        res[mask_lam_zero  (k[mask_lam_zero] == 0)] = 0\n    \n    return res\n\ndef run_em_algorithm(U, S, l, beta, gamma, init_params, tol, max_iter):\n    \"\"\"\n    Implements the EM algorithm for the kinetic mixture model.\n    \"\"\"\n    alpha_A, alpha_B, pi = init_params\n    \n    log_likelihood = -np.inf\n    N = len(U)\n    U_plus_S = U + S\n    rate_const = (1.0 / beta) + (1.0 / gamma)\n\n    for i in range(max_iter):\n        prev_log_likelihood = log_likelihood\n\n        # --- E-step (and log-likelihood calculation) ---\n        \n        # Calculate log likelihood of data given each state\n        lam_UA = l * alpha_A / beta\n        lam_SA = l * alpha_A / gamma\n        log_p_A = log_poisson_pmf(U, lam_UA) + log_poisson_pmf(S, lam_SA)\n        \n        lam_UB = l * alpha_B / beta\n        lam_SB = l * alpha_B / gamma\n        log_p_B = log_poisson_pmf(U, lam_UB) + log_poisson_pmf(S, lam_SB)\n\n        # Joint log probabilities (data and state assignment)\n        # Using np.log(0) = -inf is fine here\n        with np.errstate(divide='ignore'):\n            log_joint_A = np.log(pi) + log_p_A\n            log_joint_B = np.log(1.0 - pi) + log_p_B\n        \n        # Marginal log likelihood for each cell (log-sum-exp)\n        log_marginal = np.logaddexp(log_joint_A, log_joint_B)\n        \n        # Total log likelihood\n        log_likelihood = np.sum(log_marginal)\n        \n        # Check for convergence\n        if i > 0:\n            if prev_log_likelihood != -np.inf and abs(prev_log_likelihood) > 1e-9:\n                relative_improvement = (log_likelihood - prev_log_likelihood) / abs(prev_log_likelihood)\n                if relative_improvement  tol:\n                    break\n        \n        # Responsibilities (posterior probabilities of state assignment)\n        log_resp_A = log_joint_A - log_marginal\n        resp_A = np.exp(log_resp_A)\n        resp_B = 1.0 - resp_A\n        \n        # --- M-step ---\n\n        # Update pi\n        sum_resp_A = np.sum(resp_A)\n        pi = sum_resp_A / N\n        \n        # Update alpha_A and alpha_B\n        numer_A = np.sum(resp_A * U_plus_S)\n        denom_A = rate_const * np.sum(resp_A * l)\n        \n        if denom_A > 1e-12:  # Avoid division by zero if a component collapses\n            alpha_A = numer_A / denom_A\n        \n        numer_B = np.sum(resp_B * U_plus_S)\n        denom_B = rate_const * np.sum(resp_B * l)\n\n        if denom_B > 1e-12:\n            alpha_B = numer_B / denom_B\n        \n    # Ensure final log-likelihood corresponds to final parameters\n    lam_UA = l * alpha_A / beta\n    lam_SA = l * alpha_A / gamma\n    log_p_A = log_poisson_pmf(U, lam_UA) + log_poisson_pmf(S, lam_SA)\n    \n    lam_UB = l * alpha_B / beta\n    lam_SB = l * alpha_B / gamma\n    log_p_B = log_poisson_pmf(U, lam_UB) + log_poisson_pmf(S, lam_SB)\n    \n    with np.errstate(divide='ignore'):\n        log_joint_A = np.log(pi) + log_p_A\n        log_joint_B = np.log(1.0 - pi) + log_p_B\n\n    log_marginal = np.logaddexp(log_joint_A, log_joint_B)\n    log_likelihood = np.sum(log_marginal)\n\n    # Return final estimates, maintaining original A/B label identity\n    # Sorting ensures consistent output if labels are swapped\n    if alpha_A > alpha_B:\n        alpha_A, alpha_B = alpha_B, alpha_A\n        pi = 1.0 - pi\n\n    return alpha_A, alpha_B, pi, log_likelihood\n\nif __name__ == '__main__':\n    solve()\n```", "id": "4361243"}]}