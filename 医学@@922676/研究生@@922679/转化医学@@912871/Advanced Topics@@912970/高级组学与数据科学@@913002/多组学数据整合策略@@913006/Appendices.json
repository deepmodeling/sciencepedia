{"hands_on_practices": [{"introduction": "在整合来自不同来源的多组学数据之前，我们必须首先确保这些数据确实来源于同一个患者。在实际操作中，样本标签错误或互换是一个常见且严重的问题，可能导致错误的结论。本实践 [@problem_id:5034034] 将指导您构建一个基于贝叶斯推断的决策流程，通过评估全基因组测序（WGS）和RNA测序（RNA-seq）数据间的基因型一致性，来计算样本匹配与否的后验概率。完成这项练习将使您掌握一项关键的数据整理技能，并深刻理解在进行任何下游分析之前进行严格质量控制的重要性。", "problem": "您的任务是设计并实现一个程序化的决策规则，通过评估全基因组测序（WGS）和RNA测序（RNA-seq）变异检出之间的基因型一致性，来解决患者标识符不匹配的问题。您必须从基础的群体遗传学和概率推断入手，不能使用任何简化的快捷公式。生成模型如下。\n\n基本原理：\n- 假设Hardy–Weinberg平衡。对于一个次要等位基因频率为 $p$ 的双等位基因单核苷酸变异，其真实的二倍体基因型 $t \\in \\{0,1,2\\}$（次要等位基因的数量）分布为 $P(t=0)=(1-p)^2$，$P(t=1)=2p(1-p)$，$P(t=2)=p^2$。\n- 对于每种检测，假设一个对称的基因分型误差模型：给定真实基因型 $t$，观测到的基因型 $g \\in \\{0,1,2\\}$ 等于 $t$ 的概率为 $1-e$，而等于另外两种基因型中任意一种的概率均为 $e/2$，其中 $e$ 是特定检测的错误率。将WGS的错误率记为 $e_w$，RNA-seq的错误率记为 $e_r$。\n- 在不同变异之间，以其真实基因型为条件，观测结果是相互独立的。\n\n匹配与不匹配假设：\n- 在匹配假设 $\\mathcal{M}$ 下，给定变异的WGS和RNA-seq观测值来源于同一个体，共享同一个潜在的真实基因型 $t$；以 $t$ 为条件，这两个观测到的基因型是从同一个 $t$ 以各自的错误率独立生成的。\n- 在不匹配假设 $\\mathcal{U}$ 下，WGS和RNA-seq的观测值来源于从同一群体中抽样的独立个体；等价地，它们的真实基因型是从给定 $p$ 的Hardy–Weinberg分布中独立抽取的，并且每个观测值都是由其自身的真实基因型以相应的检测错误率生成的。\n\n决策框架：\n- 设匹配假设的先验概率为 $\\pi_{\\mathcal{M}} \\in (0,1)$，因此先验几率为 $O_0 = \\pi_{\\mathcal{M}}/(1-\\pi_{\\mathcal{M}})$。\n- 对于一组变异，定义总对数似然比 $\\Lambda$ 为所有变异的“在 $\\mathcal{M}$ 与 $\\mathcal{U}$ 假设下观测到该基因型对”的单变异对数似然比之和，使用上述模型计算。\n- 后验几率为 $O_{\\text{post}} = O_0 \\cdot \\exp(\\Lambda)$，匹配的后验概率为 $\\pi_{\\text{post}} = O_{\\text{post}}/(1+O_{\\text{post}})$。\n- 通过要求 $\\pi_{\\text{post}} \\ge \\tau$ 来设定一个一致性阈值，其中 $\\tau \\in (0,1)$ 是一个指定的目标水平。\n\n您的程序必须：\n1. 对于每个测试用例，使用上述生成模型定义从第一性原理计算总对数似然比 $\\Lambda$，然后计算后验概率 $\\pi_{\\text{post}}$，最后输出一个布尔决策，指示 $\\pi_{\\text{post}} \\ge \\tau$ 是否成立。\n2. 在所有对数计算中使用自然对数（以 $e$ 为底）。\n3. 将所有浮点数输出四舍五入到 $6$ 位小数。\n\n测试套件：\n- 用例A（高一致性的“理想路径”）：$G_w=[0,1,2,1,0,1,2,0]$, $G_r=[0,1,2,1,0,1,1,0]$, $p=[0.05,0.10,0.20,0.15,0.30,0.10,0.25,0.05]$, $e_w=0.01$, $e_r=0.05$, $\\pi_{\\mathcal{M}}=0.5$, $\\tau=0.95$。\n- 用例B（明显不匹配）：$G_w=[0,0,1,2,1,0,2,1,0,2]$, $G_r=[2,1,0,0,2,1,0,1,2,0]$, $p=[0.20,0.40,0.30,0.10,0.25,0.35,0.15,0.05,0.50,0.45]$, $e_w=0.01$, $e_r=0.05$, $\\pi_{\\mathcal{M}}=0.5$, $\\tau=0.95$。\n- 用例C（边界条件，少量变异，中等错误率）：$G_w=[0,1,1,2]$, $G_r=[0,1,0,2]$, $p=[0.30,0.10,0.10,0.40]$, $e_w=0.02$, $e_r=0.08$, $\\pi_{\\mathcal{M}}=0.5$, $\\tau=0.90$。\n\n计算定义：\n- 对于每个变异索引 $i$，令 $p_i$ 表示次要等位基因频率，$g_{w,i}$ 表示WGS基因型，$g_{r,i}$ 表示RNA-seq基因型。\n- 定义 $P_{\\mathcal{M},i}$ 为在 $\\mathcal{M}$ 假设下观测到 $(g_{w,i}, g_{r,i})$ 的概率，通过使用Hardy–Weinberg先验和生成模型对单一真实基因型进行边缘化计算得出。\n- 定义 $P_{\\mathcal{U},i}$ 为在 $\\mathcal{U}$ 假设下观测到 $(g_{w,i}, g_{r,i})$ 的概率，通过将每种检测在Hardy–Weinberg先验和生成模型下各自观测基因型的边际概率相乘得出。\n\n要求的最终输出格式：\n- 您的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表。对于每个测试用例，附加总对数似然比 $\\Lambda$（四舍五入到 $6$ 位小数），后跟阈值决策的布尔值（其中 $True$ 表示 $\\pi_{\\text{post}} \\ge \\tau$）。因此，整体输出格式应为 $[\\Lambda_A,\\text{decision}_A,\\Lambda_B,\\text{decision}_B,\\Lambda_C,\\text{decision}_C]$，不含任何额外文本。", "solution": "该问题要求设计并实现一个程序化的决策规则，通过比较全基因组测序（WGS）和RNA测序（RNA-seq）数据来确定患者样本的一致性。该解决方案基于一个贝叶斯框架，用于评估两个样本来源于同一个体（$\\mathcal{M}$，匹配假设）与来源于两个不同个体（$\\mathcal{U}$，不匹配假设）的后验概率。该实现将完全基于所提供的群体遗传学和概率建模的第一性原理。\n\n解决方案的核心是计算一组遗传变异的总对数似然比 $\\Lambda$。这个量衡量了观测到的基因型数据支持匹配假设而非不匹配假设的证据权重。\n\n**1. 生成模型详述**\n\n概率模型由三个部分定义：\n\n- **Hardy-Weinberg平衡（HWE）先验：**对于一个次要等位基因频率为 $p$ 的双等位基因变异，其真实的二倍体基因型 $t \\in \\{0, 1, 2\\}$（表示次要等位基因的数量）从一个三项分布中抽取，其概率为：\n  $$P(t=0) = (1-p)^2$$\n  $$P(t=1) = 2p(1-p)$$\n  $$P(t=2) = p^2$$\n\n- **对称基因分型误差模型：**在给定真实基因型 $t$ 的条件下，观测到基因型 $g \\in \\{0, 1, 2\\}$ 的概率由特定检测的错误率 $e$ 定义。条件概率 $P(g|t, e)$ 为：\n  $$P(g|t, e) = \\begin{cases} 1-e  \\text{if } g = t \\\\ e/2  \\text{if } g \\neq t \\end{cases}$$\n  我们将WGS和RNA-seq的错误率分别记为 $e_w$ 和 $e_r$。\n\n- **假设条件下的似然：**对于单个变异，观测到的WGS基因型 $g_w$ 和RNA-seq基因型 $g_r$ 在两种假设下具有不同的联合概率：\n  - **匹配假设（$\\mathcal{M}$）：**基因型 $g_w$ 和 $g_r$ 源于一个共享的真实基因型 $t$。以 $t$ 为条件，观测结果是独立的。\n  - **不匹配假设（$\\mathcal{U}$）：**基因型 $g_w$ 和 $g_r$ 源于两个独立的真实基因型 $t_w$ 和 $t_r$，每个都从HWE分布中抽取。\n\n**2. 单变异似然的推导**\n\n对于每个次要等位基因频率为 $p_i$ 且观测基因型为 $(g_{w,i}, g_{r,i})$ 的变异 $i$，我们推导每种假设下的似然。为清晰起见，在以下推导中省略下标 $i$。\n\n- **$\\mathcal{M}$ 假设下的似然：**概率 $P_{\\mathcal{M}}(g_w, g_r)$ 是通过对单一潜在真实基因型 $t$ 进行边缘化得到的：\n  $$P_{\\mathcal{M}}(g_w, g_r) = \\sum_{t=0}^{2} P(g_w, g_r, t | \\mathcal{M})$$\n  通过应用链式法则以及在给定 $t$ 的条件下 $g_w$ 和 $g_r$ 的条件独立性：\n  $$P_{\\mathcal{M}}(g_w, g_r) = \\sum_{t=0}^{2} P(g_w | t, e_w) P(g_r | t, e_r) P(t)$$\n  其中 $P(t)$ 是给定MAF $p$ 的HWE先验概率。\n\n- **$\\mathcal{U}$ 假设下的似然：**概率 $P_{\\mathcal{U}}(g_w, g_r)$ 是每个观测值的边际概率的乘积，这是由于该假设下的独立性假定：\n  $$P_{\\mathcal{U}}(g_w, g_r) = P(g_w | \\mathcal{U}) P(g_r | \\mathcal{U})$$\n  每个边际概率是通过对其自身的潜在真实基因型（$t_w$ 或 $t_r$）进行积分计算的，该基因型从HWE分布中抽取：\n  $$P(g_w | \\mathcal{U}) = \\sum_{t_w=0}^{2} P(g_w | t_w, e_w) P(t_w)$$\n  $$P(g_r | \\mathcal{U}) = \\sum_{t_r=0}^{2} P(g_r | t_r, e_r) P(t_r)$$\n  因此，\n  $$P_{\\mathcal{U}}(g_w, g_r) = \\left( \\sum_{t_w=0}^{2} P(g_w | t_w, e_w) P(t_w) \\right) \\left( \\sum_{t_r=0}^{2} P(g_r | t_r, e_r) P(t_r) \\right)$$\n\n**3. 贝叶斯推断与决策框架**\n\n决策过程使用贝叶斯更新来汇总所有变异的证据。\n\n- **对数似然比：**对于每个变异 $i$，我们计算对数似然比（使用自然对数 $\\log$）：\n  $$\\lambda_i = \\log \\left( \\frac{P_{\\mathcal{M},i}(g_{w,i}, g_{r,i})}{P_{\\mathcal{U},i}(g_{w,i}, g_{r,i})} \\right)$$\n  总对数似然比 $\\Lambda$ 是所有变异的对数似然比之和，假设它们相互独立：\n  $$\\Lambda = \\sum_i \\lambda_i$$\n\n- **后验概率计算：**匹配的先验信念由 $\\pi_{\\mathcal{M}}$ 给出，对应于先验几率 $O_0 = \\pi_{\\mathcal{M}} / (1 - \\pi_{\\mathcal{M}})$。数据中的证据，由似然比 $\\exp(\\Lambda)$ 概括，将先验几率更新为后验几率：\n  $$O_{\\text{post}} = O_0 \\cdot \\exp(\\Lambda)$$\n  后验几率随后被转换回匹配的后验概率 $\\pi_{\\text{post}}$：\n  $$\\pi_{\\text{post}} = \\frac{O_{\\text{post}}}{1 + O_{\\text{post}}}$$\n\n- **决策规则：**如果后验概率达到或超过指定的置信度阈值 $\\tau$，则判定为匹配：\n  $$\\text{Decision} = (\\pi_{\\text{post}} \\ge \\tau)$$\n\n程序将为每个测试用例实现这些计算，得出总对数似然比 $\\Lambda$ 和最终的布尔决策。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the genotype concordance problem for the given test cases.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"id\": \"A\",\n            \"Gw\": [0, 1, 2, 1, 0, 1, 2, 0],\n            \"Gr\": [0, 1, 2, 1, 0, 1, 1, 0],\n            \"p\": [0.05, 0.10, 0.20, 0.15, 0.30, 0.10, 0.25, 0.05],\n            \"ew\": 0.01,\n            \"er\": 0.05,\n            \"pi_M\": 0.5,\n            \"tau\": 0.95,\n        },\n        {\n            \"id\": \"B\",\n            \"Gw\": [0, 0, 1, 2, 1, 0, 2, 1, 0, 2],\n            \"Gr\": [2, 1, 0, 0, 2, 1, 0, 1, 2, 0],\n            \"p\": [0.20, 0.40, 0.30, 0.10, 0.25, 0.35, 0.15, 0.05, 0.50, 0.45],\n            \"ew\": 0.01,\n            \"er\": 0.05,\n            \"pi_M\": 0.5,\n            \"tau\": 0.95,\n        },\n        {\n            \"id\": \"C\",\n            \"Gw\": [0, 1, 1, 2],\n            \"Gr\": [0, 1, 0, 2],\n            \"p\": [0.30, 0.10, 0.10, 0.40],\n            \"ew\": 0.02,\n            \"er\": 0.08,\n            \"pi_M\": 0.5,\n            \"tau\": 0.90,\n        },\n    ]\n\n    results = []\n    \n    def get_p_g_given_t(obs_g, true_t, error_rate):\n        \"\"\"Calculates P(g|t) based on the symmetric error model.\"\"\"\n        if obs_g == true_t:\n            return 1.0 - error_rate\n        else:\n            return error_rate / 2.0\n\n    for case in test_cases:\n        Gw = case[\"Gw\"]\n        Gr = case[\"Gr\"]\n        p_list = case[\"p\"]\n        ew = case[\"ew\"]\n        er = case[\"er\"]\n        pi_M = case[\"pi_M\"]\n        tau = case[\"tau\"]\n\n        total_log_likelihood_ratio = 0.0\n\n        for gw, gr, p in zip(Gw, Gr, p_list):\n            # Hardy-Weinberg prior probabilities for t in {0, 1, 2}\n            p_t_vec = np.array([(1-p)**2, 2*p*(1-p), p**2])\n            \n            p_M = 0.0\n            p_gw_marginal = 0.0\n            p_gr_marginal = 0.0\n\n            for t_idx in range(3):\n                # P(g_w | t) and P(g_r | t)\n                p_gw_given_t = get_p_g_given_t(gw, t_idx, ew)\n                p_gr_given_t = get_p_g_given_t(gr, t_idx, er)\n                \n                # Contribution to P_M (match hypothesis)\n                p_M += p_gw_given_t * p_gr_given_t * p_t_vec[t_idx]\n                \n                # Contribution to marginals for P_U (mismatch hypothesis)\n                p_gw_marginal += p_gw_given_t * p_t_vec[t_idx]\n                p_gr_marginal += p_gr_given_t * p_t_vec[t_idx]\n\n            p_U = p_gw_marginal * p_gr_marginal\n\n            variant_llr = np.log(p_M / p_U)\n            total_log_likelihood_ratio += variant_llr\n\n        # Calculate posterior probability\n        prior_odds = pi_M / (1.0 - pi_M)\n        posterior_odds = prior_odds * np.exp(total_log_likelihood_ratio)\n        posterior_prob = posterior_odds / (1.0 + posterior_odds)\n\n        # Make decision\n        decision = posterior_prob >= tau\n\n        # Append results\n        results.append(f\"{total_log_likelihood_ratio:.6f}\")\n        results.append(str(decision))\n\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "5034034"}, {"introduction": "在确认了样本身份的准确性之后，下一步是在每个组学层面上评估单个样本的数据质量。技术性假象或异常的生物信号都可能扭曲最终的整合分析结果。本练习 [@problem_id:5033985] 将引导您构建一个稳健的质量控制（QC）流程，该流程结合了两种强大的统计方法：利用主成分分析（PCA）的杠杆值（leverage scores）来识别结构性异常样本，以及利用中位数绝对偏差（Median Absolute Deviation, MAD）来识别基于特定质量指标的离群点。通过实现这一流程，您将学会如何系统性地标记跨多个数据集的可疑样本，这是确保多组学研究可靠性的核心技能。", "problem": "您的任务是为转化医学中的多组学整合构建一个质量控制流程，该流程使用主成分分析（PCA）杠杆分数和应用于关键质量度量的中位数绝对偏差（MAD）阈值来检测跨组学的离群样本。该流程必须实现为一个完整的、可运行的程序，不接受任何输入，并产生单行输出。该程序必须为提供的测试套件计算离群值索引。\n\n使用的基础和定义：\n- 设一个组学数据矩阵表示为 $X \\in \\mathbb{R}^{n \\times p}$，其中有 $n$ 个样本（行）和 $p$ 个特征（列）。在后续计算之前，必须将 $X$ 的每一列标准化为零均值和单位方差。\n- 主成分分析（PCA）可以通过奇异值分解（SVD）来定义，$X = U \\Sigma V^\\top$，其中 $U \\in \\mathbb{R}^{n \\times r}$ 和 $V \\in \\mathbb{R}^{p \\times r}$ 的列是标准正交的，$\\Sigma \\in \\mathbb{R}^{r \\times r}$ 是一个对角矩阵，其对角线元素为非负奇异值，且 $r = \\operatorname{rank}(X)$。\n- 对于选定的成分数 $k$，其中 $k \\leq p$，定义到前 $k$ 个左奇异子空间的投影由 $U_k \\in \\mathbb{R}^{n \\times k}$ 表示，如果 $r \\geq k$，则为 $U$ 的前 $k$ 列，否则为 $U_k \\in \\mathbb{R}^{n \\times r}$。样本 $i$ 的PCA杠杆值是到该子空间的投影矩阵的对角元素，$h_i = \\sum_{j=1}^{\\min(k, r)} U_{ij}^2$。\n- 投影矩阵 $H_k = U_k U_k^\\top$ 是对称且幂等的，并满足 $\\operatorname{trace}(H_k) = \\min(k, r)$。因此，平均杠杆值等于 $\\operatorname{trace}(H_k)/n = \\min(k, r)/n$。可以通过将 $h_i$ 与阈值 $\\alpha \\cdot \\min(k, r)/n$ 进行比较来定义基于杠杆值的离群值，其中放大因子 $\\alpha > 1$。\n- 对于一个质量度量向量 $q \\in \\mathbb{R}^n$，定义 $\\operatorname{median}(q)$，中位数绝对偏差 $d_i = |q_i - \\operatorname{median}(q)|$，$\\operatorname{MAD}(q) = \\operatorname{median}(d)$，以及稳健尺度化偏差 $z_i = d_i / (c \\cdot \\operatorname{MAD}(q))$，其中 $c = 1.4826$（正态分布下的一致性常数）。基于度量的离群值是任何满足 $z_i$ 超过阈值 $t$ 的 $i$。\n- 跨组学整合：给定 $O$ 个组学矩阵 $\\{X^{(o)}\\}_{o=1}^O$，为每个样本 $i$ 定义跨组学的杠杆值超限计数 $C^{\\text{lev}}_i$，以及跨所提供度量的度量超限计数 $C^{\\text{met}}_i$。如果对于给定的整数阈值 $\\theta$ 和 $\\phi$，满足 $C^{\\text{lev}}_i \\geq \\theta$ 或 $C^{\\text{met}}_i \\geq \\phi$ 中任一条件，则样本 $i$ 被标记为整合离群值。\n\n实现要求：\n- 将每个组学矩阵按列标准化为零均值和单位方差；如果某一列的方差为零，则将其标准化值视为全零。\n- 使用上述基于SVD的定义，通过 $U_k$ 和 $h_i$ 计算PCA杠杆值。\n- 使用基于MAD的稳健偏差计算质量度量离群值。如果 $\\operatorname{MAD}(q) = 0$，则该度量没有离群值，除非有任何 $q_i \\neq \\operatorname{median}(q)$；在后一种情况下，将那些 $q_i \\neq \\operatorname{median}(q)$ 的样本视为离群值。\n- 使用0-基索引报告离群样本的索引。\n\n测试套件：\n- 测试用例1（通用多组学，其中一个组学和度量中存在明显离群值）：\n    - 样本数：$n = 6$；组学数：$O = 3$；成分数 $k = 2$；杠杆值放大因子 $\\alpha = 2.0$；杠杆值计数阈值 $\\theta = 1$；度量阈值 $t = 3.0$；度量计数阈值 $\\phi = 1$。\n    - 基因组学矩阵 $X^{(1)}$ ($6 \\times 4$):\n      $\n      \\begin{bmatrix}\n      0.5  1.0  -0.3  0.2 \\\\\n      0.6  0.8  -0.1  0.0 \\\\\n      0.4  1.1  -0.2  0.1 \\\\\n      0.5  0.9  -0.3  0.2 \\\\\n      0.6  1.0  -0.2  0.3 \\\\\n      0.5  0.95  -0.25  0.15\n      \\end{bmatrix}\n      $\n    - 转录组学矩阵 $X^{(2)}$ ($6 \\times 5$):\n      $\n      \\begin{bmatrix}\n      10  12  9  11  10 \\\\\n      11  12  9  10  11 \\\\\n      10  11  10  11  10 \\\\\n      10  12  9  11  10 \\\\\n      11  11  9  10  12 \\\\\n      10  12  10  11  11\n      \\end{bmatrix}\n      $\n    - 蛋白质组学矩阵 $X^{(3)}$ ($6 \\times 3$):\n      $\n      \\begin{bmatrix}\n      0  0  1 \\\\\n      0  0  1 \\\\\n      0  0  1 \\\\\n      10  10  1 \\\\\n      0  0  1 \\\\\n      0  0  1\n      \\end{bmatrix}\n      $\n    - 质量度量：\n      - 度量1（例如，RNA质量）：$[8.0,\\, 8.2,\\, 7.9,\\, 3.0,\\, 8.1,\\, 8.0]$\n      - 度量2（例如，文库大小）：$[5{,}000{,}000,\\, 5{,}100{,}000,\\, 4{,}900{,}000,\\, 1{,}000{,}000,\\, 5{,}200{,}000,\\, 5{,}000{,}000]$\n    - 预期行为：一个单一的整合离群值，对应于离群的蛋白质组学样本和度量。\n- 测试用例2（边界条件：零方差特征且无度量偏差）：\n    - $n = 4$, $O = 2$, $k = 2$, $\\alpha = 2.0$, $\\theta = 1$, $t = 3.0$, $\\phi = 1$。\n    - 组学矩阵 $X^{(1)} = X^{(2)} = \\begin{bmatrix}1  2  3 \\\\ 1  2  3 \\\\ 1  2  3 \\\\ 1  2  3 \\end{bmatrix}$\n    - 质量度量：\n      - 度量1：$[10,\\, 10,\\, 10,\\, 10]$\n      - 度量2：$[100,\\, 100,\\, 100,\\, 100]$\n    - 预期行为：无整合离群值。\n- 测试用例3（边缘案例：仅通过度量产生的离群值）：\n    - $n = 5$, $O = 2$, $k = 2$, $\\alpha = 2.0$, $\\theta = 2$, $t = 3.0$, $\\phi = 2$。\n    - 组学矩阵：\n      - $X^{(1)} = \\begin{bmatrix} 1  2 \\\\ 1  2 \\\\ 1.1  1.9 \\\\ 0.9  2.1 \\\\ 1  2 \\end{bmatrix}$\n      - $X^{(2)} = \\begin{bmatrix} 5  5 \\\\ 5  5 \\\\ 5.1  4.9 \\\\ 4.9  5.1 \\\\ 5  5 \\end{bmatrix}$\n    - 质量度量：\n      - 度量1：$[0.1,\\, 5.0,\\, 0.2,\\, 0.1,\\, 0.0]$\n      - 度量2：$[100,\\, 1000,\\, 105,\\, 98,\\, 97]$\n    - 预期行为：一个通过度量产生的单一整合离群值（第二个样本）。\n输出规范：\n- 您的程序应产生单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。每个结果必须是对应测试用例中被标记为整合离群值的样本的0-基索引列表。例如，形式为 $[[i\\_1, i\\_2],[\\,], [j]]$ 的输出是有效的。最终输出必须精确地打印为单行上的一个Python列表的列表字面量，不带任何附加文本。", "solution": "该问题在科学上基于已建立的统计方法（主成分分析杠杆值，中位数绝对偏差），问题设定良好，具有确定性算法，语言客观，并且在数据和参数的规范上是完整的。该问题是转化医学中多组学数据质量控制领域一个可形式化且相关的任务。不存在矛盾、违反科学原理之处，也没有会妨碍唯一、可验证解的歧义。\n\n以下是一个完整的、经过推理的解决方案。\n\n### **算法流程**\n\n该质量控制流程通过整合两种不同类型的统计度量来识别离群样本，这两种度量分别是基于PCA的杠杆分数和基于MAD的稳健偏差，它们被应用于多个组学数据集和质量度量向量。对于给定的测试用例，流程如下。\n\n**1. 初始化**\n设 $n$ 为样本数。初始化两个整数向量来存储每个样本的离群值计数：\n- $C^{\\text{lev}} \\in \\mathbb{Z}^n$，初始化为零，用于计算基于杠杆值的离群值标记数。\n- $C^{\\text{met}} \\in \\mathbb{Z}^n$，初始化为零，用于计算基于度量的离群值标记数。\n\n**2. 基于杠杆值的离群值检测（每个组学数据集）**\n对于 $O$ 个组学数据矩阵中的每一个 $X^{(o)} \\in \\mathbb{R}^{n \\times p}$，其中 $o \\in \\{1, \\dots, O\\}$：\n\n**a. 标准化：**\n将 $X^{(o)}$ 的每一列 $j$ 标准化，使其均值为 $0$，标准差为 $1$。设 $X^{(o)}_{:,j}$ 为第 $j$ 列。计算其均值 $\\mu_j$ 和标准差 $\\sigma_j$。标准化的列 $X'^{(o)}_{:,j}$ 由下式给出：\n$$\nX'^{(o)}_{i,j} = \\begin{cases} (X^{(o)}_{i,j} - \\mu_j) / \\sigma_j  \\text{if } \\sigma_j > 0 \\\\ 0  \\text{if } \\sigma_j = 0 \\end{cases}\n$$\n这会创建标准化矩阵 $X'^{(o)}$。\n\n**b. 奇异值分解 (SVD)：**\n计算标准化矩阵的SVD：$X'^{(o)} = U^{(o)} \\Sigma^{(o)} (V^{(o)})^\\top$。这里，$U^{(o)} \\in \\mathbb{R}^{n \\times n}$ 是左奇异向量矩阵。\n\n**c. 秩与成分选择：**\n确定矩阵的秩，$r^{(o)} = \\operatorname{rank}(X'^{(o)})$。这对应于非零奇异值的数量。要考虑的主成分数量为 $k' = \\min(k, r^{(o)})$，其中 $k$ 是用户指定的成分数。我们将 $U_{k'}^{(o)}$ 定义为包含 $U^{(o)}$ 前 $k'$ 列的矩阵。\n\n**d. 杠杆值计算：**\n每个样本 $i \\in \\{1, \\dots, n\\}$ 的杠杆分数 $h_i^{(o)}$ 是 $U_{k'}^{(o)}$ 第 $i$ 行元素平方和：\n$$\nh_i^{(o)} = \\sum_{j=1}^{k'} (U^{(o)}_{ij})^2\n$$\n\n**e. 离群值标记：**\n基于平均杠杆值计算杠杆值阈值 $\\tau_{\\text{lev}}^{(o)}$：\n$$\n\\tau_{\\text{lev}}^{(o)} = \\frac{\\alpha \\cdot k'}{n}\n$$\n其中 $\\alpha$ 是给定的放大因子。如果一个样本的杠杆值 $h_i^{(o)}$ 超过此阈值，则其杠杆值离群值计数 $C^{\\text{lev}}_i$ 增加：\n$$\n\\text{if } h_i^{(o)} > \\tau_{\\text{lev}}^{(o)}, \\text{ then } C^{\\text{lev}}_i \\leftarrow C^{\\text{lev}}_i + 1\n$$\n\n**3. 基于度量的离群值检测（每个质量度量）**\n对于每个提供的质量度量向量 $q \\in \\mathbb{R}^n$：\n\n**a. 中位数与中位数绝对偏差 (MAD)：**\n计算度量的中位数，$m = \\operatorname{median}(q)$。计算所有样本与中位数的绝对偏差，$d_i = |q_i - m|$。MAD是这些绝对偏差的中位数：$\\operatorname{MAD}(q) = \\operatorname{median}(d)$。\n\n**b. 离群值标记：**\n标记离群值的方法取决于 $\\operatorname{MAD}(q)$ 的值：\n- 如果 $\\operatorname{MAD}(q) > 0$：为每个样本计算稳健尺度化偏差 $z_i$：\n  $$\n  z_i = \\frac{d_i}{c \\cdot \\operatorname{MAD}(q)} = \\frac{|q_i - \\operatorname{median}(q)|}{1.4826 \\cdot \\operatorname{MAD}(q)}\n  $$\n  如果 $z_i$ 超过度量阈值 $t$，则样本的度量离群值计数 $C^{\\text{met}}_i$ 增加。\n- 如果 $\\operatorname{MAD}(q) = 0$：任何度量值 $q_i$ 不等于中位数 $m$ 的样本 $i$ 都被视为离群值。对于每个这样的样本，$C^{\\text{met}}_i$ 增加。如果所有 $q_i$ 都等于中位数，则该度量不会标记任何离群值。\n\n**4. 整合离群值识别**\n处理完所有组学矩阵和质量度量后，通过将其累积计数 $C^{\\text{lev}}_i$ 和 $C^{\\text{met}}_i$ 与各自的整数阈值 $\\theta$ 和 $\\phi$ 进行比较，来确定每个样本 $i$ 的最终离群状态：\n$$\n\\text{样本 } i \\text{ 是整合离群值，如果 } (C^{\\text{lev}}_i \\geq \\theta) \\lor (C^{\\text{met}}_i \\geq \\phi)\n$$\n满足此条件的所有样本的0-基索引被收集起来，作为该测试用例的最终结果。\n\n---\n### **应用于测试用例**\n\n**测试用例 1**\n- 参数：$n=6, O=3, k=2, \\alpha=2.0, \\theta=1, t=3.0, \\phi=1$。\n- **杠杆值：**\n  - 对于 $X^{(1)}$ 和 $X^{(2)}$，数据点相对同质。标准化后，SVD产生的杠杆分数中没有单个样本占主导地位。秩为 $r^{(1)}=4$ 和 $r^{(2)}=5$。则 $k' = \\min(2,4)=2$ 和 $k'=\\min(2,5)=2$。阈值为 $\\tau_{\\text{lev}}^{(1)} = 2.0 \\cdot 2 / 6 \\approx 0.667$ 和 $\\tau_{\\text{lev}}^{(2)} = 2.0 \\cdot 2 / 6 \\approx 0.667$。计算出的所有 $h_i^{(1)}$ 和 $h_i^{(2)}$ 值都低于此阈值。\n  - 对于 $X^{(3)}$，第4个样本（索引3）是异常的：$[10, 10, 1]$。标准化后，矩阵的秩为 $r^{(3)}=1$。因此，$k'=\\min(2,1)=1$。杠杆值阈值为 $\\tau_{\\text{lev}}^{(3)} = 2.0 \\cdot 1 / 6 \\approx 0.333$。杠杆值大约为 $h^{(3)} = [0.038, 0.038, 0.038, 0.769, 0.038, 0.038]$。只有 $h_3^{(3)} \\approx 0.769 > 0.333$。\n  - 杠杆值计数为 $C^{\\text{lev}} = [0, 0, 0, 1, 0, 0]$。\n- **度量：**\n  - 度量1：$q = [8.0, 8.2, 7.9, 3.0, 8.1, 8.0]$。中位数为 $8.0$。偏差为 $[0.0, 0.2, 0.1, 5.0, 0.1, 0.0]$。MAD为 $0.1$。样本4（索引3）的z-分数为 $z_3 = 5.0 / (1.4826 \\cdot 0.1) \\approx 33.72 > 3.0$。\n  - 度量2：$q = [5\\text{e}6, 5.1\\text{e}6, 4.9\\text{e}6, 1\\text{e}6, 5.2\\text{e}6, 5\\text{e}6]$。中位数为 $5\\text{e}6$。MAD为 $1\\text{e}5$。样本4的z-分数为 $z_3 = 4\\text{e}6 / (1.4826 \\cdot 1\\text{e}5) \\approx 26.98 > 3.0$。\n  - 度量计数为 $C^{\\text{met}} = [0, 0, 0, 2, 0, 0]$。\n- **整合：**\n  - 对于样本4（索引3）：$C^{\\text{lev}}_3=1 \\geq \\theta=1$ 且 $C^{\\text{met}}_3=2 \\geq \\phi=1$。该样本是离群值。\n  - 对于所有其他样本 $i \\neq 3$，$C^{\\text{lev}}_i=0  \\theta=1$ 且 $C^{\\text{met}}_i=0  \\phi=1$。它们不是离群值。\n- **结果：** `[3]`\n\n**测试用例 2**\n- 参数：$n=4, O=2, k=2, \\alpha=2.0, \\theta=1, t=3.0, \\phi=1$。\n- **杠杆值：**\n  - $X^{(1)}$ 和 $X^{(2)}$ 都由相同的行组成。每列的标准差均为 $0$。\n  - 根据规则，两个标准化矩阵 $X'^{(1)}$ 和 $X'^{(2)}$ 都是零矩阵。\n  - 零矩阵的秩为 $r=0$。因此 $k'=\\min(2, 0)=0$。\n  - 杠杆分数 $h_i$ 全为 $0$，阈值 $\\tau_{\\text{lev}}$ 也为 $0$。条件 $h_i  \\tau_{\\text{lev}}$ 永远不满足。\n  - 杠杆值计数为 $C^{\\text{lev}} = [0, 0, 0, 0]$。\n- **度量：**\n  - 两个度量向量 $[10, 10, 10, 10]$ 和 $[100, 100, 100, 100]$ 都由相同的值组成。\n  - 对于两者，中位数都是该常数值，所有偏差都是 $0$，因此MAD也是 $0$。\n  - 适用 $\\operatorname{MAD}=0$ 的特殊情况。由于没有 $q_i$ 与中位数不同，因此没有标记离群值。\n  - 度量计数为 $C^{\\text{met}} = [0, 0, 0, 0]$。\n- **整合：**\n  - 对于所有样本，$C^{\\text{lev}}_i=0$ 且 $C^{\\text{met}}_i=0$。条件 $C^{\\text{lev}}_i \\geq 1$ 或 $C^{\\text{met}}_i \\geq 1$ 永远不满足。\n- **结果：** `[]`\n\n**测试用例 3**\n- 参数：$n=5, O=2, k=2, \\alpha=2.0, \\theta=2, t=3.0, \\phi=2$。\n- **杠杆值：**\n  - 矩阵 $X^{(1)}$ 和 $X^{(2)}$ 由非常相似的样本组成。\n  - 对于 $X^{(1)}$，$r^{(1)}=2, k'=2$。$\\tau_{\\text{lev}}^{(1)} = 2.0 \\cdot 2 / 5 = 0.8$。所有 $h_i^{(1)}$ 均低于此阈值。\n  - 对于 $X^{(2)}$，$r^{(2)}=2, k'=2$。$\\tau_{\\text{lev}}^{(2)} = 2.0 \\cdot 2 / 5 = 0.8$。所有 $h_i^{(2)}$ 均低于此阈值。\n  - 在任何组学中都没有样本被标记为杠杆值离群值。杠杆值计数为 $C^{\\text{lev}} = [0, 0, 0, 0, 0]$。\n- **度量：**\n  - 度量1：$q = [0.1, 5.0, 0.2, 0.1, 0.0]$。中位数为 $0.1$。MAD为 $0.1$。样本2（索引1）的z-分数为 $z_1 = 4.9 / (1.4826 \\cdot 0.1) \\approx 33.05  3.0$。样本2是离群值。\n  - 度量2：$q = [100, 1000, 105, 98, 97]$。中位数为 $100$。MAD为 $3$。样本2的z-分数为 $z_1 = 900 / (1.4826 \\cdot 3) \\approx 202.41  3.0$。样本2是离群值。\n  - 度量计数为 $C^{\\text{met}} = [0, 2, 0, 0, 0]$。\n- **整合：**\n  - 阈值较高：$\\theta=2, \\phi=2$。\n  - 对于样本2（索引1）：$C^{\\text{lev}}_1=0  \\theta=2$，但 $C^{\\text{met}}_1=2 \\geq \\phi=2$。该样本是离群值。\n  - 对于所有其他样本，计数都太低。\n- **结果：** `[1]`", "answer": "```python\nimport numpy as np\nfrom scipy.linalg import svd\n\ndef solve():\n    \"\"\"\n    Main function to run the multi-omics outlier detection pipeline on a predefined test suite.\n    \"\"\"\n    \n    test_cases = [\n        # Test Case 1\n        {\n            \"params\": {\"n\": 6, \"O\": 3, \"k\": 2, \"alpha\": 2.0, \"theta\": 1, \"t\": 3.0, \"phi\": 1},\n            \"omics_data\": [\n                np.array([\n                    [0.5, 1.0, -0.3, 0.2],\n                    [0.6, 0.8, -0.1, 0.0],\n                    [0.4, 1.1, -0.2, 0.1],\n                    [0.5, 0.9, -0.3, 0.2],\n                    [0.6, 1.0, -0.2, 0.3],\n                    [0.5, 0.95, -0.25, 0.15]\n                ]),\n                np.array([\n                    [10, 12, 9, 11, 10],\n                    [11, 12, 9, 10, 11],\n                    [10, 11, 10, 11, 10],\n                    [10, 12, 9, 11, 10],\n                    [11, 11, 9, 10, 12],\n                    [10, 12, 10, 11, 11]\n                ]),\n                np.array([\n                    [0, 0, 1],\n                    [0, 0, 1],\n                    [0, 0, 1],\n                    [10, 10, 1],\n                    [0, 0, 1],\n                    [0, 0, 1]\n                ])\n            ],\n            \"quality_metrics\": [\n                np.array([8.0, 8.2, 7.9, 3.0, 8.1, 8.0]),\n                np.array([5_000_000, 5_100_000, 4_900_000, 1_000_000, 5_200_000, 5_000_000])\n            ]\n        },\n        # Test Case 2\n        {\n            \"params\": {\"n\": 4, \"O\": 2, \"k\": 2, \"alpha\": 2.0, \"theta\": 1, \"t\": 3.0, \"phi\": 1},\n            \"omics_data\": [\n                np.array([[1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3]]),\n                np.array([[1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3]])\n            ],\n            \"quality_metrics\": [\n                np.array([10, 10, 10, 10]),\n                np.array([100, 100, 100, 100])\n            ]\n        },\n        # Test Case 3\n        {\n            \"params\": {\"n\": 5, \"O\": 2, \"k\": 2, \"alpha\": 2.0, \"theta\": 2, \"t\": 3.0, \"phi\": 2},\n            \"omics_data\": [\n                np.array([[1, 2], [1, 2], [1.1, 1.9], [0.9, 2.1], [1, 2]]),\n                np.array([[5, 5], [5, 5], [5.1, 4.9], [4.9, 5.1], [5, 5]])\n            ],\n            \"quality_metrics\": [\n                np.array([0.1, 5.0, 0.2, 0.1, 0.0]),\n                np.array([100, 1000, 105, 98, 97])\n            ]\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        params = case[\"params\"]\n        n = params[\"n\"]\n        k = params[\"k\"]\n        alpha = params[\"alpha\"]\n        theta = params[\"theta\"]\n        t_thresh = params[\"t\"]\n        phi = params[\"phi\"]\n        \n        c_lev = np.zeros(n, dtype=int)\n        c_met = np.zeros(n, dtype=int)\n\n        # Leverage-based outlier detection\n        for X in case[\"omics_data\"]:\n            # Standardize matrix\n            mean = np.mean(X, axis=0)\n            std = np.std(X, axis=0)\n            X_std = np.zeros_like(X, dtype=float)\n            for j in range(X.shape[1]):\n                if std[j] > 1e-9: # Use tolerance for float comparison\n                    X_std[:, j] = (X[:, j] - mean[j]) / std[j]\n            \n            # SVD and rank\n            try:\n                # Rank is number of singular values greater than a tolerance\n                rank = np.linalg.matrix_rank(X_std)\n                if rank == 0:\n                    continue\n                U, s, Vh = svd(X_std, full_matrices=False)\n            except np.linalg.LinAlgError:\n                continue\n\n            num_components = min(k, rank)\n            if num_components == 0:\n                continue\n\n            # Leverage calculation\n            U_k = U[:, :num_components]\n            h = np.sum(U_k**2, axis=1)\n            \n            # Leverage outlier flagging\n            leverage_threshold = alpha * num_components / n\n            c_lev[h > leverage_threshold] += 1\n\n        # Metric-based outlier detection\n        c_consistency = 1.4826\n        for q in case[\"quality_metrics\"]:\n            median_q = np.median(q)\n            deviations = np.abs(q - median_q)\n            mad_q = np.median(deviations)\n\n            if mad_q > 1e-9: # Use tolerance for float comparison\n                z_scores = deviations / (c_consistency * mad_q)\n                c_met[z_scores > t_thresh] += 1\n            else:\n                # Special case for MAD == 0\n                c_met[q != median_q] += 1\n        \n        # Integrated outlier identification\n        integrated_outliers = np.where((c_lev >= theta) | (c_met >= phi))[0].tolist()\n        results.append(integrated_outliers)\n    \n    # Using str representation and join for the final output format.\n    output_str = f\"[{','.join(map(str, results))}]\"\n    print(output_str.replace(\" \", \"\"))\n\nsolve()\n```", "id": "5033985"}, {"introduction": "当拥有了经过严格清洗和验证的数据后，我们便可以着手进行核心的数据整合任务。相似性网络融合（Similarity Network Fusion, SNF）是一种强大的“中期整合”策略，它通过融合为每个组学数据构建的“患者-患者”相似性网络来整合信息。这项综合性实践 [@problem_id:5034014] 将指导您从零开始实现SNF算法，您将学习如何使用高斯核函数构建相似性网络，然后通过一种迭代式的“信息传递”机制来更新这些网络，直到它们收敛成一个单一、全面的融合网络。这项练习将让您深入理解如何将一个复杂的算法转化为实用代码，并体会如何协同利用不同组学数据的互补信息，以揭示更全面的患者间相似性规律。", "problem": "实现一个完整、自包含的程序，该程序构建一个多组学相似性网络融合 (SNF) 管道，以整合跨多个组学的患者-患者相似性网络，并为每个提供的测试用例返回一个单一的融合亲和矩阵。算法步骤必须源自基本且经过充分测试的原理：基于距离的相似性、高斯核、最近邻图、随机归一化以及带收敛准则的图上迭代消息传递。您的实现必须严格遵循下述过程和定义，并以指定格式精确生成输出。\n\n对于每个测试用例，给定一组特定组学的患者特征矩阵和标量超参数。设有 $M$ 个组学（数据视图），每个由一个实值矩阵 $X^{(m)} \\in \\mathbb{R}^{N \\times p_m}$ 表示（$m \\in \\{1,\\dots,M\\}$），其中 $N$ 是患者数量，$p_m$ 是组学 $m$ 中的特征数量。目标是生成一个单一的融合亲和矩阵 $F \\in \\mathbb{R}^{N \\times N}$，该矩阵使用迭代消息传递整合所有组学的相似性，直到收敛或达到最大迭代次数。\n\n基本定义和必需步骤，必须完全按照所述实现：\n\n1. Z-score 标准化（逐个组学和逐个特征）：\n   - 对每个组学 $m$ 和每个特征（列）$j \\in \\{1,\\dots,p_m\\}$，计算所有患者（行）的均值 $\\mu_{m,j}$ 和标准差 $\\sigma_{m,j}$。通过 $\\tilde{X}^{(m)}_{i,j} = \\frac{X^{(m)}_{i,j} - \\mu_{m,j}}{\\sigma_{m,j}}$ 将 $X^{(m)}_{:,j}$ 转换为 $\\tilde{X}^{(m)}_{:,j}$。如果 $\\sigma_{m,j} = 0$，则将 $\\tilde{X}^{(m)}_{:,j}$ 设置为零向量。\n   - 统计学中广泛使用标准化来消除尺度差异，以确保特征和组学之间的可比性，这证明了此步骤的合理性。\n\n2. 每个组学内部的成对平方欧几里得距离：\n   - 对每个组学 $m$，计算 $D^{(m)} \\in \\mathbb{R}^{N \\times N}$，其元素为 $D^{(m)}_{ij} = \\sum_{l=1}^{p_m} \\left(\\tilde{X}^{(m)}_{i,l} - \\tilde{X}^{(m)}_{j,l}\\right)^2$。\n\n3. 高斯核相似性：\n   - 给定一个正带宽参数 $\\sigma  0$（每个测试用例提供），通过以下公式定义 $G^{(m)} \\in \\mathbb{R}^{N \\times N}$：\n     $$G^{(m)}_{ij} = \\exp\\left( - \\frac{D^{(m)}_{ij}}{2 \\sigma^2} \\right)。$$\n   - 对所有 $i$，设置 $G^{(m)}_{ii} = 1$。\n\n4. $k$-最近邻稀疏化和对称化：\n   - 设 $k$ 为一个正整数，满足 $1 \\le k \\le N-1$（每个测试用例提供）。对于 $G^{(m)}$ 中的每一行 $i$，识别出 $k$ 个最大的非对角线元素 $G^{(m)}_{ij}$（其中 $j \\neq i$）的索引；如果出现平局，则首先通过较小的索引 $j$ 来打破。创建一个稀疏矩阵 $S^{(m)}_{\\text{mask}}$，每行（非对角线）仅保留这 $k$ 个邻居，并将其余非对角线元素置零。然后对称化：\n     $$W^{(m)} = \\frac{S^{(m)}_{\\text{mask}} + \\left(S^{(m)}_{\\text{mask}}\\right)^{\\top}}{2}，$$\n     最后对所有 $i$ 设置对角线元素 $W^{(m)}_{ii} = 1$。\n\n5. 行随机归一化：\n   - 通过将行归一化使其总和为 $1$，将 $W^{(m)}$ 转换为行随机矩阵 $P^{(m,0)}$：\n     $$P^{(m,0)}_{ij} = \\frac{W^{(m)}_{ij}}{\\sum_{j'=1}^{N} W^{(m)}_{ij'}}。$$\n     如果行和为 $0$，则用所有列上的均匀分布替换该行，即对所有 $j$，$P^{(m,0)}_{ij} = \\frac{1}{N}$。\n\n6. 固定邻居约束的传播矩阵：\n   - 从 $P^{(m,0)}$ 出发，构建固定传播矩阵 $S^{(m)}$。方法是：将除每行相同的 $k$ 个非对角线最近邻（基于 $P^{(m,0)}$ 中的数值大小，平局由较小的索引打破）之外的所有元素置零，然后将每行归一化使其总和为 $1$：\n     $$S^{(m)}_{ij} = \\begin{cases}\n     \\frac{P^{(m,0)}_{ij}}{\\sum_{j' \\in \\mathcal{N}^{(m)}_k(i)} P^{(m,0)}_{ij'}}  \\text{如果 } j \\in \\mathcal{N}^{(m)}_k(i),\\ j \\neq i,\\\\\n     0  \\text{其他情况,}\n     \\end{cases}$$\n     其中 $\\mathcal{N}^{(m)}_k(i)$ 是在 $P^{(m,0)}$ 中为 $i$ 选择的 $k$ 个非对角线邻居的索引集。如果分母为 $0$，则对所有 $j$ 设置 $S^{(m)}_{ij} = \\frac{1}{N}$。\n\n7. 迭代消息传递（融合）：\n   - 对于 $t = 0,1,2,\\dots$，将每个视图更新为\n     $$P^{(m,t+1)} = S^{(m)} \\left( \\frac{1}{M-1} \\sum_{\\substack{v=1 \\\\ v \\ne m}}^{M} P^{(v,t)} \\right) \\left(S^{(m)}\\right)^{\\top},$$\n     随后按照步骤 5 对 $P^{(m,t+1)}$ 进行行随机归一化。\n   - 对于 $M = 1$ 的情况，跳过此迭代更新，并将步骤 5 后的单个视图定义为融合矩阵。\n\n8. 收敛准则和终止：\n   - 将第 $t$ 次迭代的变化定义为\n     $$\\Delta^{(t)} = \\max_{m \\in \\{1,\\dots,M\\}} \\left\\| P^{(m,t+1)} - P^{(m,t)} \\right\\|_F,$$\n     其中 $\\|\\cdot\\|_F$ 是弗罗贝尼乌斯范数。给定一个容差 $\\varepsilon  0$ 和最大迭代次数 $T_{\\max} \\in \\mathbb{N}$（两者均提供），在第一个满足 $\\Delta^{(t)} \\le \\varepsilon$ 的 $t$ 或当 $t+1 = T_{\\max}$ 时停止迭代，以先发生者为准。\n\n9. 融合矩阵：\n   - 终止后，定义\n     $$F = \\frac{1}{M} \\sum_{m=1}^{M} P^{(m,t_{\\text{final}})}。$$\n     按照步骤 5 对 $F$ 进行行归一化，使其成为行随机矩阵。\n\n10. 每个测试用例的必需输出：\n    - 将 $F$ 按行主序展开成一个包含 $N \\times N$ 个实数的列表。将每个条目四舍五入到恰好 $6$ 位小数（定点表示，非科学记数法）。\n\n程序输入固定在您的代码中，且必须包含以下测试套件。对于每个测试用例，您必须使用给定的组学矩阵和超参数 $(k,\\ \\sigma,\\ \\varepsilon,\\ T_{\\max})$ 实现上述步骤：\n\n- 测试用例 1 (正常路径)：\n  - $N = 4$, $M = 2$, $k = 2$, $\\sigma = 1.0$, $\\varepsilon = 1\\times 10^{-6}$, $T_{\\max} = 50$.\n  - 组学 1：$X^{(1)} \\in \\mathbb{R}^{4 \\times 2}$，行数据为\n    $[0.0, 1.0]$, $[0.2, 0.9]$, $[3.0, 3.5]$, $[3.2, 3.6]$。\n  - 组学 2：$X^{(2)} \\in \\mathbb{R}^{4 \\times 2}$，行数据为\n    $[0.1, 1.1]$, $[0.0, 1.0]$, $[3.1, 3.4]$, $[3.3, 3.7]$。\n\n- 测试用例 2 (单组学边界情况)：\n  - $N = 4$, $M = 1$, $k = 1$, $\\sigma = 0.7$, $\\varepsilon = 1\\times 10^{-6}$, $T_{\\max} = 10$.\n  - 组学 1：$X^{(1)} \\in \\mathbb{R}^{4 \\times 3}$，行数据为\n    $[1.0, 0.0, 0.5]$, $[0.9, 0.1, 0.4]$, $[3.0, 3.5, 3.7]$, $[3.1, 3.6, 3.8]$。\n\n- 测试用例 3 (通过大容差提前停止)：\n  - $N = 5$, $M = 2$, $k = 2$, $\\sigma = 1.5$, $\\varepsilon = 10^{9}$, $T_{\\max} = 20$.\n  - 组学 1：$X^{(1)} \\in \\mathbb{R}^{5 \\times 2}$，行数据为\n    $[0.0, 0.0]$, $[0.1, -0.1]$, $[5.0, 5.0]$, $[5.1, 4.9]$, $[2.5, 2.5]$。\n  - 组学 2：$X^{(2)} \\in \\mathbb{R}^{5 \\times 2}$，行数据为\n    $[0.2, -0.2]$, $[0.0, 0.0]$, $[4.9, 5.1]$, $[5.2, 5.0]$, $[2.4, 2.6]$。\n\n- 测试用例 4 (迭代次数边界)：\n  - $N = 3$, $M = 3$, $k = 2$, $\\sigma = 1.0$, $\\varepsilon = 1\\times 10^{-12}$, $T_{\\max} = 1$.\n  - 组学 1：$X^{(1)} \\in \\mathbb{R}^{3 \\times 2}$，行数据为\n    $[0.0, 0.0]$, $[1.0, 1.0]$, $[2.0, 2.0]$。\n  - 组学 2：$X^{(2)} \\in \\mathbb{R}^{3 \\times 2}$，行数据为\n    $[0.0, 0.1]$, $[1.0, 1.1]$, $[1.9, 2.1]$。\n  - 组学 3：$X^{(3)} \\in \\mathbb{R}^{3 \\times 3}$，行数据为\n    $[0.0, 1.0, 2.0]$, $[1.0, 2.0, 3.0]$, $[2.0, 3.0, 4.0]$。\n\n您的程序必须遵循上述步骤 1 到 9，为每个测试用例计算融合矩阵 $F$，然后按照步骤 10 的规定展开并四舍五入 $F$。\n\n最终输出格式要求：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果（例如，$\\big[$结果_1,结果_2,结果_3,结果_4$\\big]$）。在此，每个结果本身必须是一个包含 $N \\times N$ 个浮点数的列表（展开的融合矩阵），四舍五入到恰好 $6$ 位小数，并以定点表示法打印，不使用科学记数法。不允许有多余的文本或行。", "solution": "该问题提供了一个有效的问题陈述。它具有科学依据，定义明确，客观且完整。该问题要求实现相似性网络融合 (SNF) 算法，这是一种用于整合多组学数据的生物信息学前沿方法。该过程基于统计学、数值分析和图论的既定原理。提供的测试用例定义明确，可以对实现进行确定性验证。\n\n该解决方案涉及逐步实现指定的 SNF 管道。其核心思想是将每个组学数据集转换为一个患者-患者相似性网络，然后迭代地融合这些网络，以生成一个单一、全面的网络，该网络捕获了在多种数据类型中得到强化的相似性。\n\n### 算法设计与原理\n\n实现被设计为一个模块化函数，用于执行规定的操作序列。\n\n1.  **数据标准化 (Z-score)：**\n    对于每种组学数据类型 $m \\in \\{1,\\dots,M\\}$（由矩阵 $X^{(m)} \\in \\mathbb{R}^{N \\times p_m}$ 表示），我们首先对数据进行标准化。标准化是一个关键的预处理步骤，以确保数值范围较大的特征不会不成比例地影响下游的距离计算。对于每个特征（列）$j$，我们计算其在 $N$ 个患者上的均值 $\\mu_{m,j}$ 和标准差 $\\sigma_{m,j}$。然后根据 Z-score 公式对每个条目进行转换：\n    $$ \\tilde{X}^{(m)}_{i,j} = \\frac{X^{(m)}_{i,j} - \\mu_{m,j}}{\\sigma_{m,j}} $$\n    在特殊情况下，如果一个特征在所有患者中都是恒定的，其标准差 $\\sigma_{m,j}$ 为 $0$。为防止除以零并使该特征不提供信息（因为它没有方差），根据问题规范，相应的转换后特征向量 $\\tilde{X}^{(m)}_{:,j}$ 被设置为零向量。\n\n2.  **成对相似性网络构建：**\n    标准化之后，我们将每个组学的基于特征的表示转换为患者-患者相似性网络。这是一个两阶段的过程。首先，对于每个组学 $m$，我们计算成对平方欧几里得距离矩阵 $D^{(m)} \\in \\mathbb{R}^{N \\times N}$，其中每个元素 $D^{(m)}_{ij}$ 衡量患者 $i$ 和患者 $j$ 在标准化特征空间中的不相似性：\n    $$ D^{(m)}_{ij} = \\sum_{l=1}^{p_m} \\left(\\tilde{X}^{(m)}_{i,l} - \\tilde{X}^{(m)}_{j,l}\\right)^2 $$\n    接下来，使用高斯相似性核（也称为径向基函数 (RBF) 核）将这些距离转换为亲和度。这会创建亲和矩阵 $G^{(m)} \\in \\mathbb{R}^{N \\times N}$：\n    $$ G^{(m)}_{ij} = \\exp\\left( - \\frac{D^{(m)}_{ij}}{2 \\sigma^2} \\right) $$\n    超参数 $\\sigma$ 是核带宽，它控制亲和度随距离衰减的速度。此函数将距离（从 $0$ 到 $\\infty$）映射到相似性（从 $1$ 到 $0$）。对角线元素 $G^{(m)}_{ii}$ 被明确设置为 $1$，表示最大自身相似性。\n\n3.  **网络稀疏化与对称化：**\n    真实世界的网络通常是稀疏的。为了反映这一点并移除微弱、可能是伪造的连接来对网络进行去噪，我们对每个患者仅保留与其 $k$-最近邻的连接。对于每个患者 $i$，我们识别出对应于 $k$ 个最大亲和度值 $G^{(m)}_{ij}$（其中 $j \\neq i$）的其他 $k$ 个患者 $j$。平局通过优先选择索引 $j$ 较小的邻居来打破。这会产生一个有向 k-NN 图。由于相似性本质上是一个对称概念，该图被对称化以产生一个无向加权邻接矩阵 $W^{(m)}$：\n    $$ W^{(m)} = \\frac{S^{(m)}_{\\text{mask}} + \\left(S^{(m)}_{\\text{mask}}\\right)^{\\top}}{2} $$\n    这里，$S^{(m)}_{\\text{mask}}$ 是一个矩阵，它保留了 $G^{(m)}$ 每行中 $k$ 个最近邻的亲和度值，其他地方为零。对角线元素 $W^{(m)}_{ii}$ 被设置为 $1$。\n\n4.  **随机归一化与传播矩阵构建：**\n    亲和矩阵 $W^{(m)}$ 被转换为行随机矩阵 $P^{(m,0)}$，其中每行之和为 $1$。这是通过将每个元素除以其行和来实现的：\n    $$ P^{(m,0)}_{ij} = \\frac{W^{(m)}_{ij}}{\\sum_{j'=1}^{N} W^{(m)}_{ij'}} $$\n    如果行和为零（即一个患者没有邻居），则用均匀分布 $P^{(m,0)}_{ij} = 1/N$ 替换该行。这些矩阵可以解释为图上随机游走的转移概率矩阵。\n    同时，我们构建固定的传播矩阵 $S^{(m)}$。这些是编码每个网络局部邻域结构的稀疏行随机矩阵。$S^{(m)}$ 是从 $P^{(m,0)}$ 派生出来的，方法是为每行 $i$ 仅保留其 $k$-最近邻（由 $P^{(m,0)}$ 中的值确定）对应的条目，并将这些条目重新归一化使其总和为 $1$。这个矩阵 $S^{(m)}$ 将在融合过程中充当固定滤波器来传播信息。\n\n5.  **迭代网络融合：**\n    融合是通过迭代的跨网络扩散过程实现的，这是一种消息传递的形式。在每次迭代 $t$ 中，每个网络 $P^{(m,t)}$ 都基于所有其他网络的信息进行更新。更新规则是：\n    $$ P^{(m,t+1)} = S^{(m)} \\left( \\frac{1}{M-1} \\sum_{\\substack{v=1 \\\\ v \\ne m}}^{M} P^{(v,t)} \\right) \\left(S^{(m)}\\right)^{\\top} $$\n    括号中的项是第 $t$ 次迭代时所有其他网络的平均值。然后，这个平均网络通过前乘 $S^{(m)}$ 和后乘其转置，被网络 $m$ 的局部结构所“过滤”。这一步有效地加强了由多个数据源支持的相似性，导致网络逐渐变得更加相似。每次更新后，$P^{(m,t+1)}$ 都被重新归一化为行随机矩阵。对于单组学情况（$M=1$），此过程被跳过。\n\n6.  **收敛与最终融合：**\n    迭代过程持续进行，直到网络稳定或达到最大迭代次数 $T_{\\max}$。通过使用弗罗贝尼乌斯范数测量连续迭代之间的变化来评估稳定性。如果所有网络的最大变化量低于容差 $\\varepsilon$，则过程在第 $t$ 次迭代时终止：\n    $$ \\Delta^{(t)} = \\max_{m \\in \\{1,\\dots,M\\}} \\left\\| P^{(m,t+1)} - P^{(m,t)} \\right\\|_F \\le \\varepsilon $$\n    在 $t_{\\text{final}}$ 终止时，通过对收敛的网络求平均来计算最终的融合网络 $F$：\n    $$ F = \\frac{1}{M} \\sum_{m=1}^{M} P^{(m,t_{\\text{final}})} $$\n    这个最终矩阵也经过行归一化，以产生最终的患者-患者相似性网络。最终得到的矩阵 $F$ 代表了患者相似性的一个综合视图，整合了来自所有 $M$ 个组学的证据。\n\n7.  **输出格式化：**\n    最终的融合矩阵 $F$ 按行主序展开为一维列表，并且根据要求，每个元素都四舍五入到 6 位小数。", "answer": "```python\nimport numpy as np\nfrom scipy.spatial.distance import pdist, squareform\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and run the SNF pipeline, printing the final results.\n    \"\"\"\n\n    def normalize_rows(matrix):\n        \"\"\"\n        Row-normalizes a matrix to be row-stochastic.\n        If a row sum is 0, it is replaced with a uniform distribution.\n        \"\"\"\n        N = matrix.shape[0]\n        row_sums = matrix.sum(axis=1, keepdims=True)\n        normalized_matrix = matrix.copy()\n        \n        non_zero_rows = row_sums.flatten() > 0\n        if np.any(non_zero_rows):\n            normalized_matrix[non_zero_rows, :] /= row_sums[non_zero_rows]\n        \n        zero_rows = ~non_zero_rows\n        if np.any(zero_rows):\n            normalized_matrix[zero_rows, :] = 1.0 / N\n            \n        return normalized_matrix\n\n    def get_k_nearest_neighbor_mask(A, k):\n        \"\"\"\n        Determines the k-nearest-neighbor mask for a given affinity matrix.\n        Tie-breaking is done by smaller column index.\n        \"\"\"\n        N = A.shape[0]\n        mask = np.zeros((N, N), dtype=bool)\n\n        for i in range(N):\n            row_values = A[i, :]\n            # Get off-diagonal elements and their original indices\n            off_diag_indices = np.arange(N) != i\n            off_diag_vals = row_values[off_diag_indices]\n            off_diag_j_indices = np.arange(N)[off_diag_indices]\n\n            # Use lexsort for stable sorting: sort by -value (desc), then index (asc)\n            sorted_indices = np.lexsort((off_diag_j_indices, -off_diag_vals))\n            \n            # Identify the top k original column indices\n            top_k_j_indices = off_diag_j_indices[sorted_indices[:k]]\n            mask[i, top_k_j_indices] = True\n            \n        return mask\n\n    def run_snf_for_case(X_list, k, sigma, eps, T_max):\n        \"\"\"\n        Executes the complete Similarity Network Fusion (SNF) pipeline for a single test case.\n        \"\"\"\n        N = X_list[0].shape[0]\n        M = len(X_list)\n\n        # Step 1: Z-scoring per omic and per feature\n        X_std_list = []\n        for X_m in X_list:\n            mean = np.mean(X_m, axis=0)\n            std = np.std(X_m, axis=0)\n            X_tilde_m = np.zeros_like(X_m, dtype=float)\n            \n            non_zero_std_mask = std > 0\n            if np.any(non_zero_std_mask):\n                X_tilde_m[:, non_zero_std_mask] = (X_m[:, non_zero_std_mask] - mean[non_zero_std_mask]) / std[non_zero_std_mask]\n            \n            X_std_list.append(X_tilde_m)\n\n        # Step 2: Pairwise squared Euclidean distance\n        D_list = [squareform(pdist(X_std, metric='sqeuclidean')) for X_std in X_std_list]\n\n        # Step 3: Gaussian kernel similarity\n        G_list = []\n        for D_m in D_list:\n            G_m = np.exp(-D_m / (2 * sigma**2))\n            np.fill_diagonal(G_m, 1)\n            G_list.append(G_m)\n\n        # Step 4: k-nearest neighbor sparsification and symmetrization\n        W_list = []\n        for G_m in G_list:\n            knn_mask = get_k_nearest_neighbor_mask(G_m, k)\n            S_mask_matrix = np.zeros_like(G_m)\n            S_mask_matrix[knn_mask] = G_m[knn_mask]\n            \n            W_m = (S_mask_matrix + S_mask_matrix.T) / 2\n            np.fill_diagonal(W_m, 1)\n            W_list.append(W_m)\n\n        # Step 5: Row-stochastic normalization\n        P0_list = [normalize_rows(W_m) for W_m in W_list]\n\n        if M == 1:\n            # For M=1, result is the single normalized network\n            final_fused_matrix = normalize_rows(P0_list[0])\n            flat_rounded = [f\"{x:.6f}\" for x in final_fused_matrix.flatten()]\n            return f\"[{','.join(flat_rounded)}]\"\n\n        # Step 6: Fixed neighbor-constrained propagation matrices\n        S_list = []\n        for P0_m in P0_list:\n            S_m = np.zeros_like(P0_m)\n            knn_mask = get_k_nearest_neighbor_mask(P0_m, k)\n            for i in range(N):\n                neighbor_indices = np.where(knn_mask[i, :])[0]\n                denominator = P0_m[i, neighbor_indices].sum()\n                if denominator > 0:\n                    S_m[i, neighbor_indices] = P0_m[i, neighbor_indices] / denominator\n                else:\n                    S_m[i, :] = 1.0 / N\n            S_list.append(S_m)\n            \n        # Step 7  8: Iterative message passing and convergence\n        P_current = [p.copy() for p in P0_list]\n        for t in range(T_max):\n            P_next = [np.zeros_like(p) for p in P_current]\n            sum_P_current = sum(P_current) if M > 1 else P_current[0]\n            \n            for m in range(M):\n                avg_others = (sum_P_current - P_current[m]) / (M - 1)\n                P_next_m_unnorm = S_list[m] @ avg_others @ S_list[m].T\n                P_next[m] = normalize_rows(P_next_m_unnorm)\n\n            max_diff = 0\n            for m in range(M):\n                diff = np.linalg.norm(P_next[m] - P_current[m], 'fro')\n                max_diff = max(max_diff, diff)\n            \n            P_current = P_next\n            \n            if max_diff = eps:\n                break\n\n        # Step 9: Fused matrix\n        F_unnorm = sum(P_current) / M\n        final_fused_matrix = normalize_rows(F_unnorm)\n\n        # Step 10: Required output formatting\n        flat_rounded = [f\"{x:.6f}\" for x in final_fused_matrix.flatten()]\n        return f\"[{','.join(flat_rounded)}]\"\n\n    test_cases = [\n        {\n            \"X_list\": [\n                np.array([[0.0, 1.0], [0.2, 0.9], [3.0, 3.5], [3.2, 3.6]], dtype=float),\n                np.array([[0.1, 1.1], [0.0, 1.0], [3.1, 3.4], [3.3, 3.7]], dtype=float)\n            ],\n            \"k\": 2, \"sigma\": 1.0, \"eps\": 1e-6, \"T_max\": 50\n        },\n        {\n            \"X_list\": [\n                np.array([[1.0, 0.0, 0.5], [0.9, 0.1, 0.4], [3.0, 3.5, 3.7], [3.1, 3.6, 3.8]], dtype=float)\n            ],\n            \"k\": 1, \"sigma\": 0.7, \"eps\": 1e-6, \"T_max\": 10\n        },\n        {\n            \"X_list\": [\n                np.array([[0.0, 0.0], [0.1, -0.1], [5.0, 5.0], [5.1, 4.9], [2.5, 2.5]], dtype=float),\n                np.array([[0.2, -0.2], [0.0, 0.0], [4.9, 5.1], [5.2, 5.0], [2.4, 2.6]], dtype=float)\n            ],\n            \"k\": 2, \"sigma\": 1.5, \"eps\": 1e9, \"T_max\": 20\n        },\n        {\n            \"X_list\": [\n                np.array([[0.0, 0.0], [1.0, 1.0], [2.0, 2.0]], dtype=float),\n                np.array([[0.0, 0.1], [1.0, 1.1], [1.9, 2.1]], dtype=float),\n                np.array([[0.0, 1.0, 2.0], [1.0, 2.0, 3.0], [2.0, 3.0, 4.0]], dtype=float)\n            ],\n            \"k\": 2, \"sigma\": 1.0, \"eps\": 1e-12, \"T_max\": 1\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result_str = run_snf_for_case(\n            case[\"X_list\"], case[\"k\"], case[\"sigma\"], case[\"eps\"], case[\"T_max\"]\n        )\n        results.append(result_str)\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "5034014"}]}