## 引言
在转化医学的广阔领域中，真实世界数据（RWD）正以前所未有的深度和广度，重塑我们对疾病、疗效和医疗实践的认知。这些源于日常临床环境的数据蕴含着巨大的潜力，然而，从海量、原始的RWD中提炼出可信的真实世界证据（RWE）并非易事。研究面临的核心挑战在于如何跨越原始数据与可靠因果结论之间的鸿沟，这不仅需要数据处理技术，更需要对数据生成机制和因果推断方法的深刻理解。本文旨在系统性地解决这一知识差距。在接下来的内容中，我们将首先在“原理与机制”一章中，奠定RWD与RWE的基础，剖析主要数据源的特性，并探讨数据质量、标准化以及因果推断中的核心方法论挑战。随后，在“应用与跨学科连接”一章中，我们将展示这些原理如何在药物评估、卫生经济学和[精准医疗](@entry_id:152668)等前沿领域中得到实际应用，并介绍高级分析方法。最后，“动手实践”部分将提供具体练习，帮助您巩固所学知识。通过这一结构化的学习路径，您将掌握从RWD生成可靠RWE的全过程。

## 原理与机制

在转化医学研究中，真实世界数据（Real-world Data, RWD）的价值日益凸显。这些数据源于常规临床实践，为理解疾病、治疗效果和医疗服务模式提供了前所未有的机遇。然而，要将这些原始数据转化为可靠的真实世界证据（Real-world Evidence, RWE），需要研究者不仅掌握数据科学技术，更需深刻理解这些数据生成的底层原理及其在因果推断中所固有的复杂挑战。本章旨在系统阐述支撑 RWE 生成的核心原理与机制，从基本概念、数据源特性，到[数据质量](@entry_id:185007)、标准化，再到因果推断中的关键方法论挑战，为研究者构建一个严谨的知识框架。

### 基础概念：真实世界数据与真实世界证据

首先，我们必须精确界定真实世界数据（RWD）与真实世界证据（RWE）。**真实世界数据**（RWD）指在常规医疗实践中收集的、与患者健康状况和/或医疗服务提供相关的数据。这些数据并非为了特定的研究方案而生成，其来源多种多样，包括电子健康记录（Electronic Health Records, EHRs）、行政医疗理赔数据（administrative claims）、疾病登记（disease registries）等。与此相对，**真实世界证据**（RWE）是基于对 RWD 的恰当分析而产生的、关于医疗产品的使用情况、潜在获益或风险的临床证据。生成 RWE 的过程并非简单的数据汇总，而是一个以明确定义的因果估计目标（causal estimand）为指引，并采用严谨分析方法的过程。

RWD 与随机对照试验（Randomized Controlled Trials, RCTs）的数据在性质上存在根本差异，这直接影响了它们各自证据的优势与局限。RCTs 通过**随机化**分配处理（例如，药物或安慰剂），旨在确保处理组与[对照组](@entry_id:188599)在所有基线特征（无论是已测量还是未测量）上具有可比性。因此，在理想情况下，RCTs 能够实现极高的**内部有效性**（internal validity），即在研究人群内部对因果效应的估计是可信的。然而，为了维持严格的实验控制，RCTs 通常设定了严格的入组和排除标准，可能排除了许多在真实世界中常见的患者类型（如多病共存、高龄等），这可能限制了其研究结果向更广泛目标人群推广的能力，即其**外部有效性**（external validity）可能受限。

相比之下，RWD 通常来源于更具异质性的人群和更多样化的临床实践场景，因此，基于 RWD 的分析在外部有效性方面具有天然优势。然而，RWD 的核心挑战在于其非随机化的数据生成过程，这使得研究的内部有效性面临巨大威胁。为了从 RWD 中得出可靠的因果结论，即生成 RWE，我们必须依赖一套可信的因果识别条件，将观察到的数据分布与我们真正关心的反事实结果联系起来。这些条件主要包括：

1.  **[可交换性](@entry_id:263314)（Exchangeability）**：在给定一组已测量的协变量 $X$ 的条件下，处理组和非处理组的反事实结果是独立的。形式化地，对于处理分配 $A$ 和[潜在结果](@entry_id:753644) $Y(a)$（即在处理为 $a$ 时的结果），该条件表示为 $Y(a) \perp\!\!\!\perp A \mid X$。在 RCTs 中，随机化保证了无条件的可交换性（$Y(a) \perp\!\!\!\perp A$）。在 RWD 分析中，我们则希望通过设计（如限制研究人群）或统计学调整（如匹配、分层、加权）来使得条件可交换性假设变得合理。

2.  **正性（Positivity）**：对于任何具有特定协变量 $X=x$ 的个体，他们接受或不接受处理的概率都大于零。形式化地，对于所有相关的 $x$，$\mathbb{P}(A=a \mid X=x) > 0$。这个条件确保了在数据的每个子层中都存在接受不同处理的个体，从而使得比较成为可能。

3.  **一致性（Consistency）**：一个个体实际观察到的结果 $Y$ 等于其在实际接受的处理 $A$ 下的潜在结果 $Y(A)$。这个假设要求处理的定义必须明确且无歧义，即不存在多种版本的处理。

只有当这三个核心假设被可信地满足时，对 RWD 的分析才能被视为产生了关于因果效应的 RWE。仅仅对 RWD 进行描述性统计，而未能阐明因果估计目标并验证这些识别条件，其结果不能构成因果证据 [@problem_id:5054770]。

### 主要真实世界数据源剖析

理解不同 RWD 的生成机制是评估其适用性和局限性的前提。以下我们将剖析几种最重要的数据源。

#### 电子健康记录（EHRs）

EHRs 是临床诊疗活动的数字化副产品，记录了患者与医疗系统交互的丰富细节。理解 EHR 内部不同数据对象的含义至关重要。

-   **就诊（Encounter）**：这是一个有明确开始和结束时间的医疗服务事件，如一次住院或一次门诊。它构成了特定时间段内所有临床事件的容器，为数据提供了时序上下文。
-   **问题列表（Problem List）**：这是一个由临床医生维护的、纵向记录患者当前和历史重要医疗状况、诊断和问题的列表。它是一个在患者层面进行管理的动态记录。
-   **用药医嘱（Medication Order）**：通过计算机化医嘱录入系统（CPOE）记录的、旨在提供或施用药物的指令。这代表了治疗的**意图**。
-   **用药执行记录（Medication Administration）**：通常由护士在用药执行记录系统（MAR）中记录的、药物实际给予患者的事件。它包含了药物、剂量、途径和精确的时间戳，代表了医嘱的**执行**或已实现的治疗。
-   **检验结果（Laboratory Result）**：来自诊断性检测的结构化观测值，通常包含数值、单位和参考范围。
-   **临床文书（Clinical Note）**：由临床医生撰写的叙事性文本，用以记录其观察、思考过程和计划，本质上是非结构化的。

在进行研究时，必须深刻理解这些数据对象在认知地位（epistemic status）上的差异。例如，在确定患者是否真正接受了某种药物治疗时，**用药医嘱**（$O(t)$）仅代表治疗意图，而**用药执行记录**（$A(t)$）则记录了实际的给药行为。由于医嘱可能因各种原因（如患者病情变化、拒绝用药等）而未被执行，因此 $A(t)$ 相对于 $O(t)$，为确定患者的真实暴露状态 $E(t)$ 提供了更强有力的证据。换言之，用药执行记录在确认暴露方面具有更高的认知地位 [@problem_id:5054530]。

#### 行政医疗理赔数据

与 EHRs 源于临床工作流不同，行政医疗理赔数据（简称“理赔数据”）是为支付和报销目的而产生的。其生成过程围绕着医疗服务提供方向支付方（如保险公司）提交账单并获得支付。

-   **审理（Adjudication）**：这是支付方处理提交的理赔申请的流程。该过程会审核服务项目、诊断和程序代码的有效性，并最终确定支付金额。这个过程可以被形式化地理解为一个函数 $g$，它将提交的理赔记录映射到最终审定的记录。
-   **允许金额（Allowed Amount）** 与 **支付金额（Paid Amount）**：审理后的理赔记录包含关键的财务字段。“允许金额”是支付方根据与医疗服务提供方的合同为某项服务设定的最高报销额度。“支付金额”是支付方实际支付的部分。通常，支付金额小于或等于允许金额，差额部分由患者自付（如免赔额、共付额等）。
-   **参保期（Enrollment Periods）**：理赔数据只能捕获患者在特定健康保险计划中处于有效参保状态期间发生的医疗服务。这个参保期 $[t_a, t_b]$ 定义了研究中的**可观察时间窗口**。在此之前（左截断）或之后（右截断）发生的事件通常无法被观察到。

在证据价值方面，理赔数据与 EHRs 各有优劣。在确定药物暴露方面，基于药品理赔（pharmacy claim）的暴露代理变量 $X^{*}_{\text{claims}}$（表示药物已被药房分发）通常被认为比基于 EHR 医嘱的暴露代理变量 $X^{*}_{\text{EHR}}$ 更可靠，因为它更接近药物的实际获取。在确定结局事件方面，对于如“住院”这类会产生明确账单的离散事件，基于审定后住院理赔记录的结局代理变量 $Y^{*}_{\text{claims}}$ 具有很高的可靠性。而 EHRs 则能为结局事件提供理赔数据所缺乏的临床细节，如生命体征、实验室值等，这对于需要生理指标来定义的结局或验证诊断至关重要。在时间性方面，理赔数据的时间锚点是“服务日期”，而 EHRs 则提供更细粒度的临床时间戳（如医嘱时间、给药时间），二者均存在各自独特的延迟和错分风险 [@problem_id:5054523]。

#### 临床登记

临床登记是为了特定目的（如监测疾病、评估产品安全性）而主动收集特定人群数据的系统。其设计直接影响研究的有效性。

-   **疾病登记（Disease Registry）**：基于患者是否患有某种特定疾病来入组，而不论其接受何种治疗。
-   **产品登记（Product Registry）**：基于患者是否开始使用或正在接受某种特定的医疗产品（如药物或器械）来入组。
-   **质量登记（Quality Registry）**：通常入组医疗机构或临床医生，以监测系统层面的绩效指标和指南依从性。

这些登记的设计，特别是**病例确认机制**（case ascertainment）、**入组标准**（inclusion criteria）和**随访策略**（follow-up policies），对研究的**内部有效性**（即估计值免于系统误差的程度）有决定性影响。

以一项旨在估计某新生物制剂在类风湿关节炎患者中引发严重感染的6个月累积发生率的研究为例。一个理想的设计应能最小化选择偏倚、信息偏倚和随访偏倚。

-   一个设计良好的**产品登记**将是最佳选择。它会直接针对目标人群——即该生物制剂的**新使用者**（incident new users）——在首次用药时将其纳入登记（即**入组标准**）。通过主动、定期的随访和多源数据（如 EHRs、实验室数据）的临床审定来确认感染事件（即**病例确认机制**），可以最大化结局测量的敏感性（$\mathrm{Se}$）和特异性（$\mathrm{Sp}$），从而减少结局错分。随访从首次用药的“指数日期”开始，并确保低失访率，这构成了恰当的**随访策略**。这样的设计系统性地解决了影响内部有效性的主要威胁 [@problem_id:5054640]。

-   相比之下，其他设计则存在严重缺陷。例如，一个依赖被动报告（低敏感性）、纳入已接受多种治疗的**普遍使用者**（prevalent users，引入幸存者偏倚）的**疾病登记**，并且在年度访视时才开始计算风险期（引入不朽时间偏倚），其内部有效性将极低。同样，一个以机构为单位、无法在患者层面定义暴露的**质量登记**，根本无法回答个体层面的因果问题 [@problem_id:5054640]。

### 数据质量、溯源与标准化

原始的 RWD 充满了不一致、不完整和不准确之处。在进行任何分析之前，必须对其进行处理，而这个过程本身必须是透明和可重复的。

#### [数据溯源](@entry_id:175012)：可解释性与可审计性的基石

**[数据溯源](@entry_id:175012)**（Data Provenance）是关于数据“血统”的明确、可机读的记录。它不仅仅是描述数据结构的**[元数据](@entry_id:275500)**（metadata，如列名、单位、编码列表），而是记录了每个数据点从其原始来源到最终分析数据集的完整历程。这包括：

-   源系统标识符（如来自哪个 EHR 系统或理赔数据库）。
-   提取和转换的时间戳。
-   数据连接的决策（如用于连接不同来源记录的概率匹配分数）。
-   应用于数据的有序转换函数 $\{f_i\}$ 及其版本号。

在一个多源 RWD 研究中，例如，估计 [SGLT2](@entry_id:168233) 抑制剂对心力衰竭住院风险的影响，严谨的[数据溯源](@entry_id:175012)至关重要。它能够让我们验证因果推断的基本前提，例如，确保基线协变量 $Z$ 的测量时间 $t_Z$ 早于治疗开始时间 $t_X$，而治疗开始时间 $t_X$ 又早于结局发生时间 $t_Y$（即 $t_Z  t_X  t_Y$）。此外，它还确保了暴露的编码（例如，从国家药品代码 NDC 映射到 SGLT2i 药物类别）与研究旨在评估的干预 $\operatorname{do}(X)$ 保持一致。最后，完整的溯源记录提供了一个完整的**审计追踪**（audit trail），使得任何独立的第三方都能重复整个分析流程，从而保证了研究的**可重复性**和**透明度** [@problem_id:5054538]。

#### 评估[数据质量](@entry_id:185007)维度

数据质量是一个多维度的概念，包括完整性、准确性、一致性、及时性等。**完整性**（Completeness），即真实事件被数据源捕获的概率，是一个尤其重要的维度。由于没有任何单一的 RWD 源是完全无缺的，量化其完整性对于理解研究结果的潜在偏倚至关重要。

一种评估事件捕获完整性的强大技术是**捕获-再捕获方法**（capture-recapture method）。该方法利用两个或多个不完全但独立的来源来估计事件的总数。假设我们有两个数据源，EHR 和理赔数据，并且我们假定，对于一个真实发生的事件，被 EHR 捕获和被理赔数据捕获是两个独立的事件。

设 $N$ 为真实事件的总数（未知），$N_{E}^{\text{true}}$ 为被 EHR 捕获的真实事件数， $N_{C}^{\text{true}}$ 为被理赔数据捕获的真实事件数，$N_{EC}^{\text{true}}$ 为同时被两者捕获的真实事件数。根据独立性假设，在被 EHR 捕获的真实事件中，同时也被理赔数据捕获的比例应约等于在所有真实事件中，被理赔数据捕获的比例。即：
$$
\frac{N_{EC}^{\text{true}}}{N_{E}^{\text{true}}} \approx \frac{N_{C}^{\text{true}}}{N}
$$
通过这个关系，我们可以估计总的真实事件数 $N$：
$$
\hat{N} = \frac{N_{E}^{\text{true}} \cdot N_{C}^{\text{true}}}{N_{EC}^{\text{true}}}
$$
在实际操作中，我们需要用观察到的数据来估计等式右边的各项。例如，如果 EHR 记录的事件中有已知的假阳性率，我们需要使用阳性预测值（PPV）来校正观察到的计数值。假设 EHR 的阳性预测值为 $\text{PPV}_E$，观察到的事件数为 $n_E$，那么 $N_{E}^{\text{true}}$ 的估计值就是 $\text{PPV}_E \cdot n_E$。将这些估计值代入上式，就可以得到对总真实事件数 $\hat{N}$ 的估计。

于是，EHR 的完整性 $p_E = N_{E}^{\text{true}} / N$ 的一个[有效估计量](@entry_id:271983)就是：
$$
\hat{p}_E = \frac{\text{PPV}_E \cdot n_E}{\left(\dfrac{(\text{PPV}_E \cdot n_E) \cdot n_C}{n_{EC}}\right)}
$$
这个估计量在给定的假设下，比简单地使用某个“黄金标准”数据源（如果该标准本身覆盖不全）或简单地将两个来源的观察计数相加（该方法忽略了两个来源都未捕获的事件）更为稳健和无偏 [@problem_id:5054657]。

#### 协调与[互操作性](@entry_id:750761)：OMOP CDM 和 FHIR

在多中心研究中，一个核心挑战是如何整合来自不同机构、具有不同结构和编码系统的数据。这需要**数据协调**（data harmonization），它分为两个层面：

-   **结构协调（Structural Harmonization）**：将不同来源的数据模式（如表、字段、关系）映射到一个统一的目标模式。这可以被形式化地看作一个模式同态映射 $f:(T_i,A_i,R_i)\to(T^*,A^*,R^*)$，其中 $(T_i,A_i,R_i)$ 是源站点 $i$ 的模式，而 $(T^*,A^*,R^*)$ 是公共目标模式。
-   **语义协调（Semantic Harmonization）**：将不同来源的本地编码（如本地的药物代码或检验项目代码）映射到一个标准的、统一的词汇体系。这可以被形式化地看作一个映射函数 $g:\mathcal{C}_i\to\mathcal{C}^*$，其中 $\mathcal{C}_i$ 是源站点的编码集，而 $\mathcal{C}^*$ 是标准概念空间。

为了应对这些挑战，社群开发了多种标准和模型。**OMOP 通用数据模型（Observational Medical Outcomes Partnership Common Data Model, OMOP CDM）** 是一个为观察性健康数据分析设计的关系型数据模型。它通过提供一套标准的表、字段和约定，实现了结构协调。更重要的是，OMOP CDM 包含了一个庞大的标准化词汇表，将各种源词汇（如 ICD、SNOMED CT、RxNorm、LOINC）映射到标准概念ID，从而实现了语义协调。

另一方面，**快速医疗互操作性资源（Fast Healthcare Interoperability Resources, FHIR）** 是一个为实时医疗数据交换而设计的现代标准。它定义了一系列模块化的、可计算的“资源”（如 Patient、Observation、Medication），通常以 JSON 或 XML 格式表示。FHIR 通过其“配置文件”（Profiles）机制提供了强大的扩展性，允许为特定用例约束资源，并将资源中的元素绑定到标准编码系统，从而支持语义[互操作性](@entry_id:750761)。

在多站点网络中，OMOP CDM 主要用于构建用于分析的、协调一致的数据仓库，而 FHIR 主要用于在不同系统间实时交换数据。二者共同为实现 RWD 的[互操作性](@entry_id:750761)提供了关键工具 [@problem_id:5054665]。

### RWD 因果推断的核心方法论挑战

即使数据已被妥善地处理和协调，使用 RWD 进行因果推断仍然面临着一系列源于其观察性质的深刻挑战。

#### 偏倚的起源：临床工作流与数据生成

与为研究目的而精心设计的数据收集不同，RWD 是临床工作流的副产品。这个生成过程本身就会引入系统性偏倚。考虑一个检测某种生物标志物 $B$ 的完[整流](@entry_id:197363)程，它包括：医生**开具**检测医嘱（$T$），实验室**执行**检测（$P$），临床医生将结果**记录**到病历中（$D$），以及向保险公司**提交账单**（$L$）。

这个流程的每一步都可能受到临床因素的影响，从而导致我们最终观察到的数据是有偏的。例如，假设一个生成模型如下：
-   疾病严重程度 $Z$ 影响生物标志物 $B$ 的真实状态，也影响医生开具检测医嘱 $T$ 的倾向（更严重的患者更可能被检测）。
-   医嘱 $T$ 被执行 $P$ 的概率很高，但前提是必须有医嘱。
-   结果的记录 $D$ 概率不仅取决于检测是否被执行，还取决于检测结果本身 $B$ 和疾病严重程度 $Z$（例如，阳性或异常结果更可能被记录）。

在这种情况下，如果我们仅分析那些有完整记录（即 $T=1, P=1, D=1$）的患者来估计生物标志物 $B$ 的患病率，我们实际上是在一个经过筛选的子集上进行分析。由于记录 $D$ 的行为本身受到生物标志物值 $B$ 的影响（阳性结果更可能被记录），这种筛选过程不是随机的。这属于**[非随机缺失](@entry_id:163489)**（Missing Not At Random, MNAR）的情形。在因果图中，记录行为 $D$ 是一个**对撞节点**（collider），因为它同时被 $B$ 和 $Z$ 影响。对对撞节点进行条件化（即选择 $D=1$ 的样本）会打开 $B$ 和 $Z$ 之间的非因果路径，从而在被选中的样本中引入虚假的关联，导致对 $B$ 的真实患病率 $E(B)$ 的估计产生偏倚（$E(B \mid D=1) \neq E(B)$）[@problem_id:5054410]。这个例子深刻地揭示了，如果不显式地对数据生成过程进行建模，简单的“完整病例分析”可能导致严重的系统性误差。

#### 适应证混杂

**适应证混杂**（Confounding by Indication）是在使用 RWD 进行药物效应研究时最普遍和最棘手的挑战之一。其根本原因在于，在临床实践中，医生决定给予患者何种治疗（$A$）的依据是患者的临床状况或疾病严重程度（即治疗的“适应证”，$I$）。而这种临床状况 $I$ 本身也强烈地预测着患者未来的健康结局（$Y$）。

因此，$I$ 成为了治疗 $A$ 和结局 $Y$ 的一个**[共同原因](@entry_id:266381)**。这种关系可以用一个最小化的**[有向无环图](@entry_id:164045)**（Directed Acyclic Graph, DAG）来表示：$I \rightarrow A$ 且 $I \rightarrow Y$。由于存在这样一条从 $A$ 到 $Y$ 的“后门路径”（backdoor path）$A \leftarrow I \rightarrow Y$，在未对 $I$ 进行调整的情况下，观察到的 $A$ 和 $Y$ 之间的关联将是混杂的，它混合了 $A$ 对 $Y$ 的真实因果效应（由路径 $A \rightarrow Y$ 表示）和由[共同原因](@entry_id:266381) $I$ 造成的虚假关联。

从反事实的角度看，存在混杂意味着边际可交换性不成立，即 $Y^a \not\perp\!\!\!\perp A$。换句话说，接受治疗这件事本身就提供了关于患者潜在结局的信息。例如，在[观察性研究](@entry_id:174507)中，接受某种强效降压药的患者往往比未接受者有更高的基线血压和死亡风险。如果不充分调整这些基线风险差异，简单的比较可能会错误地得出该药物“有害”的结论。因此，识别并恰当调整所有重要的混杂因素是 RWD 因果推断的基石 [@problem_id:5054573]。

#### 时间相关偏倚：不朽时间偏倚

在基于 RWD 的队列研究中，对时间的错误处理会导致一类特殊的、被称为**不朽时间偏倚**（Immortal Time Bias）的系统误差。当一段随访时间被错误地归类时，就会发生这种偏倚。具体来说，如果一个患者在随访开始后的某个时间点才开始接受治疗，那么从随访开始到治疗开始的这段时间，该患者为了能最终被归为“治疗组”，他必须“存活”且未发生结局事件。这段时间就是“不朽的”，因为根据定义，在此期间结局事件不可能发生。如果这段不朽时间被错误地计入治疗组的总随访时间（即作为计算发生率的分母），它将人为地稀释治疗组的事件发生率，从而导致对治疗效应的偏倚估计（通常是夸大其保护作用）。

为了避免这种偏倚，必须采用严谨的研究设计，精确地定义和对齐时间窗口。一个标准的做法是**新使用者设计**（new-user design），其核心要素包括：

-   **指数日期（Index Date）**：对于治疗组，指数日期 $t_0$ 定义为首次用药（如首次药品理赔）的日期。对于[对照组](@entry_id:188599)，则需要选择一个可比的指数日期。
-   **回看期（Look-back Period）**：指数日期之前的预设时间段（如 $[t_0-L, t_0)$），用于确认患者是“新使用者”（即在此期间未使用过该药物）以及测量基线协变量。
-   **风险窗口（Risk Window）**：从指数日期开始的随访时间，用于计算人-时和观察结局事件。
-   **暴露窗口（Exposure Window）**：定义了患者被视为“暴露”的时间段。

在最简单的设计中，患者从指数日期 $t_0$ 开始即被视为暴露。其在指数日期之前的随访时间，要么不被计入分析，要么被正确地归类为“未暴露”人-时。通过将暴露状态视为一个随时间变化的变量，并确保人-时在任何时刻都被正确分类，就可以从根本上避免不朽时间偏倚 [@problem_id:5054666]。