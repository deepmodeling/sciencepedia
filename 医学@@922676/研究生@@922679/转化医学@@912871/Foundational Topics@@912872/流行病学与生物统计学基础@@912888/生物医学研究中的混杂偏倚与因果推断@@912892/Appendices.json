{"hands_on_practices": [{"introduction": "因果推断始于清晰地陈述我们对数据生成过程的假设。有向无环图（DAGs）为此提供了一种直观而严谨的语言。第一个练习 [@problem_id:5001872] 将挑战您在一个常见的转化医学场景中应用后门准则，迫使您区分混杂路径、因果路径以及在不当处理时会引入偏倚的路径。掌握这项技能对于设计有效的观察性研究和正确解释其结果至关重要。", "problem": "一项转化医学中的观察性队列研究评估了一种抗炎疗法 $A$ 对六个月功能性结局 $Y$ 的总因果效应。基线协变量 $L$ 概括了治疗前的疾病严重程度和合并症，中间生物标志物 $M$ 是在治疗一个月时测量的一种对治疗有反应的炎症标志物，$U$ 代表一种在分子水平上影响生物学的未测量的促炎倾向。因果结构由一个有向无环图（DAG）表示，其有向边如下：$L \\rightarrow A$、$L \\rightarrow Y$、$A \\rightarrow M \\rightarrow Y$ 以及 $U \\rightarrow M$、$U \\rightarrow Y$。没有其他箭头。假设 $U$ 未被测量，科学目标是从观察数据中识别 $A$ 对 $Y$ 的总因果效应。\n\n使用 $d$-分离和后门准则的定义，判断在估计 $A$ 对 $Y$ 的总因果效应时，同时对 $L$ 和 $M$ 进行条件化是否足以控制混杂。选择唯一的最佳答案。\n\nA. 是的。对 $\\{L, M\\}$ 进行调整会阻断从 $A$ 到 $Y$ 的所有后门路径，因此它足以估计总效应。\n\nB. 不是。对 $M$ 进行条件化会打开一条通过 $U$ 的对撞路径 $A \\rightarrow M \\leftarrow U \\rightarrow Y$，从而引入偏倚；单独使用 $\\{L\\}$ 就足以估计总效应。\n\nC. 是的。对中介变量 $M$ 进行调整会移除中介路径，从而分离出直接效应，在此图中该直接效应等于总效应。\n\nD. 不是。因为 $U$ 混杂了 $M$ 和 $Y$，所以 $A \\rightarrow Y$ 关系存在不可避免的混杂，在不测量 $U$ 的情况下，根据此 DAG 无法从观察数据中识别总效应。", "solution": "问题询问在估计治疗 $A$ 对结局 $Y$ 的总因果效应时，对协变量集 $\\{L, M\\}$ 进行条件化是否足以控制混杂。因果关系由一个有向无环图（DAG）描述，其边如下：$L \\rightarrow A$、$L \\rightarrow Y$、$A \\rightarrow M$、$M \\rightarrow Y$、$U \\rightarrow M$ 以及 $U \\rightarrow Y$。变量 $U$ 是未测量的。\n\n为了识别 $A$ 对 $Y$ 的总因果效应，我们必须找到一个满足后门准则的协变量集 $Z$。如果满足两个条件，则称集合 $Z$ 相对于 $(A, Y)$ 满足后门准则：\n1.  $Z$ 中没有变量是 $A$ 的后代。\n2.  $Z$ 中的变量阻断了 $A$ 和 $Y$ 之间每一条包含指向 $A$ 的箭头（即“后门路径”）的路径。\n\n如果存在这样的集合 $Z$，则总因果效应可以通过调整公式从观察数据中识别：\n$$ P(Y|do(A=a)) = \\sum_{z} P(Y|A=a, Z=z)P(Z=z) $$\n\n让我们首先识别给定 DAG 中 $A$ 和 $Y$ 之间的所有路径。\n- **路径1（因果路径）：** $A \\rightarrow M \\rightarrow Y$。这是一条从 $A$ 到 $Y$ 的有向路径，代表了由生物标志物 $M$ 中介的 $A$ 对 $Y$ 的因果效应。总因果效应必须包括通过此路径传递的效应。\n\n- **路径2（后门路径）：** $A \\leftarrow L \\rightarrow Y$。这条路径是一条非因果的“后门”路径，因为它包含一个指向 $A$ 的箭头。变量 $L$ 是 $A$ 和 $Y$ 的共同原因，因此充当了混杂因素。\n\n- **路径3（非因果路径）：** $A \\rightarrow M \\leftarrow U \\rightarrow Y$。这条路径连接了 $A$ 和 $Y$，但不是从 $A$到 $Y$ 的有向因果路径。此路径上的变量 $M$ 是一个“对撞点”，因为它有两个指向它的箭头（$A \\rightarrow M$ 和 $U \\rightarrow M$）。根据 $d$-分离的规则，包含对撞点的路径默认是阻断的（即，除非对该对撞点或其后代进行条件化）。\n\n现在，让我们确定用于估计总因果效应的正确调整集。为了满足后门准则，我们必须阻断路径2 ($A \\leftarrow L \\rightarrow Y$)，并且不能对 $A$ 的任何后代进行条件化。\n- 集合 $Z = \\{L\\}$ 满足这些条件。对 $L$ 进行条件化可以阻断路径 $A \\leftarrow L \\rightarrow Y$。此外，$L$ 不是 $A$ 的后代。因此，$\\{L\\}$ 是一个足以识别 $A$ 对 $Y$ 的总因果效应的调整集。\n\n问题询问集合 $\\{L, M\\}$ 是否是一个充分的调整集。让我们根据后门准则的两个条件来评估这个集合。\n1.  **$\\{L, M\\}$ 中是否有变量是 $A$ 的后代？** 有。在 DAG 中，存在一条路径 $A \\rightarrow M$。这意味着 $M$ 是 $A$ 的后代。因此，集合 $\\{L, M\\}$ 违反了后门准则的第一个条件。对因果路径上的变量（如中介变量 $M$）进行调整会阻断该路径，从而得到直接效应的估计，而非总效应。\n\n2.  **对 $\\{L, M\\}$ 进行条件化是否会引入偏倚？** 会。考虑路径 $A \\rightarrow M \\leftarrow U \\rightarrow Y$。如前所述，$M$ 是此路径上的一个对撞点，因此该路径天然是阻断的。然而，通过对对撞点 $M$ 进行条件化，我们*打开*了这条路径。这会通过 $M$ 和 $Y$ 的未测量共同原因 $U$ 在 $A$ 和 $Y$ 之间产生一种非因果关联。这种现象被称为对撞分层偏倚。因此，对 $M$ 进行调整会引入一种新的偏倚来源。\n\n总之，对 $\\{L, M\\}$ 进行条件化是错误的，主要有两个原因：\n- 它包含一个中介变量（$M$），这会阻断我们感兴趣的部分因果效应，从而无法估计总效应。\n- 它包含路径 $A \\rightarrow M \\leftarrow U \\rightarrow Y$ 上的一个对撞点（$M$），这会打开该路径并因未测量的变量 $U$ 而引入偏倚。\n\n估计总因果效应的正确程序是仅对 $\\{L\\}$ 进行调整。\n\n让我们基于此分析评估所提供的选项。\n\n**A. 是的。对 $\\{L, M\\}$ 进行调整会阻断从 $A$ 到 $Y$ 的所有后门路径，因此它足以估计总效应。**\n这个陈述是错误的。虽然对 $\\{L, M\\}$ 进行条件化确实阻断了后门路径 $A \\leftarrow L \\rightarrow Y$，但它不满足估计总效应的条件。首先，$M$ 是 $A$ 的后代，违反了后门准则。其次，对 $M$ 进行条件化会通过对撞点 $M$ 打开一条新的偏倚路径。因此，这种调整不足以估计总效应。**错误**。\n\n**B. 不是。对 $M$ 进行条件化会打开一条通过 $U$ 的对撞路径 $A \\rightarrow M \\leftarrow U \\rightarrow Y$，从而引入偏倚；单独使用 $\\{L\\}$ 就足以估计总效应。**\n这个陈述是正确的。它正确地指出了两个关键问题。它正确地说明了对对撞点 $M$ 进行条件化会打开路径 $A \\rightarrow M \\leftarrow U \\rightarrow Y$，通过未测量的混杂因素 $U$ 引入偏倚。它还正确地指出，仅对 $\\{L\\}$ 进行调整就足以识别总效应，因为 $\\{L\\}$ 满足后门准则。**正确**。\n\n**C. 是的。对中介变量 $M$ 进行调整会移除中介路径，从而分离出直接效应，在此图中该直接效应等于总效应。**\n这个陈述是错误的。对中介变量 $M$ 进行调整确实会移除中介路径 $A \\rightarrow M \\rightarrow Y$ 并有助于分离出直接效应。然而，总效应是直接效应和间接（中介）效应的总和。由于此图中存在中介路径，直接效应不等于总效应。我们的目标是估计总效应，因此移除中介部分与目标相悖。**错误**。\n\n**D. 不是。因为 $U$ 混杂了 $M$ 和 $Y$，所以 $A \\rightarrow Y$ 关系存在不可避免的混杂，在不测量 $U$ 的情况下，根据此 DAG 无法从观察数据中识别总效应。**\n这个陈述是错误的。虽然 $U$ 确实混杂了 $M$ 和 $Y$ 之间的关系，但它并没有为 $A$ 对 $Y$ 的总效应造成混杂。涉及 $U$ 的路径是 $A \\rightarrow M \\leftarrow U \\rightarrow Y$，该路径被对撞点 $M$ 阻断。只要我们不对 $M$ 进行条件化，这条路径就保持阻断状态，$U$ 也不会混杂 $A \\rightarrow Y$ 的关系。如前所述，通过仅对 $\\{L\\}$ 进行调整，总效应是可识别的。**错误**。", "answer": "$$\\boxed{B}$$", "id": "5001872"}, {"introduction": "一旦我们确定了需要调整的混杂因素集合，下一步就是实施调整。逆概率治疗加权（IPTW）是一种功能强大且广泛使用的方法，它通过创建一个加权的“伪人群”来实现这一目标，在这个伪人群中，混杂因素与治疗不再相关。这个计算练习 [@problem_id:5001916] 不仅仅是简单的公式应用，它将指导您实现稳定的IPTW，并执行关键的诊断检查以确保权重不会引入不稳定性——这是任何现实世界分析中都至关重要的一步。", "problem": "您面临一个在转化医学背景下的因果推断任务。考虑一个目标试验模拟，其中每个受试者 $i \\in \\{1,\\dots,N\\}$ 都有一个估计的倾向性得分 $e_i$，定义为在给定已测量协变量的情况下接受处理 $A=1$ 的估计概率。二元处理由 $A \\in \\{0,1\\}$ 表示，受试者 $i$ 的观测处理为 $A_i$。已知处理的边缘概率为 $P(A=1)=p$，其中 $p$ 已指定。您的目标是从概率和因果推断的第一性原理出发，推导、实现并评估稳定逆概率处理加权。\n\n您的推导应基于以下基本定义和事实，不使用任何预先提供的特定于加权公式的结果：\n- 生物医学中因果推断的潜在结果框架：每个受试者都有潜在结果 $\\{Y^0,Y^1\\}$，在一致性假设下，观测结果为 $Y=Y^A$。\n- 可交换性（条件可忽略性）：在给定已测量协变量 $X$ 的条件下，处理 $A$ 是“近似”随机的，因此 $\\{Y^0,Y^1\\} \\perp\\!\\!\\!\\perp A \\mid X$。\n- 正值性：对于所有具有正密度的协变量模式，$0  P(A=1 \\mid X)  1$。\n- 全概率定律、迭代期望定律，以及使用概率测度间的拉东-尼科迪姆导数来构建重加权以恢复目标边缘分布的定义。\n- 通过一个边缘因子进行稳定化，以控制方差膨胀，同时保持目标边缘处理分布。\n\n从这些原理出发，推导如何构建一个受试者级别的稳定权重，该权重使用边缘处理概率与条件处理概率之间的比率，使得重加权后的数据近似于一个伪群体，在该群体中处理与已测量协变量无关。然后按照下文所述实现计算和诊断。\n\n计算规范：\n- 对于每个测试用例，生成 $N$ 个受试者，其个体估计倾向性得分 $\\{e_i\\}_{i=1}^N$ 独立地从一个贝塔分布中抽取，该分布的参数为 $(\\alpha,\\beta)$，使得贝塔分布的均值等于 $\\alpha/(\\alpha+\\beta)=0.4$。对于每个受试者 $i$，从一个成功概率为 $e_i$ 的伯努利分布中模拟观测处理 $A_i$。在任何需要边缘处理概率的地方，使用已知的边缘处理概率 $p=0.4$。\n- 对于每个受试者 $i$，使用您推导出的、仅依赖于 $p$、$A_i$ 和 $e_i$ 的表达式，计算稳定逆概率处理权重。\n- 极端权重的诊断：计算以下权重分布的摘要度量，以评估对正值性的潜在违背和方差膨胀。\n  1. 权重的均值（一个浮点数）。\n  2. 权重的方差，使用除数为 $N$ 的总体方差（一个浮点数）。\n  3. 权重的 $0.99$ 分位数（一个浮点数）。\n  4. 权重严格大于阈值 $T$ 的比例，表示为 $[0,1]$ 区间内的小数而非百分比（一个浮点数）。\n  5. 有效样本量 $\\mathrm{ESS} = \\left(\\sum_{i=1}^N w_i\\right)^2 \\big/ \\left(\\sum_{i=1}^N w_i^2\\right)$（一个浮点数）。\n  6. 变异系数 $\\mathrm{CV} = \\mathrm{sd}(w)/\\mathrm{mean}(w)$，使用总体标准差（一个浮点数）。\n  7. 一个极端权重标志，定义为 $\\{0,1\\}$ 中的整数，如果以下任一条件成立，则为 $1$，否则为 $0$：$0.99$ 分位数至少为 $10$，或高于 $T$ 的比例至少为 $0.01$，或 $\\mathrm{ESS} \\leq 0.5 N$。\n- 对所有用例使用 $N=1000$ 和 $p=0.4$。对于高于阈值比例的诊断，使用阈值 $T=10$。\n\n测试套件：\n- 用例 1（理想路径，中等离散度）：$(\\alpha,\\beta)=(4,6)$，随机种子 $20231101$。\n- 用例 2（边缘案例，接近边界的极端离散度）：$(\\alpha,\\beta)=(0.2,0.3)$，随机种子 $20231102$。\n- 用例 3（低方差案例，集中在均值附近）：$(\\alpha,\\beta)=(40,60)$，随机种子 $20231103$。\n\n算法要求：\n- 使用可复现的伪随机数生成器，并为每个用例指定种子。\n- 对于每个测试用例，按上述顺序生成一个包含恰好 $7$ 个条目的列表：$[\\text{mean},\\text{variance},\\text{q}_{0.99},\\text{fraction\\_gt\\_}T,\\mathrm{ESS},\\mathrm{CV},\\text{flag}]$。对于高于阈值的比例，报告一个小数（例如，$0.03$）而不是百分比。对于标志，报告 $1$ 或 $0$。\n- 您的程序应生成单行输出，其中包含所有提供的测试用例的结果，形式为由三个单用例列表组成的逗号分隔列表，并用方括号括起来，不含空格。例如，输出格式必须严格为 $[[r_{11},\\dots,r_{17}],[r_{21},\\dots,r_{27}],[r_{31},\\dots,r_{37}]]$ 的形式，其中每个 $r_{jk}$ 是一个数字，内部列表的顺序与上述测试套件的顺序一致。\n\n角度单位不适用。百分比必须始终表示为小数或分数，不能使用百分号。\n\n本规范中的所有数字字面量，包括 $N$、$p$、$T$、种子和贝塔参数，都是精确的，必须按给定值使用。最终输出是无单位的实数或整数，如规范所述，不含任何额外文本。程序必须是完整的、自包含的，并且不需要任何输入。", "solution": "该问题陈述被评估为有效。它科学地植根于成熟的因果推断潜在结果框架，问题设定良好，具有明确的计算任务，并且其表述是客观的。所有必要的数据、参数和定义都已提供，使得该问题是自包含且可解的。\n\n**1. 稳定逆概率处理权重的推导**\n\n逆概率处理加权（IPTW）的目标是通过创建一个伪群体来估计因果效应，在该伪群体中，处理分配 $A$ 与已测量的协变量 $X$ 无关。此过程纠正了在观察性研究中由于处理的非随机分配而引入的混杂偏倚。\n\n令观测群体中处理 $A$ 和协变量 $X$ 的联合概率分布由测度 $P$ 表示。相应的联合概率密度（或质量）函数为 $p(a, x) = p(a \\mid x) p(x)$。在这里，$p(a \\mid x)$ 是在给定协变量 $x$ 的情况下接受处理 $a$ 的条件概率，$p(x)$ 是协变量的边缘概率密度。条件概率 $P(A=1 \\mid X=x)$ 是倾向性得分，记为 $e(x)$。\n\n目标是一个伪群体，由一个测度 $P^*$ 描述，其中处理和协变量在统计上是独立的。在这个目标群体中，联合密度为 $p^*(a, x) = p^*(a) p^*(x)$。为了保留原始研究的边缘特征，我们将目标边缘分布设置为与观测边缘分布相同：$p^*(a) = P(A=a)$ 和 $p^*(x) = p(x)$。问题指定处理的边缘概率 $P(A=1)$ 为 $p$。因此，$p^*(a=1) = p$ 且 $p^*(a=0) = 1-p$。\n\n对于一个具有观测处理 $A_i$ 和协变量 $X_i$ 的受试者，其权重由目标测度 $P^*$ 相对于观测测度 $P$ 的拉东-尼科迪姆导数给出。该导数表示目标世界与观测世界中概率密度的比率：\n$$\nw(a, x) = \\frac{d P^*}{d P}(a, x) = \\frac{p^*(a, x)}{p(a, x)}\n$$\n代入联合密度的表达式：\n$$\nw(a, x) = \\frac{p^*(a) p^*(x)}{p(a \\mid x) p(x)} = \\frac{P(A=a) p(x)}{P(A=a \\mid X=x) p(x)}\n$$\n协变量密度 $p(x)$ 被消去，得到稳定权重的一般公式：\n$$\nw(a, x) = \\frac{P(A=a)}{P(A=a \\mid X=x)}\n$$\n对于具有观测处理 $A_i$ 和估计倾向性得分 $e_i = P(A=1 \\mid X_i)$ 的单个受试者 $i$，我们可以将其权重 $w_i$ 写成其观测数据的函数。\n\n如果受试者 $i$ 接受处理（$A_i=1$）：\n分子是边缘概率 $P(A=1) = p$。\n分母是条件概率 $P(A=1 \\mid X_i) = e_i$。\n权重为 $w_i = \\frac{p}{e_i}$。\n\n如果受试者 $i$ 未接受处理（$A_i=0$）：\n分子是边缘概率 $P(A=0) = 1-p$。\n分母是条件概率 $P(A=0 \\mid X_i) = 1 - P(A=1 \\mid X_i) = 1 - e_i$。\n权重为 $w_i = \\frac{1-p}{1-e_i}$。\n\n这两种情况可以合并成受试者 $i$ 的稳定权重 $w_i$ 的单一表达式：\n$$\nw_i = A_i \\frac{p}{e_i} + (1-A_i) \\frac{1-p}{1-e_i}\n$$\n术语“稳定”指的是在分子中包含边缘概率 $p$ 和 $1-p$。与非稳定权重（其分子为 $1$）相比，这些因子会压缩权重，减小其方差，从而减轻加权估计器中的方差膨胀。这些权重的一个关键性质是它们的均值期望为 $1$。\n\n**2. 计算和诊断规范**\n\n指定的任务涉及模拟数据并计算这些权重，然后对权重分布进行分析。\n\n**数据生成：**\n对于三个测试用例中的每一个，我们为 $N=1000$ 个受试者生成数据。\n1.  根据指定为每个用例设置种子，以保证可复现性。\n2.  倾向性得分 $\\{e_i\\}_{i=1}^N$ 独立地从一个贝塔分布 $e_i \\sim \\text{Beta}(\\alpha, \\beta)$ 中抽取，其中参数 $(\\alpha, \\beta)$ 为每个用例提供。\n3.  对于每个受试者 $i$，观测处理 $A_i \\in \\{0,1\\}$ 从参数为 $e_i$ 的伯努利分布中抽取，即 $A_i \\sim \\text{Bernoulli}(e_i)$。\n\n**权重计算：**\n对于每个受试者 $i$，使用推导出的公式和已知的边缘概率 $p=0.4$ 计算稳定权重 $w_i$：\n$$\nw_i = A_i \\frac{0.4}{e_i} + (1-A_i) \\frac{1-0.4}{1-e_i}\n$$\n\n**诊断度量：**\n在计算出权重 $\\{w_i\\}_{i=1}^N$ 后，计算以下七个摘要统计量以评估权重分布。大的权重可能表明对正值性假设的实际违背（$e_i$ 或 $1-e_i$ 太接近 $0$），并可能导致最终效应估计的高方差和不稳定性。\n1.  **权重均值**：$\\bar{w} = \\frac{1}{N} \\sum_{i=1}^N w_i$。该值应接近 $1$。\n2.  **权重方差**：$\\sigma^2_w = \\frac{1}{N} \\sum_{i=1}^N (w_i - \\bar{w})^2$。使用除数为 $N$ 的总体方差。\n3.  **权重的 $0.99$ 分位数**：值 $q_{0.99}$，使得 $99\\%$ 的权重小于或等于它。\n4.  **权重  $T$ 的比例**：严格大于阈值 $T=10$ 的权重比例。计算为 $\\frac{1}{N}\\sum_{i=1}^N \\mathbb{I}(w_i  10)$，其中 $\\mathbb{I}(\\cdot)$ 是指示函数。\n5.  **有效样本量（ESS）**：衡量因加权而导致的精度损失。其公式为 $\\mathrm{ESS} = \\frac{(\\sum_{i=1}^N w_i)^2}{\\sum_{i=1}^N w_i^2}$。相对于 $N$ 而言较小的 ESS 表明权重方差较大。\n6.  **变异系数（CV）**：一种标准化的离散度度量，定义为 $\\mathrm{CV} = \\frac{\\sigma_w}{\\bar{w}}$，其中 $\\sigma_w = \\sqrt{\\sigma^2_w}$ 是总体标准差。\n7.  **极端权重标志**：一个整数指示符，如果以下三个条件中任何一个成立，则设为 $1$，否则为 $0$：\n    - $0.99$ 分位数至少为 $10$（$q_{0.99} \\ge 10$）。\n    - 大于 $T=10$ 的权重比例至少为 $0.01$。\n    - 有效样本量小于或等于名义样本量的一半（$\\mathrm{ESS} \\le 0.5N$）。\n\n对三个测试用例中的每一个执行这些步骤，并为每个用例将七个得到的诊断值报告在一个列表中。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the causal inference problem by deriving and applying stabilized IPTW,\n    and computes the specified diagnostic statistics for three test cases.\n    \"\"\"\n    \n    # Define the problem constants and test cases.\n    # Each case is a tuple of (alpha, beta, seed).\n    test_cases = [\n        (4, 6, 20231101),      # Case 1: Moderate dispersion\n        (0.2, 0.3, 20231102),  # Case 2: Extreme dispersion (U-shaped)\n        (40, 60, 20231103),    # Case 3: Low dispersion (concentrated)\n    ]\n    \n    N = 1000\n    p = 0.4\n    T = 10.0\n    \n    all_results = []\n    \n    for alpha, beta, seed in test_cases:\n        # Initialize the pseudo-random number generator for reproducibility.\n        rng = np.random.default_rng(seed)\n        \n        # 1. Generate N subjects with propensity scores from a Beta distribution.\n        #    The mean is alpha / (alpha + beta) = 0.4, matching p.\n        e = rng.beta(alpha, beta, size=N)\n        \n        # 2. Simulate observed treatment A_i from a Bernoulli distribution\n        #    with success probability e_i for each subject.\n        A = rng.binomial(1, p=e)\n        \n        # 3. Compute the stabilized inverse probability of treatment weights (SIPTW).\n        #    w_i = A_i * (p / e_i) + (1 - A_i) * ((1 - p) / (1 - e_i))\n        # np.divide with where clause handles potential division by zero,\n        # though Beta(a,b) with a,b > 0 should not produce exact 0 or 1.\n        # This is a robust practice.\n        weights_treated = np.divide(p, e, out=np.zeros_like(e, dtype=float), where=e!=0)\n        weights_control = np.divide(1 - p, 1 - e, out=np.zeros_like(e, dtype=float), where=(1-e)!=0)\n        weights = A * weights_treated + (1 - A) * weights_control\n        \n        # 4. Compute the required diagnostic measures.\n        \n        # 1. Mean of the weights\n        mean_w = np.mean(weights)\n        \n        # 2. Variance of the weights (population variance, divisor N)\n        var_w = np.var(weights, ddof=0)\n        \n        # 3. 0.99 quantile of the weights\n        q99_w = np.quantile(weights, 0.99)\n        \n        # 4. Fraction of weights strictly greater than threshold T\n        frac_gt_T = np.mean(weights > T)\n        \n        # 5. Effective Sample Size (ESS)\n        ess = np.sum(weights)**2 / np.sum(weights**2)\n        \n        # 6. Coefficient of Variation (CV)\n        #    Using population standard deviation (sqrt of population variance)\n        sd_w = np.std(weights, ddof=0)\n        cv_w = sd_w / mean_w if mean_w != 0 else np.inf\n        \n        # 7. Extreme-weight flag\n        ess_threshold = 0.5 * N\n        frac_threshold = 0.01\n        quantile_threshold = 10.0\n        \n        flag = int(\n            (q99_w >= quantile_threshold) or\n            (frac_gt_T >= frac_threshold) or\n            (ess = ess_threshold)\n        )\n        \n        case_results = [\n            mean_w, var_w, q99_w, frac_gt_T, ess, cv_w, flag\n        ]\n        all_results.append(case_results)\n        \n    # Format the final output as specified.\n    # e.g., [[r11,...,r17],[r21,...,r27],[r31,...,r37]]\n    output_str = f\"[[{','.join(map(str, all_results[0]))}],[{','.join(map(str, all_results[1]))}],[{','.join(map(str, all_results[2]))}]]\"\n    print(output_str)\n\nsolve()\n```", "id": "5001916"}, {"introduction": "在任何观察性研究中，无论数据多么丰富，未测量的混杂因素的幽灵始终存在。敏感性分析提供了一种量化此类未观察到变量潜在影响的方法。E-值（$E$-value）已成为实现此目的的标准工具，而这个练习 [@problem_id:5001897] 将指导您完成其推导和计算。通过完成这个练习，您将学会如何确定一个未测量的混杂因素需要与暴露和结局同时具有多大的关联强度才能完全“解释掉”一个观察到的效应，从而为您的研究发现提供一个关键的稳健性度量。", "problem": "一个转化医学研究团队进行了一项观察性队列研究，评估在慢性肺病患者中启用一种新的抗炎疗法（$E$）是否与降低一年期死亡率（$Y$）相关。在对一组丰富的已测量协变量进行调整后，观察到的无治疗与有治疗之间关联的风险比为 $RR_{\\text{obs}} = 2.0$（因此 $RR_{\\text{obs}} > 1$ 表示未治疗组的风险更高）。\n\n由于该研究不是随机对照试验（RCT），团队使用 E 值的概念对未测量的混杂因素进行敏感性分析。在使用有向无环图（DAGs）进行因果推断的标准框架中，令 $U$ 表示一个单一的、二元的、未测量的混杂因素。将 $RR_{EU}$ 定义为在已测量协变量的条件下，暴露 $E$ 和混杂因素 $U$ 之间在风险比尺度上的关联；将 $RR_{UY}$ 定义为在已测量协变量的条件下，在 $E$ 的各水平内，混杂因素 $U$ 和结局 $Y$ 之间在风险比尺度上的关联。E 值被定义为，在最坏情况的混杂安排下，未测量的混杂因素必须与 $E$ 和 $Y$（在已测量协变量的条件下）同时具有的最小强度（在风险比尺度上），才能将真实的因果 $RR$ 降至 $1$。\n\n仅从存在混杂时风险比的基本定义，以及关于风险比尺度上未测量混杂的广为接受的偏倚界限结果出发，推导当 $RR_{\\text{obs}} = 2.0$ 时的 E 值，并给出 E 值的精确、闭合形式的解析表达式。将最终答案表示为单个解析表达式；不要近似，也不要包含单位。", "solution": "问题要求推导当观察到的风险比 $RR_{\\text{obs}}$ 为 $2.0$ 时的 E 值。这项任务需要从观察到的关联、真实的因果效应和混杂偏倚之间的基本关系出发，然后应用敏感性分析中的一个标准结果。\n\n令 $E$ 表示暴露（治疗），$Y$ 表示结局（死亡率），$U$ 表示一个单一的、二元的、未测量的混杂因素。所有的关联都是以一组已测量的协变量为条件的，为了清晰起见，在符号表示中省略了这些协变量。问题提供了一个观察到的风险比 $RR_{\\text{obs}}$，表示无治疗（$E=0$）与有治疗（$E=1$）对一年期死亡率（$Y=1$）的关联。\n$$ RR_{\\text{obs}} = \\frac{P(Y=1|E=0)}{P(Y=1|E=1)} = 2.0 $$\n为便于使用标准公式（这些公式通常是为对应于有害暴露或风险因素的大于 1 的风险比定义的），我们将使用给定的 $RR_{\\text{obs}} = 2.0$ 进行计算。无论这代表的是有害暴露，还是以其倒数形式表示的保护性暴露，数学推导过程都是相同的。\n\n观察到的风险比（$RR_{\\text{obs}}$）、真实的因果风险比（$RR_{\\text{true}}$）以及由未测量混杂因素 $U$ 引起的偏倚因子（$B$）之间的关系由下式给出：\n$$ RR_{\\text{obs}} = RR_{\\text{true}} \\times B $$\n敏感性分析的目标是确定需要多大强度的混杂才能“解释掉”观察到的关联。这对应于真实因果风险比为空值（即 $RR_{\\text{true}} = 1$）的情景。在此零假设下，观察到的风险比完全由混杂偏倚造成：\n$$ RR_{\\text{obs}} = 1 \\times B \\implies B = RR_{\\text{obs}} $$\n在我们的具体案例中，偏倚因子必须是 $B = 2.0$。\n\n接下来，我们采用一个广为接受的结果来界定偏倚因子的大小。对于单个未测量的混杂因素 $U$，偏倚因子 $B$ 的界限由其与暴露和结局的关联强度决定。令 $RR_{EU}$ 为混杂因素与暴露之间关联的风险比，令 $RR_{UY}$ 为混杂因素与结局之间关联的风险比。在此框架的惯例中，$RR_{EU}$ 和 $RR_{UY}$ 都被定义为大于或等于 1。可以产生的最大偏倚 $B_{\\max}$ 由以下不等式给出：\n$$ B \\le B_{\\max} = \\frac{RR_{EU} \\cdot RR_{UY}}{RR_{EU} + RR_{UY} - 1} $$\n要使观察到的关联完全由混杂解释，最大可能的偏倚必须至少与观察到的风险比一样大，即 $B_{\\max} \\ge RR_{\\text{obs}}$。\n\nE 值被正式定义为最小值 $x$，使得如果 $RR_{EU} \\ge x$ 且 $RR_{UY} \\ge x$，观察到的关联就可以被解释掉。这个最小值出现在 $RR_{EU} = RR_{UY} = x$ 时。为了求出这个值，我们将用这些参数可实现的最大偏倚设为等于观察到的风险比：\n$$ RR_{\\text{obs}} = \\frac{x \\cdot x}{x + x - 1} = \\frac{x^2}{2x - 1} $$\n我们必须解这个关于 $x$ 的方程。整理各项，我们得到一个二次方程：\n$$ RR_{\\text{obs}}(2x - 1) = x^2 $$\n$$ x^2 - 2(RR_{\\text{obs}})x + RR_{\\text{obs}} = 0 $$\n我们使用二次公式 $x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$ 求解 $x$，其中 $a=1$，$b=-2 \\cdot RR_{\\text{obs}}$，$c=RR_{\\text{obs}}$：\n$$ x = \\frac{2 \\cdot RR_{\\text{obs}} \\pm \\sqrt{(-2 \\cdot RR_{\\text{obs}})^2 - 4(1)(RR_{\\text{obs}})}}{2} $$\n$$ x = \\frac{2 \\cdot RR_{\\text{obs}} \\pm \\sqrt{4 \\cdot RR_{\\text{obs}}^2 - 4 \\cdot RR_{\\text{obs}}}}{2} $$\n$$ x = RR_{\\text{obs}} \\pm \\sqrt{RR_{\\text{obs}}^2 - RR_{\\text{obs}}} $$\n这给出了 $x$ 的两个数学解。然而，参数 $RR_{EU}$ 和 $RR_{UY}$，以及它们的共同值 $x$，被定义为风险比，必须大于或等于 1。我们必须检验这两个解中哪一个满足这个约束条件。\n\n问题陈述 $RR_{\\text{obs}} = 2.0$，严格大于 1。\n第一个解是 $x_{+} = RR_{\\text{obs}} + \\sqrt{RR_{\\text{obs}}(RR_{\\text{obs}} - 1)}$。由于 $RR_{\\text{obs}} > 1$，平方根下的项为正，所以 $x_{+} > RR_{\\text{obs}} > 1$。这个解总是有效的。\n\n第二个解是 $x_{-} = RR_{\\text{obs}} - \\sqrt{RR_{\\text{obs}}^2 - RR_{\\text{obs}}}$。我们来检验条件 $x_{-} \\ge 1$：\n$$ RR_{\\text{obs}} - 1 \\ge \\sqrt{RR_{\\text{obs}}^2 - RR_{\\text{obs}}} $$\n由于 $RR_{\\text{obs}} > 1$，不等式两边都是非负的，允许我们对它们进行平方而不改变不等式的方向：\n$$ (RR_{\\text{obs}} - 1)^2 \\ge RR_{\\text{obs}}^2 - RR_{\\text{obs}} $$\n$$ RR_{\\text{obs}}^2 - 2 \\cdot RR_{\\text{obs}} + 1 \\ge RR_{\\text{obs}}^2 - RR_{\\text{obs}} $$\n$$ -2 \\cdot RR_{\\text{obs}} + 1 \\ge -RR_{\\text{obs}} $$\n$$ 1 \\ge RR_{\\text{obs}} $$\n这个结果与 $RR_{\\text{obs}} > 1$ 的前提相矛盾。因此，假设 $x_{-} \\ge 1$ 是错误的。解 $x_{-}$ 仅在 $RR_{\\text{obs}} \\le 1$ 时有效。由于我们正在评估一个 $RR_{\\text{obs}}>1$ 的关联，所以在该框架下，$x_{-}$ 不是一个有效的混杂因素关联强度。\n\n唯一有效的解是 $x_{+}$，它给出了对于给定的 $RR_{\\text{obs}} > 1$ 的 E 值的一般解析表达式：\n$$ \\text{E-value} = RR_{\\text{obs}} + \\sqrt{RR_{\\text{obs}}(RR_{\\text{obs}} - 1)} $$\n现在，我们将具体值 $RR_{\\text{obs}} = 2.0$ 代入这个推导出的表达式：\n$$ \\text{E-value} = 2 + \\sqrt{2(2 - 1)} $$\n$$ \\text{E-value} = 2 + \\sqrt{2(1)} $$\n$$ \\text{E-value} = 2 + \\sqrt{2} $$\n这就是与观察到的风险比为 2.0 相对应的 E 值的精确、闭合形式的解析表达式。", "answer": "$$\n\\boxed{2 + \\sqrt{2}}\n$$", "id": "5001897"}]}