{"hands_on_practices": [{"introduction": "理论知识需要通过实践来巩固。本章节提供了一系列实践练习，旨在解决确保研究诚信、严谨性和可重复性中的核心挑战。这些练习涵盖了研究项目的整个生命周期：从初始设计到数据分析，再到最终的结果解读。本节的第一个练习将探讨严谨性的基础——设计功效充足的研究。动力不足的研究是导致研究结果不可重复的主要原因之一。这项练习将引导您学习样本量计算的基本原理，这是严谨实验设计的基石。通过从第一性原理出发推导公式，您将深入理解统计功效、效应大小和显著性水平之间如何相互作用，并最终决定一项研究需要投入的资源。这项技能对于规划稳健且符合伦理的临床试验至关重要。[@problem_id:5057046]", "problem": "一个转化医学团队正在计划一项双臂、平行组、随机对照试验，以在生物标志物水平升高的患者中，比较一种新型抗炎小分子药物与标准治疗的效果。主要终点是在一个经过验证的炎症生物标志物上，以标准化单位测量的连续性变化评分。研究者希望通过前瞻性地确定，为达到双侧显著性检验的预设效能所需的每臂最小样本量，来确保研究的严谨性和可重复性，从而避免出现效能不足、无法重复的结果。\n\n假设以下设计特征和建模假设：\n- 两个独立组，采用相等分配，每组样本量为 $n$。\n- 组内的结局是独立同分布的，且具有共同方差 $\\sigma^{2}$。\n- 主要分析将采用显著性水平为 $\\alpha$ 的双侧双样本 $t$ 检验，检验原假设 $H_{0}:\\ \\mu_{1}-\\mu_{2}=0$ 与备择假设 $H_{1}:\\ \\mu_{1}-\\mu_{2}\\neq 0$。其中，$\\mu_{1}-\\mu_{2}$ 表示试验组和对照组之间的真实均值差。\n- 为进行规划，当为 $\\sigma^{2}$ 代入一个规划值时，标准化的样本均值差的抽样分布可根据中心极限定理，用标准正态分布来近似。\n\n任务：\n1. 从 I 型错误（当 $H_{0}$ 为真时拒绝 $H_{0}$ 的概率 $\\alpha$）、II 型错误（当 $H_{1}$ 为真时未能拒绝 $H_{0}$ 的概率 $\\beta$）的核心定义，以及两个独立样本均值之差的分布出发，推导出一个解析表达式，用于计算在显著性水平为 $\\alpha$ 的双侧检验下，达到 $1-\\beta$ 的效能以检测出大小为 $\\delta=|\\mu_{1}-\\mu_{2}|$ 的临床显著差异所需的每臂最小样本量 $n$。您的推导必须从样本均值差的分布、显著性水平为 $\\alpha$ 的双侧检验的拒绝域定义，以及在固定备择假设 $|\\mu_{1}-\\mu_{2}|=\\delta$ 下的效能定义开始。\n2. 然后，根据设计值 $\\alpha=0.05$（双侧）、$1-\\beta=0.90$、临床显著差异 $\\delta=5$ 和共同方差 $\\sigma^{2}=64$，计算得出的每臂样本量 $n$。报告在您推导的准则下，达到或超过目标效能的每臂最小整数 $n$。请提供该整数作为您的最终答案。不要包含任何单位，也不要四舍五入到指定的有效位数；相反，应报告满足要求的确切最小整数 $n$。", "solution": "### 第 1 步：提取已知条件\n- **研究设计**：双臂、平行组、随机对照试验。\n- **分配**：两个独立组，采用相等分配，每组样本量为 $n$。\n- **结局**：一个连续变量，假定在每组内独立同分布。\n- **方差**：两组的共同方差为 $\\sigma^{2}$。\n- **假设检验**：针对原假设 $H_{0}:\\ \\mu_{1}-\\mu_{2}=0$ 与备择假设 $H_{1}:\\ \\mu_{1}-\\mu_{2}\\neq 0$ 的双侧双样本 $t$ 检验。\n- **显著性水平**：$\\alpha$。\n- **效能**：$1-\\beta$。\n- **效应量**：大小为 $\\delta=|\\mu_{1}-\\mu_{2}|$ 的临床显著差异。\n- **近似**：为进行规划，标准化的样本均值差的抽样分布近似于标准正态分布。\n- **推导要求**：推导必须从(1)样本均值差的分布，(2)双侧检验的拒绝域定义，以及(3)固定备择假设下的效能定义开始。\n- **用于计算的数值**：\n    - 显著性水平 $\\alpha=0.05$（双侧）。\n    - 期望效能 $1-\\beta=0.90$。\n    - 临床显著差异 $\\delta=5$。\n    - 共同方差 $\\sigma^{2}=64$。\n\n### 第 2 步：使用提取的已知条件进行验证\n该问题具有科学依据，提法得当且客观。它提出了生物统计学和临床试验设计中一个标准的、基本的问题：为确保足够的统计效能而进行样本量的事先计算。该问题与转化医学中研究严谨性和可重复性的主题直接相关。为求得唯一解所需的所有参数和假设均已提供，且不存在矛盾。在规划阶段使用正态近似代替 $t$ 检验是一种标准且公认的做法，它将推导简化为代数推导而非迭代推导。该问题并非微不足道，因为它要求从第一性原理进行推导。\n\n### 第 3 步：结论与行动\n问题有效。将提供严谨的解答。\n\n### 第 1 部分：样本量公式的推导\n\n设 $\\bar{X}_1$ 和 $\\bar{X}_2$ 为来自两个独立组（试验组和对照组）的样本均值，每组的样本量均为 $n$。假设总体的均值分别为 $\\mu_1$ 和 $\\mu_2$，并有共同方差 $\\sigma^2$。\n\n1.  **样本均值差的分布**：\n    $\\bar{X}_1$ 的均值为 $E[\\bar{X}_1] = \\mu_1$，其方差为 $Var(\\bar{X}_1) = \\frac{\\sigma^2}{n}$。同理，$E[\\bar{X}_2] = \\mu_2$，其方差为 $Var(\\bar{X}_2) = \\frac{\\sigma^2}{n}$。\n    样本均值差为 $D = \\bar{X}_1 - \\bar{X}_2$。\n    该差值的期望为 $E[D] = E[\\bar{X}_1] - E[\\bar{X}_2] = \\mu_1 - \\mu_2$。\n    由于各组是独立的，差值的方差是方差之和：$Var(D) = Var(\\bar{X}_1) + Var(\\bar{X}_2) = \\frac{\\sigma^2}{n} + \\frac{\\sigma^2}{n} = \\frac{2\\sigma^2}{n}$。\n    差值的标准误为 $SE(D) = \\sqrt{\\frac{2\\sigma^2}{n}}$。\n    根据中心极限定理和题目的明确假设，$D$ 的抽样分布近似于正态分布：\n    $$D \\sim N\\left(\\mu_1 - \\mu_2, \\frac{2\\sigma^2}{n}\\right)$$\n\n2.  **原假设下的拒绝域**：\n    原假设为 $H_0: \\mu_1 - \\mu_2 = 0$。在 $H_0$ 下，差值的分布为 $D \\sim N\\left(0, \\frac{2\\sigma^2}{n}\\right)$。\n    检验统计量通过在 $H_0$ 下对 $D$ 进行标准化来构建：\n    $$Z = \\frac{\\bar{X}_1 - \\bar{X}_2}{SE(D)} = \\frac{\\bar{X}_1 - \\bar{X}_2}{\\sigma\\sqrt{2/n}}$$\n    在 $H_0$ 下，$Z \\sim N(0,1)$。\n    对于一个显著性水平为 $\\alpha$ 的双侧检验，如果观察到的统计量落在零分布的尾部，我们就拒绝 $H_0$。设 $z_{\\alpha/2}$ 为标准正态分布的上 $\\alpha/2$ 临界值，定义为 $P(Z > z_{\\alpha/2}) = \\alpha/2$。根据对称性，$P(Z  -z_{\\alpha/2}) = \\alpha/2$。\n    因此，拒绝域定义为 $|Z| > z_{\\alpha/2}$。用均值差 $D$ 来表示，我们在以下情况下拒绝 $H_0$：\n    $$|D| > z_{\\alpha/2} \\sigma\\sqrt{\\frac{2}{n}}$$\n\n3.  **备择假设下的效能**：\n    效能是在备择假设 $H_1$ 为真时正确拒绝 $H_0$ 的概率。效能为 $1-\\beta$。我们考虑一个具体的备择假设，其中真实差异的大小为 $\\delta$，即 $|\\mu_1 - \\mu_2| = \\delta$。不失一般性，我们假设 $\\mu_1 - \\mu_2 = \\delta$，其中 $\\delta > 0$。在此具体备择假设下，均值差的分布为 $D \\sim N\\left(\\delta, \\frac{2\\sigma^2}{n}\\right)$。\n    效能是在此备择分布下，$D$ 落在拒绝域内的概率：\n    $$1-\\beta = P\\left(|D| > z_{\\alpha/2} \\sigma\\sqrt{\\frac{2}{n}} \\;\\middle|\\; \\mu_1 - \\mu_2 = \\delta\\right)$$\n    $$1-\\beta = P\\left(D > z_{\\alpha/2} \\sigma\\sqrt{\\frac{2}{n}}\\right) + P\\left(D  -z_{\\alpha/2} \\sigma\\sqrt{\\frac{2}{n}}\\right)$$\n    为了评估这些概率，我们在备择假设下对 $D$ 进行标准化。设 $Z' = \\frac{D - \\delta}{\\sigma\\sqrt{2/n}}$，其中 $Z' \\sim N(0,1)$。\n    $$1-\\beta = P\\left(\\frac{D - \\delta}{\\sigma\\sqrt{2/n}} > \\frac{z_{\\alpha/2} \\sigma\\sqrt{2/n} - \\delta}{\\sigma\\sqrt{2/n}}\\right) + P\\left(\\frac{D - \\delta}{\\sigma\\sqrt{2/n}}  \\frac{-z_{\\alpha/2} \\sigma\\sqrt{2/n} - \\delta}{\\sigma\\sqrt{2/n}}\\right)$$\n    $$1-\\beta = P\\left(Z' > z_{\\alpha/2} - \\frac{\\delta}{\\sigma\\sqrt{2/n}}\\right) + P\\left(Z'  -z_{\\alpha/2} - \\frac{\\delta}{\\sigma\\sqrt{2/n}}\\right)$$\n    对于一个效能充足的研究，备择假设下的均值 $\\delta$ 位于原假设分布的右尾足够远的位置，以至于观察到结果落在相反（左）尾部的概率可以忽略不计。也就是说，$P\\left(Z'  -z_{\\alpha/2} - \\frac{\\delta}{\\sigma\\sqrt{2/n}}\\right)$ 这一项非常接近于 $0$。我们采用标准近似法：\n    $$1-\\beta \\approx P\\left(Z' > z_{\\alpha/2} - \\frac{\\delta}{\\sigma\\sqrt{2/n}}\\right)$$\n    设 $z_{\\beta}$ 为标准正态分布的上 $\\beta$ 临界值，即 $P(Z' > z_{\\beta}) = \\beta$。根据对称性，$P(Z' > -z_{\\beta}) = 1-\\beta$。为了达到 $1-\\beta$ 的效能，概率积分的下界必须等于 $-z_{\\beta}$：\n    $$z_{\\alpha/2} - \\frac{\\delta}{\\sigma\\sqrt{2/n}} = -z_{\\beta}$$\n    现在，我们求解每臂的样本量 $n$：\n    $$z_{\\alpha/2} + z_{\\beta} = \\frac{\\delta}{\\sigma\\sqrt{2/n}}$$\n    $$\\sqrt{n} = \\frac{\\sigma\\sqrt{2}(z_{\\alpha/2} + z_{\\beta})}{\\delta}$$\n    两边平方，得到 $n$ 的解析表达式：\n    $$n = \\frac{2\\sigma^2(z_{\\alpha/2} + z_{\\beta})^2}{\\delta^2}$$\n    此表达式给出了使用显著性水平为 $\\alpha$ 的双侧检验，以 $1-\\beta$ 的效能检测出大小为 $\\delta$ 的真实差异所需的每臂最小样本量。\n\n### 第 2 部分：针对特定设计值的计算\n\n已知条件为：\n- $\\alpha = 0.05$，所以 $\\alpha/2 = 0.025$。对应的临界值为 $z_{0.025} \\approx 1.960$。\n- $1-\\beta = 0.90$，所以 $\\beta = 0.10$。对应的临界值为 $z_{0.10} \\approx 1.282$。\n- $\\delta = 5$。\n- $\\sigma^2 = 64$。\n\n将这些值代入推导出的 $n$ 的公式中：\n$$n = \\frac{2(64)(1.960 + 1.282)^2}{5^2}$$\n$$n = \\frac{128(3.242)^2}{25}$$\n$$n = \\frac{128(10.510564)}{25}$$\n$$n = \\frac{1345.352192}{25}$$\n$$n \\approx 53.814$$\n\n由于样本量 $n$ 必须是整数，且计算出的值代表最低要求，我们必须对该结果向上取整，以确保效能至少为 $0.90$。不能招募小数个受试者，而向下取整到 $n=53$ 将导致效能略低于 $0.90$ 的目标。\n\n因此，每臂所需的最小整数样本量为 $54$。", "answer": "$$\\boxed{54}$$", "id": "5057046"}, {"introduction": "分析过程中的诚信是确保结论可靠的关键。随着机器学习在转化医学中的兴起，一种被称为“数据泄露”的微妙但致命的错误，可能导致对模型性能的评估过于乐观且无法重现。本练习要求您在一个典型的交叉验证工作流程中诊断出这一常见缺陷。对于任何构建预测模型的研究者来说，掌握这一概念对于确保模型性能评估的真实性和泛化能力都至关重要。[@problem_id:5057006]", "problem": "一个转化医学团队正在构建一个分类器，用于根据从 $n$ 名患者收集的基线多组学特征 ($x \\in \\mathbb{R}^p$) 来预测治疗反应 ($y \\in \\{0,1\\}$)。他们打算使用 $k$-折交叉验证 (CV) 来估计泛化性能，其中在每一折中，模型 $f_i$ 在训练子集 $S_i^{\\text{train}}$ 上进行训练，并在留出的测试子集 $S_i^{\\text{test}}$ 上进行评估。在创建分折之前，该团队使用变换 $T_{\\hat{\\theta}}(x) = (x - \\hat{\\mu}) / \\hat{\\sigma}$ 对所有 $n$ 名患者的每个特征进行标准化，其中 $\\hat{\\mu}$ 和 $\\hat{\\sigma}$ 是在整个数据集 $D$ 上计算的样本均值和标准差，然后在归一化的数据上执行 CV。\n\n基于以下基本定义和经过充分检验的事实，从第一性原理出发回答下面的诊断与设计问题：\n- 期望损失 $R = \\mathbb{E}_{(X,Y) \\sim P}[\\ell(f(X),Y)]$ 的 CV 估计量 $\\hat{R}_{\\text{CV}}$ 依赖于测试数据与训练过程的独立性：对于第 $i$ 折，$S_i^{\\text{test}}$ 必须被排除在任何用于推导 $f_i$ 所用参数的操作之外。\n- 如果参数 $\\theta$ 是从数据中估计的，那么带有参数 $\\theta$ 的数据依赖型预处理变换 $T_{\\theta}$ 就是训练过程的一部分。\n- 在转化医学中，重复测量或共享的批次效应可能会导致样本间的依赖性；保持独立性要求任何估计步骤都不能使用来自第 $i$ 折的 $S_i^{\\text{test}}$ 的信息。\n\n哪个选项正确地诊断了问题，并指定了一个能保持测试折独立性的修正工作流程？\n\nA. 存在数据泄漏，因为 $\\hat{\\mu}$ 和 $\\hat{\\sigma}$ 是使用所有 $n$ 名患者估计的，这通过 $T_{\\hat{\\theta}}$ 将 $S_i^{\\text{test}}$ 与 $S_i^{\\text{train}}$ 耦合起来。修正的工作流程是：对于每一折 $i$，仅使用 $S_i^{\\text{train}}$ 来拟合 $\\hat{\\mu}_{\\text{train},i}$ 和 $\\hat{\\sigma}_{\\text{train},i}$，用 $T_{\\hat{\\theta}_{\\text{train},i}}$ 变换 $S_i^{\\text{train}}$ 和 $S_i^{\\text{test}}$，在变换后的 $S_i^{\\text{train}}$ 上训练 $f_i$，并在变换后的 $S_i^{\\text{test}}$ 上进行评估。如果需要调整超参数，则在 $S_i^{\\text{train}}$ 内执行嵌套 CV，并在每个内部划分中重新拟合缩放器。\n\nB. 不存在泄漏，因为归一化是无监督的（不使用 $y$），并且特征级标准化是单调变换；因此，在 CV 之前全局应用 $T_{\\hat{\\theta}}$ 是可以接受的。\n\nC. 存在潜在的泄漏，但可以通过在全局归一化后对标签 $y$ 进行随机重排，然后计算受试者工作特征曲线下面积 (AUROC) 来消除；随机重排消除了 $T_{\\hat{\\theta}}$ 与测试折之间的依赖关系。\n\nD. 存在数据泄漏，但修正的工作流程是为每一折仅使用 $S_i^{\\text{test}}$ 来计算 $\\hat{\\mu}$ 和 $\\hat{\\sigma}$ 以避免偏差，然后在训练和评估之前使用这些从测试集派生的参数来变换 $S_i^{\\text{train}}$ 和 $S_i^{\\text{test}}$。\n\nE. 存在数据泄漏，但可以通过在整个数据集上进行归一化，然后执行“留一特征交叉验证”来缓解，这样每个模型都不会一次看到所有特征；这可以在不改变归一化策略的情况下保持测试折的独立性。", "solution": "问题要求识别所提出的交叉验证 (CV) 程序中的方法论缺陷，并指定正确的工作流程。问题的核心在于估计预测模型的泛化性能，这要求 CV 每一折中的测试数据在训练过程中完全不被看到。\n\n**1. 问题验证**\n\n问题陈述是有效的。它描述了机器学习流程中一个常见且关键的错误，即数据泄漏或信息泄漏。所提供的关于 CV 估计量、数据依赖型变换的性质以及转化医学中独立性重要性的定义在科学上是合理的，并构成了进行推理的一致基础。该问题提法恰当、客观，并与科学研究中的严谨性和可重复性原则直接相关。\n\n**2. 对所提出工作流程的分析**\n\n既定目标是使用 $k$-折 CV 估计期望损失 $R = \\mathbb{E}_{(X,Y) \\sim P}[\\ell(f(X),Y)]$。CV 的基本原则是在与训练流程所用数据独立的数据上，估计整个学习流程的性能。\n\n提出的工作流程是：\n1.  使用数据集 $D$ 中的所有 $n$ 名患者，计算每个特征的样本均值 $\\hat{\\mu}$ 和样本标准差 $\\hat{\\sigma}$。设这些参数为 $\\hat{\\theta} = (\\hat{\\mu}, \\hat{\\sigma})$。\n2.  使用变换 $T_{\\hat{\\theta}}(x) = (x - \\hat{\\mu}) / \\hat{\\sigma}$ 转换整个数据集 $D$。\n3.  在这个预转换的数据集上执行 $k$-折 CV。\n\n让我们分析单一折 $i$ 的这个过程。数据集被划分为训练集 $S_i^{\\text{train}}$ 和测试集 $S_i^{\\text{test}}$。变换参数 $\\hat{\\theta}$ 是使用所有 $n$ 名患者的数据计算的，这意味着 $\\hat{\\theta}$ 是使用来自 $S_i^{\\text{train}}$ 和 $S_i^{\\text{test}}$ 的数据计算的。\n\n问题陈述指出，“如果参数 $\\theta$ 是从数据中估计的，那么带有参数 $\\theta$ 的数据依赖型预处理变换 $T_{\\theta}$ 就是训练过程的一部分。” 在本例中，标准化是一个数据依赖型变换，其参数 $\\hat{\\theta}$ 是从数据中估计的。\n\n问题还提出了一个关键要求：“对于第 $i$ 折，$S_i^{\\text{test}}$ 必须被排除在任何用于推导 $f_i$ 所用参数的操作之外。” 模型 $f_i$ 是在经过 $T_{\\hat{\\theta}}$ 变换的数据上训练的。因为参数 $\\hat{\\theta}$ 依赖于 $S_i^{\\text{test}}$，所以用于训练 $f_i$ 的数据不再独立于测试集。来自测试集的信息已经“泄漏”到训练过程中。这违反了 CV 的核心假设，导致对泛化性能的估计产生乐观偏差。实际上，模型已经“偷看”了测试数据的统计特性。\n\n**3. 修正的工作流程**\n\n为确保测试集的独立性，整个学习流程，包括任何数据依赖型的预处理，都必须*仅*在每一折的训练数据上进行拟合。然后，测试集应被视为新的、未见过的数据，并应用已完全拟合的流程。\n\n每一折 $i$ ($i \\in \\{1, \\dots, k\\}$) 的修正工作流程应为：\n1.  将原始、未转换的数据集 $D$ 划分为 $S_i^{\\text{train}}$ 和 $S_i^{\\text{test}}$。\n2.  *仅*使用 $S_i^{\\text{train}}$ 中的数据估计预处理参数 $\\hat{\\theta}_{\\text{train},i} = (\\hat{\\mu}_{\\text{train},i}, \\hat{\\sigma}_{\\text{train},i})$。\n3.  将学习到的变换 $T_{\\hat{\\theta}_{\\text{train},i}}$ 应用于训练数据和测试数据*两者*。这会创建一个变换后的训练集和一个变换后的测试集。\n4.  在变换后的训练集上训练分类器 $f_i$。\n5.  在变换后的测试集上评估 $f_i$。\n\n对所有 $k$ 折重复此过程，并对性能指标进行平均。这确保了对于每一折，测试集都完全被排除在模型构建过程的每一步之外，包括缩放参数的估计。\n\n**4. 选项评估**\n\n**A. 存在数据泄漏，因为 $\\hat{\\mu}$ 和 $\\hat{\\sigma}$ 是使用所有 $n$ 名患者估计的，这通过 $T_{\\hat{\\theta}}$ 将 $S_i^{\\text{test}}$ 与 $S_i^{\\text{train}}$ 耦合起来。修正的工作流程是：对于每一折 $i$，仅使用 $S_i^{\\text{train}}$ 来拟合 $\\hat{\\mu}_{\\text{train},i}$ 和 $\\hat{\\sigma}_{\\text{train},i}$，用 $T_{\\hat{\\theta}_{\\text{train},i}}$ 变换 $S_i^{\\text{train}}$ 和 $S_i^{\\text{test}}$，在变换后的 $S_i^{\\text{train}}$ 上训练 $f_i$，并在变换后的 $S_i^{\\text{test}}$ 上进行评估。如果需要调整超参数，则在 $S_i^{\\text{train}}$ 内执行嵌套 CV，并在每个内部划分中重新拟合缩放器。**\n此选项正确地将问题诊断为由全局归一化导致的数据泄漏。所提出的修正方案与上述推导出的原则完全一致：缩放器在分折的训练数据上拟合，并应用于两个数据分割。提及嵌套 CV 和在内循环中重新拟合缩放器也是正确的，因为它将防止泄漏的原则扩展到了超参数选择阶段。\n**结论：正确。**\n\n**B. 不存在泄漏，因为归一化是无监督的（不使用 $y$），并且特征级标准化是单调变换；因此，在 CV 之前全局应用 $T_{\\hat{\\theta}}$ 是可以接受的。**\n这是不正确的。有监督方法和无监督方法之间的区别不是数据泄漏的决定性因素。当来自测试集的信息影响训练过程时，就会发生泄漏。在这里，来自测试集的特征统计数据（$\\hat{\\mu}, \\hat{\\sigma}$）被用来定义应用于训练集的变换。变换的单调性也与违反测试集独立性无关。\n**结论：不正确。**\n\n**C. 存在潜在的泄漏，但可以通过在全局归一化后对标签 $y$ 进行随机重排，然后计算受试者工作特征曲线下面积 (AUROC) 来消除；随机重排消除了 $T_{\\hat{\\theta}}$ 与测试折之间的依赖关系。**\n这是不正确的。随机重排标签是一种用于置换检验的技术，以评估结果的统计显著性，而不是用来纠正数据泄漏。本问题中的泄漏是通过特征 ($x$) 发生的，而不是标签 ($y$)。随机重排标签会破坏特征与结果之间的真实关系，得到的性能指标将估计模型在随机数据上的性能，而不是其真实的泛化性能。它没有修复原始缺陷。\n**结论：不正确。**\n\n**D. 存在数据泄漏，但修正的工作流程是为每一折仅使用 $S_i^{\\text{test}}$ 来计算 $\\hat{\\mu}$ 和 $\\hat{\\sigma}$ 以避免偏差，然后在训练和评估之前使用这些从测试集派生的参数来变换 $S_i^{\\text{train}}$ 和 $S_i^{\\text{test}}$。**\n这是不正确的。虽然它正确地识别了泄漏，但所提出的解决方案在根本上是有缺陷的。它建议在测试数据上拟合缩放器。这是一种极端形式的数据泄漏。训练过程应该模拟从可用数据中学习，以预测未来的、未见过的数据。人们永远无法获知未来数据的统计特性。训练流程必须完全从训练集中推导出来。\n**结论：不正确。**\n\n**E. 存在数据泄漏，但可以通过在整个数据集上进行归一化，然后执行“留一特征交叉验证”来缓解，这样每个模型都不会一次看到所有特征；这可以在不改变归一化策略的情况下保持测试折的独立性。**\n这是不正确的。“留一特征交叉验证”的概念不是解决基于样本的数据泄漏的标准方法。泄漏是关于来自*测试样本*（患者）的信息影响模型训练，而不是关于使用哪些*特征*。即使排除了某些特征，其余特征的归一化参数仍然是使用所有 $n$ 个样本计算的，因此泄漏依然存在。测试*折*（样本子集）的独立性没有得到保持。\n**结论：不正确。**", "answer": "$$\\boxed{A}$$", "id": "5057006"}, {"introduction": "在解读结果时保持严谨性，尤其是在处理复杂数据集时，是科学发现的最后一道关卡。现代“组学”技术使我们能够同时检验成千上万个假设，但这会产生“多重比较问题”，即假阳性的数量会急剧增加。这项练习要求您在一个探索性生物标志物研究的背景下，权衡两种不同的错误控制策略：控制总体错误率（FWER）与控制错误发现率（FDR）。选择正确的统计框架，是在发现新线索的需求与追逐错误线索的成本之间取得平衡的关键，这对于实现可重复的科学至关重要。[@problem_id:5057032]", "problem": "一个转化医学团队进行多重细胞因子分析，以筛选与疾病相关的生物标志物。他们在患者队列和匹配的健康对照组中测量了 $m=100$ 种细胞因子的血清水平。使用预先指定的统计检验方法对每种细胞因子进行差异表达检验，从而产生 $m=100$ 个 $p$ 值。许多细胞因子在生物学上是共同调控的，因此预计检验统计量会呈正相关。该研究被明确定义为发现阶段的筛选，旨在为后续队列中的独立验证提名候选标志物。研究人员的目标是通过预先指定多重性控制来维护科研诚信，并通过生成一个假线索比例有界的候选列表来最大化可重复性。他们考虑了两类错误控制标准：在预先设定的水平上控制的族系误差率（FWER）和错误发现率（FDR）。哪个选项最准确地从第一性原理出发对这些标准进行了对比，并为这项 $m=100$ 的研究确定了最合适的选择，同时其理由基于对信号稀疏性、相关性和下游验证的科学现实考量？\n\nA. 使用标准的步升法将FDR控制在预设水平 $q$。因为FDR限制了发现结果中假线索的预期比例，这与发现阶段的目标和下游验证相符；对于 $m=100$ 个相关的细胞因子，FDR保持了灵敏度，并且在细胞因子网络典型的正相关依赖下，标准的步升法仍然有效。相比之下，将FWER控制在水平 $\\alpha$ 会强制施加随 $m$ 增长的单项检验严格性，从而大大降低功效，并产生很少或没有候选者，这与筛选的目的不符。\n\nB. 对所有 $m=100$ 个检验使用一个简单的统一阈值，将FWER控制在预设水平 $\\alpha$。因为在存在相关检验的情况下，FDR控制是无效的，而FWER是唯一通过完全消除错误发现来确保严谨性的方法；这使得FWER成为发现阶段多重细胞因子分析的合适选择。\n\nC. 在发现阶段筛选期间不应用任何多重性校正。因为独立验证将在之后剔除假阳性；任何多重性控制都会降低功效，并通过在初始筛选中掩盖真实效应来损害可重复性。\n\nD. 通过设置 $q=\\alpha/m$ 来控制FDR。当 $m=100$ 时，由于 $q$ 值很小，这可以同时保证FDR和FWER都得到控制，使得这种混合阈值成为多重分析最严谨和可重复的方法。\n\nE. 倾向于使用FWER控制，并辅以分层建模来借力。因为FDR仅为基因组规模的研究设计，不适用于细胞因子组分析；筛选研究要求任何假阳性的概率接近于零才能保证可重复性，无论下游验证计划如何。", "solution": "在进行解答之前，首先评估问题陈述的有效性。\n\n### 步骤1：提取已知信息\n-   **研究类型：** 转化医学，为疾病相关生物标志物进行的发现阶段筛选。\n-   **分析方法：** 多重细胞因子分析。\n-   **检验数量 ($m$)：** 测量并检验了 $m=100$ 种细胞因子。\n-   **P值：** 生成了 $m=100$ 个 $p$ 值。\n-   **依赖结构：** 由于生物学上的共同调控，检验统计量预期呈正相关。\n-   **研究目标：** 为后续的独立验证提名候选生物标志物。\n-   **明确的目标：**\n    1.  通过预先指定多重性控制方法来维护科研诚信。\n    2.  通过生成一个假线索比例有界的候选短名单来最大化可重复性。\n-   **考虑中的方法：** 族系误差率（FWER）控制和错误发现率（FDR）控制。\n-   **问题：** 对比FWER和FDR，并为本研究确定最合适的选择，理由需基于信号稀疏性、相关性和下游验证计划。\n\n### 步骤2：使用提取的已知信息进行验证\n问题陈述描述了生物统计学和转化研究中一个标准且高度现实的场景。\n\n-   **科学依据充分：** 该问题牢固地植根于生物统计学的既定原则和生物标志物发现的实践现实。多重分析、多重假设检验、FWER、FDR，以及发现阶段和验证阶段之间的区别，都是该领域的基本概念。细胞因子正相关的假设在生物学上是现实的。\n-   **问题定义明确：** 问题定义明确。它提供了一个清晰的背景（在一个发现性筛选中进行 $m=100$ 个相关检验），并要求基于所提供的标准（研究目标、相关性）在两个标准统计框架之间做出合理的选择。可以从统计学的第一性原理推导出一个独特的、合理的答案。\n-   **客观性：** 语言客观而精确。像“FWER”、“FDR”、“正相关”和“发现阶段”等术语在统计学和科学研究中具有清晰、普遍接受的定义。\n\n该问题没有违反任何无效性标准。它在科学上是合理的、定义明确的、客观的、完整的，并提出了一个重要且相关的问题。\n\n### 步骤3：结论与行动\n问题陈述是**有效的**。将进行推导解答。\n\n### 从第一性原理推导\n\n假设有 $m$ 个原假设 $H_1, H_2, \\ldots, H_m$ 被同时检验。我们可以将这 $m$ 个检验的结果总结在一个表格中：\n\n| | 未拒绝 (接受 $H_0$) | 拒绝 (宣布发现) | 总计 |\n|---|---|---|---|\n| $H_0$ 为真 | $U$ (真阴性) | $V$ (假阳性) | $m_0$ |\n| $H_0$ 为假 | $T$ (假阴性) | $S$ (真阳性) | $m_1$ |\n| **总计** | $m-R$ | $R$ (总发现数) | $m$ |\n\n在这里，$m_0$ 是真原假设的数量，$R$ 是被拒绝的假设总数。\n\n**族系误差率 (Familywise Error Rate, FWER):** FWER是在整个检验族系中犯下一次或多次错误发现（I类错误）的概率。\n$$ \\text{FWER} = P(V > 0) $$\n要将FWER控制在水平 $\\alpha$ 以下，我们需要 $P(V > 0) \\le \\alpha$。一个经典的方法是Bonferroni校正，即将 $m$ 个检验中每个检验的显著性阈值设为 $\\alpha/m$。这种方法非常严格，因为它旨在防止哪怕一个假阳性的出现。对于一个可能存在许多真实但微弱信号（低信噪比）的筛选研究，这种严格性会极大地降低统计功效（增加 $T$），可能导致没有任何发现（$R=0$）。这与“发现阶段筛选”的目标背道而驰。\n\n**错误发现率 (False Discovery Rate, FDR):** FDR是所有发现中错误发现的预期比例。\n$$ \\text{FDR} = E\\left[ \\frac{V}{R} \\right], \\text{ with } \\frac{V}{R} := 0 \\text{ if } R=0 $$\n要将FDR控制在水平 $q$ 以下，我们需要 $E[V/R] \\le q$。这意味着，平均而言，所宣布的发现中不超过 $q$ 的比例是错误的。这直接解决了研究的目标，即生成一个“假线索比例有界的候选短名单”。控制FDR的程序，如Benjamini-Hochberg (BH) 步升法，通常比控制FWER的程序具有更高的功效。\n\n**相关性的影响：** 问题指出检验统计量是正相关的。用于控制FDR的BH程序保证在独立检验下是有效的（即达到 $\\text{FDR} \\le q$），并且在一种称为正回归依赖性（PRDS）的条件下也有效。PRDS条件被广泛认为适用于生物数据中发现的多种正依赖结构，例如共同调控的基因或细胞因子。因此，正相关的存在并不会使标准的BH程序在控制FDR方面失效。\n\n**该场景的结论：** 对于一个包含 $m=100$ 个检验的发现阶段筛选，目标是生成一个有希望的候选者列表，以进行更有针对性、更昂贵的后续验证。在这个列表中包含一小部分假阳性是可以接受的，但错过大部分真实信号是不可接受的。FDR控制提供了理想的框架：相对于FWER控制，它提高了发现的功效，同时对发现列表的质量提供了明确的保证（限制了假阳性的预期比例）。这比FWER控制的极端风险规避更符合发现流程的科学和经济现实。\n\n### 逐项分析选项\n\n**A. 使用标准的步升法将FDR控制在预设水平 $ q $。因为FDR限制了发现结果中假线索的预期比例，这与发现阶段的目标和下游验证相符；对于 $ m=100 $ 个相关的细胞因子，FDR保持了灵敏度，并且在细胞因子网络典型的正相关依赖下，标准的步升法仍然有效。相比之下，将FWER控制在水平 $ \\alpha $ 会强制施加随 $ m $ 增长的单项检验严格性，从而大大降低功效，并产生很少或没有候选者，这与筛选的目的不符。**\n此选项是对上述推导推理的精确和准确总结。它正确地定义了FDR的目的，将其与发现性筛选的目标联系起来，正确地指出了其相对于FWER的更高功效（灵敏度），并正确地说明了在给定的相关结构下标准程序的有效性。与FWER的对比也是准确的。\n**结论：正确**\n\n**B. 对所有 $ m=100 $ 个检验使用一个简单的统一阈值，将FWER控制在预设水平 $ \\alpha $。因为在存在相关检验的情况下，FDR控制是无效的，而FWER是唯一通过完全消除错误发现来确保严谨性的方法；这使得FWER成为发现阶段多重细胞因子分析的合适选择。**\n此选项包含几个错误。首先，“在存在相关检验的情况下，FDR控制是无效的”这一说法是错误的。如前所述，BH程序在正依赖性下是有效的。其次，“FWER……完全消除错误发现”的说法是错误的；它只确保一次或多次错误发现的*概率*很低（例如，$\\le 0.05$），而不是零。第三，宣称FWER是“唯一确保严谨性的方法”是一个武断且错误的断言；FDR也是一个严谨的统计框架。最后，它错误地理解了发现阶段研究的目标。\n**结论：不正确**\n\n**C. 在发现阶段筛选期间不应用任何多重性校正。因为独立验证将在之后剔除假阳性；任何多重性控制都会降低功效，并通过在初始筛选中掩盖真实效应来损害可重复性。**\n此选项提倡的是不良的统计实践。对于 $m=100$ 个检验和每个检验的水平 $\\alpha = 0.05$，即使所有原假设都为真，也预期会产生 $100 \\times 0.05 = 5$ 个假阳性。不进行任何校正会使后续阶段充斥着假线索，这既低效又昂贵，并损害了发现过程本身的完整性。问题明确指出研究人员希望“预先指定多重性控制”以保证科研诚信，此选项直接与之相悖。真正的可重复性不是通过最大化原始发现数量来实现的，而是通过确保发现集合的错误率较低来实现的。\n**结论：不正确**\n\n**D. 通过设置 $ q=\\alpha/m $ 来控制FDR。当 $ m=100 $ 时，由于 $ q $ 值很小，这可以同时保证FDR和FWER都得到控制，使得这种混合阈值成为多重分析最严谨和可重复的方法。**\n虽然将FWER控制在水平 $\\alpha$ 意味着FDR也被控制在水平 $\\le \\alpha$ 以下，但提议将FDR阈值 $q$ 设置为 $\\alpha/m$ 是没有意义的。对于Benjamini-Hochberg程序，拒绝第 $k$ 个有序p值的条件是 $p_{(k)} \\le \\frac{k}{m}q$。如果 $q=\\alpha/m$，这就变成 $p_{(k)} \\le \\frac{k}{m^2}\\alpha$。这个阈值比Bonferroni阈值 $\\alpha/m$ 更小（更严格），因为 $k/m \\le 1$。这种方法的功效甚至会低于标准但已经过于保守的Bonferroni校正，完全违背了使用FDR来提高功效的初衷。\n**结论：不正确**\n\n**E. 倾向于使用FWER控制，并辅以分层建模来借力。因为FDR仅为基因组规模的研究设计，不适用于细胞因子组分析；筛选研究要求任何假阳性的概率接近于零才能保证可重复性，无论下游验证计划如何。**\n此选项有两个主要缺陷。首先，“FDR仅为基因组规模的研究设计”的说法是错误的。FDR是一个适用于任何多重检验问题的通用统计原则，它被广泛且适当地用于蛋白质组学和细胞因子组分析，其中 $m$ 的数量在几十到几百之间。其次，“筛选研究要求任何假阳性的概率接近于零”这一断言错误地描述了筛选的目标。这种对错误的近零容忍度是*验证性*研究的特征，而不是发现阶段筛选的特征，后者的主要目标是为进一步研究生成丰富的候选者集合。\n**结论：不正确**", "answer": "$$\\boxed{A}$$", "id": "5057032"}]}