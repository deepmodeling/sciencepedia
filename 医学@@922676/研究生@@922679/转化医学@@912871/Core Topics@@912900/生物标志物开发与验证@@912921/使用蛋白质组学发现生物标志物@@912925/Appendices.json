{"hands_on_practices": [{"introduction": "在蛋白质组学分析中，从海量的质谱数据中准确鉴定出肽段是后续所有分析的基础。本实践将引导你应用靶标-诱饵策略，这是控制蛋白质鉴定中假发现率（FDR）的黄金标准方法。通过亲手实现从原始匹配分数到校准$q$值的计算过程[@problem_id:4994733]，你将深刻理解如何为肽段鉴定提供严格的统计置信度，这是解读蛋白质组学数据的关键一步。", "problem": "给定由串联质谱搜索引擎为两类数据生成的原始肽谱匹配（PSM）分数数组：靶标（推定的真实肽段鉴定）和伪靶标（旨在模拟错误匹配的人工合成或随机打乱的序列）。目标是设计一个有原则的校准程序，使用伪靶标零分布将原始分数转换为显著性值，然后计算最小假发现率（q-值）以确定鉴定阈值。\n\n在你的推导和算法中，请使用以下基本原理：\n\n- 在靶标-伪靶标框架中，假设在零假设下，错误匹配的分布与伪靶标相同。设伪靶标分数从一个零分布中抽样。对于任何原始分数 $s$，通过经验伪靶标尾部概率定义校准的 $p$ 值：\n$$\np(s) = \\frac{\\#\\{\\text{decoy scores } \\ge s\\}}{n_D}\n$$\n其中 $n_D$ 是伪靶标观测的总数。这是一种经验性的、无分布的校准方法，它将异构的原始分数映射到一个共同的显著性尺度上。\n\n- 对于应用于校准后 $p$ 值的显著性阈值 $t$，将 $p$ 值小于或等于 $t$ 的伪靶标数量定义为 $D(t)$，将 $p$ 值小于或等于 $t$ 的靶标数量定义为 $T(t)$。在阈值 $t$ 处的估计假发现率为\n$$\n\\widehat{\\mathrm{FDR}}(t) = \\frac{D(t)}{T(t)} \\, .\n$$\n\n- 对于一个给定的、校准后 $p$ 值为 $p_i$ 的靶标 PSM，其 $q$ 值是它能够被接受的最小假发现率。如果 $p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(m)}$ 表示排序后的靶标 $p$ 值，那么对于排名为 $k$ 的靶标：\n$$\nq_{(k)} = \\min_{j \\ge k} \\widehat{\\mathrm{FDR}}(p_{(j)}) \\, .\n$$\n这强制了 $q$ 值相对于接受阈值的单调性。所有比例和阈值都必须以小数形式表示（例如，使用 $0.05$ 而不是百分号）。\n\n你的任务是在一个程序中实现这种校准和 $q$ 值计算。该程序必须：\n\n1. 不接受任何输入；而是使用下面提供的嵌入式测试套件。\n2. 对于每个测试用例，使用上述定义的经验伪靶标尾部概率 $p(s)$ 为靶标和伪靶标计算校准后的 $p$ 值。\n3. 使用上述定义计算靶标的 $q$ 值，其中 $\\widehat{\\mathrm{FDR}}(t) = D(t)/T(t)$ 且不进行额外的连续性校正。\n4. 对于每个指定的鉴定阈值 $\\alpha$（以小数表示），计算其 $q$ 值小于或等于 $\\alpha$ 的靶标 PSM 的数量。\n5. 将所有测试用例和阈值的这些计数汇总到一个预定义顺序的单一扁平列表中，并将其精确打印一次。\n\n测试套件参数值：\n\n- 测试用例 $1$（一般情况）：\n    - 靶标分数：$[2.1, 3.0, 1.5, 2.7, 3.5, 0.9, 1.2]$\n    - 伪靶标分数：$[0.5, 1.0, 1.4, 2.0, 2.3, 2.6, 2.9, 3.2]$\n    - 阈值 $\\alpha$：$[0.05, 0.10]$\n\n- 测试用例 $2$（具有非常强靶标的边界情况）：\n    - 靶标分数：$[4.0, 3.8, 3.6, 3.5]$\n    - 伪靶标分数：$[0.2, 0.3, 0.4, 0.1, 0.25]$\n    - 阈值 $\\alpha$：$[0.01, 0.05, 0.10]$\n\n- 测试用例 $3$（靶标和伪靶标分数存在并列的边缘情况）：\n    - 靶标分数：$[1.0, 1.0, 0.5]$\n    - 伪靶标分数：$[1.0, 0.5, 0.5]$\n    - 阈值 $\\alpha$：$[0.20]$\n\n输出规范：\n\n- 你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。该列表必须是一个扁平的整数序列，按顺序给出测试用例 1（按给定顺序）在每个阈值下接受的靶标数量，然后是测试用例 2（按给定顺序），最后是测试用例 3（按给定顺序）。例如，输出必须具有 $[\\text{tc1\\_a1},\\text{tc1\\_a2},\\text{tc2\\_a1},\\text{tc2\\_a2},\\text{tc2\\_a3},\\text{tc3\\_a1}]$ 的形式。", "solution": "目标是将原始肽谱匹配（PSM）分数转换为校准后的显著性值，然后确定用于设定鉴定阈值的最小假发现率（$q$ 值）。其科学基础依赖于靶标-伪靶标策略，该策略将伪靶标匹配视为错误匹配零分布的可靠经验替代物。这允许进行非参数校准和对发现进行控制。\n\n原则 1：通过经验零分布进行校准。设伪靶标分数是从错误匹配的零分布中独立抽取的样本。对于任何原始分数 $s$，伪靶标分布下的经验尾部概率给出了一个校准的 $p$ 值：\n$$\np(s) = \\frac{\\#\\{\\text{decoy scores } \\ge s\\}}{n_D} \\, .\n$$\n这个映射在 $s$ 上是单调递减的，并将任意的原始分数转换到一个共同的显著性尺度上。在零假设下，$p(s)$ 在 $[0,1]$ 上近似均匀分布，因为它是一个经验累积分布函数（根据概率积分变换），而在备择假设（真实靶标）下，$p(s)$ 集中在 0 附近。\n\n原则 2：估计假发现率（FDR）。对于校准后 $p$ 值的阈值 $t$，定义\n$$\nD(t) = \\#\\{\\text{decoy } p \\le t\\}, \\quad T(t) = \\#\\{\\text{target } p \\le t\\} \\, .\n$$\n假设搜索是平衡的，并且伪靶标的 $p$ 值代表了零分布，那么在阈值 $t$ 处接受的靶标中，假发现的比例估计为\n$$\n\\widehat{\\mathrm{FDR}}(t) = \\frac{D(t)}{T(t)} \\, .\n$$\n该估计量是接受的零假设样本与接受的靶标样本数量的经验比率。我们在这里不引入连续性校正；因此，如果没有伪靶标被接受，$\\widehat{\\mathrm{FDR}}(t)$ 可以为 0。\n\n原则 3：将 $q$ 值作为最小 FDR。给定靶标 PSM 的 $q$ 值定义为它能被接受的最小假发现率。设排序后的靶标 $p$ 值为 $p_{(1)} \\le p_{(2)} \\le \\cdots \\le p_{(m)}$。在每个排名 $k$ 处，考虑接受阈值 $t = p_{(k)}$ 并计算\n$$\n\\widehat{\\mathrm{FDR}}(p_{(k)}) = \\frac{D(p_{(k)})}{T(p_{(k)})} = \\frac{D(p_{(k)})}{k} \\, .\n$$\n为了强制单调性（即，随着严格性的降低，$q$ 值应该非递减），定义\n$$\nq_{(k)} = \\min_{j \\ge k} \\widehat{\\mathrm{FDR}}(p_{(j)}) \\, .\n$$\n这是在该 PSM 自身接受阈值或更高阈值处的最小 FDR 的经验模拟。\n\n算法设计：\n\n- 使用经验伪靶标尾部概率 $p(s)$ 为靶标和伪靶标计算校准后的 $p$ 值。此步骤执行分数校准，将异构的原始分数转换到统一的显著性尺度上，其合理性由伪靶标建模的经验零分布来保证。\n\n- 将靶标 $p$ 值按升序排序以形成排名。对于每个排序后的靶标阈值 $p_{(k)}$，使用伪靶标 $p$ 值计算 $D(p_{(k)})$，并设 $T(p_{(k)}) = k$。在这些阈值下的估计假发现率为 $\\widehat{\\mathrm{FDR}}(p_{(k)}) = D(p_{(k)})/k$。\n\n- 计算序列 $\\{\\widehat{\\mathrm{FDR}}(p_{(k)})\\}_{k=1}^m$ 的后缀最小值以获得单调的 $q$ 值：$q_{(k)} = \\min_{j \\ge k} \\widehat{\\mathrm{FDR}}(p_{(j)})$。将这些值映射回原始的靶标顺序。\n\n- 对于每个鉴定阈值 $\\alpha$（以小数表示），计算满足 $q_i \\le \\alpha$ 的靶标 $q$ 值的数量。\n\n测试套件覆盖范围的基本原理：\n\n- 测试用例 1 运用了靶标和伪靶标分数之间的典型重叠，产生大小混合的 $p$ 值，并确保 $D(t)$ 和 $T(t)$ 的比率不为平凡值。\n\n- 测试用例 2 代表了一个边界场景，其中靶标远强于伪靶标；此处靶标的经验伪靶标尾部概率为 0，且 $\\widehat{\\mathrm{FDR}}(t)$ 可以为 0，从而验证了算法在严格的 $\\alpha$ 下接受了许多靶标。\n\n- 测试用例 3 引入了靶标和伪靶标分数之间的并列值，以测试计算尾部概率和累积计数时的鲁棒性，确保通过 $\\ge$ 和 $\\le$ 定义对等式的一致处理。\n\n最终输出格式：\n\n- 生成单行输出，其中包含一个扁平的整数列表，按顺序给出测试用例 1 各阈值下接受的靶标数量，然后是测试用例 2 各阈值，最后是测试用例 3 各阈值，格式与 $[\\text{tc1\\_a1},\\text{tc1\\_a2},\\text{tc2\\_a1},\\text{tc2\\_a2},\\text{tc2\\_a3},\\text{tc3\\_a1}]$ 完全一致。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef empirical_p_values(scores, decoy_scores):\n    \"\"\"\n    Compute calibrated p-values for given raw scores using the empirical decoy tail.\n    p(s) = #{decoy >= s} / n_decoy\n    \"\"\"\n    decoy_scores = np.asarray(decoy_scores, dtype=float)\n    n_decoy = decoy_scores.size\n    if n_decoy == 0:\n        return np.zeros_like(scores, dtype=float)\n    # Sort decoys for efficient tail counting using binary search\n    decoy_sorted = np.sort(decoy_scores)\n    # For each s, count how many decoys are >= s using searchsorted on ascending array\n    # Number >= s = n_decoy - index of first element >= s\n    def tail_count(s):\n        idx = np.searchsorted(decoy_sorted, s, side='left')\n        return n_decoy - idx\n    # Vectorize tail_count over scores\n    scores = np.asarray(scores, dtype=float)\n    tail_counts = np.array([tail_count(s) for s in scores], dtype=float)\n    pvals = tail_counts / float(n_decoy)\n    return pvals\n\ndef target_decoy_q_values(target_pvals, decoy_pvals):\n    \"\"\"\n    Compute q-values for targets using the target-decoy FDR estimator:\n    FDR(p_(k)) = D(p_(k)) / k where D counts decoy p-values = threshold.\n    q_{(k)} = min_{j>=k} FDR(p_{(j)}) to enforce monotonicity.\n    \"\"\"\n    target_pvals = np.asarray(target_pvals, dtype=float)\n    decoy_pvals = np.asarray(decoy_pvals, dtype=float)\n    \n    if target_pvals.size == 0:\n        return np.array([], dtype=float)\n\n    # Sort target p-values ascending and keep indices to map back\n    sort_idx = np.argsort(target_pvals)\n    sorted_target_p = target_pvals[sort_idx]\n\n    # Pre-sort decoy p-values ascending for cumulative counting\n    decoy_sorted_p = np.sort(decoy_pvals)\n\n    # For each sorted target threshold t, compute D(t) = # decoy p = t using searchsorted with 'right'\n    D = np.searchsorted(decoy_sorted_p, sorted_target_p, side='right').astype(float)\n    # T(t_k) = k for ranks 1..m\n    m = sorted_target_p.size\n    T = np.arange(1, m + 1, dtype=float)\n\n    # Estimated FDR at each threshold\n    fdr = D / T\n\n    # Compute suffix minimum to get monotone q-values in sorted order\n    # q_sorted[k] = min_{j>=k} fdr[j]\n    # Use cumulative minimum on reversed array, then reverse back\n    rev_cummin = np.minimum.accumulate(fdr[::-1])\n    q_sorted = rev_cummin[::-1]\n\n    # Map back to original order\n    q_vals = np.empty_like(q_sorted)\n    q_vals[sort_idx] = q_sorted\n\n    return q_vals\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test Case 1\n        {\n            \"target_scores\": [2.1, 3.0, 1.5, 2.7, 3.5, 0.9, 1.2],\n            \"decoy_scores\":  [0.5, 1.0, 1.4, 2.0, 2.3, 2.6, 2.9, 3.2],\n            \"alphas\":        [0.05, 0.10],\n        },\n        # Test Case 2\n        {\n            \"target_scores\": [4.0, 3.8, 3.6, 3.5],\n            \"decoy_scores\":  [0.2, 0.3, 0.4, 0.1, 0.25],\n            \"alphas\":        [0.01, 0.05, 0.10],\n        },\n        # Test Case 3\n        {\n            \"target_scores\": [1.0, 1.0, 0.5],\n            \"decoy_scores\":  [1.0, 0.5, 0.5],\n            \"alphas\":        [0.20],\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        target_scores = case[\"target_scores\"]\n        decoy_scores = case[\"decoy_scores\"]\n        alphas = case[\"alphas\"]\n\n        # Step 1: Calibrate scores to p-values using empirical decoy tail\n        target_p = empirical_p_values(target_scores, decoy_scores)\n        decoy_p = empirical_p_values(decoy_scores, decoy_scores)\n\n        # Step 2: Compute q-values for targets using target-decoy FDR estimator\n        q_vals = target_decoy_q_values(target_p, decoy_p)\n\n        # Step 3: For each alpha threshold, count accepted targets (q = alpha)\n        for alpha in alphas:\n            count = int(np.sum(q_vals = float(alpha)))\n            results.append(count)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "4994733"}, {"introduction": "鉴定出候选生物标志物后，下一步是评估它们区分不同临床状态（如疾病与健康）的性能。受试者工作特征（ROC）曲线分析是衡量分类器区分能力的标准化工具。在本实践中，你将学习如何根据一组预测概率从头构建ROC曲线，计算曲线下面积（AUC），并解释其在评估生物标志物性能时的意义[@problem_id:4994751]。此练习还将探讨区分度与校准度这两个核心概念，它们对于在临床决策中正确使用模型至关重要。", "problem": "一个转化蛋白质组学团队正在验证一个通过液相色谱-串联质谱 (LC-MS/MS) 测量的候选生物标志物组合，以区分临床定义的疾病状态与对照组。一个在肽强度特征上训练的概率分类器为盲法验证样本输出了排序后的预测概率。对于验证集，已知的临床状态和模型输出概率如下：\n\n- 存在疾病（阳性）：$\\{0.93,\\,0.85,\\,0.77,\\,0.52,\\,0.40,\\,0.30\\}$。\n- 不存在疾病（阴性）：$\\{0.88,\\,0.68,\\,0.35,\\,0.25,\\,0.15,\\,0.05\\}$。\n\n使用真阳性率（TPR，灵敏度）为 $\\mathrm{TPR} = \\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FN}}$ 和伪阳性率（FPR，$1-$特异度）为 $\\mathrm{FPR} = \\frac{\\mathrm{FP}}{\\mathrm{FP}+\\mathrm{TN}}$ 的基本定义，以及受试者工作特征（ROC）曲线是当预测概率的决策阈值 $\\tau$ 从高到低扫描时 $\\left(\\mathrm{FPR}(\\tau),\\,\\mathrm{TPR}(\\tau)\\right)$ 的参数图，执行以下任务：\n\n- 通过在唯一的模型输出集上扫描 $\\tau$，从第一性原理推导 ROC 曲线，并明确列出 $\\left(\\mathrm{FPR},\\,\\mathrm{TPR}\\right)$ 点的序列。\n- 计算曲线下面积（AUC），即 $\\mathrm{TPR}$ 在 $\\mathrm{FPR}\\in[0,1]$ 上对 $\\mathrm{FPR}$ 的积分，并对给定数据进行精确计算。\n\n此外，对于临床决策，请在此背景下简要解释区分度与校准度的区别。假设通过单调映射 $p' = \\sigma\\!\\left(a + b\\,\\sigma^{-1}(p)\\right)$ 对预测概率进行重校准，其中 $\\sigma(x) = \\frac{1}{1+\\exp(-x)}$，$a = 0$ 且 $b = 2$。讨论（无需进行任何新的数值计算）这种重校准是否会改变 ROC 曲线或 AUC，并解释在不等错分成本的情况下，这对阈值选择的影响。\n\n将最终的 AUC 表示为精确分数或小数。不包含任何单位，也不要使用百分号。如果选择小数，可以精确报告，无需四舍五入。", "solution": "该问题被验证为具有科学依据、定义明确且客观。它提供了足够的数据和清晰的定义，以便为所要求的计算推导出唯一的解决方案，并为概念部分提供合理的讨论。该问题是评估二元分类器的一个标准练习，这是转化医学和生物标志物发现中的一项核心任务。\n\n### 第1部分：ROC 曲线的推导\n\n受试者工作特征（ROC）曲线是在不同决策阈值设置下，真阳性率（TPR）对伪阳性率（FPR）的图。\n\n给定数据如下：\n-   存在疾病（阳性）类别的概率，$P$：$\\{0.93, 0.85, 0.77, 0.52, 0.40, 0.30\\}$。阳性样本总数为 $N_P = 6$。\n-   不存在疾病（阴性）类别的概率，$N$：$\\{0.88, 0.68, 0.35, 0.25, 0.15, 0.05\\}$。阴性样本总数为 $N_N = 6$。\n\nTPR 和 FPR 定义如下：\n$$ \\mathrm{TPR} = \\frac{\\mathrm{TP}}{N_P} \\quad \\text{和} \\quad \\mathrm{FPR} = \\frac{\\mathrm{FP}}{N_N} $$\n其中 TP（真阳性）是分数大于或等于阈值 $\\tau$ 的阳性样本数量，而 FP（伪阳性）是分数 $\\ge \\tau$ 的阴性样本数量。\n\n为了构建 ROC 曲线，我们将每个唯一的分数值视为一个潜在的阈值。我们将所有唯一的分数按降序排序：\n$S = \\{0.93, 0.88, 0.85, 0.77, 0.68, 0.52, 0.40, 0.35, 0.30, 0.25, 0.15, 0.05\\}$。\n\n我们将阈值 $\\tau$ 从一个大于最大分数的值（例如 $\\tau=1$）扫描到一个小于或等于最小分数的值。\n\n1.  对于 $\\tau  0.93$：没有样本被分类为阳性。$\\mathrm{TP}=0$，$\\mathrm{FP}=0$。因此，$(\\mathrm{FPR}, \\mathrm{TPR}) = (0, 0)$。这是 ROC 曲线的起点。\n\n2.  当我们将阈值降低到每个分数以下时，我们更新 TP 或 FP。每当阈值越过一个阳性样本的分数，TP 增加 1，TPR 增加 $1/N_P = 1/6$。每当它越过一个阴性样本的分数，FP 增加 1，FPR 增加 $1/N_N = 1/6$。\n\n随着阈值的降低，生成了以下 $(\\mathrm{FPR}, \\mathrm{TPR})$ 点序列：\n-   $\\tau \\le 0.93$：越过一个阳性分数。TP 变为 1。点：$(\\frac{0}{6}, \\frac{1}{6}) = (0, \\frac{1}{6})$。\n-   $\\tau \\le 0.88$：越过一个阴性分数。FP 变为 1。点：$(\\frac{1}{6}, \\frac{1}{6})$。\n-   $\\tau \\le 0.85$：越过一个阳性分数。TP 变为 2。点：$(\\frac{1}{6}, \\frac{2}{6}) = (\\frac{1}{6}, \\frac{1}{3})$。\n-   $\\tau \\le 0.77$：越过一个阳性分数。TP 变为 3。点：$(\\frac{1}{6}, \\frac{3}{6}) = (\\frac{1}{6}, \\frac{1}{2})$。\n-   $\\tau \\le 0.68$：越过一个阴性分数。FP 变为 2。点：$(\\frac{2}{6}, \\frac{3}{6}) = (\\frac{1}{3}, \\frac{1}{2})$。\n-   $\\tau \\le 0.52$：越过一个阳性分数。TP 变为 4。点：$(\\frac{2}{6}, \\frac{4}{6}) = (\\frac{1}{3}, \\frac{2}{3})$。\n-   $\\tau \\le 0.40$：越过一个阳性分数。TP 变为 5。点：$(\\frac{2}{6}, \\frac{5}{6}) = (\\frac{1}{3}, \\frac{5}{6})$。\n-   $\\tau \\le 0.35$：越过一个阴性分数。FP 变为 3。点：$(\\frac{3}{6}, \\frac{5}{6}) = (\\frac{1}{2}, \\frac{5}{6})$。\n-   $\\tau \\le 0.30$：越过一个阳性分数。TP 变为 6。点：$(\\frac{3}{6}, \\frac{6}{6}) = (\\frac{1}{2}, 1)$。\n-   $\\tau \\le 0.25$：越过一个阴性分数。FP 变为 4。点：$(\\frac{4}{6}, \\frac{6}{6}) = (\\frac{2}{3}, 1)$。\n-   $\\tau \\le 0.15$：越过一个阴性分数。FP 变为 5。点：$(\\frac{5}{6}, \\frac{6}{6}) = (\\frac{5}{6}, 1)$。\n-   $\\tau \\le 0.05$：越过一个阴性分数。FP 变为 6。点：$(\\frac{6}{6}, \\frac{6}{6}) = (1, 1)$。这是最后一个点。\n\nROC 曲线的 $(\\mathrm{FPR}, \\mathrm{TPR})$ 顶点显式序列，从 $(0,0)$ 开始到 $(1,1)$ 结束，如下：\n$$ (0,0) \\to (0, \\frac{1}{6}) \\to (\\frac{1}{6}, \\frac{1}{6}) \\to (\\frac{1}{6}, \\frac{1}{3}) \\to (\\frac{1}{6}, \\frac{1}{2}) \\to (\\frac{1}{3}, \\frac{1}{2}) \\to (\\frac{1}{3}, \\frac{2}{3}) \\to (\\frac{1}{3}, \\frac{5}{6}) \\to (\\frac{1}{2}, \\frac{5}{6}) \\to (\\frac{1}{2}, 1) \\to (\\frac{2}{3}, 1) \\to (\\frac{5}{6}, 1) \\to (1,1) $$\n\n### 第2部分：曲线下面积（AUC）的计算\n\nAUC 是 ROC 曲线下的面积，可以通过对 ROC 曲线的顶点形成的梯形面积求和来计算。\n\n一个等价且更稳健的计算方法是利用其统计学解释：AUC 等于一个随机选择的阳性样本比一个随机选择的阴性样本得分更高的概率，即 $P(S_P > S_N)$。这可以通过 Wilcoxon-Mann-Whitney U 统计量来计算。我们总共有 $N_P \\times N_N = 6 \\times 6 = 36$ 对可能的（阳性，阴性）样本对。\n我们计算满足 $p \\in P$，$n \\in N$ 且 $p > n$ 的配对 $(p, n)$ 的数量。\n-   对于 $p=0.93$：$6$ 对（$0.93 >$ 所有 6 个阴性分数）。\n-   对于 $p=0.85$：$5$ 对（$0.85 >$ 除 $0.88$ 外的所有阴性分数）。\n-   对于 $p=0.77$：$5$ 对（$0.77 >$ 除 $0.88$ 外的所有阴性分数）。\n-   对于 $p=0.52$：$4$ 对（$0.52 > \\{0.35, 0.25, 0.15, 0.05\\}$）。\n-   对于 $p=0.40$：$4$ 对（$0.40 > \\{0.35, 0.25, 0.15, 0.05\\}$）。\n-   对于 $p=0.30$：$3$ 对（$0.30 > \\{0.25, 0.15, 0.05\\}$）。\n一致对的总数是 $6 + 5 + 5 + 4 + 4 + 3 = 27$。\n阳性分数和阴性分数之间没有相同的值。\n因此，AUC 为：\n$$ \\mathrm{AUC} = \\frac{27}{36} = \\frac{3}{4} = 0.75 $$\n\n### 第3部分：区分度与校准度的解释\n\n-   **区分度**指的是模型区分不同类别的能力。一个具有良好区分度的模型会给阳性实例分配比阴性实例更高的分数。ROC 曲线及其相关的 AUC 是纯粹的区分度度量。它们是基于分数的排序构建的。AUC 为 $1.0$ 代表完美的区分度，而 AUC 为 $0.5$ 代表模型的区分能力不优于随机猜测。\n\n-   **校准度**指的是模型的预测概率反映事件真实可能性的程度。如果一个模型是完美校准的，那么在所有它预测概率为 $p$ 的实例中，阳性实例的真实比例也是 $p$。校准度关注的是预测值的绝对意义，而不仅仅是它们的排序。一个模型可以有很好的区分度（高 AUC），但校准得很差（例如，系统性地过于自信或不自信）。\n\n总之，区分度是关于区分不同类别，而校准度是关于概率分数本身的可靠性。\n\n### 第4部分：重校准的影响\n\n提议的重校准是一个单调映射 $p' = \\sigma(a + b\\,\\sigma^{-1}(p))$。当 $a=0$ 且 $b=2$ 时，该映射为 $p' = \\sigma(2\\,\\sigma^{-1}(p))$。sigmoid 函数 $\\sigma(x) = (1+\\exp(-x))^{-1}$ 及其反函数 logit 函数 $\\sigma^{-1}(p) = \\ln(p/(1-p))$ 都是严格单调递增的。由于 $b = 2 > 0$，变换 $x \\mapsto 2x$ 也是严格递增的。严格单调递增函数的复合函数本身也是严格单调递增的。\n\n-   **对 ROC 曲线和 AUC 的影响**：ROC 曲线和 AUC 是区分度的度量，仅依赖于分数的排序。由于重校准函数 $p \\mapsto p'$ 是严格单调的，它保留了预测概率的排序。如果 $p_1 > p_2$，那么 $p'_1 > p'_2$。因此，ROC 曲线将与原始曲线**完全相同**，AUC 将**保持不变**。重校准在不影响区分度的情况下改善了校准度。\n\n-   **对阈值选择的影响**：临床决策通常涉及不同类型错分（伪阳性 vs. 伪阴性）的不等成本。最优决策阈值 $\\tau^*$ 取决于这些成本。例如，为了最小化期望成本，如果预测概率 $p$ 超过与成本比率相关的阈值，则可将其分类为阳性，例如 $\\tau^* = \\frac{C_{FP}}{C_{FP} + C_{FN}}$，其中 $C_{FP}$ 和 $C_{FN}$ 分别是伪阳性和伪阴性的成本。该公式假设概率是良好校准的。如果原始概率 $p$ 未经校准，应用理论上推导的阈值是不正确的。重校准旨在使概率 $p'$ 可靠。通过使用重校准后的概率 $p'$，决策者可以更有信心地应用从成本-效益分析中得出的阈值，相信它将导致最优结果。因此，尽管重校准不改变整体区分能力（AUC），但通过确保用于阈值判断的概率是有意义的，它对于在个体层面做出明智的、对成本敏感的决策至关重要。", "answer": "$$\\boxed{0.75}$$", "id": "4994751"}, {"introduction": "一个生物标志物检测的灵敏度和特异性是其固有属性，但其在真实世界中的临床价值还取决于所测试人群中的疾病患病率。阳性预测值（PPV）和阴性预测值（NPV）是连接检测准确性与临床应用场景的关键桥梁。这个最终实践将引导你使用贝叶斯定理，将灵敏度、特异性和患病率结合起来，计算PPV和NPV[@problem_id:4994694]，从而将抽象的性能指标转化为具体的临床效用，这是转化医学的核心。", "problem": "一种基于平行反应监测 (PRM) 质谱 (MS) 的转化蛋白质组学检测方法已被开发出来，用于使用一组经过验证的肽生物标志物对患者进行临床可干预表型（存在疾病与不存在疾病）的分类。在一个旨在匹配该检测方法在现实世界中部署情况的独立临床验证队列中，该检测方法的性能通过灵敏度 $\\mathrm{sens}$ 和特异度 $\\mathrm{spec}$ 来表征，目标人群的疾病患病率估计为 $P$。灵敏度定义为条件概率 $P(T^{+}\\mid D^{+})$，其中 $T^{+}$ 表示检测结果为阳性，$D^{+}$ 表示存在疾病。特异度定义为 $P(T^{-}\\mid D^{-})$，其中 $T^{-}$ 表示检测结果为阴性，$D^{-}$ 表示不存在疾病。疾病患病率为 $P(D^{+})=P$，因此 $P(D^{-})=1-P$。\n\n从以上定义、全概率公式以及条件概率的贝叶斯定理出发，推导阳性预测值 (PPV) $P(D^{+}\\mid T^{+})$ 和阴性预测值 (NPV) $P(D^{-}\\mid T^{-})$ 关于 $\\mathrm{sens}$、$\\mathrm{spec}$ 和 $P$ 的表达式。然后，对于一个灵敏度 $\\mathrm{sens}=0.92$、特异度 $\\mathrm{spec}=0.85$ 且患病率 $P=0.12$ 的检测（适用于高风险临床人群），对这两个量进行数值计算。\n\n将 PPV 和 NPV 都表示为 0 到 1 之间的小数，并将每个值四舍五入到四位有效数字。将您的最终数值结果以有序对 $(\\mathrm{PPV},\\ \\mathrm{NPV})$ 的形式一起报告。", "solution": "问题要求使用灵敏度、特异度、患病率、全概率公式和贝叶斯定理的基本定义来求解 $P(D^{+}\\mid T^{+})$ 和 $P(D^{-}\\mid T^{-})$。\n\n定义事件：\n- $D^{+}$：存在疾病，\n- $D^{-}$：不存在疾病，\n- $T^{+}$：检测结果为阳性，\n- $T^{-}$：检测结果为阴性。\n\n根据定义，\n- 灵敏度为 $\\mathrm{sens}=P(T^{+}\\mid D^{+})$。\n- 特异度为 $\\mathrm{spec}=P(T^{-}\\mid D^{-})$。\n- 患病率为 $P(D^{+})=P$，因此 $P(D^{-})=1-P$。\n\n从这些定义中，我们还可以得到\n$$\nP(T^{+}\\mid D^{-}) = 1 - \\mathrm{spec}, \\quad P(T^{-}\\mid D^{+}) = 1 - \\mathrm{sens}.\n$$\n\n根据全概率公式，检测结果为阳性的边际概率是\n$$\nP(T^{+}) = P(T^{+}\\mid D^{+})P(D^{+}) + P(T^{+}\\mid D^{-})P(D^{-}) = \\mathrm{sens}\\cdot P + (1-\\mathrm{spec})\\cdot (1-P).\n$$\n同样地，检测结果为阴性的边际概率是\n$$\nP(T^{-}) = P(T^{-}\\mid D^{+})P(D^{+}) + P(T^{-}\\mid D^{-})P(D^{-}) = (1-\\mathrm{sens})\\cdot P + \\mathrm{spec}\\cdot (1-P).\n$$\n\n贝叶斯定理给出的阳性预测值 (PPV) 为\n$$\n\\mathrm{PPV} = P(D^{+}\\mid T^{+}) = \\frac{P(T^{+}\\mid D^{+})P(D^{+})}{P(T^{+})} = \\frac{\\mathrm{sens}\\cdot P}{\\mathrm{sens}\\cdot P + (1-\\mathrm{spec})\\cdot (1-P)}.\n$$\n类似地，贝叶斯定理给出的阴性预测值 (NPV) 为\n$$\n\\mathrm{NPV} = P(D^{-}\\mid T^{-}) = \\frac{P(T^{-}\\mid D^{-})P(D^{-})}{P(T^{-})} = \\frac{\\mathrm{spec}\\cdot (1-P)}{(1-\\mathrm{sens})\\cdot P + \\mathrm{spec}\\cdot (1-P)}.\n$$\n\n现在代入数值 $\\mathrm{sens}=0.92$、$\\mathrm{spec}=0.85$ 和 $P=0.12$。\n\n计算 $\\mathrm{PPV}$ 的各组成部分：\n$$\n\\mathrm{sens}\\cdot P = 0.92 \\times 0.12 = 0.1104,\n$$\n$$\n(1-\\mathrm{spec})\\cdot (1-P) = (1-0.85)\\times (1-0.12) = 0.15 \\times 0.88 = 0.132.\n$$\n因此，\n$$\n\\mathrm{PPV} = \\frac{0.1104}{0.1104 + 0.132} = \\frac{0.1104}{0.2424}.\n$$\n这个分数可以精确地化简为\n$$\n\\mathrm{PPV} = \\frac{1104}{2424} = \\frac{46}{101} \\approx 0.455445544\\ldots\n$$\n四舍五入到四位有效数字，$\\mathrm{PPV} = 0.4554$。\n\n计算 $\\mathrm{NPV}$ 的各组成部分：\n$$\n(1-\\mathrm{sens})\\cdot P = (1-0.92)\\times 0.12 = 0.08 \\times 0.12 = 0.0096,\n$$\n$$\n\\mathrm{spec}\\cdot (1-P) = 0.85 \\times 0.88 = 0.748.\n$$\n因此，\n$$\n\\mathrm{NPV} = \\frac{0.748}{0.0096 + 0.748} = \\frac{0.748}{0.7576}.\n$$\n这个分数可以精确地化简为\n$$\n\\mathrm{NPV} = \\frac{748}{757.6} = \\frac{7480}{7576} = \\frac{935}{947} \\approx 0.987332262\\ldots\n$$\n四舍五入到四位有效数字，$\\mathrm{NPV} = 0.9873$。\n\n按照要求，将两者都报告为四舍五入到四位有效数字的小数，并一起呈现。", "answer": "$$\\boxed{\\begin{pmatrix}0.4554  0.9873\\end{pmatrix}}$$", "id": "4994694"}]}