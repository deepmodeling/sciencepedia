{"hands_on_practices": [{"introduction": "在设计一项关键性III期临床试验时，首要且最基本的步骤是确定所需的样本量。一个恰当的样本量是确保试验在统计学上具有足够的检验效能以检测出有临床意义的疗效，同时避免不必要地浪费资源或让过多受试者暴露于潜在风险之中的关键平衡。本练习将引导您从第一性原理出发，为一个基于二元终点（应答者分析）的优效性试验推导并计算样本量，从而加深您对I类错误、II类错误和统计功效这些核心概念在实践中应用的理解。[@problem_id:5044717]", "problem": "一家申办方正在设计一项转化医学领域的III期关键性试验，以评估一种新型镇痛药在慢性骨关节炎疼痛患者中的疗效。主要终点是一项应答者分析：如果在第$12$周时，患者的数值疼痛评定量表（NPRS，一种$10$分制量表）评分改善至少达到$2$分的最小临床重要差异（MCID），则该患者被定义为应答者。根据在相似入组标准下获得的II期数据，预计对照组的应答概率为$p_{C} = 0.35$，而治疗组的应答概率为$p_{T} = 0.50$。需要检测的具有临床意义的组间改善是这些计划值所隐含的差异$\\Delta = p_{T} - p_{C}$。\n\n该试验将采用单侧优效性假设检验，显著性水平为$\\alpha = 0.025$，统计功效为$1 - \\beta = 0.9$，治疗组与对照组按$1{:}1$的比例进行分配。假设采用以下标准大样本框架：各组内的个体应答是独立同分布的；组水平的应答者计数服从二项分布；并且样本比例之差通过中心极限定理（CLT）近似为正态分布。该检验为Wald型$z$检验，在原假设$H_{0}\\!:\\, p_{T} - p_{C} \\leq 0$下使用合并方差，在备择假设$H_{1}\\!:\\, p_{T} - p_{C}  0$下使用非合并方差。设$\\Phi$表示标准正态分布的累积分布函数（CDF），并记$z_{\\gamma} = \\Phi^{-1}(\\gamma)$为相应的分位数。\n\n从第一性原理出发，推导为达到指定的$\\alpha$和$1-\\beta$所需的每组相等样本量$n$的计划方程。推导应从二项分布模型、中心极限定理（CLT）以及I型和II型错误的定义开始。然后，使用给定的计划值以及$\\alpha$和$1-\\beta$的分位数，计算连续值的每组样本量。将最终答案表示为代表所需每组样本量的单个实数，并四舍五入至四位有效数字。在此计算中，不应用连续性校正或因数据缺失而增加样本量。", "solution": "用户希望我解决以下问题：\n一家申办方正在设计一项转化医学领域的III期关键性试验，以评估一种新型镇痛药在慢性骨关节炎疼痛患者中的疗效。主要终点是一项应答者分析：如果在第$12$周时，患者的数值疼痛评定量表（NPRS，一种$10$分制量表）评分改善至少达到$2$分的最小临床重要差异（MCID），则该患者被定义为应答者。根据在相似入组标准下获得的II期数据，预计对照组的应答概率为$p_{C} = 0.35$，而治疗组的应答概率为$p_{T} = 0.50$。需要检测的具有临床意义的组间改善是这些计划值所隐含的差异$\\Delta = p_{T} - p_{C}$。\n\n该试验将采用单侧优效性假设检验，显著性水平为$\\alpha = 0.025$，统计功效为$1 - \\beta = 0.9$，治疗组与对照组按$1{:}1$的比例进行分配。假设采用以下标准大样本框架：各组内的个体应答是独立同分布的；组水平的应答者计数服从二项分布；并且样本比例之差通过中心极限定理（CLT）近似为正态分布。该检验为Wald型$z$检验，在原假设$H_{0}\\!:\\, p_{T} - p_{C} \\leq 0$下使用合并方差，在备择假设$H_{1}\\!:\\, p_{T} - p_{C}  0$下使用非合并方差。设$\\Phi$表示标准正态分布的累积分布函数（CDF），并记$z_{\\gamma} = \\Phi^{-1}(\\gamma)$为相应的分位数。\n\n从第一性原理出发，推导为达到指定的$\\alpha$和$1-\\beta$所需的每组相等样本量$n$的计划方程。推导应从二项分布模型、中心极限定理（CLT）以及I型和II型错误的定义开始。然后，使用给定的计划值以及$\\alpha$和$1-\\beta$的分位数，计算连续值的每组样本量。将最终答案表示为代表所需每组样本量的单个实数，并四舍五入至四位有效数字。在此计算中，不应用连续性校正或因数据缺失而增加样本量。\n\n## 问题验证\n\n### 步骤 1：提取已知条件\n-   主要终点：基于第$12$周NPRS改善$\\ge 2$分（MCID）的应答者分析。\n-   对照组应答概率：$p_{C} = 0.35$。\n-   治疗组应答概率：$p_{T} = 0.50$。\n-   关注的效应量：$\\Delta = p_{T} - p_{C}$。\n-   假设检验：单侧优效性检验。\n-   显著性水平：$\\alpha = 0.025$。\n-   统计功效：$1 - \\beta = 0.9$。\n-   分配比例：$1:1$，每组样本量相等，为$n$。\n-   统计框架：大样本，每组独立的二项应答，通过CLT对比例之差进行正态近似。\n-   检验统计量：Wald型$z$检验，在$H_0$下使用合并方差。\n-   功效计算：在$H_1$下使用非合并方差。\n-   假设：$H_{0}: p_{T} - p_{C} \\leq 0$ 和 $H_{1}: p_{T} - p_{C}  0$。\n-   符号：$\\Phi$是标准正态CDF，$z_{\\gamma} = \\Phi^{-1}(\\gamma)$是分位数函数。\n-   任务：推导样本量$n$的公式并计算其值。\n-   最终答案：连续值$n$，四舍五入至四位有效数字。无连续性校正。\n\n### 步骤 2：使用提取的已知条件进行验证\n1.  **科学依据**：该问题是统计学原理在随机对照试验设计中的一个标准、典型的应用，这是转化医学和药物开发的基石。所有概念（应答者分析、MCID、$\\alpha$、$\\beta$、CLT、$z$检验）都是生物统计学的基础。\n2.  **适定性**：该问题提供了推导和计算唯一样本量所需的所有必要参数（$p_C$、$p_T$、$\\alpha$、$\\beta$、分配比例、检验类型）。目标明确。\n3.  **客观性**：问题以精确、定量和客观的语言陈述，没有主观论断。\n4.  **不完整或矛盾的设置**：设置是完整且自洽的。指定在原假设下使用合并方差进行检验，在备择假设下使用非合并方差进行功效计算，这是样本量计算的标准且明确定义的惯例。\n5.  **不切实际或不可行**：所提供的概率（$35\\%$和$50\\%$的应答率）和设计参数（$\\alpha=0.025$，功效=$90\\%$）对于慢性疼痛适应症的III期试验来说是非常现实的。\n6.  **不适定或结构不良**：问题结构良好，可以导出一个确定的解。\n7.  **伪深刻、琐碎或同义反复**：该任务要求从第一性原理进行推导，这是一个将基础理论与实用公式联系起来的非平凡练习。这是一个实质性的问题。\n8.  **超出科学可验证性范围**：推导和计算在数学上是可验证的。\n\n### 步骤 3：结论与行动\n问题有效。将提供完整解答。\n\n## 解答推导与计算\n我们的任务是为一个比较两个独立比例$p_T$和$p_C$的单侧优效性检验推导每组的样本量$n$。\n\n设$\\hat{p}_T$和$\\hat{p}_C$分别为治疗组和对照组的样本应答比例，每组样本量为$n$。假设为：\n$$H_0: p_T - p_C \\le 0 \\quad \\text{vs.} \\quad H_1: p_T - p_C  0$$\n根据中心极限定理，对于大样本量$n$，样本比例近似服从正态分布。因此，样本比例之差$\\hat{D} = \\hat{p}_T - \\hat{p}_C$也近似服从正态分布。\n\n$\\hat{D}$的分布取决于真实的潜在概率。\n在特定备择假设$H_1$下，即真实概率为$p_T$和$p_C$时，$\\hat{D}$的分布为：\n$$ \\hat{D} | H_1 \\sim \\mathcal{N}\\left(p_T - p_C, \\frac{p_T(1-p_T)}{n} + \\frac{p_C(1-p_C)}{n}\\right) $$\n方差项是为功效计算所指定的非合并方差。我们将$H_1$下差值的标准差记为$\\sigma_{H_1} = \\sqrt{\\frac{p_T(1-p_T) + p_C(1-p_C)}{n}}$。\n\n检验在显著性水平$\\alpha$下进行。这意味着I型错误（当$H_0$为真时拒绝$H_0$）的概率最多为$\\alpha$。如果观测到的差异$\\hat{D}$超过一个临界值$D_{crit}$，我们就拒绝$H_0$。\n$$ \\mathbb{P}(\\hat{D}  D_{crit} | H_0 \\text{ is true}) = \\alpha $$\n在原假设的边界上，有$p_T = p_C = p$。问题指定对检验统计量使用合并方差。这意味着在设计阶段，原假设下的方差是基于单个合并概率。在样本量规划中，这个概率的标准选择是在$H_1$下预期概率的平均值，记为$\\bar{p} = \\frac{p_T + p_C}{2}$。\n在这种原假设情景下（$p_T = p_C = \\bar{p}$），$\\hat{D}$的均值为$0$，其方差为$\\frac{\\bar{p}(1-\\bar{p})}{n} + \\frac{\\bar{p}(1-\\bar{p})}{n} = \\frac{2\\bar{p}(1-\\bar{p})}{n}$。\n设该原假设下的标准差为$\\sigma_{H_0} = \\sqrt{\\frac{2\\bar{p}(1-\\bar{p})}{n}}$。\nI型错误的条件可以通过对$D_{crit}$进行标准化来表示：\n$$ \\mathbb{P}\\left(\\frac{\\hat{D} - 0}{\\sigma_{H_0}}  \\frac{D_{crit}}{\\sigma_{H_0}} \\bigg| H_0\\right) = \\alpha $$\n这意味着$\\frac{D_{crit}}{\\sigma_{H_0}} = z_{1-\\alpha}$，其中$z_{1-\\alpha}$是标准正态分布的$(1-\\alpha)$分位数。\n求解$D_{crit}$，得到我们的第一个表达式：\n$$ D_{crit} = z_{1-\\alpha} \\sigma_{H_0} = z_{1-\\alpha} \\sqrt{\\frac{2\\bar{p}(1-\\bar{p})}{n}} $$\n\n接下来，我们考虑研究的功效，$1-\\beta$。功效是在特定备择假设$H_1$为真时正确拒绝$H_0$的概率。\n$$ \\mathbb{P}(\\hat{D}  D_{crit} | H_1 \\text{ is true}) = 1-\\beta $$\n为了评估这个概率，我们使用$\\hat{D}$在$H_1$下的分布对其进行标准化：\n$$ \\mathbb{P}\\left(\\frac{\\hat{D} - (p_T - p_C)}{\\sigma_{H_1}}  \\frac{D_{crit} - (p_T - p_C)}{\\sigma_{H_1}} \\bigg| H_1\\right) = 1-\\beta $$\n这意味着概率函数的参数必须是$z_{1-\\beta}$。然而，标准正态累积分布函数$\\Phi$通常用于形如$\\mathbb{P}(Z \\le z)$的概率。重写该条件：\n$$ \\mathbb{P}\\left(\\frac{\\hat{D} - (p_T - p_C)}{\\sigma_{H_1}} \\le \\frac{D_{crit} - (p_T - p_C)}{\\sigma_{H_1}} \\bigg| H_1\\right) = \\beta $$\n这要求$\\frac{D_{crit} - (p_T - p_C)}{\\sigma_{H_1}} = z_{\\beta}$。因为$z_\\beta = -z_{1-\\beta}$，我们可以写成：\n$$ D_{crit} - (p_T - p_C) = -z_{1-\\beta} \\sigma_{H_1} $$\n求解$D_{crit}$，得到我们的第二个表达式：\n$$ D_{crit} = (p_T - p_C) - z_{1-\\beta} \\sigma_{H_1} = (p_T - p_C) - z_{1-\\beta} \\sqrt{\\frac{p_T(1-p_T) + p_C(1-p_C)}{n}} $$\n\n现在，我们令$D_{crit}$的两个表达式相等，以求解$n$：\n$$ z_{1-\\alpha} \\sqrt{\\frac{2\\bar{p}(1-\\bar{p})}{n}} = (p_T - p_C) - z_{1-\\beta} \\sqrt{\\frac{p_T(1-p_T) + p_C(1-p_C)}{n}} $$\n设$\\Delta = p_T - p_C$。重新整理各项以分离出$n$：\n$$ \\Delta = z_{1-\\alpha} \\sqrt{\\frac{2\\bar{p}(1-\\bar{p})}{n}} + z_{1-\\beta} \\sqrt{\\frac{p_T(1-p_T) + p_C(1-p_C)}{n}} $$\n提出因子$\\frac{1}{\\sqrt{n}}$：\n$$ \\Delta = \\frac{1}{\\sqrt{n}} \\left( z_{1-\\alpha} \\sqrt{2\\bar{p}(1-\\bar{p})} + z_{1-\\beta} \\sqrt{p_T(1-p_T) + p_C(1-p_C)} \\right) $$\n求解$\\sqrt{n}$然后平方，得到每组样本量$n$的最终计划方程：\n$$ n = \\frac{\\left( z_{1-\\alpha} \\sqrt{2\\bar{p}(1-\\bar{p})} + z_{1-\\beta} \\sqrt{p_T(1-p_T) + p_C(1-p_C)} \\right)^2}{\\Delta^2} $$\n其中$\\bar{p} = \\frac{p_C + p_T}{2}$。这就完成了从第一性原理的推导。\n\n现在我们代入给定值来计算$n$：\n-   $p_C = 0.35$\n-   $p_T = 0.50$\n-   $\\alpha = 0.025$ (单侧)\n-   $1 - \\beta = 0.90 \\implies \\beta = 0.10$\n\n我们首先计算所需的组成部分：\n-   差值：$\\Delta = p_T - p_C = 0.50 - 0.35 = 0.15$。\n-   用于原假设方差的合并概率：$\\bar{p} = \\frac{0.35 + 0.50}{2} = 0.425$。\n-   标准正态分布的分位数：\n    -   $z_{1-\\alpha} = z_{1-0.025} = z_{0.975} \\approx 1.959964$。\n    -   $z_{1-\\beta} = z_{1-0.10} = z_{0.90} \\approx 1.281552$。\n-   方差分量（将乘以$1/n$）：\n    -   合并方差项（用于原假设）：$2\\bar{p}(1-\\bar{p}) = 2(0.425)(1 - 0.425) = 2(0.425)(0.575) = 0.48875$。\n    -   非合并方差项（用于备择假设）：$p_T(1-p_T) + p_C(1-p_C) = 0.50(0.50) + 0.35(0.65) = 0.25 + 0.2275 = 0.4775$。\n\n将这些值代入推导出的公式：\n$$ n = \\frac{\\left( z_{0.975} \\sqrt{0.48875} + z_{0.90} \\sqrt{0.4775} \\right)^2}{(0.15)^2} $$\n$$ n = \\frac{\\left( 1.959964 \\times \\sqrt{0.48875} + 1.281552 \\times \\sqrt{0.4775} \\right)^2}{0.0225} $$\n首先，计算平方根：\n$$ \\sqrt{0.48875} \\approx 0.69910657 $$\n$$ \\sqrt{0.4775} \\approx 0.69101375 $$\n现在计算分子括号中的各项：\n$$ n = \\frac{\\left( 1.959964 \\times 0.69910657 + 1.281552 \\times 0.69101375 \\right)^2}{0.0225} $$\n$$ n = \\frac{\\left( 1.370222... + 0.885541... \\right)^2}{0.0225} $$\n$$ n = \\frac{\\left( 2.255763... \\right)^2}{0.0225} $$\n$$ n = \\frac{5.08847...}{0.0225} $$\n$$ n \\approx 226.1542... $$\n\n问题要求将连续值的样本量四舍五入到四位有效数字。\n$$ n = 226.2 $$\n这是试验每组所需的样本量。", "answer": "$$\\boxed{226.2}$$", "id": "5044717"}, {"introduction": "在临床试验中，尤其是在肿瘤学领域，生存时间等时间-事件终点至关重要。标准的分析方法，如Cox比例风险模型，依赖于一个关键假设——比例风险（Proportional Hazards, PH）假设。然而，随着免疫疗法等新型治疗手段的出现，其疗效模式（如延迟效应）常常导致该假设不成立。本练习提供了一个非比例风险的假设场景，旨在挑战您对传统风险比（Hazard Ratio, HR）解释的理解，并促使您思考在这种复杂情况下，如何选择和解释更稳健的效应评估指标，例如限制性平均生存时间（Restricted Mean Survival Time, RMST）。[@problem_id:5044569]", "problem": "一项针对转移性疾病的 III 期关键性优效性试验设计，以总生存期为主要终点。对照组的死亡风险在时间 $t \\ge 0$ 内为每月 $0.05$ 的恒定风险。假设实验组表现出延迟的临床效果和早期毒性：其死亡风险在 $0 \\le t \\le 6$ 期间为每月 $0.10$，在 $t  6$ 时为每月 $0.02$。考虑标准的 Cox 比例风险模型分析和对数秩检验，这两者都预设了风险比是时间恒定的。研究者们正在辩论，当风险不成比例时，风险比（HR）是否可解释，以及是否应预先指定一个替代的估计量，例如限制性平均生存时间（RMST）。\n\n仅使用风险函数、生存函数和比例风险含义的基本定义，从第一性原理出发对该情景进行推理。在不假设上述分段风险未隐含的任何比例风险性质的情况下，确定下列哪些陈述是正确的。\n\nA. 在此设定中，瞬时风险比在 $0 \\le t \\le 6$ 时为 $2$，在 $t  6$ 时为 $0.4$。因此，单一的 Cox 模型风险比不能代表一个恒定的相对效应；Cox 估计值将反映一个由事件较多时期主导的加权平均值，即使后期治疗组的风险较低，该估计值也可能大于 $1$。\n\nB. Cox 模型部分似然估计的风险比等于截至任何固定时间 $\\,\\tau\\,$ 的累积风险之比，即 $\\,\\widehat{\\mathrm{HR}} = \\Lambda_{\\text{treat}}(\\tau) / \\Lambda_{\\text{control}}(\\tau)\\,$，这在非比例风险下提供了一个有效的估计量。\n\nC. 截至 $\\tau = 24$ 个月的限制性平均生存时间差异约为 $-1.17$ 个月（实验组减去对照组），而截至 $\\tau = 36$ 个月的差异约为 $+0.20$ 个月，这表明 RMST 不假定比例风险，其解释依赖于截断时间 $\\tau$。\n\nD. 按随机化分层对 Cox 模型进行分层可恢复比例风险，并使风险比即使在真实的组特定风险随时间交叉时也能被解释为恒定效应。\n\nE. 预先指定的加权对数秩检验，例如使用 Fleming–Harrington 后期事件加权或 MaxCombo 程序，相对于标准对数秩检验，可以增加对延迟治疗效果的检验效能，但应预先指定相应的效应量估计量，例如 RMST 的差异或里程碑生存概率。\n\n选择所有适用的选项。", "solution": "问题陈述是有效的。它在生物统计学和临床试验设计领域，提出了一个有科学依据、定义明确且客观的情景。对照组和实验组的风险函数已完全指定，允许进行严谨的数学分析。问题要求基于生存分析的基本原理来评估几个陈述，这是一项可行且定义明确的任务。\n\n我们首先根据提供的信息定义基本量。\n\n设 $h_C(t)$ 和 $h_E(t)$ 分别为对照组和实验组的风险函数。\n设 $S_C(t)$ 和 $S_E(t)$ 为相应的生存函数。\n设 $\\Lambda_C(t)$ 和 $\\Lambda_E(t)$ 为相应的累积风险函数。\n\n基本关系如下：\n累积风险：$\\Lambda(t) = \\int_0^t h(u) du$\n生存函数：$S(t) = \\exp(-\\Lambda(t))$\n限制性平均生存时间（RMST）：$RMST(\\tau) = \\int_0^\\tau S(t) dt$\n\n问题陈述如下：\n对照组：$h_C(t) = 0.05$，对于 $t \\ge 0$。\n实验组：\n$h_E(t) = 0.10$，对于 $0 \\le t \\le 6$\n$h_E(t) = 0.02$，对于 $t  6$\n\n由此，我们可以推导出各组的具体函数。\n\n**对照组：**\n-   累积风险：$\\Lambda_C(t) = \\int_0^t 0.05 du = 0.05t$。\n-   生存函数：$S_C(t) = e^{-0.05t}$。\n\n**实验组：**\n-   累积风险是分段的：\n    对于 $0 \\le t \\le 6$：$\\Lambda_E(t) = \\int_0^t 0.10 du = 0.10t$。\n    对于 $t  6$：$\\Lambda_E(t) = \\int_0^6 0.10 du + \\int_6^t 0.02 du = 0.6 + 0.02(t-6) = 0.6 + 0.02t - 0.12 = 0.48 + 0.02t$。\n-   生存函数是分段的：\n    对于 $0 \\le t \\le 6$：$S_E(t) = e^{-0.10t}$。\n    对于 $t  6$：$S_E(t) = e^{-(0.48 + 0.02t)}$。\n\n现在，我们评估每个陈述。\n\n**A. 在此设定中，瞬时风险比在 $0 \\le t \\le 6$ 时为 $2$，在 $t  6$ 时为 $0.4$。因此，单一的 Cox 模型风险比不能代表一个恒定的相对效应；Cox 估计值将反映一个由事件较多时期主导的加权平均值，即使后期治疗组的风险较低，该估计值也可能大于 $1$。**\n\n首先，我们计算瞬时风险比，$HR(t) = h_E(t) / h_C(t)$。\n-   对于 $0 \\le t \\le 6$：$HR(t) = 0.10 / 0.05 = 2.0$。\n-   对于 $t  6$：$HR(t) = 0.02 / 0.05 = 0.4$。\n该陈述的第一部分是正确的。风险比不是恒定的，因此违反了比例风险（PH）假设。来自标准 Cox 模型的单一风险比是一种误设，因为它假定相对效应是恒定的。\n\n在非比例风险下，对数风险比的 Cox 部分似然估计量 $\\hat{\\beta}$，已知是真实时变对数风险比 $\\log(HR(t))$ 的加权平均值的估计。权重与每个事件时间贡献的统计信息量有关，而该信息量大致与当时发生的事件数量成正比。\n\n在这种情况下，实验组在早期（$0 \\le t \\le 6$）的风险（$h_E=0.10$）远高于后期（$h_E=0.02$）。早期两组的总风险也很高。这意味着试验中总事件的很大一部分将发生在前 6 个月内，而此时的 $HR$ 为 $2.0$。后期的总风险较低，且 $HR$ 为 $0.4$。因为 Cox 估计值由事件较多的时期主导，最终的估计值将受到早期 $HR=2.0$ 的严重影响。因此，单一估计的风险比大于 $1$ 是非常可能的，甚至是预料之中的。该陈述正确地描述了这种行为。\n\n对 A 的判断：**正确**。\n\n**B. Cox 模型部分似然估计的风险比等于截至任何固定时间 $\\,\\tau\\,$ 的累积风险之比，即 $\\,\\widehat{\\mathrm{HR}} = \\Lambda_{\\text{treat}}(\\tau) / \\Lambda_{\\text{control}}(\\tau)\\,$，这在非比例风险下提供了一个有效的估计量。**\n\n该陈述为 Cox 模型估计量提出了一个特定的数学恒等式。我们来检验这个提议的估计量，$R(\\tau) = \\Lambda_E(\\tau) / \\Lambda_C(\\tau)$。\n-   对于 $0 \\le \\tau \\le 6$：$R(\\tau) = (0.10\\tau) / (0.05\\tau) = 2.0$。\n-   对于 $\\tau  6$：$R(\\tau) = (0.48 + 0.02\\tau) / (0.05\\tau) = 9.6/\\tau + 0.4$。\n\n这个比率 $R(\\tau)$ 的值取决于 $\\tau$ 的选择。例如，$R(6)=2.0$，$R(12) = 9.6/12 + 0.4 = 0.8 + 0.4 = 1.2$，以及 $R(24) = 9.6/24 + 0.4 = 0.4 + 0.4 = 0.8$。然而，Cox 模型只产生一个单一的风险比数值 $\\widehat{HR}$。一个单一的数值 $\\widehat{HR}$ 在数学上不可能等于一个随 $\\tau$ 变化的函数 $R(\\tau)$。该陈述声称这对“任何固定的时间 $\\tau$”都成立，这是错误的。Cox 部分似然估计量是从一个得分方程推导出来的，该方程不能简化为这个累积风险之比。\n\n对 B 的判断：**不正确**。\n\n**C. 截至 $\\tau = 24$ 个月的限制性平均生存时间差异约为 $-1.17$ 个月（实验组减去对照组），而截至 $\\tau = 36$ 个月的差异约为 $+0.20$ 个月，这表明 RMST 不假定比例风险，其解释依赖于截断时间 $\\tau$。**\n\n我们必须计算 RMST 差异，$\\Delta RMST(\\tau) = RMST_E(\\tau) - RMST_C(\\tau)$，对于 $\\tau=24$ 和 $\\tau=36$。\n\n$RMST_C(\\tau) = \\int_0^\\tau e^{-0.05t} dt = \\left[ -\\frac{1}{0.05}e^{-0.05t} \\right]_0^\\tau = 20(1 - e^{-0.05\\tau})$。\n-   $RMST_C(24) = 20(1 - e^{-0.05 \\times 24}) = 20(1 - e^{-1.2}) \\approx 20(1 - 0.301194) \\approx 13.9761$ 个月。\n-   $RMST_C(36) = 20(1 - e^{-0.05 \\times 36}) = 20(1 - e^{-1.8}) \\approx 20(1 - 0.165299) \\approx 16.6940$ 个月。\n\n$RMST_E(\\tau) = \\int_0^\\tau S_E(t) dt$。对于 $\\tau  6$，这是一个分段积分：\n$RMST_E(\\tau) = \\int_0^6 e^{-0.10t} dt + \\int_6^\\tau e^{-(0.48+0.02t)} dt$。\n-   第一部分：$\\int_0^6 e^{-0.10t} dt = \\left[ -\\frac{1}{0.10}e^{-0.10t} \\right]_0^6 = 10(1 - e^{-0.6}) \\approx 10(1 - 0.548812) \\approx 4.5119$ 个月。\n-   第二部分：$\\int_6^\\tau e^{-0.48}e^{-0.02t} dt = e^{-0.48} \\left[ -\\frac{1}{0.02}e^{-0.02t} \\right]_6^\\tau = 50e^{-0.48} (e^{-0.12} - e^{-0.02\\tau}) = 50(e^{-0.6} - e^{-(0.48+0.02\\tau)})$。\n\n对于 $\\tau=24$：\n$RMST_E(24) = 4.5119 + 50(e^{-0.6} - e^{-(0.48+0.02 \\times 24)}) = 4.5119 + 50(e^{-0.6} - e^{-0.96})$。\n$RMST_E(24) \\approx 4.5119 + 50(0.548812 - 0.382893) = 4.5119 + 50(0.165919) = 4.5119 + 8.2960 = 12.8079$ 个月。\n$\\Delta RMST(24) = 12.8079 - 13.9761 = -1.1682 \\approx -1.17$ 个月。\n\n对于 $\\tau=36$：\n$RMST_E(36) = 4.5119 + 50(e^{-0.6} - e^{-(0.48+0.02 \\times 36)}) = 4.5119 + 50(e^{-0.6} - e^{-1.2})$。\n$RMST_E(36) \\approx 4.5119 + 50(0.548812 - 0.301194) = 4.5119 + 50(0.247618) = 4.5119 + 12.3809 = 16.8928$ 个月。\n$\\Delta RMST(36) = 16.8928 - 16.6940 = +0.1988 \\approx +0.20$ 个月。\n\n计算结果证实了陈述中的数值。RMST，根据其作为生存函数积分的定义，不需要任何关于比例风险的假设。RMST 差异的符号随截断时间 $\\tau$ 的选择而改变（从 24 个月时的负值变为 36 个月时的正值），这一事实完美地说明了当用 RMST 衡量治疗效果时，其解释严重依赖于预先指定的时间范围 $\\tau$。\n\n对 C 的判断：**正确**。\n\n**D. 按随机化分层对 Cox 模型进行分层可恢复比例风险，并使风险比即使在真实的组特定风险随时间交叉时也能被解释为恒定效应。**\n\n在 Cox 模型中，分层是一种处理不满足 PH 假设的协变量的技术。分层 Cox 模型估计暴露在不同分层中的共同风险比，但允许基线风险函数在分层之间有所不同。模型形式为 $h(t|X, Z=k) = h_{0k}(t) \\exp(\\beta X)$，其中 $k$ 表示分层，$X$ 是暴露变量（例如，治疗组）。\n\n该方法*不能*解决暴露变量本身的不成比例性问题。模型仍然假设 $X$ 的风险比 $\\exp(\\beta)$ 在*每个分层内*随时间是恒定的。问题描述的是治疗效果的不成比例性，意味着比率 $h_E(t)/h_C(t)$ 是随时间变化的。通过其他变量（随机化因素）进行分层无法修复这个根本性的违规。治疗的风险比在每个分层内仍然会随时间交叉，模型将继续是误设的。\n\n对 D 的判断：**不正确**。\n\n**E. 预先指定的加权对数秩检验，例如使用 Fleming–Harrington 后期事件加权或 MaxCombo 程序，相对于标准对数秩检验，可以增加对延迟治疗效果的检验效能，但应预先指定相应的效应量估计量，例如 RMST 的差异或里程碑生存概率。**\n\n标准对数秩检验在比例风险假设下效能最高，因为它对所有时间点给予相同的权重。在延迟效应情景中，治疗初期有害（$HR=2.0$）而后期有益（$HR=0.4$），标准对数秩检验会因早期事件对治疗不利而损失大量效能。\n\n加权对数秩检验，例如 Fleming-Harrington $G^{\\rho, \\gamma}$ 族检验，就是为了解决这个问题而设计的。通过选择能够增加后期时间点权重的参数（例如，$\\rho=0, \\gamma  0$），检验可以更侧重于治疗效果有利的时期，从而提高检测到真实晚期益处的统计效能。一种“MaxCombo”检验，它结合了几个不同加权的对数秩检验并对多重性进行调整，是在包括延迟效应在内的各种非比例风险模式下保持良好效能的稳健策略。因此，该陈述的第一部分是正确的。\n\n在使用此类检验时，所得的检验统计量不易转化为直观的效应量。由于非比例风险（NPH），来自 Cox 模型的风险比是无效的。因此，良好的试验设计的一个关键原则是预先指定一个在非比例风险下定义明确且可解释的主要估计量（效应量的度量）。RMST 的差异和里程碑生存概率的差异（例如，$\\tau=36$ 个月时的生存率）是两种常见且适合作为此类估计量的选择。该陈述的第二部分正确地反映了这一重要的现代统计实践。\n\n对 E 的判断：**正确**。", "answer": "$$\\boxed{ACE}$$", "id": "5044569"}, {"introduction": "临床试验结论的可靠性不仅取决于统计模型的选择，还取决于数据的完整性。然而，数据缺失在临床试验中几乎无法避免，而处理缺失数据所做的假设（如随机缺失, Missing At Random, MAR）直接影响分析结果的有效性。本练习将介绍一种重要的敏感性分析方法——“临界点分析”（Tipping Point Analysis），它系统地评估当数据并非随机缺失（Missing Not At Random, MNAR）时，试验结论的稳健性。通过此练习，您将学会如何量化一个试验结果对偏离MAR假设的耐受程度，这是评估研究结论可信度的关键一步。[@problem_id:5044646]", "problem": "一项III期优效性随机对照试验（RCT）比较了一种研究性疗法与对照组在第$24$周时的一个连续性主要终点上的效果。主要分析预先指定为意向性治疗（intention-to-treat）比较，使用在随机缺失（MAR）假设下有效的基于似然的模型来比较各组的边际均值。从主要分析中观察到以下结果：在MAR假设下，估计的治疗效应（表示为$\\hat{\\tau}^{\\mathrm{MAR}}$）为$\\hat{\\tau}^{\\mathrm{MAR}} = 0.30$个单位，大样本标准误为$s = 0.12$，双侧显著性水平为$\\alpha = 0.05$。治疗组主要结局的缺失比例为$\\pi_T = 0.10$，对照组为$\\pi_C = 0.05$。\n\n为了评估对MAR假设违背的稳健性，研究团队计划在非随机缺失（MNAR）假设下进行模式混合模型敏感性分析，采用一种对称的$\\delta$调整插补方案，该方案明确不利于研究性疗法：对于治疗组的缺失结局，相对于基于MAR的插补，插补值向下调整$\\delta$；对于对照组的缺失结局，相对于基于MAR的插补，插补值向上调整$\\delta$。为进行此敏感性分析，并根据大样本实践，假设标准误$s$对于小到中度的$\\delta$偏移近似不变，并使用双侧$100(1-\\alpha)\\%$置信区间来判断统计显著性。\n\n基于关于缺失数据机制（完全随机缺失(MCAR)、随机缺失(MAR)和非随机缺失(MNAR)）的基本原理以及各组内边际均值的混合表示，哪个选项既正确定义了此III期临床试验背景下的临界点分析，又在所述的对称$\\delta$调整下，正确识别出能导致治疗效应估计在双侧$5\\%$水平上失去统计显著性的最小$\\delta$值（以终点单位计）？\n\nA. 临界点分析是在一个偏离MAR的网格上进行的系统性探索，它将MNAR偏移参数的组合映射到定性结论（例如，显著与不显著），从而确定结论“逆转”的边界。在所述的对称、不利于治疗的方案下，使统计显著性失效的最小$\\delta$值约为$0.432$。\n\nB. 临界点分析仅从数据中确定最可能的MNAR机制；这里，因为治疗组缺失的数据更多，所以只有缺失比例的差异是重要的，因此消除显著性的最小$\\delta$值约为$1.296$。\n\nC. 临界点分析通过改变插补次数直到结果稳定；在对称的$\\delta$调整下，对于优效性检验，使用单侧$5\\%$的临界值是合适的，得出最小$\\delta$值约为$0.688$。\n\nD. 临界点分析假设数据完全随机缺失，因此点估计值不随$\\delta$变化；因此，推翻统计显著性的最小$\\delta$值为$0$。\n\nE. 临界点分析是一项预先设定的检查，用于验证当使用至少$50$次多重插补时结果是否稳健；因为$50$次超出了常规实践，没有$\\delta$能改变结论，所以最小$\\delta$值未定义。", "solution": "问题陈述经评估有效。它具有科学依据，提问清晰，且客观，描述了临床试验背景下的一种标准统计敏感性分析。所有必要的数据和假设均已提供，以得出一个唯一的、可验证的解。\n\n主要任务有两个方面：首先，正确定义临界点分析；其次，计算能够逆转统计显著性结论的敏感性参数$\\delta$的最小值。\n\n首先，我们建立统计框架。在随机缺失（MAR）假设下的主要分析得出的估计治疗效应为$\\hat{\\tau}^{\\mathrm{MAR}} = 0.30$，标准误为$s = 0.12$。双侧检验的显著性水平为$\\alpha = 0.05$。\n\n为了评估统计显著性，我们计算Z统计量：\n$$\nZ = \\frac{\\hat{\\tau}^{\\mathrm{MAR}}}{s} = \\frac{0.30}{0.12} = 2.5\n$$\n在$\\alpha=0.05$水平下的双侧检验的临界值为$Z_{\\alpha/2} = Z_{0.025}$，约等于$1.96$。由于$|Z| = 2.5  1.96$，因此拒绝无治疗效应的原假设。结果具有统计显著性。这也可以通过构建治疗效应的$95\\%$置信区间（CI）来看出：\n$$\n\\text{CI} = \\hat{\\tau}^{\\mathrm{MAR}} \\pm Z_{0.025} \\cdot s = 0.30 \\pm 1.96 \\cdot 0.12 = 0.30 \\pm 0.2352 = [0.0648, 0.5352]\n$$\n由于整个区间都在$0$以上，因此在$5\\%$的水平上，治疗效应具有统计显著性。\n\n接下来，我们在非随机缺失（MNAR）假设下对敏感性分析进行形式化。这里使用模式混合模型，其中每个组的边际均值是具有观测结局的受试者均值和具有缺失结局的受试者均值的加权平均值。设$\\hat{\\mu}_{O}$为观测到结局的受试者的估计均值，$\\hat{\\mu}_{M}$为结局缺失的受试者的估计均值。边际均值为$\\hat{\\mu} = (1-\\pi)\\hat{\\mu}_{O} + \\pi\\hat{\\mu}_{M}$，其中$\\pi$是缺失数据的比例。\n\nMAR假设意味着，在给定协变量的条件下，观测到结局和结局缺失的受试者的期望结局是相同的。在这个简化的背景下，这意味着基于MAR的插补将使用$\\hat{\\mu}_{M} = \\hat{\\mu}_{O}$。因此，基于MAR的边际均值估计$\\hat{\\mu}^{\\mathrm{MAR}}$等于$\\hat{\\mu}_{O}$。\n\n指定的MNAR敏感性分析引入了一个偏移参数$\\delta$。该方案“明确不利于研究性疗法”，意味着它假设治疗组中结局缺失的受试者比观测到结局的受试者表现更差，而对照组中结局缺失的受试者表现更好。\n- 在治疗组（T）中：结局缺失受试者的插补均值为$\\hat{\\mu}_{M,T} = \\hat{\\mu}_{O,T} - \\delta = \\hat{\\mu}_T^{\\mathrm{MAR}} - \\delta$。\n- 在对照组（C）中：结局缺失受试者的插补均值为$\\hat{\\mu}_{M,C} = \\hat{\\mu}_{O,C} + \\delta = \\hat{\\mu}_C^{\\mathrm{MAR}} + \\delta$。\n\n经MNAR调整后，各组的边际均值$\\hat{\\mu}^{\\mathrm{MNAR}}$为：\n$$\n\\hat{\\mu}_T^{\\mathrm{MNAR}}(\\delta) = (1-\\pi_T)\\hat{\\mu}_T^{\\mathrm{MAR}} + \\pi_T(\\hat{\\mu}_T^{\\mathrm{MAR}} - \\delta) = \\hat{\\mu}_T^{\\mathrm{MAR}} - \\pi_T \\delta\n$$\n$$\n\\hat{\\mu}_C^{\\mathrm{MNAR}}(\\delta) = (1-\\pi_C)\\hat{\\mu}_C^{\\mathrm{MAR}} + \\pi_C(\\hat{\\mu}_C^{\\mathrm{MAR}} + \\delta) = \\hat{\\mu}_C^{\\mathrm{MAR}} + \\pi_C \\delta\n$$\n经MNAR调整后的治疗效应$\\hat{\\tau}^{\\mathrm{MNAR}}(\\delta)$是这些调整后均值的差：\n$$\n\\hat{\\tau}^{\\mathrm{MNAR}}(\\delta) = \\hat{\\mu}_T^{\\mathrm{MNAR}}(\\delta) - \\hat{\\mu}_C^{\\mathrm{MNAR}}(\\delta) = (\\hat{\\mu}_T^{\\mathrm{MAR}} - \\pi_T \\delta) - (\\hat{\\mu}_C^{\\mathrm{MAR}} + \\pi_C \\delta)\n$$\n$$\n\\hat{\\tau}^{\\mathrm{MNAR}}(\\delta) = (\\hat{\\mu}_T^{\\mathrm{MAR}} - \\hat{\\mu}_C^{\\mathrm{MAR}}) - \\pi_T\\delta - \\pi_C\\delta = \\hat{\\tau}^{\\mathrm{MAR}} - (\\pi_T + \\pi_C)\\delta\n$$\n这个方程显示了估计的治疗效应如何随着敏感性参数$\\delta$的增加而减小。\n\n“临界点”分析系统地探讨了这种偏离MAR假设的影响。它确定了研究的定性结论（例如，统计显著性）“逆转”或改变时的敏感性参数值。在本例中，我们需要找到使结果不再具有统计显著性的最小$\\delta  0$。\n\n当治疗效应的双侧$95\\%$置信区间的下限变为$0$时，统计显著性就会丧失。假设标准误$s$不变，经MNAR调整后效应的置信区间为$\\hat{\\tau}^{\\mathrm{MNAR}}(\\delta) \\pm Z_{0.025} \\cdot s$。当下限为$0$时：\n$$\n\\hat{\\tau}^{\\mathrm{MNAR}}(\\delta) - Z_{0.025} \\cdot s = 0\n$$\n$$\n\\hat{\\tau}^{\\mathrm{MNAR}}(\\delta) = Z_{0.025} \\cdot s\n$$\n代入$\\hat{\\tau}^{\\mathrm{MNAR}}(\\delta)$的表达式：\n$$\n\\hat{\\tau}^{\\mathrm{MAR}} - (\\pi_T + \\pi_C)\\delta = Z_{0.025} \\cdot s\n$$\n现在，我们求解临界点$\\delta$的值：\n$$\n(\\pi_T + \\pi_C)\\delta = \\hat{\\tau}^{\\mathrm{MAR}} - Z_{0.025} \\cdot s\n$$\n$$\n\\delta = \\frac{\\hat{\\tau}^{\\mathrm{MAR}} - Z_{0.025} \\cdot s}{\\pi_T + \\pi_C}\n$$\n我们代入给定值：$\\hat{\\tau}^{\\mathrm{MAR}} = 0.30$，$s = 0.12$，$\\pi_T = 0.10$，$\\pi_C = 0.05$，以及$Z_{0.025} \\approx 1.96$：\n$$\n\\delta = \\frac{0.30 - 1.96 \\cdot 0.12}{0.10 + 0.05} = \\frac{0.30 - 0.2352}{0.15} = \\frac{0.0648}{0.15} = 0.432\n$$\n因此，一个对称的、不利于治疗的$\\delta = 0.432$单位的偏移是使治疗效应在双侧$5\\%$水平上不再具有统计显著性所需的最小值。\n\n现在我们评估每个选项。\n\n**A. 临界点分析是在一个偏离MAR的网格上进行的系统性探索，它将MNAR偏移参数的组合映射到定性结论（例如，显著与不显著），从而确定结论“逆转”的边界。在所述的对称、不利于治疗的方案下，使统计显著性失效的最小$\\delta$值约为$0.432$。**\n临界点分析的定义是准确且表述良好的。计算结果与我们推导出的$\\delta = 0.432$值相符。\n**结论：正确。**\n\n**B. 临界点分析仅从数据中确定最可能的MNAR机制；这里，因为治疗组缺失的数据更多，所以只有缺失比例的差异是重要的，因此消除显著性的最小$\\delta$值约为$1.296$。**\n这个定义不正确。临界点分析是一种敏感性分析，而不是一种从观测数据中识别真实MNAR机制的方法，这在根本上是不可能的。其数学前提也不正确；调整依赖于和$(\\pi_T + \\pi_C)$，而不是差$(\\pi_T - \\pi_C)$。基于差值的计算得出$\\delta = \\frac{0.0648}{0.10 - 0.05} = \\frac{0.0648}{0.05} = 1.296$，这证实了错误的来源。\n**结论：不正确。**\n\n**C. 临界点分析通过改变插补次数直到结果稳定；在对称的$\\delta$调整下，对于优效性检验，使用单侧$5\\%$的临界值是合适的，得出最小$\\delta$值约为$0.688$。**\n这个定义不正确。它混淆了临界点分析（改变像$\\delta$这样的模型参数）与检查多重插补过程稳定性的方法（改变插补次数$m$）。此外，问题明确规定了双侧显著性水平为$\\alpha = 0.05$，因此使用单侧临界值违反了问题的条件。\n**结论：不正确。**\n\n**D. 临界点分析假设数据完全随机缺失，因此点估计值不随$\\delta$变化；因此，推翻统计显著性的最小$\\delta$值为$0$。**\n这从根本上就是错误的。临界点分析明确用于探索MNAR情景，即偏离MAR的情况。它不假设MCAR。点估计值$\\hat{\\tau}^{\\mathrm{MNAR}}(\\delta)$是$\\delta$的直接函数，因此声称它不变是错误的。$\\delta = 0$的值对应于MAR分析，而该分析被发现具有统计显著性。\n**结论：不正确。**\n\n**E. 临界点分析是一项预先设定的检查，用于验证当使用至少$50$次多重插补时结果是否稳健；因为$50$次超出了常规实践，没有$\\delta$能改变结论，所以最小$\\delta$值未定义。**\n这个定义不正确，再次将敏感性参数$\\delta$与插补次数$m$混淆。插补次数影响的是模拟的精度，而不是底层的缺失模型。没有$\\delta$能改变结论的说法是错误的；只要初始结果显著且存在缺失数据，总可以计算出临界点。\n**结论：不正确。**\n\n只有选项A既提供了临界点分析的正确定义，也提供了正确计算的$\\delta$值。", "answer": "$$\\boxed{A}$$", "id": "5044646"}]}