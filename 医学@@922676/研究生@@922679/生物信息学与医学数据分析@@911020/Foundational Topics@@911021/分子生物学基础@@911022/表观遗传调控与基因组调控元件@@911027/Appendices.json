{"hands_on_practices": [{"introduction": "识别转录因子在基因组上的结合位点是破译基因调控网络的第一步。本练习将介绍生物信息学中的基石模型——位置权重矩阵（PWM），并让你亲手实践如何使用对数优势比（log-odds score）来评估潜在结合序列。掌握这项基本技能对于从序列数据中注释调控元件至关重要。[@problem_id:4560143]", "problem": "一个与染色质结构表观遗传调控中的绝缘子功能有关的候选转录因子结合位点基序，是根据染色质免疫沉淀后测序（ChIP-seq）得到的高置信度峰值建模的。该基序由一个位置权重矩阵（PWM）表示，形式上是长度为 $L$、基于核苷酸 $b \\in \\{\\mathrm{A},\\mathrm{C},\\mathrm{G},\\mathrm{T}\\}$ 的位置特异性多项式参数矩阵 $P=\\{p_{i,b}\\}$，其中每个位置 $i \\in \\{1,\\dots,L\\}$ 都满足 $\\sum_{b} p_{i,b} = 1$ 且 $p_{i,b} \\ge 0$。基因组背景被建模为一个独立同分布的多项式模型，其概率为 $q=\\{q_{\\mathrm{A}}, q_{\\mathrm{C}}, q_{\\mathrm{G}}, q_{\\mathrm{T}}\\}$，满足 $\\sum_{b} q_{b} = 1$。\n\n从第一性原理出发，定义位置权重矩阵（PWM），并将一般背景下的位置信息含量定义为基序位置分布与背景之间的库尔贝克-莱布勒散度（KLD）。然后，从序列在 PWM 模型和背景模型下的似然出发，并引用转录因子结合基序的标准位置独立性假设，推导对数似然比评分函数。最后，使用自然对数计算以下实例的对数优势比基序得分。\n\nPWM 和背景均使用 $(\\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T})$ 的核苷酸顺序。设基序长度为 $L=8$，PWM 为\n$$\nP \\;=\\; \\begin{pmatrix}\n0.05  0.10  0.75  0.10 \\\\\n0.10  0.60  0.20  0.10 \\\\\n0.05  0.10  0.80  0.05 \\\\\n0.10  0.10  0.20  0.60 \\\\\n0.65  0.10  0.15  0.10 \\\\\n0.15  0.10  0.65  0.10 \\\\\n0.10  0.70  0.10  0.10 \\\\\n0.55  0.15  0.15  0.15\n\\end{pmatrix}.\n$$\n设基因组背景为\n$$\nq \\;=\\; (0.30,\\, 0.20,\\, 0.22,\\, 0.28).\n$$\n考虑长度为8的序列\n$$\n\\mathbf{b} \\;=\\; (\\mathrm{G},\\, \\mathrm{C},\\, \\mathrm{G},\\, \\mathrm{T},\\, \\mathrm{A},\\, \\mathrm{G},\\, \\mathrm{C},\\, \\mathrm{A}).\n$$\n\n计算在 $P$ 模型下相对于 $q$ 的序列 $\\mathbf{b}$ 的自然对数对数优势比基序得分，以奈特（nats）为单位表示，并将您的答案四舍五入到4位有效数字。您最终报告的值必须是单个实数。", "solution": "该问题要求一个包含三部分的回答：位置权重矩阵（PWM）和位置信息含量的理论定义，对数似然比评分函数的推导，以及针对给定DNA序列、PWM和背景模型的具体计算。\n\n### 问题验证\n\n首先，评估问题陈述的有效性。\n\n1.  **提取已知条件**：\n    *   位置权重矩阵（PWM）是一个针对长度为 $L$、基于核苷酸 $b \\in \\{\\mathrm{A},\\mathrm{C},\\mathrm{G},\\mathrm{T}\\}$ 的基序的位置特异性多项式参数矩阵 $P=\\{p_{i,b}\\}$。\n    *   对于每个位置 $i \\in \\{1,\\dots,L\\}$，概率总和为一：$\\sum_{b} p_{i,b} = 1$，且为非负：$p_{i,b} \\ge 0$。\n    *   基因组背景是一个独立同分布（i.i.d.）的多项式模型，其概率为 $q=\\{q_{\\mathrm{A}}, q_{\\mathrm{C}}, q_{\\mathrm{G}}, q_{\\mathrm{T}}\\}$，其中 $\\sum_{b} q_{b} = 1$。\n    *   核苷酸顺序指定为 $(\\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T})$。\n    *   基序长度为 $L=8$。\n    *   PWM 给出如下：\n        $$\n        P \\;=\\; \\begin{pmatrix}\n        0.05  0.10  0.75  0.10 \\\\\n        0.10  0.60  0.20  0.10 \\\\\n        0.05  0.10  0.80  0.05 \\\\\n        0.10  0.10  0.20  0.60 \\\\\n        0.65  0.10  0.15  0.10 \\\\\n        0.15  0.10  0.65  0.10 \\\\\n        0.10  0.70  0.10  0.10 \\\\\n        0.55  0.15  0.15  0.15\n        \\end{pmatrix}.\n        $$\n    *   背景核苷酸概率为 $q = (0.30, 0.20, 0.22, 0.28)$。\n    *   待评分的特定DNA序列是 $\\mathbf{b} = (\\mathrm{G}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T}, \\mathrm{A}, \\mathrm{G}, \\mathrm{C}, \\mathrm{A})$。\n    *   任务是计算自然对数对数优势比基序得分，并四舍五入到4位有效数字。\n\n2.  **使用提取的已知条件进行验证**：\n    *   **科学性和事实合理性**：该问题基于生物信息学中为转录因子结合位点建模的基石概念，包括PWM、背景模型和对数优势比评分。这些都是标准且成熟的方法。\n    *   **完整性和一致性**：该问题是自洽的。PWM矩阵的各行之和正确地为1。例如，对于第1行：$0.05 + 0.10 + 0.75 + 0.10 = 1.00$。这对所有8行都成立。背景概率之和也为1：$0.30 + 0.20 + 0.22 + 0.28 = 1.00$。PWM的维度（$8 \\times 4$）与基序长度（$L=8$）和字母表大小（4个核苷酸）一致。计算所需的所有数据均已提供。\n    *   **适定性**：该问题要求基于定义明确的数学公式进行计算。存在一个唯一、稳定且有意义的解。\n\n3.  **结论**：该问题是有效的。\n\n### 第1部分：基于第一性原理的定义\n\n**位置权重矩阵（PWM）**，记作 $P$，是一个表示固定长度 $L$ 的序列基序的概率模型。它是一个 $L \\times k$ 矩阵，其中 $k$ 是字母表的大小（此处对于DNA核苷酸 $\\{\\mathrm{A},\\mathrm{C},\\mathrm{G},\\mathrm{T}\\}$，$k=4$）。矩阵的每个元素 $p_{i,b}$ 指定了在基序的第 $i$ 个位置观察到核苷酸 $b$ 的概率。该模型假设位置之间是独立的。对于每个位置 $i \\in \\{1, \\dots, L\\}$，概率集合 $\\{p_{i,b}\\}_{b \\in \\{\\mathrm{A,C,G,T}\\}}$ 构成一个多项分布，因此 $\\sum_{b} p_{i,b} = 1$ 且 $p_{i,b} \\ge 0$。\n\n在位置 $i$ 的**位置信息含量**，记作 $I_i$，量化了该位置的保守性。它衡量了相对于背景分布 $q$，关于位置 $i$ 处核苷酸的不确定性的减少量。这被形式化地定义为从背景分布 $q$ 到基序的位置分布 $p_{i,\\cdot} = (p_{i,\\mathrm{A}}, p_{i,\\mathrm{C}}, p_{i,\\mathrm{G}}, p_{i,\\mathrm{T}})$ 的库尔贝克-莱布勒散度（KLD）。使用自然对数，以奈特（nats）为单位的信息含量为：\n$$\nI_i = D_{\\mathrm{KL}}(p_{i,\\cdot} || q) = \\sum_{b \\in \\{\\mathrm{A,C,G,T}\\}} p_{i,b} \\ln\\left(\\frac{p_{i,b}}{q_b}\\right)\n$$\n\n### 第2部分：对数似然比评分函数的推导\n\n为了区分真实的基序实例和背景DNA，我们构建一个假设检验。设 $\\mathbf{b} = (b_1, b_2, \\dots, b_L)$ 为一个长度为 $L$ 的DNA序列。\n\n*   **假设 $M$ (基序模型)**：序列 $\\mathbf{b}$ 是由基序模型 $P$ 生成的。\n*   **假设 $B$ (背景模型)**：序列 $\\mathbf{b}$ 是由背景模型 $q$ 生成的。\n\n在PWM模型固有的位置独立性假设下，在假设 $M$ 下观察到序列 $\\mathbf{b}$ 的似然是观察到每个碱基 $b_i$ 在其相应位置 $i$ 的概率的乘积：\n$$\n\\mathbb{P}(\\mathbf{b} | M) = \\prod_{i=1}^{L} p_{i, b_i}\n$$\n在独立同分布的背景模型下，在假设 $B$ 下观察到序列 $\\mathbf{b}$ 的似然是每个碱基的背景概率的乘积：\n$$\n\\mathbb{P}(\\mathbf{b} | B) = \\prod_{i=1}^{L} q_{b_i}\n$$\n**似然比**比较了这两个概率：\n$$\n\\frac{\\mathbb{P}(\\mathbf{b} | M)}{\\mathbb{P}(\\mathbf{b} | B)} = \\frac{\\prod_{i=1}^{L} p_{i, b_i}}{\\prod_{i=1}^{L} q_{b_i}} = \\prod_{i=1}^{L} \\frac{p_{i, b_i}}{q_{b_i}}\n$$\n为了数值稳定性和可加性，我们取这个比率的对数。这就得到了**对数似然比**或**对数优势比得分**，$S(\\mathbf{b})$。使用自然对数：\n$$\nS(\\mathbf{b}) = \\ln\\left( \\prod_{i=1}^{L} \\frac{p_{i, b_i}}{q_{b_i}} \\right) = \\sum_{i=1}^{L} \\ln\\left( \\frac{p_{i, b_i}}{q_{b_i}} \\right)\n$$\n这个函数通过对位置特异性的对数优势比求和来为序列评分，其中每一项都反映了观察到的核苷酸在基序模型下比在背景模型下更为可能的程度。这个得到的和就是对数优势比基序得分。\n\n### 第3部分：具体实例的计算\n\n我们给出的序列是 $\\mathbf{b} = (\\mathrm{G}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T}, \\mathrm{A}, \\mathrm{G}, \\mathrm{C}, \\mathrm{A})$。PWM列和背景向量的核苷酸顺序是 $(\\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T})$。背景概率是 $q = (q_{\\mathrm{A}}, q_{\\mathrm{C}}, q_{\\mathrm{G}}, q_{\\mathrm{T}}) = (0.30, 0.20, 0.22, 0.28)$。\n\n分数 $S(\\mathbf{b})$ 是通过对每个位置 $i=1, \\dots, 8$ 的对数优势比求和来计算的：\n$$\nS(\\mathbf{b}) = \\sum_{i=1}^{8} \\ln\\left( \\frac{p_{i, b_i}}{q_{b_i}} \\right)\n$$\n让我们计算每一项：\n*   位置 1：碱基 $b_1 = \\mathrm{G}$。$p_{1,\\mathrm{G}} = 0.75$, $q_{\\mathrm{G}} = 0.22$。得分 = $\\ln(0.75 / 0.22)$。\n*   位置 2：碱基 $b_2 = \\mathrm{C}$。$p_{2,\\mathrm{C}} = 0.60$, $q_{\\mathrm{C}} = 0.20$。得分 = $\\ln(0.60 / 0.20) = \\ln(3)$。\n*   位置 3：碱基 $b_3 = \\mathrm{G}$。$p_{3,\\mathrm{G}} = 0.80$, $q_{\\mathrm{G}} = 0.22$。得分 = $\\ln(0.80 / 0.22)$。\n*   位置 4：碱基 $b_4 = \\mathrm{T}$。$p_{4,\\mathrm{T}} = 0.60$, $q_{\\mathrm{T}} = 0.28$。得分 = $\\ln(0.60 / 0.28)$。\n*   位置 5：碱基 $b_5 = \\mathrm{A}$。$p_{5,\\mathrm{A}} = 0.65$, $q_{\\mathrm{A}} = 0.30$。得分 = $\\ln(0.65 / 0.30)$。\n*   位置 6：碱基 $b_6 = \\mathrm{G}$。$p_{6,\\mathrm{G}} = 0.65$, $q_{\\mathrm{G}} = 0.22$。得分 = $\\ln(0.65 / 0.22)$。\n*   位置 7：碱基 $b_7 = \\mathrm{C}$。$p_{7,\\mathrm{C}} = 0.70$, $q_{\\mathrm{C}} = 0.20$。得分 = $\\ln(0.70 / 0.20) = \\ln(3.5)$。\n*   位置 8：碱基 $b_8 = \\mathrm{A}$。$p_{8,\\mathrm{A}} = 0.55$, $q_{\\mathrm{A}} = 0.30$。得分 = $\\ln(0.55 / 0.30)$。\n\n将这些值相加：\n$S(\\mathbf{b}) = \\ln(\\frac{0.75}{0.22}) + \\ln(\\frac{0.60}{0.20}) + \\ln(\\frac{0.80}{0.22}) + \\ln(\\frac{0.60}{0.28}) + \\ln(\\frac{0.65}{0.30}) + \\ln(\\frac{0.65}{0.22}) + \\ln(\\frac{0.70}{0.20}) + \\ln(\\frac{0.55}{0.30})$\n$S(\\mathbf{b}) \\approx 1.226402 + 1.098612 + 1.290944 + 0.762140 + 0.773190 + 1.083319 + 1.252763 + 0.606136$\n$S(\\mathbf{b}) \\approx 8.093506$\n\n问题要求答案四舍五入到4位有效数字。计算值为 $8.093506...$。第五位有效数字是5，因此我们将第四位数字向上取整。\n$S(\\mathbf{b}) \\approx 8.094$。", "answer": "$$\n\\boxed{8.094}\n$$", "id": "4560143"}, {"introduction": "序列基元（motif）揭示了*潜在*的调控位点，但我们需要实验数据来确定哪些区域在细胞中是真正*活跃*的。本练习模拟了一个核心的ATAC-seq数据分析流程，教你如何识别开放染色质区域（“峰”），并检验它们在不同生物条件下的可及性变化。你将应用泊松分布和负二项分布等统计模型，这些是分析测序计数数据的基本工具。[@problem_id:4560167]", "problem": "一个研究小组使用转座酶可及染色质测序技术（ATAC-seq）研究开放染色质图谱，以推断基因组调控元件处的表观遗传调控。在经过充分检验的假设下，一个固定基因组窗口内的 ATAC-seq 读数计数可以被建模为背景率为 $\\lambda$ 的泊松过程的一个实现，而不同生物条件下的差异可及性可以使用源于泊松-伽马混合模型的、带有对数连接函数的负二项广义线性模型（GLM）进行建模。峰内读数分数（FRiP）定义为单个样本中落入有统计学支持的峰窗口内的读数总数与总比对读数的比值。Benjamini–Hochberg 程序提供了一种在多重检验中控制假发现率的标准方法。\n\n基于以上基础，设计一个单一程序，对每个给定的测试用例执行以下操作：\n\n1. 峰调用任务：\n   - 对于每个观测计数为 $k$ 且背景率为 $\\lambda$ 的基因组窗口，计算单侧上尾泊松 $p$-值 $p = \\mathbb{P}(K \\ge k \\mid \\lambda)$。\n   - 如果一个窗口的 $p$-值严格小于给定的阈值 $\\alpha$，则将其称为峰。\n   - 计算 FRiP，即被识别为峰的窗口中的观测计数总和与该测试用例的总比对读数 $N$ 的比值。将 FRiP 表示为小数并四舍五入到4位小数。\n\n2. 差异可及性任务：\n   - 对于跨样本的每个区域，拟合一个带有对数连接函数的负二项 GLM\n     $$\\log(\\mu_i) = \\log(s_i) + \\beta_0 + \\beta_{\\text{cond}} \\cdot x_i + \\beta_{\\text{batch}} \\cdot b_i,$$\n     其中 $\\mu_i$ 是样本 $i$ 的期望计数，$s_i$ 是由文库大小 $L_i$ 派生的大小因子，公式为 $s_i = L_i / \\overline{L}$，$x_i \\in \\{0,1\\}$ 编码生物学条件，而 $b_i \\in \\{0,1\\}$ 编码批次。使用迭代重加权最小二乘法（IRLS）来估计系数，负二项方差为\n     $$\\mathrm{Var}(Y_i) = \\mu_i + \\alpha \\mu_i^2,$$\n     权重为\n     $$w_i = \\frac{\\mu_i}{1 + \\alpha \\mu_i}.$$\n     通过对大小因子归一化的计数 $y_i / s_i$ 使用矩估计法，来跨区域估计一个单一的合并离散度 $\\alpha$，具体公式为\n     $$\\alpha = \\max\\left(\\epsilon, \\frac{1}{R} \\sum_{r=1}^{R} \\frac{\\widehat{v}_r - \\widehat{m}_r}{\\widehat{m}_r^2}\\right),$$\n     其中 $\\widehat{m}_r$ 和 $\\widehat{v}_r$ 分别是区域 $r$ 的样本均值和样本方差，$\\epsilon$ 是一个小的正常数以确保数值稳定性。对 $\\beta_{\\text{cond}}$ 执行沃尔德检验（Wald test），以获得每个区域的双侧 $p$-值。将 Benjamini–Hochberg 程序应用于跨区域的 $p$-值集合，并计算校正后 $q$-值严格小于指定阈值的区域数量。\n\n3. 输出：\n   - 对于每个测试用例，返回一个包含三个条目的列表：被识别为峰的整数数量、四舍五入到4位小数的 FRiP 值、以及经过假发现率控制后的差异可及性区域的整数数量。将所有测试用例的结果汇总到一个单一列表中。你的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表，每个测试用例贡献其自己的子列表。例如，输出格式必须类似于 $[[a,b,c],[d,e,f],[g,h,i]]$，且不含空格。\n\n使用以下测试套件。每个测试用例提供峰调用输入 $(k,\\lambda,\\alpha,N)$ 和差异可及性输入 $(Y, x, b, L, q)$。\n\n- 测试用例 1：\n  - 峰调用：\n    - 观测窗口计数 $k = [12,3,0,10,25,2]$。\n    - 背景率 $\\lambda = [5,2,1,3,10,1]$。\n    - 显著性阈值 $\\alpha = 0.01$。\n    - 总比对读数 $N = 52$。\n  - 差异可及性：\n    - 区域-样本计数矩阵 $Y$，行为区域，列为样本：\n      $$Y = \\begin{bmatrix}\n      30  20  60  40 \\\\\n      5  5  15  10 \\\\\n      10  12  11  9\n      \\end{bmatrix}.$$\n    - 条件向量 $x = [0,0,1,1]$。\n    - 批次向量 $b = [0,1,0,1]$。\n    - 文库大小 $L = [1000000,800000,1100000,900000]$。\n    - 假发现率阈值 $q = 0.1$。\n\n- 测试用例 2：\n  - 峰调用：\n    - 观测窗口计数 $k = [5,4,6,3,3]$。\n    - 背景率 $\\lambda = [4.5,4,5.5,3,2.9]$。\n    - 显著性阈值 $\\alpha = 0.05$。\n    - 总比对读数 $N = 21$。\n  - 差异可及性：\n    - 区域-样本计数矩阵：\n      $$Y = \\begin{bmatrix}\n      8  7  9  8 \\\\\n      2  1  6  5 \\\\\n      0  0  1  0\n      \\end{bmatrix}.$$\n    - 条件向量 $x = [0,0,1,1]$。\n    - 批次向量 $b = [0,1,0,1]$。\n    - 文库大小 $L = [900000,900000,900000,900000]$。\n    - 假发现率阈值 $q = 0.1$。\n\n- 测试用例 3：\n  - 峰调用：\n    - 观测窗口计数 $k = [0,1,0,2,1,0,3]$。\n    - 背景率 $\\lambda = [0.5,0.8,0.5,1.8,1,0.5,2]$。\n    - 显著性阈值 $\\alpha = 0.1$。\n    - 总比对读数 $N = 7$。\n  - 差异可及性：\n    - 区域-样本计数矩阵：\n      $$Y = \\begin{bmatrix}\n      10  50  12  55 \\\\\n      20  40  21  42 \\\\\n      5  10  5  10\n      \\end{bmatrix}.$$\n    - 条件向量 $x = [0,0,1,1]$。\n    - 批次向量 $b = [0,1,0,1]$。\n    - 文库大小 $L = [900000,900000,900000,900000]$。\n    - 假发现率阈值 $q = 0.1$。\n\n实现约束：\n- 使用单侧上尾泊松分布进行峰调用，并且不合并相邻窗口。\n- 对负二项 GLM 使用迭代重加权最小二乘法，其中单一的合并离散度通过对大小因子归一化的计数使用矩估计法进行估计，并包括从文库大小派生的偏移量 $\\log(s_i)$。\n- 在每个测试用例内，使用 Benjamini–Hochberg 程序对跨区域的 $p$-值进行校正。\n- 在需要时使用 $\\epsilon = 10^{-8}$ 以确保数值稳定性。\n- 你的程序必须是自包含的，不需要任何输入，并且仅按指定格式生成单行输出。FRiP 必须表示为小数（而非百分比）并四舍五入到4位小数。不涉及角度，除了计数之外不需要任何物理单位。", "solution": "该问题被评估为有效。它在科学上基于计算生物学和统计学的既定原则，问题陈述清晰完整，使用了客观、正式的语言。所提供的数据是一致且充分的，足以产生一个唯一的、有意义的解决方案。\n\n解决方案分为两个主要的计算任务：（1）基于泊松过程模型对 ATAC-seq 数据进行峰调用，以及（2）使用负二项广义线性模型（GLM）识别差异可及性基因组区域。\n\n### 第 1 部分：峰调用\n\n此任务旨在识别基因组窗口中读数计数显著高于背景预期的区域。\n\n**原理：** 一个基因组窗口内的读数数量 $K$ 被建模为一个泊松随机变量，其率参数 $\\lambda$ 代表背景信号。一个显著富集的窗口，即“峰”，是指其观测计数 $k$ 在此背景模型下极不可能发生的窗口。\n\n**方法论：**\n1.  **假设检验：** 对于每个具有观测计数 $k$ 和背景率 $\\lambda$ 的窗口，我们检验原假设 $H_0$，即该计数由率参数为 $\\lambda$ 的泊松分布生成。备择假设是真实率大于 $\\lambda$。\n2.  **p-值计算：** p-值是在原假设下观测到至少为 $k$ 的计数的概率。这对应于泊松分布的单侧上尾概率：\n    $$p = \\mathbb{P}(K \\ge k | \\lambda) = \\sum_{j=k}^{\\infty} \\frac{e^{-\\lambda}\\lambda^j}{j!}$$\n    在计算上，使用生存函数（SF）（即 $1$ 减去累积分布函数 (CDF)）来计算此值更高效、更准确：$p = 1 - \\text{CDF}(k-1; \\lambda)$。\n3.  **峰识别：** 如果一个窗口计算出的 $p$-值严格小于预定义的显著性阈值 $\\alpha$，即 $p  \\alpha$，则该窗口被称为一个峰。\n4.  **峰内读数分数（FRiP）：** 这个质量度量是落入被调用为峰的窗口内的总读数与样本的总比对读数 $N$ 的比率。\n    $$\\text{FRiP} = \\frac{\\sum_{i \\in \\text{peaks}} k_i}{N}$$\n    结果按要求四舍五入到4位小数。\n\n### 第 2 部分：差异可及性分析\n\n此任务旨在识别其可及性（通过读数计数衡量）在不同生物学条件之间发生显著变化的基因组区域，同时控制批次效应和测序深度的差异。\n\n**原理：** 读数计数使用负二项（NB）分布进行建模，该分布能适应测序数据中通常观察到的过离散现象（即方差大于均值）。GLM 框架允许我们将期望计数建模为实验变量的函数。\n\n**方法论：**\n1.  **模型设定：** 给定区域中样本 $i$ 的期望计数 $\\mu_i$ 通过一个对数连接函数进行建模：\n    $$\\log(\\mu_i) = \\log(s_i) + \\beta_0 + \\beta_{\\text{cond}} \\cdot x_i + \\beta_{\\text{batch}} \\cdot b_i$$\n    -   $\\log(s_i)$ 是一个偏移项，用于校正文库大小的差异。大小因子 $s_i$ 计算为 $s_i = L_i / \\overline{L}$，其中 $L_i$ 是样本 $i$ 的文库大小（总读数），$\\overline{L}$ 是所有样本的平均文库大小。\n    -   $\\beta_0$ 是截距，代表基线对数期望计数。\n    -   $x_i \\in \\{0, 1\\}$ 是生物学条件的指示变量。系数 $\\beta_{\\text{cond}}$ 代表条件之间可及性的对数倍数变化。\n    -   $b_i \\in \\{0, 1\\}$ 是批次的指示变量。系数 $\\beta_{\\text{batch}}$ 用于解释由批次效应引起的系统性变异。\n\n2.  **参数估计：**\n    -   **离散参数（$\\alpha$）：** NB 方差由 $\\mathrm{Var}(Y_i) = \\mu_i + \\alpha \\mu_i^2$ 给出。使用矩估计法，对大小因子归一化的计数（区域 $r$ 和样本 $i$ 的 $y_{ir}/s_i$）在所有区域上估计一个单一的、合并的离散参数 $\\alpha$。公式为：\n        $$\\alpha = \\max\\left(\\epsilon, \\frac{1}{R} \\sum_{r=1}^{R} \\frac{\\widehat{v}_r - \\widehat{m}_r}{\\widehat{m}_r^2}\\right)$$\n        其中 $\\widehat{m}_r$ 和 $\\widehat{v}_r$ 是区域 $r$ 归一化计数的样本均值和方差，$R$ 是区域数量，$\\epsilon=10^{-8}$ 确保了正值。\n    -   **GLM 系数 ($\\boldsymbol{\\beta}$):** 对每个区域，使用迭代重加权最小二乘法（IRLS）估计系数 $\\boldsymbol{\\beta} = [\\beta_0, \\beta_{\\text{cond}}, \\beta_{\\text{batch}}]^T$。该算法迭代地解决一个加权最小二乘问题，直到系数估计收敛。在第 $(t+1)$ 次迭代的更新步骤是：\n        $$\\boldsymbol{\\beta}^{(t+1)} = (\\mathbf{X}^T \\mathbf{W}^{(t)} \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{W}^{(t)} \\mathbf{z}'^{(t)}$$\n        其中：\n        -   $\\mathbf{X}$ 是设计矩阵，其列分别代表截距、条件 ($x_i$) 和批次 ($b_i$)。\n        -   $\\mathbf{W}^{(t)}$ 是一个对角权重矩阵，其元素为 $w_i = \\mu_i^{(t)} / (1 + \\alpha (\\mu_i^{(t)}))$，使用前一次迭代的均值计算。\n        -   $\\mathbf{z}'^{(t)}$ 是调整后的响应向量，其元素为 $z'_i = (\\eta_i^{(t)} - \\log(s_i)) + (y_i - \\mu_i^{(t)})/\\mu_i^{(t)}$，其中 $\\eta^{(t)}$ 是线性预测器。\n\n3.  **假设检验：**\n    -   为检验差异可及性，我们对感兴趣的系数 $\\beta_{\\text{cond}}$ 执行沃尔德检验。原假设是 $H_0: \\beta_{\\text{cond}} = 0$，表示条件之间没有变化。\n    -   沃尔德检验统计量 $Z$ 计算为估计系数与其标准误的比值：\n        $$Z = \\frac{\\hat{\\beta}_{\\text{cond}}}{\\text{SE}(\\hat{\\beta}_{\\text{cond}})}$$\n    -   标准误从系数协方差矩阵的对角线获得，该矩阵估计为 $\\text{Cov}(\\hat{\\boldsymbol{\\beta}}) = (\\mathbf{X}^T\\hat{\\mathbf{W}}\\mathbf{X})^{-1}$，其中 $\\hat{\\mathbf{W}}$ 使用最终收敛的均值估计。\n    -   双侧 $p$-值从标准正态分布计算得出：$p = 2 \\cdot \\mathbb{P}(N(0,1) \\ge |Z|)$。\n\n4.  **多重检验校正：**\n    -   由于对每个区域都进行了一次检验，我们必须进行多重比较校正以控制假发现率（FDR）。Benjamini-Hochberg (BH) 程序被应用于这组 $p$-值。\n    -   BH 程序将 $p$-值转换为 $q$-值（校正后的 $p$-值）。如果一个区域的 $q$-值严格小于指定的 FDR 阈值 $q$，则该区域被宣布为差异可及性区域。\n\n上述算法在最终程序中实现，用于处理每个测试用例并生成所需的输出。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\n\ndef solve():\n    \"\"\"\n    Solves the bioinformatics problem for a suite of test cases.\n    The problem involves two main tasks:\n    1. Peak calling based on a Poisson model.\n    2. Differential accessibility analysis using a Negative Binomial GLM.\n    \"\"\"\n    \n    test_cases = [\n        {\n            \"peak_calling\": {\n                \"k\": np.array([12, 3, 0, 10, 25, 2]),\n                \"lambda\": np.array([5, 2, 1, 3, 10, 1]),\n                \"alpha\": 0.01,\n                \"N\": 52\n            },\n            \"diff_access\": {\n                \"Y\": np.array([[30, 20, 60, 40], [5, 5, 15, 10], [10, 12, 11, 9]]),\n                \"x\": np.array([0, 0, 1, 1]),\n                \"b\": np.array([0, 1, 0, 1]),\n                \"L\": np.array([1000000, 800000, 1100000, 900000]),\n                \"q\": 0.1\n            }\n        },\n        {\n            \"peak_calling\": {\n                \"k\": np.array([5, 4, 6, 3, 3]),\n                \"lambda\": np.array([4.5, 4, 5.5, 3, 2.9]),\n                \"alpha\": 0.05,\n                \"N\": 21\n            },\n            \"diff_access\": {\n                \"Y\": np.array([[8, 7, 9, 8], [2, 1, 6, 5], [0, 0, 1, 0]]),\n                \"x\": np.array([0, 0, 1, 1]),\n                \"b\": np.array([0, 1, 0, 1]),\n                \"L\": np.array([900000, 900000, 900000, 900000]),\n                \"q\": 0.1\n            }\n        },\n        {\n            \"peak_calling\": {\n                \"k\": np.array([0, 1, 0, 2, 1, 0, 3]),\n                \"lambda\": np.array([0.5, 0.8, 0.5, 1.8, 1, 0.5, 2]),\n                \"alpha\": 0.1,\n                \"N\": 7\n            },\n            \"diff_access\": {\n                \"Y\": np.array([[10, 50, 12, 55], [20, 40, 21, 42], [5, 10, 5, 10]]),\n                \"x\": np.array([0, 0, 1, 1]),\n                \"b\": np.array([0, 1, 0, 1]),\n                \"L\": np.array([900000, 900000, 900000, 900000]),\n                \"q\": 0.1\n            }\n        }\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        # --- Task 1: Peak Calling ---\n        pc_data = case[\"peak_calling\"]\n        k, lam, alpha_peak, N = pc_data[\"k\"], pc_data[\"lambda\"], pc_data[\"alpha\"], pc_data[\"N\"]\n        \n        # p-value is P(K >= k), computed using survival function 1 - CDF(k-1)\n        p_values_peak = stats.poisson.sf(k - 1, lam)\n        is_peak = p_values_peak  alpha_peak\n        \n        num_peaks = np.sum(is_peak)\n        reads_in_peaks = np.sum(k[is_peak])\n        \n        frip = 0.0\n        if N > 0:\n            frip = reads_in_peaks / N\n        frip_rounded = round(frip, 4)\n\n        # --- Task 2: Differential Accessibility ---\n        da_data = case[\"diff_access\"]\n        Y, x, b, L, q_thresh = da_data[\"Y\"], da_data[\"x\"], da_data[\"b\"], da_data[\"L\"], da_data[\"q\"]\n        \n        epsilon = 1e-8\n        num_regions, num_samples = Y.shape\n\n        # Calculate size factors\n        mean_L = np.mean(L)\n        s = L / mean_L if mean_L > 0 else np.ones_like(L)\n\n        # Estimate pooled dispersion alpha\n        normalized_counts = Y / s\n        \n        disp_terms = []\n        for r in range(num_regions):\n            norm_counts_r = normalized_counts[r, :]\n            m_r = np.mean(norm_counts_r)\n            if m_r > epsilon:\n                v_r = np.var(norm_counts_r, ddof=1)\n                disp_terms.append((v_r - m_r) / (m_r**2))\n        \n        alpha_disp = np.mean(disp_terms) if disp_terms else 0\n        alpha_disp = max(epsilon, alpha_disp)\n        \n        # Design matrix\n        X = np.c_[np.ones(num_samples), x, b]\n        p_values_da = []\n\n        # Per-region GLM fit using IRLS\n        for r in range(num_regions):\n            y_r = Y[r, :]\n            \n            # IRLS\n            beta = np.zeros(X.shape[1])\n            num_iter = 25\n            \n            for _ in range(num_iter):\n                eta = X @ beta + np.log(s)\n                mu = np.exp(eta)\n                \n                # numerical stability\n                mu = np.clip(mu, epsilon, 1e10)\n                \n                weights = mu / (1 + alpha_disp * mu)\n                W = np.diag(weights)\n                \n                z_prime = (eta - np.log(s)) + (y_r - mu) / mu\n                \n                try:\n                    # Solve beta = (X^T W X)^-1 X^T W z'\n                    XTWX = X.T @ W @ X\n                    XTWz = X.T @ W @ z_prime\n                    beta = np.linalg.solve(XTWX, XTWz)\n                except np.linalg.LinAlgError:\n                    beta = np.full(X.shape[1], np.nan)\n                    break\n            \n            # Wald test for beta_cond (second coefficient)\n            if np.isnan(beta).any():\n                p_values_da.append(1.0)\n                continue\n\n            try:\n                # Recalculate W for final covariance\n                eta = X @ beta + np.log(s)\n                mu = np.exp(eta)\n                mu = np.clip(mu, epsilon, 1e10)\n                weights = mu / (1 + alpha_disp * mu)\n                W = np.diag(weights)\n\n                cov_beta = np.linalg.inv(X.T @ W @ X)\n                se_beta_cond = np.sqrt(cov_beta[1, 1])\n                \n                if se_beta_cond  epsilon:\n                    p_values_da.append(1.0)\n                else:\n                    wald_stat = beta[1] / se_beta_cond\n                    p_val = 2 * stats.norm.sf(np.abs(wald_stat))\n                    p_values_da.append(p_val)\n            except (np.linalg.LinAlgError, ValueError):\n                p_values_da.append(1.0)\n\n        p_values_da = np.array(p_values_da)\n\n        # Benjamini-Hochberg procedure\n        num_diff_regions = 0\n        if len(p_values_da) > 0:\n            sorted_indices = np.argsort(p_values_da)\n            sorted_pvals = p_values_da[sorted_indices]\n            \n            ranks = np.arange(1, num_regions + 1)\n            q_vals_sorted = sorted_pvals * num_regions / ranks\n            \n            # Enforce monotonicity\n            q_vals_sorted = np.minimum.accumulate(q_vals_sorted[::-1])[::-1]\n            q_vals_sorted = np.minimum(q_vals_sorted, 1.0)\n\n            # Map back to original order\n            q_vals = np.empty_like(p_values_da)\n            q_vals[sorted_indices] = q_vals_sorted\n            \n            num_diff_regions = np.sum(q_vals  q_thresh)\n\n        all_results.append([num_peaks, frip_rounded, num_diff_regions])\n    \n    # Format output as specified\n    output_str = str(all_results).replace(\" \", \"\")\n    print(output_str)\n\nsolve()\n```", "id": "4560167"}, {"introduction": "基因调控元件（如增强子）通常通过基因组的三维折叠来远程控制基因表达。本练习将深入Hi-C数据的分析，通过实现关键的ICE归一化算法来处理这些揭示远程相互作用的数据。掌握这种数据校正技术是准确解释染色质三维结构及其在基因调控中作用的重要前提。[@problem_id:4560081]", "problem": "实现一个算法，通过迭代比例拟合（Iterative Proportional Fitting, IPF）对高通量染色体构象捕获（High-throughput chromosome conformation capture, Hi-C）接触矩阵执行迭代校正和特征向量分解（Iterative Correction and Eigenvector decomposition, ICE）归一化，其目标是使有效（非低覆盖度）区块子集上的行和与列和相等。您的程序必须计算一个乘性偏差向量，当用该向量对矩阵进行对称缩放时，可以使有效区块的行和近似恒定，同时将低覆盖度区块从平衡约束中排除。\n\n使用的基本和核心定义：\n- Hi-C 接触矩阵是一个方形、对称、非负矩阵 $M \\in \\mathbb{R}_{\\ge 0}^{n \\times n}$，其中条目 $M_{ij}$ 代表基因组区块 $i$ 和 $j$ 之间的接触次数。一个区块的边际（行或列）总和是其与所有区块接触次数的总和。\n- ICE 归一化问题寻求一个对角缩放 $D = \\mathrm{diag}(w)$，其中 $w \\in \\mathbb{R}_{\\ge 0}^{n}$，使得缩放后的矩阵 $B = D M D$ 在指定的有效区块集合上具有统一的行和。统一的行和目标是一个正常数 $t \\in \\mathbb{R}_{0}$。\n- 低覆盖度区块是指其原始行和低于阈值 $\\tau \\in \\mathbb{R}_{0}$ 或等于 $0$ 的区块，并且这些区块应从等和约束中排除。令 $S \\subset \\{1,\\dots,n\\}$ 表示通过低覆盖度筛选的有效区块的索引集。\n- 对于任意向量 $x \\in \\mathbb{R}^{n}$，将缩放矩阵 $B$ 中区块 $i$ 的行和定义为 $r_i(B) = \\sum_{j=1}^{n} B_{ij}$。对于对称缩放 $B = D M D$，这满足 $r_i(B) = w_i \\cdot (M w)_i$，其中 $(M w)_i$ 表示矩阵向量乘积 $M w$ 的第 $i$ 个条目。\n\n要实现的任务：\n- 给定一个方形对称非负矩阵 $M$、一个目标行和 $t$、一个低覆盖度阈值 $\\tau$、一个容差 $\\delta$ 以及一个最大迭代次数上限 $K$，实现一个 IPF 风格的乘性更新，以计算权重向量 $w$，目标如下：\n  - 有效区块集：定义 $S = \\{ i \\in \\{1,\\dots,n\\} \\mid \\sum_{j=1}^{n} M_{ij} \\ge \\tau \\ \\text{and} \\ \\sum_{j=1}^{n} M_{ij}  0 \\}$。\n  - 初始化：对于 $i \\in S$，设置 $w_i^{(0)} = 1$；对于 $i \\notin S$，设置 $w_i^{(0)} = 0$。\n  - 对于 $k = 0,1,2,\\dots$ 的对称 IPF 更新：\n    - 对所有 $i$ 计算 $r_i^{(k)} = w_i^{(k)} \\cdot (M w^{(k)})_i$。\n    - 对于 $i \\in S$ 且 $r_i^{(k)}  0$，更新 $w_i^{(k+1)} = w_i^{(k)} \\cdot \\sqrt{\\frac{t}{r_i^{(k)}}}$。对于 $i \\notin S$，保持 $w_i^{(k+1)} = 0$。\n  - 收敛准则：定义有效区块中的最大相对偏差\n    $$\\varepsilon^{(k)} = \\max_{i \\in S} \\left| \\frac{r_i^{(k)}}{t} - 1 \\right|.$$\n    当 $\\varepsilon^{(k)} \\le \\delta$ 或 $k$ 达到 $K$ 时停止。\n  - 低覆盖度处理：区块 $i \\notin S$ 被排除在约束之外，并保持 $w_i = 0$；它们在缩放矩阵 $B$ 中对应的行和列通过对角缩放被有效地置零。\n\n程序要求：\n- 输入：将下面指定的测试套件硬编码到您的程序中。不要从文件或标准输入中读取。\n- 输出：对于每个测试用例，计算一个元组，其中包含一个布尔收敛标志（如果在超出迭代限制之前 $\\varepsilon^{(k)} \\le \\delta$ 则为 true）、最终的最大相对偏差 $\\varepsilon^{(\\ast)}$（浮点数值）以及执行的迭代次数（整数）。将所有测试用例的结果汇总到一个列表中，并以单个方括号列表的格式精确打印一行，条目之间用逗号分隔且无空格。每个条目本身必须是 $[ \\text{布尔值}, \\text{浮点数}, \\text{整数} ]$ 形式的列表。\n\n要实现和评估的测试套件：\n- 除非另有说明，否则使用 $t = 1$，$\\delta = 10^{-8}$ 和 $K = 10^4$。对于每种情况，按指定定义 $\\tau$。\n- 情况 A（一般的良态矩阵）：\n  $$M = \\begin{bmatrix}\n  20  5  3  0  2 \\\\\n  5  15  4  1  0 \\\\\n  3  4  18  2  1 \\\\\n  0  1  2  12  3 \\\\\n  2  0  1  3  10\n  \\end{bmatrix}, \\quad \\tau = 10.$$\n- 情况 B（带有零行和零列的矩阵；一个区块必须被排除）：\n  $$M = \\begin{bmatrix}\n  8  2  0  0 \\\\\n  2  7  1  0 \\\\\n  0  1  5  0 \\\\\n  0  0  0  0\n  \\end{bmatrix}, \\quad \\tau = 1.$$\n- 情况 C（具有多个低覆盖度区块的稀疏矩阵，被阈值排除）：\n  $$M = \\begin{bmatrix}\n  5  1  0  0  0  0 \\\\\n  1  4  1  0  0  0 \\\\\n  0  1  0  0  0  0 \\\\\n  0  0  0  3  1  0 \\\\\n  0  0  0  1  2  1 \\\\\n  0  0  0  0  1  0\n  \\end{bmatrix}, \\quad \\tau = 3.$$\n- 情况 D（已为等和结构；预期会快速收敛）：\n  $$M = \\begin{bmatrix}\n  1  1  1 \\\\\n  1  1  1 \\\\\n  1  1  1\n  \\end{bmatrix}, \\quad \\tau = 1.$$\n\n角度单位不适用。没有要报告的物理单位。所有数值输出必须是基本实数。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的、以逗号分隔的列表，无空格。例如，如果有四个情况，输出必须如下所示\n  $$[ [\\text{boolean}_1,\\text{float}_1,\\text{integer}_1], [\\text{boolean}_2,\\text{float}_2,\\text{integer}_2], [\\text{boolean}_3,\\text{float}_3,\\text{integer}_3], [\\text{boolean}_4,\\text{float}_4,\\text{integer}_4] ]$$\n  但没有空格，即，\n  $$[[\\text{boolean}_1,\\text{float}_1,\\text{integer}_1],[\\text{boolean}_2,\\text{float}_2,\\text{integer}_2],[\\text{boolean}_3,\\text{float}_3,\\text{integer}_3],[\\text{boolean}_4,\\text{float}_4,\\text{integer}_4]].$$", "solution": "用户要求基于迭代比例拟合（IPF）为 Hi-C 接触矩阵实现迭代校正和特征向量分解（ICE）归一化算法。\n\n### 第 1 步：问题验证\n\n**1.1. 提取的已知信息**\n- **Hi-C 矩阵 ($M$)**：一个方形、对称、非负矩阵 $M \\in \\mathbb{R}_{\\ge 0}^{n \\times n}$。\n- **缩放**：一个对角缩放矩阵 $D = \\mathrm{diag}(w)$，其中 $w \\in \\mathbb{R}_{\\ge 0}^{n}$ 是一个偏差向量。缩放后的矩阵是 $B = DMD$。\n- **归一化目标**：对于给定的目标和 $t \\in \\mathbb{R}_{0}$，缩放矩阵的行和 $r_i(B) = \\sum_{j=1}^{n} B_{ij}$ 对于所有“有效”区块应约等于 $t$。\n- **有效区块 ($S$)**：待归一化的区块集合定义为 $S = \\{ i \\mid \\sum_{j=1}^{n} M_{ij} \\ge \\tau \\ \\text{and} \\ \\sum_{j=1}^{n} M_{ij}  0 \\}$，其中 $\\tau \\in \\mathbb{R}_{0}$ 是一个低覆盖度阈值。不在 $S$ 中的区块被排除。\n- **初始化**：权重向量初始化为，对于 $i \\in S$，$w_i^{(0)} = 1$；对于 $i \\notin S$，$w_i^{(0)} = 0$。\n- **IPF 更新规则**：对于迭代 $k=0, 1, 2, \\dots$：当前行和：$r_i^{(k)} = w_i^{(k)} \\cdot (M w^{(k)})_i$。权重更新：对于 $i \\in S$ 且 $r_i^{(k)}  0$，更新 $w_i^{(k+1)} = w_i^{(k)} \\cdot \\sqrt{\\frac{t}{r_i^{(k)}}}$。对于 $i \\notin S$，$w_i^{(k+1)} = 0$。\n- **收敛准则**：当最大相对偏差 $\\varepsilon^{(k)} = \\max_{i \\in S} \\left| \\frac{r_i^{(k)}}{t} - 1 \\right|$ 小于或等于容差 $\\delta$ 时，过程停止。\n- **终止**：如果迭代次数 $k$ 达到最大上限 $K$，过程也停止。\n- **输出**：对于每个测试用例，输出一个包含布尔收敛标志、最终偏差 $\\varepsilon^{(\\ast)}$ 和迭代次数的元组。最终输出是这些结果列表的单行字符串表示。\n- **测试用例**：提供了四个特定的矩阵 $M$ 和阈值 $\\tau$，全局参数为 $t=1$, $\\delta=10^{-8}$ 和 $K=10^4$。\n\n**1.2. 依据标准验证**\n- **科学依据**：该问题描述了标准的 ICE 归一化算法，这是生物信息学领域中用于校正 Hi-C 数据偏差的一种广为接受的基本技术。其基于迭代比例拟合的数学基础是可靠的。\n- **适定性**：该问题是适定的。它提供了所有必要的输入（$M, t, \\tau, \\delta, K$）、清晰的迭代过程和明确的终止条件（收敛或迭代限制）。排除低覆盖度区块是处理稀疏或不连通矩阵的标准做法，确保了算法的稳定性。\n- **客观性**：所有定义和要求都以精确、定量的数学术语陈述，没有主观解释的余地。\n\n**1.3. 结论**\n该问题是有效的。它在科学上是可靠的、适定的、客观的和完整的。我将继续提供解决方案。\n\n### 第 2 步：算法设计与解释\n\n解决方案的核心是一个迭代算法，该算法通过优化权重向量 $w$ 来平衡 Hi-C 矩阵 $M$ 的行/列和。算法流程如下：\n\n1.  **初始化**：\n    - 给定输入矩阵 $M$ 和低覆盖度阈值 $\\tau$，我们首先计算每个区块（基因组区域）的原始行和。由于 $M$ 是对称的，行和等于列和。\n    - 我们将“有效”区块集合 $S$ 定义为那些原始和大于或等于 $\\tau$ 的区块。由于 $\\tau$ 被定义为正实数，和必须大于 0 的条件会自动满足。\n    - 初始化一个大小为 $n$ 的权重向量 $w$。对于每个有效区块 $i \\in S$，$w_i$ 设置为 1。对于所有其他区块 $i \\notin S$，$w_i$ 设置为 0。这确保了低覆盖度或空区块被排除在归一化过程之外，并且在最终的平衡矩阵中信号为零。\n\n2.  **迭代校正**：\n    - 算法进入一个循环，直到达到收敛或超过最大迭代次数 $K$。设当前迭代为 $k$。\n    - **计算缩放后的行和**：在每次迭代中，我们计算隐式缩放矩阵 $B = DMD$ 的当前行和。区块 $i$ 的行和为 $r_i = \\sum_j D_{ii} M_{ij} D_{jj} = w_i \\sum_j M_{ij} w_j = w_i (Mw)_i$。通过一个矩阵向量乘积后跟一个逐元素乘积，可以为所有区块高效地计算这个值。\n    - **检查收敛性**：我们通过计算所有有效区块中的最大相对偏差 $\\varepsilon^{(k)}$ 来评估收敛性：$\\varepsilon^{(k)} = \\max_{i \\in S} \\left| \\frac{r_i^{(k)}}{t} - 1 \\right|$。如果 $\\varepsilon^{(k)} \\le \\delta$，则认为矩阵已平衡。算法终止，报告成功、最终的 $\\varepsilon^{(k)}$ 和当前迭代次数 $k$。\n    - **更新权重**：如果未收敛，则为下一次迭代更新权重向量。更新规则 $w_i^{(k+1)} = w_i^{(k)} \\cdot \\sqrt{t/r_i^{(k)}}$ 仅适用于那些同时具有非零当前行和（$r_i^{(k)}  0$）的有效区块（$i \\in S$）。这种乘性更新旨在将 $r_i$ 推向目标 $t$。行和为 $r_i^{(k)}=0$ 的区块不会被更新，因为这会涉及除以零。它们的权重保持不变，如果它们与系统断开连接，就会有效地被排除在进一步的平衡过程之外。\n\n3.  **终止**：\n    - 如果循环在完成 $K$ 次迭代后仍未达到收敛，则过程停止。\n    - 返回收敛标志的最终值（此时为 `False`）、最后计算的偏差 $\\varepsilon$ 和总迭代次数（$K$）。\n\n这个基于对称 IPF 的过程保证了对于不可约非负矩阵的收敛性。通过滤除低覆盖度区块，我们提高了剩余子矩阵表现良好的可能性，从而使归一化在实践中更加稳健。实现将使用 `numpy` 进行高效的数组和矩阵运算。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the ICE normalization test suite and print results.\n    \"\"\"\n\n    def ice_normalize(M, t, tau, delta, K):\n        \"\"\"\n        Performs ICE normalization on a Hi-C matrix using Iterative Proportional Fitting.\n\n        Args:\n            M (list of lists): The input square symmetric matrix.\n            t (float): The target row sum.\n            tau (float): The low-coverage threshold.\n            delta (float): The convergence tolerance.\n            K (int): The maximum number of iterations.\n\n        Returns:\n            tuple: A tuple containing (converged, final_epsilon, iterations).\n                   - converged (bool): True if the algorithm converged.\n                   - final_epsilon (float): The final maximum relative deviation.\n                   - iterations (int): The number of iterations performed.\n        \"\"\"\n        mat = np.array(M, dtype=float)\n        n = mat.shape[0]\n\n        # Step 1: Identify valid bins based on raw row sums and threshold tau.\n        # Since tau > 0, the condition raw_sums >= tau implies raw_sums > 0.\n        raw_sums = mat.sum(axis=1)\n        valid_mask = raw_sums >= tau\n\n        # Handle the edge case where no bins are considered valid.\n        if not np.any(valid_mask):\n            return (True, 0.0, 0)\n\n        # Step 2: Initialize the weight vector w.\n        w = np.zeros(n, dtype=float)\n        w[valid_mask] = 1.0\n        \n        k = 0\n        epsilon = np.inf\n\n        # Step 3: Begin the iterative correction loop.\n        while k  K:\n            # Calculate the current row sums of the scaled matrix: r_i = w_i * (M*w)_i\n            r = w * (mat @ w)\n            \n            # Isolate the row sums of valid bins to calculate epsilon.\n            r_valid = r[valid_mask]\n            \n            # Calculate the maximum relative deviation for valid bins.\n            epsilon = np.max(np.abs(r_valid / t - 1.0))\n\n            # Check for convergence.\n            if epsilon = delta:\n                return (True, epsilon, k)\n\n            # Prepare for the weight update. Only update valid bins with r > 0.\n            update_mask = (r > 0)  valid_mask\n\n            # If no bins can be updated, the algorithm is stuck. Break the loop.\n            if not np.any(update_mask):\n                break\n\n            # Apply the multiplicative update rule.\n            w[update_mask] *= np.sqrt(t / r[update_mask])\n            \n            k += 1\n\n        # After the loop, k = K or we broke out early. Recalculate the final epsilon.\n        r = w * (mat @ w)\n        r_valid = r[valid_mask]\n        epsilon = np.max(np.abs(r_valid / t - 1.0)) if np.any(valid_mask) else 0.0\n        \n        # Determine final convergence status.\n        converged = epsilon = delta\n\n        # Return the final state. k is the number of iterations performed.\n        return (converged, epsilon, k)\n\n    # Define the test suite.\n    # Global parameters: t = 1, delta = 1e-8, K = 10000\n    common_params = {\"t\": 1.0, \"delta\": 1e-8, \"K\": 10000}\n    \n    test_cases = [\n        # Case A: General well-conditioned matrix\n        {\n            \"M\": [\n                [20, 5, 3, 0, 2],\n                [5, 15, 4, 1, 0],\n                [3, 4, 18, 2, 1],\n                [0, 1, 2, 12, 3],\n                [2, 0, 1, 3, 10]\n            ],\n            \"tau\": 10.0\n        },\n        # Case B: Matrix with a zero row and column\n        {\n            \"M\": [\n                [8, 2, 0, 0],\n                [2, 7, 1, 0],\n                [0, 1, 5, 0],\n                [0, 0, 0, 0]\n            ],\n            \"tau\": 1.0\n        },\n        # Case C: Sparse matrix with multiple low-coverage bins\n        {\n            \"M\": [\n                [5, 1, 0, 0, 0, 0],\n                [1, 4, 1, 0, 0, 0],\n                [0, 1, 0, 0, 0, 0],\n                [0, 0, 0, 3, 1, 0],\n                [0, 0, 0, 1, 2, 1],\n                [0, 0, 0, 0, 1, 0]\n            ],\n            \"tau\": 3.0\n        },\n        # Case D: Already equal-sum structure\n        {\n            \"M\": [\n                [1, 1, 1],\n                [1, 1, 1],\n                [1, 1, 1]\n            ],\n            \"tau\": 1.0\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        # Unpack parameters and run the normalization.\n        result_tuple = ice_normalize(\n            M=case[\"M\"],\n            tau=case[\"tau\"],\n            **common_params\n        )\n        # Convert tuple to list for the final string representation.\n        results.append(list(result_tuple))\n    \n    # Format the output string exactly as specified, without any spaces.\n    final_output = str(results).replace(' ', '')\n    print(final_output)\n\nsolve()\n```", "id": "4560081"}]}