{"hands_on_practices": [{"introduction": "中心法则的起点是DNA的精确复制，它确保了遗传信息在世代间的稳定传递。这项练习将理论付诸实践，通过结合DNA聚合酶、校对机制和错配修复系统的各自错误率，来量化DNA复制的整体保真度。通过这个计算，你将亲身体会到，在庞大的基因组尺度上，即便是极低的单点错误率，也会累积成一个不可忽视的突变数量，这对于理解进化和疾病的分子基础至关重要。[@problem_id:2965554]", "problem": "一个真核细胞在每次细胞分裂期间会复制一个包含 $3.2 \\times 10^{9}$ 个核苷酸位置的线性基因组。在每个位置上，脱氧核糖核酸（DNA）聚合酶错误掺入一个核苷酸的边际概率为 $\\epsilon_{\\text{pol}} = 10^{-5}$。在一个错配事件发生的条件下，核酸外切酶的校对机制会尝试移除该错配；校对未能纠正错配的条件概率为 $\\epsilon_{\\text{proof}} = 10^{-2}$。在一个复制后错配持续存在的条件下，错配修复（MMR）系统会尝试纠正它；错配修复失败的条件概率为 $\\epsilon_{\\text{MMR}} = 10^{-1}$。假设不同位置上的错误事件是相互独立的，并且在存在错配的情况下，校正失败事件是条件独立的。只有当发生一次错误掺入，并且在下一次复制循环之前两个校正系统都未能纠正时，一个碱基替换才会成为一个固定突变。\n\n在分子生物学中心法则（其中高保真复制维持了从DNA到DNA的信息流）的框架内，请仅使用上述定义以及概率和期望的第一性原理，推导一个表达式，用于计算每次细胞分裂在全部 $3.2 \\times 10^{9}$ 个位置上由复制引起的碱基替换的期望数量。然后，使用给定的参数值对该期望进行数值计算。报告每次分裂的最终替换数，结果应为一个精确的数字（不进行四舍五入，不带单位）。\n\n最后，根据你的计算结果以及关于具有完整校对和错配修复功能的正常人类体细胞中复制保真度的既有定性知识，用文字简要评估你计算出的数量级是否具有生物学合理性，并定性地解释你的理由（你的定性评估不会影响对数值答案的要求）。", "solution": "该问题要求推导并计算在一个复制周期后，基因组中固定下来的碱基替换的期望数量。这个数量由DNA聚合酶引入错误与随后两大修复系统（校对和错配修复）进行校正之间的相互作用决定。解题的基础在于概率论，具体而言是计算一系列相关事件的概率，以及应用期望的线性性质。\n\n设 $N$ 为基因组中核苷酸位置的总数，给定为 $N = 3.2 \\times 10^{9}$。\n在单个位置上，一个碱基替换要成为固定突变，当且仅当发生以下三个事件序列：初始的错误掺入、校对失败以及随后的错配修复失败。我们必须计算这个复合事件的概率。\n\n让我们为单个核苷酸位置定义以下事件：\n- $M$：DNA聚合酶错误掺入一个核苷酸的事件。其概率为 $P(M) = \\epsilon_{\\text{pol}} = 10^{-5}$。\n- $F_P$：核酸外切酶校对机制未能纠正错配的事件。这是一个条件事件，取决于是否发生了错误掺入。问题给出的条件概率为 $P(F_P | M) = \\epsilon_{\\text{proof}} = 10^{-2}$。\n- $F_{MMR}$：错配修复（MMR）系统未能纠正错配的事件。该事件的条件是错配在复制和校对后仍然存在，即以事件 $M \\cap F_P$ 为条件。问题给出的条件概率为 $P(F_{MMR} | M \\cap F_P) = \\epsilon_{\\text{MMR}} = 10^{-1}$。\n\n单个固定替换的概率（我们记为 $\\mu$）是这三个事件交集的概率：$\\mu = P(M \\cap F_P \\cap F_{MMR})$。使用概率的链式法则，我们可以将 $\\mu$ 表示如下：\n$$ \\mu = P(M) \\times P(F_P | M) \\times P(F_{MMR} | M \\cap F_P) $$\n问题陈述提供了等式右侧所有必需的概率。代入给定的符号参数：\n$$ \\mu = \\epsilon_{\\text{pol}} \\cdot \\epsilon_{\\text{proof}} \\cdot \\epsilon_{\\text{MMR}} $$\n这个表达式代表了在一次细胞分裂中，任何单个核苷酸位置上出现固定突变的概率。\n\n现在，我们必须计算在整个包含 $N$ 个位置的基因组中，此类突变的总期望数。设 $X$ 为一个随机变量，表示每次细胞分裂的总替换数。我们可以定义 $N$ 个指示随机变量 $X_1, X_2, \\dots, X_N$，其中如果位置 $i$ 发生固定替换，则 $X_i = 1$，否则 $X_i = 0$。$X_i=1$ 的概率恰好是上面计算出的 $\\mu$。\n总替换数是这些指示变量的总和：$X = \\sum_{i=1}^{N} X_i$。\n\n根据期望的线性性质，随机变量之和的期望值等于它们各自期望值的和：\n$$ E[X] = E\\left[\\sum_{i=1}^{N} X_i\\right] = \\sum_{i=1}^{N} E[X_i] $$\n指示变量 $X_i$ 的期望等于它所指示事件的概率：$E[X_i] = 1 \\cdot P(X_i=1) + 0 \\cdot P(X_i=0) = P(X_i=1) = \\mu$。\n由于假设所有位置的突变概率 $\\mu$ 相同，所以总和简化为：\n$$ E[X] = \\sum_{i=1}^{N} \\mu = N \\cdot \\mu $$\n因此，期望替换数的最终表达式为：\n$$ E[X] = N \\cdot \\epsilon_{\\text{pol}} \\cdot \\epsilon_{\\text{proof}} \\cdot \\epsilon_{\\text{MMR}} $$\n我们现在使用给定的参数值进行数值计算：\n$N = 3.2 \\times 10^{9}$\n$\\epsilon_{\\text{pol}} = 10^{-5}$\n$\\epsilon_{\\text{proof}} = 10^{-2}$\n$\\epsilon_{\\text{MMR}} = 10^{-1}$\n\n首先，我们计算单一位点的突变概率 $\\mu$：\n$$ \\mu = (10^{-5}) \\times (10^{-2}) \\times (10^{-1}) = 10^{-5-2-1} = 10^{-8} $$\n这是每个位点、每次复制的突变率。\n\n接下来，我们计算总替换数的期望值 $E[X]$：\n$$ E[X] = (3.2 \\times 10^{9}) \\times (10^{-8}) = 3.2 \\times 10^{9-8} = 3.2 \\times 10^{1} = 32 $$\n因此，每次细胞分裂由复制引起的碱基替换的期望数量为 $32$。\n\n最后，我们评估该结果的生物学合理性。计算出的总突变率 $\\mu = 10^{-8}$（每个碱基对每次复制周期的突变数）是一个教科书级别的值，与人类和其他哺乳动物生殖系突变率的测量值高度一致。对于一个大小为 $3.2 \\times 10^{9}$ 碱基对的基因组，由此产生的32个新突变的期望值也完全在既有生物学估计的范围内。对人类新生（*de novo*）突变（这些突变通过细胞分裂累积）的实证研究报告称，每代会出现几十个新突变。因此，源于单轮基因组复制的32个突变的期望值，在科学上是一个合理且可信的数量级。它正确地量化了一个过程的结果，即海量的核苷酸以极高但并非完美的保真度被复制。中心法则中从DNA到DNA信息保存的原则被高保真地维持着，但此计算表明它并非绝对。", "answer": "$$\n\\boxed{32}\n$$", "id": "2965554"}, {"introduction": "遗传信息的表达过程遵循中心法则，从DNA转录为RNA，最终翻译为蛋白质。此过程的精确性依赖于明确的“启始”和“终止”信号。这项练习模拟了一种“无终止”突变的情景，即一个终止密码子因单核苷酸缺失而失效。通过计算由此产生的异常蛋白质的分子量变化，你将深入理解阅读框、遗传密码以及终止信号在维持蛋白质功能完整性方面的关键作用，并量化基因型突变对表型的直接影响。[@problem_id:1526374]", "problem": "在某个真核细胞中，一个高度表达的基因产生一条成熟的信使RNA（mRNA）。该mRNA包含一个长度为1497个核苷酸的蛋白质编码序列（CDS），其后跟一个`UAG`终止密码子，以及一个由251个腺嘌呤核苷酸组成的多聚腺苷酸（poly-A）尾。从此mRNA翻译出的野生型蛋白质的平均氨基酸残基分子量为112.5道尔顿（Da）。\n\n该基因发生了一次自发点突变，导致单个核苷酸缺失，在最终的mRNA转录本中，该缺失从`UAG`终止密码子中移除了尿嘧啶（`U`）。这种“无终止”突变导致核糖体无法终止翻译，并继续翻译进入poly-A尾，直到到达mRNA分子的末端。\n\n给定以下残基分子量：\n- 精氨酸（Arg）：156.2 Da\n- 赖氨酸（Lys）：128.2 Da\n\n假设使用简化的遗传密码，其中`AGA`编码精氨酸，`AAA`编码赖氨酸。核糖体以连续、不重叠的三联体框架进行读取。请计算产生的异常多肽与原始野生型多肽相比，其分子质量的绝对增加量。请以道尔顿（Da）为单位表示你的最终答案，并四舍五入至四位有效数字。", "solution": "CDS的长度为 $1497$ 个核苷酸，因此野生型蛋白质的长度为\n$$\n\\frac{1497}{3}=499 \\text{ amino acids},\n$$\n终止密码子紧随此CDS之后。\n\n野生型终止密码子序列是 $UAG$，其后是长度为 $251$ 的poly-A尾（即 $A^{251}$）。一次缺失事件从 $UAG$ 中移除了 $U$，使得从原终止位置开始的序列变为 $AG$ 后跟poly-A尾。核糖体在相同的阅读框架内继续翻译，使用不重叠的三联体密码子。\n\n在原终止密码子位置形成的第一个密码子，使用了突变后终止密码子剩余的两个碱基和poly-A尾的第一个腺嘌呤：\n$$\n\\text{codon}_{1} = AGA \\quad \\Rightarrow \\quad \\text{Arginine}.\n$$\n这消耗了poly-A尾中的 $1$ 个腺嘌呤，剩下 $251-1=250$ 个腺嘌呤。这些腺嘌呤被作为连续的三联体密码子读取：\n$$\n\\left\\lfloor \\frac{250}{3} \\right\\rfloor = 83 \\text{ full codons } = 83 \\times AAA \\quad \\Rightarrow \\quad 83 \\text{ Lysines},\n$$\n剩下 $1$ 个腺嘌呤，不能形成一个完整的密码子，因此不被翻译。\n\n因此，异常多肽增加了 $1$ 个精氨酸和 $83$ 个赖氨酸。使用给定的残基分子量，分子质量的绝对增加量为\n$$\n\\Delta M = 1 \\times 156.2 + 83 \\times 128.2.\n$$\n计算乘积与和：\n$$\n83 \\times 128.2 = 10640.6, \\quad \\Delta M = 156.2 + 10640.6 = 10796.8 \\text{ Da}.\n$$\n四舍五入至四位有效数字，\n$$\n\\Delta M = 1.080 \\times 10^{4} \\text{ Da}.\n$$", "answer": "$$\\boxed{1.080 \\times 10^{4}}$$", "id": "1526374"}, {"introduction": "超越单个基因的机制，现代生物学致力于利用高通量数据构建系统层面的定量模型来理解基因调控网络。这项练习将你置于一个真实的生物信息学分析场景中，任务是基于模拟的ChIP-seq（转录因子占位）和RNA-seq（基因表达）数据，建立一个预测转录速率的回归模型。你将不仅应用中心法则的定量关系（如转录速率与mRNA稳态水平），还将学习如何识别和处理数据分析中的一个核心挑战——混杂变量，从而更准确地解释基因调控的驱动因素。[@problem_id:4613289]", "problem": "考虑分子生物学中心法则，该法则指出脱氧核糖核酸 (DNA) 被转录为核糖核酸 (RNA)，然后翻译成蛋白质。在转录层面，对于索引为 $i$ 的基因，令 $r_i$ 表示其转录起始率（分子数/细胞/单位时间），$m_i$ 表示其稳态信使核糖核酸 (mRNA) 丰度（分子数/细胞），$d_i$ 表示其一级降解率（每单位时间）。一个经过充分检验的 mRNA 动力学稳态关系由以下微分方程给出\n$$\\frac{dm_i}{dt} = r_i - d_i m_i,$$\n该方程在稳态时（$\\frac{dm_i}{dt}=0$）意味着\n$$r_i = d_i m_i.$$\n假设经过适当标准化的核糖核酸测序 (RNA-seq) 测量值 $E_i$ 与 $m_i$ 成正比。在本问题中，设 $E_i$ 的任意单位与 $m_i$ 相同，因此 $E_i = m_i$。假设染色质免疫沉淀测序 (ChIP-seq) 提供了一个标量占有特征 $O_i$，该特征概括了基因启动子附近的转录因子结合情况，而染色质可及性 $A_i$（例如来自转座酶可及染色质测序分析，ATAC-seq）可能作为一个混杂因素，同时与 $O_i$ 和 $r_i$ 相关。潜变量转录率被建模为\n$$\\log r_i = \\alpha + \\beta_O O_i + \\beta_A A_i + \\varepsilon_i,$$\n其中 $\\varepsilon_i$ 是独立同分布的，满足 $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$。\n\n您需要实现一个程序，该程序在给定模拟数组 $(O_i,A_i,E_i,d_i)$（$i=1,\\dots,N$）的情况下，将执行以下操作：\n- 使用稳态关系，通过 $\\hat{r}_i = d_i E_i$ 从 $E_i$ 和 $d_i$ 推断出 $\\hat{r}_i$。\n- 通过普通最小二乘法 (OLS) 拟合两个线性模型：\n  1. 模型 $\\mathcal{M}_1$：将 $y_i = \\log \\hat{r}_i$ 对 $O_i$ 进行回归，并包含截距项。\n  2. 模型 $\\mathcal{M}_2$：将 $y_i = \\log \\hat{r}_i$ 对 $O_i$ 和 $A_i$ 进行回归，并包含截距项。\n- 使用前 $\\lfloor 0.7N \\rfloor$ 个基因作为训练集，其余基因作为测试集，用于预测评估。不使用角度，因此不需要角度单位。输出中不需要进行物理单位转换；所有要求的输出都是无量纲的。\n- 为每个测试用例计算以下量值：\n  1. 模型 $\\mathcal{M}_1$ 在测试集上的均方根误差 (RMSE)：\n     $$\\mathrm{RMSE}_1 = \\sqrt{\\frac{1}{n_{\\text{test}}} \\sum_{i \\in \\text{test}} \\left(y_i - \\hat{y}_{1,i}\\right)^2},$$\n     其中 $\\hat{y}_{1,i}$ 是来自模型 $\\mathcal{M}_1$ 的预测值，$n_{\\text{test}}$ 是测试基因的数量。\n  2. 模型 $\\mathcal{M}_2$ 在测试集上的 RMSE：\n     $$\\mathrm{RMSE}_2 = \\sqrt{\\frac{1}{n_{\\text{test}}} \\sum_{i \\in \\text{test}} \\left(y_i - \\hat{y}_{2,i}\\right)^2},$$\n     其中 $\\hat{y}_{2,i}$ 是来自模型 $\\mathcal{M}_2$ 的预测值。\n  3. 在两个模型之间，占有系数的估计值绝对变化（在训练集上计算）：\n     $$\\Delta_{\\beta_O} = \\left|\\hat{\\beta}_O^{(2)} - \\hat{\\beta}_O^{(1)}\\right|,$$\n     其中 $\\hat{\\beta}_O^{(1)}$ 是模型 $\\mathcal{M}_1$ 中 $O$ 的系数，$\\hat{\\beta}_O^{(2)}$ 是模型 $\\mathcal{M}_2$ 中 $O$ 的系数。\n  4. 一个布尔混杂标志，如果 $\\Delta_{\\beta_O} > \\tau$ 则定义为 $\\mathrm{True}$，否则为 $\\mathrm{False}$，其中 $\\tau$ 是该测试用例的指定阈值。\n  5. 在训练集上，给定 $A$ 时 $O$ 的偏决定系数，\n     $$R^2_{O\\mid A} = \\frac{R^2_{\\text{full}} - R^2_{\\text{reduced}}}{1 - R^2_{\\text{reduced}}},$$\n     其中 $R^2_{\\text{full}}$ 来自 $\\mathcal{M}_2$，$R^2_{\\text{reduced}}$ 来自仅将 $y$ 对 $A$ 进行回归并包含截距项的简化模型。如果数值四舍五入导致结果略微超出 $[0,1]$ 范围，则将其裁剪到 $[0,1]$。\n\n通过最小化残差平方和来实现 OLS；除了基本的线性代数外，不要依赖任何预打包的模型拟合工具。训练/测试集的划分必须按照指定的方式是确定性的。所有对数均为自然对数。\n\n测试套件。您的程序必须为以下测试用例在内部生成数据，使用独立的高斯基和指定的随机种子以确保确定性。令 $Z_i \\sim \\mathcal{N}(0,1)$ 和 $O_i \\sim \\mathcal{N}(0,1)$ 相互独立，并构造 $A_i = \\rho O_i + \\sqrt{1-\\rho^2} Z_i$。令 $\\log r_i = \\alpha + \\beta_O O_i + \\beta_A A_i + \\varepsilon_i$，其中 $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$，并设 $r_i = \\exp(\\log r_i)$。抽取 $\\log d_i \\sim \\mathcal{N}(\\mu_d,\\sigma_d^2)$ 并设 $d_i = \\exp(\\log d_i)$。最后，设 $E_i = r_i / d_i$。对于每个用例，提供 $(N,\\text{seed},\\alpha,\\beta_O,\\beta_A,\\sigma,\\rho,\\mu_d,\\sigma_d,\\tau)$：\n\n- 用例 $1$（独立可及性，中等效应）：$(N=300, \\text{seed}=13, \\alpha=1.0, \\beta_O=0.8, \\beta_A=0.5, \\sigma=0.2, \\rho=0.0, \\mu_d=-2.0, \\sigma_d=0.5, \\tau=0.1)$。\n- 用例 $2$（通过相关性产生混杂）：$(N=300, \\text{seed}=17, \\alpha=1.0, \\beta_O=0.8, \\beta_A=0.8, \\sigma=0.2, \\rho=0.8, \\mu_d=-2.0, \\sigma_d=0.5, \\tau=0.1)$。\n- 用例 $3$（更强的混杂，低噪声）：$(N=200, \\text{seed}=19, \\alpha=1.0, \\beta_O=0.8, \\beta_A=0.8, \\sigma=0.05, \\rho=0.95, \\mu_d=-2.0, \\sigma_d=0.7, \\tau=0.1)$。\n- 用例 $4$（无真实占有效应，存在伪关联风险）：$(N=300, \\text{seed}=23, \\alpha=1.0, \\beta_O=0.0, \\beta_A=0.8, \\sigma=0.2, \\rho=0.9, \\mu_d=-2.0, \\sigma_d=0.5, \\tau=0.1)$。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。对于以上述顺序排列的每个用例，输出四元组 $[\\mathrm{RMSE}_1,\\mathrm{RMSE}_2,\\text{flag},R^2_{O\\mid A}]$，并将这些四元组连接成一个包含所有用例的扁平列表。例如，输出应如下所示\n$$[\\mathrm{RMSE}_{1,1},\\mathrm{RMSE}_{2,1},\\text{flag}_1,R^2_{O\\mid A,1},\\mathrm{RMSE}_{1,2},\\mathrm{RMSE}_{2,2},\\text{flag}_2,R^2_{O\\mid A,2},\\mathrm{RMSE}_{1,3},\\mathrm{RMSE}_{2,3},\\text{flag}_3,R^2_{O\\mid A,3},\\mathrm{RMSE}_{1,4},\\mathrm{RMSE}_{2,4},\\text{flag}_4,R^2_{O\\mid A,4}],$$\n其中所有条目均由逗号分隔，布尔值显示为 True 或 False。不应打印任何其他文本。", "solution": "该问题在科学和数学上是适定的，为模拟和分析基因组学中一个称为“混杂”的常见统计问题提供了清晰的协议。该问题是有效的，并且可以构建一个解决方案。\n\n此问题的核心在于理解和量化线性回归模型中混杂变量的影响，这一问题被置于转录调控的背景下。中心法则提供了生物学基础：脱氧核糖核酸 ($DNA$) 被转录为信使核糖核酸 ($mRNA$)，后者再被翻译成蛋白质。特定 $mRNA$ 分子（记为 $m_i$）的丰度由其合成速率（转录起始，$r_i$）和降解速率 ($d_i$) 决定。一个常见的动力学模型由常微分方程 $\\frac{dm_i}{dt} = r_i - d_i m_i$ 给出。在稳态下，$mRNA$ 的浓度稳定，$\\frac{dm_i}{dt} = 0$，从而得到基本关系 $r_i = d_i m_i$。\n\n问题陈述我们拥有 $mRNA$ 丰度的测量值 ($E_i$，假设等于 $m_i$) 和 $mRNA$ 降解率 ($d_i$)。根据这些数据，我们可以推断出每个基因 $i$ 的转录率为 $\\hat{r}_i = d_i E_i$。问题假定该转录率受调控因子的影响。具体来说，转录率的对数被建模为转录因子占有 ($O_i$) 和染色质可及性 ($A_i$) 的线性函数：\n$$ \\log r_i = \\alpha + \\beta_O O_i + \\beta_A A_i + \\varepsilon_i $$\n在此模型中，$\\alpha$ 是基础转录率（作为截距项），$\\beta_O$ 和 $\\beta_A$ 分别是占有和可及性的效应，而 $\\varepsilon_i$ 是一个随机噪声项，假设服从正态分布 $\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$。我们的任务是从模拟数据中估计这些效应。\n\n关键的统计挑战是混杂。混杂因素是这样一个变量，它既与我们感兴趣的预测变量（此处为 $O_i$）相关，也与结果（此处为 $y_i = \\log \\hat{r}_i$）相关。在我们的模拟设置中，通过参数 $\\rho$ 构造染色质可及性 $A_i$ 使其与占有 $O_i$ 相关，表达式为 $A_i = \\rho O_i + \\sqrt{1-\\rho^2} Z_i$，其中 $Z_i$ 是一个独立的随机变量。由于 $A_i$ 也通过 $\\beta_A A_i$ 项直接影响 $\\log r_i$，因此它是一个潜在的混杂因素。\n\n为了研究这一点，我们使用普通最小二乘法 (OLS) 拟合两个线性模型。对于任何线性模型 $\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}$，其系数向量 $\\boldsymbol{\\beta}$ 的 OLS 估计值是使残差平方和最小化的值，由正规方程组的解给出：\n$$ \\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y} $$\n其中 $\\mathbf{X}$ 是设计矩阵（包括一列全为 1 的截距项），$\\mathbf{y}$ 是结果向量。\n\n模型 $\\mathcal{M}_1$ 是一个省略了潜在混杂因素的简单回归：\n$$ y_i = \\log \\hat{r}_i = \\alpha^{(1)} + \\beta_O^{(1)} O_i + \\text{error}_1 $$\n如果 $A_i$ 确实是一个混杂因素（即 $\\rho \\neq 0$ 且 $\\beta_A \\neq 0$），那么估计值 $\\hat{\\beta}_O^{(1)}$ 将是有偏的。它会错误地吸收一部分被省略变量 $A_i$ 的效应。\n\n模型 $\\mathcal{M}_2$ 是一个包含了潜在混杂因素的多元回归：\n$$ y_i = \\log \\hat{r}_i = \\alpha^{(2)} + \\beta_O^{(2)} O_i + \\beta_A^{(2)} A_i + \\text{error}_2 $$\n通过在模型中包含 $A_i$，我们可以获得一个针对 $A_i$ 效应进行调整后的估计值 $\\hat{\\beta}_O^{(2)}$。该估计值反映了在统计上保持 $A_i$ 不变的情况下，$O_i$ 与结果的关联。\n\n每个测试用例的处理流程如下：\n1.  **数据模拟**：根据指定的随机过程生成长度为 $N$ 的向量 $(O_i, A_i, E_i, d_i)$，通过随机种子确保可复现性。\n2.  **数据准备**：计算结果变量 $y_i = \\log(d_i E_i)$。将数据确定性地划分为训练集（前 $\\lfloor 0.7N \\rfloor$ 个样本）和测试集（剩余部分）。\n3.  **模型拟合**：在训练集上，使用 OLS 拟合模型 $\\mathcal{M}_1$ 和 $\\mathcal{M}_2$，以获得系数估计值 $(\\hat{\\alpha}^{(1)}, \\hat{\\beta}_O^{(1)})$ 和 $(\\hat{\\alpha}^{(2)}, \\hat{\\beta}_O^{(2)}, \\hat{\\beta}_A^{(2)})$。\n4.  **性能评估**：使用拟合好的模型预测测试集的结果，得到 $\\hat{y}_{1,i}$ 和 $\\hat{y}_{2,i}$。计算两个模型的均方根误差 (RMSE)，即 $\\mathrm{RMSE}_1$ 和 $\\mathrm{RMSE}_2$，以评估它们在未见数据上的预测准确性。较低的 RMSE 表示更好的性能。\n5.  **混杂评估**：计算估计值变化量 $\\Delta_{\\beta_O} = \\left|\\hat{\\beta}_O^{(2)} - \\hat{\\beta}_O^{(1)}\\right|$。一个较大的值表明 $A_i$ 是一个显著的混杂因素，因为将其包含在模型中会大幅改变 $O_i$ 的估计效应。根据阈值 $\\tau$ 设置一个布尔标志。\n6.  **偏决定系数计算**：计算偏决定系数 $R^2_{O\\mid A}$。该指标量化了在考虑了已被 $A_i$ 解释的方差之后，$y_i$ 中能被 $O_i$ 解释的方差比例。它在训练数据上通过公式 $R^2_{O\\mid A} = (R^2_{\\text{full}} - R^2_{\\text{reduced}}) / (1 - R^2_{\\text{reduced}})$ 计算，其中 $R^2_{\\text{full}}$ 是模型 $\\mathcal{M}_2$（将 $y$ 对 $O$ 和 $A$ 回归）的 R-squared 值，$R^2_{\\text{reduced}}$ 是仅将 $y$ 对 $A$ 回归的模型的 R-squared 值。这分离出了 $O_i$ 的独特贡献。\n\n这种全面的分析不仅使我们能够检测混杂的存在，还能量化其对模型系数和预测能力的影响。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation and analysis for all test cases.\n    \"\"\"\n    test_cases = [\n        # (N, seed, alpha, beta_O, beta_A, sigma, rho, mu_d, sigma_d, tau)\n        (300, 13, 1.0, 0.8, 0.5, 0.2, 0.0, -2.0, 0.5, 0.1),\n        (300, 17, 1.0, 0.8, 0.8, 0.2, 0.8, -2.0, 0.5, 0.1),\n        (200, 19, 1.0, 0.8, 0.8, 0.05, 0.95, -2.0, 0.7, 0.1),\n        (300, 23, 1.0, 0.0, 0.8, 0.2, 0.9, -2.0, 0.5, 0.1),\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        N, seed, alpha, beta_O, beta_A, sigma, rho, mu_d, sigma_d, tau = case\n        \n        # 1. Data Generation\n        rng = np.random.default_rng(seed)\n        O = rng.normal(0, 1, N)\n        Z = rng.normal(0, 1, N)\n        A = rho * O + np.sqrt(1 - rho**2) * Z\n        epsilon = rng.normal(0, sigma, N)\n        \n        log_r = alpha + beta_O * O + beta_A * A + epsilon\n        r = np.exp(log_r)\n        \n        log_d = rng.normal(mu_d, sigma_d, N)\n        d = np.exp(log_d)\n        \n        E = r / d\n        \n        # 2. Data Preparation\n        r_hat = d * E\n        y = np.log(r_hat)\n        \n        n_train = int(np.floor(0.7 * N))\n        n_test = N - n_train\n        \n        # Training set\n        O_train, A_train, y_train = O[:n_train], A[:n_train], y[:n_train]\n        # Test set\n        O_test, A_test, y_test = O[n_train:], A[n_train:], y[n_train:]\n\n        def perform_ols(X, y_data):\n            \"\"\"Performs OLS regression using np.linalg.solve for stability.\"\"\"\n            # beta_hat = (X.T @ X)^-1 @ X.T @ y\n            try:\n                # More stable than inv()\n                beta_hat = np.linalg.solve(X.T @ X, X.T @ y_data)\n            except np.linalg.LinAlgError:\n                # Fallback for singular matrix\n                beta_hat = np.linalg.pinv(X.T @ X) @ X.T @ y_data\n            return beta_hat\n\n        # 3. Model Fitting on Training Data\n        \n        # Model 1: y ~ 1 + O\n        X1_train = np.c_[np.ones(n_train), O_train]\n        beta1_hat = perform_ols(X1_train, y_train)\n        \n        # Model 2: y ~ 1 + O + A (Full model)\n        X2_train = np.c_[np.ones(n_train), O_train, A_train]\n        beta2_hat = perform_ols(X2_train, y_train)\n\n        # 4. RMSE Calculation on Test Data\n        \n        # Predictions for Model 1\n        X1_test = np.c_[np.ones(n_test), O_test]\n        y1_pred = X1_test @ beta1_hat\n        rmse1 = np.sqrt(np.mean((y_test - y1_pred)**2))\n        \n        # Predictions for Model 2\n        X2_test = np.c_[np.ones(n_test), O_test, A_test]\n        y2_pred = X2_test @ beta2_hat\n        rmse2 = np.sqrt(np.mean((y_test - y2_pred)**2))\n        \n        # 5. Confounding Assessment (on training coefficients)\n        beta_O1 = beta1_hat[1]\n        beta_O2 = beta2_hat[1]\n        delta_beta_O = np.abs(beta_O2 - beta_O1)\n        confounding_flag = delta_beta_O > tau\n\n        # 6. Partial R^2 Calculation (on training data)\n        \n        # Reduced model for partial R^2: y ~ 1 + A\n        XA_train = np.c_[np.ones(n_train), A_train]\n        betaA_hat = perform_ols(XA_train, y_train)\n        \n        SST = np.sum((y_train - np.mean(y_train))**2)\n        \n        # R^2 for full model (M2)\n        y2_pred_train = X2_train @ beta2_hat\n        SSR_full = np.sum((y_train - y2_pred_train)**2)\n        R2_full = 1 - SSR_full / SST if SST > 0 else 1.0\n\n        # R^2 for reduced model\n        yA_pred_train = XA_train @ betaA_hat\n        SSR_reduced = np.sum((y_train - yA_pred_train)**2)\n        R2_reduced = 1 - SSR_reduced / SST if SST > 0 else 1.0\n        \n        # Partial R^2\n        denominator = 1 - R2_reduced\n        if np.isclose(denominator, 0):\n             # If reduced model explains all variance, O can't explain more\n            R2_partial = 0.0\n        else:\n            R2_partial = (R2_full - R2_reduced) / denominator\n        \n        R2_partial_clipped = np.clip(R2_partial, 0, 1)\n\n        all_results.extend([rmse1, rmse2, confounding_flag, R2_partial_clipped])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "4613289"}]}