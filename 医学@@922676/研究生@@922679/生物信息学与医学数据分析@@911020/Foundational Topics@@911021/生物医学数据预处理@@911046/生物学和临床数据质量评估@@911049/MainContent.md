## 引言
在生物信息学和临床数据分析领域，数据的数量呈爆炸式增长，但其质量却参差不齐，成为制约科学发现和临床决策可靠性的关键瓶颈。从基因组测序的原始读段到电子健康记录中的临床笔记，任何环节的数据缺陷都可能被放大，最终导致错误的统计结论和无效的[科学推断](@entry_id:155119)。因此，系统性地评估、管理和提升[数据质量](@entry_id:185007)，已成为每一位数据科学家和研究人员必备的核心能力。本文旨在为读者构建一个关于[数据质量](@entry_id:185007)评估的全面知识框架，帮助您应对真实世界数据的复杂挑战。

我们将分三个章节展开探讨。在“原理与机制”中，我们将深入定义数据质量的六个核心维度，并从统计学和因果推断的角度，揭示数据缺陷如何转化为下游分析中的偏倚和不确定性。随后的“应用与跨学科连接”章节将通过基因组学、临床研究、药物研发等多个领域的真实案例，展示这些原理在实践中的具体应用和深远影响。最后，“动手实践”部分将提供一系列编程练习，让您亲手实现关键的数据质量评估与校正方法，将理论知识转化为解决实际问题的能力。通过这一系列的学习，您将能够更自信、更严谨地处理和分析复杂的生物与临床数据。

## 原理与机制

继前一章对生物与临床数据质量重要性的宏观介绍之后，本章将深入探讨构成[数据质量](@entry_id:185007)的核心原理与机制。我们将首先精确定义[数据质量](@entry_id:185007)的多个基础维度，然后详细阐释这些维度上的缺陷如何具体地转化为下游统计分析中的偏倚和不确定性。最后，我们将介绍一些用于系统性管理和评估[数据质量](@entry_id:185007)的高级框架，包括[数据溯源](@entry_id:175012)、[FAIR原则](@entry_id:275880)，并从因果推断的视角统一审视各类数据质量问题。本章旨在为读者提供一个严谨、系统且可操作的知识体系，以应对真实世界生物医学数据分析中的复杂挑战。

### [数据质量](@entry_id:185007)的核心维度

对[数据质量](@entry_id:185007)的评估不是一个单一的、模糊的概念，而是对一系列明确、可量化维度的多方面考量。一个被广泛接受的框架将数据质量分解为六个核心维度：完整性、准确性、有效性、一致性、及时性和唯一性。理解这些维度的精确定义是构建任何数据质量保证体系的第一步。

假设一个数据集可以被建模为一个有限的关系 $\mathcal{R}=\{r_i\}_{i=1}^N$，包含 $N$ 条记录，每条记录有 $M$ 个属性 $\mathcal{A}=\{A_j\}_{j=1}^M$。每个数据单元格 $x_{ij}$ 的值要么属于其声明的定义域，要么是一个缺失标记。基于此模型，我们可以如下形式化定义这六个维度 [@problem_id:4551930]。

**完整性 (Completeness)** 是指数据集中必需的数据元素是否存在。在许多应用中，并非所有属性都同等重要。因此，完整性通常针对一个预先定义的必需属性子集 $\mathcal{A}_{\mathrm{req}} \subseteq \mathcal{A}$ 进行评估。一个衡量完整性的指标 $c$ 可以是这些必需单元格中非缺失值的比例：
$$
c = \frac{1}{N |\mathcal{A}_{\mathrm{req}}|} \sum_{i=1}^N \sum_{A_j \in \mathcal{A}_{\mathrm{req}}} \mathbf{1}(x_{ij} \text{ 非缺失})
$$
其中 $\mathbf{1}(\cdot)$ 是[指示函数](@entry_id:186820)。一个不完整的诊断代码字段或缺失的实验室结果，会直接限制可用于分析的样本量或变量集。

**准确性 (Accuracy)** 指的是记录的值与“真实世界”中它所代表的真实值之间的一致性程度。评估准确性从根本上需要一个“金标准”或外部可信的参考源。例如，一个子集的细胞 $(i,j) \in \mathcal{S}_{\mathrm{acc}}$ 可能有经过专家精心策划的参考值 $g_{ij}$。准确性指标 $a$ 可以定义为数据值与这些参考值匹配的比例，通常在进行必要的格式或单位协调（通过函数 $\phi_j$）之后进行比较：
$$
a = \frac{1}{|\mathcal{S}_{\mathrm{acc}}|} \sum_{(i,j) \in \mathcal{S}_{\mathrm{acc}}} \mathbf{1}\big(\phi_j(x_{ij}) = \phi_j(g_{ij})\big)
$$
准确性是数据质量最直观的维度，但也是最难评估的，因为它依赖于外部“真相”的存在。

**有效性 (Validity)** 指的是数据值是否遵循其属性预先声明的规则，如数据类型、取值范围、格式或是否属于某个受控词汇表。例如，一个人的年龄应该是正整数，性别代码应为“男”或“女”，诊断代码应属于国际疾病分类（ICD）等标准编码系统。有效性指标 $v$ 可以是满足其属性定义域 $\mathcal{D}_j$ 约束的单元格的比例：
$$
v = \frac{1}{N M} \sum_{i=1}^N \sum_{j=1}^M \mathbf{1}(x_{ij} \in \mathcal{D}_j)
$$
一个值可以是有效的但并不准确。例如，一个记录的实验室值为“$5.0$”，如果该指标的有效范围是 $0.0$ 到 $10.0$，那么它是有效的。但如果该病人的真实值为“$7.5$”，那么这个记录是不准确的。

**一致性 (Consistency)** 衡量的是数据内部是否存在逻辑上的矛盾。这些矛盾通常由一组预定义的完整性约束 $\mathcal{C}$ 来定义，例如函数依赖（如一个病人ID在所有记录中对应同一个出生日期）、跨字段规则（如“若性别为男，则怀孕状态必须为否”）或业务规则（如“出院日期不能早于入院日期”）。一致性指标 $s$ 可以定义为所有适用的约束检查中未被违反的比例：
$$
s = 1 - \frac{B(\mathcal{C})}{V(\mathcal{C})}
$$
其中 $V(\mathcal{C})$ 是已验证的约束检查总数，$B(\mathcal{C})$ 是观察到的违规次数。不一致的数据会严重破坏分析的逻辑基础。

**及时性 (Timeliness)** 衡量的是数据对其所代表的事件而言是否足够新，以满足其预期用途。在临床环境中，一个关键方面是事件发生时间（如症状出现）与数据可用时间（如记录在电子健康记录中）之间的延迟。对于那些定义了事件时间 $e_i$ 和记录可用时间 $r_i$ 的记录子集 $\mathcal{I}$，及时性指标 $t$ 可以定义为延迟在可接受阈值 $\tau$ 内的记录比例：
$$
t = \frac{1}{|\mathcal{I}|} \sum_{i \in \mathcal{I}} \mathbf{1}\big((r_i - e_i) \le \tau\big)
$$
过时的数据可能会导致对当前状况的错误判断，尤其是在动态监测和快速响应的应用中。

**唯一性 (Uniqueness)** 衡量的是数据集中是否存在重复的记录。重复的定义取决于一个或多个属性的组合，即所谓的“键”。例如，在病人登记数据中，（病人ID）或（姓名、出生日期、社保号）的组合应能唯一地标识一个个体。对于一个选定的键函数 $\kappa$，唯一性指标 $u$ 可以定义为数据集中唯一键的比例：
$$
u = \frac{|\{\kappa(r_i): i=1, \dots, N\}|}{N}
$$
这个值仅在没有重复键时等于 $1$。重复记录会人为地夸大样本量，并可能导致[统计估计](@entry_id:270031)的严重偏倚。

这六个维度共同构成了一个多维的质量评估向量 $\mathbf{q}=(c,a,v,s,t,u)$。由于它们衡量的是数据质量的不同方面且本质上不可通约，因此将它们简单相加得到一个单一的质量分数通常是无意义的。一个更严谨的方法是采用多标准决策分析，或者在明确了特定应用场景下的权重后，进行加权汇总。

### [数据质量](@entry_id:185007)问题对[统计推断](@entry_id:172747)的影响

定义了数据质量的维度后，一个更深层次的问题是：为什么这些维度是必要的？答案在于，任何一个维度上的缺陷都可能通过特定的机制传播，最终导致下游[统计推断](@entry_id:172747)产生偏倚或不确定性。

#### 准确性与测量误差

准确性问题在[统计模型](@entry_id:755400)中通常表现为**测量误差 (measurement error)**。假设我们想要估计一个真实生物标志物浓度 $X^*$ 对某个连续健康结局 $Y$ 的影响，真实模型为 $Y = \beta X^* + \varepsilon$。然而，由于实验室检测的噪声，我们观察到的是一个有误差的测量值 $X$。测量误差的统计后果极大地取决于其产生机制 [@problem_id:4551935]。

**经典测量误差 (Classical Measurement Error)** 模型假设观测值 $X$ 是真实值 $X^*$ 加上一个随机误差 $U$，即 $X = X^* + U$。这里的误差 $U$ 通常被假定为均值为零，且与真实值 $X^*$ 无关。例如，在诊所使用自动[血压计](@entry_id:140497)测量血压时，由于袖带位置的微小差[异或](@entry_id:172120)短期的生理波动，读数会在个体真实的平均血压上下随机浮动。这就是一个典型的经典测量误差场景 [@problem_id:4551935]。

这种误差结构对[回归分析](@entry_id:165476)有着深刻的影响。如果我们天真地用观测值 $X$ 去代替真实值 $X^*$ 进行[普通最小二乘法](@entry_id:137121)（OLS）回归，即回归 $Y$ 对 $X$，那么所得到的斜率估计 $\hat{\beta}_{\mathrm{OLS}}$ 将会产生系统性偏倚。可以证明，在样本量足够大时，该估计值会收敛于 [@problem_id:4551854] [@problem_id:4552099]：
$$
\mathbb{E}[\hat{\beta}_{\mathrm{OLS}}] \to \beta \cdot \frac{\sigma_{X^*}^2}{\sigma_{X^*}^2 + \sigma_U^2}
$$
其中 $\sigma_{X^*}^2$ 是真实信号的方差，$\sigma_U^2$ 是测量误差的方差。由于方差总是非负的，分式 $\frac{\sigma_{X^*}^2}{\sigma_{X^*}^2 + \sigma_U^2}$ 的值在 $0$ 和 $1$ 之间。这意味着估计的效应大小 $|\mathbb{E}[\hat{\beta}_{\mathrm{OLS}}]|$ 将小于真实的效应大小 $|\beta|$。这种偏倚被称为**衰减偏倚 (attenuation bias)** 或[回归稀释](@entry_id:746571) (regression dilution)。测量误差越大（即 $\sigma_U^2$ 越大），估计的效应就越被“稀释”或“衰减”至零。这清晰地表明，准确性的缺失（即存在测量误差）会直接传播为统计[模型[参数估](@entry_id:752080)计](@entry_id:139349)的偏倚。

**Berkson测量误差 (Berkson Measurement Error)** 模型则描述了一个相反的情境。在这里，真实值 $X^*$ 是在一个设定的目标值 $X$ 周围随机波动，即 $X^* = X + V$。这里的误差 $V$ 被假定为与设定的目标值 $X$ 无关。一个典型的例子是空气污染流行病学研究，研究者将距离每个参与者最近的监测站的区域平均浓度作为其暴露值 $X$。然而，个体真实的暴露水平 $X^*$ 会因为微环境的差异（如室内外活动时间）而在这个指定的平均值上下波动 [@problem_id:4551935]。另一个例子是剂量滴定试验，临床医生设定了一个目标剂量 $W$（在此处对应 $X$），但病人由于依从性不佳，实际服用的剂量 $X^*$ 在 $W$ 周围随机变化 [@problem_id:4551935]。

与经典误差模型不同，当我们将结局 $Y$ 回归到设定的暴露值 $X$ 上时，Berkson误差并不会导致斜率估计的偏倚。因为真实模型可以重写为 $Y = \beta(X+V) + \varepsilon = \beta X + (\beta V + \varepsilon)$。新的复合误差项 $(\beta V + \varepsilon)$ 与回归量 $X$ 不相关，因此[OLS估计量](@entry_id:177304) $\hat{\beta}_{\mathrm{OLS}}$ 仍然是无偏的。然而，由于复合误差项的方差增大了（$\mathrm{Var}(\beta V + \varepsilon) > \mathrm{Var}(\varepsilon)$），这会导致估计的[置信区间](@entry_id:138194)变宽，[统计功效](@entry_id:197129)降低。

**不完美金标准下的准确性评估**
在许多生物医学场景中，评估准确性本身就面临挑战，因为“金标准”并非完美。例如，在评估一个用于预测变异致病性的分类器 $M$ 时，我们可能依赖一个本身就有误差的参考实验 $G$ 作为“真相”[@problem_id:4552107]。假设真实状态为 $T$，分类器 $M$ 和[参考标准](@entry_id:754189) $G$ 都可能对 $T$ 产生错误分类。在这种情况下，直接用 $G$ 作为基准计算的性能指标（如召回率 $P(M=1|G=1)$）将是有偏的。其偏差大小依赖于 $M$ 和 $G$ 各自的灵敏度和特异性，以及真实阳性率。

处理这种“真相不确定性”的严谨方法包括：
1.  **概率化标签 (Probabilistic Labels)**：将每个样本的真实标签不视为一个确定的 $0$ 或 $1$，而是表示为一个概率 $p_i = P(T_i=1)$。然后可以计算各种性能指标的[期望值](@entry_id:150961)，并通过蒙特卡洛模拟来估计其不确定性分布 [@problem_id:4552107]。
2.  **潜类别模型 (Latent Class Models)**：如果存在多个（通常至少三个）条件独立的检测方法，可以构建一个潜类别模型来联合估计所有方法的灵敏度/特异性以及真实的患病率，从而在没有完美金标准的情况下校正分类器 $M$ 的性能评估 [@problem_id:4552107]。

#### 完整性与[缺失数据](@entry_id:271026)

完整性问题在统计上对应**缺失数据 (missing data)**。处理缺失数据的关键在于理解数据为何会缺失，即缺失机制。Rubin的框架将缺失机制分为三类 [@problem_id:4552042]。

令 $Z$ 为可能存在缺失的变量， $R$ 为其缺失[指示变量](@entry_id:266428)（$R=1$表示观测到，$R=0$表示缺失）。令 $Y$ 和 $X$ 为总是被完全观测到的其他变量。

1.  **[完全随机缺失](@entry_id:170286) (Missing Completely At Random, MCAR)**：当缺失的概率与任何变量（无论是观测到的还是未观测到的）都无关时，即 $R \perp (Y, X, Z)$。在这种情况下，包含完整数据的子集可以看作是整个数据集的一个简单随机样本，因此基于完整数据的分析（Complete-Case Analysis, CCA）通常是无偏的。

2.  **[随机缺失](@entry_id:168632) (Missing At Random, MAR)**：当缺失的概率只依赖于已观测到的数据，而与未观测到的数据值本身无关时，即 $R \perp Z_{\mathrm{mis}} | (Y, X, Z_{\mathrm{obs}})$。例如，在临床试验中，男性患者可能比女性患者更有可能缺失某个生活质量问卷的数据（缺失性与性别相关），但对于有相同性别的患者来说，他们是否填写问卷与他们未填写的真实生活质量得分无关。

3.  **[非随机缺失](@entry_id:163489) (Missing Not At Random, MNAR)**：当缺失的概率依赖于未观测到的数据值本身时。例如，体重过高的患者可能因为不愿意透露而更倾向于不报告他们的体重。

这些机制对参数能否从观测数据中被唯一确定（即可识别性）有着至关重要的影响。对于基于似然的推断，如果参数 $\theta$（来自数据[生成模型](@entry_id:177561)）和 $\psi$（来自缺失[机制模型](@entry_id:202454)）是分离的，且观测数据的似然函数可以分解为两个独立的部分，那么缺失机制就是**可忽略的 (ignorable)**。

在MCAR和MAR下，可以证明观测数据的似然函数确实可以分解，因此缺失机制是可忽略的。这意味着，只要我们使用正确的统计方法（如[最大似然估计](@entry_id:142509)或[多重插补](@entry_id:177416)），我们就可以在不显式地对缺失机制建模的情况下获得对 $\theta$ 的有效推断 [@problem_id:4552042]。然而，需要注意的是，即使在MAR下，简单的完整数据分析（CCA）也通常是有偏的，除非缺失性与结局变量 $Y$ 无关 [@problem_id:4552042]。

而在MNAR下，似然函数无法分解，因为缺失概率与积分掉的缺失值 $Z_{\mathrm{mis}}$ 相关。这导致模型参数通常是**不可识别的 (non-identifiable)**，除非我们做出关于缺失机制的额外、无法由数据验证的假设。因此，完整性的缺失，特别是当其机制为MNAR时，会对[统计推断](@entry_id:172747)的有效性构成根本性的威胁。

#### 一致性、及时性与唯一性的后果

**一致性**的缺失会导致数据中存在逻辑矛盾或异构性，这可能引入严重的偏倚。例如，考虑一个情景：由于ICD编码标准的变更，在某个特定亚群中，一部分真实的阳性结局被错误地归类为阴性。如果这个亚群的暴露倾向与其他人群不同，那么这种错误分类就与暴露状态相关联，构成了**差异性错误分类 (differential misclassification)**。众所周知，差异性错误分类可以导致效应估计产生任意方向的偏倚，甚至逆转效应的方向 [@problem_id:4552099]。

**及时性**的缺失，如数据报告的延迟，在生存分析中可以被自然地建模为**右删失 (right-censoring)**。如果报告延迟（即删失时间）独立于真实的事件时间，这被称为**非信息性删失 (non-informative censoring)**。在这种情况下，标准的生存分析方法（如Kaplan-Meier估计或Cox比例风险模型）仍然可以提供对生存函数或风险比的无偏估计。然而，删失会减少处于风险集中的个体数量，从而增大了估计量（如生存率）的方差，降低了统计检验的功效。因此，在这种情况下，及时性的缺失主要传播为推断的**不确定性增加**，而非偏倚 [@problem_id:4552099]。

**唯一性**的缺失，即存在重复记录，会直接影响样本量的计算和描述性统计。例如，如果某些病人被重复计数，那么疾病患病率的估计将会被高估。在关联分析中，重复记录会使得某些个体的数据点在回归模型中获得不应有的权重，从而可能导致[参数估计](@entry_id:139349)的偏倚和[标准误](@entry_id:635378)的错误估计。

### 数据质量的管理与评估框架

除了在单个维度上评估数据质量，研究者还依赖更宏观的框架来系统地管理和保证数据的可靠性。[数据溯源](@entry_id:175012)和[FAIR原则](@entry_id:275880)是两个日益重要的指导性框架。

#### [数据溯源](@entry_id:175012)：可追溯性、[可复现性](@entry_id:151299)与可信度

**[数据溯源](@entry_id:175012) (Data Provenance)**，有时也称为数据沿袭 (data lineage) 或谱系 (pedigree)，记录了数据从其起源到当前状态所经历的完整历史。这包括原始数据源、所有应用的转换、处理步骤、所用软件和参数，以及执行这些步骤的环境。在生物信息学分析中，一个复杂的工作流可能包含数十个步骤，从原始测序读数（如 $D_0$）开始，经过比对（$f_1$）、变异调用（$f_2$）、注释（$f_3$）等一系列转换，最终得到一份变异列表（$D_3$）。

[数据溯源](@entry_id:175012)对于[数据质量](@entry_id:185007)至关重要，因为它支撑着三个关键概念 [@problem_id:4551924]：

1.  **[可复现性](@entry_id:151299) (Reproducibility)**：指他人能够利用相同的原始数据和相同的分析流程，得到完全相同（或比特级相同）结果的能力。要实现计算上的[可复现性](@entry_id:151299)，必须捕获完整的溯源信息，包括：所有输入数据（及其哈希值）、所用工具的精确版本、所有参数设置、所依赖的参考基因组等外部资源、计算环境（如操作系统、库版本，最好通过容器镜像指纹来捕获），以及控制[随机过程](@entry_id:268487)的随机数种子。只有当所有这些都被精确记录和复现时，一个确定性的分析流程才能保证产生相同的结果。

2.  **可追溯性 (Traceability)**：指能够追踪数据集中任一元素的来源。这可以是数据集级别的（例如，知道最终的基因表达矩阵 $D_3$ 是由原始读数文件 $D_0$ 生成的），也可以是记录级别的。例如，为了审计基因表达矩阵中的一个异常高表达的基因计数，我们需要能够追溯到是哪些具体的测序读数（reads）通过比对和定量步骤贡献了这一计数。这种细粒度的可追溯性对于调试、质量控制和理解异常结果至关重要，而这要求溯源记录包含记录间的明确链接，而不仅仅是数据集级别的元数据 [@problem_id:4551924]。

3.  **可信度 (Trust)**：指对分析结果完整性和有效性的合理信心。一个详尽且经过验证的溯源记录是建立信任的基石。例如，通过为每个数据制品记录加密哈希值，可以验证数据在分析流程中没有被篡改。然而，需要强调的是，溯源记录了“做了什么”，但不能保证“这样做在科学上是正确的”。一个完全可复现的分析仍可能因为使用了不合适的[参考基因组](@entry_id:269221)或错误的[统计模型](@entry_id:755400)假设而得出无效的科学结论 [@problem_id:4551924]。

#### [FAIR原则](@entry_id:275880)：一个指导性框架

[FAIR原则](@entry_id:275880)是一套旨在提升科学数据可重用性的高级指导方针。这四个原则——**可发现性 (Findable)**、**可访问性 (Accessible)**、**[互操作性](@entry_id:750761) (Interoperable)** 和 **可重用性 (Reusable)**——与我们之前讨论的[数据质量](@entry_id:185007)维度密切相关，并为其提供了更广阔的实践背景 [@problem_id:4552004]。

-   **可发现性 (Findable)**：数据及其[元数据](@entry_id:275500)应易于被人类和计算机找到。这要求为数据分配一个全球唯一且持久的标识符（如DOI），并用丰富的元数据来描述它，同时在可搜索的资源中对数据进行索引。这与**完整性**（丰富的[元数据](@entry_id:275500)）和**唯一性**（持久标识符）直接相关。用一个非持久的实验室URL代替DOI会严重损害可发现性 [@problem_id:4552004]。

-   **可访问性 (Accessible)**：一旦找到数据，用户需要知道如何访问它，可能包括认证和授权。这要求数据可通过标准化的、开放的通信协议（如HTTPS）进行访问。值得注意的是，可访问不等于完全公开。对于敏感的临床数据，[FAIR原则](@entry_id:275880)明确支持使用标准的认证和授权机制（如OAuth 2.0）来保护数据访问。因此，为受控数据设置[访问控制](@entry_id:746212)并不违反可访问性原则，反而是其负责任的实现方式 [@problem_id:4552004]。

-   **[互操作性](@entry_id:750761) (Interoperable)**：数据需要能够与其他数据进行整合和交互。这要求数据和元数据使用形式化的、共享的、广泛适用的语言进行知识表示，例如使用受控词汇表和[本体论](@entry_id:264049)（如用HPO描述表型，用SNOMED CT描述诊断）。这直接关联到**有效性**（遵循词汇表标准）和**一致性**（在不同数据集间使用相同的语义标准）。提高对标准本体论的覆盖率是增强互操作性的关键举措，这反过来又能提高跨数据集的**一致性** [@problem_id:4552004]。

-   **可重用性 (Reusable)**：最终目标是优化数据的重用。这要求数据有清晰的许可协议、详尽的来源信息（即**[数据溯源](@entry_id:175012)**），并遵循领域相关的社区标准。详尽的、机器可读的**溯源**信息是可重用性的核心，因为它能让其他研究者理解数据是如何产生的，从而信任并正确地重用它 [@problem_id:4552004]。

### 数据质量的因果推断视角

最后，我们可以借助因果推断的语言和工具，为各类数据质量问题如何导致偏倚提供一个统一的理论框架。有向无环图 (DAGs) 是表示变量间因果假设的强大工具，可以清晰地揭示不同类型的偏倚是如何产生的 [@problem_id:4552010]。

考虑一个使用电子健康记录（EHR）评估某项治疗 $A$ 对结局 $Y$ 影响的研究。假设我们关心的变量包括治疗 $A$、结局 $Y$、一个已知的混杂因素 $C$（如合并症负担）和一个未测量的混杂因素 $D$（如疾病严重程度）。

1.  **混杂偏倚 (Confounding Bias)**：当一个变量（如 $C$）既是 $A$ 的原因又是 $Y$ 的原因时，就会产生混杂。在DAG中，这表现为一条从 $A$ 到 $Y$ 的“后门路径”（如 $A \leftarrow C \to Y$）。如果不通过统计调整来“阻断”这条路径（如在[回归模型](@entry_id:163386)中控制 $C$），$A$ 和 $Y$ 之间的观测关联将部分反映 $C$ 的共同影响，从而偏离真实的因果效应。

2.  **选择偏倚 (Selection Bias)**：当样本的选择过程与暴露和结局相关时，就会产生选择偏倚。在DAG中，一个典型的机制是**对撞机分层偏倚 (collider-stratification bias)**。假设研究者只分析了接受了某个实验室检测 $L$ 的病人，而该检测的执行同时受到治疗 $A$ 和未测量的严重程度 $D$ 的影响（即 $A \to L \leftarrow D$）。在这种结构中，$L$ 是一个“对撞机”。在整个人群中，$A$ 和 $D$ 是不相关的，但当我们把分析限制在 $L=1$ 的人群中时，这种条件化行为会在 $A$ 和 $D$ 之间打开一个虚假的关联。由于 $D$ 也影响结局 $Y$（$D \to Y$），这就产生了一条从 $A$ 到 $Y$ 的非因果路径（$A \to L \leftarrow D \to Y$），导致选择偏倚。这种偏倚是由数据收集或分析过程中的**完整性**问题（只选择了特定子集）引起的。

3.  **测量偏倚 (Measurement Bias)**：当用于分析的变量不能准确地反映其所代表的真实概念时，就会产生测量偏倚。这直接源于**准确性**问题。例如，如果我们无法观测到真实的合并症负担 $C$，而只能使用一个有误差的代理指标 $C^*$ 来进行调整。在[回归模型](@entry_id:163386)中控制 $C^*$ 并不能完全阻断由 $C$ 造成的后门路径，从而导致**残余混杂 (residual confounding)**。同样，如果结局 $Y$ 被错误分类为 $Y^*$，也会导致效应估计的偏倚。

通过因果图，我们可以清晰地看到，[数据质量](@entry_id:185007)问题并非孤立存在，而是可以通过不同的因果路径机制，表现为统计分析中不同类型的偏倚。对数据质量的评估，从根本上说，就是对这些可能破坏因果推断有效性的路径的识别和量化。