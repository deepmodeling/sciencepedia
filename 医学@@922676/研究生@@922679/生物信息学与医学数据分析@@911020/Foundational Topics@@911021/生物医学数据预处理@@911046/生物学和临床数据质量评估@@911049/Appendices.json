{"hands_on_practices": [{"introduction": "下一代测序（NGS）的数据质量对于准确的基因组分析至关重要。虽然FastQC等工具提供的质量指标是数据集的重要“生命体征”，但它们对变异检测等下游分析结果的直接影响可能很抽象。本实践将通过从第一性原理出发建立一个模型，将常见的QC指标（如Phred质量分、重复率）转化为单核苷酸变异（SNV）检测中灵敏度损失的具体量化估计，从而填补这一空白。通过完成此练习[@problem_id:4551926]，您将对原始数据质量如何直接影响基因组发现的统计功效获得更深刻、更定量的理解。", "problem": "在下一代测序（NGS）的生物和临床数据的数据质量评估背景下，您将获得一个任务。您必须编写一个完整的程序，为每个数据集执行以下操作：计算一个FastQC风格的摘要，识别质量控制（QC）失败，并量化由观测到的QC指标导致的下游单核苷酸变异（SNV）检出灵敏度的预期损失。您的推导和实现必须基于第一性原理：Phred质量定义和用于变异检测的二项检验。\n\n请使用以下基础和定义：\n- Phred质量分数的定义为 $Q = -10 \\log_{10}(e)$，其中 $e$ 是碱基检出错误概率。因此，$e = 10^{-Q/10}$。\n- 假设一个二倍体杂合变异，其真实替代等位基因频率为 $f = 0.5$。设 $n$ 为一个位点上独立观测的有效数量（有效覆盖度）。在考虑重复后，假设该位点上的read是独立的。\n- 定义零假设 $H_0$（无真实变异）：一个替代碱基检出等于某个特定非参考等位基因的概率为 $p_0 = e/3$（假设替换错误在三个非参考碱基中均匀分布）。\n- 定义备择假设 $H_1$（一个真实的杂合变异）：一个read被观测为特定替代等位基因的概率为 $p_1 = f \\cdot (1 - e) + (1 - f) \\cdot (e/3)$。\n- 设置每个位点的假阳性尾部概率预算为 $\\alpha = 10^{-6}$。将在深度为 $n$ 时进行变异检出的最小整数阈值 $t$ 定义为满足 $\\Pr[X \\ge t \\mid X \\sim \\mathrm{Binomial}(n, p_0)] \\le \\alpha$ 的最小 $t$。如果不存在这样的 $t \\le n$，则灵敏度定义为 $0$。\n- 在 $H_1$ 下的灵敏度（功效）为 $S = \\Pr[X \\ge t \\mid X \\sim \\mathrm{Binomial}(n, p_1)]$。\n\n根据原始覆盖度和QC指标定义有效覆盖度 $n$ 如下。设 $C_{\\text{raw}}$ 为原始名义覆盖度。有效覆盖度为\n$$\nn = \\left\\lfloor C_{\\text{raw}} \\cdot m \\cdot (1 - d) \\cdot (1 - a) \\cdot (1 - n_f) \\cdot (1 - o) \\right\\rfloor,\n$$\n其中 $m$ 是比对率（小数），$d$ 是重复率（小数），$a$ 是接头污染比例（小数），$o$ 是过表达序列比例（小数），$n_f$ 是每碱基模糊检出比例（小数）。向下取整函数 $\\lfloor \\cdot \\rfloor$ 返回不大于其参数的最大整数。所有比例必须以小数形式提供，而不是百分比。\n\n为以下 $6$ 个模块计算FastQC风格的模块摘要，每个数据集均有通过/警告/失败状态，使用以下阈值：\n- 使用平均Phred质量 $Q_m$ 的每碱基序列质量：如果 $Q_m \\ge 28$ 则通过，如果 $23 \\le Q_m < 28$ 则警告，如果 $Q_m < 23$ 则失败。\n- 每序列GC含量偏差 $|g - g_0|$，其中 $g$ 是观测到的GC比例，$g_0$ 是预期的GC比例：如果 $|g - g_0| \\le 0.05$ 则通过，如果 $0.05 < |g - g_0| \\le 0.10$ 则警告，如果 $|g - g_0| > 0.10$ 则失败。\n- 使用重复率 $d$ 的序列重复水平：如果 $d \\le 0.20$ 则通过，如果 $0.20 < d \\le 0.50$ 则警告，如果 $d > 0.50$ 则失败。\n- 接头含量 $a$：如果 $a \\le 0.01$ 则通过，如果 $0.01 < a \\le 0.05$ 则警告，如果 $a > 0.05$ 则失败。\n- 过表达序列比例 $o$：如果 $o \\le 0.01$ 则通过，如果 $0.01 < o \\le 0.10$ 则警告，如果 $o > 0.10$ 则失败。\n- 每碱基 $N$ 含量 $n_f$：如果 $n_f \\le 0.01$ 则通过，如果 $0.01 < n_f \\le 0.03$ 则警告，如果 $n_f > 0.03$ 则失败。\n\n将通过/警告/失败映射为整数代码，具体如下：通过 $\\to +1$，警告 $\\to 0$，失败 $\\to -1$。模块顺序必须固定为：\n$[$每碱基序列质量, GC偏差, 重复, 接头, 过表达序列, $N$含量$]$。\n\n相对于每个数据集在相同原始覆盖度下具有理想QC的基线来定义灵敏度损失：对于基线，设置 $Q_m^{\\mathrm{base}} = 35$, $m^{\\mathrm{base}} = 1$, $d^{\\mathrm{base}} = 0$, $a^{\\mathrm{base}} = 0$, $o^{\\mathrm{base}} = 0$, $n_f^{\\mathrm{base}} = 0$，并计算 $n_{\\mathrm{base}} = \\lfloor C_{\\text{raw}} \\rfloor$。使用 $e_{\\mathrm{base}} = 10^{-Q_m^{\\mathrm{base}}/10}$ 以及相同的 $\\alpha$ 和 $f$ 来计算 $S_{\\mathrm{base}}$。灵敏度损失为 $L = S_{\\mathrm{base}} - S$，必须以 $[0,1]$ 范围内的小数形式报告。\n\n每个数据集的输入包括以下参数，所有参数均为无量纲，并在适用时以小数形式提供：\n- Read长度 $L$ (碱基) [仅用于报告一致性，不用于计算]，\n- 原始覆盖度 $C_{\\text{raw}}$，\n- 平均Phred质量 $Q_m$，\n- 比对率 $m$，\n- 重复率 $d$，\n- 接头污染比例 $a$，\n- 过表达序列比例 $o$，\n- 每碱基 $N$ 比例 $n_f$，\n- 观测GC比例 $g$，\n- 预期GC比例 $g_0$。\n\n使用以下数据集测试套件，每个数据集指定为一个元组 $(L, C_{\\text{raw}}, Q_m, m, d, a, o, n_f, g, g_0)$，所有数值均以小数形式写入：\n- 测试用例 $1$：$(150, 30, 32, 0.97, 0.12, 0.008, 0.006, 0.004, 0.41, 0.41)$。\n- 测试用例 $2$：$(100, 20, 25, 0.95, 0.35, 0.02, 0.03, 0.015, 0.36, 0.41)$。\n- 测试用例 $3$：$(150, 40, 20, 0.70, 0.70, 0.10, 0.15, 0.04, 0.50, 0.41)$。\n- 测试用例 $4$：$(75, 10, 30, 0.20, 0.50, 0.02, 0.01, 0.01, 0.41, 0.41)$。\n\n您的程序必须为每个测试用例计算：\n- 按上述固定顺序排列的模块状态码向量，\n- 失败模块的整数计数（等于 $-1$ 的条目数），\n- 灵敏度损失 $L$（浮点数）。\n\n最终输出格式：\n您的程序应生成单行输出，包含一个长度为 $4$ 的列表，其中每个元素对应一个测试用例，并且本身是一个形式为 $[$status\\_codes, fail\\_count, loss$]$ 的列表。$status\\_codes$ 必须是一个包含 $6$ 个整数的列表，顺序为固定的模块顺序。例如，整体结构必须如下所示\n$[[[s_{11},\\dots,s_{16}], f_1, \\ell_1], [[s_{21},\\dots,s_{26}], f_2, \\ell_2], [[s_{31},\\dots,s_{36}], f_3, \\ell_3], [[s_{41},\\dots,s_{46}], f_4, \\ell_4]]$，\n其中 $s_{ij} \\in \\{-1,0,1\\}$，$f_i$ 是一个整数，$\\ell_i$ 是 $[0,1]$ 范围内的小数。请严格按照这种单行格式打印列表，使用逗号分隔值，并用方括号表示列表。", "solution": "我们构建一个基于Phred质量定义和二项分布假设检验的有原则的解决方案。其目的是将可观察的质量控制（QC）指标转化为一个有效的覆盖度模型，然后量化不完美的QC对单核苷酸变异（SNV）检测灵敏度的影响。\n\n首先，我们使用Phred质量定义。Phred分数 $Q$ 和错误概率 $e$ 遵循 $Q = -10 \\log_{10}(e)$，所以 $e = 10^{-Q/10}$。对于一个平均Phred质量为 $Q_m$ 的数据集，我们将每碱基错误概率建模为 $e = 10^{-Q_m/10}$。这是测序技术中一个经过充分检验的关系。\n\n其次，我们将有效覆盖度 $n$ 计算为原始覆盖度与来自比对、重复、接头污染、过表达序列和模糊碱基的乘法惩罚的乘积。设 $C_{\\text{raw}}$ 为名义覆盖度。有效覆盖度是\n$$\nn = \\left\\lfloor C_{\\text{raw}} \\cdot m \\cdot (1 - d) \\cdot (1 - a) \\cdot (1 - n_f) \\cdot (1 - o) \\right\\rfloor.\n$$\n该公式基于以下理由：\n- 只有一部分比例为 $m$ 的read能比对到参考基因组并对覆盖度做出贡献。\n- 重复率 $d$ 表示非独立read的比例；因此，因子 $(1-d)$ 保留了唯一的观测值。\n- 接头污染 $a$ 通常导致剪切或产生不可用的碱基；我们通过 $(1-a)$ 进行惩罚。\n- 每碱基N比例 $n_f$ 表示无法为SNV检测提供信息的模糊检出；我们通过 $(1-n_f)$ 进行惩罚。\n- 过表达序列 $o$ 通常反映了污染或技术伪影；我们通过 $(1-o)$ 进行惩罚。\n我们应用向下取整函数 $\\lfloor \\cdot \\rfloor$ 将 $n$ 定义为独立伯努利试验的非负整数计数。\n\n第三，我们使用二项分布的假设检验来形式化变异检测的决策规则。在零假设 $H_0$（无真实变异）下，任何替代观测都源于测序错误。如果错误概率为 $e$，并假设在三个非参考碱基中错误检出是均匀分布的，那么观测到特定预定替代碱基的概率是\n$$\np_0 = \\frac{e}{3}.\n$$\n我们设定每个位点严格的假阳性预算为 $\\alpha = 10^{-6}$。检测阈值 $t$ 是满足以下条件的最小整数：\n$$\n\\Pr\\!\\left[X \\ge t \\mid X \\sim \\mathrm{Binomial}(n, p_0)\\right] \\le \\alpha.\n$$\n如果这样的 $t$ 超过了 $n$（即，没有 $t \\le n$ 满足不等式），则在给定的 $n$ 和 $e$ 下无法进行检出，我们将灵敏度设为 $0$。\n\n在备择假设 $H_1$（等位基因频率 $f = 0.5$ 的真实杂合变异）下，一个read支持特定的替代等位基因，原因要么是它来自替代染色体且被正确检出，要么是它来自参考染色体但被错误检出为该特定替代等位基因。因此，\n$$\np_1 = f \\cdot (1 - e) + (1 - f) \\cdot \\frac{e}{3}.\n$$\n灵敏度（功效）则为\n$$\nS = \\Pr\\!\\left[X \\ge t \\mid X \\sim \\mathrm{Binomial}(n, p_1)\\right].\n$$\n该表达式等于参数为 $(n, p_1)$ 的二项分布在 $t-1$ 处的生存函数值。\n\n第四，为了量化归因于QC的灵敏度损失，我们定义了一个每个数据集的基线，该基线固定了原始覆盖度，但移除了QC惩罚并使用高质量。对于基线，设 $Q_m^{\\mathrm{base}} = 35$（因此 $e_{\\mathrm{base}} = 10^{-3.5}$），$m^{\\mathrm{base}} = 1$，$d^{\\mathrm{base}} = 0$，$a^{\\mathrm{base}} = 0$，$o^{\\mathrm{base}} = 0$，$n_f^{\\mathrm{base}} = 0$，以及\n$$\nn_{\\mathrm{base}} = \\left\\lfloor C_{\\text{raw}} \\right\\rfloor.\n$$\n我们使用 $p_0^{\\mathrm{base}} = e_{\\mathrm{base}}/3$ 和 $\\alpha$ 类似地计算基线阈值 $t_{\\mathrm{base}}$，并使用 $p_1^{\\mathrm{base}} = f \\cdot (1 - e_{\\mathrm{base}}) + (1 - f) \\cdot e_{\\mathrm{base}}/3$ 计算基线灵敏度 $S_{\\mathrm{base}}$。灵敏度损失是\n$$\nL = S_{\\mathrm{base}} - S.\n$$\n\n第五，我们使用阈值将QC映射到FastQC风格的模块状态：\n- 使用 $Q_m$ 的每碱基序列质量：如果 $Q_m \\ge 28$ 则通过，如果 $23 \\le Q_m < 28$ 则警告，如果 $Q_m < 23$ 则失败。\n- 每序列GC含量偏差 $|g - g_0|$：如果 $\\le 0.05$ 则通过，如果 $\\in (0.05, 0.10]$ 则警告，如果 $> 0.10$ 则失败。\n- 序列重复水平 $d$：如果 $\\le 0.20$ 则通过，如果 $\\in (0.20, 0.50]$ 则警告，如果 $> 0.50$ 则失败。\n- 接头含量 $a$：如果 $\\le 0.01$ 则通过，如果 $\\in (0.01, 0.05]$ 则警告，如果 $> 0.05$ 则失败。\n- 过表达序列 $o$：如果 $\\le 0.01$ 则通过，如果 $\\in (0.01, 0.10]$ 则警告，如果 $> 0.10$ 则失败。\n- 每碱基 $N$ 含量 $n_f$：如果 $\\le 0.01$ 则通过，如果 $\\in (0.01, 0.03]$ 则警告，如果 $> 0.03$ 则失败。\n\n我们将通过 $\\to +1$，警告 $\\to 0$，失败 $\\to -1$ 进行映射，并通过计算六个模块中状态为 $-1$ 的数量来计算总失败次数。\n\n算法设计：\n- 对每个数据集，计算 $e = 10^{-Q_m/10}$，然后通过乘法惩罚和向下取整计算 $n$。计算 $p_0 = e/3$ 并找到二项分布尾部概率 $\\le \\alpha$ 的最小阈值 $t$。如果 $t > n$，则设置 $S = 0$；否则，计算 $p_1$ 和 $S$ 作为二项分布在 $t-1$ 处的生存函数值。\n- 类似地计算基线值 $e_{\\mathrm{base}}$、$n_{\\mathrm{base}}$、$p_0^{\\mathrm{base}}$、$t_{\\mathrm{base}}$、$p_1^{\\mathrm{base}}$ 和 $S_{\\mathrm{base}}$。\n- 输出 $L = S_{\\mathrm{base}} - S$ 以及模块状态向量和失败计数。\n- 测试套件由四个指定的数据集组成，每个数据集的 $(L, C_{\\text{raw}}, Q_m, m, d, a, o, n_f, g, g_0)$ 分别由以下给出：\n  - $(150, 30, 32, 0.97, 0.12, 0.008, 0.006, 0.004, 0.41, 0.41)$，\n  - $(100, 20, 25, 0.95, 0.35, 0.02, 0.03, 0.015, 0.36, 0.41)$，\n  - $(150, 40, 20, 0.70, 0.70, 0.10, 0.15, 0.04, 0.50, 0.41)$，\n  - $(75, 10, 30, 0.20, 0.50, 0.02, 0.01, 0.01, 0.41, 0.41)$。\n这些案例涵盖了高质量情况、无失败的临界警告、严重失败以及低有效覆盖度的情况。\n\n程序计算所请求的输出，并以指定的嵌套列表格式打印单行：\n$[[[s_{11},\\dots,s_{16}], f_1, \\ell_1], [[s_{21},\\dots,s_{26}], f_2, \\ell_2], [[s_{31},\\dots,s_{36}], f_3, \\ell_3], [[s_{41},\\dots,s_{46}], f_4, \\ell_4]]$，\n其中 $s_{ij} \\in \\{-1,0,1\\}$，$f_i$ 为整数，$\\ell_i \\in [0,1]$ 为小数（非百分比）。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom math import floor\nfrom scipy.stats import binom\n\n# Fixed parameters for the detection model\nALPHA = 1e-6  # per-site false positive tail probability\nF = 0.5       # heterozygous allele fraction\nQ_BASE = 35.0 # baseline mean Phred quality\n\n# Module thresholds and order:\n# [Per-base quality, GC deviation, Duplication, Adapter, Overrepresented, N content]\ndef classify_modules(Qm, g, g0, d, a, o, nf):\n    statuses = []\n    # Per-base sequence quality\n    if Qm >= 28:\n        statuses.append(1)\n    elif Qm >= 23:\n        statuses.append(0)\n    else:\n        statuses.append(-1)\n    # GC deviation\n    gc_dev = abs(g - g0)\n    if gc_dev = 0.05:\n        statuses.append(1)\n    elif gc_dev = 0.10:\n        statuses.append(0)\n    else:\n        statuses.append(-1)\n    # Duplication\n    if d = 0.20:\n        statuses.append(1)\n    elif d = 0.50:\n        statuses.append(0)\n    else:\n        statuses.append(-1)\n    # Adapter\n    if a = 0.01:\n        statuses.append(1)\n    elif a = 0.05:\n        statuses.append(0)\n    else:\n        statuses.append(-1)\n    # Overrepresented sequences\n    if o = 0.01:\n        statuses.append(1)\n    elif o = 0.10:\n        statuses.append(0)\n    else:\n        statuses.append(-1)\n    # N content\n    if nf = 0.01:\n        statuses.append(1)\n    elif nf = 0.03:\n        statuses.append(0)\n    else:\n        statuses.append(-1)\n    return statuses\n\ndef phred_to_error(Q):\n    # e = 10^{-Q/10}\n    return 10.0 ** (-Q / 10.0)\n\ndef effective_coverage(C_raw, m, d, a, o, nf):\n    eff = C_raw * m * (1.0 - d) * (1.0 - a) * (1.0 - nf) * (1.0 - o)\n    n = int(np.floor(eff)) if eff > 0 else 0\n    return max(n, 0)\n\ndef find_threshold(n, p0, alpha):\n    # Find the smallest integer t such that P[X >= t | Bin(n, p0)] = alpha\n    # We scan from t=0 to n+1; at t=n+1, the tail prob is 0 by definition.\n    # Use survival function for numerical stability.\n    for t in range(0, n + 2):\n        tail = binom.sf(t - 1, n, p0)  # P[X >= t]\n        if tail = alpha:\n            return t\n    # Should never reach here due to n+1 guard\n    return n + 1\n\ndef sensitivity_at_params(n, Qm, alpha, f):\n    # Compute sensitivity given effective coverage n and mean Phred Qm\n    if n == 0:\n        return 0.0\n    e = phred_to_error(Qm)\n    p0 = e / 3.0\n    t = find_threshold(n, p0, alpha)\n    if t > n:\n        return 0.0\n    p1 = f * (1.0 - e) + (1.0 - f) * (e / 3.0)\n    # Sensitivity = P[X >= t | Bin(n, p1)] = sf(t-1)\n    S = float(binom.sf(t - 1, n, p1))\n    # Clip to [0,1] to avoid minor numerical issues\n    if S  0.0:\n        S = 0.0\n    elif S > 1.0:\n        S = 1.0\n    return S\n\ndef compute_loss(C_raw, Qm, m, d, a, o, nf):\n    # Current dataset sensitivity\n    n_eff = effective_coverage(C_raw, m, d, a, o, nf)\n    S_curr = sensitivity_at_params(n_eff, Qm, ALPHA, F)\n    # Baseline sensitivity\n    n_base = int(np.floor(C_raw)) if C_raw > 0 else 0\n    S_base = sensitivity_at_params(n_base, Q_BASE, ALPHA, F)\n    loss = S_base - S_curr\n    # Clip for safety\n    if loss  0.0:\n        loss = 0.0\n    if loss > 1.0:\n        loss = 1.0\n    return loss\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each test case: (L, C_raw, Qm, m, d, a, o, nf, g, g0)\n    test_cases = [\n        (150, 30.0, 32.0, 0.97, 0.12, 0.008, 0.006, 0.004, 0.41, 0.41),\n        (100, 20.0, 25.0, 0.95, 0.35, 0.02, 0.03, 0.015, 0.36, 0.41),\n        (150, 40.0, 20.0, 0.70, 0.70, 0.10, 0.15, 0.04, 0.50, 0.41),\n        (75,  10.0, 30.0, 0.20, 0.50, 0.02, 0.01, 0.01, 0.41, 0.41),\n    ]\n\n    results = []\n    for case in test_cases:\n        L, C_raw, Qm, m, d, a, o, nf, g, g0 = case\n        status_codes = classify_modules(Qm, g, g0, d, a, o, nf)\n        fail_count = sum(1 for s in status_codes if s == -1)\n        loss = compute_loss(C_raw, Qm, m, d, a, o, nf)\n        # Round loss moderately for stable display\n        loss_rounded = float(np.round(loss, 6))\n        results.append([status_codes, fail_count, loss_rounded])\n\n    # Final print statement in the exact required format.\n    # Ensure no extra spaces for compact single-line output\n    def list_to_str(obj):\n        if isinstance(obj, list):\n            return \"[\" + \",\".join(list_to_str(x) for x in obj) + \"]\"\n        elif isinstance(obj, float):\n            # Use repr-like but controlled: avoid scientific for small numbers if possible\n            s = f\"{obj:.6f}\"\n            # Strip trailing zeros and possible trailing dot\n            s = s.rstrip('0').rstrip('.') if '.' in s else s\n            if s == \"\":\n                s = \"0\"\n            return s\n        else:\n            return str(obj)\n\n    print(list_to_str(results))\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "4551926"}, {"introduction": "在临床诊断和研究中，引入新的检测分析方法或比较两种现有方法是常见任务。简单地计算它们结果的相关性是不够的；我们需要严谨地评估系统性偏倚（比例偏倚和固定偏倚）和随机不一致性。本练习将指导您实现两种金标准技术：用于稳健估计偏倚的Passing-Bablok回归，以及用于可视化和量化一致性界限的Bland-Altman分析。这项实践[@problem_id:4552070]为您提供了验证新技术和确保不同测量系统可互换使用的基本技能。", "problem": "您将获得来自两种临床检测方法对同一样本评估的配对测量值。目标是使用稳健线性估计量和基于分布的一致性度量来评估方法比较和一致性。假设两种检测方法之间存在线性关系，表示为 $y = a + b x$，其中 $x$ 表示检测方法 $X$ 的测量值，$y$ 表示检测方法 $Y$ 的测量值。您必须实现一个非参数稳健回归来估计恒定偏倚 $a$ 和比例误差 $b$，并遵循以下约束：该估计量必须在单调变换下保持不变，并且必须依赖于顺序统计量而非参数化的分布假设。此外，您必须使用差值框架实现一个基于分布的一致性评估，计算差值均值和一致性界限 (LoA)，对于差值 $d_i = y_i - x_i$，LoA 定义为区间 $[\\overline{d} - 1.96 s_d, \\overline{d} + 1.96 s_d]$，其中 $\\overline{d}$ 是差值的样本均值，$s_d$ 是差值的样本标准差。LoA 应在与测量值相同的尺度上进行解释，并且必须计算为实数。\n\n用于推导和实现的基本原理和定义：\n- 线性模型 $y = a + b x$，其中 $a$ 和 $b$ 未知。\n- 基于中位数和顺序统计量的稳健估计原理，以减轻离群值的影响并避免对正态性的依赖。\n- 基于差值的一致性度量：对于配对数据 $(x_i,y_i)$，差值为 $d_i = y_i - x_i$，均值为 $\\overline{d} = \\frac{1}{n}\\sum_{i=1}^{n} d_i$，样本标准差为 $s_d = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^{n} (d_i - \\overline{d})^2}$。\n- 一致性界限 (LoA): $[\\overline{d} - 1.96 s_d, \\overline{d} + 1.96 s_d]$。\n\n您必须编写一个程序，该程序针对每个测试用例返回一个列表 $[b,a,\\overline{d},\\text{LoA}_{\\text{low}},\\text{LoA}_{\\text{high}}]$，其中 $b$ 和 $a$ 是线性关系 $y = a + b x$ 的稳健斜率和截距估计值，$\\overline{d}$ 是差值均值，而 $\\text{LoA}_{\\text{low}}$ 和 $\\text{LoA}_{\\text{high}}$ 是下一致性界限和上一致性界限。所有量都应被视为无量纲的数值；不涉及物理单位。一致性界限应使用常数 $1.96$ 计算，这反映了在差值分布近似对称的假设下的双侧覆盖范围。\n\n测试套件：\n- 案例 1（一般情况；中等比例误差和小偏倚）：\n  $x = [\\,8,12,18,25,35,48,60,72,85,100\\,]$ 和 \n  $y = [\\,0.98\\cdot 8 + 1.7 + 0.3,\\;0.98\\cdot 12 + 1.7 - 0.4,\\;0.98\\cdot 18 + 1.7 + 0.2,\\;0.98\\cdot 25 + 1.7 - 0.1,\\;0.98\\cdot 35 + 1.7 + 0.5,\\;0.98\\cdot 48 + 1.7 - 0.2,\\;0.98\\cdot 60 + 1.7 + 0.1,\\;0.98\\cdot 72 + 1.7 + 0.0,\\;0.98\\cdot 85 + 1.7 - 0.3,\\;0.98\\cdot 100 + 1.7 + 0.4\\,]$。\n- 案例 2（边界情况，包含重复的 $x$ 值；测试对零分母数据对的处理）：\n  $x = [\\,50,50,60,60,60,80,80,80,90,110\\,]$ 和 \n  $y = [\\,1.05\\cdot 50 - 3 + 1.0,\\;1.05\\cdot 50 - 3 - 2.0,\\;1.05\\cdot 60 - 3 + 0.5,\\;1.05\\cdot 60 - 3 - 1.5,\\;1.05\\cdot 60 - 3 + 0.4,\\;1.05\\cdot 80 - 3 + 1.2,\\;1.05\\cdot 80 - 3 - 0.8,\\;1.05\\cdot 80 - 3 + 0.3,\\;1.05\\cdot 90 - 3 + 0.0,\\;1.05\\cdot 110 - 3 - 0.6\\,]$。\n- 案例 3（存在离群值；测试稳健性）：\n  $x = [\\,5,15,25,35,45,55,65,75,85,95\\,]$ 和 \n  $y = [\\,1.2\\cdot 5 - 4 + 0.2,\\;1.2\\cdot 15 - 4 - 0.1,\\;1.2\\cdot 25 - 4 + 0.3,\\;1.2\\cdot 35 - 4 + 15.0,\\;1.2\\cdot 45 - 4 - 0.5,\\;1.2\\cdot 55 - 4 + 0.0,\\;1.2\\cdot 65 - 4 + 0.4,\\;1.2\\cdot 75 - 4 - 12.0,\\;1.2\\cdot 85 - 4 + 0.1,\\;1.2\\cdot 95 - 4 - 0.2\\,]$。\n- 案例 4（接近一致；微小随机偏差）：\n  $x = [\\,10,20,30,40,50,60,70,80,90,100\\,]$ 和 \n  $y = [\\,10 + 0.05,\\;20 - 0.02,\\;30 + 0.03,\\;40 + 0.01,\\;50 - 0.04,\\;60 + 0.02,\\;70 - 0.03,\\;80 + 0.00,\\;90 + 0.04,\\;100 - 0.01\\,]$。\n\n您的程序必须：\n- 实现基于点对关系派生的顺序统计量的稳健估计器，用于估计 $a$ 和 $b$，并在 $x_j = x_i$ 时避免零分母计算。\n- 实现一致性界限的计算，使用差值 $d_i = y_i - x_i$，计算 $\\overline{d}$ 和 $s_d$，然后计算 $\\overline{d} \\pm 1.96 s_d$。\n- 对于每个测试用例，生成列表 $[b,a,\\overline{d},\\text{LoA}_{\\text{low}},\\text{LoA}_{\\text{high}}]$，其值为实数。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个以逗号分隔的列表，该列表被方括号括起，其中每个项目是针对一个测试用例的列表。例如，输出必须采用 $[[b_1,a_1,\\overline{d}_1,\\text{LoA}_{\\text{low},1},\\text{LoA}_{\\text{high},1}],[b_2,a_2,\\overline{d}_2,\\text{LoA}_{\\text{low},2},\\text{LoA}_{\\text{high},2}],\\ldots]$ 的形式，不得包含任何附加文本。", "solution": "该问题要求实现一种用于比较两种临床检测方法的统计方法学。这涉及两个主要部分：首先，使用稳健线性回归来模拟两种方法之间的关系；其次，进行一致性分析以量化它们测量值之间的差异。解决方案将基于生物统计学和临床化学中符合问题规范的标准、成熟技术进行推导和实现。\n\n### 问题验证\n问题陈述已经过验证，被认为是合理、定义明确且具有科学依据的。它指定了线性模型 $y = a + b x$ 来关联两种检测方法 $X$ 和 $Y$ 的测量值。它要求使用一种基于顺序统计量的稳健、非参数回归技术来估计参数 $a$（恒定偏倚）和 $b$（比例误差）。在计算斜率时排除 $x_i = x_j$ 的情况这一特定约束，与其他要求相结合，唯一地确定了所需的方法为 Passing-Bablok 回归。对于一致性分析，它指定了差值均值和一致性界限 (LoA) 的计算，这与 Bland-Altman 方法一致。数据和所需的输出格式都已明确定义。\n\n### 第 1 部分：使用 Passing-Bablok 估计量的稳健线性回归\n\nPassing-Bablok 方法是一种用于拟合线性回归线的非参数过程，对离群值具有稳健性。它完全符合问题的要求。估计过程分两步进行：首先是斜率 $b$，然后是截距 $a$。\n\n**步骤 1.1：斜率估计 ($\\hat{b}$)**\n\n给定 $n$ 个配对数据点 $(x_i, y_i)$，第一步是计算所有可能的点对斜率。对于任意两个不同的点 $i$ 和 $j$ ($1 \\le i  j \\le n$)，只要分母不为零，就计算一个斜率 $s_{ij}$。所有此类有效斜率的集合 $S$ 由下式给出：\n$$\nS = \\left\\{ s_{ij} = \\frac{y_j - y_i}{x_j - x_i} \\quad \\forall i  j \\text{ such that } x_i \\ne x_j \\right\\}\n$$\n问题明确指出，在计算斜率时应忽略 $x_i = x_j$ 的数据对，这是该方法的一个决定性特征。设 $N$ 为集合 $S$ 中元素的数量。斜率的稳健估计值 $\\hat{b}$ 是这点对斜率集合的中位数：\n$$\n\\hat{b} = \\text{median}(S)\n$$\n选择中位数是因为其稳健性。对于一个包含 $N$ 个斜率的排序集合，如果 $N$ 是奇数，中位数是位于位置 $(N+1)/2$ 的值。如果 $N$ 是偶数，中位数通常是位于位置 $N/2$ 和 $N/2+1$ 的两个中心值的平均值。该估计量依赖于顺序统计量（中位数），并且不对数据或误差的分布做任何假设。\n\n**步骤 1.2：截距估计 ($\\hat{a}$)**\n\n一旦获得斜率估计值 $\\hat{b}$，就可以估计截距 $a$。对于每个数据点 $(x_i, y_i)$，通过重新排列线性方程来计算一个候选截距 $c_i$：\n$$\nc_i = y_i - \\hat{b} x_i\n$$\n这将产生一个包含 $n$ 个候选截距的集合 $\\{c_1, c_2, \\ldots, c_n\\}$。截距的稳健估计值 $\\hat{a}$ 是该集合的中位数：\n$$\n\\hat{a} = \\text{median}(\\{c_1, c_2, \\ldots, c_n\\})\n$$\n这个两步过程得出了稳健回归直线 $\\hat{y} = \\hat{a} + \\hat{b} x$。\n\n### 第 2 部分：使用 Bland-Altman 方法进行一致性分析\n\n回归分析描述了两种方法之间的系统性关系，而一致性分析则量化了它们之间的随机差异。Bland-Altman 方法是完成此任务的标准方法。\n\n**步骤 2.1：差值计算 ($d_i$)**\n\n基本量是配对测量值之间的差值：\n$$\nd_i = y_i - x_i\n$$\n这代表了第 $i$ 个样本的误差或不一致性。\n\n**步骤 2.2：差值的均值和标准差**\n\n这些差值的平均值 $\\overline{d}$ 代表了两种检测方法之间的平均偏倚。接近 $0$ 的 $\\overline{d}$ 值表示系统性偏倚较低。其计算公式为：\n$$\n\\overline{d} = \\frac{1}{n} \\sum_{i=1}^{n} d_i\n$$\n差值围绕均值的离散程度由样本标准差 $s_d$ 来量化。问题提供了无偏样本标准差的公式，即除以 $n-1$：\n$$\ns_d = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^{n} (d_i - \\overline{d})^2}\n$$\n\n**步骤 2.3：一致性界限 (LoA)**\n\n一致性界限定义了一个范围，两种方法之间的大多数差异预计会落入此范围内。假设差值近似呈正态分布，该范围通常是一个 $95\\%$ 的预测区间。问题指定使用常数 $1.96$，这对应于标准正态分布中的相应 z-score ($z_{0.025}$)。\n\n下一致性界限和上一致性界限的计算公式如下：\n$$\n\\text{LoA}_{\\text{low}} = \\overline{d} - 1.96 s_d\n$$\n$$\n\\text{LoA}_{\\text{high}} = \\overline{d} + 1.96 s_d\n$$\n这两个值与差值均值 $\\overline{d}$ 一起，为检测方法之间的一致性提供了完整的总结。\n\n### 计算总结\n对于每个测试用例，程序将执行这些步骤来计算五个所需的值：稳健斜率 $\\hat{b}$、稳健截距 $\\hat{a}$、差值均值 $\\overline{d}$、下一致性界限 $\\text{LoA}_{\\text{low}}$ 和上一致性界限 $\\text{LoA}_{\\text{high}}$。这些值将以列表 $[\\hat{b}, \\hat{a}, \\overline{d}, \\text{LoA}_{\\text{low}}, \\text{LoA}_{\\text{high}}]$ 的形式返回。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the method comparison problem for all test cases.\n    Implements Passing-Bablok regression and Bland-Altman analysis.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (general case; moderate proportional error and small bias)\n        (\n            np.array([8, 12, 18, 25, 35, 48, 60, 72, 85, 100], dtype=float),\n            np.array([9.84, 13.06, 19.54, 26.1, 36.5, 48.54, 60.6, 72.26, 84.7, 100.1], dtype=float)\n        ),\n        # Case 2 (boundary with repeated x values; tests handling of zero-denominator pairs)\n        (\n            np.array([50, 50, 60, 60, 60, 80, 80, 80, 90, 110], dtype=float),\n            np.array([50.5, 47.5, 60.5, 58.5, 60.4, 82.2, 80.2, 81.3, 91.5, 111.9], dtype=float)\n        ),\n        # Case 3 (outliers present; tests robustness)\n        (\n            np.array([5, 15, 25, 35, 45, 55, 65, 75, 85, 95], dtype=float),\n            np.array([2.2, 13.9, 26.3, 53.0, 49.5, 62.0, 74.4, 74.0, 98.1, 109.8], dtype=float)\n        ),\n        # Case 4 (near-agreement; small random deviations)\n        (\n            np.array([10, 20, 30, 40, 50, 60, 70, 80, 90, 100], dtype=float),\n            np.array([10.05, 19.98, 30.03, 40.01, 49.96, 60.02, 69.97, 80.00, 90.04, 99.99], dtype=float)\n        )\n    ]\n\n    results = []\n    \n    for x, y in test_cases:\n        # Part 1: Passing-Bablok Regression for b and a\n        \n        # Step 1.1: Estimate slope b\n        n = len(x)\n        slopes = []\n        for i in range(n):\n            for j in range(i + 1, n):\n                if x[j] - x[i] != 0:\n                    slope_ij = (y[j] - y[i]) / (x[j] - x[i])\n                    slopes.append(slope_ij)\n        \n        b = np.median(slopes)\n        \n        # Step 1.2: Estimate intercept a\n        intercept_residuals = y - b * x\n        a = np.median(intercept_residuals)\n        \n        # Part 2: Bland-Altman Analysis for agreement\n        \n        # Step 2.1: Calculate differences\n        differences = y - x\n        \n        # Step 2.2: Calculate mean and std dev of differences\n        mean_diff = np.mean(differences)\n        # ddof=1 for sample standard deviation (division by n-1)\n        std_diff = np.std(differences, ddof=1)\n        \n        # Step 2.3: Calculate Limits of Agreement (LoA)\n        loa_low = mean_diff - 1.96 * std_diff\n        loa_high = mean_diff + 1.96 * std_diff\n        \n        # Compile results for the current test case\n        case_result = [b, a, mean_diff, loa_low, loa_high]\n        results.append(case_result)\n\n    # Final print statement in the exact required format.\n    # The default str() representation for a list is '[item1, item2, ...]', which is what's needed.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "4552070"}, {"introduction": "电子健康记录（EHR）常常是碎片化的，并且包含错误，由于姓名和日期的拼写错误或格式变化，多条记录可能指向同一位患者。识别并合并这些记录的过程，即实体解析，是一项基础性的数据质量挑战。这个动手实践[@problem_id:4551876]将引导您构建一个完整的实体解析流程，涵盖从分块、相似度评分到基于图的聚类。您将学会实施精确率、召回率以及合并/拆分错误等指标来评估流程性能，为清理和整合复杂的真实世界临床数据集提供坚实的实践基础。", "problem": "考虑一个用于电子健康记录 (EHR) 中患者记录的实体解析工作流，其中每条记录可能包含带有噪声的标识符。其目标是算法化地确定哪些记录指向真实世界中的同一位患者（实体），通过成对链接的传递闭包构建预测簇，然后使用信息检索和集合论中的标准定义（包括合并与分裂的误差分析）来评估数据质量。解决方案必须从第一性原理推导，并实现为一个完整的、可运行的程序。\n\n您将获得以下基础性依据：\n- 实体作为指向同一真实世界患者的记录的等价类的概念，由记录集的一个划分表示。\n- 基于集合论定义的成对评估。给定一组预测簇，定义包含在同一预测簇内的无序记录对集合。同样，定义包含在同一真实簇内的无序记录对集合。\n- 信息检索中被广泛接受的精确率和召回率的定义。精确率等于预测为正的实例中真正例的比例。召回率等于所有真正例中被正确预测的比例。\n\n您必须实现以下工作流和计算，不得依赖预封装的实体解析例程：\n1. 记录表示：每条记录包含字段 \"id\"、\"name\"、\"dob\"（\"YYYY-MM-DD\" 格式的出生日期）和 \"zip\"（邮政编码）。\n2. 分块：分块函数 $b$ 通过将具有相同（姓氏最后一个单词的首字母，出生年份）对的记录分组来减少候选空间。形式上，对于一条记录 $r$，令 $b(r) = (L(r), Y(r))$，其中 $L(r)$ 是 \"name\" 字段最后一个词元的大写首字母，而 $Y(r)$ 是 \"dob\" 字段的前四个字符。\n3. 字符串规范化：在计算相似度之前，将 \"name\" 字段映射为大写并移除所有非字母字符。\n4. 编辑距离：对于两个规范化的字符串 $a$ 和 $b$，将 Levenshtein 编辑距离 $d(a,b)$ 定义为将 $a$ 转换为 $b$ 所需的最小单字符插入、删除或替换次数。$d(a,b)$ 的动态规划递推式是根据编辑距离具有最优子结构的基本原理构建的。定义姓名相似度\n$$\ns_{\\text{name}}(a,b) = \n\\begin{cases}\n1 - \\dfrac{d(a,b)}{\\max(|a|,|b|)},  \\text{if } \\max(|a|,|b|)  0,\\\\\n1,  \\text{otherwise.}\n\\end{cases}\n$$\n5. 属性相似度：定义 $s_{\\text{dob}}(r_i,r_j) = 1$ 如果 \"dob\" 字符串完全相等，否则为 $0$。定义 $s_{\\text{zip}}(r_i,r_j) = 1$ 如果 \"zip\" 字符串完全相等；如果 \"zip\" 字符串的前三个字符相等且字符串长度至少为三，则 $s_{\\text{zip}}(r_i,r_j) = 0.5$；否则 $s_{\\text{zip}}(r_i,r_j) = 0$。\n6. 加权分数：对于同一分块内的候选对 $(r_i,r_j)$，计算加权分数\n$$\nS(r_i,r_j) = w_{\\text{name}} \\cdot s_{\\text{name}}(r_i,r_j) + w_{\\text{dob}} \\cdot s_{\\text{dob}}(r_i,r_j) + w_{\\text{zip}} \\cdot s_{\\text{zip}}(r_i,r_j),\n$$\n其中非负权重 $w_{\\text{name}}, w_{\\text{dob}}, w_{\\text{zip}}$ 的和为 $1$。\n7. 边构建与聚类：如果 $S(r_i,r_j) \\ge T$（其中 $T$ 是一个指定的阈值），则在 $r_i$ 和 $r_j$ 之间创建一条无向链接。预测簇是这个基于记录的无向图的连通分量。\n8. 成对度量：令 $P$ 为位于同一预测簇内的无序记录对集合，令 $G$ 为位于同一真实簇内的无序记录对集合。定义\n$$\n\\text{TP} = |P \\cap G|,\\quad \\text{FP} = |P \\setminus G|,\\quad \\text{FN} = |G \\setminus P|.\n$$\n精确率定义为\n$$\n\\text{precision} =\n\\begin{cases}\n\\dfrac{\\text{TP}}{\\text{TP} + \\text{FP}},  \\text{if } \\text{TP} + \\text{FP}  0,\\\\\n1,  \\text{if } \\text{TP} + \\text{FP} = 0,\n\\end{cases}\n$$\n召回率定义为\n$$\n\\text{recall} =\n\\begin{cases}\n\\dfrac{\\text{TP}}{\\text{TP} + \\text{FN}},  \\text{if } \\text{TP} + \\text{FN}  0,\\\\\n1,  \\text{if } \\text{TP} + \\text{FN} = 0.\n\\end{cases}\n$$\n所有比率输出必须是小数，而不是百分比。\n9. 合并与分裂误差分析：对于每个预测簇 $C$，令 $m_C$ 为 $C$ 中记录所包含的不同真实实体标识符的数量。合并误差计数为\n$$\nM = \\sum_{C} \\max(0, m_C - 1).\n$$\n对于每个真实簇 $T$，令 $s_T$ 为包含 $T$ 成员的不同预测簇的数量。分裂误差计数为\n$$\nS_{\\text{split}} = \\sum_{T} \\max(0, s_T - 1).\n$$\n\n您必须实现上述工作流，并为以下每个测试用例计算精确率、召回率、$M$ 和 $S_{\\text{split}}$。请使用指定的权重和阈值。\n\n测试用例 1（理想路径，中度噪声，正确合并）：\n- 权重：$w_{\\text{name}} = 0.6$，$w_{\\text{dob}} = 0.3$，$w_{\\text{zip}} = 0.1$，阈值 $T = 0.85$。\n- 记录：\n  - $\\text{id}=$\"r1\", $\\text{name}=$\"John Smith\", $\\text{dob}=$\"1980-05-12\", $\\text{zip}=$\"02139\"\n  - $\\text{id}=$\"r2\", $\\text{name}=$\"JON SMITH\", $\\text{dob}=$\"1980-05-12\", $\\text{zip}=$\"02139\"\n  - $\\text{id}=$\"r3\", $\\text{name}=$\"Jane Doe\", $\\text{dob}=$\"1975-11-30\", $\\text{zip}=$\"02138\"\n  - $\\text{id}=$\"r4\", $\\text{name}=$\"Janet Doe\", $\\text{dob}=$\"1975-11-30\", $\\text{zip}=$\"02138\"\n  - $\\text{id}=$\"r5\", $\\text{name}=$\"Alice Johnson\", $\\text{dob}=$\"1990-02-01\", $\\text{zip}=$\"10001\"\n  - $\\text{id}=$\"r6\", $\\text{name}=$\"Alyce Johnson\", $\\text{dob}=$\"1990-02-01\", $\\text{zip}=$\"10001\"\n  - $\\text{id}=$\"r7\", $\\text{name}=$\"Bob Lee\", $\\text{dob}=$\"1980-05-12\", $\\text{zip}=$\"02139\"\n- 真实实体标识符：\n  - \"r1\" 和 \"r2\" 属于实体 \"t1\"。\n  - \"r3\" 和 \"r4\" 属于实体 \"t2\"。\n  - \"r5\" 和 \"r6\" 属于实体 \"t3\"。\n  - \"r7\" 属于实体 \"t4\"。\n\n测试用例 2（边界情况，全部唯一，预期无合并）：\n- 权重：$w_{\\text{name}} = 0.6$，$w_{\\text{dob}} = 0.3$，$w_{\\text{zip}} = 0.1$，阈值 $T = 0.95$。\n- 记录：\n  - $\\text{id}=$\"s1\", $\\text{name}=$\"Michael Brown\", $\\text{dob}=$\"1965-07-19\", $\\text{zip}=$\"90210\"\n  - $\\text{id}=$\"s2\", $\\text{name}=$\"Michelle Brown\", $\\text{dob}=$\"1970-07-19\", $\\text{zip}=$\"90210\"\n  - $\\text{id}=$\"s3\", $\\text{name}=$\"Carlos Garcia\", $\\text{dob}=$\"1988-12-12\", $\\text{zip}=$\"33101\"\n  - $\\text{id}=$\"s4\", $\\text{name}=$\"Li Wang\", $\\text{dob}=$\"1993-03-03\", $\\text{zip}=$\"10002\"\n- 真实实体标识符：\n  - \"s1\"、\"s2\"、\"s3\"、\"s4\" 中的每一个都属于一个独立的实体。\n\n测试用例 3（边缘情况，重度噪声导致错误合并与分裂）：\n- 权重：$w_{\\text{name}} = 0.6$，$w_{\\text{dob}} = 0.3$，$w_{\\text{zip}} = 0.1$，阈值 $T = 0.7$。\n- 记录：\n  - $\\text{id}=$\"u1\", $\\text{name}=$\"Sara Connor\", $\\text{dob}=$\"1979-01-01\", $\\text{zip}=$\"94110\"\n  - $\\text{id}=$\"u2\", $\\text{name}=$\"Sarah Conner\", $\\text{dob}=$\"1979-01-01\", $\\text{zip}=$\"94110\"\n  - $\\text{id}=$\"u3\", $\\text{name}=$\"Sera Conor\", $\\text{dob}=$\"1980-01-01\", $\\text{zip}=$\"94110\"\n  - $\\textid=$\"u4\", $\\text{name}=$\"Sam Conor\", $\\text{dob}=$\"1979-01-01\", $\\text{zip}=$\"94110\"\n  - $\\text{id}=$\"u5\", $\\text{name}=$\"Tom Hanks\", $\\text{dob}=$\"1956-07-09\", $\\text{zip}=$\"94110\"\n  - $\\text{id}=$\"u6\", $\\text{name}=$\"Thomas Hank\", $\\text{dob}=$\"1956-07-09\", $\\text{zip}=$\"94110\"\n  - $\\text{id}=$\"u7\", $\\text{name}=$\"Sara Connor\", $\\text{dob}=$\"1979-01-02\", $\\text{zip}=$\"94110\"\n- 真实实体标识符：\n  - \"u1\"、\"u2\"、\"u3\" 属于实体 \"A\"。\n  - \"u4\" 属于实体 \"B\"。\n  - \"u5\"、\"u6\" 属于实体 \"C\"。\n  - \"u7\" 属于实体 \"D\"。\n\n最终输出规范：\n- 对于按顺序列出的每个测试用例，输出一个四元列表 $[\\text{precision}, \\text{recall}, M, S_{\\text{split}}]$，其中精确率和召回率四舍五入到四位小数（以小数而非百分比形式），$M$ 和 $S_{\\text{split}}$ 为整数。\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，每个元素是对应测试用例的四元列表。例如，格式必须像 $[[p_1,r_1,M_1,S_1],[p_2,r_2,M_2,S_2],[p_3,r_3,M_3,S_3]]$ 在单行上。", "solution": "电子健康记录 (EHR) 中的实体解析问题是确保数据质量和患者安全的一项关键任务。所提供的问题陈述为这项任务勾勒了一个完整的、自包含的工作流，从初始记录处理到最终性能评估。该问题在计算机科学、信息检索和数据管理的既定原则上具有科学依据。它是一个良构问题，所有必要的数据、参数和算法步骤都已明确定义，确保每个测试用例都存在唯一且可验证的解决方案。因此，该问题被认为是有效的，下面将给出完整的解决方案。\n\n该解决方案通过实现问题陈述中指定的操作序列来系统地构建。\n\n**1. 基础数据表示与预处理**\n\n每条患者记录都被视为一个结构化数据对象，包含 \"id\"、\"name\"、\"dob\" 和 \"zip\" 字段。真实情况由记录集的一个划分表示，其中划分的每个单元对应一个唯一的真实世界实体。\n\n**2. 为提高计算效率而进行分块**\n\n为避免计算成本高昂的全对比较（对于 $n$ 条记录，其复杂度为 $O(n^2)$），采用了分块策略。记录根据从其属性派生的键被划分为块。指定的分块函数 $b(r) = (L(r), Y(r))$ 将共享相同姓氏最后一个单词首字母 $L(r)$ 和相同四位数出生年份 $Y(r)$ 的记录分组。所有后续的成对比较都限制在同一分块内的记录之间，从而显著减少了搜索空间。\n\n**3. 字符串规范化与相似度度量**\n\n原始数据通常带有噪声。为了稳健地比较姓名，首先应用一个规范化函数。该函数将 \"name\" 字段转换为大写并移除所有非字母字符，以确保比较不区分大小写且不受标点符号影响。\n\n规范化之后，为每个属性计算记录对 $(r_i, r_j)$ 之间的相似度分数：\n\n- **姓名相似度 ($s_{\\text{name}}$)**：这基于 Levenshtein 编辑距离 $d(a,b)$，它是字符串比较中的一个基本度量，用于量化两个序列之间的差异。该距离使用动态规划算法计算，该算法依赖于最优子结构原理。对于两个规范化的姓名字符串 $a$ 和 $b$，基于矩阵的递推式为：\n$$\nD[i][j] = \\min\n\\begin{cases}\nD[i-1][j] + 1  \\text{(删除)} \\\\\nD[i][j-1] + 1  \\text{(插入)} \\\\\nD[i-1][j-1] + \\mathbf{1}_{a[i] \\neq b[j]}  \\text{(替换)}\n\\end{cases}\n$$\n距离 $d(a,b)$ 是值 $D[|a|][|b|]$。然后将此距离进行规范化，以产生一个介于 $0$ 和 $1$ 之间的相似度分数：\n$$\ns_{\\text{name}}(a,b) = 1 - \\dfrac{d(a,b)}{\\max(|a|,|b|)}, \\text{ for } \\max(|a|,|b|)  0\n$$\n如果两个字符串都为空，则 $s_{\\text{name}}=1$。\n\n- **出生日期相似度 ($s_{\\text{dob}}$)**：这是一个严格的二元比较。如果 \"dob\" 字符串完全相同，则 $s_{\\text{dob}}(r_i,r_j) = 1$，否则 $s_{\\text{dob}}(r_i,r_j) = 0$。\n\n- **邮政编码相似度 ($s_{\\text{zip}}$)**：该度量允许部分匹配，以反映地理上的邻近性。对于完全匹配，$s_{\\text{zip}}(r_i,r_j) = 1$；如果前三位数字匹配（对于长度至少为 $3$ 的邮政编码），则 $s_{\\text{zip}}(r_i,r_j) = 0.5$；否则 $s_{\\text{zip}}(r_i,r_j) = 0$。\n\n这些单独的相似度通过加权和组合成一个单一的复合分数：\n$$\nS(r_i,r_j) = w_{\\text{name}} \\cdot s_{\\text{name}}(r_i,r_j) + w_{\\text{dob}} \\cdot s_{\\text{dob}}(r_i,r_j) + w_{\\text{zip}} \\cdot s_{\\text{zip}}(r_i,r_j)\n$$\n其中权重 $w_{\\text{name}}, w_{\\text{dob}}, w_{\\text{zip}}$ 是非负的，且和为 $1$。\n\n**4. 基于图的聚类**\n\n记录集被建模为一个无向图 $G=(V, E)$，其中顶点 $V$ 是记录。如果相似度分数 $S(r_i, r_j)$ 达到或超过指定的阈值 $T$，则将一条边 $(r_i, r_j)$ 添加到边集 $E$ 中。此步骤将成对相似性转换为关系网络。\n\n记录的预测簇随后通过找到该图的连通分量来确定。连通分量是一个极大子图，其中任意两个顶点都通过一条路径相互连接。这内在地强制执行了传递闭包：如果记录 A 与 B 链接，B 与 C 链接，那么这三者都会被分到同一个实体中，即使 A 和 C 没有被直接比较或未达到相似度阈值。使用标准的图遍历算法，如深度优先搜索 (DFS) 或广度优先搜索 (BFS)，来识别这些分量。\n\n**5. 基于第一性原理的性能评估**\n\n预测簇的质量通过使用两类度量对照真实情况进行评估。\n\n- **成对度量**：精确率和召回率是从信息检索中借鉴而来的。其核心思想是评估所有被预测在同一簇内的无序记录对集合，并将其与所有真正在同一簇内的记录对集合进行比较。\n    - 令 $G$ 为属于同一真实实体的无序记录对集合。$|G| = \\sum_{T \\in \\text{Truth}} \\binom{|T|}{2}$。\n    - 令 $P$ 为属于同一预测簇的无序记录对集合。$|P| = \\sum_{C \\in \\text{Predicted}} \\binom{|C|}{2}$。\n    - 真正例 ($TP$)：$|P \\cap G|$，被正确识别的对的数量。\n    - 假正例 ($FP$)：$|P \\setminus G|$，被错误链接的对的数量。\n    - 假反例 ($FN$)：$|G \\setminus P|$，被遗漏的真实对的数量。\n    - 精确率和召回率的计算公式如下：\n    $$\n    \\text{precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}} = \\frac{|P \\cap G|}{|P|} \\quad \\text{and} \\quad \\text{recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}} = \\frac{|P \\cap G|}{|G|}\n    $$\n    如规定，分母为 $0$ 的特殊情况通过将度量定义为 $1$ 来处理。\n\n- **簇级误差分析**：\n    - **合并误差 ($M$)**：该指标量化了多少个不同的真实实体被错误地合并到单个预测簇中。对于每个预测簇 $C$，我们计算其所代表的不同真实实体的数量 $m_C$。总合并误差是超出 $1$ 的部分的总和：$M = \\sum_{C} \\max(0, m_C - 1)$。\n    - **分裂误差 ($S_{\\text{split}}$)**：该指标量化了真实实体在多个预测簇中的碎片化程度。对于每个真实实体 $T$，我们计算其成员分散在多少个不同的预测簇中，记为 $s_T$。总分裂误差是 $S_{\\text{split}} = \\sum_{T} \\max(0, s_T - 1)$。\n\n这些步骤构成了一套完整而严谨的实体解析及其评估方法论，该方法论将以编程方式实现，以解决给定的测试用例。", "answer": "```python\nimport numpy as np\nfrom collections import defaultdict\nfrom itertools import combinations\n\ndef solve():\n    \"\"\"\n    Main function to run the entity resolution workflow for all test cases.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"params\": {\"w_name\": 0.6, \"w_dob\": 0.3, \"w_zip\": 0.1, \"threshold\": 0.85},\n            \"records\": [\n                {\"id\": \"r1\", \"name\": \"John Smith\", \"dob\": \"1980-05-12\", \"zip\": \"02139\"},\n                {\"id\": \"r2\", \"name\": \"JON SMITH\", \"dob\": \"1980-05-12\", \"zip\": \"02139\"},\n                {\"id\": \"r3\", \"name\": \"Jane Doe\", \"dob\": \"1975-11-30\", \"zip\": \"02138\"},\n                {\"id\": \"r4\", \"name\": \"Janet Doe\", \"dob\": \"1975-11-30\", \"zip\": \"02138\"},\n                {\"id\": \"r5\", \"name\": \"Alice Johnson\", \"dob\": \"1990-02-01\", \"zip\": \"10001\"},\n                {\"id\": \"r6\", \"name\": \"Alyce Johnson\", \"dob\": \"1990-02-01\", \"zip\": \"10001\"},\n                {\"id\": \"r7\", \"name\": \"Bob Lee\", \"dob\": \"1980-05-12\", \"zip\": \"02139\"},\n            ],\n            \"ground_truth\": {\"t1\": [\"r1\", \"r2\"], \"t2\": [\"r3\", \"r4\"], \"t3\": [\"r5\", \"r6\"], \"t4\": [\"r7\"]},\n        },\n        {\n            \"params\": {\"w_name\": 0.6, \"w_dob\": 0.3, \"w_zip\": 0.1, \"threshold\": 0.95},\n            \"records\": [\n                {\"id\": \"s1\", \"name\": \"Michael Brown\", \"dob\": \"1965-07-19\", \"zip\": \"90210\"},\n                {\"id\": \"s2\", \"name\": \"Michelle Brown\", \"dob\": \"1970-07-19\", \"zip\": \"90210\"},\n                {\"id\": \"s3\", \"name\": \"Carlos Garcia\", \"dob\": \"1988-12-12\", \"zip\": \"33101\"},\n                {\"id\": \"s4\", \"name\": \"Li Wang\", \"dob\": \"1993-03-03\", \"zip\": \"10002\"},\n            ],\n            \"ground_truth\": {\"e1\": [\"s1\"], \"e2\": [\"s2\"], \"e3\": [\"s3\"], \"e4\": [\"s4\"]},\n        },\n        {\n            \"params\": {\"w_name\": 0.6, \"w_dob\": 0.3, \"w_zip\": 0.1, \"threshold\": 0.7},\n            \"records\": [\n                {\"id\": \"u1\", \"name\": \"Sara Connor\", \"dob\": \"1979-01-01\", \"zip\": \"94110\"},\n                {\"id\": \"u2\", \"name\": \"Sarah Conner\", \"dob\": \"1979-01-01\", \"zip\": \"94110\"},\n                {\"id\": \"u3\", \"name\": \"Sera Conor\", \"dob\": \"1980-01-01\", \"zip\": \"94110\"},\n                {\"id\": \"u4\", \"name\": \"Sam Conor\", \"dob\": \"1979-01-01\", \"zip\": \"94110\"},\n                {\"id\": \"u5\", \"name\": \"Tom Hanks\", \"dob\": \"1956-07-09\", \"zip\": \"94110\"},\n                {\"id\": \"u6\", \"name\": \"Thomas Hank\", \"dob\": \"1956-07-09\", \"zip\": \"94110\"},\n                {\"id\": \"u7\", \"name\": \"Sara Connor\", \"dob\": \"1979-01-02\", \"zip\": \"94110\"},\n            ],\n            \"ground_truth\": {\"A\": [\"u1\", \"u2\", \"u3\"], \"B\": [\"u4\"], \"C\": [\"u5\", \"u6\"], \"D\": [\"u7\"]},\n        },\n    ]\n\n    final_results = []\n    \n    for case in test_cases:\n        final_results.append(process_case(case))\n    \n    print(f\"[{','.join(map(str, final_results))}]\")\n\n\ndef normalize_name(name):\n    return \"\".join(filter(str.isalpha, name.upper()))\n\ndef levenshtein_distance(s1, s2):\n    m, n = len(s1), len(s2)\n    if m  n:\n        s1, s2 = s2, s1\n        m, n = n, m\n    \n    if n == 0:\n        return m\n    \n    dp = np.zeros((m + 1, n + 1), dtype=int)\n    for i in range(m + 1):\n        dp[i][0] = i\n    for j in range(n + 1):\n        dp[0][j] = j\n        \n    for i in range(1, m + 1):\n        for j in range(1, n + 1):\n            cost = 0 if s1[i-1] == s2[j-1] else 1\n            dp[i][j] = min(dp[i-1][j] + 1,        # Deletion\n                           dp[i][j-1] + 1,        # Insertion\n                           dp[i-1][j-1] + cost)   # Substitution\n    return dp[m, n]\n\ndef get_pairs_from_clusters(clusters):\n    pairs = set()\n    for cluster in clusters:\n        # Sort to make pairs canonical\n        sorted_cluster = sorted(list(cluster))\n        for r1, r2 in combinations(sorted_cluster, 2):\n            pairs.add((r1, r2))\n    return pairs\n\ndef find_connected_components(adj, nodes):\n    visited = set()\n    components = []\n    for node in nodes:\n        if node not in visited:\n            component = set()\n            stack = [node]\n            visited.add(node)\n            while stack:\n                curr = stack.pop()\n                component.add(curr)\n                for neighbor in adj.get(curr, []):\n                    if neighbor not in visited:\n                        visited.add(neighbor)\n                        stack.append(neighbor)\n            components.append(component)\n    return components\n\ndef process_case(case_data):\n    records = case_data[\"records\"]\n    params = case_data[\"params\"]\n    ground_truth_clusters = case_data[\"ground_truth\"]\n\n    records_map = {rec['id']: rec for rec in records}\n    \n    # 1. Blocking\n    blocks = defaultdict(list)\n    for rec in records:\n        last_name_token = rec['name'].split()[-1]\n        last_initial = last_name_token[0].upper()\n        year_of_birth = rec['dob'][:4]\n        block_key = (last_initial, year_of_birth)\n        blocks[block_key].append(rec['id'])\n    \n    # 2. Edge Construction\n    adj = defaultdict(list)\n    for block in blocks.values():\n        for r_id1, r_id2 in combinations(block, 2):\n            rec1, rec2 = records_map[r_id1], records_map[r_id2]\n            \n            # Name similarity\n            norm_name1 = normalize_name(rec1['name'])\n            norm_name2 = normalize_name(rec2['name'])\n            max_len = max(len(norm_name1), len(norm_name2))\n            if max_len > 0:\n                s_name = 1 - levenshtein_distance(norm_name1, norm_name2) / max_len\n            else:\n                s_name = 1.0\n\n            # DOB similarity\n            s_dob = 1.0 if rec1['dob'] == rec2['dob'] else 0.0\n\n            # ZIP similarity\n            s_zip = 0.0\n            zip1, zip2 = rec1['zip'], rec2['zip']\n            if zip1 == zip2:\n                s_zip = 1.0\n            elif len(zip1) >= 3 and len(zip2) >= 3 and zip1[:3] == zip2[:3]:\n                s_zip = 0.5\n            \n            # Weighted score\n            score = (params['w_name'] * s_name +\n                     params['w_dob'] * s_dob +\n                     params['w_zip'] * s_zip)\n            \n            if score >= params['threshold']:\n                adj[r_id1].append(r_id2)\n                adj[r_id2].append(r_id1)\n    \n    # 3. Clustering\n    predicted_clusters = find_connected_components(adj, records_map.keys())\n\n    # 4. Pairwise Metrics\n    true_pairs = get_pairs_from_clusters(ground_truth_clusters.values())\n    predicted_pairs = get_pairs_from_clusters(predicted_clusters)\n\n    tp = len(true_pairs.intersection(predicted_pairs))\n    fp = len(predicted_pairs) - tp\n    fn = len(true_pairs) - tp\n    \n    precision = 1.0 if (tp + fp) == 0 else tp / (tp + fp)\n    recall = 1.0 if (tp + fn) == 0 else tp / (tp + fn)\n\n    # 5. Merge and Split Error Analysis\n    # Merge errors\n    record_to_gt = {rec_id: gt_id for gt_id, rec_ids in ground_truth_clusters.items() for rec_id in rec_ids}\n    merge_error = 0\n    for p_cluster in predicted_clusters:\n        gt_entities_in_cluster = {record_to_gt[rec_id] for rec_id in p_cluster}\n        merge_error += max(0, len(gt_entities_in_cluster) - 1)\n        \n    # Split errors\n    record_to_p_cluster = {}\n    for i, p_cluster in enumerate(predicted_clusters):\n        for rec_id in p_cluster:\n            record_to_p_cluster[rec_id] = i\n    \n    split_error = 0\n    for gt_cluster in ground_truth_clusters.values():\n        p_clusters_hit = {record_to_p_cluster[rec_id] for rec_id in gt_cluster}\n        split_error += max(0, len(p_clusters_hit) - 1)\n\n    return [round(precision, 4), round(recall, 4), merge_error, split_error]\n\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "4551876"}]}