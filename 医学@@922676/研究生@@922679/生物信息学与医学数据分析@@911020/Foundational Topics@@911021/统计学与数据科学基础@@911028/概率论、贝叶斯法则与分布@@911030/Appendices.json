{"hands_on_practices": [{"introduction": "在生物信息学分析中，正确理解变量之间的关系至关重要。一个常见的误区是将在统计上不相关的变量（协方差为零）等同于相互独立的变量。本练习旨在通过一个关于单细胞测序数据中批次效应的模拟研究，来揭示这一区别的实际意义，强调简单的线性相关性度量可能无法捕捉到非线性的复杂依赖关系 [@problem_id:4598782]。通过构建并分析这些反直觉的例子，您将加深对协方差与独立性之间深刻差异的理解。", "problem": "一位统计学家正在设计一项模拟研究，以评估在单细胞核糖核酸测序 (scRNA-seq) 数据中，匹配一阶矩的去混杂程序是否会错过批次效应。设 $X$ 表示某个固定基因在不同细胞中的一个实值、标准化的基因表达量，设 $Y$ 表示批次标签。该研究考虑 $2$ 个批次。这位统计学家想要一个 $(X,Y)$ 的明确联合分布，使得 $\\operatorname{Cov}(X,Y)=0$ 但 $X$ 和 $Y$ 不独立，从而证明零协方差并不意味着没有批次效应。假设下述所有随机变量都定义在同一个概率空间上，并且独立性陈述指的是概率独立性。\n\n仅使用基本定义（例如，协方差的定义 $\\operatorname{Cov}(X,Y)=\\mathbb{E}\\left[(X-\\mathbb{E}[X])(Y-\\mathbb{E}[Y])\\right]$ 和独立性的定义，以及全期望定律），选择所有满足研究目标的构造。每个选项都为 $(X,Y)$ 提出了一个分布构造；除非另有说明，任何辅助变量都与 $Y$ 独立。\n\nA. 令 $Y\\sim \\mathrm{Bernoulli}(0.5)$ 且 $W\\sim \\mathcal{N}(0,1)$ 独立。定义 $X=Y\\,W$。\n\nB. 令 $Y$ 以相等的概率取值于 $\\{-1,1\\}$，且 $W\\sim \\mathcal{N}(0,1)$，与 $Y$ 独立。定义 $X=Y\\,W$。\n\nC. 令 $Y\\sim \\mathrm{Bernoulli}(0.5)$ 且 $W\\sim \\mathcal{N}(0,1)$ 独立。定义 $X=W+Y$。\n\nD. 令 $Y\\sim \\mathrm{Bernoulli}(0.5)$。在给定 $Y$ 的条件下，定义 $X\\mid(Y=0)\\sim \\mathcal{N}(0,1)$ 和 $X\\mid(Y=1)\\sim \\mathcal{N}(0,4)$。\n\nE. 令 $Y\\sim \\mathrm{Bernoulli}(0.5)$。在给定 $Y$ 的条件下，定义 $X\\mid(Y=0)\\sim \\mathcal{N}(0,1)$ 和 $X\\mid(Y=1)\\sim \\mathrm{Laplace}(0,1/\\sqrt{2})$。\n\nF. 令 $Y\\sim \\mathrm{Bernoulli}(0.5)$ 且 $X\\sim \\mathcal{N}(0,1)$，并且 $X$ 和 $Y$ 独立。\n\n选择所有适用项。", "solution": "我们发现问题陈述是有效的。它在概率论及其在生物信息学中的应用方面具有科学依据，提法恰当且客观。这是一个标准的练习，用于说明不相关性和独立性之间的区别。我将继续解答。\n\n目标是找出随机变量对 $(X,Y)$ 的所有构造，使其满足以下两个条件：\n1.  $X$ 和 $Y$ 不独立。这意味着给定 $Y$ 时 $X$ 的条件分布取决于 $Y$ 的值。\n2.  $X$ 和 $Y$ 之间的协方差为零。即 $\\operatorname{Cov}(X,Y) = 0$。\n\n我们回顾协方差的定义：$\\operatorname{Cov}(X,Y) = \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y]$。计算这些期望的一个强大工具是全期望定律：对于任意随机变量 $Z$ 和 $Y$，$\\mathbb{E}[Z] = \\mathbb{E}[\\mathbb{E}[Z|Y]]$。\n\n一种能导致零协方差但存在依赖关系的通用结构是：当条件期望 $\\mathbb{E}[X|Y]$ 是常数，但给定 $Y$ 的 $X$ 的条件分布 $f_{X|Y}(x|y)$ 关于 $y$ 不是恒定的。如果对于某个常数 $c$，$\\mathbb{E}[X|Y] = c$，那么 $\\mathbb{E}[X] = \\mathbb{E}[\\mathbb{E}[X|Y]] = \\mathbb{E}[c] = c$。于是协方差为 $\\operatorname{Cov}(X,Y) = \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y] = \\mathbb{E}[\\mathbb{E}[XY|Y]] - c\\mathbb{E}[Y] = \\mathbb{E}[Y\\mathbb{E}[X|Y]] - c\\mathbb{E}[Y] = \\mathbb{E}[Yc] - c\\mathbb{E}[Y] = c\\mathbb{E}[Y] - c\\mathbb{E}[Y] = 0$。\n\n我们现在将根据这些标准分析每个选项。\n\n### 选项 A\n**构造**：令 $Y\\sim \\mathrm{Bernoulli}(0.5)$，因此 $Y$ 在 $\\{0, 1\\}$ 中取值，每个值的概率为 $0.5$。令 $W\\sim \\mathcal{N}(0,1)$ 为一个独立的随机变量。定义 $X=Y\\,W$。\n\n**1. 独立性**：\n我们考察给定 $Y$ 时 $X$ 的条件分布。\n- 如果 $Y=0$，那么 $X = 0 \\cdot W = 0$。所以 $P(X=0|Y=0) = 1$。这是一个在 $0$ 处的点质量分布。\n- 如果 $Y=1$，那么 $X = 1 \\cdot W = W$。所以 $X|Y=1 \\sim \\mathcal{N}(0,1)$。\n由于 $Y=0$ 时 $X$ 的条件分布与 $Y=1$ 时的条件分布不同，所以 $X$ 和 $Y$ **不独立**。\n\n**2. 协方差**：\n- 我们首先计算期望值。\n- $\\mathbb{E}[Y] = 0 \\cdot P(Y=0) + 1 \\cdot P(Y=1) = 0 \\cdot 0.5 + 1 \\cdot 0.5 = 0.5$。\n- $\\mathbb{E}[W] = 0$，因为 $W \\sim \\mathcal{N}(0,1)$。\n- $\\mathbb{E}[X] = \\mathbb{E}[YW]$。由于 $Y$ 和 $W$ 独立，$\\mathbb{E}[YW] = \\mathbb{E}[Y]\\mathbb{E}[W] = 0.5 \\cdot 0 = 0$。\n- $\\mathbb{E}[XY] = \\mathbb{E}[(YW)Y] = \\mathbb{E}[Y^2W]$。由于 $Y$ 是一个伯努利随机变量，所以 $Y^2=Y$。因此，$\\mathbb{E}[Y^2W] = \\mathbb{E}[YW]$。如前所算，$\\mathbb{E}[YW]=0$。\n- $\\operatorname{Cov}(X,Y) = \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y] = 0 - (0)(0.5) = 0$。\n\n两个条件都满足。\n**结论：正确。**\n\n### 选项 B\n**构造**：令 $Y$ 在 $\\{-1,1\\}$ 中取值，且 $P(Y=-1)=P(Y=1)=0.5$。令 $W\\sim \\mathcal{N}(0,1)$，与 $Y$ 独立。定义 $X=Y\\,W$。\n\n**1. 独立性**：\n我们考察给定 $Y$ 时 $X$ 的条件分布。\n- 如果 $Y=1$，那么 $X = 1 \\cdot W = W$，所以 $X|Y=1 \\sim \\mathcal{N}(0,1)$。\n- 如果 $Y=-1$，那么 $X = -1 \\cdot W = -W$。由于 $W$ 服从关于 $0$ 对称的标准正态分布，$-W$ 也服从标准正态分布。所以 $X|Y=-1 \\sim \\mathcal{N}(0,1)$。\n给定 $Y$ 的 $X$ 的条件分布都是 $\\mathcal{N}(0,1)$，无论 $Y$ 的取值如何。因此，$X$ 和 $Y$ 是**独立的**。这违反了研究的主要条件。\n\n**2. 协方差**：\n对于独立的随机变量，协方差总是 $0$。\n\n这个构造不满足 $X$ 和 $Y$ 不独立的要求。\n**结论：错误。**\n\n### 选项 C\n**构造**：令 $Y\\sim \\mathrm{Bernoulli}(0.5)$ 且 $W\\sim \\mathcal{N}(0,1)$ 独立。定义 $X=W+Y$。\n\n**1. 独立性**：\n- 如果 $Y=0$，那么 $X = W \\sim \\mathcal{N}(0,1)$。\n- 如果 $Y=1$，那么 $X = W+1 \\sim \\mathcal{N}(1,1)$。\n条件分布不同，所以 $X$ 和 $Y$ **不独立**。\n\n**2. 协方差**：\n- $\\mathbb{E}[Y] = 0.5$。\n- $\\mathbb{E}[X] = \\mathbb{E}[W+Y] = \\mathbb{E}[W] + \\mathbb{E}[Y] = 0 + 0.5 = 0.5$。\n- $\\mathbb{E}[XY] = \\mathbb{E}[(W+Y)Y] = \\mathbb{E}[WY + Y^2] = \\mathbb{E}[WY] + \\mathbb{E}[Y^2]$。\n- 由于 $W$ 和 $Y$ 独立，$\\mathbb{E}[WY]=\\mathbb{E}[W]\\mathbb{E}[Y] = 0 \\cdot 0.5 = 0$。\n- 对于 $Y \\sim \\mathrm{Bernoulli}(p)$，$\\mathbb{E}[Y^2] = p$。这里 $p=0.5$，所以 $\\mathbb{E}[Y^2]=0.5$。\n- $\\mathbb{E}[XY] = 0 + 0.5 = 0.5$。\n- $\\operatorname{Cov}(X,Y) = \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y] = 0.5 - (0.5)(0.5) = 0.5 - 0.25 = 0.25$。\n协方差不为零。\n\n这个构造不满足零协方差的要求。\n**结论：错误。**\n\n### 选项 D\n**构造**：令 $Y\\sim \\mathrm{Bernoulli}(0.5)$。在给定 $Y$ 的条件下，定义 $X\\mid(Y=0)\\sim \\mathcal{N}(0,1)$ 和 $X\\mid(Y=1)\\sim \\mathcal{N}(0,4)$。\n\n**1. 独立性**：\n给定 $Y=0$ 时 $X$ 的条件分布是 $\\mathcal{N}(0,1)$，而给定 $Y=1$ 时 $X$ 的条件分布是 $\\mathcal{N}(0,4)$。由于这些分布不同（它们的方差不同），$X$ 和 $Y$ **不独立**。\n\n**2. 协方差**：\n- $\\mathbb{E}[Y] = 0.5$。\n- 我们使用全期望定律来求 $\\mathbb{E}[X]$：$\\mathbb{E}[X] = \\mathbb{E}[\\mathbb{E}[X|Y]]$。\n- $\\mathbb{E}[X|Y=0] = 0$（$\\mathcal{N}(0,1)$ 的均值）。\n- $\\mathbb{E}[X|Y=1] = 0$（$\\mathcal{N}(0,4)$ 的均值）。\n- 随机变量 $\\mathbb{E}[X|Y]$ 是常数 $0$。因此 $\\mathbb{E}[X] = \\mathbb{E}[0] = 0$。\n- 我们使用全期望定律来求 $\\mathbb{E}[XY]$：$\\mathbb{E}[XY] = \\mathbb{E}[\\mathbb{E}[XY|Y]] = \\mathbb{E}[Y \\mathbb{E}[X|Y]]$。\n- 由于 $\\mathbb{E}[X|Y]=0$，我们有 $\\mathbb{E}[XY] = \\mathbb{E}[Y \\cdot 0] = \\mathbb{E}[0] = 0$。\n- $\\operatorname{Cov}(X,Y) = \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y] = 0 - (0)(0.5) = 0$。\n\n两个条件都满足。\n**结论：正确。**\n\n### 选项 E\n**构造**：令 $Y\\sim \\mathrm{Bernoulli}(0.5)$。在给定 $Y$ 的条件下，定义 $X\\mid(Y=0)\\sim \\mathcal{N}(0,1)$ 和 $X\\mid(Y=1)\\sim \\mathrm{Laplace}(0,1/\\sqrt{2})$。\n\n**1. 独立性**：\n当 $Y=0$ 时 $X$ 的条件分布是正态分布，而当 $Y=1$ 时是拉普拉斯分布。这些是根本不同的分布族。因此，$X$ 和 $Y$ **不独立**。\n\n**2. 协方差**：\n- $\\mathbb{E}[Y] = 0.5$。\n- 我们求 $\\mathbb{E}[X]$:\n- $\\mathbb{E}[X|Y=0] = 0$（$\\mathcal{N}(0,1)$ 的均值）。\n- 拉普拉斯分布 $\\mathrm{Laplace}(\\mu, b)$ 的均值为 $\\mu$。因此，对于 $\\mathrm{Laplace}(0,1/\\sqrt{2})$，$\\mathbb{E}[X|Y=1] = 0$。\n- 随机变量 $\\mathbb{E}[X|Y]$ 是常数 $0$。因此 $\\mathbb{E}[X] = \\mathbb{E}[0] = 0$。\n- 我们求 $\\mathbb{E}[XY]$:\n- 与选项 D 中类似，$\\mathbb{E}[XY] = \\mathbb{E}[Y \\mathbb{E}[X|Y]] = \\mathbb{E}[Y \\cdot 0] = 0$。\n- $\\operatorname{Cov}(X,Y) = \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y] = 0 - (0)(0.5) = 0$。\n\n两个条件都满足。\n**结论：正确。**\n\n### 选项 F\n**构造**：令 $Y\\sim \\mathrm{Bernoulli}(0.5)$ 且 $X\\sim \\mathcal{N}(0,1)$，并且 $X$ 和 $Y$ 独立。\n\n**1. 独立性**：\n问题陈述明确断言 $X$ 和 $Y$ 是独立的。这违反了研究的目标，即找到一个 $X$ 和 $Y$ **不**独立的情况。\n\n这个构造不满足非独立性的要求。\n**结论：错误。**", "answer": "$$\\boxed{ADE}$$", "id": "4598782"}, {"introduction": "在对生物数据进行建模时，我们不仅要估计模型参数，还要量化这些估计的不确定性。Fisher信息和Cramér-Rao下界是频率学派统计推断中评估估计量性能的核心工具。本练习以单细胞转录组学中的UMI计数为背景，指导您从第一性原理出发，为泊松分布的率参数推导Fisher信息，并确定任何无偏估计量方差的理论下限 [@problem_id:4598809]。这项实践将帮助您掌握如何运用似然理论来评估统计模型在生物学背景下的理论极限。", "problem": "在使用唯一分子标识符 (UMI) 标记的单细胞转录组学中，对于一个低表达基因，每个细胞观察到的 UMI 计数可以被建模为源于独立的分子捕获事件。假设在 $n$ 个独立细胞中，特定基因的 UMI 计数 $X_{1}, X_{2}, \\ldots, X_{n}$ 被建模为独立同分布的随机变量，服从未知的速率参数为 $\\lambda>0$ 的泊松分布，即对于每个 $i \\in \\{1,2,\\ldots,n\\}$，$X_{i} \\sim \\mathrm{Poisson}(\\lambda)$，取值于 $\\{0,1,2,\\ldots\\}$。\n\n仅从独立泊松观测值的联合似然以及分数函数和费雪信息的核心定义出发，根据这 $n$ 个观测值推导 $\\lambda$ 的分数函数和关于 $\\lambda$ 的费雪信息。然后，在标准正则性条件下，使用克拉默-拉奥不等式，给出根据 $X_{1}, X_{2}, \\ldots, X_{n}$ 构建的任何关于 $\\lambda$ 的无偏估计量的方差的克拉默-拉奥下界。\n\n请用一个包含 $n$ 和 $\\lambda$ 的封闭形式解析表达式来表示你的最终答案。不需要进行数值舍入，也不涉及物理单位。", "solution": "该问题要求基于 $n$ 个独立同分布 (i.i.d.) 观测值的样本，推导泊松分布速率参数 $\\lambda$ 的分数函数、费雪信息以及克拉默-拉奥下界。\n\n首先，我们验证问题陈述的有效性。\n**第一步：提取已知条件**\n-   数据由 $n$ 个独立观测值 $X_{1}, X_{2}, \\ldots, X_{n}$ 组成。\n-   这些观测值被建模为独立同分布的随机变量。\n-   每个观测值的分布是泊松分布，其未知速率参数为 $\\lambda > 0$，记为 $X_{i} \\sim \\mathrm{Poisson}(\\lambda)$。\n-   任务是推导 $\\lambda$ 的分数函数、关于 $\\lambda$ 的费雪信息，以及 $\\lambda$ 的任何无偏估计量方差的克拉默-拉奥下界。\n-   推导必须从联合似然和核心定义出发。\n-   假定克拉默-拉奥不等式的标准正则性条件成立。\n\n**第二步：使用提取的已知条件进行验证**\n-   **科学依据充分：** 使用泊松分布对计数数据（例如单细胞转录组学中的UMI计数）进行建模是一种标准的、成熟的统计实践。该问题在科学上是合理的。\n-   **适定性：** 该问题在数学上是适定的。它明确了统计模型（独立同分布的泊松分布）、目标参数（$\\lambda$）以及需要推导的量（分数函数、费雪信息、克拉默-拉奥下界）。泊松分布属于指数族，满足克拉默-拉奥不等式所需的正则性条件。因此，存在唯一且有意义的解。\n-   **客观性：** 该问题使用精确、正式、客观的语言陈述，没有歧义或主观性陈述。\n\n**第三步：结论与行动**\n该问题被认为是**有效的**，因为它科学依据充分、适定且客观。没有可识别的缺陷。我们可以继续进行解答。\n\n服从参数为 $\\lambda$ 的泊松分布的单个随机变量 $X_i$ 的概率质量函数 (PMF) 为：\n$$P(X_i=x_i; \\lambda) = \\frac{\\lambda^{x_i} \\exp(-\\lambda)}{x_i!}$$\n其中 $x_i \\in \\{0, 1, 2, \\ldots\\}$。\n\n鉴于 $n$ 个观测值 $X_1, X_2, \\ldots, X_n$ 是独立同分布的，观测数据 $\\mathbf{x} = (x_1, x_2, \\ldots, x_n)$ 的联合似然函数 $L(\\lambda | \\mathbf{x})$ 是各个概率质量函数的乘积：\n$$L(\\lambda | \\mathbf{x}) = \\prod_{i=1}^{n} P(X_i = x_i; \\lambda) = \\prod_{i=1}^{n} \\frac{\\lambda^{x_i} \\exp(-\\lambda)}{x_i!} = \\frac{\\lambda^{\\sum_{i=1}^{n} x_i} \\exp(-n\\lambda)}{\\prod_{i=1}^{n} x_i!}$$\n\n为了数学上的便利，我们使用对数似然函数 $\\ell(\\lambda | \\mathbf{x}) = \\ln(L(\\lambda | \\mathbf{x}))$。\n$$\\ell(\\lambda | \\mathbf{x}) = \\ln\\left(\\frac{\\lambda^{\\sum_{i=1}^{n} x_i} \\exp(-n\\lambda)}{\\prod_{i=1}^{n} x_i!}\\right)$$\n$$\\ell(\\lambda | \\mathbf{x}) = \\ln\\left(\\lambda^{\\sum_{i=1}^{n} x_i}\\right) + \\ln(\\exp(-n\\lambda)) - \\ln\\left(\\prod_{i=1}^{n} x_i!\\right)$$\n$$\\ell(\\lambda | \\mathbf{x}) = \\left(\\sum_{i=1}^{n} x_i\\right) \\ln(\\lambda) - n\\lambda - \\sum_{i=1}^{n} \\ln(x_i!)$$\n\n参数 $\\lambda$ 的分数函数，记为 $S(\\lambda)$，是对数似然函数关于 $\\lambda$ 的一阶导数。\n$$S(\\lambda) = \\frac{\\partial \\ell(\\lambda | \\mathbf{x})}{\\partial \\lambda} = \\frac{\\partial}{\\partial \\lambda} \\left[ \\left(\\sum_{i=1}^{n} x_i\\right) \\ln(\\lambda) - n\\lambda - \\sum_{i=1}^{n} \\ln(x_i!) \\right]$$\n项 $\\sum_{i=1}^{n} \\ln(x_i!)$ 不依赖于 $\\lambda$，因此其导数为 $0$。\n$$S(\\lambda) = \\frac{1}{\\lambda} \\left(\\sum_{i=1}^{n} x_i\\right) - n$$\n这是样本大小为 $n$ 的分数函数。\n\n$n$ 个观测值样本的费雪信息 $I_n(\\lambda)$ 可以计算为对数似然函数关于 $\\lambda$ 的二阶导数的负期望值。\n$$I_n(\\lambda) = -E\\left[ \\frac{\\partial^2 \\ell(\\lambda | \\mathbf{X})}{\\partial \\lambda^2} \\right]$$\n首先，我们计算二阶导数：\n$$\\frac{\\partial^2 \\ell(\\lambda | \\mathbf{x})}{\\partial \\lambda^2} = \\frac{\\partial}{\\partial \\lambda} S(\\lambda) = \\frac{\\partial}{\\partial \\lambda} \\left( \\frac{1}{\\lambda} \\sum_{i=1}^{n} x_i - n \\right) = -\\frac{1}{\\lambda^2} \\sum_{i=1}^{n} x_i$$\n接下来，我们对该表达式求期望，其中观测值 $x_i$ 现在被视为随机变量 $X_i$：\n$$E\\left[ \\frac{\\partial^2 \\ell(\\lambda | \\mathbf{X})}{\\partial \\lambda^2} \\right] = E\\left[ -\\frac{1}{\\lambda^2} \\sum_{i=1}^{n} X_i \\right]$$\n利用期望的线性性质，我们有：\n$$E\\left[ \\frac{\\partial^2 \\ell(\\lambda | \\mathbf{X})}{\\partial \\lambda^2} \\right] = -\\frac{1}{\\lambda^2} E\\left[ \\sum_{i=1}^{n} X_i \\right] = -\\frac{1}{\\lambda^2} \\sum_{i=1}^{n} E[X_i]$$\n对于服从泊松分布的随机变量 $X_i \\sim \\mathrm{Poisson}(\\lambda)$，其期望为 $E[X_i] = \\lambda$。\n$$E\\left[ \\frac{\\partial^2 \\ell(\\lambda | \\mathbf{X})}{\\partial \\lambda^2} \\right] = -\\frac{1}{\\lambda^2} \\sum_{i=1}^{n} \\lambda = -\\frac{n\\lambda}{\\lambda^2} = -\\frac{n}{\\lambda}$$\n最后，样本大小为 $n$ 的费雪信息是：\n$$I_n(\\lambda) = -E\\left[ \\frac{\\partial^2 \\ell(\\lambda | \\mathbf{X})}{\\partial \\lambda^2} \\right] = -\\left(-\\frac{n}{\\lambda}\\right) = \\frac{n}{\\lambda}$$\n\n克拉默-拉奥不等式指出，对于参数 $\\lambda$ 的任何无偏估计量 $\\hat{\\lambda}$，在满足某些正则性条件的情况下，其方差的下界是费雪信息的倒数。\n$$\\mathrm{Var}(\\hat{\\lambda}) \\ge \\frac{1}{I_n(\\lambda)}$$\n克拉默-拉奥下界 (CRLB) 就是这个下界本身。代入我们推导出的费雪信息 $I_n(\\lambda)$，我们得到 $\\lambda$ 的任何无偏估计量方差的克拉默-拉奥下界：\n$$\\mathrm{CRLB}(\\lambda) = \\frac{1}{I_n(\\lambda)} = \\frac{1}{n/\\lambda} = \\frac{\\lambda}{n}$$\n这是基于 $n$ 个独立同分布的泊松观测值得出的 $\\lambda$ 的任何无偏估计量的最小可能方差。", "answer": "$$\\boxed{\\frac{\\lambda}{n}}$$", "id": "4598809"}, {"introduction": "贝叶斯方法为处理生物数据中的不确定性和复杂性提供了强大的框架，而分层模型是其关键组成部分，能够有效捕捉样本间的异质性。本练习包含两个独立的、在分子检测中常见的场景：利用Beta-二项分布对变异等位基因计数建模，以及利用正态-逆伽马模型分析qPCR表达数据。您将通过推导共轭后验分布和设计吉布斯采样器（Gibbs sampler），来亲手实践贝叶斯推断的核心计算过程 [@problem_id:4598789]，从而掌握这一在现代生物信息学和医学数据分析中不可或缺的技能。", "problem": "一个临床生物信息学小组正在使用概率分层模型对分子检测流程的两个独立组分进行建模，以便量化不确定性并将其传播到下游的医疗决策中。\n\nA部分（用于过度离散变异计数的Beta-二项模型）。对于由 $i \\in \\{1,\\dots,I\\}$ 索引的 $I$ 个独立样本，令 $X_i$ 表示在样本 $i$ 的 $M_i$ 个总读数中，在预先指定的基因座上支持某个变异的测序读数数量。为了捕捉真实变异流行率的样本间异质性，假设采用以下分层模型：对于每个 $i$，给定一个潜在流行率参数 $\\theta_i \\in (0,1)$，$X_i \\mid \\theta_i \\sim \\mathrm{Binomial}(M_i,\\theta_i)$，并且 $\\theta_i \\sim \\mathrm{Beta}(\\alpha,\\beta)$，其中超参数 $\\alpha > 0$ 和 $\\beta > 0$ 是固定的已知值。在一项包含 $I=5$ 个样本的研究中，实现的数据为 $(X_1,M_1)=(27,50)$、$(X_2,M_2)=(45,80)$、$(X_3,M_3)=(38,60)$、$(X_4,M_4)=(22,40)$ 和 $(X_5,M_5)=(40,75)$，超参数为 $(\\alpha,\\beta)=(2.5,3.5)$。\n\n任务A。从Bayes法则以及Beta分布和二项分布的概率密度函数出发，推导给定所有其他未知量和所有数据时每个 $\\theta_i$ 的全条件分布，并证明该条件分布是共轭的。然后，使用这些全条件分布来指定一个有效的Gibbs抽样方案，该方案以所述模型下的联合后验 $(\\theta_1,\\dots,\\theta_I)$ 为目标。将Gibbs采样器表示为一个条件抽样序列，每个抽样都由一个命名分布及其参数指定，参数用 $(\\alpha,\\beta)$ 和观测到的 $(X_i,M_i)$ 表示。\n\nB部分（用于定量聚合酶链反应（qPCR）对数表达的方差未知的Normal-Inverse-Gamma模型）。对于在固定条件下通过定量聚合酶链反应（qPCR）对单个基因进行的 $n$ 次技术重复测量，令 $y_1,\\dots,y_n$ 表示对数尺度的表达测量值。假设抽样模型为 $y_i \\mid \\mu,\\sigma^2 \\overset{\\mathrm{iid}}{\\sim} \\mathcal{N}(\\mu,\\sigma^2)$，对于所有 $i \\in \\{1,\\dots,n\\}$，其中 $\\mu$ 和 $\\sigma^2$ 均为未知。设置共轭Normal–Inverse-Gamma先验\n- $\\mu \\mid \\sigma^2 \\sim \\mathcal{N}(m_0,\\sigma^2/\\kappa_0)$，其中 $m_0 \\in \\mathbb{R}$ 且 $\\kappa_0 > 0$，\n- $\\sigma^2 \\sim \\mathrm{Inverse\\mbox{-}Gamma}(a_0,b_0)$，其中形状参数 $a_0>0$ 且尺度参数 $b_0>0$，密度为 $p(\\sigma^2) = \\dfrac{b_0^{a_0}}{\\Gamma(a_0)} (\\sigma^2)^{-a_0-1} \\exp\\!\\big(-b_0/\\sigma^2\\big)$，对于 $\\sigma^2>0$。\n\n在一项有 $n=6$ 次重复的实验中，实现的数据为 $y=(1.2,\\,0.9,\\,1.5,\\,1.1,\\,1.3,\\,0.8)$，先验超参数为 $(m_0,\\kappa_0,a_0,b_0)=(1.0,\\,2.0,\\,3.0,\\,0.5)$。\n\n任务B。从Bayes法则以及Normal分布和Inverse-Gamma分布的概率密度函数出发，推导全条件分布 $p(\\mu \\mid \\sigma^2,y)$ 和 $p(\\sigma^2 \\mid \\mu,y)$，并展示一个从这两个条件分布中交替抽样的Gibbs抽样方案。然后，解析地积分以获得闭式后验超参数，并计算在所述先验和数据下的后验均值 $\\mathbb{E}[\\sigma^2 \\mid y]$。将您的 $\\mathbb{E}[\\sigma^2 \\mid y]$ 数值答案四舍五入到四位有效数字。最终答案必须是这个四舍五入后的单一数字，不带单位。", "solution": "该问题提出了Bayesian分层建模中的两个独立任务，在生物信息学和医疗数据分析的背景下，这两个任务都是标准的且是良定的。模型、数据和任务都具有科学依据，数学上一致，并包含了完整解决方案所需的所有信息。因此，该问题被认为是有效的。\n\nA部分：Beta-二项模型\n\n模型是为 $I$ 个独立样本定义的。对于每个样本 $i \\in \\{1, \\dots, I\\}$：\n在 $M_i$ 个总读数中观测到的变异计数 $X_i$ 的似然由一个Binomial分布给出，以潜在流行率参数 $\\theta_i$ 为条件：\n$$X_i \\mid \\theta_i \\sim \\mathrm{Binomial}(M_i, \\theta_i)$$\n潜在流行率 $\\theta_i$ 的先验分布是一个Beta分布：\n$$\\theta_i \\sim \\mathrm{Beta}(\\alpha, \\beta)$$\n样本是独立的，意味着 $\\boldsymbol{\\theta} = (\\theta_1, \\dots, \\theta_I)$ 的联合先验是 $p(\\boldsymbol{\\theta}) = \\prod_{i=1}^I p(\\theta_i)$，而给定 $\\boldsymbol{\\theta}$ 的 $\\mathbf{X} = (X_1, \\dots, X_I)$ 的联合似然是 $p(\\mathbf{X} \\mid \\boldsymbol{\\theta}, \\mathbf{M}) = \\prod_{i=1}^I p(X_i \\mid \\theta_i, M_i)$。\n\n任务是找到每个 $\\theta_i$ 的全条件分布，即给定所有其他参数和所有数据下 $\\theta_i$ 的分布，记为 $p(\\theta_i \\mid \\boldsymbol{\\theta}_{-i}, \\mathbf{X}, \\mathbf{M})$，其中 $\\boldsymbol{\\theta}_{-i} = (\\theta_1, \\dots, \\theta_{i-1}, \\theta_{i+1}, \\dots, \\theta_I)$。\n\n根据Bayes法则，全条件分布与所有变量的联合分布成正比：\n$$p(\\theta_i \\mid \\boldsymbol{\\theta}_{-i}, \\mathbf{X}, \\mathbf{M}) \\propto p(\\boldsymbol{\\theta}, \\mathbf{X} \\mid \\mathbf{M})$$\n联合分布由似然和先验的乘积给出：\n$$p(\\boldsymbol{\\theta}, \\mathbf{X} \\mid \\mathbf{M}) = p(\\mathbf{X} \\mid \\boldsymbol{\\theta}, \\mathbf{M}) p(\\boldsymbol{\\theta}) = \\left( \\prod_{j=1}^I p(X_j \\mid \\theta_j, M_j) \\right) \\left( \\prod_{j=1}^I p(\\theta_j \\mid \\alpha, \\beta) \\right)$$\n为了找到 $\\theta_i$ 的全条件分布，我们可以将所有不依赖于 $\\theta_i$ 的其他项视为比例常数的一部分：\n$$p(\\theta_i \\mid \\boldsymbol{\\theta}_{-i}, \\mathbf{X}, \\mathbf{M}) \\propto p(X_i \\mid \\theta_i, M_i) p(\\theta_i \\mid \\alpha, \\beta) \\times \\left( \\prod_{j \\neq i} p(X_j \\mid \\theta_j, M_j) p(\\theta_j \\mid \\alpha, \\beta) \\right)$$\n$$p(\\theta_i \\mid \\boldsymbol{\\theta}_{-i}, \\mathbf{X}, \\mathbf{M}) \\propto p(X_i \\mid \\theta_i, M_i) p(\\theta_i \\mid \\alpha, \\beta)$$\n这种简化源于模型的条件独立结构：给定 $\\theta_i$，$X_i$ 与所有其他 $X_j$ 和 $\\theta_j$（对于 $j \\neq i$）是独立的，并且 $\\theta_i$ 上的先验是独立的。因此，$\\theta_i$ 的全条件分布仅依赖于其对应的数据 $(X_i, M_i)$ 及其先验超参数 $(\\alpha, \\beta)$。\n\nBinomial似然的概率质量函数是 $p(X_i \\mid \\theta_i, M_i) = \\binom{M_i}{X_i} \\theta_i^{X_i} (1-\\theta_i)^{M_i-X_i}$。作为 $\\theta_i$ 的函数，它正比于：\n$$p(X_i \\mid \\theta_i, M_i) \\propto \\theta_i^{X_i} (1-\\theta_i)^{M_i-X_i}$$\nBeta先验的概率密度函数是 $p(\\theta_i \\mid \\alpha, \\beta) = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\theta_i^{\\alpha-1} (1-\\theta_i)^{\\beta-1}$。作为 $\\theta_i$ 的函数，它正比于：\n$$p(\\theta_i \\mid \\alpha, \\beta) \\propto \\theta_i^{\\alpha-1} (1-\\theta_i)^{\\beta-1}$$\n将似然核与先验核相乘：\n$$p(\\theta_i \\mid X_i, M_i, \\alpha, \\beta) \\propto \\left( \\theta_i^{X_i} (1-\\theta_i)^{M_i-X_i} \\right) \\times \\left( \\theta_i^{\\alpha-1} (1-\\theta_i)^{\\beta-1} \\right)$$\n$$p(\\theta_i \\mid X_i, M_i, \\alpha, \\beta) \\propto \\theta_i^{X_i + \\alpha - 1} (1-\\theta_i)^{M_i - X_i + \\beta - 1}$$\n这是具有更新参数的Beta分布的核。具体来说，$\\theta_i$ 的全条件分布（在这种情况下即边缘后验分布）是：\n$$\\theta_i \\mid X_i, M_i, \\alpha, \\beta \\sim \\mathrm{Beta}(X_i + \\alpha, M_i - X_i + \\beta)$$\n由于后验分布（Beta）与先验分布（Beta）属于同一族，因此Beta先验是Binomial似然的共轭先验。这一点已通过推导得到证明。\n\n针对联合后验 $p(\\boldsymbol{\\theta} \\mid \\mathbf{X}, \\mathbf{M})$ 的Gibbs抽样方案包括从其全条件分布中迭代地抽取每个参数。由于每个 $\\theta_i$ 的全条件分布独立于所有其他 $\\theta_j$（对于 $j \\neq i$），因此Gibbs采样器特别简单。在每次迭代中，我们可以并行或顺序地抽取所有 $\\theta_i$ 的值。一个有效的方案如下：\n\n初始化 $\\boldsymbol{\\theta}^{(0)} = (\\theta_1^{(0)}, \\dots, \\theta_I^{(0)})$。对于迭代 $t=1, 2, \\dots$：\n1. 从 $\\mathrm{Beta}(X_1 + \\alpha, M_1 - X_1 + \\beta)$ 中抽样 $\\theta_1^{(t)}$\n2. 从 $\\mathrm{Beta}(X_2 + \\alpha, M_2 - X_2 + \\beta)$ 中抽样 $\\theta_2^{(t)}$\n3. $\\dots$\n4. 从 $\\mathrm{Beta}(X_I + \\alpha, M_I - X_I + \\beta)$ 中抽样 $\\theta_I^{(t)}$\n\n使用给定的数据和超参数 $(X_i, M_i)$ 和 $(\\alpha, \\beta)=(2.5, 3.5)$：\n\\begin{itemize}\n    \\item 从 $\\mathrm{Beta}(27 + 2.5, 50 - 27 + 3.5) = \\mathrm{Beta}(29.5, 26.5)$ 中抽样 $\\theta_1 \\mid \\text{data}$\n    \\item 从 $\\mathrm{Beta}(45 + 2.5, 80 - 45 + 3.5) = \\mathrm{Beta}(47.5, 38.5)$ 中抽样 $\\theta_2 \\mid \\text{data}$\n    \\item 从 $\\mathrm{Beta}(38 + 2.5, 60 - 38 + 3.5) = \\mathrm{Beta}(40.5, 25.5)$ 中抽样 $\\theta_3 \\mid \\text{data}$\n    \\item 从 $\\mathrm{Beta}(22 + 2.5, 40 - 22 + 3.5) = \\mathrm{Beta}(24.5, 21.5)$ 中抽样 $\\theta_4 \\mid \\text{data}$\n    \\item 从 $\\mathrm{Beta}(40 + 2.5, 75 - 40 + 3.5) = \\mathrm{Beta}(42.5, 38.5)$ 中抽样 $\\theta_5 \\mid \\text{data}$\n\\end{itemize}\n\nB部分：Normal-Inverse-Gamma模型\n\n对于 $n$ 个对数表达测量值 $y=(y_1, \\dots, y_n)$ 的模型是：\n似然：$y_i \\mid \\mu, \\sigma^2 \\overset{\\mathrm{iid}}{\\sim} \\mathcal{N}(\\mu, \\sigma^2)$\n先验：$p(\\mu, \\sigma^2) = p(\\mu \\mid \\sigma^2) p(\\sigma^2)$，其中\n    $\\mu \\mid \\sigma^2 \\sim \\mathcal{N}(m_0, \\sigma^2/\\kappa_0)$\n    $\\sigma^2 \\sim \\mathrm{Inverse\\mbox{-}Gamma}(a_0, b_0)$\n\n任务B包括推导全条件分布，指定一个Gibbs采样器，并计算 $\\sigma^2$ 的后验均值。\n\n$\\mu$ 的全条件分布的推导：\n$p(\\mu \\mid \\sigma^2, y) \\propto p(y \\mid \\mu, \\sigma^2) p(\\mu \\mid \\sigma^2)$。\n似然核是 $p(y \\mid \\mu, \\sigma^2) \\propto \\exp\\left(-\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\mu)^2\\right)$。\n先验核是 $p(\\mu \\mid \\sigma^2) \\propto \\exp\\left(-\\frac{1}{2(\\sigma^2/\\kappa_0)} (\\mu - m_0)^2\\right) = \\exp\\left(-\\frac{\\kappa_0}{2\\sigma^2} (\\mu - m_0)^2\\right)$。\n$\\mu$ 的后验核与乘积成正比，因此我们将指数中的项相加：\n$p(\\mu \\mid \\sigma^2, y) \\propto \\exp\\left(-\\frac{1}{2\\sigma^2} \\left[ \\sum_{i=1}^n (y_i - \\mu)^2 + \\kappa_0(\\mu - m_0)^2 \\right] \\right)$。\n方括号中的项是关于 $\\mu$ 的二次式：\n$\\sum(y_i^2 - 2y_i\\mu + \\mu^2) + \\kappa_0(\\mu^2 - 2\\mu m_0 + m_0^2) = (n+\\kappa_0)\\mu^2 - 2(n\\bar{y} + \\kappa_0 m_0)\\mu + C$，其中 C 不依赖于 $\\mu$。\n对 $\\mu$ 进行配方，该表达式揭示了一个Normal分布核。后验分布是 $\\mu \\mid \\sigma^2, y \\sim \\mathcal{N}(m_n, \\sigma^2/\\kappa_n)$，其参数为：\n$\\kappa_n = \\kappa_0 + n$\n$m_n = \\frac{\\kappa_0 m_0 + n\\bar{y}}{\\kappa_0 + n}$\n\n$\\sigma^2$ 的全条件分布的推导：\n全条件分布 $p(\\sigma^2 \\mid \\mu, y)$ 与联合后验成正比，在 $\\mu$ 和 $y$ 已知的情况下，我们可以将其视为 $\\sigma^2$ 的函数。联合后验正比于 $p(y \\mid \\mu, \\sigma^2)p(\\mu \\mid \\sigma^2)p(\\sigma^2)$。我们收集所有依赖于 $\\sigma^2$ 的项：\n$p(y \\mid \\mu, \\sigma^2) \\propto (\\sigma^2)^{-n/2} \\exp\\left(-\\frac{1}{2\\sigma^2} \\sum (y_i - \\mu)^2\\right)$\n$p(\\mu \\mid \\sigma^2) \\propto (\\sigma^2/\\kappa_0)^{-1/2} \\exp\\left(-\\frac{\\kappa_0}{2\\sigma^2} (\\mu-m_0)^2\\right) \\propto (\\sigma^2)^{-1/2} \\exp\\left(-\\frac{\\kappa_0}{2\\sigma^2} (\\mu-m_0)^2\\right)$\n$p(\\sigma^2) \\propto (\\sigma^2)^{-a_0-1} \\exp\\left(-\\frac{b_0}{\\sigma^2}\\right)$\n将它们相乘：\n$p(\\sigma^2 \\mid \\mu, y) \\propto (\\sigma^2)^{-(a_0 + n/2 + 1/2) - 1} \\exp\\left( -\\frac{1}{\\sigma^2} \\left[ b_0 + \\frac{1}{2}\\sum (y_i - \\mu)^2 + \\frac{\\kappa_0}{2}(\\mu - m_0)^2 \\right] \\right)$。\n这正是Inverse-Gamma分布的核，因此 $\\sigma^2$ 的全条件分布是 $\\mathrm{IG}(a_n(\\mu), b_n(\\mu))$，其参数为：\n$a_n(\\mu) = a_0 + \\frac{n+1}{2}$\n$b_n(\\mu) = b_0 + \\frac{1}{2}\\sum_{i=1}^n(y_i - \\mu)^2 + \\frac{\\kappa_0}{2}(\\mu - m_0)^2$\n\nGibbs采样器规格：\n一个有效的Gibbs采样器通过在每次迭代中交替从这两个全条件分布中抽样来生成联合后验分布的样本。\n初始化 $\\mu^{(0)}$ 和 $\\sigma^{2,(0)}$。对于迭代 $t=1, 2, \\dots$：\n1. 从 $p(\\mu \\mid \\sigma^{2,(t-1)}, y) = \\mathcal{N}\\left(m_n, \\frac{\\sigma^{2,(t-1)}}{\\kappa_n}\\right)$ 中抽样 $\\mu^{(t)}$，其中 $m_n = \\frac{\\kappa_0 m_0 + n\\bar{y}}{\\kappa_0 + n}$ 且 $\\kappa_n = \\kappa_0 + n$。\n2. 从 $p(\\sigma^2 \\mid \\mu^{(t)}, y) = \\mathrm{Inverse-Gamma}\\left(a_0 + \\frac{n+1}{2}, b_0 + \\frac{1}{2}\\sum_{i=1}^n (y_i - \\mu^{(t)})^2 + \\frac{\\kappa_0}{2}(\\mu^{(t)} - m_0)^2\\right)$ 中抽样 $\\sigma^{2,(t)}$。\n\n$\\mathbb{E}[\\sigma^2 \\mid y]$的计算：\n要计算后验均值 $\\mathbb{E}[\\sigma^2 \\mid y]$，我们需要 $\\sigma^2$ 的边缘后验分布 $p(\\sigma^2 \\mid y)$。通过将联合后验 $p(\\mu, \\sigma^2 \\mid y)$ 对 $\\mu$ 积分，可以得到 $\\sigma^2 \\mid y \\sim \\mathrm{Inverse\\mbox{-}Gamma}(a_n, b_n)$。其后验超参数为：\n$\\kappa_n = \\kappa_0 + n$\n$m_n = \\frac{\\kappa_0 m_0 + n\\bar{y}}{\\kappa_0 + n}$\n$a_n = a_0 + \\frac{n}{2}$\n$b_n = b_0 + \\frac{1}{2}\\left( \\sum_{i=1}^n(y_i-\\bar{y})^2 + \\frac{n\\kappa_0}{n+\\kappa_0}(\\bar{y}-m_0)^2 \\right)$\n$\\sigma^2$ 的边缘后验是 $\\sigma^2 \\mid y \\sim \\mathrm{Inverse\\mbox{-}Gamma}(a_n, b_n)$。一个随机变量 $Z \\sim \\mathrm{Inverse\\mbox{-}Gamma}(a, b)$ 的期望值是 $\\mathbb{E}[Z] = \\frac{b}{a-1}$（对于 $a>1$）。\n因此，$\\mathbb{E}[\\sigma^2 \\mid y] = \\frac{b_n}{a_n - 1}$。\n\n数据：$y=(1.2,\\,0.9,\\,1.5,\\,1.1,\\,1.3,\\,0.8)$, $n=6$。\n超参数：$(m_0,\\kappa_0,a_0,b_0)=(1.0,\\,2.0,\\,3.0,\\,0.5)$。\n首先，计算样本统计量：\n$\\bar{y} = \\frac{1}{6}(1.2+0.9+1.5+1.1+1.3+0.8) = \\frac{6.8}{6} = \\frac{17}{15}$。\n$\\sum_{i=1}^n (y_i - \\bar{y})^2 = \\sum y_i^2 - n\\bar{y}^2$。\n$\\sum y_i^2 = 1.2^2 + 0.9^2 + 1.5^2 + 1.1^2 + 1.3^2 + 0.8^2 = 1.44 + 0.81 + 2.25 + 1.21 + 1.69 + 0.64 = 8.04$。\n$n\\bar{y}^2 = 6 \\left(\\frac{17}{15}\\right)^2 = 6 \\frac{289}{225} = 2 \\frac{289}{75} = \\frac{578}{75}$。\n$\\sum (y_i - \\bar{y})^2 = 8.04 - \\frac{578}{75} = \\frac{804}{100} - \\frac{578}{75} = \\frac{201}{25} - \\frac{578}{75} = \\frac{603 - 578}{75} = \\frac{25}{75} = \\frac{1}{3}$。\n\n接下来，计算后验超参数 $a_n$ 和 $b_n$：\n$a_n = a_0 + \\frac{n}{2} = 3.0 + \\frac{6}{2} = 6$。\n$b_n = b_0 + \\frac{1}{2}\\left( \\sum_{i=1}^n(y_i-\\bar{y})^2 + \\frac{n\\kappa_0}{n+\\kappa_0}(\\bar{y}-m_0)^2 \\right)$。\n括号内的第二项是：\n$\\frac{n\\kappa_0}{n+\\kappa_0}(\\bar{y}-m_0)^2 = \\frac{6 \\times 2.0}{6+2.0} \\left(\\frac{17}{15} - 1.0\\right)^2 = \\frac{12}{8} \\left(\\frac{2}{15}\\right)^2 = \\frac{3}{2} \\times \\frac{4}{225} = \\frac{6}{225} = \\frac{2}{75}$。\n现在，将这些值代入 $b_n$：\n$b_n = 0.5 + \\frac{1}{2} \\left( \\frac{1}{3} + \\frac{2}{75} \\right) = \\frac{1}{2} + \\frac{1}{2} \\left( \\frac{25}{75} + \\frac{2}{75} \\right) = \\frac{1}{2} + \\frac{1}{2} \\left( \\frac{27}{75} \\right) = \\frac{1}{2} + \\frac{27}{150} = \\frac{75}{150} + \\frac{27}{150} = \\frac{102}{150} = \\frac{17}{25} = 0.68$。\n\n最后，计算后验均值：\n$\\mathbb{E}[\\sigma^2 \\mid y] = \\frac{b_n}{a_n - 1} = \\frac{17/25}{6 - 1} = \\frac{17/25}{5} = \\frac{17}{125}$。\n转换为小数：$\\frac{17}{125} = 0.136$。\n四舍五入到四位有效数字得到 $0.1360$。", "answer": "$$\\boxed{0.1360}$$", "id": "4598789"}]}