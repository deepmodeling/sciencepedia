## 引言
在生物信息学和医学数据分析领域，从充满噪声的数据中提取可靠的科学见解是一项核心挑战。经典统计检验，如t检验、[方差分析](@entry_id:275547)（[ANOVA](@entry_id:275547)）和卡方检验，是实现这一目标不可或缺的基石工具，它们为研究者提供了评估假设、量化证据和做出[科学推断](@entry_id:155119)的严谨框架。然而，仅仅知道如何执行这些检验是远远不够的。真正的挑战在于如何根据研究问题和数据特性做出明智的选择，深刻理解其背后的原理与假设，并正确解读其结果。许多研究者常常在[p值](@entry_id:136498)的误区中迷失，或因忽视数据假设而得出脆弱的结论。

本文旨在系统性地解决这些问题，为读者构建一个从理论到实践的完整知识体系。我们将带领您穿越经典统计检验的核心地带，确保您不仅“会用”，更“懂用”。

- 在第一章**“原理与机制”**中，我们将深入剖析[假设检验](@entry_id:142556)的基本框架，澄清关于[p值](@entry_id:136498)和[置信区间](@entry_id:138194)的常见误解，并阐明[t检验](@entry_id:272234)、ANOVA和[卡方检验](@entry_id:174175)等核心方法的内在逻辑和数学基础。
- 随后的第二章**“应用与跨学科连接”**，将通过丰富的临床研究和高通量基因组学实例，生动展示这些理论工具如何被应用于解决现实世界中的复杂问题，包括如何处理配对数据、控制[混杂变量](@entry_id:199777)、分析[交互效应](@entry_id:164533)以及应对RNA-seq计数数据和生存数据等特殊挑战。
- 最后，在**“动手实践”**部分，您将有机会通过解决具体问题来巩固所学知识，将理论真正转化为可操作的技能。

通过本章的学习，您将掌握选择、应用和解读经典统计检验的专业能力，为后续更高级的[统计建模](@entry_id:272466)和数据分析打下坚实的基础。

## 原理与机制

本章旨在深入阐述经典统计检验的基本原理与内在机制。作为“导论”的延续，我们将直接进入假设检验、[参数估计](@entry_id:139349)及模型选择的核心概念，这些是生物信息学和医学数据分析中进行严谨推断的基石。我们将从假设检验的基本框架出发，探讨其关键组成部分，然后转向为不同类型数据（连续与分类）设计的具体检验方法，最后讨论经典方法的局限性以及相应的稳健性与非参数替代方案。

### [假设检验](@entry_id:142556)的基本框架

经典统计检验，通常遵循由 Jerzy Neyman 和 Egon Pearson 奠定的频率学派框架，其核心是一种基于数据的决策规则，旨在评估关于总体参数的某个声明是否可信。

#### 虚无假设与备择假设

一切假设检验都始于两个[互斥](@entry_id:752349)的假设：**虚无假设 (null hypothesis, $H_0$)** 和 **备择假设 (alternative hypothesis, $H_1$)**。虚无假设通常代表一种“无效应”或“无关联”的基准状态，而[备择假设](@entry_id:167270)则是研究者希望发现的效应或关联。

例如，在一项评估候选基因 $G$ 表达水平的转化生物信息学研究中，研究者可能希望比较突变阳性组与野生型组的差异。对于对数转换后的连续表达数据，一个典型的假设对是 [@problem_id:4546666]：
- $H_0: \mu_{\text{mut}} = \mu_{\text{wt}}$ （突变阳性组和野生型组的平均对数表达水平没有差异）
- $H_1: \mu_{\text{mut}} \ne \mu_{\text{wt}}$ （平均对数表达水平存在差异）

这里，$\mu_{\text{mut}}$ 和 $\mu_{\text{wt}}$ 分别代表两个群体中基因 $G$ 表达水平的真实（但未知）的总体均值。

对于[分类数据](@entry_id:202244)，例如评估两种药物引发的二元肾脏不良事件发生率是否存在差异，我们可以使用[独立性检验](@entry_id:165431)。其假设可以表述为 [@problem_id:4546666]：
- $H_0$: 药物类型与不良事件的发生是相互独立的。这等价于，在两种药物组中，发生不良事件的条件概率是相等的。
- $H_1$: 药物类型与不良事件的发生并非相互独立。

#### [I型错误](@entry_id:163360)、[II型错误](@entry_id:173350)与统计功效

由于我们的决策是基于样本数据（总体的一个不完美快照），因此任何决策规则都有犯错的可能。存在两种类型的错误：

- **[I型错误](@entry_id:163360) (Type I error)**：当虚无假设 $H_0$ 为真时，我们却拒绝了它。这种“[假阳性](@entry_id:635878)”错误的概率用 $\alpha$ 表示，即 $\alpha = P(\text{拒绝 } H_0 \mid H_0 \text{ 为真})$。在研究设计阶段，研究者会预先设定一个**显著性水平 (significance level)** $\alpha$ (通常为 $0.05$ 或 $0.01$)，以此作为控制 I 型错误率的上限。这是一个关于检验程序长期表现的承诺 [@problem_id:4546666]。

- **II型错误 (Type II error)**：当备择假设 $H_1$ 为真时，我们却未能拒绝 $H_0$。这种“假阴性”错误的概率用 $\beta$ 表示，即 $\beta = P(\text{未能拒绝 } H_0 \mid H_1 \text{ 为真})$。

与II型错误相对的概念是**统计功效 (statistical power)**，其定义为 $1 - \beta$。功效是在 $H_1$ 为真的情况下，我们的检验能够正确拒绝 $H_0$ 的概率，即 $1 - \beta = P(\text{拒绝 } H_0 \mid H_1 \text{ 为真})$。功效衡量了检验探测真实效应的灵敏度。值得注意的是，功效不是一个单一的数值，而是一个函数，它依赖于真实的效应大小（例如，$\mu_{\text{mut}} - \mu_{\text{wt}}$ 的真实值）、样本量 $n$ 和[显著性水平](@entry_id:170793) $\alpha$ [@problem_id:4546666]。效应越大，样本量越多，功效通常越高。

#### 检验统计量与决策规则

为了在 $H_0$ 和 $H_1$ 之间做出抉择，我们从样本数据中计算出一个**检验统计量 (test statistic)** $T$。这个统计量的构造方式使其在 $H_0$ 为真时的概率分布（即**虚无分布**）是已知的或可近似的。

决策规则可以通过两种等价的方式来表述：

1.  **临界值法 (Critical Value Approach)**：我们根据预设的 $\alpha$ 在虚无分布的尾部确定一个或多个**临界值 (critical values)**，这些值构成了**拒绝域 (rejection region)**。如果计算出的[检验统计量](@entry_id:167372)的观测值 $t_{\text{obs}}$ 落入拒绝域，我们就拒绝 $H_0$。例如，在一个双侧 $t$ 检验中，[显著性水平](@entry_id:170793)为 $\alpha$，自由度为 $\nu = n-1$，我们会在 $t$ 分布的左右两尾各分配 $\alpha/2$ 的概率。拒绝域由满足 $|T| \ge t_{1-\alpha/2, \nu}$ 的所有值组成，其中 $t_{1-\alpha/2, \nu}$ 是学生 $t$ 分布的第 $1-\alpha/2$ 分位数 [@problem_id:4546870]。

2.  **$p$值法 ($p$-value Approach)**：这是现代统计实践中更常见的方法。我们将在下一节详细讨论。

### $p$值的角色与解读

**$p$值 (p-value)** 是[假设检验](@entry_id:142556)中一个核心但又极易被误解的概念。

#### $p$值的定义与计算

$p$值是在假定虚无假设 $H_0$ 为真的前提下，观测到当前样本或更极端样本的概率。这里的“更极端”是指与 $H_0$ 更不一致。对于一个[检验统计量](@entry_id:167372) $T$，其观测值为 $t_{\text{obs}}$，双侧检验的 $p$ 值计算公式为 $p = P(|T| \ge |t_{\text{obs}}| \mid H_0)$ [@problem_id:4546870]。

从这个定义可以看出，$p$值本身就是一个**统计量**，即一个由样本数据决定的函数 $p(x)$ [@problem_id:4546804]。它的计算依赖于两部分：(1) 从样本 $x$ 中得到的观测值 $t_{\text{obs}}$，和 (2) 由检验程序预先确定的在 $H_0$ 下的[抽样分布](@entry_id:269683)。

$p$值法下的决策规则非常简单：如果 $p \le \alpha$，则拒绝 $H_0$。这两种方法是等价的，因为 $p \le \alpha$ 的条件恰好等价于 $t_{\text{obs}}$ 落入[拒绝域](@entry_id:172793)。因此，$p$值可以被理解为：能够拒绝 $H_0$ 的最小[显著性水平](@entry_id:170793) [@problem_id:4546666]。例如，如果一项[基因表达分析](@entry_id:138388)得到 $p_{\text{obs}} = 0.013$，那么在 $\alpha=0.05$ 的水平下，我们会拒绝 $H_0$ (因为 $0.013 \le 0.05$)；但在 $\alpha=0.01$ 的水平下，我们会未能拒绝 $H_0$ (因为 $0.013 \gt 0.01$)。这清晰地展示了预设的 $\alpha$ 与数据驱动的 $p$ 值在操作上的区别 [@problem_id:4546666]。

#### 对$p$值的正确解读与常见误区

一个至关重要的警示是：**$p$值不是虚无假设$H_0$为真的概率**。即 $p \ne P(H_0 \mid \text{数据})$。这是一个根本性的、普遍存在的误解 [@problem_id:4546804]。在频率学派框架中，$H_0$ 是对一个固定（非随机）参数的陈述，它本身非真即假，没有概率可言。$P(H_0 \mid \text{数据})$ 是一个[贝叶斯后验概率](@entry_id:197730)，它的计算需要一个关于 $H_0$ 的先验概率，这在经典检验的框架下是未定义的 [@problem_id:4546804]。

另一个需要澄清的误区是，**$p$值不直接衡量效应的大小**。一个极小的 $p$ 值可能来自于一个效应很小但样本量极大的研究，反之，一个重要的临床效应也可能因为样本量不足而产生一个不显著的 $p$ 值 [@problem_id:4546743]。

一个更深刻的理解是，将 $p$ 值本身视为一个随机变量 $p(X)$。当 $H_0$ 为真且检验统计量的虚无分布是连续时，这个随机变量 $p(X)$ 服从**均匀分布 Uniform(0,1)** [@problem_id:4546804] [@problem_id:4546666]。这意味着，在 $H_0$ 为真的情况下，我们有 $1\%$ 的机会得到一个小于 $0.01$ 的 $p$ 值，有 $5\%$ 的机会得到一个小于 $0.05$ 的 $p$ 值。这一性质再次强调了 $p$ 值是数据在虚无假设下的一个随机函数，而不是对假设本身真实性的概率度量。

### [置信区间](@entry_id:138194)：解释及其与检验的对偶性

与点估计（提供参数的单一最佳猜测值）相比，**[置信区间](@entry_id:138194) (confidence interval, CI)** 提供了一个参数可能取值的范围。一个 $100(1-\alpha)\%$ 的[置信区间](@entry_id:138194)是通过一个特定程序构造出来的。

#### [置信区间](@entry_id:138194)的频率学派解释

与 $p$ 值一样，[置信区间](@entry_id:138194)的正确解释也植根于频率学派思想。一个 $100(1-\alpha)\%$ 的[置信区间](@entry_id:138194)**不是**指“我们有 $1-\alpha$ 的概率相信，真实的参数 $\mu$ 落在这个具体的区间内”。

正确的解释是关于**程序**的长期表现 [@problem_id:4546670]：如果我们使用相同的实验设计和区间构造程序，独立地重复无数次实验，那么由这些实验产生的**随机区间**中，大约有 $100(1-\alpha)\%$ 的比例会包含（或“覆盖”）那个唯一的、固定的真实参数 $\mu$。这里的随机性在于样本数据，从而在于区间的端点，而不在于参数本身。

例如，一项研究报告称，某药物[对数倍数变化](@entry_id:272578)的平[均差](@entry_id:138238)异 $\mu$ 的 $95\%$ [置信区间](@entry_id:138194)为 $[0.10, 0.55]$。这意味着，产生这个特定区间的程序，在长期运行时有 $95\%$ 的成功率。一旦我们计算出这个具体的区间 $[0.10, 0.55]$，真实参数 $\mu$ 要么在其中，要么不在其中——不存在概率。我们的“信心”是对于方法的可靠性，而非对该次具体结果的概率陈述 [@problem_id:4546670]。

#### 与假设检验的对偶性

[置信区间与假设检验](@entry_id:178870)之间存在着密切的**对偶关系**。一个双侧检验在[显著性水平](@entry_id:170793) $\alpha$ 下拒绝 $H_0: \mu = \mu_0$，当且仅当相应的 $100(1-\alpha)\%$ [置信区间](@entry_id:138194)不包含 $\mu_0$。这一关系使得[置信区间](@entry_id:138194)不仅提供了效应大小的可能范围，还同时进行了一次隐式的假设检验。

### 选择正确的检验：测量尺度的作用

在应用统计检验之前，一个至关重要的步骤是确定我们数据的**测量尺度 (scale of measurement)**。由 S. S. Stevens 提出的分类系统，将数据分为四种尺度，每种尺度决定了何种数学运算是有意义的，从而约束了可以选择的统计检验方法 [@problem_id:4546737]。

- **名义尺度 (Nominal Scale)**：数据仅作为标签或类别，没有内在顺序。例如，单核苷酸多态性（SNP）的基因型 `{'AA', 'AG', 'GG'}`。对于名义数据，只能进行频数统计。任何改变标签顺序的变换都不会丢失信息，因此有效的检验必须对标签的任意置换保持不变，如**[皮尔逊卡方检验](@entry_id:272929)**或**费希尔[精确检验](@entry_id:178040)**。计算数值编码后的均值是没有意义的 [@problem_id:4546737]。

- **次序尺度 (Ordinal Scale)**：数据具有明确的顺序，但类别之间的间隔不一定是相等的。例如，患者报告的从1到5的症状严重程度李克特量表。对于次[序数](@entry_id:150084)据，有意义的运算是排序。有效的检验应对任何保持顺序的严格单调递增变换保持不变，如基于秩次的[非参数检验](@entry_id:176711)（**Mann-Whitney-Wilcoxon [秩和检验](@entry_id:168486)**、**Spearman [秩相关](@entry_id:175511)**）。直接使用 $t$ 检验比较均值是不恰当的，因为它隐含了等间隔的假设 [@problem_id:4546737]。

- **等距尺度 (Interval Scale)**：数据不仅有顺序，而且任意两点之间的差值是有意义的。但是，它没有一个真正的、非任意的零点。例如，摄氏温度。我们可以说 $20^\circ\text{C}$ 比 $10^\circ\text{C}$ 高 $10$ 度，但不能说它“热两倍”。对数变换等乘性变换通常是不允许的 [@problem_id:4546737]。

- **等比尺度 (Ratio Scale)**：这是信息最丰富的尺度，它具有等距尺度的所有性质，并且拥有一个有意义的、绝对的零点，表示“不存在”。例如，以拷贝数/毫升计量的血浆病毒载量。对于等比数据，比率（如“两倍载量”）是有意义的。正值的等比数据常常可以进行[对数变换](@entry_id:267035)，这在生物学数据中尤其有用，因为它可以使乘性误差变为加性误差，并使数据更接近正态分布 [@problem_id:4546737]。

理解测量尺度是连接研究问题与统计工具的桥梁，确保我们使用的分析方法与数据所包含的信息相匹配。

### 连续数据检验：$t$检验与方差分析

当处理的数据是等距或等比尺度时，我们可以使用参数检验来比较均值。

#### 配对 $t$ 检验

在许多生物医学研究中，数据天然成对，例如在同一患者治疗前后的测量值。在这种**[配对设计](@entry_id:176739) (paired design)** 中，使用**配对 $t$ 检验 (paired $t$-test)** 比使用独立的双样本 $t$ 检验更为有效。

其机制是将分析简化为单样本问题 [@problem_id:4546749]。我们首先为每对数据（例如，患者 $i$ 的治疗后值 $Y_i$ 和治疗前值 $X_i$）计算一个差值 $D_i = Y_i - X_i$。然后，我们对这些差值 $\{D_i\}$ 进行一个**单样本 $t$ 检验**，检验其均值 $\mu_D$ 是否为零。

[配对设计](@entry_id:176739)的效率增益源于它能有效控制个体间的变异。差值的方差为：
$$ \operatorname{Var}(D_i) = \operatorname{Var}(Y_i - X_i) = \operatorname{Var}(Y_i) + \operatorname{Var}(X_i) - 2\operatorname{Cov}(X_i, Y_i) $$
用相关系数 $\rho = \operatorname{Corr}(X_i, Y_i)$ 表示，则 $\operatorname{Cov}(X_i, Y_i) = \rho \sigma_X \sigma_Y$。因此：
$$ \operatorname{Var}(D_i) = \sigma_Y^2 + \sigma_X^2 - 2\rho\sigma_X\sigma_Y $$
在治疗前后研究中，由于稳定的个体基线，$\rho$ 通常是正的。当 $\rho > 0$ 时，差值的方差会小于独立样本方差之和 ($\sigma_Y^2 + \sigma_X^2$)。更小的方差意味着对均值差异的估计更精确，从而带来更高的统计功效 [@problem_id:4546749]。

#### 单因素[方差分析 (ANOVA)](@entry_id:262372)

当需要比较两个以上组的均值时，我们使用**方差分析 (Analysis of Variance, [ANOVA](@entry_id:275547))**。[单因素ANOVA](@entry_id:163873)是双样本 $t$ 检验的推广。其基本思想是将数据的总变异分解为两部分：**组间变异 (between-group variability)** 和**组内变异 (within-group variability)**。

检验统计量是 **$F$ 统计量**，定义为组间均方 ($MS_{\text{between}}$) 与组内均方 ($MS_{\text{within}}$) 的比值：
$$ F = \frac{MS_{\text{between}}}{MS_{\text{within}}} = \frac{SS_{\text{between}}/(g-1)}{SS_{\text{within}}/(N-g)} $$
其中 $SS$ 代表平方和，$g$ 是组数，$N$ 是总样本量。

在虚无假设 $H_0: \mu_1 = \mu_2 = \dots = \mu_g$ 下，$F$ 统计量为何服从 $F$ 分布？这背后有深刻的理论依据 [@problem_id:4546662]。其成立需要满足三个关键假设：
1.  **独立性**：各观测值的误差项 $\varepsilon_{ij}$ 相互独立。
2.  **[方差齐性](@entry_id:167143) (Homoscedasticity)**：各组的误差方差相同，即 $\operatorname{Var}(\varepsilon_{ij}) = \sigma^2$。
3.  **正态性**：误差项服从正态分布，$\varepsilon_{ij} \sim \mathcal{N}(0, \sigma^2)$。

在这些假设下，**Cochran定理**保证了以下两点：
- $SS_{\text{within}}/\sigma^2$ 服从自由度为 $N-g$ 的卡方 ($\chi^2$) 分布。
- 在 $H_0$ 为真的情况下，$SS_{\text{between}}/\sigma^2$ 服从自由度为 $g-1$ 的卡方分布。
- 最关键的是，$SS_{\text{between}}$ 和 $SS_{\text{within}}$ 是相互独立的。

根据 $F$ 分布的定义，两个独立的、已除以各自自由度的卡方变量之比，即服从 $F$ 分布。因此，在 $H_0$ 下，$F = MS_{\text{between}}/MS_{\text{within}}$ 服从[分子自由度](@entry_id:175192)为 $g-1$、分母自由度为 $N-g$ 的 $F$ 分布 [@problem_id:4546662]。

### [分类数据](@entry_id:202244)检验：[列联表](@entry_id:162738)分析

对于名义或次序[分类变量](@entry_id:637195)，我们通常将数据整理成**[列联表](@entry_id:162738) (contingency table)** 进行分析。

#### [卡方检验](@entry_id:174175)及其局限性

**皮尔逊卡方 ($\chi^2$) 检验** 是分析[列联表](@entry_id:162738)中行变量和列变量是否独立的标准方法。其检验统计量通过比较**观测频数 ($O_{ij}$)** 和在独立性假设下的**期望频数 ($E_{ij}$)** 来构造：
$$ X^2 = \sum_{i,j} \frac{(O_{ij} - E_{ij})^2}{E_{ij}} $$
在独立性 $H_0$ 下，期望频数由边际总计计算得出：$E_{ij} = (\text{行}i\text{总计} \times \text{列}j\text{总计}) / \text{总样本量}$ [@problem_id:4546685]。在大样本情况下，$X^2$ 统计量近似服从自由度为 $(r-1)(c-1)$ 的卡方分布（其中 $r, c$ 分别为行数和列数）。

然而，这种近似的有效性依赖于“大样本”假设，具体而言，是期望频数不能太小。如果某些单元格的 $E_{ij}$ 过低，卡方分布的近似就会很差，导致[I型错误](@entry_id:163360)率失控。常用的经验法则是：
- 所有期望频数 $E_{ij}$ 均不应小于 $1$。
- 至少 $80\%$ 的单元格的期望频数应大于等于 $5$。

当这些条件不满足时，例如在研究稀有基因型与疾病关联的场景中，卡方检验的结果是不可信的 [@problem_id:4546685]。

#### [精确检验](@entry_id:178040)与关联度量

当[卡方检验](@entry_id:174175)的近似条件不满足时，应使用**[精确检验](@entry_id:178040) (exact test)**。对于 $2 \times 2$ 表格，最常用的是**费希尔[精确检验](@entry_id:178040) (Fisher's exact test)**。该检验在固定所有行和列总计的条件下，计算观测到的表格及更极端表格出现的精确概率（基于[超几何分布](@entry_id:193745)），从而得到精确的 $p$ 值 [@problem_id:4546685]。对于更大的表格，可以使用基于网络算法或蒙特卡洛模拟的精确检验。

除了检验独立性，我们还关心关联的强度和方向。对于 $2 \times 2$ 表，两个重要的关联度量是**风险比 (Risk Ratio, RR)** 和**比值比 (Odds Ratio, OR)**。
- **风险比 (RR)**: $RR = \frac{P(\text{疾病} | \text{暴露})}{P(\text{疾病} | \text{非暴露})}$。它直观地比较了两组的风险，是队列研究中的首选指标。
- **比值比 (OR)**: $OR = \frac{\text{暴露组的疾病比值}}{\text{非暴露组的疾病比值}}$。比值定义为事件发生概率与不发生概率之比。

在一个关键的区分中，**OR 在病例-对照研究中具有特殊的不变性**。病例-对照研究根据疾病状态抽样，因此无法直接[估计风险](@entry_id:139340) $P(\text{疾病} | \text{暴露})$，也就无法计算 RR。然而，可以证明，从病例-对照数据中计算出的“暴露比值比”（即病例中的暴露比值与对照中的暴露比值之比）在数值上恒等于我们真正关心的“疾病比值比” [@problem_id:4546821]。这一性质使得 OR 成为病例-对照研究的标准关联度量。

此外，在**罕见病假设**下，当疾病发生率很低时，$P(\text{疾病} | \text{暴露})$ 和 $P(\text{疾病} | \text{非暴露})$ 都接近于0，此时 $OR \approx RR$。这使得在某些情况下，可以从病例-对照研究中得到的 OR 来近似 RR [@problem_id:4546821]。

### 稳健性与非参数替代方法

经典参数检验（如 $t$ 检验和 ANOVA）虽然强大，但它们的有效性依赖于特定的假设（如正态性和[方差齐性](@entry_id:167143)），并且对**离群值 (outliers)** 非常敏感。

#### 离群值的影响与诊断

$t$ 检验和 ANOVA 都基于样本均值和方差，而这两者都对极端值极为敏感。一个离群值可以不成比例地影响计算结果。从理论上讲，样本均值的**[影响函数](@entry_id:168646) (influence function)** 是无界的，这意味着单个离群点可以对估计值产生任意大的影响 [@problem_id:4546743]。

一个常见的误解是认为离群值总会夸大效应，导致 I 型错误。实际上，离群值对 $t$ 统计量的影响是双重的：它会同时增大分子（组间均值差）和分母（[合并标准差](@entry_id:198759)）。由于方差的计算涉及偏差的平方，离群值对分母的“拉动”作用通常远大于对分子的作用。结果常常是 $t$ 统计量的绝对值**减小**，从而导致统计功效的丧失（[II型错误](@entry_id:173350)增加），而不是[I型错误](@entry_id:163360)的膨胀 [@problem_id:4546743]。

因此，在进行参数检验前，进行离群值诊断至关重要。诊断工具包括：
- **可视化方法**：**[Q-Q图](@entry_id:174944) (Quantile-Quantile plot)** 可用于检查数据是否偏离正态分布，离群点在图的尾部会明显偏离直线。
- **影响度量**：在[线性模型](@entry_id:178302)框架下，**[库克距离](@entry_id:175103) (Cook's distance)** 衡量删除单个观测值对[模型拟合](@entry_id:265652)的总体影响，是识别高[影响点](@entry_id:170700)的有力工具 [@problem_id:4546743]。

#### 基于秩次和置换的[非参数检验](@entry_id:176711)

当数据不满足[正态性假设](@entry_id:170614)或存在离群值时，应考虑使用**[非参数检验](@entry_id:176711)**。

**基于秩次的检验**，如 **Wilcoxon[秩和检验](@entry_id:168486)**，通过将原始数据替换为其排序后的秩次来进行分析。这有效地“限制”了离群值的影响——最大的离群值仅仅是最大的秩次，其影响是有界的 [@problem_id:4546743]。

更深层的原理在于**[置换检验](@entry_id:175392) (permutation test)**。[置换检验](@entry_id:175392)是一种强大的方法，它可以在不依赖任何参数分布假设的情况下，为检验统计量生成一个精确的虚无分布 [@problem_id:4546658]。其逻辑基于数据在虚无假设下的对称性：

- **对于两独立样本检验**：虚无假设是两组样本来自同一分布。如果 $H_0$ 为真，那么将样本的组别标签任意打乱重排，得到的任何新数据集都与原数据集等可能。这种**标签[可交换性](@entry_id:263314) (label exchangeability)** 意味着我们可以通过枚举所有可能的标签排列（共 $\binom{n}{n_1}$ 种），计算每种排列下的[检验统计量](@entry_id:167372)，从而构建出精确的虚无分布 [@problem_id:4546658]。

- **对于[配对样本检验](@entry_id:163958)**（如[Wilcoxon符号秩检验](@entry_id:168040)）：其对应的虚无假设是差值 $D_i$ 的分布关于0对称。如果 $H_0$ 为真，那么每个 $D_i$ 的符号（正或负）都是随机的，如同抛硬币。我们可以通过枚举所有 $2^n$ 种可能的符号组合，计算每种组合下的[检验统计量](@entry_id:167372)，从而构建出精确的虚无分布 [@problem_id:4546658]。

[置换检验](@entry_id:175392)体现了统计推断的第一性原理，它直接从数据和虚无假设的逻辑后果中导出结论，为处理复杂的生物医学数据提供了稳健而强大的工具。