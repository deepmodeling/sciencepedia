{"hands_on_practices": [{"introduction": "哈希表是实现高效数据查找的基石，在生物信息学中，例如在大规模基因组数据中进行$k$-mer计数等任务，哈希表至关重要。本练习将指导你从第一性原理出发，推导著名的哈希表 $O(1)$ 期望查找时间，并进一步探讨其性能的方差 [@problem_id:4538794]。通过这个过程，你将理解理论假设（如简单均匀哈希）如何转化为实际的性能保证，并对算法性能的稳定性有更深刻的认识。", "problem": "在一个医院网络的大规模宏基因组变异监测流程中，有$n$个不同$k$-mer的计数存储在一个具有$m$个桶的哈希表中，该哈希表使用独立链表法（每个桶一个链表）。我们假设满足简单均匀哈希假设（SUHA），即每个$k$-mer独立且均匀地哈希到$m$个桶中的任意一个。设负载因子为$\\alpha = n/m$。查找成本定义为在一次查询中，与表中存储的$k$-mer进行键比较的次数。考虑两种自然的查询情景：一种是不成功的查找，即被查询的$k$-mer不在表中；另一种是成功的查找，即被查询的键是从$n$个已存储$k$-mer中均匀随机抽取的一个。\n\n从SUHA和$\\alpha$的基本定义出发，并利用关于占用分布的成熟结论（桶大小的二项式建模以及在$n$和$m$很大且$\\alpha$固定时成立的泊松近似），完成以下任务：\n\n1. 对每种情景，推导以$\\alpha$表示的期望查找成本，并解释为何当问题规模扩大时（即当$n$和$m$增长而$\\alpha$保持有界时），期望查找时间为$O(1)$。\n2. 在适用于生物信息学中大规模$k$-mer表的泊松近似下，计算成功查找情景下查找成本的方差，并将其表示为仅含$\\alpha$的函数。将您的最终结果表示为仅含$\\alpha$的单个封闭形式符号表达式。\n\n您的最终答案必须是表示方差的单个封闭形式表达式，并且仅是$\\alpha$的函数，无单位。", "solution": "该问题提法明确，有科学依据，客观，并包含了获得完整解析解所需的所有必要信息。这是算法分析中的一个标准问题，并应用于一个真实的生物信息学背景。\n\n### 第一部分：期望查找成本\n\n问题定义了一个具有$m$个桶和$n$个不同键的哈希表，使用独立链表法。负载因子为$\\alpha = n/m$。我们假设满足简单均匀哈希假设（SUHA），即每个键以等概率$1/m$哈希到$m$个桶中的一个，且与其他所有键独立。查找成本是键比较的次数。\n\n**不成功的查找**\n\n对于一个键$x$的不成功查找，算法首先计算哈希值$h(x)$以确定一个桶，比如说桶$j$。然后，它必须遍历桶$j$处的整个链表以确认$x$不存在。因此，成本等于桶$j$中的键数，我们用随机变量$N_j$表示。我们需要找到期望成本，$E[N_j]$。\n\n令$X_i$为一个指示随机变量，表示第$i$个键（对于$i \\in \\{1, 2, \\dots, n\\}$）哈希到桶$j$的事件。在SUHA下，此事件的概率为$P(\\text{hash}(k_i) = j) = 1/m$。因此，$E[X_i] = 1 \\cdot P(X_i=1) + 0 \\cdot P(X_i=0) = 1/m$。\n\n桶$j$中的总键数是这$n$个键的指示变量之和：$N_j = \\sum_{i=1}^{n} X_i$。\n根据期望的线性性质，链表的期望长度是：\n$$E[N_j] = E\\left[\\sum_{i=1}^{n} X_i\\right] = \\sum_{i=1}^{n} E[X_i] = \\sum_{i=1}^{n} \\frac{1}{m} = \\frac{n}{m}$$\n根据负载因子$\\alpha = n/m$的定义，不成功查找的期望成本$C_{unsucc}$为：\n$$E[C_{unsucc}] = \\alpha$$\n\n**成功的查找**\n\n对于一次成功的查找，我们查询一个保证在表中的键$x$。问题指明$x$是从$n$个已存储键中均匀随机选择的。查找的成本是$1$（用于与$x$自身的比较）加上在其链表中出现在$x$之前的其他键的数量。\n\n让我们考虑对所有$n$个键进行成功查找的总成本，然后求其平均值。假设键按其插入表的顺序为$k_1, k_2, \\dots, k_n$。假设新键被添加到其各自桶中链表的末尾。找到键$k_i$的成本是$1$加上先前插入的键（$k_j$且$j  i$）中哈希到与$k_i$相同桶的键的数量。\n令$I_{ij}$为事件$\\text{hash}(k_i) = \\text{hash}(k_j)$的指示变量。在SUHA下，对于$i \\neq j$，有$E[I_{ij}] = P(\\text{hash}(k_i) = \\text{hash}(k_j)) = 1/m$。\n\n找到一个特定键$k_i$的期望成本是$E[1 + \\sum_{j=1}^{i-1} I_{ij}] = 1 + \\sum_{j=1}^{i-1} E[I_{ij}] = 1 + \\frac{i-1}{m}$。\n一次成功查找的平均成本$C_{succ}$是这$n$个键的成本的平均值：\n$$E[C_{succ}] = \\frac{1}{n} \\sum_{i=1}^{n} \\left(1 + \\frac{i-1}{m}\\right) = \\frac{1}{n} \\left(\\sum_{i=1}^{n} 1 + \\frac{1}{m} \\sum_{i=1}^{n} (i-1)\\right)$$\n$$E[C_{succ}] = \\frac{1}{n} \\left(n + \\frac{1}{m} \\frac{(n-1)n}{2}\\right) = 1 + \\frac{n-1}{2m}$$\n代入$\\alpha = n/m$，我们可以将其写为：\n$$E[C_{succ}] = 1 + \\frac{n}{2m} - \\frac{1}{2m} = 1 + \\frac{\\alpha}{2} - \\frac{1}{2m}$$\n在$n, m \\to \\infty$的大规模极限下，项$1/(2m)$趋近于$0$，从而得到众所周知的结果：\n$$E[C_{succ}] \\approx 1 + \\frac{\\alpha}{2}$$\n\n**渐近复杂度$O(1)$**\n\n问题的规模通过让$n$和$m$增长而负载因子$\\alpha = n/m$保持有界常数来扩大。期望查找成本为$E[C_{unsucc}] = \\alpha$和$E[C_{succ}] \\approx 1 + \\alpha/2$。由于$\\alpha$是一个常数，所以两个期望成本都是常数。假设哈希函数本身可以在常数时间内计算，则成功和不成功查找的总期望时间均为$O(1)$。这是哈希表的一个关键优势。\n\n### 第二部分：成功查找成本的方差\n\n我们被要求在泊松近似下计算成功查找成本的方差$\\text{Var}(C_{succ})$。此近似在$n$和$m$很大且比率$\\alpha=n/m$固定的情况下有效。它指出，任何给定桶中的键数服从均值为$\\alpha$的泊松分布。\n\n对于一次成功的查找，我们均匀随机地选择一个键。设此键为$x$。与$x$哈希到同一个桶的*其他*键的数量服从二项分布$B(n-1, 1/m)$。对于大的$n$和小的$1/m$，这可以很好地用均值为$\\lambda = (n-1)/m \\approx n/m = \\alpha$的泊松分布来近似。令$K$为我们所选键$x$所在桶中其他键数量的随机变量。因此，$K \\sim \\text{Pois}(\\alpha)$。此桶中的总键数为$L = K+1$。\n\n成功查找的成本$C$取决于$x$在长度为$L$的链表中的位置。由于$x$是从所有$n$个键中均匀随机选择的，因此它在自己链表中的位置在$1$到$L$之间均匀分布。\n设$C$为成本的随机变量。我们将使用全方variance公式：\n$$\\text{Var}(C) = E[\\text{Var}(C|L)] + \\text{Var}(E[C|L])$$\n\n首先，我们需要在给定$L$的条件下$C$的条件期望和条件方差。对于一个在$\\{1, 2, \\dots, L\\}$上的离散均匀随机变量，其期望和方差为：\n$$E[C|L] = \\frac{L+1}{2}$$\n$$\\text{Var}(C|L) = \\frac{L^2-1}{12}$$\n\n现在，我们计算全方差公式的两个项。\n\n1.  **第1项: $\\text{Var}(E[C|L])$**\n    $$\\text{Var}(E[C|L]) = \\text{Var}\\left(\\frac{L+1}{2}\\right) = \\left(\\frac{1}{2}\\right)^2 \\text{Var}(L) = \\frac{1}{4}\\text{Var}(L)$$\n    由于$L = K+1$且$K \\sim \\text{Pois}(\\alpha)$，我们有$\\text{Var}(L) = \\text{Var}(K+1) = \\text{Var}(K)$。对于泊松分布，方差等于均值，所以$\\text{Var}(K) = \\alpha$。\n    $$\\text{Var}(E[C|L]) = \\frac{1}{4}\\alpha$$\n\n2.  **第2项: $E[\\text{Var}(C|L)]$**\n    $$E[\\text{Var}(C|L)] = E\\left[\\frac{L^2-1}{12}\\right] = \\frac{1}{12}(E[L^2] - 1)$$\n    为了求$E[L^2]$，我们使用$L=K+1$:\n    $$E[L^2] = E[(K+1)^2] = E[K^2 + 2K + 1] = E[K^2] + 2E[K] + 1$$\n    我们知道$E[K]=\\alpha$。我们从$K$的方差中求$E[K^2]$:\n    $$E[K^2] = \\text{Var}(K) + (E[K])^2 = \\alpha + \\alpha^2$$\n    将此代回：\n    $$E[L^2] = (\\alpha + \\alpha^2) + 2(\\alpha) + 1 = \\alpha^2 + 3\\alpha + 1$$\n    现在，我们可以计算第二项：\n    $$E[\\text{Var}(C|L)] = \\frac{1}{12}((\\alpha^2 + 3\\alpha + 1) - 1) = \\frac{\\alpha^2 + 3\\alpha}{12}$$\n\n最后，我们将两项相加得到总方差：\n$$\\text{Var}(C) = \\text{Var}(E[C|L]) + E[\\text{Var}(C|L)] = \\frac{\\alpha}{4} + \\frac{\\alpha^2 + 3\\alpha}{12}$$\n为了合并它们，我们找到一个公分母：\n$$\\text{Var}(C) = \\frac{3\\alpha}{12} + \\frac{\\alpha^2 + 3\\alpha}{12} = \\frac{\\alpha^2 + 6\\alpha}{12}$$\n\n这就是在泊松近似下，成功查找的查找成本的方差。", "answer": "$$\\boxed{\\frac{\\alpha^2 + 6\\alpha}{12}}$$", "id": "4538794"}, {"introduction": "从数据结构转向算法本身，快速排序是分析最坏情况与平均情况性能差异的经典案例。本练习将展示一个“聪明的对手”如何利用确定性算法的弱点，导致灾难性的性能表现 [@problem_id:4538777]。同时，它也揭示了随机化这一简单而强大的技术如何能够抵抗最坏情况，确保算法在期望意义上达到高效、稳健的性能。", "problem": "给定一个包含 $n$ 个不同测序读段标识符的集合 $\\mathcal{R} = (r_{1}, r_{2}, \\ldots, r_{n})$，其中每个标识符都是一个唯一的字符串。定义一个键函数 $\\kappa$，它将每个读段标识符映射到其在 $\\{1, 2, \\ldots, n\\}$ 中的字典序排名，因此 $\\kappa$ 导出一个严格全序，且不存在平级关系。考虑一个内存中的快速排序实现 $Q$。在每次递归调用中，它选择当前子数组的第一个元素作为主元，并通过将该主元与子数组中的所有其他元素进行比较来进行划分（每次两两排序检查计为一次键值比较）。提供给 $Q$ 的输入顺序完全由一个对手控制。运行时间由排序过程中执行的键值比较总次数来衡量。\n\n任务：\n- 构建一个 $\\mathcal{R}$ 的明确输入顺序，该顺序对 $Q$ 是对抗性的，即每个划分步骤都产生大小为 $0$ 和 $n-1$ 的子问题。仅使用 $Q$ 的定义和比较模型，推导 $Q$ 在该输入上执行的总比较次数 $C_{\\mathrm{det}}(n)$ 关于 $n$ 的封闭形式精确表达式。\n- 现在考虑一个随机化变体 $Q_{\\mathrm{rand}}$，它在每次递归调用中，从当前子数组中均匀随机地选择其主元，该选择与输入顺序无关，且各次调用之间相互独立。在相同的成本模型下，并假设所有 $\\kappa(r)$ 都是不同的，推导期望总比较次数 $\\mathbb{E}[C_{\\mathrm{rand}}(n)]$ 关于 $n$ 和第 $n$ 个调和数 $H_{n} = \\sum_{j=1}^{n} \\frac{1}{j}$ 的精确封闭形式表达式。从第一性原理出发，论证为何该表达式意味着随机化主元选择能将期望复杂度恢复到 $O(n \\log n)$。\n\n将你的最终答案以一个包含两个条目 $\\big(C_{\\mathrm{det}}(n), \\mathbb{E}[C_{\\mathrm{rand}}(n)]\\big)$ 的行矩阵形式提供，并按此顺序排列。不要四舍五入，也不要包含任何单位。", "solution": "问题陈述已经过验证，被认为具有科学依据、是良定的和客观的。它提出了一个算法分析中的标准、形式化问题。\n\n我们将依次解决这两个任务。设 $n$ 个不同测序读段标识符的集合为 $\\mathcal{R} = \\{r_1, r_2, \\ldots, r_n\\}$。键函数 $\\kappa$ 将这些标识符映射到它们在 $\\{1, 2, \\ldots, n\\}$ 中的字典序排名。为便于分析，我们可以用它们的排名来表示待排序的项，我们将其记为已排序元素的集合 $z_1  z_2  \\ldots  z_n$，其中对于某个 $j$ 有 $z_i = \\kappa(r_j)$，且 $z_i$ 是第 $i$ 小的键。\n\n**第1部分：确定性快速排序 ($Q$) 的对抗性分析**\n\n确定性快速排序算法 $Q$ 选择子数组的第一个元素作为其主元。成本由键值比较的次数衡量。对一个大小为 $k$ 的子数组进行划分，需要将主元与其余 $k-1$ 个元素进行比较，这导致 $k-1$ 次比较。一个对抗性输入是指能迫使每个划分步骤都产生大小为 $0$ 和 $n-1$（或更一般地，对于大小为 $k$ 的子数组，产生大小为 $0$ 和 $k-1$）的子问题的输入。\n\n要实现这种划分，所选的主元必须总是当前子数组中的最小或最大元素。由于主元总是第一个元素，对手必须构建一个输入列表，使得 $Q$ 处理的每个子数组的第一个元素都是极值元素。\n\n一个能保证这一点的明确输入顺序是一个已排序的列表。设 $Q$ 的输入为序列 $(z_1, z_2, \\ldots, z_n)$。\n\\begin{enumerate}\n    \\item 初始调用是 $Q((z_1, z_2, \\ldots, z_n))$。主元是 $z_1$。它与其余 $n-1$ 个元素进行比较。由于 $z_1$ 是最小元素，划分产生一个大小为 $0$ 的子问题（对于小于 $z_1$ 的元素）和一个包含 $(z_2, \\ldots, z_n)$ 的大小为 $n-1$ 的子问题。此步骤花费 $n-1$ 次比较。\n    \\item 下一个递归调用是 $Q((z_2, \\ldots, z_n))$。主元是 $z_2$。它与该子数组中的其余 $n-2$ 个元素进行比较。由于 $z_2$ 是该子数组中的最小元素，划分产生大小为 $0$ 和 $n-2$ 的子问题。此步骤花费 $n-2$ 次比较。\n    \\item 这个过程持续进行。对于一个大小为 $k \\ge 2$ 的子数组的一般步骤，输入为 $(z_{n-k+1}, \\ldots, z_n)$。主元是 $z_{n-k+1}$，它是最小值。这需要 $k-1$ 次比较，并生成大小为 $0$ 和 $k-1$ 的子问题。\n\\end{enumerate}\n一个逆序排序的列表 $(z_n, z_{n-1}, \\ldots, z_1)$ 也是一个对抗性输入，因为此时主元总是最大元素。\n\n设 $C_{\\mathrm{det}}(n)$ 是在大小为 $n$ 的对抗性输入上的总比较次数。处理的子数组大小序列为 $n, n-1, n-2, \\ldots, 2$。大小为 1 的子数组是基本情况，需要 0 次比较。总比较次数是每一步比较次数的总和：\n$$C_{\\mathrm{det}}(n) = (n-1) + (n-2) + \\dots + (2-1)$$\n这是前 $n-1$ 个正整数的和：\n$$C_{\\mathrm{det}}(n) = \\sum_{k=1}^{n-1} k = \\frac{(n-1)n}{2}$$\n这是 $n$ 的一个二次函数，表明了这种确定性快速排序实现的最坏情况时间复杂度为 $O(n^2)$。\n\n**第2部分：随机化快速排序 ($Q_{\\mathrm{rand}}$) 的平均情况分析**\n\n随机化变体 $Q_{\\mathrm{rand}}$ 从当前子数组中均匀随机地选择一个主元。为了找到期望比较次数 $\\mathbb{E}[C_{\\mathrm{rand}}(n)]$，我们使用一种基于指示器随机变量的方法。\n\n设已排序的元素为 $z_1  z_2  \\ldots  z_n$。总比较次数 $C_{\\mathrm{rand}}(n)$ 是对所有不同元素对进行比较的总和。设 $I_{ij}$ 是一个指示器随机变量，表示事件“$z_i$ 和 $z_j$ 被比较”。根据定义，如果它们被比较，则 $I_{ij}=1$，否则 $I_{ij}=0$。我们关心的是 $i  j$ 的元素对。\n总比较次数为 $C_{\\mathrm{rand}}(n) = \\sum_{i=1}^{n-1} \\sum_{j=i+1}^{n} I_{ij}$。根据期望的线性性：\n$$\\mathbb{E}[C_{\\mathrm{rand}}(n)] = \\mathbb{E}\\left[\\sum_{i=1}^{n-1} \\sum_{j=i+1}^{n} I_{ij}\\right] = \\sum_{i=1}^{n-1} \\sum_{j=i+1}^{n} \\mathbb{E}[I_{ij}]$$\n指示器变量的期望是它所指示事件的概率：$\\mathbb{E}[I_{ij}] = P(z_i \\text{ 与 } z_j \\text{ 被比较})$。\n\n考虑元素集合 $S_{ij} = \\{z_i, z_{i+1}, \\ldots, z_j\\}$。两个元素 $z_i$ 和 $z_j$ 被比较，当且仅当从集合 $S_{ij}$ 中选出的第一个主元是 $z_i$ 或 $z_j$。\n如果任何其他满足 $i  k  j$ 的元素 $z_k$ 被首先选为主元，那么 $z_i$ 和 $z_j$ 将被分到不同的划分中（一个包含小于 $z_k$ 的元素，另一个包含大于 $z_k$ 的元素），并且它们将永远不会被比较。如果一个在范围 $[z_i, z_j]$ 之外的元素被选为主元，那么 $z_i$ 和 $z_j$ 都会被分到同一个划分中，它们是否会被比较的决定将被推迟。因此，$z_i$ 和 $z_j$ 是否被比较仅取决于从 $S_{ij}$ 内部选择的第一个主元。\n\n集合 $S_{ij}$ 的大小为 $j-i+1$。由于主元是从任何子数组中均匀随机选择的，因此 $S_{ij}$ 中的任何元素都有同等可能成为从该集合中选出的第一个主元。任何特定元素 $z_k \\in S_{ij}$ 成为第一个被选中的主元的概率是 $\\frac{1}{j-i+1}$。\n事件“$z_i$ 与 $z_j$ 被比较”发生，如果 $z_i$ 是从 $S_{ij}$ 中选出的第一个主元，或者 $z_j$ 是从 $S_{ij}$ 中选出的第一个主元。这两个是互斥事件。\n$$P(z_i \\text{ 与 } z_j \\text{ 被比较}) = P(z_i \\text{ 是 } S_{ij} \\text{ 的第一个主元}) + P(z_j \\text{ 是 } S_{ij} \\text{ 的第一个主元}) = \\frac{1}{j-i+1} + \\frac{1}{j-i+1} = \\frac{2}{j-i+1}$$\n现在我们将这个概率代回到期望总比较次数的求和式中：\n$$\\mathbb{E}[C_{\\mathrm{rand}}(n)] = \\sum_{i=1}^{n-1} \\sum_{j=i+1}^{n} \\frac{2}{j-i+1}$$\n为了计算这个和，我们可以通过设置 $k = j-i$ 来重新索引。内部的和变为：\n$$\\mathbb{E}[C_{\\mathrm{rand}}(n)] = \\sum_{i=1}^{n-1} \\sum_{k=1}^{n-i} \\frac{2}{k+1}$$\n这仍然有些复杂。一个更直接的方法是改变求和顺序，通过固定元素之间的距离。令 $d = j-i+1$ 为集合 $S_{ij}$ 的大小。$d$ 的最小值为 $2$（对于相邻元素），最大值为 $n$（对于 $z_1, z_n$）。对于一个固定的 $d \\in \\{2, \\ldots, n\\}$，我们计算满足 $j-i+1 = d$ 或 $j-i = d-1$ 的对 $(i, j)$ 的数量。这些对是 $(1, d), (2, d+1), \\ldots, (n-d+1, n)$。总共有 $n-d+1$ 对这样的元素对。\n所以，我们可以重写关于 $d$ 的和：\n$$\\mathbb{E}[C_{\\mathrm{rand}}(n)] = \\sum_{d=2}^{n} (\\text{大小为 } d \\text{ 的元素对数量}) \\times \\frac{2}{d} = \\sum_{d=2}^{n} (n-d+1) \\frac{2}{d}$$\n$$\\mathbb{E}[C_{\\mathrm{rand}}(n)] = 2 \\sum_{d=2}^{n} \\frac{n+1-d}{d} = 2 \\sum_{d=2}^{n} \\left(\\frac{n+1}{d} - 1\\right)$$\n$$= 2 \\left( (n+1)\\sum_{d=2}^{n} \\frac{1}{d} - \\sum_{d=2}^{n} 1 \\right)$$\n使用第 $n$ 个调和数的定义 $H_n = \\sum_{j=1}^{n}\\frac{1}{j}$，我们有 $\\sum_{d=2}^{n} \\frac{1}{d} = H_n-1$。第二个和有 $n-1$ 项。\n$$\\mathbb{E}[C_{\\mathrm{rand}}(n)] = 2 \\left( (n+1)(H_n - 1) - (n-1) \\right)$$\n$$= 2 ( (n+1)H_n - (n+1) - (n-1) ) = 2 ( (n+1)H_n - 2n )$$\n$$\\mathbb{E}[C_{\\mathrm{rand}}(n)] = 2(n+1)H_n - 4n$$\n\n最后，我们论证为什么这个表达式意味着期望复杂度为 $O(n \\log n)$。调和数 $H_n$ 有着众所周知的渐近行为：\n$$H_n = \\ln(n) + \\gamma + O\\left(\\frac{1}{n}\\right)$$\n其中 $\\gamma \\approx 0.577$ 是欧拉-马斯刻若尼常数 (Euler-Mascheroni constant)。因此，$H_n$ 的增长率为 $\\Theta(\\ln n)$。\n将此代入我们关于 $\\mathbb{E}[C_{\\mathrm{rand}}(n)]$ 的表达式中：\n$$\\mathbb{E}[C_{\\mathrm{rand}}(n)] = 2(n+1)(\\ln(n) + \\gamma + O(n^{-1})) - 4n$$\n$$= 2n\\ln(n) + 2n\\gamma + O(1) + 2\\ln(n) + 2\\gamma + O(n^{-1}) - 4n$$\n$$= 2n\\ln(n) + n(2\\gamma - 4) + 2\\ln(n) + O(1)$$\n此表达式中的主导项是 $2n\\ln(n)$。由于 $\\ln(n)$ 和 $\\log(n)$ 仅相差一个常数因子 $(\\ln(n) = \\ln(2) \\log_2(n))$，所以渐近复杂度为：\n$$\\mathbb{E}[C_{\\mathrm{rand}}(n)] = \\Theta(n \\log n)$$\n因此，随机化主元选择减轻了持续选到坏主元的可能性，将期望比较次数从最坏情况的 $\\Theta(n^2)$ 降低到平均情况的 $\\Theta(n \\log n)$，这对于基于比较的排序算法来说是最优的。", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{n(n-1)}{2}  2(n+1)H_{n} - 4n \\end{pmatrix}}$$", "id": "4538777"}, {"introduction": "我们的视角将从单个算法拓宽到在现代多核处理器上运行的完整计算流程。本练习将引入阿姆达尔定律（Amdahl's Law），这是一个预测并行化加速极限的基本模型 [@problem_id:4538775]。通过根据实际观测数据推断系统中的“串行瓶颈”，你将切身体会到为什么简单地增加处理器数量并不总能带来成比例的性能提升，从而理解并行计算的内在限制。", "problem": "一个临床全基因组比对流程在单个共享内存节点上，使用种子扩展策略处理独立的短读序列与固定的参考基因组的比对。该流程包含几个不同的阶段：输入解压缩和索引加载、逐个读段的比对以及输出整理。假设逐个读段的比对阶段可以完美地划分给 $P$ 个工作线程，且线程之间无需通信，而其余工作是严格串行的，无法并行化。设串行比例为 $s \\in (0,1)$，定义为当 $P=1$ 时，在不可并行化阶段所花费的时间占总运行时间的比例。理想化模型假设，可并行化部分的时间与 $P$ 成反比，而串行部分的时间与 $P$ 无关。\n\n在一个包含 $10^6$ 个读段的基准数据集上，于同一节点进行性能分析，观察到使用 $P=16$ 个工作线程相对于 $P=1$ 时的加速比为 $10$。将此观察结果视为在所述假设下的理想强扩展行为的体现，并忽略诸如调度或非一致性内存访问等额外开销。\n\n仅使用所述的理想化模型和加速比的定义，首先根据在 $P=16$ 时的观察结果推断出 $s$ 的隐含值，然后计算在同一节点上、相同的 $s$ 值下，扩展到 $P=256$ 个工作线程时可实现的理想加速比。将最终答案四舍五入到四位有效数字。仅以纯数字形式给出最终加速比，不带单位。", "solution": "该问题描述了一个经典的强扩展场景，其行为可以用阿姆达尔定律（Amdahl's Law）来建模。设 $T_1$ 为流程在单个工作线程上（即 $P=1$ 的情况）的总运行时间。不失一般性，我们可以将此时间归一化为 $T_1 = 1$。\n\n问题定义了串行比例 $s$，其中 $s \\in (0,1)$，作为 $P=1$ 时总运行时间中无法被并行化的部分。因此，串行任务所花费的时间为 $s T_1 = s$。工作的剩余部分 $1-s$ 被指定为可完美并行化的。当使用 $P$ 个工作线程时，完成可并行化部分所需的时间与 $P$ 成反比，变为 $\\frac{1-s}{P}$。串行部分的时间假设与 $P$ 无关，保持为 $s$。\n\n在 $P$ 个线程上的总运行时间，记为 $T_P$，是串行和并行执行时间的总和：\n$$T_P = s + \\frac{1-s}{P}$$\n\n加速比 $S_P$ 定义为单线程执行时间与多线程执行时间的比值：\n$$S_P = \\frac{T_1}{T_P} = \\frac{1}{s + \\frac{1-s}{P}}$$\n\n第一步是使用提供的基准数据来推断串行比例 $s$ 的值。已知当 $P=16$ 个工作线程时，观察到的加速比为 $S_{16} = 10$。将这些值代入加速比方程：\n$$10 = \\frac{1}{s + \\frac{1-s}{16}}$$\n\n我们接着解这个关于 $s$ 的方程：\n$$10 \\left( s + \\frac{1-s}{16} \\right) = 1$$\n$$10s + \\frac{10(1-s)}{16} = 1$$\n为了消去分母，我们可以将整个方程乘以 $16$：\n$$16 \\times 10s + 16 \\times \\frac{10(1-s)}{16} = 16 \\times 1$$\n$$160s + 10(1-s) = 16$$\n$$160s + 10 - 10s = 16$$\n$$150s = 16 - 10$$\n$$150s = 6$$\n$$s = \\frac{6}{150} = \\frac{1}{25} = 0.04$$\n这个值 $s=0.04$ 在指定的范围 $s \\in (0,1)$ 内，证实了它在模型中的有效性。这意味着该流程 $4\\%$ 的工作负载是严格串行的。\n\n第二步是使用这个推断出的串行比例来预测当 $P=256$ 个工作线程时的理想加速比。我们使用相同的加速比公式，代入 $s=0.04$ 和 $P=256$：\n$$S_{256} = \\frac{1}{s + \\frac{1-s}{256}} = \\frac{1}{0.04 + \\frac{1-0.04}{256}}$$\n$$S_{256} = \\frac{1}{0.04 + \\frac{0.96}{256}}$$\n\n现在，我们计算这个表达式。让我们先计算分母中的分数项：\n$$\\frac{0.96}{256} = \\frac{96 \\times 10^{-2}}{256} = \\frac{3 \\times 32}{8 \\times 32} \\times 10^{-2} = \\frac{3}{8} \\times 10^{-2} = 0.375 \\times 10^{-2} = 0.00375$$\n将其代回 $S_{256}$ 的表达式中：\n$$S_{256} = \\frac{1}{0.04 + 0.00375} = \\frac{1}{0.04375}$$\n\n为了求得数值，更精确的做法是在最后一步之前都使用分数进行计算。我们可以将分母转换为分数：\n$$0.04375 = \\frac{4375}{100000} = \\frac{7 \\times 625}{160 \\times 625} = \\frac{7}{160}$$\n所以，加速比为：\n$$S_{256} = \\frac{1}{\\frac{7}{160}} = \\frac{160}{7}$$\n\n最后，我们计算小数值，并按题目要求将其四舍五入到四位有效数字：\n$$S_{256} = \\frac{160}{7} \\approx 22.8571428...$$\n前四位有效数字是 $2$、$2$、$8$ 和 $5$。第五位有效数字是 $7$。由于 $7 \\ge 5$，我们将第四位数字（$5$）向上取整变为 $6$。\n$$S_{256} \\approx 22.86$$\n这就是在给定模型下，使用 $256$ 个工作线程可实现的理想加速比。", "answer": "$$\\boxed{22.86}$$", "id": "4538775"}]}