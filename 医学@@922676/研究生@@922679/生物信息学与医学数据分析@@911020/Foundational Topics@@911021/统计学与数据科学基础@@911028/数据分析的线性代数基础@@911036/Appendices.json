{"hands_on_practices": [{"introduction": "在分析高维生物数据时，我们常常会遇到冗余的预测变量，例如来自同一调控通路的基因表现出高度相关的表达水平。此练习 [@problem_id:4578482] 提供了一种动手实践的、由算法驱动的方法，用于识别和移除此类冗余。通过使用数值稳健的秩标准来迭代地检验线性无关性，您将为您的原始数据构建一个最小的、非冗余的特征集，这是构建稳定且可解释模型的关键一步。", "problem": "给定多个实值设计矩阵，它们代表了生物信息学和医学数据分析中使用的冗余临床预测因子。任务是为每个矩阵提取一个最小预测因子张成集，方法是移除在数值线性代数意义上线性相关的列。您的程序必须依据第一性原理和一个考虑稳定性的数值秩标准来确定线性无关性。\n\n定义和基本原理：\n- $\\mathbb{R}^m$ 中的一组列向量 $\\{\\mathbf{a}_1,\\dots,\\mathbf{a}_k\\}$ 是线性无关的，如果 $x_1 \\mathbf{a}_1 + \\dots + x_k \\mathbf{a}_k = \\mathbf{0}$ 的唯一解是 $x_1 = \\dots = x_k = 0$。等价地，矩阵 $A = [\\mathbf{a}_1 \\ \\dots \\ \\mathbf{a}_k]$ 的秩为 $k$。\n- 矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 的秩是其列空间的维度，等于 $A$ 的严格正奇异值的数量。\n- 在数值计算中，精确的零被一个数值阈值所取代。我们将数值秩 $\\operatorname{rank}_{\\tau}(A)$ 定义为严格大于容差 $\\tau$ 的奇异值 $\\sigma_i(A)$ 的数量，其中容差相对于谱范数定义为 $\\tau = 10^{-9} \\cdot \\|A\\|_2$。这里，$\\|A\\|_2$ 是 $A$ 的最大奇异值。\n\n要求的算法行为（基于原理）：\n- 从左到右（即按其给定的从索引 $0$ 到 $n-1$ 的顺序）处理每个给定矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 的列。\n- 令 $\\tau = 10^{-9} \\cdot \\|A\\|_2$ 为该矩阵的固定阈值。初始化一个空索引集 $S$ 和一个当前秩 $r = 0$。对于每个按升序排列的列索引 $j$：\n  - 形成子矩阵 $A_S$，其列是由 $S$ 索引的那些列（如果 $S$ 为空，则 $A_S$ 有零列）。计算 $r_{\\text{old}} = \\operatorname{rank}_{\\tau}(A_S)$。\n  - 通过将列 $j$ 附加到 $A_S$ 来形成增广子矩阵 $A_{S \\cup \\{j\\}}$。计算 $r_{\\text{new}} = \\operatorname{rank}_{\\tau}(A_{S \\cup \\{j\\}})$。\n  - 如果 $r_{\\text{new}}  r_{\\text{old}}$，则更新 $S \\leftarrow S \\cup \\{j\\}$ 和 $r \\leftarrow r_{\\text{new}}$；否则，跳过列 $j$，因为它在数值上依赖于已选集合。\n- 继续直到处理完所有列。得到的索引集 $S$（根据构造按升序排序）是最小张成集，其基数等于数值秩 $\\operatorname{rank}_{\\tau}(A)$，并且它张成了 $A$ 的数值列空间。\n\n测试套件：\n对于下面的每个矩阵，按照规定计算构成最小张成集 $S$ 的从零开始的升序排列的列索引列表。不涉及物理单位或角度。\n\n- 情况 $1$（冗余的高矩阵）：\n  $$\n  A_1 =\n  \\begin{bmatrix}\n  1  0  1  0  1 \\\\\n  0  1  1  0  0 \\\\\n  2  1  3  0  2 \\\\\n  0  0  0  1  2 \\\\\n  1  1  2  1  3 \\\\\n  3  1  4  1  5\n  \\end{bmatrix}\n  $$\n  其中第3列等于第1列加第2列，第5列等于第1列加2倍的第4列。\n\n- 情况 $２$（零列和重复列）：\n  $$\n  A_2 =\n  \\begin{bmatrix}\n  1  0  1  0 \\\\\n  2  0  2  1 \\\\\n  3  0  3  0 \\\\\n  4  0  4  1\n  \\end{bmatrix}\n  $$\n  其中第2列是零向量，第3列重复了第1列。\n\n- 情况 $３$（低于容差的近零列）：\n  $$\n  A_3 =\n  \\begin{bmatrix}\n  1  10^{-12}  0 \\\\\n  0  0          1 \\\\\n  0  0          0 \\\\\n  0  0          0 \\\\\n  0  0          0\n  \\end{bmatrix}\n  $$\n\n- 情况 $４$（带有组合的宽矩阵）：\n  $$\n  A_4 =\n  \\begin{bmatrix}\n  1  0  0  1  0  1 \\\\\n  0  1  0  1  1  0 \\\\\n  0  0  1  0  1  1\n  \\end{bmatrix}\n  $$\n  其中第4、5和6列是前三列的线性组合。\n\n- 情况 $５$（病态但在容差下无关）：\n  $$\n  A_5 =\n  \\begin{bmatrix}\n  1  1 \\\\\n  0  10^{-8}\n  \\end{bmatrix}\n  $$\n\n答案规范：\n- 对于每个矩阵 $A_i$，输出所选的从零开始的升序排列的列索引列表 $S_i$。\n- 将所有五个结果聚合为单行，形式为方括号括起来的、逗号分隔的列表的列表，不含空格，例如 `[[a_1,a_2],[b_1,\\dots],\\dots]`。\n- 您的程序必须生成只包含此聚合输出的一行。\n\n您的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的列表的列表形式的结果，不含空格（例如 `[[0,1,3],[0,3],[0,2],[0,1,2],[0,1]]`）。", "solution": "该问题要求从给定的设计矩阵 $A$ 中识别出一个最小的预测因子张成集。这是数据分析中的一项基本任务，通常称为特征选择或降维，其目标是消除冗余信息。规定的方法是一种贪心算法，它基于一个数值上稳健的矩阵秩定义，迭代地构建一个线性无关列的集合。\n\n其核心原理基于数值线性代数的概念。一组向量 $\\{\\mathbf{a}_1, \\dots, \\mathbf{a}_k\\}$ 是线性无关的，如果矩阵 $A = [\\mathbf{a}_1 \\ \\dots \\ \\mathbf{a}_k]$ 的秩为 $k$。在浮点运算中，计算误差使得简单地检查奇异值是否为零变得不可靠。因此，我们使用数值秩 $\\operatorname{rank}_{\\tau}(A)$ 的概念，其定义为严格大于容差 $\\tau$ 的奇异值 $\\sigma_i(A)$ 的数量。问题指定了一个相对容差：$\\tau = 10^{-9} \\cdot \\|A\\|_2$，其中 $\\|A\\|_2$ 是矩阵的谱范数，等同于其最大奇异值 $\\sigma_{\\max}(A)$。如果一列的加入增加了由所选列构成的矩阵的数值秩，则该列被视为贡献了新信息。\n\n算法流程如下：\n1.  对于给定的矩阵 $A \\in \\mathbb{R}^{m \\times n}$，我们首先通过找到 $A$ 的最大奇异值来计算其谱范数 $\\|A\\|_2$。然后将数值容差固定为 $\\tau = 10^{-9} \\cdot \\|A\\|_2$。\n2.  我们初始化一个空索引集 $S$，用于存储所选列的索引，以及一个变量 $r=0$ 用于表示所选子矩阵的当前秩。\n3.  我们从左到右遍历 $A$ 的列，索引为 $j = 0, 1, \\dots, n-1$。\n4.  对于每一列 $\\mathbf{a}_j$，我们通过将其附加到已选择的列（由 $S$ 索引）来形成一个测试矩阵。设这个增广矩阵为 $A_{S \\cup \\{j\\}}$。\n5.  我们计算这个增广矩阵的数值秩，$r_{\\text{new}} = \\operatorname{rank}_{\\tau}(A_{S \\cup \\{j\\}})$。\n6.  如果 $r_{\\text{new}} > r$，这表示相对于容差 $\\tau$，列 $\\mathbf{a}_j$ 与集合 $S$ 中的列是线性无关的。在这种情况下，我们通过添加 $j$ 来更新我们选择的索引集，即 $S \\leftarrow S \\cup \\{j\\}$，并更新当前秩，$r \\leftarrow r_{\\text{new}}$。\n7.  如果 $r_{\\text{new}} \\le r$，则列 $\\mathbf{a}_j$ 在数值上依赖于已在 $S$ 中的列，我们将其丢弃。\n8.  遍历所有列后，最终的集合 $S$ 包含了 $A$ 的列空间的一个最小张成集的从零开始的索引。\n\n让我们用情况 $1$ 的矩阵来说明这个过程：\n$$\nA_1 =\n\\begin{bmatrix}\n1  0  1  0  1 \\\\\n0  1  1  0  0 \\\\\n2  1  3  0  2 \\\\\n0  0  0  1  2 \\\\\n1  1  2  1  3 \\\\\n3  1  4  1  5\n\\end{bmatrix}\n$$\n首先，我们计算 $A_1$ 的奇异值，约等于 $\\{8.33, 2.50, 1.00, 0, 0\\}$。谱范数为 $\\|A_1\\|_2 \\approx 8.33$。容差为 $\\tau = 10^{-9} \\cdot 8.33 \\approx 8.33 \\times 10^{-9}$。我们初始化 $S = []$ 和 $r = 0$。\n\n- **对于 $j=0$**：我们测试列 $\\mathbf{a}_0$。矩阵 $[\\mathbf{a}_0]$ 的秩为 $1$。由于 $r_{\\text{new}}=1  r=0$，我们将 $0$ 添加到我们的集合中。$S \\leftarrow [0]$，$r \\leftarrow 1$。\n- **对于 $j=1$**：我们测试列 $\\mathbf{a}_1$。矩阵 $[\\mathbf{a}_0 \\ \\mathbf{a}_1]$ 的秩为 $2$，因为 $\\mathbf{a}_0$ 和 $\\mathbf{a}_1$ 是线性无关的。由于 $r_{\\text{new}}=2  r=1$，我们将 $1$ 添加到我们的集合中。$S \\leftarrow [0, 1]$，$r \\leftarrow 2$。\n- **对于 $j=2$**：我们测试列 $\\mathbf{a}_2$。已知 $\\mathbf{a}_2 = \\mathbf{a}_0 + \\mathbf{a}_1$。因此，$\\mathbf{a}_2$ 位于 $\\{\\mathbf{a}_0, \\mathbf{a}_1\\}$ 的张成空间中。矩阵 $[\\mathbf{a}_0 \\ \\mathbf{a}_1 \\ \\mathbf{a}_2]$ 的秩为 $2$。由于 $r_{\\text{new}}=2$ 并不大于 $r=2$，我们不将 $2$ 添加到我们的集合中。$S$ 仍然是 $[0, 1]$。\n- **对于 $j=3$**：我们测试列 $\\mathbf{a}_3$。可以证明矩阵 $[\\mathbf{a}_0 \\ \\mathbf{a}_1 \\ \\mathbf{a}_3]$ 的秩为 $3$。由于 $r_{\\text{new}}=3  r=2$，我们将 $3$ 添加到我们的集合中。$S \\leftarrow [0, 1, 3]$，$r \\leftarrow 3$。\n- **对于 $j=4$**：我们测试列 $\\mathbf{a}_4$。已知 $\\mathbf{a}_4 = \\mathbf{a}_0 + 2\\mathbf{a}_3$。因此，$\\mathbf{a}_4$ 位于 $\\{\\mathbf{a}_0, \\mathbf{a}_3\\}$ 的张成空间中，而这个空间是 $\\{\\mathbf{a}_0, \\mathbf{a}_1, \\mathbf{a}_3\\}$ 的张成空间的子空间。矩阵 $[\\mathbf{a}_0 \\ \\mathbf{a}_1 \\ \\mathbf{a}_3 \\ \\mathbf{a}_4]$ 的秩为 $3$。由于 $r_{\\text{new}}=3$ 并不大于 $r=3$，我们不将 $4$ 添加到我们的集合中。\n\n处理完所有列后，$A_1$ 的最终最小张成集索引为 $S_1 = [0, 1, 3]$。这个相同的过程应用于所有提供的测试矩阵。该实现使用 `numpy.linalg.svd` 来获取数值秩计算所需的奇异值。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef find_minimal_spanning_set(A: np.ndarray) - list[int]:\n    \"\"\"\n    Extracts a minimal spanning set of column indices from matrix A.\n\n    The method iteratively builds a set of linearly independent columns based\n    on a numerically robust rank criterion. A column is added if its inclusion\n    increases the numerical rank of the matrix formed by the selected columns.\n    \"\"\"\n    m, n = A.shape\n    if n == 0:\n        return []\n\n    # Calculate the spectral norm of the full matrix A to determine the tolerance.\n    # The spectral norm is the largest singular value.\n    try:\n        s_full = np.linalg.svd(A, compute_uv=False)\n        norm_A = s_full[0] if len(s_full) > 0 else 0.0\n    except np.linalg.LinAlgError:\n        norm_A = 0.0\n    \n    # Define the tolerance for numerical rank calculation.\n    tau = 1e-9 * norm_A\n\n    def get_numerical_rank(M: np.ndarray, tolerance: float) - int:\n        \"\"\"\n        Computes the numerical rank of matrix M based on a given tolerance.\n        The rank is the number of singular values greater than the tolerance.\n        \"\"\"\n        if M.shape[1] == 0:\n            return 0\n        try:\n            s_sub = np.linalg.svd(M, compute_uv=False)\n            return np.sum(s_sub > tolerance)\n        except np.linalg.LinAlgError:\n            return 0\n\n    selected_indices = []\n    current_rank = 0\n\n    # Iterate through each column index from left to right.\n    for j in range(n):\n        # Form a temporary matrix by augmenting the current set with the new column.\n        potential_indices = selected_indices + [j]\n        A_augmented = A[:, potential_indices]\n        \n        # Calculate the numerical rank of the augmented matrix.\n        new_rank = get_numerical_rank(A_augmented, tau)\n        \n        # If the rank increases, the new column is linearly independent.\n        if new_rank > current_rank:\n            selected_indices.append(j)\n            current_rank = new_rank\n            \n    return selected_indices\n\ndef solve():\n    \"\"\"\n    Defines the test cases, runs the algorithm, and prints the formatted result.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    A1 = np.array([\n        [1., 0., 1., 0., 1.],\n        [0., 1., 1., 0., 0.],\n        [2., 1., 3., 0., 2.],\n        [0., 0., 0., 1., 2.],\n        [1., 1., 2., 1., 3.],\n        [3., 1., 4., 1., 5.]\n    ], dtype=np.float64)\n\n    A2 = np.array([\n        [1., 0., 1., 0.],\n        [2., 0., 2., 1.],\n        [3., 0., 3., 0.],\n        [4., 0., 4., 1.]\n    ], dtype=np.float64)\n    \n    A3 = np.array([\n        [1., 1e-12, 0.],\n        [0., 0.,    1.],\n        [0., 0.,    0.],\n        [0., 0.,    0.],\n        [0., 0.,    0.]\n    ], dtype=np.float64)\n\n    A4 = np.array([\n        [1., 0., 0., 1., 0., 1.],\n        [0., 1., 0., 1., 1., 0.],\n        [0., 0., 1., 0., 1., 1.]\n    ], dtype=np.float64)\n\n    A5 = np.array([\n        [1., 1.],\n        [0., 1e-8]\n    ], dtype=np.float64)\n\n    test_cases = [A1, A2, A3, A4, A5]\n\n    results = []\n    for A in test_cases:\n        result = find_minimal_spanning_set(A)\n        results.append(result)\n\n    # The final print statement must match the specified format exactly:\n    # a bracketed, comma-separated list of lists with no spaces.\n    # The str() function on a list of lists includes spaces, e.g., '[[0, 1], [2]]'.\n    # We remove these spaces to match the required format '[[0,1],[2]]'.\n    print(str(results).replace(' ', ''))\n\nsolve()\n```", "id": "4578482"}, {"introduction": "在我们有了一组特征之后，一个强有力的下一步是识别数据内部变化的主要模式。这是主成分分析 (PCA) 的目标，该技术的计算核心是奇异值分解 (SVD)。这项实践 [@problem_id:4578458] 将指导您推导并计算由前导奇异值所捕获的总方差比例，这是一个决定降维效果的关键量度。", "problem": "给定面向列的基因表达矩阵，这些矩阵用于生物信息学和医学数据分析，以总结信使核糖核酸 (mRNA) 在不同样本中的丰度。计算任务是，从线性代数和统计学的基础定义出发，量化通过截断奇异值分解 (SVD) 获得的前 $k$ 个奇异值捕获了多少总样本方差。您的实现必须严格遵循一个从第一性原理推导出的算法：计算列中心化数据矩阵，获取其 SVD，并确定由前导的 $k$ 个奇异值解释的方差比例。除标准定义外，不要假设任何预先存在的公式。\n\n使用的基础理论：\n- 列中心化数据矩阵的样本协方差矩阵定义：对于一个数据矩阵 $X \\in \\mathbb{R}^{n \\times p}$，其中 $n$ 是样本数， $p$ 是基因数，通过从每列中减去其样本均值来定义列中心化矩阵 $X_c$。样本协方差矩阵为 $S = \\frac{1}{n - 1} X_c^\\top X_c$。\n- 实数矩阵的奇异值分解 (SVD)：对于 $X_c \\in \\mathbb{R}^{n \\times p}$，其 SVD 为 $X_c = U \\Sigma V^\\top$，其中 $U \\in \\mathbb{R}^{n \\times r}$ 和 $V \\in \\mathbb{R}^{p \\times r}$ 具有标准正交列，$\\Sigma = \\operatorname{diag}(\\sigma_1, \\dots, \\sigma_r)$，奇异值为 $\\sigma_1 \\ge \\sigma_2 \\ge \\dots \\ge \\sigma_r \\ge 0$，且 $r = \\operatorname{rank}(X_c)$。\n- 弗罗贝尼乌斯范数恒等式：$\\|X_c\\|_F^2 = \\sum_{i=1}^{r} \\sigma_i^2$。\n\n您的程序必须：\n- 对于每个测试用例，将输入矩阵 $X$ 的列进行中心化以获得 $X_c$（减去每列的均值；不进行缩放）。\n- 计算 $X_c$ 的 SVD 以获得奇异值 $\\sigma_1, \\dots, \\sigma_r$。\n- 将级别为 $k$ 的截断 SVD 定义为保留前 $k$ 个奇异值和相应的奇异向量。为了稳健地处理数值秩，令有效秩 $r$ 为满足 $\\sigma_i  \\tau$ 的奇异值的数量，其中 $\\tau$ 是一个基于维度和机器精度的容差。如果 $k  r$，则使用 $k_{\\text{eff}} = r$。如果 $k = 0$，则解释的比例必须为 $0$。\n- 仅使用上述基础恒等式，计算由前 $k_{\\text{eff}}$ 个奇异值解释的方差比例，结果为小数（而非百分比），即前 $k_{\\text{eff}}$ 个奇异值的平方和与所有 $r$ 个奇异值的平方和之比。\n\n角度单位不适用。物理单位不适用。所有输出必须是小数形式。\n\n测试套件：\n对于下面的每个测试用例，$X$ 是原始表达矩阵，$k$ 是截断级别。在计算 SVD 之前，您必须对 $X$ 的列进行中心化。矩阵如下：\n\n- 案例 1 (正常情况，高矩阵，中等 $k$):\n$$\nX^{(1)} =\n\\begin{bmatrix}\n2  0  1 \\\\\n0  1  3 \\\\\n4  2  5 \\\\\n6  3  6\n\\end{bmatrix}, \\quad k^{(1)} = 2.\n$$\n\n- 案例 2 (边界情况 $k = 0$):\n$$\nX^{(2)} =\n\\begin{bmatrix}\n10  0  -2  3 \\\\\n5  1  0  0 \\\\\n0  -1  2  -3\n\\end{bmatrix}, \\quad k^{(2)} = 0.\n$$\n\n- 案例 3 (宽矩阵，冗余列和常数列；$k$ 超过秩):\n$$\nX^{(3)} =\n\\begin{bmatrix}\n1  1  5  0  -1 \\\\\n2  2  5  1  0 \\\\\n3  3  5  2  1\n\\end{bmatrix}, \\quad k^{(3)} = 3.\n$$\n\n- 案例 4 (带有一个零列的高矩阵，非平凡秩):\n$$\nX^{(4)} =\n\\begin{bmatrix}\n0  1  0  -1 \\\\\n0  2  1  0 \\\\\n0  3  2  1 \\\\\n0  4  3  2 \\\\\n0  5  4  3\n\\end{bmatrix}, \\quad k^{(4)} = 2.\n$$\n\n- 案例 5 (列之间存在精确的线性相关性；$k$ 等于秩):\n$$\nX^{(5)} =\n\\begin{bmatrix}\n1  2  5 \\\\\n2  4  10 \\\\\n3  6  15 \\\\\n4  8  20\n\\end{bmatrix}, \\quad k^{(5)} = 2.\n$$\n\n数值秩容差：\n使用一个数值稳定的容差 $\\tau$ 来判断哪些奇异值应被视为非零。选择 $\\tau = \\max(n, p) \\cdot \\sigma_{\\max} \\cdot \\varepsilon$，其中 $n$ 和 $p$ 是 $X_c$ 的维度，$\\sigma_{\\max}$ 是 $X_c$ 的最大奇异值，$\\varepsilon$ 是 64 位浮点运算的机器 epsilon。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，每个比例都四舍五入到 8 位小数，表示为 $[0, 1]$ 区间内的小数。例如，一个有效的输出看起来像 $[r_a,r_b,r_c,r_d,r_e]$，其中每个 $r_\\cdot$ 都是一个小数。\n\n您的程序必须是自包含的，使用指定的测试套件，并产生上述单行输出。", "solution": "问题要求我们计算列中心化数据矩阵的前 $k$ 个奇异值所捕获的总样本方差的比例。这个量是主成分分析 (PCA) 的核心，用于评估降维的质量。解决方案将从所提供的基础定义中推导得出。\n\n设给定的原始数据矩阵为 $X \\in \\mathbb{R}^{n \\times p}$，其中有 $n$ 个样本（行）和 $p$ 个特征或基因（列）。\n\n首先，我们通过从每列的元素中减去该列的均值来对数据进行中心化。设 $\\bar{x}_j = \\frac{1}{n} \\sum_{i=1}^{n} X_{ij}$ 为第 $j$ 列的均值。列中心化矩阵 $X_c$ 的元素为 $(X_c)_{ij} = X_{ij} - \\bar{x}_j$。\n\n总样本方差 $\\text{Var}_{\\text{total}}$ 是每个特征样本方差的总和。这等价于样本协方差矩阵 $S$ 的迹。问题将样本协方差矩阵定义为 $S = \\frac{1}{n - 1} X_c^\\top X_c$。\n利用迹算子的线性性质，总方差为：\n$$\n\\text{Var}_{\\text{total}} = \\operatorname{tr}(S) = \\operatorname{tr}\\left(\\frac{1}{n-1} X_c^\\top X_c\\right) = \\frac{1}{n - 1} \\operatorname{tr}(X_c^\\top X_c)\n$$\n迹的一个基本性质是 $\\operatorname{tr}(A^\\top A)$ 等于 $A$ 的弗罗贝尼乌斯范数的平方，即 $\\|A\\|_F^2 = \\sum_{i,j} A_{ij}^2$。因此，我们有：\n$$\n\\text{Var}_{\\text{total}} = \\frac{1}{n - 1} \\|X_c\\|_F^2\n$$\n问题提供了一个关键的恒等式，将弗罗贝尼乌斯范数与 $X_c$ 的奇异值联系起来。设 $X_c$ 的奇异值分解 (SVD) 为 $X_c = U \\Sigma V^\\top$，其中奇异值 $\\sigma_1 \\ge \\sigma_2 \\ge \\dots \\ge \\sigma_r  0$ 是 $\\Sigma$ 的对角线元素，且 $r = \\operatorname{rank}(X_c)$。该恒等式为：\n$$\n\\|X_c\\|_F^2 = \\sum_{i=1}^{r} \\sigma_i^2\n$$\n将此代入我们的总方差表达式中，得到：\n$$\n\\text{Var}_{\\text{total}} = \\frac{1}{n - 1} \\sum_{i=1}^{r} \\sigma_i^2\n$$\n数据的主成分是矩阵 $Z = X_c V$ 的列。第 $i$ 个主成分的方差与第 $i$ 个奇异值的平方直接相关：$\\text{Var}(Z_i) = \\frac{\\sigma_i^2}{n - 1}$。由前 $k$ 个主成分解释的总方差是它们各自方差的总和：\n$$\n\\text{Var}_k = \\sum_{i=1}^{k} \\text{Var}(Z_i) = \\sum_{i=1}^{k} \\frac{\\sigma_i^2}{n - 1} = \\frac{1}{n - 1} \\sum_{i=1}^{k} \\sigma_i^2\n$$\n由前 $k$ 个成分解释的方差比例是它们捕获的方差 $\\text{Var}_k$ 与总方差 $\\text{Var}_{\\text{total}}$ 的比值。\n$$\nP_k = \\frac{\\text{Var}_k}{\\text{Var}_{\\text{total}}} = \\frac{\\frac{1}{n-1} \\sum_{i=1}^{k} \\sigma_i^2}{\\frac{1}{n-1} \\sum_{i=1}^{r} \\sigma_i^2} = \\frac{\\sum_{i=1}^{k} \\sigma_i^2}{\\sum_{i=1}^{r} \\sigma_i^2}\n$$\n因子 $\\frac{1}{n-1}$ 被约掉，表明方差比例可以直接从奇异值的平方计算得出。这个推导出的公式为我们的算法提供了基础。\n\n计算算法如下：\n1.  对于每个输入矩阵 $X \\in \\mathbb{R}^{n \\times p}$ 和整数 $k$，计算列中心化矩阵 $X_c$。\n2.  使用 SVD 计算 $X_c$ 的奇异值 $\\sigma_i$。\n3.  为处理数值精度问题，确定有效秩 $r$。如果奇异值 $\\sigma_i  \\tau$，则认为其非零，其中容差 $\\tau$ 定义为 $\\tau = \\max(n, p) \\cdot \\sigma_{\\max} \\cdot \\varepsilon$。这里，$\\sigma_{\\max}$ 是最大奇异值，$\\varepsilon$ 是所用浮点精度的机器 epsilon。有效秩 $r$ 是超过 $\\tau$ 的奇异值的数量。\n4.  要考虑的成分数量 $k_{\\text{eff}}$ 根据秩进行调整。如果 $k=0$，则比例为 $0$。否则，$k_{\\text{eff}} = \\min(k, r)$。\n5.  最终比例使用推导出的公式计算：\n    $$\n    P_{k_{\\text{eff}}} = \\frac{\\sum_{i=1}^{k_{\\text{eff}}} \\sigma_i^2}{\\sum_{i=1}^{r} \\sigma_i^2}\n    $$\n    其中求和是针对在步骤 3 中被视为非零的奇异值的平方。如果分母为零（即中心化矩阵的方差为零），则比例为 $0$。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the proportion of variance explained by the first k singular values\n    for a list of test cases according to the derived formula.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (happy path, tall matrix, moderate k)\n        (np.array([\n            [2, 0, 1],\n            [0, 1, 3],\n            [4, 2, 5],\n            [6, 3, 6]\n        ], dtype=float), 2),\n        \n        # Case 2 (boundary k = 0)\n        (np.array([\n            [10, 0, -2, 3],\n            [5, 1, 0, 0],\n            [0, -1, 2, -3]\n        ], dtype=float), 0),\n\n        # Case 3 (wide matrix, redundant and constant columns; k exceeds rank)\n        (np.array([\n            [1, 1, 5, 0, -1],\n            [2, 2, 5, 1, 0],\n            [3, 3, 5, 2, 1]\n        ], dtype=float), 3),\n\n        # Case 4 (tall matrix with a zero column, nontrivial rank)\n        (np.array([\n            [0, 1, 0, -1],\n            [0, 2, 1, 0],\n            [0, 3, 2, 1],\n            [0, 4, 3, 2],\n            [0, 5, 4, 3]\n        ], dtype=float), 2),\n\n        # Case 5 (exact linear dependence among columns; k equals rank)\n        (np.array([\n            [1, 2, 5],\n            [2, 4, 10],\n            [3, 6, 15],\n            [4, 8, 20]\n        ], dtype=float), 2)\n    ]\n\n    results = []\n    \n    for X, k in test_cases:\n        n, p = X.shape\n        \n        # Handle case with no rows, which implies no variance.\n        if n == 0:\n            results.append(0.0)\n            continue\n            \n        # Step 1: Center the columns of the input matrix X.\n        X_c = X - X.mean(axis=0)\n\n        # Step 2: Compute the SVD of the centered matrix X_c. Only singular values are needed.\n        try:\n            sigma = np.linalg.svd(X_c, compute_uv=False)\n        except np.linalg.LinAlgError:\n            # In case of a failure, assume zero variance.\n            results.append(0.0)\n            continue\n\n        # Handle matrices that result in no singular values (e.g., zero columns/rows).\n        if sigma.size == 0:\n            results.append(0.0)\n            continue\n\n        # Step 3: Determine the numerical rank r using the specified tolerance.\n        eps = np.finfo(X.dtype).eps\n        sigma_max = sigma[0]\n        tolerance = max(n, p) * sigma_max * eps\n        \n        # Filter for singular values greater than the tolerance.\n        sigma_effective = sigma[sigma > tolerance]\n        r = len(sigma_effective)\n        \n        # Step 4: Handle k and calculate the proportion of variance.\n        # If k is 0, the proportion must be 0.\n        if k == 0:\n            proportion = 0.0\n        else:\n            # Effective k cannot exceed the rank.\n            k_eff = min(k, r)\n            \n            # Use the squared effective singular values for variance calculations.\n            sigma_sq_effective = sigma_effective**2\n            \n            # The denominator is the sum of all effective squared singular values.\n            total_variance_proxy = np.sum(sigma_sq_effective)\n\n            if total_variance_proxy  1e-15: # Check for near-zero total variance.\n                # If total variance is zero, no variance can be explained.\n                proportion = 0.0\n            else:\n                # The numerator is the sum of the first k_eff squared singular values.\n                explained_variance_proxy = np.sum(sigma_sq_effective[:k_eff])\n                proportion = explained_variance_proxy / total_variance_proxy\n                \n        results.append(round(proportion, 8))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "4578458"}, {"introduction": "数据分析的一个主要目标是构建预测模型，而线性回归是一个基础工具。虽然经典的正规方程提供了一个简洁的解，但在存在共线或近共线特征的情况下，它们在数值上会变得不稳定。此练习 [@problem_id:4578463] 探索了一种更稳健的替代方案，即使用 SVD 构建 Moore-Penrose 伪逆，从而为所有情况下的最小二乘问题提供稳定的解，并突显其在实际数据分析场景中的优势。", "problem": "考虑一个线性模型，其中给定了设计矩阵 $X \\in \\mathbb{R}^{m \\times p}$ 和结果向量 $y \\in \\mathbb{R}^{m}$。在生物信息学和医学数据分析中，当对基因表达特征与表型测量之间的关系进行建模时，就会出现此类矩阵。从线性代数的基本定义出发，使用奇异值分解 (SVD) 构建 Moore–Penrose 伪逆 $X^{+}$ 并计算最小二乘解 $X^{+} y$。当 $X^{\\top} X$ 可逆时，还需计算唯一的正规方程解。设计您的程序以实现以下功能：\n\n- 使用 SVD 从第一性原理出发推导 $X^{+}$，并采用一个具有数值合理性的阈值来判断哪些奇异值应被视为非零。\n- 根据 $X$ 的列秩判断 $X^{\\top} X$ 是否可逆。\n- 如果 $X^{\\top} X$ 可逆，计算正规方程解，并通过其与 $X^{+} y$ 差值的欧几里得范数进行比较。\n- 在所有情况下，计算残差 $X (X^{+} y) - y$ 的欧几里得范数。\n\n仅使用经过充分检验的结论：矩阵分解的定义、正交矩阵的性质以及线性系统的可解性条件。不要使用任何未经证明的捷径。\n\n您的程序必须实现并评估以下参数值测试套件。每个 $X$ 和 $y$ 都明确给出：\n\n1. 理想情况（高矩阵，满列秩）：\n   $$X_1 = \\begin{bmatrix}\n   2  -1  3 \\\\\n   0  4  5 \\\\\n   1  2  -2 \\\\\n   3  -5  1 \\\\\n   4  0  -1\n   \\end{bmatrix}, \\quad\n   y_1 = \\begin{bmatrix}\n   1 \\\\ 0 \\\\ -1 \\\\ 2 \\\\ 3\n   \\end{bmatrix}.$$\n\n2. 病态但 $X^{\\top} X$ 可逆（近共线性）：\n   $$X_2 = \\begin{bmatrix}\n   1  2.0001  0 \\\\\n   2  4.0002  1 \\\\\n   3  6.0003  0 \\\\\n   4  8.0004  1 \\\\\n   5  10.0005  0\n   \\end{bmatrix}, \\quad\n   y_2 = \\begin{bmatrix}\n   1 \\\\ 1 \\\\ 2 \\\\ 3 \\\\ 5\n   \\end{bmatrix}.$$\n\n3. 秩亏（正规方程不适用）：\n   $$X_3 = \\begin{bmatrix}\n   1  0  0 \\\\\n   0  1  1 \\\\\n   1  0  0 \\\\\n   0  1  1\n   \\end{bmatrix}, \\quad\n   y_3 = \\begin{bmatrix}\n   1 \\\\ 2 \\\\ 3 \\\\ 4\n   \\end{bmatrix}.$$\n\n4. 方阵且可逆：\n   $$X_4 = \\begin{bmatrix}\n   3  0  1 \\\\\n   2  -1  0 \\\\\n   1  2  4\n   \\end{bmatrix}, \\quad\n   y_4 = \\begin{bmatrix}\n   0 \\\\ 1 \\\\ 2\n   \\end{bmatrix}.$$\n\n为保证数值稳健性，基于 SVD 的伪逆应使用阈值 $\\tau = \\max(m, p) \\cdot \\varepsilon \\cdot \\sigma_{\\max}$，其中 $\\varepsilon$ 是双精度浮点数的机器精度，$\\sigma_{\\max}$ 是 $X$ 的最大奇异值。严格大于 $\\tau$ 的奇异值将被求倒数；其他奇异值则视为零。\n\n将每个测试用例的最终输出定义为一个包含三个条目的列表：\n- 表示正规方程计算是否适用（即 $X^{\\top} X$ 是否可逆）的布尔值。\n- 基于 SVD 的解与正规方程解之间差值的欧几里得范数（如果适用）的浮点数；如果不适用，则为浮点数 $-1.0$。\n- 残差 $X (X^{+} y) - y$ 的欧几里得范数的浮点数。\n\n您的程序应生成单行输出，其中包含由这些按测试用例组织的列表组成的逗号分隔列表，并用方括号括起来。例如，输出格式必须是：\n$$\\texttt{[[b\\_1,d\\_1,r\\_1],[b\\_2,d\\_2,r\\_2],[b\\_3,d\\_3,r\\_3],[b\\_4,d\\_4,r\\_4]]}.$$\n不涉及物理单位或角度单位；所有量均为无量纲实数。", "solution": "对所提供问题的分析分两个阶段进行：首先，验证问题陈述；其次，基于线性代数的第一性原理详细推导求解方法。\n\n### 问题验证\n\n**1. 提取已知条件：**\n- **模型**：由设计矩阵 $X \\in \\mathbb{R}^{m \\times p}$ 和结果向量 $y \\in \\mathbb{R}^{m}$ 定义的线性系统。\n- **目标**：计算使 $\\|X\\beta - y\\|_2$ 最小化的最小二乘解 $\\hat{\\beta}$。\n- **方法1（SVD伪逆）**：计算 $\\hat{\\beta}_{SVD} = X^{+}y$，其中 Moore-Penrose 伪逆 $X^{+}$ 由 $X$ 的奇异值分解 (SVD) 构建。\n- **方法2（正规方程）**：当且仅当 $X^{\\top}X$ 可逆时，计算 $\\hat{\\beta}_{NE} = (X^{\\top}X)^{-1}X^{\\top}y$。\n- **SVD 的数值阈值**：如果奇异值 $\\sigma_i  \\tau$，则将其视为非零，其中 $\\tau = \\max(m, p) \\cdot \\varepsilon \\cdot \\sigma_{\\max}$。这里，$\\varepsilon$ 是双精度浮点数的机器精度，$\\sigma_{\\max}$ 是 $X$ 的最大奇异值。\n- **可逆性判据**：如果使用阈值 $\\tau$ 在数值上确定的 $X$ 的列秩等于 $p$，则矩阵 $X^{\\top}X$ 被视为可逆。\n- **每个测试用例的要求输出**：一个包含三个值的列表：\n    1. 一个布尔值，指示正规方程方法是否适用（即 $X^{\\top}X$ 是否可逆）。\n    2. SVD 解与正规方程解之差的欧几里得范数 $\\|\\hat{\\beta}_{SVD} - \\hat{\\beta}_{NE}\\|_2$。如果正规方程方法不适用，此值为 $-1.0$。\n    3. SVD 解的残差向量的欧几里得范数 $\\|X\\hat{\\beta}_{SVD} - y\\|_2$。\n- **测试数据**：提供了四对特定的 $(X, y)$ 用于评估。\n\n**2. 验证结论：**\n问题是 **有效的**。\n- 它 **有科学依据**，植根于线性代数和数值分析的基本原理，特别是关于线性最小二乘问题的求解。\n- 它是 **良定的**，所有必要的数据、定义和数值标准都已明确提供，以便计算出唯一且有意义的解。\n- 它是 **客观的**，以精确的数学术语陈述，没有歧义或主观论断。\n- 问题背景（生物信息学和医学数据分析）是恰当的，因为线性模型是这些领域的基石。所有指定的条件和数据在数学上和计算上都是合理的。\n\n### 求解推导\n\n该问题要求对解决线性最小二乘问题的两种方法进行比较分析，这对于数据建模至关重要。目标是找到一个参数向量 $\\beta \\in \\mathbb{R}^p$，通过设计矩阵 $X \\in \\mathbb{R}^{m \\times p}$ 的线性变换，最好地解释观测到的结果 $y \\in \\mathbb{R}^m$。“最好”的定义是最小化误差平方和，即最小化残差向量的欧几里得范数的平方。\n\n**最小二乘问题**\n目标是找到向量 $\\hat{\\beta}$，它能解决以下最小化问题：\n$$ \\hat{\\beta} = \\arg\\min_{\\beta \\in \\mathbb{R}^p} \\| y - X\\beta \\|_2^2 $$\n平方范数可以表示为二次型：\n$$ L(\\beta) = (y - X\\beta)^{\\top}(y - X\\beta) = y^{\\top}y - 2\\beta^{\\top}X^{\\top}y + \\beta^{\\top}X^{\\top}X\\beta $$\n这是关于 $\\beta$ 的凸函数，其最小值可以通过将其关于 $\\beta$ 的梯度设为零向量来找到。\n$$ \\nabla_{\\beta} L(\\beta) = -2X^{\\top}y + 2X^{\\top}X\\beta = 0 $$\n这就得到了著名的 **正规方程**：\n$$ X^{\\top}X\\beta = X^{\\top}y $$\n\n**方法1：正规方程解**\n矩阵 $X^{\\top}X$ 是一个 $p \\times p$ 的方阵。如果该矩阵可逆，则存在唯一的 $\\beta$ 解，由下式给出：\n$$ \\hat{\\beta}_{NE} = (X^{\\top}X)^{-1}X^{\\top}y $$\n线性代数中的一个核心定理指出，$X^{\\top}X$ 可逆当且仅当矩阵 $X$ 的列线性无关。这等价于说 $X$ 具有满列秩，即 $\\text{rank}(X) = p$。当这些条件不满足时（即当列是共线的或系统是欠定的），$X^{\\top}X$ 是奇异的，该方法失效。此外，即使 $X^{\\top}X$ 理论上可逆，如果 $X$ 的列近似共线，它也可能是病态的。在这种情况下，显式计算逆矩阵会放大数值误差。\n\n**方法2：SVD 与 Moore-Penrose 伪逆解**\n奇异值分解 (SVD) 为分析线性系统提供了一个强大且数值稳健的框架。任何矩阵 $X \\in \\mathbb{R}^{m \\times p}$ 都可以分解为：\n$$ X = U \\Sigma V^{\\top} $$\n其中：\n- $U$ 是一个 $m \\times m$ 的正交矩阵，其列 ($u_i$) 是左奇异向量。\n- $V$ 是一个 $p \\times p$ 的正交矩阵，其列 ($v_i$) 是右奇异向量。\n- $\\Sigma$ 是一个 $m \\times p$ 的矩形对角矩阵，按降序包含非负奇异值 $\\sigma_i$。非零奇异值的数量等于 $X$ 的秩。\n\n利用 SVD，$X$ 的 Moore-Penrose 伪逆 $X^{+}$ 被唯一定义为：\n$$ X^{+} = V \\Sigma^{+} U^{\\top} $$\n其中 $\\Sigma^{+}$ 是一个从 $\\Sigma$ 推导出的 $p \\times m$ 矩阵。它的构造方法是先取 $\\Sigma$ 的转置，然后对每个非零奇异值取倒数。在有限精度算术中，我们必须使用一个阈值 $\\tau = \\max(m, p) \\cdot \\varepsilon \\cdot \\sigma_{\\max}$ 来判断哪些奇异值在数值上是非零的。因此，$\\Sigma^{+}$ 对角线上的元素，记为 $\\sigma_i^{+}$，为：\n$$ \\sigma_i^{+} = \\begin{cases} 1/\\sigma_i  \\text{if } \\sigma_i  \\tau \\\\ 0  \\text{if } \\sigma_i \\le \\tau \\end{cases} $$\n矩阵的秩被数值上估计为大于 $\\tau$ 的奇异值的数量。正规方程的适用条件 $\\text{rank}(X) = p$，就是用这个数值秩来检查的。\n\n基于 SVD 的最小二乘解由下式给出：\n$$ \\hat{\\beta}_{SVD} = X^{+}y = (V \\Sigma^{+} U^{\\top})y $$\n这个解总是存在的。它提供了唯一的最小范数最小二乘解，这意味着在所有最小化 $\\|X\\beta - y\\|_2$ 的向量 $\\beta$ 中，$\\hat{\\beta}_{SVD}$ 是具有最小欧几里得范数 $\\|\\beta\\|_2$ 的那一个。\n\n**算法步骤**\n对于每个给定的对 $(X, y)$，执行以下步骤：\n1.  从 $X$ 获取维度 $m$ 和 $p$。\n2.  计算 $X$ 的 SVD，得到 $U$、奇异值向量 $s$ 和 $V^{\\top}$。为提高效率，使用经济型 SVD。\n3.  确定数值阈值 $\\tau = \\max(m, p) \\cdot \\varepsilon \\cdot \\sigma_{\\max}$，其中 $\\sigma_{\\max} = s[0]$。\n4.  通过计算大于 $\\tau$ 的奇异值 $s_i$ 的数量来确定数值秩 $r_{eff}$。\n5.  如果 $r_{eff} = p$，则将布尔值 `is_normal_eq_applicable` 设为 `True`，否则设为 `False`。\n6.  计算 SVD 解 $\\hat{\\beta}_{SVD}$。这可以通过 $\\hat{\\beta}_{SVD} = V(\\Sigma^{+}(U^{\\top}y))$ 高效完成，其中操作是逐向量执行的，无需显式构造矩阵 $\\Sigma^{+}$。\n7.  如果 `is_normal_eq_applicable` 为 `True`：\n    a. 计算正规方程解 $\\hat{\\beta}_{NE} = (X^{\\top}X)^{-1}X^{\\top}y$。\n    b. 计算 `difference_norm` 作为欧几里得范数 $\\|\\hat{\\beta}_{SVD} - \\hat{\\beta}_{NE}\\|_2$。\n8.  如果 `is_normal_eq_applicable` 为 `False`，则将 `difference_norm` 设为 $-1.0$。\n9.  在所有情况下，计算残差向量的范数 `residual_norm` = $\\|X\\hat{\\beta}_{SVD} - y\\|_2$。\n10. 存储结果三元组（`is_normal_eq_applicable`, `difference_norm`, `residual_norm`）。\n\n该过程将应用于所有四个测试用例，以生成最终输出。", "answer": "```python\nimport numpy as np\n\ndef solve_least_squares_case(X, y):\n    \"\"\"\n    Solves a linear least-squares problem using SVD and Normal Equations,\n    and returns the specified comparison metrics.\n\n    Args:\n        X (np.ndarray): The m x p design matrix.\n        y (np.ndarray): The m-dimensional outcome vector.\n\n    Returns:\n        list: A list containing [is_normal_eq_applicable, difference_norm, residual_norm].\n    \"\"\"\n    m, p = X.shape\n\n    # 1. Compute SVD and determine numerical rank\n    try:\n        U, s, Vt = np.linalg.svd(X, full_matrices=False)\n    except np.linalg.LinAlgError:\n        # Handle cases where SVD might fail, though unlikely for real matrices\n        return [False, -1.0, np.linalg.norm(y)]\n\n    # Get machine epsilon for double precision\n    eps = np.finfo(np.float64).eps\n    \n    # Set the threshold for singular values\n    sigma_max = s[0] if s.size > 0 else 0\n    tau = max(m, p) * eps * sigma_max\n\n    # Determine numerical rank\n    rank = np.sum(s > tau)\n    is_normal_eq_applicable = (rank == p)\n\n    # 2. Compute the SVD-based least-squares solution beta_svd = X_plus @ y\n    # X_plus = V @ np.diag(s_inv) @ U.T\n    # beta_svd = V @ np.diag(s_inv) @ U.T @ y\n    s_inv = np.zeros_like(s)\n    s_inv[s > tau] = 1.0 / s[s > tau]\n    \n    # Efficient computation of beta_svd\n    uty = U.T @ y\n    beta_svd = Vt.T @ (s_inv * uty)\n\n    # 3. Compute normal equation solution if applicable\n    difference_norm = -1.0\n    if is_normal_eq_applicable:\n        try:\n            XTX = X.T @ X\n            XTX_inv = np.linalg.inv(XTX)\n            XTy = X.T @ y\n            beta_ne = XTX_inv @ XTy\n            difference_norm = np.linalg.norm(beta_svd - beta_ne)\n        except np.linalg.LinAlgError:\n            # If XTX is singular despite rank check (extreme ill-conditioning),\n            # consider normal equations as not applicable in practice.\n            is_normal_eq_applicable = False\n            difference_norm = -1.0\n\n    # In case of LinAlgError inside the if block, we need to ensure the values are correct.\n    if difference_norm == -1.0:\n        is_normal_eq_applicable = False\n\n\n    # 4. Compute the residual norm for the SVD solution\n    residual_vec = X @ beta_svd - y\n    residual_norm = np.linalg.norm(residual_vec)\n    \n    return [is_normal_eq_applicable, difference_norm, residual_norm]\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    X1 = np.array([\n        [2, -1, 3],\n        [0, 4, 5],\n        [1, 2, -2],\n        [3, -5, 1],\n        [4, 0, -1]\n    ], dtype=np.float64)\n    y1 = np.array([1, 0, -1, 2, 3], dtype=np.float64)\n\n    X2 = np.array([\n        [1, 2.0001, 0],\n        [2, 4.0002, 1],\n        [3, 6.0003, 0],\n        [4, 8.0004, 1],\n        [5, 10.0005, 0]\n    ], dtype=np.float64)\n    y2 = np.array([1, 1, 2, 3, 5], dtype=np.float64)\n\n    X3 = np.array([\n        [1, 0, 0],\n        [0, 1, 1],\n        [1, 0, 0],\n        [0, 1, 1]\n    ], dtype=np.float64)\n    y3 = np.array([1, 2, 3, 4], dtype=np.float64)\n\n    X4 = np.array([\n        [3, 0, 1],\n        [2, -1, 0],\n        [1, 2, 4]\n    ], dtype=np.float64)\n    y4 = np.array([0, 1, 2], dtype=np.float64)\n\n    test_cases = [\n        (X1, y1),\n        (X2, y2),\n        (X3, y3),\n        (X4, y4),\n    ]\n\n    results = []\n    for X, y in test_cases:\n        result = solve_least_squares_case(X, y)\n        results.append(result)\n\n    # Format the output string as required by the problem, without spaces.\n    print(str(results).replace(\" \", \"\"))\n\nsolve()\n```", "id": "4578463"}]}