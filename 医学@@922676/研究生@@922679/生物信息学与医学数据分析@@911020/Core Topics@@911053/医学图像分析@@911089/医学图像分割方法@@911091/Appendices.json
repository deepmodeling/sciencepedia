{"hands_on_practices": [{"introduction": "医学扫描（如MRI）通常具有各向异性的体素间距，这意味着不同轴向的分辨率不同。本练习将指导你如何为三维卷积神经网络（3D CNN）设计输入图像块，以同时满足网络架构对输入尺寸的要求，并确保物理视场（Field of View）的各向同性，这是处理真实世界医学数据的关键第一步。[@problem_id:4582642]", "problem": "一个用于腹部器官分割的三维磁共振成像（3D MRI）数据集是以各向异性体素间距采集的，其中平面内间距为 $s_{x} = 0.9\\,\\text{mm}$ 和 $s_{y} = 0.9\\,\\text{mm}$，平面间间距为 $s_{z} = 4.5\\,\\text{mm}$。一个基于U-Net架构的三维卷积神经网络（3D CNN）将使用从该数据体中提取的区块（patch）进行训练。编码器使用三个下采样阶段，每个阶段沿 $(x,y,z)$ 轴的步幅为 $(2, 2, 1)$，并且所有卷积都使用步幅为 $1$ 和“same”填充。为确保在所有金字塔层级上特征图维度的一致性，沿 $x$ 和 $y$ 轴的区块维度 $P_x$ 和 $P_y$ 必须能被 $2^{3}$ 整除，而 $z$ 维度 $P_z$ 没有来自下采样的整除性约束。\n\n设计一个区块，使其物理视场（FOV）在各轴向上是各向同性的，并满足捕获足够解剖学上下文的最小物理范围要求。具体来说，设以体素为单位的区块维度为 $(P_{x}, P_{y}, P_{z})$，并要求：\n- $P_{x} s_{x} = P_{y} s_{y} = P_{z} s_{z}$ (各向同性物理视场)，\n- $P_{x} s_{x} \\geq 72\\,\\text{mm}$ (最小物理视场)，\n- $P_x$ 和 $P_y$ 可被 $2^3$ 整除。\n\n在这些约束条件下，确定满足所有条件的以体素为单位的最小整数三元组 $(P_{x}, P_{y}, P_{z})$。使用 LaTeX $\\texttt{pmatrix}$ 环境将最终答案表示为行矩阵。无需四舍五入，最终答案框中不应包含任何单位。", "solution": "问题是确定用于训练三维卷积神经网络的区块的最小整数维度 $(P_{x}, P_{y}, P_{z})$（以体素为单位）。该设计必须满足与体素间距、网络架构和物理视场相关的几个约束条件。\n\n首先，我们将给定的信息和约束条件形式化。体素间距为 $s_{x} = 0.9\\,\\text{mm}$、$s_{y} = 0.9\\,\\text{mm}$ 和 $s_{z} = 4.5\\,\\text{mm}$。区块维度 $(P_{x}, P_{y}, P_{z})$ 必须是整数。\n\n约束条件如下：\n1.  **架构约束**：网络的编码器有三个下采样阶段，沿 $x$ 和 $y$ 轴的步幅为 $2$。因此，初始区块维度 $P_{x}$ 和 $P_{y}$ 必须能被 $2^{3} = 8$ 整除，以确保网络在所有层级上的维度都有效。由于沿 $z$ 轴的步幅为 $1$，因此对 $P_z$ 没有这样的约束。\n2.  **各向同性视场约束**：区块的物理视场（FOV）必须是各向同性的。这意味着沿每个轴的物理尺寸必须相等。设这个共同的物理尺寸为 $L$。\n    $$L = P_{x} s_{x} = P_{y} s_{y} = P_{z} s_{z}$$\n3.  **最小视场约束**：物理视场必须至少为 $72\\,\\text{mm}$。\n    $$L \\geq 72\\,\\text{mm}$$\n\n我们的目标是找到满足所有这些条件的最小整数三元组 $(P_{x}, P_{y}, P_{z})$。\n\n我们首先分析各向同性视场约束。使用等式的前两部分和给定的间距：\n$$P_{x} s_{x} = P_{y} s_{y}$$\n$$P_{x} (0.9) = P_{y} (0.9)$$\n这可以简化为 $P_{x} = P_{y}$。这意味着对 $P_{x}$ 的任何约束也适用于 $P_{y}$，这与两者都必须能被 $8$ 整除的架构约束是一致的。\n\n接下来，我们使用关联 $x$ 和 $z$ 维度的约束：\n$$P_{x} s_{x} = P_{z} s_{z}$$\n代入给定的体素间距：\n$$P_{x} (0.9) = P_{z} (4.5)$$\n我们可以用 $P_{z}$ 来求解 $P_{x}$：\n$$P_{x} = \\frac{4.5}{0.9} P_{z} = 5 P_{z}$$\n由于 $P_{x}$ 和 $P_{z}$ 都必须是整数，这个方程意味着 $P_{x}$ 必须是 $5$ 的整数倍。\n\n现在，我们结合所有对 $P_{x}$ 的约束：\na) $P_{x}$ 必须能被 $8$ 整除（来自架构约束）。\nb) $P_{x}$ 必须能被 $5$ 整除（来自各向同性视场和整数体素约束）。\nc) 物理视场 $L = P_{x} s_{x}$ 必须至少为 $72\\,\\text{mm}$。\n   $$P_{x} (0.9) \\geq 72$$\n   $$P_{x} \\geq \\frac{72}{0.9} = \\frac{720}{9} = 80$$\n\n为了同时满足(a)和(b)，$P_{x}$ 必须是 $8$ 和 $5$ 的公倍数。由于 $8$ 和 $5$ 互质（它们的最大公约数为 $1$），$P_{x}$ 必须是它们的最小公倍数的倍数，即 $\\text{lcm}(8, 5) = 8 \\times 5 = 40$。\n\n因此，我们正在寻找一个最小的整数 $P_{x}$，它既是 $40$ 的倍数，又大于或等于 $80$。$40$ 的倍数有 $40, 80, 120, \\dots$。满足条件 $P_{x} \\geq 80$ 的最小的 $40$ 的倍数是 $80$。\n\n因此，$P_{x}$ 的最小值为 $80$。\n\n有了 $P_{x}$ 的这个最小值，我们就可以找到 $P_{y}$ 和 $P_{z}$ 相应的最小值：\n-   根据 $P_{x} = P_{y}$，我们得到 $P_{y} = 80$。\n-   根据 $P_{x} = 5 P_{z}$，我们得到 $80 = 5 P_{z}$，从而得出 $P_{z} = \\frac{80}{5} = 16$。\n\n区块维度的最小整数三元组是 $(P_{x}, P_{y}, P_{z}) = (80, 80, 16)$。\n\n作为最后的检查，我们验证此解是否满足所有初始条件：\n-   $P_{x}=80$, $P_{y}=80$, $P_{z}=16$ 都是整数。\n-   $P_{x}=80$ 可被 $8$ 整除（$80 = 8 \\times 10$）。\n-   $P_{y}=80$ 可被 $8$ 整除（$80 = 8 \\times 10$）。\n-   物理视场为 $L = P_{x} s_{x} = 80 \\times 0.9\\,\\text{mm} = 72\\,\\text{mm}$。这满足 $L \\geq 72\\,\\text{mm}$。\n-   视场是各向同性的：\n    -   $P_{x} s_{x} = 80 \\times 0.9\\,\\text{mm} = 72\\,\\text{mm}$。\n    -   $P_{y} s_{y} = 80 \\times 0.9\\,\\text{mm} = 72\\,\\text{mm}$。\n    -   $P_{z} s_{z} = 16 \\times 4.5\\,\\text{mm} = 72\\,\\text{mm}$。\n所有条件都已满足。由于我们是从找到 $P_x$ 的最小可能值开始的，所以这个三元组是最小的。", "answer": "$$\\boxed{\\begin{pmatrix} 80  80  16 \\end{pmatrix}}$$", "id": "4582642"}, {"introduction": "类别不平衡是医学图像分割中的一个普遍挑战，例如，微小病灶与大面积背景组织的对比。本练习将引导你从统计决策理论出发，推导并应用三种应对该问题的核心策略：调整后验概率的决策阈值、为损失函数设置类别权重以及对训练数据进行重采样。掌握这些方法对于训练稳健的分割模型至关重要。[@problem_id:4582628]", "problem": "您正在分析用于检测病变类别与背景的二元医学图像分割，使用一个体素级分类器，该分类器输出经过校准的后验概率。核心挑战是在训练和决策过程中处理类别不平衡问题，同时保持基于统计决策理论和标准分割度量定义的原则性正确性。从基本原理出发，推导出一套可实现的规则，用于解决决策阈值、损失加权和重采样问题。\n\n假设一个经过校准的模型，该模型为病变类别输出每个体素的后验概率 $p = P(Y=1 \\mid x)$，其中 $Y \\in \\{0,1\\}$，$Y=1$ 表示病变，$Y=0$ 表示背景。设病变的流行率为 $\\pi = P(Y=1)$，背景的流行率为 $1 - \\pi$。设假阴性的错分类成本为 $C_{\\mathrm{FN}}$，假阳性的错分类成本为 $C_{\\mathrm{FP}}$。设 $\\epsilon > 0$ 是一个小的平滑常数。训练集规模大且样本独立同分布；模型经过良好校准，因此输出 $p$ 等于训练分布下的后验概率。\n\n基于这些基本原理，执行以下推导并实现相应的计算：\n\n- 使用贝叶斯决策理论，推导在非对称错分类成本 $C_{\\mathrm{FN}}$ 和 $C_{\\mathrm{FP}}$ 下最小化期望条件风险的后验概率 $p$ 的贝叶斯最优阈值 $t$。解释流行率 $\\pi$ 如何进入后验概率，以及当 $p$ 经过校准时，$\\pi$ 是否出现在最终决策规则中，然后为每个测试用例计算 $t$。\n\n- 根据多类别设置中单个类别的 Sørensen–Dice 系数定义以及广义 Dice 损失，为病变类别和背景类别构建类别权重，以在存在不平衡的情况下均衡每个类别的期望贡献。利用期望分母项与类别大小成比例的思想，推导出与类别流行率成反比的权重，并使用 $\\epsilon$ 进行平滑以避免奇异点。将权重归一化使其和为1，从而构成一个凸组合。为每个测试用例计算病变类别的归一化权重 $w_1$ 和背景类别的归一化权重 $w_0$。\n\n- 假设您仅通过对病变（正）类别进行过采样来进行重采样，而保持背景（负）类别不变，以达到目标有效流行率 $\\pi^\\star \\in (\\pi,1)$。推导所需的过采样因子 $r$，使得过采样后的新流行率等于 $\\pi^\\star$，用原始流行率 $\\pi$ 和目标流行率 $\\pi^\\star$ 表示。为每个测试用例计算 $r$。\n\n所有输出必须是用十进制表示法表示的实数。不涉及物理单位或角度。实现一个程序，为每个测试用例计算包含四个浮点数的元组，顺序为 $[t, w_1, w_0, r]$。\n\n使用以下测试套件，它涵盖了一般情况、平衡情况、严重不平衡、接近零的流行率和高流行率：\n\n- 用例 1: $\\pi = 0.05$, $C_{\\mathrm{FN}} = 5$, $C_{\\mathrm{FP}} = 1$, $\\epsilon = 10^{-6}$, $\\pi^\\star = 0.5$.\n- 用例 2: $\\pi = 0.5$, $C_{\\mathrm{FN}} = 1$, $C_{\\mathrm{FP}} = 1$, $\\epsilon = 10^{-6}$, $\\pi^\\star = 0.5$.\n- 用例 3: $\\pi = 0.01$, $C_{\\mathrm{FN}} = 10$, $C_{\\mathrm{FP}} = 1$, $\\epsilon = 10^{-3}$, $\\pi^\\star = 0.2$.\n- 用例 4: $\\pi = 10^{-4}$, $C_{\\mathrm{FN}} = 100$, $C_{\\mathrm{FP}} = 1$, $\\epsilon = 10^{-2}$, $\\pi^\\star = 0.1$.\n- 用例 5: $\\pi = 0.9$, $C_{\\mathrm{FN}} = 1$, $C_{\\mathrm{FP}} = 5$, $\\epsilon = 10^{-6}$, $\\pi^\\star = 0.95$.\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，所有测试用例的值按顺序连接且不含空格。具体而言，输出必须是\n$[t_1, w_{1,1}, w_{0,1}, r_1, t_2, w_{1,2}, w_{0,2}, r_2, t_3, w_{1,3}, w_{0,3}, r_3, t_4, w_{1,4}, w_{0,4}, r_4, t_5, w_{1,5}, w_{0,5}, r_5]$。", "solution": "问题陈述已经过验证，被认为是具有科学依据、适定且客观的。它在医学图像分析和统计决策理论领域内，基于既定原则，提出了一个可形式化的挑战。我们将对所要求的量进行严格的、分步的推导。\n\n**1. 贝叶斯最优阈值 $t$ 的推导**\n\n目标是找到后验概率 $p = P(Y=1 \\mid x)$ 的一个决策阈值，以最小化期望条件风险。对每个体素的决策是预测为病变类别 ($\\hat{Y}=1$) 或背景类别 ($\\hat{Y}=0$)。真实类别由 $Y \\in \\{0, 1\\}$ 表示。我们已知错分类的成本：假阴性（当 $Y=1$ 时预测为 $\\hat{Y}=0$）的成本为 $C_{\\mathrm{FN}}$，假阳性（当 $Y=0$ 时预测为 $\\hat{Y}=1$）的成本为 $C_{\\mathrm{FP}}$。\n\n对于一个给定的特征向量为 $x$ 的体素，校准后的模型提供病变类别的后验概率 $p = P(Y=1 \\mid x)$。因此，背景类别的后验概率是 $P(Y=0 \\mid x) = 1 - p$。\n\n在给定观测 $x$ 的情况下，做出决策 $\\hat{Y}$ 的条件风险是该决策的期望成本。\n\n决策为‘病变’($\\hat{Y}=1$)的条件风险是此决策出错的概率乘以该错误的成本：\n$$R(\\hat{Y}=1 \\mid x) = P(Y=0 \\mid x) \\cdot C_{\\mathrm{FP}} = (1 - p) C_{\\mathrm{FP}}$$\n\n类似地，决策为‘背景’($\\hat{Y}=0$)的条件风险是：\n$$R(\\hat{Y}=0 \\mid x) = P(Y=1 \\mid x) \\cdot C_{\\mathrm{FN}} = p C_{\\mathrm{FN}}$$\n\n贝叶斯决策理论规定，我们应选择使此条件风险最小化的行动。因此，我们当且仅当以下条件成立时决策为‘病变’($\\hat{Y}=1$)：\n$$R(\\hat{Y}=1 \\mid x)  R(\\hat{Y}=0 \\mid x)$$\n$$(1 - p) C_{\\mathrm{FP}}  p C_{\\mathrm{FN}}$$\n\n为了找到决策阈值 $t$，我们对此不等式求解 $p$：\n$$C_{\\mathrm{FP}} - p C_{\\mathrm{FP}}  p C_{\\mathrm{FN}}$$\n$$C_{\\mathrm{FP}}  p (C_{\\mathrm{FN}} + C_{\\mathrm{FP}})$$\n$$p > \\frac{C_{\\mathrm{FP}}}{C_{\\mathrm{FN}} + C_{\\mathrm{FP}}}$$\n\n因此，最优策略是，如果一个体素的后验概率 $p$ 超过阈值 $t$，则将其分类为‘病变’。贝叶斯最优阈值 $t$ 是两种风险相等时的值：\n$$t = \\frac{C_{\\mathrm{FP}}}{C_{\\mathrm{FN}} + C_{\\mathrm{FP}}}$$\n\n问题要求解释流行率 $\\pi = P(Y=1)$ 如何进入此规则。根据贝叶斯定理，后验概率 $p$ 是流行率 $\\pi$、类条件似然 $P(x \\mid Y=1)$ 和 $P(x \\mid Y=0)$ 以及证据 $P(x)$ 的函数：\n$$p = P(Y=1 \\mid x) = \\frac{P(x \\mid Y=1) P(Y=1)}{P(x)} = \\frac{P(x \\mid Y=1) \\pi}{P(x \\mid Y=1)\\pi + P(x \\mid Y=0)(1-\\pi)}$$\n问题陈述指出模型是经过良好校准的，这意味着其输出 $p$ 正确地表示了训练分布下的真实后验概率 $P(Y=1 \\mid x)$。这表明模型已经学习并包含了训练数据流行率 $\\pi$ 的影响。因此，决策规则 $p  t$ 通过 $p$ 的值隐式地考虑了流行率。然而，决策阈值 $t$ 本身仅取决于错分类成本 $C_{\\mathrm{FN}}$ 和 $C_{\\mathrm{FP}}$，而并非显式地取决于 $\\pi$。\n\n**2. 用于 Dice 损失的类别权重($w_1, w_0$)的推导**\n\n任务是为基于 Dice 的损失函数构建类别权重，这些权重与类别流行率成反比，并带有一个平滑常数 $\\epsilon  0$ 以防止除以零。权重必须被归一化以使其和为1。\n\n设病变类别($Y=1$)的流行率为 $\\pi_1 = \\pi$，背景类别($Y=0$)的流行率为 $\\pi_0 = 1 - \\pi$。\n未归一化的权重 $\\tilde{w}_1$ 和 $\\tilde{w}_0$ 与平滑后的流行率成反比：\n$$\\tilde{w}_1 = \\frac{1}{\\pi_1 + \\epsilon} = \\frac{1}{\\pi + \\epsilon}$$\n$$\\tilde{w}_0 = \\frac{1}{\\pi_0 + \\epsilon} = \\frac{1}{1 - \\pi + \\epsilon}$$\n\n为了将这些权重归一化使其和为1，我们将每个权重除以它们的和 $S = \\tilde{w}_1 + \\tilde{w}_0$：\n$$S = \\frac{1}{\\pi + \\epsilon} + \\frac{1}{1 - \\pi + \\epsilon} = \\frac{(1 - \\pi + \\epsilon) + (\\pi + \\epsilon)}{(\\pi + \\epsilon)(1 - \\pi + \\epsilon)} = \\frac{1 + 2\\epsilon}{(\\pi + \\epsilon)(1 - \\pi + \\epsilon)}$$\n\n病变类别的归一化权重 $w_1$ 是：\n$$w_1 = \\frac{\\tilde{w}_1}{S} = \\frac{\\frac{1}{\\pi + \\epsilon}}{\\frac{1 + 2\\epsilon}{(\\pi + \\epsilon)(1 - \\pi + \\epsilon)}} = \\frac{1}{\\pi + \\epsilon} \\cdot \\frac{(\\pi + \\epsilon)(1 - \\pi + \\epsilon)}{1 + 2\\epsilon} = \\frac{1 - \\pi + \\epsilon}{1 + 2\\epsilon}$$\n\n背景类别的归一化权重 $w_0$ 是：\n$$w_0 = \\frac{\\tilde{w}_0}{S} = \\frac{\\frac{1}{1 - \\pi + \\epsilon}}{\\frac{1 + 2\\epsilon}{(\\pi + \\epsilon)(1 - \\pi + \\epsilon)}} = \\frac{1}{1 - \\pi + \\epsilon} \\cdot \\frac{(\\pi + \\epsilon)(1 - \\pi + \\epsilon)}{1 + 2\\epsilon} = \\frac{\\pi + \\epsilon}{1 + 2\\epsilon}$$\n\n作为检验，$w_1 + w_0 = \\frac{1 - \\pi + \\epsilon}{1 + 2\\epsilon} + \\frac{\\pi + \\epsilon}{1 + 2\\epsilon} = \\frac{1 - \\pi + \\epsilon + \\pi + \\epsilon}{1 + 2\\epsilon} = \\frac{1 + 2\\epsilon}{1 + 2\\epsilon} = 1$。推导正确。\n\n**3. 过采样因子 $r$ 的推导**\n\n我们的目标是找到因子 $r$，通过对病变（正）类别进行该因子的过采样，可以将有效流行率从初始值 $\\pi$ 变为目标值 $\\pi^\\star$。\n\n设原始数据集中病变类别的样本数量为 $N_1$，背景类别的样本数量为 $N_0$。样本总数为 $N = N_0 + N_1$。原始流行率为：\n$$\\pi = \\frac{N_1}{N_0 + N_1}$$\n\n以因子 $r$ 对病变类别进行过采样，创建一个新数据集，其中有 $N'_1 = r N_1$ 个病变样本，而背景样本的数量保持不变，$N'_0 = N_0$。新的样本总数为 $N' = N'_0 + N'_1 = N_0 + r N_1$。\n\n新的流行率 $\\pi^\\star$ 为：\n$$\\pi^\\star = \\frac{N'_1}{N'} = \\frac{r N_1}{N_0 + r N_1}$$\n\n为了用 $\\pi$ 和 $\\pi^\\star$ 表示 $r$，我们首先用 $\\pi$ 表示 $N_0$ 和 $N_1$。根据 $\\pi$ 的定义，我们有 $N_1 = \\pi(N_0 + N_1)$ 和 $N_0 = (1-\\pi)(N_0 + N_1)$。比率为 $\\frac{N_0}{N_1} = \\frac{1-\\pi}{\\pi}$。所以，$N_0 = N_1 \\frac{1-\\pi}{\\pi}$。\n\n将 $N_0$ 的这个表达式代入 $\\pi^\\star$ 的方程中：\n$$\\pi^\\star = \\frac{r N_1}{N_1 \\frac{1-\\pi}{\\pi} + r N_1}$$\n由于要使这个问题有意义，$N_1$ 必须为非零值，因此我们可以将分子和分母同除以 $N_1$：\n$$\\pi^\\star = \\frac{r}{\\frac{1-\\pi}{\\pi} + r}$$\n\n现在，我们求解 $r$：\n$$\\pi^\\star \\left(\\frac{1-\\pi}{\\pi} + r\\right) = r$$\n$$\\pi^\\star \\frac{1-\\pi}{\\pi} + \\pi^\\star r = r$$\n$$\\pi^\\star \\frac{1-\\pi}{\\pi} = r - \\pi^\\star r$$\n$$\\pi^\\star \\frac{1-\\pi}{\\pi} = r(1 - \\pi^\\star)$$\n$$r = \\frac{\\pi^\\star (1 - \\pi)}{\\pi (1 - \\pi^\\star)}$$\n这就是病变类别所需的过采样因子。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes segmentation-related parameters for a series of test cases based on\n    statistical decision theory and standard machine learning practices for class imbalance.\n    \"\"\"\n    test_cases = [\n        # Case 1: General case\n        {'pi': 0.05, 'cfn': 5.0, 'cfp': 1.0, 'eps': 1e-6, 'pi_star': 0.5},\n        # Case 2: Balanced case\n        {'pi': 0.5, 'cfn': 1.0, 'cfp': 1.0, 'eps': 1e-6, 'pi_star': 0.5},\n        # Case 3: Severe imbalance\n        {'pi': 0.01, 'cfn': 10.0, 'cfp': 1.0, 'eps': 1e-3, 'pi_star': 0.2},\n        # Case 4: Near-zero prevalence\n        {'pi': 1e-4, 'cfn': 100.0, 'cfp': 1.0, 'eps': 1e-2, 'pi_star': 0.1},\n        # Case 5: High prevalence\n        {'pi': 0.9, 'cfn': 1.0, 'cfp': 5.0, 'eps': 1e-6, 'pi_star': 0.95},\n    ]\n\n    results = []\n    for case in test_cases:\n        pi = case['pi']\n        cfn = case['cfn']\n        cfp = case['cfp']\n        eps = case['eps']\n        pi_star = case['pi_star']\n\n        # 1. Bayes-optimal threshold t\n        # t = C_FP / (C_FN + C_FP)\n        t = cfp / (cfn + cfp)\n\n        # 2. Normalized class weights w1 (lesion) and w0 (background)\n        # w1 = (1 - pi + eps) / (1 + 2*eps)\n        # w0 = (pi + eps) / (1 + 2*eps)\n        w_denominator = 1.0 + 2.0 * eps\n        w1 = (1.0 - pi + eps) / w_denominator\n        w0 = (pi + eps) / w_denominator\n\n        # 3. Oversampling factor r\n        # r = (pi_star * (1 - pi)) / (pi * (1 - pi_star))\n        # Note: The problem setup ensures pi > 0, pi_star  1, so no division by zero.\n        r = (pi_star * (1.0 - pi)) / (pi * (1.0 - pi_star))\n        \n        results.extend([t, w1, w0, r])\n\n    # Format the final output as a single comma-separated list in brackets, with no spaces.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "4582628"}, {"introduction": "理论上完美的模型如果无法在现有硬件上运行，则没有任何实用价值。本练习将带你深入一个三维U-Net模型的内部，详细计算其在训练过程中所需的总显存，包括模型参数和中间层激活值。通过这个实践，你将学会如何根据给定的GPU显存预算，来确定网络可以处理的最大输入图像块尺寸，这是将理论模型付诸实践的关键工程技能。[@problem_id:4582620]", "problem": "一名研究人员正在为双类别设置下的容积式磁共振成像（MRI）设计一个三维（3D）卷积分割网络，该网络遵循带有跳跃连接的U型编码器-解码器拓扑结构。该网络使用标准三维卷积（卷积核大小为 $3 \\times 3 \\times 3$，步长为1，以及“same”填充）、步长为 $2$ 的三维最大池化进行下采样，以及三维转置卷积（卷积核大小为 $2 \\times 2 \\times 2$，步长为 $2$）进行上采样。输入是一个边长为 $N$ 体素的立方体块，且只有一个输入通道。该架构定义如下：\n\n- 编码器第 $0$ 层：两个连续的卷积层，每个层有 $C_0$ 个输出通道；输出空间尺寸保持为 $N \\times N \\times N$。\n- 通过最大池化（步长 $2$）进行下采样，空间尺寸变为 $(N/2) \\times (N/2) \\times (N/2)$。\n- 编码器第 $1$ 层：两个连续的卷积层，每个层有 $2C_0$ 个输出通道；输出空间尺寸保持为 $(N/2) \\times (N/2) \\times (N/2)$。\n- 通过最大池化（步长 $2$）进行下采样，空间尺寸变为 $(N/4) \\times (N/4) \\times (N/4)$。\n- 瓶颈层第 $2$ 层：两个连续的卷积层，每个层有 $4C_0$ 个输出通道；输出空间尺寸保持为 $(N/4) \\times (N/4) \\times (N/4)$。\n- 解码器第 $1$ 层：一个转置卷积将 $4C_0$ 映射到 $2C_0$，空间尺寸为 $(N/2) \\times (N/2) \\times (N/2)$，与编码器第 $1$ 层的第二个特征图进行拼接（跳跃连接），然后是两个连续的卷积层，每个层有 $2C_0$ 个输出通道。\n- 解码器第 $0$ 层：一个转置卷积将 $2C_0$ 映射到 $C_0$，空间尺寸为 $N \\times N \\times N$，与编码器第 $0$ 层的第二个特征图进行拼接（跳跃连接），然后是两个连续的卷积层，每个层有 $C_0$ 个输出通道。\n- 最终卷积：一个 $1 \\times 1 \\times 1$ 卷积将 $C_0$ 映射到 $C_{\\text{out}}$，空间尺寸为 $N \\times N \\times N$。\n\n假设训练在批量大小 $B=1$ 的混合精度下进行，其中所有中间激活值都以半精度（每个标量两个字节）存储，而参数、梯度和优化器状态则以单精度（每个标量四个字节）存储。训练使用自适应矩估计（Adam），它为每个参数存储其值、梯度、一阶矩和二阶矩，所有这些都以单精度存储。所有卷积层都包含偏置项。\n\n从三维卷积层的核心定义（参数数量等于卷积核体积、输入通道数和输出通道数的乘积，再加上每个输出通道一个偏置）、张量内存使用量（元素数量乘以每个元素的字节数），以及上述网络拓扑结构（其中跳跃连接要求保留相关的编码器激活值，但仅计算作为卷积或转置卷积层输出的激活值）出发，推导出总训练时内存占用 $T(N)$，作为边长 $N$ 以及常数 $C_0$ 和 $C_{\\text{out}}$ 的函数。\n\n设 $C_0 = 16$ 且 $C_{\\text{out}} = 4$。图形处理单元（GPU）的内存预算为 $M = 8 \\times 10^{9}$ 字节。忽略任何临时工作空间分配、非线性或池化存储、超出第一次卷积的输入张量存储，以及超出已计算的激活值、参数、梯度和Adam矩的框架开销。在这些假设下，确定使得总内存占用满足 $T(N) \\leq M$ 的最大整数边长 $N$。\n\n报告最大整数 $N$。无需四舍五入。答案没有物理单位。", "solution": "该问题陈述经评估有效。它在医学图像分析的深度学习领域具有科学依据，问题提出得当，信息充分且一致，并且表述客观。因此，我们可以进行正式求解。\n\n训练期间的总内存占用 $T(N)$ 是参数内存（包括梯度和优化器状态）与激活值内存的总和。\n$$T(N) = P_{\\text{mem}} + A_{\\text{mem}}(N)$$\n\n**1. 与参数相关的内存 ($P_{\\text{mem}}$)**\n\n问题陈述指出，训练使用 Adam 优化器，该优化器为每个参数存储其值、梯度、一阶矩和二阶矩。所有这些都以单精度（$4$ 字节）存储。因此，每个参数的内存成本为 $4 \\times 4 = 16$ 字节。\n$$P_{\\text{mem}} = 16 \\times N_p$$\n其中 $N_p$ 是网络中的参数总数。\n\n对于一个卷积核大小为 $k \\times k \\times k$、有 $C_{\\text{in}}$ 个输入通道和 $C_{\\text{out}}$ 个输出通道的卷积层（包括转置卷积），其参数数量（包括偏置项）由下式给出：\n$$P_{\\text{layer}} = C_{\\text{out}}(k^3 C_{\\text{in}} + 1)$$\n我们计算每一层的参数：\n\n- **编码器第 0 层：**\n  - 卷积层1 ($1 \\to C_0$, $k=3$): $P_1 = C_0(3^3 \\cdot 1 + 1) = 28C_0$\n  - 卷积层2 ($C_0 \\to C_0$, $k=3$): $P_2 = C_0(3^3 \\cdot C_0 + 1) = 27C_0^2 + C_0$\n\n- **编码器第 1 层：**\n  - 卷积层3 ($C_0 \\to 2C_0$, $k=3$): $P_3 = 2C_0(3^3 \\cdot C_0 + 1) = 54C_0^2 + 2C_0$\n  - 卷积层4 ($2C_0 \\to 2C_0$, $k=3$): $P_4 = 2C_0(3^3 \\cdot 2C_0 + 1) = 108C_0^2 + 2C_0$\n\n- **瓶颈层第 2 层：**\n  - 卷积层5 ($2C_0 \\to 4C_0$, $k=3$): $P_5 = 4C_0(3^3 \\cdot 2C_0 + 1) = 216C_0^2 + 4C_0$\n  - 卷积层6 ($4C_0 \\to 4C_0$, $k=3$): $P_6 = 4C_0(3^3 \\cdot 4C_0 + 1) = 432C_0^2 + 4C_0$\n\n- **解码器第 1 层：**\n  - 转置卷积层1 ($4C_0 \\to 2C_0$, $k=2$): $P_7 = 2C_0(2^3 \\cdot 4C_0 + 1) = 64C_0^2 + 2C_0$\n  - 卷积层7 ($4C_0 \\to 2C_0$, $k=3$): 输入通道为 $2C_0$ (来自转置卷积层1) + $2C_0$ (跳跃连接) = $4C_0$。$P_8 = 2C_0(3^3 \\cdot 4C_0 + 1) = 216C_0^2 + 2C_0$\n  - 卷积层8 ($2C_0 \\to 2C_0$, $k=3$): $P_9 = 2C_0(3^3 \\cdot 2C_0 + 1) = 108C_0^2 + 2C_0$\n\n- **解码器第 0 层：**\n  - 转置卷积层0 ($2C_0 \\to C_0$, $k=2$): $P_{10} = C_0(2^3 \\cdot 2C_0 + 1) = 16C_0^2 + C_0$\n  - 卷积层9 ($2C_0 \\to C_0$, $k=3$): 输入通道为 $C_0$ (来自转置卷积层0) + $C_0$ (跳跃连接) = $2C_0$。$P_{11} = C_0(3^3 \\cdot 2C_0 + 1) = 54C_0^2 + C_0$\n  - 卷积层10 ($C_0 \\to C_0$, $k=3$): $P_{12} = C_0(3^3 \\cdot C_0 + 1) = 27C_0^2 + C_0$\n\n- **最终卷积：**\n  - 卷积层11 ($C_0 \\to C_{\\text{out}}$, $k=1$): $P_{13} = C_{\\text{out}}(1^3 \\cdot C_0 + 1) = C_0C_{\\text{out}} + C_{\\text{out}}$\n\n对所有参数求和：\n$$N_p = \\sum_{i=1}^{13} P_i = C_0^2(27+54+108+216+432+64+216+108+16+54+27) + C_0(28+1+2+2+4+4+2+2+2+1+1+1) + C_0C_{\\text{out}} + C_{\\text{out}}$$\n$$N_p = 1322C_0^2 + 50C_0 + C_0C_{\\text{out}} + C_{\\text{out}}$$\n\n当 $C_0=16$ 且 $C_{\\text{out}}=4$ 时：\n$N_p = 1322(16^2) + 50(16) + (16)(4) + 4 = 1322(256) + 800 + 64 + 4 = 338432 + 868 = 339300$\n$P_{\\text{mem}} = 16 \\times 339300 = 5,428,800$ 字节。\n\n**2. 激活值内存 ($A_{\\text{mem}}$)**\n\n激活值以半精度（$2$ 字节）存储。内存是所有卷积层输出特征图大小的总和。在第 $i$ 层（下采样 $i$ 次）的空间体积为 $(N/2^i)^3$。\n$$A_{\\text{mem}}(N) = 2 \\times N_{\\text{act}}(N)$$\n其中 $N_{\\text{act}}$ 是激活值的总数。\n\n- **编码器第 0 层（体积 $N^3$）：** 两层，每层有 $C_0$ 个通道。激活值数量：$2 \\times N^3 C_0$。\n- **编码器第 1 层（体积 $(N/2)^3$）：** 两层，每层有 $2C_0$ 个通道。激活值数量：$2 \\times (N/2)^3 \\cdot 2C_0 = \\frac{4 N^3 C_0}{8} = \\frac{N^3 C_0}{2}$。\n- **瓶颈层第 2 层（体积 $(N/4)^3$）：** 两层，每层有 $4C_0$ 个通道。激活值数量：$2 \\times (N/4)^3 \\cdot 4C_0 = \\frac{8 N^3 C_0}{64} = \\frac{N^3 C_0}{8}$。\n- **解码器第 1 层（体积 $(N/2)^3$）：** 三层（转置卷积，卷积，卷积），每层有 $2C_0$ 个通道。激活值数量：$3 \\times (N/2)^3 \\cdot 2C_0 = \\frac{6 N^3 C_0}{8} = \\frac{3N^3 C_0}{4}$。\n- **解码器第 0 层（体积 $N^3$）：** 三层（转置卷积，卷积，卷积），每层有 $C_0$ 个通道。激活值数量：$3 \\times N^3 C_0$。\n- **最终卷积（体积 $N^3$）：** 一层，有 $C_{\\text{out}}$ 个通道。激活值数量：$N^3 C_{\\text{out}}$。\n\n总激活值数量 $N_{\\text{act}}$：\n$$N_{\\text{act}}(N) = N^3 \\left( 2C_0 + \\frac{C_0}{2} + \\frac{C_0}{8} + \\frac{3C_0}{4} + 3C_0 + C_{\\text{out}} \\right)$$\n$$N_{\\text{act}}(N) = N^3 \\left( C_0 \\left( 2 + \\frac{1}{2} + \\frac{1}{8} + \\frac{3}{4} + 3 \\right) + C_{\\text{out}} \\right)$$\n$$N_{\\text{act}}(N) = N^3 \\left( C_0 \\left( 5 + \\frac{4+1+6}{8} \\right) + C_{\\text{out}} \\right) = N^3 \\left( C_0 \\left( 5 + \\frac{11}{8} \\right) + C_{\\text{out}} \\right) = N^3 \\left(\\frac{51}{8}C_0 + C_{\\text{out}}\\right)$$\n\n$$A_{\\text{mem}}(N) = 2 \\times N_{\\text{act}}(N) = N^3 \\left(\\frac{51}{4}C_0 + 2C_{\\text{out}}\\right)$$\n\n当 $C_0=16$ 且 $C_{\\text{out}}=4$ 时：\n$$A_{\\text{mem}}(N) = N^3 \\left(\\frac{51}{4}(16) + 2(4)\\right) = N^3(51 \\cdot 4 + 8) = N^3(204 + 8) = 212N^3 \\text{ 字节。}$$\n\n**3. 总内存与求解 $N$**\n\n总内存占用为：\n$$T(N) = P_{\\text{mem}} + A_{\\text{mem}}(N) = 5,428,800 + 212N^3$$\n我们必须找到满足 $T(N) \\leq M$ 的最大整数 $N$，其中 $M = 8 \\times 10^9$ 字节。\n$$5,428,800 + 212N^3 \\leq 8 \\times 10^9$$\n$$212N^3 \\leq 8,000,000,000 - 5,428,800$$\n$$212N^3 \\leq 7,994,571,200$$\n$$N^3 \\leq \\frac{7,994,571,200}{212}$$\n$$N^3 \\leq 37,710,241.509...$$\n为了找到最大整数 $N$，我们取其立方根：\n$$N \\leq (37,710,241.509...)^{1/3}$$\n$$N \\leq 335.344...$$\n由于 $N$ 必须是整数，它能取到的最大值为 $335$。\n我们可以验证这一点：\n对于 $N=335$，$N^3 = 37,595,375 \\leq 37,710,241.509...$。这是有效的。\n对于 $N=336$，$N^3 = 37,933,056  37,710,241.509...$。这是无效的。\n\n最大整数边长 $N$ 是 $335$。", "answer": "$$\\boxed{335}$$", "id": "4582620"}]}