{"hands_on_practices": [{"introduction": "在比较不同样本间的基因表达时，首要步骤是校正技术差异，尤其是测序深度或文库大小的差异。本练习 [@problem_id:4556260] 引导您超越简单的总计数缩放方法，深入理解类似DESeq2等现代工具核心的、更为稳健的归一化策略。通过手动计算基于比率中位数的尺度因子（size factors），您将具体掌握归一化因子是如何产生的，并领会其对于获得无偏的表达变化估计为何至关重要。", "problem": "给定一个小的、科学上合理的RNA测序（RNA-seq）计数矩阵，包含四个基因和三个样本。两个样本属于条件X，一个样本属于条件Y。为校正因文库大小不等而产生的组成差异，考虑一种归一化方法：该方法使用所有样本的几何平均值为每个基因构建一个伪参考表达谱，然后通过基因间样本与参考表达谱比率的稳健摘要（中位数）来定义样本特异性的缩放因子。这是一种在差异基因表达分析中广泛使用且经过充分检验的策略。\n\n观测到的基因-样本计数矩阵如下：\n- 基因 $1$：样本 $S_1$ (X), $S_2$ (X), $S_3$ (Y) 的计数为 $[100, 200, 150]$\n- 基因 $2$：样本 $S_1$ (X), $S_2$ (X), $S_3$ (Y) 的计数为 $[50, 100, 75]$\n- 基因 $3$：样本 $S_1$ (X), $S_2$ (X), $S_3$ (Y) 的计数为 $[200, 400, 300]$\n- 基因 $4$：样本 $S_1$ (X), $S_2$ (X), $S_3$ (Y) 的计数为 $[80, 160, 320]$\n\n假设基因 $1$、$2$ 和 $3$ 在不同条件间没有差异表达（它们在所有样本中的真实表达量是恒定的），而基因 $4$ 在条件Y中是上调的。设 $g_i$ 表示基因 $i$ 在三个样本中计数的几何平均值，设 $s_j$ 表示样本 $j$ 的长度归一化大小因子，其值由所有严格正计数基因的观测计数与相应 $g_i$ 值之比的中位数得出。\n\n任务：\n1. 计算 $i \\in \\{1,2,3,4\\}$ 的 $g_i$。\n2. 使用上述定义的中位数比率归一化方法，计算 $j \\in \\{1,2,3\\}$ 的 $s_j$。\n3. 考虑对一个真实非差异表达的基因进行下游差异表达比较，即比较 $S_3$ (Y) 与 $S_1$ (X)。如果错误地忽略了归一化，那么朴素的对数倍数变化将包含一个偏差，该偏差等于 $S_3$ 和 $S_1$ 之间有效文库大小比值的自然对数。使用您计算出的 $s_j$，将此偏差以单个实数形式给出。将最终数值答案四舍五入至四位有效数字，并以自然对数单位表示（无物理单位）。", "solution": "用户提供了一个在尝试解决之前需要进行严格验证的问题。\n\n### 步骤1：提取已知信息\n- **计数矩阵 ($C$)**：一个包含4个基因和3个样本的 $4 \\times 3$ 矩阵。\n  - 基因 $1$：样本 $S_1, S_2, S_3$ 的计数为 $[100, 200, 150]$。\n  - 基因 $2$：样本 $S_1, S_2, S_3$ 的计数为 $[50, 100, 75]$。\n  - 基因 $3$：样本 $S_1, S_2, S_3$ 的计数为 $[200, 400, 300]$。\n  - 基因 $4$：样本 $S_1, S_2, S_3$ 的计数为 $[80, 160, 320]$。\n- **样本条件**:\n  - 样本 $S_1$：条件 X\n  - 样本 $S_2$：条件 X\n  - 样本 $S_3$：条件 Y\n- **假设**:\n  - 基因 $1$, $2$, 和 $3$ 没有差异表达。\n  - 基因 $4$ 在条件 Y 中是上调的。\n- **定义**:\n  - $g_i$：基因 $i$ 在所有样本中计数的几何平均值。\n  - $s_j$：样本 $j$ 的大小因子，定义为所有严格正计数基因的观测计数与相应 $g_i$ 值之比的中位数。\n- **任务**:\n  1. 计算 $i \\in \\{1, 2, 3, 4\\}$ 的 $g_i$。\n  2. 计算 $j \\in \\{1, 2, 3\\}$ 的 $s_j$。\n  3. 计算比较 $S_3$ 和 $S_1$ 时，一个非差异表达基因的朴素对数倍数变化的偏差。该偏差定义为有效文库大小比值 ($s_3/s_1$) 的自然对数。\n- **输出要求**：将偏差的最终数值答案四舍五入至四位有效数字。\n\n### 步骤2：使用提取的已知信息进行验证\n1.  **科学依据**：该问题描述了中位数比率归一化方法，这是广泛使用且经过充分验证的DESeq/DESeq2生物信息学工具中用于RNA-seq差异表达分析的核心组成部分。该方法在科学上是合理的，并在该领域得到了确立。\n2.  **问题明确**：该问题提供了一个完整的计数矩阵和所有待计算量（$g_i$ 和 $s_j$）的明确定义。任务是按顺序结构的，并导向一个唯一的、有意义的答案。\n3.  **客观性**：问题以精确、定量的术语陈述。没有主观或模糊的陈述。\n4.  **不完整或矛盾的设置**：问题是自洽的。所有计数都是正数，因此所有基因的几何平均值（$g_i$）都是明确定义且非零的。所提供的数据或定义中没有矛盾。\n5.  **不切实际或不可行**：计数值是整数，并且对于小规模的RNA-seq实验来说是科学上合理的。该情景是现实的。\n6.  **问题不适定或结构不良**：使用中位数使得大小因子的计算对单个差异表达基因（基因4）具有鲁棒性，这是该方法的一个关键设计原则。这种结构确保了稳定且有意义的解决方案。\n7.  **伪深刻、琐碎或同义反复**：这个问题并非微不足道。它需要正确地、一步一步地应用一个标准的生物信息学算法，并理解归一化因子如何与系统性偏差相关联。\n8.  **超出科学可验证性范围**：所有计算都可以通过标准数学程序进行验证。\n\n### 步骤3：结论与行动\n该问题是有效的。将提供完整的解决方案。\n\n提供的计数矩阵，记为基因 $i$ 和样本 $j$ 的 $C_{ij}$，如下所示：\n$$\nC = \\begin{pmatrix} 100 & 200 & 150 \\\\ 50 & 100 & 75 \\\\ 200 & 400 & 300 \\\\ 80 & 160 & 320 \\end{pmatrix}\n$$\n其中行对应于基因 $i \\in \\{1, 2, 3, 4\\}$，列对应于样本 $j \\in \\{1, 2, 3\\}$。\n\n**任务1：计算每个基因的几何平均值 $g_i$。**\n基因 $i$ 在 $N=3$ 个样本中的几何平均值 $g_i$ 定义为：\n$$\ng_i = \\left( \\prod_{j=1}^{3} C_{ij} \\right)^{1/3}\n$$\n对于基因1：\n$g_1 = (100 \\times 200 \\times 150)^{1/3} = (3,000,000)^{1/3} = (3 \\times 10^6)^{1/3} = 100 \\cdot 3^{1/3}$\n对于基因2：\n$g_2 = (50 \\times 100 \\times 75)^{1/3} = (375,000)^{1/3} = (0.375 \\times 10^6)^{1/3} = (125 \\times 3 \\times 10^3)^{1/3} = 50 \\cdot 3^{1/3}$\n对于基因3：\n$g_3 = (200 \\times 400 \\times 300)^{1/3} = (24,000,000)^{1/3} = (24 \\times 10^6)^{1/3} = 100 \\cdot (24)^{1/3} = 100 \\cdot (8 \\times 3)^{1/3} = 200 \\cdot 3^{1/3}$\n对于基因4：\n$g_4 = (80 \\times 160 \\times 320)^{1/3} = (4,096,000)^{1/3} = (4.096 \\times 10^6)^{1/3} = (1.6^3 \\times 10^6)^{1/3} = 1.6 \\times 100 = 160$\n\n**任务2：计算每个样本的大小因子 $s_j$。**\n样本 $j$ 的大小因子 $s_j$ 是所有基因 $i$ 的比率 $C_{ij} / g_i$ 的中位数。\n$$\ns_j = \\underset{i}{\\text{median}} \\left( \\frac{C_{ij}}{g_i} \\right)\n$$\n对于样本 $S_1$ ($j=1$):\n比率如下：\n$r_{11} = \\frac{C_{11}}{g_1} = \\frac{100}{100 \\cdot 3^{1/3}} = 3^{-1/3}$\n$r_{21} = \\frac{C_{21}}{g_2} = \\frac{50}{50 \\cdot 3^{1/3}} = 3^{-1/3}$\n$r_{31} = \\frac{C_{31}}{g_3} = \\frac{200}{200 \\cdot 3^{1/3}} = 3^{-1/3}$\n$r_{41} = \\frac{C_{41}}{g_4} = \\frac{80}{160} = \\frac{1}{2}$\n我们需要计算 $\\{3^{-1/3}, 3^{-1/3}, 3^{-1/3}, 1/2\\}$ 的中位数。为了对这些值进行排序，我们比较 $3^{-1/3}$ 和 $1/2$。这等同于比较 $2$ 和 $3^{1/3}$。由于 $2^3=8$ 且 $(3^{1/3})^3=3$，并且 $8 > 3$，所以我们有 $2 > 3^{1/3}$。因此，$\\frac{1}{2} < \\frac{1}{3^{1/3}} = 3^{-1/3}$。\n排序后的比率列表是 $\\{\\frac{1}{2}, 3^{-1/3}, 3^{-1/3}, 3^{-1/3}\\}$。这四个值的中位数是中间两个值的平均值，这两个值都是 $3^{-1/3}$。\n$s_1 = 3^{-1/3}$\n\n对于样本 $S_2$ ($j=2$):\n比率如下：\n$r_{12} = \\frac{C_{12}}{g_1} = \\frac{200}{100 \\cdot 3^{1/3}} = 2 \\cdot 3^{-1/3}$\n$r_{22} = \\frac{C_{22}}{g_2} = \\frac{100}{50 \\cdot 3^{1/3}} = 2 \\cdot 3^{-1/3}$\n$r_{32} = \\frac{C_{32}}{g_3} = \\frac{400}{200 \\cdot 3^{1/3}} = 2 \\cdot 3^{-1/3}$\n$r_{42} = \\frac{C_{42}}{g_4} = \\frac{160}{160} = 1$\n我们需要计算 $\\{2 \\cdot 3^{-1/3}, 2 \\cdot 3^{-1/3}, 2 \\cdot 3^{-1/3}, 1\\}$ 的中位数。我们比较 $2 \\cdot 3^{-1/3}$ 和 $1$。这等同于比较 $2$ 和 $3^{1/3}$。如前所述，$2 > 3^{1/3}$，所以 $2 \\cdot 3^{-1/3} > 1$。\n排序后的比率列表是 $\\{1, 2 \\cdot 3^{-1/3}, 2 \\cdot 3^{-1/3}, 2 \\cdot 3^{-1/3}\\}$。中位数是中间两个值的平均值。\n$s_2 = 2 \\cdot 3^{-1/3}$\n\n对于样本 $S_3$ ($j=3$):\n比率如下：\n$r_{13} = \\frac{C_{13}}{g_1} = \\frac{150}{100 \\cdot 3^{1/3}} = 1.5 \\cdot 3^{-1/3}$\n$r_{23} = \\frac{C_{23}}{g_2} = \\frac{75}{50 \\cdot 3^{1/3}} = 1.5 \\cdot 3^{-1/3}$\n$r_{33} = \\frac{C_{33}}{g_3} = \\frac{300}{200 \\cdot 3^{1/3}} = 1.5 \\cdot 3^{-1/3}$\n$r_{43} = \\frac{C_{43}}{g_4} = \\frac{320}{160} = 2$\n我们需要计算 $\\{1.5 \\cdot 3^{-1/3}, 1.5 \\cdot 3^{-1/3}, 1.5 \\cdot 3^{-1/3}, 2\\}$ 的中位数。我们比较 $1.5 \\cdot 3^{-1/3}$ 和 $2$。这等同于比较 $1.5 = 3/2$ 和 $2 \\cdot 3^{1/3}$。很明显 $1.5 < 2 \\cdot 3^{1/3}$ 因为 $3^{1/3} > 1$。\n排序后的比率列表是 $\\{1.5 \\cdot 3^{-1/3}, 1.5 \\cdot 3^{-1/3}, 1.5 \\cdot 3^{-1/3}, 2\\}$。中位数是中间两个值的平均值。\n$s_3 = 1.5 \\cdot 3^{-1/3} = \\frac{3}{2} \\cdot 3^{-1/3}$\n\n**任务3：计算偏差项。**\n问题指出，朴素对数倍数变化的偏差是有效文库大小比值的自然对数。大小因子 $s_j$ 是这些有效文库大小的估计值。我们正在比较 $S_3$ 与 $S_1$。\n偏差由 $\\ln(s_3/s_1)$ 给出。\n使用任务2的结果：\n$$\n\\frac{s_3}{s_1} = \\frac{1.5 \\cdot 3^{-1/3}}{3^{-1/3}} = 1.5\n$$\n因此，偏差为：\n$$\n\\text{Bias} = \\ln(1.5)\n$$\n为了获得数值，我们计算 $1.5$ 的自然对数：\n$$\n\\ln(1.5) \\approx 0.405465108...\n$$\n四舍五入到四位有效数字得到 $0.4055$。这个偏差代表了在计算对数倍数变化时，如果没有考虑文库测序深度的差异而引入的系统误差。在计算对数比率之前，通过将计数除以各自的大小因子 $s_j$ 进行归一化，可以消除此偏差。", "answer": "$$\n\\boxed{0.4055}\n$$", "id": "4556260"}, {"introduction": "除了文库大小，实验批次效应是另一大非生物学变异来源，它常常会混淆差异表达分析的结果。本练习 [@problem_id:2385475] 通过模拟，直观且有力地展示了“遗漏变量偏误”（omitted-variable bias）的危害。您将生成一组数据，其中批次效应与感兴趣的生物学条件相关联，亲眼见证若在统计模型中忽略批次项，将如何导致假阳性结果的急剧膨胀，以及正确设定模型又如何能恢复有效的统计推断。", "problem": "编写一个完整、可运行的程序，该程序在一个具有强批次效应的线性模型下模拟基因表达数据，并评估在差异基因表达分析中省略批次协变量的影响。您的程序必须实现以下有科学依据且被广泛接受的基本原则，不得依赖问题陈述中提供的任何快捷公式。\n\n使用的基本原则：\n- 在适当的转换尺度（例如对数尺度）上，基因表达可以通过一个带有高斯噪声的线性模型来建模。对于基因索引 $g$ 和样本索引 $i$，令 $y_{g i}$ 表示表达量。该模型包括一个基因特异性的基线项、一个条件项、一个批次项和一个独立的噪声项。\n- 在高斯噪声假设下，普通最小二乘法 (OLS) 在正确设定的线性模型中产生无偏估计量，并为关于模型系数的假设提供检验统计量，这些统计量在零假设下服从学生t分布。\n- 跨多个基因的多重假设检验应使用假发现率 (FDR) 进行控制。使用 Benjamini–Hochberg (BH) 程序，目标水平为 $q = 0.05$。\n\n模拟设计与假设检验：\n- 所有基因共享相同的生成模型结构，并在两种生物学条件之间无真实差异表达的全局零假设下进行模拟。具体而言，对于每个基因 $g$，条件效应为 $0$；批次效应在两个批次之间作为一个固定的偏移量在所有基因间共享；基线水平可能因基因而异；噪声在基因内的样本间是独立同分布的高斯噪声，且方差恒定。\n- 程序必须对每个基因使用以下两种模型，估计条件系数为零的零假设的双边 $p$ 值：\n  1. 一个省略了批次协变量的错误设定模型（仅条件分析）。\n  2. 一个包含了条件和批次协变量的正确设定模型（条件加批次分析）。\n- 在每次分析中，对所有基因应用目标水平 $q = 0.05$ 的 Benjamini–Hochberg (BH) 程序，以获得发现（discoveries）的数量（由于数据是在全局零假设下模拟的，这些发现都是假发现）。\n\n需要展示的科学原理：\n- 当条件和批次协变量相关（混杂）且批次效应很强时，省略批次协变量会在估计的条件效应中引入偏误，并导致假发现数量膨胀；而包含批次协变量则能消除偏误，并将假发现控制在目标FDR水平附近。\n- 当条件和批次协变量正交时，省略批次协变量不会在估计的条件效应中引入偏误；即使不进行校正，假发现也应接近目标FDR水平。\n- 作为一个边界情况，当批次效应为零时，包含或省略批次协变量应产生相似的行为。\n\n测试套件：\n在每种情况下模拟 $m = 2000$ 个基因。使用独立的基线水平 $\\mu_g \\sim \\mathcal{N}(0, 1)$，其中 $g = 1, \\dots, m$。对于每种情况，生成独立的高斯噪声 $\\varepsilon_{g i} \\sim \\mathcal{N}(0, \\sigma^2)$，其中 $\\sigma = 0.5$。\n\n将二进制条件协变量编码为 $x_i \\in \\{0, 1\\}$（代表两种条件），将二进制批次协变量编码为 $z_i \\in \\{0, 1\\}$（代表两个批次）。批次偏移是一个常数 $\\gamma$，当 $z_i = 1$ 时加上该值，当 $z_i = 0$ 时为 $0$。所有基因的真实条件效应均为 $0$。使用以下三种情况，每种情况都有特定的条件和批次样本组成：\n- 情况 $1$ (高度混杂，强批次效应)：批次 $1$ 有 $19$ 个来自条件 $0$ 的样本和 $1$ 个来自条件 $1$ 的样本；批次 $2$ 有 $1$ 个来自条件 $0$ 的样本和 $19$ 个来自条件 $1$ 的样本；$\\gamma = 1.5$；总样本数 $n = 40$。\n- 情况 $2$ (正交设计，强批次效应)：批次 $1$ 有 $10$ 个来自条件 $0$ 的样本和 $10$ 个来自条件 $1$ 的样本；批次 $2$ 有 $10$ 个来自条件 $0$ 的样本和 $10$ 个来自条件 $1$ 的样本；$\\gamma = 1.5$；总样本数 $n = 40$。\n- 情况 $3$ (高度混杂，无批次效应)：批次 $1$ 有 $9$ 个来自条件 $0$ 的样本和 $1$ 个来自条件 $1$ 的样本；批次 $2$ 有 $1$ 个来自条件 $0$ 的样本和 $9$ 个来自条件 $1$ 的样本；$\\gamma = 0.0$；总样本数 $n = 20$。\n\n随机性与可复现性：\n- 对情况 $1$ 使用固定的随机种子 $20240513$ 初始化生成器。对于情况 $2$ 和 $3$，您必须将情况索引添加到基础种子上（即 $20240513 + 2$ 和 $20240513 + 3$），以确保各情况之间的独立性，同时保持可复现性。\n\n统计分析要求：\n- 对于每个基因和每种情况，使用以下模型计算检验条件系数等于 $0$ 的零假设的双边 $p$ 值：\n  1. 一个带截距的仅条件线性模型。\n  2. 一个带截距的条件加批次线性模型。\n- 在每次分析中，对 $m$ 个 $p$ 值的集合使用水平为 $q = 0.05$ 的 Benjamini–Hochberg (BH) 程序，以确定发现（拒绝）的数量。由于根据设计所有零假设都为真，因此每个发现都是一个假阳性。报告两种分析的发现数量。\n\n要求的最终输出格式：\n- 您的程序应生成单行输出，包含 $6$ 个用逗号分隔的整数，并用方括号括起来，顺序如下：$[\\text{case1\\_naive}, \\text{case1\\_adjusted}, \\text{case2\\_naive}, \\text{case2\\_adjusted}, \\text{case3\\_naive}, \\text{case3\\_adjusted}]$，其中“naive”表示仅条件分析，“adjusted”表示条件加批次分析。\n\n无外部输入：\n- 程序必须完全自包含，不得读取任何输入或文件，也不得访问任何网络资源。所有数值必须按上述规定硬编码。\n\n角度单位和物理单位：\n- 不涉及角度或物理单位。\n\n答案类型：\n- 报告的 $6$ 个值中的每一个都必须是整数。\n\n您的目标是实现模拟和分析，以便输出通过这些测试用例来证明，在差异基因表达分析中，忽略一个强大的、混杂的批次效应会如何导致假发现膨胀，而包含批次指示符则能恢复有效的推断。", "solution": "所提出的问题是一个有效且定义明确的计算统计学练习，旨在展示高通量生物数据分析中的一个关键原则：遗漏变量偏误的危险。具体背景是差异基因表达分析，其中未测量或未建模的技术因素（如实验批次）可能会混淆感兴趣的生物信号。该问题具有科学依据，使用了标准的线性模型、普通最小二乘法 (OLS)、学生t检验以及用于控制假发现率 (FDR) 的 Benjamini-Hochberg (BH) 程序，这些都是该领域的基础方法。模拟参数被明确指定，确保了问题的自包含性和可复现性。我们将着手解决该问题。\n\n问题的核心在于通用线性模型，对于单个基因，我们将其写成矩阵形式 $Y = X\\beta + \\epsilon$。此处，$Y$ 是一个 $n \\times 1$ 的向量，表示 $n$ 个样本的表达量测量值；$X$ 是一个 $n \\times p$ 的设计矩阵，编码了 $p$ 个参数的实验协变量；$\\beta$ 是一个 $p \\times 1$ 的系数向量，待估计；$\\epsilon$ 是一个 $n \\times 1$ 的独立同分布误差项向量，假设服从高斯分布 $\\mathcal{N}(0, \\sigma^2)$。\n\n数据是在“全局零”场景下模拟的，意味着没有真实的差异表达。对于 $m=2000$ 个基因中的每一个（由 $g$ 索引）和 $n$ 个样本中的每一个（由 $i$ 索引），表达量 $y_{gi}$ 根据真实模型生成：\n$$y_{gi} = \\mu_g + \\gamma z_i + \\varepsilon_{gi}$$\n其中 $\\mu_g \\sim \\mathcal{N}(0, 1)$ 是基因特异性的基线表达水平，$\\gamma$ 是批次效应的大小，$z_i \\in \\{0, 1\\}$ 是批次指示协变量，而 $\\varepsilon_{gi} \\sim \\mathcal{N}(0, \\sigma^2)$ 是噪声项，其中 $\\sigma=0.5$。生物学条件的真实系数为零。\n\n我们将对每个基因使用两种不同的模型来分析这些模拟数据：\n\n1.  一个**错误设定或“朴素”模型**，该模型省略了批次协变量：\n    $y_{gi} = \\beta_{g0} + \\beta_{g1} x_i + e_{gi}$。设计矩阵 $X_{\\text{naive}}$ 有两列：一个截距（全为1的向量）和条件协变量向量 $x$。我们检验零假设 $H_0: \\beta_{g1} = 0$。\n\n2.  一个**正确设定或“校正”模型**，该模型包含了批次协变量：\n    $y_{gi} = \\beta'_{g0} + \\beta'_{g1} x_i + \\beta'_{g2} z_i + e'_{gi}$。设计矩阵 $X_{\\text{adj}}$ 有三列：一个截距、条件向量 $x$ 和批次向量 $z$。我们检验零假设 $H_0: \\beta'_{g1} = 0$。\n\n对于这两种模型，系数 $\\beta$ 均使用普通最小二乘法 (OLS) 进行估计，其解为 $\\hat{\\beta} = (X^T X)^{-1}X^T Y$。这可以同时对所有 $m$ 个基因进行高效求解。\n\n为了检验条件系数 $\\hat{\\beta}_1$（其中下标 $1$ 表示条件协变量 $x$ 的系数）的显著性，我们计算学生t统计量：\n$$t = \\frac{\\hat{\\beta}_1}{\\text{SE}(\\hat{\\beta}_1)}$$\n标准误 $\\text{SE}(\\hat{\\beta}_1)$ 是该系数估计量方差估计值的平方根。估计量的方差-协方差矩阵由 $\\text{Var}(\\hat{\\beta}) = \\sigma^2 (X^T X)^{-1}$ 给出。我们用其无偏估计量，即均方误差，来估计未知的误差方差 $\\sigma^2$：\n$$\\hat{\\sigma}^2 = \\frac{1}{n-p} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 = \\frac{\\text{RSS}}{n-p}$$\n其中 $\\hat{y}_i$ 是模型的拟合值，$\\text{RSS}$ 是残差平方和，$n$ 是样本数量，$p$ 是模型中的参数数量（即 $X$ 的列数）。令 $C = (X^T X)^{-1}$。$\\hat{\\beta}_1$ 的具体方差为 $\\hat{\\sigma}^2 C_{11}$（假设条件协变量是 $X$ 的第二列，索引为 $1$）。因此，标准误为 $\\text{SE}(\\hat{\\beta}_1) = \\sqrt{\\hat{\\sigma}^2 C_{11}}$。在零假设下，该t统计量服从自由度为 $n-p$ 的学生t分布。根据此分布，我们为每个基因计算一个双边 $p$ 值。\n\n由于我们正在进行 $m=2000$ 次假设检验（每个基因一次），我们必须进行多重检验校正以控制假发现的数量。我们将使用 Benjamini-Hochberg (BH) 程序，目标假发现率 (FDR) 为 $q = 0.05$。该程序如下：\n1.  将 $m$ 个 $p$ 值按升序排序：$p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(m)}$。\n2.  找到满足 $p_{(k)} \\le \\frac{k}{m} q$ 的最大整数 $k$。\n3.  如果存在这样的 $k$，则拒绝对应于 $p_{(1)}, \\dots, p_{(k)}$ 的所有零假设。发现的数量为 $k$。如果不存在这样的 $k$，则不拒绝任何假设，发现数量为 $0$。\n\n我们将对三种指定的情况实施这整个过程，这些情况在实验设计（混杂与正交）和批次效应的强度上有所不同。\n\n-   **情况 1 (混杂)：** 条件和批次协变量强相关。当批次效应 $\\gamma$ 很大时，省略批次协变量 $z$ 将导致对条件系数 $\\beta_1$ 的估计产生偏误。这种偏误被称为遗漏变量偏误，它与真实批次效应以及批次和条件协变量之间的相关性成正比。这种偏误会系统地使估计的条件效应偏离零，导致产生大量的小 $p$ 值，并在朴素分析中造成假发现的急剧膨胀。校正后的模型通过考虑 $z$ 来消除这种偏误，并提供有效的推断，将假发现数量恰当地控制在预期水平附近。\n\n-   **情况 2 (正交)：** 条件和批次协变量不相关（正交设计）。在这种情况下，遗漏变量偏误项为零。因此，即使存在强大的批次效应，朴素模型中条件系数的估计仍然是无偏的。预计朴素分析和校正分析都能正确地控制假发现率。\n\n-   **情况 3 (混杂，无批次效应)：** 设计与情况1一样是混杂的，但批次效应大小 $\\gamma$ 为零。遗漏变量偏误与 $\\gamma$ 成正比，因此如果 $\\gamma=0$，则没有偏误。朴素模型和校正模型都应该能正确执行，类似于情况2。\n\n程序将系统地执行这些模拟，对每种情况进行朴素和校正分析，应用 BH 程序，并报告由此产生的假发现数量，从而定量地展示这些基本的统计学原理。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import t\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation suite and print the final results.\n    \"\"\"\n\n    # Global parameters\n    m = 2000  # Number of genes\n    sigma = 0.5  # Noise standard deviation\n    q_level = 0.05  # Target FDR level for BH procedure\n\n    # Case 1: High confounding, strong batch\n    case1_params = {\n        'n_cond0_batch1': 19, 'n_cond1_batch1': 1,\n        'n_cond0_batch2': 1, 'n_cond1_batch2': 19\n    }\n    case1_gamma = 1.5\n    case1_seed = 20240513\n    \n    # Case 2: Orthogonal design, strong batch\n    case2_params = {\n        'n_cond0_batch1': 10, 'n_cond1_batch1': 10,\n        'n_cond0_batch2': 10, 'n_cond1_batch2': 10\n    }\n    case2_gamma = 1.5\n    case2_seed = 20240513 + 2\n\n    # Case 3: High confounding, no batch effect\n    case3_params = {\n        'n_cond0_batch1': 9, 'n_cond1_batch1': 1,\n        'n_cond0_batch2': 1, 'n_cond1_batch2': 9\n    }\n    case3_gamma = 0.0\n    case3_seed = 20240513 + 3\n    \n    test_cases = [\n        (case1_params, case1_gamma, m, sigma, q_level, case1_seed),\n        (case2_params, case2_gamma, m, sigma, q_level, case2_seed),\n        (case3_params, case3_gamma, m, sigma, q_level, case3_seed),\n    ]\n\n    results = []\n    for params in test_cases:\n        naive_discoveries, adjusted_discoveries = run_simulation(*params)\n        results.extend([naive_discoveries, adjusted_discoveries])\n\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef run_simulation(case_params, gamma, m, sigma, q, seed):\n    \"\"\"\n    Runs a single simulation case.\n    \n    Generates data, performs naive and adjusted analyses, and returns the number of discoveries for each.\n    \"\"\"\n    np.random.seed(seed)\n\n    # 1. Construct design vectors (x for condition, z for batch)\n    n01 = case_params['n_cond0_batch1']\n    n11 = case_params['n_cond1_batch1']\n    n02 = case_params['n_cond0_batch2']\n    n12 = case_params['n_cond1_batch2']\n    \n    n_batch1 = n01 + n11\n    n_batch2 = n02 + n12\n    n = n_batch1 + n_batch2\n\n    x = np.array([0]*n01 + [1]*n11 + [0]*n02 + [1]*n12)\n    z = np.array([0]*n_batch1 + [1]*n_batch2)\n\n    # 2. Generate gene expression data\n    # True model: y = mu + gamma*z + noise\n    mu_g = np.random.normal(0, 1, size=(m, 1))\n    noise = np.random.normal(0, sigma, size=(m, n))\n    Y = mu_g + gamma * z[np.newaxis, :] + noise\n\n    # 3. Define design matrices\n    X_naive = np.vstack([np.ones(n), x]).T\n    X_adjusted = np.vstack([np.ones(n), x, z]).T\n\n    # 4. Perform analyses and get discovery counts\n    naive_discoveries = perform_analysis(Y, X_naive, q)\n    adjusted_discoveries = perform_analysis(Y, X_adjusted, q)\n\n    return naive_discoveries, adjusted_discoveries\n\ndef perform_analysis(Y, X, q):\n    \"\"\"\n    Performs OLS regression and multiple testing correction for a set of genes.\n    \"\"\"\n    n, p = X.shape # n = samples, p = parameters\n    m = Y.shape[0] # m = genes\n    \n    # 1. Fit linear model for all genes at once using np.linalg.lstsq\n    # Y is (m, n), X is (n, p). We need to solve X @ B.T = Y.T for B.\n    # B will be (m, p). lstsq returns coefficients as (p, m).\n    beta_hat, rss_per_gene, _, _ = np.linalg.lstsq(X, Y.T, rcond=None)\n\n    # 2. Calculate t-statistics for the condition coefficient (at index 1)\n    df = n - p\n    sigma_sq_hat = rss_per_gene / df\n    \n    # The variance of beta_hat is diag(inv(X'X)) * sigma_hat^2\n    # We are interested in the coefficient for the condition 'x', which is at index 1\n    C = np.linalg.inv(X.T @ X)\n    se_beta1 = np.sqrt(sigma_sq_hat * C[1, 1])\n\n    # Avoid division by zero if standard error is somehow zero\n    # This should not happen in this problem's setup\n    t_stats = np.zeros(m)\n    valid_se = se_beta1 > 0\n    t_stats[valid_se] = beta_hat[1, valid_se] / se_beta1[valid_se]\n    \n    # 3. Calculate two-sided p-values\n    p_values = 2 * t.sf(np.abs(t_stats), df=df)\n\n    # 4. Apply Benjamini-Hochberg procedure\n    num_discoveries = bh_procedure(p_values, q)\n    \n    return num_discoveries\n\ndef bh_procedure(p_values, q):\n    \"\"\"\n    Applies the Benjamini-Hochberg procedure to control FDR.\n    \"\"\"\n    m = len(p_values)\n    if m == 0:\n        return 0\n        \n    p_values_sorted = np.sort(p_values)\n    ranks = np.arange(1, m + 1)\n    thresholds = (ranks / m) * q\n    \n    # Find all p-values that are below the BH threshold\n    significant_mask = p_values_sorted = thresholds\n    \n    if np.any(significant_mask):\n        # The number of discoveries is the rank of the last p-value\n        # that is below its threshold\n        k = np.max(np.where(significant_mask)[0])\n        num_discoveries = k + 1\n    else:\n        num_discoveries = 0\n        \n    return num_discoveries\n\nif __name__ == '__main__':\n    solve()\n```", "id": "2385475"}, {"introduction": "典型的基因组学实验涉及成千上万个假设检验，这极大地增加了出现假阳性的概率。本练习 [@problem_id:2385494] 旨在应对这一挑战，要求您亲自实现Benjamini-Hochberg（BH）程序，这是多重检验校正的基石。通过从零开始编写此算法，您将掌握控制伪发现率（False Discovery Rate, FDR）的核心机制，并理解原始$p$值是如何转化为更可靠的校正$p$值（或$q$值）以供后续解释的。", "problem": "给定在比较两种条件的差异基因表达实验中，由 $m$ 个独立的基因水平零假设产生的原始 $p$ 值集合。设零假设集合为 $\\{H_1,\\dots,H_m\\}$，对应的原始 $p$ 值为 $p_1,\\dots,p_m \\in [0,1]$。对于一个目标水平 $q \\in (0,1)$，用于将错误发现率 (False Discovery Rate, FDR) 控制在水平 $q$ 的 Benjamini–Hochberg (BH) 程序定义如下。将 $p$ 值按非递减顺序排列为 $p_{(1)} \\le \\dots \\le p_{(m)}$，其中下标表示顺序统计量。定义索引\n$$\nk \\;=\\; \\max\\left\\{ i \\in \\{1,\\dots,m\\} \\;:\\; p_{(i)} \\le \\frac{i}{m}\\,q \\right\\},\n$$\n约定如果该集合为空，则不拒绝任何假设。那么，BH 拒绝集是所有原始 $p$ 值不超过阈值 $p_{(k)}$ 的假设，即\n$$\n\\mathcal{R} \\;=\\; \\{ j \\in \\{1,\\dots,m\\} \\;:\\; p_j \\le p_{(k)} \\},\n$$\n当 $k$ 存在时，否则 $\\mathcal{R}=\\varnothing$。BH 校正 $p$ 值（在某些情况下也称为 BH $q$ 值）对每个假设的定义如下：首先为第 $i$ 个顺序统计量赋值\n$$\n\\tilde{p}_{(i)} \\;=\\; \\min_{j \\in \\{i,\\dots,m\\}} \\left( \\frac{m}{j}\\,p_{(j)} \\right),\n$$\n然后通过 $\\min\\{\\tilde{p}_{(i)},1\\}$ 截断至 $1$，最后映射回原始假设的顺序。为了在存在相等 $p$ 值的情况下使排序分配具有确定性，请使用一种稳定的排序方法，通过增加原始索引来打破平局，即如果 $p_a=p_b$ 且 $ab$ 则 $(p_a, a)$ 排在 $(p_b, b)$ 之前。\n\n您的任务是编写一个可执行的程序，该程序接受一个由 $m$ 个原始 $p$ 值组成的集合和一个目标 FDR 水平 $q$，并返回 BH 校正 $p$ 值和拒绝假设的原始（基于0）索引。\n\n测试套件：\n您必须对以下四种测试情况运行您的程序，并以指定格式的单行输出报告结果。\n\n-   情况 1：$p$-values: $(0.001, 0.04, 0.03, 0.2, 0.5, 0.0005, 0.07, 0.9)$, $q = 0.1$\n-   情况 2：$p$-values: $(0.0, 1.0, 0.5, 0.05, 0.2)$, $q = 0.05$\n-   情况 3：$p$-values: $(0.02, 0.02, 0.02, 0.5, 0.8, 0.9)$, $q = 0.1$\n-   情况 4：$p$-values: $(0.2, 0.3, 0.4, 0.6, 0.8)$, $q = 0.01$\n\n要求的最终输出格式：\n- 您的程序应生成一个单行输出，包含一个嵌套列表，格式为 `[[[adj_p_case1], [rej_idx_case1]], [[adj_p_case2], [rej_idx_case2]], ...]`。\n- 所有校正后的 $p$ 值必须四舍五入到六位小数。\n- 拒绝的索引列表必须按升序排序。\n\n无外部输入：\n- 您的程序必须是完全自包含的，并且不能读取任何输入或文件或访问任何网络资源。所有数值必须按上述规定硬编码。\n\n角度单位和物理单位：\n- 不涉及角度或物理单位。\n\n答案类型：\n- 最终输出应为字符串格式，不包含任何空格。", "solution": "问题陈述经评估有效。它基于标准且科学上合理的 Benjamini-Hochberg 程序，提出了一个清晰、定义明确的计算任务。该程序是控制错误发现率的一种基本方法，在计算生物学和统计学中广泛应用。定义、条件和测试用例是完整、一致和客观的，从而能够得出一个唯一且可验证的解。\n\n任务是实现 Benjamini-Hochberg (BH) 程序。给定来自多个假设检验的一组 $m$ 个原始 $p$ 值 $\\{p_1, \\dots, p_m\\}$ 和一个目标错误发现率 (FDR) 水平 $q$，我们必须计算 BH 校正 $p$ 值并确定被拒绝的假设集合。该程序是确定性的，将通过一系列直接源自所提供数学定义的原则性步骤来实现。\n\n设 $m$ 为假设的总数。算法流程如下：\n\n1.  **数据结构化与排序**：每个原始 $p$ 值 $p_j$ 都与其原始的基于 $0$ 的索引 $j$ 相关联。然后将生成的配对 $(p_j, j)$ 按 $p_j$ 的非递减顺序排序。问题指定了一种稳定的排序机制来处理平局：如果对于原始索引 $ab$ 而 $p_a=p_b$，则 $(p_a, a)$ 排在 $(p_b, b)$ 之前。这确保了排序结果的唯一性。此过程产生了一个有序的 $p$ 值列表 $p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(m)}$，以及它们对应的原始索引。\n\n2.  **确定拒绝阈值**：我们遍历排序后的 $p$ 值，找到满足 BH 条件 $p_{(i)} \\le \\frac{i}{m}q$ 的最大索引 $k$（其中 $i$ 是基于 $1$ 的秩）。如果不存在这样的 $i$，则不拒绝任何假设。如果存在，$p_{(k)}$ 就成为我们的拒绝阈值。\n\n3.  **识别被拒绝的假设**：如果 $k$ 存在，拒绝集则由所有满足 $p_j \\le p_{(k)}$ 的假设组成。然后收集这些假设的原始索引。\n\n4.  **计算校正 $p$ 值**：对于每个排序后的 $p$ 值 $p_{(i)}$，我们计算一个临时的校正值 $\\frac{m}{i} p_{(i)}$。然后，为了确保调整后的 $p$ 值是单调非递减的，我们将第 $i$ 个调整后的 $p$ 值 $\\tilde{p}_{(i)}$ 定义为从 $i$ 到 $m$ 的所有后续临时值的最小值。最后，将所有大于 $1$ 的值截断为 $1$。\n\n5.  **映射回原始顺序**：使用在排序步骤中保存的原始索引，将计算出的校正 $p$ 值重新排列回与输入 $p$ 值相对应的原始顺序。\n\n6.  **格式化输出**：将校正后的 $p$ 值四舍五入到六位小数，并对被拒绝的假设的索引进行排序。然后将所有测试用例的结果编译成指定的单行字符串格式。\n\n该实现将直接遵循这些步骤，以确保准确性和对问题要求的遵守。", "answer": "```python\nimport numpy as np\n\ndef _format_output(data):\n    \"\"\"\n    Custom recursive function to format the final list into a string\n    without spaces and with floats formatted to 6 decimal places.\n    \"\"\"\n    if isinstance(data, list):\n        return f\"[{','.join(_format_output(item) for item in data)}]\"\n    if isinstance(data, float):\n        return f\"{data:.6f}\"\n    return str(data)\n\ndef benjamini_hochberg(p_values: np.ndarray, q: float):\n    \"\"\"\n    Performs the Benjamini-Hochberg procedure for FDR control.\n\n    Args:\n        p_values: A numpy array of raw p-values.\n        q: The target False Discovery Rate level.\n\n    Returns:\n        A tuple containing:\n        - A list of BH adjusted p-values, rounded to 6 decimal places, in original order.\n        - A sorted list of 0-based indices of rejected hypotheses.\n    \"\"\"\n    m = len(p_values)\n    if m == 0:\n        return [], []\n        \n    original_indices = np.arange(m)\n    \n    # Sort p-values while keeping track of original indices.\n    # The 'stable' kind ensures that for equal p-values, the original order is preserved,\n    # satisfying the problem's tie-breaking rule.\n    sorted_order_indices = np.argsort(p_values, kind='stable')\n    sorted_p_values = p_values[sorted_order_indices]\n    \n    # --- Step 1: Find rejection threshold ---\n    ranks = np.arange(1, m + 1)\n    bh_thresholds = (ranks / m) * q\n    \n    significant_mask = sorted_p_values = bh_thresholds\n    \n    rejected_indices = []\n    if np.any(significant_mask):\n        # Find the largest rank k satisfying the BH condition\n        k_rank = np.max(ranks[significant_mask])\n        \n        # The rejection threshold is the p-value at this rank k\n        rejection_threshold = sorted_p_values[k_rank - 1]\n        \n        # Identify all hypotheses with original p-values = threshold\n        rejected_mask = p_values = rejection_threshold\n        rejected_indices = sorted(original_indices[rejected_mask].tolist())\n\n    # --- Step 2: Calculate adjusted p-values ---\n    # Calculate raw scaled p-values: (m/i) * p_(i)\n    scaled_p_values = (m / ranks) * sorted_p_values\n    \n    # Enforce monotonicity by taking the cumulative minimum from the end (right-to-left)\n    adj_p_sorted = np.minimum.accumulate(scaled_p_values[::-1])[::-1]\n    \n    # Truncate values at 1.0\n    adj_p_sorted = np.minimum(adj_p_sorted, 1.0)\n    \n    # Unsort the adjusted p-values to match the original p-value order\n    adj_p_original = np.empty(m)\n    adj_p_original[sorted_order_indices] = adj_p_sorted\n    \n    # Round to 6 decimal places for final output\n    adj_p_rounded = [round(p, 6) for p in adj_p_original]\n\n    return adj_p_rounded, rejected_indices\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the final result.\n    \"\"\"\n    test_cases = [\n        ((0.001, 0.04, 0.03, 0.2, 0.5, 0.0005, 0.07, 0.9), 0.1),\n        ((0.0, 1.0, 0.5, 0.05, 0.2), 0.05),\n        ((0.02, 0.02, 0.02, 0.5, 0.8, 0.9), 0.1),\n        ((0.2, 0.3, 0.4, 0.6, 0.8), 0.01),\n    ]\n\n    results = []\n    for p_tuple, q_val in test_cases:\n        p_values_np = np.array(p_tuple)\n        adj_p, rej_idx = benjamini_hochberg(p_values_np, q_val)\n        results.append([adj_p, rej_idx])\n    \n    # Print the final result in the specified single-line format\n    print(_format_output(results))\n\nsolve()\n```", "id": "2385494"}]}