## 引言
随着高通量测序技术的飞速发展，我们已经进入了一个能够以前所未有的深度和广度探究生命蓝图的时代。然而，这些技术产生的原始数据是数以亿计的短DNA序列片段（读段），本身是无序且带有噪音的。基因组组装，即将这些碎片化的信息拼接成完整或接近完整的基因组序列的过程，是几乎所有下游基因组学分析的起点。在众多组装策略中，基于参考的基因组组装（Reference-based Genome Assembly）已成为个体或群体“重测序”项目的基石。

该方法的核心思想是利用一个已存在的高质量同物种[参考基因组](@entry_id:269221)作为“骨架”，将测序[读段比对](@entry_id:265329)上去，从而重建目标样本的基因组。这种策略虽然高效，但其背后是一个复杂的多阶段计算流程，充满了精巧的算法和严谨的[统计模型](@entry_id:755400)。对于许多研究人员而言，这个流程可能像一个“黑箱”，输入测序数据，输出变异列表，但对其内部机制的理解不足，往往会导致对结果的误读或对潜在偏差的忽视。本文旨在系统性地揭开这个黑箱，阐明其内在逻辑与科学原理。

为了实现这一目标，本文将分为三个核心部分。在“**原理与机制**”一章中，我们将深入剖析从[数据预处理](@entry_id:197920)到[序列比对](@entry_id:172191)，再到共识[序列生成](@entry_id:635570)的每一个技术环节，揭示其背后的算法思想与统计学基础。随后，在“**应用与交叉学科联系**”一章中，我们将展示这一核心技术如何在变异发现、[转录组学](@entry_id:139549)、微生物学乃至临床诊断等多个领域发挥关键作用。最后，“**动手实践**”部分将通过具体的计算问题，帮助读者将理论知识转化为解决实际问题的能力。现在，让我们从其最根本的原理与机制开始探索。

## 原理与机制

本章在前一章介绍背景的基础上，深入探讨基于参考基因组组装的核心原理与底层机制。参考基因组组装并非单一算法，而是一个复杂的多阶段流程，其核心目标是从大量短的、带噪声的测序读段（reads）中，重建一个或多个与已知[参考基因组](@entry_id:269221)序列高度相似的供体基因组序列。我们将系统地剖析这一流程的每个阶段，从[数据预处理](@entry_id:197920)到最终的[共有序列](@entry_id:274833)生成，揭示其背后的计算与统计学基础。

### 理论基础：贝叶斯视角下的基因组组装

从根本上说，基因组组装可以被形式化为一个统计推断问题。给定一个由高通量测序产生的读段集合 $\mathcal{R} = \{r_1, \dots, r_n\}$，我们的目标是推断出最可能产生这些读段的未知目标基因组 $T$。在贝叶斯框架下，这相当于寻找能最大化后验概率 $P(T | \mathcal{R})$ 的基因组序列 $T$。根据贝叶斯定理，后验概率可以表示为：

$P(T | \mathcal{R}) \propto P(\mathcal{R} | T) P(T)$

其中，$P(\mathcal{R} | T)$ 是**似然** (likelihood)，表示在给定真实基因组为 $T$ 的情况下，观测到读段集合 $\mathcal{R}$ 的概率。这一项由测序仪的错误模型决定。$P(T)$ 是**先验概率** (prior probability)，代表了在观测到任何测[序数](@entry_id:150084)据之前，我们对基因组 $T$ 可能是什么样子的先验信念。

[参考基因组](@entry_id:269221)组装与**[从头组装](@entry_id:172264)** (*de novo* assembly) 的一个根本区别就在于对[先验概率](@entry_id:275634) $P(T)$ 的处理 [@problem_id:4604764]。在[从头组装](@entry_id:172264)中，由于没有预先的结构信息，我们通常假设一个信息量很低的先验（例如，除了基因组长度等基本约束外，所有可能的序列都是等概率的）。因此，[从头组装](@entry_id:172264)主要依赖于似然 $P(\mathcal{R} | T)$，通过分析读段之间的重叠关系（如构建[德布鲁因图](@entry_id:263552)）来推断基因组序列。

相比之下，参考基因组组装利用了一个强大的先验信息：一个已知的、高质量的同物种**[参考基因组](@entry_id:269221)** $R$。我们假设待组装的目标基因组 $T$ 与参考基因组 $R$ 在很大程度上是共线性的，并且两者之间的差异（如单[核苷](@entry_id:195320)酸变异、小的[插入和删除](@entry_id:178621)）是有限的。这个假设极大地增强了我们的先验 $P(T)$。具体来说，该先验会为那些与参考基因组 $R$ 相似（即[编辑距离](@entry_id:152711)较小）的基因组赋予高得多的概率，而为那些差异巨大的基因组赋予极低的概率。

这种强先验带来的最直接好处是**搜索空间的大幅缩减**。一个长度为 $G$ 的基因组，其可能的[序列空间](@entry_id:153584)大小为 $|\Sigma|^G$（其中 $\Sigma = \{A, C, G, T\}$），这是一个天文数字。而参考基因组组装将搜索范围从这个巨大的空间，缩小到参考基因组 $R$ 周围的一个小“球体”内。例如，如果我们假设 $T$ 与 $R$ 最多只有 $r$ 个替换差异，那么候选基因组的数量级大约为 $\sum_{i=0}^{r} \binom{G}{i} (|\Sigma| - 1)^{i}$。当 $r \ll G$ 时，这个数字远小于 $|\Sigma|^G$ [@problem_id:4604764]。这使得计算上处理成为可能。

整个[参考基因组](@entry_id:269221)组装流程可以被概念化为一个由多个映射组成的流水线 [@problem_id:4604820]：首先，将测序读段映射和比对到参考基因组上；其次，基于比对结果进行统计推断，识别出与[参考基因组](@entry_id:269221)的差异（即变异）；最后，整合这些变异信息，生成最终的[共有序列](@entry_id:274833)。接下来的章节将详细阐述实现这些阶段的关键机制。

### [数据预处理](@entry_id:197920)：确保高保真度的证据

在将读段用于组装之前，必须进行严格的质量控制和预处理，以修正测序过程中引入的系统性偏差和噪音。这些步骤对于确保下游分析（尤其是[变异检测](@entry_id:177461)）的准确性至关重要。

#### 重复读段的识别与标记

在测序文库的制备过程中，**[聚合酶链式反应](@entry_id:142924) (PCR)** 被用来扩增DNA片段。理想情况下，每个原始DNA分子在测序结果中应只出现一次。然而，PCR过程可能导致某些片段被过度扩增，产生多个完全相同的副本，这些被称为**PCR重复** (PCR duplicates)。此外，在测序仪的成像阶段，单个DNA分子簇可能被错误地识别为多个独立的簇，从而产生所谓的**光学重复** (optical duplicates)。

无论是PCR重复还是光学重复，它们都源自同一个原始DNA分子，因此携带的是冗余信息。如果在分析中不加处理，这些重复读段会人为地夸大特定基因组区域的覆盖深度，从而可能导致在变异检测中对某些等位基因的证据产生错误的[置信度](@entry_id:267904)。

识别重复读段的基本原理是“**不大可能发生的巧合**” [@problem_id:4604779]。基因组非常庞大，两个独立的DNA片段在经过随机打断后，恰好具有完全相同的起始和终止位置的概率极低。因此，当多个读段对比对到参考基因组的完全相同的位置和方向时，它们极有可能是重复，而非偶然的碰撞。

形式上，我们可以为每个比对上的读段或读段对定义一个**比对密钥** (alignment key)。对于单端测序，该密钥是其5'端起始坐标和链方向的组合 $(s, o)$。对于[双端测序](@entry_id:272784)，它通常是两个读段的5'端起始坐标和各自链方向的组合 $(s_1, s_2, o_1, o_2)$。通过按此密钥对所有读段进行分组，凡是组内成员超过一个的，就被视为一个重复组。

为了区分PCR重复和光学重复，我们需要利用非基因组的元数据，即每个读段在测序芯片（flow cell）上的物理坐标 $(x,y)$。在同一个重复组内，如果两个读段的物理坐标非常接近（在某个距离阈值 $\delta$ 之内），它们就被标记为光学重复；如果它们的物理坐标相距很远，则被认为是PCR重复。在典型的流程中，除了每个重复组中留下的一个读段外，其余的都会被标记为“重复”，以便在后续分析中被忽略。

#### 碱基质量得分校准

测序仪为每个生成的碱基提供一个**Phred质量得分** ($Q$)，它旨在量化该碱基被错误识别的概率 $p_{\text{err}}$，其定义为 $Q \equiv -10 \log_{10}(p_{\text{err}})$。然而，测序仪报告的原始质量得分往往存在系统性偏差，其准确性会受到诸如读段中的位置（**周期**，cycle）、邻近的序列模式（**上下文**，context）以及具体的测序批次（**机器运行**，run）等因素的影响。

**碱基质量得分校准 (Base Quality Score Recalibration, BQSR)** 是一种统计学校正方法，旨在修正这些系统性错误 [@problem_id:4604747]。其核心思想是，通过将[读段比对](@entry_id:265329)到高质量的[参考基因组](@entry_id:269221)上（并排除已知的多态性位点），我们可以统计在不同协变量组合下（例如，“第10个周期，前一个碱基是G”）的实际错误率。

具体来说，BQSR通常构建一个[广义线性模型 (GLM)](@entry_id:749787)。该模型在**[对数优势比](@entry_id:141427) (log-odds)** 尺度上对错误率进行建模，假设不同协变量的效应是可加的：

$\text{logit}(p_{\text{err}}(x)) \equiv \ln\left(\frac{p_{\text{err}}(x)}{1-p_{\text{err}}(x)}\right) = \beta_{0} + \beta_{\text{cycle}}(j) + \beta_{\text{context}}(k) + \beta_{\text{run}}(l)$

这里，$x$ 代表一组协变量（周期$j$、上下文$k$、运行$l$），$\beta$ 是模型参数。通过统计每个协变量水平下的经验错误率（通常使用贝叶斯方法，如结合[二项分布](@entry_id:141181)似然和Beta先验的**Beta-[二项模型](@entry_id:275034)**进行[稳健估计](@entry_id:261282)），可以拟合出这些参数。一旦模型建立，就可以为每个读段中的每个碱基计算一个校正后的、更准确的质量得分。这个校正后的得分将用于下游的变异检测，从而提高其准确性。

### 比对阶段：将读段放置在参考基因组上

比对是参考基因组组装流程的核心，它负责将数百万甚至数十亿个短读段精确地定位到长达数十亿碱基的[参考基因组](@entry_id:269221)上。这个过程可以看作是实现前文提到的映射函数 $f_1: (\mathcal{R}, G) \to \mathcal{A}$ [@problem_id:4604820]。这一阶段面临两大挑战：速度和准确性。

#### 速度的挑战：索引与播种

将每个短读段与参考基因组的每个可能位置进行比对，在计算上是不可行的。为了解决这个问题，现代比对算法普遍采用一种“**播种-延伸**”(seed-and-extend) 的策略。该策略首先快速识别出读段与参考基因组之间可能存在匹配的候选区域（播种），然后仅在这些候选区域内执行更耗时但更精确的[局部比对](@entry_id:164979)（延伸）。

##### 用于快速查找的索引：BWT

为了实现快速播种，需要对参考基因组建立一个高效的**索引** (index)。一种广泛使用的索引结构是基于**[Burrows-Wheeler变换](@entry_id:269666) (BWT)** 和**后缀数组 (Suffix Array, SA)** 的组合。

一个字符串 $R$ 的后缀数组 $SA$ 是一个整数数组，它存储了 $R$ 所有后缀按[字典序](@entry_id:143032)排序后的起始位置。BWT则是对 $R$ 的所有[循环移位](@entry_id:177315)进行[字典序](@entry_id:143032)排序后，取结果矩阵的最后一列得到的字符串，我们记为 $L$。BWT的一个神奇特性是，它通常比原始字符串更易于压缩，同时保留了足够的信息以支持快速的子串查找。

这种查找能力的核心在于**后至前映射 (Last-to-First Mapping, LF-mapping)** [@problem_id:4604765]。LF-mapping可以找到 $L$ 字符串中任意位置的字符在排序后的首列 $F$（$F$ 就是 $R$ 中所有字符的排序列表）中对应的位置。这个映射可以通过两个辅助[数据结构](@entry_id:262134)高效计算：$C$ 表和 $\text{Occ}$ 函数。$C[c]$ 存储了在 $R$ 中[字典序](@entry_id:143032)严格小于字符 $c$ 的字符总数，而 $\text{Occ}(c, i)$ 存储了字符 $c$ 在 BWT 字符串 $L$ 的前缀 $L[0..i-1]$ 中出现的次数。LF-mapping的公式如下：

$\text{LF}(i) = C[L[i]] + \text{Occ}(L[i], i)$

利用LF-mapping，我们可以在BWT索引上执行**向后搜索** (backward search)。从查询模式（例如，一个读段）的最后一个字符开始，我们可以迭代地在后缀数组对应的排序区间内缩小范围，每向前扩展一个字符，就更新一次区间。最终，区间的宽度就代表了该查询模式在参考基因组中出现的次数。这个过程非常快，因为它不需要在参考基因组上进行线性扫描。

##### 播种的[启发式](@entry_id:261307)策略：极小值聚合器

即使使用BWT索引，对一个读段中的所有可能的 $k$-mer（长度为 $k$ 的子串）都进行查找仍然可能非常耗时。为了进一步提高效率，许多比对器采用了一种名为**极小值聚合器 (minimizers)** 的[启发式](@entry_id:261307)采样策略。

其思想是，我们不索引参考基因组的所有 $k$-mer，而只索引其中的一个子集。这个子集是通过以下方式选择的：在一个长度为 $w$ 的连续 $k$-mer 窗口中，只选择具有最小哈希值的那个 $k$-mer 作为代表 [@problem_id:4604781]。通过这种方式，我们可以显著减少需要索引和查询的 $k$-mer 数量，同时保证任何足够长的匹配区域至少有一个被选中的 $k$-mer 作为“锚点”。

可以从理论上分析这种[采样策略](@entry_id:188482)的效率。在一个理想化的随机序列模型中，假设不同 $k$-mer 的哈希值是独立同分布的[连续随机变量](@entry_id:166541)，那么被选中的 $k$-mer 的**期望密度**（即被选中的 $k$-mer 占总 $k$-mer 的比例）可以被精确地计算出来，其值为：

$\text{Density} = \frac{2}{w+1}$

这个简洁的公式表明，通过调整窗口大小 $w$，我们可以在索引大小（速度）和采样密度（敏感度）之间做出权衡。

#### 准确性的挑战：空位[局部比对](@entry_id:164979)

通过播种策略找到候选区域后，下一步是在这些区域内进行精确的[局部比对](@entry_id:164979)。由于测序错误和真实的生物学变异（如[插入和删除](@entry_id:178621)，统称为**indels**），读段和参考序列之间通常不会是完美的匹配。因此，需要一种能够处理错配和空位的比对算法。

##### [仿射空位罚分](@entry_id:169823)：更符合生物学现实的打分模型

**[Smith-Waterman算法](@entry_id:179006)**是寻找两条序列之间最佳[局部比对](@entry_id:164979)的黄金标准。该算法的核心是定义一个**打分矩阵** (scoring matrix)，它为匹配、错配和空位分配分数（或罚分），然后通过动态规划找到一条得分最高的比对路径。

对于空位的罚分，简单的**[线性空位罚分](@entry_id:168525)**模型（即罚分与空位长度 $\ell$ 成正比，罚分 $= d \cdot \ell$）在生物学上并不十分合理。因为单个突变事件（如DNA聚合酶滑链）很可能一次性导致一个连续的多碱基插入或删除，而不是多个独立的单碱基indel事件。因此，一个更现实的模型应该对“打开”一个新的空位施加较大的初始罚分，而对“延伸”一个已有的空位施加较小的罚分。

这就是**[仿射空位罚分](@entry_id:169823) (affine gap penalty)** 模型的思想，其罚分形式为：

$\text{罚分} = g_o + \ell \cdot g_e$

其中，$g_o$ 是**空位开放罚分** (gap opening penalty)，$g_e$ 是**空位延伸罚分** (gap extension penalty)，并且 $g_o > 0, g_e > 0$。

我们可以从一个简单的概率模型（**[配对隐马尔可夫模型](@entry_id:162687)**，pair-HMM）来理解仿射罚分的理论基础 [@problem_id:4604731]。在这个模型中，比对路径由匹配、[插入和删除](@entry_id:178621)三种状态之间的转换生成。从匹配状态进入一个indel状态的概率（对应于打开空位）很低，而在indel状态内自我转换的概率（对应于延伸空位）相对较高。一个长度为 $\ell$ 的indel的生成概率大致正比于 $p_s \cdot p_e^{\ell-1}$，其中 $p_s$ 是打开概率，$p_e$ 是延伸概率。其[负对数似然](@entry_id:637801)得分自然地呈现出仿射形式：$S(\ell) = [-\log(p_s) + \dots] + \ell \cdot [-\log(p_e)]$。这表明，与将一个长indel拆成多个短indel相比，模型更倾向于一个连续的indel，这与生物学观察相符。

##### [Gotoh算法](@entry_id:176435)与[带状比对](@entry_id:178225)

为了在动态规划中有效地实现[仿射空位罚分](@entry_id:169823)，需要使用一种改进的[Smith-Waterman算法](@entry_id:179006)，通常称为**[Gotoh算法](@entry_id:176435)**。该算法使用三个动态规划矩阵，分别记录以匹配/错配、以X序列中的空位（水平移动）或以Y序列中的空位（垂直移动）结尾的最佳比对得分 [@problem_id:4604774]。令 $H(i,j)$, $E(i,j)$, $F(i,j)$ 分别为比对到位置 $(i,j)$ 的这三种情况的最高得分，其递推关系如下：

$E(i,j) = \max\{ H(i,j-1) - g_{o} - g_{e}, E(i,j-1) - g_{e} \}$
$F(i,j) = \max\{ H(i-1,j) - g_{o} - g_{e}, F(i-1,j) - g_{e} \}$
$H(i,j) = \max\{ 0, H(i-1,j-1) + S(x_{i},y_{j}), E(i,j), F(i,j) \}$

其中，$S(x_i, y_j)$ 是碱基 $x_i$ 和 $y_j$ 的替换得分，$H(i,j)$ 中的 $0$ 确保了比对是局部的。该算法的时间复杂度为 $O(nm)$，其中 $n$ 和 $m$ 是两条序列的长度。

在“播种-延伸”的框架下，我们不需要在整个[参考基因组](@entry_id:269221)上运行此算法。由于播种已经将比对限制在[参考基因组](@entry_id:269221)的一个小片段内，并且我们预计比对路径不会偏离主对角线太远，因此可以采用**[带状比对](@entry_id:178225) (banded alignment)**。这意味着动态规划矩阵的计算只在一个宽度为 $w$ 的对角线带内进行，从而将时间复杂度从 $O(nm)$ 显著降低到 $O(w \cdot \min(n,m))$ [@problem_id:4604774]。

### 解读比对结果：量化置信度与偏差

比对完成后，结果通常以**序列比对/图谱 (Sequence Alignment/Map, SAM)** 格式或其二进制版本BAM存储。这些文件不仅包含了读段的序列和它在参考基因组上的位置，还包含了一系列量化[比对质量](@entry_id:170584)和特性的重要信息。

#### SAM格式中的关键信息：CIGAR与MAPQ

在SAM文件中，每一行代表一个读段的比对记录。其中两个最关键的字段是**[CIGAR字符串](@entry_id:263221)**和**[比对质量](@entry_id:170584) (Mapping Quality, MAPQ)**。

[CIGAR字符串](@entry_id:263221)（Compact Idiosyncratic Gapped Alignment Report）是一种紧凑的表示法，用一系列“长度+操作符”的组合精确地描述了读段是如何与参考序列比对的 [@problem_id:4604748]。常见的操作符包括：
- `M` 或 `=` 和 `X`: 匹配或错配（消耗读段和参考序列）
- `I`: 插入（消耗读段，不消耗参考序列）
- `D`: 删除（消耗参考序列，不消耗读段）
- `S`: 软剪切（读段的部分序列未参与比对）
- `N`: 跳过区域（通常用于RNA-seq中跨越[内含子](@entry_id:144362)）

通过解析[CIGAR字符串](@entry_id:263221)，我们可以精确地重建比对，计算比对长度、错配数、indel等信息。

#### [比对质量](@entry_id:170584) (MAPQ)：应对重复序列的挑战

**MAPQ**是一个至关重要的指标，它量化了比对位置的**不确定性**。MAPQ被定义为比对位置是错误的后验概率的Phred标度值：

$\text{MAPQ} \equiv -10 \log_{10}(p_{\text{err}})$

其中 $p_{\text{err}}$ 是报告的比对位置是错误的后验概率。一个高的MAPQ值（例如40）意味着比对位置非常可信（[错误概率](@entry_id:267618)为 $10^{-4}$），而一个低的MAP[Q值](@entry_id:265045)（例如0）则意味着该读段可能来自基因组的多个地方，当前报告的位置是随机选择的一个。

比对不确定性的主要来源是基因组中的**重复序列**。如果一个读段可以同样好地比对到基因组的 $k$ 个不同位置，那么它的真实来源就是不明确的。假设这 $k$ 个位置是等可能的，那么任何一个被报告的位置是正确位置的后验概率就是 $1/k$。因此，该比对是错误的概率为 $p_{\text{err}} = 1 - 1/k = (k-1)/k$。对应的MAP[Q值](@entry_id:265045)为 [@problem_id:4604825]：

$\text{MAPQ}(k) = -10 \log_{10}\left(\frac{k-1}{k}\right) = 10 \log_{10}\left(\frac{k}{k-1}\right)$

这个公式清晰地表明，随着可能位置数 $k$ 的增加，MAPQ值会迅速下降。当 $k=2$ 时，MAPQ约为3；当 $k=10$ 时，MAPQ约为0.4。当 $k$ 趋于无穷大时，MAPQ趋于0，表示[置信度](@entry_id:267904)完全丧失。在下游分析（如变异检测）中，来自低MAPQ读段的证据通常会被打折扣或完全忽略。

#### 参考等位基因偏好

一个更微妙的问题是**参考等位基因偏好 (reference allele bias)**。在使用[参考基因组](@entry_id:269221)进行比对时，流程本身可能不自觉地偏向于与[参考基因组](@entry_id:269221)一致的序列。这意味着，携带参考等位基因的读段可能比携带变异等位基因的读段更容易获得高的比对得分，从而导致变异等位基因的证据被人为地削弱。

这种偏好可以从两个方面产生 [@problem_id:4604784]：
1.  **全局可比对性差异**：包含某些变异的序列可能位于基因组中更复杂的区域（例如，重复区域的边缘），导致其整体比对的[先验概率](@entry_id:275634)（**作图倾向性**，$m_X$）降低。
2.  **[局部比对](@entry_id:164979)打分差异**：比对算法的打分函数可能对错配有固定的罚分，但实际上，一个读段与参考序列存在一个错配，比它与一个真实的非参考单倍型存在一个错配，对总比对得分的影响可能不同（通过**错配权重** $\eta_X$ 来建模）。

我们可以建立一个模型来量化这种偏好。假设我们正在比较两个假设：该位点是参考等位基因 $\mathcal{H}_R$ 或备选等位基因 $\mathcal{H}_A$。由比对不对称性引入的[后验优势比](@entry_id:164821)的对数增量 $B$ 可以表示为：

$B = N \ln\left(\frac{m_R}{m_A}\right) + c_A \ln(\eta_R) - c_R \ln(\eta_A)$

其中 $N$ 是总读段数，$c_R$ 和 $c_A$ 是支持参考和备选等位基因的读段数。这个表达式清晰地显示了作图倾向性 ($m_R/m_A$) 和错配权重 ($\eta_R, \eta_A$) 的不对称性如何系统地改变我们对变异的判断，而这种改变与真实的测序错误无关。意识到并校正这种偏好对于准确的[变异检测](@entry_id:177461)至关重要。

### 从比对到[共有序列](@entry_id:274833)：重建目标基因组

流程的最后阶段是整合所有经过预处理和比对的读段信息，以重建供体基因组的序列。这对应于前述流水线概念中的变异推断 ($f_2$) 和[共有序列](@entry_id:274833)生成 ($f_3$) [@problem_id:4604820]。

在每个基因组位置，所有覆盖该位置的读段形成一个“**堆叠**”(pileup)。通过分析这个堆叠中不同碱基的频率、质量得分和链方向等信息，我们可以进行统计推断，以确定该位置最可能的基因型。这是一个正式的[假设检验](@entry_id:142556)过程，通常会计算每个可能基因型（例如，纯合参考、杂合、纯合变异）的后验概率。这个计算会用到我们之前讨论的所有信息：校准后的碱基质量得分、[比对质量](@entry_id:170584)得分，并结合一个关于测序错误的似然模型和一个关于基因型频率的先验。

一旦在所有位置都完成了基因型推断，就可以生成最终的**共有序列** (consensus sequence)。这通常是通过将识别出的所有高[置信度](@entry_id:267904)的变异应用到参考基因组序列上完成的。例如，如果在一个位置检测到一个杂合的A/G变异，而参考基因组是A，那么[共有序列](@entry_id:274833)在该位置可以用一个[歧义](@entry_id:276744)码（如R）表示，或者生成两个分别代表不同单倍型的序列。

### 超越线性参考：变异图谱

尽管基于[线性参考基因组](@entry_id:164850)的组装流程非常强大，但它也有其固有的局限性。当供体基因组与[参考基因组](@entry_id:269221)差异较大时（例如，来自不同族群的个体，或在研究高度多样化的物种时），参考偏好会变得非常严重，许多读段可能无法正确比对，导致大段序列的丢失或错误组装。

为了克服这一挑战，研究界正在转向使用**变异图谱 (variation graphs)** [@problem_id:4604788]。变异图谱是一种基于[图的数据结构](@entry_id:269239)，它不再将参考基因组表示为单一的[线性序](@entry_id:146781)列，而是将一个群体中已知的多种变异（包括SNV、indel和[结构变异](@entry_id:173359)）都编码到图中。

在一个典型的变异图谱中，节点被DNA序列片段标记，而有向边表示这些片段之间允许的连接。参考序列本身对应于图中的一条特定路径。而备选的等位基因则表示为从参考路径上分叉出来、并可能在下游重新[汇合](@entry_id:148680)的旁路。因此，图中的每一条完整路径都代表了一个可能的**单倍型** (haplotype)。

在这种框架下，[读段比对](@entry_id:265329)不再是与一个线性[序列比对](@entry_id:172191)，而是与图中的某条路径进行比对。这使得携带非参考等位基因的读段也能找到高质量的比对，从而大大减少了参考偏好，提高了在高度多样化区域的组装准确性。变异图谱代表了基因组学从单一参考向**[泛基因组](@entry_id:149997) (pangenome)** 范式转变的重要一步，为未来的基因组分析提供了更全面、更公正的基础。