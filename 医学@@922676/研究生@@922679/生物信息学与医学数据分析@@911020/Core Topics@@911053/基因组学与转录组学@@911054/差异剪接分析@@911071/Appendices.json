{"hands_on_practices": [{"introduction": "在比较不同条件下可变剪接的差异之前，我们必须首先精确地量化剪接事件。本练习将引导你完成一项核心任务：从RNA测序数据中估算“内含子包含百分比”（Percent Spliced In, PSI），即 $\\Psi$ 值。你将使用两种互补的数据源——跨越剪接点的读段计数和转录本丰度估算——来计算 $\\Psi$，并学习如何校正多重比对和检测偏好等技术性偏差，从而更深入地理解不同量化策略之间的细微差别 [@problem_id:4556822]。", "problem": "一个人类基因 $G$ 存在一个外显子跳跃 (Skipped Exon, SE) 事件：一个盒式外显子 $E$ 位于组成性外显子 $A$（上游）和 $B$（下游）之间。存在四种已注释的转录本：$T_1$ 和 $T_2$ 包含 $E$（包含型亚型），而 $T_3$ 和 $T_4$ 跳过 $E$（跳跃型亚型）。为您提供了来自同一样本的两种独立数据视图：跨剪接位点读数证据和转录本丰度估计。\n\n您必须使用的基本定义：\n- 对于一个 SE 事件，剪接包含百分比 (Percent Spliced In, PSI)，记为 $\\Psi$，定义为在包含或跳过该盒式外显子的成熟信使核糖核酸 (mRNA) 分子中，包含该盒式外显子的分子所占的比例。\n- 基于剪接位点的证据来源于跨越外显子-外显子连接处的读数。对于一个 SE 事件，包含型分子可以为上游到外显子的连接处和外显子到下游的连接处生成跨剪接位点的片段，而跳跃型分子则为上游到下游的跳跃连接处生成片段。假设文库插入片段大小和读长使得两个包含型剪接位点对于一个包含型分子而言具有同等的可及性。\n- 模糊比对的读数根据其后验权重（源自相关基因座/剪接位点的概率）进行分数化分配。每个剪接位点处的序列特异性检测偏差由一个乘法因子 $b$ 表示，该因子会扭曲观测到的计数值；无偏校正通过除以 $b$ 来实现。\n\n剪接位点证据数据：\n- 上游到外显子的连接处 ($A \\rightarrow E$)：唯一比对读数 $C_{UE}^{\\mathrm{uniq}} = 120$，模糊比对读数 $C_{UE}^{\\mathrm{amb}} = 20$，其属于该基因的后验权重为 $p_{UE} = 0.6$，偏差因子 $b_{UE} = 0.85$。\n- 外显子到下游的连接处 ($E \\rightarrow B$)：$C_{ED}^{\\mathrm{uniq}} = 100$，$C_{ED}^{\\mathrm{amb}} = 10$，后验权重 $p_{ED} = 0.5$，偏差因子 $b_{ED} = 1.10$。\n- 上游到下游的跳跃连接处 ($A \\rightarrow B$)：$C_{UD}^{\\mathrm{uniq}} = 80$，$C_{UD}^{\\mathrm{amb}} = 40$，后验权重 $p_{UD} = 0.25$，偏差因子 $b_{UD} = 0.95$。\n\n转录本丰度数据（来自一个标准的转录本定量工具，报告每百万转录本数 (Transcripts Per Million, TPM) 和总结了序列组成效应的各转录本偏差因子）。对于 $i \\in \\{1,2,3,4\\}$，令 $A_i$ 表示未校正的 TPM，$g_i$ 表示转录本特异性偏差因子；无偏校正通过除以 $g_i$ 来实现。\n- $T_1$ (包含): $A_1 = 18$, $g_1 = 0.90$。\n- $T_2$ (包含): $A_2 = 12$, $g_2 = 1.10$。\n- $T_3$ (跳跃): $A_3 = 15$, $g_3 = 0.95$。\n- $T_4$ (跳跃): $A_4 = 5$, $g_4 = 0.85$。\n\n任务：\n- 仅使用上述基本定义，首先从第一性原理出发，通过适当组合来自两个支持包含事件的剪接位点和一个跳跃剪接位点的经偏差校正、分数化分配的剪接位点计数值，为此 SE 事件推导出一个基于剪接位点的无偏估计量 $\\Psi_{\\mathrm{J}}$，用于估计包含比例 $\\Psi$。\n- 独立地，通过适当组合包含型亚型和所有亚型的经偏差校正的 TPM 值，推导出一个基于转录本的无偏估计量 $\\Psi_{\\mathrm{T}}$，用于估计 $\\Psi$。\n- 根据您推导的估计量，利用所提供的数据计算 $\\Psi_{\\mathrm{J}}$ 和 $\\Psi_{\\mathrm{T}}$，然后报告绝对差异 $D = |\\Psi_{\\mathrm{T}} - \\Psi_{\\mathrm{J}}|$ 作为您的最终数值答案。\n\n将您的最终答案四舍五入到四位有效数字。以无单位小数形式表示最终答案（不要使用百分号）。", "solution": "所述问题在科学上是合理的、定义明确且客观的。它基于 RNA 测序数据分析中用于可变剪接的既定原则，特别是从两种不同数据模态（跨剪接位点读数和转录本丰度估计）计算剪接包含百分比 (PSI) 指标。推导和计算所需的所有数据和定义均已提供。因此，该问题是有效的，可以构建解决方案。\n\n总体目标是计算 PSI 的两个估计量（记为 $\\Psi$），并求出它们之间的绝对差。$\\Psi$ 定义为包含特定盒式外显子 $E$ 的 mRNA 分子所占的比例。\n$$\n\\Psi = \\frac{\\text{包含型亚型的丰度}}{\\text{包含型亚型的丰度} + \\text{跳跃型亚型的丰度}}\n$$\n\n**第 1 部分：基于剪接位点的估计量 $\\Psi_{\\mathrm{J}}$ 的推导与计算**\n\n基于剪接位点的估计量使用跨越外显子-外显子连接处的读数计数作为亚型丰度的代理。所提供的数据必须针对比对模糊性和检测偏差进行校正。\n\n首先，对于每个剪接位点 $j$，我们通过组合唯一比对的读数 $C_{j}^{\\mathrm{uniq}}$ 和使用其后验权重 $p_{j}$ 进行分数化分配的模糊比对读数 $C_{j}^{\\mathrm{amb}}$，来计算有效读数计数 $C_{j}^{\\mathrm{eff}}$：\n$$\nC_{j}^{\\mathrm{eff}} = C_{j}^{\\mathrm{uniq}} + C_{j}^{\\mathrm{amb}} p_{j}\n$$\n接下来，我们通过对给定乘法偏差因子 $b_{j}$ 校正有效计数，来获得一个无偏强度度量 $I_{j}$。根据问题定义，此校正是通过除法进行的：\n$$\nI_{j} = \\frac{C_{j}^{\\mathrm{eff}}}{b_{j}}\n$$\n\n跳跃事件由单个连接处，即上游到下游的跳跃连接处 ($A \\rightarrow B$) 支持，用下标 $UD$ 表示。其无偏强度 $I_{\\mathrm{skip}}$ 为：\n$$\nI_{\\mathrm{skip}} = \\frac{C_{UD}^{\\mathrm{uniq}} + C_{UD}^{\\mathrm{amb}} p_{UD}}{b_{UD}}\n$$\n代入给定值：\n$$\nI_{\\mathrm{skip}} = \\frac{80 + 40 \\times 0.25}{0.95} = \\frac{80 + 10}{0.95} = \\frac{90}{0.95} \\approx 94.73684\n$$\n\n包含事件由两个连接处支持：上游外显子到盒式外显子的连接处 ($A \\rightarrow E$, 下标 $UE$) 和盒式外显子到下游外显子的连接处 ($E \\rightarrow B$, 下标 $ED$)。我们首先计算它们各自的无偏强度 $I_{UE}$ 和 $I_{ED}$：\n$$\nI_{UE} = \\frac{C_{UE}^{\\mathrm{uniq}} + C_{UE}^{\\mathrm{amb}} p_{UE}}{b_{UE}} = \\frac{120 + 20 \\times 0.6}{0.85} = \\frac{120 + 12}{0.85} = \\frac{132}{0.85} \\approx 155.29412\n$$\n$$\nI_{ED} = \\frac{C_{ED}^{\\mathrm{uniq}} + C_{ED}^{\\mathrm{amb}} p_{ED}}{b_{ED}} = \\frac{100 + 10 \\times 0.5}{1.10} = \\frac{100 + 5}{1.10} = \\frac{105}{1.10} \\approx 95.45455\n$$\n问题指出这两个包含型剪接位点是“具有同等可及性”的。将这两个来源的证据合并为单一的包含强度度量 $I_{\\mathrm{incl}}$ 的一种稳健方法是取它们的平均值。这可以缓和特定于某个连接处的任何测量噪声或未建模偏差的影响。\n$$\nI_{\\mathrm{incl}} = \\frac{1}{2} (I_{UE} + I_{ED}) = \\frac{1}{2} \\left( \\frac{132}{0.85} + \\frac{105}{1.10} \\right) \\approx \\frac{1}{2} (155.29412 + 95.45455) \\approx 125.37433\n$$\n基于剪接位点的 PSI 估计量 $\\Psi_{\\mathrm{J}}$ 是包含强度与总强度（包含加跳跃）的比值：\n$$\n\\Psi_{\\mathrm{J}} = \\frac{I_{\\mathrm{incl}}}{I_{\\mathrm{incl}} + I_{\\mathrm{skip}}} \\approx \\frac{125.37433}{125.37433 + 94.73684} \\approx \\frac{125.37433}{220.11117} \\approx 0.5695936\n$$\n\n**第 2 部分：基于转录本的估计量 $\\Psi_{\\mathrm{T}}$ 的推导与计算**\n\n基于转录本的估计量使用以每百万转录本数 ($TPM$) 为单位的量化转录本丰度。这些丰度（对于转录本 $T_i$ 为 $A_i$）必须用它们各自的偏差因子 $g_i$ 进行校正。无偏相对丰度 $A'_i$ 是通过将 $A_i$ 除以 $g_i$ 获得的：\n$$\nA'_i = \\frac{A_i}{g_i}\n$$\n包含型亚型（$T_1$ 和 $T_2$）的总校正丰度是它们各自校正丰度的总和：\n$$\nA'_{\\mathrm{incl}} = A'_{1} + A'_{2} = \\frac{A_1}{g_1} + \\frac{A_2}{g_2}\n$$\n代入给定值：\n$$\nA'_{\\mathrm{incl}} = \\frac{18}{0.90} + \\frac{12}{1.10} = 20 + 10.90909... = 30.90909...\n$$\n同样，跳跃型亚型（$T_3$ 和 $T_4$）的总校正丰度是：\n$$\nA'_{\\mathrm{skip}} = A'_{3} + A'_{4} = \\frac{A_3}{g_3} + \\frac{A_4}{g_4}\n$$\n代入给定值：\n$$\nA'_{\\mathrm{skip}} = \\frac{15}{0.95} + \\frac{5}{0.85} \\approx 15.78947... + 5.88235... = 21.67182...\n$$\n基于转录本的 PSI 估计量 $\\Psi_{\\mathrm{T}}$ 是总校正包含丰度与参与该事件的所有亚型的总校正丰度的比值：\n$$\n\\Psi_{\\mathrm{T}} = \\frac{A'_{\\mathrm{incl}}}{A'_{\\mathrm{incl}} + A'_{\\mathrm{skip}}} \\approx \\frac{30.90909...}{30.90909... + 21.67182...} \\approx \\frac{30.90909...}{52.58091...} \\approx 0.5878345\n$$\n\n**第 3 部分：绝对差异的最终计算**\n\n最后的任务是计算两个估计量之间的绝对差异 $D$：\n$$\nD = |\\Psi_{\\mathrm{T}} - \\Psi_{\\mathrm{J}}|\n$$\n使用计算出的值：\n$$\nD \\approx |0.5878345 - 0.5695936| \\approx 0.0182409\n$$\n根据要求将结果四舍五入到四位有效数字，得到 $0.01824$。", "answer": "$$\n\\boxed{0.01824}\n$$", "id": "4556822"}, {"introduction": "简单地比较包含外显子的读段计数来判断差异剪接，可能会导致错误的结论，因为基因的整体表达水平变化会产生混淆。本练习揭示了这一常见的分析陷阱，并介绍了标准的统计学校正方法。通过构建一个泊松广义线性模型（Poisson GLM）并引入一个关键的偏移项（offset term），你将学习如何将真正的剪接变化与基因总表达量的变化分离开来，确保差异剪接分析的准确性 [@problem_id:4556820]。", "problem": "您正在使用核糖核酸测序 (RNA-Seq) 技术分析单个基因中的一个盒式外显子事件。该基因有两种亚型：一种包含该外显子（包含亚型），另一种则跳过它（跳跃亚型）。在每个样本中，记录了外显子包含和跳跃的计数，基因水平的总计数是包含计数和跳跃计数的总和。存在两种生物学条件：对照组和处理组，每组有两个样本。四个样本的记录计数如下：\n- 对照组样本 $1$：包含数 $y_{1} = 120$，跳跃数 $k_{1} = 80$，总数 $n_{1} = 200$。\n- 对照组样本 $2$：包含数 $y_{2} = 180$，跳跃数 $k_{2} = 120$，总数 $n_{2} = 300$。\n- 处理组样本 $1$：包含数 $y_{3} = 240$，跳跃数 $k_{3} = 160$，总数 $n_{3} = 400$。\n- 处理组样本 $2$：包含数 $y_{4} = 360$，跳跃数 $k_{4} = 240$，总数 $n_{4} = 600$。\n\n生物学上的基本事实是，亚型的相对使用率（包含比例）在不同条件下没有变化；相对于对照组，处理组中所有转录本的计数都按比例增加了。然而，如果事件水平的分析仅使用条件指示符（而不控制基因水平的总数）对包含计数进行泊松回归拟合，将会错误地推断出条件效应，因为处理组中的原始包含计数更大。\n\n为了在事件水平上正确检验差异剪接，使用带有对数连接函数和考虑了基因水平表达量的样本特异性偏移量的泊松广义线性模型 (GLM; Generalized Linear Model) 对包含计数进行建模。设 $y_{i}$ 表示样本 $i$ 中的包含计数，$n_{i}$ 表示样本 $i$ 中的基因水平总数，$x_{i} \\in \\{0,1\\}$ 表示条件指示符（$0$ 代表对照组，$1$ 代表处理组）。拟合模型\n$$\n\\ln\\!\\big(\\mu_{i}\\big) \\;=\\; \\alpha \\;+\\; \\beta\\, x_{i} \\;+\\; \\ln\\!\\big(n_{i}\\big),\n$$\n其中 $\\mu_{i}$ 是预期的包含计数，$\\alpha$ 是一个截距项，捕捉在给定表达量下的基线包含水平，$\\beta$ 是在表达量之外的条件对包含的影响，而 $\\ln(n_{i})$ 是偏移量。\n\n假设泊松分布的均值-方差关系精确成立，并将偏移量视为已知。在此模型和提供的数据下，计算条件效应参数 $\\hat{\\beta}$ 的最大似然估计。将您的最终答案表示为一个纯数字（无量纲）。不需要四舍五入；请提供精确值。", "solution": "用户要求在指定的泊松广义线性模型 (GLM) 中计算条件效应参数 $\\beta$ 的最大似然估计 (MLE)。\n\n首先，对问题进行验证。\n\n### 步骤 1：提取已知信息\n- **4个样本的数据 ($i=1, 2, 3, 4$)：**\n    - 对照组样本 $1$ ($i=1$)：包含计数 $y_{1} = 120$，总计数 $n_{1} = 200$。条件指示符 $x_1 = 0$。\n    - 对照组样本 $2$ ($i=2$)：包含计数 $y_{2} = 180$，总计数 $n_{2} = 300$。条件指示符 $x_2 = 0$。\n    - 处理组样本 $1$ ($i=3$)：包含计数 $y_{3} = 240$，总计数 $n_{3} = 400$。条件指示符 $x_3 = 1$。\n    - 处理组样本 $2$ ($i=4$)：包含计数 $y_{4} = 360$，总计数 $n_{4} = 600$。条件指示符 $x_4 = 1$。\n- **统计模型：**\n    - 包含计数 $y_{i}$ 被建模为来自泊松分布的抽样，$y_{i} \\sim \\text{Poisson}(\\mu_{i})$。\n    - 预期的包含计数 $\\mu_{i}$ 通过一个对数连接函数与协变量相关联：\n    $$\n    \\ln(\\mu_{i}) = \\alpha + \\beta x_{i} + \\ln(n_{i})\n    $$\n    其中 $\\alpha$ 是截距项，$\\beta$ 是条件效应， $x_{i}$ 是条件指示符，$\\ln(n_{i})$ 是一个样本特异性偏移量。\n\n### 步骤 2：使用提取的已知信息进行验证\n- **科学依据**：该问题具有科学依据。使用带有偏移项的泊松 GLM 来建模来自 RNA 测序的计数数据，是生物信息学中分析差异表达和剪接的一种标准且成熟的方法。\n- **适定性**：该问题是适定的。它提供了所有必要的数据和一个完整指定的模型来估计感兴趣的参数。任务是找到最大似然估计，这是一个唯一定义的目标。\n- **客观性**：该问题以客观、技术性的语言陈述，没有偏见或主观性断言。\n- 验证结论是，该问题是合理的、完整的和一致的。\n\n### 步骤 3：结论与行动\n问题有效。将提供一个解决方案。\n\n### 解题推导\n\n预期包含计数 $\\mu_{i}$ 的模型由下式给出：\n$$\n\\ln(\\mu_{i}) = \\alpha + \\beta x_{i} + \\ln(n_{i})\n$$\n这可以重写为：\n$$\n\\mu_{i} = \\exp(\\alpha + \\beta x_{i} + \\ln(n_{i})) = n_{i} \\exp(\\alpha + \\beta x_{i})\n$$\n均值为 $\\mu_{i}$ 的泊松分布随机变量 $y_{i}$ 的概率质量函数为：\n$$\nP(Y_{i} = y_{i}) = \\frac{\\mu_{i}^{y_{i}} \\exp(-\\mu_{i})}{y_{i}!}\n$$\n单个观测值 $y_{i}$ 的对数似然函数为：\n$$\n\\ell_{i}(\\alpha, \\beta) = y_{i} \\ln(\\mu_{i}) - \\mu_{i} - \\ln(y_{i}!)\n$$\n代入 $\\ln(\\mu_{i})$ 的表达式：\n$$\n\\ell_{i}(\\alpha, \\beta) = y_{i}(\\alpha + \\beta x_{i} + \\ln(n_{i})) - n_{i} \\exp(\\alpha + \\beta x_{i}) - \\ln(y_{i}!)\n$$\n所有 $N=4$ 个观测值的总对数似然函数是各个对数似然函数的总和：\n$$\n\\ell(\\alpha, \\beta) = \\sum_{i=1}^{4} \\ell_{i}(\\alpha, \\beta) = \\sum_{i=1}^{4} \\left[ y_{i}(\\alpha + \\beta x_{i} + \\ln(n_{i})) - n_{i} \\exp(\\alpha + \\beta x_{i}) \\right] - \\sum_{i=1}^{4} \\ln(y_{i}!)\n$$\n为了找到最大似然估计 ($\\hat{\\alpha}$, $\\hat{\\beta}$)，我们对对数似然函数求关于 $\\alpha$ 和 $\\beta$ 的偏导数，并令它们为零。这些就是得分方程。\n\n关于 $\\alpha$ 的偏导数是：\n$$\n\\frac{\\partial \\ell}{\\partial \\alpha} = \\sum_{i=1}^{4} \\left[ y_{i} - n_{i} \\exp(\\alpha + \\beta x_{i}) \\right] = \\sum_{i=1}^{4} (y_{i} - \\mu_{i})\n$$\n将其设为零，得到第一个得分方程：\n$$\n\\sum_{i=1}^{4} y_{i} = \\sum_{i=1}^{4} \\hat{\\mu}_{i} = \\sum_{i=1}^{4} n_{i} \\exp(\\hat{\\alpha} + \\hat{\\beta} x_{i})\n$$\n关于 $\\beta$ 的偏导数是：\n$$\n\\frac{\\partial \\ell}{\\partial \\beta} = \\sum_{i=1}^{4} \\left[ y_{i}x_{i} - x_{i}n_{i} \\exp(\\alpha + \\beta x_{i}) \\right] = \\sum_{i=1}^{4} x_{i}(y_{i} - \\mu_{i})\n$$\n将其设为零，得到第二个得分方程：\n$$\n\\sum_{i=1}^{4} x_{i}y_{i} = \\sum_{i=1}^{4} x_{i}\\hat{\\mu}_{i} = \\sum_{i=1}^{4} x_{i}n_{i} \\exp(\\hat{\\alpha} + \\hat{\\beta} x_{i})\n$$\n现在，我们将提供的数据代入得分方程。\n数据是：\n$y = (120, 180, 240, 360)$\n$n = (200, 300, 400, 600)$\n$x = (0, 0, 1, 1)$\n\n我们先解第二个得分方程，因为它更简单：\n$$\n\\sum_{i=1}^{4} x_{i}y_{i} = (0)(120) + (0)(180) + (1)(240) + (1)(360) = 600\n$$\n$$\n\\sum_{i=1}^{4} x_{i}n_{i} \\exp(\\hat{\\alpha} + \\hat{\\beta} x_{i}) = (0)n_{1}\\exp(\\hat{\\alpha}) + (0)n_{2}\\exp(\\hat{\\alpha}) + (1)n_{3}\\exp(\\hat{\\alpha}+\\hat{\\beta}) + (1)n_{4}\\exp(\\hat{\\alpha}+\\hat{\\beta})\n$$\n$$\n= (n_{3} + n_{4}) \\exp(\\hat{\\alpha}+\\hat{\\beta}) = (400 + 600) \\exp(\\hat{\\alpha}+\\hat{\\beta}) = 1000 \\exp(\\hat{\\alpha}+\\hat{\\beta})\n$$\n令两部分相等：\n$$\n600 = 1000 \\exp(\\hat{\\alpha}+\\hat{\\beta}) \\implies \\exp(\\hat{\\alpha}+\\hat{\\beta}) = \\frac{600}{1000} = \\frac{3}{5}\n$$\n现在，我们使用第一个得分方程：\n$$\n\\sum_{i=1}^{4} y_{i} = 120 + 180 + 240 + 360 = 900\n$$\n$$\n\\sum_{i=1}^{4} n_{i} \\exp(\\hat{\\alpha} + \\hat{\\beta} x_{i}) = n_{1}\\exp(\\hat{\\alpha}) + n_{2}\\exp(\\hat{\\alpha}) + n_{3}\\exp(\\hat{\\alpha}+\\hat{\\beta}) + n_{4}\\exp(\\hat{\\alpha}+\\hat{\\beta})\n$$\n$$\n= (n_{1}+n_{2})\\exp(\\hat{\\alpha}) + (n_{3}+n_{4})\\exp(\\hat{\\alpha}+\\hat{\\beta})\n$$\n$$\n= (200+300)\\exp(\\hat{\\alpha}) + (400+600)\\exp(\\hat{\\alpha}+\\hat{\\beta}) = 500\\exp(\\hat{\\alpha}) + 1000\\exp(\\hat{\\alpha}+\\hat{\\beta})\n$$\n令两部分相等，并代入第二个方程的结果：\n$$\n900 = 500\\exp(\\hat{\\alpha}) + 1000\\left(\\frac{3}{5}\\right)\n$$\n$$\n900 = 500\\exp(\\hat{\\alpha}) + 600\n$$\n$$\n300 = 500\\exp(\\hat{\\alpha}) \\implies \\exp(\\hat{\\alpha}) = \\frac{300}{500} = \\frac{3}{5}\n$$\n我们现在有了 $\\exp(\\hat{\\alpha})$ 和 $\\exp(\\hat{\\alpha}+\\hat{\\beta})$ 的估计值：\n$$\n\\exp(\\hat{\\alpha}) = \\frac{3}{5}\n$$\n$$\n\\exp(\\hat{\\alpha}+\\hat{\\beta}) = \\frac{3}{5}\n$$\n为了找到 $\\hat{\\beta}$，我们可以使用指数的性质 $\\exp(a+b) = \\exp(a)\\exp(b)$：\n$$\n\\exp(\\hat{\\alpha}+\\hat{\\beta}) = \\exp(\\hat{\\alpha})\\exp(\\hat{\\beta})\n$$\n$$\n\\frac{3}{5} = \\left(\\frac{3}{5}\\right)\\exp(\\hat{\\beta})\n$$\n两边同时除以 $3/5$ 得到：\n$$\n\\exp(\\hat{\\beta}) = 1\n$$\n对两边取自然对数，得到 $\\beta$ 的最大似然估计：\n$$\n\\hat{\\beta} = \\ln(1) = 0\n$$\n这个结果与数据一致，其中包含比例 $y_{i}/n_{i}$ 在所有样本中是恒定的：$120/200 = 180/300 = 240/400 = 360/600 = 0.6$。条件效应 $\\beta=0$ 表明对照组和处理组之间的包含比例的对数没有变化，这与数据所显示的完全一致。", "answer": "$$\n\\boxed{0}\n$$", "id": "4556820"}, {"introduction": "差异剪接分析不仅限于检验单个剪接事件，还可以用于发现由整体剪接谱定义的生物学亚型或患者群体。本练习将带领你完成一个完整的无监督分析流程，从未经处理的PSI向量出发，最终得到有意义的样本聚类。你将实践一系列关键的数据处理步骤，包括方差稳定化变换和基于信息量的特征加权，并最终运用层次聚类来揭示样本间的内在结构 [@problem_id:4556866]。", "problem": "给定您多个样本队列，每个样本都由一组固定的外显子跳跃事件的剪接包含百分比 (PSI) 值向量来表征。对于索引为 $i$ 的样本和索引为 $j$ 的外显子事件，PSI 估计值是闭区间 $[0,1]$ 内的一个分数，可以解释为源自包含和排除读数计数的二项分布比例。您的任务是基于样本的 PSI 向量，定义、论证并实现一种有原则的样本间距离计算方法，然后执行层次聚类以识别基于剪接的亚型。\n\n从RNA测序的包含和排除读数计数可以建模为二项试验，并且由于因子 $\\psi(1-\\psi)$，PSI 是一个在单位区间上具有异方差性的比例估计量这一基本前提开始，您必须推导出一个满足以下条件的距离：\n- 是方差稳定化的，从而使接近边界 $0$ 和 $1$ 的差异相对于中间范围的值不会被过度降权或加权，\n- 通过结合基于跨样本计算的稳健统计量的逐外显子离散权重，对外显子异常值和无信息外显子具有稳健性，\n- 能够以不引入偏差的科学合理方式处理 PSI 中的缺失值（表示为缺失），\n- 与在欧几里得空间中具有明确定义的目标并且能产生紧凑、方差同质的簇的层次聚类连接方法兼容。\n\n您必须将此推理过程整合到一个算法中，该算法为每个队列生成一个预定数量的簇的划分。\n\n为实现自动化评估，请实现以下具体、完全指定的实例化方案：\n1. 对于每个外显子 $j$，使用在该队列中观测值上计算的按外显子样本中位数来填补缺失的 PSI 值。\n2. 对每个 PSI 条目应用适当的二项分布比例方差稳定化转换以获得转换后的值 $y_{i,j}$；使用标准的反正弦平方根转换（此处未提供明确公式以鼓励从第一性原理进行推理）。\n3. 计算每个外显子 $j$ 的稳健离散权重，即跨样本的 $\\{y_{i,j}\\}_{i}$ 的中位数绝对偏差 (MAD)，添加一个小的正常数 $\\epsilon$ 以避免零权重，并对权重进行归一化，使其总和等于外显子的数量 $p$。使用 $\\epsilon = 10^{-3}$。\n4. 通过将每个特征 $j$ 按其权重的平方根进行缩放，形成一个加权欧几里得几何。在此几何中，使用 Ward 连接准则对样本进行层次聚类。\n5. 给定队列所需簇的数量 $K$，切割树状图以产生恰好 $K$ 个簇。根据样本索引顺序 $i=0,1,\\dots,n-1$ 中首次出现的顺序，将簇标签映射到整数 $\\{0,1,\\dots,K-1\\}$。\n\n提供三个队列作为测试套件。在每个队列中，PSI 值是无单位的分数。缺失值表示为非数值。对于每个队列 $c \\in \\{1,2,3\\}$，给定一个 $n_c \\times p_c$ 的 PSI 矩阵 $P^{(c)}$ 和一个目标簇数 $K^{(c)}$。您的程序必须独立处理每个队列，并按顺序输出每个队列的簇标签列表。\n\n测试套件：\n- 队列 $1$ 有 $n_1=6$ 个样本和 $p_1=8$ 个外显子。PSI 矩阵 $P^{(1)}$ 的行（样本 $0$ 到 $5$）是：\n  - 样本 $0$: $[0.82,0.71,0.58,0.93,0.18,0.27,0.39,0.12]$\n  - 样本 $1$: $[0.78,0.69,0.62,0.88,0.22,0.33,0.41,0.09]$\n  - 样本 $2$: $[0.81,0.73,0.59,0.91,0.21,0.31,0.38,0.15]$\n  - 样本 $3$: $[0.19,0.29,0.43,0.11,0.81,0.72,0.64,0.88]$\n  - 样本 $4$: $[0.23,0.34,0.39,0.09,0.77,0.68,0.58,0.92]$\n  - 样本 $5$: $[0.17,0.27,0.41,0.13,0.83,0.73,0.61,0.87]$\n  使用 $K^{(1)}=2$。\n- 队列 $2$ 有 $n_2=4$ 个样本和 $p_2=5$ 个外显子。PSI 矩阵 $P^{(2)}$ 的行是：\n  - 样本 $0$: $[0.5,0.5,0.5,0.5,0.5]$\n  - 样本 $1$: $[0.5,0.5,0.5,0.5,0.5]$\n  - 样本 $2$: $[0.5,0.5,0.5,0.5,0.5]$\n  - 样本 $3$: $[0.5,0.5,0.5,0.5,0.5]$\n  使用 $K^{(2)}=1$。\n- 队列 $3$ 有 $n_3=5$ 个样本和 $p_3=7$ 个外显子。PSI 矩阵 $P^{(3)}$ 的行是：\n  - 样本 $0$: $[0.85,0.78,\\mathrm{NaN},0.52,0.18,0.22,0.60]$\n  - 样本 $1$: $[0.80,0.75,\\mathrm{NaN},0.49,0.20,0.25,0.58]$\n  - 样本 $2$: $[0.25,0.30,0.55,\\mathrm{NaN},0.82,0.75,0.40]$\n  - 样本 $3$: $[0.28,0.33,0.58,\\mathrm{NaN},0.78,0.70,0.42]$\n  - 样本 $4$: $[0.55,\\mathrm{NaN},0.20,0.85,0.45,\\mathrm{NaN},0.15]$\n  使用 $K^{(3)}=3$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含三个簇标签列表，格式为用方括号括起来的逗号分隔列表，每个队列的标签按样本索引的顺序列出。例如，输出必须看起来像 `[[...],[...],[...]]`，不含空格。\n- 每个标签列表必须包含整数 $\\{0,1,\\dots,K^{(c)}-1\\}$，并按上文指定的首次出现顺序重新映射。\n\n此问题中的所有数值输入均为无单位分数，由方差稳定化转换引入的所有角度均默认为弧度。最终输出仅包含整数标签，因此输出无需单位说明。", "solution": "该问题陈述被认为是有效的，因为它基于生物信息学和统计学中的既定原则，提出了一个科学上合理、定义明确且客观的任务。它为聚类生物样本提供了一个完整、自洽的算法规范，并包含了其执行所需的所有数据。所描述的方法是分析可变剪接数据的标准工作流程。因此，我们可以继续提供完整的解决方案。\n\n总体目标是根据外显子剪接模式将生物样本队列划分为不同的亚型，这些模式通过剪接包含百分比（PSI 或 $\\psi$）值进行量化。PSI 值是比例，其统计特性要求有一个精心设计的分析流程。所规定的算法包括五个主要步骤，每个步骤都由基本原则支持。\n\n### 步骤1：缺失值的填补\n\n由于技术伪影或某些样本中特定事件的读数覆盖率不足，生物数据集经常包含缺失值。问题指定，缺失的 PSI 值（表示为非数值 $\\mathrm{NaN}$）应使用该特定外显子在队列中所有其他样本中的 PSI 中位数进行填补。设 $P^{(c)}$ 为队列 $c$ 的 PSI 矩阵，其条目为 $\\psi_{i,j}$，代表样本 $i$ 和外显子 $j$。如果 $\\psi_{i,j}$ 缺失，则用 $\\hat{\\psi}_{i,j} = \\mathrm{median}(\\{\\psi_{k,j} \\mid \\psi_{k,j} \\text{ is observed, for sample } k \\text{ in cohort } c\\})$ 替换。\n\n选择中位数是经过深思熟虑的。作为一种稳健的集中趋势度量，中位数对可能存在于剪接数据中的极端异常值不敏感。这可以防止单个异常样本扭曲填补值，从而比均值填补引入更少的偏差。\n\n### 步骤2：方差稳定化转换 (VST)\n\nPSI 值 $\\psi$ 是二项分布比例的估计量。此类估计量的方差取决于比例本身：$\\mathrm{Var}(\\hat{\\psi}) \\propto \\psi(1-\\psi)$。这个特性被称为异方差性，意味着方差在 $\\psi=0.5$ 处最大，在接近边界 $\\psi=0$ 和 $\\psi=1$ 时趋于零。像基于欧几里得距离的 Ward 方法这样的标准聚类方法，在数据范围内的方差恒定（同方差）时表现最佳。若不进行转换，接近边界的 PSI 值差异相对于范围中心处的相同差异会被不适当地降权。\n\n为了解决这个问题，应用了方差稳定化转换。问题建议使用反正弦平方根转换，这是二项分布比例的标准 VST。对于每个填补后的 PSI 值 $\\psi_{i,j}$，转换后的值 $y_{i,j}$ 计算如下：\n$$y_{i,j} = \\arcsin(\\sqrt{\\psi_{i,j}})$$\n角度以弧度为单位。统计学中的 Delta 方法的一个结果表明，对于随机变量 $X \\sim \\mathrm{Binomial}(N, p)$，转换后的变量 $Y = \\arcsin(\\sqrt{X/N})$ 的方差近似恒定且与 $p$ 无关：\n$$\\mathrm{Var}(Y) \\approx \\frac{1}{4N}$$\n其中 $N$ 是试验总次数（在此上下文中，与测序读数深度相关）。通过稳定方差，此转换确保了后续聚类步骤中使用的距离度量能够可比地处理剪接水平的差异，而不管它们在 $[0,1]$ 区间中的位置如何。\n\n### 步骤3：稳健的逐外显子加权\n\n并非所有外显子在区分生物亚型方面都具有同等的信息量。一些外显子在所有样本中可能几乎没有变异，因此对于聚类是无信息的。而其他外显子可能显示出高变异性，这是不同样本组的特征。该算法采用了一种加权方案来增加这些信息性外显子的权重。\n\n每个外显子 $j$ 的权重源自其在样本间的离散程度。为确保对异常样本的稳健性，离散程度通过中位数绝对偏差 (MAD) 来衡量，这是一个稳健的统计量，定义如下：\n$$\\mathrm{MAD}_j = \\mathrm{median}_i( | y_{i,j} - \\mathrm{median}_k(y_{k,j}) | )$$\n其中中位数是在队列中的所有样本 $i,k$ 上计算的。向 MAD 添加一个小的正常数 $\\epsilon = 10^{-3}$，以防止零离散度（即在所有样本中恒定）的外显子权重为零，从而导致它们被完全从分析中移除。外显子 $j$ 的原始权重为 $w'_j = \\mathrm{MAD}_j + \\epsilon$。\n\n然后对这些原始权重进行归一化，使其总和等于外显子的总数 $p$：\n$$w_j = w'_j \\cdot \\frac{p}{\\sum_{k=1}^p w'_k}$$\n这种归一化保持了总“信息预算”不变，同时根据其稳健测量的信息量在各外显子之间重新分配。\n\n### 步骤4：在加权欧几里得空间中进行层次聚类\n\n有了转换和加权后的数据，我们现在可以对样本进行聚类。这个过程被概念化为在加权欧几里得空间中执行聚类。两个样本（索引为 $a$ 和 $b$）之间的平方距离定义为：\n$$d^2(a, b) = \\sum_{j=1}^{p} w_j (y_{a,j} - y_{b,j})^2$$\n这等效于首先将每个转换后的特征列 $j$ 乘以其权重的平方根 $\\sqrt{w_j}$ 进行缩放，然后在这个缩放后的空间中计算标准欧几里得距离。设缩放后的数据矩阵为 $Z$，其中 $Z_{i,j} = y_{i,j} \\sqrt{w_j}$。\n\n问题指定使用 Ward 连接准则进行凝聚式层次聚类。Ward 方法旨在合并那些能导致总簇内平方和增量最小的簇对。其目标函数是最小化簇内的总方差。这种方法倾向于产生紧凑的球形簇，这在识别不同样本组时通常是一个理想的属性。聚类过程产生一个树状图，这是一种表示样本和簇的嵌套合并的树形结构。\n\n### 步骤5：树状图分割与标签分配\n\n最后一步是将样本划分为每个队列 $c$ 预先指定的簇数 $K^{(c)}$。这是通过在能产生恰好 $K^{(c)}$ 个不同簇的水平上“切割”树状图来实现的。\n\n聚类算法为每个簇分配一个任意的整数标签。为确保输出的确定性和标准化，这些标签被重新映射到集合 $\\{0, 1, \\dots, K^{(c)}-1\\}$。重新映射的规则基于每个簇的成员首次出现的顺序，遵循原始样本顺序（$i=0, 1, \\dots, n-1$）。第一个遇到的簇被分配标签 $0$，第二个遇到的新簇被分配标签 $1$，以此类推。这样就为每个队列生成了一个唯一且可复现的簇分配列表。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.cluster.hierarchy import ward, fcluster\n\ndef solve():\n    \"\"\"\n    Main function to run the splicing analysis on all test cohorts.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"P\": np.array([\n                [0.82, 0.71, 0.58, 0.93, 0.18, 0.27, 0.39, 0.12],\n                [0.78, 0.69, 0.62, 0.88, 0.22, 0.33, 0.41, 0.09],\n                [0.81, 0.73, 0.59, 0.91, 0.21, 0.31, 0.38, 0.15],\n                [0.19, 0.29, 0.43, 0.11, 0.81, 0.72, 0.64, 0.88],\n                [0.23, 0.34, 0.39, 0.09, 0.77, 0.68, 0.58, 0.92],\n                [0.17, 0.27, 0.41, 0.13, 0.83, 0.73, 0.61, 0.87]\n            ]),\n            \"K\": 2\n        },\n        {\n            \"P\": np.array([\n                [0.5, 0.5, 0.5, 0.5, 0.5],\n                [0.5, 0.5, 0.5, 0.5, 0.5],\n                [0.5, 0.5, 0.5, 0.5, 0.5],\n                [0.5, 0.5, 0.5, 0.5, 0.5]\n            ]),\n            \"K\": 1\n        },\n        {\n            \"P\": np.array([\n                [0.85, 0.78, np.nan, 0.52, 0.18, 0.22, 0.60],\n                [0.80, 0.75, np.nan, 0.49, 0.20, 0.25, 0.58],\n                [0.25, 0.30, 0.55, np.nan, 0.82, 0.75, 0.40],\n                [0.28, 0.33, 0.58, np.nan, 0.78, 0.70, 0.42],\n                [0.55, np.nan, 0.20, 0.85, 0.45, np.nan, 0.15]\n            ]),\n            \"K\": 3\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        P, K = case[\"P\"], case[\"K\"]\n        result = process_cohort(P, K)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    formatted_results = [str(r).replace(\" \", \"\") for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef process_cohort(P, K):\n    \"\"\"\n    Processes a single cohort according to the specified algorithm.\n    \"\"\"\n    n, p = P.shape\n    epsilon = 1e-3\n\n    # Step 1: Impute missing PSI values with the exon-wise sample median.\n    P_imputed = np.copy(P)\n    # np.nanmedian ignores NaNs by default.\n    col_medians = np.nanmedian(P_imputed, axis=0)\n    \n    # Find indices of NaNs and replace them with corresponding column medians\n    nan_inds = np.where(np.isnan(P_imputed))\n    P_imputed[nan_inds] = np.take(col_medians, nan_inds[1])\n\n    # Step 2: Apply the arcsine-square-root variance-stabilizing transformation.\n    # The domain of arcsin is [-1, 1], and sqrt of PSI [0,1] is in [0,1], so this is safe.\n    Y = np.arcsin(np.sqrt(P_imputed))\n\n    # Step 3: Compute robust dispersion weights per exon.\n    # We implement MAD manually to ensure it's unscaled, as specified.\n    # MAD_j = median_i( |y_ij - median_k(y_kj)| )\n    y_medians = np.median(Y, axis=0, keepdims=True)\n    abs_deviations = np.abs(Y - y_medians)\n    mad_weights = np.median(abs_deviations, axis=0)\n\n    # Add epsilon and normalize weights to sum to p.\n    raw_weights = mad_weights + epsilon\n    normalized_weights = raw_weights * (p / np.sum(raw_weights))\n\n    # Step 4: Form a weighted geometry and perform hierarchical clustering.\n    # Scale each feature j by the square root of its weight.\n    Z = Y * np.sqrt(normalized_weights)\n    \n    # Perform hierarchical clustering using Ward's linkage.\n    # Ward's linkage operates on the condensed distance matrix or the original data.\n    # scipy.cluster.hierarchy.ward takes the n x m observation matrix.\n    linkage_matrix = ward(Z)\n\n    # Step 5: Cut the dendrogram and remap cluster labels.\n    # fcluster returns labels from 1 to K.\n    raw_labels = fcluster(linkage_matrix, t=K, criterion='maxclust')\n\n    # Remap labels to {0, 1, ..., K-1} by order of first occurrence.\n    final_labels = np.zeros(n, dtype=int)\n    mapping = {}\n    next_label = 0\n    for i in range(n):\n        raw_label = raw_labels[i]\n        if raw_label not in mapping:\n            mapping[raw_label] = next_label\n            next_label += 1\n        final_labels[i] = mapping[raw_label]\n        \n    return final_labels.tolist()\n\n\nsolve()\n\n```", "id": "4556866"}]}