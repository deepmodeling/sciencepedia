{"hands_on_practices": [{"introduction": "临床叙述，如医生的笔记和出院小结，包含了丰富的患者信息，但其自由文本的性质带来了巨大挑战。同一概念可能以多种形式出现（如缩写、俗称、拼写错误），这使得直接分析变得困难。为了将这些非结构化数据转化为可用于分析的标准化特征，我们需要一个强大的映射流程。本练习 [@problem_id:4563113] 将指导你构建一个确定性的映射管道，它结合了基于词元（token）的加权相似度与基于字符的编辑距离，以稳健地处理术语的变体。你还将学习如何利用先验知识来解决映射中的歧义性问题，这是从原始临床文本中提取高质量、可信赖特征的关键一步。", "problem": "您的任务是构建一个确定性的映射管线，该管线使用概念词典和一套处理未映射及模糊代码的原则性策略，将本地电子健康记录（EHR）代码归一化为标准化的术语概念标识符。您的程序必须实现该管线，并为指定的测试套件生成量化结果，结果的表达需遵循本问题末尾描述的确切输出格式。\n\n基本与核心定义：\n- 概念词典是一个有限的对集合 $\\{(c, L_c)\\}$，其中 $c$ 是一个标准化的概念标识符（一个整数），而 $L_c$ 是与概念 $c$ 相关联的规范表层形式（同义标签）的有限集合。\n- 先验概率 $p(c)$ 是概念 $c$ 的一个非负实值先验权重，反映了语料库衍生的频率或流行度。先验概率之和不必为 $1$，仅用于打破平局时的偏好选择。\n- 本地EHR代码是一个自由文本字符串。该管线将每个本地代码映射到一个单一的概念标识符，或者在没有合适匹配时映射到指定的未知哨兵值 $0$。\n\n字符串归一化与词元化：\n- 令 $g(s)$ 为一个对字符串 $s$ 进行的确定性归一化与词元化函数，它按顺序应用以下转换：\n  $1.$ 将所有字符转换为小写。\n  $2.$ 通过将已知词元替换为其扩展短语来展开缩写；例如，“hbp” $\\to$ “high blood pressure”， “ckd” $\\to$ “chronic kidney disease”， “akd” $\\to$ “acute kidney disease”， “dz” $\\to$ “disease”， “t2dm” $\\to$ “type 2 diabetes mellitus”， “t1dm” $\\to$ “type 1 diabetes mellitus”。\n  $3.$ 将最多为 $10$ 的罗马数字（$\\mathrm{I},\\mathrm{II},\\mathrm{III},\\mathrm{IV},\\mathrm{V},\\mathrm{VI},\\mathrm{VII},\\mathrm{VIII},\\mathrm{IX},\\mathrm{X}$）转换为对应的阿拉伯数字（$1,2,3,4,5,6,7,8,9,10$）。\n  $4.$ 将所有非字母数字字符替换为空格，并按空白字符分割成词元。\n  $5.$ 移除已知的停用词，如“nos”和“unspecified”。\n  输出 $g(s)$ 是由上述步骤产生的词元集合（在相似度计算中作为集合处理）。\n\n加权词元相似度：\n- 对于一个概念词典 $\\{(c,L_c)\\}$，将词元 $t$ 的文档频率 $\\mathrm{df}(t)$ 定义为在 $\\bigcup_{c} L_c$ 中，其归一化词元集（通过 $g$ 函数）包含 $t$ 的不同概念标签的数量。定义一个权重\n$$\nw(t) = \\frac{1}{1+\\mathrm{df}(t)}.\n$$\n- 对于两个归一化的词元集 $X$ 和 $Y$，定义加权Jaccard相似度\n$$\nJ(X,Y) = \\frac{\\sum_{t \\in X \\cap Y} w(t)}{\\sum_{t \\in X \\cup Y} w(t)},\n$$\n约定当分母为零时，$J(\\varnothing,Y)=0$。\n\n字符级相似度：\n- 令 $d(a,b)$ 为字符串 $a$ 和 $b$ 之间的Levenshtein编辑距离，并令 $|a|$ 表示字符串长度。定义归一化的字符级相似度\n$$\nr(a,b) = \n\\begin{cases}\n0,  \\text{if } \\max(|a|,|b|)=0,\\\\\n1 - \\frac{d(a,b)}{\\max(|a|,|b|)},  \\text{otherwise}.\n\\end{cases}\n$$\n- 对于字符相似度，使用经过缩写扩展、罗马数字归一化和移除空白字符后的字符串归一化形式。\n\n组合相似度与概念评分：\n- 对于一个本地代码 $s$ 和一个带有标签 $L_c$ 的概念 $c$，定义概念得分\n$$\nS_c(s) = \\max_{\\ell \\in L_c} \\left[ \\alpha \\cdot J\\big(g(s), g(\\ell)\\big) + (1-\\alpha) \\cdot r\\big(\\tilde{s}, \\tilde{\\ell}\\big) \\right],\n$$\n其中 $\\alpha \\in [0,1]$，$\\tilde{s}$ 和 $\\tilde{\\ell}$ 分别是 $s$ 和 $\\ell$ 的字符归一化形式（经过缩写扩展、罗马数字归一化和空白字符剥离）。\n\n决策规则、模糊性与未映射策略：\n- 给定一个阈值 $\\tau \\in [0,1]$ 和一个平局容差 $\\epsilon > 0$，定义候选集\n$$\n\\mathcal{C}(s) = \\{ c \\mid S_c(s) \\ge \\tau \\}.\n$$\n- 如果 $\\mathcal{C}(s)=\\varnothing$，则将未知哨兵值 $0$ 分配给 $s$（这是一个未映射代码）。\n- 否则，令 $S_{\\max}(s) = \\max_{c \\in \\mathcal{C}(s)} S_c(s)$ 并定义得分最高的候选者集合\n$$\n\\mathcal{T}(s) = \\{ c \\in \\mathcal{C}(s) \\mid S_{\\max}(s) - S_c(s) \\le \\epsilon \\}.\n$$\n- 如果 $|\\mathcal{T}(s)|=1$，则将该唯一概念分配给 $s$。\n- 如果 $|\\mathcal{T}(s)|1$（模糊情况），则选择 $\\mathcal{T}(s)$ 中具有最大先验概率 $p(c)$ 的概念。如果多个候选者在 $p(c)$ 上仍然持平，则选择具有最小标识符 $c$ 的候选者（确定性打破平局）。将每个此类实例计为“已解决的模糊”。\n\n量化输出：\n- 对于一批本地代码，定义 $M$ 为映射到非零概念标识符（即非未知哨兵值）的代码的整数计数，$U$ 为映射到未知哨兵值 $0$ 的代码的整数计数，以及 $A$ 为模糊（即 $|\\mathcal{T}(s)|1$）但通过打破平局策略解决的代码的整数计数。对于每个测试用例，程序必须输出列表 $[M,U,A]$。\n\n测试套件规范：\n为以下四个测试用例实现您的程序。每个测试用例都指定了概念词典、先验概率、本地代码以及参数 $\\alpha$ 和 $\\tau$。\n\n- 测试用例 1:\n  - 概念标识符和标签：\n    $1001$: {\"Type 2 diabetes mellitus\", \"T2DM\"},\n    $1002$: {\"Type 1 diabetes mellitus\", \"T1DM\"},\n    $2001$: {\"Hypertension\", \"High blood pressure\"}.\n  - 先验概率 $p(c)$:\n    $p(1001)=0.6$, $p(1002)=0.2$, $p(2001)=0.4$.\n  - 本地代码：\n    \"type II diabetes\", \"HBP\", \"diabetes type 1\", \"unknown diagnosis\".\n  - 参数：\n    $\\alpha=0.7$, $\\tau=0.5$, 未知哨兵值 $0$, 平局容差 $\\epsilon=10^{-12}$.\n\n- 测试用例 2:\n  - 概念标识符和标签：\n    $3001$: {\"Chronic kidney disease\", \"CKD\", \"Chronic renal disease\"},\n    $3002$: {\"Acute kidney disease\", \"AKD\", \"Acute renal disease\"},\n    $4001$: {\"Chronic renal insufficiency\"}.\n  - 先验概率 $p(c)$:\n    $p(3001)=0.55$, $p(3002)=0.25$, $p(4001)=0.30$.\n  - 本地代码：\n    \"renal disease\", \"ckd stage\", \"acute kidney dz\".\n  - 参数：\n    $\\alpha=0.7$, $\\tau=0.55$, 未知哨兵值 $0$, 平局容差 $\\epsilon=10^{-12}$.\n\n- 测试用例 3:\n  - 概念标识符和标签：\n    $5001$: {\"Fever\", \"Pyrexia\"},\n    $5002$: {\"Hypothermia\", \"Cold\"},\n    $5003$: {\"Cold\", \"Common cold\"}.\n  - 先验概率 $p(c)$:\n    $p(5001)=0.5$, $p(5002)=0.5$, $p(5003)=0.5$.\n  - 本地代码：\n    \"fever\", \"\", \"pyrexia\", \"cold\".\n  - 参数：\n    $\\alpha=0.7$, $\\tau=0.6$, 未知哨兵值 $0$, 平局容差 $\\epsilon=10^{-12}$.\n\n- 测试用例 4:\n  - 概念标识符和标签：\n    $6001$: {\"Myocardial infarction\", \"Heart attack\"},\n    $6002$: {\"Angina\", \"Anginal pain\"}.\n  - 先验概率 $p(c)$:\n    $p(6001)=0.4$, $p(6002)=0.6$.\n  - 本地代码：\n    \"heart attak\", \"anginal pain\".\n  - 参数：\n    $\\alpha=0.5$, $\\tau=0.5$, 未知哨兵值 $0$, 平局容差 $\\epsilon=10^{-12}$.\n\n最终输出格式要求：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个结果都是一个 $[M,U,A]$ 列表，按测试用例的顺序排列。例如，输出必须看起来像 \"[[x1,y1,z1],[x2,y2,z2],[x3,y3,z3],[x4,y4,z4]]\"，不含空格。", "solution": "该问题要求实现一个确定性管线，用于将本地电子健康记录（EHR）文本代码映射到标准化概念标识符。该解决方案通过系统地实现指定管线的每个组件（从字符串归一化到最终决策逻辑）来构建，然后将此管线应用于一套测试用例以生成量化评估指标。\n\n总体方法是首先建立一组预计算步骤来准备必要的数据结构，例如词元权重，然后通过评分和决策管线处理每个本地代码。\n\n### 步骤 1：字符串归一化与预计算\n\n映射管线的基础是一个确定性的字符串归一化函数 $g(s)$ 和一个字符归一化形式 $\\tilde{s}$。它们的实现如下：\n\n1.  **公共预处理**：首先对 $g(s)$ 和 $\\tilde{s}$ 应用一个共享的归一化序列。一个给定的字符串 $s$ 会经过以下处理：\n    a. 转换为小写。\n    b. 展开已知缩写（例如，“$t2dm$” $\\to$ “type 2 diabetes mellitus”）。这通过使用能感知词边界的正则表达式替换来实现，以防止词内不正确的替换。\n    c. 转换最多为10的罗马数字（例如，“$\\mathrm{ix}$” $\\to$ “$9$”）。为确保正确性（例如，在处理“$\\mathrm{i}$”之前先处理“$\\mathrm{ix}$”），罗马数字列表在替换前按长度降序排序。\n\n2.  **词元集生成 $g(s)$**：在公共预处理之后，将生成的字符串中所有非字母数字字符替换为空格，并按空白字符进行分割以实现词元化。然后移除已知的停用词（“$nos$”， “$unspecified$”）。最终输出是唯一词元的集合。\n\n3.  **字符归一化字符串 $\\tilde{s}$**：在公共预处理之后，从字符串中移除所有非字母数字字符以生成 $\\tilde{s}$。\n\n在处理本地代码之前，为提高效率，预先计算了几个组件：\n-   **词元权重 $w(t)$**：计算每个词元 $t$ 的文档频率 $\\mathrm{df}(t)$。这是概念词典 $\\bigcup_{c} L_c$ 中，其归一化形式 $g(\\ell)$ 包含 $t$ 的不同标签的数量。词元权重则为 $w(t) = \\frac{1}{1+\\mathrm{df}(t)}$。对词典标签中存在的所有词元预先计算这些权重。\n-   **已处理的概念词典**：对于每个概念 $c$，其标签集 $L_c$ 都经过预处理。对于每个标签 $\\ell \\in L_c$，我们计算并存储其词元集表示 $g(\\ell)$ 和其字符归一化形式 $\\tilde{\\ell}$。这避免了在评分阶段的冗余计算。\n\n### 步骤 2：相似度与评分\n\n利用预计算的数据，我们可以高效地计算给定本地代码 $s$ 和概念 $c$ 的得分 $S_c(s)$。\n\n1.  **Levenshtein距离 $d(a,b)$**：实现了一个标准的动态规划算法来计算两个字符串之间的Levenshtein编辑距离。此函数是字符级相似度的先决条件。\n\n2.  **加权Jaccard相似度 $J(X,Y)$**：对于本地代码的词元集 $X=g(s)$ 和标签的词元集 $Y=g(\\ell)$，相似度计算如下：\n    $$\n    J(X,Y) = \\frac{\\sum_{t \\in X \\cap Y} w(t)}{\\sum_{t \\in X \\cup Y} w(t)}\n    $$\n    分子是两个集合共有词元的权重之和，分母是两个集合中所有唯一词元的权重之和。如果并集为空（即 $X$ 和 $Y$ 都为空），则 $J(X, Y)$ 为 $0$。\n\n3.  **字符级相似度 $r(a,b)$**：对于本地代码的字符归一化形式 $a=\\tilde{s}$ 和标签的形式 $b=\\tilde{\\ell}$，相似度为：\n    $$\n    r(a,b) = 1 - \\frac{d(a,b)}{\\max(|a|,|b|)}\n    $$\n    仅当 $\\max(|a|,|b|) > 0$ 时才计算此值；否则为 $0$。\n\n4.  **概念得分 $S_c(s)$**：概念 $c$ 的最终得分是其所有标签 $\\ell \\in L_c$ 上的最大组合相似度得分。单个标签的组合得分是两种相似度指标的加权平均值：\n    $$\n    S_c(s) = \\max_{\\ell \\in L_c} \\left[ \\alpha \\cdot J\\big(g(s), g(\\ell)\\big) + (1-\\alpha) \\cdot r\\big(\\tilde{s}, \\tilde{\\ell}\\big) \\right]\n    $$\n\n### 步骤 3：决策逻辑与量化指标\n\n对于每个本地代码 $s$，在计算了词典中所有概念 $c$ 的 $S_c(s)$ 之后，通过一个多步决策规则来确定最终的映射。相应地更新已映射（$M$）、未映射（$U$）和模糊（$A$）代码的计数器。\n\n1.  **候选者选择**：候选概念集形成为 $\\mathcal{C}(s) = \\{ c \\mid S_c(s) \\ge \\tau \\}$，其中 $\\tau$ 是给定的相似度阈值。\n\n2.  **未映射代码**：如果 $\\mathcal{C}(s)$ 为空，则该代码被视为未映射。它被分配未知哨兵值 $0$，并且计数器 $U$ 递增。\n\n3.  **得分最高的候选者**：如果 $\\mathcal{C}(s)$ 不为空，该代码将被映射。计数器 $M$ 递增。我们找到最大得分 $S_{\\max}(s) = \\max_{c \\in \\mathcal{C}(s)} S_c(s)$。然后，得分最高的候选者集合为 $\\mathcal{T}(s) = \\{ c \\in \\mathcal{C}(s) \\mid S_{\\max}(s) - S_c(s) \\le \\epsilon \\}$，其中 $\\epsilon$ 是一个很小的容差。\n\n4.  **模糊性解决**：\n    -   如果 $|\\mathcal{T}(s)|=1$，映射是明确的，指向 $\\mathcal{T}(s)$ 中的单个概念。\n    -   如果 $|\\mathcal{T}(s)|>1$，映射是模糊的。计数器 $A$ 递增。通过从 $\\mathcal{T}(s)$ 中选择具有最高先验权重 $p(c)$ 的概念来解决模糊性。如果先验概率存在平局，则选择具有最小数值标识符 $c$ 的概念。这种两级打破平局的机制确保了单一的、确定性的映射。\n\n通过此管线处理每个测试用例中的所有本地代码，生成最终计数 $[M, U, A]$。", "answer": "```python\nimport re\nimport numpy as np\nfrom collections import defaultdict\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final results.\n    \"\"\"\n    test_cases = [\n        {\n            \"concepts\": {\n                1001: {\"Type 2 diabetes mellitus\", \"T2DM\"},\n                1002: {\"Type 1 diabetes mellitus\", \"T1DM\"},\n                2001: {\"Hypertension\", \"High blood pressure\"},\n            },\n            \"priors\": {1001: 0.6, 1002: 0.2, 2001: 0.4},\n            \"codes\": [\"type II diabetes\", \"HBP\", \"diabetes type 1\", \"unknown diagnosis\"],\n            \"alpha\": 0.7, \"tau\": 0.5, \"epsilon\": 1e-12\n        },\n        {\n            \"concepts\": {\n                3001: {\"Chronic kidney disease\", \"CKD\", \"Chronic renal disease\"},\n                3002: {\"Acute kidney disease\", \"AKD\", \"Acute renal disease\"},\n                4001: {\"Chronic renal insufficiency\"},\n            },\n            \"priors\": {3001: 0.55, 3002: 0.25, 4001: 0.30},\n            \"codes\": [\"renal disease\", \"ckd stage\", \"acute kidney dz\"],\n            \"alpha\": 0.7, \"tau\": 0.55, \"epsilon\": 1e-12\n        },\n        {\n            \"concepts\": {\n                5001: {\"Fever\", \"Pyrexia\"},\n                5002: {\"Hypothermia\", \"Cold\"},\n                5003: {\"Cold\", \"Common cold\"},\n            },\n            \"priors\": {5001: 0.5, 5002: 0.5, 5003: 0.5},\n            \"codes\": [\"fever\", \"\", \"pyrexia\", \"cold\"],\n            \"alpha\": 0.7, \"tau\": 0.6, \"epsilon\": 1e-12\n        },\n        {\n            \"concepts\": {\n                6001: {\"Myocardial infarction\", \"Heart attack\"},\n                6002: {\"Angina\", \"Anginal pain\"},\n            },\n            \"priors\": {6001: 0.4, 6002: 0.6},\n            \"codes\": [\"heart attak\", \"anginal pain\"],\n            \"alpha\": 0.5, \"tau\": 0.5, \"epsilon\": 1e-12\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = _solve_case(\n            case[\"concepts\"], case[\"priors\"], case[\"codes\"], \n            case[\"alpha\"], case[\"tau\"], case[\"epsilon\"]\n        )\n        results.append(result)\n\n    formatted_results = [f\"[{','.join(map(str, res))}]\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\n\ndef _solve_case(concept_dict, priors, local_codes, alpha, tau, epsilon):\n    \"\"\"\n    Solves a single test case based on the problem specification.\n    \"\"\"\n    \n    # Memoization caches for normalization functions\n    memo_g = {}\n    memo_char_norm = {}\n\n    ABBREVIATIONS = {\n        \"hbp\": \"high blood pressure\", \"ckd\": \"chronic kidney disease\",\n        \"akd\": \"acute kidney disease\", \"dz\": \"disease\",\n        \"t2dm\": \"type 2 diabetes mellitus\", \"t1dm\": \"type 1 diabetes mellitus\",\n    }\n    ROMAN_NUMERALS = {\n        \"i\": \"1\", \"ii\": \"2\", \"iii\": \"3\", \"iv\": \"4\", \"v\": \"5\",\n        \"vi\": \"6\", \"vii\": \"7\", \"viii\": \"8\", \"ix\": \"9\", \"x\": \"10\",\n    }\n    ROMAN_KEYS_SORTED = sorted(ROMAN_NUMERALS.keys(), key=len, reverse=True)\n    STOPWORDS = {\"nos\", \"unspecified\"}\n\n    def _normalize_common(s):\n        norm_s = s.lower()\n        for abbr, expansion in ABBREVIATIONS.items():\n            norm_s = re.sub(r'\\b' + re.escape(abbr) + r'\\b', expansion, norm_s)\n        for r_key in ROMAN_KEYS_SORTED:\n            norm_s = re.sub(r'\\b' + r_key + r'\\b', ROMAN_NUMERALS[r_key], norm_s)\n        return norm_s\n    \n    def g(s):\n        if s in memo_g: return memo_g[s]\n        norm_s = _normalize_common(s)\n        tokens = re.sub(r'[^a-zA-Z0-9]', ' ', norm_s).split()\n        final_tokens = {token for token in tokens if token not in STOPWORDS}\n        memo_g[s] = final_tokens\n        return final_tokens\n\n    def char_normalize(s):\n        if s in memo_char_norm: return memo_char_norm[s]\n        norm_s = _normalize_common(s)\n        result = re.sub(r'[^a-zA-Z0-9]', '', norm_s)\n        memo_char_norm[s] = result\n        return result\n\n    def levenshtein(s1, s2):\n        m, n = len(s1), len(s2)\n        dp = np.zeros((m + 1, n + 1), dtype=int)\n        for i in range(m + 1):\n            dp[i, 0] = i\n        for j in range(n + 1):\n            dp[0, j] = j\n        for i in range(1, m + 1):\n            for j in range(1, n + 1):\n                cost = 0 if s1[i - 1] == s2[j - 1] else 1\n                dp[i, j] = min(dp[i - 1, j] + 1,\n                               dp[i, j - 1] + 1,\n                               dp[i - 1, j - 1] + cost)\n        return dp[m, n]\n\n    # Pre-computation steps\n    all_labels = {label for labels in concept_dict.values() for label in labels}\n    \n    df = defaultdict(int)\n    for label in all_labels:\n        for token in g(label):\n            df[token] += 1\n            \n    all_dict_tokens = df.keys()\n    w = {t: 1.0 / (1.0 + df.get(t, 0)) for t in all_dict_tokens}\n\n    processed_concepts = {}\n    for cid, labels in concept_dict.items():\n        processed_labels = [\n            {\"g\": g(label), \"char_norm\": char_normalize(label)}\n            for label in labels\n        ]\n        processed_concepts[cid] = processed_labels\n\n    M, U, A = 0, 0, 0\n    for s in local_codes:\n        if not s.strip():\n            U += 1\n            continue\n        \n        s_g = g(s)\n        s_char_norm = char_normalize(s)\n        \n        scores = {}\n        for cid, p_labels in processed_concepts.items():\n            max_label_score = 0.0\n            for label_data in p_labels:\n                l_g = label_data[\"g\"]\n                l_char_norm = label_data[\"char_norm\"]\n                \n                intersect = s_g.intersection(l_g)\n                union = s_g.union(l_g)\n                sum_w_intersect = sum(w.get(t, 1.0) for t in intersect)\n                sum_w_union = sum(w.get(t, 1.0) for t in union)\n                j_sim = sum_w_intersect / sum_w_union if sum_w_union > 0 else 0.0\n                \n                lev_dist = levenshtein(s_char_norm, l_char_norm)\n                max_len = max(len(s_char_norm), len(l_char_norm))\n                r_sim = (1.0 - lev_dist / max_len) if max_len > 0 else 0.0\n\n                combined_score = alpha * j_sim + (1 - alpha) * r_sim\n                if combined_score > max_label_score:\n                    max_label_score = combined_score\n            scores[cid] = max_label_score\n\n        candidate_set = {cid for cid, score in scores.items() if score >= tau}\n        \n        if not candidate_set:\n            U += 1\n            continue\n        \n        M += 1\n        max_score = max(scores[cid] for cid in candidate_set)\n        top_candidates = {cid for cid in candidate_set if max_score - scores[cid] = epsilon}\n\n        if len(top_candidates) > 1:\n            A += 1\n            # Ambiguity resolution not needed for counting, but included for completeness:\n            # resolved_candidate = sorted(list(top_candidates), key=lambda cid: (-priors[cid], cid))[0]\n    \n    return [M, U, A]\n\nif __name__ == '__main__':\n    solve()\n```", "id": "4563113"}, {"introduction": "在电子健康记录（EHR）数据中，临床事件（如诊断、用药）不仅关乎其“是否发生”，更关乎其“何时发生”。一个最近发生的事件通常比一个久远的事件具有更高的临床相关性。因此，简单的事件计数往往无法捕捉这种动态变化。本练习 [@problem_id:4563133] 探讨了一种更精细的特征构建方法：新近度加权计数。你将从“无记忆”这一基本公理出发，推导出指数衰减函数 $w(d) = \\exp(-\\lambda d)$ 作为权重，并学习如何根据临床直觉（如“半衰期”）来校准衰减率 $\\lambda$。这个过程不仅能让你构建出更具临床意义的时间序列特征，还能加深你对如何将抽象的临床概念转化为严谨数学模型的理解。", "problem": "在电子健康记录 (EHR) 数据的特征工程中，通常需要对临床事件进行近期加权计数，即相较于近期事件，对较早发生的事件进行更多折减。设事件时间戳为 $\\{t_i\\}$，单位为天，索引时间为 $t_{\\text{index}}$，单位为天。对每个事件，定义非负延迟 $d_i = t_{\\text{index}} - t_i$（单位为天）。考虑一个权重函数 $w(d)$，它将每个延迟 $d \\ge 0$ 映射到一个非负实数，该实数代表该事件对近期加权计数的贡献。假设以下基于生理过程和健康数据中就诊近期性常用的无记忆衰减的基本属性：\n- 零延迟归一化：$w(0) = 1$。\n- 单调衰减：当 $d_1 \\le d_2$ 时，$w(d_1) \\ge w(d_2)$。\n- 半群（无记忆）属性：对于所有 $d_1, d_2 \\ge 0$，$w(d_1 + d_2) = w(d_1)\\,w(d_2)$。\n- 在 $d = 0$ 处可微。\n\n根据这些基本属性，推导出 $w(d)$ 的函数形式，然后将近期加权计数定义为\n$$\nC = \\sum_{i=1}^{n} w\\!\\left(t_{\\text{index}} - t_i\\right),\n$$\n其中，求和范围是所有满足 $t_i \\le t_{\\text{index}}$ 的事件。\n\n必须进行衰减率的校准，以编码关于事件影响力应多快衰减的临床假设。您将从推导出的 $w(d)$ 中校准一个正参数，以满足以下临床医生指定的约束之一：\n- 半衰期约束：延迟 $h$ 天应使权重减半，即 $w(h) = 0.5$。这里的 $h$ 以天为单位。\n- 窗口内质量分数：将 $w(d)$ 视为在 $d \\in [0,\\infty)$ 上的未归一化核，最近 $T$ 天内捕获的总质量分数应为 $p$（$p$ 以小数表示），即比率 $\\int_0^T w(d)\\, \\mathrm{d}d \\Big/ \\int_0^\\infty w(d)\\, \\mathrm{d}d$ 等于 $p$。这里的 $T$ 以天为单位。\n- 两个延迟下的比率：两个延迟 $d_a$ 和 $d_b$ 处的权重之比应为 $r$，即 $w(d_a)/w(d_b) = r$。这里的 $d_a$ 和 $d_b$ 以天为单位，$r$ 是一个正实数。\n- 特定延迟下的绝对权重：延迟 $L$ 处的权重应等于 $a$，即 $w(L) = a$。这里的 $L$ 以天为单位，$a \\in (0,1)$。\n\n您的任务是：\n- 从所述属性中推导出 $w(d)$，确定其唯一的正校准参数，并推导出如何根据上述四种约束类型中的每一种来计算此参数。\n- 实现一个程序，该程序在给定一小组场景测试套件的情况下，为每个场景校准参数并计算相应的近期加权计数 $C$。\n\n所有时间戳的单位均为天，计数是无单位的。本问题不使用角度。最终程序必须输出一个单行，其格式如下文指定。\n\n使用以下测试套件。每个测试用例由一个索引时间 $t_{\\text{index}}$、一个事件时间列表 $\\{t_i\\}$ 和一个带有参数的校准模式指定：\n\n- 测试用例 1（正常路径，半衰期）：\n  - $t_{\\text{index}} = 100$。\n  - $\\{t_i\\} = [98, 90, 60, 20]$。\n  - 校准模式：半衰期，其中 $h = 30$。\n- 测试用例 2（窗口内质量分数，强调不同窗口）：\n  - $t_{\\text{index}} = 200$。\n  - $\\{t_i\\} = [140, 150, 180, 199]$。\n  - 校准模式：质量分数，其中 $T = 60$，$p = 0.9$（以小数表示）。\n- 测试用例 3（两个延迟下的比率，检查从相对偏好中的可识别性）：\n  - $t_{\\text{index}} = 1000$。\n  - $\\{t_i\\} = [940, 970, 986, 995]$。\n  - 校准模式：比率，其中 $d_a = 14$，$d_b = 60$，$r = 3$。\n- 测试用例 4（特定延迟下的绝对权重，极端小目标，数值稳定性）：\n  - $t_{\\text{index}} = 1000$。\n  - $\\{t_i\\} = [820, 635, 999]$。\n  - 校准模式：绝对值，其中 $L = 180$，$a = 0.01$。\n- 测试用例 5（边界条件，无事件）：\n  - $t_{\\text{index}} = 123$。\n  - $\\{t_i\\} = []$（空）。\n  - 校准模式：半衰期，其中 $h = 7$。\n\n对于每个测试用例，您的程序必须：\n- 根据指定的模式和参数校准衰减参数。\n- 为给定的事件和 $t_{\\text{index}}$ 计算近期加权计数 $C$。\n\n最终输出格式：\n- 生成一个单行，包含一个由数对组成的列表，每个测试用例对应一个数对，每个数对包含校准后的参数和相应的近期加权计数，两者均四舍五入到小数点后六位。输出不应包含任何空格。例如，一个包含两个假设测试用例的输出应如下所示：`[[0.123456,2.500000],[0.500000,0.000000]]`。", "solution": "首先对问题陈述进行严格的验证过程。\n\n### 步骤 1：提取给定信息\n- **事件数据**：一组事件时间戳 $\\{t_i\\}$，单位为天。\n- **索引时间**：一个参考时间 $t_{\\text{index}}$，单位为天。\n- **延迟定义**：每个事件的时间差 $d_i = t_{\\text{index}} - t_i$，其中 $d_i \\ge 0$。\n- **权重函数**：一个函数 $w(d)$，对于 $d \\ge 0$，将延迟映射到一个非负实数。\n- **$w(d)$ 的属性**：\n    1.  $w(0) = 1$（零延迟归一化）。\n    2.  对于 $d_1 \\le d_2$，$w(d_1) \\ge w(d_2)$（单调衰减）。\n    3.  对于所有 $d_1, d_2 \\ge 0$，$w(d_1 + d_2) = w(d_1) w(d_2)$（半群/无记忆属性）。\n    4.  $w(d)$ 在 $d=0$ 处可微。\n- **近期加权计数**：计数 $C$ 定义为 $C = \\sum_{i=1}^{n} w(t_{\\text{index}} - t_i)$，对所有满足 $t_i \\le t_{\\text{index}}$ 的事件求和。\n- **校准约束**：提供四个互斥约束之一，用于校准 $w(d)$ 的单个正参数。\n    1.  **半衰期**：对于给定的延迟 $h  0$，$w(h) = 0.5$。\n    2.  **质量分数**：对于给定的持续时间 $T  0$ 和分数 $p \\in (0,1)$，$\\int_0^T w(d)\\, \\mathrm{d}d \\Big/ \\int_0^\\infty w(d)\\, \\mathrm{d}d = p$。\n    3.  **两个延迟下的比率**：对于给定的延迟 $d_a, d_b  0$ 和比率 $r  0$，$w(d_a)/w(d_b) = r$。\n    4.  **绝对权重**：对于给定的延迟 $L  0$ 和权重 $a \\in (0,1)$，$w(L) = a$。\n- **测试套件**：提供了五个测试用例，包含 $t_{\\text{index}}$、$\\{t_i\\}$ 和校准参数的具体值。\n\n### 步骤 2：使用提取的给定信息进行验证\n- **科学依据**：该问题基础扎实。施加于 $w(d)$ 的属性是唯一定义指数函数的标准公理，指数函数是模拟众多科学领域（例如，放射性衰变、一级化学动力学以及如问题所述的数据分析中的近期效应）中衰减过程的基石。\n- **适定性 (Well-Posed)**：该问题是适定的。$w(d)$ 的函数形式由给定属性唯一确定。四个校准约束中的每一个都是一个单未知参数的单方程，似乎可以求解出唯一的正值。总体任务定义清晰，每个测试用例都有唯一的解。\n- **客观性**：问题以精确、客观的数学语言陈述。所有术语均已定义，没有歧义或主观内容。\n- **完整性和一致性**：问题是自洽且一致的。解决测试用例所需的所有数据都已提供。$w(d)$ 的属性相互一致，校准约束与推导出的函数形式兼容。例如，在比率约束中，提供的测试数据（$d_a  d_b$ 和 $r > 1$）确保了衰减参数为正。\n- **解决方案推理**：\n    1.  **推导 $w(d)$**：柯西函数方程 $w(d_1 + d_2) = w(d_1)w(d_2)$ 以及在 $d=0$ 处可微的条件，唯一地确定了函数形式为 $w(d) = \\exp(kd)$。由于函数是单调衰减的，我们必须有 $k  0$。因此，我们可以将权重函数写为 $w(d) = \\exp(-\\lambda d)$，其中 $\\lambda = -k$ 是一个正的衰减参数。$w(0) = \\exp(0) = 1$ 的条件也得到满足。\n    2.  **推导校准公式**：\n        a. **半衰期**：$w(h) = \\exp(-\\lambda h) = 0.5 \\implies -\\lambda h = \\ln(0.5) = -\\ln(2) \\implies \\lambda = \\frac{\\ln(2)}{h}$。\n        b. **质量分数**：$\\int_0^T \\exp(-\\lambda d) \\, \\mathrm{d}d = [-\\frac{1}{\\lambda}\\exp(-\\lambda d)]_0^T = \\frac{1}{\\lambda}(1 - \\exp(-\\lambda T))$。$\\int_0^\\infty \\exp(-\\lambda d) \\, \\mathrm{d}d = [-\\frac{1}{\\lambda}\\exp(-\\lambda d)]_0^\\infty = \\frac{1}{\\lambda}$。它们的比率为 $1 - \\exp(-\\lambda T) = p \\implies \\exp(-\\lambda T) = 1-p \\implies -\\lambda T = \\ln(1-p) \\implies \\lambda = -\\frac{\\ln(1-p)}{T}$。\n        c. **比率**：$w(d_a)/w(d_b) = \\exp(-\\lambda d_a)/\\exp(-\\lambda d_b) = \\exp(\\lambda(d_b - d_a)) = r \\implies \\lambda(d_b - d_a) = \\ln(r) \\implies \\lambda = \\frac{\\ln(r)}{d_b - d_a}$。\n        d. **绝对权重**：$w(L) = \\exp(-\\lambda L) = a \\implies -\\lambda L = \\ln(a) \\implies \\lambda = -\\frac{\\ln(a)}{L}$。\n    3.  **计算近期加权计数**：对于每个测试用例，首先使用适当的公式计算 $\\lambda$。然后，对于事件列表 $\\{t_i\\}$ 中的每个事件，计算延迟 $d_i = t_{\\text{index}} - t_i$。最后，计算总和 $C = \\sum_i \\exp(-\\lambda d_i)$，其中求和范围是所有满足 $t_i \\le t_{\\text{index}}$ 的事件。\n    4.  **测试用例应用**：\n        -   **用例 1**：$h=30$，$\\lambda = \\ln(2)/30 \\approx 0.023105$。延迟为 $[2, 10, 40, 80]$。$C = e^{-2\\lambda} + e^{-10\\lambda} + e^{-40\\lambda} + e^{-80\\lambda}$。\n        -   **用例 2**：$T=60, p=0.9$，$\\lambda = -\\ln(0.1)/60 \\approx 0.038379$。延迟为 $[60, 50, 20, 1]$。$C = e^{-60\\lambda} + e^{-50\\lambda} + e^{-20\\lambda} + e^{-1\\lambda}$。\n        -   **用例 3**：$d_a=14, d_b=60, r=3$，$\\lambda = \\ln(3)/46 \\approx 0.023883$。延迟为 $[60, 30, 14, 5]$。$C = e^{-60\\lambda} + e^{-30\\lambda} + e^{-14\\lambda} + e^{-5\\lambda}$。\n        -   **用例 4**：$L=180, a=0.01$，$\\lambda = -\\ln(0.01)/180 \\approx 0.025584$。延迟为 $[180, 365, 1]$。$C = e^{-180\\lambda} + e^{-365\\lambda} + e^{-1\\lambda}$。\n        -   **用例 5**：$h=7$，$\\lambda = \\ln(2)/7 \\approx 0.099021$。事件列表为空，因此 $C=0$。\n- **输出格式**：要求以 `[[lambda1, C1], [lambda2, C2], ...]` 的形式输出，其中数字四舍五入到小数点后六位。这要求在最终格式化之前进行数值计算。\n\n该解决方案的逻辑是健全的，直接遵循数学推导和问题要求。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the recency-weighted count problem for a suite of test cases.\n\n    The function first defines the test cases as provided in the problem statement.\n    It then iterates through each case, performing two main steps:\n    1. Calibrates the decay parameter 'lambda' based on the specified mode and parameters.\n       The formulas for lambda are derived from the exponential decay model w(d) = exp(-lambda * d).\n         - Half-life: lambda = ln(2) / h\n         - Mass-fraction: lambda = -ln(1 - p) / T\n         - Ratio: lambda = ln(r) / (d_b - d_a)\n         - Absolute: lambda = -ln(a) / L\n    2. Computes the recency-weighted count 'C' by summing the weights for all events.\n       The weight for an event with lag 'd' is w(d). The lag is t_index - t_event.\n       C = sum(exp(-lambda * (t_index - t_i))) over all event times t_i.\n    \n    The results (calibrated lambda, computed C) for each case are collected and\n    formatted into a single string as per the problem's output specification.\n    \"\"\"\n    test_cases = [\n        {\n            \"t_index\": 100,\n            \"t_i_list\": [98, 90, 60, 20],\n            \"mode\": \"half-life\",\n            \"params\": {\"h\": 30}\n        },\n        {\n            \"t_index\": 200,\n            \"t_i_list\": [140, 150, 180, 199],\n            \"mode\": \"mass-fraction\",\n            \"params\": {\"T\": 60, \"p\": 0.9}\n        },\n        {\n            \"t_index\": 1000,\n            \"t_i_list\": [940, 970, 986, 995],\n            \"mode\": \"ratio\",\n            \"params\": {\"d_a\": 14, \"d_b\": 60, \"r\": 3}\n        },\n        {\n            \"t_index\": 1000,\n            \"t_i_list\": [820, 635, 999],\n            \"mode\": \"absolute\",\n            \"params\": {\"L\": 180, \"a\": 0.01}\n        },\n        {\n            \"t_index\": 123,\n            \"t_i_list\": [],\n            \"mode\": \"half-life\",\n            \"params\": {\"h\": 7}\n        }\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        mode = case[\"mode\"]\n        params = case[\"params\"]\n        lambda_val = 0.0\n\n        # Step 1: Calibrate the decay parameter lambda\n        if mode == \"half-life\":\n            h = params[\"h\"]\n            lambda_val = np.log(2) / h\n        elif mode == \"mass-fraction\":\n            T = params[\"T\"]\n            p = params[\"p\"]\n            lambda_val = -np.log(1 - p) / T\n        elif mode == \"ratio\":\n            d_a = params[\"d_a\"]\n            d_b = params[\"d_b\"]\n            r = params[\"r\"]\n            lambda_val = np.log(r) / (d_b - d_a)\n        elif mode == \"absolute\":\n            L = params[\"L\"]\n            a = params[\"a\"]\n            lambda_val = -np.log(a) / L\n\n        # Step 2: Compute the recency-weighted count C\n        t_index = case[\"t_index\"]\n        t_i_list = case[\"t_i_list\"]\n        count_C = 0.0\n        \n        if t_i_list:\n            lags = t_index - np.array(t_i_list)\n            # Ensure no negative lags, as per problem definition d >= 0\n            lags = lags[lags >= 0]\n            if lags.size > 0:\n                weights = np.exp(-lambda_val * lags)\n                count_C = np.sum(weights)\n\n        all_results.append([lambda_val, count_C])\n    \n    # Format the final output string as specified\n    formatted_pairs = [f\"[{lam:.6f},{c:.6f}]\" for lam, c in all_results]\n    final_output_string = f\"[{','.join(formatted_pairs)}]\"\n    \n    print(final_output_string)\n\nsolve()\n```", "id": "4563133"}, {"introduction": "利用纵向的EHR数据构建预测模型时，一个常见但极其危险的陷阱是“不朽时间偏倚”（immortal time bias）。这种偏倚发生在使用未来信息来定义过去的风险或暴露时，导致模型表现被严重高估。为了构建科学上严谨且临床上可靠的预测模型，我们必须采用能规避此问题的方法论。本练习 [@problem_id:4563190] 将引导你实践界标分析（landmark analysis）这一核心技术。你将学习如何在一个固定的“界标”时间点 $L$ 上，严格筛选合格的风险人群，并仅使用该时间点之前的数据来构建特征，从而从根本上杜绝未来信息泄露。掌握这项技能对于开发任何有意义的临床决策支持系统都至关重要。", "problem": "您会获得一份针对多个受试者的电子健康记录 (EHR) 数据和临床随访的简化抽象模型，其目标是在一个固定的地标时间构建地标特征，并定义规则以避免在后续的结果标签化中出现永生时间偏倚。核心任务是实现一个地标分析程序，该程序在一个固定的时间原点构建随时间变化的协变量，并使用符合原则的生存分析定义，在一个固定的时间窗内为结果添加标签。\n\n基本原理和定义：\n- 生存分析通过事件时间 $T_i$ 和删失时间 $C_i$ 来定义每个受试者，其中观测时间为 $X_i = \\min(T_i, C_i)$，事件指示符为 $\\Delta_i = \\mathbb{1}\\{T_i \\le C_i\\}$。当使用基线后信息对暴露或结果进行分类，而这种分类方式要求受试者存活到信息被记录的时刻时，就会产生永生时间偏倚；为避免这种情况，地标分析在源自地标的固定原点构建协变量和标签。\n- 地标分析固定一个地标时间 $L$，并将风险集定义为在 $L$ 时刻无事件且未删失的受试者。结果是相对于 $L$ 定义的，而不是原始的开始时间。\n\n任务：\n- 您必须实现一个程序，使用以下固定参数来构建地标特征和标记结果：\n  1. 地标时间 $L = 100$ 天。\n  2. 结果时间窗 $H = 30$ 天。\n  3. 收缩压回溯窗口 $W_{\\mathrm{sbp}} = 60$ 天。\n  4. 就诊次数回溯窗口 $W_{\\mathrm{vis}} = 90$ 天。\n  5. 指数衰减参数 $\\lambda = 0.05$ 每天。\n  6. 参考收缩压 $r_{\\mathrm{sbp}} = 120$ 毫米汞柱 (mmHg)。\n\n- 对于每个受试者 $i$，程序必须强制执行以下数学表达的规则以避免永生时间偏倚：\n  1. 资格（风险集）：当且仅当 $\\min(T_i, C_i)  L$，并且在 $T_i$ 有定义的情况下，$T_i  L$ 且 $C_i  L$ 时，才包括一个受试者。如果 $T_i = L$ 或 $C_i \\le L$，则该受试者在地标时刻不符合资格。\n  2. 时间原点和延迟进入：在地标时刻，通过定义 $t' = t - L$ 将时间重置为 $0$。只有来自时间 $t \\le L$ 的协变量信息才可用于特征构建。\n  3. 时间窗内的结果标签：为符合资格的受试者定义标签 $Y_i = \\mathbb{1}\\{L  T_i \\le \\min(C_i, L + H)\\}$。这将在删失前将在区间 $(L, L + H]$ 内发生的事件标记出来。对于不符合资格的受试者，按照惯例将标签设置为 $0$，并且资格标志表示将其从风险集中排除。\n\n从可采纳的地标前数据构建特征（所有时间单位为天，所有收缩压值单位为毫米汞柱）：\n- 收缩压特征：\n  1. 窗口内的末次观测值结转：设 $\\{(t_{ij}, x_{ij})\\}$ 为收缩压测量值，其中 $t_{ij} \\in [L - W_{\\mathrm{sbp}}, L]$。末次观测值结转为 $x_{i,\\mathrm{last}} = x_{ij^*}$，其中 $j^* = \\arg\\max_j t_{ij}$。如果没有测量值满足该窗口条件，则设置 $x_{i,\\mathrm{last}} = r_{\\mathrm{sbp}}$。\n  2. 窗口内的指数加权平均值：为 $t_{ij} \\in [L - W_{\\mathrm{sbp}}, L]$ 定义权重 $w_{ij} = \\exp(-\\lambda (L - t_{ij}))$。指数加权平均值为 $$\\bar{x}_{i,\\mathrm{ewm}} = \\begin{cases}\\frac{\\sum_j w_{ij} x_{ij}}{\\sum_j w_{ij}},  \\text{如果存在 } j \\text{ 使得 } t_{ij} \\in [L - W_{\\mathrm{sbp}}, L],\\\\ r_{\\mathrm{sbp}},  \\text{其他情况。}\\end{cases}$$\n- 药物暴露特征：\n  1. 地标时刻是否有效：给定用药区间 $\\{[a_{ik}, b_{ik})\\}$，定义 $m_{i,\\mathrm{active}} = \\mathbb{1}\\{\\exists k: a_{ik} \\le L  b_{ik}\\}$，即如果在任何区间覆盖了 $L$ 时刻，则认为在 $L$ 时刻有效。\n- 就诊次数特征：\n  1. 窗口内就诊次数：给定就诊时间 $\\{v_{i\\ell}\\}$，定义 $n_{i,\\mathrm{vis}} = \\left|\\{v_{i\\ell} \\in [L - W_{\\mathrm{vis}}, L]\\}\\right|$。\n\n单位：\n- 所有时间以天表示。\n- 收缩压值以毫米汞柱 (mmHg) 表示。\n- 输出的浮点数必须四舍五入到三位小数。\n\n测试套件：\n- 使用以下四个具有科学上合理数值的受试者。\n\n受试者 1：\n- 事件时间 $T_1 = 115$，删失时间 $C_1 = 200$。\n- 收缩压时间 $[20, 85, 95, 99]$，对应值 $[130, 140, 135, 138]$。\n- 用药区间 $[[50, 120]]$。\n- 就诊时间 $[30, 70, 80, 95]$。\n\n受试者 2（边界情况：事件发生在地标时刻）：\n- 事件时间 $T_2 = 100$，删失时间 $C_2 = 300$。\n- 收缩压时间 $[40, 55, 100]$，对应值 $[128, 132, 129]$。\n- 用药区间 $[[101, 200]]$。\n- 就诊时间 $[99, 100]$。\n\n受试者 3（回溯窗口内缺少收缩压数据，在时间窗内删失）：\n- 未观测到事件；视为 $T_3 = +\\infty$，删失时间 $C_3 = 120$。\n- 收缩压时间 $[10, 20, 30]$，对应值 $[125, 127, 126]$。\n- 用药区间 $[[0, 90]]$。\n- 就诊时间 $[5, 15, 25, 35, 45]$。\n\n受试者 4（事件发生在时间窗之后）：\n- 事件时间 $T_4 = 160$，删失时间 $C_4 = 200$。\n- 收缩压时间 $[70, 110]$，对应值 $[150, 149]$。\n- 用药区间 $[[20, 80], [95, 105]]$。\n- 就诊时间 $[40, 100, 101]$。\n\n输出规范：\n- 对于每个受试者 $i$，计算并输出一个列表 $[\\,\\text{eligible}_i,\\, Y_i,\\, x_{i,\\mathrm{last}},\\, \\bar{x}_{i,\\mathrm{ewm}},\\, m_{i,\\mathrm{active}},\\, n_{i,\\mathrm{vis}}\\,]$，其中布尔值是标准的逻辑值，浮点数四舍五入到三位小数。最终的程序输出必须是包含这些受试者级别列表的单行逗号分隔列表，并用方括号括起来，例如 $[[\\dots],[\\dots],[\\dots],[\\dots]]$。", "solution": "该解决方案通过有原则地应用生存分析和精心构建的特征工程规则来进行，这些规则明确地避免了在地标时刻的永生时间偏倚。其科学基础如下：\n\n1. 使用生存分析定义事件时间和删失时间。对每个受试者 $i$，设 $T_i$ 为事件时间，$C_i$ 为删失时间。观测时间为 $X_i = \\min(T_i, C_i)$，事件指示符为 $\\Delta_i = \\mathbb{1}\\{T_i \\le C_i\\}$。如果我们使用基线或地标后发生的信息来对暴露或结果进行分类，从而要求受试者存活到这些信息被观测到时，就会产生永生时间偏倚。地标分析通过在 $L$ 处固定一个原点，并将特征和结果标签都限制在 $L$ 时刻或之前可用的信息，并将结果定义为相对于 $L$，从而缓解了这个问题。\n\n2. 地标时刻的资格使用延迟进入（左截断）逻辑：仅包括那些在 $L$ 时刻无事件且未删失的受试者。形式上，如果 $X_i  L$，并且当 $T_i$ 有定义时，$T_i  L$，则受试者 $i$ 符合资格。$T_i = L$ 的受试者 $i$ 在地标时刻并非无事件，必须被排除。$C_i \\le L$ 的受试者 $i$ 在地标时刻或之前被删失，也必须被排除。\n\n3. 我们通过将任何时间 $t$ 映射到 $t' = t - L$ 来将时间原点在地标 $L$ 处重置为 $0$。协变量仅使用原始时间 $t \\le L$ 的数据计算。对于符合资格的受试者，时间窗 $H$ 内的结果标签是 $Y_i = \\mathbb{1}\\{L  T_i \\le \\min(C_i, L + H)\\}$，对应于删失前在区间 $(L, L + H]$ 内发生的事件。对于不符合资格的受试者，我们按照惯例将 $Y_i$ 设为 $0$，并使用资格标志来表示他们被排除在风险集之外。这个定义通过不将地标后的暴露或未来生存归因于地标前的风险来确保科学真实性。\n\n4. 特征工程：\n   - 收缩压在窗口 $[L - W_{\\mathrm{sbp}}, L]$ 内的末次观测值结转：设 $\\{(t_{ij}, x_{ij})\\}$ 为有效窗口内的测量值。特征 $x_{i,\\mathrm{last}}$ 是与窗口内最大 $t_{ij}$ 相关的值。如果窗口内没有测量值，则设 $x_{i,\\mathrm{last}} = r_{\\mathrm{sbp}}$。\n   - 在同一窗口内使用衰减参数 $\\lambda$ 的指数加权平均值：权重为 $w_{ij} = \\exp(-\\lambda (L - t_{ij}))$。加权平均值为 $$\\bar{x}_{i,\\mathrm{ewm}} = \\begin{cases}\\frac{\\sum_j w_{ij} x_{ij}}{\\sum_j w_{ij}},  \\text{如果 } j \\text{ 的集合非空，}\\\\ r_{\\mathrm{sbp}},  \\text{其他情况。}\\end{cases}$$ 通过权重总和进行归一化可确保得到一个适当的加权平均值，并避免了对更近期值的偏倚，越接近 $L$ 的 $t_{ij}$ 权重越大。\n   - 地标时刻是否有效：给定暴露区间 $[a_{ik}, b_{ik})$，定义 $m_{i,\\mathrm{active}} = \\mathbb{1}\\{\\exists k: a_{ik} \\le L  b_{ik}\\}$ 以仅捕捉 $L$ 时刻的活动状态。这避免了如果我们把暴露定义为“随访期间曾暴露”时可能发生的永生时间偏倚，因为后者会要求受试者存活超过 $L$ 时刻才能被分类为暴露。\n   - 窗口 $[L - W_{\\mathrm{vis}}, L]$ 内的就诊次数：$n_{i,\\mathrm{vis}} = \\left|\\{v_{i\\ell} \\in [L - W_{\\mathrm{vis}}, L]\\}\\right|$。\n\n5. 应用于测试套件：\n   - 固定参数：$L = 100$ 天，$H = 30$ 天，$W_{\\mathrm{sbp}} = 60$ 天，$W_{\\mathrm{vis}} = 90$ 天，$\\lambda = 0.05$ 每天，$r_{\\mathrm{sbp}} = 120$ mmHg。\n   - 受试者 1：$T_1 = 115, C_1 = 200$ 意味着符合资格，因为 $115  100$ 且 $200  100$。标签 $Y_1 = \\mathbb{1}\\{100  115 \\le 130\\} = 1$。收缩压窗口为 $[40, 100]$，因此时间 $[85, 95, 99]$ 及其值 $[140, 135, 138]$ 被包括在内。末次值为 $x_{1,\\mathrm{last}} = 138$。指数加权平均值使用权重 $w = [\\exp(-0.05 \\cdot 15), \\exp(-0.05 \\cdot 5), \\exp(-0.05 \\cdot 1)]$，归一化后得到的值约为 $137.3$ 至 $137.4$ mmHg。用药区间 $[50, 120)$ 在 $L$ 时刻是有效的，所以 $m_{1,\\mathrm{active}} = 1$。窗口 $[10, 100]$ 内的就诊次数包括 $[30, 70, 80, 95]$，所以 $n_{1,\\mathrm{vis}} = 4$。\n   - 受试者 2：$T_2 = 100, C_2 = 300$ 意味着不符合资格，因为 $T_2 = L$。按照惯例设 $Y_2 = 0$，资格标志表示排除。收缩压窗口包括 $[40, 55, 100]$ 及其值 $[128, 132, 129]$。末次值为 $x_{2,\\mathrm{last}} = 129$。指数加权平均值使用权重 $[\\exp(-0.05 \\cdot 60), \\exp(-0.05 \\cdot 45), 1]$，得到的值约为 $129.1$ 至 $129.2$ mmHg。用药区间 $[101, 200)$ 在 $L$ 时刻无效，所以 $m_{2,\\mathrm{active}} = 0$。就诊次数窗口 $[10, 100]$ 包括 $[99, 100]$，所以 $n_{2,\\mathrm{vis}} = 2$。\n   - 受试者 3：将无事件视为 $T_3 = +\\infty, C_3 = 120$，意味着符合资格（$120  100$）。标签 $Y_3 = \\mathbb{1}\\{100  +\\infty \\le \\min(120, 130)\\} = 0$。收缩压窗口 $[40, 100]$ 内没有测量值；使用参考值 $x_{3,\\mathrm{last}} = 120$ 和 $\\bar{x}_{3,\\mathrm{ewm}} = 120$。用药区间 $[0, 90)$ 在 $L$ 之前结束，所以 $m_{3,\\mathrm{active}} = 0$。就诊窗口 $[10, 100]$ 包括 $[15, 25, 35, 45]$，所以 $n_{3,\\mathrm{vis}} = 4$。\n   - 受试者 4：$T_4 = 160, C_4 = 200$ 意味着符合资格（$160  100, 200  100$）。标签 $Y_4 = \\mathbb{1}\\{100  160 \\le 130\\} = 0$。收缩压窗口 $[40, 100]$ 只包括时间 $70$ 及其值 $150$；末次值为 $x_{4,\\mathrm{last}} = 150$，指数加权平均值也等于 $150$，因为单个测量值归一化后是其本身。用药区间 $[20, 80)$ 和 $[95, 105)$ 中的第二个区间包含 $L$，所以 $m_{4,\\mathrm{active}} = 1$。就诊窗口 $[10, 100]$ 包括 $[40, 100]$，所以 $n_{4,\\mathrm{vis}} = 2$。\n\n6. 实现细节：\n   - 所有计算必须仅使用 $L$ 时刻或之前的数据执行。\n   - 最终输出中的浮点数必须四舍五入到三位小数。\n   - 程序必须生成一行输出，其中包含受试者结果的列表：$[[\\text{eligible}_1, Y_1, x_{1,\\mathrm{last}}, \\bar{x}_{1,\\mathrm{ewm}}, m_{1,\\mathrm{active}}, n_{1,\\mathrm{vis}}], \\dots, [\\text{eligible}_4, Y_4, x_{4,\\mathrm{last}}, \\bar{x}_{4,\\mathrm{ewm}}, m_{4,\\mathrm{active}}, n_{4,\\mathrm{vis}}]]$.\n\n该设计将算法建立在生存分析原则之上，在地标处强制执行延迟进入，将协变量限制在可采纳的地标前信息，并在固定时间窗内定义结果，所有这些共同防止了永生时间偏倚。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_landmark_features(subject, params):\n    \"\"\"\n    Compute landmark features and label for one subject according to specified rules.\n    subject: dict with keys:\n        'event_time': float or None (None => no event, treated as +inf)\n        'censor_time': float\n        'sbp_times': list of floats\n        'sbp_values': list of floats (same length as sbp_times)\n        'med_intervals': list of [start, end) intervals\n        'visit_times': list of floats\n    params: dict with keys:\n        'L': landmark time\n        'H': horizon\n        'W_sbp': systolic BP lookback window\n        'W_vis': visit lookback window\n        'lambda': exponential decay per day\n        'r_sbp': reference sbp\n    Returns: list [eligible_bool, label_bool, last_sbp, ewm_sbp, med_active_int, visit_count_int]\n             floats rounded to 3 decimals as specified.\n    \"\"\"\n    L = params['L']\n    H = params['H']\n    W_sbp = params['W_sbp']\n    W_vis = params['W_vis']\n    lam = params['lambda']\n    r_sbp = params['r_sbp']\n\n    T = subject['event_time']\n    C = subject['censor_time']\n    # Treat None event time as +inf\n    T_eff = np.inf if T is None else T\n    X = min(T_eff, C)\n\n    # Eligibility: event-free and uncensored strictly after L\n    eligible = (X > L) and (C > L) and (T_eff > L)\n\n    # Window bounds\n    sbp_start = L - W_sbp\n    vis_start = L - W_vis\n\n    # Filter SBP measurements within [sbp_start, L]\n    sbp_times = subject['sbp_times']\n    sbp_values = subject['sbp_values']\n    sbp_in_window_indices = [i for i, t in enumerate(sbp_times) if (t >= sbp_start and t = L)]\n    if sbp_in_window_indices:\n        # Last value carried forward: choose max t within window\n        # Determine index of max time within window\n        last_idx = max(sbp_in_window_indices, key=lambda i: sbp_times[i])\n        last_sbp = sbp_values[last_idx]\n        # Exponentially weighted mean\n        times = np.array([sbp_times[i] for i in sbp_in_window_indices], dtype=float)\n        values = np.array([sbp_values[i] for i in sbp_in_window_indices], dtype=float)\n        weights = np.exp(-lam * (L - times))\n        ewm_sbp = float(np.sum(weights * values) / np.sum(weights))\n    else:\n        last_sbp = float(r_sbp)\n        ewm_sbp = float(r_sbp)\n\n    # Medication active at L\n    med_active = 0\n    for interval in subject['med_intervals']:\n        a, b = float(interval[0]), float(interval[1])\n        if a = L  b:\n            med_active = 1\n            break\n\n    # Visit count within [vis_start, L]\n    visit_times = subject['visit_times']\n    visit_count = sum(1 for t in visit_times if (t >= vis_start and t = L))\n\n    # Label within horizon for eligible subjects: event in (L, L+H] before censoring\n    # If ineligible, set label to False by convention\n    if eligible:\n        # Event occurs if T_eff is finite and within horizon and before or at censor\n        label = (T_eff > L) and (T_eff = min(C, L + H))\n    else:\n        label = False\n\n    # Round floats to 3 decimals\n    last_sbp_rounded = round(float(last_sbp), 3)\n    ewm_sbp_rounded = round(float(ewm_sbp), 3)\n\n    return [bool(eligible), bool(label), last_sbp_rounded, ewm_sbp_rounded, int(med_active), int(visit_count)]\n\ndef solve():\n    # Define parameters from the problem statement\n    params = {\n        'L': 100.0,      # days\n        'H': 30.0,       # days\n        'W_sbp': 60.0,   # days\n        'W_vis': 90.0,   # days\n        'lambda': 0.05,  # per day\n        'r_sbp': 120.0   # mmHg\n    }\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            'event_time': 115.0,\n            'censor_time': 200.0,\n            'sbp_times': [20.0, 85.0, 95.0, 99.0],\n            'sbp_values': [130.0, 140.0, 135.0, 138.0],\n            'med_intervals': [(50.0, 120.0)],\n            'visit_times': [30.0, 70.0, 80.0, 95.0]\n        },\n        {\n            'event_time': 100.0,\n            'censor_time': 300.0,\n            'sbp_times': [40.0, 55.0, 100.0],\n            'sbp_values': [128.0, 132.0, 129.0],\n            'med_intervals': [(101.0, 200.0)],\n            'visit_times': [99.0, 100.0]\n        },\n        {\n            'event_time': None,  # No event observed\n            'censor_time': 120.0,\n            'sbp_times': [10.0, 20.0, 30.0],\n            'sbp_values': [125.0, 127.0, 126.0],\n            'med_intervals': [(0.0, 90.0)],\n            'visit_times': [5.0, 15.0, 25.0, 35.0, 45.0]\n        },\n        {\n            'event_time': 160.0,\n            'censor_time': 200.0,\n            'sbp_times': [70.0, 110.0],\n            'sbp_values': [150.0, 149.0],\n            'med_intervals': [(20.0, 80.0), (95.0, 105.0)],\n            'visit_times': [40.0, 100.0, 101.0]\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        result = compute_landmark_features(case, params)\n        results.append(result)\n\n    # Final print statement in the exact required format: single line, comma-separated list enclosed in brackets.\n    # We convert each sublist to its string representation and join them.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "4563190"}]}