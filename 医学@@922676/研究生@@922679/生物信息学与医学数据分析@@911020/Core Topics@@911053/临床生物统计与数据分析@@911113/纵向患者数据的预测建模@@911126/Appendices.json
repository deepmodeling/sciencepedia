{"hands_on_practices": [{"introduction": "在处理纵向患者数据时，我们经常关心某个关键事件（如疾病复发或死亡）发生的时间。然而，由于患者失访或研究结束，我们往往无法观测到所有人的确切事件时间，这便产生了所谓的“删失”数据。本练习将带你亲手实现 Kaplan-Meier 估计器——一种强大的非参数方法，用于从包含删失的数据中估计生存函数，这是所有生存分析和动态预测模型的基础 [@problem_id:4597912]。", "problem": "您将获得三个小型纵向患者数据集，其中包含独立右删失下的随访时间和事件指标，其中事件表示临床终点，例如死亡或疾病进展。令 $T$ 表示事件时间随机变量，其生存函数为 $S(t) = \\mathbb{P}(T \\ge t)$，右删失表示对于某些患者，未观察到确切的事件时间，但已知其超过了最后一次随访时间。假设患者是独立同分布 (IID) 的，并且删失被假定独立于事件过程。任务是基于观测到的事件时间和删失时间，构建 $S(t)$ 的非参数最大似然估计量，解释该估计量作为仅在观测到的事件时间点发生变化的右连续阶梯函数的行为，并基于大样本原理推导 $\\hat{S}(t)$ 的方差估计量。\n\n从基本定义开始：\n- 生存函数 $S(t) = \\mathbb{P}(T \\ge t)$。\n- 右删失独立于事件过程，且观测值在其观测时间之前都对风险集有贡献。\n- 离散事件时间的似然贡献由这些时间的风险集和事件计数决定。\n\n以这些为基础，构建独立右删失下生存函数的非参数乘积极限估计量，并根据恰好在每个观测事件时间之前的风险集来阐明该时间点的阶跃变化幅度。然后，使用事件时间点上独立贡献总和的渐近理论和 delta 方法，推导一个 $\\hat{S}(t)$ 的方差估计量，该估计量聚合了直到时间 $t$ 为止的所有事件时间的贡献。\n\n您的程序必须为每个数据集和一个指定的评估时间 $t^\\star$（以天为单位）计算：\n1. 估计的生存率 $\\hat{S}(t^\\star)$。\n2. 根据估计量的大样本理论推导出的方差估计 $\\widehat{\\mathrm{Var}}(\\hat{S}(t^\\star))$。\n3. 直到 $t^\\star$ 为止所有生存率下降的总幅度，定义为 $1 - \\hat{S}(t^\\star)$。\n4. 直到 $t^\\star$ 为止的最大单步幅度，定义为在不超过 $t^\\star$ 的某个事件时间点上生存函数的最大降幅。\n\n所有生存概率和方差都是无量纲量。时间值以天表示，不涉及角度单位。输出必须是数值（浮点数）。\n\n测试套件：\n- 案例 A（包含删失和结的一般混合情况）：\n  - 时间（天）：$[3, 5, 7, 7, 10, 12]$\n  - 事件指标（1 = 观测到事件，0 = 删失）：$[1, 0, 1, 1, 0, 1]$\n  - 评估时间 $t^\\star = 9$ 天\n- 案例 B（边界情况：全部删失）：\n  - 时间（天）：$[2, 4, 6, 8]$\n  - 事件指标：$[0, 0, 0, 0]$\n  - 评估时间 $t^\\star = 5$ 天\n- 案例 C（边缘情况：同一时间出现并列事件）：\n  - 时间（天）：$[1, 4, 4, 4, 5, 9]$\n  - 事件指标：$[1, 1, 1, 0, 0, 1]$\n  - 评估时间 $t^\\star = 4$ 天\n\n算法要求：\n- 按升序对唯一的事件时间进行排序。\n- 对于每个不超过 $t^\\star$ 的不同事件时间 $t_j$，计算风险集大小 $n_j$（即观测时间至少为 $t_j$ 的个体数量），以及事件计数 $d_j$（即恰好在 $t_j$ 时刻观测到的事件数量）。\n- 将 $S(t^\\star)$ 的估计量构建为在不超过 $t^\\star$ 的所有事件时间上，反映基于风险集的条件事件概率的因子的乘积。\n- 计算 $t_j$ 处的阶跃幅度，即生存函数在 $t_j$ 处的下降值，并聚合这些幅度以获得截至 $t^\\star$ 的总下降量和最大单步下降量。\n- 使用从风险集和事件计数中获得的截至 $t^\\star$ 的每个事件时间的贡献聚合，推导并实现 $\\hat{S}(t^\\star)$ 的方差估计量。如果由于事件导致风险集完全耗尽而使 $\\hat{S}(t^\\star)$ 等于零，则将方差估计设为零。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个由每个测试案例的结果列表组成的列表。每个测试案例的结果列表必须按 $[\\hat{S}(t^\\star), \\widehat{\\mathrm{Var}}(\\hat{S}(t^\\star)), 1 - \\hat{S}(t^\\star), \\max\\text{ 截至 }t^\\star\\text{ 的阶跃幅度}]$ 的顺序排列，所有值均为浮点数。整个输出必须是包含在方括号内的单个逗号分隔列表；例如，一个有效的格式是 $[[r_{1,1}, r_{1,2}, r_{1,3}, r_{1,4}], [r_{2,1}, r_{2,2}, r_{2,3}, r_{2,4}], [r_{3,1}, r_{3,2}, r_{3,3}, r_{3,4}]]$。", "solution": "该问题要求根据右删失数据构建并应用生存函数 $S(t)$ 的非参数最大似然估计量 (NPMLE)。该估计量通常被称为 Kaplan-Meier 乘积极限估计量。我们将首先推导该估计量，然后使用大样本理论推导其方差，最后将这些结果应用于给定的测试案例。\n\n设 $n$ 个独立个体的观测数据为 $\\{(t_i, \\delta_i)\\}_{i=1}^n$，其中 $t_i$ 是观测到的随访时间（事件时间或删失时间），$\\delta_i$ 是事件指示符，如果事件在 $t_i$ 发生，则 $\\delta_i=1$，如果观测值在 $t_i$ 被删失，则 $\\delta_i=0$。我们假设删失机制独立于事件过程。\n\n生存函数定义为 $S(t) = \\mathbb{P}(T \\ge t)$，其中 $T$ 是真实的事件发生时间。对于连续时间模型，在 $t_i$ 时刻观测到事件的个体的似然贡献是概率密度函数 $f(t_i)$，而在 $t_i$ 时刻被删失的个体的贡献是存活超过 $t_i$ 的概率 $S(t_i)$。总似然为 $L = \\prod_{i=1}^n [f(t_i)]^{\\delta_i} [S(t_i)]^{1-\\delta_i}$。\n\n为了非参数地最大化此似然，我们不对 $S(t)$ 的函数形式做任何假设。可以证明，NPMLE 必须是一个仅在观测到的事件时间点下降的阶梯函数。设样本中不同的、有序的事件时间为 $\\tau_1  \\tau_2  \\dots  \\tau_k$。生存函数可以表示为在存活至每个事件时间点的前提下，存活过该时间点的条件概率的乘积：\n$$\nS(t) = \\prod_{j: \\tau_j \\le t} \\mathbb{P}(T \\ge \\tau_j | T \\ge \\tau_j^-)\n$$\n其中 $\\tau_j^-$ 表示恰好在 $\\tau_j$ 之前的时间。\n\n在每个事件时间 $\\tau_j$，我们定义风险集 $R_j$ 为恰好在 $\\tau_j$ 之前仍在观察中的个体集合。该集合的大小 $n_j$ 是观测时间 $t_i \\ge \\tau_j$ 的个体数量。设 $d_j$ 为在时间 $\\tau_j$ 发生事件的个体数量。\n\n在风险集中的个体在 $\\tau_j$ 时刻经历事件的概率是风险率 $h_j$。在 $\\tau_j$ 时刻的 $d_j$ 个事件和 $n_j - d_j$ 个存活者（或删失者）可以用一个与 $h_j^{d_j} (1 - h_j)^{n_j - d_j}$ 成正比的二项似然项来建模。风险率的最大似然估计是 $\\hat{h}_j = d_j / n_j$。在风险集中的个体存活过 $\\tau_j$ 的条件概率是 $1 - h_j$。其估计值为 $1 - \\hat{h}_j = 1 - d_j/n_j = (n_j - d_j)/n_j$。\n\n将此代入乘积形式，得到 Kaplan-Meier 生存函数估计量：\n$$\n\\hat{S}(t) = \\prod_{j: \\tau_j \\le t} \\left( \\frac{n_j - d_j}{n_j} \\right)\n$$\n按照惯例，对于 $t  \\tau_1$，$\\hat{S}(t)=1$。$\\hat{S}(t)$ 是一个右连续阶梯函数。它在事件时间之间是恒定的，并且仅在观测到的事件时间 $\\tau_j$ 处下降。在 $\\tau_j$ 处的阶跃（下降）幅度由以下公式给出：\n$$\n\\text{Step}_j = \\hat{S}(\\tau_j^-) - \\hat{S}(\\tau_j) = \\hat{S}(\\tau_j^-) - \\hat{S}(\\tau_j^-) \\left( \\frac{n_j - d_j}{n_j} \\right) = \\hat{S}(\\tau_j^-) \\frac{d_j}{n_j}\n$$\n其中 $\\hat{S}(\\tau_j^-) = \\prod_{l=1}^{j-1} (n_l - d_l)/n_l$。\n\n为了估计 $\\hat{S}(t)$ 的方差，我们使用大样本理论和 delta 方法。首先求 $\\log \\hat{S}(t)$ 的方差更为方便：\n$$\n\\log \\hat{S}(t) = \\sum_{j: \\tau_j \\le t} \\log \\left(1 - \\frac{d_j}{n_j} \\right)\n$$\n假设在每个 $\\tau_j$ 处的事件数 $d_j$ 服从二项分布 $d_j \\sim \\text{Bin}(n_j, h_j)$，那么估计的风险率 $\\hat{h}_j = d_j/n_j$ 的方差为 $\\text{Var}(\\hat{h}_j) = \\frac{h_j(1-h_j)}{n_j}$。对函数 $g(x) = \\log(1-x)$（其中 $g'(x) = -1/(1-x)$）应用 delta 方法，我们得到：\n$$\n\\text{Var}(\\log(1-\\hat{h}_j)) \\approx [g'(h_j)]^2 \\text{Var}(\\hat{h}_j) = \\left(\\frac{-1}{1-h_j}\\right)^2 \\frac{h_j(1-h_j)}{n_j} = \\frac{h_j}{n_j(1-h_j)}\n$$\n代入估计值 $\\hat{h}_j = d_j/n_j$ 并假设和中的各项近似独立，对数生存率的方差估计为：\n$$\n\\widehat{\\text{Var}}(\\log \\hat{S}(t)) \\approx \\sum_{j: \\tau_j \\le t} \\frac{d_j/n_j}{n_j(1-d_j/n_j)} = \\sum_{j: \\tau_j \\le t} \\frac{d_j}{n_j(n_j - d_j)}\n$$\n为了求出 $\\hat{S}(t)$ 的方差，我们再次应用 delta 方法，这次使用的函数是 $g(x) = e^x$。因为 $\\hat{S}(t) = \\exp(\\log \\hat{S}(t))$ 并且 $g'(x) = e^x$，我们有：\n$$\n\\text{Var}(\\hat{S}(t)) \\approx [g'(\\mathbb{E}[\\log \\hat{S}(t)])]^2 \\text{Var}(\\log \\hat{S}(t)) \\approx [S(t)]^2 \\text{Var}(\\log \\hat{S}(t))\n$$\n代入估计值，我们得到用于计算 Kaplan-Meier 估计量方差的 Greenwood 公式：\n$$\n\\widehat{\\text{Var}}(\\hat{S}(t)) = [\\hat{S}(t)]^2 \\sum_{j: \\tau_j \\le t} \\frac{d_j}{n_j(n_j - d_j)}\n$$\n如果因为在 $d_j=n_j$ 时发生事件导致 $\\hat{S}(t)=0$，则从该点开始的方差被视为 $0$，如问题所述。\n\n我们现在将此框架应用于给定的测试案例。\n\n**案例 A**：时间: $[3, 5, 7, 7, 10, 12]$，事件: $[1, 0, 1, 1, 0, 1]$，$t^\\star = 9$。\n不同的事件时间为 $\\tau_1=3, \\tau_2=7, \\tau_3=12$。我们考虑 $\\le 9$ 的事件时间。\n- 在 $\\tau_1 = 3$ 时：风险集大小 $n_1=6$。事件计数 $d_1=1$。$\\hat{S}(3) = \\frac{6-1}{6} = \\frac{5}{6}$。\n- 在 $\\tau_2 = 7$ 时：风险集大小 $n_2=4$（时间为 $[7, 7, 10, 12]$ 的个体）。事件计数 $d_2=2$。\n此时间后的生存估计为 $\\hat{S}(7) = \\hat{S}(3) \\times \\frac{4-2}{4} = \\frac{5}{6} \\times \\frac{2}{4} = \\frac{5}{12}$。\n对于 $t^\\star = 9$，$\\hat{S}(9) = \\hat{S}(7) = \\frac{5}{12}$。\n\n1. $\\hat{S}(t^\\star)$: $\\frac{5}{12} \\approx 0.416667$。\n2. $\\widehat{\\text{Var}}(\\hat{S}(t^\\star))$: 求和项为 $\\frac{d_1}{n_1(n_1-d_1)} + \\frac{d_2}{n_2(n_2-d_2)} = \\frac{1}{6(5)} + \\frac{2}{4(2)} = \\frac{1}{30} + \\frac{1}{4} = \\frac{2+15}{60} = \\frac{17}{60}$。\n $\\widehat{\\text{Var}}(\\hat{S}(9)) = (\\frac{5}{12})^2 \\times \\frac{17}{60} = \\frac{25}{144} \\times \\frac{17}{60} = \\frac{425}{8640} \\approx 0.049190$。\n3. 总下降量 $1 - \\hat{S}(t^\\star)$: $1 - \\frac{5}{12} = \\frac{7}{12} \\approx 0.583333$。\n4. 最大阶跃幅度：在 $3$ 处的阶跃是 $1 - \\frac{5}{6} = \\frac{1}{6}$。在 $7$ 处的阶跃是 $\\hat{S}(3) - \\hat{S}(7) = \\frac{5}{6} - \\frac{5}{12} = \\frac{5}{12}$。最大阶跃是 $\\frac{5}{12} \\approx 0.416667$。\n\n**案例 B**：时间: $[2, 4, 6, 8]$，事件: $[0, 0, 0, 0]$，$t^\\star = 5$。\n没有事件发生。Kaplan-Meier 曲线保持在 $1$。\n1. $\\hat{S}(t^\\star)$: $1.0$。\n2. $\\widehat{\\text{Var}}(\\hat{S}(t^\\star))$: Greenwood 公式中的求和项为空，因此为 $0$。方差为 $1^2 \\times 0 = 0.0$。\n3. 总下降量 $1 - \\hat{S}(t^\\star)$: $1 - 1 = 0.0$。\n4. 最大阶跃幅度：没有阶跃，所以最大值为 $0.0$。\n\n**案例 C**：时间: $[1, 4, 4, 4, 5, 9]$，事件: $[1, 1, 1, 0, 0, 1]$，$t^\\star = 4$。\n不同的事件时间为 $\\tau_1=1, \\tau_2=4, \\tau_3=9$。我们考虑 $\\le 4$ 的事件时间。\n- 在 $\\tau_1 = 1$ 时：风险集大小 $n_1=6$。事件计数 $d_1=1$。$\\hat{S}(1) = \\frac{6-1}{6} = \\frac{5}{6}$。\n- 在 $\\tau_2 = 4$ 时：风险集大小 $n_2=5$（时间为 $[4, 4, 4, 5, 9]$ 的个体）。事件计数 $d_2=2$。\n在 $t^\\star=4$ 处的生存估计是右连续的，所以我们计算下降之后的值：$\\hat{S}(4) = \\hat{S(1)} \\times \\frac{5-2}{5} = \\frac{5}{6} \\times \\frac{3}{5} = \\frac{1}{2}$。\n\n1. $\\hat{S}(t^\\star)$: $\\frac{1}{2} = 0.5$。\n2. $\\widehat{\\text{Var}}(\\hat{S}(t^\\star))$: 求和项为 $\\frac{d_1}{n_1(n_1-d_1)} + \\frac{d_2}{n_2(n_2-d_2)} = \\frac{1}{6(5)} + \\frac{2}{5(3)} = \\frac{1}{30} + \\frac{2}{15} = \\frac{1+4}{30} = \\frac{5}{30} = \\frac{1}{6}$。\n $\\widehat{\\text{Var}}(\\hat{S}(4)) = (\\frac{1}{2})^2 \\times \\frac{1}{6} = \\frac{1}{4} \\times \\frac{1}{6} = \\frac{1}{24} \\approx 0.041667$。\n3. 总下降量 $1 - \\hat{S}(t^\\star)$: $1 - \\frac{1}{2} = \\frac{1}{2} = 0.5$。\n4. 最大阶跃幅度：在 $1$ 处的阶跃是 $1 - \\frac{5}{6} = \\frac{1}{6}$。在 $4$ 处的阶跃是 $\\hat{S}(1) - \\hat{S}(4) = \\frac{5}{6} - \\frac{1}{2} = \\frac{2}{6} = \\frac{1}{3}$。最大阶跃是 $\\frac{1}{3} \\approx 0.333333$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef kaplan_meier_analysis(times, events, t_star):\n    \"\"\"\n    Computes Kaplan-Meier survival estimates and related quantities.\n\n    Args:\n        times (list or np.ndarray): Observed follow-up times.\n        events (list or np.ndarray): Event indicators (1=event, 0=censored).\n        t_star (float): The evaluation time.\n\n    Returns:\n        tuple: A tuple containing:\n            - s_hat (float): Estimated survival probability at t_star.\n            - variance (float): Estimated variance of s_hat using Greenwood's formula.\n            - total_drop (float): 1 - s_hat.\n            - max_step (float): The largest single drop in the survival curve up to t_star.\n    \"\"\"\n    times = np.array(times)\n    events = np.array(events)\n\n    # Find unique event times in the data, sorted in ascending order.\n    # An event is where events array is 1.\n    event_times_all = np.unique(times[events == 1])\n    \n    # Filter for event times up to the evaluation time t_star\n    event_times = event_times_all[event_times_all = t_star]\n\n    s_hat = 1.0\n    s_hat_previous = 1.0\n    var_sum = 0.0\n    max_step = 0.0\n\n    if len(event_times) == 0:\n        return 1.0, 0.0, 0.0, 0.0\n\n    for tau_j in event_times:\n        # n_j: number of individuals at risk just before time tau_j\n        # This is the count of subjects whose observed time is >= tau_j.\n        n_j = np.sum(times >= tau_j)\n\n        # d_j: number of events at time tau_j\n        d_j = np.sum((times == tau_j)  (events == 1))\n\n        if n_j == 0:\n            # No one at risk, survival cannot be estimated further.\n            # This case shouldn't be reached if tau_j is a valid event time.\n            break\n\n        # Calculate hazard and update survival estimate\n        survival_factor = (n_j - d_j) / n_j\n        s_hat *= survival_factor\n\n        # Calculate the drop in survival at this step\n        step = s_hat_previous - s_hat\n        if step > max_step:\n            max_step = step\n        \n        # Update s_hat_previous for the next iteration's step calculation\n        s_hat_previous = s_hat\n        \n        # Update sum for Greenwood's formula\n        # If n_j == d_j, the risk set is depleted. s_hat becomes 0.\n        # The variance is 0 according to the problem rule.\n        # The term d_j / (n_j * (n_j - d_j)) would be a division by zero.\n        # We can break as s_hat will be 0 and thus variance will be 0.\n        if n_j - d_j == 0:\n            var_sum = 0 # Future terms are irrelevant. S_hat is 0.\n            break\n        else:\n            var_sum += d_j / (n_j * (n_j - d_j))\n\n    # Greenwood's formula for variance\n    variance = (s_hat ** 2) * var_sum\n    \n    # Total magnitude of survival drops\n    total_drop = 1.0 - s_hat\n    \n    return s_hat, variance, total_drop, max_step\n\n\ndef solve():\n    \"\"\"\n    Main function to run the test cases and print the results.\n    \"\"\"\n    test_cases = [\n        # Case A (general mixed case with censoring and ties)\n        {'times': [3, 5, 7, 7, 10, 12], 'events': [1, 0, 1, 1, 0, 1], 't_star': 9},\n        # Case B (boundary case: all censored)\n        {'times': [2, 4, 6, 8], 'events': [0, 0, 0, 0], 't_star': 5},\n        # Case C (edge case: tied events at the same time)\n        {'times': [1, 4, 4, 4, 5, 9], 'events': [1, 1, 1, 0, 0, 1], 't_star': 4}\n    ]\n\n    all_results = []\n    for case in test_cases:\n        result = kaplan_meier_analysis(case['times'], case['events'], case['t_star'])\n        # Format each individual result as a list of floats\n        all_results.append(list(result))\n\n    # Format the final output string exactly as required\n    # e.g., [[r1, r2, r3, r4], [r5, r6, r7, r8], ...]\n    result_str = \"[\" + \", \".join([f\"[{', '.join(map(str, res))}]\" for res in all_results]) + \"]\"\n\n    print(result_str)\n\nsolve()\n```", "id": "4597912"}, {"introduction": "理解患者的生物标志物（biomarker）如何随时间变化，对于进行个体化预测至关重要。本练习将引导你运用贝叶斯线性回归，为每位患者构建个性化的 biomarker 轨迹模型。通过这个实践，你将学会如何结合先验知识与患者的具体观测数据，来估计其 biomarker 的变化速率，并对未来的数值进行带有不确定性量化（可信区间）的预测 [@problem_id:4597855]。", "problem": "您将执行一项基于共轭贝叶斯线性回归的纵向生物标志物建模任务，用于建立患者特异性轨迹。对于每个患者索引 $i$，观测数据包括以天为单位测量的时间点 $\\{t_{ij}\\}_{j=1}^{n_i}$ 和以毫克/分升 (mg/dL) 为单位测量的相应生物标志物值 $\\{y_{ij}\\}_{j=1}^{n_i}$。假设存在以下生成模型：对于每个患者 $i$，存在一个患者特异性截距 $a_i$ 和斜率 $b_i$，使得观测模型为\n$$\ny_{ij} = a_i + b_i\\, t_{ij} + \\varepsilon_{ij}, \\quad \\varepsilon_{ij} \\sim \\mathcal{N}(0,\\sigma^2),\n$$\n其中 $\\sigma^2$ 是已知的，并且在所有患者之间共享。设患者特异性参数的联合先验为高斯分布，\n$$\n\\begin{bmatrix} a_i \\\\ b_i \\end{bmatrix} \\sim \\mathcal{N}\\!\\left( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} \\right),\n$$\n其先验均值向量 $\\boldsymbol{\\mu} \\in \\mathbb{R}^2$ 和协方差矩阵 $\\boldsymbol{\\Sigma} \\in \\mathbb{R}^{2 \\times 2}$ 是已知的，并且在所有患者之间共享。\n\n您的任务是使用此模型为每位患者计算：\n- 患者特异性斜率 $b_i$ 的后验均值（平方误差损失下的贝叶斯估计量），单位为 mg/dL/天。\n- 对于一组给定的未来时间点 $\\{t^\\ast_{ik}\\}_{k=1}^{m_i}$，计算生物标志物的后验预测均值，以及在指定覆盖水平 $\\alpha$ 下，每个 $t^\\ast_{ik}$ 的对称中心可信区间。区间端点必须以 mg/dL 为单位报告。可信区间必须通过高斯分布的对称中心区间映射得到，使用以小数表示的分位数（例如，$\\alpha = 0.95$ 使用位于 $0.025$ 和 $0.975$ 的下分位数和上分位数）。不得使用百分号。\n\n在您的推导和算法设计中，请使用以下基本原理：\n- 具有同方差噪声的线性回归的高斯似然定义。\n- 正态先验对于线性模型的共轭性。\n- 多元高斯分布中的条件化和边缘化规则。\n- 在正态-正态模型下，预测分布是高斯分布，其均值和方差通过对参数的后验分布进行积分得到。\n\n请基于这些原理设计您的算法。不要依赖任何其他未引入的“捷径”公式。\n\n在所有患者中使用以下全局共享的超参数：\n- 先验均值 $\\boldsymbol{\\mu} = \\begin{bmatrix} 95.0 \\\\ 0.05 \\end{bmatrix}$ (单位：截距为 mg/dL，斜率为 mg/dL/天)。\n- 先验协方差 $\\boldsymbol{\\Sigma} = \\begin{bmatrix} 100.0  0.0 \\\\ 0.0  0.01 \\end{bmatrix}$。\n- 观测噪声方差 $\\sigma^2 = 4.0$ (单位：$(\\text{mg/dL})^2$）。\n\n测试套件。将您的程序应用于以下三位患者，每位患者都有其自身的纵向观测数据、要求的未来预测时间以及可信区间覆盖水平 $\\alpha$：\n- 案例 1 (正常路径)：\n  - 观测时间 (天)：$[\\,0,\\,30,\\,60,\\,90\\,]$\n  - 观测生物标志物 (mg/dL)：$[\\,100,\\,103,\\,107,\\,112\\,]$\n  - 未来时间 (天)：$[\\,120,\\,180\\,]$\n  - 覆盖水平 $\\alpha = 0.95$\n- 案例 2 (边界：单个观测值)：\n  - 观测时间 (天)：$[\\,0\\,]$\n  - 观测生物标志物 (mg/dL)：$[\\,80\\,]$\n  - 未来时间 (天)：$[\\,30,\\,60,\\,90\\,]$\n  - 覆盖水平 $\\alpha = 0.95$\n- 案例 3 (含噪声的轨迹和不同的覆盖率)：\n  - 观测时间 (天)：$[\\,0,\\,10,\\,20,\\,30,\\,40\\,]$\n  - 观测生物标志物 (mg/dL)：$[\\,50,\\,49,\\,53,\\,47,\\,52\\,]$\n  - 未来时间 (天)：$[\\,50,\\,100\\,]$\n  - 覆盖水平 $\\alpha = 0.90$\n\n最终输出格式。您的程序必须生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。对于按给定顺序排列的每个案例 $i$ ($i=1,2,3$)，按顺序附加以下数字：\n- $b_i$ 的后验均值 (mg/dL/天)，四舍五入到六位小数。\n- 对于按指定顺序排列的每个未来时间 $t^\\ast_{ik}$，附加预测均值 (mg/dL)、在覆盖水平 $\\alpha$ 下的对称中心可信区间的下端点 (mg/dL) 和上端点 (mg/dL)，均四舍五入到六位小数。\n\n因此，最终打印的输出是一个浮点数列表，格式为 $[\\,\\text{案例 1 斜率},\\,\\text{案例 1 在第一个未来时间的预测均值},\\,\\text{案例 1 下界},\\,\\text{案例 1 上界},\\,\\ldots,\\,\\text{案例 3 上界}\\,]$，不含任何额外文本。本问题不使用角度，因此不需要角度单位。所有物理单位均如上所述；报告的所有数字都应为无量纲的浮点数，代表在这些单位下的值。", "solution": "该问题要求应用贝叶斯线性回归来为患者特异性生物标志物轨迹建模。对于每个患者 $i$，我们给定了一个生成模型，我们的目标是计算模型参数的后验分布，并随后计算未来生物标志物值的后验预测分布。解法将按照规定从第一性原理推导得出。\n\n令患者特异性参数为截距 $a_i$ 和斜率 $b_i$，并将其收集到一个向量 $\\boldsymbol{\\theta}_i = [a_i, b_i]^\\top$ 中。患者 $i$ 的观测数据由 $n_i$ 对时间点 $\\{t_{ij}\\}_{j=1}^{n_i}$ 和生物标志物值 $\\{y_{ij}\\}_{j=1}^{n_i}$ 组成。\n\n观测模型由 $y_{ij} = a_i + b_i t_{ij} + \\varepsilon_{ij}$ 给出，其中噪声 $\\varepsilon_{ij} \\sim \\mathcal{N}(0, \\sigma^2)$。我们可以将患者的所有观测值表示为矩阵形式。令 $\\mathbf{y}_i = [y_{i1}, \\dots, y_{in_i}]^\\top$ 为生物标志物观测值的向量，$\\mathbf{X}_i$ 为 $n_i \\times 2$ 的设计矩阵：\n$$\n\\mathbf{X}_i = \\begin{bmatrix} 1  t_{i1} \\\\ 1  t_{i2} \\\\ \\vdots  \\vdots \\\\ 1  t_{in_i} \\end{bmatrix}\n$$\n观测向量 $\\mathbf{y}_i$ 的模型则为 $\\mathbf{y}_i = \\mathbf{X}_i \\boldsymbol{\\theta}_i + \\boldsymbol{\\varepsilon}_i$，其中 $\\boldsymbol{\\varepsilon}_i \\sim \\mathcal{N}(\\mathbf{0}, \\sigma^2 \\mathbf{I}_{n_i})$。这定义了给定数据 $\\mathcal{D}_i = \\{\\mathbf{y}_i, \\mathbf{X}_i\\}$ 时 $\\boldsymbol{\\theta}_i$ 的似然函数：\n$$\np(\\mathbf{y}_i | \\boldsymbol{\\theta}_i, \\sigma^2) = \\mathcal{N}(\\mathbf{y}_i | \\mathbf{X}_i \\boldsymbol{\\theta}_i, \\sigma^2 \\mathbf{I}_{n_i}) \\propto \\exp\\left( -\\frac{1}{2\\sigma^2} (\\mathbf{y}_i - \\mathbf{X}_i \\boldsymbol{\\theta}_i)^\\top (\\mathbf{y}_i - \\mathbf{X}_i \\boldsymbol{\\theta}_i) \\right)\n$$\n参数的先验分布为多元高斯分布：\n$$\np(\\boldsymbol{\\theta}_i) = \\mathcal{N}(\\boldsymbol{\\theta}_i | \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma}) \\propto \\exp\\left( -\\frac{1}{2} (\\boldsymbol{\\theta}_i - \\boldsymbol{\\mu})^\\top \\boldsymbol{\\Sigma}^{-1} (\\boldsymbol{\\theta}_i - \\boldsymbol{\\mu}) \\right)\n$$\n其中 $\\boldsymbol{\\mu}$ 和 $\\boldsymbol{\\Sigma}$ 分别是先验均值和协方差。\n\n**1. 参数的后验分布**\n\n参数 $\\boldsymbol{\\theta}_i$ 的后验分布通过贝叶斯定理获得：$p(\\boldsymbol{\\theta}_i | \\mathcal{D}_i) \\propto p(\\mathbf{y}_i | \\boldsymbol{\\theta}_i) p(\\boldsymbol{\\theta}_i)$。由于似然和先验都是高斯分布，后验分布也是高斯分布，这一性质称为共轭性。我们将后验分布表示为 $p(\\boldsymbol{\\theta}_i | \\mathcal{D}_i) = \\mathcal{N}(\\boldsymbol{\\theta}_i | \\boldsymbol{\\mu}_{\\text{post}}, \\boldsymbol{\\Sigma}_{\\text{post}})$。\n\n为了求得后验参数 $\\boldsymbol{\\mu}_{\\text{post}}$ 和 $\\boldsymbol{\\Sigma}_{\\text{post}}$，我们分析后验分布的指数部分，它是似然和先验指数部分之和（忽略常数项）：\n$$\n-\\frac{1}{2} \\left[ (\\boldsymbol{\\theta}_i - \\boldsymbol{\\mu})^\\top \\boldsymbol{\\Sigma}^{-1} (\\boldsymbol{\\theta}_i - \\boldsymbol{\\mu}) + \\frac{1}{\\sigma^2} (\\mathbf{y}_i - \\mathbf{X}_i \\boldsymbol{\\theta}_i)^\\top (\\mathbf{y}_i - \\mathbf{X}_i \\boldsymbol{\\theta}_i) \\right]\n$$\n通过展开二次型并收集包含 $\\boldsymbol{\\theta}_i$ 的项，我们可以通过配方法来确定后验均值和协方差。$\\boldsymbol{\\theta}_i$ 的二次项为：\n$$\n\\boldsymbol{\\theta}_i^\\top \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{\\theta}_i + \\frac{1}{\\sigma^2} \\boldsymbol{\\theta}_i^\\top \\mathbf{X}_i^\\top \\mathbf{X}_i \\boldsymbol{\\theta}_i = \\boldsymbol{\\theta}_i^\\top \\left( \\boldsymbol{\\Sigma}^{-1} + \\frac{1}{\\sigma^2} \\mathbf{X}_i^\\top \\mathbf{X}_i \\right) \\boldsymbol{\\theta}_i\n$$\n由此，我们确定后验协方差矩阵的逆（即后验精度）：\n$$\n\\boldsymbol{\\Sigma}_{\\text{post}}^{-1} = \\boldsymbol{\\Sigma}^{-1} + \\frac{1}{\\sigma^2} \\mathbf{X}_i^\\top \\mathbf{X}_i\n$$\n因此，后验协方差矩阵为：\n$$\n\\boldsymbol{\\Sigma}_{\\text{post}} = \\left( \\boldsymbol{\\Sigma}^{-1} + \\frac{1}{\\sigma^2} \\mathbf{X}_i^\\top \\mathbf{X}_i \\right)^{-1}\n$$\n$\\boldsymbol{\\theta}_i$ 的一次项为：\n$$\n-2 \\boldsymbol{\\mu}^\\top \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{\\theta}_i - \\frac{2}{\\sigma^2} \\mathbf{y}_i^\\top \\mathbf{X}_i \\boldsymbol{\\theta}_i = -2 \\left( \\boldsymbol{\\mu}^\\top \\boldsymbol{\\Sigma}^{-1} + \\frac{1}{\\sigma^2} \\mathbf{y}_i^\\top \\mathbf{X}_i \\right) \\boldsymbol{\\theta}_i\n$$\n将其与一般高斯形式中的一次项 $-2\\boldsymbol{\\mu}_{\\text{post}}^\\top \\boldsymbol{\\Sigma}_{\\text{post}}^{-1} \\boldsymbol{\\theta}_i$ 进行比较，我们得到：\n$$\n\\boldsymbol{\\mu}_{\\text{post}}^\\top \\boldsymbol{\\Sigma}_{\\text{post}}^{-1} = \\boldsymbol{\\mu}^\\top \\boldsymbol{\\Sigma}^{-1} + \\frac{1}{\\sigma^2} \\mathbf{y}_i^\\top \\mathbf{X}_i\n$$\n转置并求解 $\\boldsymbol{\\mu}_{\\text{post}}$，我们得到后验均值：\n$$\n\\boldsymbol{\\mu}_{\\text{post}} = \\boldsymbol{\\Sigma}_{\\text{post}} \\left( \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{\\mu} + \\frac{1}{\\sigma^2} \\mathbf{X}_i^\\top \\mathbf{y}_i \\right)\n$$\n斜率的后验均值 $\\mathbb{E}[b_i | \\mathcal{D}_i]$ 是向量 $\\boldsymbol{\\mu}_{\\text{post}}$ 的第二个分量。\n\n**2. 后验预测分布**\n\n对于一个新的时间点 $t^\\ast$，我们希望预测相应的生物标志物值 $y^\\ast$。这个新数据点的模型是 $y^\\ast = \\mathbf{x}^{\\ast \\top} \\boldsymbol{\\theta}_i + \\varepsilon^\\ast$，其中 $\\mathbf{x}^\\ast = [1, t^\\ast]^\\top$ 且 $\\varepsilon^\\ast \\sim \\mathcal{N}(0, \\sigma^2)$。\n\n后验预测分布是通过将模型参数在其后验分布上进行边缘化（积分）得到的：\n$$\np(y^\\ast | \\mathcal{D}_i) = \\int p(y^\\ast | \\boldsymbol{\\theta}_i) p(\\boldsymbol{\\theta}_i | \\mathcal{D}_i) d\\boldsymbol{\\theta}_i\n$$\n这是一个关于两个高斯分布乘积的积分，其结果是另一个高斯分布。我们可以求出其均值和方差。\n\n后验预测均值使用全期望定律求得：\n$$\n\\mu_{\\text{pred}} = \\mathbb{E}[y^\\ast | \\mathcal{D}_i] = \\mathbb{E}_{\\boldsymbol{\\theta}_i | \\mathcal{D}_i} \\left[ \\mathbb{E}[y^\\ast | \\boldsymbol{\\theta}_i, \\mathcal{D}_i] \\right] = \\mathbb{E}_{\\boldsymbol{\\theta}_i | \\mathcal{D}_i} \\left[ \\mathbf{x}^{\\ast \\top} \\boldsymbol{\\theta}_i \\right] = \\mathbf{x}^{\\ast \\top} \\mathbb{E}[\\boldsymbol{\\theta}_i | \\mathcal{D}_i] = \\mathbf{x}^{\\ast \\top} \\boldsymbol{\\mu}_{\\text{post}}\n$$\n后验预测方差使用全方差定律求得：\n$$\n\\sigma^2_{\\text{pred}} = \\text{Var}(y^\\ast | \\mathcal{D}_i) = \\mathbb{E}_{\\boldsymbol{\\theta}_i | \\mathcal{D}_i} \\left[ \\text{Var}(y^\\ast | \\boldsymbol{\\theta}_i, \\mathcal{D}_i) \\right] + \\text{Var}_{\\boldsymbol{\\theta}_i | \\mathcal{D}_i} \\left( \\mathbb{E}[y^\\ast | \\boldsymbol{\\theta}_i, \\mathcal{D}_i] \\right)\n$$\n第一项是期望观测方差：$\\mathbb{E}[\\sigma^2] = \\sigma^2$。第二项是由于参数 $\\boldsymbol{\\theta}_i$ 的不确定性而导致的均值预测的方差：$\\text{Var}(\\mathbf{x}^{\\ast \\top} \\boldsymbol{\\theta}_i | \\mathcal{D}_i) = \\mathbf{x}^{\\ast \\top} \\text{Var}(\\boldsymbol{\\theta}_i | \\mathcal{D}_i) \\mathbf{x}^\\ast = \\mathbf{x}^{\\ast \\top} \\boldsymbol{\\Sigma}_{\\text{post}} \\mathbf{x}^\\ast$。\n将这两项结合起来，后验预测方差为：\n$$\n\\sigma^2_{\\text{pred}} = \\sigma^2 + \\mathbf{x}^{\\ast \\top} \\boldsymbol{\\Sigma}_{\\text{post}} \\mathbf{x}^\\ast\n$$\n因此，后验预测分布为 $p(y^\\ast | \\mathcal{D}_i) = \\mathcal{N}(y^\\ast | \\mu_{\\text{pred}}, \\sigma^2_{\\text{pred}})$。\n\n**3. 可信区间**\n\n对于 $y^\\ast$，一个覆盖水平为 $\\alpha$ 的对称中心可信区间是根据其高斯后验预测分布的分位数构建的。令 $z_q$ 为标准正态分布 $\\mathcal{N}(0, 1)$ 的第 $q$ 个分位数。该区间的下界和上界为：\n$$\n\\text{下界} = \\mu_{\\text{pred}} + z_{(1-\\alpha)/2} \\sqrt{\\sigma^2_{\\text{pred}}} = \\mu_{\\text{pred}} - z_{(1+\\alpha)/2} \\sqrt{\\sigma^2_{\\text{pred}}}\n$$\n$$\n\\text{上界} = \\mu_{\\text{pred}} + z_{(1+\\alpha)/2} \\sqrt{\\sigma^2_{\\text{pred}}}\n$$\n分位数 $z_{(1+\\alpha)/2}$ 是使用标准正态分布的逆累积分布函数（也称为百分点函数）计算的。\n\n该算法通过对每个患者案例应用这些公式，并使用所提供的数据和超参数来执行。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Solves the Bayesian linear regression problem for multiple patient cases.\n    \"\"\"\n    # Define globally shared hyperparameters\n    mu_prior = np.array([95.0, 0.05])\n    Sigma_prior = np.array([[100.0, 0.0], [0.0, 0.01]])\n    sigma2 = 4.0\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (happy path)\n        {\n            \"t_obs\": np.array([0.0, 30.0, 60.0, 90.0]),\n            \"y_obs\": np.array([100.0, 103.0, 107.0, 112.0]),\n            \"t_future\": np.array([120.0, 180.0]),\n            \"alpha\": 0.95\n        },\n        # Case 2 (boundary: single observation)\n        {\n            \"t_obs\": np.array([0.0]),\n            \"y_obs\": np.array([80.0]),\n            \"t_future\": np.array([30.0, 60.0, 90.0]),\n            \"alpha\": 0.95\n        },\n        # Case 3 (noisy trajectory and different coverage)\n        {\n            \"t_obs\": np.array([0.0, 10.0, 20.0, 30.0, 40.0]),\n            \"y_obs\": np.array([50.0, 49.0, 53.0, 47.0, 52.0]),\n            \"t_future\": np.array([50.0, 100.0]),\n            \"alpha\": 0.90\n        }\n    ]\n\n    results = []\n    \n    # Pre-compute the prior precision matrix\n    Sigma_prior_inv = np.linalg.inv(Sigma_prior)\n    \n    for case in test_cases:\n        t_obs = case[\"t_obs\"]\n        y_obs = case[\"y_obs\"]\n        t_future = case[\"t_future\"]\n        alpha = case[\"alpha\"]\n        \n        # Construct design matrix X for observed data\n        X_obs = np.vstack([np.ones(len(t_obs)), t_obs]).T\n        \n        # Calculate posterior distribution parameters\n        # Posterior precision: Sigma_post_inv = Sigma_prior_inv + (1/sigma2) * X_obs.T @ X_obs\n        Sigma_post_inv = Sigma_prior_inv + (1.0 / sigma2) * (X_obs.T @ X_obs)\n        # Posterior covariance\n        Sigma_post = np.linalg.inv(Sigma_post_inv)\n        # Posterior mean\n        mu_post = Sigma_post @ (Sigma_prior_inv @ mu_prior + (1.0 / sigma2) * (X_obs.T @ y_obs))\n        \n        # Task 1: Find the posterior mean of the slope b_i\n        posterior_b_mean = mu_post[1]\n        results.append(round(posterior_b_mean, 6))\n        \n        # Task 2: Compute posterior predictive means and credible intervals\n        # Get the z-score corresponding to the coverage level alpha\n        z_score = norm.ppf((1.0 + alpha) / 2.0)\n        \n        for t_star in t_future:\n            # Construct design vector for the future time point\n            x_star = np.array([1.0, t_star])\n            \n            # Posterior predictive mean\n            pred_mean = x_star.T @ mu_post\n            \n            # Posterior predictive variance is the sum of two components:\n            # 1. Variance from the observation noise (sigma2)\n            # 2. Variance from the uncertainty in the posterior of the parameters\n            pred_var = sigma2 + x_star.T @ Sigma_post @ x_star\n            pred_std = np.sqrt(pred_var)\n            \n            # Calculate the symmetric central credible interval\n            margin_of_error = z_score * pred_std\n            lower_bound = pred_mean - margin_of_error\n            upper_bound = pred_mean + margin_of_error\n            \n            results.append(round(pred_mean, 6))\n            results.append(round(lower_bound, 6))\n            results.append(round(upper_bound, 6))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "4597855"}, {"introduction": "纵向预测建模的最终目标之一，是将随时间变化的患者指标（如 biomarker）与临床事件的风险联系起来。本练习将带你进入联合模型的领域，通过实现一个含时依协变量的 Cox 比例风险模型，来量化 biomarker 当前水平对瞬时事件风险的影响。你将通过最大化部分似然函数来估计关键的关联参数 $\\eta$，从而揭示 biomarker 动态变化与患者预后之间的深刻联系 [@problem_id:4597903]。", "problem": "给定一个联合建模中的典型场景，其中一个纵向生物标志物轨迹通过Cox比例风险（Cox Proportional Hazards, CPH）结构与临床事件的瞬时风险相关联。目标是估计关联参数 $\\,\\eta\\,$，该参数量化了生物标志物的当前水平如何影响风险率。估计必须使用由含时变协变量的CPH模型导出的偏似然（partial likelihood）进行，并使用Breslow近似处理事件时间平局（tied event times）。\n\n基本原理：\n- Cox比例风险（CPH）模型将个体风险率定义为\n$$\nh_i(t) \\;=\\; h_0(t)\\,\\exp\\!\\big(\\eta\\,m_i(t)\\big),\n$$\n其中 $\\,h_0(t)\\,$ 是一个未指明的基线风险率，$\\,m_i(t)\\,$ 是个体 $\\,i\\,$ 在时间 $\\,t\\,$ 的当前生物标志物水平，而 $\\,\\eta\\,$ 是待估计的关联参数。\n- 用于估计 $\\,\\eta\\,$ 的偏似然使用事件时间和风险集，并且不需要指定 $\\,h_0(t)\\,$。事件时间平局必须通过Breslow近似来处理。\n\n生物标志物轨迹表示：\n- 每个受试者 $\\,i\\,$ 在时间 $\\,t_{i0}\\,$ 和 $\\,t_{i1}\\,$ 有两个观测到的生物标志物测量值，分别为 $\\,m_{i0}\\,$ 和 $\\,m_{i1}\\,$。在任何时间 $\\,t\\,$ 的当前生物标志物水平被假定在两个观测点之间遵循线性轨迹：\n$$\nm_i(t) \\;=\\; m_{i0} + (m_{i1}-m_{i0})\\;\\frac{t - t_{i0}}{t_{i1}-t_{i0}}.\n$$\n\n数据元素与构造规则：\n- 对于每个测试案例，受试者由生存时间向量 $\\,T_i\\,$（单位：天）、事件指示符 $\\,\\delta_i \\in \\{0,1\\}\\,$、生物标志物测量时间 $\\,\\{t_{i0},t_{i1}\\}\\,$（单位：天）和生物标志物值 $\\,\\{m_{i0},m_{i1}\\}\\,$ 定义。\n- 事件时间 $\\,\\{t_k\\}\\,$ 是指至少发生一个事件的独立时间点。在每个事件时间 $\\,t_k\\,$，定义事件集 $\\,D_k \\,=\\, \\{\\,i : \\delta_i=1,\\,T_i = t_k\\,\\}\\,$ 和风险集 $\\,R_k \\,=\\, \\{\\,i : T_i \\ge t_k \\,\\}\\,$。\n- 在每个事件时间 $\\,t_k\\,$，通过在两次测量时间之间进行线性插值来为所有 $\\,i\\in R_k\\,$ 计算 $\\,m_i(t_k)\\,$。在提供的案例中，不会出现在 $\\,\\min(t_{i0},t_{i1})\\,$ 到 $\\,\\max(t_{i0},t_{i1})\\,$ 范围之外的外推。\n\n估计目标：\n- 使用数值稳定的方法最大化关于 $\\,\\eta\\,$ 的Breslow偏似然。你必须实现一个带有回溯线搜索的Newton–Raphson过程，并在Hessian矩阵接近奇异或Newton更新未能改善目标函数时，回退到有界标量最大化方法。\n- 如果在所有事件时间 $\\,t_k\\,$，风险集 $\\,R_k\\,$ 中所有个体的生物标志物水平 $\\,\\{m_i(t_k) : i \\in R_k\\}\\,$ 都相等（导致风险集中的方差为零），那么偏似然函数对于 $\\,\\eta\\,$ 是平坦的；在这种情况下，返回 $\\,0.0\\,$。\n\n单位：\n- 时间必须以天为单位处理。关联参数 $\\,\\eta\\,$ 是无量纲的。你的程序必须输出四舍五入到三位小数的 $\\,\\eta\\,$。\n\n测试套件：\n- 案例A（正相关，理想路径）：\n  - 受试者：$\\,N=6\\,$。\n  - 生存时间（天）：$\\,T = [\\,3,\\,5,\\,7,\\,12,\\,12,\\,12\\,]\\,$。\n  - 事件指示符：$\\,\\delta = [\\,1,\\,1,\\,1,\\,0,\\,0,\\,0\\,]\\,$。\n  - 生物标志物测量时间（天）：对所有受试者，$\\,t_{i0}=0\\,$, $\\,t_{i1}=10\\,$。\n  - 生物标志物值：\n    - 受试者 $\\,1$：$\\,m_{10}=3.0\\,$, $\\,m_{11}=5.0\\,$。\n    - 受试者 $\\,2$：$\\,m_{20}=2.8\\,$, $\\,m_{21}=4.3\\,$。\n    - 受试者 $\\,3$：$\\,m_{30}=2.5\\,$, $\\,m_{31}=3.5\\,$。\n    - 受试者 $\\,4$：$\\,m_{40}=1.5\\,$, $\\,m_{41}=2.0\\,$。\n    - 受试者 $\\,5$：$\\,m_{50}=1.0\\,$, $\\,m_{51}=2.0\\,$。\n    - 受试者 $\\,6$：$\\,m_{60}=0.8\\,$, $\\,m_{61}=1.3\\,$。\n- 案例B（负相关）：\n  - 受试者：$\\,N=6\\,$。\n  - 生存时间（天）：$\\,T = [\\,3,\\,5,\\,7,\\,12,\\,12,\\,12\\,]\\,$。\n  - 事件指示符：$\\,\\delta = [\\,1,\\,1,\\,1,\\,0,\\,0,\\,0\\,]\\,$。\n  - 生物标志物测量时间（天）：对所有受试者，$\\,t_{i0}=0\\,$, $\\,t_{i1}=10\\,$。\n  - 生物标志物值：\n    - 受试者 $\\,1$：$\\,m_{10}=0.5\\,$, $\\,m_{11}=0.5\\,$。\n    - 受试者 $\\,2$：$\\,m_{20}=0.7\\,$, $\\,m_{21}=1.2\\,$。\n    - 受试者 $\\,3$：$\\,m_{30}=0.8\\,$, $\\,m_{31}=1.3\\,$。\n    - 受试者 $\\,4$：$\\,m_{40}=2.5\\,$, $\\,m_{41}=3.5\\,$。\n    - 受试者 $\\,5$：$\\,m_{50}=2.8\\,$, $\\,m_{51}=4.3\\,$。\n    - 受试者 $\\,6$：$\\,m_{60}=3.0\\,$, $\\,m_{61}=5.0\\,$。\n- 案例C（无关联；平坦似然）：\n  - 受试者：$\\,N=6\\,$。\n  - 生存时间（天）：$\\,T = [\\,3,\\,5,\\,7,\\,12,\\,12,\\,12\\,]\\,$。\n  - 事件指示符：$\\,\\delta = [\\,1,\\,1,\\,1,\\,0,\\,0,\\,0\\,]\\,$。\n  - 生物标志物测量时间（天）：对所有受试者，$\\,t_{i0}=0\\,$, $\\,t_{i1}=10\\,$。\n  - 生物标志物值：对所有受试者，$\\,m_{i0}=2.0\\,$ 和 $\\,m_{i1}=2.0\\,$。\n- 案例D（平局；Breslow处理）：\n  - 受试者：$\\,N=5\\,$。\n  - 生存时间（天）：$\\,T = [\\,4,\\,4,\\,6,\\,8,\\,8\\,]\\,$。\n  - 事件指示符：$\\,\\delta = [\\,1,\\,1,\\,1,\\,0,\\,0\\,]\\,$。\n  - 生物标志物测量时间（天）：对所有受试者，$\\,t_{i0}=0\\,$, $\\,t_{i1}=8\\,$。\n  - 生物标志物值：\n    - 受试者 $\\,1$：$\\,m_{10}=2.5\\,$, $\\,m_{11}=3.5\\,$。\n    - 受试者 $\\,2$：$\\,m_{20}=2.3\\,$, $\\,m_{21}=3.3\\,$。\n    - 受试者 $\\,3$：$\\,m_{30}=1.7\\,$, $\\,m_{31}=2.1\\,$。\n    - 受试者 $\\,4$：$\\,m_{40}=1.5\\,$, $\\,m_{41}=1.9\\,$。\n    - 受试者 $\\,5$：$\\,m_{50}=1.2\\,$, $\\,m_{51}=1.6\\,$。\n\n算法要求：\n- 构建 $\\,\\{(t_k, D_k, R_k)\\}\\,$ 并通过线性插值计算 $\\,m_i(t_k)\\,$。\n- 为关于 $\\,\\eta\\,$ 的Breslow偏对数似然实现一个带有回溯线搜索和Hessian矩阵岭稳定化的Newton–Raphson优化器。如果Hessian矩阵的量级低于一个小阈值或更新未能增加目标函数值，则回退到在 $\\,[-5,5]\\,$ 区间内的有界标量最大化方法。\n- 收敛准则：当绝对更新量低于 $\\,10^{-6}\\,$ 且梯度量级低于 $\\,10^{-6}\\,$ 时，或达到最大迭代次数 $\\,50\\,$ 次时终止。\n\n输出规格：\n- 你的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表，每个 $\\,\\eta\\,$ 值四舍五入到三位小数，顺序为 $\\,[$案例A, 案例B, 案例C, 案例D$]$。\n\n答案必须是无量纲的（没有物理单位），并四舍五入到三位小数。不应打印其他任何文本。", "solution": "该问题要求在一个时变Cox比例风险（CPH）模型中估计关联参数 $\\eta$。该模型将一个纵向生物标志物轨迹与临床事件的瞬时风险联系起来。该估计通过使用Newton-Raphson算法最大化Breslow偏似然来完成。\n\n### 1. 模型与似然公式\n\n对于个体 $i$ 在时间 $t$ 的风险函数由CPH模型给出：\n$$\nh_i(t) = h_0(t)\\,\\exp(\\eta\\,m_i(t))\n$$\n其中 $h_0(t)$ 是未指定的基线风险， $m_i(t)$ 是个体 $i$ 在时间 $t$ 的时变生物标志物的值，而 $\\eta$ 是待估计的关联参数。\n\n生物标志物轨迹 $m_i(t)$ 通过在两个观测测量值 $(t_{i0}, m_{i0})$ 和 $(t_{i1}, m_{i1})$ 之间进行线性插值来确定：\n$$\nm_i(t) = m_{i0} + (m_{i1} - m_{i0}) \\frac{t - t_{i0}}{t_{i1} - t_{i0}}\n$$\n\n为了在不指定 $h_0(t)$ 的情况下估计 $\\eta$，我们使用偏似然。设独立的有序事件时间为 $t_1  t_2  \\dots  t_K$。在每个事件时间 $t_k$，我们定义发生事件的个体集合为 $D_k = \\{i : \\delta_i=1, T_i = t_k\\}$，其大小为 $d_k = |D_k|$。处于风险中的个体集合为 $R_k = \\{i : T_i \\ge t_k\\}$。\n\n为了处理事件时间平局（即 $d_k > 1$），问题指定使用Breslow近似来处理偏似然。我们旨在最大化的结果，即对数偏似然函数 $\\ell(\\eta)$ 为：\n$$\n\\ell(\\eta) = \\sum_{k=1}^K \\left[ \\eta \\sum_{j \\in D_k} m_j(t_k) - d_k \\log\\left(\\sum_{i \\in R_k} \\exp(\\eta m_i(t_k))\\right) \\right]\n$$\n该函数对于 $\\eta$ 是凹函数，这简化了最大化过程。\n\n### 2. 通过Newton-Raphson进行优化\n\n我们采用Newton-Raphson方法，这是一种迭代下降算法，来找到使 $\\ell(\\eta)$ 最大化的 $\\eta$ 值。这需要对数似然函数的一阶和二阶导数。\n\n让我们定义在事件时间 $t_k$ 的风险集 $R_k$ 上的以下求和：\n$$\nS_k^{(p)}(\\eta) = \\sum_{i \\in R_k} m_i(t_k)^p \\exp(\\eta \\, m_i(t_k)) \\quad \\text{for } p \\in \\{0, 1, 2\\}\n$$\n\n$\\ell(\\eta)$ 的一阶导数，即得分函数 $U(\\eta)$，为：\n$$\nU(\\eta) = \\frac{\\partial \\ell}{\\partial \\eta} = \\sum_{k=1}^K \\left[ \\sum_{j \\in D_k} m_j(t_k) - d_k \\frac{S_k^{(1)}(\\eta)}{S_k^{(0)}(\\eta)} \\right]\n$$\n\n二阶导数，即Hessian矩阵 $H(\\eta)$（在这个单参数案例中为标量），为：\n$$\nH(\\eta) = \\frac{\\partial^2 \\ell}{\\partial \\eta^2} = \\sum_{k=1}^K -d_k \\left[ \\frac{S_k^{(2)}(\\eta)}{S_k^{(0)}(\\eta)} - \\left(\\frac{S_k^{(1)}(\\eta)}{S_k^{(0)}(\\eta)}\\right)^2 \\right]\n$$\n方括号中的项是生物标志物值 $\\{m_i(t_k) : i \\in R_k\\}$ 以 $\\exp(\\eta m_i(t_k))$ 为权重的方差，该值始终为非负。由于 $d_k \\ge 1$，Hessian矩阵 $H(\\eta)$ 是非正的，这证实了 $\\ell(\\eta)$ 的凹性。\n\n每次迭代的Newton-Raphson更新步骤为：\n$$\n\\eta_{\\text{new}} = \\eta_{\\text{old}} - \\alpha \\cdot (H(\\eta_{\\text{old}}))^{-1} U(\\eta_{\\text{old}})\n$$\n其中 $\\alpha \\in (0, 1]$ 是通过回溯线搜索确定的步长，以确保每一步对数似然值都增加。\n\n### 3. 数值实现细节\n\n**数值稳定性**：直接计算 $S_k^{(p)}(\\eta)$ 可能因指数项导致数值溢出。为防止这种情况，我们使用log-sum-exp技巧。对于每个事件时间 $t_k$，我们定义一个移位常数 $c_k = \\max_{i \\in R_k} \\{\\eta \\cdot m_i(t_k)\\}$。然后，和的对数可以稳定地计算为：\n$$\n\\log(S_k^{(0)}(\\eta)) = \\log\\left(\\sum_{i \\in R_k} e^{\\eta m_i(t_k)}\\right) = c_k + \\log\\left(\\sum_{i \\in R_k} e^{\\eta m_i(t_k) - c_k}\\right)\n$$\n比率 $S_k^{(1)}/S_k^{(0)}$ 和 $S_k^{(2)}/S_k^{(0)}$ 可以使用项 $e^{\\eta m_i(t_k) - c_k}$ 来计算，这些项的上限为1，从而避免溢出。\n\n**回溯线搜索**：为确保收敛，选择步长 $\\alpha$ 以满足Armijo条件。从 $\\alpha=1$ 开始，我们迭代地减小它（例如，乘以0.5），直到满足以下不等式，其中 $\\Delta\\eta = -U(\\eta)/H(\\eta)$ 是Newton步长方向：\n$$\n\\ell(\\eta + \\alpha \\Delta\\eta) > \\ell(\\eta) + c_1 \\alpha U(\\eta) \\Delta\\eta\n$$\n控制参数 $c_1$ 的一个典型值为 $10^{-4}$。\n\n**特殊情况与回退策略**：\n- **平坦似然**：如果在每个事件时间 $t_k$，风险集中的所有生物标志物值 $\\{m_i(t_k) : i \\in R_k\\}$ 都相同，则Hessian矩阵中的方差项对所有 $k$ 都为零。这使得 $H(\\eta) = 0$ 对所有 $\\eta$ 成立，导致似然函数是平坦的。在这种情况下，$\\eta$ 是不可识别的，问题指定返回一个值 $0.0$。\n- **回退优化**：如果Hessian矩阵接近奇异（即其量级低于一个小的阈值，例如 $10^{-8}$），或者回溯线搜索未能找到一个合适的步长 $\\alpha$，Newton-Raphson方法可能会失败。在这种情况下，算法被指定切换到一个更稳健但可能更慢的有界标量最大化程序（`scipy.optimize.minimize_scalar`，使用 `method='bounded'`），以在区间 $[-5, 5]$ 内找到 $\\ell(\\eta)$ 的最大值。\n\n**算法摘要**：\n1. 初始化 $\\eta = 0.0$。\n2. 对每个测试案例，解析数据并预先计算集合 $\\{t_k, D_k, R_k\\}$ 以及每个 $i \\in R_k$ 的插值生物标志物值 $m_i(t_k)$。\n3. 检查平坦似然条件。如果满足，返回 $0.0$。\n4. 迭代Newton-Raphson过程：\n    a. 使用数值稳定的方法计算 $U(\\eta)$ 和 $H(\\eta)$。\n    b. 检查收敛性（梯度量级 $|U(\\eta)|  10^{-6}$ 且更新大小 $|\\Delta\\eta|  10^{-6}$）。\n    c. 检查Hessian矩阵是否接近奇异。如果是，则回退到有界优化器。\n    d. 计算Newton步长 $\\Delta\\eta = -U(\\eta)/H(\\eta)$。\n    e. 执行回溯线搜索以找到合适的步长 $\\alpha$。如果线搜索失败，则回退。\n    f. 更新 $\\eta \\leftarrow \\eta + \\alpha \\Delta\\eta$。\n5. 如果达到最大迭代次数（$50$次）仍未收敛，则回退到有界优化器。\n6. 最终估计的 $\\eta$ 四舍五入到三位小数。", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize_scalar\n\ndef solve():\n    \"\"\"\n    Solves for the association parameter eta in a time-dependent Cox model\n    for several test cases, as specified in the problem statement.\n    \"\"\"\n\n    # --- Data Definition ---\n\n    case_a_data = {\n        'T': np.array([3, 5, 7, 12, 12, 12]),\n        'delta': np.array([1, 1, 1, 0, 0, 0]),\n        'biomarker_t': np.array([[0, 10] for _ in range(6)]),\n        'biomarker_m': np.array([\n            [3.0, 5.0], [2.8, 4.3], [2.5, 3.5],\n            [1.5, 2.0], [1.0, 2.0], [0.8, 1.3]\n        ])\n    }\n\n    case_b_data = {\n        'T': np.array([3, 5, 7, 12, 12, 12]),\n        'delta': np.array([1, 1, 1, 0, 0, 0]),\n        'biomarker_t': np.array([[0, 10] for _ in range(6)]),\n        'biomarker_m': np.array([\n            [0.5, 0.5], [0.7, 1.2], [0.8, 1.3],\n            [2.5, 3.5], [2.8, 4.3], [3.0, 5.0]\n        ])\n    }\n\n    case_c_data = {\n        'T': np.array([3, 5, 7, 12, 12, 12]),\n        'delta': np.array([1, 1, 1, 0, 0, 0]),\n        'biomarker_t': np.array([[0, 10] for _ in range(6)]),\n        'biomarker_m': np.array([[2.0, 2.0] for _ in range(6)])\n    }\n\n    case_d_data = {\n        'T': np.array([4, 4, 6, 8, 8]),\n        'delta': np.array([1, 1, 1, 0, 0]),\n        'biomarker_t': np.array([[0, 8] for _ in range(5)]),\n        'biomarker_m': np.array([\n            [2.5, 3.5], [2.3, 3.3], [1.7, 2.1],\n            [1.5, 1.9], [1.2, 1.6]\n        ])\n    }\n\n    test_cases = [case_a_data, case_b_data, case_c_data, case_d_data]\n\n    # --- Solver Implementation ---\n\n    class CoxPHSolver:\n        def __init__(self, T, delta, biomarker_t, biomarker_m):\n            self.T = T\n            self.delta = delta\n            self.biomarker_t = biomarker_t\n            self.biomarker_m = biomarker_m\n            self.n_subjects = len(T)\n            self.subject_indices = np.arange(self.n_subjects)\n            \n            self.unique_event_times = sorted(np.unique(T[delta == 1]))\n            self.precomputed_data = self._precompute()\n\n        def _get_biomarker_value(self, subject_idx, t):\n            t0, t1 = self.biomarker_t[subject_idx]\n            m0, m1 = self.biomarker_m[subject_idx]\n            if t1 == t0:\n                return m0\n            return m0 + (m1 - m0) * (t - t0) / (t1 - t0)\n\n        def _precompute(self):\n            data = []\n            if not self.unique_event_times:\n                return data\n\n            for t_k in self.unique_event_times:\n                risk_set_indices = self.subject_indices[self.T >= t_k]\n                event_set_indices = self.subject_indices[(self.T == t_k)  (self.delta == 1)]\n                \n                m_values = {i: self._get_biomarker_value(i, t_k) for i in risk_set_indices}\n                \n                data.append({\n                    \"risk_set_indices\": risk_set_indices,\n                    \"event_set_indices\": event_set_indices,\n                    \"d_k\": len(event_set_indices),\n                    \"m_values\": m_values,\n                })\n            return data\n\n        def _log_likelihood_and_derivatives(self, eta):\n            logL, U, H = 0.0, 0.0, 0.0\n\n            for data_k in self.precomputed_data:\n                m_vals_risk = np.array(list(data_k[\"m_values\"].values()))\n                \n                # Numerically stable calculation using log-sum-exp trick\n                eta_m = eta * m_vals_risk\n                c_k = np.max(eta_m) if eta_m.size > 0 else 0\n                exp_terms = np.exp(eta_m - c_k)\n                \n                S0 = np.sum(exp_terms)\n                S1 = np.sum(m_vals_risk * exp_terms)\n                S2 = np.sum(m_vals_risk**2 * exp_terms)\n\n                m_vals_event = np.array([data_k[\"m_values\"][i] for i in data_k[\"event_set_indices\"]])\n                sum_m_events = np.sum(m_vals_event)\n                \n                logL += eta * sum_m_events - data_k[\"d_k\"] * (c_k + np.log(S0))\n                \n                E_m = S1 / S0\n                U += sum_m_events - data_k[\"d_k\"] * E_m\n                \n                Var_m = S2 / S0 - E_m**2\n                H -= data_k[\"d_k\"] * Var_m\n                \n            return logL, U, H\n\n        def _is_likelihood_flat(self):\n            if not self.precomputed_data:\n                return True\n            for data_k in self.precomputed_data:\n                m_vals = np.array(list(data_k[\"m_values\"].values()))\n                if m_vals.size > 1 and np.std(m_vals) > 1e-9:\n                    return False\n            return True\n\n        def _fallback_solver(self):\n            def objective(eta_val):\n                try:\n                    logL, _, _ = self._log_likelihood_and_derivatives(eta_val)\n                    if not np.isfinite(logL):\n                        return np.finfo(np.float64).max\n                    return -logL\n                except (ValueError, FloatingPointError):\n                    return np.finfo(np.float64).max\n\n            res = minimize_scalar(objective, bounds=(-5, 5), method='bounded')\n            return res.x if res.success else np.nan\n\n        def estimate_eta(self):\n            if self._is_likelihood_flat():\n                return 0.0\n\n            eta = 0.0\n            max_iter = 50\n            conv_tol_update = 1e-6\n            conv_tol_grad = 1e-6\n            hessian_min_mag = 1e-8\n            last_update = np.inf\n            \n            for i in range(max_iter):\n                try:\n                    logL, U, H = self._log_likelihood_and_derivatives(eta)\n                except (ValueError, FloatingPointError):\n                    return self._fallback_solver()\n\n                if abs(H)  hessian_min_mag:\n                    return self._fallback_solver()\n\n                update = -U / H\n                \n                # Check for convergence before line search\n                if i > 0 and abs(last_update)  conv_tol_update and abs(U)  conv_tol_grad:\n                    return eta\n                last_update = update\n\n                # Backtracking line search\n                alpha, alpha_min, c1 = 1.0, 1e-8, 1e-4\n                dir_deriv = U * update\n                \n                line_search_failed = True\n                while alpha > alpha_min:\n                    try:\n                        next_logL, _, _ = self._log_likelihood_and_derivatives(eta + alpha * update)\n                        if np.isfinite(next_logL) and next_logL > logL + c1 * alpha * dir_deriv:\n                            line_search_failed = False\n                            break\n                    except (ValueError, FloatingPointError):\n                        pass\n                    alpha *= 0.5\n\n                if line_search_failed:\n                    return self._fallback_solver()\n                \n                eta += alpha * update\n            \n            # If max iterations reached, fall back\n            return self._fallback_solver()\n\n    # --- Main Execution Logic ---\n    results = []\n    for case_data in test_cases:\n        solver = CoxPHSolver(\n            T=case_data['T'],\n            delta=case_data['delta'],\n            biomarker_t=case_data['biomarker_t'],\n            biomarker_m=case_data['biomarker_m']\n        )\n        eta_hat = solver.estimate_eta()\n        results.append(f\"{eta_hat:.3f}\")\n        \n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "4597903"}]}