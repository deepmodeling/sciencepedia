{"hands_on_practices": [{"introduction": "主成分分析的第一步是理解变量间的关系，尤其是当变量单位不同时，使用相关矩阵而非协方差矩阵至关重要。本练习旨在通过一个混合类型临床数据集，让您亲手计算相关矩阵，从而巩固进行相关性PCA前数据准备的核心步骤[@problem_id:4598175]。您将深入理解数据标准化和分类变量编码如何从根本上影响分析结果。", "problem": "一个研究团队正准备应用主成分分析（PCA）对一个成年人队列进行临床风险分层。考虑一个包含 $n=6$ 名患者的合成数据集，记录了以下变量：空腹血糖（单位：$\\mathrm{mg/dL}$）、收缩压（单位：$\\mathrm{mmHg}$）以及一个二元诊断指标，用于表示是否患有2型糖尿病，其中 $1$ 表示已诊断，$0$ 表示未诊断。患者层面的数据如下（每个元组为（血糖，收缩压，诊断））：\n$$(90, 110, 0),\\quad (100, 120, 0),\\quad (110, 130, 0),\\quad (120, 140, 1),\\quad (130, 150, 1),\\quad (140, 160, 1).$$\n任务：\n- 在对混合临床变量进行PCA的背景下，论证将诊断编码为 $0$ 和 $1$ 的合理性，并论证构建基于相关性的PCA所需的中心化和缩放选择的合理性。\n- 使用适当的编码和中心化（以及您认为正确构建相关矩阵所需的任何额外预处理），计算这三个变量的样本相关矩阵。\n- 计算所得相关矩阵的最大特征值，该值对应于基于相关性的PCA中第一个主成分所解释的方差。\n\n以单一封闭形式的解析表达式提供最大特征值。无需四舍五入，最终表达式中不应包含任何单位。", "solution": "该问题是有效的，因为它具有科学依据、提法明确、客观且自成体系。它展示了主成分分析（PCA）在一个合成临床数据集上的一个标准（尽管简化了）的应用。任务涉及论证混合数据类型的处理方法并执行必要的计算，这些在数学上是合理的，并且是该主题的核心。\n\n分析分三个阶段进行：\n1.  对混合数据类型进行基于相关性的PCA的预处理步骤的合理性论证。\n2.  样本相关矩阵的计算。\n3.  相关矩阵最大特征值的计算。\n\n令三个变量分别表示为 $X_1$（空腹血糖）、$X_2$（收缩压）和 $X_3$（糖尿病诊断）。数据集包含 $n=6$ 个观测值。\n\n**1. 预处理的合理性论证**\n\n主成分分析旨在识别数据集中方差最大的正交轴。然而，一个变量的方差取决于其尺度和单位。给定的变量——血糖和收缩压，分别以不同的单位（$\\mathrm{mg/dL}$ 和 $\\mathrm{mmHg}$）测量，并且具有不同的典型范围。如果对原始数据（即对协方差矩阵）执行PCA，数值上方差最大的变量将不成比例地主导第一个主成分，而不管其在数据结构中的实际重要性如何。为了缓解这个问题，标准做法是标准化数据。这对每个变量都包括两个步骤：通过减去样本均值进行中心化，以及通过除以样本标准差进行缩放。对此类标准化数据执行PCA在数学上等同于对样本相关矩阵执行PCA。这种方法确保每个变量的均值为 $0$，方差为 $1$，使它们处于同等地位。\n\n第三个变量，即诊断指标，是二元的。将其数值编码为 $0$ 和 $1$ 是在这类分析中包含分类数据的常用方法。当计算一个连续变量与一个编码为 $0$ 和 $1$ 的二分变量之间的皮尔逊相关系数时，其结果在代数上等同于点二列相关系数。该系数是衡量连续变量与二元类别之间线性关联的有效度量，从而证明了将诊断变量纳入相关矩阵的合理性。\n\n**2. 样本相关矩阵的计算**\n\n样本相关矩阵 $R$ 是一个 $3 \\times 3$ 的矩阵，其中元素 $R_{ij}$ 是变量 $X_i$ 和 $X_j$ 之间的样本相关系数。数据向量为：\n$$ X_1 = \\begin{pmatrix} 90 \\\\ 100 \\\\ 110 \\\\ 120 \\\\ 130 \\\\ 140 \\end{pmatrix}, \\quad X_2 = \\begin{pmatrix} 110 \\\\ 120 \\\\ 130 \\\\ 140 \\\\ 150 \\\\ 160 \\end{pmatrix}, \\quad X_3 = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix} $$\n首先，我们计算样本均值（$\\bar{x}_i$）：\n$$ \\bar{x}_1 = \\frac{1}{6}(90+100+110+120+130+140) = \\frac{690}{6} = 115 $$\n$$ \\bar{x}_2 = \\frac{1}{6}(110+120+130+140+150+160) = \\frac{810}{6} = 135 $$\n$$ \\bar{x}_3 = \\frac{1}{6}(0+0+0+1+1+1) = \\frac{3}{6} = \\frac{1}{2} $$\n接下来，我们使用分母为 $n-1=5$ 的无偏估计量来计算样本方差（$s_i^2$）和标准差（$s_i$）：\n$$ s_1^2 = \\frac{1}{5} \\sum_{k=1}^{6} (x_{1k} - \\bar{x}_1)^2 = \\frac{1}{5}[(-25)^2 + (-15)^2 + (-5)^2 + 5^2 + 15^2 + 25^2] = \\frac{1}{5}[625+225+25+25+225+625] = \\frac{1750}{5} = 350 $$\n$$ s_1 = \\sqrt{350} $$\n$X_2$ 的数据是 $X_1$ 的一个简单线性变换，具体为 $X_2 = X_1 + 20$。因此，它们的中心化向量是相同的，并且它们的方差相等。\n$$ s_2^2 = 350 \\implies s_2 = \\sqrt{350} $$\n对于 $X_3$：\n$$ s_3^2 = \\frac{1}{5} \\sum_{k=1}^{6} (x_{3k} - \\bar{x}_3)^2 = \\frac{1}{5}[3 \\cdot (0 - \\frac{1}{2})^2 + 3 \\cdot (1 - \\frac{1}{2})^2] = \\frac{1}{5}[3 \\cdot \\frac{1}{4} + 3 \\cdot \\frac{1}{4}] = \\frac{1}{5}[\\frac{6}{4}] = \\frac{3}{10} $$\n$$ s_3 = \\sqrt{\\frac{3}{10}} $$\n样本相关系数为 $R_{ij} = \\frac{\\text{Cov}(X_i, X_j)}{s_i s_j}$，其中 $\\text{Cov}(X_i, X_j) = \\frac{1}{n-1}\\sum_{k=1}^{6} (x_{ik} - \\bar{x}_i)(x_{jk} - \\bar{x}_j)$。对角线元素 $R_{ii}$ 均为 $1$。\n对于 $R_{12}$：由于 $X_2 = X_1 + 20$，这两个变量是完全线性相关的。因此，$R_{12} = 1$。\n对于 $R_{13}$：\n$$ \\text{Cov}(X_1, X_3) = \\frac{1}{5} \\sum_{k=1}^{6} (x_{1k} - \\bar{x}_1)(x_{3k} - \\bar{x}_3) = \\frac{1}{5} [(-25)(-\\frac{1}{2}) + (-15)(-\\frac{1}{2}) + (-5)(-\\frac{1}{2}) + (5)(\\frac{1}{2}) + (15)(\\frac{1}{2}) + (25)(\\frac{1}{2})] $$\n$$ \\text{Cov}(X_1, X_3) = \\frac{1}{5} [\\frac{1}{2}(25+15+5) + \\frac{1}{2}(5+15+25)] = \\frac{1}{5} [\\frac{45}{2} + \\frac{45}{2}] = \\frac{45}{5} = 9 $$\n$$ R_{13} = \\frac{9}{s_1 s_3} = \\frac{9}{\\sqrt{350}\\sqrt{3/10}} = \\frac{9}{\\sqrt{350 \\cdot 0.3}} = \\frac{9}{\\sqrt{105}} $$\n对于 $R_{23}$：由于 $X_1$ 和 $X_2$ 的中心化向量相同，所以 $\\text{Cov}(X_2, X_3) = \\text{Cov}(X_1, X_3) = 9$。同时，$s_2=s_1$。因此，$R_{23} = R_{13} = \\frac{9}{\\sqrt{105}}$。\n令 $c = \\frac{9}{\\sqrt{105}}$。相关矩阵为：\n$$ R = \\begin{pmatrix} 1  & 1 & c \\\\ 1 & 1 & c \\\\ c & c & 1 \\end{pmatrix} $$\n\n**3. 最大特征值的计算**\n\n我们需要通过求解特征方程 $\\det(R - \\lambda I) = 0$ 来找到 $R$ 的特征值 $\\lambda$。\n$$ \\det \\begin{pmatrix} 1-\\lambda  & 1 & c \\\\ 1 & 1-\\lambda & c \\\\ c & c & 1-\\lambda \\end{pmatrix} = 0 $$\n展开行列式：\n$$ (1-\\lambda)((1-\\lambda)^2 - c^2) - 1( (1-\\lambda) - c^2 ) + c(c - c(1-\\lambda)) = 0 $$\n$$ (1-\\lambda)^3 - c^2(1-\\lambda) - (1-\\lambda) + c^2 + c^2(1 - 1 + \\lambda) = 0 $$\n$$ (1-\\lambda)^3 - (1-\\lambda) - c^2(1-\\lambda) + c^2 + \\lambda c^2 = 0 $$\n$$ (1-\\lambda)^3 - (1-\\lambda) - c^2 + \\lambda c^2 + c^2 + \\lambda c^2 = 0 $$\n$$ (1-\\lambda)^3 - (1-\\lambda) + 2\\lambda c^2 = 0 $$\n提出因子 $(1-\\lambda)$：\n$$ (1-\\lambda)[(1-\\lambda)^2 - 1] + 2\\lambda c^2 = 0 $$\n$$ (1-\\lambda)[\\lambda^2 - 2\\lambda] + 2\\lambda c^2 = 0 $$\n$$ \\lambda(1-\\lambda)(\\lambda-2) + 2\\lambda c^2 = 0 $$\n一个解是 $\\lambda=0$。如果 $\\lambda \\neq 0$，我们可以两边同除以 $\\lambda$：\n$$ (1-\\lambda)(\\lambda-2) + 2c^2 = 0 $$\n$$ -\\lambda^2 + 3\\lambda - 2 + 2c^2 = 0 $$\n$$ \\lambda^2 - 3\\lambda + (2 - 2c^2) = 0 $$\n使用二次公式求另外两个特征值：\n$$ \\lambda = \\frac{3 \\pm \\sqrt{(-3)^2 - 4(1)(2-2c^2)}}{2} = \\frac{3 \\pm \\sqrt{9 - 8 + 8c^2}}{2} = \\frac{3 \\pm \\sqrt{1 + 8c^2}}{2} $$\n三个特征值为 $\\lambda_1 = 0$, $\\lambda_2 = \\frac{3 - \\sqrt{1 + 8c^2}}{2}$ 和 $\\lambda_3 = \\frac{3 + \\sqrt{1 + 8c^2}}{2}$。最大特征值是 $\\lambda_{max} = \\lambda_3$。\n现在，我们代入 $c^2$ 的值：\n$$ c^2 = \\left(\\frac{9}{\\sqrt{105}}\\right)^2 = \\frac{81}{105} = \\frac{27}{35} $$\n将 $c^2$ 代入 $\\lambda_{max}$ 的表达式中：\n$$ \\lambda_{max} = \\frac{3 + \\sqrt{1 + 8\\left(\\frac{27}{35}\\right)}}{2} = \\frac{3 + \\sqrt{1 + \\frac{216}{35}}}{2} = \\frac{3 + \\sqrt{\\frac{35}{35} + \\frac{216}{35}}}{2} = \\frac{3 + \\sqrt{\\frac{251}{35}}}{2} $$\n这就是最大特征值的最终封闭形式解析表达式。\n特征值之和为 $0 + \\frac{3 - \\sqrt{1 + 8c^2}}{2} + \\frac{3 + \\sqrt{1 + 8c^2}}{2} = \\frac{6}{2} = 3$，这与相关矩阵的迹 $\\text{Tr}(R) = 1+1+1=3$ 相符。最大特征值代表了从相关矩阵派生出的第一个主成分所解释的方差。", "answer": "$$ \\boxed{\\frac{3 + \\sqrt{\\frac{251}{35}}}{2}} $$", "id": "4598175"}, {"introduction": "原始临床数据，特别是生化指标，常常呈现出不符合传统统计方法假设的偏态分布。本练习将引导您处理临床数据分析中常见的右偏态问题，例如由倍数变化或浓度测量产生的数据[@problem_id:4598130]。您将学习为何以及如何应用对数变换等方差稳定技术，并量化该变换对协方差结构的影响，这是确保后续PCA分析稳健性的关键一步。", "problem": "一个研究团队正准备对一组无量纲的临床指标应用主成分分析 (PCA)，这些指标是相对于患者特异性基线构建的倍数变化。已知许多此类指标表现出极度的右偏和乘性误差，这与生化浓度中常见的对数正态生成机制相符。该团队希望在拟合 PCA 之前，证明进行方差稳定变换的合理性，然后通过一个小的数值例子，量化两个此类指标在变换后样本协方差的变化。\n\n从核心定义和经过充分检验的事实出发，论证对具有乘性噪声的临床指标应用单调方差稳定变换（如对数变换或 Box–Cox 变换）的合理性。然后，对于从 $n=6$ 位患者收集的以下无量纲倍数变化数据，\n- 指标 $A$：$1$, $1$, $2$, $8$, $32$, $64$,\n- 指标 $B$：$0.5$, $1$, $2$, $8$, $24$, $48$,\n\n使用样本协方差的定义，计算 $A$ 和 $B$ 之间的样本协方差以及 $\\ln(A)$ 和 $\\ln(B)$ 之间的样本协方差。将“样本协方差的变化”定义为差值\n$$\\Delta = \\operatorname{Cov}(\\ln(A),\\ln(B)) - \\operatorname{Cov}(A,B).$$\n将 $\\Delta$ 的最终数值四舍五入到四位有效数字。这些指标是无量纲的，因此最终答案不需要物理单位。", "solution": "该问题要求分两部分作答：首先，从理论上证明在应用主成分分析 (PCA) 之前对指定类型的临床数据进行对数变换的合理性；其次，对给定数据集，具体计算这种变换后样本协方差的变化。\n\n### 第1部分：对数变换的合理性证明\n\n主成分分析是一种在数据集中识别最大方差正交轴（主成分）的技术。第一主成分是原始变量的线性组合，它捕获了数据中最大量的方差。因此，PCA 对输入变量的尺度和方差高度敏感。一个方差过大的变量可能会主导第一主成分，从而可能掩盖其他变量的贡献，导致对底层数据结构的误读。\n\n问题陈述指出，临床指标表现出极度右偏和乘性误差，这与对数正态生成机制相符。设随机变量 $X$ 代表这样一个指标。如果 $X$ 服从对数正态分布，那么它的自然对数 $Y = \\ln(X)$ 服从正态分布。设 $Y \\sim \\mathcal{N}(\\mu, \\sigma^2)$。$X$ 的期望值（均值）和方差由以下公式给出：\n$$ \\mathbb{E}[X] = \\exp\\left(\\mu + \\frac{\\sigma^2}{2}\\right) $$\n$$ \\operatorname{Var}(X) = \\left(\\exp(\\sigma^2) - 1\\right) \\exp\\left(2\\mu + \\sigma^2\\right) $$\n将均值的表达式代入方差方程，我们可以看到它们之间的关系：\n$$ \\operatorname{Var}(X) = \\left(\\exp(\\sigma^2) - 1\\right) \\left(\\exp\\left(\\mu + \\frac{\\sigma^2}{2}\\right)\\right)^2 = \\left(\\exp(\\sigma^2) - 1\\right) (\\mathbb{E}[X])^2 $$\n这表明 $X$ 的方差与其均值的平方成正比，即 $\\operatorname{Var}(X) \\propto (\\mathbb{E}[X])^2$。因此，标准差与均值成正比，即 $\\operatorname{SD}(X) \\propto \\mathbb{E}[X]$。这种方差对均值的依赖性是一种异方差性。在 PCA 的背景下，均值较大的变量将具有不成比例的较大方差，导致它们对分析产生不当影响。\n\n方差稳定变换是应用于数据的一个函数 $g$，使得变换后变量 $g(X)$ 的方差近似恒定且与其均值无关。我们可以使用 Delta 方法找到一个合适的变换，该方法为随机变量的函数的方差提供了一阶近似：\n$$ \\operatorname{Var}(g(X)) \\approx \\left(g'(\\mathbb{E}[X])\\right)^2 \\operatorname{Var}(X) $$\n其中 $g'$ 是 $g$ 的一阶导数。我们寻求一个函数 $g$，使得 $\\operatorname{Var}(g(X))$ 是一个常数，记为 $c^2$。代入 $X$ 的方差结构，并记 $\\mu_X = \\mathbb{E}[X]$：\n$$ c^2 \\approx \\left(g'(\\mu_X)\\right)^2 \\left(k \\cdot \\mu_X^2\\right) $$\n其中 $k = \\exp(\\sigma^2) - 1$ 是比例常数。为了使左侧为常数，我们需要：\n$$ g'(\\mu_X) \\propto \\frac{1}{\\mu_X} $$\n对此微分方程关于 $\\mu_X$ 积分，得到：\n$$ g(\\mu_X) \\propto \\ln(\\mu_X) $$\n因此，对于标准差与均值成正比的乘性误差数据，自然对数是合适的方差稳定变换。应用对数变换将乘性误差结构转换为加性结构，稳定了方差，并减轻了右偏，使数据更加对称，从而更好地符合 PCA 的基本假设。这为对所述临床指标使用对数变换提供了有力的理论依据。\n\n### 第2部分：样本协方差变化的计算\n\n给定 $n=6$ 位患者的两个指标 $A$ 和 $B$ 的数据：\n- 指标 $A$：$\\{1, 1, 2, 8, 32, 64\\}$\n- 指标 $B$：$\\{0.5, 1, 2, 8, 24, 48\\}$\n\n两组观测值 $\\{x_i\\}_{i=1}^n$ 和 $\\{y_i\\}_{i=1}^n$ 之间的样本协方差定义为：\n$$ \\operatorname{Cov}(X,Y) = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y}) $$\n一个计算上等价的公式是 $\\operatorname{Cov}(X,Y) = \\frac{1}{n-1} \\left( \\sum_{i=1}^n x_i y_i - n\\bar{x}\\bar{y} \\right)$。我们将使用此形式进行计算。\n\n**步骤 2.1：计算 $\\operatorname{Cov}(A,B)$**\n\n首先，我们计算样本均值 $\\bar{A}$ 和 $\\bar{B}$：\n$$ \\bar{A} = \\frac{1}{6}(1+1+2+8+32+64) = \\frac{108}{6} = 18 $$\n$$ \\bar{B} = \\frac{1}{6}(0.5+1+2+8+24+48) = \\frac{83.5}{6} $$\n接下来，我们计算乘积和 $\\sum A_i B_i$：\n$$ \\sum_{i=1}^6 A_i B_i = (1)(0.5) + (1)(1) + (2)(2) + (8)(8) + (32)(24) + (64)(48) $$\n$$ \\sum_{i=1}^6 A_i B_i = 0.5 + 1 + 4 + 64 + 768 + 3072 = 3909.5 $$\n现在，我们计算 $n=6$ 时的 $\\operatorname{Cov}(A,B)$：\n$$ \\operatorname{Cov}(A,B) = \\frac{1}{6-1} \\left( \\sum_{i=1}^6 A_i B_i - 6\\bar{A}\\bar{B} \\right) = \\frac{1}{5} \\left( 3909.5 - 6(18)\\left(\\frac{83.5}{6}\\right) \\right) $$\n$$ \\operatorname{Cov}(A,B) = \\frac{1}{5} (3909.5 - 18 \\cdot 83.5) = \\frac{1}{5} (3909.5 - 1503) = \\frac{2406.5}{5} = 481.3 $$\n\n**步骤 2.2：计算 $\\operatorname{Cov}(\\ln(A), \\ln(B))$**\n\n令 $A' = \\ln(A)$ 和 $B' = \\ln(B)$。变换后的数据为：\n- $A' = \\{\\ln(1), \\ln(1), \\ln(2), \\ln(8), \\ln(32), \\ln(64)\\} = \\{0, 0, \\ln(2), 3\\ln(2), 5\\ln(2), 6\\ln(2)\\}$\n- $B' = \\{\\ln(0.5), \\ln(1), \\ln(2), \\ln(8), \\ln(24), \\ln(48)\\} = \\{-\\ln(2), 0, \\ln(2), 3\\ln(2), \\ln(3)+3\\ln(2), \\ln(3)+4\\ln(2)\\}$\n样本均值 $\\bar{A'}$ 和 $\\bar{B'}$ 是：\n$$ \\bar{A'} = \\frac{1}{6}(0+0+1+3+5+6)\\ln(2) = \\frac{15}{6}\\ln(2) = \\frac{5}{2}\\ln(2) $$\n$$ \\bar{B'} = \\frac{1}{6}(-\\ln(2) + 0 + \\ln(2) + 3\\ln(2) + \\ln(3)+3\\ln(2) + \\ln(3)+4\\ln(2)) = \\frac{1}{6}(10\\ln(2) + 2\\ln(3)) = \\frac{5}{3}\\ln(2) + \\frac{1}{3}\\ln(3) $$\n乘积和 $\\sum A'_i B'_i$：\n$$ \\sum A'_i B'_i = (0) + (0) + (\\ln(2))(\\ln(2)) + (3\\ln(2))(3\\ln(2)) + (5\\ln(2))(\\ln(3)+3\\ln(2)) + (6\\ln(2))(\\ln(3)+4\\ln(2)) $$\n$$ \\sum A'_i B'_i = (\\ln(2))^2 + 9(\\ln(2))^2 + 5\\ln(2)\\ln(3) + 15(\\ln(2))^2 + 6\\ln(2)\\ln(3) + 24(\\ln(2))^2 $$\n$$ \\sum A'_i B'_i = (1+9+15+24)(\\ln(2))^2 + (5+6)\\ln(2)\\ln(3) = 49(\\ln(2))^2 + 11\\ln(2)\\ln(3) $$\n现在，我们计算 $\\operatorname{Cov}(\\ln(A), \\ln(B))$：\n$$ \\operatorname{Cov}(A', B') = \\frac{1}{5} \\left( \\sum_{i=1}^6 A'_i B'_i - 6\\bar{A'}\\bar{B'} \\right) $$\n项 $6\\bar{A'}\\bar{B'}$ 为：\n$$ 6\\bar{A'}\\bar{B'} = 6 \\left(\\frac{5}{2}\\ln(2)\\right) \\left(\\frac{5}{3}\\ln(2) + \\frac{1}{3}\\ln(3)\\right) = 15\\ln(2) \\left(\\frac{1}{3}(5\\ln(2) + \\ln(3))\\right) = 5\\ln(2)(5\\ln(2) + \\ln(3)) $$\n$$ 6\\bar{A'}\\bar{B'} = 25(\\ln(2))^2 + 5\\ln(2)\\ln(3) $$\n偏差的交叉乘积之和为：\n$$ \\sum_{i=1}^6 (A'_i - \\bar{A'})(B'_i - \\bar{B'}) = (49(\\ln(2))^2 + 11\\ln(2)\\ln(3)) - (25(\\ln(2))^2 + 5\\ln(2)\\ln(3)) $$\n$$ = 24(\\ln(2))^2 + 6\\ln(2)\\ln(3) $$\n所以协方差为：\n$$ \\operatorname{Cov}(\\ln(A), \\ln(B)) = \\frac{1}{5} \\left( 24(\\ln(2))^2 + 6\\ln(2)\\ln(3) \\right) $$\n使用数值 $\\ln(2) \\approx 0.693147$ 和 $\\ln(3) \\approx 1.098612$：\n$$ \\operatorname{Cov}(\\ln(A), \\ln(B)) \\approx \\frac{1}{5} (24(0.480453) + 6(0.761567)) = \\frac{1}{5}(11.530872 + 4.569402) = \\frac{16.100274}{5} \\approx 3.220055 $$\n\n**步骤 2.3：计算样本协方差的变化 $\\Delta$**\n\n该变化定义为 $\\Delta = \\operatorname{Cov}(\\ln(A),\\ln(B)) - \\operatorname{Cov}(A,B)$。\n$$ \\Delta \\approx 3.220055 - 481.3 = -478.079945 $$\n将结果四舍五入到四位有效数字：\n$$ \\Delta \\approx -478.1 $$", "answer": "$$\\boxed{-478.1}$$", "id": "4598130"}, {"introduction": "在处理基因组学等高维临床数据时，标准PCA产生的主成分载荷通常是“稠密”的，即几乎所有变量的系数都不为零，这给临床解释带来了巨大挑战。本练习将带您从标准PCA迈向稀疏PCA这一高级变体，它通过生成仅包含少数非零载荷的成分来提升模型的可解释性[@problem_id:4598129]。您将亲手实现稀疏PCA优化算法中的一个关键步骤，从而获得处理高维数据分析中可解释性问题的实践经验。", "problem": "给定一个对称半正定协方差矩阵 $\\Sigma \\in \\mathbb{R}^{4 \\times 4}$，它代表 4 个标准化的临床变量，以及一个初始载荷向量 $w \\in \\mathbb{R}^{4}$。在主成分分析（PCA）中，第一个主成分载荷向量旨在最大化由二次型 $w^\\top \\Sigma w$ 给出的解释方差，通常受单位 $\\ell_2$-范数约束。为了引入适合临床可解释性的稀疏性，我们考虑以下弹性网络正则化的稀疏PCA代理目标：\n$$\nF(w) = w^\\top \\Sigma w - \\frac{\\alpha}{2} \\lVert w \\rVert_2^2 - \\lambda \\lVert w \\rVert_1,\n$$\n其中 $\\alpha > 0$ 是一个岭正则化参数，$\\lambda \\ge 0$ 是一个 $\\ell_1$-惩罚参数。假设 $\\alpha$ 满足 $\\alpha > 2 \\max_{j \\in \\{1,2,3,4\\}} \\Sigma_{jj}$，从而使得下面定义的逐坐标子问题在每个坐标上都是严格凹的。\n\n您必须实现一次 Gauss-Seidel 坐标下降扫描，按 $j \\in \\{1,2,3,4\\}$ 的顺序更新每个坐标 $w_j$，在优化当前坐标时保持其他坐标固定。坐标 $j$ 的更新被定义为通过分离出 $F(w)$ 中依赖于 $w_j$ 的项而得到的一维惩罚凹二次函数的精确最大化器，即\n$$\n\\text{对 } x \\in \\mathbb{R} \\text{ 最大化}: \\quad \\left(\\Sigma_{jj} - \\frac{\\alpha}{2}\\right) x^2 + 2 \\, c_j \\, x - \\lambda |x|,\n$$\n其中\n$$\nc_j = \\sum_{k \\neq j} \\Sigma_{jk} w_k.\n$$\n执行原地（Gauss-Seidel）更新，因此在计算 $c_j$ 时，您需要使用 $w_1,\\dots,w_{j-1}$ 的最新更新值以及 $w_{j+1},\\dots,w_4$ 的当前值。完成 4 个坐标更新后，将结果向量后归一化至单位 $\\ell_2$-范数，以报告更新后的稀疏载荷向量。如果扫描后的向量恰好是零向量，则返回零向量而不进行归一化。\n\n您可以使用的基础知识：\n- 协方差矩阵的定义和PCA方差目标 $w^\\top \\Sigma w$。\n- $\\ell_2$-范数和 $\\ell_1$-范数的定义。\n- 一维凹二次优化的性质以及绝对值惩罚的次梯度最优性。\n\n您的程序必须为以下参数集测试套件实现上述过程，每个测试套件由 $(\\Sigma, \\alpha, \\lambda, w^{(0)})$ 指定：\n- 测试用例 1（一般情况）：\n  - $\\Sigma = \\begin{bmatrix}\n  1.0  & 0.6  & 0.3  & 0.1\\\\\n  0.6  & 1.2  & 0.2  & 0.0\\\\\n  0.3  & 0.2  & 0.8  & 0.4\\\\\n  0.1  & 0.0  & 0.4  & 0.9\n  \\end{bmatrix}$，\n  - $\\alpha = 3.0$，\n  - $\\lambda = 0.5$，\n  - $w^{(0)} = \\begin{bmatrix}0.5\\\\0.5\\\\0.5\\\\0.5\\end{bmatrix}$。\n- 测试用例 2（高稀疏度，可能全为零的结果）：\n  - $\\Sigma = \\begin{bmatrix}\n  1.0  & 0.6  & 0.3  & 0.1\\\\\n  0.6  & 1.2  & 0.2  & 0.0\\\\\n  0.3  & 0.2  & 0.8  & 0.4\\\\\n  0.1  & 0.0  & 0.4  & 0.9\n  \\end{bmatrix}$，\n  - $\\alpha = 3.0$，\n  - $\\lambda = 1.5$，\n  - $w^{(0)} = \\begin{bmatrix}0.8\\\\0.2\\\\-0.5\\\\0.1\\end{bmatrix}$。\n- 测试用例 3（近带状协方差，中等稀疏度）：\n  - $\\Sigma = \\begin{bmatrix}\n  1.8  & 0.3  & 0.0  & 0.0\\\\\n  0.3  & 1.2  & 0.3  & 0.0\\\\\n  0.0  & 0.3  & 0.9  & 0.3\\\\\n  0.0  & 0.0  & 0.3  & 0.6\n  \\end{bmatrix}$，\n  - $\\alpha = 4.0$，\n  - $\\lambda = 0.2$，\n  - $w^{(0)} = \\begin{bmatrix}0.2\\\\0.6\\\\0.2\\\\-0.4\\end{bmatrix}$。\n\n角度单位不适用。不涉及物理单位。所有数值输出必须以浮点值报告。\n\n最终输出规格：\n- 对于每个测试用例，将经过一次 Gauss-Seidel 扫描后的后归一化载荷向量输出为一个包含 4 个浮点数的列表，每个浮点数四舍五入到 6 位小数。\n- 将三个结果汇总到单行的一个类 Python 列表字面量中，不带任何额外文本。格式必须是：\n$[ [a_1,a_2,a_3,a_4], [b_1,b_2,b_3,b_4], [c_1,c_2,c_3,c_4] ]$，\n其中每个 $a_i$、$b_i$、$c_i$ 是一个小数点后恰好有 6 位数字的小数。如果结果是零向量，则打印为 $[0.000000,0.000000,0.000000,0.000000]$。", "solution": "用户要求针对稀疏主成分分析（PCA）的代理目标函数，实现一次完整的 Gauss-Seidel 坐标下降扫描，然后对结果向量进行归一化。该过程必须应用于三个不同的测试用例。\n\n### 坐标更新的原理与推导\n\n需要最大化的目标函数是：\n$$\nF(w) = w^\\top \\Sigma w - \\frac{\\alpha}{2} \\lVert w \\rVert_2^2 - \\lambda \\lVert w \\rVert_1\n$$\n这可以通过展开二次项来重写：\n$$\nF(w) = \\sum_{i,j} w_i \\Sigma_{ij} w_j - \\frac{\\alpha}{2} \\sum_j w_j^2 - \\lambda \\sum_j |w_j|\n$$\n坐标下降法针对单个坐标（例如 $w_j$）优化目标函数，同时保持所有其他坐标 $w_{k \\neq j}$ 固定。为了推导 $w_j$ 的更新规则，我们分离出 $F(w)$ 中所有依赖于 $w_j$ 的项：\n$$\nF(w_j; w_{-j}) = \\Sigma_{jj} w_j^2 + 2 w_j \\sum_{k \\neq j} \\Sigma_{jk} w_k - \\frac{\\alpha}{2} w_j^2 - \\lambda |w_j| + \\text{const}\n$$\n符号 $w_{-j}$ 表示排除了分量 $j$ 的向量 $w$。常数项包含目标函数中不依赖于 $w_j$ 的所有部分。\n\n设 $x$ 为第 $j$ 个坐标的变量。用于更新 $w_j$ 的一维子问题是最大化：\n$$\nf_j(x) = \\Sigma_{jj} x^2 + 2x \\sum_{k \\neq j} \\Sigma_{jk} w_k - \\frac{\\alpha}{2} x^2 - \\lambda |x|\n$$\n将各项分组，我们得到：\n$$\nf_j(x) = \\left(\\Sigma_{jj} - \\frac{\\alpha}{2}\\right) x^2 + 2 \\left( \\sum_{k \\neq j} \\Sigma_{jk} w_k \\right) x - \\lambda |x|\n$$\n让我们定义 $c_j = \\sum_{k \\neq j} \\Sigma_{jk} w_k$。子问题变为：\n$$\n\\underset{x \\in \\mathbb{R}}{\\text{最大化}} \\quad f_j(x) = \\left(\\Sigma_{jj} - \\frac{\\alpha}{2}\\right) x^2 + 2 c_j x - \\lambda |x|\n$$\n这等价于最小化其负值：\n$$\n\\underset{x \\in \\mathbb{R}}{\\text{最小化}} \\quad -f_j(x) = \\left(\\frac{\\alpha}{2} - \\Sigma_{jj}\\right) x^2 - 2 c_j x + \\lambda |x|\n$$\n令 $D_j = \\frac{\\alpha}{2} - \\Sigma_{jj}$。问题陈述保证了 $\\alpha > 2 \\max_j \\Sigma_{jj}$，这意味着 $D_j > 0$。要最小化的函数是严格凸的。最小值可以使用次梯度微积分找到。$-f_j(x)$ 的次梯度由下式给出：\n$$\n\\partial(-f_j(x)) = 2 D_j x - 2 c_j + \\lambda \\partial|x|\n$$\n其中 $\\partial|x|$ 是绝对值函数的次梯度：\n$$\n\\partial|x| = \\begin{cases} \\{1\\} & \\text{若 } x > 0 \\\\ \\{-1\\} & \\text{若 } x < 0 \\\\ [-1, 1] & \\text{若 } x = 0 \\end{cases}\n$$\n最优解 $x^*$ 通过将次梯度设为 $0$ 来找到：$0 \\in \\partial(-f_j(x^*))$。\n\n情况 1：$x > 0$。条件是 $2 D_j x - 2 c_j + \\lambda = 0$，这给出 $x = \\frac{2 c_j - \\lambda}{2 D_j}$。这仅在结果 $x$ 为正时有效，即 $2 c_j - \\lambda > 0$，或 $2c_j > \\lambda$。\n\n情况 2：$x < 0$。条件是 $2 D_j x - 2 c_j - \\lambda = 0$，这给出 $x = \\frac{2 c_j + \\lambda}{2 D_j}$。这仅在 $x < 0$ 时有效，即 $2 c_j + \\lambda < 0$，或 $2c_j < -\\lambda$。\n\n情况 3：$x = 0$。条件是 $0 \\in -2 c_j + \\lambda [-1, 1]$。这意味着 $0 \\in [-2 c_j - \\lambda, -2 c_j + \\lambda]$，这等价于 $-2 c_j - \\lambda \\le 0$ 和 $-2 c_j + \\lambda \\ge 0$。这可以简化为 $|2 c_j| \\le \\lambda$。\n\n这三种情况可以使用软阈值算子 $S(z, \\gamma) = \\text{sign}(z) \\max(|z| - \\gamma, 0)$ 进行总结。最优解 $x^*$ 是：\n$$\nx^* = \\frac{S(2c_j, \\lambda)}{2D_j} = \\frac{S(2c_j, \\lambda)}{\\alpha - 2\\Sigma_{jj}}\n$$\n\n### 一次 Gauss-Seidel 扫描的算法\n\n对于给定的测试用例 $(\\Sigma, \\alpha, \\lambda, w^{(0)})$：\n1.  初始化工作向量 $w = w^{(0)}$。\n2.  对 $j$ 从 1 到 4 进行迭代：\n    a.  计算 $c_j = \\sum_{k \\neq j} \\Sigma_{jk} w_k$。在 Gauss-Seidel 更新中，这会使用 $k < j$ 时 $w_k$ 的最新值。这可以高效地计算为 $c_j = (\\Sigma_{j,:} \\cdot w) - \\Sigma_{jj} w_j$。\n    b.  计算更新的分子：$N = S(2c_j, \\lambda) = \\text{sign}(2c_j) \\max(|2c_j| - \\lambda, 0)$。\n    c.  计算更新的分母：$D = \\alpha - 2\\Sigma_{jj}$。\n    d.  更新工作向量的第 $j$ 个分量：$w_j \\leftarrow N/D$。\n3.  循环完成后，得到一个新向量 $w_{\\text{new}}$。\n4.  计算该向量的 $\\ell_2$-范数：$\\|w_{\\text{new}}\\|_2 = \\sqrt{\\sum_j w_{\\text{new}, j}^2}$。\n5.  如果 $\\|w_{\\text{new}}\\|_2 = 0$，最终结果是零向量 $[0,0,0,0]$。\n6.  否则，归一化向量：$w_{\\text{final}} = \\frac{w_{\\text{new}}}{\\|w_{\\text{new}}\\|_2}$。\n7.  $w_{\\text{final}}$ 的分量是该测试用例的输出。\n\n此过程是确定性的，并为每个测试用例产生唯一的输出。实现将精确遵循此逻辑。", "answer": "[ [0.655615, 0.655615, 0.374637, 0.000000], [0.000000, 0.000000, 0.000000, 0.000000], [0.970143, 0.242536, 0.000000, 0.000000] ]", "id": "4598129"}]}