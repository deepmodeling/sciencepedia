{"hands_on_practices": [{"introduction": "我们首先将探索评估模型整体偏差的最简单而有效的方法：宏观校准（calibration-in-the-large）。该方法检查整个群体的平均预测概率是否与观测到的事件发生率相符。在此练习中，你将推导并计算校准截距，该截距量化了在对数几率（log-odds）尺度上使模型预测与实际情况对齐所需的校正值。", "problem": "一个基于电子健康记录 (EHR) 的二元疾病风险模型为患者 $i=1,\\dots,n$ 输出预测概率 $\\hat{p}_{i}$。在一个留出队列中，这些预测值紧密聚集，呈现在 $0.9$ 附近为中心的窄分布，因此平均预测概率可取为 $\\bar{p}\\approx 0.9$。在同一队列中，经验观察到的疾病患病率为 $\\hat{\\pi}=0.7$。考虑在逻辑斯谛总体校准框架下评估校准，该框架将系统性未校准评估为预测概率与观测结果之间的对数优势比标度上的一个恒定偏移。\n\n仅从概率、患病率和 logit 函数 $\\operatorname{logit}(x)=\\ln\\!\\left(\\frac{x}{1-x}\\right)$ 的基本定义出发，推导带符号的总体校准截距 $a$。该截距 $a$ 将被加到 $\\operatorname{logit}(\\hat{p}_{i})$ 上，以使平均预测对数优势比与观测对数优势比对齐。将 $a$ 的符号解释为未校准的方向（负号表示在概率标度上高估；正号表示低估）。使用给定的队列摘要计算 $a$ 并报告其数值。将您的答案四舍五入到四位有效数字。", "solution": "该问题要求针对一个二元疾病风险模型，推导并计算其总体校准截距，记为 $a$。推导过程必须从基本定义开始。\n\n首先，我们验证问题陈述的有效性。\n给定条件如下：\n- 一组针对患者 $i=1,\\dots,n$ 的预测概率 $\\hat{p}_{i}$。\n- 平均预测概率为 $\\bar{p}\\approx 0.9$。\n- 经验观察到的疾病患病率为 $\\hat{\\pi}=0.7$。\n- 逻辑斯谛校准框架在对数优势比标度上应用一个恒定偏移 $a$。\n- logit 函数定义为 $\\operatorname{logit}(x)=\\ln\\!\\left(\\frac{x}{1-x}\\right)$。\n- 目标是找到 $a$，使得平均预测对数优势比与观测对数优势比对齐。\n\n该问题在生物统计学的模型校准领域具有科学依据。患病率、预测概率、对数优势比和校准截距等概念都是标准概念。所提供的值，即平均预测值 ($\\bar{p}=0.9$) 超过观测患病率 ($\\hat{\\pi}=0.7$)，代表了模型高估的一种常见且现实的情景。该问题是适定的、客观的，并且在对“对齐平均预测对数优势比”的合理解释下，包含了获得唯一解的足够信息。因此，该问题被认为是有效的。\n\n我们现在开始推导。\n\n1.  **基本定义**\n\n经验观察到的疾病患病率 $\\hat{\\pi}$ 是队列中二元结果 $y_i \\in \\{0, 1\\}$ 的平均值：\n$$ \\hat{\\pi} = \\frac{1}{n} \\sum_{i=1}^{n} y_i $$\n这代表了人群中的平均观测风险。\n\n平均预测概率 $\\bar{p}$ 是模型预测值的平均值：\n$$ \\bar{p} = \\frac{1}{n} \\sum_{i=1}^{n} \\hat{p}_i $$\n\nlogit 函数将概率 $p \\in (0, 1)$ 映射到对数优势比标度 $(-\\infty, \\infty)$，其定义如下：\n$$ \\operatorname{logit}(p) = \\ln\\left(\\frac{p}{1-p}\\right) $$\n\n2.  **总体校准框架**\n\n逻辑斯谛校准框架旨在通过对经过 logit 变换的预测值应用一个恒定偏移 $a$（校准截距）来纠正系统性未校准。校准后的概率 $p'_i$ 通过以下关系从原始预测 $\\hat{p}_i$ 获得：\n$$ \\operatorname{logit}(p'_i) = a + \\operatorname{logit}(\\hat{p}_i) $$\n\n问题指明，$a$ 的目的是将“平均预测对数优势比”与“观测对数优势比”对齐。在使用摘要统计量的总体校准背景下，这被解释为确保对应于平均预测的对数优势比，在经过 $a$ 修正后，等于观测患病率的对数优势比。\n\n队列的“观测对数优势比”自然地由总体患病率的 logit 值定义，即 $\\operatorname{logit}(\\hat{\\pi})$。\n队列的“平均预测对数优势比”由平均预测的 logit 值表示，即 $\\operatorname{logit}(\\bar{p})$。这是一个标准的简化方法，其合理性在于题目给出的信息——预测值是“紧密聚集”的，这意味着 $\\operatorname{logit}(\\bar{p}) \\approx \\frac{1}{n}\\sum\\operatorname{logit}(\\hat{p}_i)$。\n\n3.  **截距 $a$ 的推导**\n\n对齐条件可以表示为：\n$$ \\text{Observed Log-Odds} = a + \\text{Average Predicted Log-Odds} $$\n代入上面定义的表达式：\n$$ \\operatorname{logit}(\\hat{\\pi}) = a + \\operatorname{logit}(\\bar{p}) $$\n求解校准截距 $a$，我们得到：\n$$ a = \\operatorname{logit}(\\hat{\\pi}) - \\operatorname{logit}(\\bar{p}) $$\n现在，我们代入 logit 函数的定义：\n$$ a = \\ln\\left(\\frac{\\hat{\\pi}}{1-\\hat{\\pi}}\\right) - \\ln\\left(\\frac{\\bar{p}}{1-\\bar{p}}\\right) $$\n使用对数性质 $\\ln(x) - \\ln(y) = \\ln(x/y)$，可以写成：\n$$ a = \\ln\\left( \\frac{\\hat{\\pi}/(1-\\hat{\\pi})}{\\bar{p}/(1-\\bar{p})} \\right) $$\n\n4.  **数值计算**\n\n我们已知 $\\hat{\\pi} = 0.7$ 和 $\\bar{p} \\approx 0.9$。将这些值代入 $a$ 的表达式中：\n$$ a = \\ln\\left(\\frac{0.7}{1-0.7}\\right) - \\ln\\left(\\frac{0.9}{1-0.9}\\right) $$\n$$ a = \\ln\\left(\\frac{0.7}{0.3}\\right) - \\ln\\left(\\frac{0.9}{0.1}\\right) $$\n$$ a = \\ln\\left(\\frac{7}{3}\\right) - \\ln(9) $$\n我们计算各项的数值：\n$$ \\ln\\left(\\frac{7}{3}\\right) \\approx 0.84729786 $$\n$$ \\ln(9) \\approx 2.19722458 $$\n因此，截距 $a$ 为：\n$$ a \\approx 0.84729786 - 2.19722458 $$\n$$ a \\approx -1.34992672 $$\n四舍五入到四位有效数字，我们得到 $a = -1.350$。\n\n5.  **符号的解释**\n\n计算出的截距 $a$ 是负数。我们来分析其含义。校准后的对数优势比为 $\\operatorname{logit}(p') = a + \\operatorname{logit}(\\hat{p})$。由于 $a  0$，因此 $\\operatorname{logit}(p')  \\operatorname{logit}(\\hat{p})$。logit 函数是单调递增的，所以这个不等式意味着 $p'  \\hat{p}$。这意味着校准后的概率低于原始预测概率。该模型系统性地高估了风险，因为平均预测值 $\\bar{p}=0.9$ 高于观测患病率 $\\hat{\\pi}=0.7$。一个负的截距 $a$ 纠正了这种高估，这与问题陈述中的解释是一致的。", "answer": "$$\\boxed{-1.350}$$", "id": "4544791"}, {"introduction": "尽管单一的截距提供了宏观视角，但我们通常需要更详细的分析。Brier分数是一种**正常**评分规则，它能将预测误差分解为可靠性（即校准度）、解析度和不确定性，从而让我们对模型性能有更深入的理解。本练习要求你比较两个具有相同区分度（AUC）但校准度不同的模型，从而揭示为何良好的校准对于构建可信赖的模型至关重要。", "problem": "一个包含 $N = 1000$ 名成年重症监护室患者的医院队列被用来评估两个关于30天死亡率的二元预测模型，分别表示为模型 $A$ 和模型 $B$。对于每位患者 $i$，模型输出一个预测概率 $p_i \\in [0,1]$，对应事件 $y_i \\in \\{0,1\\}$。两个模型具有相同的受试者工作特征（ROC）曲线下面积（AUC），在此队列上测得的 AUC 均为 $0.85$。目标是通过从基本原理出发计算布里尔分数及其可靠性（reliability）和分辨率（resolution）分量来评估校准度，并在承认两个模型具有相同的由AUC衡量的区分度的情况下，比较它们的校准度。\n\n现提供每个模型的摘要数据，这些数据是通过将患者按模型自身的预测概率分组到不同的预测区间（bin）中得到的。对于每个模型中的每个区间 $j$，给出了患者数量 $n_j$，该区间内所有患者的共同预测概率 $p_j$，以及观测到的事件数 $e_j = \\sum_{i \\in \\text{bin } j} y_i$。队列中的总事件数为 $\\sum_j e_j = 210$，因此队列的事件发生率为 $\\bar{y} = 0.21$。\n\n对于模型 $A$，其区间为：\n- 区间 $1$：$n_1^{A} = 200$, $p_1^{A} = 0.05$, $e_1^{A} = 10$。\n- 区间 $2$：$n_2^{A} = 300$, $p_2^{A} = 0.10$, $e_2^{A} = 30$。\n- 区间 $3$：$n_3^{A} = 250$, $p_3^{A} = 0.20$, $e_3^{A} = 50$。\n- 区间 $4$：$n_4^{A} = 150$, $p_4^{A} = 0.40$, $e_4^{A} = 60$。\n- 区间 $5$：$n_5^{A} = 100$, $p_5^{A} = 0.60$, $e_5^{A} = 60$。\n\n对于模型 $B$，其区间为：\n- 区间 $1$：$n_1^{B} = 250$, $p_1^{B} = 0.15$, $e_1^{B} = 20$。\n- 区间 $2$：$n_2^{B} = 250$, $p_2^{B} = 0.20$, $e_2^{B} = 35$。\n- 区间 $3$：$n_3^{B} = 200$, $p_3^{B} = 0.25$, $e_3^{B} = 60$。\n- 区间 $4$：$n_4^{B} = 200$, $p_4^{B} = 0.35$, $e_4^{B} = 70$。\n- 区间 $5$：$n_5^{B} = 100$, $p_5^{B} = 0.55$, $e_5^{B} = 25$。\n\n从布里尔分数是预测概率与观测二元结果之间的均方误差这一定义出发，通过对各区间进行正确汇总来计算每个模型的布里尔分数。然后，使用从基本原理推导出的不确定性（uncertainty）、可靠性（reliability）和分辨率（resolution）的经典分解，计算每个模型的可靠性和分辨率分量，并用它们来解释哪个模型的校准度更好。最后，报告布里尔分数的数值差异 $\\Delta = \\text{BS}_{B} - \\text{BS}_{A}$。将最终数值答案四舍五入到四位有效数字。不需要单位。", "solution": "问题要求基于校准度来评估和比较两个预测模型，即模型 $A$ 和模型 $B$。这两个模型具有相同的区分度，表现为其受试者工作特征曲线下面积（AUC）均为 $0.85$。本次评估的主要工具是布里尔分数及其分解为可靠性、分辨率和不确定性。\n\n首先，我们为一组包含 $N$ 个预测的集合定义布里尔分数（BS）。对于每位患者 $i$，我们有一个预测概率 $p_i$ 和一个二元结果 $y_i \\in \\{0, 1\\}$。布里尔分数是预测的均方误差：\n$$ \\text{BS} = \\frac{1}{N} \\sum_{i=1}^{N} (p_i - y_i)^2 $$\n数据以分区间格式提供。对于每个区间 $j$（从 $1$ 到 $K$），我们有 $n_j$ 名患者，一个共同的预测概率 $p_j$，以及 $e_j$ 个观测事件。患者总数为 $N = \\sum_{j=1}^{K} n_j$。区间 $j$ 中的观测事件率（或平均结果）为 $\\bar{y}_j = e_j / n_j$。布里尔分数可以从分区间数据计算如下：\n$$ \\text{BS} = \\frac{1}{N} \\sum_{j=1}^{K} \\sum_{i \\in \\text{bin } j} (p_j - y_i)^2 = \\frac{1}{N} \\sum_{j=1}^{K} \\left( e_j(p_j-1)^2 + (n_j - e_j)(p_j-0)^2 \\right) $$\n这可以简化为：\n$$ \\text{BS} = \\frac{1}{N} \\sum_{j=1}^{K} (n_j p_j^2 - 2 p_j e_j + e_j) $$\n\n布里尔分数可以分解为三个分量：\n$$ \\text{BS} = \\text{可靠性} - \\text{分辨率} + \\text{不确定性} $$\n设 $\\bar{y}$ 为队列中的总体事件率，$\\bar{y} = (\\sum e_j) / N$。\n对于分区间数据，这些分量的定义如下：\n1.  **可靠性 (REL)**：衡量校准误差。它是各区间中预测概率与观测事件率之间差异的加权均方值。值越低表示校准度越好。\n    $$ \\text{REL} = \\frac{1}{N} \\sum_{j=1}^{K} n_j (p_j - \\bar{y}_j)^2 $$\n2.  **分辨率 (RES)**：衡量模型将患者分到具有不同结果率的组中的能力。它是各区间特定事件率与总体事件率之间差异的加权均方值。值越高越好。\n    $$ \\text{RES} = \\frac{1}{N} \\sum_{j=1}^{K} n_j (\\bar{y}_j - \\bar{y})^2 $$\n3.  **不确定性 (UNC)**：表示数据集中结果的内在不确定性，与模型无关。它是二元结果的方差。\n    $$ \\text{UNC} = \\bar{y}(1 - \\bar{y}) $$\n\n首先，我们计算整个队列的参数。患者总数为 $N = 1000$。给定的事件总数为 $\\sum e_j = 210$。总体事件率为：\n$$ \\bar{y} = \\frac{210}{1000} = 0.21 $$\n不确定性分量对两个模型是相同的，仅取决于数据集：\n$$ \\text{UNC} = 0.21 \\times (1 - 0.21) = 0.21 \\times 0.79 = 0.1659 $$\n\n接下来，我们分析模型 $A$。我们首先计算每个区间的观测事件率 $\\bar{y}_j^A = e_j^A / n_j^A$。\n- 区间 $1$：$\\bar{y}_1^A = 10 / 200 = 0.05$。这等于 $p_1^A = 0.05$。\n- 区间 $2$：$\\bar{y}_2^A = 30 / 300 = 0.10$。这等于 $p_2^A = 0.10$。\n- 区间 $3$：$\\bar{y}_3^A = 50 / 250 = 0.20$。这等于 $p_3^A = 0.20$。\n- 区间 $4$：$\\bar{y}_4^A = 60 / 150 = 0.40$。这等于 $p_4^A = 0.40$。\n- 区间 $5$：$\\bar{y}_5^A = 60 / 100 = 0.60$。这等于 $p_5^A = 0.60$。\n\n对于模型 $A$，每个区间中的观测事件率都与该区间的预测概率相同（对于所有 $j$，$\\bar{y}_j^A = p_j^A$）。这表明其校准度是完美的。我们现在计算各个分量。\n模型 $A$ 的可靠性：\n$$ \\text{REL}_A = \\frac{1}{1000} \\sum_{j=1}^{5} n_j^A (p_j^A - \\bar{y}_j^A)^2 = \\frac{1}{1000} \\sum_{j=1}^{5} n_j^A (0)^2 = 0 $$\n模型 $A$ 的分辨率：\n$$ \\text{RES}_A = \\frac{1}{1000} \\sum_{j=1}^{5} n_j^A (\\bar{y}_j^A - \\bar{y})^2 $$\n$$ \\text{RES}_A = \\frac{1}{1000} [ 200(0.05 - 0.21)^2 + 300(0.10 - 0.21)^2 + 250(0.20 - 0.21)^2 + 150(0.40 - 0.21)^2 + 100(0.60 - 0.21)^2 ] $$\n$$ \\text{RES}_A = \\frac{1}{1000} [ 200(-0.16)^2 + 300(-0.11)^2 + 250(-0.01)^2 + 150(0.19)^2 + 100(0.39)^2 ] $$\n$$ \\text{RES}_A = \\frac{1}{1000} [ 200(0.0256) + 300(0.0121) + 250(0.0001) + 150(0.0361) + 100(0.1521) ] $$\n$$ \\text{RES}_A = \\frac{1}{1000} [ 5.12 + 3.63 + 0.025 + 5.415 + 15.21 ] = \\frac{29.4}{1000} = 0.0294 $$\n模型 $A$ 的布里尔分数：\n$$ \\text{BS}_A = \\text{REL}_A - \\text{RES}_A + \\text{UNC} = 0 - 0.0294 + 0.1659 = 0.1365 $$\n\n现在，我们分析模型 $B$。我们计算每个区间的观测事件率 $\\bar{y}_j^B = e_j^B / n_j^B$。\n- 区间 $1$：$\\bar{y}_1^B = 20 / 250 = 0.08$。此处 $p_1^B = 0.15$。\n- 区间 $2$：$\\bar{y}_2^B = 35 / 250 = 0.14$。此处 $p_2^B = 0.20$。\n- 区间 $3$：$\\bar{y}_3^B = 60 / 200 = 0.30$。此处 $p_3^B = 0.25$。\n- 区间 $4$：$\\bar{y}_4^B = 70 / 200 = 0.35$。此处 $p_4^B = 0.35$。\n- 区间 $5$：$\\bar{y}_5^B = 25 / 100 = 0.25$。此处 $p_5^B = 0.55$。\n\n对于模型 $B$，观测率 $\\bar{y}_j^B$ 不等于预测概率 $p_j^B$，表明存在校准误差。\n模型 $B$ 的可靠性：\n$$ \\text{REL}_B = \\frac{1}{1000} \\sum_{j=1}^{5} n_j^B (p_j^B - \\bar{y}_j^B)^2 $$\n$$ \\text{REL}_B = \\frac{1}{1000} [ 250(0.15 - 0.08)^2 + 250(0.20 - 0.14)^2 + 200(0.25 - 0.30)^2 + 200(0.35 - 0.35)^2 + 100(0.55 - 0.25)^2 ] $$\n$$ \\text{REL}_B = \\frac{1}{1000} [ 250(0.07)^2 + 250(0.06)^2 + 200(-0.05)^2 + 200(0)^2 + 100(0.30)^2 ] $$\n$$ \\text{REL}_B = \\frac{1}{1000} [ 250(0.0049) + 250(0.0036) + 200(0.0025) + 0 + 100(0.09) ] $$\n$$ \\text{REL}_B = \\frac{1}{1000} [ 1.225 + 0.9 + 0.5 + 0 + 9.0 ] = \\frac{11.625}{1000} = 0.011625 $$\n模型 $B$ 的分辨率：\n$$ \\text{RES}_B = \\frac{1}{1000} \\sum_{j=1}^{5} n_j^B (\\bar{y}_j^B - \\bar{y})^2 $$\n$$ \\text{RES}_B = \\frac{1}{1000} [ 250(0.08 - 0.21)^2 + 250(0.14 - 0.21)^2 + 200(0.30 - 0.21)^2 + 200(0.35 - 0.21)^2 + 100(0.25 - 0.21)^2 ] $$\n$$ \\text{RES}_B = \\frac{1}{1000} [ 250(-0.13)^2 + 250(-0.07)^2 + 200(0.09)^2 + 200(0.14)^2 + 100(0.04)^2 ] $$\n$$ \\text{RES}_B = \\frac{1}{1000} [ 250(0.0169) + 250(0.0049) + 200(0.0081) + 200(0.0196) + 100(0.0016) ] $$\n$$ \\text{RES}_B = \\frac{1}{1000} [ 4.225 + 1.225 + 1.62 + 3.92 + 0.16 ] = \\frac{11.15}{1000} = 0.01115 $$\n模型 $B$ 的布里尔分数：\n$$ \\text{BS}_B = \\text{REL}_B - \\text{RES}_B + \\text{UNC} = 0.011625 - 0.01115 + 0.1659 = 0.166375 $$\n\n解释：\n模型 $A$ 优于模型 $B$。尽管两者具有相同的区分能力（AUC$=0.85$），但它们的校准度差异显著。模型 $A$ 是完美校准的（$\\text{REL}_A = 0$），意味着其预测的概率是准确的。模型 $B$ 的校准度不佳（$\\text{REL}_B > 0$）。此外，模型 $A$ 具有更高的分辨率（$\\text{RES}_A > \\text{RES}_B$），表明它在将患者分层为不同风险组方面做得更好。模型 $A$ 卓越的校准度和分辨率导致了更低（更好）的总体布里尔分数（$\\text{BS}_A  \\text{BS}_B$）。因此，模型 $A$ 提供了更准确、更可靠的风险预测。\n\n最后，我们计算布里尔分数的差异：\n$$ \\Delta = \\text{BS}_{B} - \\text{BS}_{A} = 0.166375 - 0.1365 = 0.029875 $$\n四舍五入到四位有效数字，我们得到 $0.02988$。", "answer": "$$\\boxed{0.02988}$$", "id": "4544798"}, {"introduction": "在诊断和评估了模型的未校准问题之后，最后一步是进行修正。本动手编程练习将指导你实现逻辑斯蒂校准，这是一种调整模型输出概率的标准技术。然后，你将应用预期校准误差（ECE）等评估指标，来验证你的校准方法是否确实提高了模型的可信度。", "problem": "给定一组二元事件预测，其形式为预测风险和相应结果，以及一个逻辑校准映射的仿射参数。根据概率校准和适当评分规则的基本原理，实现一个程序，该程序可以重新校准预测概率，评估重新校准前后的期望校准误差 (ECE) 和 Brier 可靠性分量，并报告改进情况。所有计算必须在单位区间上以纯数学方式进行，不使用任何领域特定的启发式方法。不涉及任何物理单位。所有分数都应表示为小数。\n\n背景和定义：\n- 一个二元预测模型对一个事件 $Y \\in \\{0,1\\}$ 输出一个预测风险 $p \\in [0,1]$。校准映射 $g:[0,1] \\to [0,1]$ 将 $p$ 转换为重新校准的概率 $q = g(p)$。\n- 逻辑校准映射由对数几率域中的仿射变换和随后的逻辑 (sigmoid) 反向链接函数定义。给定 $\\alpha \\in \\mathbb{R}$ 和 $\\beta \\in \\mathbb{R}$。对于任何 $p \\in [0,1]$，定义 logit 函数 $\\ell(p) = \\log\\left(\\frac{p}{1-p}\\right)$ 和 sigmoid 函数 $\\sigma(z) = \\frac{1}{1+\\exp(-z)}$。为避免在 $p \\in \\{0,1\\}$ 处出现未定义的对数，首先将 $p$ 截断到 $[\\varepsilon, 1-\\varepsilon]$（对于一个小的 $\\varepsilon > 0$），记为 $p_{\\text{clip}} = \\min\\{\\max\\{p,\\varepsilon\\},1-\\varepsilon\\}$。然后计算\n$$\nq = g(p) = \\sigma\\left(\\alpha + \\beta \\ell(p_{\\text{clip}})\\right).\n$$\n- 期望校准误差 (ECE) 通过将区间 $[0,1]$ 划分为 $B$ 个等宽的箱来近似预测概率与经验事件频率之间的期望绝对差。设 $N$ 为预测总数，并令 $b \\in \\{1,\\dots,B\\}$ 为箱的索引，其边界为 $\\left[0,\\tfrac{1}{B}\\right), \\left[\\tfrac{1}{B},\\tfrac{2}{B}\\right), \\dots, \\left[\\tfrac{B-1}{B},1\\right]$。对于一组给定的预测 $r_i \\in [0,1]$（其中 $r_i$ 对于校准前是 $p_i$，对于校准后是 $q_i$）和结果 $y_i \\in \\{0,1\\}$，设 $n_b$ 是落入箱 $b$ 的索引 $i$ 的数量，$\\bar{r}_b$ 是箱 $b$ 中 $r_i$ 的平均值，$\\bar{y}_b$ 是箱 $b$ 中 $y_i$ 的平均值。定义\n$$\n\\mathrm{ECE}(r,y;B) = \\sum_{b=1}^{B} \\frac{n_b}{N}\\left|\\bar{r}_b - \\bar{y}_b\\right|.\n$$\n空箱 ($n_b = 0$) 对总和的贡献为 $0$。\n- Brier 分数可以分解为不确定性、分辨率和可靠性。Brier 可靠性分量衡量了箱内的未校准度。使用与上述相同的分箱和表示法，定义 Brier 可靠性为\n$$\n\\mathrm{Rel}(r,y;B) = \\sum_{b=1}^{B} \\frac{n_b}{N}\\left(\\bar{r}_b - \\bar{y}_b\\right)^2.\n$$\n- 改进定义为误差的非负减少量：对于给定的度量 $M \\in \\{\\mathrm{ECE}, \\mathrm{Rel}\\}$，改进为 $M(r_{\\text{pre}},y;B) - M(r_{\\text{post}},y;B)$，其中 $r_{\\text{pre}} = p$ 且 $r_{\\text{post}} = q$。正值表示重新校准后校准效果更好。\n\n算法要求：\n- 按照定义实现逻辑校准映射 $g$。对每个测试用例使用提供的 $\\varepsilon$ 进行截断。\n- 实现将 $[0,1]$ 区间划分为 $B$ 个等宽的箱，最后一个箱为右侧包含，即箱区间为 $[0,\\tfrac{1}{B}), [\\tfrac{1}{B},\\tfrac{2}{B}), \\dots, [\\tfrac{B-1}{B},1]$。预测值 $r_i = 1$ 必须属于最后一个箱。\n- 计算校准前和校准后预测的 $\\mathrm{ECE}$ 和 $\\mathrm{Rel}$，并报告改进情况，即校准前的值减去校准后的值。\n- 对于每个测试用例，返回一个包含六个小数值的列表 $[e_{\\text{pre}}, e_{\\text{post}}, \\Delta e, \\rho_{\\text{pre}}, \\rho_{\\text{post}}, \\Delta \\rho]$，其中 $e_{\\text{pre}} = \\mathrm{ECE}(p,y;B)$，$e_{\\text{post}} = \\mathrm{ECE}(q,y;B)$，$\\Delta e = e_{\\text{pre}} - e_{\\text{post}}$，$\\rho_{\\text{pre}} = \\mathrm{Rel}(p,y;B)$，$\\rho_{\\text{post}} = \\mathrm{Rel}(q,y;B)$，以及 $\\Delta \\rho = \\rho_{\\text{pre}} - \\rho_{\\text{post}}$。将每个报告的值四舍五入到 $6$ 位小数。\n\n测试套件：\n- 案例 1 (正常路径)：$p = [0.02, 0.05, 0.08, 0.15, 0.22, 0.35, 0.50, 0.65, 0.80, 0.92]$，$y = [0, 0, 0, 0, 1, 0, 1, 1, 1, 1]$，$\\alpha = -0.2$，$\\beta = 1.3$，$B = 5$，$\\varepsilon = 10^{-12}$。\n- 案例 2 (恒等映射，无需截断)：$p = [0.10, 0.12, 0.18, 0.22, 0.28, 0.32, 0.38, 0.42, 0.55, 0.60, 0.72, 0.85]$，$y = [0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1]$，$\\alpha = 0$，$\\beta = 1$，$B = 6$，$\\varepsilon = 10^{-12}$。\n- 案例 3 (含截断的极端值)：$p = [0.00, 0.01, 0.05, 0.20, 0.40, 0.60, 0.80, 0.95, 0.99, 1.00]$，$y = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]$，$\\alpha = 0$，$\\beta = 0.5$，$B = 10$，$\\varepsilon = 10^{-9}$。\n- 案例 4 (负斜率)：$p = [0.05, 0.10, 0.15, 0.20, 0.85, 0.90, 0.95, 0.99]$，$y = [1, 1, 1, 1, 0, 0, 0, 0]$，$\\alpha = 0$，$\\beta = -1$，$B = 4$，$\\varepsilon = 10^{-12}$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。列表中的每个元素对应一个测试用例，其本身也是一个包含六个按规定四舍五入的小数值的列表。例如，抽象格式为 $[[e_{\\text{pre}}, e_{\\text{post}}, \\Delta e, \\rho_{\\text{pre}}, \\rho_{\\text{post}}, \\Delta \\rho], \\dots]$。", "solution": "该问题要求实现一个针对二元事件预测的逻辑校准过程，并评估其对校准度量的影响。解决方案分为三个主要部分：一个应用逻辑校准映射的函数，一个计算期望校准误差 (ECE) 和 Brier 可靠性 (Rel) 度量的函数，以及一个处理给定测试用例的主例程。\n\n首先，我们定义一个执行逻辑校准的函数。设 $p$ 为初始预测风险向量，$\\alpha$ 和 $\\beta$ 为对数几率空间中仿射变换的标量参数。对于给定的 $p$，重新校准的概率 $q$ 定义为 $q = g(p) = \\sigma(\\alpha + \\beta \\cdot \\ell(p_{\\text{clip}}))$。实现过程分为四个步骤：\n1.  **截断**：为防止 logit 函数中因 $p \\in \\{0, 1\\}$ 而出现 $\\log(0)$ 或除以零导致的数值不稳定性，每个预测 $p_i$ 首先被截断到区间 $[\\varepsilon, 1-\\varepsilon]$，其中 $\\varepsilon$ 是一个小的正常量。令 $p_{i, \\text{clip}} = \\min\\{\\max\\{p_i, \\varepsilon\\}, 1-\\varepsilon\\}$。\n2.  **Logit 变换**：每个截断后的预测 $p_{i, \\text{clip}}$ 使用 logit 函数 $\\ell(p) = \\log\\left(\\frac{p}{1-p}\\right)$ 变换到对数几率空间。经 logit 变换后的值为 $z_{i, \\text{logit}} = \\log\\left(\\frac{p_{i, \\text{clip}}}{1-p_{i, \\text{clip}}}\\right)$。\n3.  **仿射变换**：对 logit 值应用仿射变换：$z_i' = \\alpha + \\beta \\cdot z_{i, \\text{logit}}$。\n4.  **Sigmoid (反 Logit) 变换**：使用 sigmoid 函数 $\\sigma(z) = \\frac{1}{1 + \\exp(-z)}$ 将变换后的对数几率 $z_i'$ 映射回概率区间 $[0, 1]$，以获得重新校准的概率 $q_i = \\sigma(z_i')$。\n\n接下来，我们建立一个函数来计算 ECE 和 Brier 可靠性。这两个度量都基于对预测值的分箱。设 $r$ 为预测向量（校准前的 $p$ 或校准后的 $q$），$y$ 为真实二元结果向量。\n1.  **分箱**：将区间 $[0, 1]$ 划分为 $B$ 个等宽的箱：$[0, \\frac{1}{B}), [\\frac{1}{B}, \\frac{2}{B}), \\dots, [\\frac{B-1}{B}, 1]$。每个预测 $r_i$ 都被分配到一个箱中。预测值 $r_i$ 的箱索引 $b$ 由 $\\lfloor r_i \\cdot B \\rfloor$ 确定。为了遵守问题规范中最后一个箱为右侧包含（即 $r_i=1$ 落入最后一个箱）的要求，箱索引计算为 $\\min(B-1, \\lfloor r_i \\cdot B \\rfloor)$。\n2.  **分箱统计**：对于每个箱 $b \\in \\{1, \\dots, B\\}$，我们计算箱中的预测数量 $n_b$、箱中的平均预测值 $\\bar{r}_b$ 以及箱中的平均结果（经验频率）$\\bar{y}_b$。如果一个箱是空的（$n_b=0$），它对总误差的贡献为 $0$。\n3.  **度量计算**：\n    -   期望校准误差是所有箱中平均预测值与经验频率之间绝对差的加权平均值：\n        $$\n        \\mathrm{ECE}(r,y;B) = \\sum_{b=1}^{B} \\frac{n_b}{N}\\left|\\bar{r}_b - \\bar{y}_b\\right|\n        $$\n        其中 $N$ 是预测的总数。\n    -   Brier 可靠性分量是平方差的加权平均值：\n        $$\n        \\mathrm{Rel}(r,y;B) = \\sum_{b=1}^{B} \\frac{n_b}{N}\\left(\\bar{r}_b - \\bar{y}_b\\right)^2\n        $$\n\n主例程协调这些组件。对于每个测试用例，它执行以下操作序列：\n1.  它接受校准前预测向量 $p$ 和结果向量 $y$，以及参数 $\\alpha, \\beta, B, \\varepsilon$。\n2.  它使用校准前预测 $p$ 和结果 $y$ 调用度量计算函数，以计算 $e_{\\text{pre}} = \\mathrm{ECE}(p, y; B)$ 和 $\\rho_{\\text{pre}} = \\mathrm{Rel}(p, y; B)$。\n3.  它使用 $p, \\alpha, \\beta, \\varepsilon$ 调用逻辑校准函数，以获得校准后预测 $q$。\n4.  它使用校准后预测 $q$ 和结果 $y$ 调用度量计算函数，以计算 $e_{\\text{post}} = \\mathrm{ECE}(q, y; B)$ 和 $\\rho_{\\text{post}} = \\mathrm{Rel}(q, y; B)$。\n5.  它计算改进量为 $\\Delta e = e_{\\text{pre}} - e_{\\text{post}}$ 和 $\\Delta \\rho = \\rho_{\\text{pre}} - \\rho_{\\text{post}}$。\n6.  最后，它收集六个值 $[e_{\\text{pre}}, e_{\\text{post}}, \\Delta e, \\rho_{\\text{pre}}, \\rho_{\\text{post}}, \\Delta \\rho]$，将每个值四舍五入到 $6$ 位小数，并将结果列表附加到所有测试用例结果的集合中。\n\n这个结构化的、分步的过程确保了所有计算都根据所提供的数学定义进行，并且最终输出符合指定的格式。使用 `numpy` 数组有助于对所有步骤进行高效的向量化计算。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n\n    def apply_logistic_calibration(p, alpha, beta, eps):\n        \"\"\"\n        Applies the logistic calibration map to a set of predicted probabilities.\n        \n        Args:\n            p (np.ndarray): The initial predicted risks.\n            alpha (float): The intercept parameter.\n            beta (float): The slope parameter.\n            eps (float): The clipping parameter.\n            \n        Returns:\n            np.ndarray: The recalibrated probabilities.\n        \"\"\"\n        # Step 1: Clip p to avoid log(0) and division by zero.\n        p_clipped = np.clip(p, eps, 1.0 - eps)\n        \n        # Step 2: Compute logit.\n        logit_p = np.log(p_clipped / (1.0 - p_clipped))\n        \n        # Step 3: Apply affine transformation in log-odds space.\n        z_transformed = alpha + beta * logit_p\n        \n        # Step 4: Apply sigmoid to map back to probabilities.\n        q = 1.0 / (1.0 + np.exp(-z_transformed))\n        \n        return q\n\n    def calculate_calibration_metrics(r, y, B):\n        \"\"\"\n        Calculates the Expected Calibration Error (ECE) and Brier Reliability (Rel).\n        \n        Args:\n            r (np.ndarray): The predicted risks (pre or post calibration).\n            y (np.ndarray): The true binary outcomes.\n            B (int): The number of bins.\n            \n        Returns:\n            tuple: A tuple containing (ECE, Reliability).\n        \"\"\"\n        N = len(r)\n        if N == 0:\n            return 0.0, 0.0\n\n        # Step 1: Assign each prediction to a bin.\n        # The bin index for r_i is floor(r_i * B).\n        # We must handle the edge case r_i = 1.0, which should go into the last bin (B-1).\n        bin_indices = np.floor(r * B).astype(int)\n        bin_indices = np.minimum(bin_indices, B - 1)\n\n        ece_total = 0.0\n        rel_total = 0.0\n\n        # Step 2  3: Iterate through bins to compute stats and metrics.\n        for b in range(B):\n            # Find all predictions and outcomes in the current bin.\n            in_bin_mask = (bin_indices == b)\n            n_b = np.sum(in_bin_mask)\n\n            # If bin is empty, it contributes 0 to the sum.\n            if n_b == 0:\n                continue\n\n            r_in_bin = r[in_bin_mask]\n            y_in_bin = y[in_bin_mask]\n\n            # Compute average prediction and outcome in the bin.\n            r_bar_b = np.mean(r_in_bin)\n            y_bar_b = np.mean(y_in_bin)\n\n            # Accumulate ECE and Reliability.\n            ece_total += (n_b / N) * np.abs(r_bar_b - y_bar_b)\n            rel_total += (n_b / N) * (r_bar_b - y_bar_b)**2\n\n        return ece_total, rel_total\n\n    def process_case(p, y, alpha, beta, B, eps):\n        \"\"\"\n        Processes a single test case.\n        \"\"\"\n        # Convert inputs to numpy arrays for vectorized operations.\n        p_arr = np.array(p, dtype=float)\n        y_arr = np.array(y, dtype=float)\n\n        # Calculate pre-calibration metrics.\n        e_pre, rho_pre = calculate_calibration_metrics(p_arr, y_arr, B)\n        \n        # Perform recalibration.\n        q_arr = apply_logistic_calibration(p_arr, alpha, beta, eps)\n\n        # Calculate post-calibration metrics.\n        e_post, rho_post = calculate_calibration_metrics(q_arr, y_arr, B)\n\n        # Calculate improvements.\n        delta_e = e_pre - e_post\n        delta_rho = rho_pre - rho_post\n\n        # Package and round results.\n        result = [\n            round(e_pre, 6), round(e_post, 6), round(delta_e, 6),\n            round(rho_pre, 6), round(rho_post, 6), round(delta_rho, 6)\n        ]\n        return result\n\n    test_cases = [\n        # Case 1\n        (\n            [0.02, 0.05, 0.08, 0.15, 0.22, 0.35, 0.50, 0.65, 0.80, 0.92],\n            [0, 0, 0, 0, 1, 0, 1, 1, 1, 1],\n            -0.2, 1.3, 5, 1e-12\n        ),\n        # Case 2\n        (\n            [0.10, 0.12, 0.18, 0.22, 0.28, 0.32, 0.38, 0.42, 0.55, 0.60, 0.72, 0.85],\n            [0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1],\n            0.0, 1.0, 6, 1e-12\n        ),\n        # Case 3\n        (\n            [0.00, 0.01, 0.05, 0.20, 0.40, 0.60, 0.80, 0.95, 0.99, 1.00],\n            [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n            0.0, 0.5, 10, 1e-9\n        ),\n        # Case 4\n        (\n            [0.05, 0.10, 0.15, 0.20, 0.85, 0.90, 0.95, 0.99],\n            [1, 1, 1, 1, 0, 0, 0, 0],\n            0.0, -1.0, 4, 1e-12\n        )\n    ]\n\n    all_results = []\n    for case in test_cases:\n        p, y, alpha, beta, B, eps = case\n        result = process_case(p, y, alpha, beta, B, eps)\n        all_results.append(result)\n\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "4544765"}]}