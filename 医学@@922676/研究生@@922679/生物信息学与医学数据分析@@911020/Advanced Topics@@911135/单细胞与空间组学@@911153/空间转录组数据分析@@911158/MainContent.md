## 引言
空间转录组学作为一项革命性技术，通过同时捕获基因表达和其在组织内的空间位置信息，正在重塑我们对生物学系统的理解。它在分子层面连接了基因组学与组织病理学，为探索复杂的组织结构、[细胞异质性](@entry_id:262569)及细胞间相互作用提供了前所未有的分辨率。

然而，这项技术也带来了独特的分析挑战。其生成的数据不仅维度高、噪音大，更蕴含着复杂的空间结构信息。如何从这些数据中准确地分离生物学信号与技术伪影，并有效地解读基因表达与组织功能之间的空间关系，是当前生物信息学领域面临的关键知识缺口。

本文旨在系统性地介绍[空间转录组学](@entry_id:270096)数据分析的全过程。在**“原理与机制”**一章中，我们将深入探讨数据的基本构成、从原始测序到计数矩阵的处理流程，以及用于建模和识别空间模式的核心统计框架。接下来，在**“应用与交叉学科联系”**一章中，我们将展示这些分析方法如何在神经科学、肿瘤学等前沿领域中被用于揭示新的生物学机理。最后，**“动手实践”**部分将提供具体的编程练习，帮助读者将理论知识转化为实践技能。通过本文的学习，您将建立起一个从理论基础到应用实践的完整知识体系。

## 原理与机制

本章旨在深入阐述空间转录组学数据分析的核心原理与关键机制。我们将从数据的基本性质出发，系统地介绍数据从原始测序读段到可分析的表达矩阵的完[整流](@entry_id:197363)程，并详细探讨用于建模和解释空间基因表达模式的统计学框架。本章内容将为后续章节中更高级的应用分析奠定坚实的理论基础。

### 空间[转录组](@entry_id:274025)数据的基本构成

空间转录组学技术旨在同时捕获基因表达信息及其在组织内的二维或三维空间位置。理解这些数据的基本属性是所有后续分析的第一步。

#### 技术分野与空间分辨率

当前的[空间转录组学](@entry_id:270096)技术大致可分为两大类：**基于捕获点（spot-based）**的技术和**基于分子（molecule-based）**的技术。这两种技术在捕获机制、条形码策略和最终可实现的空间分辨率上存在根本差异。[@problem_id:4608969]

**基于捕获点**的技术，如10x Genomics的Visium平台，其核心是在载玻片上预先印刷一个[微阵列](@entry_id:270888)，阵列上布满了成千上万个微小的“捕获点”（spots）。每个捕获点都含有一组独特的**[空间条形码](@entry_id:267996)（spatial barcode）**。当组织切片被放置在阵列上并进行透化处理时，组织中的信使RNA（mRNA）分子会向下扩散并被其下方的捕获点捕获。同一捕获点捕获的所有mRNA分子都会被标记上相同的[空间条形码](@entry_id:267996)。经过测序后，我们可以得到每个捕获点的基因表达谱，即一个与特定空间位置相关联的基因表达向量。

**基于分子**的技术，如[MERFISH](@entry_id:191159)或10x Genomics的Xenium平台，则采用原位测序或成像策略。这些技术直接在组织切片内部对单个mRNA分子进行标记和解码。每个被解码的分子都会获得其自身独特的空间坐标。因此，这类技术产生的数据是一片“点云”，其中每个点都代表一个具有精确坐标的转录本。

这两种技术路径决定了**有效空间分辨率（effective spatial resolution）**的来源。有效分辨率是描述系统区分两个邻近[空间特征](@entry_id:151354)能力的综合度量，通常用一个等效的“模糊”宽度来量化，例如高斯分布的标准差（$\sigma_{\mathrm{eff}}$）或其对应的**半峰全宽（Full Width at Half Maximum, FWHM）**，其中 $\mathrm{FWHM} \approx 2.355 \sigma$。

在**基于捕获点**的系统中，有效分辨率主要由以下几个宏观因素决定：
1.  **捕获点尺寸（Spot Size）**：捕获点本身具有物理尺寸，例如直径为 $D_{\mathrm{spot}} = 55\,\mu\mathrm{m}$。这相当于对该区域内的所有信号进行平均，引入了一个与捕获点尺寸相关的模糊。我们可以将其近似为一个等效的高斯模糊，其标准差约为 $\sigma_{\mathrm{spot}} = D_{\mathrm{spot}}/4$。
2.  **捕获点间距（Spot Pitch）**：捕获点以一定的间距（例如 $P_{\mathrm{spot}} = 100\,\mu\mathrm{m}$）排列在阵列上。这种离散采样本身就限制了分辨率，无法解析小于该间距的结构。这可以被建模为一个宽度为 $P_{\mathrm{spot}}$ 的均匀分布模糊，其等效标准差为 $\sigma_{\mathrm{sampling}} = P_{\mathrm{spot}}/\sqrt{12}$。
3.  **[分子扩散](@entry_id:154595)（Molecular Diffusion）**：在透化过程中，mRNA分子会在组织内横向扩散一小段距离（例如，标准差 $\sigma_{\mathrm{diff}} = 8\,\mu\mathrm{m}$）才被捕获，这进一步增加了模糊效应。
4.  **光学对准分辨率（Optical Resolution）**：用于对齐组织学图像的光学系统分辨率（例如 $\sigma_{\mathrm{opt}} = 0.6\,\mu\mathrm{m}$）通常远高于上述因素，因此其影响可以忽略不计。

由于这些模糊源是独立的，总的有效方差是各项方差之和，即 $\sigma_{\mathrm{eff}}^2 = \sigma_{\mathrm{spot}}^2 + \sigma_{\mathrm{sampling}}^2 + \sigma_{\mathrm{diff}}^2$。在上述参数下，采样间距是决定分辨率的主导因素。

相比之下，在**基于分子**的系统中，分辨率由微观因素决定：
1.  **光学点扩散函数（Optical PSF）**：用于成像单个分子的光学系统的[衍射极限](@entry_id:193662)，例如 $\sigma_{\mathrm{opt}} = 0.25\,\mu\mathrm{m}$。
2.  **[单分子定位](@entry_id:174606)精度（Localization Precision）**：通过算法拟合分子荧光信号中心位置的精度，例如 $\sigma_{\mathrm{loc}} = 0.05\,\mu\mathrm{m}$。
3.  **固定前扩散（Pre-fixation Diffusion）**：分子在被化学固定前在细胞内的微小移动，例如 $\sigma_{\mathrm{diff}} = 0.2\,\mu\mathrm{m}$。

这些因素共同决定了单个分子定位的最终不确定性。然而，在实际分析中，为了生成类似[热图](@entry_id:273656)的表达图谱，研究者通常会将这些分子点云“分箱（binning）”到一个规则的网格中（例如，宽度为 $B = 5\,\mu\mathrm{m}$ 的正方形网格）。此时，**分箱尺寸**成为影响最终栅格化图[谱分辨率](@entry_id:263022)的主导因素，其引入的等效模糊标准差为 $\sigma_{\mathrm{bin}} = B/\sqrt{12}$。最终的有效分辨率由所有这些因素的方差叠加决定：$\sigma_{\mathrm{eff}}^2 = \sigma_{\mathrm{opt}}^2 + \sigma_{\mathrm{loc}}^2 + \sigma_{\mathrm{diff}}^2 + \sigma_{\mathrm{bin}}^2$。

#### 核心[数据结构](@entry_id:262134)

无论采用何种技术，一个典型的空间转录组学数据集最终都可以被组织成一个包含三个核心部分的[数据结构](@entry_id:262134)：基因表达计数矩阵、空间坐标和组织学图像。[@problem_id:4609004]

1.  **计数矩阵 (Count Matrix) $X$**：这是一个 $n \times p$ 的矩阵，其中 $n$ 是空间捕获单元（例如，spots或bins）的数量，$p$ 是基因的数量。矩阵中的元素 $X_{ij}$ 是一个非负整数，代表在第 $i$ 个捕获单元中检测到的基因 $j$ 的转录本数量。因此，其定义域为 $X \in \mathbb{N}^{n \times p}$。

2.  **空间坐标矩阵 (Spatial Coordinates) $S$**：这是一个 $n \times 2$ (对于2D数据) 的矩阵，存储了 $n$ 个捕获单元在组织切片物理空间中的坐标 $(x, y)$，通常以微米（$\mu\mathrm{m}$）为单位。矩阵 $S$ 的第 $i$ 行 $(S_{i1}, S_{i2})$ 对应于计数矩阵 $X$ 的第 $i$ 行所代表的那个捕获单元。因此，其定义域为 $S \in \mathbb{R}^{n \times 2}$。$X$ 和 $S$ 的行之间存在着严格的[一一对应](@entry_id:143935)关系。

3.  **组织学图像 (Histology Image) $I$**：这是一个高分辨率的组织病理学图像，例如用苏木精和伊红（HE）染色的组织病理学图像。它通常表示为一个三维数组，维度为 $H \times W \times C$，其中 $H$ 和 $W$ 分别是图像的高度和宽度（以像素为单位），$C$ 是颜色通道数（例如，对于RGB图像，$C=3$）。像素值是连续的强度值。因此，其定义域为 $I \in \mathbb{R}^{H \times W \times C}$。

这三个数据对象之间的联系是通过**空间配准（spatial registration）**建立的。由于坐标矩阵 $S$ 使用的是物理单位（微米），而图像 $I$ 使用的是像素单位，我们需要一个变换函数 $T: \mathbb{R}^{2} \rightarrow \{1,\dots,H\} \times \{1,\dots,W\}$，它能将物理[坐标映射](@entry_id:747874)到像素坐标。对于每个捕获单元 $i$，其在图像上的中心位置是 $T(S_i)$。由于捕获单元有实际大小，它对应于图像上的一个**区域**或**图块**（patch）$R_i$，而不仅仅是一个像素点。这个图块 $R_i$ 可以是围绕 $T(S_i)$ 的一个圆形或方形区域。通过这种方式，我们可以将第 $i$ 个捕获单元的基因表达向量 $X_{i,\cdot}$ 与其对应的图像特征（从 $I$ 的 $R_i$ 区域提取）联系起来，从而实现基因表达与组织形态学的多模态整合分析。

### 从原始测[序数](@entry_id:150084)据到计数矩阵

在获得上述规范化的数据结构之前，必须经过一系列复杂的生物信息学处理步骤，将测序仪产生的原始数据转化为可用的空间基因表达计数矩阵。这个流程对于保证[数据质量](@entry_id:185007)和后续分析的准确性至关重要。[@problem_id:4385427]

一个典型的处理流程包含以下关键步骤：

1.  **碱基识别 (Basecalling)**：测序仪通过捕捉荧光信号来确定DNA序列。Basecalling是将这些原始信号转换成我们熟悉的A、T、C、G碱基序列的过程。这个过程并非完美，会以一定的错误率（例如，每千个碱基中出现几个错误）引入测序错误。

2.  **条形码解析与校正 (Barcode Parsing and Correction)**：对于基于捕获点的技术，测序读段（read）的一部分编码了[空间条形码](@entry_id:267996)和**[唯一分子标识符](@entry_id:192673)（Unique Molecular Identifier, UMI）**。首先需要从读段中解析出这两部分序列。由于测序错误，解析出的[空间条形码](@entry_id:267996)可能与预先设计的“白名单（whitelist）”中的任何一个都不完全匹配。
    
    为了校正这些错误，可以利用白名单中条形码的设计特性。一个好的白名单会确保任意两个条形码之间的**[汉明距离](@entry_id:157657)（Hamming distance）**——即两个等长字符串在对应位置上不同字符的数量——足够大。例如，如果[最小汉明距离](@entry_id:272322) $d_{\min} = 3$，这意味着至少需要3个碱基突变才能将一个合法的条形码变成另一个合法的条形码。这个特性保证了，如果一个观测到的条形码与某个白名单条形码的[汉明距离](@entry_id:157657)为1，我们可以有很高的[置信度](@entry_id:267904)将其校正为这个白名单条形码，而不会错误地归属到另一个条形码上。那些距离任何白名单条形码都大于1的读段通常会被丢弃，以避免潜在的“跨点污染”（即错误地将一个点的读段分配给另一个点）。一个合理的错误校正策略对于准确定位至关重要。

3.  **基因比对 (Gene Alignment)**：读段的另一部分是cDNA序列，它对应于原始的mRNA转录本。这一部分需要与参考转录组或基因组进行比对，以确定它来源于哪个基因。为了准确量化，通常只使用那些能够**唯一比对（uniquely mapping）**到某个基因上的读段。对于真核生物，比对算法还需要具备“剪接感知”（spliced-aware）能力，以正确处理跨越外显子-内含子边界的读段。

4.  **[UMI去重](@entry_id:756286) (UMI Deduplication)**：在文库构建过程中，原始的mRNA分子会经过PCR扩增，产生大量的复制品。如果不加处理，高表达的基因或扩增效率高的分子会被过度计数。UMI的引入就是为了解决这个问题。在同一个捕获点，对于同一个基因，所有具有相同UMI序列的读段都被认为是源自同一个原始mRNA分子。因此，通过对UMI进行去重（即每个 spot-gene-UMI 组合只计数一次），我们可以更准确地估计原始分子的数量，消除PCR扩增偏好。
    
    UMI本身也可能存在测序错误。因此，在去重时，简单的精确匹配可能不够理想。更高级的策略会采用基于网络的“邻接（adjacency）”方法，将[汉明距离](@entry_id:157657)为1的UMI也合并，认为它们可能源自同一个原始UMI的测序错误变体。然而，UMI的[序列空间](@entry_id:153584)是有限的。对于高表达的基因，两个不同的原始分子被偶然标记上相同或相似UMI的概率（称为**UMI碰撞**）会增加，导致轻微的计数偏低。UMI的长度（例如 $L_u = 10$）决定了其[序列空间](@entry_id:153584)的大小（$4^{10}$），这个大小必须足够大以将在单个基因和单个捕获点中UMI碰撞的概率控制在可接受的范围内。

最终，通过以上步骤，我们可以为每个捕获点（spot）和每个基因构建一个精确的、经过校正的分子计数，从而形成计数矩阵 $X$。

### 空间基因表达的统计建模

原始的计数矩阵 $X$ 包含了技术噪音和生物变异。为了从中提取有意义的生物学洞见，必须采用恰当的[统计模型](@entry_id:755400)。

#### [数据归一化](@entry_id:265081)与变换

原始计数值受到不同捕获点测序深度（即**文库大小**）差异的严重影响。一个捕获点的总读段数越多，其每个基因的计数值也倾向于越高。为了进行有意义的比较，必须进行**归一化（normalization）**。[@problem_id:4609013]

最常用的归一化方法之一是**每百万计数（Counts-Per-Million, CPM）**。对于第 $i$ 个捕获点的基因 $j$，其CPM值计算如下：
$$
\text{CPM}_{ij} = \frac{x_{ij}}{s_i} \times 10^6
$$
其中 $x_{ij}$ 是原始计数值，而 $s_i = \sum_{j=1}^{p} x_{ij}$ 是第 $i$ 个捕获点的总计数（文库大小）。

虽然CPM校正了文库大小的差异，但它也改变了数据的统计特性。假设原始计数 $x_{ij}$ 在给定文库大小 $s_i$ 和真实相对丰度 $\theta_{ij}$ 的条件下，遵循泊松分布 $x_{ij} \sim \text{Poisson}(s_i \theta_{ij})$。那么，CPM值的条件均值为 $\mathbb{E}[\text{CPM}_{ij} | s_i] = 10^6 \theta_{ij}$，这与文库大小无关，达到了归一化的目的。然而，其[条件方差](@entry_id:183803)为 $\operatorname{Var}(\text{CPM}_{ij} | s_i) = \frac{(10^6)^2 \theta_{ij}}{s_i}$。这个方差与文库大小 $s_i$ 成反比，意味着文库大小越大的点，其CPM值的方差越小。这种方差不恒定的现象称为**异方差性（heteroscedasticity）**，它违反了许多标准统计检验（如t检验或[ANOVA](@entry_id:275547)）的基本假设。

为了稳定方差并使数据更接近正态分布，通常会对归一化后的数据进行**对数变换**。由于计数值可能为零，直接取对数是不可行的。因此，通常会加上一个小的正常数（称为**伪计数，pseudocount** $c$）再进行变换：
$$
y_{ij} = \ln(\text{CPM}_{ij} + c)
$$
对数变换是一种[方差稳定变换](@entry_id:273381)。根据**Delta方法**的[一阶近似](@entry_id:147559)，变换后数据的方差约为：
$$
\operatorname{Var}(y_{ij} | s_i) \approx \frac{\operatorname{Var}(\text{CPM}_{ij} | s_i)}{(\mathbb{E}[\text{CPM}_{ij} | s_i] + c)^2} = \frac{(10^6)^2 \theta_{ij}}{s_i (10^6 \theta_{ij} + c)^2}
$$
可以看到，尽管对数变换改变了均值-方差关系，但变换后数据的方差仍然依赖于文库大小 $s_i$。因此，它并不能完全消除异方差性，但在许多情况下可以显著减弱它，使数据更适用于那些假设[方差齐性](@entry_id:167143)的模型。此外，根据**琴生不等式（Jensen's inequality）**，由于对数函数是凹函数，变换后数据的[期望值](@entry_id:150961)总是小于或等于对[期望值](@entry_id:150961)进行变换的结果，即 $\mathbb{E}[y_{ij}] \le \ln(\mathbb{E}[\text{CPM}_{ij}] + c)$。

#### [批次效应](@entry_id:265859)的校正

在涉及多张载玻片或不同实验批次的大型研究中，**批次效应（batch effects）**是另一个主要的变异来源。这些源于技术差异的系统性变异会掩盖真实的生物学信号。在空间转录组学中，常见的[批次效应](@entry_id:265859)包括：[@problem_id:4385506]

*   **载玻片间的化学差异**：不同载玻片的涂层、捕获探针的效率可能存在微小差异。
*   **组织处理差异**：不同批次的组织在固定时间、储存条件等方面可能不同，影响RNA的质量和提取效率。
*   **[测序深度](@entry_id:178191)差异**：如前所述，即使在同一张载玻片上，不同捕获点的测序深度也可能不均匀。

处理这些效应的理想方法是在一个统一的[统计模型](@entry_id:755400)中对它们进行显式建模。一个强大的框架是**[广义线性模型](@entry_id:171019)（Generalized Linear Model, GLM）**。例如，我们可以为每个基因构建一个负二项（Negative Binomial, NB）GLM，其形式如下：
$$
\log \mathbb{E}[Y_{gsi}] = \beta_{g0} + \alpha_i + \gamma_g p_i + f_{gi}(\mathbf{x}_s) + \log L_{si}
$$
在这个模型中：
*   $Y_{gsi}$ 是基因 $g$ 在载玻片 $i$ 的捕获点 $s$ 的原始计数值，遵循[负二项分布](@entry_id:262151)。
*   $\log \mathbb{E}[Y_{gsi}]$ 是[期望计数](@entry_id:162854)的对数。
*   $\beta_{g0}$ 是基因 $g$ 的基准表达水平。
*   $\alpha_i$ 是一个**载玻片特异性截距**，用于捕获由载玻片 $i$ 引起的系统性偏差。
*   $p_i$ 是一个可测量的处理协变量（如固定时间），$\gamma_g$ 是其对基因 $g$ 表达的影响系数。
*   $f_{gi}(\mathbf{x}_s)$ 是一个关于空间坐标 $\mathbf{x}_s$ 的平滑函数，用于捕获和保留**真实的生物空间模式**。这个项至关重要，它代表我们想要研究的信号，因此在校正过程中不能被移除。
*   $\log L_{si}$ 是一个**偏移项（offset）**，其中 $L_{si}$ 是该捕获点的文库大小。这是在GLM框架下校正[测序深度](@entry_id:178191)的标准方法。

通过在一个模型中同时估计所有这些参数，我们可以有效地分离和校正技术变异，同时保留并准确估计我们感兴趣的生物学空间变异。

#### 过度离散的建模：泊松分布与负二项分布

在对计数数据进行建模时，选择合适的概率分布至关重要。一个自然的起点是**泊松分布（Poisson distribution）**，它描述了在固定时间或空间内[独立事件](@entry_id:275822)发生的次数。在泊松分布中，方差严格等于均值（$\operatorname{Var}(X) = \mu$）。[@problem_id:4609003]

然而，在真实的[转录组](@entry_id:274025)数据中，我们几乎总是观察到**过度离散（overdispersion）**的现象，即数据的方差显著大于其均值。这源于多种生物和技术因素。例如，基因表达的“爆发式”转录过程（transcriptional bursting）会导致内在的生物学变异。此外，细胞组成、捕获效率等未被观察到的异质性也会增加数据的变异性。

为了解释[过度离散](@entry_id:263748)，**[负二项分布](@entry_id:262151)（Negative Binomial, NB distribution）**成为了RNA[测序数据分析](@entry_id:162667)（包括[空间转录组学](@entry_id:270096)）的标准模型。NB分布可以被看作是一个**Gamma-泊松混合模型**。其思想是，我们不再假设每个捕获点的表达率 $\lambda_s$ 是一个固定的均值 $\mu$，而是认为它本身是一个遵循Gamma分布的随机变量。这种层级模型允许不同捕-获点的真实表达率存在差异。

当我们将这个变化的$\lambda_s$在所有捕获点上积分掉后，得到的[边际分布](@entry_id:264862)就是负二项分布。其均值仍然是 $\mu$，但方差具有更灵活的形式：
$$
\operatorname{Var}(X) = \mu + \frac{\mu^2}{\theta}
$$
这里的 $\theta$ 是一个**[离散度](@entry_id:168823)参数（dispersion parameter）**，它控制着方差超出均值的程度。$\mu^2/\theta$ 这一项正比于底层表达率$\lambda_s$的方差，完美地解释了过度离散的来源——即不同观测单元之间真实表达率的异质性。
*   当 $\theta \to \infty$ 时，$\mu^2/\theta \to 0$，方差趋近于均值 $\mu$，NB分布退化为泊松分布。
*   当 $\theta$ 较小时，过度离散程度较高，方差远大于均值。

因此，通过估计每个基因的[离散度](@entry_id:168823)参数 $\theta$，N[B模型](@entry_id:159413)能够灵活地适应不同基因的变异特性，为后续的差异表达或[空间分析](@entry_id:183208)提供一个更稳健的统计基础。

### 空间结构的分析

在对数据进行恰当的建模和校正后，我们便可以开始探究其核心的科学问题：基因表达在组织空间中是如何组织的？

#### 空间邻域的表示：邻接图

要分析空间模式，首先需要一种形式化的方式来定义“哪些捕获点是相邻的”。最常用的方法是构建一个**图（graph）**，其中每个捕获点是一个节点（node），节点之间的连边（edge）表示它们在空间上的邻近关系。这个图的结构可以用一个**[邻接矩阵](@entry_id:151010)（adjacency matrix）** $A$ 来表示。如果节点 $i$ 和 $j$ 之间有连边，则 $A_{ij}=1$，否则 $A_{ij}=0$。[@problem_id:4608991]

构建空间邻接图主要有以下几种方法，它们各有优缺点：

1.  **半径图 (Radius Graph)**：给定一个半径 $r$，如果两个捕获点 $i$ 和 $j$ 之间的欧氏距离 $\| \mathbf{x}_i - \mathbf{x}_j \|_2 \le r$，则在它们之间建立一条连边。
    *   **优点**：概念简单，强制执行了严格的物理距离局部性。
    *   **缺点**：对半径 $r$ 的选择非常敏感。$r$ 太小可能导致图不连通（尤其是在捕获点稀疏的区域）；$r$ 太大则可能引入不相关的远距离连接，使图过于稠密，失去局部性信息。

2.  **$k$-近邻图 (k-Nearest Neighbors, k-NN Graph)**：对于每个捕获点 $i$，找到其空间上最近的 $k$ 个邻居。由于“近邻”关系不是对称的（$j$ 是 $i$ 的近邻，不代表 $i$ 也是 $j$ 的近邻），需要一个对称化规则来创建[无向图](@entry_id:270905)。最常用的规则是**并集规则**：只要 $j$ 是 $i$ 的 $k$-近邻之一，**或者** $i$ 是 $j$ 的 $k$-近邻之一，就在它们之间建立连边。
    *   **优点**：能自适应捕获点密度的变化。在稀疏区域，它会自动连接到更远的邻居，从而更好地保持图的连通性。
    *   **缺点**：可能引入物理上很长的边，破坏严格的局部性。$k$ 的选择会影响图的性质。

3.  **[德劳内三角剖分](@entry_id:266197)图 (Delaunay Triangulation Graph)**：这是一种基于计算几何的无参数方法。它构建的[三角网格](@entry_id:756169)满足“空[外接圆](@entry_id:165300)”属性：任何一个三角形的[外接圆](@entry_id:165300)内部都不包含任何其他点。这个图与捕获点集的**[沃罗诺伊图](@entry_id:263046)（Voronoi diagram）**互为对偶。
    *   **优点**：无参数，能自适应点集的局部密度，并且保证图的[平面性](@entry_id:274781)（边不交叉）和在点集凸包上的连通性。
    *   **缺点**：对边界点敏感，可能会在组织样本的边缘产生非常长的、生物学意义不大的边。

选择哪种图构建方法取决于具体的分析目标和[组织结构](@entry_id:146183)的特点。

#### [空间自相关](@entry_id:177050)的量化：[莫兰指数](@entry_id:192667)I

有了空间邻接图，我们就可以量化基因表达的**[空间自相关](@entry_id:177050)（spatial autocorrelation）**，即一个基因在邻近位置的表达值是否比随机预期的更相似（正相关）或更不相似（负相关）。**[莫兰指数](@entry_id:192667)I（[Moran's I](@entry_id:192667)）**是衡量全局[空间自相关](@entry_id:177050)性最经典的统计量。[@problem_id:4609022]

对于一个基因，其[莫兰指数](@entry_id:192667) $I$ 的定义如下：
$$
I = \frac{n}{\sum_{i,j} w_{ij}} \frac{\sum_{i=1}^{n}\sum_{j=1}^{n} w_{ij} (x_i - \bar{x}) (x_j - \bar{x})}{\sum_{i=1}^{n} (x_i - \bar{x})^2}
$$
其中：
*   $n$ 是捕获点的总数。
*   $x_i$ 是基因在捕获点 $i$ 的表达值（通常是经过归一化和变换的）。
*   $\bar{x}$ 是该基因在所有捕获点的平均表达值。
*   $w_{ij}$ 是空间权重矩阵 $W$ 的元素，它量化了捕获点 $i$ 和 $j$ 之间的邻近程度。如果使用二元的邻接矩阵 $A$，$w_{ij}$ 可以就是 $A_{ij}$。

[莫兰指数](@entry_id:192667) $I$ 的解释如下：
*   **$I > 0$**：表示**正[空间[自相](@entry_id:177050)关](@entry_id:138991)**。分子中的乘积项 $(x_i - \bar{x})(x_j - \bar{x})$ 在邻近点（$w_{ij}$较大）具有相似表达值（同在均值之上或之下）时为正。这表明高值与高值聚集，低值与低值聚集，形成“斑块”或“热点”模式。
*   **$I  0$**：表示**负[空间自相关](@entry_id:177050)**。这表明邻近点的表达值倾向于不相似（一个在均值之上，一个在均值之下），形成“棋盘格”状的分散模式。
*   **$I \approx -1/(n-1)$**：表示**无[空间自相关](@entry_id:177050)**。在这种情况下，表达值在空间上随机分布。在没有空间模式的零假设下，[莫兰指数](@entry_id:192667) $I$ 的[期望值](@entry_id:150961)正是 $-1/(n-1)$。

值得注意的是，[莫兰指数](@entry_id:192667) $I$ 的取值范围不一定是 $[-1, 1]$，其具体范围依赖于权重矩阵 $W$ 的特征值。此外，当一个基因在所有位置的表达值都相同时，其方差（分母）为零，[莫兰指数](@entry_id:192667) $I$ 未定义，因为对于没有空间变异的变量，讨论[空间自相关](@entry_id:177050)是没有意义的。

#### 识别空间变异基因 (SVG)

识别那些表达模式与空间[组织结构](@entry_id:146183)显著相关的基因，即**空间变异基因（Spatially Variable Genes, SVGs）**，是[空间转录组学分析](@entry_id:173771)的一项核心任务。这本质上是一个[假设检验](@entry_id:142556)问题。[@problem_id:4608990]

*   **零假设 ($H_0$)**：该基因的表达在空间上是随机分布的，即其表达水平与空间坐标无关。
*   **备择假设 ($H_a$)**：该基因的表达存在一种非随机的空间模式。

不同的SVG识别方法采用了不同的[统计模型](@entry_id:755400)来对备择假设建模，并与零假设进行比较：

1.  **SpatialDE**：该方法适用于经过归一化和变换后的近似连续数据。它使用**高斯过程（Gaussian Process, GP）**来建模。GP是一种对函数进行建模的灵活的非参数贝叶斯方法。SpatialDE将基因的表达模式分解为空间分量和非空间噪声分量。其[备择假设](@entry_id:167270)是空间分量存在（即其方差大于零），而零假设是空间分量不存在（方差为零）。检验通过比较包含空间[协方差核](@entry_id:266561)（如[径向基函数核](@entry_id:166868)）的GP模型与仅包含独立噪声的模型的似然来进行。

2.  **SPARK/SPARK-X**：这类方法直接对**原始计数数据**进行建模，保留了数据的统计特性。它们采用**广义线性混合模型（Generalized Linear Mixed Model, GLMM）**，例如负二项混合模型。模型中包含一个**空间随机效应项**，其协方差结构由空间[协方差核](@entry_id:266561)函数定义。检验SVG等价于检验这个空间随机效应项的方差是否显著大于零。如果方差为零，则模型退化为一个不包含空间信息的标准GLMM。

3.  **trendsceek**：该方法采取了完全不同的**非参数**路径。它将基因表达值视为空间点过程中的“标记（mark）”，将捕获点坐标视为“点（point）”。然后，它检验标记（表达值）和点（空间位置）之间是否存在依赖关系。它通过计算对特定空间模式（如聚集或梯度）敏感的统计量，并通过**[置换检验](@entry_id:175392)（permutation test）**来评估其显著性——即，通过随机打乱基因表达值与空间位置的对应关系来生成零分布。这种方法不依赖于任何关于数据分布的假设。

这些方法的选择取决于研究者对数据性质的假设和分析的侧重点。

### 多重比较校正

在进行[全基因组](@entry_id:195052)范围的SVG分析时，我们会对成千上万个基因进行假设检验。这带来了严重的**多重比较（multiple comparisons）**问题。如果我们为每个检验设定一个常规的[显著性水平](@entry_id:170793)（例如 $p  0.05$），那么即使在所有基因都没有真[实空间](@entry_id:754128)模式的情况下，我们仅凭偶然性就会预期发现数百个“[假阳性](@entry_id:635878)”的结果。[@problem_id:4609019]

为了解决这个问题，我们需要对p值进行校正。一个常用的控制指标是**伪发现率（False Discovery Rate, FDR）**，它定义为在所有被判为“显著”的发现中，实际上是[假阳性](@entry_id:635878)的发现所占的期望比例。与更严格的控制“至少犯一个[假阳性](@entry_id:635878)错误”概率的**家[族错误率](@entry_id:165945)（Family-Wise Error Rate, FWER）**相比，控制FDR能在保持可接受的[假阳性](@entry_id:635878)比例的同时，提供更高的统计功效（即发现更多真实信号）。

**[Benjamini-Hochberg](@entry_id:269887) (BH) 程序**是控制FDR最流行的方法。其步骤如下：
1.  将所有 $m$ 个检验的p值从小到大排序：$p_{(1)} \le p_{(2)} \le \dots \le p_{(m)}$。
2.  设定一个目标FDR水平 $q$ (例如, 0.05)。
3.  找到最大的索引 $k$，使得 $p_{(k)} \le \frac{k}{m} q$。
4.  拒绝所有[p值](@entry_id:136498)小于或等于 $p_{(k)}$ 的假设。

BH程序被证明在所有检验**独立**或满足一种称为**正回归依赖（Positive Regression Dependence on a Subset, PRDS）**的弱依赖条件下，能够将FDR控制在 $q$ 水平以下。然而，在空间转录组学数据中，由于基因共表达和空间邻近性，不同基因或不同位置的检验统计量之间常常存在复杂的正相关结构。这种强烈的依赖性**可能不满足PRDS条件**，从而导致BH程序的FDR控制失效，实际的FDR可能会高于预设的 $q$ 水平。

为了在**任意依赖结构**下都能稳健地控制FDR，**Benjamini-Yekutieli (BY) 程序**被提出来。BY程序在BH程序的基础上引入了一个更为保守的校正因子，即第 $m$ 个[调和数](@entry_id:268421) $H_m = \sum_{i=1}^{m} \frac{1}{i}$。其检验阈值变为：
$$
p_{(k)} \le \frac{k}{m H_m} q
$$
由于 $H_m \ge 1$，BY程序的阈值比BH程序更严格，从而降低了统计功效。但它的优势在于提供了普适性的保证：无论检验之间的依赖结构如何，它都能将FDR控制在 $q$ 水平之下。在处理具有未知或复杂依赖性的空间转录组学数据时，使用BY程序或其他为依赖性设计的FDR控制方法是更审慎的选择。