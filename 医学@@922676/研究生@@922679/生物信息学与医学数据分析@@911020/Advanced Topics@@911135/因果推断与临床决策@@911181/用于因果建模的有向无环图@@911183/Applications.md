## 应用与跨学科连接

在前面的章节中，我们已经系统地介绍了[有向无环图](@entry_id:164045)（DAGs）的语法、基本原理（如[d-分离](@entry_id:748152)）以及其在因果识别中的核心作用（如[后门准则](@entry_id:637856)）。这些原理为我们提供了一套严谨的数学语言来表达因果假设并推导其逻辑结论。本章的目标是将这些抽象的理论付诸实践，探讨DAGs如何在生物信息学、医学数据分析及相关领域的复杂现实世界问题中发挥其强大作用。

我们将不再重复介绍核心概念，而是通过一系列应用案例，展示DAGs如何帮助我们设计研究、识别和应对偏倚、连接不同的统计学领域，并最终从观测数据中探寻因果关系的蛛丝马迹。这些案例旨在揭示DAGs不仅是一种理论工具，更是一种贯穿于从研究设计到数据分析全过程的、不可或缺的思维框架。

### 核心应用：研究设计与偏倚分析

DAGs最直接的应用在于帮助研究者清晰地思考研究设计中的潜在偏倚来源，[并指](@entry_id:276731)导数据分析策略的选择。通过将领域知识转化为图形结构，我们可以直观地识别混杂、选择性偏倚和中介等复杂关系。

#### 识别混杂与选择调整集

因果推断中最核心的挑战之一是处理混杂（confounding），即当一个变量同时是暴露和结果的共同原因时，它会扭曲二者之间的观测关联。[后门准则](@entry_id:637856)为我们提供了一个系统性的方法来识别并选择一个“充分调整集”，通过对这个集合中的变量进行分层或回归调整，可以阻断所有非因果的后门路径，从而无偏地估计因果效应。

考虑一个典型的药理学观察性研究，旨在评估一种新型抗凝剂（暴露$A$）对缺血性卒中（结果$Y$）的总因果效应。基于临床知识，研究者可能会构建一个DAG，其中包含多个基线变量。例如，房颤严重程度（$S$）、肾功能（$R$）和社会经济地位（$SES$）都可能影响医生是否开具新药（$S \to A, R \to A, SES \to A$），同时也直接影响卒中风险（$S \to Y, R \to Y, SES \to Y$）。这些变量是$A$和$Y$的共同原因，打开了如 $A \leftarrow S \to Y$ 这样的后门路径。为了估计$A$对$Y$的总因果效应，我们必须通过统计调整来关闭这些路径。因此，一个包含$\{S, R, SES\}$的集合是一个充分调整集。

然而，识别需要调整的变量与识别不应调整的变量同样重要。假设在该研究中，还存在其他变量：
- **治疗后中介变量**：例如，开始治疗后达到的抗凝水平（$M$）。其在因果通路 $A \to M \to Y$ 上。如果我们想要估计$A$的*总*因果效应，调整$M$将会阻断部分因果路径，导致我们估计的是直接效应而非总效应。因此，对于总效应估计，中介变量不应被纳入调整集。
- **治疗后对撞机**：例如，后续随访中的依从性监测访视次数（$Q$）。这个变量可能受到治疗分配（$A \to Q$）和社会经济地位（$SES \to Q$）的影响。在这种情况下，$Q$是路径 $A \to Q \leftarrow SES \to Y$ 上的一个[对撞机](@entry_id:192770)（collider）。在不调整$Q$时，这条路径是天然关闭的。然而，一旦我们对$Q$进行调整，这条非因果路径就会被打开，从而引入“对撞分层偏倚”（collider-stratification bias）。
- **[工具变量](@entry_id:142324)**：例如，处方医生对新药的偏好（$P$），它仅影响治疗选择（$P \to A$），而与结果$Y$没有其他[共同原因](@entry_id:266381)。这样的变量虽然与$A$相关，但它不位于任何$A$与$Y$之间的后门路径上，因此无需为了控制混杂而对其进行调整。将$P$加入调整集虽然不会引入偏倚，但会使调整集变得非最小化，并可能降低[统计效率](@entry_id:164796) [@problem_id:4934264]。

通过系统地枚举所有后门路径，并应用[d-分离](@entry_id:748152)规则，研究者可以精确地判断一个给定的变量集是否是一个有效的调整集。例如，在一个包含基因变异（$W$）、生物标志物（$Z$）、治疗（$X$）和临床结局（$Y$）的生物信息学模型中，如果DAG结构为 $W \to Z$, $W \to X$, $Z \to X$, $Z \to Y$, $X \to Y$，那么从$X$到$Y$的后门路径有两条：$X \leftarrow Z \to Y$ 和 $X \leftarrow W \to Z \to Y$。调整集 $\{Z\}$ 可以阻断这两条路径，因此是有效的。而调整集 $\{W\}$ 无法阻断第一条路径，故无效。调整集 $\{Z,W\}$ 也是有效的，尽管它不是最小的 [@problem_id:4557728]。这个过程展示了DAG如何将抽象的统计准则转化为具体的、可操作的分析步骤。

#### 治疗后调整的危害：对撞分层偏倚

对撞分层偏倚是数据分析中最微妙且最常见的错误之一，尤其是在处理观察性数据时。研究者常常倾向于调整尽可能多的变量，认为这总能“控制”更多的变异性。然而，DAGs清晰地揭示了调整某些变量——特别是那些受暴露影响的变量——实际上会*引入*偏倚，而不是消除它。

一个经典的例子来自外科结果研究。假设我们想评估微创手术与开放手术（暴露$S$）对术后肺部并发症（结果$C$）的因果效应。一个直观的想法可能是调整术后住院时长（$L$），因为它似乎反映了患者的整体恢复情况。然而，住院时长本身是一个结果。在DAG中，手术方式会影响住院时长（$S \to L$），并发症的发生同样会延长住院时长（$C \to L$）。这意味着$L$是路径 $S \to L \leftarrow C$ 上的一个[对撞机](@entry_id:192770)。

根据d-separation的规则，这条路径在未对$L$进行调整时是关闭的。但是，一旦我们在回归模型中“调整”$L$，就相当于在$L$上进行了分层。这种对对撞机的分层会打开 $S$ 与 $C$ 之间的非因果关联，从而引入偏倚。即便$S$和$C$之间没有任何真实的因果效应或共同原因（即DAG仅为 $S \to L \leftarrow C$），仅仅调整$L$就能在数据中制造出一种虚假的关联。这种偏倚是结构性的，与测量误差无关，即使$L$被完美测量，偏倚依然存在。因此，DAGs提供了一个强有力的警告：绝不应随意调整作为暴露和结果共同效应的治疗后变量 [@problem_id:5106043]。

#### 选择性偏倚与可移植性

选择性偏倚（selection bias）可以被理解为一种特殊的对撞分层偏倚。当样本的选择过程本身受到暴露和结果（或其原因）的共同影响时，就会发生选择性偏倚。在DAG中，这通常表现为选择[指示变量](@entry_id:266428)$S$（$S=1$表示被选入研究）成为一个对撞机。

在涉及工具变量（IV）分析的场景中，选择性偏倚可能尤为隐蔽。假设我们考虑使用某个预约计时策略（$Z_T$）作为[工具变量](@entry_id:142324)，该策略影响治疗依从性（$Z_T \to X$）。同时，该策略也可能影响患者是否来诊所就诊（$Z_T \to S$）。如果患者自身的疾病严重程度（一个未测量的混杂因素$U$）也影响其就诊行为（$U \to S$），那么在仅分析就诊患者（即在$S=1$上进行分层）的研究中，$S$就成为了路径 $Z_T \to S \leftarrow U$上的一个[对撞机](@entry_id:192770)。对$S$的分层打开了$Z_T$和$U$之间的关联，破坏了[工具变量](@entry_id:142324)所需的独立性假设（$Z \perp U$），使得$Z_T$成为一个无效的[工具变量](@entry_id:142324) [@problem_id:4557727]。

与选择性偏倚密切相关但更进一步的概念是“可移植性”（transportability）或“泛化性”（generalizability）。这个问题探讨的是：从一个研究环境（如一个临床试验）中获得的因果效应估计，是否可以被“移植”到另一个目标人群（如真实的临床实践）中？DAGs提供了一个称为“选择图”（selection diagrams）的工具来 formalize 这个问题。在选择图中，我们引入一个特殊的选择节点$S$，它指向所有在源域和目标域之间可能存在差异的机制所对应的变量。例如，如果目标人群的基线协变量分布不同，则$S$指向这些协变量。如果结果的发生机制不同，则$S$指向结果变量$Y$。

一个因果效应 $P^*(Y \mid \operatorname{do}(X))$ 从源域到目标域是可移植的，其图形准则是：在移除了指向$X$的所有箭头后得到的“残缺图” $G_{\bar{X}}$ 中，存在一个不包含$X$后代的变量集$Z$，使得$Y$与选择节点$S$在该图中关于$\{X, Z\}$是[d-分离](@entry_id:748152)的。这个准则直观地意味着，在干预了$X$之后，任何剩余的跨域差异（由$S$表示）对$Y$的影响都可以通过调整$Z$来阻断。如果这个条件成立，我们就可以通过结合源域的干预数据和目标域的观测数据来估计目标域的因果效应 [@problem_id:4557776]。

### 纵向研究中的高级因果建模

生物医学数据，特别是来自电子健康记录（EHR）或长期队列研究的数据，本质上是纵向的。处理随时间变化的数据引入了更为复杂的因果挑战，DAGs在阐明这些挑战并指导正确分析方法方面显得尤为重要。

#### 不朽时间偏倚

不朽时间偏倚（immortal time bias）是观察性研究中一种常見且严重的偏倚，它发生在错误地将被暴露组中治疗开始前的一段“不朽”时间归因于暴露期时。例如，一项研究比较在住院后72小时内开始使用某种抗菌药物（$X=1$）与未开始使用（$X=0$）对90天死亡率（$Y$）的影响。要被分到$X=1$组，患者必须存活到第72小时（我们用$S=1$表示）。而$X=0$组则包含了那些在72小时前就死亡的患者。

使用DAG可以清晰地揭示这种偏倚的结构性根源。患者的基线健康状况（未测量的虚弱程度$U$）会影响其存活到72小时的可能性（$U \to S$）和最终的死亡风险（$U \to Y$）。同时，存活到72小时是接受治疗的前提（$S \to X$）。天真的分析方法实际上是在一个由$X$和$S$共同决定的选择变量上进行了分层，这个选择变量是一个[对撞机](@entry_id:192770)，打开了路径 $X \leftarrow S \leftarrow U \to Y$，从而在$X$和$Y$之间引入了由$U$介导的虚假关联，即使我们调整了所有已测量的基线混杂因素$L$。

正确的处理方法是明确地设计分析以避免这种偏倚。DAGs指导我们采用“目标试验模拟”（target trial emulation）或“里程碑分析”（landmark design）等策略。这些方法的核心思想是：
1. **对齐时间零点**：将所有符合条件（即$S=1$）的患者的研究起点（时间零点）都设在治疗决策点（例如72小时）。
2. **定义暴露组**：根据在里程碑时间点的治疗决策来定义暴露组。
3. **调整混杂**：调整在新的时间零点测量的所有相关混雜因素。
这种设计通过在整个分析队列中强制$S=1$，并对齐时间轴，有效地消除了不朽时间偏倚的结构性来源。此外，对于更复杂的时变治疗场景，可以使用边际结构模型（MSM）等方法，通过[逆概率](@entry_id:196307)加权来正确处理随时间变化的暴露和混杂 [@problem_id:4557758] [@problem_id:4960136]。

#### 时变混杂

在许多纵向研究中，一个变量既可以是过去治疗的后果，也可以是未来治疗的原因。例如，在慢性病管理中，医生在每次随访时会根据患者当前的生物标志物水平（$L_t$）来调整治疗方案（$A_t$），而过去的治疗（$A_{t-1}$）又会影响当前的生物标志物水平（$A_{t-1} \to L_t$）。这个$L_t$就是一个时变混杂因素（time-varying confounder），因为它既是过去治疗效果的中介，又是未来治疗与结果之间关系的混杂因素（$A_t \leftarrow L_t \to Y$）。

这种情况对传统的回归调整方法提出了致命的挑战。如果我们为了控制$A_t$和$Y$之间的混杂而调整$L_t$，我们会无意中阻断从$A_{t-1}$到$Y$的部分因果路径（$A_{t-1} \to L_t \to \dots \to Y$），从而导致对$A_{t-1}$效应的偏倚估计。DAGs清晰地展示了这种困境：$L_t$既位于需要被阻断的后门路径上，也位于需要被保留的前向因果路径上。

解决时变混杂需要超越标准回归的“g-方法”（g-methods），如g-公式（g-computation）或[逆概率](@entry_id:196307)加权（IPW）估计的边际结构模型（MSM）。这些方法不是通过直接在[回归模型](@entry_id:163386)中“调整”时变混雜因素来工作，而是通过建模来标准化或重新加权，以模拟在一个没有混杂的世界里（即治疗分配与时变混杂因素无关）会发生什么。
- **g-公式**：通过序贯地建模$L_t$和$Y$的[条件分布](@entry_id:138367)，然后进行[蒙特卡洛模拟](@entry_id:193493)，来估计在特定治疗策略$\bar{a}$下的[潜在结果](@entry_id:753644)分布。
- **IPW/MSM**：通过为每个个体构建一个权重，该权重是其所接受的实际治疗序列概率的倒数，从而创建一个伪人群。在这个伪人群中，时变混杂因素与治疗分配之间的关联被打破，可以直接估计因果效应。
这些方法都需要对信息性审查（informative censoring，即审查本身与结果相关）进行类似的加权调整。DAGs是理解为何需要这些高级方法以及验证其所需假设（如顺序[可交换性](@entry_id:263314)）的理论基石 [@problem_id:4557707] [@problem_id:4557706]。

#### 模拟目标试验：一个统一的框架

“模拟目标试验”范式是将上述因果推断原理整合起来，用于指导观察性研究设计的强大框架。其核心思想是，在分析观察性数据之前，首先精确地、明确地写下一个我们希望模拟的理想化随机试验的方案（即“目标试验”）。这个方案应包括：
- **资格标准**：定义目标人群（在DAG中对应于选择节点$S$）。
- **治疗策略**：明确定义要比较的治疗方案，包括起始、剂量、持续时间等。
- **治疗分配**：明确治疗分配的时间点和方式。
- **随访期**：定义结果的测量时间。
- **结果**：明确定义要测量的主要和次要结果。
- **分析计划**：预先指定意向治疗（intention-to-treat）或依从方案（per-protocol）分析。

然后，使用观察性数据（如EHR）来“模拟”这个试验的每个组成部分。DAG在这一过程中扮演着至关重要的角色，它帮助我们识别和处理观察性数据与理想试验之间的偏差。例如，DAG可以帮助我们识别基线混杂因素（需要调整），处理时变混杂（需要g-方法），以及处理因informative censoring（如失访或停止依从方案）而产生的偏倚（需要[逆概率](@entry_id:196307)审查加权）。通过这种方式，DAGs将一个复杂的观察性分析[问题分解](@entry_id:272624)为一系列定义清晰、可操作的步骤，极大地提高了研究的严谨性和透明度 [@problem_id:4960136]。

### 连接因果推断与其他统计领域

DAGs的语言和逻辑不仅在因果推断内部具有统一性，它还能与其他关键的统计学领域建立深刻的联系，为理解这些领域中的核心概念提供新的视角。

#### 因果中介分析

中介分析旨在探究一个暴露（$X$）对一个结果（$Y$）的效应在多大程度上是通过一个或多个中介变量（$M$）传递的。DAG $X \to M \to Y$ 加上一个直接路径 $X \to Y$ 是最简单的中介模型。DAGs帮助我们将因果效应分解为与图形路径相对应的部分。

这种分解在[潜在结果框架](@entry_id:636884)下被赋予了精确的定义。总效应（Total Effect, TE）是 $E[Y_x - Y_{x'}]$，它捕捉了所有从$X$到$Y$的路径的总和。为了分离直接和间接路径，我们需要引入嵌套的反事实概念。
- **自然直接效应（Natural Direct Effect, NDE）**：定义为 $E[Y_{x, M_{x'}} - Y_{x', M_{x'}}]$。它回答了这样一个问题：“如果我们将暴露从$x'$变为$x$，但中介变量$M$被神奇地维持在它在无暴露（$x'$）时会达到的自然水平（$M_{x'}$），结果会改变多少？” 这恰好隔离了直接路径 $X \to Y$ 的贡献。
- **自然间接效应（Natural Indirect Effect, NIE）**：一个常见的定义是 $E[Y_{x, M_x} - Y_{x, M_{x'}}]$。它回答了另一个问题：“如果我们将暴露水平固定在$x$，但将中介变量从它在无暴露时的自然水平（$M_{x'}$）变为它在有暴露时的自然水平（$M_x$），结果会改变多少？” 这恰好隔离了通过中介路径 $X \to M \to Y$ 传递的效应。
DAGs不仅提供了这些效应的可视化表示，而且是推导识别这些反事实量所需假设（如不存在未测量的$X-M$或$M-Y$混杂）的起点 [@problem_id:4557700]。

#### [工具变量分析](@entry_id:166043)

[工具变量](@entry_id:142324)（IV）是一种在存在未测量混杂的情况下估计因果效应的方法。一个有效的工具变量$Z$必须满足三个核心假设：
1. **相关性**：$Z$与暴露$X$相关。
2. **独立性**：$Z$与任何影响结果$Y$的未测量混杂因素$U$不相关。
3. **排他性限制**：$Z$仅通过$X$影响$Y$。

这三个抽象的假设可以在DAG中被直观地检验。在一个包含工具$Z$、暴露$X$、结果$Y$和未测量混杂$U$（$U \to X$ 和 $U \to Y$）的图中：
1. **相关性**：要求存在一条从$Z$到$X$的路径，通常是 $Z \to X$。
2. **独立性**：要求$Z$和$U$之间没有开放的后门路径。例如，一个共同原因 $L \to Z$ 和 $L \to U$ 会违反此假设。
3. **排他性限制**：要求所有从$Z$到$Y$的路径都必须经过$X$。一条直接的路径 $Z \to Y$（稱為水平多效性）或通过其他途径的路径都会违反此假设。

DAGs使我们能够评估候选[工具变量](@entry_id:142324)的有效性。例如，一个随机分配的鼓励信息（$Z_E$）可能是一个有效的IV，而一个与疾病通路有多种联系的基因变异（$Z_G$，存在 $Z_G \to Y$ 的多效性路径）则可能不是。DAGs还能揭示更微妙的违规情况，如前述的选择性偏倚问题，其中对$S$的分层打开了$Z$和$U$之间的路径 [@problem_id:4557727]。

#### [缺失数据机制](@entry_id:173251)

缺失数据是所有现实世界数据分析都会面临的问题。Rubin的[缺失数据](@entry_id:271026)理论将缺失机制分为[完全随机缺失](@entry_id:170286)（MCAR）、[随机缺失](@entry_id:168632)（MAR）和[非随机缺失](@entry_id:163489)（MNAR）。这些定义虽然精确，但有时难以直观理解。DAGs通过引入一个表示缺失性的指示节点（例如，$R_X$表示变量$X$是否缺失），为这些概念提供了清晰的图形化解释。

在一个包含$X$及其缺失指示器$R_X$的DAG中：
- **MCAR**：当$R_X$与系统中所有其他变量（包括$X$本身）都d-分離时成立。在图形上，这意味着没有箭头从任何其他变量指向$R_X$。
- **MAR**：当$R_X$与$X$在给定所有观测到的变量（记为$O$）后是条件独立的（$R_X \perp X \mid O$）时成立。在图形上，这意味着所有连接$R_X$和$X$的路径都被观测变量集$O$阻断。这允许缺失性依赖于其他观测变量（例如，$Y \to R_X$），但不能直接依赖于$X$的未测值或与$X$和$R_X$都有关联的未测变量$U$（$X \leftarrow U \to R_X$）。
- **MNAR**：当MAR不成立时，即$R_X$与$X$在给定$O$后仍然相关。最常见的情况是$X$的值本身影响其缺失性（$X \to R_X$），或者是存在一个未测量的共同原因$U$同时影响$X$和$R_X$（$X \leftarrow U \to R_X$）。
这种图形化表述极大地澄清了“[随机缺失](@entry_id:168632)”的含义——它不是指缺失过程是纯粹随机的，而是指它在给定其他[观测信息](@entry_id:165764)后是“随机”的 [@problem_id:4557788]。

#### 测量误差

在生物医学研究中，我们感兴趣的变量（如真实的[细胞因子](@entry_id:204039)浓度$X$）往往无法被精确测量，我们只能得到一个带有误差的测量值 $\tilde{X}$。DAGs可以帮助我们理解测量误差如何影响因果推斷。

在一个典型的非差异性[测量误差模型](@entry_id:751821)中，$\tilde{X} = X + \epsilon$，其中误差$\epsilon$与$X$及系统中的其他变量无关。我们可以在DAG中明确地表示这个关系，即添加一个测量节点 $\tilde{X}$，并画上箭头 $X \to \tilde{X}$ 和 $\epsilon \to \tilde{X}$。假设真实模型中存在未测量混杂$U$，即 $X \leftarrow U \to Y$。如果我们天真地使用测量值$\tilde{X}$来代替真实值$X$进行调整以控制混杂，DAG可以立即告诉我们这是错误的。调整$\tilde{X}$并不能阻断后门路径 $X \leftarrow U \to Y$，因为$\tilde{X}$并不在该路径上。因此，即使在存在非差异性测量误差的情况下，混杂偏倚依然存在。DAG清晰地展示了，用代理变量进行调整并不能解决由未测量混杂引起的根本性结构问题 [@problem_id:4557709]。

### 从因果推断到因果发现

到目前为止，我们都假设DAG结构是已知的。然而，在生物信息学等探索性领域，一个核心目标恰恰是从高维数据（如组学数据）中“发现”[因果结构](@entry_id:159914)，即学习DAG本身。

#### 高维数据中的因果发现挑战

从高维观测数据（特别是$n \ll p$的情形，即样本量远小于变量数）中学习DAG是一项极具挑战性的任务。其困难主要源于：
- **等价类问题**：仅凭观测数据无法区分具有相同[条件独立性](@entry_id:262650)关系的DAGs（所谓的[马尔可夫等价](@entry_id:751683)类）。输出通常是一个部分有向的图（CPDAG）。
- **多重检验**：基于[条件独立性](@entry_id:262650)检验的方法（如[PC算法](@entry_id:753280)）需要进行数量庞大的检验，这带来了严重的[多重检验问题](@entry_id:165508)和[统计功效](@entry_id:197129)的损失。
- **高维性**：当变量数$p$很大时，即使是低阶的[条件独立性](@entry_id:262650)检验，其组合数也可能是天文数字，计算上不可行。
- **弱信号**：许多真实的生物调控效应可能很微弱，在巨大的噪声背景和有限的样本下难以检测。

#### 现代因果发现方法

为了应对这些挑战，现代因果发现算法通常结合了正则化、评分和[优化技术](@entry_id:635438)。
- **基于评分的方法**：这类方法（如GES算法）定义一个[评分函数](@entry_id:175243)（如BIC），用于衡量一个给定的DAG（或[等价类](@entry_id:156032)）与数据的[拟合优度](@entry_id:637026)，同时惩罚模型的复杂性。然后通过贪心搜索等策略来寻找最优评分的图。
- **正则化与稀疏性**：在$n \ll p$的设定下，必须假设底层的因果图是稀疏的。像[LASSO](@entry_id:751223)一样的$\ell_1$正则化被引入到[评分函数](@entry_id:175243)中，以鼓励稀疏的解。
- **连续优化**：传统上，强制图的“无环性”是一个组合难题。最近的发展（如NOTEARS算法）通过一个巧妙的数学变换，将无环性约束转化为一个光滑可微的函数，从而可以将整个DAG学习问题表述为一个连续优化问题，可以用[梯度下降](@entry_id:145942)等高效方法求解。

一个先进的策略可能包括：使用一个带有$\ell_1$正则化和光滑无环性约束的[评分函数](@entry_id:175243)进行优化，以获得一个稀疏的DAG估计。为了提供统计[置信度](@entry_id:267904)，可以结合模型-X knockoffs或[稳定性选择](@entry_id:138813)等方法来控制伪发现率（FDR），或者利用样本分裂和debiased [LASSO](@entry_id:751223)等技术对检测到的弱信号进行有效的[假设检验](@entry_id:142556)。此外，还可以引入先验生物学知识（如通路信息），通过结构化稀疏惩罚（如group-LASSO）来指导发现过程，使其偏向于更具生物学意义的结构 [@problem_id:4557754] [@problem_id:4557778]。

### 系统生物学中的应用

最后，DAGs和do-算子为形式化定义生物学实验和概念提供了精确的语言。

#### 形式化干预：[合成致死](@entry_id:139976)

[合成致死](@entry_id:139976)（synthetic lethality）是一个重要的癌症治疗概念，指的是两种基因的单独失活是可容忍的，但它们的同时失活会导致细胞死亡。这个概念本质上是关于干预的。使用DAGs和do-算子，我们可以给出一个无歧义的定义。

假设基因$X$和$Y$通过某个通路$P$影响细胞存活率$V$，并受到共同的背景因素$U$的影响。我们可以用DAG来表示这个系统。基因敲除（knockout）这一实验操作，在因果图的语言中，正是do-干预。$do(X=0)$表示强制将基因$X$的功能设置为关闭，这对应于在DAG中切断所有指向$X$的箭头，并将$X$的值固定为0。

因此，合成致死的严格定义必须基于干预概率，而非观测概率。一个细胞系表现出$X$和$Y$之间的合成致死，当且仅当：
1. 单[基因敲除](@entry_id:145810)是可行的：$P(V=0 \mid do(X=0))$很小，且$P(V=0 \mid do(Y=0))$很小。
2. 双基因敲除是致命的：$P(V=0 \mid do(X=0), do(Y=0))$接近于1。

如果存在混杂因素$U$（如细胞系的遗传背景），那么$P(V=0 \mid do(X=0), do(Y=0))$不等于观测到的[条件概率](@entry_id:151013)$P(V=0 \mid X=0, Y=0)$。然而，如果$U$是可测量的，我们可以应用后门调整公式来从观测数据中识别出干预概率：$P(V=0 \mid do(X=0), do(Y=0)) = \sum_u P(V=0 \mid X=0, Y=0, U=u)P(U=u)$。这个例子完美地展示了do-算子如何将一个模糊的生物学概念转化为一个精确的、可从数据中识别的数学量 [@problem_id:4354479]。

### 结论

本章通过一系列来自生物信息学和医学数据分析的应用，展示了有向无环图作为因果推断工具的广度和深度。从指导基础的研究设计和偏倚识别，到处理复杂的纵向数据挑战，再到与其他统计领域建立桥梁，并最终指导因果关系的发现，DAGs提供了一个统一、严谨且直观的框架。对于致力于从复杂生物医学数据中挖掘可靠知识的研究者而言，精通DAGs的语言和逻辑，是其分析工具箱中不可或缺的关键组成部分。