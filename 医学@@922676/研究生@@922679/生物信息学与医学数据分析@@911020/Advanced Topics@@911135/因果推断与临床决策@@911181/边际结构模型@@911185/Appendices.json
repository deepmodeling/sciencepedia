{"hands_on_practices": [{"introduction": "边际结构模型的核心在于通过逆概率加权来创建一个伪总体，以校正时变混杂因素。这个练习将理论付诸实践，要求您为一个个体计算稳定化和非稳定化权重。通过这个基础计算 [@problem_id:4971107]，您将加深对权重公式的理解，并直观地感受权重是如何根据个体的治疗和协变量历史来调整其在分析中的影响的。", "problem": "考虑一项医学领域的观察性纵向队列研究，其中包含一个二元时变处理过程 $\\{A_{t}: t=0,1\\}$ 和时变协变量（潜在混杂因素）$\\{L_{t}: t=0,1\\}$。测量的时序为 $L_{0}$，然后是 $A_{0}$，接着是 $L_{1}$，最后是 $A_{1}$。假设因果识别条件——一致性、正值性和序贯可交换性——均成立，并且数据生成过程遵循所述时序，因此在给定历史信息的情况下，条件处理分配概率是良定的。目标是拟合一个边际结构模型（MSM），并使用逆概率处理加权（IPTW）方法构建权重，以消除由 $\\{L_{t}\\}$ 引起的混杂，同时保留边际处理过程。\n\n对于一个观测历史为 $(L_{0}=1, A_{0}=1, L_{1}=1, A_{1}=1)$ 且时间范围 $T=2$ 的特定个体，假设以下处理分配概率成立：\n- 基线边际处理概率 $P(A_{0}=1)=0.6$，\n- 给定基线协变量的基线条件处理概率 $P(A_{0}=1 \\mid L_{0}=1)=0.8$，\n- 给定既往处理的随访边际处理概率 $P(A_{1}=1 \\mid A_{0}=1)=0.7$，\n- 给定既往处理和当前协变量的随访条件处理概率 $P(A_{1}=1 \\mid A_{0}=1, L_{1}=1)=0.9$。\n\n使用条件概率的核心定义以及IPTW用于MSM的目的，从基本原理出发，为该个体推导非稳定权重 $w_{u}$ 和稳定权重 $w_{s}$ 的表达式，然后计算它们的精确值。将您的最终答案以单行矩阵的形式表示为最简分数。无需四舍五入；请提供精确值。", "solution": "首先对问题进行验证，以确保其具有科学依据、问题设定良好且客观。\n\n### 步骤1：提取已知条件\n- **研究背景**：观察性纵向队列研究，包含一个二元时变处理 $\\{A_{t}: t=0,1\\}$ 和时变协变量 $\\{L_{t}: t=0,1\\}$。\n- **时间顺序**：$L_{0}$，然后是 $A_{0}$，接着是 $L_{1}$，最后是 $A_{1}$。\n- **因果假设**：假设一致性、正值性和序贯可交换性成立。\n- **目标**：使用逆概率处理加权（IPTW）拟合边际结构模型（MSM）。\n- **特定个体数据**：一个观测历史为 $(L_{0}=1, A_{0}=1, L_{1}=1, A_{1}=1)$ 的个体。\n- **时间范围**：$T=2$，考虑到所给变量，这对应于离散时间点 $t=0, 1$。\n- **概率**：\n  - $P(A_{0}=1)=0.6$\n  - $P(A_{0}=1 \\mid L_{0}=1)=0.8$\n  - $P(A_{1}=1 \\mid A_{0}=1)=0.7$\n  - $P(A_{1}=1 \\mid A_{0}=1, L_{1}=1)=0.9$\n\n### 步骤2：使用提取的已知条件进行验证\n该问题是IPTW用于MSM的一个标准应用，这是因果推断和生物统计学中一个成熟的方法。所有提供的概念和术语都是该领域的标准术语。问题是自洽的，因为计算指定个体权重所需的所有概率都已提供。没有内部矛盾；所有概率都是 $0$ 和 $1$ 之间的有效值。问题结构清晰，要求计算两个特定且定义明确的量（$w_u$ 和 $w_s$）。该问题不违反任何科学原理，可形式化，且表述客观。\n\n### 步骤3：结论与行动\n该问题被判定为有效。将从基本原理出发推导解答。\n\n### 解答推导\n目标是使用逆概率处理加权（IPTW）为一个特定个体计算非稳定权重（$w_{u}$）和稳定权重（$w_{s}$）。IPTW通过创建一个伪总体（pseudo-population），使得时变混杂因素 $L_t$ 不再预测后续的处理 $A_t$，从而消除随时间变化的混杂。\n\n令 $\\bar{A}_k = (A_0, A_1, \\dots, A_k)$ 表示截至时间点 $k$ 的处理历史，$\\bar{L}_k = (L_0, L_1, \\dots, L_k)$ 表示协变量的历史。对于一个在最终时间点 $K$ 前有观测历史的个体，其权重的一般形式由各时间点特定概率的乘积给出。\n\n非稳定权重 $w_{u}$ 定义为在给定既往处理和混杂因素历史的条件下，该个体在每个时间点接受其所观测到的处理的条件概率乘积的倒数。\n$$w_{u} = \\prod_{k=0}^{K} \\frac{1}{P(A_{k}=a_{k} \\mid \\bar{A}_{k-1}=\\bar{a}_{k-1}, \\bar{L}_{k}=\\bar{l}_{k})}$$\n\n稳定权重 $w_{s}$ 在此基础上增加了一个分子项，该分子项是在仅给定既往处理历史的条件下，个体接受其所观测到的处理的条件概率的乘积。这种稳定化处理可以减小权重方差，并通常使得权重的期望值为 $1$。\n$$w_{s} = \\prod_{k=0}^{K} \\frac{P(A_{k}=a_{k} \\mid \\bar{A}_{k-1}=\\bar{a}_{k-1})}{P(A_{k}=a_{k} \\mid \\bar{A}_{k-1}=\\bar{a}_{k-1}, \\bar{L}_{k}=\\bar{l}_{k})}$$\n\n在本问题中，时间范围包含两个时间点，$t=0$ 和 $t=1$，因此我们设 $K=1$。该个体的观测历史为 $(L_{0}=1, A_{0}=1, L_{1}=1, A_{1}=1)$。因此，$a_0=1, l_0=1, a_1=1, l_1=1$。\n\n对于 $k=0$，历史 $\\bar{A}_{-1}$ 为空。公式变为：\n$$w_{u} = \\frac{1}{P(A_{0}=a_{0} \\mid L_{0}=l_{0}) \\times P(A_{1}=a_{1} \\mid A_{0}=a_{0}, \\bar{L}_{1}=\\bar{l}_{1})}$$\n$$w_{s} = \\frac{P(A_{0}=a_{0}) \\times P(A_{1}=a_{1} \\mid A_{0}=a_{0})}{P(A_{0}=a_{0} \\mid L_{0}=l_{0}) \\times P(A_{1}=a_{1} \\mid A_{0}=a_{0}, \\bar{L}_{1}=\\bar{l}_{1})}$$\n\n问题提供了 $P(A_{1}=1 \\mid A_{0}=1, L_{1}=1)=0.9$。这意味着一个特定的处理分配模型，其中 $A_1$ 的概率依赖于当前的混杂因素 $L_1$ 和既往处理 $A_0$，而不依赖于基线混杂因素 $L_0$。也就是说，$P(A_{1}=a_{1} \\mid A_{0}=a_{0}, \\bar{L}_{1}=\\bar{l}_{1}) = P(A_{1}=a_{1} \\mid A_{0}=a_{0}, L_{1}=l_{1})$。这是一个常见且有效的设定。\n\n现在我们可以代入给定该特定个体的概率。\n\n**非稳定权重（$w_{u}$）的计算**\n\n对于历史为 $(L_{0}=1, A_{0}=1, L_{1}=1, A_{1}=1)$ 的个体，权重的分母是以下两项的乘积：\n1. $P(A_{0}=1 \\mid L_{0}=1) = 0.8$\n2. $P(A_{1}=1 \\mid A_{0}=1, L_{1}=1) = 0.9$\n\n因此，非稳定权重为：\n$$w_{u} = \\frac{1}{P(A_{0}=1 \\mid L_{0}=1) \\times P(A_{1}=1 \\mid A_{0}=1, L_{1}=1)}$$\n$$w_{u} = \\frac{1}{0.8 \\times 0.9} = \\frac{1}{0.72}$$\n将其表示为最简分数：\n$$w_{u} = \\frac{1}{\\frac{72}{100}} = \\frac{100}{72} = \\frac{25 \\times 4}{18 \\times 4} = \\frac{25}{18}$$\n\n**稳定权重（$w_{s}$）的计算**\n\n$w_{s}$ 的分母与用于 $w_{u}$ 的分母相同。分子是以下两项的乘积：\n1. $P(A_{0}=1) = 0.6$\n2. $P(A_{1}=1 \\mid A_{0}=1) = 0.7$\n\n因此，稳定权重为：\n$$w_{s} = \\frac{P(A_{0}=1) \\times P(A_{1}=1 \\mid A_{0}=1)}{P(A_{0}=1 \\mid L_{0}=1) \\times P(A_{1}=1 \\mid A_{0}=1, L_{1}=1)}$$\n$$w_{s} = \\frac{0.6 \\times 0.7}{0.8 \\times 0.9} = \\frac{0.42}{0.72}$$\n将其表示为最简分数：\n$$w_{s} = \\frac{42}{72} = \\frac{7 \\times 6}{12 \\times 6} = \\frac{7}{12}$$\n\n该个体的非稳定权重为 $w_{u} = \\frac{25}{18}$，稳定权重为 $w_{s} = \\frac{7}{12}$。", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{25}{18}  \\frac{7}{12} \\end{pmatrix}}$$", "id": "4971107"}, {"introduction": "在计算出个体权重后，下一步是将它们应用于模型拟合中，以估计因果效应。本练习将指导您完成一个完整的边际结构模型实现流程。通过编写代码来执行加权最小二乘法（WLS） [@problem_id:4581093]，您将把独立的权重计算与最终的参数估计联系起来，从而全面掌握从原始数据到因果结论的整个分析管道。", "problem": "您的任务是在一个纵向观测性医学数据集中，针对一个连续结局，在具有时变暴露的边际结构模型 (MSM) 下，实现加权最小二乘法 (WLS)。目标是估计与用户指定的暴露史摘要相关的因果参数。您的实现应基于潜在结局框架的基本原则，包括一致性、可交换性和正值性，并通过构建源自处理分配模型的逆概率权重来进行。\n\n考虑一个由 $n = 8$ 名个体组成的队列，在由 $t \\in \\{1, 2\\}$ 索引的 $2$ 个时间点进行观察。二元暴露序列为 $\\bar A = (A_1, A_2)$，其中对所有个体 $A_t \\in \\{0,1\\}$。基线混杂因素是 $L_0$，时变混杂因素是 $L_1$，由 $L_0$ 和 $A_1$ 确定性地定义。在随访结束时测量的连续最终结局是 $Y$。为数据定义以下数组：\n- 基线混杂因素向量：$L_0 = [-0.5, 0.3, 1.2, -1.0, 0.0, 2.5, -0.8, 1.1]$。\n- 时间点 $1$ 的暴露：$A_1 = [1, 0, 1, 0, 1, 0, 1, 0]$。\n- 时间点 $2$ 的暴露：$A_2 = [1, 1, 0, 0, 1, 0, 0, 1]$。\n- 通过结构方程 $L_1 = \\alpha_0 + \\alpha_1 L_0 + \\alpha_2 A_1$ 确定性地构建的时变混杂因素，系数为 $\\alpha_0 = 0.2$、$\\alpha_1 = 0.5$ 和 $\\alpha_2 = 0.7$。\n- 通过 $Y = \\theta_0 + \\theta_1 (A_1 + A_2) + \\theta_2 L_0 + \\theta_3 L_1$ 确定性地构建的连续结局，系数为 $\\theta_0 = 3.0$、$\\theta_1 = 1.8$、$\\theta_2 = 0.6$ 和 $\\theta_3 = 0.4$。\n\n您将拟合工作边际结构模型 (MSM)：$\\mathbb{E}[Y^{\\bar a}] = \\beta_0 + \\beta_1 f(\\bar a)$，其中 $Y^{\\bar a}$ 表示在暴露史 $\\bar a$ 下的潜在结局，而 $f(\\bar a)$ 是一个用户指定的总结暴露史的函数。估计应使用逆概率权重通过 WLS 执行。权重源自具有 logistic 链接函数的伯努利处理模型。对于在时间点 $t$ 观测到处理 $A_t \\in \\{0,1\\}$ 的个体，其观测到的处理值的概率在分子模型和分母模型下都使用 logistic 函数 $\\text{expit}(x) = \\frac{1}{1 + e^{-x}}$ 进行建模。一个个体的稳定权重是观测到的 $A_t$ 的分子概率除以观测到的 $A_t$ 的分母概率，在所有 $t \\in \\{1,2\\}$ 上的乘积。非稳定权重将所有分子概率设置为 $1$。\n\n分母模型使用完整的处理史和混杂因素：\n- 对于 $t = 1$：$P(A_1 = 1 \\mid L_0) = \\text{expit}(\\gamma_{10} + \\gamma_{11} L_0)$。\n- 对于 $t = 2$：$P(A_2 = 1 \\mid A_1, L_1) = \\text{expit}(\\gamma_{20} + \\gamma_{21} A_1 + \\gamma_{22} L_1)$。\n\n分子模型使用简化的历史来稳定权重：\n- 对于 $t = 1$：$P(A_1 = 1) = \\text{expit}(\\nu_{10})$。\n- 对于 $t = 2$：$P(A_2 = 1 \\mid A_1) = \\text{expit}(\\nu_{20} + \\nu_{21} A_1)$。\n\n对于每个个体，稳定权重为\n$$\nW = \\prod_{t=1}^{2} \\frac{P_{\\text{num}}(A_t \\mid \\text{reduced history})}{P_{\\text{den}}(A_t \\mid \\text{full history})},\n$$\n其中 $P_{\\text{num}}(A_t \\mid \\cdot)$ 和 $P_{\\text{den}}(A_t \\mid \\cdot)$ 分别表示在分子和分母模型下观测到的处理值 $A_t$ 的概率，并且对于 $A_t = 0$，有 $\\Pr(A_t=0 \\mid \\cdot) = 1 - \\Pr(A_t=1 \\mid \\cdot)$。非稳定权重将分子设置为 $1$。\n\n您必须通过最小化加权残差平方和来实现 WLS 来估计 $(\\beta_0, \\beta_1)$，其设计矩阵的列对应于一个截距项和暴露摘要 $f(\\bar A)$。通过使用小数表示法来防止概率中出现精确的零或一，以确保数值稳定性；不允许使用百分号。\n\n通过线性组合 $f(\\bar A) = c_1 A_1 + c_2 A_2$ 为每个测试用例定义暴露摘要函数 $f(\\bar A)$，其中系数 $(c_1, c_2)$ 按每个测试用例指定。\n\n测试套件。为以下四种情况中的每一种计算 $(\\hat \\beta_0, \\hat \\beta_1)$：\n\n- 情况 1 (理想路径):\n  - 稳定权重。\n  - 分母系数：$(\\gamma_{10}, \\gamma_{11}) = (-0.3, 0.8)$ 和 $(\\gamma_{20}, \\gamma_{21}, \\gamma_{22}) = (-0.1, 0.7, 0.9)$。\n  - 分子系数：$\\nu_{10} = -0.2$ 和 $(\\nu_{20}, \\nu_{21}) = (-0.05, 0.5)$。\n  - 暴露摘要：$(c_1, c_2) = (1, 1)$，所以 $f(\\bar A) = A_1 + A_2$。\n\n- 情况 2 (晚期暴露强调):\n  - 稳定权重。\n  - 分母系数：与情况 1 相同。\n  - 分子系数：与情况 1 相同。\n  - 暴露摘要：$(c_1, c_2) = (1, 2)$，所以 $f(\\bar A) = A_1 + 2 A_2$。\n\n- 情况 3 (非稳定权重):\n  - 非稳定权重（分子设置为 $1$）。\n  - 分母系数：与情况 1 相同。\n  - 暴露摘要：$(c_1, c_2) = (1, 1)$。\n\n- 情况 4 (边界正值性压力测试):\n  - 稳定权重。\n  - 分母系数：$(\\gamma_{10}, \\gamma_{11}) = (-3.0, 3.0)$ 和 $(\\gamma_{20}, \\gamma_{21}, \\gamma_{22}) = (-2.5, 2.0, 2.0)$。\n  - 分子系数：$\\nu_{10} = -0.2$ 和 $(\\nu_{20}, \\nu_{21}) = (-0.05, 0.5)$。\n  - 暴露摘要：$(c_1, c_2) = (1, 1)$。\n\n您的程序应根据具体情况计算稳定或非稳定权重，构建列为 $[1, f(\\bar A)]$ 的设计矩阵，并执行 WLS 来为每种情况估计 $(\\hat \\beta_0, \\hat \\beta_1)$。最终输出必须是单行，包含一个逗号分隔的列表的列表，每个子列表对应一种情况，其中每个内部列表按顺序包含两个浮点数系数值 $[\\hat \\beta_0, \\hat \\beta_1]$，并用方括号括起来。例如，输出格式应为 $[[b_{0,1}, b_{1,1}],[b_{0,2}, b_{1,2}],[b_{0,3}, b_{1,3}],[b_{0,4}, b_{1,4}]]$, 所有数字都以小数形式表示。", "solution": "问题陈述经评估有效。\n\n**步骤 1：提取给定信息**\n- 队列大小：$n = 8$\n- 时间点：$t \\in \\{1, 2\\}$\n- 暴露序列：$\\bar A = (A_1, A_2)$，其中 $A_t \\in \\{0,1\\}$\n- 基线混杂因素：$L_0 = [-0.5, 0.3, 1.2, -1.0, 0.0, 2.5, -0.8, 1.1]$\n- $t=1$ 时的暴露：$A_1 = [1, 0, 1, 0, 1, 0, 1, 0]$\n- $t=2$ 时的暴露：$A_2 = [1, 1, 0, 0, 1, 0, 0, 1]$\n- 时变混杂因素 $L_1$ 的结构方程：$L_1 = \\alpha_0 + \\alpha_1 L_0 + \\alpha_2 A_1$，其中 $\\alpha_0 = 0.2$, $\\alpha_1 = 0.5$, $\\alpha_2 = 0.7$。\n- 结局 $Y$ 的结构方程：$Y = \\theta_0 + \\theta_1 (A_1 + A_2) + \\theta_2 L_0 + \\theta_3 L_1$，其中 $\\theta_0 = 3.0$, $\\theta_1 = 1.8$, $\\theta_2 = 0.6$, $\\theta_3 = 0.4$。\n- 边际结构模型 (MSM)：$\\mathbb{E}[Y^{\\bar a}] = \\beta_0 + \\beta_1 f(\\bar a)$，其中 $Y^{\\bar a}$ 是潜在结局。\n- 暴露摘要函数：$f(\\bar A) = c_1 A_1 + c_2 A_2$。\n- 处理概率的分母模型：\n  - $P(A_1 = 1 \\mid L_0) = \\text{expit}(\\gamma_{10} + \\gamma_{11} L_0)$\n  - $P(A_2 = 1 \\mid A_1, L_1) = \\text{expit}(\\gamma_{20} + \\gamma_{21} A_1 + \\gamma_{22} L_1)$\n- 处理概率的分子模型（稳定权重）：\n  - $P(A_1 = 1) = \\text{expit}(\\nu_{10})$\n  - $P(A_2 = 1 \\mid A_1) = \\text{expit}(\\nu_{20} + \\nu_{21} A_1)$\n- 稳定权重定义：$W = \\prod_{t=1}^{2} \\frac{P_{\\text{num}}(A_t \\mid \\text{reduced history})}{P_{\\text{den}}(A_t \\mid \\text{full history})}$\n- 非稳定权重对乘积中的每一项使用分子 1。\n- 测试用例：\n  - 情况 1：稳定权重，$(\\gamma_{10}, \\gamma_{11}) = (-0.3, 0.8)$，$(\\gamma_{20}, \\gamma_{21}, \\gamma_{22}) = (-0.1, 0.7, 0.9)$，$\\nu_{10} = -0.2$，$(\\nu_{20}, \\nu_{21}) = (-0.05, 0.5)$，$(c_1, c_2) = (1, 1)$。\n  - 情况 2：稳定权重，系数与情况 1 相同，$(c_1, c_2) = (1, 2)$。\n  - 情况 3：非稳定权重，分母系数与情况 1 相同，$(c_1, c_2) = (1, 1)$。\n  - 情况 4：稳定权重，$(\\gamma_{10}, \\gamma_{11}) = (-3.0, 3.0)$，$(\\gamma_{20}, \\gamma_{21}, \\gamma_{22}) = (-2.5, 2.0, 2.0)$，分子系数与情况 1 相同，$(c_1, c_2) = (1, 1)$。\n\n**步骤 2：使用提取的给定信息进行验证**\n该问题具有科学依据、适定且客观。它为一个标准的统计估计程序（边际结构模型的逆概率加权估计）应用于一个确定性生成的数据集提供了完整且一致的规范。所描述的方法是纵向数据因果推断领域的标准方法。该问题是可形式化的，其计算解是唯一且可验证的。所有需要的数据、参数和函数形式都已明确提供。未发现任何缺陷。\n\n**步骤 3：结论与行动**\n问题有效。将提供一个完整的解决方案。\n\n**基于原则的设计**\n目标是估计边际结构模型 (MSM) $\\mathbb{E}[Y^{\\bar a}] = \\beta_0 + \\beta_1 f(\\bar a)$ 的因果参数 $(\\beta_0, \\beta_1)$，该模型用于处理时变二元暴露 $\\bar A$下的连续结局 $Y$。估计是在存在混杂的模拟纵向数据集上进行的。解决本身受过去暴露影响的时变混杂的标准方法是使用逆概率加权 (IPW)。该方法创建一个伪群体，其中暴露与混杂因素无关，从而可以对暴露对结局的边际（无混杂）效应进行无偏估计。估计是通过加权最小二乘法 (WLS) 进行的。\n\n解决方案分为四个主要步骤：数据准备、权重计算、WLS 估计以及应用于指定的测试用例。\n\n**步骤 1：数据准备**\n首先，我们为 $n=8$ 名个体组成的队列生成完整的数据集。问题提供了基线混杂因素 $L_0$ 和暴露史 $(A_1, A_2)$。时变混杂因素 $L_1$ 和最终结局 $Y$ 是使用指定的结构方程确定性地生成的：\n- $L_{1i} = \\alpha_0 + \\alpha_1 L_{0i} + \\alpha_2 A_{1i}$，其中 $\\alpha_0 = 0.2$, $\\alpha_1 = 0.5$, $\\alpha_2 = 0.7$。\n- $Y_i = \\theta_0 + \\theta_1 (A_{1i} + A_{2i}) + \\theta_2 L_{0i} + \\theta_3 L_{1i}$，其中 $\\theta_0 = 3.0$, $\\theta_1 = 1.8$, $\\theta_2 = 0.6$, $\\theta_3 = 0.4$。\n这些计算针对每个个体 $i=1, \\dots, n$ 执行。\n\n**步骤 2：逆概率权重 (IPW) 计算**\n对于每个个体 $i$，计算一个逆概率权重 $W_i$。该权重是在每个时间点观测到的暴露概率的乘积，以一组协变量为条件。稳定权重的一般形式是：\n$$\nW_i = \\prod_{t=1}^{2} \\frac{P(A_t = A_{ti} \\mid \\text{Reduced History}_t)}{P(A_t = A_{ti} \\mid \\text{Full History}_t)}\n$$\n概率来自 logistic 模型，$P(A_t=1 | \\mathbf{X}) = \\text{expit}(\\boldsymbol{\\theta}^T \\mathbf{X})$，其中 $\\text{expit}(x) = 1/(1+e^{-x})$。观测到的暴露 $A_{ti}$ 的概率由似然项 $L(A_{ti}) = (p_{ti})^{A_{ti}}(1-p_{ti})^{1-A_{ti}}$ 给出，其中 $p_{ti} = P(A_t=1 | \\text{history})$。\n\n对于每个个体 $i$：\n1.  **分母贡献**：这些概率以混杂因素和过去暴露的完整历史为条件。\n    - 在 $t=1$ 时，观测到的暴露 $A_{1i}$ 的概率从 $P(A_1=1|L_{0i}) = \\text{expit}(\\gamma_{10} + \\gamma_{11}L_{0i})$ 计算。\n    - 在 $t=2$ 时，观测到的暴露 $A_{2i}$ 的概率从 $P(A_2=1|A_{1i}, L_{1i}) = \\text{expit}(\\gamma_{20} + \\gamma_{21}A_{1i} + \\gamma_{22}L_{1i})$ 计算。\n    总分母项是这两个概率的乘积。\n\n2.  **分子贡献**：这些概率以简化的变量集（仅过去暴露）为条件来稳定权重，从而减小其方差。\n    - 在 $t=1$ 时，$A_{1i}$ 的概率来自 $P(A_1=1) = \\text{expit}(\\nu_{10})$。\n    - 在 $t=2$ 时，$A_{2i}$ 的概率来自 $P(A_2=1|A_{1i}) = \\text{expit}(\\nu_{20} + \\nu_{21}A_{1i})$。\n    总分子项是这两个概率的乘积。\n\n对于情况 3 中要求的**非稳定权重**，每个时间点的分子贡献简单地为 $1$，导致总分子为 $1$。权重则变为给定完整历史下观测到的暴露序列的联合概率的倒数。\n\n**步骤 3：加权最小二乘法 (WLS) 估计**\nMSM 的参数 $(\\beta_0, \\beta_1)$ 是通过使用 WLS 拟合模型 $Y_i = \\beta_0 + \\beta_1 f(\\bar A_i) + \\epsilon_i$ 来估计的，其中权重 $W_i$ 在上一步中计算得出。参数向量 $\\boldsymbol{\\beta} = [\\beta_0, \\beta_1]^T$ 的 WLS 估计量由闭式解给出：\n$$\n\\hat{\\boldsymbol{\\beta}} = (X^T \\mathbf{W} X)^{-1} X^T \\mathbf{W} \\mathbf{y}\n$$\n在这里，$\\mathbf{y}$ 是结局 $Y_i$ 的 $n \\times 1$ 向量。$X$ 是 $n \\times 2$ 的设计矩阵，其中第一列是全为 1 的向量（用于截距 $\\beta_0$），第二列是暴露摘要函数值 $f(\\bar A_i)$ 的向量。$\\mathbf{W}$ 是一个 $n \\times n$ 的对角矩阵，其对角线上的元素是权重 $W_i$。在计算上，这个系统可以高效求解而无需显式地构建逆矩阵，例如，通过求解线性系统 $(X^T \\mathbf{W} X)\\hat{\\boldsymbol{\\beta}} = X^T \\mathbf{W} \\mathbf{y}$。\n\n**步骤 4：应用于测试用例**\n为四个测试用例中的每一个执行步骤 1-3 中概述的程序。每个用例都为权重模型（$\\gamma$ 系数，$\\nu$ 系数）、权重类型（稳定或非稳定）和暴露摘要函数 $f(\\bar A)$ 提供了一组特定的参数。每个用例得到的估计值 $(\\hat{\\beta}_0, \\hat{\\beta}_1)$ 被收集起来，并以要求的格式呈现。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import expit\n\ndef solve():\n    \"\"\"\n    Implements Weighted Least Squares (WLS) for a Marginal Structural Model (MSM)\n    to estimate causal parameters from a simulated longitudinal dataset.\n    \"\"\"\n    \n    # Step 1: Define initial data and generate the full dataset\n    # Given data from the problem statement\n    L0 = np.array([-0.5, 0.3, 1.2, -1.0, 0.0, 2.5, -0.8, 1.1])\n    A1 = np.array([1, 0, 1, 0, 1, 0, 1, 0])\n    A2 = np.array([1, 1, 0, 0, 1, 0, 0, 1])\n    n = len(L0)\n\n    # Deterministic generation of L1 and Y\n    alpha = {'a0': 0.2, 'a1': 0.5, 'a2': 0.7}\n    L1 = alpha['a0'] + alpha['a1'] * L0 + alpha['a2'] * A1\n\n    theta = {'th0': 3.0, 'th1': 1.8, 'th2': 0.6, 'th3': 0.4}\n    Y = theta['th0'] + theta['th1'] * (A1 + A2) + theta['th2'] * L0 + theta['th3'] * L1\n\n    # Test suite definition\n    test_cases = [\n        # Case 1: stabilized, f(A) = A1+A2\n        {'type': 'stabilized', \n         'gamma1': (-0.3, 0.8), 'gamma2': (-0.1, 0.7, 0.9),\n         'nu1': (-0.2,), 'nu2': (-0.05, 0.5),\n         'c_coeffs': (1, 1)},\n        # Case 2: stabilized, f(A) = A1+2*A2\n        {'type': 'stabilized', \n         'gamma1': (-0.3, 0.8), 'gamma2': (-0.1, 0.7, 0.9),\n         'nu1': (-0.2,), 'nu2': (-0.05, 0.5),\n         'c_coeffs': (1, 2)},\n        # Case 3: unstabilized, f(A) = A1+A2\n        {'type': 'unstabilized', \n         'gamma1': (-0.3, 0.8), 'gamma2': (-0.1, 0.7, 0.9),\n         'nu1': None, 'nu2': None, # Not used\n         'c_coeffs': (1, 1)},\n        # Case 4: positivity stress test\n        {'type': 'stabilized', \n         'gamma1': (-3.0, 3.0), 'gamma2': (-2.5, 2.0, 2.0),\n         'nu1': (-0.2,), 'nu2': (-0.05, 0.5),\n         'c_coeffs': (1, 1)},\n    ]\n\n    results = []\n\n    for case in test_cases:\n        # Step 2: Compute Inverse Probability Weights (W)\n        \n        # Denominator probabilities\n        gamma10, gamma11 = case['gamma1']\n        p_den_t1 = expit(gamma10 + gamma11 * L0)\n        \n        gamma20, gamma21, gamma22 = case['gamma2']\n        p_den_t2 = expit(gamma20 + gamma21 * A1 + gamma22 * L1)\n\n        # Likelihood of observed treatment in denominator\n        like_den_t1 = A1 * p_den_t1 + (1 - A1) * (1 - p_den_t1)\n        like_den_t2 = A2 * p_den_t2 + (1 - A2) * (1 - p_den_t2)\n        \n        total_den_like = like_den_t1 * like_den_t2\n\n        # Numerator probabilities and total likelihood\n        if case['type'] == 'stabilized':\n            nu10, = case['nu1']\n            p_num_t1 = expit(nu10)\n            \n            nu20, nu21 = case['nu2']\n            p_num_t2 = expit(nu20 + nu21 * A1)\n            \n            like_num_t1 = A1 * p_num_t1 + (1 - A1) * (1 - p_num_t1)\n            like_num_t2 = A2 * p_num_t2 + (1 - A2) * (1 - p_num_t2)\n            \n            total_num_like = like_num_t1 * like_num_t2\n        else: # unstabilized\n            total_num_like = 1.0\n\n        # Final weights\n        weights = total_num_like / total_den_like\n\n        # Step 3: Weighted Least Squares (WLS) Estimation\n        c1, c2 = case['c_coeffs']\n        f_A = c1 * A1 + c2 * A2\n        \n        # Design matrix X with intercept and exposure summary\n        X = np.c_[np.ones(n), f_A]\n        \n        # Solve the normal equations for WLS: (X'WX)b = X'Wy\n        # This is more stable than direct inversion.\n        # Let X_w = sqrt(W) * X and Y_w = sqrt(W) * Y. Then solve (X_w'X_w)b = X_w'Y_w\n        sqrt_w = np.sqrt(weights)\n        X_w = X * sqrt_w[:, np.newaxis]\n        Y_w = Y * sqrt_w\n        \n        beta_hat = np.linalg.solve(X_w.T @ X_w, X_w.T @ Y_w)\n        \n        results.append(beta_hat.tolist())\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "4581093"}, {"introduction": "理想化的模型在应用于真实世界数据时常会遇到挑战，其中之一便是由接近违反正定性（positivity）假设而产生的极端权重。这个高级练习 [@problem_id:4581108] 探讨了权重截断（weight truncation）这一实用技术，并引导您分析其对估计结果带来的基本统计学影响。掌握偏倚-方差权衡是应用研究者从不完美数据中获得稳健因果推断的关键。", "problem": "一位研究者使用边际结构模型 (MSM) 来估计一个电子健康记录 (EHR) 队列中，时变肿瘤免疫治疗方案对一年生存率的因果效应。设个体 $i$ 的观测数据为 $Z_i=(Y_i,\\bar{A}_i,\\bar{L}_i)$，其中 $Y_i$ 是结局，$\\bar{A}_i$ 是治疗史，$\\bar{L}_i$ 是时变混杂因素史。目标参数 $\\beta_0$ 由工作MSM $m(\\bar{a};\\beta)$ 通过矩条件 $\\mathbb{E}\\{\\psi(Z;\\beta_0)\\}=0$ 定义，其中 $\\psi(Z;\\beta)$ 是从工作模型和潜在结局框架中导出的得分函数或估计函数。识别在标准的因果假设下进行：一致性、在每个时间点给定既往协变量和治疗下的条件可交换性、以及正值性。\n\n为估计 $\\beta_0$，该研究者使用逆概率加权 (IPW) 方法，其稳定权重 $SW_i$ 是通过基于既往协变量和治疗史的治疗模型和删失模型构建的。估计量 $\\hat{\\beta}$ 是加权估计方程 $\\frac{1}{n}\\sum_{i=1}^n SW_i\\,\\psi(Z_i;\\beta)=0$ 的解。$SW_i$ 的经验分布表现出重上尾，这与在 $\\bar{L}_i$ 的某些层中由于罕见的治疗模式而近乎违反了正值性假设有关。\n\n为了提高有限样本的稳定性，研究者考虑了一种基于修剪的截断规则，该规则将每个 $SW_i$ 映射到一个被限制在区间 $[l,u]$ 内的截断权重 $SW_i^{\\text{trunc}}$，其中 $0<l \\leq u < \\infty$。截断后的估计量 $\\hat{\\beta}_{\\text{trunc}}$ 是解方程 $\\frac{1}{n}\\sum_{i=1}^n SW_i^{\\text{trunc}}\\,\\psi(Z_i;\\beta)=0$ 的结果。\n\n选择所有正确描述权重截断在MSM中对估计量性质影响的陈述。\n\nA. 截断必然会在估计中引入偏倚。\n\nB. 截断会减小估计量的方差。\n\nC. 截断后的估计量对于一个不同于原始$\\beta_0$的目标参数是一致的。\n\nD. 如果用于计算权重的模型被正确指定，截断会提高估计量的效率。\n\nE. 引入的偏倚量取决于截断水平（即区间 $[l,u]$ 的选择）。\n\nF. 截断被认为是处理近乎违反正值性的一种有原则的、理论上最优的方法。", "solution": "用户提供了一个关于边际结构模型 (MSM) 的截断逆概率加权 (IPW) 估计量性质的问题陈述。我将首先验证该问题陈述，然后对每个选项进行详细分析。\n\n### 问题验证\n\n**步骤1：提取已知条件**\n-   个体 $i$ 的数据：$Z_i=(Y_i,\\bar{A}_i,\\bar{L}_i)$，其中 $Y_i$ 是结局，$\\bar{A}_i$ 是治疗史，$\\bar{L}_i$ 是时变混杂因素史。\n-   工作MSM：$m(\\bar{a};\\beta)$。\n-   目标参数：$\\beta_0$，由矩条件 $\\mathbb{E}\\{\\psi(Z;\\beta_0)\\}=0$ 定义，其中 $\\psi(Z;\\beta)$ 是得分函数。\n-   因果假设：一致性、条件可交换性、正值性。\n-   $\\beta_0$的估计量：$\\hat{\\beta}$ 是IPW估计方程 $\\frac{1}{n}\\sum_{i=1}^n SW_i\\,\\psi(Z_i;\\beta)=0$ 的解，其中 $SW_i$ 是稳定权重。\n-   问题：$SW_i$ 的分布由于近乎违反正值性而具有重尾。\n-   提议的干预措施：权重截断，定义 $SW_i^{\\text{trunc}} = \\max(l, \\min(SW_i, u))$，其中区间为 $[l, u]$ 且 $0<l \\leq u < \\infty$。\n-   截断后的估计量：$\\hat{\\beta}_{\\text{trunc}}$ 是新估计方程的解。\n\n**步骤2：使用提取的已知条件进行验证**\n该问题在科学上是合理的。它提出了一个在应用因果推断中常见且重要的实际问题：处理由近乎违反正值性引起的极端IPW权重。所描述的权重截断方法是解决此问题的标准实用技术。所提出的每个选项（A-F）都涉及该技术对估计量统计性质（如偏倚、方差、一致性、效率）的影响，这些都是统计推断中的核心概念。问题设定清晰、客观，并且不包含内部矛盾。\n\n**步骤3：结论与行动**\n该问题被判定为有效。将对每个选项进行详细分析，以确定正确答案。\n\n### 选项分析\n\n**A. 截断必然会在估计中引入偏倚。**\n**正确。** 原始的IPW估计量 $\\hat{\\beta}$之所以是一致的（即渐近无偏的），是因为其估计方程的期望为零：$\\mathbb{E}[SW_i\\,\\psi(Z_i;\\beta_0)]=0$。这是在所有因果假设和模型正确指定的前提下，由IPW理论保证的。当权重被截断时，新的估计方程为 $\\frac{1}{n}\\sum_{i=1}^n SW_i^{\\text{trunc}}\\,\\psi(Z_i;\\beta)=0$。由于 $SW_i^{\\text{trunc}}$ 不再精确地等于真实的逆概率权重比，一般情况下 $\\mathbb{E}[SW_i^{\\text{trunc}}\\,\\psi(Z_i;\\beta_0)] \\neq 0$。这意味着截断后的估计量 $\\hat{\\beta}_{\\text{trunc}}$ 对于原始目标参数 $\\beta_0$ 是有偏的。只要有任何权重被实际截断，就会引入这种偏倚。然而，如果未截断的估计量由于极端权重而具有巨大的方差，截断的估计量可能具有更低的均方误差（MSE = 偏倚^2 + 方差），这在实践中可能是可取的。但这并不否定它对于原始目标参数 $\\beta_0$ 是有偏的这一事实。\n\n**B. 截断会减小估计量的方差。**\n**正确。** 这是进行权重截断的主要动机。极端权重（非常大的值）会不成比例地影响估计方程的解，从而导致估计量在不同样本间具有高度的可变性，即方差很大。通过将这些极端权重“拉回”到一个更合理的范围内，截断减小了个别观测值对最终估计的杠杆作用，从而使估计量更加稳定，即减小了其有限样本方差。这通常会以引入偏倚为代价换取方差的减小。\n\n**C. 截断后的估计量对于一个不同于原始$\\beta_0$的目标参数是一致的。**\n**正确。** 这是对截断效应的更深入理解。$\\hat{\\beta}_{\\text{trunc}}$ 收敛于 $\\beta_0^{\\text{trunc}}$，其中 $\\beta_0^{\\text{trunc}}$ 是新估计方程 $\\mathbb{E}[SW_i^{\\text{trunc}}\\,\\psi(Z_i;\\beta)]=0$ 的解。这个新的目标参数 $\\beta_0^{\\text{trunc}}$ 通常不同于原始的 $\\beta_0$。它所描述的因果效应对应于一个假设的“截断”总体，在该总体中，处理分配的概率被人为地限制在远离0和1的范围内。因此，尽管对于 $\\beta_0$ 来说是有偏的，但 $\\hat{\\beta}_{\\text{trunc}}$ 是一致地估计了一个不同的、明确定义的目标参数 $\\beta_0^{\\text{trunc}}$。\n\n**D. 如果用于计算权重的模型被正确指定，截断会提高估计量的效率。**\n**错误。** 效率在统计学中通常指在某类估计量（如无偏估计量）中达到最低的方差。IPW估计量（在模型正确指定时）是半参数有效的，或可以通过增广达到半参数效率界。截断引入了偏倚，因此它不是一个“有效”的估计量，因为它甚至不属于通常考虑效率的无偏估计量类别。虽然它减小了方差，但这是以偏倚为代价的，这种权衡并不等同于效率的提高。\n\n**E. 引入的偏倚量取决于截断水平（即区间 $[l,u]$ 的选择）。**\n**正确。** 截断的程度，由截断边界 $l$ 和 $u$ 决定，直接决定了引入的偏倚量。更严格的截断（例如，更小的 $u$）会影响更多的权重，使 $\\mathbb{E}[SW_i^{\\text{trunc}}\\,\\psi(Z_i;\\beta_0)]$ 离零更远，从而导致更大的偏倚。相反，非常宽松的截断（非常大的 $u$）只会影响最极端的权重，引入的偏倚较小，但可能在减小方差方面效果也较差。\n\n**F. 截断被认为是处理近乎违反正值性的一种有原则的、理论上最优的方法。**\n**错误。** 权重截断是一种**实用的、特设的（ad-hoc）**方法。虽然它在实践中非常普遍且有用，但它缺乏坚实的理论基础来指导截断水平的选择。选择截断点通常是基于经验法则（例如，修剪掉权重的第99个百分位数以上的值）或诊断图。相比之下，一些替代方法，如使用增广IPW（AIPW）或直接针对一个修改后的、具有更好正值性属性的目标参数进行估计，可能被认为更有原则性。\n\n### 结论\nA、B、C和E都是关于估计量统计性质的正确陈述。D和F是错误的。问题要求选择所有正确的陈述。\n\n最终答案为 A, B, C, E。", "answer": "$$\\boxed{ABCE}$$", "id": "4581108"}]}