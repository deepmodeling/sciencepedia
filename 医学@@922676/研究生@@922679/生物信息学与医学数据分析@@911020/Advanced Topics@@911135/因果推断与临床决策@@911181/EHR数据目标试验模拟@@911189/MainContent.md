## 引言
电子健康记录（EHR）蕴含着海量的真实世界临床数据，为回答传统随机对照试验（RCT）因伦理或成本所限而无法解决的因果问题提供了前所未有的机遇。然而，直接利用这些在常规诊疗中产生的观察性数据进行分析，极易因混杂、选择偏倚等系统性误差而得出错误结论。为了弥合[观察性研究](@entry_id:174507)与可靠因果推断之间的鸿沟，目标试验模拟（Target Trial Emulation）框架应运而生，它倡导将任何观察性分析都严谨地设计为对一个理想化RCT的模拟。

本文将作为一份全面的指南，系统性地引领读者掌握利用EHR数据进行目标试验模拟的全过程。在第一部分“原则与机制”中，我们将深入剖析该框架的理论基石，阐明进行有效因果识别所必须遵循的核心假设和设计原则，并揭示如何规避不[死时间](@entry_id:273487)偏倚等常见陷阱。接下来的“应用与交叉学科联系”部分，将通过一系列真实世界案例，展示如何处理EHR数据的复杂性、模拟动态治疗方案，并探讨该方法在监管科学和真实世界证据生成中的前沿应用。最后，在“动手实践”部分，读者将有机会通过具体的练习，将所学知识应用于解决表型构建、混杂控制和敏感性分析等实际研究挑战。通过这一结构化的学习路径，我们将从理论基础出发，逐步迈向高级应用与实践操作。

## 原则与机制

利用电子健康记录（EHR）数据进行因果推断的核心挑战，在于如何从本质上属于观察性的、在常规临床实践中产生的数据中，梳理出清晰、无偏的治疗效果估计。直接比较接受治疗和未接受治疗的患者群体，往往会因多种偏倚而产生误导性结论。目标试验模拟（Target Trial Emulation）框架为应对这一挑战提供了一套系统性的科学方法。其核心思想是，任何一项基于观察性数据的因果分析，都应被视为对一个（通常是假设的）理想化随机对照试验（RCT）的模拟。本章将深入阐述支撑目标试验模拟的各项原则与机制，剖析常见的偏倚来源，并介绍为获得有效因果估计而必须遵循的设计与分析策略。

### 目标试验模拟框架：用观察性数据提出因果问题

随机对照试验（RCT）被视为评估干预措施效果的“金标准”，因为它通过随机分配处理的方式，在期望上保证了各治疗组在所有基线特征（无论测量与否）上的可比性。然而，许多重要的临床问题由于伦理、成本或可行性等原因无法通过RCT来解答。EHR数据覆盖了大量真实世界的患者群体和长期的临床实践，为这些问题提供了宝贵的研究资源。目标试验模拟框架的作用，就是将RCT的严谨设计原则作为一份“蓝图”，指导我们如何利用EHR数据构建和分析一个[观察性研究](@entry_id:174507)，使其尽可能地逼近这个理想的“目标试验”。

要清晰地模拟一个目标试验，我们必须首先明确定义该试验的七个核心组成部分[@problem_id:4612490]。这一过程不仅能澄清我们的研究问题，还能预先识别出潜在的偏倚来源。

1.  **合格标准 (Eligibility Criteria)**: 定义目标试验所研究的特定人群。这包括年龄、诊断、疾病严重程度、既往病史等。在EHR模拟中，这对应于利用诊断代码、实验室检查结果、人口统计学信息和既往用药记录等来构建研究队列。

2.  **治疗策略 (Treatment Strategies)**: 明确定义被比较的干预措施。这些策略必须是现实中可能实施的，并且需要在试验开始时就能确定。例如，比较“在基线时启动他汀类药物治疗”与“在基线时不启动[他汀类药物](@entry_id:167025)治疗”。

3.  **治疗分配 (Treatment Assignment)**: 在理想试验中，这是通过随机化实现的。在EHR模拟中，由于治疗是由患者和医生决定的，分配过程是非随机的。我们的核心任务是利用可测量的基线混杂因素，通过统计学方法（如倾向性评分加权或匹配）来模拟随机化，以达到各组间的可比性。

4.  **时间零点 (Time Zero)**: 这是每个合格个体开始接受治疗策略分配、并开始计算随访时间的精确时间点。所有试验参与者的“起跑线”必须对齐。错误地定义或对齐时间零点是导致“不[死时间](@entry_id:273487)偏倚”的主要原因之一。

5.  **随访期 (Follow-up Period)**: 从时间零点开始，对每个个体进行结果监测的持续时间。随访在发生结局事件、失访、研究结束或偏离方案时终止。

6.  **结局 (Outcomes)**: 需要明确定义的、可被客观测量的临床事件或健康状况变化。在EHR模拟中，这通常通过经过验证的表型算法（phenotyping algorithms），即诊断代码、程序代码或自然语言处理的组合来识别。

7.  **因果估计量 (Causal Estimand)**: 这是我们希望估计的、具有因果解释的具体数值。例如，比较不同治疗策略下发生结局的风险差异（Risk Difference）或风险比（Risk Ratio）。它明确了我们关心的因果对比是什么。

以一项模拟他汀类药物启动治疗对心血管事件影响的研究为例[@problem_id:4612490]，一个明确的目标试验方案可能是：合格标准为年龄40-75岁、[低密度脂蛋白胆固醇](@entry_id:172654)（LDL-C）高于$130 \text{ mg/dL}$、且过去一年内无[他汀类药物](@entry_id:167025)使用史的个体；治疗策略为“在时间零点后的7天宽限期内启动任意他汀类药物”对比“在该宽限期内不启动”；时间零点定义为合格的LDL-C检测结果日期；随访3年，结局为首次发生主要不良心血管事件。这一清晰的方案为后续的EHR数据分析提供了明确的指引。

### 因果识别的核心假设

为了从观察性数据中识别出因果效应，我们需要依赖三个核心假设。这些假设构成了从相关性走向因果性的理论桥梁。

#### 一致性 (Consistency)

一致性假设将我们观察到的现实与我们关心的潜在结局（Potential Outcomes）联系起来。令$Y$为观察到的结局，而$Y^a$为在接受治疗策略$a$下的潜在结局。一致性假设指出，如果一个体实际接受的治疗策略是$a$（即$A=a$），那么他/她观察到的结局$Y$就等于其在该策略下的潜在结局$Y^a$。

这个看似不言自明的假设在处理EHR数据时面临一个严峻的挑战：**治疗版本的异质性 (Treatment Version Heterogeneity)** [@problem_id:4612526]。在EHR中，一个粗略的治疗变量，如“启动他汀类药物”（$A=1$），实际上可能包含了许多不同的具体药物（如阿托伐他汀、瑞舒伐[他汀](@entry_id:167025)）、不同剂量和不同强度。如果这些不同版本的治疗对结局有不同的影响，那么一个统一的潜在结局$Y^1$就不再是明确定义的。此时，一个患者观察到的结局$Y$实际上对应于某个特定版本$v$的潜在结局$Y^{1,v}$。由于不同版本的效应可能不同（即$Y^{1,v_1} \ne Y^{1,v_2}$），这就违反了“无隐藏治疗版本”的假设，从而破坏了一致性。

应对这一挑战的策略是使因果问题更加具体化。例如，我们可以将研究限制在某个特定版本（如“启动高强度阿托伐[他汀](@entry_id:167025)”），或者将不同的版本视为不同的治疗策略进行比较，或者估计一个明确定义的随机干预（stochastic intervention）的效果，比如将观察到的版本分布通过加权调整到一个预设的目标分布。

#### 可交换性 (Exchangeability)

可交换性是因果推断的核心。在理想的RCT中，由于随机化，治疗组和[对照组](@entry_id:188599)在所有基线特征上是可交换的，这意味着治疗分配$A$与潜在结局$Y^a$是相互独立的，即$Y^a \perp A$。因此，除了治疗本身，两组发生结局的风险在基线时是相同的。

在观察性研究中，这种**无条件可交换性 (unconditional exchangeability)** 几乎总是不成立的。医生会基于患者的风险高低来决定是否开具处方，这种现象被称为**“适应证混杂” (confounding by indication)**。例如，心血管风险越高的患者越有可能被给予他汀类药物治疗。为了解决这个问题，我们退而求其次，依赖于一个更弱但更现实的假设：**条件可交换性 (conditional exchangeability)** [@problem_id:4612585]。该假设表述为，在控制了一系列充分的基线混杂因素$L$之后，治疗分配$A$与潜在结局$Y^a$在$L$的每个层内是独立的，即$Y^a \perp A \mid L$。

这个假设的含义是，在具有相同基线特征$L$的患者群体中，那些恰好接受治疗的患者与那些恰好未接受治疗的患者，在他们的潜在结局方面是可比的，仿佛治疗是在这个亚组内被“随机”分配的。研究设计的关键就在于通过精心选择研究人群和测量足够丰富的基线协变量$L$，使得这个“as-if random”的假设尽可能成立。

#### 正性 (Positivity)

正性，也称为重叠性（overlap），要求在所有具有特定协变量特征$L=l$的人群亚组中，接受每种治疗策略的概率都必须大于零，即$P(A=a \mid L=l) > 0$。这个假设保证了在数据的每个角落，我们都有机会观察到所有不同的治疗选择，从而能够进行有意义的比较。

在EHR数据中，正性假设可能因**结构性原因 (structural reasons)** 而被违反。一个典型的例子是存在治疗禁忌证[@problem_id:4612445]。假设某药物对于患有严重肝功能衰竭的患者是禁忌的。在该亚组中（$L$=严重肝衰），医生绝不会开具该药物，因此治疗概率$P(A=1 \mid L=\text{严重肝衰}) = 0$。这就导致了正性假设的违反。在这种情况下，我们无法从数据中得知，如果这些患者被给予了治疗，他们的结局会是怎样。因此，对于包含这个亚组的整个目标人群，该药物的平均因果效应是无法被识别的。

面对结构性正性违规，一个原则性的解决方案是修改研究问题。我们可以将目标人群限制在正性假设成立的范围内，例如，将合格标准修改为“无严重肝功能衰竭的患者”，并明确声明我们的因果效应估计仅适用于这个新的、更窄的目标人群。

### 关键偏倚及其规避设计原则

天真地分析观察性数据会掉入许多偏倚的陷阱。目标试验模拟框架通过强调严谨的研究设计来系统性地规避这些偏倚。

#### 适应证混杂与新用户设计

如前所述，适应证混杂是观察性研究的中心难题[@problem_id:4612511]。患者的疾病严重程度和预后风险既是决定其是否接受治疗的原因，也是影响其结局的因素。为了打破这种混杂关联，我们需要在分析中对这些[共同原因](@entry_id:266381)（即混杂因素$L$）进行调整。

**新用户设计 (New-User Design)** 是一个强有力的设计原则，旨在使基线时的治疗组和[对照组](@entry_id:188599)尽可能具有可比性[@problem_id:4612494]。该设计要求研究队列只纳入新近开始使用目标药物的“新用户”，并排除那些在研究开始前就已经在服用该药物的“现患用户”（prevalent users）。这是因为现患用户在很多方面都与新用户不同：他们可能对药物有更好的耐受性（否则他们可能已经停药），他们的疾病可能更慢性或更稳定，这些都会引入难以控制的偏倚。

新用户设计还有助于建立一个清晰的**时间零点**，即治疗决策发生的时刻。通过比较在同一时间点上开始用药的患者和符合条件但未开始用药的患者，我们可以更好地模拟RCT中的基线比较。一个更优化的策略是**活性药物比较者、新用户设计 (active-comparator, new-user design)** [@problem_id:4612494]，即比较两种用于相同适应证的不同药物的新用户。例如，比较[质子泵抑制剂](@entry_id:152315)（PPI）的新用户和[组胺](@entry_id:173823)-2受体拮抗剂（H2RA）的新用户。由于这两组患者都已被诊断并接受了治疗决策，他们在疾病严重程度等方面的可比性可能比与“不治疗”组相比更高。

#### 不[死时间](@entry_id:273487)偏倚与时间零点的对齐

**不死时间偏倚 (Immortal Time Bias)** 是一种由于对随访时间分类错误而导致的严重偏倚。它通常发生在错误地将受试者在开始治疗之前的随访时间归类于“治疗组”时[@problem_id:4612475]。顾名思义，在这段“不死时间”里，个体必须保持存活才能在后续时点开始治疗，因此治疗组在这段时间内的死亡风险被人为地设定为零。

让我们看一个具体的例子[@problem_id:4612475]。假设一个研究将“在随访期间任何时候启动他汀类药物”的患者定义为治疗组。某患者在队列研究开始后的第4个月启动了[他汀](@entry_id:167025)治疗。如果分析师错误地将该患者从第0个月到第12个月的全部12个月随访时间都算作“治疗组”的暴露人时，那么从第0到第4个月的这段时间就是不[死时间](@entry_id:273487)。该患者在这4个月内不可能死亡并同时被归入治疗组。这种错误分类会人为地夸大治疗组的总人时数分母，从而导致其死亡率（或风险）被严重低估，产生药物有效的假象。

规避不[死时间](@entry_id:273487)偏倚的唯一方法是严格遵循目标试验的**时间零点对齐**原则[@problem_id:4612439]。所有研究参与者的随访必须从同一个逻辑时间点——时间零点——开始。这个时间点标志着合格标准的满足和治疗策略的分配。对于治疗组和非治疗组，时间零点的定义必须一致。例如，可以统一将满足条件的诊断日期或实验室检查日期作为所有人的时间零点。

在实践中，治疗启动可能不会恰好发生在时间零点。一种先进的处理方法是**风险集匹配 (risk-set matching)** [@problem_id:4612439]。对于每一个在$t$时刻启动治疗的患者，我们从那些在$t$时刻仍然合格、存活且尚未启动治疗的患者（即风险集）中，为其匹配一个或多个对照者。然后，将这个$t$时刻作为这对匹配者的共同时间零点，并从此刻开始计算随访。这种方法动态地构建了可比较的组，有效地避免了不[死时间](@entry_id:273487)偏倚。

最后，至关重要的是，所有用于调整混杂的基线协变量$L$都必须是在**时间零点之前**测量的。如果在时间零点之后测量协变量，该变量可能已经是治疗的中间效应物（mediator）或与治疗共同作用的结果（collider），调整这些变量会引入新的偏倚，而非消除偏倚[@problem_id:4612511]。

### 定义因果问题：意向性治疗效应与依从方案效应

在EHR数据中，患者的行为是动态变化的：他们可能在研究中途开始治疗（交叉，crossover），也可能中途停止治疗（停药，discontinuation）。我们关心的因果问题，必须明确如何处理这些治疗变动。这引出了两种主要的因果估计量：意向性治疗效应和依从方案效应[@problem_id:4612545]。

#### 意向性治疗效应 (Intention-to-Treat, ITT)

ITT效应评估的是**初始治疗策略分配**的效果，而非实际接受治疗的效果。它回答的问题是：“将患者分配到‘启动治疗’策略（无论他们后续是否坚持）与分配到‘不启动治疗’策略相比，对结局有何影响？”

在EHR模拟中，ITT分析遵循“once assigned, always analyzed”的原则：
1.  **分组依据**：根据时间零点的治疗决策（$A_0$）将患者分为“初始治疗组”和“初始[对照组](@entry_id:188599)”。
2.  **随访**：对所有患者进行完整随访，直至结局发生或研究结束。**不**因患者后续的治疗交叉或停药而将其审查（censor）或重新分组。
3.  **分析**：比较两个基线分组的结局风险。混杂控制仅需在时间零点进行，即调整基线混杂因素$L_0$。

ITT效应的优势在于它避免了因依从性等治疗后行为引入的选择偏倚，并且通常能更好地反映在真实世界中推荐一种治疗策略的“实用”效果。

#### 依从方案效应 (Per-Protocol, PP)

PP效应评估的是**完全依从**于预设治疗方案的效果。它回答的问题是：“如果患者能够始终坚持‘持续治疗’方案，与始终坚持‘不治疗’方案相比，对结局有何影响？”

在EHR数据中估计PP效应要复杂得多，因为它面临**受过往治疗影响的时变混杂 (time-varying confounding affected by prior treatment)** [@problem_id:4612512]。这里的挑战在于，患者在每个时间点$t$是否继续依从治疗（即$A_t$的取值），可能受到当前健康状况$L_t$的影响；而这个$L_t$本身又可能受到过去治疗$A_{t-1}$的影响。例如，上个月的降压治疗($A_{t-1}$)会影响这个月的血压($L_t$)，而这个月的血压($L_t$)又会影响医生是否调整治疗方案($A_t$)以及患者未来的心血管风险($Y$)。

在这种反馈循环中，$L_t$既是未来治疗$A_t$的**混杂因素**，又是过去治疗$A_{t-1}$的**中介因素**。标准的[回归模型](@entry_id:163386)（如包含时依协变量的[Cox模型](@entry_id:164053)）无法处理这种情况。如果在模型中调整$L_t$以控制$A_t$的混杂，就会错误地阻断$A_{t-1}$通过$L_t$介导的因果路径，导致对整个治疗方案效果的估计产生偏倚。

正确的处理方法是使用**G方法 (G-methods)**，它们是为处理此类时变混杂而设计的。主要包括：
-   **边际结构模型 (Marginal Structural Models, MSM)**: 通过**[逆概率](@entry_id:196307)治疗加权 (Inverse Probability of Treatment Weighting, IPTW)**，为每个患者在每个时间点创建一个权重，该权重是其接受实际治疗的概率的倒数。通过加权，可以创建一个伪人群（pseudo-population），在这个伪人群中，治疗分配与时变混杂因素之间不再有关联，从而可以无偏地估计PP效应。当处理因偏离方案而导致的审查时，则使用**逆概率审查加权 (Inverse Probability of Censoring Weighting, IPCW)** [@problem_id:4612545]。
-   **参数G公式 (Parametric G-formula)**: 这种方法通过对结局和时变混杂因素的分布进行建模，然后通过蒙特卡洛模拟来估计在强制执行某个特定治疗方案（如“始终治疗”或“始终不治疗”）下的结局分布。通过比较不同方案下模拟出的平均结局，即可得到PP效应的估计[@problem_id:4612545] [@problem_id:4612512]。

总之，ITT效应和PP效应回答的是不同的因果问题，需要采用截然不同的分析策略。ITT分析相对简单，关注初始分配；而PP分析更为复杂，关注持续依从的效果，必须使用G方法来妥善处理时变混杂。在进行目标试验模拟时，清晰地定义所要估计的是哪种效应，是确保研究结论具有科学意义和[可解释性](@entry_id:637759)的前提。