## 引言
在生物医学和公共卫生研究中，我们常常希望评估某项干预措施或暴露因素的真实因果效应。然而，由于伦理或实践限制，大规模的随机对照试验（RCT）并非总是可行，研究人员不得不依赖于大量的观测数据。这些数据，如电子健康记录或登记数据，虽然丰富，却内在地受到“混杂偏倚”的困扰——即处理组与[对照组](@entry_id:188599)之间在基线特征上存在系统性差异，从而使得直接比较的结果并不能反映真实的因果关系。如何从这类充满偏倚的数据中提取可靠的因果结论，是现代数据分析面临的一大核心挑战。

倾向性得分（Propensity Score）方法正是为应对这一挑战而生的一套强大统计学工具。它提供了一个严谨的框架，通过模拟随机化过程，在非实验性研究中平衡处理组与[对照组](@entry_id:188599)的协变量分布，从而允许我们更准确地估计因果效应。本文旨在系统性地介绍倾向性得分方法的理论与实践。我们将分三个章节展开：

第一章“原理与机制”，将深入剖析因果推断的根本问题、[潜在结果框架](@entry_id:636884)以及支撑倾向性得分方法的关键假设，并详细介绍倾向性得分的定义、性质及其估计方法。

第二章“应用与跨学科连接”，将通过药物流行病学、药物基因组学和医疗人工智能等领域的真实案例，展示倾向性得分在不同场景下的具体应用、高级扩展（如处理时变混杂和缺失数据）以及与现代机器学习方法的融合。

第三章“动手实践”，将提供一系列精心设计的问题，帮助读者巩固核心概念，如评估协变量平衡性、理解不同加权策略以及规避变量选择中的常见陷阱。

通过本文的学习，您将掌握一套在观测研究中进行严谨因果推断的核心方法论，为您的科研工作提供有力的支持。

## 原理与机制

本节将从因果推断的根本挑战出发，阐述从观测数据中识别因果效应所需满足的关键假设。随后，我们将详细定义倾向性得分，并解释其如何作为一个强大的工具，来解决高维数据中的混杂偏倚问题。最后，我们将讨论倾向性得分模型的构建策略以及在不同因果效应估计目标下的具体应用方法，并剖析变量选择中的常见误区。

### 因果推断的根本挑战与核心 estimand

在生物医学研究中，我们常常希望评估某项干预措施（如一种新疗法）的因果效应。例如，我们想知道接受[靶向治疗](@entry_id:261071)是否能改善肿瘤患者的分子反应评分。为了形式化地定义这一问题，我们引入**[潜在结果](@entry_id:753644) (potential outcomes)** 框架 [@problem_id:4599527] [@problem_id:5221120]。

对于每个研究个体 $i$，我们定义两个潜在结果：$Y_i(1)$ 表示个体 $i$ 接受处理（$T_i=1$）时的潜在结局，而 $Y_i(0)$ 表示该个体未接受处理（$T_i=0$）时的潜在结局。因此，对于个体 $i$ 而言，处理的因果效应可以定义为 $Y_i(1) - Y_i(0)$。

然而，我们面临一个**因果推断的根本问题**：对于任何一个个体，我们只能观测到其两个潜在结果中的一个。如果个体 $i$ 接受了处理（$T_i=1$），我们观测到 $Y_i = Y_i(1)$，而其未接受处理的[潜在结果](@entry_id:753644) $Y_i(0)$ 则成为一个无法观测到的**反事实 (counterfactual)**。反之亦然。我们永远无法同时观测到同一个体的 $Y_i(1)$ 和 $Y_i(0)$。

由于个体层面的因果效应无法直接计算，我们转而关注群体层面的平均因果效应。根据目标人群的不同，主要有以下三种**因果 estimand（估计目标）** [@problem_id:4830861]：

1.  **平均处理效应 (Average Treatment Effect, ATE)**：这是指在整个目标人群中，处理的平均因果效应。其定义为：
    $ATE = \mathbb{E}[Y(1) - Y(0)]$
    ATE 回答的问题是：“如果我们将整个人群从不接受处理变为全部接受处理，结局的平均变化会是多少？”

2.  **处理组的平均处理效应 (Average Treatment Effect on the Treated, ATT)**：这是指在实际接受了处理的人群中，处理的平均因果效应。其定义为：
    $ATT = \mathbb{E}[Y(1) - Y(0) \mid T=1]$
    ATT 回答的问题是：“对于那些已经接受了处理的个体，这项处理平均给他们带来了多大的效应？”

3.  **[控制组](@entry_id:188599)的平均处理效应 (Average Treatment Effect on the Controls, ATC)**：这是指在实际未接受处理（即[控制组](@entry_id:188599)）的人群中，处理的平均因果效应。其定义为：
    $ATC = \mathbb{E}[Y(1) - Y(0) \mid T=0]$
    ATC 回答的问题是：“如果让那些未接受处理的个体当初接受了处理，他们的结局平均会发生多大变化？”

在观测研究中，由于处理分配不是随机的，处理组和[控制组](@entry_id:188599)的基线特征（即**协变量 (covariates)**）可能存在系统性差异。例如，病情更重的患者可能更倾向于接受一种新的、有风险但可能更有效的治疗。这种差异导致了**混杂 (confounding)**，使得直接比较两组的观测结局均值（即 $\mathbb{E}[Y \mid T=1] - \mathbb{E}[Y \mid T=0]$）通常不等于任何一个有意义的因果效应（ATE、ATT 或 ATC），这种偏差称为**选择偏倚 (selection bias)**。

### 因果识别的三个关键假设

为了从充满偏倚的观测数据中识别出真实的因果效应，我们需要借助一系列假设来连接可观测数据与不可观测的[潜在结果](@entry_id:753644)。这三个核心假设是倾向性得分方法乃至整个因果推断领域的理论基石 [@problem_id:4599527] [@problem_id:5221120] [@problem_id:4599459]。

1.  **稳定单元处理价值假设 (Stable Unit Treatment Value Assumption, SUTVA)**：
    SUTVA 包含两个子假设：
    *   **一致性 (Consistency)**：任何个体的观测结局，等于其在实际接受的处理水平下的潜在结果。形式化地，若个体 $i$ 接受的处理为 $T_i$，其观测结局为 $Y_i$，则 $Y_i = Y_i(T_i)$。这意味着 $T_i=1$ 时 $Y_i = Y_i(1)$，$T_i=0$ 时 $Y_i = Y_i(0)$。此假设排除了处理存在不同版本或定义不清的情况。
    *   **无干涉 (No Interference)**：一个个体的潜在结果不受其他个体所接受的处理的影响。这使得我们可以将个体 $i$ 的潜在结果写为仅依赖其自身处理的 $Y_i(a)$，而不是依赖于整个群体处理分配向量的复杂函数。

2.  **条件[可交换性](@entry_id:263314) (Conditional Exchangeability) 或无混杂性 (Unconfoundedness)**：
    这是克服混杂偏倚的核心假设。它断言，在控制了所有重要的基线协变量 $X$ 之后，处理的分配与[潜在结果](@entry_id:753644)是相互独立的。形式化地：
    $(Y(1), Y(0)) \perp T \mid X$
    这个假设的直观含义是，在任何由协变量 $X$ 定义的同质子群体（stratum）内部，接受处理的个体和未接受处理的个体是**可交换的 (exchangeable)**。也就是说，在调整了 $X$ 之后，处理分配机制是“**仿佛随机化的 (as-if randomized)**” [@problem_id:4599459] [@problem_id:4943138]。这意味着 $X$ 必须包含所有同时影响处理决策和结局的**[共同原因](@entry_id:266381) (common causes)**，即所有的**混杂因素 (confounders)**。例如，在一个由[有向无环图 (DAG)](@entry_id:748452) 表示的[因果结构](@entry_id:159914)中，如果存在一条从处理 $A$ 到结局 $Y$ 的“后门路径” (backdoor path)，如 $A \leftarrow L \rightarrow Y$（其中 $L$ 是一个混杂因素），那么为了满足无混杂性，我们必须将 $L$ 纳入协变量集 $X$ 中进行调整，以阻断这条非因果路径 [@problem_id:4943138]。需要强调的是，无混杂性是一个**无法通过数据验证的假设**，因为它涉及不可观测的[潜在结果](@entry_id:753644)。研究者必须基于领域知识来论证所测量的协变量集 $X$ 是否充分。

3.  **正性 (Positivity) 或重叠性 (Overlap)**：
    该假设要求，对于协变量空间中任何可能出现的特征组合 $x$，个体接受处理或不接受处理的概率都必须大于零。形式化地，对于所有在 $X$ 分布支撑集内的 $x$：
    $0 \lt \mathbb{P}(T=1 \mid X=x) \lt 1$
    正性保证了对于任何类型的患者，我们总能找到接受处理的个体和未接受处理的个体作为比较对象。如果对于某个亚组（例如，具有某种禁忌症的患者），接受处理的概率为 $0$ 或 $1$，那么对于这个亚组，我们将永远无法观测到其中一种[潜在结果](@entry_id:753644)，因果比较也就无从谈起。正性是**识别 (identification)** 的一个必要条件，而非仅仅是数值计算上的便利。如果正性不满足，例如因为对于某个 $x$ 的子集 $S_x$，$\mathbb{P}(T=1 \mid X \in S_x)=0$，那么对于这部分人群的潜在结果均值 $\mathbb{E}[Y(1) \mid X \in S_x]$ 就无法从数据中得知，从而导致整体的 ATE 无法被非参数地识别 [@problem_id:4830839]。

在满足 SUTVA、条件[可交换性](@entry_id:263314)和正性这三个假设的前提下，平均因果效应是**可识别的**。例如，ATE 可以通过 G-computation 公式识别：
$ATE = \mathbb{E}_{X}\{\mathbb{E}[Y \mid T=1, X] - \mathbb{E}[Y \mid T=0, X]\}$
这个公式的含义是，我们首先在每个由 $X$ 定义的亚组内计算处理组和[控制组](@entry_id:188599)的平均结局差异，然后根据 $X$ 在总人群中的分布对这些差异进行加权平均。

### 倾向性得分：[高维数据](@entry_id:138874)的[降维](@entry_id:142982)工具

尽管 G-computation 公式在理论上解决了识别问题，但在实践中，尤其是当协变量 $X$ 是高维向量时（例如，包含临床变量和基因组学数据），直接对 $X$ 进行分层或匹配变得不可行，这就是所谓的“[维度灾难](@entry_id:143920)”。

**倾向性得分 (Propensity Score)**，由 Rosenbaum 和 Rubin 在 1983 年提出，为这一难题提供了优雅的解决方案。倾向性得分 $e(X)$ 定义为在给定一系列基线协变量 $X$ 的条件下，个体接受处理的[条件概率](@entry_id:151013) [@problem_id:4830874]：
$e(X) = \mathbb{P}(T=1 \mid X)$

倾向性得分作为一个将高维协变量向量 $X$ 映射到 $[0, 1]$ 区间的一维标量，具有两个至关重要的理论性质 [@problem_id:4599459] [@problem_id:4599517]：

1.  **平衡得分性质 (Balancing Score Property)**：在倾向性得分的任何一个[水平集](@entry_id:751248)（level set）上，处理分配 $T$ 与协变量 $X$ 是相互独立的。形式化地：
    $X \perp T \mid e(X)$
    这意味着，如果我们选取一群倾向性得分完全相同的个体（例如，所有 $e(X)=0.3$ 的人），那么在这个亚群中，处理组和[控制组](@entry_id:188599)的协变量 $X$ 的分布是完全相同的。从几何上看，倾向性得分的水平集 $L_c = \{x : e(x) = c\}$ 是高维协变量空间中的一个[等值面](@entry_id:196027)（或等值线的集合）。平衡性质保证了，无论原始数据中处理组和[控制组](@entry_id:188599)的协变量分布差异有多大，只要我们限制在同一个 $e(X)$ 等值面上进行比较，这种差异就会被消除 [@problem_id:4599517]。

2.  **作为无混杂性调整的充分性**：如果在协变量 $X$ 上满足条件[可交换性](@entry_id:263314)，那么在倾向性得分 $e(X)$ 上也满足条件[可交换性](@entry_id:263314)。即：
    若 $(Y(1), Y(0)) \perp T \mid X$，则 $(Y(1), Y(0)) \perp T \mid e(X)$
    这个性质是倾向性得分方法的核心。它表明，为了控制由高维协变量 $X$ 引起的混杂，我们无需对 $X$ 的每一个维度进行调整，而只需调整一维的倾向性得分 $e(X)$ 即可。这极大地简化了调整过程，有效地解决了[维度灾难](@entry_id:143920)问题。

### 倾向性得分的估计与应用

倾向性得分 $e(X)$ 是一个未知的条件概率，需要从观测数据 $(T_i, X_i)$ 中进行估计。通常，我们使用一个[概率模型](@entry_id:265150)来拟合处理分配机制。最常用的模型是**逻辑斯蒂回归 (logistic regression)**。假设我们认为倾向性得分的[对数几率](@entry_id:141427)（logit）与协变量 $X$ 呈线性关系，即 $\ln(\frac{e(X)}{1 - e(X)}) = X^{\top}\beta$，其中 $\beta$ 是待估计的参数。基于处理分配 $A_i$ 服从伯努利分布且个体间相互独立的假设，我们可以推导出关于 $\beta$ 的似然函数 [@problem_id:4830874]：
$L(\beta) = \prod_{i=1}^{n} [e(X_i)]^{A_i} [1 - e(X_i)]^{1 - A_i} = \prod_{i=1}^{n} \frac{\exp(A_{i} X_{i}^{\top}\beta)}{1 + \exp(X_{i}^{\top}\beta)}$
通过最大化该似然函数，我们可以得到参数 $\hat{\beta}$ 的估计值，进而为每个个体计算其估计的倾向性得分 $\hat{e}(X_i)$。除了逻辑斯蒂回归，也可以使用更灵活的机器学习方法，如[梯度提升](@entry_id:636838)机 (Gradient Boosting Machines) 或随机森林 (Random Forests) 来估计倾向性得分，尤其是在协变量与处理之间存在复杂非线性关系时。

在获得估计的倾向性得分 $\hat{e}(X)$ 后，可以通过多种方式来调整混杂，不同的方法可以用于估计不同的因果目标 (estimands) [@problem_id:4830861]：

*   **逆概率加权 (Inverse Probability of Treatment Weighting, IPTW) for ATE**：
    该方法通过为每个个体分配权重，构建一个“伪人群”，在这个伪人群中，协变量的分布在处理组和[控制组](@entry_id:188599)之间是平衡的，且与原始总人群的协变量分布一致。为了估计 ATE，处理组个体的权重为 $w_i = 1/\hat{e}(X_i)$，[控制组](@entry_id:188599)个体的权重为 $w_i = 1/(1-\hat{e}(X_i))$。ATE 的估计量为两组加权平均结局之差。

*   **匹配 (Matching) for ATT**：
    匹配是最直观的方法之一。为了估计 ATT，其目标是为处理组中的每个个体，在[控制组](@entry_id:188599)中寻找一个或多个具有最相似倾向性得分的个体作为匹配。通过这种方式，我们构建了一个与处理组具有可比协变量分布的“新”[控制组](@entry_id:188599)。然后，比较处理组的结局与这个匹配后的[控制组](@entry_id:188599)的结局，其差值就是对 ATT 的估计。未被匹配上的[控制组](@entry_id:188599)个体则被丢弃。

*   **分层 (Stratification)**：
    该方法将所有个体按照其倾向性得分的取值（例如，按五[分位数](@entry_id:178417)）分为若干个（如 $K=5$ 个）亚组或“层”。在每个层内部，个体的倾向性得分是相似的，因此协变量分布也是近似平衡的。我们在每个层内部分别计算处理效应，最后将各层的效应进行加权平均，得到总体的因果效应估计。如果各层大小相近，简单的算术平均即可近似 ATE。

*   **加权 for ATC**：
    与 IPTW for ATE 和 Matching for ATT 类似，我们也可以通过特定的加权方案来估计 ATC。此时，我们的目标是使处理组的协变量分布与[控制组](@entry_id:188599)相匹配。这可以通过给予[控制组](@entry_id:188599)个体权重 $1$，并给予处理组个体权重 $w_i = (1-\hat{e}(X_i))/\hat{e}(X_i)$ 来实现。

### 倾向性得分模型的[变量选择](@entry_id:177971)：原则与陷阱

构建一个好的倾向性得分模型是整个分析的关键。一个常见的问题是：应该将哪些变量纳入模型中？基于因果图（DAG）的理论，我们可以得出一些清晰的指导原则 [@problem_id:4599512] [@problem_id:4943073]。

1.  **必须纳入的变量：混杂因素 (Confounders)**
    任何同时影响处理选择和结局的变量（即真正的混杂因素）都必须被包含在倾向性得分模型中。在 DAG 中，这些变量位于连接处理和结局的后门路径上（例如，$T \leftarrow C \rightarrow Y$）。忽略这些变量将无法满足条件[可交换性](@entry_id:263314)假设，导致有偏的因果效应估计。

2.  **建议纳入的变量：纯预后变量 (Prognostic Variables)**
    一些变量可能仅与结局 $Y$ 相关，而与处理分配 $T$ 无（或弱）相关。这些被称为纯预后变量。虽然从消除偏倚的角度看，它们不是必须的，但将它们纳入倾向性得分模型通常能提高因果效应估计的**统计精度 (precision)**，即减小估计量的方差。这是因为在调整了这些变量后，结局的残差变异性会减小，从而得到更稳健的估计 [@problem_id:4599512]。

3.  **可以纳入但需谨慎的变量：[工具变量](@entry_id:142324) (Instrumental Variables)**
    工具变量是那些强烈影响处理选择 $T$，但在给定混杂因素后与结局 $Y$ 独立的变量（例如，$Z \rightarrow T$）。将强工具变量纳入模型不会引入偏倚，但可能导致倾向性得分的分布极端化（即许多得分接近 $0$ 或 $1$）。这会使得 IPTW 估计中的权重变得非常大，从而极大地增加估计量的方差，降低[统计效率](@entry_id:164796) [@problem_id:4599512]。

4.  **绝对不能纳入的变量：[对撞机](@entry_id:192770) (Colliders)**
    这是[变量选择](@entry_id:177971)中最危险的陷阱。[对撞机](@entry_id:192770)是一个被两个或多个变量共同影响的变量。考虑一个 M 型结构：$A \leftarrow U_1 \rightarrow C \leftarrow U_2 \rightarrow Y$，其中 $A$ 是处理， $Y$ 是结局，$U_1$ 和 $U_2$ 是未观测变量，$C$ 是一个可观测变量。在这里，$C$ 是 $U_1$ 和 $U_2$ 共同导致的对撞机。在不调整 $C$ 的情况下，从 $A$ 到 $Y$ 的路径 $A \leftarrow U_1 \rightarrow C \leftarrow U_2 \rightarrow Y$ 是被[对撞机](@entry_id:192770) $C$ **阻断**的。然而，一旦我们在倾向性得分模型中**调整（或称“条件化”）了 $C$**，这条路径就会被**打开**，从而在 $A$ 和 $Y$ 之间引入一条新的、非因果的关联。这种由调整[对撞机](@entry_id:192770)引起的偏倚被称为**对撞机偏倚 (collider bias)** 或 M-偏倚。即使 $C$ 是一个处理前变量，这种偏倚依然会发生 [@problem_id:4943073]。类似地，调整受处理影响的治疗后变量（post-treatment variable）也常常会引入[对撞机](@entry_id:192770)偏倚，因为这些变量往往是处理和某些影响结局的未测因素的共同结果（例如，$T \rightarrow K \leftarrow U \rightarrow Y$）[@problem_id:4599512]。

综上所述，倾向性得分方法的应用不仅需要深刻理解其背后的统计学原理和假设，还需要在模型构建的实践中，依据严谨的因果理论，审慎地选择用于调整的变量。