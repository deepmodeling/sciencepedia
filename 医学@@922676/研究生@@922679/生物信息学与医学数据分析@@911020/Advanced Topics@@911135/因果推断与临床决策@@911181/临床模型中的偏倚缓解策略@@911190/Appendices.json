{"hands_on_practices": [{"introduction": "在尝试缓解临床模型中的偏见之前，我们首先必须学会如何量化它。本练习将介绍几种核心的公平性指标，它们是评估和诊断算法偏见的基础。通过分析一个脓毒症预测模型的混淆矩阵，您将亲手计算并解释不同群体间的差异，从而掌握评估模型在不同人群中表现是否公平的关键技能。", "problem": "一家三级医院部署了一个二元临床决策支持模型，该模型基于多模态电子健康记录数据和源自基因型的血统特征来触发败血症的早期干预。敏感属性用 $A \\in \\{0,1\\}$ 表示，代表两个推断出的遗传血统层次。结果为 $Y \\in \\{0,1\\}$，其中 $Y=1$ 表示在48小时内确诊为败血症事件，模型的预测为 $\\hat{Y} \\in \\{0,1\\}$。现给定一个预留测试队列中每个群体的混淆矩阵（计数）：\n- 对于 $A=0$ 组：真阳性 $TP_{0}=180$，假阴性 $FN_{0}=60$，假阳性 $FP_{0}=76$，真阴性 $TN_{0}=684$。$A=0$ 组的总数为 $N_{0}=TP_{0}+FN_{0}+FP_{0}+TN_{0}$。\n- 对于 $A=1$ 组：真阳性 $TP_{1}=195$，假阴性 $FN_{1}=105$，假阳性 $FP_{1}=105$，真阴性 $TN_{1}=595$。$A=1$ 组的总数为 $N_{1}=TP_{1}+FN_{1}+FP_{1}+TN_{1}$。\n\n使用临床机器学习中的标准公平性定义：人口统计均等差异是各组间阳性预测率的绝对差；机会均等差异是各组间真阳性率（灵敏度）的绝对差；均等化赔率差异是各组间真阳性率和假阳性率的绝对差的最大值。\n\n从混淆矩阵计算出的比率的基本定义出发，计算：\n- 人口统计均等差异，\n- 机会均等差异，\n- 均等化赔率差异，\n\n所有结果均以小数形式表示。然后，简要解释它们在 $A=0$ 与 $A=1$ 组之间警报和灵敏度差异方面的临床意义。按上述顺序列出这三个数值。无需四舍五入。将最终答案表示为包含这三个值的单行矩阵。", "solution": "在尝试任何解答之前，首先对问题进行严格的验证程序。\n\n### 问题验证\n\n**步骤1：提取已知条件**\n已知条件逐字从问题陈述中提取：\n- 敏感属性：$A \\in \\{0,1\\}$\n- 结果：$Y \\in \\{0,1\\}$，其中 $Y=1$ 表示确诊的败血症事件。\n- 模型预测：$\\hat{Y} \\in \\{0,1\\}$。\n- 对于 $A=0$ 组：真阳性 $TP_{0}=180$，假阴性 $FN_{0}=60$，假阳性 $FP_{0}=76$，真阴性 $TN_{0}=684$。\n- $A=0$ 组的总数：$N_{0}=TP_{0}+FN_{0}+FP_{0}+TN_{0}$。\n- 对于 $A=1$ 组：真阳性 $TP_{1}=195$，假阴性 $FN_{1}=105$，假阳性 $FP_{1}=105$，真阴性 $TN_{1}=595$。\n- $A=1$ 组的总数：$N_{1}=TP_{1}+FN_{1}+FP_{1}+TN_{1}$。\n- 人口统计均等差异的定义：各组间阳性预测率的绝对差。\n- 机会均等差异的定义：各组间真阳性率（灵敏度）的绝对差。\n- 均等化赔率差异的定义：各组间真阳性率和假阳性率的绝对差的最大值。\n\n**步骤2：使用提取的已知条件进行验证**\n根据所需标准评估问题：\n- **科学依据**：该问题使用了算法公平性领域的标准、明确定义的公平性指标（人口统计均等、机会均等、均等化赔率），并将其应用于一个现实的临床机器学习场景。这些概念基于基础的概率论和统计学。该问题在科学上是合理的。\n- **适定性**：所有必要的数据（每个子组的混淆矩阵计数）和待计算量的明确定义均已提供。该问题是自洽的，并能导出一个唯一的、确定性的解。\n- **客观性**：问题陈述使用了精确、明确的技术语言。它不含主观论断或意见。\n\n问题没有表现出任何列举的缺陷（例如，科学上不合理、不完整、模棱两可）。这是一个在应用统计学中定义明确的计算问题。\n\n**步骤3：结论与行动**\n问题被判定为**有效**。将提供完整的解答。\n\n### 解答\n\n解答需要根据提供的两个组（由敏感属性 $A \\in \\{0,1\\}$ 表示）的混淆矩阵数据，计算三个标准的公平性指标。我们首先计算每个组的总队列大小以及实际阳性和实际阴性的数量。\n\n对于 $A=0$ 组：\n- 总数：$N_{0} = TP_{0} + FN_{0} + FP_{0} + TN_{0} = 180 + 60 + 76 + 684 = 1000$。\n- 实际阳性（患有败血症的个体）：$P_{0} = TP_{0} + FN_{0} = 180 + 60 = 240$。\n- 实际阴性（未患败血症的个体）：$N_{\\text{neg},0} = FP_{0} + TN_{0} = 76 + 684 = 760$。\n\n对于 $A=1$ 组：\n- 总数：$N_{1} = TP_{1} + FN_{1} + FP_{1} + TN_{1} = 195 + 105 + 105 + 595 = 1000$。\n- 实际阳性（患有败血症的个体）：$P_{1} = TP_{1} + FN_{1} = 195 + 105 = 300$。\n- 实际阴性（未患败血症的个体）：$N_{\\text{neg},1} = FP_{1} + TN_{1} = 105 + 595 = 700$。\n\n有了这些汇总计数，我们就可以计算每个组所需的比率。\n\n**1. 人口统计均等差异**\n该指标衡量各组间阳性预测率的差异。组 $a$ 的阳性预测率（$PPR$）是获得阳性预测的概率，即 $P(\\hat{Y}=1|A=a)$。它计算为阳性预测的总数除以该组的总人数。\n$$ PPR_a = \\frac{TP_a + FP_a}{N_a} $$\n对于 $A=0$ 组：\n$$ PPR_{0} = \\frac{TP_{0} + FP_{0}}{N_{0}} = \\frac{180 + 76}{1000} = \\frac{256}{1000} = 0.256 $$\n对于 $A=1$ 组：\n$$ PPR_{1} = \\frac{TP_{1} + FP_{1}}{N_{1}} = \\frac{195 + 105}{1000} = \\frac{300}{1000} = 0.3 $$\n人口统计均等差异（$DPD$）是这些比率之间的绝对差：\n$$ DPD = |PPR_{0} - PPR_{1}| = |0.256 - 0.3| = |-0.044| = 0.044 $$\n\n**2. 机会均等差异**\n该指标要求对于实际为阳性（$Y=1$）的个体，各组获得阳性预测的概率相等。这等同于比较模型对每个组的真阳性率（$TPR$），或称灵敏度。组 $a$ 的 $TPR$ 计算如下：\n$$ TPR_a = P(\\hat{Y}=1|Y=1, A=a) = \\frac{TP_a}{TP_a + FN_a} = \\frac{TP_a}{P_a} $$\n对于 $A=0$ 组：\n$$ TPR_{0} = \\frac{TP_{0}}{P_{0}} = \\frac{180}{240} = \\frac{3}{4} = 0.75 $$\n对于 $A=1$ 组：\n$$ TPR_{1} = \\frac{TP_{1}}{P_{1}} = \\frac{195}{300} = \\frac{65}{100} = 0.65 $$\n机会均等差异（$EOD_{opp}$）是这些比率之间的绝对差：\n$$ EOD_{opp} = |TPR_{0} - TPR_{1}| = |0.75 - 0.65| = 0.1 $$\n\n**3. 均等化赔率差异**\n该指标是比机会均等更严格的条件。它要求各组的真阳性率和假阳性率都相等。组 $a$ 的假阳性率（$FPR$）是对于实际为阴性（$Y=0$）的个体获得阳性预测的概率。\n$$ FPR_a = P(\\hat{Y}=1|Y=0, A=a) = \\frac{FP_a}{FP_a + TN_a} = \\frac{FP_a}{N_{\\text{neg},a}} $$\n对于 $A=0$ 组：\n$$ FPR_{0} = \\frac{FP_{0}}{N_{\\text{neg},0}} = \\frac{76}{760} = 0.1 $$\n对于 $A=1$ 组：\n$$ FPR_{1} = \\frac{FP_{1}}{N_{\\text{neg},1}} = \\frac{105}{700} = \\frac{15}{100} = 0.15 $$\n均等化赔率差异（$EOD_{odds}$）定义为 $TPR$ 和 $FPR$ 的绝对差的最大值：\n$$ EOD_{odds} = \\max(|TPR_{0} - TPR_{1}|, |FPR_{0} - FPR_{1}|) $$\n我们已经计算出 $|TPR_{0} - TPR_{1}| = 0.1$。假阳性率的绝对差为：\n$$ |FPR_{0} - FPR_{1}| = |0.1 - 0.15| = |-0.05| = 0.05 $$\n因此，均等化赔率差异为：\n$$ EOD_{odds} = \\max(0.1, 0.05) = 0.1 $$\n\n**临床解读：**\n- **人口统计均等差异 ($0.044$)**：与 $A=0$ 组（$25.6\\%$）相比，模型对 $A=1$ 组的个体发出警报的频率更高（$30.0\\%$）。这意味着，无论其实际败血症状态如何，$A=1$ 组的个体更有可能收到警报。\n- **机会均等差异 ($0.1$)**：这揭示了一个显著的临床差异。模型对 $A=1$ 组的灵敏度（检测真实败血症病例的能力）为 $65\\%$，显著低于对 $A=0$ 组的 $75\\%$。这意味着，与 $A=0$ 组的败血症患者相比，$A=1$ 组的败血症患者被算法漏诊的几率高出 $10$ 个百分点。这表明该诊断工具未能提供平等的益处，可能导致 $A=1$ 组的预后更差。\n- **均等化赔率差异 ($0.1$)**：这个值是由真阳性率的差异（$0.1$）驱动的，而不是假阳性率的差异（$0.05$）。虽然 $A=1$ 组也经历了更高的假警报率（$15\\%$ vs. $10\\%$），但更关键的差异在于模型对该组的灵敏度降低了。均等化赔率表明，对于两个组中的患病或健康个体，模型的表现都不公平，其中主要且临床意义最显著的失败在于对真实疾病的不公平检测。", "answer": "$$ \\boxed{\\begin{pmatrix} 0.044  0.1  0.1 \\end{pmatrix}} $$", "id": "4542429"}, {"introduction": "量化了偏见之后，下一步便是采取行动进行干预。一种直观的策略是在模型训练开始之前，直接在数据层面进行调整。本练习将指导您实现一种经典的预处理技术——重加权 (reweighing)，通过为不同群体的样本分配特定权重，来消除敏感属性与结果之间的统计关联，从而从源头上减少偏见。", "problem": "给定一个二元分类任务，其中每个实例都有一个敏感属性 $A \\in \\{0,1\\}$、一个二元结果 $Y \\in \\{0,1\\}$ 和一个特征向量 $X \\in \\mathbb{R}^d$。您将实现一个程序，该程序对每个测试用例，从基本原理出发执行以下操作：\n\n1.  仅使用经验频率，为每个单元格 $(A=a, Y=y)$ 确定非负权重 $w_{a,y}$，使得如果为每个具有 $(A,Y)=(a,y)$ 的实例分配权重 $w_{a,y}$，那么 $(A,Y)$ 的重加权经验联合分布将分解为其经验边际分布的乘积。具体而言，分配给任意配对 $(a,y)$ 的重加权计数必须等于 $A=a$ 和 $Y=y$ 的重加权总数之积除以实例总数，这等同于强制重加权后的联合分布等于原始经验边际分布的乘积。为每个具有 $(A_i,Y_i)=(a,y)$ 的实例 $i$ 分配相应的常数权重 $w_{a,y}$。\n\n2.  使用梯度下降法，在带有逻辑斯蒂链接函数的伯努利模型下，对加权负对数似然函数进行最小化，拟合两个带截距项的二元逻辑回归模型，一个有重加权，一个没有。具体来说，对于无权重模型（所有实例权重等于 $1$）和重加权模型（实例权重如步骤 $1$ 中设置），最小化在所有实例上求和的无正则化负对数似然。对除截距外的所有系数添加一个系数为 $\\lambda = 10^{-2}$ 的 $\\ell_2$ 正则化项。使用恒定的学习率 $\\eta = 10^{-1}$，并从全零参数向量开始运行 $T = 2000$ 次迭代。逻辑斯蒂链接函数是将线性得分映射到伯努利参数的规范链接函数。梯度下降更新应使用加权目标函数的精确梯度。确保在计算任何指数或对数项时的数值稳定性。\n\n3.  为进行评估，计算人口统计均等差异 (DPD)，其定义为两个敏感群体之间正向预测率的差异，即对 $A=1$ 预测 $\\hat{Y}=1$ 的概率减去对 $A=0$ 预测 $\\hat{Y}=1$ 的概率，其中预测值 $\\hat{Y}$ 是通过将模型的预测概率在 $0.5$ 处进行阈值处理得到的。在用于训练的同一数据集上，为无权重模型和重加权模型计算此 DPD。报告由重加权引起的 DPD 变化，定义为 $\\Delta = \\mathrm{DPD}_{\\text{reweighted}} - \\mathrm{DPD}_{\\text{unweighted}}$。\n\n请遵循以下规范和假设：\n- 使用带有逻辑斯蒂链接函数的规范伯努利似然。使用带有实例权重的负对数似然来定义损失。使用指定的超参数进行全批量梯度下降。\n- 对除截距外的所有系数应用系数为 $\\lambda = 10^{-2}$ 的 $\\ell_2$ 正则化。不要对截距进行正则化。\n- 对于预测标签，使用 $0.5$ 的阈值。在训练数据本身上计算所有 DPD。\n- 对于重加权，使用从每个测试用例的给定数据集中计算出的经验频率。不假设任何先验分布。\n\n测试套件：\n为以下四个测试用例中的每一个提供变化量 $\\Delta$。每个案例都明确提供了 $X$、 $A$ 和 $Y$。所有数组均以行主序给出，每行对应一个实例。在所有情况下，均使用精确的超参数 $\\lambda = 10^{-2}$、$\\eta = 10^{-1}$ 和 $T = 2000$。\n\n- 测试用例 1（二维特征，$(A,Y)$ 之间中度不平衡）：\n  - $X = \\left[\\begin{array}{cc}\n  2.0  2.0 \\\\\n  1.8  2.2 \\\\\n  0.0  0.2 \\\\\n  0.3  -0.1 \\\\\n  -0.2  0.1 \\\\\n  3.0  3.1 \\\\\n  2.7  2.9 \\\\\n  3.2  2.8 \\\\\n  2.9  3.0 \\\\\n  1.2  1.0 \\\\\n  1.1  1.3 \\\\\n  0.9  1.2\n  \\end{array}\\right]$, $A = \\left[0,0,0,0,0,1,1,1,1,1,1,1\\right]$, $Y = \\left[1,1,0,0,0,1,1,1,1,0,0,0\\right]$。\n- 测试用例 2（一维特征，少数敏感群体带有标签偏斜）：\n  - $X = \\left[\\begin{array}{c}\n  2.1 \\\\ 1.9 \\\\ 2.3 \\\\ 1.8 \\\\ 2.0 \\\\ 2.2 \\\\ 1.7 \\\\ 2.4 \\\\ 2.1 \\\\ 1.9 \\\\ 2.2 \\\\ 2.0 \\\\ -1.1 \\\\ -0.9 \\\\ -1.2 \\\\ -1.0 \\\\\n  1.5 \\\\ -1.3 \\\\ -1.1 \\\\ -1.2\n  \\end{array}\\right]$, $A = \\left[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1\\right]$, $Y = \\left[1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,1,0,0,0\\right]$。\n- 测试用例 3（恒定特征，导致各群体间预测概率相同）：\n  - $X = \\left[\\begin{array}{c}\n  0.0 \\\\ 0.0 \\\\ 0.0 \\\\ 0.0 \\\\ 0.0 \\\\ 0.0\n  \\end{array}\\right]$, $A = \\left[0,0,0,1,1,1\\right]$, $Y = \\left[1,0,1,0,0,1\\right]$。\n- 测试用例 4（二维特征，标签间存在近可分簇且群体平衡）：\n  - $X = \\left[\\begin{array}{cc}\n  4.0  4.0 \\\\\n  5.0  5.0 \\\\\n  -4.0  -4.0 \\\\\n  -5.0  -5.0 \\\\\n  3.5  3.5 \\\\\n  4.0  3.8 \\\\\n  -3.0  -3.0 \\\\\n  -4.0  -3.5\n  \\end{array}\\right]$, $A = \\left[0,0,0,0,1,1,1,1\\right]$, $Y = \\left[1,1,0,0,1,1,0,0\\right]$。\n\n您的程序应生成一行输出，其中包含四个测试用例的人口统计均等差异变化量 $\\Delta$，按顺序排列，作为一个用方括号括起来的逗号分隔列表（例如，$\\left[\\Delta_1,\\Delta_2,\\Delta_3,\\Delta_4\\right]$）。每个 $\\Delta$ 都必须是四舍五入到六位小数的实数。不应打印任何其他文本。所有量都是无单位的，任何比例都必须表示为小数，而不是百分比。", "solution": "该问题要求实现和评估一种偏差缓解技术，特别是针对二元逻辑回归分类器的重加权方法。目标是量化应用此技术后人口统计均等差异（DPD）指标的变化。整个过程可以分解为三个主要步骤：计算实例权重、训练逻辑回归模型和评估公平性指标。\n\n### 步骤 1：实例重加权\n\n重加权的目标是修改训练数据分布，使得敏感属性 $A$ 和结果 $Y$ 在统计上变得独立。目标分布 $P_{\\text{target}}$ 是一个 $(A,Y)$ 的联合概率可以分解为原始经验分布 $P_{\\text{orig}}$ 的边际概率乘积的分布。\n设 $N$ 为实例总数。设 $N_a$ 为敏感属性为 $A=a$ 的实例计数， $N_y$ 为结果为 $Y=y$ 的实例计数， $N_{a,y}$ 为联合事件 $(A=a, Y=y)$ 的实例计数。原始经验概率为：\n$P_{\\text{orig}}(A=a) = \\frac{N_a}{N}$\n$P_{\\text{orig}}(Y=y) = \\frac{N_y}{N}$\n$P_{\\text{orig}}(A=a, Y=y) = \\frac{N_{a,y}}{N}$\n\n反映独立性的目标联合分布是 $P_{\\text{target}}(A=a, Y=y) = P_{\\text{orig}}(A=a) P_{\\text{orig}}(Y=y)$。\n为了使重加权后的数据集符合这个目标分布，我们为每个实例 $i$ 分配一个权重 $w_i$。对于一个属性为 $(A_i, Y_i)=(a,y)$ 的实例，其权重 $w_{a,y}$ 计算为目标概率与该实例所属组的原始概率之比：\n$$\nw_{a,y} = \\frac{P_{\\text{target}}(A=a, Y=y)}{P_{\\text{orig}}(A=a, Y=y)} = \\frac{P_{\\text{orig}}(A=a) P_{\\text{orig}}(Y=y)}{P_{\\text{orig}}(A=a, Y=y)}\n$$\n代入经验频率，我们得到权重的计算公式：\n$$\nw_{a,y} = \\frac{N_a N_y}{N N_{a,y}}\n$$\n然后，每个具有敏感属性 $A_i$ 和结果 $Y_i$ 的实例 $i$ 被分配相应的权重 $w_i = w_{A_i, Y_i}$。对于无权重模型，所有权重都隐式地设为 $w_i=1$。\n\n### 步骤 2：加权逻辑回归与训练\n\n二元逻辑回归模型预测给定特征向量 $X \\in \\mathbb{R}^d$ 时正向结果（$Y=1$）的概率。该模型由一个参数向量 $\\theta = (\\beta_0, \\beta_1, \\dots, \\beta_d)^T$ 定义，其中 $\\beta_0$ 是截距，$\\beta = (\\beta_1, \\dots, \\beta_d)^T$ 是特征系数。对于具有特征 $X$ 的实例，预测概率 $p$ 为：\n$$\np = P(Y=1|X, \\theta) = \\sigma(\\beta_0 + X^T\\beta)\n$$\n其中 $\\sigma(z) = (1+e^{-z})^{-1}$ 是逻辑（sigmoid）函数。\n\n参数 $\\theta$ 通过最小化一个目标函数来学习。对于这个问题，目标是伯努利模型的加权负对数似然，并对特征系数（而非截距）添加了 $\\ell_2$ 正则化项。对于一个包含 $N$ 个实例的数据集，目标函数 $L(\\theta)$ 是：\n$$\nL(\\theta) = -\\sum_{i=1}^N w_i \\left[ y_i \\log p_i + (1-y_i) \\log(1-p_i) \\right] + \\lambda \\sum_{j=1}^d \\beta_j^2\n$$\n这里，$p_i = \\sigma(\\beta_0 + X_i^T\\beta)$ 且 $\\lambda > 0$ 是正则化系数。\n\n我们使用全批量梯度下降来最小化 $L(\\theta)$。更新步骤需要目标函数相对于参数的梯度。偏导数如下：\n对于截距 $\\beta_0$：\n$$\n\\frac{\\partial L}{\\partial \\beta_0} = \\sum_{i=1}^N w_i(p_i - y_i)\n$$\n对于特征系数 $\\beta_j$ ($j \\in \\{1, \\dots, d\\}$)：\n$$\n\\frac{\\partial L}{\\partial \\beta_j} = \\left(\\sum_{i=1}^N w_i(p_i - y_i) X_{ij}\\right) + 2\\lambda\\beta_j\n$$\n参数向量 $\\theta$ 在每次迭代 $t$ 时的梯度下降更新规则是：\n$$\n\\theta^{(t+1)} \\leftarrow \\theta^{(t)} - \\eta \\nabla_\\theta L(\\theta^{(t)})\n$$\n其中 $\\eta$ 是学习率。我们从 $\\theta^{(0)}=\\mathbf{0}$ 开始，用 $\\eta=10^{-1}$ 和 $\\lambda=10^{-2}$ 迭代 $T=2000$ 步。这个过程执行两次：一次是所有 $w_i=1$（无权重模型），一次是使用公平性权重 $w_i = w_{A_i, Y_i}$（重加权模型）。\n\n在实现时，特征矩阵 $X$ 会增加一个前导的全一列，以容纳截距 $\\beta_0$。这使得线性得分可以作为单个矩阵-向量乘积 $X_{\\text{aug}}\\theta$ 来计算。\n\n### 步骤 3：使用人口统计均等差异进行评估\n\n重加权的效果通过测量人口统计均等差异（DPD）的变化来评估。DPD 量化了两个敏感群体（$A=1$ 和 $A=0$）之间正向预测率的差异。\n首先，为每个实例做出预测 $\\hat{Y}$。使用 $0.5$ 的阈值对预测概率进行处理，决策规则为：\n$$\n\\hat{Y} = 1 \\quad \\text{if } p \\ge 0.5 \\quad (\\text{等价于, if } \\beta_0 + X^T\\beta \\ge 0)\n$$\n否则 $\\hat{Y}=0$。\n然后，DPD 计算为每个群体的正向预测经验概率之差：\n$$\n\\mathrm{DPD} = \\frac{\\sum_{i: A_i=1} \\mathbb{I}(\\hat{y}_i = 1)}{N_1} - \\frac{\\sum_{i: A_i=0} \\mathbb{I}(\\hat{y}_i = 1)}{N_0}\n$$\n其中 $\\mathbb{I}(\\cdot)$ 是指示函数。该指标在用于训练的同一数据集上为无权重模型（$\\mathrm{DPD}_{\\text{unweighted}}$）和重加权模型（$\\mathrm{DPD}_{\\text{reweighted}}$）分别计算。最终报告的值是 DPD 的变化：\n$$\n\\Delta = \\mathrm{DPD}_{\\text{reweighted}} - \\mathrm{DPD}_{\\text{unweighted}}\n$$\n负的 $\\Delta$ 表示重加权减少了人口统计均等差异，使模型的行为更接近于 DPD$=0$ 的公平性理想状态。", "answer": "```python\nimport numpy as np\n\ndef _sigmoid(z):\n    \"\"\"Numerically stable sigmoid function.\"\"\"\n    # For z >= 0, use 1 / (1 + exp(-z))\n    # For z < 0, use exp(z) / (1 + exp(z)) to avoid overflow in exp(-z)\n    return np.where(z >= 0, 1 / (1 + np.exp(-z)), np.exp(z) / (1 + np.exp(z)))\n\ndef _train_logistic_regression(X, y, weights, lambda_reg, eta, T):\n    \"\"\"\n    Trains a logistic regression model using full-batch gradient descent.\n    \"\"\"\n    n_samples, n_features = X.shape\n    theta = np.zeros(n_features)\n    y = y.flatten()\n    weights = weights.flatten()\n\n    for _ in range(T):\n        scores = X @ theta\n        probabilities = _sigmoid(scores)\n        \n        error = probabilities - y\n        weighted_error = weights * error\n        \n        gradient = X.T @ weighted_error\n        \n        # Add L2 regularization gradient (not on intercept)\n        reg_gradient = 2 * lambda_reg * theta\n        reg_gradient[0] = 0.0  # Do not regularize the intercept term\n        gradient += reg_gradient\n        \n        theta -= eta * gradient\n        \n    return theta\n\ndef _calculate_dpd(X, A, theta):\n    \"\"\"\n    Calculates the Demographic Parity Difference (DPD).\n    \"\"\"\n    A = A.flatten()\n    \n    # Check for presence of both groups to avoid division by zero\n    if np.sum(A == 1) == 0 or np.sum(A == 0) == 0:\n        return 0.0\n\n    scores = X @ theta\n    predictions = (scores >= 0).astype(int)\n    \n    preds_a1 = predictions[A == 1]\n    preds_a0 = predictions[A == 0]\n    \n    ppr_a1 = np.mean(preds_a1) if len(preds_a1) > 0 else 0.0\n    ppr_a0 = np.mean(preds_a0) if len(preds_a0) > 0 else 0.0\n    \n    return ppr_a1 - ppr_a0\n    \ndef solve():\n    \"\"\"\n    Main function to run the complete pipeline for all test cases.\n    \"\"\"\n    # Hyperparameters from the problem statement\n    LAMBDA_REG = 1e-2\n    ETA = 1e-1\n    T_ITER = 2000\n\n    test_cases = [\n        # Test Case 1\n        (np.array([[2.0, 2.0], [1.8, 2.2], [0.0, 0.2], [0.3, -0.1], [-0.2, 0.1], [3.0, 3.1], [2.7, 2.9], [3.2, 2.8], [2.9, 3.0], [1.2, 1.0], [1.1, 1.3], [0.9, 1.2]]),\n         np.array([0,0,0,0,0,1,1,1,1,1,1,1]),\n         np.array([1,1,0,0,0,1,1,1,1,0,0,0])),\n        # Test Case 2\n        (np.array([[2.1], [1.9], [2.3], [1.8], [2.0], [2.2], [1.7], [2.4], [2.1], [1.9], [2.2], [2.0], [-1.1], [-0.9], [-1.2], [-1.0], [1.5], [-1.3], [-1.1], [-1.2]]),\n         np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1]),\n         np.array([1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,1,0,0,0])),\n        # Test Case 3\n        (np.array([[0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]),\n         np.array([0,0,0,1,1,1]),\n         np.array([1,0,1,0,0,1])),\n        # Test Case 4\n        (np.array([[4.0, 4.0], [5.0, 5.0], [-4.0, -4.0], [-5.0, -5.0], [3.5, 3.5], [4.0, 3.8], [-3.0, -3.0], [-4.0, -3.5]]),\n         np.array([0,0,0,0,1,1,1,1]),\n         np.array([1,1,0,0,1,1,0,0]))\n    ]\n    \n    delta_dpds = []\n\n    for X, A, Y in test_cases:\n        n_samples = X.shape[0]\n        X_aug = np.c_[np.ones(n_samples), X]\n\n        # --- Step 1: Calculate Reweighing Weights ---\n        N = n_samples\n        N_a_counts = {0: np.sum(A == 0), 1: np.sum(A == 1)}\n        N_y_counts = {0: np.sum(Y == 0), 1: np.sum(Y == 1)}\n        \n        N_ay_counts = {}\n        for a_val, y_val in zip(A, Y):\n            N_ay_counts[(a_val, y_val)] = N_ay_counts.get((a_val, y_val), 0) + 1\n\n        weights_map = {}\n        for (a, y), n_ay in N_ay_counts.items():\n            if n_ay > 0:\n                weights_map[(a, y)] = (N_a_counts[a] * N_y_counts[y]) / (N * n_ay)\n\n        reweighing_weights = np.array([weights_map.get((a_val, y_val), 1.0) for a_val, y_val in zip(A, Y)])\n        unweighted_weights = np.ones(n_samples)\n\n        # --- Step 2: Train Models ---\n        # Unweighted model\n        theta_unweighted = _train_logistic_regression(X_aug, Y, unweighted_weights, LAMBDA_REG, ETA, T_ITER)\n        \n        # Reweighted model\n        theta_reweighted = _train_logistic_regression(X_aug, Y, reweighing_weights, LAMBDA_REG, ETA, T_ITER)\n\n        # --- Step 3: Evaluate and Compute Delta ---\n        dpd_unweighted = _calculate_dpd(X_aug, A, theta_unweighted)\n        dpd_reweighted = _calculate_dpd(X_aug, A, theta_reweighted)\n        \n        delta = dpd_reweighted - dpd_unweighted\n        delta_dpds.append(round(delta, 6))\n\n    print(f\"[{','.join(f'{d:.6f}' for d in delta_dpds)}]\")\n\nsolve()\n\n```", "id": "4542367"}, {"introduction": "在某些情况下，我们可能无法重新训练模型或访问其训练数据。此时，后处理技术提供了一种有效的偏见缓解方案。本练习将探讨如何通过为不同群体设定独立的决策阈值，来校准模型的输出，以满足特定的公平性标准（例如，均等的假阳性率），这是一种在不改变模型本身的情况下实现公平性的实用方法。", "problem": "给定一个二元临床分类器，您将获得其按组估计的接受者操作特征（ROC）曲线。每个组都有一个在共同阈值标度上校准过的决策分数，以及一个在有限阈值集合上表示的离散ROC估计。本问题的基本依据是真阳性率（TPR）、假阳性率（FPR）、灵敏度和特异度的标准定义，以及ROC曲线是随着决策阈值 $t$ 变化的参数轨迹 $(\\mathrm{FPR}(t), \\mathrm{TPR}(t))$ 这一事实。具体来说，对于每个具有阳性样本 $y=1$ 和阴性样本 $y=0$ 的组 $g$，灵敏度等于 $\\mathrm{TPR}_g(t) = \\mathbb{P}(\\hat{y}=1 \\mid y=1, g)$，假阳性率等于 $\\mathrm{FPR}_g(t) = \\mathbb{P}(\\hat{y}=1 \\mid y=0, g)$，特异度等于 $1 - \\mathrm{FPR}_g(t)$。对于一组阳性样本数量为 $N^{+}_g$、阴性样本数量为 $N^{-}_g$ 的组，在阈值策略 $\\{t_g\\}_g$ 下，总体灵敏度是加权平均值 $\\sum_g \\mathrm{TPR}_g(t_g) N^{+}_g \\big/ \\sum_g N^{+}_g$，总体特异度是 $\\sum_g \\left(1 - \\mathrm{FPR}_g(t_g)\\right) N^{-}_g \\big/ \\sum_g N^{-}_g$。这些公式在临床评估中经过了充分检验，并构成了基础的出发点。\n\n您的任务是实现一个程序，对每个测试用例，仅使用这些原则和对每组给定的ROC样本进行线性插值，来执行以下步骤。\n\n1) 每组共享FPR目标的阈值设置。给定一个目标假阳性率 $f^{\\star}$，为每个组 $g$ 计算一个阈值 $t^{\\mathrm{fair}}_g$，使得 $\\mathrm{FPR}_g(t^{\\mathrm{fair}}_g) \\approx f^{\\star}$。由于ROC是以在不同阈值下的离散样本形式提供的，您必须假设，作为阈值 $t$ 的函数，$\\mathrm{FPR}_g(t)$ 和 $\\mathrm{TPR}_g(t)$ 在给定的阈值之间都是分段线性的，并且关于 $t$ 的单调方向与其定义一致。使用线性插值来对 $\\mathrm{FPR}_g(t)$ 进行反向计算，以获得满足 $\\mathrm{FPR}_g(t^{\\mathrm{fair}}_g) = f^{\\star}$ 的 $t^{\\mathrm{fair}}_g$（如果可能）。如果 $f^{\\star}$ 超出了 $\\mathrm{FPR}_g$ 采样值所覆盖的范围，则固定到最近的端点阈值，并使用相应的端点率。然后，通过对该组的ROC样本进行线性插值，计算每组的 $\\mathrm{TPR}_g(t^{\\mathrm{fair}}_g)$。基于这些值，使用上述的人口加权公式计算在此每组阈值策略下的总体灵敏度和特异度。\n\n2) 针对相同目标的单一全局阈值。使用相同的 $f^{\\star}$ 和相同的ROC样本，计算一个应用于所有组的单一全局阈值 $t^{\\mathrm{glob}}$，使得按阴性类别的人口加权后的聚合假阳性率等于 $f^{\\star}$，即：\n$$\n\\frac{\\sum_g N^{-}_g \\, \\mathrm{FPR}_g(t^{\\mathrm{glob}})}{\\sum_g N^{-}_g} = f^{\\star}.\n$$\n假设随着 $t$ 的增加，每个组 $g$ 的 $\\mathrm{FPR}_g(t)$ 都是非递增的。在由各组阈值并集构成的共同阈值域上，对 $t$ 使用二分法来找到 $t^{\\mathrm{glob}}$。使用上面给出的人口加权定义，评估在此单一阈值策略下的总体灵敏度和特异度。\n\n3) 报告总体指标的变化。对于每个测试用例，报告以下差值对：\n$$\n\\Delta \\mathrm{Sensitivity} = \\mathrm{Sensitivity}_{\\mathrm{fair}} - \\mathrm{Sensitivity}_{\\mathrm{glob}}, \\quad\n\\Delta \\mathrm{Specificity} = \\mathrm{Specificity}_{\\mathrm{fair}} - \\mathrm{Specificity}_{\\mathrm{glob}}.\n$$\n所有插值必须是线性的，任何外插都必须固定到所提供阈值域的最近端点。请注意，根据构造，两种策略下的聚合假阳性率都等于 $f^{\\star}$，因此 $\\Delta \\mathrm{Specificity}$ 在插值和舍入误差范围内，其数值应非常接近0。\n\n每个测试用例的输入格式在代码中是隐式的，包括每组的阈值数组、相应的 $(\\mathrm{TPR}, \\mathrm{FPR})$ 样本，以及数量 $(N^{+}_g, N^{-}_g)$ 和目标 $f^{\\star}$。您的程序必须嵌入以下测试套件，并按顺序为每个用例生成结果。不应读取任何外部输入。\n\n测试套件：\n- 测试用例 $1$：\n  - 组 $G = \\{A,B\\}$。\n  - A组样本：阈值 $[0.0, 0.2, 0.4, 0.6, 0.8, 1.0]$，$\\mathrm{FPR}_A = [1.0, 0.6, 0.3, 0.12, 0.05, 0.0]$，$\\mathrm{TPR}_A = [1.0, 0.9, 0.8, 0.65, 0.4, 0.0]$，数量 $(N^{+}_A, N^{-}_A) = (800, 1200)$。\n  - B组样本：阈值 $[0.0, 0.2, 0.4, 0.6, 0.8, 1.0]$，$\\mathrm{FPR}_B = [1.0, 0.75, 0.5, 0.35, 0.22, 0.0]$，$\\mathrm{TPR}_B = [1.0, 0.85, 0.7, 0.55, 0.38, 0.0]$，数量 $(N^{+}_B, N^{-}_B) = (200, 800)$。\n  - 目标 $f^{\\star} = 0.1$。\n- 测试用例 $2$：\n  - 与测试用例1中的组和样本相同，数量也相同。\n  - 目标 $f^{\\star} = 0.0$。\n- 测试用例 $3$：\n  - 组 $G = \\{A,B,C\\}$。\n  - A组与测试用例1中相同，数量为 $(N^{+}_A, N^{-}_A) = (500, 500)$。\n  - B组与测试用例1中相同，数量为 $(N^{+}_B, N^{-}_B) = (1000, 3000)$。\n  - C组样本：阈值 $[0.0, 0.2, 0.4, 0.6, 0.8, 1.0]$，$\\mathrm{FPR}_C = [1.0, 0.65, 0.42, 0.25, 0.1, 0.0]$，$\\mathrm{TPR}_C = [1.0, 0.88, 0.74, 0.57, 0.35, 0.0]$，数量 $(N^{+}_C, N^{-}_C) = (200, 800)$。\n  - 目标 $f^{\\star} = 0.25$。\n\n最终输出规范：\n- 对于每个测试用例，输出列表 $[\\Delta \\mathrm{Sensitivity}, \\Delta \\mathrm{Specificity}]$，该列表按照上述说明计算得出，其中两个条目均为实数（浮点数）。\n- 您的程序应生成单行输出，其中包含所有测试用例的结果，格式为用方括号括起来的逗号分隔列表，每个测试用例的结果都包含在各自的方括号内，并按照测试套件的顺序排列。例如，一个有效的格式是 $[[x_1,y_1],[x_2,y_2],[x_3,y_3]]$。", "solution": "该问题被认为是有效的，因为它在科学上基于临床模型评估（ROC分析）的原则，是适定的，提供了所有必要的数据和约束，并且表述客观。任务是比较一个二元分类器在不同人口群体中应用的两种不同阈值策略。\n\n流程如下。首先，我们将实现“公平”阈值策略，该策略使所有组的假阳性率相等。其次，我们将实现“全局”阈值策略，该策略对所有组应用单一决策阈值。最后，我们将计算这两种策略在总体灵敏度和特异度上的差异。此解决方案的一个核心组成部分是分段线性插值，它将用于从目标率确定决策阈值，以及确定在给定阈值下的各种率。\n\n设为组 $g$ 提供的数据是一组阈值 $\\{t_{g,i}\\}_{i=1}^M$ 和相应的率 $\\{(\\mathrm{FPR}_{g,i}, \\mathrm{TPR}_{g,i})\\}_{i=1}^M$。该组的阳性样本数和阴性样本数分别为 $N_g^+$ 和 $N_g^-$。我们假设 $\\mathrm{FPR}_g(t)$ 和 $\\mathrm{TPR}_g(t)$ 都是由给定样本点定义的、关于阈值 $t$ 的分段线性函数。问题陈述指出，随着 $t$ 增加，$\\mathrm{FPR}_g(t)$ 是非递增的。所提供的数据以及相应的 $\\mathrm{TPR}_g(t)$ 值均与此属性一致。\n\n**插值函数**\n要在给定样本 $(x_i, y_i)$ 的情况下找到函数 $y(x)$ 在点 $x'$ 处的值，我们使用线性插值。我们首先确定包含 $x'$ 的区间 $[x_j, x_{j+1}]$。然后，插值由以下公式给出：\n$$ y(x') = y_j + (y_{j+1} - y_j) \\frac{x' - x_j}{x_{j+1} - x_j} $$\n如果 $x'$ 在给定的 $x_i$ 值定义域之外，其值将被固定为最近端点处的值。像 NumPy 这样的数值库自然提供了此功能。\n\n**1. 共享FPR目标的阈值设置（“公平”策略）**\n\n此策略的目标是通过确保每个组 $g$ 都遵循相同的目标假阳性率 $f^{\\star}$ 来强制实现公平性。这就定义了每组的阈值 $t^{\\mathrm{fair}}_g$。\n\n对于每个组 $g$：\n1.  找到阈值 $t^{\\mathrm{fair}}_g$ 使得 $\\mathrm{FPR}_g(t^{\\mathrm{fair}}_g) = f^{\\star}$。这是一个反问题。我们通过对数据点 $(\\mathrm{FPR}_{g,i}, t_{g,i})$ 进行线性插值来解决它。由于所提供的 $\\mathrm{FPR}_g$ 值数组是按降序排列的，而插值函数通常要求自变量是升序的，因此我们将对反转后的数组进行插值。\n2.  一旦找到 $t^{\\mathrm{fair}}_g$，我们计算相应的真阳性率 $\\mathrm{TPR}_g^{\\mathrm{fair}} = \\mathrm{TPR}_g(t^{\\mathrm{fair}}_g)$。这是一个正问题，通过对数据点 $(t_{g,i}, \\mathrm{TPR}_{g,i})$ 进行线性插值来解决。\n3.  根据构造，每组的假阳性率即为 $f^{\\star}$（在插值精度范围内）。\n\n在为所有组计算完这些值后，我们计算总体指标：\n-   总体灵敏度：$\\mathrm{Sensitivity}_{\\mathrm{fair}} = \\frac{\\sum_g N_g^+ \\cdot \\mathrm{TPR}_g^{\\mathrm{fair}}}{\\sum_g N_g^+}$。\n-   总体特异度：由于对所有 $g$ 都有 $\\mathrm{FPR}_g(t^{\\mathrm{fair}}_g) \\approx f^{\\star}$，因此总体特异度为 $\\frac{\\sum_g (1 - f^{\\star}) N_g^-}{\\sum_g N_g^-} = 1 - f^{\\star}$。\n\n**2. 单一全局阈值（“全局”策略）**\n\n该策略对所有组使用单一阈值 $t^{\\mathrm{glob}}$。选择该阈值是为了使人口加权的聚合假阳性率等于目标 $f^{\\star}$。\n\n1.  将聚合假阳性率定义为单一阈值 $t$ 的函数：\n    $$ \\mathrm{FPR}_{\\mathrm{agg}}(t) = \\frac{\\sum_g N_g^- \\cdot \\mathrm{FPR}_g(t)}{\\sum_g N_g^-} $$\n    对于任意给定的 $t$，每个 $\\mathrm{FPR}_g(t)$ 都是通过对样本 $(t_{g,i}, \\mathrm{FPR}_{g,i})$ 进行线性插值计算得出的。\n2.  找到方程 $\\mathrm{FPR}_{\\mathrm{agg}}(t) - f^{\\star} = 0$ 的根 $t^{\\mathrm{glob}}$。由于对于所有 $g$，$\\mathrm{FPR}_g(t)$ 都是 $t$ 的非递增函数，所以 $\\mathrm{FPR}_{\\mathrm{agg}}(t)$ 也是非递增的。这种单调性使得求根问题非常适合使用二分法。我们在共同的阈值域内搜索 $t^{\\mathrm{glob}}$，对于给定的测试用例，该域为 $[0.0, 1.0]$。\n3.  一旦找到 $t^{\\mathrm{glob}}$，我们通过对 $(t_{g,i}, \\mathrm{TPR}_{g,i})$ 样本进行插值，计算每个组相应的真阳性率 $\\mathrm{TPR}_g^{\\mathrm{glob}} = \\mathrm{TPR}_g(t^{\\mathrm{glob}})$。\n\n全局策略的总体指标为：\n-   总体灵敏度：$\\mathrm{Sensitivity}_{\\mathrm{glob}} = \\frac{\\sum_g N_g^+ \\cdot \\mathrm{TPR}_g^{\\mathrm{glob}}}{\\sum_g N_g^+}$。\n-   总体特异度：根据构造，聚合FPR为 $f^{\\star}$。因此，$\\mathrm{Specificity}_{\\mathrm{glob}} = 1 - \\mathrm{FPR}_{\\mathrm{agg}}(t^{\\mathrm{glob}}) \\approx 1 - f^{\\star}$。\n\n**3. 报告总体指标的变化**\n\n最后，我们计算从两种策略获得的指标之间的差异：\n-   $\\Delta \\mathrm{Sensitivity} = \\mathrm{Sensitivity}_{\\mathrm{fair}} - \\mathrm{Sensitivity}_{\\mathrm{glob}}$\n-   $\\Delta \\mathrm{Specificity} = \\mathrm{Specificity}_{\\mathrm{fair}} - \\mathrm{Specificity}_{\\mathrm{glob}}$\n\n由于两种策略都旨在实现 $f^{\\star}$ 的聚合假阳性率，$\\Delta \\mathrm{Specificity}$ 的值预计在数值上接近0，这可作为实现的一致性检查。主要关注的值是 $\\Delta \\mathrm{Sensitivity}$，它量化了在施加公平性约束（均等的FPR）时，模型识别阳性病例的总体有效性的变化。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test suite, comparing two thresholding strategies.\n    \"\"\"\n    \n    test_cases = [\n        {\n            \"groups\": {\n                \"A\": {\n                    \"thresholds\": np.array([0.0, 0.2, 0.4, 0.6, 0.8, 1.0]),\n                    \"fpr\": np.array([1.0, 0.6, 0.3, 0.12, 0.05, 0.0]),\n                    \"tpr\": np.array([1.0, 0.9, 0.8, 0.65, 0.4, 0.0]),\n                    \"counts\": (800, 1200) # (N+, N-)\n                },\n                \"B\": {\n                    \"thresholds\": np.array([0.0, 0.2, 0.4, 0.6, 0.8, 1.0]),\n                    \"fpr\": np.array([1.0, 0.75, 0.5, 0.35, 0.22, 0.0]),\n                    \"tpr\": np.array([1.0, 0.85, 0.7, 0.55, 0.38, 0.0]),\n                    \"counts\": (200, 800)\n                }\n            },\n            \"f_star\": 0.1\n        },\n        {\n            \"groups\": {\n                \"A\": {\n                    \"thresholds\": np.array([0.0, 0.2, 0.4, 0.6, 0.8, 1.0]),\n                    \"fpr\": np.array([1.0, 0.6, 0.3, 0.12, 0.05, 0.0]),\n                    \"tpr\": np.array([1.0, 0.9, 0.8, 0.65, 0.4, 0.0]),\n                    \"counts\": (800, 1200)\n                },\n                \"B\": {\n                    \"thresholds\": np.array([0.0, 0.2, 0.4, 0.6, 0.8, 1.0]),\n                    \"fpr\": np.array([1.0, 0.75, 0.5, 0.35, 0.22, 0.0]),\n                    \"tpr\": np.array([1.0, 0.85, 0.7, 0.55, 0.38, 0.0]),\n                    \"counts\": (200, 800)\n                }\n            },\n            \"f_star\": 0.0\n        },\n        {\n            \"groups\": {\n                \"A\": {\n                    \"thresholds\": np.array([0.0, 0.2, 0.4, 0.6, 0.8, 1.0]),\n                    \"fpr\": np.array([1.0, 0.6, 0.3, 0.12, 0.05, 0.0]),\n                    \"tpr\": np.array([1.0, 0.9, 0.8, 0.65, 0.4, 0.0]),\n                    \"counts\": (500, 500)\n                },\n                \"B\": {\n                    \"thresholds\": np.array([0.0, 0.2, 0.4, 0.6, 0.8, 1.0]),\n                    \"fpr\": np.array([1.0, 0.75, 0.5, 0.35, 0.22, 0.0]),\n                    \"tpr\": np.array([1.0, 0.85, 0.7, 0.55, 0.38, 0.0]),\n                    \"counts\": (1000, 3000)\n                },\n                \"C\": {\n                    \"thresholds\": np.array([0.0, 0.2, 0.4, 0.6, 0.8, 1.0]),\n                    \"fpr\": np.array([1.0, 0.65, 0.42, 0.25, 0.1, 0.0]),\n                    \"tpr\": np.array([1.0, 0.88, 0.74, 0.57, 0.35, 0.0]),\n                    \"counts\": (200, 800)\n                }\n            },\n            \"f_star\": 0.25\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        groups = case[\"groups\"]\n        f_star = case[\"f_star\"]\n        \n        total_pos_pop = sum(g['counts'][0] for g in groups.values())\n        total_neg_pop = sum(g['counts'][1] for g in groups.values())\n\n        # --- 1) \"Fair\" Thresholding Policy ---\n        total_weighted_tpr_fair = 0.0\n        for g_name, g_data in groups.items():\n            # Invert FPR vs Threshold to find threshold for f_star\n            # np.interp requires xp to be increasing, so we reverse the arrays\n            fpr_rev = g_data['fpr'][::-1]\n            thresh_rev = g_data['thresholds'][::-1]\n            t_fair = np.interp(f_star, fpr_rev, thresh_rev)\n            \n            # Interpolate to find TPR at the new threshold\n            # Here, thresholds are the x-axis and are already increasing\n            tpr_at_t_fair = np.interp(t_fair, g_data['thresholds'], g_data['tpr'])\n            \n            total_weighted_tpr_fair += tpr_at_t_fair * g_data['counts'][0]\n\n        sensitivity_fair = total_weighted_tpr_fair / total_pos_pop\n        specificity_fair = 1.0 - f_star\n\n        # --- 2) \"Global\" Thresholding Policy ---\n        def get_aggregate_fpr(t):\n            agg_fpr_num = 0.0\n            for g_data in groups.values():\n                fpr_at_t = np.interp(t, g_data['thresholds'], g_data['fpr'])\n                agg_fpr_num += fpr_at_t * g_data['counts'][1]\n            return agg_fpr_num / total_neg_pop\n        \n        # Bisection to find t_glob\n        t_low, t_high = 0.0, 1.0\n        num_iterations = 100 # High precision\n        for _ in range(num_iterations):\n            t_mid = (t_low + t_high) / 2\n            # FPR is a non-increasing function of threshold\n            if get_aggregate_fpr(t_mid) > f_star:\n                t_low = t_mid # FPR is too high, need higher threshold\n            else:\n                t_high = t_mid # FPR is low enough, can try lower threshold\n        t_glob = (t_low + t_high) / 2\n        \n        total_weighted_tpr_glob = 0.0\n        for g_data in groups.values():\n            tpr_at_t_glob = np.interp(t_glob, g_data['thresholds'], g_data['tpr'])\n            total_weighted_tpr_glob += tpr_at_t_glob * g_data['counts'][0]\n            \n        sensitivity_glob = total_weighted_tpr_glob / total_pos_pop\n        \n        # Calculate actual specificity for accuracy\n        final_agg_fpr = get_aggregate_fpr(t_glob)\n        specificity_glob = 1.0 - final_agg_fpr\n        \n        # --- 3) Report Differences ---\n        delta_sensitivity = sensitivity_fair - sensitivity_glob\n        delta_specificity = specificity_fair - specificity_glob\n        \n        results.append([delta_sensitivity, delta_specificity])\n\n    # Format the final output string exactly as specified\n    formatted_results = [f\"[{res[0]},{res[1]}]\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "4542440"}]}