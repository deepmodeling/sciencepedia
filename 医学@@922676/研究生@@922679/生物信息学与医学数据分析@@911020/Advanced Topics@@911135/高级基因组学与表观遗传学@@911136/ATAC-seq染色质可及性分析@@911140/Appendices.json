{"hands_on_practices": [{"introduction": "任何高通量测序实验都始于一个关键问题：多少数据才足够？本练习聚焦于 ATAC-seq 实验设计与质量控制的这一基本方面。它将引导您区分总测序读数与信息量更丰富的唯一片段，这是衡量文库复杂性和测序深度的核心指标。通过完成这项实践，您将学会如何评估 ATAC-seq 数据集的质量，并理解其对后续峰值检测等分析的深远影响 [@problem_id:4545808]。", "problem": "计划进行一项批量转座酶可及性染色质测序 (ATAC-seq) 实验，目标是获得 $30 \\times 10^{6}$ 个通过标准筛选并能唯一比对到参考基因组的双端测序读段对。经过重复标记后，估计的文库重复率为 $d = 0.20$。在批量 ATAC-seq 中，每个读段对对应一个物理 DNA 片段，而被标记为重复的读段对在下游的信号量化和富集峰识别 (peak calling) 中被认为是不提供信息的。仅使用重复率和片段计数的基本定义，推导一个用于分析的预期唯一片段数量的表达式，并计算其值。然后，从高通量测序中信号累积和检测的基本考虑出发（例如，将片段抽样建模为可及性位点上的一个随机过程，以及需要足够的计数来区分真实的染色质可及性信号与背景噪音），讨论在广泛接受的实践标准下，这一唯一片段深度对于在典型哺乳动物基因组中进行标准的批量 ATAC-seq 富集峰识别是否足够。将计算出的唯一片段数作为最终答案。以精确值的形式表示最终计数，无需四舍五入。", "solution": "该问题要求分两部分作答：首先，根据所提供的测序指标计算唯一片段的数量；其次，评判该数量对于标准分析是否足够。\n\n验证问题陈述是第一个程序步骤。\n\n**步骤 1：提取已知条件**\n- 通过筛选的总双端读段对数量, $N_{total} = 30 \\times 10^{6}$。\n- 估计的文库重复率, $d = 0.20$。\n- 定义：每个读段对对应一个物理 DNA 片段。\n- 定义：被标记为重复的读段对被认为是不提供信息的。\n- 目标 1：推导预期唯一片段数量的表达式并计算其值。\n- 目标 2：讨论该数量对于在典型哺乳动物基因组中进行标准批量 ATAC-seq 富集峰识别的充分性。\n\n**步骤 2：使用提取的已知条件进行验证**\n该问题具有科学依据，因为它使用了生物信息学和基因组学领域的标准术语和现实参数（ATAC-seq、重复率、读段深度）。概念定义明确，问题自成一体且内部一致。它要求进行一个直接的计算，然后基于既定的科学实践进行讨论。该问题提法得当、客观，且不违反任何无效标准。\n\n**步骤 3：结论与行动**\n问题被判定为有效。将提供完整的解决方案。\n\n**第一部分：唯一片段数的推导与计算**\n\n我们从提供的基本定义开始。设 $N_{total}$ 表示通过标准筛选和比对的双端读段对总数。在本问题中，给定 $N_{total} = 30 \\times 10^{6}$。\n\n所有读段对的集合可以划分为两个不相交的子集：唯一的读段对和重复的读段对。设 $N_{unique}$ 为唯一读段对的数量， $N_{dup}$ 为重复读段对的数量。根据定义，总读段数是这两部分之和：\n$$N_{total} = N_{unique} + N_{dup}$$\n\n重复率 $d$ 定义为重复读段对占总读段对的比例。\n$$d = \\frac{N_{dup}}{N_{total}}$$\n给定 $d = 0.20$。\n\n问题陈述指出，被标记为重复的读段对是不提供信息的，在下游分析前会被移除。剩下的读段对是唯一的，并且每个读段对都对应一个被成功测序的、唯一的 DNA 片段。因此，保留用于分析的唯一片段数量等于唯一读段对的数量 $N_{unique}$。\n\n我们的目标是找到 $N_{unique}$ 的表达式。我们可以重排第一个方程，用 $N_{total}$ 和 $N_{dup}$ 来表示 $N_{unique}$：\n$$N_{unique} = N_{total} - N_{dup}$$\n接下来，我们可以使用重复率的定义，用 $N_{total}$ 和 $d$ 来表示 $N_{dup}$：\n$$N_{dup} = d \\times N_{total}$$\n将这个 $N_{dup}$ 的表达式代入 $N_{unique}$ 的方程中，我们得到唯一片段数量的一般表达式：\n$$N_{unique} = N_{total} - (d \\times N_{total})$$\n$$N_{unique} = N_{total} (1 - d)$$\n这就是推导出的保留用于分析的预期唯一片段数量的表达式。\n\n现在，我们使用给定的条件计算其值：$N_{total} = 30 \\times 10^{6}$ 且 $d = 0.20$。\n$$N_{unique} = (30 \\times 10^{6}) \\times (1 - 0.20)$$\n$$N_{unique} = (30 \\times 10^{6}) \\times 0.80$$\n$$N_{unique} = 24 \\times 10^{6}$$\n因此，保留用于分析的预期唯一片段数量为 $2400$ 万。\n\n**第二部分：关于富集峰识别充分性的讨论**\n\n对于 ATAC-seq 富集峰识别而言，一个给定的测序深度的充分性必须基于高通量测序中信号检测的基本原理和广泛接受的行业标准来评估。\n\n基本原理是，要检测一个特征，例如一个开放的染色质区域（一个 \"peak\"），需要对该位点进行足够的片段测序，以便将其信号与背景噪音区分开来。这个过程可以概念化为对片段的随机抽样。唯一片段的总数 $N_{unique}$ 代表了成功抽样的总次数。更高的 $N_{unique}$ 会增加从所有真实可及位点（包括那些固有可及性较低的位点）抽样的概率，并提供将它们声明为显著 peak 的统计功效。\n\n对于一个“典型的哺乳动物基因组”，例如人类或小鼠（约 $3 \\times 10^{9}$ 个碱基对），可及性位点的数量估计在数十万个（例如，$100,000$ 到 $500,000$ 个位点）。这些 $N_{unique}$ 片段非均匀地分布在这些位点和背景区域。深度的充分性决定了富集峰识别的灵敏度和特异性。\n\n计算得出的 $N_{unique} = 24 \\times 10^{6}$ 片段的深度是相当大的数据量。它当然足以识别最突出和高度可及的染色质区域，例如活性启动子和强增强子。使用这个深度的分析不会是失败的；它将产生一个有效的，尽管可能不完整的可及性基因组图谱。\n\n然而，问题提到的是在“广泛接受的实践”下的“标准”批量 ATAC-seq。这意味着要与主要基因组学联盟，如 DNA 元件百科全书（ENCODE）所建立的基准进行比较。ENCODE 联盟已经进行了广泛的经验性分析，以确定对调控景观进行稳健和可重复表征所需的测序深度。\n\n根据 ENCODE 的指导方针，在人类或小鼠样本中进行高质量批量 ATAC-seq 实验的目标是至少获得 $50 \\times 10^{6}$ 个唯一的、非线粒体的、非重复的读段对（即 $N_{unique} \\ge 50 \\times 10^{6}$）。这一建议基于饱和度分析，该分析表明低于此水平的深度可能无法捕获相当一部分真实的可及性位点，特别是较弱的或细胞类型特异性的增强子。一个拥有 $24 \\times 10^{6}$ 个唯一片段的实验尚未达到饱和，这意味着进一步测序将继续识别出大量新的富集峰。\n\n总之，虽然 $24 \\times 10^{6}$ 个唯一片段为初步或探索性分析提供了足够的数据，但这个深度被认为是次优的，不符合当前在哺乳动物系统中进行全面、高质量批量 ATAC-seq 分析的严格标准。与遵循 $\\ge 50 \\times 10^{6}$ 个唯一片段指导方针的实验相比，具有此深度的实验在富集峰发现方面将具有更高的假阴性率。它被认为足以识别强信号，但不足以灵敏地、全基因组范围地发现所有调控元件。", "answer": "$$\\boxed{24 \\times 10^{6}}$$", "id": "4545808"}, {"introduction": "ATAC-seq 实验的主要目标是绘制全基因组范围内的染色质开放区域图谱，即“峰”（peaks）。本编码练习将带您模拟峰值检测（peak calling）这一核心分析过程。您将学习如何应用泊松分布这一统计模型，从背景噪声中辨别出显著的信号富集，并采用多重检验校正来控制假阳性发现率，这是生物信息学分析中的关键步骤 [@problem_id:4545839]。通过亲手实现一个简化的峰值检测器，您将深入理解生物信息学工具如何将原始的读数计数转化为有生物学意义的特征。", "problem": "给定一个基因组区域内来自转座酶可及性染色质测序 (ATAC-seq) 的整数覆盖度计数，以及每个位置对应的局部背景率估计值。假设以下基本前提：在无富集的零假设下，每个位置的覆盖度计数是从一个泊松过程中抽取的独立样本，其速率等于局部背景率，并且独立的泊松变量之和本身也是泊松分布，其速率等于各分量速率之和。为了检验局部富集，我们考虑以步长 $1$ 滑过该区域的固定宽度窗口。对于每个窗口，计算观测到的覆盖度总和以及预期的背景率总和，然后计算在零假设下的单侧尾概率。最后，使用 Benjamini–Hochberg (BH) 程序调整这些 $p$ 值，以控制错误发现率 (False Discovery Rate)。\n\n定义和要求：\n- 令 $c_i$ 表示位置 $i$ 的观测覆盖度，$\\lambda_i$ 表示位置 $i$ 的局部背景率，其中 $i$ 的范围从 $0$ 到 $n-1$。\n- 对于宽度为 $w$ 的窗口，将起始于索引 $s$ 的窗口定义为位置集合 $\\{s, s+1, \\ldots, s+w-1\\}$，其中 $s$ 的范围从 $0$ 到 $n-w$。观测到的窗口总和为 $K_s = \\sum_{i=s}^{s+w-1} c_i$，预期的窗口速率为 $\\Lambda_s = \\sum_{i=s}^{s+w-1} \\lambda_i$。\n- 在零假设下，将 $K_s$ 建模为来自速率为 $\\Lambda_s$ 的泊松随机变量的实现。使用单侧尾概率 $p_s = \\Pr[X \\geq K_s]$，其中 $X$ 是速率为 $\\Lambda_s$ 的泊松变量，不等式在 $X$ 的支撑集上解释。\n- 对所有窗口执行 Benjamini–Hochberg (BH) 多重检验校正，以获得校正后的 $p$ 值。将重叠的窗口视为独立的假设。\n- 将 BH 校正后 $p$ 值小于或等于指定水平 $q$ 的窗口识别为“显著峰”。\n\n您的任务是编写一个完整的、可运行的程序，对每个给定的测试用例，计算显著窗口的索引 $s$ 列表和相应的 BH 校正后的 $p$ 值。报告的 BH 校正后 $p$ 值应四舍五入到六位小数。所有计数都是无单位的，不涉及物理单位。\n\n测试套件：\n- 测试用例 $1$ (正常路径)：\n  - 覆盖度向量 $c$: $[0,1,0,1,2,3,1,0,1,2,6,7,8,6,5,2,1,1,0,1,0,5,6,7,5,1,1,0,0,1]$\n  - 背景向量 $\\lambda$: $[1.0,1.0,1.2,1.0,1.0,1.1,1.0,0.9,1.1,1.2,1.3,1.2,1.1,1.2,1.1,1.0,1.0,1.0,1.0,1.0,1.1,1.2,1.3,1.2,1.1,1.0,1.0,1.0,1.0,1.0]$\n  - 窗口宽度 $w$: $5$\n  - 显著性水平 $q$: $0.05$\n- 测试用例 $2$ (边界情况，窗口宽度为 $1$)：\n  - 覆盖度向量 $c$: $[0,0,1,0,2,3,0,5,0,1,0,4]$\n  - 背景向量 $\\lambda$: $[0.1,0.1,0.2,0.1,0.2,0.3,0.1,0.2,0.1,0.2,0.1,0.2]$\n  - 窗口宽度 $w$: $1$\n  - 显著性水平 $q$: $0.05$\n- 测试用例 $3$ (窗口跨越整个区域)：\n  - 覆盖度向量 $c$: $[1,3,2,1,2,3,1,2,2,1,3,2,2,1,2,3,2,1,1,2]$\n  - 背景向量 $\\lambda$: $[2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0]$\n  - 窗口宽度 $w$: $20$\n  - 显著性水平 $q$: $0.10$\n- 测试用例 $4$ (高背景，无预期峰)：\n  - 覆盖度向量 $c$: $[1,0,2,1,0,1,1,0,2,0,1,1,0,1,0,1,1,0]$\n  - 背景向量 $\\lambda$: $[5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0]$\n  - 窗口宽度 $w$: $4$\n  - 显著性水平 $q$: $0.05$\n\n算法约束：\n- 为所有有效的 $s$ 计算 $K_s$ 和 $\\Lambda_s$。\n- 使用标准的数值例程计算泊松单侧尾概率。\n- 对测试用例中的所有窗口计算 Benjamini–Hochberg 校正后的 $p$ 值，确保当映射回原始顺序时，校正后的值具有单调性。\n- 返回校正后 $p$ 值 $\\leq q$ 的窗口索引以及相应的校正后 $p$ 值（四舍五入到六位小数），按窗口起始索引 $s$ 排序。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。列表中的每个元素对应一个测试用例，其本身是一个包含两个元素的列表：第一个是显著窗口起始索引的列表，第二个是它们经 BH 校正后并四舍五入到六位小数的 $p$ 值列表。例如，输出应类似于 $[[[s\\_1, s\\_2], [p\\_1, p\\_2]], \\ldots]$，所有数字均使用标准十进制表示法。", "solution": "问题陈述已经过严格审查，并被确定为有效。它具有科学依据，定义明确且客观。它提出了一个标准的生物信息学任务——基于已建立的统计学原理，在 ATAC-seq 数据中进行峰值检出（peak calling）。所有数据、定义和约束都已提供，构成一个自洽且可解决的问题。\n\n该问题要求一个计算程序，从 ATAC-seq 覆盖度数据中识别出染色质可及性的统计显著区域。这是通过检验测序读段相对于估计背景率的局部富集来实现的。解决方案的核心涉及三个核心步骤：滑动窗口信号聚合、对每个窗口进行基于泊松分布的统计检验，以及用于控制错误发现率 (FDR) 的多重检验校正。\n\n首先，我们形式化统计基础。问题假定在零假设（$H_0$）下，任何基因组位置 $i$ 观测到的读段计数 $c_i$ 是从泊松分布中抽取的随机变量，其速率参数为 $\\lambda_i$，记为 $c_i \\sim \\text{Poisson}(\\lambda_i)$。参数 $\\lambda_i$ 代表该位置的预期背景计数的速率。泊松分布的一个关键性质是其在加法下的封闭性：独立泊松随机变量之和也是一个泊松随机变量，其速率等于各个速率之和。\n\n其次，我们应用滑动窗口方法来评估连续基因组区域上的富集情况。一个固定整数宽度 $w$ 的窗口以步长 $1$ 滑过长度为 $n$ 的基因组区域。一个从索引 $s$（其中 $s$ 从 $0$ 到 $n-w$）开始的窗口包含位置 $\\{s, s+1, \\ldots, s+w-1\\}$。对于每个这样的窗口，我们计算两个聚合量：\n1. 观测到的总计数，$K_s = \\sum_{i=s}^{s+w-1} c_i$。\n2. 预期的总背景率，$\\Lambda_s = \\sum_{i=s}^{s+w-1} \\lambda_i$。\n\n基于泊松分布的加法性质，对于从 $s$ 开始的窗口，其零假设是观测到的总和 $K_s$ 是一个速率为 $\\Lambda_s$ 的泊松随机变量 $X$ 的实现。即，$H_{0,s}: K_s \\sim \\text{Poisson}(\\Lambda_s)$。\n\n第三，对于 $m = n-w+1$ 个窗口中的每一个，我们进行单侧假设检验。我们感兴趣的是观测到的计数 $K_s$ 是否异常大，这表示存在一个富集峰。统计显著性由一个 $p$ 值 $p_s$ 来量化，定义为在零假设下观测到至少为 $K_s$ 的计数总和的概率。这是尾概率：\n$$p_s = \\Pr[X \\geq K_s] \\quad \\text{其中} \\quad X \\sim \\text{Poisson}(\\Lambda_s)$$\n这个概率是通过对泊松分布的离散支撑集上的概率求和来计算的：\n$$p_s = \\sum_{j=K_s}^{\\infty} \\frac{e^{-\\Lambda_s} \\Lambda_s^j}{j!}$$\n在数值计算上，使用累积分布函数 (CDF) $F(k; \\Lambda_s) = \\Pr[X \\leq k]$ 会更高效，即 $p_s = 1 - F(K_s - 1; \\Lambda_s)$。这等同于在 $K_s - 1$ 处求值的生存函数 (SF)。\n\n最后，由于我们同时进行 $m$ 个假设检验，我们必须进行多重比较校正以避免假阳性率的膨胀。问题指定了一种比控制族别误差率（family-wise error rate）更不保守且通常更强大的方法：控制错误发现率 (FDR)。为此采用了 Benjamini–Hochberg (BH) 程序。该程序如下：\n1. 设计算出的 $m$ 个 $p$ 值为 $p_1, p_2, \\ldots, p_m$。\n2. 将这些 $p$ 值升序排列：$p_{(1)} \\le p_{(2)} \\le \\ldots \\le p_{(m)}$。\n3. 对于每个排好序的 $p$ 值 $p_{(i)}$，其中 $i$ 是其从 $1$ 到 $m$ 的秩，计算其对应的 BH 校正后的 $p$ 值，通常称为 $q$ 值：\n$$q_{(i)} = \\min_{j=i}^{m} \\left\\{ \\min \\left(1, \\frac{m \\cdot p_{(j)}}{j} \\right) \\right\\}$$\n这个公式包含了对单调性的强制执行，确保对于排好序的原始 $p$ 值，其对应的校正后 $q$ 值也是非递减的：$q_{(1)} \\le q_{(2)} \\le \\ldots \\le q_{(m)}$。\n4. 然后将校正后的 $q$ 值映射回其原始的窗口索引。\n5. 如果一个窗口 $s$ 的校正后 $p$ 值 $q_s$ 小于或等于指定的 FDR 控制水平 $q$，则该窗口被宣布包含一个“显著峰”。\n\n待实现的算法将首先计算所有可能的起始位置 $s$ 的窗口化总和 $K_s$ 和速率 $\\Lambda_s$。这可以通过预先计算 $c$ 和 $\\lambda$ 向量的累积和来优化。随后，它将使用标准数值库函数计算每个窗口的原始 $p$ 值（泊松生存函数）。然后将 BH 校正应用于这组 $p$ 值。最后一步是筛选出校正后 $p$ 值满足显著性阈值 $q$ 的窗口，并报告它们的起始索引和校正后的 $p$ 值，按索引排序。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import poisson\n\ndef solve():\n    \"\"\"\n    Main function to process all test cases and print the final result.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (\n            [0,1,0,1,2,3,1,0,1,2,6,7,8,6,5,2,1,1,0,1,0,5,6,7,5,1,1,0,0,1],\n            [1.0,1.0,1.2,1.0,1.0,1.1,1.0,0.9,1.1,1.2,1.3,1.2,1.1,1.2,1.1,1.0,1.0,1.0,1.0,1.0,1.1,1.2,1.3,1.2,1.1,1.0,1.0,1.0,1.0,1.0],\n            5,\n            0.05\n        ),\n        (\n            [0,0,1,0,2,3,0,5,0,1,0,4],\n            [0.1,0.1,0.2,0.1,0.2,0.3,0.1,0.2,0.1,0.2,0.1,0.2],\n            1,\n            0.05\n        ),\n        (\n            [1,3,2,1,2,3,1,2,2,1,3,2,2,1,2,3,2,1,1,2],\n            [2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0],\n            20,\n            0.10\n        ),\n        (\n            [1,0,2,1,0,1,1,0,2,0,1,1,0,1,0,1,1,0],\n            [5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0],\n            4,\n            0.05\n        )\n    ]\n\n    def _calculate_peaks(c_vec, lambda_vec, w, q_level):\n        \"\"\"\n        Calculates significant peaks for a single test case.\n        \"\"\"\n        c = np.array(c_vec, dtype=np.int64)\n        lambda_bg = np.array(lambda_vec, dtype=np.float64)\n        \n        n = len(c)\n        num_windows = n - w + 1\n\n        if num_windows == 0:\n            return [[], []]\n\n        # Efficiently compute sliding window sums using cumulative sums.\n        # This is O(n) instead of O(n*w).\n        c_cumsum = np.concatenate(([0], np.cumsum(c)))\n        lambda_cumsum = np.concatenate(([0], np.cumsum(lambda_bg)))\n        \n        indices = np.arange(num_windows)\n        k_s_array = c_cumsum[indices + w] - c_cumsum[indices]\n        lambda_s_array = lambda_cumsum[indices + w] - lambda_cumsum[indices]\n\n        # Compute one-sided p-values for each window.\n        # p_s = P(X >= K_s) where X ~ Poisson(Lambda_s).\n        # This is equivalent to the survival function P(X > K_s - 1).\n        raw_p_values = poisson.sf(k_s_array - 1, lambda_s_array)\n        \n        # Benjamini-Hochberg FDR correction.\n        m = len(raw_p_values)\n        if m == 0:\n            return [[], []]\n            \n        # Store original order, then sort p-values.\n        original_indices = np.arange(m)\n        p_sorted_indices = np.argsort(raw_p_values)\n        p_sorted = raw_p_values[p_sorted_indices]\n\n        # Calculate ranks (from 1 to m).\n        ranks = np.arange(1, m + 1)\n        \n        # Calculate BH values: (p_sorted * m) / rank.\n        bh_values = (m / ranks) * p_sorted\n        \n        # Enforce monotonicity by taking the cumulative minimum from the end of the sorted list.\n        bh_adjusted_sorted = np.minimum.accumulate(bh_values[::-1])[::-1]\n        \n        # Clip values at 1.0, as adjusted p-values cannot be > 1.\n        bh_adjusted_sorted = np.minimum(bh_adjusted_sorted, 1.0)\n        \n        # Map adjusted p-values back to their original window order.\n        bh_adjusted = np.empty_like(bh_adjusted_sorted)\n        bh_adjusted[p_sorted_indices] = bh_adjusted_sorted\n\n        # Identify significant windows and their adjusted p-values.\n        significant_mask = bh_adjusted = q_level\n        significant_indices = original_indices[significant_mask].tolist()\n        significant_p_values = [round(p, 6) for p in bh_adjusted[significant_mask]]\n        \n        return [significant_indices, significant_p_values]\n\n    results = []\n    for case in test_cases:\n        c, l, w, q = case\n        result = _calculate_peaks(c, l, w, q)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\".replace(\" \", \"\"))\n\nsolve()\n```", "id": "4545839"}, {"introduction": "鉴定出染色质开放区域仅仅是分析的第一步，理解这些区域的调控功能才是最终目标。本练习将向您展示如何整合 ATAC-seq 数据与基因表达数据（如 RNA-seq），从而将潜在的调控元件与其靶基因联系起来。您将应用皮尔逊相关性分析和假设检验等基本统计学原理，来量化基因附近染色质可及性与其转录活性之间的关系 [@problem_id:4545850]。这种整合分析是现代基因组学研究的有力工具，它将帮助您超越简单的峰值列表，开始揭示控制细胞身份与功能的复杂基因调控网络。", "problem": "给定一个包含 $6$ 个样本的匹配的转座酶可及性染色质测序 (ATAC-seq) 和 RNA 测序 (RNA-seq) 数据集。目标是通过计算相关性并在假发现率控制下识别显著的峰–基因连锁，来量化染色质可及性峰与邻近基因表达之间的统计关系。请将您的方法建立在以下基本基础上：\n\n- 分子生物学中心法则：调控性 DNA 元件影响转录起始，而通过 ATAC-seq 测量的开放染色质很可能与通过 RNA-seq 测量的信使核糖核酸 (mRNA) 水平相关。\n- 相关性的统计定义：对于两个长度为 $n$ 的样本向量 $x$ 和 $y$，样本皮尔逊相关系数定义为 $r(x,y) = \\dfrac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n} (x_i - \\bar{x})^2} \\sqrt{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}}$，其中 $\\bar{x}$ 和 $\\bar{y}$ 表示样本均值。\n- 相关性的假设检验：在原假设 $H_0: r = 0$ 下，检验统计量 $t = r \\sqrt{\\dfrac{n - 2}{1 - r^2}}$ 服从自由度为 $n - 2$ 的学生t分布（Student’s $t$ distribution），从而可以计算双边 $p$ 值 $p = 2 \\cdot \\Pr(T \\geq |t|)$。\n- 多重检验校正：对于 $m$ 个具有 $p$ 值 $\\{p_1, \\dots, p_m\\}$ 的独立或正相关假设检验，Benjamini–Hochberg 升阶程序通过找到最大索引 $k$（使得 $p_{(k)} \\leq \\dfrac{k}{m} \\alpha$）来将假发现率控制在水平 $\\alpha$ 以下，其中 $p_{(k)}$ 是第 $k$ 小的 $p$ 值。所有满足 $i \\leq k$ 的 $p_{(i)}$ 均被宣告为显著。\n\n数据被编码为确定性数组和基因组坐标，确保了科学真实性，无需外部文件。如果染色体标签匹配，并且峰中心与基因转录起始位点 (TSS) 之间的绝对距离小于或等于用户指定的最大距离（以碱基对为单位），则一个峰–基因对被视为候选对。\n\n数据集规范：\n- 样本：$6$ 个匹配的生物学样本，索引为 $i = 1, \\dots, 6$。\n- 基因及其染色体和TSS：\n    - $G1$：染色体 $chr1$，$\\text{TSS} = 100000$。\n    - $G2$：染色体 $chr1$，$\\text{TSS} = 150000$。\n    - $G3$：染色体 $chr1$，$\\text{TSS} = 500000$。\n    - $G4$：染色体 $chr2$，$\\text{TSS} = 100000$。\n- ATAC-seq峰及其染色体和中心位置：\n    - $P1$：染色体 $chr1$，位置 $103000$。\n    - $P2$：染色体 $chr1$，位置 $130000$。\n    - $P3$：染色体 $chr1$，位置 $148000$。\n    - $P4$：染色体 $chr1$，位置 $510000$。\n    - $P5$：染色体 $chr2$，位置 $90000$。\n- 跨 $6$ 个样本的 ATAC-seq 可及性向量（任意单位）：\n    - $P1$：$[10, 15, 20, 25, 30, 36]$。\n    - $P2$：$[13, 15, 14, 15, 14, 15]$。\n    - $P3$：$[10, 12, 14, 16, 18, 20]$。\n    - $P4$：$[5, 15, 5, 16, 10, 13]$。\n    - $P5$：$[5, 5, 5, 5, 5, 5]$。\n- 跨 $6$ 个样本的 RNA-seq 表达向量（任意单位）：\n    - $G1$：$[50, 62, 69, 81, 88, 101]$。\n    - $G2$：$[200, 180, 160, 140, 120, 100]$。\n    - $G3$：$[80, 85, 80, 79, 82, 81]$。\n    - $G4$：$[30, 28, 29, 31, 32, 30]$。\n\n约束和定义：\n- 候选峰–基因对必须具有匹配的染色体标签，并且绝对距离小于或等于指定的最大距离（以碱基对为单位）。\n- 对于每个候选对，使用原假设 $H_0: r = 0$ 和自由度为 $n-2$ 的学生t分布计算皮尔逊相关系数及相关的双边 $p$ 值。\n- 如果任一向量的方差为零（例如，$P5$），则将相关性视为未定义，并从假设检验中排除该对。\n- 对有效的 $p$ 值集合应用 Benjamini–Hochberg 程序（水平为 $\\alpha$）以判定显著性。\n- 将每个测试用例的显著峰–基因连锁总数报告为整数。\n\n测试套件：\n您的程序必须评估以下测试用例，每个用例由 $(\\alpha, d_{\\max})$ 描述，其中 $\\alpha$ 是假发现率水平，$d_{\\max}$ 是允许的最大距离（以碱基对为单位）：\n- 用例 1：$(\\alpha = 0.05, d_{\\max} = 10000)$。\n- 用例 2：$(\\alpha = 0.05, d_{\\max} = 2000)$。\n- 用例 3：$(\\alpha = 0.05, d_{\\max} = 20000)$。\n- 用例 4：$(\\alpha = 0.5, d_{\\max} = 20000)$。\n- 用例 5：$(\\alpha = 0.05, d_{\\max} = 500)$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$[result1,result2,result3,result4,result5]$），其中每个 $result$ 是相应测试用例的显著峰–基因连锁的整数计数。输出中不需要物理单位，因为所有量都是无量纲的计数。", "solution": "目标是量化特定基因组位点（ATAC-seq峰）的染色质可及性与附近基因表达（RNA-seq）之间的统计关联。该分析基于分子生物学的中心法则，该法则假定可及的调控区域（如增强子和启动子）会影响基因转录的速率。题目提供了一个数据集，包含 $6$ 个样本的 ATAC-seq 和 RNA-seq 测量值，以及 $4$ 个基因和 $5$ 个峰的基因组坐标。分析过程包括三个主要步骤：基于基因组邻近性识别候选峰–基因对，为每对计算统计关联度量，以及应用多重检验校正来控制假发现率。\n\n**步骤 1：识别候选峰–基因对**\n\n如果满足两个条件，一个峰–基因对就被视为关联分析的候选者：\n1.  峰和基因都位于同一条染色体上。\n2.  峰中心与基因转录起始位点 (TSS) 之间的绝对基因组距离小于或等于指定的最大距离 $d_{\\max}$。距离计算公式为 $|\\text{峰位置} - \\text{基因TSS}|$。\n\n首先，我们枚举所有可能的对，并检查染色体匹配条件。共有 $5$ 个峰和 $4$ 个基因，产生 $20$ 种总组合。\n-   $chr1$ 染色体上的峰：$P1, P2, P3, P4$。$chr1$ 染色体上的基因：$G1, G2, G3$。这在 $chr1$ 上提供了 $4 \\times 3 = 12$ 个潜在对。\n-   $chr2$ 染色体上的峰：$P5$。$chr2$ 染色体上的基因：$G4$。这在 $chr2$ 上提供了 $1 \\times 1 = 1$ 个潜在对。\n所有其他组合都涉及不同的染色体，因此无效。下面计算并列出了 $13$ 个有效对的距离：\n\n| 峰 | 基因 | 峰位置 | 基因TSS | 距离 (bp) |\n| :--- | :--- | :--- | :--- | :--- |\n| $P1$ | $G1$ | $103000$ | $100000$ | $3000$ |\n| $P1$ | $G2$ | $103000$ | $150000$ | $47000$ |\n| $P1$ | $G3$ | $103000$ | $500000$ | $397000$ |\n| $P2$ | $G1$ | $130000$ | $100000$ | $30000$ |\n| $P2$ | $G2$ | $130000$ | $150000$ | $20000$ |\n| $P2$ | $G3$ | $130000$ | $500000$ | $370000$ |\n| $P3$ | $G1$ | $148000$ | $100000$ | $48000$ |\n| $P3$ | $G2$ | $148000$ | $150000$ | $2000$ |\n| $P3$ | $G3$ | $148000$ | $500000$ | $352000$ |\n| $P4$ | $G1$ | $510000$ | $100000$ | $410000$ |\n| $P4$ | $G2$ | $510000$ | $150000$ | $360000$ |\n| $P4$ | $G3$ | $510000$ | $500000$ | $10000$ |\n| $P5$ | $G4$ | $90000$ | $100000$ | $10000$ |\n\n对于具有特定 $d_{\\max}$ 的给定测试用例，我们仅从此表中选择距离 $\\le d_{\\max}$ 的对。\n\n**步骤 2：统计显著性计算**\n\n对于每个候选对，我们分析其 ATAC-seq 可及性向量 ($x$) 和 RNA-seq 表达向量 ($y$) 之间的关联。两个向量的长度均为 $n=6$。\n\n首先，我们必须排除任一向量方差为零的对。峰 $P5$ 的 ATAC-seq 向量为 $[5, 5, 5, 5, 5, 5]$，其方差为 $0$。因此，任何涉及 $P5$ 的候选对（即 ($P5, G4$)）都从假设检验中排除。所有其他提供的向量都具有非零方差。\n\n对于每个剩余的有效候选对，我们计算样本皮尔逊相关系数：\n$$r(x,y) = \\dfrac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n} (x_i - \\bar{x})^2} \\sqrt{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}}$$\n在真实相关为零的原假设 $H_0$ 下，检验统计量 $t$ 计算如下：\n$$t = r \\sqrt{\\dfrac{n - 2}{1 - r^2}}$$\n该统计量服从自由度为 $n - 2 = 6 - 2 = 4$ 的学生t分布（Student's $t$-distribution）。双边 $p$ 值是观察到至少与 $|t|$ 一样极端的检验统计量的概率，由 $p = 2 \\cdot \\Pr(T \\ge |t|)$ 给出，其中 $T$ 是服从 $t(4)$ 分布的随机变量。我们为所有 $12$ 个可能的可检验对计算这些统计数据。\n\n| 对 | 距离 (bp) | 相关性 ($r$) | $t$-统计量 | $p$-值 |\n| :--- | :--- | :--- | :--- | :--- |\n| ($P1$, $G1$) | $3000$ | $0.9936$ | $15.35$ | $0.00018$ |\n| ($P1$, $G2$) | $47000$ | $-0.9634$ | $-6.74$ | $0.00259$ |\n| ($P1$, $G3$) | $397000$ | $-0.0150$ | $-0.03$ | $0.97780$ |\n| ($P2$, $G1$) | $30000$ | $0.2312$ | $0.48$ | $0.66040$ |\n| ($P2$, $G2$) | $20000$ | $-0.3475$ | $-0.74$ | $0.49980$ |\n| ($P2$, $G3$) | $370000$ | $0.8143$ | $2.76$ | $0.05090$ |\n| ($P3$, $G1$) | $48000$ | $0.9856$ | $10.33$ | $0.00049$ |\n| ($P3$, $G2$) | $2000$ | $-1.0000$ | $-\\infty$ | $0.00000$ |\n| ($P3$, $G3$) | $352000$ | $0.1691$ | $0.35$ | $0.74820$ |\n| ($P4$, $G1$) | $410000$ | $-0.0435$ | $-0.09$ | $0.93480$ |\n| ($P4$, $G2$) | $360000$ | $0.1332$ | $0.27$ | $0.80060$ |\n| ($P4$, $G3$) | $10000$ | $0.5000$ | $1.15$ | $0.31250$ |\n\n**步骤 3：控制假发现率 (FDR)**\n\n为了解释多重假设检验，我们应用 Benjamini–Hochberg (BH) 程序。对于一组 $m$ 个 $p$ 值和期望的 FDR 水平 $\\alpha$：\n1.  按非递减顺序对 $p$ 值进行排序：$p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(m)}$。\n2.  找到满足 $p_{(k)} \\le \\frac{k}{m} \\alpha$ 的最大整数 $k$。\n3.  拒绝所有对应于 $p_{(1)}, \\dots, p_{(k)}$ 的检验的原假设。显著连锁的数量为 $k$。如果不存在这样的 $k$，则不拒绝任何假设，计数为 $0$。\n\n**步骤 4：应用于测试用例**\n\n我们现在将这整个工作流程应用于每个测试用例。\n\n**用例 1：$(\\alpha = 0.05, d_{\\max} = 10000)$**\n- 候选对（距离 $\\le 10000$）：($P1, G1$), ($P3, G2$), ($P4, G3$)。候选对 ($P5, G4$) 因方差为零而被排除。\n- 检验数量 $m=3$。\n- $p$-值：$\\{0.00018, 0.00000, 0.31250\\}$。\n- 排序后的 $p$-值：$p_{(1)}=0.00000$, $p_{(2)}=0.00018$, $p_{(3)}=0.31250$。\n- BH 阈值 ($\\frac{k}{3} \\cdot 0.05$)：$k=1$ 时为 $0.0167$，$k=2$ 时为 $0.0333$，$k=3$ 时为 $0.0500$。\n- 检查：\n  - $k=3: p_{(3)} = 0.31250 \\not\\le 0.0500$。\n  - $k=2: p_{(2)} = 0.00018 \\le 0.0333$。此条件成立。\n- 最大的 $k$ 是 $2$。\n- 结果：$2$ 个显著连锁。\n\n**用例 2：$(\\alpha = 0.05, d_{\\max} = 2000)$**\n- 候选对（距离 $\\le 2000$）：($P3, G2$)。\n- 检验数量 $m=1$。\n- $p$-值：$\\{0.00000\\}$。\n- 排序后的 $p$-值：$p_{(1)}=0.00000$。\n- BH 阈值 ($\\frac{1}{1} \\cdot 0.05$)：$k=1$ 时为 $0.0500$。\n- 检查：$p_{(1)} = 0.00000 \\le 0.0500$。此条件成立。\n- 最大的 $k$ 是 $1$。\n- 结果：$1$ 个显著连锁。\n\n**用例 3：$(\\alpha = 0.05, d_{\\max} = 20000)$**\n- 候选对（距离 $\\le 20000$）：($P1, G1$), ($P2, G2$), ($P3, G2$), ($P4, G3$)。\n- 检验数量 $m=4$。\n- $p$-值：$\\{0.00018, 0.49980, 0.00000, 0.31250\\}$。\n- 排序后的 $p$-值：$p_{(1)}=0.00000, p_{(2)}=0.00018, p_{(3)}=0.31250, p_{(4)}=0.49980$。\n- BH 阈值 ($\\frac{k}{4} \\cdot 0.05$)：$0.0125$ ($k=1$), $0.0250$ ($k=2$), $0.0375$ ($k=3$), $0.0500$ ($k=4$)。\n- 检查：\n  - $k=4: p_{(4)} = 0.49980 \\not\\le 0.0500$。\n  - $k=3: p_{(3)} = 0.31250 \\not\\le 0.0375$。\n  - $k=2: p_{(2)} = 0.00018 \\le 0.0250$。此条件成立。\n- 最大的 $k$ 是 $2$。\n- 结果：$2$ 个显著连锁。\n\n**用例 4：$(\\alpha = 0.5, d_{\\max} = 20000)$**\n- 候选对与用例3相同，$m=4$。\n- $p$-值：$\\{0.00018, 0.49980, 0.00000, 0.31250\\}$。\n- 排序后的 $p$-值：$p_{(1)}=0.00000, p_{(2)}=0.00018, p_{(3)}=0.31250, p_{(4)}=0.49980$。\n- BH 阈值 ($\\frac{k}{4} \\cdot 0.5$)：$0.125$ ($k=1$), $0.250$ ($k=2$), $0.375$ ($k=3$), $0.500$ ($k=4$)。\n- 检查：\n  - $k=4: p_{(4)} = 0.49980 \\le 0.500$。此条件成立。\n- 最大的 $k$ 是 $4$。\n- 结果：$4$ 个显著连锁。\n\n**用例 5：$(\\alpha = 0.05, d_{\\max} = 500)$**\n- 候选对（距离 $\\le 500$）：无。\n- 检验数量 $m=0$。\n- 由于没有进行检验，因此没有显著结果。\n- 结果：$0$ 个显著连锁。\n\n五个测试用例的最终计数为 $[2, 1, 2, 4, 0]$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import t\n\ndef solve():\n    \"\"\"\n    Solves the bioinformatics problem of finding significant peak-gene links.\n    The solution involves identifying candidate pairs by distance, calculating\n    correlation and p-values, and applying the Benjamini-Hochberg procedure.\n    \"\"\"\n    \n    # Dataset specification\n    n_samples = 6\n    \n    genes_data = {\n        'G1': {'chr': 'chr1', 'tss': 100000, 'expr': np.array([50, 62, 69, 81, 88, 101])},\n        'G2': {'chr': 'chr1', 'tss': 150000, 'expr': np.array([200, 180, 160, 140, 120, 100])},\n        'G3': {'chr': 'chr1', 'tss': 500000, 'expr': np.array([80, 85, 80, 79, 82, 81])},\n        'G4': {'chr': 'chr2', 'tss': 100000, 'expr': np.array([30, 28, 29, 31, 32, 30])},\n    }\n\n    peaks_data = {\n        'P1': {'chr': 'chr1', 'pos': 103000, 'access': np.array([10, 15, 20, 25, 30, 36])},\n        'P2': {'chr': 'chr1', 'pos': 130000, 'access': np.array([13, 15, 14, 15, 14, 15])},\n        'P3': {'chr': 'chr1', 'pos': 148000, 'access': np.array([10, 12, 14, 16, 18, 20])},\n        'P4': {'chr': 'chr1', 'pos': 510000, 'access': np.array([5, 15, 5, 16, 10, 13])},\n        'P5': {'chr': 'chr2', 'pos': 90000, 'access': np.array([5, 5, 5, 5, 5, 5])},\n    }\n    \n    # Test suite\n    test_cases = [\n        # (alpha, d_max)\n        (0.05, 10000),\n        (0.05, 2000),\n        (0.05, 20000),\n        (0.5, 20000),\n        (0.05, 500),\n    ]\n\n    def calculate_p_value(vec1, vec2, n):\n        \"\"\"Calculates the two-sided p-value for a Pearson correlation.\"\"\"\n        # Check for zero variance\n        if np.var(vec1) == 0 or np.var(vec2) == 0:\n            return None # Indicates an invalid pair for hypothesis testing\n        \n        r = np.corrcoef(vec1, vec2)[0, 1]\n        \n        # Handle perfect correlation edge case\n        if abs(r) == 1.0:\n            return 0.0\n        \n        dof = n - 2\n        t_stat = r * np.sqrt(dof / (1 - r**2))\n        p_val = 2 * t.sf(np.abs(t_stat), df=dof) # sf is survival function (1-cdf)\n        \n        return p_val\n\n    results = []\n    \n    for alpha, d_max in test_cases:\n        candidate_p_values = []\n        \n        # Step 1: Identify candidate pairs and calculate p-values\n        for g_id, g_info in genes_data.items():\n            for p_id, p_info in peaks_data.items():\n                \n                # Condition 1: Matching chromosome\n                if g_info['chr'] != p_info['chr']:\n                    continue\n                \n                # Condition 2: Distance constraint\n                distance = abs(p_info['pos'] - g_info['tss'])\n                if distance > d_max:\n                    continue\n\n                # The pair is a candidate, proceed to statistical test\n                p_val = calculate_p_value(p_info['access'], g_info['expr'], n_samples)\n                \n                # Exclude pairs where correlation is undefined (zero variance)\n                if p_val is not None:\n                    candidate_p_values.append(p_val)\n        \n        # Step 2: Apply Benjamini-Hochberg procedure\n        m = len(candidate_p_values)\n        if m == 0:\n            results.append(0)\n            continue\n            \n        sorted_p_values = sorted(candidate_p_values)\n        \n        k = 0\n        for i in range(m - 1, -1, -1):\n            rank = i + 1\n            p_i = sorted_p_values[i]\n            bh_threshold = (rank / m) * alpha\n            if p_i = bh_threshold:\n                k = rank\n                break\n        \n        results.append(k)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "4545850"}]}