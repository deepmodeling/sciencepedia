{"hands_on_practices": [{"introduction": "联邦学习的强大之处在于其协调分布式计算的能力。为了深入理解其端到端的工作流程，本练习将指导您构建一个联邦学习流程的简化模拟器 ([@problem_id:4563870])。通过编写这个模拟器，您将亲手实现客户端-服务器交互、本地模型更新、安全措施（如梯度裁剪和量化）以及全局模型聚合等核心环节，从而为分析更复杂的联邦学习挑战打下坚实的基础。", "problem": "您的任务是为联邦学习（FL）实现一个最小化的、确定性的编排模拟器，该模拟器模拟了现代编排框架（如 Flower 和 NVIDIA Federated Learning Application Runtime Environment (NVFLARE)）的核心语义，重点关注生物信息学和医疗数据分析中的多机构协作场景。该模拟器必须执行基于轮次的同步协调，其中多个机构（客户端）在特定站点的数据上进行本地训练，并向中央协调器（服务器）提交更新，然后服务器聚合已接受的更新以生成新的全局模型。您的程序必须是完全确定性的，并且必须完全按照规定使用提供的测试套件。\n\n从以下基本基础开始：\n- 经验风险最小化（ERM）和基于梯度的优化：对于拥有一个二次可微、强凸局部目标函数 $f_i(\\mathbf{m})$ 的客户端，其梯度下降步骤为 $\\mathbf{m} \\leftarrow \\mathbf{m} - \\eta \\nabla f_i(\\mathbf{m})$，其中步长 $\\eta > 0$。\n- 局部最小值 $\\mathbf{m}_i^\\star$ 附近的二次近似：对于客户端 $i$，在 $\\mathbf{m}_i^\\star$ 附近，梯度可以建模为 $\\nabla f_i(\\mathbf{m}) \\approx h_i \\left(\\mathbf{m} - \\mathbf{m}_i^\\star\\right)$，其中标量曲率 $h_i > 0$（为简单起见，假设曲率是各向同性的）。\n- 联邦平均（FedAvg）：给定在轮次 $t$ 中一组被接受的客户端 $A^t$，客户端数据量为 $n_i$，全局模型更新计算为客户端增量的数据量加权平均值。\n\n为此问题定义模型维度 $d \\in \\{2\\}$ 和在轮次 $t \\in \\{0,1,\\dots,R\\}$ 的全局模型 $\\mathbf{m}^t \\in \\mathbb{R}^d$。对于每个客户端 $i \\in \\{1,2,\\dots,K\\}$，定义：\n- 本地数据量 $n_i \\in \\mathbb{N}$，\n- 曲率标量 $h_i \\in \\mathbb{R}_{>0}$，\n- 局部最优值 $\\mathbf{m}_i^\\star \\in \\mathbb{R}^d$，\n- 参与指示符 $s_i^t \\in \\{0,1\\}$，\n- 通信延迟 $d_i^t$（秒），以及轮次超时 $\\tau$（秒）。\n\n在轮次 $t$ 中，每个参与的客户端（$s_i^t = 1$）从广播的全局模型 $\\mathbf{m}^t$ 开始，计算一个单一的局部梯度下降步骤：\n$$\n\\Delta_i^t \\equiv \\mathbf{m}_i^{t,\\text{local}} - \\mathbf{m}^t = -\\eta \\nabla f_i(\\mathbf{m}^t) \\approx -\\eta\\, h_i \\left(\\mathbf{m}^t - \\mathbf{m}_i^\\star\\right),\n$$\n然后在将更新发送到服务器之前，应用逐客户端的更新裁剪和量化：\n1. 使用边界 $C > 0$ 的 L2 裁剪：\n$$\n\\widetilde{\\Delta}_i^t = \n\\begin{cases}\n\\Delta_i^t  &\\text{如果 } \\lVert \\Delta_i^t \\rVert_2 \\le C, \\\\\n\\dfrac{C}{\\lVert \\Delta_i^t \\rVert_2}\\, \\Delta_i^t  &\\text{其他情况。}\n\\end{cases}\n$$\n2. 使用 $b \\in \\mathbb{N}$ 比特的均匀逐坐标量化，步长为 $2^{-b}$：\n$$\nQ_b(x) = \\dfrac{\\operatorname{round}\\!\\left(x \\cdot 2^b\\right)}{2^b}, \\quad \\widehat{\\Delta}_i^t = \\left(Q_b\\left(\\widetilde{\\Delta}_{i,1}^t\\right), Q_b\\left(\\widetilde{\\Delta}_{i,2}^t\\right)\\right).\n$$\n服务器当且仅当 $s_i^t = 1$ 且 $d_i^t \\le \\tau$ 时接受更新。将被接受的集合表示为 $A^t = \\left\\{ i \\mid s_i^t = 1 \\text{ and } d_i^t \\le \\tau \\right\\}$。服务器更新规则为：\n$$\n\\mathbf{m}^{t+1} =\n\\begin{cases}\n\\mathbf{m}^{t} + \\displaystyle\\sum_{i \\in A^t} \\left(\\dfrac{n_i}{\\sum_{j \\in A^t} n_j}\\right) \\widehat{\\Delta}_i^t,  &\\text{如果 } \\left|A^t\\right| \\ge 1, \\\\\n\\mathbf{m}^{t},  &\\text{如果 } \\left|A^t\\right| = 0.\n\\end{cases}\n$$\n\n经过 $R$ 轮后，评估全局模型与全局数据量加权目标\n$$\n\\overline{\\mathbf{m}}^\\star = \\dfrac{\\sum_{i=1}^K n_i \\mathbf{m}_i^\\star}{\\sum_{i=1}^K n_i}\n$$\n的接近程度。报告欧几里得距离的平方\n$$\nD = \\left\\lVert \\mathbf{m}^R - \\overline{\\mathbf{m}}^\\star \\right\\rVert_2^2.\n$$\n\n您的程序必须严格实现上述内容，并为以下测试套件生成结果。除非另有说明，所有数字均为实值，延迟和超时以秒为单位，向量为二维。没有随机性；您必须按原样使用指定的值。\n\n测试用例 1（包含超时和量化，无裁剪的通用情况）：\n- $K = 4$, $d = 2$, $R = 3$。\n- $\\eta = 0.2$, $C = 10^9$, $b = 8$, $\\tau = 0.9$。\n- $\\mathbf{m}^0 = [0, 0]$。\n- 数据量 $[n_1,n_2,n_3,n_4] = [50, 30, 10, 10]$。\n- 曲率 $[h_1,h_2,h_3,h_4] = [1.0, 0.5, 1.5, 1.0]$。\n- 最优值 $\\mathbf{m}_1^\\star = [1, -1]$, $\\mathbf{m}_2^\\star = [0.5, -0.5]$, $\\mathbf{m}_3^\\star = [2, -2]$, $\\mathbf{m}_4^\\star = [1, -1]$。\n- 参与矩阵 $s_i^t = 1$ 对所有 $i \\in \\{1,2,3,4\\}$ 和 $t \\in \\{0,1,2\\}$ 成立。\n- 延迟矩阵（行为轮次 $t = 0,1,2$；列为客户端 $i = 1,2,3,4$）：\n  - 轮次 0：$[0.2, 0.5, 1.2, 0.1]$，\n  - 轮次 1：$[0.3, 1.1, 0.2, 0.4]$，\n  - 轮次 2：$[0.8, 0.7, 0.6, 1.5]$。\n\n测试用例 2（边界情况：由于零超时而无更新被接受）：\n- $K = 3$, $d = 2$, $R = 5$。\n- $\\eta = 0.1$, $C = 10^9$, $b = 8$, $\\tau = 0.0$。\n- $\\mathbf{m}^0 = [-1, -1]$。\n- 数据量 $[n_1,n_2,n_3] = [20, 40, 40]$。\n- 曲率 $[h_1,h_2,h_3] = [1.0, 1.0, 1.0]$。\n- 最优值 $\\mathbf{m}_1^\\star = [1, 0]$, $\\mathbf{m}_2^\\star = [0, 1]$, $\\mathbf{m}_3^\\star = [1, 1]$。\n- 参与矩阵 $s_i^t = 1$ 对所有 $i \\in \\{1,2,3\\}$ 和 $t \\in \\{0,1,2,3,4\\}$ 成立。\n- 延迟矩阵：每个条目都等于 $0.1$。\n\n测试用例 3（边缘情况：强裁剪和粗量化）：\n- $K = 3$, $d = 2$, $R = 2$。\n- $\\eta = 0.5$, $C = 0.4$, $b = 2$, $\\tau = 10.0$。\n- $\\mathbf{m}^0 = [0, 0]$。\n- 数据量 $[n_1,n_2,n_3] = [100, 50, 50]$。\n- 曲率 $[h_1,h_2,h_3] = [5.0, 2.0, 1.0]$。\n- 最优值 $\\mathbf{m}_1^\\star = [1, 1]$, $\\mathbf{m}_2^\\star = [-1, -1]$, $\\mathbf{m}_3^\\star = [2, 0]$。\n- 参与矩阵 $s_i^t = 1$ 对所有 $i \\in \\{1,2,3\\}$ 和 $t \\in \\{0,1\\}$ 成立。\n- 延迟矩阵：每个条目都等于 $0.0$。\n\n要求的最终输出格式：\n- 对每个测试用例，计算 $D = \\left\\lVert \\mathbf{m}^R - \\overline{\\mathbf{m}}^\\star \\right\\rVert_2^2$。\n- 您的程序应生成单行输出，其中包含三个结果，形式为用方括号括起来的逗号分隔列表，每个浮点数四舍五入到小数点后六位，例如：$[0.123456,0.000000,1.500000]$。\n\n所有计算必须严格遵循上述定义。不使用角度。时间单位必须视为秒。不使用百分比；任何小数必须表示为十进制数。", "solution": "该问题要求实现一个确定性的模拟器，用于模拟同步、基于轮次的联邦学习（FL）编排协议。该模拟遵循联邦优化的原则，即中央服务器协调多个客户端（例如医疗机构）的训练过程，而无需访问其原始数据。问题的核心是追踪一个全局模型向量 $\\mathbf{m}^t \\in \\mathbb{R}^d$ 在一系列 $R$ 个通信轮次中的演变。\n\n模拟遵循以下操作序列，对每个轮次 $t \\in \\{0, 1, \\dots, R-1\\}$ 执行。\n\n**1. 客户端选择与参与**\n\n在每个轮次 $t$ 中，会选择一部分客户端参与训练。问题指定了一个参与矩阵 $s_i^t$，其中 $s_i^t=1$ 表示客户端 $i$ 被选中参与本轮。服务器向这些参与的客户端广播当前的全局模型 $\\mathbf{m}^t$。在执行本地计算后，每个客户端发回其更新。然而，由于网络延迟，更新可能不会及时到达。一个轮次有严格的超时限制 $\\tau$。只有当客户端 $i$ 的通信延迟 $d_i^t$ 不超过超时 $\\tau$ 时，其更新才会被考虑用于聚合。因此，在轮次 $t$ 中服务器接受其更新的客户端集合，记为 $A^t$，正式定义为：\n$$\nA^t = \\left\\{ i \\mid s_i^t = 1 \\text{ and } d_i^t \\le \\tau \\right\\}\n$$\n\n**2. 本地客户端更新**\n\n每个参与的客户端 $i \\in A^t$ 执行本地计算以生成一个更新。问题将本地训练过程简化为在客户端本地目标函数 $f_i(\\mathbf{m})$ 上执行单步梯度下降。目标函数 $f_i$ 假定为二次可微且强凸的。在其局部最小值 $\\mathbf{m}_i^\\star$ 附近，梯度 $\\nabla f_i(\\mathbf{m})$ 由一个线性函数近似：\n$$\n\\nabla f_i(\\mathbf{m}) \\approx h_i \\left(\\mathbf{m} - \\mathbf{m}_i^\\star\\right)\n$$\n其中 $h_i > 0$ 是一个标量，表示损失表面的（各向同性）曲率。使用此近似，从全局模型 $\\mathbf{m}^t$ 开始的客户端按如下方式计算其本地模型更新 $\\Delta_i^t$：\n$$\n\\Delta_i^t = -\\eta \\nabla f_i(\\mathbf{m}^t) = -\\eta\\, h_i \\left(\\mathbf{m}^t - \\mathbf{m}_i^\\star\\right)\n$$\n这里，$\\eta > 0$ 是学习率或步长。\n\n**3. 更新裁剪与量化**\n\n在传输之前，每个客户端会处理其计算出的更新 $\\Delta_i^t$，以管理通信带宽并提高鲁棒性。\n\n首先，应用 L2 范数裁剪。更新向量的大小被限制在一个阈值 $C > 0$ 以内。这可以防止来自单个客户端的过大更新破坏全局模型的稳定性。裁剪后的更新 $\\widetilde{\\Delta}_i^t$ 为：\n$$\n\\widetilde{\\Delta}_i^t = \n\\begin{cases}\n\\Delta_i^t  &\\text{如果 } \\lVert \\Delta_i^t \\rVert_2 \\le C \\\\\n\\dfrac{C}{\\lVert \\Delta_i^t \\rVert_2}\\, \\Delta_i^t  &\\text{如果 } \\lVert \\Delta_i^t \\rVert_2 > C\n\\end{cases}\n$$\n\n其次，裁剪后的更新被量化以减小其传输大小。一个具有 $b$ 比特的均匀量化方案被应用于向量的每个坐标。量化函数 $Q_b(x)$ 将实数 $x$ 映射到一个离散值：\n$$\nQ_b(x) = \\dfrac{\\operatorname{round}\\!\\left(x \\cdot 2^b\\right)}{2^b}\n$$\n客户端 $i$ 准备传输的最终更新为 $\\widehat{\\Delta}_i^t = \\left(Q_b\\left(\\widetilde{\\Delta}_{i,1}^t\\right), Q_b\\left(\\widetilde{\\Delta}_{i,2}^t\\right), \\dots, Q_b\\left(\\widetilde{\\Delta}_{i,d}^t\\right)\\right)$。\n\n**4. 服务器端聚合**\n\n服务器从接受集合 $A^t$ 中的所有客户端收集处理过的更新 $\\widehat{\\Delta}_i^t$。如果该集合非空（$|A^t| \\ge 1$），服务器将聚合这些更新以形成下一个全局模型 $\\mathbf{m}^{t+1}$。聚合使用联邦平均（FedAvg）算法进行，其中每个客户端的更新按其相对数据量 $n_i$进行加权。接受的客户端的总数据量为 $N_t = \\sum_{j \\in A^t} n_j$。更新规则是：\n$$\n\\mathbf{m}^{t+1} = \\mathbf{m}^{t} + \\sum_{i \\in A^t} \\left(\\dfrac{n_i}{N_t}\\right) \\widehat{\\Delta}_i^t\n$$\n如果接受集合 $A^t$ 为空（$|A^t| = 0$），即没有收到更新或超时过于严格，则全局模型保持不变：\n$$\n\\mathbf{m}^{t+1} = \\mathbf{m}^{t}\n$$\n这个迭代过程从初始模型 $\\mathbf{m}^0$ 开始，重复进行 $R$ 轮。\n\n**5. 最终评估**\n\n经过 $R$ 轮后，评估最终全局模型 $\\mathbf{m}^R$ 的质量。比较的基准是理想的全局最优值 $\\overline{\\mathbf{m}}^\\star$，它是所有客户端局部最优值的数据量加权平均值：\n$$\n\\overline{\\mathbf{m}}^\\star = \\dfrac{\\sum_{i=1}^K n_i \\mathbf{m}_i^\\star}{\\sum_{i=1}^K n_i}\n$$\n性能指标是最终模型与此理想目标之间的欧几里得距离的平方 $D$：\n$$\nD = \\left\\lVert \\mathbf{m}^R - \\overline{\\mathbf{m}}^\\star \\right\\rVert_2^2\n$$\n对每个提供的测试用例执行模拟，并报告得到的 $D$ 值。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements a deterministic Federated Learning orchestration simulator\n    and computes the final model's squared distance to the ideal optimum\n    for a given set of test cases.\n    \"\"\"\n\n    test_cases = [\n        # Test Case 1\n        {\n            \"K\": 4, \"R\": 3, \"eta\": 0.2, \"C\": 1e9, \"b\": 8, \"tau\": 0.9,\n            \"m0\": np.array([0.0, 0.0]),\n            \"n\": np.array([50, 30, 10, 10]),\n            \"h\": np.array([1.0, 0.5, 1.5, 1.0]),\n            \"m_star\": np.array([[1.0, -1.0], [0.5, -0.5], [2.0, -2.0], [1.0, -1.0]]),\n            \"s\": np.ones((3, 4), dtype=int),\n            \"delays\": np.array([[0.2, 0.5, 1.2, 0.1], [0.3, 1.1, 0.2, 0.4], [0.8, 0.7, 0.6, 1.5]])\n        },\n        # Test Case 2\n        {\n            \"K\": 3, \"R\": 5, \"eta\": 0.1, \"C\": 1e9, \"b\": 8, \"tau\": 0.0,\n            \"m0\": np.array([-1.0, -1.0]),\n            \"n\": np.array([20, 40, 40]),\n            \"h\": np.array([1.0, 1.0, 1.0]),\n            \"m_star\": np.array([[1.0, 0.0], [0.0, 1.0], [1.0, 1.0]]),\n            \"s\": np.ones((5, 3), dtype=int),\n            \"delays\": np.full((5, 3), 0.1)\n        },\n        # Test Case 3\n        {\n            \"K\": 3, \"R\": 2, \"eta\": 0.5, \"C\": 0.4, \"b\": 2, \"tau\": 10.0,\n            \"m0\": np.array([0.0, 0.0]),\n            \"n\": np.array([100, 50, 50]),\n            \"h\": np.array([5.0, 2.0, 1.0]),\n            \"m_star\": np.array([[1.0, 1.0], [-1.0, -1.0], [2.0, 0.0]]),\n            \"s\": np.ones((2, 3), dtype=int),\n            \"delays\": np.zeros((2, 3))\n        }\n    ]\n\n    results = []\n\n    for case in test_cases:\n        K, R, eta, C, b, tau = case[\"K\"], case[\"R\"], case[\"eta\"], case[\"C\"], case[\"b\"], case[\"tau\"]\n        m_global = case[\"m0\"].copy()\n        n, h, m_star = case[\"n\"], case[\"h\"], case[\"m_star\"]\n        s, delays = case[\"s\"], case[\"delays\"]\n        \n        quantization_factor = 2**b\n\n        for t in range(R):\n            # 1. Determine accepted clients\n            accepted_indices = [i for i in range(K) if s[t, i] == 1 and delays[t, i] <= tau]\n            \n            if not accepted_indices:\n                # No updates, model does not change\n                continue\n\n            # 2. Server-side preparation\n            accepted_n = n[accepted_indices]\n            total_n_accepted = np.sum(accepted_n)\n            weights = accepted_n / total_n_accepted\n            \n            aggregated_delta = np.zeros_like(m_global)\n\n            for idx, client_idx in enumerate(accepted_indices):\n                # 3. Client-side computation\n                \n                # Calculate local update delta\n                delta = -eta * h[client_idx] * (m_global - m_star[client_idx])\n\n                # L2 clipping\n                norm = np.linalg.norm(delta)\n                if norm > C:\n                    clipped_delta = (C / norm) * delta\n                else:\n                    clipped_delta = delta\n                \n                # Quantization\n                quantized_delta = np.round(clipped_delta * quantization_factor) / quantization_factor\n                \n                # 4. Contribute to aggregation\n                aggregated_delta += weights[idx] * quantized_delta\n            \n            # 5. Update global model\n            m_global += aggregated_delta\n\n        # Final evaluation\n        m_final = m_global\n        \n        # Calculate global data-size-weighted target\n        total_n_global = np.sum(n)\n        m_star_bar = np.sum(n[:, np.newaxis] * m_star, axis=0) / total_n_global\n        \n        # Calculate squared Euclidean distance\n        distance_sq = np.sum((m_final - m_star_bar)**2)\n        results.append(distance_sq)\n\n    # Format output as required\n    output_str = f\"[{','.join([f'{r:.6f}' for r in results])}]\"\n    print(output_str)\n\nsolve()\n```", "id": "4563870"}, {"introduction": "在理想的模拟环境中，我们可以忽略网络延迟和带宽限制，但在实际的多机构协作中，通信效率是决定项目成败的关键因素。本练习 ([@problem_id:4318598]) 将带您直面这一挑战，通过计算同步联邦学习中的通信开销和总训练时间，您将量化“掉队者”（straggler）节点对系统整体性能的巨大影响。这有助于您理解在设计联邦系统时，评估和优化通信瓶颈的必要性。", "problem": "一家医院生物样本库联盟正在使用联邦学习（FL），特别是同步联邦平均（FedAvg），来训练一个疾病风险预测模型，以遵循其主管机构审查委员会（IRB）强制要求的数据最小化和非传输政策。共有$N=20$个生物样本库站点。在每个联邦轮次中，协调服务器向所有站点广播当前的模型参数，每个站点执行本地训练，然后每个站点向服务器上传一组压缩后的更新模型参数。治理要求每轮都包含所有站点，以保持代表性和公平性。\n\n假设存在以下具有科学依据且符合现实的条件：\n- 未压缩的模型大小为$M=50$兆字节。使用十进制兆字节，其中$1\\,\\mathrm{MB}=10^{6}$字节。\n- 应用于下行和上行有效载荷的无损压缩方案产生的压缩比为$r=0.2$，因此每个站点每个方向的传输有效载荷为$rM$。\n- 网络传输使用点对点链接；向$N$个站点广播模型会导致$N$次大小为$rM$的单独传输（无多播聚合）。\n- 在每一轮中，所有站点必须在轮次完成前完成下行、本地计算和上行阶段（同步屏障）。\n- 十九个站点的下行带宽为$100\\,\\mathrm{Mb/s}$，上行带宽为$100\\,\\mathrm{Mb/s}$，单向延迟分别为$0.05\\,\\mathrm{s}$（下行）和$0.10\\,\\mathrm{s}$（上行）。一个掉队站点的下行带宽为$20\\,\\mathrm{Mb/s}$，上行带宽为$20\\,\\mathrm{Mb/s}$，延迟相同。使用十进制兆比特，其中$1\\,\\mathrm{Mb}=10^{6}$比特。\n- 每个站点每轮的本地训练时间为$30\\,\\mathrm{s}$，假设所有站点相同且与网络条件无关。\n- 忽略服务器端聚合时间以及超出所述有效载荷大小和延迟的加密协议开销。\n\n从同步联邦学习轮次执行的核心定义以及数据大小、带宽和延迟之间的关系出发，完成以下任务：\n1. 计算每轮的通信开销，即所有链接（双向合并）上以兆字节为单位传输的总数据量。\n2. 估算在$T$轮内的总挂钟训练时间（以小时为单位），表示为$T$的函数，并使用同步屏障假设，即轮次持续时间由下行链路最慢的站点和上行链路最慢的站点决定。\n\n将您的答案四舍五入到四位有效数字。对于第1部分，以兆字节表示数据量。对于第2部分，以小时表示总时间。", "solution": "**问题验证**\n\n根据有效性所需标准对提供的问题陈述进行分析。\n\n**第一步：提取已知条件**\n- 站点数量：$N=20$\n- 联邦学习模型：同步联邦平均 (FedAvg)\n- 治理要求：每轮包含所有站点\n- 未压缩的模型大小：$M=50$ 兆字节（$1\\,\\mathrm{MB}=10^6$ 字节）\n- 压缩比：$r=0.2$\n- 网络传输：点对点链接\n- 轮次完成条件：下行、本地计算和上行阶段的同步屏障\n- 正常站点数量：$19$\n- 正常站点带宽：$B_{down,normal} = B_{up,normal} = 100\\,\\mathrm{Mb/s}$（$1\\,\\mathrm{Mb}=10^6$ 比特）\n- 正常站点单向延迟：$L_{down,normal} = 0.05\\,\\mathrm{s}$，$L_{up,normal} = 0.10\\,\\mathrm{s}$\n- 掉队站点数量：$1$\n- 掉队站点带宽：$B_{down,straggler} = B_{up,straggler} = 20\\,\\mathrm{Mb/s}$\n- 掉队站点单向延迟：$L_{down,straggler} = 0.05\\,\\mathrm{s}$，$L_{up,straggler} = 0.10\\,\\mathrm{s}$\n- 每个站点每轮的本地训练时间：$T_{local}=30\\,\\mathrm{s}$\n- 总轮次数：$T$\n- 忽略的因素：服务器端聚合时间，加密协议开销\n\n**第二步：使用提取的已知条件进行验证**\n问题评估如下：\n- **有科学依据**：该问题建立在分布式机器学习（联邦学习）和计算机网络的既定原则之上。同步轮次、由掉队节点引起的通信瓶颈以及使用带宽和延迟对数据传输时间进行建模等概念是标准的、科学合理的。所提供的数值对于多机构研究环境是现实的。\n- **适定性**：该问题明确规定了所有必要的参数和约束，可以为所要求的两个量得出唯一且有意义的解。\n- **客观性**：该问题以精确、定量和无偏见的技术语言陈述，不含主观或推测性主张。\n- **完整性和一致性**：该问题是自洽的，没有矛盾。正常站点（19个）和掉队站点（1个）的数量正确地加总为站点总数（N=20）。\n\n**第三步：结论与行动**\n该问题被认为是有效的。下面提供完整的解决方案。\n\n---\n\n**第1部分：每轮通信开销**\n\n每轮的总通信开销 $V_{total}$ 是从服务器到所有站点（下行）传输的总数据量与从所有站点到服务器（上行）传输的总数据量之和。\n\n首先，我们确定在每个链接上传输的压缩后模型有效载荷的大小 $S$。\n$$S = rM$$\n给定未压缩模型大小 $M=50\\,\\mathrm{MB}$ 和压缩比 $r=0.2$：\n$$S = 0.2 \\times 50\\,\\mathrm{MB} = 10\\,\\mathrm{MB}$$\n在下行阶段，服务器将此有效载荷发送到每个 $N=20$ 的站点。由于链接是点对点的，总下行数据量 $V_{down}$ 为：\n$$V_{down} = N \\times S = 20 \\times 10\\,\\mathrm{MB} = 200\\,\\mathrm{MB}$$\n在上行阶段，每个 $N=20$ 的站点将其更新后的（并压缩的）模型参数发送回服务器。因此，总上行数据量 $V_{up}$ 是相同的：\n$$V_{up} = N \\times S = 20 \\times 10\\,\\mathrm{MB} = 200\\,\\mathrm{MB}$$\n每轮总通信开销是下行和上行数据量之和：\n$$V_{total} = V_{down} + V_{up} = 200\\,\\mathrm{MB} + 200\\,\\mathrm{MB} = 400\\,\\mathrm{MB}$$\n问题要求答案保留四位有效数字。因此，总开销为 $400.0\\,\\mathrm{MB}$。\n\n**第2部分：T轮的总挂钟训练时间**\n\n$T$ 轮的总训练时间 $T_{total}$ 是轮次数与单轮持续时间 $T_{round}$ 的乘积。\n$$T_{total}(T) = T \\times T_{round}$$\n单个同步轮次的持续时间是其顺序阶段（下行、本地计算和上行）持续时间的总和。由于同步屏障的存在，每个通信阶段的持续时间由最慢的（掉队）站点决定。\n\n首先，我们将有效载荷大小 $S$ 从兆字节转换为兆比特，以便与带宽单位（$1\\,\\mathrm{Mb/s} = 10^6\\,\\mathrm{bits/s}$）保持一致。使用换算关系 $1\\,\\mathrm{byte} = 8\\,\\mathrm{bits}$：\n$$S = 10\\,\\mathrm{MB} = 10 \\times 10^6\\,\\mathrm{bytes} = 10 \\times 10^6 \\times 8\\,\\mathrm{bits} = 80 \\times 10^6\\,\\mathrm{bits} = 80\\,\\mathrm{Mb}$$\n单次数据传输的时间建模为单向延迟（$L$）和序列化时间（$S/B$，其中 $B$ 是带宽）之和。\n\n**下行阶段持续时间 ($T_{down\\_phase}$)**\n这是直到最后一个站点接收到模型更新的时间。我们必须比较正常站点和掉队站点的总下行时间。\n- 对于正常站点：\n$$T_{down,normal} = L_{down,normal} + \\frac{S}{B_{down,normal}} = 0.05\\,\\mathrm{s} + \\frac{80\\,\\mathrm{Mb}}{100\\,\\mathrm{Mb/s}} = 0.05\\,\\mathrm{s} + 0.8\\,\\mathrm{s} = 0.85\\,\\mathrm{s}$$\n- 对于掉队站点：\n$$T_{down,straggler} = L_{down,straggler} + \\frac{S}{B_{down,straggler}} = 0.05\\,\\mathrm{s} + \\frac{80\\,\\mathrm{Mb}}{20\\,\\mathrm{Mb/s}} = 0.05\\,\\mathrm{s} + 4.0\\,\\mathrm{s} = 4.05\\,\\mathrm{s}$$\n该阶段的持续时间是这些时间中的最大值：\n$$T_{down\\_phase} = \\max(T_{down,normal}, T_{down,straggler}) = 4.05\\,\\mathrm{s}$$\n\n**本地计算阶段持续时间 ($T_{local}$)**\n给定所有站点此时间相同：\n$$T_{local} = 30\\,\\mathrm{s}$$\n\n**上行阶段持续时间 ($T_{up\\_phase}$)**\n这是服务器接收到来自最后一个站点的更新所需的时间。\n- 对于正常站点：\n$$T_{up,normal} = L_{up,normal} + \\frac{S}{B_{up,normal}} = 0.10\\,\\mathrm{s} + \\frac{80\\,\\mathrm{Mb}}{100\\,\\mathrm{Mb/s}} = 0.10\\,\\mathrm{s} + 0.8\\,\\mathrm{s} = 0.90\\,\\mathrm{s}$$\n- 对于掉队站点：\n$$T_{up,straggler} = L_{up,straggler} + \\frac{S}{B_{up,straggler}} = 0.10\\,\\mathrm{s} + \\frac{80\\,\\mathrm{Mb}}{20\\,\\mathrm{Mb/s}} = 0.10\\,\\mathrm{s} + 4.0\\,\\mathrm{s} = 4.10\\,\\mathrm{s}$$\n该阶段的持续时间是这些时间中的最大值：\n$$T_{up\\_phase} = \\max(T_{up,normal}, T_{up,straggler}) = 4.10\\,\\mathrm{s}$$\n\n**总轮次持续时间 ($T_{round}$)**\n一个同步轮次的总时间是三个顺序阶段持续时间的总和：\n$$T_{round} = T_{down\\_phase} + T_{local} + T_{up\\_phase} = 4.05\\,\\mathrm{s} + 30\\,\\mathrm{s} + 4.10\\,\\mathrm{s} = 38.15\\,\\mathrm{s}$$\n\n**T轮的总训练时间**\n$T$ 轮的总时间以小时表示。一小时有 $3600\\,\\mathrm{s}$。\n$$T_{total}(T) = T \\times T_{round} = T \\times 38.15\\,\\mathrm{s} \\times \\frac{1\\,\\mathrm{hour}}{3600\\,\\mathrm{s}} = T \\times \\frac{38.15}{3600}\\,\\mathrm{hours}$$\n$$T_{total}(T) \\approx T \\times 0.01059722...\\,\\mathrm{hours}$$\n将系数四舍五入到四位有效数字，得到 $0.01060$。\n$$T_{total}(T) \\approx 0.01060\\,T\\,\\mathrm{hours}$$", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n400.0  & 0.01060T\n\\end{pmatrix}\n}\n$$", "id": "4318598"}, {"introduction": "联邦学习的一个核心挑战是处理各参与方之间固有的数据异质性（Non-IID）。当天真的聚合策略遇上分布各异的本地数据时，全局模型的收敛性和最终性能可能会受到严重影响。本练习 ([@problem_id:4563886]) 引导您从数学上解决这一问题，通过推导一个最优的梯度聚合权重，来最小化聚合梯度与理想中心化梯度之间的偏差。这个过程将加深您对统计异质性如何影响联邦优化以及如何通过调整聚合策略来缓解该问题的理解。", "problem": "考虑两家医院，$A$ 和 $B$，它们通过联邦平均（Federated Averaging, FedAvg）进行协作，使用电子健康记录（EHR）来训练一个用于二元疾病预测任务的逻辑回归模型。由于患者人口统计特征和共病情况的不同，数据在各医院间是非独立同分布的（Non-IID），这导致了局部梯度的统计异质性。\n\n在某一训练轮次中，服务器聚合来自这两家医院的针对单个模型参数的一维随机梯度，其中医院 $A$ 的权重为 $w$，医院 $B$ 的权重为 $1-w$。设此轮的局部随机梯度模型为 $g_A = \\mu_A + \\epsilon_A$ 和 $g_B = \\mu_B + \\epsilon_B$，其中 $\\epsilon_A$ 和 $\\epsilon_B$ 是代表随机梯度噪声的零均值随机变量，在医院间相互独立，其方差分别为 $\\mathrm{Var}(\\epsilon_A) = \\sigma_A^2$ 和 $\\mathrm{Var}(\\epsilon_B) = \\sigma_B^2$。此轮局部梯度的期望值分别为 $\\mu_A$ 和 $\\mu_B$。如果所有数据汇集在一起，所获得的中心化梯度是按数据比例加权的平均值 $T = p_A \\mu_A + p_B \\mu_B$，其中 $p_A$ 和 $p_B$ 分别是医院 $A$ 和 $B$ 所持有的总样本量的比例，且满足 $p_A + p_B = 1$。\n\n服务器旨在选择 $w$，以最小化此轮中聚合的联邦梯度与中心化梯度之间的期望平方偏差，即最小化\n$$\n\\mathbb{E}\\left[\\left(w g_A + (1-w) g_B - T\\right)^{2}\\right].\n$$\n\n假设 $\\epsilon_A$ 和 $\\epsilon_B$ 相互独立，局部随机梯度是无偏的，并且 $w$ 是满足 $w + (1-w) = 1$ 的实数。使用在当前轮次从局部梯度统计数据中获得的以下科学上合理的数值：\n- $\\mu_A = 0.14$, $\\mu_B = -0.02$,\n- $\\sigma_A^2 = 0.0025$, $\\sigma_B^2 = 0.0064$,\n- $p_A = 0.65$, $p_B = 0.35$.\n\n从上述定义和假设出发，推导期望平方偏差的表达式，并找出使其最小化的 $w$ 值。将最终答案表示为单个实数。将答案四舍五入到四位有效数字。", "solution": "该问题是适定的，其科学基础是联邦学习和优化原理，并且包含了获得唯一解所需的所有信息。在训练机器学习模型的背景下，所提供的数值是合理的。因此，我将开始推导。\n\n目标是找到权重因子 $w$，该因子能最小化聚合的联邦梯度与中心化梯度之间的期望平方偏差。目标函数由下式给出：\n$$\nL(w) = \\mathbb{E}\\left[\\left(w g_A + (1-w) g_B - T\\right)^{2}\\right]\n$$\n其中 $g_A$ 和 $g_B$ 是随机梯度，$T$ 是恒定的中心化梯度目标。\n\n我们可以使用偏差-方差分解来分解期望平方误差。对于任意随机变量 $X$ 和常数 $c$，我们有 $\\mathbb{E}[(X-c)^2] = \\mathrm{Var}(X) + (\\mathbb{E}[X]-c)^2$。令 $X = w g_A + (1-w) g_B$ 且 $c = T$。目标函数变为：\n$$\nL(w) = \\mathrm{Var}\\left(w g_A + (1-w) g_B\\right) + \\left(\\mathbb{E}\\left[w g_A + (1-w) g_B\\right] - T\\right)^2\n$$\n我们将分别分析方差项和偏差项。\n\n首先，我们计算方差项。局部随机梯度由 $g_A = \\mu_A + \\epsilon_A$ 和 $g_B = \\mu_B + \\epsilon_B$ 给出。由于 $\\mu_A$ 和 $\\mu_B$ 是常数，局部梯度的方差为：\n$$\n\\mathrm{Var}(g_A) = \\mathrm{Var}(\\mu_A + \\epsilon_A) = \\mathrm{Var}(\\epsilon_A) = \\sigma_A^2\n$$\n$$\n\\mathrm{Var}(g_B) = \\mathrm{Var}(\\mu_B + \\epsilon_B) = \\mathrm{Var}(\\epsilon_B) = \\sigma_B^2\n$$\n问题陈述了随机噪声项 $\\epsilon_A$ 和 $\\epsilon_B$ 是独立的，这意味着随机梯度 $g_A$ 和 $g_B$ 也是独立的。对于独立的随机变量，其加权和的方差为：\n$$\n\\mathrm{Var}\\left(w g_A + (1-w) g_B\\right) = w^2 \\mathrm{Var}(g_A) + (1-w)^2 \\mathrm{Var}(g_B) = w^2 \\sigma_A^2 + (1-w)^2 \\sigma_B^2\n$$\n\n接下来，我们计算偏差的平方项，即 $(\\mathbb{E}[w g_A + (1-w) g_B] - T)^2$。我们首先求出聚合梯度的期望。利用期望的线性性质以及 $\\mathbb{E}[\\epsilon_A] = 0$ 和 $\\mathbb{E}[\\epsilon_B] = 0$：\n$$\n\\mathbb{E}[g_A] = \\mathbb{E}[\\mu_A + \\epsilon_A] = \\mu_A\n$$\n$$\n\\mathbb{E}[g_B] = \\mathbb{E}[\\mu_B + \\epsilon_B] = \\mu_B\n$$\n聚合梯度的期望为：\n$$\n\\mathbb{E}[w g_A + (1-w) g_B] = w \\mathbb{E}[g_A] + (1-w) \\mathbb{E}[g_B] = w \\mu_A + (1-w) \\mu_B\n$$\n中心化梯度为 $T = p_A \\mu_A + p_B \\mu_B$。由于 $p_A + p_B = 1$，我们有 $p_B = 1 - p_A$。与目标的偏差为：\n$$\n\\mathbb{E}[w g_A + (1-w) g_B] - T = (w \\mu_A + (1-w) \\mu_B) - (p_A \\mu_A + (1-p_A) \\mu_B)\n$$\n$$\n= (w - p_A)\\mu_A + ((1-w) - (1-p_A))\\mu_B = (w - p_A)\\mu_A - (w - p_A)\\mu_B = (w - p_A)(\\mu_A - \\mu_B)\n$$\n因此，偏差的平方项为：\n$$\n\\left((w-p_A)(\\mu_A - \\mu_B)\\right)^2 = (w-p_A)^2 (\\mu_A - \\mu_B)^2\n$$\n\n结合方差项和偏差的平方项，我们得到完整的目标函数 $L(w)$：\n$$\nL(w) = w^2 \\sigma_A^2 + (1-w)^2 \\sigma_B^2 + (w-p_A)^2 (\\mu_A - \\mu_B)^2\n$$\n为了找到使 $L(w)$ 最小化的 $w$ 值，我们对 $w$ 求导并令其为 $0$。\n$$\n\\frac{dL}{dw} = \\frac{d}{dw} \\left[ w^2 \\sigma_A^2 + (1-w)^2 \\sigma_B^2 + (w-p_A)^2 (\\mu_A - \\mu_B)^2 \\right]\n$$\n$$\n\\frac{dL}{dw} = 2w \\sigma_A^2 + 2(1-w)(-1) \\sigma_B^2 + 2(w-p_A) (\\mu_A - \\mu_B)^2 = 0\n$$\n等式两边同除以 $2$：\n$$\nw \\sigma_A^2 - (1-w) \\sigma_B^2 + (w-p_A) (\\mu_A - \\mu_B)^2 = 0\n$$\n我们展开并合并含有 $w$ 的项：\n$$\nw \\sigma_A^2 - \\sigma_B^2 + w \\sigma_B^2 + w (\\mu_A - \\mu_B)^2 - p_A (\\mu_A - \\mu_B)^2 = 0\n$$\n$$\nw (\\sigma_A^2 + \\sigma_B^2 + (\\mu_A - \\mu_B)^2) = \\sigma_B^2 + p_A (\\mu_A - \\mu_B)^2\n$$\n解出 $w$：\n$$\nw = \\frac{\\sigma_B^2 + p_A (\\mu_A - \\mu_B)^2}{\\sigma_A^2 + \\sigma_B^2 + (\\mu_A - \\mu_B)^2}\n$$\n二阶导数为 $\\frac{d^2L}{dw^2} = 2\\sigma_A^2 + 2\\sigma_B^2 + 2(\\mu_A - \\mu_B)^2$，由于方差为正，该值严格为正，这证实了此 $w$ 值对应于一个最小值。\n\n现在，我们代入给定的数值：\n- $\\mu_A = 0.14$\n- $\\mu_B = -0.02$\n- $\\sigma_A^2 = 0.0025$\n- $\\sigma_B^2 = 0.0064$\n- $p_A = 0.65$\n\n首先，我们计算与期望梯度差异相关的项：\n$$\n\\mu_A - \\mu_B = 0.14 - (-0.02) = 0.16\n$$\n$$\n(\\mu_A - \\mu_B)^2 = (0.16)^2 = 0.0256\n$$\n现在，将这些值代入 $w$ 的表达式中。\n分子是：\n$$\n\\sigma_B^2 + p_A (\\mu_A - \\mu_B)^2 = 0.0064 + (0.65)(0.0256) = 0.0064 + 0.01664 = 0.02304\n$$\n分母是：\n$$\n\\sigma_A^2 + \\sigma_B^2 + (\\mu_A - \\mu_B)^2 = 0.0025 + 0.0064 + 0.0256 = 0.0345\n$$\n所以，$w$ 的最优值为：\n$$\nw = \\frac{0.02304}{0.0345} \\approx 0.66782608...\n$$\n将结果四舍五入到四位有效数字，我们得到 $w = 0.6678$。", "answer": "$$\n\\boxed{0.6678}\n$$", "id": "4563886"}]}