## 引言
[药物重定位](@entry_id:748682)，即为已批准[药物发现](@entry_id:261243)新的治疗适应症，已成为加速药物研发、降低成本和应对未满足医疗需求的关键策略。与从零开始的漫长且昂贵的[药物发现](@entry_id:261243)过程相比，重定位利用现有药物已知的安全性数据，显著缩短了通往临床应用的路径。然而，在数千种药物和数千种疾病构成的巨大可能性空间中，如何系统性、高效地识别出有前景的“药物-疾病”新组合，构成了一个核心的计算挑战。

本文旨在全面剖析应对这一挑战的现代计算策略。我们将带领读者深入探索这一交叉学科领域，揭示如何将海量的生物医学数据转化为可供验证的治疗假设。

*   在**“原理与机制”**一章中，我们将奠定理论基础，系统性地介绍靶点中心、疾病中心和信号中心等核心计算范式，并探讨支撑这些范式的数学模型与数据源。
*   接下来，在**“应用与跨学科连接”**一章中，我们将展示这些原理如何应用于实践，特别是如何通过[网络医学](@entry_id:273823)和知识图谱等先进技术整合[异构数据](@entry_id:265660)，并讨论将计算假设转化为临床证据所面临的转化挑战。
*   最后，在**“动手实践”**部分，读者将有机会通过具体的编程练习，加深对关键概念（如相似性计算和偏倚识别）的理解。

通过这趟旅程，本文将为您构建一个从理论到实践的完整知识框架，助您掌握计算[药物重定位](@entry_id:748682)的核心技能。

## 原理与机制

继前一章对计算[药物重定位](@entry_id:748682)的背景和意义进行概述之后，本章将深入探讨支撑这一领域的多种核心原理和关键机制。我们将系统性地剖析用于发现药物新用途的各类计算范式、它们所依赖的数据模式，以及将这些策略付诸实践所需的数学和[统计模型](@entry_id:755400)。本章旨在为读者构建一个坚实的理论框架，从而能够理解、评估并应用各种计算[药物重定位](@entry_id:748682)方法。

### [药物重定位](@entry_id:748682)的形式化定义与价值

从根本上说，[药物重定位](@entry_id:748682)旨在为已批准的[药物发现](@entry_id:261243)新的治疗适应症。我们可以使用集合论的语言来精确地形式化这一定义。设 $D$ 为已获监管机构批准（至少有一个适应症）的药物集合， $I$ 为生物医学本体（如国际疾病分类）中定义的疾病适应症集合。我们可以定义一个标签函数 $L: D \to 2^{I}$ ，该函数将每个药物 $d \in D$ 映射到其当前已批准的适应症集合 $L(d) \subseteq I$ 。

**[药物重定位](@entry_id:748682) (Drug Repositioning)** 的核心任务，就是为某个已有的药物 $d \in D$ 系统性地识别并验证一个新的适应症 $i \in I$ ，使得 $i \notin L(d)$ 。这一过程与另外两个概念有显著区别：

*   **从头发现 (De novo discovery)**：该过程始于一个全新的化学或生物实体 $d^{\ast} \notin D$ ，这个实体没有任何先前的临床标签。其目标是带领该新实体完成针对其首个适应症的完整研发流程。
*   **标签扩展 (Label extension)**：这通常指对现有适应症进行细化或扩展，例如将批准范围扩大到新的患者群体（如儿童）、新的剂型、或同一疾病类别的不同分期，而不是转向一个全新的疾病领域。

[药物重定位](@entry_id:748682)最主要的吸[引力](@entry_id:189550)在于其能够显著缩短研发时间并降低成本。传统的药物研发管线总时间 $T_{\mathrm{total}}$ 和总成本 $C_{\mathrm{total}}$ 可分解为多个阶段的总和：
$T_{\mathrm{total}} = T_{\mathrm{pre}} + T_{\mathrm{I}} + T_{\mathrm{II}} + T_{\mathrm{III}} + T_{\mathrm{rev}}$
$C_{\mathrm{total}} = C_{\mathrm{pre}} + C_{\mathrm{I}} + C_{\mathrm{II}} + C_{\mathrm{III}} + C_{\mathrm{rev}}$
其中，下标 `pre` 指临床前研究，`I`、`II`、`III` 指代临床试验的三个阶段，`rev` 指监管审批。对于一个已批准的药物 $d \in D$ ，其大量的非临床安全性和I期临床安全性数据通常可以被复用或通过桥接研究加以利用。这意味着在新适应症的研发中，$T_{\mathrm{pre}}$、$C_{\mathrm{pre}}$、$T_{\mathrm{I}}$ 和 $C_{\mathrm{I}}$ 可能会大幅缩减甚至免除。

然而，对于新适应症的**有效性 (efficacy)** 必须通过新的II期和III期临床试验证明，因此 $T_{\mathrm{II}}$ 和 $T_{\mathrm{III}}$ 依然是必要的。计算策略的价值在于，通过整合多组学和临床证据，对海量的“药物-新适应症”配对进行排序，从而优先考虑那些具有更强机制支持或观察性证据的候选者。这种方法极大地缩小了需要进入昂贵的前瞻性实验研究的候选范围，从而降低了寻找一个成功新适应症的整体**期望**成本和时间 [@problem_id:4549817]。

### [药物重定位](@entry_id:748682)的数据版图

计算[药物重定位](@entry_id:748682)的成功依赖于对多模态生物医学数据的整合与分析。这些数据横跨了从分子到临床的多个层次。理解这些数据 modality 及其主要的公共来源是掌握相关计算方法的第一步 [@problem_id:4549822]。

*   **化学指纹 (Chemical fingerprints)**：这是从小分子结构中提取的二元特征向量，用于编码原子连接性、子结构等信息。它们是衡量药物化学相似性的基础。**DrugBank** 等数据库提供了药物的化学结构，可以从中计算出各种类型的化学指纹。

*   **药物靶点 (Drug targets)**：指药物在体内直接相互作用以发挥药效的分子，通常是蛋白质。这些信息是进行靶点中心式推断的基石。**DrugBank** 是一个权威的、经过人工审编的药物-靶点关联数据库。

*   **基因表达谱 (Gene expression signatures)**：指化合物处理人类细胞系后诱导的特征性转录变化。通过“ signature matching ”，即比较药物诱导的表达谱与疾病相关的表达谱，可以发现潜在的治疗关系。**LINCS (Library of Integrated Network-based Cellular Signatures)** 项目提供了一个关于这类扰动基因表达谱的大规模标准化公共资源。

*   **生物通路 (Pathways)**：这些是经过审编的[分子相互作用](@entry_id:263767)和[反应网络](@entry_id:203526)，为理解药物靶点和基因表达谱变化提供了生物学背景。**[Reactome](@entry_id:178795)** 是一个领先的、[同行评审](@entry_id:139494)的人类[生物通路数据库](@entry_id:169545)。

*   **表型 (Phenotypes)**：包括疾病性状、体征、症状以及基因型-表型关联。这些信息有助于衡量疾病间的相似性，并为药物作用机制提供线索。**OMIM (Online Mendelian Inheritance in Man)** 是一个权威的人类[孟德尔遗传](@entry_id:156036)性状及其遗传基础的目录。

*   **电子健康记录 (Electronic Health Records, EHR)**：包含患者纵向的临床数据，如用药史、诊断、实验室检查值、手术记录和生命体征。EHR为在真实世界环境中进行药物效果的观察性分析提供了可能。**MIMIC-III (Medical Information Mart for Intensive Care III)** 是一个公开的大规模、匿名的重症监护EHR语料库。

*   **不良事件 (Adverse events)**：指与药物使用相关的不良副作用，通常从药品标签和药物警戒数据库中提取。这些信息有助于刻画药物的安全性特征，也可用于基于副作用相似性的重定位推断。**SIDER (Side Effect Resource)** 就是一个专门提取已上市药物副作用信息的公共资源。

### 核心计算范式

计算[药物重定位](@entry_id:748682)的方法多种多样，但它们大致可以归为几个核心范式。理解每个范式的基本假设和适用场景至关重要。

#### 靶点中心式方法 (Target-Centric Approaches)

该范式基于一个核心假设：如果一个药物的靶点与某个疾病的关键致病基因在生物网络中“接近”，那么该药物可能对该疾病有效。

##### 机制一：基于结构的方法——[分子对接](@entry_id:166262)

当疾病的关键蛋白靶点结构已知时，**[分子对接](@entry_id:166262) (molecular docking)** 成为一种强大的筛选工具。其目标是预测小分子配体如何与蛋白受体结合，并评估结合的亲和力。对接程序通过一个**打分函数 (scoring function)** 来近似[结合自由能](@entry_id:166006) $\Delta G_{\mathrm{bind}}$ 。一个物理上合理的打分函数通常是多个能量项的加权和，旨在模拟结合过程中的焓 ($\Delta H$) 和熵 ($-T\Delta S$) 贡献 [@problem_id:4549799]。一个典型的打分函数 $E_{\mathrm{score}}$ 形式如下：

$E_{\mathrm{score}} = w_{\mathrm{vdW}} \sum_{i \in L}\sum_{j \in P}\left(\frac{A_{ij}}{r_{ij}^{12}} - \frac{B_{ij}}{r_{ij}^{6}}\right) + w_{\mathrm{elec}} \sum_{i \in L}\sum_{j \in P} \frac{q_i q_j}{\epsilon(r_{ij})\, r_{ij}} + w_{\mathrm{hb}} \sum_{\langle ij \rangle} f_{\mathrm{dir}}(\theta_{ij})\, g_{\mathrm{dist}}(r_{ij}) + w_{\mathrm{solv}} \left(G_{\mathrm{desolv}}^{\mathrm{GB/SA}}(L,P) \right) + w_{\mathrm{tor}} N_{\mathrm{rot}}$

该函数包含以下关键组成部分：
*   **范德华斯 (van der Waals) 相互作用**: 使用[Lennard-Jones势](@entry_id:143105)（$r_{ij}^{-12}$  repulsion, $r_{ij}^{-6}$ attraction）来描述原子间的短程排斥和长程吸引。
*   **静电 (Electrostatic) 相互作用**: 使用库仑定律描述配体（$L$）和蛋白（$P$）原子上[部分电荷](@entry_id:167157) $q_i, q_j$ 之间的相互作用。
*   **[氢键](@entry_id:136659) (Hydrogen bonding)**: 一个特定的方向性项，奖励符合几何偏好的[氢键](@entry_id:136659)。
*   **溶剂化 (Solvation)**: 一个[隐式溶剂模型](@entry_id:170981)项（如GB/SA），估算配体与[受体结合](@entry_id:190271)时，从表面去除有序水分子所带来的能量增益（即疏水效应）。
*   **[构象熵](@entry_id:170224) (Conformational entropy)**: 一个惩罚项，通常与配体的可旋转键数量 $N_{\mathrm{rot}}$ 成正比，用于近似配体在结合时损失的构象自由度。

尽管这些函数基于物理原理，但它们包含许多近似，并且权重 $w$ 通常通过在已知复合物结构和亲和力数据上进行经验性拟合得到。因此，它们的预测精度是有限的。与实验测量的亲和力相关性通常只有中等水平（例如，[Pearson相关系数](@entry_id:270276) $r \approx 0.3$ 至 $0.6$），[均方根误差](@entry_id:170440) (RMSE) 在 $2$ 到 $3$ $\mathrm{kcal}\cdot\mathrm{mol}^{-1}$ 的量级。对于重定位而言，对接打分主要用于大规模[虚拟筛选](@entry_id:171634)的早期富集和假设生成，而非绝对亲和力的精确预测。

##### 机制二：基于网络的方法——邻近性分析

当药物的靶点或疾病的关联基因不止一个时，我们可以在**蛋白质-蛋白质相互作用 (Protein-Protein Interaction, PPI)** 网络中量化它们之间的关系。[PPI网络](@entry_id:271273)是一个图 $G=(V,E)$ ，其中节点 $V$ 是蛋白质，边 $E$ 代表它们之间的相互作用。

“邻近性假设”认为，如果一个药物的靶点集合 $T$ 在网络中靠近一个疾病的基因模块 $D$ ，那么该药物可能对该疾病有效。这种“邻近性”可以通过计算**[最短路径距离](@entry_id:754797) (shortest path distance)** 来量化。为了使距离更具生物学意义，边的权重可以结合其他信息，例如通路共成员关系。例如，如果两个相互作用的蛋白质 $P_i$ 和 $P_j$ 共同出现在同一个[Reactome](@entry_id:178795)通路中，它们之间的边长可以设为 $\ell_{ij}=1$ ；否则设为 $\ell_{ij}=2$ ，以反映更强的功关联。

给定药物靶点集合 $T$ 和疾病基因集合 $D$ ，我们可以计算**平均靶点-疾病邻近度** $D_{\mathrm{mean}}$：
$$D_{\mathrm{mean}}=\frac{1}{|T||D|}\sum_{t\in T}\sum_{d\in D} d(t,d)$$
其中 $d(t,d)$ 是靶点 $t$ 和疾病基因 $d$ 之间的[最短路径距离](@entry_id:754797)。较小的 $D_{\mathrm{mean}}$ 值意味着药物的扰动更有可能通过较短的功能路径传播并影响到[疾病模块](@entry_id:271920)，因此表明了更高的重定位合理性 [@problem_id:4549826]。

#### 疾病中心式方法 (Disease-Centric Approaches)

这类方法的核心思想是基于不同实体在表型层面的相似性进行推断，例如“如果药物A的副作用谱与疾病B的症状谱相似，那么药物A可能可以治疗疾病B”（或其反向关系）。

##### 机制：表型相似性

为了量化表型相似性，我们可以利用生物医学[本体](@entry_id:264049)（如人类表型[本体](@entry_id:264049)HPO）。药物的副作用和疾病的症状都可以被映射到[本体](@entry_id:264049)中的术语。设 $P_{d}$ 是与药物 $d$ 关联的副作用术语集合， $P_{z}$ 是与疾病 $z$ 相关的症状术语集合。

我们可以使用基于**信息内容 (Information Content, IC)** 的[语义相似度](@entry_id:636454)来比较两个术语。一个术语 $t$ 的信息内容定义为其在大型语料库中出现频率 $p(t)$ 的函数： $IC(t) = -\log p(t)$ 。频率越低的术语（即越特异的表型）信息内容越高。两个术语 $a$ 和 $b$ 的相似度可以通过它们最具体共同祖先（Most Informative Common Ancestor, MICA）的IC来计算。

要将术语级别的相似度 $s(a,b)$ 扩展到集合级别的相似度 $S(P_d, P_z)$ ，可以使用**对称最佳匹配平均 (symmetric best-match aggregation)** 策略。该方法为 $P_d$ 中的每个术语在 $P_z$ 中找到最相似的匹配，求平均值；反向亦然；最后取两个方向性平均值的平均值。这种方法避免了由于[本体](@entry_id:264049)层级结构导致的冗余计算。

$S(P_{d}, P_{z}) = \frac{1}{2}\left[\frac{1}{|P_{d}|}\sum_{a \in P_{d}} \max_{b \in P_{z}} s(a,b) \;+\; \frac{1}{|P_{z}|}\sum_{b \in P_{z}} \max_{a \in P_{d}} s(a,b)\right]$

这个聚合得分 $X = S(P_{d}, P_{z})$ 可以作为一个特征，输入到一个概率模型中（如逻辑回归），以预测药物-疾病之间是否存在治疗关系 $Y \in \{0,1\}$ 。在贝叶斯框架下，假设特征 $X$ 在两个类别（治疗 vs. 不治疗）下的条件分布近似为高斯分布，那么后验概率 $\mathbb{P}(Y=1 \mid X)$ 可以被建模为一个关于 $X$ 的 logistic 函数，其参数可以从数据中学习 [@problem_id:4549837]。

#### 信号中心式方法 (Signature-Centric Approaches)

该范式假设药物可以通过“逆转”疾病特有的分子信号（通常是基因表达谱）来发挥治疗作用。

##### 机制：转录组信号逆转

首先，通过比较疾病组织样本和健康对照样本的基因表达数据（如RNA-seq），可以构建一个**疾病信号向量 (disease signature vector)** $\mathbf{d} \in \mathbb{R}^{p}$ ，其中 $p$ 是基因数量，向量的每个元素代表对应基因在疾病中上调或下调的程度（如log fold-change）。

类似地，可以从公共数据库（如LINCS）中获取药物处理细胞后产生的**药物响应向量 (drug response vector)** $\mathbf{r} \in \mathbb{R}^{p}$ 。

“逆转”的理念在几何上可以理解为药物响应向量 $\mathbf{r}$ 与疾病信号向量 $\mathbf{d}$ 方向相反。这种关系可以通过计算它们之间夹角的余弦来量化。一个常用的**逆转分数 (reversal score)** 定义为：
$s(\mathbf{d},\mathbf{r}) = -\cos(\mathbf{d},\mathbf{r}) = -\dfrac{\mathbf{d} \cdot \mathbf{r}}{\|\mathbf{d}\| \, \|\mathbf{r}\|}$

该分数具有以下重要性质 [@problem_id:4549862]：
*   **范围与解释**: $\cos(\mathbf{d},\mathbf{r})$ 的范围是 $[-1, 1]$ ，因此 $s(\mathbf{d},\mathbf{r})$ 的范围也是 $[-1, 1]$ 。当 $s(\mathbf{d},\mathbf{r}) = 1$ 时，表示 $\mathbf{r}$ 与 $\mathbf{d}$ 完全反向（$\cos = -1$，夹角$180^\circ$），代表完美的理论逆转。当 $s(\mathbf{d},\mathbf{r}) = -1$ 时，表示药物在模仿疾病信号，可能加重病情。
*   **尺度不变性**: 该分数只依赖于向量的方向，而与它们的幅度无关。对于任意正标量 $\alpha > 0$ ，$s(\mathbf{d},\alpha \mathbf{r}) = s(\mathbf{d},\mathbf{r})$ 。这意味着药物作用的强度不影响逆转分数的方向性判断。
*   **与[Pearson相关](@entry_id:260880)性的关系**: 如果向量 $\mathbf{d}$ 和 $\mathbf{r}$ 都经过标准化（均值为0，方差为1），那么 $\cos(\mathbf{d},\mathbf{r})$ 就等于它们之间的Pearson相关系数 $\rho(\mathbf{d}, \mathbf{r})$ 。此时，逆转分数就是负的[Pearson相关系数](@entry_id:270276)，$s(\mathbf{d},\mathbf{r}) = -\rho(\mathbf{d}, \mathbf{r})$ 。

#### 范式选择：一个基于证据的决策

在实际研究中，选择哪种范式取决于特定疾病背景下可用证据的质量和数量。假设我们面对一种罕见的炎症性疾病，相关研究非常有限 [@problem_id:4549865]。

*   如果**靶点中心**的遗传学证据很弱（例如，GWAS发现的显著位点 $k$ 很少，位点是真阳性的后验概率 $\overline{\mathrm{PIP}}$ 很低，效应值 $\beta$ 很小，且映射到可成药蛋白的概率 $\pi_d$ 很低），那么从遗传学出发寻找靶点的策略将充满不确定性，成功率极低。
*   如果**疾病中心**的临床证据同样不可靠（例如，EHR中可靠编码的病例数 $n_c$ 很少，与其他疾病的共病相似性指数 $J$ 很低，且被观测噪声 $\sigma_J$ 淹没），那么基于表型相似性的推断也将缺乏[统计功效](@entry_id:197129)。
*   在这种情况下，如果**信号中心**的[转录组学](@entry_id:139549)证据反而相对稳健（例如，在多个独立队列中疾病信号具有[可重复性](@entry_id:194541)，相关系数 $r$ 中等偏高；基因表达变化幅度 $\overline{L}$ 较大；并且与药物库的连接图（CMap）分析显示出显著的逆转信号，连接分数 $c  0$ 且FDR $q$ 值很低），那么信号逆转范式就成为最有希望产生可行动假设的策略。

因此，对不同范式的选择是一个基于证据可靠性和信息增益的概率性决策过程，而非遵循僵化的规则。

### 整合证据：现代综合方法

单一范式往往只能捕捉到复杂生物过程的一个侧面。现代[药物重定位](@entry_id:748682)策略越来越倾向于整合来自多个信息源的证据，以构建更稳健、更准确的预测模型。

#### 基于机器学习的整合

一个直接的整合方法是构建一个统一的**[机器学习模型](@entry_id:262335)**。我们可以从不同范式中提取特征，并将它们拼接成一个特征向量 $\mathbf{x} \in \mathbb{R}^{d}$ 来代表一个“药物-疾病”对。这个向量可以包含：
*   **化学特征**: 药物的化学指纹。
*   **靶[点特征](@entry_id:155984)**: 药物靶点与疾病基因的网络邻近度分数。
*   **信号特征**: 药物与疾病的[转录组](@entry_id:274025)信号逆转分数。

然后，我们可以使用一个[二元分类](@entry_id:142257)器，如**逻辑回归 (logistic regression)**，来预测治疗关系 $y=1$ 的概率。该模型预测后验概率为 $P(y = 1 \mid \mathbf{x}) = \sigma(\mathbf{w}^\top \mathbf{x})$，其中 $\sigma(z) = (1 + e^{-z})^{-1}$ 是 logistic 函数，权重向量 $\mathbf{w}$ 通过在已知的阳性（治疗）和阴性（不治疗）样本上最小化一个正则化的[损失函数](@entry_id:136784)（如[负对数似然](@entry_id:637801)）来学习。

训练好的模型可以输出一个概率分数。在实际应用中，决策阈值 $\tau$ 的选择至关重要，特别是当误分类成本不对称时（例如，假阴性 $c_{FN}$ 的成本远高于[假阳性](@entry_id:635878) $c_{FP}$ ）。贝叶斯最优决策规则是将模型的输出概率 $p = \sigma(\mathbf{w}^\top \mathbf{x})$ 与一个依赖于成本的阈值进行比较：$\tau^{\star} = \frac{c_{FP}}{c_{FP} + c_{FN}}$ 。当 $p > \tau^{\star}$ 时，我们预测存在治疗关系 [@problem_id:4549828]。

#### 基于知识图谱的整合

另一种强大的整合范式是**知识图谱 (Knowledge Graph, KG)**。一个生物医学KG由大量的三元组 $(h, r, t)$ 构成，例如 `(阿司匹林, 靶向, COX-2)`、`(COX-2, 参与, 炎症通路)`、`(炎症, 是...的症状, 关节炎)`。这里的头实体 $h$ 、关系 $r$ 和尾实体 $t$ 共同编码了结构化的生物医学知识。

[药物重定位](@entry_id:748682)可以被视为一个**[链接预测](@entry_id:262538) (link prediction)** 问题：在KG中预测缺失的 `(药物, 治疗, 疾病)` 类型的链接。这是通过学习实体和关系的低维向量**嵌入 (embedding)** 来实现的。目标是学习一个打分函数 $\phi(h, r, t)$，使得图中真实存在的三元组得分高于随机“损坏”的（不存在的）三元组。

几种经典的知识图谱嵌入模型及其打分函数如下 [@problem_id:4549808]：
*   **TransE**: 将关系建模为[嵌入空间](@entry_id:637157)中的翻译操作。$\phi_{\mathrm{TransE}}(h,r,t) = -\|\mathbf{h} + \mathbf{r} - \mathbf{t}\|_{2}$。这里，关系嵌入 $\mathbf{r} \in \mathbb{R}^d$ 是一个翻译向量，理想情况下 $\mathbf{h} + \mathbf{r} \approx \mathbf{t}$。它能很好地处理一对一关系，但在处理对称关系时存在困难。
*   **DistMult**: 使用三线积打分。$\phi_{\mathrm{DistMult}}(h,r,t) = \sum_{k=1}^{d} h_{k} r_{k} t_{k}$。关系嵌入 $\mathbf{r} \in \mathbb{R}^d$ 充当了头尾实体嵌入元素乘积的权重。由于乘法交换律，该模型只能建模对称关系（即 $\phi(h,r,t) = \phi(t,r,h)$），无法区分 `(药物A, 治疗, 疾病B)` 和 `(疾病B, 治疗, 药物A)`。
*   **ComplEx**: 将DistMult扩展到复数域以建模非对称关系。$\phi_{\mathrm{ComplEx}}(h,r,t) = \operatorname{Re}\left(\sum_{k=1}^{d} h_{k} r_{k} \overline{t_{k}}\right)$。通过使用复数嵌入 $\mathbf{h}, \mathbf{r}, \mathbf{t} \in \mathbb{C}^d$ 和对尾实体取共轭 $\overline{t_k}$ ，该模型打破了对称性，使其能够同时建模对称和非对称关系，这对于生物医学应用至关重要。

KG方法通过在整个知识网络中学习实体和关系的表示，能够隐式地捕捉多步骤、多模态的复杂关联，是当前[药物重定位](@entry_id:748682)领域一个非常活跃和有前途的方向。

### 基于真实世界数据的验证与因果推断

计算方法产生的重定位假设最终需要验证。在进入昂贵的临床试验之前，使用电子健康记录（EHR）等**真实世界数据 (Real-World Data)** 进行[观察性研究](@entry_id:174507)是一种有效的中期验证步骤。然而，直接分析这些数据充满了挑战，最主要的是**混杂 (confounding)**。

例如，在评估一种抗炎药 $E$ 对病毒性肺炎患者死亡率 $Y$ 的影响时，我们可能会观察到用药组的死亡率更高。但这可能并非药物无效或有害，而是因为医生倾向于将药物开给病情更严重 $S$ 的患者（**因症施治 confounding by indication**），而病情严重本身就会导致更高的死亡率。

为了从观察性数据中估计**总因果效应 (total causal effect)**，我们需要借助**因果推断 (causal inference)** 的工具，特别是**[有向无环图](@entry_id:164045) (Directed Acyclic Graph, DAG)**。DAG可以清晰地编码我们关于变量间因果关系的先验知识。

考虑一个场景，其中基线疾病严重程度 $S$ 和共病负担 $C$ 都会影响用药决策 $E$ 和结局 $Y$ 。此外，医院系统 $H$ 通过影响医生偏好 $P$ 来影响用药 $E$ ，同时 $H$ 也独立影响结局 $Y$ （如医疗质量）。药物 $E$ 通过影响一个早期生物标志物 $M$ 来影响 $Y$ 。最后，一个登记系统 $R$ 的入组与否同时被用药 $E$ 和结局 $Y$ 影响。

为了消除混杂，我们需要找到一个**充分调整集 (sufficient adjustment set)** $Z$ ，它满足**[后门准则](@entry_id:637856) (back-door criterion)**：
1.  $Z$ 中没有任何变量是 $E$ 的后代。
2.  $Z$ 阻断了所有从 $E$ 到 $Y$ 的“后门路径”（即以指向 $E$ 的箭头开始的路径）。

在这个例子中，我们必须**不**调整：
*   **中介变量 (mediator)** $M$ ，因为它位于 $E \to Y$ 的因果链上。调整它会阻断我们想测量的部分效应。
*   **对撞变量 (collider)** $R$ ，因为它是由 $E$ 和 $Y$ 共同导致的（$E \to R \leftarrow Y$）。调整对撞变量会打开一条虚假的关联路径，引入选择偏倚。

分析DAG可以发现，我们需要阻断的后门路径主要有 $E \leftarrow S \to Y$, $E \leftarrow C \to Y$ 和 $E \leftarrow P \leftarrow H \to Y$。要阻断所有这些路径，同时又不违反上述规则，两个最小充分调整集是 $\{S, C, H\}$ 和 $\{S, C, P\}$。通过在[统计模型](@entry_id:755400)中对这些集合中的变量进行调整（如作为协变量纳入[回归模型](@entry_id:163386)），我们可以更准确地估计药物 $E$ 对结局 $Y$ 的因果效应 [@problem_id:4549859]。这为计算生成的假设提供了更可靠的真实世界证据支持。