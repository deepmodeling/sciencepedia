{"hands_on_practices": [{"introduction": "在我们理解bagging为何有效之前，必须首先深入探究其所使用的自助样本（bootstrap samples）的内在特性。第一个练习要求你从第一性原理出发，推导一个自助样本中唯一数据点的期望数量。掌握这一核心概念不仅能揭示bagging集成中单个模型为何具有多样性，也为后续理解和应用袋外（Out-of-Bag, OOB）评估奠定了坚实的基础。[@problem_id:4559772]", "problem": "在一项监督式基因组分类研究中，您有一个包含 $n=200$ 名患者的原始队列，每位患者都由高维基因表达谱表示。为构建基学习器的自助聚合（bagged）集成模型，每个模型都在一个自助样本上进行训练：从 $n$ 名患者中进行 $n$ 次有放回的抽样，每次抽样都以均匀随机的方式选择一名患者，且所有抽样都是独立同分布（i.i.d.）的。仅使用这些定义和诸如指示随机变量和期望线性性等第一性原理，从头推导单个自助样本中包含的唯一患者数量的期望值的精确表达式（作为 $n$ 的函数），然后对 $n=200$ 的情况进行求值。将您的数值答案四舍五入到四位有效数字，并以患者数量的形式报告。最后，在用于高维基因组分类器的自助聚合（bagging）中，结合方差缩减和过拟合控制来解释该期望值的大小，并包括袋外（OOB）评估的作用（在首次出现时定义袋外（OOB））。您最终报告的答案必须仅为四舍五入后的期望患者数量。", "solution": "该问题是有效的，因为它在科学上基于统计学习理论的原理，问题提出得当且客观。我们可以开始求解。\n\n目标是推导从一个包含 $n$ 名患者的原始队列中进行有放回抽样，得到的单个大小为 $n$ 的自助样本中所含唯一患者数量的期望值的精确表达式。\n\n设原始患者集合为 $C = \\{p_1, p_2, \\dots, p_n\\}$。通过从 $C$ 中有放回地抽取 $n$ 次来构建一个自助样本。所有抽样都是独立同分布（i.i.d.）的，并且在任何单次抽样中，每位患者被选中的概率为 $\\frac{1}{n}$。\n\n设 $X$ 为表示自助样本中唯一患者数量的随机变量。为了求 $X$ 的期望，我们可以按照建议，将 $X$ 表示为指示随机变量的和。对于每位患者 $j \\in \\{1, 2, \\dots, n\\}$，设 $I_j$ 为一个指示随机变量，定义如下：\n$$\nI_j = \\begin{cases} 1  \\text{如果患者 } j \\text{ 至少在自助样本中出现一次} \\\\ 0  \\text{如果患者 } j \\text{ 未在自助样本中出现} \\end{cases}\n$$\n样本中唯一患者的总数是这些指示变量的和：\n$$\nX = \\sum_{j=1}^{n} I_j\n$$\n根据期望的线性性，唯一患者的期望数量是单个指示变量期望值的总和：\n$$\nE[X] = E\\left[\\sum_{j=1}^{n} I_j\\right] = \\sum_{j=1}^{n} E[I_j]\n$$\n指示随机变量的期望等于它所指示事件的概率。因此，$E[I_j] = P(I_j = 1)$。\n事件 $I_j=1$ 发生，如果患者 $j$ 在 $n$ 次抽样中至少被选中一次。计算其互补事件的概率 $P(I_j = 0)$ 更简单，即患者 $j$ 在 $n$ 次抽样中从未被选中的事件。\n\n在单次抽样中，选中任何特定患者 $j$ 的概率是 $\\frac{1}{n}$。\n因此，在单次抽样中*不*选中患者 $j$ 的概率是 $1 - \\frac{1}{n}$。\n由于 $n$ 次抽样是独立的，因此在 $n$ 次抽样中都未选中患者 $j$ 的概率是每次抽样中不选中患者 $j$ 的概率的乘积：\n$$\nP(I_j = 0) = \\left(1 - \\frac{1}{n}\\right) \\times \\left(1 - \\frac{1}{n}\\right) \\times \\dots \\times \\left(1 - \\frac{1}{n}\\right) = \\left(1 - \\frac{1}{n}\\right)^n\n$$\n因此，患者 $j$ 至少被选中一次的概率是：\n$$\nP(I_j = 1) = 1 - P(I_j = 0) = 1 - \\left(1 - \\frac{1}{n}\\right)^n\n$$\n所以，指示变量的期望是 $E[I_j] = 1 - \\left(1 - \\frac{1}{n}\\right)^n$。因为抽样是均匀的，这个概率对于所有患者 $j=1, \\dots, n$ 都是相同的。\n\n将此代入 $E[X]$ 的表达式中：\n$$\nE[X] = \\sum_{j=1}^{n} \\left[1 - \\left(1 - \\frac{1}{n}\\right)^n\\right]\n$$\n由于求和号内的项相对于索引 $j$ 是常数，所以总和就是该项的 $n$ 倍：\n$$\nE[X] = n \\left[1 - \\left(1 - \\frac{1}{n}\\right)^n\\right]\n$$\n这就是单个自助样本中唯一患者数量的期望值的精确表达式。\n\n现在，我们对 $n=200$ 计算这个表达式：\n$$\nE[X] = 200 \\left[1 - \\left(1 - \\frac{1}{200}\\right)^{200}\\right] = 200 \\left[1 - \\left(\\frac{199}{200}\\right)^{200}\\right]\n$$\n计算括号中项的值：\n$$\n\\left(\\frac{199}{200}\\right)^{200} = (0.995)^{200} \\approx 0.3669528...\n$$\n将此值代回期望值的表达式中：\n$$\nE[X] \\approx 200 [1 - 0.3669528] = 200 [0.6330472] \\approx 126.60944\n$$\n四舍五入到四位有效数字，唯一患者的期望数量是 $126.6$。\n\n这意味着，平均而言，一个自助样本包含原始 $200$ 名患者中的约 $126.6$ 名，即大约 $63.3\\%$。平均剩下的 $200 - 126.6 = 73.4$ 名患者，即大约 $36.7\\%$，没有被包含在内。这些被排除的样本被称为**袋外（Out-of-Bag, OOB）**样本，即原始数据集中未出现在给定自助样本中的观测值。\n\n这个期望值的大小对于自助聚合（bagging）的有效性至关重要。\n1.  **方差缩减与过拟合控制**：Bagging通过平均多个模型的预测来降低估计的方差。为使这种平均有效，模型必须具有多样性，即它们必须犯不同的错误。通过在不同的自助样本上训练每个基学习器（每个样本仅包含约 $63.3\\%$ 的唯一数据），我们确保了这种多样性。在高维基因组研究中，分类器（如决策树）极易通过捕捉虚假的噪声而对训练数据产生过拟合。Bagging通过让每棵树对数据的不同子集进行过拟合来缓解此问题；当它们的预测被平均时，大部分特定于模型的噪声会相互抵消，从而产生更平滑的决策边界和更鲁棒的、具有更好泛化性能的集成模型。每次训练都忽略了原始数据中相当大的一部分，正是这一点驱动了基学习器之间关键的去相关性。\n\n2.  **袋外（OOB）评估的作用**：OOB样本为每个基学习器提供了一个“免费”且无偏的验证集。为了评估整个bagged集成模型的性能，可以对原始数据集中的每位患者，聚合那些将该患者作为OOB样本的模型的预测。由此产生的“OOB误差”是对集成模型泛化误差的可靠估计，计算它无需单独的留出测试集或计算成本高昂的交叉验证程序。OOB集相当大的规模（平均每个模型有 $73.4$ 名患者）确保了这种估计的稳定性和可信度，这在数据通常有限的医学数据分析中是一个显著的优势。", "answer": "$$\\boxed{126.6}$$", "id": "4559772"}, {"introduction": "Bagging方法的一个关键优势在于其提供了一种“免费”且高效的模型验证机制，即袋外（Out-of-Bag, OOB）误差估计。本练习将引导你深入比较OOB误差与广泛使用的K折交叉验证（K-fold cross-validation）方法在统计特性上的差异，特别是它们的偏差（bias）。通过这个思辨过程，你将更深刻地理解为何OOB误差不仅计算成本低，更是一种对模型泛化性能的可靠估计。[@problem_id:4559762]", "problem": "一个临床数据集提供了从未知分布中抽取的 $N$ 个独立同分布的患者记录 $\\{(X_i, Y_i)\\}_{i=1}^N$，其中 $Y_i \\in \\{0,1\\}$ 表示疾病状态。由于诊断金标准不完美，标签存在比率为 $\\varepsilon \\in (0, 1/2)$ 的对称标签噪声，特征 $X_i$ 包括常规实验室结果和人口统计信息。通过聚合 $M$ 个分类与回归树 (CART) 基学习器来构建一个 Bagging 分类器，每个基学习器都在从完整数据集中抽取的、大小为 $N$ 的自助样本上进行训练。考虑在完整数据集上构建的 Bagging 分类器的泛化误差（期望风险）的以下两种估计量：\n1. 袋外 (OOB) 误差：对于每个观测值 $i$，其预测是通过仅对那些自助样本不包含观测值 $i$ 的树进行平均而形成的，总误差是所有 $i$ 的损失的平均值。\n2. $K=5$ 的 $K$ 折交叉验证 (CV) 误差：将数据划分为 $5$ 个不相交的折，对于每一折，在其他 $4$ 折上训练一个 Bagging 分类器，并在留出的那一折上进行评估；最后对各折的误差进行平均。\n\n假设 $M \\gg 1$，因此由有限数量的树引起的蒙特卡洛波动可以忽略不计。请仅使用期望风险 $\\mathbb{E}[\\ell(\\hat{f}(X), Y)]$ 的基本定义、自助采样的性质以及 $K$ 折交叉验证的构造，来推断在含噪声的临床数据生成过程中，这两种误差估计量相对于在所有 $N$ 个观测值上训练的 Bagging 分类器的真实泛化误差的偏差方向。哪个陈述最准确？\n\nA. 当 $M \\to \\infty$ 时，对于在完整数据集上训练的 Bagging 分类器的泛化误差而言，袋外误差是渐进无偏的，而 $5$ 折交叉验证则具有悲观偏差，因为每一折的训练只使用了 $80\\%$ 的数据。\n\nB. 当 $M \\to \\infty$ 时，即使 $N$ 是有限的，袋外误差和 $5$ 折交叉验证对于在完整数据集上训练的 Bagging 分类器的泛化误差都是无偏的。\n\nC. 在含噪声的临床数据集中，袋外误差具有乐观偏差，因为许多树是在包含目标观测值的自助样本上训练的，这会泄露信息。\n\nD. $5$ 折交叉验证相对于在完整数据集上训练的 Bagging 分类器的泛化误差具有乐观偏差，因为它对留出折上的损失进行平均，而这些折比完整分布更容易预测。\n\nE. 只有当 $K=N$（留一交叉验证）时，袋外误差和 $5$ 折交叉验证之间的偏差差异才会消失；对于 $K=5$，袋外误差总是偏差更大。", "solution": "用户要求对所提供的问题陈述进行严格验证，然后进行严谨的求解推导并评估所有选项。\n\n### 步骤1：提取已知条件\n- **数据集**：$N$ 个独立同分布 (i.i.d.) 的患者记录 $\\{(X_i, Y_i)\\}_{i=1}^N$。\n- **数据分布**：从未知分布中抽取。\n- **标签**：$Y_i \\in \\{0,1\\}$ (疾病状态)。\n- **标签噪声**：比率为 $\\varepsilon \\in (0, 1/2)$ 的对称标签噪声。\n- **特征**：$X_i$ (实验室结果和人口统计信息)。\n- **分类器**：聚合了 $M$ 个分类与回归树 (CART) 基学习器的 Bagging 分类器。\n- **训练方法**：每个基学习器都在大小为 $N$ 的自助样本上训练。\n- **误差估计量1**：袋外 (OOB) 误差。对于每个观测值 $i$，通过聚合那些自助样本不包含观测值 $i$ 的树来做出预测。总误差是所有观测值损失的平均值。\n- **误差估计量2**：$K=5$ 的 $K$ 折交叉验证 (CV) 误差。数据被划分为 5 个不相交的折。对于每一折，在其他 4 折上训练一个 Bagging 分类器，并在留出的那一折上进行评估。最后对各折误差进行平均。\n- **假设**：$M \\gg 1$，意味着树的数量足够大，可以忽略聚合中的蒙特卡洛误差。\n- **目标**：确定关于这两种误差估计量相对于在所有 $N$ 个观测值上训练的 Bagging 分类器的真实泛化误差的偏差方向的最准确陈述。\n\n### 步骤2：使用提取的已知条件进行验证\n1.  **科学基础（关键）**：该问题牢固地植根于统计机器学习理论。Bagging（自助聚合）、CART、袋外误差估计和 K 折交叉验证都是标准的、定义明确的概念。在带有噪声标签的临床数据集的背景下，这是一个常见且现实的应用领域。该问题遵循既定的科学原则。\n2.  **适定性**：该问题是适定的。它要求对一个明确定义的量（特定分类器的真实泛化误差），在两个定义明确的统计估计量（$\\hat{Err}_{OOB}$ 和 $\\hat{Err}_{CV}$）之间进行定性比较（偏差方向）。基于这些估计量的性质，存在一个唯一的概念性答案。\n3.  **客观性（关键）**：语言精确且技术性强。诸如“偏差”、“泛化误差”、“自助样本”和“K 折交叉验证”等术语都有正式定义。该问题不含主观或基于观点的陈述。\n4.  **完整性**：该问题提供了推断偏差所需的所有必要信息。对于基于估计量构造的偏差定性分析，不需要 $N$、$M$（除了知道它很大）的具体值，也不需要数据分布的具体细节。假设 $M \\gg 1$ 至关重要，并且已经给出。\n5.  **未检测到其他缺陷**：该问题不存在矛盾、不切实际、不适定、琐碎或无法验证的情况。提及“对称标签噪声”增加了现实的复杂性，但并未改变误差估计量的基本机制，因此不会使问题失效。\n\n### 步骤3：结论与行动\n问题陈述是**有效的**。开始进行求解。\n\n### 推导\n设 $S = \\{(X_i, Y_i)\\}_{i=1}^N$ 是大小为 $N$ 的完整数据集。设 $\\hat{f}_S$ 表示在 $S$ 上训练的 Bagging 分类器。该分类器是 $M$ 个基学习器 $\\{\\hat{h}_b\\}_{b=1}^M$ 的聚合，其中每个 $\\hat{h}_b$ 是在从 $S$ 中抽取的、大小为 $N$ 的自助样本 $S^{*b}$ 上训练的 CART。\n我们希望估计的目标量是 $\\hat{f}_S$ 的真实泛化误差（或期望风险），定义为：\n$$ R(\\hat{f}_S) = \\mathbb{E}_{(X,Y)}[\\ell(\\hat{f}_S(X), Y)] $$\n其中期望是针对真实的、未知的数据生成分布计算的，而 $\\ell$ 是一个合适的损失函数（例如，分类问题中的 $0$-$1$ 损失）。分类器 $\\hat{f}_S$ 由数据集 $S$ 固定。我们的目标是分析这两个估计量 $\\hat{Err}_{OOB}$ 和 $\\hat{Err}_{CV}$ 对于数量 $R(\\hat{f}_S)$ 的偏差。\n\n**估计量的偏差**：一个估计量 $\\hat{\\theta}$ 对于参数 $\\theta$ 的偏差是 $\\mathbb{E}[\\hat{\\theta}] - \\theta$。正偏差称为悲观偏差（高估），负偏差称为乐观偏差（低估）。对于误差估计，我们通常关心的是估计量在训练集分布上的期望，与期望真实误差的比较。设 $Err(n)$ 表示在大小为 $n$ 的数据集上训练的分类器的期望泛化误差，即 $Err(n) = \\mathbb{E}_{S_n}[R(\\hat{f}_{S_n})]$。通常，对于一个稳定的学习算法，$Err(n)$ 是 $n$ 的一个非增函数。更多的数据会产生更好的模型，其泛化误差更低。\n\n**1. 5折交叉验证 (CV) 误差分析**\n在 $K=5$ 的 $K$ 折交叉验证中，数据集 $S$ 被划分为 5 个不相交的折。对于每一折 $k \\in \\{1,...,5\\}$，一个*新*的 Bagging 分类器（我们称之为 $\\hat{f}_{\\neg k}$）在剩下的 4 折上进行训练。这个训练集的大小是 $N(1-1/K) = N(1-1/5) = 4N/5 = 0.8N$。然后，在留出的第 $k$ 折上估计 $\\hat{f}_{\\neg k}$ 的误差。最终的 CV 误差 $\\hat{Err}_{CV}$ 是这 5 个误差估计值的平均值。\n\n关键在于，$\\hat{Err}_{CV}$ 是在大小为 $0.8N$（而非 $N$）的数据集上训练的分类器的泛化误差的估计。由于包括 Bagging 树在内的大多数分类器的性能会随着训练数据的增多而提高，学习曲线 $Err(n)$ 是 $n$ 的一个递减函数。因此，我们预期：\n$$ \\mathbb{E}[\\hat{Err}_{CV}] \\approx Err(0.8N)  Err(N) $$\n因为 CV 过程评估的是在比完整数据集更小的数据集上训练的模型，所以这些模型预计不如在完整数据集上训练的最终模型准确（即具有更高的误差）。因此，$K$ 折 CV 误差估计量具有**悲观偏差**；它倾向于高估最终模型的真实泛化误差。\n\n**2. 袋外 (OOB) 误差分析**\nOOB 误差估计量 $\\hat{Err}_{OOB}$ 的工作方式不同。它使用在完整数据集 $S$ 上训练的*单一* Bagging 分类器 $\\hat{f}_S$。对于每个观测值 $(X_i, Y_i) \\in S$，其预测是通过仅聚合那些对应的自助样本 $S^{*b}$ 中不包含 $(X_i, Y_i)$ 的树 $\\{\\hat{h}_b\\}$ 来做出的。这些就是观测值 $i$ 的“袋外”树。\n一个特定的观测值 $i$ 在大小为 $N$ 的自助采样中未被选中的概率是 $(1 - 1/N)^N$。当 $N \\to \\infty$ 时，这个概率收敛到 $1/e \\approx 0.368$。因此，平均而言，每个观测值对于大约 $36.8\\%$ 的树来说是“袋外”的。观测值 $i$ 的 OOB 误差是使用一个预测来计算的，在这个预测中 $(X_i, Y_i)$ 被有效地留出，作为该树子集的测试点。$\\hat{Err}_{OOB}$ 是这些误差在所有 $i=1,...,N$ 上的平均值。\n\n因为 OOB 过程使用在特定基学习器训练期间未见过的观测值来测试它们，所以它提供了一种有效的误差估计机制，避免了因在训练数据上测试而产生的乐观偏差。源自 Breiman 的经典观点认为，OOB 误差是真实泛化误差的一个近乎无偏的估计量。与 $K$ 折 CV 不同，它不需要在更小的数据分区上重新训练新模型。它估计的是我们所构建的那个模型 $\\hat{f}_S$ 本身的误差。\n\n尽管更详细的理论分析表明，对于有限的 $N$，OOB 误差可能存在小的悲观偏差（由于 OOB 子集成中基学习器之间的相关性），但这种偏差通常远小于 $K$ 折 CV 的悲观偏差（特别是对于像 $5$ 这样的小 $K$ 值）。出于许多实践和理论目的，特别是随着 $N$ 的增长，OOB 误差被认为是渐进无偏的。\n\n**偏差总结**：\n- **5折CV**：具有显著的悲观偏差，因为它评估的是仅在 $80\\%$ 的数据上训练的模型。\n- **OOB误差**：是无偏的或具有小的悲观偏差。相比于 $5$ 折 CV，它是一个对 $R(\\hat{f}_S)$ 偏差小得多的估计量。\n\n比率为 $\\varepsilon \\in (0, 1/2)$ 的对称标签噪声的存在增加了不可约误差，使学习问题变得更难，但它不会改变这两种估计量偏差的基本方向，因为偏差源于它们使用训练数据的方式。\n\n### 逐项分析\n\n**A. 当 $M \\to \\infty$ 时，对于在完整数据集上训练的 Bagging 分类器的泛化误差而言，袋外误差是渐进无偏的，而 $5$ 折交叉验证则具有悲观偏差，因为每一折的训练只使用了 $80\\%$ 的数据。**\n这个陈述是准确的。它正确地指出了 $5$ 折 CV 的悲观偏差及其原因。将 OOB 误差描述为“渐进无偏”是在此背景下的标准且正确的描述，特别是与偏差大得多的 CV 相比。OOB 的偏差（如果存在的话）已知很小，并且随着样本量的增加而减小。**正确**。\n\n**B. 当 $M \\to \\infty$ 时，即使 $N$ 是有限的，袋外误差和 $5$ 折交叉验证对于在完整数据集上训练的 Bagging 分类器的泛化误差都是无偏的。**\n这是不正确的。如上所推导，$5$ 折交叉验证对于有限的 $N$ 具有悲观偏差，因为它是在较小的数据集上训练的。这个偏差不会仅仅因为 $M \\to \\infty$ 而消失。**不正确**。\n\n**C. 在含噪声的临床数据集中，袋外误差具有乐观偏差，因为许多树是在包含目标观测值的自助样本上训练的，这会泄露信息。**\n这个陈述从根本上误解了 OOB 误差的计算方式。对于一个给定的观测值，其误差是*仅*使用那些*没有*在该观测值上训练过的树来计算的。这个过程是专门设计用来防止信息泄露和由此产生的乐观偏差。OOB 的偏差通常被认为是悲观的，而不是乐观的。**不正确**。\n\n**D. $5$ 折交叉验证相对于在完整数据集上训练的 Bagging 分类器的泛化误差具有乐观偏差，因为它对留出折上的损失进行平均，而这些折比完整分布更容易预测。**\n这个陈述在两点上是错误的。首先，偏差是悲观的，而不是乐观的。其次，原因也是错误的；留出的折是随机样本，并不会系统性地比来自同一分布的任何其他数据“更容易预测”。偏差来自于在较小的数据集上进行训练。**不正确**。\n\n**E. 只有当 $K=N$（留一交叉验证）时，袋外误差和 $5$ 折交叉验证之间的偏差差异才会消失；对于 $K=5$，袋外误差总是偏差更大。**\n这个陈述是不正确的。$K$ 折 CV 的偏差是 $K$ 的函数，对于 $K=N$ (LOOCV)，偏差最小但仍然是悲观的 ($Err(N-1)  Err(N)$)。OOB 误差通常被认为是 LOOCV 的一种计算上高效的近似。然而，声称偏差差异*消失*过于绝对。更重要的是，声称对于 $K=5$，OOB 误差“总是偏差更大”与既定的理论和实践相悖。由于训练集大小减少了 $20\\%$，$5$ 折 CV 的偏差要远大于 OOB 的偏差。**不正确**。", "answer": "$$\\boxed{A}$$", "id": "4559762"}, {"introduction": "Bagging和OOB评估的原理之所以强大，在于它们能够被灵活地应用于生物信息学中常见的复杂、真实数据场景。最后的这个实践将指导你为生存模型（survival models）推导并应用一个基于OOB的性能指标——一致性指数（C-index），这一过程必须妥善处理生存分析中特有的右删失（right-censoring）数据问题。完成此练习标志着你能够将集成方法与专业领域知识相结合，以解决实际的数据分析挑战。[@problem_id:4559822]", "problem": "生物信息学和医学数据分析中的一项核心任务是评估在引导聚集（bagging）下训练的生存模型的预测一致性。考虑一个包含右删失的生存数据集，其中受试者 $i$ 的真实生存时间为 $T_i$，删失时间为 $C_i$，观测时间为 $t_i = \\min\\{T_i, C_i\\}$，事件指示符为 $\\delta_i = \\mathbf{1}\\{T_i \\leq C_i\\}$。假设在重抽样数据集上训练了一个由 $B$ 个 bootstrap 模型组成的集成模型，该集成模型仅对未包含在给定模型训练集中的受试者产生袋外（OOB）预测。我们感兴趣的预测量是来自模型 $m$ 的受试者 $i$ 的风险评分 $s_{i,m}$，其中较高的值表示较高的瞬时风险，因此对应较早的事件发生时间。\n\n从右删失的定义和一致性指数（C-index）的一致性概率解释出发，推导一个用于bagging生存模型的袋外（OOB）C-index的基于样本的估计量，该估计量(i)通过对受试者为OOB的模型进行平均来聚合每个受试者的OOB风险评分，并且(ii)仅使用右删失下的可比较对来计数一致对。然后，根据以下集成模型和数据计算其数值：\n\n- 受试者 $i \\in \\{1,2,3,4,5\\}$ 的 $(t_i, \\delta_i)$ 数据如下：\n  - 受试者 1：$(t_1, \\delta_1) = (5, 1)$\n  - 受试者 2：$(t_2, \\delta_2) = (7, 0)$\n  - 受试者 3：$(t_3, \\delta_3) = (10, 1)$\n  - 受试者 4：$(t_4, \\delta_4) = (13, 1)$\n  - 受试者 5：$(t_5, \\delta_5) = (18, 0)$\n- 四个 bootstrap 模型（$B=4$）产生以下 OOB 风险评分 $s_{i,m}$（未显示的条目为袋内数据，因此不用于 OOB 聚合）：\n  - 模型 1：$s_{1,1} = 0.85$, $s_{3,1} = 0.70$, $s_{5,1} = 0.45$\n  - 模型 2：$s_{2,2} = 0.52$, $s_{3,2} = 0.73$, $s_{4,2} = 0.56$\n  - 模型 3：$s_{1,3} = 0.80$, $s_{2,3} = 0.55$, $s_{5,3} = 0.68$\n  - 模型 4：$s_{3,4} = 0.69$, $s_{4,4} = 0.52$, $s_{5,4} = 0.65$\n\n将受试者 $i$ 的 OOB 聚合风险评分定义为在 $i$ 为 OOB 的所有模型上的算术平均值。使用标准的右删失可比较性规则：如果 $\\min\\{t_i, t_j\\}$ 对应一个观测到的事件（即，如果 $t_i  t_j$ 且 $\\delta_i = 1$，或者如果 $t_j  t_i$ 且 $\\delta_j = 1$），则一对 $(i,j)$ 是可比较的。如果观测到的事件时间较小的受试者具有较大的聚合风险评分，则该可比较对是一致的。假设观测时间或聚合风险评分中没有相同的值。将最终的 OOB C-index 以单个精确分数的形式给出。如果您选择给出小数近似值，请将答案四舍五入到四位有效数字。", "solution": "该问题要求推导一个用于bagging生存模型的袋外（OOB）一致性指数（C-index）的基于样本的估计量，然后根据给定的数据集计算其值。\n\n首先，我们建立 OOB C-index 估计量的形式化定义。假设有一组 $N$ 个受试者，索引为 $i \\in \\{1, 2, \\dots, N\\}$。对于每个受试者 $i$，我们有观测时间 $t_i$ 和事件指示符 $\\delta_i$。在 bootstrap 样本上训练了一个由 $B$ 个模型组成的集成模型。对于每个受试者 $i$，令 $M_i^{\\text{OOB}}$ 为受试者 $i$ 处于袋外样本中的模型索引 $m$ 的集合。由模型 $m \\in M_i^{\\text{OOB}}$ 预测的受试者 $i$ 的风险评分为 $s_{i,m}$。\n\n受试者 $i$ 的 OOB 聚合风险评分，记为 $\\bar{s}_i$，定义为该受试者 OOB 风险评分的算术平均值：\n$$\n\\bar{s}_i = \\frac{1}{|M_i^{\\text{OOB}}|} \\sum_{m \\in M_i^{\\text{OOB}}} s_{i,m}\n$$\nC-index 评估模型区分受试者对之间结局的能力。由于存在右删失，并非所有受试者对都是可比较的。只有当我们能够明确确定哪个受试者的生存时间更短时，一对 $(i, j)$ 才被认为是可比较的。如果观测时间较早的受试者（例如 $i$，即 $t_i  t_j$）经历了事件（$\\delta_i = 1$），这才可能。如果受试者 $i$ 被删失（$\\delta_i = 0$），其真实事件时间 $T_i$ 将是未知的，并且可能大于 $t_j$，这使得事件时间的排序不确定。\n\n因此，所有可比较对的集合 $N_{\\text{comp}}$ 定义为：\n$$\nN_{\\text{comp}} = \\left\\{ (i, j) \\mid i \\neq j, (t_i  t_j \\text{ and } \\delta_i = 1) \\text{ or } (t_j  t_i \\text{ and } \\delta_j = 1) \\right\\}\n$$\n如果模型的风险预测与观测到的结局一致，则可比较对是一致的。由于较高的风险评分 $\\bar{s}$ 表示较高的风险和较早的事件时间，因此对于 $t_i  t_j$ 的一对 $(i, j)$，如果 $\\bar{s}_i  \\bar{s}_j$，则该对是一致的。一致对的集合 $N_{\\text{conc}}$ 是 $N_{\\text{comp}}$ 的一个子集，定义为：\n$$\nN_{\\text{conc}} = \\left\\{ (i, j) \\in N_{\\text{comp}} \\mid (t_i  t_j \\text{ and } \\bar{s}_i  \\bar{s}_j) \\text{ or } (t_j  t_i \\text{ and } \\bar{s}_j  \\bar{s}_i) \\right\\}\n$$\nOOB C-index 的基于样本的估计量 $C_{\\text{OOB}}$ 是一致对的数量与可比较对的数量之比：\n$$\nC_{\\text{OOB}} = \\frac{|N_{\\text{conc}}|}{|N_{\\text{comp}}|}\n$$\n如问题所述，这假设观测时间 $t_i$ 或聚合风险评分 $\\bar{s}_i$ 中没有相同的值。\n\n现在，我们为所提供的数据计算 $C_{\\text{OOB}}$ 的值。\n\n数据集包含 5 个受试者，其生存数据如下：\n- 受试者 1：$(t_1, \\delta_1) = (5, 1)$\n- 受试者 2：$(t_2, \\delta_2) = (7, 0)$\n- 受试者 3：$(t_3, \\delta_3) = (10, 1)$\n- 受试者 4：$(t_4, \\delta_4) = (13, 1)$\n- 受试者 5：$(t_5, \\delta_5) = (18, 0)$\n\n有 $B=4$ 个模型。OOB 风险评分 $s_{i,m}$ 已给出。\n\n**第1步：计算 OOB 聚合风险评分 $\\bar{s}_i$。**\n\n- 对于受试者 1，OOB 模型为 $m \\in \\{1, 3\\}$：\n  $\\bar{s}_1 = \\frac{s_{1,1} + s_{1,3}}{2} = \\frac{0.85 + 0.80}{2} = 0.825$。\n- 对于受试者 2，OOB 模型为 $m \\in \\{2, 3\\}$：\n  $\\bar{s}_2 = \\frac{s_{2,2} + s_{2,3}}{2} = \\frac{0.52 + 0.55}{2} = 0.535$。\n- 对于受试者 3，OOB 模型为 $m \\in \\{1, 2, 4\\}$：\n  $\\bar{s}_3 = \\frac{s_{3,1} + s_{3,2} + s_{3,4}}{3} = \\frac{0.70 + 0.73 + 0.69}{3} = \\frac{2.12}{3} \\approx 0.7067$。\n- 对于受试者 4，OOB 模型为 $m \\in \\{2, 4\\}$：\n  $\\bar{s}_4 = \\frac{s_{4,2} + s_{4,4}}{2} = \\frac{0.56 + 0.52}{2} = 0.54$。\n- 对于受试者 5，OOB 模型为 $m \\in \\{1, 3, 4\\}$：\n  $\\bar{s}_5 = \\frac{s_{5,1} + s_{5,3} + s_{5,4}}{3} = \\frac{0.45 + 0.68 + 0.65}{3} = \\frac{1.78}{3} \\approx 0.5933$。\n\n**第2步：识别所有可比较对。**\n\n我们检查所有 $\\binom{5}{2} = 10$ 个唯一的受试者对。如果 $t$ 值较小的一方 $\\delta=1$，则一对 $(i, j)$ 是可比较的。\n\n- 对 (1, 2)：$t_1 = 5  t_2 = 7$ 且 $\\delta_1 = 1$。**可比较。**\n- 对 (1, 3)：$t_1 = 5  t_3 = 10$ 且 $\\delta_1 = 1$。**可比较。**\n- 对 (1, 4)：$t_1 = 5  t_4 = 13$ 且 $\\delta_1 = 1$。**可比较。**\n- 对 (1, 5)：$t_1 = 5  t_5 = 18$ 且 $\\delta_1 = 1$。**可比较。**\n- 对 (2, 3)：$t_2 = 7  t_3 = 10$ 但 $\\delta_2 = 0$。不可比较。\n- 对 (2, 4)：$t_2 = 7  t_4 = 13$ 但 $\\delta_2 = 0$。不可比较。\n- 对 (2, 5)：$t_2 = 7  t_5 = 18$ 但 $\\delta_2 = 0$。不可比较。\n- 对 (3, 4)：$t_3 = 10  t_4 = 13$ 且 $\\delta_3 = 1$。**可比较。**\n- 对 (3, 5)：$t_3 = 10  t_5 = 18$ 且 $\\delta_3 = 1$。**可比较。**\n- 对 (4, 5)：$t_4 = 13  t_5 = 18$ 且 $\\delta_4 = 1$。**可比较。**\n\n可比较对的总数为 $|N_{\\text{comp}}| = 7$。\n\n**第3步：检查可比较对之间的一致性。**\n\n如果事件时间较小的受试者具有较大的聚合风险评分，则该可比较对是一致的。为避免舍入误差，使用分数进行比较。$\\bar{s}_1=0.825$, $\\bar{s}_2=0.535$, $\\bar{s}_3 \\approx 0.7067$, $\\bar{s}_4=0.54$, $\\bar{s}_5 \\approx 0.5933$。\n\n- 对 (1, 2)：$t_1  t_2$。我们检查是否 $\\bar{s}_1 > \\bar{s}_2$。\n  $0.825 > 0.535$。**一致。**\n- 对 (1, 3)：$t_1  t_3$。我们检查是否 $\\bar{s}_1 > \\bar{s}_3$。\n  $0.825 > 0.7067$。**一致。**\n- 对 (1, 4)：$t_1  t_4$。我们检查是否 $\\bar{s}_1 > \\bar{s}_4$。\n  $0.825 > 0.54$。**一致。**\n- 对 (1, 5)：$t_1  t_5$。我们检查是否 $\\bar{s}_1 > \\bar{s}_5$。\n  $0.825 > 0.5933$。**一致。**\n- 对 (3, 4)：$t_3  t_4$。我们检查是否 $\\bar{s}_3 > \\bar{s}_4$。\n  $0.7067 > 0.54$。**一致。**\n- 对 (3, 5)：$t_3  t_5$。我们检查是否 $\\bar{s}_3 > \\bar{s}_5$。\n  $0.7067 > 0.5933$。**一致。**\n- 对 (4, 5)：$t_4  t_5$。我们检查是否 $\\bar{s}_4 > \\bar{s}_5$。\n  $0.54  0.5933$。不一致。\n\n一致对的总数为 $|N_{\\text{conc}}| = 6$。\n\n**第4步：计算 OOB C-index。**\n\n使用推导的公式：\n$$\nC_{\\text{OOB}} = \\frac{|N_{\\text{conc}}|}{|N_{\\text{comp}}|} = \\frac{6}{7}\n$$\n对于给定的数据，此 bagging 生存模型的 OOB C-index 为 $\\frac{6}{7}$。", "answer": "$$\\boxed{\\frac{6}{7}}$$", "id": "4559822"}]}