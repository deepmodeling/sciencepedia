{"hands_on_practices": [{"introduction": "任何生物标志物模型的有效性都取决于能否避免数据泄漏，这是一个在模型开发中至关重要却又极易被忽视的问题。数据泄漏会导致模型性能被严重高估，使其在真实世界应用中毫无价值。本练习 [@problem_id:4543002] 探讨了在处理复杂临床数据时，数据泄漏可能发生的几种常见但微妙的方式，例如不当地使用了未来信息或在交叉验证中污染了验证集，从而为构建一个可信赖的建模流程奠定基础性原则。", "problem": "您正在使用组学-生物标志物开发一个用于癌症进展的预后分类器。对于每位患者 $i \\in \\{1,\\dots,n\\}$，您拥有以下数据：诊断时的基线时间 $t_{0,i}$，在时间 $t_{0,i}$ 测量的基线组学向量 $X_{0,i} \\in \\mathbb{R}^p$，$t_{0,i}$ 之后开始的治疗 $T_i$，在 $t_{0,i} + \\Delta$（对于某个固定的 $\\Delta \\approx 3$ 个月）测量的早期治疗反应评分 $R_i$，最后一次联系（随访）时间 $F_i \\ge t_{0,i}$，以及一个二元标签 $Y_i \\in \\{0,1\\}$，指示是否在 $t_{0,i}$ 后的5年内发生进展（如果在 $t_{0,i}+5$ 年或之前发生事件，则编码为 $Y_i=1$，否则为 $Y_i=0$）。假设一些患者在 $C_i$ 时被右删失，其中 $C_i \\le t_{0,i}+5$ 年，但标签 $Y_i$ 是使用标准的生存时间数据处理方法一致定义的。检测是按日历天分批次进行的，产生一个由检测日期决定的批次标识符 $B_i$。您打算学习一个预测器 $f:\\mathbb{R}^p \\to [0,1]$ 来近似决策时间 $t_0$ 时的条件概率 $P(Y=1 \\mid X_{0})$。\n\n此任务的基础如下：\n- 在监督学习中，目标是仅使用决策时间 $t_0$ 可用的信息来近似贝叶斯决策规则。形式上，令 $\\mathcal{F}_{t}$ 表示由截至时间 $t$（含）所有可用测量值生成的 $\\sigma$-代数，一个在基线时有效的预测器必须是 $\\mathcal{F}_{t_0}$-可测的。在损失函数 $\\ell$下的总体风险是 $\\mathcal{R}(f) = \\mathbb{E}[\\ell(Y, f(X_0))]$，其中 $X_0$ 表示基线特征向量。\n- 仅当训练集和验证集在给定数据生成过程的条件下是条件独立的，并且验证流程在训练或预处理期间不使用验证集信息时，验证集上的估计量对于部署风险才是无偏的。特别地，数据转换的拟合必须在不接触验证折的情况下进行。\n- 如果一个特征 $X_j$ 是未来信息、结果 $Y$ 或其下游后果的函数，那么在 $t_0$ 时以 $X_j$ 为条件就违反了信息约束，并可能在性能估计中引入乐观偏差。\n\n在此生物标志物发现的场景中，您需要定义标签泄露的风险，并提供在训练和验证期间防止使用结果出现后的变量或未来信息作为特征的原则。请考虑以下候选实践。\n\n选择所有正确定义了风险并陈述了在训练和验证中防止泄露的有效原则的选项。\n\nA. 当特征集包含任何相对于 $\\mathcal{F}_{t_0}$ 不可测的变量时，就会产生标签泄露的风险，这些变量包括时间戳 $t_j > t_0$ 的变量或作为 $Y$ 的确定性或随机性函数的变量。一种有原则的预防方法是将预测器限制在 $X_0$ 上，并强制执行一个时间感知的划分，使得所有训练患者满足 $t_{0,i} \\le t_{\\mathrm{cut}}$，所有验证患者满足 $t_{0,i} > t_{\\mathrm{cut}}$，从而确保在模型拟合或验证中不使用在 $t>t_0$ 时源自未来的信息。\n\nB. 可以将 $R_i$（在 $t_{0,i}+\\Delta$ 时的早期反应）和 $T_i$ 作为特征，因为它们具有预测性；为避免泄露，可以使用带随机打乱的分层K折交叉验证（CV），因为在 $Y$ 上的分层可以控制标签不平衡，因此也能控制泄露。\n\nC. 在任何训练-验证集划分之前，在整个数据集上对每个基因进行z-score标准化，并使用关于 $Y$ 的双样本t检验对 $X_0$ 进行单变量特征选择，这是可以接受的，因为标准化是无监督的，并且t检验特征选择将在交叉验证内部重复进行；这可以提高稳定性并且不会引入泄露。\n\nD. 在K折交叉验证（CV）中，每个数据依赖的转换，包括填补、缩放、经验贝叶斯批次校正（如 ComBat）和特征选择，都必须仅使用每折中的训练集索引进行拟合，然后应用于留出的折；如果批次指示符 $B_i$ 是与 $Y$ 相关的日历时间的函数，则不应将其用作预测特征。这可以防止从验证集到训练集以及从未来信息到特征的直接和间接泄露。\n\nE. 在存在右删失的情况下，包含派生特征 $F_i - t_{0,i}$（“从基线到最后一次联系的天数”）有助于解决信息性删失问题，因此是减少泄露同时提高区分度的一种有原则的方法。\n\nF. 当每个受试者存在多个样本时（例如，技术重复或纵向抽取的样本），为防止患者级别的泄露，应在受试者级别划分数据，以使任何受试者的样本都不会同时出现在训练集和验证集中。如果测量是跨时间发生的，则强制执行 $t_{\\max}^{\\text{train}}  t_{\\min}^{\\text{test}}$ 以遵守时间顺序。这可以防止受试者泄露和无意中使用未来信息。\n\n选择所有适用的选项。您的答案应为正确选项字母的集合。", "solution": "问题陈述描述了在机器学习中进行预后生物标志物发现的一项标准任务。它要求识别防止标签泄露的正确原则和实践。问题设置详细、内部一致，并在生物统计学、生物信息学和机器学习领域具有科学依据。所提供的基本原则是统计学习理论的正确陈述。因此，该问题是有效的。\n\n在此背景下，防止标签泄露的核心原则是确保预测器 $f$ 仅是决策时间 $t_0$ 可用信息的函数。这可以通过要求预测器是 $\\mathcal{F}_{t_0}$-可测来正式陈述。此外，任何验证过程都必须对模型在新患者上的性能产生无偏估计，这要求在模型开发的所有阶段（包括预处理）严格分离训练数据和验证数据。\n\n让我们根据这些原则评估每个选项。\n\n**A. 当特征集包含任何相对于 $\\mathcal{F}_{t_0}$ 不可测的变量时，就会产生标签泄露的风险，这些变量包括时间戳 $t_j  t_0$ 的变量或作为 $Y$ 的确定性或随机性函数的变量。一种有原则的预防方法是将预测器限制在 $X_0$ 上，并强制执行一个时间感知的划分，使得所有训练患者满足 $t_{0,i} \\le t_{\\mathrm{cut}}$，所有验证患者满足 $t_{0,i}  t_{\\mathrm{cut}}$，从而确保在模型拟合或验证中不使用在 $tt_0$ 时源自未来的信息。**\n\n此选项在时间背景下为标签泄露提供了正确和正式的定义。所有信息必须相对于基线时的 $\\sigma$-代数 $\\mathcal{F}_{t_0}$ 可测，这一要求是“无未来信息”规则的精确数学表述。在 $t_0$ 之后测量的变量（例如 $R_i$）或从结果 $Y$（其本身取决于 $t_0$ 之后长达5年的事件）构建的变量不是 $\\mathcal{F}_{t_0}$-可测的，并构成泄露。\n\n提出的预防策略也是合理的。\n1.  将预测器限制为特征 $X_0$ 是正确的，因为根据定义，$X_0$ 是在 $t_{0,i}$ 测量的，因此是 $\\mathcal{F}_{t_{0}}$-可测的。\n2.  强制执行按时间顺序或时间感知的划分（例如，在截止日期 $t_{\\mathrm{cut}}$ 之前诊断的患者上进行训练，并在该日期之后诊断的患者上进行验证）是一种稳健的方法，可以防止模型学习到虚假的时间趋势。这种划分结构确保了验证过程模拟了真实世界的部署场景，即将在过去数据上训练的模型应用于未来的患者。\n\n因此，该陈述正确地定义了风险，并提出了有效且有原则的预防方法。\n\n结论：**正确**。\n\n**B. 可以将 $R_i$（在 $t_{0,i}+\\Delta$ 时的早期反应）和 $T_i$ 作为特征，因为它们具有预测性；为避免泄露，可以使用带随机打乱的分层K折交叉验证（CV），因为在 $Y$ 上的分层可以控制标签不平衡，因此也能控制泄露。**\n\n这个陈述有根本性的错误。\n1.  特征 $R_i$ 是在时间 $t_{0,i} + \\Delta$ 测量的早期治疗反应，这在决策时间 $t_0$ 之后。它不是 $\\mathcal{F}_{t_0}$-可测的。将其包含在一个旨在在基线（$t_0$）进行预后的模型中，是直接违反信息约束的行为，也是标签泄露的典型例子。虽然 $R_i$ 可能具有很高的预测性，但其值在预测时是未知的。\n2.  治疗 $T_i$ 也是一个基线后事件。包含它会将要估计的量从 $P(Y=1 \\mid X_0)$ 变为 $P(Y=1 \\mid X_0, T_i, \\dots)$。这是一个不同的、通常更容易的预测任务，但它不能回答在基线时提出的预后问题。\n3.  提议的预防方法是错误且不合逻辑的。分层K折交叉验证确保了类别比例在各折中保持一致。随机打乱使数据顺序随机化。这两种操作都无法弥补包含一个无效的、基线后特征所带来的问题。事实上，对于具有时间结构的数据，不建议进行随机打乱，因为它可能允许模型在“未来”的数据点上进行训练来预测“过去”的数据点，从而引入泄露。分层并不能“控制泄露”。\n\n结论：**不正确**。\n\n**C. 在任何训练-验证集划分之前，在整个数据集上对每个基因进行z-score标准化，并使用关于 $Y$ 的双样本t检验对 $X_0$ 进行单变量特征选择，这是可以接受的，因为标准化是无监督的，并且t检验特征选择将在交叉验证内部重复进行；这可以提高稳定性并且不会引入泄露。**\n\n该陈述描述了在预处理阶段数据泄露的两个典型例子。\n1.  **在整个数据集上进行标准化**：Z-score标准化需要计算每个特征的均值和标准差。如果这些参数是使用*整个*数据集（包括训练折和验证折）计算的，那么训练数据的转换就会受到验证数据的影响。这是一个微妙但明确的违规行为，违反了验证集必须完全被留出的原则。\n2.  **在整个数据集上进行特征选择**：在划分数据集之前，在整个数据集上使用结果标签 $Y$（例如，通过t检验）进行特征选择是一种严重的标签泄露形式。这意味着特征的选择是基于对验证集标签的了解。这导致了信息泄露，使得所选特征天生就偏向于在验证集上表现良好，从而对模型的真实性能产生欺骗性的乐观估计。\n\n所提供的理由是似是而非的。标准化是“无监督的”这一事实无关紧要；泄露来自于使用验证数据来拟合标准化器。声称t检验“将在交叉验证内部重复”是没有意义的，如果选择已经在整个数据集上完成；损害已经造成。\n\n结论：**不正确**。\n\n**D. 在K折交叉验证（CV）中，每个数据依赖的转换，包括填补、缩放、经验贝叶斯批次校正（如 ComBat）和特征选择，都必须仅使用每折中的训练集索引进行拟合，然后应用于留出的折；如果批次指示符 $B_i$ 是与 $Y$ 相关的日历时间的函数，则不应将其用作预测特征。**\n\n这个选项正确地描述了在交叉验证框架内实施预处理的黄金标准。\n1.  陈述的第一部分是获得无偏性能估计的关键原则。任何从数据中“学习”的步骤——无论是计算用于缩放的均值、用于填补的中位数、用于批次校正的参数，还是用于选择的特征排序标准——都必须*仅*在该特定折的训练部分上执行。然后将拟合好的转换应用于训练和验证部分。这种方法论被封装在像 `sklearn.pipeline.Pipeline` 这样的工具中，对于防止从验证集到训练过程的泄露至关重要。\n2.  第二部分解决了一个微妙但重要的问题。批次标识符 $B_i$ 是检测日历日期的函数。如果人群、治疗甚至生存结果随时间存在长期趋势，$B_i$ 可能会与结果 $Y$ 产生虚假的关联。包含这样的特征会导致模型学习到基于时间的伪影，而不是潜在的生物信号，从而损害其泛化能力。使用 $B_i$ 来*校正*批次效应是正确的，但将其用作预测特征是有风险的。\n\n结论：**正确**。\n\n**E. 在存在右删失的情况下，包含派生特征 $F_i - t_{0,i}$（“从基线到最后一次联系的天数”）有助于解决信息性删失问题，因此是减少泄露同时提高区分度的一种有原则的方法。**\n\n这个陈述是危险地不正确的。特征 $F_i - t_{0,i}$ 代表观察到的随访时间。结果标签 $Y_i$（5年内进展）本身是由事件时间和删失时间决定的。观察到的随访时间是 $F_i - t_{0,i} = \\min(\\text{EventTime}_i, \\text{CensoringTime}_i)$。\n对于一个经历事件的患者（即 $Y_i=1$），随访时间*就是*事件时间。将此作为特征提供给模型，就相当于在训练期间向模型提供了答案的很大一部分。例如，模型会学到一个微不足道且无用的规则：如果 $F_i - t_{0,i}  5$ 年，患者很可能有 $Y_i=1$。这是循环论证。该模型在交叉验证中会表现出惊人的高性能，但在实践中却毫无用处，因为对于一个新患者，随访时间正是我们希望预测的东西。这是一种严重的标签泄露形式，声称它“减少泄露”与事实恰恰相反。\n\n结论：**不正确**。\n\n**F. 当每个受试者存在多个样本时（例如，技术重复或纵向抽取的样本），为防止患者级别的泄露，应在受试者级别划分数据，以使任何受试者的样本都不会同时出现在训练集和验证集中。如果测量是跨时间发生的，则强制执行 $t_{\\max}^{\\text{train}}  t_{\\min}^{\\text{test}}$ 以遵守时间顺序。这可以防止受试者泄露和无意中使用未来信息。**\n\n这个选项描述了稳健验证的两个基本原则，尤其是在生物医学环境中。\n1.  **受试者级别划分**：当数据不是独立同分布（i.i.d.）时，例如当存在来自同一患者的多个样本时，简单的随机划分是无效的。来自同一患者的样本高度相关。如果它们同时出现在训练集和验证集中，模型可以“记住”患者特有的特征，导致过于乐观的性能评估。正确的程序是在患者级别进行划分（例如，使用 `GroupKFold`），确保来自给定患者的所有数据只属于一个折。\n2.  **按时间顺序划分**：正如选项A中也指出的，当数据具有时间成分时，划分必须尊重时间之箭。条件 $t_{\\max}^{\\text{train}}  t_{\\min}^{\\text{test}}$（其中 $t$ 是一个相关的时间戳，如诊断或样本日期）确保模型总是在过去的数据上训练来预测未来。这可以防止来自未来数据的泄露，并提供更现实的部署性能估计。\n\n这两个原则都是正确的，并且对于在复杂数据结构中防止泄露至关重要。\n\n结论：**正确**。\n\n总之，选项 A、D 和 F 正确地陈述了在给定情境下定义和防止数据及标签泄露的原则。", "answer": "$$\\boxed{ADF}$$", "id": "4543002"}, {"introduction": "在确保了有效的实验设计以防止数据泄漏之后，下一步便是数据预处理，其中特征缩放是关键一环。特别是在处理包含基因组、蛋白质组等来源异构的多组学数据时，不同的特征尺度会给模型训练带来巨大挑战。本练习 [@problem_id:4542989] 深入探讨了特征缩放策略的选择，通过对比不同方法（如Z-score标准化、最小-最大缩放和秩变换）对不同机器学习算法（如Lasso回归、支持向量机和随机森林）的优化过程、性能及结果可解释性的深远影响。", "problem": "一个转化肿瘤学团队正在组建一个多组学队列，该队列包含二元治疗反应、时间-事件结局和异构测量数据。该数据集包含 $n=500$ 名患者，来自基于计数的流程的 $p_{\\text{gene}}=10{,}000$ 个信使核糖核酸（mRNA）表达特征，$p_{\\text{protein}}=200$ 个蛋白质组学强度特征，以及 $p_{\\text{clinical}}=50$ 个具有混合单位（例如，毫克/分升，毫米汞柱）的临床变量。探索性分析表明，在几个mRNA特征中存在重尾分布和一小部分极端离群值，以及在每个特征内部表现出近似单调的批次效应。该团队计划拟合以下模型用于生物标志物发现和风险预测：用于反应分类的$\\ell_{1}$惩罚逻辑回归，用于分类的带径向基函数（RBF）核的支持向量机（SVM），用于非参数特征交互的随机森林，以及用于总生存期分析的$\\ell_{2}$惩罚Cox比例风险回归。\n\n在模型拟合之前，他们正在考虑三种独立应用于每个特征的特征缩放策略：(i) 标准化为零均值和单位方差（z-score标准化），(ii) 最小-最大缩放到区间 $[0,1]$，以及 (iii) 基于秩的变换为 $[0,1]$ 区间内的经验累积分布函数（eCDF）得分（并列值通过平均秩处理）。在适用的情况下，该团队将使用一阶基于梯度的求解器，并且对于不同的缩放选择，使用相同的初始化和停止准则。\n\n在此生物标志物发现场景中，关于这些缩放选择对所述模型族的优化行为和可解释性的影响，以下哪个陈述是正确的？\n\nA. 对于$\\ell_{1}$惩罚逻辑回归，对所有特征进行z-score标准化可确保惩罚项在不同异构单位上对系数的影响具有可比性，并且通常会改善数值条件；此外，对于任何固定的正则化参数，最小-最大缩放将产生与z-score标准化相同的系数路径和变量选择。\n\nB. 对于随机森林，任何单调的逐特征变换（包括最小-最大缩放和基于秩的eCDF变换）都会使候选分裂点的集合和最终的预测保持不变；然而，即使预测不变，基于基尼不纯度的特征重要性也可能在这种变换下发生改变。\n\nC. 对于带有RBF核 $k(\\boldsymbol{x},\\boldsymbol{x}')=\\exp(-\\gamma\\lVert \\boldsymbol{x}-\\boldsymbol{x}'\\rVert_{2}^{2})$ 的SVM，z-score标准化或最小-最大缩放会显著影响优化和性能，因为欧几里得距离将特征尺度与核带宽 $\\gamma$ 耦合在一起；而秩变换以非仿射方式改变点间距离，如果类别分离依赖于绝对表达差异，这可能会降低性能。\n\nD. 对于$\\ell_{2}$惩罚Cox比例风险回归，z-score标准化改善了牛顿或拟牛顿更新的条件，并且系数的解释随缩放而改变；因为Cox偏似然仅依赖于事件时间的顺序，所以用其秩替换每个协变量会使估计的回归系数保持不变。\n\nE. 在存在重尾离群值的情况下，基于秩的eCDF变换可以提高基于相关的单变量生物标志物筛选的鲁棒性；此外，对于具有凸损失的基于梯度的逻辑回归，秩变换保留了梯度的利普希茨常数，因此对于不同的缩放选择，一阶方法的步长要求保持不变。", "solution": "问题陈述已经过严格验证，被认为是具有科学依据、良构且客观的。它在生物信息学和机器学习领域呈现了一个现实的场景，并提供了足够的细节来评估所给出的论断。所有模型、数据特征和预处理技术都是该领域的标准方法。因此，我将开始解答。\n\n问题要求评估关于三种逐特征缩放策略——(i) z-score标准化，(ii) 最小-最大缩放，和 (iii) 基于秩的eCDF变换——对四种不同机器学习模型影响的五个陈述的正确性。\n\n### 对陈述 A 的分析\n**陈述：** 对于$\\ell_{1}$惩罚逻辑回归，对所有特征进行z-score标准化可确保惩罚项在不同异构单位上对系数的影响具有可比性，并且通常会改善数值条件；此外，对于任何固定的正则化参数，最小-最大缩放将产生与z-score标准化相同的系数路径和变量选择。\n\n**分析：**\n$\\ell_{1}$惩罚逻辑回归（Lasso）的目标函数形式如下：\n$$ \\arg\\min_{\\boldsymbol{\\beta}} \\left( -\\frac{1}{n} \\sum_{i=1}^{n} \\left[ y_i (\\boldsymbol{x}_i^T\\boldsymbol{\\beta}) - \\log(1 + e^{\\boldsymbol{x}_i^T\\boldsymbol{\\beta}}) \\right] + \\lambda \\sum_{j=1}^{p} |\\beta_j| \\right) $$\n惩罚项 $\\lambda \\sum_{j=1}^{p} |\\beta_j|$ 惩罚系数 $\\beta_j$ 的绝对大小。如果特征 $\\boldsymbol{x}_j$ 处于不同的尺度上，惩罚项的应用将不公平。例如，如果我们将特征 $j$ 缩放一个因子 $c$（即 $x'_j = x_j/c$），为了保持乘积 $\\beta_j x_j$ 不变，其系数必须缩放 $1/c$。新的系数变为 $\\beta'_j = c\\beta_j$，其惩罚项变为 $\\lambda|c\\beta_j|$。这意味着有效惩罚取决于特征的尺度。\n\n1.  **惩罚的可比性：** Z-score标准化将每个特征变换为均值为0，标准差为1。通过将所有特征置于相同的标准化尺度上，它确保了 $\\ell_1$ 惩罚对所有系数的应用具有可比性。这部分陈述是 **正确的**。\n2.  **数值条件：** 尺度差异巨大的特征可能导致损失函数的海森矩阵是病态的，这会减慢优化算法（一阶和二阶）的收敛速度。标准化通常会改善条件。这部分是 **正确的**。\n3.  **相同的路径：** Z-score标准化应用变换 $x'_j = (x_j - \\mu_j) / \\sigma_j$。最小-最大缩放应用变换 $x''_j = (x_j - \\min_j) / (\\max_j - \\min_j)$。这两种都是仿射变换，但它们是不同的。除非数据具有非常特殊的结构（例如，所有特征具有相同的范围和标准差），否则它们将导致特征之间不同的相对尺度。由于 $\\ell_1$ 惩罚的效果是尺度依赖的，应用这两种不同的缩放方法将导致不同的相对惩罚集，从而导致不同的正则化路径（系数作为 $\\lambda$ 的函数值）以及对于固定的 $\\lambda$ 可能有不同的变量选择。因此，声称它们会产生相同的路径和选择是 **不正确的**。\n\n因为陈述的一个关键部分是错误的，所以整个陈述是不正确的。\n\n**对A的裁定：** **不正确**。\n\n### 对陈述 B 的分析\n**陈述：** 对于随机森林，任何单调的逐特征变换（包括最小-最大缩放和基于秩的eCDF变换）都会使候选分裂点的集合和最终的预测保持不变；然而，即使预测不变，基于基尼不纯度的特征重要性也可能在这种变换下发生改变。\n\n**分析：**\n1.  **分裂和预测的不变性：** 随机森林是决策树的集成。决策树基于形如 $x_j \\le t$ 的条件进行分裂，其中 $x_j$ 是一个特征值， $t$ 是一个阈值。如果我们对特征 $x_j$ 应用一个严格单调的变换 $f$，那么条件 $x_j \\le t$ 与 $f(x_j) \\le f(t)$ 是完全等价的。特征值的顺序被保留，因此该特征对数据所有可能划分的集合也被保留。原始特征上的一个最优分裂对应于变换后特征上的一个最优分裂，它们以相同的方式划分数据。由于分裂是等价的，每棵树的结构及其预测都是不变的。因此，最终的集成预测也是不变的。这部分陈述是 **正确的**。\n2.  **基尼重要性的不变性：** 最常见的基于基尼指数的特征重要性是“平均不纯度下降”。它是通过对给定特征上的每次分裂所带来的基尼不纯度减少量求和，然后在森林中的所有树上取平均值来计算的。一个节点的基尼不纯度是 $I_G(p) = 1 - \\sum_{k=1}^{K} p_k^2$，其中 $p_k$ 是节点中第 $k$ 类样本的比例。一次分裂的不纯度下降是 $\\Delta I_G = I_{G}(\\text{parent}) - w_{\\text{left}}I_{G}(\\text{left}) - w_{\\text{right}}I_{G}(\\text{right})$。如上所述，由于单调变换导致每次分裂的数据划分完全相同，因此父节点和子节点中的比例 $p_k$ 不会改变。因此，任何给定分裂的不纯度下降都是相同的。该特征累积的总重要性也必须是相同的。声称基尼重要性会改变是 **不正确的**，因为它与陈述的第一部分相矛盾。如果预测是不变的，这意味着树结构在功能上是等价的，这意味着每次分裂的不纯度减少量必须相同。\n\n陈述的两个子句是相互矛盾的。\n\n**对B的裁定：** **不正确**。\n\n### 对陈述 C 的分析\n**陈述：** 对于带有RBF核 $k(\\boldsymbol{x},\\boldsymbol{x}')=\\exp(-\\gamma\\lVert \\boldsymbol{x}-\\boldsymbol{x}'\\rVert_{2}^{2})$ 的SVM，z-score标准化或最小-最大缩放会显著影响优化和性能，因为欧几里得距离将特征尺度与核带宽 $\\gamma$ 耦合在一起；而秩变换以非仿射方式改变点间距离，如果类别分离依赖于绝对表达差异，这可能会降低性能。\n\n**分析：**\n1.  **缩放对RBF核的影响：** RBF核的值取决于欧几里得距离的平方 $\\lVert \\boldsymbol{x}-\\boldsymbol{x}'\\rVert_{2}^{2} = \\sum_{j=1}^p (x_j - x'_j)^2$。如果特征具有非常不同的单位或范围（例如，一个特征以纳米为单位，另一个以米为单位），那么范围最大的特征将主导这个和。核函数将变得对该特征的变化敏感，而对其他特征不敏感。超参数 $\\gamma$ 作为距离的全局缩放因子，但它不能单独补偿不同特征的尺度。将特征缩放到一个共同的范围（通过z-score标准化或最小-最大缩放）对于RBF核有意义以及模型表现良好至关重要。因此，不同的缩放选择将导致不同的格拉姆矩阵、不同的优化问题和不同的性能。这部分陈述是 **正确的**。\n2.  **秩变换的影响：** 秩变换是一种非线性、非仿射的变换。它用特征值的秩（或像eCDF这样的归一化版本）来替换特征值。这个过程丢弃了关于差异大小的信息。例如，值 $\\{1, 2, 100\\}$ 被变换为秩 $\\{1, 2, 3\\}$。$2$ 和 $100$ 之间的巨大差距被缩减到与 $1$ 和 $2$ 之间的差距相同的大小。如果两个类别之间的分离依赖于这种绝对特征值上的巨大差异，那么这一关键信息将被秩变换丢失或严重削弱。SVM可能不再能够在核诱导的特征空间中找到一个好的分离超平面。这会降低性能。这部分陈述是 **正确的**。\n\n陈述的两个部分都是正确的且逻辑上一致。\n\n**对C的裁定：** **正确**。\n\n### 对陈述 D 的分析\n**陈述：** 对于$\\ell_{2}$惩罚Cox比例风险回归，z-score标准化改善了牛顿或拟牛顿更新的条件，并且系数的解释随缩放而改变；因为Cox偏似然仅依赖于事件时间的顺序，所以用其秩替换每个协变量会使估计的回归系数保持不变。\n\n**分析：**\n1.  **Z-score标准化的影响：** Cox模型通常使用牛顿-拉夫森方法进行优化，该方法涉及偏对数似然的海森矩阵。与逻辑回归一样，如果协变量的尺度差异很大，这可能导致一个病态的海森矩阵和缓慢的收敛。Z-score标准化可以缓解这个问题。Cox模型中的系数 $\\beta_j$ 关系到 $x_j$ 变化一个单位时的风险比 $\\exp(\\beta_j)$。如果 $x_j$ 被缩放，“一个单位的变化”的含义就变了，因此系数 $\\beta_j$ 及其解释也必须改变。这部分陈述是 **正确的**。\n2.  **秩变换的影响：** 在时间 $t_{(i)}$ 发生事件的Cox偏似然由 $L_i(\\boldsymbol{\\beta}) = \\frac{\\exp(\\boldsymbol{x}_i^T \\boldsymbol{\\beta})}{\\sum_{j \\in R(t_{(i)})} \\exp(\\boldsymbol{x}_j^T \\boldsymbol{\\beta})}$ 给出，其中 $R(t_{(i)})$ 是在时间 $t_{(i)}$ 处于风险中的个体集合。似然函数依赖于线性预测子 $\\boldsymbol{x}_j^T \\boldsymbol{\\beta}$，而线性预测子是协变量 $\\boldsymbol{x}_j$ 实际数值的函数。虽然模型的结构依赖于*事件时间*的顺序来形成风险集，但它对于协变量是完全参数化的。用协变量的秩替换协变量 $\\boldsymbol{x}_j$ 是一种非线性变换，它将改变偏似然函数的值。最大化这个新的似然函数将产生不同的系数估计 $\\hat{\\boldsymbol{\\beta}}$。声称不变性是对协变量如何进入Cox模型的一种根本性误解。这部分是 **不正确的**。\n\n第二个论断有严重缺陷。\n\n**对D的裁定：** **不正确**。\n\n### 对陈述 E 的分析\n**陈述：** 在存在重尾离群值的情况下，基于秩的eCDF变换可以提高基于相关的单变量生物标志物筛选的鲁棒性；此外，对于具有凸损失的基于梯度的逻辑回归，秩变换保留了梯度的利普希茨常数，因此对于不同的缩放选择，一阶方法的步长要求保持不变。\n\n**分析：**\n1.  **基于秩的相关性的鲁棒性：** 标准的皮尔逊相关性对离群值高度敏感，因为它基于数据的一阶矩和二阶矩。基于秩的变换将数据转换为秩，有效地减轻了极端值的影响。在秩数据上计算的相关系数是斯皮尔曼秩相关，它是一种衡量单调关联的鲁棒度量。因此，在相关性筛选前使用基于秩的变换可以提高对离群值的鲁棒性。这部分陈述是 **正确的**。\n2.  **利普希茨常数的保持：** 对于单个数据点 $(\\boldsymbol{x}_i, y_i)$，逻辑损失函数的梯度是 $\\nabla L_i = \\sigma(y_i \\boldsymbol{x}_i^T \\boldsymbol{\\beta}) (-y_i \\boldsymbol{x}_i)$，其中 $\\sigma(\\cdot)$ 是 sigmoid 函数。海森矩阵是 $\\nabla^2 L_i = \\sigma'(\\dots) \\boldsymbol{x}_i \\boldsymbol{x}_i^T$。总损失的梯度的利普希茨常数与这些海森矩阵之和的最大特征值有关，其上界由一个与 $\\max_i \\lVert \\boldsymbol{x}_i \\rVert_2^2$ 成比例的项所限定。梯度下降中的步长通常选择为与利普希茨常数成反比。秩变换从根本上改变了特征值，通常将它们压缩到 $[0, 1]$ 的范围内。这将改变数据向量的范数 $\\lVert \\boldsymbol{x}_i \\rVert_2$，特别是对于包含离群值的点。因此，梯度的利普希茨常数将会改变（通常会减小，而且常常是大幅减小），最优步长的要求也会改变。声称利普希茨常数被保留是 **不正确的**。\n\n第二个论断是错误的。\n\n**对E的裁定：** **不正确**。\n\n### 裁定总结\n- A：不正确\n- B：不正确\n- C：正确\n- D：不正确\n- E：不正确\n\n唯一正确的陈述是 C。", "answer": "$$\\boxed{C}$$", "id": "4542989"}, {"introduction": "生物标志物发现中的一个普遍挑战是疾病的低患病率，这导致了严重的类别不平衡问题。在这种情况下，诸如准确率等标准评估指标可能会产生误导，无法反映模型的真实临床效用。本练习 [@problem_id:4542969] 通过一个具体的计算案例，清晰地揭示了这一问题，并对比了受试者工作特征（ROC）曲线和精确率-召回率（PR）曲线。您将通过动手计算理解为什么在罕见病场景下，PR曲线通常能更准确地衡量模型的实际应用价值。", "problem": "您正在开发一个二元分类器，用于从高维组学数据中检测一种罕见病的生物标志物。每个样本被赋予一个连续分数 $S \\in \\mathbb{R}$，分数越高表示患病可能性越大。令 $Y \\in \\{0,1\\}$ 表示真实类别，其中 $Y=1$ 表示患病（病例），$Y=0$ 表示未患病（对照）。令疾病患病率为 $\\pi = \\mathbb{P}(Y=1)$，则 $1-\\pi=\\mathbb{P}(Y=0)$。对于任何决策阈值 $\\tau \\in \\mathbb{R}$，如果一个样本的得分 $S \\ge \\tau$，则预测为阳性，否则预测为阴性。仅使用条件概率、混淆矩阵中的各种比率、贝叶斯法则和全概率定律的基本定义。\n\n在一个工作阈值 $\\tau^{\\star}$ 下，假设两个不同的模型产生相同的一对条件错误率：真阳性率 $\\operatorname{TPR}(\\tau^{\\star})=\\mathbb{P}(S \\ge \\tau^{\\star}\\mid Y=1)=0.9$ 和假阳性率 $\\operatorname{FPR}(\\tau^{\\star})=\\mathbb{P}(S \\ge \\tau^{\\star}\\mid Y=0)=0.1$。假设患病率 $\\pi=0.01$。\n\n选择所有正确的陈述。\n\nA. 受试者工作特征（ROC）曲线是点集 $\\{(\\operatorname{FPR}(\\tau),\\operatorname{TPR}(\\tau)):\\tau \\in \\mathbb{R}\\}$，并且由于其两个坐标都是以 $Y$ 为条件的，因此它不依赖于患病率 $\\pi$。\n\nB. 精确率-召回率（PR）曲线是点集 $\\{(\\operatorname{Recall}(\\tau),\\operatorname{Precision}(\\tau)):\\tau \\in \\mathbb{R}\\}$，其中 $\\operatorname{Recall}(\\tau)=\\operatorname{TPR}(\\tau)$ 且 $\\operatorname{Precision}(\\tau)=\\mathbb{P}(Y=1 \\mid S \\ge \\tau)$，因此精确率同时依赖于 $\\operatorname{TPR}(\\tau)$、$\\operatorname{FPR}(\\tau)$ 和患病率 $\\pi$。\n\nC. 在 $\\pi \\ll 1$ 的罕见病场景中，共享相同ROC曲线的两个分类器在给定的工作点上可能表现出截然不同的实际效用，因为当 $(1-\\pi) \\gg \\pi$ 时，$\\operatorname{Precision}(\\tau)$ 可能很小；因此，PR曲线在量化检测出的阳性样本的预期纯度方面更具信息量。\n\nD. 由于ROC曲线的坐标轴包含了患病率 $\\pi$，因此在严重类别不平衡的情况下，它在罕见病生物标志物发现中通常优于PR曲线。\n\nE. 在指定的工作点，当 $\\operatorname{TPR}(\\tau^{\\star})=0.9$，$\\operatorname{FPR}(\\tau^{\\star})=0.1$，且 $\\pi=0.01$ 时，精确率约等于 $0.083$，这表明即使在灵敏度很高的情况下，类别不平衡也会导致在标记的样本中出现大量假阳性。\n\nF. 如果类别先验概率 $\\pi$ 在训练和部署之间发生变化，而条件分数分布 $\\{S \\mid Y=1\\}$ 和 $\\{S \\mid Y=0\\}$ 保持不变，那么ROC曲线会移动，但PR曲线保持不变。", "solution": "### 步骤1：提取给定信息\n\n问题陈述提供了以下定义、条件和数据：\n-   一个二元分类器为每个样本分配一个连续分数 $S \\in \\mathbb{R}$。\n-   真实类别为 $Y \\in \\{0,1\\}$，其中 $Y=1$ 是病例（患病），$Y=0$ 是对照（未患病）。\n-   患病率（疾病的先验概率）为 $\\pi = \\mathbb{P}(Y=1) = 0.01$。\n-   未患病的先验概率为 $1-\\pi = \\mathbb{P}(Y=0) = 0.99$。\n-   如果样本的分数 $S$ 大于或等于阈值 $\\tau$，即 $S \\ge \\tau$，则预测为阳性。\n-   在一个特定阈值 $\\tau^{\\star}$ 下，两个模型具有以下条件错误率：\n    -   真阳性率：$\\operatorname{TPR}(\\tau^{\\star}) = \\mathbb{P}(S \\ge \\tau^{\\star} \\mid Y=1) = 0.9$。\n    -   假阳性率：$\\operatorname{FPR}(\\tau^{\\star}) = \\mathbb{P}(S \\ge \\tau^{\\star} \\mid Y=0) = 0.1$。\n-   ROC和PR曲线的定义在选项A和B中给出。具体来说：\n    -   受试者工作特征（ROC）曲线：$\\{(\\operatorname{FPR}(\\tau),\\operatorname{TPR}(\\tau)):\\tau \\in \\mathbb{R}\\}$。\n    -   精确率-召回率（PR）曲线：$\\{(\\operatorname{Recall}(\\tau),\\operatorname{Precision}(\\tau)):\\tau \\in \\mathbb{R}\\}$。\n    -   $\\operatorname{Recall}(\\tau)=\\operatorname{TPR}(\\tau)$。\n    -   $\\operatorname{Precision}(\\tau)=\\mathbb{P}(Y=1 \\mid S \\ge \\tau)$。\n\n### 步骤2：使用提取的给定信息进行验证\n\n问题陈述是使用统计指标评估二元分类器的一个标准练习。\n-   **科学依据**：该问题基于概率论、统计学和机器学习的基本原理。TPR、FPR、精确率、召回率、ROC曲线、PR曲线和患病率等概念在生物医学信息学和机器学习中都是标准且明确定义的。\n-   **适定性**：该问题是适定的。它提供了评估给定陈述所需的所有必要定义和数据。所提问题基于所提供的信息和标准数学推导，具有唯一的、可验证的答案。\n-   **客观性**：语言精确且客观。所有术语都通过领域内的明确定义或通用惯例进行了形式化定义。没有主观或基于意见的主张。\n\n该问题没有表现出任何无效性缺陷：\n1.  **科学或事实不健全**：没有违反数学或统计学原理。\n2.  **不可形式化或不相关**：该问题与使用机器学习进行生物标志物发现直接相关，并且是完全可以形式化的。\n3.  **不完整或矛盾的设置**：设置是完整且一致的。\n4.  **不切实际或不可行**：该场景是罕见病分类问题的现实表示。\n5.  **不适定或结构不良**：该问题结构良好，并能得出唯一的答案。\n6.  **伪深刻、琐碎或同义反复**：该问题需要对类别不平衡下分类指标的属性进行实质性推理。\n7.  **超出科学可验证范围**：所有主张都可以通过数学推导进行验证。\n\n### 步骤3：结论和行动\n\n问题陈述是**有效的**。现在将通过评估每个选项来推导解决方案。\n\n---\n\n### 选项分析\n\n**A. 受试者工作特征（ROC）曲线是点集 $\\{(\\operatorname{FPR}(\\tau),\\operatorname{TPR}(\\tau)):\\tau \\in \\mathbb{R}\\}$，并且由于其两个坐标都是以 $Y$ 为条件的，因此它不依赖于患病率 $\\pi$。**\n\nROC曲线由所有可能阈值 $\\tau$ 的点对 $(\\operatorname{FPR}(\\tau), \\operatorname{TPR}(\\tau))$ 的集合定义。\n真阳性率是 $\\operatorname{TPR}(\\tau) = \\mathbb{P}(S \\ge \\tau \\mid Y=1)$。这是在样本为真阳性的条件下，预测为阳性的概率。这个概率只依赖于阳性类别（$Y=1$）的分数 $S$ 的分布。\n假阳性率是 $\\operatorname{FPR}(\\tau) = \\mathbb{P}(S \\ge \\tau \\mid Y=0)$。这是在样本为真阴性的条件下，预测为阳性的概率。这个概率只依赖于阴性类别（$Y=0$）的分数 $S$ 的分布。\n由于 $\\operatorname{TPR}(\\tau)$ 和 $\\operatorname{FPR}(\\tau)$ 都被定义为以真实类别 $Y$ 为条件的概率，所以它们独立于类别分布，即患病率 $\\pi = \\mathbb{P}(Y=1)$。因此，构成ROC曲线的点集独立于患病率。\n\n该陈述是**正确的**。\n\n**B. 精确率-召回率（PR）曲线是点集 $\\{(\\operatorname{Recall}(\\tau),\\operatorname{Precision}(\\tau)):\\tau \\in \\mathbb{R}\\}$，其中 $\\operatorname{Recall}(\\tau)=\\operatorname{TPR}(\\tau)$ 且 $\\operatorname{Precision}(\\tau)=\\mathbb{P}(Y=1 \\mid S \\ge \\tau)$，因此精确率同时依赖于 $\\operatorname{TPR}(\\tau)$、$\\operatorname{FPR}(\\tau)$ 和患病率 $\\pi$。**\n\nPR曲线由所有可能阈值 $\\tau$ 的点对 $(\\operatorname{Recall}(\\tau), \\operatorname{Precision}(\\tau))$ 的集合定义。\n召回率定义为 $\\operatorname{Recall}(\\tau) = \\operatorname{TPR}(\\tau) = \\mathbb{P}(S \\ge \\tau \\mid Y=1)$。正如在A中确定的，这与患病率无关。\n精确率定义为 $\\operatorname{Precision}(\\tau) = \\mathbb{P}(Y=1 \\mid S \\ge \\tau)$。这是在样本被预测为阳性的条件下，它确实是阳性的概率。要看它的依赖关系，我们应用贝叶斯法则：\n$$ \\operatorname{Precision}(\\tau) = \\mathbb{P}(Y=1 \\mid S \\ge \\tau) = \\frac{\\mathbb{P}(S \\ge \\tau \\mid Y=1) \\mathbb{P}(Y=1)}{\\mathbb{P}(S \\ge \\tau)} $$\n分母 $\\mathbb{P}(S \\ge \\tau)$ 可以使用全概率定律展开：\n$$ \\mathbb{P}(S \\ge \\tau) = \\mathbb{P}(S \\ge \\tau \\mid Y=1) \\mathbb{P}(Y=1) + \\mathbb{P}(S \\ge \\tau \\mid Y=0) \\mathbb{P}(Y=0) $$\n代入 $\\operatorname{TPR}$、$\\operatorname{FPR}$ 和 $\\pi$ 的定义：\n$$ \\mathbb{P}(S \\ge \\tau) = \\operatorname{TPR}(\\tau) \\cdot \\pi + \\operatorname{FPR}(\\tau) \\cdot (1-\\pi) $$\n现在，将此代回精确率的表达式中：\n$$ \\operatorname{Precision}(\\tau) = \\frac{\\operatorname{TPR}(\\tau) \\cdot \\pi}{\\operatorname{TPR}(\\tau) \\cdot \\pi + \\operatorname{FPR}(\\tau) \\cdot (1-\\pi)} $$\n这个方程明确显示 $\\operatorname{Precision}(\\tau)$ 是 $\\operatorname{TPR}(\\tau)$、$\\operatorname{FPR}(\\tau)$ 和患病率 $\\pi$ 的函数。由于PR曲线的y轴（精确率）依赖于 $\\pi$，所以整个PR曲线都依赖于 $\\pi$。\n\n该陈述是**正确的**。\n\n**C. 在 $\\pi \\ll 1$ 的罕见病场景中，共享相同ROC曲线的两个分类器在给定的工作点上可能表现出截然不同的实际效用，因为当 $(1-\\pi) \\gg \\pi$ 时，$\\operatorname{Precision}(\\tau)$ 可能很小；因此，PR曲线在量化检测出的阳性样本的预期纯度方面更具信息量。**\n\n如果两个分类器共享相同的ROC曲线，这意味着对于任何给定的 $\\operatorname{FPR}$，它们能达到相同的 $\\operatorname{TPR}$。然而，它们的实际效用，尤其是在临床环境中，通常取决于检测后患病概率，即精确率。\n如B所示，精确率强烈依赖于患病率 $\\pi$。在罕见病场景中，$\\pi$ 非常小（例如 $\\pi=0.01$），所以 $(1-\\pi)$ 接近于1。精确率的公式是：\n$$ \\operatorname{Precision}(\\tau) = \\frac{\\operatorname{TPR}(\\tau) \\cdot \\pi}{\\operatorname{TPR}(\\tau) \\cdot \\pi + \\operatorname{FPR}(\\tau) \\cdot (1-\\pi)} $$\n如果 $\\pi \\ll 1$，那么即使 $\\operatorname{FPR}(\\tau)$ 很小，分母中的 $\\operatorname{FPR}(\\tau) \\cdot (1-\\pi)$ 项也可能占主导地位。例如，如果 $\\operatorname{TPR}(\\tau)$ 很高（如0.9），但 $\\operatorname{FPR}(\\tau)$ 不可忽略（如0.1），且 $\\pi=0.01$：$\\operatorname{Precision}(\\tau) \\approx \\frac{\\operatorname{TPR}(\\tau) \\cdot \\pi}{\\operatorname{FPR}(\\tau)}$。由于 $\\pi$ 很小，精确率可能很低。这意味着大部分阳性预测都是假阳性。PR曲线绘制了精确率，可以直接可视化这种效应。而ROC曲线对 $\\pi$ 不敏感，不会揭示这种低的阳性预测值。因此，在评估像罕见病检测这样的不平衡场景中的性能时，阳性预测的“纯度”至关重要，PR曲线通常更具信息量。\n\n该陈述是**正确的**。\n\n**D. 由于ROC曲线的坐标轴包含了患病率 $\\pi$，因此在严重类别不平衡的情况下，它在罕见病生物标志物发现中通常优于PR曲线。**\n\n该陈述声称ROC曲线“在其坐标轴中包含了患病率 $\\pi$”。正如在选项A的分析中确定的，ROC曲线的坐标轴是 $\\operatorname{TPR}(\\tau) = \\mathbb{P}(S \\ge \\tau \\mid Y=1)$ 和 $\\operatorname{FPR}(\\tau) = \\mathbb{P}(S \\ge \\tau \\mid Y=0)$。两者都是以真实类别为条件的概率，独立于患病率 $\\pi$。该陈述的前提在事实上是错误的。因此，从这个错误前提得出的结论是站不住脚的。实际上，人们通常持相反的观点：正因为ROC曲线*不*依赖于患病率，它在严重类别不平衡的情况下可能会产生误导性的乐观结果，因此PR曲线通常更受青睐。\n\n该陈述是**不正确的**。\n\n**E. 在指定的工作点，当 $\\operatorname{TPR}(\\tau^{\\star})=0.9$，$\\operatorname{FPR}(\\tau^{\\star})=0.1$，且 $\\pi=0.01$ 时，精确率约等于 $0.083$，这表明即使在灵敏度很高的情况下，类别不平衡也会导致在标记的样本中出现大量假阳性。**\n\n给定 $\\operatorname{TPR}(\\tau^{\\star})=0.9$，$\\operatorname{FPR}(\\tau^{\\star})=0.1$，以及 $\\pi=0.01$。我们使用在B中推导的精确率公式：\n$$ \\operatorname{Precision}(\\tau^{\\star}) = \\frac{\\operatorname{TPR}(\\tau^{\\star}) \\cdot \\pi}{\\operatorname{TPR}(\\tau^{\\star}) \\cdot \\pi + \\operatorname{FPR}(\\tau^{\\star}) \\cdot (1-\\pi)} $$\n代入给定值：\n$$ \\operatorname{Precision}(\\tau^{\\star}) = \\frac{0.9 \\times 0.01}{0.9 \\times 0.01 + 0.1 \\times (1-0.01)} $$\n$$ \\operatorname{Precision}(\\tau^{\\star}) = \\frac{0.009}{0.009 + 0.1 \\times 0.99} $$\n$$ \\operatorname{Precision}(\\tau^{\\star}) = \\frac{0.009}{0.009 + 0.099} $$\n$$ \\operatorname{Precision}(\\tau^{\\star}) = \\frac{0.009}{0.108} = \\frac{9}{108} = \\frac{1}{12} $$\n计算小数值：$1/12 = 0.08333...$。因此，精确率约等于 $0.083$。\n灵敏度与TPR相同，为 $0.9$。这是一个很高的值。而精确率为 $0.083$ 意味着在被预测为阳性的样本中，只有 $8.3\\%$ 是真正的阳性。剩下的 $91.7\\%$ 是假阳性。这个结果确实表明，严重的类别不平衡（$\\pi=0.01$）即使在灵敏度很高的情况下，也可能导致非常低的精确率（即预测为阳性的样本中有大量的假阳性）。\n\n该陈述是**正确的**。\n\n**F. 如果类别先验概率 $\\pi$ 在训练和部署之间发生变化，而条件分数分布 $\\{S \\mid Y=1\\}$ 和 $\\{S \\mid Y=0\\}$ 保持不变，那么ROC曲线会移动，但PR曲线保持不变。**\n\n该陈述假设每个类别的分数 $S$ 的条件分布 $p(s|Y=1)$ 和 $p(s|Y=0)$ 保持不变。\nROC曲线由 $\\operatorname{TPR}(\\tau) = \\int_{\\tau}^{\\infty} p(s|Y=1) ds$ 和 $\\operatorname{FPR}(\\tau) = \\int_{\\tau}^{\\infty} p(s|Y=0) ds$ 决定。由于这些条件分布不变，$\\tau$ 的函数 TPR 和 FPR 也保持不变。因此，作为 $(\\operatorname{FPR}(\\tau), \\operatorname{TPR}(\\tau))$ 的曲线图，ROC曲线也**保持不变**。\nPR曲线由 $(\\operatorname{Recall}(\\tau), \\operatorname{Precision}(\\tau))$ 决定。$\\operatorname{Recall}(\\tau) = \\operatorname{TPR}(\\tau)$ 保持不变。然而，我们已经证明 $\\operatorname{Precision}(\\tau)$ 依赖于 $\\pi$：\n$$ \\operatorname{Precision}(\\tau) = \\frac{\\operatorname{TPR}(\\tau) \\cdot \\pi}{\\operatorname{TPR}(\\tau) \\cdot \\pi + \\operatorname{FPR}(\\tau) \\cdot (1-\\pi)} $$\n如果患病率 $\\pi$ 改变，对于任何给定的 $\\tau$（因此对于任何给定的召回率），$\\operatorname{Precision}(\\tau)$ 的值都会改变。因此，PR曲线将会**移动**。\n该陈述断言ROC曲线会移动而PR曲线保持不变。这与正确的情况完全相反。\n\n该陈述是**不正确的**。", "answer": "$$\\boxed{ABCE}$$", "id": "4542969"}]}