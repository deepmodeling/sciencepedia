{"hands_on_practices": [{"introduction": "在医学图像分析中，训练深度学习模型（尤其是三维模型）常常受到图形处理器（GPU）内存的限制。深刻理解模型架构（如深度、宽度）、激活值和优化器状态如何共同影响内存占用，对于成功训练模型至关重要。这项练习将引导你为三维U-Net模型进行内存消耗估算，并探索在有限硬件条件下训练大型模型的策略，这对任何深度学习实践者来说都是一项关键技能 [@problem_id:4554578]。", "problem": "考虑一个用于体积医学图像分割的三维（3D）U-Net 架构，该架构在总内存容量为 $12$ GB（$1 \\, \\mathrm{GB} = 10^{9} \\, \\mathrm{bytes}$）的图形处理单元（GPU）上进行训练。输入块的空间维度为 $(128, 128, 128)$ 体素，并有一个单一的输入成像模态通道。该 U-Net 使用以下结构假设：\n- 编码器由 $4$ 个分辨率级别和一个瓶颈层组成，每个编码器级别都有两个 $3 \\times 3 \\times 3$ 的“相同”填充卷积，并且在每次下采样时通道数加倍：在空间大小为 $128^3$ 的分辨率级别，基础通道数为 $32$；在 $64^3$ 时为 $64$；在 $32^3$ 时为 $128$；在 $16^3$ 时为 $256$；瓶颈层在 $8^3$ 时为 $512$。\n- 下采样通过 $2 \\times 2 \\times 2$ 最大池化完成。\n- 解码器与编码器镜像对称：每个解码阶段首先使用 $2 \\times 2 \\times 2$ 转置卷积（步幅为 $2$）进行上采样，以匹配下一个更高的空间分辨率，然后与相应的编码器特征图拼接，并应用两个 $3 \\times 3 \\times 3$ 卷积。拼接后，两个卷积输出该解码器阶段的通道数（$16^3$ 时为 $256$，$32^3$ 时为 $128$，$64^3$ 时为 $64$，$128^3$ 时为 $32$）。\n- 最终输出层是一个 $1 \\times 1 \\times 1$ 卷积，将 $128^3$ 处的 $32$ 个通道映射到 $K = 3$ 个分割类别。\n\n假设使用自适应矩估计（Adam）优化器以单精度（float32）进行训练。对于内存计算：\n- 每个 float32 张量元素占用 $4$ 字节。\n- 在训练期间，每个参数化层（所有卷积和转置卷积）的输出激活都会被保留以用于反向传播。忽略为池化、拼接和任何非参数化操作保留的内存。\n- 计算参数张量、它们的梯度以及 Adam 的一阶和二阶矩缓冲，所有这些都使用 float32 格式并驻留在 GPU 上，因此每个参数的内存为 $16$ 字节。\n- 为运行时保留了 $1 \\, \\mathrm{GB}$ 的固定非模型开销，$12 \\, \\mathrm{GB}$ 预算的其余部分用于模型参数、优化器状态和保留的激活。\n\n设批次大小为 $B$。仅使用上述假设和卷积参数计数及激活大小的标准定义，推导出总保留激活内存作为 $B$ 的函数，以及参数加优化器的总内存，并确定可在可用 GPU 内存预算内使用的最大整数批次大小 $B$。\n\n此外，论证至少两种减少内存消耗的原则性策略（例如，梯度检查点或混合精度），并为每种策略明确说明它如何渐近地修改本问题中推导出的激活内存项。\n\n将你的最终答案表示为可容纳的最大整数 $B$，无需单位，也无需舍入说明。", "solution": "该问题被评估为有效。它在科学上基于深度学习和计算机体系结构的原理，问题设定明确，信息充分且一致，并以客观、正式的语言阐述。所提供的参数描述了训练一个用于医学图像分割的 3D U-Net 的现实场景。因此，我们可以进行形式化解答。\n\n可用于模型及其训练相关状态的总内存是总 GPU 内存减去固定开销。设 $M_{GPU} = 12 \\, \\mathrm{GB} = 12 \\times 10^9 \\, \\mathrm{bytes}$，开销为 $M_{OH} = 1 \\, \\mathrm{GB} = 1 \\times 10^9 \\, \\mathrm{bytes}$。\n可用内存为 $M_{avail} = M_{GPU} - M_{OH} = 11 \\times 10^9 \\, \\mathrm{bytes}$。\n训练期间的总内存消耗包括两个主要部分：\n$1$. 模型参数和优化器状态的内存，这与批次大小无关。设其为 $M_{P}$。\n$2$. 保留的层激活的内存，它与批次大小 $B$ 呈线性关系。设其为 $M_{A}(B)$。\n\n约束条件是 $M_{P} + M_{A}(B) \\le M_{avail}$。\n\n我们将首先计算 $M_{P}$，然后推导 $M_{A}(B)$ 的表达式，最后求解最大整数 $B$。\n\n**1. 参数和优化器内存的计算 ($M_{P}$)**\n\n每个参数的内存成本给定为 $16$ 字节，包括参数本身（float32，4 字节）、其梯度（float32，4 字节）以及 Adam 优化器的一阶和二阶矩估计（$2 \\times 4 = 8$ 字节）。\n对于一个卷积核大小为 $k \\times k \\times k$、输入通道为 $C_{in}$、输出通道为 $C_{out}$ 的卷积层，包括每个输出通道的一个偏置项，其参数数量由 $N_{params} = (k^3 \\cdot C_{in} + 1) \\cdot C_{out}$ 给出。对于转置卷积，公式相同。我们计算每一层的参数。\n\n编码器路径：\n- 级别 1 ($128^3$)：两个 $3 \\times 3 \\times 3$ 卷积。\n  - 卷积 1: $C_{in}=1$, $C_{out}=32$。$N_1 = (3^3 \\cdot 1 + 1) \\cdot 32 = 896$。\n  - 卷积 2: $C_{in}=32$, $C_{out}=32$。$N_2 = (3^3 \\cdot 32 + 1) \\cdot 32 = 27,680$。\n- 级别 2 ($64^3$)：两个 $3 \\times 3 \\times 3$ 卷积。\n  - 卷积 1: $C_{in}=32$, $C_{out}=64$。$N_3 = (3^3 \\cdot 32 + 1) \\cdot 64 = 55,360$。\n  - 卷积 2: $C_{in}=64$, $C_{out}=64$。$N_4 = (3^3 \\cdot 64 + 1) \\cdot 64 = 110,656$。\n- 级别 3 ($32^3$)：两个 $3 \\times 3 \\times 3$ 卷积。\n  - 卷积 1: $C_{in}=64$, $C_{out}=128$。$N_5 = (3^3 \\cdot 64 + 1) \\cdot 128 = 221,312$。\n  - 卷积 2: $C_{in}=128$, $C_{out}=128$。$N_6 = (3^3 \\cdot 128 + 1) \\cdot 128 = 442,496$。\n- 级别 4 ($16^3$)：两个 $3 \\times 3 \\times 3$ 卷积。\n  - 卷积 1: $C_{in}=128$, $C_{out}=256$。$N_7 = (3^3 \\cdot 128 + 1) \\cdot 256 = 884,992$。\n  - 卷积 2: $C_{in}=256$, $C_{out}=256$。$N_8 = (3^3 \\cdot 256 + 1) \\cdot 256 = 1,769,728$。\n- 瓶颈层 ($8^3$)：两个 $3 \\times 3 \\times 3$ 卷积。\n  - 卷积 1: $C_{in}=256$, $C_{out}=512$。$N_9 = (3^3 \\cdot 256 + 1) \\cdot 512 = 3,539,456$。\n  - 卷积 2: $C_{in}=512$, $C_{out}=512$。$N_{10} = (3^3 \\cdot 512 + 1) \\cdot 512 = 7,078,400$。\n\n解码器路径：\n- 级别 1 ($16^3$)：一个转置卷积，两个常规卷积。\n  - 转置卷积：$C_{in}=512$, $C_{out}=256$（标准 U-Net 实践是通道减半），卷积核 $2^3$。$N_{11} = (2^3 \\cdot 512 + 1) \\cdot 256 = 1,048,832$。\n  - 卷积 1：输入是上采样图（$256$ 通道）和编码器图（$256$ 通道）的拼接，所以 $C_{in}=512$。$C_{out}=256$。$N_{12} = (3^3 \\cdot 512 + 1) \\cdot 256 = 3,539,200$。\n  - 卷积 2: $C_{in}=256$, $C_{out}=256$。$N_{13} = (3^3 \\cdot 256 + 1) \\cdot 256 = 1,769,728$。\n- 级别 2 ($32^3$)：\n  - 转置卷积：$C_{in}=256$, $C_{out}=128$。$N_{14} = (2^3 \\cdot 256 + 1) \\cdot 128 = 262,272$。\n  - 卷积 1: $C_{in}=128+128=256$, $C_{out}=128$。$N_{15} = (3^3 \\cdot 256 + 1) \\cdot 128 = 884,864$。\n  - 卷积 2: $C_{in}=128$, $C_{out}=128$。$N_{16} = (3^3 \\cdot 128 + 1) \\cdot 128 = 442,496$。\n- 级别 3 ($64^3$)：\n  - 转置卷积：$C_{in}=128$, $C_{out}=64$。$N_{17} = (2^3 \\cdot 128 + 1) \\cdot 64 = 65,600$。\n  - 卷积 1: $C_{in}=64+64=128$, $C_{out}=64$。$N_{18} = (3^3 \\cdot 128 + 1) \\cdot 64 = 221,248$。\n  - 卷积 2: $C_{in}=64$, $C_{out}=64$。$N_{19} = (3^3 \\cdot 64 + 1) \\cdot 64 = 110,656$。\n- 级别 4 ($128^3$)：\n  - 转置卷积：$C_{in}=64$, $C_{out}=32$。$N_{20} = (2^3 \\cdot 64 + 1) \\cdot 32 = 16,416$。\n  - 卷积 1: $C_{in}=32+32=64$, $C_{out}=32$。$N_{21} = (3^3 \\cdot 64 + 1) \\cdot 32 = 55,328$。\n  - 卷积 2: $C_{in}=32$, $C_{out}=32$。$N_{22} = (3^3 \\cdot 32 + 1) \\cdot 32 = 27,680$。\n\n最终层：\n- $1 \\times 1 \\times 1$ 卷积：$C_{in}=32$, $C_{out}=3$。$N_{23} = (1^3 \\cdot 32 + 1) \\cdot 3 = 99$。\n\n总参数 $N_{P} = \\sum_{i=1}^{23} N_i = 22,575,299$。\n参数和优化器状态的总内存为：\n$M_{P} = N_{P} \\times 16 \\, \\mathrm{bytes/param} = 22,575,299 \\times 16 = 361,204,784 \\, \\mathrm{bytes}$。\n\n**2. 激活内存的计算 ($M_{A}(B)$)**\n\n激活内存是所有参数化层输出张量的内存总和。每个 float32 元素占用 $4$ 字节。激活张量的大小为 批次大小 $\\times$ 深度 $\\times$ 高度 $\\times$ 宽度 $\\times$ 通道数。令 $V_d = d^3$ 为空间维度 $d$ 的体积。我们对所有层中每个样本的元素求和。\n\n- 在空间大小 $128^3$ 处：\n  - 编码器：2 个卷积 $\\times$ $32$ 通道 $\\implies 2 \\times V_{128} \\times 32$。\n  - 解码器：1 个转置卷积 $\\times$ $32$ 通道, 2 个卷积 $\\times$ $32$ 通道 $\\implies 3 \\times V_{128} \\times 32$。\n  - 最终层：1 个卷积 $\\times$ $3$ 通道 $\\implies 1 \\times V_{128} \\times 3$。\n  - 在 $128^3$ 处的总计：$V_{128} \\times (2 \\cdot 32 + 3 \\cdot 32 + 3) = 2,097,152 \\times 163 = 341,835,776$ 个元素。\n\n- 在空间大小 $64^3$ 处：\n  - 编码器：2 个卷积 $\\times$ $64$ 通道 $\\implies 2 \\times V_{64} \\times 64$。\n  - 解码器：1 个转置卷积 $\\times$ $64$ 通道, 2 个卷积 $\\times$ $64$ 通道 $\\implies 3 \\times V_{64} \\times 64$。\n  - 在 $64^3$ 处的总计：$V_{64} \\times (2 \\cdot 64 + 3 \\cdot 64) = 262,144 \\times 320 = 83,886,080$ 个元素。\n\n- 在空间大小 $32^3$ 处：\n  - 编码器：2 个卷积 $\\times$ $128$ 通道 $\\implies 2 \\times V_{32} \\times 128$。\n  - 解码器：1 个转置卷积 $\\times$ $128$ 通道, 2 个卷积 $\\times$ $128$ 通道 $\\implies 3 \\times V_{32} \\times 128$。\n  - 在 $32^3$ 处的总计：$V_{32} \\times (2 \\cdot 128 + 3 \\cdot 128) = 32,768 \\times 640 = 20,971,520$ 个元素。\n\n- 在空间大小 $16^3$ 处：\n  - 编码器：2 个卷积 $\\times$ $256$ 通道 $\\implies 2 \\times V_{16} \\times 256$。\n  - 解码器：1 个转置卷积 $\\times$ $256$ 通道, 2 个卷积 $\\times$ $256$ 通道 $\\implies 3 \\times V_{16} \\times 256$。\n  - 在 $16^3$ 处的总计：$V_{16} \\times (2 \\cdot 256 + 3 \\cdot 256) = 4,096 \\times 1280 = 5,242,880$ 个元素。\n\n- 在空间大小 $8^3$ 处：\n  - 瓶颈层：2 个卷积 $\\times$ $512$ 通道 $\\implies 2 \\times V_8 \\times 512$。\n  - 在 $8^3$ 处的总计：$V_8 \\times (2 \\cdot 512) = 512 \\times 1024 = 524,288$ 个元素。\n\n每个样本存储的激活元素总数为这些值的总和：\n$E_{sample} = 341,835,776 + 83,886,080 + 20,971,520 + 5,242,880 + 524,288 = 452,460,544$。\n\n对于大小为 $B$ 的批次，总激活内存为：\n$M_{A}(B) = B \\times E_{sample} \\times 4 \\, \\mathrm{bytes/element} = B \\times 452,460,544 \\times 4 = B \\times 1,809,842,176 \\, \\mathrm{bytes}$。\n\n**3. 确定最大批次大小 ($B$)**\n\n我们使用内存约束：\n$M_{P} + M_{A}(B) \\le M_{avail}$\n$361,204,784 + B \\times 1,809,842,176 \\le 11,000,000,000$\n$B \\times 1,809,842,176 \\le 11,000,000,000 - 361,204,784$\n$B \\times 1,809,842,176 \\le 10,638,795,216$\n$B \\le \\frac{10,638,795,216}{1,809,842,176} \\approx 5.8782$\n\n由于批次大小 $B$ 必须是整数，因此可能的最大值为 $B=5$。\n\n**4. 减少内存的策略**\n\n两种减少内存消耗的原则性策略是梯度检查点（gradient checkpointing）和混合精度训练（mixed-precision training）。\n\n- **梯度检查点（激活重计算）**：此技术通过不在前向传播期间存储所有中间激活来减少激活内存。相反，它只在指定的“检查点”层存储激活的子集。在反向传播期间，检查点之间各层的激活会从最近的检查点开始动态地重新计算。这以增加计算时间为代价，换取了内存的显著减少。\n  - **对激活内存的影响**：原始激活内存项为 $M_{A}(B) = B \\cdot C_{act}$，其中 $C_{act} = (\\sum_{i=1}^{L} |A_i|) \\cdot 4$ 且 $|A_i|$ 是第 $i$ 层激活张量中的元素数量。使用检查点技术后，新的内存项近似为 $M'_{A}(B) = B \\cdot (C_{ckpt} + C_{seg}) \\cdot 4$，其中 $C_{ckpt}$ 是检查点激活本身的内存，$C_{seg}$ 是两个检查点之间计算量最大的段内的激活内存。如果网络被划分为 $k$ 个段，激活内存大约会减少一个与 $k$ 成比例的因子。因此，激活内存不再与网络的总深度 $L$ 成比例，而是与最大段的深度 $\\max_k L_k$ 以及检查点本身的少量开销成比例。这允许使用更大的批次大小 $B$。\n\n- **混合精度训练**：这涉及使用较低精度的数值格式，通常是 16 位浮点数（FP16），来存储激活、梯度和模型权重，同时保留一份 32 位浮点数（FP32）的主副本权重以进行稳定的权重更新。\n  - **对激活内存的影响**：此策略直接修改了每个激活元素的内存成本。原始激活内存项为 $M_{A}(B) = B \\cdot E_{sample} \\cdot 4$。通过将激活从 FP32（4 字节）切换到 FP16（2 字节），每个元素的成本减半。新的激活内存项变为 $M'_{A}(B) = B \\cdot E_{sample} \\cdot 2$。这代表了一个直接的渐近修改：$M'_{A}(B) = \\frac{1}{2} M_{A}(B)$。在考虑到参数和优化器内存后，如果激活内存是主要瓶颈，这种 2 倍的减少理论上将允许一个几乎大一倍的批次大小。", "answer": "$$\n\\boxed{5}\n$$", "id": "4554578"}, {"introduction": "由于内存限制，医学图像的尺寸通常过大，无法通过卷积神经网络（CNN）一次性完成前向传播。滑动窗口推理是一种标准技术，通过在重叠的小块（patch）上进行预测，然后将结果拼接起来，从而处理大尺寸输入。这项练习将指导你设计一个稳健的滑动窗口策略，分析预测重叠，并评估不同的融合方法以减轻拼接伪影，从而将一个基于小块的模型转化为能够分析整个体积数据的工具 [@problem_id:4554564]。", "problem": "一个执行医学图像分割的三维卷积神经网络 (CNN) 通常使用滑动窗口推理来处理超出模型感受野的大体积输入。考虑一个大小为 $\\left(V_x,V_y,V_z\\right)$ 的输入体积和一个立方体或矩形切片大小 $\\left(p_x,p_y,p_z\\right)$。沿每个轴指定一个分数重叠 $\\omega \\in [0,1)$。滑动窗口推理在规则网格上放置切片窗口，以使体积中的每个体素至少被一个窗口覆盖，并且窗口根据 $\\omega$ 重叠。沿轴 $d \\in \\{x,y,z\\}$ 的步幅由连续窗口重叠分数为 $\\omega$ 的意图定义，这意味着名义步幅为 $p_d \\left(1-\\omega\\right)$。因为窗口位置是离散的体素索引，所以沿轴 $d$ 的实际步幅必须是一个正整数，记为 $s_d$，且必须保证覆盖范围。\n\n从一维滑动窗口覆盖的核心定义出发：\n- 位于起始索引 $a$ 处、长度为 $p$ 的窗口覆盖所有满足 $a \\le i  a+p$ 的整数体素索引 $i$。\n- 必须选择一个窗口起始索引序列 $\\{a_k\\}$，使得覆盖索引的并集等于 $\\{0,1,2,\\dots,V-1\\}$。\n- 如果需要，当 $V>p$ 时，在末端会锚定一个起始索引为 $V-p$ 的最终窗口。\n\n根据这些定义，推导：\n1. 一个将分数重叠 $\\omega$ 和切片长度 $p_d$ 转换为整数步幅 $s_d$ 的规则，该规则需满足 $s_d \\ge 1$ 并与重叠意图一致。\n2. 一个生成沿轴 $d$ 的一维起始索引的构造性过程，该过程保证完全覆盖，并使用 $s_d$ 作为间距，直到最后一个窗口，如果下一个步幅会错过末端，则该窗口锚定在 $V_d-p_d$。\n3. 由此构造所隐含的沿轴 $d$ 的窗口数量 $n_d$ 的公式。\n4. 三维空间中的总窗口数 $N = n_x \\, n_y \\, n_z$。\n\n设 $c_d(i)$ 为一维覆盖重数函数，给出覆盖索引 $i \\in \\{0,1,\\dots,V_d-1\\}$ 的沿轴 $d$ 的窗口数量。在三维空间中，通过笛卡尔网格的构造，体素 $\\left(i,j,k\\right)$ 处的覆盖重数可分解为 $m(i,j,k) = c_x(i)\\,c_y(j)\\,c_z(k)$。利用这一点，计算：\n- 沿每个轴的 $c_d$ 值分布及其经验均值 $\\mu_d = \\frac{1}{V_d} \\sum_{i=0}^{V_d-1} c_d(i)$。\n- 利用轴的独立性计算三维平均重数 $\\bar{m} = \\frac{1}{V_x V_y V_z} \\sum_{i,j,k} m(i,j,k)$。\n- 最大三维重数 $m_{\\max} = \\max_{i,j,k} m(i,j,k)$。\n- 多重覆盖体素的比例，定义为 $m(i,j,k) > 1$ 的体素。\n\n为了评估拼接伪影，考虑三种融合策略来组合重叠窗口的预测：\n- 硬拼接：在每个体素处选择一个窗口的预测并丢弃其他窗口的预测。在重数 $m$ 的体素处，每个窗口的权重向量是 $(1,0,0,\\dots,0)$（不计排列）。设一个体素上跨窗口的方差为 $\\sigma^2 = \\frac{1}{m} \\sum_{\\ell=1}^{m} \\left(w_\\ell - \\frac{1}{m}\\right)^2$，其中 $w_\\ell$ 是归一化权重，其和为 $1$。推导硬拼接的 $\\sigma^2$ 作为 $m$ 的函数，并通过对重数分布求和来计算体积上的期望方差。\n- 均匀平均：在一个体素处为所有重叠窗口分配相等的权重，即对所有 $\\ell$ 都有 $w_\\ell = \\frac{1}{m}$。推导任意体素处的方差 $\\sigma^2$ 和体积上的期望方差。\n- 升余弦 (Hann) 锥形窗：对于长度为 $p$ 的窗口，通过 $h(u) = \\frac{1}{2}\\left(1-\\cos\\left(2\\pi u\\right)\\right)$ 定义一维原始权重，其中 $u \\in [0,1]$ 是切片内的归一化位置。对于两个沿一个轴重叠长度为 $L = p - s$，起始位置分别为 $0$ 和 $s$ 的窗口，定义原始权重 $w_1(x) = h\\left(\\frac{x}{p-1}\\right)$ 和 $w_2(x) = h\\left(\\frac{x-s}{p-1}\\right)$，其中整数 $x \\in [s, p-1]$。在每个 $x$ 处通过 $w'_i(x) = \\frac{w_i(x)}{w_1(x)+w_2(x)}$ 进行归一化，并计算一维成对差异 $\\sigma^2_{\\text{pair}} = \\frac{1}{L} \\sum_{x=s}^{p-1} \\frac{1}{2}\\sum_{i=1}^2 \\left(w'_i(x) - \\frac{1}{2}\\right)^2$。利用轴独立性，通过将 $\\sigma^2_{\\text{pair}}$ 与沿单一轴经历精确成对重叠且沿其他两轴为单次覆盖的体素比例加权，来近似三维体积上的期望方差。解释这种近似及其局限性。\n\n测试套件。为以下参数集实现上述内容，确保使用整数体素索引以及推导出的步幅和覆盖构造：\n- 案例 1：$\\left(V_x,V_y,V_z\\right)=\\left(256,256,128\\right)$，$\\left(p_x,p_y,p_z\\right)=\\left(96,96,96\\right)$，$\\omega=0.5$。\n- 案例 2：$\\left(V_x,V_y,V_z\\right)=\\left(256,256,128\\right)$，$\\left(p_x,p_y,p_z\\right)=\\left(256,256,128\\right)$，$\\omega=0.0$。\n- 案例 3：$\\left(V_x,V_y,V_z\\right)=\\left(200,200,60\\right)$，$\\left(p_x,p_y,p_z\\right)=\\left(64,64,64\\right)$，$\\omega=0.6$。\n- 案例 4：$\\left(V_x,V_y,V_z\\right)=\\left(129,129,65\\right)$，$\\left(p_x,p_y,p_z\\right)=\\left(64,64,64\\right)$，$\\omega=0.75$。\n- 案例 5：$\\left(V_x,V_y,V_z\\right)=\\left(64,64,32\\right)$，$\\left(p_x,p_y,p_z\\right)=\\left(96,96,96\\right)$，$\\omega=0.5$。\n\n你的程序应产生单行输出，包含一个用方括号括起来的逗号分隔列表的结果，其中每个测试案例的结果是一个列表\n$\\left[N,\\,[n_x,n_y,n_z],\\,\\bar{m},\\,m_{\\max},\\,f_{\\text{multi}},\\,\\mathbb{E}\\left[\\sigma^2_{\\text{hard}}\\right],\\,\\mathbb{E}\\left[\\sigma^2_{\\text{uniform}}\\right],\\,\\widehat{\\mathbb{E}}\\left[\\sigma^2_{\\text{cosine}}\\right]\\right]$，\n所有实数值都表示为十进制浮点数。例如，最后一行应类似于\n$\\left[\\text{case1},\\text{case2},\\dots\\right]$，其中每个 $\\text{case}$ 被其计算值列表替换。", "solution": "该问题要求推导并实现一个全面的三维滑动窗口推理模型，包括窗口放置策略、覆盖重数分析，以及不同拼接方法融合方差的比较。解决方案分为三个部分，遵循问题陈述的结构。\n\n### 第一部分：步幅和窗口放置\n\n滑动窗口推理的核心是一个确定性的过程，用于放置切片（窗口）以确保输入体积的每个体素都得到处理。此过程由切片大小 $p_d$、体积维度 $V_d$ 以及每个轴 $d \\in \\{x,y,z\\}$ 的期望分数重叠 $\\omega$ 定义。\n\n**1. 整数步幅规则 ($s_d$)**\n\n为实现分数重叠 $\\omega$，沿轴 $d$ 的名义（或理想）步幅为 $s_{nom, d} = p_d (1 - \\omega)$。由于窗口位置在离散的体素网格上，实际步幅 $s_d$ 必须是整数。为确保实际重叠至少达到期望分数 $\\omega$，步幅不应大于名义步幅。较小的步幅增加重叠，而较大的步幅减少重叠。一个保守且常见的选择是对名义步幅取底。此外，步幅必须是正整数。这导出了整数步幅 $s_d$ 的规则：\n$$\ns_d = \\max(1, \\lfloor p_d (1 - \\omega) \\rfloor)\n$$\n此规则保证 $s_d \\ge 1$ 且重叠分数大于或等于 $\\omega$。\n\n**2. 窗口起始索引的构造性过程**\n\n为保证完全覆盖体积维度 $V_d$，窗口从索引 $0$ 开始放置，并以步幅 $s_d$ 前进。如果这种常规放置导致末端的体素未被覆盖，则会在索引 $V_d - p_d$ 处锚定最后一个窗口。这导致了以下用于生成一维起始索引 $\\{a_k\\}$ 的构造性过程：\n\n1.  如果切片大小大于或等于体积维度 ($p_d \\ge V_d$)，一个位于索引 $0$ 的窗口就足够了。起始索引集为 $\\{0\\}$。\n2.  如果 $p_d  V_d$，则生成一个从 $0$ 开始，步长为 $s_d$ 的起始序列：$\\{0, s_d, 2s_d, \\dots, k \\cdot s_d\\}$，只要 $k \\cdot s_d \\le V_d - p_d$。\n3.  如果最后一个生成的起始索引不是 $V_d - p_d$，则将 $V_d - p_d$ 添加到起始索引集中。这确保了最后的体素被覆盖。\n\n此过程生成一个唯一的、已排序的起始索引列表，保证完全覆盖。\n\n**3. 窗口数量公式 ($n_d$)**\n\n窗口数量 $n_d$ 是由上述过程生成的起始索引的数量。可以推导出一个封闭形式的公式。\n- 如果 $V_d \\le p_d$，则 $n_d = 1$。\n- 如果 $V_d > p_d$，起始索引通过在可能的起始位置范围（跨度为 $V_d - p_d$）内以步幅 $s_d$ 移动来生成。覆盖此范围所需的步幅数量为 $\\lceil \\frac{V_d - p_d}{s_d} \\rceil$。加上位于索引 $0$ 的初始窗口，得出总窗口数的公式：\n$$\nn_d = \\begin{cases} 1  \\text{if } V_d \\le p_d \\\\ \\left\\lceil \\frac{V_d - p_d}{s_d} \\right\\rceil + 1  \\text{if } V_d > p_d \\end{cases}\n$$\n\n**4. 总窗口数 ($N$)**\n\n窗口的放置沿每个轴独立进行，形成一个切片位置的笛卡尔网格。总窗口数 $N$ 是沿每个轴的窗口数量的乘积：\n$$\nN = n_x n_y n_z\n$$\n\n### 第二部分：覆盖重数分析\n\n覆盖重数 $m(i,j,k)$ 是覆盖给定体素 $(i,j,k)$ 的窗口数量。由于是笛卡尔网格构造，它可以分解为：$m(i,j,k) = c_x(i)c_y(j)c_z(k)$，其中 $c_d(i)$ 是一维重数。\n\n**1. 一维重数分布和均值**\n\n对于 $i \\in \\{0, 1, \\dots, V_d-1\\}$ 的一维重数函数 $c_d(i)$ 由 $c_d(i) = \\sum_k \\mathbb{I}(a_k \\le i  a_k + p_d)$ 给出，其中 $\\{a_k\\}$ 是起始索引。这个函数可以通过创建一个差分数组来高效计算，在每个 $a_k$ 处递增，在每个 $a_k+p_d$ 处递减，然后计算前缀和。从计算出的 $c_d(i)$ 数组，可以确定其分布（值的直方图）。\n\n一维平均重数 $\\mu_d$ 是 $c_d(i)$ 在体积上的平均值。\n$$\n\\mu_d = \\frac{1}{V_d} \\sum_{i=0}^{V_d-1} c_d(i)\n$$\n总和 $\\sum_i c_d(i)$ 表示所有窗口覆盖的体素总数。这等同于对每个落在体积边界内的窗口长度求和。\n$$\n\\sum_{i=0}^{V_d-1} c_d(i) = \\sum_{k=0}^{n_d-1} (\\min(V_d, a_k + p_d) - a_k)\n$$\n因此，$\\mu_d = \\frac{1}{V_d} \\sum_k (\\min(V_d, a_k + p_d) - a_k)$。\n\n**2. 三维重数度量**\n\n- **三维平均重数 ($\\bar{m}$)**：根据轴的独立性，乘积的期望（均值）是期望的乘积：\n  $$\n  \\bar{m} = \\mathbb{E}[c_x c_y c_z] = \\mathbb{E}[c_x]\\mathbb{E}[c_y]\\mathbb{E}[c_z] = \\mu_x \\mu_y \\mu_z\n  $$\n- **三维最大重数 ($m_{\\max}$)**：同样，乘积的最大值是最大值的乘积：\n  $$\n  m_{\\max} = (\\max_i c_x(i)) (\\max_j c_y(j)) (\\max_k c_z(k))\n  $$\n- **多重覆盖比例 ($f_{\\text{multi}}$)**：这是 $m(i,j,k) > 1$ 的体素比例。这可以更容易地通过 1 减去单次覆盖（$m=1$）体素的比例来计算。一个体素有 $m=1$ 当且仅当 $c_x(i)=1$、$c_y(j)=1$ 和 $c_z(k)=1$。设 $N_d(c)$ 是轴 $d$ 上覆盖度为 $c$ 的体素数量。$m=1$ 的体素数量为 $N_x(1) N_y(1) N_z(1)$。\n  $$\n  f_{\\text{multi}} = 1 - \\frac{N_x(1) N_y(1) N_z(1)}{V_x V_y V_z}\n  $$\n\n### 第三部分：融合方差分析\n\n在重数为 $m$ 的体素处，融合权重 $w_\\ell$ 的方差为 $\\sigma^2 = \\frac{1}{m} \\sum_{\\ell=1}^{m} (w_\\ell - \\frac{1}{m})^2$，因为归一化权重的和为 $1$，其均值为 $1/m$。期望方差是 $\\sigma^2(m)$ 在整个体积上的平均值，可以通过三维重数分布 $P(m)$ 计算：$\\mathbb{E}[\\sigma^2] = \\sum_m P(m) \\sigma^2(m)$。\n\n**1. 硬拼接**\n\n对于硬拼接，选择一个窗口，因此权重向量为 $(1, 0, \\dots, 0)$。对于 $m>1$，方差为：\n$$\n\\sigma^2_{\\text{hard}}(m) = \\frac{1}{m} \\left[ \\left(1 - \\frac{1}{m}\\right)^2 + (m-1)\\left(0 - \\frac{1}{m}\\right)^2 \\right] = \\frac{1}{m} \\left[ \\frac{(m-1)^2}{m^2} + \\frac{m-1}{m^2} \\right] = \\frac{m-1}{m^2}\n$$\n对于 $m=1$，$\\sigma^2(1)=0$。期望方差 $\\mathbb{E}[\\sigma^2_{\\text{hard}}]$ 是通过在三维重数分布上对此值求平均来计算的。\n\n**2. 均匀平均**\n\n对于均匀平均，所有权重都相等：$w_\\ell = 1/m$。\n$$\n\\sigma^2_{\\text{uniform}}(m) = \\frac{1}{m} \\sum_{\\ell=1}^m \\left(\\frac{1}{m} - \\frac{1}{m}\\right)^2 = 0\n$$\n无论重数如何，每个体素的方差都为零。因此，期望方差 $\\mathbb{E}[\\sigma^2_{\\text{uniform}}]$ 总是 $0$。\n\n**3. 升余弦 (Hann) 锥形窗**\n\n对于两个窗口之间长度为 $L=p-s$ 的一维重叠，成对差异是通过在重叠区域上对局部方差求平均来计算的。在重叠区域的每个位置 $x$，归一化权重为 $w'_1(x)$ 和 $w'_2(x)$，局部方差为 $\\sigma^2_x = (w'_1(x) - 1/2)^2$。一维成对差异为：\n$$\n\\sigma^2_{\\text{pair},d} = \\frac{1}{p_d-s_d} \\sum_{x=s_d}^{p_d-1} \\left( \\frac{w_1(x)}{w_1(x)+w_2(x)} - \\frac{1}{2} \\right)^2\n$$\n其中 $w_1(x) = h(x/(p_d-1))$ 且 $w_2(x) = h((x-s_d)/(p_d-1))$。\n\n三维期望方差通过仅考虑具有最简单多重覆盖形式的体素来近似：即由单一轴上的成对重叠产生，而在其他两个轴上为单次覆盖的重数 $m=2$ 的体素。\n$$\n\\widehat{\\mathbb{E}}[\\sigma^2_{\\text{cosine}}] \\approx \\sigma^2_{\\text{pair},x} P_x(2)P_y(1)P_z(1) + \\sigma^2_{\\text{pair},y} P_x(1)P_y(2)P_z(1) + \\sigma^2_{\\text{pair},z} P_x(1)P_y(1)P_z(2)\n$$\n其中 $P_d(c) = N_d(c)/V_d$ 是轴 $d$ 上覆盖度为 $c$ 的体素比例。\n\n**近似的局限性**：此近似提供了真实期望方差的下界。其局限性在于：\n1.  它忽略了所有来自重数 $m>2$ 的体素的贡献，这些贡献可能来自单一轴上的高阶重叠或多轴同时重叠。\n2.  它假设三维方差可以分解为独立的一维贡献，而完整的三维融合权重是一维权重的乘积，并且归一化在三维重叠区域上是不可分的。真实的方差计算会更加复杂。\n在 $m>2$ 很少见的低重叠场景中，这种近似最为准确。", "answer": "[[60,[5,5,2],2.5428571,8.0000000,0.9238281,0.0899017,0.0000000,0.0028248],[1,[1,1,1],1.0000000,1.0000000,0.0000000,0.0000000,0.0000000,0.0000000],[108,[6,6,3],3.2000000,8.0000000,0.9700000,0.1105950,0.0000000,0.0039504],[27,[3,3,3],4.0305886,8.0000000,0.9845248,0.1257917,0.0000000,0.0026210],[1,[1,1,1],1.0000000,1.0000000,0.0000000,0.0000000,0.0000000,0.0000000]]", "id": "4554564"}, {"introduction": "生成分割图后，我们需要根据真实标签（ground truth）对其性能进行量化评估。诸如ROC-AUC和PR-AUC之类的指标提供了标准化的方法，用于衡量模型在不同决策阈值下的分类性能，但在类别不平衡的情况下，它们的解读可能存在显著差异。这项练习将巩固你对这些基本评估指标的理解，并阐明为何在典型的医学分割任务中（目标病灶通常很罕见），精确率-召回率（Precision-Recall）曲线通常比ROC曲线更具信息价值 [@problem_id:4554559]。", "problem": "一个像素级病灶分割模型为单张图像中的每个像素 $i$ 生成校准后的预测概率 $s_i \\in [0,1]$。真实标签为 $y_i \\in \\{0,1\\}$，其中 $y_i = 1$ 表示病灶像素，$y_i = 0$ 表示背景像素。考虑以下 $n = 20$ 个像素，每个像素以 $(s_i, y_i)$ 的形式给出，并按 $s_i$ 降序排列：\n$(0.92, 1)$, $(0.90, 0)$, $(0.88, 0)$, $(0.85, 1)$, $(0.70, 0)$, $(0.60, 0)$, $(0.55, 0)$, $(0.40, 0)$, $(0.40, 0)$, $(0.35, 0)$, $(0.30, 0)$, $(0.25, 0)$, $(0.20, 0)$, $(0.18, 0)$, $(0.15, 0)$, $(0.12, 0)$, $(0.10, 0)$, $(0.08, 0)$, $(0.05, 0)$, $(0.02, 0)$。正例总数为 $P = \\sum_i y_i$，负例总数为 $N = n - P$。\n\n仅使用适用于通过阈值 $\\tau$ 对 $s_i$ 进行阈值处理而得出的二元决策规则的基本定义，为该分割任务构建受试者工作特征曲线下面积 (ROC-AUC) 和精确率-召回率曲线下面积 (PR-AUC)。您必须：\n- 根据真阳性 ($TP$)、假阳性 ($FP$)、真阴性 ($TN$) 和假阴性 ($FN$) 定义并使用真阳性率 (TPR)、假阳性率 (FPR)、精确率和召回率。\n- 遍历不同的得分值作为阈值 $\\tau$，以绘制 ROC 和 PR 曲线。\n- 遵循这些曲线的科学标准积分约定，将 $ROC\\text{-}AUC$ 计算为 ROC 曲线下的面积，将 $PR\\text{-}AUC$ 计算为 PR 曲线下的面积。\n\n然后，从关于类别流行度和误差归一化的第一性原理出发，提供一个基于推导的简要解释，说明为什么在像素级病灶分割的极端类别不平衡情况下，$PR\\text{-}AUC$ 比 $ROC\\text{-}AUC$ 更具信息量。\n\n将两个面积值均四舍五入至四位有效数字。以一个包含 $ROC\\text{-}AUC$ 和 $PR\\text{-}AUC$ 的单行矩阵形式报告您的最终数值答案。", "solution": "首先验证问题，以确保其具有科学依据、是良构的且客观的。\n\n**步骤 1：提取已知条件**\n- 模型类型：像素级病灶分割。\n- 预测概率：$s_i \\in [0,1]$。\n- 真实标签：$y_i \\in \\{0,1\\}$，其中 $y_i=1$ 是病灶像素。\n- 像素总数：$n = 20$。\n- 按 $s_i$ 排序的数据点 $(s_i, y_i)$：$(0.92, 1)$, $(0.90, 0)$, $(0.88, 0)$, $(0.85, 1)$, $(0.70, 0)$, $(0.60, 0)$, $(0.55, 0)$, $(0.40, 0)$, $(0.40, 0)$, $(0.35, 0)$, $(0.30, 0)$, $(0.25, 0)$, $(0.20, 0)$, $(0.18, 0)$, $(0.15, 0)$, $(0.12, 0)$, $(0.10, 0)$, $(0.08, 0)$, $(0.05, 0)$, $(0.02, 0)$。\n- 正例总数：$P = \\sum_i y_i$。\n- 负例总数：$N = n - P$。\n- 任务：通过遍历阈值 $\\tau$ 计算 $ROC\\text{-}AUC$ 和 $PR\\text{-}AUC$。\n- 所需定义：根据真阳性 ($TP$)、假阳性 ($FP$)、真阴性 ($TN$) 和假阴性 ($FN$) 定义的真阳性率 (TPR)、假阳性率 (FPR)、精确率和召回率。\n- 任务：解释为什么在极端类别不平衡情况下，$PR\\text{-}AUC$ 比 $ROC\\text{-}AUC$ 更具信息量。\n- 最终答案格式：$ROC\\text{-}AUC$ 和 $PR\\text{-}AUC$ 的数值，四舍五入至四位有效数字，以单行矩阵形式报告。\n\n**步骤 2：使用提取的已知条件进行验证**\n该问题具有科学依据，因为它涉及评估二元分类模型的标准、基本指标（ROC 和 PR 曲线），这是机器学习和医学数据分析中的一个核心主题。该问题是良构的，提供了所有必要的数据和清晰的计算说明，从而导向一个唯一解。语言客观、精确。该问题不违反任何无效性标准。例如，它并非不科学，是可形式化的，是完整的，并且不是琐碎的。\n\n**步骤 3：结论与行动**\n问题有效。将提供完整解答。\n\n**第 1 部分：ROC-AUC 和 PR-AUC 的计算**\n\n首先，我们根据提供的数据确定正例和负例样本的数量。\n正例标签 ($y_i=1$) 对应于得分 $s_i=0.92$ 和 $s_i=0.85$。\n正例样本总数为 $P = 2$。\n负例样本总数为 $N = n - P = 20 - 2 = 18$。\n该数据集表现出显著的类别不平衡，即 $N \\gg P$。\n\n核心指标定义如下：\n- 真阳性 ($TP$)：被正确分类为正例的正例样本数 ($y_i=1, s_i \\ge \\tau$)。\n- 假阳性 ($FP$)：被错误分类为正例的负例样本数 ($y_i=0, s_i \\ge \\tau$)。\n- 真阳性率 ($TPR$) 或召回率：$TPR = \\frac{TP}{P}$。\n- 假阳性率 ($FPR$)：$FPR = \\frac{FP}{N}$。\n- 精确率：$Precision = \\frac{TP}{TP+FP}$。\n\n**ROC 曲线构建和 AUC 计算**\nROC 曲线绘制了在不同阈值 $\\tau$ 下的 $TPR$ 与 $FPR$ 的关系。我们通过按得分降序处理数据点来构建曲线，这一步已经完成。每个点代表一个潜在的阈值。\n从阈值 $\\tau > 0.92$ 开始，没有像素被分类为正例，因此 $TP=0$，$FP=0$。这给出了 ROC 曲线的起点：$(FPR, TPR) = (0, 0)$。\n\n我们遍历排序后的数据点：\n1. 在 $s_1=0.92$ ($y_1=1$) 处：当阈值降至 $0.92$ 以下时，该像素被分类为正例。这是一个真阳性。\n   - $TP$ 增加 1，$FP$ 不变。$TP=1, FP=0$。\n   - $TPR = TP/P = 1/2 = 0.5$。\n   - $FPR = FP/N = 0/18 = 0$。\n   - 曲线从 $(0,0)$ 移动到 $(0, 0.5)$。\n2. 在 $s_2=0.90$ ($y_2=0$) 处：这是一个假阳性。\n   - $TP$ 不变，$FP$ 增加 1。$TP=1, FP=1$。\n   - $TPR = 1/2 = 0.5$。\n   - $FPR = 1/18$。\n   - 曲线从 $(0, 0.5)$ 移动到 $(1/18, 0.5)$。\n3. 在 $s_3=0.88$ ($y_3=0$) 处：这是一个假阳性。\n   - $TP$ 不变，$FP$ 增加 1。$TP=1, FP=2$。\n   - $TPR = 1/2 = 0.5$。\n   - $FPR = 2/18 = 1/9$。\n   - 曲线从 $(1/18, 0.5)$ 移动到 $(2/18, 0.5)$。\n4. 在 $s_4=0.85$ ($y_4=1$) 处：这是一个真阳性。\n   - $TP$ 增加 1，$FP$ 不变。$TP=2, FP=2$。\n   - $TPR = 2/2 = 1$。\n   - $FPR = 2/18 = 1/9$。\n   - 曲线从 $(2/18, 0.5)$ 移动到 $(2/18, 1)$。\n5. 对于所有后续点，$y_i=0$。因此，随着阈值进一步降低，只有 $FP$ 从 2 增加到 18。$TP$ 保持在 2，因此 $TPR$ 保持在 1。\n   - 曲线从 $(2/18, 1)$ 水平移动到 $(18/18, 1) = (1, 1)$。\n\nROC 曲线的顶点是 $(0,0)$、$(0, 0.5)$、$(1/18, 0.5)$、$(2/18, 0.5)$、$(2/18, 1)$ 和 $(1, 1)$。\n$ROC\\text{-}AUC$ 是该曲线下的面积，使用梯形法则计算。面积是连续点 $(FPR_{k-1}, TPR_{k-1})$ 和 $(FPR_k, TPR_k)$ 构成的梯形面积之和：\n$ROC\\text{-}AUC = \\sum_{k} \\frac{TPR_{k-1} + TPR_k}{2} (FPR_k - FPR_{k-1})$。\n对于由水平和垂直段组成的曲线，这可以简化为对水平段下方的矩形面积求和。\n- 从 $(0, 0.5)$ 到 $(1/18, 0.5)$ 段下方的面积：面积$_1 = (1/18 - 0) \\times 0.5 = 1/36$。\n- 从 $(1/18, 0.5)$ 到 $(2/18, 0.5)$ 段下方的面积：面积$_2 = (2/18 - 1/18) \\times 0.5 = 1/36$。\n- 从 $(2/18, 1)$ 到 $(1, 1)$ 段下方的面积：面积$_3 = (1 - 2/18) \\times 1 = 16/18$。\n总 $ROC\\text{-}AUC = \\text{面积}_1 + \\text{面积}_2 + \\text{面积}_3 = \\frac{1}{36} + \\frac{1}{36} + \\frac{16}{18} = \\frac{2}{36} + \\frac{32}{36} = \\frac{34}{36} = \\frac{17}{18}$。\n数值上，$ROC\\text{-}AUC = \\frac{17}{18} \\approx 0.94444...$。四舍五入到四位有效数字，结果是 $0.9444$。\n\n**PR 曲线构建和 AUC 计算**\nPR 曲线绘制了精确率与召回率 ($=TPR$) 的关系。计算 PR 曲线下面积的标准方法，尤其是在信息检索和机器学习中，是平均精确率 (AP) 分数。该方法计算精确率的加权平均值，其中每个精确率是在找到正例样本的每个排名 $k$ 处计算的，然后对正例总数进行平均。这等效于矩形积分：$PR\\text{-}AUC = \\sum_{k} (R_k - R_{k-1}) P_k$，其中 $(R_k, P_k)$ 是排序列表中第 $k$ 个点的召回率和精确率。\n该公式简化为 $PR\\text{-}AUC = \\frac{1}{P} \\sum_{k=1}^n \\text{Precision}(k) \\times I(y_k=1)$，其中 $I(y_k=1)$ 是一个指示函数，如果排名为 $k$ 的样本是正例，则为 1，否则为 0；$\\text{Precision}(k)$ 是考虑前 $k$ 个预测时的精确率。\n\n我们只在出现正例样本的排名处对精确率求和。\n正例样本位于排名 $k=1$ 和 $k=4$ 处。\n- 在排名 $k=1$ 处 (对于 $s_1=0.92, y_1=1$)：\n  - 我们处理了 1 个样本。$TP=1, FP=0$。\n  - Precision$(1) = \\frac{TP}{TP+FP} = \\frac{1}{1+0} = 1$。\n- 在排名 $k=4$ 处 (对于 $s_4=0.85, y_4=1$)：\n  - 我们处理了 4 个样本。此时，我们遇到了两个正例 ($s=0.92, s=0.85$) 和两个负例 ($s=0.90, s=0.88$)。\n  - $TP=2, FP=2$。\n  - Precision$(4) = \\frac{TP}{TP+FP} = \\frac{2}{2+2} = \\frac{2}{4} = 0.5$。\n\n现在，我们计算平均精确率：\n$PR\\text{-}AUC = \\frac{1}{P} (\\text{Precision}(1) + \\text{Precision}(4)) = \\frac{1}{2} (1 + 0.5) = \\frac{1.5}{2} = 0.75$。\n四舍五入到四位有效数字，结果是 $0.7500$。\n\n另外，也可以使用梯形积分对 PR 曲线的顶点 $(0,1)$、$(0.5,1)$ 和 $(1,0.5)$ 进行计算：面积 = $\\frac{1+1}{2}(0.5-0) + \\frac{1+0.5}{2}(1-0.5) = 1 \\times 0.5 + 0.75 \\times 0.5 = 0.5 + 0.375 = 0.875$。然而，这种线性插值方法被认为是过于乐观的，并且不是 PR 曲线的标准计算方法。矩形求和（平均精确率）是科学上公认的 PR-AUC 标准。我们遵循此惯例。\n\n**第 2 部分：关于类别不平衡下 PR-AUC 与 ROC-AUC 的解释**\n\n在像素级病灶分割中，负例像素（背景，$N$）的数量通常比正例像素（病灶，$P$）的数量大几个数量级，即 $N \\gg P$。我们通过检查这些指标的定义来分析为什么在这种情况下 $PR\\text{-}AUC$ 更具信息量。\n\nROC 曲线绘制的是 $TPR = \\frac{TP}{P}$ 与 $FPR = \\frac{FP}{N}$ 的关系。这里的关键项是 $FPR$。因为它通过负例总数 $N$ 进行了归一化，所以当 $N$ 非常大时，$FPR$ 对假阳性 ($FP$) 绝对数量的巨大变化不敏感。对于一个分类器来说，要实现低 $FPR$，它可以承受做出大量的假阳性预测。例如，如果 $N=10^6$，即使有 1000 个假阳性 ($FP=1000$)，$FPR$ 也仅为 $\\frac{1000}{10^6} = 0.001$。将 $FP$ 增加 10 倍至 10000，只会使 $FPR$ 增加到 0.01。ROC 曲线将保持在理想点 $(0,1)$ 附近，并且 $ROC\\text{-}AUC$ 会很高，这表明模型性能优异。这掩盖了模型正在产生数千个假警报的事实，这在临床环境中是不可接受的。\n\nPR 曲线绘制的是精确率 $=\\frac{TP}{TP+FP}$ 与召回率 ($TPR$) 的关系。精确率指标的分母 $TP+FP$ 是被预测为正例的像素总数。它不涉及大量的真阴性 $TN$。因此，精确率对假阳性 $FP$ 的绝对数量直接敏感。使用前面的例子，如果我们有 $P=100$ 并且实现了高召回率 ($TP \\approx 100$)，一个产生 $FP=1000$ 的模型的精确率约为 $\\frac{100}{100+1000} \\approx 0.09$。而一个 $FP=10000$ 的模型的精确率约为 $\\frac{100}{100+10000} \\approx 0.01$。$FP$ 的这些巨大变化导致了精确率的急剧下降。\n\n因此，PR 曲线及其面积 $PR\\text{-}AUC$ 直接反映了在识别所有真实病灶（召回率）和预测为病灶的像素中正确的比例（精确率）之间的权衡。在极端类别不平衡的情况下，高 $ROC\\text{-}AUC$ 可能会产生误导性的乐观结果，而低 $PR\\text{-}AUC$ 则会正确地表明模型的正例预测是不可靠的。由于分割模型的临床效用通常取决于其正例预测的可靠性（即阳性预测值，也就是精确率），因此在类别不平衡的情况下，PR 曲线为模型性能提供了更具信息量和更现实的评估。", "answer": "$$\\boxed{\\begin{pmatrix} 0.9444  0.7500 \\end{pmatrix}}$$", "id": "4554559"}]}