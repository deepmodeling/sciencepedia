## 引言
[深度学习](@entry_id:142022)已成为推动医学图像分析变革的核心力量，为图像分割与分类等任务提供了前所未有的能力。然而，将这些强大模型的理论知识转化为稳健、可靠且能融入临床工作流的实际应用，是一项巨大的挑战。本文旨在提供一份全面的指南，以应对这一复杂性。在接下来的章节中，我们将首先深入剖析[深度学习](@entry_id:142022)的核心**原理与机制**，从学习问题与[损失函数](@entry_id:136784)的数学形式化，到卷积神经网络（CNN）与[Transformer架构](@entry_id:635198)的演进。随后，我们将探索其在真实世界中的**应用与跨学科连接**，展示这些模型如何从基于[医学物理学](@entry_id:158232)的[数据预处理](@entry_id:197920)，到最终临床转化所需的验证框架，被整合进复杂的医疗生态系统。最后，一系列的**动手实践**将提供机会，将所学概念应用于具体问题，巩固理论知识。这段结构化的学习旅程将为读者构建在该动态领域中脱颖而出所必需的、深刻且多维度的理解。

## 原理与机制

本章旨在深入探讨[医学图像分割](@entry_id:636215)与分类中深度学习模型的核心原理与机制。在前一章介绍背景之后，我们将从基础的数学表述出发，系统地剖析学习问题的构建、[损失函数](@entry_id:136784)的设计、[网络架构](@entry_id:268981)的演进，并最终触及在真实临床环境中部署模型时必须考虑的不确定性量化与领域特异性问题。

### 基础：学习问题的形式化

在应用深度学习解决任何问题之前，首要任务是精确地定义我们试图预测的目标。在医学图像分析中，最常见的任务包括图像级分类、[语义分割](@entry_id:637957)和[实例分割](@entry_id:634371)。对这些任务及其输出空间进行严格的数学形式化，是构建和评估模型的基石 [@problem_id:4554573]。

#### 任务定义与输出空间

假设输入是一个随机变量 $X$，其取值于图像空间 $\mathcal{X}$（例如，一个定义在有限像[素域](@entry_id:634209) $\Omega \subset \mathbb{Z}^2$ 上的函数）。输出是一个随机变量 $Y$，其取值于一个与任务相关的标签空间 $\mathcal{Y}$。我们定义一个有限的语义类别集合 $\mathcal{C} = \{1, \dots, C\}$。

**图像级分类 (Image-level Classification)** 的目标是为整个输入图像 $X$ 分配一个或多个类别标签。
- 在 **单标签分类** 中，图像只属于一个类别。模型的输出通常是一个在 $C-1$ 维[概率单纯形](@entry_id:635241) $\Delta^{C-1} = \{ \pi \in \mathbb{R}^{C} : \pi_c \ge 0, \sum_{c=1}^{C} \pi_c = 1 \}$ 上的概率分布向量。
- 在 **多标签分类** 中，图像可以同时属于多个类别。其输出空间通常是 $\{0,1\}^C$，即一个 $C$ 维的二元向量，其中每个元素指示对应类别是否存在。

**[语义分割](@entry_id:637957) (Semantic Segmentation)** 的目标是为图像中的每一个像素分配一个类别标签。其输出是一个与输入图像空间域 $\Omega$ 对齐的标签场。
- **硬标签 (Hard Labels)** 表示为每个像素确定一个唯一的类别，即一个映射 $y_{\text{sem}} : \Omega \to \mathcal{C}$。
- 在深度学习实践中，模型通常输出一个 **概率场**，为每个像素 $u \in \Omega$ 预测一个类别后验概率分布 $p(\cdot \mid x, u) \in \Delta^{C-1}$。因此，概率化[语义分割](@entry_id:637957)的输出空间可以表示为 $\mathcal{Y}_{\text{sem}} = (\Delta^{C-1})^{\Omega}$。

**[实例分割](@entry_id:634371) (Instance Segmentation)** 是一个更具挑战性的任务，它不仅需要识别每个像素的类别，还需要区分同一类别的不同个体（实例）。
- 其输出不能是一个固定的张量，因为一张图像中实例的数量是可变的。因此，一个合适的输出表示是一个 **有限集合** $y_{\text{inst}} = \{ (m_i, c_i) \}_{i=1}^{N}$。
- 在这个集合中，$N$ 是图像中实例的数量（本身是一个随机变量），每个元素是一个元组 $(m_i, c_i)$，其中 $m_i: \Omega \to \{0, 1\}$ 是一个二值掩码（mask），用于标示第 $i$ 个实例的空间范围，而 $c_i \in \mathcal{C}$ 是该实例的类别。
- 其输出空间可以形式化地写为 $\mathcal{Y}_{\text{inst}} = \mathsf{FinSet}(\mathcal{M} \times \mathcal{C})$，其中 $\mathcal{M}$ 是所有可能的二值掩码的空间，$\mathsf{FinSet}(\cdot)$ 代表所有有限子集的集合。

#### 现实世界的挑战：类别不平衡与稀疏标注

在医学图像中，我们常常面临两大挑战 [@problem_id:4554573]。**严重类别不平衡 (Severe Class Imbalance)** 指的是不同类别的[先验概率](@entry_id:275634)相差悬殊。例如，在肿瘤分割任务中，代表肿瘤的像素可能只占整个图像体积的极小部分（如 $0.1\%$），而绝大多数是背景像素 [@problem_id:4554532]。这种不平衡是数据固有的属性，不能通过简单的归一化“移除”，它会对模型的训练动态产生深远影响。

另一个挑战是 **稀疏标注 (Sparse Annotations)**，即标签缺失。在分割任务中，可能只有一部分像素被标注；在[实例分割](@entry_id:634371)中，可能只有部分实例被圈出。处理稀疏标注的关键在于将其视为**缺失数据**，而非负样本。例如，对于未标注的像素，我们应该在计算[损失函数](@entry_id:136784)时将其忽略，而不是默认其为背景。这通常通过一个**观测掩码 (Observation Mask)** $M: \Omega \to \{0,1\}$ 来实现，[损失函数](@entry_id:136784)只在 $M(u)=1$ 的像素上进行计算。

### 核心部件：[损失函数](@entry_id:136784)及其梯度

深度学习的训练过程本质上是一个优化过程，通过[梯度下降法](@entry_id:637322)最小化一个预定义的**[损失函数](@entry_id:136784) (Loss Function)**。[损失函数](@entry_id:136784)的选择和设计直接决定了模型的学习目标和行为。

#### [交叉熵损失](@entry_id:141524)及其梯度

对于分类和[语义分割](@entry_id:637957)任务，最常用的[损失函数](@entry_id:136784)是**[交叉熵损失](@entry_id:141524) (Cross-Entropy Loss)**。对于单个像素，其多类别[交叉熵损失](@entry_id:141524)定义为：
$$ \ell = -\sum_{c=1}^{C} y_{c} \ln(p_{c}) $$
其中，$y_c$ 是一个独热 (one-hot) 编码的真实标签（即真实类别为 $c$ 时 $y_c=1$，否则为 $0$），$p_c$ 是模型预测该像素属于类别 $c$ 的概率。这些概率通常由一组称为 **logits** 的未归一化分数 $z_c$ 通过 **softmax** 函数生成：
$$ p_{c} = \frac{\exp(z_{c})}{\sum_{k=1}^{C} \exp(z_{k})} $$
[交叉熵损失](@entry_id:141524)的一个优美特性是其相对于 logits 的梯度形式异常简洁。通过链式法则，可以推导出损失 $\ell$ 对任意 logit $z_c$ 的梯度为 [@problem_id:4554524]：
$$ \frac{\partial \ell}{\partial z_{c}} = p_c - y_c $$
这个表达式直观地揭示了学习的本质：梯度就是“预测”与“真实”之间的差异。
- 如果一个像素被错误分类（例如，真实类别为 $t$，$y_t=1$，但预测概率 $p_t$ 很小），梯度 $\partial \ell / \partial z_t = p_t - 1$ 将是一个接近 $-1$ 的大负数。在[梯度下降](@entry_id:145942)更新中，这将导致 $z_t$ 大幅增加，从而提升正确类别的概率。
- 如果一个像素被正确且高[置信度](@entry_id:267904)地分类（例如，真实类别为 $t$，$p_t \approx 1$），梯度 $\partial \ell / \partial z_t = p_t - 1 \approx 0$ 将非常小，使得模型在该样本上的更新微乎其微。这使得模型能够将学习能力集中在困难或错误的样本上。

#### 应对[类别不平衡](@entry_id:636658)：从梯度分析到加权损失

[交叉熵损失](@entry_id:141524)的简洁梯度也清晰地暴露了它在类别不平衡问题下的脆弱性。考虑一个二元病灶分割任务，病灶像素（正类，$y=1$）占比极低（例如 $\alpha = 0.001$），而背景像素（负类，$y=0$）占主导。假设在训练初期，模型对病灶像素的预测概率为 $\hat{y} = p_1 = 0.30$，对背景像素的预测概率为 $\hat{y} = p_0 = 0.02$。

对于单个体素的[二元交叉熵](@entry_id:636868)损失，其相对于 logit 的梯度为 $\hat{y} - y$ [@problem_id:4554532]。
- 对于一个病灶体素 ($y=1$)，梯度为 $p_1 - 1 = 0.30 - 1 = -0.70$。
- 对于一个背景体素 ($y=0$)，梯度为 $p_0 - 0 = 0.02$。

尽管单个病灶体素的梯度绝对值（$0.70$）远大于单个背景体素（$0.02$），但背景体素的数量是病灶体素的 $(1-\alpha)/\alpha = 999$ 倍。因此，整个三维容积中，由背景像素贡献的总梯度大小与病灶像素贡献的总梯度大小之比约为：
$$ \frac{\text{背景总梯度贡献}}{\text{病灶总梯度贡献}} = \frac{N(1-\alpha)|p_0|}{N\alpha|p_1 - 1|} = \frac{0.999 \times 0.02}{0.001 \times 0.70} \approx 28.5 $$
这意味着，在每[次梯度](@entry_id:142710)更新中，来自背景像素的信号强度是来自病灶像素的近30倍。[模型优化](@entry_id:637432)的方向将主要由数量庞大的、容易分类的背景像素主导，而对学习如何识别稀有的病灶像素关注不足。

一种直接的解决方案是引入**加权交叉熵 (Weighted Cross-Entropy)**，通过为不同类别的损失项分配权重来平衡梯度贡献。为了使病灶和背景的总梯度贡献相等，我们需要设置病灶类别权重 $w_1$（固定背景权重 $w_0=1$）来满足：
$$ N\alpha w_1 |p_1 - 1| = N(1-\alpha)w_0 |p_0| $$
解得 $w_1 = \frac{(1-\alpha)p_0}{\alpha(1-p_1)} \approx 28.54$ [@problem_id:4554532]。这个权重精确地抵消了类别数量和当前模型[预测误差](@entry_id:753692)带来的双重不平衡。

#### Dice 损失：为分割量身定制

除了逐像素的[交叉熵损失](@entry_id:141524)，[医学图像分割](@entry_id:636215)领域广泛使用基于区域重叠度量的[损失函数](@entry_id:136784)，其中最著名的是 **Dice 损失 (Dice Loss)**。它源于 **Dice 相似系数 (Dice Similarity Coefficient)**，该系数衡量两个集合 $A$ 和 $B$ 的重叠程度：
$$ \mathrm{Dice}(A,B) = \frac{2|A \cap B|}{|A| + |B|} $$
为了使其可微，我们将集合的基数 $|A|$ 替换为预测概率的总和 $\sum_i p_i$，交集 $|A \cap B|$ 替换为预测概率与真实标签的逐元素乘积之和 $\sum_i p_i y_i$。为了避免分母为零（例如在预测和真实掩码都为空的情况下），我们引入一个小的平滑项 $\epsilon > 0$。Dice 损失通常定义为 $1$ 减去可微的 Dice 分数：
$$ \ell_{\text{Dice}} = 1 - \frac{2\sum_{i=1}^{n} p_i y_i + \epsilon}{\sum_{i=1}^{n} p_i + \sum_{i=1}^{n} y_i + \epsilon} $$
通过应用[商法则](@entry_id:143051)，我们可以推导出该损失对第 $k$ 个像素预测值 $p_k$ 的梯度 [@problem_id:4554612]。更重要的是，平滑项 $\epsilon$ 的作用。在处理小病灶时，$\sum p_i$ 和 $\sum y_i$ 都可能非常小，导致分母接近于零，从而引发数值不稳定和[梯度爆炸](@entry_id:635825)。$\epsilon$ 的存在确保了分母始终远离零，从而稳定了训练过程，这对于小物体的精确分割至关重要 [@problem_id:4554612]。

### 架构原理：从局部到全局

[深度学习模型](@entry_id:635298)的性能不仅取决于[损失函数](@entry_id:136784)，更深层次上源于其[网络架构](@entry_id:268981)的设计。现代分割架构的演进趋势体现了从高效提取局部特征到有效聚合全局上下文的转变。

#### 卷积与感受野

**[卷积神经网络](@entry_id:178973) (CNN)** 是医学图像分析的基石。卷积操作本质上是一个**线性、位移等变 (shift-equivariant)** 的局部滤波器 [@problem_id:4554556]。其**局部性 (locality)** 的[归纳偏置](@entry_id:137419)非常适合处理图像数据，因为图像中的像素与其邻域高度相关。通过堆叠卷积层，网络可以逐步扩大其**[感受野](@entry_id:636171) (Receptive Field, RF)**，即影响单个输出单元的输入像素区域，从而构建从低级边缘、纹理到高级形状、部件的层级化特征表示。

#### [扩张卷积](@entry_id:636365)：在不牺牲分辨率的情况下扩大感受野

在[语义分割](@entry_id:637957)等密集预测任务中，我们既需要大的感受野来理解上下文，又需要保持高的空间分辨率来精确定位边界。传统的通过池化（pooling）或大步长卷积来扩大感受野的方法会降低分辨率。**[扩张卷积](@entry_id:636365) (Dilated Convolution)**，或称**[空洞卷积](@entry_id:636365) (Atrous Convolution)**，巧妙地解决了这个问题 [@problem_id:4554537]。

[扩张卷积](@entry_id:636365)通过在一个标准 $k \times k$ [卷积核](@entry_id:635097)的元素之间插入 $r-1$ 个“空洞”（[补零](@entry_id:269987)）来实现，其中 $r$ 是**扩张率 (dilation rate)**。这使得[卷积核](@entry_id:635097)能够以稀疏的方式采样输入特征图。其关键优势在于：
1.  **扩大感受野**：一个基础大小为 $k$、扩张率为 $r$ 的[卷积核](@entry_id:635097)，其有效大小 $k_{\text{eff}}$ 变为 $k_{\text{eff}} = k + (k-1)(r-1)$。例如，一个 $3 \times 3$ 的[卷积核](@entry_id:635097)，当 $r=3$ 时，其感受野等同于一个 $7 \times 7$ 的标准[卷积核](@entry_id:635097) [@problem_id:4554537]。
2.  **不增加参数**：扩张操作不引入任何新的可学习参数。上述 $3 \times 3$、$r=3$ 的卷积层与一个标准的 $3 \times 3$ 卷积层具有完全相同的参数量，均为 $9 \times C_{\text{in}} \times C_{\text{out}}$。
3.  **不降低分辨率**：当步长 (stride) $s=1$ 时，[扩张卷积](@entry_id:636365)不改变输出特征图的空间维度。

通过将具有不同扩张率的卷积层级联或并行使用（如在 Atrous Spatial Pyramid Pooling, ASPP 模块中），模型能够以多尺度的方式捕获上下文信息，同时保持输出[特征图](@entry_id:637719)的分辨率，这对于精确分割至关重要。

#### [自注意力机制](@entry_id:638063)：捕获[长程依赖](@entry_id:181727)

尽管[扩张卷积](@entry_id:636365)能有效扩大[感受野](@entry_id:636171)，但其本质上仍是一种预定义好的、非[数据依赖](@entry_id:748197)的稀疏采样模式。为了真正实现全局、动态的上下文建模，研究者们引入了源自自然语言处理领域的**[自注意力机制](@entry_id:638063) (Self-Attention Mechanism)**，其是 **Transformer** 架构的核心 [@problem_id:4554563]。

[自注意力机制](@entry_id:638063)将输入（例如，图像块序列）映射为三个向量序列：**查询 (Query, $Q$)**、**键 (Key, $K$)** 和**值 (Value, $V$)**。对于每个查询（代表一个输入元素），它通过与所有键计算相似度得分来确定关注权重，然后用这些权重对所有值进行加权求和。这个过程可以紧凑地表示为矩阵运算：
$$ \text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^{\top}}{\sqrt{d_k}}\right)V $$
其中，$d_k$ 是查询和键向量的维度。除以 $\sqrt{d_k}$ 是一个关键的**缩放因子 (scaling factor)**，它用于稳定点积的方差，防止 softmax 函数因输入过大而进入[饱和区](@entry_id:262273)，从而保证了梯度的稳定传播。

[自注意力](@entry_id:635960)的核心优势在于其**全局性**和**内容自适应性**。每个输出都直接依赖于所有输入，权重是根据输入内容动态计算的，这使得模型能够灵活地捕获图像中任意两个位置之间的[长程依赖](@entry_id:181727)关系。然而，这种能力的代价是其计算复杂度与输入序列长度 $N$ 的平方成正比，即 $\mathcal{O}(N^2)$。例如，将一个 $256 \times 256$ 的 2D 图像划分为 $16 \times 16$ 的块，会得到 $N_{2D}=256$ 个 token；而将一个 $256 \times 256 \times 128$ 的 3D 容积划分为 $16 \times 16 \times 16$ 的块，会得到 $N_{3D}=2048$ 个 token。在[自注意力机制](@entry_id:638063)下，3D 情况的计算量将是 2D 的 $(2048/256)^2=64$ 倍，这凸显了其在处理高分辨率数据时的计算挑战 [@problem_id:4554563]。

#### 混合架构：CNN 与 Transformer 的协同

为了结合 CNN 的高效局部建模能力和 Transformer 的强大全局上下文捕获能力，**混合架构 (Hybrid Architectures)** 应运而生，例如 **TransUNet** [@problem_id:4554556]。这类架构的设计哲学体现了对信号处理第一性原理的深刻理解：
- **CNN 编码器**：首先使用一个标准的 CNN 编码器（如 [U-Net](@entry_id:635895) 的编码路径）处理输入图像。这发挥了卷积的优势：作为一种高效的、学习驱动的**多尺度[滤波器组](@entry_id:266441)**，它能有效提取边缘、纹理等局部高频特征。同时，编码器中的[下采样](@entry_id:265757)操作（如步长为2的卷积）在层级化地扩大感受野的同时，也起到了**降维**的作用，将输入从数百万像素压缩到几百个特征向量（tokens），使得后续的[自注意力](@entry_id:635960)计算变得可行。
- **Transformer 瓶颈**：在 CNN 编码器提取的低分辨率、高通道数的特征图上应用 Transformer 模块。此时，Transformer 在一个紧凑的 token 序列上操作，能够以可接受的计算成本，建立起跨越整个图像的**[长程依赖](@entry_id:181727)关系**，从而对区域进行语义消歧，提升解剖结构的合理性。
- **CNN 解码器与[跳跃连接](@entry_id:637548)**：最后，通过一个对称的 CNN 解码器，并辅以从编码器各层级引出的**[跳跃连接](@entry_id:637548) (skip connections)**，逐步恢复空间分辨率。[跳跃连接](@entry_id:637548)将编码器早期保留的高频、精细的局部细节信息直接传递给解码器，与 Transformer 提供的全局语义信息相融合，最终重建出既有全局一致性又具边界精确性的分割图。

#### 架构微调：UNet++ 与偏见-方差权衡

即使在经典的 [U-Net](@entry_id:635895) 框架内，架构的微调也能显著影响性能，尤其是在数据量有限的医学场景下。**UNet++** 通过引入**嵌套和密集的[跳跃连接](@entry_id:637548)**，对 [U-Net](@entry_id:635895) 进行了改进 [@problem_id:4554583]。

从**偏见-方差权衡 (Bias-Variance Tradeoff)** 的角度看，UNet++ 的优势可以被深刻理解。模型的期望误差可以分解为偏见（[模型拟合](@entry_id:265652)能力的上限）、方差（模型对训练数据变化的敏感度）和不可约误差。在小数据集上，高容量模型容易[过拟合](@entry_id:139093)，导致高方差。UNet++ 的设计有助于降低方差，同时可能降低偏见：
1.  **降低偏见 (Bias Reduction)**：[U-Net](@entry_id:635895) 的长[跳跃连接](@entry_id:637548)融合了编码器浅层的低级特征和解码器深层的高级语义特征，两者之间存在**“语义鸿沟”**。UNet++ 的密集跳跃路径使得解码器节点能接收到来自多个语义层级的特征，使得特征融合更加平滑，这有助于模型更好地逼近真实的分割函数，从而降低**近似误差**（偏见）。
2.  **降低方差 (Variance Reduction)**：UNet++ 的最终输出可以看作是多个不同深度[子网](@entry_id:156282)络的预测结果的**隐式集成 (implicit ensemble)**。通过在中间节点上添加辅助损失（即**深度监督, deep supervision**），每个子网络都被鼓励成为一个有效的分割器。集成多个弱相关预测器是降低估计器方variance的经典方法。从数学上看，一个包含 $K$ 个弱相关子预测的集成的方差，其数量级为 $w^{\top}\Sigma w$（其中 $w$ 是权重，$\Sigma$ 是协方差矩阵），在权重均衡且相关性小于1时，这个值严格小于任何单个子路径的方差 [@problem_id:4554583]。这种通过架构设计和训练策略实现的正则化效果，使得模型在小数据集上更加稳定和鲁棒。

### 高级主题：不确定性与领域特异性

在将深度学习模型应用于临床实践时，除了追求高精度，理解模型的局限性、量化其预测的不确定性，以及使其适应特定的物理成像原理也同样重要。

#### 物理知情的模型设计

不同的医学成像模态（如 CT、MRI、超声）具有截然不同的噪声统计特性，这些特性源于其底层的物理成像原理。一个鲁棒的[深度学习模型](@entry_id:635298)应当将这些先验知识融入其设计中 [@problem_id:4554553]。

- **CT (Computed Tomography)**：CT 图像的噪声主要源于 X 射线光子计数的泊松统计过程。在原始的投影数据（sinogram）域，每个探测器的读数 $y_i$ 服从**泊松分布** $y_i \sim \mathrm{Poisson}(\lambda_i)$，其方差等于其均值 $\lambda_i$。因此，一个物理上合理的[损失函数](@entry_id:136784)是泊松[负对数似然](@entry_id:637801)。对于重建后的图像，噪声近似为高斯分布但其方差与信号强度相关（异方差性），使用**[方差稳定变换](@entry_id:273381)**（如 Anscombe 变换）后再应用标准的 $L_2$ 损失是更佳选择。
- **MRI (Magnetic Resonance Imaging)**：单线圈 MRI 幅值图像的噪声服从**莱斯分布 (Rician distribution)**。这源于在 k 空间中，真实的复数信号受到了加性复[高斯白噪声](@entry_id:749762)的污染。因此，对幅值图像直接应用假定[高斯噪声](@entry_id:260752)的 $L_2$ 损失在统计上是不精确的，而基于莱斯分布的[负对数似然](@entry_id:637801)是更具原则性的选择。进行数据增强时，也应在复数域添加高斯噪声再取模，而不是直接在幅值图像上加噪声。
- **超声 (Ultrasound)**：B 模式超声图像的特征是**散斑噪声 (speckle noise)**，这是一种**[乘性噪声](@entry_id:261463)**，源于亚分辨率散射体的[相干叠加](@entry_id:170209)。其[强度分布](@entry_id:163068)通常由伽马分布描述。对付[乘性噪声](@entry_id:261463)的经典方法是进行对数变换，将其转化为[加性噪声](@entry_id:194447)（即**同态滤波**原理），然后在对[数域](@entry_id:148388)进行[去噪](@entry_id:165626)或应用先验（如全变分）。

#### 量化预测不确定性

在医疗决策中，知道模型“不知道什么”和知道模型“知道什么”同样重要。**不确定性量化 (Uncertainty Quantification)** 正是为此而生。预测不确定性主要分为两类 [@problem_id:4535928]：

**数据不确定性 (Aleatoric Uncertainty)** 是数据本身固有的、不可约的随机性。它源于测量噪声、类别模糊性（如部分容积效应导致的组织边界不清）等。即使拥有无限多的数据，这种不确定性也无法消除。
- **估计方法**：一种直接的方法是让模型学习这种不确定性。例如，可以构建一个**异方差模型 (heteroscedastic model)**，让网络除了预测类别 logits 外，还为每个像素预测一个方差 $\sigma^2(\mathbf{x})$。在训练中，模型会学会在噪声大或边界模糊的区域预测出更高的方差值。

**模型不确定性 (Epistemic Uncertainty)** 是由于模型知识有限（即训练数据不足）而产生的参数不确定性。随着训练数据的增加，这种不确定性应该减小。它反映了模型对其预测的“信心”。
- **估计方法**：主要思想是近似模型参数的后验分布 $p(\boldsymbol{\theta} \mid \mathcal{D})$。
    - **蒙特卡洛 Dropout (MC Dropout)**：在测试时保持 Dropout 激活，并进行多次（$T$ 次）随机[前向传播](@entry_id:193086)。这些不同预测结果之间的方差，反映了模型参数的不确定性，从而估计了认知不确定性。
    - **[深度集成](@entry_id:636362) (Deep Ensembles)**：独立训练多个（$M$ 个）相同架构但不同随机初始化的模型。由于[损失函数](@entry_id:136784)的非凸性，它们会收敛到参数空间的不同位置。在测试时，这 $M$ 个模型预测结果的差异就构成了对认知不确定性的估计。

**总不确定性**可以根据全变分定律分解为数据不确定性和[模型不确定性](@entry_id:265539)之和：
$$ \mathrm{Var}(y \mid \mathbf{x}, \mathcal{D}) = \underbrace{\mathbb{E}_{p(\boldsymbol{\theta} \mid \mathcal{D})} [\mathrm{Var}(y \mid \mathbf{x}, \boldsymbol{\theta})]}_{\text{数据不确定性}} + \underbrace{\mathrm{Var}_{p(\boldsymbol{\theta} \mid \mathcal{D})} (\mathbb{E}[y \mid \mathbf{x}, \boldsymbol{\theta}])}_{\text{模型不确定性}} $$
理解这两种[不确定性的来源](@entry_id:164809)和估计方法，对于在临床应用中建立对模型预测的信任、指导医生进行二次复核、以及实现[主动学习](@entry_id:157812)来高效利用标注资源都具有至关重要的意义。