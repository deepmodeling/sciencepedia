{"hands_on_practices": [{"introduction": "理解成本复杂度剪枝的第一步是掌握其核心计算。本练习提供了一个具体的情景，要求您计算在给定复杂度参数 $\\alpha$ 的情况下，剪掉一个子树所导致的成本复杂度变化。通过这个实践，您将直接应用成本复杂度公式，为更复杂的剪枝决策奠定坚实的数学基础 [@problem_id:4615665]。", "problem": "考虑一个用于生物信息学和医学数据分析中的多分类决策树，它根据信使核糖核酸（mRNA）表达谱对急性白血病亚型进行分类。在一个内部节点 $\\tau$ 处，一个小子树有 $3$ 个终端叶节点。这些叶节点概括了训练数据，其样本量（$N_t$）和三个亚型的类别比例 $(p_{t,1}, p_{t,2}, p_{t,3})$ 如下：\n- 叶节点 $\\mathcal{L}_1$：$N_{\\mathcal{L}_1} = 80$，$(0.55, 0.30, 0.15)$。\n- 叶节点 $\\mathcal{L}_2$：$N_{\\mathcal{L}_2} = 65$，$(0.20, 0.50, 0.30)$。\n- 叶节点 $\\mathcal{R}$：$N_{\\mathcal{R}} = 55$，$(0.60, 0.25, 0.15)$。\n\n假设采用带有成本复杂度剪枝的分类与回归树（CART）框架。设叶节点 $t$ 的不纯度为基尼不纯度，定义为 $Q(t) = 1 - \\sum_{c=1}^{3} p_{t,c}^{2}$。一个具有终端叶节点 $\\mathcal{L}(T)$ 的树 $T$ 的成本复杂度为\n$$\nR_{\\alpha}(T) = \\sum_{t \\in \\mathcal{L}(T)} N_{t} \\, Q(t) + \\alpha \\, |\\mathcal{L}(T)|,\n$$\n其中 $\\alpha$ 是一个非负惩罚参数， $|\\mathcal{L}(T)|$ 是终端叶节点的数量。假设我们考虑剪掉以 $\\tau$ 为根的整个子树，并用一个单一叶节点替换它，该叶节点的类别比例等于当前子树中所有样本的聚合比例。设惩罚参数为 $\\alpha = 5$。\n\n计算在节点 $\\tau$ 处的这个剪枝决策所带来的成本复杂度变化，\n$$\n\\Delta R_{\\alpha} = R_{\\alpha}(\\text{剪枝后}) - R_{\\alpha}(\\text{剪枝前}),\n$$\n使用从给定叶节点计算出的聚合类别比例来评估剪枝后单一叶节点的不纯度。将你的最终数值答案四舍五入到四位有效数字。将最终答案表示为一个无量纲的实数。", "solution": "该问题是适定的，其科学基础是决策树算法的原理（特别是CART框架），并为求得唯一解提供了所有必要信息。数据和定义是自洽且一致的。因此，我们开始进行计算。\n\n目标是计算剪掉一个子树所导致的成本复杂度变化 $\\Delta R_{\\alpha}$。这个变化定义为：\n$$\n\\Delta R_{\\alpha} = R_{\\alpha}(\\text{剪枝后}) - R_{\\alpha}(\\text{剪枝前})\n$$\n树 $T$ 的成本复杂度 $R_{\\alpha}(T)$ 由下式给出：\n$$\nR_{\\alpha}(T) = \\sum_{t \\in \\mathcal{L}(T)} N_{t} \\, Q(t) + \\alpha \\, |\\mathcal{L}(T)|\n$$\n其中 $N_t$ 是终端叶节点 $t$ 中的样本数，$Q(t)$ 是该叶节点的基尼不纯度，$|\\mathcal{L}(T)|$ 是树中终端叶节点的数量，$\\alpha$ 是复杂度参数。对于一个有 $C$ 个类别的叶节点 $t$，其基尼不纯度为 $Q(t) = 1 - \\sum_{c=1}^{C} p_{t,c}^{2}$，其中 $p_{t,c}$ 是叶节点 $t$ 中类别 $c$ 的样本比例。在本问题中，我们有 $C=3$ 个类别。\n\n首先，我们计算剪枝前子树的成本复杂度，记为 $R_{\\alpha}(\\text{剪枝前})$。该子树有 $3$ 个终端叶节点：$\\mathcal{L}_1$、$\\mathcal{L}_2$ 和 $\\mathcal{R}$。因此，叶节点数量为 $|\\mathcal{L}(\\text{剪枝前})| = 3$。给定的惩罚参数为 $\\alpha = 5$。\n\n我们首先计算三个叶节点各自的基尼不纯度。\n对于叶节点 $\\mathcal{L}_1$，其比例为 $(0.55, 0.30, 0.15)$：\n$$\nQ(\\mathcal{L}_1) = 1 - (0.55^{2} + 0.30^{2} + 0.15^{2}) = 1 - (0.3025 + 0.09 + 0.0225) = 1 - 0.415 = 0.585\n$$\n对于叶节点 $\\mathcal{L}_2$，其比例为 $(0.20, 0.50, 0.30)$：\n$$\nQ(\\mathcal{L}_2) = 1 - (0.20^{2} + 0.50^{2} + 0.30^{2}) = 1 - (0.04 + 0.25 + 0.09) = 1 - 0.38 = 0.62\n$$\n对于叶节点 $\\mathcal{R}$，其比例为 $(0.60, 0.25, 0.15)$：\n$$\nQ(\\mathcal{R}) = 1 - (0.60^{2} + 0.25^{2} + 0.15^{2}) = 1 - (0.36 + 0.0625 + 0.0225) = 1 - 0.445 = 0.555\n$$\n接下来，我们计算剪枝前子树的总加权不纯度：\n$$\n\\sum_{t \\in \\{\\mathcal{L}_1, \\mathcal{L}_2, \\mathcal{R}\\}} N_t Q(t) = N_{\\mathcal{L}_1}Q(\\mathcal{L}_1) + N_{\\mathcal{L}_2}Q(\\mathcal{L}_2) + N_{\\mathcal{R}}Q(\\mathcal{R})\n$$\n使用给定的样本量 $N_{\\mathcal{L}_1} = 80$、$N_{\\mathcal{L}_2} = 65$ 和 $N_{\\mathcal{R}} = 55$：\n$$\n\\sum N_t Q(t) = 80(0.585) + 65(0.62) + 55(0.555) = 46.8 + 40.3 + 30.525 = 117.625\n$$\n剪枝前的成本复杂度为：\n$$\nR_{\\alpha}(\\text{剪枝前}) = 117.625 + \\alpha |\\mathcal{L}(\\text{剪枝前})| = 117.625 + 5 \\times 3 = 117.625 + 15 = 132.625\n$$\n\n第二，我们计算剪枝后的成本复杂度 $R_{\\alpha}(\\text{剪枝后})$。剪枝后，整个子树被一个单一叶节点替换，我们称之为 $\\tau$。因此，叶节点数量为 $|\\mathcal{L}(\\text{剪枝后})| = 1$。\n\n这个新叶节点 $\\tau$ 中的总样本数是其组成叶节点的样本数之和：\n$$\nN_{\\tau} = N_{\\mathcal{L}_1} + N_{\\mathcal{L}_2} + N_{\\mathcal{R}} = 80 + 65 + 55 = 200\n$$\n叶节点 $\\tau$ 的类别比例是聚合比例，计算为原始叶节点比例的加权平均值，其中权重为样本量。对于每个类别 $c \\in \\{1, 2, 3\\}$：\n$$\np_{\\tau,c} = \\frac{N_{\\mathcal{L}_1} p_{\\mathcal{L}_1,c} + N_{\\mathcal{L}_2} p_{\\mathcal{L}_2,c} + N_{\\mathcal{R}} p_{\\mathcal{R},c}}{N_{\\tau}}\n$$\n$$\np_{\\tau,1} = \\frac{80(0.55) + 65(0.20) + 55(0.60)}{200} = \\frac{44 + 13 + 33}{200} = \\frac{90}{200} = 0.45\n$$\n$$\np_{\\tau,2} = \\frac{80(0.30) + 65(0.50) + 55(0.25)}{200} = \\frac{24 + 32.5 + 13.75}{200} = \\frac{70.25}{200} = 0.35125\n$$\n$$\np_{\\tau,3} = \\frac{80(0.15) + 65(0.30) + 55(0.15)}{200} = \\frac{12 + 19.5 + 8.25}{200} = \\frac{39.75}{200} = 0.19875\n$$\n新叶节点 $\\tau$ 的基尼不纯度为：\n$$\nQ(\\tau) = 1 - (p_{\\tau,1}^2 + p_{\\tau,2}^2 + p_{\\tau,3}^2) = 1 - (0.45^2 + 0.35125^2 + 0.19875^2)\n$$\n$$\nQ(\\tau) = 1 - (0.2025 + 0.1233765625 + 0.0395015625) = 1 - 0.365378125 = 0.634621875\n$$\n剪枝后的树（即单一叶节点 $\\tau$）的总加权不纯度为：\n$$\nN_{\\tau} Q(\\tau) = 200 \\times 0.634621875 = 126.924375\n$$\n剪枝后的成本复杂度为：\n$$\nR_{\\alpha}(\\text{剪枝后}) = N_{\\tau} Q(\\tau) + \\alpha |\\mathcal{L}(\\text{剪枝后})| = 126.924375 + 5 \\times 1 = 131.924375\n$$\n\n最后，我们计算成本复杂度的变化：\n$$\n\\Delta R_{\\alpha} = R_{\\alpha}(\\text{剪枝后}) - R_{\\alpha}(\\text{剪枝前}) = 131.924375 - 132.625 = -0.700625\n$$\n问题要求将答案四舍五入到四位有效数字。前四位有效数字是 $7, 0, 0, 6$。随后的数字是 $2$，所以我们向下舍入。\n$$\n\\Delta R_{\\alpha} \\approx -0.7006\n$$", "answer": "$$\\boxed{-0.7006}$$", "id": "4615665"}, {"introduction": "在生成剪枝序列时，关键是确定每个子树的“最弱连接”——即它变得可以被剪枝的临界复杂度参数 $\\alpha_t$。本练习将引导您使用在临床预测模型中常见的对数似然风险函数来推导此参数。这个过程不仅展示了如何从第一性原理出发找到 $\\alpha_t$，还加深了您对风险度量如何影响剪枝决策的理解 [@problem_id:4615673]。", "problem": "一个医院系统使用分类与回归树（CART; Classification And Regression Trees）开发了一个用于预测$30$天再入院的模型。训练标签是二元结果 $y_i \\in \\{0,1\\}$，树 $T$ 的每个终端节点（叶节点）$\\ell$ 通过最大似然估计（MLE; Maximum Likelihood Estimation）拟合一个伯努利均值。叶节点 $\\ell$ 的经验风险定义为负对数似然\n$$\nR(\\ell) \\equiv -\\sum_{i \\in \\ell} \\big( y_i \\ln(\\hat{p}_\\ell) + (1-y_i)\\ln(1-\\hat{p}_\\ell) \\big),\n$$\n其中 $\\hat{p}_\\ell$ 是叶节点 $\\ell$ 中伯努利均值的最大似然估计，树 $T$ 的风险为 $R(T) \\equiv \\sum_{\\ell \\in \\mathcal{L}(T)} R(\\ell)$，其中 $\\mathcal{L}(T)$ 是叶节点的集合。在成本复杂度剪枝中，我们评估目标函数\n$$\nC_\\alpha(T) \\equiv R(T) + \\alpha |\\mathcal{L}(T)|,\n$$\n其中 $\\alpha \\ge 0$ 是一个复杂度参数，而 $|\\mathcal{L}(T)|$ 是叶节点数。考虑一个内部节点 $t$，其子树 $T_t$ 有 $|\\mathcal{L}(T_t)|$ 个叶节点。将 $T_t$ 折叠成单个叶节点 $t$ 会使叶节点数减少 $|\\mathcal{L}(T_t)|-1$，并将风险从 $R(T_t)$ 变为 $R(t)$，其中 $R(t)$ 是通过对 $T_t$ 下的所有样本进行最大似然估计拟合单个伯努利叶节点而计算出的负对数似然。\n\n仅从上述定义出发，通过将折叠 $T_t$ 时风险的增加量与叶节点数的减少量相等，推导出节点 $t$ 的最弱链接值 $\\alpha_t$。然后，在一个真实的医疗队列中，假设子树 $T_t$ 有 $|\\mathcal{L}(T_t)| = 3$ 个叶节点，每个叶节点的总患者数 $n_\\ell$ 和再入院数 $k_\\ell$ 的计数 $(n_\\ell,k_\\ell)$ 如下：\n- 叶节点 1: $(n_1,k_1) = (50,5)$,\n- 叶节点 2: $(n_2,k_2) = (30,9)$,\n- 叶节点 3: $(n_3,k_3) = (20,4)$.\n在每个叶节点内使用最大似然估计 $\\hat{p}_\\ell = k_\\ell/n_\\ell$，在折叠后的节点 $t$ 中使用 $\\hat{p}_t = (\\sum_{\\ell} k_\\ell)/(\\sum_{\\ell} n_\\ell)$。将最终答案表示为关于 $\\alpha_t$ 的、用自然对数表示的单一闭式解析表达式，不进行数值近似。不要包含任何单位。无需四舍五入。", "solution": "分类与回归树（CART）的成本复杂度剪枝原则为每个内部节点 $t$ 定义了一个复杂度参数的临界值 $\\alpha_t$。这个值被称为最弱链接值，它代表了一个阈值，在该阈值下，剪掉以 $t$ 为根的子树 $T_t$ 的成本与不剪掉它的成本相等。我们通过令未剪枝子树的成本复杂度 $C_\\alpha(T_t)$ 与剪枝后节点 $t$ 的成本复杂度 $C_\\alpha(t)$ 相等来求得 $\\alpha_t$。\n\n成本复杂度定义为 $C_\\alpha(T) \\equiv R(T) + \\alpha |\\mathcal{L}(T)|$，其中 $R(T)$ 是树的风险，$|\\mathcal{L}(T)|$ 是叶节点数。\n对于未剪枝的子树 $T_t$，成本为 $C_\\alpha(T_t) = R(T_t) + \\alpha |\\mathcal{L}(T_t)|$。\n如果我们剪掉子树 $T_t$，节点 $t$ 就变成一个叶节点。所得树的成本与这个新叶节点相关，即 $C_\\alpha(t) = R(t) + \\alpha \\cdot 1$。请注意，由于折叠后的节点是单个叶节点，因此 $|\\mathcal{L}(t)| = 1$。\n\n我们令这两个成本相等，以找到权衡达到平衡时的 $\\alpha_t$ 值：\n$$R(T_t) + \\alpha_t |\\mathcal{L}(T_t)| = R(t) + \\alpha_t$$\n重新整理各项以求解 $\\alpha_t$：\n$$\\alpha_t \\big( |\\mathcal{L}(T_t)| - 1 \\big) = R(t) - R(T_t)$$\n$$\\alpha_t = \\frac{R(t) - R(T_t)}{|\\mathcal{L}(T_t)| - 1}$$\n分子 $R(t) - R(T_t)$ 是由于剪枝导致的经验风险增加量。分母 $|\\mathcal{L}(T_t)| - 1$ 是叶节点数的减少量。\n\n单个叶节点 $\\ell$ 的风险是拟合该叶节点内数据的伯努利模型的负对数似然。对于一个有 $n_\\ell$ 个总样本和 $k_\\ell$ 个正向结果（再入院）的叶节点，伯努利均值的最大似然估计（MLE）为 $\\hat{p}_\\ell = k_\\ell / n_\\ell$。风险为：\n$$R(\\ell) \\equiv -\\sum_{i \\in \\ell} \\big( y_i \\ln(\\hat{p}_\\ell) + (1-y_i)\\ln(1-\\hat{p}_\\ell) \\big)$$\n通过计算正向结果（$y_i=1$）和负向结果（$y_i=0$）的数量，可以简化这个求和式：\n$$R(\\ell) = - \\big[ k_\\ell \\ln(\\hat{p}_\\ell) + (n_\\ell - k_\\ell) \\ln(1 - \\hat{p}_\\ell) \\big]$$\n$$R(\\ell) = - \\left[ k_\\ell \\ln\\left(\\frac{k_\\ell}{n_\\ell}\\right) + (n_\\ell - k_\\ell) \\ln\\left(\\frac{n_\\ell - k_\\ell}{n_\\ell}\\right) \\right]$$\n\n问题提供了一个具有 $|\\mathcal{L}(T_t)| = 3$ 个叶节点的子树 $T_t$ 的数据。\n未剪枝子树 $T_t$ 的风险是其叶节点风险的总和：$R(T_t) = R(\\ell_1) + R(\\ell_2) + R(\\ell_3)$。\n三个叶节点的数据如下：\n- 叶节点 1：$(n_1, k_1) = (50, 5)$。因此，$\\hat{p}_1 = 5/50 = 1/10$。\n  $$R(\\ell_1) = - \\left[ 5 \\ln\\left(\\frac{5}{50}\\right) + (50 - 5) \\ln\\left(1 - \\frac{5}{50}\\right) \\right] = - \\left[ 5 \\ln\\left(\\frac{1}{10}\\right) + 45 \\ln\\left(\\frac{9}{10}\\right) \\right]$$\n- 叶节点 2：$(n_2, k_2) = (30, 9)$。因此，$\\hat{p}_2 = 9/30 = 3/10$。\n  $$R(\\ell_2) = - \\left[ 9 \\ln\\left(\\frac{9}{30}\\right) + (30 - 9) \\ln\\left(1 - \\frac{9}{30}\\right) \\right] = - \\left[ 9 \\ln\\left(\\frac{3}{10}\\right) + 21 \\ln\\left(\\frac{7}{10}\\right) \\right]$$\n- 叶节点 3：$(n_3, k_3) = (20, 4)$。因此，$\\hat{p}_3 = 4/20 = 1/5$。\n  $$R(\\ell_3) = - \\left[ 4 \\ln\\left(\\frac{4}{20}\\right) + (20 - 4) \\ln\\left(1 - \\frac{4}{20}\\right) \\right] = - \\left[ 4 \\ln\\left(\\frac{1}{5}\\right) + 16 \\ln\\left(\\frac{4}{5}\\right) \\right]$$\n\n子树的总风险为：\n$$R(T_t) = - \\left[ 5 \\ln\\left(\\frac{1}{10}\\right) + 45 \\ln\\left(\\frac{9}{10}\\right) \\right] - \\left[ 9 \\ln\\left(\\frac{3}{10}\\right) + 21 \\ln\\left(\\frac{7}{10}\\right) \\right] - \\left[ 4 \\ln\\left(\\frac{1}{5}\\right) + 16 \\ln\\left(\\frac{4}{5}\\right) \\right]$$\n\n对于剪枝后的节点 $t$，我们聚合子树中的所有样本。总样本数为 $n_t = n_1 + n_2 + n_3 = 50 + 30 + 20 = 100$。总再入院数为 $k_t = k_1 + k_2 + k_3 = 5 + 9 + 4 = 18$。\n剪枝后节点的最大似然估计为 $\\hat{p}_t = k_t / n_t = 18 / 100 = 9/50$。\n剪枝后节点 $t$ 的风险为：\n$$R(t) = - \\left[ k_t \\ln(\\hat{p}_t) + (n_t - k_t) \\ln(1 - \\hat{p}_t) \\right]$$\n$$R(t) = - \\left[ 18 \\ln\\left(\\frac{18}{100}\\right) + (100 - 18) \\ln\\left(1 - \\frac{18}{100}\\right) \\right]$$\n$$R(t) = - \\left[ 18 \\ln\\left(\\frac{9}{50}\\right) + 82 \\ln\\left(\\frac{41}{50}\\right) \\right]$$\n\n现在，我们可以计算 $\\alpha_t$。叶节点数的减少量为 $|\\mathcal{L}(T_t)| - 1 = 3 - 1 = 2$。\n$$\\alpha_t = \\frac{R(t) - R(T_t)}{2} = \\frac{1}{2} \\big(R(t) - (R(\\ell_1) + R(\\ell_2) + R(\\ell_3))\\big)$$\n代入风险项的表达式：\n$$\\alpha_t = \\frac{1}{2} \\left( - \\left[ 18 \\ln\\left(\\frac{9}{50}\\right) + 82 \\ln\\left(\\frac{41}{50}\\right) \\right] - \\left( - \\left[ 5 \\ln\\left(\\frac{1}{10}\\right) + 45 \\ln\\left(\\frac{9}{10}\\right) \\right] - \\left[ 9 \\ln\\left(\\frac{3}{10}\\right) + 21 \\ln\\left(\\frac{7}{10}\\right) \\right] - \\left[ 4 \\ln\\left(\\frac{1}{5}\\right) + 16 \\ln\\left(\\frac{4}{5}\\right) \\right] \\right) \\right)$$\n简化符号后得到 $\\alpha_t$ 的最终闭式表达式：\n$$\\alpha_t = \\frac{1}{2} \\left[ \\left( 5 \\ln\\left(\\frac{1}{10}\\right) + 45 \\ln\\left(\\frac{9}{10}\\right) \\right) + \\left( 9 \\ln\\left(\\frac{3}{10}\\right) + 21 \\ln\\left(\\frac{7}{10}\\right) \\right) + \\left( 4 \\ln\\left(\\frac{1}{5}\\right) + 16 \\ln\\left(\\frac{4}{5}\\right) \\right) - \\left( 18 \\ln\\left(\\frac{9}{50}\\right) + 82 \\ln\\left(\\frac{41}{50}\\right) \\right) \\right]$$\n该表达式即为所要求的 $\\alpha_t$ 的精确解析值。", "answer": "$$\\boxed{\\frac{1}{2} \\left[ \\left( 5 \\ln\\left(\\frac{1}{10}\\right) + 45 \\ln\\left(\\frac{9}{10}\\right) \\right) + \\left( 9 \\ln\\left(\\frac{3}{10}\\right) + 21 \\ln\\left(\\frac{7}{10}\\right) \\right) + \\left( 4 \\ln\\left(\\frac{1}{5}\\right) + 16 \\ln\\left(\\frac{4}{5}\\right) \\right) - \\left( 18 \\ln\\left(\\frac{9}{50}\\right) + 82 \\ln\\left(\\frac{41}{50}\\right) \\right) \\right]}$$", "id": "4615673"}, {"introduction": "构建了剪枝路径后，最终的挑战是如何选择最优的树模型。本练习模拟了一个真实世界中的模型选择过程，您将使用交叉验证数据和“单标准误规则”来确定最佳的复杂度参数 $\\alpha$。这个实践对于掌握如何在模型性能和简约性之间取得平衡至关重要，是防止过拟合的关键技术 [@problem_id:4615670]。", "problem": "在一项整合了电子健康记录 (EHR) 和全外显子组变异以预测$30$天再入院（$0$ 表示未再入院，$1$ 表示再入院）的临床基因组学研究中，一个分类与回归树 (CART) 分类器被训练并使用成本复杂度剪枝进行剪枝。成本复杂度剪枝参数表示为 $\\alpha \\geq 0$，增加 $\\alpha$ 会沿着一条嵌套的剪枝路径产生严格更简单的子树。为了估计泛化误差，执行了 $K$ 折交叉验证 (CV)，其中 $K=10$。对于剪枝路径上的每个 $\\alpha$，记录了每折的错分误差（以小数形式表示）。考虑了以下的 $\\alpha$ 值和对应的子树大小（终端节点数）：\n- $\\alpha$：$0$，$0.005$，$0.01$，$0.02$，$0.03$，$0.05$。\n- 子树大小：$22$，$16$，$10$，$8$，$6$，$4$。\n\n对于每个 $\\alpha$，十折的错分误差为：\n- $\\alpha = 0$，子树大小为 $22$：$(0.150,\\;0.130,\\;0.148,\\;0.132,\\;0.146,\\;0.134,\\;0.144,\\;0.136,\\;0.142,\\;0.138)$。\n- $\\alpha = 0.005$，子树大小为 $16$：$(0.145,\\;0.125,\\;0.143,\\;0.127,\\;0.141,\\;0.129,\\;0.139,\\;0.131,\\;0.137,\\;0.133)$。\n- $\\alpha = 0.01$，子树大小为 $10$：$(0.150,\\;0.118,\\;0.146,\\;0.122,\\;0.142,\\;0.126,\\;0.138,\\;0.130,\\;0.134,\\;0.134)$。\n- $\\alpha = 0.02$，子树大小为 $8$：$(0.148,\\;0.126,\\;0.146,\\;0.128,\\;0.144,\\;0.130,\\;0.142,\\;0.132,\\;0.140,\\;0.134)$。\n- $\\alpha = 0.03$，子树大小为 $6$：$(0.153,\\;0.129,\\;0.151,\\;0.131,\\;0.149,\\;0.133,\\;0.147,\\;0.135,\\;0.145,\\;0.137)$。\n- $\\alpha = 0.05$，子树大小为 $4$：$(0.159,\\;0.129,\\;0.157,\\;0.131,\\;0.155,\\;0.133,\\;0.153,\\;0.135,\\;0.151,\\;0.137)$。\n\n从交叉验证误差估计和成本复杂度剪枝的基本定义出发，使用单标准误规则来选择剪枝参数 $\\alpha$ 并报告相应的子树大小。具体来说：\n1. 对于每个 $\\alpha$，计算 $10$ 折的平均交叉验证错分误差 $\\mu(\\alpha)$。\n2. 找出最小化 $\\mu(\\alpha)$ 的 $\\alpha^{\\star}$，并计算 $\\mu(\\alpha^{\\star})$ 的标准误为 $SE(\\alpha^{\\star}) = s(\\alpha^{\\star}) / \\sqrt{K}$，其中 $s(\\alpha^{\\star})$ 是在 $\\alpha^{\\star}$ 处各折误差的样本标准差，且 $K = 10$。\n3. 形成单标准误阈值 $\\tau = \\mu(\\alpha^{\\star}) + SE(\\alpha^{\\star})$。\n4. 选择平均误差 $\\mu(\\alpha)$ 小于或等于 $\\tau$ 的最大 $\\alpha$（即路径上最简单的子树）。\n以一个包含所选 $\\alpha$ 和相应子树大小的行向量形式报告你的最终答案。表达精确值，无需四舍五入。最终答案中不应包含单位。", "solution": "该问题要求使用单标准误规则，为 CART 分类器选择一个最优的成本复杂度剪枝参数 $\\alpha$ 及其对应的子树大小。这个过程涉及分析为一组给定的 $\\alpha$ 值所提供的 $K$ 折交叉验证结果。这里 $K=10$。\n\n单标准误规则是一种用于模型选择的启发式方法，其目标是找到性能在统计上与表现最佳的模型相当的最简单的模型。步骤如下：\n\n1.  对于调整参数 $\\alpha$ 的每个值，计算平均交叉验证错分误差 $\\mu(\\alpha)$。\n2.  找出能产生最小平均交叉验证误差 $\\mu(\\alpha^{\\star})$ 的参数 $\\alpha^{\\star}$。\n3.  计算在 $\\alpha^{\\star}$ 处的平均误差的标准误，记为 $SE(\\alpha^{\\star})$。\n4.  找到平均误差在最小值的一个标准误范围内的最简单模型（在此背景下，即对应于最大 $\\alpha$ 的模型）。也就是说，选择满足 $\\mu(\\alpha) \\leq \\mu(\\alpha^{\\star}) + SE(\\alpha^{\\star})$ 的最大 $\\alpha$。\n\n让我们用给定的数据来执行这些步骤。\n\n**步骤 1：为每个 $\\alpha$ 计算平均交叉验证误差 $\\mu(\\alpha)$。**\n\n平均误差 $\\mu(\\alpha)$ 是每个 $\\alpha$ 对应的 $K=10$ 折错分误差的平均值。\n\n对于 $\\alpha = 0$：\n$\\mu(0) = \\frac{1}{10}(0.150+0.130+0.148+0.132+0.146+0.134+0.144+0.136+0.142+0.138) = \\frac{1.400}{10} = 0.140$\n\n对于 $\\alpha = 0.005$：\n$\\mu(0.005) = \\frac{1}{10}(0.145+0.125+0.143+0.127+0.141+0.129+0.139+0.131+0.137+0.133) = \\frac{1.350}{10} = 0.135$\n\n对于 $\\alpha = 0.01$：\n$\\mu(0.01) = \\frac{1}{10}(0.150+0.118+0.146+0.122+0.142+0.126+0.138+0.130+0.134+0.134) = \\frac{1.340}{10} = 0.134$\n\n对于 $\\alpha = 0.02$：\n$\\mu(0.02) = \\frac{1}{10}(0.148+0.126+0.146+0.128+0.144+0.130+0.142+0.132+0.140+0.134) = \\frac{1.370}{10} = 0.137$\n\n对于 $\\alpha = 0.03$：\n$\\mu(0.03) = \\frac{1}{10}(0.153+0.129+0.151+0.131+0.149+0.133+0.147+0.135+0.145+0.137) = \\frac{1.410}{10} = 0.141$\n\n对于 $\\alpha = 0.05$：\n$\\mu(0.05) = \\frac{1}{10}(0.159+0.129+0.157+0.131+0.155+0.133+0.153+0.135+0.151+0.137) = \\frac{1.480}{10} = 0.148$\n\n平均误差 $\\mu(\\alpha)$ 和子树大小 $|T_{\\alpha}|$ 的总结如下：\n- $\\alpha=0, |T_{\\alpha}|=22: \\mu(0) = 0.140$\n- $\\alpha=0.005, |T_{\\alpha}|=16: \\mu(0.005) = 0.135$\n- $\\alpha=0.01, |T_{\\alpha}|=10: \\mu(0.01) = 0.134$\n- $\\alpha=0.02, |T_{\\alpha}|=8: \\mu(0.02) = 0.137$\n- $\\alpha=0.03, |T_{\\alpha}|=6: \\mu(0.03) = 0.141$\n- $\\alpha=0.05, |T_{\\alpha}|=4: \\mu(0.05) = 0.148$\n\n**步骤 2：确定 $\\alpha^{\\star}$ 并计算 $SE(\\alpha^{\\star})$。**\n\n最小平均误差为 $\\mu_{\\min} = 0.134$，出现在 $\\alpha = 0.01$ 处。因此，$\\alpha^{\\star} = 0.01$。\n\n接下来，我们计算这个 $\\alpha^{\\star}$ 对应的平均值的标准误。标准误由 $SE(\\alpha^{\\star}) = \\frac{s(\\alpha^{\\star})}{\\sqrt{K}}$ 给出，其中 $s(\\alpha^{\\star})$ 是 $\\alpha^{\\star}$ 处各折误差的样本标准差。样本方差 $s^2(\\alpha^{\\star})$ 的计算公式为：\n$$s^2(\\alpha^{\\star}) = \\frac{1}{K-1} \\sum_{k=1}^{K} (e_k - \\mu(\\alpha^{\\star}))^2$$\n对于 $\\alpha^{\\star}=0.01$，各折误差为 $e_k = (0.150, 0.118, 0.146, 0.122, 0.142, 0.126, 0.138, 0.130, 0.134, 0.134)$，均值为 $\\mu(0.01) = 0.134$。折数 $K=10$。\n\n与均值的偏差 $(e_k - \\mu)$ 为：\n$(0.016, -0.016, 0.012, -0.012, 0.008, -0.008, 0.004, -0.004, 0, 0)$。\n\n偏差的平方和为：\n$\\sum (e_k - \\mu)^2 = (0.016)^2 + (-0.016)^2 + (0.012)^2 + (-0.012)^2 + (0.008)^2 + (-0.008)^2 + (0.004)^2 + (-0.004)^2 + 0^2 + 0^2$\n$\\sum (e_k - \\mu)^2 = 2 \\times [ (0.016)^2 + (0.012)^2 + (0.008)^2 + (0.004)^2 ]$\n$\\sum (e_k - \\mu)^2 = 2 \\times [ 0.000256 + 0.000144 + 0.000064 + 0.000016 ]$\n$\\sum (e_k - \\mu)^2 = 2 \\times [ 0.000480 ] = 0.00096$\n\n样本方差为：\n$s^2(0.01) = \\frac{0.00096}{10-1} = \\frac{0.00096}{9}$\n\n均值的标准误为：\n$SE(0.01) = \\sqrt{\\frac{s^2(0.01)}{K}} = \\sqrt{\\frac{0.00096/9}{10}} = \\sqrt{\\frac{0.00096}{90}} \\approx 0.003266$\n\n**步骤 3：形成单标准误阈值 $\\tau$。**\n\n阈值为 $\\tau = \\mu(\\alpha^{\\star}) + SE(\\alpha^{\\star})$。\n$\\tau \\approx 0.134 + 0.003266 = 0.137266$。\n\n**步骤 4：选择满足 $\\mu(\\alpha) \\leq \\tau$ 的最大 $\\alpha$。**\n\n我们将每个 $\\mu(\\alpha)$ 与阈值 $\\tau$ 进行比较。\n\n- $\\mu(0) = 0.140 > 0.137266$ (Fail)\n- $\\mu(0.005) = 0.135 \\leq 0.137266$ (Pass)\n- $\\mu(0.01) = 0.134 \\leq 0.137266$ (Pass)\n- $\\mu(0.02) = 0.137 \\leq 0.137266$ (Pass)\n- $\\mu(0.03) = 0.141 > 0.137266$ (Fail)\n- $\\mu(0.05) = 0.148 > 0.137266$ (Fail)\n\n满足条件 $\\mu(\\alpha) \\leq \\tau$ 的 $\\alpha$ 值为 $0.005$，$0.01$ 和 $0.02$。规则是从这个集合中选择最大的 $\\alpha$，它对应于最简单（剪枝最多）的模型。最大的 $\\alpha$ 是 $0.02$。\n\n对应于 $\\alpha = 0.02$ 的子树大小为 $8$。\n\n因此，所选的参数是 $\\alpha=0.02$，相应的子树大小是 $8$。最终答案将以行向量的形式报告。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.02 & 8\n\\end{pmatrix}\n}\n$$", "id": "4615670"}]}