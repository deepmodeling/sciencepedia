{"hands_on_practices": [{"introduction": "任何变异检测模型的性能都必须经过严格的量化评估。本练习将介绍从混淆矩阵中派生出的最基本评估指标，它们是评估分类器性能的基石。通过计算这些指标 [@problem_id:4554266]，您将掌握评估模型在区分真实变异和背景噪声方面表现优劣的核心技能。", "problem": "一个用于单核苷酸变异 (SNV) 检出的深度学习分类器，通过将其后验概率输出以 $0.9$ 为阈值，在每个基因组位点上做出二元决策；后验概率至少为 $0.9$ 的位点被检出为变异，否则被检出为非变异。在一个从瓶中基因组 (Genome in a Bottle, GIAB) 项目整理出来的独立基准真实集中，有 $200{,}000$ 个位点具有真实标签 (ground truth)。该真实集包含 $15{,}000$ 个确实带有 SNV 的位点和 $185{,}000$ 个确实不带 SNV 的位点。当应用该分类器时，将其检出结果与真实情况进行比较，得到以下计数：$12{,}000$ 个真阳性 ($TP$)，$2{,}000$ 个假阳性 ($FP$)，$183{,}000$ 个真阴性 ($TN$)，以及 $3{,}000$ 个假阴性 ($FN$)。\n\n从医学测试评估中二元分类的标准混淆矩阵类别出发，用 $TP$、$FP$、$TN$ 和 $FN$ 定义以下用于变异检出的性能指标：\n- 灵敏度（真阳性率），\n- 特异度（真阴性率），\n- 精确率（阳性预测值），\n- 召回率，\n- 以及 $F_{1}$ 分数，定义为精确率和召回率的调和平均数。\n\n然后，使用所提供的计数计算这些指标。最终答案仅报告 $F_{1}$ 分数，以单个精确分数的形式表示，不进行四舍五入，不带单位。", "solution": "首先对问题陈述进行严格的验证过程。\n\n### 第 1 步：提取已知信息\n- 一个深度学习分类器为单核苷酸变异 (SNV) 提供二元决策（变异/非变异）。\n- 分类阈值：后验概率 $\\ge 0.9$。\n- 具有真实标签的基准位点总数：$200{,}000$。\n- 真实 SNV 位点数（真实阳性样本，P）：$15{,}000$。\n- 真实非 SNV 位点数（真实阴性样本，N）：$185{,}000$。\n- 来自混淆矩阵的分类器性能计数：\n  - 真阳性 ($TP$)：$12{,}000$。\n  - 假阳性 ($FP$)：$2{,}000$。\n  - 真阴性 ($TN$)：$183{,}000$。\n  - 假阴性 ($FN$)：$3{,}000$。\n- 任务是使用 $TP$、$FP$、$TN$ 和 $FN$ 来定义灵敏度、特异度、精确率、召回率和 $F_1$ 分数，计算它们的值，并以精确分数的形式报告 $F_1$ 分数。\n\n### 第 2 步：使用提取的已知信息进行验证\n该问题具有科学依据、提法明确且客观。它描述了生物信息学领域中一个标准的二元分类性能评估任务，使用了明确定义的指标和术语。所提供的数值数据是自洽且完整的。\n\n- **检查内部一致性**：\n  - 给出的真实阳性位点总数为 $15{,}000$。对这些位点的结果求和为 $TP + FN = 12{,}000 + 3{,}000 = 15{,}000$。这相符。\n  - 给出的真实阴性位点总数为 $185{,}000$。对这些位点的结果求和为 $TN + FP = 183{,}000 + 2{,}000 = 185{,}000$。这也相符。\n  - 位点总数为 $P + N = 15{,}000 + 185{,}000 = 200{,}000$。所有混淆矩阵元素的总和为 $TP + FP + TN + FN = 12{,}000 + 2{,}000 + 183{,}000 + 3{,}000 = 200{,}000$。这相符。\n\n所有数据点都是连贯且足以解决该问题的。该问题有效。\n\n### 第 3 步：结论和行动\n该问题被视为有效。现在将推导解决方案。\n\n二元分类器的评估基于四种可能结果的计数，这些结果表示在混淆矩阵中：\n- **真阳性 ($TP$)**：被正确分类为阳性的正例数量。在这里，指被正确检出为变异的真实 SNV 数量。$TP=12{,}000$。\n- **假阳性 ($FP$)**：被错误分类为阳性的负例数量。在这里，指被错误检出为变异的真实非 SNV 数量。$FP=2{,}000$。\n- **真阴性 ($TN$)**：被正确分类为阴性的负例数量。在这里，指被正确检出为非变异的真实非 SNV 数量。$TN=183{,}000$。\n- **假阴性 ($FN$)**：被错误分类为阴性的正例数量。在这里，指被错误检出为非变异的真实 SNV 数量。$FN=3{,}000$。\n\n真实阳性实例的总数为 $P = TP + FN$。真实阴性实例的总数为 $N = TN + FP$。\n\n我们现在用这些量来定义所要求的性能指标。\n\n**灵敏度（真阳性率）**：该指标衡量被正确识别的真实阳性样本的比例。它也被称为召回率。\n$$\n\\text{Sensitivity} = \\frac{TP}{P} = \\frac{TP}{TP + FN}\n$$\n\n**特异度（真阴性率）**：该指标衡量被正确识别的真实阴性样本的比例。\n$$\n\\text{Specificity} = \\frac{TN}{N} = \\frac{TN}{TN + FP}\n$$\n\n**精确率（阳性预测值，PPV）**：该指标衡量预测为阳性的样本中实际为阳性的比例。\n$$\n\\text{Precision} = \\frac{TP}{TP + FP}\n$$\n\n**召回率**：如前所述，召回率与灵敏度是同义词。它衡量被正确识别的真实阳性样本的比例。\n$$\n\\text{Recall} = \\frac{TP}{P} = \\frac{TP}{TP + FN}\n$$\n\n**$F_1$ 分数**：$F_1$ 分数被定义为精确率和召回率的调和平均数。两个数 $a$ 和 $b$ 的调和平均数由 $2 \\cdot \\frac{ab}{a+b}$ 给出。\n$$\nF_1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n$$\n代入精确率和召回率的表达式：\n$$\nF_1 = 2 \\cdot \\frac{\\left(\\frac{TP}{TP + FP}\\right) \\cdot \\left(\\frac{TP}{TP + FN}\\right)}{\\left(\\frac{TP}{TP + FP}\\right) + \\left(\\frac{TP}{TP + FN}\\right)} = \\frac{2 \\cdot TP^2 / ((TP+FP)(TP+FN))}{TP(TP+FN) + TP(TP+FP) / ((TP+FP)(TP+FN))} = \\frac{2 TP^2}{TP(TP+FN) + TP(TP+FP)}\n$$\n简化此表达式可得到一个更直接的公式：\n$$\nF_1 = \\frac{2 \\cdot TP}{2 \\cdot TP + FP + FN}\n$$\n\n现在，我们使用提供的数值计算这些指标：$TP=12{,}000$，$FP=2{,}000$，$TN=183{,}000$，和 $FN=3{,}000$。\n\n首先，我们计算精确率和召回率。\n$$\n\\text{Precision} = \\frac{12{,}000}{12{,}000 + 2{,}000} = \\frac{12{,}000}{14{,}000} = \\frac{12}{14} = \\frac{6}{7}\n$$\n$$\n\\text{Recall} = \\frac{12{,}000}{12{,}000 + 3{,}000} = \\frac{12{,}000}{15{,}000} = \\frac{12}{15} = \\frac{4}{5}\n$$\n虽然最终答案中没有要求，但灵敏度等于召回率，所以 $\\text{Sensitivity} = \\frac{4}{5}$。特异度为：\n$$\n\\text{Specificity} = \\frac{183{,}000}{183{,}000 + 2{,}000} = \\frac{183{,}000}{185{,}000} = \\frac{183}{185}\n$$\n最后，我们使用精确率和召回率的值来计算 $F_1$ 分数。\n$$\nF_1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}} = 2 \\cdot \\frac{\\frac{6}{7} \\cdot \\frac{4}{5}}{\\frac{6}{7} + \\frac{4}{5}}\n$$\n分子中的乘积是 $\\frac{6}{7} \\cdot \\frac{4}{5} = \\frac{24}{35}$。\n分母中的和是 $\\frac{6}{7} + \\frac{4}{5} = \\frac{6 \\cdot 5}{35} + \\frac{4 \\cdot 7}{35} = \\frac{30+28}{35} = \\frac{58}{35}$。\n将这些代回 $F_1$ 公式：\n$$\nF_1 = 2 \\cdot \\frac{\\frac{24}{35}}{\\frac{58}{35}} = 2 \\cdot \\frac{24}{58} = \\frac{48}{58} = \\frac{24}{29}\n$$\n或者，使用 $F_1$ 分数的简化公式：\n$$\nF_1 = \\frac{2 \\cdot TP}{2 \\cdot TP + FP + FN} = \\frac{2 \\cdot 12{,}000}{2 \\cdot 12{,}000 + 2{,}000 + 3{,}000} = \\frac{24{,}000}{24{,}000 + 5{,}000} = \\frac{24{,}000}{29{,}000} = \\frac{24}{29}\n$$\n两种方法都得出了相同的精确分数，这是最终答案所要求的。", "answer": "$$\n\\boxed{\\frac{24}{29}}\n$$", "id": "4554266"}, {"introduction": "虽然全局指标很有用，但稳健的评估需要更细致的分析，尤其是在基因组的复杂区域。本练习将引导您实现分层性能分析 [@problem_id:4554230]，这是理解模型在同聚物或串联重复等困难区域中表现的关键一步。此外，您还将学习如何评估模型预测概率的校准性，这对于在临床应用中信任模型的置信度至关重要。", "problem": "您正在分析一个用于基因组变异检测的二元分类器，该分类器使用深度学习进行训练，以预测候选位点是否包含真实变异。对于每个由$i$索引的候选位点，该分类器会输出一个预测概率$p_i \\in [0,1]$、一个真实的二元标签$y_i \\in \\{0,1\\}$以及一个表示局部基因组背景的分类区域类型$\\rho_i$。感兴趣的区域类型是同聚物、串联重复和片段重复。众所周知，诸如多聚物、串联重复和片段重复等困难区域会降低测序和比对的性能，从而给下游的变异检测工具带来压力，因此性能应按区域类型进行分层评估。\n\n从基础的统计决策理论和经典的二元分类框架出发，定义一个决策规则，该规则使用单一固定阈值$t$将每个概率$p_i$映射到一个二元预测$\\hat{y}_i \\in \\{0,1\\}$，此规则在假阳性和假阴性成本相等的情况下最小化$0$-$1$决策损失。然后，仅使用混淆矩阵计数（真阳性、假阳性、真阴性和假阴性）的基本定义，为每种区域类型构建以下按区域计算的量：阳性预测值（精确率）、灵敏度（召回率）和$F_1$分数。此外，通过$p_i$和$y_i$之间的均方误差（Brier分数）以及平均负对数似然（对数损失）来量化概率质量，这两者都按区域类型计算。您必须在所有区域中使用一个单一的共同阈值$t$。\n\n科学现实主义约束：使用经典的等成本阈值和标准的按区域分层方法。在计算对数损失时，通过对$p_i$和$1-p_i$应用一个无穷小下界$\\epsilon$来防止出现未定义的对数。\n\n您的程序必须从第一性原理精确实现这些计算，而不依赖于任何预封装的度量函数。阈值必须为$t = 0.5$，对数必须为自然对数。为了数值稳定性，在对数损失中使用$\\epsilon = 10^{-15}$。\n\n测试套件。对于每个测试用例，数据由三个特定区域的$(p,y)$对列表组成，每种区域类型一个列表。区域类型以字符串“homopolymer”、“tandem_repeat”和“segmental_duplication”精确写入。所有数字都是无单位的概率和二元标签。测试用例如下：\n\n- 测试用例A（一般“顺利”情况，具有中等难度和接近边界的概率）：\n  - homopolymer: $\\left[(0.9,1),(0.8,1),(0.2,0),(0.4,0),(0.6,1)\\right]$,\n  - tandem\\_repeat: $\\left[(0.7,1),(0.1,0),(0.3,0),(0.55,1),(0.49,0)\\right]$,\n  - segmental\\_duplication: $\\left[(0.6,0),(0.7,0),(0.2,0),(0.95,1),(0.4,1)\\right]$。\n- 测试用例B（边缘情况，概率普遍较低但存在阳性样本，对召回率构成压力）：\n  - homopolymer: $\\left[(0.1,1),(0.2,1),(0.05,0)\\right]$,\n  - tandem\\_repeat: $\\left[(0.49,1),(0.49,0),(0.49,1)\\right]$,\n  - segmental\\_duplication: $\\left[(0.0,0),(0.0,1),(0.0,1)\\right]$。\n- 测试用例C（边界情况，概率在$0$和$1$，对校准和数值稳定性构成压力）：\n  - homopolymer: $\\left[(1.0,1),(0.0,0)\\right]$,\n  - tandem\\_repeat: $\\left[(1.0,0),(0.0,1)\\right]$,\n  - segmental\\_duplication: $\\left[(1.0,1),(1.0,1),(0.0,0),(0.0,0)\\right]$。\n\n输出规范。对于每个测试用例，按固定顺序（homopolymer, tandem_repeat, segmental_duplication）为每种区域类型计算以下指标：精确率、召回率、$F_1$、Brier分数和对数损失。如果任何指标的分母为零，则将其值定义为$0$。将每个指标四舍五入到$6$位小数。您的程序应生成单行输出，其中包含跨所有测试用例和区域类型聚合的结果，形式为由方括号括起来的逗号分隔的浮点数列表，指标顺序如上所述。因此，输出包含$45$个浮点数：$3$个测试用例乘以$3$种区域类型乘以每种区域类型的$5$个指标。不应打印任何其他文本。", "solution": "该问题要求对一个用于基因组变异检测的二元分类器进行严格的、基于第一性原理的评估。评估将按三种基因组区域类型进行分层：同聚物、串联重复和片段重复。我们必须首先从统计学第一性原理建立决策规则，然后为给定的测试数据定义和计算一组标准的性能指标。\n\n### 1. 源自统计决策理论的决策规则\n\n一个二元分类器输出一个概率$p_i \\in [0,1]$，表示给定基因座$i$属于阳性类别（即包含一个真实变异，$y_i=1$）的可能性。我们的任务是将这个概率映射到一个硬分类$\\hat{y}_i \\in \\{0,1\\}$。这是统计决策理论中的一个经典问题。\n\n目标是找到一个能使期望损失最小化的决策规则。问题指定了$0$-$1$损失函数，其中正确分类的损失为$0$，错误分类的损失为$1$。它进一步规定，假阳性和假阴性的成本相等。设此成本为$C  0$。真阳性或真阴性的成本为$0$。\n\n设$p_i = P(y_i=1)$为真实标签为$1$的概率。因此，$P(y_i=0) = 1-p_i$。我们必须从集合$\\{0,1\\}$中选择一个行动$\\hat{y}_i$。每个行动的期望损失或风险如下：\n\n1.  **预测为阳性（$\\hat{y}_i=1$）的风险：** 仅当真实标签为阴性（$y_i=0$）时才会发生损失，这是一种假阳性。期望损失为$R(\\hat{y}_i=1) = P(y_i=0) \\cdot C_{FP} = (1-p_i) \\cdot C$。\n2.  **预测为阴性（$\\hat{y}_i=0$）的风险：** 仅当真实标签为阳性（$y_i=1$）时才会发生损失，这是一种假阴性。期望损失为$R(\\hat{y}_i=0) = P(y_i=1) \\cdot C_{FN} = p_i \\cdot C$。\n\n最优决策规则，即此损失函数下的贝叶斯分类器，是选择使期望损失最小化的行动。如果$R(\\hat{y}_i=1)  R(\\hat{y}_i=0)$，我们预测$\\hat{y}_i=1$：\n$$\n(1-p_i) \\cdot C  p_i \\cdot C\n$$\n由于$C > 0$，我们可以两边同除以$C$：\n$$\n1-p_i  p_i \\implies 1  2p_i \\implies p_i > 0.5\n$$\n因此，在成本相等的情况下最小化$0$-$1$损失的决策规则是，如果其概率超过$0.5$，则预测为阳性类别。这对应于阈值$t=0.5$。问题陈述中提供了这个值，这与我们的推导一致。正式的决策规则是：\n$$\n\\hat{y}_i = \\begin{cases} 1  \\text{if } p_i > t \\\\ 0  \\text{if } p_i \\le t \\end{cases}\n$$\n其中$t=0.5$。\n\n### 2. 源自第一性原理的性能指标\n\n对于每种区域类型$\\rho$，我们通过首先计算混淆矩阵中四种可能结果的计数来评估分类器的性能。设$S_{\\rho}$为区域类型$\\rho$中基因座对应的索引集合。设$N_{\\rho} = |S_{\\rho}|$。\n\n-   **真阳性（$TP_{\\rho}$）：** 正确识别的阳性实例数量。\n    $$TP_{\\rho} = \\sum_{i \\in S_{\\rho}} \\mathbb{I}(y_i=1 \\text{ and } \\hat{y}_i=1)$$\n-   **假阳性（$FP_{\\rho}$）：** 被错误识别为阳性的阴性实例数量。\n    $$FP_{\\rho} = \\sum_{i \\in S_{\\rho}} \\mathbb{I}(y_i=0 \\text{ and } \\hat{y}_i=1)$$\n-   **真阴性（$TN_{\\rho}$）：** 正确识别的阴性实例数量。\n    $$TN_{\\rho} = \\sum_{i \\in S_{\\rho}} \\mathbb{I}(y_i=0 \\text{ and } \\hat{y}_i=0)$$\n-   **假阴性（$FN_{\\rho}$）：** 被错误识别为阴性的阳性实例数量。\n    $$FN_{\\rho} = \\sum_{i \\in S_{\\rho}} \\mathbb{I}(y_i=1 \\text{ and } \\hat{y}_i=0)$$\n其中$\\mathbb{I}(\\cdot)$是示性函数。\n\n使用这些基本计数，我们为每个区域$\\rho$定义所需的指标。\n\n-   **阳性预测值（精确率，$PPV_{\\rho}$）：** 正确的阳性预测所占的比例。\n    $$PPV_{\\rho} = \\frac{TP_{\\rho}}{TP_{\\rho} + FP_{\\rho}}$$\n-   **灵敏度（召回率，$Sens_{\\rho}$）：** 被正确识别的实际阳性样本所占的比例。\n    $$Sens_{\\rho} = \\frac{TP_{\\rho}}{TP_{\\rho} + FN_{\\rho}}$$\n-   **$F_1$分数（$F_{1,\\rho}$）：** 精确率和召回率的调和平均数。\n    $$F_{1,\\rho} = 2 \\cdot \\frac{PPV_{\\rho} \\cdot Sens_{\\rho}}{PPV_{\\rho} + Sens_{\\rho}} = \\frac{2 TP_{\\rho}}{2 TP_{\\rho} + FP_{\\rho} + FN_{\\rho}}$$\n根据问题规范，如果这些指标中任何一个的分母为零，则该指标的值定义为$0$。\n\n问题还要求评估原始概率输出质量的指标，而不仅仅是硬分类。\n\n-   **Brier分数（$BS_{\\rho}$）：** 预测概率与真实二元标签之间的均方误差。分数越低越好。\n    $$BS_{\\rho} = \\frac{1}{N_{\\rho}} \\sum_{i \\in S_{\\rho}} (p_i - y_i)^2$$\n-   **对数损失（$LL_{\\rho}$）：** 在给定预测概率下，真实标签的平均负对数似然。该指标会严重惩罚置信度高但错误的预测。分数越低越好。为避免$\\log(0)$导致的数值不稳定，我们将概率裁剪到一个小范围$[\\epsilon, 1-\\epsilon]$。设$\\tilde{p}_i = \\max(\\min(p_i, 1-\\epsilon), \\epsilon)$，其中$\\epsilon=10^{-15}$。\n    $$LL_{\\rho} = -\\frac{1}{N_{\\rho}} \\sum_{i \\in S_{\\rho}} \\left[ y_i \\log(\\tilde{p}_i) + (1-y_i) \\log(1-\\tilde{p}_i) \\right]$$\n    使用的对数是自然对数（$\\log_e$或$\\ln$）。\n\n### 3. 计算过程\n\n该解决方案通过直接应用这些定义来实现。对于三个测试用例中的每一个，我们遍历三种指定的区域类型。对于每个区域的$(p_i, y_i)$对数据集：\n1.  使用阈值$t=0.5$生成预测标签$\\hat{y}_i$。\n2.  计算计数$TP_{\\rho}$、$FP_{\\rho}$、$TN_{\\rho}$和$FN_{\\rho}$。\n3.  使用上述公式计算五个指标（$PPV_{\\rho}, Sens_{\\rho}, F_{1,\\rho}, BS_{\\rho}, LL_{\\rho}$），并按规定对零分母进行特殊处理。\n4.  将每个得到的指标值四舍五入到$6$位小数。\n5.  将所有测试用例和区域计算并四舍五入的指标收集到一个单一列表中，保持指定的顺序。该列表构成最终输出。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_metrics(data, t, eps):\n    \"\"\"\n    Computes classification and calibration metrics from first principles.\n\n    Args:\n        data (list of tuples): A list of (probability, true_label) pairs.\n        t (float): The classification threshold.\n        eps (float): A small epsilon for clipping probabilities in log-loss.\n\n    Returns:\n        list of floats: A list containing [precision, recall, f1, brier, log_loss].\n    \"\"\"\n    if not data:\n        return [0.0] * 5\n\n    # Unpack probabilities and labels into numpy arrays for vectorized operations\n    p = np.array([item[0] for item in data], dtype=float)\n    y = np.array([item[1] for item in data], dtype=int)\n    N = len(y)\n\n    # 1. Apply decision rule to get predicted labels\n    y_hat = (p > t).astype(int)\n\n    # 2. Compute confusion matrix counts\n    TP = np.sum((y == 1)  (y_hat == 1))\n    FP = np.sum((y == 0)  (y_hat == 1))\n    TN = np.sum((y == 0)  (y_hat == 0))\n    FN = np.sum((y == 1)  (y_hat == 0))\n\n    # 3. Compute classification metrics\n    # Positive Predictive Value (Precision)\n    denom_prec = TP + FP\n    precision = TP / denom_prec if denom_prec > 0 else 0.0\n    \n    # Sensitivity (Recall)\n    denom_rec = TP + FN\n    recall = TP / denom_rec if denom_rec > 0 else 0.0\n\n    # F1 Score\n    denom_f1 = precision + recall\n    f1_score = 2 * (precision * recall) / denom_f1 if denom_f1 > 0 else 0.0\n\n    # 4. Compute probability quality metrics\n    # Brier Score (Mean Squared Error)\n    brier_score = np.mean((p - y)**2)\n\n    # Log-Loss (Mean Negative Log-Likelihood)\n    p_clipped = np.clip(p, eps, 1 - eps)\n    log_loss = -np.mean(y * np.log(p_clipped) + (1 - y) * np.log(1 - p_clipped))\n\n    return [precision, recall, f1_score, brier_score, log_loss]\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case A\n        {\n            \"homopolymer\": [(0.9, 1), (0.8, 1), (0.2, 0), (0.4, 0), (0.6, 1)],\n            \"tandem_repeat\": [(0.7, 1), (0.1, 0), (0.3, 0), (0.55, 1), (0.49, 0)],\n            \"segmental_duplication\": [(0.6, 0), (0.7, 0), (0.2, 0), (0.95, 1), (0.4, 1)],\n        },\n        # Test case B\n        {\n            \"homopolymer\": [(0.1, 1), (0.2, 1), (0.05, 0)],\n            \"tandem_repeat\": [(0.49, 1), (0.49, 0), (0.49, 1)],\n            \"segmental_duplication\": [(0.0, 0), (0.0, 1), (0.0, 1)],\n        },\n        # Test case C\n        {\n            \"homopolymer\": [(1.0, 1), (0.0, 0)],\n            \"tandem_repeat\": [(1.0, 0), (0.0, 1)],\n            \"segmental_duplication\": [(1.0, 1), (1.0, 1), (0.0, 0), (0.0, 0)],\n        }\n    ]\n\n    results = []\n    # Constants defined in the problem\n    threshold = 0.5\n    epsilon = 1e-15\n    region_order = [\"homopolymer\", \"tandem_repeat\", \"segmental_duplication\"]\n\n    # Iterate through all test cases and regions to compute metrics\n    for case_data in test_cases:\n        for region_name in region_order:\n            data_for_region = case_data[region_name]\n            metrics = calculate_metrics(data_for_region, threshold, epsilon)\n            \n            # Round each metric to 6 decimal places as required\n            rounded_metrics = [round(m, 6) for m in metrics]\n            results.extend(rounded_metrics)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "4554230"}, {"introduction": "在掌握了如何评估模型之后，下一步自然是思考如何构建性能更优的模型。本练习将挑战您设计一个基于 Transformer 的现代深度学习架构，用于基因组变异检测 [@problem_id:4554204]。您需要深入思考如何巧妙地对参考序列、测序读数和碱基质量分数等多模态数据进行编码与融合，这是构建最先进变异检测器的核心问题。", "problem": "您正在设计一个深度学习系统，用于在染色体上的一个候选位点周围进行基因组变异检测。给定一个以该位点为中心、长度为 $L$ 的参考窗口，一条覆盖了此窗口大部分区域的比对读段 (read)，以及其逐碱基的 Phred 质量分数。目标是通过使用 Transformer 编码器对参考序列、读段序列和质量分数的联合上下文进行建模，来判断该位点是否存在单核苷酸多态性 (SNP) 或插入/缺失 (indel)。\n\n假设以下基础作为您的出发点。首先，一个 Transformer 编码器层将自注意力机制应用于一个输入嵌入序列。对于嵌入为 $\\mathbf{x}_{i}$ 和 $\\mathbf{x}_{j}$ 的词元索引 $i$ 和 $j$，缩放点积自注意力计算与 $\\exp(\\langle \\mathbf{q}_{i}, \\mathbf{k}_{j} \\rangle / \\sqrt{d})$ 成正比的注意力权重，其中 $\\mathbf{q}_{i} = \\mathbf{W}_{Q} \\mathbf{x}_{i}$，$\\mathbf{k}_{j} = \\mathbf{W}_{K} \\mathbf{x}_{j}$，$d$ 是键 (key) 的维度，输出是值 (value) $\\mathbf{v}_{j} = \\mathbf{W}_{V} \\mathbf{x}_{j}$ 的加权和。其次，Phred 质量分数 (Q) 的定义为 $Q = -10 \\log_{10} p_{\\mathrm{err}}$，其中 $p_{\\mathrm{err}}$ 是碱基检出错误的概率。第三，读段与参考序列进行成对（pairwise）比对，并由一个简明异构空位比对报告 (CIGAR) 字符串表示；您可以假设存在一个比对映射函数 $a$，当碱基是匹配或错配时，该函数将读段索引 $r$ 映射到相应的参考坐标 $a(r)$，并在不适用时指明插入或缺失。\n\n您必须提出一个 Transformer 架构，该架构能够以一种感知比对 (alignment-aware)、能处理插入和缺失、并以经过概率校准的方式使用质量分数的方式，来联合关注参考序列、读段序列和质量分数。该架构应在词元化 (tokenization) 和嵌入 (embedding) 层面进行阐述，并且任何与比对相关的注意力偏置 (attention biasing) 都应能表示为对注意力 logits 的加法项。您可以自由使用特殊词元、片段嵌入 (segment embeddings)，以及位置或相对位置编码。最终输出可以是一个用于预测变异类型的分类词元，但您必须至少指定输入词元化、模态编码、位置编码、插入和缺失的处理方式、质量分数编码，以及为实现感知比对的融合所需的任何注意力掩码或偏置。\n\n哪个选项指定了一个满足这些要求的有效 Transformer 设计？\n\nA. 将参考序列和读段连接成一个单一的词元序列，使用分隔符词元和指示模态的片段嵌入。为参考序列词元和读段词元都分配等于参考坐标的绝对位置；通过在参考序列一侧引入空位词元 (gap tokens) 来表示插入，并为插入的读段词元分配其左侧邻近碱基的参考坐标加上一个学习到的分数偏移嵌入。添加一个依赖于词元间参考坐标有符号差异的相对位置编码。构建一个加性注意力偏置矩阵 $b_{ij}$，其中当词元 $i$ 和 $j$ 在比对映射 $a$ 下对应于比对上的碱基对时，$b_{ij} = \\beta$（$\\beta$ 是可学习的），否则 $b_{ij} = 0$。对于质量分数，将 $Q$ 转换为 $p_{\\mathrm{err}} = 10^{-Q/10}$，计算 logit $\\ell = \\log((1 - p_{\\mathrm{err}})/p_{\\mathrm{err}})$，并通过一个学习到的线性层将 $\\ell$ 投影到嵌入维度；仅将此投影添加到读段碱基词元上。将得到的序列输入到一个多层 Transformer 编码器中，该编码器使用由加性偏置 $b_{ij}$ 增强的全自注意力机制，并使用一个分类词元来聚合证据。\n\nB. 使用一维卷积神经网络对参考窗口进行编码，以生成一个单一的定长向量。仅将读段词元（每个词元带有其绝对读段索引位置）输入到一个 Transformer 解码器中，该解码器与单一的参考向量进行交叉注意力计算。通过获取质量分数字符串的原始 ASCII 字符，用其最大值进行归一化，然后线性投影到嵌入维度，来将逐碱基的质量分数附加到词元嵌入上。不使用任何基于比对的位置信息；让解码器通过其学习到的权重隐式地推断插入和缺失。\n\nC. 通过配对参考碱基、通过朴素索引相等对齐的读段碱基，以及分箱为独热 (one-hot) 类别的质量分数，来创建每个参考位置的三元组词元。使用基于参考索引的绝对位置编码。应用一个普通的 (vanilla) Transformer 编码器，不使用片段嵌入，也不对插入和缺失进行特殊处理。模型通过用一个常数掩蔽注意力矩阵的对角线来学习忽略未对齐的位置。质量分数的独热向量与碱基嵌入连接起来，并线性投影到模型维度。\n\nD. 构建三个独立的 Transformer 编码器，每种模态（参考序列、读段序列、被视为独立标量序列的质量分数）一个，每个编码器都有自己基于其原生索引的绝对位置编码。经过固定数量的层后，在每种模态内对所有位置的最终隐藏状态进行平均，然后连接这三个模态的摘要信息，并用一个多层感知机 (MLP) 进行分类。不使用跨模态注意力或感知比对的偏置；融合仅在最终的分类器处发生。\n\nE. 用分隔符词元连接参考序列和读段词元，并用学习到的片段嵌入标记模态。根据各自序列中的原生索引分配绝对位置；不要跨模态同步位置。使用正弦位置编码。添加一个注意力掩码，以阻止每种模态内相距超过固定距离的词元之间的注意力。对于质量分数，使用线性投影到嵌入空间中的原始 Phred 值 $Q$，并将其添加到读段和参考词元嵌入中。让 Transformer 在没有显式偏置项或特殊插入处理的情况下学习比对。", "solution": "问题要求为基因组变异检测设计一个有效的 Transformer 架构，该架构必须满足一系列特定要求：联合模态注意力、比对感知能力、对插入和缺失 (indels) 的显式处理，以及以概率上合理的方式使用 Phred 质量分数。该架构必须在词元化和嵌入层面进行详细说明。\n\n我们将根据这些要求评估每个选项。\n\n**选项 A 的分析：**\n\n1.  **输入表示**：该选项建议将参考序列和读段词元连接成单个序列，用特殊词元（例如 `[SEP]`）分隔，并使用学习到的片段嵌入来区分两种模态。这是一种标准且有效的方法，在像 BERT 这样的模型中被使用，它能让单个 Transformer 编码器对两个序列执行**联合注意力**，从而满足要求#1。\n\n2.  **位置编码和比对**：它建议根据比对分配绝对位置：在给定基因组位点上的参考词元和对齐的读段词元都被分配相同的、对应于参考坐标的位置索引。这是一种将比对信息直接注入到模型的空间感知中的强大方式，使其具有**比对感知能力** (要求#2)。添加基于参考坐标差异的相对位置编码，进一步丰富了模型对基因组距离的理解。\n\n3.  **Indel 处理**：对于读段中的插入，在参考序列中引入新的空位词元以保持对齐，并且插入的读段词元被分配前一个碱基的参考坐标加上一个学习到的分数偏移量。这是一种复杂而明确的机制，用于**处理插入** (要求#3)，允许模型区分同一位点的多个插入碱基。缺失（存在于参考序列但不存在于读段中的碱基）通过这种方案被自然地处理，因为会存在一个具有给定坐标的参考词元，但没有相应的读段词元。\n\n4.  **质量分数编码**：首先将 Phred 分数 $Q$ 转换为其概率含义，即碱基检出错误概率 $p_{\\mathrm{err}} = 10^{-Q/10}$。然后，计算碱基正确的对数几率 (logit)，即 $\\ell = \\log((1 - p_{\\mathrm{err}})/p_{\\mathrm{err}})$。这个 logit 被线性投影并加到读段碱基的嵌入上。这是对质量分数的**概率校准**使用 (要求#4)，因为它将非线性的、对数尺度的 $Q$ 分数转换为 logit 空间表示，这是使用 softmax 或 sigmoid 激活的神经网络层输入的自然域。只将此信息添加到读段词元是正确的。\n\n5.  **注意力偏置**：提出了一个加性偏置矩阵 $b_{ij}$，其中如果词元 $i$ 和 $j$ 根据比对映射 $a$ 构成一个对齐的碱基对，则 $b_{ij}$ 是一个可学习的标量 $\\beta$，否则为 $0$。这显式地鼓励自注意力机制专注于比对上的碱基之间的比较，直接满足了对**感知比对的注意力偏置**的要求 (要求#6)。\n\n6.  **整体架构**：将这些组件聚合到一个标准的多层 Transformer 编码器中，并使用一个最终的分类词元进行预测，完成了一个详细说明且连贯的设计，满足了所有问题要求（#5, #7, #8, #9）。\n\n**A 的结论：**此选项描述了一个全面、复杂且技术上合理的架构，它以一种有原则的方式满足了所有指定的要求。**正确**。\n\n**选项 B 的分析：**\n\n1.  **架构**：它建议使用一个 Transformer 解码器，该解码器与代表整个参考窗口的单个定长向量进行交叉注意力计算。这是一个编码器-解码器模型，而不是一个联合自注意力模型。将参考序列压缩成单个向量会造成严重的信息瓶颈，丢失所有位置信息和局部序列上下文，而这些对于变异检测至关重要。\n2.  **比对**：它明确指出“不使用任何基于比对的位置信息”，这直接违反了要求#2。\n3.  **Indel 处理**：它依赖于隐式学习，这不是一个指定的机制，违反了要求#3。\n4.  **质量分数**：它建议使用质量分数字符串的原始 ASCII 字符并进行归一化。这完全误解了 Phred 分数的性质。Phred 分数是对数概率 ($Q = -10 \\log_{10} p_{\\mathrm{err}}$)，它们的 ASCII 表示仅仅是一种存储约定。这种方法未经概率校准，违反了要求#4。\n\n**B 的结论：**这个设计存在根本性缺陷，并违反了多个核心要求。**错误**。\n\n**选项 C 的分析：**\n\n1.  **词元化和比对**：它建议基于“朴素索引相等”创建“每个参考位置的三元组词元”。这忽略了所提供的 CIGAR 比对，并且无法处理插入/缺失，因为在一对一索引的情况下会失效。这违反了要求#2和#3。\n2.  **注意力**：“掩蔽注意力矩阵的对角线”不是一种标准或合乎逻辑的方式来整合比对信息。对角线代表一个词元对自身的注意力，掩蔽它是不合理的。这未能正确实现一个感知比对的注意力机制。\n3.  **质量分数**：将质量分数分箱为独热类别是一种会丢弃信息的量化形式。它不像将其转换为 logits 那样有原则或经过“概率校准”(要求#4)。\n\n**C 的结论：**该设计基于关于比对的错误假设，无法处理插入/缺失，并对质量分数使用了次优的表示方法。**错误**。\n\n**选项 D 的分析：**\n\n1.  **架构**：它建议使用三个独立的 Transformer 编码器，融合仅在最终的分类层发生。这种“后期融合”方法完全阻止了模型学习参考序列、读段和质量分数之间细粒度的、逐位置的交互。它违反了在词元级别进行**联合注意力**的核心要求 (要求#1)。\n2.  **比对**：通过在每个独立序列中使用原生索引，它完全忽略了比对信息，因此违反了要求#2。\n\n**D 的结论：**该架构未能对问题所要求的关键跨模态交互进行建模，使其不适合该任务。**错误**。\n\n**选项 E 的分析：**\n\n1.  **位置编码和比对**：它建议对连接的参考序列和读段序列使用原生索引（“不要跨模态同步位置”）。这意味着参考序列中索引为 $i$ 的碱基和读段中索引为 $i$ 的碱基在位置上被视为等效，这是不正确的，因为它们通常不是对齐的。这违反了**比对感知**的要求 (#2)。\n2.  **Indel 处理**：它建议没有显式的 indel 处理机制，这违反了要求#3。\n3.  **质量分数**：它建议使用线性投影的原始 Phred 值 $Q$。这不是概率上合理的，因为 $Q$ 是对数尺度的。此外，它建议将质量嵌入同时添加到*读段*和*参考*词元的嵌入中，这是不正确的，因为质量分数只是读段的属性。这未能满足要求#4。\n\n**E 的结论：**该设计以一种合理的连接方法开始，但在位置编码、比对感知以及正确使用质量分数等关键方面失败了。**错误**。\n\n总之，只有选项 A 提出了一个内部一致、科学上合理，并满足问题陈述中所有要求的设计。", "answer": "$$\\boxed{A}$$", "id": "4554204"}]}