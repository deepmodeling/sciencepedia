## 引言
罕见病的诊断是现代医学面临的重大挑战之一，患者往往经历漫长而痛苦的“诊断之旅”。传统的监督式[机器学习模型](@entry_id:262335)虽然在许多分类任务中表现出色，但其根本局限在于无法识别那些在训练阶段从未见过标记样本的疾病类别，这使得它们在面对数千种罕见病时显得力不从心。这一知识缺口催生了对新计算范式的需求，而[零样本学习](@entry_id:635210)（Zero-Shot Learning, ZSL）正为此提供了充满希望的解决方案。

[零样本学习](@entry_id:635210)的核心思想是利用独立于患者实例的辅助知识（如疾病的文本描述或其在知识图谱中的关联），构建一个连接已知与未知疾病的“语义桥梁”。通过学习将患者数据与这个语义空间进行对齐，模型能够泛化并识别出全新的、在训练中从未出现过的罕见病。

本文旨在系统性地介绍[零样本学习](@entry_id:635210)在罕见病诊断领域的应用。在“原理与机制”一章中，我们将深入剖析ZSL的核心理论，包括语义空间的构建、模型架构的选择以及学习过程的优化。接下来，在“应用与跨学科连接”中，我们将探讨如何将这些理论转化为现实世界的临床应用，并揭示其与因果推断、人工智能伦理等领域的深刻联系。最后，通过“动手实践”部分，读者将有机会通过具体计算来巩固对关键概念的理解。

让我们首先进入[零样本学习](@entry_id:635210)的内部世界，探索其背后的计算原理与机制。

## 原理与机制

在罕见病诊断的背景下，[零样本学习](@entry_id:635210)（Zero-Shot Learning, ZSL）为识别那些在训练阶段从未见过标记样本的疾病类别提供了一套强大的计算原理和机制。本章旨在系统性地阐述支撑这些方法的核心概念，从基本定义出发，逐步深入到模型架构、学习目标、[正则化技术](@entry_id:261393)以及至关重要的评估方法论。

### 核心问题：识别未知

在[统计学习](@entry_id:269475)的框架中，一个典型的[分类任务](@entry_id:635433)是学习一个函数 $h: \mathcal{X} \to \mathcal{Y}$，它将来自特征空间 $\mathcal{X}$（例如，从电子健康记录（EHR）和分子谱分析中提取的特征）的输入映射到一组疾病标签 $\mathcal{Y}$。标准的**监督学习** (Supervised Learning) 假设在训练和部署期间，我们处理的是同一组疾病类别。形式上，如果我们用 $\mathcal{Y}_{\mathrm{tr}}$ 表示[训练集](@entry_id:636396)中出现的标签集合，用 $\mathcal{Y}_{\mathrm{te}}$ 表示[测试集](@entry_id:637546)中遇到的标签集合，那么监督学习的设定是 $\mathcal{Y}_{\mathrm{te}} \subseteq \mathcal{Y}_{\mathrm{tr}}$。然而，在罕见病诊断的现实场景中，模型在部署后很可能会遇到在训练数据中完全没有标记实例的新兴或极其罕见的疾病。

这正是**[零样本学习](@entry_id:635210)** (ZSL) 要解决的核心挑战。在纯粹的 ZSL 设定中，训练和测试的类别集合是完全不相交的，即 $\mathcal{Y}_{\mathrm{tr}} \cap \mathcal{Y}_{\mathrm{te}} = \emptyset$。模型必须在没有任何目标类别标记样本的情况下，对属于 $\mathcal{Y}_{\mathrm{te}}$ 的新患者进行分类。

为了更清晰地界定 ZSL，有必要将其与其他相关的学习范式区分开来 [@problem_id:4618437]：

- **[少样本学习](@entry_id:636112)** (Few-Shot Learning, FSL)：与 ZSL 不同，FSL 假设对于每个新类别，我们可以在学习时获得极少数（例如，1到5个）标记样本。这个小型的“支持集”足以让模型快速适应新类别，而 ZSL 的要求更为严苛，即每个新类别的样本数为零。

- **[开集识别](@entry_id:634480)** (Open-Set Recognition, OSR)：OSR 的目标是在保持对已知类别分类能力的同时，识别出任何不属于 $\mathcal{Y}_{\mathrm{tr}}$ 的输入，并将其标记为“未知”或“新奇”。OSR 的关键在于**拒绝**，而不是像 ZSL 那样将未知输入**识别**为特定的新类别。因此，OSR 通常不依赖于描述未知类别的辅助信息。

ZSL 之所以可能，是因为它利用了一个关键的元素：**辅助信息**（side information），它为连接已知与未知类别提供了桥梁。

### 连接已知与未知的桥梁：语义标签空间

ZSL 的核心思想是通过一个共享的**语义标签空间** (semantic label space) $\mathcal{S}$ 来实现知识迁移。这个空间为**每一个**疾病类别 $y \in \mathcal{Y}$（无论是已见还是未见）提供了一个表示，即一个语义嵌入向量 $\psi(y) \in \mathcal{S}$。这个嵌入向量 $\psi(y)$ 编码了关于疾病的、独立于任何特定患者实例的先验知识 [@problem_id:4618431]。模型在训练阶段学习的不是从患者特征到离散标签的直接映射，而是学习一个患者[特征空间](@entry_id:638014) $\mathcal{X}$ 与语义标签空间 $\mathcal{S}$ 之间的对齐关系。

在生物信息学和医学数据分析中，构建这种语义嵌入的方式多种多样，主要包括：

- **基于属性的向量 (Attribute-based vectors)**：这是最直接的方式，将每种疾病表示为一个向量，其维度对应一组预先定义的、可解释的属性。例如，一个向量可以编码某种疾病关联的一组人类表型[本体](@entry_id:264049) (Human Phenotype Ontology, HPO) 术语的出现频率或二元存在性。这些向量通常是稀疏且易于解释的。

- **基于文本的嵌入 (Textual embeddings)**：利用自然语言处理技术，从大量医学文献、临床指南或本体定义文本中为每种疾病学习一个密集的[向量表示](@entry_id:166424)。像 word2vec 或 BERT 这样的模型能够捕捉到疾病名称及其描述中的语义相似性和关联性，例如，在文本中出现在相似上下文的疾病会获得相似的嵌入向量。

- **基于图的表示 (Graph-based representations)**：利用生物医学知识图谱（如 HPO、疾病本体论、基因-疾病-表型图）的拓扑结构。通过图嵌入算法（如 Node2Vec、Graph Convolutional Networks），可以为图中的每个节点（代表疾病或表型）生成一个向量。这种方法的强大之处在于，即使某个罕见病的直接注释信息很少，它仍然可以通过其在图谱中的邻居和多跳连接关系，从结构上推断出丰富的语义表示 [@problem_id:4618431]。

### 从生物医学知识中构建语义嵌入

在罕见病领域，知识源的选择对 ZSL 模型的性能至关重要。三种常用的资源是 HPO、UMLS 和 SNOMED CT，它们在编码疾病-表型关系方面各有优劣 [@problem_id:4618364]。

- **人类表型[本体](@entry_id:264049) (Human Phenotype Ontology, HPO)**：HPO 是罕见病 ZSL 的黄金标准之一。它提供了一个关于表型异常的、结构清晰的[有向无环图 (DAG)](@entry_id:748452)，并将外部疾病目录（如 OMIM 和 Orphanet）中的疾病与 HPO 表型进行**人工策展的标注**。这些标注通常附带证据和频率限定词（例如，该表型在某疾病患者中出现的频率），非常适合构建加权的属性向量 $\psi(y)$。由于疾病实体与表型本体是分离的（即疾病标注于表型之上），其结构清晰，便于进行无环的祖先闭包扩展，从而生成更丰富的特征。这种清晰的二分图结构和高质量的标注使其非常适合作为罕见病 ZSL 的辅助信息。

- **统一医学语言系统 (Unified Medical Language System, UMLS)**：UMLS 是一个庞大的元知识库，整合了包括 HPO 和 SNOMED CT 在内的数百个词表。它的优势在于覆盖面广，但缺点也同样明显。UMLS 中的关系类型异构、命名和粒度不一，并且缺乏系统性的、高质量的疾病-表型频率数据。虽然 UMLS 整合了 HPO，但这种整合是“有损的”，原始 HPO 中丰富的频率和证据信息在 UMLS 的核心结构中可能无法完全保留。因此，直接使用 UMLS 可能引入噪声，导致性能不如使用更纯净、更专注的 HPO。

- **医学系统命名法临床术语 (SNOMED CT)**：SNOMED CT 提供了一个巨大的、覆盖临床医学各个方面的多重继承体系（polyhierarchy）。它使用描述逻辑来定义概念，例如通过“发现部位”和“关联形态”等属性来形式化定义“障碍”。虽然它对临床常见发现的覆盖非常全面，但其明确的“疾病-表型”关联比 HPO 稀疏，很多关系是隐含在定义公理中的。提取这些信息需要复杂的逻辑推理，并且其复杂的多重继承结构也给构建一致的嵌入向量带来了挑战。

在实践中，HPO 因其针对[遗传病](@entry_id:273195)的专注性和高质量的策展数据而成为首选。SNOMED CT 可作为补充，尤其是在需要整合来自 EHR 的、更广泛的临床发现时。一个重要的结构性差异是，在 HPO 中，疾病和表型是分离的实体，而在 UMLS 和 SNOMED CT 中，它们共同存在于一个庞大的图谱中。这意味着在后两者中，进行简单的关系传递（例如，天真地进行[传递闭包](@entry_id:262879)）很容易引入语义漂移，需要仔细选择关系类型才能构建有意义的嵌入 [@problem_id:4618364]。

### 学习对齐：兼容性函数与模型架构

拥有了患者特征向量 $x$ 和疾病语义嵌入 $\psi(y)$ 之后，下一步是定义一个**兼容性函数** (compatibility function) $F(x, y)$，用于度量两者之间的匹配程度。这个函数的分数越高，表示患者 $x$ 患有疾病 $y$ 的可能性越大。

模型的选择会极大地影响其表达能力和泛化性能 [@problem_id:4618547]。常见的兼容性函数族包括：

- **双线性模型 (Bilinear Models)**：这是 ZSL 中最经典和常用的一类模型。其形式为 $F(x,y) = \phi(x)^{\top}W\psi(y)$，其中 $\phi(x)$ 是对原始患者特征 $x$ 的（可能非线性的）编码，而 $W$ 是一个可训练的参数矩阵。该模型通过矩阵 $W$ 捕捉了患者特征维度与疾病语义属性维度之间的复杂交互。例如，它可以学习到“某个特定基因变异（患者特征）主要与影响神经系统的疾病（语义属性）相关”。有趣的是，在某些理想化的[生成模型](@entry_id:177561)假设下，[双线性形式](@entry_id:746794)正是贝叶斯最优[判别函数](@entry_id:637860)的形式。例如，假设给定疾病 $y$ 的患者特征服从高斯分布 $x | y \sim \mathcal{N}(M \psi(y), \Sigma)$，其[对数似然](@entry_id:273783)可以分解为一个关于 $(x, \psi(y))$ 的[双线性](@entry_id:146819)项和一个只与 $\psi(y)$ 有关的项。这为双[线性模型](@entry_id:178302)的合理性提供了理论支持 [@problem_id:4618547]。

- **神经[网络模型](@entry_id:136956) (Neural Models)**：这类模型使用多层感知机 (MLP) 等神经网络来定义兼容性函数，例如 $F(x,y) = \text{MLP}([\phi(x); \psi(y)])$，其中 $[\cdot;\cdot]$ 表示向量拼接。根据**[通用近似定理](@entry_id:146978)**，只要有足够的神经元，一个带有[非线性激活函数](@entry_id:635291)的单隐藏层网络就可以近似任何连续函数。这使得神经网络模型具有极高的表达能力，能够学习任意复杂的匹配模式。然而，这种灵活性是一把双刃剑。在数据稀疏的罕见病场景下，高度灵活的模型更容易过拟合，需要更大量的训练数据和更强的[正则化技术](@entry_id:261393)来保证泛化能力 [@problem_id:4618547]。

### 学习过程：目标函数与优化

定义了模型架构后，我们需要一个**目标函数**（或[损失函数](@entry_id:136784)）来指导参数（如双[线性模型](@entry_id:178302)中的矩阵 $W$）的优化过程。学习的目标是，对于一个训练样本 $(x_i, y_i)$，其真实疾病 $y_i$ 的兼容性分数应高于任何不正确的疾病 $y_j$。

- **基于排序的损失 (Ranking-based Losses)**：这是 ZSL 中的主流方法，它将学习问题转化为一个排序问题。
    - **成对排序[铰链损失](@entry_id:168629) (Pairwise Ranking Hinge Loss)**：这是 **DeViSE** 等模型采用的方法。对于一个正样本对 $(x, y)$ 和一个负样本 $y'$，[损失函数](@entry_id:136784)的形式为 $\ell = \max(0, m - F(x, y) + F(x, y'))$，其中 $m$ 是一个预设的间隔 (margin)。这个[损失函数](@entry_id:136784)的目标是确保正样本对的得分至少比负样本对的得分高出 $m$。当这个条件满足时，损失为零；否则，模型会受到惩罚。对这个[损失函数](@entry_id:136784)求导，我们可以看到梯度只在间隔被“违反”时才非零。对于双[线性模型](@entry_id:178302)，此时的梯度会推动 $W$ 以使得 $\phi(x)$ 与 $\psi(y)$ 的[内积](@entry_id:750660)增大，同时与 $\psi(y')$ 的[内积](@entry_id:750660)减小 [@problem_id:4618439] [@problem_id:4618510]。
    - **加权近似排序损失 (Weighted Approximate-Rank of Pairwise loss, WARP)**：**ALE** 模型采用这种更精细的损失。它通过采样来近似估计正确标签在排序列表中的位置，并对排在列表顶部的错误给予更大的惩罚。这使得模型更专注于修正那些最容易混淆的错误 [@problem_id:4618510]。

- **基于概率/对比的损失 (Probabilistic/Contrastive Losses)**：
    - **InfoNCE 损失**：这是一种流行的[对比学习](@entry_id:635684)损失，它将 ZSL 视为一个多[分类问题](@entry_id:637153)。对于一个患者 $x$ 及其对应的正样本疾病 $y^+$ 和一批负样本疾病 $\{y^-\}$，InfoNCE 将其转化为一个分类任务：从这个批次中正确识别出 $y^+$。它使用 softmax 函数将兼容性分数转换为概率分布，并最小化真实标签的[负对数似然](@entry_id:637801)：
    $$ L_{\text{InfoNCE}} = -\log \frac{\exp(s(f(x), g(y^{+}))/\tau)}{\sum_{y' \in \mathcal{B}(x)} \exp(s(f(x), g(y'))/\tau)} $$
    其中 $s(\cdot, \cdot)$ 是相似度函数（如余弦相似度），$\tau$ 是一个温度超参数，$\mathcal{B}(x)$ 是包含一个正样本和多个负样本的批次。与[铰链损失](@entry_id:168629)不同，InfoNCE 的梯度会作用于批次中的**所有**负样本，其强度与它们的 softmax 概率成正比，从而鼓励在[嵌入空间](@entry_id:637157)中形成更具全局性的结构。InfoNCE 也与最大化患者嵌入和疾病嵌入之间[互信息](@entry_id:138718)的下界有深刻的理论联系 [@problem_id:4618581]。

- **基于回归的损失 (Regression-based Losses)**：
    - **[平方误差损失](@entry_id:178358) (Squared Error Loss)**：以 **ESZSL** 为代表的一些方法将问题构建为岭回归。它们学习一个映射，使得患者特征经过该映射后，与对应的疾病语义嵌入的平方误差最小。这类方法通常伴有正则化项，并且一个显著的优点是其解常常具有[闭式](@entry_id:271343)形式，避免了迭代优化 [@problem_id:4618510]。

### 提升泛化的先进机制

为了使模型能够从已见类别泛化到未见类别，必须严格控制模型的复杂性，并引入能够反映问题本质的[归纳偏置](@entry_id:137419)。

- **正则化以促进泛化**：在双线性模型 $F(x,y) = \phi(x)^{\top}W\psi(y)$ 中，对矩阵 $W$ 施加结构性约束是提升泛化能力的关键。从[统计学习理论](@entry_id:274291)的角度来看，这些约束通过减小[假设空间](@entry_id:635539)的**雷德梅克复杂度** (Rademacher complexity) 来收紧[泛化界](@entry_id:637175) [@problem_id:4618426]。
    - **低秩约束 (Low-rank constraint)**：通过惩罚 $W$ 的**[核范数](@entry_id:195543)** (nuclear norm) $\|W\|_*$ 来鼓励 $W$ 是低秩的。一个低秩的 $W$ 可以分解为 $W = UV^\top$，其中 $U$ 和 $V$ 的列数远小于原始维度。这在机制上意味着模型被迫学习一个共享的、低维的潜在空间。患者[特征和](@entry_id:189446)疾病属性首先被投影到这个潜在空间中（分别为 $U^\top\phi(x)$ 和 $V^\top\psi(y)$），然后再计算它们的[内积](@entry_id:750660)。这极大地减少了模型参数量，有效地约束了模型，迫使其学习更鲁棒和可迁移的跨模态关联 [@problem_id:4618426]。
    - **稀疏约束 (Sparsity constraint)**：通过惩罚 $W$ 的**[L1范数](@entry_id:143036)** $\|W\|_1$ 来鼓励 $W$ 中的许多元素为零。这相当于在患者特征和疾病语义属性之间进行特征选择，只保留最关键的少数关联，从而避免了过拟合和对噪声的敏感性。

- **利用标签流形结构**：**疾病标签流形假说** (label manifold hypothesis) 提出，具有相似病理生理学机制的疾病在语义空间中也应该彼此靠近，共同构成一个低维流形 [@problem_id:4618355]。我们可以利用生物学知识构建一个疾病图，其中边的权重 $w_{yy'}$ 代表疾病 $y$ 和 $y'$ 的相似度。为了让模型学习到的表示尊重这个固有的生物学结构，我们可以在[损失函数](@entry_id:136784)中加入一个**图[拉普拉斯正则化](@entry_id:634509)项**：
  $$ \mathcal{L}_{\text{manifold}} = \sum_{y, y' \in \mathcal{Y}} w_{yy'} \|g(y) - g(y')\|_2^2 $$
  其中 $g(y)$ 是模型学习到的疾病 $y$ 的嵌入表示（例如，在双线性模型中可以是 $W\psi(y)$）。这个正则项会惩罚那些将生物学上相似的疾病映射到[嵌入空间](@entry_id:637157)中相距很远的位置的参数。通过在**所有**疾病（包括未见疾病）上施加这个约束，它将流形结构从已见类别传播到未见类别，从而为零样本预测提供了强大的[归纳偏置](@entry_id:137419)。

### 方法论的严谨性：在评估中避免信息泄露

ZSL 的评估极易出错，不恰当的评估流程会导致性能被严重高估。最常见的陷阱是**信息泄露** (information leakage) [@problem_id:4618584]。

- **实例级交叉验证的谬误**：标准的 k 折[交叉验证](@entry_id:164650) (CV) 是通过随机划分**样本实例**来进行的。如果在 ZSL 场景中对已见类别的所有样本执行此操作，那么每个验证折中都会包含训练折中已经出现过的**类别**。这样的评估检验的是模型对“已见类别的新样本”的泛化能力，即估计的是 $R_{\mathrm{seen}}(\theta)$，而不是 ZSL 的核心目标——对“未见类别”的泛化能力 $R_{\mathrm{unseen}}(\theta)$。因此，使用这种方式选择的超参数是针对错误的目标进行优化的，得到的性能评估也是无效的。

- **正确的协议：按类别划分的[交叉验证](@entry_id:164650)**：为了忠实地模拟 ZSL 的设定，[交叉验证](@entry_id:164650)必须在**类别层面**进行划分。正确的做法是，将**已见类别**集合 $\mathcal{L}_{\mathrm{seen}}$ 划分为 $K$ 个不相交的子集 $\{\mathcal{L}_1, \dots, \mathcal{L}_K\}$。在第 $j$ 次验证中，模型在除了 $\mathcal{L}_j$ 之外的所有类别上进行训练，然后在 $\mathcal{L}_j$ 对应的样本上进行验证。这个“留出一组类别”(leave-labels-out) 的方法确保了[验证集](@entry_id:636445)中的类别对于模型来说总是“未见的”，从而为 ZSL 性能提供了无偏的估计。

- **[嵌套交叉验证](@entry_id:176273)与数据卫生**：为了进行严格的[超参数调优](@entry_id:143653)和性能评估，应采用**嵌套的按类别划分 CV**。
    - **外层循环**用于评估最终性能。它将 $\mathcal{L}_{\mathrm{seen}}$ 划分为[训练集](@entry_id:636396)和测试集（例如，80% 的类别用于训练，20% 用于测试）。
    - **内层循环**用于超参数选择。它只作用于外层循环的[训练集](@entry_id:636396)，并再次按类别进行划分来寻找最佳超参数。
    此外，任何[数据依赖](@entry_id:748197)的预处理步骤（如特征归一化、基于患者数据构建属性向量等）都必须在每个内层循环的训练数据上**重新计算**，以防止任何关于验证集或[测试集](@entry_id:637546)的[信息泄露](@entry_id:155485)到训练过程中。

遵循这些严谨的评估原则，是确保 ZSL 研究在罕见病诊断等高风险应用中具有可靠性和实际价值的基石。