## 应用与跨学科连接

在前面的章节中，我们已经探讨了临床文本[词嵌入](@entry_id:633879)模型的基本原理和机制。我们学习了如何将语言的离散单元（单词或子词）转换为高维空间中的密集向量，以及这些向量如何通过捕捉共现模式来编码语义关系。然而，这些模型的核心价值在于它们能够解决现实世界中的问题。本章旨在通过一系列应用导向的场景，展示这些核心原理在多样化、真实且跨学科的临床和生物医学信息学背景下的实际应用、扩展和整合。我们的目标不是重复讲授核心概念，而是阐明它们在从[预测建模](@entry_id:166398)到模型评估，再到实际部署等一系列复杂任务中的巨大效用。

### 核心临床自然语言处理任务

[词嵌入](@entry_id:633879)最直接的价值体现在其能够驱动核心的临床自然语言处理（NLP）任务，将非结构化的文本转化为可计算的、有意义的表征。

#### 从词语到患者级别的特征工程

单个[词嵌入](@entry_id:633879)的效用可以通过聚合来扩展，从而为整个文档（如临床笔记）或患者创建一个固定长度的[向量表示](@entry_id:166424)。这种文档级别的嵌入是下游预测任务（如诊断预测、风险分层或预后评估）的基石。构建这种表示有多种策略，每种策略都旨在从不同的角度捕捉文档的语义内容。

一种常见的方法是计算文档中所有[词嵌入](@entry_id:633879)的加权平均值。简单地取平均值可能会被高频但信息量低的词（如“the”、“is”）所主导。为了解决这个问题，可以使用“[词频-逆文档频率](@entry_id:634366)”（Term Frequency-Inverse Document Frequency, [TF-IDF](@entry_id:634366)）权重。[TF-IDF](@entry_id:634366)通过降低在整个语料库中普遍存在的词的权重，同时提升在特定文档中频繁出现但在其他地方罕见的词的权重，从而突显出文档的“关键词”。因此，[TF-IDF](@entry_id:634366)加权的平均嵌入向量能够更准确地反映文档的语义核心。

然而，文档的含义不仅仅是其词语的平均意义。文本中的语义多样性或分散性也可能包含有价值的诊断信息。例如，一篇笔记如果同时涉及糖尿病和心脏病学的概念，其语义的广度本身就是一种信号。这种分散性可以通过计算文档中所有[词嵌入](@entry_id:633879)的元素级标准差来量化。一个标准差较大的[向量表示](@entry_id:166424)其成分词在语义空间中分布广泛。

此外，某些极端语义信号可能至关重要。例如，在检测药物不良反应时，即使是单个表示严重过敏反应的词也比笔记中其他所有内容都重要。为了捕捉这种信号，可以采用元素级[最大池化](@entry_id:636121)（element-wise maximum pooling），即沿着嵌入的每个维度，取文档中所有词向量在该维度上的最大值。这个[最大池化](@entry_id:636121)向量捕捉了文本中存在的“最强”语义特征。

通过将这三种（或更多）不同类型的聚合向量——加权平均、标准差和[最大池化](@entry_id:636121)向量——拼接在一起，我们可以为每个临床笔记创建一个丰富的、多方面的特征向量。这个向量随后可以被输入到标准分类器（如逻辑回归）中，用于预测患者的诊断等任务。在训练此类模型之前，通常需要进行[特征选择](@entry_id:177971)，例如使用[互信息](@entry_id:138718)（Mutual Information）来识别与目标标签最相关的特征维度，从而提高模型的泛化能力和[可解释性](@entry_id:637759)。[@problem_id:2389770]

#### 实体标准化与消歧

临床文本中充满了缩写、同义词和多义词（一个词有多种含义），这给[数据标准化](@entry_id:147200)带来了巨大挑战。例如，“crown”一词在牙科记录中既可以指牙齿的解剖结构（牙冠），也可以指修复牙齿的程序（放置牙冠）。实体标准化（或称实体链接）的目标是将这些模糊的文本提及（mentions）准确地映射到标准医学术语体系（如SNOMED CT、UMLS）中的唯一概念。

一个先进的实体[标准化流](@entry_id:272573)程通常结合了上下文信息和外部知识。首先，使用命名实体识别（NER）模型在文本中定位出如“crown”这样的实体提及。然后，系统会从SNOMED CT等知识库中检索一组候选概念。

此处的关键挑战是消歧。现代方法通过利用由[大型语言模型](@entry_id:751149)（如基于Transformer的模型）生成的上下文感知嵌入来解决这个问题。系统会为实体提及周围的文本窗口（例如，“Placed temp crown on tooth 12”）创建一个上下文嵌入向量 $\mathbf{e}_{\text{ctx}}$。在更高级的系统中，例如在远程牙科场景中，来自远程操作的口腔内成像机器人捕获的视觉信号也可以被编码并融合到这个上下文中，从而创建一个多模态的上下文表示。

每个候选概念（如 $c_1$：“放置临时牙冠（程序）”和 $c_2$：“牙齿的牙冠（解剖结构）”）本身也由其在SNOMED CT中的描述性文本生成一个嵌入向量。然后，通过计算上下文嵌入 $\mathbf{e}_{\text{ctx}}$ 与每个候选概念嵌入 $\mathbf{e}_{c}$ 之间的余弦相似度，来评估上下文与每个候选概念的匹配程度。

为了做出最终决定，系统通常采用贝叶斯推断框架。给定上下文 $\text{ctx}$，候选概念 $c$ 的后验概率 $P(c \mid \text{ctx})$ 正比于其似然 $P(\text{ctx} \mid c)$ 和先验概率 $P(c)$ 的乘积。似然通常被建模为相似度得分的函数（例如，通过softmax变换），而先验概率则可以从历史数据中估计，反映了不同概念在临床实践中的常见程度。此外，上下文中的明确线索（如动词“placed”）可以用来施加类型约束，进一步为“程序”类型的概念提供证据。

最终，系统选择后验概率最高的候选概念。为了确保临床应用的安全性，决策过程通常是成本敏感的。如果将一个实体错误地分配给一个概念的代价很高，系统可能会设定一个后验概率阈值。只有当最可能的概念的后验概率超过这个阈值时，系统才会自动进行分配；否则，它将“弃权”并将该案例提交给人类专家进行审查。这个过程确保了在不确定的情况下，系统的决策会偏向于安全和谨慎。[@problem_id:4694073]

### 增强与评估嵌入质量

除了直接应用于下游任务，[词嵌入](@entry_id:633879)的另一个重要研究方向是开发增强其表征能力和评估其临床有效性的方法。一个好的嵌入模型不仅要在预测任务中表现出色，其内部的几何结构也应与临床知识和逻辑相一致。

#### 融合分布式语义与结构化知识

[词嵌入](@entry_id:633879)主要通过分析大规模文本中的词语共现模式来学习语义，这被称为分布式语义。然而，医学领域拥有大量结构化的知识库，如UMLS和SNOMED CT。将这两种信息来源相结合，可以创建出更强大、更符合临床实际的嵌入。

##### 嵌入后处理（Retrofitting）与本体对齐

一种有效的方法被称为“后处理”（retrofitting）。该方法从一个预训练好的、基于文本的嵌入模型开始，然后使用一个外部知识图谱（如UMLS同义词关系图）对其进行微调。其核心思想是，如果两个词在知识图谱中是同义词，那么它们的嵌入向量在空间中也应该是相近的。

这可以通过一个优化目标来实现。该目标函数包含两个部分：一个“保真度”项，惩罚新的嵌入向量 $v_i$ 与其原始预训练向量 $v_i^0$ 之间的差异；以及一个“平滑度”项，惩罚在知识图谱中互为同义词的两个词的嵌入向量 $v_i$ 和 $v_j$ 之间的距离。目标函数的形式通常如下：
$$
\mathcal{L}(v) = \sum_{i \in V} \alpha_i \lVert v_i - v_i^{0} \rVert^2 + \lambda \sum_{(i,j) \in E} \lVert v_i - v_j \rVert^2
$$
其中，$V$ 是词汇表，$E$ 是同义词关系边集，$\alpha_i$ 和 $\lambda$ 是控制两项相对重要性的超参数。最小化这个目标函数，相当于在保持原始分布式语义的同时，将作为同义词的向量“拉”得更近。从几何上看，每个更新后的向量 $v_i$ 成为了其原始向量 $v_i^0$ 和其在图谱中邻居向量平均值的一个加权平均。这种方法能够有效地将结构化本体知识注入到[向量空间](@entry_id:177989)中，使嵌入的几何结构更好地反映公认的医学关系。[@problem_id:4617656]

##### 融合非结构化文本与结构化电子病历数据

患者的临床画像并非仅存于自由文本中，同样也存在于结构化的电子病历（EHR）数据中，如诊断代码（ICD）、药品代码（RxNorm）和实验室检测代码（LOINC）。为了进行精确的患者表型分析（phenotyping），融合这两种数据源至关重要。

一种直接的方法是**拼接**（concatenation）。我们可以为患者的自由文本笔记生成一个嵌入向量 $x$，同时为他们的结构化代码集生成另一个嵌入向量 $y$（例如，使用知识图谱嵌入方法）。然后，将这两个向量拼接成一个更长的向量 $[x; y]$，并将其输入到下游的分类器中。在理想的统计假设下（例如，给定表型时，文本和代码是条件独立的），这种方法理论上是最优的，因为它保留了来自两个数据源的所有信息，并且能够比任何单一数据源实现更好的分类性能。

然而，简单的拼接会显著增加特征维度，当训练数据有限时，这可能会导致[过拟合](@entry_id:139093)（即所谓的“维度灾难”）。一种替代方案是**学习融合**（learned fusion），它通过可训练的矩阵 $W_x$ 和 $W_y$ 将高维的 $x$ 和 $y$ 投影到一个共享的、更低维的融合空间中：$f = W_x x + W_y y$。这种方法可以学习到保留判别信息的最优投影，从而降低模型复杂性，提高泛化能力。

在处理现实世界中质量参差不齐的临床数据时，一种更为复杂的**自适应门控**（adaptive gating）机制可能更为有效。例如，对于某个患者，其临床笔记可能非常简短且信息量不足，但其结构化代码却很完整。对于另一个患者，情况可能正好相反。自适应[门控机制](@entry_id:152433)可以根据每个数据源的质量[元数据](@entry_id:275500)（如笔记长度、代码数量等）为每个患者动态计算一个权重 $\alpha$，并生成一个融合特征 $f = \alpha W_x x + (1 - \alpha) W_y y$。这使得模型能够动态地、因人而异地侧重于更可靠的信息来源，从而提高整体的鲁棒性和准确性。[@problem_id:4617652]

#### 探测量化临床语义的有效性

一个高质量的临床[词嵌入](@entry_id:633879)模型不仅要在下游任务中取得高分，其内部的[向量空间](@entry_id:177989)结构本身也应该能够反映细微的临床逻辑和语义关系。因此，开发能够“探查”[嵌入空间](@entry_id:637157)内部质量的评估方法至关重要。

##### 评估语义邻近区域的医学一致性

分布式假设的核心观点是，具有相似上下文的词语会有相似的嵌入向量。在临床领域，这这意味着我们期望相关的医学概念（例如，都属于“降糖药”的几种药物）在[嵌入空间](@entry_id:637157)中形成紧密的聚类。我们可以通过最近邻分析来系统地验证这一点。给定一个目标词（如“metformin”，[二甲双胍](@entry_id:154107)），我们可以使用余弦相似度计算其在词汇表中的 $k$ 个最近邻。我们期望这些邻居在医学上是相关的（例如，“glipizide”格列吡嗪和“insulin”胰岛素）。

为了将这种直观的评估转化为严谨的科学审计，可以设计一个全面的方案。首先，将词汇表中的每个词映射到一个标准的医学本体（如UMLS语义类型或ICD章节）。然后，从词汇表中随机抽样一系列目标词，并计算其最近邻区域的“纯度”，即邻居中与目标词共享相同[本体](@entry_id:264049)标签的比例。为了确保结果的可靠性，这个过程需要严格的[统计控制](@entry_id:636808)：使用自助法（bootstrap）来估计纯度得分的[置信区间](@entry_id:138194)；通过[置换检验](@entry_id:175392)（permutation test）来确定观察到的纯度是否显著高于随机情况；并要求多位经过认证的临床医生对邻近区域的语义一致性进行独立评分，通过计算Cohen's $\kappa$ 系数来确保评估者之间的一致性。这种严谨的审计流程是验证临床嵌入模型构造效度（construct validity）的黄金标准。[@problem_id:4617690]

##### 测试关系型知识：词语类比

词[嵌入空间](@entry_id:637157)的一个显著特性是它有时能够通过简单的向量运算来捕捉词语之间的类比关系。著名的例子是“king - man + woman ≈ queen”。在临床领域，这种特性可以被用来测试模型是否学到了诸如“药物:治疗类别”之类的关系。例如，我们可以构建一个类比任务：“aspirin : antiplatelet :: metoprolol : ?”。理论上，这个问题的答案可以通过计算向量 $v_{\text{metoprolol}} + v_{\text{antiplatelet}} - v_{\text{aspirin}}$ 并寻找与其最接近的词向量来找到。如果模型的答案是“beta_blocker”（β-受体阻滞剂），这将表明模型成功地捕捉到了这种药物-类别的线性关系。

然而，必须批判性地看待这种方法。它假设语义关系在整个[向量空间](@entry_id:177989)中是线性且可传递的，这个假设在复杂的临床文本中可能不成立。多义性（例如，阿司匹林既是抗血小板药又是镇痛药）、不一致的术语标准化以及强烈的共现模式（例如，药物与其治疗的疾病之间的关联可能比其与药理类别的关联更强）都可能干扰或破坏这种脆弱的线性结构。因此，虽然词语类比是探查嵌入模型关系知识的有用工具，但它并非一个完美的评估指标。[@problem_id:4617679]

##### 评估对断言和不确定性的表征

临床决策严重依赖于对信息确定性的判断。医生在记录中会使用诸如“可能”、“疑似”或“排除”之类的词语来表达不确定性。一个优秀的临床嵌入模型应该能够区分“肺炎”的确定性陈述和“可能肺炎”的不确定性陈述。

为了测试这一点，可以在预处理阶段创建复合词元（composite tokens）。例如，将文本中所有被标注为不确定的“pneumonia”替换为“possible_pneumonia”，而确定性的提及则保持为“pneumonia”。在这样的语料库上训练模型后，我们可以检验 $\mathbf{v}(\text{possible\_pneumonia})$ 的最近邻是否富含其他不确定性线索词（如“likely”、“suggests”），而 $\mathbf{v}(\text{pneumonia})$ 的最近邻则富含确定性线索词（如“confirmed”、“diagnosed”）。

这种评估需要严谨的统计设计。可以定义一个检验统计量，例如，比较“possible_pneumonia”的邻域和“pneumonia”的邻域中不确定性词汇的比例差异。为了确定这个差异的显著性，可以构建一个零假设模型，例如，通过在语料库中[随机置换](@entry_id:268827)所有提及的断言标签，然后重新训练嵌入并计算差异，从而生成一个[零分布](@entry_id:195412)。对多个医学状况重复此测试，并使用如错误发现率（False Discovery Rate, FDR）控制之类的多重比较校正，可以有力地证明模型是否真正学到了区分确定性和不确定性的细微差别。[@problem_id:4617649]

### 模型部署与生命周期管理的高级主题

将在实验室中构建的模型成功部署到真实的临床环境中，并长期维持其性能和安全性，需要解决一系列高级的工程和伦理挑战。

#### 确保模型的公平性与公正性

[词嵌入](@entry_id:633879)模型是从人类编写的文本中学习的，因此它们不可避免地会学习并可能放大其中存在的社会偏见。在临床应用中，这可能导致极其有害的后果。例如，如果模型将与特定人口统计群体相关的词语（如种族或民族）与负面临床结果（如“并发症”、“死亡”）更紧密地关联起来，那么依赖这些嵌入的下游预测模型可能会对这些群体做出不公平的预测，从而加剧健康不平等。

为了审计这种偏见，可以将在社会语言学中使用的[词嵌入](@entry_id:633879)关联测试（Word Embedding Association Test, WEAT）改编到临床环境中。WEAT通过比较两组目标词（如，代表不同种族群体的词集 $T_{\text{Black}}$ 和 $T_{\text{White}}$）与两组属性词（如，代表负面结果的词集 $A$ 和代表正面结果的词集 $B$）之间的关联差异来量化偏见。具体来说，可以为每个目标词计算一个关联分数，即其与负面结果词的平均余弦相似度减去其与正面结果词的平均余弦相似度。然后，计算两组目标词的平均关联分数的差异，并将其除以所有分数的标准差，得到一个标准化的效应大小。这个效应大小提供了一个量化指标，用于衡量嵌入模型中存在的与特定人群相关的潜在偏见，这是迈向构建更公平、更负责任的临床AI系统的关键一步。[@problem_id:4617699]

#### 适应新领域与不断演化的语言

医学知识和临床实践并非一成不变。新的药物、疗法和诊断术语不断涌现，导致临床语言随时间发生“概念漂移”（concept drift）。一个在2020年训练的模型可能无法很好地理解2025年的临床笔记。此外，一个在大型学术医疗中心数据上训练的通用模型，可能需要适应某个特定社区医院独特的缩写和行话。

##### 高效的[领域自适应](@entry_id:637871)

当需要将一个大型预训练模型（如ClinicalBERT）适应到一个数据量有限的特定领域时，完全微调（full fine-tuning，即更新模型的所有参数）风险很高，因为它很容易导致“[灾难性遗忘](@entry_id:636297)”——模型为了学习新领域知识而忘记了其在预训练阶段学到的大量通用医学知识。

一种更参数高效（parameter-efficient）的策略是使用**适配器（adapters）**。适配器是插入到预训练模型每一层内部的、小型的、可训练的神经网络模块。在自适应过程中，庞大的预训练模型参数保持冻结，只有这些小型的适配器模块被训练。由于适配器引入的参数量极少（通常不到总参数的1%），这种方法极大地降低了[灾难性遗忘](@entry_id:636297)的风险，同时又能有效地捕捉特定领域的新知识。从线性代数的角度看，适配器只能对模型的每一层进行低秩（low-rank）更新，这在数学上限制了模型能够学习的改变的复杂性，使其非常适合在保留核心知识的同时学习局部的、系统的变化。[@problem_id:4617726]

##### [持续学习](@entry_id:634283)与时间漂移

为了应对语言随时间的持续演变，模型需要具备**持续学习（continual learning）**的能力。其目标是在新数据上更新模型，使其适应新的语言模式，同时不损害在旧数据上学到的知识。这同样是一个对抗[灾难性遗忘](@entry_id:636297)的问题。

一种强大的方法是**弹性权重巩固（Elastic Weight Consolidation, EWC）**，它源于贝叶斯推断的原理。其核心思想是，在更新模型参数时，对那些被认为对先前任务“重要”的参数施加一个二次惩罚，从而限制它们的改变。参数的重要性可以通过费雪信息矩阵（Fisher information matrix）的对角线来量化，该矩阵衡量了每个参数对模型在旧数据上输出的敏感度。在持续学习新一批临床笔记时，模型的优化目标函数会增加一个惩罚项，该惩罚项正比于每个参数的重要性及其与旧模型参数值的差异的平方。这种方法允许对新词（其重要性为零）进行无约束的学习，同时保护了构成模型核心知识的旧词的嵌入，从而在可塑性（适应新知识）和稳定性（保留旧知识）之间取得了平衡。[@problem_id:4617735]

#### 生产环境中的工程考量

将复杂的嵌入模型部署到繁忙的医院信息系统中，需要仔细考虑效率、[互操作性](@entry_id:750761)和安全性。

##### 用于提升效率的[知识蒸馏](@entry_id:637767)

大型、最先进的嵌入模型（例如，基于Transformer的上下文模型）虽然功能强大，但计算成本高昂，可能无法满足某些临床应用（如实时用户界面中的建议）的低延迟要求。**[知识蒸馏](@entry_id:637767)（Knowledge Distillation）**是一种有效的[模型压缩](@entry_id:634136)技术，用于将一个大型、复杂的“教师”模型的知识迁移到一个小型的、更快的“学生”模型中。

在这个过程中，学生模型不仅学习预测真实标签，还学习模仿教师模型的输出。这可以通过一个复合[损失函数](@entry_id:136784)来实现。一个分量是“表征对齐”损失，它鼓励学生的静态[词嵌入](@entry_id:633879)向量接近教师模型为该词生成的上下文向量的平均值。另一个分量是“关系匹配”损失，它使用KL散度等度量，鼓励学生模型学习到的词间相似度分布与教师模型所见的分布相匹配。通过这种方式，学生模型可以在保持较小规模和较高速度的同时，继承教师模型的许多精细语义知识，使其能够在资源受限的环境中进行部署。[@problem_id:4617695]

##### 对齐不同的[嵌入空间](@entry_id:637157)

在大型医疗系统中，不同的部门或研究项目可能会使用由不同算法（如BioWordVec和ClinicalBERT）或在不同数据集上训练的嵌入模型。这导致了互操作性问题：来自不同模型的向量无法直接比较或组合。**无监督嵌入对齐**的目标是学习一个变换（通常是一个[正交矩阵](@entry_id:169220)$W$），将一个[嵌入空间](@entry_id:637157)映射到另一个空间，同时保持其内部的几何结构（即，词语间的相似度关系）。

这个任务可以被形式化为一个分布[匹配问题](@entry_id:275163)。目标是找到一个[正交矩阵](@entry_id:169220) $W$（正交性确保了[内积](@entry_id:750660)和距离不变），使得变换后的源嵌入 $\{W x_i\}$ 的分布与目标嵌入 $\{y_j\}$ 的分布尽可能接近。可以使用诸如[最大均值差异](@entry_id:636886)（Maximum Mean Discrepancy, MMD）之类的非参数分布度量来量化两个点云分布之间的差异。通过最小化这个差异，同时强制施加正交约束，可以找到一个能有效对齐两个空间、使它们能够互操作的线性映射。[@problem_id:4617657]

##### 部署策略与数据治理

在一个真实的医院环境中部署NLP系统，技术性能只是挑战的一部分。数据治理、安全性和可靠性至关重要。一个健全的部署计划必须在设计上就满足这些要求。

例如，一个支持实时决策的系统必须遵守严格的延迟服务水平目标（SLO），如P99延迟低于150毫秒。这要求采用低延迟架构，例如预先计算并缓存嵌入，而不是在每次请求时实时生成。为了处理负载突发，需要通过排队论进行容量规划，确保有足够的副本在高峰期也能保持系统稳定。

根据HIPAA等法规，所有包含受保护健康信息（PHI）的数据及其衍生表示（包括[词嵌入](@entry_id:633879)）都必须保留在医院的本地网络内，并对传输和静态数据进行强加密。

为了确保患者安全和模型可靠性，模型更新必须通过一个保守的、分阶段的流程进行，例如，先在“影子模式”下运行新模型以比较其输出，然后进行小规模的“金丝渠道”发布，最后通过蓝绿部署（blue-green deployment）进行切换，并具备即时回滚到旧版本的能力。这些工程实践对于在临床这种高风险环境中负责任地部署AI至关重要。[@problem_id:4617671]

### 结论：选择正确的评估范式

本章探讨了临床[词嵌入](@entry_id:633879)模型的广泛应用，从核心NLP任务到复杂的部署挑战。一个反复出现的主题是评估的重要性。我们如何知道一个嵌入模型是否真的“好”？

评估方法大致可分为两类：**内在评估（intrinsic evaluation）**和**外在评估（extrinsic evaluation）**。内在评估关注于[嵌入空间](@entry_id:637157)本身的属性，独立于任何特定任务。本章中讨论的语义邻近区域一致性审计、词语类比测试以及对不确定性的探查都属于此类。这些方法对于模型的快速开发和调试非常有用，因为它们能直接揭示模型的几何结构和语义表征能力。

然而，内在评估的根本局限在于，它们与模型的最终临床效用是脱节的。一个在词语类比任务上得分很高的模型，不一定能在预测患者败血症风险的任务中表现出色。**外在评估**通过在真实的下游临床任务（如命名实体识别、表型分析、代码分配）上衡量模型的性能来弥补这一差距。

当临床效用可以通过一个明确的、考虑了任务特定数据分布（$P_{\text{task}}$）和非对称成本结构（$u$）的[效用函数](@entry_id:137807) $U$ 来量化时，外在评估成为衡量模型价值的黄金标准。它直接通过在与实际应用场景相匹配的数据和条件下，对整个系统（嵌入模型+下游分类器）进行端到端的测试，来估计这个[效用函数](@entry_id:137807)。相比之下，内在指标既不依赖于 $P_{\text{task}}$ 也不编码 $u$，因此它们本质上只是临床效用的一个间接且不完美的代理。因此，在为高风险的临床应用选择模型时，尽管内在评估有其价值，但最终的决策必须基于严谨的外在评估，因为它能最忠实地反映模型在现实世界中的实际价值和影响。[@problem_id:4617686]