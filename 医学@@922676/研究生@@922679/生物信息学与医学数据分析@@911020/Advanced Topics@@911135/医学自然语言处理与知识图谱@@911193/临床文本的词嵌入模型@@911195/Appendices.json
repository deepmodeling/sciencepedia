{"hands_on_practices": [{"introduction": "理论知识是基础，但真正的理解来自于实践。在构建复杂的词嵌入模型之前，掌握如何用统计量来量化词语之间的关联强度至关重要。点互信息（Pointwise Mutual Information, PMI）是信息论中的一个基本工具，它衡量词语的共现频率是否高于偶然，这是判断语义关联性的一个关键信号。本练习 [@problem_id:4617647] 将指导你亲手计算并解读 PMI 值，从而为更复杂的分布语义模型打下坚实的基础。", "problem": "在为临床文本构建词嵌入模型时，一种为词-上下文共现推导信息权重的常用方法是使用点互信息 (PMI) 及其非负变体正点互信息 (PPMI)。根据信息论，两个离散事件 $w$ 和 $c$ 之间的 PMI 定义为其联合概率与边际概率乘积之比的自然对数，即 $PMI(w,c) = \\ln\\left(\\frac{P(w,c)}{P(w)P(c)}\\right)$。正点互信息定义为 $PPMI(w,c) = \\max(PMI(w,c), 0)$。在经验语料库中，概率通过最大似然法从计数中估计，$P(w) \\approx \\frac{n(w)}{N}$，$P(c) \\approx \\frac{n(c)}{N}$，以及 $P(w,c) \\approx \\frac{n(w,c)}{N}$，其中 $n(w)$ 是词 $w$ 的计数，$n(c)$ 是上下文 $c$ 的计数，$n(w,c)$ 是在一个固定的、对称的窗口策略内 $w$ 和 $c$ 的共现计数，而 $N$ 是在相同采样方案下对边际计数有贡献的总词元位置数。\n\n您正在分析一个由临床医生撰写的去标识化笔记语料库，以决定一个候选词-上下文对是否应在一个正点互信息加权的分解模型中被保留为一个强特征。给定 $n(w,c) = 50$，$n(w) = 200$，$n(c) = 300$ 和 $N = 100{,}000$，请使用自然对数 $\\ln$ 计算 $PMI(w,c)$，然后计算 $PPMI(w,c)$。根据计算出的值，判断在独立性基线下，该词对是否可能代表一个具有临床意义的关联。将您的数值结果表示为一个行矩阵 $\\begin{pmatrix}PMI  PPMI\\end{pmatrix}$，并将每个条目四舍五入到四位有效数字。无需单位。", "solution": "这个问题提法明确，具有科学依据，并为求解提供了所有必要信息。它是计算语言学和生物信息学中使用的信息论标准定义的直接应用。\n\n第一步是计算给定词-上下文对 $(w,c)$ 的点互信息 ($PMI$) 。$PMI$ 的定义如下：\n$$PMI(w,c) = \\ln\\left(\\frac{P(w,c)}{P(w)P(c)}\\right)$$\n问题指出，在经验环境中，这些概率是使用最大似然估计从计数中估算出来的。这些估计的公式如下：\n$$P(w) \\approx \\frac{n(w)}{N}$$\n$$P(c) \\approx \\frac{n(c)}{N}$$\n$$P(w,c) \\approx \\frac{n(w,c)}{N}$$\n其中 $n(w)$ 是词 $w$ 的计数，$n(c)$ 是上下文 $c$ 的计数，$n(w,c)$ 是它们的共现计数，而 $N$ 是相关词元位置的总数。\n\n将这些经验概率估计值代入 $PMI$ 公式，我们得到一个以计数表示的表达式：\n$$PMI(w,c) \\approx \\ln\\left(\\frac{\\frac{n(w,c)}{N}}{\\left(\\frac{n(w)}{N}\\right)\\left(\\frac{n(c)}{N}\\right)}\\right)$$\n这个表达式可以通过将分子中的 $N$ 项与分母中的一个 $N$ 项相消来简化：\n$$PMI(w,c) \\approx \\ln\\left(\\frac{n(w,c) \\cdot N}{n(w) \\cdot n(c)}\\right)$$\n问题给出了以下的计数值：\n- $n(w,c) = 50$\n- $n(w) = 200$\n- $n(c) = 300$\n- $N = 100{,}000$\n\n我们将这些值代入简化后的公式：\n$$PMI(w,c) \\approx \\ln\\left(\\frac{50 \\cdot 100{,}000}{200 \\cdot 300}\\right)$$\n我们首先计算自然对数的参数：\n$$\\frac{50 \\cdot 100{,}000}{200 \\cdot 300} = \\frac{5{,}000{,}000}{60{,}000} = \\frac{500}{6} = \\frac{250}{3}$$\n现在，我们计算这个值的自然对数：\n$$PMI(w,c) \\approx \\ln\\left(\\frac{250}{3}\\right) \\approx \\ln(83.333...)$$\n$$PMI(w,c) \\approx 4.4228486...$$\n将此结果四舍五入到四位有效数字，我们得到 $4.423$。\n\n接下来，我们计算正点互信息 ($PPMI$)，其定义为：\n$$PPMI(w,c) = \\max(PMI(w,c), 0)$$\n由于我们计算出的 $PMI(w,c)$ 值约等于 $4.423$，大于 $0$，所以 $PPMI$ 将等于 $PMI$。\n$$PPMI(w,c) = \\max(4.423, 0) = 4.423$$\n\n$PMI$ 的值量化了观测到的共现概率 $P(w,c)$ 与在统计独立性假设下预期的共现概率 $P(w)P(c)$ 之间的差异。$PMI$ 值为 $0$ 表示独立。正值表示词和上下文的共现频率高于偶然预期的频率，暗示存在有意义的关联。负值表示它们的共现频率低于预期。在本例中，$PMI(w,c) \\approx 4.423$ 是一个强正值。这表明词-上下文对 $(w,c)$ 的共现率比它们独立时的预期共现率高出约 $\\exp(4.423) \\approx 83.3$ 倍。如此强的正相关表明，该词对不是随机偶然的产物，并且可能代表一种具有临床意义的关系，这使其成为在分解模型中保留的强候选特征。\n\n$PMI$ 和 $PPMI$ 的最终数值结果，已四舍五入到四位有效数字，按要求以行矩阵形式呈现。", "answer": "$$\\boxed{\\begin{pmatrix} 4.423  4.423 \\end{pmatrix}}$$", "id": "4617647"}, {"introduction": "理解了如何衡量词语关联后，下一步是探索模型如何学习这些关联并将其编码为向量。诸如 word2vec 等现代模型并非直接使用静态的 PMI 值，而是通过优化过程动态地学习稠密向量。本练习 [@problem_id:4617685] 深入到 Skip-Gram with Negative Sampling (SGNS) 算法的内部，让你通过手动执行一个学习步骤，直观地理解词向量是如何根据上下文共现信号进行迭代更新的。", "problem": "一个研究团队正在为一个由句子 $[\\text{\"no chest pain\"}, \\text{\"chest pain resolved\"}]$ 组成的小型临床语料库构建一个二维词嵌入模型的原型。他们使用带独立词输入和输出嵌入的 Skip-Gram 负采样 (SGNS) 目标函数。对于单个训练实例，他们选取中心词 \"chest\" 和正向上下文词 \"pain\"。假设在这一步中，单个负向上下文词被采样为 \"no\"。\n\n设 \"chest\" 的输入嵌入为 $v \\in \\mathbb{R}^{2}$，\"pain\" 的输出嵌入为 $w \\in \\mathbb{R}^{2}$，\"no\" 的输出嵌入为 $u \\in \\mathbb{R}^{2}$。初始嵌入为\n$$\nv = \\begin{pmatrix} 0.20 \\\\ -0.35 \\end{pmatrix}, \\quad\nw = \\begin{pmatrix} 0.10 \\\\ 0.30 \\end{pmatrix}, \\quad\nu = \\begin{pmatrix} -0.25 \\\\ 0.40 \\end{pmatrix}.\n$$\n设逻辑 sigmoid 函数为 $\\sigma(x) = \\frac{1}{1 + \\exp(-x)}$。对于一个正样本对和一个负样本，SGNS 损失函数定义为\n$$\nJ(v,w,u) = -\\ln\\big(\\sigma(w^{\\top} v)\\big) \\;-\\; \\ln\\big(\\sigma(-u^{\\top} v)\\big).\n$$\n从给定的初始值开始，对 $J$ 关于参数 $v$、$w$ 和 $u$ 执行一步全批量梯度下降，使用学习率 $\\eta = 0.05$，仅更新这三个向量并保持其他所有参数固定。在这次单步更新之后，使用相同的三元组 $(v,w,u)$ 和相同的正向/负向上下文词再次评估损失 $J$。\n\n更新后的损失 $J$ 的数值是多少？将您的答案四舍五入到四位有效数字。以纯数字形式表示您的答案，不带单位。", "solution": "用户提供的问题通过了所有验证标准。它在科学上基于机器学习的原理，特别是用于词嵌入的 Skip-Gram 负采样 (SGNS) 模型。该问题定义明确，包含了所有必要的数据和明确的目标。其语言客观，设置一致。因此，我将提供完整的解题过程。\n\n目标是计算经过一步全批量梯度下降后损失函数 $J$ 的值。对于一个中心词、一个正向上下文词和一个负向上下文词，损失函数由下式给出：\n$$\nJ(v,w,u) = -\\ln\\big(\\sigma(w^{\\top} v)\\big) \\;-\\; \\ln\\big(\\sigma(-u^{\\top} v)\\big)\n$$\n其中 $\\sigma(x) = \\frac{1}{1 + \\exp(-x)}$ 是逻辑 sigmoid 函数。\n\n需要更新的参数是向量 $v$、$w$ 和 $u$。对于学习率为 $\\eta$ 的参数 $\\theta$，梯度下降的更新规则是：\n$$\n\\theta_{\\text{new}} = \\theta - \\eta \\nabla_{\\theta} J\n$$\n\n首先，我们必须推导 $J$ 关于 $v$、$w$ 和 $u$ 的梯度。我们将使用链式法则以及 sigmoid 函数的导数性质 $\\frac{d}{dx}\\sigma(x) = \\sigma(x)(1 - \\sigma(x))$。\n\n我们来求关于 $w$ 的梯度：\n$$\n\\nabla_w J = \\frac{\\partial}{\\partial w} \\left[ -\\ln\\left(\\sigma(w^{\\top}v)\\right) \\right] = - \\frac{1}{\\sigma(w^{\\top}v)} \\cdot \\sigma(w^{\\top}v)(1-\\sigma(w^{\\top}v)) \\cdot \\frac{\\partial}{\\partial w}(w^{\\top}v)\n$$\n由于 $\\frac{\\partial}{\\partial w}(w^{\\top}v) = v$，上式可简化为：\n$$\n\\nabla_w J = -(1 - \\sigma(w^{\\top}v))v\n$$\n\n接下来，求关于 $u$ 的梯度：\n$$\n\\nabla_u J = \\frac{\\partial}{\\partial u} \\left[ -\\ln\\left(\\sigma(-u^{\\top}v)\\right) \\right] = - \\frac{1}{\\sigma(-u^{\\top}v)} \\cdot \\sigma(-u^{\\top}v)(1-\\sigma(-u^{\\top}v)) \\cdot \\frac{\\partial}{\\partial u}(-u^{\\top}v)\n$$\n由于 $\\frac{\\partial}{\\partial u}(-u^{\\top}v) = -v$，上式可简化为：\n$$\n\\nabla_u J = - (1 - \\sigma(-u^{\\top}v))(-v) = (1 - \\sigma(-u^{\\top}v))v\n$$\n\n最后，求关于 $v$ 的梯度。该梯度由损失函数中的两项贡献：\n$$\n\\nabla_v J = \\frac{\\partial}{\\partial v} \\left[ -\\ln(\\sigma(w^{\\top}v)) \\right] + \\frac{\\partial}{\\partial v} \\left[ -\\ln(\\sigma(-u^{\\top}v)) \\right]\n$$\n使用与上面相同的逻辑，但使用 $\\frac{\\partial}{\\partial v}(w^{\\top}v) = w$ 和 $\\frac{\\partial}{\\partial v}(-u^{\\top}v) = -u$：\n$$\n\\nabla_v J = -(1 - \\sigma(w^{\\top}v))w + (1 - \\sigma(-u^{\\top}v))u\n$$\n\n现在，我们代入初始值：\n$$\nv = \\begin{pmatrix} 0.20 \\\\ -0.35 \\end{pmatrix}, \\quad\nw = \\begin{pmatrix} 0.10 \\\\ 0.30 \\end{pmatrix}, \\quad\nu = \\begin{pmatrix} -0.25 \\\\ 0.40 \\end{pmatrix}, \\quad\n\\eta = 0.05\n$$\n\n**步骤 1：计算初始点积和 sigmoid 值。**\n点积为：\n$$\nw^{\\top}v = (0.10)(0.20) + (0.30)(-0.35) = 0.02 - 0.105 = -0.085\n$$\n$$\nu^{\\top}v = (-0.25)(0.20) + (0.40)(-0.35) = -0.05 - 0.14 = -0.19\n$$\nsigmoid 函数的参数为 $w^{\\top}v = -0.085$ 和 $-u^{\\top}v = 0.19$。\n$$\n\\sigma(w^{\\top}v) = \\sigma(-0.085) = \\frac{1}{1 + \\exp(0.085)} \\approx 0.478761\n$$\n$$\n\\sigma(-u^{\\top}v) = \\sigma(0.19) = \\frac{1}{1 + \\exp(-0.19)} \\approx 0.547359\n$$\n\n**步骤 2：计算梯度。**\n我们使用步骤 1 中的 sigmoid 值：\n$$\n\\nabla_w J = -(1 - 0.478761) \\begin{pmatrix} 0.20 \\\\ -0.35 \\end{pmatrix} = -0.521239 \\begin{pmatrix} 0.20 \\\\ -0.35 \\end{pmatrix} = \\begin{pmatrix} -0.104248 \\\\ 0.182434 \\end{pmatrix}\n$$\n$$\n\\nabla_u J = (1 - 0.547359) \\begin{pmatrix} 0.20 \\\\ -0.35 \\end{pmatrix} = 0.452641 \\begin{pmatrix} 0.20 \\\\ -0.35 \\end{pmatrix} = \\begin{pmatrix} 0.090528 \\\\ -0.158424 \\end{pmatrix}\n$$\n$$\n\\nabla_v J = -(1 - 0.478761) \\begin{pmatrix} 0.10 \\\\ 0.30 \\end{pmatrix} + (1 - 0.547359) \\begin{pmatrix} -0.25 \\\\ 0.40 \\end{pmatrix}\n$$\n$$\n\\nabla_v J = -0.521239 \\begin{pmatrix} 0.10 \\\\ 0.30 \\end{pmatrix} + 0.452641 \\begin{pmatrix} -0.25 \\\\ 0.40 \\end{pmatrix} = \\begin{pmatrix} -0.052124 \\\\ -0.156372 \\end{pmatrix} + \\begin{pmatrix} -0.113160 \\\\ 0.181056 \\end{pmatrix} = \\begin{pmatrix} -0.165284 \\\\ 0.024684 \\end{pmatrix}\n$$\n\n**步骤 3：使用梯度下降更新向量。**\n$$\nv_{\\text{new}} = v - \\eta \\nabla_v J = \\begin{pmatrix} 0.20 \\\\ -0.35 \\end{pmatrix} - 0.05 \\begin{pmatrix} -0.165284 \\\\ 0.024684 \\end{pmatrix} = \\begin{pmatrix} 0.20 \\\\ -0.35 \\end{pmatrix} - \\begin{pmatrix} -0.008264 \\\\ 0.001234 \\end{pmatrix} = \\begin{pmatrix} 0.208264 \\\\ -0.351234 \\end{pmatrix}\n$$\n$$\nw_{\\text{new}} = w - \\eta \\nabla_w J = \\begin{pmatrix} 0.10 \\\\ 0.30 \\end{pmatrix} - 0.05 \\begin{pmatrix} -0.104248 \\\\ 0.182434 \\end{pmatrix} = \\begin{pmatrix} 0.10 \\\\ 0.30 \\end{pmatrix} - \\begin{pmatrix} -0.005212 \\\\ 0.009122 \\end{pmatrix} = \\begin{pmatrix} 0.105212 \\\\ 0.290878 \\end{pmatrix}\n$$\n$$\nu_{\\text{new}} = u - \\eta \\nabla_u J = \\begin{pmatrix} -0.25 \\\\ 0.40 \\end{pmatrix} - 0.05 \\begin{pmatrix} 0.090528 \\\\ -0.158424 \\end{pmatrix} = \\begin{pmatrix} -0.25 \\\\ 0.40 \\end{pmatrix} - \\begin{pmatrix} 0.004526 \\\\ -0.007921 \\end{pmatrix} = \\begin{pmatrix} -0.254526 \\\\ 0.407921 \\end{pmatrix}\n$$\n\n**步骤 4：使用更新后的向量评估损失函数。**\n首先，我们计算新的点积：\n$$\nw_{\\text{new}}^{\\top} v_{\\text{new}} = (0.105212)(0.208264) + (0.290878)(-0.351234) \\approx 0.021909 - 0.102170 = -0.080261\n$$\n$$\nu_{\\text{new}}^{\\top} v_{\\text{new}} = (-0.254526)(0.208264) + (0.407921)(-0.351234) \\approx -0.053005 - 0.143283 = -0.196288\n$$\n现在，我们计算新的损失 $J_{\\text{new}}$：\n$$\nJ_{\\text{new}} = -\\ln(\\sigma(w_{\\text{new}}^{\\top} v_{\\text{new}})) - \\ln(\\sigma(-u_{\\text{new}}^{\\top} v_{\\text{new}}))\n$$\n$$\nJ_{\\text{new}} = -\\ln(\\sigma(-0.080261)) - \\ln(\\sigma(0.196288))\n$$\n新的 sigmoid 值为：\n$$\n\\sigma(-0.080261) = \\frac{1}{1 + \\exp(0.080261)} \\approx 0.479950\n$$\n$$\n\\sigma(0.196288) = \\frac{1}{1 + \\exp(-0.196288)} \\approx 0.548924\n$$\n最后，我们计算新的损失值：\n$$\nJ_{\\text{new}} = -\\ln(0.479950) - \\ln(0.548924) \\approx -(-0.734089) - (-0.599738) = 0.734089 + 0.599738 = 1.333827\n$$\n将结果四舍五入到四位有效数字，得到 $1.334$。", "answer": "$$\\boxed{1.334}$$", "id": "4617685"}, {"introduction": "训练出词嵌入向量后，我们必须评估其质量和有效性。本章的最后一个实践环节将聚焦于模型评估。这个练习 [@problem_id:4617732] 演示了一种标准的词嵌入内在评估方法：通过计算词向量间的几何相似度（余弦相似度），并将其与人类专家对语义相似度的判断进行排序相关性分析。这是验证模型是否成功捕捉到临床相关知识的关键步骤，确保了模型的可靠性和实用性。", "problem": "一个临床自然语言处理团队提出了一个轻量级的内部评估基准，用于评估在出院小结上训练的词嵌入。该基准包含五个具有临床动机的概念对，人类专家为这些概念对提供了 $[0,10]$ 范围内的相似度评分。嵌入空间是二维的，并且为了使几何推理透明化，每个临床概念 $c$ 都被映射到一个单位向量 $e(\\theta_c)$，该向量由一个以弧度为单位的角度 $\\theta_c$ 参数化，其中 $e(\\theta) = (\\cos \\theta, \\sin \\theta)$。概念的角度如下：\n- $\\text{dyspnea}$: $\\theta_{\\text{dyspnea}} = 0.20$，$\\text{shortness\\_of\\_breath}$: $\\theta_{\\text{sob}} = 0.22$，\n- $\\text{angina}$: $\\theta_{\\text{angina}} = 2.20$，$\\text{rash}$: $\\theta_{\\text{rash}} = 0.30$，\n- $\\text{hypertension}$: $\\theta_{\\text{htn}} = 1.10$，$\\text{high\\_blood\\_pressure}$: $\\theta_{\\text{hbp}} = 1.18$，\n- $\\text{chest\\_pain}$: $\\theta_{\\text{cp}} = 2.10$，\n- $\\text{type\\_2\\_diabetes}$: $\\theta_{\\text{t2d}} = 1.90$，$\\text{insulin\\_resistance}$: $\\theta_{\\text{ir}} = 1.60$。\n\n五个评估对及其专家相似度评分（在 $[0,10]$ 范围内）如下：\n- $(\\text{dyspnea}, \\text{shortness\\_of\\_breath}): 9.8$，\n- $(\\text{angina}, \\text{rash}): 0.5$，\n- $(\\text{hypertension}, \\text{high\\_blood\\_pressure}): 9.4$，\n- $(\\text{angina}, \\text{chest\\_pain}): 9.6$，\n- $(\\text{type\\_2\\_diabetes}, \\text{insulin\\_resistance}): 7.5$。\n\n使用余弦相似度和 Spearman 秩相关系数的标准定义，计算给定嵌入中每对概念的余弦相似度，然后计算余弦相似度向量与专家评分向量之间的 Spearman $\\rho$ 值。假设如果出现平级，则使用标准平均排名法处理，并且对两个变量使用相同的排序方向，将排名 $1$ 分配给最高的相似度。将 Spearman $\\rho$ 的最终答案表示为四舍五入到四位有效数字的小数。角度以弧度为单位。", "solution": "首先根据所需标准对问题陈述进行验证。\n\n### 第1步：提取已知条件\n- **嵌入空间**：二维。\n- **嵌入函数**：一个概念 $c$ 映射到一个单位向量 $e(\\theta_c) = (\\cos \\theta_c, \\sin \\theta_c)$，其中 $\\theta_c$ 是以弧度为单位的角度。\n- **概念角度**：\n  - $\\theta_{\\text{dyspnea}} = 0.20$\n  - $\\theta_{\\text{sob}} = 0.22$\n  - $\\theta_{\\text{angina}} = 2.20$\n  - $\\theta_{\\text{rash}} = 0.30$\n  - $\\theta_{\\text{htn}} = 1.10$\n  - $\\theta_{\\text{hbp}} = 1.18$\n  - $\\theta_{\\text{cp}} = 2.10$\n  - $\\theta_{\\text{t2d}} = 1.90$\n  - $\\theta_{\\text{ir}} = 1.60$\n- **评估对和专家相似度评分**：\n  1. $(\\text{dyspnea}, \\text{shortness\\_of\\_breath}): 9.8$\n  2. $(\\text{angina}, \\text{rash}): 0.5$\n  3. $(\\text{hypertension}, \\text{high\\_blood\\_pressure}): 9.4$\n  4. $(\\text{angina}, \\text{chest\\_pain}): 9.6$\n  5. $(\\text{type\\_2\\_diabetes}, \\text{insulin\\_resistance}): 7.5$\n- **任务**：计算嵌入的余弦相似度与专家相似度评分之间的 Spearman 秩相关系数 $\\rho$。\n- **约束条件**：\n  - 使用余弦相似度和 Spearman $\\rho$ 的标准定义。\n  - 排名 $1$ 分配给最高的相似度分数。\n  - 使用平均排名处理平级。\n  - $\\rho$ 的最终答案必须是四舍五入到四位有效数字的小数。\n\n### 第2步：使用提取的已知条件进行验证\n对问题的有效性进行评估：\n- **科学依据**：该问题使用了线性代数（向量、余弦相似度）和统计学（Spearman 相关性）中的标准概念，并将其应用于自然语言处理和生物信息学中的一个常见任务（词嵌入评估）。该场景虽然经过简化（一个二维嵌入空间），但作为一个模型问题在科学上是合理的。\n- **适定性**：该问题提供了所有必要的数据（概念的角度、用于评估的配对、专家评分），并指定了要使用的方法（余弦相似度、Spearman $\\rho$、排名标准、四舍五入）。可以确定一个唯一的解。\n- **客观性**：该问题使用精确的数学定义和数值进行陈述，没有主观或模糊的语言。\n\n### 第3步：结论和行动\n该问题是有效的。它在其定义的模型内是自洽的、科学合理的且适定的。将推导求解。\n\n***\n\n求解过程首先计算五个概念对中每一对的余弦相似度，然后对这些相似度和专家评分进行排名，最后计算 Spearman 秩相关系数。\n\n两个向量 $u$ 和 $v$ 之间的余弦相似度定义为 $\\frac{u \\cdot v}{\\|u\\| \\|v\\|}$。在这个问题中，每个概念 $c$ 由一个单位向量 $e(\\theta_c) = (\\cos \\theta_c, \\sin \\theta_c)$ 表示。对于两个这样的向量 $e(\\theta_1)$ 和 $e(\\theta_2)$，它们的范数是 $\\|e(\\theta_1)\\| = 1$ 和 $\\|e(\\theta_2)\\| = 1$。因此，余弦相似度简化为它们的点积：\n$$ \\text{sim}(e(\\theta_1), e(\\theta_2)) = e(\\theta_1) \\cdot e(\\theta_2) = \\cos \\theta_1 \\cos \\theta_2 + \\sin \\theta_1 \\sin \\theta_2 $$\n使用三角函数的差角恒等式，这可以进一步简化为：\n$$ \\text{sim}(e(\\theta_1), e(\\theta_2)) = \\cos(\\theta_1 - \\theta_2) = \\cos(|\\theta_1 - \\theta_2|) $$\n\n令 $S$ 为计算出的余弦相似度向量，$E$ 为按给定顺序排列的五个配对的专家评分向量。\n\n五个配对是：\n1.  $(\\text{dyspnea}, \\text{shortness\\_of\\_breath})$: $\\theta_{\\text{dyspnea}} = 0.20$, $\\theta_{\\text{sob}} = 0.22$。\n    $S_1 = \\cos(|0.20 - 0.22|) = \\cos(0.02)$。\n2.  $(\\text{angina}, \\text{rash})$: $\\theta_{\\text{angina}} = 2.20$, $\\theta_{\\text{rash}} = 0.30$。\n    $S_2 = \\cos(|2.20 - 0.30|) = \\cos(1.90)$。\n3.  $(\\text{hypertension}, \\text{high\\_blood\\_pressure})$: $\\theta_{\\text{htn}} = 1.10$, $\\theta_{\\text{hbp}} = 1.18$。\n    $S_3 = \\cos(|1.10 - 1.18|) = \\cos(0.08)$。\n4.  $(\\text{angina}, \\text{chest\\_pain})$: $\\theta_{\\text{cp}} = 2.10$, $\\theta_{\\text{angina}} = 2.20$。 注意：$\\theta_{\\text{angina}}$ 再次被使用。\n    $S_4 = \\cos(|2.10 - 2.20|) = \\cos(0.10)$。\n5.  $(\\text{type\\_2\\_diabetes}, \\text{insulin\\_resistance})$: $\\theta_{\\text{t2d}} = 1.90$, $\\theta_{\\text{ir}} = 1.60$。\n    $S_5 = \\cos(|1.90 - 1.60|) = \\cos(0.30)$。\n\n专家评分向量为 $E = (9.8, 0.5, 9.4, 9.6, 7.5)$。\n\n要计算 Spearman 的 $\\rho$ 值，我们必须对两组值进行排名。排名 $1$ 分配给最高值。\n\n对专家评分 $E$ 进行排名：\n评分为 $9.8, 0.5, 9.4, 9.6, 7.5$。\n按降序排列为：$9.8, 9.6, 9.4, 7.5, 0.5$。\n对应的排名为 $1, 2, 3, 4, 5$。\n将这些排名分配回原始顺序，我们得到排名向量 $R_E$：\n- $E_1 = 9.8$ (排名 $1$)\n- $E_2 = 0.5$ (排名 $5$)\n- $E_3 = 9.4$ (排名 $3$)\n- $E_4 = 9.6$ (排名 $2$)\n- $E_5 = 7.5$ (排名 $4$)\n所以，$R_E = (1, 5, 3, 2, 4)$。没有平级。\n\n对余弦相似度 $S$ 进行排名：\n值为 $\\cos(0.02)$, $\\cos(1.90)$, $\\cos(0.08)$, $\\cos(0.10)$, $\\cos(0.30)$。\n函数 $\\cos(x)$ 在 $x \\in [0, \\pi]$ 上是严格递减的。所有角度差 $|\\Delta\\theta|$ 都在这个区间内。因此，更小的角度差对应着更大的余弦相似度。\n角度差为 $0.02, 1.90, 0.08, 0.10, 0.30$。\n按升序排列为：$0.02, 0.08, 0.10, 0.30, 1.90$。\n这个顺序对应于余弦相似度的降序。排名为 $1, 2, 3, 4, 5$。\n将这些排名分配回原始顺序，我们得到排名向量 $R_S$：\n- $S_1 = \\cos(0.02)$ (排名 $1$)\n- $S_2 = \\cos(1.90)$ (排名 $5$)\n- $S_3 = \\cos(0.08)$ (排名 $2$)\n- $S_4 = \\cos(0.10)$ (排名 $3$)\n- $S_5 = \\cos(0.30)$ (排名 $4$)\n所以，$R_S = (1, 5, 2, 3, 4)$。没有平级。\n\nSpearman 秩相关系数 $\\rho$ 是根据排名计算的。由于没有平级，可以使用简化公式：\n$$ \\rho = 1 - \\frac{6 \\sum_{i=1}^{n} d_i^2}{n(n^2 - 1)} $$\n其中 $n$ 是配对的数量，$d_i = R_{S_i} - R_{E_i}$ 是每对的排名差。\n这里，$n=5$。\n\n让我们计算排名差 $d_i$：\n- $d_1 = R_{S_1} - R_{E_1} = 1 - 1 = 0$\n- $d_2 = R_{S_2} - R_{E_2} = 5 - 5 = 0$\n- $d_3 = R_{S_3} - R_{E_3} = 2 - 3 = -1$\n- $d_4 = R_{S_4} - R_{E_4} = 3 - 2 = 1$\n- $d_5 = R_{S_5} - R_{E_5} = 4 - 4 = 0$\n\n差的平方和是：\n$$ \\sum_{i=1}^{5} d_i^2 = 0^2 + 0^2 + (-1)^2 + 1^2 + 0^2 = 0 + 0 + 1 + 1 + 0 = 2 $$\n\n现在我们将这个值代入 $\\rho$ 的公式：\n$$ \\rho = 1 - \\frac{6 \\times 2}{5(5^2 - 1)} = 1 - \\frac{12}{5(24)} = 1 - \\frac{12}{120} = 1 - \\frac{1}{10} = 0.9 $$\n\nSpearman $\\rho$ 的值恰好是 $0.9$。题目要求答案为四舍五入到四位有效数字的小数。即 $0.9000$。", "answer": "$$\n\\boxed{0.9000}\n$$", "id": "4617732"}]}