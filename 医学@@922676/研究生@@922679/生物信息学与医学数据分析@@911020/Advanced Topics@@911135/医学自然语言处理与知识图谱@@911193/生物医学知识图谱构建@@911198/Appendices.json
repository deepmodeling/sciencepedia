{"hands_on_practices": [{"introduction": "实体标准化是知识图谱构建中的关键第一步。在生物医学文献和数据源中，基因和药物的提及方式通常是模糊的，存在许多同义词、缩写和拼写错误。本练习将指导您构建一个强大的管道，该管道结合了多种字符串匹配技术——包括精确匹配、基于词元的相似度（Jaccard）和编辑距离（Levenshtein）——将这些杂乱的提及映射到来自HGNC和DrugBank等数据库的规范标识符。通过调整特征权重和决策阈值，您还将探索此任务中精确率 $P$ 和召回率 $R$ 之间的基本权衡。[@problem_id:4577572]", "problem": "构建一个完整、可运行的程序，用于实现和评估一个为生物医学知识图谱构建而设计的、有原则的实体规范化流水线。该流水线必须将自由文本提及（free-text mentions）映射到从基因和药物的精选标识符中提取的规范标识符，具体来说，基因使用 HUGO 基因命名委员会（HUGO Gene Nomenclature Committee, HGNC）的标识符，药物使用 DrugBank 数据库（DrugBank）的标识符。程序必须是自包含的，仅使用下文指定的数据和参数，并以指定格式生成单行输出。评估必须使用可调的评分阈值和特征权重向量，量化在同义词环境下精确率-召回率的权衡。\n\n您必须从核心定义以及关于字符串规范化和评估指标的成熟事实出发来推导算法。程序必须精确实现以下组件。\n\n1) 规范实体和同义词。令规范标识符的集合表示为 $\\mathcal{C}$。每个规范标识符 $c \\in \\mathcal{C}$ 都有一个有限的表层形式（同义词）集合 $\\mathcal{S}(c)$ 和一个单一的优选标签 $p(c) \\in \\mathcal{S}(c)$。必须精确使用以下集合：\n- 基因 (HGNC):\n  - $c = \\text{HGNC:11998}$, $\\mathcal{S}(c) = \\{\\text{\"TP53\"}, \\text{\"p53\"}, \\text{\"tumor protein p53\"}\\}$, $p(c) = \\text{\"TP53\"}$。\n  - $c = \\text{HGNC:3236}$, $\\mathcal{S}(c) = \\{\\text{\"EGFR\"}, \\text{\"epidermal growth factor receptor\"}, \\text{\"ERBB1\"}\\}$, $p(c) = \\text{\"EGFR\"}$。\n  - $c = \\text{HGNC:391}$, $\\mathcal{S}(c) = \\{\\text{\"AKT1\"}, \\text{\"PKB\"}, \\text{\"RAC-alpha serine/threonine-protein kinase\"}\\}$, $p(c) = \\text{\"AKT1\"}$。\n- 药物 (DrugBank):\n  - $c = \\text{DrugBank:DB00316}$, $\\mathcal{S}(c) = \\{\\text{\"acetaminophen\"}, \\text{\"paracetamol\"}, \\text{\"APAP\"}\\}$, $p(c) = \\text{\"acetaminophen\"}$。\n  - $c = \\text{DrugBank:DB00945}$, $\\mathcal{S}(c) = \\{\\text{\"aspirin\"}, \\text{\"acetylsalicylic acid\"}, \\text{\"ASA\"}\\}$, $p(c) = \\text{\"aspirin\"}$。\n  - $c = \\text{DrugBank:DB01050}$, $\\mathcal{S}(c) = \\{\\text{\"ibuprofen\"}\\}$, $p(c) = \\text{\"ibuprofen\"}$。\n\n2) 提及和基准真相 (Ground Truth)。令评估提及集合为 $\\mathcal{M}$，其基准真相映射为 $g: \\mathcal{M} \\to \\mathcal{C} \\cup \\{\\varnothing\\}$，其中 $\\varnothing$ 表示没有规范映射。必须精确使用以下列表：\n- $(\\text{\"TP53\"}, \\text{HGNC:11998})$\n- $(\\text{\"p53\"}, \\text{HGNC:11998})$\n- $(\\text{\"tumor prot p53\"}, \\text{HGNC:11998})$\n- $(\\text{\"p 53\"}, \\text{HGNC:11998})$\n- $(\\text{\"EGFR\"}, \\text{HGNC:3236})$\n- $(\\text{\"ERBB1\"}, \\text{HGNC:3236})$\n- $(\\text{\"erbb-1\"}, \\text{HGNC:3236})$\n- $(\\text{\"AKT-1\"}, \\text{HGNC:391})$\n- $(\\text{\"PKB\"}, \\text{HGNC:391})$\n- $(\\text{\"acetaminophen\"}, \\text{DrugBank:DB00316})$\n- $(\\text{\"paracetamol\"}, \\text{DrugBank:DB00316})$\n- $(\\text{\"APAP\"}, \\text{DrugBank:DB00316})$\n- $(\\text{\"aspirin\"}, \\text{DrugBank:DB00945})$\n- $(\\text{\"ASA\"}, \\text{DrugBank:DB00945})$\n- $(\\text{\"acetylsalicylic acid\"}, \\text{DrugBank:DB00945})$\n- $(\\text{\"ibuprofen\"}, \\text{DrugBank:DB01050})$\n- $(\\text{\"ibuprfen\"}, \\text{DrugBank:DB01050})$\n- $(\\text{\"randomword\"}, \\varnothing)$\n- $(\\text{\"EGFR inhibitor\"}, \\varnothing)$\n\n3) 规范化函数。定义一个用于相等性和编辑距离比较的确定性规范化函数 $N:\\text{strings}\\to\\text{strings}$，以及一个用于 Jaccard 相似度的分词函数 $T:\\text{strings}\\to 2^{\\text{tokens}}$。\n- 缩写扩展：在规范化之前，对小写词元（token）应用映射 $\\{\\text{\"asa\"}\\mapsto\\text{\"acetylsalicylic acid\"}, \\text{\"apap\"}\\mapsto\\text{\"acetaminophen\"}\\}$ 进行逐词元替换。\n- 用于相等性/编辑距离的字符串规范化：$N(s)$ 通过将字符串小写化、执行缩写扩展并移除所有非字母数字字符得到。例如，$N(\\text{\"p 53\"}) = \\text{\"p53\"}$ 和 $N(\\text{\"erbb-1\"}) = \\text{\"erbb1\"}$。\n- 分词：$T(s)$ 通过将字符串小写化、执行缩写扩展、将每个非字母数字字符替换为空格、按空格分割，并从集合 $\\{\\text{\"protein\"}, \\text{\"receptor\"}, \\text{\"acid\"}, \\text{\"serine\"}, \\text{\"threonine\"}, \\text{\"alpha\"}, \\text{\"beta\"}, \\text{\"inhibitor\"}\\}$ 中移除停用词得到。例如，$T(\\text{\"epidermal growth factor receptor\"}) = \\{\\text{\"epidermal\"}, \\text{\"growth\"}, \\text{\"factor\"}\\}$。\n\n4) 特征函数和评分。对于一个提及 $m$ 和某个 $c\\in\\mathcal{C}$ 的候选同义词 $s \\in \\mathcal{S}(c)$，定义特征向量 $\\phi(m,s) \\in \\mathbb{R}^{4}$ 如下：\n- 完全匹配特征：$f_{\\mathrm{e}}(m,s) = \\mathbf{1}[N(m) = N(s)]$。\n- 优选标签完全匹配特征：$f_{\\mathrm{p}}(m,s) = \\mathbf{1}[N(m) = N(p(c))]$。\n- 词元 Jaccard 特征：$f_{\\mathrm{j}}(m,s) = \\dfrac{|T(m)\\cap T(s)|}{|T(m)\\cup T(s)|}$，约定 $0/0$ 为 $0$。\n- 归一化 Levenshtein 相似度：$f_{\\mathrm{d}}(m,s) = 1 - \\dfrac{D(N(m),N(s))}{\\max\\{|N(m)|,|N(s)|\\}}$，其中 $D(\\cdot,\\cdot)$ 是 Levenshtein 编辑距离，$|\\cdot|$ 是字符串的字符长度；如果两个长度都为 $0$，则设 $f_{\\mathrm{d}}(m,s)=1$。\n令权重向量为 $w = (w_{\\mathrm{e}}, w_{\\mathrm{j}}, w_{\\mathrm{d}}, w_{\\mathrm{p}}) \\in \\mathbb{R}_{\\ge 0}^{4}$。通过 $\\tilde{w} = w / \\sum_{i} w_{i}$ 将权重归一化到概率单纯形；如果 $\\sum_{i} w_{i} = 0$，则设 $\\tilde{w} = (1/4,1/4,1/4,1/4)$。每个同义词的得分是\n$$\nS(m,s; \\tilde{w}) = \\tilde{w}_{\\mathrm{e}} f_{\\mathrm{e}}(m,s) + \\tilde{w}_{\\mathrm{j}} f_{\\mathrm{j}}(m,s) + \\tilde{w}_{\\mathrm{d}} f_{\\mathrm{d}}(m,s) + \\tilde{w}_{\\mathrm{p}} f_{\\mathrm{p}}(m,s).\n$$\n每个实体的得分是其同义词中的最大值：\n$$\nS^{*}(m,c;\\tilde{w}) = \\max_{s \\in \\mathcal{S}(c)} S(m,s;\\tilde{w}).\n$$\n\n5) 带阈值的决策规则。给定一个阈值 $\\tau \\in [0,1]$，如果 $\\max_{c\\in\\mathcal{C}} S^{*}(m,c;\\tilde{w}) \\ge \\tau$，则预测 $\\hat{g}(m) = \\arg\\max_{c\\in\\mathcal{C}} S^{*}(m,c;\\tilde{w})$；否则预测 $\\hat{g}(m) = \\varnothing$。通过选择字典序最小的标识符字符串来打破 $\\arg\\max$ 中的平局。\n\n6) 评估指标。在提及集合 $\\mathcal{M}$ 和基准真相 $g$ 上，计算真正例 $TP = |\\{m \\in \\mathcal{M}: g(m)\\in \\mathcal{C}, \\hat{g}(m) = g(m)\\}|$、假正例 $FP = |\\{m \\in \\mathcal{M}: \\hat{g}(m)\\in \\mathcal{C}, \\hat{g}(m) \\neq g(m)\\}|$ 和假负例 $FN = |\\{m \\in \\mathcal{M}: g(m)\\in \\mathcal{C}, \\hat{g}(m) = \\varnothing\\}|$。精确率和召回率为\n$$\nP = \\begin{cases}\n\\dfrac{TP}{TP+FP}  \\text{if } TP+FP > 0\\\\\n0  \\text{otherwise}\n\\end{cases}, \\quad\nR = \\begin{cases}\n\\dfrac{TP}{TP+FN}  \\text{if } TP+FN > 0\\\\\n0  \\text{otherwise}\n\\end{cases}.\n$$\n调和平均数是\n$$\nF_{1} = \\begin{cases}\n\\dfrac{2PR}{P+R}  \\text{if } P+R > 0\\\\\n0  \\text{otherwise}\n\\end{cases}.\n$$\n所有三个量都必须报告为在 $[0,1]$ 范围内并四舍五入到四位小数的十进制数；不要使用百分号。\n\n7) 测试套件。精确评估以下 $5$ 个测试用例，每个用例包含一个权重向量 $w$ 和一个阈值 $\\tau$：\n- 用例 1: $w=(0.6, 0.1, 0.2, 0.1)$, $\\tau=0.7$。\n- 用例 2: $w=(0.95, 0.0, 0.05, 0.0)$, $\\tau=0.95$。\n- 用例 3: $w=(0.25, 0.35, 0.35, 0.05)$, $\\tau=0.6$。\n- 用例 4: $w=(1.0, 0.0, 0.0, 0.0)$, $\\tau=1.0$。\n- 用例 5: $w=(2.0, 0.5, 0.5, 0.0)$, $\\tau=0.65$。\n\n8) 最终输出格式。您的程序应产生单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。该列表必须按上述顺序将每个用例的三元组 $(P,R,F_{1})$ 扁平化。例如，格式为 $[\\text{P}_{1},\\text{R}_{1},\\text{F1}_{1},\\text{P}_{2},\\text{R}_{2},\\text{F1}_{2},\\dots,\\text{P}_{5},\\text{R}_{5},\\text{F1}_{5}]$，其中每个值都四舍五入到四位小数。", "solution": "我们通过从实体解析中的基本定义推导出一个规范化和匹配流水线，然后将其转化为一个具有可量化评估的算法，从而构建解决方案。\n\n理论基础。我们从以下经过充分检验的定义出发：字符串规范化可以在不改变身份的情况下减少表面的变异；基于词元（token）的相似度（如 Jaccard 相似度）衡量集合间的重叠程度；编辑距离量化了将一个字符串转换为另一个字符串的最小操作次数；而分类指标（如精确率和召回率）衡量映射的正确性和完整性。对于生物医学领域的自由文本提及集合，规范标识符（例如，HUGO 基因命名委员会和 DrugBank）各自拥有多个同义词，这导致了需要仔细规范化处理的同义和近义问题。鉴于知识图谱的构建需要将提及链接到规范节点，我们必须实现一个确定性的决策规则，该规则通过一个阈值参数在错误匹配和漏掉的匹配之间进行权衡。\n\n规范化设计。令 $N(\\cdot)$ 为一个执行小写化、缩写扩展和非字母数字字符剥离的函数。其基本原理是，字母数字核心承载了基因符号和药物名称的大部分区分性内容，而标点和空格通常是书写的人为产物。令 $T(\\cdot)$ 将字符串映射到词元集合，该过程在小写化、缩写扩展、将标点转换为空格以及移除停用词之后进行。停用词集包括通用的生物医学词汇，如 $\\{\\text{\"protein\"}, \\text{\"receptor\"}, \\text{\"acid\"}, \\text{\"serine\"}, \\text{\"threonine\"}, \\text{\"alpha\"}, \\text{\"beta\"}, \\text{\"inhibitor\"}\\}$，这些词汇会夸大重叠度而没有增加区分价值。这些词被视为非信息性词元，以便 Jaccard 相似度能更强调像 $\\text{\"p53\"}$ 和 $\\text{\"epidermal\"}$ 这样的特定标记。\n\n特征构建。对于一个提及 $m$ 和一个候选实体 $c$ 的同义词 $s$，我们定义四个特征：\n- $f_{\\mathrm{e}}(m,s) = \\mathbf{1}[N(m)=N(s)]$ 捕获规范化后的稳健完全等价性，这是一个高精确率的信号。\n- $f_{\\mathrm{p}}(m,s) = \\mathbf{1}[N(m)=N(p(c))]$ 编码了优选标签在完全匹配时具有额外的可靠性（例如，官方符号）。\n- $f_{\\mathrm{j}}(m,s)$ 是词元集合 $T(m)$ 和 $T(s)$ 之间的 Jaccard 相似度，定义为 $|A\\cap B|/|A\\cup B|$，这是一个范围在 $[0,1]$ 内的度量，可以总结对词序不敏感的重叠度。\n- $f_{\\mathrm{d}}(m,s) = 1 - D(N(m),N(s))/\\max\\{|N(m)|,|N(s)|\\}$ 是一个基于 Levenshtein 的归一化相似度，同样在 $[0,1]$ 范围内，它奖励近似匹配，对于像 $\\text{\"ibuprfen\"}$ 对比 $\\text{\"ibuprofen\"}$ 这样的拼写错误尤其有用。\n\n线性评分。我们使用一个非负权重向量 $w=(w_{\\mathrm{e}},w_{\\mathrm{j}},w_{\\mathrm{d}},w_{\\mathrm{p}})$ 来构建这些特征的凸组合。为确保有原则的可解释性和有界性，我们将权重归一化到概率单纯形：当 $\\sum_{i}w_{i} > 0$ 时，$\\tilde{w} = w / \\sum_{i} w_{i}$；否则使用均匀权重 $\\tilde{w}=(1/4,1/4,1/4,1/4)$。每个同义词的得分是 $S(m,s;\\tilde{w}) = \\tilde{w}_{\\mathrm{e}} f_{\\mathrm{e}} + \\tilde{w}_{\\mathrm{j}} f_{\\mathrm{j}} + \\tilde{w}_{\\mathrm{d}} f_{\\mathrm{d}} + \\tilde{w}_{\\mathrm{p}} f_{\\mathrm{p}}$。每个实体的得分 $S^{*}(m,c;\\tilde{w})$ 是其所有同义词中的最大值。这个 max 操作符是合理的，因为从逻辑语义上讲，一个实体应该因其最佳匹配的别名而获得评分。\n\n决策规则和权衡。当且仅当最大得分超过一个阈值 $\\tau\\in[0,1]$ 时，我们预测 $\\hat{g}(m)$ 为最大化 $S^{*}(m,c;\\tilde{w})$ 的参数；否则我们通过预测 $\\varnothing$ 来弃权。这创造了一个可调的精确率-召回率曲线：较高的 $\\tau$ 通过排除低置信度的匹配来提高精确率，但代价是牺牲召回率；而较低的 $\\tau$ 通过允许更多的近似匹配来提高召回率，但这在同义和词元重叠的情况下会增加假正例的风险。通过字典序来打破平局确保了确定性。\n\n特征计算。我们使用词元集合计算 $f_{\\mathrm{j}}$，并约定如果两个词元集合都为空，则相似度为 $0$，反映没有证据。我们通过时间复杂度为 $O(|x|\\cdot|y|)$ 的动态规划计算 Levenshtein 距离 $D(\\cdot,\\cdot)$，考虑到生物医学字符串较短，这是可行的。\n\n评估指标。使用基准真相函数 $g$，我们根据 $\\hat{g}(m)$ 和 $g(m)$ 的集合基数来计算真正例 $TP$、假正例 $FP$ 和假负例 $FN$。当分母为正时，精确率 $P$ 和召回率 $R$ 分别计算为比率 $TP/(TP+FP)$ 和 $TP/(TP+FN)$，否则设为 $0$。调和平均数 $F_{1} = 2PR/(P+R)$ 提供了一个单一数字的总结，当 $P+R=0$ 时设为 $0$。\n\n边缘情况和边界条件。权重向量被重新归一化以处理总和不为 $1$ 的输入（用例 5），而全零权重则默认为均匀权重。阈值 $\\tau=1.0$（用例 4）要求完美的得分，测试了最严格的精确率偏好。拼写错误和连字符（例如，$\\text{\"erbb-1\"}$、$\\text{\"AKT-1\"}$、$\\text{\"ibuprfen\"}$）通过 $N(\\cdot)$ 和 $f_{\\mathrm{d}}$ 来处理。像 $\\text{\"EGFR inhibitor\"}$ 这样带有上下文的提及旨在展示词元重叠，但在足够高的 $\\tau$ 下应被过滤掉，这说明了在同义词压力下的精确率。\n\n算法步骤。\n- 对每个同义词 $s$，预先计算其 $N(s)$ 和 $T(s)$；对每个实体 $c$，预先计算其优选规范化标签 $N(p(c))$。\n- 对每个提及 $m$，计算 $N(m)$ 和 $T(m)$，然后对每个实体 $c$，通过评估与每个 $s\\in \\mathcal{S}(c)$ 的特征并取最大值来计算 $S^{*}(m,c;\\tilde{w})$。\n- 使用带 $\\tau$ 的阈值规则和指定的平局打破规则来选择 $\\hat{g}(m)$。\n- 汇总计数 $TP$、$FP$、$FN$，然后计算 $P$、$R$ 和 $F_{1}$。\n- 对 $5$ 个权重-阈值用例重复以上步骤，并输出扁平化的列表 $[P_{1},R_{1},F_{1,1},\\dots,P_{5},R_{5},F_{1,5}]$，四舍五入到四位小数。\n\n该设计直接将核心原则付诸实践：确定性规范化、互补相似度信号的凸组合，以及阈值决策理论来表达在同义和近义情况下的精确率-召回率权衡。提供的测试套件涵盖了一个平衡的用例、一个以完全匹配为主的高阈值用例、一个面向召回率的用例、一个要求完美匹配的边界用例以及一个重归一化用例，确保了对关键行为的覆盖。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef normalize_weights(w):\n    w = np.array(w, dtype=float)\n    s = w.sum()\n    if s > 0:\n        return w / s\n    # default to uniform if all-zero\n    return np.ones_like(w) / len(w)\n\ndef abbrev_expand_tokens(tokens, abbr_map):\n    # Expand tokens using abbreviation map (inputs and keys lowercase).\n    out = []\n    for tok in tokens:\n        if tok in abbr_map:\n            # Expansion may introduce multiple space-separated tokens.\n            expanded = abbr_map[tok].lower().split()\n            out.extend(expanded)\n        else:\n            out.append(tok)\n    return out\n\ndef normalize_string_for_match(s, abbr_map):\n    # Lowercase, tokenize by replacing non-alphanumeric with space, expand, then remove non-alphanumeric entirely.\n    s_low = s.lower()\n    # Replace non-alphanumeric with space to tokenize\n    chars = []\n    for ch in s_low:\n        if ch.isalnum():\n            chars.append(ch)\n        else:\n            chars.append(' ')\n    tokenized = ''.join(chars).split()\n    expanded = abbrev_expand_tokens(tokenized, abbr_map)\n    # Remove non-alphanumeric and join: expanded are alphanumeric tokens already\n    return ''.join(''.join([c for c in tok if c.isalnum()]) for tok in expanded)\n\ndef token_set(s, abbr_map, stopwords):\n    s_low = s.lower()\n    # Replace non-alphanumeric with space to tokenize\n    chars = []\n    for ch in s_low:\n        if ch.isalnum():\n            chars.append(ch)\n        else:\n            chars.append(' ')\n    tokenized = ''.join(chars).split()\n    expanded = abbrev_expand_tokens(tokenized, abbr_map)\n    # Remove stopwords\n    toks = [tok for tok in expanded if tok and tok not in stopwords]\n    return set(toks)\n\ndef jaccard(a_set, b_set):\n    if not a_set and not b_set:\n        return 0.0\n    inter = len(a_set & b_set)\n    union = len(a_set | b_set)\n    return inter / union if union > 0 else 0.0\n\ndef levenshtein(a, b):\n    # Classic DP, space-optimized\n    la, lb = len(a), len(b)\n    if la == 0:\n        return lb\n    if lb == 0:\n        return la\n    # Ensure a is shorter\n    if la > lb:\n        a, b = b, a\n        la, lb = lb, la\n    prev = list(range(lb + 1))\n    for i in range(1, la + 1):\n        curr = [i] + [0] * lb\n        ca = a[i - 1]\n        for j in range(1, lb + 1):\n            cb = b[j - 1]\n            cost = 0 if ca == cb else 1\n            curr[j] = min(\n                curr[j - 1] + 1,      # insertion\n                prev[j] + 1,          # deletion\n                prev[j - 1] + cost    # substitution\n            )\n        prev = curr\n    return prev[lb]\n\ndef normalized_lev_sim(a, b):\n    # a and b are normalized strings\n    maxlen = max(len(a), len(b))\n    if maxlen == 0:\n        return 1.0\n    d = levenshtein(a, b)\n    return 1.0 - (d / maxlen)\n\ndef score_features(m_norm, m_tokens, s_norm, s_tokens, pref_norm):\n    # Compute features: f_e, f_j, f_d, f_p in that order mapping to weights [we, wj, wd, wp]\n    f_e = 1.0 if m_norm == s_norm else 0.0\n    f_p = 1.0 if m_norm == pref_norm else 0.0\n    f_j = jaccard(m_tokens, s_tokens)\n    f_d = normalized_lev_sim(m_norm, s_norm)\n    return np.array([f_e, f_j, f_d, f_p], dtype=float)\n\ndef predict_for_mention(mention, entities, syn_data, weight_vec, tau, abbr_map, stopwords):\n    # Precompute mention normalized and tokens\n    m_norm = normalize_string_for_match(mention, abbr_map)\n    m_tokens = token_set(mention, abbr_map, stopwords)\n    max_score = -1.0\n    best_ids = []\n    for cid, data in syn_data.items():\n        # data: dict with keys 'syn_norms', 'syn_tokens', 'pref_norm'\n        syn_norms = data['syn_norms']\n        syn_tokens = data['syn_tokens']\n        pref_norm = data['pref_norm']\n        # Compute max over synonyms\n        best_c_score = -1.0\n        for s_norm, s_tok in zip(syn_norms, syn_tokens):\n            feats = score_features(m_norm, m_tokens, s_norm, s_tok, pref_norm)\n            s = float(np.dot(weight_vec, feats))\n            if s > best_c_score:\n                best_c_score = s\n        # Track best overall\n        if best_c_score > max_score:\n            max_score = best_c_score\n            best_ids = [cid]\n        elif best_c_score == max_score:\n            best_ids.append(cid)\n    # Decision\n    if max_score >= tau and best_ids:\n        # tie-break lex smallest\n        return sorted(best_ids)[0]\n    else:\n        return None\n\ndef evaluate(weight_vec_raw, tau, entities, mentions, abbr_map, stopwords):\n    w = normalize_weights(weight_vec_raw)\n    # Precompute synonym data\n    syn_data = {}\n    for cid, info in entities.items():\n        syns = info['synonyms']\n        pref = info['preferred']\n        syn_norms = [normalize_string_for_match(s, abbr_map) for s in syns]\n        syn_tokens = [token_set(s, abbr_map, stopwords) for s in syns]\n        pref_norm = normalize_string_for_match(pref, abbr_map)\n        syn_data[cid] = {\n            'syn_norms': syn_norms,\n            'syn_tokens': syn_tokens,\n            'pref_norm': pref_norm\n        }\n    TP = 0\n    FP = 0\n    FN = 0\n    for mention, truth in mentions:\n        pred = predict_for_mention(mention, entities, syn_data, w, tau, abbr_map, stopwords)\n        if truth is None:\n            if pred is not None:\n                FP += 1\n        else:\n            if pred is None:\n                FN += 1\n            elif pred == truth:\n                TP += 1\n            else:\n                FP += 1\n    P = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n    R = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n    F1 = (2 * P * R) / (P + R) if (P + R) > 0 else 0.0\n    return P, R, F1\n\ndef solve():\n    # Define entities and synonyms\n    entities = {\n        \"HGNC:11998\": {\n            \"synonyms\": [\"TP53\", \"p53\", \"tumor protein p53\"],\n            \"preferred\": \"TP53\"\n        },\n        \"HGNC:3236\": {\n            \"synonyms\": [\"EGFR\", \"epidermal growth factor receptor\", \"ERBB1\"],\n            \"preferred\": \"EGFR\"\n        },\n        \"HGNC:391\": {\n            \"synonyms\": [\"AKT1\", \"PKB\", \"RAC-alpha serine/threonine-protein kinase\"],\n            \"preferred\": \"AKT1\"\n        },\n        \"DrugBank:DB00316\": {\n            \"synonyms\": [\"acetaminophen\", \"paracetamol\", \"APAP\"],\n            \"preferred\": \"acetaminophen\"\n        },\n        \"DrugBank:DB00945\": {\n            \"synonyms\": [\"aspirin\", \"acetylsalicylic acid\", \"ASA\"],\n            \"preferred\": \"aspirin\"\n        },\n        \"DrugBank:DB01050\": {\n            \"synonyms\": [\"ibuprofen\"],\n            \"preferred\": \"ibuprofen\"\n        }\n    }\n    # Mentions and ground truth\n    mentions = [\n        (\"TP53\", \"HGNC:11998\"),\n        (\"p53\", \"HGNC:11998\"),\n        (\"tumor prot p53\", \"HGNC:11998\"),\n        (\"p 53\", \"HGNC:11998\"),\n        (\"EGFR\", \"HGNC:3236\"),\n        (\"ERBB1\", \"HGNC:3236\"),\n        (\"erbb-1\", \"HGNC:3236\"),\n        (\"AKT-1\", \"HGNC:391\"),\n        (\"PKB\", \"HGNC:391\"),\n        (\"acetaminophen\", \"DrugBank:DB00316\"),\n        (\"paracetamol\", \"DrugBank:DB00316\"),\n        (\"APAP\", \"DrugBank:DB00316\"),\n        (\"aspirin\", \"DrugBank:DB00945\"),\n        (\"ASA\", \"DrugBank:DB00945\"),\n        (\"acetylsalicylic acid\", \"DrugBank:DB00945\"),\n        (\"ibuprofen\", \"DrugBank:DB01050\"),\n        (\"ibuprfen\", \"DrugBank:DB01050\"),\n        (\"randomword\", None),\n        (\"EGFR inhibitor\", None),\n    ]\n    # Abbreviation map and stopwords\n    abbr_map = {\n        \"asa\": \"acetylsalicylic acid\",\n        \"apap\": \"acetaminophen\",\n    }\n    stopwords = {\n        \"protein\", \"receptor\", \"acid\", \"serine\", \"threonine\", \"alpha\", \"beta\", \"inhibitor\"\n    }\n    # Test cases: (weights, tau)\n    test_cases = [\n        ([0.6, 0.1, 0.2, 0.1], 0.7),\n        ([0.95, 0.0, 0.05, 0.0], 0.95),\n        ([0.25, 0.35, 0.35, 0.05], 0.6),\n        ([1.0, 0.0, 0.0, 0.0], 1.0),\n        ([2.0, 0.5, 0.5, 0.0], 0.65),\n    ]\n    results = []\n    for w, tau in test_cases:\n        P, R, F1 = evaluate(w, tau, entities, mentions, abbr_map, stopwords)\n        # Round to four decimals\n        results.extend([round(P + 1e-12, 4), round(R + 1e-12, 4), round(F1 + 1e-12, 4)])\n    # Format as requested: single line, comma-separated in brackets.\n    # Ensure fixed 4-decimal formatting.\n    formatted = \"[\" + \",\".join(f\"{x:.4f}\" for x in results) + \"]\"\n    print(formatted)\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "4577572"}, {"introduction": "构建知识图谱后，我们可以分析其拓扑结构以揭示潜在的生物学原理。本实践专注于计算节点度，这是衡量连通性的基本指标。您将计算一个生物医学图谱样本中药物节点的入度 $k_{\\text{in}}$ 和出度 $k_{\\text{out}}$ 分布，并对分布的尾部拟合一个幂律模型，这是真实世界网络的一个共同特征。该分析使您能够通过识别高度连接的“枢纽”药物，来定量地探索多靶点药理学（即某些药物与多个靶点相互作用）的概念。[@problem_id:4577536]", "problem": "一个生物医学资源描述框架（RDF）知识图谱由类型化节点和有向边组成，表示为 $(\\text{主语}, \\text{谓语}, \\text{宾语})$ 形式的三元组。考虑以下一个小型且科学上合理的、捕获药物-蛋白质结合、药物-疾病适应症和药物-通路参与关系的三元组集合，以及指向药物的关系：\n\n$(D\\_A, \\text{binds}, P1)$; $(D\\_A, \\text{binds}, P2)$; $(D\\_A, \\text{binds}, P3)$; $(D\\_A, \\text{treats}, Dis1)$; $(D\\_A, \\text{participates\\_in}, PW1)$\n\n$(D\\_B, \\text{binds}, P2)$; $(D\\_B, \\text{binds}, P3)$; $(D\\_B, \\text{treats}, Dis1)$; $(D\\_B, \\text{treats}, Dis2)$\n\n$(D\\_C, \\text{binds}, P4)$; $(D\\_C, \\text{binds}, P5)$\n\n$(D\\_D, \\text{binds}, P1)$; $(D\\_D, \\text{binds}, P2)$; $(D\\_D, \\text{binds}, P3)$; $(D\\_D, \\text{binds}, P4)$; $(D\\_D, \\text{treats}, Dis2)$; $(D\\_D, \\text{treats}, Dis3)$\n\n$(D\\_E, \\text{binds}, P1)$\n\n$(D\\_F, \\text{treats}, Dis3)$\n\n$(P1, \\text{inhibited\\_by}, D\\_A)$; $(Dis1, \\text{has\\_contraindicated\\_drug}, D\\_B)$; $(Dis2, \\text{has\\_indicated\\_drug}, D\\_D)$; $(PW1, \\text{has\\_participating\\_drug}, D\\_A)$; $(P3, \\text{activated\\_by}, D\\_D)$; $(Dis3, \\text{has\\_contraindicated\\_drug}, D\\_A)$; $(P4, \\text{inhibited\\_by}, D\\_C)$。\n\n对于每个药物节点 $d \\in \\{D\\_A, D\\_B, D\\_C, D\\_D, D\\_E, D\\_F\\}$，定义出度 $k_{\\text{out}}(d)$ 为 $d$ 作为主语出现的三元组数量，入度 $k_{\\text{in}}(d)$ 为 $d$ 作为宾语出现的三元组数量。根据标准的相对频率定义，构建药物节点的经验出度分布 $p_{\\text{out}}(k)$，同样地构建经验入度分布 $p_{\\text{in}}(k)$。\n\n假设药物节点的出度尾部在阈值 $x_{\\min} = 2$ 之上遵循连续幂律分布，即对于 $k \\ge x_{\\min}$，尾部密度满足 $p(k) \\propto k^{-\\alpha}$，其中 $\\alpha$ 为某个指数。仅使用概率密度的基本定义和最大似然原理，推导连续幂律尾部的 $\\alpha$ 的最大似然估计量，并计算该图中药物出度在 $x_{\\min} = 2$ 时的 $\\alpha$ 值。将最终的 $\\alpha$ 数值估计四舍五入到4位有效数字。在你的推理中，基于所构建的分布，解释重尾的 $p_{\\text{out}}(k)$ 分布在该数据集中对多重药理学（polypharmacology）意味着什么。最终数值答案无需单位。", "solution": "首先验证问题，以确保其具有科学依据、问题明确且客观。\n\n### 步骤 1：提取已知条件\n所提供的数据包括一组RDF三元组、节点度的定义以及关于出度分布的建模假设。\n\n**RDF 三元组（边）：**\n*   $(D\\_A, \\text{binds}, P1)$; $(D\\_A, \\text{binds}, P2)$; $(D\\_A, \\text{binds}, P3)$; $(D\\_A, \\text{treats}, Dis1)$; $(D\\_A, \\text{participates\\_in}, PW1)$\n*   $(D\\_B, \\text{binds}, P2)$; $(D\\_B, \\text{binds}, P3)$; $(D\\_B, \\text{treats}, Dis1)$; $(D\\_B, \\text{treats}, Dis2)$\n*   $(D\\_C, \\text{binds}, P4)$; $(D\\_C, \\text{binds}, P5)$\n*   $(D\\_D, \\text{binds}, P1)$; $(D\\_D, \\text{binds}, P2)$; $(D\\_D, \\text{binds}, P3)$; $(D\\_D, \\text{binds}, P4)$; $(D\\_D, \\text{treats}, Dis2)$; $(D\\_D, \\text{treats}, Dis3)$\n*   $(D\\_E, \\text{binds}, P1)$\n*   $(D\\_F, \\text{treats}, Dis3)$\n*   $(P1, \\text{inhibited\\_by}, D\\_A)$; $(Dis1, \\text{has\\_contraindicated\\_drug}, D\\_B)$; $(Dis2, \\text{has\\_indicated\\_drug}, D\\_D)$; $(PW1, \\text{has\\_participating\\_drug}, D\\_A)$; $(P3, \\text{activated\\_by}, D\\_D)$; $(Dis3, \\text{has\\_contraindicated\\_drug}, D\\_A)$; $(P4, \\text{inhibited\\_by}, D\\_C)$\n\n**定义与变量：**\n*   药物节点集：$d \\in \\{D\\_A, D\\_B, D\\_C, D\\_D, D\\_E, D\\_F\\}$\n*   出度 $k_{\\text{out}}(d)$：$d$ 作为主语的三元组数量。\n*   入度 $k_{\\text{in}}(d)$：$d$ 作为宾语的三元组数量。\n*   经验分布 $p_{\\text{out}}(k)$ 和 $p_{\\text{in}}(k)$ 由相对频率定义。\n\n**建模假设与任务：**\n*   药物节点的出度尾部在 $k \\ge x_{\\min}$ 时遵循连续幂律分布。\n*   幂律概率密度函数（PDF）为 $p(k) \\propto k^{-\\alpha}$。\n*   尾部的最小值为 $x_{\\min} = 2$。\n*   推导 $\\alpha$ 的最大似然估计量（MLE）。\n*   计算药物出度的 $\\alpha$ 值，并四舍五入到4位有效数字。\n*   在多重药理学的背景下解释结果。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题在网络理论和生物信息学方面具有科学依据。RDF知识图谱、度分布、幂律和最大似然估计等概念都是标准概念。其在多重药理学上的应用是一个成熟的研究领域。该问题是适定的（well-posed），提供了所有必要的数据和定义以得出唯一解。语言客观且正式。对于一个离散量（节点度）假设其遵循连续幂律分布，是一种在推导估计量时常用且被广泛接受的近似方法，特别是为了简化微积分计算。这不构成科学缺陷，而是一个明确的建模选择。因此，该问题被认为是有效的。\n\n### 步骤 3：结论与行动\n问题有效。将提供完整解答。\n\n### 解题推导\n\n首先，我们根据所提供的三元组计算每个药物节点的出度和入度。\n\n**出度（$k_{\\text{out}}$）：**\n*   $k_{\\text{out}}(D\\_A) = 5$ （是5个三元组的主语）\n*   $k_{\\text{out}}(D\\_B) = 4$ （是4个三元组的主语）\n*   $k_{\\text{out}}(D\\_C) = 2$ （是2个三元组的主语）\n*   $k_{\\text{out}}(D\\_D) = 6$ （是6个三元组的主语）\n*   $k_{\\text{out}}(D\\_E) = 1$ （是1个三元组的主语）\n*   $k_{\\text{out}}(D\\_F) = 1$ （是1个三元组的主语）\n出度集合为 $\\{5, 4, 2, 6, 1, 1\\}$。药物节点总数为 $N=6$。\n经验出度分布 $p_{\\text{out}}(k)$ 为：\n*   $p_{\\text{out}}(1) = \\frac{2}{6} = \\frac{1}{3}$\n*   $p_{\\text{out}}(2) = \\frac{1}{6}$\n*   $p_{\\text{out}}(4) = \\frac{1}{6}$\n*   $p_{\\text{out}}(5) = \\frac{1}{6}$\n*   $p_{\\text{out}}(6) = \\frac{1}{6}$\n*   $p_{\\text{out}}(k) = 0$ 对于其他 $k$ 值。\n\n**入度（$k_{\\text{in}}$）：**\n*   $k_{\\text{in}}(D\\_A) = 3$ （是3个三元组的宾语）\n*   $k_{\\text{in}}(D\\_B) = 1$ （是1个三元组的宾语）\n*   $k_{\\text{in}}(D\\_C) = 1$ （是1个三元组的宾语）\n*   $k_{\\text{in}}(D\\_D) = 2$ （是2个三元组的宾语）\n*   $k_{\\text{in}}(D\\_E) = 0$ （是0个三元组的宾语）\n*   $k_{\\text{in}}(D\\_F) = 0$ （是0个三元组的宾语）\n入度集合为 $\\{3, 1, 1, 2, 0, 0\\}$。\n经验入度分布 $p_{\\text{in}}(k)$ 为：\n*   $p_{\\text{in}}(0) = \\frac{2}{6} = \\frac{1}{3}$\n*   $p_{\\text{in}}(1) = \\frac{2}{6} = \\frac{1}{3}$\n*   $p_{\\text{in}}(2) = \\frac{1}{6}$\n*   $p_{\\text{in}}(3) = \\frac{1}{6}$\n*   $p_{\\text{in}}(k) = 0$ 对于其他 $k$ 值。\n\n接下来，我们推导连续幂律分布的指数 $\\alpha$ 的最大似然估计量。其概率密度函数（PDF）在 $k \\ge x_{\\min}$ 时由 $p(k) \\propto k^{-\\alpha}$ 给出。\n首先，我们必须对PDF进行归一化。设 $p(k) = Ck^{-\\alpha}$。\n$$ \\int_{x_{\\min}}^{\\infty} Ck^{-\\alpha} \\, dk = 1 $$\n$$ C \\left[ \\frac{k^{-\\alpha+1}}{1-\\alpha} \\right]_{x_{\\min}}^{\\infty} = 1 $$\n为保证收敛，我们需要 $1-\\alpha  0$，即 $\\alpha > 1$。在此条件下，$\\infty$ 处的项为 $0$。\n$$ C \\left( 0 - \\frac{x_{\\min}^{1-\\alpha}}{1-\\alpha} \\right) = 1 \\implies C = (\\alpha-1)x_{\\min}^{\\alpha-1} $$\n归一化后的PDF为 $p(k|\\alpha, x_{\\min}) = (\\alpha-1)x_{\\min}^{\\alpha-1} k^{-\\alpha}$。\n\n给定一组 $n$ 个观测值 $\\{k_i\\}$，其中每个 $k_i \\ge x_{\\min}$，其似然函数为：\n$$ L(\\alpha) = \\prod_{i=1}^{n} p(k_i|\\alpha, x_{\\min}) = \\prod_{i=1}^{n} (\\alpha-1)x_{\\min}^{\\alpha-1} k_i^{-\\alpha} $$\n对数似然函数 $\\mathcal{L}(\\alpha) = \\ln(L(\\alpha))$ 更易于最大化：\n$$ \\mathcal{L}(\\alpha) = \\sum_{i=1}^{n} \\ln\\left( (\\alpha-1)x_{\\min}^{\\alpha-1} k_i^{-\\alpha} \\right) $$\n$$ \\mathcal{L}(\\alpha) = \\sum_{i=1}^{n} \\left[ \\ln(\\alpha-1) + (\\alpha-1)\\ln(x_{\\min}) - \\alpha\\ln(k_i) \\right] $$\n$$ \\mathcal{L}(\\alpha) = n\\ln(\\alpha-1) + n(\\alpha-1)\\ln(x_{\\min}) - \\alpha\\sum_{i=1}^{n}\\ln(k_i) $$\n为了找到最大值，我们将关于 $\\alpha$ 的导数设为零：\n$$ \\frac{d\\mathcal{L}}{d\\alpha} = \\frac{n}{\\alpha-1} + n\\ln(x_{\\min}) - \\sum_{i=1}^{n}\\ln(k_i) = 0 $$\n求解估计量 $\\hat{\\alpha}$：\n$$ \\frac{n}{\\hat{\\alpha}-1} = \\sum_{i=1}^{n}\\ln(k_i) - n\\ln(x_{\\min}) = \\sum_{i=1}^{n} \\ln\\left(\\frac{k_i}{x_{\\min}}\\right) $$\n$$ \\hat{\\alpha}-1 = n \\left( \\sum_{i=1}^{n} \\ln\\left(\\frac{k_i}{x_{\\min}}\\right) \\right)^{-1} $$\n$$ \\hat{\\alpha} = 1 + n \\left( \\sum_{i=1}^{n} \\ln\\left(\\frac{k_i}{x_{\\min}}\\right) \\right)^{-1} $$\n这就是 $\\alpha$ 的最大似然估计量（MLE）。\n\n现在，我们将此估计量应用于药物出度数据。所有出度的集合为 $\\{5, 4, 2, 6, 1, 1\\}$。阈值为 $x_{\\min} = 2$。我们选取数据点 $k_i \\ge x_{\\min}$：$\\{5, 4, 2, 6\\}$。这些数据点的数量为 $n=4$。\n我们计算分母中的和：\n$$ \\sum_{i=1}^{4} \\ln\\left(\\frac{k_i}{x_{\\min}}\\right) = \\ln\\left(\\frac{5}{2}\\right) + \\ln\\left(\\frac{4}{2}\\right) + \\ln\\left(\\frac{2}{2}\\right) + \\ln\\left(\\frac{6}{2}\\right) $$\n$$ = \\ln(2.5) + \\ln(2) + \\ln(1) + \\ln(3) $$\n使用属性 $\\ln(a) + \\ln(b) = \\ln(ab)$ 以及 $\\ln(1)=0$：\n$$ = \\ln(2.5 \\times 2 \\times 3) = \\ln(15) $$\n将此代入MLE公式：\n$$ \\hat{\\alpha} = 1 + \\frac{4}{\\ln(15)} $$\n数值上，$\\ln(15) \\approx 2.70805$。\n$$ \\hat{\\alpha} \\approx 1 + \\frac{4}{2.70805} \\approx 1 + 1.47707 \\approx 2.47707 $$\n四舍五入到4位有效数字，我们得到 $\\hat{\\alpha} = 2.477$。\n\n**解释：**\n药物 $d$ 的出度 $k_{\\text{out}}(d)$ 代表了以它为起点的关系数量，例如与蛋白质结合、治疗疾病或参与通路。一个重尾的出度分布，如指数 $\\hat{\\alpha} \\approx 2.477$（这是真实世界网络中的典型值）的幂律分布所示，意味着大多数药物只有少数几个连接，但少数“枢纽”药物拥有非常多的连接。在这个数据集中，药物 $D\\_A$（$k_{\\text{out}}=5$）和 $D\\_D$（$k_{\\text{out}}=6$）就是这样的枢纽。\n多重药理学（Polypharmacology）是指单一药物作用于多个分子靶点的现象。'binds'（结合）关系就是对此的直接体现。药物 $D\\_A$ 和 $D\\_D$ 分别与3个和4个蛋白质结合，这体现了多重药理学。$p_{\\text{out}}(k)$ 的重尾特性表明，这种多重药理学现象并非均匀分布，而是少数高度连接药物的特征。这对药物发现具有深远的影响，表明某些药物可能通过多靶点作用来达到疗效，但也可能因此具有更高的脱靶副作用倾向。", "answer": "$$\n\\boxed{2.477}\n$$", "id": "4577536"}, {"introduction": "知识图谱是通过链接预测任务来产生假设的强大工具，例如预测新的基因-疾病关联。为了评估这些预测的质量，我们需要严谨的评估指标。本练习要求您从第一性原理出发，实现标准的排序指标——Hits@k ($\\text{Hits@}k$) 和平均倒数排名 (Mean Reciprocal Rank, $\\text{MRR}$)。您将使用预训练的实体嵌入向量对候选预测进行评分和排序，确定性地处理平局情况，并汇总结果以产生模型性能的量化度量，这是该领域任何机器学习实践者的关键技能。[@problem_id:4577593]", "problem": "给定从基因-疾病知识图谱中训练出的生物医学实体的低维向量表示。每个基因和每种疾病都由一个 $\\mathbb{R}^d$ 空间中的向量表示。基因向量和疾病向量之间的相似度定义为余弦相似度，即向量经过 $\\ell_2$-归一化后的点积。根据信息检索中排序评估的基本原则，通过按相似度降序对疾病进行排序，为每个查询基因定义候选疾病的全序关系。如果两种疾病与一个查询基因的相似度完全相等，则通过将排名赋予整数索引较小的疾病来确定性地打破平局。\n\n仅使用这些原则和定义，实现一个程序，为每个测试用例从基本原则计算以下两个查询聚合排序指标：\n- Hits at $k$（记作 $\\text{Hits@}k$）：对于一个固定的整数 $k \\geq 1$，对每个查询基因计算其相关疾病中是否至少有一个出现在排序列表的前 $k$ 个位置，然后将这些二元结果在测试用例中的所有查询基因上取平均，得到一个表示为小数的 $[0,1]$ 范围内的值。\n- 平均倒数排名（记作 $\\text{MRR}$）：对每个查询基因，确定排名最高的那个相关疾病的排名位置（最高位置为 1）；取该排名的倒数；然后在测试用例中的所有查询基因上对这些倒数取平均，得到一个表示为小数的 $(0,1]$ 范围内的值。\n\n评分函数必须是经过 $\\ell_2$-归一化的基因和疾病嵌入之间的余弦相似度。提供的所有向量都是非零的。排名必须严格遵循余弦相似度降序，并使用上述的确定性平局打破规则。对于有多个相关疾病的查询基因，使用排名最高的相关疾病来确定倒数排名。查询总是至少有一个相关疾病。\n\n您的程序必须完全按照描述实现评估，并为以下测试套件计算指标。在每个案例中，疾病索引是基于零的整数，基因索引也是基于零的整数。所有嵌入均按行提供。\n\n测试用例 $\\mathrm{A}$（顺利路径，平局不影响最高位置）：\n- 疾病嵌入 $\\mathbf{D}^{(\\mathrm{A})} \\in \\mathbb{R}^{4 \\times 3}$：\n  - 第 $0$ 行：$[1,0,0]$\n  - 第 $1$ 行：$[0,1,0]$\n  - 第 $2$ 行：$[0,0,1]$\n  - 第 $3$ 行：$[-1,0,0]$\n- 基因嵌入 $\\mathbf{G}^{(\\mathrm{A})} \\in \\mathbb{R}^{2 \\times 3}$：\n  - 第 $0$ 行：$[0.9,0.1,0.0]$\n  - 第 $1$ 行：$[0.0,0.7,0.7]$\n- 相关疾病集合 $\\mathcal{T}^{(\\mathrm{A})}$：\n  - 基因 $0$：$\\{0\\}$\n  - 基因 $1$：$\\{2\\}$\n- 要求的 $k$ 值：$k \\in \\{1,3\\}$\n\n测试用例 $\\mathrm{B}$（单个查询，有多个相关疾病，且在最高位置有决定性平局，通过索引解决）：\n- 疾病嵌入 $\\mathbf{D}^{(\\mathrm{B})} \\in \\mathbb{R}^{5 \\times 5}$：\n  - 第 $0$ 行：$[1,0,0,0,0]$\n  - 第 $1$ 行：$[0,1,0,0,0]$\n  - 第 $2$ 行：$[0,0,1,0,0]$\n  - 第 $3$ 行：$[0,0,0,1,0]$\n  - 第 $4$ 行：$[0,0,0,0,1]$\n- 基因嵌入 $\\mathbf{G}^{(\\mathrm{B})} \\in \\mathbb{R}^{1 \\times 5}$：\n  - 第 $0$ 行：$[0,1,1,0,0]$\n- 相关疾病集合 $\\mathcal{T}^{(\\mathrm{B})}$：\n  - 基因 $0$：$\\{2,4\\}$\n- 要求的 $k$ 值：$k \\in \\{1,2\\}$\n\n测试用例 $\\mathrm{C}$（所有疾病之间存在对抗性平局，完全通过索引解决，有三个查询）：\n- 疾病嵌入 $\\mathbf{D}^{(\\mathrm{C})} \\in \\mathbb{R}^{3 \\times 3}$：\n  - 第 $0$ 行：$[1,0,0]$\n  - 第 $1$ 行：$[0,1,0]$\n  - 第 $2$ 行：$[0,0,1]$\n- 基因嵌入 $\\mathbf{G}^{(\\mathrm{C})} \\in \\mathbb{R}^{3 \\times 3}$：\n  - 第 $0$ 行：$[1,1,1]$\n  - 第 $1$ 行：$[1,1,1]$\n  - 第 $2$ 行：$[1,1,1]$\n- 相关疾病集合 $\\mathcal{T}^{(\\mathrm{C})}$：\n  - 基因 $0$：$\\{1\\}$\n  - 基因 $1$：$\\{2\\}$\n  - 基因 $2$：$\\{0\\}$\n- 要求的 $k$ 值：$k \\in \\{1,2\\}$\n\n您的程序必须：\n- 在计算余弦相似度之前，将所有嵌入归一化为单位 $\\ell_2$-范数。\n- 对于每个测试用例，使用上述定义计算 $\\text{MRR}$ 和每个要求的 $\\text{Hits@}k$。\n- 对于完全相等的余弦相似度，使用基于疾病索引升序的平局打破规则。\n\n最终输出格式：\n- 生成单行输出，包含一个由方括号括起来的逗号分隔列表，其中的值按以下顺序排列：\n  - 对于测试用例 $\\mathrm{A}$：$\\text{MRR}$，然后是 $\\text{Hits@}1$，然后是 $\\text{Hits@}3$。\n  - 对于测试用例 $\\mathrm{B}$：$\\text{MRR}$，然后是 $\\text{Hits@}1$，然后是 $\\text{Hits@}2$。\n  - 对于测试用例 $\\mathrm{C}$：$\\text{MRR}$，然后是 $\\text{Hits@}1$，然后是 $\\text{Hits@}2$。\n- 每个值必须四舍五入到恰好 $6$ 位小数，并表示为十进制数。\n- 例如，一个有效的输出形式为 $[x_1,x_2,\\dots,x_9]$，其中每个 $x_i$ 是一个小数点后恰好有 $6$ 位数字的十进制数。", "solution": "问题陈述已经过严格验证，被认为是科学可靠、定义明确且客观的。它代表了知识图谱嵌入评估中的一个标准任务，这是生物信息学和机器学习的一个子领域。所有定义、数据和约束都是完整、一致且可形式化的。因此，下面将给出一个解决方案。\n\n该问题要求为以向量表示的生物医学实体实现一个排序评估流程。评估基于信息检索的基本原则。对于每个基因-疾病测试用例，解决方案分四个主要阶段进行：1) 向量归一化，2) 相似度评分，3) 使用确定性平局打破规则进行排序，以及 4) 计算聚合性能指标。\n\n**1. 向量归一化**\n嵌入空间 $\\mathbb{R}^d$ 中的每个向量 $\\mathbf{v}$ 必须首先被投影到单位超球面上。这是通过 $\\ell_2$-归一化实现的。归一化后的向量 $\\hat{\\mathbf{v}}$ 由下式给出：\n$$\n\\hat{\\mathbf{v}} = \\frac{\\mathbf{v}}{\\|\\mathbf{v}\\|_2}\n$$\n其中 $\\|\\mathbf{v}\\|_2$ 是 $\\mathbf{v}$ 的欧几里得范数（或 $\\ell_2$-范数），计算方式为 $\\|\\mathbf{v}\\|_2 = \\sqrt{\\sum_{i=1}^d v_i^2}$。由于问题保证所有向量都是非零的，此操作总是有定义的。\n\n**2. 相似度评分**\n查询基因向量 $\\mathbf{g}$ 和候选疾病向量 $\\mathbf{d}$ 之间的相似度是余弦相似度。归一化后，这等同于归一化向量的点积：\n$$\n\\text{sim}(\\mathbf{g}, \\mathbf{d}) = \\cos(\\theta) = \\hat{\\mathbf{g}} \\cdot \\hat{\\mathbf{d}} = \\sum_{i=1}^d \\hat{g}_i \\hat{d}_i\n$$\n该分数范围从 -1（完全反向相似）到 1（完全相似）。\n\n**3. 排序与平局打破**\n对于每个查询基因 $\\mathbf{g}_i$，我们计算它与数据集中每个疾病 $\\mathbf{d}_j$ 的相似度分数，得到一组分数 $\\{s_{ij}\\}_{j=0}^{N_d-1}$。为了建立一个确定的排名，我们构建（分数，疾病索引）对：$(s_{ij}, j)$。这些对根据一个字典序键进行排序。主要排序标准是分数 $s_{ij}$ 的降序。次要标准仅在两个分数相同时（$s_{ij_1} = s_{ij_2}$）应用，即疾病索引 $j$ 的升序。这个确定性规则确保了对于任何给定的查询，所有疾病都有一个唯一的全序关系。\n\n**4. 性能指标**\n使用为每个查询基因生成的排序列表，我们计算两个标准指标：\n\n- **平均倒数排名 (MRR):** 对于一个查询基因 $\\mathbf{g}_i$ 及其相关疾病集合 $\\mathcal{T}_i$，我们确定其列表中排名最高的相关疾病的排名。这表示为 $\\text{rank}_i = \\min_{j \\in \\mathcal{T}_i} \\text{rank}(j)$。倒数排名为 $1/\\text{rank}_i$。MRR 是这些值在所有 $N_g$ 个查询上的算术平均值：\n$$\n\\text{MRR} = \\frac{1}{N_g} \\sum_{i=0}^{N_g-1} \\frac{1}{\\text{rank}_i}\n$$\n\n- **Hits at $k$ ($\\text{Hits@}k$):** 对于一个给定的整数 $k \\ge 1$，我们检查查询 $\\mathbf{g}_i$ 的任何相关疾病是否出现在其排序列表的前 $k$ 个位置内。这产生一个二元结果 $h_i(k)$：\n$$\nh_i(k) =\n\\begin{cases}\n1  \\text{if } \\exists j \\in \\mathcal{T}_i \\text{ such that } \\text{rank}(j) \\le k \\\\\n0  \\text{otherwise}\n\\end{cases}\n$$\n$\\text{Hits@}k$ 指标是这些结果在所有 $N_g$ 个查询上的平均值：\n$$\n\\text{Hits@}k = \\frac{1}{N_g} \\sum_{i=0}^{N_g-1} h_i(k)\n$$\n\n以下各节将此方法应用于每个测试用例。\n\n**测试用例 A**\n- 提供了疾病嵌入 $\\mathbf{D}^{(\\mathrm{A})}$ 和基因嵌入 $\\mathbf{G}^{(\\mathrm{A})}$。疾病向量 $\\mathbf{d}_0, \\mathbf{d}_1, \\mathbf{d}_2, \\mathbf{d}_3$ 已经是单位向量。\n- 基因向量被归一化：\n  - $\\mathbf{g}_0 = [0.9,0.1,0.0] \\implies \\|\\mathbf{g}_0\\|_2 = \\sqrt{0.82} \\implies \\hat{\\mathbf{g}}_0 \\approx [0.9938, 0.1104, 0.0]$\n  - $\\mathbf{g}_1 = [0.0, 0.7, 0.7] \\implies \\|\\mathbf{g}_1\\|_2 = \\sqrt{0.98} \\implies \\hat{\\mathbf{g}}_1 \\approx [0.0, 0.7071, 0.7071]$\n- 查询 1（$i=0$，相关疾病 $\\mathcal{T}_0=\\{0\\}$）：\n  - 分数：$\\text{sim}(\\mathbf{g}_0, \\mathbf{d}_0) \\approx 0.9938$，$\\text{sim}(\\mathbf{g}_0, \\mathbf{d}_1) \\approx 0.1104$，$\\text{sim}(\\mathbf{g}_0, \\mathbf{d}_2)=0.0$，$\\text{sim}(\\mathbf{g}_0, \\mathbf{d}_3)\\approx -0.9938$。\n  - 排序列表：$[0, 1, 2, 3]$。相关疾病 $0$ 排名为 $1$。\n  - RR: $1/1 = 1.0$。Hits@1: $1$。Hits@3: $1$。\n- 查询 2（$i=1$，相关疾病 $\\mathcal{T}_1=\\{2\\}$）：\n  - 分数：$\\text{sim}(\\mathbf{g}_1, \\mathbf{d}_0)=0.0$，$\\text{sim}(\\mathbf{g}_1, \\mathbf{d}_1) \\approx 0.7071$，$\\text{sim}(\\mathbf{g}_1, \\mathbf{d}_2) \\approx 0.7071$，$\\text{sim}(\\mathbf{g}_1, \\mathbf{d}_3)=0.0$。\n  - 疾病 1 和 2 之间存在平局。由于 $1  2$，疾病 1 排名更高。疾病 0 和 3 之间存在平局，由于 $03$，所以 0 排名更高。\n  - 排序列表：$[1, 2, 0, 3]$。相关疾病 $2$ 排名为 $2$。\n  - RR: $1/2 = 0.5$。Hits@1: $0$。Hits@3: $1$。\n- 案例 A 的聚合结果：\n  - MRR = $(1.0 + 0.5) / 2 = 0.75$\n  - Hits@1 = $(1 + 0) / 2 = 0.5$\n  - Hits@3 = $(1 + 1) / 2 = 1.0$\n\n**测试用例 B**\n- 疾病嵌入 $\\mathbf{D}^{(\\mathrm{B})}$ 是标准基向量，已经归一化。\n- 基因向量被归一化：$\\mathbf{g}_0 = [0,1,1,0,0] \\implies \\|\\mathbf{g}_0\\|_2 = \\sqrt{2} \\implies \\hat{\\mathbf{g}}_0 = [0, 1/\\sqrt{2}, 1/\\sqrt{2}, 0, 0] \\approx [0, 0.7071, 0.7071, 0, 0]$。\n- 查询 1（$i=0$，相关疾病 $\\mathcal{T}_0=\\{2, 4\\}$）：\n  - 分数：$s_{00}=0, s_{01} \\approx 0.7071, s_{02} \\approx 0.7071, s_{03}=0, s_{04}=0$。\n  - 疾病 1 和 2 之间存在平局。由于 $1  2$，疾病 1 排名更高。疾病 0, 3, 4 之间存在平局，排名遵循索引顺序：0, 3, 4。\n  - 排序列表：$[1, 2, 0, 3, 4]$。\n  - 相关疾病是 2（排名 2）和 4（排名 5）。排名最高的是疾病 2，排名为 2。\n  - RR: $1/2 = 0.5$。Hits@1: $0$。Hits@2: $1$。\n- 案例 B 的聚合结果（单个查询）：\n  - MRR = $0.5$\n  - Hits@1 = $0.0$\n  - Hits@2 = $1.0$\n\n**测试用例 C**\n- 疾病嵌入 $\\mathbf{D}^{(\\mathrm{C})}$ 是标准基向量，已经归一化。\n- 所有基因向量都相同：$\\mathbf{g}_i = [1,1,1] \\implies \\|\\mathbf{g}_i\\|_2 = \\sqrt{3} \\implies \\hat{\\mathbf{g}}_i = [1/\\sqrt{3}, 1/\\sqrt{3}, 1/\\sqrt{3}] \\approx [0.5774, 0.5774, 0.5774]$。\n- 对于任何查询基因，与所有三种疾病的相似度分数都相同：$s_{i0} = s_{i1} = s_{i2} = 1/\\sqrt{3}$。\n- 排名完全由平局打破规则（疾病索引升序）决定。\n- 所有查询的排序列表为：$[0, 1, 2]$。\n- 查询 1（$i=0$，相关疾病 $\\mathcal{T}_0=\\{1\\}$）：疾病 $1$ 排名为 $2$。RR: $1/2$。Hits@1:$0$。Hits@2:$1$。\n- 查询 2（$i=1$，相关疾病 $\\mathcal{T}_1=\\{2\\}$）：疾病 $2$ 排名为 $3$。RR: $1/3$。Hits@1:$0$。Hits@2:$0$。\n- 查询 3（$i=2$，相关疾病 $\\mathcal{T}_2=\\{0\\}$）：疾病 $0$ 排名为 $1$。RR: $1/1$。Hits@1:$1$。Hits@2:$1$。\n- 案例 C 的聚合结果：\n  - MRR = $(1/2 + 1/3 + 1/1) / 3 = (11/6) / 3 = 11/18 \\approx 0.611111$\n  - Hits@1 = $(0 + 0 + 1) / 3 = 1/3 \\approx 0.333333$\n  - Hits@2 = $(1 + 0 + 1) / 3 = 2/3 \\approx 0.666667$", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to define test cases, run the evaluation, and print results.\n    \"\"\"\n    \n    test_cases = [\n        {\n            \"name\": \"A\",\n            \"gene_embeds\": np.array([\n                [0.9, 0.1, 0.0],\n                [0.0, 0.7, 0.7]\n            ]),\n            \"disease_embeds\": np.array([\n                [1.0, 0.0, 0.0],\n                [0.0, 1.0, 0.0],\n                [0.0, 0.0, 1.0],\n                [-1.0, 0.0, 0.0]\n            ]),\n            \"relevant_sets\": [\n                {0},\n                {2}\n            ],\n            \"k_values\": [1, 3]\n        },\n        {\n            \"name\": \"B\",\n            \"gene_embeds\": np.array([\n                [0.0, 1.0, 1.0, 0.0, 0.0]\n            ]),\n            \"disease_embeds\": np.array([\n                [1.0, 0.0, 0.0, 0.0, 0.0],\n                [0.0, 1.0, 0.0, 0.0, 0.0],\n                [0.0, 0.0, 1.0, 0.0, 0.0],\n                [0.0, 0.0, 0.0, 1.0, 0.0],\n                [0.0, 0.0, 0.0, 0.0, 1.0]\n            ]),\n            \"relevant_sets\": [\n                {2, 4}\n            ],\n            \"k_values\": [1, 2]\n        },\n        {\n            \"name\": \"C\",\n            \"gene_embeds\": np.array([\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0]\n            ]),\n            \"disease_embeds\": np.array([\n                [1.0, 0.0, 0.0],\n                [0.0, 1.0, 0.0],\n                [0.0, 0.0, 1.0]\n            ]),\n            \"relevant_sets\": [\n                {1},\n                {2},\n                {0}\n            ],\n            \"k_values\": [1, 2]\n        }\n    ]\n\n    final_results = []\n    \n    for case in test_cases:\n        metrics = evaluate_case(\n            case[\"gene_embeds\"],\n            case[\"disease_embeds\"],\n            case[\"relevant_sets\"],\n            case[\"k_values\"]\n        )\n        final_results.extend(metrics)\n\n    formatted_results = [f\"{val:.6f}\" for val in final_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef evaluate_case(gene_embeds, disease_embeds, relevant_sets, k_values):\n    \"\"\"\n    Computes MRR and Hits@k for a single test case.\n    \"\"\"\n    # 1. L2-normalize all embeddings\n    gene_norms = np.linalg.norm(gene_embeds, axis=1, keepdims=True)\n    disease_norms = np.linalg.norm(disease_embeds, axis=1, keepdims=True)\n    \n    # Avoid division by zero, though problem guarantees non-zero vectors\n    gene_norms[gene_norms == 0] = 1e-10\n    disease_norms[disease_norms == 0] = 1e-10\n    \n    norm_gene_embeds = gene_embeds / gene_norms\n    norm_disease_embeds = disease_embeds / disease_norms\n    \n    num_queries = gene_embeds.shape[0]\n    num_diseases = disease_embeds.shape[0]\n    \n    reciprocal_ranks = []\n    hits_at_k_per_query = {k: [] for k in k_values}\n    \n    for i in range(num_queries):\n        query_gene_vec = norm_gene_embeds[i, :]\n        relevant_diseases = relevant_sets[i]\n        \n        # 2. Compute cosine similarities (dot product of normalized vectors)\n        scores = np.dot(norm_disease_embeds, query_gene_vec)\n        \n        # 3. Create pairs of (score, index) and rank them\n        # Sorting key: primary is score descending, secondary is index ascending\n        score_index_pairs = list(zip(scores, range(num_diseases)))\n        score_index_pairs.sort(key=lambda x: (-x[0], x[1]))\n        \n        ranked_disease_indices = [idx for score, idx in score_index_pairs]\n        \n        # 4. Find rank of the highest-ranked relevant disease for MRR\n        min_rank = -1\n        for rank_pos, disease_idx in enumerate(ranked_disease_indices, 1):\n            if disease_idx in relevant_diseases:\n                min_rank = rank_pos\n                break\n        \n        # Problem guarantees at least one relevant disease, so min_rank is always found\n        reciprocal_ranks.append(1.0 / min_rank)\n        \n        # 5. Compute Hits@k for each k\n        for k in k_values:\n            top_k_indices = set(ranked_disease_indices[:k])\n            # Intersection is non-empty if there's a hit\n            if not top_k_indices.isdisjoint(relevant_diseases):\n                hits_at_k_per_query[k].append(1)\n            else:\n                hits_at_k_per_query[k].append(0)\n\n    # 6. Aggregate metrics across all queries\n    mrr = np.mean(reciprocal_ranks)\n    \n    # Sort k_values to ensure deterministic output order\n    sorted_k = sorted(k_values)\n    hits_results = [np.mean(hits_at_k_per_query[k]) for k in sorted_k]\n    \n    return [mrr] + hits_results\n\n# Execute the solution\nsolve()\n```", "id": "4577593"}]}