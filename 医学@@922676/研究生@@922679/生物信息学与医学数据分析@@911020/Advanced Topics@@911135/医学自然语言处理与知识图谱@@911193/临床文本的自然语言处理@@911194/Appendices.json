{"hands_on_practices": [{"introduction": "在任何自然语言处理（NLP）流程中，将原始文本分解为可处理的单元——即分词（tokenization）——是至关重要的第一步。本练习 [@problem_id:4588759] 旨在通过对比简单的空白分词、更复杂的基于规则的分词以及现代的子词（subword）分词方法，让您深入理解不同策略如何影响词汇量和未登录词（out-of-vocabulary）率等关键指标。掌握这些基础知识对于处理结构复杂、充满专业术语的临床文本至关重要。", "problem": "请考虑以下临床记录片段（原文照录，包括标点和空格）：\nPt c/o chest pain, 2/10, onset ~3h ago; Na 142 mg/dL; uh... denies SOB.\n\n您将分析应用于此片段的三种分词方案，计算它们的词元计数和词表外（out-of-vocabulary）率，然后将这些量组合成一个标量。请根据下述的分词和词表外率定义，从第一性原理出发进行计算。\n\n分词方案：\n1. 空格分词：仅根据空格（即空格字符）分割片段。不执行标点分割；如果存在标点，则标点仍附着于周围的文本。\n2. 保留数值单位的基于规则的分词：\n   - 首先如上所述按空格分割，以获得初步的词元。\n   - 然后，对于每个初步的词元：\n     - 如果词元包含精确子字符串“...”，则将其分割为“...”之前（如果非空）的子字符串和一个单独的词元“...”。\n     - 分离任何作为单个尾随字符的逗号、分号或句号（“,”、“;”、“.”），并将其作为独立的词元输出。不要在斜杠（“/”）内部进行分割，当标点是单位的一部分（例如“mg/dL”）或三字符省略号“...”的一部分时，不要分离标点。\n   - 处理完标点后，合并数值-单位表达式：如果一个词元是纯数字，或可选地以“~”为前缀的数字（即“~”后跟数字，或仅数字），且紧随其后的是来自单位列表 U = {\"mg/dL\", \"mmHg\", \"h\"} 的一个单位词元，则将这两个词元合并成一个单一词元，通过串联连接，中间不加任何空格（例如，“142”后跟“mg/dL”变为“142mg/dL”；“~3”后跟“h”等同于“~3h”，它仍然是一个单一词元）。\n3. 子词字节对编码（BPE）风格的分词：\n   - 在子词切分之前，将片段转换为小写。\n   - 按空格分割以获得单词，然后使用贪心最长匹配规则，基于以下子词词表 V_b，从左到右对每个单词进行切分：\n     {\"pt\", \"c\", \"/\", \"o\", \"chest\", \"pain\", \",\", \"2/10\", \"onset\", \"~\", \"3h\", \"ago\", \";\", \"na\", \"142\", \"mg/dl\", \"uh\", \"...\", \"denies\", \"sob\", \".\"}。\n   - 如果一个单词无法使用 V_b 完全切分，则用特殊符号“[UNK]”表示整个单词，作为一个单独的子词词元。对于本问题，仅将字面词元“[UNK]”视为子词级别的词表外词元。\n\n用于确定词表外（OOV）的词典：\n- 对于空格分词，使用词级词典 V_w = {\"Pt\", \"c/o\", \"chest\", \"pain\", \"2/10\", \"onset\", \"~3h\", \"ago\", \"Na\", \"142\", \"mg/dL\", \"uh...\", \"denies\", \"SOB\"}。\n- 对于基于规则的分词，使用词元词典 V_r = {\"Pt\", \"c/o\", \"chest\", \"pain\", \"2/10\", \"onset\", \"~3h\", \"ago\", \"Na\", \"142mg/dL\", \"uh\", \"...\", \"denies\", \"SOB\", \",\", \";\", \".\"}。\n- 对于 BPE 分词，使用上面的子词词表 V_b，并仅将“[UNK]”定义为 OOV 符号。\n\n定义：\n- 在一种分词方案下，词元计数是该方案对片段产生的词元总数。\n- 在一种方案下，词表外率定义为在该方案对应的词典中未找到的词元数量（对于 BPE：等于“[UNK]”的子词词元数量）除以该方案产生的词元总数。\n\n任务：\n- 计算由空格分词、基于规则的分词和 BPE 分词产生的词元数量。分别用 $N_{\\mathrm{ws}}$、$N_{\\mathrm{rule}}$ 和 $N_{\\mathrm{bpe}}$ 表示。\n- 计算每种方案下的词表外率。分别用 $R_{\\mathrm{ws}}$、$R_{\\mathrm{rule}}$ 和 $R_{\\mathrm{bpe}}$ 表示。\n- 最后，计算标量\n$$S \\equiv \\left(N_{\\mathrm{bpe}} - N_{\\mathrm{rule}}\\right) + \\left(R_{\\mathrm{ws}} - R_{\\mathrm{rule}}\\right).$$\n\n请以单个最简分数的形式给出 $S$ 的最终值。不要四舍五入。不需要单位。", "solution": "所提出的问题是计算语言学应用于临床文本的一个明确定义的练习。所有过程和定义都已明确说明，从而可以得到一个唯一且可验证的解。因此，该问题是有效的。我们将通过系统地分析每种指定的分词方案来计算所需的量。\n\n临床记录片段为：“Pt c/o chest pain, 2/10, onset ~3h ago; Na 142 mg/dL; uh... denies SOB.”\n\n**1. 空格分词**\n\n此方案仅根据空格字符分割文本。\n将此规则应用于片段，产生以下词元：\n`\"Pt\"`、`\"c/o\"`、`\"chest\"`、`\"pain,\"`、`\"2/10,\"`、`\"onset\"`、`\"~3h\"`、`\"ago;\"`、`\"Na\"`、`\"142\"`、`\"mg/dL;\"`、`\"uh...\"`、`\"denies\"`、`\"SOB.\"`\n\n词元总数是此列表中元素的数量。\n$$N_{\\mathrm{ws}} = 14$$\n\n接下来，我们计算词表外（OOV）率。给定的词级词典是 $V_w = \\{\"Pt\", \"c/o\", \"chest\", \"pain\", \"2/10\", \"onset\", \"\\~3h\", \"ago\", \"Na\", \"142\", \"mg/dL\", \"uh...\", \"denies\", \"SOB\"\\}$。如果一个词元不在 $V_w$ 中，则它被认为是 OOV。我们检查每个词元：\n- `\"Pt\"`：在 $V_w$ 中\n- `\"c/o\"`：在 $V_w$ 中\n- `\"chest\"`：在 $V_w$ 中\n- `\"pain,\"`：**不在** $V_w$ 中（因为有逗号）\n- `\"2/10,\"`：**不在** $V_w$ 中（因为有逗号）\n- `\"onset\"`：在 $V_w$ 中\n- `\"~3h\"`：在 $V_w$ 中\n- `\"ago;\"`：**不在** $V_w$ 中（因为有分号）\n- `\"Na\"`：在 $V_w$ 中\n- `\"142\"`：在 $V_w$ 中\n- `\"mg/dL;\"`：**不在** $V_w$ 中（因为有分号）\n- `\"uh...\"`：在 $V_w$ 中\n- `\"denies\"`：在 $V_w$ 中\n- `\"SOB.\"`：**不在** $V_w$ 中（因为有句号）\n\nOOV 词元的数量为 $5$。\nOOV 率 $R_{\\mathrm{ws}}$ 是 OOV 词元数与总词元数的比率。\n$$R_{\\mathrm{ws}} = \\frac{5}{14}$$\n\n**2. 基于规则的分词**\n\n此方案涉及一个多步骤过程。\n步骤（a）：按空格进行初始分割，得到与第一种方案相同的 $14$ 个初步词元。\n步骤（b）：标点处理。\n- `\"pain,\"` $\\rightarrow$ `\"pain\"`, `\",\"`\n- `\"2/10,\"` $\\rightarrow$ `\"2/10\"`, `\",\"`\n- `\"ago;\"` $\\rightarrow$ `\"ago\"`, `\";\"`\n- `\"mg/dL;\"` $\\rightarrow$ `\"mg/dL\"`, `\";\"`\n- `\"uh...\"` $\\rightarrow$ `\"uh\"`, `\"...\"`\n- `\"SOB.\"` $\\rightarrow$ `\"SOB\"`, `\".\"`\n此步骤后的词元列表是：\n`\"Pt\"`、`\"c/o\"`、`\"chest\"`、`\"pain\"`、`\",\"`、`\"2/10\"`、`\",\"`、`\"onset\"`、`\"~3h\"`、`\"ago\"`、`\";\"`、`\"Na\"`、`\"142\"`、`\"mg/dL\"`、`\";\"`、`\"uh\"`、`\"...\"`、`\"denies\"`、`\"SOB\"`、`\".\"`\n\n步骤（c）：合并数值-单位表达式。单位列表是 $U = \\{\"mg/dL\", \"mmHg\", \"h\"\\}$。我们寻找一个数字词元后跟一个来自 $U$ 的单位词元的序列。在上面的列表中，词元“142”是一个数字，紧随其后的是“mg/dL”，它在 $U$ 中。这两个词元被合并。\n- `\"142\"`, `\"mg/dL\"` $\\rightarrow$ `\"142mg/dL\"`\n\n基于规则的方案的最终词元列表是：\n`\"Pt\"`、`\"c/o\"`、`\"chest\"`、`\"pain\"`、`\",\"`、`\"2/10\"`、`\",\"`、`\"onset\"`、`\"~3h\"`、`\"ago\"`、`\";\"`、`\"Na\"`、`\"142mg/dL\"`、`\";\"`、`\"uh\"`、`\"...\"`、`\"denies\"`、`\"SOB\"`、`\".\"`\n\n这些词元的总数是：\n$$N_{\\mathrm{rule}} = 19$$\n\n此方案的词典是 $V_r = \\{\"Pt\", \"c/o\", \"chest\", \"pain\", \"2/10\", \"onset\", \"\\~3h\", \"ago\", \"Na\", \"142mg/dL\", \"uh\", \"...\", \"denies\", \"SOB\", \",\", \";\", \".\"\\}$。通过检查，我们基于规则的过程生成的 19 个词元中的每一个都存在于 $V_r$ 中。因此，OOV 词元的数量为 $0$。\nOOV 率是：\n$$R_{\\mathrm{rule}} = \\frac{0}{19} = 0$$\n\n**3. BPE 风格的分词**\n\n步骤（a）：将片段转换为小写：\n`\"pt c/o chest pain, 2/10, onset ~3h ago; na 142 mg/dl; uh... denies sob.\"`\n步骤（b）：按空格分割得到初始单词列表：\n`[\"pt\", \"c/o\", \"chest\", \"pain,\", \"2/10,\", \"onset\", \"~3h\", \"ago;\", \"na\", \"142\", \"mg/dl;\", \"uh...\", \"denies\", \"sob.\"]`\n步骤（c）：使用贪心最长匹配和子词词表 $V_b = \\{\"pt\", \"c\", \"/\", \"o\", \"chest\", \"pain\", \",\", \"2/10\", \"onset\", \"\\~\", \"3h\", \"ago\", \";\", \"na\", \"142\", \"mg/dl\", \"uh\", \"...\", \"denies\", \"sob\", \".\"\\}$ 对每个单词进行切分。\n- `\"pt\"` $\\rightarrow$ `[\"pt\"]` (1个词元)\n- `\"c/o\"` $\\rightarrow$ `[\"c\", \"/\", \"o\"]` (3个词元)\n- `\"chest\"` $\\rightarrow$ `[\"chest\"]` (1个词元)\n- `\"pain,\"` $\\rightarrow$ `[\"pain\", \",\"]` (2个词元)\n- `\"2/10,\"` $\\rightarrow$ `[\"2/10\", \",\"]` (2个词元)\n- `\"onset\"` $\\rightarrow$ `[\"onset\"]` (1个词元)\n- `\"~3h\"` $\\rightarrow$ `[\"~\", \"3h\"]` (2个词元)\n- `\"ago;\"` $\\rightarrow$ `[\"ago\", \";\"]` (2个词元)\n- `\"na\"` $\\rightarrow$ `[\"na\"]` (1个词元)\n- `\"142\"` $\\rightarrow$ `[\"142\"]` (1个词元)\n- `\"mg/dl;\"` $\\rightarrow$ `[\"mg/dl\", \";\"]` (2个词元)\n- `\"uh...\"` $\\rightarrow$ `[\"uh\", \"...\"]` (2个词元)\n- `\"denies\"` $\\rightarrow$ `[\"denies\"]` (1个词元)\n- `\"sob.\"` $\\rightarrow$ `[\"sob\", \".\"]` (2个词元)\n\n所有单词都已完全切分。没有生成 `\"[UNK]\"` 词元。\nBPE 词元的总数是每个单词的计数之和：\n$$N_{\\mathrm{bpe}} = 1 + 3 + 1 + 2 + 2 + 1 + 2 + 2 + 1 + 1 + 2 + 2 + 1 + 2 = 23$$\nOOV 词元的数量，定义为 `\"[UNK]\"` 的计数，是 $0$。\nOOV 率是：\n$$R_{\\mathrm{bpe}} = \\frac{0}{23} = 0$$\n\n**最终计算**\n\n我们需要计算标量 $S$：\n$$S \\equiv \\left(N_{\\mathrm{bpe}} - N_{\\mathrm{rule}}\\right) + \\left(R_{\\mathrm{ws}} - R_{\\mathrm{rule}}\\right)$$\n我们代入上面计算出的值：\n- $N_{\\mathrm{bpe}} = 23$\n- $N_{\\mathrm{rule}} = 19$\n- $R_{\\mathrm{ws}} = \\frac{5}{14}$\n- $R_{\\mathrm{rule}} = 0$\n\n$$S = (23 - 19) + \\left(\\frac{5}{14} - 0\\right)$$\n$$S = 4 + \\frac{5}{14}$$\n为了将其表示为单个分数，我们找到一个公分母：\n$$S = \\frac{4 \\times 14}{14} + \\frac{5}{14} = \\frac{56}{14} + \\frac{5}{14} = \\frac{61}{14}$$\n数字 61 是一个质数，而 $14 = 2 \\times 7$。因此，分数 $\\frac{61}{14}$ 是其最简形式。", "answer": "$$\\boxed{\\frac{61}{14}}$$", "id": "4588759"}, {"introduction": "将文本分词后，下一个挑战是如何量化并比较这些词语的含义。本练习 [@problem_id:4588751] 介绍了一种经典方法：使用词频-逆文档频率（TF-IDF）为词语加权，并构建向量空间模型。通过亲手计算TF-IDF向量并运用余弦相似度，您将学会如何量化“HTN”和“hypertension”这类缩写与其全称之间的语义关系，这是信息检索和文本分析中的一项基本技能。", "problem": "给定一个临床句式小型语料库，要求您在一个标准的自然语言处理（NLP）词袋模型下，计算词元“htn”和“hypertension”的词频-逆文档频率（TF-IDF）向量，然后计算这两个向量之间的余弦相似度，以评估它们在上下文中的同义性。请基于以下基本原理进行操作：文本的向量空间表示，其中每个词项由一个按文档索引的权重向量表示；词频的定义为词项在文档中的计数；逆文档频率的定义为文档总数与包含该词项的文档数之比的对数。请使用以下词元化和归一化规则：转换为小写，移除标点符号，按空格分割，不移除停用词，并将字符串“htn”和“hypertension”视为不同的词元，不进行缩写扩展或词形还原。该语料库包含 $N=5$ 个文档：\n\n文档 $d_{1}$：“Patient with HTN and diabetes; HTN uncontrolled.”\n文档 $d_{2}$：“History of hypertension, treated with Angiotensin-Converting Enzyme (ACE) inhibitors.”\n文档 $d_{3}$：“Hypertension has been noted; HTN stage $2$.”\n文档 $d_{4}$：“No history of HTN; blood pressure normal.”\n文档 $d_{5}$：“Family history negative for hypertension.”\n\n采用以下定义：\n\n- 词频（TF）：对于文档 $d_{i}$ 中的词项 $t$，定义 $\\mathrm{tf}(t,d_{i})$ 为 $t$ 在 $d_{i}$ 中的原始计数。\n- 逆文档频率（IDF）：对于词项 $t$，定义 $\\mathrm{idf}(t) = \\ln\\!\\left(\\frac{N}{\\mathrm{df}(t)}\\right)$，其中 $\\mathrm{df}(t)$ 是包含 $t$ 的文档数，$\\ln$ 表示自然对数。\n- TF-IDF向量：对于词项 $t$，定义按文档索引的向量 $v_{t}$，其第 $i$ 个分量为 $\\mathrm{tf}(t,d_{i}) \\cdot \\mathrm{idf}(t)$。\n- 余弦相似度：对于两个词项向量 $v_{a}$ 和 $v_{b}$，定义 $\\cos\\theta = \\frac{v_{a} \\cdot v_{b}}{\\|v_{a}\\|_{2}\\,\\|v_{b}\\|_{2}}$，其中 $\\cdot$ 表示欧几里得点积，$\\|\\cdot\\|_{2}$ 表示欧几里得范数。\n\n计算TF-IDF向量 $v_{\\text{htn}}$ 和 $v_{\\text{hypertension}}$，然后计算它们之间的余弦相似度。将最终的余弦相似度表示为一个四舍五入到四位有效数字的实数。最终答案不需要单位。", "solution": "问题陈述已经过分析并被认为是有效的。它在科学上基于自然语言处理和向量空间模型的原理，问题提出得很好，提供了所有必要的信息和定义，并且其表述是客观的。因此，我们可以进行完整的解答。\n\n目标是计算词元“htn”和“hypertension”的词频-逆文档频率（TF-IDF）向量之间的余弦相似度。语料库包含 $N=5$ 个文档。该过程涉及几个连续的步骤：计算词频，计算逆文档频率，构建TF-IDF向量，最后计算它们的余弦相似度。\n\n设我们感兴趣的两个词项为 $t_{1} = \\text{\"htn\"}$ 和 $t_{2} = \\text{\"hypertension\"}$。\n\n**步骤1：计算词频（TF）**\n首先，我们将指定的归一化规则（小写，移除标点，按空格分割）应用于文档，并计算每个文档 $d_{i}$ 中 $t_1$ 和 $t_2$ 的出现次数。词频 $\\mathrm{tf}(t, d_{i})$ 是词项 $t$ 在文档 $d_i$ 中的原始计数。\n\n对于 $t_1 = \\text{\"htn\"}$：\n- $d_1$: “Patient with HTN and diabetes; HTN uncontrolled.” $\\rightarrow$ `patient with htn and diabetes htn uncontrolled`。“htn”的计数为 $2$。因此，$\\mathrm{tf}(t_1, d_1) = 2$。\n- $d_2$: “History of hypertension, treated with...” $\\rightarrow$ “htn”的计数为 $0$。因此，$\\mathrm{tf}(t_1, d_2) = 0$。\n- $d_3$: “Hypertension has been noted; HTN stage 2.” $\\rightarrow$ `hypertension has been noted htn stage 2`。“htn”的计数为 $1$。因此，$\\mathrm{tf}(t_1, d_3) = 1$。\n- $d_4$: “No history of HTN; blood pressure normal.” $\\rightarrow$ `no history of htn blood pressure normal`。“htn”的计数为 $1$。因此，$\\mathrm{tf}(t_1, d_4) = 1$。\n- $d_5$: “Family history negative for hypertension.” $\\rightarrow$ “htn”的计数为 $0$。因此，$\\mathrm{tf}(t_1, d_5) = 0$。\n\n语料库中 $t_{1}$ 的词频向量为 $T_{\\text{htn}} = (2, 0, 1, 1, 0)$。\n\n对于 $t_2 = \\text{\"hypertension\"}$：\n- $d_1$: “hypertension”的计数为 $0$。因此，$\\mathrm{tf}(t_2, d_1) = 0$。\n- $d_2$: “History of hypertension...” $\\rightarrow$ `history of hypertension...`。“hypertension”的计数为 $1$。因此，$\\mathrm{tf}(t_2, d_2) = 1$。\n- $d_3$: “Hypertension has been noted...” $\\rightarrow$ `hypertension has been noted...`。“hypertension”的计数为 $1$。因此，$\\mathrm{tf}(t_2, d_3) = 1$。\n- $d_4$: “hypertension”的计数为 $0$。因此，$\\mathrm{tf}(t_2, d_4) = 0$。\n- $d_5$: “Family history negative for hypertension.” $\\rightarrow$ `... for hypertension`。“hypertension”的计数为 $1$。因此，$\\mathrm{tf}(t_2, d_5) = 1$。\n\n$t_{2}$ 的词频向量为 $T_{\\text{hypertension}} = (0, 1, 1, 0, 1)$。\n\n**步骤2：计算逆文档频率（IDF）**\n词项 $t$ 的IDF由公式 $\\mathrm{idf}(t) = \\ln(\\frac{N}{\\mathrm{df}(t)})$ 给出，其中 $N=5$ 是文档总数，$\\mathrm{df}(t)$ 是包含词项 $t$ 的文档数。\n\n对于 $t_1 = \\text{\"htn\"}$：\n词项“htn”出现在文档 $d_{1}$、$d_{3}$ 和 $d_{4}$ 中。因此，文档频率为 $\\mathrm{df}(t_1) = 3$。\nIDF为 $\\mathrm{idf}(t_1) = \\ln(\\frac{5}{3})$。\n\n对于 $t_2 = \\text{\"hypertension\"}$：\n词项“hypertension”出现在文档 $d_{2}$、$d_{3}$ 和 $d_{5}$ 中。因此，文档频率为 $\\mathrm{df}(t_2) = 3$。\nIDF为 $\\mathrm{idf}(t_2) = \\ln(\\frac{5}{3})$。\n\n值得注意的是，两个词项具有相同的IDF值，因为它们出现在相同数量的文档中，这反映了它们在语料库层面具有相同的稀有度。\n\n**步骤3：构建TF-IDF向量**\nTF-IDF向量 $v_{t}$ 的第 $i$ 个分量是词频和逆文档频率的乘积：$(v_t)_i = \\mathrm{tf}(t,d_i) \\cdot \\mathrm{idf}(t)$。\n\n设 $v_{\\text{htn}}$ 是 $t_1$ 的向量，$v_{\\text{hypertension}}$ 是 $t_2$ 的向量。\n$v_{\\text{htn}} = \\left( \\mathrm{tf}(t_1, d_1)\\cdot\\mathrm{idf}(t_1), \\dots, \\mathrm{tf}(t_1, d_5)\\cdot\\mathrm{idf}(t_1) \\right)$\n$v_{\\text{htn}} = \\ln(\\frac{5}{3}) \\cdot (2, 0, 1, 1, 0)$\n\n$v_{\\text{hypertension}} = \\left( \\mathrm{tf}(t_2, d_1)\\cdot\\mathrm{idf}(t_2), \\dots, \\mathrm{tf}(t_2, d_5)\\cdot\\mathrm{idf}(t_2) \\right)$\n$v_{\\text{hypertension}} = \\ln(\\frac{5}{3}) \\cdot (0, 1, 1, 0, 1)$\n\n**步骤4：计算余弦相似度**\n两个向量 $v_{a}$ 和 $v_{b}$ 之间的余弦相似度定义为 $\\cos\\theta = \\frac{v_{a} \\cdot v_{b}}{\\|v_{a}\\|_{2}\\,\\|v_{b}\\|_{2}}$。\n\n设 $I = \\ln(\\frac{5}{3})$。向量为 $v_{\\text{htn}} = I \\cdot T_{\\text{htn}}$ 和 $v_{\\text{hypertension}} = I \\cdot T_{\\text{hypertension}}$。\n\n点积为：\n$$v_{\\text{htn}} \\cdot v_{\\text{hypertension}} = (I \\cdot T_{\\text{htn}}) \\cdot (I \\cdot T_{\\text{hypertension}}) = I^2 (T_{\\text{htn}} \\cdot T_{\\text{hypertension}})$$\n$$T_{\\text{htn}} \\cdot T_{\\text{hypertension}} = (2)(0) + (0)(1) + (1)(1) + (1)(0) + (0)(1) = 1$$\n所以，$v_{\\text{htn}} \\cdot v_{\\text{hypertension}} = I^2 \\cdot 1 = \\left(\\ln(\\frac{5}{3})\\right)^2$。\n\n欧几里得范数为：\n$$\\|v_{\\text{htn}}\\|_{2} = \\|I \\cdot T_{\\text{htn}}\\|_{2} = |I| \\cdot \\|T_{\\text{htn}}\\|_{2}$$\n$$\\|T_{\\text{htn}}\\|_{2} = \\sqrt{2^2 + 0^2 + 1^2 + 1^2 + 0^2} = \\sqrt{4 + 1 + 1} = \\sqrt{6}$$\n所以，$\\|v_{\\text{htn}}\\|_{2} = \\ln(\\frac{5}{3}) \\sqrt{6}$。\n\n$$\\|v_{\\text{hypertension}}\\|_{2} = \\|I \\cdot T_{\\text{hypertension}}\\|_{2} = |I| \\cdot \\|T_{\\text{hypertension}}\\|_{2}$$\n$$\\|T_{\\text{hypertension}}\\|_{2} = \\sqrt{0^2 + 1^2 + 1^2 + 0^2 + 1^2} = \\sqrt{1 + 1 + 1} = \\sqrt{3}$$\n所以，$\\|v_{\\text{hypertension}}\\|_{2} = \\ln(\\frac{5}{3}) \\sqrt{3}$。\n\n现在，我们计算余弦相似度：\n$$\\cos\\theta = \\frac{v_{\\text{htn}} \\cdot v_{\\text{hypertension}}}{\\|v_{\\text{htn}}\\|_{2}\\,\\|v_{\\text{hypertension}}\\|_{2}} = \\frac{\\left(\\ln(\\frac{5}{3})\\right)^2}{\\left(\\ln(\\frac{5}{3})\\sqrt{6}\\right) \\left(\\ln(\\frac{5}{3})\\sqrt{3}\\right)}$$\n公因子 $(\\ln(\\frac{5}{3}))^2$ 从分子和分母中约去，因为它不为零（因为 $\\frac{5}{3} \\neq 1$）。\n$$\\cos\\theta = \\frac{1}{\\sqrt{6} \\cdot \\sqrt{3}} = \\frac{1}{\\sqrt{18}} = \\frac{1}{3\\sqrt{2}}$$\n为了使分母有理化，我们将分子和分母同乘以 $\\sqrt{2}$：\n$$\\cos\\theta = \\frac{\\sqrt{2}}{3\\sqrt{2} \\cdot \\sqrt{2}} = \\frac{\\sqrt{2}}{3 \\cdot 2} = \\frac{\\sqrt{2}}{6}$$\n\n这一结果表明，当两个词项的IDF值相同时，它们的TF-IDF向量的余弦相似度简化为其原始词频向量的余弦相似度。在这种特定情况下，TF-IDF加权不改变向量之间的夹角，只改变它们的模长。相似度值本身是正数但远小于1，这反映了这两个词项在一个文档（$d_3$）中共现，但在其他文档中出现在不同的文档集中，表明在这个语料库中，它们的关系比简单的同义关系更复杂（即，它们不是完全可互换的）。\n\n**步骤5：数值计算**\n最后一步是计算数值并按要求四舍五入到四位有效数字。\n$$\\cos\\theta = \\frac{\\sqrt{2}}{6} \\approx \\frac{1.41421356}{6} \\approx 0.23570226$$\n四舍五入到四位有效数字，我们得到 $0.2357$。", "answer": "$$\\boxed{0.2357}$$", "id": "4588751"}, {"introduction": "在临床应用中，构建模型只是起点，评估其性能并理解其在真实世界中的影响同样重要。本练习 [@problem_id:4588718] 引导您超越简单的准确率，使用精确率（precision）、召回率（recall）和 $F_1$ 分数这些对于不平衡数据集更为有效的指标来评估一个关系提取分类器。更重要的是，它要求您在药物警戒的高风险背景下，解读假阳性（false positives）和假阴性（false negatives）的临床意义，从而将抽象的性能指标与切实的患者安全联系起来。", "problem": "一个临床自然语言处理系统处理去身份化的电子健康记录（EHR），以识别在同一份临床记录中，提及的药物是否与提及的不良事件存在因果关系。一个二元关系分类器在领域专家标注的药物-事件对上进行训练。每个配对被标记为正类 $C$（存在因果药物-事件关系）或负类 $\\neg C$（无因果关系）。在一个包含 $1,500$ 个候选对的留出评估集上，对于正类 $C$ 获得了以下混淆矩阵计数：真阳性 $TP = 208$，假阳性 $FP = 104$，假阴性 $FN = 52$，以及真阴性 $TN = 1,136$。使用信息检索和机器学习中二元分类器评估的基本定义（这些定义源于预测标签和真实标签的集合隶属关系），计算正类的精确率、正类的召回率和 $F_1$ 分数。按以下顺序报告这三个指标：精确率、召回率、$F_1$。将每个指标四舍五入到四位有效数字。此外，基于临床药物警戒的推理，简明扼要地解释在这种情况下假阳性与假阴性的不同含义，重点关注其对下游安全信号检测和临床决策支持的潜在影响（在解释中不要提供数值）。", "solution": "题目陈述为在明确定义的临床自然语言处理背景下评估二元分类器提供了一套独立且内部一致的数据。给定的真阳性（$TP$）、假阳性（$FP$）、假阴性（$FN$）和真阴性（$TN$）的值之和等于总样本量：$208 + 104 + 52 + 1,136 = 1,500$。该任务基于机器学习评估和药物警戒的既定原则。因此，该问题被认为是有效的，可以制定解决方案。\n\n任务的第一部分是计算正类（$C$）的精确率、召回率和 $F_1$ 分数，其中正类代表存在因果药物-事件关系。这些指标的定义如下：\n\n精确率（$P$）是预测为正类的实例中实际为正类的比例。它衡量分类器的准确性。\n$$P = \\frac{TP}{TP + FP}$$\n\n召回率（$R$），也称为灵敏度或真阳性率，是实际为正类的实例中被分类器正确识别的比例。它衡量分类器的完备性。\n$$R = \\frac{TP}{TP + FN}$$\n\n$F_1$ 分数是精确率和召回率的调和平均数，提供了一个平衡两者的单一指标。\n$$F_1 = 2 \\cdot \\frac{P \\cdot R}{P + R} = \\frac{2 \\cdot TP}{2 \\cdot TP + FP + FN}$$\n\n使用给定的值：$TP = 208$，$FP = 104$，和 $FN = 52$。\n\n首先，我们计算精确率：\n$$P = \\frac{208}{208 + 104} = \\frac{208}{312} = \\frac{2}{3} \\approx 0.666666...$$\n四舍五入到四位有效数字，我们得到 $P \\approx 0.6667$。\n\n接下来，我们计算召回率：\n$$R = \\frac{208}{208 + 52} = \\frac{208}{260} = \\frac{4}{5} = 0.8$$\n为了用四位有效数字表示，我们写作 $R = 0.8000$。\n\n最后，我们使用 $P$ 和 $R$ 的精确分数值来计算 $F_1$ 分数，以避免过早的舍入误差：\n$$F_1 = 2 \\cdot \\frac{\\left(\\frac{2}{3}\\right) \\cdot \\left(\\frac{4}{5}\\right)}{\\left(\\frac{2}{3}\\right) + \\left(\\frac{4}{5}\\right)} = 2 \\cdot \\frac{\\frac{8}{15}}{\\frac{10 + 12}{15}} = 2 \\cdot \\frac{\\frac{8}{15}}{\\frac{22}{15}} = 2 \\cdot \\frac{8}{22} = \\frac{16}{22} = \\frac{8}{11} \\approx 0.727272...$$\n四舍五入到四位有效数字，我们得到 $F_1 \\approx 0.7273$。\n\n任务的第二部分要求在临床药物警戒的背景下，简明扼要地解释假阳性与假阴性的含义。\n\n**假阳性**（$FP$）指系统错误地识别出药物与不良事件之间存在因果关系。在安全信号检测的背景下，这会导致产生错误的警报。主要后果是给人类专家带来负担，他们必须花费宝贵的时间和资源来调查这些虚假信号，从而分散了他们对真正安全问题的注意力。在临床决策支持环境中，高假阳性率可能导致“警报疲劳”，即临床医生变得麻木，开始忽略所有系统警告，包括有效的警告，从而削弱了系统的有效性，并可能增加患者风险。\n\n**假阴性**（$FN$）指系统未能识别出药物与不良事件之间存在的真实因果关系。这代表一个被遗漏的安全信号。其影响是严重的，直接影响患者安全。未能检测到真实的不良药物反应意味着患者可能会继续受到药物的伤害，并且失去了早期监管干预（例如，更新标签、发布安全警告）的机会。延迟识别真实的安全信号可能导致在整个患者群体中发生广泛的、可预防的伤害，这代表了药物警戒过程中的一个严重失败。在这个具体应用中，由于对患者存在直接的潜在伤害，假阴性比假阳性更令人担忧。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.6667  0.8000  0.7273\n\\end{pmatrix}\n}\n$$", "id": "4588718"}]}