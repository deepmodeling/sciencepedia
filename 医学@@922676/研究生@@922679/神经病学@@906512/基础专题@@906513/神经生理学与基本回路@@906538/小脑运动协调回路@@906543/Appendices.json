{"hands_on_practices": [{"introduction": "小脑学习的根本在于平行纤维-浦肯野细胞突触的可塑性，特别是长时程抑制（LTD）。本练习将这一复杂的生物学机制提炼成一个简洁而强大的数学公式。通过推导突触权重的期望变化，您将学习如何将攀爬纤维的随机性放电（传递误差信号）与运动适应中渐进、可预测的学习过程联系起来，这是计算神经科学的一个核心原理。[@problem_id:4464805]", "problem": "在小脑皮层中，平行纤维-浦肯野细胞（PF-PC）突触的突触可塑性是由平行纤维的联合活动和攀援纤维传递的复杂峰电位共同驱动的。考虑一个突触权重用 $w$ 表示的单一PF-PC突触。在一次运动学习任务的试验中，设平行纤维活动为 $x$（解释为在一个确定的时间窗口内的突触前活动的固定标量），并设复杂峰电位的发生由一个指示随机变量 $I_{CS}$ 编码，其取值于 $\\{0,1\\}$，其中当复杂峰电位发生时 $I_{CS} = 1$，否则 $I_{CS} = 0$。假设存在以下被广泛接受的可塑性机制：当复杂峰电位与平行纤维活动同时发生时，PF-PC突触会诱发长时程抑制（LTD），产生如下的单次试验突触变化：\n$$\n\\Delta w = -\\eta \\, x \\, I_{CS},\n$$\n其中 $\\eta  0$ 是学习率参数。假设 $I_{CS}$ 服从成功概率为 $P_{CS}$ 的伯努利分布，即 $\\mathbb{P}(I_{CS} = 1) = P_{CS}$ 且 $\\mathbb{P}(I_{CS} = 0) = 1 - P_{CS}$，并且在计算期望时 $x$ 是固定的。使用期望的定义和期望算子的线性性质，推导出期望突触变化 $\\mathbb{E}[\\Delta w]$ 的一个以 $\\eta$、$x$ 和 $P_{CS}$ 表示的闭式表达式。提供您对 $\\mathbb{E}[\\Delta w]$ 的最终表达式。不需要进行数值近似。将您的答案表示为单个闭式解析表达式。", "solution": "该问题要求推导期望突触变化，记为 $\\mathbb{E}[\\Delta w]$。在一次给定的试验中，突触变化 $\\Delta w$ 由以下方程定义：\n$$\n\\Delta w = -\\eta \\, x \\, I_{CS}\n$$\n此处，$\\eta$ 是学习率，一个正常数。变量 $x$ 代表平行纤维活动，在本次计算中被视为一个固定的标量。变量 $I_{CS}$ 是一个指示复杂峰电位发生的伯努利随机变量。它以概率 $P_{CS}$ 取值为 $1$，以概率 $1 - P_{CS}$ 取值为 $0$。\n\n随机变量的期望是一个线性算子。因此，$\\Delta w$ 的期望可以表示为：\n$$\n\\mathbb{E}[\\Delta w] = \\mathbb{E}[-\\eta \\, x \\, I_{CS}]\n$$\n由于 $\\eta$ 和 $x$ 相对于控制 $I_{CS}$ 的随机过程是常数，我们可以将它们从期望中提出来：\n$$\n\\mathbb{E}[\\Delta w] = -\\eta \\, x \\, \\mathbb{E}[I_{CS}]\n$$\n此步骤利用了期望的线性性质，具体来说，对于常数 $a$ 和随机变量 $Y$，有 $\\mathbb{E}[aY] = a\\mathbb{E}[Y]$。\n\n下一步是计算伯努利随机变量 $I_{CS}$ 的期望。离散随机变量的期望定义为该变量每个可能值与其对应概率的乘积之和。对于 $I_{CS}$，其可能值为 $0$ 和 $1$。\n期望的定义是 $\\mathbb{E}[Y] = \\sum_{y} y \\cdot \\mathbb{P}(Y=y)$，其中求和遍历随机变量 $Y$ 能取到的所有可能值 $y$。\n\n将此定义应用于 $I_{CS}$：\n$$\n\\mathbb{E}[I_{CS}] = \\sum_{i \\in \\{0, 1\\}} i \\cdot \\mathbb{P}(I_{CS} = i)\n$$\n这个和可以展开为两项，每一项对应 $I_{CS}$ 的一个可能值：\n$$\n\\mathbb{E}[I_{CS}] = (0 \\cdot \\mathbb{P}(I_{CS} = 0)) + (1 \\cdot \\mathbb{P}(I_{CS} = 1))\n$$\n我们已知概率为：$\\mathbb{P}(I_{CS} = 1) = P_{CS}$ 和 $\\mathbb{P}(I_{CS} = 0) = 1 - P_{CS}$。将这些概率代入期望的表达式中：\n$$\n\\mathbb{E}[I_{CS}] = (0 \\cdot (1 - P_{CS})) + (1 \\cdot P_{CS})\n$$\n第一项的计算结果为 $0$：\n$$\n\\mathbb{E}[I_{CS}] = 0 + P_{CS} = P_{CS}\n$$\n因此，伯努利随机变量的期望值就是其成功概率 $P_{CS}$。\n\n最后，我们将这个结果代回到 $\\mathbb{E}[\\Delta w]$ 的表达式中：\n$$\n\\mathbb{E}[\\Delta w] = -\\eta \\, x \\, \\mathbb{E}[I_{CS}] = -\\eta \\, x \\, P_{CS}\n$$\n这就是以给定参数 $\\eta$、$x$ 和 $P_{CS}$ 表示的期望突触变化的闭式表达式。这个结果表明，平均而言，突触权重的减少量与突触前活动 $x$ 和复杂峰电位概率 $P_{CS}$ 成正比。", "answer": "$$\n\\boxed{-\\eta x P_{CS}}\n$$", "id": "4464805"}, {"introduction": "微观的突触调整如何转化为宏观的运动行为改善？本练习通过对前庭-眼动反射（VOR）进行建模来探讨这一问题，VOR是小脑运动学习的一个经典范例。您将推导该反射的适应动力学过程，展示一个简单的、具有生物学合理性的学习规则如何使小脑作为一个自适应控制器，持续不断地最小化感觉预测误差。[@problem_id:4464878]", "problem": "小脑在运动协调中的一个核心功能是调整感觉运动映射，以最小化感觉预测误差。在水平前庭-眼动反射 (VOR) 中，其目标是减少视网膜滑移，即头部旋转时视网膜上的残余图像速度。考虑一个高级研究生水平的模型，其中小脑绒球实现了一个线性控制器，其标量增益 $G(t)$ 通过由编码视网膜滑移的攀爬纤维信号驱动的监督学习缓慢适应。假设旋转角度很小，因此线性叠加原理成立。\n\n一名受试者进行正弦头部旋转，其头部角速度为 $v_{\\mathrm{head}}(t) = V_{0} \\sin(\\omega t)$，单位为弧度/秒。引入棱镜眼镜，它将视觉场景的表观速度放大一个正因子 $s$，因此视网膜滑移误差为 $e(t) = s\\,v_{\\mathrm{head}}(t) - v_{\\mathrm{eye}}(t)$，其中 $v_{\\mathrm{eye}}(t)$ 是水平眼球角速度，单位为弧度/秒。小脑增益 $G(t)$ 根据一个周期平均的监督学习法则进行适应，该法则的动因是平行纤维-浦肯野细胞突触可塑性和攀爬纤维误差教学信号（长时程抑制 (LTD) 相关性学习）：\n\n$$\\frac{dG}{dt} = \\eta \\left\\langle v_{\\mathrm{head}}(t)\\, e(t) \\right\\rangle,$$\n\n其中 $\\eta  0$ 是一个学习率常数，$\\langle \\cdot \\rangle$ 表示在一个刺激周期 $T = \\frac{2\\pi}{\\omega}$ 内的平均值：\n\n$$\\left\\langle f(t) \\right\\rangle = \\frac{1}{T} \\int_{0}^{T} f(t)\\, dt.$$\n\n假设从小脑输出到眼球速度的运动系统可以很好地由一个线性映射来近似（对于小角度、低频旋转有效），并且适应后的控制器产生的期望眼球速度与头部速度成正比，比例常数 $G(t)$ 由上述学习动力学确定。在时间 $t=0$ 时的初始增益为 $G(0) = G_{0}$。\n\n从这些定义和假设出发，推导在适应时间 $t$ 后的期望眼球速度 $v_{\\mathrm{eye}}(t)$ 的闭式表达式，用 $V_{0}$、$\\omega$、$s$、$\\eta$ 和 $G_{0}$ 表示。您的最终表达式必须以弧度/秒为单位。没有提供数值；请将您的答案表示为单个闭式解析表达式。不需要四舍五入。", "solution": "问题陈述已经过验证，被认为是科学合理的、定义明确的且自洽的。任务是推导期望眼球速度 $v_{\\mathrm{eye}}(t)$ 的闭式表达式。这首先需要求解随时间变化的的小脑增益 $G(t)$。\n\n增益 $G(t)$ 的适应由以下学习法则控制：\n$$ \\frac{dG}{dt} = \\eta \\left\\langle v_{\\mathrm{head}}(t)\\, e(t) \\right\\rangle $$\n视网膜滑移误差 $e(t)$ 由 $e(t) = s\\,v_{\\mathrm{head}}(t) - v_{\\mathrm{eye}}(t)$ 给出。运动系统由线性映射 $v_{\\mathrm{eye}}(t) = G(t) v_{\\mathrm{head}}(t)$ 描述。我们可以将此代入误差表达式中：\n$$ e(t) = s\\,v_{\\mathrm{head}}(t) - G(t) v_{\\mathrm{head}}(t) = (s - G(t)) v_{\\mathrm{head}}(t) $$\n现在，我们将此误差表达式代回到学习法则中：\n$$ \\frac{dG}{dt} = \\eta \\left\\langle v_{\\mathrm{head}}(t)\\, (s - G(t)) v_{\\mathrm{head}}(t) \\right\\rangle = \\eta \\left\\langle (s - G(t)) v_{\\mathrm{head}}(t)^2 \\right\\rangle $$\n该模型假设增益 $G(t)$ 相对于刺激周期 $T = \\frac{2\\pi}{\\omega}$ 适应缓慢。因此，我们可以在单周期平均区间内将 $G(t)$ 视为常数。这使我们能够将项 $(s - G(t))$ 从平均算子中提出：\n$$ \\frac{dG}{dt} = \\eta (s - G(t)) \\left\\langle v_{\\mathrm{head}}(t)^2 \\right\\rangle $$\n接下来，我们必须计算时间平均的头部速度平方，即 $\\left\\langle v_{\\mathrm{head}}(t)^2 \\right\\rangle$。头部速度由 $v_{\\mathrm{head}}(t) = V_{0} \\sin(\\omega t)$ 给出。\n$$ \\left\\langle v_{\\mathrm{head}}(t)^2 \\right\\rangle = \\frac{1}{T} \\int_{0}^{T} (V_{0} \\sin(\\omega t))^2 dt = \\frac{V_{0}^2}{T} \\int_{0}^{T} \\sin^2(\\omega t) dt $$\n使用三角恒等式 $\\sin^2(\\theta) = \\frac{1}{2}(1 - \\cos(2\\theta))$，积分变为：\n$$ \\int_{0}^{T} \\sin^2(\\omega t) dt = \\int_{0}^{T} \\frac{1 - \\cos(2\\omega t)}{2} dt = \\frac{1}{2} \\left[ t - \\frac{\\sin(2\\omega t)}{2\\omega} \\right]_{0}^{T} $$\n代入周期 $T = \\frac{2\\pi}{\\omega}$：\n$$ \\frac{1}{2} \\left[ T - \\frac{\\sin(2\\omega T)}{2\\omega} - (0 - 0) \\right] = \\frac{1}{2} \\left[ \\frac{2\\pi}{\\omega} - \\frac{\\sin(2\\omega \\frac{2\\pi}{\\omega})}{2\\omega} \\right] = \\frac{1}{2} \\left[ \\frac{2\\pi}{\\omega} - \\frac{\\sin(4\\pi)}{2\\omega} \\right] $$\n由于 $\\sin(4\\pi) = 0$，积分结果为 $\\frac{T}{2}$。因此，平均值为：\n$$ \\left\\langle v_{\\mathrm{head}}(t)^2 \\right\\rangle = \\frac{V_{0}^2}{T} \\left( \\frac{T}{2} \\right) = \\frac{V_{0}^2}{2} $$\n将此结果代回到 $G(t)$ 的微分方程中：\n$$ \\frac{dG}{dt} = \\eta (s - G(t)) \\frac{V_{0}^2}{2} $$\n这是一个一阶线性常微分方程。为方便起见，令 $k = \\frac{\\eta V_{0}^2}{2}$。方程为：\n$$ \\frac{dG}{dt} = k(s - G) $$\n该方程是可分离的：\n$$ \\frac{dG}{s - G} = k\\,dt $$\n我们可以对两边进行积分，时间从 $0$ 到 $t$，增益从 $G(0)=G_0$ 到 $G(t)$：\n$$ \\int_{G_0}^{G(t)} \\frac{dG'}{s - G'} = \\int_{0}^{t} k\\,dt' $$\n$$ \\left[ -\\ln|s - G'| \\right]_{G_0}^{G(t)} = \\left[ kt' \\right]_{0}^{t} $$\n$$ -\\ln|s - G(t)| - (-\\ln|s - G_0|) = kt $$\n$$ \\ln\\left(\\frac{|s - G_0|}{|s - G(t)|}\\right) = kt $$\n对两边取指数：\n$$ \\frac{|s - G_0|}{|s - G(t)|} = e^{kt} \\implies |s - G(t)| = |s - G_0| e^{-kt} $$\n由于增益 $G(t)$ 将从 $G_0$ 单调地趋近于目标 $s$（可能从上方或下方，但不会穿过 $s$），因此项 $(s-G)$ 不会改变符号。所以，我们可以去掉绝对值符号：\n$$ s - G(t) = (s - G_0) e^{-kt} $$\n求解 $G(t)$：\n$$ G(t) = s - (s - G_0) e^{-kt} $$\n代回 $k$ 的表达式：\n$$ G(t) = s - (s - G_0) \\exp\\left(-\\frac{\\eta V_{0}^2}{2} t\\right) $$\n问题要求的是期望眼球速度 $v_{\\mathrm{eye}}(t)$。我们使用关系式 $v_{\\mathrm{eye}}(t) = G(t) v_{\\mathrm{head}}(t)$：\n$$ v_{\\mathrm{eye}}(t) = \\left[ s - (s - G_0) \\exp\\left(-\\frac{\\eta V_{0}^2}{2} t\\right) \\right] v_{\\mathrm{head}}(t) $$\n最后，代入 $v_{\\mathrm{head}}(t) = V_0 \\sin(\\omega t)$ 的表达式：\n$$ v_{\\mathrm{eye}}(t) = \\left[ s - (s - G_0) \\exp\\left(-\\frac{\\eta V_{0}^2}{2} t\\right) \\right] V_0 \\sin(\\omega t) $$\n这就是期望眼球速度关于时间和给定参数的闭式表达式。", "answer": "$$ \\boxed{\\left(s - (s - G_{0}) \\exp\\left(-\\frac{\\eta V_{0}^{2}}{2} t\\right)\\right) V_{0} \\sin(\\omega t)} $$", "id": "4464878"}, {"introduction": "理论模型的威力巨大，但其真正的考验在于能否被实现并应用于数据。本练习要求您从抽象的方程走向具体的代码，根据精确的脉冲发放时间来实现一个学习规则。您将构建一个基于“资格痕迹”（eligibility trace）的模型——这是连接过去神经活动与后续学习信号的关键概念——并用它来根据真实的脉冲序列数据预测运动表现的变化，从而获得计算神经科学研究方法的直接经验。[@problem_id:4464820]", "problem": "提供给您的是在一个运动任务的离散试验中记录的浦肯野细胞简单锋电位和复杂锋电位的事件时间。假设以下在小脑生理学中被广泛接受的基本前提：当存在运动误差时，攀援纤维输入会引起浦肯野细胞产生复杂锋电位；复杂锋电位指导平行纤维-浦肯野细胞突触发生可塑性变化；浦肯野细胞抑制小脑深部核团，从而塑造运动输出。基于这些事实，请从第一性原理推导一个简化的、逐次试验的模型。在该模型中，每个浦肯野细胞的单一有效突触权重由作用于先前简单锋电位所形成的资格迹上的复杂锋电位来更新，并利用此模型预测运动表现的逐次试验变化。资格迹应当是简单锋电位的因果函数，具有由单一时间常数表征的指数衰减特性。从突触变化到运动表现的映射必须反映出浦肯野细胞输出的减少会去抑制小脑深部核团，从而改善运动表现。除了这些基础原理外，不要假设或使用任何快捷公式；相反，应推导出实现所需的表达式。\n\n在一个程序中实现您推导出的规则，该程序针对每次试验，仅根据该次试验中的简单锋电位和复杂锋电位时间，在给定固定模型参数的情况下，计算预测的运动表现变化。时间值的单位是秒，运动表现变化是无量纲的。\n\n使用以下参数值：指数资格迹时间常数 $\\tau_{e} = 0.05$ (秒)，学习率 $\\eta = 0.01$ (无量纲)，以及表现增益 $\\kappa = 1.0$ (无量纲)。每次试验的持续时间为 $T = 1.0$ (秒)。\n\n您的程序必须处理以下测试套件，其中每个测试用例包含固定数量的试验，并为每次试验指定了简单锋电位时间和复杂锋电位时间：\n\n- 测试用例 $1$ (一般情况，混合时间点):\n  - 试验 $1$: 简单锋电位 $[0.10, 0.18, 0.32, 0.47, 0.55, 0.70, 0.82]$, 复杂锋电位 $[0.60]$。\n  - 试验 $2$: 简单锋电位 $[0.12, 0.19, 0.40, 0.58, 0.75]$, 复杂锋电位 $[0.20]$。\n  - 试验 $3$: 简单锋电位 $[0.08, 0.16, 0.30, 0.33, 0.51, 0.72]$, 复杂锋电位 $[]$。\n  - 试验 $4$: 简单锋电位 $[0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65]$, 复杂锋电位 $[0.50]$。\n  - 试验 $5$: 简单锋电位 $[0.22, 0.29, 0.41, 0.67, 0.83]$, 复杂锋电位 $[0.68, 0.90]$。\n- 测试用例 $2$ (边界情况，无复杂锋电位):\n  - 试验 $1$: 简单锋电位 $[0.10, 0.20, 0.30]$, 复杂锋电位 $[]$。\n  - 试验 $2$: 简单锋电位 $[0.15, 0.45, 0.80]$, 复杂锋电位 $[]$。\n  - 试验 $3$: 简单锋电位 $[0.25, 0.35, 0.55, 0.75]$, 复杂锋电位 $[]$。\n  - 试验 $4$: 简单锋电位 $[0.05, 0.65, 0.95]$, 复杂锋电位 $[]$。\n- 测试用例 $3$ (边缘情况：早期复杂锋电位，多个复杂锋电位，同时的复杂锋电位):\n  - 试验 $1$: 简单锋电位 $[0.20, 0.40]$, 复杂锋电位 $[0.05]$。\n  - 试验 $2$: 简单锋电位 $[0.05, 0.06, 0.07]$, 复杂锋电位 $[0.08, 0.50]$。\n  - 试验 $3$: 简单锋电位 $[0.10, 0.11, 0.12, 0.13, 0.14]$, 复杂锋电位 $[0.12, 0.12]$。\n\n对于每个测试用例，计算一个预测的逐次试验表现变化的列表，其中每个元素对应于该次试验的预测变化。输出值必须是无单位的实数（浮点数）。您的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表。将所有测试用例的结果聚合到一个单一列表中，其中每个测试用例的结果本身就是一个列表。例如，最终输出应类似于 $[[a_{1}, a_{2}, \\dots], [b_{1}, b_{2}, \\dots], [c_{1}, c_{2}, \\dots]]$，其中每个 $a_{i}$、$b_{i}$ 和 $c_{i}$ 都是浮点数。", "solution": "问题陈述已经过验证，并被认为是有效的。它科学地植根于小脑生理学的既定原则，是一个具有充分信息以获得唯一解的适定问题，并以客观、可形式化的语言表达。\n\n任务是根据浦肯野细胞的锋电位时间，推导一个用于运动表现变化的逐次试验计算模型，然后加以实现。从给定的第一性原理进行的推导如下。\n\n**1. 资格迹 ($E(t)$) 的推导**\n\n问题指明，资格迹由简单锋电位 (SS) 形成，并且是一个具有指数衰减的因果函数。该迹代表了平行纤维-浦肯野细胞突触的一种临时状态，使其“有资格”发生可塑性变化。设单次试验内的简单锋电位时间集合为 $\\{t_{\\text{SS},i}\\}$。\n\n在时间 $t_{\\text{SS},i}$ 发生的单个简单锋电位对资格迹产生一个随时间指数衰减的贡献。根据因果性要求，对于任何时间 $t \\le t_{\\text{SS},i}$，此贡献为零。对于时间 $t  t_{\\text{SS},i}$，其贡献与 $\\exp(-(t - t_{\\text{SS},i}) / \\tau_{e})$ 成正比，其中 $\\tau_{e}$ 是资格迹时间常数。假设每个锋电位的贡献幅度为单位1，则试验中任意时刻 $t$ 的总资格迹 $E(t)$ 是所有先前简单锋电位贡献的线性叠加。\n\n在数学上，这表示为：\n$$\nE(t) = \\sum_{i \\text{ such that } t_{\\text{SS},i}  t} \\exp\\left(-\\frac{t - t_{\\text{SS},i}}{\\tau_{e}}\\right)\n$$\n该方程将资格迹是过去简单锋电位活动的衰减记忆这一概念形式化。\n\n**2. 突触权重更新 ($\\Delta w$) 的推导**\n\n问题指出，由攀援纤维输入响应运动误差而引起的复杂锋电位 (CS) 指导可塑性变化。这与平行纤维-浦肯野细胞突触的长时程抑制 (LTD) 理论一致，即当平行纤维活动（由 SS 信号表示）与攀援纤维活动（由 CS 信号表示）联合配对时，突触权重会降低。\n\n在时间 $t_{\\text{CS},j}$ 发生的复杂锋电位作为一个“指令”信号。突触变化的幅度由资格迹 $E(t)$ 在那一刻的值 $E(t_{\\text{CS},j})$ 决定。这个值量化了近期发生了多少相关的简单锋电位活动。\n\n因此，有效突触权重的变化 $\\Delta w$ 与这个采样的资格迹值成正比。由于此过程介导 LTD，该变化必须是负的。我们引入一个学习率 $\\eta$ 来缩放更新的幅度。对于单次试验，突触权重的总变化 $\\Delta w_{\\text{trial}}$ 是该试验中每个复杂锋电位引起的变化之和。设复杂锋电位的时间集合为 $\\{t_{\\text{CS},j}\\}$。\n\n该次试验的总权重更新为：\n$$\n\\Delta w_{\\text{trial}} = -\\eta \\sum_{j} E(t_{\\text{CS},j})\n$$\n如果一次试验没有复杂锋电位，则求和为空，$\\Delta w_{\\text{trial}} = 0$，这正确地模拟了没有误差信号就不会发生学习的情况。\n\n**3. 运动表现变化 ($\\Delta P$) 的推导**\n\n最后一步是将突触权重的变化与运动表现的变化联系起来。所提供的原则指出：\n- 浦肯野细胞 (PCs) 向小脑深部核团 (DCN) 提供抑制性输出。\n- PC 输出的减少会去抑制 DCN，从而改善运动表现。\n\n让我们将此形式化。我们假设有效突触权重 $w$ 与 PC 的抑制性输出强度成正比。$w$ 的减少（即，由于 LTD 导致 $\\Delta w  0$）会导致 PC 对 DCN 的抑制影响减弱。这种去抑制导致 DCN 放电增加，进而驱动运动表现 $P$ 的改善。\n\n因此，表现的变化 $\\Delta P$ 必须与突触权重的变化 $\\Delta w$ 呈负相关。我们可以使用给定的表现增益参数 $\\kappa$ 将其表示为线性关系：\n$$\n\\Delta P_{\\text{trial}} = -\\kappa \\cdot \\Delta w_{\\text{trial}}\n$$\n负号确保了负的 $\\Delta w$（突触抑制）会导致正的 $\\Delta P$（表现改善）。\n\n**4. 完整的逐次试验模型**\n\n将 $\\Delta w_{\\text{trial}}$ 和 $E(t)$ 的表达式代入表现变化方程，我们得到用于运动表现逐次试验变化的完整、简化模型：\n$$\n\\Delta P_{\\text{trial}} = -\\kappa \\left( -\\eta \\sum_{j} E(t_{\\text{CS},j}) \\right) = \\kappa \\eta \\sum_{j} E(t_{\\text{CS},j})\n$$\n代入资格迹的完整表达式：\n$$\n\\Delta P_{\\text{trial}} = \\kappa \\eta \\sum_{j} \\left( \\sum_{i \\text{ s.t. } t_{\\text{SS},i}  t_{\\text{CS},j}} \\exp\\left(-\\frac{t_{\\text{CS},j} - t_{\\text{SS},i}}{\\tau_{e}}\\right) \\right)\n$$\n这是需要实现的最终方程。对于每次试验，我们遍历每个复杂锋电位，通过对所有先前简单锋电位的贡献求和来计算该时刻的资格迹值，然后将这些资格迹值相加，并将结果乘以学习率 $\\eta$ 和表现增益 $\\kappa$ 的乘积。给定的参数为 $\\tau_{e} = 0.05$，$\\eta = 0.01$，和 $\\kappa = 1.0$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and applies a model of cerebellar motor learning to predict\n    trial-by-trial changes in motor performance based on spike timings.\n    \"\"\"\n\n    # Define model parameters from the problem statement.\n    tau_e = 0.05  # exponential eligibility time constant in seconds\n    eta = 0.01    # dimensionless learning rate\n    kappa = 1.0   # dimensionless performance gain\n\n    # Pre-calculate the product of kappa and eta for efficiency.\n    k_eta_product = kappa * eta\n\n    # Define the test suite from the problem statement.\n    # Each test case is a list of trials.\n    # Each trial is a tuple of (simple_spike_times, complex_spike_times).\n    test_cases = [\n        # Test case 1 (general case, mixed timing)\n        [\n            ([0.10, 0.18, 0.32, 0.47, 0.55, 0.70, 0.82], [0.60]),\n            ([0.12, 0.19, 0.40, 0.58, 0.75], [0.20]),\n            ([0.08, 0.16, 0.30, 0.33, 0.51, 0.72], []),\n            ([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65], [0.50]),\n            ([0.22, 0.29, 0.41, 0.67, 0.83], [0.68, 0.90]),\n        ],\n        # Test case 2 (boundary case, no complex spikes)\n        [\n            ([0.10, 0.20, 0.30], []),\n            ([0.15, 0.45, 0.80], []),\n            ([0.25, 0.35, 0.55, 0.75], []),\n            ([0.05, 0.65, 0.95], []),\n        ],\n        # Test case 3 (edge cases)\n        [\n            ([0.20, 0.40], [0.05]),  # Early complex spike\n            ([0.05, 0.06, 0.07], [0.08, 0.50]), # Multiple complex spikes\n            ([0.10, 0.11, 0.12, 0.13, 0.14], [0.12, 0.12]), # Simultaneous complex spikes\n        ]\n    ]\n\n    all_results = []\n    \n    # Iterate through each test case\n    for case in test_cases:\n        case_results = []\n        # Iterate through each trial in the current test case\n        for ss_times, cs_times in case:\n            total_eligibility_sum = 0.0\n\n            # If there are no complex spikes, no learning occurs.\n            if not cs_times:\n                case_results.append(0.0)\n                continue\n\n            # For each complex spike, calculate the eligibility trace value at that time.\n            for t_cs in cs_times:\n                eligibility_at_cs = 0.0\n                # Sum the contributions from all preceding simple spikes.\n                # The rule is causal, so only simple spikes t_ss  t_cs contribute.\n                for t_ss in ss_times:\n                    if t_ss  t_cs:\n                        delta_t = t_cs - t_ss\n                        eligibility_at_cs += np.exp(-delta_t / tau_e)\n                \n                total_eligibility_sum += eligibility_at_cs\n            \n            # Calculate the change in performance for the trial.\n            # delta_P = kappa * eta * sum(E(t_cs))\n            delta_p = k_eta_product * total_eligibility_sum\n            case_results.append(delta_p)\n            \n        all_results.append(case_results)\n\n    # Format the final output as a single-line string representation\n    # of a list of lists, with no spaces.\n    final_output_str = str(all_results).replace(\" \", \"\")\n    print(final_output_str)\n\nsolve()\n```", "id": "4464820"}]}