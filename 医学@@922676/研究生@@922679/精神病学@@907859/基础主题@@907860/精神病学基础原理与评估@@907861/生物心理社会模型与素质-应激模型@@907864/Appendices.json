{"hands_on_practices": [{"introduction": "在将模型付诸实践之前，理解其数学构造至关重要。本质上，素质-压力模型的核心论点是素质和压力之间的协同（或交互）效应。该练习引导您从第一性原理出发，推导素质-压力框架下风险的逻辑斯蒂函数形式，从而揭示交互作用系数 $ \\beta_{DS} $ 如何从数学上捕捉和量化调节效应的概念。完成此练习将为您提供扎实的理论基础，让您明白模型的系数如何直接转化为关于风险如何变化的、具有临床意义的论述。[@problem_id:4765951]", "problem": "精神病学中素质-压力模型的一个核心论点是，某种障碍的发病概率取决于个体的素质（类特质易感性）和环境压力，并且它们的共同效应可能不是纯粹相加的。考虑一个在固定观察窗口内的二元发病指标 $Y \\in \\{0,1\\}$，其中 $Y=1$ 表示发病。令 $D \\in \\mathbb{R}$ 表示连续的素质得分，$S \\in \\mathbb{R}$ 表示连续的压力暴露得分。\n\n使用以下基本建模假设：\n- 发病指标 $Y$ 被建模为一个成功概率为 $p(D,S)$ 的伯努利随机变量。\n- 发病几率定义为 $\\frac{p(D,S)}{1 - p(D,S)}$。\n- 在具有伯努利结果的广义线性模型（GLM）中使用的对数几率（logit）链接，通过变换 $\\ln\\!\\left(\\frac{p(D,S)}{1 - p(D,S)}\\right)$ 将期望值与线性预测变量关联起来。\n- 本着素质-压力模型的精神，假设线性预测变量在 $D$ 和 $S$ 的主效应上是相加的，并包含它们的乘积以允许交互作用。\n\n任务：\n1) 仅从上述定义以及对数几率尺度上线性预测变量的相加性出发，推导包含截距、$D$ 和 $S$ 的线性主效应及其交互作用的风险函数 $p(D,S)$ 的闭式表达式。用系数 $\\beta_{0}$、$\\beta_{D}$、$\\beta_{S}$ 和 $\\beta_{DS}$ 表示结果。\n\n2) 将在固定素质水平 $D$ 下，压力增加一个单位时的压力优势比定义为\n$$\\mathrm{OR}_{S}(D) \\equiv \\frac{\\text{在 }(D,S+1) \\text{ 时的发病几率}}{\\text{在 }(D,S) \\text{ 时的发病几率}}。$$\n用这些系数推导 $\\mathrm{OR}_{S}(D)$。\n\n3) 将当素质增加一个单位时，素质对压力效应的调节强度定义为压力优势比的比率：\n$$M \\equiv \\frac{\\mathrm{OR}_{S}(D+1)}{\\mathrm{OR}_{S}(D)}。$$\n提供一个用模型系数表示的 $M$ 的简化闭式解析表达式。仅报告此最终表达式作为答案。不要包含单位。如果在中间步骤中得到数值，请勿四舍五入；最终交付成果是一个符号表达式。", "solution": "该问题要求推导与一个形式化素质-压力模型的逻辑斯蒂回归模型相关的三个量。该模型基于连续素质得分 $D$ 和连续压力得分 $S$ 来预测障碍的发病概率 $p(D,S)$。\n\n基本假设是：\n1.  发病 $Y$ 是一个成功概率为 $p(D,S)$ 的伯努利试验。\n2.  该模型使用一个 logit 链接函数，意味着发病的对数几率是预测变量的线性函数。\n3.  线性预测变量 $\\eta(D,S)$ 包括一个截距、$D$ 和 $S$ 的主效应，以及它们的交互作用项。\n\n首先，我们使用给定的系数 $\\beta_{0}$、$\\beta_{D}$、$\\beta_{S}$ 和 $\\beta_{DS}$ 写出线性预测变量 $\\eta(D,S)$ 的表达式：\n$$ \\eta(D,S) = \\beta_{0} + \\beta_{D}D + \\beta_{S}S + \\beta_{DS}DS $$\n\nlogit 链接函数表明，对数几率等于这个线性预测变量：\n$$ \\ln\\left(\\frac{p(D,S)}{1 - p(D,S)}\\right) = \\eta(D,S) = \\beta_{0} + \\beta_{D}D + \\beta_{S}S + \\beta_{DS}DS $$\n\n任务 1：推导风险函数 $p(D,S)$ 的闭式表达式。\n为了求得 $p(D,S)$，我们必须反转 logit 变换。首先，我们对等式两边取指数，以解出几率 $\\frac{p(D,S)}{1 - p(D,S)}$：\n$$ \\frac{p(D,S)}{1 - p(D,S)} = \\exp(\\eta(D,S)) = \\exp(\\beta_{0} + \\beta_{D}D + \\beta_{S}S + \\beta_{DS}DS) $$\n为代数方便起见，令 $p = p(D,S)$ 且 $E = \\exp(\\eta(D,S))$。该等式变为：\n$$ \\frac{p}{1-p} = E $$\n解出 $p$：\n$$ p = E(1-p) \\implies p = E - Ep \\implies p + Ep = E \\implies p(1+E) = E \\implies p = \\frac{E}{1+E} $$\n将 $E$ 的表达式代回，我们得到风险函数：\n$$ p(D,S) = \\frac{\\exp(\\beta_{0} + \\beta_{D}D + \\beta_{S}S + \\beta_{DS}DS)}{1 + \\exp(\\beta_{0} + \\beta_{D}D + \\beta_{S}S + \\beta_{DS}DS)} $$\n这就是任务 1 所需的表达式。\n\n任务 2：推导压力优势比 $\\mathrm{OR}_{S}(D)$。\n压力优势比是在固定素质水平 $D$ 下，压力 $S$ 增加一个单位时定义的：\n$$ \\mathrm{OR}_{S}(D) \\equiv \\frac{\\text{在 }(D,S+1) \\text{ 时的发病几率}}{\\text{在 }(D,S) \\text{ 时的发病几率}} $$\n根据我们上一步的结果，几率由 $\\exp(\\eta(D,S))$ 给出。\n在 $(D, S+1)$ 处的几率是：\n$$ \\text{odds}(D,S+1) = \\exp(\\beta_{0} + \\beta_{D}D + \\beta_{S}(S+1) + \\beta_{DS}D(S+1)) $$\n$$ = \\exp(\\beta_{0} + \\beta_{D}D + \\beta_{S}S + \\beta_{S} + \\beta_{DS}DS + \\beta_{DS}D) $$\n在 $(D, S)$ 处的几率是：\n$$ \\text{odds}(D,S) = \\exp(\\beta_{0} + \\beta_{D}D + \\beta_{S}S + \\beta_{DS}DS) $$\n我们构成比率：\n$$ \\mathrm{OR}_{S}(D) = \\frac{\\exp(\\beta_{0} + \\beta_{D}D + \\beta_{S}S + \\beta_{S} + \\beta_{DS}DS + \\beta_{DS}D)}{\\exp(\\beta_{0} + \\beta_{D}D + \\beta_{S}S + \\beta_{DS}DS)} $$\n使用指数性质 $\\frac{\\exp(a)}{\\exp(b)} = \\exp(a-b)$，结果表达式的指数是分子指数与分母指数之差：\n$$ (\\beta_{0} + \\beta_{D}D + \\beta_{S}S + \\beta_{S} + \\beta_{DS}DS + \\beta_{DS}D) - (\\beta_{0} + \\beta_{D}D + \\beta_{S}S + \\beta_{DS}DS) = \\beta_{S} + \\beta_{DS}D $$\n因此，压力优势比是：\n$$ \\mathrm{OR}_{S}(D) = \\exp(\\beta_{S} + \\beta_{DS}D) $$\n\n任务 3：推导调节强度 $M$。\n最后一项任务是求调节强度 $M$ 的简化表达式，其定义为：\n$$ M \\equiv \\frac{\\mathrm{OR}_{S}(D+1)}{\\mathrm{OR}_{S}(D)} $$\n我们使用任务 2 的结果。分子是通过将 $D+1$ 代入 $\\mathrm{OR}_{S}(D)$ 的表达式中求得的：\n$$ \\mathrm{OR}_{S}(D+1) = \\exp(\\beta_{S} + \\beta_{DS}(D+1)) = \\exp(\\beta_{S} + \\beta_{DS}D + \\beta_{DS}) $$\n分母就是 $\\mathrm{OR}_{S}(D)$ 本身的表达式：\n$$ \\mathrm{OR}_{S}(D) = \\exp(\\beta_{S} + \\beta_{DS}D) $$\n构成 $M$ 的比率：\n$$ M = \\frac{\\exp(\\beta_{S} + \\beta_{DS}D + \\beta_{DS})}{\\exp(\\beta_{S} + \\beta_{DS}D)} $$\n同样，我们将指数相减：\n$$ (\\beta_{S} + \\beta_{DS}D + \\beta_{DS}) - (\\beta_{S} + \\beta_{DS}D) = \\beta_{DS} $$\n因此，调节强度 $M$ 的简化闭式表达式为：\n$$ M = \\exp(\\beta_{DS}) $$\n这个结果表明，在这个特定的交互作用对数线性模型中，调节强度 $M$ 是一个常数，并且仅取决于交互作用系数 $\\beta_{DS}$。这是问题所要求的最终表达式。", "answer": "$$\n\\boxed{\\exp(\\beta_{DS})}\n$$", "id": "4765951"}, {"introduction": "掌握了素质-压力模型的理论基础后，下一步便是将其应用于临床预测。精神病学研究通常会产出经过拟合的统计模型，我们可以利用这些模型来评估特定个体的风险。本练习提供了一个基于真实研究场景的实例，其中包含一个用于预测重度抑郁症发作的逻辑斯蒂回归模型及其估计系数。您将运用该模型，通过代入具体个体的遗传风险评分和压力指数，计算其在未来12个月内发病的预测概率，并解释这一概率的临床意义，从而将抽象的模型与个体化的风险评估联系起来。[@problem_id:4765949]", "problem": "一项为期 $12$ 个月的首发重度抑郁症前瞻性队列研究在素质-压力框架下进行建模。该框架假定，发病概率取决于个体的脆弱性（素质）和压力暴露程度。在该队列中，素质被操作化为以标准差为单位的标准化多基因风险评分（PRS；Polygenic Risk Score），压力暴露则被概括为一个在经过验证的 $0$ 到 $3$ 量表上的连续压力指数 $S$。为了将预测因子与发病概率联系起来，该研究使用了一个与素质-压力模型和基因-环境（G$\\times$E；Gene-by-Environment）交互作用相一致的逻辑回归模型：\n$$\n\\mathrm{logit}(p) \\equiv \\ln\\!\\left(\\frac{p}{1-p}\\right) = \\beta_{0} + \\beta_{G}\\,PRS + \\beta_{S}\\,S + \\beta_{G\\times E}\\,PRS\\cdot S,\n$$\n其中 $p$ 是在 $12$ 个月内发作的概率。\n\n假设该队列的代表性总体训练数据得到以下系数：$\\beta_{0} = -3.2$，$\\beta_{G} = 0.45$，$\\beta_{S} = 0.55$，以及 $\\beta_{G\\times E} = 0.20$。对于一个 $PRS = 1.2$ 且 $S = 2.0$ 的个体：\n\n1. 从素质-压力框架的核心定义和逻辑斯蒂连接函数的性质出发，推导出以线性预测变量和反-logit变换表示的预测发病概率 $p$ 的解析表达式，然后为给定的 $PRS$ 和 $S$ 计算其数值。\n2. 结合由 $\\beta_{0}$ 隐含的基线风险和 $\\beta_{G\\times E}$ 的符号，简要解释所得概率的临床相关性。\n\n将预测概率 $p$ 表示为 $[0,1]$ 区间内的无量纲标量，并将最终数值答案四舍五入至四位有效数字。", "solution": "该问题要求根据一个形式化的素质-压力逻辑回归模型，计算特定个体的抑郁症发病概率，并解释其临床意义。\n\n**第 1 部分：计算发病概率**\n\n给定的逻辑回归模型为：\n$$ \\ln\\left(\\frac{p}{1-p}\\right) = \\beta_{0} + \\beta_{G}\\,PRS + \\beta_{S}\\,S + \\beta_{G\\times E}\\,PRS\\cdot S $$\n我们将这个线性组合表示为 $\\eta$。为了从 $\\eta$ 求出概率 $p$，我们应用反-logit（logistic）函数：\n$$ p = \\frac{1}{1 + \\exp(-\\eta)} $$\n首先，代入给定的系数和个体数据计算线性预测变量 $\\eta$：\n$$ \\eta = \\beta_{0} + \\beta_{G}\\,PRS + \\beta_{S}\\,S + \\beta_{G\\times E}\\,PRS\\cdot S $$\n$$ \\eta = -3.2 + (0.45)(1.2) + (0.55)(2.0) + (0.20)(1.2)(2.0) $$\n$$ \\eta = -3.2 + 0.54 + 1.10 + 0.48 $$\n$$ \\eta = -3.2 + 2.12 = -1.08 $$\n现在，将 $\\eta = -1.08$ 代入概率公式：\n$$ p = \\frac{1}{1 + \\exp(-(-1.08))} = \\frac{1}{1 + \\exp(1.08)} $$\n计算数值结果：\n$$ p \\approx \\frac{1}{1 + 2.94468} = \\frac{1}{3.94468} \\approx 0.253496 $$\n四舍五入到四位有效数字，预测概率为 $p = 0.2535$。\n\n**第 2 部分：临床相关性解释**\n\n1.  **基线风险对比：** 截距 $\\beta_0 = -3.2$ 代表在没有遗传风险（$PRS=0$）和没有压力（$S=0$）时的基线对数几率。对应的基线概率为 $p_{baseline} = (1 + \\exp(-(-3.2)))^{-1} = (1 + \\exp(3.2))^{-1} \\approx 0.039$。这意味着在没有特定风险因素的情况下，12个月的发病风险约为3.9%。该个体计算出的风险 $25.35\\%$ 远高于这一基线水平，表明其风险显著增加。\n\n2.  **交互作用的意义：** 交互作用系数 $\\beta_{G\\times E} = 0.20$ 是一个正数，这在数学上证实了素质-压力模型的协同效应假说。它意味着，压力对发病风险的影响在高遗传素质的个体中被放大了。对于这个同时具有高遗传风险（$PRS=1.2$）和高压力水平（$S=2.0$）的个体，交互项对对数几率的贡献是 $\\beta_{G\\times E} \\cdot PRS \\cdot S = (0.20)(1.2)(2.0) = 0.48$。这个正值使得总风险超过了基因和压力主效应简单相加所能预测的水平，体现了风险的乘性增长，这是素质-压力交互作用的核心特征。", "answer": "$$\n\\boxed{0.2535}\n$$", "id": "4765949"}, {"introduction": "在临床研究和实践中，我们常常面临不同理论模型的竞争，例如强调多因素累加效应的生物-心理-社会模型，与强调交互效应的素质-压力模型。如何以数据驱动的方式在它们之间做出选择？本练习旨在通过一项计算实践来解决这一高级问题，要求您实施 k 折交叉验证，以评估和比较这两个模型的样本外预测性能。通过完成这项编码任务，您不仅能深入了解两种模型的结构差异，还能掌握一种在现代计算精神病学中用于模型选择的强大实证方法，从而为临床决策提供更可靠的依据。[@problem_id:4766024]", "problem": "给定两个用于预测二元临床结果的竞争性概率模型，这两个模型都植根于精神病学理论。第一个是生物-心理-社会模型（Biopsychosocial Model），该模型假定生物、心理和社会变量各自对疾病风险有加性贡献。第二个是素质-压力模型（Diathesis-Stress Model），该模型假定脆弱性（素质）和环境压力以乘性交互的方式共同塑造风险。您的任务是为每个模型实现逻辑回归的 $k$-折交叉验证，通过平均每样本负对数似然计算样本外预测性能，并为每个提供的测试用例决定应使用哪个模型来指导临床决策。\n\n基本定义和假设：\n- 令 $y_i \\in \\{0,1\\}$ 表示个体 $i$ 的二元结果，其中 $y_i = 1$ 代表抑郁发作的发生，而 $y_i = 0$ 代表其未发生。\n- 令 $\\sigma(z)$ 为 logistic (sigmoid) 函数，定义为 $\\sigma(z) = \\dfrac{1}{1 + e^{-z}}$。\n- 对于给定的设计矩阵 $\\mathbf{X} \\in \\mathbb{R}^{n \\times p}$ 和参数向量 $\\mathbf{w} \\in \\mathbb{R}^{p}$，逻辑回归模型指定 $p_i = \\mathbb{P}(y_i=1 \\mid \\mathbf{x}_i) = \\sigma(\\mathbf{x}_i^\\top \\mathbf{w})$。\n- 在数据集 $\\{(\\mathbf{x}_i,y_i)\\}_{i=1}^n$ 上，逻辑回归的负对数似然（交叉熵损失）由下式给出\n$$\n\\mathcal{L}(\\mathbf{w}) = \\sum_{i=1}^n \\left[\\log\\left(1 + e^{\\mathbf{x}_i^\\top \\mathbf{w}}\\right) - y_i \\cdot \\mathbf{x}_i^\\top \\mathbf{w}\\right].\n$$\n- 在 $k$-折交叉验证中，数据集索引被划分为 $k$ 个大小（约）相等的互斥折；对每个折 $j$，在其余的互补折上拟合参数 $\\mathbf{w}^{(j)}$，并在折 $j$ 上评估损失 $\\mathcal{L}^{(j)}$。样本外性能是所有留出折上的平均每样本损失，\n$$\n\\overline{\\mathcal{L}} = \\frac{1}{n} \\sum_{j=1}^k \\sum_{i \\in \\text{fold } j} \\left[\\log\\left(1 + e^{\\mathbf{x}_i^\\top \\mathbf{w}^{(j)}}\\right) - y_i \\cdot \\mathbf{x}_i^\\top \\mathbf{w}^{(j)}\\right].\n$$\n\n竞争模型：\n- 生物-心理-社会模型（加性）：生物（$B$）、心理（$P$）和社会（$S$）变量通过以下方式进行加性贡献\n$$\n\\mathbb{P}(y=1 \\mid B,P,S) = \\sigma\\left(\\beta_0 + \\beta_B \\cdot B + \\beta_P \\cdot P + \\beta_S \\cdot S\\right).\n$$\n- 素质-压力模型（交互）：素质 $D$ 是生物和心理因素的线性组合（$D = w_B \\cdot B + w_P \\cdot P$），压力 $T$ 是社会因素（$T=S$），风险取决于它们的加性及乘性交互作用\n$$\n\\mathbb{P}(y=1 \\mid D,T) = \\sigma\\left(\\alpha_0 + \\alpha_D \\cdot D + \\alpha_T \\cdot T + \\alpha_{DT} \\cdot D \\cdot T\\right).\n$$\n\n数据生成：\n- 对于每个测试用例，按如下方式生成合成数据。从相关系数为 $\\rho$ 的二元正态分布中联合抽取 $B$ 和 $P$，通过 $B = \\mu_B + \\sigma_B \\cdot Z_1$，$P = \\mu_P + \\sigma_P \\cdot (\\rho \\cdot Z_1 + \\sqrt{1-\\rho^2} \\cdot Z_2)$ 实现，其中 $Z_1, Z_2 \\sim \\mathcal{N}(0,1)$ 是独立的。独立地抽取 $S$ 为 $S = \\mu_S + \\sigma_S \\cdot Z_3$，其中 $Z_3 \\sim \\mathcal{N}(0,1)$ 与 $Z_1$ 和 $Z_2$ 独立。\n- 计算 $D = w_B \\cdot B + w_P \\cdot P$ 和 $T = S$。对于每个测试用例中指定的真实模型，计算线性预测器 $z$（$B,P,S$ 的加性形式，或 $D,T,D \\cdot T$ 的交互形式），然后在个体间独立地从 $\\text{Bernoulli}(\\sigma(z))$ 分布中抽取 $y$。\n\n交叉验证和决策规则：\n- 对每个模型执行 $k$-折交叉验证逻辑回归，仅使用训练折来计算任何数据标准化。评估指标是留出折上的平均每样本负对数似然 $\\overline{\\mathcal{L}}$。优先选择 $\\overline{\\mathcal{L}}$ 较小的模型。\n- 为了决定哪个模型指导临床决策，为每个测试用例输出一个整数：如果生物-心理-社会模型的样本外损失较低，则输出 $1$；如果素质-压力模型的样本外损失较低，则输出 $2$。如果损失之差小于一个小的容差 $\\epsilon$（使用 $\\epsilon = 10^{-6}$），则选择生物-心理-社会模型（输出 $1$），以偏好更简单的加性结构。\n\n测试套件：\n为以下测试用例实现上述过程，每个用例由样本量 $n$、折数 $k$、相关系数 $\\rho$、素质权重 $(w_B,w_P)$ 和真实系数指定。使用提供的随机种子以保证索引洗牌和数据生成的可复现性。\n\n- 案例 1（加性真实模型）：\n  - $n = 800$, $k = 5$, $\\rho = 0.2$, $(w_B,w_P) = (0.7,0.3)$, seed $= 17$。\n  - 特征尺度：$(\\mu_B,\\mu_P,\\mu_S) = (0,0,0)$, $(\\sigma_B,\\sigma_P,\\sigma_S) = (1,1,1)$。\n  - 真实加性系数：$(\\beta_0,\\beta_B,\\beta_P,\\beta_S) = (-1.0, 0.8, 0.6, 0.5)$。\n\n- 案例 2（交互真实模型）：\n  - $n = 1200$, $k = 5$, $\\rho = 0.1$, $(w_B,w_P) = (0.6,0.4)$, seed $= 23$。\n  - 特征尺度：$(\\mu_B,\\mu_P,\\mu_S) = (0,0,0)$, $(\\sigma_B,\\sigma_P,\\sigma_S) = (1,1,1)$。\n  - 真实交互系数：$(\\alpha_0,\\alpha_D,\\alpha_T,\\alpha_{DT}) = (-2.0, 1.0, 0.3, 1.2)$。\n\n- 案例 3（小样本加性真实模型）：\n  - $n = 60$, $k = 3$, $\\rho = 0.0$, $(w_B,w_P) = (0.5,0.5)$, seed $= 99$。\n  - 特征尺度：$(\\mu_B,\\mu_P,\\mu_S) = (0,0,0)$, $(\\sigma_B,\\sigma_P,\\sigma_S) = (1,1,1)$。\n  - 真实加性系数：$(\\beta_0,\\beta_B,\\beta_P,\\beta_S) = (-0.5, 0.5, 0.4, 0.4)$。\n\n- 案例 4（高相关性交互真实模型）：\n  - $n = 1000$, $k = 5$, $\\rho = 0.9$, $(w_B,w_P) = (0.5,0.5)$, seed $= 202$。\n  - 特征尺度：$(\\mu_B,\\mu_P,\\mu_S) = (0,0,0)$, $(\\sigma_B,\\sigma_P,\\sigma_S) = (1,1,1)$。\n  - 真实交互系数：$(\\alpha_0,\\alpha_D,\\alpha_T,\\alpha_{DT}) = (-1.5, 0.9, 0.3, 0.8)$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个方括号内的逗号分隔列表形式的结果（例如，$[result_1,result_2,result_3,result_4]$）。每个元素必须是根据上述决策规则定义的整数 $1$ 或 $2$，并按所列案例（1 到 4）的顺序排列。不应打印任何其他文本。", "solution": "该问题要求使用 $k$-折交叉验证框架来比较两种精神病学模型——生物-心理-社会（BPS）模型和素质-压力（DS）模型。哪个模型更优的决定取决于其样本外预测性能，该性能通过平均每样本负对数似然来衡量。每个测试用例的总体过程包括：数据生成，接着通过交叉验证进行模型拟合与评估，最后以模型选择决策结束。\n\n首先，为每个测试用例，根据提供的规格生成合成数据。使用给定的种子初始化一个随机数生成器，以确保数据和后续交叉验证分区的可复现性。生物（$B$）、心理（$P$）和社会（$S$）变量从高斯分布中抽取。具体来说，$B$ 和 $P$ 从一个均值为 $(\\mu_B, \\mu_P)$、标准差为 $(\\sigma_B, \\sigma_P)$、相关系数为 $\\rho$ 的二元正态分布中联合抽取。这是通过生成独立的标准正态变量 $Z_1, Z_2 \\sim \\mathcal{N}(0,1)$ 并设置 $B = \\mu_B + \\sigma_B Z_1$ 和 $P = \\mu_P + \\sigma_P (\\rho Z_1 + \\sqrt{1-\\rho^2} Z_2)$ 来实现的。社会变量 $S = \\mu_S + \\sigma_S Z_3$ 从一个正态分布中抽取，其中 $Z_3 \\sim \\mathcal{N}(0,1)$ 与 $Z_1$ 和 $Z_2$ 独立。然后，对于 $n$ 个个体中的每一个，其二元结果 $y_i \\in \\{0, 1\\}$ 从伯努利分布 $y_i \\sim \\text{Bernoulli}(p_i)$ 中生成，其中概率 $p_i$ 由 logistic 函数 $p_i = \\sigma(z_i) = (1 + e^{-z_i})^{-1}$ 决定。线性预测器 $z_i$ 是根据为该案例指定的真实模型计算的，该模型可以是加性的 BPS 模型，也可以是基于交互的 DS 模型。\n\n这两个竞争模型都是逻辑回归的特例。\n1.  **生物-心理-社会（BPS）模型**：这是一个加性模型，其中线性预测器 $z$ 是 $B$、$P$ 和 $S$ 的函数。阳性结果的概率是 $\\mathbb{P}(y=1) = \\sigma(\\beta_0 + \\beta_B B + \\beta_P P + \\beta_S S)$。该模型的特征就是 $(B, P, S)$，我们拟合系数 $(\\beta_0, \\beta_B, \\beta_P, \\beta_S)$。\n2.  **素质-压力（DS）模型**：该模型包含一个乘性交互项。首先，构造一个“素质”变量 $D$，作为生物和心理因素的指定线性组合，即 $D = w_B B + w_P P$；同时，将“压力”变量 $T$ 等同于社会因素，即 $T = S$。然后，阳性结果的概率由 $\\mathbb{P}(y=1) = \\sigma(\\alpha_0 + \\alpha_D D + \\alpha_T T + \\alpha_{DT} D \\cdot T)$ 给出。该模型的特征是 $(D, T, D \\cdot T)$，我们拟合系数 $(\\alpha_0, \\alpha_D, \\alpha_T, \\alpha_{DT})$。\n\n任务的核心是为每个模型执行 $k$-折交叉验证。将包含 $n$ 个样本的数据集随机划分为 $k$ 个大小约相等的互斥折。对于每个折 $j \\in \\{1, \\dots, k\\}$，该折作为验证集被留出，而其余的 $k-1$ 折构成训练集。\n\n对每个模型和 $k$ 个划分中的每一个：\n- 构建模型的特征。\n- 一个关键步骤是特征标准化。特征的均值和标准差*仅从训练集*计算。然后，这些统计数据用于对训练集和验证集的特征进行标准化（通过减去均值并除以标准差）。这个过程正确地防止了验证集信息泄漏到训练过程中。通过不对其进行缩放来处理常数特征（标准差为 0）。\n- 一个截距项（一列 1）被添加到标准化后的训练集特征矩阵中。\n- 通过在训练数据上最小化负对数似然（NLL），或称交叉熵损失，来估计逻辑回归参数 $\\mathbf{w}$。在数据集 $\\{(\\mathbf{x}_i,y_i)\\}_{i=1}^m$ 上，参数 $\\mathbf{w}$ 的 NLL 为\n$$ \\mathcal{L}(\\mathbf{w}) = \\sum_{i=1}^m \\left[\\log\\left(1 + e^{\\mathbf{x}_i^\\top \\mathbf{w}}\\right) - y_i (\\mathbf{x}_i^\\top \\mathbf{w})\\right]. $$\n这是一个凸优化问题，可以使用 BFGS 算法高效求解。通过提供 NLL 函数的解析梯度可以提高算法的性能：\n$$ \\nabla_{\\mathbf{w}} \\mathcal{L}(\\mathbf{w}) = \\sum_{i=1}^m \\left(\\sigma(\\mathbf{x}_i^\\top \\mathbf{w}) - y_i\\right) \\mathbf{x}_i = \\mathbf{X}^\\top (\\sigma(\\mathbf{X}\\mathbf{w}) - \\mathbf{y}). $$\n- 一旦参数 $\\mathbf{w}^{(j)}$ 在折 $j$ 的训练数据上拟合完成，就使用这些参数在相应的留出验证集上计算 NLL。\n\n遍历所有 $k$ 个折后，每个模型的总 NLL 是来自 $k$ 个验证集的 NLL 之和。然后将此总损失除以总样本数 $n$，以获得平均每样本样本外 NLL，即 $\\overline{\\mathcal{L}}$。\n\n最后，通过比较 $\\overline{\\mathcal{L}}_{\\text{BPS}}$ 和 $\\overline{\\mathcal{L}}_{\\text{DS}}$ 做出决策。只有当 DS 模型的损失严格低于 BPS 模型的损失，且差值大于容差 $\\epsilon = 10^{-6}$ 时，才选择 DS 模型（输出 $2$）。即，如果 $\\overline{\\mathcal{L}}_{\\text{BPS}} > \\overline{\\mathcal{L}}_{\\text{DS}} + \\epsilon$。否则，选择更简单的 BPS 模型（输出 $1$），在性能相近的情况下偏好简约性。对所有指定的测试用例重复此过程。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef _nll(w, X, y):\n    \"\"\"\n    Calculates the negative log-likelihood for logistic regression.\n    The formula is sum(log(1 + exp(z)) - y*z), which is numerically\n    stabilized using logaddexp(0, z) for log(1 + exp(z)).\n    \"\"\"\n    z = X @ w\n    loss = np.sum(np.logaddexp(0, z) - y * z)\n    return loss\n\ndef _grad_nll(w, X, y):\n    \"\"\"\n    Calculates the gradient of the negative log-likelihood.\n    The formula is X.T @ (p - y), where p is the predicted probability.\n    \"\"\"\n    z = X @ w\n    # Sigmoid function, numerically stable for large negative z\n    p = 1 / (1 + np.exp(-z))\n    grad = X.T @ (p - y)\n    return grad\n\ndef fit_logistic_regression(X, y):\n    \"\"\"\n    Fits a logistic regression model.\n    Assumes X already includes an intercept column.\n    \"\"\"\n    num_features = X.shape[1]\n    w0 = np.zeros(num_features)\n    \n    res = minimize(\n        _nll,\n        w0,\n        args=(X, y),\n        jac=_grad_nll,\n        method='BFGS'\n    )\n    \n    return res.x\n\ndef run_single_case(n, k, rho, w_diathesis, feature_scales, ground_truth, seed):\n    \"\"\"\n    Runs a single test case for model comparison.\n    \"\"\"\n    # 1. Setup Random Number Generator for reproducibility\n    rng = np.random.default_rng(seed)\n\n    # 2. Generate Synthetic Data\n    mus = feature_scales['mus']\n    sigmas = feature_scales['sigmas']\n    \n    z1 = rng.normal(0, 1, size=n)\n    z2 = rng.normal(0, 1, size=n)\n    z3 = rng.normal(0, 1, size=n)\n    \n    B = mus[0] + sigmas[0] * z1\n    P = mus[1] + sigmas[1] * (rho * z1 + np.sqrt(1 - rho**2) * z2)\n    S = mus[2] + sigmas[2] * z3\n    \n    if ground_truth['type'] == 'additive':\n        beta0, betaB, betaP, betaS = ground_truth['coefs']\n        z_true = beta0 + betaB * B + betaP * P + betaS * S\n    else:  # 'interaction'\n        w_b, w_p = w_diathesis\n        D = w_b * B + w_p * P\n        T = S\n        alpha0, alphaD, alphaT, alphaDT = ground_truth['coefs']\n        z_true = alpha0 + alphaD * D + alphaT * T + alphaDT * D * T\n\n    p_true = 1 / (1 + np.exp(-z_true))\n    y = rng.binomial(1, p_true, size=n)\n    \n    # 3. K-Fold Cross-Validation\n    indices = np.arange(n)\n    rng.shuffle(indices)\n    folds = np.array_split(indices, k)\n    \n    total_loss_bps = 0.0\n    total_loss_ds = 0.0\n    \n    w_b, w_p = w_diathesis\n\n    for i in range(k):\n        val_indices = folds[i]\n        train_indices = np.concatenate([folds[j] for j in range(k) if i != j])\n        y_train, y_val = y[train_indices], y[val_indices]\n\n        # --- Biopsychosocial Model ---\n        X_train_feats_bps = np.column_stack((B[train_indices], P[train_indices], S[train_indices]))\n        \n        mean_bps = np.mean(X_train_feats_bps, axis=0)\n        std_bps = np.std(X_train_feats_bps, axis=0)\n        std_bps[std_bps == 0] = 1.0 # Prevent division by zero\n        \n        X_train_std_bps = (X_train_feats_bps - mean_bps) / std_bps\n        X_train_int_bps = np.insert(X_train_std_bps, 0, 1, axis=1)\n        w_bps = fit_logistic_regression(X_train_int_bps, y_train)\n\n        X_val_feats_bps = np.column_stack((B[val_indices], P[val_indices], S[val_indices]))\n        X_val_std_bps = (X_val_feats_bps - mean_bps) / std_bps\n        X_val_int_bps = np.insert(X_val_std_bps, 0, 1, axis=1)\n        total_loss_bps += _nll(w_bps, X_val_int_bps, y_val)\n\n        # --- Diathesis-Stress Model ---\n        D_train = w_b * B[train_indices] + w_p * P[train_indices]\n        T_train = S[train_indices]\n        DT_train = D_train * T_train\n        X_train_feats_ds = np.column_stack((D_train, T_train, DT_train))\n        \n        mean_ds = np.mean(X_train_feats_ds, axis=0)\n        std_ds = np.std(X_train_feats_ds, axis=0)\n        std_ds[std_ds == 0] = 1.0\n        \n        X_train_std_ds = (X_train_feats_ds - mean_ds) / std_ds\n        X_train_int_ds = np.insert(X_train_std_ds, 0, 1, axis=1)\n        w_ds = fit_logistic_regression(X_train_int_ds, y_train)\n        \n        D_val = w_b * B[val_indices] + w_p * P[val_indices]\n        T_val = S[val_indices]\n        DT_val = D_val * T_val\n        X_val_feats_ds = np.column_stack((D_val, T_val, DT_val))\n        \n        X_val_std_ds = (X_val_feats_ds - mean_ds) / std_ds\n        X_val_int_ds = np.insert(X_val_std_ds, 0, 1, axis=1)\n        total_loss_ds += _nll(w_ds, X_val_int_ds, y_val)\n        \n    # 4. Final Comparison\n    avg_loss_bps = total_loss_bps / n\n    avg_loss_ds = total_loss_ds / n\n    epsilon = 1e-6\n\n    if avg_loss_bps > avg_loss_ds + epsilon:\n        return 2\n    else:\n        return 1\n\ndef solve():\n    test_cases = [\n        {\n            'n': 800, 'k': 5, 'rho': 0.2, 'w_diathesis': (0.7, 0.3), 'seed': 17,\n            'feature_scales': {'mus': (0, 0, 0), 'sigmas': (1, 1, 1)},\n            'ground_truth': {'type': 'additive', 'coefs': (-1.0, 0.8, 0.6, 0.5)}\n        },\n        {\n            'n': 1200, 'k': 5, 'rho': 0.1, 'w_diathesis': (0.6, 0.4), 'seed': 23,\n            'feature_scales': {'mus': (0, 0, 0), 'sigmas': (1, 1, 1)},\n            'ground_truth': {'type': 'interaction', 'coefs': (-2.0, 1.0, 0.3, 1.2)}\n        },\n        {\n            'n': 60, 'k': 3, 'rho': 0.0, 'w_diathesis': (0.5, 0.5), 'seed': 99,\n            'feature_scales': {'mus': (0, 0, 0), 'sigmas': (1, 1, 1)},\n            'ground_truth': {'type': 'additive', 'coefs': (-0.5, 0.5, 0.4, 0.4)}\n        },\n        {\n            'n': 1000, 'k': 5, 'rho': 0.9, 'w_diathesis': (0.5, 0.5), 'seed': 202,\n            'feature_scales': {'mus': (0, 0, 0), 'sigmas': (1, 1, 1)},\n            'ground_truth': {'type': 'interaction', 'coefs': (-1.5, 0.9, 0.3, 0.8)}\n        }\n    ]\n    \n    results = []\n    for case in test_cases:\n        result = run_single_case(**case)\n        results.append(result)\n        \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "4766024"}]}