{"hands_on_practices": [{"introduction": "信号检测论 (Signal Detection Theory, SDT) 是一个强大的框架，用以区分个体感知信号的能力和他们报告信号的倾向。这在研究精神病等疾病时至关重要，因为在这些疾病中，知觉偏见可能非常显著。本练习将提供计算核心SDT指标 $d'$ 和 $c$ 的动手实践，从而将抽象的理论应用于具体的精神病理学研究场景中 [@problem_id:4749342]。", "problem": "一个研究团队正在对临床精神病高危个体使用听觉信号检测范式，研究与精神病学中感知与思维的精神病理学相关的知觉决策偏差。对无信号（噪声）和有信号（低语的带情感色彩的词语）的内部反应，采用等方差高斯分布进行建模，这与信号检测论 (Signal Detection Theory, SDT) 一致。具体来说，噪声分布建模为 $X_{N} \\sim \\mathcal{N}(0,1)$，信号分布建模为 $X_{S} \\sim \\mathcal{N}(d',1)$，其中 $d'$ 以标准差为单位量化了这两个分布之间的间隔。决策规则是：当内部反应在共同的标准化决策轴上超过一个固定的判断标准 $k$ 时，报告“有信号”。\n\n将击中率 $H$ 定义为 $H = \\mathbb{P}(X_{S} \\geq k)$，虚报率 $F$ 定义为 $F = \\mathbb{P}(X_{N} \\geq k)$。令 $\\Phi(\\cdot)$ 表示标准正态分布的累积分布函数，而 $Z(\\cdot)$ 表示其反函数，$Z(p) = \\Phi^{-1}(p)$，该函数将概率 $p$ 映射到其对应的 z 分数。\n\n从这些定义和上述等方差高斯假设出发，推导 $d'$ 和偏好指标 $c$ 的表达式，其中 $c$ 定义为决策标准相对于两个分布均值中点的位移（即 $c = k - \\frac{d'}{2}$），并仅用 $Z(H)$ 和 $Z(F)$ 来表示。然后，使用经验观察到的击中率 $H = 0.7$ 和虚报率 $F = 0.4$，计算 $d'$ 和 $c$ 的数值。\n\n将 $d'$ 和 $c$ 的值均四舍五入至四位有效数字。将最终答案表示为一个不带单位的、包含两个元素的行向量 $\\big[d' \\;\\; c\\big]$。", "solution": "用户提供的问题已经过验证，被认为是具有科学依据、提法明确且客观的。这是信号检测论 (SDT) 的一个标准应用，没有任何使其无效的缺陷。因此，我们可以着手求解。\n\n问题要求推导用击中率 $H$ 和虚报率 $F$ 表示的敏感性 $d'$ 和偏好 $c$ 的表达式，然后进行数值计算。内部反应由两个等方差高斯分布建模：\n1. 仅噪声：$X_{N} \\sim \\mathcal{N}(\\mu_{N}=0, \\sigma^{2}=1)$\n2. 信号加噪声：$X_{S} \\sim \\mathcal{N}(\\mu_{S}=d', \\sigma^{2}=1)$\n\n如果内部反应 $x$ 超过一个判断标准 $k$，则报告“有信号”。\n\n首先，我们将建立可观察率（$H$ 和 $F$）与模型参数（$d'$ 和 $k$）之间的关系。令 $\\Phi(z) = \\mathbb{P}(Z \\leq z)$ 为标准正态分布 $Z \\sim \\mathcal{N}(0,1)$ 的累积分布函数 (CDF)，并令 $Z(p) = \\Phi^{-1}(p)$ 为其反函数，即分位数函数。\n\n虚报率 $F$ 是在只有噪声存在时报告有信号的概率：\n$$F = \\mathbb{P}(X_{N} \\geq k)$$\n由于 $X_{N}$ 服从标准正态分布，我们可以写出：\n$$F = \\mathbb{P}(Z \\geq k) = 1 - \\mathbb{P}(Z  k) = 1 - \\Phi(k)$$\n对 $\\Phi(k)$ 进行移项得到：\n$$\\Phi(k) = 1 - F$$\n对两边应用逆正态累积分布函数 $Z(\\cdot)$，得到判断标准 $k$ 的表达式：\n$$k = Z(1 - F)$$\n利用标准正态分布的对称性，即 $Z(1-p) = -Z(p)$，我们可以写出：\n$$k = -Z(F)$$\n\n击中率 $H$ 是在信号存在时正确报告有信号的概率：\n$$H = \\mathbb{P}(X_{S} \\geq k)$$\n$X_{S}$ 的分布是 $\\mathcal{N}(d', 1)$。为了使用标准正态累积分布函数，我们通过减去其均值 ($d'$) 并除以其标准差 ($1$) 来对变量进行标准化：\n$$H = \\mathbb{P}\\left(\\frac{X_{S}-d'}{1} \\geq \\frac{k-d'}{1}\\right) = \\mathbb{P}\\left(Z \\geq k-d'\\right)$$\n与对 $F$ 的推导类似，这可以用累积分布函数表示：\n$$H = 1 - \\Phi(k-d')$$\n对 $\\Phi(k-d')$ 进行移项得到：\n$$\\Phi(k-d') = 1 - H$$\n对两边应用逆正态累积分布函数 $Z(\\cdot)$ 得到：\n$$k - d' = Z(1 - H)$$\n利用对称性 $Z(1-p) = -Z(p)$，我们有：\n$$k - d' = -Z(H)$$\n\n现在我们得到了一个包含两个未知数 $k$ 和 $d'$ 的二元方程组：\n1. $k = -Z(F)$\n2. $k - d' = -Z(H)$\n\n为了推导 $d'$ 的表达式，我们将第一个方程代入第二个方程：\n$$-Z(F) - d' = -Z(H)$$\n解出 $d'$ 即可得到所需的表达式：\n$$d' = Z(H) - Z(F)$$\n\n接下来，我们推导偏好指标 $c$ 的表达式，其定义为 $c = k - \\frac{d'}{2}$。我们代入已推导出的 $k$ 和 $d'$ 的表达式：\n$$c = \\left(-Z(F)\\right) - \\frac{1}{2}\\left(Z(H) - Z(F)\\right)$$\n分配 $-\\frac{1}{2}$ 项：\n$$c = -Z(F) - \\frac{1}{2}Z(H) + \\frac{1}{2}Z(F)$$\n合并含有 $Z(F)$ 的项：\n$$c = -\\frac{1}{2}Z(H) - \\frac{1}{2}Z(F)$$\n提出因子 $-\\frac{1}{2}$ 得到 $c$ 的最终表达式：\n$$c = -\\frac{1}{2}\\left(Z(H) + Z(F)\\right)$$\n\n现在，我们使用经验观察到的率 $H = 0.7$ 和 $F = 0.4$ 来计算 $d'$ 和 $c$ 的数值。我们需要与这些概率相对应的 z 分数：\n- $Z(H) = Z(0.7) = \\Phi^{-1}(0.7)$\n- $Z(F) = Z(0.4) = \\Phi^{-1}(0.4)$\n\n使用标准正态分布表或计算工具，我们得到以下值：\n$$Z(0.7) \\approx 0.5244005$$\n$$Z(0.4) \\approx -0.2533471$$\n\n现在我们可以计算 $d'$：\n$$d' = Z(0.7) - Z(0.4) \\approx 0.5244005 - (-0.2533471)$$\n$$d' \\approx 0.5244005 + 0.2533471 = 0.7777476$$\n四舍五入到四位有效数字，我们得到 $d' \\approx 0.7777$。\n\n接下来，我们计算 $c$：\n$$c = -\\frac{1}{2}(Z(0.7) + Z(0.4)) \\approx -\\frac{1}{2}(0.5244005 + (-0.2533471))$$\n$$c \\approx -\\frac{1}{2}(0.5244005 - 0.2533471) = -\\frac{1}{2}(0.2710534)$$\n$$c \\approx -0.1355267$$\n四舍五入到四位有效数字，我们得到 $c \\approx -0.1355$。\n\n观察者的敏感性 $d'$ 约为 $0.7777$，反应偏好 $c$ 约为 $-0.1355$。$c$ 的负值表明存在一种自由的反应偏好，意味着判断标准设置在了中性点 $\\frac{d'}{2}$ 的左侧，从而导致更多的“有信号”反应。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.7777  -0.1355\n\\end{pmatrix}\n}\n$$", "id": "4749342"}, {"introduction": "贝叶斯框架为我们提供了一个理性信念更新的规范模型，是理解信念如何随新证据而改变的基石。“珠子任务”(beads task) 是一个经典工具，用于研究与妄想思维相关的概率推理偏见，例如“急于下结论”(jumping to conclusions) 。本练习将演示如何运用贝叶斯定理的赔率形式来量化证据强度并更新信念 [@problem_id:4749140]。", "problem": "在关于知觉与思维精神病理学的研究中，珠子任务被用来量化概率推理偏差（例如“急于下结论”偏差），这些偏差常常与妄想观念有关。考虑以下在贝叶斯框架下形式化的经典珠子任务：存在两个隐藏的来源，Jar A 和 Jar B，它们以已知的条件概率产生红色或蓝色的珠子。Jar A 产生红色珠子的概率为 $p(\\text{red}\\mid \\text{Jar A})=0.8$，而 Jar B 产生红色珠子的概率为 $p(\\text{red}\\mid \\text{Jar B})=0.2$。在观察到任何证据之前，先验概率是相等的，$p(\\text{Jar A})=p(\\text{Jar B})=0.5$，这反映了两个假设之间没有初始偏差。\n\n将假设 $H$ 的优势比定义为 $O(H)=\\frac{p(H)}{p(\\neg H)}$。将数据点 $D$ 相对于假设 $H$ 的似然比定义为 $\\text{LR}=\\frac{p(D\\mid H)}{p(D\\mid \\neg H)}$。然后观察到一个红色珠子作为数据点。\n\n从这些定义和贝叶斯定理的基本形式出发，推导并计算在观察到一个红色珠子后的后验优势比 $O_{\\text{post}}(\\text{Jar A}\\mid \\text{red})$。将最终答案表示为单个实数，无需四舍五入。", "solution": "该问题要求推导并计算在给定珠子为红色的条件下，该珠子来自 Jar A 这一假设的后验优势比。我们将首先使用所提供的定义来形式化该问题，然后应用贝叶斯定理来推导所需的量。\n\n令 $H_A$ 代表来源是 Jar A 的假设，令 $H_B$ 代表来源是 Jar B 的假设。令 $D$ 为观察到红色珠子这一数据点。问题提供了以下概率：\n- 假设的先验概率为 $p(H_A) = 0.5$ 和 $p(H_B) = 0.5$。\n- 在每个假设下观察到该数据点的条件概率（似然）为 $p(D \\mid H_A) = p(\\text{red}\\mid \\text{Jar A}) = 0.8$ 和 $p(D \\mid H_B) = p(\\text{red}\\mid \\text{Jar B}) = 0.2$。\n\n由于只有两个可能的来源，假设 $H_A$ 和 $H_B$ 是互斥且穷尽的。这意味着 $H_B$ 是 $H_A$ 的否定，可以写为 $H_B = \\neg H_A$。\n\n问题将假设 $H$ 的优势比定义为 $O(H)=\\frac{p(H)}{p(\\neg H)}$。我们的任务是找到在观察到数据点 $D$ 后，假设 $H_A$ 的后验优势比，记为 $O_{\\text{post}}(H_A \\mid D)$。这是在给定数据点 $D$ 的条件下，$H_A$ 的后验概率与其否定（即 $H_B$）的后验概率之比。\n$$O_{\\text{post}}(H_A \\mid D) = \\frac{p(H_A \\mid D)}{p(\\neg H_A \\mid D)} = \\frac{p(H_A \\mid D)}{p(H_B \\mid D)}$$\n\n根据贝叶斯定理，一个假设的后验概率由以下公式给出：\n$$p(H \\mid D) = \\frac{p(D \\mid H) p(H)}{p(D)}$$\n将此定理应用于我们的假设 $H_A$ 和 $H_B$：\n$$p(H_A \\mid D) = \\frac{p(D \\mid H_A) p(H_A)}{p(D)}$$\n$$p(H_B \\mid D) = \\frac{p(D \\mid H_B) p(H_B)}{p(D)}$$\n\n将这两个表达式代入我们的后验优势比方程：\n$$O_{\\text{post}}(H_A \\mid D) = \\frac{\\frac{p(D \\mid H_A) p(H_A)}{p(D)}}{\\frac{p(D \\mid H_B) p(H_B)}{p(D)}}$$\n\n代表证据的边际概率的项 $p(D)$ 从分子和分母中约去。剩下：\n$$O_{\\text{post}}(H_A \\mid D) = \\frac{p(D \\mid H_A) p(H_A)}{p(D \\mid H_B) p(H_B)}$$\n\n这个表达式可以重组，以分离似然和先验概率：\n$$O_{\\text{post}}(H_A \\mid D) = \\left( \\frac{p(D \\mid H_A)}{p(D \\mid H_B)} \\right) \\left( \\frac{p(H_A)}{p(H_B)} \\right)$$\n\n现在我们将此方程中的各项与问题中给出的定义联系起来。第一个括号中的项是数据点 $D$ 相对于假设 $H_A$ 的似然比 $\\text{LR}$：\n$$\\text{LR} = \\frac{p(D \\mid H_A)}{p(D \\mid \\neg H_A)} = \\frac{p(D \\mid H_A)}{p(D \\mid H_B)}$$\n第二个括号中的项是假设 $H_A$ 的先验优势比，我们将其表示为 $O_{\\text{prior}}(H_A)$：\n$$O_{\\text{prior}}(H_A) = \\frac{p(H_A)}{p(\\neg H_A)} = \\frac{p(H_A)}{p(H_B)}$$\n\n这证实了贝叶斯定理的优势比形式：后验优势比是似然比和先验优势比的乘积。\n$$O_{\\text{post}}(H_A \\mid D) = \\text{LR} \\times O_{\\text{prior}}(H_A)$$\n\n现在我们使用提供的数值进行计算。首先，我们计算先验优势比：\n$$O_{\\text{prior}}(H_A) = \\frac{p(H_A)}{p(H_B)} = \\frac{0.5}{0.5} = 1$$\n接下来，我们计算似然比：\n$$\\text{LR} = \\frac{p(D \\mid H_A)}{p(D \\mid H_B)} = \\frac{p(\\text{red}\\mid \\text{Jar A})}{p(\\text{red}\\mid \\text{Jar B})} = \\frac{0.8}{0.2} = 4$$\n\n最后，我们通过将这两个值相乘来计算后验优势比：\n$$O_{\\text{post}}(H_A \\mid D) = O_{\\text{post}}(\\text{Jar A}\\mid \\text{red}) = 4 \\times 1 = 4$$\n在观察到一个红色珠子后，该珠子源自 Jar A 的后验优势比是 $4$。", "answer": "$$\\boxed{4}$$", "id": "4749140"}, {"introduction": "传统的思维障碍评估依赖于主观的临床评定，而现代计算方法为此提供了客观化的可能。本练习介绍了一种前沿技术，即利用词向量嵌入和余弦相似度来量化言语的语义连贯性。通过这个编码实践，你将构建一个实用的计算工具，用以分析和量化思维形式障碍中的思维脱轨现象 [@problem_id:4749168]。", "problem": "你的任务是形式化一个局部语义连贯性的定量指标，作为思维障碍与正常思维流的代理指标，其理论基础源于感知与思维的精神病理学。基本依据是，精神病学背景下的思维紊乱表现为思维切线、思维脱轨以及连续话语间局部语义连贯性降低等特征。在计算术语中，一种经过充分检验的表征方法将句子映射到固定维度的数值嵌入；局部语义连贯性可以通过连续句子嵌入之间的余弦相似度来操作化。你必须从向量几何的核心定义出发，构建连贯性指数和一个基于阈值的分类器。\n\n定义：\n- 对于$\\mathbb{R}^d$中的任意两个非零向量$\\mathbf{u}$和$\\mathbf{v}$，余弦相似度定义为\n$$\n\\mathrm{cos\\_sim}(\\mathbf{u},\\mathbf{v}) \\equiv \\frac{\\mathbf{u}\\cdot \\mathbf{v}}{\\|\\mathbf{u}\\|_2 \\, \\|\\mathbf{v}\\|_2}.\n$$\n如果$\\|\\mathbf{u}\\|_2 = 0$或$\\|\\mathbf{v}\\|_2 = 0$，则该向量对不贡献有效相似度，必须在求平均值时排除。\n- 对于一个由$n$个句子嵌入组成的序列$\\mathbf{s}_1,\\mathbf{s}_2,\\ldots,\\mathbf{s}_n$，将有效连续对的数量定义为$m$，连贯性指数定义为\n$$\nCI \\equiv \n\\begin{cases}\n\\frac{1}{m} \\sum_{i=1}^{n-1} \\mathrm{cos\\_sim}(\\mathbf{s}_i,\\mathbf{s}_{i+1}) \\;\\;\\text{over all valid pairs,}  \\text{if } m0,\\\\\n0,  \\text{if } m=0. \n\\end{cases}\n$$\n当$m=0$时$CI=0$的约定，反映了因缺少有效比较而无法在转换之间建立局部连贯性。\n- 分类规则：对于一个阈值$T \\in [-1,1]$，如果$CI  T$，则将其分类为思维障碍（1）。\n\n任务：\n1.  计算训练集$S\\_{train}$中每个序列的连贯性指数$CI$。\n2.  通过在$S\\_{train}$上最大化平衡准确率（$BA = \\frac{1}{2}(\\mathrm{TPR}+\\mathrm{TNR})$），找到最优阈值$T$。如果存在多个阈值达到相同的最大$BA$，选择最小的那个。\n3.  使用确定的$T$对测试集$S\\_{test}$中的每个序列进行分类。\n\n你的最终答案应该是一个列表，格式为`[T, C1, C2, C3, C4]`，其中$T$是四舍五入到小数点后六位的最优阈值，$C1, C2, C3, C4$分别是测试序列$T1, T2, T3, T4$的分类标签（0或1）。\n\n数据集：\n-   训练集$S_{train}$：\n    -   $S\\_N1$（标签0，正常）：$\\big[[1,1,0,0,0],[1.1,0.9,0.1,0,0],[0.9,1.05,-0.05,0,0],[1,1,0,0,0]\\big]$\n    -   $S\\_D1$（标签1，思维障碍）：$\\big[[1,0,0,0,0],[0,1,0,0,0],[0,0,1,0,0],[0,0,0,1,0]\\big]$\n    -   $S\\_N2$（标签0，正常）：$\\big[[0,0,1,1,0],[0,0.1,1,0.9,0.05],[0,-0.05,1.05,1.1,-0.02],[0,0,1,1,0]\\big]$\n    -   $S\\_D2$（标签1，思维障碍）：$\\big[[1,0,0,0,0],[-1,0,0,0,0],[0,1,0,0,0],[0,0,1,0,0]\\big]$\n-   测试集$S_{test}$：\n    -   $T1$：$\\big[[0,1,1,0,0],[0,0.9,1.1,-0.05,0],[0,1.05,0.95,0.02,0],[0,0.98,1.02,-0.01,0]\\big]$\n    -   $T2$：$\\big[[1,0,0,0,0],[0,0,-1,0,0],[0,1,0,0,0],[0,0,0,1,0]\\big]$\n    -   $T3$：$\\big[[1,2,3,4,5]\\big]$\n    -   $T4$：$\\big[[0,0,0,0,0],[1,1,0,0,0],[0,0,0,0,0],[1,-1,0,0,0]\\big]$", "solution": "问题陈述已经过评估并被确定为有效。它在科学上基于计算语言学和精神病学的既定原则，定义明确，数据充分，问题阐述清晰，并且其表述是客观的。所有术语都得到了正式定义，计算任务的结构旨在产生一个唯一的、可验证的解决方案。该问题没有说明中列出的导致无效的缺陷。因此，我们可以着手解决。\n\n解决方案是一个多步骤的过程：\n1.  为四个训练序列中的每一个计算连贯性指数（$CI$）。\n2.  通过在训练集上最大化平衡准确率（$BA$）来确定最优分类阈值$T$。\n3.  为四个测试序列中的每一个计算$CI$，并使用确定的阈值$T$对它们进行分类。\n\n所有向量运算都在$\\mathbb{R}^5$中执行。\n\n**第1步：训练集的连贯性指数（$CI$）计算**\n\n连贯性指数（$CI$）是连续有效句子嵌入之间余弦相似度的平均值。如果一对向量$(\\mathbf{s}_i, \\mathbf{s}_{i+1})$中的两个向量L2范数都不为零，则该对是有效的。\n\n余弦相似度为$\\mathrm{cos\\_sim}(\\mathbf{u},\\mathbf{v}) = \\frac{\\mathbf{u}\\cdot \\mathbf{v}}{\\|\\mathbf{u}\\|_2 \\, \\|\\mathbf{v}\\|_2}$。\n\n1.  **序列$S\\_N1$（标签$0$，正常）**：\n    $\\mathbf{s}_1 = [1,1,0,0,0]$, $\\mathbf{s}_2 = [1.1,0.9,0.1,0,0]$, $\\mathbf{s}_3 = [0.9,1.05,-0.05,0,0]$, $\\mathbf{s}_4 = [1,1,0,0,0]$。\n    所有向量都非零。存在$m=3$个有效对。\n    -   $\\mathrm{cos\\_sim}(\\mathbf{s}_1, \\mathbf{s}_2) = \\frac{1(1.1) + 1(0.9)}{\\sqrt{1^2+1^2}\\sqrt{1.1^2+0.9^2+0.1^2}} = \\frac{2}{\\sqrt{2}\\sqrt{2.03}} = \\frac{2}{\\sqrt{4.06}} \\approx 0.992523$\n    -   $\\mathrm{cos\\_sim}(\\mathbf{s}_2, \\mathbf{s}_3) = \\frac{1.1(0.9) + 0.9(1.05) + 0.1(-0.05)}{\\sqrt{2.03}\\sqrt{0.9^2+1.05^2+(-0.05)^2}} = \\frac{1.93}{\\sqrt{2.03}\\sqrt{1.915}} = \\frac{1.93}{\\sqrt{3.88745}} \\approx 0.978749$\n    -   $\\mathrm{cos\\_sim}(\\mathbf{s}_3, \\mathbf{s}_4) = \\frac{0.9(1) + 1.05(1)}{\\sqrt{1.915}\\sqrt{2}} = \\frac{1.95}{\\sqrt{3.83}} \\approx 0.996425$\n    -   $CI(S\\_N1) = \\frac{1}{3}(0.992523 + 0.978749 + 0.996425) \\approx 0.989232$\n\n2.  **序列$S\\_D1$（标签$1$，思维障碍）**：\n    $\\mathbf{s}_1 = [1,0,0,0,0]$, $\\mathbf{s}_2 = [0,1,0,0,0]$, $\\mathbf{s}_3 = [0,0,1,0,0]$, $\\mathbf{s}_4 = [0,0,0,1,0]$。\n    所有向量都是非零单位向量。所有连续对都是正交的。\n    -   对于$i=1, 2, 3$，$\\mathbf{s}_i \\cdot \\mathbf{s}_{i+1} = 0$。\n    -   对于所有对，$\\mathrm{cos\\_sim}(\\mathbf{s}_i, \\mathbf{s}_{i+1}) = 0$。\n    -   $CI(S\\_D1) = \\frac{1}{3}(0 + 0 + 0) = 0$\n\n3.  **序列$S\\_N2$（标签$0$，正常）**：\n    $\\mathbf{s}_1 = [0,0,1,1,0]$, $\\mathbf{s}_2 = [0,0.1,1,0.9,0.05]$, $\\mathbf{s}_3 = [0,-0.05,1.05,1.1,-0.02]$, $\\mathbf{s}_4 = [0,0,1,1,0]$。\n    所有向量都非零。存在$m=3$个有效对。\n    -   $\\mathrm{cos\\_sim}(\\mathbf{s}_1, \\mathbf{s}_2) = \\frac{1(1) + 1(0.9)}{\\sqrt{2}\\sqrt{0.1^2+1^2+0.9^2+0.05^2}} = \\frac{1.9}{\\sqrt{2}\\sqrt{1.8225}} = \\frac{1.9}{1.35\\sqrt{2}} \\approx 0.995221$\n    -   $\\mathrm{cos\\_sim}(\\mathbf{s}_2, \\mathbf{s}_3) = \\frac{0.1(-0.05) + 1(1.05) + 0.9(1.1) + 0.05(-0.02)}{\\sqrt{1.8225}\\sqrt{(-0.05)^2+1.05^2+1.1^2+(-0.02)^2}} = \\frac{2.034}{\\sqrt{1.8225}\\sqrt{2.3154}} \\approx 0.990145$\n    -   $\\mathrm{cos\\_sim}(\\mathbf{s}_3, \\mathbf{s}_4) = \\frac{1.05(1) + 1.1(1)}{\\sqrt{2.3154}\\sqrt{2}} = \\frac{2.15}{\\sqrt{4.6308}} \\approx 0.999052$\n    -   $CI(S\\_N2) = \\frac{1}{3}(0.995221 + 0.990145 + 0.999052) \\approx 0.994806$\n\n4.  **序列$S\\_D2$（标签$1$，思维障碍）**：\n    $\\mathbf{s}_1 = [1,0,0,0,0]$, $\\mathbf{s}_2 = [-1,0,0,0,0]$, $\\mathbf{s}_3 = [0,1,0,0,0]$, $\\mathbf{s}_4 = [0,0,1,0,0]$。\n    所有向量都非零。存在$m=3$个有效对。\n    -   $\\mathrm{cos\\_sim}(\\mathbf{s}_1, \\mathbf{s}_2) = -1$（向量是反平行的）。\n    -   $\\mathrm{cos\\_sim}(\\mathbf{s}_2, \\mathbf{s}_3) = 0$（向量是正交的）。\n    -   $\\mathrm{cos\\_sim}(\\mathbf{s}_3, \\mathbf{s}_4) = 0$（向量是正交的）。\n    -   $CI(S\\_D2) = \\frac{1}{3}(-1 + 0 + 0) = -1/3 \\approx -0.333333$\n\n**第2步：最优阈值确定**\n\n我们有以下训练集（$CI$，标签）对：\n$\\{ (-0.333333, 1), (0, 1), (0.989232, 0), (0.994806, 0) \\}$。\n有$P=2$个正例（思维障碍，标签$1$）样本和$N=2$个负例（正常，标签$0$）样本。\n排序后的唯一$CI$值为$v_1 = -1/3$， $v_2 = 0$， $v_3 \\approx 0.989232$， $v_4 \\approx 0.994806$。\n候选阈值是连续排序的唯一值之间的中点，加上$-1$和$1$。\n-   $T_1 = -1$\n-   $T_2 = (v_1 + v_2) / 2 = (-1/3 + 0)/2 = -1/6 \\approx -0.166667$\n-   $T_3 = (v_2 + v_3) / 2 = (0 + 0.989232)/2 \\approx 0.494616$\n-   $T_4 = (v_3 + v_4) / 2 = (0.989232 + 0.994806)/2 \\approx 0.992019$\n-   $T_5 = 1$\n\n我们为每个候选$T$评估平衡准确率$BA(T) = \\frac{1}{2}(\\mathrm{TPR}(T) + \\mathrm{TNR}(T))$。如果序列的$CI  T$，则将其分类为思维障碍（1）。\n\n-   对于$T = -0.166667$：\n    -   预测：$CI(S\\_D2)  T \\implies 1$；$CI(S\\_D1) \\not T \\implies 0$；$CI(S\\_N1) \\not T \\implies 0$；$CI(S\\_N2) \\not T \\implies 0$。\n    -   TP=1, FN=1, TN=2, FP=0。TPR = $1/2 = 0.5$。TNR = $2/2 = 1.0$。\n    -   $BA = 0.5 \\times (0.5 + 1.0) = 0.75$。\n\n-   对于$T = 0.494616$：\n    -   预测：$CI(S\\_D2)  T \\implies 1$；$CI(S\\_D1)  T \\implies 1$；$CI(S\\_N1) \\not T \\implies 0$；$CI(S\\_N2) \\not T \\implies 0$。\n    -   TP=2, FN=0, TN=2, FP=0。TPR = $2/2 = 1.0$。TNR = $2/2 = 1.0$。\n    -   $BA = 0.5 \\times (1.0 + 1.0) = 1.0$。\n\n-   对于$T = 0.992019$：\n    -   预测：$CI(S\\_D2)  T \\implies 1$；$CI(S\\_D1)  T \\implies 1$；$CI(S\\_N1)  T \\implies 1$；$CI(S\\_N2) \\not T \\implies 0$。\n    -   TP=2, FN=0, TN=1, FP=1。TPR = $2/2 = 1.0$。TNR = $1/2 = 0.5$。\n    -   $BA = 0.5 \\times (1.0 + 0.5) = 0.75$。\n\n最大$BA$为$1.0$，由阈值$T \\approx 0.494616$唯一实现。因此，这是我们选择的阈值。\n\n**第3步：测试序列分类**\n\n现在我们为每个测试序列计算$CI$，并使用$T \\approx 0.494616$对其进行分类。\n\n1.  **测试序列$T1$**：\n    序列：$\\big[[0,1,1,0,0],[0,0.9,1.1,-0.05,0],[0,1.05,0.95,0.02,0],[0,0.98,1.02,-0.01,0]\\big]$。\n    这些向量与$S\\_N1$和$S\\_N2$相似，表明具有高连贯性。\n    -   $\\mathrm{cos\\_sim}_1 \\approx 0.993884$\n    -   $\\mathrm{cos\\_sim}_2 \\approx 0.989211$\n    -   $\\mathrm{cos\\_sim}_3 \\approx 0.997204$\n    -   $CI(T1) = \\frac{1}{3}(0.993884 + 0.989211 + 0.997204) \\approx 0.993433$。\n    -   由于$CI(T1) \\approx 0.993433 \\not 0.494616$，分类为$0$（正常）。\n\n2.  **测试序列$T2$**：\n    序列：$\\big[[1,0,0,0,0],[0,0,-1,0,0],[0,1,0,0,0],[0,0,0,1,0]\\big]$。\n    -   所有连续向量对都是正交的。\n    -   对于所有对，$\\mathrm{cos\\_sim}(\\mathbf{s}_i, \\mathbf{s}_{i+1}) = 0$。\n    -   $CI(T2) = 0$。\n    -   由于$CI(T2) = 0  0.494616$，分类为$1$（思维障碍）。\n\n3.  **测试序列$T3$**：\n    序列：$\\big[[1,2,3,4,5]\\big]$。\n    -   该序列只有$n=1$个句子。连续对的数量为$n-1=0$。\n    -   有效对的数量为$m=0$。\n    -   根据定义，如果$m=0$，则$CI=0$。\n    -   由于$CI(T3) = 0  0.494616$，分类为$1$（思维障碍）。\n\n4.  **测试序列$T4$**：\n    序列：$\\big[[0,0,0,0,0],[1,1,0,0,0],[0,0,0,0,0],[1,-1,0,0,0]\\big]$。\n    -   对1：$(\\mathbf{s}_1, \\mathbf{s}_2)$。$\\mathbf{s}_1$是零向量，因此该对无效。\n    -   对2：$(\\mathbf{s}_2, \\mathbf{s}_3)$。$\\mathbf{s}_3$是零向量，因此该对无效。\n    -   对3：$(\\mathbf{s}_3, \\mathbf{s}_4)$。$\\mathbf{s}_3$是零向量，因此该对无效。\n    -   有效对的数量为$m=0$。\n    -   根据定义，如果$m=0$，则$CI=0$。\n    -   由于$CI(T4) = 0  0.494616$，分类为$1$（思维障碍）。\n\n**最终结果总结**\n-   最优阈值$T \\approx 0.494616$\n-   $T1$的分类：$0$\n-   $T2$的分类：$1$\n-   $T3$的分类：$1$\n-   $T4$的分类：$1$\n\n最终输出将按指定格式列出这些值。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the quantitative index of local semantic coherence, determines\n    an optimal classification threshold, and classifies test sequences.\n    \"\"\"\n\n    # Data specification\n    # Training sequences with labels (0: normal, 1: disordered)\n    train_data = {\n        'S_N1': (np.array([[1,1,0,0,0], [1.1,0.9,0.1,0,0], [0.9,1.05,-0.05,0,0], [1,1,0,0,0]]), 0),\n        'S_D1': (np.array([[1,0,0,0,0], [0,1,0,0,0], [0,0,1,0,0], [0,0,0,1,0]]), 1),\n        'S_N2': (np.array([[0,0,1,1,0], [0,0.1,1,0.9,0.05], [0,-0.05,1.05,1.1,-0.02], [0,0,1,1,0]]), 0),\n        'S_D2': (np.array([[1,0,0,0,0], [-1,0,0,0,0], [0,1,0,0,0], [0,0,1,0,0]]), 1)\n    }\n\n    # Test sequences\n    test_data = {\n        'T1': np.array([[0,1,1,0,0], [0,0.9,1.1,-0.05,0], [0,1.05,0.95,0.02,0], [0,0.98,1.02,-0.01,0]]),\n        'T2': np.array([[1,0,0,0,0], [0,0,-1,0,0], [0,1,0,0,0], [0,0,0,1,0]]),\n        'T3': np.array([[1,2,3,4,5]]),\n        'T4': np.array([[0,0,0,0,0], [1,1,0,0,0], [0,0,0,0,0], [1,-1,0,0,0]])\n    }\n\n    def calculate_ci(sequence):\n        \"\"\"\n        Calculates the Coherence Index (CI) for a sequence of sentence embeddings.\n        \"\"\"\n        if sequence.shape[0] == 1:\n            return 0.0\n\n        similarities = []\n        \n        for i in range(sequence.shape[0] - 1):\n            s_i = sequence[i]\n            s_i_plus_1 = sequence[i+1]\n            \n            norm_s_i = np.linalg.norm(s_i)\n            norm_s_i_plus_1 = np.linalg.norm(s_i_plus_1)\n\n            if norm_s_i == 0 or norm_s_i_plus_1 == 0:\n                continue\n\n            dot_product = np.dot(s_i, s_i_plus_1)\n            cos_sim = dot_product / (norm_s_i * norm_s_i_plus_1)\n            similarities.append(cos_sim)\n\n        if not similarities:\n            return 0.0\n        \n        return np.mean(similarities)\n\n    # Step 1: Compute CI for all training sequences\n    train_cis = []\n    train_labels = []\n    for name, (data, label) in train_data.items():\n        ci = calculate_ci(data)\n        train_cis.append(ci)\n        train_labels.append(label)\n\n    # Step 2: Determine the optimal threshold T\n    unique_sorted_cis = sorted(list(set(train_cis)))\n    \n    candidate_thresholds = set([-1.0, 1.0])\n    for i in range(len(unique_sorted_cis) - 1):\n        midpoint = (unique_sorted_cis[i] + unique_sorted_cis[i+1]) / 2\n        candidate_thresholds.add(midpoint)\n    \n    best_t_list = []\n    max_ba = -np.inf\n\n    pos_samples = sum(1 for label in train_labels if label == 1)\n    neg_samples = sum(1 for label in train_labels if label == 0)\n\n    for t_cand in sorted(list(candidate_thresholds)):\n        predictions = [1 if ci  t_cand else 0 for ci in train_cis]\n        \n        tp = sum(1 for i in range(len(train_labels)) if train_labels[i] == 1 and predictions[i] == 1)\n        tn = sum(1 for i in range(len(train_labels)) if train_labels[i] == 0 and predictions[i] == 0)\n        \n        tpr = tp / pos_samples if pos_samples > 0 else 0.0\n        tnr = tn / neg_samples if neg_samples > 0 else 0.0\n        \n        ba = 0.5 * (tpr + tnr)\n\n        if ba > max_ba:\n            max_ba = ba\n            best_t_list = [t_cand]\n        elif ba == max_ba:\n            best_t_list.append(t_cand)\n\n    # Among thresholds with max BA, choose the smallest T\n    optimal_t = min(best_t_list)\n\n    # Step 3: Compute CI for test sequences and classify\n    test_classifications = []\n    for name in ['T1', 'T2', 'T3', 'T4']:\n        data = test_data[name]\n        ci = calculate_ci(data)\n        classification = 1 if ci  optimal_t else 0\n        test_classifications.append(classification)\n\n    # Final output formatting\n    c1, c2, c3, c4 = test_classifications\n    print(f\"[{optimal_t:.6f},{c1},{c2},{c3},{c4}]\")\n\nsolve()\n```", "id": "4749168"}]}