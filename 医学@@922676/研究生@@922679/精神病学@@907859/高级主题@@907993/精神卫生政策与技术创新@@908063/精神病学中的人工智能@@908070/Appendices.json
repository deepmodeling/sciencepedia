{"hands_on_practices": [{"introduction": "一个在精神病学中用于筛查高风险个体的AI模型，即使其灵敏度和特异性很高，也可能因为罕见事件的低患病率而产生大量的假阳性警报。本次实践将引导你应用贝叶斯定理，计算一个自杀风险预测模型的阳性预测值（Positive Predictive Value, PPV），从而揭示在临床实践中应如何审慎解读这些AI警报，并理解其对后续临床分诊和资源分配的影响 [@problem_id:4689968]。", "problem": "一个综合医疗保健系统部署了一个人工智能（AI）风险分层模型，用于筛查成年基层医疗患者在未来$6$个月内尝试自杀的风险。在一个代表目标部署人群的时间上留出的测试集上，该模型在固定的警报阈值下运行，其灵敏度为$0.85$，特异性为$0.95$。独立的监测数据表明，该人群中$6$个月内自杀未遂的发生率（预测期内的患病率）为 $\\pi = 0.02$。仅使用灵敏度、特异性和患病率的核心定义以及贝叶斯定理，从第一性原理推导阳性预测值（PPV）的表达式。阳性预测值定义为：在给定阳性警报的情况下，患者在$6$个月内确实发生自杀未遂的概率。然后，计算此情景下的PPV数值。将最终的PPV表示为四舍五入到$4$位有效数字的小数。最后，简要地用文字解释，如果该模型用于触发外展服务，这个PPV对临床分诊和资源分配意味着什么，无需计算任何额外的数值。", "solution": "该问题是有效的，因为它科学地基于生物统计学的既定原则，问题提出得当，信息充分且一致，并且陈述客观。\n\n任务是推导阳性预测值（PPV）的表达式，计算给定情景下的数值，并解释结果。\n\n让我们定义以下事件：\n- $S$：患者在$6$个月内发生自杀未遂的事件。\n- $S^c$：患者在$6$个月内未发生自杀未遂的事件。\n- $A$：AI模型为患者生成阳性警报的事件。\n- $A^c$：AI模型未为患者生成阳性警报的事件。\n\n根据问题陈述，我们已知以下概率：\n- 自杀未遂的患病率（发生率）为 $\\pi = P(S) = 0.02$。\n- 模型的灵敏度是在发生自杀未遂的情况下出现阳性警报的概率，即 $P(A|S) = 0.85$。\n- 模型的特异性是在未发生自杀未遂的情况下出现阴性警报的概率，即 $P(A^c|S^c) = 0.95$。\n\n根据患病率的定义，患者未发生自杀未遂的概率为 $P(S^c) = 1 - P(S) = 1 - \\pi = 1 - 0.02 = 0.98$。\n根据特异性的定义，我们可以推导出假阳性率（FPR），即在未发生自杀未遂的情况下出现阳性警报的概率：\n$P(A|S^c) = 1 - P(A^c|S^c) = 1 - 0.95 = 0.05$。\n\n阳性预测值（PPV）定义为在测试结果为阳性（警报）的情况下，患者确实患有该状况（自杀未遂）的概率。用我们的符号表示，即为 $P(S|A)$。\n\n我们使用贝叶斯定理从第一性原理推导PPV的表达式：\n$$P(S|A) = \\frac{P(A|S)P(S)}{P(A)}$$\n\n分母 $P(A)$ 是收到阳性警报的边际概率。我们可以使用全概率定律计算它，对互斥且穷尽的事件 $S$ 和 $S^c$ 求和：\n$$P(A) = P(A|S)P(S) + P(A|S^c)P(S^c)$$\n\n将 $P(A)$ 的这个表达式代入贝叶斯定理，得到PPV的完整表达式：\n$$PPV = P(S|A) = \\frac{P(A|S)P(S)}{P(A|S)P(S) + P(A|S^c)P(S^c)}$$\n\n这可以表示为灵敏度、特异性和患病率（$\\pi$）的函数：\n$$PPV = \\frac{(\\text{sensitivity}) \\times \\pi}{(\\text{sensitivity}) \\times \\pi + (1 - \\text{specificity}) \\times (1 - \\pi)}$$\n这就是从第一性原理进行的推导。\n\n接下来，我们通过代入给定值来计算PPV的数值：\n- $\\text{sensitivity} = 0.85$\n- $\\text{specificity} = 0.95$\n- $\\pi = 0.02$\n\n分子是：\n$P(A|S)P(S) = 0.85 \\times 0.02 = 0.017$。\n\n分母是：\n$P(A) = P(A|S)P(S) + P(A|S^c)P(S^c) = (0.85 \\times 0.02) + ((1 - 0.95) \\times (1 - 0.02))$\n$P(A) = (0.017) + (0.05 \\times 0.98)$\n$P(A) = 0.017 + 0.049 = 0.066$。\n\n现在，我们可以计算PPV：\n$$PPV = \\frac{0.017}{0.066} = \\frac{17}{66} \\approx 0.257575...$$\n\n四舍五入到$4$位有效数字，PPV为$0.2576$。\n\n最后，我们解释这个PPV对临床分诊和资源分配的意义。PPV为$0.2576$意味着，在所有收到AI模型阳性警报的患者中，只有大约$25.8\\%$的人会在随后的$6$个月内真正发生自杀未遂。剩下的绝大多数，约$74.2\\%$，是假阳性。\n\n在临床上，这意味着一个阳性警报不能被视为高风险的最终确认。相反，它应被视为一个需要进一步、更详细临床评估的信号。如果模型的警报用于触发外展服务，那么外展方案必须设计成能够处理大量的假阳性。对于模型正确识别的每一个真正的高风险个体，外展人员将需要与大约三个并非真正高风险的个体接触（因为 $(1-0.2576)/0.2576 \\approx 2.88$）。这对资源分配有重大影响。一个高效的二次筛查过程至关重要，以避免精神卫生服务负担过重，并防止临床医生出现“警报疲劳”——即频繁的假警报可能导致警报被忽略。该模型的价值在于丰富用于靶向筛查的亚群，而不是取代临床判断。", "answer": "$$\\boxed{0.2576}$$", "id": "4689968"}, {"introduction": "在临床决策中，一个AI模型预测的风险概率值本身与分类结果同样重要，但前提是这些概率值是可靠的。本次实践将介绍布里尔分数（Brier score）和校准斜率（calibration slope）这两个关键指标，通过计算它们，你将学会如何评估一个模型的预测概率是否“校准”良好，以及它是倾向于过度自信还是过于保守 [@problem_id:4689987]。", "problem": "一个人工智能模型为一组由$10$名接受门诊治疗的成年人组成的预留队列，输出了未来$30$天内重度抑郁症复发的个体化预测概率。对每位患者$i$，模型的预测概率为$p_i \\in (0,1)$，观察结果为$y_i \\in \\{0,1\\}$，其中$y_i=1$表示在随访期间复发。预测和结果如下：\n- 患者$1$–$6$：$p_i = 0.20$。其中，患者$1$和$3$复发（$y_1 = 1, y_3 = 1$），患者$2、4、5、6$未复发（$y_2 = 0, y_4 = 0, y_5 = 0, y_6 = 0$）。\n- 患者$7$–$10$：$p_i = 0.65$。其中，患者$7、8、10$复发（$y_7 = 1, y_8 = 1, y_{10} = 1$），患者$9$未复发（$y_9 = 0$）。\n\n仅从核心定义出发：\n- Brier分数是$n$名患者的预测概率$p_i$与观察结果$y_i$之间的均方误差。\n- 校准斜率通过逻辑斯蒂校准定义：对$y_i$与预测概率的对数优势（log-odds）进行逻辑斯蒂回归拟合，即用线性预测量$\\alpha + \\beta \\,\\text{logit}(p_i)$来建模$\\Pr(y_i=1 \\mid \\text{logit}(p_i))$，其中$\\text{logit}(p) = \\ln\\!\\left(\\frac{p}{1-p}\\right)$，并取斜率$\\beta$的最大似然估计。\n\n使用以上定义和数据，计算：\n1. 该队列的Brier分数。\n2. 校准斜率$\\beta$。\n\n然后，就业抑郁症复发风险预测的临床术语简要解释这两个量，重点关注总体准确性以及模型的概率是过于极端还是过于保守。按顺序报告Brier分数和校准斜率的最终数值结果，每个结果都四舍五入到四位有效数字。无需单位。", "solution": "该问题陈述被评估为具有科学依据、问题设定良好且客观。它提供了计算所要求数量的所有必要数据和定义。该问题是统计模型评估指标（Brier分数和校准斜率）在给定数据集上的标准应用。满足有效问题的所有条件。\n\n问题要求基于一个由$n=10$名患者组成的队列的一组预测概率和观察结果，计算两个量：Brier分数和校准斜率。\n\n首先，我们计算Brier分数。Brier分数定义为预测概率$p_i$和观察结果$y_i$之间的均方误差。公式为：\n$$ BS = \\frac{1}{n} \\sum_{i=1}^{n} (p_i - y_i)^2 $$\n数据以两组形式提供。\n对于患者$1$到$6$，预测概率为$p_i = 0.20$。\n- 其中两名患者（$i=1, 3$）复发，因此他们的结果是$y_i=1$。他们对平方误差和的贡献各为$(0.20 - 1)^2 = (-0.80)^2 = 0.64$。\n- 其中四名患者（$i=2, 4, 5, 6$）未复发，因此他们的结果是$y_i=0$。他们的贡献各为$(0.20 - 0)^2 = (0.20)^2 = 0.04$。\n第一组的总平方误差和为$2 \\times 0.64 + 4 \\times 0.04 = 1.28 + 0.16 = 1.44$。\n\n对于患者$7$到$10$，预测概率为$p_i = 0.65$。\n- 其中三名患者（$i=7, 8, 10$）复发，因此他们的结果是$y_i=1$。他们的贡献各为$(0.65 - 1)^2 = (-0.35)^2 = 0.1225$。\n- 一名患者（$i=9$）未复发，因此他的结果是$y_i=0$。他的贡献是$(0.65 - 0)^2 = (0.65)^2 = 0.4225$。\n第二组的总平方误差和为$3 \\times 0.1225 + 1 \\times 0.4225 = 0.3675 + 0.4225 = 0.79$。\n\n所有$n=10$名患者的总平方误差和为$1.44 + 0.79 = 2.23$。\nBrier分数是该和的平均值：\n$$ BS = \\frac{2.23}{10} = 0.223 $$\n四舍五入到四位有效数字，Brier分数为$0.2230$。\n\n其次，我们计算校准斜率$\\beta$。这是通过将结果$y_i$对预测概率的对数优势$x_i = \\text{logit}(p_i) = \\ln\\left(\\frac{p_i}{1-p_i}\\right)$进行逻辑斯蒂回归模型拟合得到的。该模型为$\\Pr(y_i=1 \\mid x_i) = \\sigma(\\alpha + \\beta x_i)$，其中$\\sigma(z) = (1+\\exp(-z))^{-1}$是sigmoid函数。\n\n数据可以根据预测变量$x_i$的两个不同值聚合成两组。\nA组：$p_A = 0.20$。预测变量为$x_A = \\text{logit}(0.20) = \\ln\\left(\\frac{0.20}{0.80}\\right) = \\ln(0.25) = -\\ln(4)$。该组有$n_A=6$名患者，其中$k_A=2$人复发。观察到的复发频率为$f_A = k_A/n_A = 2/6 = 1/3$。\nB组：$p_B = 0.65$。预测变量为$x_B = \\text{logit}(0.65) = \\ln\\left(\\frac{0.65}{0.35}\\right) = \\ln\\left(\\frac{13}{7}\\right)$。该组有$n_B=4$名患者，其中$k_B=3$人复发。观察到的复发频率为$f_B = k_B/n_B = 3/4$。\n\n对于具有分类预测变量的逻辑斯蒂回归，其中每个类别都包含两种结果（$0$和$1$），该模型是饱和的。每组概率的最大似然估计值$\\hat{\\pi}_A$和$\\hat{\\pi}_B$等于观察到的频率。\n$$ \\hat{\\pi}_A = f_A = \\frac{1}{3} $$\n$$ \\hat{\\pi}_B = f_B = \\frac{3}{4} $$\n这些拟合概率必须满足逻辑斯蒂模型方程：\n$$ \\text{logit}(\\hat{\\pi}_A) = \\alpha + \\beta x_A $$\n$$ \\text{logit}(\\hat{\\pi}_B) = \\alpha + \\beta x_B $$\n我们得到一个关于$\\alpha$和$\\beta$的二元线性方程组：\n1. $\\text{logit}(1/3) = \\ln\\left(\\frac{1/3}{2/3}\\right) = \\ln(1/2) = -\\ln(2) = \\alpha + \\beta (-\\ln(4))$\n2. $\\text{logit}(3/4) = \\ln\\left(\\frac{3/4}{1/4}\\right) = \\ln(3) = \\alpha + \\beta \\ln(13/7)$\n\n为了求$\\beta$，我们将第二个方程减去第一个方程：\n$$ \\ln(3) - (-\\ln(2)) = (\\alpha + \\beta \\ln(13/7)) - (\\alpha - \\beta \\ln(4)) $$\n$$ \\ln(3) + \\ln(2) = \\beta (\\ln(13/7) + \\ln(4)) $$\n$$ \\ln(6) = \\beta \\ln\\left(\\frac{13}{7} \\times 4\\right) $$\n$$ \\ln(6) = \\beta \\ln\\left(\\frac{52}{7}\\right) $$\n解出$\\beta$：\n$$ \\beta = \\frac{\\ln(6)}{\\ln(52/7)} $$\n现在我们计算数值：\n$$ \\beta \\approx \\frac{1.791759}{2.005318} \\approx 0.893504 $$\n四舍五入到四位有效数字，校准斜率为$\\beta = 0.8935$。\n\n最后，我们解释这些结果。\n- Brier分数是衡量总体准确性的指标，越低越好。$0.2230$的分数表明存在一定程度的预测误差。作为比较，一个总是预测队列中总体复发率（$\\bar{y} = 5/10 = 0.5$）的朴素模型，其Brier分数为$\\frac{1}{10}[5 \\times (0.5-1)^2 + 5 \\times (0.5-0)^2] = 0.25$。该模型的分数$0.2230$略优于这个朴素基准，表明它具有一定的预测价值，但价值有限。\n\n- 校准斜率评估模型的概率是否经过良好校准。一个完美校准的模型其斜率为$\\beta=1$。\n  - 斜率$\\beta > 1$意味着模型的概率过于保守（信心不足）。\n  - 斜率$\\beta  1$意味着模型的概率过于极端（过度自信）。\n我们计算出的斜率为$\\beta=0.8935$，小于$1$。这表明模型过度自信。其在对数优势尺度上的预测分布范围（$\\Delta_{\\text{pred}} = \\text{logit}(0.65)-\\text{logit}(0.20) = \\ln(52/7) \\approx 2.005$）比在相同尺度上观察结果的分布范围（$\\Delta_{\\text{obs}} = \\text{logit}(3/4)-\\text{logit}(1/3) = \\ln(6) \\approx 1.792$）更宽。这意味着模型高估了两组之间的风险差异。尽管原始概率（$0.20$和$0.65$）相对于观察频率（$1/3 \\approx 0.33$和$3/4 = 0.75$）可能显得保守，但斜率参数$\\beta1$揭示出，在logit尺度上，预测过于极端，需要向其均值“收缩”才能得到更好的校准。\n\n最终数值结果为Brier分数$0.2230$和校准斜率$0.8935$。", "answer": "$$\n\\boxed{\\begin{pmatrix} 0.2230  0.8935 \\end{pmatrix}}\n$$", "id": "4689987"}, {"introduction": "复杂的AI模型常被喻为“黑箱”，这在要求高透明度和可信度的医疗领域构成了巨大挑战。本次编码实践将带你从零开始实现两种核心的可解释性技术——置换特征重要性（Permutation Feature Importance, PFI）和部分依赖图（Partial Dependence Plots, PDP），让你亲手揭示一个梯度提升模型是如何利用临床特征来进行预测的 [@problem_id:4690017]。", "problem": "给定一个精神病学领域的二元分类任务：使用一个已训练的梯度提升集成模型，根据临床特征预测近期的躁狂发作。您的目标是，从基本原理出发，为两个具有临床显著性的特征实现排列特征重要性（PFI）的计算，并为这两个相同的特征实现一维偏依赖图（PDP）的计算。您必须使用二元概率预测、概率的 logistic 链接函数、用经验均值计算期望、用排列作为条件独立性的度量，以及梯度提升模型的加性形式等定义。\n\n背景与基本原理：\n- 梯度提升分类器可以表示为在 logit 标度上的一个加性模型：对于一个特征向量 $\\mathbf{x} \\in \\mathbb{R}^d$，其 logit 为 $F(\\mathbf{x}) = b_0 + \\sum_{m=1}^{M} \\nu \\, T_m(\\mathbf{x})$，其中 $b_0$ 是截距，$\\nu$ 是学习率，$T_m$ 是第 $m$ 棵回归树，它为 $\\mathbf{x}$ 输出一个实数值的叶节点分数。\n- 预测的躁狂概率由 logistic 链接函数给出 $p(\\mathbf{x}) = \\sigma(F(\\mathbf{x})) = \\frac{1}{1 + e^{-F(\\mathbf{x})}}$，该函数将任何实数值的 logit 映射到 $(0,1)$ 区间内的一个值。\n- 对于一个数据集 $\\{(\\mathbf{x}_i, y_i)\\}_{i=1}^N$，其中 $y_i \\in \\{0,1\\}$，经验平均交叉熵（对数损失）为 $\\frac{1}{N}\\sum_{i=1}^N \\left[-y_i \\log p(\\mathbf{x}_i) - (1 - y_i) \\log \\left(1 - p(\\mathbf{x}_i)\\right)\\right]$，它在给定预测概率 $p(\\mathbf{x}_i)$ 的情况下衡量预测性能。\n- 特征 $j$ 的排列特征重要性（PFI）定义为：当特征 $j$ 的值在样本间被随机排列时，损失的期望增量。这个过程会破坏该特征与目标之间的关联，同时保持其边际分布。形式上，令 $\\pi$ 表示对 $\\{1,\\dots,N\\}$ 的一个随机排列，$\\mathbf{x}_i^{(j \\leftarrow x_{\\pi(i),j})}$ 表示将 $\\mathbf{x}_i$ 的第 $j$ 个特征替换为排列后的值 $x_{\\pi(i),j}$，则 PFI 为 $I_j = \\mathbb{E}_\\pi\\left[\\frac{1}{N}\\sum_{i=1}^N \\ell\\left(y_i, p\\left(\\mathbf{x}_i^{(j \\leftarrow x_{\\pi(i),j})}\\right)\\right)\\right] - \\frac{1}{N}\\sum_{i=1}^N \\ell\\left(y_i, p(\\mathbf{x}_i)\\right)$，其中 $\\ell$ 是对数损失。您将通过对重复的独立排列进行平均来经验性地近似这个期望。\n- 特征 $j$ 的一维偏依赖图（PDP）在值 $v$ 处的定义为 $PD_j(v) = \\mathbb{E}_{\\mathbf{X}_{-j}}\\left[p\\left(v, \\mathbf{X}_{-j}\\right)\\right]$，它可以通过数据集上的经验平均来估计：$PD_j(v) \\approx \\frac{1}{N}\\sum_{i=1}^N p\\left(\\mathbf{x}_i^{(j \\leftarrow v)}\\right)$。\n\n模型、特征和数据：\n- 特征顺序固定如下：\n  - 索引 $0$：睡眠时长（单位：小时），记为 $x_0$。\n  - 索引 $1$：用药依从性（[0,1] 范围内的小数），记为 $x_1$。\n  - 索引 $2$：年龄（单位：岁），记为 $x_2$。\n  - 索引 $3$：以往躁狂发作次数，记为 $x_3$。\n  - 索引 $4$：合并症评分（非负整数），记为 $x_4$。\n- 已训练的梯度提升模型参数为：\n  - 截距 $b_0 = -0.3$。\n  - 学习率 $\\nu = 0.25$。\n  - 树的数量 $M = 3$，每棵树由轴对齐分裂和叶节点定义如下（所有分裂形式均为“若 $x_j  \\tau$ 则向左，否则向右”）：\n    - 树 1：\n      - 节点 $0$：在特征 $0$ 上以阈值 $6.5$ 分裂，左子节点为 $1$，右子节点为 $2$。\n      - 节点 $1$：在特征 $1$ 上以阈值 $0.6$ 分裂，左叶节点值为 $+0.8$，右叶节点值为 $+0.3$。\n      - 节点 $2$：在特征 $3$ 上以阈值 $2.5$ 分裂，左叶节点值为 $-0.2$，右叶节点值为 $+0.4$。\n    - 树 2：\n      - 节点 $0$：在特征 $1$ 上以阈值 $0.4$ 分裂，左叶节点值为 $+0.5$，右子节点为 $1$。\n      - 节点 $1$：在特征 $0$ 上以阈值 $7.5$ 分裂，左叶节点值为 $+0.2$，右叶节点值为 $-0.3$。\n    - 树 3：\n      - 节点 $0$：在特征 $4$ 上以阈值 $3.5$ 分裂，左叶节点值为 $-0.1$，右子节点为 $1$。\n      - 节点 $1$：在特征 $0$ 上以阈值 $5.5$ 分裂，左叶节点值为 $+0.6$，右叶节点值为 $+0.0$。\n  - 集成模型在 logit 标度上的输出为 $F(\\mathbf{x}) = b_0 + \\nu \\sum_{m=1}^{3} T_m(\\mathbf{x})$，概率为 $p(\\mathbf{x}) = \\sigma(F(\\mathbf{x}))$。\n- 数据集 $\\{(\\mathbf{x}_i, y_i)\\}_{i=1}^{12}$：\n  - 第 $0$ 行：$(x_0, x_1, x_2, x_3, x_4, y) = (4.5, 0.2, 24, 3, 5, 1)$。\n  - 第 $1$ 行：$(5.0, 0.3, 31, 1, 2, 1)$。\n  - 第 $2$ 行：$(6.0, 0.7, 40, 0, 1, 0)$。\n  - 第 $3$ 行：$(7.0, 0.9, 52, 0, 0, 0)$。\n  - 第 $4$ 行：$(8.0, 0.8, 45, 2, 4, 0)$。\n  - 第 $5$ 行：$(5.5, 0.5, 28, 2, 3, 1)$。\n  - 第 $6$ 行：$(9.0, 0.4, 36, 1, 2, 0)$。\n  - 第 $7$ 行：$(6.5, 0.6, 33, 3, 6, 1)$。\n  - 第 $8$ 行：$(4.0, 0.9, 29, 4, 5, 1)$。\n  - 第 $9$ 行：$(7.5, 0.2, 50, 0, 1, 0)$。\n  - 第 $10$ 行：$(6.0, 0.3, 42, 2, 2, 1)$。\n  - 第 $11$ 行：$(8.5, 1.0, 60, 0, 0, 0)$。\n\n任务：\n1. 精确实现指定的模型 $F(\\mathbf{x})$ 和 $p(\\mathbf{x})$。使用上文定义的经验平均交叉熵（对数损失）。对于处于边界的概率 $p(\\mathbf{x})$，应用数值裁剪以确保它们严格位于 $(0,1)$ 区间内。\n2. 计算数据集上的基线平均对数损失。\n3. 计算以下特征的排列特征重要性（PFI）：\n   - 特征索引 $0$（睡眠时长，单位：小时）。\n   - 特征索引 $1$（用药依从性，小数形式）。\n   对于给定的独立排列重复次数 $R$ 和随机种子 $s$，通过在 $R$ 次独立随机排列（使用指定的种子以保证可复现性）中对平均对数损失进行平均来近似期望，然后减去基线平均对数损失。将 PFI 报告为非负浮点数（如果数值噪声导致一个微小的负值，则按原样保留四舍五入后的值）。\n4. 计算以下特征的一维偏依赖图（PDP）估计值：\n   - 在网格值 $[5.0, 6.5, 8.0]$ 小时上评估的特征索引 $0$。\n   - 在网格值 $[0.2, 0.6, 0.9]$（小数）上评估的特征索引 $1$。\n   对于每个网格值 $v$，通过将该特征替换为 $v$ 来为所有样本构建修改后的输入，为每个样本评估 $p(\\mathbf{x})$，然后在所有样本上取平均值以估计 $PD_j(v)$。\n\n测试套件：\n- 您必须对以下三种情况进行计算，每种情况由一对 $(R, s)$ 定义，其中 $R$ 是排列重复次数，$s$ 是随机种子：\n  - 情况 1：$(R, s) = (1, 11)$。\n  - 情况 2：$(R, s) = (7, 123)$。\n  - 情况 3：$(R, s) = (25, 9871)$。\n- 对于每种情况，生成一个结果列表，包含：\n  - 基线平均对数损失（浮点数）。\n  - 睡眠时长的 PFI（浮点数）。\n  - 用药依从性的 PFI（浮点数）。\n  - 睡眠时长在 $[5.0, 6.5, 8.0]$ 上的 PDP 值（浮点数列表）。\n  - 用药依从性在 $[0.2, 0.6, 0.9]$ 上的 PDP 值（浮点数列表）。\n- 所有浮点数必须四舍五入到 $6$ 位小数。输出中没有物理单位；概率和损失是无量纲的，用药依从性是小数。\n\n最终输出格式：\n- 您的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表，其中每个元素对应上述顺序的一个情况。每个情况本身必须是所描述的五个项目的列表。例如，整体输出必须具有以下形式：\n  \"[[baseline,PFI_sleep,PFI_adherence,[PD_sleep_values],[PD_adherence_values]],[...case2...],[...case3...]]\"\n所有数值都四舍五入到 $6$ 位小数，不含多余的空格或文本。", "solution": "用户要求为一个指定的梯度提升模型实现排列特征重要性（PFI）和偏依赖图（PDP）。这项任务涉及一系列步骤，从模型实现到应用这些可解释性技术，最终为三个不同的测试用例生成格式化的输出。整个过程基于机器学习的基本原理。\n\n首先，我们必须形式化预测模型。梯度提升分类器是一个由 $M=3$ 棵回归树组成的加性集成模型。对于给定的特征向量 $\\mathbf{x} \\in \\mathbb{R}^5$，模型在对数几率（logit）标度上的输出由以下公式给出：\n$$F(\\mathbf{x}) = b_0 + \\nu \\sum_{m=1}^{M} T_m(\\mathbf{x})$$\n其中截距为 $b_0 = -0.3$，学习率为 $\\nu = 0.25$，$T_m(\\mathbf{x})$ 是第 $m$ 棵树的实数值输出。每棵树的决策规则都由轴对齐分裂明确定义，形式为“$x_j  \\tau$”。\n\n各个树函数的实现如下：\n-   $T_1(\\mathbf{x})$:\n    - 如果 $x_0  6.5$：如果 $x_1  0.6$，输出为 $0.8$；否则输出为 $0.3$。\n    - 如果 $x_0 \\geq 6.5$：如果 $x_3  2.5$，输出为 $-0.2$；否则输出为 $0.4$。\n-   $T_2(\\mathbf{x})$:\n    - 如果 $x_1  0.4$：输出为 $0.5$。\n    - 如果 $x_1 \\geq 0.4$：如果 $x_0  7.5$，输出为 $0.2$；否则输出为 $-0.3$。\n-   $T_3(\\mathbf{x})$:\n    - 如果 $x_4  3.5$：输出为 $-0.1$。\n    - 如果 $x_4 \\geq 3.5$：如果 $x_0  5.5$，输出为 $0.6$；否则输出为 $0.0$。\n\n预测的躁狂概率 $p(\\mathbf{x})$ 是通过将 logistic (sigmoid) 函数 $\\sigma(\\cdot)$ 应用于 logit 输出得到的：\n$$p(\\mathbf{x}) = \\sigma(F(\\mathbf{x})) = \\frac{1}{1 + e^{-F(\\mathbf{x})}}$$\n此函数将实数值的 logit $F(\\mathbf{x})$ 映射到区间 $(0, 1)$，代表一个概率。\n\n为了评估模型性能，我们使用二元交叉熵，也称为对数损失。对于单个观测 $(\\mathbf{x}_i, y_i)$，其中 $y_i \\in \\{0, 1\\}$ 是真实标签，损失为：\n$$\\ell(y_i, p(\\mathbf{x}_i)) = -y_i \\log(p(\\mathbf{x}_i)) - (1 - y_i) \\log(1 - p(\\mathbf{x}_i))$$\n为确保当 $p(\\mathbf{x}_i)$ 接近 $0$ 或 $1$ 时的数值稳定性，在传递给对数函数之前，概率值会被裁剪到一个小区间 $[\\epsilon, 1-\\epsilon]$ 内，其中 $\\epsilon  0$ 是一个小数（例如，$10^{-15}$）。模型在数据集 $\\{(\\mathbf{x}_i, y_i)\\}_{i=1}^N$ 上的整体性能是经验平均对数损失，它作为我们的基线损失。\n\n定义了模型和损失函数后，我们可以进行可解释性的计算。\n\n**排列特征重要性（PFI）** 衡量在特征值被随机排列后模型误差的增加量。这个过程打破了特征与目标变量之间的关系。对于特征 $j$，PFI 的计算如下：\n1.  在原始数据集上计算基线损失 $L_{base} = \\frac{1}{N}\\sum_{i=1}^N \\ell(y_i, p(\\mathbf{x}_i))$。\n2.  进行 $R$ 次重复：\n    a.  生成样本索引 $\\{1, \\dots, N\\}$ 的一个随机排列 $\\pi$。\n    b.  创建一个新数据集，其中第 $j$ 个特征列根据 $\\pi$ 进行排列。即，对于每个样本 $i$，新的特征向量是 $\\mathbf{x}_i' = \\mathbf{x}_i^{(j \\leftarrow x_{\\pi(i),j})}$。\n    c.  在这个新数据集上计算平均对数损失 $L_{permuted}$。\n3.  对所有 $R$ 次重复的排列损失取平均，得到 $\\bar{L}_{permuted}$。\n4.  特征 $j$ 的 PFI 是差值：$I_j = \\bar{L}_{permuted} - L_{base}$。\n较高的 PFI 值表明模型更依赖该特征进行预测。随机种子 $s$ 确保排列在不同运行中是可复现的。\n\n**偏依赖图（PDP）** 显示了单个特征对机器学习模型预测结果的边际效应。对于特征 $j$ 和来自感兴趣网格的特定值 $v$，PDP 值的估计方法如下：\n1.  通过将特征 $j$ 的整个列替换为常数值 $v$ 来创建一个修改后的数据集。对于每个原始样本 $\\mathbf{x}_i$，我们构建 $\\mathbf{x}_i' = \\mathbf{x}_i^{(j \\leftarrow v)}$。\n2.  对于每个修改后的样本 $\\mathbf{x}_i'$，计算模型的预测概率 $p(\\mathbf{x}_i')$。\n3.  PDP 值是这些概率在数据集中所有 $N$ 个样本上的平均值：\n$$PD_j(v) \\approx \\frac{1}{N}\\sum_{i=1}^N p\\left(\\mathbf{x}_i^{(j \\leftarrow v)}\\right)$$\n对特征的指定网格中的每个值重复此过程，从而得到一组点，可以绘制这些点以可视化特征的影响。\n\n最终算法首先将数据集和模型参数定义为常量。然后，它遍历三个指定的测试用例 $(R, s)$。在每次迭代中，它计算基线损失，然后计算睡眠时长（$j=0$）和用药依从性（$j=1$）的 PFI，最后计算这两个特征在各自网格上的 PDP 值。所有浮点结果在格式化为最终所需的字符串输出之前，都四舍五入到六位小数。", "answer": "```python\nimport numpy as np\nfrom typing import List, Tuple, Dict, Any\n\ndef solve():\n    \"\"\"\n    Main function to perform all calculations for the problem statement.\n    \"\"\"\n    # Define model, data, and problem parameters\n    b0 = -0.3\n    nu = 0.25\n    \n    data = np.array([\n        [4.5, 0.2, 24, 3, 5, 1],\n        [5.0, 0.3, 31, 1, 2, 1],\n        [6.0, 0.7, 40, 0, 1, 0],\n        [7.0, 0.9, 52, 0, 0, 0],\n        [8.0, 0.8, 45, 2, 4, 0],\n        [5.5, 0.5, 28, 2, 3, 1],\n        [9.0, 0.4, 36, 1, 2, 0],\n        [6.5, 0.6, 33, 3, 6, 1],\n        [4.0, 0.9, 29, 4, 5, 1],\n        [7.5, 0.2, 50, 0, 1, 0],\n        [6.0, 0.3, 42, 2, 2, 1],\n        [8.5, 1.0, 60, 0, 0, 0]\n    ])\n    X = data[:, :-1]\n    y = data[:, -1]\n    N = X.shape[0]\n    epsilon = 1e-15\n\n    pdp_grids = {\n        0: [5.0, 6.5, 8.0],\n        1: [0.2, 0.6, 0.9]\n    }\n\n    test_cases = [\n        (1, 11),\n        (7, 123),\n        (25, 9871)\n    ]\n    \n    # Helper functions for the model and calculations\n    def _T1(x: np.ndarray) - float:\n        if x[0]  6.5:\n            return 0.8 if x[1]  0.6 else 0.3\n        else:\n            return -0.2 if x[3]  2.5 else 0.4\n\n    def _T2(x: np.ndarray) - float:\n        if x[1]  0.4:\n            return 0.5\n        else:\n            return 0.2 if x[0]  7.5 else -0.3\n\n    def _T3(x: np.ndarray) - float:\n        if x[4]  3.5:\n            return -0.1\n        else:\n            return 0.6 if x[0]  5.5 else 0.0\n\n    def get_prediction(x: np.ndarray) - float:\n        tree_sum = _T1(x) + _T2(x) + _T3(x)\n        logit = b0 + nu * tree_sum\n        return 1.0 / (1.0 + np.exp(-logit))\n\n    def get_log_loss(y_true: float, p_pred: float) - float:\n        p_clipped = np.clip(p_pred, epsilon, 1 - epsilon)\n        return -y_true * np.log(p_clipped) - (1 - y_true) * np.log(1 - p_clipped)\n\n    # Main loop for test cases\n    all_results = []\n    for R, s in test_cases:\n        # 1. Calculate baseline loss\n        base_predictions = np.array([get_prediction(row) for row in X])\n        base_losses = np.array([get_log_loss(y[i], base_predictions[i]) for i in range(N)])\n        baseline_loss = np.mean(base_losses)\n        \n        # 2. Calculate PFI for features 0 and 1\n        pfi_results = {}\n        for feature_idx in [0, 1]:\n            rng = np.random.default_rng(seed=s)\n            permuted_losses = []\n            for _ in range(R):\n                X_permuted = X.copy()\n                permuted_indices = rng.permutation(N)\n                X_permuted[:, feature_idx] = X[permuted_indices, feature_idx]\n                \n                perm_predictions = np.array([get_prediction(row) for row in X_permuted])\n                perm_losses = np.array([get_log_loss(y[i], perm_predictions[i]) for i in range(N)])\n                permuted_losses.append(np.mean(perm_losses))\n            \n            mean_permuted_loss = np.mean(permuted_losses)\n            pfi = mean_permuted_loss - baseline_loss\n            pfi_results[feature_idx] = pfi\n\n        # 3. Calculate PDP for features 0 and 1\n        pdp_results = {}\n        for feature_idx in [0, 1]:\n            grid = pdp_grids[feature_idx]\n            pdp_values = []\n            for value in grid:\n                X_modified = X.copy()\n                X_modified[:, feature_idx] = value\n                \n                mod_predictions = np.array([get_prediction(row) for row in X_modified])\n                pdp_values.append(np.mean(mod_predictions))\n            pdp_results[feature_idx] = pdp_values\n\n        # 4. Assemble and round the results for the current case\n        case_result = [\n            round(baseline_loss, 6),\n            round(pfi_results[0], 6),\n            round(pfi_results[1], 6),\n            [round(v, 6) for v in pdp_results[0]],\n            [round(v, 6) for v in pdp_results[1]]\n        ]\n        all_results.append(case_result)\n        \n    # 5. Format the final output string\n    def format_list(lst):\n        return f\"[{','.join(map(str, lst))}]\"\n\n    case_strings = []\n    for case_res in all_results:\n        bl, pfi0, pfi1, pdp0, pdp1 = case_res\n        case_str = f\"[{bl},{pfi0},{pfi1},{format_list(pdp0)},{format_list(pdp1)}]\"\n        case_strings.append(case_str)\n        \n    final_output = f\"[{','.join(case_strings)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "4690017"}]}