{"hands_on_practices": [{"introduction": "我们从一个基本问题开始，直接运用由随机变量生成的$\\sigma$-代数的独立性定义。对于一个随机变量，由它派生出的不同函数（例如它的符号和绝对值）是否相互独立？本练习将揭示，即使在这种简单情况下，独立性也并非理所当然，而是微妙地取决于该变量分布的具体属性，特别是其在原点的概率质量([@problem_id:2980204])。通过这个练习，我们可以加深对事件概率因子分解这一独立性核心要求的理解。", "problem": "设 $X$ 是概率空间 $(\\Omega,\\mathcal{F},\\mathbb{P})$ 上的一个实值随机变量，其分布关于 $0$ 对称，即 $X \\stackrel{d}{=} -X$。定义 $S=\\operatorname{sign}(X)$，约定 $\\operatorname{sign}(0)=0$，以及 $Y=|X|$。回顾定义：两个随机变量 $U$ 和 $V$ 是独立的，如果 $\\sigma(U)$ 和 $\\sigma(V)$ 是独立的 $\\sigma$-代数，这等价于对所有 Borel 集 $A,B\\subset\\mathbb{R}$ 都有 $\\mathbb{P}(U\\in A,V\\in B)=\\mathbb{P}(U\\in A)\\mathbb{P}(V\\in B)$。仅使用这些定义和对称性 $X \\stackrel{d}{=} -X$，确定 $S$ 与 $Y$ 独立（等价于 $\\sigma(S)$ 与 $\\sigma(Y)$ 独立）的充要条件（用在 $0$ 处的质量来表示）。然后将你的准则应用于高斯情况和非高斯对称定律。\n\n以下哪个陈述是正确的？\n\nA. $S$ 和 $Y$ 独立当且仅当 $\\mathbb{P}(X=0)=0$ 或 $\\mathbb{P}(X=0)=1$。特别地，对于任何在 $0$ 处没有原子（离散或连续）的对称定律，$S$ 和 $Y$ 都是独立的；如果 $0  \\mathbb{P}(X=0)  1$，它们则不独立。\n\nB. $S$ 和 $Y$ 的独立性在对称定律中表征了高斯分布：如果 $X$ 是对称的且 $S$ 和 $Y$ 独立，则 $X$ 必须是高斯分布。\n\nC. 如果 $X$ 是对称的且绝对连续，具有偶密度函数 $f$ 并且 $\\mathbb{P}(X=0)=0$，那么 $S$ 和 $Y$ 是独立的，但如果 $X$ 是对称的并且支撑在有限多个非零点上，那么 $S$ 和 $Y$ 永远不会独立。\n\nD. 如果 $X\\sim \\mathcal{N}(0,\\sigma^{2})$ 且 $\\sigma0$，那么 $S$ 和 $Y$ 独立，且 $\\sigma(S)$ 与 $\\sigma(Y)$ 独立。如果 $X$ 是对称伯努利分布，以各 $1/2$ 的概率取值 $\\{-1,+1\\}$，那么 $S$ 和 $Y$ 独立。\n\nE. 如果 $X$ 具有一个在 $0$ 处有原子且在别处有正质量的对称分布，那么重新定义 $\\operatorname{sign}(0)=+1$ 会使 $S$ 和 $Y$ 独立。", "solution": "我们从核心定义开始。随机变量 $U$ 和 $V$ 的独立性意味着对所有 Borel 集 $A,B\\subset\\mathbb{R}$ 都有 $\\mathbb{P}(U\\in A, V\\in B)=\\mathbb{P}(U\\in A)\\mathbb{P}(V\\in B)$，这等价于它们生成的 $\\sigma$-代数 $\\sigma(U)$ 和 $\\sigma(V)$ 的独立性。对称性 $X\\stackrel{d}{=}-X$ 意味着对所有 Borel 集 $B$ 都有 $\\mathbb{P}(X\\in B)=\\mathbb{P}(X\\in -B)$，其中 $-B=\\{-x:x\\in B\\}$。\n\n设 $S=\\operatorname{sign}(X)$，约定 $\\operatorname{sign}(0)=0$，以及 $Y=|X|$。令 $p_{0}=\\mathbb{P}(X=0)=\\mathbb{P}(Y=0)=\\mathbb{P}(S=0)$。\n\n步骤1：通过远离 $0$ 的事件得到一个必要条件。固定任意 Borel 集 $B\\subset(0,\\infty)$（因此 $0\\notin B$）。那么事件 $\\{X\\in B\\}$ 和 $\\{X\\in -B\\}$ 是不相交的，并且根据对称性有 $\\mathbb{P}(X\\in B)=\\mathbb{P}(X\\in -B)$。因此\n$$\n\\mathbb{P}(Y\\in B)=\\mathbb{P}(X\\in B\\cup -B)\n=\\mathbb{P}(X\\in B)+\\mathbb{P}(X\\in -B)=2\\,\\mathbb{P}(X\\in B).\n$$\n此外，\n$$\n\\mathbb{P}(Y\\in B, S=+1)=\\mathbb{P}(|X|\\in B, X0)=\\mathbb{P}(X\\in B),\n$$\n因为对于 $B\\subset(0,\\infty)$，交集 $\\{|X|\\in B, X0\\}$ 正好是 $\\{X\\in B\\}$。如果 $S$ 和 $Y$ 独立，那么对于每个这样的 $B$，\n$$\n\\mathbb{P}(X\\in B)\n=\\mathbb{P}(Y\\in B, S=+1)\n=\\mathbb{P}(Y\\in B)\\,\\mathbb{P}(S=+1).\n$$\n使用 $\\mathbb{P}(Y\\in B)=2\\,\\mathbb{P}(X\\in B)$，我们得到\n$$\n\\mathbb{P}(X\\in B)=2\\,\\mathbb{P}(X\\in B)\\,\\mathbb{P}(S=+1).\n$$\n如果存在一个 $B\\subset(0,\\infty)$ 使得 $\\mathbb{P}(X\\in B)0$，那么我们可以消去 $\\mathbb{P}(X\\in B)$ 得到\n$$\n\\mathbb{P}(S=+1)=\\tfrac{1}{2}.\n$$\n对于对称的 $X$，我们有 $\\mathbb{P}(X0)=\\mathbb{P}(X0)=(1-p_{0})/2$ 并且 $\\mathbb{P}(S=+1)=\\mathbb{P}(X0)=(1-p_{0})/2$。因此条件 $\\mathbb{P}(S=+1)=\\tfrac{1}{2}$ 等价于 $p_{0}=0$。\n\n因此，如果 $S$ 和 $Y$ 独立并且在远离 $0$ 的地方存在任何正质量（即 $\\mathbb{P}(|X|0)0$，等价于 $p_{0}  1$），那么必然有 $p_{0}=0$。\n\n步骤2：所有质量都集中在 $0$ 处的边缘情况。如果 $p_{0}=1$，那么 $X=0$ 几乎必然成立。因此 $S=0$ 几乎必然成立，$Y=0$ 几乎必然成立。在这个退化的情况下，$S$ 和 $Y$ 都是常数，而常数随机变量与任何其他随机变量都是独立的。因此当 $p_{0}=1$ 时独立性成立。\n\n结合步骤1，我们证明了必要性：如果 $S$ 和 $Y$ 独立，则要么 $p_{0}=1$ 要么 $p_{0}=0$。\n\n步骤3：当 $p_{0}=0$ 时的充分性。假设 $p_{0}=0$。对于任何如上所述的 $B\\subset(0,\\infty)$，\n$$\n\\mathbb{P}(Y\\in B, S=+1)=\\mathbb{P}(X\\in B)=\\tfrac{1}{2}\\,\\mathbb{P}(X\\in B\\cup -B)=\\tfrac{1}{2}\\,\\mathbb{P}(Y\\in B),\n$$\n这里我们使用了 $B$ 和 $-B$ 的对称性和不相交性。由于当 $p_{0}=0$ 时 $\\mathbb{P}(S=+1)=\\tfrac{1}{2}$，我们已经证明了对于所有 $B\\subset(0,\\infty)$，$\\mathbb{P}(Y\\in B, S=+1)=\\mathbb{P}(Y\\in B)\\mathbb{P}(S=+1)$。类似的计算可得，对于所有 $B\\subset(0,\\infty)$，$\\mathbb{P}(Y\\in B, S=-1)=\\mathbb{P}(Y\\in B)\\mathbb{P}(S=-1)$。对于包含 $0$ 的集合 $B$，我们使用在 $p_{0}=0$ 的情况下 $\\mathbb{P}(Y=0)=0$ 这一事实，所以加上或去掉 $\\{0\\}$ 不会改变概率。通过单调类论证（或标准的 $\\pi$-$\\lambda$ 论证），这些等式可以推广到所有 Borel 集 $B\\subset[0,\\infty)$，从而证明了 $S$ 和 $Y$ 的独立性。\n\n步骤4：当 $p_{0}=1$ 时的充分性。如前所述，如果 $X=0$ 几乎必然成立，那么 $S=0$ 和 $Y=0$ 也几乎必然成立，所以 $S$ 和 $Y$ 的独立性是显而易见的。\n\n结论：对于对称的 $X$，$S$ 和 $Y$ 独立当且仅当 $p_{0}=0$ 或 $p_{0}=1$。等价地，当且仅当 $0  p_0  1$ 时不独立。", "answer": "$$\\boxed{AD}$$", "id": "2980204"}, {"introduction": "在许多入门课程中，独立随机变量的线性变换通常仍保持独立，但事实并非总是如此。本练习围绕线性变换如何影响独立性这一问题展开，探讨了一个关键特例，它揭示了高斯分布的一个独特性质。通过分析两个独立变量的和与差在何种条件下相互独立([@problem_id:2980206])，我们将发现独立性与联合概率律的几何对称性之间存在着深刻的联系。", "problem": "考虑一个赋滤波的概率空间，该空间支持$2$个独立的标准布朗运动 $\\{W^{(1)}_t\\}_{t \\ge 0}$ 和 $\\{W^{(2)}_t\\}_{t \\ge 0}$，并固定一个确定性时间 $T  0$。通过以下纯扩散动态定义两个标量随机微分方程（SDE）：\n$$\ndX_t = \\sigma_1\\, dW^{(1)}_t,\\quad X_0 = 0,\\qquad dY_t = \\sigma_2\\, dW^{(2)}_t,\\quad Y_0 = 0,\n$$\n其中 $\\sigma_1, \\sigma_2  0$ 是固定常数。设 $X := X_T$ 和 $Y := Y_T$，因此 $X$ 和 $Y$ 是适应于不相交驱动噪声的零均值随机变量。考虑线性组合 $S := X + Y$ 和 $D := X - Y$ 以及它们生成的 $\\sigma$-代数 $\\sigma(X)$、$\\sigma(Y)$、$\\sigma(S)$ 和 $\\sigma(D)$。下列哪个陈述是正确的？\n\nA. 对 $(X,Y)$ 由独立的零均值高斯随机变量组成，但只要 $\\sigma_1 \\neq \\sigma_2$，$S$ 和 $D$ 就是相关的。这种相关性产生的原因是 $(S,D)$ 是通过对 $(X,Y)$ 进行正交混合得到的，而正交变换仅在 $(X,Y)$ 的联合分布是球对称时才保持独立性。\n\nB. 对于任何具有有限方差的独立零均值随机变量 $X$ 和 $Y$，通过正交混合得到 $S = X + Y$ 和 $D = X - Y$ 会保持独立性，因此 $S$ 和 $D$ 总是独立的。\n\nC. 如果 $X$ 和 $Y$ 是独立同分布的零均值拉普拉斯随机变量，具有共同的尺度参数 $b  0$，那么由于拉普拉斯分布的对称性，$S$ 和 $D$ 是独立的。\n\nD. 在从 $(X,Y)$ 到 $(S,D)$ 的任何可逆线性变换下，$\\sigma$-代数 $\\sigma(X)$ 和 $\\sigma(Y)$ 的独立性意味着 $\\sigma(S)$ 和 $\\sigma(D)$ 的独立性。\n\nE. 如果 $(X,Y)$ 是独立的零均值高斯随机变量，且 $\\operatorname{Var}(X) = \\operatorname{Var}(Y)$，那么 $S$ 和 $D$ 是独立的，因为 $(X,Y)$ 的联合分布是球对称的，并且正交变换会保持该结构。", "solution": "必须首先验证问题陈述的科学合理性、自洽性和适定性。\n\n### 步骤 1：提取已知条件\n- 一个赋滤波的概率空间 $(\\Omega, \\mathcal{F}, \\{\\mathcal{F}_t\\}_{t \\ge 0}, \\mathbb{P})$。\n- 两个独立的标准布朗运动 $\\{W^{(1)}_t\\}_{t \\ge 0}$ 和 $\\{W^{(2)}_t\\}_{t \\ge 0}$。\n- 一个固定的确定性时间 $T  0$。\n- 两个随机过程 $X_t$ 和 $Y_t$，由以下随机微分方程（SDE）定义：\n  $$dX_t = \\sigma_1\\, dW^{(1)}_t, \\quad X_0 = 0$$\n  $$dY_t = \\sigma_2\\, dW^{(2)}_t, \\quad Y_0 = 0$$\n  其中 $\\sigma_1  0$ 和 $\\sigma_2  0$ 是固定常数。\n- 两个随机变量 $X$ 和 $Y$ 被定义为过程在时间 $T$ 的值：$X := X_T$ 和 $Y := Y_T$。\n- $X$ 和 $Y$ 的两个线性组合被定义为：$S := X + Y$ 和 $D := X - Y$。\n- 问题涉及这些变量生成的 $\\sigma$-代数之间的关系：$\\sigma(X)$、$\\sigma(Y)$、$\\sigma(S)$ 和 $\\sigma(D)$。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题在随机微积分和概率论的标准数学框架内是良定的。\n1.  **科学基础性**：布朗运动、SDE、随机变量和 $\\sigma$-代数的概念是现代概率论的基础。该问题研究了线性变换对随机变量独立性的影响，这是一个核心且完善的主题。该问题是科学合理的。\n2.  **适定性**：$X_t$ 和 $Y_t$ 的SDE具有由随机积分给出的唯一强解：\n    $$X_t = \\int_0^t \\sigma_1 \\, dW^{(1)}_s = \\sigma_1 W^{(1)}_t$$\n    $$Y_t = \\int_0^t \\sigma_2 \\, dW^{(2)}_s = \\sigma_2 W^{(2)}_t$$\n    在时间 $T$，随机变量为 $X = \\sigma_1 W^{(1)}_T$ 和 $Y = \\sigma_2 W^{(2)}_T$。由于 $W^{(1)}_T$ 和 $W^{(2)}_T$ 是从均值为 $0$、方差为 $T$ 的正态分布中的独立抽样，因此 $X \\sim \\mathcal{N}(0, \\sigma_1^2 T)$ 且 $Y \\sim \\mathcal{N}(0, \\sigma_2^2 T)$。由于驱动布朗运动的独立性，$X$ 和 $Y$ 是独立的随机变量。线性组合 $S$ 和 $D$ 是良定的。它们的独立性问题是概率论中一个标准且可解的问题。\n3.  **客观性**：问题陈述由客观的数学定义和查询组成。它没有歧义和主观性语言。\n4.  **完整性和一致性**：所有必要的参数（$\\sigma_1, \\sigma_2, T$）都已定义，并且它们的性质（正常数）也已指定。没有内部矛盾。\n\n### 步骤 3：结论和行动\n问题陈述是有效的。可以推导出严谨的解答。\n\n### 独立性条件的推导\n\n随机变量 $X$ 和 $Y$ 是独立的，并服从零均值正态分布：$X \\sim \\mathcal{N}(0, \\sigma_1^2 T)$ 和 $Y \\sim \\mathcal{N}(0, \\sigma_2^2 T)$。\n因此，向量 $(X, Y)$ 是一个零均值二元高斯随机向量。\n\n变量 $S$ 和 $D$ 由 $(X, Y)$ 的线性变换定义：\n$$\n\\begin{pmatrix} S \\\\ D \\end{pmatrix} = \\begin{pmatrix} 1  1 \\\\ 1  -1 \\end{pmatrix} \\begin{pmatrix} X \\\\ Y \\end{pmatrix}\n$$\n高斯随机向量的线性变换结果是另一个高斯随机向量。因此，$(S, D)$ 也是一个零均值二元高斯随机向量。\n\n对于联合高斯随机向量，其分量独立的充要条件是它们的协方差为零。我们计算 $S$ 和 $D$ 的协方差：\n$$\n\\operatorname{Cov}(S, D) = E[S \\cdot D] - E[S]E[D]\n$$\n由于 $X$ 和 $Y$ 是零均值的，$E[X] = 0$ 和 $E[Y] = 0$，因此 $E[S] = E[X+Y] = E[X] + E[Y] = 0$ 且 $E[D] = E[X-Y] = E[X] - E[Y] = 0$。\n因此，协方差简化为：\n$$\n\\operatorname{Cov}(S, D) = E[S \\cdot D] = E[(X+Y)(X-Y)] = E[X^2 - Y^2]\n$$\n根据期望的线性性质，这变为：\n$$\n\\operatorname{Cov}(S, D) = E[X^2] - E[Y^2]\n$$\n对于一个零均值随机变量，其二阶矩等于其方差：$E[X^2] = \\operatorname{Var}(X)$ 和 $E[Y^2] = \\operatorname{Var}(Y)$。我们知道 $\\operatorname{Var}(X) = \\sigma_1^2 T$ 和 $\\operatorname{Var}(Y) = \\sigma_2^2 T$。\n将这些代入协方差表达式中：\n$$\n\\operatorname{Cov}(S, D) = \\sigma_1^2 T - \\sigma_2^2 T = T(\\sigma_1^2 - \\sigma_2^2)\n$$\n由于 $T  0$，协方差 $\\operatorname{Cov}(S, D)$ 为零的充要条件是 $\\sigma_1^2 = \\sigma_2^2$。考虑到 $\\sigma_1  0$ 和 $\\sigma_2  0$，这等价于 $\\sigma_1 = \\sigma_2$。\n\n总之，对于问题中定义的特定高斯变量 $X$ 和 $Y$，它们的线性组合 $S = X+Y$ 和 $D = X-Y$ 是独立的，当且仅当 $\\sigma_1 = \\sigma_2$，这等价于 $\\operatorname{Var}(X) = \\operatorname{Var}(Y)$。\n\n### 逐项分析\n\n**A. 对 $(X,Y)$ 由独立的零均值高斯随机变量组成，但只要 $\\sigma_1 \\neq \\sigma_2$，$S$ 和 $D$ 就是相关的。这种相关性产生的原因是 $(S,D)$ 是通过对 $(X,Y)$ 进行正交混合得到的，而正交变换仅在 $(X,Y)$ 的联合分布是球对称时才保持独立性。**\n\n-   最初的论断——$(X,Y)$ 是独立的零均值高斯变量，以及只要 $\\sigma_1 \\neq \\sigma_2$，$S$ 和 $D$ 就是相关的——是正确的，正如我们上面的推导所确立的。\n-   提供的理由也是合理的。变换矩阵 $M = \\begin{pmatrix} 1  1 \\\\ 1  -1 \\end{pmatrix}$ 在一个缩放因子内是正交的，因为 $M^T M = 2I$。\n-   $(X,Y)$ 的联合概率密度是球对称的（径向对称），当且仅当其水平集是圆形。该密度正比于 $\\exp\\left(-\\frac{1}{2T} \\left(\\frac{x^2}{\\sigma_1^2} + \\frac{y^2}{\\sigma_2^2}\\right)\\right)$。水平集是椭圆，除非 $\\sigma_1 = \\sigma_2$，在这种情况下它们是圆形，分布是球对称的。\n-   当 $\\sigma_1 \\neq \\sigma_2$ 时，分布不是球对称的。该陈述正确地指出，对于独立高斯变量的这种正交变换，联合分布中缺少球对称性会导致变换后变量的独立性丧失。这个理由是对高斯情况的正确描述。\n-   结论：**正确**。\n\n**B. 对于任何具有有限方差的独立零均值随机变量 $X$ 和 $Y$，通过正交混合得到 $S = X + Y$ 和 $D = X - Y$ 会保持独立性，因此 $S$ 和 $D$ 总是独立的。**\n\n-   这个陈述是一个极大的过度概括。$S$ 和 $D$ 的独立性至少要求它们是不相关的。如前所示，$\\operatorname{Cov}(S,D) = \\operatorname{Var}(X) - \\operatorname{Var}(Y)$。\n-   如果我们取任意两个独立的、零均值的随机变量 $X$ 和 $Y$，使得 $\\operatorname{Var}(X) \\neq \\operatorname{Var}(Y)$，那么 $\\operatorname{Cov}(S,D) \\neq 0$，这立即意味着 $S$ 和 $D$ 不是独立的。\n-   例如，设 $X \\sim \\mathcal{N}(0,1)$ 和 $Y \\sim \\mathcal{N}(0,4)$，它们是独立的。那么 $\\operatorname{Cov}(S,D) = 1 - 4 = -3 \\neq 0$。$S$ 和 $D$ 是相关的。\n-   因此，该陈述是错误的。事实上，概率论中一个著名的结果（Bernstein-Skitovich-Darmois 定理）指出，如果 $X$ 和 $Y$ 是独立的，并且它们的线性组合 $aX+bY$ 和 $cX+dY$（其中 $abcd \\neq 0$）也是独立的，那么 $X$ 和 $Y$ 必须是高斯分布的。这个选项声称独立性对*任何*分布都成立，这是不正确的。\n-   结论：**不正确**。\n\n**C. 如果 $X$ 和 $Y$ 是独立同分布的零均值拉普拉斯随机变量，具有共同的尺度参数 $b  0$，那么由于拉普拉斯分布的对称性，$S$ 和 $D$ 是独立的。**\n\n-   设 $X, Y \\sim \\text{Laplace}(0,b)$，独立同分布。由于它们是独立同分布的，$\\operatorname{Var}(X) = \\operatorname{Var(Y)} = 2b^2$，这意味着 $\\operatorname{Cov}(S,D) = \\operatorname{Var}(X) - \\operatorname{Var}(Y) = 0$。所以 $S$ 和 $D$ 是不相关的。\n-   然而，对于非高斯变量，不相关并不意味着独立。我们必须检查联合特征函数 $\\phi_{S,D}(t_1, t_2)$。一个 $\\text{Laplace}(0,b)$ 变量的特征函数是 $\\phi(t) = (1+b^2t^2)^{-1}$。\n-   $\\phi_{S,D}(t_1, t_2) = E[e^{i(t_1 S + t_2 D)}] = E[e^{i((t_1+t_2)X + (t_1-t_2)Y)}]$。\n-   由于 $X$ 和 $Y$ 的独立性和同分布性：\n    $\\phi_{S,D}(t_1, t_2) = \\phi(t_1+t_2) \\phi(t_1-t_2) = \\frac{1}{1+b^2(t_1+t_2)^2} \\frac{1}{1+b^2(t_1-t_2)^2}$。\n-   为了使 $S$ 和 $D$ 独立，我们需要 $\\phi_{S,D}(t_1, t_2)$ 能分解为 $\\phi_S(t_1)\\phi_D(t_2)$。\n-   $\\phi_S(t_1) = \\phi_{S,D}(t_1, 0) = \\phi(t_1)\\phi(t_1) = (1+b^2t_1^2)^{-2}$。\n-   $\\phi_D(t_2) = \\phi_{S,D}(0, t_2) = \\phi(t_2)\\phi(-t_2) = (1+b^2t_2^2)^{-2}$。\n-   乘积为 $\\phi_S(t_1)\\phi_D(t_2) = (1+b^2t_1^2)^{-2}(1+b^2t_2^2)^{-2}$。\n-   这显然不等于对所有 $t_1, t_2$ 的 $\\frac{1}{(1+b^2(t_1+t_2)^2)(1+b^2(t_1-t_2)^2)}$。例如，取 $b=1, t_1=1, t_2=1$ 得到联合特征函数的值为 $\\frac{1}{(1+4)(1+0)} = \\frac{1}{5}$，而边际特征函数的乘积为 $\\frac{1}{(1+1)^2(1+1)^2} = \\frac{1}{16}$。\n-   因此，$S$ 和 $D$ 不是独立的。这是一个经典的反正例，表明在此旋转下保持独立性的性质是高斯分布的特征。\n-   结论：**不正确**。\n\n**D. 在从 $(X,Y)$ 到 $(S,D)$ 的任何可逆线性变换下，$\\sigma$-代数 $\\sigma(X)$ 和 $\\sigma(Y)$ 的独立性意味着 $\\sigma(S)$ 和 $\\sigma(D)$ 的独立性。**\n\n-   这是一个非常强且错误的论断。$\\sigma(X)$ 和 $\\sigma(Y)$ 的独立性等价于随机变量 $X$ 和 $Y$ 的独立性。\n-   问题本身的设置就提供了一个反例。如果 $\\sigma_1 \\neq \\sigma_2$，那么 $X$ 和 $Y$ 是独立的，但 $S=X+Y$ 和 $D=X-Y$ 不是。变换矩阵 $M = \\begin{pmatrix} 1  1 \\\\ 1  -1 \\end{pmatrix}$ 是可逆的（其行列式为 $-2$）。这直接驳斥了该陈述。\n-   选项C中的反例（独立同分布的拉普拉斯变量）也证伪了该陈述。\n-   结论：**不正确**。\n\n**E. 如果 $(X,Y)$ 是独立的零均值高斯随机变量，且 $\\operatorname{Var}(X) = \\operatorname{Var}(Y)$，那么 $S$ 和 $D$ 是独立的，因为 $(X,Y)$ 的联合分布是球对称的，并且正交变换会保持该结构。**\n\n-   前提是 $X$ 和 $Y$ 是独立的、零均值的高斯变量，且 $\\operatorname{Var}(X) = \\operatorname{Var}(Y)$。在我们问题的背景下，这对应于 $\\sigma_1 = \\sigma_2$ 的情况。\n-   如初始推导所示，如果 $\\sigma_1 = \\sigma_2$，则 $\\operatorname{Cov}(S,D) = 0$。由于 $(S,D)$ 是一个联合高斯向量，零协方差意味着独立。因此 $S$ 和 $D$ 是独立的结论是正确的。\n-   提供的理由也是正确的。如果 $X, Y$ 是独立同分布的零均值高斯变量，它们的联合密度正比于 $\\exp(-(x^2+y^2)/(2\\sigma^2))$，这是欧几里得范数的平方 $x^2+y^2$ 的函数。这定义了一个球对称分布。从 $(X,Y)$到$(S,D)$ 的变换是一个正交变换（在一个缩放因子内）。将这样的变换应用于一个球对称分布会得到一个新的、也是球对称的分布。对于高斯变量，球对称的联合分布意味着其分量是独立的。\n-   结论：**正确**。", "answer": "$$\\boxed{AE}$$", "id": "2980206"}, {"introduction": "“不相关即独立”是概率论中一个常见的误解，仅在特定条件下（如联合高斯分布）成立。本练习旨在挑战这一观念，提供了一种具体构造不相关但相依的随机变量对的方法。通过引入一个潜在的混合变量，我们将看到如何利用条件独立性来构建精妙的反例([@problem_id:2980208])，从而加深我们对独立性与不相关性之间差异的直观理解。", "problem": "考虑一个支撑标准布朗运动 $B=\\{B_t: t\\geq 0\\}$ 和一个独立离散潜变量 $S$ 的概率空间，$S$ 在集合 $\\{s_1,s_2,s_3\\}$ 中取值，且对每个 $k\\in\\{1,2,3\\}$ 都有 $\\mathbb{P}(S=s_k)=\\frac{1}{3}$。定义确定性函数 $m:\\{s_1,s_2,s_3\\}\\to\\mathbb{R}$ 和 $n:\\{s_1,s_2,s_3\\}\\to\\mathbb{R}$ 如下\n$$\nm(s_1)=1,\\quad m(s_2)=-1,\\quad m(s_3)=0,\\qquad\nn(s_1)=1,\\quad n(s_2)=1,\\quad n(s_3)=-2.\n$$\n令随机变量对 $(X,Y)$ 由下式构造\n$$\nX := B_1 + m(S),\\qquad Y := \\big(B_2 - B_1\\big) + n(S).\n$$\n你可以利用以下事实：$B_1$ 和 $B_2-B_1$ 是独立的、均值为零的高斯随机变量，并且 $S$ 独立于 $B$。使用随机变量独立性和$\\sigma$-代数独立性的定义，以及通过特征函数的刻画，分析这个乘积测度的混合，并确定以下哪些陈述是正确的。\n\nA. 随机变量 $X$ 和 $Y$ 是独立的。\n\nB. 协方差 $\\operatorname{Cov}(X,Y)$ 等于 $0$。\n\nC. 联合特征函数 $\\varphi_{X,Y}(t,u)$ 可对所有 $t,u\\in\\mathbb{R}$ 分解为 $\\varphi_X(t)\\,\\varphi_Y(u)$。\n\nD. 随机变量 $X$ 和 $Y$ 在给定 $S$ 的条件下是条件独立的。\n\nE. $\\sigma$-代数 $\\sigma(X)$ 和 $\\sigma(Y)$ 是独立的。\n\n选择所有正确的选项。", "solution": "问题陈述已经过验证，被认为是合理的。我们可以进行形式化分析。\n\n令 $Z_1 = B_1$ 且 $Z_2 = B_2 - B_1$。根据标准布朗运动的性质，$Z_1$ 和 $Z_2$ 是独立同分布的标准正态随机变量，即 $Z_1, Z_2 \\sim \\mathcal{N}(0,1)$。问题陈述指出离散随机变量 $S$ 独立于布朗运动 $B$，这意味着 $S$ 同时独立于 $Z_1$ 和 $Z_2$。因此，随机变量 $Z_1$、$Z_2$ 和 $S$ 是相互独立的。\n\n随机变量 $X$ 和 $Y$ 定义如下：\n$$\nX = Z_1 + m(S)\n$$\n$$\nY = Z_2 + n(S)\n$$\n其中随机变量 $m(S)$ 和 $n(S)$ 的值由 $S$ 的状态决定，如下所示：\n- 如果 $S=s_1$，$(m(S), n(S)) = (1, 1)$。\n- 如果 $S=s_2$，$(m(S), n(S)) = (-1, 1)$。\n- 如果 $S=s_3$，$(m(S), n(S)) = (0, -2)$。\n每种状态发生的概率为 $\\frac{1}{3}$。\n\n我们现在将评估每个陈述。\n\n**D. 随机变量 $X$ 和 $Y$ 在给定 $S$ 的条件下是条件独立的。**\n\n为了验证在给定 $S$ 的条件下 $X$ 和 $Y$ 的条件独立性，我们必须证明对于 $S$ 的任意值 $s_k$，随机变量对 $(X, Y)$ 的条件分布是其条件边际分布的乘积。\n$$\n\\mathbb{P}(X \\in A, Y \\in B | S=s_k) = \\mathbb{P}(X \\in A | S=s_k) \\mathbb{P}(Y \\in B | S=s_k)\n$$\n对于所有 Borel 集 $A, B \\subseteq \\mathbb{R}$。\n\n让我们以事件 $S=s_k$ 为条件。随机变量 $X$ 和 $Y$ 变为：\n$$\nX|_{S=s_k} = Z_1 + m(s_k)\n$$\n$$\nY|_{S=s_k} = Z_2 + n(s_k)\n$$\n其中对于一个固定的 $s_k$，$m(s_k)$ 和 $n(s_k)$ 是确定性常数。\n随机变量 $Z_1$ 和 $Z_2$ 是独立的。对每个变量加上一个常数的变换不影响它们的独立性。也就是说，对于任意常数 $c_1, c_2$，如果 $Z_1$ 和 $Z_2$ 是独立的，那么 $Z_1+c_1$ 和 $Z_2+c_2$ 也是独立的。\n由于 $Z_1$ 和 $Z_2$ 独立于 $S$，给定 $S=s_k$ 时 $(Z_1, Z_2)$ 的条件分布与其无条件分布相同。因此，在给定 $S=s_k$ 的条件下，$X$ 和 $Y$ 是一对独立随机变量 $Z_1$ 和 $Z_2$ 的函数。因此，对于每个 $k \\in \\{1,2,3\\}$，随机变量 $X|_{S=s_k}$ 和 $Y|_{S=s_k}$ 是独立的。\n这证实了在给定 $S$ 的条件下，$X$ 和 $Y$ 是条件独立的。\n\n结论：**正确**。\n\n**B. 协方差 $\\operatorname{Cov}(X,Y)$ 等于 $0$。**\n\n协方差定义为 $\\operatorname{Cov}(X,Y) = \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y]$。我们将使用全期望定律计算期望值，即 $\\mathbb{E}[V] = \\mathbb{E}[\\mathbb{E}[V|S]]$。\n\n首先，我们计算 $\\mathbb{E}[X]$ 和 $\\mathbb{E}[Y]$。\n给定 $S$ 时 $X$ 的条件期望是：\n$$\n\\mathbb{E}[X|S] = \\mathbb{E}[Z_1 + m(S)|S] = \\mathbb{E}[Z_1|S] + \\mathbb{E}[m(S)|S]\n$$\n由于 $Z_1$ 独立于 $S$，$\\mathbb{E}[Z_1|S] = \\mathbb{E}[Z_1] = 0$。给定 $S$，$m(S)$ 是一个常数，所以 $\\mathbb{E}[m(S)|S] = m(S)$。\n因此，$\\mathbb{E}[X|S] = m(S)$。\n对 $S$ 取期望：\n$$\n\\mathbb{E}[X] = \\mathbb{E}[m(S)] = \\sum_{k=1}^3 m(s_k) \\mathbb{P}(S=s_k) = \\frac{1}{3}(1) + \\frac{1}{3}(-1) + \\frac{1}{3}(0) = 0.\n$$\n对 $Y$ 同理：\n$$\n\\mathbb{E}[Y|S] = \\mathbb{E}[Z_2 + n(S)|S] = \\mathbb{E}[Z_2|S] + n(S) = 0 + n(S) = n(S).\n$$\n$$\n\\mathbb{E}[Y] = \\mathbb{E}[n(S)] = \\sum_{k=1}^3 n(s_k) \\mathbb{P}(S=s_k) = \\frac{1}{3}(1) + \\frac{1}{3}(1) + \\frac{1}{3}(-2) = 0.\n$$\n现在我们计算 $\\mathbb{E}[XY]$。\n$$\n\\mathbb{E}[XY] = \\mathbb{E}[\\mathbb{E}[XY|S]].\n$$\n条件期望是：\n$$\n\\mathbb{E}[XY|S] = \\mathbb{E}[(Z_1+m(S))(Z_2+n(S))|S].\n$$\n如陈述 D 所示，在给定 $S=s_k$ 的条件下，$X$ 和 $Y$ 是独立的。因此，$\\mathbb{E}[XY|S=s_k] = \\mathbb{E}[X|S=s_k]\\mathbb{E}[Y|S=s_k]$。\n我们已经发现 $\\mathbb{E}[X|S] = m(S)$ 且 $\\mathbb{E}[Y|S] = n(S)$。所以，$\\mathbb{E}[XY|S] = m(S)n(S)$。\n对 $S$ 取期望：\n$$\n\\mathbb{E}[XY] = \\mathbb{E}[m(S)n(S)] = \\sum_{k=1}^3 m(s_k)n(s_k)\\mathbb{P}(S=s_k).\n$$\n$$\n\\mathbb{E}[m(S)n(S)] = \\frac{1}{3} [ (1)(1) + (-1)(1) + (0)(-2) ] = \\frac{1}{3} [1 - 1 + 0] = 0.\n$$\n最后，协方差为：\n$$\n\\operatorname{Cov}(X,Y) = \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y] = 0 - (0)(0) = 0.\n$$\n\n结论：**正确**。\n\n**A. 随机变量 $X$ 和 $Y$ 是独立的。**\n**C. 联合特征函数 $\\varphi_{X,Y}(t,u)$ 可对所有 $t,u\\in\\mathbb{R}$ 分解为 $\\varphi_X(t)\\,\\varphi_Y(u)$。**\n**E. $\\sigma$-代数 $\\sigma(X)$ 和 $\\sigma(Y)$ 是独立的。**\n\n这三个陈述是两个随机变量 $X$ 和 $Y$ 独立性的等价刻画。如果一个为真，则所有都为真。如果一个为假，则所有都为假。我们将使用特征函数来检验独立性。如果 $X$ 和 $Y$ 是独立的，它们的联合特征函数必须能分解为其边际特征函数的乘积。\n\n联合特征函数是 $\\varphi_{X,Y}(t,u) = \\mathbb{E}[e^{i(tX+uY)}]$。使用全期望定律：\n$$\n\\varphi_{X,Y}(t,u) = \\mathbb{E}[\\mathbb{E}[e^{i(tX+uY)}|S]].\n$$\n在给定 $S=s_k$ 的条件下，$X$ 和 $Y$ 是独立的。因此，条件特征函数可以分解：\n$$\n\\mathbb{E}[e^{i(tX+uY)}|S=s_k] = \\mathbb{E}[e^{itX}|S=s_k]\\mathbb{E}[e^{iuY}|S=s_k].\n$$\n$\\mathbb{E}[e^{itX}|S=s_k] = \\mathbb{E}[e^{it(Z_1+m(s_k))}] = e^{itm(s_k)}\\mathbb{E}[e^{itZ_1}] = e^{itm(s_k)}e^{-t^2/2}$，因为 $Z_1 \\sim \\mathcal{N}(0,1)$。\n$\\mathbb{E}[e^{iuY}|S=s_k] = \\mathbb{E}[e^{iu(Z_2+n(s_k))}] = e^{iun(s_k)}\\mathbb{E}[e^{iuZ_2}] = e^{iun(s_k)}e^{-u^2/2}$，因为 $Z_2 \\sim \\mathcal{N}(0,1)$。\n所以，$\\mathbb{E}[e^{i(tX+uY)}|S=s_k] = e^{itm(s_k)}e^{-t^2/2} \\cdot e^{iun(s_k)}e^{-u^2/2} = e^{-(t^2+u^2)/2} e^{i(tm(s_k)+un(s_k))}$。\n对 $S$ 取期望：\n$$\n\\varphi_{X,Y}(t,u) = e^{-(t^2+u^2)/2} \\mathbb{E}[e^{i(tm(S)+un(S))}].\n$$\n$$\n\\mathbb{E}[e^{i(tm(S)+un(S))}] = \\frac{1}{3}\\sum_{k=1}^3 e^{i(tm(s_k)+un(s_k))} = \\frac{1}{3}(e^{i(t+u)} + e^{i(-t+u)} + e^{i(-2u)}).\n$$\n$$\n\\varphi_{X,Y}(t,u) = \\frac{1}{3} e^{-(t^2+u^2)/2} (e^{i(t+u)} + e^{i(-t+u)} + e^{-i2u}) = \\frac{1}{3} e^{-(t^2+u^2)/2} (2e^{iu}\\cos(t) + e^{-i2u}).\n$$\n现在我们求边际特征函数：\n$$\n\\varphi_X(t) = \\varphi_{X,Y}(t,0) = \\frac{1}{3} e^{-t^2/2} (e^{it} + e^{-it} + e^0) = \\frac{1}{3} e^{-t^2/2} (2\\cos(t) + 1).\n$$\n$$\n\\varphi_Y(u) = \\varphi_{X,Y}(0,u) = \\frac{1}{3} e^{-u^2/2} (e^{iu} + e^{iu} + e^{-i2u}) = \\frac{1}{3} e^{-u^2/2} (2e^{iu} + e^{-i2u}).\n$$\n为了满足独立性，必须有 $\\varphi_{X,Y}(t,u) = \\varphi_X(t)\\varphi_Y(u)$。\n$$\n\\varphi_X(t)\\varphi_Y(u) = \\left(\\frac{1}{3} e^{-t^2/2} (2\\cos(t) + 1)\\right) \\left(\\frac{1}{3} e^{-u^2/2} (2e^{iu} + e^{-i2u})\\right)\n$$\n$$\n= \\frac{1}{9} e^{-(t^2+u^2)/2} (2\\cos(t) + 1)(2e^{iu} + e^{-i2u}).\n$$\n我们检查 $\\frac{1}{3}(2e^{iu}\\cos(t) + e^{-i2u}) = \\frac{1}{9}(2\\cos(t) + 1)(2e^{iu} + e^{-i2u})$ 是否成立。\n让我们在 $t=\\pi/2$ 时测试这个等式，此时 $\\cos(t)=0$。\n左边 (LHS): $\\frac{1}{3}(e^{-i2u})$。\n右边 (RHS): $\\frac{1}{9}(1)(2e^{iu} + e^{-i2u})$。\n等式 $\\frac{1}{3}e^{-i2u} = \\frac{1}{9}(2e^{iu} + e^{-i2u})$ 显然不适用于所有 $u$。例如，对于 $u=\\pi/2$。左边 (LHS): $1/3 e^{-i\\pi} = -1/3$。右边 (RHS): $1/9(2e^{i\\pi/2} + e^{-i\\pi}) = 1/9(2i-1)$。这两者不相等。\n由于该恒等式不适用于所有 $(t,u)$，联合特征函数不能分解。\n\n对 C 的结论：**不正确**。\n由于特征函数的分解是独立性的一个充分必要条件，分解的失败意味着 $X$ 和 $Y$ 不是独立的。\n对 A 的结论：**不正确**。\n所生成的 $\\sigma$-代数的独立性等价于随机变量的独立性。\n对 E 的结论：**不正确**。\n\n总而言之，$X$ 和 $Y$ 的构造方式使得它们不相关但非独立。这种依赖性是由共同的潜变量 $S$ 引入的，但参数的选择使得协方差为零。", "answer": "$$\\boxed{BD}$$", "id": "2980208"}]}