{"hands_on_practices": [{"introduction": "粒子滤波器的有效性在高维空间中会严重下降，这种现象被称为权重退化。这个练习 [@problem_id:2990102] 提供了一种通过推导重要性权重方差来直接理解此问题的方法。这项分析性实践将揭示方差如何随维度增长，从而让您对粒子滤波最重大的理论挑战之一——“维度灾难”——有更具体的认识。", "problem": "考虑一个 $d$ 维潜状态 $X_t$，它遵循一个具有全局渐近稳定平衡和各向同性平稳协方差的伊藤随机微分方程（Itô SDE），具体来说是一个由 $dX_t = -\\lambda X_t\\,dt + \\sqrt{2\\lambda \\tau^2}\\,dW_t$ 给出的 Ornstein–Uhlenbeck (OU) 模型，其中 $W_t$ 是一个 $d$ 维标准维纳过程且 $\\tau^2 > 0$。在平稳状态下，$X_t$ 的分布为 $X \\sim \\mathcal{N}(0, \\tau^2 I_d)$。在一个序列蒙特卡洛（SMC）自举粒子滤波器（提议分布等于先验分布）中，考虑一个单一滤波步骤，其观测模型为 $Y = H X + V$，$H = I_d$，$V \\sim \\mathcal{N}(0, \\sigma^2 I_d)$ 且与 $X$ 独立，实现的观测值为 $y = 0$。根据贝叶斯法则，目标后验密度与先验预测密度乘以似然贡献成正比，因此目标是一个似然倾斜的先验。对于状态值为 $x$ 的粒子，其非归一化增量重要性权重与似然因子 $\\ell(x) = \\exp\\!\\big(-\\|x\\|^2/(2\\sigma^2)\\big)$ 成正比。\n\n在提议分布 $p(x) = \\mathcal{N}(0, \\tau^2 I_d)$ 下，将归一化重要性权重定义为 $w(x) = \\ell(x)\\big/\\mathbb{E}_p[\\ell(X)]$，因此 $\\mathbb{E}_p[w(X)] = 1$。仅使用第一性原理——贝叶斯法则、高斯积分的性质以及重要性采样的定义——推导方差 $\\mathrm{Var}_p[w(X)]$ 作为维度 $d$ 和参数 $\\tau^2$ 与 $\\sigma^2$ 的函数的闭式表达式。将你的最终答案表示为关于 $d$、$\\tau^2$ 和 $\\sigma^2$ 的单一解析表达式。", "solution": "问题陈述已经过验证，被认为是科学上合理的、适定的和客观的。它提出了贝叶斯滤波中的一个标准情景，并要求使用第一性原理推导出一个可导出的量。所有必要的信息都已提供，没有矛盾或歧义。\n\n目标是计算归一化重要性权重的方差 $\\mathrm{Var}_p[w(X)]$。粒子 $X$ 从中抽取的提议分布是 Ornstein-Uhlenbeck 过程的平稳分布，给定为 $p(x) = \\mathcal{N}(0, \\tau^2 I_d)$。对于向量 $x \\in \\mathbb{R}^d$，其概率密度函数为：\n$$\np(x) = \\frac{1}{(2\\pi \\tau^2)^{d/2}} \\exp\\left(-\\frac{\\|x\\|^2}{2\\tau^2}\\right)\n$$\n非归一化重要性权重由似然因子 $\\ell(x)$ 给出，该因子源于观测模型 $Y = X + V$（其中 $V \\sim \\mathcal{N}(0, \\sigma^2 I_d)$）和实现的观测值 $y=0$。给定观测值 $y=0$ 时状态 $x$ 的似然为：\n$$\np(y=0|x) \\propto \\exp\\left(-\\frac{\\|0-x\\|^2}{2\\sigma^2}\\right) = \\exp\\left(-\\frac{\\|x\\|^2}{2\\sigma^2}\\right)\n$$\n因此，我们将非归一化权重函数确定为 $\\ell(x) = \\exp\\left(-\\frac{\\|x\\|^2}{2\\sigma^2}\\right)$。\n\n问题将归一化重要性权重定义为 $w(x) = \\ell(x) / \\mathbb{E}_p[\\ell(X)]$。根据此定义，在提议分布下，归一化权重的期望为1：\n$$\n\\mathbb{E}_p[w(X)] = \\mathbb{E}_p\\left[\\frac{\\ell(X)}{\\mathbb{E}_p[\\ell(X)]}\\right] = \\frac{1}{\\mathbb{E}_p[\\ell(X)]}\\mathbb{E}_p[\\ell(X)] = 1\n$$\n归一化权重的方差由标准公式给出：\n$$\n\\mathrm{Var}_p[w(X)] = \\mathbb{E}_p[w(X)^2] - (\\mathbb{E}_p[w(X)])^2 = \\mathbb{E}_p[w(X)^2] - 1\n$$\n我们的任务简化为计算二阶矩 $\\mathbb{E}_p[w(X)^2]$。我们用 $\\ell(x)$ 来表示它：\n$$\n\\mathbb{E}_p[w(X)^2] = \\mathbb{E}_p\\left[\\left(\\frac{\\ell(X)}{\\mathbb{E}_p[\\ell(X)]}\\right)^2\\right] = \\frac{\\mathbb{E}_p[\\ell(X)^2]}{(\\mathbb{E}_p[\\ell(X)])^2}\n$$\n我们必须计算两个期望：$\\mathbb{E}_p[\\ell(X)]$ 和 $\\mathbb{E}_p[\\ell(X)^2]$。\n\n首先，我们计算 $\\mathbb{E}_p[\\ell(X)]$，这是权重的归一化常数：\n$$\n\\mathbb{E}_p[\\ell(X)] = \\int_{\\mathbb{R}^d} \\ell(x) p(x) \\,dx = \\int_{\\mathbb{R}^d} \\exp\\left(-\\frac{\\|x\\|^2}{2\\sigma^2}\\right) \\frac{1}{(2\\pi \\tau^2)^{d/2}} \\exp\\left(-\\frac{\\|x\\|^2}{2\\tau^2}\\right) \\,dx\n$$\n合并指数项，我们得到：\n$$\n\\mathbb{E}_p[\\ell(X)] = \\frac{1}{(2\\pi \\tau^2)^{d/2}} \\int_{\\mathbb{R}^d} \\exp\\left(-\\|x\\|^2 \\left(\\frac{1}{2\\sigma^2} + \\frac{1}{2\\tau^2}\\right)\\right) \\,dx\n$$\n让我们简化括号中的项：$\\frac{1}{2\\sigma^2} + \\frac{1}{2\\tau^2} = \\frac{\\tau^2 + \\sigma^2}{2\\sigma^2\\tau^2}$。积分现在是：\n$$\n\\int_{\\mathbb{R}^d} \\exp\\left(-\\frac{1}{2} \\|x\\|^2 \\left(\\frac{\\tau^2 + \\sigma^2}{\\sigma^2\\tau^2}\\right)\\right) \\,dx\n$$\n这是一个均值为零、协方差矩阵为 $(\\frac{\\sigma^2\\tau^2}{\\tau^2+\\sigma^2})I_d$ 的未归一化 $d$ 维高斯密度的积分。这样一个积分 $\\int_{\\mathbb{R}^d}\\exp(-\\frac{1}{2}x^T\\Sigma^{-1}x)dx$ 的值为 $(2\\pi)^{d/2}|\\Sigma|^{1/2}$。这里，$\\Sigma^{-1} = \\frac{\\tau^2+\\sigma^2}{\\sigma^2\\tau^2}I_d$，所以 $|\\Sigma|^{1/2} = \\left(\\left(\\frac{\\sigma^2\\tau^2}{\\tau^2+\\sigma^2}\\right)^d\\right)^{1/2} = \\left(\\frac{\\sigma^2\\tau^2}{\\tau^2+\\sigma^2}\\right)^{d/2}$。\n因此，该积分的值为 $(2\\pi)^{d/2} \\left(\\frac{\\sigma^2\\tau^2}{\\tau^2+\\sigma^2}\\right)^{d/2}$。将此代回 $\\mathbb{E}_p[\\ell(X)]$ 的表达式中：\n$$\n\\mathbb{E}_p[\\ell(X)] = \\frac{1}{(2\\pi \\tau^2)^{d/2}} (2\\pi)^{d/2} \\left(\\frac{\\sigma^2\\tau^2}{\\tau^2+\\sigma^2}\\right)^{d/2} = \\frac{1}{(\\tau^2)^{d/2}} \\left(\\frac{\\sigma^2\\tau^2}{\\tau^2+\\sigma^2}\\right)^{d/2} = \\left(\\frac{\\sigma^2}{\\tau^2+\\sigma^2}\\right)^{d/2}\n$$\n\n接下来，我们计算 $\\mathbb{E}_p[\\ell(X)^2]$。平方似然因子为 $\\ell(x)^2 = \\left(\\exp\\left(-\\frac{\\|x\\|^2}{2\\sigma^2}\\right)\\right)^2 = \\exp\\left(-\\frac{\\|x\\|^2}{\\sigma^2}\\right)$。\n$$\n\\mathbb{E}_p[\\ell(X)^2] = \\int_{\\mathbb{R}^d} \\ell(x)^2 p(x) \\,dx = \\int_{\\mathbb{R}^d} \\exp\\left(-\\frac{\\|x\\|^2}{\\sigma^2}\\right) \\frac{1}{(2\\pi \\tau^2)^{d/2}} \\exp\\left(-\\frac{\\|x\\|^2}{2\\tau^2}\\right) \\,dx\n$$\n再次合并指数项：\n$$\n\\mathbb{E}_p[\\ell(X)^2] = \\frac{1}{(2\\pi \\tau^2)^{d/2}} \\int_{\\mathbb{R}^d} \\exp\\left(-\\|x\\|^2 \\left(\\frac{1}{\\sigma^2} + \\frac{1}{2\\tau^2}\\right)\\right) \\,dx\n$$\n括号中的项为 $\\frac{1}{\\sigma^2} + \\frac{1}{2\\tau^2} = \\frac{2\\tau^2 + \\sigma^2}{2\\sigma^2\\tau^2}$。这个积分对应于一个未归一化高斯密度的积分，其指数项可以写作 $-\\frac{1}{2} x^T \\Sigma^{-1} x$，其中 $\\Sigma^{-1} = \\frac{2\\tau^2+\\sigma^2}{\\sigma^2\\tau^2}I_d$。该积分的值为 $(2\\pi)^{d/2} |\\Sigma|^{1/2} = (2\\pi)^{d/2} \\left(\\frac{\\sigma^2\\tau^2}{2\\tau^2+\\sigma^2}\\right)^{d/2}$。将此结果代入期望的表达式中：\n$$\n\\mathbb{E}_p[\\ell(X)^2] = \\frac{1}{(2\\pi \\tau^2)^{d/2}} (2\\pi)^{d/2} \\left(\\frac{\\sigma^2\\tau^2}{2\\tau^2+\\sigma^2}\\right)^{d/2} = \\left(\\frac{\\sigma^2}{2\\tau^2+\\sigma^2}\\right)^{d/2}\n$$\n\n现在我们可以计算 $\\mathbb{E}_p[w(X)^2]$：\n$$\n\\mathbb{E}_p[w(X)^2] = \\frac{\\mathbb{E}_p[\\ell(X)^2]}{(\\mathbb{E}_p[\\ell(X)])^2} = \\frac{\\left(\\frac{\\sigma^2}{2\\tau^2+\\sigma^2}\\right)^{d/2}}{\\left(\\left(\\frac{\\sigma^2}{\\tau^2+\\sigma^2}\\right)^{d/2}\\right)^2} = \\frac{\\left(\\frac{\\sigma^2}{2\\tau^2+\\sigma^2}\\right)^{d/2}}{\\left(\\frac{\\sigma^2}{\\tau^2+\\sigma^2}\\right)^d}\n$$\n$$\n= \\left(\\frac{\\sigma^2}{2\\tau^2+\\sigma^2}\\right)^{d/2} \\left(\\frac{\\tau^2+\\sigma^2}{\\sigma^2}\\right)^d = \\frac{(\\sigma^2)^{d/2}}{(2\\tau^2+\\sigma^2)^{d/2}} \\frac{(\\tau^2+\\sigma^2)^d}{(\\sigma^2)^d} = \\frac{(\\tau^2+\\sigma^2)^d}{(2\\tau^2+\\sigma^2)^{d/2}(\\sigma^2)^{d/2}}\n$$\n这可以更紧凑地写成，将各项收集在 $d/2$ 次幂下：\n$$\n\\mathbb{E}_p[w(X)^2] = \\frac{\\left((\\tau^2+\\sigma^2)^2\\right)^{d/2}}{\\left(\\sigma^2(2\\tau^2+\\sigma^2)\\right)^{d/2}} = \\left(\\frac{(\\tau^2+\\sigma^2)^2}{\\sigma^2(2\\tau^2+\\sigma^2)}\\right)^{d/2}\n$$\n最后，方差为 $\\mathbb{E}_p[w(X)^2] - 1$：\n$$\n\\mathrm{Var}_p[w(X)] = \\left(\\frac{(\\tau^2+\\sigma^2)^2}{\\sigma^2(2\\tau^2+\\sigma^2)}\\right)^{d/2} - 1\n$$\n此表达式给出了归一化重要性权重的方差，作为模型参数 $d$、$\\tau^2$ 和 $\\sigma^2$ 的函数。可以验证，当 $\\tau^2>0, \\sigma^2>0$ 时，指数的底数大于 $1$：\n$$\n\\frac{(\\tau^2+\\sigma^2)^2}{\\sigma^2(2\\tau^2+\\sigma^2)} = \\frac{\\tau^4 + 2\\tau^2\\sigma^2 + \\sigma^4}{2\\tau^2\\sigma^2 + \\sigma^4} = 1 + \\frac{\\tau^4}{2\\tau^2\\sigma^2 + \\sigma^4} > 1\n$$\n这确保了方差为正，符合要求。", "answer": "$$\n\\boxed{\\left(\\frac{(\\tau^2 + \\sigma^2)^2}{\\sigma^2(2\\tau^2 + \\sigma^2)}\\right)^{d/2} - 1}\n$$", "id": "2990102"}, {"introduction": "在解决了权重退化等理论挑战之后，实际的实现过程又会带来新的障碍。本练习 [@problem_id:2990126] 聚焦于一个关键问题：数值不稳定性。您将实现“log-sum-exp”技巧，这是一种防止权重计算中发生下溢（underflow）导致结果为零的重要技术，从而确保您构建的滤波器在实践中是稳健和可靠的。", "problem": "考虑一个通过随机微分方程的欧拉-丸山（Euler–Maruyama）离散化得到的离散时间非线性隐马尔可夫模型。设隐藏状态为 $x_k \\in \\mathbb{R}^n$，其演化遵循\n$$\nx_k = x_{k-1} + f(x_{k-1})\\,\\Delta t + G(x_{k-1})\\,\\sqrt{\\Delta t}\\,\\eta_k,\n$$\n其中 $f(\\cdot)$ 是一个漂移项，$G(\\cdot)$ 是一个扩散项，$\\Delta t$ 是时间步长，$\\eta_k$ 是一个标准高斯随机向量。观测值由下式给出\n$$\ny_k = h(x_k) + v_k,\n$$\n其中 $h(\\cdot)$ 是一个非线性传感器模型，$v_k$ 是一个高斯噪声向量。\n\n在该系统的粒子滤波器中，假设我们有 $N$ 个粒子 $\\{x_k^{(i)}\\}_{i=1}^N$ 及其先前的归一化权重 $\\{w_{k-1}^{(i)}\\}_{i=1}^N$，满足 $\\sum_{i=1}^N w_{k-1}^{(i)} = 1$。时刻 $k$ 的测量更新基于贝叶斯法则和重要性采样原理：未归一化的新权重与先前权重和似然的乘积成正比，\n$$\n\\tilde{w}_k^{(i)} \\propto w_{k-1}^{(i)}\\,p(y_k \\mid x_k^{(i)}),\n$$\n然后归一化权重为\n$$\nw_k^{(i)} = \\frac{\\tilde{w}_k^{(i)}}{\\sum_{j=1}^N \\tilde{w}_k^{(j)}}.\n$$\n\n当似然 $p(y_k \\mid x_k^{(i)})$ 非常小（例如由于严重失配或测量噪声协方差很小）时，在浮点运算中直接计算 $\\tilde{w}_k^{(i)}$ 可能会下溢为零。一个鲁棒的计算策略是在对数域中操作。定义对数权重\n$$\n\\ell_{k-1}^{(i)} = \\log w_{k-1}^{(i)}, \\quad \\lambda_k^{(i)} = \\log p(y_k \\mid x_k^{(i)}),\n$$\n以及更新后的对数权重\n$$\n\\ell_k^{(i)} = \\ell_{k-1}^{(i)} + \\lambda_k^{(i)}.\n$$\n然后，可以使用一种数值安全的方法稳定地恢复归一化的 $w_k^{(i)}$，即使当 $\\lambda_k^{(i)}$ 是极负数时，该方法也能避免灾难性的下溢。\n\n你的任务是，在上述基础上，且不假设任何快捷公式，推导出一个基于对数权重的数值稳定的 $\\{w_k^{(i)}\\}_{i=1}^N$ 归一化过程，该过程在某些 $\\lambda_k^{(i)}$ 非常小或为 $-\\infty$（表示零似然）时仍保持鲁棒。用一个完整的程序实现此过程，对于下面提供的每个测试用例，该程序接收先前权重的数组和对数似然增量，计算更新后的对数权重，并以数值稳定的方式对其进行归一化。如果所有更新后的对数权重均为 $-\\infty$（即在当前观测下所有粒子都具有零似然），你必须返回均匀权重 $w_k^{(i)} = 1/N$ 作为回退方案，以避免退化。\n\n设计你的程序来处理以下测试套件。对于每种情况，输入包括先前的归一化权重 $\\{w_{k-1}^{(i)}\\}$ 和对数似然增量 $\\{\\lambda_k^{(i)}\\}$，输出是归一化权重 $\\{w_k^{(i)}\\}$ 的列表，四舍五入到十二位小数：\n\n- 测试用例 1（常见极端缩放下的理想情况）：$N=5$。先前权重 $[0.2,\\,0.3,\\,0.1,\\,0.25,\\,0.15]$。对数似然增量 $[-1000.0,\\,-1000.0,\\,-1000.0,\\,-1000.0,\\,-1000.0]$。\n- 测试用例 2（混合极端值与不可能粒子）：$N=5$。先前权重 $[0.2,\\,0.2,\\,0.2,\\,0.2,\\,0.2]$。对数似然增量 $[-1000.0,\\,-2000.0,\\,-\\infty,\\,-1200.0,\\,-1100.0]$。\n- 测试用例 3（严重失配下的单一主导支撑）：$N=5$。先前权重 $[0.05,\\,0.05,\\,0.8,\\,0.05,\\,0.05]$。对数似然增量 $[-1000.0,\\,-1000.0,\\,0.0,\\,-1000.0,\\,-1000.0]$。\n- 测试用例 4（全部不可能，回退到均匀分布）：$N=4$。先前权重 $[0.1,\\,0.2,\\,0.3,\\,0.4]$。对数似然增量 $[-\\infty,\\,-\\infty,\\,-\\infty,\\,-\\infty]$。\n\n你的程序应该产生单行输出，其中包含一个由方括号括起来的逗号分隔列表形式的结果。这个顶层列表的每个元素都必须是相应测试用例的归一化权重列表，四舍五入到十二位小数。例如，你的输出行必须看起来像\n$[ [\\cdots], [\\cdots], [\\cdots], [\\cdots] ]$\n且不包含额外文本。角度和物理单位不适用于此问题，唯一的输出是四舍五入到十二位小数的浮点数列表。确保你的实现在所提供的边缘情况下是数值稳定和鲁棒的。", "solution": "该问题要求推导并实现一个数值稳定的程序，用于在粒子滤波器中对粒子权重进行归一化，特别是在对数域中操作以减轻浮点下溢问题。\n\n出发点是粒子权重的标准重要性采样更新规则。给定一组具有先前归一化权重 $\\{w_{k-1}^{(i)}\\}_{i=1}^N$ 的 $N$ 个粒子，使得 $\\sum_{i=1}^N w_{k-1}^{(i)} = 1$，在时间步 $k$ 的未归一化更新权重 $\\tilde{w}_k^{(i)}$ 由先验权重与给定粒子状态 $x_k^{(i)}$ 下新观测值 $y_k$ 的似然的乘积给出：\n$$\n\\tilde{w}_k^{(i)} = w_{k-1}^{(i)} \\, p(y_k \\mid x_k^{(i)})\n$$\n然后通过归一化得到新的权重 $w_k^{(i)}$：\n$$\nw_k^{(i)} = \\frac{\\tilde{w}_k^{(i)}}{\\sum_{j=1}^N \\tilde{w}_k^{(j)}}\n$$\n直接计算此表达式容易出现数值下溢。如果似然值 $p(y_k \\mid x_k^{(i)})$ 极小，则在有限精度算术中，乘积 $\\tilde{w}_k^{(i)}$ 对于所有 $i$ 都可能计算为零，导致除以零。\n\n为了规避这个问题，我们在对数域中进行操作。设 $\\ell_{k-1}^{(i)} = \\log w_{k-1}^{(i)}$ 为先前的对数权重，$\\lambda_k^{(i)} = \\log p(y_k \\mid x_k^{(i)})$ 为对数似然。未归一化的更新对数权重 $\\ell_k^{(i)}$ 为：\n$$\n\\ell_k^{(i)} = \\log(\\tilde{w}_k^{(i)}) = \\log(w_{k-1}^{(i)}) + \\log(p(y_k \\mid x_k^{(i)})) = \\ell_{k-1}^{(i)} + \\lambda_k^{(i)}\n$$\n由此，归一化权重 $w_k^{(i)}$ 可以表示为：\n$$\nw_k^{(i)} = \\frac{\\exp(\\ell_k^{(i)})}{\\sum_{j=1}^N \\exp(\\ell_k^{(j)})}\n$$\n这种形式仍然存在相同的下溢问题，因为 $\\ell_k^{(i)}$ 可以是很大的负数（例如 -1000），导致 $\\exp(\\ell_k^{(i)})$ 计算为零。\n\n稳定计算的关键是“log-sum-exp”技巧。设 $L_{max}$ 是所有未归一化更新对数权重中的最大值：\n$$\nL_{max} = \\max_{j \\in \\{1, \\dots, N\\}} \\{\\ell_k^{(j)}\\}\n$$\n我们可以在 $w_k^{(i)}$ 表达式的分子和分母上乘以相同的非零因子 $\\exp(-L_{max})$，而不改变其值：\n$$\nw_k^{(i)} = \\frac{\\exp(\\ell_k^{(i)}) \\cdot \\exp(-L_{max})}{\\left(\\sum_{j=1}^N \\exp(\\ell_k^{(j)})\\right) \\cdot \\exp(-L_{max})}\n$$\n利用属性 $\\exp(a)\\exp(b) = \\exp(a+b)$ 并将因子分配到和式中，我们得到：\n$$\nw_k^{(i)} = \\frac{\\exp(\\ell_k^{(i)} - L_{max})}{\\sum_{j=1}^N \\exp(\\ell_k^{(j)} - L_{max})}\n$$\n该表达式是数值稳定的。让我们分析它的组成部分：\n1. 对于和式中的任何项，指数 $(\\ell_k^{(j)} - L_{max})$ 始终小于或等于 0，因为 $L_{max}$ 是集合 $\\{\\ell_k^{(j)}\\}$ 中的最大值。这可以防止 $\\exp(\\cdot)$ 的参数成为大的正数，从而避免上溢。\n2. 至少存在一个粒子，比如说索引为 $m$ 的粒子，其 $\\ell_k^{(m)} = L_{max}$。对于这个粒子，和式中的项为 $\\exp(\\ell_k^{(m)} - L_{max}) = \\exp(0) = 1$。\n3. 因此，分母 $S = \\sum_{j=1}^N \\exp(\\ell_k^{(j)} - L_{max})$ 保证大于或等于 1。这可以防止和式下溢为零，而这正是主要的数值不稳定性来源。\n4. 如果 $\\ell_k^{(i)}$ 远小于 $L_{max}$，项 $\\exp(\\ell_k^{(i)} - L_{max})$ 仍可能下溢为零。然而，这是一个正确且期望的结果，因为它反映了与最可能的粒子相比，粒子 $i$ 的权重可以忽略不计。\n\n当所有粒子都具有零似然时，会出现一个特殊情况，这对应于所有对数似然 $\\lambda_k^{(i)}$ 均为 $-\\infty$ 或导致所有 $\\ell_k^{(i)}$ 均为 $-\\infty$ 的组合。在这种情况下，$L_{max} = -\\infty$。直接应用该公式是未定义的。问题指定了一个鲁棒的回退机制：如果所有更新的对数权重均为 $-\\infty$，则通过分配均匀权重 $w_k^{(i)} = 1/N$ (对于所有 $i$) 来重置滤波器。这可以防止滤波器退化。\n\n完整的数值稳定算法如下：\n1. 对于每个粒子 $i \\in \\{1, \\dots, N\\}$，计算未归一化的对数权重：$\\ell_k^{(i)} = \\log(w_{k-1}^{(i)}) + \\lambda_k^{(i)}$。注意，如果 $w_{k-1}^{(i)}=0$，则 $\\ell_{k-1}^{(i)}=-\\infty$，因此 $\\ell_k^{(i)}=-\\infty$。\n2. 找到最大对数权重：$L_{max} = \\max_{i} \\{\\ell_k^{(i)}\\}$。\n3. 检查退化情况：如果 $L_{max} = -\\infty$，则对所有 $i=1, \\dots, N$ 设置 $w_k^{(i)} = 1/N$ 并终止。\n4. 如果 $L_{max}$ 是有限的，计算移位的对数权重：$\\ell'^{(i)}_k = \\ell_k^{(i)} - L_{max}$。\n5. 计算稳定的未归一化权重：$w'^{(i)}_k = \\exp(\\ell'^{(i)}_k)$。\n6. 计算它们的和：$S = \\sum_{j=1}^N w'^{(j)}_k$。\n7. 计算最终的归一化权重：$w_k^{(i)} = \\frac{w'^{(i)}_k}{S}$。\n这个过程即使在对数似然值为极端的情况下，也能确保权重归一化的鲁棒性和准确性。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the particle filter weight normalization problem for a suite of test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test Case 1: happy path with common extreme scaling\n        (np.array([0.2, 0.3, 0.1, 0.25, 0.15]), np.array([-1000.0, -1000.0, -1000.0, -1000.0, -1000.0])),\n        # Test Case 2: mixed extremes and impossible particle\n        (np.array([0.2, 0.2, 0.2, 0.2, 0.2]), np.array([-1000.0, -2000.0, -np.inf, -1200.0, -1100.0])),\n        # Test Case 3: single dominant support amid severe mismatch\n        (np.array([0.05, 0.05, 0.8, 0.05, 0.05]), np.array([-1000.0, -1000.0, 0.0, -1000.0, -1000.0])),\n        # Test Case 4: all impossible, fallback to uniform\n        (np.array([0.1, 0.2, 0.3, 0.4]), np.array([-np.inf, -np.inf, -np.inf, -np.inf]))\n    ]\n    \n    results = []\n\n    for prev_weights, log_likelihoods in test_cases:\n        # Step 1: Compute previous log-weights and updated unnormalized log-weights.\n        # np.log handles arrays and np.log(0) correctly returns -inf.\n        # Since all given prev_weights are > 0, we don't encounter np.log(0).\n        log_prev_weights = np.log(prev_weights)\n        \n        # This is l_k^{(i)} in the problem description.\n        updated_log_weights = log_prev_weights + log_likelihoods\n        \n        # Step 2: Find the maximum log-weight.\n        max_log_weight = np.max(updated_log_weights)\n        \n        # Step 3: Handle the degenerate case where all particles have zero likelihood.\n        if max_log_weight == -np.inf:\n            num_particles = len(prev_weights)\n            normalized_weights = np.full(num_particles, 1.0 / num_particles)\n        else:\n            # Step 4: Compute shifted log-weights.\n            # This is l_k^{(i)} - L_max.\n            shifted_log_weights = updated_log_weights - max_log_weight\n            \n            # Step 5  6: Exponentiate and compute the sum.\n            # This is exp(l_k^{(i)} - L_max).\n            exp_weights = np.exp(shifted_log_weights)\n            sum_exp_weights = np.sum(exp_weights)\n            \n            # Step 7: Compute the final normalized weights.\n            normalized_weights = exp_weights / sum_exp_weights\n            \n        # Round the final weights to 12 decimal places as required.\n        rounded_weights = np.round(normalized_weights, 12).tolist()\n        results.append(rounded_weights)\n\n    # Format the final output string as specified.\n    # The problem specifies that the output for each test case is a list.\n    # The overall output is a list of these lists.\n    # A simple map to str over `results` would create strings of lists.\n    # We must format it carefully.\n    result_strings = [str(r) for r in results]\n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n```", "id": "2990126"}, {"introduction": "既然我们已经了解如何构建一个稳健的滤波器，接下来就必须考虑其效率。本练习 [@problem_id:2990065] 将指导您分析粒子滤波器的计算复杂度。通过将算法分解为传播、加权和重采样这几个核心部分，您将能够识别出性能瓶颈，这对于为复杂的高维系统设计高效的滤波器来说是一项至关重要的技能。", "problem": "考虑一个状态维数为 $d$ 的非线性连续时间随机动力学系统，由一个随机微分方程（SDE）控制\n$$\n\\mathrm{d}X_{t} \\;=\\; f(X_{t})\\,\\mathrm{d}t \\;+\\; G(X_{t})\\,\\mathrm{d}W_{t},\n$$\n其中 $X_{t}\\in\\mathbb{R}^{d}$ 是状态， $f:\\mathbb{R}^{d}\\to\\mathbb{R}^{d}$ 是一个漂移场， $G:\\mathbb{R}^{d}\\to\\mathbb{R}^{d\\times d}$ 是一个对于典型状态是稠密的扩散场， $W_{t}$ 是一个标准的 $d$ 维维纳过程。在时间点 $\\{t_{k}\\}$ 的离散时间观测由下式给出\n$$\nY_{k} \\;=\\; h(X_{t_{k}}) \\;+\\; V_{k},\n$$\n其中 $h:\\mathbb{R}^{d}\\to\\mathbb{R}^{d}$ 是一个非线性测量函数， $V_{k}\\sim \\mathcal{N}(0,S)$ 是高斯测量噪声，其协方差 $S\\in\\mathbb{R}^{d\\times d}$ 是时不变且稠密的。假设 $S$ 是非奇异的，并且其逆或 Cholesky 分解被预先计算一次并重复使用。\n\n使用一个带有 $N$ 个粒子的序贯蒙特卡罗（SMC）粒子滤波器来近似滤波分布。在每个时间步长 $t_{k}\\to t_{k+1}$，滤波器执行三个阶段：\n\n（1）传播：每个粒子 $X^{(i)}_{t_{k}}$ 使用步长为 $\\Delta t$ 的 Euler–Maruyama 方法推进到 $X^{(i)}_{t_{k+1}}$，即\n$$\nX^{(i)}_{t_{k+1}} \\;=\\; X^{(i)}_{t_{k}} \\;+\\; f\\!\\big(X^{(i)}_{t_{k}}\\big)\\,\\Delta t \\;+\\; G\\!\\big(X^{(i)}_{t_{k}}\\big)\\,\\Delta W^{(i)}_{k},\n$$\n其中 $\\Delta W^{(i)}_{k}\\sim \\mathcal{N}(0,\\Delta t\\,I_{d})$ 对每个粒子是独立的。假设评估 $f$ 需要每个粒子 $\\Theta(d)$ 次算术运算， $G(X)$ 是稠密的，因此形成 $G(X)\\in\\mathbb{R}^{d\\times d}$ 并将其乘以 $\\Delta W\\in\\mathbb{R}^{d}$ 需要每个粒子 $\\Theta(d^{2})$ 次算术运算。\n\n（2）权重计算：对于每个粒子状态 $x^{(i)}$，计算残差 $r^{(i)}=y_{k+1}-h(x^{(i)})$（假设对 $h$ 需要 $\\Theta(d)$ 次运算），并通过二次型 $Q^{(i)}=(r^{(i)})^{\\top}S^{-1}r^{(i)}$ 评估高斯似然（至多相差一个归一化常数），或者等价地，使用预计算的 Cholesky 分解 $S=LL^{\\top}$，通过求解 $Lz=r^{(i)}$，然后计算 $Q^{(i)}=\\|z\\|^{2}$。对于稠密的 $L\\in\\mathbb{R}^{d\\times d}$，三角求解每个粒子需要 $\\Theta(d^{2})$ 次运算，计算 $\\|z\\|^{2}$ 需要 $\\Theta(d)$ 次运算。\n\n（3）重采样：执行系统重采样，从加权集合中抽取 $N$ 个新粒子。计算归一化权重、它们的累积和以及生成重采样索引，假设每个时间步的成本为 $\\Theta(N)$。\n\n从上述关于 SDE 离散化、高斯似然评估和系统重采样的第一性原理描述出发，推导整个粒子滤波器每个时间步的主要渐近计算复杂度，表示为关于 $N$ 和 $d$ 的单个表达式，忽略所有常数因子和低阶项。你的推导必须清楚地说明在所述假设下，哪个（些）阶段构成了计算瓶颈。以大O表示法的闭式渐近表达式形式提供最终答案。不需要数值近似或舍入。", "solution": "该问题要求推导应用于状态维数为 $d$ 的系统的、具有 $N$ 个粒子的序贯蒙特卡罗（SMC）粒子滤波器每个时间步的主要渐近计算复杂度。总复杂度是其三个组成阶段的复杂度之和：传播、权重计算和重采样。我们将依次分析每个阶段。\n\n设 $N$ 为粒子数， $d$ 为状态空间 $\\mathbb{R}^{d}$ 的维数。\n\n1.  **传播阶段：**\n    该阶段将 $N$ 个粒子中的每一个从时间 $t_{k}$ 推进到 $t_{k+1}$。此阶段的成本是每个粒子的成本乘以粒子数 $N$。对于单个粒子 $X^{(i)}_{t_{k}}$，更新规则为：\n    $$\n    X^{(i)}_{t_{k+1}} \\;=\\; X^{(i)}_{t_{k}} \\;+\\; f\\!\\big(X^{(i)}_{t_{k}}\\big)\\,\\Delta t \\;+\\; G\\!\\big(X^{(i)}_{t_{k}}\\big)\\,\\Delta W^{(i)}_{k}\n    $$\n    一个粒子的计算成本是评估右侧各项并执行向量加法所需的成本之和。\n    -   评估漂移项 $f(X^{(i)}_{t_{k}})$ 被指出需要 $\\Theta(d)$ 次运算。随后的与 $\\Delta t$ 的标量-向量乘法也需要 $\\Theta(d)$ 次运算。\n    -   评估扩散项涉及形成稠密的 $d \\times d$ 矩阵 $G(X^{(i)}_{t_{k}})$ 并将其乘以 $d \\times 1$ 向量 $\\Delta W^{(i)}_{k}$。一个稠密矩阵-向量乘积需要 $\\Theta(d^{2})$ 次算术运算。从 $\\mathcal{N}(0, \\Delta t\\,I_{d})$ 生成随机向量 $\\Delta W^{(i)}_{k}$ 涉及抽取 $d$ 个独立的高斯样本，成本为 $\\Theta(d)$。\n    -   两次向量加法每次成本为 $\\Theta(d)$。\n    传播步骤中每个粒子的总成本是这些单个成本的总和：$\\Theta(d) + \\Theta(d) + (\\Theta(d^{2}) + \\Theta(d)) + \\Theta(d) + \\Theta(d)$。此总和中的主导项是 $\\Theta(d^{2})$，源于稠密矩阵-向量乘法 $G \\Delta W$。\n    因此，传播一个粒子的复杂度是 $\\Theta(d^{2})$。\n    对于所有 $N$ 个粒子，传播阶段的总复杂度为：\n    $$\n    C_{\\text{prop}} = N \\times \\Theta(d^{2}) = \\Theta(Nd^{2})\n    $$\n\n2.  **权重计算阶段：**\n    该阶段为 $N$ 个传播后的粒子中的每一个计算一个重要性权重。成本同样是每个粒子的成本乘以 $N$。对于单个粒子 $x^{(i)} = X^{(i)}_{t_{k+1}}$ 和观测值 $y_{k+1}$，未归一化的权重与给定粒子状态下观测值的似然成正比。这涉及计算二次型 $Q^{(i)}=(r^{(i)})^{\\top}S^{-1}r^{(i)}$，其中 $r^{(i)}=y_{k+1}-h(x^{(i)})$。\n    -   评估测量函数 $h(x^{(i)})$ 被指出成本为 $\\Theta(d)$。\n    -   通过向量减法计算残差向量 $r^{(i)}$ 的额外成本为 $\\Theta(d)$。\n    -   二次型 $Q^{(i)}$ 的计算是使用预计算的 Cholesky 分解 $S = LL^{\\top}$ 来执行的。这包括两个步骤：首先，使用前向替换求解下三角系统 $Lz = r^{(i)}$ 以得到 $z$；其次，计算平方范数 $Q^{(i)} = z^{\\top}z = \\|z\\|^{2}$。对于一个稠密的 $d \\times d$ 矩阵 $L$，前向替换的成本为 $\\Theta(d^{2})$ 次运算。随后计算 $d$ 维向量 $z$ 的平方范数的成本为 $\\Theta(d)$。似然的评估，例如 $\\exp(-Q^{(i)}/2)$，是一个成本为 $\\Theta(1)$ 的标量运算。\n    权重计算中每个粒子的总成本是这些成本的总和：$(\\Theta(d) + \\Theta(d)) + (\\Theta(d^{2}) + \\Theta(d)) + \\Theta(1)$。这里的主导项是 $\\Theta(d^{2})$，它来自于求解三角线性系统。\n    因此，为一个粒子加权的复杂度是 $\\Theta(d^{2})$。\n    对于所有 $N$ 个粒子，权重计算阶段的总复杂度为：\n    $$\n    C_{\\text{weight}} = N \\times \\Theta(d^{2}) = \\Theta(Nd^{2})\n    $$\n\n3.  **重采样阶段：**\n    该阶段从当前的加权集合中抽取一组新的 $N$ 个粒子，以对抗退化问题。问题陈述，系统重采样，包括计算归一化权重、它们的累积和以及抽取新索引，其总计算成本为 $\\Theta(N)$。值得注意的是，这个成本与状态维数 $d$ 无关。\n    $$\n    C_{\\text{resample}} = \\Theta(N)\n    $$\n\n**总复杂度和瓶颈**\n每个时间步的总计算复杂度 $C_{\\text{total}}$ 是三个阶段复杂度之和：\n$$\nC_{\\text{total}} = C_{\\text{prop}} + C_{\\text{weight}} + C_{\\text{resample}} = \\Theta(Nd^{2}) + \\Theta(Nd^{2}) + \\Theta(N)\n$$\n为了找到主要渐近复杂度，我们确定当 $N$ 和 $d$ 变大时增长最快的项。由于 $d \\ge 1$，项 $Nd^{2}$ 优于 $N$。\n$$\nC_{\\text{total}} = \\Theta(Nd^{2})\n$$\n计算瓶颈是那些复杂度与此主要项相匹配的阶段。在此分析中，**传播**阶段和**权重计算**阶段的复杂度均为 $\\Theta(Nd^{2})$。它们的成本与状态维数 $d$ 呈二次方关系，这源于涉及稠密矩阵 $G$ 和 $S$（或其 Cholesky 因子 $L$）的线性代数运算。重采样阶段的复杂度为 $\\Theta(N)$，在 $d>1$ 时不是瓶颈。因此，对于此粒子滤波器配置，传播和加权都是主要的计算负担。\n\n最终答案，按要求以大O表示法表示，是从该分析中推导出的主要项。", "answer": "$$\n\\boxed{O(Nd^{2})}\n$$", "id": "2990065"}]}