{"hands_on_practices": [{"introduction": "理论是骨架，实践是血肉。要真正掌握随机变量期望的核心思想，最好的方法莫过于通过解决实际问题来加深理解。本章精选了一系列动手实践题，旨在引导你将抽象的数学定义应用于具体情境，从而锻炼你的建模与计算能力。我们首先来看一个离散随机变量的例子，它将展示期望线性性质的强大威力。通过分析一个看似复杂的评分系统，我们将学习如何将问题分解为简单的独立部分，这是随机过程问题求解中的一个关键策略。[@problem_id:1301089]", "problem": "一名学生正在参加一项标准化考试，其选择题部分有着不寻常的计分系统。该部分由 $N$ 道题组成。每道题有 $M$ 个可能的答案，其中只有一个是正确答案。计分规则如下：\n- 每答对一题，学生得 $C$ 分。\n- 每答错一题，学生扣 $P$ 分。\n- 未作答的题目不影响得分。\n\n该学生决定对整个部分采用纯粹的猜测策略，即对 $N$ 道题中的每一道题，他们都会从 $M$ 个可用答案中随机选择一个。假设学生回答了每一道题，那么他在这部分的期望总分是多少？请用 $N$、$M$、$C$ 和 $P$ 表示你的答案，给出一个封闭形式的解析表达式。", "solution": "对于每道题，学生从 $M$ 个选项中随机均匀地选择一个。因此，答对的概率是 $1/M$，答错的概率是 $(M-1)/M$。令 $S_{i}$ 表示第 $i$ 题的得分。那么\n$$\n\\mathbb{P}(\\text{correct})=\\frac{1}{M}, \\quad \\mathbb{P}(\\text{incorrect})=\\frac{M-1}{M},\n$$\n根据离散随机变量期望的定义，\n$$\n\\mathbb{E}[S_{i}]=C\\cdot \\frac{1}{M}+(-P)\\cdot \\frac{M-1}{M}=\\frac{C-P(M-1)}{M}.\n$$\n令总分为 $T=\\sum_{i=1}^{N} S_{i}$。根据期望的线性性质，\n$$\n\\mathbb{E}[T]=\\sum_{i=1}^{N} \\mathbb{E}[S_{i}]=N \\cdot \\mathbb{E}[S_{1}]=N \\cdot \\frac{C-P(M-1)}{M}.\n$$\n因此，期望总分为\n$$\n\\frac{N}{M}\\left(C-P(M-1)\\right).\n$$", "answer": "$$\\boxed{\\frac{N}{M}\\left(C-P(M-1)\\right)}$$", "id": "1301089"}, {"introduction": "在掌握了离散情形后，我们将注意力转向连续随机变量。这个问题，通常被称为“断棍问题”，是一个经典的概率谜题，它完美地阐释了如何计算一个由其他随机变量派生出的新随机变量的期望。此练习的核心挑战在于，你需要先将文字描述（“较长一段的长度”）转化为一个精确的数学函数 $Y = \\max(X, L-X)$，然后运用积分来求解其期望。这个问题不仅能巩固你对连续期望定义的理解，还能培养你将现实问题数学化的能力。[@problem_id:1301069]", "problem": "在一个制造高精度复合材料棒的工厂里，对一根长度为 $L$ 的样品棒进行质量控制测试。该测试包括在棒的长度上的一个随机点上引发一次断裂。已知该断裂点的位置在区间 $[0, L]$ 上均匀分布。测试后，棒在断裂点处被分成两段。为了库存和物料规划，工厂需要确定这两段中*较长*一段的长度的统计平均值。\n\n求较长一段的期望长度关于 $L$ 的符号表达式。", "solution": "设棒的长度为 $L$。我们可以将棒建模为从 $0$ 到 $L$ 的一条线段。\n设随机变量 $X$ 表示断裂点的位置。\n由于断裂点是在棒的长度上随机均匀选择的，所以 $X$ 服从区间 $[0, L]$ 上的连续均匀分布。\n$X$ 的概率密度函数 (PDF)，记为 $f_X(x)$，由下式给出：\n$$\nf_X(x) = \\begin{cases} \\frac{1}{L}  \\text{for } 0 \\le x \\le L \\\\ 0  \\text{otherwise} \\end{cases}\n$$\n当棒在位置 $x$ 处断裂时，产生的两段的长度分别为 $x$ 和 $L-x$。\n设 $Y$ 为表示较长一段长度的随机变量。$Y$ 的值由 $X$ 的值决定。具体来说，$Y$ 是这两段长度中的最大值：\n$$\nY = \\max(X, L-X)\n$$\n我们需要求 $Y$ 的期望值，记为 $E[Y]$。我们可以使用连续随机变量函数的期望定义来计算它：\n$$\nE[Y] = E[\\max(X, L-X)] = \\int_{-\\infty}^{\\infty} \\max(x, L-x) f_X(x) \\, dx\n$$\n由于 $f_X(x)$ 仅在区间 $[0, L]$ 上非零，积分可以简化为：\n$$\nE[Y] = \\int_{0}^{L} \\max(x, L-x) \\frac{1}{L} \\, dx\n$$\n为了计算这个积分，我们需要处理 $\\max(x, L-x)$ 项。我们可以根据 $x$ 和 $L-x$ 这两项中哪一个更大来分割积分。\n当 $x \\ge L-x$ 时，项 $x$ 大于或等于 $L-x$，这可以简化为 $2x \\ge L$，或 $x \\ge \\frac{L}{2}$。\n当 $L-x > x$ 时，项 $L-x$ 大于 $x$，这可以简化为 $L > 2x$，或 $x  \\frac{L}{2}$。\n所以，我们有：\n$$\n\\max(x, L-x) = \\begin{cases} L-x  \\text{for } 0 \\le x  L/2 \\\\ x  \\text{for } L/2 \\le x \\le L \\end{cases}\n$$\n现在我们可以在点 $x = L/2$ 处将积分分成两部分：\n$$\nE[Y] = \\frac{1}{L} \\left[ \\int_{0}^{L/2} (L-x) \\, dx + \\int_{L/2}^{L} x \\, dx \\right]\n$$\n我们分别计算每个积分。\n对于第一个积分：\n$$\n\\int_{0}^{L/2} (L-x) \\, dx = \\left[ Lx - \\frac{x^2}{2} \\right]_{0}^{L/2} = \\left( L\\left(\\frac{L}{2}\\right) - \\frac{(L/2)^2}{2} \\right) - (0) = \\frac{L^2}{2} - \\frac{L^2/4}{2} = \\frac{L^2}{2} - \\frac{L^2}{8} = \\frac{3L^2}{8}\n$$\n对于第二个积分：\n$$\n\\int_{L/2}^{L} x \\, dx = \\left[ \\frac{x^2}{2} \\right]_{L/2}^{L} = \\frac{L^2}{2} - \\frac{(L/2)^2}{2} = \\frac{L^2}{2} - \\frac{L^2/4}{2} = \\frac{L^2}{2} - \\frac{L^2}{8} = \\frac{3L^2}{8}\n$$\n现在，将这些结果代回到 $E[Y]$ 的表达式中：\n$$\nE[Y] = \\frac{1}{L} \\left( \\frac{3L^2}{8} + \\frac{3L^2}{8} \\right) = \\frac{1}{L} \\left( \\frac{6L^2}{8} \\right) = \\frac{1}{L} \\left( \\frac{3L^2}{4} \\right)\n$$\n$$\nE[Y] = \\frac{3L}{4}\n$$\n因此，较长一段的期望长度是 $\\frac{3L}{4}$。", "answer": "$$\\boxed{\\frac{3L}{4}}$$", "id": "1301069"}, {"introduction": "最后，我们来解决一个更具挑战性的问题，它将展示一种极为优雅且强大的工具——示性随机变量。直接计算所观察到的不同颜色数量的概率分布会非常复杂，但通过为每种颜色定义一个“是否出现”的示性变量，问题便迎刃而解。这个练习巧妙地再次运用了期望的线性性质，证明了即使在各随机变量并非相互独立的情况下，该性质依然成立。掌握这项技术将为你解决各种组合计数和概率问题提供一个有力的视角。[@problem_id:1301042]", "problem": "一个瓮中装有非常大量的球，对应$N$种不同的颜色。瓮的构成使得抽到任何一种特定颜色球的概率为$1/N$，并且每次抽取的概率都保持不变。一个实验包括从瓮中一次一个地有放回地抽取$k$个球。\n\n令$X$为随机变量，表示在抽出的$k$个球中观察到的不同颜色的数量。\n\n找出$X$的期望值$E[X]$关于$N$和$k$的闭式解析表达式。", "solution": "为了求出不同颜色的期望数量$E[X]$，我们可以使用指示随机变量和期望的线性性这一技巧。\n\n设颜色集合为$\\{C_1, C_2, \\ldots, C_N\\}$。对每一种颜色$C_i$（其中$i \\in \\{1, 2, \\ldots, N\\}$），我们定义一个指示随机变量$I_i$如下：\n$$\nI_i = \n\\begin{cases} \n1  \\text{如果在 } k \\text{ 次抽取中至少观察到一次颜色 } C_i \\\\\n0  \\text{如果在 } k \\text{ 次抽取中从未观察到颜色 } C_i \n\\end{cases}\n$$\n观察到的不同颜色的总数$X$可以表示为这些指示变量的和：\n$$\nX = \\sum_{i=1}^{N} I_i\n$$\n根据期望的线性性，$X$的期望值是这些指示变量期望值的和：\n$$\nE[X] = E\\left[\\sum_{i=1}^{N} I_i\\right] = \\sum_{i=1}^{N} E[I_i]\n$$\n指示随机变量的期望等于它所指示事件的概率。因此，$E[I_i] = P(I_i = 1)$。\n\n事件$I_i=1$表示颜色$C_i$被至少观察到一次。更简单的方法是先计算其互补事件$I_i=0$的概率，即在$k$次抽取中从未观察到颜色$C_i$。\n\n对于任意单次抽取，抽到颜色$C_i$的球的概率为$p = 1/N$。因此，在单次抽取中*不*抽到颜色$C_i$的球的概率为$1 - p = 1 - 1/N = (N-1)/N$。\n\n由于$k$次抽取是独立的（因为是有放回抽取），在$k$次抽取中都未抽到颜色$C_i$的概率是每次抽取概率的乘积：\n$$\nP(I_i = 0) = \\left(1 - \\frac{1}{N}\\right)^k = \\left(\\frac{N-1}{N}\\right)^k\n$$\n现在，我们可以求出颜色$C_i$被至少观察到一次的概率：\n$$\nP(I_i = 1) = 1 - P(I_i = 0) = 1 - \\left(\\frac{N-1}{N}\\right)^k\n$$\n因此，指示变量$I_i$的期望为：\n$$\nE[I_i] = P(I_i = 1) = 1 - \\left(\\frac{N-1}{N}\\right)^k\n$$\n由于问题的对称性，这个期望对于所有颜色$i=1, 2, \\ldots, N$都是相同的。\n\n最后，我们将此结果代回到$E[X]$的表达式中。这个和变成了$N$个相同项的和：\n$$\nE[X] = \\sum_{i=1}^{N} \\left(1 - \\left(\\frac{N-1}{N}\\right)^k\\right) = N \\left(1 - \\left(\\frac{N-1}{N}\\right)^k\\right)\n$$\n这就是不同颜色期望数量的最终闭式表达式。", "answer": "$$\\boxed{N \\left(1 - \\left(\\frac{N-1}{N}\\right)^{k}\\right)}$$", "id": "1301042"}]}