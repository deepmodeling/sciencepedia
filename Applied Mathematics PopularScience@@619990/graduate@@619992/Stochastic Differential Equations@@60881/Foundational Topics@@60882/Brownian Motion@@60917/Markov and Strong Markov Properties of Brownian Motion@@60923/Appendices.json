{"hands_on_practices": [{"introduction": "We begin with a canonical problem in the study of stochastic processes: determining the probability that a Brownian motion exits a given interval through one boundary before the other. This scenario, a continuous-time analogue of the classic gambler's ruin problem, serves as a perfect vehicle for applying the Optional Stopping Theorem. By defining an appropriate martingale and carefully justifying the theorem's use for an unbounded stopping time, this exercise demonstrates a foundational technique for solving exit problems [@problem_id:2986583].", "problem": "Let $\\{W_{t}\\}_{t \\ge 0}$ be a one-dimensional standard Brownian motion starting at $W_{0} = x$ with $x \\in (a,b)$, where $a  b$ are fixed real numbers. Define the first hitting times $\\tau_{a} := \\inf\\{t \\ge 0 : W_{t} = a\\}$ and $\\tau_{b} := \\inf\\{t \\ge 0 : W_{t} = b\\}$, and let $\\tau := \\tau_{a} \\wedge \\tau_{b}$. Denote by $\\mathbb{P}_{x}$ the law of the process when $W_{0} = x$. Using only the defining properties of Brownian motion, the strong Markov property, and fundamental martingale facts for Brownian motion, derive the analytic expression for the probability $\\mathbb{P}_{x}(\\tau_{a}  \\tau_{b})$. In your derivation, justify any use of stopping times and limiting arguments that involve stopping times by appealing to standard conditions under which the Optional Stopping Theorem holds. Conclude by showing that this probability is a linear function of $x$. Express your final answer as a single simplified closed-form expression in terms of $a$, $b$, and $x$. No rounding is required.", "solution": "Let $\\{W_{t}\\}_{t \\ge 0}$ be a one-dimensional standard Brownian motion starting at $W_{0} = x$, with $x \\in (a,b)$ for fixed real numbers $a  b$. The filtration generated by the process is denoted by $\\{\\mathcal{F}_{t}\\}_{t \\ge 0}$, where $\\mathcal{F}_{t} = \\sigma(W_{s} : s \\le t)$. The governing probability measure is $\\mathbb{P}_{x}$. We wish to find the probability $p(x) := \\mathbb{P}_{x}(\\tau_{a}  \\tau_{b})$, where $\\tau_{a} := \\inf\\{t \\ge 0 : W_{t} = a\\}$ and $\\tau_{b} := \\inf\\{t \\ge 0 : W_{t} = b\\}$ are the first hitting times of $a$ and $b$ respectively.\n\nThe derivation will proceed by applying the Optional Stopping Theorem to the martingale $M_{t} = W_{t}$ and the stopping time $\\tau = \\tau_{a} \\wedge \\tau_{b}$.\n\nFirst, we establish that $\\{W_t\\}_{t \\ge 0}$ is a martingale with respect to the filtration $\\{\\mathcal{F}_t\\}_{t \\ge 0}$ under the measure $\\mathbb{P}_x$. For any $s  t$, we must show that $\\mathbb{E}_{x}[W_{t} | \\mathcal{F}_{s}] = W_{s}$.\nBy the properties of conditional expectation and the definition of Brownian motion, we have:\n$$\n\\mathbb{E}_{x}[W_{t} | \\mathcal{F}_{s}] = \\mathbb{E}_{x}[W_{s} + (W_{t} - W_{s}) | \\mathcal{F}_{s}] = W_{s} + \\mathbb{E}_{x}[W_{t} - W_{s} | \\mathcal{F}_{s}]\n$$\nThe increment $W_{t} - W_{s}$ is independent of the past information contained in $\\mathcal{F}_{s}$. Therefore, the conditional expectation is equal to the unconditional expectation:\n$$\n\\mathbb{E}_{x}[W_{t} - W_{s} | \\mathcal{F}_{s}] = \\mathbb{E}_{x}[W_{t} - W_{s}]\n$$\nA standard Brownian motion has increments with mean zero, so $\\mathbb{E}_{x}[W_{t} - W_{s}] = 0$. Thus, we have:\n$$\n\\mathbb{E}_{x}[W_{t} | \\mathcal{F}_{s}] = W_{s} + 0 = W_{s}\n$$\nThis confirms that $\\{W_{t}\\}_{t \\ge 0}$ is a martingale under $\\mathbb{P}_{x}$.\n\nNext, we define the stopping time $\\tau = \\tau_{a} \\wedge \\tau_{b}$. This is the first time the process $W_{t}$ exits the open interval $(a,b)$. To verify that $\\tau$ is a stopping time, we must show that the event $\\{\\tau \\le t\\}$ is in $\\mathcal{F}_{t}$ for all $t \\ge 0$. The event $\\{\\tau \\le t\\}$ can be written as:\n$$\n\\{\\tau \\le t\\} = \\{ \\inf_{0 \\le s \\le t} W_{s} \\le a \\} \\cup \\{ \\sup_{0 \\le s \\le t} W_{s} \\ge b \\}\n$$\nSince the paths of a Brownian motion are continuous functions, the infimum and supremum over a closed interval $[0,t]$ are $\\mathcal{F}_{t}$-measurable random variables. The union of two $\\mathcal{F}_{t}$-measurable sets is also $\\mathcal{F}_{t}$-measurable. Hence, $\\tau$ is a stopping time with respect to $\\{\\mathcal{F}_{t}\\}$.\n\nWe now apply the Optional Stopping Theorem. The theorem states that for a martingale $M_{t}$ and a stopping time $T$, under certain conditions, $\\mathbb{E}[M_{T}] = \\mathbb{E}[M_{0}]$. We must justify that these conditions hold for $M_{t} = W_{t}$ and $T = \\tau$.\nA sufficient set of conditions is that $\\mathbb{P}_{x}(\\tau  \\infty) = 1$ and that the stopped process $W_{t \\wedge \\tau}$ is uniformly integrable.\n\nThe probability that a one-dimensional Brownian motion remains within a finite interval for all time is zero. That is, $\\mathbb{P}_{x}(\\tau = \\infty) = 0$, which implies $\\mathbb{P}_{x}(\\tau  \\infty) = 1$.\n\nNow, we examine the stopped process $\\{W_{t \\wedge \\tau}\\}_{t \\ge 0}$. For any time $s  \\tau$, by the definition of $\\tau$, the process value $W_{s}$ is strictly between $a$ and $b$. Due to the continuity of Brownian paths, at the very instant of stopping, $W_{\\tau}$ must be equal to either $a$ or $b$. Consequently, for any $t \\ge 0$, the value of the stopped process $W_{t \\wedge \\tau}$ is always contained in the closed interval $[a,b]$. This means the random variables $W_{t \\wedge \\tau}$ are uniformly bounded:\n$$\na \\le W_{t \\wedge \\tau} \\le b \\quad \\forall t \\ge 0\n$$\nwhich implies $|W_{t \\wedge \\tau}| \\le \\max(|a|,|b|)$. A family of random variables that is uniformly bounded is also uniformly integrable. Doob's Optional Stopping Theorem in one of its common forms states that for a uniformly integrable martingale, the expectation is preserved at a stopping time.\nAlternatively, and more directly, we can use a limiting argument. For any fixed time $T_{0} > 0$, the stopped process $W_{t \\wedge T_{0}}$ is a bounded martingale, so $\\mathbb{E}_{x}[W_{T_{0} \\wedge \\tau}] = \\mathbb{E}_{x}[W_{0}] = x$. We wish to let $T_{0} \\to \\infty$. We have established that $\\tau  \\infty$ almost surely, so as $T_{0} \\to \\infty$, $T_{0} \\wedge \\tau \\to \\tau$ almost surely. By the path continuity of Brownian motion, $W_{T_{0} \\wedge \\tau} \\to W_{\\tau}$ almost surely.\nSince the random variables $\\{W_{T_{0} \\wedge \\tau}\\}_{T_{0} \\ge 0}$ are uniformly bounded by $\\max(|a|,|b|)$, we can apply the Bounded Convergence Theorem to exchange the limit and expectation:\n$$\n\\mathbb{E}_{x}[W_{\\tau}] = \\mathbb{E}_{x}[\\lim_{T_{0} \\to \\infty} W_{T_{0} \\wedge \\tau}] = \\lim_{T_{0} \\to \\infty} \\mathbb{E}_{x}[W_{T_{0} \\wedge \\tau}]\n$$\nSince $\\mathbb{E}_{x}[W_{T_{0} \\wedge \\tau}] = x$ for all $T_{0}$, the limit is also $x$. Therefore, we have established:\n$$\n\\mathbb{E}_{x}[W_{\\tau}] = x\n$$\nNow, we compute this expectation in another way. The random variable $W_{\\tau}$ can only take values $a$ or $b$ (the event $\\tau_{a} = \\tau_{b}$ has probability $0$). Its distribution is given by:\n$\\mathbb{P}_{x}(W_{\\tau} = a) = \\mathbb{P}_{x}(\\tau_{a}  \\tau_{b}) = p(x)$\n$\\mathbb{P}_{x}(W_{\\tau} = b) = \\mathbb{P}_{x}(\\tau_{b} \\le \\tau_{a}) = 1 - p(x)$\nThe expectation of $W_{\\tau}$ is therefore:\n$$\n\\mathbb{E}_{x}[W_{\\tau}] = a \\cdot \\mathbb{P}_{x}(W_{\\tau} = a) + b \\cdot \\mathbb{P}_{x}(W_{\\tau} = b) = a \\cdot p(x) + b \\cdot (1 - p(x))\n$$\nEquating the two expressions for $\\mathbb{E}_{x}[W_{\\tau}]$:\n$$\nx = a \\cdot p(x) + b - b \\cdot p(x)\n$$\nWe now solve for $p(x)$:\n$$\nx - b = p(x) (a - b)\n$$\n$$\np(x) = \\frac{x-b}{a-b}\n$$\nThis expression can be simplified by multiplying the numerator and denominator by $-1$:\n$$\np(x) = \\frac{-(b-x)}{-(b-a)} = \\frac{b-x}{b-a}\n$$\nThis is the analytic expression for the probability $\\mathbb{P}_{x}(\\tau_{a}  \\tau_{b})$. We can rewrite this expression as:\n$$\np(x) = \\left(\\frac{-1}{b-a}\\right)x + \\frac{b}{b-a}\n$$\nThis shows that $p(x)$ is a linear function of the starting position $x$. The slope is $\\frac{-1}{b-a}$ and the intercept is $\\frac{b}{b-a}$. The derivation adheres to the use of martingale properties and the Optional Stopping Theorem as required.", "answer": "$$\\boxed{\\frac{b-x}{b-a}}$$", "id": "2986583"}, {"introduction": "Having explored where a Brownian motion might exit an interval, we now turn to a different question: what is the probability that its maximum value ever reaches a certain level? This problem introduces the celebrated reflection principle, a powerful and elegant consequence of the strong Markov property. This practice will guide you through a rigorous derivation, using symmetry arguments to connect the probability of the supremum to the much simpler distribution of the process at a fixed time [@problem_id:2986626].", "problem": "Let $B=\\{B_{s}: s\\ge 0\\}$ be a one-dimensional standard Brownian motion (also called a Wiener process) started at $B_{0}=0$ on a filtered probability space $(\\Omega,\\mathcal{F},\\{\\mathcal{F}_{s}\\}_{s\\ge 0},\\mathbb{P})$ satisfying the usual conditions. Fix $a0$ and $t0$, and define the first hitting time of the level $a$ by\n$$\n\\tau_{a} := \\inf\\{s\\ge 0: B_{s}=a\\}.\n$$\nThe strong Markov property asserts that for any stopping time $\\tau$ with respect to the natural filtration of $B$, the shifted process $\\{B_{\\tau+s}-B_{\\tau}: s\\ge 0\\}$ is a Brownian motion independent of $\\mathcal{F}_{\\tau}$. Using only the fundamental properties of Brownian motion (independent and stationary Gaussian increments, continuity of paths, symmetry of the Gaussian distribution) and the strong Markov property at $\\tau_{a}$, derive a rigorous reflection argument that relates the law of $B_{t}$ on the event $\\{\\tau_{a}\\le t\\}$ to its reflection across the level $a$. Then use this reflection argument to compute the probability\n$$\n\\mathbb{P}\\Big(\\sup_{0\\le s\\le t} B_s \\ge a\\Big).\n$$\nYour final answer must be given in closed form as a single analytic expression. If you choose to express your answer in terms of the standard normal cumulative distribution function (CDF), define it precisely in your derivation.", "solution": "The problem asks for the probability $\\mathbb{P}(\\sup_{0\\le s\\le t} B_s \\ge a)$ for a standard one-dimensional Brownian motion $B_s$ starting at $B_0=0$, where $a0$ and $t0$ are fixed constants.\n\nFirst, we establish the equivalence between the event of the supremum reaching $a$ and the event of the first hitting time of $a$ occurring by time $t$. Let $\\tau_a = \\inf\\{s \\ge 0 : B_s = a\\}$. The paths of a Brownian motion are continuous almost surely. By the definition of the supremum, if $\\sup_{0\\le s\\le t} B_s \\ge a$, then for any $\\epsilon  0$, there exists an $s_0 \\in [0, t]$ such that $B_{s_0}  a-\\epsilon$. By continuity of paths, and since $B_0 = 0  a$, the Intermediate Value Theorem implies that the process must take the value $a$ at some time $s^* \\le s_0 \\le t$. Therefore, $\\tau_a = \\inf\\{s \\ge 0: B_s = a\\} \\le t$. Conversely, if $\\tau_a \\le t$, then there is a time $s \\in [0,t]$ such that $B_s=a$, which implies that $\\sup_{0\\le u\\le t} B_u \\ge a$. Thus, the two events are the same, and we have\n$$\n\\mathbb{P}\\Big(\\sup_{0\\le s\\le t} B_s \\ge a\\Big) = \\mathbb{P}(\\tau_a \\le t).\n$$\nTo compute $\\mathbb{P}(\\tau_a \\le t)$, we employ the reflection principle, which we derive using the strong Markov property of Brownian motion. We partition the event $\\{\\tau_a \\le t\\}$ into two disjoint events based on the value of $B_t$:\n$$\nE_1 = \\{\\tau_a \\le t \\text{ and } B_t \\ge a\\}\n$$\n$$\nE_2 = \\{\\tau_a \\le t \\text{ and } B_t  a\\}\n$$\nSince the distribution of $B_t$ is continuous, $\\mathbb{P}(B_t=a)=0$, so we do not need to consider this case separately in the partition. We have\n$$\n\\mathbb{P}(\\tau_a \\le t) = \\mathbb{P}(E_1) + \\mathbb{P}(E_2).\n$$\nThe reflection argument rests on proving that $\\mathbb{P}(E_1) = \\mathbb{P}(E_2)$. To establish this, we use the strong Markov property at the stopping time $\\tau_a$. This property states that the process $W_s = B_{\\tau_a+s} - B_{\\tau_a}$ for $s \\ge 0$ is a standard Brownian motion and is independent of the pre-$\\tau_a$ sigma-algebra $\\mathcal{F}_{\\tau_a}$.\n\nOn the event $\\{\\tau_a \\le t\\}$, we have $B_{\\tau_a} = a$ almost surely due to the continuity of paths. We can express $B_t$ for $t \\ge \\tau_a$ as:\n$$\nB_t = B_{\\tau_a + (t-\\tau_a)} = B_{\\tau_a} + (B_{\\tau_a+(t-\\tau_a)} - B_{\\tau_a}) = a + W_{t-\\tau_a}.\n$$\nNow we analyze the probability of $E_2$:\n$$\n\\mathbb{P}(E_2) = \\mathbb{P}(\\tau_a \\le t \\text{ and } B_t  a) = \\mathbb{P}(\\tau_a \\le t \\text{ and } a + W_{t-\\tau_a}  a) = \\mathbb{P}(\\tau_a \\le t \\text{ and } W_{t-\\tau_a}  0).\n$$\nUsing the law of total expectation by conditioning on the sigma-algebra $\\mathcal{F}_{\\tau_a}$:\n$$\n\\mathbb{P}(E_2) = \\mathbb{E}\\big[\\mathbb{P}(E_2 | \\mathcal{F}_{\\tau_a})\\big] = \\mathbb{E}\\big[\\mathbf{1}_{\\{\\tau_a \\le t\\}} \\mathbb{P}(W_{t-\\tau_a}  0 | \\mathcal{F}_{\\tau_a})\\big].\n$$\nSince $\\tau_a$ is $\\mathcal{F}_{\\tau_a}$-measurable, we can treat its value as fixed inside the conditional probability. The process $W$ is independent of $\\mathcal{F}_{\\tau_a}$. Let $u=t-\\tau_a$. On the event $\\{\\tau_a \\le t\\}$, $u \\ge 0$. If $\\tau_a  t$, then $u  0$, and $W_u \\sim N(0, u)$. By the symmetry of the Gaussian distribution about its mean of $0$, $\\mathbb{P}(W_u  0) = 1/2$. If $\\tau_a = t$, the condition becomes $W_0  0$, which is $00$, an impossible event. However, $\\mathbb{P}(\\tau_a=t)=0$ (a non-trivial result related to the law of the iterated logarithm, but can be accepted here). Thus, we can proceed:\n$$\n\\mathbb{P}(W_{t-\\tau_a}  0 | \\mathcal{F}_{\\tau_a}) = \\frac{1}{2} \\quad \\text{a.s. on } \\{\\tau_a  t\\}.\n$$\nSo, $\\mathbb{P}(E_2) = \\mathbb{E}\\left[\\mathbf{1}_{\\{\\tau_a \\le t\\}} \\cdot \\frac{1}{2}\\right] = \\frac{1}{2} \\mathbb{P}(\\tau_a \\le t)$.\n\nA similar calculation for $E_1$ gives:\n$$\n\\mathbb{P}(E_1) = \\mathbb{P}(\\tau_a \\le t \\text{ and } B_t \\ge a) = \\mathbb{P}(\\tau_a \\le t \\text{ and } W_{t-\\tau_a} \\ge 0).\n$$\n$$\n\\mathbb{P}(E_1) = \\mathbb{E}\\big[\\mathbf{1}_{\\{\\tau_a \\le t\\}} \\mathbb{P}(W_{t-\\tau_a} \\ge 0 | \\mathcal{F}_{\\tau_a})\\big].\n$$\nBy symmetry, $\\mathbb{P}(W_{t-\\tau_a} \\ge 0 | \\mathcal{F}_{\\tau_a}) = 1/2$ (since the probability of being exactly $0$ is $0$). Thus, $\\mathbb{P}(E_1) = \\frac{1}{2} \\mathbb{P}(\\tau_a \\le t)$.\nThis derivation rigorously shows that $\\mathbb{P(E_1)} = \\mathbb{P(E_2)}$. This equality is the essence of the reflection principle. It shows that conditioned on having hit level $a$ by time $t$, the process $B_t$ is equally likely to be above or below $a$. This relates the law of $B_t$ on $\\{\\tau_a \\le t\\}$ to its reflection, as requested.\n\nNow we use this result to compute the desired probability. From $\\mathbb{P}(\\tau_a \\le t) = \\mathbb{P}(E_1) + \\mathbb{P}(E_2)$ and $\\mathbb{P}(E_1)=\\mathbb{P}(E_2)$, we get\n$$\n\\mathbb{P}(\\tau_a \\le t) = 2 \\mathbb{P}(E_1) = 2 \\mathbb{P}(\\tau_a \\le t, B_t \\ge a).\n$$\nNext, we simplify the event $\\{\\tau_a \\le t, B_t \\ge a\\}$. Consider the event $\\{B_t \\ge a\\}$. Since $B_0=0$ and $a0$, for any path where $B_t \\ge a$, the path must have crossed the level $a$ at some time $s \\in [0,t]$ by the Intermediate Value Theorem for continuous functions. The first such time is $\\tau_a$, so we must have $\\tau_a \\le t$. Therefore, the event $\\{B_t \\ge a\\}$ is a subset of $\\{\\tau_a \\le t\\}$. This implies:\n$$\n\\{\\tau_a \\le t\\} \\cap \\{B_t \\ge a\\} = \\{B_t \\ge a\\}.\n$$\nSo, we have the equality of events $E_1 = \\{B_t \\ge a\\}$. This leads to\n$$\n\\mathbb{P}(\\tau_a \\le t) = 2 \\mathbb{P}(B_t \\ge a).\n$$\nThe final step is to calculate $\\mathbb{P}(B_t \\ge a)$. A standard one-dimensional Brownian motion $B_t$ started at $0$ has a Gaussian distribution with mean $0$ and variance $t$, i.e., $B_t \\sim N(0,t)$. Let $Z = B_t/\\sqrt{t}$ be a standard normal random variable, $Z \\sim N(0,1)$.\n$$\n\\mathbb{P}(B_t \\ge a) = \\mathbb{P}\\left(\\frac{B_t}{\\sqrt{t}} \\ge \\frac{a}{\\sqrt{t}}\\right) = \\mathbb{P}\\left(Z \\ge \\frac{a}{\\sqrt{t}}\\right).\n$$\nLet us define the cumulative distribution function (CDF) of the standard normal distribution as\n$$\n\\Phi(x) = \\mathbb{P}(Z \\le x) = \\int_{-\\infty}^{x} \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{z^2}{2}\\right) dz.\n$$\nThen, $\\mathbb{P}(Z \\ge y) = 1 - \\mathbb{P}(Z  y) = 1 - \\Phi(y)$. So,\n$$\n\\mathbb{P}(B_t \\ge a) = 1 - \\Phi\\left(\\frac{a}{\\sqrt{t}}\\right).\n$$\nSubstituting this back into our main result, we obtain the final answer:\n$$\n\\mathbb{P}\\Big(\\sup_{0\\le s\\le t} B_s \\ge a\\Big) = 2 \\mathbb{P}(B_t \\ge a) = 2 \\left(1 - \\Phi\\left(\\frac{a}{\\sqrt{t}}\\right)\\right).\n$$", "answer": "$$\\boxed{2\\left(1 - \\Phi\\left(\\frac{a}{\\sqrt{t}}\\right)\\right)}$$", "id": "2986626"}, {"introduction": "Our final practice shifts the focus from 'if' and 'where' to 'when'. We will calculate the average time it takes for a Brownian motion to first leave a specified interval. This problem showcases a profound connection between probability theory and analysis, illustrating how a question about an expected stopping time can be translated into a solvable boundary value problem using the process's infinitesimal generator. Mastering this technique, rooted in Dynkin's formula, opens the door to a wide range of problems linking stochastic differential equations and partial differential equations [@problem_id:2986589].", "problem": "Let $\\{B_{t}\\}_{t \\ge 0}$ be a standard one-dimensional Brownian motion started at $x \\in (a,b)$, where $a  b$ are fixed real numbers. Define the first exit time from the open interval $(a,b)$ by\n$$\n\\tau_{(a,b)} \\;=\\; \\inf\\{\\, t \\ge 0 \\,:\\, B_{t} \\notin (a,b) \\,\\}.\n$$\nDenote by $\\mathcal{L}$ the infinitesimal generator of Brownian motion, which acts on twice continuously differentiable functions $f \\in C^{2}(\\mathbb{R})$ by\n$$\n\\mathcal{L} f(y) \\;=\\; \\frac{1}{2}\\, f''(y).\n$$\nUsing the strong Markov property of Brownian motion and Dynkinâ€™s formula for stopping times, derive the boundary value problem satisfied by the function\n$$\nu(y) \\;=\\; \\mathbb{E}_{y}\\!\\left[\\, \\tau_{(a,b)} \\,\\right], \\quad y \\in (a,b),\n$$\nand solve this boundary value problem to obtain an explicit expression for $u(x)$ in terms of $a$, $b$, and $x$. Your final answer must be a single closed-form analytic expression. No rounding is required.", "solution": "The problem asks for the expected first exit time of a standard one-dimensional Brownian motion from an open interval $(a,b)$, starting from a point $x \\in (a,b)$. Let $\\{B_t\\}_{t \\ge 0}$ be the Brownian motion, with $B_0 = y$. The function of interest is $u(y) = \\mathbb{E}_y[\\tau_{(a,b)}]$, where $\\tau_{(a,b)} = \\inf\\{ t \\ge 0 : B_t \\notin (a,b) \\}$. We are asked to derive the boundary value problem (BVP) that $u(y)$ satisfies, solve it, and provide the specific value $u(x)$.\n\nFirst, we derive the boundary value problem for $u(y)$. This consists of a differential equation on the interval $(a,b)$ and conditions at the boundaries $a$ and $b$.\n\nThe boundary conditions are determined by the definition of the stopping time $\\tau_{(a,b)}$. If the process starts at a boundary point, for instance $y=a$, it is already outside the open interval $(a,b)$. Thus, the first time $t \\ge 0$ for which $B_t \\notin (a,b)$ is $t=0$. Therefore, $\\tau_{(a,b)} = 0$ if the starting point is $a$ or $b$. By continuity of Brownian paths and the expected value operator, we can infer the boundary conditions for $u(y)$:\n$$ \\lim_{y \\to a^+} u(y) = \\mathbb{E}_a[\\tau_{(a,b)}] = 0 $$\n$$ \\lim_{y \\to b^-} u(y) = \\mathbb{E}_b[\\tau_{(a,b)}] = 0 $$\nSo, the boundary conditions are $u(a)=0$ and $u(b)=0$.\n\nNext, we derive the differential equation for $y \\in (a,b)$. We use the strong Markov property. Let $\\tau_h = \\inf\\{t \\ge 0 : |B_t - y| \\ge \\epsilon\\}$ be the first exit time from the interval $(y-\\epsilon, y+\\epsilon)$ for a small $\\epsilon  0$ such that $(y-\\epsilon, y+\\epsilon) \\subset (a,b)$. By the law of total expectation and the strong Markov property applied at the stopping time $\\tau_h$:\n$$ u(y) = \\mathbb{E}_y[\\tau_{(a,b)}] = \\mathbb{E}_y[\\tau_h + (\\tau_{(a,b)} - \\tau_h)] = \\mathbb{E}_y[\\tau_h] + \\mathbb{E}_y[\\mathbb{E}_y[\\tau_{(a,b)} - \\tau_h | \\mathcal{F}_{\\tau_h}]] $$\nThe term $\\tau_{(a,b)} - \\tau_h$ is the remaining time to exit $(a,b)$ after time $\\tau_h$. By the strong Markov property, this is equivalent to the exit time from $(a,b)$ for a new Brownian motion starting at $B_{\\tau_h}$.\n$$ \\mathbb{E}_y[\\tau_{(a,b)} - \\tau_h | \\mathcal{F}_{\\tau_h}] = \\mathbb{E}_{B_{\\tau_h}}[\\tau_{(a,b)}] = u(B_{\\tau_h}) $$\nSubstituting this back, we get:\n$$ u(y) = \\mathbb{E}_y[\\tau_h] + \\mathbb{E}_y[u(B_{\\tau_h})] $$\nFor a one-dimensional standard Brownian motion, the expected exit time from an interval $(y-\\epsilon, y+\\epsilon)$ is known to be $\\mathbb{E}_y[\\tau_h] = \\epsilon^2$. Also, by symmetry, the process is equally likely to exit at $y-\\epsilon$ or $y+\\epsilon$, so $\\mathbb{P}_y(B_{\\tau_h} = y+\\epsilon) = \\mathbb{P}_y(B_{\\tau_h} = y-\\epsilon) = \\frac{1}{2}$. Thus:\n$$ \\mathbb{E}_y[u(B_{\\tau_h})] = \\frac{1}{2}u(y+\\epsilon) + \\frac{1}{2}u(y-\\epsilon) $$\nAssuming $u$ is twice continuously differentiable ($u \\in C^2(a,b)$), we use Taylor expansion for $u$ around $y$:\n$$ u(y \\pm \\epsilon) = u(y) \\pm \\epsilon u'(y) + \\frac{\\epsilon^2}{2} u''(y) \\pm \\frac{\\epsilon^3}{6} u'''(y) + O(\\epsilon^4) $$\n$$ \\mathbb{E}_y[u(B_{\\tau_h})] = \\frac{1}{2} \\left[ (u(y) + \\epsilon u'(y) + \\frac{\\epsilon^2}{2} u''(y) + O(\\epsilon^3)) + (u(y) - \\epsilon u'(y) + \\frac{\\epsilon^2}{2} u''(y) - O(\\epsilon^3)) \\right] = u(y) + \\frac{\\epsilon^2}{2} u''(y) + O(\\epsilon^4) $$\nSubstituting these results into the equation for $u(y)$:\n$$ u(y) = \\epsilon^2 + \\left( u(y) + \\frac{\\epsilon^2}{2} u''(y) + O(\\epsilon^4) \\right) $$\nSubtracting $u(y)$ from both sides:\n$$ 0 = \\epsilon^2 + \\frac{\\epsilon^2}{2} u''(y) + O(\\epsilon^4) $$\nDividing by $\\epsilon^2$ (for $\\epsilon \\neq 0$) and taking the limit as $\\epsilon \\to 0$:\n$$ 0 = 1 + \\frac{1}{2} u''(y) $$\nThis gives the differential equation $u''(y) = -2$, which can also be written using the generator $\\mathcal{L}u(y) = -1$.\n\nThe complete boundary value problem is:\n$$ \\begin{cases} u''(y) = -2,  y \\in (a,b) \\\\ u(a) = 0 \\\\ u(b) = 0 \\end{cases} $$\nWe now solve this BVP. Integrating the differential equation $u''(y) = -2$ with respect to $y$ gives:\n$$ u'(y) = -2y + C_1 $$\nIntegrating again:\n$$ u(y) = -y^2 + C_1 y + C_2 $$\nwhere $C_1$ and $C_2$ are constants of integration. We determine them using the boundary conditions:\n$$ u(a) = -a^2 + C_1 a + C_2 = 0 $$\n$$ u(b) = -b^2 + C_1 b + C_2 = 0 $$\nSubtracting the first equation from the second gives:\n$$ (-b^2 + a^2) + C_1(b-a) = 0 $$\n$$ -(b-a)(b+a) + C_1(b-a) = 0 $$\nSince $a  b$, $b-a \\neq 0$, so we can divide by $(b-a)$:\n$$ -(b+a) + C_1 = 0 \\implies C_1 = a+b $$\nSubstituting $C_1$ into the first boundary condition equation:\n$$ -a^2 + (a+b)a + C_2 = 0 \\implies -a^2 + a^2 + ab + C_2 = 0 \\implies C_2 = -ab $$\nThe solution to the BVP is:\n$$ u(y) = -y^2 + (a+b)y - ab $$\nThis can be factored as:\n$$ u(y) = -(y^2 - (a+b)y + ab) = -(y-a)(y-b) = (y-a)(b-y) $$\nLet us denote this candidate solution by $v(y) = (y-a)(b-y)$.\n\nTo rigorously confirm this result using Dynkin's formula, we show that $v(y)$ is indeed equal to $\\mathbb{E}_y[\\tau_{(a,b)}]$. The function $v(y)$ is in $C^2(\\mathbb{R})$ and satisfies the BVP. The infinitesimal generator acting on $v$ is $\\mathcal{L}v(y) = \\frac{1}{2}v''(y) = \\frac{1}{2}(-2) = -1$. Let $\\tau = \\tau_{(a,b)}$ and consider the bounded stopping time $\\tau_t = \\min(t, \\tau)$. By Dynkin's formula applied to $v(y)$:\n$$ \\mathbb{E}_y[v(B_{\\tau_t})] = v(y) + \\mathbb{E}_y\\left[ \\int_0^{\\tau_t} (\\mathcal{L}v)(B_s) ds \\right] $$\nSubstituting $\\mathcal{L}v = -1$:\n$$ \\mathbb{E}_y[v(B_{\\tau_t})] = v(y) + \\mathbb{E}_y\\left[ \\int_0^{\\tau_t} (-1) ds \\right] = v(y) - \\mathbb{E}_y[\\tau_t] $$\nRearranging, we get an expression for the expected stopped time:\n$$ \\mathbb{E}_y[\\tau_t] = v(y) - \\mathbb{E}_y[v(B_{\\tau_t})] $$\nNow, we take the limit as $t \\to \\infty$. On the left side, $\\tau_t \\uparrow \\tau$ as $t \\to \\infty$. By the Monotone Convergence Theorem, $\\lim_{t\\to\\infty} \\mathbb{E}_y[\\tau_t] = \\mathbb{E}_y[\\tau] = u(y)$.\nOn the right side, as $t \\to \\infty$, $B_{\\tau_t} \\to B_\\tau$ almost surely. Since $v$ is continuous, $v(B_{\\tau_t}) \\to v(B_\\tau)$ almost surely. Upon exit, $B_\\tau \\in \\{a,b\\}$. The function $v(y)$ is constructed to be zero at the boundaries: $v(a)=0$ and $v(b)=0$. Therefore, $v(B_\\tau) = 0$ almost surely. The function $v(y)$ is bounded on $[a,b]$, so we can apply the Dominated Convergence Theorem:\n$$ \\lim_{t\\to\\infty} \\mathbb{E}_y[v(B_{\\tau_t})] = \\mathbb{E}_y[\\lim_{t\\to\\infty} v(B_{\\tau_t})] = \\mathbb{E}_y[v(B_\\tau)] = \\mathbb{E}_y[0] = 0 $$\nTaking the limit of the entire equation gives:\n$$ u(y) = v(y) - 0 = v(y) $$\nThis confirms that our solution to the BVP, $v(y)=(y-a)(b-y)$, is indeed the desired expected exit time $u(y)$.\n\nThe problem specifies the starting point as $x \\in (a,b)$. So we substitute $y=x$ into our derived expression for $u(y)$:\n$$ u(x) = (x-a)(b-x) $$\nThis is the explicit expression for the expected first exit time.", "answer": "$$\n\\boxed{(x-a)(b-x)}\n$$", "id": "2986589"}]}