{
    "hands_on_practices": [
        {
            "introduction": "To begin our hands-on exploration, we will focus on the fundamental mechanism of the Metropolis-Hastings algorithm: the acceptance probability calculation. This ratio is the core decision-making component of the sampler, designed to ensure that the resulting Markov chain satisfies the detailed balance condition and ultimately converges to the desired target distribution. This first practice  provides a direct application of the acceptance formula to a simple, discrete state space, allowing you to build intuition for the interplay between the target probabilities, $\\pi(x)$, and the proposal distribution, $Q(j|i)$.",
            "id": "1343441",
            "problem": "A simulation generates states from the set of non-negative integers $\\{0, 1, 2, \\dots \\}$. The objective is to sample from a target probability distribution where the probability of being in state $k$, denoted $\\pi(k)$, is proportional to $(1/2)^k$.\n\nThe simulation uses a Markov chain which transitions between states. At any given state $i > 0$, a proposal for the next state, $j$, is made by choosing either $j=i-1$ or $j=i+1$ with equal probability of $1/2$. If the current state is $i=0$, the proposal is always to state $j=1$. The transition probability from state $i$ to a proposed state $j$ is denoted $Q(j|i)$.\n\nThe decision to accept the proposed move is determined by the Metropolis-Hastings acceptance probability.\n\nSuppose the chain is currently at state $X_t=3$, and a move to the candidate state $y=4$ is proposed. Calculate the probability that this move is accepted. Express your answer as an exact value.",
            "solution": "We are given a target distribution on non-negative integers with probabilities proportional to $(1/2)^{k}$. Write the target as\n$$\n\\pi(k)=C\\left(\\frac{1}{2}\\right)^{k},\n$$\nwhere $C$ is the normalizing constant (which will cancel in the Metropolis-Hastings ratio).\n\nThe proposal kernel $Q(j\\mid i)$ is defined by:\n- If $i>0$, then $Q(i-1\\mid i)=\\frac{1}{2}$ and $Q(i+1\\mid i)=\\frac{1}{2}$.\n- If $i=0$, then $Q(1\\mid 0)=1$.\n\nThe Metropolis-Hastings acceptance probability for a move from current state $i$ to proposed state $y$ is\n$$\n\\alpha(i\\to y)=\\min\\left\\{1,\\ \\frac{\\pi(y)\\,Q(i\\mid y)}{\\pi(i)\\,Q(y\\mid i)}\\right\\}.\n$$\n\nHere, the current state is $i=3$ and the proposal is $y=4$. Since both $i=3$ and $y=4$ are greater than $0$, we have\n$$\nQ(4\\mid 3)=\\frac{1}{2},\\qquad Q(3\\mid 4)=\\frac{1}{2}.\n$$\nTherefore,\n$$\n\\frac{\\pi(4)\\,Q(3\\mid 4)}{\\pi(3)\\,Q(4\\mid 3)}\n=\\frac{C\\left(\\frac{1}{2}\\right)^{4}\\cdot \\frac{1}{2}}{C\\left(\\frac{1}{2}\\right)^{3}\\cdot \\frac{1}{2}}\n=\\frac{\\left(\\frac{1}{2}\\right)^{4}}{\\left(\\frac{1}{2}\\right)^{3}}\n=\\frac{1}{2}.\n$$\nThus, the acceptance probability is\n$$\n\\alpha(3\\to 4)=\\min\\left\\{1,\\ \\frac{1}{2}\\right\\}=\\frac{1}{2}.\n$$",
            "answer": "$$\\boxed{\\frac{1}{2}}$$"
        },
        {
            "introduction": "A well-functioning MCMC sampler must not only accept moves but also efficiently explore the entire state space, especially in complex, multimodal landscapes. This practice  delves into the critical trade-off between local exploration and global discovery, a central challenge in tuning MCMC algorithms. By quantitatively comparing the acceptance of a small, local proposal versus a large, ambitious jump between two modes, you will see firsthand why the choice of proposal step size is essential for ensuring the sampler does not become trapped in a single region of high probability.",
            "id": "1401728",
            "problem": "A researcher is implementing the Metropolis-Hastings (MH) algorithm to generate samples from a one-dimensional target probability distribution. The probability density function, $p(x)$, of this distribution is known to be proportional to a function $f(x)$, where $f(x) = \\exp(8x^2 - x^4)$. The algorithm proceeds by proposing a new state, $x'$, from the current state, $x_t$, using a proposal distribution $q(x'|x_t)$. For this particular implementation, the proposal distribution is a symmetric normal distribution, $q(x'|x_t) = N(x'|x_t, \\sigma^2)$, which simplifies the MH procedure to the Metropolis algorithm.\n\nSuppose the sampler is currently at the state $x_t = 2.0$, which corresponds to a local maximum (a mode) of the target probability density. The researcher wishes to understand how the acceptance probability changes for different types of proposed moves. They consider two specific, hypothetical proposals:\n\n1.  A small, local move to the proposed state $x'_S = 2.1$.\n2.  A large, exploratory move to the proposed state $x'_L = -1.5$, which is on the other side of a low-probability region centered at $x=0$.\n\nLet $A_S$ be the acceptance probability for the small move from $x_t$ to $x'_S$, and let $A_L$ be the acceptance probability for the large move from $x_t$ to $x'_L$.\n\nCalculate the ratio $\\frac{A_S}{A_L}$. Round your final answer to three significant figures.",
            "solution": "In the Metropolis-Hastings algorithm, the acceptance probability for a proposal from $x_{t}$ to $x'$ is\n$$\nA(x_{t}\\to x')=\\min\\left(1,\\frac{p(x')\\,q(x_{t}|x')}{p(x_{t})\\,q(x'|x_{t})}\\right).\n$$\nFor a symmetric proposal $q(x'|x_{t})=q(x_{t}|x')$, this reduces to the Metropolis rule\n$$\nA(x_{t}\\to x')=\\min\\left(1,\\frac{p(x')}{p(x_{t})}\\right).\n$$\nGiven $p(x)\\propto f(x)$ with $f(x)=\\exp(8x^{2}-x^{4})$, the normalization cancels in the ratio, so\n$$\n\\frac{p(x')}{p(x_{t})}=\\frac{f(x')}{f(x_{t})}=\\exp\\!\\left(8\\bigl(x'^{2}-x_{t}^{2}\\bigr)-\\bigl(x'^{4}-x_{t}^{4}\\bigr)\\right).\n$$\n\nFor the small move $x_{t}=2.0$ to $x'_{S}=2.1$:\n- $x_{t}^{2}=4$, $x_{t}^{4}=16$; $x_{S}'^{2}=4.41$, $x_{S}'^{4}=19.4481$.\n- Exponent difference:\n$$\n8\\bigl(4.41-4\\bigr)-\\bigl(19.4481-16\\bigr)=8\\cdot 0.41-3.4481=3.28-3.4481=-0.1681.\n$$\nThus\n$$\n\\frac{p(x'_{S})}{p(x_{t})}=\\exp(-0.1681)1,\\quad A_{S}=\\exp(-0.1681).\n$$\n\nFor the large move $x_{t}=2.0$ to $x'_{L}=-1.5$:\n- $x_{L}'^{2}=2.25$, $x_{L}'^{4}=5.0625$.\n- Exponent difference:\n$$\n8\\bigl(2.25-4\\bigr)-\\bigl(5.0625-16\\bigr)=8\\cdot(-1.75)-(-10.9375)=-14+10.9375=-3.0625.\n$$\nThus\n$$\n\\frac{p(x'_{L})}{p(x_{t})}=\\exp(-3.0625)1,\\quad A_{L}=\\exp(-3.0625).\n$$\n\nTherefore, the ratio of acceptance probabilities is\n$$\n\\frac{A_{S}}{A_{L}}=\\frac{\\exp(-0.1681)}{\\exp(-3.0625)}=\\exp(2.8944)\\approx 18.1\n$$\nrounded to three significant figures.",
            "answer": "$$\\boxed{18.1}$$"
        },
        {
            "introduction": "The theoretical guarantee that an MCMC sampler will converge to the correct target distribution rests on a critical assumption: ergodicity. An ergodic Markov chain is one that can eventually reach any part of the state space from any other part. This final exercise  presents a crucial cautionary tale where this assumption breaks down. By analyzing a sampler on a state space with disconnected regions, you will discover how a seemingly reasonable local proposal mechanism can produce a non-ergodic (reducible) chain, leading to biased and fundamentally incorrect results.",
            "id": "1401742",
            "problem": "A statistician is using a Markov Chain Monte Carlo (MCMC) algorithm to sample from a one-dimensional target probability density $p(x)$. The state space $\\mathcal{X}$ for the random variable $x$ is defined as the union of two disjoint intervals: $\\mathcal{X} = [-2, -1] \\cup [1, 2]$.\n\nThe unnormalized target density, $f(x)$, is defined piecewise as:\n$$\nf(x) = \\begin{cases}\n1  \\text{if } x \\in [-2, -1] \\\\\n3  \\text{if } x \\in [1, 2] \\\\\n0  \\text{otherwise}\n\\end{cases}\n$$\nThe normalized target density is $p(x) = f(x) / Z$, where $Z = \\int_{\\mathcal{X}} f(x) dx$.\n\nThe sampler uses the Metropolis-Hastings algorithm. At each step, given the current state $x_t$, a candidate state $x'$ is proposed from a symmetric proposal distribution $q(x'|x_t)$ which is a uniform distribution over the interval $[x_t - 0.5, x_t + 0.5]$. If the proposed state $x'$ falls outside the state space $\\mathcal{X}$, it is automatically rejected.\n\nThe sampler is initialized at the state $x_0 = 1.5$. It is then run for a very large number of iterations. According to the theory of MCMC, the long-run average of the samples, $\\frac{1}{N}\\sum_{i=1}^N x_i$, should converge to the expected value of $x$ under the stationary distribution of the chain.\n\nDetermine the numerical value to which the sample mean of $x$ will converge. Express your answer as an exact fraction.",
            "solution": "The unnormalized target density is piecewise constant: $f(x)=1$ on $[-2,-1]$, $f(x)=3$ on $[1,2]$, and $0$ otherwise. The normalizing constant is\n$$\nZ=\\int_{\\mathcal{X}} f(x)\\,dx=\\int_{-2}^{-1} 1\\,dx+\\int_{1}^{2} 3\\,dx=(x)\\big|_{-2}^{-1}+3(x)\\big|_{1}^{2}=1+3=4.\n$$\nThus the full-space normalized target density is $p(x)=f(x)/Z$, which places total mass $\\int_{-2}^{-1} p(x)\\,dx=\\frac{1}{4}$ on $[-2,-1]$ and $\\int_{1}^{2} p(x)\\,dx=\\frac{3}{4}$ on $[1,2]$.\n\nThe Metropolis-Hastings proposal is symmetric: $q(x'|x)$ is uniform on $[x-0.5,x+0.5]$. Proposals falling outside $\\mathcal{X}$ are rejected, which is equivalent to the standard MH rule with target density zero outside $\\mathcal{X}$. Crucially, because the maximum proposal step size is $0.5$ while the gap between the two intervals is $2$, there is zero probability to move from one interval to the other in any number of accepted steps: from any $x\\in[1,2]$, the proposal support $[x-0.5,x+0.5]\\subset[0.5,2.5]$, so any proposed $x'1$ or $x'2$ lies outside $\\mathcal{X}$ and is rejected. Therefore the chain has two closed communicating classes, and starting at $x_{0}=1.5\\in[1,2]$ it remains in $[1,2]$ forever.\n\nWithin $[1,2]$, $f(x)\\equiv 3$ is constant, so for any proposed $x'\\in[1,2]$ the Metropolis-Hastings acceptance probability is $\\min\\{1,f(x')/f(x)\\}=1$. The invariant distribution of the chain restricted to this class is proportional to $f$ on $[1,2]$ and hence is uniform on $[1,2]$:\n$$\ng(x)=\\frac{f(x)}{\\int_{1}^{2} f(u)\\,du}=\\frac{3}{\\int_{1}^{2}3\\,du}=\\frac{3}{3}=1\\quad\\text{for }x\\in[1,2],\n$$\nand $g(x)=0$ otherwise. Consequently, the long-run sample mean converges to the expectation of $X$ under $g$, namely\n$$\n\\mathbb{E}_{g}[X]=\\int_{1}^{2} x\\,g(x)\\,dx=\\int_{1}^{2} x\\,dx=\\frac{1}{2}\\left(x^{2}\\right)\\bigg|_{1}^{2}=\\frac{1}{2}\\left(4-1\\right)=\\frac{3}{2}.\n$$\nBy the ergodic theorem for Markov chains within a closed communicating class, the empirical mean $\\frac{1}{N}\\sum_{i=1}^{N} x_{i}$ converges almost surely to $\\mathbb{E}_{g}[X]=\\frac{3}{2}$.",
            "answer": "$$\\boxed{\\frac{3}{2}}$$"
        }
    ]
}