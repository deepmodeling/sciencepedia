{
    "hands_on_practices": [
        {
            "introduction": "A cornerstone of continuum mechanics is the ability to formulate physical laws that are independent of the observer's coordinate system. Principal invariants of a tensor provide exactly this kind of objective, basis-independent description. This first exercise focuses on the fundamental skill of computing these three essential quantities directly from a tensor's components, using definitions based on the trace and determinant, without the intermediate step of solving for eigenvalues .",
            "id": "3814787",
            "problem": "In multiscale modeling and analysis, effective constitutive laws often depend on scalar quantities extracted from second-order tensors that are invariant under changes of basis. For a linear operator represented by a real $3 \\times 3$ matrix $\\boldsymbol{A}$ acting on a three-dimensional vector space, the three principal invariants $I_1$, $I_2$, and $I_3$ are defined in terms of the characteristic polynomial of $\\boldsymbol{A}$. These invariants are used to parameterize isotropic scale-bridging relations and must be computed without reference to any particular basis.\n\nConsider the coarse-grained rate operator\n$$\n\\boldsymbol{A} \\;=\\;\n\\begin{pmatrix}\n4 & -2 & 1 \\\\\n0 & 3 & -1 \\\\\n2 & 1 & 5\n\\end{pmatrix}.\n$$\nStarting from the basis-independent characterization of principal invariants via the characteristic polynomial of $\\boldsymbol{A}$ and fundamental identities for traces and determinants, derive expressions for $I_1$, $I_2$, and $I_3$ that do not require computing the eigenvalues of $\\boldsymbol{A}$. Then evaluate these expressions for the given $\\boldsymbol{A}$.\n\nExpress your final answer as the ordered triple $(I_1, I_2, I_3)$, using exact integers. Do not compute or use the eigenvalues of $\\boldsymbol{A}$. No rounding is required, and no units are associated with the invariants.",
            "solution": "The problem requires the derivation and calculation of the three principal invariants, $I_1$, $I_2$, and $I_3$, of a given $3 \\times 3$ matrix $\\boldsymbol{A}$ without computing its eigenvalues. The principal invariants are coefficients of the characteristic polynomial of the matrix, which is a basis-independent property.\n\nLet $\\boldsymbol{A}$ be a linear operator on a three-dimensional vector space, represented by a $3 \\times 3$ matrix in some basis. The characteristic equation of $\\boldsymbol{A}$ is given by $\\det(\\boldsymbol{A} - \\lambda\\boldsymbol{I}) = 0$, where $\\lambda$ represents the eigenvalues of $\\boldsymbol{A}$ and $\\boldsymbol{I}$ is the $3 \\times 3$ identity matrix. The characteristic polynomial, $p(\\lambda) = \\det(\\boldsymbol{A} - \\lambda\\boldsymbol{I})$, can be written in terms of the principal invariants. A standard convention in continuum mechanics expresses the polynomial as:\n$$\np(\\lambda) = -\\lambda^3 + I_1 \\lambda^2 - I_2 \\lambda + I_3\n$$\nOur goal is to find expressions for $I_1$, $I_2$, and $I_3$ using basis-invariant tensor operations, specifically the trace ($\\mathrm{tr}$) and determinant ($\\det$), and then evaluate them for the given matrix $\\boldsymbol{A}$.\n\nThe matrix is given as:\n$$\n\\boldsymbol{A} \\;=\\;\n\\begin{pmatrix}\n4 & -2 & 1 \\\\\n0 & 3 & -1 \\\\\n2 & 1 & 5\n\\end{pmatrix}\n$$\n\nFirst, we derive the general expressions for the invariants.\n\n**Invariant $I_1$**\nThe first invariant, $I_1$, is the coefficient of $\\lambda^2$. By expanding the determinant $\\det(\\boldsymbol{A} - \\lambda\\boldsymbol{I})$, we can identify the terms that contribute to the $\\lambda^2$ power. The characteristic polynomial is:\n$$\n\\det\\begin{pmatrix}\nA_{11}-\\lambda & A_{12} & A_{13} \\\\\nA_{21} & A_{22}-\\lambda & A_{23} \\\\\nA_{31} & A_{32} & A_{33}-\\lambda\n\\end{pmatrix} = 0\n$$\nThe term with the highest power of $\\lambda$, which is $\\lambda^3$, arises from the product of the diagonal elements: $(A_{11}-\\lambda)(A_{22}-\\lambda)(A_{33}-\\lambda)$. The expansion of this product is $-\\lambda^3 + (A_{11}+A_{22}+A_{33})\\lambda^2 + \\dots$. No other term in the full determinant expansion contains powers of $\\lambda$ as high as $\\lambda^2$. Therefore, the coefficient of $\\lambda^2$ in $p(\\lambda)$ is $A_{11}+A_{22}+A_{33}$, which is the trace of $\\boldsymbol{A}$.\n$$\nI_1 = A_{11}+A_{22}+A_{33} = \\mathrm{tr}(\\boldsymbol{A})\n$$\n\n**Invariant $I_3$**\nThe third invariant, $I_3$, is the constant term in the polynomial. This can be found by evaluating $p(\\lambda)$ at $\\lambda=0$.\n$$\np(0) = \\det(\\boldsymbol{A} - 0 \\cdot \\boldsymbol{I}) = \\det(\\boldsymbol{A})\n$$\nFrom the polynomial form, $p(0) = -0^3 + I_1 \\cdot 0^2 - I_2 \\cdot 0 + I_3 = I_3$. Thus, the third invariant is the determinant of the matrix.\n$$\nI_3 = \\det(\\boldsymbol{A})\n$$\n\n**Invariant $I_2$**\nThe second invariant, $I_2$, is the negative of the coefficient of $\\lambda$. A direct expansion of the determinant to find the linear term in $\\lambda$ is cumbersome. A more elegant and insightful method utilizes the relationship between invariants and the traces of the powers of the matrix. If $\\lambda_1, \\lambda_2, \\lambda_3$ are the eigenvalues of $\\boldsymbol{A}$, the invariants are the elementary symmetric polynomials in the eigenvalues:\n$I_1 = \\lambda_1 + \\lambda_2 + \\lambda_3 = \\mathrm{tr}(\\boldsymbol{A})$\n$I_2 = \\lambda_1\\lambda_2 + \\lambda_2\\lambda_3 + \\lambda_3\\lambda_1$\n$I_3 = \\lambda_1\\lambda_2\\lambda_3 = \\det(\\boldsymbol{A})$\n\nWe also know that the trace of $\\boldsymbol{A}^k$ is the sum of the $k$-th powers of the eigenvalues: $\\mathrm{tr}(\\boldsymbol{A}^k) = \\lambda_1^k + \\lambda_2^k + \\lambda_3^k$.\nConsider the square of the first invariant:\n$$\nI_1^2 = (\\lambda_1 + \\lambda_2 + \\lambda_3)^2 = \\lambda_1^2 + \\lambda_2^2 + \\lambda_3^2 + 2(\\lambda_1\\lambda_2 + \\lambda_2\\lambda_3 + \\lambda_3\\lambda_1)\n$$\nRecognizing the terms, we have:\n$$\n(\\mathrm{tr}(\\boldsymbol{A}))^2 = \\mathrm{tr}(\\boldsymbol{A}^2) + 2 I_2\n$$\nSolving for $I_2$ gives a formula that depends only on traces, satisfying the problem's constraints:\n$$\nI_2 = \\frac{1}{2} \\left[ (\\mathrm{tr}(\\boldsymbol{A}))^2 - \\mathrm{tr}(\\boldsymbol{A}^2) \\right]\n$$\n\nNow we apply these derived formulas to the given matrix $\\boldsymbol{A}$.\n\n**Calculation of $I_1$**:\nThe first invariant is the trace of $\\boldsymbol{A}$.\n$$\nI_1 = \\mathrm{tr}(\\boldsymbol{A}) = 4 + 3 + 5 = 12\n$$\n\n**Calculation of $I_3$**:\nThe third invariant is the determinant of $\\boldsymbol{A}$. We compute this using cofactor expansion along the first row.\n$$\nI_3 = \\det(\\boldsymbol{A}) = 4 \\begin{vmatrix} 3 & -1 \\\\ 1 & 5 \\end{vmatrix} - (-2) \\begin{vmatrix} 0 & -1 \\\\ 2 & 5 \\end{vmatrix} + 1 \\begin{vmatrix} 0 & 3 \\\\ 2 & 1 \\end{vmatrix}\n$$\n$$\nI_3 = 4((3)(5) - (-1)(1)) + 2((0)(5) - (-1)(2)) + 1((0)(1) - (3)(2))\n$$\n$$\nI_3 = 4(15 + 1) + 2(0 + 2) + 1(0 - 6)\n$$\n$$\nI_3 = 4(16) + 2(2) - 6 = 64 + 4 - 6 = 62\n$$\n\n**Calculation of $I_2$**:\nTo calculate $I_2$, we first need to compute $\\boldsymbol{A}^2$ and its trace.\n$$\n\\boldsymbol{A}^2 = \\boldsymbol{A}\\boldsymbol{A} =\n\\begin{pmatrix}\n4 & -2 & 1 \\\\\n0 & 3 & -1 \\\\\n2 & 1 & 5\n\\end{pmatrix}\n\\begin{pmatrix}\n4 & -2 & 1 \\\\\n0 & 3 & -1 \\\\\n2 & 1 & 5\n\\end{pmatrix}\n$$\n$$\n\\boldsymbol{A}^2 =\n\\begin{pmatrix}\n(4)(4)+(-2)(0)+(1)(2) & (4)(-2)+(-2)(3)+(1)(1) & (4)(1)+(-2)(-1)+(1)(5) \\\\\n(0)(4)+(3)(0)+(-1)(2) & (0)(-2)+(3)(3)+(-1)(1) & (0)(1)+(3)(-1)+(-1)(5) \\\\\n(2)(4)+(1)(0)+(5)(2) & (2)(-2)+(1)(3)+(5)(1) & (2)(1)+(1)(-1)+(5)(5)\n\\end{pmatrix}\n$$\n$$\n\\boldsymbol{A}^2 =\n\\begin{pmatrix}\n18 & -13 & 11 \\\\\n-2 & 8 & -8 \\\\\n18 & 4 & 26\n\\end{pmatrix}\n$$\nThe trace of $\\boldsymbol{A}^2$ is the sum of its diagonal elements:\n$$\n\\mathrm{tr}(\\boldsymbol{A}^2) = 18 + 8 + 26 = 52\n$$\nNow we can compute $I_2$:\n$$\nI_2 = \\frac{1}{2} \\left[ (\\mathrm{tr}(\\boldsymbol{A}))^2 - \\mathrm{tr}(\\boldsymbol{A}^2) \\right] = \\frac{1}{2} \\left[ (12)^2 - 52 \\right]\n$$\n$$\nI_2 = \\frac{1}{2} (144 - 52) = \\frac{1}{2} (92) = 46\n$$\n\nThus, the three principal invariants for the given matrix $\\boldsymbol{A}$ are $I_1 = 12$, $I_2 = 46$, and $I_3 = 62$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n12 & 46 & 62\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "This practice solidifies the crucial link between a tensor's principal values (its eigenvalues) and its principal invariants. By first finding the principal stresses of a given Cauchy stress tensor and then independently calculating its invariants, you will explicitly verify their relationship as elementary symmetric polynomials . This exercise reinforces the idea that invariants are coefficients of the characteristic polynomial whose roots are the principal values.",
            "id": "3814789",
            "problem": "In an upscaled description of a statistically isotropic, linearly elastic composite, the Cauchy stress tensor at a material point is represented in an arbitrary orthonormal basis by the symmetric tensor\n$$\n\\boldsymbol{\\sigma} \\;=\\;\n\\begin{pmatrix}\n5 & 2 & 2 \\\\\n2 & 5 & 2 \\\\\n2 & 2 & 5\n\\end{pmatrix}.\n$$\nWorking from first principles appropriate to tensor analysis, proceed as follows.\n- Define the principal values as the eigenvalues of the linear map represented by $\\boldsymbol{\\sigma}$ and define the principal invariants $I_1$, $I_2$, and $I_3$ as the basis-independent coefficients of the characteristic polynomial of $\\boldsymbol{\\sigma}$.\n- Starting from the characteristic polynomial definition and standard linear algebraic identities, derive the relationship between the coefficients and the elementary symmetric polynomials of the eigenvalues. Use this to compute the principal values of $\\boldsymbol{\\sigma}$.\n- Independently, compute $I_1$, $I_2$, and $I_3$ directly from $\\boldsymbol{\\sigma}$ without diagonalizing it, using only standard invariant operations on $\\boldsymbol{\\sigma}$ that do not depend on a particular basis.\n- Verify that the sum, the sum of pairwise products, and the product of the principal values agree with $I_1$, $I_2$, and $I_3$, respectively.\n\nReport as your final answer the three principal values of $\\boldsymbol{\\sigma}$, sorted in nonincreasing order, as a single row matrix. No rounding is necessary, and no units are required.",
            "solution": "The problem requires a detailed analysis of the principal values and invariants of the given Cauchy stress tensor\n$$\n\\boldsymbol{\\sigma} \\;=\\;\n\\begin{pmatrix}\n5 & 2 & 2 \\\\\n2 & 5 & 2 \\\\\n2 & 2 & 5\n\\end{pmatrix}.\n$$\nThe analysis will proceed in four distinct steps as outlined in the problem statement.\n\nFirst, we define the principal values and principal invariants. The principal values, denoted here by $\\sigma_1$, $\\sigma_2$, and $\\sigma_3$, are the eigenvalues of the linear map represented by the tensor $\\boldsymbol{\\sigma}$. They are the roots $\\lambda$ of the characteristic equation $\\det(\\boldsymbol{\\sigma} - \\lambda\\boldsymbol{I}) = 0$, where $\\boldsymbol{I}$ is the second-order identity tensor. The characteristic polynomial for a second-order tensor in a three-dimensional space is a cubic polynomial in $\\lambda$, which can be written in terms of its principal invariants $I_1$, $I_2$, and $I_3$ as:\n$$\nP(\\lambda) = \\det(\\boldsymbol{\\sigma} - \\lambda\\boldsymbol{I}) = -\\lambda^3 + I_1\\lambda^2 - I_2\\lambda + I_3\n$$\nThe principal invariants $I_1$, $I_2$, and $I_3$ are the scalar coefficients of this polynomial and are independent of the basis chosen to represent the tensor.\n\nSecond, we derive the relationship between the principal invariants and the principal values, and then compute the principal values. Since the principal values $\\sigma_1$, $\\sigma_2$, and $\\sigma_3$ are the roots of the characteristic polynomial $P(\\lambda)=0$, the polynomial can be expressed in factored form:\n$$\nP(\\lambda) = -(\\lambda - \\sigma_1)(\\lambda - \\sigma_2)(\\lambda - \\sigma_3)\n$$\nExpanding this expression gives:\n$$\nP(\\lambda) = -[\\lambda^2 - (\\sigma_1 + \\sigma_2)\\lambda + \\sigma_1\\sigma_2](\\lambda - \\sigma_3)\n$$\n$$\nP(\\lambda) = -[\\lambda^3 - \\sigma_3\\lambda^2 - (\\sigma_1 + \\sigma_2)\\lambda^2 + \\sigma_3(\\sigma_1 + \\sigma_2)\\lambda + \\sigma_1\\sigma_2\\lambda - \\sigma_1\\sigma_2\\sigma_3]\n$$\n$$\nP(\\lambda) = -\\lambda^3 + (\\sigma_1 + \\sigma_2 + \\sigma_3)\\lambda^2 - (\\sigma_1\\sigma_2 + \\sigma_1\\sigma_3 + \\sigma_2\\sigma_3)\\lambda + (\\sigma_1\\sigma_2\\sigma_3)\n$$\nBy comparing the coefficients of this expanded form with the definition $P(\\lambda) = -\\lambda^3 + I_1\\lambda^2 - I_2\\lambda + I_3$, we establish the fundamental relationships:\n$$\nI_1 = \\sigma_1 + \\sigma_2 + \\sigma_3\n$$\n$$\nI_2 = \\sigma_1\\sigma_2 + \\sigma_1\\sigma_3 + \\sigma_2\\sigma_3\n$$\n$$\nI_3 = \\sigma_1\\sigma_2\\sigma_3\n$$\nThese are the elementary symmetric polynomials of the principal values.\n\nTo compute the principal values of the given tensor $\\boldsymbol{\\sigma}$, we must solve its characteristic equation:\n$$\n\\det(\\boldsymbol{\\sigma} - \\lambda\\boldsymbol{I}) = \\det\\begin{pmatrix} 5-\\lambda & 2 & 2 \\\\ 2 & 5-\\lambda & 2 \\\\ 2 & 2 & 5-\\lambda \\end{pmatrix} = 0\n$$\nCalculating the determinant:\n$$\n(5-\\lambda)((5-\\lambda)^2 - 4) - 2(2(5-\\lambda) - 4) + 2(4 - 2(5-\\lambda)) = 0\n$$\n$$\n(5-\\lambda)(\\lambda^2 - 10\\lambda + 25 - 4) - 2(10 - 2\\lambda - 4) + 2(4 - 10 + 2\\lambda) = 0\n$$\n$$\n(5-\\lambda)(\\lambda^2 - 10\\lambda + 21) - 2(6 - 2\\lambda) + 2(-6 + 2\\lambda) = 0\n$$\n$$\n5\\lambda^2 - 50\\lambda + 105 - \\lambda^3 + 10\\lambda^2 - 21\\lambda - 12 + 4\\lambda - 12 + 4\\lambda = 0\n$$\nCombining terms, we obtain the characteristic polynomial:\n$$\n-\\lambda^3 + 15\\lambda^2 - 63\\lambda + 81 = 0\n$$\nTo find the roots, we can test integer divisors of the constant term $81$, which are $\\pm 1, \\pm 3, \\pm 9, \\dots$. Let's test $\\lambda = 3$:\n$$\n-(3)^3 + 15(3)^2 - 63(3) + 81 = -27 + 15(9) - 189 + 81 = -27 + 135 - 189 + 81 = (-27 - 189) + (135 + 81) = -216 + 216 = 0\n$$\nSince $\\lambda = 3$ is a root, $(\\lambda - 3)$ is a factor. We perform polynomial division of $-\\lambda^3 + 15\\lambda^2 - 63\\lambda + 81$ by $(\\lambda - 3)$:\n$$\n(-\\lambda^3 + 15\\lambda^2 - 63\\lambda + 81) \\div (\\lambda - 3) = -\\lambda^2 + 12\\lambda - 27\n$$\nSo the equation becomes:\n$$\n(\\lambda - 3)(-\\lambda^2 + 12\\lambda - 27) = -(\\lambda - 3)(\\lambda^2 - 12\\lambda + 27) = 0\n$$\nFactoring the quadratic term $\\lambda^2 - 12\\lambda + 27 = 0$, we get $(\\lambda-3)(\\lambda-9)=0$.\nThus, the full factorization of the characteristic polynomial is $-(\\lambda - 9)(\\lambda - 3)(\\lambda - 3) = 0$.\nThe roots, which are the principal values of $\\boldsymbol{\\sigma}$, are $\\lambda = 9$, $\\lambda = 3$, and $\\lambda = 3$. Sorted in nonincreasing order, they are:\n$$\n\\sigma_1 = 9, \\quad \\sigma_2 = 3, \\quad \\sigma_3 = 3\n$$\n\nThird, we compute the principal invariants $I_1$, $I_2$, and $I_3$ directly from the components of $\\boldsymbol{\\sigma}$ using standard basis-independent tensor operations.\nThe first invariant, $I_1$, is the trace of the tensor:\n$$\nI_1 = \\text{tr}(\\boldsymbol{\\sigma}) = \\sigma_{kk} = 5 + 5 + 5 = 15\n$$\nThe second invariant, $I_2$, can be computed as the sum of the principal minors of the matrix representation:\n$$\nI_2 = \\det\\begin{pmatrix} 5 & 2 \\\\ 2 & 5 \\end{pmatrix} + \\det\\begin{pmatrix} 5 & 2 \\\\ 2 & 5 \\end{pmatrix} + \\det\\begin{pmatrix} 5 & 2 \\\\ 2 & 5 \\end{pmatrix}\n$$\n$$\nI_2 = (5 \\cdot 5 - 2 \\cdot 2) + (5 \\cdot 5 - 2 \\cdot 2) + (5 \\cdot 5 - 2 \\cdot 2) = (25-4) + (25-4) + (25-4) = 21 + 21 + 21 = 63\n$$\nAlternatively, $I_2 = \\frac{1}{2}[(\\text{tr}(\\boldsymbol{\\sigma}))^2 - \\text{tr}(\\boldsymbol{\\sigma}^2)]$.\nThe third invariant, $I_3$, is the determinant of the tensor:\n$$\nI_3 = \\det(\\boldsymbol{\\sigma}) = \\det\\begin{pmatrix} 5 & 2 & 2 \\\\ 2 & 5 & 2 \\\\ 2 & 2 & 5 \\end{pmatrix}\n$$\n$$\nI_3 = 5(5 \\cdot 5 - 2 \\cdot 2) - 2(2 \\cdot 5 - 2 \\cdot 2) + 2(2 \\cdot 2 - 2 \\cdot 5) = 5(21) - 2(6) + 2(-6) = 105 - 12 - 12 = 81\n$$\nSo, the directly computed invariants are $I_1 = 15$, $I_2 = 63$, and $I_3 = 81$. These match the coefficients of the characteristic polynomial we derived earlier.\n\nFourth, we verify that the elementary symmetric polynomials of the computed principal values agree with the directly computed invariants.\nThe principal values are $\\sigma_1 = 9$, $\\sigma_2 = 3$, $\\sigma_3 = 3$.\nThe directly computed invariants are $I_1 = 15$, $I_2 = 63$, $I_3 = 81$.\nVerification for $I_1$:\n$$\n\\sigma_1 + \\sigma_2 + \\sigma_3 = 9 + 3 + 3 = 15\n$$\nThis matches $I_1$.\nVerification for $I_2$:\n$$\n\\sigma_1\\sigma_2 + \\sigma_1\\sigma_3 + \\sigma_2\\sigma_3 = (9)(3) + (9)(3) + (3)(3) = 27 + 27 + 9 = 63\n$$\nThis matches $I_2$.\nVerification for $I_3$:\n$$\n\\sigma_1\\sigma_2\\sigma_3 = (9)(3)(3) = 9 \\times 9 = 81\n$$\nThis matches $I_3$.\nThe verification is successful, confirming the consistency of our calculations. The final answer is the three principal values, sorted in nonincreasing order.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 9 & 3 & 3 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Building on the analysis of single tensors, this exercise investigates the interaction between two distinct symmetric tensors. You will explore the trace of their product, $\\mathrm{tr}(\\boldsymbol{A}\\boldsymbol{B})$, and demonstrate through a concrete counterexample that it is not, in general, equal to the simple dot product of their ordered principal values . This important result reveals that the relative orientation of the tensors' principal directions—a concept known as coaxiality—is critical in determining the outcome of such products.",
            "id": "3814777",
            "problem": "Consider symmetric second-order tensors in a $2$-dimensional Euclidean space. Principal values are defined as the eigenvalues of a symmetric tensor, and principal directions as the corresponding orthonormal eigenvectors. Two tensors are said to be coaxial if they share the same principal directions. The trace of a tensor is the sum of its diagonal entries, and the trace of a product is defined as the trace of the resulting tensor after matrix multiplication.\n\nDefine the tensor $\\boldsymbol{A} \\in \\mathbb{R}^{2 \\times 2}$ by $\\boldsymbol{A} = \\mathrm{diag}(2,1)$. Define the tensor $\\boldsymbol{B} \\in \\mathbb{R}^{2 \\times 2}$ by $\\boldsymbol{B} = \\boldsymbol{R} \\, \\mathrm{diag}(4,3) \\, \\boldsymbol{R}^{\\mathsf{T}}$, where $\\boldsymbol{R}$ is the proper orthogonal rotation tensor corresponding to a counterclockwise rotation by angle $\\pi/4$ radians, that is,\n$$\n\\boldsymbol{R} = \\begin{pmatrix}\n\\cos(\\pi/4) & -\\sin(\\pi/4) \\\\\n\\sin(\\pi/4) & \\cos(\\pi/4)\n\\end{pmatrix}.\n$$\n\nUsing only the definitions above and standard linear algebra properties for symmetric tensors (in particular, that symmetric tensors admit an orthonormal eigenbasis and that the trace is invariant under cyclic permutations of a product), do the following:\n\n$1.$ Argue whether $\\boldsymbol{A}$ and $\\boldsymbol{B}$ are coaxial.\n\n$2.$ Compute the exact value of $\\mathrm{tr}(\\boldsymbol{A}\\boldsymbol{B})$.\n\n$3.$ Compute the ordered principal values (from largest to smallest) of $\\boldsymbol{A}$ and $\\boldsymbol{B}$ and form their dot product in that order. Compare this value to $\\mathrm{tr}(\\boldsymbol{A}\\boldsymbol{B})$ to show that they are not equal for this pair $\\boldsymbol{A}$, $\\boldsymbol{B}$.\n\nReport as your final answer the exact value of $\\mathrm{tr}(\\boldsymbol{A}\\boldsymbol{B})$ (no rounding).",
            "solution": "The problem considers two symmetric second-order tensors in a $2$-dimensional Euclidean space, $\\boldsymbol{A}$ and $\\boldsymbol{B}$, belonging to $\\mathbb{R}^{2 \\times 2}$. The tensors are defined as:\n$$\n\\boldsymbol{A} = \\mathrm{diag}(2,1) = \\begin{pmatrix} 2 & 0 \\\\ 0 & 1 \\end{pmatrix}\n$$\nand\n$$\n\\boldsymbol{B} = \\boldsymbol{R} \\, \\mathrm{diag}(4,3) \\, \\boldsymbol{R}^{\\mathsf{T}}\n$$\nwhere $\\boldsymbol{R}$ is the rotation matrix for a counterclockwise rotation by an angle $\\theta = \\pi/4$:\n$$\n\\boldsymbol{R} = \\begin{pmatrix}\n\\cos(\\pi/4) & -\\sin(\\pi/4) \\\\\n\\sin(\\pi/4) & \\cos(\\pi/4)\n\\end{pmatrix} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix}\n1 & -1 \\\\\n1 & 1\n\\end{pmatrix}\n$$\n\n$1.$ Argument on whether $\\boldsymbol{A}$ and $\\boldsymbol{B}$ are coaxial.\n\nTwo tensors are coaxial if they share the same principal directions, which are the orthonormal eigenvectors of the tensors.\n\nFor tensor $\\boldsymbol{A}$, it is given in diagonal form. This is its spectral representation. The principal values (eigenvalues) of $\\boldsymbol{A}$ are the diagonal entries, $\\lambda_1(\\boldsymbol{A}) = 2$ and $\\lambda_2(\\boldsymbol{A}) = 1$. The corresponding principal directions (eigenvectors) are the standard basis vectors:\n$$\n\\boldsymbol{v}_1(\\boldsymbol{A}) = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\quad \\text{and} \\quad \\boldsymbol{v}_2(\\boldsymbol{A}) = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}.\n$$\n\nFor tensor $\\boldsymbol{B}$, its definition $\\boldsymbol{B} = \\boldsymbol{R} \\, \\mathrm{diag}(4,3) \\, \\boldsymbol{R}^{\\mathsf{T}}$ is its spectral decomposition. The principal values of $\\boldsymbol{B}$ are the diagonal entries of the diagonal matrix, $\\lambda_1(\\boldsymbol{B}) = 4$ and $\\lambda_2(\\boldsymbol{B}) = 3$. The principal directions of $\\boldsymbol{B}$ are the columns of the orthogonal matrix $\\boldsymbol{R}$.\n$$\n\\boldsymbol{v}_1(\\boldsymbol{B}) = \\begin{pmatrix} \\cos(\\pi/4) \\\\ \\sin(\\pi/4) \\end{pmatrix} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\n$$\n$$\n\\boldsymbol{v}_2(\\boldsymbol{B}) = \\begin{pmatrix} -\\sin(\\pi/4) \\\\ \\cos(\\pi/4) \\end{pmatrix} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} -1 \\\\ 1 \\end{pmatrix}\n$$\nThe principal directions of $\\boldsymbol{A}$ are the standard basis vectors, which align with the coordinate axes. The principal directions of $\\boldsymbol{B}$ are rotated by an angle of $\\pi/4$ with respect to the coordinate axes. Since the rotation angle $\\pi/4$ is not an integer multiple of $\\pi/2$, the set of principal directions for $\\boldsymbol{A}$, i.e., $\\{\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\\}$, is not the same as the set of principal directions for $\\boldsymbol{B}$, i.e., $\\{\\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}, \\frac{1}{\\sqrt{2}}\\begin{pmatrix} -1 \\\\ 1 \\end{pmatrix}\\}$.\nTherefore, the tensors $\\boldsymbol{A}$ and $\\boldsymbol{B}$ are not coaxial.\n\n$2.$ Computation of the exact value of $\\mathrm{tr}(\\boldsymbol{A}\\boldsymbol{B})$.\n\nFirst, we compute the matrix representation of $\\boldsymbol{B}$.\n$$\n\\boldsymbol{R}^{\\mathsf{T}} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix}\n1 & 1 \\\\\n-1 & 1\n\\end{pmatrix}\n$$\n$$\n\\boldsymbol{B} = \\boldsymbol{R} \\, \\mathrm{diag}(4,3) \\, \\boldsymbol{R}^{\\mathsf{T}} = \\left( \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 & -1 \\\\ 1 & 1 \\end{pmatrix} \\right) \\begin{pmatrix} 4 & 0 \\\\ 0 & 3 \\end{pmatrix} \\left( \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 & 1 \\\\ -1 & 1 \\end{pmatrix} \\right)\n$$\n$$\n\\boldsymbol{B} = \\frac{1}{2} \\begin{pmatrix} 1 & -1 \\\\ 1 & 1 \\end{pmatrix} \\begin{pmatrix} 4 & 4 \\\\ -3 & 3 \\end{pmatrix} = \\frac{1}{2} \\begin{pmatrix} (1)(4)+(-1)(-3) & (1)(4)+(-1)(3) \\\\ (1)(4)+(1)(-3) & (1)(4)+(1)(3) \\end{pmatrix}\n$$\n$$\n\\boldsymbol{B} = \\frac{1}{2} \\begin{pmatrix} 7 & 1 \\\\ 1 & 7 \\end{pmatrix} = \\begin{pmatrix} 7/2 & 1/2 \\\\ 1/2 & 7/2 \\end{pmatrix}\n$$\nNext, we compute the product $\\boldsymbol{A}\\boldsymbol{B}$:\n$$\n\\boldsymbol{A}\\boldsymbol{B} = \\begin{pmatrix} 2 & 0 \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} 7/2 & 1/2 \\\\ 1/2 & 7/2 \\end{pmatrix} = \\begin{pmatrix} (2)(7/2)+(0)(1/2) & (2)(1/2)+(0)(7/2) \\\\ (0)(7/2)+(1)(1/2) & (0)(1/2)+(1)(7/2) \\end{pmatrix}\n$$\n$$\n\\boldsymbol{A}\\boldsymbol{B} = \\begin{pmatrix} 7 & 1 \\\\ 1/2 & 7/2 \\end{pmatrix}\n$$\nThe trace of a tensor is the sum of its diagonal entries.\n$$\n\\mathrm{tr}(\\boldsymbol{A}\\boldsymbol{B}) = 7 + \\frac{7}{2} = \\frac{14}{2} + \\frac{7}{2} = \\frac{21}{2}\n$$\n\n$3.$ Comparison of $\\mathrm{tr}(\\boldsymbol{A}\\boldsymbol{B})$ with the dot product of ordered principal values.\n\nThe principal values of $\\boldsymbol{A}$ are $2$ and $1$. Ordered from largest to smallest, they are $\\lambda_1(\\boldsymbol{A}) = 2$ and $\\lambda_2(\\boldsymbol{A}) = 1$.\nThe principal values of $\\boldsymbol{B}$ are $4$ and $3$. Ordered from largest to smallest, they are $\\lambda_1(\\boldsymbol{B}) = 4$ and $\\lambda_2(\\boldsymbol{B}) = 3$.\n\nThe dot product of these ordered principal values is computed as:\n$$\n\\sum_{i=1}^{2} \\lambda_i(\\boldsymbol{A})\\lambda_i(\\boldsymbol{B}) = \\lambda_1(\\boldsymbol{A})\\lambda_1(\\boldsymbol{B}) + \\lambda_2(\\boldsymbol{A})\\lambda_2(\\boldsymbol{B}) = (2)(4) + (1)(3) = 8 + 3 = 11\n$$\nWe compare this value to the previously computed trace:\n$$\n\\mathrm{tr}(\\boldsymbol{A}\\boldsymbol{B}) = \\frac{21}{2} = 10.5\n$$\nThe dot product of the ordered principal values is $11$. The two values are not equal:\n$$\n\\mathrm{tr}(\\boldsymbol{A}\\boldsymbol{B}) = 10.5 \\neq 11 = \\sum_{i=1}^{2} \\lambda_i(\\boldsymbol{A})\\lambda_i(\\boldsymbol{B})\n$$\nThis inequality is expected, as the equality $\\mathrm{tr}(\\boldsymbol{A}\\boldsymbol{B}) = \\sum_{i} \\lambda_i(\\boldsymbol{A})\\lambda_i(\\boldsymbol{B})$ holds if and only if the tensors $\\boldsymbol{A}$ and $\\boldsymbol{B}$ are coaxial. As established in the first part, they are not.",
            "answer": "$$\n\\boxed{\\frac{21}{2}}\n$$"
        }
    ]
}