{
    "hands_on_practices": [
        {
            "introduction": "The principal invariants of a tensor are scalar quantities that remain unchanged under coordinate system rotations, making them fundamental descriptors of a physical state. While they are formally defined as the coefficients of the characteristic polynomial, finding the roots of this polynomial (the principal values) can be computationally intensive. This practice focuses on a more direct and efficient method for computing the invariants $I_1$, $I_2$, and $I_3$ using trace and determinant operations, a skill essential for efficiently characterizing tensors in multiscale models .",
            "id": "3814787",
            "problem": "In multiscale modeling and analysis, effective constitutive laws often depend on scalar quantities extracted from second-order tensors that are invariant under changes of basis. For a linear operator represented by a real $3 \\times 3$ matrix $\\boldsymbol{A}$ acting on a three-dimensional vector space, the three principal invariants $I_1$, $I_2$, and $I_3$ are defined in terms of the characteristic polynomial of $\\boldsymbol{A}$. These invariants are used to parameterize isotropic scale-bridging relations and must be computed without reference to any particular basis.\n\nConsider the coarse-grained rate operator\n$$\n\\boldsymbol{A} \\;=\\;\n\\begin{pmatrix}\n4 & -2 & 1 \\\\\n0 & 3 & -1 \\\\\n2 & 1 & 5\n\\end{pmatrix}.\n$$\nStarting from the basis-independent characterization of principal invariants via the characteristic polynomial of $\\boldsymbol{A}$ and fundamental identities for traces and determinants, derive expressions for $I_1$, $I_2$, and $I_3$ that do not require computing the eigenvalues of $\\boldsymbol{A}$. Then evaluate these expressions for the given $\\boldsymbol{A}$.\n\nExpress your final answer as the ordered triple $\\left(I_1, I_2, I_3\\right)$, using exact integers. Do not compute or use the eigenvalues of $\\boldsymbol{A}$. No rounding is required, and no units are associated with the invariants.",
            "solution": "The problem requires the derivation and calculation of the three principal invariants, $I_1$, $I_2$, and $I_3$, of a given $3 \\times 3$ matrix $\\boldsymbol{A}$ without computing its eigenvalues. The principal invariants are coefficients of the characteristic polynomial of the matrix, which is a basis-independent property.\n\nLet $\\boldsymbol{A}$ be a linear operator on a three-dimensional vector space, represented by a $3 \\times 3$ matrix in some basis. The characteristic equation of $\\boldsymbol{A}$ is given by $\\det(\\boldsymbol{A} - \\lambda\\boldsymbol{I}) = 0$, where $\\lambda$ represents the eigenvalues of $\\boldsymbol{A}$ and $\\boldsymbol{I}$ is the $3 \\times 3$ identity matrix. The characteristic polynomial, $p(\\lambda) = \\det(\\boldsymbol{A} - \\lambda\\boldsymbol{I})$, can be written in terms of the principal invariants. A standard convention in continuum mechanics expresses the polynomial as:\n$$\np(\\lambda) = -\\lambda^3 + I_1 \\lambda^2 - I_2 \\lambda + I_3\n$$\nOur goal is to find expressions for $I_1$, $I_2$, and $I_3$ using basis-invariant tensor operations, specifically the trace ($\\mathrm{tr}$) and determinant ($\\det$), and then evaluate them for the given matrix $\\boldsymbol{A}$.\n\nThe matrix is given as:\n$$\n\\boldsymbol{A} \\;=\\;\n\\begin{pmatrix}\n4 & -2 & 1 \\\\\n0 & 3 & -1 \\\\\n2 & 1 & 5\n\\end{pmatrix}\n$$\n\nFirst, we derive the general expressions for the invariants.\n\n**Invariant $I_1$**\nThe first invariant, $I_1$, is the coefficient of $\\lambda^2$. By expanding the determinant $\\det(\\boldsymbol{A} - \\lambda\\boldsymbol{I})$, we can identify the terms that contribute to the $\\lambda^2$ power. The characteristic polynomial is:\n$$\n\\det\\begin{pmatrix}\nA_{11}-\\lambda & A_{12} & A_{13} \\\\\nA_{21} & A_{22}-\\lambda & A_{23} \\\\\nA_{31} & A_{32} & A_{33}-\\lambda\n\\end{pmatrix} = 0\n$$\nThe term with the highest power of $\\lambda$, which is $\\lambda^3$, arises from the product of the diagonal elements: $(A_{11}-\\lambda)(A_{22}-\\lambda)(A_{33}-\\lambda)$. The expansion of this product is $-\\lambda^3 + (A_{11}+A_{22}+A_{33})\\lambda^2 + \\dots$. No other term in the full determinant expansion contains powers of $\\lambda$ as high as $\\lambda^2$. Therefore, the coefficient of $\\lambda^2$ in $p(\\lambda)$ is $A_{11}+A_{22}+A_{33}$, which is the trace of $\\boldsymbol{A}$.\n$$\nI_1 = A_{11}+A_{22}+A_{33} = \\mathrm{tr}(\\boldsymbol{A})\n$$\n\n**Invariant $I_3$**\nThe third invariant, $I_3$, is the constant term in the polynomial. This can be found by evaluating $p(\\lambda)$ at $\\lambda=0$.\n$$\np(0) = \\det(\\boldsymbol{A} - 0 \\cdot \\boldsymbol{I}) = \\det(\\boldsymbol{A})\n$$\nFrom the polynomial form, $p(0) = -0^3 + I_1 \\cdot 0^2 - I_2 \\cdot 0 + I_3 = I_3$. Thus, the third invariant is the determinant of the matrix.\n$$\nI_3 = \\det(\\boldsymbol{A})\n$$\n\n**Invariant $I_2$**\nThe second invariant, $I_2$, is the negative of the coefficient of $\\lambda$. A direct expansion of the determinant to find the linear term in $\\lambda$ is cumbersome. A more elegant and insightful method utilizes the relationship between invariants and the traces of the powers of the matrix. If $\\lambda_1, \\lambda_2, \\lambda_3$ are the eigenvalues of $\\boldsymbol{A}$, the invariants are the elementary symmetric polynomials in the eigenvalues:\n$I_1 = \\lambda_1 + \\lambda_2 + \\lambda_3 = \\mathrm{tr}(\\boldsymbol{A})$\n$I_2 = \\lambda_1\\lambda_2 + \\lambda_2\\lambda_3 + \\lambda_3\\lambda_1$\n$I_3 = \\lambda_1\\lambda_2\\lambda_3 = \\det(\\boldsymbol{A})$\n\nWe also know that the trace of $\\boldsymbol{A}^k$ is the sum of the $k$-th powers of the eigenvalues: $\\mathrm{tr}(\\boldsymbol{A}^k) = \\lambda_1^k + \\lambda_2^k + \\lambda_3^k$.\nConsider the square of the first invariant:\n$$\nI_1^2 = (\\lambda_1 + \\lambda_2 + \\lambda_3)^2 = \\lambda_1^2 + \\lambda_2^2 + \\lambda_3^2 + 2(\\lambda_1\\lambda_2 + \\lambda_2\\lambda_3 + \\lambda_3\\lambda_1)\n$$\nRecognizing the terms, we have:\n$$\n(\\mathrm{tr}(\\boldsymbol{A}))^2 = \\mathrm{tr}(\\boldsymbol{A}^2) + 2 I_2\n$$\nSolving for $I_2$ gives a formula that depends only on traces, satisfying the problem's constraints:\n$$\nI_2 = \\frac{1}{2} \\left[ (\\mathrm{tr}(\\boldsymbol{A}))^2 - \\mathrm{tr}(\\boldsymbol{A}^2) \\right]\n$$\n\nNow we apply these derived formulas to the given matrix $\\boldsymbol{A}$.\n\n**Calculation of $I_1$**:\nThe first invariant is the trace of $\\boldsymbol{A}$.\n$$\nI_1 = \\mathrm{tr}(\\boldsymbol{A}) = 4 + 3 + 5 = 12\n$$\n\n**Calculation of $I_3$**:\nThe third invariant is the determinant of $\\boldsymbol{A}$. We compute this using cofactor expansion along the first row.\n$$\nI_3 = \\det(\\boldsymbol{A}) = 4 \\begin{vmatrix} 3 & -1 \\\\ 1 & 5 \\end{vmatrix} - (-2) \\begin{vmatrix} 0 & -1 \\\\ 2 & 5 \\end{vmatrix} + 1 \\begin{vmatrix} 0 & 3 \\\\ 2 & 1 \\end{vmatrix}\n$$\n$$\nI_3 = 4((3)(5) - (-1)(1)) + 2((0)(5) - (-1)(2)) + 1((0)(1) - (3)(2))\n$$\n$$\nI_3 = 4(15 + 1) + 2(0 + 2) + 1(0 - 6)\n$$\n$$\nI_3 = 4(16) + 2(2) - 6 = 64 + 4 - 6 = 62\n$$\n\n**Calculation of $I_2$**:\nTo calculate $I_2$, we first need to compute $\\boldsymbol{A}^2$ and its trace.\n$$\n\\boldsymbol{A}^2 = \\boldsymbol{A}\\boldsymbol{A} =\n\\begin{pmatrix}\n4 & -2 & 1 \\\\\n0 & 3 & -1 \\\\\n2 & 1 & 5\n\\end{pmatrix}\n\\begin{pmatrix}\n4 & -2 & 1 \\\\\n0 & 3 & -1 \\\\\n2 & 1 & 5\n\\end{pmatrix}\n$$\n$$\n\\boldsymbol{A}^2 =\n\\begin{pmatrix}\n(4)(4)+(-2)(0)+(1)(2) & (4)(-2)+(-2)(3)+(1)(1) & (4)(1)+(-2)(-1)+(1)(5) \\\\\n(0)(4)+(3)(0)+(-1)(2) & (0)(-2)+(3)(3)+(-1)(1) & (0)(1)+(3)(-1)+(-1)(5) \\\\\n(2)(4)+(1)(0)+(5)(2) & (2)(-2)+(1)(3)+(5)(1) & (2)(1)+(1)(-1)+(5)(5)\n\\end{pmatrix}\n$$\n$$\n\\boldsymbol{A}^2 =\n\\begin{pmatrix}\n16+0+2 & -8-6+1 & 4+2+5 \\\\\n0+0-2 & 0+9-1 & 0-3-5 \\\\\n8+0+10 & -4+3+5 & 2-1+25\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n18 & -13 & 11 \\\\\n-2 & 8 & -8 \\\\\n18 & 4 & 26\n\\end{pmatrix}\n$$\nThe trace of $\\boldsymbol{A}^2$ is the sum of its diagonal elements:\n$$\n\\mathrm{tr}(\\boldsymbol{A}^2) = 18 + 8 + 26 = 52\n$$\nNow we can compute $I_2$:\n$$\nI_2 = \\frac{1}{2} \\left[ (\\mathrm{tr}(\\boldsymbol{A}))^2 - \\mathrm{tr}(\\boldsymbol{A}^2) \\right] = \\frac{1}{2} \\left[ (12)^2 - 52 \\right]\n$$\n$$\nI_2 = \\frac{1}{2} (144 - 52) = \\frac{1}{2} (92) = 46\n$$\n\nThus, the three principal invariants for the given matrix $\\boldsymbol{A}$ are $I_1 = 12$, $I_2 = 46$, and $I_3 = 62$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n12 & 46 & 62\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Principal values, such as principal stresses or strains, have direct physical significance as they represent the extremal values of a tensor quantity. These values are intrinsically linked to the tensor's invariants through the elementary symmetric polynomials. This exercise bridges the abstract definition of invariants with their physical roots by having you calculate the principal values of a stress tensor and then explicitly verifying that their sums and products indeed match the directly computed invariants $I_1$, $I_2$, and $I_3$ .",
            "id": "3814789",
            "problem": "In an upscaled description of a statistically isotropic, linearly elastic composite, the Cauchy stress tensor at a material point is represented in an arbitrary orthonormal basis by the symmetric tensor\n$$\n\\boldsymbol{\\sigma} \\;=\\;\n\\begin{pmatrix}\n5 & 2 & 2 \\\\\n2 & 5 & 2 \\\\\n2 & 2 & 5\n\\end{pmatrix}.\n$$\nWorking from first principles appropriate to tensor analysis, proceed as follows.\n- Define the principal values as the eigenvalues of the linear map represented by $\\boldsymbol{\\sigma}$ and define the principal invariants $I_1$, $I_2$, and $I_3$ as the basis-independent coefficients of the characteristic polynomial of $\\boldsymbol{\\sigma}$.\n- Starting from the characteristic polynomial definition and standard linear algebraic identities, derive the relationship between the coefficients and the elementary symmetric polynomials of the eigenvalues. Use this to compute the principal values of $\\boldsymbol{\\sigma}$.\n- Independently, compute $I_1$, $I_2$, and $I_3$ directly from $\\boldsymbol{\\sigma}$ without diagonalizing it, using only standard invariant operations on $\\boldsymbol{\\sigma}$ that do not depend on a particular basis.\n- Verify that the sum, the sum of pairwise products, and the product of the principal values agree with $I_1$, $I_2$, and $I_3$, respectively.\n\nReport as your final answer the three principal values of $\\boldsymbol{\\sigma}$, sorted in nonincreasing order, as a single row matrix. No rounding is necessary, and no units are required.",
            "solution": "The problem requires a detailed analysis of the principal values and invariants of the given Cauchy stress tensor\n$$\n\\boldsymbol{\\sigma} \\;=\\;\n\\begin{pmatrix}\n5 & 2 & 2 \\\\\n2 & 5 & 2 \\\\\n2 & 2 & 5\n\\end{pmatrix}.\n$$\nThe analysis will proceed in four distinct steps as outlined in the problem statement.\n\nFirst, we define the principal values and principal invariants. The principal values, denoted here by $\\sigma_1$, $\\sigma_2$, and $\\sigma_3$, are the eigenvalues of the linear map represented by the tensor $\\boldsymbol{\\sigma}$. They are the roots $\\lambda$ of the characteristic equation $\\det(\\boldsymbol{\\sigma} - \\lambda\\boldsymbol{I}) = 0$, where $\\boldsymbol{I}$ is the second-order identity tensor. The characteristic polynomial for a second-order tensor in a three-dimensional space is a cubic polynomial in $\\lambda$, which can be written in terms of its principal invariants $I_1$, $I_2$, and $I_3$ as:\n$$\nP(\\lambda) = \\det(\\boldsymbol{\\sigma} - \\lambda\\boldsymbol{I}) = -\\lambda^3 + I_1\\lambda^2 - I_2\\lambda + I_3\n$$\nThe principal invariants $I_1$, $I_2$, and $I_3$ are the scalar coefficients of this polynomial and are independent of the basis chosen to represent the tensor.\n\nSecond, we derive the relationship between the principal invariants and the principal values, and then compute the principal values. Since the principal values $\\sigma_1$, $\\sigma_2$, and $\\sigma_3$ are the roots of the characteristic polynomial $P(\\lambda)=0$, the polynomial can be expressed in factored form:\n$$\nP(\\lambda) = -(\\lambda - \\sigma_1)(\\lambda - \\sigma_2)(\\lambda - \\sigma_3)\n$$\nExpanding this expression gives:\n$$\nP(\\lambda) = -[\\lambda^2 - (\\sigma_1 + \\sigma_2)\\lambda + \\sigma_1\\sigma_2](\\lambda - \\sigma_3)\n$$\n$$\nP(\\lambda) = -[\\lambda^3 - \\sigma_3\\lambda^2 - (\\sigma_1 + \\sigma_2)\\lambda^2 + \\sigma_3(\\sigma_1 + \\sigma_2)\\lambda + \\sigma_1\\sigma_2\\lambda - \\sigma_1\\sigma_2\\sigma_3]\n$$\n$$\nP(\\lambda) = -\\lambda^3 + (\\sigma_1 + \\sigma_2 + \\sigma_3)\\lambda^2 - (\\sigma_1\\sigma_2 + \\sigma_1\\sigma_3 + \\sigma_2\\sigma_3)\\lambda + (\\sigma_1\\sigma_2\\sigma_3)\n$$\nBy comparing the coefficients of this expanded form with the definition $P(\\lambda) = -\\lambda^3 + I_1\\lambda^2 - I_2\\lambda + I_3$, we establish the fundamental relationships:\n$$\nI_1 = \\sigma_1 + \\sigma_2 + \\sigma_3\n$$\n$$\nI_2 = \\sigma_1\\sigma_2 + \\sigma_1\\sigma_3 + \\sigma_2\\sigma_3\n$$\n$$\nI_3 = \\sigma_1\\sigma_2\\sigma_3\n$$\nThese are the elementary symmetric polynomials of the principal values.\n\nTo compute the principal values of the given tensor $\\boldsymbol{\\sigma}$, we must solve its characteristic equation:\n$$\n\\det(\\boldsymbol{\\sigma} - \\lambda\\boldsymbol{I}) = \\det\\begin{pmatrix} 5-\\lambda & 2 & 2 \\\\ 2 & 5-\\lambda & 2 \\\\ 2 & 2 & 5-\\lambda \\end{pmatrix} = 0\n$$\nCalculating the determinant:\n$$\n(5-\\lambda)((5-\\lambda)^2 - 4) - 2(2(5-\\lambda) - 4) + 2(4 - 2(5-\\lambda)) = 0\n$$\n$$\n(5-\\lambda)(\\lambda^2 - 10\\lambda + 25 - 4) - 2(10 - 2\\lambda - 4) + 2(4 - 10 + 2\\lambda) = 0\n$$\n$$\n(5-\\lambda)(\\lambda^2 - 10\\lambda + 21) - 2(6 - 2\\lambda) + 2(-6 + 2\\lambda) = 0\n$$\n$$\n5\\lambda^2 - 50\\lambda + 105 - \\lambda^3 + 10\\lambda^2 - 21\\lambda - 12 + 4\\lambda - 12 + 4\\lambda = 0\n$$\nCombining terms, we obtain the characteristic polynomial:\n$$\n-\\lambda^3 + 15\\lambda^2 - 63\\lambda + 81 = 0\n$$\nTo find the roots, we can test integer divisors of the constant term $81$, which are $\\pm 1, \\pm 3, \\pm 9, \\dots$. Let's test $\\lambda = 3$:\n$$\n-(3)^3 + 15(3)^2 - 63(3) + 81 = -27 + 15(9) - 189 + 81 = -27 + 135 - 189 + 81 = (-27 - 189) + (135 + 81) = -216 + 216 = 0\n$$\nSince $\\lambda = 3$ is a root, $(\\lambda - 3)$ is a factor. We perform polynomial division of $-\\lambda^3 + 15\\lambda^2 - 63\\lambda + 81$ by $(\\lambda - 3)$:\n$$\n(-\\lambda^3 + 15\\lambda^2 - 63\\lambda + 81) \\div (\\lambda - 3) = -\\lambda^2 + 12\\lambda - 27\n$$\nSo the equation becomes:\n$$\n(\\lambda - 3)(-\\lambda^2 + 12\\lambda - 27) = -(\\lambda - 3)(\\lambda^2 - 12\\lambda + 27) = 0\n$$\nFactoring the quadratic term $\\lambda^2 - 12\\lambda + 27 = 0$, we get $(\\lambda-3)(\\lambda-9)=0$.\nThus, the full factorization of the characteristic polynomial is $-(\\lambda - 9)(\\lambda - 3)(\\lambda - 3) = 0$.\nThe roots, which are the principal values of $\\boldsymbol{\\sigma}$, are $\\lambda = 9$, $\\lambda = 3$, and $\\lambda = 3$. Sorted in nonincreasing order, they are:\n$$\n\\sigma_1 = 9, \\quad \\sigma_2 = 3, \\quad \\sigma_3 = 3\n$$\n\nThird, we compute the principal invariants $I_1$, $I_2$, and $I_3$ directly from the components of $\\boldsymbol{\\sigma}$ using standard basis-independent tensor operations.\nThe first invariant, $I_1$, is the trace of the tensor:\n$$\nI_1 = \\text{tr}(\\boldsymbol{\\sigma}) = \\sigma_{kk} = 5 + 5 + 5 = 15\n$$\nThe second invariant, $I_2$, can be computed as the sum of the principal minors of the matrix representation:\n$$\nI_2 = \\det\\begin{pmatrix} 5 & 2 \\\\ 2 & 5 \\end{pmatrix} + \\det\\begin{pmatrix} 5 & 2 \\\\ 2 & 5 \\end{pmatrix} + \\det\\begin{pmatrix} 5 & 2 \\\\ 2 & 5 \\end{pmatrix}\n$$\n$$\nI_2 = (5 \\cdot 5 - 2 \\cdot 2) + (5 \\cdot 5 - 2 \\cdot 2) + (5 \\cdot 5 - 2 \\cdot 2) = (25-4) + (25-4) + (25-4) = 21 + 21 + 21 = 63\n$$\nAlternatively, $I_2 = \\frac{1}{2}[(\\text{tr}(\\boldsymbol{\\sigma}))^2 - \\text{tr}(\\boldsymbol{\\sigma}^2)]$.\nThe third invariant, $I_3$, is the determinant of the tensor:\n$$\nI_3 = \\det(\\boldsymbol{\\sigma}) = \\det\\begin{pmatrix} 5 & 2 & 2 \\\\ 2 & 5 & 2 \\\\ 2 & 2 & 5 \\end{pmatrix}\n$$\n$$\nI_3 = 5(5 \\cdot 5 - 2 \\cdot 2) - 2(2 \\cdot 5 - 2 \\cdot 2) + 2(2 \\cdot 2 - 2 \\cdot 5) = 5(21) - 2(6) + 2(-6) = 105 - 12 - 12 = 81\n$$\nSo, the directly computed invariants are $I_1 = 15$, $I_2 = 63$, and $I_3 = 81$. These match the coefficients of the characteristic polynomial we derived earlier.\n\nFourth, we verify that the elementary symmetric polynomials of the computed principal values agree with the directly computed invariants.\nThe principal values are $\\sigma_1 = 9$, $\\sigma_2 = 3$, $\\sigma_3 = 3$.\nThe directly computed invariants are $I_1 = 15$, $I_2 = 63$, $I_3 = 81$.\nVerification for $I_1$:\n$$\n\\sigma_1 + \\sigma_2 + \\sigma_3 = 9 + 3 + 3 = 15\n$$\nThis matches $I_1$.\nVerification for $I_2$:\n$$\n\\sigma_1\\sigma_2 + \\sigma_1\\sigma_3 + \\sigma_2\\sigma_3 = (9)(3) + (9)(3) + (3)(3) = 27 + 27 + 9 = 63\n$$\nThis matches $I_2$.\nVerification for $I_3$:\n$$\n\\sigma_1\\sigma_2\\sigma_3 = (9)(3)(3) = 9 \\times 9 = 81\n$$\nThis matches $I_3$.\nThe verification is successful, confirming the consistency of our calculations. The final answer is the three principal values, sorted in nonincreasing order.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 9 & 3 & 3 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Beyond understanding the static state of a system, advanced modeling often requires knowing how that state responds to small changes—a concept captured by sensitivity analysis. For tensor quantities, a crucial question is how their principal values evolve as the tensor itself is perturbed. This advanced practice guides you through the derivation of the sensitivity of a principal value, a foundational result in matrix perturbation theory with wide-ranging applications in constitutive modeling, optimization, and stability analysis .",
            "id": "3814783",
            "problem": "In multiscale modeling and analysis of heterogeneous media, the local kinematic or constitutive response is often encoded by a symmetric second-order tensor $\\boldsymbol{A} \\in \\mathbb{R}^{n \\times n}$ (with $n \\in \\{2,3\\}$) whose principal values quantify directional extremal responses. Consider a baseline symmetric tensor $\\boldsymbol{A}$ with a simple spectrum, i.e., it has $n$ distinct principal values $\\lambda_{1},\\dots,\\lambda_{n}$ and an associated orthonormal basis of principal directions $\\{\\boldsymbol{v}_{i}\\}_{i=1}^{n}$, so that $\\boldsymbol{A}\\boldsymbol{v}_{i}=\\lambda_{i}\\boldsymbol{v}_{i}$ and $\\boldsymbol{v}_{i}^{\\top}\\boldsymbol{v}_{j}=\\delta_{ij}$. Let $\\boldsymbol{P}_{i} := \\boldsymbol{v}_{i}\\boldsymbol{v}_{i}^{\\top}$ denote the eigenprojector onto the $i$-th principal direction, and let the double contraction of two second-order tensors be defined by $\\boldsymbol{X}:\\boldsymbol{Y}:=\\operatorname{tr}(\\boldsymbol{X}^{\\top}\\boldsymbol{Y})$.\n\nSuppose $\\boldsymbol{A}$ is perturbed along a direction $\\boldsymbol{H} \\in \\mathbb{R}^{n \\times n}$ by a small scalar parameter $t \\in \\mathbb{R}$ via $\\boldsymbol{A}(t)=\\boldsymbol{A}+t\\,\\boldsymbol{H}$, where $\\boldsymbol{H}$ is symmetric. Define the directional derivative (Gâteaux derivative) of the $i$-th principal value at $\\boldsymbol{A}$ in direction $\\boldsymbol{H}$ by\n$$\nD\\lambda_{i}[\\boldsymbol{A}]:\\boldsymbol{H} \\;:=\\; \\lim_{t \\to 0}\\,\\frac{\\lambda_{i}(\\boldsymbol{A}+t\\,\\boldsymbol{H})-\\lambda_{i}(\\boldsymbol{A})}{t},\n$$\nassuming the limit exists.\n\nStarting only from the eigenvalue relation, orthonormality of eigenvectors, and the symmetry of $\\boldsymbol{A}$, derive an explicit analytic expression for $D\\lambda_{i}[\\boldsymbol{A}]:\\boldsymbol{H}$ and express it in terms of the eigenprojector $\\boldsymbol{P}_{i}$ and the perturbation $\\boldsymbol{H}$. Your derivation should make clear why the expression is independent of the particular choice of normalized eigenvector representing the $i$-th eigenspace. Express your final answer as a single closed-form analytic expression involving $\\boldsymbol{P}_{i}$ and $\\boldsymbol{H}$. No numerical evaluation is required, and no units are involved. Provide only the final analytic expression, not an inequality or equation to be solved.",
            "solution": "The objective is to find an expression for the Gâteaux derivative of the $i$-th principal value (eigenvalue) of a symmetric tensor $\\boldsymbol{A}$ in the direction of a symmetric tensor $\\boldsymbol{H}$. We start from the fundamental eigenvalue relation applied to the perturbed tensor $\\boldsymbol{A}(t) = \\boldsymbol{A} + t\\,\\boldsymbol{H}$. For a small parameter $t$, both the eigenvalue $\\lambda_i(t)$ and its corresponding normalized eigenvector $\\boldsymbol{v}_i(t)$ are functions of $t$. The eigenvalue equation for the perturbed system is:\n$$\n\\boldsymbol{A}(t)\\boldsymbol{v}_{i}(t) = \\lambda_{i}(t)\\boldsymbol{v}_{i}(t)\n$$\nWe assume that $\\lambda_i(t)$ and $\\boldsymbol{v}_i(t)$ are differentiable at $t=0$. We can thus write their first-order Taylor series expansions around $t=0$:\n$$\n\\lambda_{i}(t) = \\lambda_{i}(0) + t\\,\\frac{d\\lambda_{i}}{dt}\\bigg|_{t=0} + O(t^2)\n$$\n$$\n\\boldsymbol{v}_{i}(t) = \\boldsymbol{v}_{i}(0) + t\\,\\frac{d\\boldsymbol{v}_{i}}{dt}\\bigg|_{t=0} + O(t^2)\n$$\nBy definition, $\\lambda_{i}(0) = \\lambda_{i}$ and $\\boldsymbol{v}_{i}(0) = \\boldsymbol{v}_{i}$ are the eigenvalue and eigenvector of the unperturbed tensor $\\boldsymbol{A}$. The derivative $\\frac{d\\lambda_{i}}{dt}\\big|_{t=0}$ is precisely the Gâteaux derivative $D\\lambda_{i}[\\boldsymbol{A}]:\\boldsymbol{H}$ we seek to find. Let's denote the derivative of the eigenvector as $\\dot{\\boldsymbol{v}}_{i} = \\frac{d\\boldsymbol{v}_{i}}{dt}\\big|_{t=0}$.\n\nSubstituting the expansions into the eigenvalue equation:\n$$\n(\\boldsymbol{A} + t\\,\\boldsymbol{H})(\\boldsymbol{v}_{i} + t\\,\\dot{\\boldsymbol{v}}_{i}) = (\\lambda_{i} + t\\,D\\lambda_{i}[\\boldsymbol{A}]:\\boldsymbol{H})(\\boldsymbol{v}_{i} + t\\,\\dot{\\boldsymbol{v}}_{i})\n$$\nExpanding this equation and retaining terms up to the first order in $t$:\n$$\n\\boldsymbol{A}\\boldsymbol{v}_{i} + t\\,\\boldsymbol{H}\\boldsymbol{v}_{i} + t\\,\\boldsymbol{A}\\dot{\\boldsymbol{v}}_{i} + O(t^2) = \\lambda_{i}\\boldsymbol{v}_{i} + t\\,(D\\lambda_{i}[\\boldsymbol{A}]:\\boldsymbol{H})\\boldsymbol{v}_{i} + t\\,\\lambda_{i}\\dot{\\boldsymbol{v}}_{i} + O(t^2)\n$$\nThe terms of order $t^0$ on both sides constitute the original eigenvalue problem, $\\boldsymbol{A}\\boldsymbol{v}_{i} = \\lambda_{i}\\boldsymbol{v}_{i}$, and thus cancel each other out. Equating the coefficients of the terms of order $t^1$ gives:\n$$\n\\boldsymbol{H}\\boldsymbol{v}_{i} + \\boldsymbol{A}\\dot{\\boldsymbol{v}}_{i} = (D\\lambda_{i}[\\boldsymbol{A}]:\\boldsymbol{H})\\boldsymbol{v}_{i} + \\lambda_{i}\\dot{\\boldsymbol{v}}_{i}\n$$\nTo isolate the scalar derivative $D\\lambda_{i}[\\boldsymbol{A}]:\\boldsymbol{H}$, we left-multiply the entire equation by the transpose of the unperturbed eigenvector, $\\boldsymbol{v}_{i}^{\\top}$:\n$$\n\\boldsymbol{v}_{i}^{\\top}\\boldsymbol{H}\\boldsymbol{v}_{i} + \\boldsymbol{v}_{i}^{\\top}\\boldsymbol{A}\\dot{\\boldsymbol{v}}_{i} = (D\\lambda_{i}[\\boldsymbol{A}]:\\boldsymbol{H})\\boldsymbol{v}_{i}^{\\top}\\boldsymbol{v}_{i} + \\lambda_{i}\\boldsymbol{v}_{i}^{\\top}\\dot{\\boldsymbol{v}}_{i}\n$$\nWe can simplify the second term on the left-hand side. Since $\\boldsymbol{A}$ is symmetric ($\\boldsymbol{A}^{\\top} = \\boldsymbol{A}$), we have $\\boldsymbol{v}_{i}^{\\top}\\boldsymbol{A} = (\\boldsymbol{A}^{\\top}\\boldsymbol{v}_{i})^{\\top} = (\\boldsymbol{A}\\boldsymbol{v}_{i})^{\\top}$. Using the unperturbed eigenvalue relation, this becomes $(\\lambda_i\\boldsymbol{v}_i)^{\\top} = \\lambda_i\\boldsymbol{v}_i^{\\top}$. Therefore:\n$$\n\\boldsymbol{v}_{i}^{\\top}\\boldsymbol{A}\\dot{\\boldsymbol{v}}_{i} = \\lambda_{i}\\boldsymbol{v}_{i}^{\\top}\\dot{\\boldsymbol{v}}_{i}\n$$\nSubstituting this back into the equation yields:\n$$\n\\boldsymbol{v}_{i}^{\\top}\\boldsymbol{H}\\boldsymbol{v}_{i} + \\lambda_{i}\\boldsymbol{v}_{i}^{\\top}\\dot{\\boldsymbol{v}}_{i} = (D\\lambda_{i}[\\boldsymbol{A}]:\\boldsymbol{H})\\boldsymbol{v}_{i}^{\\top}\\boldsymbol{v}_{i} + \\lambda_{i}\\boldsymbol{v}_{i}^{\\top}\\dot{\\boldsymbol{v}}_{i}\n$$\nThe term $\\lambda_{i}\\boldsymbol{v}_{i}^{\\top}\\dot{\\boldsymbol{v}}_{i}$ appears on both sides and cancels. Furthermore, due to the orthonormality condition $\\boldsymbol{v}_{i}^{\\top}\\boldsymbol{v}_{i} = 1$. This simplifies the equation to:\n$$\n\\boldsymbol{v}_{i}^{\\top}\\boldsymbol{H}\\boldsymbol{v}_{i} = D\\lambda_{i}[\\boldsymbol{A}]:\\boldsymbol{H}\n$$\nThis provides an expression for the derivative. The problem requires this to be expressed in terms of the eigenprojector $\\boldsymbol{P}_{i} = \\boldsymbol{v}_{i}\\boldsymbol{v}_{i}^{\\top}$ and the double contraction $\\boldsymbol{X}:\\boldsymbol{Y} = \\operatorname{tr}(\\boldsymbol{X}^{\\top}\\boldsymbol{Y})$.\nLet's compute $\\boldsymbol{P}_{i}:\\boldsymbol{H}$:\n$$\n\\boldsymbol{P}_{i}:\\boldsymbol{H} = \\operatorname{tr}(\\boldsymbol{P}_{i}^{\\top}\\boldsymbol{H})\n$$\nThe eigenprojector $\\boldsymbol{P}_{i}$ is symmetric because $\\boldsymbol{P}_{i}^{\\top} = (\\boldsymbol{v}_{i}\\boldsymbol{v}_{i}^{\\top})^{\\top} = (\\boldsymbol{v}_{i}^{\\top})^{\\top}\\boldsymbol{v}_{i}^{\\top} = \\boldsymbol{v}_{i}\\boldsymbol{v}_{i}^{\\top} = \\boldsymbol{P}_{i}$. Thus, $\\boldsymbol{P}_{i}:\\boldsymbol{H} = \\operatorname{tr}(\\boldsymbol{P}_{i}\\boldsymbol{H})$.\n$$\n\\boldsymbol{P}_{i}:\\boldsymbol{H} = \\operatorname{tr}((\\boldsymbol{v}_{i}\\boldsymbol{v}_{i}^{\\top})\\boldsymbol{H})\n$$\nUsing the cyclic property of the trace operator, $\\operatorname{tr}(MN) = \\operatorname{tr}(NM)$, we identify $M=\\boldsymbol{v}_i$ and $N=\\boldsymbol{v}_i^\\top\\boldsymbol{H}$:\n$$\n\\operatorname{tr}(\\boldsymbol{v}_{i}(\\boldsymbol{v}_{i}^{\\top}\\boldsymbol{H})) = \\operatorname{tr}((\\boldsymbol{v}_{i}^{\\top}\\boldsymbol{H})\\boldsymbol{v}_{i})\n$$\nThe product $(\\boldsymbol{v}_{i}^{\\top}\\boldsymbol{H})\\boldsymbol{v}_{i}$ is a scalar (a $1 \\times 1$ matrix), and the trace of a scalar is the scalar itself. Thus:\n$$\n\\operatorname{tr}((\\boldsymbol{v}_{i}^{\\top}\\boldsymbol{H})\\boldsymbol{v}_{i}) = \\boldsymbol{v}_{i}^{\\top}\\boldsymbol{H}\\boldsymbol{v}_{i}\n$$\nCombining these results, we establish the final expression:\n$$\nD\\lambda_{i}[\\boldsymbol{A}]:\\boldsymbol{H} = \\boldsymbol{v}_{i}^{\\top}\\boldsymbol{H}\\boldsymbol{v}_{i} = \\boldsymbol{P}_{i}:\\boldsymbol{H}\n$$\nThe expression is independent of the particular choice of normalized eigenvector. Since the eigenvalue $\\lambda_i$ is simple, its eigenspace is one-dimensional. Any normalized eigenvector associated with $\\lambda_i$ must be either $\\boldsymbol{v}_i$ or $-\\boldsymbol{v}_i$. If we choose $\\tilde{\\boldsymbol{v}}_i = -\\boldsymbol{v}_i$, the corresponding eigenprojector is $\\tilde{\\boldsymbol{P}}_i = \\tilde{\\boldsymbol{v}}_i \\tilde{\\boldsymbol{v}}_i^{\\top} = (-\\boldsymbol{v}_i)(-\\boldsymbol{v}_i)^{\\top} = \\boldsymbol{v}_i\\boldsymbol{v}_i^{\\top} = \\boldsymbol{P}_i$. Since the eigenprojector $\\boldsymbol{P}_i$ is uniquely determined by the one-dimensional eigenspace (and is independent of the sign choice for its basis vector), the expression $\\boldsymbol{P}_{i}:\\boldsymbol{H}$ is also unique.",
            "answer": "$$\\boxed{\\boldsymbol{P}_{i}:\\boldsymbol{H}}$$"
        }
    ]
}