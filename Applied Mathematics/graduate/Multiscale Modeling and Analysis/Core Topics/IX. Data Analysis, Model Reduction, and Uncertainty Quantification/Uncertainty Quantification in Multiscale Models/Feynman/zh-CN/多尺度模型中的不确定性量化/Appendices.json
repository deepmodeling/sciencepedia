{
    "hands_on_practices": [
        {
            "introduction": "本练习为广义多项式混沌 (gPC) 的优雅框架提供了一个具体的切入点。通过为一个简单的二次模型手动推导 gPC 系数，您可以亲身体验随机变量如何在谱基中表示，以及这种表示如何直接产生均值和方差等统计矩。这个基本计算揭示了 gPC 作为一种不确定性量化工具的力量和机理 。",
            "id": "3827665",
            "problem": "考虑一个双尺度模型，其中微观尺度参数 $ \\theta $ 通过一个二阶代理模型 $ Y(\\theta) = a_{0} + a_{1}\\,\\theta + a_{2}\\,\\theta^{2} $ 进入粗尺度目标量 $Y$，其中 $ a_{0}, a_{1}, a_{2} $ 是确定性常数。假设 $ \\theta \\sim \\mathcal{N}(0,1) $，并使用广义多项式混沌 (gPC) 框架进行不确定性量化 (UQ)。使用相对于标准正态测度的标准正交 Hermite 多项式基 $ \\{ \\psi_{0}, \\psi_{1}, \\psi_{2} \\} $。gPC 表示是 $Y$ 在 $ \\{ \\psi_{0}, \\psi_{1}, \\psi_{2} \\} $ 的生成空间上的均方投影，对于这个 $Y$，可以精确得到 $ Y(\\theta) = c_{0}\\,\\psi_{0}(\\theta) + c_{1}\\,\\psi_{1}(\\theta) + c_{2}\\,\\psi_{2}(\\theta) $。\n\n从关于概率测度的标准正交多项式基的基本定义出发，并仅使用标准正态分布和正交性的性质，计算 gPC 系数 $ c_{0}, c_{1}, c_{2} $（用 $ a_{0}, a_{1}, a_{2} $ 表示）。然后直接从 gPC 展开和标准正交性推导出输出均值 $ \\mu_{Y} $ 和方差 $ \\sigma_{Y}^{2} $。将您的最终答案以符号形式表示为一个单行矩阵，按顺序包含 $ c_{0}, c_{1}, c_{2}, \\mu_{Y}, \\sigma_{Y}^{2} $。不需要进行数值舍入，也不涉及物理单位。",
            "solution": "该问题要求为给定的二次代理模型确定广义多项式混沌 (gPC) 系数，并随后计算输出目标量的均值和方差。\n\n该问题是有效的。它是自洽的，科学上基于不确定性量化和正交多项式理论，并且是适定的。我们开始求解。\n\ngPC 方法的核心是将一个随机变量表示为关于其底层输入随机变量的正交多项式的谱展开。\n给定输入随机参数 $\\theta \\sim \\mathcal{N}(0,1)$，适用的正交多项式是 Hermite 多项式。其正交性是关于标准正态概率测度定义的，其概率密度函数为 $w(\\theta) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-\\frac{\\theta^2}{2})$。两个函数 $f(\\theta)$ 和 $g(\\theta)$ 的内积定义为其乘积的期望：\n$$ \\langle f, g \\rangle = \\mathbb{E}[f(\\theta)g(\\theta)] = \\int_{-\\infty}^{\\infty} f(\\theta)g(\\theta) w(\\theta) d\\theta $$\n问题指定了一个标准正交 Hermite 多项式基 $\\{\\psi_k(\\theta)\\}_{k=0}^{\\infty}$，它满足标准正交条件：\n$$ \\langle \\psi_i, \\psi_j \\rangle = \\mathbb{E}[\\psi_i(\\theta)\\psi_j(\\theta)] = \\delta_{ij} $$\n其中 $\\delta_{ij}$ 是克罗内克 δ。\n\n概率论学家的 Hermite 多项式，记为 $He_k(\\theta)$，关于此测度是正交的（但非标准正交的）。其正交关系为 $\\mathbb{E}[He_i(\\theta)He_j(\\theta)] = i! \\delta_{ij}$。前三个多项式是：\n$$ He_0(\\theta) = 1 $$\n$$ He_1(\\theta) = \\theta $$\n$$ He_2(\\theta) = \\theta^2 - 1 $$\n为了获得所需的标准正交基 $\\{\\psi_k(\\theta)\\}$，我们对 $He_k(\\theta)$ 多项式进行归一化：\n$$ \\psi_k(\\theta) = \\frac{He_k(\\theta)}{\\sqrt{\\mathbb{E}[He_k(\\theta)^2]}} = \\frac{He_k(\\theta)}{\\sqrt{k!}} $$\n因此，前三个标准正交基多项式是：\n$$ \\psi_0(\\theta) = \\frac{He_0(\\theta)}{\\sqrt{0!}} = \\frac{1}{1} = 1 $$\n$$ \\psi_1(\\theta) = \\frac{He_1(\\theta)}{\\sqrt{1!}} = \\frac{\\theta}{1} = \\theta $$\n$$ \\psi_2(\\theta) = \\frac{He_2(\\theta)}{\\sqrt{2!}} = \\frac{\\theta^2 - 1}{\\sqrt{2}} $$\n目标量 $Y(\\theta)$ 是一个二次多项式。其 gPC 展开是一个精确的有限级数：\n$$ Y(\\theta) = c_0 \\psi_0(\\theta) + c_1 \\psi_1(\\theta) + c_2 \\psi_2(\\theta) $$\n系数 $c_k$ 是 $Y(\\theta)$ 在基函数上的投影：\n$$ c_k = \\langle Y(\\theta), \\psi_k(\\theta) \\rangle = \\mathbb{E}[Y(\\theta)\\psi_k(\\theta)] $$\n然而，由于展开是精确的，并且我们有 $\\theta$ 的幂和基多项式的显式表示，我们可以通过代数代换来找到系数。首先，我们将标准多项式基 $\\{1, \\theta, \\theta^2\\}$ 用标准正交基 $\\{\\psi_0, \\psi_1, \\psi_2\\}$ 来表示：\n由 $\\psi_0(\\theta) = 1$ 可得 $1 = \\psi_0(\\theta)$。\n由 $\\psi_1(\\theta) = \\theta$ 可得 $\\theta = \\psi_1(\\theta)$。\n由 $\\psi_2(\\theta) = \\frac{\\theta^2 - 1}{\\sqrt{2}}$，我们可以解出 $\\theta^2$：\n$$ \\sqrt{2} \\psi_2(\\theta) = \\theta^2 - 1 \\implies \\theta^2 = \\sqrt{2} \\psi_2(\\theta) + 1 = \\sqrt{2} \\psi_2(\\theta) + \\psi_0(\\theta) $$\n现在，我们将这些表达式代入 $Y(\\theta)$ 的代理模型中：\n$$ Y(\\theta) = a_{0} + a_{1}\\theta + a_{2}\\theta^{2} $$\n$$ Y(\\theta) = a_0 \\psi_0(\\theta) + a_1 \\psi_1(\\theta) + a_2 (\\sqrt{2} \\psi_2(\\theta) + \\psi_0(\\theta)) $$\n接下来，我们按基多项式 $\\psi_k(\\theta)$ 对各项进行分组：\n$$ Y(\\theta) = (a_0 + a_2) \\psi_0(\\theta) + a_1 \\psi_1(\\theta) + a_2 \\sqrt{2} \\psi_2(\\theta) $$\n通过将其与 gPC 展开形式 $Y(\\theta) = c_0 \\psi_0(\\theta) + c_1 \\psi_1(\\theta) + c_2 \\psi_2(\\theta)$ 直接比较，根据展开的唯一性，我们可以确定系数：\n$$ c_0 = a_0 + a_2 $$\n$$ c_1 = a_1 $$\n$$ c_2 = \\sqrt{2} a_2 $$\n在确定了 gPC 系数后，我们现在可以计算输出的均值 $\\mu_Y$ 和方差 $\\sigma_Y^2$。\n\n$Y$ 的均值是其期望：\n$$ \\mu_Y = \\mathbb{E}[Y(\\theta)] = \\mathbb{E}[c_0 \\psi_0(\\theta) + c_1 \\psi_1(\\theta) + c_2 \\psi_2(\\theta)] $$\n利用期望的线性性质：\n$$ \\mu_Y = c_0 \\mathbb{E}[\\psi_0(\\theta)] + c_1 \\mathbb{E}[\\psi_1(\\theta)] + c_2 \\mathbb{E}[\\psi_2(\\theta)] $$\n对于 $k > 0$ 的任何基函数 $\\psi_k$ 的期望为零，因为 $\\mathbb{E}[\\psi_k(\\theta)] = \\mathbb{E}[\\psi_k(\\theta)\\psi_0(\\theta)] = \\langle \\psi_k, \\psi_0 \\rangle = \\delta_{k0}$。并且，$\\mathbb{E}[\\psi_0(\\theta)] = \\mathbb{E}[1] = 1$。\n因此，均值的表达式简化为：\n$$ \\mu_Y = c_0 \\cdot 1 + c_1 \\cdot 0 + c_2 \\cdot 0 = c_0 $$\n代入 $c_0$ 的表达式，我们得到：\n$$ \\mu_Y = a_0 + a_2 $$\n$Y$ 的方差由 $\\sigma_Y^2 = \\text{Var}(Y(\\theta)) = \\mathbb{E}[(Y(\\theta) - \\mu_Y)^2]$ 给出。\n由于 $\\mu_Y = c_0$ 且 $\\psi_0(\\theta)=1$，我们有 $\\mu_Y = c_0\\psi_0(\\theta)$。\n$$ Y(\\theta) - \\mu_Y = (c_0 \\psi_0(\\theta) + c_1 \\psi_1(\\theta) + c_2 \\psi_2(\\theta)) - c_0 \\psi_0(\\theta) = c_1 \\psi_1(\\theta) + c_2 \\psi_2(\\theta) $$\n那么方差为：\n$$ \\sigma_Y^2 = \\mathbb{E}[(c_1 \\psi_1(\\theta) + c_2 \\psi_2(\\theta))^2] = \\mathbb{E}[c_1^2 \\psi_1(\\theta)^2 + 2c_1c_2 \\psi_1(\\theta)\\psi_2(\\theta) + c_2^2 \\psi_2(\\theta)^2] $$\n根据期望的线性性质：\n$$ \\sigma_Y^2 = c_1^2 \\mathbb{E}[\\psi_1(\\theta)^2] + 2c_1c_2 \\mathbb{E}[\\psi_1(\\theta)\\psi_2(\\theta)] + c_2^2 \\mathbb{E}[\\psi_2(\\theta)^2] $$\n使用标准正交性 $\\mathbb{E}[\\psi_i(\\theta)\\psi_j(\\theta)] = \\delta_{ij}$：\n$$ \\mathbb{E}[\\psi_1(\\theta)^2] = 1 $$\n$$ \\mathbb{E}[\\psi_1(\\theta)\\psi_2(\\theta)] = 0 $$\n$$ \\mathbb{E}[\\psi_2(\\theta)^2] = 1 $$\n方差简化为高阶 gPC 系数的平方和：\n$$ \\sigma_Y^2 = c_1^2 (1) + 2c_1c_2 (0) + c_2^2 (1) = c_1^2 + c_2^2 $$\n代入 $c_1$ 和 $c_2$ 的表达式：\n$$ \\sigma_Y^2 = (a_1)^2 + (\\sqrt{2} a_2)^2 = a_1^2 + 2a_2^2 $$\n最后，我们将所需的量 $c_0, c_1, c_2, \\mu_Y, \\sigma_Y^2$ 组合成一个单行矩阵。\n$$ c_0 = a_0 + a_2 $$\n$$ c_1 = a_1 $$\n$$ c_2 = \\sqrt{2}a_2 $$\n$$ \\mu_Y = a_0 + a_2 $$\n$$ \\sigma_Y^2 = a_1^2 + 2a_2^2 $$",
            "answer": "$$ \\boxed{\\begin{pmatrix} a_{0} + a_{2}  a_{1}  \\sqrt{2}a_{2}  a_{0} + a_{2}  a_{1}^{2} + 2a_{2}^{2} \\end{pmatrix}} $$"
        },
        {
            "introduction": "在多尺度不确定性量化中，一个普遍的挑战是精细尺度模型的高昂计算成本。本练习演示了控制变量法，这是一种强大的方差缩减技术，它利用相关的低保真度模型（例如，粗尺度模拟）来显著提高高保真度模型蒙特卡洛估计的效率。通过推导最优权重和由此产生的方差缩减，您将理解多层蒙特卡洛等高级方法的核心思想 。",
            "id": "3827688",
            "problem": "考虑一个多尺度模型，其中一个精细尺度求解器产生一个随机输出 $Y_{f}$，其均值 $\\mu_{f}$ 未知，方差 $\\sigma_{f}^{2}$ 有限；一个粗略尺度求解器产生一个随机输出 $Y_{c}$，其均值 $\\mu_{c}$ 已知，方差 $\\sigma_{c}^{2}$ 有限。假设在共同的随机输入下对 $(Y_{f}, Y_{c})$ 进行联合抽样，因此 $Y_{f}$ 和 $Y_{c}$ 是相关的。令 $\\rho \\in [-1,1]$ 表示 $Y_{f}$ 和 $Y_{c}$ 之间的皮尔逊相关系数，定义为 $\\rho = \\mathrm{Cov}(Y_{f}, Y_{c})/(\\sigma_{f}\\sigma_{c})$，其中 $\\mathrm{Cov}(Y_{f}, Y_{c})$ 是协方差，$\\sigma_{f}$ 和 $\\sigma_{c}$ 分别是 $Y_{f}$ 和 $Y_{c}$ 的标准差。\n\n在不确定性量化 (UQ) 的背景下，考虑使用 $n$ 个独立同分布的联合样本 $\\{(Y_{f}^{(i)}, Y_{c}^{(i)})\\}_{i=1}^{n}$，通过蒙特卡洛方法来估计 $\\mu_{f}$。构建一个形式如下的控制变量估计量\n$$\\widehat{\\mu}_{\\mathrm{cv}} = \\overline{Y}_{f} - \\beta \\left(\\overline{Y}_{c} - \\mu_{c}\\right),$$\n其中 $\\overline{Y}_{f} = \\frac{1}{n}\\sum_{i=1}^{n} Y_{f}^{(i)}$ 和 $\\overline{Y}_{c} = \\frac{1}{n}\\sum_{i=1}^{n} Y_{c}^{(i)}$，$\\beta \\in \\mathbb{R}$ 是一个可调标量。从期望、方差、协方差和相关性的定义出发，推导出使 $\\widehat{\\mu}_{\\mathrm{cv}}$ 的方差最小化的 $\\beta$ 的选择，然后推导出方差缩减因子，其定义为\n$$\\mathrm{VRF} = \\frac{\\mathrm{Var}\\!\\left(\\widehat{\\mu}_{\\mathrm{cv}}\\right)}{\\mathrm{Var}\\!\\left(\\overline{Y}_{f}\\right)},$$\n并将其仅表示为 $\\rho$ 的函数。以闭式形式给出 $\\mathrm{VRF}$ 的最终表达式。不需要进行数值计算。如果需要任何近似，则应以有效数字说明，但此处期望得到一个精确的解析表达式。",
            "solution": "用户希望找到多尺度蒙特卡洛模拟中的最优控制变量参数 $\\beta$ 以及由此产生的方差缩减因子。\n\n### 问题验证\n根据所需标准对问题陈述进行评估。\n#### 第1步：提取已知条件\n- 精细尺度随机输出：$Y_{f}$\n- 精细尺度均值：$\\mu_{f} = E[Y_{f}]$ (未知)\n- 精细尺度方差：$\\sigma_{f}^{2} = \\mathrm{Var}(Y_{f})$ (有限)\n- 粗略尺度随机输出：$Y_{c}$\n- 粗略尺度均值：$\\mu_{c} = E[Y_{c}]$ (已知)\n- 粗略尺度方差：$\\sigma_{c}^{2} = \\mathrm{Var}(Y_{c})$ (有限)\n- 相关系数：$\\rho = \\frac{\\mathrm{Cov}(Y_{f}, Y_{c})}{\\sigma_{f}\\sigma_{c}}$，其中 $\\rho \\in [-1,1]$\n- 样本大小：$n$ 个独立同分布的联合样本 $\\{(Y_{f}^{(i)}, Y_{c}^{(i)})\\}_{i=1}^{n}$\n- 样本均值：$\\overline{Y}_{f} = \\frac{1}{n}\\sum_{i=1}^{n} Y_{f}^{(i)}$ 和 $\\overline{Y}_{c} = \\frac{1}{n}\\sum_{i=1}^{n} Y_{c}^{(i)}$\n- 控制变量估计量：$\\widehat{\\mu}_{\\mathrm{cv}} = \\overline{Y}_{f} - \\beta \\left(\\overline{Y}_{c} - \\mu_{c}\\right)$，其中 $\\beta \\in \\mathbb{R}$ 为可调标量\n- 目标：找到使 $\\mathrm{Var}\\!\\left(\\widehat{\\mu}_{\\mathrm{cv}}\\right)$ 最小化的 $\\beta$ 值，并推导方差缩减因子 $\\mathrm{VRF} = \\frac{\\mathrm{Var}\\!\\left(\\widehat{\\mu}_{\\mathrm{cv}}\\right)}{\\mathrm{Var}\\!\\left(\\overline{Y}_{f}\\right)}$ 作为 $\\rho$ 的函数。\n\n#### 第2步：使用提取的已知条件进行验证\n该问题具有科学依据，是适定且客观的。这是蒙特卡洛方法和不确定性量化 (UQ) 领域的一个标准推导。所有术语都定义清晰，任务是基于概率论的基本原理进行数学推导。未发现任何缺陷。\n\n#### 第3步：结论与行动\n该问题有效。现在开始推导解答。\n\n### 推导过程\n目标是找到使控制变量估计量 $\\widehat{\\mu}_{\\mathrm{cv}}$ 方差最小化的 $\\beta$ 值，然后计算由此产生的方差缩减因子。\n\n首先，我们确定估计量 $\\widehat{\\mu}_{\\mathrm{cv}}$ 的方差。该估计量由下式给出：\n$$ \\widehat{\\mu}_{\\mathrm{cv}} = \\overline{Y}_{f} - \\beta \\left(\\overline{Y}_{c} - \\mu_{c}\\right) $$\n由于 $\\mu_c$ 是一个已知常数，从随机变量 $\\overline{Y}_c$ 中减去它会平移均值，但不会改变其方差或与其他变量的协方差。因此，为了计算方差，我们可以分析 $\\overline{Y}_{f} - \\beta \\overline{Y}_{c}$ 的方差：\n$$ \\mathrm{Var}\\!\\left(\\widehat{\\mu}_{\\mathrm{cv}}\\right) = \\mathrm{Var}\\!\\left(\\overline{Y}_{f} - \\beta \\overline{Y}_{c}\\right) $$\n使用两个随机变量之差的方差的标准公式 $\\mathrm{Var}(A - B) = \\mathrm{Var}(A) + \\mathrm{Var}(B) - 2\\mathrm{Cov}(A,B)$：\n$$ \\mathrm{Var}\\!\\left(\\widehat{\\mu}_{\\mathrm{cv}}\\right) = \\mathrm{Var}\\!\\left(\\overline{Y}_{f}\\right) + \\mathrm{Var}\\!\\left(\\beta \\overline{Y}_{c}\\right) - 2\\mathrm{Cov}\\!\\left(\\overline{Y}_{f}, \\beta \\overline{Y}_{c}\\right) $$\n使用方差和协方差的性质 $\\mathrm{Var}(cX) = c^2\\mathrm{Var}(X)$ 和 $\\mathrm{Cov}(X, cY) = c\\mathrm{Cov}(X,Y)$：\n$$ \\mathrm{Var}\\!\\left(\\widehat{\\mu}_{\\mathrm{cv}}\\right) = \\mathrm{Var}\\!\\left(\\overline{Y}_{f}\\right) + \\beta^{2} \\mathrm{Var}\\!\\left(\\overline{Y}_{c}\\right) - 2\\beta \\mathrm{Cov}\\!\\left(\\overline{Y}_{f}, \\overline{Y}_{c}\\right) $$\n接下来，我们用基础随机变量 $Y_f$ 和 $Y_c$ 的性质来表示样本均值的方差和协方差。样本 $\\{(Y_{f}^{(i)}, Y_{c}^{(i)})\\}$ 是独立同分布的。\n对于独立同分布的样本，样本均值的方差是总体方差的 $\\frac{1}{n}$ 倍：\n$$ \\mathrm{Var}\\!\\left(\\overline{Y}_{f}\\right) = \\mathrm{Var}\\!\\left(\\frac{1}{n}\\sum_{i=1}^{n} Y_{f}^{(i)}\\right) = \\frac{1}{n^2} \\sum_{i=1}^{n} \\mathrm{Var}\\!\\left(Y_{f}^{(i)}\\right) = \\frac{n\\sigma_{f}^{2}}{n^2} = \\frac{\\sigma_{f}^{2}}{n} $$\n$$ \\mathrm{Var}\\!\\left(\\overline{Y}_{c}\\right) = \\mathrm{Var}\\!\\left(\\frac{1}{n}\\sum_{i=1}^{n} Y_{c}^{(i)}\\right) = \\frac{1}{n^2} \\sum_{i=1}^{n} \\mathrm{Var}\\!\\left(Y_{c}^{(i)}\\right) = \\frac{n\\sigma_{c}^{2}}{n^2} = \\frac{\\sigma_{c}^{2}}{n} $$\n样本均值的协方差为：\n$$ \\mathrm{Cov}\\!\\left(\\overline{Y}_{f}, \\overline{Y}_{c}\\right) = \\mathrm{Cov}\\!\\left(\\frac{1}{n}\\sum_{i=1}^{n} Y_{f}^{(i)}, \\frac{1}{n}\\sum_{j=1}^{n} Y_{c}^{(j)}\\right) = \\frac{1}{n^2} \\sum_{i=1}^{n}\\sum_{j=1}^{n} \\mathrm{Cov}\\!\\left(Y_{f}^{(i)}, Y_{c}^{(j)}\\right) $$\n由于当 $i \\neq j$ 时，样本 $(Y_{f}^{(i)}, Y_{c}^{(i)})$ 是独立的，因此对于 $i \\neq j$，有 $\\mathrm{Cov}(Y_{f}^{(i)}, Y_{c}^{(j)}) = 0$。双重求和简化为 $i=j$ 时的单重求和：\n$$ \\mathrm{Cov}\\!\\left(\\overline{Y}_{f}, \\overline{Y}_{c}\\right) = \\frac{1}{n^2} \\sum_{i=1}^{n} \\mathrm{Cov}\\!\\left(Y_{f}^{(i)}, Y_{c}^{(i)}\\right) = \\frac{n \\mathrm{Cov}\\!\\left(Y_{f}, Y_{c}\\right)}{n^2} = \\frac{\\mathrm{Cov}\\!\\left(Y_{f}, Y_{c}\\right)}{n} $$\n将这些表达式代回到 $\\mathrm{Var}\\!\\left(\\widehat{\\mu}_{\\mathrm{cv}}\\right)$ 的方程中：\n$$ \\mathrm{Var}\\!\\left(\\widehat{\\mu}_{\\mathrm{cv}}\\right) = \\frac{\\sigma_{f}^{2}}{n} + \\beta^{2} \\frac{\\sigma_{c}^{2}}{n} - 2\\beta \\frac{\\mathrm{Cov}\\!\\left(Y_{f}, Y_{c}\\right)}{n} $$\n为了找到使该方差最小化的 $\\beta$ 值，我们将 $\\mathrm{Var}\\!\\left(\\widehat{\\mu}_{\\mathrm{cv}}\\right)$ 视为 $\\beta$ 的函数，并通过将其关于 $\\beta$ 的一阶导数设为零来求其最小值：\n$$ \\frac{d}{d\\beta} \\mathrm{Var}\\!\\left(\\widehat{\\mu}_{\\mathrm{cv}}\\right) = \\frac{d}{d\\beta} \\left( \\frac{\\sigma_{f}^{2}}{n} + \\beta^{2} \\frac{\\sigma_{c}^{2}}{n} - 2\\beta \\frac{\\mathrm{Cov}\\!\\left(Y_{f}, Y_{c}\\right)}{n} \\right) = \\frac{2\\beta\\sigma_{c}^{2}}{n} - \\frac{2\\mathrm{Cov}\\!\\left(Y_{f}, Y_{c}\\right)}{n} $$\n将导数设为零：\n$$ \\frac{2\\beta\\sigma_{c}^{2}}{n} - \\frac{2\\mathrm{Cov}\\!\\left(Y_{f}, Y_{c}\\right)}{n} = 0 \\implies \\beta\\sigma_{c}^{2} = \\mathrm{Cov}\\!\\left(Y_{f}, Y_{c}\\right) $$\n这就得出了 $\\beta$ 的最优值，我们记作 $\\beta^{*}$：\n$$ \\beta^{*} = \\frac{\\mathrm{Cov}\\!\\left(Y_{f}, Y_{c}\\right)}{\\sigma_{c}^{2}} $$\n二阶导数为 $\\frac{d^2}{d\\beta^2}\\mathrm{Var}(\\widehat{\\mu}_{\\mathrm{cv}}) = \\frac{2\\sigma_c^2}{n}  0$（假设 $\\sigma_c^2  0$），证实了这是一个最小值。\n现在，我们将 $\\beta^{*}$ 代回到方差的表达式中：\n$$ \\mathrm{Var}\\!\\left(\\widehat{\\mu}_{\\mathrm{cv}}\\right)_{\\mathrm{opt}} = \\frac{\\sigma_{f}^{2}}{n} + \\left(\\frac{\\mathrm{Cov}\\!\\left(Y_{f}, Y_{c}\\right)}{\\sigma_{c}^{2}}\\right)^{2} \\frac{\\sigma_{c}^{2}}{n} - 2\\left(\\frac{\\mathrm{Cov}\\!\\left(Y_{f}, Y_{c}\\right)}{\\sigma_{c}^{2}}\\right) \\frac{\\mathrm{Cov}\\!\\left(Y_{f}, Y_{c}\\right)}{n} $$\n$$ \\mathrm{Var}\\!\\left(\\widehat{\\mu}_{\\mathrm{cv}}\\right)_{\\mathrm{opt}} = \\frac{\\sigma_{f}^{2}}{n} + \\frac{\\mathrm{Cov}\\!\\left(Y_{f}, Y_{c}\\right)^{2}}{n\\sigma_{c}^{2}} - \\frac{2\\mathrm{Cov}\\!\\left(Y_{f}, Y_{c}\\right)^{2}}{n\\sigma_{c}^{2}} = \\frac{\\sigma_{f}^{2}}{n} - \\frac{\\mathrm{Cov}\\!\\left(Y_{f}, Y_{c}\\right)^{2}}{n\\sigma_{c}^{2}} $$\n问题要求用相关系数 $\\rho = \\frac{\\mathrm{Cov}(Y_{f}, Y_{c})}{\\sigma_{f}\\sigma_{c}}$ 来表示结果。由此可得 $\\mathrm{Cov}(Y_{f}, Y_{c}) = \\rho\\sigma_{f}\\sigma_{c}$。\n将此代入最优方差的表达式中：\n$$ \\mathrm{Var}\\!\\left(\\widehat{\\mu}_{\\mathrm{cv}}\\right)_{\\mathrm{opt}} = \\frac{\\sigma_{f}^{2}}{n} - \\frac{\\left(\\rho\\sigma_{f}\\sigma_{c}\\right)^{2}}{n\\sigma_{c}^{2}} = \\frac{\\sigma_{f}^{2}}{n} - \\frac{\\rho^{2}\\sigma_{f}^{2}\\sigma_{c}^{2}}{n\\sigma_{c}^{2}} = \\frac{\\sigma_{f}^{2}}{n}\\left(1 - \\rho^{2}\\right) $$\n最后，我们计算方差缩减因子 $\\mathrm{VRF}$，其定义为优化后的控制变量方差与标准蒙特卡洛估计量 $\\overline{Y}_f$ 的方差之比：\n$$ \\mathrm{VRF} = \\frac{\\mathrm{Var}\\!\\left(\\widehat{\\mu}_{\\mathrm{cv}}\\right)_{\\mathrm{opt}}}{\\mathrm{Var}\\!\\left(\\overline{Y}_{f}\\right)} $$\n代入我们推导出的表达式：\n$$ \\mathrm{VRF} = \\frac{\\frac{\\sigma_{f}^{2}}{n}\\left(1 - \\rho^{2}\\right)}{\\frac{\\sigma_{f}^{2}}{n}} $$\n项 $\\frac{\\sigma_f^2}{n}$ 被消去，最终表达式仅用 $\\rho$ 表示：\n$$ \\mathrm{VRF} = 1 - \\rho^{2} $$\n这个结果表明，方差的缩减量由精细尺度和粗略尺度模型输出之间相关系数的平方决定。更强的相关性（即 $|\\rho|$ 更接近于 1）会导致更大的方差缩减。",
            "answer": "$$\\boxed{1 - \\rho^{2}}$$"
        },
        {
            "introduction": "本练习旨在解决计算多尺度建模中一个核心的实际数据分析挑战。它将指导您实施一个稳健的统计程序，从一系列有限尺寸的模拟中外推有效的材料属性，同时考虑系统性的有限尺寸误差和统计采样噪声。掌握这种从模拟数据中估计物理参数及其不确定性的能力，是将模拟结果与宏观物理定律联系起来的关键技能 。",
            "id": "3827718",
            "problem": "考虑一个随机异质介质，其中一个标量有效属性 $p$（例如，有效电导率或刚度）通过线性尺寸为 $L$ 的代表性体积单元（RVE）进行估计。令 $p(L)$ 表示尺寸为 $L$ 时基于 RVE 的有效属性估计量，其计算方式是对 $n(L)$ 个独立的微观结构样本进行平均。假设由于有限尺寸偏差，$p(L)$ 与无限体积极限 $p_{\\infty}$ 之间的主阶偏差遵循一个指数为 $\\alpha  0$ 的已知有限尺寸标度律，并且根据中心极限定理（CLT），每个 $L$ 处的样本平均值近似服从高斯分布。具体来说，假设以下测量模型成立：\n$$\n\\bar{p}_i = p_{\\infty} + A \\, L_i^{-\\alpha} + \\varepsilon_i \\quad \\text{for} \\quad i = 1,\\dots,m,\n$$\n其中 $L_i$ 是不同的 RVE 尺寸，$\\bar{p}_i$ 是在尺寸 $L_i$ 下由 $n_i$ 个独立实现计算出的样本均值，$A$ 是一个未知振幅，而 $\\varepsilon_i$ 是独立的零均值高斯误差，其方差为\n$$\n\\operatorname{Var}(\\varepsilon_i) = \\sigma_i^2 = \\frac{s_i^2}{n_i},\n$$\n其中 $s_i$ 是在尺寸 $L_i$ 下 $n_i$ 个实现的测量样本标准差。确定性的 $L_i^{-\\alpha}$ 标度关系代表了主阶有限尺寸偏差，而随机误差则捕捉了 $\\bar{p}_i$ 的抽样变异性。\n\n您的任务是实现一个程序，该程序能够：\n- 在给定数据 $\\{(L_i, \\bar{p}_i, s_i, n_i)\\}_{i=1}^m$ 和已知 $\\alpha$ 的情况下，在高斯误差模型下使用加权最小二乘法估计 $p_{\\infty}$，并通过一个折合卡方缩放来考虑可能的模型差异，从而为 $p_{\\infty}$ 提供一个有统计学原理支撑的不确定度估计。\n- 通过设置 $x_i = L_i^{-\\alpha}$ 并拟合以下模型，来使用模型的线性化形式：\n$$\n\\bar{p}_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i,\n$$\n其中 $\\beta_0 = p_{\\infty}$ 且 $\\beta_1 = A$。\n- 采用权重 $w_i = 1/\\sigma_i^2$（其中 $\\sigma_i = s_i/\\sqrt{n_i}$），通过矩阵形式的正规方程求解 $\\hat{\\beta} = (\\hat{\\beta}_0, \\hat{\\beta}_1)$\n$$\n\\hat{\\beta} = (X^{\\top} W X)^{-1} X^{\\top} W \\, \\bar{p},\n$$\n其中设计矩阵为 $X = \\begin{bmatrix} 1  x_1 \\\\ \\vdots  \\vdots \\\\ 1  x_m \\end{bmatrix}$，权重矩阵为 $W = \\operatorname{diag}(w_1,\\dots,w_m)$，响应向量为 $\\bar{p} = (\\bar{p}_1,\\dots,\\bar{p}_m)^{\\top}$。\n- 计算残差 $r_i = \\bar{p}_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i$，加权平方和\n$$\n\\chi^2 = \\sum_{i=1}^m w_i r_i^2,\n$$\n以及折合卡方缩放\n$$\n\\hat{\\sigma}^2_{\\text{red}} = \\frac{\\chi^2}{m - 2} \\quad \\text{for} \\quad m  2.\n$$\n- 将 $\\hat{\\beta}$ 的协方差估计为\n$$\n\\operatorname{Cov}(\\hat{\\beta}) \\approx \\hat{\\sigma}^2_{\\text{red}} \\, (X^{\\top} W X)^{-1},\n$$\n并报告 $p_{\\infty}$ 的标准不确定度为 $u(p_{\\infty}) = \\sqrt{\\operatorname{Cov}(\\hat{\\beta})_{00}}$。如果 $m \\leq 2$，则使用 $\\operatorname{Cov}(\\hat{\\beta}) \\approx (X^{\\top} W X)^{-1}$。\n\n输入数据是固定的，并在下方为五个测试用例提供。对于每个用例，请严格按照规定使用给定的 $\\alpha$、尺寸 $L_i$、样本均值 $\\bar{p}_i$、样本标准差 $s_i$ 和重复次数 $n_i$。所有量均为无量纲。\n\n测试套件：\n- 用例 1：\n  - $\\alpha = 1.0$\n  - $L = [50, 100, 200, 400]$\n  - $\\bar{p} = [2.104, 1.947, 1.877, 1.8365]$\n  - $s = [0.2, 0.16, 0.14, 0.1]$\n  - $n = [30, 30, 30, 30]$\n- 用例 2：\n  - $\\alpha = 1.0$\n  - $L = [40, 80, 160, 320]$\n  - $\\bar{p} = [2.028, 2.0105, 2.00775, 2.002125]$\n  - $s = [0.05, 0.05, 0.05, 0.05]$\n  - $n = [20, 20, 20, 20]$\n- 用例 3：\n  - $\\alpha = 1.0$\n  - $L = [100, 200, 400]$\n  - $\\bar{p} = [1.06, 1.02, 1.0125]$\n  - $s = [0.3, 0.2, 0.2]$\n  - $n = [10, 10, 10]$\n- 用例 4：\n  - $\\alpha = 1.0$\n  - $L = [30, 60, 120, 240, 480]$\n  - $\\bar{p} = [3.3383333, 3.1626666, 3.0863333, 3.0396666, 3.0218333]$\n  - $s = [0.5, 0.35, 0.25, 0.18, 0.12]$\n  - $n = [25, 25, 25, 25, 25]$\n- 用例 5：\n  - $\\alpha = 1.5$\n  - $L = [50, 100, 200, 400]$\n  - $\\bar{p} = [5.286842712, 5.097, 5.037355339, 5.0115]$\n  - $s = [0.2, 0.15, 0.1, 0.08]$\n  - $n = [50, 50, 50, 50]$\n\n对于每个测试用例，您的程序应计算并返回一个包含 $[\\hat{p}_{\\infty}, u(\\hat{p}_{\\infty})]$ 的双元素列表，其中 $\\hat{p}_{\\infty} = \\hat{\\beta}_0$ 且 $u(\\hat{p}_{\\infty}) = \\sqrt{\\operatorname{Cov}(\\hat{\\beta})_{00}}$。最终输出应将所有五个测试用例的结果汇总到一行，格式为一个由方括号括起来的逗号分隔列表，其中包含五个内部列表，且无多余空格，例如：\n$$\n[\\,[\\hat{p}_{\\infty}^{(1)}, u^{(1)}], [\\hat{p}_{\\infty}^{(2)}, u^{(2)}], [\\hat{p}_{\\infty}^{(3)}, u^{(3)}], [\\hat{p}_{\\infty}^{(4)}, u^{(4)}], [\\hat{p}_{\\infty}^{(5)}, u^{(5)}]\\,].\n$$\n不涉及物理单位。不使用角度。所有数值输出均表示为浮点数。程序不得读取任何输入，必须仅依赖于所提供的测试用例。",
            "solution": "经评估，用户提供的问题是有效的。它在科学上基于统计推断和有限尺寸标度分析的原理，这些是计算科学中的标准方法。该问题是适定的，具有明确的目标、充足的数据，以及一个用于寻找唯一解的数学上合理且无矛盾的程序。所有术语都已定义，任务是将已确立的方法直接应用于多尺度建模中的一个现实场景。\n\n目标是从一系列有限尺寸的样本均值 $\\{\\bar{p}_i\\}_{i=1}^m$ 中，估计无限体积有效属性 $p_{\\infty}$ 及其相关的不确定度 $u(p_{\\infty})$。所提供的数据遵循一个结合了确定性有限尺寸偏差和随机抽样误差的测量模型。\n\n该模型由下式给出：\n$$\n\\bar{p}_i = p_{\\infty} + A \\, L_i^{-\\alpha} + \\varepsilon_i\n$$\n其中 $\\bar{p}_i$ 是尺寸为 $L_i$ 时的样本均值，$\\alpha$ 是一个已知的标度指数，$A$ 是一个未知的振幅，而 $\\varepsilon_i$ 代表随机误差。此误差被假设为一个独立的、零均值的高斯随机变量，$\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma_i^2)$，其方差 $\\sigma_i^2 = s_i^2/n_i$ 由样本标准差 $s_i$ 和实现次数 $n_i$ 导出。\n\n解决方案的核心在于将此模型转换为适合回归分析的线性形式。通过定义一个新的自变量 $x_i = L_i^{-\\alpha}$ 并将参数重新标记为 $\\beta_0 = p_{\\infty}$ 和 $\\beta_1 = A$，该模型变成了一个标准的简单线性回归模型：\n$$\n\\bar{p}_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i\n$$\n我们的目标是估计截距参数 $\\beta_0$ 及其标准不确定度。\n\n由于所有测量的方差 $\\sigma_i^2$ 并不相等（这种情况被称为异方差性），普通最小二乘法并非最佳方法。所规定的方法，即加权最小二乘法（WLS），是适当的技术，因为它给予更精确的测量（即方差较小的测量）更大的权重。WLS 旨在找到参数 $\\hat{\\beta} = (\\hat{\\beta}_0, \\hat{\\beta}_1)^{\\top}$，以最小化加权残差平方和：\n$$\n\\chi^2(\\beta) = \\sum_{i=1}^m w_i (\\bar{p}_i - (\\beta_0 + \\beta_1 x_i))^2\n$$\n最优权重 $w_i$ 是相应测量值方差的倒数：$w_i = 1/\\sigma_i^2 = n_i/s_i^2$。\n\n这个最小化问题可以用矩阵代数优雅地解决。我们定义响应向量 $\\bar{p}$、参数向量 $\\beta$、设计矩阵 $X$ 和对角权重矩阵 $W$：\n$$\n\\bar{p} = \\begin{pmatrix} \\bar{p}_1 \\\\ \\vdots \\\\ \\bar{p}_m \\end{pmatrix}, \\quad\n\\beta = \\begin{pmatrix} \\beta_0 \\\\ \\beta_1 \\end{pmatrix}, \\quad\nX = \\begin{bmatrix} 1  x_1 \\\\ \\vdots  \\vdots \\\\ 1  x_m \\end{bmatrix} = \\begin{bmatrix} 1  L_1^{-\\alpha} \\\\ \\vdots  \\vdots \\\\ 1  L_m^{-\\alpha} \\end{bmatrix}, \\quad\nW = \\operatorname{diag}(w_1, \\dots, w_m)\n$$\nWLS 解 $\\hat{\\beta}$ 通过求解正规方程 $(X^{\\top} W X) \\hat{\\beta} = X^{\\top} W \\bar{p}$ 得到，其结果为：\n$$\n\\hat{\\beta} = (X^{\\top} W X)^{-1} X^{\\top} W \\bar{p}\n$$\n无限体积属性的估计值是该向量的第一个分量：$\\hat{p}_{\\infty} = \\hat{\\beta}_0$。\n\n为了量化此估计中的不确定度，我们首先考虑估计量 $\\hat{\\beta}$ 的协方差矩阵。在误差模型正确的假设下，协方差由 $\\operatorname{Cov}(\\hat{\\beta}) = (X^{\\top} W X)^{-1}$ 给出。然而，问题指定了一种改进方法，用以说明潜在的模型不足或误差方差的错误设定。这是通过使用折合卡方统计量 $\\hat{\\sigma}^2_{\\text{red}}$ 对协方差矩阵进行缩放来完成的。该统计量将数据围绕拟合线的观察散布与来自先验误差估计的预期散布进行比较。\n\n首先，计算残差：$r_i = \\bar{p}_i - (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i)$。最小化的加权平方和则为 $\\chi^2 = \\sum_{i=1}^m w_i r_i^2$。折合卡方是该值通过自由度 $\\nu = m - k$进行归一化的结果，其中 $m$ 是数据点的数量，$k=2$ 是拟合参数的数量。对于 $m  2$：\n$$\n\\hat{\\sigma}^2_{\\text{red}} = \\frac{\\chi^2}{m-2}\n$$\n$\\hat{\\sigma}^2_{\\text{red}}$ 的值提供了拟合优度的度量。接近 1 的值表示模型与数据的拟合与假设的误差方差一致。远大于 1 的值则表明模型拟合不佳或误差方差被低估。调整后的协方差矩阵则为：\n$$\n\\operatorname{Cov}(\\hat{\\beta}) \\approx \\hat{\\sigma}^2_{\\text{red}} (X^{\\top} W X)^{-1} \\quad (\\text{for } m  2)\n$$\n如果 $m \\le 2$，自由度为非正数，因此不应用此缩放，并使用原始的协方差表达式 $\\operatorname{Cov}(\\hat{\\beta}) \\approx (X^{\\top} W X)^{-1}$。\n\n我们的估计量 $\\hat{p}_{\\infty} = \\hat{\\beta}_0$ 的方差是此协方差矩阵的左上角元素，记作 $\\operatorname{Cov}(\\hat{\\beta})_{00}$。标准不确定度是其平方根：\n$$\nu(p_{\\infty}) = \\sqrt{\\operatorname{Cov}(\\hat{\\beta})_{00}}\n$$\n所实现的算法将针对每个测试用例，从输入数据构建矩阵 $X$ 和 $W$，求解正规方程得到 $\\hat{\\beta}$，计算折合卡方统计量以缩放协方差矩阵（因为所有用例中 $m  2$），并提取最终估计值 $\\hat{p}_{\\infty}$ 及其不确定度 $u(p_{\\infty})$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to process all test cases and print the final result.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"alpha\": 1.0,\n            \"L\": [50, 100, 200, 400],\n            \"p_bar\": [2.104, 1.947, 1.877, 1.8365],\n            \"s\": [0.2, 0.16, 0.14, 0.1],\n            \"n\": [30, 30, 30, 30],\n        },\n        {\n            \"alpha\": 1.0,\n            \"L\": [40, 80, 160, 320],\n            \"p_bar\": [2.028, 2.0105, 2.00775, 2.002125],\n            \"s\": [0.05, 0.05, 0.05, 0.05],\n            \"n\": [20, 20, 20, 20],\n        },\n        {\n            \"alpha\": 1.0,\n            \"L\": [100, 200, 400],\n            \"p_bar\": [1.06, 1.02, 1.0125],\n            \"s\": [0.3, 0.2, 0.2],\n            \"n\": [10, 10, 10],\n        },\n        {\n            \"alpha\": 1.0,\n            \"L\": [30, 60, 120, 240, 480],\n            \"p_bar\": [3.3383333, 3.1626666, 3.0863333, 3.0396666, 3.0218333],\n            \"s\": [0.5, 0.35, 0.25, 0.18, 0.12],\n            \"n\": [25, 25, 25, 25, 25],\n        },\n        {\n            \"alpha\": 1.5,\n            \"L\": [50, 100, 200, 400],\n            \"p_bar\": [5.286842712, 5.097, 5.037355339, 5.0115],\n            \"s\": [0.2, 0.15, 0.1, 0.08],\n            \"n\": [50, 50, 50, 50],\n        },\n    ]\n\n    all_results = []\n    for case in test_cases:\n        p_inf_hat, u_p_inf = calculate_wls_extrapolation(\n            case[\"alpha\"],\n            case[\"L\"],\n            case[\"p_bar\"],\n            case[\"s\"],\n            case[\"n\"],\n        )\n        all_results.append(f\"[{p_inf_hat},{u_p_inf}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(all_results)}]\")\n\ndef calculate_wls_extrapolation(alpha, L, p_bar, s, n):\n    \"\"\"\n    Performs weighted least squares extrapolation to find p_infinity and its uncertainty.\n    \n    Args:\n        alpha (float): The scaling exponent.\n        L (list): List of RVE sizes.\n        p_bar (list): List of sample means.\n        s (list): List of sample standard deviations.\n        n (list): List of replicate counts.\n\n    Returns:\n        tuple: A tuple containing (p_infinity_estimate, p_infinity_uncertainty).\n    \"\"\"\n    # Convert input lists to numpy arrays for vectorized calculations.\n    L_arr = np.array(L, dtype=float)\n    p_bar_arr = np.array(p_bar, dtype=float)\n    s_arr = np.array(s, dtype=float)\n    n_arr = np.array(n, dtype=float)\n    \n    m = len(L_arr)\n\n    # 1. Linearize the model: x_i = L_i^(-alpha)\n    x = L_arr ** (-alpha)\n\n    # 2. Construct the design matrix X.\n    X = np.vstack((np.ones(m), x)).T\n\n    # 3. Calculate weights w_i = 1 / sigma_i^2 = n_i / s_i^2 and construct matrix W.\n    variances = s_arr**2 / n_arr\n    weights = 1.0 / variances\n    W = np.diag(weights)\n\n    # 4. Solve the normal equations: beta_hat = (X^T W X)^-1 X^T W p_bar\n    XT_W_X = X.T @ W @ X\n    XT_W_X_inv = np.linalg.inv(XT_W_X)\n    XT_W_p = X.T @ W @ p_bar_arr\n    beta_hat = XT_W_X_inv @ XT_W_p\n\n    p_infinity_estimate = beta_hat[0]\n\n    # 5. Calculate the covariance matrix of beta_hat and the uncertainty of p_infinity.\n    if m  2:\n        # Calculate residuals and reduced chi-square for m  2.\n        residuals = p_bar_arr - (X @ beta_hat)\n        chi_squared = np.sum(weights * residuals**2)\n        degrees_of_freedom = m - 2\n        reduced_chi_squared = chi_squared / degrees_of_freedom\n        \n        # Scale the covariance matrix by the reduced chi-square.\n        cov_beta_hat = reduced_chi_squared * XT_W_X_inv\n    else: # m = 2\n        # Use the unscaled covariance matrix.\n        cov_beta_hat = XT_W_X_inv\n\n    # The variance of p_infinity is the (0,0) element of the covariance matrix.\n    # The standard uncertainty is its square root.\n    variance_p_inf = cov_beta_hat[0, 0]\n    p_infinity_uncertainty = np.sqrt(variance_p_inf)\n\n    return p_infinity_estimate, p_infinity_uncertainty\n\nsolve()\n```"
        }
    ]
}