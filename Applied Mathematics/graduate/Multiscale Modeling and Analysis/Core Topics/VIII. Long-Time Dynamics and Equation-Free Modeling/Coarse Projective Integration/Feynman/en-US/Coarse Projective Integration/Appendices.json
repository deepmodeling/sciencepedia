{
    "hands_on_practices": [
        {
            "introduction": "This exercise explores the fundamental connection between Coarse Projective Integration (CPI) and classical numerical methods by examining its behavior in an idealized limit. It demonstrates that as the microscopic simulation burst length approaches zero, the CPI scheme gracefully reduces to the explicit Forward Euler method for the underlying coarse dynamics. By completing this derivation , you will solidify your understanding of CPI as a data-driven approximation of a coarse vector field, $F(U)$, and see how the projective step functions as a standard time-stepping scheme.",
            "id": "3744108",
            "problem": "Consider a deterministic coarse variable $U(t) \\in \\mathbb{R}^{m}$ evolving according to the ordinary differential equation (ODE)\n$$\n\\frac{dU}{dt} = F(U),\n$$\nwhere $F:\\mathbb{R}^{m} \\to \\mathbb{R}^{m}$ is continuously differentiable in a neighborhood of a given coarse state $U^{n}$. In a single macro-step of Coarse Projective Integration (CPI), one proceeds as follows: at coarse time $t^{n}$ with coarse state $U^{n}$, one constructs a consistent fine-scale microstate and evolves the microscopic simulator for a healing time $t_{h} > 0$, followed by a short burst of length $\\tau > 0$. Over the burst, a coarse time derivative estimator $\\widehat{F}_{\\tau}(U^{n})$ is formed from the coarse evolution of the microstate. The CPI macro-step then performs a projective update\n$$\nU^{n+1} = U^{n} + \\Delta T\\, \\widehat{F}_{\\tau}(U^{n}),\n$$\nwhere the macro-step size $\\Delta T > 0$ is fixed and independent of $\\tau$.\n\nAssume the following:\n- The coarse ODE $\\frac{dU}{dt} = F(U)$ is the correct closed evolution for the coarse variable.\n- The healing time $t_{h}$ is sufficiently long to render the subsequent burst derivative estimator asymptotically unbiased with respect to the coarse dynamics at $U^{n}$ in the limit $\\tau \\to 0$, in the sense that\n$$\n\\lim_{\\tau \\to 0} \\widehat{F}_{\\tau}(U^{n}) = F(U^{n}),\n$$\nand $F$ is locally Lipschitz near $U^{n}$.\n- The macro-step size $\\Delta T$ is fixed and positive.\n\nDefine the CPI macro-slope\n$$\nL(\\tau) := \\frac{U^{n+1} - U^{n}}{\\Delta T}.\n$$\nUsing only the ODE definition $\\frac{dU}{dt} = F(U)$, standard smoothness assumptions on $F$, and the unbiasedness condition stated above, derive the limit\n$$\nL := \\lim_{\\tau \\to 0} L(\\tau)\n$$\nand express it in closed form as a symbolic function of $U^{n}$ and $F$.\n\nYour final answer must be a single closed-form analytic expression for $L$. No numerical approximation is required. If you use any angles, express them in radians. No units are required. Do not present your final answer as an equation; present only the expression for $L$.",
            "solution": "The objective is to determine the limit $L := \\lim_{\\tau \\to 0} L(\\tau)$, where $L(\\tau)$ is the Coarse Projective Integration (CPI) macro-slope. The problem provides the definition of the macro-slope as:\n$$\nL(\\tau) := \\frac{U^{n+1} - U^{n}}{\\Delta T}\n$$\nHere, $U^{n}$ represents the coarse state at a given time $t^{n}$, $U^{n+1}$ is the coarse state after a single macro-step of duration $\\Delta T$, and $\\tau$ is the duration of the microscopic simulation burst used to estimate the time derivative.\n\nThe CPI update rule for advancing the coarse state from $U^{n}$ to $U^{n+1}$ is given by the projective step:\n$$\nU^{n+1} = U^{n} + \\Delta T\\, \\widehat{F}_{\\tau}(U^{n})\n$$\nIn this expression, $\\widehat{F}_{\\tau}(U^{n})$ is the estimator for the coarse time derivative, $\\frac{dU}{dt}$, computed at the state $U^{n}$ using a simulation of duration $\\tau$.\n\nTo derive an expression for $L(\\tau)$, we substitute the CPI update rule into its definition. This yields:\n$$\nL(\\tau) = \\frac{\\left(U^{n} + \\Delta T\\, \\widehat{F}_{\\tau}(U^{n})\\right) - U^{n}}{\\Delta T}\n$$\nThe terms $U^{n}$ and $-U^{n}$ in the numerator cancel one another, leading to a simplified expression:\n$$\nL(\\tau) = \\frac{\\Delta T\\, \\widehat{F}_{\\tau}(U^{n})}{\\Delta T}\n$$\nThe macro-step size $\\Delta T$ is stated to be a fixed, positive constant, so it can be canceled from the numerator and the denominator, provided $\\Delta T \\neq 0$. This gives a direct relationship between the macro-slope and the derivative estimator:\n$$\nL(\\tau) = \\widehat{F}_{\\tau}(U^{n})\n$$\nWith this simplified expression for $L(\\tau)$, we can now compute the required limit $L$. The limit is defined as:\n$$\nL = \\lim_{\\tau \\to 0} L(\\tau)\n$$\nSubstituting our result for $L(\\tau)$, we have:\n$$\nL = \\lim_{\\tau \\to 0} \\widehat{F}_{\\tau}(U^{n})\n$$\nThe problem statement includes a critical assumption regarding the asymptotic behavior of the estimator $\\widehat{F}_{\\tau}(U^{n})$. It is assumed that the healing time $t_{h}$ is sufficient to make the estimator asymptotically unbiased in the limit $\\tau \\to 0$. This is formally stated as:\n$$\n\\lim_{\\tau \\to 0} \\widehat{F}_{\\tau}(U^{n}) = F(U^{n})\n$$\nThis condition asserts that as the burst time becomes infinitesimally short, the estimator converges to the exact value of the coarse vector field $F$ at the state $U^{n}$. The function $F(U)$ is defined by the underlying correct coarse ODE, $\\frac{dU}{dt} = F(U)$.\n\nBy applying this given limit directly to our expression for $L$, we arrive at the final result:\n$$\nL = F(U^{n})\n$$\nThus, the limit of the CPI macro-slope as the burst time $\\tau$ approaches zero is simply the true coarse time derivative evaluated at the initial state of the macro-step, $U^{n}$. The other smoothness and Lipschitz continuity assumptions on $F$ ensure that $F(U^{n})$ is a well-defined quantity, which underpins the validity of this entire procedure.",
            "answer": "$$\n\\boxed{F(U^{n})}\n$$"
        },
        {
            "introduction": "A core challenge in practical CPI is managing the statistical noise inherent in estimating coarse derivatives from finite-time microscopic simulations. This exercise  explores the primary tool for this task: ensemble averaging. You will derive from first principles how averaging the results of $N$ independent simulation bursts systematically reduces the variance of the final derivative estimator, demonstrating the powerful and predictable $\\frac{1}{N}$ scaling of variance that is critical for designing robust and efficient multiscale simulations.",
            "id": "3744088",
            "problem": "Consider a multiscale modeling setting in which Coarse Projective Integration (CPI) is used to advance a macroscopic coarse variable. Let the macroscopic coarse state be denoted by $U^{\\ast}$ at time $t$, and suppose the macroscopic time derivative at $U^{\\ast}$ is $f(U^{\\ast})$. In CPI, one estimates $f(U^{\\ast})$ by running $N$ independent microscopic simulation bursts, each of duration $\\tau$, starting from microstates that are consistent with the coarse state $U^{\\ast}$ via a lifting operation. For burst $i$, define the coarse observable $X_{i}(t)$ and construct the slope estimator\n$$\n\\hat{f}_{i} \\equiv \\frac{X_{i}(t+\\tau) - X_{i}(t)}{\\tau}.\n$$\nAssume that, due to microscopic fluctuations and finite-duration sampling, each $ \\hat{f}_{i} $ is an unbiased estimator of $ f(U^{\\ast}) $ with finite variance and that the estimators are mutually independent across bursts:\n$$\n\\mathbb{E}[\\hat{f}_{i}] = f(U^{\\ast}), \\quad \\mathrm{Var}(\\hat{f}_{i}) = \\sigma^{2}, \\quad \\hat{f}_{1},\\ldots,\\hat{f}_{N} \\text{ independent}.\n$$\nTo reduce estimator variability, CPI forms the ensemble-averaged slope estimator\n$$\n\\hat{f}_{N} \\equiv \\frac{1}{N} \\sum_{i=1}^{N} \\hat{f}_{i},\n$$\nand then executes a projective forward Euler step of size $H$ to approximate the coarse state at time $t+H$ by\n$$\nU_{\\mathrm{proj}} \\equiv U^{\\ast} + H \\hat{f}_{N}.\n$$\nStarting only from the definitions of expectation and variance, the independence of the microscopic bursts, and the linearity of the projective step, derive the variance of the projection error $U_{\\mathrm{proj}} - \\left(U^{\\ast} + H f(U^{\\ast})\\right)$ as a function of $N$, $H$, and $\\sigma$. Your final answer must be a single closed-form analytic expression in terms of $N$, $H$, and $\\sigma$, with no numerical substitution. If you introduce any auxiliary symbols, clearly define them in your derivation. No rounding is required, and no physical units are to be reported in the final expression.",
            "solution": "The objective is to derive the variance of the projection error, $U_{\\mathrm{proj}} - \\left(U^{\\ast} + H f(U^{\\ast})\\right)$, based on the provided definitions and assumptions.\n\nLet the projection error be denoted by the random variable $\\mathcal{E}$. By definition,\n$$\n\\mathcal{E} \\equiv U_{\\mathrm{proj}} - \\left(U^{\\ast} + H f(U^{\\ast})\\right)\n$$\nSubstituting the expression for the projected state, $U_{\\mathrm{proj}} = U^{\\ast} + H \\hat{f}_{N}$, we get:\n$$\n\\mathcal{E} = \\left(U^{\\ast} + H \\hat{f}_{N}\\right) - \\left(U^{\\ast} + H f(U^{\\ast})\\right)\n$$\nSimplifying the expression by canceling the $U^{\\ast}$ terms and factoring out the projective step size $H$ yields:\n$$\n\\mathcal{E} = H \\left(\\hat{f}_{N} - f(U^{\\ast})\\right)\n$$\nThe problem requires us to find the variance of this error, $\\mathrm{Var}(\\mathcal{E})$. We will proceed by first calculating the expectation of the error $\\mathcal{E}$ and then using the definition of variance, $\\mathrm{Var}(X) = \\mathbb{E}\\left[(X - \\mathbb{E}[X])^2\\right]$.\n\nFirst, let's find the expectation of the ensemble-averaged slope estimator, $\\hat{f}_{N}$. Using the linearity of the expectation operator and the given fact that each individual estimator $\\hat{f}_{i}$ is unbiased, i.e., $\\mathbb{E}[\\hat{f}_{i}] = f(U^{\\ast})$:\n$$\n\\mathbb{E}[\\hat{f}_{N}] = \\mathbb{E}\\left[\\frac{1}{N} \\sum_{i=1}^{N} \\hat{f}_{i}\\right] = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbb{E}[\\hat{f}_{i}] = \\frac{1}{N} \\sum_{i=1}^{N} f(U^{\\ast}) = \\frac{1}{N} \\left(N f(U^{\\ast})\\right) = f(U^{\\ast})\n$$\nThis shows that the ensemble-averaged estimator $\\hat{f}_{N}$ is also an unbiased estimator of the true macroscopic derivative $f(U^{\\ast})$.\n\nNow, we can compute the expectation of the projection error $\\mathcal{E}$:\n$$\n\\mathbb{E}[\\mathcal{E}] = \\mathbb{E}\\left[H \\left(\\hat{f}_{N} - f(U^{\\ast})\\right)\\right] = H \\left(\\mathbb{E}[\\hat{f}_{N}] - \\mathbb{E}[f(U^{\\ast})]\\right)\n$$\nSince $f(U^{\\ast})$ is a deterministic quantity (a constant with respect to the microscopic fluctuations), its expectation is itself. Thus,\n$$\n\\mathbb{E}[\\mathcal{E}] = H \\left(f(U^{\\ast}) - f(U^{\\ast})\\right) = 0\n$$\nThe projection error has a mean of zero.\n\nWith the mean of $\\mathcal{E}$ established as $0$, the variance of $\\mathcal{E}$ simplifies to the expectation of its square:\n$$\n\\mathrm{Var}(\\mathcal{E}) = \\mathbb{E}\\left[(\\mathcal{E} - \\mathbb{E}[\\mathcal{E}])^2\\right] = \\mathbb{E}\\left[(\\mathcal{E} - 0)^2\\right] = \\mathbb{E}[\\mathcal{E}^2]\n$$\nSubstituting the expression for $\\mathcal{E}$:\n$$\n\\mathrm{Var}(\\mathcal{E}) = \\mathbb{E}\\left[\\left(H (\\hat{f}_{N} - f(U^{\\ast}))\\right)^2\\right] = H^2 \\mathbb{E}\\left[(\\hat{f}_{N} - f(U^{\\ast}))^2\\right]\n$$\nThe term $\\mathbb{E}\\left[(\\hat{f}_{N} - f(U^{\\ast}))^2\\right]$ is, by definition, the variance of $\\hat{f}_{N}$, since $\\mathbb{E}[\\hat{f}_{N}] = f(U^{\\ast})$. Therefore,\n$$\n\\mathrm{Var}(\\mathcal{E}) = H^2 \\mathrm{Var}(\\hat{f}_{N})\n$$\nOur remaining task is to compute $\\mathrm{Var}(\\hat{f}_{N})$. We start from its definition:\n$$\n\\mathrm{Var}(\\hat{f}_{N}) = \\mathrm{Var}\\left(\\frac{1}{N} \\sum_{i=1}^{N} \\hat{f}_{i}\\right)\n$$\nUsing the property $\\mathrm{Var}(aX) = a^2\\mathrm{Var}(X)$, we get:\n$$\n\\mathrm{Var}(\\hat{f}_{N}) = \\frac{1}{N^2} \\mathrm{Var}\\left(\\sum_{i=1}^{N} \\hat{f}_{i}\\right)\n$$\nSince the estimators $\\hat{f}_i$ are independent, the variance of their sum is the sum of their variances:\n$$\n\\mathrm{Var}\\left(\\sum_{i=1}^{N} \\hat{f}_{i}\\right) = \\sum_{i=1}^{N} \\mathrm{Var}(\\hat{f}_i) = \\sum_{i=1}^{N} \\sigma^2 = N\\sigma^2\n$$\nSubstituting this result back into the expression for $\\mathrm{Var}(\\hat{f}_{N})$:\n$$\n\\mathrm{Var}(\\hat{f}_{N}) = \\frac{1}{N^2} \\left(N \\sigma^2\\right) = \\frac{\\sigma^2}{N}\n$$\nFinally, we substitute this into our expression for the variance of the projection error, $\\mathrm{Var}(\\mathcal{E})$:\n$$\n\\mathrm{Var}(\\mathcal{E}) = H^2 \\mathrm{Var}(\\hat{f}_{N}) = H^2 \\left(\\frac{\\sigma^2}{N}\\right) = \\frac{H^2 \\sigma^2}{N}\n$$\nThis is the final expression for the variance of the projection error as a function of the number of bursts $N$, the projective step size $H$, and the variance of a single burst estimator $\\sigma^2$.",
            "answer": "$$\n\\boxed{\\frac{H^{2} \\sigma^{2}}{N}}\n$$"
        },
        {
            "introduction": "The choice of simulation burst length, $T$, involves a fundamental trade-off between systematic error (bias) and statistical error (variance). This advanced exercise  formalizes this by asking you to construct and minimize a mean-squared error cost functional that captures both effects. By solving for the optimal burst length $T^{\\star}$, you will gain concrete experience with the bias-variance decomposition—a cornerstone of statistical modeling and machine learning—in the practical context of tuning multiscale algorithms for a fixed computational budget.",
            "id": "3744105",
            "problem": "Consider a multiscale fast–slow system in which the coarse observable $Y(t)$ evolves on a slow time scale, while hidden fast variables relax exponentially toward a slow manifold with relaxation time $\\tau_{f}$. In coarse projective integration, a coarse time-derivative estimator is constructed from short “bursts” of microscopic simulation of duration $T$ (the burst length). Each burst is initialized (“lifted”) consistently with a coarse state, and the last portion of the burst—an estimation window of fixed length $\\delta$ with $\\delta \\ll T$ and $\\delta \\gg \\tau_{c}$—is used to estimate the coarse drift. The fast variables are assumed to equilibrate toward the slow manifold, and the bias in the estimated coarse drift due to incomplete relaxation after a burst of length $T$ decays as $b_{0}\\exp(-T/\\tau_{f})$, where $b_{0}$ is the initial bias amplitude determined by the lifting.\n\nAssume that the noisy fluctuations contaminating the drift estimator over the length-$\\delta$ window arise from a zero-mean, stationary process with variance $\\sigma^{2}$ and integrated autocorrelation time $\\tau_{c}$ (the integral of the normalized autocorrelation function), so that for $\\delta \\gg \\tau_{c}$ the variance of a time-average over a window of length $\\delta$ is $2\\sigma^{2}\\tau_{c}/\\delta$. Suppose $n$ independent bursts are run and their estimates are averaged; the total available microscopic compute budget per coarse step is a fixed micro-time $B$, so that $nT=B$.\n\nDefine the mean-squared error cost functional for the averaged coarse drift estimator as the sum of the squared bias and the averaged estimator variance. Using the assumptions above and treating $T$ as a continuous decision variable subject to $T\\delta$, derive, from first principles, an analytic expression for the burst length $T^{\\star}$ that minimizes this cost as a function of the parameters $b_{0}$, $\\tau_{f}$, $\\sigma^{2}$, $\\tau_{c}$, $\\delta$, and $B$. Your final answer must be a single closed-form expression for $T^{\\star}$ in terms of these parameters. Do not include units in your final expression and do not perform any numerical substitution. The final answer must be exact (no rounding is required).",
            "solution": "The objective is to find the optimal burst length, $T^{\\star}$, that minimizes the mean-squared error (MSE) of the coarse drift estimator. The MSE is the sum of the squared bias and the variance:\n$$\n\\text{MSE}(T) = (\\text{Bias}(T))^2 + \\text{Variance}(T)\n$$\nLet's formulate the two components as functions of the burst length $T$.\n\n1.  **Squared Bias:**\n    The bias of the estimator is given as $b(T) = b_{0}\\exp(-T/\\tau_{f})$. Averaging over $n$ independent bursts does not change the bias. The squared bias is:\n    $$\n    (\\text{Bias}(T))^2 = b_{0}^{2}\\exp(-2T/\\tau_{f})\n    $$\n\n2.  **Estimator Variance:**\n    The variance of a single burst's estimate is $V_{1} = \\frac{2\\sigma^{2}\\tau_{c}}{\\delta}$. When averaging $n$ independent estimates, the variance of the average is $\\text{Variance} = V_1 / n$. The total computational budget is fixed at $B$, so $nT = B$, which implies $n = B/T$. Substituting for $n$, the variance becomes a function of $T$:\n    $$\n    \\text{Variance}(T) = \\frac{1}{(B/T)}\\left(\\frac{2\\sigma^{2}\\tau_{c}}{\\delta}\\right) = \\frac{2\\sigma^{2}\\tau_{c}T}{B\\delta}\n    $$\n\nThe total MSE as a cost functional $C(T)$ is:\n$$\nC(T) = b_{0}^{2}\\exp(-2T/\\tau_{f}) + \\frac{2\\sigma^{2}\\tau_{c}T}{B\\delta}\n$$\nTo find the minimum, we take the derivative with respect to $T$ and set it to zero:\n$$\n\\frac{dC}{dT} = -\\frac{2b_{0}^{2}}{\\tau_{f}}\\exp(-2T/\\tau_{f}) + \\frac{2\\sigma^{2}\\tau_{c}}{B\\delta} = 0\n$$\nSolving for the optimal burst length $T^{\\star}$:\n$$\n\\frac{2b_{0}^{2}}{\\tau_{f}}\\exp(-2T^{\\star}/\\tau_{f}) = \\frac{2\\sigma^{2}\\tau_{c}}{B\\delta}\n$$\n$$\n\\exp(-2T^{\\star}/\\tau_{f}) = \\frac{\\sigma^{2}\\tau_{c}\\tau_{f}}{B\\delta b_{0}^{2}}\n$$\nTaking the natural logarithm of both sides:\n$$\n-\\frac{2T^{\\star}}{\\tau_{f}} = \\ln\\left(\\frac{\\sigma^{2}\\tau_{c}\\tau_{f}}{B\\delta b_{0}^{2}}\\right)\n$$\nFinally, isolating $T^{\\star}$ and using the identity $-\\ln(x) = \\ln(1/x)$:\n$$\nT^{\\star} = -\\frac{\\tau_{f}}{2} \\ln\\left(\\frac{\\sigma^{2}\\tau_{c}\\tau_{f}}{B\\delta b_{0}^{2}}\\right) = \\frac{\\tau_{f}}{2} \\ln\\left(\\frac{B\\delta b_{0}^{2}}{\\sigma^{2}\\tau_{c}\\tau_{f}}\\right)\n$$\nThe second derivative $\\frac{d^{2}C}{dT^{2}} = \\frac{4b_{0}^{2}}{\\tau_{f}^{2}}\\exp(-2T/\\tau_{f})$ is always positive, which confirms that $T^{\\star}$ corresponds to a global minimum.",
            "answer": "$$\n\\boxed{\\frac{\\tau_{f}}{2}\\ln\\left(\\frac{B \\delta b_{0}^{2}}{\\sigma^{2}\\tau_{c}\\tau_{f}}\\right)}\n$$"
        }
    ]
}