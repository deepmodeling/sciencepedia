{
    "hands_on_practices": [
        {
            "introduction": "任何计算模型的可靠性都取决于严格的验证。对于动力学蒙特卡洛（KMC）模拟，这意味着要确保其正确实现了马尔可夫过程和统计力学的基本原理。本练习将指导您创建一个单元测试套件，以验证事件选择概率和细致平衡等基本方面，这对于建立对模拟结果的信心至关重要。",
            "id": "3790392",
            "problem": "设计并实现一个程序，为动力学蒙特卡洛 (kMC) 实现构建一套单元测试，以验证其在格点和离格点模型中的三个核心属性：速率归一化、细致平衡和事件选择的正确性。动力学蒙特卡洛 (kMC) 被建模为一个具有离散事件列表和相关速率向量的连续时间马尔可夫过程。其推导的基础是连续时间马尔可夫链理论和平衡统计力学。\n\n从以下基本定义和事实出发。一个连续时间马尔可夫链由一个状态集和一个速率矩阵 $\\mathbf{R}$ 定义，其中 $R_{i \\to j}$ 是从状态 $i$ 到状态 $j$ 的跃迁速率。对于从给定状态出发的单步 kMC，我们考虑一组候选事件，其速率为 $\\{r_i\\}$。总速率为 $R = \\sum_i r_i$。当 $R > 0$ 时，选择事件 $i$ 的概率为 $p_i = r_i / R$，到下一个事件的等待时间 $\\Delta t$ 服从参数为 $R$ 的指数分布。在平衡统计力学中，细致平衡条件是对所有状态对 $\\{i,j\\}$ 均成立的恒等式 $\\pi_i R_{i \\to j} = \\pi_j R_{j \\to i}$，其中 $\\pi_i$ 是状态 $i$ 的稳态概率。对于一个能量为 $\\{E_i\\}$（以热能 $k_{\\mathrm{B}}T$ 为单位）的系统，玻尔兹曼分布为 $\\pi_i = \\exp(-E_i) / Z$，其中 $Z = \\sum_k \\exp(-E_k)$。满足细致平衡的一个充分构造是使用对称的指前因子，并选择 $R_{i \\to j} = \\nu \\exp(-(E_j - E_i)/2)$，其中 $\\nu > 0$ 是一个恒定的尝试频率。\n\n您的程序必须实现单元测试来检查以下属性：\n- 速率归一化：给定一个具有非负项 $r_i \\ge 0$ 和总速率 $R = \\sum_i r_i$ 的有限速率向量 $\\mathbf{r}$，当 $R > 0$ 时，归一化概率满足 $\\sum_i p_i = 1$。程序必须通过随机抽样来经验性地估计事件选择概率，并在指定的容差范围内将其与 $p_i$ 进行比较。\n- 细致平衡：对于具有指定能量 $\\{E_i\\}$（以 $k_{\\mathrm{B}}T$ 为单位）并为满足细致平衡而构建速率的系统，连续时间马尔可夫链的稳态分布等于玻尔兹曼分布。稳态分布 $\\boldsymbol{\\pi}$ 满足 $\\boldsymbol{\\pi}^\\top \\mathbf{G} = \\mathbf{0}$ 和 $\\sum_i \\pi_i = 1$，其中 $\\mathbf{G}$ 是生成元矩阵，其非对角线元素为 $G_{i j} = R_{i \\to j}$（对于 $i \\ne j$），对角线元素为 $G_{i i} = -\\sum_{j \\ne i} R_{i \\to j}$。\n- 事件选择的正确性：事件抽样过程必须永远不选择速率为零的事件，必须处理只有一个事件非零的退化情况，并且必须正确处理总速率 $R = 0$ 的边界条件（没有事件可被选择）。\n\n处理格点和离格点两种情景。在格点 kMC 模型中，状态是离散的格点位置，允许的跃迁由邻接结构指定。在离格点 kMC 模型中，事件列表由几何关系（例如，实体之间的距离）构建，速率可能依赖于连续的几何变量；然而，事件选择仍然是在具有速率向量的离散事件集上进行。对于本问题中的离格点测试，使用的事件速率与距离呈指数依赖关系，$r_i = k_0 \\exp(-\\alpha d_i)$，其中 $k_0 > 0$、$\\alpha > 0$ 和 $d_i \\ge 0$ 是无量纲的。\n\n实现以下测试套件。每个测试必须产生一个布尔结果，指示通过 ($\\mathrm{True}$) 或失败 ($\\mathrm{False}$)。随机抽样必须为每个测试使用固定的种子以确保可复现性。所有指定的能量、速率、距离、计数和容差都是无量纲的。不涉及物理单位。\n\n- 测试 $1$ (格点速率归一化与事件选择)：使用速率向量 $\\mathbf{r} = (1.0, 2.0, 3.0, 0.0)$，抽样次数 $N = 100000$，随机种子 $s = 12345$，归一化容差 $\\varepsilon_{\\mathrm{norm}} = 10^{-12}$，以及频率偏差容差 $\\varepsilon_{\\mathrm{freq}} = 5 \\times 10^{-3}$。如果 $\\left|\\sum_i p_i - 1\\right|  \\varepsilon_{\\mathrm{norm}}$ 且经验频率与 $p_i$ 之间的最大绝对偏差小于 $\\varepsilon_{\\mathrm{freq}}$，则测试通过。\n- 测试 $2$ (离格点速率归一化与事件选择)：使用距离 $\\mathbf{d} = (0.1, 0.2, 1.0)$，$k_0 = 1.0$，$\\alpha = 2.5$，抽样次数 $N = 200000$，随机种子 $s = 54321$，归一化容差 $\\varepsilon_{\\mathrm{norm}} = 10^{-12}$，以及频率偏差容差 $\\varepsilon_{\\mathrm{freq}} = 5 \\times 10^{-3}$。测试通过的标准与测试 $1$ 相同。\n- 测试 $3$ (两状态细致平衡)：使用能量 $\\mathbf{E} = (0.0, 1.0)$（以 $k_{\\mathrm{B}}T$ 为单位），尝试频率 $\\nu = 1.0$，两个状态之间完全邻接，以及细致平衡速率 $R_{i \\to j} = \\nu \\exp(-(E_j - E_i)/2)$。构建生成元 $\\mathbf{G}$，通过求解 $\\boldsymbol{\\pi}^\\top \\mathbf{G} = \\mathbf{0}$ 和 $\\sum_i \\pi_i = 1$ 来计算稳态分布 $\\boldsymbol{\\pi}$，并与玻尔兹曼分布进行比较。如果 $\\boldsymbol{\\pi}$ 与玻尔兹曼分布之间的最大绝对差小于 $\\varepsilon_{\\mathrm{db}} = 10^{-8}$，则测试通过。\n- 测试 $4$ (三状态环形格点细致平衡)：使用能量 $\\mathbf{E} = (0.0, 0.5, 1.0)$（以 $k_{\\mathrm{B}}T$ 为单位），尝试频率 $\\nu = 2.0$。使用环形邻接，其中每个状态连接到其两个邻居（对于三个状态，这会将每个状态连接到另外两个状态）。构建速率 $R_{i \\to j} = \\nu \\exp(-(E_j - E_i)/2)$，建立 $\\mathbf{G}$，计算 $\\boldsymbol{\\pi}$，并与玻尔兹曼分布进行比较。如果最大绝对差小于 $\\varepsilon_{\\mathrm{db}} = 10^{-8}$，则测试通过。\n- 测试 $5$ (边界情况 $R = 0$)：使用速率向量 $\\mathbf{r} = (0.0, 0.0, 0.0)$。如果事件选择过程正确返回“无事件”（即不选择任何索引），则测试通过。\n- 测试 $6$ (确定性事件选择)：使用速率向量 $\\mathbf{r} = (0.0, 0.0, 5.0)$，抽样次数 $N = 10000$，随机种子 $s = 111$。如果在所有样本中，唯一被选中的事件索引是具有非零速率的那个，则测试通过。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$[result1,result2,result3]$），其中每个 $resultk$ 是一个布尔值，指示测试 $k$ 的通过/失败结果。不得打印任何额外文本。",
            "solution": "本问题所依据的原理是动力学蒙特卡洛 (kMC) 模拟的基础，该模拟将系统的时间演化建模为连续时间、离散状态的马尔可夫过程。单元测试的设计重点是根据这些原理验证 kMC 实现的核心机制。\n\n一个 kMC 模拟步骤包括两个部分：选择接下来将发生哪个事件，以及确定系统等待该事件发生多长时间。本问题侧重于事件选择机制的正确性。给定当前状态下 $N$ 个可能事件的集合，每个事件的速率为 $r_i \\ge 0$，总速率为 $R = \\sum_{i=1}^{N} r_i$。根据马尔可夫过程理论，选择事件 $i$ 的概率 $p_i$ 与其速率成正比，由 $p_i = r_i / R$ 给出。所选事件发生的等待时间 $\\Delta t$ 是一个从参数为 $R$ 的指数分布中抽取的随机变量。单元测试将验证与此过程相关的三个关键属性。\n\n1.  **速率归一化与事件选择的正确性**：\n    理论概率 $p_i = r_i/R$ 的总和必须为1，即 $\\sum_{i} p_i = 1$，前提是总速率 $R  0$。事件选择算法必须遵循这些概率。一种标准且稳健的事件选择方法是“首达”或“累积速率”法，本测试将实现此方法。首先，从区间 $[0, R)$ 中抽取一个均匀分布的随机数 $u$。然后，选择事件索引 $k$，使得 $\\sum_{i=0}^{k-1} r_i \\le u  \\sum_{i=0}^{k} r_i$。这确保了速率为 $r_i = 0$ 的事件永远不会被选中（因为它们不增加累积和），而速率较高的事件覆盖了区间 $[0, R)$ 的更大部分，从而使其被选中的可能性成比例地增加。测试通过对给定的速率向量 $\\mathbf{r}$ 重复抽样事件，并将经验选择频率与理论概率 $p_i$ 进行比较来验证这一点。大数定律表明，对于大量的样本 $N_s$，经验频率应收敛于 $p_i$。测试还评估了边界条件：所有速率均为零（$R=0$）的情况，此时不应选择任何事件；以及只有一个事件具有非零速率的确定性情况。\n\n2.  **细致平衡**：\n    对于处于热力学平衡的系统，必须满足细致平衡原理。该原理指出，在平衡状态下，每个微观过程的速率都与其逆过程的速率相平衡。对于描述状态 $i$ 和 $j$ 之间跃迁的马尔可夫过程，这表示为 $\\pi_i R_{i \\to j} = \\pi_j R_{j \\to i}$，其中 $\\pi_k$ 是处于状态 $k$ 的稳态（平衡）概率，而 $R_{i \\to j}$ 是从 $i$ 到 $j$ 的跃迁速率。动力学遵循细致平衡的系统最终将弛豫到一个稳态分布，该分布与统计力学中的平衡分布一致。对于具有离散能级 $E_i$（以热能 $k_{\\mathrm{B}}T$ 为单位）的系统，这个平衡分布是玻尔兹曼分布，$\\pi_{i, \\text{B}} = \\exp(-E_i) / Z$，其中 $Z = \\sum_k \\exp(-E_k)$ 是配分函数。\n    本问题提供了一个特定的速率形式，$R_{i \\to j} = \\nu \\exp(-(E_j - E_i)/2)$，这是满足相对于玻尔兹曼分布的细致平衡的充分（但非必要）条件。测试将通过以下方式验证此属性：\n    a. 构建连续时间马尔可夫链的生成元矩阵 $\\mathbf{G}$。非对角线元素是跃迁速率，$G_{ij} = R_{i \\to j}$（对于 $i \\ne j$），对角线元素是负的总迁出速率，$G_{ii} = -\\sum_{j \\ne i} R_{i \\to j}$。\n    b. 数值求解稳态分布 $\\boldsymbol{\\pi}$，它是满足线性系统 $\\boldsymbol{\\pi}^\\top \\mathbf{G} = \\mathbf{0}$（等价于 $\\mathbf{G}^\\top \\boldsymbol{\\pi} = \\mathbf{0}$）并服从归一化约束 $\\sum_i \\pi_i = 1$ 的唯一归一化向量。这可以通过求解从这些条件导出的线性方程组来实现。\n    c. 将数值得到的稳态分布 $\\boldsymbol{\\pi}$ 与解析推导的玻尔兹曼分布 $\\boldsymbol{\\pi}_{\\text{B}}$ 进行比较。\n\n该测试套件的结构旨在在格点（其中状态跃迁由固定的邻接关系定义）和离格点情景（其中事件速率可能依赖于如距离之类的连续变量）中检验这些属性。\n\n**测试实现**\n\n**测试 $1$ 和 $2$（速率归一化与选择）**：\n这些测试将使用累积速率选择算法的实现。对于给定的速率向量 $\\mathbf{r}$，首先计算理论概率 $\\mathbf{p} = \\mathbf{r} / \\sum \\mathbf{r}$。检查归一化的有效性，$|\\sum p_i - 1|  \\varepsilon_{\\mathrm{norm}}$。然后，使用固定的随机种子进行大量事件（测试 $1$ 为 $N=100000$，测试 $2$ 为 $N=200000$）的抽样，以保证可复现性。计算每个事件的经验频率，并与理论概率进行比较。如果最大绝对偏差在指定的容差 $\\varepsilon_{\\mathrm{freq}}$ 内，则测试通过。对于测试 $1$，速率是直接给出的。对于测试 $2$，首先使用提供的参数根据离格点模型 $r_i = k_0 \\exp(-\\alpha d_i)$ 计算速率 $r_i$。\n\n**测试 $3$ 和 $4$（细致平衡）**：\n这些测试验证指定的速率构造是否能产生与玻尔兹曼分布一致的稳态分布。对于给定的能量 $\\mathbf{E}$ 和尝试频率 $\\nu$，构建速率矩阵 $\\mathbf{R}$：对于所有指定的允许跃迁 $i \\to j$，$R_{i \\to j} = \\nu \\exp(-(E_j - E_i)/2)$。从 $\\mathbf{R}$ 构建生成元矩阵 $\\mathbf{G}$。通过将 $\\mathbf{G}^\\top \\boldsymbol{\\pi} = \\mathbf{0}$ 中的一个方程替换为归一化条件 $\\sum_i \\pi_i = 1$，求解形成的线性系统以找到稳态分布 $\\boldsymbol{\\pi}$。然后将得到的 $\\boldsymbol{\\pi}$ 与理论玻尔兹曼分布 $\\boldsymbol{\\pi}_{\\text{B}} = \\exp(-\\mathbf{E})/\\sum\\exp(-\\mathbf{E})$进行比较。如果 $\\boldsymbol{\\pi}$ 和 $\\boldsymbol{\\pi}_{\\text{B}}$ 的分量之间的最大绝对差小于 $\\varepsilon_{\\mathrm{db}} = 10^{-8}$，则测试通过。测试 $3$ 使用一个 $2$ 态系统，测试 $4$ 使用一个 $3$ 态系统。\n\n**测试 $5$（边界情况 $R=0$）**：\n此测试检查对没有可能迁出事件的状态的处理。速率向量为 $\\mathbf{r} = (0.0, 0.0, 0.0)$，因此总速率为 $R=0$。一个正确的 kMC 实现应将此识别为终止状态，并且不选择任何事件。如果选择函数返回“无事件”的指示符，则测试通过。\n\n**测试 $6$（确定性选择）**：\n此测试验证当只有一个事件具有非零速率（例如 $\\mathbf{r} = (0.0, 0.0, 5.0)$）时的正确行为。在这种情况下，选择必须是确定性的：必须总是选择具有正速率的事件。该测试执行 $N=10000$ 次选择，并且只有在每次都选择了正确的事件索引时才通过。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the kMC unit test suite and print results.\n    \"\"\"\n\n    def select_event(rates: np.ndarray, rng: np.random.Generator):\n        \"\"\"\n        Selects an event based on a list of rates using the cumulative rate method.\n        \n        Args:\n            rates: A numpy array of event rates.\n            rng: A numpy random number generator instance.\n        \n        Returns:\n            The index of the selected event, or None if the total rate is zero.\n        \"\"\"\n        total_rate = np.sum(rates)\n        \n        # Handle the boundary case where no events are possible.\n        if total_rate = 1e-15: # Use a small tolerance for floating point comparison\n            return None\n\n        # Generate a random number u in [0, total_rate).\n        random_draw = rng.random() * total_rate\n        \n        # Use searchsorted for a robust and efficient implementation of the\n        # first-passage algorithm.\n        cumulative_rates = np.cumsum(rates)\n        \n        # Find the index of the first cumulative rate greater than the random draw.\n        selected_index = np.searchsorted(cumulative_rates, random_draw, side='right')\n        \n        return int(selected_index)\n\n    def test_1():\n        \"\"\"\n        Test 1: On-lattice rate normalization and event selection.\n        \"\"\"\n        rates = np.array([1.0, 2.0, 3.0, 0.0])\n        n_samples = 100000\n        seed = 12345\n        eps_norm = 1e-12\n        eps_freq = 5e-3\n        \n        total_rate = np.sum(rates)\n        if total_rate = 1e-15: return False\n\n        p_theoretical = rates / total_rate\n        \n        # 1. Check rate normalization\n        norm_check = abs(np.sum(p_theoretical) - 1.0)  eps_norm\n        if not norm_check: return False\n        \n        # 2. Empirically estimate probabilities\n        rng = np.random.default_rng(seed)\n        counts = np.zeros_like(rates, dtype=int)\n        for _ in range(n_samples):\n            idx = select_event(rates, rng)\n            if idx is not None:\n                counts[idx] += 1\n        \n        # Check that the event with rate 0 was never selected\n        if counts[3] != 0: return False\n\n        p_empirical = counts / n_samples\n        \n        # 3. Check frequency deviation\n        freq_check = np.max(np.abs(p_empirical - p_theoretical))  eps_freq\n        \n        return freq_check\n\n    def test_2():\n        \"\"\"\n        Test 2: Off-lattice rate normalization and event selection.\n        \"\"\"\n        distances = np.array([0.1, 0.2, 1.0])\n        k0 = 1.0\n        alpha = 2.5\n        n_samples = 200000\n        seed = 54321\n        eps_norm = 1e-12\n        eps_freq = 5e-3\n        \n        rates = k0 * np.exp(-alpha * distances)\n        total_rate = np.sum(rates)\n        if total_rate = 1e-15: return False\n        \n        p_theoretical = rates / total_rate\n        \n        # 1. Check rate normalization\n        norm_check = abs(np.sum(p_theoretical) - 1.0)  eps_norm\n        if not norm_check: return False\n        \n        # 2. Empirically estimate probabilities\n        rng = np.random.default_rng(seed)\n        counts = np.zeros_like(rates, dtype=int)\n        for _ in range(n_samples):\n            idx = select_event(rates, rng)\n            if idx is not None:\n                 counts[idx] += 1\n        \n        p_empirical = counts / n_samples\n        \n        # 3. Check frequency deviation\n        freq_check = np.max(np.abs(p_empirical - p_theoretical))  eps_freq\n        \n        return freq_check\n\n    def test_3():\n        \"\"\"\n        Test 3: Two-state detailed balance.\n        \"\"\"\n        energies = np.array([0.0, 1.0])\n        nu = 1.0\n        eps_db = 1e-8\n        n_states = len(energies)\n        \n        # 1. Calculate theoretical Boltzmann distribution\n        pi_boltzmann = np.exp(-energies) / np.sum(np.exp(-energies))\n        \n        # 2. Construct rate and generator matrices\n        rate_matrix = np.zeros((n_states, n_states))\n        for i in range(n_states):\n            for j in range(n_states):\n                if i != j:\n                    rate_matrix[i, j] = nu * np.exp(-(energies[j] - energies[i]) / 2.0)\n        \n        generator_matrix = rate_matrix - np.diag(np.sum(rate_matrix, axis=1))\n\n        # 3. Solve for the stationary distribution\n        # System is G.T @ pi = 0, with sum(pi) = 1\n        A = generator_matrix.T\n        A[-1, :] = 1.0 # Replace last row with normalization condition\n        b = np.zeros(n_states)\n        b[-1] = 1.0\n        \n        try:\n            pi_stationary = np.linalg.solve(A, b)\n        except np.linalg.LinAlgError:\n            return False\n\n        # 4. Compare distributions\n        return np.max(np.abs(pi_stationary - pi_boltzmann))  eps_db\n\n    def test_4():\n        \"\"\"\n        Test 4: Three-state ring detailed balance on-lattice.\n        \"\"\"\n        energies = np.array([0.0, 0.5, 1.0])\n        nu = 2.0\n        eps_db = 1e-8\n        n_states = len(energies)\n        \n        # 1. Calculate theoretical Boltzmann distribution\n        pi_boltzmann = np.exp(-energies) / np.sum(np.exp(-energies))\n        \n        # 2. Construct rate and generator matrices\n        # For 3 states, a ring is a fully connected graph.\n        rate_matrix = np.zeros((n_states, n_states))\n        for i in range(n_states):\n            for j in range(n_states):\n                if i != j:\n                    rate_matrix[i, j] = nu * np.exp(-(energies[j] - energies[i]) / 2.0)\n\n        generator_matrix = rate_matrix - np.diag(np.sum(rate_matrix, axis=1))\n\n        # 3. Solve for the stationary distribution\n        A = generator_matrix.T\n        A[-1, :] = 1.0\n        b = np.zeros(n_states)\n        b[-1] = 1.0\n        \n        try:\n            pi_stationary = np.linalg.solve(A, b)\n        except np.linalg.LinAlgError:\n            return False\n\n        # 4. Compare distributions\n        return np.max(np.abs(pi_stationary - pi_boltzmann))  eps_db\n\n    def test_5():\n        \"\"\"\n        Test 5: Boundary case R = 0.\n        \"\"\"\n        rates = np.array([0.0, 0.0, 0.0])\n        rng = np.random.default_rng() # seed doesn't matter\n        \n        result = select_event(rates, rng)\n        \n        return result is None\n\n    def test_6():\n        \"\"\"\n        Test 6: Deterministic event selection.\n        \"\"\"\n        rates = np.array([0.0, 0.0, 5.0])\n        n_samples = 10000\n        seed = 111\n        \n        rng = np.random.default_rng(seed)\n        correct_index = 2\n        \n        for _ in range(n_samples):\n            idx = select_event(rates, rng)\n            if idx != correct_index:\n                return False\n                \n        return True\n\n    results = [\n        test_1(),\n        test_2(),\n        test_3(),\n        test_4(),\n        test_5(),\n        test_6(),\n    ]\n    \n    # Format and print the final output as specified\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "多尺度建模的一个关键目标是从微观规则预测宏观性质。在离格KMC中，我们模拟单个粒子的跳跃，但我们关心的涌现行为通常是像扩散这样的集体属性。本练习要求您推导并实现一个算法，该算法直接从事件目录中计算有效扩散系数，从而在微观跳跃参数和宏观输运现象之间架起一座桥梁。",
            "id": "3790399",
            "problem": "考虑一个离格动理学蒙特卡洛（kMC）模型，其中一个质点由于一系列可能的事件在连续空间中移动。每个事件由一个速率 $r_i$（单位为 $\\mathrm{s}^{-1}$）和一个确定性位移矢量 $\\Delta \\mathbf{x}_i \\in \\mathbb{R}^d$（单位为 $\\mathrm{m}$）来表征。事件作为连续时间马尔可夫链（CTMC）随机发生，其等待时间呈指数分布，且事件的选择概率与其速率成正比。该过程可以看作一个复合泊松过程，在无穷小的时间间隔内，发生类型 $i$ 跳跃的概率与 $r_i$ 成正比，总速率为 $R = \\sum_i r_i$。\n\n从连接均方位移（MSD）与扩散系数的爱因斯坦扩散关系出发，并基于复合泊松跳跃过程的定义，推导一个基于第一性原理的算法，用以根据事件目录 $\\{(r_i,\\Delta \\mathbf{x}_i)\\}_i$ 计算 $d$ 维空间中的有效标量扩散系数 $D$（以 $\\mathrm{m}^2/\\mathrm{s}$ 为单位）。你的推导必须明确在所描述的随机动力学下，MSD 是如何由特定事件的位移和速率累积而成的，并且必须通过在 $d$ 维空间中的适当维度因子，将这种累积与 $D$ 逻辑上关联起来。不要假设或使用任何预先推导出的 $D$ 的简化公式；相反，应从上述基本定义出发构建计算过程。\n\n实现一个程序，该程序对每个提供的测试用例，使用你推导出的算法计算有效标量扩散系数 $D$（以 $\\mathrm{m}^2/\\mathrm{s}$ 为单位）。此问题不涉及角度，因此无需指定角度单位。程序必须以实数（浮点值）形式产生结果。\n\n使用以下测试套件（每个测试用例定义了一个维度 $d$ 和一个事件列表，其中每个事件是一个数对 $(r_i, \\Delta \\mathbf{x}_i)$，$r_i$ 的单位是 $\\mathrm{s}^{-1}$，$\\Delta \\mathbf{x}_i$ 的单位是 $\\mathrm{m}$）：\n\n- 测试用例 $1$（理想情况，d=2 下各向同性）：$d=2$；事件 $[ (\\,5.0,\\,(1\\times 10^{-9},\\,0)\\,),\\ (\\,5.0,\\,(0,\\,1\\times 10^{-9})\\,) ]$。\n- 测试用例 $2$（d=3 下各向异性，具有混合的量值和速率）：$d=3$；事件 $[ (\\,1\\times 10^{3},\\,(1\\times 10^{-10},\\,0,\\,0)\\,),\\ (\\,2\\times 10^{2},\\,(0,\\,2\\times 10^{-10},\\,0)\\,),\\ (\\,5\\times 10^{1},\\,(0,\\,0,\\,1\\times 10^{-9})\\,) ]$。\n- 测试用例 $3$（边界情况，由于零位移/零速率导致零迁移率）：$d=2$；事件 $[ (\\,1\\times 10^{4},\\,(0,\\,0)\\,),\\ (\\,0,\\,(1\\times 10^{-9},\\,-1\\times 10^{-9})\\,) ]$。\n- 测试用例 $4$（d=2 下稀疏长跳跃与频繁短跳跃之间的竞争）：$d=2$；事件 $[ (\\,1.0,\\,(1\\times 10^{-6},\\,1\\times 10^{-6})\\,),\\ (\\,1\\times 10^{5},\\,(1\\times 10^{-9},\\,0)\\,) ]$。\n- 测试用例 $5$（d=3 下的离格非正交位移）：$d=3$；事件 $[ (\\,10,\\,(3\\times 10^{-10},\\,4\\times 10^{-10},\\,0)\\,),\\ (\\,20,\\,( -3\\times 10^{-10},\\,0,\\,4\\times 10^{-10})\\,),\\ (\\,30,\\,(0,\\,-4\\times 10^{-10},\\,3\\times 10^{-10})\\,) ]$。\n\n你的程序应产生单行输出，其中包含一个用方括号括起来的、以逗号分隔的结果列表，其顺序与上述测试用例一致（例如 $[D_1,D_2,D_3,D_4,D_5]$），其中每个 $D_k$ 是为测试用例 $k$ 计算出的扩散系数，单位为 $\\mathrm{m}^2/\\mathrm{s}$。",
            "solution": "目标是为一个在 $d$ 维连续空间中经历随机跳跃过程的粒子，推导计算其有效标量扩散系数 $D$ 的算法，然后实现该算法。推导过程必须从第一性原理出发，具体来说是爱因斯坦关系式以及底层的复合泊松过程的定义。\n\n### 从第一性原理推导\n\n我们分析的基础是爱因斯坦扩散关系，它在长时间极限下将粒子的均方位移（MSD）与扩散系数 $D$ 联系起来。在 $d$ 维空间中，该关系式为：\n$$\n\\langle \\|\\mathbf{x}(t) - \\mathbf{x}(0)\\|^2 \\rangle = 2 d D t\n$$\n其中 $\\mathbf{x}(t)$ 是粒子在时间 $t$ 的位置，$\\langle \\cdot \\rangle$ 表示对所有可能的随机轨迹的系综平均。等式左侧是 MSD。由此，扩散系数可以定义为：\n$$\nD = \\lim_{t \\to \\infty} \\frac{\\langle \\|\\mathbf{x}(t) - \\mathbf{x}(0)\\|^2 \\rangle}{2 d t}\n$$\n问题指明，粒子的运动由一系列以 $i$ 为索引的不同事件类型所支配。每种事件类型 $i$ 都由一个恒定速率 $r_i$ 和一个确定性位移矢量 $\\Delta \\mathbf{x}_i$ 来表征。类型 $i$ 事件的发生构成一个速率为 $r_i$ 的泊松过程。整个过程是一个复合泊松过程，意味着不同类型的事件是独立发生的。\n\n让我们对粒子随时间的位置进行建模。不失一般性，我们将初始位置设为原点，即 $\\mathbf{x}(0) = \\mathbf{0}$。在稍后的时间 $t$，其位置是截至该时间发生的所有位移事件的矢量和：\n$$\n\\mathbf{x}(t) = \\sum_i n_i(t) \\Delta \\mathbf{x}_i\n$$\n其中 $n_i(t)$ 是在时间间隔 $[0, t]$ 内事件 $i$ 发生的次数。由于每种事件类型都遵循泊松过程，$n_i(t)$ 是一个服从泊松分布的随机变量，其均值和方差由下式给出：\n$$\n\\langle n_i(t) \\rangle = \\text{Var}(n_i(t)) = r_i t\n$$\n此外，由于事件过程的独立性，不同事件类型计数之间的协方差为零：\n$$\n\\text{Cov}(n_i(t), n_j(t)) = \\langle (n_i(t) - \\langle n_i(t) \\rangle)(n_j(t) - \\langle n_j(t) \\rangle) \\rangle = 0 \\quad \\text{for } i \\neq j\n$$\n综合这些，我们可以写出 $\\text{Cov}(n_i(t), n_j(t)) = \\delta_{ij} r_i t$，其中 $\\delta_{ij}$ 是克罗内克 δ 符号。\n\n爱因斯坦关系中的 MSD 指的是粒子位置的方差，它衡量粒子位置围绕其平均位置的分布广度。让我们首先计算平均位置 $\\langle \\mathbf{x}(t) \\rangle$：\n$$\n\\langle \\mathbf{x}(t) \\rangle = \\left\\langle \\sum_i n_i(t) \\Delta \\mathbf{x}_i \\right\\rangle = \\sum_i \\langle n_i(t) \\rangle \\Delta \\mathbf{x}_i = \\sum_i (r_i t) \\Delta \\mathbf{x}_i = t \\left( \\sum_i r_i \\Delta \\mathbf{x}_i \\right)\n$$\n项 $\\mathbf{v}_{\\text{drift}} = \\sum_i r_i \\Delta \\mathbf{x}_i$ 代表一个恒定的漂移速度。扩散运动是围绕此平均漂移的随机涨落。因此，用于扩散计算的正确 MSD 是位置的方差：\n$$\n\\text{MSD}(t) = \\langle \\|\\mathbf{x}(t) - \\langle \\mathbf{x}(t) \\rangle\\|^2 \\rangle\n$$\n现在我们来计算这个方差。我们将其表示为 $\\mathbf{x}(t)$ 的协方差矩阵的迹（trace）：\n$$\n\\text{MSD}(t) = \\text{Tr}(\\text{Cov}(\\mathbf{x}(t))) = \\text{Tr}\\left( \\left\\langle (\\mathbf{x}(t) - \\langle \\mathbf{x}(t) \\rangle)(\\mathbf{x}(t) - \\langle \\mathbf{x}(t) \\rangle)^T \\right\\rangle \\right)\n$$\n代入 $\\mathbf{x}(t)$ 的表达式：\n$$\n\\mathbf{x}(t) - \\langle \\mathbf{x}(t) \\rangle = \\sum_i n_i(t) \\Delta \\mathbf{x}_i - \\sum_i \\langle n_i(t) \\rangle \\Delta \\mathbf{x}_i = \\sum_i (n_i(t) - \\langle n_i(t) \\rangle) \\Delta \\mathbf{x}_i\n$$\n协方差矩阵则为：\n$$\n\\text{Cov}(\\mathbf{x}(t)) = \\left\\langle \\left( \\sum_i (n_i(t) - \\langle n_i(t) \\rangle) \\Delta \\mathbf{x}_i \\right) \\left( \\sum_j (n_j(t) - \\langle n_j(t) \\rangle) \\Delta \\mathbf{x}_j \\right)^T \\right\\rangle\n$$\n$$\n= \\sum_{i,j} \\Delta \\mathbf{x}_i \\Delta \\mathbf{x}_j^T \\left\\langle (n_i(t) - \\langle n_i(t) \\rangle)(n_j(t) - \\langle n_j(t) \\rangle) \\right\\rangle\n$$\n期望项正是协方差 $\\text{Cov}(n_i(t), n_j(t)) = \\delta_{ij} r_i t$。双重求和坍缩为对 $i$ 的单一求和：\n$$\n\\text{Cov}(\\mathbf{x}(t)) = \\sum_i \\Delta \\mathbf{x}_i \\Delta \\mathbf{x}_i^T (r_i t) = t \\sum_i r_i (\\Delta \\mathbf{x}_i \\otimes \\Delta \\mathbf{x}_i)\n$$\n其中 $\\otimes$ 表示外积。\n\nMSD 是该矩阵的迹：\n$$\n\\text{MSD}(t) = \\text{Tr}\\left( t \\sum_i r_i (\\Delta \\mathbf{x}_i \\otimes \\Delta \\mathbf{x}_i) \\right) = t \\sum_i r_i \\text{Tr}(\\Delta \\mathbf{x}_i \\otimes \\Delta \\mathbf{x}_i)\n$$\n一个矢量与其自身外积的迹 $\\text{Tr}(\\mathbf{v} \\otimes \\mathbf{v})$，等于该矢量的模的平方（或点积），即 $\\|\\mathbf{v}\\|^2$。因此：\n$$\n\\text{MSD}(t) = t \\sum_i r_i \\|\\Delta \\mathbf{x}_i\\|^2\n$$\n这个结果表明 MSD 随时间线性增长，这是扩散过程的标志。增长速率由每个事件的速率乘以其跳跃距离平方的总和决定。\n\n最后，我们将这个推导出的 MSD 表达式代入扩散系数的定义中：\n$$\nD = \\lim_{t \\to \\infty} \\frac{t \\sum_i r_i \\|\\Delta \\mathbf{x}_i\\|^2}{2 d t}\n$$\n因子 $t$ 被约去，得到最终公式：\n$$\nD = \\frac{1}{2d} \\sum_i r_i \\|\\Delta \\mathbf{x}_i\\|^2\n$$\n\n### 算法\n基于此推导，计算标量扩散系数 $D$ 的算法如下：\n1.  初始化一个求和变量 $S$ 为 $0$。\n2.  对于所提供目录 $\\{(r_i, \\Delta \\mathbf{x}_i)\\}_i$ 中的每个事件 $i$：\n    a.  取位移矢量 $\\Delta \\mathbf{x}_i$。\n    b.  计算其欧几里得范数（模）的平方：$\\|\\Delta \\mathbf{x}_i\\|^2 = \\Delta \\mathbf{x}_i \\cdot \\Delta \\mathbf{x}_i = \\sum_{j=1}^{d} (\\Delta x_{i,j})^2$。\n    c.  将此平方范数乘以事件速率 $r_i$。\n    d.  将得到的乘积 $r_i \\|\\Delta \\mathbf{x}_i\\|^2$ 加到求和变量 $S$ 上。\n3.  遍历所有事件后，通过将总和 $S$ 除以因子 $2d$ 来计算扩散系数，其中 $d$ 是空间维度。\n\n该算法直接实现了推导出的公式，并基于指定的第一性原理。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the effective diffusion coefficient based on a catalog of\n    kMC events.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # Each test case is a tuple: (dimension, list_of_events)\n    # Each event is a tuple: (rate, displacement_vector)\n    test_cases = [\n        # Test Case 1 (happy path, isotropic in d=2)\n        (2, [\n            (5.0, np.array([1e-9, 0.0])),\n            (5.0, np.array([0.0, 1e-9]))\n        ]),\n        \n        # Test Case 2 (anisotropic in d=3 with mixed magnitudes and rates)\n        (3, [\n            (1e3, np.array([1e-10, 0.0, 0.0])),\n            (2e2, np.array([0.0, 2e-10, 0.0])),\n            (5e1, np.array([0.0, 0.0, 1e-9]))\n        ]),\n\n        # Test Case 3 (boundary case, zero mobility)\n        (2, [\n            (1e4, np.array([0.0, 0.0])),\n            (0.0, np.array([1e-9, -1e-9]))\n        ]),\n\n        # Test Case 4 (competition between rare long jumps and frequent short jumps in d=2)\n        (2, [\n            (1.0, np.array([1e-6, 1e-6])),\n            (1e5, np.array([1e-9, 0.0]))\n        ]),\n\n        # Test Case 5 (off-lattice non-orthogonal displacements in d=3)\n        (3, [\n            (10.0, np.array([3e-10, 4e-10, 0.0])),\n            (20.0, np.array([-3e-10, 0.0, 4e-10])),\n            (30.0, np.array([0.0, -4e-10, 3e-10]))\n        ])\n    ]\n\n    results = []\n    \n    # Process each test case using the derived formula.\n    # D = (1 / (2*d)) * sum(r_i * ||dx_i||^2)\n    for d, events in test_cases:\n        # Initialize the sum of rate-weighted squared displacements\n        sum_r_dx_sq = 0.0\n        \n        for rate, dx_vec in events:\n            # Calculate the squared magnitude (norm) of the displacement vector\n            # ||dx_i||^2 is equivalent to the dot product of the vector with itself\n            squared_magnitude = np.dot(dx_vec, dx_vec)\n            \n            # Add the contribution of this event to the sum\n            sum_r_dx_sq += rate * squared_magnitude\n\n        # Handle the case where the denominator 2*d could be zero, though\n        # d is always >= 1 in this problem's context.\n        if d > 0:\n            diffusion_coefficient = sum_r_dx_sq / (2 * d)\n        else:\n            # Physically, d=0 is ill-defined for diffusion.\n            # For completeness, return 0.\n            diffusion_coefficient = 0.0\n\n        results.append(diffusion_coefficient)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在简单的在格KMC模型和更复杂的离格模型之间做出选择，通常取决于系统是否具有“记忆”。标准KMC是无记忆的（马尔可夫过程），但真实系统，尤其是在粗粒化处理后，可能表现出非马尔可夫行为。本练习介绍了一种基于时间重整化定理的强大统计方法，通过分析等待时间分布来诊断记忆效应，帮助您判断简单的指数等待时间模型是否适用于您的系统。",
            "id": "3790261",
            "problem": "您的任务是基于随机过程的基本原理，设计并实现一个诊断性检验，用于区分马尔可夫链格上动力学蒙特卡洛（Markovian on-lattice kinetic Monte Carlo）与通过非指数等待时间统计表现出记忆效应的粗粒化离格动力学。在马尔可夫链格上动力学蒙特卡洛中，由于其无记忆性，事件的等待时间是独立同分布的指数随机变量。相反，粗粒化、未解析的自由度或集体性离格运动可以引入有效的记忆核，并导致非指数的等待时间。\n\n从以下基础理论出发：\n\n- 更新过程具有独立同分布的等待时间 $\\{T_i\\}_{i=1}^N$，其累积分布函数为 $F(t)$，概率密度函数为 $f(t) = F'(t)$，生存函数为 $S(t) = 1 - F(t)$，风险函数为 $h(t) = \\dfrac{f(t)}{S(t)}$。\n- 泊松过程具有无记忆性 $P(T  t + s \\mid T  s) = P(T  t)$，这等价于 $h(t) = \\lambda$（常数）和 $f(t) = \\lambda e^{-\\lambda t}$（指数分布）。\n- 时间重标度定理指出，如果风险函数模型 $h(t)$ 是正确的，那么变换后的变量 $\\tau_i = \\int_0^{T_i} h(s)\\,ds$ 是速率为1的独立同分布指数随机变量，并且 $U_i = 1 - e^{-\\tau_i}$ 是[0,1]区间上的独立同分布均匀随机变量。\n\n您的目标是构建一个程序，应用基于时间重标度的拟合优度检验来验证等待时间是否呈指数分布（即马尔可夫原假设），从而诊断出指示记忆核存在的偏差。使用以下检验规范：\n\n- 在原假设下，估计恒定风险为 $\\hat{\\lambda} = 1/\\bar{T}$，其中 $\\bar{T}$ 是等待时间的样本均值。\n- 计算 $\\tau_i = \\hat{\\lambda} T_i$ 和 $U_i = 1 - e^{-\\tau_i}$。\n- 对 $\\{U_i\\}$ 样本执行 Kolmogorov–Smirnov 检验，以检验其是否服从 Uniform$(0,1)$ 分布，显著性水平 $\\alpha = 0.01$。若拒绝原假设，则表明统计数据为非指数分布，因此存在记忆核效应。\n\n此外，计算一个风险变异指数（用于提高可解释性，不用于决策），该指数在经验支撑集的 $B$ 个等距分箱上定义如下：令 $\\widehat{f}_b$ 为分箱 $b$ 中基于直方图的密度估计，$\\widehat{S}_b$ 为分箱 $b$ 左边缘的经验生存函数值。对于 $\\widehat{S}_b  0.05$ 的分箱，定义分箱风险估计为 $\\widehat{h}_b = \\widehat{f}_b / \\widehat{S}_b$，变异系数为 $\\mathrm{CV}_h = \\dfrac{\\mathrm{std}(\\{\\widehat{h}_b\\})}{\\mathrm{mean}(\\{\\widehat{h}_b\\})}$。接近于零的 $\\mathrm{CV}_h$ 是恒定风险的特征。\n\n为以下测试套件构建以秒为单位的合成等待时间样本，以测试该方法的不同方面：\n\n- 情况 A（理想路径，马尔可夫链格上）：速率为 $\\lambda_A = 2\\,\\mathrm{s}^{-1}$ 的指数分布；样本量 $N_A = 5000$。\n- 情况 B（具有老化记忆的离格系统；重尾行为的边界）：形状参数为 $k_B = 0.7$、尺度参数 $\\theta_B$ 经选择以使 $\\mathbb{E}[T] = 0.5\\,\\mathrm{s}$（即 $\\theta_B = 0.5 / \\Gamma(1 + 1/k_B)$）的 Weibull 分布；样本量 $N_B = 5000$。\n- 情况 C（隐藏的异质性；导致非指数统计的混合分布）：超指数混合分布，其中以概率 $p_C = 0.3$，$T \\sim \\mathrm{Exp}(\\lambda_1)$ 且 $\\lambda_1 = 1\\,\\mathrm{s}^{-1}$；以概率 $1 - p_C$，$T \\sim \\mathrm{Exp}(\\lambda_2)$ 且 $\\lambda_2 = 5\\,\\mathrm{s}^{-1}$；样本量 $N_C = 5000$。\n- 情况 D（小样本边界条件，马尔可夫）：速率为 $\\lambda_D = 2\\,\\mathrm{s}^{-1}$ 的指数分布；样本量 $N_D = 50$。\n\n所有等待时间均以秒为单位。为保证可复现性，请使用固定的伪随机种子。您的程序必须：\n\n- 为四种情况生成等待时间样本。\n- 在 $\\alpha = 0.01$ 的显著性水平下，应用所述的时间重标度检验。\n- 生成单行输出，其中包含一个由四个布尔值组成的列表 $[b_A, b_B, b_C, b_D]$，如果检验拒绝了情况 X 的指数分布原假设，则 $b_X$ 为 $\\mathrm{True}$，否则为 $\\mathrm{False}$。该行必须严格按照逗号分隔的 Python 风格列表格式打印，例如：“[True,False,True,False]”。\n\n通过使用给定的分布和参数来确保科学真实性。输出由布尔值组成，因此没有物理单位。代码必须是自包含的，并且无需用户输入即可运行。",
            "solution": "该问题要求设计并实现一个统计检验，用以在动力学蒙特卡洛（kMC）模拟中诊断对马尔可夫行为的偏离。该检验的物理基础在于，随机过程的马尔可夫性质与其等待时间的统计分布之间存在紧密联系。\n\n格上 kMC 的一个基本原则是，系统的演化是一个连续时间马尔可夫链。这意味着该过程是无记忆的：跃迁到未来状态的概率仅取决于当前状态，而与到达该状态的路径无关。这种无记忆性的一个直接数学推论是，直到下一个事件发生的等待时间 $T$ 服从指数分布 $f(t) = \\lambda e^{-\\lambda t}$，其中速率参数 $\\lambda$ 是从当前状态出发所有可能事件的速率之和。在总速率恒定的模拟中，等待时间序列 $\\{T_i\\}_{i=1}^N$ 构成了泊松过程的一个样本。\n\n相反，离格系统或粗粒化模型通常表现出记忆性。这种“记忆”源于未解析的自由度或集体运动，导致事件发生的概率取决于系统的历史。这样的过程是非马尔可夫的，其等待时间不呈指数分布。这些过程更普遍地被描述为更新过程，其特征是从某个非指数分布中抽取的独立同分布（i.i.d.）等待时间序列 $\\{T_i\\}$。\n\n任何更新过程都可以通过其风险函数 $h(t)$ 来表征，该函数给出在事件尚未发生的情况下，于时间 $t$ 发生事件的瞬时概率速率。其形式上定义为 $h(t) = f(t)/S(t)$，其中 $f(t)$ 是概率密度函数（PDF），$S(t) = 1 - F(t)$ 是生存函数（$F(t)$ 是累积分布函数，CDF）。马尔可夫过程的无记忆性唯一等价于具有恒定的风险函数 $h(t) = \\lambda$。任何对恒定风险的偏离都表明这是一个非马尔可夫的、依赖于记忆的过程。\n\n该诊断性检验通过时间重标度定理利用了这一原理。该定理指出，如果一组等待时间 $\\{T_i\\}$ 是从一个具有已知风险函数 $h(t)$ 的分布中抽取的，那么变换后的变量 $\\tau_i = \\int_0^{T_i} h(s)\\,ds$ 是独立同分布（i.i.d.）的，并服从速率为 1 的指数分布。\n\n我们可以基于该定理构建一个统计检验。原假设 $H_0$ 是等待时间呈指数分布，这对应于一个马尔可夫过程。\n$H_0$：等待时间 $\\{T_i\\}$ 是从某个未知 $\\lambda  0$ 的 $\\mathrm{Exponential}(\\lambda)$ 分布中抽取的。\n\n在 $H_0$ 成立的条件下，风险函数是恒定的，$h(t) = \\lambda$。给定一个包含 $N$ 个等待时间的样本，该速率的最大似然估计量是 $\\hat{\\lambda} = 1/\\bar{T}$，其中 $\\bar{T} = \\frac{1}{N}\\sum_{i=1}^N T_i$ 是样本均值。\n\n使用这个估计的风险函数应用时间重标度定理，我们计算重标度后的时间：\n$$ \\tau_i = \\int_0^{T_i} \\hat{\\lambda}\\,ds = \\hat{\\lambda} T_i $$\n如果 $H_0$ 为真，集合 $\\{\\tau_i\\}$ 应为来自 $\\mathrm{Exponential}(1)$ 分布的样本。\n\n为了便于检验，我们应用概率积分变换。如果一个随机变量 $\\tau$ 服从 $\\mathrm{Exponential}(1)$ 分布，其累积分布函数（CDF）为 $F_{\\tau}(t) = 1 - e^{-t}$。那么变换后的变量 $U = F_{\\tau}(\\tau) = 1 - e^{-\\tau}$ 将在区间 $[0, 1]$ 上均匀分布。因此，通过对整个样本计算 $U_i = 1 - e^{-\\tau_i} = 1 - e^{-\\hat{\\lambda} T_i}$，我们可以将问题重构为检验一个新的原假设 $H'_0$：\n$H'_0$：样本 $\\{U_i\\}$ 是从 $\\mathrm{Uniform}(0, 1)$ 分布中抽取的。\n\n这个假设使用双边 Kolmogorov-Smirnov (KS) 检验进行验证。KS 检验将样本 $\\{U_i\\}$ 的经验累积分布函数与 $\\mathrm{Uniform}(0, 1)$ 分布的累积分布函数进行比较。它量化了两者之间的最大差异并计算出一个 p 值。该 p 值表示在数据确实来自 $\\mathrm{Uniform}(0, 1)$ 分布的情况下，观测到如此大（或更大）差异的概率。如果 p 值小于预定的显著性水平 $\\alpha$（此处为 $\\alpha = 0.01$），我们就拒绝 $H'_0$，并进而拒绝原假设 $H_0$。拒绝原假设表明等待时间数据与指数分布不一致，为存在记忆的非马尔可夫动力学提供了强有力的证据。\n\n提供的测试用例旨在验证此程序：\n- 情况 A（指数分布，$N_A=5000$, $\\lambda_A = 2\\,\\mathrm{s}^{-1}$）：原假设为真。我们预期会得到一个高的 p 值并且不会拒绝 $H_0$（结果：`False`）。\n- 情况 B（Weibull 分布，$N_B=5000$, $k_B=0.7$）：形状参数 $k_B  1$ 意味着风险率递减，这明显违反了 $H_0$。对于大样本，该检验应有足够的能力检测到这一点。我们预期会拒绝 $H_0$（结果：`True`）。\n- 情况 C（超指数分布，$N_C=5000$）：这种指数分布的混合本身不是指数分布，并且具有非恒定的风险函数。我们预期会拒绝 $H_0$（结果：`True`）。\n- 情况 D（指数分布，$N_D=50$, $\\lambda_D = 2\\,\\mathrm{s}^{-1}$）：原假设为真，但小样本量大大降低了检验的统计功效。最可能的结果是无法拒绝 $H_0$，这说明了在数据不足的情况下进行统计检验的局限性（结果：`False`）。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats, special\n\ndef solve():\n    \"\"\"\n    Runs a diagnostic test on four synthetic waiting-time datasets to distinguish\n    Markovian (exponential) from non-Markovian (non-exponential) dynamics.\n    \"\"\"\n    # Define constants and the pseudorandom number generator for reproducibility.\n    SEED = 12345\n    rng = np.random.default_rng(SEED)\n    ALPHA = 0.01\n\n    # --- Case A: Exponential (Markovian null hypothesis is true) ---\n    N_A = 5000\n    lambda_A = 2.0\n    # The 'scale' parameter for numpy.random.exponential is 1/lambda.\n    samples_A = rng.exponential(scale=1.0/lambda_A, size=N_A)\n\n    # --- Case B: Weibull (Non-Markovian, aging memory) ---\n    N_B = 5000\n    k_B = 0.7  # Shape parameter\n    mean_B = 0.5\n    # The mean of a Weibull(k, theta) distribution is theta * Gamma(1 + 1/k).\n    # We solve for the scale parameter theta.\n    theta_B = mean_B / special.gamma(1.0 + 1.0/k_B)\n    # numpy.random.weibull(a) generates samples with scale=1. We must\n    # multiply by the calculated scale parameter theta_B.\n    samples_B = theta_B * rng.weibull(a=k_B, size=N_B)\n\n    # --- Case C: Hyperexponential (Non-Markovian, mixture) ---\n    N_C = 5000\n    p_C = 0.3\n    lambda1_C = 1.0\n    lambda2_C = 5.0\n    \n    # Generate mixture samples.\n    choices_C = rng.uniform(size=N_C)\n    samples_C = np.zeros(N_C)\n    # Create a boolean mask to select which samples come from the first exponential.\n    mask1 = choices_C  p_C\n    n1 = np.sum(mask1)\n    n2 = N_C - n1\n    samples_C[mask1] = rng.exponential(scale=1.0/lambda1_C, size=n1)\n    samples_C[~mask1] = rng.exponential(scale=1.0/lambda2_C, size=n2)\n\n    # --- Case D: Exponential, small sample (test of statistical power) ---\n    N_D = 50\n    lambda_D = 2.0\n    samples_D = rng.exponential(scale=1.0/lambda_D, size=N_D)\n\n    all_samples = [samples_A, samples_B, samples_C, samples_D]\n    results = []\n\n    for T_values in all_samples:\n        # --- Apply the time-rescaling goodness-of-fit test ---\n        \n        # 1. Estimate the constant hazard rate lambda under the null hypothesis.\n        # The Maximum Likelihood Estimator for an exponential distribution is 1/mean.\n        T_bar = np.mean(T_values)\n        \n        # Edge case handling: a non-positive mean is impossible for waiting times\n        # and would not be exponential.\n        if T_bar = 0:\n            results.append(True)  # Reject the null hypothesis.\n            continue\n            \n        lambda_hat = 1.0 / T_bar\n\n        # 2. Apply the time-rescaling theorem and the probability integral transform.\n        # If the data is exponential, the transformed variables U should be Uniform(0,1).\n        U_values = 1.0 - np.exp(-lambda_hat * T_values)\n\n        # 3. Perform a Kolmogorov-Smirnov test against the Uniform(0,1) distribution.\n        # The null hypothesis of kstest is that the data is drawn from the specified dist.\n        ks_statistic, p_value = stats.kstest(U_values, 'uniform')\n\n        # 4. Make a decision based on the significance level alpha.\n        # We reject the null hypothesis if the p-value is less than alpha.\n        is_rejected = p_value  ALPHA\n        results.append(is_rejected)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(str(r) for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}