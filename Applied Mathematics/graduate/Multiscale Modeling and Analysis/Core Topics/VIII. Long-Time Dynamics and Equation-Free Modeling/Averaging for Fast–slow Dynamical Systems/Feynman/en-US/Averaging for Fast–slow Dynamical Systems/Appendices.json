{
    "hands_on_practices": [
        {
            "introduction": "Before applying averaging, it is crucial to understand when the averaged drift vanishes at the leading order. This problem explores the concept of a coboundary, where the oscillatory forcing term can be expressed as a total derivative along the fast flow. By working through this exercise , you will prove from first principles that such terms average to zero, providing a deeper insight into the mathematical structure that underpins the averaging method itself.",
            "id": "3734750",
            "problem": "Consider the fast–slow ordinary differential equation (ODE) system on the circle $\\mathbb{T}=\\mathbb{R}/(2\\pi\\mathbb{Z})$ for a fast phase $y_{\\varepsilon}(t)\\in\\mathbb{T}$ and a slow variable $x_{\\varepsilon}(t)\\in\\mathbb{R}$:\n$$\n\\dot{x}_{\\varepsilon}(t)=f\\bigl(x_{\\varepsilon}(t),y_{\\varepsilon}(t)\\bigr),\\qquad \\dot{y}_{\\varepsilon}(t)=\\frac{1}{\\varepsilon}\\,b\\bigl(y_{\\varepsilon}(t)\\bigr),\n$$\nwith $\\varepsilon\\in(0,1]$ small and $b:\\mathbb{T}\\to\\mathbb{R}$ a smooth function that is strictly positive everywhere on $\\mathbb{T}$. Let $\\mathcal{L}_{b}$ denote the Lie derivative along the fast vector field $b$, that is, for a smooth function $g:\\mathbb{R}\\times\\mathbb{T}\\to\\mathbb{R}$ that is $2\\pi$-periodic in its second argument,\n$$\n\\mathcal{L}_{b} g(x,y):=\\partial_{y}g(x,y)\\,b(y).\n$$\nAssume that $f$ is a coboundary relative to the fast flow in the sense that $f(x,y)=\\mathcal{L}_{b} g(x,y)$ for some such $g$. Using only the chain rule, the definition of Lie derivative, and the fact that the fast flow on $\\mathbb{T}$ generated by $\\dot{y}=b(y)$ admits a unique smooth invariant probability measure absolutely continuous with respect to Lebesgue measure, do the following:\n\n1. Show from first principles that the averaged drift of the slow variable vanishes, in the precise sense that the averaged vector field\n$$\n\\bar{f}(x):=\\int_{\\mathbb{T}} f(x,y)\\,\\mu(\\mathrm{d}y)\n$$\nequals $0$ for all $x\\in\\mathbb{R}$, where $\\mu$ is the invariant probability measure of the fast flow.\n\n2. Specialize to the explicit fast flow with constant speed $b(y)=\\omega$ for a given constant $\\omega>0$, so that $\\dot{y}_{\\varepsilon}(t)=\\omega/\\varepsilon$. Choose $g$ independent of $x$ and equal to $g(y)=\\sin(y)$, and hence define $f(x,y):=\\mathcal{L}_{b}g(x,y)=\\omega\\cos(y)$. With initial conditions $x_{\\varepsilon}(0)=x_{0}$ and $y_{\\varepsilon}(0)=y_{0}$, compute the exact expression for $x_{\\varepsilon}(T)$ at an arbitrary final time $T>0$ in terms of $x_{0}$, $y_{0}$, $\\omega$, $\\varepsilon$, and $T$. Express your final result as a single closed-form analytic expression. No rounding is required, and no physical units are involved. Angles are to be treated as dimensionless (radians) on $\\mathbb{T}$.",
            "solution": "The problem is well-posed, scientifically grounded, and contains sufficient information for a unique solution.\n\n**Part 1: Vanishing Averaged Drift**\n\nWe are tasked to show that the averaged vector field $\\bar{f}(x)$ vanishes for all $x \\in \\mathbb{R}$, where\n$$\n\\bar{f}(x) := \\int_{\\mathbb{T}} f(x,y)\\,\\mu(\\mathrm{d}y).\n$$\nThe problem states that $f(x,y)$ is a coboundary, meaning $f(x,y) = \\mathcal{L}_b g(x,y) = \\partial_{y}g(x,y) b(y)$ for some smooth function $g$ that is $2\\pi$-periodic in its second argument. The measure $\\mu$ is the unique smooth invariant probability measure for the fast flow on the circle $\\mathbb{T} = \\mathbb{R}/(2\\pi\\mathbb{Z})$, which is generated by the vector field $b(y)$. The governing equation for this fast flow is $\\dot{y} = b(y)$.\n\nThe invariance of the measure $\\mu$ with respect to the flow $\\phi_t$ generated by $b(y)$ means that for any smooth, $2\\pi$-periodic test function $h(y)$ on $\\mathbb{T}$, the integral of $h$ against $\\mu$ is constant along the flow. That is,\n$$\n\\int_{\\mathbb{T}} h(\\phi_t(y))\\,\\mu(\\mathrm{d}y) = \\int_{\\mathbb{T}} h(y)\\,\\mu(\\mathrm{d}y) \\quad \\text{for all } t \\in \\mathbb{R}.\n$$\nSince the right-hand side is constant, the time derivative of the left-hand side must be zero. We differentiate with respect to $t$ and evaluate at $t=0$:\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}t}\\bigg|_{t=0} \\int_{\\mathbb{T}} h(\\phi_t(y))\\,\\mu(\\mathrm{d}y) = 0.\n$$\nFor smooth functions, we can interchange differentiation and integration:\n$$\n\\int_{\\mathbb{T}} \\left( \\frac{\\mathrm{d}}{\\mathrm{d}t}\\bigg|_{t=0} h(\\phi_t(y)) \\right) \\mu(\\mathrm{d}y) = 0.\n$$\nUsing the chain rule, the derivative inside the integral is\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}t}\\bigg|_{t=0} h(\\phi_t(y)) = \\partial_y h(y) \\cdot \\frac{\\mathrm{d}\\phi_t(y)}{\\mathrm{d}t}\\bigg|_{t=0}.\n$$\nBy definition of the flow, $\\frac{\\mathrm{d}\\phi_t(y)}{\\mathrm{d}t} = b(\\phi_t(y))$, so at $t=0$, this gives $\\frac{\\mathrm{d}\\phi_t(y)}{\\mathrm{d}t}\\big|_{t=0} = b(\\phi_0(y)) = b(y)$.\nTherefore, the expression inside the integral becomes\n$$\n\\partial_y h(y) \\, b(y) = \\mathcal{L}_b h(y),\n$$\nwhich is the Lie derivative of $h$ along the vector field $b$.\nThus, a fundamental property of the invariant measure $\\mu$ is that the integral of the Lie derivative of any smooth $2\\pi$-periodic function vanishes:\n$$\n\\int_{\\mathbb{T}} \\mathcal{L}_b h(y)\\,\\mu(\\mathrm{d}y) = 0.\n$$\nNow, we apply this property to compute $\\bar{f}(x)$. We substitute the coboundary condition $f(x,y) = \\mathcal{L}_b g(x,y)$ into the definition of $\\bar{f}(x)$:\n$$\n\\bar{f}(x) = \\int_{\\mathbb{T}} \\mathcal{L}_b g(x,y)\\,\\mu(\\mathrm{d}y).\n$$\nFor any fixed $x \\in \\mathbb{R}$, the function $y \\mapsto g(x,y)$ is a smooth, $2\\pi$-periodic function on $\\mathbb{T}$. Let's denote this function by $g_x(y) = g(x,y)$. Then the integrand is $\\mathcal{L}_b g_x(y)$.\nBased on the general property derived above (with $h=g_x$), we have\n$$\n\\bar{f}(x) = \\int_{\\mathbb{T}} \\mathcal{L}_b g_x(y)\\,\\mu(\\mathrm{d}y) = 0.\n$$\nThis holds for all $x \\in \\mathbb{R}$, which completes the proof.\n\n**Part 2: Exact Solution for a Specific Case**\n\nWe are given the specific system:\n$$\n\\dot{x}_{\\varepsilon}(t) = \\omega\\cos\\bigl(y_{\\varepsilon}(t)\\bigr), \\qquad \\dot{y}_{\\varepsilon}(t) = \\frac{\\omega}{\\varepsilon},\n$$\nwith initial conditions $x_{\\varepsilon}(0) = x_0$ and $y_{\\varepsilon}(0) = y_0$. We need to find the exact expression for $x_{\\varepsilon}(T)$ at a time $T > 0$.\n\nFirst, we solve the equation for the fast variable $y_{\\varepsilon}(t)$. This is a simple linear ODE.\n$$\n\\frac{\\mathrm{d}y_{\\varepsilon}}{\\mathrm{d}t} = \\frac{\\omega}{\\varepsilon}.\n$$\nIntegrating with respect to time from $0$ to $t$ yields:\n$$\n\\int_{y_{\\varepsilon}(0)}^{y_{\\varepsilon}(t)} \\mathrm{d}y = \\int_0^t \\frac{\\omega}{\\varepsilon} \\mathrm{d}\\tau.\n$$\n$$\ny_{\\varepsilon}(t) - y_0 = \\frac{\\omega}{\\varepsilon}t.\n$$\nThus, the solution for the fast variable is:\n$$\ny_{\\varepsilon}(t) = y_0 + \\frac{\\omega t}{\\varepsilon}.\n$$\nNext, we substitute this solution into the equation for the slow variable $x_{\\varepsilon}(t)$:\n$$\n\\frac{\\mathrm{d}x_{\\varepsilon}}{\\mathrm{d}t} = \\omega\\cos\\left(y_0 + \\frac{\\omega t}{\\varepsilon}\\right).\n$$\nTo find $x_{\\varepsilon}(T)$, we integrate this equation from $t=0$ to $t=T$:\n$$\n\\int_{x_{\\varepsilon}(0)}^{x_{\\varepsilon}(T)} \\mathrm{d}x = \\int_0^T \\omega\\cos\\left(y_0 + \\frac{\\omega t}{\\varepsilon}\\right)\\mathrm{d}t.\n$$\n$$\nx_{\\varepsilon}(T) - x_{\\varepsilon}(0) = \\omega \\int_0^T \\cos\\left(y_0 + \\frac{\\omega t}{\\varepsilon}\\right)\\mathrm{d}t.\n$$\nWe evaluate the integral on the right-hand side:\n$$\n\\int_0^T \\cos\\left(y_0 + \\frac{\\omega t}{\\varepsilon}\\right)\\mathrm{d}t = \\left[ \\frac{\\varepsilon}{\\omega}\\sin\\left(y_0 + \\frac{\\omega t}{\\varepsilon}\\right) \\right]_{t=0}^{t=T}.\n$$\n$$\n= \\frac{\\varepsilon}{\\omega} \\left( \\sin\\left(y_0 + \\frac{\\omega T}{\\varepsilon}\\right) - \\sin\\left(y_0\\right) \\right).\n$$\nSubstituting this result back into the equation for $x_{\\varepsilon}(T)$:\n$$\nx_{\\varepsilon}(T) - x_0 = \\omega \\left[ \\frac{\\varepsilon}{\\omega} \\left( \\sin\\left(y_0 + \\frac{\\omega T}{\\varepsilon}\\right) - \\sin(y_0) \\right) \\right].\n$$\n$$\nx_{\\varepsilon}(T) - x_0 = \\varepsilon \\left( \\sin\\left(y_0 + \\frac{\\omega T}{\\varepsilon}\\right) - \\sin(y_0) \\right).\n$$\nFinally, solving for $x_{\\varepsilon}(T)$, we obtain the exact closed-form expression:\n$$\nx_{\\varepsilon}(T) = x_0 + \\varepsilon \\left( \\sin\\left(y_0 + \\frac{\\omega T}{\\varepsilon}\\right) - \\sin(y_0) \\right).\n$$",
            "answer": "$$\\boxed{x_0 + \\varepsilon \\left(\\sin\\left(y_0 + \\frac{\\omega T}{\\varepsilon}\\right) - \\sin(y_0)\\right)}$$"
        },
        {
            "introduction": "We now move from theory to a canonical application in nonlinear dynamics: the parametrically forced Duffing oscillator. This problem introduces the powerful technique of representing the solution using a slowly varying complex amplitude, $a(T)$, which elegantly separates the fast oscillations from the slow evolution of the system's amplitude and phase. Mastering this approach  is essential for analyzing resonant phenomena and deriving the simplified slow-flow equations that govern the long-term behavior of weakly nonlinear systems.",
            "id": "3734768",
            "problem": "Consider the dimensionless Duffing oscillator with small periodic parametric forcing,\n$$\n\\ddot{x} + x + \\varepsilon\\left(\\delta\\,x + \\beta\\,x^{3} + \\gamma \\cos(2 t)\\,x\\right) = 0,\n$$\nwhere $x(t)$ is the displacement, $t$ is the fast time, $\\varepsilon$ satisfies $0<\\varepsilon\\ll 1$, and $\\delta$, $\\beta$, $\\gamma$ are fixed real parameters. The term $\\gamma \\cos(2 t)\\,x$ represents a small parametric modulation at frequency $2$, near the principal parametric resonance of the linear oscillator. Introduce the slow time $T=\\varepsilon t$ and perform averaging via a near-identity transformation consistent with removing nonresonant harmonics in the sense of normal form theory. Represent the solution in terms of a slowly varying complex amplitude $a(T)$ by\n$$\nx(t) = a(T)\\exp(i t) + \\overline{a(T)}\\exp(-i t),\n$$\nand then introduce polar variables by $a(T) = \\frac{R(T)}{2}\\exp\\big(i\\theta(T)\\big)$, where $R(T)>0$ is the slow amplitude and $\\theta(T)$ is the slow phase. Working consistently to first order in $\\varepsilon$ and assuming only the fundamental definitions of averaging and near-identity transformations for fast–slow systems, derive the averaged slow dynamics. Report, as your final answer, the single closed-form expression for the averaged drift term $F(R,\\theta)$ that appears in the slow amplitude equation $R'(T) = F(R,\\theta)$, where the prime denotes $\\frac{d}{dT}$. Provide only the expression $F(R,\\theta)$ (do not write the equation), and do not introduce any additional assumptions beyond those stated above. No rounding is required, and no units are involved. Express all intermediate and final formulas in LaTeX.",
            "solution": "The problem requires the derivation of the averaged slow-flow equation for the amplitude of a parametrically forced Duffing oscillator. The system is described by the second-order ordinary differential equation:\n$$\n\\ddot{x} + x + \\varepsilon\\left(\\delta\\,x + \\beta\\,x^{3} + \\gamma \\cos(2 t)\\,x\\right) = 0\n$$\nwhere $0 < \\varepsilon \\ll 1$. We are given the fast time $t$ and the slow time $T = \\varepsilon t$. The solution is sought in the form $x(t) = a(T)\\exp(i t) + \\overline{a(T)}\\exp(-i t)$, where $a(T)$ is a slowly varying complex amplitude.\n\nWe will use the method of multiple scales. We formally treat $t$ and $T$ as independent variables and expand the solution in powers of $\\varepsilon$:\n$$\nx(t) = x_0(t, T) + \\varepsilon x_1(t, T) + \\mathcal{O}(\\varepsilon^2)\n$$\nThe time derivatives are transformed as:\n$$\n\\frac{d}{dt} = \\frac{\\partial}{\\partial t} + \\varepsilon \\frac{\\partial}{\\partial T}\n$$\n$$\n\\frac{d^2}{dt^2} = \\left(\\frac{\\partial}{\\partial t} + \\varepsilon \\frac{\\partial}{\\partial T}\\right)^2 = \\frac{\\partial^2}{\\partial t^2} + 2\\varepsilon \\frac{\\partial^2}{\\partial t \\partial T} + \\varepsilon^2 \\frac{\\partial^2}{\\partial T^2}\n$$\nSubstituting these into the original equation and collecting terms by powers of $\\varepsilon$:\n\nAt order $\\mathcal{O}(\\varepsilon^0)$:\n$$\n\\frac{\\partial^2 x_0}{\\partial t^2} + x_0 = 0\n$$\nThe general solution to this equation is:\n$$\nx_0(t, T) = a(T)\\exp(i t) + \\overline{a(T)}\\exp(-i t)\n$$\nThis matches the form given in the problem statement. Here, $a(T)$ is an arbitrary function of the slow time $T$, to be determined at the next order.\n\nAt order $\\mathcal{O}(\\varepsilon^1)$:\n$$\n\\frac{\\partial^2 x_1}{\\partial t^2} + x_1 = -2\\frac{\\partial^2 x_0}{\\partial t \\partial T} - \\left(\\delta\\,x_0 + \\beta\\,x_0^{3} + \\gamma \\cos(2 t)\\,x_0\\right)\n$$\nThis is a forced linear oscillator equation for $x_1$. To ensure a uniformly valid expansion, we must eliminate secular terms (terms that grow unboundedly in $t$) from the right-hand side. Secular terms arise from forcing terms that are resonant with the natural frequency of the homogeneous operator, i.e., terms proportional to $\\exp(it)$ or $\\exp(-it)$.\n\nFirst, we compute the term involving the mixed partial derivative:\n$$\n\\frac{\\partial x_0}{\\partial t} = i a(T)\\exp(i t) - i \\overline{a(T)}\\exp(-i t)\n$$\n$$\n\\frac{\\partial^2 x_0}{\\partial t \\partial T} = i \\frac{da}{dT}\\exp(i t) - i \\frac{d\\overline{a}}{dT}\\exp(-i t) = i a'(T)\\exp(i t) - i \\overline{a'}(T)\\exp(-i t)\n$$\nSo, the first term on the right-hand side is:\n$$\n-2\\frac{\\partial^2 x_0}{\\partial t \\partial T} = -2i a'(T)\\exp(i t) + 2i \\overline{a'}(T)\\exp(-i t)\n$$\nNext, we expand the nonlinear and parametric terms, keeping $a(T)$ and $\\overline{a(T)}$ as constants with respect to the fast time $t$, and identify the resonant components.\n\n1.  Term $\\delta x_0$:\n    $$\n    \\delta x_0 = \\delta \\left(a\\exp(it) + \\overline{a}\\exp(-it)\\right)\n    $$\n    The term proportional to $\\exp(it)$ is $\\delta a\\exp(it)$.\n\n2.  Term $\\beta x_0^3$:\n    $$\n    x_0^3 = \\left(a\\exp(it) + \\overline{a}\\exp(-it)\\right)^3 = a^3\\exp(3it) + 3a^2\\overline{a}\\exp(it) + 3a\\overline{a}^2\\exp(-it) + \\overline{a}^3\\exp(-3it)\n    $$\n    The term proportional to $\\exp(it)$ is $3\\beta a^2\\overline{a}\\exp(it)$. The problem statement uses $\\beta$, so the coefficient is $3\\beta a^2\\overline{a}$.\n\n3.  Term $\\gamma \\cos(2t) x_0$:\n    We use $\\cos(2t) = \\frac{1}{2}(\\exp(2it) + \\exp(-2it))$.\n    $$\n    \\gamma \\cos(2t) x_0 = \\frac{\\gamma}{2}\\left(\\exp(2it) + \\exp(-2it)\\right)\\left(a\\exp(it) + \\overline{a}\\exp(-it)\\right)\n    $$\n    $$\n    = \\frac{\\gamma}{2}\\left(a\\exp(3it) + \\overline{a}\\exp(it) + a\\exp(-it) + \\overline{a}\\exp(-3it)\\right)\n    $$\n    The term proportional to $\\exp(it)$ is $\\frac{\\gamma}{2}\\overline{a}\\exp(it)$.\n\nThe solvability condition requires that the sum of all coefficients of $\\exp(it)$ on the right-hand side of the $x_1$ equation must be zero.\n$$\n-2i a'(T) - \\delta a(T) - 3\\beta a(T)^2\\overline{a(T)} - \\frac{\\gamma}{2}\\overline{a(T)} = 0\n$$\nSolving for $a'(T)$:\n$$\n-2i a'(T) = \\delta a + 3\\beta a^2\\overline{a} + \\frac{\\gamma}{2}\\overline{a}\n$$\n$$\na'(T) = \\frac{i}{2}\\left(\\delta a + 3\\beta |a|^2 a + \\frac{\\gamma}{2}\\overline{a}\\right)\n$$\nThis is the averaged equation for the complex amplitude $a(T)$.\n\nNow, we introduce the polar representation $a(T) = \\frac{R(T)}{2}\\exp(i\\theta(T))$. We need to find the equation for $R'(T)$. We differentiate $a(T)$ with respect to $T$:\n$$\na'(T) = \\frac{R'(T)}{2}\\exp(i\\theta(T)) + i\\frac{R(T)\\theta'(T)}{2}\\exp(i\\theta(T)) = \\left(\\frac{R'}{2} + i\\frac{R\\theta'}{2}\\right)\\exp(i\\theta)\n$$\nWe substitute the polar form into the averaged equation for $a'(T)$:\n$$\na'(T) = \\frac{i}{2}\\left[\\delta \\frac{R}{2}\\exp(i\\theta) + 3\\beta \\left(\\frac{R}{2}\\right)^3\\exp(i\\theta) + \\frac{\\gamma}{2}\\frac{R}{2}\\exp(-i\\theta)\\right]\n$$\nNote that we have used $|a|^2 a = (\\frac{R}{2})^2 \\frac{R}{2}\\exp(i\\theta) = (\\frac{R}{2})^3\\exp(i\\theta)$.\n$$\na'(T) = \\frac{i}{2}\\left[\\left(\\frac{\\delta R}{2} + \\frac{3\\beta R^3}{8}\\right)\\exp(i\\theta) + \\frac{\\gamma R}{4}\\exp(-i\\theta)\\right]\n$$\nEquating the two expressions for $a'(T)$:\n$$\n\\left(\\frac{R'}{2} + i\\frac{R\\theta'}{2}\\right)\\exp(i\\theta) = \\frac{i}{2}\\left[\\left(\\frac{\\delta R}{2} + \\frac{3\\beta R^3}{8}\\right)\\exp(i\\theta) + \\frac{\\gamma R}{4}\\exp(-i\\theta)\\right]\n$$\nMultiplying both sides by $2\\exp(-i\\theta)$:\n$$\nR' + iR\\theta' = i\\left[\\left(\\frac{\\delta R}{2} + \\frac{3\\beta R^3}{8}\\right) + \\frac{\\gamma R}{4}\\exp(-2i\\theta)\\right]\n$$\nNow, expand $\\exp(-2i\\theta) = \\cos(2\\theta) - i\\sin(2\\theta)$:\n$$\nR' + iR\\theta' = i\\left(\\frac{\\delta R}{2} + \\frac{3\\beta R^3}{8} + \\frac{\\gamma R}{4}\\cos(2\\theta)\\right) - i^2\\frac{\\gamma R}{4}\\sin(2\\theta)\n$$\n$$\nR' + iR\\theta' = \\frac{\\gamma R}{4}\\sin(2\\theta) + i\\left(\\frac{\\delta R}{2} + \\frac{3\\beta R^3}{8} + \\frac{\\gamma R}{4}\\cos(2\\theta)\\right)\n$$\nEquating the real and imaginary parts gives the averaged equations for $R(T)$ and $\\theta(T)$:\n$$\nR'(T) = \\frac{\\gamma R}{4}\\sin(2\\theta)\n$$\n$$\nR\\theta'(T) = \\frac{\\delta R}{2} + \\frac{3\\beta R^3}{8} + \\frac{\\gamma R}{4}\\cos(2\\theta)\n$$\nThe problem asks for the expression $F(R, \\theta)$ in the equation $R'(T) = F(R, \\theta)$. From our derivation, this is:\n$$\nF(R, \\theta) = \\frac{\\gamma R}{4}\\sin(2\\theta)\n$$\nThis result is physically consistent, as the amplitude dynamics (energy injection or dissipation) are governed by the parametric forcing term $\\gamma$ and its phase relationship $2\\theta$ with the oscillator, while the detuning $\\delta$ and the nonlinearity $\\beta$ primarily affect the frequency of oscillation, which is captured in $\\theta'$.\n\nThe final expression is $\\frac{\\gamma R}{4}\\sin(2\\theta)$.",
            "answer": "$$\\boxed{\\frac{\\gamma R}{4}\\sin(2\\theta)}$$"
        },
        {
            "introduction": "A first-order analysis is often insufficient, making it necessary to consider higher-order effects. This practice guides you through the systematic procedure of second-order averaging, which refines the transformation to capture dynamics at the $\\mathcal{O}(\\epsilon^2)$ level. This exercise  is particularly valuable as it demonstrates how second-order averaging can reveal subtle but physically important phenomena, such as a slow frequency shift, that are completely invisible to a leading-order approximation.",
            "id": "3734761",
            "problem": "Consider the two-dimensional autonomous dynamical system for a radial amplitude $r(t)$ and a fast phase $\\theta(t)$,\n$$\n\\dot{r} \\;=\\; \\epsilon\\,\\alpha\\,r \\;+\\; \\epsilon\\,\\beta\\,r\\,\\cos\\theta, \n\\qquad\n\\dot{\\theta} \\;=\\; \\omega \\;+\\; \\epsilon\\,\\gamma\\,\\sin\\theta,\n$$\nwhere $\\epsilon>0$ is a small parameter, $\\omega\\neq 0$ is a constant fast frequency, and $\\alpha,\\beta,\\gamma$ are bounded constants. All angles are measured in radians. The goal is to derive the averaged dynamics for a slow amplitude $R(t)$ and a corrected fast phase $\\Theta(t)$ up to and including terms of order $\\epsilon^{2}$.\n\nBegin from first principles of averaging in fast–slow systems: the fast phase $\\,\\theta\\,$ generates $\\mathcal{O}(1)$ oscillations in terms such as $\\cos\\theta$ and $\\sin\\theta$, and an averaged (effective) slow dynamics is obtained by eliminating the leading oscillatory dependence on the fast phase over one period of the fast motion, using a near-identity change of variables that is periodic in the fast phase. Work systematically by introducing a near-identity transformation that removes oscillatory terms at $\\mathcal{O}(\\epsilon)$, and then compute the residual averaged drift at $\\mathcal{O}(\\epsilon^{2})$.\n\nAssume sufficiently smoothness so that all expansions and averages are justified, and keep all constants in symbolic form. Do not use any pre-packaged shortcut formula. Derive the averaged system for $(R,\\Theta)$ with right-hand sides accurate up to and including terms of order $\\epsilon^{2}$.\n\nProvide your final answer as the pair of right-hand sides for the averaged system $(\\dot{R},\\dot{\\Theta})$ expressed as a two-entry row matrix in the order $(\\dot{R},\\dot{\\Theta})$. No numerical rounding is required.",
            "solution": "The problem asks for the derivation of an averaged system from first principles up to order $\\epsilon^2$. We are given the fast-slow system:\n$$\n\\dot{r} = \\epsilon(\\alpha r + \\beta r \\cos\\theta) \\\\\n\\dot{\\theta} = \\omega + \\epsilon \\gamma \\sin\\theta\n$$\nHere, $\\theta$ is the fast variable as $\\dot{\\theta} = \\mathcal{O}(1)$, and $r$ is the slow variable as $\\dot{r} = \\mathcal{O}(\\epsilon)$.\n\nWe introduce a near-identity transformation to new variables, a slow amplitude $R(t)$ and a fast phase $\\Theta(t)$, which are governed by the averaged equations. The transformation is defined as a series expansion in $\\epsilon$:\n$$\nr(t) = R(t) + \\epsilon u_1(R, \\Theta) + \\epsilon^2 u_2(R, \\Theta) + \\mathcal{O}(\\epsilon^3) \\\\\n\\theta(t) = \\Theta(t) + \\epsilon a_1(R, \\Theta) + \\epsilon^2 a_2(R, \\Theta) + \\mathcal{O}(\\epsilon^3)\n$$\nThe functions $u_1, u_2, a_1, a_2$ are chosen to be periodic functions of $\\Theta$ with zero mean, to absorb the oscillatory dynamics. The averaged system for $R$ and $\\Theta$ will have the form:\n$$\n\\dot{R} = \\epsilon F_1(R) + \\epsilon^2 F_2(R) + \\mathcal{O}(\\epsilon^3) \\\\\n\\dot{\\Theta} = \\omega + \\epsilon G_1(R) + \\epsilon^2 G_2(R) + \\mathcal{O}(\\epsilon^3)\n$$\nwhere $F_1, F_2, G_1, G_2$ are functions of $R$ only and do not depend on the fast phase $\\Theta$.\n\nFirst, we express $\\dot{r}$ and $\\dot{\\theta}$ in terms of the new variables by differentiating the transformation with respect to time $t$. We expand the time derivatives of $r$ and $\\theta$ and equate them to the Taylor expansions of the right-hand sides of the original equations around $(R, \\Theta)$.\n$$\n\\dot{r} = \\frac{d}{dt}(R+\\epsilon u_1+\\epsilon^2 u_2) = \\dot{R} + \\epsilon(\\frac{\\partial u_1}{\\partial R}\\dot{R} + \\frac{\\partial u_1}{\\partial \\Theta}\\dot{\\Theta}) + \\epsilon^2(\\frac{\\partial u_2}{\\partial R}\\dot{R} + \\frac{\\partial u_2}{\\partial \\Theta}\\dot{\\Theta}) + \\mathcal{O}(\\epsilon^3)\n$$\nSubstituting the expansions for $\\dot{R}$ and $\\dot{\\Theta}$ and keeping terms up to $\\mathcal{O}(\\epsilon^2)$:\n$$\n\\dot{r} = (\\epsilon F_1+\\epsilon^2 F_2) + \\epsilon(\\frac{\\partial u_1}{\\partial R}(\\epsilon F_1) + \\frac{\\partial u_1}{\\partial \\Theta}(\\omega+\\epsilon G_1)) + \\epsilon^2(\\frac{\\partial u_2}{\\partial \\Theta}\\omega) + \\mathcal{O}(\\epsilon^3) \\\\\n\\dot{r} = \\epsilon F_1 + \\epsilon \\omega \\frac{\\partial u_1}{\\partial \\Theta} + \\epsilon^2(F_2 + \\frac{\\partial u_1}{\\partial R}F_1 + \\frac{\\partial u_1}{\\partial \\Theta}G_1 + \\omega \\frac{\\partial u_2}{\\partial \\Theta}) + \\mathcal{O}(\\epsilon^3)\n$$\nSimilarly for $\\dot{\\theta}$:\n$$\n\\dot{\\theta} = \\omega + \\epsilon (G_1 + \\omega \\frac{\\partial a_1}{\\partial \\Theta}) + \\epsilon^2 \\left(G_2 + \\frac{\\partial a_1}{\\partial R}F_1 + \\frac{\\partial a_1}{\\partial \\Theta} G_1 + \\omega \\frac{\\partial a_2}{\\partial \\Theta}\\right) + \\mathcal{O}(\\epsilon^3)\n$$\n\nNext, we expand the right-hand sides (RHS) of the original system in powers of $\\epsilon$ around $(R, \\Theta)$:\nFor $\\dot{r}$:\n$$\n\\epsilon(\\alpha r + \\beta r \\cos\\theta) = \\epsilon[\\alpha(R+\\epsilon u_1) + \\beta(R+\\epsilon u_1)\\cos(\\Theta+\\epsilon a_1)] + \\mathcal{O}(\\epsilon^3) \\\\\n= \\epsilon[\\alpha R + \\epsilon \\alpha u_1 + \\beta R(\\cos\\Theta - \\epsilon a_1 \\sin\\Theta) + \\epsilon \\beta u_1 \\cos\\Theta] + \\mathcal{O}(\\epsilon^3) \\\\\n= \\epsilon(\\alpha R + \\beta R \\cos\\Theta) + \\epsilon^2(\\alpha u_1 + \\beta u_1 \\cos\\Theta - \\beta R a_1 \\sin\\Theta) + \\mathcal{O}(\\epsilon^3)\n$$\nFor $\\dot{\\theta}$:\n$$\n\\omega + \\epsilon\\gamma\\sin\\theta = \\omega + \\epsilon\\gamma\\sin(\\Theta+\\epsilon a_1) + \\mathcal{O}(\\epsilon^3) \\\\\n= \\omega + \\epsilon\\gamma(\\sin\\Theta + \\epsilon a_1 \\cos\\Theta) + \\mathcal{O}(\\epsilon^3) \\\\\n= \\omega + \\epsilon\\gamma\\sin\\Theta + \\epsilon^2 \\gamma a_1 \\cos\\Theta + \\mathcal{O}(\\epsilon^3)\n$$\n\nNow we match the coefficients of powers of $\\epsilon$.\n**Order $\\epsilon$ equations:**\nBy comparing the $\\mathcal{O}(\\epsilon)$ terms, we get:\nFor $r$: $F_1 + \\omega \\frac{\\partial u_1}{\\partial \\Theta} = \\alpha R + \\beta R \\cos\\Theta$\nFor $\\theta$: $G_1 + \\omega \\frac{\\partial a_1}{\\partial \\Theta} = \\gamma \\sin\\Theta$\n\nTo find the averaged equations, we take the average of these equations with respect to $\\Theta$ over one period $[0, 2\\pi]$, denoted by $\\langle \\cdot \\rangle$. Since $u_1$ and $a_1$ have zero mean, $\\langle \\frac{\\partial u_1}{\\partial \\Theta} \\rangle = 0$ and $\\langle \\frac{\\partial a_1}{\\partial \\Theta} \\rangle = 0$.\n$$\nF_1 = \\langle \\alpha R + \\beta R \\cos\\Theta \\rangle = \\alpha R \\\\\nG_1 = \\langle \\gamma \\sin\\Theta \\rangle = 0\n$$\nNow we find the oscillatory parts $u_1$ and $a_1$.\n$$\n\\omega \\frac{\\partial u_1}{\\partial \\Theta} = (\\alpha R + \\beta R \\cos\\Theta) - F_1 = \\beta R \\cos\\Theta \\implies u_1(R, \\Theta) = \\frac{\\beta R}{\\omega} \\sin\\Theta \\\\\n\\omega \\frac{\\partial a_1}{\\partial \\Theta} = \\gamma \\sin\\Theta - G_1 = \\gamma \\sin\\Theta \\implies a_1(R, \\Theta) = -\\frac{\\gamma}{\\omega} \\cos\\Theta\n$$\nWe choose the integration constants to be zero to ensure $\\langle u_1 \\rangle = 0$ and $\\langle a_1 \\rangle = 0$.\n\n**Order $\\epsilon^2$ equations:**\nBy comparing the $\\mathcal{O}(\\epsilon^2)$ terms, we get:\nFor $r$: $F_2 + \\frac{\\partial u_1}{\\partial R}F_1 + \\frac{\\partial u_1}{\\partial \\Theta}G_1 + \\omega \\frac{\\partial u_2}{\\partial \\Theta} = \\alpha u_1 + \\beta u_1 \\cos\\Theta - \\beta R a_1 \\sin\\Theta$\nFor $\\theta$: $G_2 + \\frac{\\partial a_1}{\\partial R}F_1 + \\frac{\\partial a_1}{\\partial \\Theta}G_1 + \\omega \\frac{\\partial a_2}{\\partial \\Theta} = \\gamma a_1 \\cos\\Theta$\n\nAveraging the equation for $r$ over $\\Theta$ gives $F_2$:\n$$\nF_2 = \\left\\langle \\alpha u_1 + \\beta u_1 \\cos\\Theta - \\beta R a_1 \\sin\\Theta - \\frac{\\partial u_1}{\\partial R}F_1 - \\frac{\\partial u_1}{\\partial \\Theta}G_1 \\right\\rangle\n$$\nSubstitute the known expressions: $F_1 = \\alpha R$, $G_1 = 0$, $u_1 = \\frac{\\beta R}{\\omega} \\sin\\Theta$, $a_1 = -\\frac{\\gamma}{\\omega} \\cos\\Theta$. Also $\\frac{\\partial u_1}{\\partial R} = \\frac{\\beta}{\\omega} \\sin\\Theta$.\n$$\nF_2 = \\left\\langle \\alpha \\left(\\frac{\\beta R}{\\omega} \\sin\\Theta\\right) + \\beta \\left(\\frac{\\beta R}{\\omega} \\sin\\Theta\\right) \\cos\\Theta - \\beta R \\left(-\\frac{\\gamma}{\\omega} \\cos\\Theta\\right) \\sin\\Theta - \\left(\\frac{\\beta}{\\omega} \\sin\\Theta\\right)(\\alpha R) \\right\\rangle\n$$\n$$\nF_2 = \\left\\langle \\frac{\\alpha\\beta R}{\\omega}\\sin\\Theta + \\frac{\\beta^2 R}{\\omega}\\sin\\Theta\\cos\\Theta + \\frac{\\beta\\gamma R}{\\omega}\\sin\\Theta\\cos\\Theta - \\frac{\\alpha\\beta R}{\\omega}\\sin\\Theta \\right\\rangle\n$$\n$$\nF_2 = \\left\\langle \\frac{\\beta(\\beta+\\gamma)R}{\\omega}\\sin\\Theta\\cos\\Theta \\right\\rangle = \\frac{\\beta(\\beta+\\gamma)R}{2\\omega} \\langle \\sin(2\\Theta) \\rangle = 0\n$$\nNow let's find $G_2$ by averaging the equation for $\\theta$:\n$$\nG_2 = \\langle \\gamma a_1 \\cos\\Theta - \\frac{\\partial a_1}{\\partial R}F_1 - \\frac{\\partial a_1}{\\partial \\Theta}G_1 \\rangle\n$$\nSince $G_1 = 0$, the last term vanishes. As $a_1$ does not depend on $R$, $\\frac{\\partial a_1}{\\partial R}=0$, so the second term also vanishes.\n$$\nG_2 = \\langle \\gamma a_1 \\cos\\Theta \\rangle\n$$\nSubstitute $a_1 = -\\frac{\\gamma}{\\omega} \\cos\\Theta$:\n$$\nG_2 = \\left\\langle \\gamma \\left(-\\frac{\\gamma}{\\omega} \\cos\\Theta\\right) \\cos\\Theta \\right\\rangle = -\\frac{\\gamma^2}{\\omega} \\langle \\cos^2\\Theta \\rangle\n$$\nUsing the identity $\\langle\\cos^2\\Theta\\rangle = \\frac{1}{2}$:\n$$\nG_2 = -\\frac{\\gamma^2}{2\\omega}\n$$\n\n**Assembling the Averaged System:**\nWe have found the coefficients for the averaged system up to order $\\epsilon^2$:\n- $F_1 = \\alpha R$, $F_2 = 0$\n- $G_1 = 0$, $G_2 = -\\frac{\\gamma^2}{2\\omega}$\n\nThe averaged system is therefore:\n$$\n\\dot{R} = \\epsilon F_1 + \\epsilon^2 F_2 + \\mathcal{O}(\\epsilon^3) = \\epsilon \\alpha R + \\mathcal{O}(\\epsilon^3)\n$$\n$$\n\\dot{\\Theta} = \\omega + \\epsilon G_1 + \\epsilon^2 G_2 + \\mathcal{O}(\\epsilon^3) = \\omega - \\epsilon^2 \\frac{\\gamma^2}{2\\omega} + \\mathcal{O}(\\epsilon^3)\n$$\nThe right-hand sides of the averaged system, accurate up to and including terms of order $\\epsilon^2$, are:\nFor $\\dot{R}$: $\\epsilon \\alpha R$\nFor $\\dot{\\Theta}$: $\\omega - \\frac{\\epsilon^2 \\gamma^2}{2\\omega}$",
            "answer": "$$ \\boxed{ \\begin{pmatrix} \\epsilon \\alpha R & \\omega - \\frac{\\epsilon^2 \\gamma^2}{2\\omega} \\end{pmatrix} } $$"
        }
    ]
}