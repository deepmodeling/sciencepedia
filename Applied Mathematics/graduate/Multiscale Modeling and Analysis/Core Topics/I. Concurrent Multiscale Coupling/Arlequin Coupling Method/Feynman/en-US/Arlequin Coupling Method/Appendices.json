{
    "hands_on_practices": [
        {
            "introduction": "We begin our practical exploration at the most fundamental level: the continuous energy functional. Before discretizing a model or writing any code, a powerful first step is to perform a scaling analysis to understand the interplay between the physical parameters. This exercise in nondimensionalization will guide you through stripping the Arlequin functional for linear elasticity down to its essential, dimensionless form, revealing the single parameter that truly governs the coupling behavior .",
            "id": "3733235",
            "problem": "Consider two small-strain linear elastic models defined on overlapping subdomains $\\Omega_{1}$ and $\\Omega_{2}$ in three-dimensional space, with an overlap region $\\Omega_{o}=\\Omega_{1}\\cap\\Omega_{2}$. Let $\\Gamma_{c}\\subset\\Omega_{o}$ be a smooth coupling interface of characteristic size comparable to the overlap, with characteristic length scale $L>0$. The models are coupled using the Arlequin method, in which the total energy functional is taken as a weighted superposition of the elastic energies together with a penalty enforcing kinematic compatibility on $\\Gamma_{c}$. Specifically, let the total energy functional be\n$$\n\\Pi(\\boldsymbol{u}_{1},\\boldsymbol{u}_{2}) \\;=\\; \\int_{\\Omega_{1}} \\alpha_{1}(\\boldsymbol{x})\\, W\\!\\left(\\boldsymbol{\\varepsilon}(\\boldsymbol{u}_{1}(\\boldsymbol{x}))\\right)\\,\\mathrm{d}\\boldsymbol{x} \\;+\\; \\int_{\\Omega_{2}} \\alpha_{2}(\\boldsymbol{x})\\, W\\!\\left(\\boldsymbol{\\varepsilon}(\\boldsymbol{u}_{2}(\\boldsymbol{x}))\\right)\\,\\mathrm{d}\\boldsymbol{x} \\;+\\; \\frac{\\gamma}{2}\\int_{\\Gamma_{c}} w_{c}(\\boldsymbol{x})\\, \\left\\|\\boldsymbol{u}_{1}(\\boldsymbol{x})-\\boldsymbol{u}_{2}(\\boldsymbol{x})\\right\\|^{2}\\,\\mathrm{d}s,\n$$\nwhere $\\boldsymbol{u}_{i}:\\Omega_{i}\\to\\mathbb{R}^{3}$ are displacement fields, $\\boldsymbol{\\varepsilon}(\\boldsymbol{u}_{i})=\\tfrac{1}{2}\\left(\\nabla\\boldsymbol{u}_{i}+\\nabla\\boldsymbol{u}_{i}^{\\top}\\right)$ is the small-strain tensor, $W(\\boldsymbol{\\varepsilon})=\\tfrac{1}{2}\\lambda\\left(\\mathrm{tr}\\,\\boldsymbol{\\varepsilon}\\right)^{2}+\\mu\\,\\boldsymbol{\\varepsilon}:\\boldsymbol{\\varepsilon}$ is the elastic energy density, and $(\\lambda,\\mu)$ are Lamé parameters satisfying standard relations with a representative Young’s modulus $E>0$ and Poisson’s ratio $\\nu\\in(-1/2,1/2)$. The weighting functions $\\alpha_{1},\\alpha_{2}$ and $w_{c}$ are dimensionless and bounded, and $\\gamma>0$ is a penalty parameter controlling the coupling strength on $\\Gamma_{c}$.\n\nUsing a characteristic displacement scale $U_{0}>0$ and the length scale $L$, perform a nondimensionalization of $\\Pi(\\boldsymbol{u}_{1},\\boldsymbol{u}_{2})$ by introducing dimensionless variables $\\tilde{\\boldsymbol{x}}=\\boldsymbol{x}/L$ and $\\tilde{\\boldsymbol{u}}_{i}=\\boldsymbol{u}_{i}/U_{0}$. Express the resulting nondimensional functional in the form\n$$\n\\Pi(\\boldsymbol{u}_{1},\\boldsymbol{u}_{2}) \\;=\\; E\\,U_{0}^{2}\\,L \\;\\tilde{\\Pi}(\\tilde{\\boldsymbol{u}}_{1},\\tilde{\\boldsymbol{u}}_{2}),\n$$\nand identify the single dimensionless parameter that multiplies the coupling penalty term in $\\tilde{\\Pi}$. Your final answer must be a closed-form analytic expression for this dimensionless coupling number in terms of $\\gamma$, $L$, and $E$. Do not use any numerical values. If you introduce any additional intermediate scales, you must eliminate them so that the final expression depends only on $\\gamma$, $L$, and $E$.",
            "solution": "The problem requires the nondimensionalization of the given energy functional $\\Pi(\\boldsymbol{u}_{1},\\boldsymbol{u}_{2})$ to identify a dimensionless coupling parameter. The functional is given by:\n$$\n\\Pi(\\boldsymbol{u}_{1},\\boldsymbol{u}_{2}) \\;=\\; \\int_{\\Omega_{1}} \\alpha_{1}(\\boldsymbol{x})\\, W\\!\\left(\\boldsymbol{\\varepsilon}(\\boldsymbol{u}_{1}(\\boldsymbol{x}))\\right)\\,\\mathrm{d}\\boldsymbol{x} \\;+\\; \\int_{\\Omega_{2}} \\alpha_{2}(\\boldsymbol{x})\\, W\\!\\left(\\boldsymbol{\\varepsilon}(\\boldsymbol{u}_{2}(\\boldsymbol{x}))\\right)\\,\\mathrm{d}\\boldsymbol{x} \\;+\\; \\frac{\\gamma}{2}\\int_{\\Gamma_{c}} w_{c}(\\boldsymbol{x})\\, \\left\\|\\boldsymbol{u}_{1}(\\boldsymbol{x})-\\boldsymbol{u}_{2}(\\boldsymbol{x})\\right\\|^{2}\\,\\mathrm{d}s\n$$\nThe nondimensionalization is performed using the characteristic length scale $L>0$ and displacement scale $U_{0}>0$. The dimensionless variables are defined as:\n$$\n\\tilde{\\boldsymbol{x}} = \\frac{\\boldsymbol{x}}{L} \\quad \\implies \\quad \\boldsymbol{x} = L\\tilde{\\boldsymbol{x}}\n$$\n$$\n\\tilde{\\boldsymbol{u}}_{i} = \\frac{\\boldsymbol{u}_{i}}{U_{0}} \\quad \\implies \\quad \\boldsymbol{u}_{i} = U_{0}\\tilde{\\boldsymbol{u}}_{i}\n$$\nfor $i=1,2$. We will transform each component of the functional $\\Pi$ in terms of these dimensionless variables.\n\nFirst, we transform the gradient operator $\\nabla$ (with respect to $\\boldsymbol{x}$) to the dimensionless gradient operator $\\tilde{\\nabla}$ (with respect to $\\tilde{\\boldsymbol{x}}$). The chain rule gives:\n$$\n\\nabla = \\frac{\\partial}{\\partial \\boldsymbol{x}} = \\frac{\\partial \\tilde{\\boldsymbol{x}}}{\\partial \\boldsymbol{x}} \\frac{\\partial}{\\partial \\tilde{\\boldsymbol{x}}} = \\frac{1}{L} \\tilde{\\nabla}\n$$\n\nNext, we transform the small-strain tensor $\\boldsymbol{\\varepsilon}(\\boldsymbol{u}_{i})$:\n$$\n\\boldsymbol{\\varepsilon}(\\boldsymbol{u}_{i}) = \\frac{1}{2}\\left(\\nabla\\boldsymbol{u}_{i}+\\nabla\\boldsymbol{u}_{i}^{\\top}\\right) = \\frac{1}{2}\\left(\\nabla(U_{0}\\tilde{\\boldsymbol{u}}_{i})+(\\nabla(U_{0}\\tilde{\\boldsymbol{u}}_{i}))^{\\top}\\right)\n$$\n$$\n\\boldsymbol{\\varepsilon}(\\boldsymbol{u}_{i}) = \\frac{U_{0}}{2}\\left(\\nabla\\tilde{\\boldsymbol{u}}_{i}+(\\nabla\\tilde{\\boldsymbol{u}}_{i})^{\\top}\\right) = \\frac{U_{0}}{2}\\left(\\frac{1}{L}\\tilde{\\nabla}\\tilde{\\boldsymbol{u}}_{i}+\\left(\\frac{1}{L}\\tilde{\\nabla}\\tilde{\\boldsymbol{u}}_{i}\\right)^{\\top}\\right) = \\frac{U_{0}}{L} \\left[ \\frac{1}{2}\\left(\\tilde{\\nabla}\\tilde{\\boldsymbol{u}}_{i}+\\tilde{\\nabla}\\tilde{\\boldsymbol{u}}_{i}^{\\top}\\right) \\right]\n$$\nLet $\\tilde{\\boldsymbol{\\varepsilon}}(\\tilde{\\boldsymbol{u}}_{i}) = \\frac{1}{2}\\left(\\tilde{\\nabla}\\tilde{\\boldsymbol{u}}_{i}+\\tilde{\\nabla}\\tilde{\\boldsymbol{u}}_{i}^{\\top}\\right)$ be the dimensionless strain tensor. Then, the relationship is:\n$$\n\\boldsymbol{\\varepsilon}(\\boldsymbol{u}_{i}) = \\frac{U_{0}}{L} \\tilde{\\boldsymbol{\\varepsilon}}(\\tilde{\\boldsymbol{u}}_{i})\n$$\n\nNow, we transform the elastic energy density $W(\\boldsymbol{\\varepsilon}) = \\frac{1}{2}\\lambda\\left(\\mathrm{tr}\\,\\boldsymbol{\\varepsilon}\\right)^{2}+\\mu\\,\\boldsymbol{\\varepsilon}:\\boldsymbol{\\varepsilon}$.\n$$\nW(\\boldsymbol{\\varepsilon}(\\boldsymbol{u}_{i})) = \\frac{1}{2}\\lambda\\left(\\mathrm{tr}\\left(\\frac{U_{0}}{L}\\tilde{\\boldsymbol{\\varepsilon}}(\\tilde{\\boldsymbol{u}}_{i})\\right)\\right)^{2} + \\mu\\left(\\frac{U_{0}}{L}\\tilde{\\boldsymbol{\\varepsilon}}(\\tilde{\\boldsymbol{u}}_{i})\\right):\\left(\\frac{U_{0}}{L}\\tilde{\\boldsymbol{\\varepsilon}}(\\tilde{\\boldsymbol{u}}_{i})\\right)\n$$\n$$\nW(\\boldsymbol{\\varepsilon}(\\boldsymbol{u}_{i})) = \\left(\\frac{U_{0}}{L}\\right)^{2} \\left( \\frac{1}{2}\\lambda\\left(\\mathrm{tr}\\,\\tilde{\\boldsymbol{\\varepsilon}}(\\tilde{\\boldsymbol{u}}_{i})\\right)^{2}+\\mu\\,\\tilde{\\boldsymbol{\\varepsilon}}(\\tilde{\\boldsymbol{u}}_{i}):\\tilde{\\boldsymbol{\\varepsilon}}(\\tilde{\\boldsymbol{u}}_{i}) \\right)\n$$\nThe Lamé parameters $\\lambda$ and $\\mu$ are related to the Young's modulus $E$ and Poisson's ratio $\\nu$. Specifically, $\\lambda$ and $\\mu$ are both linearly proportional to $E$, i.e., $\\lambda=E f_{\\lambda}(\\nu)$ and $\\mu=E f_{\\mu}(\\nu)$ for some dimensionless functions $f_{\\lambda}, f_{\\mu}$ of $\\nu$. Thus, we can factor out $E$:\n$$\nW(\\boldsymbol{\\varepsilon}(\\boldsymbol{u}_{i})) = E \\left(\\frac{U_{0}}{L}\\right)^{2} \\left[ \\frac{1}{2}f_{\\lambda}(\\nu)\\left(\\mathrm{tr}\\,\\tilde{\\boldsymbol{\\varepsilon}}(\\tilde{\\boldsymbol{u}}_{i})\\right)^{2}+f_{\\mu}(\\nu)\\,\\tilde{\\boldsymbol{\\varepsilon}}(\\tilde{\\boldsymbol{u}}_{i}):\\tilde{\\boldsymbol{\\varepsilon}}(\\tilde{\\boldsymbol{u}}_{i}) \\right] = E \\left(\\frac{U_{0}}{L}\\right)^{2} \\tilde{W}(\\tilde{\\boldsymbol{\\varepsilon}}(\\tilde{\\boldsymbol{u}}_{i}))\n$$\nwhere $\\tilde{W}(\\tilde{\\boldsymbol{\\varepsilon}})$ is the dimensionless energy density function, dependent on $\\nu$.\n\nWe now transform the integral terms. For the volume integrals over $\\Omega_{1}$ and $\\Omega_{2}$ (which are $3$-dimensional domains), the volume element scales as $\\mathrm{d}\\boldsymbol{x} = L^{3}\\,\\mathrm{d}\\tilde{\\boldsymbol{x}}$. The domains transform to $\\tilde{\\Omega}_{1}$ and $\\tilde{\\Omega}_{2}$. Let us examine the first term:\n$$\n\\int_{\\Omega_{1}} \\alpha_{1}(\\boldsymbol{x})\\, W\\!\\left(\\boldsymbol{\\varepsilon}(\\boldsymbol{u}_{1}(\\boldsymbol{x}))\\right)\\,\\mathrm{d}\\boldsymbol{x} = \\int_{\\tilde{\\Omega}_{1}} \\alpha_{1}(L\\tilde{\\boldsymbol{x}}) \\left[ E \\left(\\frac{U_{0}}{L}\\right)^{2} \\tilde{W}(\\tilde{\\boldsymbol{\\varepsilon}}(\\tilde{\\boldsymbol{u}}_{1})) \\right] (L^{3}\\,\\mathrm{d}\\tilde{\\boldsymbol{x}})\n$$\n$$\n= E U_{0}^{2} L \\int_{\\tilde{\\Omega}_{1}} \\tilde{\\alpha}_{1}(\\tilde{\\boldsymbol{x}}) \\tilde{W}(\\tilde{\\boldsymbol{\\varepsilon}}(\\tilde{\\boldsymbol{u}}_{1})) \\,\\mathrm{d}\\tilde{\\boldsymbol{x}}\n$$\nwhere $\\tilde{\\alpha}_{1}(\\tilde{\\boldsymbol{x}}) = \\alpha_{1}(L\\tilde{\\boldsymbol{x}})$. Since $\\alpha_{1}$ is dimensionless, $\\tilde{\\alpha}_{1}$ is also dimensionless. An identical result holds for the integral over $\\Omega_{2}$.\n\nFinally, we transform the coupling penalty term, which is an integral over the $2$-dimensional surface $\\Gamma_{c}$. The surface element scales as $\\mathrm{d}s = L^{2}\\,\\mathrm{d}\\tilde{s}$. The surface transforms to $\\tilde{\\Gamma}_{c}$.\n$$\n\\frac{\\gamma}{2}\\int_{\\Gamma_{c}} w_{c}(\\boldsymbol{x})\\, \\left\\|\\boldsymbol{u}_{1}(\\boldsymbol{x})-\\boldsymbol{u}_{2}(\\boldsymbol{x})\\right\\|^{2}\\,\\mathrm{d}s = \\frac{\\gamma}{2}\\int_{\\tilde{\\Gamma}_{c}} w_{c}(L\\tilde{\\boldsymbol{x}})\\, \\left\\|U_{0}\\tilde{\\boldsymbol{u}}_{1}(\\tilde{\\boldsymbol{x}})-U_{0}\\tilde{\\boldsymbol{u}}_{2}(\\tilde{\\boldsymbol{x}})\\right\\|^{2}\\,(L^{2}\\,\\mathrm{d}\\tilde{s})\n$$\n$$\n= \\frac{\\gamma U_{0}^{2} L^{2}}{2}\\int_{\\tilde{\\Gamma}_{c}} \\tilde{w}_{c}(\\tilde{\\boldsymbol{x}})\\, \\left\\|\\tilde{\\boldsymbol{u}}_{1}(\\tilde{\\boldsymbol{x}})-\\tilde{\\boldsymbol{u}}_{2}(\\tilde{\\boldsymbol{x}})\\right\\|^{2}\\,\\mathrm{d}\\tilde{s}\n$$\nwhere $\\tilde{w}_{c}(\\tilde{\\boldsymbol{x}}) = w_{c}(L\\tilde{\\boldsymbol{x}})$, which is dimensionless.\n\nCombining all transformed parts, the total energy functional $\\Pi$ becomes:\n$$\n\\Pi = E U_{0}^{2} L \\left[ \\int_{\\tilde{\\Omega}_{1}} \\tilde{\\alpha}_{1} \\tilde{W}(\\tilde{\\boldsymbol{\\varepsilon}}_{1}) \\,\\mathrm{d}\\tilde{\\boldsymbol{x}} + \\int_{\\tilde{\\Omega}_{2}} \\tilde{\\alpha}_{2} \\tilde{W}(\\tilde{\\boldsymbol{\\varepsilon}}_{2}) \\,\\mathrm{d}\\tilde{\\boldsymbol{x}} \\right] + \\frac{\\gamma U_{0}^{2} L^{2}}{2}\\int_{\\tilde{\\Gamma}_{c}} \\tilde{w}_{c} \\left\\|\\tilde{\\boldsymbol{u}}_{1}-\\tilde{\\boldsymbol{u}}_{2}\\right\\|^{2}\\,\\mathrm{d}\\tilde{s}\n$$\nThe problem requires expressing this in the form $\\Pi = E U_{0}^{2} L \\, \\tilde{\\Pi}$. To achieve this, we must factor $E U_{0}^{2} L$ from the entire expression, including the coupling term.\n$$\n\\frac{\\gamma U_{0}^{2} L^{2}}{2} = (E U_{0}^{2} L) \\left( \\frac{\\gamma L}{2E} \\right)\n$$\nSubstituting this back into the expression for $\\Pi$:\n$$\n\\Pi = E U_{0}^{2} L \\left[ \\int_{\\tilde{\\Omega}_{1}} \\tilde{\\alpha}_{1} \\tilde{W}(\\tilde{\\boldsymbol{\\varepsilon}}_{1}) \\,\\mathrm{d}\\tilde{\\boldsymbol{x}} + \\int_{\\tilde{\\Omega}_{2}} \\tilde{\\alpha}_{2} \\tilde{W}(\\tilde{\\boldsymbol{\\varepsilon}}_{2}) \\,\\mathrm{d}\\tilde{\\boldsymbol{x}} + \\frac{\\gamma L}{2E} \\int_{\\tilde{\\Gamma}_{c}} \\tilde{w}_{c} \\left\\|\\tilde{\\boldsymbol{u}}_{1}-\\tilde{\\boldsymbol{u}}_{2}\\right\\|^{2}\\,\\mathrm{d}\\tilde{s} \\right]\n$$\nThis gives the dimensionless functional $\\tilde{\\Pi}(\\tilde{\\boldsymbol{u}}_{1},\\tilde{\\boldsymbol{u}}_{2})$:\n$$\n\\tilde{\\Pi}(\\tilde{\\boldsymbol{u}}_{1},\\tilde{\\boldsymbol{u}}_{2}) = \\int_{\\tilde{\\Omega}_{1}} \\tilde{\\alpha}_{1} \\tilde{W}(\\tilde{\\boldsymbol{\\varepsilon}}_{1}) \\,\\mathrm{d}\\tilde{\\boldsymbol{x}} + \\int_{\\tilde{\\Omega}_{2}} \\tilde{\\alpha}_{2} \\tilde{W}(\\tilde{\\boldsymbol{\\varepsilon}}_{2}) \\,\\mathrm{d}\\tilde{\\boldsymbol{x}} + \\frac{\\gamma L}{2E} \\int_{\\tilde{\\Gamma}_{c}} \\tilde{w}_{c} \\left\\|\\tilde{\\boldsymbol{u}}_{1}-\\tilde{\\boldsymbol{u}}_{2}\\right\\|^{2}\\,\\mathrm{d}\\tilde{s}\n$$\nThe coupling penalty term in the original functional has the form $\\frac{\\gamma}{2} \\times (\\text{integral})$. The corresponding term in the dimensionless functional $\\tilde{\\Pi}$ is $\\frac{1}{2} \\left(\\frac{\\gamma L}{E}\\right) \\times (\\text{integral})$. Therefore, the original penalty parameter $\\gamma$ has been replaced by the dimensionless group $\\frac{\\gamma L}{E}$.\n\nTo confirm this result, we perform a dimensional analysis on the identified parameter. The units of the physical quantities are denoted by $[\\cdot]$. The energy functional term has units of energy, $[ \\text{Force} \\times \\text{Length} ]$.\nFrom the penalty term, $[\\gamma] \\times [\\text{dimensionless}] \\times [\\text{Length}]^{2} \\times [\\text{Length}]^{2} = [\\text{Force}] \\times [\\text{Length}]$.\n$$\n[\\gamma] L^{4} = F L \\implies [\\gamma] = \\frac{F}{L^{3}}\n$$\nThe Young's modulus $E$ has units of stress, which is force per area: $[E] = \\frac{F}{L^{2}}$.\nThe characteristic length $L$ has units of length, $[L]$.\nThe dimensionless number is thus:\n$$\n\\left[\\frac{\\gamma L}{E}\\right] = \\frac{[\\gamma][L]}{[E]} = \\frac{(F/L^{3})(L)}{(F/L^{2})} = \\frac{F/L^{2}}{F/L^{2}} = 1\n$$\nThe parameter is indeed dimensionless. This is the single dimensionless parameter that multiplies the coupling penalty term in $\\tilde{\\Pi}$ in a manner analogous to $\\gamma$ in $\\Pi$.\nThe final expression depends only on $\\gamma$, $L$, and $E$, as required.",
            "answer": "$$\n\\boxed{\\frac{\\gamma L}{E}}\n$$"
        },
        {
            "introduction": "Having examined the continuous formulation, we now turn to its discrete counterpart in a finite element setting. A crucial test for any numerical method is its ability to exactly reproduce simple, physically meaningful solutions—a property known as consistency. This practice introduces the celebrated 'patch test,' applying it to the Arlequin framework to confirm that the method correctly handles a linear displacement field, regardless of how the underlying meshes are configured .",
            "id": "3733233",
            "problem": "Consider an overlapping coupling region $\\,\\Omega_{c}=[0,1]\\,$ in a one-dimensional Arlequin framework that blends two models, denoted Model A and Model B. Each model is discretized with the Finite Element Method (FEM) using continuous, piecewise-linear shape functions on generally nonmatching meshes. Let $\\,V_{A}\\,$ and $\\,V_{B}\\,$ be the corresponding discrete trial spaces, and let $\\,\\{\\varphi_{i}\\}\\,$ denote the nodal basis of $\\,V_{A}\\,$. The Arlequin coupling penalty energy in the overlap is defined, for any linear transfer operator $\\,P:V_{B}\\to V_{A}\\,$, by\n$$\nE(P)\\;=\\;\\frac{\\gamma}{2}\\int_{\\Omega_{c}}\\big(u_{h}^{A}(x)\\;-\\;P\\,u_{h}^{B}(x)\\big)^{2}\\,\\mathrm{d}x,\n$$\nwhere $\\,\\gamma>0\\,$ is a constant penalty parameter, $\\,u_{h}^{A}\\in V_{A}\\,$ is the discrete displacement in Model A, and $\\,u_{h}^{B}\\in V_{B}\\,$ is the discrete displacement in Model B. Assume exact quadrature is used in all integrals.\n\nPerform a patch test with a globally linear exact displacement field\n$$\nu(x)\\;=\\;\\alpha\\,x\\;+\\;\\beta,\n$$\nwhere $\\,\\alpha,\\beta\\in\\mathbb{R}\\,$. Let $\\,u_{h}^{A}\\,$ and $\\,u_{h}^{B}\\,$ be the standard nodal interpolants of $\\,u\\,$ into $\\,V_{A}\\,$ and $\\,V_{B}\\,$, respectively. Consider two choices for the transfer operator $\\,P\\,$:\n- $\\,P_{I}\\,$, defined by nodal interpolation from $\\,V_{B}\\,$ to $\\,V_{A}\\,$, that is, $\\,P_{I}u_{h}^{B}\\in V_{A}\\,$ is the unique $\\,V_{A}\\,$-function whose nodal values at the nodes of Model A equal the pointwise values of $\\,u_{h}^{B}\\,$ evaluated at those nodes.\n- $\\,P_{L^{2}}\\,$, defined by the $L^2$ (Lebesgue space) orthogonal projection from $\\,V_{B}\\,$ onto $\\,V_{A}\\,$, i.e., $\\,P_{L^{2}}u_{h}^{B}\\in V_{A}\\,$ satisfies\n$$\n\\int_{\\Omega_{c}}\\varphi_{i}(x)\\,\\big(P_{L^{2}}u_{h}^{B}(x)\\;-\\;u_{h}^{B}(x)\\big)\\,\\mathrm{d}x\\;=\\;0\\quad\\text{for all basis functions}\\;\\varphi_{i}\\in V_{A}.\n$$\n\nCompute the consistency error energies\n$$\nE(P_{I})\\;=\\;\\frac{\\gamma}{2}\\int_{\\Omega_{c}}\\big(u_{h}^{A}(x)-P_{I}u_{h}^{B}(x)\\big)^{2}\\,\\mathrm{d}x,\\qquad\nE(P_{L^{2}})\\;=\\;\\frac{\\gamma}{2}\\int_{\\Omega_{c}}\\big(u_{h}^{A}(x)-P_{L^{2}}u_{h}^{B}(x)\\big)^{2}\\,\\mathrm{d}x,\n$$\nand report the difference\n$$\n\\Delta E\\;=\\;E(P_{I})\\;-\\;E(P_{L^{2}}).\n$$\nExpress your final answer for $\\,\\Delta E\\,$ as a single real number. No rounding is required.",
            "solution": "The problem is validated as scientifically grounded, well-posed, and objective. It represents a standard consistency analysis, known as a patch test, for a numerical coupling method. All necessary definitions and conditions are provided, and there are no internal contradictions or factual errors. We may proceed with the solution.\n\nThe problem asks for the computation of the difference in consistency error energies, $\\Delta E = E(P_{I}) - E(P_{L^{2}})$, for an Arlequin coupling formulation subjected to a linear displacement field.\n\nThe exact displacement field is given as a linear function:\n$$\nu(x) = \\alpha x + \\beta\n$$\nwhere $\\alpha, \\beta \\in \\mathbb{R}$.\n\nThe discrete spaces $V_{A}$ and $V_{B}$ are defined as spaces of continuous, piecewise-linear functions over their respective meshes. A fundamental property of such finite element spaces is that they can exactly represent any linear polynomial. The nodal interpolant of a linear function into a space of piecewise-linear functions is the linear function itself.\n\nGiven that $u_{h}^{A} \\in V_{A}$ is the nodal interpolant of $u(x)$, it follows that:\n$$\nu_{h}^{A}(x) = u(x) = \\alpha x + \\beta \\quad \\text{for all } x \\in \\Omega_{c}\n$$\nSimilarly, for $u_{h}^{B} \\in V_{B}$:\n$$\nu_{h}^{B}(x) = u(x) = \\alpha x + \\beta \\quad \\text{for all } x \\in \\Omega_{c}\n$$\nThis is a crucial observation. The discrete fields are identical to the exact continuous field throughout the domain.\n\nNow, we analyze the two transfer operators, $P_{I}$ and $P_{L^{2}}$, and their corresponding energies.\n\n**1. The Interpolation Operator, $P_{I}$**\n\nThe operator $P_{I}$ maps a function from $V_{B}$ to $V_{A}$ by nodal interpolation. $P_{I}u_{h}^{B}$ is defined as the unique function in $V_{A}$ whose nodal values at the nodes of the Model A mesh are equal to the pointwise values of $u_{h}^{B}$ at those nodes.\n\nLet $\\{x_{j}^{A}\\}$ be the set of nodes for the mesh of Model A. The nodal values of $P_{I}u_{h}^{B}$ are:\n$$\n(P_{I}u_{h}^{B})(x_{j}^{A}) = u_{h}^{B}(x_{j}^{A})\n$$\nSince $u_{h}^{B}(x) = u(x)$, we have:\n$$\n(P_{I}u_{h}^{B})(x_{j}^{A}) = u(x_{j}^{A})\n$$\nBy definition, $u_{h}^{A}$ is the nodal interpolant of $u(x)$ in $V_{A}$, which means its nodal values are also $u_{h}^{A}(x_{j}^{A}) = u(x_{j}^{A})$.\nSince both $P_{I}u_{h}^{B}$ and $u_{h}^{A}$ belong to the same space $V_{A}$ and have identical values at all nodes of the associated mesh, they must be the same function.\n$$\nP_{I}u_{h}^{B}(x) = u_{h}^{A}(x) \\quad \\text{for all } x \\in \\Omega_{c}\n$$\nNow we can compute the energy $E(P_{I})$:\n$$\nE(P_{I}) = \\frac{\\gamma}{2}\\int_{\\Omega_{c}}\\big(u_{h}^{A}(x) - P_{I}u_{h}^{B}(x)\\big)^{2}\\,\\mathrm{d}x = \\frac{\\gamma}{2}\\int_{\\Omega_{c}}\\big(u_{h}^{A}(x) - u_{h}^{A}(x)\\big)^{2}\\,\\mathrm{d}x = \\frac{\\gamma}{2}\\int_{\\Omega_{c}} 0^{2}\\,\\mathrm{d}x = 0\n$$\n\n**2. The $L^{2}$-Projection Operator, $P_{L^{2}}$**\n\nThe operator $P_{L^{2}}$ is the orthogonal projection from $V_{B}$ onto $V_{A}$ with respect to the $L^{2}$ inner product. The projection $P_{L^{2}}u_{h}^{B}$ is the function in $V_{A}$ that is \"closest\" to $u_{h}^{B}$ in the $L^{2}$ sense.\n\nWe are projecting the function $u_{h}^{B}(x) = u(x)$ onto the space $V_{A}$. As we established, the linear function $u(x)$ is an element of the space of continuous, piecewise-linear functions, $V_{A}$. That is, $u \\in V_{A}$.\n\nThe $L^{2}$ projection of a function $f$ onto a space $S$ is $f$ itself if $f \\in S$. The projection finds the best approximation in $S$; if the function is already in $S$, the best approximation is trivially the function itself, with zero error.\nTherefore, the projection of $u_{h}^{B} = u$ onto $V_{A}$ is $u$:\n$$\nP_{L^{2}}u_{h}^{B}(x) = u(x)\n$$\nSince $u_{h}^{A}(x) = u(x)$ as well, we have:\n$$\nP_{L^{2}}u_{h}^{B}(x) = u_{h}^{A}(x) \\quad \\text{for all } x \\in \\Omega_{c}\n$$\nNow we can compute the energy $E(P_{L^{2}})$:\n$$\nE(P_{L^{2}}) = \\frac{\\gamma}{2}\\int_{\\Omega_{c}}\\big(u_{h}^{A}(x) - P_{L^{2}}u_{h}^{B}(x)\\big)^{2}\\,\\mathrm{d}x = \\frac{\\gamma}{2}\\int_{\\Omega_{c}}\\big(u_{h}^{A}(x) - u_{h}^{A}(x)\\big)^{2}\\,\\mathrm{d}x = \\frac{\\gamma}{2}\\int_{\\Omega_{c}} 0^{2}\\,\\mathrm{d}x = 0\n$$\n\n**3. The Difference in Energies, $\\Delta E$**\n\nBoth coupling energies are zero, which signifies that the Arlequin formulation passes the linear patch test with either choice of transfer operator. This is an essential property for a sound coupling method, ensuring consistency.\n\nThe difference is therefore:\n$$\n\\Delta E = E(P_{I}) - E(P_{L^{2}}) = 0 - 0 = 0\n$$\nThe result is independent of the penalty parameter $\\gamma > 0$ and the specific coefficients $\\alpha$ and $\\beta$ of the linear field.",
            "answer": "$$\n\\boxed{0}\n$$"
        },
        {
            "introduction": "With confidence in the method's theoretical consistency, the final step is to tackle the practical challenge of solving the large-scale algebraic equations that arise from discretization. This exercise delves into the numerical engine of the Lagrange multiplier-based Arlequin method, where you will derive the Schur complement system and implement an efficient preconditioned iterative solver. Through this computational practice, you will directly observe the connection between abstract spectral theory and the concrete performance of a numerical algorithm .",
            "id": "3733205",
            "problem": "Consider the Arlequin coupling method for overlapping models in linear elasticity, where consistency across the overlap is enforced by Lagrange multipliers. After finite-dimensional discretization, this leads to a symmetric saddle-point linear system for the primal variables and multipliers. Let the assembled stiffness matrix be $K \\in \\mathbb{R}^{n \\times n}$, the constraint matrix be $B \\in \\mathbb{R}^{m \\times n}$, the Lagrange multipliers be $\\lambda \\in \\mathbb{R}^{m}$, and the load vector be $f \\in \\mathbb{R}^{n}$. The discrete saddle-point system is\n$$\n\\begin{bmatrix}\nK & B^{\\top} \\\\\nB & 0\n\\end{bmatrix}\n\\begin{bmatrix}\nu \\\\\n\\lambda\n\\end{bmatrix}\n=\n\\begin{bmatrix}\nf \\\\\nc\n\\end{bmatrix},\n$$\nwith $c \\in \\mathbb{R}^{m}$ the constraint target in the overlap, typically $c = 0$ to enforce continuity in the overlap. Assume $K$ is symmetric positive definite and $B$ has full row rank. Eliminating the primal variables reduces the problem to the Schur complement system in the multiplier space:\n$$\nS \\lambda = g, \\quad \\text{where} \\quad S := B K^{-1} B^{\\top} \\in \\mathbb{R}^{m \\times m}, \\quad g := B K^{-1} f \\in \\mathbb{R}^{m}.\n$$\nYou must implement a Krylov subspace solver, specifically the preconditioned Conjugate Gradient (PCG) method, for the multiplier-space system $S \\lambda = g$ with a constraint preconditioner $\\widetilde{S}$, and then compute and report the convergence bounds derived from spectral properties of the preconditioned operator in the multiplier space.\n\nStarting from the fundamental base of linear algebra and the saddle-point elimination, derive the multiplier-space problem, justify that $S$ is symmetric positive definite (SPD) under the given assumptions, and show that the convergence of preconditioned Conjugate Gradient depends only on the spectrum of $\\widetilde{S}^{-1} S$. You must derive a bound of the form\n$$\n\\|e_k\\|_{S} \\leq \\rho(\\kappa)^{k} C \\|e_0\\|_{S},\n$$\nwhere $e_k := \\lambda_k - \\lambda^{\\star}$ is the error after $k$ iterations, $\\lambda^{\\star}$ is the exact solution of $S \\lambda = g$, $\\kappa$ is a condition number extracted from the eigenvalues of $\\widetilde{S}^{-1} S$, $\\rho(\\kappa)$ is a convergence factor depending on $\\kappa$, and $C$ is a constant that you must justify. Your implementation must:\n- Construct the multiplier-space Schur complement $S$ and right-hand side $g$ from specified $(K, B, f)$.\n- Implement preconditioned Conjugate Gradient for $S \\lambda = g$ using an SPD preconditioner $\\widetilde{S}$.\n- Compute the eigenvalues of $\\widetilde{S}^{-1} S$ and then the associated condition number $\\kappa$ and use it to evaluate the theoretical bound for $\\|e_k\\|_{S}$ at the attained iteration count $k$.\n- Report, for each test case, the final number of iterations $k$, the final error norm $\\|e_k\\|_{S}$, and the theoretical bound value evaluated at $k$.\n\nFor all calculations, use purely mathematical quantities; there are no physical units involved. Angles do not appear. Express all numeric results in standard decimal form, not as percentages.\n\nUse the following test suite with explicit matrices. In each case, define $K := \\operatorname{diag}(K_1, K_2)$, $B$ as below, $f$ as below, and choose $\\widetilde{S}$ as specified.\n\nTest case $1$ (ideal preconditioner, well-conditioned stiffness):\n- $K_1 = \\begin{bmatrix} 4 & 1 \\\\ 1 & 3 \\end{bmatrix}$, $K_2 = \\begin{bmatrix} 5 & 0 \\\\ 0 & 2 \\end{bmatrix}$,\n- $B = \\begin{bmatrix} 1 & 0 & -1 & 0 \\\\ 0 & 1 & 0 & -1 \\end{bmatrix}$,\n- $f = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 1 \\end{bmatrix}$,\n- $\\widetilde{S} = S$.\n\nTest case $2$ (diagonal preconditioner, moderate conditioning):\n- $K_1 = \\begin{bmatrix} 4 & 1 \\\\ 1 & 3 \\end{bmatrix}$, $K_2 = \\begin{bmatrix} 5 & 0 \\\\ 0 & 2 \\end{bmatrix}$,\n- $B = \\begin{bmatrix} 1 & 0 & -1 & 0 \\\\ 0 & 1 & 0 & -1 \\end{bmatrix}$,\n- $f = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 1 \\end{bmatrix}$,\n- $\\widetilde{S} = \\operatorname{diag}(S)$, i.e., the diagonal of $S$ assembled into a diagonal matrix.\n\nTest case $3$ (diagonal preconditioner, strong stiffness contrast):\n- $K_1 = \\begin{bmatrix} 1000 & 0 \\\\ 0 & 0.001 \\end{bmatrix}$, $K_2 = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}$,\n- $B = \\begin{bmatrix} 1 & 0 & -1 & 0 \\\\ 0 & 1 & 0 & -1 \\end{bmatrix}$,\n- $f = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 1 \\end{bmatrix}$,\n- $\\widetilde{S} = \\operatorname{diag}(S)$.\n\nAlgorithmic requirements:\n- Implement preconditioned Conjugate Gradient with initial guess $\\lambda_0 = 0$, stopping when the Euclidean norm of the residual $\\|r_k\\|_2$ falls below $10^{-10}$ or when $k$ reaches $m$, whichever comes first, where $m$ is the number of constraints (the dimension of $\\lambda$).\n- After convergence, compute $\\|e_k\\|_{S} = \\sqrt{e_k^{\\top} S e_k}$ using the exact solution $\\lambda^{\\star} = S^{-1} g$.\n- Compute the eigenvalues $\\{\\mu_i\\}$ of $\\widetilde{S}^{-1} S$, then set $\\kappa = \\dfrac{\\max_i \\mu_i}{\\min_i \\mu_i}$, and evaluate the bound $\\|e_k\\|_{S} \\leq 2 \\left(\\dfrac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1}\\right)^{k} \\|e_0\\|_{S}$ at the attained iteration count $k$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with one entry per test case, each entry itself being a list of the form $[k, \\|e_k\\|_{S}, \\text{bound}]$. For example: $[[k_1,\\|e_{k_1}\\|_{S},b_1],[k_2,\\|e_{k_2}\\|_{S},b_2],[k_3,\\|e_{k_3}\\|_{S},b_3]]$.\n\nNo external input is allowed; all data must be generated inside your program from the test suite provided above.",
            "solution": "The problem has been validated and is deemed a well-posed, scientifically grounded exercise in numerical linear algebra, specifically concerning the solution of saddle-point systems arising in computational mechanics. All necessary data and conditions are provided.\n\nThe problem requires the analysis and implementation of a preconditioned conjugate gradient solver for a Schur complement system derived from a linear elasticity problem formulated using the Arlequin method. The analysis involves deriving the system, proving the requisite mathematical properties for the solver, and establishing the theoretical convergence bounds.\n\n**1. Derivation of the Schur Complement System**\n\nThe governing discrete saddle-point system is given by:\n$$\n\\begin{bmatrix}\nK & B^{\\top} \\\\\nB & 0\n\\end{bmatrix}\n\\begin{bmatrix}\nu \\\\\n\\lambda\n\\end{bmatrix}\n=\n\\begin{bmatrix}\nf \\\\\nc\n\\end{bmatrix}\n$$\nwhere $K \\in \\mathbb{R}^{n \\times n}$ is the symmetric positive definite (SPD) stiffness matrix, $B \\in \\mathbb{R}^{m \\times n}$ is the constraint matrix with full row rank, $u \\in \\mathbb{R}^{n}$ are the primal variables, $\\lambda \\in \\mathbb{R}^{m}$ are the Lagrange multipliers, $f \\in \\mathbb{R}^{n}$ is the load vector, and $c \\in \\mathbb{R}^{m}$ is the constraint target vector. The problem specifies using $c=0$.\n\nThis block system represents two coupled equations:\n$$\n\\begin{align*}\nK u + B^{\\top} \\lambda &= f \\quad &(1) \\\\\nB u &= c \\quad &(2)\n\\end{align*}\n$$\nSince $K$ is SPD, it is invertible. From equation $(1)$, we can express the primal variable $u$ in terms of the Lagrange multiplier $\\lambda$:\n$$\nu = K^{-1} (f - B^{\\top} \\lambda)\n$$\nSubstituting this expression for $u$ into equation $(2)$ eliminates the primal variables:\n$$\nB \\left( K^{-1} (f - B^{\\top} \\lambda) \\right) = c\n$$\nExpanding and rearranging the terms to solve for $\\lambda$:\n$$\nB K^{-1} f - B K^{-1} B^{\\top} \\lambda = c\n$$\n$$\n(B K^{-1} B^{\\top}) \\lambda = B K^{-1} f - c\n$$\nThis is the Schur complement system in the multiplier space, written as $S \\lambda = g$. The Schur complement matrix $S$ and the right-hand side vector $g$ are defined as:\n$$\nS := B K^{-1} B^{\\top} \\in \\mathbb{R}^{m \\times m}\n$$\n$$\ng := B K^{-1} f - c\n$$\nAs per the problem statement, we take the constraint target $c=0$, yielding $g := B K^{-1} f$.\n\n**2. Properties of the Schur Complement Matrix $S$**\n\nThe applicability of the Conjugate Gradient (CG) method hinges on the matrix $S$ being symmetric and positive definite.\n\n- **Symmetry:** We verify the symmetry of $S$ by taking its transpose.\n$$\nS^{\\top} = (B K^{-1} B^{\\top})^{\\top} = (B^{\\top})^{\\top} (K^{-1})^{\\top} B^{\\top}\n$$\nGiven that the transpose of a product is the product of transposes in reverse order, and $(A^{\\top})^{\\top}=A$. We are given that $K$ is symmetric, so $K = K^{\\top}$. The inverse of a symmetric matrix is also symmetric, thus $(K^{-1})^{\\top} = (K^{\\top})^{-1} = K^{-1}$.\n$$\nS^{\\top} = B K^{-1} B^{\\top} = S\n$$\nTherefore, the Schur complement matrix $S$ is symmetric.\n\n- **Positive Definiteness:** To prove positive definiteness, we must show that $x^{\\top} S x > 0$ for any non-zero vector $x \\in \\mathbb{R}^{m}$.\n$$\nx^{\\top} S x = x^{\\top} (B K^{-1} B^{\\top}) x = (B^{\\top} x)^{\\top} K^{-1} (B^{\\top} x)\n$$\nLet the vector $y = B^{\\top} x$. The matrix $B$ is an $m \\times n$ matrix with full row rank. This implies that its transpose, $B^{\\top}$, an $n \\times m$ matrix, has full column rank. Consequently, for any non-zero vector $x \\in \\mathbb{R}^{m}$, the resulting vector $y = B^{\\top} x \\in \\mathbb{R}^{n}$ is also non-zero.\nWe are given that $K$ is SPD. A property of SPD matrices is that their inverse, $K^{-1}$, is also SPD. This means that for any non-zero vector $y$, the quadratic form $y^{\\top} K^{-1} y > 0$.\nSince $y=B^{\\top}x$ is non-zero for any non-zero $x$, we have:\n$$\nx^{\\top} S x = y^{\\top} K^{-1} y > 0 \\quad \\forall x \\neq 0\n$$\nThis confirms that $S$ is positive definite. Being both symmetric and positive definite, $S$ is an SPD matrix, which validates the use of the CG method for solving $S\\lambda=g$.\n\n**3. Preconditioned Conjugate Gradient (PCG) and Convergence Analysis**\n\nThe convergence rate of the CG method depends on the condition number of the system matrix. For the system $S\\lambda=g$, the condition number is $\\kappa(S) = \\lambda_{\\max}(S) / \\lambda_{\\min}(S)$. Preconditioning is a technique to improve this condition number. We introduce an SPD preconditioner matrix $\\widetilde{S} \\in \\mathbb{R}^{m \\times m}$ that approximates $S$ in some sense and whose inverse is inexpensive to apply. We then solve the equivalent system:\n$$\n\\widetilde{S}^{-1} S \\lambda = \\widetilde{S}^{-1} g\n$$\nThe CG algorithm is applied to this preconditioned system. For the standard derivation of PCG, the operator must be self-adjoint (symmetric) with respect to the inner product used. The preconditioned operator $\\widetilde{S}^{-1} S$ is not generally symmetric in the standard Euclidean inner product. However, it is self-adjoint with respect to the $\\widetilde{S}$-inner product, defined as $\\langle x, y \\rangle_{\\widetilde{S}} = x^{\\top} \\widetilde{S} y$:\n$$\n\\langle \\widetilde{S}^{-1} S x, y \\rangle_{\\widetilde{S}} = (\\widetilde{S}^{-1} S x)^{\\top} \\widetilde{S} y = x^{\\top} S^{\\top} (\\widetilde{S}^{-1})^{\\top} \\widetilde{S} y = x^{\\top} S y\n$$\n$$\n\\langle x, \\widetilde{S}^{-1} S y \\rangle_{\\widetilde{S}} = x^{\\top} \\widetilde{S} (\\widetilde{S}^{-1} S y) = x^{\\top} S y\n$$\nSince $\\langle \\widetilde{S}^{-1} S x, y \\rangle_{\\widetilde{S}} = \\langle x, \\widetilde{S}^{-1} S y \\rangle_{\\widetilde{S}}$, the operator is indeed self-adjoint in this inner product, justifying the application of PCG.\n\nThe convergence of PCG is governed by the spectral properties of the preconditioned matrix $\\widetilde{S}^{-1}S$. The standard convergence bound for the error $e_k = \\lambda_k - \\lambda^\\star$ after $k$ iterations is given in the energy norm induced by the original matrix $S$, which is $\\|v\\|_S = \\sqrt{v^{\\top} S v}$. The bound is:\n$$\n\\|e_k\\|_{S} \\leq 2 \\left( \\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1} \\right)^{k} \\|e_0\\|_{S}\n$$\nHere, $\\kappa$ is the condition number of the preconditioned operator, $\\kappa = \\kappa(\\widetilde{S}^{-1}S) = \\frac{\\mu_{\\max}}{\\mu_{\\min}}$, where $\\mu_i$ are the eigenvalues of $\\widetilde{S}^{-1}S$. The initial error is $e_0 = \\lambda_0 - \\lambda^\\star$. The constant $C=2$\nis justified as it arises from the standard worst-case analysis of CG convergence, which relies on bounding the error using properties of Chebyshev polynomials that optimally approximate zero on the interval containing the eigenvalues of the preconditioned operator.\n\n**4. Numerical Implementation and Analysis**\n\nFor each specified test case, the following procedure is executed:\n1.  The matrices $K$, $B$, and vector $f$ are constructed.\n2.  The Schur complement $S = B K^{-1} B^{\\top}$ and the right-hand side $g = B K^{-1} f$ are computed explicitly.\n3.  The specified preconditioner $\\widetilde{S}$ is formed.\n4.  The PCG algorithm is executed to solve $S\\lambda=g$ with an initial guess $\\lambda_0=0$. The algorithm terminates when the Euclidean norm of the residual falls below $10^{-10}$ or the number of iterations reaches the system size $m$. The final iterate $\\lambda_k$ and iteration count $k$ are recorded.\n5.  The exact solution $\\lambda^\\star = S^{-1}g$ is computed directly to facilitate error analysis.\n6.  The final error norm $\\|e_k\\|_S = \\sqrt{(\\lambda_k-\\lambda^\\star)^{\\top} S (\\lambda_k-\\lambda^\\star)}$ is calculated.\n7.  The eigenvalues of $\\widetilde{S}^{-1} S$ are computed to find the condition number $\\kappa$.\n8.  The theoretical error bound $2 \\left( \\frac{\\sqrt{\\kappa}-1}{\\sqrt{\\kappa}+1} \\right)^k \\|e_0\\|_S$ is evaluated using the final iteration count $k$ and the initial error norm $\\|e_0\\|_S = \\|\\lambda^\\star\\|_S$.\nThe results for each test case are then reported.\n```python\nimport numpy as np\n\ndef solve_pcg(S, g, S_tilde, tol=1e-10):\n    \"\"\"\n    Solves the system S*lambda = g using the Preconditioned Conjugate Gradient method.\n\n    Args:\n        S (np.ndarray): The SPD matrix of the system.\n        g (np.ndarray): The right-hand side vector.\n        S_tilde (np.ndarray): The SPD preconditioner matrix.\n        tol (float): The tolerance for the residual norm to determine convergence.\n\n    Returns:\n        tuple: A tuple containing:\n            - np.ndarray: The solution vector lambda.\n            - int: The number of iterations performed.\n    \"\"\"\n    m = S.shape[0]\n    lmbda = np.zeros(m)\n    r = g - S @ lmbda\n\n    if np.linalg.norm(r)  tol:\n        return lmbda, 0\n\n    # For diagonal preconditioners, can use division. For general S_tilde, solve.\n    if np.all(S_tilde == np.diag(np.diag(S_tilde))):\n        z = r / np.diag(S_tilde)\n    else:\n        z = np.linalg.solve(S_tilde, r)\n        \n    p = z.copy()\n    rho_old = r.T @ z\n\n    # The loop must run at most m times.\n    for k in range(m):\n        Sp = S @ p\n        alpha = rho_old / (p.T @ Sp)\n        \n        lmbda_new = lmbda + alpha * p\n        r_new = r - alpha * Sp\n        \n        if np.linalg.norm(r_new)  tol:\n            return lmbda_new, k + 1\n            \n        if np.all(S_tilde == np.diag(np.diag(S_tilde))):\n            z_new = r_new / np.diag(S_tilde)\n        else:\n            z_new = np.linalg.solve(S_tilde, r_new)\n\n        rho_new = r_new.T @ z_new\n        beta = rho_new / rho_old\n        \n        p = z_new + beta * p\n        rho_old = rho_new\n        r = r_new\n        lmbda = lmbda_new\n\n    return lmbda, m\n\n\ndef solve():\n    \"\"\"\n    Main function to run the test cases and print the results.\n    \"\"\"\n    # Test case 1: Ideal preconditioner\n    K1_1 = np.array([[4, 1], [1, 3]])\n    K2_1 = np.array([[5, 0], [0, 2]])\n    B_1 = np.array([[1, 0, -1, 0], [0, 1, 0, -1]])\n    f_1 = np.array([1, 0, 0, 1])\n    \n    # Test case 2: Diagonal preconditioner\n    K1_2 = np.array([[4, 1], [1, 3]])\n    K2_2 = np.array([[5, 0], [0, 2]])\n    B_2 = np.array([[1, 0, -1, 0], [0, 1, 0, -1]])\n    f_2 = np.array([1, 0, 0, 1])\n\n    # Test case 3: High stiffness contrast\n    K1_3 = np.array([[1000, 0], [0, 0.001]])\n    K2_3 = np.array([[1, 0], [0, 1]])\n    B_3 = np.array([[1, 0, -1, 0], [0, 1, 0, -1]])\n    f_3 = np.array([1, 0, 0, 1])\n\n    test_cases = [\n        {'K1': K1_1, 'K2': K2_1, 'B': B_1, 'f': f_1, 'precond_type': 'ideal'},\n        {'K1': K1_2, 'K2': K2_2, 'B': B_2, 'f': f_2, 'precond_type': 'diag'},\n        {'K1': K1_3, 'K2': K2_3, 'B': B_3, 'f': f_3, 'precond_type': 'diag'}\n    ]\n\n    results = []\n\n    for case in test_cases:\n        K = np.block([[case['K1'], np.zeros((2, 2))], [np.zeros((2, 2)), case['K2']]])\n        B = case['B']\n        f = case['f']\n\n        # 1. Form Schur complement system S*lambda = g\n        K_inv = np.linalg.inv(K)\n        S = B @ K_inv @ B.T\n        g = B @ K_inv @ f\n\n        # 2. Define preconditioner S_tilde\n        if case['precond_type'] == 'ideal':\n            S_tilde = S.copy()\n        elif case['precond_type'] == 'diag':\n            S_tilde = np.diag(np.diag(S))\n        \n        # 3. Solve using PCG\n        lmbda_k, k_final = solve_pcg(S, g, S_tilde)\n\n        # 4. Compute exact solution and error norm\n        lmbda_star = np.linalg.solve(S, g)\n        e_k = lmbda_k - lmbda_star\n        norm_ek_S = np.sqrt(e_k.T @ S @ e_k)\n\n        # 5. Compute theoretical bound\n        if np.all(S_tilde == np.diag(np.diag(S_tilde))):\n            S_tilde_inv = np.linalg.inv(S_tilde)\n        else:\n            # For ideal case S_tilde = S, S_tilde_inv @ S is identity\n            S_tilde_inv = np.linalg.inv(S_tilde)\n            \n        preconditioned_op = S_tilde_inv @ S\n        \n        try:\n            eigenvalues = np.linalg.eigvals(preconditioned_op)\n            kappa = np.max(eigenvalues.real) / np.min(eigenvalues.real)\n        except np.linalg.LinAlgError:\n            # In case of an issue, fallback which shouldn't happen for these cases\n            kappa = 1.0\n\n        if kappa  1.0: # Handle potential floating point inaccuracies\n            kappa = 1.0\n        \n        # Initial error e_0 = 0 - lambda_star\n        e_0 = -lmbda_star\n        norm_e0_S = np.sqrt(e_0.T @ S @ e_0)\n        \n        if kappa == 1.0:\n            rho_factor = 0.0\n        else:\n            rho_factor = (np.sqrt(kappa) - 1) / (np.sqrt(kappa) + 1)\n        \n        bound = 2.0 * (rho_factor ** k_final) * norm_e0_S\n\n        results.append([k_final, norm_ek_S, bound])\n\n    # Format the output string\n    output_str = \"[\" + \",\".join(map(str, results)) + \"]\"\n    print(output_str)\n\nsolve()\n```",
            "answer": "[[1, 0.0, 0.0], [2, 0.0, 0.015024095493], [2, 0.0, 0.778848135835]]"
        }
    ]
}