{
    "hands_on_practices": [
        {
            "introduction": "To build effective coarse-grained models, we first need to understand the fundamental operators that map information between scales. This exercise  explores the deep connection between an intuitive restriction operator—simple averaging—and the mathematically rigorous concept of an orthogonal projection. By deriving the projection matrix from the principle of minimizing error, you will gain a geometric understanding of how a coarse representation can be seen as the \"best possible approximation\" of a fine-scale state within a specific subspace.",
            "id": "3777685",
            "problem": "Consider a fine grid with $8$ equally spaced sites and the corresponding fine state space $\\mathbb{R}^{8}$ endowed with the standard Euclidean inner product. Define the restriction operator $R \\in \\mathbb{R}^{4 \\times 8}$ that maps a fine vector $u \\in \\mathbb{R}^{8}$ to a coarse vector $Ru \\in \\mathbb{R}^{4}$ by averaging adjacent pairs:\n- For $I \\in \\{1,2,3,4\\}$, $(Ru)_{I} = \\dfrac{u_{2I-1} + u_{2I}}{2}$.\n\nAdopt the principle that the coarse-to-fine mapping should be the orthogonal projection (with respect to the Euclidean inner product on $\\mathbb{R}^{8}$) onto the subspace of fine vectors that are piecewise-constant on each adjacent pair, i.e., vectors $v \\in \\mathbb{R}^{8}$ satisfying $v_{2I-1} = v_{2I}$ for all $I \\in \\{1,2,3,4\\}$.\n\nTasks:\n- Using only the foundational characterization of orthogonal projections as minimizers of squared Euclidean distance onto a linear subspace, derive the orthogonal projector $P \\in \\mathbb{R}^{8 \\times 8}$ that maps any fine vector $u \\in \\mathbb{R}^{8}$ to its closest vector (in Euclidean norm) that is piecewise-constant on adjacent pairs, expressed purely in terms of $R$.\n- Compute $P$ explicitly as an $8 \\times 8$ matrix.\n- Verify analytically that $P^{2} = P$.\n\nProvide only the explicit matrix $P$ as your final answer. No rounding is required, and no units apply. The final answer must be a single analytical expression.",
            "solution": "The problem asks for the derivation of an orthogonal projection operator $P$, its explicit computation, and verification of its properties. The projection is onto a specific subspace of $\\mathbb{R}^{8}$.\n\nFirst, we identify the target subspace for the projection. The problem states that this is the subspace of fine vectors that are piecewise-constant on each adjacent pair. Let this subspace be denoted by $S$. A vector $v \\in \\mathbb{R}^{8}$ is in $S$ if and only if its components satisfy $v_{2I-1} = v_{2I}$ for each $I \\in \\{1, 2, 3, 4\\}$.\nThis means any vector $v \\in S$ can be written in the form:\n$$v = \\begin{pmatrix} c_1 \\\\ c_1 \\\\ c_2 \\\\ c_2 \\\\ c_3 \\\\ c_3 \\\\ c_4 \\\\ c_4 \\end{pmatrix}$$\nfor some set of scalars $\\{c_1, c_2, c_3, c_4\\} \\in \\mathbb{R}^4$.\n\nThe problem specifies that the orthogonal projector $P$ maps any fine vector $u \\in \\mathbb{R}^{8}$ to its closest vector in $S$ with respect to the standard Euclidean norm. This means that for a given $u$, the projected vector $Pu=v$ is the unique vector in $S$ that minimizes the squared Euclidean distance $\\|u-v\\|_2^2$.\n\nWe can express the squared distance as a function of the coefficients $c_I$:\n$$F(c_1, c_2, c_3, c_4) = \\|u - v\\|_2^2 = \\sum_{j=1}^{8} (u_j - v_j)^2$$\nSubstituting the structure of $v \\in S$, we get:\n$$F(c_1, c_2, c_3, c_4) = \\sum_{I=1}^{4} \\left[ (u_{2I-1} - c_I)^2 + (u_{2I} - c_I)^2 \\right]$$\nTo find the coefficients $c_I$ that minimize this function, we take the partial derivative with respect to each $c_K$ for $K \\in \\{1, 2, 3, 4\\}$ and set it to zero. The terms in the sum are independent for each $I$.\n$$\\frac{\\partial F}{\\partial c_K} = \\frac{\\partial}{\\partial c_K} \\left[ (u_{2K-1} - c_K)^2 + (u_{2K} - c_K)^2 \\right] = 0$$\n$$-2(u_{2K-1} - c_K) - 2(u_{2K} - c_K) = 0$$\n$$u_{2K-1} + u_{2K} - 2c_K = 0$$\nSolving for $c_K$, we find the optimal coefficient:\n$$c_K = \\frac{u_{2K-1} + u_{2K}}{2}$$\nThis expression is precisely the definition of the restriction operator $R \\in \\mathbb{R}^{4 \\times 8}$ given in the problem, $(Ru)_I = \\frac{u_{2I-1} + u_{2I}}{2}$. So, the vector of optimal coefficients $c = (c_1, c_2, c_3, c_4)^T$ is given by $c = Ru$.\n\nThe projected vector $Pu = v$ is constructed using these coefficients. Specifically, for each $I \\in \\{1, 2, 3, 4\\}$, the components of $Pu$ are $(Pu)_{2I-1} = c_I$ and $(Pu)_{2I} = c_I$.\nThis operation can be represented by a coarse-to-fine mapping, or prolongation operator, $Q \\in \\mathbb{R}^{8 \\times 4}$, which maps the coarse vector of coefficients $c \\in \\mathbb{R}^4$ to the fine, piecewise-constant vector $v \\in S$. The matrix $Q$ is constructed such that $v=Qc$. Its columns form a basis for the subspace $S$:\n$$Q = \\begin{pmatrix} 1 & 0 & 0 & 0 \\\\ 1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 1 \\\\ 0 & 0 & 0 & 1 \\end{pmatrix}$$\nSince $Pu = v = Qc$ and $c = Ru$, we can write $Pu = Q(Ru) = (QR)u$. This implies that the projection matrix is $P = QR$.\n\nThe problem requires expressing $P$ purely in terms of $R$. Let's write the explicit matrix for $R$:\n$$R = \\begin{pmatrix} \\frac{1}{2} & \\frac{1}{2} & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & \\frac{1}{2} & \\frac{1}{2} & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & \\frac{1}{2} & \\frac{1}{2} & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & \\frac{1}{2} & \\frac{1}{2} \\end{pmatrix}$$\nNow we find the relationship between $Q$ and $R$. The transpose of $R$ is:\n$$R^T = \\begin{pmatrix} \\frac{1}{2} & 0 & 0 & 0 \\\\ \\frac{1}{2} & 0 & 0 & 0 \\\\ 0 & \\frac{1}{2} & 0 & 0 \\\\ 0 & \\frac{1}{2} & 0 & 0 \\\\ 0 & 0 & \\frac{1}{2} & 0 \\\\ 0 & 0 & \\frac{1}{2} & 0 \\\\ 0 & 0 & 0 & \\frac{1}{2} \\\\ 0 & 0 & 0 & \\frac{1}{2} \\end{pmatrix} = \\frac{1}{2} Q$$\nThus, we have the relationship $Q = 2R^T$. Substituting this into our expression for $P$, we get:\n$$P = QR = (2R^T)R = 2R^T R$$\nThis completes the first task, expressing $P$ purely in terms of $R$.\n\nNext, we compute the explicit $8 \\times 8$ matrix for $P$. We can use the expression $P = 2R^T R$:\n$$R^T R = \\begin{pmatrix} \\frac{1}{2} & 0 & 0 & 0 \\\\ \\frac{1}{2} & 0 & 0 & 0 \\\\ 0 & \\frac{1}{2} & 0 & 0 \\\\ 0 & \\frac{1}{2} & 0 & 0 \\\\ 0 & 0 & \\frac{1}{2} & 0 \\\\ 0 & 0 & \\frac{1}{2} & 0 \\\\ 0 & 0 & 0 & \\frac{1}{2} \\\\ 0 & 0 & 0 & \\frac{1}{2} \\end{pmatrix} \\begin{pmatrix} \\frac{1}{2} & \\frac{1}{2} & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & \\frac{1}{2} & \\frac{1}{2} & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & \\frac{1}{2} & \\frac{1}{2} & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & \\frac{1}{2} & \\frac{1}{2} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{4} & \\frac{1}{4} & 0 & 0 & 0 & 0 & 0 & 0 \\\\ \\frac{1}{4} & \\frac{1}{4} & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & \\frac{1}{4} & \\frac{1}{4} & 0 & 0 & 0 & 0 \\\\ 0 & 0 & \\frac{1}{4} & \\frac{1}{4} & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & \\frac{1}{4} & \\frac{1}{4} & 0 & 0 \\\\ 0 & 0 & 0 & 0 & \\frac{1}{4} & \\frac{1}{4} & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & \\frac{1}{4} & \\frac{1}{4} \\\\ 0 & 0 & 0 & 0 & 0 & 0 & \\frac{1}{4} & \\frac{1}{4} \\end{pmatrix}$$\n$$P = 2 R^T R = 2 \\times \\begin{pmatrix} \\frac{1}{4} & \\frac{1}{4} & \\dots \\\\ \\vdots \\end{pmatrix}  = \\begin{pmatrix} \\frac{1}{2} & \\frac{1}{2} & 0 & 0 & 0 & 0 & 0 & 0 \\\\ \\frac{1}{2} & \\frac{1}{2} & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & \\frac{1}{2} & \\frac{1}{2} & 0 & 0 & 0 & 0 \\\\ 0 & 0 & \\frac{1}{2} & \\frac{1}{2} & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & \\frac{1}{2} & \\frac{1}{2} & 0 & 0 \\\\ 0 & 0 & 0 & 0 & \\frac{1}{2} & \\frac{1}{2} & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & \\frac{1}{2} & \\frac{1}{2} \\\\ 0 & 0 & 0 & 0 & 0 & 0 & \\frac{1}{2} & \\frac{1}{2} \\end{pmatrix}$$\n\nFinally, we verify analytically that $P$ is idempotent, i.e., $P^2 = P$.\nWe can do this using the expression $P=QR = Q(\\frac{1}{2}Q^T)=\\frac{1}{2}QQ^T$.\n$$P^2 = \\left(\\frac{1}{2}QQ^T\\right) \\left(\\frac{1}{2}QQ^T\\right) = \\frac{1}{4} Q (Q^T Q) Q^T$$\nLet's compute the product $Q^T Q$:\n$$Q^T Q = \\begin{pmatrix} 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 1 & 1 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 1 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 \\end{pmatrix} \\begin{pmatrix} 1 & 0 & 0 & 0 \\\\ 1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 1 \\\\ 0 & 0 & 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 2 & 0 & 0 & 0 \\\\ 0 & 2 & 0 & 0 \\\\ 0 & 0 & 2 & 0 \\\\ 0 & 0 & 0 & 2 \\end{pmatrix} = 2I_{4}$$\nwhere $I_4$ is the $4 \\times 4$ identity matrix.\nSubstituting this result into the expression for $P^2$:\n$$P^2 = \\frac{1}{4} Q (2I_4) Q^T = \\frac{2}{4} Q I_4 Q^T = \\frac{1}{2} QQ^T = P$$\nThe condition $P^2=P$ is satisfied. This also confirms the general formula for an orthogonal projector onto the column space of a matrix $A$ whose columns are not necessarily orthonormal: $P = A(A^T A)^{-1} A^T$. With $A=Q$, we have $(Q^T Q)^{-1} = (2I_4)^{-1}=\\frac{1}{2}I_4$, so $P=Q(\\frac{1}{2}I_4)Q^T = \\frac{1}{2}QQ^T$. Our derivation from first principles is consistent with this standard formula.\nThe explicit matrix $P$ is given above.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{1}{2} & \\frac{1}{2} & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n\\frac{1}{2} & \\frac{1}{2} & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & \\frac{1}{2} & \\frac{1}{2} & 0 & 0 & 0 & 0 \\\\\n0 & 0 & \\frac{1}{2} & \\frac{1}{2} & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & \\frac{1}{2} & \\frac{1}{2} & 0 & 0 \\\\\n0 & 0 & 0 & 0 & \\frac{1}{2} & \\frac{1}{2} & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & \\frac{1}{2} & \\frac{1}{2} \\\\\n0 & 0 & 0 & 0 & 0 & 0 & \\frac{1}{2} & \\frac{1}{2}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Once we have defined the restriction ($R$) and prolongation ($P$) operators, a crucial question arises: how do we coarse-grain the governing equations themselves? This practice  introduces the powerful Galerkin principle, which provides a systematic recipe for constructing a coarse-grid operator via the \"sandwich\" formula $A_c = R A_f P$. By applying this to the fundamental second-difference operator, you will discover a remarkable and important result about how this method preserves the essential structure of the original operator, a key reason for the success of multigrid methods.",
            "id": "3777667",
            "problem": "Consider the one-dimensional Poisson equation $-u^{\\prime\\prime}(x)=f(x)$ on a uniform grid. Let the fine grid have spacing $h$ and grid points indexed by $i \\in \\mathbb{Z}$, and let the coarse grid have spacing $H=2h$ and grid points indexed by $J \\in \\mathbb{Z}$. The fine-grid discrete operator $A_f$ is the standard three-point second-difference operator defined by\n$$\n(A_f u)_i \\;=\\; \\frac{1}{h^2}\\left(-u_{i-1}+2u_i-u_{i+1}\\right).\n$$\nDefine the prolongation (fine-grid injection by linear interpolation) operator $P:\\mathbb{R}^{N_c}\\to\\mathbb{R}^{N_f}$ from the coarse grid to the fine grid by\n$$\n(P V)_{2J} \\;=\\; V_J,\\qquad (P V)_{2J+1} \\;=\\; \\frac{1}{2}\\left(V_J+V_{J+1}\\right),\n$$\nand define the full-weighting restriction operator $R:\\mathbb{R}^{N_f}\\to\\mathbb{R}^{N_c}$ from the fine grid to the coarse grid by\n$$\n(R y)_J \\;=\\; \\frac{1}{4}y_{2J-1}+\\frac{1}{2}y_{2J}+\\frac{1}{4}y_{2J+1}.\n$$\nUsing only these definitions and the uniform-grid structure, derive from first principles the Galerkin coarse operator $A_c = R\\,A_f\\,P$. Then, determine the interior three-point stencil of $A_c$ expressed in terms of the coarse-grid spacing $H$.\n\nYour final answer must be the three stencil coefficients written as a single row vector expression in terms of $H$ (no units). Do not provide intermediate steps in the final answer. No rounding is required.",
            "solution": "The problem is well-posed and scientifically grounded in the field of numerical analysis, specifically multigrid methods. All definitions and conditions are provided, allowing for a direct derivation. The problem is therefore valid.\n\nThe objective is to derive the Galerkin coarse-grid operator $A_c = R A_f P$ and determine its interior stencil. We will compute the action of $A_c$ on an arbitrary coarse-grid vector $V$. The result, $(A_c V)_J$, will be a linear combination of coarse-grid values $V_{J-1}$, $V_J$, and $V_{J+1}$. The coefficients of this combination constitute the stencil. The derivation proceeds by applying the operators $P$, $A_f$, and $R$ in sequence.\n\nLet $V$ be a vector defined on the coarse grid with grid points indexed by $J \\in \\mathbb{Z}$.\n\nStep 1: Apply the prolongation operator $P$.\nThe operator $P$ maps the coarse-grid vector $V$ to a fine-grid vector $u = P V$. The components of $u$ are given by the definition of linear interpolation:\n$$\nu_{2J} = (P V)_{2J} = V_J\n$$\n$$\nu_{2J+1} = (P V)_{2J+1} = \\frac{1}{2}(V_J + V_{J+1})\n$$\n\nStep 2: Apply the fine-grid operator $A_f$.\nThe operator $A_f$ is applied to the fine-grid vector $u$. Let the result be $w = A_f u$. The components of $w$ are given by:\n$$\nw_i = (A_f u)_i = \\frac{1}{h^2}(-u_{i-1} + 2u_i - u_{i+1})\n$$\n\nStep 3: Apply the restriction operator $R$.\nThe operator $R$ maps the fine-grid vector $w$ to the coarse-grid vector $A_c V$. The $J$-th component is given by the definition of full-weighting restriction:\n$$\n(A_c V)_J = (R w)_J = \\frac{1}{4}w_{2J-1} + \\frac{1}{2}w_{2J} + \\frac{1}{4}w_{2J+1}\n$$\nTo evaluate this expression, we need to compute the components $w_{2J-1}$, $w_{2J}$, and $w_{2J+1}$.\n\nFirst, we express the required fine-grid values of $u$ in terms of the coarse-grid values of $V$. The indices around the coarse-grid point $J$ correspond to fine-grid indices $2J-1$, $2J$, and $2J+1$. We will also need neighboring points.\nFor the fine-grid point $i=2J-1$:\n$u_{2J-2} = (PV)_{2(J-1)} = V_{J-1}$\n$u_{2J-1} = (PV)_{2(J-1)+1} = \\frac{1}{2}(V_{J-1} + V_J)$\n$u_{2J} = (PV)_{2J} = V_J$\n\nFor the fine-grid point $i=2J$:\n$u_{2J-1} = \\frac{1}{2}(V_{J-1} + V_J)$\n$u_{2J} = V_J$\n$u_{2J+1} = \\frac{1}{2}(V_J + V_{J+1})$\n\nFor the fine-grid point $i=2J+1$:\n$u_{2J} = V_J$\n$u_{2J+1} = \\frac{1}{2}(V_J + V_{J+1})$\n$u_{2J+2} = (PV)_{2(J+1)} = V_{J+1}$\n\nNow we can compute the required components of $w = A_f u$:\nFor $i = 2J-1$:\n$$\nw_{2J-1} = \\frac{1}{h^2}(-u_{2J-2} + 2u_{2J-1} - u_{2J}) = \\frac{1}{h^2}\\left(-V_{J-1} + 2\\left(\\frac{1}{2}(V_{J-1} + V_J)\\right) - V_J\\right)\n$$\n$$\nw_{2J-1} = \\frac{1}{h^2}(-V_{J-1} + V_{J-1} + V_J - V_J) = 0\n$$\n\nFor $i = 2J$:\n$$\nw_{2J} = \\frac{1}{h^2}(-u_{2J-1} + 2u_{2J} - u_{2J+1}) = \\frac{1}{h^2}\\left(-\\frac{1}{2}(V_{J-1} + V_J) + 2V_J - \\frac{1}{2}(V_J + V_{J+1})\\right)\n$$\n$$\nw_{2J} = \\frac{1}{h^2}\\left(-\\frac{1}{2}V_{J-1} + \\left(-\\frac{1}{2} + 2 - \\frac{1}{2}\\right)V_J - \\frac{1}{2}V_{J+1}\\right) = \\frac{1}{h^2}\\left(-\\frac{1}{2}V_{J-1} + 1V_J - \\frac{1}{2}V_{J+1}\\right)\n$$\n\nFor $i = 2J+1$:\n$$\nw_{2J+1} = \\frac{1}{h^2}(-u_{2J} + 2u_{2J+1} - u_{2J+2}) = \\frac{1}{h^2}\\left(-V_J + 2\\left(\\frac{1}{2}(V_J + V_{J+1})\\right) - V_{J+1}\\right)\n$$\n$$\nw_{2J+1} = \\frac{1}{h^2}(-V_J + V_J + V_{J+1} - V_{J+1}) = 0\n$$\n\nFinally, substitute these components of $w$ back into the expression for $(A_c V)_J$:\n$$\n(A_c V)_J = \\frac{1}{4}(0) + \\frac{1}{2}w_{2J} + \\frac{1}{4}(0) = \\frac{1}{2}w_{2J}\n$$\n$$\n(A_c V)_J = \\frac{1}{2} \\left[ \\frac{1}{h^2}\\left(-\\frac{1}{2}V_{J-1} + V_J - \\frac{1}{2}V_{J+1}\\right) \\right]\n$$\n$$\n(A_c V)_J = \\frac{1}{4h^2}(-V_{J-1} + 2V_J - V_{J+1})\n$$\nThe problem specifies the coarse-grid spacing is $H=2h$, which implies $h=H/2$ and $h^2=H^2/4$. Substituting this into the expression for $A_c$:\n$$\n(A_c V)_J = \\frac{1}{4(H^2/4)}(-V_{J-1} + 2V_J - V_{J+1}) = \\frac{1}{H^2}(-V_{J-1} + 2V_J - V_{J+1})\n$$\nThis expression defines the action of the coarse-grid operator $A_c$. The interior three-point stencil is composed of the coefficients of $V_{J-1}$, $V_J$, and $V_{J+1}$. These coefficients are, respectively:\n$$\n\\text{coeff}(V_{J-1}) = -\\frac{1}{H^2}\n$$\n$$\n\\text{coeff}(V_{J}) = \\frac{2}{H^2}\n$$\n$$\n\\text{coeff}(V_{J+1}) = -\\frac{1}{H^2}\n$$\nThe stencil is thus $\\frac{1}{H^2}(-1, 2, -1)$. The problem asks for the three stencil coefficients as a single row vector.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} -\\frac{1}{H^2} & \\frac{2}{H^2} & -\\frac{1}{H^2} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "The principles of coarse-graining extend beyond spatial discretizations to the reduction of complex dynamical systems. This exercise  demonstrates how to construct a \"closed\" coarse-grained model for a linear system of ordinary differential equations, ensuring the evolution of the coarse variable depends only on itself. You will see how the choice of restriction ($R$) and lifting ($L$) operators determines which aspects of the fine-scale dynamics are preserved, and how a clever choice can allow the coarse model to perfectly capture a critical feature, such as an unstable mode.",
            "id": "3777664",
            "problem": "Consider a fine-grain linear ordinary differential equation (ODE) defined on the Euclidean space $\\mathbb{R}^{2}$ by the evolution law $\\dot{x}=A_{f} x$, where $x \\in \\mathbb{R}^{2}$ and $A_{f} \\in \\mathbb{R}^{2 \\times 2}$. A coarse-grain model is to be constructed for a scalar coarse variable $y \\in \\mathbb{R}$ using a restriction operator $R \\in \\mathbb{R}^{1 \\times 2}$ and a lifting operator $L \\in \\mathbb{R}^{2 \\times 1}$, with the requirement that the coarse dynamics be closed and consistent with the fine dynamics under lift-and-restrict in the following sense: if the fine state is lifted from the coarse state by $x=L y$, then the restricted fine time derivative must agree with the coarse time derivative computed from the coarse model.\n\nStarting from the definitions of restriction, lifting, linearity of the fine dynamics, and the compatibility condition for constructing closed coarse dynamics, derive from first principles a closed-form expression for the coarse evolution operator $A_{c} \\in \\mathbb{R}$ governing the scalar ODE $\\dot{y}=A_{c} y$. Then, for the specific data\n$$\nA_{f}=\\begin{pmatrix}2&1\\\\0&-1\\end{pmatrix}, \\quad R=\\begin{pmatrix}1&0\\end{pmatrix}, \\quad L=\\begin{pmatrix}1\\\\0\\end{pmatrix},\n$$\ncompute the resulting coarse evolution operator $A_{c}$ and briefly interpret the qualitative behavior of the corresponding coarse dynamics relative to the fine-grain dynamics.\n\nYour final answer must be a single real number, and no rounding is required. No units are to be included in the final answer. Define any acronyms you use on first appearance (for example, ordinary differential equation (ODE)).",
            "solution": "The problem is validated as scientifically grounded, well-posed, objective, and self-contained. It is a standard exercise in model reduction for linear systems.\n\nThe fine-grain dynamics are described by a linear ordinary differential equation (ODE) in $\\mathbb{R}^{2}$:\n$$\n\\dot{x} = A_{f} x\n$$\nwhere $x \\in \\mathbb{R}^{2}$ is the fine-grain state vector and $A_{f} \\in \\mathbb{R}^{2 \\times 2}$ is the fine-grain evolution operator.\n\nThe coarse-grain dynamics are described by a scalar linear ODE:\n$$\n\\dot{y} = A_{c} y\n$$\nwhere $y \\in \\mathbb{R}$ is the coarse-grain scalar variable and $A_{c} \\in \\mathbb{R}$ is the coarse-grain evolution operator to be determined.\n\nThe connection between the fine and coarse models is established by a restriction operator $R \\in \\mathbb{R}^{1 \\times 2}$, which maps a fine state to a coarse state ($y = Rx$), and a lifting operator $L \\in \\mathbb{R}^{2 \\times 1}$, which reconstructs a fine state from a coarse state ($x = Ly$).\n\nThe core requirement is that the coarse dynamics must be closed and consistent with the fine dynamics. This is formalized by the compatibility condition: if a fine state is generated by lifting a coarse state, $x = Ly$, then the time evolution of the coarse state must be consistent. The time derivative of the coarse state is obtained by restricting the time derivative of the fine state.\n\nLet us begin the derivation from first principles. The coarse variable is defined as $y = Rx$. Its time derivative is found by applying the chain rule:\n$$\n\\dot{y} = \\frac{d}{dt}(Rx) = R \\dot{x}\n$$\nWe substitute the fine-grain evolution law, $\\dot{x} = A_{f} x$, into this expression:\n$$\n\\dot{y} = R (A_{f} x)\n$$\nThis equation relates the time evolution of the coarse variable $\\dot{y}$ to the full fine-grain state $x$. For the coarse dynamics to be \"closed,\" the evolution of $y$ must depend only on $y$ itself, not on other details of $x$. The problem specifies that this closure is achieved by assuming the fine state lies in the subspace spanned by the lifting operator, i.e., $x = Ly$. This assumes that the dynamics of interest are those that can be represented by the coarse variable.\n\nSubstituting $x = Ly$ into the expression for $\\dot{y}$:\n$$\n\\dot{y} = R A_{f} (Ly)\n$$\nSince $R$, $A_{f}$, and $L$ are matrices (or vectors) of constants, and $y$ is a scalar, we can re-group the terms:\n$$\n\\dot{y} = (R A_{f} L) y\n$$\nThis equation now has the form of a closed, linear ODE for $y$. Comparing this derived expression with the postulated coarse-grain model, $\\dot{y} = A_{c} y$, we can identify the coarse evolution operator by direct equivalence:\n$$\nA_{c} = R A_{f} L\n$$\nThis is the general closed-form expression for the coarse evolution operator under the given assumptions. The product of matrices $R$ ($1 \\times 2$), $A_{f}$ ($2 \\times 2$), and $L$ ($2 \\times 1$) results in a $1 \\times 1$ matrix, which is a scalar, as required for $A_{c}$.\n\nNow, we compute $A_{c}$ for the specific data provided:\n$$\nA_{f}=\\begin{pmatrix}2&1\\\\0&-1\\end{pmatrix}, \\quad R=\\begin{pmatrix}1&0\\end{pmatrix}, \\quad L=\\begin{pmatrix}1\\\\0\\end{pmatrix}\n$$\nWe calculate the product $A_{c} = R A_{f} L$. It is computationally efficient to first calculate the product $A_f L$:\n$$\nA_{f}L = \\begin{pmatrix}2&1\\\\0&-1\\end{pmatrix} \\begin{pmatrix}1\\\\0\\end{pmatrix} = \\begin{pmatrix}(2)(1) + (1)(0)\\\\(0)(1) + (-1)(0)\\end{pmatrix} = \\begin{pmatrix}2\\\\0\\end{pmatrix}\n$$\nNext, we pre-multiply this result by $R$:\n$$\nA_{c} = R (A_{f}L) = \\begin{pmatrix}1&0\\end{pmatrix} \\begin{pmatrix}2\\\\0\\end{pmatrix} = (1)(2) + (0)(0) = 2\n$$\nThus, the coarse evolution operator is $A_{c} = 2$.\n\nFor the qualitative interpretation, we analyze the dynamics of both systems.\nThe fine-grain dynamics are governed by $\\dot{x} = A_{f} x$. The stability and behavior of this system are determined by the eigenvalues of $A_{f}$. Since $A_{f}$ is an upper triangular matrix, its eigenvalues are its diagonal entries: $\\lambda_1 = 2$ and $\\lambda_2 = -1$.\nThe eigenvalue $\\lambda_1 = 2$ is positive, corresponding to an unstable mode that grows exponentially as $\\exp(2t)$. The corresponding eigenvector $v_1$ is found by solving $(A_f - 2I)v_1 = 0$:\n$$\n\\begin{pmatrix}0&1\\\\0&-3\\end{pmatrix} \\begin{pmatrix}v_{11}\\\\v_{12}\\end{pmatrix} = \\begin{pmatrix}0\\\\0\\end{pmatrix} \\implies v_{12}=0\n$$\nAn eigenvector is $v_1 = \\begin{pmatrix}1\\\\0\\end{pmatrix}$.\nThe eigenvalue $\\lambda_2 = -1$ is negative, corresponding to a stable mode that decays exponentially as $\\exp(-t)$.\n\nThe coarse-grain dynamics are given by $\\dot{y} = A_{c} y$, which is $\\dot{y} = 2y$. The solution is $y(t) = y(0)\\exp(2t)$. This is a purely unstable system, with its single mode growing exponentially, governed by the rate $A_{c}=2$.\n\nThe interpretation becomes clear upon observing that the lifting operator $L = \\begin{pmatrix}1\\\\0\\end{pmatrix}$ is precisely the eigenvector $v_1$ of $A_f$ associated with the unstable eigenvalue $\\lambda_1 = 2$. The restriction operator $R = \\begin{pmatrix}1&0\\end{pmatrix}$ projects the fine-grain state $x = \\begin{pmatrix}x_1 \\\\ x_2\\end{pmatrix}$ onto its first component, $y=x_1$. The condition for closure, $x=Ly$, means we are constraining the fine-grain state to lie in the one-dimensional subspace spanned by the unstable eigenvector. The coarse-graining procedure has therefore perfectly isolated the dynamics of the unstable manifold of the fine-grain system. The coarse evolution operator $A_c = 2$ is exactly the unstable eigenvalue of $A_f$. In this specific case, the coarse model is not an approximation but an exact representation of the fine-grain dynamics projected onto its dominant, unstable subspace.",
            "answer": "$$\n\\boxed{2}\n$$"
        }
    ]
}