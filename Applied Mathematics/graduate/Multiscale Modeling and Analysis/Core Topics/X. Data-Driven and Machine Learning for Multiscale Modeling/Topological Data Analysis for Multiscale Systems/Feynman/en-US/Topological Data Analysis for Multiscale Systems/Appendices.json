{
    "hands_on_practices": [
        {
            "introduction": "The foundation of topological data analysis rests on the principles of algebraic topology. This first practice grounds these abstract concepts by challenging you to build a simplicial complex from a point cloud at a fixed scale and compute its homology groups from first principles. By manually constructing the chain groups and boundary matrices, you will gain a tactile understanding of how topological features like connected components ($H_0$) and loops ($H_1$) are algebraically encoded .",
            "id": "3825403",
            "problem": "Consider a point cloud consisting of two spatially separated clusters intended to model a multiscale phenomenon captured by Topological Data Analysis (TDA). Let the first cluster be the set of four points $a_1=(0,0)$, $a_2=(0,1)$, $a_3=(1,1)$, and $a_4=(1,0)$, and let the second cluster be the set of three points $b_1=(10,10)$, $b_2=(10.9,10)$, and $b_3=(10.45,10.779422863)$ arranged as an equilateral triangle of side length $0.9$. Consider the Vietoris–Rips (VR) complex at scale parameter $\\varepsilon=1.1$, constructed over this point cloud with coefficients in the two-element field $\\mathbb{Z}_2$.\n\nStarting from first principles—the definition of the VR complex at a fixed scale parameter $\\varepsilon$, the chain groups $C_k$ over $\\mathbb{Z}_2$ spanned by $k$-simplices of the VR complex, and the boundary operators $\\partial_k:C_k\\to C_{k-1}$ defined by the simplicial boundary—explicitly build the $0$-chains, $1$-chains, and $2$-chains of the VR complex at the given $\\varepsilon$, and construct the boundary matrices for $\\partial_1$ and $\\partial_2$. Using these explicit constructions, compute the $0$-dimensional and $1$-dimensional homology groups $H_0$ and $H_1$ over $\\mathbb{Z}_2$ by evaluating $\\ker(\\partial_k)$ and $\\operatorname{Im}(\\partial_{k+1})$ and hence the Betti numbers $\\beta_0=\\dim H_0$ and $\\beta_1=\\dim H_1$.\n\nExpress your final answer as the row matrix $\\begin{pmatrix}\\beta_0  \\beta_1\\end{pmatrix}$. No rounding is required; provide exact integers.",
            "solution": "The problem requires the computation of the $0$-th and $1$-st Betti numbers, $\\beta_0$ and $\\beta_1$, for a Vietoris–Rips (VR) complex constructed on a given point cloud. The homology is to be computed with coefficients in the field $\\mathbb{Z}_2$.\n\nFirst, we validate the problem statement.\nThe set of points is $P = \\{a_1, a_2, a_3, a_4, b_1, b_2, b_3\\}$, where $a_1=(0,0)$, $a_2=(0,1)$, $a_3=(1,1)$, $a_4=(1,0)$, and $b_1=(10,10)$, $b_2=(10.9,10)$, $b_3=(10.45,10.779422863)$. The scale parameter is $\\varepsilon=1.1$. The coefficients for homology are in $\\mathbb{Z}_2$.\nThe distances between points in the second cluster are $d(b_1, b_2) = \\sqrt{(10.9-10)^2 + (10-10)^2} = 0.9$, $d(b_1, b_3) = \\sqrt{(10.45-10)^2 + (10.779422863-10)^2} = \\sqrt{0.45^2 + 0.779422863^2} = \\sqrt{0.2025 + 0.6075000...} = \\sqrt{0.81} = 0.9$, and $d(b_2, b_3) = \\sqrt{(10.45-10.9)^2 + (10.779422863-10)^2} = \\sqrt{(-0.45)^2 + 0.779422863^2} = 0.9$. The points in cluster B form an equilateral triangle of side length $0.9$ as stated. The problem is well-defined and scientifically sound.\n\nThe Vietoris–Rips complex $VR(P, \\varepsilon)$ on a point cloud $P$ at scale $\\varepsilon$ is a simplicial complex whose vertices are the points in $P$, and a set of vertices $\\{v_0, v_1, \\dots, v_k\\} \\subseteq P$ forms a $k$-simplex if and only if the Euclidean distance $d(v_i, v_j) \\le \\varepsilon$ for all $0 \\le i, j \\le k$.\n\nWe identify the simplices of the complex at $\\varepsilon=1.1$.\nThe set of $0$-simplices ($vertices$) is the set of all $7$ points $P = \\{[a_1], [a_2], [a_3], [a_4], [b_1], [b_2], [b_3]\\}$.\n\nFor the $1$-simplices ($edges$), we calculate pairwise distances:\nWithin the first cluster (A):\n$d(a_1, a_2)=1 \\le 1.1$\n$d(a_2, a_3)=1 \\le 1.1$\n$d(a_3, a_4)=1 \\le 1.1$\n$d(a_4, a_1)=1 \\le 1.1$\n$d(a_1, a_3) = \\sqrt{2} \\approx 1.414  1.1$\n$d(a_2, a_4) = \\sqrt{2} \\approx 1.414  1.1$\nSo, the edges in cluster A are $[a_1, a_2]$, $[a_2, a_3]$, $[a_3, a_4]$, and $[a_4, a_1]$. These form a $4$-cycle.\n\nWithin the second cluster (B):\nThe side lengths are given as $0.9$, which is less than $\\varepsilon=1.1$.\nSo, the edges $[b_1, b_2]$, $[b_1, b_3]$, and $[b_2, b_3]$ all exist.\n\nBetween clusters A and B:\nThe minimum distance is $d(a_3, b_1) = d((1,1), (10,10)) = \\sqrt{(10-1)^2+(10-1)^2} = \\sqrt{81+81} = 9\\sqrt{2} \\approx 12.7$, which is much greater than $\\varepsilon=1.1$. Thus, no edges connect the two clusters.\n\nThe VR complex is a disjoint union of two subcomplexes: $K = K_A \\cup K_B$.\n$K_A$ has vertices $\\{a_1, a_2, a_3, a_4\\}$ and edges $\\{[a_1,a_2], [a_2,a_3], [a_3,a_4], [a_4,a_1]\\}$.\n$K_B$ has vertices $\\{b_1, b_2, b_3\\}$ and edges $\\{[b_1,b_2], [b_1,b_3], [b_2,b_3]\\}$.\n\nFor the $2$-simplices ($triangles$), we check for complete subgraphs on $3$ vertices.\nIn $K_A$, there are no sets of $3$ vertices that are all mutually connected. For example, in $\\{a_1, a_2, a_3\\}$, the edge $[a_1, a_3]$ is missing. So, there are no $2$-simplices in $K_A$.\nIn $K_B$, the vertices $\\{b_1, b_2, b_3\\}$ are all mutually connected. Therefore, the $2$-simplex $[b_1, b_2, b_3]$ exists. This means $K_B$ is a filled triangle (a standard $2$-simplex).\n\nNo higher-dimensional simplices can exist.\n\nThe chain groups $C_k(K; \\mathbb{Z}_2)$ are vector spaces over $\\mathbb{Z}_2$ spanned by the $k$-simplices.\n$C_0$: $\\dim C_0 = 7$. Basis: $\\{[a_1], [a_2], [a_3], [a_4], [b_1], [b_2], [b_3]\\}$\n$C_1$: $\\dim C_1 = 7$. Basis: $\\{[a_1,a_2], [a_2,a_3], [a_3,a_4], [a_4,a_1], [b_1,b_2], [b_1,b_3], [b_2,b_3]\\}$\n$C_2$: $\\dim C_2 = 1$. Basis: $\\{[b_1,b_2,b_3]\\}$\n$C_k = \\{0\\}$ for $k \\ge 3$.\n\nThe chain complex is $0 \\xrightarrow{\\partial_3} C_2 \\xrightarrow{\\partial_2} C_1 \\xrightarrow{\\partial_1} C_0 \\xrightarrow{\\partial_0} 0$.\nThe boundary operator $\\partial_k: C_k \\to C_{k-1}$ is defined on a simplex $[v_0, \\dots, v_k]$ as $\\partial_k[v_0, \\dots, v_k] = \\sum_{i=0}^k [v_0, \\dots, \\hat{v}_i, \\dots, v_k]$ (since we are in $\\mathbb{Z}_2$, signs are ignored).\n\nThe Betti numbers are the dimensions of the homology groups: $\\beta_k = \\dim H_k = \\dim(\\ker \\partial_k / \\operatorname{Im} \\partial_{k+1})$.\nSince $K=K_A \\cup K_B$ is a disjoint union, $H_k(K) \\cong H_k(K_A) \\oplus H_k(K_B)$, and $\\beta_k(K) = \\beta_k(K_A) + \\beta_k(K_B)$.\n\nCalculation for $K_A$:\n$K_A$ is a cycle graph on $4$ vertices.\nChain groups for $K_A$: $\\dim C_{0,A} = 4$, $\\dim C_{1,A} = 4$, $C_{k,A}=\\{0\\}$ for $k\\ge2$.\nThe boundary map $\\partial_{1,A}: C_{1,A} \\to C_{0,A}$ is represented by a $4 \\times 4$ matrix. Let the basis for $C_{0,A}$ be $([a_1], [a_2], [a_3], [a_4])$ and for $C_{1,A}$ be $([a_1,a_2], [a_2,a_3], [a_3,a_4], [a_4,a_1])$.\n$\\partial_1([a_1,a_2])=[a_1]+[a_2]$, $\\partial_1([a_2,a_3])=[a_2]+[a_3]$, $\\partial_1([a_3,a_4])=[a_3]+[a_4]$, $\\partial_1([a_4,a_1])=[a_4]+[a_1]$.\n$$ \\partial_{1,A} = \\begin{pmatrix} 1  0  0  1 \\\\ 1  1  0  0 \\\\ 0  1  1  0 \\\\ 0  0  1  1 \\end{pmatrix} $$\nTo find $\\beta_0(K_A)$, we compute the rank of $\\partial_{1,A}$. By row reduction over $\\mathbb{Z}_2$:\n$ \\begin{pmatrix} 1  0  0  1 \\\\ 1  1  0  0 \\\\ 0  1  1  0 \\\\ 0  0  1  1 \\end{pmatrix} \\xrightarrow{R_2 \\to R_2+R_1} \\begin{pmatrix} 1  0  0  1 \\\\ 0  1  0  1 \\\\ 0  1  1  0 \\\\ 0  0  1  1 \\end{pmatrix} \\xrightarrow{R_3 \\to R_3+R_2} \\begin{pmatrix} 1  0  0  1 \\\\ 0  1  0  1 \\\\ 0  0  1  1 \\\\ 0  0  1  1 \\end{pmatrix} \\xrightarrow{R_4 \\to R_4+R_3} \\begin{pmatrix} 1  0  0  1 \\\\ 0  1  0  1 \\\\ 0  0  1  1 \\\\ 0  0  0  0 \\end{pmatrix} $\nThe rank is $3$. $\\dim(\\operatorname{Im} \\partial_{1,A}) = 3$.\n$\\beta_0(K_A) = \\dim C_{0,A} - \\dim(\\operatorname{Im} \\partial_{1,A}) = 4 - 3 = 1$. This signifies one connected component.\nTo find $\\beta_1(K_A)$, we need $\\dim(\\ker \\partial_{1,A})$ and $\\dim(\\operatorname{Im} \\partial_{2,A})$.\nSince $C_{2,A}=\\{0\\}$, $\\partial_{2,A}=0$ and $\\operatorname{Im} \\partial_{2,A} = \\{0\\}$.\n$\\beta_1(K_A) = \\dim(\\ker \\partial_{1,A}) - 0$.\nBy the rank-nullity theorem, $\\dim C_{1,A} = \\dim(\\operatorname{Im} \\partial_{1,A}) + \\dim(\\ker \\partial_{1,A})$.\n$4 = 3 + \\dim(\\ker \\partial_{1,A})$, so $\\dim(\\ker \\partial_{1,A}) = 1$.\nThus, $\\beta_1(K_A) = 1$. This corresponds to the hole formed by the $4$-cycle.\n\nCalculation for $K_B$:\n$K_B$ is a filled triangle (a $2$-simplex).\nChain groups for $K_B$: $\\dim C_{0,B}=3$, $\\dim C_{1,B}=3$, $\\dim C_{2,B}=1$.\nThe boundary map $\\partial_{1,B}: C_{1,B} \\to C_{0,B}$. Let basis for $C_{0,B}$ be $([b_1], [b_2], [b_3])$ and for $C_{1,B}$ be $([b_1,b_2], [b_1,b_3], [b_2,b_3])$.\n$$ \\partial_{1,B} = \\begin{pmatrix} 1  1  0 \\\\ 1  0  1 \\\\ 0  1  1 \\end{pmatrix} $$\nRow reducing over $\\mathbb{Z}_2$:\n$ \\begin{pmatrix} 1  1  0 \\\\ 1  0  1 \\\\ 0  1  1 \\end{pmatrix} \\xrightarrow{R_2 \\to R_2+R_1} \\begin{pmatrix} 1  1  0 \\\\ 0  1  1 \\\\ 0  1  1 \\end{pmatrix} \\xrightarrow{R_3 \\to R_3+R_2} \\begin{pmatrix} 1  1  0 \\\\ 0  1  1 \\\\ 0  0  0 \\end{pmatrix} $\nThe rank is $2$. $\\dim(\\operatorname{Im} \\partial_{1,B}) = 2$.\n$\\beta_0(K_B) = \\dim C_{0,B} - \\dim(\\operatorname{Im} \\partial_{1,B}) = 3 - 2 = 1$. This signifies one connected component.\nTo find $\\beta_1(K_B)$, we need $\\dim(\\ker \\partial_{1,B})$ and $\\dim(\\operatorname{Im} \\partial_{2,B})$.\nFrom rank-nullity on $\\partial_{1,B}$: $\\dim C_{1,B} = \\dim(\\operatorname{Im} \\partial_{1,B}) + \\dim(\\ker \\partial_{1,B})$.\n$3 = 2 + \\dim(\\ker \\partial_{1,B})$, so $\\dim(\\ker \\partial_{1,B}) = 1$. The kernel is generated by the cycle $[b_1,b_2]+[b_2,b_3]+[b_1,b_3]$ (sum of edges of the triangle).\nNow we consider $\\partial_{2,B}: C_{2,B} \\to C_{1,B}$. The basis for $C_{2,B}$ is $\\{[b_1,b_2,b_3]\\}$.\n$\\partial_2([b_1,b_2,b_3]) = [b_2,b_3] + [b_1,b_3] + [b_1,b_2]$.\nIn the basis of $C_{1,B}$, this vector is $(1,1,1)^T$.\nThe image $\\operatorname{Im} \\partial_{2,B}$ is the span of this non-zero vector, so $\\dim(\\operatorname{Im} \\partial_{2,B}) = 1$.\n$\\beta_1(K_B) = \\dim(\\ker \\partial_{1,B}) - \\dim(\\operatorname{Im} \\partial_{2,B}) = 1 - 1 = 0$. This is expected as the triangle is filled, closing the hole.\n\nTotal Betti numbers:\n$\\beta_0 = \\beta_0(K_A) + \\beta_0(K_B) = 1 + 1 = 2$.\nThis corresponds to the two spatially separated, unconnected clusters.\n$\\beta_1 = \\beta_1(K_A) + \\beta_1(K_B) = 1 + 0 = 1$.\nThis corresponds to the single $1$-dimensional hole in the square-shaped cluster $K_A$.\n\nThe final answer is the row matrix of these Betti numbers.",
            "answer": "$$\\boxed{\\begin{pmatrix}2  1\\end{pmatrix}}$$"
        },
        {
            "introduction": "The true power of TDA lies in its ability to capture features across a continuum of scales, which is achieved by computing *persistent* homology. This exercise transitions from a static complex to a dynamic filtration, requiring you to implement the full computational pipeline that tracks the birth and death of topological features as the scale parameter grows. By coding the algorithm to generate a persistence barcode for a noisy circle, you will bridge the gap between theoretical definitions and practical, data-driven analysis .",
            "id": "3825425",
            "problem": "You are given a finite metric dataset sampled from a noisy circle in the Euclidean plane and asked to compute the persistent barcode for the first homology group $H_1$ using a Vietoris–Rips filtration. The objective is to derive and implement a complete algorithm from first principles by explicitly constructing boundary matrices across scales and performing matrix reduction to track births and deaths of one-dimensional cycles.\n\nFundamental base and definitions:\n- Let $(X,d)$ be a finite metric space, where $X \\subset \\mathbb{R}^2$ is a set of sample points and $d$ is the Euclidean metric $d(\\mathbf{x},\\mathbf{y}) = \\|\\mathbf{x}-\\mathbf{y}\\|_2$.\n- For $\\epsilon \\ge 0$, the Vietoris–Rips complex $\\mathrm{VR}_\\epsilon(X)$ is the abstract simplicial complex whose $p$-simplices are subsets $\\sigma \\subset X$ with $|\\sigma| = p+1$ such that $d(\\mathbf{x},\\mathbf{y}) \\le \\epsilon$ for all $\\mathbf{x},\\mathbf{y} \\in \\sigma$.\n- A filtration is a nested sequence of complexes $(K_t)_{t \\in \\mathbb{R}_{\\ge 0}}$ with $K_s \\subseteq K_t$ for $s \\le t$. For the Vietoris–Rips filtration we assign each simplex $\\sigma$ the filtration value\n$$\nf(\\sigma) = \\max_{\\mathbf{x},\\mathbf{y} \\in \\sigma} d(\\mathbf{x},\\mathbf{y}),\n$$\nwhich ensures that $\\sigma$ enters the complex at the first scale where all its edges are present.\n- Let $C_p(K_t)$ denote the $p$-dimensional chain group with coefficients in the field $\\mathbb{Z}_2$, generated by the $p$-simplices present at scale $t$. The boundary operator $\\partial_p: C_p \\to C_{p-1}$ is defined by\n$$\n\\partial_p\\left([v_0,\\dots,v_p]\\right) = \\sum_{i=0}^{p} [v_0,\\dots,\\hat{v}_i,\\dots,v_p],\n$$\nwhere the hat denotes omission and the sum is taken mod $2$. Homology groups are $H_p = \\ker(\\partial_p) / \\mathrm{im}(\\partial_{p+1})$.\n- Persistent homology pairs simplices across the filtration using a reduction of the boundary matrix. Ordering simplices by nondecreasing filtration values (breaking ties by dimension and lexicographic vertex order) yields a boundary matrix $D$ whose columns are the boundaries of $p$-simplices expressed in the basis of $(p-1)$-simplices. Reduction over $\\mathbb{Z}_2$ produces pivot pairs $(\\sigma,\\tau)$ where $\\sigma$ is a $(p-1)$-simplex and $\\tau$ is a $p$-simplex; this pair represents a homology class in $H_{p-1}$ that is born at $f(\\sigma)$ and dies at $f(\\tau)$. Columns that reduce to the zero vector create homology classes of their own dimension that either persist until they are later killed (by higher-dimensional columns) or persist to the end of the filtration in the absence of a killer.\n\nTask requirements:\n- Construct the Vietoris–Rips filtration on $X$ up to dimension $2$ using the diameter-based filtration value $f(\\sigma)$ as defined above. Implement explicit boundary matrices with coefficients in $\\mathbb{Z}_2$ and perform column-wise matrix reduction to compute persistent pairs. Extract the barcode for $H_1$ (pairs between $1$-simplices and $2$-simplices) as intervals $[b,d] = [f(\\sigma), f(\\tau)]$ for each pair $(\\sigma,\\tau)$ with $\\dim(\\sigma)=1$ and $\\dim(\\tau)=2$.\n- Sampling model: For each test case, construct $X$ by drawing $N$ angles $\\theta_i$ uniformly from $[0,2\\pi]$ and mapping them to the unit circle $(\\cos\\theta_i,\\sin\\theta_i)$, then add independent isotropic Gaussian noise with standard deviation $\\sigma$ to each coordinate. Angles are measured in radians.\n- Filtration construction: Include all simplices of dimension $0$, $1$, and $2$ with their filtration values as given by $f(\\sigma)$. Order the simplices by nondecreasing $f(\\sigma)$; break ties by increasing dimension and then lexicographic vertex order, to ensure faces precede cofaces at equal filtration values.\n- Boundary matrix reduction: Use coefficients in $\\mathbb{Z}_2$, represent columns as sets of row indices, and implement the standard reduction by repeatedly adding columns to eliminate duplicate pivots. Track pivot pairs to determine births and deaths of homology classes. Report only the $H_1$ barcode intervals, i.e., pairs where the pivot is a $1$-simplex and the killing column is a $2$-simplex.\n- For each test case, report the longest $H_1$ interval $[b,d]$ by maximizing the lifetime $d-b$. If no $H_1$ intervals are found, report $[0.0,0.0]$.\n- Rounding: Round $b$ and $d$ to three decimal places.\n\nTest suite:\n- Case A (happy path): $N = 30$, $\\sigma = 0.05$, random seed $0$.\n- Case B (boundary condition, small sample): $N = 18$, $\\sigma = 0.01$, random seed $1$.\n- Case C (edge case, higher noise): $N = 26$, $\\sigma = 0.12$, random seed $2$.\n\nFinal output specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to one test case and is itself a two-element list $[b,d]$ giving the birth and death scales of the longest $H_1$ interval, rounded to three decimal places. For example:\n\"[[b_A,d_A],[b_B,d_B],[b_C,d_C]]\"",
            "solution": "The problem as stated is scientifically grounded, well-posed, and internally consistent. It outlines a standard computational task in topological data analysis: calculating the persistent homology of a point cloud. All definitions, parameters, and objectives are specified with sufficient mathematical and algorithmic precision to permit a unique and verifiable solution. We may therefore proceed with the derivation and implementation.\n\nThe solution is developed from first principles, following a structured pipeline to compute the persistent barcode for the first homology group, $H_1$. This pipeline consists of four main stages: (1) data generation, (2) filtration construction, (3) boundary matrix reduction for persistence calculation, and (4) extraction of the longest-lived $H_1$ feature.\n\n**1. Data Generation**\n\nFor each test case, we generate a dataset $X = \\{\\mathbf{x}_i\\}_{i=0}^{N-1}$ of $N$ points in the Euclidean plane $\\mathbb{R}^2$. The generation process, for a given number of points $N$, noise level $\\sigma$, and random seed, is as follows:\n-   Generate $N$ angles $\\theta_i$ sampled uniformly from the interval $[0, 2\\pi]$.\n-   Map these angles to points on the unit circle: $\\mathbf{p}_i = (\\cos\\theta_i, \\sin\\theta_i)$.\n-   Add independent isotropic Gaussian noise to each point. For each $\\mathbf{p}_i = (p_{ix}, p_{iy})$, the final point is $\\mathbf{x}_i = (p_{ix} + \\delta_{ix}, p_{iy} + \\delta_{iy})$, where $\\delta_{ix}$ and $\\delta_{iy}$ are drawn from a normal distribution with mean $0$ and standard deviation $\\sigma$.\nThe underlying metric space is $(X, d)$, where $d$ is the standard Euclidean L2-norm, $d(\\mathbf{x}_i, \\mathbf{x}_j) = \\|\\mathbf{x}_i - \\mathbf{x}_j\\|_2$.\n\n**2. Vietoris–Rips Filtration Construction**\n\nThe core of persistent homology is to study the evolution of topological features across a nested sequence of simplicial complexes, known as a filtration. We use the Vietoris-Rips (VR) construction.\n\nA $p$-simplex is an unordered set of $p+1$ vertices. We consider simplices of dimension $p=0, 1, 2$:\n-   **$0$-simplices (vertices)**: The $N$ points $\\{\\mathbf{x}_i\\}$ themselves, denoted as $[v_i]$.\n-   **$1$-simplices (edges)**: Any pair of vertices $[v_i, v_j]$.\n-   **$2$-simplices (triangles)**: Any triplet of vertices $[v_i, v_j, v_k]$.\n\nThe filtration value $f(\\sigma)$ of a simplex $\\sigma$ determines when it enters the filtration. As defined, $f(\\sigma)$ is the diameter of the vertex set of $\\sigma$:\n$$\nf(\\sigma) = \\max_{\\mathbf{x}_i, \\mathbf{x}_j \\in \\sigma} d(\\mathbf{x}_i, \\mathbf{x}_j)\n$$\n-   For a vertex $[v_i]$, $f([v_i]) = 0$.\n-   For an edge $[v_i, v_j]$, $f([v_i, v_j]) = d(\\mathbf{x}_i, \\mathbf{x}_j)$.\n-   For a triangle $[v_i, v_j, v_k]$, $f([v_i, v_j, v_k]) = \\max(d(\\mathbf{x}_i, \\mathbf{x}_j), d(\\mathbf{x}_i, \\mathbf{x}_k), d(\\mathbf{x}_j, \\mathbf{x}_k))$.\n\nTo form a valid filtration for the persistence algorithm, all simplices up to dimension $2$ are generated and then sorted into a single ordered list $\\mathcal{F} = (\\tau_0, \\tau_1, \\dots, \\tau_m)$. The sorting follows a strict rule:\n1.  Primary sort key: Non-decreasing filtration value $f(\\tau)$.\n2.  Secondary sort key (tie-breaker): Non-decreasing dimension $\\dim(\\tau)$.\n3.  Tertiary sort key (tie-breaker): Lexicographical order of the vertex indices comprising $\\tau$.\n\nThis ordering is critical as it ensures that any face of a simplex appears earlier in the list than the simplex itself, i.e., $f(\\text{face}) \\le f(\\text{simplex})$. This property guarantees that the boundary matrix of the entire filtration is upper-triangular, a necessary condition for the standard persistence algorithm.\n\n**3. Persistence Algorithm via Boundary Matrix Reduction**\n\nPersistent homology tracks the birth and death of topological features (connected components $H_0$, loops/holes $H_1$, voids $H_2$, etc.) through the filtration. We work with chain groups $C_p$ over the finite field $\\mathbb{Z}_2$, where addition is equivalent to XOR. The boundary operator $\\partial_p: C_p \\to C_{p-1}$ maps a $p$-simplex to the sum of its $(p-1)$-dimensional faces. For instance, $\\partial_2 [v_i, v_j, v_k] = [v_j, v_k] + [v_i, v_k] + [v_i, v_j]$.\n\nThe persistence algorithm reduces the boundary matrix $D$ of the filtration $\\mathcal{F}$. The columns and rows of $D$ correspond to the sorted simplices in $\\mathcal{F}$. The entry $D_{ij}$ is $1$ if simplex $\\tau_i$ is a face of $\\tau_j$ with codimension $1$, and $0$ otherwise. We employ an efficient, column-wise reduction algorithm that avoids constructing the full matrix explicitly.\n\nThe algorithm proceeds as follows:\n-   A map `pivot_to_col` is used to store pairings between a pivot row index and the column index that claims it.\n-   We iterate through each simplex $\\tau_j$ in the sorted list $\\mathcal{F}$, treating it as the $j$-th column of the boundary matrix.\n-   For each $\\tau_j$ (with $p = \\dim(\\tau_j)  0$), we compute its boundary $\\partial \\tau_j$. This is represented as a set of row indices, `col_j`, corresponding to the $(p-1)$-faces of $\\tau_j$.\n-   We find the `pivot` of `col_j`, which is the row with the largest index, i.e., `pivot = max(col_j)`.\n-   **Reduction Step**: We check if `pivot` has already been claimed by a previous column $kj$.\n    -   If `pivot_to_col[pivot]` exists, it means another column $\\tau_k$ has the same pivot. To eliminate this duplicate, we add the (already reduced) column `col_k` to `col_j`. Over $\\mathbb{Z}_2$, this addition is a symmetric difference (XOR) of the sets of row indices. We repeat this process until `col_j` has a unique pivot or becomes empty.\n    -   If `col_j` becomes empty, $\\tau_j$ is a cycle and represents the birth of a new feature in the $p$-th homology group, $H_p$.\n    -   If `col_j` is non-empty and its pivot is unique, we create a new pairing. The simplex $\\tau_{pivot}$ (a generator of an $H_{p-1}$ class) is \"born\" at filtration time $f(\\tau_{pivot})$. The simplex $\\tau_j$ \"kills\" this feature, so the feature \"dies\" at filtration time $f(\\tau_j)$. This forms a persistence pair $(\\tau_{pivot}, \\tau_j)$ and a corresponding lifetime interval $[b, d] = [f(\\tau_{pivot}), f(\\tau_j)]$. We record this pairing by setting `pivot_to_col[pivot] = j`.\n\n**4. Extraction of the $H_1$ Barcode**\n\nWe are tasked with finding the barcode for the first homology group, $H_1$. These features correspond to one-dimensional loops or holes. In the persistence algorithm:\n-   A $1$-cycle is born when a $1$-simplex (edge) closes a loop without forming the boundary of a $2$-simplex (triangle) that is already in the complex. This corresponds to a column for a $1$-simplex that reduces to zero.\n-   An $H_1$ feature dies when the cycle it represents is filled in by a $2$-simplex. This corresponds to a pairing where a $1$-simplex (or a $1$-chain) is the pivot for the boundary of a $2$-simplex.\n\nOur algorithm identifies these death events as pairs $(\\tau_{pivot}, \\tau_j)$ where $\\dim(\\tau_{pivot})=1$ and $\\dim(\\tau_j)=2$. For each such pair, we generate a persistence interval $[b,d] = [f(\\tau_{pivot}), f(\\tau_j)]$.\n\nAfter processing all simplices and collecting all $H_1$ intervals, we find the one with the maximum lifetime, defined as $d-b$. If no such intervals are found (i.e., no $1$-cycles are killed by $2$-simplices in the filtration), the result is $[0.0, 0.0]$. The birth and death times of the longest-lived feature are then rounded to three decimal places as required. The expected result for a noisy circle is one highly persistent $H_1$ feature corresponding to the central hole of the circle.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom itertools import combinations\nfrom math import dist\n\nclass Simplex:\n    \"\"\"A class to represent a simplex in a filtration.\"\"\"\n    def __init__(self, vertices, points):\n        \"\"\"\n        Initializes a Simplex.\n\n        Args:\n            vertices (tuple): A tuple of integer indices for the vertices.\n            points (np.ndarray): The dataset of points.\n        \"\"\"\n        self.vertices = tuple(sorted(vertices))\n        self.dim = len(self.vertices) - 1\n        \n        if self.dim = 0:\n            self.f_val = 0.0\n        else:\n            # The filtration value is the diameter of the simplex.\n            max_dist = 0.0\n            # For a simplex, the diameter is the length of its longest edge.\n            for v1_idx, v2_idx in combinations(self.vertices, 2):\n                d = dist(points[v1_idx], points[v2_idx])\n                if d  max_dist:\n                    max_dist = d\n            self.f_val = max_dist\n\n    def __lt__(self, other):\n        \"\"\"\n        Comparison for sorting simplices by filtration value, then dimension, \n        then lexicographically by vertex indices.\n        \"\"\"\n        return (self.f_val, self.dim, self.vertices)  (other.f_val, other.dim, other.vertices)\n\n    def boundary(self):\n        \"\"\"\n        Computes the boundary of the simplex.\n\n        Returns:\n            list: A list of tuples, where each tuple represents the vertices of a boundary face.\n        \"\"\"\n        if self.dim == 0:\n            return []\n        \n        boundary_faces = []\n        for i in range(len(self.vertices)):\n            # Omitting the i-th vertex gives a (d-1)-face.\n            face_vertices = self.vertices[:i] + self.vertices[i+1:]\n            boundary_faces.append(face_vertices)\n        return boundary_faces\n\ndef compute_longest_h1_barcode(N, sigma, seed):\n    \"\"\"\n    Computes the longest H1 persistence interval for a given dataset configuration.\n    \"\"\"\n    # 1. Generate point data\n    rng = np.random.default_rng(seed)\n    angles = rng.uniform(0, 2 * np.pi, N)\n    points_on_circle = np.array([np.cos(angles), np.sin(angles)]).T\n    noise = rng.normal(0, sigma, size=(N, 2))\n    points = points_on_circle + noise\n\n    # 2. Construct and sort the filtration\n    simplices = []\n    # 0-simplices (vertices)\n    for i in range(N):\n        simplices.append(Simplex((i,), points))\n    # 1-simplices (edges)\n    for i, j in combinations(range(N), 2):\n        simplices.append(Simplex((i, j), points))\n    # 2-simplices (triangles)\n    for i, j, k in combinations(range(N), 3):\n        simplices.append(Simplex((i, j, k), points))\n    \n    simplices.sort()\n    \n    # Create a map for quick index lookup\n    simplex_to_idx = {s.vertices: i for i, s in enumerate(simplices)}\n\n    # 3. Compute persistence pairs via matrix reduction\n    pivot_to_col = {}  # Maps pivot row index to its column index\n    col_data = {}      # Stores the reduced columns\n    h1_intervals = []\n\n    for j, s_j in enumerate(simplices):\n        if s_j.dim == 0:\n            continue\n            \n        boundary_v_tuples = s_j.boundary()\n        col_j = {simplex_to_idx[vt] for vt in boundary_v_tuples if vt in simplex_to_idx}\n\n        # Reduction loop\n        while True:\n            if not col_j:\n                # This column is a cycle, representing the birth of a homology class.\n                # For this problem, we only care about death pairs.\n                break\n\n            pivot = max(col_j)\n            \n            if pivot in pivot_to_col:\n                # Pivot is already taken, add the column that took it to eliminate the pivot.\n                k = pivot_to_col[pivot]\n                col_k = col_data[k]\n                col_j.symmetric_difference_update(col_k)  # Z_2 addition\n            else:\n                # Found a unique pivot. This column kills the class born at `pivot`.\n                pivot_to_col[pivot] = j\n                col_data[j] = col_j\n                \n                # Check if this is an H1 death (1-simplex killed by a 2-simplex)\n                s_p = simplices[pivot]\n                if s_p.dim == 1 and s_j.dim == 2:\n                    birth = s_p.f_val\n                    death = s_j.f_val\n                    h1_intervals.append([birth, death])\n                \n                break # Reduction of this column is complete\n\n    # 4. Find the longest H1 interval\n    if not h1_intervals:\n        return [0.0, 0.0]\n        \n    longest_interval = max(h1_intervals, key=lambda interval: interval[1] - interval[0])\n    \n    return [round(longest_interval[0], 3), round(longest_interval[1], 3)]\n\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (N, sigma, seed)\n        (30, 0.05, 0),  # Case A\n        (18, 0.01, 1),  # Case B\n        (26, 0.12, 2),  # Case C\n    ]\n\n    results = []\n    for N, sigma, seed in test_cases:\n        result = compute_longest_h1_barcode(N, sigma, seed)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "Once persistence diagrams are computed, the next step is often to compare them to measure the dissimilarity between datasets. This final practice delves into the critical task of interpreting these topological summaries through the lens of different metrics. Using a carefully designed thought experiment, you will explore how the Bottleneck ($d_B$) and Wasserstein ($W_p$) distances weigh features differently, revealing their distinct sensitivities to phenomena at microscopic versus macroscopic scales .",
            "id": "3825414",
            "problem": "Consider a multiscale system in which a point cloud in $\\mathbb{R}^2$ exhibits one dominant loop at a mesoscopic scale and numerous microscopic fluctuations that intermittently create short-lived homology-$1$ features. Let $\\mathcal{D}_X$ and $\\mathcal{D}_Y$ denote the persistent homology (dimension $1$) persistence diagrams obtained from Vietoris–Rips filtrations on two realizations of the system. A persistence diagram is a multiset of points $(b,d)$ with $bd$ representing birth and death scales; points may be matched to other points or to the diagonal $\\Delta=\\{(t,t): t\\in\\mathbb{R}\\}$.\n\nAssume the following construction:\n- Diagram $\\mathcal{D}_X$ contains one large-scale feature $L=(b_L,d_L)$ with $b_L=0.10$ and $d_L=1.10$, and $m$ small-scale features $\\{s_i=(b_i,d_i)\\}_{i=1}^m$ where each has lifetime $d_i-b_i=\\epsilon$ with $b_i\\in[0.05,0.15]$, $d_i=b_i+\\epsilon$, and all $b_i$ are distinct. Take $m=1000$ and $\\epsilon=0.010$.\n- Diagram $\\mathcal{D}_Y$ contains the corresponding large-scale feature $L'=(b_L+\\delta,d_L+\\delta)$ with $\\delta=0.030$ and no small-scale features (that is, the microscopic fluctuations collapse to the diagonal in the second realization).\n\nDistances between persistence diagrams are defined using the $\\ell^\\infty$ ground metric on points in $\\mathbb{R}^2$ and allow matchings to the diagonal. The bottleneck distance $d_B(\\mathcal{D}_X,\\mathcal{D}_Y)$ is the infimum over bijections between the multisets (augmented with countably many copies of the diagonal) of the supremum of the $\\ell^\\infty$ distances of matched pairs. The $p$-Wasserstein distance $W_p(\\mathcal{D}_X,\\mathcal{D}_Y)$, for $p\\ge 1$, is the infimum over such bijections of the $\\ell^p$ aggregate of the $\\ell^\\infty$ distances of matched pairs.\n\nUsing only these core definitions, reason carefully about the effect of the many small features versus the single large feature in the constructed example. Select all statements that are correct.\n\nA. In this construction, $d_B(\\mathcal{D}_X,\\mathcal{D}_Y)=\\delta$ because the maximal optimal matching cost is set by the large-scale feature, provided $\\epsilon/2\\delta$, whereas $W_2(\\mathcal{D}_X,\\mathcal{D}_Y)\\approx\\sqrt{\\delta^2+m(\\epsilon/2)^2}$ so that, as $m$ grows, the $2$-Wasserstein distance becomes increasingly dominated by the accumulation of many small features.\n\nB. For any $p\\ge 1$, $W_p(\\mathcal{D}_X,\\mathcal{D}_Y)\\le d_B(\\mathcal{D}_X,\\mathcal{D}_Y)$, so the $p$-Wasserstein distance cannot exceed the bottleneck distance regardless of $m$ or $\\epsilon$.\n\nC. As $p\\to\\infty$, the $p$-Wasserstein distance $W_p(\\mathcal{D}_X,\\mathcal{D}_Y)$ converges to the bottleneck distance $d_B(\\mathcal{D}_X,\\mathcal{D}_Y)$, thereby prioritizing the largest-scale feature in the limit.\n\nD. In a multiscale modeling workflow, if one applies a coarse-graining step that removes features with persistence less than a threshold $\\tau$ chosen so that $\\epsilon\\tau\\delta$, then both $d_B$ and $W_2$ on the coarse-grained diagrams become dominated by the single large-scale feature, aligning $W_2$ with coarse-grained objectives.\n\nE. Increasing $m$ with fixed $\\epsilon$ and $\\delta$ leaves both $d_B$ and $W_2$ unchanged because matching small features to the diagonal has zero cost.\n\nExplain your reasoning from first principles, including how matchings to the diagonal contribute to each metric and the multiscale implications for modeling choices (coarse-grained versus fine-grained sensitivity).",
            "solution": "The problem statement has been validated and is deemed sound. It is a well-posed problem grounded in the established mathematical principles of topological data analysis. The setup is self-contained, consistent, and provides a standard example for comparing different metrics on persistence diagrams.\n\nWe are given two persistence diagrams, $\\mathcal{D}_X$ and $\\mathcal{D}_Y$, representing homology in dimension $1$.\nThe first diagram, $\\mathcal{D}_X$, is the multiset of points given by:\n$\\mathcal{D}_X = \\{L\\} \\cup \\{s_i\\}_{i=1}^m$, where\n- The large-scale feature is $L=(b_L, d_L) = (0.10, 1.10)$.\n- The small-scale features are $s_i = (b_i, d_i)$ for $i=1, \\dots, m$.\n- For these small features, we have $m=1000$ and a constant lifetime $d_i - b_i = \\epsilon = 0.010$. Their birth times $b_i$ are distinct and lie in the interval $[0.05, 0.15]$.\n\nThe second diagram, $\\mathcal{D}_Y$, contains only one point:\n$\\mathcal{D}_Y = \\{L'\\}$, where\n- $L' = (b_L+\\delta, d_L+\\delta) = (0.10+0.030, 1.10+0.030) = (0.13, 1.13)$.\n- $\\delta=0.030$.\n\nTo compute the distances between $\\mathcal{D}_X$ and $\\mathcal{D}_Y$, we must find an optimal matching between their points, where points can be matched to other points or to the diagonal $\\Delta = \\{(t,t) : t \\in \\mathbb{R}\\}$. The ground metric for pairs of points is the $\\ell^\\infty$ distance: $d_\\infty((x_1, y_1), (x_2, y_2)) = \\max(|x_1-x_2|, |y_1-y_2|)$. The cost of matching a point $q=(b,d)$ to the diagonal is its distance to the diagonal, which is $d_\\infty(q, \\Delta) = \\inf_{t \\in \\mathbb{R}} d_\\infty((b,d),(t,t)) = (d-b)/2$.\n\nSince $\\mathcal{D}_X$ has $m+1 = 1001$ points and $\\mathcal{D}_Y$ has $1$ point, any matching must pair the point $L' \\in \\mathcal{D}_Y$ with exactly one point from $\\mathcal{D}_X$ or with the diagonal, and all remaining points from $\\mathcal{D}_X$ must be matched to the diagonal.\n\nLet's evaluate the costs of possible matchings for $L'$:\n1.  Match $L' \\in \\mathcal{D}_Y$ with $L \\in \\mathcal{D}_X$:\n    The cost is $d_\\infty(L, L') = d_\\infty((0.10, 1.10), (0.13, 1.13)) = \\max(|0.10-0.13|, |1.10-1.13|) = \\max(0.03, 0.03) = 0.03 = \\delta$.\n\n2.  Match $L' \\in \\mathcal{D}_Y$ with some $s_i \\in \\mathcal{D}_X$:\n    The cost is $d_\\infty(s_i, L') = d_\\infty((b_i, b_i+\\epsilon), (0.13, 1.13))$. Since $b_i \\in [0.05, 0.15]$ and $\\epsilon = 0.010$, we have $d_\\infty(s_i, L') = \\max(|b_i-0.13|, |b_i+0.010-1.13|) = \\max(|b_i-0.13|, |b_i-1.12|)$. The first term is at most $|0.05-0.13|=0.08$. The second term is approximately $1$. The cost is thus much larger than $\\delta=0.03$. This matching is not optimal.\n\n3.  Match $L' \\in \\mathcal{D}_Y$ to the diagonal $\\Delta$:\n    The cost is $d_\\infty(L', \\Delta) = \\frac{(d_L+\\delta)-(b_L+\\delta)}{2} = \\frac{d_L-b_L}{2} = \\frac{1.10-0.10}{2} = 0.50$. This is also much larger than $\\delta$.\n\nThe optimal strategy must therefore involve matching $L$ to $L'$. After this pair is matched, the remaining $m=1000$ points $\\{s_i\\}_{i=1}^m$ from $\\mathcal{D}_X$ must be matched to the diagonal. The cost for matching each $s_i$ to the diagonal is:\n$d_\\infty(s_i, \\Delta) = \\frac{d_i-b_i}{2} = \\frac{\\epsilon}{2} = \\frac{0.010}{2} = 0.005$.\n\nSo, for the optimal matching, we have a set of costs: one cost of $\\delta=0.030$ (from the $L \\leftrightarrow L'$ match) and $m=1000$ costs of $\\epsilon/2=0.005$ (from matching each $s_i$ to the diagonal).\n\nNow we can compute the distances.\n\n**Bottleneck Distance ($d_B$)**\nThe bottleneck distance is the supremum (maximum) of the costs in the optimal matching.\n$$d_B(\\mathcal{D}_X, \\mathcal{D}_Y) = \\max \\left( d_\\infty(L, L'), d_\\infty(s_1, \\Delta), \\dots, d_\\infty(s_m, \\Delta) \\right)$$\n$$d_B(\\mathcal{D}_X, \\mathcal{D}_Y) = \\max(\\delta, \\epsilon/2) = \\max(0.030, 0.005) = 0.030 = \\delta$$\n\n**$p$-Wasserstein Distance ($W_p$)**\nThe $p$-Wasserstein distance is the $\\ell^p$-norm of the vector of costs in the optimal matching.\n$$W_p(\\mathcal{D}_X, \\mathcal{D}_Y) = \\left( d_\\infty(L, L')^p + \\sum_{i=1}^m d_\\infty(s_i, \\Delta)^p \\right)^{1/p}$$\n$$W_p(\\mathcal{D}_X, \\mathcal{D}_Y) = \\left( \\delta^p + m \\left(\\frac{\\epsilon}{2}\\right)^p \\right)^{1/p}$$\nFor $p=2$, the $2$-Wasserstein distance is:\n$$W_2(\\mathcal{D}_X, \\mathcal{D}_Y) = \\sqrt{\\delta^2 + m\\left(\\frac{\\epsilon}{2}\\right)^2} = \\sqrt{(0.030)^2 + 1000 \\cdot (0.005)^2}$$\n$$W_2(\\mathcal{D}_X, \\mathcal{D}_Y) = \\sqrt{0.0009 + 1000 \\cdot 0.000025} = \\sqrt{0.0009 + 0.025} = \\sqrt{0.0259} \\approx 0.1609$$\n\nWith these results, we can evaluate each option.\n\n**A. In this construction, $d_B(\\mathcal{D}_X,\\mathcal{D}_Y)=\\delta$ because the maximal optimal matching cost is set by the large-scale feature, provided $\\epsilon/2\\delta$, whereas $W_2(\\mathcal{D}_X,\\mathcal{D}_Y)\\approx\\sqrt{\\delta^2+m(\\epsilon/2)^2}$ so that, as $m$ grows, the $2$-Wasserstein distance becomes increasingly dominated by the accumulation of many small features.**\nOur derivation shows $d_B(\\mathcal{D}_X, \\mathcal{D}_Y) = \\max(\\delta, \\epsilon/2)$. The condition $\\epsilon/2  \\delta$ is satisfied since $0.005  0.030$, so indeed $d_B(\\mathcal{D}_X, \\mathcal{D}_Y) = \\delta$. The formula for $W_2$ is exactly $W_2(\\mathcal{D}_X,\\mathcal{D}_Y) = \\sqrt{\\delta^2+m(\\epsilon/2)^2}$. In our case, the term $m(\\epsilon/2)^2 = 0.025$ is much larger than $\\delta^2 = 0.0009$, demonstrating that the distance is dominated by the many small features. This dominance increases with $m$. The statement is fully consistent with our derivations.\n**Verdict: Correct**\n\n**B. For any $p\\ge 1$, $W_p(\\mathcal{D}_X,\\mathcal{D}_Y)\\le d_B(\\mathcal{D}_X,\\mathcal{D}_Y)$, so the $p$-Wasserstein distance cannot exceed the bottleneck distance regardless of $m$ or $\\epsilon$.**\nThis statement claims an incorrect inequality. For any multiset of non-negative costs $\\{c_j\\}$, the $\\ell^p$-norm is always greater than or equal to the $\\ell^\\infty$-norm: $(\\sum_j c_j^p)^{1/p} \\ge \\max_j c_j$. Applying this to the costs of any matching $\\eta$, we get that the $p$-Wasserstein cost of $\\eta$ is greater than or equal to its bottleneck cost. This implies that the infimum over all matchings, $W_p(\\mathcal{D}_X, \\mathcal{D}_Y)$, must be greater than or equal to $d_B(\\mathcal{D}_X, \\mathcal{D}_Y)$. Our specific example provides a direct counterexample: $W_2 \\approx 0.1609$ and $d_B = 0.030$, so $W_2  d_B$.\n**Verdict: Incorrect**\n\n**C. As $p\\to\\infty$, the $p$-Wasserstein distance $W_p(\\mathcal{D}_X,\\mathcal{D}_Y)$ converges to the bottleneck distance $d_B(\\mathcal{D}_X,\\mathcal{D}_Y)$, thereby prioritizing the largest-scale feature in the limit.**\nThis is a general property relating $\\ell^p$-norms. The limit of the $p$-Wasserstein distance as $p \\to \\infty$ is the bottleneck distance ($W_\\infty \\equiv d_B$). Let's verify with our formula:\n$$ \\lim_{p\\to\\infty} W_p(\\mathcal{D}_X, \\mathcal{D}_Y) = \\lim_{p\\to\\infty} \\left( \\delta^p + m \\left(\\frac{\\epsilon}{2}\\right)^p \\right)^{1/p} $$\nSince $\\delta  \\epsilon/2$, we can factor out $\\delta$:\n$$ \\lim_{p\\to\\infty} \\delta \\left( 1 + m \\left(\\frac{\\epsilon/2}{\\delta}\\right)^p \\right)^{1/p} $$\nThe ratio $r = (\\epsilon/2)/\\delta  1$. As $p\\to\\infty$, $r^p \\to 0$, so the term $m \\cdot r^p$ also goes to $0$. The expression becomes $\\delta \\cdot (1+0)^{1/\\infty} = \\delta \\cdot 1 = \\delta$. As we calculated, $d_B(\\mathcal{D}_X, \\mathcal{D}_Y) = \\delta$. Thus, the convergence holds. This limiting behavior effectively ignores the sum of smaller costs and focuses only on the maximal cost, which in this case is associated with the large-scale feature.\n**Verdict: Correct**\n\n**D. In a multiscale modeling workflow, if one applies a coarse-graining step that removes features with persistence less than a threshold $\\tau$ chosen so that $\\epsilon\\tau\\delta$, then both $d_B$ and $W_2$ on the coarse-grained diagrams become dominated by the single large-scale feature, aligning $W_2$ with coarse-grained objectives.**\nThe persistence of a feature $(b,d)$ is its lifetime $d-b$.\n- Persistence of $L$ is $d_L-b_L = 1.10 - 0.10 = 1.0$.\n- Persistence of each $s_i$ is $d_i-b_i = \\epsilon = 0.010$.\nA threshold $\\tau$ is chosen such that $0.010  \\tau  0.030$.\nWe apply this threshold to create coarse-grained diagrams $\\mathcal{D}_X'$ and $\\mathcal{D}_Y'$:\n- In $\\mathcal{D}_X$, the persistence of $L$ is $1.0  \\tau$, so $L$ is kept. The persistence of all $s_i$ is $\\epsilon  \\tau$, so they are all removed. Thus, $\\mathcal{D}_X' = \\{L\\}$.\n- In $\\mathcal{D}_Y$, the persistence of $L'$ is $(d_L+\\delta)-(b_L+\\delta) = 1.0  \\tau$, so $L'$ is kept. Thus, $\\mathcal{D}_Y' = \\{L'\\}$.\nNow, we compute distances between $\\mathcal{D}_X' = \\{L\\}$ and $\\mathcal{D}_Y' = \\{L'\\}$. The only possible matching is to pair $L$ with $L'$, which has a cost of $d_\\infty(L, L') = \\delta$.\n- The new bottleneck distance is $d_B(\\mathcal{D}_X', \\mathcal{D}_Y') = \\delta$.\n- The new $2$-Wasserstein distance is $W_2(\\mathcal{D}_X', \\mathcal{D}_Y') = \\sqrt{\\delta^2} = \\delta$.\nBoth distances are now equal to $\\delta$ and are determined solely by the large-scale feature. This filtering step makes the $W_2$ distance insensitive to the microscopic fluctuations, aligning its value with the coarse-grained view that only the large, persistent feature is significant. The statement is accurate.\n**Verdict: Correct**\n\n**E. Increasing $m$ with fixed $\\epsilon$ and $\\delta$ leaves both $d_B$ and $W_2$ unchanged because matching small features to the diagonal has zero cost.**\nThe reason provided is factually incorrect. The cost of matching a small feature $s_i$ to the diagonal is $\\epsilon/2 = 0.005$, which is not zero. Let's evaluate the main claim.\n- $d_B = \\max(\\delta, \\epsilon/2)$. This expression does not depend on $m$. So, increasing $m$ leaves $d_B$ unchanged.\n- $W_2 = \\sqrt{\\delta^2 + m(\\epsilon/2)^2}$. This expression explicitly depends on $m$. As $m$ increases, $W_2$ increases.\nSince $W_2$ changes with $m$, the claim that \"both... [are] unchanged\" is false.\n**Verdict: Incorrect**",
            "answer": "$$\\boxed{ACD}$$"
        }
    ]
}