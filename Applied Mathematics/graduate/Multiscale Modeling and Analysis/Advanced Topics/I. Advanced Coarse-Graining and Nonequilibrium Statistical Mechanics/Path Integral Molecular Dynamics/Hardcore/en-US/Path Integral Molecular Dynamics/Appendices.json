{
    "hands_on_practices": [
        {
            "introduction": "The foundation of Path Integral Molecular Dynamics lies in the isomorphism between a quantum particle and a classical ring polymer. This exercise provides a crucial, quantitative verification of this principle by comparing the PIMD model directly against an exact quantum mechanical solution. By calculating the partition function for the quantum harmonic oscillator, both exactly and through the discretized path integral, you will gain a concrete understanding of how the number of beads $P$ controls the accuracy of the simulation and empirically determine the rate of convergence .",
            "id": "2659206",
            "problem": "Consider a one-dimensional quantum harmonic oscillator of mass $m$ and angular frequency $\\omega$ at inverse temperature $\\beta$. Work in reduced units where Planck’s constant divided by $2\\pi$ is set to $\\hbar = 1$ and Boltzmann’s constant is $k_{\\mathrm{B}} = 1$, so that all quantities are dimensionless. Your task is to derive, implement, and test a comparison between the exact quantum canonical partition function and its imaginary-time path integral discretization as a function of the Trotter number $P$.\n\nStart from the following fundamental bases:\n- The canonical partition function is $Z = \\mathrm{Tr}\\left[e^{-\\beta \\hat{H}}\\right]$ with Hamiltonian $\\hat{H} = \\frac{\\hat{p}^2}{2m} + \\frac{1}{2} m \\omega^2 \\hat{q}^2$.\n- The Trotter factorization and Feynman imaginary-time path integral representation express $Z$ as a limit of $P$-fold factorizations of imaginary-time evolution operators, which for finite $P$ yields a classical configuration integral over a $P$-bead ring polymer with nearest-neighbor harmonic springs and on-bead potential $V(q) = \\frac{1}{2} m \\omega^2 q^2$.\n- For a quadratic action, Gaussian integrals reduce to determinants of the quadratic form.\n\nRequirements:\n1) Derive the exact quantum partition function $Z_{\\mathrm{exact}}(\\beta,\\omega)$ for the one-dimensional harmonic oscillator in these units.\n2) From the discretized imaginary-time path integral with $P$ beads and primitive Trotter splitting, derive an explicit, computable expression $Z_P(\\beta,\\omega)$ in terms of a product over the ring-polymer normal modes for finite $P$ (this is the $P$-level Path Integral Monte Carlo (PIMC) target that true Monte Carlo sampling would estimate; here you will compute it deterministically via the equivalent Gaussian integral).\n3) For each specified test case below, compute $Z_{\\mathrm{exact}}(\\beta,\\omega)$ and $Z_P(\\beta,\\omega)$ for $P \\in \\{1,2,4,8,16,32,64\\}$. Use these to compute the absolute error $|Z_P - Z_{\\mathrm{exact}}|$ for each $P$.\n4) Quantify the convergence rate by fitting a power-law $|Z_P - Z_{\\mathrm{exact}}| \\approx C P^{-r}$ to the last four $P$ values $P \\in \\{8,16,32,64\\}$ using linear least squares on $\\log$-$\\log$ data to extract the exponent $r$.\n5) Implement the above as a complete program that produces the required outputs for the test suite.\n\nUse the following test suite of parameter sets (all dimensionless in the stated units $\\hbar = 1$, $k_{\\mathrm{B}}=1$):\n- Case $1$: $(\\beta,\\omega) = (0.5, 1.0)$.\n- Case $2$: $(\\beta,\\omega) = (1.0, 1.0)$.\n- Case $3$: $(\\beta,\\omega) = (3.0, 1.0)$.\n- Case $4$: $(\\beta,\\omega) = (1.0, 0.5)$.\n\nProgram input: None. All parameters are provided above.\n\nProgram outputs:\n- For each case, output a single float: the fitted convergence exponent $r$ from step $4$.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the cases listed above, for example, $[r_1,r_2,r_3,r_4]$.\n- Each $r$ must be reported as a floating-point number. All outputs are unitless due to the choice $\\hbar = 1$, $k_{\\mathrm{B}}=1$.\n\nNumerical guidance and constraints:\n- For numerical stability, evaluate products for $Z_P(\\beta,\\omega)$ using logarithms of eigenmode contributions.\n- Angles used in trigonometric functions must be in radians.\n- No external input or randomness is allowed; your implementation must be deterministic and self-contained.",
            "solution": "The problem statement has been rigorously validated and is found to be scientifically sound, well-posed, and objective. It is a standard problem in statistical mechanics that admits a unique and verifiable solution. We now proceed with the derivation and implementation as requested. The analysis will be performed in reduced units where Planck's constant divided by $2\\pi$ is $\\hbar=1$ and Boltzmann's constant is $k_{\\mathrm{B}}=1$.\n\nFirst, we derive the exact quantum canonical partition function, $Z_{\\mathrm{exact}}$. The Hamiltonian for the one-dimensional quantum harmonic oscillator is given by $\\hat{H} = \\frac{\\hat{p}^2}{2m} + \\frac{1}{2} m \\omega^2 \\hat{q}^2$. The energy eigenvalues of this system are quantized and given by $E_n = \\hbar \\omega (n + \\frac{1}{2})$, where $n$ is a non-negative integer, $n=0, 1, 2, \\ldots$. In the specified reduced units where $\\hbar=1$, the energy levels are $E_n = \\omega(n + \\frac{1}{2})$. The canonical partition function $Z$ at an inverse temperature $\\beta = 1/(k_{\\mathrm{B}}T)$ is defined as the trace of the Boltzmann operator, $Z = \\mathrm{Tr}[e^{-\\beta \\hat{H}}]$. In the energy eigenbasis, this becomes a sum over all states:\n$$Z_{\\mathrm{exact}} = \\sum_{n=0}^{\\infty} e^{-\\beta E_n} = \\sum_{n=0}^{\\infty} e^{-\\beta \\omega (n + 1/2)}$$\nWe can factor out the ground state contribution and recognize the remaining sum as a geometric series:\n$$Z_{\\mathrm{exact}} = e^{-\\beta \\omega/2} \\sum_{n=0}^{\\infty} (e^{-\\beta \\omega})^n$$\nThe geometric series $\\sum_{n=0}^{\\infty} x^n$ converges to $1/(1-x)$ for $|x|<1$. Here, $x=e^{-\\beta\\omega}$, which is always less than $1$ for positive $\\beta$ and $\\omega$. Thus, the sum evaluates to $1/(1-e^{-\\beta\\omega})$. Substituting this back, we obtain:\n$$Z_{\\mathrm{exact}} = \\frac{e^{-\\beta \\omega/2}}{1 - e^{-\\beta \\omega}} = \\frac{1}{e^{\\beta \\omega/2} - e^{-\\beta \\omega/2}}$$\nThis expression is equivalent to the hyperbolic cosecant function:\n$$Z_{\\mathrm{exact}}(\\beta, \\omega) = \\frac{1}{2\\sinh(\\beta\\omega/2)}$$\nNote that this expression is independent of the mass $m$.\n\nNext, we derive the approximate partition function, $Z_P$, from the discretized imaginary-time path integral formulation. The partition function can be expressed as an integral over closed paths in imaginary time $\\tau \\in [0, \\beta\\hbar]$. Discretizing this time interval into $P$ steps of size $\\epsilon = \\beta/P$ and using the primitive Trotter factorization $e^{-\\beta \\hat{H}} \\approx (e^{-\\epsilon \\hat{V}} e^{-\\epsilon \\hat{T}})^P$ leads to the expression for $Z_P$:\n$$Z_P = \\mathrm{Tr}\\left[ \\left(e^{-\\frac{\\beta}{P}\\hat{T}} e^{-\\frac{\\beta}{P}\\hat{V}}\\right)^P \\right]$$\nInserting complete sets of position eigenstates between the operators results in a classical-like configuration integral over the positions $q_1, q_2, \\ldots, q_P$ of a cyclic polymer chain (a \"ring polymer\"). For a particle of mass $m$, the expression is:\n$$Z_P = \\left(\\frac{mP}{2\\pi\\beta\\hbar^2}\\right)^{P/2} \\int_{-\\infty}^{\\infty} \\! \\dots \\! \\int_{-\\infty}^{\\infty} d\\mathbf{q} \\exp\\left(-\\sum_{i=1}^{P} \\left[ \\frac{mP}{2\\beta\\hbar^2}(q_{i+1}-q_i)^2 + \\frac{\\beta}{P}V(q_i) \\right] \\right)$$\nwhere $q_{P+1} \\equiv q_1$ enforces the ring closure. In our reduced units ($\\hbar=1$) and for the harmonic potential $V(q) = \\frac{1}{2}m\\omega^2 q^2$, the argument of the exponential becomes:\n$$S(\\mathbf{q}) = \\sum_{i=1}^{P} \\left[ \\frac{mP}{2\\beta}(q_{i+1}-q_i)^2 + \\frac{\\beta m\\omega^2}{2P} q_i^2 \\right]$$\nThe integral is a multidimensional Gaussian integral. The term $S(\\mathbf{q})$ can be written as a quadratic form, $S(\\mathbf{q}) = \\frac{1}{2}\\mathbf{q}^T \\mathbf{A} \\mathbf{q}$, where $\\mathbf{q} = (q_1, \\ldots, q_P)^T$ and $\\mathbf{A}$ is a $P \\times P$ symmetric matrix. The elements of $\\mathbf{A}$ are found by expanding the sum:\n$$A_{ij} = m \\left[ \\left(\\frac{2P}{\\beta} + \\frac{\\beta\\omega^2}{P}\\right)\\delta_{ij} - \\frac{P}{\\beta}(\\delta_{i,j+1} + \\delta_{i,j-1}) \\right]$$\nwhere indices are taken modulo $P$. This is a circulant matrix.\nThe general formula for a $d$-dimensional Gaussian integral is $\\int d^d\\mathbf{x} \\exp(-\\frac{1}{2}\\mathbf{x}^T \\mathbf{M} \\mathbf{x}) = (2\\pi)^{d/2} (\\det \\mathbf{M})^{-1/2}$. Applying this to our integral for $Z_P$ gives:\n$$Z_P = \\left(\\frac{mP}{2\\pi\\beta}\\right)^{P/2} (2\\pi)^{P/2} (\\det \\mathbf{A})^{-1/2} = \\left(\\frac{mP}{\\beta}\\right)^{P/2} m^{-P/2} (\\det \\mathbf{A}')^{-1/2} = \\left(\\frac{P}{\\beta}\\right)^{P/2} (\\det \\mathbf{A}')^{-1/2}$$\nwhere $\\mathbf{A}' = \\mathbf{A}/m$. The mass $m$ cancels out, consistent with the exact result. The eigenvalues $\\lambda_k$ of the circulant matrix $\\mathbf{A}'$ are given by the discrete Fourier transform of its first row. For $k=0, 1, \\dots, P-1$:\n$$\\lambda_k = \\left(\\frac{2P}{\\beta} + \\frac{\\beta\\omega^2}{P}\\right) - \\frac{P}{\\beta}e^{2\\pi i k/P} - \\frac{P}{\\beta}e^{-2\\pi i k/P} = \\left(\\frac{2P}{\\beta} + \\frac{\\beta\\omega^2}{P}\\right) - \\frac{2P}{\\beta}\\cos\\left(\\frac{2\\pi k}{P}\\right)$$\nUsing the identity $1-\\cos(2\\theta) = 2\\sin^2(\\theta)$, this simplifies to:\n$$\\lambda_k = \\frac{2P}{\\beta} \\left(1 - \\cos\\left(\\frac{2\\pi k}{P}\\right)\\right) + \\frac{\\beta\\omega^2}{P} = \\frac{4P}{\\beta}\\sin^2\\left(\\frac{\\pi k}{P}\\right) + \\frac{\\beta\\omega^2}{P}$$\nThe determinant is the product of the eigenvalues, $\\det \\mathbf{A}' = \\prod_{k=0}^{P-1} \\lambda_k$. Substituting this into the expression for $Z_P$ yields the final computable formula:\n$$Z_P(\\beta, \\omega) = \\left(\\frac{P}{\\beta}\\right)^{P/2} \\left[ \\prod_{k=0}^{P-1} \\left( \\frac{4P}{\\beta}\\sin^2\\left(\\frac{\\pi k}{P}\\right) + \\frac{\\beta\\omega^2}{P} \\right) \\right]^{-1/2}$$\nFor numerical evaluation, especially for large $P$, it is more stable to compute the logarithm of $Z_P$:\n$$\\log Z_P = \\frac{P}{2} \\log\\left(\\frac{P}{\\beta}\\right) - \\frac{1}{2} \\sum_{k=0}^{P-1} \\log(\\lambda_k)$$\nThis expression is a direct consequence of the path integral formulation and represents the target value for a PIMC simulation.\n\nThe final requirement is to analyze the convergence of $Z_P$ to $Z_{\\mathrm{exact}}$ as $P$ increases. The primitive Trotter approximation introduces an error that scales with the number of beads $P$. We expect a power-law relationship for the absolute error:\n$$|Z_P - Z_{\\mathrm{exact}}| \\approx C P^{-r}$$\nwhere $C$ is a constant and $r$ is the convergence exponent. To determine $r$, we can perform a linear regression on the logarithm of this equation:\n$$\\log|Z_P - Z_{\\mathrm{exact}}| \\approx \\log C - r \\log P$$\nThis is a linear equation of the form $y = b + mx$, with $y = \\log|Z_P - Z_{\\mathrm{exact}}|$, $x = \\log P$, slope $m = -r$, and intercept $b = \\log C$. We will compute the errors for $P \\in \\{1, 2, 4, 8, 16, 32, 64\\}$, and use the last four data points ($P \\in \\{8, 16, 32, 64\\}$) to perform a linear least-squares fit and extract the slope $m$. The convergence exponent is then $r = -m$. For the primitive algorithm used here, theoretical considerations predict that the error in the partition function scales as $\\mathcal{O}(P^{-1})$, corresponding to a convergence exponent of $r=1$. The implementation will calculate this exponent for each test case.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of comparing the exact and path-integral discretized\n    partition functions for a quantum harmonic oscillator.\n    \"\"\"\n\n    # Test cases from the problem statement: (beta, omega)\n    test_cases = [\n        (0.5, 1.0),\n        (1.0, 1.0),\n        (3.0, 1.0),\n        (1.0, 0.5),\n    ]\n\n    # Trotter numbers for the analysis\n    P_values = np.array([1, 2, 4, 8, 16, 32, 64])\n\n    # List to store the final convergence exponents r for each test case\n    convergence_exponents = []\n\n    for beta, omega in test_cases:\n        # 1. Calculate the exact partition function Z_exact\n        # Z_exact = 1 / (2 * sinh(beta * omega / 2))\n        z_exact = 1.0 / (2.0 * np.sinh(beta * omega / 2.0))\n\n        errors = []\n        for P in P_values:\n            # 2. Calculate the discretized path integral partition function Z_P\n            # The formula is derived in the solution text. We compute its logarithm\n            # for numerical stability.\n            # log(Z_P) = (P/2)*log(P/beta) - (1/2)*sum_{k=0}^{P-1}log(lambda_k)\n            # lambda_k = (4P/beta)*sin^2(pi*k/P) + (beta*omega^2)/P\n\n            k_vals = np.arange(P)\n            sin_term = np.sin(np.pi * k_vals / P)**2\n            lambda_k = (4.0 * P / beta) * sin_term + (beta * omega**2 / P)\n            \n            # The logarithm of lambda_k can have -inf if lambda_k is 0,\n            # which does not happen for omega > 0.\n            log_lambda_k_sum = np.sum(np.log(lambda_k))\n\n            log_z_p = (P / 2.0) * np.log(P / beta) - 0.5 * log_lambda_k_sum\n            z_p = np.exp(log_z_p)\n\n            # 3. Compute the absolute error\n            error = np.abs(z_p - z_exact)\n            errors.append(error)\n\n        # 4. Fit the convergence rate r from the last four P values\n        # Model: error = C * P^(-r) => log(error) = log(C) - r * log(P)\n        # We perform a linear fit on log-log data.\n        \n        # Use last four points for the fit: P = {8, 16, 32, 64}\n        fit_P_values = P_values[-4:]\n        fit_errors = np.array(errors[-4:])\n        \n        log_P = np.log(fit_P_values)\n        log_error = np.log(fit_errors)\n\n        # Using numpy's polyfit to find the slope of the linear regression\n        # polyfit returns [slope, intercept] for degree 1\n        slope, _ = np.polyfit(log_P, log_error, 1)\n\n        # The convergence exponent r is the negative of the slope\n        r = -slope\n        convergence_exponents.append(r)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.10f}' for r in convergence_exponents)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While the harmonic oscillator provides a vital benchmark, real molecular systems are anharmonic, which poses significant challenges for efficient conformational sampling. The strong harmonic coupling between adjacent beads in the ring polymer can drastically slow down the exploration of the potential energy surface. This practice moves beyond simple models to address the critical issue of sampling efficiency by implementing and comparing two advanced coordinate systems—normal modes and staging—for a particle in a double-well potential, demonstrating how a clever choice of coordinates can dramatically accelerate convergence .",
            "id": "3793344",
            "problem": "Implement a self-contained program that, for a one-dimensional quantum particle in an anharmonic potential within the Path Integral Molecular Dynamics (PIMD) framework, compares the statistical efficiency of two coordinate representations—staging coordinates and normal modes—by estimating the integrated autocorrelation time of the potential energy. Use the following fundamental base.\n\n- The quantum canonical partition function can be represented by a discretized Feynman path integral, which maps to a classical ring polymer with $P$ beads. In reduced units with Planck’s constant $\\hbar$ set to $1$, Boltzmann’s constant $k_B$ set to $1$, and mass $m$ set to $1$, the effective classical potential for the ring polymer is\n$$\nU_{\\mathrm{eff}}(\\mathbf{x}) \\;=\\; \\frac{P}{2\\beta^2} \\sum_{j=0}^{P-1} \\left(x_j - x_{j+1}\\right)^2 \\;+\\; \\frac{1}{P}\\sum_{j=0}^{P-1} V(x_j),\n$$\nwith periodic boundary $x_P \\equiv x_0$. The anharmonic external potential is the double-well\n$$\nV(x) \\;=\\; a \\left(x^2 - b^2\\right)^2,\n$$\nwith parameters $a>0$ and $b>0$. The canonical probability density for the bead coordinates $\\mathbf{x}\\in\\mathbb{R}^P$ is proportional to $\\exp\\left(-\\beta\\,U_{\\mathrm{eff}}(\\mathbf{x})\\right)$.\n\n- Two linear coordinate transforms are to be implemented:\n  1. Normal modes: Diagonalize the ring-polymer spring matrix $\\mathbf{K}\\in\\mathbb{R}^{P\\times P}$ defined by $K_{jj}=2$, $K_{j,j+1}=K_{j+1,j}=-1$ with periodic indexing, so that $\\mathbf{K}=\\mathbf{Q}\\,\\mathrm{diag}(\\lambda_0,\\dots,\\lambda_{P-1})\\,\\mathbf{Q}^\\top$, where $\\mathbf{Q}$ is orthonormal and $\\lambda_k\\ge 0$. Proposals are made by adding a Gaussian increment in normal-mode coordinates, i.e., $\\delta \\mathbf{x}=\\mathbf{Q}\\,\\delta\\mathbf{q}$, with mode-dependent scales chosen as a function of $\\lambda_k$.\n  2. Staging transformation: Define staging coordinates $\\mathbf{s}\\in\\mathbb{R}^P$ by the lower-triangular, volume-preserving mapping\n     - $s_0 = x_0$,\n     - for $j\\in\\{1,\\dots,P-1\\}$,\n       $$\n       s_j \\;=\\; x_j \\;-\\; \\frac{j}{j+1}\\,x_{j-1} \\;-\\; \\frac{1}{j+1}\\,x_0.\n       $$\n     The inverse mapping is\n       $$\n       x_0 \\;=\\; s_0, \\qquad\n       x_j \\;=\\; s_0 \\;+\\; \\sum_{m=1}^{j} \\frac{m+1}{j+1}\\,s_m \\quad \\text{for } j\\in\\{1,\\dots,P-1\\}.\n       $$\n     Proposals are made by adding a Gaussian increment in staging coordinates and mapping back linearly to bead space, i.e., $\\delta \\mathbf{x}=\\mathbf{T}\\,\\delta\\mathbf{s}$ where $\\mathbf{T}$ is the lower-triangular matrix defined by the inverse mapping above.\n\n- Sampling must be performed using a single-step global Gaussian proposal in the chosen internal coordinates, followed by a Metropolis accept/reject step with acceptance probability\n$$\n\\alpha \\;=\\; \\min\\!\\left\\{1,\\;\\exp\\!\\left[-\\beta\\left(U_{\\mathrm{eff}}(\\mathbf{x}^{\\mathrm{new}})-U_{\\mathrm{eff}}(\\mathbf{x}^{\\mathrm{old}})\\right)\\right]\\right\\}.\n$$\nSince both transforms are linear with constant Jacobians, symmetric Gaussian proposals in the internal coordinates yield symmetric proposals in bead space.\n\n- For the normal-mode proposal, scale each mode $k$ by a factor proportional to $1/\\sqrt{\\lambda_k}$ for $k\\ge 1$ and a finite centroid scale for $k=0$. For the staging proposal, scale staging coordinate $s_j$ for $j\\ge 1$ proportionally to $\\sqrt{\\frac{j}{j+1}}$ and use a finite scale for $s_0$. Use the same baseline step-size factor for both methods to enable a fair comparison.\n\n- From the Markov Chain Monte Carlo (MCMC) trajectory, record the time series of the ring-polymer averaged potential energy\n$$\n\\overline{V}_t \\;=\\; \\frac{1}{P}\\sum_{j=0}^{P-1} V\\!\\left(x_j^{(t)}\\right).\n$$\n\n- Estimate the Integrated Autocorrelation Time (IAT) of the scalar series $\\{\\overline{V}_t\\}$ using the initial positive sequence method: compute the normalized autocorrelation function $\\rho(\\tau)$ via the standard fast Fourier transform convolution estimator, then define\n$$\n\\tau_{\\mathrm{int}} \\;=\\; 1 + 2 \\sum_{\\tau=1}^{\\tau^\\star} \\rho(\\tau),\n$$\nwhere $\\tau^\\star$ is the largest even lag such that each pairwise sum $\\rho(2\\ell-1)+\\rho(2\\ell)$ remains nonnegative. If the variance is numerically zero, define $\\tau_{\\mathrm{int}}=1$.\n\n- For each test case below, run both samplers (normal modes and staging) with the same number of total MCMC steps, discard an initial burn-in fraction, and estimate the IATs from the retained samples. Report the ratio\n$$\nR \\;=\\; \\frac{\\tau_{\\mathrm{int}}^{\\mathrm{NM}}}{\\tau_{\\mathrm{int}}^{\\mathrm{ST}}}\n$$\nas a floating-point number. A value $R>1$ indicates that staging yields shorter autocorrelation (higher efficiency) than normal modes for that case.\n\nAssumptions and computational details:\n\n- Work in reduced, dimensionless units with $\\hbar=1$, $k_B=1$, and $m=1$. In these units, $\\beta$ is dimensionless, positions are dimensionless, and the time index in the MCMC trajectory is a count of Monte Carlo steps (dimensionless). No physical unit conversion is required.\n- Angles do not appear; no specification is needed.\n- The program must be deterministic and require no external input. Fix an internal pseudorandom seed.\n\nTest suite:\n\nFor each parameter tuple $(P,\\beta,a,b,N_{\\mathrm{steps}})$, run both samplers and output the scalar ratio $R$ defined above. Use the following four cases:\n\n- Case A: $(P,\\beta,a,b,N_{\\mathrm{steps}}) = (16,\\,4.0,\\,1.0,\\,1.0,\\,12000)$.\n- Case B: $(P,\\beta,a,b,N_{\\mathrm{steps}}) = (32,\\,8.0,\\,1.0,\\,1.0,\\,12000)$.\n- Case C: $(P,\\beta,a,b,N_{\\mathrms}) = (24,\\,2.0,\\,0.5,\\,1.2,\\,12000)$.\n- Case D: $(P,\\beta,a,b,N_{\\mathrm{steps}}) = (12,\\,1.5,\\,0.25,\\,0.5,\\,10000)$.\n\nFinal output format:\n\n- Your program should produce a single line of output containing the four ratios $R$ for the test cases A–D in order, as a comma-separated list enclosed in square brackets (e.g., $[r_A,r_B,r_C,r_D]$).",
            "solution": "The problem requires a comparison of the statistical efficiency of two coordinate representations, normal modes and staging coordinates, within the Path Integral Molecular Dynamics (PIMD) framework for a one-dimensional quantum particle in an anharmonic potential. The efficiency is quantified by the Integrated Autocorrelation Time (IAT) of the potential energy estimator.\n\n### 1. Theoretical Framework: Path Integral Molecular Dynamics\n\nThe canonical partition function $Z$ of a quantum system at inverse temperature $\\beta = 1/(k_B T)$ can be expressed using the Feynman path integral. By discretizing this integral into $P$ time slices (or \"beads\"), the quantum particle is mapped onto a classical system of $P$ beads forming a ring polymer. For a particle of mass $m=1$ in reduced units where $\\hbar=1$ and $k_B=1$, the effective classical potential energy of this ring polymer is given by:\n$$\nU_{\\mathrm{eff}}(\\mathbf{x}) = \\frac{P}{2\\beta^2} \\sum_{j=0}^{P-1} \\left(x_j - x_{j+1}\\right)^2 + \\frac{1}{P}\\sum_{j=0}^{P-1} V(x_j)\n$$\nHere, $\\mathbf{x} = (x_0, x_1, \\dots, x_{P-1})$ are the positions of the $P$ beads, with the ring closure condition $x_P \\equiv x_0$. The first term represents the kinetic energy via harmonic springs connecting adjacent beads. The second term is the average external potential $V(x)$ experienced by the beads. For this problem, the external potential is the anharmonic double-well:\n$$\nV(x) = a \\left(x^2 - b^2\\right)^2\n$$\nThe configuration space of the ring polymer is sampled from the canonical probability distribution $p(\\mathbf{x}) \\propto \\exp(-\\beta U_{\\mathrm{eff}}(\\mathbf{x}))$.\n\n### 2. Sampling and Coordinate Representations\n\nDirect sampling of the bead coordinates $x_j$ using simple Monte Carlo moves is notoriously inefficient. The harmonic spring term creates strong correlations between adjacent beads, and its stiffness increases with $P$ and $\\beta$, leading to slow exploration of the configuration space. To overcome this, we employ coordinate transformations that decouple the system's degrees of freedom.\n\n#### a. Normal Mode (NM) Coordinates\nThe quadratic spring potential term, $\\frac{P}{2\\beta^2} \\sum_{j=0}^{P-1} (x_j - x_{j+1})^2$, can be written in matrix form as $\\frac{P}{2\\beta^2} \\mathbf{x}^\\top \\mathbf{K} \\mathbf{x}$, where $\\mathbf{K}$ is the circulant spring matrix. The normal mode transformation diagonalizes this matrix: $\\mathbf{K} = \\mathbf{Q} \\mathbf{\\Lambda} \\mathbf{Q}^\\top$, where $\\mathbf{\\Lambda} = \\mathrm{diag}(\\lambda_0, \\dots, \\lambda_{P-1})$ contains the eigenvalues and $\\mathbf{Q}$ is the matrix of orthonormal eigenvectors. The normal mode coordinates are $\\mathbf{q} = \\mathbf{Q}^\\top \\mathbf{x}$. In these coordinates, the spring potential becomes a sum of uncoupled harmonic oscillators. The eigenvalues are given by $\\lambda_k = 4\\sin^2(\\pi k/P)$. One eigenvalue, $\\lambda_0=0$, corresponds to the centroid mode (center of mass of the polymer), which moves as a free particle. The other modes, $k>0$, have non-zero frequencies and represent the internal vibrations of the ring polymer.\n\nAn efficient proposal strategy is to make Gaussian moves in the normal mode space, scaling the size of the move for each mode $q_k$ inversely to its characteristic frequency. As per the problem, we scale the proposal standard deviation for mode $k \\ge 1$ by $1/\\sqrt{\\lambda_k}$ and use a constant scale for the centroid mode ($k=0$). A proposed move $\\delta\\mathbf{q}$ in normal modes is transformed back to bead space via $\\delta\\mathbf{x} = \\mathbf{Q} \\delta\\mathbf{q}$.\n\n#### b. Staging (ST) Coordinates\nThe staging transformation provides an alternative, sequential decoupling of the bead coordinates. It is defined by the lower-triangular mapping from bead coordinates $\\mathbf{x}$ to staging coordinates $\\mathbf{s}$:\n$$\ns_0 = x_0, \\quad s_j = x_j - \\frac{j}{j+1}x_{j-1} - \\frac{1}{j+1}x_0 \\quad \\text{for } j \\in \\{1,\\dots,P-1\\}\n$$\nThis transformation, which is volume-preserving, can be inverted to express the bead positions in terms of staging coordinates. The key idea is that the spring potential energy term can also be expressed in terms of $\\mathbf{s}$, where the modes are more decoupled than in bead representation. An efficient proposal involves Gaussian moves in $\\mathbf{s}$-space, with step sizes scaled according to the stage index $j$. The problem specifies scaling the proposal for $s_j$ ($j \\ge 1$) by $\\sqrt{j/(j+1)}$ and using a constant scale for $s_0$. A proposed move $\\delta\\mathbf{s}$ is mapped back to bead space via the linear inverse transformation $\\delta\\mathbf{x} = \\mathbf{T} \\delta\\mathbf{s}$.\n\n### 3. Simulation and Analysis\n\nWe use the Metropolis-Hastings Markov Chain Monte Carlo (MCMC) algorithm to sample bead configurations. For both NM and ST representations, we generate a global proposal move for all coordinates simultaneously from a symmetric Gaussian distribution. Since the coordinate transformations are linear and the proposal distributions are symmetric, the proposal probability in bead space is also symmetric, and the Metropolis acceptance probability simplifies to:\n$$\n\\alpha = \\min\\left\\{1, \\exp\\left[-\\beta\\left(U_{\\mathrm{eff}}(\\mathbf{x}^{\\mathrm{new}}) - U_{\\mathrm{eff}}(\\mathbf{x}^{\\mathrm{old}})\\right)\\right]\\right\\}\n$$\nFor each test case, we run two separate simulations, one using NM and one using ST proposals, for a total of $N_{\\mathrm{steps}}$. We use the same baseline step-size factor and random number seed for both runs to ensure a fair comparison. After discarding an initial fraction of steps for thermalization (burn-in), we record the time series of the estimator for the average potential energy:\n$$\n\\overline{V}_t = \\frac{1}{P}\\sum_{j=0}^{P-1} V(x_j^{(t)})\n$$\nThe statistical efficiency is measured by the Integrated Autocorrelation Time (IAT), $\\tau_{\\mathrm{int}}$, of this time series. A smaller IAT indicates a more efficient sampler, as the samples are less correlated and converge to the true average more quickly. We estimate $\\tau_{\\mathrm{int}}$ using the initial positive sequence method specified in the problem:\n$$\n\\tau_{\\mathrm{int}} = 1 + 2 \\sum_{\\tau=1}^{\\tau^\\star} \\rho(\\tau)\n$$\nwhere $\\rho(\\tau)$ is the normalized autocorrelation function at lag $\\tau$, and $\\tau^\\star$ is the largest even lag for which all preceding pairwise sums $\\rho(2\\ell-1)+\\rho(2\\ell)$ are non-negative. $\\rho(\\tau)$ is computed efficiently via Fast Fourier Transform (FFT).\n\nFinally, for each test case, we compute the ratio $R = \\tau_{\\mathrm{int}}^{\\mathrm{NM}} / \\tau_{\\mathrm{int}}^{\\mathrm{ST}}$. This ratio quantifies the relative performance of the two methods, with $R > 1$ indicating that staging is more efficient than normal modes.",
            "answer": "```python\nimport numpy as np\n\n# Global constants as specified or reasonably chosen for the problem\nRANDOM_SEED = 1337\nBURN_IN_FRACTION = 0.2\n# Baseline step-size factors selected to give reasonable acceptance rates\n# across the different physical conditions of the test cases.\n# The same factor is used for both Normal Mode and Staging samplers within a given case.\nSTEP_SIZES = {\n    'A': 0.8,\n    'B': 0.6,\n    'C': 1.2,\n    'D': 1.5,\n}\n\ndef calculate_iat(series):\n    \"\"\"\n    Calculates the Integrated Autocorrelation Time (IAT) of a time series.\n    Uses the initial positive sequence method with pairwise sums, as specified.\n    \"\"\"\n    n = len(series)\n    if n  4:  # Need at least two lags for the first pair sum\n        return 1.0\n        \n    variance = np.var(series)\n    if variance  1e-12:\n        return 1.0\n\n    series_centered = series - np.mean(series)\n    \n    # Use FFT to compute the biased autocorrelation function\n    fft_len = 2 * n\n    autocorr_fft = np.fft.fft(series_centered, n=fft_len)\n    autocorr_real = np.fft.ifft(autocorr_fft * np.conj(autocorr_fft)).real\n    \n    # Normalize to get the autocorrelation function rho(tau)\n    # autocorr_real[0] is n * variance\n    if autocorr_real[0] = 0:\n        return 1.0\n    rho = autocorr_real[:n] / autocorr_real[0]\n\n    # Sum using the initial positive sequence (pairwise) method\n    cutoff_lag = 0\n    # Iterate through pairs of lags\n    for l in range(1, (n // 2)):\n        lag1_idx = 2 * l - 1\n        lag2_idx = 2 * l\n        \n        if lag2_idx >= n:\n            break\n        \n        if rho[lag1_idx] + rho[lag2_idx] >= 0:\n            cutoff_lag = lag2_idx\n        else:\n            break\n            \n    sum_rho = 0.0\n    if cutoff_lag > 0:\n        sum_rho = np.sum(rho[1 : cutoff_lag + 1])\n        \n    tau_int = 1.0 + 2.0 * sum_rho\n    return tau_int\n\n\nclass PIMDSimulator:\n    \"\"\"\n    A class to perform PIMD simulations for a 1D particle in a double-well potential.\n    \"\"\"\n    def __init__(self, P, beta, a, b, N_steps, step_size):\n        self.P = P\n        self.beta = beta\n        self.a = a\n        self.b = b\n        self.N_steps = N_steps\n        self.step_size = step_size\n        \n        self.Q = None\n        self.nm_scales = None\n        self.T_st = None\n        self.st_scales = None\n        \n        self._setup_transforms()\n        self.rng = None  # RNG is set before each run for comparability\n\n    def _v_external(self, x):\n        return self.a * (x**2 - self.b**2)**2\n\n    def _u_effective(self, x):\n        diff = x - np.roll(x, -1)\n        # Correct spring potential term based on corrected formula\n        u_spring = (self.P / (2 * self.beta**2)) * np.dot(diff, diff)\n        u_ext = np.sum(self._v_external(x)) / self.P\n        return u_spring + u_ext\n\n    def _setup_transforms(self):\n        # 1. Normal Modes\n        K = 2.0 * np.eye(self.P) - np.eye(self.P, k=1) - np.eye(self.P, k=-1)\n        K[0, -1] = -1.0\n        K[-1, 0] = -1.0\n        \n        lambdas, Q = np.linalg.eigh(K)\n        self.Q = Q\n        \n        self.nm_scales = np.ones(self.P)\n        if self.P > 1:\n            # lambdas[0] is ~0 for the centroid mode. Its scale is kept at 1.\n            # For other modes, scale is 1/sqrt(lambda_k)\n            # Add a small epsilon to avoid division by zero for degenerate eigenvalues\n            # although eigh for this K matrix should be stable.\n            lambdas_safe = np.maximum(lambdas[1:], 1e-15)\n            self.nm_scales[1:] = 1.0 / np.sqrt(lambdas_safe)\n        \n        # 2. Staging\n        # T_st matrix for the inverse transform s -> x\n        T_st_mat = np.zeros((self.P, self.P))\n        T_st_mat[:, 0] = 1.0\n        for j in range(1, self.P):\n            for m in range(1, j + 1):\n                T_st_mat[j, m] = (m + 1.0) / (j + 1.0)\n        self.T_st = T_st_mat\n        \n        self.st_scales = np.ones(self.P)\n        if self.P > 1:\n            j_vals = np.arange(1, self.P)\n            self.st_scales[1:] = np.sqrt(j_vals / (j_vals + 1.0))\n\n    def run(self, mode):\n        # Initialize position at one of the potential minima\n        x = np.full(self.P, self.b)\n        u_eff = self._u_effective(x)\n        \n        potential_energies = np.zeros(self.N_steps)\n        \n        for i in range(self.N_steps):\n            if mode == 'NM':\n                delta_internal = self.step_size * self.rng.normal(size=self.P) * self.nm_scales\n                delta_x = self.Q @ delta_internal\n            elif mode == 'ST':\n                delta_internal = self.step_size * self.rng.normal(size=self.P) * self.st_scales\n                delta_x = self.T_st @ delta_internal\n            else:\n                raise ValueError(\"Invalid mode specified.\")\n\n            x_new = x + delta_x\n            u_eff_new = self._u_effective(x_new)\n            \n            # Metropolis-Hastings acceptance step\n            if u_eff_new  u_eff or self.rng.random()  np.exp(-self.beta * (u_eff_new - u_eff)):\n                x = x_new\n                u_eff = u_eff_new\n\n            potential_energies[i] = np.mean(self._v_external(x))\n            \n        n_burn = int(self.N_steps * BURN_IN_FRACTION)\n        return potential_energies[n_burn:]\n\ndef solve():\n    test_cases = [\n        # (Key, P, beta, a, b, N_steps)\n        ('A', 16, 4.0, 1.0, 1.0, 12000),\n        ('B', 32, 8.0, 1.0, 1.0, 12000),\n        ('C', 24, 2.0, 0.5, 1.2, 12000),\n        ('D', 12, 1.5, 0.25, 0.5, 10000),\n    ]\n\n    results = []\n    \n    for case_key, P, beta, a, b, N_steps in test_cases:\n        step_size = STEP_SIZES[case_key]\n        \n        sim = PIMDSimulator(P=P, beta=beta, a=a, b=b, N_steps=N_steps, step_size=step_size)\n\n        # Run Normal Modes simulation\n        sim.rng = np.random.default_rng(RANDOM_SEED)\n        v_series_nm = sim.run(mode='NM')\n        tau_nm = calculate_iat(v_series_nm)\n\n        # Run Staging simulation\n        sim.rng = np.random.default_rng(RANDOM_SEED)\n        v_series_st = sim.run(mode='ST')\n        tau_st = calculate_iat(v_series_st)\n        \n        if tau_st > 1e-9: # Avoid division by zero\n            ratio = tau_nm / tau_st\n        else:\n            # Handle cases where IAT is ~0 or calculation fails.\n            # If both are zero, ratio is 1. If only ST is zero, NM is less efficient.\n            ratio = float('inf') if tau_nm > 1e-9 else 1.0\n\n        results.append(ratio)\n        \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "In many state-of-the-art applications, such as *ab initio* PIMD, the computational cost of evaluating the potential energy and forces is the primary bottleneck. Ring Polymer Contraction (RPC) is a powerful technique that addresses this by evaluating computationally expensive parts of the potential on a \"contracted\" version of the ring polymer. This exercise provides hands-on experience with implementing different RPC schemes, including centroid and low-pass filter-based contractions, and quantifying the error they introduce in energies and forces, offering insight into the trade-offs between accuracy and computational efficiency .",
            "id": "2914435",
            "problem": "Implement a program that, for a one-dimensional quantum particle in the Path Integral Molecular Dynamics (PIMD) formalism, computes the difference between a full multi-component force evaluation and its Ring Polymer Contraction (RPC) approximation that uses two distinct contraction strategies for two different expensive force components. Work in atomic units, so that reduced Planck constant is $\\hbar = 1$ and Boltzmann constant is $k_{\\mathrm{B}} = 1$. Energies must be expressed in Hartree, lengths in Bohr, and forces in Hartree per Bohr. Angles used inside any trigonometric functions must be in radians.\n\nStart from the imaginary-time path integral discretization into $P$ beads, with inverse temperature $\\beta$, mass $m$, and ring polymer frequency $\\omega_{P} = \\dfrac{P}{\\beta \\hbar} = \\dfrac{P}{\\beta}$. The ring polymer Hamiltonian for a configuration $\\mathbf{q} = (q_{0},\\ldots,q_{P-1})$ is\n$$\nH_{P}(\\mathbf{q},\\mathbf{p}) = \\sum_{j=0}^{P-1} \\left[ \\dfrac{p_{j}^{2}}{2 m} + \\dfrac{1}{2} m \\omega_{P}^{2} \\left(q_{j} - q_{j+1}\\right)^{2} \\right] + \\sum_{j=0}^{P-1} V(q_{j}),\n$$\nwith cyclic boundary $q_{P} \\equiv q_{0}$. The configurational part of the force on bead $j$ is $- \\dfrac{\\partial}{\\partial q_{j}} \\left[ \\sum_{k} \\dfrac{1}{2} m \\omega_{P}^{2} \\left(q_{k} - q_{k+1}\\right)^{2} + \\sum_{k} V(q_{k}) \\right]$.\n\nConsider a decomposition of the potential energy into three components,\n$$\nV(x) = V_{\\mathrm{L}}(x) + \\Delta V_{\\mathrm{A}}(x) + \\Delta V_{\\mathrm{B}}(x),\n$$\nwith the following definitions:\n- Cheap component applied on the full ring polymer:\n$$\nV_{\\mathrm{L}}(x) = \\dfrac{1}{2} k_{\\mathrm{L}} x^{2}.\n$$\n- Expensive component $\\Delta V_{\\mathrm{A}}$ to be contracted to the centroid only (centroid contraction):\n$$\n\\Delta V_{\\mathrm{A}}(x) = \\alpha x^{4}.\n$$\n- Expensive component $\\Delta V_{\\mathrm{B}}$ to be contracted by a low-pass projector in ring polymer normal-mode space (low-pass contraction):\n$$\n\\Delta V_{\\mathrm{B}}(x) = \\dfrac{1}{2} k_{\\mathrm{B}} x^{2}.\n$$\n\nDefine the centroid as\n$$\nq_{\\mathrm{c}} = \\dfrac{1}{P} \\sum_{j=0}^{P-1} q_{j}.\n$$\nDefine the unitary Discrete Fourier Transform (DFT) and its inverse on $\\mathbb{C}^{P}$ by\n$$\n\\hat{\\mathbf{q}}_{k} = \\dfrac{1}{\\sqrt{P}} \\sum_{n=0}^{P-1} q_{n} \\, e^{- 2 \\pi i k n / P}, \\quad\nq_{n} = \\dfrac{1}{\\sqrt{P}} \\sum_{k=0}^{P-1} \\hat{q}_{k} \\, e^{+ 2 \\pi i k n / P},\n$$\nimplemented numerically by scaling the standard DFT and inverse DFT so that the transform is unitary. For a given nonnegative integer cutoff $k_{\\max}$, define the low-pass projector $\\mathcal{P}_{\\mathrm{L}}$ by keeping modes $k \\in \\{0,1,\\ldots,k_{\\max}\\}$ and their complex conjugate partners $P-k$ (when distinct), and zeroing all other modes. The projected coordinates are\n$$\n\\mathbf{q}^{\\mathrm{low}} = \\mathcal{P}_{\\mathrm{L}} \\mathbf{q}.\n$$\nUnder centroid contraction for $\\Delta V_{\\mathrm{A}}$, replace $\\sum_{j=0}^{P-1} \\Delta V_{\\mathrm{A}}(q_{j})$ by $P \\, \\Delta V_{\\mathrm{A}}(q_{\\mathrm{c}})$. Under low-pass contraction for $\\Delta V_{\\mathrm{B}}$, replace $\\sum_{j=0}^{P-1} \\Delta V_{\\mathrm{B}}(q_{j})$ by $\\sum_{j=0}^{P-1} \\Delta V_{\\mathrm{B}}(q^{\\mathrm{low}}_{j})$.\n\nForces must be derived from these approximations. Using the chain rule:\n- The spring force on bead $j$ is\n$$\nF^{\\mathrm{spring}}_{j} = - m \\omega_{P}^{2} \\left(2 q_{j} - q_{j-1} - q_{j+1}\\right).\n$$\n- The cheap component force on bead $j$ is\n$$\nF^{\\mathrm{L}}_{j} = - \\dfrac{\\mathrm{d}}{\\mathrm{d}x} V_{\\mathrm{L}}(x)\\bigg|_{x=q_{j}} = - k_{\\mathrm{L}} q_{j}.\n$$\n- The centroid-contracted force for $\\Delta V_{\\mathrm{A}}$ is\n$$\nF^{\\mathrm{A,RPC}}_{j} = - \\dfrac{\\mathrm{d}}{\\mathrm{d}x} \\left[ P \\, \\Delta V_{\\mathrm{A}}(x) \\right]\\bigg|_{x=q_{\\mathrm{c}}} \\cdot \\dfrac{\\partial q_{\\mathrm{c}}}{\\partial q_{j}} = - 4 \\alpha q_{\\mathrm{c}}^{3}.\n$$\n- The low-pass contracted force for $\\Delta V_{\\mathrm{B}}$ is, with $\\mathbf{g}$ defined beadwise as $g_{j} = \\dfrac{\\mathrm{d}}{\\mathrm{d}x} \\Delta V_{\\mathrm{B}}(x)\\big|_{x=q^{\\mathrm{low}}_{j}} = k_{\\mathrm{B}} q^{\\mathrm{low}}_{j}$,\n$$\n\\mathbf{F}^{\\mathrm{B,RPC}} = - \\mathcal{P}_{\\mathrm{L}} \\, \\mathbf{g}.\n$$\nBecause $\\mathcal{P}_{\\mathrm{L}}$ is an idempotent orthogonal projector constructed from a unitary DFT, this simplifies to\n$$\n\\mathbf{F}^{\\mathrm{B,RPC}} = - k_{\\mathrm{B}} \\, \\mathbf{q}^{\\mathrm{low}}.\n$$\n\nFor comparison, define the full (uncontracted) potential energy and forces by\n$$\nV_{\\mathrm{full}} = \\sum_{j=0}^{P-1} \\left[ \\dfrac{1}{2} m \\omega_{P}^{2} \\left(q_{j} - q_{j+1}\\right)^{2} \\right] + \\sum_{j=0}^{P-1} \\left[ V_{\\mathrm{L}}(q_{j}) + \\Delta V_{\\mathrm{A}}(q_{j}) + \\Delta V_{\\mathrm{B}}(q_{j}) \\right],\n$$\nand\n$$\nF^{\\mathrm{A,full}}_{j} = - \\dfrac{\\mathrm{d}}{\\mathrm{d}x} \\Delta V_{\\mathrm{A}}(x)\\bigg|_{x=q_{j}} = - 4 \\alpha q_{j}^{3}, \\quad\nF^{\\mathrm{B,full}}_{j} = - \\dfrac{\\mathrm{d}}{\\mathrm{d}x} \\Delta V_{\\mathrm{B}}(x)\\bigg|_{x=q_{j}} = - k_{\\mathrm{B}} q_{j}.\n$$\nDefine the RPC-approximated potential as\n$$\nV_{\\mathrm{RPC}} = \\sum_{j=0}^{P-1} \\left[ \\dfrac{1}{2} m \\omega_{P}^{2} \\left(q_{j} - q_{j+1}\\right)^{2} \\right] + \\sum_{j=0}^{P-1} V_{\\mathrm{L}}(q_{j}) + P \\, \\Delta V_{\\mathrm{A}}(q_{\\mathrm{c}}) + \\sum_{j=0}^{P-1} \\Delta V_{\\mathrm{B}}(q^{\\mathrm{low}}_{j}),\n$$\nwith the corresponding total force $\\mathbf{F}_{\\mathrm{RPC}} = \\mathbf{F}^{\\mathrm{spring}} + \\mathbf{F}^{\\mathrm{L}} + \\mathbf{F}^{\\mathrm{A,RPC}} + \\mathbf{F}^{\\mathrm{B,RPC}}$.\n\nYour program must, for each test case listed below, compute:\n- The energy difference $\\Delta E = V_{\\mathrm{RPC}} - V_{\\mathrm{full}}$ in Hartree.\n- The root-mean-square (RMS) force difference\n$$\n\\mathrm{RMS} = \\sqrt{ \\dfrac{1}{P} \\sum_{j=0}^{P-1} \\left( F_{\\mathrm{RPC},j} - F_{\\mathrm{full},j} \\right)^{2} }\n$$\nin Hartree per Bohr.\n\nTest Suite (angles inside sine and cosine are in radians):\n- Case $\\#1$: $P = 8$, $\\beta = 10.0$, $m = 1.0$, $k_{\\mathrm{L}} = 1.5$, $\\alpha = 0.05$, $k_{\\mathrm{B}} = 0.7$, $k_{\\max} = 1$, and bead coordinates\n$$\nq_{j} = 0.3 \\sin\\!\\left( \\dfrac{2 \\pi j}{P} \\right) + 0.1 \\cos\\!\\left( \\dfrac{4 \\pi j}{P} \\right), \\quad j = 0,\\ldots,P-1.\n$$\n- Case $\\#2$: $P = 6$, $\\beta = 4.0$, $m = 2.0$, $k_{\\mathrm{L}} = 0.8$, $\\alpha = 0.2$, $k_{\\mathrm{B}} = 1.1$, $k_{\\max} = 2$, and $q_{j} = 0.2$ for all $j$.\n- Case $\\#3$: $P = 10$, $\\beta = 2.5$, $m = 1.0$, $k_{\\mathrm{L}} = 0.5$, $\\alpha = 0.1$, $k_{\\mathrm{B}} = 2.0$, $k_{\\max} = 1$, and $q_{j} = 0.3 \\, (-1)^{j}$ for all $j$.\n\nFinal Output Format:\n- Your program should produce a single line of output containing a flat list of $2 \\times 3 = 6$ comma-separated floating point numbers enclosed in square brackets. The numbers must appear in the following order: $[\\Delta E_{\\#1}, \\mathrm{RMS}_{\\#1}, \\Delta E_{\\#2}, \\mathrm{RMS}_{\\#2}, \\Delta E_{\\#3}, \\mathrm{RMS}_{\\#3}]$.",
            "solution": "The problem statement is scientifically sound and computationally well-posed. It requires the implementation of the Ring Polymer Contraction (RPC) approximation for a one-dimensional quantum system within the Path Integral Molecular Dynamics (PIMD) formalism and a comparison to the full, uncontracted calculation. We will compute the difference in potential energy, $\\Delta E$, and the root-mean-square (RMS) difference in forces for three specific test cases.\n\nThe objective is to compute two quantities:\n$1$. The difference in potential energy, $\\Delta E = V_{\\mathrm{RPC}} - V_{\\mathrm{full}}$.\n$2$. The root-mean-square force difference, $\\mathrm{RMS} = \\sqrt{ \\dfrac{1}{P} \\sum_{j=0}^{P-1} \\left( F_{\\mathrm{RPC},j} - F_{\\mathrm{full},j} \\right)^{2} }$.\n\nThe total potential energies are given by:\n$$\nV_{\\mathrm{full}} = \\sum_{j=0}^{P-1} \\left[ \\dfrac{1}{2} m \\omega_{P}^{2} \\left(q_{j} - q_{j+1}\\right)^{2} \\right] + \\sum_{j=0}^{P-1} \\left[ V_{\\mathrm{L}}(q_{j}) + \\Delta V_{\\mathrm{A}}(q_{j}) + \\Delta V_{\\mathrm{B}}(q_{j}) \\right]\n$$\n$$\nV_{\\mathrm{RPC}} = \\sum_{j=0}^{P-1} \\left[ \\dfrac{1}{2} m \\omega_{P}^{2} \\left(q_{j} - q_{j+1}\\right)^{2} \\right] + \\sum_{j=0}^{P-1} V_{\\mathrm{L}}(q_{j}) + P \\, \\Delta V_{\\mathrm{A}}(q_{\\mathrm{c}}) + \\sum_{j=0}^{P-1} \\Delta V_{\\mathrm{B}}(q^{\\mathrm{low}}_{j})\n$$\nThe energy difference $\\Delta E$ simplifies, as the harmonic spring term and the cheap potential term $V_{\\mathrm{L}}$ are identical in both expressions and thus cancel:\n$$\n\\Delta E = \\left( P \\, \\Delta V_{\\mathrm{A}}(q_{\\mathrm{c}}) + \\sum_{j=0}^{P-1} \\Delta V_{\\mathrm{B}}(q^{\\mathrm{low}}_{j}) \\right) - \\left( \\sum_{j=0}^{P-1} \\Delta V_{\\mathrm{A}}(q_{j}) + \\sum_{j=0}^{P-1} \\Delta V_{\\mathrm{B}}(q_{j}) \\right)\n$$\nSubstituting the specific potential forms, $\\Delta V_{\\mathrm{A}}(x) = \\alpha x^{4}$ and $\\Delta V_{\\mathrm{B}}(x) = \\dfrac{1}{2} k_{\\mathrm{B}} x^{2}$, we obtain:\n$$\n\\Delta E = \\left( P \\alpha q_{\\mathrm{c}}^{4} + \\sum_{j=0}^{P-1} \\dfrac{1}{2} k_{\\mathrm{B}} (q^{\\mathrm{low}}_{j})^{2} \\right) - \\left( \\sum_{j=0}^{P-1} \\alpha q_{j}^{4} + \\sum_{j=0}^{P-1} \\dfrac{1}{2} k_{\\mathrm{B}} q_{j}^{2} \\right)\n$$\n\nSimilarly, the total forces are:\n$$\nF_{\\mathrm{full},j} = F^{\\mathrm{spring}}_{j} + F^{\\mathrm{L}}_{j} + F^{\\mathrm{A,full}}_{j} + F^{\\mathrm{B,full}}_{j}\n$$\n$$\nF_{\\mathrm{RPC},j} = F^{\\mathrm{spring}}_{j} + F^{\\mathrm{L}}_{j} + F^{\\mathrm{A,RPC}}_{j} + F^{\\mathrm{B,RPC}}_{j}\n$$\nThe force difference on bead $j$, $\\Delta F_{j} = F_{\\mathrm{RPC},j} - F_{\\mathrm{full},j}$, also simplifies because the spring and cheap forces cancel:\n$$\n\\Delta F_{j} = \\left( F^{\\mathrm{A,RPC}}_{j} + F^{\\mathrm{B,RPC}}_{j} \\right) - \\left( F^{\\mathrm{A,full}}_{j} + F^{\\mathrm{B,full}}_{j} \\right)\n$$\nSubstituting the expressions for the forces:\n- $F^{\\mathrm{A,RPC}}_{j} = - 4 \\alpha q_{\\mathrm{c}}^{3}$\n- $F^{\\mathrm{B,RPC}}_{j} = - k_{\\mathrm{B}} q^{\\mathrm{low}}_{j}$\n- $F^{\\mathrm{A,full}}_{j} = - 4 \\alpha q_{j}^{3}$\n- $F^{\\mathrm{B,full}}_{j} = - k_{\\mathrm{B}} q_{j}$\nwe arrive at the expression for the force difference on bead $j$:\n$$\n\\Delta F_{j} = \\left( -4 \\alpha q_{\\mathrm{c}}^{3} - k_{\\mathrm{B}} q^{\\mathrm{low}}_{j} \\right) - \\left( -4 \\alpha q_{j}^{3} - k_{\\mathrm{B}} q_{j} \\right) = 4 \\alpha (q_{j}^{3} - q_{\\mathrm{c}}^{3}) + k_{\\mathrm{B}} (q_{j} - q^{\\mathrm{low}}_{j})\n$$\nThe RMS force difference is then computed over all beads using this $\\Delta \\mathbf{F}$.\n\nThe core of the algorithm is the computation of the centroid $q_{\\mathrm{c}}$ and the low-pass projected coordinates $\\mathbf{q}^{\\mathrm{low}}$.\nGiven a bead configuration vector $\\mathbf{q} = (q_0, \\dots, q_{P-1})$:\n$1$. The centroid is simply the arithmetic mean: $q_{\\mathrm{c}} = \\dfrac{1}{P} \\sum_{j=0}^{P-1} q_{j}$.\n$2$. The low-pass projection $\\mathbf{q}^{\\mathrm{low}} = \\mathcal{P}_{\\mathrm{L}} \\mathbf{q}$ is performed in the ring polymer normal-mode space, which is equivalent to the frequency domain via a Discrete Fourier Transform (DFT). The procedure is as follows:\n    a. Compute the unitary DFT of the bead coordinates: $\\hat{\\mathbf{q}}_{k} = \\dfrac{1}{\\sqrt{P}} \\sum_{n=0}^{P-1} q_{n} e^{-2\\pi i kn/P}$.\n    b. Construct a filter (mask) that is $1$ for the modes to be kept and $0$ otherwise. The modes to be kept are $k \\in \\{0, 1, \\dots, k_{\\max}\\}$ and their complex conjugate partners $P-k$ for $k \\in \\{1, \\dots, k_{\\max}\\}$. For $k=0$, it is its own partner.\n    c. Apply the filter to the transformed coordinates: $\\hat{\\mathbf{q}}^{\\mathrm{low}}_{k} = \\hat{q}_{k} \\cdot \\mathrm{mask}_{k}$.\n    d. Compute the inverse unitary DFT of the filtered coordinates to obtain $\\mathbf{q}^{\\mathrm{low}}$: $q_{n}^{\\mathrm{low}} = \\dfrac{1}{\\sqrt{P}} \\sum_{k=0}^{P-1} \\hat{q}_{k}^{\\mathrm{low}} e^{2\\pi i kn/P}$. Since the input $\\mathbf{q}$ is real and the filter is symmetric, $\\mathbf{q}^{\\mathrm{low}}$ must be real. We take the real part of the result to discard negligible imaginary components arising from floating-point inaccuracies.\n\nThe implementation will proceed by defining a function that takes the parameters of a given test case, constructs the bead coordinate vector $\\mathbf{q}$, computes $q_{\\mathrm{c}}$ and $\\mathbf{q}^{\\mathrm{low}}$, and then evaluates the expressions for $\\Delta E$ and $\\mathrm{RMS}(\\Delta \\mathbf{F})$. This function will be called for each of the three test cases provided.",
            "answer": "```python\nimport numpy as np\n\ndef calculate_quantities(P, beta, m, k_L, alpha, k_B, k_max, q_func):\n    \"\"\"\n    Computes the energy and RMS force differences for a given set of PIMD parameters.\n\n    Args:\n        P (int): Number of beads.\n        beta (float): Inverse temperature.\n        m (float): Mass of the particle.\n        k_L (float): Force constant for the cheap potential V_L.\n        alpha (float): Parameter for the expensive potential Delta V_A.\n        k_B (float): Force constant for the expensive potential Delta V_B.\n        k_max (int): Cutoff for the low-pass projector.\n        q_func (function): A function that takes (j, P) and returns the coordinate q_j.\n\n    Returns:\n        tuple[float, float]: A tuple containing (Delta E, RMS_force_diff).\n    \"\"\"\n\n    # 1. Generate bead coordinates\n    j_indices = np.arange(P, dtype=float)\n    q = q_func(j_indices, P)\n\n    # 2. Calculate intermediate quantities: centroid and low-pass coordinates\n    # 2a. Calculate centroid\n    q_c = np.mean(q)\n\n    # 2b. Calculate low-pass projected coordinates q_low\n    # Unitary DFT\n    q_hat = np.fft.fft(q) / np.sqrt(P)\n\n    # Create the low-pass filter mask\n    mask = np.zeros(P)\n    # Keep modes k = 0, 1, ..., k_max\n    mask[0 : k_max + 1] = 1\n    # Keep partner modes P-k for k = 1, ..., k_max\n    if k_max > 0:\n        mask[P - k_max : P] = 1\n\n    # Apply mask\n    q_hat_low = q_hat * mask\n\n    # Unitary inverse DFT\n    q_low = (np.fft.ifft(q_hat_low) * np.sqrt(P)).real\n\n    # 3. Calculate energy difference Delta E = V_RPC - V_full\n    # The spring and V_L terms cancel, so we only need the expensive parts.\n    # V_A_RPC = P * alpha * q_c^4\n    # V_B_RPC = sum(0.5 * k_B * q_low**2)\n    # V_A_full = sum(alpha * q**4)\n    # V_B_full = sum(0.5 * k_B * q**2)\n    \n    V_RPC = P * alpha * q_c**4 + 0.5 * k_B * np.sum(q_low**2)\n    V_full = alpha * np.sum(q**4) + 0.5 * k_B * np.sum(q**2)\n    \n    delta_E = V_RPC - V_full\n\n    # 4. Calculate RMS force difference\n    # Force difference Delta_F_j = (F_A_RPC_j + F_B_RPC_j) - (F_A_full_j + F_B_full_j)\n    # Delta_F_j = (-4*alpha*q_c^3 - k_B*q_low_j) - (-4*alpha*q_j^3 - k_B*q_j)\n    # Delta_F_j = 4*alpha*(q_j^3 - q_c^3) + k_B*(q_j - q_low_j)\n    \n    delta_F = 4.0 * alpha * (q**3 - q_c**3) + k_B * (q - q_low)\n    \n    rms_force_diff = np.sqrt(np.mean(delta_F**2))\n\n    return delta_E, rms_force_diff\n\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    # Test cases defined in the problem statement\n    test_cases = [\n        {\n            \"P\": 8, \"beta\": 10.0, \"m\": 1.0, \"k_L\": 1.5, \"alpha\": 0.05, \"k_B\": 0.7, \"k_max\": 1,\n            \"q_func\": lambda j, P: 0.3 * np.sin(2 * np.pi * j / P) + 0.1 * np.cos(4 * np.pi * j / P)\n        },\n        {\n            \"P\": 6, \"beta\": 4.0, \"m\": 2.0, \"k_L\": 0.8, \"alpha\": 0.2, \"k_B\": 1.1, \"k_max\": 2,\n            \"q_func\": lambda j, P: 0.2 * np.ones_like(j, dtype=float)\n        },\n        {\n            \"P\": 10, \"beta\": 2.5, \"m\": 1.0, \"k_L\": 0.5, \"alpha\": 0.1, \"k_B\": 2.0, \"k_max\": 1,\n            \"q_func\": lambda j, P: 0.3 * (-1.0)**j\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        delta_E, rms_force_diff = calculate_quantities(\n            P=case[\"P\"],\n            beta=case[\"beta\"],\n            m=case[\"m\"],\n            k_L=case[\"k_L\"],\n            alpha=case[\"alpha\"],\n            k_B=case[\"k_B\"],\n            k_max=case[\"k_max\"],\n            q_func=case[\"q_func\"]\n        )\n        results.extend([delta_E, rms_force_diff])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.10f}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}