{
    "hands_on_practices": [
        {
            "introduction": "The foundation of Variational Monte Carlo (VMC) rests upon evaluating the expectation value of the Hamiltonian using a trial wavefunction. This practice takes you back to first principles by applying this idea to the simplest quantum system: the hydrogen atom. By analytically deriving the local energy $E_L(\\mathbf{r})$ and its variance, you will gain a concrete understanding of how the quality of the trial wavefunction directly relates to the accuracy and efficiency of a VMC calculation .",
            "id": "3799579",
            "problem": "Consider the nonrelativistic hydrogen atom in atomic units, with Hamiltonian $H$ acting on a single electron moving in the Coulomb field of a point nucleus of charge $Z=1$, defined by $H = -\\frac{1}{2}\\nabla^{2} - \\frac{1}{r}$. In a Variational Monte Carlo (VMC) calculation, the local energy $E_L(\\mathbf{r})$ associated with a trial wavefunction $\\psi_T(\\mathbf{r};\\alpha)$ is defined by $E_L(\\mathbf{r}) = \\frac{H\\psi_T(\\mathbf{r};\\alpha)}{\\psi_T(\\mathbf{r};\\alpha)}$. As a simple baseline for multiscale model validation, use the spherically symmetric exponential ansatz $\\psi_T(\\mathbf{r};\\alpha) = \\mathcal{N}\\exp(-\\alpha r)$, where $\\alpha>0$ is a variational parameter and $\\mathcal{N}$ is a normalization constant chosen so that $\\int |\\psi_T(\\mathbf{r};\\alpha)|^{2}\\,\\mathrm{d}^{3}\\mathbf{r} = 1$.\n\nStarting from the fundamental definitions given above and the hydrogenic Hamiltonian in atomic units, analytically derive the local energy $E_L(r)$ for this ansatz and compute the expectation values $\\langle E_L\\rangle$ and $\\langle E_L^{2}\\rangle$ with respect to the probability density $|\\psi_T(\\mathbf{r};\\alpha)|^{2}$. Then obtain the variance of the local energy,\n$$\\sigma^{2}(\\alpha) = \\langle E_L^{2}\\rangle - \\langle E_L\\rangle^{2},$$\nas a closed-form expression in terms of $\\alpha$.\n\nExpress your final answer as a single analytic expression for $\\sigma^{2}(\\alpha)$ in atomic units. No numerical rounding is required.",
            "solution": "The problem asks for the variance of the local energy, $\\sigma^{2}(\\alpha)$, for a hydrogenic atom with nuclear charge $Z=1$ described by a trial wavefunction $\\psi_T(\\mathbf{r};\\alpha) = \\mathcal{N}\\exp(-\\alpha r)$. The variance is defined as $\\sigma^{2}(\\alpha) = \\langle E_L^{2}\\rangle - \\langle E_L\\rangle^{2}$. To compute this, we must first derive the local energy $E_L(r)$, and then find the expectation values $\\langle E_L\\rangle$ and $\\langle E_L^{2}\\rangle$.\n\nFirst, we derive the expression for the local energy, $E_L(\\mathbf{r}) = \\frac{H\\psi_T(\\mathbf{r};\\alpha)}{\\psi_T(\\mathbf{r};\\alpha)}$.\nThe Hamiltonian for the hydrogen atom in atomic units is $H = -\\frac{1}{2}\\nabla^{2} - \\frac{1}{r}$.\nThe trial wavefunction $\\psi_T(r) = \\mathcal{N}\\exp(-\\alpha r)$ is spherically symmetric. The action of the Laplacian operator, $\\nabla^{2}$, on a spherically symmetric function $f(r)$ is given by $\\nabla^{2}f(r) = \\frac{1}{r^{2}}\\frac{d}{dr}\\left(r^{2}\\frac{df}{dr}\\right) = \\frac{d^{2}f}{dr^{2}} + \\frac{2}{r}\\frac{df}{dr}$.\n\nLet's apply the Laplacian to $\\psi_T(r)$.\nThe first derivative with respect to $r$ is:\n$$\\frac{d\\psi_T}{dr} = \\frac{d}{dr}(\\mathcal{N}\\exp(-\\alpha r)) = -\\alpha \\mathcal{N}\\exp(-\\alpha r) = -\\alpha \\psi_T$$\nThe second derivative is:\n$$\\frac{d^{2}\\psi_T}{dr^{2}} = \\frac{d}{dr}(-\\alpha \\psi_T) = (-\\alpha)(-\\alpha \\psi_T) = \\alpha^{2}\\psi_T$$\nNow, we can compute $\\nabla^2 \\psi_T$:\n$$\\nabla^{2}\\psi_T = \\frac{d^{2}\\psi_T}{dr^{2}} + \\frac{2}{r}\\frac{d\\psi_T}{dr} = \\alpha^{2}\\psi_T + \\frac{2}{r}(-\\alpha\\psi_T) = \\left(\\alpha^{2} - \\frac{2\\alpha}{r}\\right)\\psi_T$$\nNext, we apply the full Hamiltonian $H$ to $\\psi_T$:\n$$H\\psi_T = \\left(-\\frac{1}{2}\\nabla^{2} - \\frac{1}{r}\\right)\\psi_T = -\\frac{1}{2}\\left(\\alpha^{2} - \\frac{2\\alpha}{r}\\right)\\psi_T - \\frac{1}{r}\\psi_T$$\n$$H\\psi_T = \\left(-\\frac{\\alpha^{2}}{2} + \\frac{\\alpha}{r} - \\frac{1}{r}\\right)\\psi_T = \\left(-\\frac{\\alpha^{2}}{2} + \\frac{\\alpha - 1}{r}\\right)\\psi_T$$\nThe local energy $E_L(r)$ is the ratio of $H\\psi_T$ to $\\psi_T$:\n$$E_L(r) = \\frac{H\\psi_T}{\\psi_T} = -\\frac{\\alpha^{2}}{2} + \\frac{\\alpha - 1}{r}$$\nNote that the local energy is independent of the normalization constant $\\mathcal{N}$ and depends only on the radial coordinate $r$.\n\nNext, we need to compute the expectation values $\\langle E_L\\rangle$ and $\\langle E_L^{2}\\rangle$ with respect to the probability density $p(\\mathbf{r}) = |\\psi_T(\\mathbf{r})|^{2}$. An expectation value of a function $f(\\mathbf{r})$ is given by $\\langle f \\rangle = \\int f(\\mathbf{r}) p(\\mathbf{r}) \\,\\mathrm{d}^{3}\\mathbf{r}$.\nThe probability density is $|\\psi_T(r)|^{2} = \\mathcal{N}^{2}\\exp(-2\\alpha r)$. To proceed, we must determine the normalization constant $\\mathcal{N}$ from the condition $\\int |\\psi_T|^{2}\\,\\mathrm{d}^{3}\\mathbf{r} = 1$.\nIn spherical coordinates, $\\mathrm{d}^{3}\\mathbf{r} = r^{2}\\sin\\theta\\,\\mathrm{d}r\\,\\mathrm{d}\\theta\\,\\mathrm{d}\\phi$. Integrating over the angular variables yields a factor of $4\\pi$.\n$$1 = \\int_{0}^{\\infty} \\mathcal{N}^{2}\\exp(-2\\alpha r) (4\\pi r^{2})\\,\\mathrm{d}r = 4\\pi\\mathcal{N}^{2} \\int_{0}^{\\infty} r^{2}\\exp(-2\\alpha r)\\,\\mathrm{d}r$$\nWe use the standard integral formula $\\int_{0}^{\\infty} x^{n}\\exp(-ax)\\,\\mathrm{d}x = \\frac{n!}{a^{n+1}}$. For $n=2$ and $a=2\\alpha$:\n$$\\int_{0}^{\\infty} r^{2}\\exp(-2\\alpha r)\\,\\mathrm{d}r = \\frac{2!}{(2\\alpha)^{3}} = \\frac{2}{8\\alpha^{3}} = \\frac{1}{4\\alpha^{3}}$$\nSubstituting this into the normalization equation:\n$$1 = 4\\pi\\mathcal{N}^{2}\\left(\\frac{1}{4\\alpha^{3}}\\right) = \\frac{\\pi\\mathcal{N}^{2}}{\\alpha^{3}} \\quad \\implies \\quad \\mathcal{N}^{2} = \\frac{\\alpha^{3}}{\\pi}$$\nThe normalized probability density is thus $p(r) = |\\psi_T(r)|^{2} = \\frac{\\alpha^{3}}{\\pi}\\exp(-2\\alpha r)$.\n\nNow we compute $\\langle E_L\\rangle$:\n$$\\langle E_L\\rangle = \\left\\langle -\\frac{\\alpha^{2}}{2} + \\frac{\\alpha - 1}{r} \\right\\rangle = -\\frac{\\alpha^{2}}{2} + (\\alpha - 1)\\left\\langle \\frac{1}{r} \\right\\rangle$$\nWe need to calculate $\\langle \\frac{1}{r} \\rangle$:\n$$\\left\\langle \\frac{1}{r} \\right\\rangle = \\int_{0}^{\\infty} \\frac{1}{r} p(r) (4\\pi r^{2})\\,\\mathrm{d}r = \\int_{0}^{\\infty} \\frac{1}{r} \\left(\\frac{\\alpha^{3}}{\\pi}\\exp(-2\\alpha r)\\right) (4\\pi r^{2})\\,\\mathrm{d}r = 4\\alpha^{3}\\int_{0}^{\\infty} r\\exp(-2\\alpha r)\\,\\mathrm{d}r$$\nUsing the integral formula with $n=1$ and $a=2\\alpha$:\n$$\\int_{0}^{\\infty} r\\exp(-2\\alpha r)\\,\\mathrm{d}r = \\frac{1!}{(2\\alpha)^{2}} = \\frac{1}{4\\alpha^{2}}$$\nSo, $\\langle \\frac{1}{r} \\rangle = 4\\alpha^{3}\\left(\\frac{1}{4\\alpha^{2}}\\right) = \\alpha$.\nSubstituting this back into the expression for $\\langle E_L\\rangle$:\n$$\\langle E_L\\rangle = -\\frac{\\alpha^{2}}{2} + (\\alpha - 1)\\alpha = -\\frac{\\alpha^{2}}{2} + \\alpha^{2} - \\alpha = \\frac{\\alpha^{2}}{2} - \\alpha$$\n\nNext, we compute $\\langle E_L^{2}\\rangle$:\n$$E_L(r)^{2} = \\left(-\\frac{\\alpha^{2}}{2} + \\frac{\\alpha - 1}{r}\\right)^{2} = \\frac{\\alpha^{4}}{4} - 2\\left(\\frac{\\alpha^{2}}{2}\\right)\\left(\\frac{\\alpha - 1}{r}\\right) + \\frac{(\\alpha - 1)^{2}}{r^{2}} = \\frac{\\alpha^{4}}{4} - \\frac{\\alpha^{2}(\\alpha - 1)}{r} + \\frac{(\\alpha - 1)^{2}}{r^{2}}$$\nTaking the expectation value:\n$$\\langle E_L^{2}\\rangle = \\left\\langle \\frac{\\alpha^{4}}{4} - \\frac{\\alpha^{2}(\\alpha - 1)}{r} + \\frac{(\\alpha - 1)^{2}}{r^{2}} \\right\\rangle = \\frac{\\alpha^{4}}{4} - \\alpha^{2}(\\alpha - 1)\\left\\langle \\frac{1}{r} \\right\\rangle + (\\alpha - 1)^{2}\\left\\langle \\frac{1}{r^{2}} \\right\\rangle$$\nWe need to calculate $\\langle \\frac{1}{r^{2}} \\rangle$:\n$$\\left\\langle \\frac{1}{r^{2}} \\right\\rangle = \\int_{0}^{\\infty} \\frac{1}{r^{2}} p(r) (4\\pi r^{2})\\,\\mathrm{d}r = \\int_{0}^{\\infty} \\frac{1}{r^{2}}\\left(\\frac{\\alpha^{3}}{\\pi}\\exp(-2\\alpha r)\\right)(4\\pi r^{2})\\,\\mathrm{d}r = 4\\alpha^{3}\\int_{0}^{\\infty} \\exp(-2\\alpha r)\\,\\mathrm{d}r$$\nUsing the integral formula with $n=0$ and $a=2\\alpha$:\n$$\\int_{0}^{\\infty} \\exp(-2\\alpha r)\\,\\mathrm{d}r = \\frac{0!}{(2\\alpha)^{1}} = \\frac{1}{2\\alpha}$$\nSo, $\\langle \\frac{1}{r^{2}} \\rangle = 4\\alpha^{3}\\left(\\frac{1}{2\\alpha}\\right) = 2\\alpha^{2}$.\nSubstituting $\\langle \\frac{1}{r} \\rangle = \\alpha$ and $\\langle \\frac{1}{r^{2}} \\rangle = 2\\alpha^{2}$ into the expression for $\\langle E_L^{2}\\rangle$:\n$$\\langle E_L^{2}\\rangle = \\frac{\\alpha^{4}}{4} - \\alpha^{2}(\\alpha - 1)(\\alpha) + (\\alpha - 1)^{2}(2\\alpha^{2})$$\n$$\\langle E_L^{2}\\rangle = \\frac{\\alpha^{4}}{4} - \\alpha^{3}(\\alpha - 1) + 2\\alpha^{2}(\\alpha^{2} - 2\\alpha + 1)$$\n$$\\langle E_L^{2}\\rangle = \\frac{\\alpha^{4}}{4} - \\alpha^{4} + \\alpha^{3} + 2\\alpha^{4} - 4\\alpha^{3} + 2\\alpha^{2}$$\n$$\\langle E_L^{2}\\rangle = \\left(\\frac{1}{4} - 1 + 2\\right)\\alpha^{4} + (1 - 4)\\alpha^{3} + 2\\alpha^{2} = \\frac{5}{4}\\alpha^{4} - 3\\alpha^{3} + 2\\alpha^{2}$$\n\nFinally, we compute the variance $\\sigma^{2}(\\alpha) = \\langle E_L^{2}\\rangle - \\langle E_L\\rangle^{2}$.\nWe have $\\langle E_L\\rangle = \\frac{\\alpha^{2}}{2} - \\alpha$. So,\n$$\\langle E_L\\rangle^{2} = \\left(\\frac{\\alpha^{2}}{2} - \\alpha\\right)^{2} = \\left(\\frac{\\alpha^{2}}{2}\\right)^{2} - 2\\left(\\frac{\\alpha^{2}}{2}\\right)(\\alpha) + \\alpha^{2} = \\frac{\\alpha^{4}}{4} - \\alpha^{3} + \\alpha^{2}$$\nNow, subtract this from $\\langle E_L^{2}\\rangle$:\n$$\\sigma^{2}(\\alpha) = \\left(\\frac{5}{4}\\alpha^{4} - 3\\alpha^{3} + 2\\alpha^{2}\\right) - \\left(\\frac{\\alpha^{4}}{4} - \\alpha^{3} + \\alpha^{2}\\right)$$\n$$\\sigma^{2}(\\alpha) = \\left(\\frac{5}{4} - \\frac{1}{4}\\right)\\alpha^{4} + (-3 + 1)\\alpha^{3} + (2 - 1)\\alpha^{2}$$\n$$\\sigma^{2}(\\alpha) = \\frac{4}{4}\\alpha^{4} - 2\\alpha^{3} + \\alpha^{2} = \\alpha^{4} - 2\\alpha^{3} + \\alpha^{2}$$\nThis expression can be factored:\n$$\\sigma^{2}(\\alpha) = \\alpha^{2}(\\alpha^{2} - 2\\alpha + 1) = \\alpha^{2}(\\alpha - 1)^{2}$$\n\nThe variance of the local energy is zero when $\\alpha = 1$, which is the case where the trial wavefunction becomes the exact ground state wavefunction of the hydrogen atom, $\\psi_{1s} \\propto \\exp(-r)$. For an exact eigenstate, the local energy is constant and equal to the eigenvalue, and thus its variance is zero.",
            "answer": "$$\\boxed{\\alpha^2(\\alpha - 1)^2}$$"
        },
        {
            "introduction": "While Diffusion Monte Carlo (DMC) can, in principle, find the exact ground-state energy, for fermionic systems this requires confronting the notorious fermion sign problem. This challenge is overcome by the fixed-node approximation, which constrains the DMC simulation based on the nodes of a trial wavefunction. This exercise provides a powerful and intuitive demonstration of the consequences of this approximation, showing how an error in the nodal position for a simple particle-in-a-box model leads to a predictable and understandable error in the final energy .",
            "id": "2461100",
            "problem": "Consider a single electron of mass $m$ confined in a one-dimensional ($1\\mathrm{D}$) infinite potential well of length $L$, with $V(x)=0$ for $0<x<L$ and $V(x)=\\infty$ otherwise. You perform a fixed-node Diffusion Monte Carlo (DMC) simulation, in which the nodal surface of the trial wave function is imposed as an absorbing boundary. The exact first excited state of the well has a single internal node at $x=L/2$. Suppose, however, that your trial wave function has its single internal node misplaced at $x=0.6\\,L$ (that is, shifted by $+0.1\\,L$, i.e., $10\\%$ of the box length, from the exact location). Let $E_0$ denote the exact ground-state energy of the full well.\n\nWhich statement best describes the long-imaginary-time behavior of the DMC simulation under these conditions?\n\nA. The projected energy converges to $E_0$, since a single electron has no fermionic sign problem, and the walkers effectively ignore the spurious internal node.\n\nB. The projected energy converges to a fixed-node upper bound $E_{\\mathrm{FN}}\\approx E_0/0.6^2\\approx 2.78\\,E_0$, with walkers confined to two nodal pockets that they cannot cross; asymptotically, the pocket of length $0.6\\,L$ dominates.\n\nC. The projected energy converges to $4\\,E_0$, matching the exact $n=2$ excited state, because any interior node enforces $n=2$ character regardless of its position.\n\nD. The projected energy becomes variationally lower than $E_0$ (e.g., near $0.9\\,E_0$) because the additional node increases variational flexibility.\n\nE. The simulation fails to equilibrate, with walkers repeatedly crossing the misplaced node so that the energy fluctuates without converging.",
            "solution": "The problem statement is scrutinized for validity.\n\n**Step 1: Extract Givens**\n- System: A single electron of mass $m$.\n- Potential: A one-dimensional ($1\\mathrm{D}$) infinite potential well of length $L$.\n- Potential definition: $V(x)=0$ for $0 < x < L$ and $V(x)=\\infty$ otherwise.\n- Simulation method: Fixed-node Diffusion Monte Carlo (DMC).\n- Fixed-node constraint: The nodal surface of the trial wave function is an absorbing boundary.\n- Trial wave function: Contains a single internal node at the position $x = 0.6\\,L$.\n- Reference energy: $E_0$ is defined as the exact ground-state energy of the full well of length $L$.\n- Exact reference state: The first excited state of the well has its node at $x=L/2$.\n- Question: Determine the long-imaginary-time behavior of the DMC projected energy.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem describes a standard application of the fixed-node DMC method to a canonical quantum mechanical system, the particle in an infinite well. The setup is scientifically grounded in the principles of quantum mechanics and computational chemistry. The use of a trial wave function with an inexact nodal position is a common scenario for analyzing the properties of the fixed-node approximation. The problem is well-posed, as the long-time behavior of a DMC simulation under these constraints leads to a unique, well-defined energy. All terms are defined, and the data are consistent. No scientific, logical, or factual flaws are present.\n\n**Step 3: Verdict and Action**\nThe problem statement is determined to be **valid**. The solution will now be derived from first principles.\n\nThe energy eigenvalues for a particle of mass $m$ in a one-dimensional infinite potential well of length $L'$ are given by the formula:\n$$ E_n' = \\frac{n^2 \\pi^2 \\hbar^2}{2m (L')^2}, \\quad n = 1, 2, 3, \\dots $$\nFor the given problem, the well has length $L$. The exact ground-state energy ($n=1$) is denoted as $E_0$.\n$$ E_0 = \\frac{(1)^2 \\pi^2 \\hbar^2}{2m L^2} = \\frac{\\pi^2 \\hbar^2}{2m L^2} $$\nThe exact first excited state ($n=2$) has energy $E_2$:\n$$ E_2 = \\frac{(2)^2 \\pi^2 \\hbar^2}{2m L^2} = 4 \\left( \\frac{\\pi^2 \\hbar^2}{2m L^2} \\right) = 4\\,E_0 $$\nThis first excited state has a wave function $\\psi_2(x) = \\sqrt{2/L} \\sin(2\\pi x/L)$, which possesses a single node at $x=L/2$.\n\nThe fixed-node Diffusion Monte Carlo (DMC) method solves the time-dependent Schrödinger equation in imaginary time $\\tau = it/\\hbar$. A key feature is the fixed-node approximation, where the nodes of a given trial wave function, $\\Psi_T$, are imposed on the solution. These nodes act as infinite potential barriers, or absorbing boundaries, for the walkers (which represent the a particle's probability amplitude). Any walker attempting to cross a node is removed from the simulation.\n\nIn this problem, the trial wave function has a single node at $x=0.6\\,L$. This imposed boundary condition effectively divides the original box of length $L$ into two independent, smaller infinite potential wells:\n1.  **Pocket 1:** A well of length $L_1 = 0.6\\,L$, defined on the interval $(0, 0.6\\,L)$.\n2.  **Pocket 2:** A well of length $L_2 = L - 0.6\\,L = 0.4\\,L$, defined on the interval $(0.6\\,L, L)$.\n\nThe DMC simulation seeks the lowest energy eigenstate consistent with these boundary conditions. This corresponds to the ground state of the system composed of these two non-communicating pockets. The walkers will populate both pockets initially, but the simulation will evolve. The population in each pocket will grow or decay according to its ground-state energy. The ground-state energy of each pocket is:\n- For Pocket 1:\n$$ E_{p1} = \\frac{\\pi^2 \\hbar^2}{2m (L_1)^2} = \\frac{\\pi^2 \\hbar^2}{2m (0.6\\,L)^2} = \\frac{1}{(0.6)^2} \\frac{\\pi^2 \\hbar^2}{2m L^2} = \\frac{1}{0.36} E_0 \\approx 2.78\\,E_0 $$\n- For Pocket 2:\n$$ E_{p2} = \\frac{\\pi^2 \\hbar^2}{2m (L_2)^2} = \\frac{\\pi^2 \\hbar^2}{2m (0.4\\,L)^2} = \\frac{1}{(0.4)^2} \\frac{\\pi^2 \\hbar^2}{2m L^2} = \\frac{1}{0.16} E_0 = 6.25\\,E_0 $$\n\nIn the long-imaginary-time limit ($\\tau \\to \\infty$), the population of walkers in the pocket with the lower ground-state energy will dominate exponentially over the population in the higher-energy pocket. Since $E_{p1} < E_{p2}$, the walkers in Pocket 2 will eventually all be removed from the simulation relative to the population in Pocket 1. The simulation will therefore converge to a state where all walkers are confined to Pocket 1. The projected energy of the system will converge to the ground-state energy of this dominant pocket.\n$$ E_{\\mathrm{FN}} = E_{p1} \\approx 2.78\\,E_0 $$\nThis energy, $E_{\\mathrm{FN}}$, is the fixed-node energy. According to the fixed-node theorem, this energy is a strict upper bound to the true ground-state energy, $E_0$. This is clearly satisfied since $2.78\\,E_0 > E_0$. It is also known that for an excited state calculation, an incorrect nodal surface yields an energy that is not necessarily an upper bound to the true excited-state energy ($E_2 = 4\\,E_0$). Indeed, our result $E_{\\mathrm{FN}} \\approx 2.78\\,E_0$ is less than $E_2$.\n\nNow we evaluate the given options.\n\n**A. The projected energy converges to $E_0$, since a single electron has no fermionic sign problem, and the walkers effectively ignore the spurious internal node.**\nThis is **Incorrect**. The presence of a node in the trial wave function, regardless of the cause, is strictly enforced in a fixed-node DMC simulation. Walkers do not ignore the node; they are absorbed by it. The simulation finds the ground state energy compatible with the nodal constraint, which is necessarily higher than the true ground state energy $E_0$. The lack of a fermionic sign problem is irrelevant to the enforcement of the fixed-node approximation itself.\n\n**B. The projected energy converges to a fixed-node upper bound $E_{\\mathrm{FN}}\\approx E_0/0.6^2\\approx 2.78\\,E_0$, with walkers confined to two nodal pockets that they cannot cross; asymptotically, the pocket of length $0.6\\,L$ dominates.**\nThis is **Correct**. The analysis matches the derivation perfectly. The fixed-node constraint creates two pockets. The final energy is determined by the lowest-energy pocket, which is the larger one of length $0.6\\,L$. The calculation $E_{\\mathrm{FN}} = E_0/(0.6)^2 \\approx 2.78\\,E_0$ is correct. The description of the walker dynamics—confinement and dominance of the lower-energy pocket—is also accurate. The term \"fixed-node upper bound\" is appropriate, as $E_{\\mathrm{FN}}$ is an upper bound to the true ground-state energy $E_0$.\n\n**C. The projected energy converges to $4\\,E_0$, matching the exact $n=2$ excited state, because any interior node enforces $n=2$ character regardless of its position.**\nThis is **Incorrect**. The energy converges to $4\\,E_0$ only if the node of the trial wave function is placed at the exact position for the $n=2$ state, which is $x=L/2$. A misplaced node, as in this problem, leads to an incorrect energy. The position of the node is critical. For any nodal position other than the exact one, the resulting fixed-node energy is different from the true eigenvalue.\n\n**D. The projected energy becomes variationally lower than $E_0$ (e.g., near $0.9\\,E_0$) because the additional node increases variational flexibility.**\nThis is **Incorrect**. Any fixed-node DMC calculation must yield an energy greater than or equal to the true ground-state energy $E_0$. Imposing a node is a constraint that *reduces* variational flexibility and *increases* the energy relative to the nodeless ground state. One cannot obtain an energy lower than $E_0$. The calculated energy is $\\approx 2.78\\,E_0$, which is significantly higher than $E_0$.\n\n**E. The simulation fails to equilibrate, with walkers repeatedly crossing the misplaced node so that the energy fluctuates without converging.**\nThis is **Incorrect**. This statement fundamentally misunderstands the fixed-node DMC method. The very purpose of the fixed-node constraint is to prevent walkers from crossing the node. The boundary is absorbing. This leads to a stable, well-defined equilibrium state and a converged energy. The simulation will equilibrate.",
            "answer": "$$\\boxed{B}$$"
        },
        {
            "introduction": "Both VMC and DMC produce a time-series of energy values that are serially correlated, meaning each data point is not statistically independent of its neighbors. Naively computing the standard error of the mean ignores this correlation and can lead to a drastic underestimation of the true uncertainty. This advanced practice guides you through the industry-standard blocking method, an essential statistical technique for obtaining asymptotically unbiased error bars from correlated Monte Carlo data, ensuring the credibility of your final results .",
            "id": "3897159",
            "problem": "A catalytic reaction barrier on a heterogeneous surface is computed with Variational Monte Carlo (VMC) and Diffusion Monte Carlo (DMC) to benchmark electronic structure models used in computational catalysis and chemical engineering. The quantity of interest is the time-series of local energies $\\{E_t\\}_{t=1}^N$ sampled along a Markov chain after equilibration, where $N$ is the number of post-equilibration time steps. In DMC, walker branching induces per-time-step weights $\\{w_t\\}_{t=1}^N$ and it is standard to report the per-time-step weighted average local energy $X_t = \\sum_{i} w_{t,i} E_{t,i} / \\sum_{i} w_{t,i}$, where $i$ indexes walkers at time $t$, yielding a scalar series $\\{X_t\\}_{t=1}^N$ analogous to $\\{E_t\\}_{t=1}^N$ in VMC.\n\nYou must construct a blocking analysis procedure to produce asymptotically unbiased error bars for the sample mean of the time-series, and justify the choice of block size based on autocorrelation diagnostics. Use as fundamental base the Central Limit Theorem (CLT) for weakly dependent sequences, the definition of the normalized autocorrelation function $\\rho(k)$ at lag $k$, and the integrated autocorrelation time $\\tau_{\\mathrm{int}}$. Assume the following scientifically plausible setting:\n\n- The post-equilibration series length is $N = 131072$.\n- The normalized autocorrelation function is well fit by $\\rho(k) \\approx \\exp(-k / 50)$ for integer $k \\ge 0$.\n- The time step is uniform and the series is stationary after discarding equilibration.\n\nYour goal is to select the most appropriate procedure among the options below that guarantees asymptotically unbiased error bars for both VMC and DMC, and to justify its choice of block size using the autocorrelation diagnostics implied by the given $\\rho(k)$.\n\nWhich option best satisfies these requirements?\n\nA. Discard equilibration to obtain a stationary series and compute the sample autocorrelation function $\\rho(k)$ on $\\{E_t\\}$ (VMC) or $\\{X_t\\}$ (DMC). Estimate the integrated autocorrelation time $\\tau_{\\mathrm{int}}$ using the initial positive sequence estimator, then choose an initial block size $b_0 \\approx 4 \\tau_{\\mathrm{int}}$. Perform recursive reblocking with $b_\\ell = 2^\\ell b_0$ for $\\ell = 0, 1, 2, \\dots$ and, at each $\\ell$, compute the sample variance $s_{Y(\\ell)}^2$ of the block means $\\{Y_j^{(\\ell)}\\}_{j=1}^{m_\\ell}$, where $m_\\ell = N / b_\\ell$ is the number of blocks. Identify the smallest $\\ell$ such that $s_{Y(\\ell)}^2$ has reached a plateau with $m_\\ell \\ge 30$, then report the standard error of the overall mean as $s_{Y(\\ell)} / \\sqrt{m_\\ell}$. For DMC, form $\\{X_t\\}$ via descendant weighting or population reconfiguration to stabilize total weight, then apply the same blocking scheme to $\\{X_t\\}$.\n\nB. Treat all samples as independent, set the block size $b = 1$, and report the standard error as $s / \\sqrt{N}$, where $s^2$ is the sample variance of $\\{E_t\\}$ (VMC) or $\\{X_t\\}$ (DMC), without computing autocorrelations or performing any blocking.\n\nC. Fit $\\rho(k)$ to an exponential to obtain the correlation time $\\tau \\approx 50$ and choose a single fixed block size $b \\approx \\tau$. Compute block means with this $b$ and report the standard error as the sample standard deviation of block means divided by $\\sqrt{m}$, where $m = N / b$, skipping any plateau diagnostics or adjustments based on $m$.\n\nD. Choose an extremely large block size $b$ so that $m = N / b < 10$ to ensure complete decorrelation between blocks. Report the standard error as the sample standard deviation of block means divided by $\\sqrt{m}$, disregarding the small number of blocks and any variance plateau diagnostics.\n\nE. Use overlapping moving averages of window length $b$ to construct overlapping block means that increase the number of blocks beyond $m = N / b$. Treat the overlapping block means as independent, select $b$ by minimizing the empirical standard error, and report that minimized value as the error bar, without computing $\\rho(k)$ or $\\tau_{\\mathrm{int}}$.\n\nAnswer by selecting the single best option.",
            "solution": "The user requires a critical validation of the provided problem statement followed by a full derivation of the solution and an evaluation of all options.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n-   **Methodology**: Variational Monte Carlo (VMC) and Diffusion Monte Carlo (DMC) for computing a catalytic reaction barrier.\n-   **Data Series**: A time-series of local energies $\\{E_t\\}_{t=1}^N$ for VMC, and a time-series of weighted average local energies $\\{X_t\\}_{t=1}^N$ for DMC, where $X_t = \\sum_{i} w_{t,i} E_{t,i} / \\sum_{i} w_{t,i}$.\n-   **State**: The series is sampled after equilibration and is stationary.\n-   **Series Length**: $N = 131072$.\n-   **Autocorrelation Model**: The normalized autocorrelation function is given by $\\rho(k) \\approx \\exp(-k / 50)$ for integer $k \\ge 0$.\n-   **Theoretical Basis**: Central Limit Theorem (CLT) for weakly dependent sequences, normalized autocorrelation function $\\rho(k)$, and integrated autocorrelation time $\\tau_{\\mathrm{int}}$.\n-   **Objective**: To identify the most appropriate procedure for constructing asymptotically unbiased error bars for the sample mean, including justification for the choice of block size.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientifically Grounded**: The problem is set in the standard context of computational materials science and chemistry, specifically using Quantum Monte Carlo (QMC) methods. VMC and DMC are cornerstone techniques in this field. The generation of a time-series of energy values via a Markov chain process is fundamental to these methods. The existence of serial correlation in such data is a well-known statistical feature. The concept of weighted averages in DMC due to walker branching, and the need for population control or descendant weighting to obtain meaningful statistics, are accurate representations of the method's practical implementation. The blocking method is the standard, state-of-the-art technique for error analysis of correlated data from such simulations. The assumed exponential decay of the autocorrelation function is a common and physically plausible model. All aspects of the problem are scientifically sound and rooted in established principles of statistical mechanics and computational physics.\n-   **Well-Posed**: The problem is clearly defined. It presents a specific data analysis challenge (error estimation for a correlated series) with sufficient quantitative information ($N$, $\\rho(k)$) to evaluate potential solutions. The goal is unambiguous: find the best procedure among the given options that yields asymptotically unbiased error bars. A unique best solution based on statistical theory can be determined.\n-   **Objective**: The problem is stated in precise, technical language, free from subjectivity or bias. The quantities are well-defined.\n\n**Step 3: Verdict and Action**\nThe problem statement is scientifically sound, well-posed, objective, and complete. It contains no discernible flaws. Therefore, the problem is **valid**. I will proceed with the derivation and solution.\n\n### Solution Derivation\n\nThe core task is to determine the standard error of the mean for a stationary but serially correlated time series $\\{x_t\\}_{t=1}^N$. Let the true mean be $\\mu = \\mathbb{E}[x_t]$ and the true variance be $\\sigma^2 = \\text{Var}(x_t)$. The sample mean is $\\bar{x} = \\frac{1}{N} \\sum_{t=1}^N x_t$.\n\nThe variance of the sample mean is given by:\n$$ \\text{Var}(\\bar{x}) = \\text{Var}\\left(\\frac{1}{N}\\sum_{t=1}^N x_t\\right) = \\frac{1}{N^2} \\sum_{t=1}^N \\sum_{s=1}^N \\text{Cov}(x_t, x_s) $$\nFor a stationary series, the covariance depends only on the time lag $k = |t-s|$, i.e., $\\text{Cov}(x_t, x_s) = \\sigma^2 \\rho(k)$. For large $N$, the variance of the mean can be expressed as:\n$$ \\text{Var}(\\bar{x}) \\approx \\frac{\\sigma^2}{N} \\left(1 + 2\\sum_{k=1}^\\infty \\rho(k)\\right) $$\nThe term in parentheses is the statistical inefficiency, $S$. It is related to the integrated autocorrelation time, $\\tau_{\\mathrm{int}}$, defined as:\n$$ \\tau_{\\mathrm{int}} = \\frac{1}{2} + \\sum_{k=1}^\\infty \\rho(k) $$\nThis gives $S = 2\\tau_{\\mathrm{int}}$. The variance of the mean is therefore:\n$$ \\text{Var}(\\bar{x}) \\approx \\frac{2\\tau_{\\mathrm{int}}\\sigma^2}{N} = \\frac{\\sigma^2}{N / (2\\tau_{\\mathrm{int}})} $$\nThis shows that the effective number of independent samples is $N_{\\mathrm{eff}} = N / S = N / (2\\tau_{\\mathrm{int}})$. A naive estimate of the variance of the mean, $\\sigma^2/N$, which assumes independent samples ($\\tau_{\\mathrm{int}} = 1/2$), would be an underestimate by a factor of $S = 2\\tau_{\\mathrm{int}}$.\n\nFor the given autocorrelation function $\\rho(k) = \\exp(-k/50)$, the integrated autocorrelation time is:\n$$ \\tau_{\\mathrm{int}} = \\frac{1}{2} + \\sum_{k=1}^\\infty e^{-k/50} $$\nThe sum is a geometric series $\\sum_{k=1}^\\infty r^k = r/(1-r)$ with $r = e^{-1/50}$.\n$$ \\tau_{\\mathrm{int}} = \\frac{1}{2} + \\frac{e^{-1/50}}{1 - e^{-1/50}} = \\frac{1}{2} + \\frac{1}{e^{1/50} - 1} $$\nUsing the approximation $e^x \\approx 1+x$ for small $x$, $e^{1/50} - 1 \\approx 1/50$, so $\\tau_{\\mathrm{int}} \\approx 1/2 + 50 - 1/2 = 49.5$. A more precise calculation gives $\\tau_{\\mathrm{int}} \\approx 0.5 + 49.5017 \\approx 50.0$. Thus, the data are highly correlated.\n\nThe **blocking method** is a robust numerical procedure to estimate $\\text{Var}(\\bar{x})$ without needing to explicitly compute $\\tau_{\\mathrm{int}}$. The data series is partitioned into $m_\\ell$ non-overlapping blocks of size $b_\\ell$, such that $N = m_\\ell b_\\ell$. The mean of each block is computed:\n$$ Y_j^{(\\ell)} = \\frac{1}{b_\\ell} \\sum_{t=(j-1)b_\\ell+1}^{jb_\\ell} x_t $$\nIf the block size $b_\\ell$ is chosen to be much larger than the integrated autocorrelation time ($b_\\ell \\gg \\tau_{\\mathrm{int}}$), the block means $\\{Y_j^{(\\ell)}\\}$ will be approximately independent and identically distributed. The Central Limit Theorem can then be applied to these block means. The variance of the overall mean $\\bar{x}$ (which is also the mean of the $Y_j^{(\\ell)}$) is estimated as:\n$$ \\widehat{\\text{Var}}(\\bar{x}) \\approx \\frac{s_{Y(\\ell)}^2}{m_\\ell} $$\nwhere $s_{Y(\\ell)}^2$ is the sample variance of the block means. The corresponding standard error is $\\text{SE}(\\bar{x}) = s_{Y(\\ell)}/\\sqrt{m_\\ell}$.\n\nThe critical part is choosing $b_\\ell$. A procedure of **reblocking** is employed: one computes the standard error estimate for a sequence of increasing block sizes (e.g., $b_\\ell = 2 b_{\\ell-1}$). As $b_\\ell$ increases, the estimated error incorporates correlations on larger scales; it will first rise and then plateau when $b_\\ell$ is large enough to make the blocks effectively independent. This plateau value is the correct estimate of the standard error. For the estimate $s_{Y(\\ell)}^2$ to be statistically reliable, the number of blocks $m_\\ell$ must not be too small; a common rule of thumb is to require $m_\\ell \\ge 20$ or $m_\\ell \\ge 30$.\n\n### Option-by-Option Analysis\n\n**A. Discard equilibration to obtain a stationary series and compute the sample autocorrelation function $\\rho(k)$ on $\\{E_t\\}$ (VMC) or $\\{X_t\\}$ (DMC). Estimate the integrated autocorrelation time $\\tau_{\\mathrm{int}}$ using the initial positive sequence estimator, then choose an initial block size $b_0 \\approx 4 \\tau_{\\mathrm{int}}$. Perform recursive reblocking with $b_\\ell = 2^\\ell b_0$ for $\\ell = 0, 1, 2, \\dots$ and, at each $\\ell$, compute the sample variance $s_{Y(\\ell)}^2$ of the block means $\\{Y_j^{(\\ell)}\\}_{j=1}^{m_\\ell}$, where $m_\\ell = N / b_\\ell$ is the number of blocks. Identify the smallest $\\ell$ such that $s_{Y(\\ell)}^2$ has reached a plateau with $m_\\ell \\ge 30$, then report the standard error of the overall mean as $s_{Y(\\ell)} / \\sqrt{m_\\ell}$. For DMC, form $\\{X_t\\}$ via descendant weighting or population reconfiguration to stabilize total weight, then apply the same blocking scheme to $\\{X_t\\}$.**\n\nThis option describes the standard, state-of-the-art reblocking procedure.\n1.  It correctly identifies the need for a stationary series and the proper handling of VMC vs. DMC data, including stabilization techniques for the latter.\n2.  It uses $\\tau_{\\mathrm{int}}$ to make an educated initial guess for the block size, $b_0 \\approx 4 \\tau_{\\mathrm{int}}$, which is a sound heuristic ($b_0 \\approx 4 \\times 50 = 200$).\n3.  It employs recursive reblocking to systematically find the correct block size by looking for a plateau, which is the most robust approach. The phrase \"plateau in $s_{Y(\\ell)}^2$\" is a common but slightly imprecise colloquialism; what actually plateaus is the variance of the overall mean, $s_{Y(\\ell)}^2/m_\\ell$. However, the intent is clear and the overall procedure is correct.\n4.  It includes the crucial constraint $m_\\ell \\ge 30$ to ensure the variance estimate is statistically meaningful.\n5.  It uses the correct formula for the standard error of the mean, $s_{Y(\\ell)} / \\sqrt{m_\\ell}$.\nThis procedure is comprehensive and statistically robust.\n**Verdict: Correct**\n\n**B. Treat all samples as independent, set the block size $b = 1$, and report the standard error as $s / \\sqrt{N}$, where $s^2$ is the sample variance of $\\{E_t\\}$ (VMC) or $\\{X_t\\}$ (DMC), without computing autocorrelations or performing any blocking.**\n\nThis approach is fundamentally flawed. It ignores the serial correlation inherent in the Markov chain process, which is explicitly stated through $\\rho(k)$. With $\\tau_{\\mathrm{int}} \\approx 50$, the statistical inefficiency is $S = 2\\tau_{\\mathrm{int}} \\approx 100$. This means the naive standard error $s/\\sqrt{N}$ would underestimate the true error by a factor of $\\sqrt{S} \\approx \\sqrt{100} = 10$. This is a severe error in statistical analysis.\n**Verdict: Incorrect**\n\n**C. Fit $\\rho(k)$ to an exponential to obtain the correlation time $\\tau \\approx 50$ and choose a single fixed block size $b \\approx \\tau$. Compute block means with this $b$ and report the standard error as the sample standard deviation of block means divided by $\\sqrt{m}$, where $m = N / b$, skipping any plateau diagnostics or adjustments based on $m$.**\n\nThis procedure is inadequate. The condition for block independence is that the block size must be *much larger* than the autocorrelation time, $b \\gg \\tau_{\\mathrm{int}}$. Choosing $b \\approx \\tau_{\\mathrm{int}} \\approx 50$ is insufficient; adjacent blocks will remain significantly correlated, leading to an underestimation of the error. Furthermore, by skipping the plateau diagnostic, the method lacks any self-consistency check to verify if the chosen block size was sufficient.\n**Verdict: Incorrect**\n\n**D. Choose an extremely large block size $b$ so that $m = N / b < 10$ to ensure complete decorrelation between blocks. Report the standard error as the sample standard deviation of block means divided by $\\sqrt{m}$, disregarding the small number of blocks and any variance plateau diagnostics.**\n\nThis approach resolves the issue of inter-block correlation but introduces a new, severe problem. With fewer than $10$ data points (the block means), the sample variance $s_Y^2$ is an extremely noisy and unreliable estimator of the true variance of the block means. The confidence interval on the variance estimate itself is enormous. This high uncertainty in the error estimate makes the resulting error bar practically useless. A robust statistical estimate requires a sufficient number of samples.\n**Verdict: Incorrect**\n\n**E. Use overlapping moving averages of window length $b$ to construct overlapping block means that increase the number of blocks beyond $m = N / b$. Treat the overlapping block means as independent, select $b$ by minimizing the empirical standard error, and report that minimized value as the error bar, without computing $\\rho(k)$ or $\\tau_{\\mathrm{int}}$.**\n\nThis procedure is based on multiple invalid statistical assumptions.\n1.  Overlapping block means are, by construction, strongly correlated. Treating them as independent is a gross error that will lead to a significant underestimation of the true variance.\n2.  The goal of error analysis is to find an accurate and unbiased estimate of the error, not to minimize it. The criterion of minimizing the empirical standard error is nonsensical and would incentivize choosing parameters that produce an artificially small, incorrect error.\n**Verdict: Incorrect**\n\n### Conclusion\n\nOption A describes the most complete and correct methodology, conforming to the best practices for statistical error analysis of correlated data from Monte Carlo simulations. Despite a minor terminological imprecision, it is the only option that outlines a robust and asymptotically unbiased procedure.",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}