{
    "hands_on_practices": [
        {
            "introduction": "In Hamiltonian mechanics for field theories, physical quantities are represented by functionals, and their \"gradients\" are given by variational derivatives. This exercise provides essential practice in computing these derivatives, a fundamental skill for constructing Hamiltonian equations of motion. By applying integration by parts under periodic boundary conditions, you will master a core technique used throughout the study of integrable systems like the Korteweg-de Vries (KdV) equation .",
            "id": "3777386",
            "problem": "In the bi-Hamiltonian formulation of the Korteweg–de Vries (KdV) equation, Hamiltonian functionals and their variational derivatives play a central role in generating flows via compatible Poisson operators. Consider the functional defined on the circle $S^{1}$,\n$$\nF[u] \\;=\\; \\int_{0}^{2\\pi} u(x)\\,u_{xx}(x)\\,dx,\n$$\nwhere $u \\colon S^{1} \\to \\mathbb{R}$ is a smooth, $2\\pi$-periodic function, and $u_{xx}$ denotes the second derivative with respect to $x$. Using first principles from the calculus of variations, namely the definition of the Gâteaux derivative in the direction of a smooth variation $v$ and the representation of the variational derivative via the $L^{2}$ pairing,\n$$\n\\delta F[u;v] \\;=\\; \\left.\\frac{d}{d\\varepsilon}\\right|_{\\varepsilon=0} F[u+\\varepsilon v] \\;=\\; \\int_{0}^{2\\pi} \\frac{\\delta F}{\\delta u}(x)\\,v(x)\\,dx,\n$$\ncompute the variational derivative $\\delta F/\\delta u$ and reduce it to a local expression in terms of $u$ and its derivatives by systematically applying integration by parts under periodic boundary conditions. Express your final answer as a single closed-form analytic expression in terms of $u$ and its derivatives. No numerical approximation or rounding is required, and no physical units are involved.",
            "solution": "The problem requires the computation of the variational derivative, denoted as $\\frac{\\delta F}{\\delta u}$, for the functional $F[u] = \\int_{0}^{2\\pi} u(x)\\,u_{xx}(x)\\,dx$. The function $u(x)$ is defined on the circle $S^{1}$, which implies that it is a smooth and $2\\pi$-periodic function. The calculation will be performed using the first principles of the calculus of variations, specifically utilizing the definition of the Gâteaux derivative in the direction of a smooth, $2\\pi$-periodic variation $v(x)$, and the representation of the variational derivative via the $L^{2}$ pairing.\n\nThe Gâteaux derivative of the functional $F[u]$ in the direction of the variation $v$ is defined as:\n$$\n\\delta F[u;v] = \\left.\\frac{d}{d\\varepsilon}\\right|_{\\varepsilon=0} F[u+\\varepsilon v]\n$$\nFirst, we substitute the perturbed function $u + \\varepsilon v$ into the functional $F$:\n$$\nF[u+\\varepsilon v] = \\int_{0}^{2\\pi} (u(x)+\\varepsilon v(x)) \\frac{d^2}{dx^2}(u(x)+\\varepsilon v(x)) \\,dx\n$$\nBy the linearity of the differentiation operator, $(u+\\varepsilon v)_{xx} = u_{xx} + \\varepsilon v_{xx}$. The expression becomes:\n$$\nF[u+\\varepsilon v] = \\int_{0}^{2\\pi} (u+\\varepsilon v) (u_{xx}+\\varepsilon v_{xx}) \\,dx\n$$\nExpanding the integrand, we obtain a polynomial in $\\varepsilon$:\n$$\nF[u+\\varepsilon v] = \\int_{0}^{2\\pi} (u u_{xx} + \\varepsilon u v_{xx} + \\varepsilon v u_{xx} + \\varepsilon^2 v v_{xx}) \\,dx\n$$\nTo find the Gâteaux derivative, we differentiate this expression with respect to $\\varepsilon$. Assuming sufficient smoothness of the functions to allow differentiation under the integral sign, we get:\n$$\n\\frac{d}{d\\varepsilon} F[u+\\varepsilon v] = \\int_{0}^{2\\pi} \\frac{\\partial}{\\partial\\varepsilon} (u u_{xx} + \\varepsilon(u v_{xx} + v u_{xx}) + \\varepsilon^2 v v_{xx}) \\,dx\n$$\n$$\n\\frac{d}{d\\varepsilon} F[u+\\varepsilon v] = \\int_{0}^{2\\pi} (u v_{xx} + v u_{xx} + 2\\varepsilon v v_{xx}) \\,dx\n$$\nEvaluating this derivative at $\\varepsilon = 0$ yields the first variation, $\\delta F[u;v]$:\n$$\n\\delta F[u;v] = \\left.\\frac{d}{d\\varepsilon}\\right|_{\\varepsilon=0} F[u+\\varepsilon v] = \\int_{0}^{2\\pi} (u v_{xx} + u_{xx} v) \\,dx\n$$\nThe variational derivative $\\frac{\\delta F}{\\delta u}$ is defined implicitly by the relation:\n$$\n\\delta F[u;v] = \\int_{0}^{2\\pi} \\frac{\\delta F}{\\delta u}(x)\\,v(x)\\,dx\n$$\nTo find $\\frac{\\delta F}{\\delta u}$, we must manipulate the expression for $\\delta F[u;v]$ such that the variation $v(x)$ appears as a simple factor in the integrand, with no derivatives acting on it. This requires the use of integration by parts. The term $\\int_{0}^{2\\pi} u_{xx} v \\,dx$ is already in the desired form. We must process the other term, $\\int_{0}^{2\\pi} u v_{xx} \\,dx$.\n\nApplying integration by parts to $\\int_{0}^{2\\pi} u v_{xx} \\,dx$, we set the parts as $f = u$ and $dg = v_{xx}\\,dx$. This gives $df = u_x\\,dx$ and $g = v_x$.\n$$\n\\int_{0}^{2\\pi} u v_{xx} \\,dx = \\left[ u v_x \\right]_{0}^{2\\pi} - \\int_{0}^{2\\pi} u_x v_x \\,dx\n$$\nThe boundary term $\\left[ u v_x \\right]_{0}^{2\\pi}$ evaluates to $u(2\\pi)v_x(2\\pi) - u(0)v_x(0)$. Since the functions $u$ and $v$ are $2\\pi$-periodic, their derivatives $u_x$ and $v_x$ are also $2\\pi$-periodic. Therefore, $u(2\\pi)=u(0)$ and $v_x(2\\pi)=v_x(0)$. The boundary term vanishes:\n$$\nu(2\\pi)v_x(2\\pi) - u(0)v_x(0) = u(0)v_x(0) - u(0)v_x(0) = 0\n$$\nThis simplifies the expression to:\n$$\n\\int_{0}^{2\\pi} u v_{xx} \\,dx = - \\int_{0}^{2\\pi} u_x v_x \\,dx\n$$\nThe integral on the right-hand side still contains a derivative of $v$. We apply integration by parts a second time. Let $f = u_x$ and $dg = v_x\\,dx$. This gives $df = u_{xx}\\,dx$ and $g = v$.\n$$\n- \\int_{0}^{2\\pi} u_x v_x \\,dx = - \\left( \\left[ u_x v \\right]_{0}^{2\\pi} - \\int_{0}^{2\\pi} u_{xx} v \\,dx \\right)\n$$\nThe new boundary term $\\left[ u_x v \\right]_{0}^{2\\pi}$ is $u_x(2\\pi)v(2\\pi) - u_x(0)v(0)$. Due to periodicity, $u_x(2\\pi)=u_x(0)$ and $v(2\\pi)=v(0)$, so this term also vanishes.\nThus, the expression further simplifies to:\n$$\n- \\int_{0}^{2\\pi} u_x v_x \\,dx = - \\left( 0 - \\int_{0}^{2\\pi} u_{xx} v \\,dx \\right) = \\int_{0}^{2\\pi} u_{xx} v \\,dx\n$$\nWe have now established that, under periodic boundary conditions, $\\int_{0}^{2\\pi} u v_{xx} \\,dx = \\int_{0}^{2\\pi} u_{xx} v \\,dx$.\n\nWe substitute this result back into our expression for $\\delta F[u;v]$:\n$$\n\\delta F[u;v] = \\int_{0}^{2\\pi} u v_{xx} \\,dx + \\int_{0}^{2\\pi} u_{xx} v \\,dx = \\int_{0}^{2\\pi} u_{xx} v \\,dx + \\int_{0}^{2\\pi} u_{xx} v \\,dx\n$$\n$$\n\\delta F[u;v] = \\int_{0}^{2\\pi} 2 u_{xx} v \\,dx\n$$\nBy comparing this result with the definition $\\delta F[u;v] = \\int_{0}^{2\\pi} \\frac{\\delta F}{\\delta u}(x)\\,v(x)\\,dx$, we can identify the variational derivative by inspection. The function multiplying the variation $v(x)$ in the integrand is the desired quantity.\nTherefore, the variational derivative of the functional $F[u]$ is:\n$$\n\\frac{\\delta F}{\\delta u}(x) = 2 u_{xx}(x)\n$$\nThis is the final local expression in terms of $u$ and its derivatives.",
            "answer": "$$\\boxed{2u_{xx}}$$"
        },
        {
            "introduction": "A key feature of the KdV equation's bi-Hamiltonian structure is its ability to systematically generate an infinite hierarchy of conserved quantities, which is the hallmark of its integrability. This practice offers a direct demonstration of the Lenard-Magri recursion scheme, the engine that produces this hierarchy. Starting with a simple conserved quantity, you will use the two compatible Hamiltonian operators, $\\mathcal{J}_1$ and $\\mathcal{J}_2$, to explicitly derive the next conserved quantity in the sequence .",
            "id": "3777407",
            "problem": "Consider the Korteweg–de Vries equation within the bi-Hamiltonian framework on the real line. Let $u(x)$ be a smooth, rapidly decaying function on $\\mathbb{R}$. Define the first and second Hamiltonian operators by\n$$\nJ_{1} := \\partial_{x}, \n\\qquad\nJ_{2} := -(\\partial_{x}^{3} + 4u\\partial_{x} + 2u_{x}),\n$$\nwhere $\\partial_{x}$ denotes differentiation with respect to $x$ and $u_{x} := \\partial_{x} u$. For a local functional $H[u] = \\int_{\\mathbb{R}} h(u, u_{x}, u_{xx}, \\dots)\\,dx$, define its $L^{2}$-gradient (variational derivative) $\\nabla H = \\delta H/\\delta u$ in the usual sense of the calculus of variations. Start from the base Hamiltonian\n$$\nH_{0}[u] := \\int_{\\mathbb{R}} u(x)\\,dx,\n$$\nand use the relation\n$$\nJ_{2}\\,\\nabla H_{0} \\;=\\; J_{1}\\,\\nabla H_{1}\n$$\nto determine $\\nabla H_{1}$ uniquely under the normalization that $\\nabla H_{1}$ vanishes when $u \\equiv 0$. Explicitly verify that your result satisfies the displayed relation for all smooth, rapidly decaying $u(x)$ by direct computation, using only the definitions above and standard integration by parts justified by decay at infinity.\n\nProvide your final answer as a single closed-form analytic expression for $\\nabla H_{1}$. No rounding is required, and no physical units are involved.",
            "solution": "The task is to determine the variational derivative $\\nabla H_1$ from the recursive relation $J_2\\,\\nabla H_0 = J_1\\,\\nabla H_1$, given the operators $J_1$ and $J_2$ and the base Hamiltonian $H_0$.\n\nFirst, we compute the variational derivative (or $L^2$-gradient) of the base Hamiltonian, $H_0[u] := \\int_{\\mathbb{R}} u(x)\\,dx$. The variational derivative $\\nabla H_0 = \\frac{\\delta H_0}{\\delta u}$ is defined by the first-order term in the expansion of $H_0[u+\\delta u]$, where $\\delta u$ is a smooth, rapidly decaying perturbation.\n$$\n\\delta H_0 = H_0[u+\\delta u] - H_0[u] = \\int_{\\mathbb{R}} (u(x)+\\delta u(x))\\,dx - \\int_{\\mathbb{R}} u(x)\\,dx = \\int_{\\mathbb{R}} \\delta u(x)\\,dx.\n$$\nBy definition, $\\delta H_0 = \\int_{\\mathbb{R}} (\\nabla H_0) \\delta u(x) \\,dx$. Comparing the two expressions, we identify the integrand multiplying $\\delta u(x)$. Since this must hold for any arbitrary smooth and rapidly decaying function $\\delta u(x)$, we conclude by the fundamental lemma of the calculus of variations that\n$$\n\\nabla H_0 = 1.\n$$\n\nNext, we compute the left-hand side of the given relation, $J_2\\,\\nabla H_0$. The second Hamiltonian operator is given as $J_2 := -(\\partial_x^3 + 4u\\partial_x + 2u_x)$. We apply this operator to our result $\\nabla H_0 = 1$. The operator acts on a function $f(x)$ as $J_2(f) = -(\\partial_x^3 f + 4u(\\partial_x f) + (2u_x)f)$.\n$$\nJ_2\\,\\nabla H_0 = J_2(1) = -(\\partial_x^3 + 4u\\partial_x + 2u_x)(1).\n$$\nWe evaluate each term's action on the constant function $1$:\n$$\n\\partial_x^3(1) = 0,\n$$\n$$\n4u\\partial_x(1) = 4u(0) = 0,\n$$\n$$\n2u_x(1) = 2u_x \\cdot 1 = 2u_x.\n$$\nCombining these results, we find\n$$\nJ_2\\,\\nabla H_0 = -(0 + 0 + 2u_x) = -2u_x.\n$$\n\nNow we consider the right-hand side of the relation, $J_1\\,\\nabla H_1$. The first Hamiltonian operator is $J_1 := \\partial_x$. Thus, the right-hand side is\n$$\nJ_1\\,\\nabla H_1 = \\partial_x(\\nabla H_1).\n$$\n\nEquating the left and right sides, we obtain a differential equation for $\\nabla H_1$:\n$$\n\\partial_x(\\nabla H_1) = -2u_x.\n$$\nTo solve for $\\nabla H_1$, we integrate both sides with respect to $x$:\n$$\n\\int \\partial_x(\\nabla H_1) \\,dx = \\int (-2u_x) \\,dx.\n$$\nThe fundamental theorem of calculus yields\n$$\n\\nabla H_1(x) = -2u(x) + C,\n$$\nwhere $C$ is a constant of integration.\n\nTo determine this constant, we apply the specified normalization condition: $\\nabla H_1$ must vanish when $u \\equiv 0$. Substituting $u(x) = 0$ for all $x$ into our expression for $\\nabla H_1$:\n$$\n\\nabla H_1 = -2(0) + C = C.\n$$\nFor this to be zero as required, we must have $C=0$. Therefore, the unique expression for $\\nabla H_1$ under the given conditions is\n$$\n\\nabla H_1 = -2u.\n$$\n\nFinally, we explicitly verify that this result satisfies the original relation $J_{2}\\,\\nabla H_{0} = J_{1}\\,\\nabla H_{1}$.\n\nWe compute the left-hand side (LHS) and right-hand side (RHS) independently.\n\nLHS:\nAs calculated above, $\\nabla H_0 = 1$, and applying $J_2$ gives:\n$$\n\\text{LHS} = J_2\\,\\nabla H_0 = -(\\partial_x^3 + 4u\\partial_x + 2u_x)(1) = -2u_x.\n$$\n\nRHS:\nUsing our determined result $\\nabla H_1 = -2u$ and the definition $J_1 = \\partial_x$:\n$$\n\\text{RHS} = J_1\\,\\nabla H_1 = \\partial_x(-2u) = -2u_x.\n$$\n\nSince LHS $= -2u_x$ and RHS $= -2u_x$, the equality holds. This verifies the correctness of our solution. The expression is a closed-form analytic expression as required.",
            "answer": "$$\\boxed{-2u}$$"
        },
        {
            "introduction": "The recursion operator $\\mathcal{R} = \\mathcal{J}_2 \\mathcal{J}_1^{-1}$ is central to the bi-Hamiltonian framework, yet its definition contains a subtle but critical component: the inverse operator $\\mathcal{J}_1^{-1} = \\partial_x^{-1}$. This practice explores the nature of this inverse, revealing why it is inherently nonlocal and how its definition on a periodic domain requires special care. Understanding these points is crucial for a deeper appreciation of the mathematical structure that underpins the KdV hierarchy and its nonlocal properties .",
            "id": "3777353",
            "problem": "Consider the Korteweg–de Vries (KdV) equation on the periodic domain $S^1$,\n$$\nu_t + 6\\,u\\,u_x + u_{xxx} = 0,\n$$\nviewed as a bi-Hamiltonian system with two compatible Poisson operators\n$$\n\\mathcal{J}_1 = \\partial_x, \\qquad \\mathcal{J}_2 = -(\\partial_x^3 + 4u\\partial_x + 2u_x),\n$$\nso that the recursion operator is $\\mathcal{R} = \\mathcal{J}_2 \\mathcal{J}_1^{-1}$. Work in a Sobolev space $H^s(S^1)$ of periodic functions of period $2\\pi$ with $s$ sufficiently large to justify the operations below. A local differential operator of finite order at a point $x$ is, by definition, one whose value at $x$ depends only on finitely many derivatives of the input at $x$. The kernel of $\\partial_x$ on $S^1$ consists of constant functions.\n\nUsing only the fundamental definitions above, reason about the nature of $\\partial_x^{-1}$ as an operator in this context and how it is made well-defined on the circle. In particular, determine which statements correctly explain why $\\partial_x^{-1}$ is nonlocal and how imposing the mean-zero constraint $\\int_{S^1} u\\,dx = 0$ on the function space resolves the ambiguity in inverting $\\partial_x$.\n\nSelect all that apply.\n\nA. $(\\partial_x^{-1} f)(x)$ is obtained by integrating $f$ along an interval to $x$, so it depends on values of $f$ away from $x$; hence it is nonlocal. On $S^1$, constants lie in $\\ker(\\partial_x)$, so restricting to the subspace $\\{f \\in H^s(S^1): \\int_{S^1} f\\,dx = 0\\}$ ensures existence of a periodic antiderivative, and fixing its mean (for example, to zero) makes $\\partial_x^{-1}$ unique. This renders $\\mathcal{R}$ well-defined but nonlocal.\n\nB. $\\partial_x^{-1}$ is local because differentiation and integration are pointwise inverses, so $(\\partial_x^{-1} f)(x)$ depends only on $f(x)$. The mean-zero constraint is unrelated to defining $\\partial_x^{-1}$ on $S^1$.\n\nC. In Fourier variables on $S^1$, the action of $\\partial_x$ is multiplication by $i k$ on the $k$-th Fourier mode. Defining $\\partial_x^{-1}$ as multiplication by $1/(i k)$ for $k \\neq 0$ and setting the $k=0$ mode to zero removes the singularity at $k=0$ and is equivalent to encoding the mean-zero restriction. This definition still yields a nonlocal operator.\n\nD. On $S^1$, $\\partial_x$ is invertible on all $L^2$ functions by Fourier series, because one can define $1/(i\\cdot 0)$ consistently at $k=0$. Therefore $\\partial_x^{-1}$ is a local operator and the mean-zero constraint is unnecessary for the KdV Poisson structures.\n\nE. The mean-zero constraint on $u$ identifies a symplectic leaf for the Poisson operator $\\mathcal{J}_1 = \\partial_x$, since the conserved quantity $M(u) = \\int_{S^1} u\\,dx$ is a Casimir for $\\mathcal{J}_1$. On this leaf, $\\partial_x$ is invertible modulo constants, and choosing a normalization (for example, zero-mean antiderivative) makes $\\partial_x^{-1}$ well-defined. Because the inverse is realized by integration, it is nonlocal, and thus $\\mathcal{R}$ is nonlocal.",
            "solution": "We begin from the definitions provided. A local differential operator of finite order at a point $x$ uses only a finite jet $(f(x), f_x(x), \\dots, f^{(m)}(x))$ of the input at $x$. The derivative operator $\\partial_x$ is local. Its inverse, if it exists, must solve $g_x = f$. On a line, such a $g$ is given by $g(x) = \\int_{x_0}^x f(\\xi)\\,d\\xi + C$, which depends on values of $f$ on an interval extending away from $x$ unless $f \\equiv 0$. This already indicates nonlocality: evaluating $g(x)$ requires integrating $f$ over an interval. On a circle $S^1$, one must also ensure $g$ is periodic; this requires that $\\int_{S^1} f\\,dx = 0$ so that $g(x+2\\pi) - g(x) = \\int_x^{x+2\\pi} f(\\xi)\\,d\\xi = 0$. Thus, on $S^1$, a necessary and sufficient condition for a periodic antiderivative to exist is that the mean of $f$ vanish. Furthermore, any two periodic antiderivatives differ by a constant; one fixes uniqueness by specifying a normalization, such as imposing zero mean on $g$ or fixing $g(x_0)=0$. Any normalization leads to an integral expression of $g$ in terms of $f$, making $\\partial_x^{-1}$ nonlocal.\n\nIn the Korteweg–de Vries setting, the first Poisson operator is $\\mathcal{J}_1=\\partial_x$, which is degenerate because constants are in its kernel. The functional $M(u)=\\int_{S^1} u\\,dx$ is a Casimir for $\\mathcal{J}_1$, so its level sets are the symplectic leaves. Restricting to the leaf with $\\int_{S^1} u\\,dx = 0$ removes the constant mode and allows one to invert $\\mathcal{J}_1$ (modulo normalization), thereby defining $\\partial_x^{-1}$. The recursion operator $\\mathcal{R}=\\mathcal{J}_2 \\mathcal{J}_1^{-1}$ therefore inherits nonlocality from $\\partial_x^{-1}$.\n\nA complementary viewpoint uses Fourier series. Writing $f(x) = \\sum_{k\\in \\mathbb{Z}} f_k e^{i k x}$, the operator $\\partial_x$ acts as multiplication by $i k$, so an inverse would multiply by $1/(i k)$ for $k\\neq 0$. The $k=0$ mode corresponds to the mean of $f$ and is in the kernel of $\\partial_x$. Discarding or setting to zero the $k=0$ mode is equivalent to restricting to mean-zero functions. The symbol $1/(i k)$ is not a polynomial in $k$, so the corresponding operator is a pseudodifferential operator with a nonlocal integral kernel; this encodes nonlocality.\n\nWith this principle-based reasoning in place, we now analyze each option.\n\nOption A: Correct. The description of nonlocality via integration along an interval is accurate. The necessity of the mean-zero condition for the existence of a periodic antiderivative on $S^1$ follows from $\\int_{S^1} f\\,dx = \\int_0^{2\\pi} g_x\\,dx = g(2\\pi)-g(0)$, which must vanish for periodic $g$. Fixing the mean (or any normalization) yields uniqueness. This makes $\\mathcal{R}$ well-defined but nonlocal.\n\nOption B: Incorrect. Integration is not a pointwise inverse of differentiation in the sense of locality. $(\\partial_x^{-1} f)(x)$ depends on an integral of $f$ over an interval, not solely on $f(x)$. Moreover, on $S^1$, the mean-zero constraint is directly related to the existence of periodic antiderivatives and hence to defining $\\partial_x^{-1}$.\n\nOption C: Correct. In Fourier space, $\\partial_x$ has symbol $i k$. The inverse symbol $1/(i k)$ is undefined at $k=0$, which corresponds to the mean. Declaring the $k=0$ mode of $\\partial_x^{-1} f$ to be zero is equivalent to imposing $\\int_{S^1} f\\,dx=0$ and removes the singularity. Because $1/(i k)$ is not a polynomial, the inverse is pseudodifferential and nonlocal.\n\nOption D: Incorrect. One cannot consistently define $1/(i\\cdot 0)$; the $k=0$ mode is singular and reflects the non-invertibility of $\\partial_x$ on the full space. Furthermore, Fourier multipliers with non-polynomial symbols are generally nonlocal; thus $\\partial_x^{-1}$ is not local, and the mean-zero restriction is necessary to make sense of the inverse.\n\nOption E: Correct. The functional $M(u)=\\int_{S^1} u\\,dx$ is a Casimir for $\\mathcal{J}_1=\\partial_x$, so the level sets $M(u)=\\text{const}$ are symplectic leaves. On such a leaf, one can invert $\\mathcal{J}_1$ modulo constants by fixing a normalization, which defines $\\partial_x^{-1}$. Since this inverse is given by integration, it is nonlocal. Consequently, the recursion operator $\\mathcal{R}$ is nonlocal but well-defined on the mean-zero leaf.\n\nTherefore, the correct choices are A, C, and E.",
            "answer": "$$\\boxed{ACE}$$"
        }
    ]
}