{
    "hands_on_practices": [
        {
            "introduction": "This first exercise grounds our theoretical discussion in a familiar setting: a controlled harmonic oscillator. By applying the Pontryagin Maximum Principle, you will walk through the essential steps of constructing the control Hamiltonian, deriving the optimal control law, and obtaining the final Hamiltonian system that governs the extremal trajectories. This practice solidifies the core mechanics of the theory and highlights the deep connection between optimal control and classical Hamiltonian dynamics .",
            "id": "3774822",
            "problem": "Consider the controlled canonical mechanical system on the configuration space $\\mathbb{R}$ with generalized coordinate $q$ and conjugate momentum $p$ given by the drift-plus-control dynamics\n$$\n\\dot{q} = p, \\qquad \\dot{p} = -\\omega^{2} q + u,\n$$\nwhere $\\omega > 0$ is a fixed frequency parameter and $u$ is a scalar control. The performance index is the quadratic energy functional\n$$\nJ[u] = \\int_{0}^{T} \\frac{1}{2} r\\, u(t)^{2}\\, \\mathrm{d}t,\n$$\nwith $r > 0$ constant and $T > 0$ a fixed terminal time. The task is to analyze extremal curves in the cotangent bundle $T^{\\ast}X$ of the state space $X = \\mathbb{R}^{2}$, where $x = (q,p)$ and the costate is $\\lambda = (\\lambda_{q}, \\lambda_{p})$. Use the canonical symplectic form on $T^{\\ast}X$, denoted $\\omega_{\\mathrm{can}}$, and the Pontryagin Maximum Principle (PMP), which introduces the control Hamiltonian defined by\n$$\n\\mathcal{H}(x,\\lambda,u) = \\lambda \\cdot f(x,u) - L(x,u),\n$$\nwhere $f(x,u)$ is the state dynamics and $L(x,u)$ is the running cost density.\n\nStarting from the above fundamental definitions and facts, carry out the following steps:\n\n1. Derive the explicit control Hamiltonian $\\mathcal{H}(q,p,\\lambda_{q},\\lambda_{p},u)$ for this system using the given $f$ and $L$.\n2. Determine the control $u^{\\ast}$ that maximizes $\\mathcal{H}$ pointwise in $u$.\n3. Substitute $u^{\\ast}$ back to obtain the maximized Hamiltonian $\\mathcal{H}^{\\ast}(q,p,\\lambda_{q},\\lambda_{p})$ and write the canonical Hamiltonian system for the extremal lift $(q,p,\\lambda_{q},\\lambda_{p})$ on $T^{\\ast}X$ associated with $\\mathcal{H}^{\\ast}$ and $\\omega_{\\mathrm{can}}$.\n4. Using only the symplectic invariance of Hamiltonian flows and the time-autonomy of the maximized Hamiltonian, argue that $\\mathcal{H}^{\\ast}$ is conserved along extremal curves.\n5. Given the initial conditions $q(0) = q_{0}$, $p(0) = p_{0}$, $\\lambda_{q}(0) = \\alpha$, and $\\lambda_{p}(0) = \\beta$, compute the constant value of $\\mathcal{H}^{\\ast}$ along the extremal curve. Express your final answer as a single closed-form analytic expression.\n\nYour final answer must be a single analytic expression. No rounding is required. No physical units should be included in the final answer.",
            "solution": "The problem is analyzed and solved by following the five specified steps.\n\n### Step 1: Derivation of the Control Hamiltonian\n\nThe problem provides the state space $X = \\mathbb{R}^{2}$ with coordinates $x = (q,p)$, where $q$ is the generalized coordinate and $p$ is the conjugate momentum. The state dynamics are given by the vector field $f(x,u)$:\n$$\n\\dot{x} = \\begin{pmatrix} \\dot{q} \\\\ \\dot{p} \\end{pmatrix} = f(x,u) = \\begin{pmatrix} p \\\\ -\\omega^{2} q + u \\end{pmatrix}\n$$\nThe running cost is given by the Lagrangian $L(x,u) = \\frac{1}{2} r u(t)^{2}$.\n\nThe Pontryagin Maximum Principle (PMP) introduces a control Hamiltonian $\\mathcal{H}$ on the cotangent bundle $T^{\\ast}X$. The coordinates on $T^{\\ast}X$ are $(x, \\lambda) = (q, p, \\lambda_{q}, \\lambda_{p})$, where $\\lambda = (\\lambda_{q}, \\lambda_{p})$ is the costate. The control Hamiltonian is defined as:\n$$\n\\mathcal{H}(x,\\lambda,u) = \\lambda \\cdot f(x,u) - L(x,u)\n$$\nSubstituting the given expressions for $f(x,u)$ and $L(x,u)$, we get:\n$$\n\\mathcal{H}(q,p,\\lambda_{q},\\lambda_{p},u) = \\begin{pmatrix} \\lambda_{q}  \\lambda_{p} \\end{pmatrix} \\begin{pmatrix} p \\\\ -\\omega^{2} q + u \\end{pmatrix} - \\frac{1}{2} r u^{2}\n$$\nExpanding the dot product yields the explicit form of the control Hamiltonian:\n$$\n\\mathcal{H}(q,p,\\lambda_{q},\\lambda_{p},u) = \\lambda_{q} p + \\lambda_{p}(-\\omega^{2} q + u) - \\frac{1}{2} r u^{2}\n$$\n\n### Step 2: Determination of the Optimal Control\n\nAccording to the PMP, for an extremal curve, the control $u^{\\ast}(t)$ must maximize the Hamiltonian $\\mathcal{H}$ pointwise in time, for the given state $x(t)$ and costate $\\lambda(t)$. To find the control $u^{\\ast}$ that maximizes $\\mathcal{H}$, we treat $(q, p, \\lambda_{q}, \\lambda_{p})$ as fixed parameters and optimize with respect to $u$.\n\nWe compute the first and second partial derivatives of $\\mathcal{H}$ with respect to $u$:\n$$\n\\frac{\\partial \\mathcal{H}}{\\partial u} = \\lambda_{p} - r u\n$$\nSetting the first derivative to zero gives the necessary condition for an extremum:\n$$\n\\lambda_{p} - r u = 0 \\implies u = \\frac{\\lambda_{p}}{r}\n$$\nTo confirm this is a maximum, we check the second derivative:\n$$\n\\frac{\\partial^{2} \\mathcal{H}}{\\partial u^{2}} = -r\n$$\nSince the problem states $r > 0$, the second derivative is negative. This confirms that the value $u = \\frac{\\lambda_{p}}{r}$ globally maximizes $\\mathcal{H}$. Thus, the optimal control is:\n$$\nu^{\\ast}(q,p,\\lambda_{q},\\lambda_{p}) = \\frac{\\lambda_{p}}{r}\n$$\n\n### Step 3: The Maximized Hamiltonian and Canonical System\n\nThe maximized Hamiltonian, denoted $\\mathcal{H}^{\\ast}$, is obtained by substituting the optimal control $u^{\\ast}$ back into the expression for $\\mathcal{H}$:\n$$\n\\mathcal{H}^{\\ast}(q,p,\\lambda_{q},\\lambda_{p}) = \\mathcal{H}(q,p,\\lambda_{q},\\lambda_{p},u^{\\ast}) = \\lambda_{q} p + \\lambda_{p}(-\\omega^{2} q + u^{\\ast}) - \\frac{1}{2} r (u^{\\ast})^{2}\n$$\n$$\n\\mathcal{H}^{\\ast} = \\lambda_{q} p + \\lambda_{p}\\left(-\\omega^{2} q + \\frac{\\lambda_{p}}{r}\\right) - \\frac{1}{2} r \\left(\\frac{\\lambda_{p}}{r}\\right)^{2}\n$$\nSimplifying the expression:\n$$\n\\mathcal{H}^{\\ast} = \\lambda_{q} p - \\omega^{2} q \\lambda_{p} + \\frac{\\lambda_{p}^{2}}{r} - \\frac{1}{2} \\frac{\\lambda_{p}^{2}}{r}\n$$\n$$\n\\mathcal{H}^{\\ast}(q,p,\\lambda_{q},\\lambda_{p}) = \\lambda_{q} p - \\omega^{2} q \\lambda_{p} + \\frac{1}{2r} \\lambda_{p}^{2}\n$$\nThis function $\\mathcal{H}^{\\ast}$ is the true Hamiltonian for the extremal curves on the symplectic manifold $(T^{\\ast}X, \\omega_{\\mathrm{can}})$, where $T^{\\ast}X \\cong \\mathbb{R}^{4}$ has coordinates $(q,p,\\lambda_{q},\\lambda_{p})$ and the canonical symplectic form is $\\omega_{\\mathrm{can}} = \\mathrm{d}\\lambda_{q} \\wedge \\mathrm{d}q + \\mathrm{d}\\lambda_{p} \\wedge \\mathrm{d}p$. The dynamics of the extremal lift are given by Hamilton's equations for $\\mathcal{H}^{\\ast}$:\n- $\\dot{q} = \\frac{\\partial \\mathcal{H}^{\\ast}}{\\partial \\lambda_{q}} = p$\n- $\\dot{p} = \\frac{\\partial \\mathcal{H}^{\\ast}}{\\partial \\lambda_{p}} = -\\omega^{2} q + \\frac{1}{r} \\lambda_{p}$\n- $\\dot{\\lambda}_{q} = -\\frac{\\partial \\mathcal{H}^{\\ast}}{\\partial q} = -(-\\omega^{2} \\lambda_{p}) = \\omega^{2} \\lambda_{p}$\n- $\\dot{\\lambda}_{p} = -\\frac{\\partial \\mathcal{H}^{\\ast}}{\\partial p} = -(\\lambda_{q}) = -\\lambda_{q}$\n\nThis is the canonical Hamiltonian system for the extremal lift $(q(t), p(t), \\lambda_{q}(t), \\lambda_{p}(t))$ on $T^{\\ast}X$.\n\n### Step 4: Conservation of the Maximized Hamiltonian\n\nThe maximized Hamiltonian $\\mathcal{H}^{\\ast}$ is a function on the phase space $T^{\\ast}X$ and does not explicitly depend on time $t$. Such a Hamiltonian is called autonomous or time-independent. The extremal curves are the integral curves of the Hamiltonian vector field $X_{\\mathcal{H}^{\\ast}}$ associated with $\\mathcal{H}^{\\ast}$ on the symplectic manifold $(T^{\\ast}X, \\omega_{\\mathrm{can}})$.\n\nFor any Hamiltonian system, the time evolution of a function $F$ along the flow is given by the Poisson bracket: $\\frac{\\mathrm{d}F}{\\mathrm{d}t} = \\{F, H\\} + \\frac{\\partial F}{\\partial t}$. Applying this to the Hamiltonian $H=\\mathcal{H}^{\\ast}$ itself, we have:\n$$\n\\frac{\\mathrm{d}\\mathcal{H}^{\\ast}}{\\mathrm{d}t} = \\{\\mathcal{H}^{\\ast}, \\mathcal{H}^{\\ast}\\} + \\frac{\\partial \\mathcal{H}^{\\ast}}{\\partial t}\n$$\nThe Poisson bracket is antisymmetric, which implies $\\{F, F\\} = 0$ for any function $F$. Therefore, $\\{\\mathcal{H}^{\\ast}, \\mathcal{H}^{\\ast}\\} = 0$.\nFurthermore, as noted, $\\mathcal{H}^{\\ast}$ is time-autonomous, so its partial derivative with respect to time is zero: $\\frac{\\partial \\mathcal{H}^{\\ast}}{\\partial t} = 0$.\nCombining these facts, we get:\n$$\n\\frac{\\mathrm{d}\\mathcal{H}^{\\ast}}{\\mathrm{d}t} = 0 + 0 = 0\n$$\nThis shows that $\\mathcal{H}^{\\ast}$ is a constant of motion along any extremal curve. This is a fundamental result in Hamiltonian mechanics: for an autonomous system, the Hamiltonian itself is a conserved quantity (an integral of motion). The \"symplectic invariance of Hamiltonian flows\" refers to the fact that the flow consists of symplectomorphisms, which is the geometric foundation leading to such conservation laws, including this one.\n\n### Step 5: Computation of the Constant Value of $\\mathcal{H}^{\\ast}$\n\nSince $\\mathcal{H}^{\\ast}$ is conserved along any extremal curve, its value is constant and equal to its initial value at $t=0$. We are given the initial conditions:\n$$\nq(0) = q_{0}, \\quad p(0) = p_{0}, \\quad \\lambda_{q}(0) = \\alpha, \\quad \\lambda_{p}(0) = \\beta\n$$\nWe evaluate the expression for $\\mathcal{H}^{\\ast}$ at $t=0$ by substituting these initial values:\n$$\n\\mathcal{H}^{\\ast}(t=0) = \\mathcal{H}^{\\ast}(q(0), p(0), \\lambda_{q}(0), \\lambda_{p}(0)) = \\lambda_{q}(0)p(0) - \\omega^{2}q(0)\\lambda_{p}(0) + \\frac{1}{2r}(\\lambda_{p}(0))^{2}\n$$\n$$\n\\text{Constant value of } \\mathcal{H}^{\\ast} = \\alpha p_{0} - \\omega^{2} q_{0} \\beta + \\frac{1}{2r}\\beta^{2}\n$$\nThis is the constant value of the maximized Hamiltonian along the unique extremal curve determined by the given initial conditions.",
            "answer": "$$\n\\boxed{\\alpha p_{0} - \\omega^{2} q_{0} \\beta + \\frac{\\beta^{2}}{2r}}\n$$"
        },
        {
            "introduction": "Optimal control problems often require steering a system between specified initial and final states, leading to a two-point boundary value problem. This exercise demonstrates how to tackle this challenge by introducing the shooting method, a powerful computational technique . You will first derive the family of extremal curves parameterized by initial costate values and then formulate the equations to \"shoot\" for the correct parameters that hit the desired target.",
            "id": "3774821",
            "problem": "Consider a controlled mechanical system on the real line with configuration variable $q$ and velocity $v$. The control input is $u$. The state is $x = (q, v)$ and the dynamics are given by the fundamental kinematic and dynamic relations $ \\dot{q} = v$ and $ \\dot{v} = u$. The performance index to be minimized is the action $J[u] = \\int_{0}^{T} \\frac{1}{2} u(t)^2 \\, dt$ over a fixed time horizon $T > 0$, subject to the endpoint constraints $q(0) = q_0$, $v(0) = v_0$, $q(T) = q_T$, and $v(T) = v_T$.\n\nUse Pontryagin's Maximum Principle for optimal control and geometric mechanics on the cotangent bundle $T^*X$ with canonical symplectic form to construct the control Hamiltonian and derive the necessary conditions for extremal curves. Then, design a shooting method for a parameterized family of extremals to satisfy the endpoint constraints. Specifically:\n\n- Define the control Hamiltonian $H(q, v, p_q, p_v, u)$ using the standard pairing $ \\langle p, f(x,u) \\rangle$ and the Lagrangian term in the integrand. Derive the minimizer of $H$ with respect to $u$ and the Hamiltonian system for $(q, v, p_q, p_v)$.\n- Show that the costate $p_q$ is constant and $p_v$ is affine in time, and introduce the parameters $c_1 = p_q(0)$ and $c_2 = p_v(0)$, thereby obtaining a parameterized family of extremals $(q(t; c_1, c_2), v(t; c_1, c_2))$.\n- Formulate the shooting equations by enforcing the terminal constraints $q(T; c_1, c_2) = q_T$ and $v(T; c_1, c_2) = v_T$. Use Newton's method to solve for $(c_1, c_2)$, employing the Jacobian with respect to $(c_1, c_2)$ derived from the state-transition relations to terminal time.\n\nYour program must:\n- Implement the above parameterized shooting method to compute the unique pair $(c_1, c_2)$ that satisfies the terminal constraints for each test case (assume the test cases are chosen so that a unique solution exists).\n- Compute the minimal action value $J^\\star = \\int_{0}^{T} \\frac{1}{2} u(t)^2 \\, dt$ for the resulting extremal, where $u(t)$ is obtained from the Hamiltonian minimization condition.\n- Produce a single line of output containing the list of action values $[J_1, J_2, \\dots]$ for the specified test suite, with each element printed as a floating-point number. The format must be a comma-separated list enclosed in square brackets, with no spaces (for example, $[1.0,2.0]$).\n\nUse the following test suite of parameter values, covering a general case, a boundary condition, and edge cases:\n- Case $1$: $T = 1$, $q_0 = 0$, $v_0 = 0$, $q_T = 1$, $v_T = 0$.\n- Case $2$: $T = 2$, $q_0 = 0$, $v_0 = 0$, $q_T = 0$, $v_T = 0$.\n- Case $3$: $T = \\frac{1}{2}$, $q_0 = 0$, $v_0 = 1$, $q_T = 1$, $v_T = 0$.\n- Case $4$: $T = 1$, $q_0 = 0$, $v_0 = 0$, $q_T = 0$, $v_T = 1$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[J_1,J_2,J_3,J_4]$). No physical units are required; all quantities are dimensionless. Angles are not involved. Percentages are not involved. The outputs must be floating-point numbers.",
            "solution": "The problem is assessed to be valid. It is a well-defined, self-contained, and scientifically sound optimal control problem based on fundamental principles of mechanics and control theory. All necessary data and conditions are provided, and there are no internal contradictions or ill-posed elements. We may proceed with the solution.\n\nThe core of this problem is to find an optimal control $u(t)$ that steers a simple mechanical system from a given initial state $(q_0, v_0)$ to a final state $(q_T, v_T)$ in a fixed time $T$, while minimizing the total control effort, measured by the action integral $J[u] = \\int_{0}^{T} \\frac{1}{2} u(t)^2 \\, dt$. We employ Pontryagin's Maximum Principle (PMP) to derive the necessary conditions for an optimal trajectory (an extremal).\n\nThe state of the system is $x = (q, v)$, and the dynamics are given by $\\dot{x} = f(x, u)$, where:\n$$ \\dot{q} = v $$\n$$ \\dot{v} = u $$\nThe cost function to be minimized is $J[u] = \\int_{0}^{T} L(x, u) \\, dt$, with the Lagrangian (or running cost) $L(x, u) = \\frac{1}{2} u^2$.\n\n**Step 1: The Control Hamiltonian and Optimality Conditions**\n\nAccording to Pontryagin's Maximum Principle, we introduce costate variables $p = (p_q, p_v)$ and form the control Hamiltonian $H(x, p, u)$. The problem statement specifies the convention $H = \\langle p, f(x,u) \\rangle + L(x,u)$. Note that for minimization problems, it is common to define $H = L + p^T f$, which is then minimized w.r.t. $u$.\n$$ H(q, v, p_q, p_v, u) = L(x, u) + p_q \\dot{q} + p_v \\dot{v} $$\n$$ H(q, v, p_q, p_v, u) = \\frac{1}{2} u^2 + p_q v + p_v u $$\nFor an extremal trajectory, the optimal control $u^\\star(t)$ must minimize $H$ at each instant in time. We find this minimizer by setting the partial derivative of $H$ with respect to $u$ to zero:\n$$ \\frac{\\partial H}{\\partial u} = u + p_v = 0 \\implies u^\\star(t) = -p_v(t) $$\nThe second derivative, $\\frac{\\partial^2 H}{\\partial u^2} = 1 > 0$, confirms that this is indeed a minimum.\n\n**Step 2: The Hamiltonian System for Extremals**\n\nWe substitute the optimal control $u^\\star = -p_v$ back into the Hamiltonian to obtain the \"true\" Hamiltonian, $H^\\star$, which governs the flow of the state and costate along an extremal curve:\n$$ H^\\star(q, v, p_q, p_v) = \\frac{1}{2}(-p_v)^2 + p_q v + p_v(-p_v) = p_q v - \\frac{1}{2}p_v^2 $$\nThe dynamics of the state $(q, v)$ and costate $(p_q, p_v)$ along an extremal are given by Hamilton's equations:\n$$ \\dot{q} = \\frac{\\partial H^\\star}{\\partial p_q} = v \\qquad \\dot{p}_q = -\\frac{\\partial H^\\star}{\\partial q} = 0 $$\n$$ \\dot{v} = \\frac{\\partial H^\\star}{\\partial p_v} = -p_v \\qquad \\dot{p}_v = -\\frac{\\partial H^\\star}{\\partial v} = -p_q $$\nThese four equations form the Hamiltonian system that describes all possible extremal paths.\n\n**Step 3: Solving for the Parameterized Extremals**\n\nWe can solve this system of ordinary differential equations analytically.\nFrom $\\dot{p}_q = 0$, we find that $p_q(t)$ is constant. Let $p_q(t) = c_1$, where $c_1 = p_q(0)$.\nThen, $\\dot{p}_v = -p_q = -c_1$. Integrating with respect to time gives $p_v(t) = -c_1 t + c_2$, where $c_2 = p_v(0)$. This confirms that $p_q$ is constant and $p_v$ is affine in time.\n\nNow we solve for the state variables. The optimal control is $u^\\star(t) = -p_v(t) = c_1 t - c_2$.\nSubstituting this into the dynamic equation for $v$:\n$$ \\dot{v}(t) = u^\\star(t) = c_1 t - c_2 $$\nIntegrating from $0$ to $t$ using the initial condition $v(0) = v_0$:\n$$ v(t) = v_0 + \\int_{0}^{t} (c_1 \\tau - c_2) d\\tau = v_0 + \\frac{1}{2}c_1 t^2 - c_2 t $$\nNext, we solve for $q(t)$ using $\\dot{q} = v(t)$ and the initial condition $q(0) = q_0$:\n$$ q(t) = q_0 + \\int_{0}^{t} \\left(v_0 + \\frac{1}{2}c_1 \\tau^2 - c_2 \\tau \\right) d\\tau = q_0 + v_0 t + \\frac{1}{6}c_1 t^3 - \\frac{1}{2}c_2 t^2 $$\nWe have now found a two-parameter family of extremals, $(q(t; c_1, c_2), v(t; c_1, c_2))$, parameterized by the initial costates $c_1$ and $c_2$.\n\n**Step 4: The Shooting Method**\n\nThe shooting method consists of finding the unique values of the parameters $(c_1, c_2)$ such that the resulting trajectory satisfies the terminal boundary conditions $q(T) = q_T$ and $v(T) = v_T$. We enforce these conditions by substituting $t=T$ into our solutions for $q(t)$ and $v(t)$:\n$$ q_T = q_0 + v_0 T + \\frac{1}{6}c_1 T^3 - \\frac{1}{2}c_2 T^2 $$\n$$ v_T = v_0 + \\frac{1}{2}c_1 T^2 - c_2 T $$\nThis is a system of two linear equations in the two unknowns $c_1$ and $c_2$. We can write it in matrix form $A \\mathbf{c} = \\mathbf{b}$, where $\\mathbf{c} = [c_1, c_2]^T$:\n$$ \\begin{pmatrix} \\frac{T^3}{6}  -\\frac{T^2}{2} \\\\ \\frac{T^2}{2}  -T \\end{pmatrix} \\begin{pmatrix} c_1 \\\\ c_2 \\end{pmatrix} = \\begin{pmatrix} q_T - q_0 - v_0 T \\\\ v_T - v_0 \\end{pmatrix} $$\nThe matrix $A$ is the Jacobian of the shooting function $F(c_1, c_2) = (q(T; c_1, c_2) - q_T, v(T; c_1, c_2) - v_T)^T$. As the problem is linear, Newton's method for solving $F(c_1, c_2) = 0$ converges in a single step to the exact solution $\\mathbf{c} = A^{-1} \\mathbf{b}$. The determinant of $A$ is $\\det(A) = -T^4/6 - (-T^4/4) = T^4/12$. Since $T>0$, the matrix is always invertible, guaranteeing a unique solution for $(c_1, c_2)$.\n\nThe inverse matrix is:\n$$ A^{-1} = \\frac{12}{T^4} \\begin{pmatrix} -T  T^2/2 \\\\ -T^2/2  T^3/6 \\end{pmatrix} = \\begin{pmatrix} -12/T^3  6/T^2 \\\\ -6/T^2  2/T \\end{pmatrix} $$\nSolving for $c_1$ and $c_2$:\n$$ c_1 = -\\frac{12}{T^3}(q_T - q_0 - v_0 T) + \\frac{6}{T^2}(v_T - v_0) $$\n$$ c_2 = -\\frac{6}{T^2}(q_T - q_0 - v_0 T) + \\frac{2}{T}(v_T - v_0) $$\nThese are the analytical formulas that will be implemented in the code.\n\n**Step 5: Calculating the Minimal Action**\n\nFinally, we compute the minimal action $J^\\star$ using the optimal control $u^\\star(t) = c_1 t - c_2$.\n$$ J^\\star = \\int_{0}^{T} \\frac{1}{2} (u^\\star(t))^2 \\, dt = \\frac{1}{2} \\int_{0}^{T} (c_1 t - c_2)^2 \\, dt $$\n$$ J^\\star = \\frac{1}{2} \\int_{0}^{T} (c_1^2 t^2 - 2c_1 c_2 t + c_2^2) \\, dt $$\n$$ J^\\star = \\frac{1}{2} \\left[ \\frac{1}{3}c_1^2 t^3 - c_1 c_2 t^2 + c_2^2 t \\right]_0^T $$\n$$ J^\\star = \\frac{1}{2} \\left( \\frac{1}{3}c_1^2 T^3 - c_1 c_2 T^2 + c_2^2 T \\right) $$\nThe program will use these analytical formulas to compute $c_1$, $c_2$, and subsequently $J^\\star$ for each test case.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the optimal control problem for a set of test cases using an\n    analytical solution derived from Pontryagin's Maximum Principle.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (T, q0, v0, qT, vT)\n    test_cases = [\n        (1.0, 0.0, 0.0, 1.0, 0.0),  # Case 1\n        (2.0, 0.0, 0.0, 0.0, 0.0),  # Case 2\n        (0.5, 0.0, 1.0, 1.0, 0.0),  # Case 3\n        (1.0, 0.0, 0.0, 0.0, 1.0),  # Case 4\n    ]\n\n    results = []\n    for case in test_cases:\n        T, q0, v0, qT, vT = case\n\n        # The shooting method for this linear problem reduces to solving a 2x2\n        # linear system A*c = b for the initial costates c = [c1, c2]^T.\n        #\n        # A = [[T^3/6, -T^2/2],\n        #      [T^2/2, -T]]\n        #\n        # b = [qT - q0 - v0*T,\n        #      vT - v0]\n        #\n        # We use the direct analytical solution c = A_inv * b.\n\n        b1 = qT - q0 - v0 * T\n        b2 = vT - v0\n\n        # Precompute powers of T\n        T2 = T * T\n        T3 = T2 * T\n\n        # Analytical solution for c1 and c2 from the inverted system matrix.\n        # This is equivalent to one step of Newton's method.\n        # c1 = (-12/T^3)*b1 + (6/T^2)*b2\n        # c2 = (-6/T^2)*b1 + (2/T)*b2\n        c1 = -12.0 * b1 / T3 + 6.0 * b2 / T2\n        c2 = -6.0 * b1 / T2 + 2.0 * b2 / T\n\n        # Calculate the minimal action J* using the derived formula:\n        # J* = 0.5 * ( (1/3)*c1^2*T^3 - c1*c2*T^2 + c2^2*T )\n        cost = 0.5 * (c1**2 * T3 / 3.0 - c1 * c2 * T2 + c2**2 * T)\n        \n        results.append(cost)\n\n    # Format the output as a comma-separated list of floating-point numbers\n    # enclosed in square brackets, with no spaces.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The power of the Hamiltonian formalism extends far beyond standard control systems into the realm of modern differential geometry. In this advanced practice, you will apply the Pontryagin Maximum Principle to the Heisenberg group, a canonical model in sub-Riemannian geometry . This exercise will guide you in deriving the extremal curves, which correspond to the sub-Riemannian geodesics, showcasing how optimal control theory provides a unifying framework for finding shortest paths in non-holonomic systems.",
            "id": "3767471",
            "problem": "Consider the three-dimensional Heisenberg manifold with global coordinates $(x,y,z)$ and the rank-$2$ distribution $\\mathcal{D}=\\mathrm{span}\\{X_1,X_2\\}$, where $X_1=\\partial_x-\\frac{y}{2}\\partial_z$ and $X_2=\\partial_y+\\frac{x}{2}\\partial_z$. Equip $\\mathcal{D}$ with the sub-Riemannian metric that makes $X_1$ and $X_2$ orthonormal. A horizontal curve $q(t)=(x(t),y(t),z(t))$ obeys the controlled dynamics $\\dot{q}(t)=u_1(t)X_1(q(t))+u_2(t)X_2(q(t))$ with measurable controls $u_1,u_2$. The cost is the kinetic energy functional $J(u)=\\frac{1}{2}\\int_0^T\\left(u_1(t)^2+u_2(t)^2\\right)\\,\\mathrm{d}t$ on a fixed horizon $T0$.\n\nStarting from the following foundational facts and principles:\n- The Chow–Rashevskii theorem ensures small-time controllability when the Lie bracket closure of $\\mathcal{D}$ spans the tangent space.\n- The Pontryagin Maximum Principle (PMP) for energy-minimizing control systems yields a nontrivial covector $p(t)\\in T^*_{q(t)}M$ and a maximized Hamiltonian $H$ on the cotangent bundle $T^*M$ endowed with the canonical symplectic form, such that the extremals satisfy Hamilton's equations $\\dot{q}=\\frac{\\partial H}{\\partial p}$ and $\\dot{p}=-\\frac{\\partial H}{\\partial q}$, together with the pointwise maximization of the control-dependent Hamiltonian.\n- The orthonormality of $X_1,X_2$ in the sub-Riemannian metric implies the energy Hamiltonian depends quadratically on the covector evaluations $h_i(t)=\\langle p(t),X_i(q(t))\\rangle$.\n\nTasks:\n1. Write down the Pontryagin Maximum Principle equations for this Heisenberg control system, explicitly identifying the maximized Hamiltonian $H$, the state–costate (Hamiltonian) system, and the optimal feedback relation between controls $u_1,u_2$ and the covector components.\n2. Determine the normal extremals by solving the Hamiltonian system for the case in which the vertical covector component $\\lambda:=p_z$ is a nonzero constant, and the Hamiltonian level is fixed to $H=\\frac{1}{2}\\rho^2$ with $\\rho0$. Impose the initial condition $q(0)=(0,0,0)$ and choose the rotational phase so that the tangent at $t=0$ has no $y$-component (this canonicalizes the phase to simplify the final expression). Your derivation must start from the stated principles and proceed step by step to an explicit trajectory.\n\nAnswer specification:\n- Express your final trajectory $(x(t),y(t),z(t))$ as a single closed-form analytic expression in terms of the parameters $\\rho0$, $\\lambda\\neq 0$, and time $t$, using standard functions. \n- Provide the final answer as a single row in a matrix using the $\\mathrm{pmatrix}$ environment, in the order $x(t)$, $y(t)$, $z(t)$.\n- No numerical rounding is required.",
            "solution": "The problem is first subjected to a rigorous validation procedure.\n\n### Step 1: Extract Givens\n- **Manifold and Coordinates**: Three-dimensional Heisenberg manifold with global coordinates $(x,y,z)$.\n- **Distribution**: Rank-$2$ distribution $\\mathcal{D}=\\mathrm{span}\\{X_1,X_2\\}$.\n- **Vector Fields**: $X_1=\\partial_x-\\frac{y}{2}\\partial_z$ and $X_2=\\partial_y+\\frac{x}{2}\\partial_z$.\n- **Metric**: Sub-Riemannian metric making $\\{X_1, X_2\\}$ orthonormal.\n- **Dynamics**: Horizontal curve $q(t)=(x(t),y(t),z(t))$ with dynamics $\\dot{q}(t)=u_1(t)X_1(q(t))+u_2(t)X_2(q(t))$.\n- **Controls**: $u_1(t), u_2(t)$ are measurable functions.\n- **Cost Functional**: Kinetic energy $J(u)=\\frac{1}{2}\\int_0^T\\left(u_1(t)^2+u_2(t)^2\\right)\\,\\mathrm{d}t$ on a fixed time horizon $[0,T]$ with $T0$.\n- **Foundational Principles**:\n    1.  Chow–Rashevskii theorem for small-time controllability.\n    2.  Pontryagin Maximum Principle (PMP) for energy-minimizing systems, leading to Hamilton's equations on the cotangent bundle $T^*M$.\n    3.  Orthonormality of $X_1, X_2$ implies the Hamiltonian is $H = \\frac{1}{2}(h_1^2 + h_2^2)$, where $h_i = \\langle p, X_i \\rangle$.\n- **Tasks**:\n    1.  Formulate the PMP equations: maximized Hamiltonian $H$, state-costate system, and optimal control feedback law.\n    2.  Solve for normal extremals under the conditions:\n        - $p_z(t) = \\lambda$ is a nonzero constant.\n        - Hamiltonian level is $H=\\frac{1}{2}\\rho^2$ with $\\rho0$.\n        - Initial condition is $q(0)=(0,0,0)$.\n        - Phase canonicalization: the tangent vector at $t=0$ has no $y$-component.\n- **Answer Specification**:\n    - Final answer is the trajectory $(x(t), y(t), z(t))$ as a single closed-form expression.\n    - Format is a single row matrix using the $\\mathrm{pmatrix}$ environment.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is analyzed for validity.\n- **Scientific Groundedness**: The problem is a canonical example in sub-Riemannian geometry and geometric control theory. The Heisenberg group, its sub-Riemannian structure, and the application of the Pontryagin Maximum Principle are all standard, well-established concepts in mathematics and theoretical physics. The system's controllability, a prerequisite for the control problem to be meaningful, is guaranteed by the Chow–Rashevskii theorem. We verify this by computing the Lie bracket of the generating vector fields:\n$$\n[X_1, X_2] = \\left[\\partial_x - \\frac{y}{2}\\partial_z, \\partial_y + \\frac{x}{2}\\partial_z\\right]\n= [\\partial_x, \\frac{x}{2}\\partial_z] - \\left[\\frac{y}{2}\\partial_z, \\partial_y\\right]\n= \\frac{1}{2}\\partial_z - \\left(-\\frac{1}{2}\\partial_z\\right) = \\partial_z.\n$$\nSince $\\{X_1(q), X_2(q), [X_1,X_2](q)\\}$ span the tangent space $T_q M$ at every point $q$, the distribution $\\mathcal{D}$ is bracket-generating. The problem is scientifically sound.\n- **Well-Posedness**: The problem provides sufficient data and constraints to determine a unique solution. The task is to find a specific set of extremals (geodesics) under given energy, momentum, and initial conditions. The phase canonicalization fixes the final degree of freedom in the solution. The problem is well-posed.\n- **Objectivity**: The problem is stated using precise mathematical language, free of ambiguity or subjective content.\n- **Flaw Analysis**: The problem does not violate any of the invalidity criteria. It is scientifically sound, formalizable, complete, internally consistent, and constitutes a non-trivial, standard problem in its field.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. Proceeding to the solution.\n\n### Task 1: Pontryagin Maximum Principle Formulation\n\nThe state is $q=(x,y,z)$ and the controls are $u=(u_1, u_2)$. The dynamics are $\\dot{q} = u_1 X_1 + u_2 X_2$. The Lagrangian is $L(u) = \\frac{1}{2}(u_1^2 + u_2^2)$. The PMP introduces a covector $p(t) = (p_x(t), p_y(t), p_z(t)) \\in T^*_{q(t)}M$. The control-dependent Hamiltonian is $H_u = \\langle p, \\dot{q} \\rangle - L_0$, where $L_0$ is the integrand of the cost. The problem seeks to minimize energy, which corresponds to choosing $L_0 = L(u)=\\frac{1}{2}(u_1^2+u_2^2)$.\n\nThe control-dependent Hamiltonian is:\n$$ H_u(q,p,u) = \\langle p, u_1 X_1 + u_2 X_2 \\rangle - \\frac{1}{2}(u_1^2 + u_2^2) $$\nLet $h_1 = \\langle p, X_1 \\rangle$ and $h_2 = \\langle p, X_2 \\rangle$. The Hamiltonian becomes:\n$$ H_u = u_1 h_1 + u_2 h_2 - \\frac{1}{2}(u_1^2 + u_2^2) $$\nThe PMP states that for an optimal trajectory, the control $u(t)$ must maximize $H_u$ at each time $t$. We find the maximum by setting the partial derivatives with respect to the controls to zero:\n$$ \\frac{\\partial H_u}{\\partial u_1} = h_1 - u_1 = 0 \\implies u_1 = h_1 $$\n$$ \\frac{\\partial H_u}{\\partial u_2} = h_2 - u_2 = 0 \\implies u_2 = h_2 $$\nThis provides the optimal feedback relation. Substituting these optimal controls back into $H_u$ yields the maximized Hamiltonian (or Pontryagin Hamiltonian) $H$:\n$$ H(q,p) = h_1^2 + h_2^2 - \\frac{1}{2}(h_1^2 + h_2^2) = \\frac{1}{2}(h_1^2+h_2^2) $$\nTo write Hamilton's equations, we express $H$ in canonical coordinates. The covector $p$ has components $(p_x, p_y, p_z)$ dual to $(\\partial_x, \\partial_y, \\partial_z)$.\n$$ h_1 = \\langle p, \\partial_x-\\frac{y}{2}\\partial_z \\rangle = p_x - \\frac{y}{2}p_z $$\n$$ h_2 = \\langle p, \\partial_y+\\frac{x}{2}\\partial_z \\rangle = p_y + \\frac{x}{2}p_z $$\nTherefore, the Hamiltonian is:\n$$ H = \\frac{1}{2} \\left[ \\left( p_x - \\frac{y}{2}p_z \\right)^2 + \\left( p_y + \\frac{x}{2}p_z \\right)^2 \\right] $$\nThe extremal trajectories satisfy Hamilton's equations, $\\dot{q} = \\frac{\\partial H}{\\partial p}$ and $\\dot{p} = -\\frac{\\partial H}{\\partial q}$:\n- **State equations**:\n$$ \\dot{x} = \\frac{\\partial H}{\\partial p_x} = p_x - \\frac{y}{2}p_z = h_1 = u_1 $$\n$$ \\dot{y} = \\frac{\\partial H}{\\partial p_y} = p_y + \\frac{x}{2}p_z = h_2 = u_2 $$\n$$ \\dot{z} = \\frac{\\partial H}{\\partial p_z} = -\\frac{y}{2}h_1 + \\frac{x}{2}h_2 = \\frac{1}{2}(x\\dot{y} - y\\dot{x}) $$\n- **Costate equations**:\n$$ \\dot{p}_x = -\\frac{\\partial H}{\\partial x} = -\\left(p_y + \\frac{x}{2}p_z\\right)\\frac{p_z}{2} = -\\frac{p_z}{2}h_2 $$\n$$ \\dot{p}_y = -\\frac{\\partial H}{\\partial y} = -\\left(p_x - \\frac{y}{2}p_z\\right)\\left(-\\frac{p_z}{2}\\right) = \\frac{p_z}{2}h_1 $$\n$$ \\dot{p}_z = -\\frac{\\partial H}{\\partial z} = 0 $$\n\n### Task 2: Solving for Normal Extremals\n\nWe solve this system under the given conditions.\nThe equation $\\dot{p}_z = 0$ implies $p_z(t)$ is a constant. We are given this constant is $p_z = \\lambda \\neq 0$.\nThe Hamiltonian is also a constant of motion. We are given $H = \\frac{1}{2}\\rho^2$ for some $\\rho>0$. This implies $h_1(t)^2 + h_2(t)^2 = \\rho^2$ for all $t$.\n\nWe find the dynamics of $h_1$ and $h_2$:\n$$ \\dot{h}_1 = \\frac{d}{dt}\\left(p_x - \\frac{y}{2}\\lambda\\right) = \\dot{p}_x - \\frac{\\lambda}{2}\\dot{y} = \\left(-\\frac{\\lambda}{2}h_2\\right) - \\frac{\\lambda}{2}h_2 = -\\lambda h_2 $$\n$$ \\dot{h}_2 = \\frac{d}{dt}\\left(p_y + \\frac{x}{2}\\lambda\\right) = \\dot{p}_y + \\frac{\\lambda}{2}\\dot{x} = \\left(\\frac{\\lambda}{2}h_1\\right) + \\frac{\\lambda}{2}h_1 = \\lambda h_1 $$\nWe have the system $\\dot{h}_1 = -\\lambda h_2$ and $\\dot{h}_2 = \\lambda h_1$. Differentiating the first equation gives $\\ddot{h}_1 = -\\lambda \\dot{h}_2 = -\\lambda(\\lambda h_1) = -\\lambda^2 h_1$. This is the simple harmonic oscillator equation. The general solution is $h_1(t) = A\\cos(\\lambda t) + B\\sin(\\lambda t)$. Then, from the equation $\\dot{h}_1 = -\\lambda h_2$, we find $h_2(t) = -\\frac{1}{\\lambda}\\dot{h}_1 = A\\sin(\\lambda t) - B\\cos(\\lambda t)$.\nThe condition $h_1^2+h_2^2=\\rho^2$ implies $A^2+B^2=\\rho^2$. Let $A = \\rho\\cos(\\phi)$ and $B = \\rho\\sin(\\phi)$ for a phase angle $\\phi$.\n$$ h_1(t) = \\rho \\cos(\\lambda t - \\phi) $$\n$$ h_2(t) = \\rho \\sin(\\lambda t - \\phi) $$\nNow we solve for the state variables $x,y,z$.\n$$ \\dot{x}(t) = h_1(t) = \\rho \\cos(\\lambda t - \\phi) $$\n$$ \\dot{y}(t) = h_2(t) = \\rho \\sin(\\lambda t - \\phi) $$\nIntegrating with the initial condition $q(0) = (0,0,0)$:\n$$ x(t) = \\int_0^t \\rho \\cos(\\lambda \\tau - \\phi) d\\tau = \\left[ \\frac{\\rho}{\\lambda} \\sin(\\lambda \\tau - \\phi) \\right]_0^t = \\frac{\\rho}{\\lambda}(\\sin(\\lambda t - \\phi) + \\sin(\\phi)) $$\n$$ y(t) = \\int_0^t \\rho \\sin(\\lambda \\tau - \\phi) d\\tau = \\left[ -\\frac{\\rho}{\\lambda} \\cos(\\lambda \\tau - \\phi) \\right]_0^t = -\\frac{\\rho}{\\lambda}(\\cos(\\lambda t - \\phi) - \\cos(\\phi)) $$\nWe apply the phase canonicalization: the tangent at $t=0$ has no $y$-component, which means $\\dot{y}(0)=0$.\n$$ \\dot{y}(0) = h_2(0) = \\rho \\sin(-\\phi) = -\\rho\\sin(\\phi) = 0 $$\nSince $\\rho>0$, this implies $\\sin(\\phi)=0$, so $\\phi=k\\pi$ for some integer $k$. We choose $\\phi=0$, which gives $\\cos(\\phi)=1$. This choice simplifies the expressions without loss of generality (the choice $\\phi=\\pi$ would flip the signs of $x$ and $y$).\nWith $\\phi=0$, the expressions for $x(t)$ and $y(t)$ become:\n$$ x(t) = \\frac{\\rho}{\\lambda}(\\sin(\\lambda t) + \\sin(0)) = \\frac{\\rho}{\\lambda}\\sin(\\lambda t) $$\n$$ y(t) = -\\frac{\\rho}{\\lambda}(\\cos(\\lambda t) - \\cos(0)) = \\frac{\\rho}{\\lambda}(1 - \\cos(\\lambda t)) $$\nThe controls become $u_1(t) = h_1(t) = \\rho\\cos(\\lambda t)$ and $u_2(t) = h_2(t) = \\rho\\sin(\\lambda t)$.\nFinally, we solve for $z(t)$ using $\\dot{z} = \\frac{1}{2}(x\\dot{y} - y\\dot{x})$:\n$$ \\dot{z}(t) = \\frac{1}{2} \\left[ \\left(\\frac{\\rho}{\\lambda}\\sin(\\lambda t)\\right)(\\rho \\sin(\\lambda t)) - \\left(\\frac{\\rho}{\\lambda}(1 - \\cos(\\lambda t))\\right)(\\rho \\cos(\\lambda t)) \\right] $$\n$$ \\dot{z}(t) = \\frac{\\rho^2}{2\\lambda} \\left[ \\sin^2(\\lambda t) - (\\cos(\\lambda t) - \\cos^2(\\lambda t)) \\right] $$\n$$ \\dot{z}(t) = \\frac{\\rho^2}{2\\lambda} \\left[ (\\sin^2(\\lambda t) + \\cos^2(\\lambda t)) - \\cos(\\lambda t) \\right] = \\frac{\\rho^2}{2\\lambda}(1 - \\cos(\\lambda t)) $$\nIntegrating with $z(0)=0$:\n$$ z(t) = \\int_0^t \\frac{\\rho^2}{2\\lambda}(1 - \\cos(\\lambda \\tau)) d\\tau = \\frac{\\rho^2}{2\\lambda} \\left[ \\tau - \\frac{1}{\\lambda}\\sin(\\lambda \\tau) \\right]_0^t $$\n$$ z(t) = \\frac{\\rho^2}{2\\lambda} \\left(t - \\frac{1}{\\lambda}\\sin(\\lambda t)\\right) = \\frac{\\rho^2}{2\\lambda^2}(\\lambda t - \\sin(\\lambda t)) $$\nThe final trajectory is given by the triplet $(x(t), y(t), z(t))$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{\\rho}{\\lambda}\\sin(\\lambda t)  \\frac{\\rho}{\\lambda}(1 - \\cos(\\lambda t))  \\frac{\\rho^2}{2\\lambda^2}(\\lambda t - \\sin(\\lambda t)) \\end{pmatrix}}\n$$"
        }
    ]
}