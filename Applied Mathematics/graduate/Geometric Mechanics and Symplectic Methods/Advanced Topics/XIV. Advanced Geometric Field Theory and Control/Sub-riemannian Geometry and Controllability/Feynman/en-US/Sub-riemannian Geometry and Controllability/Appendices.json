{
    "hands_on_practices": [
        {
            "introduction": "To navigate a constrained system, we must first determine if we can reach all nearby points. This fundamental property, known as controllability, is not guaranteed by the control vector fields alone but is revealed through their Lie brackets. This practice provides a concrete exercise in applying the bracket-generating condition, also known as Hörmander's condition, to determine the controllability of a system at a specific point .",
            "id": "3767485",
            "problem": "Consider the smooth distribution $\\Delta=\\mathrm{span}\\{X_1, X_2\\}$ on $\\mathbb{R}^3$ defined by the vector fields $X_1=\\partial_x$ and $X_2=x\\,\\partial_y+\\partial_z$. Equip $\\Delta$ with a sub-Riemannian structure by declaring $X_1$ and $X_2$ orthonormal at every point. Using the foundational definitions of the Lie bracket of vector fields, the flag of a distribution at a point, and the bracket-generating (Hörmander) condition from geometric control theory, determine whether $\\Delta$ is bracket-generating at the origin $0\\in\\mathbb{R}^3$. Then compute the minimal step $s\\in\\mathbb{N}$ of the bracket generation at the origin, defined as the smallest integer such that the span of all iterated Lie brackets of $X_1$ and $X_2$ of length at most $s$ evaluated at the origin equals the full tangent space $T_0\\mathbb{R}^3$. Provide your final answer as the single integer $s$.",
            "solution": "The problem requires us to determine if a given distribution $\\Delta$ on $\\mathbb{R}^3$ is bracket-generating at the origin and to find the minimal step $s$ for this generation. The bracket-generating property, also known as Hörmander's condition, is a fundamental concept in geometric control theory and sub-Riemannian geometry that ensures the controllability of the system defined by the vector fields.\n\nThe distribution is given by $\\Delta = \\mathrm{span}\\{X_1, X_2\\}$, where the vector fields are defined on $\\mathbb{R}^3$ with coordinates $(x, y, z)$ as:\n$$X_1 = \\partial_x$$\n$$X_2 = x\\,\\partial_y + \\partial_z$$\nIn the standard basis $\\{\\partial_x, \\partial_y, \\partial_z\\}$ of the tangent bundle $T\\mathbb{R}^3$, these vector fields can be represented as column vectors:\n$$X_1 = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\quad X_2 = \\begin{pmatrix} 0 \\\\ x \\\\ 1 \\end{pmatrix}$$\n\nThe bracket-generating condition at a point $p \\in \\mathbb{R}^3$ states that the tangent space $T_p\\mathbb{R}^3$ is spanned by the values of the generating vector fields and their iterated Lie brackets evaluated at $p$. Let $\\mathcal{L}_k$ be the set of all iterated Lie brackets of $X_1$ and $X_2$ of length at most $k$. The condition is satisfied at $p$ if there exists some integer $s$ such that $\\mathrm{span}\\{Y(p) \\mid Y \\in \\mathcal{L}_s\\} = T_p\\mathbb{R}^3$. The minimal such integer $s$ is the step of the bracket generation.\n\nWe will proceed by constructing the flag of the distribution at the origin $p=0=(0,0,0)$. Let $\\Delta_k(p) = \\mathrm{span}\\{Y(p) \\mid Y \\in \\mathcal{L}_k\\}$. We seek the smallest $s \\in \\mathbb{N}$ such that $\\dim(\\Delta_s(0)) = 3$.\n\n**Step 1: Evaluation for $s=1$**\n\nFor $s=1$, we consider the space spanned by the generating vector fields themselves, evaluated at the origin $p=0$.\nThe set of vector fields is $\\mathcal{L}_1 = \\{X_1, X_2\\}$. Evaluating them at $0=(0,0,0)$:\n$$X_1(0) = \\partial_x|_0 = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}$$\n$$X_2(0) = x\\,\\partial_y|_0 + \\partial_z|_0 = (0)\\,\\partial_y|_0 + \\partial_z|_0 = \\partial_z|_0 = \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix}$$\nThe space spanned by these vectors is $\\Delta_1(0) = \\mathrm{span}\\{X_1(0), X_2(0)\\} = \\mathrm{span}\\{(1,0,0)^T, (0,0,1)^T\\}$.\nThe dimension of this subspace is $\\dim(\\Delta_1(0)) = 2$. Since this is less than the dimension of the ambient space $\\mathbb{R}^3$, which is $3$, the step $s=1$ is insufficient to generate the full tangent space.\n\n**Step 2: Evaluation for $s=2$**\n\nFor $s=2$, we must augment our set of vector fields with all Lie brackets of length $2$. The only new, non-trivial bracket (up to sign) is $[X_1, X_2]$. The Lie bracket of two vector fields $X$ and $Y$ is defined by the commutator of their actions as differential operators, $[X,Y] = XY - YX$.\nLet us compute $[X_1, X_2]$:\n$$[X_1, X_2] = [\\partial_x, x\\,\\partial_y + \\partial_z] = [\\partial_x, x\\,\\partial_y] + [\\partial_x, \\partial_z]$$\nThe bracket of two constant-coefficient vector fields is zero, so $[\\partial_x, \\partial_z] = 0$. For the first term, we apply the rule $[X, fY] = X(f)Y + f[X,Y]$.\n$$[\\partial_x, x\\,\\partial_y] = (\\partial_x x)\\,\\partial_y + x[\\partial_x, \\partial_y]$$\nSince $\\partial_x x = 1$ and $[\\partial_x, \\partial_y]=0$, we get:\n$$[\\partial_x, x\\,\\partial_y] = (1)\\,\\partial_y + x(0) = \\partial_y$$\nTherefore, the Lie bracket is:\n$$[X_1, X_2] = \\partial_y$$\nThis new vector field, let's call it $X_3 = [X_1, X_2]$, is a constant vector field:\n$$X_3 = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}$$\nNow, we evaluate all brackets of length at most $2$ at the origin $p=0$. The set of vector fields is $\\mathcal{L}_2 = \\{X_1, X_2, [X_1, X_2]\\}$. The evaluated vectors are:\n$$X_1(0) = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}$$\n$$X_2(0) = \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix}$$\n$$[X_1, X_2](0) = X_3(0) = \\partial_y|_0 = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}$$\nThe space spanned by these vectors is $\\Delta_2(0) = \\mathrm{span}\\{X_1(0), X_2(0), [X_1, X_2](0)\\}$. This is the span of the three standard basis vectors of $\\mathbb{R}^3$:\n$$\\Delta_2(0) = \\mathrm{span}\\left\\{ \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix}, \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix} \\right\\}$$\nThese three vectors are clearly linearly independent. We can form a matrix with these vectors as columns, and its determinant is non-zero:\n$$\\det \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 0 & 1 \\\\ 0 & 1 & 0 \\end{pmatrix} = 1(0-1) = -1 \\neq 0$$\nThus, these vectors form a basis for $\\mathbb{R}^3$, and their span is the entire tangent space at the origin, $T_0\\mathbb{R}^3$.\n$$\\dim(\\Delta_2(0)) = 3$$\n\n**Conclusion**\n\nSince the iterated Lie brackets of length up to $2$ span the full tangent space at the origin, the distribution $\\Delta$ is indeed bracket-generating at this point. The minimal step $s$ is the smallest integer for which this holds.\n- For $s=1$, $\\dim(\\Delta_1(0)) = 2 < 3$.\n- For $s=2$, $\\dim(\\Delta_2(0)) = 3$.\n\nTherefore, the minimal step of the bracket generation at the origin is $s=2$. It is not necessary to compute brackets of higher length, such as $[X_1, [X_1, X_2]]$ or $[X_2, [X_1, X_2]]$, as we have already achieved full rank.",
            "answer": "$$\\boxed{2}$$"
        },
        {
            "introduction": "Once controllability is established, the central problem in sub-Riemannian geometry becomes finding the shortest path, or 'geodesic,' between two points. The Pontryagin Maximum Principle (PMP) provides the essential framework for solving this energy-minimization problem. This exercise walks through the foundational derivation that connects the PMP to the sub-Riemannian Hamiltonian, the function that governs the dynamics of optimal paths .",
            "id": "3767465",
            "problem": "Consider a smooth connected manifold $M$ of dimension $n$ and a smooth rank-$m$ distribution $\\mathcal{D} \\subset TM$ locally spanned by smooth vector fields $\\{X_{1},\\dots,X_{m}\\}$ such that $\\mathcal{D}$ is bracket-generating. Let the system be driftless and control-affine,\n$$\n\\dot{x}(t)=\\sum_{i=1}^{m}u_{i}(t)\\,X_{i}\\big(x(t)\\big),\n$$\nwith control $u(t)=(u_{1}(t),\\dots,u_{m}(t))\\in\\mathbb{R}^{m}$. Consider the energy minimization cost\n$$\nJ[u]=\\int_{0}^{T}\\frac{1}{2}\\|u(t)\\|^{2}\\,dt,\n$$\nwhere $\\|\\cdot\\|$ is the Euclidean norm on $\\mathbb{R}^{m}$, and $T>0$ is fixed. Using the Pontryagin Maximum Principle (PMP) in the geometric mechanics and symplectic methods framework, start from the canonical pairing between the cotangent vector $p(t)\\in T^{*}_{x(t)}M$ and tangent vectors in $T_{x(t)}M$, and from the general control-affine PMP construction on the cotangent bundle with its canonical symplectic structure, to perform the following steps:\n\n1. Formulate the appropriate Hamiltonian on the cotangent bundle $T^{*}M$ that encodes the dynamics and the running cost.\n2. Impose the stationarity condition with respect to the control to obtain the optimality relation for the control components $u_{i}(t)$ in terms of the costate $p(t)$ and the vector fields $X_{i}$.\n3. Eliminate the control and write the resulting sub-Riemannian Hamiltonian purely as a function of the state $x$ and the costate $p$.\n\nProvide the final result as closed-form analytic expressions for the maximized sub-Riemannian Hamiltonian and the optimal control as functions of $(x,p)$. No numerical rounding is required. Your final answer must be a single composite expression.",
            "solution": "The problem requires the derivation of the optimal control law and the corresponding maximized Hamiltonian for a driftless, control-affine system with a quadratic cost functional. This is the canonical problem of sub-Riemannian geometry. The derivation will be performed using the Pontryagin Maximum Principle (PMP) on the cotangent bundle $T^{*}M$.\n\nLet a point on the cotangent bundle $T^{*}M$ be denoted by a pair $(x, p)$, where $x \\in M$ is a point on the manifold and $p \\in T_{x}^{*}M$ is a covector at that point. The PMP seeks to find necessary conditions for an optimal control $u(t)$ and its corresponding state trajectory $x(t)$. It introduces an auxiliary trajectory, the costate $p(t) \\in T_{x(t)}^{*}M$, which is a curve in the cotangent bundle covering the state trajectory.\n\nThe core of the PMP is the Pontryagin Hamiltonian (or pre-Hamiltonian), which is a function on $T^*M \\times \\mathbb{R}^m$. For a system with dynamics $\\dot{x} = f(x, u)$ and running cost $L(x, u)$, this Hamiltonian is defined as $H(x, p, u, \\lambda_0) = \\langle p, f(x,u) \\rangle - \\lambda_0 L(x,u)$, where $\\langle \\cdot, \\cdot \\rangle$ denotes the canonical pairing between a covector $p \\in T_x^*M$ and a vector $v \\in T_xM$. The constant $\\lambda_0$ is a non-negative number. For non-trivial extremals, $(\\lambda_0, p(t))$ cannot be identically zero. If $\\lambda_0 = 0$, the extremal is called abnormal. If $\\lambda_0 > 0$, the extremal is normal, and we can rescale the costate to set $\\lambda_0=1$. For the given problem, which involves minimizing energy on a controllable system, we consider normal extremals and set $\\lambda_0=1$.\n\nStep 1: Formulate the control-dependent Hamiltonian.\n\nThe system dynamics are given by $f(x,u) = \\dot{x}(t)=\\sum_{i=1}^{m}u_{i}(t)\\,X_{i}\\big(x(t)\\big)$. The running cost is $L(u) = \\frac{1}{2}\\|u(t)\\|^{2} = \\frac{1}{2}\\sum_{i=1}^{m}u_{i}(t)^{2}$. The problem statement correctly notes that the cost only depends on the control $u$, not the state $x$.\n\nThe Pontryagin Hamiltonian $H_u(x,p)$, which depends on the control $u \\in \\mathbb{R}^m$, is constructed as:\n$$\nH_u(x,p) = \\langle p, f(x,u) \\rangle - L(u)\n$$\nSubstituting the given expressions for $f(x,u)$ and $L(u)$:\n$$\nH_u(x,p) = \\left\\langle p, \\sum_{i=1}^{m}u_{i}X_{i}(x) \\right\\rangle - \\frac{1}{2}\\sum_{i=1}^{m}u_{i}^{2}\n$$\nUsing the linearity of the canonical pairing in its second argument, we can write:\n$$\nH_u(x,p) = \\sum_{i=1}^{m}u_{i}\\langle p, X_{i}(x) \\rangle - \\frac{1}{2}\\sum_{i=1}^{m}u_{i}^{2}\n$$\nIt is standard to define the fiber-linear functions $H_i: T^*M \\to \\mathbb{R}$ as the Hamiltonian lifts of the vector fields $X_i$:\n$$\nH_i(x,p) := \\langle p, X_i(x) \\rangle\n$$\nIn local coordinates $(x^j, p_j)$, if $X_i = \\sum_{j=1}^n X_i^j(x) \\frac{\\partial}{\\partial x^j}$, then $H_i(x,p) = \\sum_{j=1}^n p_j X_i^j(x)$.\nUsing this notation, the control-dependent Hamiltonian is:\n$$\nH_u(x,p) = \\sum_{i=1}^{m}u_{i}H_i(x,p) - \\frac{1}{2}\\sum_{i=1}^{m}u_{i}^{2}\n$$\nThis completes the first step.\n\nStep 2: Impose the stationarity condition for the control.\n\nThe PMP states that for an optimal trajectory, the control $u^*(t)$ must maximize the Hamiltonian $H_u(x(t), p(t))$ for almost all $t \\in [0, T]$. That is,\n$$\nH_{u^*(t)}(x(t),p(t)) = \\max_{v \\in \\mathbb{R}^m} H_v(x(t),p(t))\n$$\nTo find the control $u^*$ that maximizes $H_u(x,p)$ for a fixed $(x,p)$, we find the critical points by setting the gradient with respect to $u$ to zero. For each component $u_j$ where $j \\in \\{1, \\dots, m\\}$:\n$$\n\\frac{\\partial H_u}{\\partial u_j} = \\frac{\\partial}{\\partial u_j}\\left( \\sum_{i=1}^{m}u_{i}H_i(x,p) - \\frac{1}{2}\\sum_{i=1}^{m}u_{i}^{2} \\right) = H_j(x,p) - u_j\n$$\nSetting this to zero yields the stationarity condition:\n$$\nH_j(x,p) - u_j = 0 \\implies u_j = H_j(x,p)\n$$\nTo confirm this is a maximum, we examine the Hessian matrix of $H_u$ with respect to $u$:\n$$\n\\frac{\\partial^2 H_u}{\\partial u_j \\partial u_k} = -\\delta_{jk}\n$$\nwhere $\\delta_{jk}$ is the Kronecker delta. The Hessian is the negative of the $m \\times m$ identity matrix, which is negative definite. Thus, the stationarity condition indeed yields a unique global maximum.\n\nThe optimal control law is therefore given by:\n$$\nu_i^*(x,p) = H_i(x,p) = \\langle p, X_i(x) \\rangle \\quad \\text{for } i=1, \\dots, m\n$$\nThis provides the optimal control components as functions of the state $x$ and costate $p$.\n\nStep 3: Eliminate the control to find the sub-Riemannian Hamiltonian.\n\nThe maximized Hamiltonian, denoted $H_{SR}(x,p)$, is obtained by substituting the optimal control law $u^*(x,p)$ back into the expression for $H_u(x,p)$. This $H_{SR}(x,p)$ is the true Hamiltonian for the optimal system, whose integral curves on $T^*M$ are the optimal trajectories (extremals).\n$$\nH_{SR}(x,p) = H_{u^*(x,p)}(x,p) = \\sum_{i=1}^{m}u_i^*(x,p)H_i(x,p) - \\frac{1}{2}\\sum_{i=1}^{m}(u_i^*(x,p))^2\n$$\nSubstituting $u_i^*(x,p) = H_i(x,p)$:\n$$\nH_{SR}(x,p) = \\sum_{i=1}^{m}H_i(x,p) \\cdot H_i(x,p) - \\frac{1}{2}\\sum_{i=1}^{m}(H_i(x,p))^2\n$$\n$$\nH_{SR}(x,p) = \\sum_{i=1}^{m}H_i(x,p)^2 - \\frac{1}{2}\\sum_{i=1}^{m}H_i(x,p)^2\n$$\nThis simplifies to:\n$$\nH_{SR}(x,p) = \\frac{1}{2}\\sum_{i=1}^{m}H_i(x,p)^2\n$$\nSubstituting back the definition $H_i(x,p) = \\langle p, X_i(x) \\rangle$, the final expression for the sub-Riemannian Hamiltonian is:\n$$\nH_{SR}(x,p) = \\frac{1}{2}\\sum_{i=1}^{m} \\left( \\langle p, X_i(x) \\rangle \\right)^2\n$$\nThis Hamiltonian is quadratic in the covector $p$, which is a defining characteristic of sub-Riemannian and Riemannian geometry. The optimal trajectories $(x(t), p(t))$ are solutions to the Hamilton's equations derived from this Hamiltonian $H_{SR}$.\n\nIn summary, the final results are the expression for the optimal control component $u_i^*$ and the maximized sub-Riemannian Hamiltonian $H_{SR}$, both as functions of the state $x$ and costate $p$.\nThe optimal control for the $i$-th component is $u_i^*(x,p) = \\langle p, X_i(x) \\rangle$.\nThe maximized sub-Riemannian Hamiltonian is $H_{SR}(x,p) = \\frac{1}{2} \\sum_{i=1}^{m} \\left( \\langle p, X_i(x) \\rangle \\right)^2$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{1}{2} \\sum_{k=1}^{m} \\left( \\langle p, X_{k}(x) \\rangle \\right)^2 & \\langle p, X_{i}(x) \\rangle\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "The Pontryagin Maximum Principle is a powerful tool, but it occasionally reveals surprising solutions known as 'abnormal extremals,' which are independent of the energy cost. These special paths are not mathematical quirks but are deeply connected to the geometric singularities of the distribution where the bracket-generating condition fails. This advanced practice explores the nature of these abnormal paths and their relationship to the underlying geometry of the control system .",
            "id": "3767548",
            "problem": "Consider a driftless control-affine system on $\\mathbb{R}^{3}$ with coordinates $(x,y,z)$ defined by two smooth control vector fields $X_{1}$ and $X_{2}$ and measurable controls $u_{1}(t)$ and $u_{2}(t)$ taking values in the closed unit disk of $\\mathbb{R}^{2}$, so that the state equation is\n$$\n\\dot{x}(t)=u_{1}(t),\\quad \\dot{y}(t)=u_{2}(t),\\quad \\dot{z}(t)=\\frac{y(t)^{2}}{2}\\,u_{1}(t),\n$$\nwhich is equivalently the distribution $\\mathcal{D}$ spanned by\n$$\nX_{1}(x,y,z)=\\partial_{x}+\\frac{y^{2}}{2}\\,\\partial_{z},\\qquad X_{2}(x,y,z)=\\partial_{y}.\n$$\nWe pose the time-optimal problem of steering the system from $(0,0,0)$ to $(L,0,0)$, with $L>0$, under the constraint $u_{1}(t)^{2}+u_{2}(t)^{2}\\leq 1$ for almost every $t$, and with free terminal time.\n\nBegin from the Pontryagin Maximum Principle (PMP) on the cotangent bundle $T^{*}\\mathbb{R}^{3}$ endowed with the canonical symplectic form, and its Hamiltonian lift for control-affine systems. Explain what the abnormal case $\\lambda_{0}=0$ implies for the necessary conditions of optimality, in particular how the maximizing condition and the costate dynamics depend only on the distribution $\\mathcal{D}$ and not on any metric or quadratic form on $\\mathcal{D}$. Then, construct abnormal extremals for the rank-$2$ Martinet distribution above by analyzing the singular set $\\{y=0\\}$ where the bracket-generating condition fails and exhibiting a nontrivial covector annihilating $\\mathcal{D}$ along an extremal that remains in $\\{y=0\\}$.\n\nFinally, compute explicitly the unique (up to multiplication by a nonzero constant) smooth one-form $\\omega$ on $\\mathbb{R}^{3}$ whose kernel equals the distribution $\\mathcal{D}$ for all $(x,y,z)$, that is, the one-form satisfying $\\omega(X_{1})=0$ and $\\omega(X_{2})=0$ everywhere. Provide your final answer as the closed-form analytic expression for $\\omega$ in the standard coordinate coframe $\\{dx,dy,dz\\}$.",
            "solution": "We start from the Pontryagin Maximum Principle for control-affine systems on a smooth manifold $M$ with state $x(t)\\in M$, controls $u(t)\\in U\\subset\\mathbb{R}^{m}$ (compact), and dynamics $\\dot{x}(t)=f(x(t),u(t))$. The PMP asserts the existence of a multiplier pair $(\\lambda_{0},p(t))$, where $\\lambda_{0}\\in\\{0,1\\}$ and $p(t)\\in T_{x(t)}^{*}M\\setminus\\{0\\}$, such that the Hamiltonian\n$$\nH(x,p,u)=\\langle p, f(x,u)\\rangle + \\lambda_{0}\\,\\ell(x,u)\n$$\nis maximized by $u(t)$ almost everywhere, and the costate $p(t)$ evolves by the Hamiltonian equations $\\dot{p}(t)=-\\partial_{x}H(x(t),p(t),u(t))$, together with the transversality or endpoint conditions appropriate to the problem. For time-optimal control with free terminal time, the running cost $\\ell\\equiv 1$, but the abnormal case $\\lambda_{0}=0$ eliminates the cost term from the Hamiltonian, leaving $H(x,p,u)=\\langle p, f(x,u)\\rangle$. In this case, the PMP conditions depend only on the control system and the admissible control set $U$, not on a metric on the distribution or a quadratic cost, and one speaks of abnormal extremals. For driftless systems $f(x,u)=\\sum_{i=1}^{m}u_{i}X_{i}(x)$, the Hamiltonian becomes\n$$\nH(x,p,u)=\\sum_{i=1}^{m}u_{i}\\,\\langle p, X_{i}(x)\\rangle,\n$$\nwhich is linear in $u$. The maximization over a compact $U$ is determined solely by the covector components $\\langle p, X_{i}(x)\\rangle$; in particular, if $\\langle p, X_{i}(x)\\rangle=0$ for all $i$, then $H\\equiv 0$ and any admissible control is a maximizer. The costate equation for driftless systems can be written in the Lie-algebraic form\n$$\n\\frac{d}{dt}\\langle p(t),Y\\rangle=-\\left\\langle p(t),\\left[\\sum_{i=1}^{m}u_{i}(t)X_{i},Y\\right]\\right\\rangle\n$$\nfor all smooth vector fields $Y$, which shows that the evolution of $p$ is governed by the adjoint action of the controlled vector field, independent of any metric. In abnormal extremals it is typical that $p(t)\\in\\mathrm{Ann}(\\mathcal{D}_{x(t)})$ along the trajectory, where $\\mathrm{Ann}(\\mathcal{D}_{x})\\subset T_{x}^{*}M$ denotes the annihilator of the distribution at $x$.\n\nWe now analyze the Martinet distribution $\\mathcal{D}=\\mathrm{span}\\{X_{1},X_{2}\\}$ on $\\mathbb{R}^{3}$ with\n$$\nX_{1}=\\partial_{x}+\\frac{y^{2}}{2}\\,\\partial_{z},\\qquad X_{2}=\\partial_{y}.\n$$\nA direct computation of the Lie bracket yields\n$$\n[X_{1},X_{2}]=\\left[\\partial_{x}+\\frac{y^{2}}{2}\\,\\partial_{z},\\,\\partial_{y}\\right]=-\\frac{\\partial}{\\partial y}\\left(\\frac{y^{2}}{2}\\right)\\partial_{z}=-y\\,\\partial_{z}.\n$$\nAway from the singular set $\\{y=0\\}$, the family $\\{X_{1},X_{2},[X_{1},X_{2}]\\}$ spans $T\\mathbb{R}^{3}$, and the distribution is bracket-generating. On the singular set $\\{y=0\\}$, the bracket vanishes, and $\\mathcal{D}$ fails to generate the $\\partial_{z}$ direction, which is responsible for the existence of abnormal extremals contained in $\\{y=0\\}$.\n\nTo construct abnormal extremals, we look for a smooth one-form $\\omega$ whose kernel is precisely the distribution $\\mathcal{D}$. Equivalently, we seek $\\omega$ such that\n$$\n\\omega(X_{1})=0,\\qquad \\omega(X_{2})=0.\n$$\nWrite a general one-form as $\\omega=a(x,y,z)\\,dx+b(x,y,z)\\,dy+c(x,y,z)\\,dz$. Evaluating on $X_{2}=\\partial_{y}$ yields\n$$\n\\omega(X_{2})=a\\,dx(\\partial_{y})+b\\,dy(\\partial_{y})+c\\,dz(\\partial_{y})=b=0,\n$$\nso $b\\equiv 0$. Evaluating on $X_{1}=\\partial_{x}+\\frac{y^{2}}{2}\\,\\partial_{z}$ yields\n$$\n\\omega(X_{1})=a\\,dx(\\partial_{x})+0+c\\,dz\\!\\left(\\partial_{x}+\\frac{y^{2}}{2}\\,\\partial_{z}\\right)=a+c\\,\\frac{y^{2}}{2}=0.\n$$\nOne choice, unique up to multiplication by a nonzero scalar, is to take $c\\equiv 1$ and $a\\equiv -\\frac{y^{2}}{2}$. Thus\n$$\n\\omega=dz-\\frac{y^{2}}{2}\\,dx.\n$$\nThis is the canonical Martinet one-form, and indeed $\\mathcal{D}=\\ker\\omega$.\n\nOn the singular set $\\{y=0\\}$, the one-form reduces to $\\omega|_{y=0}=dz$, so any covector proportional to $dz$ annihilates both $X_{1}$ and $X_{2}$. Consider the admissible control $u_{1}(t)\\equiv 1$, $u_{2}(t)\\equiv 0$. Then the trajectory $(x(t),y(t),z(t))$ satisfies\n$$\n\\dot{x}(t)=1,\\quad \\dot{y}(t)=0,\\quad \\dot{z}(t)=\\frac{y(t)^{2}}{2}\\cdot 1=0,\n$$\nwith the solution\n$$\nx(t)=t,\\quad y(t)=0,\\quad z(t)=0.\n$$\nAlong this curve, $\\omega=dz$, and we can choose a nontrivial costate $p(t)=\\omega$ (up to scalar multiplication). The Hamiltonian in the abnormal case is\n$$\nH(x,p,u)=u_{1}\\,\\langle p, X_{1}\\rangle+u_{2}\\,\\langle p, X_{2}\\rangle,\n$$\nwhich vanishes because $\\langle p, X_{1}\\rangle=\\langle dz, \\partial_{x}+\\frac{y^{2}}{2}\\partial_{z}\\rangle=0$ and $\\langle p, X_{2}\\rangle=\\langle dz, \\partial_{y}\\rangle=0$. Therefore any admissible control maximizes $H$ identically. The costate evolution for driftless systems satisfies\n$$\n\\frac{d}{dt}\\langle p(t),Y\\rangle=-\\left\\langle p(t),\\left[u_{1}(t)X_{1}+u_{2}(t)X_{2},\\,Y\\right]\\right\\rangle.\n$$\nAlong $y(t)=0$ with $u_{1}=1$, $u_{2}=0$, and for $p(t)=dz$, we use $[X_{1},Y]$ evaluated at $y=0$; the only potentially nonzero bracket component in the $\\partial_{z}$ direction is proportional to $y$, which vanishes on the singular set. Consequently $p(t)$ remains constant, verifying the abnormal extremal conditions. The time-optimality of the chosen control to reach $(L,0,0)$ follows from the bound $|\\dot{x}|=|u_{1}|\\leq 1$, which implies $T\\geq L$, and our control achieves $T=L$; this argument depends only on the control constraint and the distribution, not on any metric on $\\mathcal{D}$.\n\nThe requested closed-form expression for the annihilating one-form $\\omega$ is therefore\n$$\n\\omega=dz-\\frac{y^{2}}{2}\\,dx.\n$$",
            "answer": "$$\\boxed{dz-\\frac{y^{2}}{2}\\,dx}$$"
        }
    ]
}