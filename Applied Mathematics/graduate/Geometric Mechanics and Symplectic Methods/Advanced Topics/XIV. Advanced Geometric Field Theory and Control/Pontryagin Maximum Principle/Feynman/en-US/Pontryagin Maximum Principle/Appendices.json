{
    "hands_on_practices": [
        {
            "introduction": "The time-optimal control of a double integrator is a cornerstone problem in optimal control theory, providing a clear and tangible application of the Pontryagin Maximum Principle (PMP). This exercise challenges you to find the fastest way to steer a simple system—modeling, for instance, a point mass accelerated by a thruster—to the origin. The solution involves deriving the celebrated \"bang-bang\" control structure and constructing the switching curve in the state space, which dictates when the control must flip from one extreme to the other. This practice is fundamental for building intuition about the geometric interpretation of PMP and the nature of time-optimal trajectories .",
            "id": "3762899",
            "problem": "Consider the time-optimal control problem on the configuration space $\\mathbb{R}^{2}$ with state $x=(x_{1},x_{2})$ governed by the control-affine dynamics $\\dot{x}_{1}=x_{2}$ and $\\dot{x}_{2}=u$, where the control $u$ takes values in the compact convex set $U=[-1,1]$. The objective is to steer the system from the initial state $x(0)=(1,-1)$ to the terminal state $x(T)=(0,0)$ in minimum time $T0$. Assume a normal extremal in the sense of Pontryagin's maximum principle (PMP), with the cost functional $J=\\int_{0}^{T} 1 \\, \\mathrm{d}t$. \n\nUsing the geometric formulation of Pontryagin's maximum principle (PMP), interpret the necessary conditions as a Hamiltonian system on the cotangent bundle $T^{*}\\mathbb{R}^{2}$ endowed with the canonical symplectic form, and derive the switching structure of the optimal control. Then, by enforcing the transversality and continuity conditions for the state and costate, determine:\n- the optimal bang-bang sequence (i.e., the signs of $u$ on each arc and their order),\n- the unique switching time $\\tau \\in [0,T]$, and\n- the minimal final time $T$.\n\nProvide your final answer as the ordered pair $(\\tau, T)$ in exact algebraic form. No numerical approximation is required. Your final answer must be a single expression; report it as a row vector with two entries.",
            "solution": "This is a time-optimal control problem for a double integrator system. We will solve it using the geometric interpretation of Pontryagin's maximum principle (PMP).\n\nThe problem statement is first validated.\nGivens:\n- State space: $\\mathbb{R}^{2}$, with state $x=(x_{1},x_{2})$.\n- Dynamics: $\\dot{x}_{1}=x_{2}$, $\\dot{x}_{2}=u$.\n- Control set: $u \\in U=[-1,1]$.\n- Initial state: $x(0)=(1,-1)$.\n- Terminal state: $x(T)=(0,0)$.\n- Objective: Minimize final time $T  0$.\n- Cost functional: $J = \\int_{0}^{T} 1 \\, dt$. This corresponds to a running cost $L(x,u) = 1$.\n- Assumption: The extremal is normal.\n\nThe problem is scientifically grounded, well-posed, objective, and complete. It is a canonical example in optimal control theory and is suitable for solution. The problem is valid.\n\nWe proceed with the solution.\n\n1.  **Hamiltonian Formulation:**\n    The problem is set on the cotangent bundle $T^{*}\\mathbb{R}^{2}$ with coordinates $(x, p) = (x_1, x_2, p_1, p_2)$. The Hamiltonian for this optimal control problem is given by $H(x,p,u) = p_0 L(x,u) + \\langle p, f(x,u) \\rangle$, where $f(x,u)$ is the vector field of the dynamics.\n    Given $L(x,u)=1$ and $f(x,u)=(x_2, u)$, the Hamiltonian is:\n    $$H(x,p,u) = p_0 + p_1 x_2 + p_2 u$$\n    The problem states we assume a normal extremal, which implies the costate multiplier $p_0$ is non-zero. For a minimization problem, we have $p_0 \\leq 0$. By scaling the costate vector $(p_0, p)$, we can set $p_0 = -1$.\n    $$H(x,p,u) = p_1 x_2 + p_2 u - 1$$\n\n2.  **Pontryagin's Maximum Principle (PMP):**\n    PMP states that for an optimal control $u^*(t)$ and corresponding state trajectory $x^*(t)$, there exists a non-zero costate trajectory $p(t)$ such that:\n    (i) The Hamiltonian is maximized by the optimal control:\n    $$H(x^*(t), p(t), u^*(t)) = \\max_{v \\in [-1,1]} H(x^*(t), p(t), v)$$\n    (ii) The state and costate variables evolve according to Hamilton's equations:\n    $$\\dot{x}_i = \\frac{\\partial H}{\\partial p_i}, \\quad \\dot{p}_i = -\\frac{\\partial H}{\\partial x_i}$$\n    (iii) The maximized Hamiltonian $\\mathcal{H}(x,p) = \\max_{u \\in U} H(x,p,u)$ is constant along the optimal trajectory. For a time-optimal problem (free final time), this constant value is zero.\n    $$\\mathcal{H}(x^*(t), p(t)) = 0 \\quad \\forall t \\in [0,T]$$\n\n3.  **Optimal Control Law and Costate Dynamics:**\n    From condition (i), to maximize $H = p_1 x_2 + p_2 u - 1$ with respect to $u \\in [-1,1]$, we must maximize the term $p_2 u$. This yields the control law:\n    $$u^*(t) = \\mathrm{sgn}(p_2(t))$$\n    This is a bang-bang control law. The control switches value only when the switching function $\\phi(t) = p_2(t)$ passes through zero.\n\n    From condition (ii), Hamilton's equations are:\n    $\\dot{x}_1 = \\frac{\\partial H}{\\partial p_1} = x_2$\n    $\\dot{x}_2 = \\frac{\\partial H}{\\partial p_2} = u$\n    (These are the state dynamics, as expected.)\n    $\\dot{p}_1 = -\\frac{\\partial H}{\\partial x_1} = 0 \\implies p_1(t) = c_1$ (a constant)\n    $\\dot{p}_2 = -\\frac{\\partial H}{\\partial x_2} = -p_1 = -c_1 \\implies p_2(t) = -c_1 t + c_2$ (a constant)\n    Since the switching function $p_2(t)$ is a linear function of time, it can have at most one zero (unless $c_1=0$, which would imply constant control, a case we can show does not satisfy the boundary conditions). Thus, there is at most one control switch.\n\n4.  **Geometric Interpretation and Switching Curve:**\n    The optimal strategy is to drive the state from $x(0)$ to a special curve, the switching curve $\\mathcal{S}$, and then follow $\\mathcal{S}$ to the origin. The switching curve is the set of all points that can be driven to the origin using a single constant control ($u=+1$ or $u=-1$). We find $\\mathcal{S}$ by integrating the dynamics backward in time from the origin.\n\n    -   Backward with $u=+1$ (equivalent to forward with $u=-1$ from origin):\n        Starting from $x(0)=(0,0)$, with $u=-1$, we have $\\dot{x}_2=-1 \\implies x_2(t)=-t$, and $\\dot{x}_1=x_2 \\implies x_1(t) = -t^2/2$. Eliminating $t$, we get $x_1 = -\\frac{1}{2}x_2^2$. This trajectory runs in the region $x_20$. To reach the origin on this path, one must apply $u=-1$ forward in time, so this arc is for states with $x_20$. Thus, this part of the switching curve is $\\mathcal{S}_- = \\{(x_1, x_2) | x_1 = -\\frac{1}{2}x_2^2, x_20\\}$.\n\n    -   Backward with $u=-1$ (equivalent to forward with $u=+1$ from origin):\n        Starting from $x(0)=(0,0)$, with $u=+1$, we have $x_2(t)=t$ and $x_1(t)=t^2/2$. This gives $x_1 = \\frac{1}{2}x_2^2$ for $x_20$. To reach the origin on this path, one must apply $u=+1$ forward in time, so this arc is for states with $x_20$. Thus, this part is $\\mathcal{S}_+ = \\{(x_1, x_2) | x_1 = \\frac{1}{2}x_2^2, x_20\\}$.\n\n    The full switching curve is $\\mathcal{S} = \\mathcal{S}_- \\cup \\mathcal{S}_+$, which can be written as $x_1 = -\\frac{1}{2}x_2|x_2|$.\n\n5.  **Finding the Optimal Trajectory and Switching Time $\\tau$:**\n    The initial state is $x(0)=(1,-1)$. Let's check its position relative to the switching curve. For $x_2=-1$, the corresponding point on the curve $\\mathcal{S}$ is on $\\mathcal{S}_+$, where $x_1 = \\frac{1}{2}(-1)^2 = 0.5$. Our initial point has $x_1(0)=1$, so $1  0.5$. The phase portrait shows that trajectories with $u=+1$ move to the right (increasing $x_1$ for $x_20$) and trajectories with $u=-1$ move to the left. To reach the switching curve $\\mathcal{S}_+$ from $(1,-1)$, we must move left, so the initial control must be $u=-1$.\n    The optimal control sequence is therefore $u=-1$ followed by $u=+1$. Let $\\tau$ be the switching time.\n\n    -   **Arc 1:** $t \\in [0, \\tau]$, $u(t) = -1$.\n        Initial conditions: $x_1(0)=1$, $x_2(0)=-1$.\n        $\\dot{x}_2 = -1 \\implies x_2(t) = x_2(0) - t = -1-t$.\n        $\\dot{x}_1 = x_2(t) \\implies x_1(t) = x_1(0) + \\int_0^t (-1-s)ds = 1 - t - \\frac{1}{2}t^2$.\n        At time $\\tau$, the state is $x(\\tau)=(1-\\tau-\\frac{1}{2}\\tau^2, -1-\\tau)$.\n\n    -   **Switching Condition:** At $t=\\tau$, the state $x(\\tau)$ must lie on the switching curve $\\mathcal{S}_+$.\n        $x_1(\\tau) = \\frac{1}{2}[x_2(\\tau)]^2$.\n        $$1 - \\tau - \\frac{1}{2}\\tau^2 = \\frac{1}{2}(-1-\\tau)^2$$\n        $$1 - \\tau - \\frac{1}{2}\\tau^2 = \\frac{1}{2}(1 + 2\\tau + \\tau^2)$$\n        Multiplying by $2$:\n        $$2 - 2\\tau - \\tau^2 = 1 + 2\\tau + \\tau^2$$\n        $$2\\tau^2 + 4\\tau - 1 = 0$$\n        Solving the quadratic equation for $\\tau$:\n        $$\\tau = \\frac{-4 \\pm \\sqrt{16 - 4(2)(-1)}}{4} = \\frac{-4 \\pm \\sqrt{24}}{4} = \\frac{-2 \\pm \\sqrt{6}}{2}$$\n        Since time must be positive ($\\tau0$), we take the positive root:\n        $$\\tau = \\frac{-2+\\sqrt{6}}{2} = -1 + \\frac{\\sqrt{6}}{2}$$\n\n6.  **Finding the Minimal Final Time $T$:**\n    -   **Arc 2:** $t \\in (\\tau, T]$, $u(t) = +1$.\n        This arc starts at $x(\\tau)$ and ends at $x(T)=(0,0)$. The time required to travel from a point $(x_1,x_2)$ on $\\mathcal{S}_+$ to the origin with $u=+1$ is given by $t_{final\\_arc} = -x_2$.\n        The duration of the second arc is $T-\\tau$. Therefore:\n        $$T-\\tau = -x_2(\\tau)$$\n        We have $x_2(\\tau) = -1-\\tau$.\n        $$T-\\tau = -(-1-\\tau) = 1+\\tau$$\n        $$T = 2\\tau + 1$$\n        Substituting the value of $\\tau$:\n        $$T = 2 \\left(\\frac{\\sqrt{6}-2}{2}\\right) + 1 = (\\sqrt{6}-2) + 1 = \\sqrt{6}-1$$\n\nThe optimal switching time is $\\tau = \\frac{\\sqrt{6}-2}{2}$ and the minimal final time is $T = \\sqrt{6}-1$. The bang-bang sequence is $u=-1$ on $[0, \\tau]$ and $u=+1$ on $(\\tau, T]$.\n\nThe final answer is the ordered pair $(\\tau, T)$.",
            "answer": "$$ \\boxed{ \\begin{pmatrix} \\frac{\\sqrt{6}-2}{2}  \\sqrt{6}-1 \\end{pmatrix} } $$"
        },
        {
            "introduction": "While many optimal control problems yield a \"bang-bang\" solution where the control is always at its limits, some scenarios give rise to a more subtle phenomenon known as a singular arc. This occurs when the Hamiltonian is momentarily insensitive to the control input, and the standard maximization condition of PMP becomes inconclusive. This exercise presents a system where such a singular arc can be part of the optimal solution. To find the control along this arc, one must employ a more advanced technique: repeatedly differentiating the switching function until the control variable explicitly reappears, a crucial skill for tackling more complex, real-world systems .",
            "id": "3162826",
            "problem": "Consider the controlled system with state $x(t) = \\begin{pmatrix} x_{1}(t) \\\\ x_{2}(t) \\end{pmatrix} \\in \\mathbb{R}^{2}$ and control $u(t) \\in [-1,1]$ over a fixed horizon $t \\in [0,T]$:\n$$\n\\dot{x}_{1}(t) = x_{2}(t), \\qquad \\dot{x}_{2}(t) = -x_{1}(t) + u(t).\n$$\nThe performance index to be minimized is the integral of a linear-in-control running cost,\n$$\nJ[u] = \\int_{0}^{T} L(x(t),u(t)) \\, dt, \\qquad L(x,u) = c(x) \\, u, \\qquad c(x) = x_{1}.\n$$\nUsing the Pontryagin Maximum Principle (PMP), which states that along an optimal trajectory there exists a nontrivial costate $p(t) = \\begin{pmatrix} p_{1}(t) \\\\ p_{2}(t) \\end{pmatrix}$ such that the Hamiltonian\n$$\nH(x,u,p) = p^{\\top}\\big(f(x) + g(x)u\\big) - L(x,u)\n$$\nis maximized almost everywhere by the optimal control $u(t)$, where $f(x) = \\begin{pmatrix} x_{2} \\\\ -x_{1} \\end{pmatrix}$ and $g(x) = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$, investigate the possibility of a singular optimal control. A singular control occurs on an interval where the switching function vanishes and, due to the linearity in $u$, one must differentiate the switching function along the trajectory until the control $u$ appears explicitly; the singular control value is then determined by enforcing persistence of the singularity.\n\nDerive the Hamiltonian, the costate dynamics, and the switching function. Then, assuming a singular arc where the switching function and its first time derivative both vanish, compute the explicit value of the singular control $u_{\\text{sing}}$ by differentiating the switching function along the trajectory until $u$ appears and enforcing that the singularity persists. Express your final answer as a single real number. No rounding is required.",
            "solution": "The problem asks for the explicit value of the singular control, $u_{\\text{sing}}$, for a specified linear-in-control optimal control problem. The analysis will be conducted using Pontryagin's Maximum Principle (PMP).\n\nFirst, we define the system components based on the problem statement. The state vector is $x(t) = \\begin{pmatrix} x_{1}(t) \\\\ x_{2}(t) \\end{pmatrix}$, and the control input is $u(t) \\in [-1, 1]$. The state dynamics are given by:\n$$\n\\dot{x}_{1}(t) = x_{2}(t) \\\\\n\\dot{x}_{2}(t) = -x_{1}(t) + u(t)\n$$\nThis can be written in the form $\\dot{x} = f(x) + g(x)u$, where:\n$$\nf(x) = \\begin{pmatrix} x_{2} \\\\ -x_{1} \\end{pmatrix}, \\qquad g(x) = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\n$$\nThe Lagrangian (running cost) is $L(x, u) = x_{1}u$.\n\nAccording to Pontryagin's Maximum Principle, for an optimal trajectory, there exists a nonzero costate vector $p(t) = \\begin{pmatrix} p_{1}(t) \\\\ p_{2}(t) \\end{pmatrix}$ such that the Hamiltonian $H(x, u, p)$ is maximized with respect to the control $u$. The Hamiltonian is defined as $H(x, u, p) = p^{\\top}\\dot{x} - L(x, u)$. Note that the problem provides a slightly different but equivalent definition for our purpose ($H = p^{\\top}(f+gu) - L$). We will use the standard control-theory definition for a minimization problem, which is $H= p^{\\top}\\dot{x} + L_0$, where the objective is $\\min \\int_0^T L_0(x,u) dt$. To reconcile with the problem statement's maximization formulation, we consider minimizing $J = \\int L(x,u) dt$, which is equivalent to maximizing $\\int -L(x,u) dt$. Thus, the Hamiltonian for maximization is $H = p^{\\top}\\dot{x} - L(x,u)$. Let's proceed with this formulation.\n\nSubstituting the system dynamics and the Lagrangian, the Hamiltonian is:\n$$\nH(x, u, p) = p_{1}(t)\\dot{x}_{1}(t) + p_{2}(t)\\dot{x}_{2}(t) - L(x(t), u(t))\n$$\n$$\nH(x, u, p) = p_{1}x_{2} + p_{2}(-x_{1} + u) - x_{1}u\n$$\nWe can rearrange this to separate the terms that depend on the control $u$:\n$$\nH(x, u, p) = (p_{1}x_{2} - p_{2}x_{1}) + (p_{2} - x_{1})u\n$$\nThe Hamiltonian is linear in the control $u$. The term multiplying $u$ is the switching function, which we denote by $\\Phi(t)$.\n$$\n\\Phi(t) = \\frac{\\partial H}{\\partial u} = p_{2}(t) - x_{1}(t)\n$$\nThe optimal control $u^*(t)$ maximizes $H$. Given the control constraint $u \\in [-1, 1]$, the optimal control law is given by:\n$$\nu^{*}(t) = \\begin{cases}\n1  \\text{if } \\Phi(t)  0 \\\\\n-1  \\text{if } \\Phi(t)  0 \\\\\n\\text{undetermined}  \\text{if } \\Phi(t) = 0\n\\end{cases}\n$$\nA singular arc is an interval of time over which $\\Phi(t) = 0$. To maintain this condition, all time derivatives of the switching function must also be zero, i.e., $\\Phi^{(k)}(t) = 0$ for $k = 1, 2, \\ldots$. We must differentiate $\\Phi(t)$ until the control $u$ explicitly appears.\n\nThe costate dynamics are given by the canonical equations $\\dot{p} = -\\frac{\\partial H}{\\partial x}$.\n$$\n\\dot{p}_{1} = -\\frac{\\partial H}{\\partial x_{1}} = -(-p_{2} - u) = p_{2} + u\n$$\n$$\n\\dot{p}_{2} = -\\frac{\\partial H}{\\partial x_{2}} = -(p_{1}) = -p_{1}\n$$\nNow, we compute the time derivatives of the switching function $\\Phi(t) = p_{2}(t) - x_{1}(t)$.\nThe first derivative is:\n$$\n\\dot{\\Phi}(t) = \\frac{d}{dt}\\Phi(t) = \\dot{p}_{2}(t) - \\dot{x}_{1}(t)\n$$\nSubstituting the expressions for $\\dot{p}_{2}$ and $\\dot{x}_{1}$:\n$$\n\\dot{\\Phi}(t) = -p_{1}(t) - x_{2}(t)\n$$\nOn a singular arc, we must have $\\Phi(t) = 0$ and $\\dot{\\Phi}(t) = 0$.\nThe condition $\\Phi(t) = 0$ implies $p_{2}(t) = x_{1}(t)$.\nThe condition $\\dot{\\Phi}(t) = 0$ implies $-p_{1}(t) - x_{2}(t) = 0$, or $p_{1}(t) = -x_{2}(t)$.\nThe control $u$ does not appear in the expression for $\\dot{\\Phi}(t)$. Therefore, we must compute the second time derivative.\n$$\n\\ddot{\\Phi}(t) = \\frac{d}{dt}\\dot{\\Phi}(t) = -\\dot{p}_{1}(t) - \\dot{x}_{2}(t)\n$$\nSubstituting the expressions for $\\dot{p}_{1}$ and $\\dot{x}_{2}$:\n$$\n\\ddot{\\Phi}(t) = -(p_{2}(t) + u(t)) - (-x_{1}(t) + u(t))\n$$\n$$\n\\ddot{\\Phi}(t) = -p_{2}(t) - u(t) + x_{1}(t) - u(t)\n$$\n$$\n\\ddot{\\Phi}(t) = x_{1}(t) - p_{2}(t) - 2u(t)\n$$\nOn a singular arc, we must also have $\\ddot{\\Phi}(t) = 0$. The control that enforces this condition is the singular control, $u_{\\text{sing}}(t)$. Setting $\\ddot{\\Phi}(t) = 0$:\n$$\nx_{1}(t) - p_{2}(t) - 2u_{\\text{sing}}(t) = 0\n$$\nWe also know that on a singular arc, $\\Phi(t) = p_{2}(t) - x_{1}(t) = 0$, which means $p_{2}(t) = x_{1}(t)$. Substituting this into the equation for $\\ddot{\\Phi}(t) = 0$:\n$$\nx_{1}(t) - x_{1}(t) - 2u_{\\text{sing}}(t) = 0\n$$\n$$\n0 - 2u_{\\text{sing}}(t) = 0\n$$\n$$\n-2u_{\\text{sing}}(t) = 0\n$$\nSolving for $u_{\\text{sing}}(t)$ yields:\n$$\nu_{\\text{sing}}(t) = 0\n$$\nThis value is a constant and lies within the admissible control set, $0 \\in [-1, 1]$. Thus, the explicit value of the singular control is $0$.",
            "answer": "$$\\boxed{0}$$"
        },
        {
            "introduction": "Moving beyond standard applications, PMP reveals a deep connection between optimality and the underlying geometry of the control system. This is most profoundly seen in the case of \"abnormal extremals\"—trajectories whose existence is determined purely by the system's kinematic constraints, independent of any cost function. Such paths can be optimal but are invisible to a cost-centric analysis. This advanced practice invites you to explore this concept on a manifold, using the tools of geometric mechanics to identify a system that admits abnormal extremals and to derive the necessary conditions that govern them. This exercise illuminates one of the most subtle and powerful aspects of the Pontryagin framework .",
            "id": "3762921",
            "problem": "Consider the manifold $M = \\mathbb{R}^{3}$ with coordinates $(x,y,z)$ and the control-affine system\n$$\n\\dot{q}(t) = u_{1}(t) X_{1}(q(t)) + u_{2}(t) X_{2}(q(t)),\n$$\nwhere $q(t) \\in M$, $(u_{1}(t),u_{2}(t)) \\in U := \\{(u_{1},u_{2}) \\in \\mathbb{R}^{2} : u_{1}^{2}+u_{2}^{2} \\leq 1\\}$, and the vector fields are\n$$\nX_{1}(x,y,z) = \\partial_{x} + y^{2} \\partial_{z}, \\qquad X_{2}(x,y,z) = \\partial_{y}.\n$$\nWe consider the time-optimal problem: among all admissible controls $(u_{1},u_{2})$ steering $q(0) = (0,0,0)$ to $q(T) = (x_{T}, 0, 0)$ for some fixed $x_{T}  0$, minimize the transfer time $T$. Use Pontryagin’s maximum principle within the geometric mechanics and symplectic framework, where extremals are lifts to the cotangent bundle $T^{*}M$ equipped with the canonical symplectic form.\n\nTasks:\n1. Construct the Pontryagin Hamiltonian $H(q,p,u,p_{0})$ for this problem and explain the distinction between normal extremals ($p_{0}  0$) and abnormal extremals ($p_{0} = 0$). Derive the necessary first-order optimality conditions for abnormal extremals, including the maximization condition over $U$ and the costate dynamics on $T^{*}M$ induced by the Hamiltonian vector field.\n2. Show that abnormal extremals exist for this system and identify a nontrivial abnormal extremal lying entirely in the plane $y=0$. In particular, consider the trajectory\n$$\nq(t) = (t,0,0), \\qquad t \\in [0,T], \\quad \\text{with the control} \\quad u_{1}(t) \\equiv 1, \\; u_{2}(t) \\equiv 0.\n$$\n3. Derive the necessary conditions on the costate $p(t) \\in T^{*}_{q(t)}M$ for this abnormal extremal, and compute explicitly the time evolution of the costate components $(p_{x}(t), p_{y}(t), p_{z}(t))$ along the trajectory in Task 2. Express your final answer for $(p_{x}(t), p_{y}(t), p_{z}(t))$ as a single closed-form analytical expression. No rounding is required. Do not include units. If your final expression contains a constant, you may leave it as a symbolic parameter.",
            "solution": "The problem presented is a well-defined time-optimal control problem in the field of geometric control theory. All provided information—the state space $M = \\mathbb{R}^3$, the control-affine dynamics $\\dot{q} = u_1 X_1 + u_2 X_2$, the vector fields $X_1$ and $X_2$, the control constraint set $U$, and the boundary conditions $q(0)=(0,0,0)$ and $q(T)=(x_T,0,0)$—is mathematically precise, self-contained, and consistent. The specified task of applying Pontryagin's Maximum Principle in its geometric/symplectic formulation to analyze abnormal extremals is a standard and rigorous procedure in this domain. The candidate trajectory and control provided in Task 2 are consistent with the system dynamics. The problem is free of scientific flaws, ambiguities, or contradictions. Therefore, the problem is valid and a solution can be derived.\n\nThe problem is addressed in three parts as requested.\n\n**1. Pontryagin Hamiltonian and Conditions for Abnormal Extremals**\n\nThe objective is to minimize the final time $T$, which corresponds to a cost functional $J = \\int_0^T 1 \\, dt$. The Lagrangian is $L(q,u) = 1$. The state equations are $\\dot{q} = u_1 X_1(q) + u_2 X_2(q)$, with $q=(x,y,z)$, $X_1 = \\partial_x + y^2 \\partial_z = (1, 0, y^2)$, and $X_2 = \\partial_y = (0, 1, 0)$.\n\nAccording to Pontryagin's Maximum Principle (PMP), for an optimal trajectory $q(t)$ with control $u(t)$, there exists a non-zero curve $(p(t), p_0)$ where $p(t) \\in T_{q(t)}^*M$ is the costate and $p_0 \\leq 0$ is a constant. The Pontryagin Hamiltonian is defined as:\n$$ H(q, p, u, p_0) = \\langle p, \\dot{q} \\rangle + p_0 L(q,u) $$\nHere, $p = (p_x, p_y, p_z)$ is the costate vector. Let us define the control Hamiltonians $H_i(q,p) = \\langle p, X_i(q) \\rangle$ for $i=1,2$.\n$$ H_1(q,p) = \\langle (p_x, p_y, p_z), (1, 0, y^2) \\rangle = p_x + y^2 p_z $$\n$$ H_2(q,p) = \\langle (p_x, p_y, p_z), (0, 1, 0) \\rangle = p_y $$\nThe Pontryagin Hamiltonian can then be written as:\n$$ H(q, p, u, p_0) = u_1 H_1(q,p) + u_2 H_2(q,p) + p_0 $$\nThe distinction between normal and abnormal extremals is based on the value of $p_0$:\n- **Normal extremals**: $p_0  0$. By homogeneity, we can normalize $p_0$ to $-1$. The cost function is genuinely incorporated into the optimization through the Hamiltonian $H = u_1 H_1 + u_2 H_2 - 1$.\n- **Abnormal extremals**: $p_0 = 0$. The Hamiltonian becomes $H_{ab} = u_1 H_1 + u_2 H_2$. These extremals are independent of the cost function and are determined purely by the geometry of the vector fields and control constraints. The non-zero condition on the PMP lift implies that $p(t)$ cannot be identically zero.\n\nFor abnormal extremals ($p_0=0$), the necessary conditions from PMP are:\n1.  **Hamiltonian dynamics**: The extremal curve $(q(t), p(t))$ evolves according to Hamilton's equations for $H_{ab}$ on the cotangent bundle $T^*M$. The Hamiltonian vector field $\\vec{H}_{ab}$ generates the flow: $\\dot{q} = \\frac{\\partial H_{ab}}{\\partial p}$ and $\\dot{p} = -\\frac{\\partial H_{ab}}{\\partial q}$.\n    $$ \\dot{x} = \\frac{\\partial H_{ab}}{\\partial p_x} = u_1, \\quad \\dot{y} = \\frac{\\partial H_{ab}}{\\partial p_y} = u_2, \\quad \\dot{z} = \\frac{\\partial H_{ab}}{\\partial p_z} = u_1 y^2 $$\n    These are precisely the given state dynamics. The costate dynamics are:\n    $$ \\dot{p}_x = -\\frac{\\partial H_{ab}}{\\partial x} = 0 $$\n    $$ \\dot{p}_y = -\\frac{\\partial H_{ab}}{\\partial y} = -\\frac{\\partial}{\\partial y}(u_1(p_x + y^2 p_z) + u_2 p_y) = -2 u_1 y p_z $$\n    $$ \\dot{p}_z = -\\frac{\\partial H_{ab}}{\\partial z} = 0 $$\n2.  **Maximization condition**: For almost every $t \\in [0,T]$, the optimal control $u^*(t)$ maximizes the Hamiltonian:\n    $$ H_{ab}(q(t), p(t), u^*(t)) = \\max_{v \\in U} H_{ab}(q(t), p(t), v) $$\n3.  **Hamiltonian value**: For a time-optimal problem, the maximized Hamiltonian must be constant and equal to zero along the extremal trajectory:\n    $$ H_{ab}(q(t), p(t), u^*(t)) = u_1^*(t) H_1(t) + u_2^*(t) H_2(t) = 0 $$\n    The maximization of the linear function $u_1 H_1 + u_2 H_2$ over the disk $U$ subject to the condition that the maximum value is zero implies that the vector $(H_1(t), H_2(t))$ must be the zero vector. If it were not, the maximum value would be $\\sqrt{H_1(t)^2 + H_2(t)^2}  0$. Thus, a necessary condition for an abnormal extremal is that\n    $$ H_1(q(t), p(t)) = 0 \\quad \\text{and} \\quad H_2(q(t), p(t)) = 0 $$\n    for almost all $t \\in [0,T]$.\n\n**2. Existence of a Nontrivial Abnormal Extremal**\n\nWe need to show there exists a trajectory $q(t)$ and a non-zero costate $p(t)$ satisfying the abnormal conditions. The problem proposes the trajectory $q(t) = (t,0,0)$ for $t \\in [0,T]$ with control $u_1(t) \\equiv 1, u_2(t) \\equiv 0$.\n\nFirst, let's verify this trajectory is valid.\nWith $q(t)=(t,0,0)$, we have $\\dot{q}(t)=(1,0,0)$.\nWith $u=(1,0)$ and $y=0$, the dynamics are $\\dot{q} = 1 \\cdot X_1(t,0,0) + 0 \\cdot X_2(t,0,0)$.\n$X_1(t,0,0) = \\partial_x + 0^2 \\partial_z = \\partial_x$, which corresponds to the vector $(1,0,0)$.\nSo, $\\dot{q} = 1 \\cdot (1,0,0) = (1,0,0)$, which is consistent. The control $u=(1,0)$ is in $U$ since $1^2+0^2=1 \\leq 1$. The trajectory starts at $q(0)=(0,0,0)$ and ends at $q(T)=(T,0,0)$. For a given $x_T0$, we can set $T=x_T$.\n\nNow, we check if this can be an abnormal extremal. There must exist a non-zero $p(t)$ such that $H_1(t)=0$ and $H_2(t)=0$ along this path, and $p(t)$ must satisfy the costate equations.\nThe conditions $H_1=0$ and $H_2=0$ along $q(t)=(t,0,0)$ become:\n$$ H_1(t) = p_x(t) + y(t)^2 p_z(t) = p_x(t) + 0^2 \\cdot p_z(t) = p_x(t) = 0 $$\n$$ H_2(t) = p_y(t) = 0 $$\nSo, for our trajectory to be abnormal, the costate must satisfy $p_x(t) = 0$ and $p_y(t) = 0$ for all $t$.\n\nLet's check for consistency with the costate dynamics using $u(t)=(1,0)$ and $q(t)=(t,0,0)$:\n$$ \\dot{p}_x = 0 \\implies p_x(t) = \\text{constant} $$\n$$ \\dot{p}_y = -2 u_1(t) y(t) p_z(t) = -2(1)(0)p_z(t) = 0 \\implies p_y(t) = \\text{constant} $$\n$$ \\dot{p}_z = 0 \\implies p_z(t) = \\text{constant} $$\nThe condition $p_x(t)=0$ requires the constant of integration to be $0$. This is consistent.\nThe condition $p_y(t)=0$ requires the constant of integration to be $0$. This is consistent.\nThe equation for $p_z(t)$ implies $p_z(t)=C$ for some constant $C$.\nSo, we have a candidate costate trajectory $p(t) = (0, 0, C)$. For the extremal to be non-trivial (i.e., $(p(t),p_0)$ is never zero and $p_0=0$), we must have $p(t) \\neq 0$, which means $C \\neq 0$.\n\nThus, the trajectory $q(t)=(t,0,0)$ with control $u(t)=(1,0)$, paired with the costate $p(t)=(0,0,C)$ for any non-zero constant $C$, satisfies all necessary first-order conditions for an abnormal extremal. This proves that a nontrivial abnormal extremal exists and lies in the plane $y=0$.\n\n**3. Costate Evolution along the Abnormal Extremal**\n\nWe are asked to derive the necessary conditions on the costate $p(t)$ for the specific abnormal extremal $q(t)=(t,0,0)$ with control $u(t)=(1,0)$, and to compute the explicit time evolution of the costate components $(p_x(t), p_y(t), p_z(t))$.\n\nThe necessary conditions on the costate for an abnormal extremal are that there must exist a non-zero $p(t)$ such that for almost all $t \\in [0,T]$:\n1.  $H_1(q(t),p(t)) = p_x(t) + y(t)^2 p_z(t) = 0$.\n2.  $H_2(q(t),p(t)) = p_y(t) = 0$.\n3.  The costate evolves according to $\\dot{p}(t) = -\\frac{\\partial H_{ab}}{\\partial q}|_{(q(t),p(t),u(t))}$.\n\nWe substitute the specified trajectory $q(t)=(t,0,0)$ with $y(t)=0$ into the first two conditions:\n1.  $p_x(t) + (0)^2 p_z(t) = p_x(t) = 0$.\n2.  $p_y(t) = 0$.\n\nThese algebraic constraints must hold for all $t$.\n\nNow we analyze the costate differential equations along the given extremal path, where $q(t)=(t,0,0)$ and $u(t)=(1,0)$:\n$$ \\dot{p}_x(t) = 0 $$\n$$ \\dot{p}_y(t) = -2 u_1(t) y(t) p_z(t) = -2(1)(0)p_z(t) = 0 $$\n$$ \\dot{p}_z(t) = 0 $$\nIntegrating these simple differential equations yields:\n$$ p_x(t) = C_x $$\n$$ p_y(t) = C_y $$\n$$ p_z(t) = C_z $$\nwhere $C_x, C_y, C_z$ are constants of integration.\n\nTo obtain the final expression for $p(t)$, we must enforce the algebraic constraints derived from $H_1=0$ and $H_2=0$.\nFrom $p_x(t)=0$, we must have $C_x=0$.\nFrom $p_y(t)=0$, we must have $C_y=0$.\nThe component $p_z(t)$ is simply a constant, $p_z(t)=C_z$.\nFor the extremal to be nontrivial as required by PMP, the costate vector $p(t)$ cannot be the zero vector. Therefore, we must have $C_z \\neq 0$.\n\nThe time evolution of the costate components is thus given by:\n$$ p_x(t) = 0 $$\n$$ p_y(t) = 0 $$\n$$ p_z(t) = C $$\nwhere $C$ is an arbitrary non-zero constant. Let's denote this symbolic parameter as $C$. The resulting expression for the costate vector is $(p_x(t), p_y(t), p_z(t)) = (0, 0, C)$.",
            "answer": "$$ \\boxed{ \\begin{pmatrix} 0  0  C \\end{pmatrix} } $$"
        }
    ]
}