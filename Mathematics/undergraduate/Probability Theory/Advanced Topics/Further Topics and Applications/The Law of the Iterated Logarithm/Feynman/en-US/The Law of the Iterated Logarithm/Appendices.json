{
    "hands_on_practices": [
        {
            "introduction": "The Law of the Iterated Logarithm (LIL) provides a remarkably precise description of the fluctuations of a random walk. To truly grasp its meaning, it's helpful to think about how one might observe this law from data. This first practice challenges you to move from theory to computation, asking you to design an algorithm that correctly tracks the key quantity in the LIL . Translating an abstract mathematical statement into a concrete and efficient computational plan is a fundamental skill for any modern scientist or data analyst.",
            "id": "1400273",
            "problem": "A computational probabilist is studying the long-term behavior of a one-dimensional simple symmetric random walk. The walk is constructed from a sequence of independent and identically distributed (i.i.d.) random variables $X_1, X_2, \\dots$, where the probability of stepping right or left is equal, i.e., $P(X_i = 1) = P(X_i = -1) = 1/2$ for each $i$. The position of the random walk after $n$ steps is given by the sum $S_n = \\sum_{i=1}^{n} X_i$, with an initial position of $S_0 = 0$.\n\nTo investigate the boundary of the walk's fluctuations, the probabilist is interested in computing the sequence $Z_n$ for $n = 3, 4, \\dots, N$, where $N$ is a large integer. The sequence $Z_n$ is defined as the running maximum of the normalized absolute position of the walk:\n$$\nZ_n = \\max_{3 \\le k \\le n} \\frac{|S_k|}{\\sqrt{2 k \\ln(\\ln(k))}}\n$$\nHere, $\\ln$ denotes the natural logarithm. The maximum is taken over all integer steps $k$ from 3 to $n$, inclusive.\n\nThe task is to devise an efficient computational algorithm that, for a single simulated path of the random walk, generates the list of values $[Z_3, Z_4, \\dots, Z_N]$. Four pseudo-code outlines are proposed. Which of the following algorithms correctly and efficiently generates the target sequence?\n\nA.\n1. Initialize `current_S = 0`.\n2. Initialize `results_list` as an empty list.\n3. For `k` from 1 to `N`:\n4.   Generate a random step `X` from `{-1, 1}`.\n5.   Update `current_S = current_S + X`.\n6.   If `k >= 3`:\n7.     Calculate `current_Y_k = |current_S| / sqrt(2 * k * ln(ln(k)))`.\n8.     Append `current_Y_k` to `results_list`.\n9. Return `results_list`.\n\nB.\n1. Initialize `current_S = 0` and `running_max_S = 0`.\n2. Initialize `results_list` as an empty list.\n3. For `k` from 1 to `N`:\n4.   Generate a random step `X` from `{-1, 1}`.\n5.   Update `current_S = current_S + X`.\n6.   If `k >= 3`:\n7.     Update `running_max_S = max(running_max_S, |current_S|)`.\n8.     Calculate `intermediate_Z = running_max_S / sqrt(2 * k * ln(ln(k)))`.\n9.     Append `intermediate_Z` to `results_list`.\n10. Return `results_list`.\n\nC.\n1. Initialize `current_S = 0` and `running_max_Z = 0`.\n2. Initialize `results_list` as an empty list.\n3. For `k` from 1 to `N`:\n4.   Generate a random step `X` from `{-1, 1}`.\n5.   Update `current_S = current_S + X`.\n6.   If `k >= 3`:\n7.     Calculate `current_Y_k = |current_S| / sqrt(2 * k * ln(ln(k)))`.\n8.     Update `running_max_Z = max(running_max_Z, current_Y_k)`.\n9.     Append `running_max_Z` to `results_list`.\n10. Return `results_list`.\n\nD.\n1. Initialize `current_S = 0` and `running_max_Z = 0`.\n2. Initialize `results_list` as an empty list.\n3. For `k` from 1 to `N`:\n4.   Generate a random step `X` from `{-1, 1}`.\n5.   Update `current_S = current_S + X`.\n6.   Calculate `current_Y_k = |current_S| / sqrt(2 * k * ln(ln(k)))`.\n7.   Update `running_max_Z = max(running_max_Z, current_Y_k)`.\n8.   If `k >= 3`:\n9.     Append `running_max_Z` to `results_list`.\n10. Return `results_list`.",
            "solution": "We are given a simple symmetric random walk with increments $X_{i} \\in \\{-1,1\\}$ i.i.d. with $P(X_{i}=1)=P(X_{i}=-1)=\\frac{1}{2}$. The partial sums are $S_{n}=\\sum_{i=1}^{n}X_{i}$ with $S_{0}=0$. For each $n \\geq 3$, the target quantity is\n$$\nZ_{n}=\\max_{3 \\leq k \\leq n}\\frac{|S_{k}|}{\\sqrt{2k\\ln(\\ln(k))}}.\n$$\nDefine $Y_{k}=\\frac{|S_{k}|}{\\sqrt{2k\\ln(\\ln(k))}}$ for $k \\geq 3$. Then by definition,\n$$\nZ_{n}=\\max\\{Y_{3},Y_{4},\\dots,Y_{n}\\}.\n$$\nThus, as we simulate the path sequentially for $k=1,2,\\dots,N$, once $k \\geq 3$ we can compute $Y_{k}$ from the current $S_{k}$ and update a running maximum $M_{k}=\\max\\{M_{k-1},Y_{k}\\}$ with $M_{2}$ initialized appropriately. Then the desired output at time $n$ is $Z_{n}=M_{n}$ for $n \\geq 3$.\n\nWe now analyze each proposed algorithm against this definition.\n\nAlgorithm A computes and appends $Y_{k}$ for each $k \\geq 3$ without taking a running maximum. Therefore it produces the sequence $[Y_{3},Y_{4},\\dots,Y_{N}]$ rather than $[Z_{3},Z_{4},\\dots,Z_{N}]$ with $Z_{n}=\\max_{3 \\leq k \\leq n}Y_{k}$. Hence A is incorrect.\n\nAlgorithm B maintains $r=\\max_{j \\leq k}|S_{j}|$ and then forms\n$$\n\\frac{r}{\\sqrt{2k\\ln(\\ln(k))}}.\n$$\nHowever, $Z_{n}=\\max_{3 \\leq k \\leq n}\\frac{|S_{k}|}{\\sqrt{2k\\ln(\\ln(k))}}$ requires maximizing the ratio for each $k$ with its own denominator $\\sqrt{2k\\ln(\\ln(k))}$. Replacing $|S_{k}|$ by $\\max_{j \\leq k}|S_{j}|$ while still dividing by the current denominator at time $k$ does not, in general, equal $\\max_{3 \\leq j \\leq k}\\frac{|S_{j}|}{\\sqrt{2j\\ln(\\ln(j))}}$, because the time index that maximizes $|S_{j}|$ need not maximize the ratio once scaled by the time-dependent denominator. Therefore B is incorrect.\n\nAlgorithm C computes $Y_{k}$ at the current $k$ for $k \\geq 3$, updates a running maximum over these ratios, and appends that running maximum. Formally, it constructs $M_{k}=\\max\\{M_{k-1},Y_{k}\\}$ for $k \\geq 3$, and outputs $M_{k}$ at each step $k$. This matches $Z_{n}$ as defined, is a single pass, and is $O(N)$ in time and $O(1)$ in additional space, so it is correct and efficient.\n\nAlgorithm D updates the running maximum over $Y_{k}$ for all $k$, including $k3$, and only appends when $k \\geq 3$. This is flawed for two reasons: first, $Y_{k}$ is undefined at $k=1$ because $\\ln(\\ln(1))$ is undefined, and problematic at $k=2$ because $\\ln(\\ln(2))0$ makes the denominator imaginary in the square root; second, even if one were to ignore domain issues, incorporating $k3$ into the running maximum would contaminate the value that should be $\\max_{3 \\leq j \\leq k}Y_{j}$. Hence D is incorrect.\n\nTherefore, the only algorithm that correctly and efficiently generates the sequence $[Z_{3},Z_{4},\\dots,Z_{N}]$ is Algorithm C.",
            "answer": "$$\\boxed{C}$$"
        },
        {
            "introduction": "The LIL tells us that the boundary of a random walk's fluctuations grows like $\\sqrt{2n \\ln(\\ln n)}$. But how does this unusual function compare to more familiar power laws, such as $\\sqrt{n}$ or $n^{0.6}$? This exercise invites you to explore this question by finding the critical power-law exponent that separates a random walk that is eventually contained from one that escapes its boundary infinitely often . By solving this, you'll gain a deeper appreciation for the sharpness of the LIL's prediction and the intricate geometry of random paths.",
            "id": "1400265",
            "problem": "Consider a one-dimensional simple symmetric random walk (SSRW), denoted by $S_n$, which starts at the origin $S_0 = 0$. The position at time step $n$ is given by the sum $S_n = \\sum_{i=1}^{n} X_i$, where the steps $X_i$ are independent and identically distributed random variables with probability mass function $P(X_i = 1) = P(X_i = -1) = 1/2$.\n\nWe are interested in comparing the long-term behavior of this random walk to a power-law boundary of the form $f(n, \\alpha) = n^{\\alpha}$, where $\\alpha > 0$ is a real-valued exponent. The behavior of the walk can be classified into two distinct regimes based on the value of $\\alpha$. For certain values of $\\alpha$, the walk is eventually contained by the boundary, meaning that for almost every realization of the walk, the inequality $|S_n| \\leq n^{\\alpha}$ holds for all sufficiently large integers $n$. For other values of $\\alpha$, the walk escapes the boundary infinitely often, meaning $|S_n| > n^{\\alpha}$ for infinitely many values of $n$ with probability one.\n\nThere exists a critical exponent, $\\alpha_c$, which marks the transition between these two regimes. For any $\\alpha > \\alpha_c$, the walk is eventually contained by the boundary $n^{\\alpha}$. For any $0  \\alpha  \\alpha_c$, the walk escapes the boundary $n^{\\alpha}$ infinitely often.\n\nDetermine the value of this critical exponent $\\alpha_c$.",
            "solution": "The simple symmetric random walk $S_{n}=\\sum_{i=1}^{n}X_{i}$ has independent increments with $\\mathbb{E}[X_{i}]=0$ and $\\mathrm{Var}(X_{i})=1$. By the Kolmogorov law of the iterated logarithm (LIL), one has almost surely\n$$\n\\limsup_{n\\to\\infty}\\frac{|S_{n}|}{\\sqrt{2n\\ln\\ln n}}=1.\n$$\nThis identifies the exact almost sure fluctuation scale of $S_{n}$ as $\\sqrt{n\\ln\\ln n}$.\n\nTo determine the critical exponent $\\alpha_{c}$ for the boundary $n^{\\alpha}$, compare $n^{\\alpha}$ with the LIL scale.\n\n1) Case $\\alpha>\\frac{1}{2}$. Write $\\alpha=\\frac{1}{2}+\\delta$ with $\\delta>0$. By the LIL, for any $\\epsilon>0$ there exists $N_{1}$ such that for all $n\\geq N_{1}$,\n$$\n|S_{n}|\\leq (1+\\epsilon)\\sqrt{2n\\ln\\ln n}.\n$$\nConsider the ratio\n$$\n\\frac{n^{\\alpha}}{\\sqrt{2n\\ln\\ln n}}=\\frac{n^{\\delta}}{\\sqrt{2\\ln\\ln n}}.\n$$\nSince $n^{\\delta}\\to\\infty$ polynomially while $\\sqrt{\\ln\\ln n}\\to\\infty$ only logarithmically, this ratio tends to $\\infty$. Hence there exists $N_{2}$ such that for all $n\\geq N_{2}$,\n$$\nn^{\\alpha}\\geq (1+\\epsilon)\\sqrt{2n\\ln\\ln n}.\n$$\nFor $n\\geq \\max\\{N_{1},N_{2}\\}$, combining the two inequalities yields $|S_{n}|\\leq n^{\\alpha}$. Therefore, for $\\alpha>\\frac{1}{2}$ the walk is eventually contained by the boundary $n^{\\alpha}$ almost surely.\n\n2) Case $0\\alpha\\frac{1}{2}$. Write $\\alpha=\\frac{1}{2}-\\delta$ with $\\delta>0$. By the LIL, for any $\\epsilon\\in(0,1)$ there are infinitely many $n$ such that\n$$\n|S_{n}|\\geq (1-\\epsilon)\\sqrt{2n\\ln\\ln n}.\n$$\nFor these $n$,\n$$\n\\frac{(1-\\epsilon)\\sqrt{2n\\ln\\ln n}}{n^{\\alpha}}=(1-\\epsilon)\\sqrt{2}\\,n^{\\delta}\\sqrt{\\ln\\ln n}\\to\\infty,\n$$\nso for all sufficiently large such $n$ one has $|S_{n}|>n^{\\alpha}$. Because there are infinitely many such $n$, the walk exceeds the boundary $n^{\\alpha}$ infinitely often almost surely.\n\n3) Boundary case $\\alpha=\\frac{1}{2}$. The LIL gives\n$$\n\\frac{|S_{n}|}{\\sqrt{n}}\\geq (1-\\epsilon)\\sqrt{2\\ln\\ln n}\n$$\ninfinitely often, and since $\\ln\\ln n\\to\\infty$, this shows $|S_{n}|>n^{1/2}$ infinitely often almost surely. Thus there is no eventual containment at $\\alpha=\\frac{1}{2}$.\n\nCombining these implications, the transition occurs at $\\alpha_{c}=\\frac{1}{2}$: for $\\alpha>\\alpha_{c}$ there is eventual containment, and for $0\\alpha\\alpha_{c}$ there are infinitely many escapes.",
            "answer": "$$\\boxed{\\frac{1}{2}}$$"
        },
        {
            "introduction": "The power of the LIL extends far beyond the simple symmetric random walk. It applies to a vast class of random processes, including the sum of Bernoulli trials, which form the bedrock of many statistical models. This final practice asks you to apply the LIL to quantify the long-run fluctuations of a sample proportion around its true expected value . This demonstrates how the LIL provides a rigorous way to understand the size of \"typical\" large deviations in sampling and estimation.",
            "id": "783239",
            "problem": "Let $Y_1, Y_2, \\dots$ be a sequence of independent and identically distributed (i.i.d.) random variables, each following a Bernoulli distribution with parameter $p \\in (0,1)$, i.e., $P(Y_i=1) = p$ and $P(Y_i=0) = 1-p$. Let $S_n = \\sum_{i=1}^n Y_i$ be the partial sum representing the number of \"successes\" in the first $n$ trials.\n\nThe Law of the Iterated Logarithm (LIL) describes the typical magnitude of the fluctuations of a random walk. For a sequence of i.i.d. random variables $X_1, X_2, \\dots$ with mean $E[X_i] = 0$ and finite variance $\\text{Var}(X_i) = \\sigma^2$, the LIL states:\n$$\n\\limsup_{n \\to \\infty} \\frac{\\sum_{i=1}^n X_i}{\\sqrt{2n \\ln(\\ln n)}} = \\sigma \\quad \\text{a.s.}\n$$\nA stronger result, which you may use without proof, is that the set of limit points (or cluster points) of the sequence $\\left\\{\\frac{\\sum_{i=1}^n X_i}{\\sqrt{2n \\ln(\\ln n)}}\\right\\}_{n\\ge 3}$ is almost surely the entire closed interval $[-\\sigma, \\sigma]$.\n\nConsider the sequence of random variables $V_n$ defined by the squared deviation of the sample proportion of successes from the true probability $p$, scaled by a time-dependent factor:\n$$\nV_n = n \\left( \\frac{S_n}{n} - p \\right)^2 (\\ln(\\ln n))^{-1}\n$$\nfor $n \\ge 3$. Your task is to find the almost sure limit superior of this sequence. Derive the value of the constant $C$ such that:\n$$\n\\limsup_{n \\to \\infty} V_n = C \\quad \\text{a.s.}\n$$\nExpress your answer for $C$ in terms of the parameter $p$.",
            "solution": "Define centered variables $X_i = Y_i - p$, then \n$$E[X_i] = 0,\\quad \\operatorname{Var}(X_i) = p(1-p) = \\sigma^2.$$\nSince $S_n = \\sum_{i=1}^n Y_i$, we have \n$$\\sum_{i=1}^n X_i = S_n - np.$$\nHence \n$$V_n = n\\Bigl(\\frac{S_n}{n}-p\\Bigr)^2(\\ln(\\ln n))^{-1}\n= \\frac{(S_n-np)^2}{n\\ln(\\ln n)}\n= \\frac{\\bigl(\\sum_{i=1}^n X_i\\bigr)^2}{n\\ln(\\ln n)}.$$\nDefine \n$$W_n = \\frac{\\sum_{i=1}^n X_i}{\\sqrt{2n\\ln(\\ln n)}}.$$\nThen \n$$\\bigl(\\sum_{i=1}^n X_i\\bigr)^2 = 2n\\ln(\\ln n)\\,W_n^2$$\nand so \n$$V_n = \\frac{2n\\ln(\\ln n)\\,W_n^2}{n\\ln(\\ln n)} = 2W_n^2.$$\nBy the Law of the Iterated Logarithm, the cluster points of $W_n$ are almost surely the entire interval $[-\\sigma,\\sigma]$.  Therefore the cluster points of\n$$V_n = 2W_n^2$$\nfill the interval $[0,2\\sigma^2] = [0,2p(1-p)]$, and hence\n$$\\limsup_{n\\to\\infty}V_n = 2p(1-p)\\quad\\text{a.s.}$$",
            "answer": "$$\\boxed{2p(1-p)}$$"
        }
    ]
}