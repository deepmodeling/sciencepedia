{"hands_on_practices": [{"introduction": "对于一些基础化学反应系统，化学主方程 (Chemical Master Equation, CME) 可以被解析求解，从而为我们提供关于系统随机行为的精确描述。本练习将引导你使用概率生成函数 (Probability Generating Function, PGF) 这一强有力的数学工具，将描述概率演化的无限维常微分方程组转化为一个单一的、可解的偏微分方程。通过求解这个方程，你将能够精确地推导出系统粒子数随时间变化的完整概率分布及其统计矩，这不仅加深了对主方程理论的理解，也为验证随机模拟算法的准确性提供了黄金标准 [@problem_id:2669255]。", "problem": "考虑一个充分混合、等温、恒容的系统，其中包含一个单一化学物种，该物种根据基元反应 $X \\to 2X$ 进行自催化复制。假设在稀释极限下遵循质量作用随机动力学，因此，在时刻 $t$ 有 $n$ 个分子的条件下，发生 $X \\to 2X$ 事件的瞬时倾向（风险率）为 $a(n) = \\lambda n$，其中 $\\lambda > 0$ 是一个常数。令 $N(t)$ 表示时刻 $t$ 的分子数，并假设 $N(0) = n_{0}$ 的概率为 $1$，其中 $n_{0} \\in \\mathbb{N}$。\n\n从这个线性纯生过程的化学主方程（CME）出发，定义概率生成函数（PGF）$G(s,t) = \\sum_{n=0}^{\\infty} s^{n} \\mathbb{P}(N(t)=n)$，并推导其满足的偏微分方程（PDE）以及相应的初始条件。然后求解此 PDE 以获得 $G(s,t)$ 的闭式解。使用您得到的闭式 PGF，提取对于 $n \\in \\{n_{0}, n_{0}+1, \\dots \\}$ 的概率质量函数 $\\mathbb{P}(N(t)=n \\mid N(0)=n_{0})$，并用 $\\lambda$、$t$ 和 $n_{0}$ 计算前两个矩 $\\mathbb{E}[N(t)]$ 和 $\\mathrm{Var}[N(t)]$。最后，将 $G(s,t)$ 的闭式表达式表述为一个单一的、简化的解析表达式。你的最终答案应该是这个用 $s$、$\\lambda$、$t$ 和 $n_{0}$ 书写的关于 $G(s,t)$ 的单一解析表达式。不要包含单位。不要四舍五入。", "solution": "该过程是一个纯生过程，其中每个反应 $X \\to 2X$ 使分子数增加一。系统的状态是分子数 $n$。状态的变化是 $n \\to n+1$。\n\n令 $P(n, t) = \\mathbb{P}(N(t) = n \\mid N(0) = n_{0})$。$P(n, t)$ 的时间演化由化学主方程（CME）控制。$P(n, t)$ 的变化是由迁入和迁出状态 n 的跃迁引起的。\n*   系统以倾向 $a(n-1) = \\lambda(n-1)$ 从状态 $n-1$ 跃迁到状态 $n$。\n*   系统以倾向 $a(n) = \\lambda n$ 从状态 $n$ 跃迁到状态 $n+1$。\n\n因此，CME 为：\n$$\n\\frac{d P(n, t)}{d t} = \\lambda(n-1) P(n-1, t) - \\lambda n P(n, t) \\quad \\text{for } n > n_{0}\n$$\n初始分子数为 $n_0$，因此无法达到小于 $n_0$ 的状态。对于 $n=n_0$，系统只能跃迁出去，所以没有增益项：\n$$\n\\frac{d P(n_{0}, t)}{d t} = - \\lambda n_{0} P(n_{0}, t)\n$$\n初始条件是 $P(n, 0) = \\delta_{n, n_{0}}$，其中 $\\delta_{n, n_{0}}$ 是克罗内克 δ。\n\n接下来，我们推导概率生成函数 $G(s,t) = \\sum_{n=n_0}^{\\infty} s^n P(n,t)$ 的 PDE。我们将 $G(s,t)$ 对时间 $t$ 求导：\n$$\n\\frac{\\partial G}{\\partial t} = \\sum_{n=n_0}^{\\infty} s^n \\frac{d P(n,t)}{d t}\n$$\n代入 CME 表达式：\n$$\n\\frac{\\partial G}{\\partial t} = \\sum_{n=n_0}^{\\infty} s^n \\left[ \\lambda(n-1) P(n-1, t) - \\lambda n P(n, t) \\right]\n$$\n其中，约定 $P(n_0-1, t)=0$。将和式分开：\n$$\n\\frac{\\partial G}{\\partial t} = \\lambda \\sum_{n=n_0}^{\\infty} s^n (n-1) P(n-1, t) - \\lambda \\sum_{n=n_0}^{\\infty} s^n n P(n, t)\n$$\n对于第一个和式，令 $m=n-1$。当 $n=n_0$ 时 $m=n_0-1$。\n$$\n\\sum_{n=n_0}^{\\infty} s^n (n-1) P(n-1, t) = \\sum_{m=n_0-1}^{\\infty} s^{m+1} m P(m, t) = s \\sum_{m=n_0}^{\\infty} m s^m P(m, t)\n$$\n利用 $s \\frac{\\partial G}{\\partial s} = \\sum_{n=n_0}^{\\infty} n s^n P(n, t)$，我们将和式重写为：\n$$\n\\frac{\\partial G}{\\partial t} = \\lambda s \\left(s \\frac{\\partial G}{\\partial s}\\right) - \\lambda \\left(s \\frac{\\partial G}{\\partial s}\\right) = \\lambda s(s-1) \\frac{\\partial G}{\\partial s}\n$$\n这就得到了一阶线性 PDE：\n$$\n\\frac{\\partial G}{\\partial t} = \\lambda s(s-1) \\frac{\\partial G}{\\partial s}\n$$\n$G(s, t)$ 在 $t=0$ 时的初始条件由 $P(n, 0) = \\delta_{n, n_{0}}$ 推导得出：\n$$\nG(s, 0) = \\sum_{n=n_0}^{\\infty} s^n P(n, 0) = \\sum_{n=n_0}^{\\infty} s^n \\delta_{n, n_{0}} = s^{n_{0}}\n$$\n我们使用特征线法求解该 PDE。特征方程为：\n$$\n\\frac{dt}{1} = \\frac{ds}{-\\lambda s(s-1)} = \\frac{dG}{0}\n$$\n从 $\\frac{dG}{0}=0$ 可知，$G$ 沿着特征线是常数。从另一对等式可得 $\\frac{ds}{dt} = -\\lambda s(s-1) = \\lambda s(1-s)$。这是一个可分离的 ODE：\n$$\n\\int \\frac{ds}{s(1-s)} = \\int \\lambda dt\n$$\n使用部分分式分解 $\\frac{1}{s(1-s)} = \\frac{1}{s} + \\frac{1}{1-s}$：\n$$\n\\int \\left( \\frac{1}{s} + \\frac{1}{1-s} \\right) ds = \\ln|s| - \\ln|1-s| = \\ln\\left|\\frac{s}{1-s}\\right|\n$$\n积分后得到 $\\ln\\left(\\frac{s}{1-s}\\right) = \\lambda t + C$，因此特征线由 $\\frac{s}{1-s}e^{-\\lambda t} = \\text{constant}$ 给出。通解的形式为 $G(s,t) = f\\left(\\frac{s}{1-s}e^{-\\lambda t}\\right)$。\n我们应用初始条件 $G(s,0) = s^{n_0}$：\n$$\nf\\left(\\frac{s}{1-s}\\right) = s^{n_{0}}\n$$\n令 $u = \\frac{s}{1-s}$。那么 $s = \\frac{u}{1+u}$。函数 $f$ 是 $f(u) = \\left(\\frac{u}{1+u}\\right)^{n_{0}}$。\n代回到 $G(s, t)$ 的通解中：\n$$\nG(s,t) = \\left( \\frac{\\frac{s}{1-s}e^{-\\lambda t}}{1 + \\frac{s}{1-s}e^{-\\lambda t}} \\right)^{n_{0}} = \\left( \\frac{s e^{-\\lambda t}}{1-s + s e^{-\\lambda t}} \\right)^{n_{0}}\n$$\n为了与最终答案的格式匹配，我们将分子和分母同乘以 $e^{\\lambda t}$：\n$$\nG(s,t) = \\left( \\frac{s}{(1-s)e^{\\lambda t} + s} \\right)^{n_{0}} = \\left( \\frac{s}{s(1-e^{\\lambda t}) + e^{\\lambda t}} \\right)^{n_{0}}\n$$\n为了找到 PMF，我们将 PGF 重写为标准形式。令 $p = e^{-\\lambda t}$，则 $1-p=1-e^{-\\lambda t}$。\n$$\nG(s,t) = \\left( \\frac{s e^{-\\lambda t}}{1-s(1-e^{-\\lambda t})} \\right)^{n_{0}} = \\left( \\frac{ps}{1 - (1-p)s} \\right)^{n_{0}}\n$$\n这是在集合 $\\{1, 2, ...\\}$ 上，成功概率为 $p$ 的 $n_0$ 个独立同分布几何随机变量之和的 PGF。因此，$N(t)$ 服从负二项分布，参数为 $n_0$ 和 $p=e^{-\\lambda t}$，其 PMF 为：\n$$\n\\mathbb{P}(N(t)=n \\mid N(0)=n_0) = \\binom{n-1}{n_0-1} p^{n_0} (1-p)^{n-n_0} \\quad \\text{for } n \\ge n_0\n$$\n$$\n\\mathbb{P}(N(t)=n \\mid N(0)=n_0) = \\binom{n-1}{n_0-1} (e^{-\\lambda t})^{n_0} (1-e^{-\\lambda t})^{n-n_0}\n$$\n矩可以从 PGF 中求得。均值为 $\\mathbb{E}[N(t)] = \\frac{\\partial G}{\\partial s} \\bigg|_{s=1}$。\n$$\n\\frac{\\partial G}{\\partial s} = n_{0} \\left( \\frac{s}{s(1-e^{\\lambda t}) + e^{\\lambda t}} \\right)^{n_{0}-1} \\cdot \\frac{d}{ds}\\left( \\frac{s}{s(1-e^{\\lambda t}) + e^{\\lambda t}} \\right)\n$$\n$$\n\\frac{d}{ds}\\left( \\frac{s}{s(1-e^{\\lambda t}) + e^{\\lambda t}} \\right) = \\frac{(s(1-e^{\\lambda t}) + e^{\\lambda t}) \\cdot 1 - s \\cdot (1-e^{\\lambda t})}{\\left(s(1-e^{\\lambda t}) + e^{\\lambda t}\\right)^{2}} = \\frac{e^{\\lambda t}}{\\left(s(1-e^{\\lambda t}) + e^{\\lambda t}\\right)^{2}}\n$$\n在 $s=1$ 时，大括号中的项为 $1$。\n$$\n\\mathbb{E}[N(t)] = n_{0} (1)^{n_{0}-1} \\frac{e^{\\lambda t}}{\\left(1(1-e^{\\lambda t}) + e^{\\lambda t}\\right)^{2}} = n_{0} \\frac{e^{\\lambda t}}{1^{2}} = n_{0} e^{\\lambda t}\n$$\n方差为 $\\mathrm{Var}[N(t)] = n_{0} \\frac{1-p}{p^2}$，其中 $p=e^{-\\lambda t}$。\n$$\n\\mathrm{Var}[N(t)] = n_{0} \\frac{1-e^{-\\lambda t}}{(e^{-\\lambda t})^2} = n_{0} \\frac{1-e^{-\\lambda t}}{e^{-2\\lambda t}} = n_{0} (e^{2\\lambda t} - e^{\\lambda t})\n$$\n题目要求给出 $G(s,t)$ 的单一简化解析表达式。这就是上面推导并给出的表达式。", "answer": "$$\n\\boxed{\\left( \\frac{s}{s(1-e^{\\lambda t}) + e^{\\lambda t}} \\right)^{n_{0}}}\n$$", "id": "2669255"}, {"introduction": "当化学反应网络变得复杂时，解析求解主方程几乎是不可能的，此时我们必须转向数值模拟，而Gillespie的随机模拟算法 (Stochastic Simulation Algorithm, SSA) 正是此领域的基石。然而，算法的计算效率直接决定了其在处理大规模实际问题时的可行性。本练习将挑战你从计算科学的视角出发，深入分析SSA核心步骤的实现方式，评估不同数据结构（如线性扫描、树状数组）在反应选择和倾向性更新等操作上的性能差异，从而深刻理解算法效率与设计选择之间的内在联系 [@problem_id:2669219]。", "problem": "一个具有 $N$ 个分子种类和 $R$ 个反应通道的充分混合化学反应网络，使用 Gillespie 的随机模拟算法 (Stochastic Simulation Algorithm, SSA) 进行模拟。设状态为 $X(t)\\in\\mathbb{N}^N$，对于反应 $\\mu\\in\\{1,\\dots,R\\}$，其倾向（propensity）为 $a_{\\mu}(X(t))$。在一个 SSA 步骤中，等待时间 $\\tau$ 从速率为 $a_0(X)=\\sum_{\\mu=1}^{R} a_{\\mu}(X)$ 的指数分布中采样，反应索引 $J$ 以概率 $\\mathbb{P}(J=\\mu\\mid X)=a_{\\mu}(X)/a_0(X)$ 被抽取。反应 $J$ 发生后，状态根据化学计量变化向量进行更新，并且每个依赖于任何已改变物种的倾向 $a_{\\mu}$ 都将被重新计算。假设在一次反应发生后必须更新的倾向数量是一个均值为 $\\bar{d}$ 的随机变量，该值由一个依赖图决定，此依赖图除了通过网络的连通性外与 $R$ 无关。\n\n假设：\n- 计算任何单个倾向 $a_{\\mu}$ 的时间复杂度为 $\\mathcal{O}(1)$。\n- 更新状态的时间复杂度为 $\\mathcal{O}(1)$。\n- 生成每个均匀分布随机变量的时间复杂度为 $\\mathcal{O}(1)$。\n- 你可以选择数据结构和更新策略，但必须遵守上述随机规则。\n\n考虑在不同实现选择下每一步的计算复杂度。选择所有正确的陈述。\n\nA. 在一个朴素的直接法实现中，每一步都重新构建累积和数组 $\\left(\\sum_{\\nu=1}^{\\mu} a_{\\nu}\\right)_{\\mu=1}^{R}$，然后线性扫描它来选择 $J$，选择工作的复杂度为 $\\mathcal{O}(R)$。加上重新计算 $\\bar{d}$ 个受影响的倾向，每步的成本为 $\\mathcal{O}(R+\\bar{d})$。\n\nB. 如果总倾向 $a_0$ 是增量维护的（通过在每次反应发生后加上受影响的 $a_{\\mu}$ 的变化量），那么对指数等待时间采样的复杂度变为 $\\mathcal{O}(1)$；然而，若没有额外的数据结构，通过线性扫描累积倾向来选择 $J$ 的复杂度仍然是 $\\mathcal{O}(R)$。\n\nC. 将倾向存储在以索引 $1,\\dots,R$ 为键的树状数组（也称为 Fenwick 树）中，支持通过前缀和搜索以 $\\mathcal{O}(\\log R)$ 的时间进行逆变换采样来选择 $J$，并以 $\\mathcal{O}(\\log R)$ 的时间更新单个 $a_{\\mu}$。因此，选择加上更新，一个步骤的成本为 $\\mathcal{O}(\\log R+\\bar{d}\\log R)$。\n\nD. 维护一个以当前倾向 $a_{\\mu}$ 为键的二叉堆，使得 SSA 选择的复杂度为 $\\mathcal{O}(\\log R)$，因为下一个反应是 $a_{\\mu}$ 最大的那个反应。\n\nE. 对于固定的权重，别名法（alias method）可以实现期望时间为 $\\mathcal{O}(1)$ 的采样，但由于 SSA 的倾向在每次反应后都会改变，重建别名表通常每步需要 $\\mathcal{O}(R)$ 的成本；在没有额外结构支持动态更新的情况下，每步的均摊成本是 $\\mathcal{O}(R)$。\n\nF. 在使用依赖图和存储暂定绝对发生时间的二叉堆的下一个反应法（NRM）中，提取下一个反应的复杂度为 $\\mathcal{O}(\\log R)$，更新 $\\bar{d}$ 个受影响的键的复杂度为 $\\mathcal{O}(\\bar{d}\\log R)$，前提是假设受影响的指数时钟的转换公式计算时间为常数。\n\nG. 任何为直接法实现亚线性于 $R$（sublinear-in-$R$）的选择时间的数据结构，由于需要维护累积和，必然导致单个倾向改变时产生 $\\mathcal{O}(R)$ 的最坏情况更新时间。\n\n选择所有适用的选项。", "solution": "问题陈述是关于随机模拟算法分析的一个有效练习。它具有科学依据，问题阐述清晰，并使用了精确、客观的语言。我们现在将对每个陈述进行审慎的评估。\n\n**对陈述 A 的分析**\n\n该陈述描述了 Gillespie 算法“直接法”最基础的实现。选择下一个反应 $J$ 需要从离散概率分布 $\\mathbb{P}(J=\\mu | X) = a_{\\mu}(X) / a_0(X)$ 中采样。\n\n1.  为了执行逆变换采样，通常会计算总倾向 $a_0 = \\sum_{\\mu=1}^{R} a_{\\mu}$，然后找到满足 $\\sum_{\\nu=1}^{J} a_{\\nu} > r \\cdot a_0$ 的最小整数 $J$，其中 $r \\sim U(0,1)$。\n2.  该陈述指明在每一步都要重建累积和数组 $\\left(\\sum_{\\nu=1}^{\\mu} a_{\\nu}\\right)_{\\mu=1}^{R}$。构建这个包含 $R$ 个元素的数组是一个 $\\mathcal{O}(R)$ 的操作。\n3.  一旦累积和数组建立，通过线性扫描找到正确的索引 $J$ 在平均和最坏情况下也需要 $\\mathcal{O}(R)$ 的时间。因此，总的选择工作的复杂度为 $\\mathcal{O}(R)$。\n4.  除了选择之外，算法还必须更新受状态变化影响的倾向。问题假定平均有 $\\bar{d}$ 个倾向需要重新计算。由于假设每次评估的复杂度为 $\\mathcal{O}(1)$，这部分步骤的成本为 $\\mathcal{O}(\\bar{d})$。\n\n每一步的总计算成本是选择和更新成本的总和，即 $\\mathcal{O}(R + \\bar{d})$。该陈述是对这个朴素算法复杂度的正确评估。\n\n**对 A 的判断**: **正确**。\n\n**对陈述 B 的分析**\n\n该陈述考虑了一个小的优化，其中总倾向 $a_0$ 不是从头计算，而是增量维护。\n\n1.  一个反应发生后，$\\bar{d}$ 个倾向发生变化。对于每个受影响的倾向 $a_\\mu$，我们可以找到其变化量 $\\Delta a_\\mu = a_\\mu^{\\text{new}} - a_\\mu^{\\text{old}}$。总倾向通过 $a_0^{\\text{new}} = a_0^{\\text{old}} + \\sum_{\\text{affected}} \\Delta a_\\mu$ 进行更新。这个更新过程需要 $\\mathcal{O}(\\bar{d})$ 的工作量。\n2.  有了 $a_0$ 的值，对等待时间 $\\tau = -\\frac{1}{a_0} \\ln(r_1)$ 进行采样涉及一个随机数生成、一个对数运算和一个除法运算，所有这些都是 $\\mathcal{O}(1)$ 操作。因此，该陈述的第一部分是正确的。\n3.  然而，选择反应索引 $J$ 仍然需要从由各个倾向 $\\{a_\\mu\\}$ 定义的离散分布中采样。在这种情况下，执行逆变换采样的唯一方法是遍历倾向，动态计算部分和，即找到满足 $\\sum_{\\nu=1}^{J-1} a_\\nu  r_2 a_0 \\leq \\sum_{\\nu=1}^{J} a_\\nu$ 的 $J$。这种线性扫描是一个 $\\mathcal{O}(R)$ 的操作。\n\n该陈述正确地分解了每步的工作，并准确地为给定实现策略下的每个部分分配了复杂度。\n\n**对 B 的判断**: **正确**。\n\n**对陈述 C 的分析**\n\n该陈述提议使用树状数组 (BIT)，或称 Fenwick 树，它是一种能实现高效动态前缀和计算的数据结构。\n\n1.  BIT 支持在 $\\mathcal{O}(\\log R)$ 时间内更新单个索引处的值和查询到任意索引的前缀和。\n2.  **更新倾向**：当 $\\bar{d}$ 个倾向必须更新时，这对应于对 BIT 进行 $\\bar{d}$ 次单独的更新操作。此阶段的总成本为 $\\mathcal{O}(\\bar{d} \\log R)$。\n3.  **采样 $J$**：选择需要找到与从 $U(0, a_0)$ 中抽取的值相对应的索引 $J$。首先，通过查询到 $R$ 的前缀和来找到总倾向 $a_0$，这需要 $\\mathcal{O}(\\log R)$ 的时间。然后，必须在 BIT 上执行搜索，以找到前缀和首次超过随机阈值的索引 $J$。在 BIT 上的这种搜索可以实现为在 $\\mathcal{O}(\\log R)$ 时间内运行。因此，整个选择过程的复杂度为 $\\mathcal{O}(\\log R)$。\n4.  每步的总成本是选择和更新复杂度的总和：$\\mathcal{O}(\\log R) + \\mathcal{O}(\\bar{d}\\log R) = \\mathcal{O}(\\log R + \\bar{d}\\log R)$。\n\n该陈述正确地指出了在 BIT 上的相关操作的复杂度，并正确地将它们结合起来以得出每步的总复杂度。\n\n**对 C 的判断**: **正确**。\n\n**对陈述 D 的分析**\n\n该陈述断言 SSA 选择涉及挑选具有最大倾向的反应 $a_{\\mu}$。这个前提是根本错误的。根据定义，随机模拟算法是随机的。选择规则是概率性的：反应 $\\mu$ 被选中的概率与其倾向 $a_{\\mu}$ 成正比，而不是因为它的倾向是最大的。一个确定性地选择最大倾向反应的算法不是 Gillespie 算法，并且会导致性质上不同、不符合物理现实的系统动力学。一个以倾向值为键的二叉堆是寻找最大值的有效数据结构，但此操作与正确的 SSA 选择步骤无关。\n\n**对 D 的判断**: **不正确**。\n\n**对陈述 E 的分析**\n\n别名法（alias method）是一种从离散分布中采样的著名技术。它包括一个 $\\mathcal{O}(R)$ 的设置阶段来构建内部表格，之后可以在 $\\mathcal{O}(1)$ 时间内进行采样。在 SSA 的背景下，底层的概率分布（由倾向定义）在每一步都会改变。因此，使用别名法的朴素实现将需要在每个模拟步骤中执行昂贵的 $\\mathcal{O}(R)$ 设置阶段。后续采样是 $\\mathcal{O}(1)$ 的事实并不能改变每步成本由 $\\mathcal{O}(R)$ 的重建主导的现实。因此，均摊成本是 $\\mathcal{O}(R)$，正如陈述所正确指出的。\n\n**对 E 的判断**: **正确**。\n\n**对陈述 F 的分析**\n\n该陈述描述了 Gibson 和 Bruck 的下一个反应法（NRM），这是 SSA 的一种精确但结构上不同的表述。它不是维护一个等待时间，而是维护 $R$ 个暂定的绝对发生时间 $\\{T_\\mu\\}$，通常存储在最小优先队列（例如，二叉堆）中。\n\n1.  **提取下一个反应**：下一个要发生的反应是具有最小发生时间的反应，$T_J = \\min_{\\mu} \\{T_\\mu\\}$。从大小为 $R$ 的二叉堆中查找并删除此最小元素是 `extract-min` 操作，其成本为 $\\mathcal{O}(\\log R)$。\n2.  **更新**：反应 $J$ 发生后，状态改变，这又会改变其他一些反应的倾向。使用依赖图来识别这些受影响的反应，平均有 $\\bar{d}$ 个。对于这 $\\bar{d}$ 个反应中的每一个，其暂定发生时间必须重新计算，并且其在堆中的位置必须调整。在二叉堆中更新一个键是 $\\mathcal{O}(\\log R)$ 的操作。执行 $\\bar{d}$ 次这样的更新成本为 $\\mathcal{O}(\\bar{d} \\log R)$。\n\n该陈述为 NRM 的计算复杂度提供了精确而准确的总结。\n\n**对 F 的判断**: **正确**。\n\n**对陈述 G 的分析**\n\n该陈述声称，任何为直接法提供亚线性选择时间的数据结构，在单个倾向改变时都必须具有 $\\mathcal{O}(R)$ 的最坏情况更新时间。这个说法是错误的。它错误地假设了一个必要的权衡，而这个权衡可以通过适当的数据结构来规避。\n\n对陈述 C 的分析提供了一个明确的反例。树状数组允许选择（通过逆前缀和搜索）和单倾向更新都在 $\\mathcal{O}(\\log R)$ 时间内执行。由于 $\\log R$ 是 $R$ 的亚线性函数，这表明可以同时为两种操作实现亚线性复杂度。该陈述关于“需要维护累积和”的推理是基于对实现的狭隘看法；像 BITs 和线段树这样的高级数据结构隐式地维护了这些信息，从而避免了与简单的累积和数组相关的线性时间成本。\n\n**对 G 的判断**: **不正确**。", "answer": "$$\\boxed{ABCEF}$$", "id": "2669219"}, {"introduction": "标准的Gillespie算法基于一个核心假设：在两次反应事件之间，所有反应的倾向性 (propensity) 保持不变。然而，在许多物理化学情境中，例如当系统受到周期性变化的外部激光或电场驱动时，反应速率常数会明确地依赖于时间，导致倾向性也随时间变化。本练习将指导你掌握处理这类非平稳过程的“瘦化”方法 (thinning method)，通过引入一个虚拟的恒定速率上界和拒绝采样步骤，巧妙地将非齐次泊松过程转化为齐次过程进行模拟。你将从第一性原理出发，推导关键的接受概率，从而将基础概率论与高级随机模拟技术紧密结合 [@problem_id:2669241]。", "problem": "在一个充分混合的系统中，一个单分子反应通道由于外部驱动场的作用，其倾向函数 $a_{0}(t)$ 是随时间变化的。你需要分析如何在随机模拟算法（SSA）（也称为 Gillespie 算法）中，使用细化法或增广状态构造来处理这种非平稳性，并为第一个提议事件推导出一个显式的接受概率。\n\n从第一性原理出发：使用具有瞬时风险率的计数过程的生存概率定义，并构建一个有效的齐次边界过程。不要假设任何预先推导的接受规则。\n\n考虑具体情况 $a_{0}(t)=k_{0}+k_{1}\\cos(\\omega t)$，其中 $k_{0}\\geq |k_{1}|$，因此对于所有 $t\\geq 0$ 都有 $a_{0}(t)\\geq 0$。在 $[0,\\infty)$ 上，对细化法使用全局上界 $M=k_{0}+|k_{1}|$。从第一性原理出发，推导一个表达式，表示由细化法产生的第一个提议的候选事件（等价地，在增广状态方法中通过添加一个虚拟反应使总速率常数为 $M$）被接受为真实反应的概率。然后，对于数值参数 $k_{0}=2.0\\,\\mathrm{s}^{-1}$、$k_{1}=1.0\\,\\mathrm{s}^{-1}$ 和 $\\omega=3.0\\,\\mathrm{s}^{-1}$，以及 $M=k_{0}+|k_{1}|$，计算这个接受概率。\n\n将你的最终答案表示为一个无量纲小数，并四舍五入到四位有效数字。", "solution": "该问题要求使用细化法，在一个非平稳过程的随机模拟中，推导并计算第一个候选事件的接受概率。分析必须从第一性原理开始。\n\n设系统在时间 $t$ 的状态为 $X(t)$。考虑单个反应通道，其发生由一个时间依赖的倾向函数 $a_{0}(t)$ 控制。这描述了一个非齐次泊松过程。控制此类过程的基本量是生存概率 $S(t|t_{0})$，即在时间区间 $[t_{0}, t)$ 内没有事件发生的概率。它由下式给出：\n$$ S(t|t_{0}) = \\exp\\left( -\\int_{t_{0}}^{t} a_{0}(t') dt' \\right) $$\n下一个事件发生的时间 $\\tau$ 的概率密度函数 $p(\\tau)$（假定过程从 $t_0=0$ 开始）可以从生存概率推导得出。事件在无穷小区间 $[\\tau, \\tau+d\\tau]$ 内发生的概率，是生存到时间 $\\tau$ 的概率乘以在 $[\\tau, \\tau+d\\tau]$ 内发生一个事件的概率，后者为 $a_{0}(\\tau)d\\tau$。因此：\n$$ p(\\tau)d\\tau = S(\\tau|0) \\cdot a_{0}(\\tau)d\\tau $$\n$$ p(\\tau) = a_{0}(\\tau) \\exp\\left( -\\int_{0}^{\\tau} a_{0}(t') dt' \\right) $$\n直接从此分布中抽样通常是难以处理的，因为它需要先对 $a_{0}(t)$ 进行积分，然后再对该积分求逆。\n\n细化法，或称拒绝法，规避了这一困难。它依赖于一个速率恒为 $M$ 的边界齐次泊松过程，其中对于所关注域中的所有 $t$，都有 $M \\geq a_{0}(t)$。问题为在 $t \\in [0, \\infty)$ 上的倾向 $a_{0}(t)=k_{0}+k_{1}\\cos(\\omega t)$ 指定了一个全局上界 $M = k_{0} + |k_{1}|$。这个上界是有效的，因为 $k_{0}+k_{1}\\cos(\\omega t) \\leq k_{0} + |k_{1}\\cos(\\omega t)| \\leq k_{0} + |k_{1}| = M$。\n\n这个边界过程会生成一系列“候选”事件。到第一个候选事件的时间，我们记为 $\\tau_c$，是一个从速率为 $M$ 的指数分布中抽取的随机变量：\n$$ p_M(\\tau_c) = M \\exp(-M \\tau_c) $$\n当一个候选事件在时间 $\\tau_c$ 发生时，它以等于该时刻真实倾向与边界倾向之比的概率被接受为“真实”事件：\n$$ P_{\\text{accept}}(\\tau_c) = \\frac{a_{0}(\\tau_c)}{M} $$\n否则，该事件被拒绝（或“细化”），模拟继续进行到下一个候选事件。这个过程是有效的，因为在任何时间 $t$，被接受事件的有效速率是候选事件的速率乘以接受概率，即 $M \\times \\frac{a_{0}(t)}{M} = a_{0}(t)$，这正是真实的瞬时速率。\n\n问题要求的是*第一个*提议的候选事件被接受的概率。这不是在特定时间下的条件概率，而是总体的、无条件的概率。为了求得这个值（我们记为 $P_A$），我们必须将随时间变化的接受概率 $P_{\\text{accept}}(\\tau_c)$ 对第一个候选事件所有可能的时间 $\\tau_c$ 进行平均。时间 $\\tau_c$ 根据 $p_M(\\tau_c)$ 分布。因此，$P_A$ 是 $P_{\\text{accept}}(\\tau_c)$ 的期望：\n$$ P_A = E[P_{\\text{accept}}(\\tau_c)] = \\int_{0}^{\\infty} P_{\\text{accept}}(t) p_M(t) dt $$\n代入 $P_{\\text{accept}}(t)$ 和 $p_M(t)$ 的表达式：\n$$ P_A = \\int_{0}^{\\infty} \\left( \\frac{a_{0}(t)}{M} \\right) (M \\exp(-Mt)) dt = \\int_{0}^{\\infty} a_{0}(t) \\exp(-Mt) dt $$\n这个积分是倾向函数 $a_{0}(t)$ 的拉普拉斯变换在 $s=M$ 处的值。\n\n现在，我们代入给定的形式 $a_{0}(t) = k_{0} + k_{1}\\cos(\\omega t)$：\n$$ P_A = \\int_{0}^{\\infty} (k_{0} + k_{1}\\cos(\\omega t)) \\exp(-Mt) dt $$\n我们可以把它分成两个积分：\n$$ P_A = \\int_{0}^{\\infty} k_{0} \\exp(-Mt) dt + \\int_{0}^{\\infty} k_{1}\\cos(\\omega t) \\exp(-Mt) dt $$\n第一个积分是基本的：\n$$ \\int_{0}^{\\infty} k_{0} \\exp(-Mt) dt = k_{0} \\left[ -\\frac{1}{M}\\exp(-Mt) \\right]_{0}^{\\infty} = k_{0} \\left( 0 - \\left(-\\frac{1}{M}\\right) \\right) = \\frac{k_{0}}{M} $$\n第二个积分是标准的拉普拉斯变换，$\\mathcal{L}\\{\\cos(\\omega t)\\}(s) = \\frac{s}{s^2 + \\omega^2}$。在 $s=M$ 处求值：\n$$ \\int_{0}^{\\infty} k_{1}\\cos(\\omega t) \\exp(-Mt) dt = k_{1} \\mathcal{L}\\{\\cos(\\omega t)\\}(M) = k_{1} \\frac{M}{M^2 + \\omega^2} $$\n结合这两个结果，得到第一个事件的接受概率的通用表达式：\n$$ P_A = \\frac{k_{0}}{M} + \\frac{k_{1}M}{M^2 + \\omega^2} $$\n现在，我们代入指定的数值参数：$k_{0} = 2.0\\,\\mathrm{s}^{-1}$、$k_{1} = 1.0\\,\\mathrm{s}^{-1}$ 和 $\\omega = 3.0\\,\\mathrm{s}^{-1}$。边界速率为 $M = k_{0} + |k_{1}| = 2.0 + |1.0| = 3.0\\,\\mathrm{s}^{-1}$。\n\n将这些值代入 $P_A$ 的表达式中：\n$$ P_A = \\frac{2.0}{3.0} + \\frac{(1.0)(3.0)}{(3.0)^2 + (3.0)^2} $$\n$$ P_A = \\frac{2}{3} + \\frac{3}{9 + 9} = \\frac{2}{3} + \\frac{3}{18} $$\n$$ P_A = \\frac{2}{3} + \\frac{1}{6} = \\frac{4}{6} + \\frac{1}{6} = \\frac{5}{6} $$\n为了以要求的格式提供最终答案，我们将此分数转换为小数并四舍五入到四位有效数字：\n$$ P_A = \\frac{5}{6} \\approx 0.833333... $$\n四舍五入到四位有效数字得到 $0.8333$。", "answer": "$$\n\\boxed{0.8333}\n$$", "id": "2669241"}]}