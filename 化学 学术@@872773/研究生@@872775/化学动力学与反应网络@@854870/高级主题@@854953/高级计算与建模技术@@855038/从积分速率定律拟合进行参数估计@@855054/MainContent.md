## 引言
从实验数据中确定反应网络的速率常数和其他参数是[化学动力学](@entry_id:144961)中的一项基本任务。这些内嵌于数学模型中的参数是揭示化学和[生物过程](@entry_id:164026)潜在机理的关键。然而，从充满噪声的实验数据中提取这些数值是一个复杂的挑战，其意义远超简单的曲线拟合。若没有严谨的方法论，[参数估计](@entry_id:139349)可能产生偏差，其不确定性会被错误评估，甚至可能选出错误的机理模型，从而导致错误的科学结论。本文旨在提供一份全面的指南，指导读者如何通过拟合[积分速率方程](@entry_id:141884)来应对这一挑战。

为了构建坚实的基础，我们将首先在“**原理与机制**”一章中深入探讨参数估计的理论。本章将阐述其统计学框架，从最小二乘法和[最大似然估计](@entry_id:142509)，到[非线性拟合](@entry_id:136388)算法的计算核心，并讨论如何批判性地评估参数和模型本身的质量。接着，在“**应用与交叉学科联系**”中，我们将见证这些原理的实际应用，探索它们如何被用于解决从酶动力学到[材料科学](@entry_id:152226)和[发育生物学](@entry_id:141862)等领域的真实问题。最后，“**动手实践**”部分将提供练习，帮助您巩固理解并亲手应用这些技术。现在，让我们从构成稳健动力学[参数估计](@entry_id:139349)基石的核心原理与机制开始。

## 原理与机制

在化学动力学中，一个核心任务是从实验观测数据中推断出反应网络的潜在机理和定量参数。在上一章引言之后，本章将深入探讨从[积分速率方程](@entry_id:141884)拟合中估计参数的“原理与机制”。我们将系统性地阐述从基本的统计学原理到先进的计算方法的整个工作流程。这包括如何建立参数估计的统计学框架，如何执行[非线性拟合](@entry_id:136388)，如何评估所得参数的不确定性和模型的适当性，以及最终如何在多个候选模型之间进行选择。

### [最小二乘法](@entry_id:137100)及其统计学基础

[参数估计](@entry_id:139349)的核心目标是找到一组模型参数 $\boldsymbol{\theta}$，使得模型的预测值 $f(t_i; \boldsymbol{\theta})$ 与在时间点 $t_i$ 观测到的实验数据 $y_i$ 之间的差异最小化。最直观和广泛使用的方法是**[最小二乘法](@entry_id:137100) (Least Squares)**，它旨在最小化残差（即预测值与观测值之差）的平方和 (Sum of Squared Residuals, SSR)。

在更一般的情况下，我们考虑到不同数据点的[测量精度](@entry_id:271560)可能不同，因此引入**[加权最小二乘法](@entry_id:177517) (Weighted Least Squares, WLS)**。其[目标函数](@entry_id:267263) $S(\boldsymbol{\theta})$ 定义为：

$$
S(\boldsymbol{\theta}) = \sum_{i=1}^{n} w_i \left( y_i - f(t_i; \boldsymbol{\theta}) \right)^2
$$

其中 $n$ 是数据点的数量，$w_i$ 是分配给第 $i$ 个数据点的权重。

这个[目标函数](@entry_id:267263)的选择并非随意的，它具有坚实的统计学基础。假设测量误差 $\varepsilon_i = y_i - f(t_i; \boldsymbol{\theta})$ 是相互独立的，并且服从均值为零、[方差](@entry_id:200758)为 $\sigma_i^2$ 的高斯（正态）[分布](@entry_id:182848)，即 $\varepsilon_i \sim \mathcal{N}(0, \sigma_i^2)$。在这种情况下，整个数据集的[似然函数](@entry_id:141927) $L(\boldsymbol{\theta})$ 是所有单点概率密度的乘积。最大化[似然函数](@entry_id:141927)（或其对数）的**[最大似然估计](@entry_id:142509) (Maximum Likelihood Estimation, MLE)** 方法，其目标等价于最小化以下形式的加权平方和 [@problem_id:2660597]：

$$
\sum_{i=1}^{n} \frac{(y_i - f(t_i; \boldsymbol{\theta}))^2}{\sigma_i^2}
$$

通过比较 WLS [目标函数](@entry_id:267263)，我们得出一个关键结论：最优的权重 $w_i$ 应与测量误差[方差](@entry_id:200758)的倒数成正比，即 $w_i \propto 1/\sigma_i^2$ [@problem_id:2660597] [@problem_id:2660616]。这意味着测量越精确（[方差](@entry_id:200758) $\sigma_i^2$ 越小），其在拟合中被赋予的权重就越大。

在实际应用中，误差的[方差](@entry_id:200758)结构主要分为两种情况 [@problem_id:2660616]：
1.  **[同方差性](@entry_id:634679) (Homoscedasticity)**：所有测量的[误差方差](@entry_id:636041)都相同，即 $\sigma_i^2 = \sigma^2$ 为常数。这通常对应于测量背景噪声恒定的情况。此时，所有权重 $w_i$ 都相等，WLS 简化为**[普通最小二乘法](@entry_id:137121) (Ordinary Least Squares, OLS)**，其目标是最小化未加权的[残差平方和](@entry_id:174395)。
2.  **[异方差性](@entry_id:136378) (Heteroscedasticity)**：[误差方差](@entry_id:636041)随测量条件（如信号强度或时间）而变化。在化学分析中，一种常见的情况是[相对误差](@entry_id:147538)恒定，即误差的[标准差](@entry_id:153618)与信号的[真值](@entry_id:636547)成正比，$\sigma_i \propto f(t_i; \boldsymbol{\theta})$。这意味着浓度越高，测量的[绝对误差](@entry_id:139354)越大。在这种情况下，使用 WLS 并设置权重 $w_i \propto 1/f(t_i; \boldsymbol{\theta})^2$ 是至关重要的。

对于具有近似恒定[相对误差](@entry_id:147538)的异[方差](@entry_id:200758)数据，一种常见的处理方法是对浓度数据进行[对数变换](@entry_id:267035)。如果原始误差模型是[乘性](@entry_id:187940)的，例如 $y_i = f(t_i; \boldsymbol{\theta})\exp(\eta_i)$，其中 $\eta_i$ 是均值为零、[方差](@entry_id:200758)恒定的高斯噪声，那么取对数后模型变为 $\ln(y_i) = \ln(f(t_i; \boldsymbol{\theta})) + \eta_i$。这样，变换后的误差变为加性的、同[方差](@entry_id:200758)的高斯噪声。此时，[对数变换](@entry_id:267035)后的数据可以直接使用 OLS进行拟合，这在统计上是合理的，并且等价于对原始数据进行权重为 $w_i \propto 1/y_i^2$ 的 WLS 拟合 [@problem_id:2660604] [@problem_id:2660616]。此外，如果实验允许在每个时间点进行重复测量，我们可以直接从重复样本中估计每个点的[方差](@entry_id:200758) $\hat{\sigma}_i^2$，并用其倒数作为权重 $w_i = 1/\hat{\sigma}_i^2$ [@problem_id:2660616]。

### 线性化方法：一种历史性视角

在现代计算方法普及之前，动力学[参数估计](@entry_id:139349)主要依赖于**线性化方法 (Linearization Method)**。这种方法的思想是将[非线性](@entry_id:637147)的[积分速率方程](@entry_id:141884)通过数学变换，重写为一个线性方程，然后使用简单的线性回归（即 OLS）来估计参数。

考虑一个简单的[分解反应](@entry_id:145427) $A \to \text{产物}$，其[速率方程](@entry_id:198152)为 $-d[A]/dt = k[A]^n$。根据反应级数 $n$ 的不同，我们可以推导出不同的线性化形式 [@problem_id:2660620]：

*   **[零级反应](@entry_id:176293) ($n=0$)**: [积分速率方程](@entry_id:141884)为 $[A](t) = [A]_0 - kt$。这是一个[线性方程](@entry_id:151487)，因此可以直接将浓度 $[A]$ 对时间 $t$ 作图，通过[线性回归](@entry_id:142318)得到斜率 $-k$ 和截距 $[A]_0$。
*   **[一级反应](@entry_id:136907) ($n=1$)**: [积分速率方程](@entry_id:141884)为 $\ln[A](t) = \ln[A]_0 - kt$。此时，应将 $\ln[A]$ 对时间 $t$ 作图，回归线的斜率为 $-k$，截距为 $\ln[A]_0$。
*   **[二级反应](@entry_id:139599) ($n=2$)**: [积分速率方程](@entry_id:141884)为 $1/[A](t) = 1/[A]_0 + kt$。此时，应将 $1/[A]$ 对时间 $t$ 作图，回归线的斜率为 $k$，截距为 $1/[A]_0$。

为了确定反应级数，研究者会分别对这三种变换后的数据进行线性拟合，并选择给出最佳[线性关系](@entry_id:267880)（例如，具有最接近1的[决定系数](@entry_id:142674) $R^2$）的级数作为模型的[反应级数](@entry_id:142981)。例如，如果实验数据点 $(t_i, [A]_i)$ 经过变换后，在 $[A]$ vs. $t$ 的图上完美地落于一条直线上，那么可以断定这是一个[零级反应](@entry_id:176293)，并且可以直接从该直线的斜率确定速率常数 $k$ [@problem_id:2660620]。

然而，线性化方法虽然简单直观，但存在严重的统计学缺陷 [@problem_id:2660604]。主要问题在于对因变量（浓度）的[非线性变换](@entry_id:636115)（如取对数或倒数）会扭曲原始[测量误差](@entry_id:270998)的[分布](@entry_id:182848)。即使原始数据的[测量误差](@entry_id:270998)是同[方差](@entry_id:200758)的[高斯噪声](@entry_id:260752)，变换后的数据误差也将不再是同[方差](@entry_id:200758)的，也不再服从[高斯分布](@entry_id:154414)。例如，对一个具有恒定[方差](@entry_id:200758) $\sigma^2$ 的变量 $y$ 取倒数，新变量 $1/y$ 的[方差](@entry_id:200758)将近似为 $\sigma^2/y^4$，这显然不再是恒定的。在变换后的空间中使用为同[方差](@entry_id:200758)[高斯噪声](@entry_id:260752)设计的 OLS，会违反其基本假设，从而导致参数估计产生系统性偏差且[统计效率](@entry_id:164796)低下。因此，现代动力学分析强烈推荐使用直接的[非线性拟合](@entry_id:136388)方法。

### [非线性](@entry_id:637147)最小二乘 (NLS) 估计

与线性化方法不同，**[非线性](@entry_id:637147)最小二乘 (Nonlinear Least Squares, NLS)** 方法直接在原始浓度-时间数据上最小化加权[残差平方和](@entry_id:174395) $S(\boldsymbol{\theta})$，而无需对模型或数据进行变换。由于 $S(\boldsymbol{\theta})$ 通常是参数 $\boldsymbol{\theta}$ 的一个复杂[非线性](@entry_id:637147)函数，其最小值无法通过解析方法求得，必须依赖迭代的[数值优化](@entry_id:138060)算法。

**[高斯-牛顿法](@entry_id:173233) (Gauss-Newton Method)** 是解决 NLS 问题的标准算法之一。该算法的核心是**雅可比矩阵 (Jacobian Matrix)** $J$，也称为**灵敏度矩阵 (Sensitivity Matrix)**。该矩阵的元素 $J_{ij}$ 定义为第 $i$ 个数据点的模型预测值对第 $j$ 个参数的偏导数：

$$
J_{ij} = \frac{\partial f(t_i; \boldsymbol{\theta})}{\partial \theta_j}
$$

雅可比矩阵的每一列代表了模型输出对相应参数变化的敏感程度。它是连接[参数空间](@entry_id:178581)和数据空间的桥梁 [@problem_id:2660615]。

利用[雅可比矩阵](@entry_id:264467)，[目标函数](@entry_id:267263) $S(\boldsymbol{\theta})$ 的梯度 $\nabla S(\boldsymbol{\theta})$ 可以表示为 $\nabla S(\boldsymbol{\theta}) = -2 J^{\top} W \boldsymbol{r}(\boldsymbol{\theta})$，其中 $W$ 是权重[对角矩阵](@entry_id:637782)，$\boldsymbol{r}(\boldsymbol{\theta})$ 是残差向量，其元素为 $r_i(\boldsymbol{\theta}) = y_i - f(t_i; \boldsymbol{\theta})$。[高斯-牛顿法](@entry_id:173233)通过在当前参数估计 $\boldsymbol{\theta}^{(k)}$ 附近对模型进行线性化，并近似目标函数的[二阶导数](@entry_id:144508)矩阵（Hessian矩阵）为 $H \approx 2 J^{\top} W J$，从而推导出每次迭代的参数更新步长 $\delta\boldsymbol{\theta}$。这个步长通过求解以下[线性方程组](@entry_id:148943)（称为**[正规方程](@entry_id:142238) (Normal Equations)**）获得 [@problem_id:2660615]：

$$
\left( J^{\top} W J \right) \delta\boldsymbol{\theta} = J^{\top} W \boldsymbol{r}
$$

通过迭代更新 $\boldsymbol{\theta}^{(k+1)} = \boldsymbol{\theta}^{(k)} + \delta\boldsymbol{\theta}$，算法逐步逼近 $S(\boldsymbol{\theta})$ 的[最小值点](@entry_id:634980)，即最终的[参数估计](@entry_id:139349) $\hat{\boldsymbol{\theta}}$。

为了更具体地理解这一过程，我们考虑一个一级不可逆衰减反应 $A \to \text{产物}$，其[积分速率方程](@entry_id:141884)为 $[A](t) = [A]_0 \exp(-kt)$。参数向量为 $\boldsymbol{\theta} = ([A]_0, k)^{\top}$ [@problem_id:2660585]。
1.  **计算灵敏度**: 首先，我们计算模型对每个参数的[偏导数](@entry_id:146280)（即[雅可比矩阵](@entry_id:264467)的列）：
    $$
    \frac{\partial [A](t)}{\partial [A]_0} = \exp(-kt)
    $$
    $$
    \frac{\partial [A](t)}{\partial k} = -[A]_0 t \exp(-kt)
    $$
2.  **构建雅可比矩阵**: 对于一组给定的时间点 $\{t_i\}$ 和一个初始参数猜测 $\boldsymbol{\theta}^{(0)} = ([A]_0^{(0)}, k^{(0)})^{\top}$，我们可以将这些[灵敏度函数](@entry_id:271212)在每个时间点求值，从而构建出雅可比矩阵 $J$。
3.  **计算高斯-[牛顿步长](@entry_id:177069)**: 接下来，计算在 $\boldsymbol{\theta}^{(0)}$ 处的残差向量 $\boldsymbol{r}$。然后，构建并求解[正规方程](@entry_id:142238) $(J^{\top}J)\delta\boldsymbol{\theta} = J^{\top}\boldsymbol{r}$（这里假设为 OLS，即 $W=I$），得到第一个更新步长 $\delta\boldsymbol{\theta}$。通过这个具体的计算过程，我们可以看到理论是如何转化为实际的数值操作的 [@problem_id:2660585]。

### 模型与参数的评估

得到最优参数估计 $\hat{\boldsymbol{\theta}}$ 只是分析的第一步。同样重要的是评估这些估计的可靠性以及模型本身的适当性。

#### [参数不确定性](@entry_id:264387)

我们得到的 $\hat{\boldsymbol{\theta}}$ 只是一个[点估计](@entry_id:174544)，它会因实验数据的随机性而变化。量化这种不确定性，通常通过计算**[置信区间](@entry_id:142297) (Confidence Intervals)** 来实现。

一种标准方法是利用雅可比矩阵。对于一个表现良好的模型（参数可辨识且数据量足够大），[参数估计](@entry_id:139349)的**协方差矩阵 (Covariance Matrix)** $\hat{C}$ 可以通过在最优解 $\hat{\boldsymbol{\theta}}$ 处计算的雅可比矩阵来近似 [@problem_id:2660603]：

$$
\hat{C} \approx \hat{\sigma}^2 (J^{\top} W J)^{-1}
$$

其中，$\hat{\sigma}^2 = S(\hat{\boldsymbol{\theta}})/(n-p)$ 是残差[方差](@entry_id:200758)的无偏估计（$p$ 是参数个数），而 $J^{\top} W J$ 实际上是**[费雪信息矩阵](@entry_id:750640) (Fisher Information Matrix, FIM)** 的一个近似 [@problem_id:2660615]。[协方差矩阵](@entry_id:139155)的对角[线元](@entry_id:196833)素 $\hat{C}_{jj}$ 提供了参数 $\hat{\theta}_j$ 的[方差估计](@entry_id:268607)，其平方根即为该参数的**标准误 (Standard Error)**，可用于构造基于正态分布假设的[置信区间](@entry_id:142297)。

然而，上述方法依赖于模型在最优解附近的线性近似。对于高度[非线性](@entry_id:637147)的模型，这种近似可能不准确。一种更稳健、不依赖线性近似的方法是**轮廓[似然](@entry_id:167119)法 (Profile Likelihood)** [@problem_id:2660549]。对于我们感兴趣的某个特定参数（例如 $k$），其轮廓[似然函数](@entry_id:141927) $L_p(k)$ 是通过在固定 $k$ 的值时，最大化关于所有其他“无关参数”（Nuisance Parameters，如 $[A]_0$ 和 $\sigma^2$）的完全[似然函数](@entry_id:141927)而得到的。

基于轮廓[似然](@entry_id:167119)，我们可以构造一个**[似然比检验](@entry_id:268070) (Likelihood Ratio Test, LRT)** 统计量：

$$
W(k) = 2 \left( \ell(\hat{\boldsymbol{\theta}}) - \ell_p(k) \right)
$$

其中 $\ell(\hat{\boldsymbol{\theta}})$ 是全局最大对数似然值，$\ell_p(k)$ 是在固定 $k$ 时的轮廓[对数似然](@entry_id:273783)值。根据[Wilks定理](@entry_id:169826)，在原假设成立的条件下，该统计量渐近服从自由度为1的卡方分布 ($\chi^2_1$)。因此，参数 $k$ 的 $(1-\alpha)$ 置信区间就是所有满足 $W(k) \le \chi^2_{1, 1-\alpha}$ 的 $k$ 值的集合，其中 $\chi^2_{1, 1-\alpha}$ 是 $\chi^2_1$ [分布](@entry_id:182848)的 $(1-\alpha)$ 分位数。这种方法生成的[置信区间](@entry_id:142297)能更好地反映模型的[非线性](@entry_id:637147)特性，即使区间不对称也是如此。

#### [模型可辨识性](@entry_id:186414)

在进行参数估计之前，一个根本性的问题是：从给定的实验数据中，我们能否唯一地确定模型的参数？这就是**[可辨识性](@entry_id:194150) (Identifiability)** 问题 [@problem_id:2660589]。

*   **结构[可辨识性](@entry_id:194150) (Structural Identifiability)**：这是一个理论问题，它询问在理想条件下（无噪声、连续观测的完美数据），模型的参数是否能被唯一确定。如果两个不同的参数集能够产生完全相同的模型输出轨迹，那么这些参数就是结构不可辨识的。例如，对于[平行反应](@entry_id:176609) $A \xrightarrow{k_1} P$ 和 $A \xrightarrow{k_2} Q$，如果只观测物种 $A$ 的浓度，其衰减由 $[A](t) = [A]_0 \exp(-(k_1+k_2)t)$ 描述。任何具有相同和值 $k_1+k_2$ 的 $(k_1, k_2)$ 组合都会产生相同的轨迹，因此 $k_1$ 和 $k_2$ 本身是结构不可辨识的，只有它们的和 $k_1+k_2$ 是可辨识的。
*   **[实际可辨识性](@entry_id:190721) (Practical Identifiability)**：这是一个实践问题，它关注在真实、有限且带噪声的数据下，我们能以多大的精度估计参数。即使一个模型是结构可辨识的，如果实验设计不当（例如，采样时间过短或数据噪声过大），也可能导致参数的[置信区间](@entry_id:142297)非常宽，参数之间高度相关，使得参数值实际上无法被精确确定。例如，对于一级衰减，如果只在非常短的时间内 ($t \approx 0$) 采集数据，此时 $[A](t) \approx [A]_0$，模型对速率常数 $k$ 的敏感性极低，导致 $k$ 和 $[A]_0$ 几乎无法区分，这就是[实际不可辨识性](@entry_id:270178)。在数学上，这通常表现为费雪信息矩阵接近奇异（即病态）。

#### 模型充分性 ([残差分析](@entry_id:191495))

拟合完成后，我们需要检查模型是否充分地描述了数据，即模型的假设是否成立。**[残差分析](@entry_id:191495) (Residual Analysis)** 是进行此项检查的关键工具 [@problem_id:2660625]。为了进行有效的比较，我们通常使用**[标准化残差](@entry_id:634169) (Standardized Residuals)**：

$$
z_i = \frac{r_i}{\hat{\sigma}_i} = \frac{y_i - \hat{f}_i}{\hat{\sigma}_i}
$$

其中 $\hat{f}_i$ 是拟合值，$\hat{\sigma}_i$ 是根据[方差](@entry_id:200758)模型估计的第 $i$ 个数据点的标准差。如果均值模型（[动力学方程](@entry_id:751029)）和[方差](@entry_id:200758)模型（权重）都正确，那么[标准化残差](@entry_id:634169)应近似地表现为从[标准正态分布](@entry_id:184509) $\mathcal{N}(0, 1)$ 中抽取的随机样本。

通过绘制[标准化残差](@entry_id:634169)图，我们可以诊断模型的潜在问题：
*   **残差 vs. 时间图** 或 **残差 vs. 拟合值图**：如果[残差图](@entry_id:169585)中出现系统性趋势（如曲线形状），这强烈表明均值模型（即动力学模型）存在**设定误差 (Misspecification)**，例如，选择了错误的[反应级数](@entry_id:142981)或忽略了重要的反应步骤。
*   **残差 vs. 拟合值图**：如果残差的散布程度随拟合值的变化而变化（如呈“喇叭口”形状），这表明[方差](@entry_id:200758)模型设定不当。标准化本应消除[异方差性](@entry_id:136378)，若该现象依然存在，则意味着所用的权重不正确。
*   **残差 vs. 时间图**：如果残差出现连续的正值或负值（即“成串”现象），这表明误差项之间存在**自相关 (Serial Correlation)**，违反了独立性假设。这可能源于未建模的动态过程，如[仪器漂移](@entry_id:202986)或缓慢的混合过程。杜宾-瓦特森 (Durbin-Watson) 检验可以用来定量评估这种相关性。

### [模型选择](@entry_id:155601)

在动力学研究中，我们常常需要比较几个不同的、都看似合理的非[嵌套模型](@entry_id:635829)（例如，一级模型 vs. 米氏-门顿模型）。我们如何客观地选择“最佳”模型？一个好的模型应该在良好拟合数据和保持简洁性（即参数数量少）之间取得平衡，这就是**奥卡姆剃刀 (Occam's razor)** 原则。

[信息准则](@entry_id:636495) (Information Criteria) 为此提供了定量的框架 [@problem_id:2660596]。最常用的准则包括：

*   **[赤池信息准则](@entry_id:139671) (Akaike Information Criterion, AIC)**:
    $$ \mathrm{AIC} = 2k_{\text{eff}} - 2\ln(\hat{L}) $$
*   **[贝叶斯信息准则](@entry_id:142416) (Bayesian Information Criterion, BIC)**:
    $$ \mathrm{BIC} = k_{\text{eff}}\ln(n) - 2\ln(\hat{L}) $$
*   **修正的AIC (Corrected AIC, AICc)**，适用于小样本情况:
    $$ \mathrm{AICc} = \mathrm{AIC} + \frac{2k_{\text{eff}}(k_{\text{eff}}+1)}{n - k_{\text{eff}} - 1} $$

在这些公式中，$-2\ln(\hat{L})$ 是[拟合优度](@entry_id:637026)项（对于高斯噪声模型，它可以直接由[残差平方和](@entry_id:174395)SSE计算得出），$\hat{L}$ 是最大化后的似然函数值。$k_{\text{eff}}$ 是模型的**有效参数数量**，它包括所有从数据中估计的参数（若[方差](@entry_id:200758) $\sigma^2$ 也被估计，则也计入）。$n$ 是样本量。模型选择的原则是，**选择具有最低[信息准则](@entry_id:636495)值的模型**。

AIC和BIC有不同的理论基础 [@problem_id:2660596]。AIC旨在最小化预测模型与真实数据生成过程之间的Kullback-Leibler信息散度，是一种面向预测的准则。BIC源于对模型后验概率的贝叶斯近似，倾向于选择在贝叶斯意义下最可能的模型。由于BIC的惩罚项 $k_{\text{eff}}\ln(n)$ 随样本量 $n$ 增大而增强，它比AIC对复杂模型施加更重的惩罚，因此更倾向于选择更简单的模型。

在使用这些准则时，必须注意：
1.  **有效参数数量**：对于存在参数不可辨识性的模型，其有效参数数量 $k_{\text{eff}}$ 可能小于其名义上的参数数量。一个更严谨的做法是使用雅可比矩阵的秩来确定动力学参数的有效数量 [@problem_id:2660596]。
2.  **相同数据集**：所有[信息准则](@entry_id:636495)的比较必须基于完全相同的实验数据集。如果因为某些原因（如数值计算失败）导致不同模型拟合了不同大小的数据集，那么它们的[似然](@entry_id:167119)值和[信息准则](@entry_id:636495)值是不可直接比较的 [@problem_id:2660596]。

通过本章介绍的原理和方法，研究者可以从实验数据中严谨地估计动力学参数，评估其不确定性，并对模型的有效性进行批判性检验，最终在多个候选机理之间做出有根据的选择。