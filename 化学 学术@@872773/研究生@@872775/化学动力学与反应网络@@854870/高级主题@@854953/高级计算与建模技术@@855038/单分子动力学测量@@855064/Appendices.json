{"hands_on_practices": [{"introduction": "真实的探测器存在固有的局限性，例如“死时间”（dead time），在此期间它们无法记录新的事件。这会导致一种系统性偏差，即寿命较短的事件会被忽略，从而低估真实的速率常数。本练习 [@problem_id:2674069] 将指导你通过推导来量化这种偏差，更重要的是，构建一个统计上严谨的最大似然估计量来校正这种由数据截断效应带来的影响。", "problem": "在一个单分子驻留时间实验中，某个状态的真实驻留时间被建模为一个速率参数为 $k$ 的独立同分布指数随机变量，其概率密度函数为 $f(t \\mid k) = k \\exp(-k t)$，$t \\ge 0$。检测器有一个固定的死时间 $\\tau_{d} > 0$，这意味着任何真实持续时间 $T < \\tau_{d}$ 的事件都完全观测不到，因此不存在于记录的数据集中。对于持续时间 $T \\ge \\tau_{d}$ 的事件，其完整的真实持续时间 $T$ 会被无误差地记录下来。设观测样本为 $\\{t_{i}\\}_{i=1}^{n}$，其中每个 $t_{i} \\ge \\tau_{d}$，该样本来自于 $T$ 在 $T \\ge \\tau_{d}$ 条件下的条件分布。\n\n一位实验者朴素地估计 $k$，他将样本 $\\{t_{i}\\}$ 视为未截断的数据，并使用估计量 $\\hat{k}_{\\text{naive}} = 1/\\bar{t}$，其中 $\\bar{t} = \\frac{1}{n} \\sum_{i=1}^{n} t_{i}$。从条件密度和大数定律的定义出发，并利用独立观测的似然原理：\n\n1. 将朴素估计量的渐近偏差定义为 $\\operatorname{plim}_{n \\to \\infty} \\hat{k}_{\\text{naive}} - k$，并将其推导为 $k$ 和 $\\tau_{d}$ 的显式函数。\n2. 从第一性原理出发，推导在正确的截断指数似然下的最大似然估计量，并以 $\\bar{t}$ 和 $\\tau_{d}$ 的闭合形式表示。\n\n将你的最终答案以一个包含两个条目的单行矩阵形式给出：第一个条目是第1部分的渐近偏差，第二个条目是第2部分的修正后的最大似然估计量。不需要进行数值计算，也不需要四舍五入。只报告解析表达式。", "solution": "该问题要求进行两项与从截断指数分布中估计速率常数 $k$ 相关的推导。\n\n**第1部分：朴素估计量的渐近偏差**\n\n真实驻留时间 $T$ 服从概率密度函数（PDF）为 $f(t \\mid k) = k \\exp(-k t)$（$t \\ge 0$）的指数分布。由于检测器死时间 $\\tau_{d}$ 的存在，只有 $T \\ge \\tau_{d}$ 的事件才被观测到。因此，观测数据 $\\{t_{i}\\}$ 是从 $T$ 在 $T \\ge \\tau_{d}$ 条件下的分布中抽取的。\n\n朴素估计量由 $\\hat{k}_{\\text{naive}} = 1/\\bar{t}$ 给出，其中 $\\bar{t} = \\frac{1}{n} \\sum_{i=1}^{n} t_{i}$。根据大数定律，当 $n \\to \\infty$ 时，样本均值 $\\bar{t}$ 依概率收敛于观测到的随机变量的期望值，即 $\\operatorname{plim}_{n \\to \\infty} \\bar{t} = E[T \\mid T \\ge \\tau_{d}]$。\n\n渐近偏差定义为 $\\operatorname{plim}_{n \\to \\infty} \\hat{k}_{\\text{naive}} - k$。利用概率极限的连续映射定理，我们有：\n$$\n\\operatorname{plim}_{n \\to \\infty} \\hat{k}_{\\text{naive}} = \\frac{1}{\\operatorname{plim}_{n \\to \\infty} \\bar{t}} = \\frac{1}{E[T \\mid T \\ge \\tau_{d}]}\n$$\n因此，渐近偏差为 $\\frac{1}{E[T \\mid T \\ge \\tau_{d}]} - k$。\n\n为了计算条件期望 $E[T \\mid T \\ge \\tau_{d}]$，我们首先需要条件事件的概率：\n$$\nP(T \\ge \\tau_{d}) = \\int_{\\tau_{d}}^{\\infty} f(t \\mid k) \\, dt = \\int_{\\tau_{d}}^{\\infty} k \\exp(-kt) \\, dt = \\left[ -\\exp(-kt) \\right]_{\\tau_{d}}^{\\infty} = \\exp(-k\\tau_{d})\n$$\n对于观测时间 $t \\ge \\tau_{d}$，截断分布的PDF，记为 $g(t)$，是：\n$$\ng(t) = \\frac{f(t \\mid k)}{P(T \\ge \\tau_{d})} = \\frac{k \\exp(-kt)}{\\exp(-k\\tau_{d})} = k \\exp(-k(t - \\tau_{d})), \\quad \\text{for } t \\ge \\tau_{d}\n$$\n现在，我们计算条件期望。由于指数分布的无记忆性，一个已经存活了时间 $\\tau_d$ 的事件，其剩余寿命的期望值等于原始分布的期望值 $1/k$。因此，总的条件期望寿命是 $\\tau_d$ 加上剩余的期望寿命：\n$$\nE[T \\mid T \\ge \\tau_{d}] = \\tau_d + E[T] = \\tau_d + \\frac{1}{k}\n$$\n将此结果代回渐近偏差的表达式中：\n$$\n\\text{Asymptotic Bias} = \\frac{1}{\\frac{1}{k} + \\tau_{d}} - k = \\frac{k}{1 + k\\tau_{d}} - k = k \\left( \\frac{1}{1 + k\\tau_{d}} - 1 \\right) = k \\left( \\frac{1 - (1 + k\\tau_{d})}{1 + k\\tau_{d}} \\right) = -\\frac{k^{2} \\tau_{d}}{1 + k \\tau_{d}}\n$$\n\n**第2部分：最大似然估计量（MLE）**\n\n对于观测到的独立同分布样本 $\\{t_{i}\\}_{i=1}^{n}$，其似然函数 $L(k)$ 是在每个数据点处求值的截断分布PDF的乘积：\n$$\nL(k; \\{t_{i}\\}) = \\prod_{i=1}^{n} g(t_{i}) = \\prod_{i=1}^{n} k \\exp(-k(t_{i} - \\tau_{d}))\n$$\n处理对数似然函数 $\\mathcal{L}(k) = \\ln(L(k))$ 更为方便：\n$$\n\\mathcal{L}(k) = \\ln \\left( \\prod_{i=1}^{n} k \\exp(-k(t_{i} - \\tau_{d})) \\right) = \\sum_{i=1}^{n} \\left[ \\ln(k) - k(t_{i} - \\tau_{d}) \\right]\n$$\n$$\n\\mathcal{L}(k) = n \\ln(k) - k \\sum_{i=1}^{n} (t_{i} - \\tau_{d}) = n \\ln(k) - k(n\\bar{t} - n\\tau_{d}) = n \\ln(k) - nk(\\bar{t} - \\tau_d)\n$$\n为了找到最大似然估计量 $\\hat{k}_{\\text{MLE}}$，我们将 $\\mathcal{L}(k)$ 对 $k$ 求导，并令结果为零：\n$$\n\\frac{d\\mathcal{L}(k)}{dk} = \\frac{n}{k} - n(\\bar{t} - \\tau_{d}) = 0\n$$\n对 $k$ 求解，得到估计量 $\\hat{k}_{\\text{MLE}}$：\n$$\n\\frac{n}{\\hat{k}_{\\text{MLE}}} = n(\\bar{t} - \\tau_{d}) \\implies \\hat{k}_{\\text{MLE}} = \\frac{1}{\\bar{t} - \\tau_{d}}\n$$\n二阶导数为 $\\frac{d^{2}\\mathcal{L}(k)}{dk^{2}} = -\\frac{n}{k^{2}}$，恒为负，证实我们找到了一个最大值。\n\n所求的两个量是渐近偏差 $-\\frac{k^{2} \\tau_{d}}{1 + k \\tau_{d}}$ 和最大似然估计量 $\\frac{1}{\\bar{t} - \\tau_{d}}$。", "answer": "$$\n\\boxed{\\begin{pmatrix} -\\frac{k^{2} \\tau_{d}}{1 + k \\tau_{d}} & \\frac{1}{\\bar{t} - \\tau_{d}} \\end{pmatrix}}\n$$", "id": "2674069"}, {"introduction": "在单分子荧光实验中，观测到的“闪烁”（即荧光信号在亮态和暗态之间的切换）可能源于生物分子自身的构象动力学，也可能仅仅是荧光探针的光物理假象。本练习 [@problem_id:2674086] 旨在挑战你像实验科学家一样思考，学习如何利用激发光功率这一变量，设计出能够明确区分这两种根本不同来源的判决性实验。掌握这种方法对于正确解读单分子轨迹至关重要。", "problem": "您正在一项单分子实验中研究荧光闪烁，该实验观察一个标记的生物分子，其轨迹表现为两种状态：一个发光的亮态 $B$ 和一个不发光的暗态 $X$。您考虑了两种关于暗态来源的机理假设。假设 K（动力学关断态）：$B \\rightleftarrows X$ 是生物分子的构象或结合转变，其有效一级速率常数 $k_{BX}$ 和 $k_{XB}$ 不依赖于激发光强度 $I$。假设 P（光物理暗态）：$X$ 是一个光可及的光物理暗态，从 $B$ 态经由一个单光子驱动的步骤进入，其速率与 $I$ 成正比；并通过一个热激活的步骤离开，该步骤与 $I$ 无关。实验在光漂白在观察时间尺度上可忽略不计、且激发远未达到发光跃迁饱和的条件下进行。\n\n仅使用以下基本原理：(i) 对于一个连续时间马尔可夫双态过程，每个状态的停留时间呈指数分布，其平均值等于该状态总离开速率的倒数；(ii) 对于单光子诱导的跃迁，其速率与激发光强度 $I$ 成正比；(iii) 在稳态下，处于某个状态的时间分数等于进入该状态的速率与进入和离开该状态的速率之和的比率。\n\n您在几个不同的激发光强度 $I$ 下获取了长时间轨迹，并提取了平均亮态时间 $\\langle \\tau_{\\mathrm{on}} \\rangle$（两次暗态偏移之间在 $B$ 态中度过的时间）、平均暗态时间 $\\langle \\tau_{\\mathrm{off}} \\rangle$（两次返回 $B$ 态之间在 $X$ 态中度过的时间）以及稳态暗态分数 $f_{\\mathrm{dark}}$。以下哪个陈述正确解释了如何利用激发功率依赖性来区分动力学关断态和光物理暗态，并提出了一种基于速率随 $I$ 变化的定量诊断方法？选择所有适用项。\n\nA. 在假设 P 下，即进入 $X$ 态是单光子过程且恢复过程与光强无关，$\\langle \\tau_{\\mathrm{on}} \\rangle$ 与 $I^{-1}$ 成比例，而 $\\langle \\tau_{\\mathrm{off}} \\rangle$ 与 $I$ 无关；在假设 K 下，$\\langle \\tau_{\\mathrm{on}} \\rangle$ 和 $\\langle \\tau_{\\mathrm{off}} \\rangle$ 都与 $I$ 无关。一种定量的诊断方法是估计对数-对数斜率 $s_{\\mathrm{on}} = \\mathrm{d}\\ln \\langle \\tau_{\\mathrm{on}} \\rangle / \\mathrm{d}\\ln I$ 和 $s_{\\mathrm{off}} = \\mathrm{d}\\ln \\langle \\tau_{\\mathrm{off}} \\rangle / \\mathrm{d}\\ln I$：如果 $s_{\\mathrm{on}} \\approx -1$ 且 $s_{\\mathrm{off}} \\approx 0$，则诊断为假设 P；如果 $s_{\\mathrm{on}} \\approx 0$ 且 $s_{\\mathrm{off}} \\approx 0$，则诊断为假设 K。\n\nB. 在假设 P 下，$\\langle \\tau_{\\mathrm{off}} \\rangle$ 与 $I^{-1}$ 成比例，而 $\\langle \\tau_{\\mathrm{on}} \\rangle$ 与 $I$ 无关；在假设 K 下，两者都与 $I$ 无关。一种定量的诊断方法是将 $\\ln \\langle \\tau_{\\mathrm{off}} \\rangle$ 对 $\\ln I$ 作图并进行线性拟合，若为假设 P，则预期斜率为 -1。\n\nC. 在假设 P 下，荧光强度的功率谱密度 (PSD) 的角频率应与 $I^{2}$ 成比例，而在假设 K 下与 $I$ 无关。一种定量的诊断方法是计算亮-暗轨迹的 PSD，并将拐点频率拟合为 $I$ 的函数；二次依赖关系表明是假设 P。\n\nD. 一种定量的诊断方法是估计表观亮态速率 $k_{\\mathrm{on,app}} = 1/\\langle \\tau_{\\mathrm{off}} \\rangle$ 并绘制其与 $I$ 的关系图：对于假设 P，由于更多的光子促进了从 $X$ 态的离开， $k_{\\mathrm{on,app}}$ 随 $I$ 线性增加；而对于假设 K，它与 $I$ 无关。\n\nE. 在假设 P 下，即进入 $X$ 态是单光子过程且恢复过程与光强无关，稳态暗态分数遵循 $f_{\\mathrm{dark}}(I) = \\alpha I / (\\alpha I + k_{\\mathrm{rec}})$，其中 $\\alpha$ 和 $k_{\\mathrm{rec}}$ 为常数；而在假设 K 下，$f_{\\mathrm{dark}}$ 与 $I$ 无关。一种定量的诊断方法是在多个 $I$ 值下测量 $f_{\\mathrm{dark}}$，并拟合到一个直角双曲线；一个具有非零 $\\alpha$ 的良好拟合支持假设 P，而一个平坦的依赖关系则支持假设 K。", "solution": "我们根据问题中给出的原理，系统地分析两种假设下可观测量对激发光强度 $I$ 的依赖性。\n\n**假设 K (动力学模型)**\n反应方案为 $B \\underset{k_{XB}}{\\stackrel{k_{BX}}{\\rightleftarrows}} X$。根据假设，速率常数 $k_{BX}$ 和 $k_{XB}$ 均与强度 $I$ 无关。\n1.  **平均亮态时间 ($\\langle \\tau_{\\mathrm{on}} \\rangle$)**: 这是在亮态 $B$ 的平均停留时间。离开 $B$ 的总速率为 $k_{BX}$。根据原理 (i)，$\\langle \\tau_{\\mathrm{on}} \\rangle = 1/k_{BX}$。因此，$\\langle \\tau_{\\mathrm{on}} \\rangle$ 与 $I$ 无关。\n2.  **平均暗态时间 ($\\langle \\tau_{\\mathrm{off}} \\rangle$)**: 这是在暗态 $X$ 的平均停留时间。离开 $X$ 的总速率为 $k_{XB}$。根据原理 (i)，$\\langle \\tau_{\\mathrm{off}} \\rangle = 1/k_{XB}$。因此，$\\langle \\tau_{\\mathrm{off}} \\rangle$ 与 $I$ 无关。\n3.  **稳态暗态分数 ($f_{\\mathrm{dark}}$)**: 根据原理 (iii)，在状态 $X$ 中度过的时间分数为进入该状态的速率与总速率之和的比率：$f_{\\mathrm{dark}} = k_{BX} / (k_{BX} + k_{XB})$。由于两个速率常数都与 $I$ 无关，因此 $f_{\\mathrm{dark}}$ 与 $I$ 无关。\n\n**假设 P (光物理模型)**\n反应方案为 $B \\underset{k_{\\mathrm{rec}}}{\\stackrel{k_{\\mathrm{photo}}(I)}{\\rightleftarrows}} X$。\n- 进入暗态的速率 $B \\to X$ 与强度 $I$ 成正比 (原理 (ii))。我们将其写为 $k_{\\mathrm{photo}}(I) = \\alpha I$，其中 $\\alpha$ 是一个比例常数。\n- 离开暗态的速率 $X \\to B$ 与强度无关。我们将其写为常数 $k_{\\mathrm{rec}}$。\n\n1.  **平均亮态时间 ($\\langle \\tau_{\\mathrm{on}} \\rangle$)**: 离开状态 $B$ 的总速率为 $k_{\\mathrm{photo}}(I) = \\alpha I$。根据原理 (i)，$\\langle \\tau_{\\mathrm{on}} \\rangle = 1/k_{\\mathrm{photo}}(I) = 1/(\\alpha I)$。因此，$\\langle \\tau_{\\mathrm{on}} \\rangle$ 与 $I^{-1}$ 成正比。\n2.  **平均暗态时间 ($\\langle \\tau_{\\mathrm{off}} \\rangle$)**: 离开状态 $X$ 的总速率为 $k_{\\mathrm{rec}}$。根据原理 (i)，$\\langle \\tau_{\\mathrm{off}} \\rangle = 1/k_{\\mathrm{rec}}$。因此，$\\langle \\tau_{\\mathrm{off}} \\rangle$ 与 $I$ 无关。\n3.  **稳态暗态分数 ($f_{\\mathrm{dark}}$)**: 根据原理 (iii)，$f_{\\mathrm{dark}}(I) = k_{\\mathrm{photo}}(I) / (k_{\\mathrm{photo}}(I) + k_{\\mathrm{rec}}) = \\alpha I / (\\alpha I + k_{\\mathrm{rec}})$。这个分数是强度 $I$ 的一个饱和函数（直角双曲线）。\n\n**选项评估**\n\n- **A:** 该选项正确地陈述了：对于假设 P，$\\langle \\tau_{\\mathrm{on}} \\rangle \\propto I^{-1}$ 且 $\\langle \\tau_{\\mathrm{off}} \\rangle$ 恒定；对于假设 K，两者都恒定。这与我们的推导完全一致。它提出的对数-对数斜率诊断方法是正确的：对于假设 P，$\\ln \\langle \\tau_{\\mathrm{on}} \\rangle = -\\ln \\alpha - \\ln I$ 给出斜率 $s_{\\mathrm{on}} = -1$，而 $\\ln \\langle \\tau_{\\mathrm{off}} \\rangle = \\text{const}$ 给出斜率 $s_{\\mathrm{off}} = 0$。对于假设 K，两个寿命都恒定，因此 $s_{\\mathrm{on}} = 0$ 且 $s_{\\mathrm{off}} = 0$。该诊断方法正确。**因此，A是正确的。**\n\n- **B:** 该选项颠倒了亮态时间和暗态时间对光强的依赖关系，称对于假设 P，$\\langle \\tau_{\\mathrm{off}} \\rangle \\propto I^{-1}$。这与我们的推导相矛盾。**因此，B是不正确的。**\n\n- **C:** 该选项讨论功率谱密度 (PSD)。对于双态马尔可夫过程，PSD的拐点角频率对应于弛豫速率 $\\lambda = k_{\\text{forward}} + k_{\\text{reverse}}$。对于假设 K，$\\lambda_K = k_{BX} + k_{XB}$，与 $I$ 无关。对于假设 P，$\\lambda_P = k_{\\mathrm{photo}}(I) + k_{\\mathrm{rec}} = \\alpha I + k_{\\mathrm{rec}}$，与 $I$ 呈线性关系。该选项声称依赖关系是二次的 ($I^2$)，这是不正确的。**因此，C是不正确的。**\n\n- **D:** 该选项将表观亮态速率定义为 $k_{\\mathrm{on,app}} = 1/\\langle \\tau_{\\mathrm{off}} \\rangle$，这实际上是从暗态恢复的速率。对于假设 K，这是 $k_{XB}$ (恒定)。对于假设 P，这是 $k_{\\mathrm{rec}}$ (恒定)。该选项错误地声称对于假设 P，这个速率随 $I$ 线性增加，并给出了一个与问题定义相矛盾的错误物理理由。**因此，D是不正确的。**\n\n- **E:** 该选项正确地描述了稳态暗态分数 $f_{\\mathrm{dark}}$ 的行为：对于假设 P，其形式为 $f_{\\mathrm{dark}}(I) = \\alpha I / (\\alpha I + k_{\\mathrm{rec}})$（一个饱和曲线）；对于假设 K，$f_{\\mathrm{dark}}$ 与 $I$ 无关。这与我们的推导完全一致。提出的通过拟合实验数据来区分这两种依赖关系的诊断方法是有效的。**因此，E是正确的。**", "answer": "$$\\boxed{AE}$$", "id": "2674086"}, {"introduction": "在单分子实验中，我们观测到的信号（如FRET效率或荧光强度）通常是分子真实状态的一个带噪声的表征。隐马尔可夫模型（Hidden Markov Models, HMMs）为从这些含噪数据中推断最可能潜在状态序列提供了一个强大的框架。本编程练习 [@problem_id:2674022] 将引导你从第一性原理出发，构建核心的前向-后向算法，并实现保证其在真实计算中数值稳定性的关键技术。", "problem": "考虑一个用于单分子观测轨迹的离散时间隐马尔可夫模型（HMM），其中一个生物分子在多个隐藏的构象状态之间切换，这些状态构成一个时间齐次的马尔可夫链。在每个时间索引 $t \\in \\{1,\\dots,T\\}$，存在一个隐藏状态 $s_t \\in \\{1,\\dots,K\\}$，其初始分布为 $p(s_1=i)=\\pi_i$，对于所有 $i,j \\in \\{1,\\dots,K\\}$，转移概率为 $p(s_{t}=j \\mid s_{t-1}=i)=A_{ij}$。在时间 $t$ 的观测是一个实值标量 $y_t \\in \\mathbb{R}$，其分布仅依赖于当前的隐藏状态 $s_t$（条件独立）。假设给定 $s_t=i$，观测分布为均值为 $\\mu_i$、标准差为 $\\sigma_i$ 的高斯分布，因此发射概率密度为 $b_i(y_t) = \\mathcal{N}(y_t \\mid \\mu_i,\\sigma_i^2)$。所有模型参数 $(\\boldsymbol{\\pi}, \\mathbf{A}, \\boldsymbol{\\mu}, \\boldsymbol{\\sigma})$ 均已知。\n\n您的任务是从第一性原理构建前向-后向算法，以计算所有 $t \\in \\{1,\\dots,T\\}$ 和所有 $i \\in \\{1,\\dots,K\\}$ 的后验边缘状态概率 $p(s_t=i \\mid y_{1:T})$，并实现两种数值稳定的策略来防止下溢：(1) 使用逐时间点缩放因子的按比例缩放的前向-后向递归，以及 (2) 使用 log-sum-exp 变换的对数域递归。推导必须从基本的概率法则开始，如条件概率的定义、马尔可夫性质和全概率定律，并且不得假设任何关于前向或后向递归的现成公式。\n\n程序要求：\n- 实现对后验概率矩阵 $\\boldsymbol{\\gamma}$ 的两种独立计算，其中 $\\gamma_{i,t} = p(s_t=i \\mid y_{1:T})$：\n  1. 一种按比例缩放的前向-后向方法，该方法通过依赖于时间的正常数因子来缩放前向变量和后向变量，以避免数值下溢，并从这些缩放因子中恢复序列对数似然 $\\log p(y_{1:T})$。\n  2. 一种对数域前向-后向方法，该方法使用 log-sum-exp 恒等式计算相同的后验概率矩阵和相同的序列对数似然。\n- 对于下方的每个测试用例，逐元素计算两个后验概率矩阵之间的最大绝对差，并验证其小于指定的容差 $\\varepsilon = 10^{-8}$。同时，验证对于每个时间索引 $t$，后验概率条目之和在容差 $\\delta = 10^{-12}$ 内为一，即 $\\left|\\sum_{i=1}^K \\gamma_{i,t} - 1\\right| \\le \\delta$。最后，验证两个对数似然值的绝对差在容差 $\\eta = 10^{-8}$ 以内。\n- 对于每个测试用例，返回一个布尔值结果，当且仅当所有三个验证都通过时，该结果为真。\n\n测试套件：\n- 用例 1（具有中等区分度高斯发射的双状态构象切换）：\n  - 状态数 $K = 2$。\n  - 初始分布 $\\boldsymbol{\\pi} = [\\,0.5,\\,0.5\\,]$。\n  - 转移矩阵 $\\mathbf{A} = \\begin{bmatrix} 0.95  0.05 \\\\ 0.04  0.96 \\end{bmatrix}$。\n  - 发射参数 $\\boldsymbol{\\mu} = [\\,0.2,\\,0.8\\,]$，$\\boldsymbol{\\sigma} = [\\,0.05,\\,0.05\\,]$。\n  - 长度为 $T=20$ 的观测序列：$[\\,0.18,\\,0.22,\\,0.19,\\,0.81,\\,0.79,\\,0.82,\\,0.21,\\,0.20,\\,0.78,\\,0.83,\\,0.18,\\,0.17,\\,0.82,\\,0.80,\\,0.22,\\,0.19,\\,0.77,\\,0.84,\\,0.23,\\,0.20\\,]$。\n- 用例 2（具有单个观测的三状态模型，用于测试边界条件）：\n  - 状态数 $K = 3$。\n  - 初始分布 $\\boldsymbol{\\pi} = [\\,0.2,\\,0.5,\\,0.3\\,]$。\n  - 转移矩阵 $\\mathbf{A} = \\begin{bmatrix} 0.90  0.05  0.05 \\\\ 0.10  0.80  0.10 \\\\ 0.05  0.15  0.80 \\end{bmatrix}$。\n  - 发射参数 $\\boldsymbol{\\mu} = [\\,0.1,\\,0.5,\\,0.9\\,]$，$\\boldsymbol{\\sigma} = [\\,0.1,\\,0.05,\\,0.1\\,]$。\n  - 长度为 $T=1$ 的观测序列：$[\\,0.52\\,]$。\n- 用例 3（双状态模型，具有长轨迹且发射远离状态均值，以考验数值稳定性）：\n  - 状态数 $K = 2$。\n  - 初始分布 $\\boldsymbol{\\pi} = [\\,0.5,\\,0.5\\,]$。\n  - 转移矩阵 $\\mathbf{A} = \\begin{bmatrix} 0.995  0.005 \\\\ 0.003  0.997 \\end{bmatrix}$。\n  - 发射参数 $\\boldsymbol{\\mu} = [\\,0.2,\\,0.8\\,]$，$\\boldsymbol{\\sigma} = [\\,0.1,\\,0.1\\,]$。\n  - 长度为 $T=120$ 的观测序列：前 $60$ 个条目等于 $0.45$，后 $60$ 个条目等于 $0.55$，即 $[\\,\\underbrace{0.45,\\,\\dots,\\,0.45}_{60\\ \\text{次}},\\,\\underbrace{0.55,\\,\\dots,\\,0.55}_{60\\ \\text{次}}\\,]$。\n\n数值容差（无量纲）：\n- 后验概率一致性容差 $\\varepsilon = 10^{-8}$。\n- 逐时间点后验概率归一化容差 $\\delta = 10^{-12}$。\n- 对数似然一致性容差 $\\eta = 10^{-8}$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个布尔值列表，对应于按上述顺序排列的三个测试用例，例如 $[\\,\\mathrm{True},\\mathrm{False},\\mathrm{True}\\,]$。该列表必须严格按照方括号内逗号分隔的列表形式打印，每个元素呈现为 Python 布尔字面量。", "solution": "我们的目标是计算后验边缘概率 $\\gamma_t(i) = p(s_t=i \\mid y_{1:T})$。根据条件概率的定义和全概率定律，我们有：\n$$\n\\gamma_t(i) = p(s_t=i \\mid y_{1:T}) = \\frac{p(s_t=i, y_{1:T})}{p(y_{1:T})}\n$$\n分子可以分解为过去和未来的观测：\n$$\np(s_t=i, y_{1:T}) = p(y_{t+1:T} \\mid s_t=i, y_{1:t}) p(s_t=i, y_{1:t})\n$$\n利用HMM的条件独立性，这简化为 $p(s_t=i, y_{1:T}) = p(y_{t+1:T} \\mid s_t=i) p(s_t=i, y_{1:t})$。\n这引出了**前向变量** $\\alpha_t(i) \\triangleq p(s_t=i, y_{1:t})$ 和**后向变量** $\\beta_t(i) \\triangleq p(y_{t+1:T} \\mid s_t=i)$。因此，后验概率为：\n$$\n\\gamma_t(i) = \\frac{\\alpha_t(i) \\beta_t(i)}{\\sum_{j=1}^K \\alpha_t(j) \\beta_t(j)}\n$$\n\n**1. 前向-后向递归**\n\n**前向递归**:\n- 初始化 ($t=1$): $\\alpha_1(i) = \\pi_i b_i(y_1)$\n- 递归 ($t=2, \\dots, T$): $\\alpha_t(i) = b_i(y_t) \\sum_{j=1}^K \\alpha_{t-1}(j) A_{ji}$\n\n**后向递归**:\n- 初始化 ($t=T$): $\\beta_T(i) = 1$\n- 递归 ($t=T-1, \\dots, 1$): $\\beta_t(i) = \\sum_{j=1}^K A_{ij} b_j(y_{t+1}) \\beta_{t+1}(j)$\n\n对于长序列，$ \\alpha_t(i) $ 会指数级减小，导致数值下溢。以下是两种稳定的实现。\n\n**2. 数值稳定策略**\n\n**策略1：缩放的前向-后向算法**\n我们定义缩放后的前向变量 $\\hat{\\alpha}_t(i) = p(s_t=i \\mid y_{1:t})$。这通过在每个时间步引入归一化因子 $c_t = p(y_t \\mid y_{1:t-1})$ 来实现。\n- **前向传递**:\n  1. 初始化 ($t=1$): $\\alpha'_1(i) = \\pi_i b_i(y_1)$。$c_1 = \\sum_j \\alpha'_1(j)$。$\\hat{\\alpha}_1(i) = \\alpha'_1(i) / c_1$。\n  2. 递归 ($t > 1$): $\\alpha'_t(i) = b_i(y_t) \\sum_j \\hat{\\alpha}_{t-1}(j) A_{ji}$。$c_t = \\sum_j \\alpha'_t(j)$。$\\hat{\\alpha}_t(i) = \\alpha'_t(i) / c_t$。\n- **后向传递**: 使用相同的缩放因子 $c_t$ 缩放后向变量 $\\beta_t(i)$。定义 $\\hat{\\beta}_t(i) = \\beta_t(i) / \\prod_{k=t+1}^T c_k$。\n  1. 初始化 ($t=T$): $\\hat{\\beta}_T(i) = 1$。\n  2. 递归 ($t  T$): $\\hat{\\beta}_t(i) = \\frac{1}{c_{t+1}} \\sum_j A_{ij} b_j(y_{t+1}) \\hat{\\beta}_{t+1}(j)$。\n- **后验概率**: $\\gamma_t(i) = \\frac{\\hat{\\alpha}_t(i) \\hat{\\beta}_t(i)}{\\sum_j \\hat{\\alpha}_t(j) \\hat{\\beta}_t(j)}$。\n- **对数似然**: $\\log p(y_{1:T}) = \\sum_{t=1}^T \\log c_t$。\n\n**策略2：对数域的前向-后向算法**\n所有计算都在对数域中进行，以避免下溢。加法使用 log-sum-exp (LSE) 技巧：$\\log(\\sum_i e^{x_i}) = \\max(x_i) + \\log(\\sum_i e^{x_i - \\max(x_i)})$。\n- **对数前向传递**: $\\ln\\alpha_t(i) = \\log \\alpha_t(i)$\n  1. 初始化: $\\ln\\alpha_1(i) = \\log\\pi_i + \\log b_i(y_1)$。\n  2. 递归: $\\ln\\alpha_t(i) = \\log b_i(y_t) + \\underset{j}{\\text{LSE}}(\\ln\\alpha_{t-1}(j) + \\log A_{ji})$。\n- **对数后向传递**: $\\ln\\beta_t(i) = \\log \\beta_t(i)$\n  1. 初始化: $\\ln\\beta_T(i) = 0$。\n  2. 递归: $\\ln\\beta_t(i) = \\underset{j}{\\text{LSE}}(\\log A_{ij} + \\log b_j(y_{t+1}) + \\ln\\beta_{t+1}(j))$。\n- **后验概率**: $\\log \\gamma_t(i) = \\ln\\alpha_t(i) + \\ln\\beta_t(i) - \\underset{j}{\\text{LSE}}(\\ln\\alpha_t(j) + \\ln\\beta_t(j))$。然后取指数得到 $\\gamma_t(i)$。\n- **对数似然**: $\\log p(y_{1:T}) = \\underset{i}{\\text{LSE}}(\\ln\\alpha_T(i))$。\n\n以下是这两种算法的Python实现。\n\n```python\nimport numpy as np\nfrom scipy.special import logsumexp\n\ndef solve():\n    \"\"\"\n    Solves the HMM inference problem for the given test cases using two\n    numerically stable forward-backward algorithm implementations.\n    \"\"\"\n\n    def gaussian_log_pdf(y, mu, sigma):\n        \"\"\"\n        Computes the log of the Gaussian probability density function.\n        More stable than taking log of the pdf.\n        \"\"\"\n        return -np.log(sigma) - 0.5 * np.log(2 * np.pi) - 0.5 * ((y - mu) / sigma) ** 2\n\n    def scaled_forward_backward(pi, A, mu, sigma, y, K, T):\n        \"\"\"\n        Computes posterior state probabilities and log-likelihood using the\n        scaled forward-backward algorithm.\n        \"\"\"\n        # Pre-compute emission probabilities\n        emissions = np.zeros((T, K))\n        for t in range(T):\n            for i in range(K):\n                # We can use log-pdf and exponentiate, it is safer than pdf for tiny values\n                emissions[t, i] = np.exp(gaussian_log_pdf(y[t], mu[i], sigma[i]))\n\n        # Forward pass (scaled)\n        alpha_hat = np.zeros((T, K))\n        c = np.zeros(T)\n\n        alpha_hat_t_unscaled = pi * emissions[0, :]\n        c[0] = np.sum(alpha_hat_t_unscaled)\n        if c[0] == 0: c[0] = 1e-300 # Prevent division by zero\n        alpha_hat[0, :] = alpha_hat_t_unscaled / c[0]\n\n        for t in range(1, T):\n            alpha_hat_t_unscaled = (alpha_hat[t-1, :] @ A) * emissions[t, :]\n            c[t] = np.sum(alpha_hat_t_unscaled)\n            if c[t] == 0: c[t] = 1e-300 # Prevent division by zero\n            alpha_hat[t, :] = alpha_hat_t_unscaled / c[t]\n\n        log_likelihood = np.sum(np.log(c[c>0])) # Avoid log(0) if c was 0\n\n        # Backward pass (scaled)\n        beta_hat = np.zeros((T, K))\n        beta_hat[T-1, :] = 1.0\n\n        for t in range(T - 2, -1, -1):\n            beta_hat[t, :] = (A @ (emissions[t+1, :] * beta_hat[t+1, :])) / c[t+1]\n\n        # Posteriors\n        gamma_unnorm = alpha_hat * beta_hat\n        gamma = gamma_unnorm / np.sum(gamma_unnorm, axis=1, keepdims=True)\n\n        return gamma.T, log_likelihood  # Return as (K, T)\n\n    def log_domain_forward_backward(pi, A, mu, sigma, y, K, T):\n        \"\"\"\n        Computes posterior state probabilities and log-likelihood using the\n        log-domain forward-backward algorithm.\n        \"\"\"\n        log_pi = np.log(pi)\n        log_A = np.log(A)\n\n        log_emissions = np.zeros((T, K))\n        for t in range(T):\n            for i in range(K):\n                log_emissions[t, i] = gaussian_log_pdf(y[t], mu[i], sigma[i])\n\n        # Log-Forward pass\n        log_alpha = np.zeros((T, K))\n        log_alpha[0, :] = log_pi + log_emissions[0, :]\n\n        for t in range(1, T):\n            for j in range(K):\n                log_alpha[t, j] = log_emissions[t, j] + logsumexp(log_alpha[t - 1, :] + log_A[:, j])\n\n        log_likelihood = logsumexp(log_alpha[T - 1, :])\n\n        # Log-Backward pass\n        log_beta = np.zeros((T, K))\n        # log_beta[T-1, :] is already 0.0\n\n        for t in range(T - 2, -1, -1):\n            for i in range(K):\n                log_beta[t, i] = logsumexp(log_A[i, :] + log_emissions[t + 1, :] + log_beta[t + 1, :])\n\n        # Log-Posteriors\n        log_gamma = log_alpha + log_beta\n        log_normalizer = logsumexp(log_gamma, axis=1, keepdims=True)\n        log_gamma = log_gamma - log_normalizer\n        \n        gamma = np.exp(log_gamma)\n\n        return gamma.T, log_likelihood # Return as (K, T)\n\n    test_cases = [\n        {\n            \"K\": 2, \"T\": 20,\n            \"pi\": np.array([0.5, 0.5]),\n            \"A\": np.array([[0.95, 0.05], [0.04, 0.96]]),\n            \"mu\": np.array([0.2, 0.8]), \"sigma\": np.array([0.05, 0.05]),\n            \"y\": np.array([0.18, 0.22, 0.19, 0.81, 0.79, 0.82, 0.21, 0.20, 0.78, 0.83, 0.18, 0.17, 0.82, 0.80, 0.22, 0.19, 0.77, 0.84, 0.23, 0.20]),\n        },\n        {\n            \"K\": 3, \"T\": 1,\n            \"pi\": np.array([0.2, 0.5, 0.3]),\n            \"A\": np.array([[0.90, 0.05, 0.05], [0.10, 0.80, 0.10], [0.05, 0.15, 0.80]]),\n            \"mu\": np.array([0.1, 0.5, 0.9]), \"sigma\": np.array([0.1, 0.05, 0.1]),\n            \"y\": np.array([0.52]),\n        },\n        {\n            \"K\": 2, \"T\": 120,\n            \"pi\": np.array([0.5, 0.5]),\n            \"A\": np.array([[0.995, 0.005], [0.003, 0.997]]),\n            \"mu\": np.array([0.2, 0.8]), \"sigma\": np.array([0.1, 0.1]),\n            \"y\": np.concatenate([np.full(60, 0.45), np.full(60, 0.55)]),\n        }\n    ]\n\n    epsilon = 1e-8\n    delta = 1e-12\n    eta = 1e-8\n\n    results = []\n    \n    for case in test_cases:\n        K, T = case[\"K\"], case[\"T\"]\n        pi, A, mu, sigma, y = case[\"pi\"], case[\"A\"], case[\"mu\"], case[\"sigma\"], case[\"y\"]\n\n        # Suppress warnings for log(0) which is handled correctly as -inf by logsumexp\n        with np.errstate(divide='ignore'):\n            gamma_scaled, ll_scaled = scaled_forward_backward(pi, A, mu, sigma, y, K, T)\n            gamma_log, ll_log = log_domain_forward_backward(pi, A, mu, sigma, y, K, T)\n\n        # 1. Posterior agreement check\n        posterior_diff = np.max(np.abs(gamma_scaled - gamma_log))\n        check1 = posterior_diff  epsilon\n       \n        # 2. Per-time posterior normalization check\n        # We only need to check one result as check1 ensures they are close\n        normalization_diffs = np.abs(np.sum(gamma_log, axis=0) - 1.0)\n        check2 = np.all(normalization_diffs  delta)\n\n        # 3. Log-likelihood agreement check\n        ll_diff = np.abs(ll_scaled - ll_log)\n        check3 = ll_diff  eta\n\n        results.append(check1 and check2 and check3)\n\n    return f\"[{', '.join(str(r) for r in results)}]\"\n\nresult_string = solve()\n```", "answer": "[True, True, True]", "id": "2674022"}]}