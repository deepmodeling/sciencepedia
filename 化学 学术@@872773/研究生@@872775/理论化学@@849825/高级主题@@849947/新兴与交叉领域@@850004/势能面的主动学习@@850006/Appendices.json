{"hands_on_practices": [{"introduction": "为了高效地构建势能面，主动学习策略必须智能地选择信息量最大的新计算点。本练习将深入探讨不确定性驱动选择的核心，使用高斯过程（GP）模型——一种在该领域广受欢迎的工具。你将亲手计算后验方差，这是模型不确定性的直接度量，并理解它如何量化一次新计算所带来的预期信息增益 ([@problem_id:2760116])。", "problem": "在数据高效的势能面（PES）构建中，主动学习器选择新的量子化学计算，以最有效地减少认知不确定性。考虑一个一维反应坐标 $s$，沿着该坐标，在潜能量 $f(s)$ 上设置了一个零均值高斯过程（GP；Gaussian Process）先验，其协方差函数为 $k(s,s') = \\sigma_{f}^{2}\\exp\\!\\big(-\\frac{(s-s')^{2}}{2\\ell^{2}}\\big)$。独立的观测噪声被建模为方差为 $\\sigma_{n}^{2}$ 的高斯分布。您已经在两个构型 $s_{1} = 0$ 和 $s_{2} = 1$ 处进行了电子结构计算（计算所求量不需要具体的能量数值）。您正在考虑一个候选构型 $s_{c} = 0.5$ 用于下一次计算。\n\n假设超参数 $\\sigma_{f}^{2} = 1$（单位为 $(\\mathrm{kJ}\\,\\mathrm{mol}^{-1})^{2}$），$\\ell = 1$（长度单位与 $s$ 相同），以及 $\\sigma_{n}^{2} = 0.01$（单位为 $(\\mathrm{kJ}\\,\\mathrm{mol}^{-1})^{2}$）。仅使用多元高斯条件作用和微分熵的基本性质，计算在给定两个现有输入的情况下，潜能量 $f(s_{c})$ 的后验方差，然后将此量解释为主动学习的单步信息增益代理。具体来说，将在 $s_{c}$ 处查询的预期信息增益视为在当前数据集条件下，新的含噪观测与 $s_{c}$ 处潜能量之间的互信息。\n\n请报告在 $s_{c}$ 处的预期信息增益的数值作为您的最终答案，以奈特（nats）为单位，并四舍五入到四位有效数字。请勿在最终的方框答案中包含单位。", "solution": "该问题已经过验证，被认为是科学上合理的、适定的、客观的，并包含唯一解所需的所有必要信息。所涉及的概念在理论化学的机器学习领域是标准的。因此，我将继续进行解答。\n\n目标是计算在候选构型 $s_c$ 处执行新的量子化学计算所带来的预期信息增益。该增益定义为在现有数据集 $D$ 的条件下，$s_c$ 处预期的含噪观测 $y_c$ 与真实潜能量 $f_c \\equiv f(s_c)$ 之间的互信息。因此，信息增益（记为 $IG$）由下式给出：\n$$\nIG = I(y_c; f_c | D)\n$$\n根据互信息和微分熵 $h(\\cdot)$ 的性质，这可以表示为两种等价形式：\n$$\nI(y_c; f_c | D) = h(f_c | D) - h(f_c | y_c, D) = h(y_c | D) - h(y_c | f_c, D)\n$$\n对于方差为 $\\sigma^2$ 的高斯随机变量 $X$，其微分熵为 $h(X) = \\frac{1}{2}\\ln(2\\pi e \\sigma^2)$。因此，信息增益是方差的函数。\n\n我们使用第二种形式，$h(y_c | D) - h(y_c | f_c, D)$。\n观测模型为 $y_c = f_c + \\epsilon_c$，其中 $\\epsilon_c \\sim \\mathcal{N}(0, \\sigma_n^2)$ 是独立噪声。\n在给定真实潜能量值 $f_c$ 的条件下，观测值 $y_c$ 的分布为 $p(y_c | f_c, D) = p(y_c | f_c) = \\mathcal{N}(y_c | f_c, \\sigma_n^2)$。其方差为 $\\mathrm{Var}(y_c | f_c, D) = \\sigma_n^2$。因此，其熵为：\n$$\nh(y_c | f_c, D) = \\frac{1}{2}\\ln(2\\pi e \\sigma_n^2)\n$$\n接下来，我们考虑仅以现有数据 $D$ 为条件的 $y_c$ 的分布。这就是后验预测分布。以 $D$ 为条件的潜函数值 $f_c$ 是高斯分布的，$p(f_c | D) = \\mathcal{N}(f_c | \\mu_*(s_c), \\sigma^2_*(s_c))$，其中 $\\mu_*(s_c)$ 和 $\\sigma^2_*(s_c)$ 是高斯过程回归的后验均值和后验方差。观测值 $y_c$ 是两个独立高斯变量 $f_c|D$ 和 $\\epsilon_c$ 的和。其和的方差是它们方差的和：\n$$\n\\mathrm{Var}(y_c|D) = \\mathrm{Var}(f_c|D) + \\mathrm{Var}(\\epsilon_c) = \\sigma^2_*(s_c) + \\sigma_n^2\n$$\n$y_c$ 的后验预测分布的熵为：\n$$\nh(y_c|D) = \\frac{1}{2}\\ln\\left(2\\pi e (\\sigma^2_*(s_c) + \\sigma_n^2)\\right)\n$$\n结合这些结果，信息增益为：\n$$\nIG = \\frac{1}{2}\\ln\\left(2\\pi e (\\sigma^2_*(s_c) + \\sigma_n^2)\\right) - \\frac{1}{2}\\ln(2\\pi e \\sigma_n^2) = \\frac{1}{2}\\ln\\left(\\frac{\\sigma^2_*(s_c) + \\sigma_n^2}{\\sigma_n^2}\\right) = \\frac{1}{2}\\ln\\left(1 + \\frac{\\sigma^2_*(s_c)}{\\sigma_n^2}\\right)\n$$\n该结果表明，信息增益仅取决于潜函数的后验方差与观测噪声方差之比。为了计算 $IG$，我们必须首先计算后验方差 $\\sigma^2_*(s_c)$。\n\n给定训练点 $\\mathbf{s} = [s_1, s_2]^T$，高斯过程在测试点 $s_c$ 处的后验方差由以下公式给出：\n$$\n\\sigma^2_*(s_c) = k(s_c, s_c) - \\mathbf{k}_c^T (\\mathbf{K} + \\sigma_n^2 \\mathbf{I})^{-1} \\mathbf{k}_c\n$$\n其中：\n- 协方差函数为 $k(s, s') = \\sigma_{f}^{2}\\exp\\left(-\\frac{(s-s')^{2}}{2\\ell^{2}}\\right)$。\n- 超参数为 $\\sigma_f^2 = 1$，$\\ell = 1$ 和 $\\sigma_n^2 = 0.01$。\n- 训练点为 $s_1=0$，$s_2=1$。候选点为 $s_c=0.5$。\n- $\\mathbf{k}_c$ 是测试点和训练点之间的协方差向量：$\\mathbf{k}_c = [k(s_c, s_1), k(s_c, s_2)]^T$。\n- $\\mathbf{K}$ 是训练点的协方差矩阵：$\\mathbf{K}_{ij} = k(s_i, s_j)$。\n- $\\mathbf{I}$ 是单位矩阵。\n\n根据给定值，核函数简化为 $k(s, s') = \\exp\\left(-\\frac{(s-s')^2}{2}\\right)$。我们计算必要的核函数值：\n$k(s_c, s_c) = k(0.5, 0.5) = \\exp(0) = 1$。\n$k(s_c, s_1) = k(0.5, 0) = \\exp\\left(-\\frac{0.5^2}{2}\\right) = \\exp(-0.125)$。\n$k(s_c, s_2) = k(0.5, 1) = \\exp\\left(-\\frac{(-0.5)^2}{2}\\right) = \\exp(-0.125)$。\n$k(s_1, s_1) = k(0, 0) = 1$。\n$k(s_2, s_2) = k(1, 1) = 1$。\n$k(s_1, s_2) = k(0, 1) = \\exp\\left(-\\frac{(-1)^2}{2}\\right) = \\exp(-0.5)$。\n\n向量 $\\mathbf{k}_c$ 和矩阵 $\\mathbf{K}$ 为：\n$$\n\\mathbf{k}_c = \\begin{pmatrix} \\exp(-0.125) \\\\ \\exp(-0.125) \\end{pmatrix} \\quad , \\quad\n\\mathbf{K} = \\begin{pmatrix} 1 & \\exp(-0.5) \\\\ \\exp(-0.5) & 1 \\end{pmatrix}\n$$\n现在我们构造待求逆的矩阵 $\\mathbf{M} = \\mathbf{K} + \\sigma_n^2 \\mathbf{I}$：\n$$\n\\mathbf{M} = \\begin{pmatrix} 1 + 0.01 & \\exp(-0.5) \\\\ \\exp(-0.5) & 1 + 0.01 \\end{pmatrix} = \\begin{pmatrix} 1.01 & \\exp(-0.5) \\\\ \\exp(-0.5) & 1.01 \\end{pmatrix}\n$$\n由于问题的对称性（$s_c$ 是 $s_1$ 和 $s_2$ 的中点），我们可以简化二次型 $\\mathbf{k}_c^T \\mathbf{M}^{-1} \\mathbf{k}_c$。令 $a = 1.01$，$b = \\exp(-0.5)$，以及 $k_{val} = \\exp(-0.125)$。\n$$\n\\mathbf{M}^{-1} = \\frac{1}{a^2 - b^2}\\begin{pmatrix} a & -b \\\\ -b & a \\end{pmatrix}\n$$\n$$\n\\mathbf{k}_c^T \\mathbf{M}^{-1} \\mathbf{k}_c = \\begin{pmatrix} k_{val} & k_{val} \\end{pmatrix} \\frac{1}{a^2-b^2} \\begin{pmatrix} a & -b \\\\ -b & a \\end{pmatrix} \\begin{pmatrix} k_{val} \\\\ k_{val} \\end{pmatrix} = \\frac{k_{val}^2}{a^2-b^2} \\begin{pmatrix} 1 & 1 \\end{pmatrix} \\begin{pmatrix} a-b \\\\ a-b \\end{pmatrix} = \\frac{2k_{val}^2(a-b)}{a^2-b^2}\n$$\n使用 $a^2-b^2 = (a-b)(a+b)$，上式可简化为：\n$$\n\\mathbf{k}_c^T \\mathbf{M}^{-1} \\mathbf{k}_c = \\frac{2k_{val}^2}{a+b} = \\frac{2(\\exp(-0.125))^2}{1.01 + \\exp(-0.5)} = \\frac{2\\exp(-0.25)}{1.01 + \\exp(-0.5)}\n$$\n现在，我们代入数值：\n$\\exp(-0.25) \\approx 0.77880078$\n$\\exp(-0.5) \\approx 0.60653066$\n$$\n\\mathbf{k}_c^T \\mathbf{M}^{-1} \\mathbf{k}_c \\approx \\frac{2 \\times 0.77880078}{1.01 + 0.60653066} = \\frac{1.55760156}{1.61653066} \\approx 0.96354636\n$$\n那么后验方差为：\n$$\n\\sigma^2_*(s_c) = k(s_c, s_c) - \\mathbf{k}_c^T \\mathbf{M}^{-1} \\mathbf{k}_c \\approx 1 - 0.96354636 = 0.03645364\n$$\n最后，我们计算信息增益，由于使用了自然对数，其单位为奈特（nats）：\n$$\nIG = \\frac{1}{2}\\ln\\left(1 + \\frac{\\sigma^2_*(s_c)}{\\sigma_n^2}\\right) \\approx \\frac{1}{2}\\ln\\left(1 + \\frac{0.03645364}{0.01}\\right) = \\frac{1}{2}\\ln(1 + 3.645364) = \\frac{1}{2}\\ln(4.645364)\n$$\n$$\nIG \\approx \\frac{1}{2} \\times 1.535876 \\approx 0.767938\n$$\n四舍五入到四位有效数字，预期信息增益为 $0.7679$。", "answer": "$$\\boxed{0.7679}$$", "id": "2760116"}, {"introduction": "一个基于不确定性的主动学习策略的成败，完全取决于其不确定性估计的质量。因此，验证模型预测的不确定性是否经过良好校准至关重要，即它是否能准确反映模型的真实误差。本实践编码练习将指导你构建可靠性图（reliability diagrams），这是一种评估模型对原子力的不确定性预测是否校准的标准诊断工具 ([@problem_id:2760108])。", "problem": "您将实现并运行一个完整的程序，该程序通过对预测方差进行分箱，并将经验平方误差与期望值进行比较，来构建力的不certainty校准的可靠性图。\n\n我们考虑一组标量力分量，每个分量都有一个基准真相值、一个模型预测值和一个模型报告的预测方差。每个标量分量以电子伏特每埃（$\\,\\mathrm{eV}\\,\\mathrm{\\AA}^{-1}\\,$）为单位进行测量。预测方差的单位是 $(\\mathrm{eV}\\,\\mathrm{\\AA}^{-1})^2$。\n\n从以下基本原理出发：\n- 对于标量目标 $y$ 的异方差高斯预测模型，该模型返回预测均值 $\\hat{y}$ 和预测方差 $v$。如果预测不确定性经过校准，且残差以零为均值呈条件高斯分布，则 $\\mathbb{E}\\left[(y-\\hat{y})^2 \\mid v\\right] = v$。\n- 方差校准的可靠性图在预测方差的各个分箱中，比较了经验均方误差与平均预测方差。\n\n您必须精确实现以下定义。假设我们有 $M$ 个标量观测值，索引为 $j=1,\\dots,M$，其真实值为 $y_j$（单位 $\\mathrm{eV}\\,\\mathrm{\\AA}^{-1}$），预测值为 $\\hat{y}_j$（单位 $\\mathrm{eV}\\,\\mathrm{\\AA}^{-1}$），预测方差为 $v_j$（单位 $(\\mathrm{eV}\\,\\mathrm{\\AA}^{-1})^2$）。设分箱边界向量为 $\\mathbf{e} = (e_0, e_1, \\dots, e_B)$，且 $e_0  e_1  \\cdots  e_B$。通过半开区间定义 $B$ 个分箱\n- 对于 $b=0,1,\\dots,B-2$，分箱为 $[e_b, e_{b+1})$，以及\n- 对于最后一个分箱，为 $[e_{B-1}, e_B]$，\n因此最后一个分箱是右闭合的，以包含右端点。使用此规则将每个 $v_j$ 精确分配到一个分箱中；如果某个 $v_j$ 在 $[e_0, e_B]$ 之外，则必须将其丢弃（但在本问题中不会出现这种情况）。\n\n对于分箱 $b$，令 $I_b$ 为分配到该分箱的分量的索引集，$n_b = |I_b|$ 为其计数。定义分箱平均预测方差和经验均方误差如下\n$$\n\\bar{v}_b = \\frac{1}{n_b} \\sum_{j \\in I_b} v_j, \\qquad\n\\mathrm{MSE}_b = \\frac{1}{n_b} \\sum_{j \\in I_b} (y_j - \\hat{y}_j)^2,\n$$\n约定在任何求和中都忽略空分箱（$n_b = 0$），并报告其为空。定义每个分箱的校准差距\n$$\ng_b = \\mathrm{MSE}_b - \\bar{v}_b,\n$$\n其单位为 $(\\mathrm{eV}\\,\\mathrm{\\AA}^{-1})^2$。定义两个标量校准度量：\n- 加权期望校准误差 (wECE)：\n$$\n\\mathrm{wECE} = \\sum_{b=0}^{B-1} \\frac{n_b}{M} \\left| g_b \\right|.\n$$\n- 均方根校准误差 (RMSCE)：\n$$\n\\mathrm{RMSCE} = \\sqrt{ \\sum_{b=0}^{B-1} \\frac{n_b}{M} \\, g_b^2 }.\n$$\n$\\mathrm{wECE}$ 和 $\\mathrm{RMSCE}$ 的单位均为 $(\\mathrm{eV}\\,\\mathrm{\\AA}^{-1})^2$。由于 $n_b = 0$，空分箱对总和的贡献为零。\n\n您的程序必须为下面描述的每个测试用例计算这些度量，所有测试用例都是确定性的。残差的生成使用标准正态分位数序列来定义，以避免伪随机性：\n\n- 对于给定的 $N$，定义分位数 $u_j = \\frac{j - 0.5}{N}$，其中 $j = 1, \\dots, N$。\n- 通过以下方式确定性地定义标准正态分数\n$$\ns_j = \\sqrt{2}\\,\\operatorname{erf}^{-1}\\!\\left( 2 u_j - 1 \\right),\n$$\n其中 $\\operatorname{erf}^{-1}$ 是逆误差函数。然后应用确定性置换来去除 $s_j$ 与方差中任何简单模式的相关性：\n$$\n\\pi(j) = \\left( a \\cdot (j-1) + c \\right) \\bmod N + 1,\n$$\n其中 $a$ 和 $N$ 互质，$c$ 是一个固定整数。在以下所有情况中，使用 $(a, c) = (7919, 0)$。置换后的正态分数为 $s_{\\pi(j)}$。对于指定的分量级真实方差 $w_j \\ge 0$，设置\n$$\n\\hat{y}_j = y_j + \\sqrt{w_j}\\; s_{\\pi(j)}.\n$$\n\n使用以下三个测试用例。在所有情况下，基准真相力分量均为 $y_j = 0$，单位为 $\\mathrm{eV}\\,\\mathrm{\\AA}^{-1}$。\n\n- 测试用例 1（近乎完美的校准，连续覆盖）：\n    - 分量数：$N_1 = 6000$。\n    - 预测方差与真实方差相同：对于 $j=1,\\dots,N_1$，\n      $v_j = w_j = v_{\\min} + (v_{\\max} - v_{\\min}) \\cdot \\frac{j - 0.5}{N_1}$\n      其中 $v_{\\min} = 10^{-4}$ 和 $v_{\\max} = 0.4$，单位均为 $(\\mathrm{eV}\\,\\mathrm{\\AA}^{-1})^2$。\n    - 预测均值：$\\hat{y}_j = \\sqrt{w_j}\\; s_{\\pi(j)}$。\n    - 分箱边界：$e_b$ 从 $0.0$ 到 $0.5$ 线性间隔，有 $B_1 = 10$ 个分箱，即 $e_b = 0.05\\, b$ for $b = 0,\\dots,10$。\n\n- 测试用例 2（系统性预测方差过低）：\n    - 分量数：$N_2 = 6000$。\n    - 真实方差线性间隔：$w_j = w_{\\min} + (w_{\\max} - w_{\\min}) \\cdot \\frac{j - 0.5}{N_2}$，其中 $w_{\\min} = 0.01$ 和 $w_{\\max} = 0.3$，单位为 $(\\mathrm{eV}\\,\\mathrm{\\AA}^{-1})^2$。\n    - 预测方差：$v_j = \\gamma \\, w_j$，其中 $\\gamma = 2.0$。\n    - 预测均值：$\\hat{y}_j = \\sqrt{w_j}\\; s_{\\pi(j)}$。\n    - 分箱边界：$e_b$ 从 $0.0$ 到 $0.6$ 线性间隔，有 $B_2 = 6$ 个分箱，即 $e_b = 0.1\\, b$ for $b = 0,\\dots,6$。\n\n- 测试用例 3（零值、极端范围和故意设置的空分箱）：\n    - 分量数：$N_3 = 300$。\n    - 预测方差 $v_j$ 仅取以下值（每个值重复 50 次，按所列顺序）：$0.0$、$10^{-6}$、$5 \\times 10^{-3}$、$5 \\times 10^{-2}$、$2 \\times 10^{-1}$、$1.0$，单位均为 $(\\mathrm{eV}\\,\\mathrm{\\AA}^{-1})^2$。\n    - 真实方差：$w_j = 0.5\\, v_j$。\n    - 预测均值：$\\hat{y}_j = \\sqrt{w_j}\\; s_{\\pi(j)}$。\n    - 分箱边界：$e = \\left[ 0.0, 10^{-9}, 10^{-7}, 10^{-6}, 5\\times 10^{-6}, 5\\times 10^{-5}, 5\\times 10^{-4}, 5\\times 10^{-3}, 5\\times 10^{-2}, 5\\times 10^{-1}, 1.0 \\right]$，因此有 $B_3 = 10$ 个分箱。\n\n对于每个测试用例，您的程序必须：\n1. 使用左闭右开约定 $[e_b, e_{b+1})$（对于 $b=0,\\dots,B-2$）和右闭合的最后一个分箱 $[e_{B-1}, e_{B}]$ 来构建分箱。\n2. 为每个非空分箱计算 $\\bar{v}_b$、$\\mathrm{MSE}_b$ 和 $g_b$。\n3. 计算如上定义的 $\\mathrm{wECE}$ 和 $\\mathrm{RMSCE}$。\n4. 统计空分箱（$n_b = 0$ 的分箱）的数量。\n\n答案规格：\n- 单位：所有力分量 $y_j$ 和 $\\hat{y}_j$ 的单位均为 $\\mathrm{eV}\\,\\mathrm{\\AA}^{-1}$。所有方差，包括 $v_j$、$\\bar{v}_b$、$\\mathrm{MSE}_b$、$\\mathrm{wECE}$ 和 $\\mathrm{RMSCE}$，单位均为 $(\\mathrm{eV}\\,\\mathrm{\\AA}^{-1})^2$。\n- 对于每个测试用例，报告三个值：$\\mathrm{wECE}$、$\\mathrm{RMSCE}$ 和空分箱的数量。\n- 四舍五入：将每个 $\\mathrm{wECE}$ 和 $\\mathrm{RMSCE}$ 值四舍五入到六位小数。空分箱的数量是整数，必须精确报告。\n\n最终输出格式：\n您的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表，顺序如下：\n$[\\mathrm{wECE}_1, \\mathrm{RMSCE}_1, \\text{empty}_1, \\mathrm{wECE}_2, \\mathrm{RMSCE}_2, \\text{empty}_2, \\mathrm{wECE}_3, \\mathrm{RMSCE}_3, \\text{empty}_3]$,\n其中下标表示测试用例索引。两个校准误差值必须按规定四舍五入到六位小数。不允许有其他输出。", "solution": "该问题要求实现一个程序，用于评估原子力的不确定性预测的校准情况。这是理论化学和材料科学领域开发机器学习势函数时的一项常见任务。评估基于可靠性图，该图将模型报告的预测方差与观察到的经验误差进行比较。我们将为三个不同的、确定性生成的测试用例计算两个标准度量：加权期望校准误差（$\\mathrm{wECE}$）和均方根校准误差（$\\mathrm{RMSCE}$）。整个过程将在一个独立的 Python 程序中实现。\n\n所测试的基本原理是异方差模型的校准。对于一个完美的校准模型，其为目标量 $y$ 输出预测均值 $\\hat{y}$ 和方差 $v$，必须满足以下条件：\n$$\n\\mathbb{E}\\left[(y-\\hat{y})^2 \\mid v\\right] = v\n$$\n这表明，以预测方差 $v$ 为条件，期望平方误差应等于 $v$。在实践中，我们通过根据预测方差 $v$ 对数据进行分箱，并将每个分箱内的平均平方误差与平均预测方差进行比较来验证这一点。\n\n该问题指定了一种精确的、确定性的方法来生成合成数据，以避免任何随机性。基准真相力分量 $y_j$ 均设为 $0 \\, \\mathrm{eV}\\,\\mathrm{\\AA}^{-1}$。预测力分量 $\\hat{y}_j$ 是通过向真实值添加噪声生成的。噪声从具有真实方差 $w_j$ 的正态分布中采样。样本本身不是随机的，而是从逆误差函数派生的标准正态分数 $s_j$ 确定性地生成的：\n$$\ns_j = \\sqrt{2}\\,\\operatorname{erf}^{-1}\\!\\left( 2 u_j - 1 \\right) \\quad \\text{其中} \\quad u_j = \\frac{j - 0.5}{N} \\quad \\text{对于} \\quad j = 1, \\dots, N\n$$\n这将生成一组 $N$ 个值的集合，其行为类似于来自标准正态分布 $\\mathcal{N}(0, 1)$ 的样本。为防止因有序生成 $s_j$ 和 $w_j$ 而产生伪相关，使用线性同余生成器对分数进行置换：$\\pi(j) = (a \\cdot (j-1) + c) \\bmod N + 1$。然后将预测均值设置为：\n$$\n\\hat{y}_j = y_j + \\sqrt{w_j}\\; s_{\\pi(j)} = \\sqrt{w_j}\\; s_{\\pi(j)}\n$$\n因此，分量 $j$ 的平方误差为 $(y_j - \\hat{y}_j)^2 = w_j s_{\\pi(j)}^2$。\n\n分析的核心是根据 $M$ 个数据点的预测方差 $v_j$ 将它们划分到 $B$ 个分箱中。分箱边界由向量 $\\mathbf{e} = (e_0, \\dots, e_B)$ 给出。问题强制规定了一种特定的分箱规则：除最后一个分箱 $[e_{B-1}, e_B]$（两端闭合）外，所有分箱都是左闭右开的 $[e_b, e_{b+1})$。这确保了所有预测方差 $v_j \\in [e_0, e_B]$ 的数据点都被分配到一个唯一的分箱中。\n\n对于每个分箱 $b$，我们计算点的数量 $n_b$，平均预测方差 $\\bar{v}_b$，以及均方误差 $\\mathrm{MSE}_b$：\n$$\n\\bar{v}_b = \\frac{1}{n_b} \\sum_{j \\in I_b} v_j, \\qquad\n\\mathrm{MSE}_b = \\frac{1}{n_b} \\sum_{j \\in I_b} (y_j - \\hat{y}_j)^2\n$$\n其中 $I_b$ 是落入分箱 $b$ 的数据点的索引集。每个分箱的校准差距为 $g_b = \\mathrm{MSE}_b - \\bar{v}_b$。对于一个完美校准的模型，我们期望所有分箱的 $g_b \\approx 0$。\n\n最后，我们将这些分箱内的差距汇总成两个标量度量，以量化整体的未校准程度。加权期望校准误差（$\\mathrm{wECE}$）衡量平均绝对差距，并按每个分箱中的点数加权：\n$$\n\\mathrm{wECE} = \\sum_{b=0}^{B-1} \\frac{n_b}{M} \\left| g_b \\right|\n$$\n均方根校准误差（$\\mathrm{RMSCE}$）对任何分箱中的大偏差都很敏感：\n$$\n\\mathrm{RMSCE} = \\sqrt{ \\sum_{b=0}^{B-1} \\frac{n_b}{M} \\, g_b^2 }\n$$\n空分箱（其中 $n_b=0$）对这些总和的贡献为零。\n\n实现将通过依次处理三个测试用例来进行。\n\n对每个用例：\n$1$. 定义总分量数 $N$。基准真相值 $y_j$ 均为零。\n$2$. 生成确定性的标准正态分数 $s_j$ 并应用指定的置换。\n$3$. 根据测试用例的规则构建真实方差 $w_j$ 和预测方差 $v_j$ 的数组。\n$4$. 计算预测均值 $\\hat{y}_j$ 和平方误差 $(\\hat{y}_j)^2$。\n$5$. 将每个数据点 $(v_j, (\\hat{y}_j)^2)$ 分配到预定义的分箱之一。这通过对每个分箱区间应用布尔掩码来识别相应索引来完成。\n$6$. 对每个分箱，计算 $n_b$、$\\bar{v}_b$ 和 $\\mathrm{MSE}_b$，注意处理 $n_b=0$ 的空分箱。\n$7$. 计算校准差距 $g_b$。\n$8$. 使用全套分箱统计数据计算最终度量 $\\mathrm{wECE}$ 和 $\\mathrm{RMSCE}$。\n$9$. 统计空分箱的数量。\n\n对三个测试用例分别执行这些步骤，这三个用例分别设计用于代表近乎完美的校准、系统性的预测方差过低，以及具有空分箱的稀疏方差分布。将每个用例得到的三个值——$\\mathrm{wECE}$、$\\mathrm{RMSCE}$ 和空分箱计数——收集起来并按指定格式输出。所有与方差或平方误差相关的量，包括最终度量，都以 $(\\mathrm{eV}\\,\\mathrm{\\AA}^{-1})^2$ 为单位。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import erfinv\n\ndef solve():\n    \"\"\"\n    Computes reliability diagram metrics for three test cases of uncertainty calibration.\n    \"\"\"\n    results = []\n\n    # --- Test Case 1: Near-perfect calibration ---\n    N1 = 6000\n    B1 = 10\n    bin_edges1 = np.linspace(0.0, 0.5, B1 + 1)\n    \n    # Generate data for Case 1\n    y1 = np.zeros(N1)\n    j1 = np.arange(1, N1 + 1)\n    u1 = (j1 - 0.5) / N1\n    s1 = np.sqrt(2) * erfinv(2 * u1 - 1)\n    \n    a, c = 7919, 0\n    pi1 = (a * (j1 - 1) + c) % N1 + 1\n    s_permuted1 = s1[pi1 - 1]\n    \n    v_min1, v_max1 = 1e-4, 0.4\n    w1 = v_min1 + (v_max1 - v_min1) * (j1 - 0.5) / N1\n    v1 = w1\n    y_hat1 = np.sqrt(w1) * s_permuted1\n    squared_errors1 = (y_hat1 - y1)**2\n    \n    # Binning and statistics for Case 1\n    bin_indices1 = -np.ones(N1, dtype=int)\n    for b in range(B1 - 1):\n        mask = (v1 >= bin_edges1[b])  (v1  bin_edges1[b+1])\n        bin_indices1[mask] = b\n    mask_last_bin = (v1 >= bin_edges1[B1-1])  (v1 = bin_edges1[B1])\n    bin_indices1[mask_last_bin] = B1 - 1\n    \n    n_b1 = np.bincount(bin_indices1, minlength=B1)\n    v_sums1 = np.bincount(bin_indices1, weights=v1, minlength=B1)\n    mse_sums1 = np.bincount(bin_indices1, weights=squared_errors1, minlength=B1)\n    \n    v_bar_b1 = np.zeros(B1)\n    mse_b1 = np.zeros(B1)\n    non_empty_mask1 = n_b1 > 0\n    v_bar_b1[non_empty_mask1] = v_sums1[non_empty_mask1] / n_b1[non_empty_mask1]\n    mse_b1[non_empty_mask1] = mse_sums1[non_empty_mask1] / n_b1[non_empty_mask1]\n    \n    g_b1 = mse_b1 - v_bar_b1\n    \n    wECE1 = np.sum((n_b1 / N1) * np.abs(g_b1))\n    RMSCE1 = np.sqrt(np.sum((n_b1 / N1) * (g_b1**2)))\n    empty_bins1 = B1 - np.count_nonzero(n_b1)\n    \n    results.extend([round(wECE1, 6), round(RMSCE1, 6), empty_bins1])\n\n    # --- Test Case 2: Systematically underconfident ---\n    N2 = 6000\n    B2 = 6\n    bin_edges2 = np.linspace(0.0, 0.6, B2 + 1)\n    \n    # Generate data for Case 2\n    y2 = np.zeros(N2)\n    j2 = np.arange(1, N2 + 1)\n    u2 = (j2 - 0.5) / N2\n    s2 = np.sqrt(2) * erfinv(2 * u2 - 1)\n    \n    pi2 = (a * (j2 - 1) + c) % N2 + 1\n    s_permuted2 = s2[pi2 - 1]\n    \n    w_min2, w_max2 = 0.01, 0.3\n    w2 = w_min2 + (w_max2 - w_min2) * (j2 - 0.5) / N2\n    gamma2 = 2.0\n    v2 = gamma2 * w2\n    y_hat2 = np.sqrt(w2) * s_permuted2\n    squared_errors2 = (y_hat2 - y2)**2\n    \n    # Binning and statistics for Case 2\n    bin_indices2 = -np.ones(N2, dtype=int)\n    for b in range(B2 - 1):\n        mask = (v2 >= bin_edges2[b])  (v2  bin_edges2[b+1])\n        bin_indices2[mask] = b\n    mask_last_bin2 = (v2 >= bin_edges2[B2-1])  (v2 = bin_edges2[B2])\n    bin_indices2[mask_last_bin2] = B2 - 1\n\n    n_b2 = np.bincount(bin_indices2, minlength=B2)\n    v_sums2 = np.bincount(bin_indices2, weights=v2, minlength=B2)\n    mse_sums2 = np.bincount(bin_indices2, weights=squared_errors2, minlength=B2)\n    \n    v_bar_b2 = np.zeros(B2)\n    mse_b2 = np.zeros(B2)\n    non_empty_mask2 = n_b2 > 0\n    v_bar_b2[non_empty_mask2] = v_sums2[non_empty_mask2] / n_b2[non_empty_mask2]\n    mse_b2[non_empty_mask2] = mse_sums2[non_empty_mask2] / n_b2[non_empty_mask2]\n    \n    g_b2 = mse_b2 - v_bar_b2\n    \n    wECE2 = np.sum((n_b2 / N2) * np.abs(g_b2))\n    RMSCE2 = np.sqrt(np.sum((n_b2 / N2) * (g_b2**2)))\n    empty_bins2 = B2 - np.count_nonzero(n_b2)\n    \n    results.extend([round(wECE2, 6), round(RMSCE2, 6), empty_bins2])\n\n    # --- Test Case 3: Zeros, extremes, and empty bins ---\n    N3 = 300\n    B3 = 10\n    bin_edges3 = np.array([0.0, 1e-9, 1e-7, 1e-6, 5e-6, 5e-5, 5e-4, 5e-3, 5e-2, 5e-1, 1.0])\n\n    # Generate data for Case 3\n    y3 = np.zeros(N3)\n    j3 = np.arange(1, N3 + 1)\n    u3 = (j3 - 0.5) / N3\n    s3 = np.sqrt(2) * erfinv(2 * u3 - 1)\n    \n    pi3 = (a * (j3 - 1) + c) % N3 + 1\n    s_permuted3 = s3[pi3 - 1]\n    \n    v_values = [0.0, 1e-6, 5e-3, 5e-2, 2e-1, 1.0]\n    v3 = np.repeat(v_values, 50)\n    w3 = 0.5 * v3\n    y_hat3 = np.sqrt(w3) * s_permuted3\n    squared_errors3 = (y_hat3 - y3)**2\n\n    # Binning and statistics for Case 3\n    bin_indices3 = -np.ones(N3, dtype=int)\n    for b in range(B3 - 1):\n        mask = (v3 >= bin_edges3[b])  (v3  bin_edges3[b+1])\n        bin_indices3[mask] = b\n    mask_last_bin3 = (v3 >= bin_edges3[B3-1])  (v3 = bin_edges3[B3])\n    bin_indices3[mask_last_bin3] = B3 - 1\n\n    n_b3 = np.bincount(bin_indices3, minlength=B3)\n    v_sums3 = np.bincount(bin_indices3, weights=v3, minlength=B3)\n    mse_sums3 = np.bincount(bin_indices3, weights=squared_errors3, minlength=B3)\n    \n    v_bar_b3 = np.zeros(B3)\n    mse_b3 = np.zeros(B3)\n    non_empty_mask3 = n_b3 > 0\n    v_bar_b3[non_empty_mask3] = v_sums3[non_empty_mask3] / n_b3[non_empty_mask3]\n    mse_b3[non_empty_mask3] = mse_sums3[non_empty_mask3] / n_b3[non_empty_mask3]\n    \n    g_b3 = mse_b3 - v_bar_b3\n    \n    wECE3 = np.sum((n_b3 / N3) * np.abs(g_b3))\n    RMSCE3 = np.sqrt(np.sum((n_b3 / N3) * (g_b3**2)))\n    empty_bins3 = B3 - np.count_nonzero(n_b3)\n    \n    results.extend([round(wECE3, 6), round(RMSCE3, 6), empty_bins3])\n\n    # Final print statement\n    formatted_results = []\n    for i in range(len(results)):\n        if (i % 3) != 2:\n            formatted_results.append(f\"{results[i]:.6f}\")\n        else:\n            formatted_results.append(str(results[i]))\n            \n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2760108"}, {"introduction": "在实际应用中，主动学习并非简单地挑选单个最佳点，而是要在有限的时间和资源约束下，选择一整批计算任务并行执行。本练习将这一实际挑战转化为一个规范的优化问题——多重背包问题（Multiple Knapsack Problem），你需要在满足多个处理器壁钟时间（walltime）预算的同时，最大化总信息增益。你将实现一个启发式求解器来找到近似解，从而将在理论上的采集函数与实际的高性能计算工作流之间架起一座桥梁 ([@problem_id:2760084])。", "problem": "考虑一个用于构建势能面（PES）的主动学习循环设计，其中候选分子构型被选中以进行昂贵的从头算（ab initio）标记。每个候选构型（由 $i \\in \\{1,\\dots,N\\}$ 索引）都有一个采集增益估计 $u_i \\ge 0$（无量纲），它反映了预期的信息增益（例如，在高斯过程（GP）模型下后验方差的减少），以及单次标记计算（例如，单点密度泛函理论（DFT）计算）的预测墙上时间 $r_i  0$（单位：秒）。计算环境提供 $W$ 个相同的并行评估器，每个评估器每次迭代有 $\\tau$ 秒的硬性墙上时间预算。仅当 $r_i \\le \\tau$ 时，任务 $i$ 才是可调度的。该迭代必须选择一个任务子集和一种调度方案，以确保没有评估器分配到的任务总时间超过其单次迭代的墙上时间预算，并且每个被选中的任务最多被评估一次。\n\n你的任务是将在并行和墙上时间约束下的批次选择问题形式化为一个离散优化问题，然后实现一个近似求解器。使用以下数学形式化要求：\n\n1. 定义二元分配变量 $y_{im} \\in \\{0,1\\}$，表示任务 $i$ 是否分配给评估器 $m \\in \\{1,\\dots,W\\}$，并定义选择变量 $x_i \\in \\{0,1\\}$，其中 $x_i = \\sum_{m=1}^{W} y_{im}$。施加约束条件：对于每个评估器 $m$，$\\sum_{i=1}^{N} r_i y_{im} \\le \\tau$；对于每个任务 $i$，$\\sum_{m=1}^{W} y_{im} \\le 1$。目标是最大化 $\\sum_{i=1}^{N} u_i x_i$。这是一个多重0-1背包问题（MKP）的变体，通常是计算上难解的（NP-hard）。\n2. 从一个经过充分测试的基础出发，推导出一个有原则的近似策略：首先使用总容量为 $W \\tau$ 且满足单项可行性 $r_i \\le \\tau$ 的单个0-1背包问题松弛，然后使用确定性贪婪调度，在 $W$ 个容量为 $\\tau$ 的箱子中进行装箱可行性步骤。明确论证为什么这种构造是有效的松弛，以及可行性修复如何恢复原始的各评估器约束。\n\n你必须实现一个完整的程序，在给定一个小型实例测试集的情况下，应用以下近似求解器：\n- 在松弛后的容量预算 $W \\tau$ 下，按 $u_i / r_i$ 比率降序进行贪婪预选（跳过任何满足 $r_i  \\tau$ 的任务 $i$）。\n- 尝试使用基于 $r_i$ 的首次适应递减（FFD）算法，将预选出的任务调度到 $W$ 个容量各为 $\\tau$ 的评估器上。\n- 如果调度失败，则迭代地移除当前选定项中 $u_i / r_i$ 比率最小的一项（若比率相同，则移除 $r_i$ 较大的一项），然后重试调度，直到找到一个可行的分配方案。\n- 在获得一个可行的调度方案后，尝试按比率降序贪婪地插入任何剩余的（未选择的）任务，前提是它们能够放入 $W$ 个评估器的剩余容量中且不违反任何约束。\n\n你的程序必须解决以下测试集。对于每个测试用例，返回所选任务的索引（使用从零开始的索引），形式为一个升序排列的整数列表。将所有测试用例的结果汇总到一个列表的列表中。最终输出必须是单行打印的、不含空格的聚合列表。\n\n测试集（所有运行时间单位均为秒；增益为无量纲）：\n- 测试用例 1（顺利情况）：\n  - $u = [9.0, 6.0, 10.0, 12.0, 2.5, 7.5, 4.0]$\n  - $r = [1800, 1200, 2400, 3000, 600, 1500, 900]$\n  - $W = 2$, $\\tau = 3600$\n- 测试用例 2（边界情况，包含精确匹配和一个不可调度的任务）：\n  - $u = [8.0, 7.5, 100.0, 7.0, 0.1]$\n  - $r = [2000, 2000, 2100, 1999, 1]$\n  - $W = 3$, $\\tau = 2000$\n- 测试用例 3（在朴素容量下装箱不可行，需要修复）：\n  - $u = [10.0, 9.9, 3.9, 3.9, 3.9]$\n  - $r = [2500, 2500, 1000, 1000, 1000]$\n  - $W = 2$, $\\tau = 3000$\n- 测试用例 4（单个评估器，含多个小任务和相同的比率）：\n  - $u = [4.0, 3.0, 2.0, 1.0]$\n  - $r = [400, 400, 400, 400]$\n  - $W = 1$, $\\tau = 1000$\n- 测试用例 5（每个评估器的预算为零，导致选择为空）：\n  - $u = [1.0, 2.0]$\n  - $r = [100, 200]$\n  - $W = 5$, $\\tau = 0$\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含一个以逗号分隔的列表的列表，用方括号括起来，且不含空格。例如：`[[0,2],[1],[]]` 表示两个非空选择后跟一个空选择。你的程序必须精确输出：$[\\text{case}_1,\\text{case}_2,\\dots,\\text{case}_5]$，其中每个 $\\text{case}_k$ 是一个整数列表，表示测试用例 $k$ 选中的从零开始的索引，并按升序排列。", "solution": "所提出的问题是一个离散优化任务，与材料科学和化学领域中主动学习的计算资源管理相关。具体来说，它涉及在一组并行的高性能计算资源上选择一批量子化学计算来执行，这是构建势能面时的常见场景。目标是在每个并行评估器的计算时间约束下，最大化所选计算的总预期信息增益。该问题被正确地识别为多重0-1背包问题（MKP）的一个变体，已知是NP-hard问题。因此，对于非平凡的实例，精确解在计算上是不可行的，需要一个精心设计的近似算法。该问题是有效的、有科学依据的，并且是适定的。我们接下来着手推导和实现指定的启发式求解器。\n\n首先，我们将问题形式化。设 $N$ 为候选分子构型的数量。对于每个候选构型 $i \\in \\{1,\\dots,N\\}$，我们给定一个无量纲的信息增益估计 $u_i \\ge 0$ 和一个所需的计算时间 $r_i  0$。我们有 $W$ 个相同的并行评估器，每个评估器每次迭代的最大墙上时间预算为 $\\tau$ 秒。如果一个任务 $i$ 的时间需求超过了评估器的预算，即 $r_i  \\tau$，则该任务从根本上是不可调度的。\n\n为了对选择和分配进行建模，我们引入二元决策变量。设 $y_{im} \\in \\{0,1\\}$ 是一个变量，如果任务 $i$ 分配给评估器 $m \\in \\{1,\\dots,W\\}$，则其值为 $1$，否则为 $0$。设 $x_i \\in \\{0,1\\}$ 是一个变量，如果任务 $i$ 被选中进行计算，则其值为 $1$，否则为 $0$。这些变量通过 $x_i = \\sum_{m=1}^{W} y_{im}$ 相关联。每个任务最多只能评估一次的约束是 $\\sum_{m=1}^{W} y_{im} \\le 1$，这等价于 $x_i \\in \\{0,1\\}$。\n\n目标是最大化总信息增益：\n$$\n\\text{maximize} \\quad Z = \\sum_{i=1}^{N} u_i x_i\n$$\n\n这一最大化过程受两组约束条件的限制：\n$1.$ 分配给任何单个评估器 $m$ 的任务总运行时间不得超过其墙上时间预算 $\\tau$：\n$$\n\\sum_{i=1}^{N} r_i y_{im} \\le \\tau \\quad \\forall m \\in \\{1,\\dots,W\\}\n$$\n$2.$ 每个任务 $i$ 最多只能分配给一个评估器：\n$$\n\\sum_{m=1}^{W} y_{im} \\le 1 \\quad \\forall i \\in \\{1,\\dots,N\\}\n$$\n如前所述，这是多重0-1背包问题。$W$ 个评估器是“背包”，每个容量为 $\\tau$。各项任务具有“重量” $r_i$ 和“价值” $u_i$。\n\n所指定的近似策略是一个有原则的多步启发式方法。它首先将多重背包约束松弛为单个背包约束。原始MKP的任何可行解（由一组分配 $\\{y_{im}\\}$ 定义）都必须满足 $\\sum_{i=1}^{N} r_i x_i = \\sum_{i=1}^{N} r_i \\left(\\sum_{m=1}^{W} y_{im}\\right) = \\sum_{m=1}^{W} \\left(\\sum_{i=1}^{N} r_i y_{im}\\right) \\le \\sum_{m=1}^{W} \\tau = W\\tau$。因此，一个总容量为 $W\\tau$ 的单背包问题是一个有效的松弛，因为它的可行集包含了原始问题的所有可行解。然而，反之则不成立；一组总大小在 $W\\tau$ 容量内的任务，并不能保证可以被划分到 $W$ 个容量各为 $\\tau$ 的背包中。这使得可行性检查和修复程序成为必要。\n\n算法步骤设计如下：\n\n$1$. **贪婪预选：** 我们首先过滤掉任何 $r_i  \\tau$ 的任务，因为它们天生不可调度。然后，我们解决容量为 $W\\tau$ 的松弛单背包问题。我们使用基于效率比（或“价值密度”）$u_i/r_i$ 的标准贪婪策略。将任务按此比率降序排序，然后贪婪地选择它们，直到累积运行时间超过总容量 $W\\tau$。这样就创建了一个高价值密度任务的初始候选集。\n\n$2$. **调度与修复：** 现在必须根据原始、更严格的MKP约束来测试上一步得到的候选集的可行性。这等同于一个装箱问题：能否将选定的任务（大小为 $r_i$）装入 $W$ 个容量为 $\\tau$ 的箱子中？我们使用首次适应递减（FFD）启发式算法。将任务按运行时间 $r_i$ 降序排序，然后依次放入第一个有足够剩余容量的可用评估器（箱子）中。如果FFD未能放置所有任务，则该候选集是不可行的。在这种情况下，我们进入一个修复循环：我们系统地从候选集中移除最“低效”的任务——即 $u_i/r_i$ 比率最低的任务（若比率相同，则移除 $r_i$ 较大的任务）——然后重新尝试FFD调度。重复此过程，直到找到一个可行的调度方案。如果候选集变空，则唯一的可行解是不选择任何任务。\n\n$3$. **贪婪增强：** 一旦建立了一个可行的、已调度的子集，该解可能是次优的，因为修复过程可能移除了有价值的任务。此步骤尝试通过重新引入任何先前未被选择的任务来改进解。我们再次按照 $u_i/r_i$ 比率的降序遍历当前可行集中没有的所有任务。对于每个任务，我们检查它是否可以放入 $W$ 个评估器中任何一个的剩余容量。如果找到可容纳的位置，就将该任务添加到调度中。这个贪婪的局部搜索步骤确保我们不会不必要地丢弃本可以包含的任务。\n\n这种复合算法正确地平衡了最大化价值（通过松弛背包启发式算法）和满足复杂划分约束（通过FFD和修复循环）之间的权衡，为解决此优化问题提供了一种鲁棒且确定性的方法。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to define and run the test suite for the active learning\n    batch selection problem.\n    \"\"\"\n    test_cases = [\n        # Test case 1 (happy path)\n        (\n            [9.0, 6.0, 10.0, 12.0, 2.5, 7.5, 4.0],\n            [1800, 1200, 2400, 3000, 600, 1500, 900],\n            2,\n            3600\n        ),\n        # Test case 2 (boundary with exact fits and an unschedulable item)\n        (\n            [8.0, 7.5, 100.0, 7.0, 0.1],\n            [2000, 2000, 2100, 1999, 1],\n            3,\n            2000\n        ),\n        # Test case 3 (infeasible bin-packing that requires repair)\n        (\n            [10.0, 9.9, 3.9, 3.9, 3.9],\n            [2500, 2500, 1000, 1000, 1000],\n            2,\n            3000\n        ),\n        # Test case 4 (single evaluator with many small items)\n        (\n            [4.0, 3.0, 2.0, 1.0],\n            [400, 400, 400, 400],\n            1,\n            1000\n        ),\n        # Test case 5 (zero per-evaluator budget)\n        (\n            [1.0, 2.0],\n            [100, 200],\n            5,\n            0\n        )\n    ]\n\n    results = []\n    for u, r, W, tau in test_cases:\n        result = solve_instance(np.array(u), np.array(r), W, tau)\n        results.append(result)\n\n    def format_list(lst):\n        return '[' + ','.join(map(str, lst)) + ']'\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(format_list, results))}]\")\n\ndef solve_instance(u, r, W, tau):\n    \"\"\"\n    Implements the specified approximation algorithm for the Multiple Knapsack Problem variant.\n    \n    Args:\n        u (np.ndarray): Array of acquisition gain estimates.\n        r (np.ndarray): Array of predicted walltimes.\n        W (int): Number of parallel evaluators.\n        tau (float): Walltime budget per evaluator.\n\n    Returns:\n        list: A sorted list of zero-based indices of the selected items.\n    \"\"\"\n    N = len(u)\n    items = []\n    for i in range(N):\n        if r[i] > 0:\n            items.append({'u': u[i], 'r': r[i], 'ratio': u[i] / r[i], 'idx': i})\n    \n    # Pre-filter items that can never be scheduled\n    schedulable_items = [item for item in items if item['r'] = tau]\n    \n    if not schedulable_items:\n        return []\n\n    # Sort all schedulable items by ratio descending for preselection and augmentation.\n    # The original index is used as a secondary key for deterministic sorting.\n    schedulable_items.sort(key=lambda x: (-x['ratio'], x['idx']))\n    \n    # Step 1: Greedy Preselection based on the relaxed problem\n    preselected_items = []\n    relaxed_capacity = W * tau\n    current_weight = 0.0\n    for item in schedulable_items:\n        if current_weight + item['r'] = relaxed_capacity:\n            preselected_items.append(item)\n            current_weight += item['r']\n\n    # Step 2  3: Iterative Scheduling and Repair\n    final_selection = []\n    bins_final = []\n    \n    while True:\n        if not preselected_items:\n            final_selection = []\n            bins_final = [tau] * W\n            break\n\n        # Sort current selection by runtime descending for FFD\n        items_to_schedule = sorted(preselected_items, key=lambda x: -x['r'])\n        \n        bins = [tau] * W\n        schedule_possible = True\n        \n        for item in items_to_schedule:\n            placed = False\n            for m in range(W):\n                if item['r'] = bins[m]:\n                    bins[m] -= item['r']\n                    placed = True\n                    break\n            if not placed:\n                schedule_possible = False\n                break\n        \n        if schedule_possible:\n            final_selection = preselected_items\n            bins_final = bins\n            break\n        else:\n            # Repair: remove item with smallest ratio, tie-break by larger r\n            remover_sort_key = lambda x: (x['ratio'], -x['r'])\n            preselected_items.sort(key=remover_sort_key)\n            preselected_items.pop(0)\n\n    # Step 4: Greedy Augmentation\n    if final_selection: # Only augment if a non-empty schedule was found\n        scheduled_indices = {item['idx'] for item in final_selection}\n        # Remaining items are already sorted by descending ratio\n        remaining_items = [item for item in schedulable_items if item['idx'] not in scheduled_indices]\n        \n        for item in remaining_items:\n            for m in range(W):\n                if item['r'] = bins_final[m]:\n                    bins_final[m] -= item['r']\n                    final_selection.append(item)\n                    break \n\n    result_indices = sorted([item['idx'] for item in final_selection])\n    return result_indices\n\n# Execute the solver\nsolve()\n```", "id": "2760084"}]}