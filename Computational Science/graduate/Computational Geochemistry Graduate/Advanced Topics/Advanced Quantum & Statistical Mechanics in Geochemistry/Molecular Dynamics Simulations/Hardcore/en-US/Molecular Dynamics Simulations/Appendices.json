{
    "hands_on_practices": [
        {
            "introduction": "Molecular dynamics simulations of bulk materials rely on periodic boundary conditions (PBC) to eliminate surface artifacts and approximate an infinite system. The cornerstone of PBC is the minimum image convention (MIC), which dictates that the distance between two particles is the shortest possible distance between one particle and all the periodic images of the other. This hands-on exercise challenges you to implement the MIC for an orthorhombic box, a fundamental skill for anyone developing or critically analyzing simulation codes, as it is essential for the correct calculation of forces and energies.",
            "id": "2458300",
            "problem": "You are to write a complete, runnable program that demonstrates the effect of the minimum image convention for periodic boundary conditions in molecular dynamics (MD) simulations. The program must compute the Euclidean distance between two particles in an orthorhombic periodic simulation box in two ways: (1) the naive Euclidean distance that ignores periodicity, and (2) the Euclidean distance after applying the minimum image convention. Distances must be expressed in nanometers (nm) and reported rounded to exactly six decimal places.\n\nBackground and fundamental base: In molecular dynamics (MD) simulations with periodic boundary conditions (PBC), an infinite tiling of the finite simulation box is used to mimic bulk behavior. The physical distance between two particles is interpreted as the minimum distance between one particle and any periodic image of the other. The underlying geometric rule is derived from the definition of Euclidean distance and the translation symmetry of the lattice. For an orthorhombic box with side lengths $L_x$, $L_y$, and $L_z$, the minimum distance is obtained by selecting an integer number of box-length translations along each axis that minimizes the Euclidean norm of the displacement vector. Your program must implement this rule.\n\nYour task:\n- Define a function that, given two $3$-dimensional positions $\\mathbf{r}_i$ and $\\mathbf{r}_j$ in nanometers and box lengths $(L_x,L_y,L_z)$ in nanometers, returns two values:\n  1) the naive Euclidean distance $d_{\\text{naive}} = \\lVert \\mathbf{r}_j - \\mathbf{r}_i \\rVert$ in nm,\n  2) the minimum image convention distance $d_{\\text{mic}}$ in nm, obtained by translating the displacement components by integer multiples of $(L_x,L_y,L_z)$ to minimize the norm.\n- Treat the box as orthorhombic and axis-aligned.\n- Positions may lie outside the primary box interval. Your implementation must still correctly compute $d_{\\text{mic}}$ using periodicity.\n- To make your implementation clear, also include within the program a multi-line pseudocode string (not printed) that outlines the minimum image convention logic you implemented.\n\nNumerical and unit requirements:\n- All distances must be in nanometers (nm).\n- Report distances rounded to exactly $6$ decimal places.\n\nTest suite:\nYour program must compute $[d_{\\text{naive}}, d_{\\text{mic}}]$ for each of the following $5$ test cases, in the stated order.\n\n1) Happy path, small separation well within the box:\n- Box: $(L_x,L_y,L_z) = (\\,3.0\\,\\text{nm},\\,3.0\\,\\text{nm},\\,3.0\\,\\text{nm}\\,)$\n- $\\mathbf{r}_i = (\\,0.5\\,\\text{nm},\\,1.0\\,\\text{nm},\\,1.5\\,\\text{nm}\\,)$\n- $\\mathbf{r}_j = (\\,0.7\\,\\text{nm},\\,1.2\\,\\text{nm},\\,1.6\\,\\text{nm}\\,)$\n\n2) Crossing a periodic boundary along one axis:\n- Box: $(L_x,L_y,L_z) = (\\,3.0\\,\\text{nm},\\,3.0\\,\\text{nm},\\,3.0\\,\\text{nm}\\,)$\n- $\\mathbf{r}_i = (\\,0.1\\,\\text{nm},\\,1.0\\,\\text{nm},\\,1.0\\,\\text{nm}\\,)$\n- $\\mathbf{r}_j = (\\,2.9\\,\\text{nm},\\,1.0\\,\\text{nm},\\,1.0\\,\\text{nm}\\,)$\n\n3) Anisotropic box and wrapping along multiple axes:\n- Box: $(L_x,L_y,L_z) = (\\,2.0\\,\\text{nm},\\,4.0\\,\\text{nm},\\,5.0\\,\\text{nm}\\,)$\n- $\\mathbf{r}_i = (\\,1.9\\,\\text{nm},\\,0.2\\,\\text{nm},\\,4.8\\,\\text{nm}\\,)$\n- $\\mathbf{r}_j = (\\,0.1\\,\\text{nm},\\,3.9\\,\\text{nm},\\,0.3\\,\\text{nm}\\,)$\n\n4) Exactly half-box separation along one axis (tie case):\n- Box: $(L_x,L_y,L_z) = (\\,4.0\\,\\text{nm},\\,4.0\\,\\text{nm},\\,4.0\\,\\text{nm}\\,)$\n- $\\mathbf{r}_i = (\\,0.0\\,\\text{nm},\\,0.0\\,\\text{nm},\\,0.0\\,\\text{nm}\\,)$\n- $\\mathbf{r}_j = (\\,2.0\\,\\text{nm},\\,0.0\\,\\text{nm},\\,0.0\\,\\text{nm}\\,)$\n\n5) Positions outside the primary box interval:\n- Box: $(L_x,L_y,L_z) = (\\,3.0\\,\\text{nm},\\,3.0\\,\\text{nm},\\,3.0\\,\\text{nm}\\,)$\n- $\\mathbf{r}_i = (\\,{-}0.1\\,\\text{nm},\\,{-}0.1\\,\\text{nm},\\,{-}0.1\\,\\text{nm}\\,)$\n- $\\mathbf{r}_j = (\\,3.1\\,\\text{nm},\\,3.1\\,\\text{nm},\\,3.1\\,\\text{nm}\\,)$\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list of pairs enclosed in square brackets. Each pair corresponds to one test case in the specified order and must have the form $[d_{\\text{naive}},d_{\\text{mic}}]$, with both values rounded to exactly $6$ decimal places in nanometers. There must be no spaces in the output.\n- For example, the required overall format is like $[[a_1,b_1],[a_2,b_2],\\dots]$ where each $a_k$ and $b_k$ are floats in nanometers with exactly $6$ decimal places.",
            "solution": "The problem posed is a fundamental exercise in computational statistical mechanics, specifically concerning the implementation of periodic boundary conditions (PBC) in molecular dynamics (MD) simulations. The use of PBC is a standard and necessary technique to approximate the properties of a macroscopic system by simulating a small, finite number of particles. It mitigates the severe surface effects that would otherwise dominate the behavior of a small system. The core of this problem is the correct calculation of inter-particle distances, which is governed by the minimum image convention (MIC).\n\nThe problem is well-posed, scientifically grounded, and provides all necessary data for a unique and verifiable solution. We will proceed with a rigorous derivation and implementation.\n\nLet the orthorhombic simulation box be defined by a set of three orthogonal vectors corresponding to the side lengths, $\\mathbf{L} = (L_x, L_y, L_z)$. The position of two particles, $i$ and $j$, are given by vectors $\\mathbf{r}_i$ and $\\mathbf{r}_j$.\n\nFirst, we define the naive Euclidean distance, $d_{\\text{naive}}$. This is the standard distance in a non-periodic, three-dimensional Euclidean space. It is calculated from the norm of the displacement vector $\\Delta\\mathbf{r} = \\mathbf{r}_j - \\mathbf{r}_i$.\n$$\nd_{\\text{naive}} = \\lVert \\Delta\\mathbf{r} \\rVert = \\sqrt{(\\Delta x)^2 + (\\Delta y)^2 + (\\Delta z)^2}\n$$\nwhere $\\Delta\\mathbf{r} = (\\Delta x, \\Delta y, \\Delta z)$. This calculation ignores the periodic nature of the simulation box and treats the system as if it were isolated in a vacuum.\n\nSecond, we address the minimum image convention distance, $d_{\\text{mic}}$. In a periodic system, the simulation box is replicated infinitely in all directions. A particle at position $\\mathbf{r}$ has an infinite lattice of periodic images at positions $\\mathbf{r} + n_x L_x \\hat{\\mathbf{x}} + n_y L_y \\hat{\\mathbf{y}} + n_z L_z \\hat{\\mathbf{z}}$, where $n_x, n_y, n_z$ are any integers. The physical distance between particle $i$ and particle $j$ is the shortest distance between particle $i$ and *any* of the periodic images of particle $j$.\n\nMathematically, this is expressed as:\n$$\nd_{\\text{mic}} = \\min_{n_x, n_y, n_z \\in \\mathbb{Z}} \\left\\lVert (\\mathbf{r}_j - \\mathbf{r}_i) - (n_x L_x \\hat{\\mathbf{x}} + n_y L_y \\hat{\\mathbf{y}} + n_z L_z \\hat{\\mathbf{z}}) \\right\\rVert\n$$\nFor an orthorhombic box, the minimization of the norm can be performed independently for each Cartesian component. Let us consider the $x$-component of the displacement vector, $\\Delta x = x_j - x_i$. We must find an integer $n_x$ that minimizes $|\\Delta x - n_x L_x|$. This is achieved when $n_x$ is the integer nearest to the ratio $\\Delta x / L_x$. This is the \"nearest integer function,\" often denoted as $\\text{nint}(s)$ or implemented via `round(s)`.\n\nThe MIC-adjusted displacement component, $\\Delta x'$, is therefore:\n$$\n\\Delta x' = \\Delta x - L_x \\cdot \\text{round}\\left(\\frac{\\Delta x}{L_x}\\right)\n$$\nThis formula correctly \"wraps\" the displacement vector component into the interval $[-L_x/2, L_x/2]$. The same logic applies to the $y$ and $z$ components. The complete MIC-adjusted displacement vector, $\\Delta\\mathbf{r}'$, is then:\n$$\n\\Delta\\mathbf{r}' = \\left( \\Delta x - L_x \\cdot \\text{round}\\left(\\frac{\\Delta x}{L_x}\\right), \\Delta y - L_y \\cdot \\text{round}\\left(\\frac{\\Delta y}{L_y}\\right), \\Delta z - L_z \\cdot \\text{round}\\left(\\frac{\\Delta z}{L_z}\\right) \\right)\n$$\nThis vector operation is robust and correctly handles cases where particle coordinates may lie outside the primary simulation box, as only their relative displacement matters.\n\nThe minimum image distance, $d_{\\text{mic}}$, is the Euclidean norm of this adjusted displacement vector:\n$$\nd_{\\text{mic}} = \\lVert \\Delta\\mathbf{r}' \\rVert = \\sqrt{(\\Delta x')^2 + (\\Delta y')^2 + (\\Delta z')^2}\n$$\n\nThe provided test cases will be solved using this established methodology. The implementation will utilize the `numpy` library for efficient vector arithmetic. For each test case, we will compute $d_{\\text{naive}}$ and $d_{\\text{mic}}$ and report the results rounded to precisely $6$ decimal places as specified. The special case of a displacement of exactly half a box length, e.g., $\\Delta x = L_x/2$, is handled by the `round` function, which typically rounds to the nearest even integer (e.g., in `numpy`), but the resulting distance is uniquely $L_x/2$ regardless of the sign choice for the adjusted displacement. For $\\Delta x = L_x/2$, $\\Delta x' = L_x/2 - L_x \\cdot \\text{round}(0.5) = L_x/2 - L_x \\cdot 0 = L_x/2$. The magnitude is unambiguous.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of calculating naive and minimum image convention (MIC)\n    distances for a set of test cases in a molecular dynamics context.\n    \"\"\"\n\n    # Per the problem specification, this multi-line string contains the\n    # pseudocode explaining the implemented MIC logic. It is not printed.\n    # noinspection PyUnusedLocal\n    MIC_PSEUDOCODE = \"\"\"\n    function calculate_minimum_image_distance(r_i, r_j, box_dims):\n        // r_i, r_j: 3D position vectors [x, y, z] of two particles in nm.\n        // box_dims: 3D vector of orthorhombic box lengths [L_x, L_y, L_z] in nm.\n\n        // 1. Calculate the raw displacement vector.\n        //    This is a simple vector subtraction.\n        delta_r = r_j - r_i\n\n        // 2. Apply the minimum image convention to each component of the displacement vector.\n        //    For an orthorhombic box, this can be done independently for each axis.\n        //    The principle is to find the closest periodic image by shifting the displacement\n        //    by an integer number of box lengths. This is mathematically equivalent to\n        //    finding the nearest integer multiple of the box length to subtract.\n        \n        //    Let dr_c be a component of delta_r (e.g., delta_x) and L_c be the\n        //    corresponding box length (e.g., L_x).\n        //    The scaled displacement is s = dr_c / L_c.\n        //    The nearest integer number of box lengths to shift by is n = round(s).\n        //    The MIC-adjusted displacement component is dr'_c = dr_c - n * L_c.\n\n        //    In vector notation, this is:\n        mic_delta_r = delta_r - box_dims * np.round(delta_r / box_dims)\n        \n        // 3. Calculate the Euclidean norm (length) of the MIC-adjusted displacement vector.\n        //    This is the final minimum image distance.\n        distance_mic = sqrt(mic_delta_r[0]^2 + mic_delta_r[1]^2 + mic_delta_r[2]^2)\n        \n        return distance_mic\n    \"\"\"\n\n    def compute_distances(r_i_tuple, r_j_tuple, box_dims_tuple):\n        \"\"\"\n        Calculates naive and MIC distances for a single pair of particles.\n        \n        Args:\n            r_i_tuple (tuple): Position of particle i.\n            r_j_tuple (tuple): Position of particle j.\n            box_dims_tuple (tuple): Orthorhombic box dimensions (Lx, Ly, Lz).\n        \n        Returns:\n            A list containing two floats: [d_naive, d_mic].\n        \"\"\"\n        r_i = np.array(r_i_tuple, dtype=float)\n        r_j = np.array(r_j_tuple, dtype=float)\n        box_dims = np.array(box_dims_tuple, dtype=float)\n\n        # 1. Naive Euclidean distance\n        delta_r_naive = r_j - r_i\n        d_naive = np.linalg.norm(delta_r_naive)\n\n        # 2. Minimum Image Convention (MIC) distance\n        # The logic delta_r - L * round(delta_r / L) correctly finds the\n        # shortest vector in a periodic lattice.\n        delta_r_mic = delta_r_naive - box_dims * np.round(delta_r_naive / box_dims)\n        d_mic = np.linalg.norm(delta_r_mic)\n        \n        return [d_naive, d_mic]\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # 1) Happy path, small separation\n        {'r_i': (0.5, 1.0, 1.5), 'r_j': (0.7, 1.2, 1.6), 'box': (3.0, 3.0, 3.0)},\n        # 2) Crossing a periodic boundary\n        {'r_i': (0.1, 1.0, 1.0), 'r_j': (2.9, 1.0, 1.0), 'box': (3.0, 3.0, 3.0)},\n        # 3) Anisotropic box and multi-axis wrapping\n        {'r_i': (1.9, 0.2, 4.8), 'r_j': (0.1, 3.9, 0.3), 'box': (2.0, 4.0, 5.0)},\n        # 4) Exactly half-box separation\n        {'r_i': (0.0, 0.0, 0.0), 'r_j': (2.0, 0.0, 0.0), 'box': (4.0, 4.0, 4.0)},\n        # 5) Positions outside the primary box\n        {'r_i': (-0.1, -0.1, -0.1), 'r_j': (3.1, 3.1, 3.1), 'box': (3.0, 3.0, 3.0)},\n    ]\n\n    result_strings = []\n    for case in test_cases:\n        d_naive, d_mic = compute_distances(case['r_i'], case['r_j'], case['box'])\n        \n        # Format the numbers to exactly 6 decimal places and create the pair string.\n        # This ensures trailing zeros are included and meets the formatting requirement.\n        result_strings.append(f\"[{d_naive:.6f},{d_mic:.6f}]\")\n\n    # Final print statement in the exact required format: [[a1,b1],[a2,b2],...]\n    # without spaces between elements.\n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A crucial parameter in any molecular dynamics simulation is the integration time step, $dt$. While a larger $dt$ allows for longer simulation timescales, it can also introduce numerical instabilities that render the trajectory meaningless. This practice explores the stability limit of the widely used Velocity-Verlet algorithm by simulating a simple harmonic oscillator, which serves as an analog for the fastest vibrational modes in a real molecular system. By systematically increasing $dt$ and monitoring the total energy, you will gain a practical understanding of why simulations can \"explode\" and how to choose a time step that balances computational efficiency with physical accuracy.",
            "id": "2458247",
            "problem": "You are asked to implement a self-contained computational experiment, grounded in first principles, to study the time-step stability of a single one-dimensional harmonic mode that represents a stiff normal mode in a protein in Molecular Dynamics (MD). The system is a particle of mass $m$ confined to a harmonic potential with force constant $k$, evolving under Newton’s second law. Use reduced, dimensionless units throughout; do not attach physical units to any quantity.\n\nThe dynamics are defined by Newton’s second law, $m \\,\\ddot{x}(t) = - k \\, x(t)$, with initial conditions $x(0) = x_0$ and $\\dot{x}(0) = v_0$. The total energy is $E(t) = \\tfrac{1}{2} m \\,\\dot{x}(t)^2 + \\tfrac{1}{2} k \\, x(t)^2$. For a given discrete time step $dt$, simulate the motion for a total simulation time $T$ and monitor $E(t)$ during the trajectory.\n\nDefine an “explosion” for a chosen $dt$ to have occurred if any one of the following three events happens at any simulation step:\n- The computed total energy $E(t)$ becomes not finite (that is, not a real, finite number).\n- The relative energy error exceeds a specified tolerance, that is, $\\lvert E(t) - E(0) \\rvert / E(0) > \\varepsilon$ for any time $t$ up to the end of the simulation.\n- The magnitude of the position exceeds a prescribed bound derived from the initial energy, that is, $\\lvert x(t) \\rvert > B \\, A_0$ for any $t$, where $A_0 = \\sqrt{2 E(0)/k}$.\n\nFor each test case below, you are given the parameter set $(m, k, x_0, v_0, T, \\varepsilon, B)$ and an ordered list of time steps $[dt_1, dt_2, \\dots, dt_n]$. For each test case, simulate the system separately for each $dt_i$ in the given order and identify the smallest $dt_i$ in the list that leads to an explosion by the above definition. If none of the listed $dt_i$ leads to an explosion, return the sentinel value $-1.0$.\n\nUse the following four test cases. All symbols and numbers below are to be interpreted in reduced, dimensionless units.\n\nTest Case 1:\n- Parameters: $m = 1.0$, $k = 1.0$, $x_0 = 1.0$, $v_0 = 1.0$, $T = 100.0$, $\\varepsilon = 0.20$, $B = 100.0$.\n- Time steps to test (in ascending order): $[0.1, 0.5, 1.5, 1.9, 2.0, 2.1]$.\n\nTest Case 2:\n- Parameters: $m = 1.0$, $k = 16.0$, $x_0 = 1.0$, $v_0 = 1.0$, $T = 20.0$, $\\varepsilon = 0.10$, $B = 100.0$.\n- Time steps to test (in ascending order): $[0.05, 0.10, 0.30, 0.49, 0.50, 0.51]$.\n\nTest Case 3:\n- Parameters: $m = 2.0$, $k = 0.5$, $x_0 = 1.0$, $v_0 = 1.0$, $T = 50.0$, $\\varepsilon = 0.05$, $B = 1000.0$.\n- Time steps to test (in ascending order): $[0.50, 1.00, 2.00, 3.00, 3.50]$.\n\nTest Case 4:\n- Parameters: $m = 1.0$, $k = 100.0$, $x_0 = 1.0$, $v_0 = 1.0$, $T = 8.0$, $\\varepsilon = 0.15$, $B = 100.0$.\n- Time steps to test (in ascending order): $[0.02, 0.10, 0.19, 0.20, 0.25]$.\n\nYour program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each result must be a floating-point number rounded to six decimal places, in the same order as the test cases above. For example, if the results for the four test cases are $r_1$, $r_2$, $r_3$, and $r_4$, your program must print exactly\n\"[r1,r2,r3,r4]\"\nwith each $r_i$ formatted to six decimal places and no additional text.\n\nAngle quantities, if any arise internally, must be treated in radians. All values in this problem are dimensionless by construction, so no physical units are to be displayed in the output.",
            "solution": "The problem requires a computational experiment to determine the stability limit of a numerical integration scheme for a one-dimensional harmonic oscillator, which serves as a model for a stiff vibrational mode in a molecular dynamics (MD) simulation. The problem is well-posed and scientifically grounded. It constitutes a direct test of numerical integration stability, a fundamental concept in computational science.\n\nThe system is described by the equation of motion for a simple harmonic oscillator:\n$$\nm \\frac{d^2x}{dt^2} = -k x(t)\n$$\nwhere $m$ is the mass, $k$ is the force constant, and $x(t)$ is the position. The angular frequency of this oscillator is $\\omega = \\sqrt{k/m}$. The dynamics are to be propagated from initial conditions $x(0) = x_0$ and $\\dot{x}(0) = v_0$ using a discrete time step $dt$.\n\nThe problem statement does not specify the numerical integration algorithm. For MD simulations of Newtonian mechanics, the Velocity-Verlet algorithm is a standard, widely-used, and robust choice due to its time-reversibility and symplectic nature, which leads to good long-term energy conservation properties. Therefore, the Velocity-Verlet integrator is the appropriate algorithm to implement.\n\nThe Velocity-Verlet algorithm consists of the following steps to advance the system from time $t$ to $t+dt$:\n1.  Compute the half-step velocity:\n    $$\n    v(t + \\tfrac{1}{2}dt) = v(t) + \\tfrac{1}{2} a(t) dt\n    $$\n2.  Update the position to the full new time step:\n    $$\n    x(t + dt) = x(t) + v(t + \\tfrac{1}{2}dt) dt\n    $$\n3.  Compute the acceleration at the new position. The acceleration is derived from the force $F(x) = -kx$, so $a(x) = F(x)/m = -(k/m)x$:\n    $$\n    a(t + dt) = -\\frac{k}{m} x(t + dt)\n    $$\n4.  Compute the full-step velocity at the new time:\n    $$\n    v(t + dt) = v(t + \\tfrac{1}{2}dt) + \\tfrac{1}{2} a(t + dt) dt\n    $$\n\nFor each test case, we are given a set of parameters $(m, k, x_0, v_0, T, \\varepsilon, B)$ and an ordered list of time steps $[dt_1, dt_2, \\dots]$. The task is to find the smallest $dt_i$ from this list for which the simulation becomes unstable or \"explodes.\" The simulation for a given $dt$ runs for a total time $T$, which corresponds to $N_{steps} = \\lfloor T/dt \\rfloor$ integration steps.\n\nBefore the simulation loop begins, we must establish the baseline for the explosion criteria. The initial total energy $E(0)$ is calculated as:\n$$\nE(0) = \\frac{1}{2} m v_0^2 + \\frac{1}{2} k x_0^2\n$$\nThe problem states that for all test cases, $x_0$, $v_0$, $m$, and $k$ are positive, ensuring $E(0) > 0$. The characteristic amplitude $A_0$ is then defined as:\n$$\nA_0 = \\sqrt{\\frac{2 E(0)}{k}}\n$$\nThis $A_0$ represents the maximum displacement in the exact analytical solution.\n\nThe simulation proceeds by iterating the Velocity-Verlet algorithm for $N_{steps}$ times. After each step, we obtain the new state $(x(t+dt), v(t+dt))$ and check for the three explosion conditions:\n1.  **Finiteness of Energy**: The total energy at the new step, $E(t+dt) = \\frac{1}{2} m v(t+dt)^2 + \\frac{1}{2} k x(t+dt)^2$, must be a finite real number. Computationally, this is checked by verifying if the value is not `NaN` (Not a Number) or infinite. This condition detects catastrophic numerical overflow.\n2.  **Relative Energy Conservation**: The relative deviation of the current energy from the initial energy must not exceed a tolerance $\\varepsilon$.\n    $$\n    \\frac{\\lvert E(t+dt) - E(0) \\rvert}{E(0)} > \\varepsilon\n    $$\n    This condition detects when the numerical integration error leads to a significant, unphysical drift in the total energy, even if the trajectory has not yet diverged to infinity.\n3.  **Position Bound**: The magnitude of the position must not exceed a large multiple of the characteristic amplitude.\n    $$\n    \\lvert x(t+dt) \\rvert > B \\cdot A_0\n    $$\n    This is another practical check for trajectory divergence, where the particle escapes to unphysically large distances from the potential minimum.\n\nThe overall procedure for each test case is as follows:\nIterate through the provided list of time steps $dt_i$, which are sorted in ascending order. For each $dt_i$:\n- Run a full simulation for time $T$.\n- At every step of the simulation, check the three explosion conditions.\n- If any condition is met at any point during the simulation, the simulation for this $dt_i$ is deemed unstable. This $dt_i$ is the result for the test case, and we proceed to the next test case.\n- If the simulation completes for $T$ without any explosion, this $dt_i$ is considered stable. We then proceed to test the next $dt_i$ in the list.\n\nIf all time steps in the list for a given test case result in stable simulations, the result for that test case is the sentinel value $-1.0$.\n\nThe implementation will consist of a primary function that iterates through the test cases. This function will call a sub-function for each test case, which in turn iterates through the provided $dt$ values and calls a simulation function. The simulation function implements the Velocity-Verlet loop and the stability checks described above. The final output is a list of the smallest exploding $dt$ for each case, or $-1.0$ if none are found.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_simulation(m, k, x0, v0, T, epsilon, B, dt) -> bool:\n    \"\"\"\n    Runs a simulation of a 1D harmonic oscillator using the Velocity-Verlet algorithm.\n\n    Args:\n        m (float): Mass.\n        k (float): Force constant.\n        x0 (float): Initial position.\n        v0 (float): Initial velocity.\n        T (float): Total simulation time.\n        epsilon (float): Relative energy error tolerance.\n        B (float): Position bound factor.\n        dt (float): Time step.\n\n    Returns:\n        bool: True if an explosion occurs, False otherwise.\n    \"\"\"\n    if dt <= 0:\n        return False  # A time step of zero or less is not meaningful.\n\n    num_steps = int(T / dt)\n    \n    # Initial conditions\n    x = float(x0)\n    v = float(v0)\n    \n    # Calculate initial energy and derived bounds for explosion criteria\n    e0 = 0.5 * m * v**2 + 0.5 * k * x**2\n    \n    # The problem constraints ensure e0 > 0, so no division by zero.\n    a0 = np.sqrt(2 * e0 / k)\n    x_bound = B * a0\n\n    # Initial acceleration\n    a = -(k / m) * x\n    \n    # Main simulation loop\n    for _ in range(num_steps):\n        # Velocity-Verlet integrator\n        # v(t + dt/2)\n        v_half = v + 0.5 * a * dt\n        # x(t + dt)\n        x = x + v_half * dt\n        # a(t + dt)\n        a_new = -(k / m) * x\n        # v(t + dt)\n        v = v_half + 0.5 * a_new * dt\n        \n        # Update acceleration for the next step\n        a = a_new\n        \n        # Calculate current energy at the full step\n        e_current = 0.5 * m * v**2 + 0.5 * k * x**2\n        \n        # --- Check for explosion conditions ---\n        \n        # 1. Non-finite energy (numerical overflow)\n        if not np.isfinite(e_current):\n            return True  # Explosion\n            \n        # 2. Relative energy error exceeds tolerance\n        # In the case e0 is 0, any change would be an infinite relative error.\n        # But for the given test cases, e0 is always positive.\n        if abs(e_current - e0) / e0 > epsilon:\n            return True  # Explosion\n        \n        # 3. Position exceeds bound\n        if abs(x) > x_bound:\n            return True  # Explosion\n            \n    return False  # No explosion occurred\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = [\n        {\n            'params': (1.0, 1.0, 1.0, 1.0, 100.0, 0.20, 100.0),\n            'dts': [0.1, 0.5, 1.5, 1.9, 2.0, 2.1],\n        },\n        {\n            'params': (1.0, 16.0, 1.0, 1.0, 20.0, 0.10, 100.0),\n            'dts': [0.05, 0.10, 0.30, 0.49, 0.50, 0.51],\n        },\n        {\n            'params': (2.0, 0.5, 1.0, 1.0, 50.0, 0.05, 1000.0),\n            'dts': [0.50, 1.00, 2.00, 3.00, 3.50],\n        },\n        {\n            'params': (1.0, 100.0, 1.0, 1.0, 8.0, 0.15, 100.0),\n            'dts': [0.02, 0.10, 0.19, 0.20, 0.25],\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        m, k, x0, v0, T, epsilon, B = case['params']\n        dts = case['dts']\n        \n        explosion_dt = -1.0\n        # The 'dts' lists are sorted, so we find the smallest by breaking on the first hit.\n        for dt in dts:\n            if run_simulation(m, k, x0, v0, T, epsilon, B, dt):\n                explosion_dt = dt\n                break\n        \n        results.append(f\"{explosion_dt:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Many geochemical processes, from mineral dissolution to ion transport, involve rare events that are difficult to capture with standard MD simulations. Enhanced sampling methods like umbrella sampling are designed to overcome this challenge by driving a system along a specific reaction coordinate, $z$, using artificial biasing potentials. This advanced practice guides you through a complete workflow to calculate the Potential of Mean Force (PMF), $W(z)$, for a model process. You will first generate biased data and then use the powerful Weighted Histogram Analysis Method (WHAM) to combine these data and reconstruct the true underlying free energy landscape, a vital skill for quantitative studies of reaction mechanisms and kinetics.",
            "id": "2458249",
            "problem": "You will model the reversible pulling of a single amino acid side chain along the axis of a hydrophobic carbon nanotube as a one-dimensional reaction coordinate $z$ (in $\\mathrm{nm}$), with $z=0$ at the nanotube center and $z$ increasing along its axis. The goal is to recover the potential of mean force (PMF), denoted $W(z)$ (in $\\mathrm{kJ/mol}$), from biased sampling data obtained under harmonic umbrella potentials. Work entirely within a one-dimensional, classical canonical ensemble at absolute temperature $T$ (in $\\mathrm{K}$), and restrict the coordinate to a uniform grid $z \\in [z_{\\min}, z_{\\max}]$ with spacing $\\Delta z$ (both in $\\mathrm{nm}$).\n\nDefinitions:\n\n- The PMF $W(z)$ is defined up to an additive constant by the canonical probability density $P(z)$ via\n$$\nW(z) = -k_\\mathrm{B} T \\ln P(z) + C,\n$$\nwhere $k_\\mathrm{B}$ is the Boltzmann constant, and $C$ is an arbitrary constant. When expressing energies per mole, use the gas constant $R$ in place of $k_\\mathrm{B}$, with $R = 8.314462618 \\,\\mathrm{J\\,mol^{-1}\\,K^{-1}}$; you must carry energies in $\\mathrm{kJ/mol}$ consistently and use $\\beta = \\frac{1}{R_\\mathrm{kJ}T}$ with $R_\\mathrm{kJ} = R/1000$ in $\\mathrm{kJ\\,mol^{-1}\\,K^{-1}}$.\n\n- In umbrella sampling window $i$, the additional harmonic bias potential is\n$$\nU_i(z) = \\tfrac{1}{2} k_i \\left(z - z_i\\right)^2,\n$$\nwith force constant $k_i$ (in $\\mathrm{kJ\\,mol^{-1}\\,nm^{-2}}$) and center $z_i$ (in $\\mathrm{nm}$). The biased equilibrium distribution in window $i$ is proportional to $\\exp\\!\\left[-\\beta (W(z) + U_i(z))\\right]$.\n\nIn this exercise, the intrinsic PMF representing the amino acid–nanotube interaction is modeled by the smooth barrier\n$$\nW^\\ast(z) = H \\exp\\!\\left(-\\frac{z^2}{\\sigma^2}\\right),\n$$\nwith barrier amplitude $H$ (in $\\mathrm{kJ/mol}$) and width parameter $\\sigma$ (in $\\mathrm{nm}$). This $W^\\ast(z)$ serves to generate biased histograms, but when reconstructing the PMF from the biased data you must use only the histograms and known biases according to the canonical definitions above. The uniform $z$-grid and histogram construction are defined as follows.\n\n- Grid: $z_{\\min} = -1.0 \\,\\mathrm{nm}$, $z_{\\max} = +1.0 \\,\\mathrm{nm}$, $\\Delta z = 0.02 \\,\\mathrm{nm}$. Let the grid points be $z_j = z_{\\min} + j \\,\\Delta z$ for integer $j$ over the range so that $z_{\\max}$ is included.\n\n- In each window $i$, the biased probability density is proportional to $\\exp\\!\\left[-\\beta \\left(W^\\ast(z_j) + U_i(z_j)\\right)\\right]$. The histogram count in bin $j$ for window $i$ is\n$$\nn_i(z_j) = \\mathrm{round}\\!\\left(N_i \\, \\pi_i(z_j)\\, \\Delta z\\right),\n$$\nwhere $N_i$ is the total number of sampled configurations in window $i$, $\\pi_i(z_j)$ is the normalized discrete biased probability satisfying $\\sum_j \\pi_i(z_j)\\,\\Delta z = 1$, and $\\mathrm{round}(\\cdot)$ denotes rounding to the nearest integer.\n\nYour task: For each test case specified below, construct the biased histograms $\\{n_i(z_j)\\}$ from $W^\\ast(z)$ and the provided umbrella parameters, and then, using only $\\{n_i(z_j)\\}$, the known $U_i(z_j)$, and the canonical definitions above, reconstruct the unbiased discrete probability $P(z_j)$ and the PMF $W(z_j)$ up to an additive constant. Finally, report the PMF barrier height\n$$\n\\Delta W = \\max_j W(z_j) - \\min_j W(z_j)\n$$\nin $\\mathrm{kJ/mol}$. Express the final $\\Delta W$ values rounded to three decimal places.\n\nTest suite (four independent cases). Each case defines temperature $T$ (in $\\mathrm{K}$), barrier parameters $H$ (in $\\mathrm{kJ/mol}$) and $\\sigma$ (in $\\mathrm{nm}$), a set of umbrella windows defined by centers $z_i$ (in $\\mathrm{nm}$) and a common harmonic force constant $k_i \\equiv k$ (in $\\mathrm{kJ\\,mol^{-1}\\,nm^{-2}}$), and an equal number of samples per window $N_i \\equiv N$:\n\n- Case A (happy path):\n  - $T = 300$, $H = 10$, $\\sigma = 0.25$,\n  - $k = 200$,\n  - $z_i$ uniformly from $-0.8$ to $+0.8$ with spacing $0.2$,\n  - $N = 200000$ for every window.\n\n- Case B (wider barrier, sparser windows):\n  - $T = 300$, $H = 15$, $\\sigma = 0.20$,\n  - $k = 150$,\n  - $z_i$ uniformly from $-0.9$ to $+0.9$ with spacing $0.3$,\n  - $N = 250000$ for every window.\n\n- Case C (higher temperature):\n  - $T = 350$, $H = 9$, $\\sigma = 0.30$,\n  - $k = 200$,\n  - $z_i$ uniformly from $-0.8$ to $+0.8$ with spacing $0.2$,\n  - $N = 200000$ for every window.\n\n- Case D (edge coverage case):\n  - $T = 300$, $H = 6$, $\\sigma = 0.35$,\n  - $k = 100$,\n  - $z_i$ uniformly from $-0.8$ to $+0.8$ with spacing $0.4$,\n  - $N = 300000$ for every window.\n\nRequired final output format: Your program should produce a single line containing a list with the four barrier heights $\\Delta W$ for Cases A, B, C, and D, in this order, expressed in $\\mathrm{kJ/mol}$ and rounded to three decimal places, as a comma-separated list enclosed in square brackets, for example, \"[$x_1,x_2,x_3,x_4$]\".",
            "solution": "The problem statement has been critically examined and is determined to be valid. It is scientifically grounded in the principles of statistical mechanics, well-posed, and presented with objective, unambiguous definitions and data. It constitutes a standard, albeit idealized, exercise in computational chemistry, specifically the reconstruction of a potential of mean force (PMF) from umbrella sampling data. We shall now proceed with a complete solution.\n\nThe fundamental task is to recover the one-dimensional PMF, $W(z)$, from a set of biased histograms, $\\{n_i(z_j)\\}$. The data for each histogram $i$ are generated under the influence of a known harmonic biasing potential, $U_i(z)$. This is a classic inverse problem that can be solved using the Weighted Histogram Analysis Method (WHAM), which provides an optimal, self-consistent way to combine data from multiple biased simulations.\n\nFirst, we establish the necessary physical and mathematical framework. The system is in a canonical ensemble at temperature $T$. The unbiased probability of observing the system at coordinate $z$ is $P(z)$, which defines the PMF via the relation:\n$$\nW(z) = -k_\\mathrm{B} T \\ln P(z) + C\n$$\nFor molar energies, we use the gas constant $R$. As energies are required in $\\mathrm{kJ/mol}$, we define $R_{\\mathrm{kJ}} = R/1000$ and the inverse thermal energy $\\beta = \\frac{1}{R_\\mathrm{kJ} T}$. The PMF for a discrete set of coordinate bins $z_j$ is then given by:\n$$\nW(z_j) = -\\frac{1}{\\beta} \\ln P(z_j) + C'\n$$\nwhere $P(z_j)$ is the probability density at $z_j$. It is more convenient to work with the probability of being in bin $j$, $p_j = P(z_j) \\Delta z$, where $\\Delta z$ is the bin width. The set $\\{p_j\\}$ forms a probability distribution, $\\sum_j p_j = 1$. The PMF can be expressed as:\n$$\nW(z_j) = -\\frac{1}{\\beta} \\ln p_j + C''\n$$\nThe constant $C''$ includes the term $\\frac{1}{\\beta} \\ln(\\Delta z)$ and can be ignored for calculating the barrier height, $\\Delta W = \\max_j W(z_j) - \\min_j W(z_j)$.\n\nIn each umbrella sampling window $i$, a bias $U_i(z)$ is applied. The biased probability distribution, $P_i(z)$, is related to the unbiased distribution $P(z)$ by:\n$$\nP_i(z) = \\frac{P(z) \\exp(-\\beta U_i(z))}{\\int P(z') \\exp(-\\beta U_i(z')) dz'}\n$$\nThe denominator is a normalization constant related to the free energy, $F_i$, of applying the bias: $\\exp(-\\beta F_i) = \\int P(z') \\exp(-\\beta U_i(z')) dz'$.\n\nThe WHAM equations provide the optimal estimate for the unbiased probabilities $\\{p_j\\}$ by combining data from all $M$ windows. The equations are:\n$$\np_j = \\frac{\\sum_{i=1}^{M} n_{ij}}{\\sum_{i=1}^{M} N_i \\exp(-\\beta (U_{ij} - F_i))}\n$$\n$$\nF_i = -\\frac{1}{\\beta} \\ln \\left( \\sum_{j} p_j \\exp(-\\beta U_{ij}) \\right)\n$$\nHere, $n_{ij}$ is the number of samples in bin $j$ from window $i$, $N_i$ is the total number of samples from window $i$, $U_{ij} = U_i(z_j)$ is the bias potential energy, and $\\{F_i\\}$ are the free energies of the windows relative to the unbiased state. These equations are coupled and must be solved self-consistently. The free energies $\\{F_i\\}$ are only defined up to an additive constant, so we can fix one (e.g., $F_1 = 0$) during the iterative process to ensure convergence.\n\nThe solution process is implemented in two main stages for each test case:\n\n**Stage 1: Data Generation**\n\nFirst, we generate the \"experimental\" data (the histograms $\\{n_{ij}\\}$) according to the problem specification. This involves using the provided model PMF, $W^\\ast(z)$. This stage is for generating input data only; $W^\\ast(z)$ is not used in the subsequent reconstruction.\n\n1.  A uniform grid of $z_j$ coordinates is established from $z_{\\min} = -1.0$ to $z_{\\max} = +1.0$ with spacing $\\Delta z = 0.02$.\n2.  For each window $i$, with center $z_i$ and force constant $k_i$:\n    a. The true PMF $W^\\ast(z_j) = H \\exp(-z_j^2/\\sigma^2)$ and the bias potential $U_{ij} = \\frac{1}{2} k_i (z_j - z_i)^2$ are calculated on the grid.\n    b. The total potential is $E_{ij} = W^\\ast(z_j) + U_{ij}$.\n    c. The unnormalized biased probability for bin $j$ is $q_{ij} = \\exp(-\\beta E_{ij})$.\n    d. The normalized probability density $\\pi_i(z_j)$ is computed as $\\pi_i(z_j) = q_{ij} / (\\sum_k q_{ik} \\Delta z)$.\n    e. The histogram counts are generated: $n_{ij} = \\mathrm{round}(N_i \\cdot \\pi_i(z_j) \\cdot \\Delta z)$.\n\n**Stage 2: PMF Reconstruction and Barrier Calculation**\n\nSecond, we use the generated histograms $\\{n_{ij}\\}$, the known biases $\\{U_{ij}\\}$, and the sample counts $\\{N_i\\}$ to reconstruct the PMF.\n\n1.  **Initialization**: The free energies are initialized, for example, $F_i = 0$ for all $i=1, \\dots, M$.\n2.  **Self-Consistent Iteration**: The WHAM equations are solved iteratively until the values of $\\{F_i\\}$ converge.\n    a. An updated, unnormalized probability distribution $\\{p'_j\\}$ is calculated using the current $\\{F_i\\}$:\n       $$\n       p'_j = \\frac{\\sum_{i=1}^{M} n_{ij}}{\\sum_{i=1}^{M} N_i \\exp(-\\beta (U_{ij} - F_i))}\n       $$\n    b. The distribution is normalized: $p_j = p'_j / (\\sum_k p'_k)$.\n    c. New free energies $\\{F_i^{\\text{new}}\\}$ are calculated using the updated $\\{p_j\\}$:\n       $$\n       F_i^{\\text{new}} = -\\frac{1}{\\beta} \\ln \\left( \\sum_{j} p_j \\exp(-\\beta U_{ij}) \\right)\n       $$\n    d. The free energies are shifted to enforce a consistent reference, e.g., by setting $F_1^{\\text{new}} = 0$, to prevent numerical drift.\n    e. The process is repeated until the change in $\\{F_i\\}$ between iterations is below a small tolerance.\n3.  **Final Calculation**:\n    a. Once the converged probabilities $\\{p_j\\}$ are obtained, the PMF is calculated for all bins with non-zero probability ($p_j > 0$): $W_j = -\\frac{1}{\\beta} \\ln(p_j)$.\n    b. The PMF is shifted by setting its minimum value to zero: $W_j^{\\text{final}} = W_j - \\min_k W_k$.\n    c. The barrier height is the maximum value of the final PMF: $\\Delta W = \\max_j W_j^{\\text{final}}$.\n\nThis procedure is applied to each of the four test cases specified. The resulting $\\Delta W$ values are collected and reported.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the PMF reconstruction problem for all test cases.\n    \"\"\"\n    # Universal constants and grid parameters\n    R_KJ = 8.314462618 / 1000  # Gas constant in kJ/mol/K\n    Z_MIN, Z_MAX, DZ = -1.0, 1.0, 0.02\n    \n    # Grid setup (ensuring z_max is included)\n    num_bins = int(round((Z_MAX - Z_MIN) / DZ)) + 1\n    z_grid = np.linspace(Z_MIN, Z_MAX, num_bins)\n\n    # Test suite definition\n    test_cases = [\n        { # Case A\n            \"T\": 300, \"H\": 10, \"sigma\": 0.25, \"k\": 200,\n            \"z_i_range\": (-0.8, 0.8), \"z_i_step\": 0.2, \"N\": 200000\n        },\n        { # Case B\n            \"T\": 300, \"H\": 15, \"sigma\": 0.20, \"k\": 150,\n            \"z_i_range\": (-0.9, 0.9), \"z_i_step\": 0.3, \"N\": 250000\n        },\n        { # Case C\n            \"T\": 350, \"H\": 9, \"sigma\": 0.30, \"k\": 200,\n            \"z_i_range\": (-0.8, 0.8), \"z_i_step\": 0.2, \"N\": 200000\n        },\n        { # Case D\n            \"T\": 300, \"H\": 6, \"sigma\": 0.35, \"k\": 100,\n            \"z_i_range\": (-0.8, 0.8), \"z_i_step\": 0.4, \"N\": 300000\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        delta_w = process_case(case, z_grid, R_KJ, DZ)\n        results.append(f\"{delta_w:.3f}\")\n\n    print(f\"[{','.join(results)}]\")\n\ndef process_case(case_params, z_grid, r_kj, dz):\n    \"\"\"\n    Generates histograms and runs WHAM for a single test case.\n    \"\"\"\n    # Unpack parameters\n    T = case_params[\"T\"]\n    H = case_params[\"H\"]\n    sigma = case_params[\"sigma\"]\n    k = case_params[\"k\"]\n    z_i_start, z_i_end = case_params[\"z_i_range\"]\n    z_i_step = case_params[\"z_i_step\"]\n    N_samples_per_window = case_params[\"N\"]\n\n    # Umbrella window centers\n    z_i_centers = np.arange(z_i_start, z_i_end + z_i_step * 0.1, z_i_step)\n    num_windows = len(z_i_centers)\n    num_bins = len(z_grid)\n    \n    beta = 1.0 / (r_kj * T)\n\n    # --- Stage 1: Data Generation ---\n    W_star = H * np.exp(-z_grid**2 / sigma**2)\n    \n    histograms = np.zeros((num_windows, num_bins))\n    bias_potentials = np.zeros((num_windows, num_bins))\n    \n    for i in range(num_windows):\n        z_i = z_i_centers[i]\n        U_i = 0.5 * k * (z_grid - z_i)**2\n        bias_potentials[i, :] = U_i\n        \n        total_potential = W_star + U_i\n        \n        # Biased probability density\n        unnormalized_prob = np.exp(-beta * total_potential)\n        normalization_const = np.sum(unnormalized_prob) * dz\n        prob_density_pi = unnormalized_prob / normalization_const\n        \n        # Histogram counts\n        counts = np.round(N_samples_per_window * prob_density_pi * dz)\n        histograms[i, :] = counts\n        \n    N_i_array = np.full(num_windows, N_samples_per_window)\n\n    # --- Stage 2: PMF Reconstruction (WHAM) ---\n    F = np.zeros(num_windows)  # Initial guess for free energies\n    \n    max_iter = 1000\n    tolerance = 1e-9\n    \n    for iteration in range(max_iter):\n        F_old = F.copy()\n        \n        # Calculate unnormalized probabilities p'_j\n        # Numerator: total counts in each bin\n        numerator = np.sum(histograms, axis=0)\n        \n        # Denominator: sum over windows\n        # Use broadcasting for efficient computation\n        log_weights = -beta * (bias_potentials - F[:, np.newaxis])\n        # Handle potential overflow in exp by subtracting max value, though\n        # standard WHAM is usually stable enough for typical parameters.\n        exp_weights = np.exp(log_weights)\n        denominator_terms = N_i_array[:, np.newaxis] * exp_weights\n        denominator = np.sum(denominator_terms, axis=0)\n\n        # Avoid division by zero for empty bins\n        p_unnormalized = np.zeros_like(numerator)\n        valid_bins_mask = denominator > 0\n        p_unnormalized[valid_bins_mask] = numerator[valid_bins_mask] / denominator[valid_bins_mask]\n        \n        # Normalize probabilities\n        p_sum = np.sum(p_unnormalized)\n        p = p_unnormalized / p_sum if p_sum > 0 else p_unnormalized\n\n        # Update free energies F_i\n        # Sum term for F_i calculation: sum_j p_j * exp(-beta * U_ij)\n        sum_terms = np.sum(p[np.newaxis, :] * np.exp(-beta * bias_potentials), axis=1)\n\n        # Avoid log(0)\n        valid_F_mask = sum_terms > 0\n        F[valid_F_mask] = -(1.0 / beta) * np.log(sum_terms[valid_F_mask])\n        \n        # Shift F to keep F[0] = 0 for stability\n        F -= F[0]\n\n        # Check for convergence\n        if np.max(np.abs(F - F_old)) < tolerance:\n            break\n            \n    # --- Final Calculation ---\n    # Calculate PMF from converged probabilities\n    valid_pmf_bins = p > 0\n    W = np.full_like(p, np.inf)\n    W[valid_pmf_bins] = -(1.0 / beta) * np.log(p[valid_pmf_bins])\n    \n    # Normalize PMF to have minimum of 0\n    min_W = np.min(W)\n    W -= min_W\n    \n    # Barrier height is the maximum of the final PMF\n    delta_W = np.max(W[np.isfinite(W)])\n    \n    return delta_W\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}