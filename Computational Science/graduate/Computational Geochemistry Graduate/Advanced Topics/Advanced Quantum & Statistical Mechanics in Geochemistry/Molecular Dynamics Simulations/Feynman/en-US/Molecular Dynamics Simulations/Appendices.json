{
    "hands_on_practices": [
        {
            "introduction": "Molecular dynamics simulations of bulk materials rely on periodic boundary conditions (PBC) to minimize surface effects. A cornerstone of PBC is the minimum image convention (MIC), which ensures that interactions are always calculated between the closest periodic images of particles. This foundational exercise () will guide you through implementing the MIC for distance calculations, a critical first step in building or understanding any MD code.",
            "id": "2458300",
            "problem": "You are to write a complete, runnable program that demonstrates the effect of the minimum image convention for periodic boundary conditions in molecular dynamics (MD) simulations. The program must compute the Euclidean distance between two particles in an orthorhombic periodic simulation box in two ways: (1) the naive Euclidean distance that ignores periodicity, and (2) the Euclidean distance after applying the minimum image convention. Distances must be expressed in nanometers (nm) and reported rounded to exactly six decimal places.\n\nBackground and fundamental base: In molecular dynamics (MD) simulations with periodic boundary conditions (PBC), an infinite tiling of the finite simulation box is used to mimic bulk behavior. The physical distance between two particles is interpreted as the minimum distance between one particle and any periodic image of the other. The underlying geometric rule is derived from the definition of Euclidean distance and the translation symmetry of the lattice. For an orthorhombic box with side lengths $L_x$, $L_y$, and $L_z$, the minimum distance is obtained by selecting an integer number of box-length translations along each axis that minimizes the Euclidean norm of the displacement vector. Your program must implement this rule.\n\nYour task:\n- Define a function that, given two $3$-dimensional positions $\\mathbf{r}_i$ and $\\mathbf{r}_j$ in nanometers and box lengths $(L_x,L_y,L_z)$ in nanometers, returns two values:\n  1) the naive Euclidean distance $d_{\\text{naive}} = \\lVert \\mathbf{r}_j - \\mathbf{r}_i \\rVert$ in nm,\n  2) the minimum image convention distance $d_{\\text{mic}}$ in nm, obtained by translating the displacement components by integer multiples of $(L_x,L_y,L_z)$ to minimize the norm.\n- Treat the box as orthorhombic and axis-aligned.\n- Positions may lie outside the primary box interval. Your implementation must still correctly compute $d_{\\text{mic}}$ using periodicity.\n- To make your implementation clear, also include within the program a multi-line pseudocode string (not printed) that outlines the minimum image convention logic you implemented.\n\nNumerical and unit requirements:\n- All distances must be in nanometers (nm).\n- Report distances rounded to exactly $6$ decimal places.\n\nTest suite:\nYour program must compute $[d_{\\text{naive}}, d_{\\text{mic}}]$ for each of the following $5$ test cases, in the stated order.\n\n1) Happy path, small separation well within the box:\n- Box: $(L_x,L_y,L_z) = (\\,3.0\\,\\text{nm},\\,3.0\\,\\text{nm},\\,3.0\\,\\text{nm}\\,)$\n- $\\mathbf{r}_i = (\\,0.5\\,\\text{nm},\\,1.0\\,\\text{nm},\\,1.5\\,\\text{nm}\\,)$\n- $\\mathbf{r}_j = (\\,0.7\\,\\text{nm},\\,1.2\\,\\text{nm},\\,1.6\\,\\text{nm}\\,)$\n\n2) Crossing a periodic boundary along one axis:\n- Box: $(L_x,L_y,L_z) = (\\,3.0\\,\\text{nm},\\,3.0\\,\\text{nm},\\,3.0\\,\\text{nm}\\,)$\n- $\\mathbf{r}_i = (\\,0.1\\,\\text{nm},\\,1.0\\,\\text{nm},\\,1.0\\,\\text{nm}\\,)$\n- $\\mathbf{r}_j = (\\,2.9\\,\\text{nm},\\,1.0\\,\\text{nm},\\,1.0\\,\\text{nm}\\,)$\n\n3) Anisotropic box and wrapping along multiple axes:\n- Box: $(L_x,L_y,L_z) = (\\,2.0\\,\\text{nm},\\,4.0\\,\\text{nm},\\,5.0\\,\\text{nm}\\,)$\n- $\\mathbf{r}_i = (\\,1.9\\,\\text{nm},\\,0.2\\,\\text{nm},\\,4.8\\,\\text{nm}\\,)$\n- $\\mathbf{r}_j = (\\,0.1\\,\\text{nm},\\,3.9\\,\\text{nm},\\,0.3\\,\\text{nm}\\,)$\n\n4) Exactly half-box separation along one axis (tie case):\n- Box: $(L_x,L_y,L_z) = (\\,4.0\\,\\text{nm},\\,4.0\\,\\text{nm},\\,4.0\\,\\text{nm}\\,)$\n- $\\mathbf{r}_i = (\\,0.0\\,\\text{nm},\\,0.0\\,\\text{nm},\\,0.0\\,\\text{nm}\\,)$\n- $\\mathbf{r}_j = (\\,2.0\\,\\text{nm},\\,0.0\\,\\text{nm},\\,0.0\\,\\text{nm}\\,)$\n\n5) Positions outside the primary box interval:\n- Box: $(L_x,L_y,L_z) = (\\,3.0\\,\\text{nm},\\,3.0\\,\\text{nm},\\,3.0\\,\\text{nm}\\,)$\n- $\\mathbf{r}_i = (\\,{-}0.1\\,\\text{nm},\\,{-}0.1\\,\\text{nm},\\,{-}0.1\\,\\text{nm}\\,)$\n- $\\mathbf{r}_j = (\\,3.1\\,\\text{nm},\\,3.1\\,\\text{nm},\\,3.1\\,\\text{nm}\\,)$\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list of pairs enclosed in square brackets. Each pair corresponds to one test case in the specified order and must have the form $[d_{\\text{naive}},d_{\\text{mic}}]$, with both values rounded to exactly $6$ decimal places in nanometers. There must be no spaces in the output.\n- For example, the required overall format is like $[[a_1,b_1],[a_2,b_2],\\dots]$ where each $a_k$ and $b_k$ are floats in nanometers with exactly $6$ decimal places.",
            "solution": "The problem posed is a fundamental exercise in computational statistical mechanics, specifically concerning the implementation of periodic boundary conditions (PBC) in molecular dynamics (MD) simulations. The use of PBC is a standard and necessary technique to approximate the properties of a macroscopic system by simulating a small, finite number of particles. It mitigates the severe surface effects that would otherwise dominate the behavior of a small system. The core of this problem is the correct calculation of inter-particle distances, which is governed by the minimum image convention (MIC).\n\nThe problem is well-posed, scientifically grounded, and provides all necessary data for a unique and verifiable solution. We will proceed with a rigorous derivation and implementation.\n\nLet the orthorhombic simulation box be defined by a set of three orthogonal vectors corresponding to the side lengths, $\\mathbf{L} = (L_x, L_y, L_z)$. The position of two particles, $i$ and $j$, are given by vectors $\\mathbf{r}_i$ and $\\mathbf{r}_j$.\n\nFirst, we define the naive Euclidean distance, $d_{\\text{naive}}$. This is the standard distance in a non-periodic, three-dimensional Euclidean space. It is calculated from the norm of the displacement vector $\\Delta\\mathbf{r} = \\mathbf{r}_j - \\mathbf{r}_i$.\n$$\nd_{\\text{naive}} = \\lVert \\Delta\\mathbf{r} \\rVert = \\sqrt{(\\Delta x)^2 + (\\Delta y)^2 + (\\Delta z)^2}\n$$\nwhere $\\Delta\\mathbf{r} = (\\Delta x, \\Delta y, \\Delta z)$. This calculation ignores the periodic nature of the simulation box and treats the system as if it were isolated in a vacuum.\n\nSecond, we address the minimum image convention distance, $d_{\\text{mic}}$. In a periodic system, the simulation box is replicated infinitely in all directions. A particle at position $\\mathbf{r}$ has an infinite lattice of periodic images at positions $\\mathbf{r} + n_x L_x \\hat{\\mathbf{x}} + n_y L_y \\hat{\\mathbf{y}} + n_z L_z \\hat{\\mathbf{z}}$, where $n_x, n_y, n_z$ are any integers. The physical distance between particle $i$ and particle $j$ is the shortest distance between particle $i$ and *any* of the periodic images of particle $j$.\n\nMathematically, this is expressed as:\n$$\nd_{\\text{mic}} = \\min_{n_x, n_y, n_z \\in \\mathbb{Z}} \\left\\lVert (\\mathbf{r}_j - \\mathbf{r}_i) - (n_x L_x \\hat{\\mathbf{x}} + n_y L_y \\hat{\\mathbf{y}} + n_z L_z \\hat{\\mathbf{z}}) \\right\\rVert\n$$\nFor an orthorhombic box, the minimization of the norm can be performed independently for each Cartesian component. Let us consider the $x$-component of the displacement vector, $\\Delta x = x_j - x_i$. We must find an integer $n_x$ that minimizes $|\\Delta x - n_x L_x|$. This is achieved when $n_x$ is the integer nearest to the ratio $\\Delta x / L_x$. This is the \"nearest integer function,\" often denoted as $\\text{nint}(s)$ or implemented via `round(s)`.\n\nThe MIC-adjusted displacement component, $\\Delta x'$, is therefore:\n$$\n\\Delta x' = \\Delta x - L_x \\cdot \\text{round}\\left(\\frac{\\Delta x}{L_x}\\right)\n$$\nThis formula correctly \"wraps\" the displacement vector component into the interval $[-L_x/2, L_x/2]$. The same logic applies to the $y$ and $z$ components. The complete MIC-adjusted displacement vector, $\\Delta\\mathbf{r}'$, is then:\n$$\n\\Delta\\mathbf{r}' = \\left( \\Delta x - L_x \\cdot \\text{round}\\left(\\frac{\\Delta x}{L_x}\\right), \\Delta y - L_y \\cdot \\text{round}\\left(\\frac{\\Delta y}{L_y}\\right), \\Delta z - L_z \\cdot \\text{round}\\left(\\frac{\\Delta z}{L_z}\\right) \\right)\n$$\nThis vector operation is robust and correctly handles cases where particle coordinates may lie outside the primary simulation box, as only their relative displacement matters.\n\nThe minimum image distance, $d_{\\text{mic}}$, is the Euclidean norm of this adjusted displacement vector:\n$$\nd_{\\text{mic}} = \\lVert \\Delta\\mathbf{r}' \\rVert = \\sqrt{(\\Delta x')^2 + (\\Delta y')^2 + (\\Delta z')^2}\n$$\n\nThe provided test cases will be solved using this established methodology. The implementation will utilize the `numpy` library for efficient vector arithmetic. For each test case, we will compute $d_{\\text{naive}}$ and $d_{\\text{mic}}$ and report the results rounded to precisely $6$ decimal places as specified. The special case of a displacement of exactly half a box length, e.g., $\\Delta x = L_x/2$, is handled by the `round` function, which typically rounds to the nearest even integer (e.g., in `numpy`), but the resulting distance is uniquely $L_x/2$ regardless of the sign choice for the adjusted displacement. For $\\Delta x = L_x/2$, $\\Delta x' = L_x/2 - L_x \\cdot \\text{round}(0.5) = L_x/2 - L_x \\cdot 0 = L_x/2$. The magnitude is unambiguous.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of calculating naive and minimum image convention (MIC)\n    distances for a set of test cases in a molecular dynamics context.\n    \"\"\"\n\n    # Per the problem specification, this multi-line string contains the\n    # pseudocode explaining the implemented MIC logic. It is not printed.\n    # noinspection PyUnusedLocal\n    MIC_PSEUDOCODE = \"\"\"\n    function calculate_minimum_image_distance(r_i, r_j, box_dims):\n        // r_i, r_j: 3D position vectors [x, y, z] of two particles in nm.\n        // box_dims: 3D vector of orthorhombic box lengths [L_x, L_y, L_z] in nm.\n\n        // 1. Calculate the raw displacement vector.\n        //    This is a simple vector subtraction.\n        delta_r = r_j - r_i\n\n        // 2. Apply the minimum image convention to each component of the displacement vector.\n        //    For an orthorhombic box, this can be done independently for each axis.\n        //    The principle is to find the closest periodic image by shifting the displacement\n        //    by an integer number of box lengths. This is mathematically equivalent to\n        //    finding the nearest integer multiple of the box length to subtract.\n        \n        //    Let dr_c be a component of delta_r (e.g., delta_x) and L_c be the\n        //    corresponding box length (e.g., L_x).\n        //    The scaled displacement is s = dr_c / L_c.\n        //    The nearest integer number of box lengths to shift by is n = round(s).\n        //    The MIC-adjusted displacement component is dr'_c = dr_c - n * L_c.\n\n        //    In vector notation, this is:\n        mic_delta_r = delta_r - box_dims * np.round(delta_r / box_dims)\n        \n        // 3. Calculate the Euclidean norm (length) of the MIC-adjusted displacement vector.\n        //    This is the final minimum image distance.\n        distance_mic = sqrt(mic_delta_r[0]^2 + mic_delta_r[1]^2 + mic_delta_r[2]^2)\n        \n        return distance_mic\n    \"\"\"\n\n    def compute_distances(r_i_tuple, r_j_tuple, box_dims_tuple):\n        \"\"\"\n        Calculates naive and MIC distances for a single pair of particles.\n        \n        Args:\n            r_i_tuple (tuple): Position of particle i.\n            r_j_tuple (tuple): Position of particle j.\n            box_dims_tuple (tuple): Orthorhombic box dimensions (Lx, Ly, Lz).\n        \n        Returns:\n            A list containing two floats: [d_naive, d_mic].\n        \"\"\"\n        r_i = np.array(r_i_tuple, dtype=float)\n        r_j = np.array(r_j_tuple, dtype=float)\n        box_dims = np.array(box_dims_tuple, dtype=float)\n\n        # 1. Naive Euclidean distance\n        delta_r_naive = r_j - r_i\n        d_naive = np.linalg.norm(delta_r_naive)\n\n        # 2. Minimum Image Convention (MIC) distance\n        # The logic delta_r - L * round(delta_r / L) correctly finds the\n        # shortest vector in a periodic lattice.\n        delta_r_mic = delta_r_naive - box_dims * np.round(delta_r_naive / box_dims)\n        d_mic = np.linalg.norm(delta_r_mic)\n        \n        return [d_naive, d_mic]\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # 1) Happy path, small separation\n        {'r_i': (0.5, 1.0, 1.5), 'r_j': (0.7, 1.2, 1.6), 'box': (3.0, 3.0, 3.0)},\n        # 2) Crossing a periodic boundary\n        {'r_i': (0.1, 1.0, 1.0), 'r_j': (2.9, 1.0, 1.0), 'box': (3.0, 3.0, 3.0)},\n        # 3) Anisotropic box and multi-axis wrapping\n        {'r_i': (1.9, 0.2, 4.8), 'r_j': (0.1, 3.9, 0.3), 'box': (2.0, 4.0, 5.0)},\n        # 4) Exactly half-box separation\n        {'r_i': (0.0, 0.0, 0.0), 'r_j': (2.0, 0.0, 0.0), 'box': (4.0, 4.0, 4.0)},\n        # 5) Positions outside the primary box\n        {'r_i': (-0.1, -0.1, -0.1), 'r_j': (3.1, 3.1, 3.1), 'box': (3.0, 3.0, 3.0)},\n    ]\n\n    result_strings = []\n    for case in test_cases:\n        d_naive, d_mic = compute_distances(case['r_i'], case['r_j'], case['box'])\n        \n        # Format the numbers to exactly 6 decimal places and create the pair string.\n        # This ensures trailing zeros are included and meets the formatting requirement.\n        result_strings.append(f\"[{d_naive:.6f},{d_mic:.6f}]\")\n\n    # Final print statement in the exact required format: [[a1,b1],[a2,b2],...]\n    # without spaces between elements.\n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The choice of the integration time step, $dt$, is one of the most critical parameters in a molecular dynamics simulation, balancing computational efficiency with numerical stability. If the time step is too large relative to the fastest motions in the system, the integration will be unstable, leading to catastrophic energy non-conservation. This practical exercise () demonstrates this phenomenon by identifying the \"explosion\" point for a simple harmonic oscillator, which serves as an excellent model for the stiff, high-frequency vibrations that often limit $dt$ in real systems.",
            "id": "2458247",
            "problem": "You are asked to implement a self-contained computational experiment, grounded in first principles, to study the time-step stability of a single one-dimensional harmonic mode that represents a stiff normal mode in a protein in Molecular Dynamics (MD). The system is a particle of mass $m$ confined to a harmonic potential with force constant $k$, evolving under Newton’s second law. Use reduced, dimensionless units throughout; do not attach physical units to any quantity.\n\nThe dynamics are defined by Newton’s second law, $m \\,\\ddot{x}(t) = - k \\, x(t)$, with initial conditions $x(0) = x_0$ and $\\dot{x}(0) = v_0$. The total energy is $E(t) = \\tfrac{1}{2} m \\,\\dot{x}(t)^2 + \\tfrac{1}{2} k \\, x(t)^2$. For a given discrete time step $dt$, simulate the motion for a total simulation time $T$ and monitor $E(t)$ during the trajectory.\n\nDefine an “explosion” for a chosen $dt$ to have occurred if any one of the following three events happens at any simulation step:\n- The computed total energy $E(t)$ becomes not finite (that is, not a real, finite number).\n- The relative energy error exceeds a specified tolerance, that is, $\\lvert E(t) - E(0) \\rvert / E(0) > \\varepsilon$ for any time $t$ up to the end of the simulation.\n- The magnitude of the position exceeds a prescribed bound derived from the initial energy, that is, $\\lvert x(t) \\rvert > B \\, A_0$ for any $t$, where $A_0 = \\sqrt{2 E(0)/k}$.\n\nFor each test case below, you are given the parameter set $(m, k, x_0, v_0, T, \\varepsilon, B)$ and an ordered list of time steps $[dt_1, dt_2, \\dots, dt_n]$. For each test case, simulate the system separately for each $dt_i$ in the given order and identify the smallest $dt_i$ in the list that leads to an explosion by the above definition. If none of the listed $dt_i$ leads to an explosion, return the sentinel value $-1.0$.\n\nUse the following four test cases. All symbols and numbers below are to be interpreted in reduced, dimensionless units.\n\nTest Case 1:\n- Parameters: $m = 1.0$, $k = 1.0$, $x_0 = 1.0$, $v_0 = 1.0$, $T = 100.0$, $\\varepsilon = 0.20$, $B = 100.0$.\n- Time steps to test (in ascending order): $[0.1, 0.5, 1.5, 1.9, 2.0, 2.1]$.\n\nTest Case 2:\n- Parameters: $m = 1.0$, $k = 16.0$, $x_0 = 1.0$, $v_0 = 1.0$, $T = 20.0$, $\\varepsilon = 0.10$, $B = 100.0$.\n- Time steps to test (in ascending order): $[0.05, 0.10, 0.30, 0.49, 0.50, 0.51]$.\n\nTest Case 3:\n- Parameters: $m = 2.0$, $k = 0.5$, $x_0 = 1.0$, $v_0 = 1.0$, $T = 50.0$, $\\varepsilon = 0.05$, $B = 1000.0$.\n- Time steps to test (in ascending order): $[0.50, 1.00, 2.00, 3.00, 3.50]$.\n\nTest Case 4:\n- Parameters: $m = 1.0$, $k = 100.0$, $x_0 = 1.0$, $v_0 = 1.0$, $T = 8.0$, $\\varepsilon = 0.15$, $B = 100.0$.\n- Time steps to test (in ascending order): $[0.02, 0.10, 0.19, 0.20, 0.25]$.\n\nYour program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each result must be a floating-point number rounded to six decimal places, in the same order as the test cases above. For example, if the results for the four test cases are $r_1$, $r_2$, $r_3$, and $r_4$, your program must print exactly\n\"[r1,r2,r3,r4]\"\nwith each $r_i$ formatted to six decimal places and no additional text.\n\nAngle quantities, if any arise internally, must be treated in radians. All values in this problem are dimensionless by construction, so no physical units are to be displayed in the output.",
            "solution": "The problem requires a computational experiment to determine the stability limit of a numerical integration scheme for a one-dimensional harmonic oscillator, which serves as a model for a stiff vibrational mode in a molecular dynamics (MD) simulation. The problem is well-posed and scientifically grounded. It constitutes a direct test of numerical integration stability, a fundamental concept in computational science.\n\nThe system is described by the equation of motion for a simple harmonic oscillator:\n$$\nm \\frac{d^2x}{dt^2} = -k x(t)\n$$\nwhere $m$ is the mass, $k$ is the force constant, and $x(t)$ is the position. The angular frequency of this oscillator is $\\omega = \\sqrt{k/m}$. The dynamics are to be propagated from initial conditions $x(0) = x_0$ and $\\dot{x}(0) = v_0$ using a discrete time step $dt$.\n\nThe problem statement does not specify the numerical integration algorithm. For MD simulations of Newtonian mechanics, the Velocity-Verlet algorithm is a standard, widely-used, and robust choice due to its time-reversibility and symplectic nature, which leads to good long-term energy conservation properties. Therefore, the Velocity-Verlet integrator is the appropriate algorithm to implement.\n\nThe Velocity-Verlet algorithm consists of the following steps to advance the system from time $t$ to $t+dt$:\n1.  Compute the half-step velocity:\n    $$\n    v(t + \\tfrac{1}{2}dt) = v(t) + \\tfrac{1}{2} a(t) dt\n    $$\n2.  Update the position to the full new time step:\n    $$\n    x(t + dt) = x(t) + v(t + \\tfrac{1}{2}dt) dt\n    $$\n3.  Compute the acceleration at the new position. The acceleration is derived from the force $F(x) = -kx$, so $a(x) = F(x)/m = -(k/m)x$:\n    $$\n    a(t + dt) = -\\frac{k}{m} x(t + dt)\n    $$\n4.  Compute the full-step velocity at the new time:\n    $$\n    v(t + dt) = v(t + \\tfrac{1}{2}dt) + \\tfrac{1}{2} a(t + dt) dt\n    $$\n\nFor each test case, we are given a set of parameters $(m, k, x_0, v_0, T, \\varepsilon, B)$ and an ordered list of time steps $[dt_1, dt_2, \\dots]$. The task is to find the smallest $dt_i$ from this list for which the simulation becomes unstable or \"explodes.\" The simulation for a given $dt$ runs for a total time $T$, which corresponds to $N_{steps} = \\lfloor T/dt \\rfloor$ integration steps.\n\nBefore the simulation loop begins, we must establish the baseline for the explosion criteria. The initial total energy $E(0)$ is calculated as:\n$$\nE(0) = \\frac{1}{2} m v_0^2 + \\frac{1}{2} k x_0^2\n$$\nThe problem states that for all test cases, $x_0$, $v_0$, $m$, and $k$ are positive, ensuring $E(0) > 0$. The characteristic amplitude $A_0$ is then defined as:\n$$\nA_0 = \\sqrt{\\frac{2 E(0)}{k}}\n$$\nThis $A_0$ represents the maximum displacement in the exact analytical solution.\n\nThe simulation proceeds by iterating the Velocity-Verlet algorithm for $N_{steps}$ times. After each step, we obtain the new state $(x(t+dt), v(t+dt))$ and check for the three explosion conditions:\n1.  **Finiteness of Energy**: The total energy at the new step, $E(t+dt) = \\frac{1}{2} m v(t+dt)^2 + \\frac{1}{2} k x(t+dt)^2$, must be a finite real number. Computationally, this is checked by verifying if the value is not `NaN` (Not a Number) or infinite. This condition detects catastrophic numerical overflow.\n2.  **Relative Energy Conservation**: The relative deviation of the current energy from the initial energy must not exceed a tolerance $\\varepsilon$.\n    $$\n    \\frac{\\lvert E(t+dt) - E(0) \\rvert}{E(0)} > \\varepsilon\n    $$\n    This condition detects when the numerical integration error leads to a significant, unphysical drift in the total energy, even if the trajectory has not yet diverged to infinity.\n3.  **Position Bound**: The magnitude of the position must not exceed a large multiple of the characteristic amplitude.\n    $$\n    \\lvert x(t+dt) \\rvert > B \\cdot A_0\n    $$\n    This is another practical check for trajectory divergence, where the particle escapes to unphysically large distances from the potential minimum.\n\nThe overall procedure for each test case is as follows:\nIterate through the provided list of time steps $dt_i$, which are sorted in ascending order. For each $dt_i$:\n- Run a full simulation for time $T$.\n- At every step of the simulation, check the three explosion conditions.\n- If any condition is met at any point during the simulation, the simulation for this $dt_i$ is deemed unstable. This $dt_i$ is the result for the test case, and we proceed to the next test case.\n- If the simulation completes for $T$ without any explosion, this $dt_i$ is considered stable. We then proceed to test the next $dt_i$ in the list.\n\nIf all time steps in the list for a given test case result in stable simulations, the result for that test case is the sentinel value $-1.0$.\n\nThe implementation will consist of a primary function that iterates through the test cases. This function will call a sub-function for each test case, which in turn iterates through the provided $dt$ values and calls a simulation function. The simulation function implements the Velocity-Verlet loop and the stability checks described above. The final output is a list of the smallest exploding $dt$ for each case, or $-1.0$ if none are found.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_simulation(m, k, x0, v0, T, epsilon, B, dt) -> bool:\n    \"\"\"\n    Runs a simulation of a 1D harmonic oscillator using the Velocity-Verlet algorithm.\n\n    Args:\n        m (float): Mass.\n        k (float): Force constant.\n        x0 (float): Initial position.\n        v0 (float): Initial velocity.\n        T (float): Total simulation time.\n        epsilon (float): Relative energy error tolerance.\n        B (float): Position bound factor.\n        dt (float): Time step.\n\n    Returns:\n        bool: True if an explosion occurs, False otherwise.\n    \"\"\"\n    if dt <= 0:\n        return False  # A time step of zero or less is not meaningful.\n\n    num_steps = int(T / dt)\n    \n    # Initial conditions\n    x = float(x0)\n    v = float(v0)\n    \n    # Calculate initial energy and derived bounds for explosion criteria\n    e0 = 0.5 * m * v**2 + 0.5 * k * x**2\n    \n    # The problem constraints ensure e0 > 0, so no division by zero.\n    a0 = np.sqrt(2 * e0 / k)\n    x_bound = B * a0\n\n    # Initial acceleration\n    a = -(k / m) * x\n    \n    # Main simulation loop\n    for _ in range(num_steps):\n        # Velocity-Verlet integrator\n        # v(t + dt/2)\n        v_half = v + 0.5 * a * dt\n        # x(t + dt)\n        x = x + v_half * dt\n        # a(t + dt)\n        a_new = -(k / m) * x\n        # v(t + dt)\n        v = v_half + 0.5 * a_new * dt\n        \n        # Update acceleration for the next step\n        a = a_new\n        \n        # Calculate current energy at the full step\n        e_current = 0.5 * m * v**2 + 0.5 * k * x**2\n        \n        # --- Check for explosion conditions ---\n        \n        # 1. Non-finite energy (numerical overflow)\n        if not np.isfinite(e_current):\n            return True  # Explosion\n            \n        # 2. Relative energy error exceeds tolerance\n        # In the case e0 is 0, any change would be an infinite relative error.\n        # But for the given test cases, e0 is always positive.\n        if abs(e_current - e0) / e0 > epsilon:\n            return True  # Explosion\n        \n        # 3. Position exceeds bound\n        if abs(x) > x_bound:\n            return True  # Explosion\n            \n    return False  # No explosion occurred\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = [\n        {\n            'params': (1.0, 1.0, 1.0, 1.0, 100.0, 0.20, 100.0),\n            'dts': [0.1, 0.5, 1.5, 1.9, 2.0, 2.1],\n        },\n        {\n            'params': (1.0, 16.0, 1.0, 1.0, 20.0, 0.10, 100.0),\n            'dts': [0.05, 0.10, 0.30, 0.49, 0.50, 0.51],\n        },\n        {\n            'params': (2.0, 0.5, 1.0, 1.0, 50.0, 0.05, 1000.0),\n            'dts': [0.50, 1.00, 2.00, 3.00, 3.50],\n        },\n        {\n            'params': (1.0, 100.0, 1.0, 1.0, 8.0, 0.15, 100.0),\n            'dts': [0.02, 0.10, 0.19, 0.20, 0.25],\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        m, k, x0, v0, T, epsilon, B = case['params']\n        dts = case['dts']\n        \n        explosion_dt = -1.0\n        # The 'dts' lists are sorted, so we find the smallest by breaking on the first hit.\n        for dt in dts:\n            if run_simulation(m, k, x0, v0, T, epsilon, B, dt):\n                explosion_dt = dt\n                break\n        \n        results.append(f\"{explosion_dt:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A common pitfall in analyzing molecular dynamics data is treating successive simulation frames as independent statistical samples, which they are not. This temporal correlation means that naive error estimates are often deceptively small and physically incorrect. This advanced practice () delves into the proper statistical treatment of time-correlated data, guiding you to design a block-averaging procedure to compute robust and unbiased uncertainty estimates for key observables.",
            "id": "4090898",
            "problem": "In a classical Molecular Dynamics (MD) simulation of aqueous sodium chloride relevant to geochemical aqueous solutions, you compute the oxygen–oxygen radial distribution function (RDF), denoted $g(r)$, by histogramming inter-oxygen separations in bins of width $\\Delta r$ at a fixed $r$-bin. Let $A_k$ denote the per-frame contribution to this specific $g(r)$-bin (for example, the normalized bin count at time index $k$), sampled every $\\Delta t = 10\\,\\mathrm{fs}$ over a total trajectory length $T = 20\\,\\mathrm{ns}$. An independent analysis of the normalized autocorrelation function of $A_k$ suggests an approximately exponential decay, $\\rho_A(t) \\approx \\exp(-t/\\tau_c)$, with a correlation time $\\tau_c \\approx 5\\,\\mathrm{ps}$. You also wish to estimate the self-diffusion coefficient $D$ of water via the Einstein relation from the mean-squared displacement (MSD), using the same trajectory, and you need a statistically sound uncertainty estimate for $D$.\n\nStarting from fundamental definitions of time correlation functions and the fact that time averages in ergodic stationary processes converge to ensemble averages, reason about how autocorrelation affects the variance of time-averaged estimators. Use this reasoning to explain the meaning of the integrated autocorrelation time and how it alters the effective number of independent samples. Then design a block-averaging procedure that yields an unbiased estimate of the uncertainty in the $g(r)$ bin and can be adapted to $D$.\n\nWhich of the following procedures is correct?\n\nA. Treat each frame as independent. Compute the standard error of the $g(r)$ bin as $\\sqrt{\\hat{\\sigma}^2/N}$ where $\\hat{\\sigma}^2$ is the sample variance of $A_k$ across all frames and $N = T/\\Delta t$. For $D$, fit a single straight line to the full-trajectory MSD to obtain a slope and take the linear regression’s standard error as the uncertainty, because averaging over many time origins makes MSD points effectively independent.\n\nB. Estimate the normalized autocorrelation function $\\rho_A(t)$ of $A_k$ from the trajectory and compute the integrated autocorrelation time $\\tau_{\\mathrm{int}}$ from the time integral of $\\rho_A(t)$. Choose a non-overlapping block length $L$ satisfying $L \\gg \\tau_{\\mathrm{int}}$ (for example, $L \\approx 100\\,\\mathrm{ps}$ here), partition the trajectory into $M = T/L$ non-overlapping blocks, compute the block means $\\{\\bar{A}^{(m)}\\}_{m=1}^M$, and estimate the variance of the overall mean by the sample variance of the block means divided by $M$ using the unbiased denominator $(M-1)$. Check that the estimated standard error plateaus as $L$ is increased above several $\\tau_{\\mathrm{int}}$. For $D$, compute independent block-wise estimates $D^{(m)}$ (e.g., from the MSD slope within each block over lags much smaller than $L$ but larger than the ballistic regime), then use the same block-variance approach to obtain the uncertainty of $D$.\n\nC. Use overlapping blocks of length $L \\approx \\tau_c$ to maximize the number of blocks. Compute the variance of the $g(r)$ mean from the sample variance across all overlapping block means. For $D$, average the velocity autocorrelation function over all time origins, integrate it once to get $D$, and use the number of overlapping blocks as the effective degrees of freedom for the uncertainty.\n\nD. Compute the integrated autocorrelation time of $A_k$ and then set the effective sample size to $N_{\\mathrm{eff}} = N$. Because $A_k$ is bounded (as a histogram contribution), correlations are weak and vanish in the limit $N \\to \\infty$, so the naive standard error $\\sqrt{\\hat{\\sigma}^2/N}$ is asymptotically unbiased. For $D$, bootstrap the MSD time series by resampling time points with replacement to obtain a distribution of slopes; use its standard deviation as the uncertainty.\n\nSelect the single best option.",
            "solution": "The user requires a critical validation of a problem in computational geochemistry concerning the statistical analysis of molecular dynamics (MD) simulation data, followed by a detailed solution and evaluation of provided options.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n-   **System and Simulation:** A classical Molecular Dynamics (MD) simulation of aqueous sodium chloride.\n-   **Observables:**\n    1.  Oxygen–oxygen radial distribution function, $g(r)$, specifically the value in a single histogram bin.\n    2.  Self-diffusion coefficient, $D$, of water, to be estimated via the Einstein relation from the mean-squared displacement (MSD).\n-   **Trajectory Data:**\n    -   Per-frame contribution to the $g(r)$ bin is denoted $A_k$.\n    -   Sampling interval: $\\Delta t = 10\\,\\mathrm{fs}$.\n    -   Total trajectory length: $T = 20\\,\\mathrm{ns}$.\n-   **Correlation Information:**\n    -   The normalized autocorrelation function of $A_k$ is given as $\\rho_A(t) \\approx \\exp(-t/\\tau_c)$.\n    -   The correlation time constant is $\\tau_c \\approx 5\\,\\mathrm{ps}$.\n-   **Core Task:** Starting from fundamental principles of time correlation functions and ergodicity, explain how autocorrelation affects the variance of time-averaged estimators and what the integrated autocorrelation time signifies. Based on this, design a block-averaging procedure to estimate the uncertainty in the $g(r)$ bin value and the diffusion coefficient $D$.\n\n**Step 2: Validate Using Extracted Givens**\n\n-   **Scientific Grounding:** The problem is firmly located within the standard practices of computational chemistry and physics. The analysis of time-correlated data from MD simulations using statistical tools like autocorrelation functions, block averaging, RDFs, and MSDs is a fundamental topic. The parameters given ($\\Delta t = 10\\,\\mathrm{fs}$, $T = 20\\,\\mathrm{ns}$, $\\tau_c \\approx 5\\,\\mathrm{ps}$) are physically realistic for simulations of aqueous solutions. The underlying principles invoked (ergodicity, central limit theorem for correlated variables) are cornerstones of statistical mechanics. The problem is scientifically sound.\n-   **Well-Posedness:** The problem poses a clear and answerable question. It asks for the correct procedure to estimate statistical uncertainty for time-correlated data, a well-defined problem in time-series analysis with established solutions.\n-   **Objectivity:** The language is technical and precise. There are no subjective or ambiguous terms.\n-   **Consistency and Completeness:** The provided information is self-consistent and sufficient to formulate a correct statistical procedure. The presence of significant correlation is explicitly stated ($\\tau_c \\approx 5\\,\\mathrm{ps} \\gg \\Delta t = 0.01\\,\\mathrm{ps}$), making the core of the problem non-trivial. There are no contradictions.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is **valid**. It is scientifically sound, well-posed, and provides a clear basis for evaluating the proposed procedures. The solution phase will now proceed.\n\n### Derivation and Option Analysis\n\n**1. Fundamental Principles of Uncertainty in Time Averages**\n\nA time average of an observable $A$ over a simulation of $N$ discrete time steps is given by $\\bar{A} = \\frac{1}{N} \\sum_{k=1}^N A_k$. The standard formula for the variance of a mean, $\\mathrm{Var}(\\bar{A}) = \\mathrm{Var}(A)/N$, is valid only if the samples $A_k$ are independent and identically distributed (i.i.d.). In an MD simulation, successive configurations are correlated, hence the samples $A_k$ are not independent.\n\nThe correct expression for the variance of the mean of a stationary, correlated time series is:\n$$ \\mathrm{Var}(\\bar{A}) = \\frac{\\mathrm{Var}(A)}{N} \\left[ 1 + 2 \\sum_{k=1}^{N-1} \\left(1-\\frac{k}{N}\\right) \\rho_A(k\\Delta t) \\right] $$\nwhere $\\rho_A(k\\Delta t)$ is the normalized autocorrelation function at a lag of $k$ time steps.\n\nFor a long trajectory where $N \\gg 1$ and correlations decay sufficiently fast, this can be approximated as:\n$$ \\mathrm{Var}(\\bar{A}) \\approx \\frac{\\mathrm{Var}(A)}{N} \\left[ 1 + 2 \\sum_{k=1}^{\\infty} \\rho_A(k\\Delta t) \\right] $$\nThe term in the brackets is the *statistical inefficiency*, $s$. We can define an *effective number of independent samples*, $N_{\\mathrm{eff}} = N/s$. The variance of the mean is then concisely written as $\\mathrm{Var}(\\bar{A}) \\approx \\mathrm{Var}(A)/N_{\\mathrm{eff}}$.\n\nThe *integrated autocorrelation time*, $\\tau_{\\mathrm{int}}$, is a continuous-time measure of the persistence of correlations:\n$$ \\tau_{\\mathrm{int}} = \\int_0^\\infty \\rho_A(t) dt $$\nFor the given exponential decay, $\\rho_A(t) \\approx \\exp(-t/\\tau_c)$, the integral evaluates to $\\tau_{\\mathrm{int}} \\approx \\tau_c = 5\\,\\mathrm{ps}$. The statistical inefficiency can be related to $\\tau_{\\mathrm{int}}$: $s \\approx 2\\tau_{\\mathrm{int}}/\\Delta t$.\n\nIn this problem, $s \\approx 2 \\times (5\\,\\mathrm{ps}) / (0.01\\,\\mathrm{ps}) = 1000$. This means the naive standard error calculation, which assumes $s=1$, would underestimate the true statistical error by a factor of $\\sqrt{s} \\approx \\sqrt{1000} \\approx 31.6$.\n\n**2. The Block-Averaging Procedure**\n\nDirectly calculating $\\tau_{\\mathrm{int}}$ (and thus $s$) can be statistically noisy. A more robust and widely accepted method is **block averaging**.\n1.  Partition the total trajectory of length $T$ into $M$ non-overlapping blocks, each of length $L = T/M$.\n2.  Calculate the average of the observable for each block, yielding a set of block averages $\\{\\bar{A}^{(1)}, \\bar{A}^{(2)}, \\dots, \\bar{A}^{(M)}\\}$.\n3.  Critically, the block length $L$ must be chosen to be much larger than the integrated autocorrelation time, $L \\gg \\tau_{\\mathrm{int}}$. This ensures that correlations between successive blocks are negligible, making the block averages $\\{\\bar{A}^{(m)}\\}$ approximately i.i.d. random variables.\n4.  Since the block averages are now effectively independent, the standard statistical formulas apply to them. The overall mean is $\\bar{A} = \\frac{1}{M} \\sum_{m=1}^M \\bar{A}^{(m)}$.\n5.  An unbiased estimate of the variance of the block averages is $\\hat{\\sigma}_{\\bar{A}^{(m)}}^2 = \\frac{1}{M-1} \\sum_{m=1}^M (\\bar{A}^{(m)} - \\bar{A})^2$.\n6.  The variance of the overall mean is then estimated as $\\widehat{\\mathrm{Var}}(\\bar{A}) = \\frac{\\hat{\\sigma}_{\\bar{A}^{(m)}}^2}{M}$. The standard error is the square root of this value.\n7.  To ensure $L$ is large enough, one should calculate the estimated error for several increasing values of $L$. The error estimate will be erroneously small for small $L$ (where block averages are still correlated) and will increase and plateau at a constant value once $L \\gg \\tau_{\\mathrm{int}}$. This plateau value is the correct uncertainty estimate.\n\nThis procedure applies directly to the $g(r)$ bin value. For the diffusion coefficient $D$, which is derived from the slope of the MSD, the same principle is adapted:\n1.  Partition the trajectory into $M$ blocks of length $L \\gg \\tau_D$, where $\\tau_D$ is the correlation time relevant to diffusion.\n2.  For each block $m$, calculate an independent estimate of the diffusion coefficient, $D^{(m)}$, by computing the MSD within that block and finding its slope. The MSD fit must use lag times $\\tau$ that are much smaller than the block length $L$ (to have good statistics for the MSD itself) but large enough to be in the Fickian (linear) diffusion regime.\n3.  Treat the set $\\{D^{(1)}, D^{(2)}, \\dots, D^{(M)}\\}$ as i.i.d. samples and calculate the mean and standard error as described above.\n\n**3. Evaluation of Options**\n\n**Option A:** This option suggests treating all $N = T/\\Delta t = 2 \\times 10^6$ frames as independent. This is fundamentally wrong as it ignores the strong time correlations ($\\tau_c / \\Delta t = 500$), leading to a massive underestimation of the true uncertainty. The justification for the MSD analysis is also incorrect; averaging over time origins improves the statistics of the MSD curve but does not remove the correlations between MSD points at different lag times, making standard linear regression error estimates invalid.\n**Verdict:** **Incorrect**.\n\n**Option B:** This option precisely describes the correct block-averaging procedure.\n-   It correctly identifies the condition $L \\gg \\tau_{\\mathrm{int}}$ (suggesting $L \\approx 100\\,\\mathrm{ps}$, which is $20$ times the given $\\tau_c \\approx 5\\,\\mathrm{ps}$).\n-   It correctly outlines the process of partitioning into non-overlapping blocks, computing block means, and then calculating the variance of the overall mean from the sample variance of the block means using the appropriate $M-1$ denominator.\n-   It includes the crucial step of checking for the plateau in the estimated error as $L$ increases.\n-   It correctly adapts the procedure for the diffusion coefficient $D$ by computing block-wise estimates $D^{(m)}$ and performing the same statistical analysis.\n**Verdict:** **Correct**.\n\n**Option C:** This option proposes using overlapping blocks of length $L \\approx \\tau_c$. This block length is too short; the block averages will remain correlated, and the error will be underestimated. While methods for overlapping blocks exist, they are more complex than simply treating the block means as independent. Using the number of overlapping blocks as the degrees of freedom is an incorrect simplification.\n**Verdict:** **Incorrect**.\n\n**Option D:** This option makes the patently false claim that $N_{\\mathrm{eff}} = N$ and that correlations can be ignored. The reasoning that boundedness implies weak correlations is fallacious. For the diffusion coefficient, it suggests a standard bootstrap by resampling individual time points. This is incorrect for a correlated time series because it destroys the temporal correlation structure. The correct method would be a *block bootstrap*, which is a resampling analogue of the block-averaging method in Option B.\n**Verdict:** **Incorrect**.",
            "answer": "$$\\boxed{B}$$"
        }
    ]
}