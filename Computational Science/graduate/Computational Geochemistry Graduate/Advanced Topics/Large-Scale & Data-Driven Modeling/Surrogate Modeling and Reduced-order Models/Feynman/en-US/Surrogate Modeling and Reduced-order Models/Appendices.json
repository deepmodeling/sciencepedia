{
    "hands_on_practices": [
        {
            "introduction": "Effective model reduction begins not with algorithms, but with a deep understanding of the underlying physical system. This first practice focuses on using nondimensionalization to distill the complex interplay of advection, dispersion, and reaction into key dimensionless groups, the Peclet ($\\mathrm{Pe}$) and Damkohler ($\\mathrm{Da}$) numbers. By completing this exercise , you will gain firsthand insight into how these numbers reveal the inherent characteristics of a transport problem—such as the presence of sharp fronts or stiff reaction dynamics—which are critical for anticipating challenges in surrogate model training and ensuring the stability of a reduced-order model.",
            "id": "4102078",
            "problem": "A one-dimensional saturated porous column of length $L$ transports and reacts a dissolved species with concentration $c(x,t)$ under steady flow. The governing transport arises from conservation of mass, linear advection, Fickian dispersion, and a first-order reaction. Let the Darcy velocity be $q$ and the porosity be $\\phi$, so that the interstitial (pore) velocity is $u = q/\\phi$. The effective hydrodynamic dispersion coefficient is $D$ (assumed constant), and the homogeneous first-order reaction rate constant is $k$ (assumed constant). The dimensional governing equation for $c(x,t)$ on $x \\in [0,L]$ and $t \\ge 0$ is obtained from mass conservation and linear flux laws, with an inlet Dirichlet boundary condition $c(0,t) = C_{\\mathrm{in}}$ and an outlet convective boundary condition at $x=L$. Assume an initially solute-free column $c(x,0)=0$.\n\nStarting from these physical statements and without invoking any pre-derived dimensionless formulas, perform a nondimensionalization of the governing equation using a characteristic length $L$, an inlet concentration $C_{\\mathrm{in}}$, and a time scale consistent with the advective transport implied by $u$. Identify, in closed form, the Peclet number $\\mathrm{Pe}$ and the Damkohler number $\\mathrm{Da}$ that arise from this nondimensionalization.\n\nThen, using the resulting dimensionless model, discuss from first principles how the magnitudes of $\\mathrm{Pe}$ and $\\mathrm{Da}$ influence (i) the smoothness of the parameter-to-solution map that surrogate models attempt to learn, and (ii) the stability properties of Reduced-Order Models (ROMs), such as those built by Proper Orthogonal Decomposition (POD) and Galerkin projection. Your discussion should connect the physical interpretation of $\\mathrm{Pe}$ and $\\mathrm{Da}$ to expected features in the solution (e.g., fronts, boundary layers, stiffness, non-normality) and to qualitative stability constraints in time integration.\n\nProvide your final answer as the row matrix containing the analytic expressions for $\\mathrm{Pe}$ and $\\mathrm{Da}$ in terms of $u$, $L$, $D$, and $k$. No numerical evaluation is required. Because the final answer is dimensionless, no unit specification is needed.",
            "solution": "The appropriate starting point is the local conservation of mass for the dissolved species in a saturated porous medium, which balances accumulation, advection, dispersion, and reaction. With constant porosity $\\phi$, Darcy velocity $q$, interstitial velocity $u = q/\\phi$, dispersion coefficient $D$, and first-order reaction rate $k$, the dimensional conservation equation for the aqueous concentration $c(x,t)$ is\n$$\n\\phi \\frac{\\partial c}{\\partial t} + \\frac{\\partial}{\\partial x}\\left(q\\,c - \\phi D \\frac{\\partial c}{\\partial x}\\right) \\;=\\; -\\phi k\\,c.\n$$\nAssuming $\\phi$ is constant and dividing by $\\phi$ yields\n$$\n\\frac{\\partial c}{\\partial t} + \\frac{\\partial}{\\partial x}\\left(u\\,c - D \\frac{\\partial c}{\\partial x}\\right) \\;=\\; -k\\,c,\n$$\nwhere $u \\equiv q/\\phi$ is the pore velocity. With constant $u$ and $D$ and neglecting spatial variability in coefficients, expanding the spatial derivative gives the linear advection–dispersion–reaction equation\n$$\n\\frac{\\partial c}{\\partial t} + u \\frac{\\partial c}{\\partial x} \\;=\\; D \\frac{\\partial^{2} c}{\\partial x^{2}} \\;-\\; k\\,c.\n$$\nBoundary conditions are $c(0,t) = C_{\\mathrm{in}}$ and a convective (or zero-diffusive-flux) outlet at $x=L$, and the initial condition is $c(x,0) = 0$.\n\nTo nondimensionalize, introduce characteristic scales for length, time, and concentration. Take the column length $L$ as the characteristic length and the inlet concentration $C_{\\mathrm{in}}$ as the concentration scale. A physically meaningful advective time scale is the residence time based on pore velocity $u$, namely $T = L/u$. Define dimensionless variables\n$$\nx \\;=\\; L\\,\\xi,\\qquad t \\;=\\; T\\,\\tau \\;=\\; \\frac{L}{u}\\,\\tau,\\qquad c(x,t) \\;=\\; C_{\\mathrm{in}}\\,\\hat{c}(\\xi,\\tau).\n$$\nCompute derivatives under this change of variables:\n$$\n\\frac{\\partial c}{\\partial t} \\;=\\; C_{\\mathrm{in}} \\frac{\\partial \\hat{c}}{\\partial \\tau} \\frac{\\partial \\tau}{\\partial t} \\;=\\; C_{\\mathrm{in}} \\frac{\\partial \\hat{c}}{\\partial \\tau} \\frac{u}{L},\\qquad\n\\frac{\\partial c}{\\partial x} \\;=\\; C_{\\mathrm{in}} \\frac{\\partial \\hat{c}}{\\partial \\xi} \\frac{\\partial \\xi}{\\partial x} \\;=\\; C_{\\mathrm{in}} \\frac{1}{L} \\frac{\\partial \\hat{c}}{\\partial \\xi},\n$$\nand\n$$\n\\frac{\\partial^{2} c}{\\partial x^{2}} \\;=\\; C_{\\mathrm{in}} \\frac{1}{L^{2}} \\frac{\\partial^{2} \\hat{c}}{\\partial \\xi^{2}}.\n$$\nSubstitute these into the dimensional equation:\n$$\nC_{\\mathrm{in}} \\frac{u}{L} \\frac{\\partial \\hat{c}}{\\partial \\tau} \\;+\\; u\\, C_{\\mathrm{in}} \\frac{1}{L} \\frac{\\partial \\hat{c}}{\\partial \\xi}\n\\;=\\;\nD\\, C_{\\mathrm{in}} \\frac{1}{L^{2}} \\frac{\\partial^{2} \\hat{c}}{\\partial \\xi^{2}} \\;-\\; k\\, C_{\\mathrm{in}} \\hat{c}.\n$$\nDivide through by $C_{\\mathrm{in}}$ and multiply both sides by $L/u$ to obtain the dimensionless form\n$$\n\\frac{\\partial \\hat{c}}{\\partial \\tau} \\;+\\; \\frac{\\partial \\hat{c}}{\\partial \\xi}\n\\;=\\;\n\\left(\\frac{D}{u L}\\right) \\frac{\\partial^{2} \\hat{c}}{\\partial \\xi^{2}} \\;-\\; \\left(\\frac{k L}{u}\\right) \\hat{c}.\n$$\nIdentify the standard dimensionless groups by defining\n$$\n\\mathrm{Pe} \\;\\equiv\\; \\frac{u L}{D},\\qquad \\mathrm{Da} \\;\\equiv\\; \\frac{k L}{u}.\n$$\nThen the nondimensional governing equation reads\n$$\n\\frac{\\partial \\hat{c}}{\\partial \\tau} \\;+\\; \\frac{\\partial \\hat{c}}{\\partial \\xi}\n\\;=\\;\n\\frac{1}{\\mathrm{Pe}} \\frac{\\partial^{2} \\hat{c}}{\\partial \\xi^{2}} \\;-\\; \\mathrm{Da}\\, \\hat{c}.\n$$\nThe inlet boundary condition becomes $\\hat{c}(0,\\tau) = 1$, the initial condition is $\\hat{c}(\\xi,0) = 0$, and the outlet convective boundary condition remains consistent in dimensionless form.\n\nInfluence of $\\mathrm{Pe}$ and $\\mathrm{Da}$ on surrogate smoothness and Reduced-Order Model (ROM) stability can be assessed from the dimensionless operator structure. The dimensionless spatial operator is\n$$\n\\mathcal{L} \\hat{c} \\;=\\; - \\frac{\\partial \\hat{c}}{\\partial \\xi} \\;+\\; \\frac{1}{\\mathrm{Pe}} \\frac{\\partial^{2} \\hat{c}}{\\partial \\xi^{2}} \\;-\\; \\mathrm{Da}\\, \\hat{c},\n$$\nand the evolution equation is $\\partial \\hat{c}/\\partial \\tau = \\mathcal{L}\\hat{c}$. When $\\mathrm{Pe}$ is large, the diffusion term $\\frac{1}{\\mathrm{Pe}} \\partial^{2}_{\\xi} \\hat{c}$ is weak relative to advection. This produces sharp advective fronts and thin boundary layers, making the parameter-to-solution map less smooth with respect to inputs such as $u$, $D$, and $k$. Surrogates such as Gaussian process regressors or neural networks rely on smoothness to generalize; high $\\mathrm{Pe}$ reduces differentiability and increases local curvature, requiring denser training samples near fronts to resolve the solution manifold. Conversely, when $\\mathrm{Pe}$ is small, diffusion dominates, fronts are smeared, and the solution varies more smoothly with parameters, easing surrogate learning.\n\nThe Damkohler number $\\mathrm{Da}$ compares reaction to advection. Large $\\mathrm{Da}$ implies strong reaction over an advective time scale, which can introduce stiff decay terms and reaction-induced boundary layers near the inlet where $\\hat{c}$ is forced to $1$. Stiffness manifests as widely separated time scales in $\\partial \\hat{c}/\\partial \\tau = \\mathcal{L}\\hat{c}$: eigenvalues associated with the reaction term $-\\mathrm{Da}\\,\\hat{c}$ shift the spectrum leftward by approximately $-\\mathrm{Da}$, increasing the magnitude of negative eigenvalues and creating rapid transients. This reduces the smoothness of the parameter-to-solution map with respect to $k$ and can challenge surrogates that assume slowly varying outputs.\n\nFor Reduced-Order Models built by Proper Orthogonal Decomposition (POD) and Galerkin projection, stability is governed by the reduced operator’s spectrum and non-normality. The diffusion term contributes negative definite symmetric components that are stabilizing, proportional to $1/\\mathrm{Pe}$. The advection term is skew-adjoint in continuous form but becomes non-normal under discretization, which can exhibit transient growth even when asymptotically stable; higher $\\mathrm{Pe}$ enhances non-normal effects because dissipation is weaker, making ROMs more sensitive to projection errors and mode truncation. The reaction term adds a diagonal negative component of magnitude $\\mathrm{Da}$, which is asymptotically stabilizing but increases stiffness. For explicit time integration of the ROM, qualitative stability constraints in dimensionless time step $\\Delta \\tau$ reflect the strongest of advective, diffusive, and reactive restrictions, such as\n$$\n\\Delta \\tau \\;\\lesssim\\; \\min\\left\\{\\, \\Delta \\xi,\\; \\frac{\\mathrm{Pe}\\,\\Delta \\xi^{2}}{2},\\; \\frac{1}{\\mathrm{Da}} \\,\\right\\},\n$$\nwhere $\\Delta \\xi$ is a characteristic dimensionless spatial resolution of the ROM modes; large $\\mathrm{Pe}$ and large $\\mathrm{Da}$ tighten these bounds. Thus, increasing $\\mathrm{Pe}$ tends to decrease surrogate smoothness and ROM robustness to truncation, while increasing $\\mathrm{Da}$ increases stiffness, demanding either implicit integration or stabilized ROM formulations.\n\nThe requested dimensionless groups are therefore\n$$\n\\mathrm{Pe} \\;=\\; \\frac{u L}{D},\\qquad \\mathrm{Da} \\;=\\; \\frac{k L}{u}.\n$$\nProviding them as the final row matrix meets the specification.",
            "answer": "$$\\boxed{\\begin{pmatrix}\\frac{u L}{D} & \\frac{k L}{u}\\end{pmatrix}}$$"
        },
        {
            "introduction": "Once the system's characteristics are understood, the next step is to construct an efficient model. This practice delves into a core challenge of building projection-based Reduced-Order Models (ROMs): selecting the right level of complexity. Using data from a Proper Orthogonal Decomposition (POD), you will learn to move beyond simple heuristics like \"energy capture\" and apply a rigorous, goal-oriented criterion to choose the number of modes ($r$) needed to guarantee a desired accuracy for a specific output of interest . This exercise is fundamental to mastering the trade-off between computational cost and predictive precision that defines model order reduction.",
            "id": "4101999",
            "problem": "A reactive transport model for aqueous carbonate chemistry in a 3-dimensional porous column is discretized to $n$ spatial degrees of freedom, yielding a Full-Order Model (FOM) of dimension $n$ governed by advection–diffusion–reaction. The concentration field $C(\\boldsymbol{x},t)$ evolves according to mass conservation and linear transport, with reaction kinetics captured by a spatially distributed source term obeying Arrhenius-type rate laws. A Reduced-Order Model (ROM) is constructed via Proper Orthogonal Decomposition (POD) using the Singular Value Decomposition (SVD) of a snapshot matrix $X \\in \\mathbb{R}^{n \\times m}$ formed from $m$ state snapshots of the discrete concentration vector $\\boldsymbol{c}(t) \\in \\mathbb{R}^n$. The output of interest is the effluent alkalinity at the column outlet at final time $t_f$, modeled as a linear functional $y = \\boldsymbol{w}^\\top \\boldsymbol{c}(t_f)$, where $\\boldsymbol{w} \\in \\mathbb{R}^n$ encodes quadrature weights over the outlet plane.\n\nAssume the following calibrated, physically consistent information is available:\n- The discretization size is $n = 200{,}000$ and the snapshot SVD yields ordered singular values $\\sigma_1 = 9.0$, $\\sigma_2 = 3.0$, $\\sigma_3 = 1.0$, $\\sigma_4 = 0.35$, $\\sigma_5 = 0.12$, $\\sigma_6 = 0.04$, $\\sigma_7 = 0.015$, $\\sigma_8 = 0.006$, with negligible subsequent values.\n- The measurement vector has Euclidean norm $\\lVert \\boldsymbol{w} \\rVert_2 = 0.5$.\n- The desired tolerance on the output of interest is $\\varepsilon_y = 0.1$.\n- The online computational cost per time step for the FOM scales as $C_{\\text{FOM}} = \\alpha n$ with $\\alpha = 50$. The ROM employs Galerkin projection and hyper-reduction via the Discrete Empirical Interpolation Method (DEIM), with online cost per time step $C_{\\text{ROM}} = \\beta r^2 + \\gamma q$, where $r$ is the number of retained POD modes, $q = 25$ is the number of DEIM sample points, and $\\beta = 300$, $\\gamma = 500$.\n\nStarting from first principles and well-tested facts:\n- The SVD optimality of rank-$r$ approximations in the Frobenius norm,\n- Linear functional stability bounds for outputs induced by the Euclidean norm,\n- Dimensionality scaling of algebraic operations in ROM time stepping,\n\nevaluate how the selection of $r$ affects approximation error in $y$ and the computational cost, and identify a sound criterion that uses the decay of $\\sigma_i$ and the tolerance $\\varepsilon_y$ to choose $r$. Which option correctly states such a criterion, applies it to the given data to select $r$, and consistently characterizes the resulting computational cost and error?\n\nA. Choose $r$ as the smallest integer such that $\\lVert \\boldsymbol{w} \\rVert_2 \\sqrt{\\sum_{i=r+1}^{8} \\sigma_i^2} \\le \\varepsilon_y$. With the provided data, this yields $r = 4$. Under the stated cost models, $C_{\\text{ROM}} = \\beta r^2 + \\gamma q$ and $C_{\\text{FOM}} = \\alpha n$, so the ROM per-step cost at $r = 4$ is strictly less than the FOM cost by orders of magnitude, and the output error bound is below $\\varepsilon_y$.\n\nB. Choose $r$ by requiring the captured energy fraction $\\sum_{i=1}^{r} \\sigma_i^2 \\big/ \\sum_{i=1}^{8} \\sigma_i^2 \\ge 0.998$; this yields $r = 3$. Because $99.8\\%$ of energy is captured, the output error is guaranteed to be below $\\varepsilon_y$, and the ROM cost is minimal.\n\nC. Choose $r$ as the smallest integer such that $\\sum_{i=r+1}^{8} \\sigma_i \\le \\varepsilon_y / \\lVert \\boldsymbol{w} \\rVert_2$; this yields $r = 5$. This linear tail criterion on singular values ensures the output error is below tolerance. The ROM cost will decrease roughly linearly with $r$.\n\nD. Choose $r = 4$ because cost decreases linearly with $r$ and the output error decreases linearly with $\\sum_{i=r+1}^{8} \\sigma_i$. This choice balances cost and error optimally for the given data; no norm-based bound is necessary since the singular values already indicate adequacy.",
            "solution": "The main task is to find a criterion for selecting the ROM dimension, $r$, that rigorously guarantees the error in the output of interest, $y$, is within a specified tolerance, $\\varepsilon_y$.\n\nThe error in the linear output functional $y = \\boldsymbol{w}^\\top \\boldsymbol{c}(t_f)$ due to the ROM approximation $\\boldsymbol{c}_r(t_f)$ is $\\Delta y = \\boldsymbol{w}^\\top (\\boldsymbol{c}(t_f) - \\boldsymbol{c}_r(t_f))$. Using the Cauchy-Schwarz inequality, this error can be bounded:\n$$ |\\Delta y| \\le \\lVert \\boldsymbol{w} \\rVert_2 \\lVert \\boldsymbol{c}(t_f) - \\boldsymbol{c}_r(t_f) \\rVert_2 $$\nA standard *a priori* error estimate from POD theory bounds the squared norm of the solution error by the sum of the squared neglected singular values:\n$$ \\lVert \\boldsymbol{c}(t_f) - \\boldsymbol{c}_r(t_f) \\rVert_2^2 \\le \\sum_{i=r+1}^{m} \\sigma_i^2 $$\nCombining these gives a goal-oriented error bound on the output:\n$$ |\\Delta y| \\le \\lVert \\boldsymbol{w} \\rVert_2 \\sqrt{\\sum_{i=r+1}^{m} \\sigma_i^2} $$\nTo meet the tolerance $\\varepsilon_y$, we must choose the smallest integer $r$ that satisfies $\\lVert \\boldsymbol{w} \\rVert_2 \\sqrt{\\sum_{i=r+1}^{m} \\sigma_i^2} \\le \\varepsilon_y$. This is precisely the criterion stated in option A.\n\nApplying the given data ($\\lVert \\boldsymbol{w} \\rVert_2 = 0.5$, $\\varepsilon_y = 0.1$, and the provided singular values):\n$$ 0.5 \\sqrt{\\sum_{i=r+1}^{8} \\sigma_i^2} \\le 0.1 \\implies \\sum_{i=r+1}^{8} \\sigma_i^2 \\le (0.2)^2 = 0.04 $$\n- For $r=3$, the sum is $\\sum_{i=4}^{8} \\sigma_i^2 = 0.35^2 + 0.12^2 + 0.04^2 + 0.015^2 + 0.006^2 \\approx 0.1388 > 0.04$.\n- For $r=4$, the sum is $\\sum_{i=5}^{8} \\sigma_i^2 = 0.12^2 + 0.04^2 + 0.015^2 + 0.006^2 \\approx 0.0163 \\le 0.04$.\nThus, the smallest required dimension is $r=4$. The computational cost for the ROM is $C_{\\text{ROM}} = 300(4^2) + 500(25) = 17{,}300$, which is several orders of magnitude smaller than the FOM cost of $C_{\\text{FOM}} = 50(200{,}000) = 10{,}000{,}000$. Option A is fully consistent with this analysis.\n\nThe other options are incorrect:\n- **Option B** uses a generic energy-capture heuristic, which is not goal-oriented and provides no guarantee for the specific output error.\n- **Option C** uses a mathematically incorrect error bound (sum of $\\sigma_i$ instead of root-sum-square) and incorrectly states that cost decreases with $r$.\n- **Option D** also incorrectly describes cost scaling and dismisses the need for a rigorous, norm-based bound, which contradicts the principles of robust model reduction.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "A reduced-order model that is fast but physically inconsistent has limited value. This final practice addresses an advanced but critical topic: ensuring that your ROM respects fundamental physical laws, such as mass conservation. Standard Galerkin projection does not inherently guarantee this, so this exercise  will guide you through the powerful technique of using Lagrange multipliers to enforce linear constraints on the reduced system. By deriving and solving the resulting Karush-Kuhn-Tucker (KKT) system, you will learn how to build ROMs that are not only computationally cheap but also physically robust and trustworthy.",
            "id": "4102010",
            "problem": "A reduced-order model is constructed for a three-component geochemical transport system in a closed, no-flux domain. The semi-discrete full-order mass balance for the concentration vector $\\mathbf{c}(t) \\in \\mathbb{R}^{3}$ is governed by the linear system $ \\mathbf{M} \\, \\frac{d \\mathbf{c}}{dt} = \\mathbf{A} \\, \\mathbf{c} + \\mathbf{b}$, where $\\mathbf{M} \\in \\mathbb{R}^{3 \\times 3}$ is a symmetric positive-definite mass matrix (reflecting accumulation/porosity and control-volume scaling), $\\mathbf{A} \\in \\mathbb{R}^{3 \\times 3}$ is the spatial operator, and $\\mathbf{b} \\in \\mathbb{R}^{3}$ is a source term. Assume a backward (implicit) Euler time discretization from time $t^{k}$ to $t^{k+1} = t^{k} + \\Delta t$ yields\n$$\n\\left( \\frac{\\mathbf{M}}{\\Delta t} - \\mathbf{A} \\right) \\mathbf{c}^{k+1} = \\frac{\\mathbf{M}}{\\Delta t} \\mathbf{c}^{k} + \\mathbf{b}.\n$$\nTo build a reduced-order model, approximate $\\mathbf{c}^{k+1} \\approx \\mathbf{c}_{\\mathrm{ref}} + \\mathbf{V} \\mathbf{a}^{k+1}$, where $\\mathbf{V} \\in \\mathbb{R}^{3 \\times r}$ is a reduced basis with $r=2$, $\\mathbf{a}^{k+1} \\in \\mathbb{R}^{2}$ are reduced coordinates, and $\\mathbf{c}_{\\mathrm{ref}} \\in \\mathbb{R}^{3}$ is a reference state. To ensure physically consistent predictions, impose both global and local mass conservation constraints of the form\n$$\n\\mathbf{S} \\, \\mathbf{c}^{k+1} = \\mathbf{s},\n$$\nwhere $\\mathbf{S} \\in \\mathbb{R}^{p \\times 3}$ encodes $p=2$ independent conservation constraints: a global conserved quantity (e.g., total moles of a conserved element) and a local conserved quantity in a subdomain with zero flux. Two approaches to enforce these constraints in the reduced-order model are considered: augmenting the basis with conserved directions or introducing Lagrange multipliers.\n\nStarting from the mass balance law and the implicit Euler discretization, derive the constrained reduced system using the Lagrange multiplier approach. Write the Karush–Kuhn–Tucker (KKT) system explicitly in terms of the reduced stiffness matrix, the constraint matrix in reduced coordinates, the reduced right-hand side, and the constraint targets. Then, for the specific data\n$$\n\\mathbf{M} = \\mathrm{diag}(2,1,1), \\quad \\mathbf{A} = \\mathbf{0}, \\quad \\Delta t = 1, \\quad \\mathbf{b} = \\mathbf{0}, \\quad \\mathbf{c}^{k} = \\begin{pmatrix} 1 \\\\ 2 \\\\ 0 \\end{pmatrix}, \\quad \\mathbf{c}_{\\mathrm{ref}} = \\mathbf{0},\n$$\nreduced basis\n$$\n\\mathbf{V} = \\begin{pmatrix}\n1 & 0 \\\\\n1 & 1 \\\\\n0 & 1\n\\end{pmatrix},\n$$\nand conservation operators and targets\n$$\n\\mathbf{S} = \\begin{pmatrix}\n1 & 1 & 1 \\\\\n0 & 0 & 1\n\\end{pmatrix}, \\quad \\mathbf{s} = \\begin{pmatrix}\n\\mathbf{1}^{\\top} \\mathbf{c}^{k} \\\\\n\\mathbf{e}_{3}^{\\top} \\mathbf{c}^{k}\n\\end{pmatrix} = \\begin{pmatrix}\n3 \\\\\n0\n\\end{pmatrix},\n$$\nsolve the constrained reduced KKT system to obtain the first reduced coefficient $a^{k+1}_{1}$. Express your final answer as an exact fraction, with no units. No rounding is required. Define any acronyms upon first use, including Reduced-Order Model (ROM) and Karush–Kuhn–Tucker (KKT).",
            "solution": "The goal is to find the reduced coordinates $\\mathbf{a}^{k+1}$ that solve the time-discretized system while satisfying the specified conservation laws. This is a constrained optimization problem that can be solved using the method of Lagrange multipliers.\n\nFirst, we define the reduced system. The implicit Euler-discretized full-order system is $\\mathbf{L} \\mathbf{c}^{k+1} = \\mathbf{f}$, where the system matrix is $\\mathbf{L} = \\frac{\\mathbf{M}}{\\Delta t} - \\mathbf{A}$ and the right-hand side is $\\mathbf{f} = \\frac{\\mathbf{M}}{\\Delta t} \\mathbf{c}^{k} + \\mathbf{b}$. Substituting the Reduced-Order Model (ROM) approximation $\\mathbf{c}^{k+1} = \\mathbf{c}_{\\mathrm{ref}} + \\mathbf{V} \\mathbf{a}^{k+1}$ and applying a Galerkin projection (left-multiplying by $\\mathbf{V}^{\\top}$) gives the unconstrained reduced system $\\mathbf{L}_r \\mathbf{a}^{k+1} = \\mathbf{f}_r$, where:\n- Reduced stiffness matrix: $\\mathbf{L}_r = \\mathbf{V}^{\\top} \\mathbf{L} \\mathbf{V} = \\mathbf{V}^{\\top} \\left( \\frac{\\mathbf{M}}{\\Delta t} - \\mathbf{A} \\right) \\mathbf{V}$.\n- Reduced right-hand side: $\\mathbf{f}_r = \\mathbf{V}^{\\top} (\\mathbf{f} - \\mathbf{L} \\mathbf{c}_{\\mathrm{ref}})$.\n\nNext, we express the linear conservation constraints $\\mathbf{S} \\mathbf{c}^{k+1} = \\mathbf{s}$ in terms of the reduced coordinates. Substituting the ROM approximation gives $(\\mathbf{S} \\mathbf{V}) \\mathbf{a}^{k+1} = \\mathbf{s} - \\mathbf{S} \\mathbf{c}_{\\mathrm{ref}}$, which we write as $\\mathbf{S}_r \\mathbf{a}^{k+1} = \\mathbf{s}_r$, where:\n- Reduced constraint matrix: $\\mathbf{S}_r = \\mathbf{S} \\mathbf{V}$.\n- Reduced constraint targets: $\\mathbf{s}_r = \\mathbf{s} - \\mathbf{S} \\mathbf{c}_{\\mathrm{ref}}$.\n\nThe problem is to solve for $\\mathbf{a}^{k+1}$ from the reduced system, subject to the reduced constraints. The Lagrangian function $\\mathcal{L}$ for this problem is:\n$$ \\mathcal{L}(\\mathbf{a}^{k+1}, \\boldsymbol{\\lambda}) = \\frac{1}{2} (\\mathbf{a}^{k+1})^{\\top} \\mathbf{L}_r \\mathbf{a}^{k+1} - (\\mathbf{f}_r)^{\\top} \\mathbf{a}^{k+1} + \\boldsymbol{\\lambda}^{\\top} (\\mathbf{S}_r \\mathbf{a}^{k+1} - \\mathbf{s}_r) $$\nwhere $\\boldsymbol{\\lambda}$ is the vector of Lagrange multipliers. The solution is at the stationary point of the Lagrangian, given by the Karush–Kuhn–Tucker (KKT) conditions, which form the following block matrix system:\n$$ \\begin{pmatrix} \\mathbf{L}_r & \\mathbf{S}_r^{\\top} \\\\ \\mathbf{S}_r & \\mathbf{0} \\end{pmatrix} \\begin{pmatrix} \\mathbf{a}^{k+1} \\\\ \\boldsymbol{\\lambda} \\end{pmatrix} = \\begin{pmatrix} \\mathbf{f}_r \\\\ \\mathbf{s}_r \\end{pmatrix} $$\n\nNow, we substitute the provided numerical data:\n$ \\mathbf{M} = \\mathrm{diag}(2,1,1), \\mathbf{A} = \\mathbf{0}, \\Delta t = 1, \\mathbf{b} = \\mathbf{0}, \\mathbf{c}^{k} = \\begin{pmatrix} 1 \\\\ 2 \\\\ 0 \\end{pmatrix}, \\mathbf{c}_{\\mathrm{ref}} = \\mathbf{0}, \\mathbf{V} = \\begin{pmatrix} 1 & 0 \\\\ 1 & 1 \\\\ 0 & 1 \\end{pmatrix}, \\mathbf{S} = \\begin{pmatrix} 1 & 1 & 1 \\\\ 0 & 0 & 1 \\end{pmatrix}, \\mathbf{s} = \\begin{pmatrix} 3 \\\\ 0 \\end{pmatrix} $.\n\n1.  Calculate $\\mathbf{L}_r$: Since $\\mathbf{A}=\\mathbf{0}$, $\\mathbf{L} = \\mathbf{M}$.\n    $$ \\mathbf{L}_r = \\mathbf{V}^{\\top} \\mathbf{M} \\mathbf{V} = \\begin{pmatrix} 1 & 1 & 0 \\\\ 0 & 1 & 1 \\end{pmatrix} \\begin{pmatrix} 2 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 1 & 1 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 3 & 1 \\\\ 1 & 2 \\end{pmatrix} $$\n\n2.  Calculate $\\mathbf{f}_r$: Since $\\mathbf{c}_{\\mathrm{ref}} = \\mathbf{0}$ and $\\mathbf{b} = \\mathbf{0}$, $\\mathbf{f}_r = \\mathbf{V}^{\\top} \\mathbf{M} \\mathbf{c}^{k}$.\n    $$ \\mathbf{f}_r = \\begin{pmatrix} 1 & 1 & 0 \\\\ 0 & 1 & 1 \\end{pmatrix} \\begin{pmatrix} 2 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 1 & 0 \\\\ 0 & 1 & 1 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 2 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 4 \\\\ 2 \\end{pmatrix} $$\n\n3.  Calculate $\\mathbf{S}_r$:\n    $$ \\mathbf{S}_r = \\mathbf{S} \\mathbf{V} = \\begin{pmatrix} 1 & 1 & 1 \\\\ 0 & 0 & 1 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 1 & 1 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 2 & 2 \\\\ 0 & 1 \\end{pmatrix} $$\n\n4.  Calculate $\\mathbf{s}_r$: Since $\\mathbf{c}_{\\mathrm{ref}} = \\mathbf{0}$, $\\mathbf{s}_r = \\mathbf{s} = \\begin{pmatrix} 3 \\\\ 0 \\end{pmatrix}$.\n\n5.  Assemble and solve the KKT system with $\\mathbf{a}^{k+1} = (a_1, a_2)^\\top$:\n    $$ \\left( \\begin{array}{cc|cc} 3 & 1 & 2 & 0 \\\\ 1 & 2 & 2 & 1 \\\\ \\hline 2 & 2 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\end{array} \\right) \\begin{pmatrix} a_1 \\\\ a_2 \\\\ \\lambda_1 \\\\ \\lambda_2 \\end{pmatrix} = \\begin{pmatrix} 4 \\\\ 2 \\\\ 3 \\\\ 0 \\end{pmatrix} $$\n    This is a system of four linear equations:\n    (1) $3a_1 + a_2 + 2\\lambda_1 = 4$\n    (2) $a_1 + 2a_2 + 2\\lambda_1 + \\lambda_2 = 2$\n    (3) $2a_1 + 2a_2 = 3$\n    (4) $a_2 = 0$\n\n    From equation (4), we have $a_2 = 0$.\n    Substituting $a_2 = 0$ into equation (3):\n    $$ 2a_1 + 2(0) = 3 \\implies 2a_1 = 3 \\implies a_1 = \\frac{3}{2} $$\n    The problem asks for the first reduced coefficient, $a^{k+1}_{1}$, which is $a_1$.",
            "answer": "$$\\boxed{\\frac{3}{2}}$$"
        }
    ]
}