{
    "hands_on_practices": [
        {
            "introduction": "标准的随机游走Metropolis等MCMC方法在处理高维问题时效率可能较低。为了提升采样效率，我们可以利用目标分布的几何信息来指导采样过程。本练习将介绍Metropolis调整的朗之万算法（MALA），该算法利用后验概率的梯度信息（即后验“地形”的坡度）来提出更智能的移动方向，从而更有效地探索参数空间。通过从朗之万随机微分方程（SDE）出发，推导MALA的提议分布和接受概率，您将深刻理解基于梯度的采样器的工作原理，并将其应用于一个具体的计算实例中。 ",
            "id": "3289331",
            "problem": "计算系统生物学中的一个核心任务是根据含噪声观测，对基因调控的随机模型进行参数推断。考虑一个双参数转录-降解模型，其参数矢量 $\\theta \\in \\mathbb{R}^{2}$ 上的贝叶斯后验是光滑且严格为正的。假设我们希望构建一个马尔可夫链蒙特卡洛（MCMC）方法，该方法使用受过阻尼朗之万随机微分方程（SDE）启发的动力学来对该后验进行抽样。针对目标密度 $\\pi(\\theta)$ 的过阻尼朗之万 SDE 由下式给出\n$$\nd\\theta_{t} \\;=\\; \\frac{1}{2}\\,\\nabla \\log \\pi(\\theta_{t})\\,dt \\;+\\; dW_{t},\n$$\n其中 $W_{t}$ 是一个标准的二维维纳过程，$\\nabla \\log \\pi(\\theta)$ 表示关于 $\\theta$ 的梯度。\n\n任务：\n- 仅从上述 SDE 和 Metropolis-Hastings (MH) 算法的基本定义出发，推导出一个形式为 $\\theta' = \\theta + \\frac{\\delta^{2}}{2}\\,\\nabla \\log \\pi(\\theta) + \\delta\\,\\eta$（其中 $\\eta \\sim \\mathcal{N}(0, I)$）的提议机制，并根据 $\\pi$、当前状态 $\\theta$、提议状态 $\\theta'$ 和高斯提议密度推导相应的 MH 接受概率。在首次出现时定义你所引入的任何缩写词。\n\n然后，将问题具体化到以下由随机基因表达模型的线性高斯近似产生的、具有科学真实性的后验。后验 $\\pi(\\theta)$ 与一个均值为 $\\mu$、协方差为 $\\Sigma$ 的高斯密度成正比：\n$$\n\\pi(\\theta) \\;\\propto\\; \\exp\\!\\left(-\\frac{1}{2}(\\theta - \\mu)^{\\top}\\Sigma^{-1}(\\theta - \\mu)\\right),\n$$\n其中\n$$\n\\mu \\;=\\; \\begin{pmatrix}0.5 \\\\ -0.3\\end{pmatrix}, \n\\qquad \n\\Sigma \\;=\\; \\begin{pmatrix}0.5  0.1 \\\\ 0.1  0.4\\end{pmatrix}.\n$$\n假设当前状态为\n$$\n\\theta \\;=\\; \\begin{pmatrix}0.6 \\\\ -0.2\\end{pmatrix},\n$$\n步长参数为 $\\delta = 0.2$，实现的高斯噪声抽取为\n$$\n\\eta \\;=\\; \\begin{pmatrix}0.5 \\\\ -1.2\\end{pmatrix}.\n$$\n使用你推导的提议机制和通用的 MH 接受概率表达式，计算从 $\\theta$ 移动到提议状态 $\\theta'$ 的 Metropolis 调整的朗之万算法（MALA）接受概率。将你的最终答案表示为小数，并四舍五入到四位有效数字。",
            "solution": "该问题被评估为具有科学依据、问题明确、客观且内部一致。它提供了将马尔可夫链蒙特卡洛方法应用于贝叶斯推断问题的一个标准练习，这是计算系统生物学中的一个核心任务。所有必要的定义、数据和参数都已提供，足以推导出所要求的表达式并计算出最终的数值答案。该问题是有效的。\n\n任务是为一种特定的马尔可夫链蒙特卡洛（MCMC）方法推导提议机制和接受概率，然后将其应用于给定的贝叶斯后验。\n\n首先，我们推导提议机制。问题指定了受过阻尼朗之万随机微分方程（SDE）启发的动力学：\n$$d\\theta_{t} = \\frac{1}{2}\\nabla \\log \\pi(\\theta_{t})\\,dt + dW_{t}$$\n其中 $\\theta_t \\in \\mathbb{R}^2$ 是参数矢量，$\\pi(\\theta)$ 是目标后验密度，而 $W_t$ 是一个标准的二维维纳过程。\n\n可以使用欧拉-丸山方法获得此 SDE 的离散时间近似。我们用步长 $\\Delta t  0$ 对时间进行离散化。从时间 $t$ 的状态 $\\theta$ 到时间 $t+\\Delta t$ 的状态 $\\theta'$ 的更新为：\n$$\\theta' \\approx \\theta + \\frac{1}{2}\\nabla \\log \\pi(\\theta) \\Delta t + \\Delta W_t$$\n维纳过程的增量 $\\Delta W_t = W_{t+\\Delta t} - W_t$ 是一个均值为 0、协方差矩阵为 $(\\Delta t)I$ 的高斯随机变量，其中 $I$ 是 $2 \\times 2$ 单位矩阵。\n我们可以写成 $\\Delta W_t = \\sqrt{\\Delta t}\\,\\eta$，其中 $\\eta \\sim \\mathcal{N}(0, I)$。设步长参数为 $\\delta = \\sqrt{\\Delta t}$，因此 $\\Delta t = \\delta^2$。将此代入离散化方程，得到提议机制：\n$$\\theta' = \\theta + \\frac{\\delta^2}{2}\\nabla \\log \\pi(\\theta) + \\delta\\eta, \\quad \\eta \\sim \\mathcal{N}(0, I)$$\n这是一个从高斯提议密度 $q(\\theta'|\\theta)$ 中的抽样，该密度以 $\\theta + \\frac{\\delta^2}{2}\\nabla \\log \\pi(\\theta)$ 为中心，协方差为 $\\delta^2 I$。提议密度函数为：\n$$q(\\theta'|\\theta) = \\frac{1}{(2\\pi\\delta^2)^{2/2}} \\exp\\left( -\\frac{1}{2\\delta^2} \\left\\| \\theta' - \\left( \\theta + \\frac{\\delta^2}{2}\\nabla \\log \\pi(\\theta) \\right) \\right\\|^2 \\right)$$\n其中 $||\\cdot||$ 表示欧几里得范数。\n\n接下来，我们推导 Metropolis-Hastings (MH) 接受概率。MH 算法确保生成的马尔可夫链以 $\\pi(\\theta)$ 作为其平稳分布。从状态 $\\theta$ 移动到提议状态 $\\theta'$ 的接受概率 $\\alpha(\\theta', \\theta)$ 由下式给出：\n$$\\alpha(\\theta', \\theta) = \\min\\left(1, \\frac{\\pi(\\theta')q(\\theta|\\theta')}{\\pi(\\theta)q(\\theta'|\\theta)}\\right)$$\n项 $q(\\theta|\\theta')$ 是从 $\\theta'$ 出发提议 $\\theta$ 的密度。根据我们的提议机制，它为：\n$$q(\\theta|\\theta') = \\frac{1}{(2\\pi\\delta^2)^{2/2}} \\exp\\left( -\\frac{1}{2\\delta^2} \\left\\| \\theta - \\left( \\theta' + \\frac{\\delta^2}{2}\\nabla \\log \\pi(\\theta') \\right) \\right\\|^2 \\right)$$\n将 $q(\\theta'|\\theta)$ 和 $q(\\theta|\\theta')$ 的表达式代入接受概率公式，归一化常数相互抵消，得到：\n$$\\alpha(\\theta', \\theta) = \\min\\left(1, \\frac{\\pi(\\theta')}{\\pi(\\theta)} \\frac{\\exp\\left( -\\frac{1}{2\\delta^2} \\left\\| \\theta - \\theta' - \\frac{\\delta^2}{2}\\nabla \\log \\pi(\\theta') \\right\\|^2 \\right)}{\\exp\\left( -\\frac{1}{2\\delta^2} \\left\\| \\theta' - \\theta - \\frac{\\delta^2}{2}\\nabla \\log \\pi(\\theta) \\right\\|^2 \\right)}\\right)$$\n这种使用基于朗之万的提议并带有 MH 校正步骤的算法，被称为 Metropolis 调整的朗之万算法（MALA）。\n\n现在，我们具体化到给定的后验，它与一个多元高斯密度成正比：\n$$\\pi(\\theta) \\propto \\exp\\left(-\\frac{1}{2}(\\theta - \\mu)^{\\top}\\Sigma^{-1}(\\theta - \\mu)\\right)$$\n对数后验为 $\\log\\pi(\\theta) = C - \\frac{1}{2}(\\theta - \\mu)^{\\top}\\Sigma^{-1}(\\theta - \\mu)$，其中 $C$ 为某个常数。对数后验关于 $\\theta$ 的梯度，我们记为 $g(\\theta)$，是：\n$$g(\\theta) = \\nabla \\log \\pi(\\theta) = \\nabla_\\theta \\left( -\\frac{1}{2}(\\theta - \\mu)^{\\top}\\Sigma^{-1}(\\theta - \\mu) \\right) = -\\Sigma^{-1}(\\theta - \\mu)$$\n给定的值为：\n$$\\mu = \\begin{pmatrix}0.5 \\\\ -0.3\\end{pmatrix}, \\quad \\Sigma = \\begin{pmatrix}0.5  0.1 \\\\ 0.1  0.4\\end{pmatrix}, \\quad \\theta = \\begin{pmatrix}0.6 \\\\ -0.2\\end{pmatrix}, \\quad \\delta = 0.2, \\quad \\eta = \\begin{pmatrix}0.5 \\\\ -1.2\\end{pmatrix}$$\n首先，我们计算协方差矩阵 $\\Sigma$ 的逆矩阵：\n$$\\det(\\Sigma) = (0.5)(0.4) - (0.1)(0.1) = 0.2 - 0.01 = 0.19$$\n$$\\Sigma^{-1} = \\frac{1}{0.19} \\begin{pmatrix}0.4  -0.1 \\\\ -0.1  0.5\\end{pmatrix}$$\n接下来，我们计算提议状态 $\\theta'$：\n$$\\theta' = \\theta + \\frac{\\delta^2}{2}g(\\theta) + \\delta\\eta$$\n我们计算每一项：\n$$\\theta - \\mu = \\begin{pmatrix}0.6 \\\\ -0.2\\end{pmatrix} - \\begin{pmatrix}0.5 \\\\ -0.3\\end{pmatrix} = \\begin{pmatrix}0.1 \\\\ 0.1\\end{pmatrix}$$\n$$g(\\theta) = -\\Sigma^{-1}(\\theta - \\mu) = -\\frac{1}{0.19} \\begin{pmatrix}0.4  -0.1 \\\\ -0.1  0.5\\end{pmatrix} \\begin{pmatrix}0.1 \\\\ 0.1\\end{pmatrix} = -\\frac{1}{0.19} \\begin{pmatrix}0.03 \\\\ 0.04\\end{pmatrix}$$\n漂移项为，其中 $\\delta^2 = (0.2)^2 = 0.04$：\n$$\\frac{\\delta^2}{2}g(\\theta) = \\frac{0.04}{2} \\left( -\\frac{1}{0.19} \\begin{pmatrix}0.03 \\\\ 0.04\\end{pmatrix} \\right) = -\\frac{0.02}{0.19} \\begin{pmatrix}0.03 \\\\ 0.04\\end{pmatrix} = -\\frac{1}{19} \\begin{pmatrix}0.06 \\\\ 0.08\\end{pmatrix}$$\n扩散项为：\n$$\\delta\\eta = 0.2 \\begin{pmatrix}0.5 \\\\ -1.2\\end{pmatrix} = \\begin{pmatrix}0.1 \\\\ -0.24\\end{pmatrix}$$\n所以，提议状态为：\n$$\\theta' = \\begin{pmatrix}0.6 \\\\ -0.2\\end{pmatrix} - \\frac{1}{19} \\begin{pmatrix}0.06 \\\\ 0.08\\end{pmatrix} + \\begin{pmatrix}0.1 \\\\ -0.24\\end{pmatrix} = \\begin{pmatrix}0.7 \\\\ -0.44\\end{pmatrix} - \\begin{pmatrix}0.06/19 \\\\ 0.08/19\\end{pmatrix} = \\begin{pmatrix}13.3/19 - 0.06/19 \\\\ -8.36/19 - 0.08/19\\end{pmatrix} = \\frac{1}{19}\\begin{pmatrix}13.24 \\\\ -8.44\\end{pmatrix}$$\n\n为了计算接受概率，我们评估比率 $R = \\frac{\\pi(\\theta')q(\\theta|\\theta')}{\\pi(\\theta)q(\\theta'|\\theta)}$。使用 $\\log R$ 更为方便。对于高斯目标，梯度 $g(\\theta)$ 是 $\\theta$ 的线性函数。这导致了显著的简化。目标密度的对数比为 $\\log\\pi(\\theta') - \\log\\pi(\\theta) = \\frac{1}{2}(\\theta'-\\theta)^T(g(\\theta)+g(\\theta'))$。提议密度的对数比为 $\\log q(\\theta|\\theta') - \\log q(\\theta'|\\theta) = -\\frac{1}{2}(\\theta'-\\theta)^T(g(\\theta)+g(\\theta')) - \\frac{\\delta^2}{8}(\\|g(\\theta')\\|^2 - \\|g(\\theta)\\|^2)$。\n结合这些，接受比率的对数简化为：\n$$\\log R = - \\frac{\\delta^2}{8} \\left( \\|g(\\theta')\\|^2 - \\|g(\\theta)\\|^2 \\right)$$\n我们需要计算在 $\\theta$ 和 $\\theta'$ 处的梯度的平方范数。\n$$g(\\theta) = -\\frac{1}{0.19} \\begin{pmatrix}0.03 \\\\ 0.04\\end{pmatrix} = -\\frac{1}{19} \\begin{pmatrix}3 \\\\ 4\\end{pmatrix}$$\n$$\\|g(\\theta)\\|^2 = \\left(-\\frac{1}{19}\\right)^2 (3^2 + 4^2) = \\frac{1}{361}(9 + 16) = \\frac{25}{361}$$\n接下来，我们计算 $g(\\theta')$：\n$$\\theta'-\\mu = \\frac{1}{19}\\begin{pmatrix}13.24 \\\\ -8.44\\end{pmatrix} - \\begin{pmatrix}0.5 \\\\ -0.3\\end{pmatrix} = \\frac{1}{19}\\begin{pmatrix}13.24 \\\\ -8.44\\end{pmatrix} - \\frac{1}{19}\\begin{pmatrix}9.5 \\\\ -5.7\\end{pmatrix} = \\frac{1}{19}\\begin{pmatrix}3.74 \\\\ -2.74\\end{pmatrix}$$\n$$g(\\theta') = -\\Sigma^{-1}(\\theta'-\\mu) = -\\frac{1}{0.19} \\begin{pmatrix}0.4  -0.1 \\\\ -0.1  0.5\\end{pmatrix} \\frac{1}{19}\\begin{pmatrix}3.74 \\\\ -2.74\\end{pmatrix} = -\\frac{100}{361} \\begin{pmatrix}0.4(3.74) - 0.1(-2.74) \\\\ -0.1(3.74) + 0.5(-2.74)\\end{pmatrix}$$\n$$g(\\theta') = -\\frac{100}{361} \\begin{pmatrix}1.496 + 0.274 \\\\ -0.374 - 1.37\\end{pmatrix} = -\\frac{100}{361} \\begin{pmatrix}1.77 \\\\ -1.744\\end{pmatrix}$$\n$$\\|g(\\theta')\\|^2 = \\left(-\\frac{100}{361}\\right)^2 (1.77^2 + (-1.744)^2) = \\frac{10000}{130321} (3.1329 + 3.041536) = \\frac{10000}{130321} (6.174436) = \\frac{61744.36}{130321}$$\n现在我们计算数值：\n$$\\|g(\\theta)\\|^2 = \\frac{25}{361} \\approx 0.06925208$$\n$$\\|g(\\theta')\\|^2 = \\frac{61744.36}{130321} \\approx 0.47378602$$\n当 $\\delta^2/8 = 0.04/8 = 0.005$ 时，我们求得 $\\log R$：\n$$\\log R = -0.005 \\times (0.47378602 - 0.06925208) = -0.005 \\times (0.40453394) = -0.00202267$$\n接受概率是 $\\alpha = \\min(1, \\exp(\\log R))$。因为 $\\log R  0$，我们有：\n$$\\alpha = \\exp(-0.00202267) \\approx 0.99797936$$\n四舍五入到四位有效数字，结果是 $0.9980$。",
            "answer": "$$\\boxed{0.9980}$$"
        },
        {
            "introduction": "在运行MCMC模拟后，我们得到的是一串相关的样本，而非独立的样本。因此，我们需要一种方法来量化我们实际收集到的独立信息的“数量”。本练习聚焦于MCMC诊断的两个关键指标：积分自相关时间（IACT）和有效样本量（ESS）。IACT衡量链需要多少步才能“忘记”其历史状态，而ESS则告诉我们所得到的MCMC链相当于多少个独立的样本。  这个思想实验通过一个简化的自相关模型，清晰地揭示了其背后的数学原理。",
            "id": "4318054",
            "problem": "在一个用于细胞因子信号传导的贝叶斯网络模型中，一个标量边权重参数 $\\,\\theta\\,$（例如，某个调控边的对数效应大小）通过马尔可夫链蒙特卡罗 (MCMC) 方法进行推断。在预烧期之后，关于 $\\,\\theta\\,$ 的马尔可夫链是平稳且均方遍历的。假设该链的滞后k自相关函数 $\\,\\rho_k\\,$ 对于所有整数 $\\,k \\geq 1\\,$ 都可以很好地近似为指数形式 $\\,\\rho_k = 0.8^{k}\\,$，且 $\\,\\rho_0 = 1\\,$。仅使用平稳标量链的积分自相关时间 (IACT) 的定义以及绝对收敛级数的标准性质，为此自相关结构推导出IACT的闭式解。然后，使用单变量MCMC输出的有效样本量 (ESS) 的标准定义，估计在保留 $\\,T = 5000\\,$ 次预烧期后迭代的情况下，有效独立样本的数量。\n\n明确说明你使用的任何中间假设，证明所用到的任何无穷级数的收敛性，并将你的最终答案表示为两个精确值，不进行四舍五入。两个输出应按顺序为：积分自相关时间和有效样本量。不包括单位。如果你选择近似，则必须四舍五入到四位有效数字；否则请提供精确值。",
            "solution": "在进行求解之前，对问题陈述进行了严格验证。\n\n### 步骤 1：提取已知条件\n问题陈述中逐字提供的数据如下：\n- 用于标量参数 $\\theta$ 的马尔可夫链蒙特卡罗 (MCMC) 链是平稳且均方遍历的。\n- 对于所有整数 $k \\geq 1$，滞后k自相关函数由 $\\rho_k = 0.8^k$ 给出。\n- 滞后0自相关为 $\\rho_0 = 1$。\n- 预烧期后的迭代次数（样本数）为 $T = 5000$。\n\n### 步骤 2：使用提取的已知条件进行验证\n根据所需标准对问题进行评估：\n- **科学依据**：该问题在MCMC方法的统计理论中有坚实的基础，该理论是系统生物学和其他领域中贝叶斯推断的基石。自相关、积分自相关时间 (IACT) 和有效样本量 (ESS) 等概念是评估MCMC采样器效率的标准。自相关的指数衰减模型是一种常见且易于处理的近似方法。\n- **适定性**：该问题是适定的。它为自相关函数提供了显式的函数形式，并要求根据其标准定义推导派生量 (IACT 和 ESS)。所有必要的信息（$T$, $\\rho_k$）均已提供，以求得唯一且有意义的解。\n- **客观性**：语言精确，使用了统计学中标准、无歧义的术语。\n- **完整性/一致性**：该问题是自洽的。给定的自相关结构与平稳过程的性质（例如，$|\\rho_k| \\leq 1$）一致。均方遍历的条件与给定的自相关函数导出一个收敛级数这一事实相符，这一点将在后面展示。\n- **其他缺陷**：该问题没有表现出任何其他缺陷，例如不切实际、不适定、伪深刻或无法验证。\n\n### 步骤 3：结论与行动\n该问题被判定为**有效**。下面提供一个完整的、有理有据的解答。\n\n解答按要求分两部分进行：首先，推导积分自相关时间 (IACT)；其次，计算有效样本量 (ESS)。\n\n**第 1 部分：积分自相关时间 (IACT) 的推导**\n\n对于一个平稳标量时间序列，积分自相关时间（用 $\\tau$ 表示）定义为从滞后 $k = -\\infty$ 到 $k = \\infty$ 的所有自相关之和。\n$$ \\tau = \\sum_{k=-\\infty}^{\\infty} \\rho_k $$\n对于平稳过程，自相关函数是对称的，即 $\\rho_k = \\rho_{-k}$。此外，根据定义，$\\rho_0 = 1$。因此，该定义可以重写为：\n$$ \\tau = \\rho_0 + \\sum_{k=1}^{\\infty} \\rho_k + \\sum_{k=-\\infty}^{-1} \\rho_k = 1 + 2 \\sum_{k=1}^{\\infty} \\rho_k $$\n这就是我们将使用的标准定义，正如问题陈述中提到收敛级数的性质所建议的那样。\n\n问题给出的自相关结构为，当 $k \\geq 1$ 时，$\\rho_k = 0.8^k$。将此代入 $\\tau$ 的定义中：\n$$ \\tau = 1 + 2 \\sum_{k=1}^{\\infty} (0.8)^k $$\n和式 $\\sum_{k=1}^{\\infty} (0.8)^k$ 是一个首项 $a = 0.8$、公比 $r = 0.8$ 的几何级数。\n无穷几何级数 $\\sum_{n=1}^{\\infty} ar^{n-1}$ 收敛的充要条件是公比的绝对值小于 1，即 $|r|  1$。在这种情况下，$r = 0.8$，由于 $|0.8|  1$，该级数绝对收敛。\n\n从 $k=1$ 项开始的无穷几何级数的求和公式为：\n$$ \\sum_{k=1}^{\\infty} r^k = \\frac{r}{1-r} $$\n将 $r=0.8$ 应用于此公式：\n$$ \\sum_{k=1}^{\\infty} (0.8)^k = \\frac{0.8}{1 - 0.8} = \\frac{0.8}{0.2} = 4 $$\n这个和的收敛性证实了IACT是有限的，这与给定的链是均方遍历的信息相一致。\n\n现在，我们将这个和代回到 $\\tau$ 的表达式中：\n$$ \\tau = 1 + 2 \\times 4 = 1 + 8 = 9 $$\n因此，积分自相关时间恰好为 $9$。\n\n**第 2 部分：有效样本量 (ESS) 的估计**\n\n有效样本量 (ESS) 是一个度量，它量化了需要多少独立样本，才能使样本均值的方差与来自MCMC链的 $T$ 个自相关样本的样本均值方差相同。给定长度为 $T$ 的链和积分自相关时间 $\\tau$，ESS的标准定义是：\n$$ \\text{ESS} = \\frac{T}{\\tau} $$\n我们已知预烧期后的总迭代次数为 $T = 5000$。从第 1 部分，我们推导出 IACT 为 $\\tau = 9$。\n\n将这些值代入 ESS 公式：\n$$ \\text{ESS} = \\frac{5000}{9} $$\n问题要求提供精确值。分数 $\\frac{5000}{9}$ 是该值的精确表示。这对应于循环小数 $555.\\overline{5}$。根据说明，我们提供精确的分数形式。\n\n最终答案是 IACT，$\\tau = 9$，和 ESS，$\\text{ESS} = \\frac{5000}{9}$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n9  \\frac{5000}{9}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "在MCMC的实际应用中，一个常见的做法是“稀疏化”（thinning），即每隔$k$个样本才保留一个，以期减小样本的自相关性和存储空间。但这总是一个好主意吗？本练习将引导您在不同约束条件（例如，固定的计算预算与固定的存储预算）下，对稀疏化这一操作进行批判性分析。通过探讨其中的利弊权衡，您将明晰稀疏化在何时有益，何时无害，甚至何时会有损分析效率。 ",
            "id": "4925206",
            "problem": "一位生物统计学家拟合了一个贝叶斯逻辑回归模型，用于分析不良事件的概率。参数向量记为$\\theta$，目标是计算标量函数$g(\\theta)$在后验分布$\\pi(\\theta \\mid \\text{data})$下的后验期望。一个马尔可夫链蒙特卡洛（MCMC）算法生成了一个平稳马尔可夫链$\\{X_t\\}_{t=1}^T$，其不变分布为$\\pi$。遍历均值$\\hat{\\mu} = \\frac{1}{N}\\sum_{t=1}^N g(X_t)$被用来估计$\\mu = \\mathbb{E}_\\pi[g(\\theta)]$。该链表现出序列相关性，其程度由滞后$\\ell \\ge 1$的自相关函数$\\rho_\\ell = \\text{corr}(g(X_t), g(X_{t+\\ell}))$量化。为了解决磁盘存储限制和在短滞后下感知到的高自相关性问题，分析师考虑以整数步长$k \\ge 2$进行稀疏化，即在预烧期后仅保留$Y_j = X_{jk}$（其中$j = 1,\\dots,N_s$），而丢弃中间的抽样点。\n\n在现实的资源模型和相关性结构下，分析稀疏化对存储和$\\hat{\\mu}$的蒙特卡洛误差的影响。以下哪些陈述是正确的？\n\nA. 在固定的$N_s$个已保存抽样的存储预算和允许生成$kN_s$次迭代的计算预算下，如果$\\rho_\\ell \\ge 0$且$\\rho_\\ell$随$\\ell$减小，则以步长$k$进行稀疏化可以减少$N_s$个已存储抽样之间的相关性，从而降低仅基于这些已存储抽样的估计量的方差，而不会相对于保存$N_s$个连续未稀疏化抽样增加蒙特卡洛误差。\n\nB. 在固定的总生成迭代次数$M$下，以任何步长$k>1$进行稀疏化总是会减少遍历均值的蒙特卡洛误差，因为它使保存的抽样点间隔更远，从而充分降低了相关性以补偿所保存抽样数量的减少。\n\nC. 如果滞后自相关函数是几何的，即$\\rho_\\ell = r^\\ell$，$0  r  1$，那么在固定的计算预算下，稀疏化总是会增加蒙特卡洛误差，因为$\\tau_{thinned} = \\frac{1}{k} \\tau_{unthinned}$这一关系并不成立。\n\nD. 稀疏化对于减少用于分析的MCMC输出的磁盘存储空间是有用的，尤其是当$\\rho_\\ell$对于小的$\\ell$值很高时，因为相邻抽样携带冗余信息。\n\nE. 稀疏化不是一种减少遍历均值估计量蒙特卡洛误差的方法，而主要是为了缓解数据存储和后处理瓶颈的实用策略。",
            "solution": "用户提供了一个关于马尔可夫链蒙特卡洛（MCMC）方法中稀疏化实践的问题陈述。\n\n**问题验证**\n\n**步骤1：提取已知条件**\n-   使用贝叶斯逻辑回归，参数向量为$\\theta$。\n-   目标量是标量函数$g(\\theta)$的后验期望$\\mu = \\mathbb{E}_\\pi[g(\\theta)]$，其中$\\pi(\\theta \\mid \\text{data})$是后验分布。\n-   一个MCMC算法生成一个平稳马尔可夫链$\\{X_t\\}_{t=1}^T$，其不变分布为$\\pi$。\n-   $\\mu$的估计量是来自长度为$N$的预烧期后链的遍历均值$\\hat{\\mu} = \\frac{1}{N}\\sum_{t=1}^N g(X_t)$。\n-   序列相关性由滞后$\\ell \\ge 1$的自相关函数（ACF）$\\rho_\\ell = \\text{corr}(g(X_t), g(X_{t+\\ell}))$量化。\n-   稀疏化由整数步长$k \\ge 2$定义，其中稀疏化链由抽样$Y_j = X_{jk}$（$j = 1, \\dots, N_s$）组成。\n\n**步骤2：使用提取的已知条件进行验证**\n-   **科学上合理：** 该问题设定在贝叶斯推断和MCMC方法的标准理论框架内，这是现代生物统计学的基石。所有概念——遍历均值、自相关、稀疏化——都定义明确且是该领域的基础。该问题在科学上是合理的。\n-   **定义明确：** 该问题要求评估关于稀疏化后果的几个陈述。这是一个定义明确的任务，需要分析标准的MCMC理论。\n-   **客观性：** 语言精确、正式且客观。问题设置中没有主观或基于意见的主张。\n-   **完整性和一致性：** 该问题提供了所有必要的定义和背景，以分析在不同资源约束下稀疏化对估计量方差的影响。设置是自洽和一致的。\n\n**步骤3：结论与行动**\n问题陈述有效。我现在将进行完整的推导和分析。\n\n**核心原理推导**\n\n评估MCMC估计量效率的核心量是其方差，通常被称为蒙特卡洛误差的平方。令$Z_t = g(X_t)$。我们使用样本均值$\\hat{\\mu}_N = \\frac{1}{N}\\sum_{t=1}^N Z_t$来估计$\\mu = \\mathbb{E}[Z_t]$。链$\\{Z_t\\}$是平稳的，其边际方差为$\\sigma^2 = \\text{Var}(Z_t)$，自相关函数（ACF）为$\\rho_\\ell = \\text{Corr}(Z_t, Z_{t+\\ell})$。\n\n样本均值的方差由下式给出：\n$$ \\text{Var}(\\hat{\\mu}_N) = \\frac{\\sigma^2}{N^2} \\sum_{i=1}^N \\sum_{j=1}^N \\rho_{|i-j|} $$\n对于大样本量$N$，此方差可以近似为：\n$$ \\text{Var}(\\hat{\\mu}_N) \\approx \\frac{\\sigma^2}{N} \\left( 1 + 2 \\sum_{\\ell=1}^{\\infty} \\rho_\\ell \\right) = \\frac{\\sigma^2 \\tau}{N} $$\n这里，$\\tau = 1 + 2 \\sum_{\\ell=1}^{\\infty} \\rho_\\ell$是积分自相关时间（IAT）。IAT量化了多少个相关样本等价于一个独立样本。较小的$\\tau$或较大的样本量$N$会减小估计量的方差。有效样本量定义为$N_{eff} = N/\\tau$。最小化方差等价于最大化$N_{eff}$。\n\n现在，考虑对总长度为$M$的链以步长$k$进行稀疏化的效果。\n1.  **未稀疏化估计量：** 使用所有$M$个抽样。\n    $\\hat{\\mu}_{unthinned} = \\frac{1}{M}\\sum_{t=1}^M Z_t$。\n    方差为$V_{unthinned} = \\text{Var}(\\hat{\\mu}_{unthinned}) \\approx \\frac{\\sigma^2}{M} \\tau_{unthinned}$，其中$\\tau_{unthinned} = 1 + 2\\sum_{\\ell=1}^\\infty \\rho_\\ell$。\n\n2.  **稀疏化估计量：** 使用$N_s = M/k$个抽样，$Y_j = X_{jk}$。\n    $\\hat{\\mu}_{thinned} = \\frac{1}{N_s}\\sum_{j=1}^{N_s} g(Y_j)$。\n    稀疏化序列$\\{g(Y_j)\\}$的ACF为$\\rho'_\\ell = \\text{Corr}(g(Y_j), g(Y_{j+\\ell})) = \\text{Corr}(g(X_{jk}), g(X_{(j+\\ell)k})) = \\rho_{k\\ell}$。\n    稀疏化序列的IAT为$\\tau_{thinned} = 1 + 2\\sum_{\\ell=1}^\\infty \\rho'_\\ell = 1 + 2\\sum_{\\ell=1}^\\infty \\rho_{k\\ell}$。\n    稀疏化估计量的方差为$V_{thinned} = \\text{Var}(\\hat{\\mu}_{thinned}) \\approx \\frac{\\sigma^2}{N_s} \\tau_{thinned} = \\frac{\\sigma^2}{M/k} \\tau_{thinned} = \\frac{k \\sigma^2}{M} \\tau_{thinned}$。\n\n有了这些公式，我们就可以评估每个选项。\n\n**逐项分析**\n\n**A. 在固定的$N_s$个已保存抽样的存储预算和允许生成$kN_s$次迭代的计算预算下，如果$\\rho_\\ell \\ge 0$且$\\rho_\\ell$随$\\ell$减小，则以步长$k$进行稀疏化可以减少$N_s$个已存储抽样之间的相关性，从而降低仅基于这些已存储抽样的估计量的方差，而不会相对于保存$N_s$个连续未稀疏化抽样增加蒙特卡洛误差。**\n\n该选项比较了两种获取基于$N_s$个抽样的估计量的策略：\n1.  **连续抽样：** 生成$N_s$个抽样并全部保存。估计量为$\\hat{\\mu}_1 = \\frac{1}{N_s} \\sum_{t=1}^{N_s} g(X_t)$。方差为$\\text{Var}(\\hat{\\mu}_1) \\approx \\frac{\\sigma^2}{N_s} (1 + 2\\sum_{\\ell=1}^\\infty \\rho_\\ell)$。\n2.  **稀疏化抽样：** 生成$M=kN_s$个抽样，每隔$k$个保存一个。估计量为$\\hat{\\mu}_2 = \\frac{1}{N_s} \\sum_{j=1}^{N_s} g(X_{jk})$。方差为$\\text{Var}(\\hat{\\mu}_2) \\approx \\frac{\\sigma^2}{N_s} (1 + 2\\sum_{\\ell=1}^\\infty \\rho_{k\\ell})$。\n\n该陈述声称稀疏化可以减少相关性。第一个样本的IAT为$\\tau_1 = 1 + 2\\sum \\rho_\\ell$，而第二个（稀疏化）样本的IAT为$\\tau_2 = 1 + 2\\sum \\rho_{k\\ell}$。鉴于$\\rho_\\ell \\ge 0$且递减，对于$k \\ge 2$，我们有$\\rho_{k\\ell} \\le \\rho_\\ell$，并且如果链不是完全相关的，对于至少某些$\\ell$该不等式是严格的。因此，$\\sum_{\\ell=1}^\\infty \\rho_{k\\ell}  \\sum_{\\ell=1}^\\infty \\rho_\\ell$，这意味着$\\tau_2  \\tau_1$。所以，已存储抽样之间的相关性确实减少了。\n\n这直接意味着估计量的方差减小了：$\\text{Var}(\\hat{\\mu}_2)  \\text{Var}(\\hat{\\mu}_1)$。因此，蒙特卡洛误差（方差的平方根）没有增加；它减小了。该陈述的措辞很谨慎，反映了一种权衡：对于固定的存储预算，可以投入更多的计算精力来获得一组质量更高（IAT更低）的样本，从而得到更精确的估计量。这是稀疏化的一个有效动机。\n\n结论：**正确**。\n\n**B. 在固定的总生成迭代次数$M$下，以任何步长$k>1$进行稀疏化总是会减少遍历均值的蒙特卡洛误差，因为它使保存的抽样点间隔更远，从而充分降低了相关性以补偿所保存抽样数量的减少。**\n\n该选项描述了最常见的比较：固定计算预算$M$。我们比较$V_{unthinned} \\approx \\frac{\\sigma^2}{M} \\tau_{unthinned}$与$V_{thinned} \\approx \\frac{k\\sigma^2}{M} \\tau_{thinned}$。如果$V_{thinned}  V_{unthinned}$，则稀疏化有帮助，这等价于$k \\cdot \\tau_{thinned}  \\tau_{unthinned}$。\n\n让我们用一个常见的ACF模型，即几何衰减$\\rho_\\ell = r^\\ell$（$0  r  1$）来检验这一点。\n$\\tau_{unthinned} = 1 + 2 \\sum_{\\ell=1}^\\infty r^\\ell = 1 + 2\\frac{r}{1-r} = \\frac{1+r}{1-r}$。\n以$k$进行稀疏化的链的ACF为$\\rho'_{ \\ell} = \\rho_{k\\ell} = (r^k)^\\ell$。\n$\\tau_{thinned} = 1 + 2 \\sum_{\\ell=1}^\\infty (r^k)^\\ell = \\frac{1+r^k}{1-r^k}$。\n稀疏化更好的条件是$k \\frac{1+r^k}{1-r^k}  \\frac{1+r}{1-r}$。\n让我们测试$k=2$的情况。条件变为$2 \\frac{1+r^2}{1-r^2}  \\frac{1+r}{1-r}$。\n因为$0  r  1$，所以$1-r$和$1-r^2 = (1-r)(1+r)$都是正数。我们可以相乘而不改变不等式的方向：\n$2 \\frac{1+r^2}{(1-r)(1+r)}  \\frac{(1+r)^2}{(1-r)(1+r)} \\implies 2(1+r^2)  (1+r)^2 \\implies 2+2r^2  1+2r+r^2 \\implies r^2 - 2r + 1  0 \\implies (r-1)^2  0$。\n对于任何实数$r$这都是不可能的。因此，对于几何ACF，稀疏化会*增加*方差。该陈述声称稀疏化*总是*减少误差，这显然是错误的。\n\n结论：**不正确**。\n\n**C. 如果滞后自相关函数是几何的，即$\\rho_\\ell = r^\\ell$，$0  r  1$，那么在固定的计算预算下，稀疏化总是会增加蒙特卡洛误差，因为$\\tau_{thinned} = \\frac{1}{k} \\tau_{unthinned}$这一关系并不成立。**\n\n正如在B中推导的，稀疏化确实增加了误差。陈述的第二部分给出了一个原因：“因为$\\tau_{thinned} = \\frac{1}{k} \\tau_{unthinned}$这一关系并不成立”。让我们检查这个关系。\n$\\tau_{thinned} = \\frac{1+r^k}{1-r^k}$\n$\\frac{1}{k} \\tau_{unthinned} = \\frac{1}{k} \\frac{1+r}{1-r}$\n这两者显然不相等。例如，取$r=0.5, k=2$。\n$\\tau_{thinned} = \\frac{1+0.25}{1-0.25} = \\frac{1.25}{0.75} = 5/3 \\approx 1.67$。\n$\\frac{1}{2} \\tau_{unthinned} = \\frac{1}{2} \\frac{1+0.5}{1-0.5} = \\frac{1}{2} \\frac{1.5}{0.5} = 1.5$。\n它们不相等。因此，陈述的两个部分都是正确的。稀疏化增加了误差，给出的原因（该关系不成立）也是正确的。但是，给出的原因并不是稀疏化增加误差的直接原因。稀疏化增加误差是因为$(r-1)^2  0$是假的。然而，陈述本身在逻辑上是“A因为B”，即使B不是A的唯一或直接原因，如果A和B都为真，则可能被认为是正确的。让我们重新评估陈述的措辞。它说稀疏化“总是会增加蒙特卡洛误差”。我们在B中证明了这一点。然后它给出了一个原因。虽然给出的原因有点偏离，但它是正确的。让我们重新审视A、B、C、D、E，看看是否有更好的选择。D和E看起来非常正确。A也正确。B肯定不正确。C的措辞有点尴尬，但它陈述了两个真实的事实。在多项选择题中，这通常是棘手的。然而，最简洁的论点是，对于固定的计算，不稀疏化会最大化有效样本量，因此误差最小。任何丢弃样本的行为（稀疏化）都会增加误差。\n\n结论：**不正确**。陈述的两个子句都是正确的，但连接词“因为”具有误导性。稀疏化增加误差的真正原因是$k \\tau_{thinned} > \\tau_{unthinned}$，这对于几何ACF总是成立。该陈述是正确的，即误差增加，但其理由不充分。在严格的逻辑评估中，这个“因为”是薄弱的。\n\n**D. 稀疏化对于减少用于分析的MCMC输出的磁盘存储空间是有用的，尤其是当$\\rho_\\ell$对于小的$\\ell$值很高时，因为相邻抽样携带冗余信息。**\n\n这准确地描述了稀疏化最公认的实际好处。如果样本高度相关，则保存所有样本的收益递减。稀疏化以很小的统计效率损失为代价，显著减小了文件大小。\n\n结论：**正确**。\n\n**E. 稀疏化不是一种减少遍历均值估计量蒙特卡洛误差的方法，而主要是为了缓解数据存储和后处理瓶颈的实用策略。**\n\n这总结了现代对稀疏化的共识。除非在选项A所述的“固定存储”场景下，否则对于固定的计算预算，稀疏化会增加误差（或在最好的情况下，不改变它）。其主要目的是实用的：减少文件大小和后续计算的负担。该陈述准确地反映了这一点。\n\n结论：**正确**。\n\n**最终评估**\n\n-   A：正确。在固定存储预算下，稀疏化减少了误差。\n-   B：不正确。在固定计算预算下，稀疏化增加了误差。\n-   C：不正确。陈述的因果关系不严谨。\n-   D：正确。稀疏化的主要实际好处之一。\n-   E：正确。对稀疏化目的的准确总结。\n\n因此，正确的陈述是A、D和E。",
            "answer": "$$\\boxed{ADE}$$"
        }
    ]
}