{
    "hands_on_practices": [
        {
            "introduction": "逆向建模的核心任务之一是从实验数据中提取物理上有意义的参数。本练习将通过一个地球化学中的经典例子，即利用范特霍夫（van 't Hoff）方程从不同温度下的平衡常数数据估算反应焓（$\\Delta H^\\circ$）和熵（$\\Delta S^\\circ$），来向您介绍这一过程。您将学习如何将非线性物理模型线性化，并应用加权最小二乘法来正确处理具有不同不确定性的测量数据，这是处理真实世界数据的关键技能()。",
            "id": "4082921",
            "problem": "您的任务是实现一个计算地球化学中的反演建模程序，以根据平衡常数随温度变化的数据来估计标准反应焓 $\\Delta H^\\circ$ 和标准反应熵 $\\Delta S^\\circ$。其基本原理包括标准吉布斯自由能 $\\Delta G^\\circ$ 与反应平衡常数 $K$ 之间的关系（定义为 $\\Delta G^\\circ = - R T \\ln K$），以及热力学恒等式 $\\Delta G^\\circ = \\Delta H^\\circ - T \\Delta S^\\circ$（适用于在有限温度范围内 $\\Delta H^\\circ$ 和 $\\Delta S^\\circ$ 与温度无关的反应）。结合这两个经过充分检验的公式，可以推导出 $\\ln K$ 和 $1/T$ 之间存在线性关系，其中 $T$ 是以开尔文为单位的绝对温度。$K$ 的测量值具有相关的不确定度，必须将其传播到 $\\ln K$ 的不确定度中，并在统计学上合理的加权线性回归中用作权重。\n\n您的程序必须：\n- 为关联 $\\ln K$ 和 $1/T$ 的线性模型构建加权最小二乘问题。\n- 通过一阶误差传播，使用 $K$ 的测量不确定度计算 $\\ln K$ 的不确定度，对于每次测量 $i$，$\\sigma_{\\ln K,i} \\approx \\sigma_{K,i} / K_i$。\n- 求解加权线性回归问题以估计斜率和截距，然后使用气体常数 $R$ 将这些值转换为 $\\Delta H^\\circ$ 和 $\\Delta S^\\circ$。\n- 基于加权最小二乘估计量的协方差，计算 $\\Delta H^\\circ$ 和 $\\Delta S^\\circ$ 的后验一倍标准差（one-sigma）不确定度，假设误差是方差已知的独立高斯误差。\n- 将 $\\Delta H^\\circ$ 以千焦每摩尔为单位表示，将 $\\Delta S^\\circ$ 以焦耳每摩尔每开尔文为单位表示，两者均四舍五入到六位小数。\n\n使用以下气体常数：$R = 8.31446261815324 \\ \\mathrm{J \\ mol^{-1} \\ K^{-1}}$。\n\n为以下数据集测试套件实现解决方案。每个测试用例提供多次测量的温度 $T$（单位：开尔文）、平衡常数 $K$（无量纲）和绝对不确定度 $\\sigma_K$（与 $K$ 的量纲相同）。以下所有数字都必须按给定的方式精确处理。数据集是：\n\n- 案例 A（一般情况，不确定度不同）：\n  - $T$: $\\{298.0, 310.0, 330.0, 360.0\\}$ (开尔文)\n  - $K$: $\\{3000.0, 1200.0, 300.0, 120.0\\}$ (无量纲)\n  - $\\sigma_K$: $\\{150.0, 48.0, 30.0, 9.6\\}$ (无量纲)\n- 案例 B（边界情况：最少数量的点）：\n  - $T$: $\\{298.0, 350.0\\}$ (开尔文)\n  - $K$: $\\{2500.0, 500.0\\}$ (无量纲)\n  - $\\sigma_K$: $\\{125.0, 25.0\\}$ (无量纲)\n- 案例 C（边缘情况：一次测量的不确定度非常小，主导了权重）：\n  - $T$: $\\{280.0, 300.0, 320.0, 340.0, 360.0\\}$ (开尔文)\n  - $K$: $\\{5000.0, 2000.0, 900.0, 420.0, 200.0\\}$ (无量纲)\n  - $\\sigma_K$: $\\{500.0, 200.0, 9.0, 42.0, 20.0\\}$ (无量纲)\n- 案例 D（边缘情况：温度紧密聚集）：\n  - $T$: $\\{300.0, 301.0, 302.0, 303.0\\}$ (开尔文)\n  - $K$: $\\{2000.0, 1900.0, 1800.0, 1700.0\\}$ (无量纲)\n  - $\\sigma_K$: $\\{50.0, 50.0, 50.0, 50.0\\}$ (无量纲)\n\n您的程序必须输出一行，其中包含一个用方括号括起来的、包含所有案例结果的逗号分隔列表。每个案例的结果必须是 $[\\Delta H^\\circ \\ (\\mathrm{kJ \\ mol^{-1}}), \\Delta S^\\circ \\ (\\mathrm{J \\ mol^{-1} \\ K^{-1}}), \\sigma_{\\Delta H^\\circ} \\ (\\mathrm{kJ \\ mol^{-1}}), \\sigma_{\\Delta S^\\circ} \\ (\\mathrm{J \\ mol^{-1} \\ K^{-1}})]$ 形式的列表，每个数值都四舍五入到六位小数。例如，最终输出必须看起来像 `[[h_1,s_1,sh_1,ss_1],[h_2,s_2,sh_2,ss_2],[h_3,s_3,sh_3,ss_3],[h_4,s_4,sh_4,ss_4]]`，其中每个 $h_i$, $s_i$, $sh_i$ 和 $ss_i$ 都是浮点数。\n\n所有输入均如所述，单位为开尔文和无量纲。所有输出必须按照规定，以 $\\mathrm{kJ \\ mol^{-1}}$ 表示 $\\Delta H^\\circ$，以 $\\mathrm{J \\ mol^{-1} \\ K^{-1}}$ 表示 $\\Delta S^\\circ$。不涉及角度。不得使用百分比；不确定度必须作为绝对值提供和使用。\n\n您的实现必须是自包含的，且不得读取任何外部输入。它必须遵循适用于现代编程语言的加权线性回归原理，纯粹关注上述数学逻辑。",
            "solution": "该问题要求从不同温度 $T$ 下的平衡常数 $K$ 的实验数据中，估计标准反应焓 $\\Delta H^\\circ$ 和标准反应熵 $\\Delta S^\\circ$。这是物理化学中一个经典的反演问题，其解决方案基于基本的热力学原理和统计回归分析。\n\n### 1. 理论阐述：范特霍夫方程\n\n分析始于化学热力学中的两个基本方程。第一个方程将标准反应吉布斯自由能 $\\Delta G^\\circ$ 与平衡常数 $K$ 联系起来：\n$$ \\Delta G^\\circ = - R T \\ln K $$\n其中 $R$ 是通用气体常数，$T$ 是以开尔文为单位的绝对温度。\n\n第二个是吉布斯自由能根据焓和熵的定义：\n$$ \\Delta G^\\circ = \\Delta H^\\circ - T \\Delta S^\\circ $$\n问题假设在实验的有限温度范围内，$\\Delta H^\\circ$ 和 $\\Delta S^\\circ$ 都是常数。\n\n通过令这两个 $\\Delta G^\\circ$ 的表达式相等，我们得到：\n$$ - R T \\ln K = \\Delta H^\\circ - T \\Delta S^\\circ $$\n为了建立一个适合回归分析的线性关系，我们将此方程的所有项除以 $-RT$ 进行重排：\n$$ \\ln K = -\\frac{\\Delta H^\\circ}{R T} + \\frac{T \\Delta S^\\circ}{R T} $$\n$$ \\ln K = \\left(-\\frac{\\Delta H^\\circ}{R}\\right) \\frac{1}{T} + \\left(\\frac{\\Delta S^\\circ}{R}\\right) $$\n该方程是直线形式 $y = mx + c$，其中：\n- 因变量是 $y = \\ln K$。\n- 自变量是 $x = 1/T$。\n- 斜率是 $m = -\\frac{\\Delta H^\\circ}{R}$。\n- y轴截距是 $c = \\frac{\\Delta S^\\circ}{R}$。\n\n### 2. 统计方法：加权最小二乘法 (WLS)\n\n实验测量的是 $K$ 值，并带有相关的不确定度 $\\sigma_K$。为了对变换后的变量 $y = \\ln K$ 和 $x = 1/T$ 进行线性回归，我们必须传播这些不确定度。使用一阶泰勒展开（误差传播），每个 $y_i = \\ln K_i$ 值的不确定度 $\\sigma_{y,i}$ 由下式给出：\n$$ \\sigma_{y,i} = \\sigma_{\\ln K,i} \\approx \\left| \\frac{d(\\ln K)}{dK} \\right|_{K=K_i} \\sigma_{K,i} = \\frac{1}{K_i} \\sigma_{K,i} $$\n由于这些不确定度在数据点之间不一致，简单的最小二乘回归是不合适的。统计上正确的方法是加权最小二乘法 (WLS)，其中每个数据点对拟合的贡献由其方差的倒数加权。第 $i$ 个数据点的权重是：\n$$ w_i = \\frac{1}{\\sigma_{y,i}^2} = \\left(\\frac{K_i}{\\sigma_{K,i}}\\right)^2 $$\nWLS 方法通过最小化加权残差平方和 $\\chi^2$ 来找到参数 $m$ 和 $c$：\n$$ \\chi^2(m, c) = \\sum_{i=1}^{n} w_i (y_i - (mx_i + c))^2 $$\n其中 $n$ 是数据点的数量。\n\n使用矩阵代数可以最有效地解决这个最小化问题。我们定义如下：\n- 观测向量，$y = [y_1, y_2, \\dots, y_n]^T = [\\ln K_1, \\ln K_2, \\dots, \\ln K_n]^T$。\n- 设计矩阵 $X$，它包含一列用于截距的全1列和一列用于自变量值的列：\n$$ X = \\begin{pmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\vdots & \\vdots \\\\ 1 & x_n \\end{pmatrix} = \\begin{pmatrix} 1 & 1/T_1 \\\\ 1 & 1/T_2 \\\\ \\vdots & \\vdots \\\\ 1 & 1/T_n \\end{pmatrix} $$\n- 参数向量，$\\beta = [c, m]^T$。\n- 对角权重矩阵 $W$，其对角线上是权重 $w_i$：\n$$ W = \\begin{pmatrix} w_1 & 0 & \\dots & 0 \\\\ 0 & w_2 & \\dots & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & \\dots & w_n \\end{pmatrix} $$\n参数向量的 WLS 估计 $\\hat{\\beta}$ 由正规方程给出：\n$$ \\hat{\\beta} = (X^T W X)^{-1} X^T W y $$\n\n### 3. 参数与不确定度估计\n\n一旦确定了最佳拟合参数 $\\hat{\\beta} = [\\hat{c}, \\hat{m}]^T$，我们就可以计算热力学量的估计值：\n$$ \\hat{\\Delta H^\\circ} = -\\hat{m} \\cdot R $$\n$$ \\hat{\\Delta S^\\circ} = \\hat{c} \\cdot R $$\n$\\hat{\\Delta H^\\circ}$ 的单位将是 $\\mathrm{J \\ mol^{-1}}$，必须通过除以 $1000$ 转换为 $\\mathrm{kJ \\ mol^{-1}}$。$\\hat{\\Delta S^\\circ}$ 的单位将是 $\\mathrm{J \\ mol^{-1} \\ K^{-1}}$，符合要求。\n\n该问题还要求计算这些估计值的一倍标准差不确定度。假设模型正确，且测量误差是方差已知的独立高斯分布（如题所述），参数估计量 $\\hat{\\beta}$ 的协方差矩阵由下式给出：\n$$ \\text{Cov}(\\hat{\\beta}) = (X^T W X)^{-1} $$\n这是一个 $2 \\times 2$ 的矩阵：\n$$ \\text{Cov}(\\hat{\\beta}) = \\begin{pmatrix} \\sigma_c^2 & \\text{cov}(c, m) \\\\ \\text{cov}(c, m) & \\sigma_m^2 \\end{pmatrix} $$\n对角元素 $\\sigma_c^2$ 和 $\\sigma_m^2$ 分别是估计截距和斜率的方差。一倍标准差不确定度是它们的平方根，即 $\\sigma_c$ 和 $\\sigma_m$。\n\n$\\Delta H^\\circ$ 和 $\\Delta S^\\circ$ 的不确定度通过从 $\\hat{m}$ 和 $\\hat{c}$ 传播不确定度来找到：\n$$ \\sigma_{\\Delta H^\\circ} = \\left| \\frac{\\partial (\\Delta H^\\circ)}{\\partial m} \\right| \\sigma_m = R \\cdot \\sigma_m $$\n$$ \\sigma_{\\Delta S^\\circ} = \\left| \\frac{\\partial (\\Delta S^\\circ)}{\\partial c} \\right| \\sigma_c = R \\cdot \\sigma_c $$\n不确定度 $\\sigma_{\\Delta H^\\circ}$ 也必须转换为 $\\mathrm{kJ \\ mol^{-1}}$。\n\n### 4. 算法摘要\n\n对每个提供的测试用例，执行以下计算步骤：\n\n1.  给定数据集 $\\{T_i, K_i, \\sigma_{K,i}\\}$，构造自变量 $x_i = 1/T_i$ 和因变量 $y_i = \\ln K_i$ 的数组。\n2.  计算每个 $y_i$ 的方差为 $\\sigma_{y,i}^2 = (\\sigma_{K,i} / K_i)^2$。\n3.  构造对角权重矩阵 $W$，其中 $W_{ii} = w_i = 1/\\sigma_{y,i}^2$。\n4.  构造设计矩阵 $X$。\n5.  使用 $\\hat{\\beta} = (X^T W X)^{-1} X^T W y$ 求解参数向量 $\\hat{\\beta} = [\\hat{c}, \\hat{m}]^T$。\n6.  计算协方差矩阵 $\\text{Cov}(\\hat{\\beta}) = (X^T W X)^{-1}$。\n7.  提取参数方差：$\\sigma_c^2 = \\text{Cov}(\\hat{\\beta})_{0,0}$ 和 $\\sigma_m^2 = \\text{Cov}(\\hat{\\beta})_{1,1}$。\n8.  使用气体常数 $R = 8.31446261815324 \\ \\mathrm{J \\ mol^{-1} \\ K^{-1}}$ 计算热力学估计值：\n    - $\\hat{\\Delta H^\\circ} = (-\\hat{m} \\cdot R) / 1000 \\quad (\\text{单位} \\ \\mathrm{in \\ kJ \\ mol^{-1}})$\n    - $\\hat{\\Delta S^\\circ} = \\hat{c} \\cdot R \\quad (\\text{单位} \\ \\mathrm{in \\ J \\ mol^{-1} \\ K^{-1}})$\n9.  计算相应的一倍标准差不确定度：\n    - $\\sigma_{\\Delta H^\\circ} = (\\sqrt{\\sigma_m^2} \\cdot R) / 1000 \\quad (\\text{单位} \\ \\mathrm{in \\ kJ \\ mol^{-1}})$\n    - $\\sigma_{\\Delta S^\\circ} = \\sqrt{\\sigma_c^2} \\cdot R \\quad (\\text{单位} \\ \\mathrm{in \\ J \\ mol^{-1} \\ K^{-1}})$\n10. 将四个结果值四舍五入到六位小数，并格式化为指定的列表结构用于最终输出。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the inverse modeling problem for multiple test cases to estimate\n    thermodynamic parameters from equilibrium constant data using weighted\n    linear regression.\n    \"\"\"\n\n    # Universal gas constant in J mol^-1 K^-1\n    R = 8.31446261815324\n\n    test_cases = [\n        # Case A (general, varied uncertainties)\n        {\n            \"T\": np.array([298.0, 310.0, 330.0, 360.0]),\n            \"K\": np.array([3000.0, 1200.0, 300.0, 120.0]),\n            \"sigma_K\": np.array([150.0, 48.0, 30.0, 9.6])\n        },\n        # Case B (boundary case: minimal number of points)\n        {\n            \"T\": np.array([298.0, 350.0]),\n            \"K\": np.array([2500.0, 500.0]),\n            \"sigma_K\": np.array([125.0, 25.0])\n        },\n        # Case C (edge case: one measurement with very small uncertainty dominating)\n        {\n            \"T\": np.array([280.0, 300.0, 320.0, 340.0, 360.0]),\n            \"K\": np.array([5000.0, 2000.0, 900.0, 420.0, 200.0]),\n            \"sigma_K\": np.array([500.0, 200.0, 9.0, 42.0, 20.0])\n        },\n        # Case D (edge case: temperatures tightly clustered)\n        {\n            \"T\": np.array([300.0, 301.0, 302.0, 303.0]),\n            \"K\": np.array([2000.0, 1900.0, 1800.0, 1700.0]),\n            \"sigma_K\": np.array([50.0, 50.0, 50.0, 50.0])\n        }\n    ]\n\n    all_results = []\n\n    for case_data in test_cases:\n        T = case_data[\"T\"]\n        K = case_data[\"K\"]\n        sigma_K = case_data[\"sigma_K\"]\n\n        # 1. Transform variables for linear model y = c + mx\n        x = 1.0 / T        # Independent variable: 1/T\n        y = np.log(K)      # Dependent variable: ln(K)\n\n        # 2. Propagate uncertainty to ln(K) and calculate weights\n        # sigma_y = sigma_K / K\n        # weight w = 1 / sigma_y^2 = (K / sigma_K)^2\n        sigma_y_sq = (sigma_K / K)**2\n        w = 1.0 / sigma_y_sq\n\n        # 3. Construct matrices for Weighted Least Squares (WLS)\n        # Design matrix X\n        X = np.vstack((np.ones_like(x), x)).T\n        \n        # Weight matrix W\n        W = np.diag(w)\n\n        # 4. Solve for parameters beta_hat = [c, m]^T\n        # beta_hat = (X^T W X)^-1 X^T W y\n        try:\n            XTWX = X.T @ W @ X\n            XTWX_inv = np.linalg.inv(XTWX)\n            XTWy = X.T @ W @ y\n            beta_hat = XTWX_inv @ XTWy\n        except np.linalg.LinAlgError:\n            # Handle cases where the matrix is singular, though not expected\n            # with the given test data.\n            all_results.append([np.nan, np.nan, np.nan, np.nan])\n            continue\n\n        c_hat = beta_hat[0]  # Intercept\n        m_hat = beta_hat[1]  # Slope\n\n        # 5. Calculate covariance matrix of parameters\n        # Cov(beta_hat) = (X^T W X)^-1\n        cov_beta = XTWX_inv\n        sigma_c_sq = cov_beta[0, 0]\n        sigma_m_sq = cov_beta[1, 1]\n        \n        sigma_c = np.sqrt(sigma_c_sq)\n        sigma_m = np.sqrt(sigma_m_sq)\n\n        # 6. Calculate thermodynamic quantities and their uncertainties\n        # Delta_H = -m * R\n        # Delta_S = c * R\n        delta_H = -m_hat * R\n        delta_S = c_hat * R\n        \n        sigma_delta_H = sigma_m * R\n        sigma_delta_S = sigma_c * R\n\n        # 7. Convert units (H to kJ/mol) and round\n        delta_H_kJ = delta_H / 1000.0\n        sigma_delta_H_kJ = sigma_delta_H / 1000.0\n\n        # Store results for this case\n        case_result = [\n            round(delta_H_kJ, 6),\n            round(delta_S, 6),\n            round(sigma_delta_H_kJ, 6),\n            round(sigma_delta_S, 6)\n        ]\n        all_results.append(case_result)\n\n    # 8. Format the final output string as specified: [[...],[...]] without spaces\n    output_str = str(all_results).replace(\" \", \"\")\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "在对地球化学系统进行建模时，我们常常面临一个关键问题：哪个模型最能恰当地描述我们的观测数据？一个更复杂的模型可能会更好地拟合数据，但它是否引入了不必要的参数，从而导致过拟合？本练习将通过比较描述电解质溶液行为的理想溶液模型和德拜-休克尔（Debye-Hückel）模型，引导您使用赤池信息准则（AIC）和贝叶斯信息准则（BIC）来进行模型选择()。您将亲手实践如何量化模型的拟合优度和复杂度之间的权衡，这是现代科学数据分析中的一个基本概念。",
            "id": "4082910",
            "problem": "在计算地球化学中，您的任务是使用逆向建模、参数估计和优化进行模型选择。考虑在标准实验室温度下，扩展德拜-休克尔理论适用的对称电解质水溶液的平均活度系数。您需要使用最大似然和信息准则的原理，对相同的数据集比较理想溶液模型与德拜-休克尔模型。\n\n建模基本原理：\n- 对于阳离子和阴离子价数大小相等（为 $z$）但符号相反的对称电解质，理想溶液模型假设活度系数为1，因此平均活度系数满足 $\\gamma_{\\pm} = 1$，即 $\\log_{10}\\gamma_{\\pm} = 0$。\n- 对称电解质的扩展德拜-休克尔模型给出了以10为底的对数形式的平均活度系数：\n$$\n\\log_{10}\\gamma_{\\pm}(I; z, a) = -\\frac{A\\, z^2 \\sqrt{I}}{1 + B\\, a \\sqrt{I}},\n$$\n其中 $I$ 是以 $\\text{mol}\\,\\text{L}^{-1}$ 为单位的离子强度，$z$ 是离子电荷的大小，$a$ 是以 $\\text{\\AA}$ 为单位的有效离子尺寸参数，而 $A$ 和 $B$ 是在指定温度下与溶剂相关的常数。对于 $25\\,^{\\circ}\\text{C}$ 的水，使用 $A = 0.509$ 和 $B = 0.328$。\n\n逆向建模和信息准则要求：\n- 假设观测响应 $y_i = \\log_{10}\\gamma_{\\pm}$ 的测量误差是独立的、呈高斯分布的，且每次观测的标准差 $\\sigma_i$ 已知。在此假设下，模型在观测点 $i$ 的预测值 $m_i$ 的对数似然是高斯对数似然的总和。\n- 从最大似然和模型维度的第一性原理出发，数学上定义赤池信息量准则（AIC）和贝叶斯信息准则（BIC），并应用它们来比较每个数据集的理想溶液模型和德拜-休克尔模型。理想溶液模型有零个拟合参数（$k = 0$）。对于本问题中的德拜-休克尔模型，将 $a$ 视为唯一的拟合参数（$k = 1$），所有其他量均已指定。在计算信息准则时，请使用与每个数据集相对应的观测数量 $n$。\n\n参数估计设置：\n- 对于德拜-休克尔模型，在给定的具有已知 $\\sigma_i$ 的高斯误差模型下，通过最大似然估计 $a$。将 $a$ 约束在物理上合理的区间 $[1, 20]\\, \\text{\\AA}$ 内。\n\n测试套件：\n将您的方法应用于以下四种情况。对于每种情况，自变量是离子强度 $I$（单位 $\\text{mol}\\,\\text{L}^{-1}$），电荷大小是 $z$，观测响应 $y$ 是 $\\log_{10}\\gamma_{\\pm}$（无量纲），观测标准差是 $\\sigma$（无量纲）。提供的 $y$ 值在科学上是合理的，并且与在 $25\\,^{\\circ}\\text{C}$ 下使用所述 $A$ 和 $B$ 及一个潜在的真实 $a$ 的扩展德拜-休克尔模型一致；无需进一步转换。\n\n- 情况 (a) 低离子强度，一价对称电解质：\n  - $I = [0.001, 0.010, 0.050]$\n  - $z = 1$\n  - $y = [-0.015460, -0.045000, -0.087970]$\n  - $\\sigma = [0.010, 0.010, 0.010]$\n  - 单位：$I$ 单位为 $\\text{mol}\\,\\text{L}^{-1}$，$a$ 单位为 $\\text{\\AA}$，$\\sigma$ 无量纲。\n\n- 情况 (b) 低至中等离子强度，二价对称电解质：\n  - $I = [0.001, 0.010, 0.030]$\n  - $z = 2$\n  - $y = [-0.058950, -0.157200, -0.233200]$\n  - $\\sigma = [0.020, 0.020, 0.020]$\n  - 单位：$I$ 单位为 $\\text{mol}\\,\\text{L}^{-1}$，$a$ 单位为 $\\text{\\AA}$，$\\sigma$ 无量纲。\n\n- 情况 (c) 零离子强度下的边界条件，一价对称电解质：\n  - $I = [0.000]$\n  - $z = 1$\n  - $y = [0.000000]$\n  - $\\sigma = [0.001]$\n  - 单位：$I$ 单位为 $\\text{mol}\\,\\text{L}^{-1}$，$a$ 单位为 $\\text{\\AA}$，$\\sigma$ 无量纲。\n\n- 情况 (d) 较高离子强度，接近扩展德拜-休克尔理论的有效性极限，一价对称电解质：\n  - $I = [0.080, 0.100]$\n  - $z = 1$\n  - $y = [-0.104300, -0.113800]$\n  - $\\sigma = [0.020, 0.020]$\n  - 单位：$I$ 单位为 $\\text{mol}\\,\\text{L}^{-1}$，$a$ 单位为 $\\text{\\AA}$，$\\sigma$ 无量纲。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。对于给定顺序的每种情况，输出浮点数差值对 $[\\Delta \\text{AIC}, \\Delta \\text{BIC}]$，其中 $\\Delta \\text{AIC} = \\text{AIC}_{\\text{Debye-H\\\"uckel}} - \\text{AIC}_{\\text{Ideal}}$ 且 $\\Delta \\text{BIC} = \\text{BIC}_{\\text{Debye-H\\\"uckel}} - \\text{BIC}_{\\text{Ideal}}$。将四种情况的结果汇总成一个列表的列表，形式如下：\n$$\n[[\\Delta \\text{AIC}_a, \\Delta \\text{BIC}_a], [\\Delta \\text{AIC}_b, \\Delta \\text{BIC}_b], [\\Delta \\text{AIC}_c, \\Delta \\text{BIC}_c], [\\Delta \\text{AIC}_d, \\Delta \\text{BIC}_d]].\n$$\n这些最终值不需要单位。打印的单行应与此嵌套列表的文本列表表示完全匹配。",
            "solution": "问题陈述经评估有效。它在科学上基于物理化学（德拜-休克尔理论）和统计学（最大似然，信息准则）的原理。该问题是适定的，所有必要的数据、常数、模型和约束都已明确定义，从而能够得到一个唯一且有意义的解。它是客观的，没有歧义或矛盾。\n\n任务是比较对称电解质平均活度系数（$\\gamma_{\\pm}$）的两个模型：一个理想溶液模型和一个扩展德拜-休克尔模型。比较将使用赤池信息量准则（AIC）和贝叶斯信息准则（BIC），基于通过最大似然进行的参数估计。\n\n该方法论的核心在于最大似然原理。对于一组 $n$ 个独立观测值 $y_i$，其相关的高斯误差具有已知的标准差 $\\sigma_i$，一个产生预测值 $m_i$ 的模型的似然由单个概率密度的乘积给出：\n$$\nL = \\prod_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi}\\sigma_i} \\exp\\left(-\\frac{(y_i - m_i)^2}{2\\sigma_i^2}\\right)\n$$\n最大化此似然等同于最小化其负对数。负对数似然 $\\mathcal{L} = -\\ln L$ 为：\n$$\n\\mathcal{L} = \\frac{n}{2}\\ln(2\\pi) + \\sum_{i=1}^{n}\\ln(\\sigma_i) + \\frac{1}{2} \\sum_{i=1}^{n} \\left(\\frac{y_i - m_i}{\\sigma_i}\\right)^2\n$$\n模型的参数通过最小化此函数来估计。求和项是加权残差平方和，通常表示为 $\\chi^2$。\n$$\n\\chi^2 = \\sum_{i=1}^{n} \\left(\\frac{y_i - m_i}{\\sigma_i}\\right)^2\n$$\n因此，最大化似然等同于最小化 $\\chi^2$。设此函数对于给定模型的最小值为 $\\chi^2_{\\text{min}}$。\n\n要比较的两个模型是：\n1.  **理想溶液模型 ($M_0$)**：该模型假定 $\\log_{10}\\gamma_{\\pm} = 0$。模型预测对所有观测值均为 $m_{0,i} = 0$。此模型没有可调参数，因此其维度为 $k_0 = 0$。拟合优度计算如下：\n    $$\n    \\chi^2_{\\text{min, Ideal}} = \\sum_{i=1}^{n} \\left(\\frac{y_i - 0}{\\sigma_i}\\right)^2 = \\sum_{i=1}^{n} \\frac{y_i^2}{\\sigma_i^2}\n    $$\n\n2.  **扩展德拜-休克尔模型 ($M_1$)**：该模型将 $\\log_{10}\\gamma_{\\pm}$ 的预测值表示为离子强度 $I$、电荷大小 $z$ 和有效离子尺寸参数 $a$ 的函数：\n    $$\n    m_{1,i}(a) = \\log_{10}\\gamma_{\\pm}(I_i; z, a) = -\\frac{A\\, z^2 \\sqrt{I_i}}{1 + B\\, a \\sqrt{I_i}}\n    $$\n    常数给定为 $A = 0.509$ 和 $B = 0.328$。参数 $a$ 将从数据中估计，因此该模型的维度为 $k_1 = 1$。通过最小化该模型的 $\\chi^2$ 函数来找到 $a$ 的值：\n    $$\n    \\chi^2_{M_1}(a) = \\sum_{i=1}^{n} \\left(\\frac{y_i - m_{1,i}(a)}{\\sigma_i}\\right)^2\n    $$\n    这是一个在区间 $a \\in [1, 20]\\, \\text{\\AA}$ 上的一维优化问题。找到的最小值为 $\\chi^2_{\\text{min, DH}}$。\n\n模型选择使用信息准则进行，该准则对模型的复杂性（参数数量）进行惩罚，以避免过拟合。\n赤池信息量准则 (AIC) 定义为：\n$$\n\\text{AIC} = -2 \\ln(L_{\\text{max}}) + 2k\n$$\n其中 $L_{\\text{max}}$ 是最大似然值。代入包含 $\\chi^2_{\\text{min}}$ 的对数似然表达式：\n$$\n\\text{AIC} = 2\\mathcal{L}_{\\text{min}} + 2k = n\\ln(2\\pi) + 2\\sum_{i=1}^{n}\\ln(\\sigma_i) + \\chi^2_{\\text{min}} + 2k\n$$\n贝叶斯信息准则 (BIC) 定义为：\n$$\n\\text{BIC} = -2 \\ln(L_{\\text{max}}) + k\\ln(n) = n\\ln(2\\pi) + 2\\sum_{i=1}^{n}\\ln(\\sigma_i) + \\chi^2_{\\text{min}} + k\\ln(n)\n$$\n其中 $n$ 是观测次数。\n\n为了比较两个模型，我们计算差值 $\\Delta\\text{AIC}$ 和 $\\Delta\\text{BIC}$。涉及 $\\pi$ 和 $\\sigma_i$ 的常数项会抵消。\n$$\n\\Delta \\text{AIC} = \\text{AIC}_{\\text{DH}} - \\text{AIC}_{\\text{Ideal}} = (\\chi^2_{\\text{min, DH}} + 2k_1) - (\\chi^2_{\\text{min, Ideal}} + 2k_0)\n$$\n当 $k_1=1$ 且 $k_0=0$ 时：\n$$\n\\Delta \\text{AIC} = \\chi^2_{\\text{min, DH}} - \\chi^2_{\\text{min, Ideal}} + 2\n$$\nBIC 的情况类似：\n$$\n\\Delta \\text{BIC} = \\text{BIC}_{\\text{DH}} - \\text{BIC}_{\\text{Ideal}} = (\\chi^2_{\\text{min, DH}} + k_1\\ln n) - (\\chi^2_{\\text{min, Ideal}} + k_0\\ln n)\n$$\n当 $k_1=1$ 且 $k_0=0$ 时：\n$$\n\\Delta \\text{BIC} = \\chi^2_{\\text{min, DH}} - \\chi^2_{\\text{min, Ideal}} + \\ln n\n$$\n这些差值为负值表明，即使在对附加参数进行惩罚之后，更复杂的德拜-休克尔模型也能更好地描述数据。\n\n每个测试用例的计算过程如下：\n1.  将 $I$、$y$ 和 $\\sigma$ 的输入数据列表转换为数值数组。确定观测次数 $n$。\n2.  使用其定义计算 $\\chi^2_{\\text{min, Ideal}}$。\n3.  将德拜-休克尔模型和相应的 $\\chi^2_{M_1}(a)$ 定义为目标函数。\n4.  使用数值优化程序在 $[1, 20]$ 范围内找到使 $\\chi^2_{M_1}(a)$ 最小化的值 $\\hat{a}$，从而得到 $\\chi^2_{\\text{min, DH}}$。\n5.  使用计算出的 $\\chi^2$ 值来计算 $\\Delta \\text{AIC}$ 和 $\\Delta \\text{BIC}$。\n\n情况 (c) 是一个特例，其中 $I = [0.0]$。在零离子强度下，两个模型都预测 $\\log_{10}\\gamma_{\\pm} = 0$。由于观测值也是 $y=[0.0]$，两个模型都完美拟合。因此，$\\chi^2_{\\text{min, Ideal}} = 0$ 且 $\\chi^2_{\\text{min, DH}} = 0$。观测次数为 $n=1$。差值变为：\n$$\n\\Delta \\text{AIC} = 0 - 0 + 2 = 2\n$$\n$$\n\\Delta \\text{BIC} = 0 - 0 + \\ln(1) = 0\n$$\n这表明，对于两个模型都精确拟合的单个数据点，AIC 会惩罚更复杂的模型，而 BIC 由于其 $\\ln(n)$ 惩罚项则不会。",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize_scalar\n\ndef solve():\n    \"\"\"\n    Solves the model selection problem for four test cases in computational geochemistry.\n    Compares an ideal-solution model with the extended Debye-Hückel model using\n    Akaike (AIC) and Bayesian (BIC) information criteria.\n    \"\"\"\n    \n    A = 0.509  # Debye-Hückel constant for water at 25 C\n    B = 0.328  # Debye-Hückel constant for water at 25 C\n    a_bounds = (1.0, 20.0) # Physical bounds for ion-size parameter in Angstroms\n\n    test_cases = [\n        # Case (a) low ionic strength, monovalent\n        {\n            \"I\": np.array([0.001, 0.010, 0.050]),\n            \"z\": 1.0,\n            \"y\": np.array([-0.015460, -0.045000, -0.087970]),\n            \"sigma\": np.array([0.010, 0.010, 0.010]),\n        },\n        # Case (b) low-to-moderate ionic strength, divalent\n        {\n            \"I\": np.array([0.001, 0.010, 0.030]),\n            \"z\": 2.0,\n            \"y\": np.array([-0.058950, -0.157200, -0.233200]),\n            \"sigma\": np.array([0.020, 0.020, 0.020]),\n        },\n        # Case (c) boundary condition at zero ionic strength, monovalent\n        {\n            \"I\": np.array([0.000]),\n            \"z\": 1.0,\n            \"y\": np.array([0.000000]),\n            \"sigma\": np.array([0.001]),\n        },\n        # Case (d) higher ionic strength, monovalent\n        {\n            \"I\": np.array([0.080, 0.100]),\n            \"z\": 1.0,\n            \"y\": np.array([-0.104300, -0.113800]),\n            \"sigma\": np.array([0.020, 0.020]),\n        }\n    ]\n\n    results = []\n\n    for case in test_cases:\n        I, z, y, sigma = case[\"I\"], case[\"z\"], case[\"y\"], case[\"sigma\"]\n        n = len(y)\n\n        # 1. Ideal-Solution Model (M0)\n        # Model prediction is m = 0. k=0 parameters.\n        chi2_ideal = np.sum((y / sigma)**2)\n        k_ideal = 0\n\n        # 2. Extended Debye-Hückel Model (M1)\n        # Model prediction is a function of parameter 'a'. k=1 parameter.\n        def debye_huckel_model(I_vals, z_val, a_val, A_val, B_val):\n            sqrt_I = np.sqrt(I_vals)\n            # This calculation is robust against I=0, as sqrt(0)=0 and the numerator becomes 0.\n            return -A_val * z_val**2 * sqrt_I / (1 + B_val * a_val * sqrt_I)\n\n        def objective_function(a, I_vals, z_val, y_vals, sigma_vals, A_val, B_val):\n            y_pred = debye_huckel_model(I_vals, z_val, a, A_val, B_val)\n            residuals = y_vals - y_pred\n            return np.sum((residuals / sigma_vals)**2)\n\n        # Handle the special case where I=0, y=0.\n        # The objective function is identically zero, so optimization is not needed.\n        if np.all(I == 0):\n             chi2_min_dh = 0.0\n        else:\n            opt_result = minimize_scalar(\n                fun=objective_function,\n                bounds=a_bounds,\n                args=(I, z, y, sigma, A, B),\n                method='bounded'\n            )\n            chi2_min_dh = opt_result.fun\n\n        k_dh = 1\n\n        # 3. Calculate Information Criteria Differences\n        # delta_AIC = (chi2_dh + 2*k_dh) - (chi2_ideal + 2*k_ideal)\n        delta_aic = (chi2_min_dh - chi2_ideal) + 2 * (k_dh - k_ideal)\n\n        # delta_BIC = (chi2_dh + k_dh*ln(n)) - (chi2_ideal + k_ideal*ln(n))\n        # Handle n=1 where ln(1)=0\n        if n > 0:\n            ln_n = np.log(n)\n        else:\n            ln_n = 0 # should not happen with given data\n        delta_bic = (chi2_min_dh - chi2_ideal) + (k_dh - k_ideal) * ln_n\n\n        results.append([delta_aic, delta_bic])\n        \n    # The required output is the string representation of the list of lists.\n    # The placeholder `f\"[{','.join(map(str, results))}]\"` doesn't produce standard\n    # list-of-list formatting with spaces. Direct str() casting does.\n    # e.g., str([[1.2, 3.4], [5.6, 7.8]]) is '[[1.2, 3.4], [5.6, 7.8]]'\n    # The prompt's example format shows spaces after commas, so str() is correct.\n    # The example print format in the prompt template might be misleading for nested lists.\n    # I will adapt it to produce the correct textual representation.\n    \n    # Correction to match textual representation with spaces as in standard `str(list)`\n    final_output_str = str(results)\n    \n    # A custom formatter to match the format from the prompt's `f\"[{','.join...}]\"` exactly\n    # just in case that's the intended interpretation (no spaces).\n    # final_output_str = f\"[{','.join(str(item) for item in results)}]\"\n    # This results in '[[...], [...]...]' with spaces inside but not between sublists.\n    # `str(list)` is the most standard interpretation of \"textual list representation\".\n    \n    print(final_output_str)\n\n\nsolve()\n```"
        },
        {
            "introduction": "确定模型参数的最佳估计值只是分析的第一步，同样重要的是要量化这些估计值的不确定性。对于非线性模型，传统的置信区间计算方法可能并不可靠。本练习将介绍一种更为稳健和强大的技术——剖面似然法（profile likelihood），用以构建参数的置信区间()。您将以阿伦尼乌斯（Arrhenius）方程为例，通过计算活化能（$E_a$）的剖面似然，亲身体验该方法如何揭示参数不确定性的真实（通常是不对称的）性质。",
            "id": "4082889",
            "problem": "给定一个遵循阿伦尼乌斯定律 (Arrhenius law) 的单步地球化学反应的数据集，其中包含随温度变化的反应速率常数。阿伦尼乌斯定律指出，速率常数 $k(T)$ 作为温度 $T$（单位：开尔文）的函数，由 $k(T) = A \\exp(-E_a/(R T))$ 给出。其中 $A$ 是指前因子（单位：s$^{-1}$），$E_a$ 是活化能（单位：J/mol），$R$ 是普适气体常数，其值为 $R = 8.314462618$ J mol$^{-1}$ K$^{-1}$。假设在温度 $T_i$ 下测得的速率常数 $k_i$ 受到对数正态分布的乘性噪声影响。等价地，对数转换后的响应 $y_i = \\ln(k_i)$ 可以用具有未知方差的高斯分布建模，并且阿伦尼乌斯模型在对数空间中变为线性：$y_i = \\ln(A) - E_a/R \\cdot (1/T_i) + \\varepsilon_i$，其中 $\\varepsilon_i$ 是独立高斯噪声。\n\n您的任务是：\n- 在上述假设下，构建最大似然估计问题，将对数空间中的方差视为未知参数，并将 $A$ 和 $E_a$ 作为待估参数。\n- 对于每个固定的 $E_a$ 值，通过对讨厌参数 $A$ 进行似然最大化来构造 $E_a$ 的剖面似然。\n- 实现似然比统计量，用于检验固定值 $E_a$ 相对于无约束最大似然估计的假设，并使用它在指定的置信水平下计算 $E_a$（单位：kJ/mol）的置信区间。在非线性（非二次剖面性质）条件下解释此区间。\n\n您的程序必须：\n- 使用所提供的数据集（测试套件），并对每个数据集，在指定的边界和步长所构成的活化能 $E_a$（单位：kJ/mol）值网格上评估剖面似然。对于每个网格点，对 $A$ 进行最大化，并计算相对于无约束最大似然解的似然比统计量。\n- 使用针对单自由度的大样本似然比校准，将 $E_a$ 的置信集定义为似然比统计量不超过单自由度卡方分布的 $(\\text{confidence level})$ 分位数的所有值的集合。\n- 返回网格内包含该置信集的最小闭区间。如果所提供网格上的置信集为空，则返回网格边界作为区间。如果置信集连接到某个边界，则区间端点可能位于网格边界上。\n\n物理单位：\n- 输入温度单位必须是开尔文。\n- 输入速率常数单位必须是 s$^{-1}$。\n- 输出的置信区间端点必须以 kJ/mol 表示，并四舍五入到六位小数。\n\n角度单位不适用。任何分数或百分比必须表示为小数。\n\n测试套件：\n对于每个案例，您将获得温度 $T_i$（单位 K）、测量的速率常数 $k_i$（单位 s$^{-1}$）、活化能网格边界（单位 kJ/mol）和网格步长（单位 kJ/mol）。置信水平以小数形式给出。普适气体常数值为 $R = 8.314462618$ J mol$^{-1}$ K$^{-1}$。\n\n- 案例 1（温度间隔良好，中等噪声；“理想路径”）:\n    - $T = [280, 300, 320, 340, 360]$ K\n    - $k = [5.751\\times 10^{-6}, 3.938\\times 10^{-5}, 1.28\\times 10^{-4}, 6.258\\times 10^{-4}, 2.376\\times 10^{-3}]$ s$^{-1}$\n    - $E_a$ 网格：下界 $30$ kJ/mol，上界 $120$ kJ/mol，步长 $0.1$ kJ/mol\n    - 置信水平：$0.95$\n\n- 案例 2（温度范围窄；非线性增加）：\n    - $T = [295, 300, 305]$ K\n    - $k = [7.00\\times 10^{-4}, 9.31\\times 10^{-4}, 1.429\\times 10^{-3}]$ s$^{-1}$\n    - $E_a$ 网格：下界 $20$ kJ/mol，上界 $120$ kJ/mol，步长 $0.5$ kJ/mol\n    - 置信水平：$0.95$\n\n- 案例 3（高噪声，置信集可能触及网格边界）：\n    - $T = [290, 310, 330, 350]$ K\n    - $k = [1.18\\times 10^{-8}, 9.90\\times 10^{-9}, 1.08\\times 10^{-6}, 2.28\\times 10^{-7}]$ s$^{-1}$\n    - $E_a$ 网格：下界 $40$ kJ/mol，上界 $90$ kJ/mol，步长 $0.25$ kJ/mol\n    - 置信水平：$0.95$\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。该列表必须按顺序包含案例 1、案例 2、案例 3 的置信区间下限和上限端点（单位：kJ/mol，四舍五入到六位小数）。例如：\n- $\"[E1_{\\text{lower}},E1_{\\text{upper}},E2_{\\text{lower}},E2_{\\text{upper}},E3_{\\text{lower}},E3_{\\text{upper}}]\"$。",
            "solution": "此问题被评估为有效。它在科学上基于化学动力学（阿伦尼乌斯定律）和数理统计（最大似然估计、剖面似然、似然比检验）的原理。该问题是适定的，具有明确的目标和为获得唯一且有意义的解所需的所有数据和约束。语言客观而精确。\n\n### I. 理论阐述\n\n该问题要求估计地球化学反应活化能 $E_a$ 的置信区间。已知该反应的速率常数 $k$ 作为绝对温度 $T$ 的函数，遵循阿伦尼乌斯定律：\n$$ k(T) = A \\exp\\left(-\\frac{E_a}{RT}\\right) $$\n其中 $A$ 是指前因子，$E_a$ 是活化能，$R$ 是普适气体常数。\n\n为了便于线性分析，通过取自然对数来转换模型：\n$$ \\ln(k(T)) = \\ln(A) - \\frac{E_a}{R} \\frac{1}{T} $$\n我们给定一组 $n$ 个测量值 $(T_i, k_i)$。令 $y_i = \\ln(k_i)$ 和 $x_i = 1/T_i$。该模型可以表示为简单线性回归：\n$$ y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i $$\n此处，回归参数与物理参数的关系为 $\\beta_0 = \\ln(A)$ 和 $\\beta_1 = -E_a/R$。误差项 $\\varepsilon_i$ 假定为均值为 $0$ 且方差 $\\sigma^2$ 未知的独立同分布正态随机变量，即 $\\varepsilon_i \\sim N(0, \\sigma^2)$。\n\n给定参数 $\\beta_0$、$\\beta_1$ 和 $\\sigma^2$ 时，观测数据 $\\mathbf{y} = (y_1, ..., y_n)$ 的似然函数为：\n$$ L(\\beta_0, \\beta_1, \\sigma^2 | \\mathbf{y}) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_i - (\\beta_0 + \\beta_1 x_i))^2}{2\\sigma^2}\\right) $$\n对数似然函数为：\n$$ \\ln L(\\beta_0, \\beta_1, \\sigma^2) = -\\frac{n}{2}\\ln(2\\pi) - \\frac{n}{2}\\ln(\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - (\\beta_0 + \\beta_1 x_i))^2 $$\n最大化此对数似然等价于最小化残差平方和 $SSR(\\beta_0, \\beta_1) = \\sum_{i=1}^n (y_i - (\\beta_0 + \\beta_1 x_i))^2$。\n\n对于任何固定的 $\\beta_0$ 和 $\\beta_1$，$\\sigma^2$ 的最大似然估计 (MLE) 是 $\\hat{\\sigma}^2 = SSR(\\beta_0, \\beta_1)/n$。将其代入对数似然函数，得到 $\\beta_0$ 和 $\\beta_1$ 的剖面对数似然：\n$$ \\ln L_p(\\beta_0, \\beta_1) = -\\frac{n}{2}\\left(\\ln(2\\pi) + \\ln\\left(\\frac{SSR(\\beta_0, \\beta_1)}{n}\\right) + 1\\right) $$\n最大化此式等价于最小化 $SSR(\\beta_0, \\beta_1)$。\n\n### II. 无约束最大似然估计\n\n$\\beta_0$ 和 $\\beta_1$ 的无约束最大似然估计可以通过标准普通最小二乘法 (OLS) 回归找到。设 $\\bar{x}$ 和 $\\bar{y}$ 为 $x_i$ 和 $y_i$ 的样本均值。定义 $S_{xx} = \\sum(x_i - \\bar{x})^2$ 和 $S_{xy} = \\sum(x_i - \\bar{x})(y_i - \\bar{y})$。最大似然估计为：\n$$ \\hat{\\beta}_1 = \\frac{S_{xy}}{S_{xx}}, \\quad \\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x} $$\n无约束模型的最小残差平方和为 $SSR_{unconstrained} = \\sum(y_i - (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i))^2$。最大化后的对数似然为 $\\ln L_{max} = \\ln L_p(\\hat{\\beta}_0, \\hat{\\beta}_1)$。\n\n### III. $E_a$ 的剖面似然和置信区间\n\n我们关心的是 $E_a$ 的置信区间。我们构造 $E_a$ 的剖面似然。对于一个固定的活化能值 $E_a = E_{a,0}$，斜率参数也是固定的：$\\beta_1 = \\beta_{1,0} = -E_{a,0}/R$。模型变为 $y_i - \\beta_{1,0}x_i = \\beta_0 + \\varepsilon_i$。\n\n讨厌参数 $\\beta_0$ 是通过在 $\\beta_{1,0}$ 固定的情况下最大化似然来估计的。这等价于最小化 $SSR(\\beta_0) = \\sum(y_i - \\beta_{1,0}x_i - \\beta_0)^2$。解是 $\\beta_0$ 的条件最大似然估计：\n$$ \\hat{\\beta}_0(E_{a,0}) = \\frac{1}{n}\\sum(y_i - \\beta_{1,0}x_i) = \\bar{y} - \\beta_{1,0}\\bar{x} $$\n这个约束模型对应的残差平方和是：\n$$ SSR_{constrained}(E_{a,0}) = \\sum (y_i - (\\hat{\\beta}_0(E_{a,0}) + \\beta_{1,0} x_i))^2 $$\n这可以高效地计算为 $SSR_{constrained}(E_{a,0}) = S_{yy} - 2\\beta_{1,0}S_{xy} + \\beta_{1,0}^2 S_{xx}$，其中 $S_{yy} = \\sum(y_i - \\bar{y})^2$。\n\n$E_a$ 的剖面对数似然是在每个固定的 $E_a$ 值下最大化的对数似然：\n$$ \\ln L(E_{a,0}) = -\\frac{n}{2}\\left(\\ln(2\\pi) + \\ln\\left(\\frac{SSR_{constrained}(E_{a,0})}{n}\\right) + 1\\right) $$\n用于检验假设 $H_0: E_a = E_{a,0}$ 的似然比检验统计量是：\n$$ \\Lambda(E_{a,0}) = -2(\\ln L(E_{a,0}) - \\ln L_{max}) = n \\ln\\left(\\frac{SSR_{constrained}(E_{a,0})}{SSR_{unconstrained}}\\right) $$\n根据威尔克斯定理，在原假设下，该统计量渐近服从自由度为1的卡方分布 $\\chi^2_1$。\n\n$E_a$ 的一个 $(1-\\alpha)$ 置信区间由在显著性水平 $\\alpha$ 下不被似然比检验 (LRT) 拒绝的所有 $E_{a,0}$ 值构成。这个集合是：\n$$ \\{ E_a \\mid \\Lambda(E_a) \\le C \\} $$\n其中 $C$ 是 $\\chi^2_1$ 分布的 $(1-\\alpha)$ 分位数（例如，对于 $95\\%$ 的置信水平，$\\alpha=0.05$，$C \\approx 3.841$）。该方法优于像瓦尔德区间这样的简单方法，因为它不假设对数似然函数是二次的。当剖面似然是偏斜时，它自然会产生非对称区间，这种情况在小数据集或高度相关的参数（例如在狭窄温度范围内的阿伦尼乌斯分析）中经常发生。\n\n### IV. 算法实现\n\n对于每个测试案例，实现以下过程：\n1.  将输入数据 $(T_i, k_i)$ 转换为 $(x_i, y_i) = (1/T_i, \\ln(k_i))$。\n2.  定义数据点数 $n$ 和普适气体常数 $R=8.314462618$ J mol$^{-1}$ K$^{-1}$。\n3.  计算汇总统计量 $\\bar{x}$、$\\bar{y}$、$S_{xx}$、$S_{yy}$ 和 $S_{xy}$。\n4.  计算无约束最大似然估计 $\\hat{\\beta}_1$ 和 $\\hat{\\beta}_0$，以及最小残差平方和 $SSR_{unconstrained} = S_{yy} - \\hat{\\beta}_1 S_{xy}$。\n5.  根据给定的置信水平，从 $\\chi^2_1$ 分布中确定临界值 $C$。\n6.  根据指定的边界和步长生成一个 $E_a$ 值的网格。\n7.  对于每个网格值 $E_{a,0}$ (单位：kJ/mol)：\n    a.  将 $E_{a,0}$ 乘以 $1000$ 转换为 J/mol。\n    b.  计算对应的固定斜率 $\\beta_{1,0} = -E_{a,0}/R$。\n    c.  计算约束模型的残差平方和 $SSR_{constrained}(E_{a,0}) = S_{yy} - 2\\beta_{1,0}S_{xy} + \\beta_{1,0}^2 S_{xx}$。\n    d.  计算似然比统计量 $\\Lambda(E_{a,0}) = n \\ln(SSR_{constrained}(E_{a,0}) / SSR_{unconstrained})$。\n    e.  如果 $\\Lambda(E_{a,0}) \\le C$，则将网格值 $E_{a,0}$ 添加到可接受值的集合中。\n8.  如果可接受值的集合为空，则区间由网格边界定义。否则，最终的置信区间由集合中的最小值和最大值确定。\n9.  区间的下限和上限被四舍五入到六位小数，并格式化以供输出。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef calculate_confidence_interval(T, k, Ea_grid_params, conf_level):\n    \"\"\"\n    Calculates the confidence interval for Ea using the profile likelihood method.\n    \"\"\"\n    R = 8.314462618  # J mol^-1 K^-1\n    T_arr = np.array(T, dtype=np.float64)\n    k_arr = np.array(k, dtype=np.float64)\n    n = len(T_arr)\n\n    # 1. Transform data to linear form: y = b0 + b1*x\n    # y = ln(k), x = 1/T\n    # b0 = ln(A), b1 = -Ea/R\n    y = np.log(k_arr)\n    x = 1.0 / T_arr\n\n    # 2. Calculate summary statistics for OLS\n    x_bar = np.mean(x)\n    y_bar = np.mean(y)\n    \n    S_xx = np.sum((x - x_bar)**2)\n    S_yy = np.sum((y - y_bar)**2)\n    S_xy = np.sum((x - x_bar) * (y - y_bar))\n\n    # 3. Unconstrained Maximum Likelihood Estimation\n    # These are the standard OLS estimates\n    beta1_hat = S_xy / S_xx\n    # beta0_hat = y_bar - beta1_hat * x_bar # Not strictly needed for LRT\n    \n    # Calculate Sum of Squared Residuals for the unconstrained model\n    SSR_unconstrained = S_yy - beta1_hat * S_xy\n    if SSR_unconstrained = 0: # Should not happen with real data, but for robustness\n        SSR_unconstrained = 1e-20\n\n    # 4. Get critical value from Chi-square distribution\n    # df = 1 because we are constraining one parameter (Ea, which is equivalent to b1)\n    critical_value = chi2.ppf(conf_level, df=1)\n\n    # 5. Grid search for Ea\n    Ea_lower_kj, Ea_upper_kj, Ea_step_kj = Ea_grid_params\n    Ea_grid_kj = np.arange(Ea_lower_kj, Ea_upper_kj + Ea_step_kj, Ea_step_kj)\n    \n    valid_Ea_values = []\n\n    for Ea_kj in Ea_grid_kj:\n        Ea_j = Ea_kj * 1000.0  # Convert from kJ/mol to J/mol\n        \n        # This is the fixed slope under Ho: Ea = Ea_j\n        beta1_0 = -Ea_j / R\n        \n        # Calculate SSR for the constrained model (where slope is fixed)\n        # SSR_constrained = sum(( (y-y_bar) - b1_0*(x-x_bar) )^2)\n        # which expands to:\n        SSR_constrained = S_yy - 2 * beta1_0 * S_xy + beta1_0**2 * S_xx\n        \n        # LRT statistic\n        if SSR_constrained  SSR_unconstrained:\n            # Due to floating point issues, might be slightly smaller.\n            # The test statistic must be non-negative.\n            lrt_statistic = 0.0\n        else:\n            lrt_statistic = n * np.log(SSR_constrained / SSR_unconstrained)\n        \n        if lrt_statistic = critical_value:\n            valid_Ea_values.append(Ea_kj)\n\n    # 6. Determine interval from the set of valid Ea values\n    if not valid_Ea_values:\n        return Ea_lower_kj, Ea_upper_kj\n    else:\n        return min(valid_Ea_values), max(valid_Ea_values)\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    \"\"\"\n    test_cases = [\n        {\n            \"T\": [280, 300, 320, 340, 360],\n            \"k\": [5.751e-6, 3.938e-5, 1.28e-4, 6.258e-4, 2.376e-3],\n            \"grid\": (30, 120, 0.1),\n            \"level\": 0.95\n        },\n        {\n            \"T\": [295, 300, 305],\n            \"k\": [7.00e-4, 9.31e-4, 1.429e-3],\n            \"grid\": (20, 120, 0.5),\n            \"level\": 0.95\n        },\n        {\n            \"T\": [290, 310, 330, 350],\n            \"k\": [1.18e-8, 9.90e-9, 1.08e-6, 2.28e-7],\n            \"grid\": (40, 90, 0.25),\n            \"level\": 0.95\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        lower_bound, upper_bound = calculate_confidence_interval(\n            case[\"T\"], case[\"k\"], case[\"grid\"], case[\"level\"]\n        )\n        results.append(lower_bound)\n        results.append(upper_bound)\n    \n    # Format results to six decimal places for the final output string\n    formatted_results = [\"{:.6f}\".format(r) for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}