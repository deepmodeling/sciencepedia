## Introduction
At the heart of modern chemistry and materials science lies the challenge of describing how molecules move, react, and transform. While quantum mechanics provides the fundamental laws, its direct application is often computationally intractable. The Born-Oppenheimer (BO) approximation, which separates the motion of light electrons from that of heavy nuclei, has been the cornerstone of [computational chemistry](@entry_id:143039), enabling the simulation of molecular structures and ground-state reactions with remarkable success. However, many of the most fascinating and technologically important processes—from photosynthesis and vision to catalysis and charge transport in solar cells—involve the breakdown of this very approximation. In these scenarios, multiple electronic states become strongly coupled, and the system can no longer be described as evolving on a single potential energy surface. This is the domain of [non-adiabatic dynamics](@entry_id:197704).

This article addresses the critical knowledge gap between understanding the limitations of the BO approximation and implementing robust methods to simulate dynamics beyond it. It serves as a comprehensive guide to the theory and practice of non-adiabatic simulations, with a particular focus on the widely used [surface hopping](@entry_id:185261) methodologies. By bridging fundamental principles with practical applications, this text equips you with the tools to tackle complex chemical problems where [electronic transitions](@entry_id:152949) are not just a perturbation, but the main event.

The journey begins in the **Principles and Mechanisms** section, where we deconstruct the Born-Oppenheimer approximation to understand precisely where and why it fails. We will quantify the couplings that drive [electronic transitions](@entry_id:152949), explore the significance of [conical intersections](@entry_id:191929), and introduce the primary computational strategies for simulating these events, culminating in a detailed breakdown of the Fewest-Switches Surface Hopping (FSSH) algorithm. Next, in **Applications and Interdisciplinary Connections**, we will explore how these methods are applied to solve real-world problems in [heterogeneous catalysis](@entry_id:139401), photochemistry, and materials science, highlighting the decision-making process required to choose the right tool for the job. Finally, the **Hands-On Practices** section provides concrete exercises to translate theoretical knowledge into practical computational skills, from calculating couplings to simulating [population dynamics](@entry_id:136352) and reaction rates.

## Principles and Mechanisms

### The Breakdown of the Born-Oppenheimer Approximation

The foundation of most quantum chemistry and [materials simulation](@entry_id:176516) rests upon the **Born-Oppenheimer (BO) approximation**. This approximation is justified by the vast difference in mass between electrons and atomic nuclei. Because nuclei are thousands of times heavier than electrons, their motion is correspondingly slower. This separation of timescales allows us to decouple the electronic and nuclear problems: we can solve for the electronic structure of a system for a fixed, or "clamped," nuclear geometry, and then treat the motion of the nuclei as occurring on a potential energy surface (PES) generated by the resulting electronic energy.

To formalize this, consider a molecular system with nuclear coordinates $\mathbf{R}$ and electronic coordinates $\mathbf{r}$. The total non-relativistic Hamiltonian, $H$, can be written as the sum of the nuclear kinetic energy, $T_n$, and the electronic Hamiltonian, $H_e$:

$H = T_n + H_e(\mathbf{R})$

The electronic Hamiltonian, $H_e(\mathbf{R})$, includes the kinetic energy of the electrons ($T_e$) and all Coulombic potential energy terms (electron-electron $V_{ee}$, electron-nuclear $V_{en}$, and nuclear-nuclear $V_{nn}$), and it depends parametrically on the nuclear configuration $\mathbf{R}$. The nuclear [kinetic energy operator](@entry_id:265633) is given by:

$T_n = -\sum_{\alpha} \frac{\hbar^2}{2 M_{\alpha}} \nabla_{\mathbf{R}_{\alpha}}^{2}$

where $M_{\alpha}$ is the mass of nucleus $\alpha$. The BO approximation begins by solving the time-independent Schrödinger equation for the electrons at a fixed $\mathbf{R}$:

$H_e(\mathbf{R}) \phi_j(\mathbf{r}; \mathbf{R}) = U_j(\mathbf{R}) \phi_j(\mathbf{r}; \mathbf{R})$

This yields a set of adiabatic electronic wavefunctions, $\phi_j(\mathbf{r}; \mathbf{R})$, and their corresponding potential energy surfaces, $U_j(\mathbf{R})$. The total system wavefunction, $\Psi(\mathbf{r}, \mathbf{R})$, can be rigorously expanded in this adiabatic basis, a representation known as the **Born-Huang expansion**:

$\Psi(\mathbf{r}, \mathbf{R}) = \sum_{j} \chi_{j}(\mathbf{R}) \phi_{j}(\mathbf{r}; \mathbf{R})$

Here, $\chi_j(\mathbf{R})$ are the nuclear wavefunctions. When this expansion is substituted into the full time-independent Schrödinger equation, $H\Psi = E\Psi$, and we project onto a specific electronic state $\phi_i$, we obtain a set of coupled equations for the nuclear wavefunctions. The BO approximation consists of neglecting the off-diagonal coupling terms in these equations, effectively assuming that the [nuclear motion](@entry_id:185492) is confined to a single PES.

The terms that are neglected are the **[non-adiabatic coupling](@entry_id:159497) operators**. These operators arise because the nuclear [kinetic energy operator](@entry_id:265633) $T_n$ acts on the complete product $\chi_j(\mathbf{R}) \phi_j(\mathbf{r}; \mathbf{R})$, and since the adiabatic electronic wavefunctions $\phi_j$ depend on $\mathbf{R}$, the derivatives $\nabla_{\mathbf{R}_{\alpha}}$ do not vanish when applied to them. This gives rise to coupling terms, $\Lambda_{ij}$, which mediate transitions between different electronic states:

$\Lambda_{ij} = -\sum_{\alpha} \frac{\hbar^2}{M_{\alpha}} \langle \phi_i | \nabla_{\mathbf{R}_{\alpha}} | \phi_j \rangle_{\mathbf{r}} \cdot \nabla_{\mathbf{R}_{\alpha}} - \sum_{\alpha} \frac{\hbar^2}{2M_{\alpha}} \langle \phi_i | \nabla^2_{\mathbf{R}_{\alpha}} | \phi_j \rangle_{\mathbf{r}}$

The validity of the BO approximation is controlled by the [mass ratio](@entry_id:167674) $m_e/M_\alpha$. If we define a representative nuclear mass $m_n$ and a small dimensionless parameter $\epsilon = \sqrt{m_e/m_n}$, we see that in [atomic units](@entry_id:166762) (where $\hbar=1, m_e=1$), the nuclear masses $M_\alpha$ are of order $\mathcal{O}(\epsilon^{-2})$. Consequently, the prefactors $1/M_\alpha$ in $T_n$ and $\Lambda_{ij}$ are of order $\mathcal{O}(\epsilon^2)$. This means the entire nuclear [kinetic energy operator](@entry_id:265633) $T_n$ scales as $\mathcal{O}(\epsilon^2)$, while the electronic Hamiltonian $H_e$ scales as $\mathcal{O}(1)$. The **adiabatic limit** is the limit where $\epsilon \to 0$ (infinitely heavy nuclei), in which the non-adiabatic couplings vanish and the BO approximation becomes exact. However, for finite nuclear masses, these coupling terms are non-zero and can become significant, leading to the breakdown of the BO approximation and enabling **[non-adiabatic dynamics](@entry_id:197704)**. 

### Quantifying Non-Adiabatic Coupling

The key quantity that governs transitions between adiabatic electronic states is the **[non-adiabatic coupling](@entry_id:159497) vector (NACV)**, or **[derivative coupling](@entry_id:202003)**, defined as:

$\mathbf{d}_{ij}(\mathbf{R}) = \langle \phi_i(\mathbf{R}) | \nabla_{\mathbf{R}} | \phi_j(\mathbf{R}) \rangle$

This vector quantifies how much the electronic wavefunction of state $j$ changes in the direction of state $i$ as the nuclear geometry $\mathbf{R}$ is infinitesimally displaced. Its physical significance becomes clear when we consider the time evolution of the electronic state in the mixed quantum-classical framework, where nuclei move along a classical trajectory $\mathbf{R}(t)$. The electronic wavefunction $|\Psi_e(t)\rangle = \sum_j c_j(t) |\phi_j(\mathbf{R}(t))\rangle$ evolves according to the time-dependent Schrödinger equation (TDSE). This leads to a set of coupled equations for the amplitudes $c_j(t)$:

$i\hbar \dot{c}_j(t) = c_j(t) E_j(t) - i\hbar \sum_k c_k(t) \dot{\mathbf{R}}(t) \cdot \mathbf{d}_{jk}(\mathbf{R}(t))$

The first term on the right describes the phase evolution of the amplitude on its own potential energy surface. The second term is the [non-adiabatic coupling](@entry_id:159497), which drives [population transfer](@entry_id:170564) between states. It is the [scalar product](@entry_id:175289) of the nuclear velocity $\dot{\mathbf{R}}$ and the NACV $\mathbf{d}_{jk}$ that acts as the "engine" of [non-adiabatic transitions](@entry_id:175769). Without [nuclear motion](@entry_id:185492) ($\dot{\mathbf{R}}=0$) or without coupling ($\mathbf{d}_{jk}=0$), no transitions occur. 

A crucial property of the NACV can be derived by differentiating the electronic Schrödinger equation with respect to $\mathbf{R}$ (a result related to the Hellmann-Feynman theorem). For non-[degenerate states](@entry_id:274678) ($i \neq j$), this yields:

$\mathbf{d}_{ij}(\mathbf{R}) = \frac{\langle \phi_i(\mathbf{R}) | (\nabla_{\mathbf{R}} H_e(\mathbf{R})) | \phi_j(\mathbf{R}) \rangle}{E_j(\mathbf{R}) - E_i(\mathbf{R})}$

This expression reveals a fundamental insight: the magnitude of the [non-adiabatic coupling](@entry_id:159497) is inversely proportional to the energy gap between the electronic states. This means that [non-adiabatic transitions](@entry_id:175769) are most likely to occur in regions of the nuclear configuration space where potential energy surfaces approach each other closely, i.e., at **[avoided crossings](@entry_id:187565)** or **[conical intersections](@entry_id:191929)**. As the energy denominator $|E_j - E_i|$ approaches zero, the coupling strength tends to diverge, making the BO approximation fail spectacularly. 

It is also worth noting the properties of the diagonal coupling, $\mathbf{d}_{ii}(\mathbf{R})$. While it can sometimes be made zero locally by a choice of phase for the wavefunction, it cannot always be globally eliminated. Its curl is related to the **Berry curvature**, and its integral around a closed loop in nuclear configuration space gives the **Berry phase**, a geometric phase with observable consequences for nuclear dynamics. 

### Regions of Strong Coupling: Conical Intersections

The most dramatic failure of the Born-Oppenheimer approximation occurs at **[conical intersections](@entry_id:191929) (CIs)**, which are points or seams of true [electronic degeneracy](@entry_id:147984) in polyatomic systems. These features act as efficient funnels for ultrafast, radiationless transitions between electronic states and are central to processes in [photochemistry](@entry_id:140933), vision, and catalysis.

For a system with $N$ atoms, the degeneracy can be lifted by nuclear displacements in at most two dimensions. These two directions define the **branching plane**. Motion within this plane lifts the degeneracy linearly, forming a double-cone topology of the [potential energy surfaces](@entry_id:160002) around the intersection point, $\mathbf{R}_c$. Motion in the remaining $3N-8$ dimensions (for a non-linear molecule) does not lift the degeneracy to first order; this space is known as the **seam space** or intersection space.

The local topology of a CI can be understood using a simple two-state diabatic model. In a **[diabatic basis](@entry_id:188251)**, the electronic wavefunctions are chosen to vary smoothly with nuclear coordinates, which means the electronic Hamiltonian matrix $\mathbf{H}_e$ is not diagonal. For a two-state system near a CI, we can write:

$\mathbf{H}_e(\mathbf{R}) = \begin{pmatrix} V_{11}(\mathbf{R}) & V_{12}(\mathbf{R}) \\ V_{12}(\mathbf{R}) & V_{22}(\mathbf{R}) \end{pmatrix}$

A [conical intersection](@entry_id:159757) at $\mathbf{R}_c$ corresponds to the two conditions:
1.  The diabatic energies are degenerate: $V_{11}(\mathbf{R}_c) = V_{22}(\mathbf{R}_c)$.
2.  The [diabatic coupling](@entry_id:198284) vanishes: $V_{12}(\mathbf{R}_c) = 0$.

The adiabatic potential energies are the eigenvalues of this matrix:

$E_{\pm}(\mathbf{R}) = \frac{V_{11} + V_{22}}{2} \pm \sqrt{\left(\frac{V_{11} - V_{22}}{2}\right)^2 + V_{12}^2}$

Near $\mathbf{R}_c$, the terms under the square root can be expanded to first order in the nuclear displacement $\delta\mathbf{R} = \mathbf{R} - \mathbf{R}_c$. The two vectors that define the branching plane are then found to be the gradient-difference vector, $\mathbf{g}$, and the coupling-gradient vector, $\mathbf{h}$:

$\mathbf{g} = \left.\nabla_{\mathbf{R}}\left[V_{11}(\mathbf{R}) - V_{22}(\mathbf{R})\right]\right|_{\mathbf{R}_c}$

$\mathbf{h} = \left.\nabla_{\mathbf{R}} V_{12}(\mathbf{R})\right|_{\mathbf{R}_c}$

Displacements along $\mathbf{g}$ and $\mathbf{h}$ lift the degeneracy, while displacements orthogonal to both vectors maintain the degeneracy to first order. The energy gap $\Delta E = E_+ - E_-$ opens linearly with distance from the CI within the branching plane, forming the characteristic cone shape that gives these intersections their name. 

### Simulating Non-Adiabatic Dynamics: An Overview of Approaches

To simulate molecular processes where the BO approximation fails, we require methods that can account for transitions between electronic states. Several mixed quantum-classical approaches have been developed, where the electrons are treated quantum mechanically and the nuclei are treated as classical particles.

#### The Mean-Field Approach: Ehrenfest Dynamics

The most direct extension of [classical molecular dynamics](@entry_id:1122427) is **Ehrenfest dynamics**. In this method, the electronic wavefunction $|\Psi_e(t)\rangle$ evolves according to the TDSE, driven by the potential from the moving nuclei. In turn, the nuclei evolve classically under a force that is the expectation value of the quantum force operator (the Hellmann-Feynman force): $\mathbf{F}_{\text{Eh}} = -\langle \Psi_e(t) | \nabla_{\mathbf{R}} H_e(\mathbf{R}) | \Psi_e(t) \rangle$. This creates a trajectory that evolves on a single [mean-field potential](@entry_id:158256) energy surface, where the force is an average over the forces from each adiabatic state, weighted by the electronic amplitudes.

While conceptually simple, Ehrenfest dynamics suffers from serious deficiencies. If the electronic state is a superposition of two states (e.g., after passing through a coupling region), the nuclei feel a force averaged from both surfaces. This can lead the trajectory along an unphysical path that exists neither on the upper nor the lower PES. Furthermore, Ehrenfest dynamics fails to describe **electronic decoherence**—the process by which a superposition state collapses into a statistical mixture as the associated nuclear wavepackets separate. This leads to trajectories remaining in unphysical coherent superpositions for too long. 

#### The Trajectory-Based Approach: Surface Hopping

To overcome the mean-field problem, **[surface hopping](@entry_id:185261) (SH)** methods were developed. The central idea is to propagate the nuclear trajectory on a single adiabatic potential energy surface at any given time. The electronic wavefunction is still propagated coherently via the TDSE, but its amplitudes are used to calculate probabilities for stochastic, instantaneous "hops" from the current active surface to another. This approach allows for the branching of trajectories onto different electronic states, providing a more physically intuitive picture of the dynamics. The most widely used variant is the **Fewest-Switches Surface Hopping (FSSH)** algorithm. 

#### The Dissipative Approach: Electronic Friction

For systems where the [nuclear motion](@entry_id:185492) is coupled to a dense continuum of electronic states, such as an adsorbate on a metal surface, an alternative approach is to model the effect of the electrons as a dissipative environment. This leads to **molecular dynamics with electronic friction**. The [nuclear motion](@entry_id:185492) is described by a **Langevin-like equation**, which includes not only the [conservative force](@entry_id:261070) from the ground-state PES but also a velocity-dependent **frictional force** and a **stochastic (random) force**:

$M \ddot{\mathbf{R}}(t) = -\nabla_{\mathbf{R}} U(\mathbf{R}(t)) - \boldsymbol{\Lambda}(\mathbf{R}(t)) \cdot \dot{\mathbf{R}}(t) + \boldsymbol{\eta}(t)$

Here, $\boldsymbol{\Lambda}(\mathbf{R})$ is the **electronic friction tensor**, and $\boldsymbol{\eta}(t)$ is the random force. Crucially, these two terms are not independent but are related by the **[fluctuation-dissipation theorem](@entry_id:137014)**. In the Markovian (memory-less) limit, the friction tensor can be calculated from the time-integral of the equilibrium [time-correlation function](@entry_id:187191) of the electronic force fluctuations, a result from Green-Kubo theory:

$\Lambda_{\alpha \beta}(\mathbf{R}) = \frac{1}{k_B T} \int_{0}^{\infty} \langle \delta F_{\alpha}(0) \delta F_{\beta}(t) \rangle_{\mathrm{eq}, \mathbf{R}} \, dt$

The random force $\boldsymbol{\eta}(t)$ is a white noise term whose strength is proportional to both the temperature and the friction tensor: $\langle \eta_{\alpha}(t) \eta_{\beta}(t') \rangle = 2 k_{\mathrm{B}} T \Lambda_{\alpha \beta}(\mathbf{R}) \delta(t-t')$. This framework models energy transfer between the nuclear and electronic degrees of freedom as a continuous process of dissipation and thermal fluctuation, rather than discrete hops. 

### The Fewest-Switches Surface Hopping (FSSH) Algorithm in Detail

The FSSH algorithm provides a practical and powerful framework for simulating [non-adiabatic dynamics](@entry_id:197704). It is designed to ensure that in an ensemble of independent trajectories, the fraction of trajectories residing on each electronic state matches the quantum mechanical population of that state.

#### The Core Algorithm

A single FSSH time step for a trajectory active on state $a$ consists of the following ordered steps :

1.  **Classical Nuclear Propagation**: Advance the nuclear positions $\mathbf{R}$ and velocities $\mathbf{v}$ for a time step $\Delta t$ by integrating Newton's equations of motion on the *active* potential energy surface, $E_a(\mathbf{R})$: $M \ddot{\mathbf{R}}(t) = -\nabla_{\mathbf{R}} E_a(\mathbf{R}(t))$.

2.  **Electronic Amplitude Propagation**: Concurrently, advance the electronic amplitudes $c_i(t)$ by integrating the TDSE in the [adiabatic representation](@entry_id:192459) over the same time step $\Delta t$. This accounts for both phase accumulation and [population transfer](@entry_id:170564) driven by the [non-adiabatic coupling](@entry_id:159497) $\mathbf{v} \cdot \mathbf{d}_{ij}$.

3.  **Hopping Probability Calculation**: At the end of the time step, calculate the probability of hopping from the active state $a$ to every other state $j$. This probability, $g_{aj}$, is derived from the rate of population flow out of state $a$ into state $j$:
    $g_{aj}(t) = \max \left( 0, \frac{-2 \Delta t \text{Re} \left[ c_a^*(t) c_j(t) \mathbf{v}(t) \cdot \mathbf{d}_{aj}(\mathbf{R}) \right]}{|c_a(t)|^2} \right)$
    Note the use of the property $\mathbf{d}_{ja} = -\mathbf{d}_{aj}^*$. The term inside the Re[...] represents the rate of amplitude flow from $j$ to $a$. The negative sign gives the flow from $a$ to $j$. The max(0, ...) ensures that only transitions that decrease the population of the active state are considered for a hop.

4.  **Stochastic Hop Decision**: Generate a uniform random number $\xi \in [0,1)$. Calculate the total probability to switch away from state $a$, $G_a = \sum_{j \neq a} g_{aj}$. If $\xi  G_a$, a hop is accepted. The target state $j$ is chosen from the available states with probabilities proportional to their respective $g_{aj}$ values. If $\xi \ge G_a$, no hop occurs, and the trajectory remains on state $a$.

5.  **Energy Conservation and Velocity Adjustment**: If a hop to state $j$ is accepted, the potential energy changes instantaneously by $\Delta E = E_j(\mathbf{R}) - E_a(\mathbf{R})$. To conserve total energy, the nuclear kinetic energy must be adjusted accordingly.

#### Energy Conservation and Momentum Rescaling

The standard FSSH procedure adjusts the nuclear momentum (and thus velocity) along the direction of the [non-adiabatic coupling](@entry_id:159497) vector $\mathbf{d}_{aj}$ that mediated the hop. This is physically motivated as this direction is responsible for the [electronic transition](@entry_id:170438). Let the pre-hop momentum be $\mathbf{p}$ and the post-hop momentum be $\mathbf{p}' = \mathbf{p} + \alpha \hat{\mathbf{n}}$, where $\hat{\mathbf{n}}$ is a [unit vector](@entry_id:150575) proportional to $\mathbf{d}_{aj}$ and $\alpha$ is a scalar adjustment. Enforcing total energy conservation leads to a quadratic equation for $\alpha$ :

$\frac{1}{2m} \alpha^2 + \frac{\mathbf{p} \cdot \hat{\mathbf{n}}}{m} \alpha + (E_j - E_a) = 0$

Solving this equation for $\alpha$ yields two possible solutions. The physically meaningful root is chosen, which typically corresponds to the one that results in the minimum change to the momentum. 

#### Frustrated Hops

A critical situation arises when a hop to a higher energy surface ($E_j > E_a$) is attempted. The quadratic equation for $\alpha$ may have no real solutions, which occurs when the kinetic energy available along the coupling direction is insufficient to pay the potential energy "cost" $\Delta E = E_j - E_a$. Such an event is called a **frustrated hop**.

When a hop is frustrated, it is rejected by the algorithm. According to the standard FSSH protocol, the trajectory simply continues on the original active surface $a$, and the nuclear momentum is not changed. Crucially, the electronic amplitudes $\{c_k(t)\}$ are also left unaltered; they continue their [unitary evolution](@entry_id:145020) from their current values as if the hop was never attempted. No [wavefunction collapse](@entry_id:152132) or [renormalization](@entry_id:143501) occurs as a result of the rejection. This seemingly simple rule has profound consequences for the long-time behavior of the simulation. 

### Critical Limitations of Standard FSSH and Modern Corrections

Despite its power and widespread use, the standard FSSH algorithm has well-known theoretical limitations that can affect its accuracy, particularly in complex, multi-event simulations.

#### The Decoherence Problem

After a trajectory passes through a coupling region and emerges as a superposition of electronic states, the components of the nuclear wavepacket associated with each state begin to travel on different [potential energy surfaces](@entry_id:160002). They experience different forces and will separate in phase space. In a fully quantum description, this separation leads to the decay of the off-diagonal elements of the electronic [density matrix](@entry_id:139892)—a process called **electronic decoherence**. The system evolves from a pure [coherent superposition](@entry_id:170209) into a statistical mixture.

Standard FSSH fails to capture this process. Because it propagates a single classical trajectory, the different "branches" of the nuclear wavepacket are not represented. The electronic wavefunction remains coherent indefinitely, even when the PESs are well-separated and uncoupled. This **overcoherence** is unphysical and can lead to incorrect behavior if the trajectory later re-enters a coupling region, as it carries an artificial "memory" of phase relationships that should have decayed.

To remedy this, various **decoherence correction** schemes have been proposed. Many of these involve damping the amplitudes of the inactive electronic states over a characteristic **decoherence time**, $\tau_d$. Physically motivated definitions for $\tau_d$ can be derived from the two main drivers of decoherence :

1.  **Energy-Gap Dephasing**: The rapid accumulation of [relative phase](@entry_id:148120) between states with a large energy gap $\Delta E$. The [characteristic timescale](@entry_id:276738) for this [dephasing](@entry_id:146545) is given by the [time-energy uncertainty principle](@entry_id:186272):
    $\tau_d = \frac{\hbar}{|\Delta E|}$

2.  **Wavepacket Separation**: The time it takes for nuclear wavepackets of width $\sigma$ to become spatially distinct. This can be driven by a difference in velocity $\Delta v$ or a difference in force $\Delta F$:
    $\tau_d \approx \frac{\sigma}{|\Delta v|}$ or $\tau_d \approx \sqrt{\frac{2m\sigma}{|\Delta F|}}$

Incorporating such corrections is essential for accurately simulating systems that undergo multiple non-adiabatic events.

#### Violation of Detailed Balance

Another significant limitation of standard FSSH is its failure to maintain **detailed balance**. In thermal equilibrium at temperature $T$, the ratio of forward and reverse [transition rate](@entry_id:262384) constants between two states must equal the Boltzmann factor of their energy difference:

$\frac{k_{i \to j}}{k_{j \to i}} = \exp\left(-\frac{E_j - E_i}{k_B T}\right)$

Standard FSSH does not inherently satisfy this condition. The reasons are multifaceted :

-   The hopping probability depends on dynamical quantities ($c_k, \mathbf{v}, \mathbf{d}_{ij}$) and does not contain an explicit Boltzmann weighting factor.
-   The asymmetric treatment of frustrated hops strongly suppresses upward transitions in a manner that is purely mechanical (based on kinetic energy) and not thermodynamically consistent. Downward hops are never frustrated.
-   The overcoherence problem means that the system does not properly thermalize, as trajectories retain unphysical electronic phase information.

As a result, an ensemble of FSSH trajectories may not relax to the correct Boltzmann distribution of electronic [state populations](@entry_id:197877) at long times. Achieving detailed balance in FSSH requires modifications, with the inclusion of decoherence corrections being one of the most important steps toward restoring proper thermodynamic behavior. 