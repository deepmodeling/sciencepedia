{
    "hands_on_practices": [
        {
            "introduction": "Understanding statistical ensembles begins with their mathematical foundations. This exercise takes you back to first principles to derive a key component of the microcanonical ensemble: the kinetic contribution to the density of states, $\\Omega(E)$. By performing this multidimensional integral, you will see how the characteristic energy dependence of the phase space volume emerges directly from the quadratic form of the kinetic energy, providing a concrete link between the system's Hamiltonian and its statistical properties. ",
            "id": "3900131",
            "problem": "Consider a classical molecular system relevant to heterogeneous catalytic reaction modeling, consisting of $N$ adsorbed species whose Cartesian coordinates are collected into the $3N$-dimensional position vector $\\mathbf{r}$ and whose conjugate momenta are collected into the $3N$-dimensional momentum vector $\\mathbf{p}$. The system is governed by the Hamiltonian\n$$\nH(\\mathbf{r},\\mathbf{p}) \\;=\\; \\sum_{i=1}^{N} \\frac{\\mathbf{p}_{i}^{2}}{2 m_{i}} \\;+\\; U(\\mathbf{r}),\n$$\nwhere $\\mathbf{p}_{i}$ is the $3$-component momentum of particle $i$, $m_{i}$ is its mass, and $U(\\mathbf{r})$ is a differentiable potential energy surface arising from the catalyst–adsorbate interactions and adsorbate–adsorbate interactions. In the microcanonical ensemble, the density of states at energy $E$ is defined by the phase-space integral\n$$\n\\Omega(E) \\;=\\; \\int \\delta\\!\\big(E - H(\\mathbf{r},\\mathbf{p})\\big)\\, d^{3N}\\mathbf{r}\\, d^{3N}\\mathbf{p},\n$$\nwhere $\\delta(\\cdot)$ is the Dirac delta function. Focusing on the kinetic contribution at a fixed configuration $\\mathbf{r}$, consider the momentum integral\n$$\nI(E,\\mathbf{r}) \\;=\\; \\int_{\\mathbb{R}^{3N}} \\delta\\!\\left(E - U(\\mathbf{r}) - \\sum_{i=1}^{N} \\frac{\\mathbf{p}_{i}^{2}}{2 m_{i}} \\right)\\, d^{3N}\\mathbf{p}.\n$$\nStarting from the fundamental definition of the microcanonical density of states and the standard properties of the Dirac delta function and multidimensional integrals, compute $I(E,\\mathbf{r})$ exactly in closed form for $E>U(\\mathbf{r})$, expressing the result as a function of $E$, $U(\\mathbf{r})$, $N$, and $\\{m_{i}\\}_{i=1}^{N}$, and using standard special functions if needed. Your final answer should be a single analytic expression. Do not provide a numerical approximation. Do not include any physical units in your final expression.",
            "solution": "The problem requires the computation of the momentum integral, $I(E,\\mathbf{r})$, for a classical system of $N$ particles, given by:\n$$I(E,\\mathbf{r}) \\;=\\; \\int_{\\mathbb{R}^{3N}} \\delta\\!\\left(E - U(\\mathbf{r}) - \\sum_{i=1}^{N} \\frac{\\mathbf{p}_{i}^{2}}{2 m_{i}} \\right)\\, d^{3N}\\mathbf{p}$$\nThe integral is to be evaluated for a fixed configuration $\\mathbf{r}$ under the condition $E > U(\\mathbf{r})$.\n\nFirst, let us define the total kinetic energy of the system as $K_{sys}$. The argument of the Dirac delta function, $\\delta(\\cdot)$, sets a constraint on the total energy. The delta function is non-zero only when its argument is zero, which means:\n$$E - U(\\mathbf{r}) - \\sum_{i=1}^{N} \\frac{\\mathbf{p}_{i}^{2}}{2 m_{i}} = 0$$\nThis implies that the integral is evaluated over the surface in phase space where the total kinetic energy is fixed at a specific value. Let us define this value as $K$:\n$$K \\;=\\; E - U(\\mathbf{r})$$\nThe condition $E > U(\\mathbf{r})$ ensures that $K > 0$, which is physically required for a system with non-zero momenta. The integral now takes the form:\n$$I(E,\\mathbf{r}) \\;=\\; \\int_{\\mathbb{R}^{3N}} \\delta\\!\\left(K - \\sum_{i=1}^{N} \\sum_{j=1}^{3} \\frac{p_{ij}^{2}}{2 m_{i}} \\right)\\, \\prod_{i=1}^{N} \\prod_{j=1}^{3} dp_{ij}$$\nwhere $p_{ij}$ is the $j$-th Cartesian component of the momentum vector $\\mathbf{p}_i$ for particle $i$.\n\nTo simplify the quadratic sum in the argument of the delta function, we perform a mass-weighted change of variables. Let us define a new set of $3N$ coordinates, $q_{ij}$, as:\n$$q_{ij} = \\frac{p_{ij}}{\\sqrt{2m_i}}$$\nWith this substitution, the kinetic energy term for each component becomes $p_{ij}^{2}/(2m_i) = q_{ij}^{2}$. The sum over all particles and components simplifies to a sum of squares:\n$$\\sum_{i=1}^{N} \\sum_{j=1}^{3} \\frac{p_{ij}^{2}}{2 m_{i}} = \\sum_{i=1}^{N} \\sum_{j=1}^{3} q_{ij}^{2}$$\nThe volume element in momentum space, $d^{3N}\\mathbf{p}$, must be transformed into the new $q$-coordinates. From the definition $p_{ij} = \\sqrt{2m_i} q_{ij}$, the differential element is $dp_{ij} = \\sqrt{2m_i} dq_{ij}$. The total volume element is the product of these differentials:\n$$d^{3N}\\mathbf{p} = \\prod_{i=1}^{N} \\prod_{j=1}^{3} dp_{ij} = \\prod_{i=1}^{N} \\prod_{j=1}^{3} (\\sqrt{2m_i} dq_{ij}) = \\left(\\prod_{i=1}^{N} (2m_i)^{3/2}\\right) \\left(\\prod_{i=1}^{N} \\prod_{j=1}^{3} dq_{ij}\\right)$$\nThe Jacobian of this transformation is $J = \\prod_{i=1}^{N} (2m_i)^{3/2} = (2)^{3N/2} (\\prod_{i=1}^{N} m_i)^{3/2}$.\nSubstituting the new variables and the Jacobian into the integral for $I(E,\\mathbf{r})$:\n$$I(E,\\mathbf{r}) = \\left(\\prod_{i=1}^{N} (2m_i)^{3/2}\\right) \\int_{\\mathbb{R}^{3N}} \\delta\\!\\left(K - \\sum_{k=1}^{3N} q_k^2 \\right)\\, d^{3N}\\mathbf{q}$$\nwhere we have relabeled the $3N$ components $q_{ij}$ with a single index $k$ running from $1$ to $3N$. The integral is now over a function that depends only on the squared magnitude of the vector $\\mathbf{q} \\in \\mathbb{R}^{3N}$.\n\nTo evaluate the remaining integral, we transform to $3N$-dimensional hyperspherical coordinates. Let $R^2 = \\sum_{k=1}^{3N} q_k^2$. The volume element in these coordinates is $d^{3N}\\mathbf{q} = R^{3N-1} dR d\\Omega_{3N-1}$, where $d\\Omega_{3N-1}$ is the surface element of a unit $(3N-1)$-sphere. The integral becomes:\n$$\\int_{\\mathbb{R}^{3N}} \\delta(K - R^2) d^{3N}\\mathbf{q} = \\int_{0}^{\\infty} \\int_{S^{3N-1}} \\delta(K - R^2) R^{3N-1} dR d\\Omega_{3N-1}$$\nThe integrand does not depend on the angular variables, so we can perform the angular integration first. The integral over $d\\Omega_{3N-1}$ gives the total solid angle in $3N$ dimensions, which is a known result equal to the surface area of a unit $(3N-1)$-sphere, $A_{3N-1}$:\n$$A_{3N-1} = \\frac{2\\pi^{3N/2}}{\\Gamma(3N/2)}$$\nwhere $\\Gamma(z)$ is the Gamma function. The integral simplifies to a one-dimensional integral over the radial coordinate $R$:\n$$ \\frac{2\\pi^{3N/2}}{\\Gamma(3N/2)} \\int_{0}^{\\infty} \\delta(K - R^2) R^{3N-1} dR $$\nTo evaluate this integral, we use the property of the Dirac delta function for a function argument: $\\int f(x)\\delta(g(x))dx = \\sum_i \\frac{f(x_i)}{|g'(x_i)|}$, where $x_i$ are the roots of $g(x)=0$. Here, $f(R) = R^{3N-1}$ and $g(R) = K - R^2$. Since $R$ is a radial coordinate, we are interested in roots for $R \\ge 0$. The only such root is $R_0 = \\sqrt{K}$ (since $K > 0$). The derivative of $g(R)$ is $g'(R) = -2R$. At the root, its absolute value is $|g'(R_0)| = |-2\\sqrt{K}| = 2\\sqrt{K}$.\nApplying this property, the radial integral evaluates to:\n$$\\int_{0}^{\\infty} \\delta(K - R^2) R^{3N-1} dR = \\frac{R_0^{3N-1}}{|g'(R_0)|} = \\frac{(\\sqrt{K})^{3N-1}}{2\\sqrt{K}} = \\frac{K^{(3N-1)/2}}{2K^{1/2}} = \\frac{1}{2}K^{(3N-2)/2}$$\nNow, we assemble all the parts. The momentum-space integral in $q$-coordinates is:\n$$\\int_{\\mathbb{R}^{3N}} \\delta(K - \\sum q_k^2) d^{3N}\\mathbf{q} = \\frac{2\\pi^{3N/2}}{\\Gamma(3N/2)} \\times \\frac{1}{2}K^{(3N-2)/2} = \\frac{\\pi^{3N/2}}{\\Gamma(3N/2)} K^{(3N-2)/2}$$\nFinally, we substitute this result back into the expression for $I(E,\\mathbf{r})$ and include the Jacobian factor:\n$$I(E,\\mathbf{r}) = \\left(\\prod_{i=1}^{N} (2m_i)^{3/2}\\right) \\frac{\\pi^{3N/2}}{\\Gamma(3N/2)} K^{(3N-2)/2}$$\nLet's simplify the product term and combine it with $\\pi^{3N/2}$:\n$$\\left(\\prod_{i=1}^{N} (2m_i)^{3/2}\\right) \\pi^{3N/2} = \\left(2^{3N/2} \\left(\\prod_{i=1}^{N} m_i \\right)^{3/2}\\right) \\pi^{3N/2} = (2\\pi)^{3N/2} \\left(\\prod_{i=1}^{N} m_i \\right)^{3/2}$$\nSubstituting $K = E - U(\\mathbf{r})$ and combining the terms gives the final closed-form expression:\n$$I(E,\\mathbf{r}) = \\frac{(2\\pi)^{3N/2} \\left(\\prod_{i=1}^{N} m_i \\right)^{3/2}}{\\Gamma(3N/2)} (E - U(\\mathbf{r}))^{(3N-2)/2}$$\nThis expression can also be written with the exponent as $\\frac{3N}{2}-1$, which is a characteristic form for the density of states of a system with $3N$ quadratic degrees of freedom.",
            "answer": "$$ \\boxed{ \\frac{(2\\pi)^{\\frac{3N}{2}} \\left( \\prod_{i=1}^{N} m_i \\right)^{\\frac{3}{2}}}{\\Gamma(\\frac{3N}{2})} (E - U(\\mathbf{r}))^{\\frac{3N}{2}-1} } $$"
        },
        {
            "introduction": "The microcanonical ensemble assumes that a system at constant energy will explore all accessible states with equal probability—a principle known as ergodicity. This exercise presents a thought-provoking scenario where this assumption fails on practical timescales, a common challenge in simulations of stiff molecular systems where energy can become \"trapped\" in specific modes. You will diagnose this non-ergodic behavior and evaluate different computational strategies used to restore proper phase space sampling, highlighting the practical transition from microcanonical to canonical simulation methods. ",
            "id": "3900133",
            "problem": "Consider an adsorbate-surface model relevant to catalytic reaction coordinate activation, with two degrees of freedom that capture the essential physics of an activated event along a reaction coordinate $x$ and a fast vibrational mode $y$. The Hamiltonian is\n$$\nH(x,y,p_x,p_y) \\;=\\; \\frac{p_x^2}{2 m} \\;+\\; \\frac{p_y^2}{2 m} \\;+\\; U_0 \\left(x^2 - x_0^2\\right)^2 \\;+\\; \\frac{1}{2} m \\omega^2 y^2 \\;+\\; \\epsilon x^2 y^2,\n$$\nwhere $m$ is the adsorbate mass, $U_0 \\left(x^2 - x_0^2\\right)^2$ represents a double-well potential with barrier height $U^\\ddagger \\equiv U_0 x_0^4$, the $y$-mode has angular frequency $\\omega$, and $\\epsilon \\ge 0$ tunes weak anharmonic coupling between $x$ and $y$. Suppose we perform deterministic molecular dynamics (MD) in the microcanonical ensemble (constant number of particles $N$, constant volume $V$, constant energy $E$; often abbreviated as $NVE$), using a symplectic integrator and a small time step such that numerical energy drift is negligible. The initial conditions have total energy $E = U^\\ddagger + \\Delta E$ with $\\Delta E = 0.05 \\,\\mathrm{eV}$, and are chosen so that at $t=0$ the $y$-mode holds most of the excess energy (large amplitude in $y$), while $x$ starts near one minimum with small $p_x$. For $\\epsilon$ sufficiently small, the dynamics shows long-time confinement of $x$ to its initial well despite $E > U^\\ddagger$, consistent across many trials with different random phases in $y$.\n\nIn the microcanonical ensemble, the probability density is uniform on the constant-energy hypersurface:\n$$\n\\rho_E(\\mathbf{q},\\mathbf{p}) \\;\\propto\\; \\delta\\!\\left(H(\\mathbf{q},\\mathbf{p}) - E\\right),\n$$\nwhere $\\mathbf{q}=(x,y)$ and $\\mathbf{p}=(p_x,p_y)$, and ergodicity means that, for almost all initial conditions at energy $E$, time averages of observables equal ensemble averages. In nearly integrable Hamiltonian systems ($\\epsilon \\to 0$), approximate action variables may severely impede phase-space mixing, producing mode-trapping on the potential energy surface.\n\nSelect all statements that correctly identify manifestations of non-ergodicity in this $NVE$ scenario and propose scientifically sound remedies that address poor mixing, with attention to the ensemble actually sampled and computational catalysis goals:\n\nA. Persistent confinement of $x$ in one well over times much longer than the $y$-mode period, even when $E > U^\\ddagger$, is consistent with non-ergodicity due to near-integrable dynamics that conserves approximate actions and traps energy in $y$. Introducing a weak Langevin thermostat (linear friction $\\gamma$ and Gaussian noise satisfying the fluctuation-dissipation relation $\\langle \\eta_i(t)\\eta_j(t')\\rangle = 2 \\gamma m k_B T \\,\\delta_{ij}\\delta(t-t')$) will break the invariants, restore mixing, and produce correct canonical ($NVT$) sampling at temperature $T$.\n\nB. If the instantaneous velocity histogram deviates from a Maxwell–Boltzmann distribution, non-ergodicity is ruled out in microcanonical dynamics for small systems; reducing the integrator time step will then force barrier crossings and cure trapping without changing the ensemble.\n\nC. In the decoupled limit ($\\epsilon = 0$), periodic microcanonical momentum mixing that, at fixed $(x,y)$, redraws $\\mathbf{p}$ uniformly from the sphere $\\|\\mathbf{p}\\| = \\sqrt{2 m \\left(E - V(x,y)\\right)}$ (where $V(x,y)=U_0(x^2-x_0^2)^2 + \\frac{1}{2} m \\omega^2 y^2$) preserves the exact energy while redistributing kinetic energy among coordinates, breaks mode trapping, and samples the correct conditional microcanonical distribution of momenta.\n\nD. Applying a deterministic Nosé–Hoover chain thermostat tuned so that the average kinetic temperature equals the microcanonical temperature associated with $E$ will generate the same microcanonical sampling as $NVE$ while eliminating trapping through enhanced mixing.\n\nE. Performing temperature replica exchange molecular dynamics (multiple replicas at different temperatures with exchange moves that satisfy detailed balance in the canonical ensemble) mitigates trapping by facilitating barrier crossings; while this alters the ensemble to canonical, it is a valid remedy for catalysis at controlled temperature, and microcanonical averages at a target energy can in principle be recovered by reweighting using the density of states if it is available or can be estimated.\n\nChoose all that apply.",
            "solution": "The problem statement is scientifically sound and well-posed. It presents a classic and physically meaningful model system for studying reaction dynamics in the presence of weak intramolecular vibrational energy redistribution (IVR). The scenario described—energy trapping in a vibrational mode that is not the reaction coordinate, leading to a breakdown of ergodicity on simulation timescales despite sufficient total energy for reaction—is a well-documented phenomenon in chemical physics. The Hamiltonian, initial conditions, and theoretical framework (microcanonical ensemble, ergodicity) are all standard and correctly formulated. The task is to evaluate proposed interpretations and remedies for this non-ergodic behavior. We will proceed to analyze each option.\n\nThe core issue is a failure of the ergodic hypothesis for the given system on practical timescales. In this $2$-degree-of-freedom system with weak coupling ($\\epsilon \\to 0$), the dynamics are near-integrable. This means there exist approximate constants of motion, in addition to the total energy $H$. Specifically, the energy in the $y$-mode, $E_y = \\frac{p_y^2}{2m} + \\frac{1}{2} m \\omega^2 y^2$, is approximately conserved. Because the initial condition places most of the excess energy into the $y$-mode, it stays there for a very long time. The system explores only a small sub-region of the constant-energy hypersurface defined by $H=E$, violating the assumption of equal a priori probability for all accessible microstates that is fundamental to the microcanonical ensemble.\n\n**A. Persistent confinement of $x$ in one well over times much longer than the $y$-mode period, even when $E > U^\\ddagger$, is consistent with non-ergodicity due to near-integrable dynamics that conserves approximate actions and traps energy in $y$. Introducing a weak Langevin thermostat (linear friction $\\gamma$ and Gaussian noise satisfying the fluctuation-dissipation relation $\\langle \\eta_i(t)\\eta_j(t')\\rangle = 2 \\gamma m k_B T \\,\\delta_{ij}\\delta(t-t')$) will break the invariants, restore mixing, and produce correct canonical ($NVT$) sampling at temperature $T$.**\n\nThis statement is entirely correct.\n1. The interpretation of the observed dynamics as a manifestation of non-ergodicity is accurate. The persistence of invariant tori in near-integrable systems, as described by KAM (Kolmogorov-Arnold-Moser) theory, leads to the conservation of approximate action variables, which in this case correspond to the individual energies of the modes. This is the physical mechanism behind the energy trapping.\n2. The proposed remedy, a Langevin thermostat, is scientifically sound. The Langevin equation of motion for a coordinate $q_i$ is $m \\ddot{q}_i = -\\frac{\\partial H}{\\partial q_i} - \\gamma p_i + \\eta_i(t)$. The friction term $-\\gamma p_i$ and the stochastic force $\\eta_i(t)$ explicitly break the time-reversal symmetry and conservation of energy inherent to Hamiltonian dynamics. These additional terms destroy the invariant tori and other constants of motion (besides those explicitly conserved by construction, like linear momentum if the whole system is thermostatted).\n3. The result is restored mixing and enhanced exploration of the phase space. The fluctuation-dissipation theorem, which links the magnitude of the noise to the friction coefficient and temperature $T$, ensures that the dynamics will sample the canonical ($NVT$) ensemble probability distribution, $\\rho \\propto \\exp(-H/k_B T)$. This is a standard and effective method to overcome ergodicity problems, at the cost of changing the statistical ensemble from microcanonical ($NVE$) to canonical ($NVT$), which is often physically desirable for modeling systems at constant temperature.\n\nVerdict: **Correct**.\n\n**B. If the instantaneous velocity histogram deviates from a Maxwell–Boltzmann distribution, non-ergodicity is ruled out in microcanonical dynamics for small systems; reducing the integrator time step will then force barrier crossings and cure trapping without changing the ensemble.**\n\nThis statement is fundamentally incorrect.\n1. The velocity distribution in a microcanonical ($NVE$) ensemble for a system with a small number of degrees of freedom is *not* a Maxwell-Boltzmann distribution. The total energy $E$ is fixed, so the total kinetic energy is constrained by $K = E - V(\\mathbf{q})$. The momenta $(p_x, p_y)$ are restricted to a circle (a $1$-sphere) with radius $\\sqrt{2mK}$, not a Gaussian distribution. A Maxwell-Boltzmann distribution emerges in the canonical ($NVT$) ensemble or in the thermodynamic limit ($N \\to \\infty$) for a subsystem. Therefore, observing a deviation from a Maxwell-Boltzmann distribution is expected for this small $NVE$ system and says nothing about ergodicity.\n2. The proposed remedy is also incorrect. The problem states that a small time step is already in use, ensuring good energy conservation. The trapping is a physical feature of the potential energy surface and the near-integrable Hamiltonian dynamics, not a numerical artifact. Reducing the time step will only cause the numerical trajectory to follow the true, trapped trajectory more accurately. It will not introduce the phase space mixing required to facilitate the energy transfer from mode $y$ to mode $x$ and thus will not \"cure\" trapping.\n\nVerdict: **Incorrect**.\n\n**C. In the decoupled limit ($\\epsilon = 0$), periodic microcanonical momentum mixing that, at fixed $(x,y)$, redraws $\\mathbf{p}$ uniformly from the sphere $\\|\\mathbf{p}\\| = \\sqrt{2 m \\left(E - V(x,y)\\right)}$ (where $V(x,y)=U_0(x^2-x_0^2)^2 + \\frac{1}{2} m \\omega^2 y^2$) preserves the exact energy while redistributing kinetic energy among coordinates, breaks mode trapping, and samples the correct conditional microcanonical distribution of momenta.**\n\nThis statement is correct.\n1. The procedure described is a valid method to enforce ergodicity within the microcanonical ensemble. It is sometimes referred to as a \"microcanonical Andersen thermostat\" or momentum resampling.\n2. By construction, it preserves the total energy $E$. The new momentum vector $\\mathbf{p}'$ is chosen to have a magnitude that precisely satisfies $H = \\frac{\\|\\mathbf{p}'\\|^2}{2m} + V(x,y) = E$.\n3. The key effect is the redistribution of kinetic energy. The initial trapped state has kinetic energy primarily in the $p_y$ component. By redrawing the momentum vector $(p_x, p_y)$ uniformly from a circle of constant total kinetic energy, the energy is randomly partitioned between the $x$ and $y$ modes. This artificial intervention breaks the approximate conservation of $E_y$ and effectively mimics the random collisions that would occur in a larger, more chaotic system, thus breaking the mode trapping.\n4. The procedure samples the correct distribution. The fundamental postulate of microcanonical statistical mechanics is that the probability density is uniform on the constant-energy hypersurface. This implies that for any fixed configuration $\\mathbf{q}$, the distribution of momenta $\\mathbf{p}$ must be uniform on the hypersphere of momenta defined by the constraint $K(\\mathbf{p}) = E - V(\\mathbf{q})$. The proposed method does exactly this. It correctly enforces the consequences of the ergodic hypothesis without changing the ensemble.\n\nVerdict: **Correct**.\n\n**D. Applying a deterministic Nosé–Hoover chain thermostat tuned so that the average kinetic temperature equals the microcanonical temperature associated with $E$ will generate the same microcanonical sampling as $NVE$ while eliminating trapping through enhanced mixing.**\n\nThis statement is incorrect.\n1. The primary error lies in the claim that a Nosé–Hoover thermostat generates microcanonical ($NVE$) sampling. The entire purpose of the Nosé-Hoover method (and its chain extension) is to generate trajectories that sample the *canonical* ($NVT$) ensemble. It achieves this by coupling the physical system to fictitious degrees of freedom (the \"thermostat variables\") that allow the energy of the physical system to fluctuate, exchanging it with a fictitious heat bath. The conserved quantity is an extended Hamiltonian, not the physical Hamiltonian $H$. The resulting phase space density is proportional to $\\exp(-H/k_B T)$, the hallmark of the canonical ensemble.\n2. While it is true that a well-behaved Nosé-Hoover chain thermostat can enhance mixing and overcome ergodicity issues present in the underlying $NVE$ dynamics, it achieves this by fundamentally changing the ensemble. The claim that it generates \"the same microcanonical sampling\" is a direct contradiction of its designed purpose and mechanism.\n\nVerdict: **Incorrect**.\n\n**E. Performing temperature replica exchange molecular dynamics (multiple replicas at different temperatures with exchange moves that satisfy detailed balance in the canonical ensemble) mitigates trapping by facilitating barrier crossings; while this alters the ensemble to canonical, it is a valid remedy for catalysis at controlled temperature, and microcanonical averages at a target energy can in principle be recovered by reweighting using the density of states if it is available or can be estimated.**\n\nThis statement is correct.\n1. Temperature replica exchange molecular dynamics (REMD) is a powerful, state-of-the-art enhanced sampling method designed specifically to overcome trapping problems like the one described. High-temperature replicas can easily cross potential barriers. By swapping configurations between high-temperature and low-temperature replicas, the low-temperature simulation is able to escape local minima and sample the configuration space more completely. This correctly describes how REMD mitigates trapping.\n2. The statement correctly identifies that this method operates within the canonical ($NVT$) ensemble (or more precisely, a generalized ensemble from which $NVT$ properties at each temperature are obtained). This is appropriate for many catalysis problems where temperature, not total energy, is the controlled experimental variable.\n3. The statement correctly notes that it is possible, in principle, to recover microcanonical properties from canonical simulations. Data from multiple temperatures (as generated by REMD) can be combined using techniques like the Weighted Histogram Analysis Method (WHAM) to compute the density of states, $\\Omega(E)$. Once $\\Omega(E)$ is known, thermodynamic and structural properties in any ensemble, including the microcanonical ensemble at a specific energy $E$, can be calculated. This demonstrates a sophisticated understanding of the relationship between statistical ensembles.\n\nVerdict: **Correct**.",
            "answer": "$$\\boxed{ACE}$$"
        },
        {
            "introduction": "A cornerstone of the canonical ensemble is the Maxwell-Boltzmann distribution of velocities, which serves as a vital diagnostic for thermal equilibrium in a simulation. This hands-on computational task guides you through building a statistical verification tool to test whether simulated velocity data truly conforms to the canonical distribution. By implementing a chi-squared goodness-of-fit test, you will gain practical experience in data analysis and learn how to quantitatively validate the output of molecular dynamics simulations against theoretical expectations. ",
            "id": "3900108",
            "problem": "You are tasked with writing a complete, runnable program that constructs and applies a goodness-of-fit verification procedure for Maxwell–Boltzmann velocity component distributions in the canonical ensemble, using histogramming and a chi-squared test. The context is computational catalysis and chemical engineering, where validating equilibrium sampling in molecular dynamics is essential. The program must simulate velocity-component datasets under specified ensemble conditions, compute expected bin counts based on the canonical prediction, and perform a chi-squared test to decide acceptance or rejection at a stated significance level.\n\nThe foundational base for this problem is the canonical ensemble and basic statistical testing methodology:\n- In the canonical ensemble at absolute temperature $T$ for non-interacting particles of mass $m$, each Cartesian velocity component $v_x$ is a normal random variable with mean $0$ and variance $\\sigma^2 = k_\\mathrm{B} T / m$, where $k_\\mathrm{B}$ is the Boltzmann constant.\n- The chi-squared goodness-of-fit test compares observed frequencies and expected frequencies in bins. It uses the statistic $\\chi^2 = \\sum_{i} (O_i - E_i)^2 / E_i$, where $O_i$ is the observed count in bin $i$ and $E_i$ is the expected count in bin $i$. Under the null hypothesis that the data follow the specified distribution and assuming valid binning, $\\chi^2$ follows a chi-squared distribution with degrees of freedom equal to the number of used bins minus $1$ (no parameters are estimated from data in this problem).\n\nYour program must do the following for each test case:\n1. Generate a synthetic dataset of $N$ samples of a single Cartesian velocity component $v_x$ in meters per second. Use a fixed random seed per test case to ensure reproducibility. Use the following sampling modes:\n   - Canonical sampling: draw $v_x$ from a normal distribution with mean $0$ and variance $\\sigma_\\mathrm{sample}^2 = k_\\mathrm{B} T_\\mathrm{sample}/m$.\n   - Mismatched temperature sampling: same as canonical sampling but with $T_\\mathrm{sample} \\neq T_\\mathrm{expected}$ in the chi-squared comparison.\n   - Microcanonical shell sampling: draw velocities with fixed speed $v_0$ such that the per-particle kinetic energy equals $(3/2) k_\\mathrm{B} T_\\mathrm{sample}$; assign $v_x$ as $v_x = v_0 u$ with $u$ drawn uniformly from $[-1,1]$ to represent random orientation on the constant-speed shell. Here $v_0 = \\sqrt{3 k_\\mathrm{B} T_\\mathrm{sample} / m}$.\n2. Define histogram bin edges symmetric about zero, using a range $[-R, R]$ that is wide enough to contain both the expected canonical distribution and the observed sample tails. Choose $R$ as the maximum of $6 \\sigma_\\mathrm{expected}$ and the microcanonical support bound for $v_x$ (which is $v_0$) multiplied by a safety factor of $1.05$. Use the specified number of bins $B$ to create $B$ equal-width bins over $[-R, R]$.\n3. Compute observed bin counts $O_i$ by histogramming the sampled $v_x$ values into the defined bins.\n4. Compute expected bin counts $E_i$ for the canonical model with $T_\\mathrm{expected}$ and mass $m$ by integrating the normal distribution over each bin $[a_i, b_i]$. Use the variance $\\sigma_\\mathrm{expected}^2 = k_\\mathrm{B} T_\\mathrm{expected} / m$ for the expected distribution, and $E_i = N \\cdot P(a_i \\le v_x \\le b_i)$ where $P(\\cdot)$ is the normal probability for the specified interval.\n5. Merge adjacent bins as needed to ensure validity of the chi-squared test: repeatedly merge neighboring bins left-to-right until every merged bin has expected count at least $5$. For each merged bin, sum corresponding $O_i$ and $E_i$. If merging results in fewer than $2$ bins, treat the test as inconclusive and accept the null hypothesis for that case.\n6. Compute the chi-squared statistic $\\chi^2$ over the merged bins and the corresponding $p$-value using the chi-squared survival function with degrees of freedom equal to the number of merged bins minus $1$.\n7. Decide acceptance if the $p$-value is greater than or equal to the specified significance level $\\alpha$, and rejection otherwise.\n\nPhysical quantities must be handled in International System of Units: $m$ in kilograms, $T$ in kelvin, $v_x$ in meters per second. Boltzmann’s constant must be taken as $k_\\mathrm{B} = 1.380649 \\times 10^{-23}$ joule per kelvin. Angles are not used, and no percentage signs are allowed.\n\nTest Suite:\nImplement the procedure on the following four test cases. Each case is given as a tuple $(m, T_\\mathrm{sample}, T_\\mathrm{expected}, N, B, \\alpha, \\text{mode}, \\text{seed})$, with units and meanings as stated above. For microcanonical sampling, $T_\\mathrm{sample}$ defines the shell energy as described.\n\n- Case 1 (happy path, canonical match): $(4.6495 \\times 10^{-26}, 1200, 1200, 50000, 60, 0.05, \\text{\"canonical\"}, 12345)$\n- Case 2 (mismatched temperature, canonical test): $(4.6495 \\times 10^{-26}, 1200, 800, 50000, 60, 0.05, \\text{\"canonical\"}, 54321)$\n- Case 3 (microcanonical shell, canonical test): $(4.6495 \\times 10^{-26}, 1200, 1200, 50000, 60, 0.05, \\text{\"microcanonical_shell\"}, 67890)$\n- Case 4 (small sample, canonical match, boundary condition): $(1.0 \\times 10^{-26}, 300, 300, 800, 40, 0.10, \\text{\"canonical\"}, 24680)$\n\nOutput Specification:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each result is a boolean indicating whether the Maxwell–Boltzmann canonical model was accepted by the chi-squared test at the given significance level for the case, in the same order as the test suite above. For example, the output should look like: \"[True,False,False,True]\".",
            "solution": "The objective is to develop and implement a computational procedure to validate whether a given set of particle velocities conforms to the Maxwell–Boltzmann distribution for a single velocity component, as predicted by the canonical ensemble in statistical mechanics. This is achieved through a chi-squared ($\\chi^2$) goodness-of-fit test. The procedure involves generating synthetic velocity data under different physical assumptions, binning this data into a histogram, calculating the expected frequencies from the theoretical distribution, and performing the statistical test to accept or reject the null hypothesis that the data follows the canonical distribution.\n\nThe foundational principle is that in a system of non-interacting particles in thermal equilibrium with a heat bath at a constant absolute temperature $T$ (a canonical ensemble), the probability distribution for any single Cartesian component of velocity, say $v_x$, follows a Gaussian (normal) distribution. The probability density function (PDF) is given by:\n$$\nf(v_x; T, m) = \\sqrt{\\frac{m}{2 \\pi k_\\mathrm{B} T}} \\exp\\left(-\\frac{m v_x^2}{2 k_\\mathrm{B} T}\\right)\n$$\nwhere $m$ is the particle mass and $k_\\mathrm{B}$ is the Boltzmann constant, $k_\\mathrm{B} = 1.380649 \\times 10^{-23} \\, \\text{J/K}$. This is a normal distribution $\\mathcal{N}(0, \\sigma^2)$ with a mean of $0$ and variance $\\sigma^2 = k_\\mathrm{B} T / m$.\n\nThe verification process follows a structured statistical methodology:\n\n1.  **Data Generation**: For each test case, a synthetic dataset of $N$ velocity components $v_x$ is generated based on a specified sampling mode and parameters ($m$, $T_\\mathrm{sample}$, $N$, seed).\n    -   For **canonical sampling**, values are drawn from a normal distribution $\\mathcal{N}(0, \\sigma_\\mathrm{sample}^2)$ where the sampling variance is $\\sigma_\\mathrm{sample}^2 = k_\\mathrm{B} T_\\mathrm{sample} / m$. This directly simulates the theoretical distribution.\n    -   For **microcanonical shell sampling**, the particle's total kinetic energy is fixed, corresponding to a constant speed $v_0 = \\sqrt{3 k_\\mathrm{B} T_\\mathrm{sample} / m}$. This models a particle with energy $E = \\frac{3}{2} k_\\mathrm{B} T_\\mathrm{sample}$. For a randomly oriented velocity vector of this magnitude, the distribution of a single component $v_x$ is uniform over the interval $[-v_0, v_0]$. Samples are generated as $v_x = v_0 u$, where $u$ is drawn from a uniform distribution $U[-1, 1]$.\n\n2.  **Histogram Binning**: The range of velocities is discretized into $B$ bins to create a histogram. The bins must cover the significant range of both the sampled data and the theoretical distribution being tested. The bin range is set to $[-R, R]$, symmetric around $0$. The value of $R$ is chosen to be sufficiently large: $R = \\max(6 \\sigma_\\mathrm{expected}, 1.05 \\cdot v_{0, \\text{support}})$, where $\\sigma_\\mathrm{expected} = \\sqrt{k_\\mathrm{B} T_\\mathrm{expected} / m}$. The term $v_{0, \\text{support}}$ is the maximum velocity component magnitude possible in the microcanonical sampling mode, which is $v_0$. For canonical sampling modes, this term is not applicable and $R$ is simply $6 \\sigma_\\mathrm{expected}$. The range is divided into $B$ equal-width bins.\n\n3.  **Observed Counts ($O_i$)**: The generated $N$ velocity samples are sorted into the $B$ bins, and the number of samples falling into each bin $i$ constitutes the observed count, $O_i$.\n\n4.  **Expected Counts ($E_i$)**: The null hypothesis is that the data follows the canonical distribution with temperature $T_\\mathrm{expected}$. The expected number of samples in bin $i$, with edges $[a_i, b_i]$, is $E_i = N \\cdot P(a_i \\le v_x \\le b_i)$. The probability $P$ is calculated by integrating the normal PDF $f(v_x; T_\\mathrm{expected}, m)$ over the bin interval. This is most efficiently computed using the cumulative distribution function (CDF), $\\Phi(v_x)$, of the $\\mathcal{N}(0, \\sigma_\\mathrm{expected}^2)$ distribution:\n    $$\n    E_i = N \\cdot (\\Phi(b_i) - \\Phi(a_i))\n    $$\n\n5.  **Bin Merging**: The chi-squared test is an approximation that becomes valid when expected counts in all bins are sufficiently large. A common heuristic is that all $E_i$ must be at least $5$. To satisfy this condition, adjacent bins are merged. Following a left-to-right procedure, bins are iteratively accumulated until the sum of their expected counts is at least $5$. The observed counts for these bins are also summed. Any final group of bins with a cumulative expected count less than $5$ is merged with the preceding merged bin. If this process results in fewer than $2$ final bins, the test is considered inconclusive and the null hypothesis is accepted by default.\n\n6.  **Chi-Squared Test Statistic and P-Value**: After merging, let the number of final bins be $k$. The chi-squared statistic is calculated as:\n    $$\n    \\chi^2 = \\sum_{i=1}^{k} \\frac{(O_i - E_i)^2}{E_i}\n    $$\n    Under the null hypothesis, this statistic follows a chi-squared distribution with $\\nu$ degrees of freedom. Since the parameters of the null distribution ($T_\\mathrm{expected}$ and $m$) are given and not estimated from the data, the degrees of freedom are $\\nu = k - 1$. The $p$-value is the probability of observing a $\\chi^2$ value as extreme as or more extreme than the one calculated, assuming the null hypothesis is true. This is given by the survival function of the $\\chi^2_{\\nu}$ distribution, $P(\\chi^2_{\\nu} \\ge \\chi^2_\\text{calculated})$.\n\n7.  **Decision**: The null hypothesis is rejected if the $p$-value is less than a predetermined significance level $\\alpha$. Otherwise, it is accepted. For each test case, the final result is a boolean value indicating acceptance ($p \\ge \\alpha$) or rejection ($p < \\alpha$).\n\nThe test cases are designed to probe different scenarios:\n-   **Case 1**: A canonical sample is tested against the correct canonical model ($T_\\mathrm{sample} = T_\\mathrm{expected}$). Acceptance is expected.\n-   **Case 2**: A canonical sample from a hotter system ($T_\\mathrm{sample} = 1200 \\, \\text{K}$) is tested against a colder model ($T_\\mathrm{expected} = 800 \\, \\text{K}$). The distributions differ in variance, so rejection is expected.\n-   **Case 3**: A microcanonical sample (uniform $v_x$ distribution) is tested against a canonical model (normal distribution). The distribution shapes are fundamentally different, so rejection is expected.\n-   **Case 4**: A canonical sample with a small size ($N=800$) is tested against the correct model. This tests the procedure's robustness, especially the bin merging logic. Acceptance is expected, but statistical fluctuations are larger.\n\nThis entire procedure provides a rigorous framework for validating equilibrium sampling in molecular simulations, a critical task in computational science.",
            "answer": "```python\nimport numpy as np\nfrom scipy import stats\n\ndef solve():\n    \"\"\"\n    Main function to run the chi-squared goodness-of-fit test for all specified cases.\n    \"\"\"\n    KB = 1.380649e-23  # Boltzmann constant in J/K\n\n    test_cases = [\n        # (m, T_sample, T_expected, N, B, alpha, mode, seed)\n        (4.6495e-26, 1200, 1200, 50000, 60, 0.05, \"canonical\", 12345),\n        (4.6495e-26, 1200, 800, 50000, 60, 0.05, \"canonical\", 54321),\n        (4.6495e-26, 1200, 1200, 50000, 60, 0.05, \"microcanonical_shell\", 67890),\n        (1.0e-26, 300, 300, 800, 40, 0.10, \"canonical\", 24680),\n    ]\n\n    results = []\n    for case in test_cases:\n        results.append(perform_chi2_test(case, KB))\n\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef perform_chi2_test(case, kb):\n    \"\"\"\n    Executes the goodness-of-fit verification procedure for a single test case.\n    \"\"\"\n    m, T_sample, T_expected, N, B, alpha, mode, seed = case\n    rng = np.random.default_rng(seed)\n\n    # Step 1: Generate synthetic dataset\n    if mode == \"canonical\":\n        sigma_sample = np.sqrt(kb * T_sample / m)\n        vx_sample = rng.normal(0, sigma_sample, N)\n    elif mode == \"microcanonical_shell\":\n        v0 = np.sqrt(3 * kb * T_sample / m)\n        u = rng.uniform(-1, 1, N)\n        vx_sample = v0 * u\n    else:\n        raise ValueError(f\"Unknown sampling mode: {mode}\")\n\n    # Step 2: Define histogram bin edges\n    sigma_expected = np.sqrt(kb * T_expected / m)\n    R_canonical = 6 * sigma_expected\n    \n    if mode == \"microcanonical_shell\":\n        # Ensure R is large enough for the microcanonical support\n        v0_sample = np.sqrt(3 * kb * T_sample / m)\n        R_micro = 1.05 * v0_sample\n        R = max(R_canonical, R_micro)\n    else:\n        R = R_canonical\n\n    bin_edges = np.linspace(-R, R, B + 1)\n\n    # Step 3: Compute observed bin counts\n    observed_counts, _ = np.histogram(vx_sample, bins=bin_edges)\n\n    # Step 4: Compute expected bin counts\n    norm_dist_expected = stats.norm(loc=0, scale=sigma_expected)\n    cdf_values = norm_dist_expected.cdf(bin_edges)\n    bin_probabilities = np.diff(cdf_values)\n    expected_counts_initial = N * bin_probabilities\n\n    # Step 5: Merge adjacent bins to ensure E_i >= 5\n    merged_O = []\n    merged_E = []\n    current_O_sum = 0\n    current_E_sum = 0\n\n    for o, e in zip(observed_counts, expected_counts_initial):\n        current_O_sum += o\n        current_E_sum += e\n        if current_E_sum >= 5:\n            merged_O.append(current_O_sum)\n            merged_E.append(current_E_sum)\n            current_O_sum = 0\n            current_E_sum = 0\n\n    # If there's a remainder, merge it with the last created bin\n    if current_E_sum > 0:\n        if len(merged_E) > 0:\n            merged_O[-1] += current_O_sum\n            merged_E[-1] += current_E_sum\n        else:\n            # This happens if total expected count is < 5; all data goes to one bin\n            merged_O.append(current_O_sum)\n            merged_E.append(current_E_sum)\n\n    # Special condition: if merging results in fewer than 2 bins, accept.\n    k_merged = len(merged_E)\n    if k_merged < 2:\n        return True\n\n    merged_O = np.array(merged_O)\n    merged_E = np.array(merged_E)\n\n    # Step 6: Compute chi-squared statistic and p-value\n    # Prevent division by zero, although merging should prevent E_i=0.\n    # A small positive epsilon can be added to the denominator for safety,\n    # but the merging logic for E_i>=5 makes it unnecessary.\n    chi2_stat = np.sum((merged_O - merged_E)**2 / merged_E)\n    dof = k_merged - 1\n    \n    if dof <= 0: # Should not happen if k_merged >= 2\n        return True\n\n    p_value = stats.chi2.sf(chi2_stat, df=dof)\n\n    # Step 7: Decide acceptance or rejection\n    return p_value >= alpha\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}