{
    "hands_on_practices": [
        {
            "introduction": "数据同化的核心在于将模型预测与实际观测相结合。本练习将从最基本的情景入手：为一个标量状态（例如单个网格点的海面温度）推导卡尔曼滤波的更新方程。通过从贝叶斯定理出发并使用配方法，你将亲手构建数据同化的基石，理解先验估计（预报）和新数据（观测）是如何根据它们各自的不确定性（方差）进行最优融合的。",
            "id": "3795500",
            "problem": "在一个单网格点设置中，该设置代表了单步持续性模型数据同化循环中的无量纲化海面温度异常，假设预报状态为标量，且在该循环中动力学是线性和确定性的。状态的先验（也称为预报或背景）分布是均值为 $x^{f}$、方差为 $P^{f}$ 的高斯分布。获取了一个与状态线性相关的单一、同位观测，其观测算子为 $H$，且独立的观测误差服从一个方差为 $R$ 的高斯分布。假设所有变量都是无量纲的，并且先验和似然是独立且联合高斯分布的。使用适用于线性高斯模型的贝叶斯定理和配方法，推导后验（也称为分析）高斯分布，并用 $x^{f}$、$P^{f}$、$H$、$R$ 和观测值 $y$ 明确表示卡尔曼增益、分析均值和分析方差。\n\n然后，在特定情况下 $F=\\begin{bmatrix}1\\end{bmatrix}$，$H=\\begin{bmatrix}1\\end{bmatrix}$，$P^{f}=2$，$R=1$，$x^{f}=0$ 和 $y=1$ 时，计算你的表达式的值。以精确有理数的形式提供最终数值。\n\n将最终答案表示为一行三个条目，顺序为：卡尔曼增益、分析均值、分析方差。无需单位。不要四舍五入；提供精确值。",
            "solution": "问题要求在线性高斯数据同化设置中标量状态的后验（分析）分布的推导，然后针对特定情况计算关键量的值。分析将按照要求，通过应用贝叶斯定理和配方法进行。\n\n### 第1步：问题验证\n\n首先根据所需标准对问题进行验证。\n\n**1.1. 提取的已知条件：**\n- 预报状态 $x$ 是一个标量。\n- 状态的先验分布是均值为 $x^f$、方差为 $P^f$ 的高斯分布。\n- 观测值 $y$ 是一个单一的、同位的测量值。\n- 观测算子 $H$ 是线性的。\n- 观测误差来自一个均值为零、方差为 $R$ 的独立高斯分布。\n- 先验和似然是独立的并且是联合高斯分布。\n- 任务是使用贝叶斯定理和配方法来推导后验（分析）分布。\n- 确定卡尔曼增益 ($K$)、分析均值 ($x^a$) 和分析方差 ($P^a$)。\n- 在以下情况下计算这些量的值：$F=\\begin{bmatrix}1\\end{bmatrix}$，$H=\\begin{bmatrix}1\\end{bmatrix}$，$P^{f}=2$，$R=1$，$x^{f}=0$ 和 $y=1$。\n\n**1.2. 验证：**\n- **科学依据：** 该问题是数据同化理论中的一个标准、基础练习，特别是卡尔曼滤波分析步骤的推导。它基于贝叶斯统计和概率论的既定原理。它在科学上是合理的。\n- **适定性：** 该问题提供了推导通用表达式和计算特定数值结果所需的所有信息。状态和观测模型都已明确定义。提及模型算子 $F$ 提供了关于数据同化循环（一个持续性预报）的背景，但对于分析计算本身而言不是必需的，因为预报状态 $x^f$ 已给出。这不构成矛盾或不明确的设置。\n- **客观性：** 问题是用精确、客观的数学语言陈述的。\n\n**1.3. 结论：**\n该问题是有效的，因为它具有科学依据、适定且客观。没有任何缺陷会妨碍严谨的求解。我们可以继续。\n\n### 第2步：分析分布的推导\n\n根据贝叶斯定理，后验概率密度函数 (PDF) $p(x|y)$ 与似然 PDF $p(y|x)$ 和先验 PDF $p(x)$ 的乘积成正比。\n$$p(x|y) \\propto p(y|x) p(x)$$\n根据问题陈述，先验和似然都是高斯分布。对于标量状态 $x$，PDFs 如下：\n\n先验分布为 $x \\sim \\mathcal{N}(x^f, P^f)$:\n$$p(x) \\propto \\exp\\left( -\\frac{1}{2} \\frac{(x - x^f)^2}{P^f} \\right)$$\n基于观测模型 $y = Hx + \\epsilon$（其中 $\\epsilon \\sim \\mathcal{N}(0, R)$），似然为：\n$$p(y|x) \\propto \\exp\\left( -\\frac{1}{2} \\frac{(y - Hx)^2}{R} \\right)$$\n\n后验 PDF 则是这两者的乘积：\n$$p(x|y) \\propto \\exp\\left( -\\frac{1}{2} \\frac{(x - x^f)^2}{P^f} \\right) \\exp\\left( -\\frac{1}{2} \\frac{(y - Hx)^2}{R} \\right)$$\n$$p(x|y) \\propto \\exp\\left( -\\frac{1}{2} \\left[ \\frac{(x - x^f)^2}{P^f} + \\frac{(y - Hx)^2}{R} \\right] \\right)$$\n两个高斯分布的乘积是另一个高斯分布。因此，$x$ 的后验分布将是高斯分布，假设为 $x \\sim \\mathcal{N}(x^a, P^a)$，其 PDF 的形式为：\n$$p(x|y) \\propto \\exp\\left( -\\frac{1}{2} \\frac{(x - x^a)^2}{P^a} \\right)$$\n为了求得分析均值 $x^a$ 和方差 $P^a$，我们让指数函数的参数相等。令 $J(x)$ 为后验 PDF 指数中的代价函数：\n$$J(x) = \\frac{(x - x^a)^2}{P^a} + \\text{const.} = \\frac{(x - x^f)^2}{P^f} + \\frac{(y - Hx)^2}{R}$$\n现在我们展开右边的项，并根据 $x$ 的幂次收集项：\n$$J(x) = \\frac{1}{P^f}(x^2 - 2xx^f + (x^f)^2) + \\frac{1}{R}(y^2 - 2yHx + H^2x^2)$$\n$$J(x) = x^2 \\left(\\frac{1}{P^f} + \\frac{H^2}{R}\\right) - 2x \\left(\\frac{x^f}{P^f} + \\frac{yH}{R}\\right) + \\left(\\frac{(x^f)^2}{P^f} + \\frac{y^2}{R}\\right)$$\n这个关于 $x$ 的二次式必须等价于 $\\frac{1}{P^a}(x^2 - 2xx^a + (x^a)^2) + \\text{const.}$ 的形式。通过比较 $x^2$ 和 $x$ 项的系数（即“配方法”），我们可以确定 $P^a$ 和 $x^a$。\n\n比较 $x^2$ 项的系数：\n$$\\frac{1}{P^a} = \\frac{1}{P^f} + \\frac{H^2}{R}$$\n这个方程表明，分析的精度（方差的倒数）是预报精度和观测精度的和。求解分析方差 $P^a$：\n$$P^a = \\left( \\frac{R + H^2 P^f}{P^f R} \\right)^{-1} = \\frac{P^f R}{R + H^2 P^f}$$\n\n比较 $-2x$ 项的系数：\n$$\\frac{x^a}{P^a} = \\frac{x^f}{P^f} + \\frac{yH}{R}$$\n求解分析均值 $x^a$：\n$$x^a = P^a \\left( \\frac{x^f}{P^f} + \\frac{yH}{R} \\right) = \\frac{P^f R}{R + H^2 P^f} \\left( \\frac{x^f R + yH P^f}{P^f R} \\right) = \\frac{x^f R + yH P^f}{R + H^2 P^f}$$\n为了将其表示为包含卡尔曼增益的标准形式，我们对 $x^a$ 的表达式进行变换：\n$$x^a = \\frac{x^f(R + H^2 P^f) - x^f H^2 P^f + yH P^f}{R + H^2 P^f}$$\n$$x^a = x^f + \\frac{yH P^f - x^f H^2 P^f}{R + H^2 P^f} = x^f + \\left( \\frac{P^f H}{R + H^2 P^f} \\right) (y - Hx^f)$$\n这是标准的卡尔曼更新方程 $x^a = x^f + K(y - Hx^f)$。由此，我们确定卡尔曼增益 $K$：\n$$K = \\frac{P^f H}{H^2 P^f + R}$$\n分析方差 $P^a$ 也可以用 $K$ 来表示。从我们关于 $P^a$ 的表达式：\n$$P^a = \\frac{P^f R}{R + H^2 P^f} = P^f \\frac{R + H^2 P^f - H^2 P^f}{R + H^2 P^f} = P^f \\left( 1 - \\frac{H^2 P^f}{R + H^2 P^f} \\right)$$\n$$P^a = P^f \\left( 1 - H \\cdot \\frac{H P^f}{R + H^2 P^f} \\right) = P^f(1 - HK)$$\n由于所有量都是标量，这等价于 $P^a = (1-KH)P^f$。\n\n### 第3步：特定情况的计算\n\n我们已知以下数值：\n- 预报均值：$x^f = 0$\n- 预报方差：$P^f = 2$\n- 观测算子：$H = 1$ (来自 $H=\\begin{bmatrix}1\\end{bmatrix}$)\n- 观测误差方差：$R = 1$\n- 观测值：$y = 1$\n\n现在我们将这些值代入推导出的表达式中。\n\n**1. 卡尔曼增益 ($K$):**\n$$K = \\frac{P^f H}{H^2 P^f + R} = \\frac{2 \\cdot 1}{1^2 \\cdot 2 + 1} = \\frac{2}{2 + 1} = \\frac{2}{3}$$\n\n**2. 分析均值 ($x^a$):**\n$$x^a = x^f + K(y - Hx^f) = 0 + \\frac{2}{3}(1 - 1 \\cdot 0) = \\frac{2}{3}(1) = \\frac{2}{3}$$\n\n**3. 分析方差 ($P^a$):**\n使用 $P^a = (1 - KH)P^f$ 的形式：\n$$P^a = \\left( 1 - \\frac{2}{3} \\cdot 1 \\right) \\cdot 2 = \\left( 1 - \\frac{2}{3} \\right) \\cdot 2 = \\frac{1}{3} \\cdot 2 = \\frac{2}{3}$$\n或者，使用直接公式：\n$$P^a = \\frac{P^f R}{R + H^2 P^f} = \\frac{2 \\cdot 1}{1 + 1^2 \\cdot 2} = \\frac{2}{1 + 2} = \\frac{2}{3}$$\n结果是一致的。\n\n以精确有理数表示的最终值为：卡尔曼增益 $K = \\frac{2}{3}$，分析均值 $x^a = \\frac{2}{3}$，分析方差 $P^a = \\frac{2}{3}$。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{2}{3}  \\frac{2}{3}  \\frac{2}{3} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "现实世界中的海洋模型包含数百万个变量，因此我们需要将标量更新推广到多维状态。本练习将卡尔曼滤波的概念推广到矢量状态，展示如何利用矩阵代数处理多变量系统。你将看到，通过预报误差协方差矩阵 $P^f$，对一个变量的观测可以同时订正其他未被观测的变量，这是现代数据同化系统的一个关键特征。",
            "id": "3795551",
            "problem": "在计算海洋学中，考虑一个区域海洋模型中两个相邻网格点的海面温度异常所代表的二维状态的线性高斯单次同化步骤。设状态由随机向量 $x \\in \\mathbb{R}^{2}$ 表示，其预报（先验）均值为 $x^{f}$，预报协方差为 $P^{f} \\in \\mathbb{R}^{2 \\times 2}$。单个原位观测 $y \\in \\mathbb{R}$ 通过线性观测算子 $H \\in \\mathbb{R}^{1 \\times 2}$ 测量第一个状态分量，其加性测量噪声为 $\\varepsilon$，与 $x$ 独立且满足 $\\varepsilon \\sim \\mathcal{N}(0, R)$，其中 $R \\in \\mathbb{R}$ 是观测误差方差。观测模型为 $y = H x + \\varepsilon$。假设 $(x, y)$ 的联合分布是高斯分布，并考虑最佳线性无偏估计 (Best Linear Unbiased Estimator, BLUE)，也称为卡尔曼滤波 (Kalman Filter, KF) 分析更新，它产生分析状态 $x^{a}$ 和分析协方差 $P^{a}$。\n\n从高斯设定下的线性估计定义以及估计量在无偏性约束下最小化分析误差方差的要求出发，推导卡尔曼增益 $K \\in \\mathbb{R}^{2 \\times 1}$ 和分析协方差 $P^{a} \\in \\mathbb{R}^{2 \\times 2}$ 关于 $P^{f}$、$H$ 和 $R$ 的表达式。然后，对于特定情况\n$$\nP^{f} = \\begin{bmatrix} 1  0.5 \\\\ 0.5  1 \\end{bmatrix}, \\quad\nH = \\begin{bmatrix} 1  0 \\end{bmatrix}, \\quad\nR = 0.25,\n$$\n精确计算 $K$ 和 $P^{a}$ 的数值。\n\n将最终答案表示为单个行矩阵，使用以下顺序：列出 $K$ 的两个元素（从上到下），然后是 $P^{a}$ 的四个元素（按行主序，即先第一行从左到右，再第二行从左到右）。无需四舍五入，也不涉及物理单位。最终答案必须是计算结果。",
            "solution": "该问题要求推导线性高斯估计问题中的卡尔曼增益 $K$ 和分析协方差 $P^{a}$，然后对一个特定情况进行数值计算。\n\n分析状态 $x^{a}$ 是一个线性估计量，它结合了预报（先验）状态 $x^{f}$ 和新的观测值 $y$。线性估计量的一般形式为：\n$$\nx^{a} = A x^{f} + B y\n$$\n其中 $A$ 和 $B$ 是矩阵。对于标准卡尔曼滤波，我们寻求基于观测得到的新信息对预报进行更新。这表示为用“新息”或“残差” $(y - Hx^{f})$ 来修正预报，并由增益矩阵 $K$ 加权。\n$$\nx^{a} = x^{f} + K(y - Hx^{f})\n$$\n这种形式可以重写为 $x^{a} = (I - KH)x^{f} + Ky$，它对应于 $A=I-KH$ 和 $B=K$ 的一般线性形式。\n\n估计量必须是无偏的，并且最小化分析误差方差。\n\n**1. 无偏性条件**\n分析误差定义为 $e^{a} = x - x^{a}$。无偏估计量要求分析误差的期望值为零，即 $E[e^{a}] = 0$。\n代入 $x^{a}$ 的表达式和观测模型 $y = Hx + \\varepsilon$：\n$$\ne^{a} = x - [x^{f} + K(y - Hx^{f})]\n$$\n$$\ne^{a} = x - x^{f} - K(Hx + \\varepsilon - Hx^{f})\n$$\n设预报误差为 $e^{f} = x - x^{f}$。则：\n$$\ne^{a} = e^{f} - K(H(x-x^{f}) + \\varepsilon)\n$$\n$$\ne^{a} = e^{f} - K(He^{f} + \\varepsilon)\n$$\n$$\ne^{a} = (I - KH)e^{f} - K\\varepsilon\n$$\n分析误差的期望值为：\n$$\nE[e^{a}] = E[(I - KH)e^{f} - K\\varepsilon] = (I - KH)E[e^{f}] - KE[\\varepsilon]\n$$\n假设预报是无偏的，因此 $E[x^{f}] = E[x]$，这意味着 $E[e^{f}] = E[x - x^{f}] = 0$。还假设测量噪声的均值为零，即 $E[\\varepsilon] = 0$。因此：\n$$\nE[e^{a}] = (I - KH)(0) - K(0) = 0\n$$\n所选的估计量形式是内在地无偏的，与 $K$ 的选择无关。\n\n**2. 最小化分析误差方差**\n分析误差协方差矩阵定义为 $P^{a} = E[e^{a}(e^{a})^T]$。我们的目标是找到卡尔曼增益 $K$，以最小化该矩阵的标量度量，通常是其迹，它代表状态估计的总方差。\n$$\nP^{a} = E[((I - KH)e^{f} - K\\varepsilon)((I - KH)e^{f} - K\\varepsilon)^T]\n$$\n展开转置：\n$$\nP^{a} = E[((I - KH)e^{f} - K\\varepsilon)((e^{f})^T(I - KH)^T - \\varepsilon^T K^T)]\n$$\n$$\nP^{a} = E[(I - KH)e^{f}(e^{f})^T(I - KH)^T - (I - KH)e^{f}\\varepsilon^T K^T - K\\varepsilon(e^{f})^T(I - KH)^T + K\\varepsilon\\varepsilon^T K^T]\n$$\n逐项取期望，并利用预报误差 $e^f$ 和观测噪声 $\\varepsilon$ 不相关的事实，即 $E[e^{f}\\varepsilon^T] = 0$ 和 $E[\\varepsilon(e^{f})^T] = 0$：\n$$\nP^{a} = (I - KH)E[e^{f}(e^{f})^T](I - KH)^T + K E[\\varepsilon\\varepsilon^T] K^T\n$$\n根据定义，预报误差协方差为 $P^{f} = E[e^{f}(e^{f})^T]$，观测误差协方差为 $R = E[\\varepsilon\\varepsilon^T]$（由于 $y$ 是标量，因此 $R$ 是一个标量方差）。\n$$\nP^{a} = (I - KH)P^{f}(I - KH)^T + KRK^T\n$$\n为了最小化分析误差方差，我们最小化 $P^{a}$ 的迹，即 $J(K) = \\text{tr}(P^{a})$。\n$$\nJ(K) = \\text{tr}((I - KH)P^{f}(I - KH)^T + KRK^T)\n$$\n展开第一项：\n$$\n(I - KH)P^{f}(I - KH)^T = (P^{f} - KHP^{f})(I - H^T K^T) = P^{f} - P^{f}H^T K^T - KHP^{f} + KHP^{f}H^T K^T\n$$\n所以，\n$$\nJ(K) = \\text{tr}(P^{f}) - \\text{tr}(P^{f}H^T K^T) - \\text{tr}(KHP^{f}) + \\text{tr}(KHP^{f}H^T K^T) + \\text{tr}(KRK^T)\n$$\n利用迹的循环性质 $\\text{tr}(ABC) = \\text{tr}(CAB)$，我们有 $\\text{tr}(P^{f}H^T K^T) = \\text{tr}(K^T P^{f}H^T)$。由于矩阵的迹等于其转置的迹，$\\text{tr}(K^T P^{f}H^T) = \\text{tr}((P^{f}H^T)^T K) = \\text{tr}(HP^{f}K)$。但 $P^f$ 是对称的 ($P^f = (P^f)^T$)，所以这是 $\\text{tr}(HP^f K)$。此外，$\\text{tr}(KHP^f)$ 是一个标量，所以它等于它的转置 $\\text{tr}((KHP^f)^T) = \\text{tr}((P^f)^T H^T K^T) = \\text{tr}(P^f H^T K^T)$。一个更直接的方法是注意到对于实矩阵，$\\text{tr}(KHP^f) = \\text{tr}(P^f H^T K^T)$。\n因此，$\\text{tr}(P^{f}H^T K^T) = \\text{tr}(KHP^{f})$。\n$$\nJ(K) = \\text{tr}(P^{f}) - 2 \\text{tr}(KHP^{f}) + \\text{tr}(K(HP^{f}H^T + R)K^T)\n$$\n为求最小值，我们将 $J(K)$ 对 $K$ 求导并令结果为零。使用标准矩阵求导恒等式 $\\frac{d}{dX}\\text{tr}(AXB) = A^T B^T$ 和 $\\frac{d}{dX}\\text{tr}(AXA^T) = 2AX$：\n$$\n\\frac{d J(K)}{dK} = -2\\frac{d}{dK}\\text{tr}(KHP^{f}) + \\frac{d}{dK}\\text{tr}(K(HP^{f}H^T + R)K^T) = 0\n$$\n$$\n-2(HP^{f})^T + 2K(HP^{f}H^T + R) = 0\n$$\n$$\n-2 P^{f}H^T + 2K(HP^{f}H^T + R) = 0\n$$\n$$\nK(HP^{f}H^T + R) = P^{f}H^T\n$$\n解出 $K$，我们得到最优卡尔曼增益的表达式：\n$$\nK = P^{f}H^T(HP^{f}H^T + R)^{-1}\n$$\n现在我们推导分析协方差 $P^{a}$ 的简化表达式。从 $P^{a} = (I - KH)P^{f} - (I - KH)P^{f}H^T K^T + KRK^T$ 开始：\n$$\nP^{a} = P^{f} - KHP^{f} - P^{f}H^T K^T + KHP^{f}H^T K^T + KRK^T\n$$\n$$\nP^{a} = P^{f} - KHP^{f} - P^{f}H^T K^T + K(HP^{f}H^T + R)K^T\n$$\n从 $K$ 的推导中，我们有 $K(HP^{f}H^T + R) = P^{f}H^T$。将此代入最后一项：\n$$\nP^{a} = P^{f} - KHP^{f} - P^{f}H^T K^T + (P^{f}H^T)K^T\n$$\n最后两项相互抵消，剩下：\n$$\nP^{a} = P^{f} - KHP^{f}\n$$\n由于 $KHP^f$ 不一定是对称的，一个更稳健的形式是 $P^a = (I - KH)P^f$。如果 $P^f$ 是对称的，这种形式可以保持 $P^a$ 的对称性，我们将在计算中看到这一点。\n\n**3. 数值计算**\n给定：\n$$\nP^{f} = \\begin{bmatrix} 1  0.5 \\\\ 0.5  1 \\end{bmatrix}, \\quad\nH = \\begin{bmatrix} 1  0 \\end{bmatrix}, \\quad\nR = 0.25 = \\frac{1}{4}\n$$\n首先，计算卡尔曼增益 $K$ 所需的项。\n$H$ 的转置是 $H^T = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$。\n项 $P^{f}H^T$ 为：\n$$\nP^{f}H^T = \\begin{bmatrix} 1  0.5 \\\\ 0.5  1 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 1 \\cdot 1 + 0.5 \\cdot 0 \\\\ 0.5 \\cdot 1 + 1 \\cdot 0 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 0.5 \\end{bmatrix}\n$$\n项 $HP^{f}H^T$ 为：\n$$\nHP^{f}H^T = \\begin{bmatrix} 1  0 \\end{bmatrix} \\left( \\begin{bmatrix} 1  0.5 \\\\ 0.5  1 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\right) = \\begin{bmatrix} 1  0 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0.5 \\end{bmatrix} = 1 \\cdot 1 + 0 \\cdot 0.5 = 1\n$$\n新息协方差为 $S = HP^{f}H^T + R$：\n$$\nS = 1 + 0.25 = 1.25 = \\frac{5}{4}\n$$\n由于这是一个标量，其逆为 $S^{-1} = \\frac{1}{1.25} = \\frac{4}{5} = 0.8$。\n现在，计算卡尔曼增益 $K = P^{f}H^T S^{-1}$：\n$$\nK = \\begin{bmatrix} 1 \\\\ 0.5 \\end{bmatrix} \\cdot 0.8 = \\begin{bmatrix} 0.8 \\\\ 0.4 \\end{bmatrix} = \\begin{bmatrix} \\frac{4}{5} \\\\ \\frac{2}{5} \\end{bmatrix}\n$$\n接下来，使用 $P^{a} = (I-KH)P^{f}$ 计算分析协方差 $P^{a}$。\n首先，计算矩阵 $KH$：\n$$\nKH = \\begin{bmatrix} 0.8 \\\\ 0.4 \\end{bmatrix} \\begin{bmatrix} 1  0 \\end{bmatrix} = \\begin{bmatrix} 0.8 \\cdot 1  0.8 \\cdot 0 \\\\ 0.4 \\cdot 1  0.4 \\cdot 0 \\end{bmatrix} = \\begin{bmatrix} 0.8  0 \\\\ 0.4  0 \\end{bmatrix}\n$$\n然后，计算 $I - KH$：\n$$\nI - KH = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix} - \\begin{bmatrix} 0.8  0 \\\\ 0.4  0 \\end{bmatrix} = \\begin{bmatrix} 1 - 0.8  0 - 0 \\\\ 0 - 0.4  1 - 0 \\end{bmatrix} = \\begin{bmatrix} 0.2  0 \\\\ -0.4  1 \\end{bmatrix}\n$$\n最后，计算 $P^{a} = (I - KH)P^{f}$：\n$$\nP^{a} = \\begin{bmatrix} 0.2  0 \\\\ -0.4  1 \\end{bmatrix} \\begin{bmatrix} 1  0.5 \\\\ 0.5  1 \\end{bmatrix}\n$$\n$$\nP^{a} = \\begin{bmatrix} (0.2)(1) + (0)(0.5)  (0.2)(0.5) + (0)(1) \\\\ (-0.4)(1) + (1)(0.5)  (-0.4)(0.5) + (1)(1) \\end{bmatrix}\n$$\n$$\nP^{a} = \\begin{bmatrix} 0.2  0.1 \\\\ 0.1  -0.2 + 1 \\end{bmatrix} = \\begin{bmatrix} 0.2  0.1 \\\\ 0.1  0.8 \\end{bmatrix}\n$$\n让我们将这些结果表示为精确分数：\n$K = \\begin{bmatrix} 4/5 \\\\ 2/5 \\end{bmatrix}$\n$P^{a} = \\begin{bmatrix} 1/5  1/10 \\\\ 1/10  4/5 \\end{bmatrix}$\n\n题目要求将 $K$ 的元素（从上到下）和 $P^{a}$ 的元素（按行主序）排列成一个单行矩阵。\n这些元素是： $K_1 = \\frac{4}{5}$, $K_2 = \\frac{2}{5}$, $P^{a}_{11} = \\frac{1}{5}$, $P^{a}_{12} = \\frac{1}{10}$, $P^{a}_{21} = \\frac{1}{10}$, $P^{a}_{22} = \\frac{4}{5}$。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{4}{5}  \\frac{2}{5}  \\frac{1}{5}  \\frac{1}{10}  \\frac{1}{10}  \\frac{4}{5} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "数据同化领域存在两大主流方法：序贯方法（如卡尔曼滤波）和变分方法（如三维变分法，3D-Var）。尽管它们的表述形式不同，但两者之间存在深刻的联系。本练习将引导你证明，在线性高斯假设下，卡尔曼滤波分析与 3D-Var 分析在数学上是等价的。通过从两个不同角度推导并计算相同问题的解，你将获得对数据同化理论一个强大而统一的认识。",
            "id": "3795564",
            "problem": "考虑计算海洋学中的一个分析步骤，该步骤针对一个二维线性状态，其分量代表单个水平网格点上的两个预报变量。设未知真实状态为 $x \\in \\mathbb{R}^{2}$，并假设背景（先验）状态 $x_b \\in \\mathbb{R}^{2}$ 及其误差协方差 $B \\in \\mathbb{R}^{2 \\times 2}$ 已知，观测值 $y \\in \\mathbb{R}$ 通过一个已知的线性算子 $H \\in \\mathbb{R}^{1 \\times 2}$ 与状态相关，观测误差协方差为 $R \\in \\mathbb{R}^{1 \\times 1}$。假设先验误差和观测误差是独立的、无偏的且服从高斯分布。\n\n仅从 Bayes 定理以及线性和高斯误差统计的假设出发，推导使后验密度负对数最小化的分析状态，这等价于三维变分数据同化（3D-Var）分析。独立地，从高斯误差下最优线性估计器的定义出发，为同一设置推导单步 Kalman 滤波器（KF）分析。然后，对于以下特定情况\n$$\nx_b = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}, \\quad\nB = \\begin{pmatrix} 2  0 \\\\ 0  1 \\end{pmatrix}, \\quad\nH = \\begin{pmatrix} 1  1 \\end{pmatrix}, \\quad\nR = \\begin{pmatrix} 1 \\end{pmatrix}, \\quad\ny = 0.5,\n$$\n显式计算 3D-Var 分析和单步 KF 分析，并报告这两个分析状态之差的欧几里得范数。\n\n最终答案以无单位的实数表示。无需四舍五入。",
            "solution": "该问题是有效的，因为它科学地基于数据同化原理，问题提法良好，具有唯一且有意义的解，并以客观、正式的语言表述。这是计算海洋学和统计估计中的一个标准问题。\n\n该问题要求对分析状态 $x_a \\in \\mathbb{R}^2$ 进行两次独立的推导，并进行最终的数值计算。首先，我们推导三维变分（3D-Var）分析。其次，我们推导单步 Kalman 滤波器（KF）分析。最后，我们证明在线性和高斯情况下，这两种方法是等价的，这直接导出了最终答案。\n\n**第一部分：3D-Var 分析的推导**\n\n3D-Var 分析旨在寻找使后验概率密度函数（PDF）$p(x|y)$ 最大化的状态 $x$。根据 Bayes 定理，后验概率正比于似然概率与先验概率的乘积：\n$$p(x|y) \\propto p(y|x) p(x)$$\n问题陈述先验误差和观测误差是无偏且服从高斯分布的。\n\n先验信息是背景状态 $x_b$ 及其误差协方差 $B$。因此，先验 PDF $p(x)$ 是一个以 $x_b$ 为中心、协方差为 $B$ 的高斯分布：\n$$p(x) = \\mathcal{N}(x_b, B) \\propto \\exp\\left(-\\frac{1}{2}(x - x_b)^T B^{-1} (x - x_b)\\right)$$\n观测值 $y$ 通过线性算子 $H$ 与真实状态 $x$ 相关，观测误差 $\\epsilon_o$ 的均值为零，协方差为 $R$。因此，$y = Hx + \\epsilon_o$。在给定状态 $x$ 的条件下观测到 $y$ 的似然概率 $p(y|x)$ 也是一个以 $Hx$ 为中心、协方差为 $R$ 的高斯分布：\n$$p(y|x) = \\mathcal{N}(Hx, R) \\propto \\exp\\left(-\\frac{1}{2}(y - Hx)^T R^{-1} (y - Hx)\\right)$$\n结合以上两点，后验 PDF 为：\n$$p(x|y) \\propto \\exp\\left(-\\frac{1}{2}\\left[ (x - x_b)^T B^{-1} (x - x_b) + (y - Hx)^T R^{-1} (y - Hx) \\right]\\right)$$\n最大化后验 PDF $p(x|y)$ 等价于最小化其负对数。我们将 3D-Var 代价函数 $J(x)$ 定义为负指数部分的两倍：\n$$J(x) = (x - x_b)^T B^{-1} (x - x_b) + (y - Hx)^T R^{-1} (y - Hx)$$\n为了找到最小化 $J(x)$ 的状态 $x_a$，我们计算 $J(x)$ 关于 $x$ 的梯度并将其设为零。使用矩阵微积分恒等式，梯度为：\n$$\\nabla_x J(x) = 2B^{-1}(x - x_b) - 2H^T R^{-1}(y - Hx)$$\n在 $x = x_a$ 处，令 $\\nabla_x J(x) = 0$：\n$$B^{-1}(x_a - x_b) - H^T R^{-1}(y - Hx_a) = 0$$\n整理各项以求解 $x_a$：\n$$B^{-1}x_a - B^{-1}x_b - H^T R^{-1}y + H^T R^{-1}Hx_a = 0$$\n$$(B^{-1} + H^T R^{-1}H)x_a = B^{-1}x_b + H^T R^{-1}y$$\n因此，3D-Var 分析状态为：\n$$x_{a, \\text{3DVar}} = (B^{-1} + H^T R^{-1}H)^{-1} (B^{-1}x_b + H^T R^{-1}y)$$\n\n**第二部分：Kalman 滤波器分析的推导**\n\nKalman 滤波器分析更新提供了状态的最优线性无偏估计。分析状态 $x_a$ 表示为对背景状态 $x_b$ 的线性修正，该修正基于新息（innovation），即观测值 $y$ 与其背景估计 $Hx_b$ 之间的差：\n$$x_a = x_b + K(y - Hx_b)$$\n这里，$K$ 是 Kalman 增益矩阵，其选择旨在最小化分析误差的方差，即最小化分析误差协方差矩阵 $P_a = E[(x_a-x)(x_a-x)^T]$ 的迹。\n\n分析误差 $x_a-x$ 可以写作：\n$$x_a - x = x_b + K(y - Hx_b) - x = x_b + K(Hx + \\epsilon_o - Hx_b) - x$$\n其中 $\\epsilon_o$ 是观测误差。令 $\\epsilon_b = x_b - x$ 为背景误差。\n$$x_a - x = (x_b - x) + K(H(x-x_b) + \\epsilon_o) = \\epsilon_b - KH\\epsilon_b + K\\epsilon_o = (I - KH)\\epsilon_b + K\\epsilon_o$$\n现在，我们计算分析误差协方差 $P_a$。由于背景误差 $\\epsilon_b$ 和观测误差 $\\epsilon_o$ 是独立的，所以 $E[\\epsilon_b \\epsilon_o^T] = 0$ 且 $E[\\epsilon_o \\epsilon_b^T] = 0$。\n$$P_a = E[((I - KH)\\epsilon_b + K\\epsilon_o)((I - KH)\\epsilon_b + K\\epsilon_o)^T]$$\n$$P_a = (I - KH) E[\\epsilon_b\\epsilon_b^T] (I - KH)^T + K E[\\epsilon_o\\epsilon_o^T] K^T$$\n使用 $E[\\epsilon_b\\epsilon_b^T] = B$ 和 $E[\\epsilon_o\\epsilon_o^T] = R$：\n$$P_a = (I - KH)B(I - KH)^T + KRK^T$$\n$$P_a = B - KHB - BH^T K^T + KHBH^TK^T + KRK^T$$\n为了最小化 $P_a$ 关于 $K$ 的迹，我们将其导数设为零：\n$$\\frac{\\partial}{\\partial K} \\mathrm{tr}(P_a) = -2BH^T + 2K(HBH^T + R) = 0$$\n求解 $K$ 得到最优 Kalman 增益：\n$$K = BH^T(HBH^T + R)^{-1}$$\n因此，Kalman 滤波器分析状态为：\n$$x_{a, \\text{KF}} = x_b + BH^T(HBH^T + R)^{-1}(y - Hx_b)$$\n\n**等价性与最终计算**\n\n对于具有高斯误差的线性系统，3D-Var 分析和 Kalman 滤波器分析是相同的。这可以通过将 Woodbury 矩阵恒等式应用于 3D-Var 分析表达式来证明。该恒等式为 $(A+UCV)^{-1} = A^{-1} - A^{-1}U(C^{-1}+VA^{-1}U)^{-1}VA^{-1}$。令 $A = B^{-1}$，$U=H^T$，$C=R^{-1}$，$V=H$。\n$$(B^{-1} + H^T R^{-1}H)^{-1} = B - BH^T(R + HBH^T)^{-1}HB$$\n将此代入 $x_a$ 的 3D-Var 公式中：\n$$x_{a, \\text{3DVar}} = (B - BH^T(HBH^T + R)^{-1}HB)(B^{-1}x_b + H^T R^{-1}y)$$\n$$x_{a, \\text{3DVar}} = x_b + BH^T R^{-1}y - BH^T(HBH^T + R)^{-1}HB B^{-1}x_b - BH^T(HBH^T + R)^{-1}HBH^TR^{-1}y$$\n$$x_{a, \\text{3DVar}} = x_b - BH^T(HBH^T + R)^{-1}Hx_b + BH^T[I - (HBH^T + R)^{-1}HBH^T]R^{-1}y$$\n方括号中的项可以简化：$I - (HBH^T+R)^{-1}HBH^T = (HBH^T+R)^{-1}[(HBH^T+R) - HBH^T] = (HBH^T+R)^{-1}R$。\n$$x_{a, \\text{3DVar}} = x_b - BH^T(HBH^T + R)^{-1}Hx_b + BH^T(HBH^T + R)^{-1}R R^{-1}y$$\n$$x_{a, \\text{3DVar}} = x_b + BH^T(HBH^T + R)^{-1}(y - Hx_b) = x_{a, \\text{KF}}$$\n由于两种方法在解析上产生相同的结果，它们数值输出之间的差必定是零向量，该差的欧几里得范数也必定为零。\n\n为完整起见，我们使用 Kalman 滤波器公式计算给定数值的分析状态。\n给定：\n$$\nx_b = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}, \\quad\nB = \\begin{pmatrix} 2  0 \\\\ 0  1 \\end{pmatrix}, \\quad\nH = \\begin{pmatrix} 1  1 \\end{pmatrix}, \\quad\nR = 1, \\quad\ny = 0.5\n$$\n首先，计算 Kalman 增益 $K = BH^T(HBH^T + R)^{-1}$ 的各分量：\n$$H^T = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$$\n$$BH^T = \\begin{pmatrix} 2  0 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}$$\n$$HBH^T = \\begin{pmatrix} 1  1 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = 1(2)+1(1) = 3$$\n项 $(HBH^T + R)^{-1}$ 是一个标量：\n$$(3 + 1)^{-1} = 4^{-1} = \\frac{1}{4}$$\nKalman 增益为：\n$$K = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} \\frac{1}{4} = \\begin{pmatrix} 1/2 \\\\ 1/4 \\end{pmatrix}$$\n接下来，计算新息项 $y - Hx_b$：\n$$Hx_b = \\begin{pmatrix} 1  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} = 1(1) + 1(-1) = 0$$\n$$y - Hx_b = 0.5 - 0 = 0.5 = \\frac{1}{2}$$\n最后，计算分析状态 $x_a$：\n$$x_a = x_b + K(y - Hx_b) = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} + \\begin{pmatrix} 1/2 \\\\ 1/4 \\end{pmatrix} \\left(\\frac{1}{2}\\right) = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} + \\begin{pmatrix} 1/4 \\\\ 1/8 \\end{pmatrix} = \\begin{pmatrix} 5/4 \\\\ -7/8 \\end{pmatrix}$$\n$x_{a, \\text{3DVar}}$ 和 $x_{a, \\text{KF}}$ 都等于 $\\begin{pmatrix} 5/4 \\\\ -7/8 \\end{pmatrix}$。\n差值为 $x_{a, \\text{3DVar}} - x_{a, \\text{KF}} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$。\n差的欧几里得范数为：\n$$\\left\\| \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} \\right\\|_2 = \\sqrt{0^2 + 0^2} = 0$$",
            "answer": "$$\\boxed{0}$$"
        }
    ]
}