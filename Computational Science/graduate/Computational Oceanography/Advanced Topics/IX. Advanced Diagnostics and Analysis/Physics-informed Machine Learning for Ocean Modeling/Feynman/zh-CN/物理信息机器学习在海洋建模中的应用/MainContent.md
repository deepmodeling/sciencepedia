## 引言
在探索和预测广阔海洋的过程中，计算建模是不可或缺的工具。然而，传统的物理模型虽然根植于坚实的理论，却常因对复杂过程（如[湍流](@entry_id:151300)）的简化[参数化](@entry_id:265163)而存在偏差，且计算成本高昂；而纯粹的数据驱动方法，如传统的机器学习，虽能高效拟合数据，却往往缺乏物理一致性，可能在长期预测中产生荒谬的结果。[物理信息](@entry_id:152556)机器学习（PIML）的出现，正是为了弥合这一鸿沟。它代表了一种新的科学计算范式，通过将物理学第一性原理作为强大的归纳偏置，引导机器学习模型在数据中发现规律的同时，严格遵守自然法则，从而有望构建出更快速、更准确且物理上可靠的海洋模型。

本文将系统性地引导读者深入PIML在海洋建模中的世界。在第一章“**原理与机制**”中，我们将揭开PIML的神秘面纱，探讨它如何将[偏微分](@entry_id:194612)方程、守恒律等物理知识转化为可计算的约束，并详解[物理信息神经网络](@entry_id:145229)（PINN）与[混合模型](@entry_id:266571)这两种核心技术路径。接下来，在第二章“**应用与交叉学科联系**”中，我们将把目光投向广阔的海洋，看PIML如何在解决[次网格尺度参数化](@entry_id:1132601)、数据同化等海洋科学前沿挑战中大显身手，并讨论确保模型长期稳定性的关键。最后，通过第三章“**实践环节**”中的具体编程问题，读者将有机会亲手实现PIML的关键思想，将理论知识转化为实践能力。让我们一同开启这段旅程，探索数据与物理定律交织的魅力。

## 原理与机制

与单纯依赖数据驱动的“黑箱”模型不同，物理信息机器学习（PIML）的核心魅力在于它在学习过程中融入了我们数百年来对自然界运行规律的深刻理解。它并非试图凭空创造知识，而是构建了一座桥梁，让数据中蕴含的模式与物理学第一性原理相互验证、相互启发。本章将深入探讨这一过程背后的核心原理与关键机制，揭示 PIML 如何将抽象的物理定律转化为可计算、可学习的约束。

### 两种哲学：教神经网络学物理

将物理知识赋予机器学习模型，主要有两种截然不同的哲学思想：一种是将神经网络本身训练成一个“理解”并遵循物理定律的求解器；另一种则是让神经网络成为传统[物理模拟](@entry_id:144318)器的“得力助手”，为其补全缺失的关键环节。

#### 将神经网络作为物理的学生：PINN

想象一下，我们想求解一个描述海洋中[污染物扩散](@entry_id:195534)的方程，这是一个经典的平流-扩散问题。传统的数值方法会把时空离散化成网格，然后用[有限差分](@entry_id:167874)或有限元等方法近似求解。而**物理信息神经网络（PINN）**  提供了一种全新的思路：它不再将解看作是一堆离散的数值，而是将其视为一个连续的函数。而谁最擅长表示任意复杂的[连续函数](@entry_id:137361)呢？正是神经网络。

PINN 的核心思想是，一个经过良好训练的神经网络 $u(\mathbf{x}, t; \boldsymbol{\theta})$（其中 $\boldsymbol{\theta}$ 是网络参数）本身就是对真实物理场的一个解析近似。这个“学生”的优秀之处在于，我们可以对它进行任意阶的求导。这要归功于一项名为**[自动微分](@entry_id:144512)（Automatic Differentiation, AD）**的强大技术 。AD 并非[数值微分](@entry_id:144452)（如有限差分）那样的[近似计算](@entry_id:1121073)，也不是[符号微分](@entry_id:177213)那样可能导致表达式爆炸。它像一位不知疲倦、极其严谨的微积分大师，通过精确地、系统地应用[链式法则](@entry_id:190743)于构成神经网络的每一个基本运算，从而能够计算出网络输出对于其任何输入的精确导数。

有了 AD 这个工具，我们就可以构建 PINN 的“考试卷”——也就是它的**损失函数**。这份考试卷至少包含两部分：

1.  **数据匹配题**：在有观测数据的地方，我们要求网络的输出 $u(\mathbf{x}, t; \boldsymbol{\theta})$ 与真实观测值尽可能一致。
2.  **物理原理题**：我们将网络输出 $u(\mathbf{x}, t; \boldsymbol{\theta})$ 和它通过 AD 计算出的导数（如 $\partial u / \partial t$, $\nabla u$, $\nabla^2 u$）代入到控制物理过程的[偏微分](@entry_id:194612)方程（PDE）中。如果网络给出的解是完美的，那么方程两边应该相等，其差值——即**PDE 残差**——应为零。因此，我们在时空域内选取大量“配点”，要求网络在这些点上产生的 PDE 残差尽可能小。

通过最小化这个包含数据和物理残差的总[损失函数](@entry_id:634569)，神经网络就像一个学生，在观测数据的“标准答案”和物理定律的“基本公理”的双重指导下进行学习。

这种约束的植入方式也有“软”硬之分 。将残差加入[损失函数](@entry_id:634569)，是一种**软约束** (soft enforcement)，如同对违反物理定律的行为处以罚款，优化过程会尽量减少罚款，但无法保证完全杜绝。而**硬约束** (hard enforcement) 则是通过巧妙地设计网络结构，使其输出在任何参数下都必然满足某些条件。例如，要保证[二维不可压缩流](@entry_id:136406)动的连续性方程 $\partial_x u + \partial_z w = 0$ 被精确满足，我们可以不直接让网络预测速度分量 $(u, w)$，而是预测一个[流函数](@entry_id:1132499) $\psi$，并定义 $u = \partial_z \psi$ 和 $w = - \partial_x \psi$。这样，无论 $\psi$ 是什么函数，[连续性方程](@entry_id:195013)都将自动满足，网络的“语法”天生就符合这项物理法则 。

然而，教神经网络物理并非一帆风顺。[海洋动力学](@entry_id:1129055)中普遍存在着时间尺度差异巨大的现象，例如，由层结引起的快速内部重力波（周期可能只有几分钟）与缓慢的背景环流（时间尺度可达数天甚至数年）。这种**刚度（stiffness）**问题会给 PINN 的训练带来巨大的挑战。一个未经**精心**设计的损失函数，其梯度可能完全被快速过程的巨大残差所主导，使得优化器对缓慢但同样重要的慢过程“充耳不闻”，导致训练失败。这就像老师只关注学生在快速问答中的表现，而忽略了他们深度思考的能力。为了解决这种“梯度病理”（gradient pathology），研究者们必须借鉴物理学家的智慧，通过物理驱动的尺度分析对变量和方程进行恰当的[无量纲化](@entry_id:136704)，或者设计能量守恒的[损失函数](@entry_id:634569)权重，甚至引入算子预条件等技术，来平衡不同物理过程在学习中的话语权 。

#### 将神经网络作为物理的合作者：混合模型

PINN 试图让神经网络独力承担起求解 PDE 的重任，而另一种哲学则显得更为**务实**：让神经网络与传统的 PDE 求解器协同工作，构成**混合模型**（Hybrid Modeling） 。

在经典的海洋模型中，一个永恒的难题是**[次网格尺度](@entry_id:1132591)（subgrid-scale, SGS）过程**的[参数化](@entry_id:265163)。由于计算资源的限制，模型的分辨率总是有限的，无法解析海洋中所有尺度的[湍流](@entry_id:151300)涡旋。这些未被解析的小尺度运动对大尺度环流有着至关重要的影响（例如能量的耗散和物质的混合），必须通过所谓的“[闭包](@entry_id:148169)”或“[参数化](@entry_id:265163)方案”来描述。例如，人们常常用**涡粘性（eddy viscosity）**和**涡扩散（eddy diffusivity）**系数来模拟小尺度[湍流](@entry_id:151300)对动量和示踪剂的混合效应 。然而，这些[参数化](@entry_id:265163)方案往往是基于高度**简化**的理论，其普适性备受质疑。

这正是机器学习大显身手的舞台。在混合模型中，我们保留了传统数值求解器（如[有限体积法](@entry_id:141374)）的框架，这个框架严格保证了诸如质量守恒等基本物理定律。与此同时，我们将其中最不确定、最依赖经验假设的[参数化](@entry_id:265163)模块替换为一个神经网络。通过在高分辨率模拟数据或真实观测上进行训练，神经网络可以学到一个远比传统方案更精确、更动态的 SGS 模型，例如，它可以学会涡粘性系数如何依赖于当地的流场剪切、层结强度等复杂因素。

这种“合作模式”的优越性在于它集两家之所长。PDE 求解器的结构保证了模型的[长期稳定性](@entry_id:146123)和物理守恒性——比如，在一个采用[有限体积法](@entry_id:141374)的[混合模型](@entry_id:266571)中，只要质量方程本身不被修改，模型的总质量将在长时间积分中完美守恒（仅受[时间积分](@entry_id:267413)误差影响），绝不会出现“无中生有”或“凭空消失”的现象 。而神经网络则凭借其强大的[非线性拟合](@entry_id:136388)能力，为模型注入了前所未有的**真实感**和精度。这与纯粹的**黑箱模拟（black-box emulation）**形成了鲜明对比，后者试图用一个神经网络完全取代 PDE 求解器，直接学习从当前状态到下一时刻状态的映射。尽管黑箱模型可能在短期预测上表现出色，但由于缺乏内禀的物理结构，它很容易在长期积分中偏离物理现实，导致能量不守恒、解崩溃等问题。

### 物理的语言：我们教什么法则？

要构建一个“懂物理”的[机器学习模型](@entry_id:262335)，我们首先要明确，海洋这本大书中写下了哪些不容置疑的“黄金定律”。这些定律从基本的[运动方程](@entry_id:264286)到深刻的对称性原理，构成了 PIML 的“物理信息”库。

#### 基石：控制方程与近似

[海洋环流](@entry_id:195237)的动力学本质上由流体力学的基本方程——Navier-Stokes 方程——所支配。然而，对于地球尺度上的海洋运动，我们通常会引入一系列关键的近似来简化问题。其中，**Boussinesq 近似**和**静力平衡近似**（Hydrostatic Approximation）是构建现代[海洋环流](@entry_id:195237)模型的两大基石 。

- **Boussinesq 近似**：考虑到海水的密度变化（通常由温度和盐度引起）相对于其平均密度非常小。此近似允许我们在计算惯性力时将密度视为常数，从而大大简化[动量方程](@entry_id:197225)，并将流体处理为不可压缩的（即[速度场散度](@entry_id:178755)为零 $\nabla \cdot \boldsymbol{u} = 0$）。但它巧妙地保留了密度变化在重[力场](@entry_id:147325)中的效应，即**[浮力](@entry_id:154088)**，因为正是这微小的密度差异驱动了海洋中大部分的垂直运动和能量转换。

- **[静力平衡近似](@entry_id:1126281)**：海洋是一个“扁平”的系统，其水平尺度（成百上千公里）远大于垂直尺度（几公里）。这导致垂直方向的加速度与重力和压力梯度相比微不足道。因此，我们可以忽略[垂直动量方程](@entry_id:1133792)中的加速度项，得到一个极简的平衡关系：[垂直压力梯度](@entry_id:1133794)精确地平衡了重力，即 $\partial p / \partial z = - \rho g$。这使得垂直方向的动力学从一个复杂的预测问题简化为一个诊断关系，极大地提高了计算效率。

在 PIML 的框架下，这些近似可以直接作为 PINN 训练时的物理约束。例如，我们可以要求神经网络预测的流场散度为零，并且其预测的压[力场](@entry_id:147325)和密度场严格满足[静力平衡](@entry_id:163498)关系，从而确保模型捕捉到的是大规模海洋运动的正确物理图像 。

#### 更深层次的对称性与守恒律

除了直接的控制方程，物理学还为我们提供了更深刻、更普适的指导原则，它们是所有物理过程都必须遵守的“元规则”。将这些原则注入[机器学习模型](@entry_id:262335)，能极大地提升其泛化能力和物理真实性。

- **能量守恒**：在一个封闭、无摩擦、绝热的层结流体系统中，总的机械能——即**动能（Kinetic Energy, KE）**和**有效位能（Available Potential Energy, APE）**之和——是守恒的 。APE 是指流体中因密度分布不均而储存的、可以转化为动能的那部分势能。当较重的流体向上运动或较轻的流体向下运动时，APE 转化为 KE，驱动流动；反之，KE 则可以转化为 APE。这个能量转换过程由**浮力通量**（即[浮力](@entry_id:154088)与垂直速度的乘积）来量化。任何一个声称模拟了理想层结[流体动力](@entry_id:750449)学的[机器学习模型](@entry_id:262335)，都必须尊重这个精确的能量收支平衡。反之，当考虑混合和耗散时，模型也必须正确地描述 APE 和 KE 如何因粘性摩擦和分子扩散而不可逆地减少  。

- **位涡守恒**：在旋转层结流体中，存在一个比能量更为神奇的[守恒量](@entry_id:161475)——**Ertel 位涡（Potential Vorticity, PV）** 。它可以直观地理解为一个流体微块的“[绝对涡度](@entry_id:262794)”与其“层结厚度”之比。在理想（无摩擦、绝热）条件下，每个流体微块在运动过程中其 PV 值将保持恒定不变。这就像每个流体微块都携带了一个永不磨灭的“身份证号”。PV 守恒是对流体运动轨迹的极强约束，它支配了海洋中尺度涡的形成、波动和相互作用。让 PIML 模型学会并遵守 PV 守恒，是通往高保真模拟的关键一步。

- **伽利略不变性与旋转[协变](@entry_id:634097)性**：这些是关于参考系的[基本对称性](@entry_id:161256)原理 。**伽利略不变性**（Galilean Invariance）指出，物理定律的形式不应因观测者处于匀速[直线运动](@entry_id:165142)状态而改变。这意味着，一个描述[湍流](@entry_id:151300)的模型，其输出应该依赖于流体的[相对运动](@entry_id:169798)和[速度梯度](@entry_id:261686)，而不是绝对速度。**旋转协变性**（Rotational Equivariance）则要求，如果我们将整个物理系统旋转一个角度，那么其演化结果也应该是初始结果的同样旋转。一个 ML 模型不应有“方向偏好”。通过设计特殊的[网络架构](@entry_id:268981)，例如只使用[速度梯度](@entry_id:261686)等伽利略不变的量作为输入，或者采用**群 equivariant 卷积网络**（[G-CNNs](@entry_id:637878)），我们可以从根本上保证模型天生就具备这些对称性，这远比寄希望于模型从数据中“碰巧”学到这些原理要稳健和高效得多。

### 超越单一答案：PIML 的新前沿

随着领域的发展，PIML 的目标已经超越了仅仅求解一个给定的 PDE，开始探索更广阔、更深刻的问题。

#### 学习物理定律本身：[系统辨识](@entry_id:201290)

在某些情况下，我们甚至可能不完全清楚控制系统的精确方程形式。这时，我们可以让数据“自己说话”。**稀疏非线性动力学辨识（[SINDy](@entry_id:266063)）**  就是这样一种方法。其哲学是**奥卡姆剃刀原理**——最简单的解释往往是最好的。我们首先构建一个庞大的“候选物理项库”，包含各种可能的[微分](@entry_id:158422)项，如平流项（$-\mathbf{u}\cdot\nabla c$）、扩散项（$\nabla^2 c$）、[非线性](@entry_id:637147)反应项（$c^2$）等等。然后，[SINDy](@entry_id:266063) 利用[稀疏回归](@entry_id:276495)技术（如 [LASSO](@entry_id:751223)），从这个庞大的库中“挑选”出最少的几项，来最好地拟合观测到的系统时间演化。这就像一位侦探，面对众多嫌疑人（候选物理项），通过分析证据（数据），最终找出真正的“罪魁祸首”（控制方程）。这种方法已经成功地从数据中“重新发现”了流[体力](@entry_id:174230)学中的许多经典方程。

#### 学习求解器：[神经算子](@entry_id:1128605)

PINN 学习的是一个特定问题的**解**（一个函数），而**神经算子**（Neural Operators）  的目标则更为宏大：它要学习 PDE 的**解算子**本身。解算子是一个抽象的映射，它将任意的输入函数（如初始条件、边界条件或强迫项）映射到对应的解函数。一旦神经算子训练完成，它就能像一个传统的数值求解器一样，对于**任何**新的输入函数，几乎瞬时地给出一个近似解，而无需重新训练。

这种“一次训练，到处使用”的特性使其在所谓的“多查询”（many-query）场景中具有无与伦比的优势。例如，在进行[不确定性量化](@entry_id:138597)或数据同化时，我们需要对成千上万种不同的初始条件或模型参数进行模拟。使用 PINN 需要对每一次查询都进行一次昂贵的训练，而一个预训练好的神经算子则只需进行廉价的前向传播计算。当然，这种效率的代价是[神经算子](@entry_id:1128605)的训练成本更高，且其精度和泛化能力高度依赖于训练数据的多样性 。

#### 拥抱不确定性：贝叶斯 PIML

标准的机器学习模型通常给出一个确定的“点估计”答案。但在科学研究中，知道我们“不知道什么”和知道我们“知道什么”同样重要。**贝叶斯 PIML**  正是为了回答这个问题而生。它将贝叶斯推理的框架应用于 PINN，不再求解唯一的网络参数，而是求解参数的一个后验概率分布。

这使我们能够量化模型预测中的不确定性，并将其分解为两种类型：

1.  **[偶然不确定性](@entry_id:634772)（Aleatoric Uncertainty）**：源于数据本身的[固有噪声](@entry_id:261197)和随机性。比如，传感器测量的误差。这种不确定性是系统内禀的，即使拥有无限多的数据也无法消除。
2.  **认知不确定性（Epistemic Uncertainty）**：源于我们知识的局限，即模型本身的不完美和训练数据的稀疏性。例如，在远离数据点的区域，模型会“不确定”该如何插值。这种不确定性可以通过收集更多的数据或引入更强的物理约束来减小。

一个贝叶斯 PINN 的输出不再是一个单一的预测值，而是一个完整的概率分布，它清晰地告诉我们在何处模型的预测是可靠的，在何处是存疑的。这种诚实的自我评估对于将机器学习模型应用于高风险决策（如气候预测和灾害预警）至关重要。