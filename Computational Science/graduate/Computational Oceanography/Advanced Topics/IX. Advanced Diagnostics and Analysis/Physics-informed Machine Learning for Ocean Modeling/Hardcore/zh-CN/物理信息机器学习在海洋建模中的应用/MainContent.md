## 引言
在计算海洋学领域，模拟复杂海洋过程的传统数值模型与新兴的数据驱动方法各有优劣。前者基于第一性原理但计算成本高昂且依赖于经验性的[参数化](@entry_id:265163)方案；后者能从海量数据中学习复杂模式，却常因缺乏物理约束而产生不切实际的预测，且在数据稀疏区[域泛化](@entry_id:635092)能力差。物理信息机器学习（PIML）应运而生，旨在弥合这一鸿沟，它通过将物理定律直接融入[机器学习模型](@entry_id:262335)，为海洋建模带来了革命性的新范式。本文将系统性地阐述PIML在海洋科学中的应用，为读者构建一个从理论到实践的完整知识体系。

本文分为三个核心部分。在“原理与机制”一章中，我们将深入剖析PIML的基石——物理信息神经网络（PINNs），解释其如何通过自动微分和复合[损失函数](@entry_id:634569)将[偏微分](@entry_id:194612)方程编码为学习约束，并探讨如何整合Boussinesq近似、守恒律等关键[海洋物理学](@entry_id:183539)原理。接下来，在“应用与跨学科连接”一章中，我们将展示这些原理如何应用于解决实际问题，包括开发物理一致的[参数化](@entry_id:265163)方案、求解复杂边界问题以及革新数据同化框架。最后，在“动手实践”部分，我们将通过具体的编程问题，引导读者亲身体验如何实现可[微分](@entry_id:158422)物理求解器、验证模型的物理对称性以及设计孪生实验来[标定模型](@entry_id:180554)参数。通过这一系列的学习，读者将掌握利用PIML解决前沿海洋学问题的核心技能。

## 原理与机制

[物理信息](@entry_id:152556)机器学习（Physics-Informed Machine Learning, PIML）的核心在于将物理定律的数学形式作为一种强大的归纳偏置，融入到机器学习模型的设计、训练和验证过程中。这种融合旨在克服纯数据驱动方法的局限性，例如需要海量数据、在分布外（out-of-distribution）泛化能力差，以及可能产生物理上不合理的预测。本章将深入探讨支撑海洋PIM[L模](@entry_id:1126990)型的关键原理与核心机制，从[物理信息神经网络](@entry_id:145229)（[PINNs](@entry_id:145229)）的基本构造，到高级架构选择和实际应用中面临的挑战。

### 核心方法论：物理信息神经网络（PINNs）

[物理信息神经网络](@entry_id:145229)（[PINNs](@entry_id:145229)）是将[偏微分](@entry_id:194612)方程（PDEs）直接编码到[神经网络损失函数](@entry_id:634461)中的一种基本框架。其核心思想是，一个神经网络不仅要拟合观测数据，还必须在其定义域内逐点地满足控制物理过程的PDE。

#### PINN范式与物理信息[损失函数](@entry_id:634569)

假设我们关注一个由状态场 $u(\mathbf{x}, t)$ 描述的海洋物理过程，其演化由一个微分算子 $\mathcal{N}$ 控制，形式为 $\mathcal{N}(u) = 0$。一个PINN模型构建一个神经网络 $\hat{u}_{\theta}(\mathbf{x}, t)$，其参数为 $\theta$，以逼近真实解 $u(\mathbf{x}, t)$。该网络的训练不完全依赖于对真实解的直接观测，而是通过最小化一个复合[损失函数](@entry_id:634569) $\mathcal{L}(\theta)$ 来进行，该函数通常由三部分组成：

$\mathcal{L}(\theta) = w_{data} \mathcal{L}_{data} + w_{PDE} \mathcal{L}_{PDE} + w_{BC/IC} \mathcal{L}_{BC/IC}$

其中，$w$ 是各部分损失的权重。

*   **数据损失 $\mathcal{L}_{data}$**：衡量网络预测与稀疏观测数据点之间的失配。如果我们在点 $(\mathbf{x}_i, t_i)$ 处有观测值 $u_i$，则该损失通常是[均方误差](@entry_id:175403)（MSE）：$\mathcal{L}_{data} = \frac{1}{N_{data}} \sum_i |\hat{u}_{\theta}(\mathbf{x}_i, t_i) - u_i|^2$。

*   **PDE残差损失 $\mathcal{L}_{PDE}$**：这是PINN的标志性部分。它惩罚网络输出对PDE的违反程度。首先，定义PDE残差 $r_{\theta}(\mathbf{x}, t) = \mathcal{N}(\hat{u}_{\theta}(\mathbf{x}, t))$。然后，在时空域内的大量[配置点](@entry_id:169000)（collocation points）上计算该残差的均方范数：$\mathcal{L}_{PDE} = \frac{1}{N_{PDE}} \sum_j |r_{\theta}(\mathbf{x}_j, t_j)|^2$。这些[配置点](@entry_id:169000)无需有对应的真实数据。

*   **边界与初始条件损失 $\mathcal{L}_{BC/IC}$**：类似地，该损失惩罚网络在时空域边界上对给定边界条件（BC）和初始条件（IC）的违反。

通过最小化这个复合损失，优化器会驱动神经网络参数 $\theta$ 的更新，使得网络输出 $\hat{u}_{\theta}$ 在满足观测数据的同时，也成为控制PDE的一个近似解。

#### 自动微分机制

PINN的实际实现依赖于一个关键技术：**[自动微分](@entry_id:144512)（Automatic Differentiation, AD）**。为了计算PDE残差 $r_{\theta}$，我们需要计算网络输出 $\hat{u}_{\theta}$ 对其时空输入 $(\mathbf{x}, t)$ 的[偏导数](@entry_id:146280)，例如 $\partial \hat{u}_{\theta} / \partial t$ 或 $\nabla^2 \hat{u}_{\theta}$。自动微分提供了一种精确计算这些导数的方法，避免了传统数值方法（如[有限差分](@entry_id:167874)）所带来的[截断误差](@entry_id:140949)。

以一个二维[海洋混合层](@entry_id:1129065)温度 $T(x, y, t)$ 的平流-扩散方程为例 ：
$\frac{\partial T}{\partial t} + u\frac{\partial T}{\partial x} + v\frac{\partial T}{\partial y} - \kappa\left(\frac{\partial^2 T}{\partial x^2}+\frac{\partial^2 T}{\partial y^2}\right) = Q$

PINN的[计算图](@entry_id:636350)从输入节点 $(x, y, t)$ 和参数节点 $\boldsymbol{\theta}$ 开始，通过网络前向传播计算输出 $T_{\theta}(x, y, t)$。随后，AD被用来构建新的[计算图](@entry_id:636350)节点，这些节点代表了 $T_{\theta}$ 对输入的各阶导数，如 $\partial T_{\theta}/\partial x$ 和 $\partial^2 T_{\theta}/\partial x^2$。这些导数节点与给定的速度场 $\boldsymbol{u}$ 和源汇项 $Q$ 组合，形成PDE残差节点 $r_{\theta}$，最终汇聚到标量[损失函数](@entry_id:634569) $\mathcal{L}_{PDE}$。

在训练过程中，我们需要计算[损失函数](@entry_id:634569) $\mathcal{L}_{PDE}$ 对网络参数 $\boldsymbol{\theta}$ 的梯度 $\partial \mathcal{L}_{PDE}/\partial \boldsymbol{\theta}$，以通过[梯度下降法](@entry_id:637322)更新参数。对于拥有数百万参数的深层神经网络，**反向模式[自动微分](@entry_id:144512)（Reverse-mode AD）**，也就是我们熟知的**反向传播（backpropagation）**，显示出其无与伦比的效率。该方法通过一次从输出到输入的反向遍历，即可计算出标量损失对所有参数的梯度。其计算成本仅为一次前向传播的几倍，且与参数数量基本无关，这使得训练大规模PINN成为可能 。外源场（如 $\boldsymbol{u}$ 和 $Q$），若不依赖于参数 $\boldsymbol{\theta}$，则在反向传播中被视为常数 。

#### 硬约束与软约束

在PINN框架中，施加物理约束的方式可分为“软约束”和“硬约束” 。

*   **软约束（Soft Enforcement）**：这是最常见的方法，即通过在[损失函数](@entry_id:634569)中添加惩罚项来施加约束。上述的 $\mathcal{L}_{PDE}$ 和 $\mathcal{L}_{BC/IC}$ 都是软约束的例子。优化过程会“鼓励”网络满足这些约束，但不能保证在所有点上都精确满足。PDE残差几乎总是以软约束的形式施加。

*   **硬约束（Hard Enforcement）**：指通过特殊设计[网络架构](@entry_id:268981)或输出形式（ansatz），使得约束对于任意网络参数 $\theta$ 都被精确满足。例如，对于一个在边界 $\partial\Omega$ 上满足[狄利克雷边界条件](@entry_id:173524) $u|_{\partial\Omega}=g$ 的问题，我们可以构造网络输出为：
    $\hat{u}_{\theta}(\mathbf{x}) = D(\mathbf{x}) N_{\theta}(\mathbf{x}) + g(\mathbf{x})$
    其中，$N_{\theta}$ 是一个标准的神经网络，$D(\mathbf{x})$ 是一个在边界 $\partial\Omega$ 上取值为零的已知函数（例如，到边界的距离函数）。通过这种构造，无论 $N_{\theta}$ 输出什么，$\hat{u}_{\theta}$ 在边界上总是等于 $g$，从而硬性地满足了边界条件。这种方法将约束从优化问题中移除，有时可以简化训练。另一个硬约束的例子是在[二维不可压缩流](@entry_id:136406)问题中，使用[流函数](@entry_id:1132499) $\psi$ 作为网络输出，然后通过导数计算速度分量 $u = \partial_z \psi$ 和 $w = -\partial_x \psi$，这样速度场天然满足连续性方程 $\partial_x u + \partial_z w = 0$ 。

### 桥接理论与实践：整合基础[海洋物理学](@entry_id:183539)

PIML的真正威力体现在将特定领域的物理原理转化为有效的模型约束。对于海洋建模，这意味着要将地球物理流体动力学（GFD）的基石理论融入学习框架。

#### 基本近似：[Boussinesq近似](@entry_id:147239)与[静力平衡](@entry_id:163498)

大尺度海洋动力学模型通常建立在一系列简化近似之上。其中两个核心近似是**Boussinesq近似**和**[静力平衡](@entry_id:163498)（hydrostatic balance）** 。

*   **Boussinesq近似**：适用于密度变化 $\rho'$ 远小于参考密度 $\rho_0$ 的情况（$|\rho'|/\rho_0 \ll 1$）。该近似系统性地简化了控制方程：(1) 在惯性项中，密度被其常数参考值 $\rho_0$ 替代；(2) 在重力项中，仅保留密度异常 $\rho'$ 产生的[浮力](@entry_id:154088)效应；(3) 质量守恒方程简化为运动学上的不可压缩条件 $\nabla \cdot \mathbf{u} = 0$。

*   **[静力平衡](@entry_id:163498)**：适用于展弦比（垂直尺度/水平尺度）很小的流动。通过[尺度分析](@entry_id:1131264)可知，垂直方向的加速度项远小于[垂直压力梯度](@entry_id:1133794)力和重力项。因此，[垂直动量方程](@entry_id:1133792)简化为一个诊断关系：
    $\frac{\partial p}{\partial z} = -\rho g$

在PINN中，这些近似可以直接转化为损失函数中的残差项。例如，一个旨在模拟Boussinesq、[静力平衡](@entry_id:163498)流的PINN，其损失函数中应包含 $R_{mass} = \nabla \cdot \mathbf{u}$ 和 $R_{hyd} = \partial p/\partial z + \rho g$ 这两项，并驱动它们趋近于零 。

#### 守恒律作为[归纳偏置](@entry_id:137419)

守恒律是物理系统的基本法则，将其施加于机器学习模型是确保其长期稳定性和物理真实性的关键。

*   **能量守恒与转换**：在层结流体中，机械能主要分为动能（Kinetic Energy, KE）和重力势能（Gravitational Potential Energy, GPE）。然而，并非所有GPE都能转化为KE。只有那部分超过了通过绝热重排流体质点所能达到的最小能量状态（即稳定层结[参考态](@entry_id:151465)）的势能，才可用于驱动流动，这部分能量被称为**有效势能（Available Potential Energy, APE）** 。

    在无粘、绝热、闭合的Boussinesq流体中，动能和[有效势能](@entry_id:1124192)的总和是守恒的，即 $\frac{d(K+A)}{dt} = 0$。两者之间的瞬时转换率由浮力通量项 $\int_V \rho_0 b w \, dV$ 给出，其中 $b$ 是[浮力](@entry_id:154088)，$w$ 是垂直速度。该项在KE预算中作为源项，在APE预算中则作为汇项。当流体[质点](@entry_id:186768)克服重力向上运动时（$w>0$，假设[浮力](@entry_id:154088) $b$ 为正），APE增加，KE减少；反之，当较重的流体下沉时，APE释放，转化为KE 。此外，由扩散引起的不可逆混合过程（diapycnal mixing）会耗散APE，将其转化为背景势能和内能 。在PIML中，约束总能量 $K+A$ 的守恒，而非单独约束KE，是保证模型动态演化真实性的一个强有力手段。

*   **位涡守恒**：在[地球物理流体动力学](@entry_id:150356)中，**[Ertel位涡](@entry_id:1124655)（Potential Vorticity, PV）** 是一个至关重要的[守恒量](@entry_id:161475)。在Boussinesq近似下，其定义为 $q = (\boldsymbol{\omega}_a \cdot \nabla b)/\rho_0$，其中 $\boldsymbol{\omega}_a = \nabla \times \mathbf{u} + f\hat{\mathbf{k}}$ 是[绝对涡度](@entry_id:262794)，$b$ 是[浮力](@entry_id:154088)。根据Ertel定理，在无粘、绝热的流动中，位涡是物质守恒的，即跟随流体[质点](@entry_id:186768)其值不变：
    $\frac{Dq}{Dt} = \frac{\partial q}{\partial t} + \mathbf{u} \cdot \nabla q = 0$
    这个拉格朗日守恒律为PINN提供了一个强大的约束。通过在[损失函数](@entry_id:634569)中加入一项 $L_{PV} = \int |\partial_t q + \mathbf{u} \cdot \nabla q|^2 dV$，可以强制模型学习到的流场尊重这一深刻的动力学不变量 。

### 架构选择与高级PIML范式

除了基本的PINN框架，PIML领域还发展出多种架构和范式，以应对不同的建模挑战。

#### 混合建模：为未解析物理过程学习[闭包](@entry_id:148169)

在海洋建模中，一个核心挑战是[参数化](@entry_id:265163)那些由于分辨率限制而无法直接解析的**次网格尺度（subgrid-scale, SGS）**过程，如湍流混合。这里存在两种主要的机器学习策略：**黑箱模拟（black-box emulation）**和**混合建模（hybrid modeling）** 。

*   **黑箱模拟**：用一个[深度学习模型](@entry_id:635298)（如CNN或Transformer）直接学习从当前时刻的流场状态到下一时刻状态的映射，即 $\mathcal{N}: \mathbf{u}^n \mapsto \mathbf{u}^{n+1}$，从而完全取代传统的[PDE求解器](@entry_id:753289)。这种方法的缺点是，除非经过特殊设计，否则它不保证遵守基本的物理守恒律，长期积分时容易出现漂移和不稳定性 。

*   **混合建模**：将[机器学习模型](@entry_id:262335)嵌入到传统的数值求解器中，让其学习和提供SGS[闭包](@entry_id:148169)项。例如，在海洋模型中，未解析的[雷诺应力](@entry_id:263788)项 $\boldsymbol{\tau}$ 通常通过**涡粘性（eddy viscosity）**假设来[参数化](@entry_id:265163)，即应力的偏量部分与[应变率张量](@entry_id:266108) $\mathbf{S}$ 线性相关：$\boldsymbol{\tau}^{dev} = -2\nu_t \mathbf{S}$ 。在[混合模型](@entry_id:266571)中，涡粘性系数 $\nu_t$ 或涡扩散系数 $\kappa_t$ 可以由一个神经网络根据已解析的流场特征来预测。这种方法的巨大优势在于，它保留了[PDE求解器](@entry_id:753289)的结构，例如，如果方程以[守恒形式](@entry_id:1122899)离散化（如[有限体积法](@entry_id:141374)），那么像总质量这样的量仍然可以被精确守恒（在时间积分误差内）。此外，可以通过对神经网络输出施加约束（例如，要求 $\nu_t \ge 0$）来强制满足基本的物理原理，如确保能量耗散，从而增强模型的稳定性和物理真实性  。

#### 学习模型中的对称性与不变性

物理定律通常具有对称性，这意味着方程在某些变换下保持形式不变。将这些对称性构建到模型架构中，是一种强大的归纳偏置，可以显著提高模型的泛化能力和数据效率。

*   **伽利略不变性（Galilean Invariance）**：指物理定律在所有匀速运动的[惯性参考系](@entry_id:276742)中都相同。对于[流体动力](@entry_id:750449)学，这意味着控制方程和任何物理上一致的[闭包](@entry_id:148169)模型都不应依赖于参考系的绝对速度。在架构上，这可以通过让模型只处理伽利略不变的输入特征来实现，例如[速度梯度](@entry_id:261686) $\nabla\mathbf{u}$ 或相对于局部[平均速度](@entry_id:267649)的[相对速度](@entry_id:178060)，而不是绝对速度 $\mathbf{u}$ 。

*   **旋转[等变性](@entry_id:636671)（Rotational Equivariance）**：在没有外部方向性影响（如地球自转）的[均匀流](@entry_id:272775)体中，物理过程是各向同性的。这意味着如果输入场旋转，输出场也应以相同的方式旋转。例如，如果一个[闭包](@entry_id:148169)模型 $\mathcal{M}$ 的输入是一个矢量 $\mathbf{v}_{in}$，输出也是一个矢量 $\mathbf{v}_{out}$，那么在旋转 $R$ 的作用下，应满足 $\mathcal{M}(R\mathbf{v}_{in}) = R\mathcal{M}(\mathbf{v}_{in})$。这种性质可以通过使用**群[等变神经网络](@entry_id:137437)（[G-CNNs](@entry_id:637878)）**来精确保证。这类网络使用特殊设计的“可操纵”[卷积核](@entry_id:1123051)，使其[特征图](@entry_id:637719)在[旋转变换](@entry_id:200017)下具有明确的协变行为，从而将对称性硬编码到[网络结构](@entry_id:265673)中 。

#### [算子学习](@entry_id:752958)用于多查询问题

在许多[科学计算](@entry_id:143987)场景中，如不确定性量化（UQ）或数据同化，我们需要针对大量不同的输入参数（如边界条件或[强迫项](@entry_id:165986)）反复求解同一个PDE。

*   **PINN**：对于每个新的输入参数，都需要重新训练或微调一次PINN，其单次查询成本为 $C_{opt}$。

*   **神经算子（Neural Operator, NO）**：如[傅里叶神经算子](@entry_id:189138)（FNO）或[深度算子网络](@entry_id:748262)（[DeepONet](@entry_id:748262)），是另一种PIML范式。它们的目标不是学习单个PDE的解，而是学习将输入函数（如强迫项 $f$ 和边界条件 $g$）映射到输出函数（解 $\psi$）的**解算子** $S: (f, g) \mapsto \psi$ 。[神经算子](@entry_id:1128605)需要一次性的、可能非常昂贵的训练过程（成本为 $C_{train}$），但在训练完成后，对于任何新的输入函数，它都可以通过一次快速的[前向传播](@entry_id:193086)来近似解，其查询成本 $C_{infer}$ 非常低。

在多查询场景中，当查询次数 $N_q$ 足够大时，神经算子的总成本 $C_{train} + N_q C_{infer}$ 将低于PINN的总成本 $N_q C_{opt}$。具体的盈亏平衡点为 $N_q^* = C_{train} / (C_{opt} - C_{infer})$ 。因此，[算子学习](@entry_id:752958)在需要对[参数空间](@entry_id:178581)进行广泛探索的“多查询”任务中具有巨大的计算优势。然而，这种优势的前提是训练数据能充分覆盖查询输入的分布，且模型的[泛化误差](@entry_id:637724)满足精度要求 。

#### 基于[稀疏回归](@entry_id:276495)的模型发现（SINDy）

PIML的另一个前沿方向是**模型发现**，即从数据中自动推断出控制系统的 governing equations。**[非线性动力学的稀疏辨识](@entry_id:276479)（Sparse Identification of Nonlinear Dynamics, [SINDy](@entry_id:266063)）** 是实现这一目标的有力框架 。

SINDy的基本假设是，尽管动力学行为可能很复杂，但其控制方程在某个（可能很大的）候选函数库中是**稀疏**的。其工作流程如下：
1.  **数据与求导**：从时空数据场 $c(\mathbf{x}, t)$ 中，使用对噪声鲁棒的数值方法计算时间导数 $\partial_t c$ 和各种空间导数。
2.  **构建候选库**：基于物理先验（如守恒律、[量纲一致性](@entry_id:271193)、对称性），构建一个包含所有可能PDE项的库矩阵 $\mathbf{\Theta}$。例如，对于一个[示踪剂输运](@entry_id:1133278)问题，这个库可以包含平流项（如 $-\nabla \cdot(\mathbf{u}c)$）、扩散项（如 $\nabla^2 c, \nabla^4 c$）和[非线性](@entry_id:637147)反应项（如 $c^2, c^3$）等。
3.  **[稀疏回归](@entry_id:276495)**：求解一个[稀疏回归](@entry_id:276495)问题 $\partial_t c \approx \mathbf{\Theta}\boldsymbol{\xi}$，寻找一个稀疏的系数向量 $\boldsymbol{\xi}$。常用的方法是[LASSO](@entry_id:751223)（最小绝对收缩和选择算子）或序贯阈值[最小二乘法](@entry_id:137100)（STLS）。这些方法会驱动大部分[无关项](@entry_id:165299)的系数精确地变为零，从而“发现”控制方程中最重要的项。

通过这种方式，SINDy能够从复杂的海洋数据中辨识出简洁、可解释的物理模型，为我们理解和[参数化](@entry_id:265163)海洋过程提供了新的途径 。

### 应对海洋建模的实际挑战

将PIML应用于真实的海洋问题时，会遇到一系列挑战，其中最突出的是如何[量化不确定性](@entry_id:272064)以及如何处理多尺度动力学带来的训练困难。

#### 不确定性量化：[偶然不确定性与认知不确定性](@entry_id:1120923)

在[科学建模](@entry_id:171987)中，预测的不确定性至关重要。它主要分为两类 ：

*   **[偶然不确定性](@entry_id:634772)（Aleatoric Uncertainty）**：源于系统或观测过程固有的随机性。例如，传感器噪声、未解析的[湍流](@entry_id:151300)波动等。这种不确定性是不可约减的，即使拥有无限数据也依然存在。在[概率模型](@entry_id:265150)中，它通常通过数据[似然函数](@entry_id:921601) $p(D|u)$ 的方差来表示。例如，我们可以假设[测量噪声](@entry_id:275238)是异方差的（heteroscedastic），其方差 $\sigma^2(\mathbf{x},t)$ 随空间和时间变化，并让模型学习这个方差函数 。

*   **认知不确定性（Epistemic Uncertainty）**：源于我们对模型的认知不足，例如数据有限、模型结构不完美等。这种不确定性是可约减的，通过收集更多数据或改进模型可以降低。

**[贝叶斯物理信息神经网络](@entry_id:746730)（Bayesian PINNs）** 为量化认知不确定性提供了一个原则性框架。与标准PINN寻找一个唯一的“最佳”解（点估计）不同，Bayesian PINN旨在推断一个在函数空间上的**后验分布** $p(u|D, \mathcal{P})$。这个分布的“宽度”或“[离散度](@entry_id:168823)”就代表了认知不确定性：在数据稀疏或物理约束较弱的区域，[后验分布](@entry_id:145605)会比较宽，表明模型对该处的解“不确定”。随着数据增多或物理约束增强，后验分布会变窄，认知不确定性随之降低 。

#### 刚性系统中的训练病理学

许多海洋动力学系统是**刚性（stiff）**的，即它们包含以非常不同的时间尺度演化的过程。一个典型的例子是强层结流体，其中存在快速传播的[内重力波](@entry_id:185206)（时间尺度 $T_s = 1/N$）和缓慢的平流过程（时间尺度 $T_a = L/U$）。当分层很强时，刚[性比](@entry_id:172643) $\epsilon = T_s/T_a \ll 1$ 。

这种时间尺度上的巨大差异会给PINN的训练带来严重的**梯度[病理学](@entry_id:193640)（gradient pathology）**。如果使用慢的平流时间尺度对整个系统进行朴素的无量纲化，那么控制快波的项（如[浮力](@entry_id:154088)方程中的 $N^2 w$）的系数会变得非常大，量级为 $\mathcal{O}(1/\epsilon)$。这导致PDE残差和[损失函数](@entry_id:634569)被这些大项完全主导。在反向传播过程中，来自这些项的梯度会爆炸，使得优化器几乎所有的“精力”都用于压制快波残差，而忽略了对慢动力学过程的学习，最终导致训练不稳定和收敛失败 。

解决这一挑战需要采用物理启发的策略：
1.  **恰当的尺度变换**：使用快速时间尺度 $T_s$ 对系统进行无量纲化，可以使控制快波的[线性算子](@entry_id:149003)的系数变为 $\mathcal{O}(1)$，从而平衡方程中各项的量级。
2.  **损失函数加权**：根据物理意义（如能量守恒）对不同残差项进行加权。例如，可以调整权重使得动能残差和[有效势能](@entry_id:1124192)残差对总损失的贡献在量级上相当，例如通过平衡 $\langle r_m^2 \rangle$ 和 $\langle r_b^2/N^2 \rangle$ 。
3.  **算子[预处理](@entry_id:141204)**：在损失函数中引入预条件算子，其作用类似于[数值线性代数](@entry_id:144418)中的预条件子，旨在改善[梯度流](@entry_id:635964)的[条件数](@entry_id:145150)，特别是在导致刚性的子系统上（如 $(w, b)$ 耦合系统） 。

通过这些精心设计的机制，PIML模型才能有效学习和模拟复杂的多尺度海洋动力学过程，从而在这一充满挑战的领域发挥其全部潜力。