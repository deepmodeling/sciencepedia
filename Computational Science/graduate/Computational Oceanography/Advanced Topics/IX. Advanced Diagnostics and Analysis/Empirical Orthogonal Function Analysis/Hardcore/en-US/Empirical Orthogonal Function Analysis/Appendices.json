{
    "hands_on_practices": [
        {
            "introduction": "The foundation of Empirical Orthogonal Function (EOF) analysis is the decomposition of variance in a dataset. Therefore, the first essential step is to isolate this variance by creating an anomaly matrix, which is achieved by removing the temporal mean from each spatial point. This practice  focuses on this crucial data preparation step, guiding you to compute and numerically verify the anomaly matrix for several hypothetical data fields, ensuring a solid starting point for any subsequent analysis.",
            "id": "3792009",
            "problem": "Consider Empirical Orthogonal Function (EOF) analysis, which requires constructing an anomaly matrix with zero temporal mean at each spatial location. Let a Sea Surface Temperature (SST) field be represented by a matrix $S \\in \\mathbb{R}^{N \\times T}$, where $N$ is the number of spatial grid points and $T$ is the number of time steps, with entries $S_{i t}$ denoting the SST (in degrees Celsius) at grid point $i$ at time index $t$. The anomaly matrix $X \\in \\mathbb{R}^{N \\times T}$ is defined by removing the temporal mean at each grid point. Formally, define the temporal mean at grid point $i$ as $\\mu_i = \\frac{1}{T}\\sum_{t=0}^{T-1} S_{i t}$, and define the anomaly matrix entries as $X_{i t} = S_{i t} - \\mu_i$. For numerical verification, define a tolerance $\\tau = 10^{-12}$ and declare a row $i$ to be zero-mean if $\\left|\\frac{1}{T}\\sum_{t=0}^{T-1} X_{i t}\\right| \\le \\tau$. The task is to compute $X$ for each test case and verify that each row of $X$ has zero mean to numerical precision.\n\nYou must construct $S$ for each of the following test cases using the given deterministic formulas. Indices in all formulas are zero-based: $i \\in \\{0,1,\\dots,N-1\\}$ and $t \\in \\{0,1,\\dots,T-1\\}$. All SST values are in degrees Celsius.\n\nTest Suite:\n- Case $1$: $N=4$, $T=5$, $S_{i t} = 20 + 0.5\\,i - 0.3\\,t + 0.5\\,(-1)^t$.\n- Case $2$: $N=3$, $T=1$, $S_{i 0} = 14 + 6\\,i$.\n- Case $3$: $N=2$, $T=8$, $S_{i t} = 10^{7} + 10^{5}\\,i + 1000\\,t + 100\\,(-1)^t$.\n- Case $4$: $N=1$, $T=6$, $S_{0 t} = 18$ for all $t$.\n- Case $5$: $N=5$, $T=7$, $S_{i t} = 10 + 0.2\\,i + 0.01\\,t^2 - 0.5\\,t$.\n\nFor each case:\n1. Compute the temporal mean $\\mu_i$ for each row $i$.\n2. Compute the anomaly matrix $X$ by $X_{i t} = S_{i t} - \\mu_i$.\n3. Verify that the mean of each row of $X$ is within the tolerance, i.e., $\\left|\\frac{1}{T}\\sum_{t=0}^{T-1} X_{i t}\\right| \\le \\tau$ for all rows $i$, using $\\tau = 10^{-12}$.\n4. Return a boolean indicating whether all rows satisfy the zero-mean condition.\n\nYour program should produce a single line of output containing the results for the five cases as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3,result4,result5]\"), where each entry is a boolean (\"True\" or \"False\").",
            "solution": "The user-provided problem has been analyzed and is deemed valid.\n\nThe problem requires the implementation and verification of a fundamental step in Empirical Orthogonal Function (EOF) analysis: the creation of an anomaly matrix. This task is scientifically grounded, well-posed, and objective. It presents a clear computational challenge rooted in the field of computational oceanography. All necessary parameters, definitions, and formulas are provided, creating a self-contained and solvable problem.\n\nThe core of the task is to transform a data matrix $S \\in \\mathbb{R}^{N \\times T}$ into an anomaly matrix $X \\in \\mathbb{R}^{N \\times T}$. Here, $N$ represents the number of spatial locations and $T$ represents the number of time steps. The element $S_{i t}$ is the data value (Sea Surface Temperature) at spatial point $i$ and time $t$.\n\nThe transformation is defined by removing the temporal mean from each spatial point. The temporal mean for a given spatial point $i$ (the $i$-th row of $S$) is given by:\n$$\n\\mu_i = \\frac{1}{T}\\sum_{t=0}^{T-1} S_{i t}\n$$\nThe corresponding anomaly matrix $X$ is then constructed by subtracting this mean from each element in that row:\n$$\nX_{i t} = S_{i t} - \\mu_i\n$$\nA key mathematical property of the anomaly matrix $X$ is that the temporal mean of each of its rows is, by definition, zero. We can demonstrate this analytically:\n$$\n\\text{Mean of row } i \\text{ of } X = \\frac{1}{T}\\sum_{t=0}^{T-1} X_{i t} = \\frac{1}{T}\\sum_{t=0}^{T-1} (S_{i t} - \\mu_i)\n$$\nBy distributing the summation:\n$$\n= \\left(\\frac{1}{T}\\sum_{t=0}^{T-1} S_{i t}\\right) - \\left(\\frac{1}{T}\\sum_{t=0}^{T-1} \\mu_i\\right)\n$$\nThe first term is the definition of $\\mu_i$. Since $\\mu_i$ is a constant with respect to the summation index $t$, the second term simplifies to $\\frac{1}{T}(T \\cdot \\mu_i) = \\mu_i$. Therefore:\n$$\n= \\mu_i - \\mu_i = 0\n$$\nThe problem asks for a numerical verification of this property. In digital computers, floating-point arithmetic can introduce small precision errors. Consequently, a direct comparison to $0$ might fail. The problem specifies a tolerance $\\tau = 10^{-12}$, such that a row $i$ is considered to have a zero mean if the absolute value of its computed mean is within this tolerance:\n$$\n\\left|\\frac{1}{T}\\sum_{t=0}^{T-1} X_{i t}\\right| \\le \\tau\n$$\nThe final result for each test case is a boolean (`True`) if all $N$ rows of its anomaly matrix $X$ satisfy this condition, and `False` otherwise.\n\nThe algorithm to solve the problem for each test case is as follows:\n1.  Initialize an $N \\times T$ matrix, $S$, with floating-point numbers.\n2.  Populate the matrix $S$ according to the specified formula $S_{i t}$ for the given case, iterating through each spatial index $i \\in \\{0, \\dots, N-1\\}$ and temporal index $t \\in \\{0, \\dots, T-1\\}$.\n3.  Compute the temporal mean for each row of $S$. This can be efficiently achieved by calculating the mean along the axis corresponding to time (axis $1$ in a row-major implementation). This yields a vector of means $\\boldsymbol{\\mu} \\in \\mathbb{R}^{N}$.\n4.  Construct the anomaly matrix $X$ by subtracting the mean vector from the data matrix $S$. This operation requires broadcasting the mean of each row across all elements of that row. For an $N \\times T$ matrix $S$ and an $N \\times 1$ column vector of means, the subtraction $X = S - \\boldsymbol{\\mu}$ performs this operation element-wise.\n5.  Compute the temporal mean for each row of the resulting anomaly matrix $X$.\n6.  For each of these newly computed row means, check if its absolute value is less than or equal to the tolerance $\\tau=10^{-12}$.\n7.  The overall result for the test case is `True` if the condition from step 6 holds for all rows, and `False` otherwise.\nThis procedure will be applied to all five test cases provided.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes anomaly matrices for several SST test cases and verifies\n    if each row has a zero temporal mean to numerical precision.\n    \"\"\"\n\n    # Define the tolerance for numerical verification.\n    tau = 1e-12\n\n    # Define the test cases from the problem statement.\n    # Each case is a dictionary with N, T, and a lambda function for S_it.\n    test_cases = [\n        {\n            \"N\": 4, \"T\": 5,\n            \"formula\": lambda i, t: 20 + 0.5 * i - 0.3 * t + 0.5 * (-1)**t,\n        },\n        {\n            \"N\": 3, \"T\": 1,\n            \"formula\": lambda i, t: 14 + 6 * i,\n        },\n        {\n            \"N\": 2, \"T\": 8,\n            \"formula\": lambda i, t: 10**7 + 10**5 * i + 1000 * t + 100 * (-1)**t,\n        },\n        {\n            \"N\": 1, \"T\": 6,\n            \"formula\": lambda i, t: 18.0,\n        },\n        {\n            \"N\": 5, \"T\": 7,\n            \"formula\": lambda i, t: 10 + 0.2 * i + 0.01 * t**2 - 0.5 * t,\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        N = case[\"N\"]\n        T = case[\"T\"]\n        formula = case[\"formula\"]\n\n        # 1. Construct the SST matrix S\n        S = np.zeros((N, T), dtype=np.float64)\n        for i in range(N):\n            for t in range(T):\n                S[i, t] = formula(i, t)\n\n        # 2. Compute the temporal mean mu_i for each row i.\n        #    The shape of mu will be (N, 1) for broadcasting.\n        mu = S.mean(axis=1, keepdims=True)\n\n        # 3. Compute the anomaly matrix X.\n        #    Broadcasting subtracts mu[i, 0] from every element in row i of S.\n        X = S - mu\n\n        # 4. Verify that the mean of each row of X is within the tolerance.\n        #    Compute the mean of each row of the anomaly matrix.\n        X_row_means = X.mean(axis=1)\n\n        # 5. Check if the absolute value of all row means are = tau.\n        #    np.all returns True if all elements in the iterable are True.\n        all_rows_verified = np.all(np.abs(X_row_means) = tau)\n        \n        results.append(all_rows_verified)\n\n    # Final print statement in the exact required format.\n    # The map(str, ...) converts boolean True/False to strings \"True\"/\"False\".\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "At its core, Empirical Orthogonal Function (EOF) analysis is an application of linear algebra, specifically the Singular Value Decomposition (SVD). This exercise  demystifies the method by having you compute the SVD of several small data matrices and explicitly verify the fundamental relationships between its components and the products of an EOF analysis. By confirming that squared singular values match the eigenvalues of the covariance matrix and that the bases are orthonormal, you will solidify your understanding of why SVD is the definitive tool for this decomposition.",
            "id": "3791994",
            "problem": "You are given a set of small, synthetic data matrices representing standardized anomaly fields in computational oceanography. Let $\\tilde{X} \\in \\mathbb{R}^{m \\times n}$ denote an anomaly matrix whose rows index spatial locations and columns index times. In Empirical Orthogonal Function (EOF) analysis, spatial patterns (EOFs) and temporal coefficients (Principal Components, PCs) are obtained by decomposing $\\tilde{X}$ into orthonormal spatial and temporal bases and a set of nonnegative amplitudes. From first principles, the relationship between the squared amplitudes and the eigenvalues of the spatial covariance operator $\\tilde{X}\\tilde{X}^{\\top}$ must be demonstrated. Your task is to build a program that, for each test matrix, computes a singular value decomposition, explicitly constructs Empirical Orthogonal Functions (EOFs) and Principal Components (PCs), and verifies three properties: (i) the squared amplitudes match the eigenvalues of $\\tilde{X}\\tilde{X}^{\\top}$, (ii) the decomposition reconstructs the data, and (iii) the spatial and temporal bases are orthonormal.\n\nDefinitions on first use:\n- Empirical Orthogonal Function (EOF): The spatial basis vectors corresponding to the optimal orthonormal decomposition of space-time anomalies.\n- Principal Component (PC): The temporal coefficients associated with the spatial EOFs.\n- Singular Value Decomposition (SVD): A numerical factorization that yields orthonormal bases and nonnegative amplitudes for any real matrix.\n\nFor each matrix $\\tilde{X}$ in the test suite below, do the following:\n1. Compute a numerical factorization that yields an orthonormal set of spatial vectors (EOFs), an orthonormal set of temporal vectors (PC directions), and nonnegative scalar amplitudes. Denote the spatial EOFs by the columns of $U$, the PCs by the rows of $V^{\\top}$, and the amplitudes by the entries of a nonnegative vector $S$.\n2. Verify that the squared amplitudes $S^2$ match the eigenvalues of $\\tilde{X}\\tilde{X}^{\\top}$ within a tolerance of $10^{-10}$, after sorting both sets in descending order.\n3. Verify that the decomposition reconstructs $\\tilde{X}$ within a relative error tolerance of $10^{-12}$ (use absolute error tolerance $10^{-12}$ if $\\|\\tilde{X}\\|_F=0$).\n4. Verify that the spatial basis and the temporal basis are orthonormal by checking $U^{\\top}U=I$ and $V^{\\top}V=I$ within a tolerance of $10^{-12}$.\n\nTest suite of matrices:\n- Case $1$ (happy path, $3 \\times 4$): $\\tilde{X}_1 = \\begin{bmatrix} 1.2  -0.3  0.5  -1.4 \\\\ 0.8  -0.2  -0.1  -0.5 \\\\ -0.6  0.7  -0.9  0.8 \\end{bmatrix}$.\n- Case $2$ (rank-deficient, $3 \\times 3$): $\\tilde{X}_2 = \\begin{bmatrix} 1  -1  0 \\\\ 2  -2  0 \\\\ -1  1  0 \\end{bmatrix}$.\n- Case $3$ (boundary, all zeros, $3 \\times 3$): $\\tilde{X}_3 = \\begin{bmatrix} 0  0  0 \\\\ 0  0  0 \\\\ 0  0  0 \\end{bmatrix}$.\n- Case $4$ (repeated amplitudes, $2 \\times 2$): $\\tilde{X}_4 = \\begin{bmatrix} 2  0 \\\\ 0  2 \\end{bmatrix}$.\n- Case $5$ (rectangular wide, $2 \\times 5$): $\\tilde{X}_5 = \\begin{bmatrix} 3  -1  -2  0  0 \\\\ -2  2  1  -1  0 \\end{bmatrix}$.\n\nFor each case, your program must compute:\n- A boolean indicating whether $S^2$ equals the eigenvalues of $\\tilde{X}\\tilde{X}^{\\top}$ to within $10^{-10}$, after sorting both sets in descending order.\n- A boolean indicating whether the reconstruction error criterion is satisfied to within $10^{-12}$ (relative, or absolute if $\\|\\tilde{X}\\|_F=0$).\n- A boolean indicating whether both orthonormality conditions $U^{\\top}U=I$ and $V^{\\top}V=I$ are satisfied to within $10^{-12}$.\n\nFinal output format:\nYour program should produce a single line of output containing the results for the five cases as a comma-separated list of lists of booleans with no whitespace, for example: \"[[True,True,True],[True,True,True],[True,True,True],[True,True,True],[True,True,True]]\".",
            "solution": "The problem statement is valid. It presents a well-defined computational task grounded in the established mathematical principles of linear algebra, specifically Singular Value Decomposition (SVD) and its relationship to the eigendecomposition of covariance matrices. This relationship is the theoretical foundation of Empirical Orthogonal Function (EOF) analysis, a standard method in oceanography and climate science. The problem provides all necessary data, definitions, and precise, objective verification criteria, making it a complete and solvable problem.\n\nThe core of EOF analysis is the decomposition of a space-time data matrix $\\tilde{X} \\in \\mathbb{R}^{m \\times n}$, where $m$ represents spatial locations and $n$ represents time points, into a set of orthogonal spatial patterns and their corresponding temporal amplitudes. The Singular Value Decomposition (SVD) provides a natural and numerically robust framework for this task.\n\nThe SVD of the matrix $\\tilde{X}$ is given by:\n$$\n\\tilde{X} = U \\Sigma V^{\\top}\n$$\nwhere:\n- $U \\in \\mathbb{R}^{m \\times m}$ is an orthogonal matrix whose columns are the left-singular vectors. In the context of EOF analysis, these are the spatial basis vectors, known as Empirical Orthogonal Functions (EOFs).\n- $V \\in \\mathbb{R}^{n \\times n}$ is an orthogonal matrix whose columns are the right-singular vectors. These represent an orthonormal basis for the temporal domain, often called PC directions.\n- $\\Sigma \\in \\mathbb{R}^{m \\times n}$ is a rectangular diagonal matrix containing the non-negative singular values, $s_i$, in descending order. These values are the amplitudes of the corresponding modes.\n\nThe Principal Components (PCs), which represent the time series of the spatial patterns, are given by the rows of the matrix product $\\Sigma V^{\\top}$.\n\nThe validation task consists of three parts, each confirming a fundamental property of the SVD in this context.\n\n**Part 1: Verification of Squared Amplitudes and Eigenvalues**\n\nThis verification rests on the connection between the SVD of $\\tilde{X}$ and the eigendecomposition of the spatial covariance matrix, $C_{space} = \\tilde{X}\\tilde{X}^{\\top}$. The spatial covariance matrix measures the covariance between different spatial points over time. Its eigenvectors represent the dominant modes of spatial variability, which are precisely the EOFs.\n\nLet's substitute the SVD of $\\tilde{X}$ into the definition of $C_{space}$:\n$$\nC_{space} = \\tilde{X}\\tilde{X}^{\\top} = (U \\Sigma V^{\\top})(U \\Sigma V^{\\top})^{\\top}\n$$\nUsing the property $(AB)^{\\top} = B^{\\top}A^{\\top}$, we get:\n$$\nC_{space} = (U \\Sigma V^{\\top})(V \\Sigma^{\\top} U^{\\top})\n$$\nSince $V$ is an orthogonal matrix, $V^{\\top}V = I$, where $I$ is the identity matrix. The expression simplifies to:\n$$\nC_{space} = U (\\Sigma \\Sigma^{\\top}) U^{\\top}\n$$\nThis equation is the eigenvalue decomposition of the symmetric matrix $C_{space}$. The columns of $U$ are the eigenvectors (the EOFs), and the diagonal matrix $\\Lambda = \\Sigma \\Sigma^{\\top}$ contains the eigenvalues. The diagonal entries of $\\Lambda$ are the squares of the singular values, $s_i^2$, from the SVD of $\\tilde{X}$. Specifically, if $\\tilde{X}$ is $m \\times n$, then $\\Sigma \\Sigma^{\\top}$ is an $m \\times m$ diagonal matrix whose first $k = \\min(m, n)$ diagonal entries are $s_1^2, s_2^2, \\ldots, s_k^2$, and the remaining $m-k$ entries are zero (if $m  n$).\nTherefore, the eigenvalues of $\\tilde{X}\\tilde{X}^{\\top}$ must be equal to the squared singular values of $\\tilde{X}$ (padded with zeros if necessary). The numerical verification involves computing both sets of numbers, sorting them in descending order, and checking for equality within a specified numerical tolerance, here $10^{-10}$.\n\n**Part 2: Verification of Data Reconstruction**\n\nThe equation $\\tilde{X} = U \\Sigma V^{\\top}$ itself states that the original data matrix can be perfectly reconstructed from its SVD components. In a computational environment with finite precision arithmetic, we expect this reconstruction to be accurate up to a small floating-point error. The verification step confirms this by computing the reconstructed matrix $\\tilde{X}_{rec} = U \\Sigma V^{\\top}$ and measuring the error relative to the original matrix $\\tilde{X}$. The Frobenius norm, $\\|\\cdot\\|_F$, is used for this purpose. The relative error is calculated as:\n$$\n\\text{Error}_{rel} = \\frac{\\|\\tilde{X} - \\tilde{X}_{rec}\\|_F}{\\|\\tilde{X}\\|_F}\n$$\nThis error is checked against a tolerance of $10^{-12}$. For the special case where $\\tilde{X}$ is the zero matrix, $\\|\\tilde{X}\\|_F=0$, and the check reverts to an absolute error $\\|\\tilde{X} - \\tilde{X}_{rec}\\|_F  10^{-12}$.\n\n**Part 3: Verification of Orthonormality**\n\nA defining property of the SVD is that the matrices $U$ and $V$ are orthogonal. Orthogonality means that the dot product of any two distinct columns is zero, and the dot product of any column with itself is one. This can be expressed concisely in matrix form:\n$$\nU^{\\top}U = I_m \\quad \\text{and} \\quad V^{\\top}V = I_n\n$$\nwhere $I_m$ and $I_n$ are identity matrices of size $m$ and $n$, respectively. From a practical standpoint when using an \"economy\" SVD where $U$ is $m \\times k$ and $V$ is $n \\times k$ (with $k=\\min(m,n)$), the corresponding properties are $U^\\top U = I_k$ and $V^\\top V = I_k$. The verification step checks these identities for the numerically computed matrices, confirming that the spatial basis (EOFs in $U$) and the temporal basis (PC directions in $V$) are indeed orthonormal sets of vectors, within a numerical tolerance of $10^{-12}$. For the implementation, where the SVD routine returns $V^{\\top}$ (denoted `Vh`), the check for $V$ becomes a check on `Vh`, as $(Vh^\\top)^\\top(Vh^\\top) = Vh Vh^\\top = I_k$.\n\nThe program will implement these three verification steps for each provided test matrix, demonstrating the consistency between the theoretical properties of SVD and their numerical implementation.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run EOF analysis verification on the test suite of matrices.\n    \"\"\"\n\n    test_cases = [\n        # Case 1: happy path, 3x4\n        np.array([\n            [1.2, -0.3, 0.5, -1.4],\n            [0.8, -0.2, -0.1, -0.5],\n            [-0.6, 0.7, -0.9, 0.8]\n        ]),\n        # Case 2: rank-deficient, 3x3\n        np.array([\n            [1., -1., 0.],\n            [2., -2., 0.],\n            [-1., 1., 0.]\n        ]),\n        # Case 3: boundary, all zeros, 3x3\n        np.array([\n            [0., 0., 0.],\n            [0., 0., 0.],\n            [0., 0., 0.]\n        ]),\n        # Case 4: repeated amplitudes, 2x2\n        np.array([\n            [2., 0.],\n            [0., 2.]\n        ]),\n        # Case 5: rectangular wide, 2x5\n        np.array([\n            [3., -1., -2., 0., 0.],\n            [-2., 2., 1., -1., 0.]\n        ])\n    ]\n\n    results = []\n    for x_tilde in test_cases:\n        results.append(verify_eof_properties(x_tilde))\n\n    # Format the final output string to match the problem specification\n    # e.g., [[True,True,True],[True,True,True],...]\n    formatted_results = []\n    for res in results:\n        # Convert each boolean in the inner list to a string\n        inner_list_str = ','.join(map(str, res))\n        # Enclose in brackets\n        formatted_results.append(f\"[{inner_list_str}]\")\n    \n    # Join the formatted inner lists and enclose in outer brackets\n    final_output = f\"[{','.join(formatted_results)}]\"\n    \n    print(final_output)\n\ndef verify_eof_properties(x_tilde):\n    \"\"\"\n    Performs SVD and verifies the three specified properties for a given matrix.\n\n    Args:\n        x_tilde (np.ndarray): The input anomaly matrix.\n\n    Returns:\n        list: A list of three booleans corresponding to the three verified properties.\n    \"\"\"\n    m, n = x_tilde.shape\n    k = min(m, n)\n\n    # 1. Compute the Singular Value Decomposition.\n    # U: EOFs, s: singular values (amplitudes), Vh: transpose of PC directions\n    # Using full_matrices=False is the standard for economy SVD\n    # and sufficient for these checks.\n    try:\n        U, s, Vh = np.linalg.svd(x_tilde, full_matrices=False)\n    except np.linalg.LinAlgError:\n        # SVD might fail in extreme cases, though unlikely with numpy's robust implementation.\n        # If it fails, all checks are considered False.\n        return [False, False, False]\n    \n    # Property (i): Squared amplitudes match eigenvalues of X*X^T\n    # Calculate spatial covariance matrix and its eigenvalues\n    cov_spatial = x_tilde @ x_tilde.T\n    # eigvalsh is preferred for hermitian (or real symmetric) matrices\n    # and returns eigenvalues in ascending order.\n    eigvals = np.linalg.eigvalsh(cov_spatial)\n    # Sort eigenvalues in descending order to match singular value ordering\n    eigvals_sorted_desc = eigvals[::-1]\n    \n    s_squared = s**2\n    # The number of singular values is k=min(m,n).\n    # The number of eigenvalues is m. If m  n, there are m-n zero eigenvalues.\n    # We must compare the k squared singular values with the k largest eigenvalues.\n    # The remaining m-k eigenvalues should be zero. A robust way is to pad s^2 with zeros.\n    s_squared_padded = np.zeros(m)\n    s_squared_padded[:len(s_squared)] = s_squared\n    \n    is_eig_match = np.allclose(s_squared_padded, eigvals_sorted_desc, atol=1e-10, rtol=0)\n\n    # Property (ii): Decomposition reconstructs the data matrix\n    # Reconstruct the matrix using the SVD components\n    # s is a 1D array, so it needs to be formed into a diagonal matrix.\n    s_diag = np.diag(s)\n    x_reconstructed = U @ s_diag @ Vh\n    \n    norm_x = np.linalg.norm(x_tilde, 'fro')\n    norm_error = np.linalg.norm(x_tilde - x_reconstructed, 'fro')\n    \n    if norm_x == 0:\n        is_reconstructed = norm_error  1e-12\n    else:\n        is_reconstructed = (norm_error / norm_x)  1e-12\n\n    # Property (iii): Spatial and temporal bases are orthonormal\n    # Check U^T * U = I\n    identity_U = np.identity(U.shape[1])\n    is_U_orthonormal = np.allclose(U.T @ U, identity_U, atol=1e-12, rtol=0)\n    \n    # Check V^T * V = I. Since we have Vh = V^T, this is Vh * Vh^T = I\n    identity_V = np.identity(Vh.shape[0])\n    is_V_orthonormal = np.allclose(Vh @ Vh.T, identity_V, atol=1e-12, rtol=0)\n    \n    is_orthonormal = is_U_orthonormal and is_V_orthonormal\n    \n    return [is_eig_match, is_reconstructed, is_orthonormal]\n\nsolve()\n```"
        },
        {
            "introduction": "Applying EOF analysis to realistic oceanographic datasets often presents a significant computational hurdle: the number of spatial grid points ($N$) can be orders of magnitude larger than the number of time steps ($T$). Directly computing the $N \\times N$ covariance matrix is infeasible. This practice  introduces a powerful and elegant solution: the 'method of snapshots,' which cleverly solves the problem by working with the much smaller $T \\times T$ temporal covariance matrix. You will implement this algorithm to efficiently extract the EOFs, demonstrating a technique essential for large-scale data analysis.",
            "id": "3791937",
            "problem": "You are given the task of implementing the method of snapshots for Empirical Orthogonal Function (EOF) analysis in computational oceanography. The goal is to compute spatial patterns, temporal patterns, and associated variances from an anomaly data matrix without forming large covariance matrices that scale as $N \\times N$. Consider a hypothetical dataset with $N = 10^5$ spatial locations and $T = 500$ time steps. The method to be implemented must avoid forming any $N \\times N$ matrices and must proceed by leveraging objects of size at most $T \\times T$. All computations concern anomalies obtained by subtracting the temporal mean from each spatial location, and no physical units are involved in this problem.\n\nStarting from fundamental definitions, treat the anomaly matrix $X \\in \\mathbb{R}^{N \\times T}$ as the data container whose columns are time samples. The Empirical Orthogonal Function (EOF) decomposition is defined in terms of the Singular Value Decomposition (SVD) of $X$ into spatial patterns, singular values, and temporal patterns. The method of snapshots avoids direct computation with $N \\times N$ matrices by focusing on the $T \\times T$ temporal covariance matrix. The target outputs of the method are the temporal patterns $V$, the diagonal matrix of covariance eigenvalues $\\Lambda$, and the spatial patterns $U$, in a manner that is consistent with the SVD convention for EOF analysis of the anomaly matrix.\n\nYour program must implement a numerically stable algorithm that:\n- Subtracts the temporal mean from each spatial location to form anomalies.\n- Constructs only a $T \\times T$ temporal covariance matrix from the anomalies.\n- Computes the temporal patterns $V$, the nonnegative eigenvalues collected in a diagonal matrix $\\Lambda$, and the spatial patterns $U$ without ever forming any $N \\times N$ matrix.\n- Handles rank-deficient cases and exactly zero or numerically negligible eigenvalues using a relative tolerance.\n- Produces reconstructions of the anomaly matrix from the computed triplet and validates internal consistency using strictly quantitative criteria.\n\nYour implementation will be graded using the following test suite. For each case, construct $X$ as instructed, then compute the triplet $(V, \\Lambda, U)$ using the method of snapshots, and then compute the specified scalar result. All random variables must be drawn from a standard normal distribution with the provided seed. All arithmetic must use double precision.\n\nDefinitions and constraints to be used in all cases:\n- The anomaly matrix must be formed by subtracting the temporal mean from each row of $X$.\n- The temporal covariance matrix is the $T \\times T$ symmetric matrix built from anomalies.\n- Eigenvalues must be sorted in descending order, and columns of $V$ must be ordered accordingly.\n- The estimated numerical rank is the number of eigenvalues strictly larger than $\\tau \\cdot \\lambda_{\\max}$, where $\\lambda_{\\max}$ is the largest eigenvalue and $\\tau = 10^{-10}$.\n- Reconstruction must be performed using only the modes associated with eigenvalues above tolerance.\n\nTest suite (five cases):\n- Case $1$ (happy path, $N > T$): $N = 120$, $T = 50$, seed $= 0$. Construct $X$ with independent standard normal entries and form anomalies. Compute the relative Frobenius reconstruction error of the anomaly matrix using the triplet $(V, \\Lambda, U)$. The required scalar result is\n  $$e_1 = \\frac{\\lVert X_{\\mathrm{anom}} - \\widehat{X} \\rVert_F}{\\lVert X_{\\mathrm{anom}} \\rVert_F},$$\n  where $\\widehat{X}$ is reconstructed from the retained modes.\n- Case $2$ ($T > N$): $N = 40$, $T = 80$, seed $= 1$. Construct $X$ with independent standard normal entries and form anomalies. Compute the full-matrix SVD singular values of the anomaly matrix and compare them to the singular values implied by the method of snapshots. The required scalar result is the relative $\\ell_2$ error between the two singular value vectors (both truncated to the retained modes),\n  $$e_2 = \\frac{\\lVert s_{\\mathrm{snap}} - s_{\\mathrm{svd}} \\rVert_2}{\\lVert s_{\\mathrm{svd}} \\rVert_2}.$$\n- Case $3$ (rank-deficient): $N = 90$, $T = 70$, rank parameter $r = 15$, seed $= 2$. Construct $A \\in \\mathbb{R}^{N \\times r}$ and $B \\in \\mathbb{R}^{r \\times T}$ with independent standard normal entries using the given seed, then enforce zero temporal means by replacing $B$ with $B - \\mathrm{mean}(B, \\text{axis}=1)$. Set $X = A B$. Form anomalies (which should be zero by construction). Compute the estimated numerical rank and return the integer difference\n  $$d_3 = \\left| \\mathrm{rank}_{\\mathrm{est}} - \\min(r, T - 1) \\right|.$$\n- Case $4$ (orthonormality check): $N = 60$, $T = 60$, seed $= 3$. Construct $X$ with independent standard normal entries and form anomalies. Compute the Frobenius norm of the deviation from orthonormality of the columns of $U$ retained by the tolerance rule:\n  $$e_4 = \\lVert U^\\top U - I \\rVert_F,$$\n  where $I$ is the identity matrix of compatible size.\n- Case $5$ (small $T$ edge case): $N = 50$, $T = 5$, seed $= 4$. Construct $X$ with independent standard normal entries and form anomalies. Compute the relative Frobenius reconstruction error using the retained modes:\n  $$e_5 = \\frac{\\lVert X_{\\mathrm{anom}} - \\widehat{X} \\rVert_F}{\\lVert X_{\\mathrm{anom}} \\rVert_F}.$$\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets in the order $[e_1, e_2, d_3, e_4, e_5]$. For example, a syntactically correct output is\n\"[0.0,0.0,0,0.0,0.0]\".",
            "solution": "The user-provided problem is assessed to be valid. It is a well-posed, scientifically grounded, and objective computational task rooted in the principles of linear algebra and its application to computational oceanography. The problem asks for an implementation of the \"method of snapshots\" for Empirical Orthogonal Function (EOF) analysis, a standard and efficient algorithm for dimensionality reduction when the number of spatial points ($N$) greatly exceeds the number of temporal snapshots ($T$).\n\nThe solution proceeds by first detailing the theoretical basis of the method, followed by an outline of the algorithm's design and its application to the specific test cases.\n\n### Principle-Based Design\n\n**1. Theoretical Foundation: EOF Analysis and Singular Value Decomposition (SVD)**\n\nEOF analysis seeks to decompose a spatio-temporal dataset, represented as a matrix of anomalies $X_{\\mathrm{anom}} \\in \\mathbb{R}^{N \\times T}$, into a set of orthogonal spatial patterns (EOFs) and corresponding temporal patterns (Principal Components). Mathematically, this is equivalent to the Singular Value Decomposition (SVD) of the anomaly matrix:\n$$\nX_{\\mathrm{anom}} = U S V^\\top\n$$\nwhere:\n- $X_{\\mathrm{anom}}$ is the data matrix with dimensions $N$ (space) $\\times$ $T$ (time), where the temporal mean has been subtracted from each row.\n- $U \\in \\mathbb{R}^{N \\times k}$ is a matrix whose columns are the orthonormal spatial patterns (EOFs).\n- $S \\in \\mathbb{R}^{k \\times k}$ is a diagonal matrix containing the singular values $\\sigma_i  0$, which represent the importance of each mode.\n- $V \\in \\mathbb{R}^{T \\times k}$ is a matrix whose columns are the orthonormal temporal patterns.\n- $k = \\mathrm{rank}(X_{\\mathrm{anom}})$ is the number of non-zero modes.\n\nThe direct computation of the SVD, or the equivalent eigendecomposition of the $N \\times N$ spatial covariance matrix $C_N = X_{\\mathrm{anom}} X_{\\mathrm{anom}}^\\top$, becomes computationally prohibitive when $N$ is very large (e.g., $N=10^5$ as suggested).\n\n**2. The Method of Snapshots**\n\nThe method of snapshots circumvents this issue by operating on the much smaller $T \\times T$ temporal scatter matrix (also referred to as the temporal covariance matrix, up to a scaling factor):\n$$\nC_T = X_{\\mathrm{anom}}^\\top X_{\\mathrm{anom}}\n$$\nThe core insight connects the eigendecomposition of $C_T$ to the SVD of $X_{\\mathrm{anom}}$. By substituting $X_{\\mathrm{anom}} = U S V^\\top$ into the definition of $C_T$, we find:\n$$\nC_T = (U S V^\\top)^\\top (U S V^\\top) = V S^\\top U^\\top U S V^\\top = V (S^2) V^\\top\n$$\nThis last expression is the eigendecomposition of $C_T$, since $U^\\top U = I$ and $V^\\top V = I$. Comparing this to the standard form of eigendecomposition, $C_T V = V \\Lambda$, two key relationships emerge:\n\n-   The eigenvectors of $C_T$ (the columns of $V$) are the temporal patterns of $X_{\\mathrm{anom}}$.\n-   The eigenvalues of $C_T$ (the diagonal elements of $\\Lambda$) are the squares of the singular values of $X_{\\mathrm{anom}}$, i.e., $\\lambda_i = \\sigma_i^2$.\n\nWith $V$ and $S$ (derived from $\\Lambda$) known, the spatial patterns $U$ can be recovered from the SVD equation without forming any $N \\times N$ matrices:\n$$\nX_{\\mathrm{anom}} V = U S \\implies U = X_{\\mathrm{anom}} V S^{-1}\n$$\nFor each mode $i$, this corresponds to:\n$$\n\\mathbf{u}_i = \\frac{1}{\\sigma_i} X_{\\mathrm{anom}} \\mathbf{v}_i\n$$\nThis formula shows that the spatial patterns $U$ are linear combinations of the data snapshots (columns of $X_{\\mathrm{anom}}$), with weighting coefficients given by the elements of $V S^{-1}$. The columns $\\mathbf{u}_i$ computed this way are guaranteed to be orthonormal.\n\n**3. Algorithmic Implementation**\n\nThe algorithm is implemented as a function that takes the raw data matrix $X$ and a tolerance $\\tau$ as input.\n\n-   **Step 1: Anomaly Calculation**: The temporal mean is subtracted from each row of $X$ to form the anomaly matrix $X_{\\mathrm{anom}}$. For a matrix $X \\in \\mathbb{R}^{N \\times T}$, its temporal mean is a vector $\\boldsymbol{\\mu} \\in \\mathbb{R}^{N \\times 1}$ where $\\mu_i = \\frac{1}{T}\\sum_{j=1}^T X_{ij}$. Then, $(X_{\\mathrm{anom}})_{ij} = X_{ij} - \\mu_i$.\n-   **Step 2: Eigendecomposition of the Temporal Matrix**: The $T \\times T$ matrix $C_T = X_{\\mathrm{anom}}^\\top X_{\\mathrm{anom}}$ is formed. Since $C_T$ is symmetric positive semi-definite, its eigenvalues $\\lambda_i$ and eigenvectors $\\mathbf{v}_i$ are computed using a specialized solver like `scipy.linalg.eigh`. The eigenvalues are sorted in descending order, and the corresponding eigenvectors are reordered to form the columns of $V$.\n-   **Step 3: Numerical Rank Truncation**: Due to floating-point limitations, a numerical rank $k$ is determined. Eigenvalues are considered significant if they are strictly greater than a threshold relative to the largest eigenvalue: $\\lambda_i  \\tau \\cdot \\lambda_{\\max}$, where $\\tau = 10^{-10}$. All results ($V$, $\\Lambda$, $U$) are truncated to this rank $k$.\n-   **Step 4: Computation of Spatial Patterns and Singular Values**: The first $k$ significant eigenvalues are used to compute the corresponding singular values, $\\sigma_i = \\sqrt{\\lambda_i}$. The truncated spatial patterns $U_k$ are then computed using the formula $U_k = X_{\\mathrm{anom}} V_k S_k^{-1}$, which is implemented efficiently as a matrix-matrix product followed by column-wise scaling.\n-   **Step 5: Test Case Execution**: For each test case defined in the problem, the data matrix $X$ is constructed as specified. The implemented snapshot method is used to compute the EOF triplet. The required scalar result is then calculated. For reconstruction-based tests (Cases $1$ and $5$), the anomaly matrix is reconstructed as $\\widehat{X} = U_k S_k V_k^\\top$. For orthonormality checks (Case $4$), the product $U_k^\\top U_k$ is compared to the identity matrix. For rank checks (Case $3$), the computed rank $k$ is compared to the theoretical rank. For SVD comparison (Case $2$), the singular values obtained from snapshots ($\\sqrt{\\lambda_i}$) are compared to those from a direct SVD call. All calculations use double-precision floating-point arithmetic.",
            "answer": "```python\nimport numpy as np\nimport scipy.linalg\n\ndef compute_eofs_snapshots(X, tau):\n    \"\"\"\n    Computes EOFs using the method of snapshots.\n    \n    Args:\n        X (np.ndarray): Data matrix of shape (N, T), where N is space and T is time.\n        tau (float): Relative tolerance for rank determination.\n\n    Returns:\n        tuple: A tuple containing:\n            - U (np.ndarray): Spatial patterns (EOFs), shape (N, k).\n            - lambda_trunc (np.ndarray): Truncated eigenvalues, shape (k,).\n            - V_trunc (np.ndarray): Temporal patterns (PCs), shape (T, k).\n            - s_trunc (np.ndarray): Truncated singular values, shape (k,).\n            - k (int): Estimated numerical rank.\n    \"\"\"\n    N, T = X.shape\n\n    # Step 1: Form the anomaly matrix by subtracting the temporal mean.\n    mean = X.mean(axis=1, keepdims=True)\n    X_anom = X - mean\n\n    # Step 2: Form the temporal scatter matrix.\n    C_T = X_anom.T @ X_anom\n\n    # Step 3: Eigendecomposition of the symmetric matrix C_T.\n    # eigh returns eigenvalues in ascending order.\n    eigvals, V = scipy.linalg.eigh(C_T)\n\n    # Sort eigenvalues and eigenvectors in descending order.\n    idx = np.argsort(eigvals)[::-1]\n    eigvals = eigvals[idx]\n    V = V[:, idx]\n\n    # Clean up potential small negative eigenvalues from numerical error.\n    eigvals[eigvals  0] = 0\n\n    # Step 4: Determine numerical rank based on the tolerance.\n    # The rank is the number of eigenvalues greater than tau * max_eigenvalue.\n    max_eigval = eigvals[0] if len(eigvals)  0 else 0.0\n    if max_eigval  0:\n        k = np.sum(eigvals  tau * max_eigval)\n    else:\n        k = 0\n\n    # If the effective rank is 0, the anomaly matrix was all zeros.\n    if k == 0:\n        return np.zeros((N, 0)), np.array([]), np.zeros((T, 0)), np.array([]), 0\n\n    # Truncate to the estimated rank k.\n    lambda_trunc = eigvals[:k]\n    V_trunc = V[:, :k]\n\n    # Step 5: Compute singular values and spatial patterns U.\n    s_trunc = np.sqrt(lambda_trunc)\n    \n    # U = X_anom @ V_trunc @ inv(diag(s_trunc))\n    # This is numerically better and more efficient:\n    U = (X_anom @ V_trunc) / s_trunc\n    \n    return U, lambda_trunc, V_trunc, s_trunc, k\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        {'case': 1, 'N': 120, 'T': 50, 'seed': 0, 'tau': 1e-10},\n        {'case': 2, 'N': 40, 'T': 80, 'seed': 1, 'tau': 1e-10},\n        {'case': 3, 'N': 90, 'T': 70, 'r': 15, 'seed': 2, 'tau': 1e-10},\n        {'case': 4, 'N': 60, 'T': 60, 'seed': 3, 'tau': 1e-10},\n        {'case': 5, 'N': 50, 'T': 5, 'seed': 4, 'tau': 1e-10},\n    ]\n    \n    results = []\n\n    for params in test_cases:\n        case_id = params['case']\n        np.random.seed(params['seed'])\n        \n        if case_id == 1:\n            N, T, tau = params['N'], params['T'], params['tau']\n            X = np.random.standard_normal(size=(N, T))\n            X_anom = X - X.mean(axis=1, keepdims=True)\n            \n            U, _, V, S, _ = compute_eofs_snapshots(X, tau)\n            \n            X_hat = U @ np.diag(S) @ V.T\n            \n            norm_X_anom = np.linalg.norm(X_anom, 'fro')\n            error = np.linalg.norm(X_anom - X_hat, 'fro') / norm_X_anom if norm_X_anom  0 else 0.0\n            results.append(error)\n\n        elif case_id == 2:\n            N, T, tau = params['N'], params['T'], params['tau']\n            X = np.random.standard_normal(size=(N, T))\n            X_anom = X - X.mean(axis=1, keepdims=True)\n            \n            _, _, _, s_snap, k = compute_eofs_snapshots(X, tau)\n            \n            _, s_svd, _ = scipy.linalg.svd(X_anom, full_matrices=False)\n            \n            s_svd_trunc = s_svd[:k]\n            \n            norm_s_svd = np.linalg.norm(s_svd_trunc)\n            error = np.linalg.norm(s_snap - s_svd_trunc) / norm_s_svd if norm_s_svd  0 else 0.0\n            results.append(error)\n\n        elif case_id == 3:\n            N, T, r, tau = params['N'], params['T'], params['r'], params['tau']\n            A = np.random.standard_normal(size=(N, r))\n            B = np.random.standard_normal(size=(r, T))\n            # Construct X to have zero temporal mean\n            B_centered = B - B.mean(axis=1, keepdims=True)\n            X = A @ B_centered\n            \n            _, _, _, _, rank_est = compute_eofs_snapshots(X, tau)\n            \n            # Theoretical rank is min(r, T-1) since rank(X_anom=X) = min(rank(A@B_centered), T-1)\n            # and rank(A@B_centered) = min(rank(A), rank(B_centered)) = r\n            theoretical_rank = min(r, T - 1)\n            diff = abs(rank_est - theoretical_rank)\n            results.append(diff)\n            \n        elif case_id == 4:\n            N, T, tau = params['N'], params['T'], params['tau']\n            X = np.random.standard_normal(size=(N, T))\n            \n            U, _, _, _, k = compute_eofs_snapshots(X, tau)\n            \n            if k == 0:\n                error = 0.0\n            else:\n                I_k = np.identity(k)\n                error = np.linalg.norm(U.T @ U - I_k, 'fro')\n            results.append(error)\n\n        elif case_id == 5:\n            N, T, tau = params['N'], params['T'], params['tau']\n            X = np.random.standard_normal(size=(N, T))\n            X_anom = X - X.mean(axis=1, keepdims=True)\n\n            U, _, V, S, k = compute_eofs_snapshots(X, tau)\n            \n            if k == 0:\n                X_hat = np.zeros_like(X_anom)\n            else:\n                X_hat = U @ np.diag(S) @ V.T\n            \n            norm_X_anom = np.linalg.norm(X_anom, 'fro')\n            error = np.linalg.norm(X_anom - X_hat, 'fro') / norm_X_anom if norm_X_anom  0 else 0.0\n            results.append(error)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}