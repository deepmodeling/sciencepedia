{
    "hands_on_practices": [
        {
            "introduction": "The Ornstein-Uhlenbeck process is a cornerstone model in statistical physics, representing the simplest case of a system with linear relaxation (dissipation) and stochastic forcing. This exercise  guides you through deriving the stationary variance of a tracer anomaly governed by this process. The result crystallizes the fluctuation-dissipation relationship, a fundamental concept in ocean modeling where the equilibrium variability of a resolved field is determined by the balance between deterministic damping and the energy injected by unresolved sub-grid scale processes.",
            "id": "3811642",
            "problem": "Consider a nondimensional resolved tracer anomaly $X(t)$ at a fixed location in the ocean mixed layer, obtained by normalizing a physical tracer by a characteristic variability scale. The large-scale tendency of this anomaly arises from deterministic relaxation toward the climatological state at rate $\\lambda>0$ and unresolved sub-grid scale flux divergences that are represented as a temporally uncorrelated stochastic process. Under a stochastic parameterization, model $X(t)$ as the solution of the one-dimensional Stochastic Differential Equation (SDE)\n$$\ndX(t) = -\\lambda\\,X(t)\\,dt + \\sigma\\,dW_t,\n$$\nwhere $W_t$ is a standard Wiener process (Brownian motion), $\\lambda>0$ is the effective linear relaxation rate encapsulating mean-advection and diffusion, and $\\sigma\\ge 0$ is the amplitude of the unresolved stochastic forcing. Assume the process admits a stationary distribution.\n\nStarting from the fundamental properties of Wiener increments and the definition of stationarity for moments, derive the stationary variance of $X(t)$ as a closed-form analytic expression in terms of $\\lambda$ and $\\sigma$ only. Then, explain how this variance quantifies equilibrium fluctuations of the resolved tracer under stochastic forcing and how the balance between $\\lambda$ and $\\sigma$ embodies a fluctuation-dissipation relationship in computational oceanography, where dissipation represents deterministic relaxation and fluctuations originate from unresolved processes.\n\nYour final answer must be a single closed-form analytic expression. No numerical evaluation is required, and because $X$ is nondimensional, the variance is nondimensional as well.",
            "solution": "The problem requires the derivation of the stationary variance of a tracer anomaly $X(t)$ governed by the Ornstein-Uhlenbeck stochastic differential equation (SDE), followed by a physical interpretation. The SDE is given by:\n$$\ndX(t) = -\\lambda\\,X(t)\\,dt + \\sigma\\,dW_t\n$$\nHere, $X(t)$ is the nondimensional tracer anomaly, $\\lambda > 0$ is the relaxation rate, $\\sigma \\ge 0$ is the stochastic forcing amplitude, and $W_t$ is a standard Wiener process. We assume the process $X(t)$ admits a stationary distribution, which implies that its statistical moments, such as the mean and variance, are constant in time.\n\nFirst, we determine the stationary mean of the process, $E[X]_{stat}$. We take the expectation of the SDE:\n$$\nE[dX(t)] = E[-\\lambda\\,X(t)\\,dt + \\sigma\\,dW_t]\n$$\nUsing the linearity of the expectation operator, we have:\n$$\ndE[X(t)] = -\\lambda\\,E[X(t)]\\,dt + \\sigma\\,E[dW_t]\n$$\nA fundamental property of the standard Wiener process is that its increments have zero mean, so $E[dW_t] = 0$. This simplifies the equation for the mean, $m_1(t) = E[X(t)]$, to a simple ordinary differential equation (ODE):\n$$\n\\frac{d m_1(t)}{dt} = -\\lambda\\,m_1(t)\n$$\nThe solution to this ODE is $m_1(t) = m_1(0)\\,\\exp(-\\lambda t)$, where $m_1(0)$ is the initial mean. Since $\\lambda > 0$, as $t \\to \\infty$, the mean decays to zero. Therefore, in the stationary state, the mean of the process is zero:\n$$\nE[X]_{stat} = 0\n$$\n\nNext, we derive the stationary second moment, $E[X^2]_{stat}$. We use Itô's lemma for the function $f(X) = X^2$. Itô's lemma states that for a function $f(X_t)$ of an Itô process $X_t$, its differential is:\n$$\ndf(X_t) = f'(X_t)\\,dX_t + \\frac{1}{2}f''(X_t)\\,(dX_t)^2\n$$\nFor $f(X) = X^2$, the derivatives are $f'(X) = 2X$ and $f''(X) = 2$. We also need the quadratic variation term $(dX_t)^2$. Using the rules of Itô calculus ($dt \\cdot dt = 0$, $dt \\cdot dW_t = 0$, and $dW_t \\cdot dW_t = dt$):\n$$\n(dX_t)^2 = (-\\lambda\\,X_t\\,dt + \\sigma\\,dW_t)^2 = (-\\lambda\\,X_t\\,dt)^2 + 2(-\\lambda\\,X_t\\,dt)(\\sigma\\,dW_t) + (\\sigma\\,dW_t)^2 = \\sigma^2\\,dt\n$$\nSubstituting these into Itô's lemma:\n$$\nd(X^2) = (2X)dX_t + \\frac{1}{2}(2)(dX_t)^2\n$$\n$$\nd(X^2) = 2X(-\\lambda\\,X\\,dt + \\sigma\\,dW_t) + \\sigma^2\\,dt\n$$\n$$\nd(X^2) = -2\\lambda\\,X^2\\,dt + 2\\sigma\\,X\\,dW_t + \\sigma^2\\,dt\n$$\nNow, we take the expectation of this expression to find the dynamics of the second moment, $m_2(t) = E[X(t)^2]$:\n$$\ndE[X^2] = E[-2\\lambda\\,X^2\\,dt + 2\\sigma\\,X\\,dW_t + \\sigma^2\\,dt]\n$$\n$$\ndE[X^2] = -2\\lambda\\,E[X^2]\\,dt + 2\\sigma\\,E[X\\,dW_t] + \\sigma^2\\,dt\n$$\nThe term $E[X\\,dW_t]$ is the expectation of an Itô integral, which is zero. This leaves us with an ODE for the second moment $m_2(t)$:\n$$\n\\frac{d m_2(t)}{dt} = -2\\lambda\\,m_2(t) + \\sigma^2\n$$\nIn the stationary state, the moments are time-invariant, so $\\frac{d m_2}{dt} = 0$. We denote the stationary second moment as $m_2^{stat}$:\n$$\n0 = -2\\lambda\\,m_2^{stat} + \\sigma^2\n$$\nSolving for $m_2^{stat}$ gives:\n$$\nm_2^{stat} = E[X^2]_{stat} = \\frac{\\sigma^2}{2\\lambda}\n$$\nThe variance of $X(t)$, denoted $\\text{Var}(X)$, is defined as $\\text{Var}(X) = E[X^2] - (E[X])^2$. In the stationary state:\n$$\n\\text{Var}(X)_{stat} = E[X^2]_{stat} - (E[X]_{stat})^2 = \\frac{\\sigma^2}{2\\lambda} - 0^2\n$$\nThus, the stationary variance is:\n$$\n\\text{Var}(X)_{stat} = \\frac{\\sigma^2}{2\\lambda}\n$$\n\nThe physical interpretation of this result is as follows. The stationary variance, $\\text{Var}(X)_{stat}$, quantifies the magnitude of equilibrium fluctuations of the resolved tracer anomaly $X(t)$ around its climatological mean state, which is zero. It represents the characteristic squared amplitude of the deviations from the mean that persist in a statistical steady state. This steady state arises from a balance between the continuous injection of energy at resolved scales by unresolved processes and the dissipation of this energy by resolved-scale dynamics.\n\nThis balance embodies a fluctuation-dissipation relationship.\n1.  **Fluctuations:** The term $\\sigma\\,dW_t$ represents the stochastic forcing from unresolved, sub-grid scale processes. The parameter $\\sigma^2$ is the variance of this white noise forcing per unit time and thus represents the rate at which variance is injected into the resolved system. It is the direct measure of the strength of the \"fluctuations\".\n2.  **Dissipation:** The term $-\\lambda X(t) dt$ represents a deterministic relaxation or damping process that pulls the tracer anomaly back towards its mean of zero. This term models the effects of processes like mean advection and diffusion that act to smooth out and \"dissipate\" anomalies. The parameter $\\lambda$ is the rate of this dissipation; a larger $\\lambda$ implies faster damping.\n\nThe derived expression for the stationary variance, $\\text{Var}(X)_{stat} = \\frac{\\sigma^2}{2\\lambda}$, explicitly shows this relationship. The equilibrium variance of the resolved tracer is directly proportional to the strength of the unresolved stochastic forcing ($\\sigma^2$) and inversely proportional to the efficiency of the resolved dissipative processes ($\\lambda$). This means that a system subjected to strong random kicks ($\\sigma^2$ is large) but with weak self-damping ($\\lambda$ is small) will exhibit large equilibrium fluctuations. Conversely, a system with strong damping can maintain small fluctuations even in the presence of significant random forcing. In the context of computational oceanography, this relationship is fundamental: the variance of the resolved fields, a key diagnostic of model climate variability, is determined by the interplay between the stochastic parameterization of sub-grid physics (the fluctuation source) and the model's inherent dissipative characteristics.",
            "answer": "$$\n\\boxed{\\frac{\\sigma^{2}}{2\\lambda}}\n$$"
        },
        {
            "introduction": "Building physically consistent models requires ensuring that fundamental principles, such as conservation of energy or enstrophy, are respected. When stochastic forcing is introduced, these quantities may no longer be conserved pathwise, but we can demand their conservation in expectation. This practice  explores this crucial design principle by tasking you to find the specific form of the deterministic drift, $a(X)$, required to counteract the systematic energy injection from multiplicative noise, $b(X)$, thereby maintaining a statistical conservation law.",
            "id": "3811630",
            "problem": "Consider a one-dimensional coarse-grained resolved variable $X(t)$ representing a large-scale prognostic state (e.g., a local streamfunction amplitude or potential vorticity anomaly) in a computational oceanography model in which sub-grid scale (SGS) effects are parameterized stochastically. Assume that $X(t)$ evolves according to a Itō-type Stochastic Differential Equation (SDE) of the form $dX = a(X)\\,dt + b(X)\\,dW$, where $a(X)$ is a deterministic drift induced by SGS processes, $b(X)$ is a state-dependent stochastic amplitude encapsulating unresolved variability, and $W(t)$ is a standard Brownian Motion (BM). A physically relevant quadratic invariant for many geophysical flows is $I(X) = X^{2}/2$, which mirrors energy or enstrophy-like quantities in appropriate scalings.\n\nStarting from the definition of an Itō SDE and the rules of Itō calculus, derive the stochastic differential $dI$ for $I(X) = X^{2}/2$ under the given dynamics and identify the drift component of $dI$. Then, by taking expectations and using the canonical properties of Itō integrals, determine the condition on $(a,b)$ under which $I$ remains conserved in expectation, meaning $\\frac{d}{dt}\\,\\mathbb{E}[I(X(t))] = 0$ for all times. You should reason from first principles, explicitly applying Itō calculus and expectation properties rather than invoking shortcut results.\n\nExpress your final answer as a two-entry row vector containing:\n1. The drift term of $dI$ as a function of $X$, $a(X)$, and $b(X)$.\n2. A closed-form expression for $a(X)$, written solely in terms of $X$ and $b(X)$, that ensures conservation of $I$ in expectation for all times.\n\nNo numerical evaluation is required. Provide no units. If any domain restriction is needed for your expression, infer it rigorously from your derivation and state it in your solution, but the final answer itself must remain a pair of analytic expressions without additional text.",
            "solution": "The problem asks for the condition on the drift $a(X)$ and diffusion $b(X)$ of the SDE $dX = a(X)\\,dt + b(X)\\,dW$ such that the quadratic invariant $I(X) = X^2/2$ is conserved in expectation. Conservation in expectation means $\\frac{d}{dt}\\mathbb{E}[I(X(t))] = 0$.\n\nWe begin by finding the stochastic differential $dI$ using Itô's lemma. For a function $f(X_t)$ of an Itô process, the lemma states:\n$$\ndf(X_t) = f'(X_t)\\,dX_t + \\frac{1}{2}f''(X_t)\\,(dX_t)^2\n$$\nFor our invariant $I(X) = X^2/2$, the first and second derivatives are:\n$$\nI'(X) = \\frac{d}{dX}\\left(\\frac{X^2}{2}\\right) = X\n$$\n$$\nI''(X) = \\frac{d^2}{dX^2}\\left(\\frac{X^2}{2}\\right) = 1\n$$\nThe quadratic variation term $(dX_t)^2$ is found using the rules of Itô calculus ($dt^2 = 0$, $dt \\cdot dW = 0$, $dW^2 = dt$):\n$$\n(dX_t)^2 = (a(X)\\,dt + b(X)\\,dW_t)^2 = a(X)^2\\,dt^2 + 2a(X)b(X)\\,dt\\,dW_t + b(X)^2\\,dW_t^2 = b(X)^2\\,dt\n$$\nSubstituting these components into Itô's lemma:\n$$\ndI = (X)(a(X)\\,dt + b(X)\\,dW_t) + \\frac{1}{2}(1)(b(X)^2\\,dt)\n$$\nWe can group the terms by $dt$ and $dW_t$ to get the SDE for $I(t)$:\n$$\ndI = \\left( X a(X) + \\frac{1}{2} b(X)^2 \\right) dt + X b(X) dW_t\n$$\nThe first part of the problem asks for the drift term of $dI$. From the equation above, this is:\n$$\n\\text{Drift}(dI) = X a(X) + \\frac{1}{2} b(X)^2\n$$\n\nNext, to find the condition for conservation in expectation, we take the expectation of the SDE for $I(t)$:\n$$\n\\mathbb{E}[dI] = \\mathbb{E}\\left[ \\left( X a(X) + \\frac{1}{2} b(X)^2 \\right) dt + X b(X) dW_t \\right]\n$$\nUsing the linearity of expectation and the fact that the expectation of an Itô integral is zero ($\\mathbb{E}[ \\int_0^t g(s) dW_s ] = 0$), we get:\n$$\nd\\mathbb{E}[I] = \\mathbb{E}\\left[ X a(X) + \\frac{1}{2} b(X)^2 \\right] dt\n$$\nSo, the time evolution of the expected value of the invariant is:\n$$\n\\frac{d}{dt}\\mathbb{E}[I(t)] = \\mathbb{E}\\left[ X a(X) + \\frac{1}{2} b(X)^2 \\right]\n$$\nFor $I$ to be conserved in expectation for all times, we must have $\\frac{d}{dt}\\mathbb{E}[I(t)] = 0$. This implies:\n$$\n\\mathbb{E}\\left[ X a(X) + \\frac{1}{2} b(X)^2 \\right] = 0\n$$\nFor this condition to hold for any probability distribution of $X$ at any time $t$, the term inside the expectation must be identically zero for all possible values of $X$. Thus, we set the drift term of $dI$ to zero:\n$$\nX a(X) + \\frac{1}{2} b(X)^2 = 0\n$$\nSolving for $a(X)$, we find the required form of the deterministic drift. This is the second part of the answer:\n$$\na(X) = -\\frac{b(X)^2}{2X}\n$$\nThis expression is valid for all $X$ in the domain of the process where $X \\neq 0$. If the process can reach $X=0$, this form of the drift is singular, which implies that either $b(0)$ must be zero or a different physical constraint applies at that point.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nX a(X) + \\frac{1}{2} b(X)^2 & -\\frac{b(X)^2}{2X}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Translating a theoretical stochastic model into a robust numerical algorithm presents unique challenges not found in deterministic modeling. A primary issue is enforcing physical bounds on state variables, such as the non-negativity of a tracer concentration, which can be violated by discrete stochastic steps. This hands-on coding exercise  requires you to implement a physically consistent reflection method for boundary conditions, contrasting it with naive and incorrect clipping methods, and thus ensuring your numerical simulation remains stable and physically meaningful.",
            "id": "3811634",
            "problem": "You are tasked with designing and implementing a numerically stable and physically consistent method to enforce boundedness of tracer concentrations when adding stochastic fluxes in a one-dimensional model column. The unresolved sub-grid effects are represented by a Stochastic Differential Equation (SDE; Stochastic Differential Equation), and the concentration is constrained to lie in a closed interval. The requirement is to implement reflecting boundary conditions for the SDE so that the concentration remains within specified bounds without introducing artificial sinks or sources at the boundaries.\n\nStarting point and fundamental base: consider a scalar tracer concentration $C$ that evolves according to a conservation law with deterministic flux and source terms plus unresolved stochastic small-scale fluxes aggregated into a stochastic term. In a one-dimensional framework (a model column at fixed depth or a box model in concentration space), the unresolved processes are represented by an Itô SDE\n$$\n\\mathrm{d}C = a(C,t)\\,\\mathrm{d}t + b(C,t)\\,\\mathrm{d}W_t,\n$$\nwhere $a(C,t)$ is a drift (deterministic tendency per unit time), $b(C,t)$ is a diffusion amplitude (noise intensity), and $W_t$ is a standard Wiener process. The probability density $p(c,t)$ of $C$ obeys the Fokker–Planck Equation (FPE; Fokker–Planck Equation),\n$$\n\\frac{\\partial p}{\\partial t} = -\\frac{\\partial}{\\partial c}\\big(a(c,t)\\,p(c,t)\\big) + \\frac{1}{2}\\frac{\\partial^2}{\\partial c^2}\\big(b^2(c,t)\\,p(c,t)\\big),\n$$\nand the probability current (flux in concentration space) is\n$$\nJ(c,t) = a(c,t)\\,p(c,t) - \\frac{1}{2}\\frac{\\partial}{\\partial c}\\big(b^2(c,t)\\,p(c,t)\\big).\n$$\nReflecting boundary conditions at a lower bound $C_{\\min}$ and an upper bound $C_{\\max}$ impose zero probability current at the boundaries,\n$$\nJ(C_{\\min},t)=0,\\qquad J(C_{\\max},t)=0,\n$$\nwhich corresponds physically to no probability leakage of $C$ through the bounds. Numerically, you must derive from these principles a method that enforces these reflecting boundary conditions in the discrete Euler–Maruyama scheme without biasing the distribution (for example, without artificially clipping, which would create an absorbing-like behavior and distort $p(c,t)$ near the boundaries).\n\nYour task:\n1. Derive, from the above fundamental base, a correct and efficient discrete-time algorithm that integrates the SDE using the Euler–Maruyama method with time step $\\Delta t$ and then enforces reflecting boundary conditions over the interval $[C_{\\min},C_{\\max}]$ after each step in a way consistent with zero probability current at the boundaries.\n2. Implement the algorithm in a program that runs multiple independent realizations (Monte Carlo ensemble), supports both additive and multiplicative noise models, and returns diagnostic quantities for a test suite.\n3. Use a fixed random seed $42$ for reproducibility.\n4. Treat the concentration $C$ as nondimensional, i.e., all quantities are unitless; no physical units are to be reported.\n\nDiscretization requirement:\n- Use the Euler–Maruyama step to compute a tentative update\n$$\nC_{n+1}^{\\text{raw}} = C_n + a(C_n,t_n)\\,\\Delta t + b(C_n,t_n)\\,\\sqrt{\\Delta t}\\,\\xi_n,\n$$\nwhere $\\xi_n \\sim \\mathcal{N}(0,1)$ are independent standard normal random variables across realizations and time steps.\n- Enforce reflecting boundary conditions by a mathematically justified transformation that maps $C_{n+1}^{\\text{raw}}$ into $[C_{\\min},C_{\\max}]$ while preserving the stochastic symmetry of the increments relative to the boundaries.\n\nDiagnostics to compute per test case:\n- A boolean indicating whether all post-reflection concentrations stayed within $[C_{\\min},C_{\\max}]$ for the entire simulation time.\n- The ensemble mean of the final concentrations $C_T$ across realizations.\n- The ensemble variance of the final concentrations $C_T$ across realizations.\n- The fraction, as a decimal, of attempted steps that would have violated the bounds before reflection,\n$$\n\\text{hit fraction} = \\frac{\\text{number of indices with }C_{n+1}^{\\text{raw}} \\notin [C_{\\min},C_{\\max}] }{\\text{total number of indices over all realizations and steps}}.\n$$\n\nTest suite:\nImplement the following four cases. In all cases, the concentration bounds are $[C_{\\min},C_{\\max}]=[0,1]$, and the number of realizations is $N=1000$.\n\n- Case 1 (happy path, moderate additive noise with restoring drift): Initial condition $C_0=0.5$, time step $\\Delta t=0.005$, number of steps $N_{\\text{steps}}=1000$, drift $a(C,t)=k\\,(C_{\\text{eq}}-C)$ with $k=0.5$ and $C_{\\text{eq}}=0.6$, diffusion $b(C,t)=\\sigma$ with $\\sigma=0.2$.\n- Case 2 (strong additive noise, zero drift, frequent boundary hits): Initial condition $C_0=0.5$, $\\Delta t=0.005$, $N_{\\text{steps}}=1000$, drift $a(C,t)=0$, diffusion $b(C,t)=\\sigma$ with $\\sigma=1.5$.\n- Case 3 (deterministic drift driving towards the upper bound, zero noise): Initial condition $C_0=0.2$, $\\Delta t=0.01$, $N_{\\text{steps}}=80$, drift $a(C,t)=\\theta$ with $\\theta=1.0$, diffusion $b(C,t)=0$.\n- Case 4 (multiplicative noise vanishing at the boundaries): Initial condition $C_0=0.5$, $\\Delta t=0.005$, $N_{\\text{steps}}=1000$, drift $a(C,t)=0$, diffusion $b(C,t)=\\sigma\\sqrt{C\\,(1-C)}$ with $\\sigma=1.0$.\n\nRequired final output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to one test case and is itself a list containing the diagnostics in the order specified above. For example, the output should look like\n$$\n[\\,[\\text{bool}_1,\\text{mean}_1,\\text{var}_1,\\text{frac}_1],\\,[\\text{bool}_2,\\text{mean}_2,\\text{var}_2,\\text{frac}_2],\\,[\\text{bool}_3,\\text{mean}_3,\\text{var}_3,\\text{frac}_3],\\,[\\text{bool}_4,\\text{mean}_4,\\text{var}_4,\\text{frac}_4]\\,].\n$$",
            "solution": "The problem requires the design and implementation of a numerical algorithm to solve a one-dimensional Itô Stochastic Differential Equation (SDE) for a tracer concentration $C$, subject to reflecting boundary conditions. The concentration is constrained to the closed interval $[C_{\\min}, C_{\\max}]$.\n\nThe evolution of the tracer concentration $C$ is governed by the SDE:\n$$\n\\mathrm{d}C = a(C,t)\\,\\mathrm{d}t + b(C,t)\\,\\mathrm{d}W_t\n$$\nwhere $a(C,t)$ is the drift coefficient, $b(C,t)$ is the diffusion coefficient, and $W_t$ represents a standard Wiener process. The physical constraint that the concentration must remain within the bounds $[C_{\\min}, C_{\\max}]$ is mathematically formulated as a zero-flux condition for the probability current $J(c,t)$ at the boundaries, as derived from the corresponding Fokker-Planck Equation:\n$$\nJ(c,t) = a(c,t)\\,p(c,t) - \\frac{1}{2}\\frac{\\partial}{\\partial c}\\big(b^2(c,t)\\,p(c,t)\\big)\n$$\nThe reflecting boundary conditions are $J(C_{\\min},t)=0$ and $J(C_{\\max},t)=0$. These conditions ensure that the total probability of finding the tracer within the domain is conserved, i.e., $\\int_{C_{\\min}}^{C_{\\max}} p(c,t) \\mathrm{d}c = 1$ for all time $t$, by preventing any leakage of probability density across the boundaries.\n\nThe task is to discretize this system using the Euler–Maruyama method and to enforce the reflecting boundaries in a manner consistent with the zero-flux condition.\n\nA single step of the Euler–Maruyama scheme with time step $\\Delta t$ provides a tentative, or \"raw,\" update for the concentration from time $t_n$ to $t_{n+1}$:\n$$\nC_{n+1}^{\\text{raw}} = C_n + a(C_n,t_n)\\,\\Delta t + b(C_n,t_n)\\,\\sqrt{\\Delta t}\\,\\xi_n\n$$\nwhere $\\xi_n$ is a random variable drawn from a standard normal distribution, $\\mathcal{N}(0,1)$. Due to the stochastic term, $C_{n+1}^{\\text{raw}}$ may fall outside the prescribed interval $[C_{\\min}, C_{\\max}]$, violating the physical constraint. A naive \"clipping\" approach, such as setting $C_{n+1} = \\max(C_{\\min}, \\min(C_{\\max}, C_{n+1}^{\\text{raw}}))$, is incorrect. This would correspond to an absorbing boundary condition, creating an artificial sink of probability at the boundaries and leading to a spurious accumulation of tracer concentration density, thus distorting the stationary probability distribution $p(c,t)$.\n\nThe correct approach is based on a \"reflection\" principle. If a stochastic path attempts to cross a boundary, it must be reflected back into the domain. Consider a provisional value $C_{n+1}^{\\text{raw}}$ that undershoots the lower boundary $C_{\\min}$ by a distance $\\delta_l = C_{\\min} - C_{n+1}^{\\text{raw}}$. The reflection principle dictates that the final value $C_{n+1}$ should be placed inside the domain at the same distance $\\delta_l$ from the boundary.\n$$\nC_{n+1} = C_{\\min} + \\delta_l = C_{\\min} + (C_{\\min} - C_{n+1}^{\\text{raw}}) = 2C_{\\min} - C_{n+1}^{\\text{raw}}\n$$\nSimilarly, if $C_{n+1}^{\\text{raw}}$ overshoots the upper boundary $C_{\\max}$ by a distance $\\delta_u = C_{n+1}^{\\text{raw}} - C_{\\max}$, the reflected value is:\n$$\nC_{n+1} = C_{\\max} - \\delta_u = C_{\\max} - (C_{n+1}^{\\text{raw}} - C_{\\max}) = 2C_{\\max} - C_{n+1}^{\\text{raw}}\n$$\nThis procedure ensures that the magnitude of the displacement relative to the wall is conserved, maintaining the statistical properties of the random walk near the boundary.\n\nFor a sufficiently large time step $\\Delta t$ or noise amplitude $b$, it is possible for a reflected value to fall outside the opposite boundary. For instance, a particle starting near $C_{\\min}$ might receive a large negative stochastic kick, resulting in a $C_{n+1}^{\\text{raw}}$ far below $C_{\\min}$. The reflection $2C_{\\min} - C_{n+1}^{\\text{raw}}$ could then be larger than $C_{\\max}$. This necessitates an iterative application of the reflection principle, effectively \"folding\" the path back into the domain until the final value $C_{n+1}$ lies within $[C_{\\min}, C_{\\max}]$. The algorithm for a single time step is as follows:\n\n1.  Calculate the raw value $C_{n+1}^{\\text{raw}}$.\n2.  Initialize the corrected value $C_{n+1} \\leftarrow C_{n+1}^{\\text{raw}}$.\n3.  While $C_{n+1} < C_{\\min}$ or $C_{n+1} > C_{\\max}$:\n    a. If $C_{n+1} < C_{\\min}$, update: $C_{n+1} \\leftarrow 2C_{\\min} - C_{n+1}$.\n    b. If $C_{n+1} > C_{\\max}$, update: $C_{n+1} \\leftarrow 2C_{\\max} - C_{n+1}$.\n4.  The loop terminates when $C_ {n+1}$ is in $[C_{\\min}, C_{\\max}]$, which is guaranteed for a finite step.\n\nThis algorithm will be implemented for an ensemble of $N=1000$ realizations for four distinct test cases. All quantities are nondimensional, the domain is $[0, 1]$, and a fixed random seed of $42$ is used for reproducibility.\n\nThe test cases are:\n-   **Case $1$:** Moderate additive noise with a linear drift term $a(C,t)=k(C_{\\text{eq}}-C)$ where $k=0.5$ and $C_{\\text{eq}}=0.6$. The process is an Ornstein-Uhlenbeck process, which will fluctuate around the equilibrium $C_{\\text{eq}}=0.6$. Boundary interactions are expected to be infrequent.\n-   **Case $2$:** Strong additive noise with zero drift, $a(C,t)=0$. This is a reflected Brownian motion. The strong noise ($b(C,t) = \\sigma = 1.5$) will cause frequent boundary hits. The long-term probability distribution is uniform over $[0,1]$.\n-   **Case $3$:** A purely deterministic case with $b(C,t)=0$ and a constant positive drift $a(C,t)=1.0$. Starting from $C_0=0.2$, the trajectory is $C(t) = 0.2+t$. The simulation time $T=N_{\\text{steps}}\\Delta t = 80 \\times 0.01 = 0.8$. The final concentration will be $C(0.8)=1.0$, which lies on the boundary but does not cross it. No reflections should occur.\n-   **Case $4$:** Multiplicative noise with $b(C,t) = \\sigma\\sqrt{C(1-C)}$ and zero drift. The diffusion coefficient vanishes at the boundaries $C=0$ and $C=1$. While in the continuous limit the boundaries are unattainable, the discrete Euler-Maruyama scheme can still produce overshoots, necessitating a reflection mechanism for numerical stability. The number of such events is expected to be small.\n\nFor each case, we will compute four diagnostics: a boolean for path containment, the ensemble mean and variance of the final concentration, and the fraction of numerical steps that required reflection. The containment boolean is expected to be `True` for all cases, confirming the correctness of the reflection algorithm.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation suite and print results.\n    \"\"\"\n\n    def run_simulation(C0, dt, n_steps, a_func, b_func, C_min, C_max, N, rng):\n        \"\"\"\n        Runs a single Monte Carlo simulation for a given SDE and parameters.\n        \n        Args:\n            C0 (float): Initial concentration.\n            dt (float): Time step.\n            n_steps (int): Number of time steps.\n            a_func (callable): Drift function a(C).\n            b_func (callable): Diffusion function b(C).\n            C_min (float): Lower bound.\n            C_max (float): Upper bound.\n            N (int): Number of realizations.\n            rng (numpy.random.Generator): Random number generator.\n            \n        Returns:\n            list: A list containing the four required diagnostics.\n        \"\"\"\n        \n        # Initialize array to store all concentration paths\n        C_paths = np.zeros((N, n_steps + 1))\n        C_paths[:, 0] = C0\n        \n        hit_count = 0\n        \n        # Time-stepping loop\n        for n in range(n_steps):\n            C_n = C_paths[:, n]\n            \n            # Generate N standard normal random variables\n            xi_n = rng.normal(size=N)\n            \n            # Calculate raw Euler-Maruyama step\n            drift_term = a_func(C_n) * dt\n            diffusion_term = b_func(C_n) * np.sqrt(dt) * xi_n\n            C_raw = C_n + drift_term + diffusion_term\n            \n            # Count steps that would violate bounds\n            hit_mask = (C_raw  C_min) | (C_raw > C_max)\n            hit_count += np.sum(hit_mask)\n            \n            # Apply reflecting boundary conditions iteratively\n            C_next = C_raw.copy()\n            \n            is_out = (C_next  C_min) | (C_next > C_max)\n            while np.any(is_out):\n                # Reflect values below the lower bound\n                low_mask = C_next  C_min\n                C_next[low_mask] = 2 * C_min - C_next[low_mask]\n                \n                # Reflect values above the upper bound\n                high_mask = C_next > C_max\n                C_next[high_mask] = 2 * C_max - C_next[high_mask]\n                \n                # Check again if any values are out of bounds\n                is_out = (C_next  C_min) | (C_next > C_max)\n                \n            C_paths[:, n + 1] = C_next\n\n        # Compute diagnostics\n        \n        # 1. Boolean for boundedness\n        all_in_bounds = np.all((C_paths >= C_min)  (C_paths = C_max))\n        \n        # 2. Ensemble mean of final concentrations\n        C_T = C_paths[:, -1]\n        mean_T = np.mean(C_T)\n        \n        # 3. Ensemble variance of final concentrations\n        var_T = np.var(C_T)\n        \n        # 4. Fraction of hits\n        total_indices = N * n_steps\n        hit_fraction = hit_count / total_indices if total_indices > 0 else 0.0\n\n        return [all_in_bounds, mean_T, var_T, hit_fraction]\n\n    # Common parameters\n    C_min, C_max = 0.0, 1.0\n    N = 1000\n    \n    # Test suite definition\n    test_cases = [\n        # Case 1: Happy path\n        {'C0': 0.5, 'dt': 0.005, 'n_steps': 1000, \n         'a': lambda C: 0.5 * (0.6 - C), 'b': lambda C: 0.2*np.ones_like(C)},\n        \n        # Case 2: Strong additive noise\n        {'C0': 0.5, 'dt': 0.005, 'n_steps': 1000, \n         'a': lambda C: 0.0, 'b': lambda C: 1.5*np.ones_like(C)},\n\n        # Case 3: Deterministic drift\n        {'C0': 0.2, 'dt': 0.01, 'n_steps': 80, \n         'a': lambda C: 1.0, 'b': lambda C: 0.0},\n\n        # Case 4: Multiplicative noise\n        {'C0': 0.5, 'dt': 0.005, 'n_steps': 1000, \n         'a': lambda C: 0.0, 'b': lambda C: 1.0 * np.sqrt(np.maximum(0, C * (1.0 - C)))},\n    ]\n\n    # Use a single RNG for reproducibility across all cases\n    rng = np.random.default_rng(42)\n    \n    results = []\n    # A small adjustment in case 4 to prevent domain errors with sqrt for values barely outside [0,1] due to float precision\n    test_cases[3]['b'] = lambda C: 1.0 * np.sqrt(np.maximum(0, C * (1.0 - C)))\n    \n    for case in test_cases:\n        case_result = run_simulation(\n            C0=case['C0'], \n            dt=case['dt'], \n            n_steps=case['n_steps'],\n            a_func=case['a'], \n            b_func=case['b'], \n            C_min=C_min, \n            C_max=C_max, \n            N=N,\n            rng=rng\n        )\n        # Convert NumPy boolean to Python boolean for standard string representation\n        case_result[0] = bool(case_result[0])\n        results.append(case_result)\n        \n    # Format the output as a list of lists string representation\n    inner_strs = [f\"[{res[0]},{res[1]},{res[2]},{res[3]}]\" for res in results]\n    final_output = f\"[{','.join(inner_strs)}]\"\n\n    print(final_output.replace('True', 'true').replace('False', 'false'))\n\nsolve()\n```"
        }
    ]
}