{
    "hands_on_practices": [
        {
            "introduction": "The foundation of any reliable *ab initio* molecular dynamics study is a carefully converged set of computational parameters. Because these simulations are computationally demanding, a blind pursuit of the highest possible accuracy is impractical. This exercise guides you through the essential practice of balancing computational cost against numerical precision by systematically determining the plane-wave energy cutoff ($E_{\\text{cut}}$) and Brillouin zone sampling ($k$-point grid). By formalizing the trade-off between cost and error, you will learn to select parameters that meet specific accuracy targets for forces and stress, a critical skill for producing scientifically defensible AIMD results .",
            "id": "3728689",
            "problem": "You are asked to formalize and solve a convergence study design for Ab Initio Molecular Dynamics (AIMD) applied to a liquid High-Entropy Alloy (HEA). The objective is to determine the minimal plane-wave kinetic energy cutoff and the minimal uniform $k$-point grid per direction that bound the force and stress errors across a set of representative atomic snapshots within specified tolerances. Begin from the definitions of discretization error and computational cost, and formulate a selection rule that minimizes cost subject to error constraints. Then implement this selection rule.\n\nDefinitions and assumptions:\n- Ab Initio Molecular Dynamics (AIMD) computes interatomic forces and stress using electronic structure calculations that employ a plane-wave basis with kinetic energy cutoff and $k$-point sampling in reciprocal space. Discretization of the basis and sampling introduces errors in forces and stress.\n- Let there be $N$ representative snapshots indexed by $s \\in \\{1,\\dots,N\\}$. For a given plane-wave kinetic energy cutoff $E_{\\text{cut}}$ (in eV) and a uniform Monkhorst-Pack $k$-point grid size per direction $K$ (dimensionless integer), the force error at snapshot $s$ is modeled as\n$$\n\\mathcal{E}_f^{(s)}(E_{\\text{cut}},K) = A_s \\, E_{\\text{cut}}^{-p} + B_s \\, K^{-q}\n$$\nand the stress error at snapshot $s$ is modeled as\n$$\n\\mathcal{E}_\\sigma^{(s)}(E_{\\text{cut}},K) = C_s \\, E_{\\text{cut}}^{-p_\\sigma} + D_s \\, K^{-q_\\sigma}.\n$$\nHere $A_s$, $B_s$, $C_s$, and $D_s$ are nonnegative coefficients that encode snapshot-dependent sensitivity, and $p$, $q$, $p_\\sigma$, $q_\\sigma$ are positive exponents describing error decay with increasing $E_{\\text{cut}}$ and $K$.\n- The maximal errors across snapshots are\n$$\n\\mathcal{E}_f^{\\max}(E_{\\text{cut}},K) = \\max_{s} \\mathcal{E}_f^{(s)}(E_{\\text{cut}},K), \\quad \\mathcal{E}_\\sigma^{\\max}(E_{\\text{cut}},K) = \\max_{s} \\mathcal{E}_\\sigma^{(s)}(E_{\\text{cut}},K).\n$$\n- The target tolerances are a force error bound $T_f$ and a stress error bound $T_\\sigma$. The convergence feasibility constraints are\n$$\n\\mathcal{E}_f^{\\max}(E_{\\text{cut}},K) \\le T_f, \\quad \\mathcal{E}_\\sigma^{\\max}(E_{\\text{cut}},K) \\le T_\\sigma.\n$$\n- The computational cost model is\n$$\n\\mathcal{C}(E_{\\text{cut}},K) = \\alpha \\, E_{\\text{cut}}^{3/2} + \\beta \\, K^3,\n$$\nwhere $\\alpha$ and $\\beta$ are positive weights reflecting the scaling of the number of plane waves with $E_{\\text{cut}}$ and the number of sampled points with $K$ per direction.\n- Among candidate values $E_{\\text{cut}} \\in \\mathcal{E}$ and $K \\in \\mathcal{K}$, select the pair $(E_{\\text{cut}}^\\star,K^\\star)$ that satisfies the feasibility constraints and minimizes $\\mathcal{C}(E_{\\text{cut}},K)$. If multiple pairs have identical minimal cost, choose the one with smaller $E_{\\text{cut}}$, and if still tied, choose the one with smaller $K$. If no feasible pair exists, return a sentinel output indicating infeasibility.\n\nScientific units and output specification:\n- Express $E_{\\text{cut}}$ in eV and $K$ as an integer per direction. The force error bound $T_f$ is in meV/Å and the stress error bound $T_\\sigma$ is in GPa. There are no angle quantities in this problem.\n- Your program must compute the selection for each test case below and produce a single line of output containing a comma-separated list of per-test-case results, each result formatted as a two-element list $[E_{\\text{cut}},K]$ with $E_{\\text{cut}}$ represented as a decimal (float) and $K$ as an integer, all enclosed in square brackets. For example, the output line must look like $[[400.0,2],[300.0,1],[0.0,0]]$.\n\nTest suite:\n- Test case $1$ (happy path):\n  - $N = 3$ snapshots, coefficients:\n    - Force: $A = [1600,1400,1500]$ (units meV/Å$\\cdot$eV$^p$), $B = [4.0,6.0,5.0]$ (units meV/Å), exponents $p = 1.0$, $q = 2.0$.\n    - Stress: $C = [20.0,16.0,18.0]$ (units GPa$\\cdot$eV$^{p_\\sigma}$), $D = [0.05,0.07,0.06]$ (units GPa), exponents $p_\\sigma = 0.8$, $q_\\sigma = 1.5$.\n  - Tolerances: $T_f = 5.0$ meV/Å, $T_\\sigma = 0.2$ GPa.\n  - Candidates: $\\mathcal{E} = [300,350,400,450,500,600]$ eV, $\\mathcal{K} = [1,2,3,4,5,6]$.\n  - Cost weights: $\\alpha = 1.0$, $\\beta = 0.08$.\n- Test case $2$ (boundary and tie-possibility):\n  - $N = 2$ snapshots, coefficients:\n    - Force: $A = [1200,1200]$, $B = [0.5,0.5]$, exponents $p = 1.0$, $q = 1.0$.\n    - Stress: $C = [10.0,8.0]$, $D = [0.02,0.02]$, exponents $p_\\sigma = 1.0$, $q_\\sigma = 1.0$.\n  - Tolerances: $T_f = 5.0$ meV/Å, $T_\\sigma = 0.2$ GPa.\n  - Candidates: $\\mathcal{E} = [300,350,400,450,500,600]$ eV, $\\mathcal{K} = [1,2,3,4,5,6]$.\n  - Cost weights: $\\alpha = 1.0$, $\\beta = 0.08$.\n- Test case $3$ (edge case infeasible):\n  - $N = 2$ snapshots, coefficients:\n    - Force: $A = [8000,9000]$, $B = [10.0,10.0]$, exponents $p = 1.0$, $q = 2.0$.\n    - Stress: $C = [100.0,120.0]$, $D = [0.10,0.10]$, exponents $p_\\sigma = 1.0$, $q_\\sigma = 1.0$.\n  - Tolerances: $T_f = 5.0$ meV/Å, $T_\\sigma = 0.2$ GPa.\n  - Candidates: $\\mathcal{E} = [300,350,400,450,500,600]$ eV, $\\mathcal{K} = [1,2,3,4,5,6]$.\n  - Cost weights: $\\alpha = 1.0$, $\\beta = 0.08$.\n- Sentinel output rule: If no feasible pair exists, output $[0.0,0]$ for that test case.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each per-test-case result itself being a two-element list $[E_{\\text{cut}},K]$ as specified, for example $[[400.0,2],[300.0,1],[0.0,0]]$.",
            "solution": "The goal is to design and implement a principled selection of the plane-wave kinetic energy cutoff and $k$-point grid per direction that jointly satisfy error tolerances for forces and stress across representative snapshots, while minimizing a model of computational cost. The scientific basis is the behavior of discretization errors in plane-wave electronic structure calculations and Brillouin zone sampling. In a plane-wave basis, the number of basis functions scales with the volume of reciprocal space inside the kinetic energy sphere, which is proportional to $E_{\\text{cut}}^{3/2}$, and in uniform $k$-point sampling, the number of sampled points grows like $K^3$ for a cubic grid of size $K \\times K \\times K$. These scalings motivate the cost model $\\mathcal{C}(E_{\\text{cut}},K) = \\alpha E_{\\text{cut}}^{3/2} + \\beta K^3$. The discretization errors typically decrease monotonically with $E_{\\text{cut}}$ and $K$, and the provided parametric error model captures this decay: $\\mathcal{E}_f^{(s)} = A_s E_{\\text{cut}}^{-p} + B_s K^{-q}$ and $\\mathcal{E}_\\sigma^{(s)} = C_s E_{\\text{cut}}^{-p_\\sigma} + D_s K^{-q_\\sigma}$ with positive exponents.\n\nPrinciple-based algorithm design:\n- Start from the definitions of maximum errors across snapshots,\n$$\n\\mathcal{E}_f^{\\max}(E_{\\text{cut}},K) = \\max_{s} \\left( A_s E_{\\text{cut}}^{-p} + B_s K^{-q} \\right), \\quad\n\\mathcal{E}_\\sigma^{\\max}(E_{\\text{cut}},K) = \\max_{s} \\left( C_s E_{\\text{cut}}^{-p_\\sigma} + D_s K^{-q_\\sigma} \\right).\n$$\n- The feasibility region in $(E_{\\text{cut}},K)$ is the set where $\\mathcal{E}_f^{\\max}(E_{\\text{cut}},K) \\le T_f$ and $\\mathcal{E}_\\sigma^{\\max}(E_{\\text{cut}},K) \\le T_\\sigma$ simultaneously.\n- Among discrete candidates $E_{\\text{cut}} \\in \\mathcal{E}$ and $K \\in \\mathcal{K}$, select the feasible pair that minimizes $\\mathcal{C}(E_{\\text{cut}},K) = \\alpha E_{\\text{cut}}^{3/2} + \\beta K^3$. If ties occur, prefer smaller $E_{\\text{cut}}$, then smaller $K$.\n\nAlgorithm steps:\n- For each $E_{\\text{cut}} \\in \\mathcal{E}$ and each $K \\in \\mathcal{K}$:\n  - Compute $\\mathcal{E}_f^{\\max}(E_{\\text{cut}},K)$ and $\\mathcal{E}_\\sigma^{\\max}(E_{\\text{cut}},K)$ from the snapshot coefficients and exponents.\n  - Check feasibility: $\\mathcal{E}_f^{\\max}(E_{\\text{cut}},K) \\le T_f$ and $\\mathcal{E}_\\sigma^{\\max}(E_{\\text{cut}},K) \\le T_\\sigma$.\n  - If feasible, evaluate $\\mathcal{C}(E_{\\text{cut}},K)$ and track the minimal cost solution with the specified tie-breaks.\n- If no feasible pair exists, return the sentinel $[0.0,0]$.\n\nValidation on the test suite:\n- Test case $1$:\n  - Parameters: $A = [1600,1400,1500]$, $B = [4.0,6.0,5.0]$, $p = 1.0$, $q = 2.0$; $C = [20.0,16.0,18.0]$, $D = [0.05,0.07,0.06]$, $p_\\sigma = 0.8$, $q_\\sigma = 1.5$; $T_f = 5.0$ meV/Å, $T_\\sigma = 0.2$ GPa; $\\mathcal{E} = [300,350,400,450,500,600]$ eV; $\\mathcal{K} = [1,2,3,4,5,6]$; $\\alpha = 1.0$, $\\beta = 0.08$.\n  - Consider $E_{\\text{cut}} = 400$ eV, $K = 2$. Force errors per snapshot:\n    - Snapshot $1$: $\\mathcal{E}_f^{(1)} = 1600 \\cdot 400^{-1.0} + 4.0 \\cdot 2^{-2.0} = 4.0 + 1.0 = 5.0$ meV/Å.\n    - Snapshot $2$: $\\mathcal{E}_f^{(2)} = 1400 \\cdot 400^{-1.0} + 6.0 \\cdot 2^{-2.0} = 3.5 + 1.5 = 5.0$ meV/Å.\n    - Snapshot $3$: $\\mathcal{E}_f^{(3)} = 1500 \\cdot 400^{-1.0} + 5.0 \\cdot 2^{-2.0} = 3.75 + 1.25 = 5.0$ meV/Å.\n    - Hence $\\mathcal{E}_f^{\\max}(400,2) = 5.0$ meV/Å satisfies $T_f = 5.0$ meV/Å.\n  - Stress errors per snapshot:\n    - Compute $400^{-0.8}$. Using $400^{-0.8} \\approx \\exp(-0.8 \\ln 400) \\approx \\exp(-0.8 \\cdot 5.991) \\approx \\exp(-4.793) \\approx 0.0083$.\n    - $2^{-1.5} = 1 / 2^{1.5} = 1 / (2 \\sqrt{2}) \\approx 1 / 2.828 \\approx 0.3536$.\n    - Snapshot $1$: $\\mathcal{E}_\\sigma^{(1)} = 20.0 \\cdot 0.0083 + 0.05 \\cdot 0.3536 \\approx 0.166 + 0.0177 \\approx 0.1837$ GPa.\n    - Snapshot $2$: $\\mathcal{E}_\\sigma^{(2)} = 16.0 \\cdot 0.0083 + 0.07 \\cdot 0.3536 \\approx 0.133 + 0.0248 \\approx 0.1578$ GPa.\n    - Snapshot $3$: $\\mathcal{E}_\\sigma^{(3)} = 18.0 \\cdot 0.0083 + 0.06 \\cdot 0.3536 \\approx 0.149 + 0.0212 \\approx 0.1702$ GPa.\n    - Hence $\\mathcal{E}_\\sigma^{\\max}(400,2) \\approx 0.1837$ GPa satisfies $T_\\sigma = 0.2$ GPa.\n  - Check whether any lower-cost pair could satisfy both bounds. For $E_{\\text{cut}} = 350$ eV, $A \\cdot 350^{-1.0}$ forces are at least $4.571$ meV/Å for snapshot $1$, and with $K \\ge 2$, the added $B_s K^{-2}$ term increases the error, so the maximum force exceeds $5.0$ meV/Å. For $K = 1$, the $B_s K^{-2}$ term is larger and infeasible. Thus $(400,2)$ is the minimal feasible pair by $E_{\\text{cut}}$ and $K$ among the candidate sets. Its cost is $\\mathcal{C}(400,2) = 1.0 \\cdot 400^{3/2} + 0.08 \\cdot 2^3 = 8000.0 + 0.64 = 8000.64$, and no lower $E_{\\text{cut}}$ or $K$ choice is feasible, making $(400,2)$ the selected pair.\n- Test case $2$:\n  - Parameters: $A = [1200,1200]$, $B = [0.5,0.5]$, $p = 1.0$, $q = 1.0$; $C = [10.0,8.0]$, $D = [0.02,0.02]$, $p_\\sigma = 1.0$, $q_\\sigma = 1.0$; $T_f = 5.0$ meV/Å, $T_\\sigma = 0.2$ GPa; same candidates and cost weights as test case $1$.\n  - Evaluate $(E_{\\text{cut}},K) = (300,1)$:\n    - Force: $\\mathcal{E}_f^{(s)} = 1200 \\cdot 300^{-1.0} + 0.5 \\cdot 1^{-1.0} = 4.0 + 0.5 = 4.5$ meV/Å for both snapshots, hence $\\mathcal{E}_f^{\\max}(300,1) = 4.5 \\le 5.0$ meV/Å.\n    - Stress: snapshot $1$, $\\mathcal{E}_\\sigma^{(1)} = 10.0 \\cdot 300^{-1.0} + 0.02 \\cdot 1^{-1.0} = 0.033\\overline{3} + 0.02 \\approx 0.053\\overline{3}$ GPa; snapshot $2$, $\\mathcal{E}_\\sigma^{(2)} = 8.0 \\cdot 300^{-1.0} + 0.02 = 0.026\\overline{6} + 0.02 \\approx 0.046\\overline{6}$ GPa; thus $\\mathcal{E}_\\sigma^{\\max}(300,1) \\approx 0.053\\overline{3} \\le 0.2$ GPa.\n  - This pair is feasible and has cost $\\mathcal{C}(300,1) = 1.0 \\cdot 300^{3/2} + 0.08 \\cdot 1 = 300 \\cdot \\sqrt{300} + 0.08 \\approx 300 \\cdot 17.3205 + 0.08 \\approx 5196.15 + 0.08 \\approx 5196.23$, which is minimal among feasible pairs because it uses the smallest $E_{\\text{cut}}$ and $K$ that already satisfy the tolerances, and cost increases monotonically with either parameter. Hence $(300,1)$ is selected.\n- Test case $3$:\n  - Parameters: $A = [8000,9000]$, $B = [10.0,10.0]$, $p = 1.0$, $q = 2.0$; $C = [100.0,120.0]$, $D = [0.10,0.10]$, $p_\\sigma = 1.0$, $q_\\sigma = 1.0$; $T_f = 5.0$ meV/Å, $T_\\sigma = 0.2$ GPa; same candidates and cost weights.\n  - Evaluate the most favorable candidate $(E_{\\text{cut}},K) = (600,6)$ for forces:\n    - Snapshot $2$: $\\mathcal{E}_f^{(2)} = 9000 \\cdot 600^{-1.0} + 10.0 \\cdot 6^{-2.0} = 15.0 + 10.0/36 \\approx 15.0 + 0.277\\overline{7} \\approx 15.277\\overline{7}$ meV/Å, which far exceeds $T_f = 5.0$ meV/Å. Thus no candidate can satisfy the force bound, and feasibility fails.\n  - By the sentinel rule, the output for this test case is $[0.0,0]$.\n\nThe algorithm therefore returns the per-test-case selections $[400.0,2]$, $[300.0,1]$, and $[0.0,0]$. The implementation directly evaluates the defined functions over the candidate sets, applies the feasibility constraints, minimizes the cost under tie-break rules, and formats the output as specified.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef select_minimal_cutoff_and_kgrid(A, B, C, D, p, q, p_sigma, q_sigma,\n                                    T_f, T_sigma, E_candidates, K_candidates,\n                                    alpha, beta):\n    \"\"\"\n    Given error model parameters and candidate sets, select the minimal-cost\n    (E_cut, K) satisfying the force and stress tolerances across snapshots.\n    Tie-break by smaller E_cut, then smaller K. If none feasible, return [0.0, 0].\n    \"\"\"\n    # Convert inputs to numpy arrays for vectorized operations\n    A = np.array(A, dtype=float)\n    B = np.array(B, dtype=float)\n    C = np.array(C, dtype=float)\n    D = np.array(D, dtype=float)\n    E_candidates = np.array(E_candidates, dtype=float)\n    K_candidates = np.array(K_candidates, dtype=int)\n\n    best_pair = None\n    best_cost = np.inf\n\n    for E in E_candidates:\n        # Precompute E-dependent factors\n        E_pow_f = E ** (-p)\n        E_pow_sigma = E ** (-p_sigma)\n        for K in K_candidates:\n            # Compute K-dependent factors\n            K_pow_f = K ** (-q)\n            K_pow_sigma = K ** (-q_sigma)\n\n            # Force and stress errors per snapshot\n            force_errors = A * E_pow_f + B * K_pow_f\n            stress_errors = C * E_pow_sigma + D * K_pow_sigma\n\n            max_force_error = np.max(force_errors)\n            max_stress_error = np.max(stress_errors)\n\n            # Check tolerances\n            if (max_force_error <= T_f) and (max_stress_error <= T_sigma):\n                # Compute cost\n                cost = alpha * (E ** 1.5) + beta * (K ** 3)\n                # Update best with tie-breaks: lower cost, then lower E, then lower K\n                if (cost < best_cost) or (\n                    np.isclose(cost, best_cost) and (\n                        (best_pair is None) or (E < best_pair[0]) or (\n                            (np.isclose(E, best_pair[0])) and (K < best_pair[1])\n                        )\n                    )\n                ):\n                    best_cost = cost\n                    best_pair = (float(E), int(K))\n\n    if best_pair is None:\n        return [0.0, 0]\n    else:\n        # Ensure E is printed as float\n        return [float(best_pair[0]), int(best_pair[1])]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"A\": [1600, 1400, 1500],\n            \"B\": [4.0, 6.0, 5.0],\n            \"C\": [20.0, 16.0, 18.0],\n            \"D\": [0.05, 0.07, 0.06],\n            \"p\": 1.0,\n            \"q\": 2.0,\n            \"p_sigma\": 0.8,\n            \"q_sigma\": 1.5,\n            \"T_f\": 5.0,       # meV/Å\n            \"T_sigma\": 0.2,   # GPa\n            \"E_candidates\": [300, 350, 400, 450, 500, 600],  # eV\n            \"K_candidates\": [1, 2, 3, 4, 5, 6],              # per-direction\n            \"alpha\": 1.0,\n            \"beta\": 0.08\n        },\n        {\n            \"A\": [1200, 1200],\n            \"B\": [0.5, 0.5],\n            \"C\": [10.0, 8.0],\n            \"D\": [0.02, 0.02],\n            \"p\": 1.0,\n            \"q\": 1.0,\n            \"p_sigma\": 1.0,\n            \"q_sigma\": 1.0,\n            \"T_f\": 5.0,       # meV/Å\n            \"T_sigma\": 0.2,   # GPa\n            \"E_candidates\": [300, 350, 400, 450, 500, 600],  # eV\n            \"K_candidates\": [1, 2, 3, 4, 5, 6],              # per-direction\n            \"alpha\": 1.0,\n            \"beta\": 0.08\n        },\n        {\n            \"A\": [8000, 9000],\n            \"B\": [10.0, 10.0],\n            \"C\": [100.0, 120.0],\n            \"D\": [0.10, 0.10],\n            \"p\": 1.0,\n            \"q\": 2.0,\n            \"p_sigma\": 1.0,\n            \"q_sigma\": 1.0,\n            \"T_f\": 5.0,       # meV/Å\n            \"T_sigma\": 0.2,   # GPa\n            \"E_candidates\": [300, 350, 400, 450, 500, 600],  # eV\n            \"K_candidates\": [1, 2, 3, 4, 5, 6],              # per-direction\n            \"alpha\": 1.0,\n            \"beta\": 0.08\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = select_minimal_cutoff_and_kgrid(\n            A=case[\"A\"], B=case[\"B\"], C=case[\"C\"], D=case[\"D\"],\n            p=case[\"p\"], q=case[\"q\"], p_sigma=case[\"p_sigma\"], q_sigma=case[\"q_sigma\"],\n            T_f=case[\"T_f\"], T_sigma=case[\"T_sigma\"],\n            E_candidates=case[\"E_candidates\"], K_candidates=case[\"K_candidates\"],\n            alpha=case[\"alpha\"], beta=case[\"beta\"]\n        )\n        results.append(result)\n\n    # Format results as specified: single line, comma-separated, list of [E_cut,K] with no spaces.\n    formatted = \"[\" + \",\".join(f\"[{res[0]:.1f},{res[1]}]\" for res in results) + \"]\"\n    print(formatted)\n\nsolve()\n```"
        },
        {
            "introduction": "Once simulation parameters are chosen, the next critical step is to validate the quality of the molecular dynamics trajectory itself. In a microcanonical (NVE) ensemble, the total energy of the system should be a conserved quantity, and any systematic drift is a red flag indicating numerical inaccuracies. This practice explores the two primary sources of this drift: the finite integration time step ($\\Delta t$) and the incomplete convergence of the electronic self-consistent field (SCF) calculation. By fitting a predictive model to calibration data, you will learn to quantify these error contributions and select parameters that ensure the long-term stability and physical realism of your AIMD simulation .",
            "id": "3728716",
            "problem": "Consider a Born-Oppenheimer Molecular Dynamics (BOMD) simulation in the microcanonical ensemble (constant number of particles, volume, and energy; NVE) for a high-entropy alloy composed of $128$ atoms. The total energy of the system should be conserved in an ideal continuous-time evolution under exact Self-Consistent Field (SCF) convergence and exact forces. In practice, two sources of systematic numerical error contribute to energy drift: the finite time step $\\Delta t$ of the integrator and the finite SCF convergence tolerance $\\tau$ of the electronic structure solver. For sufficiently small $\\Delta t$ and tight SCF tolerance, the energy drift rate per atom can be approximated by a model that is linear in the dominant small-error contributions. Assuming a velocity-Verlet integrator (which has a local truncation error of order $\\mathcal{O}((\\Delta t)^3)$ and a global energy error scaling as $\\mathcal{O}((\\Delta t)^2)$ for well-behaved forces) and a residual force error that scales approximately linearly with the SCF energy tolerance, adopt the following linearized drift-rate model:\n$$\nr(\\Delta t,\\tau) = \\alpha\\,(\\Delta t)^2 + \\beta\\,\\tau + \\gamma,\n$$\nwhere $r$ is the energy drift rate in meV/atom/ns, $\\Delta t$ is the time step in fs (femtoseconds), $\\tau$ is the SCF energy tolerance in eV (electronvolts), and $\\alpha$, $\\beta$, $\\gamma$ are parameters to be determined.\n\nYou are provided with calibration measurements of the energy drift rate $r$ for a set of $(\\Delta t,\\tau)$ pairs obtained from short NVE BOMD runs on the $128$-atom high-entropy alloy. All listed $r$ values are per atom in meV/atom/ns. Use these calibration data to fit the linear model parameters $\\alpha$, $\\beta$, and $\\gamma$ via least squares:\n- $(\\Delta t=0.5\\,\\text{fs}, \\tau=1\\times 10^{-5}\\,\\text{eV}) \\rightarrow r=0.1625$\n- $(\\Delta t=0.5\\,\\text{fs}, \\tau=5\\times 10^{-5}\\,\\text{eV}) \\rightarrow r=0.3625$\n- $(\\Delta t=0.5\\,\\text{fs}, \\tau=1\\times 10^{-4}\\,\\text{eV}) \\rightarrow r=0.6125$\n- $(\\Delta t=0.5\\,\\text{fs}, \\tau=5\\times 10^{-4}\\,\\text{eV}) \\rightarrow r=2.6125$\n- $(\\Delta t=1.0\\,\\text{fs}, \\tau=1\\times 10^{-5}\\,\\text{eV}) \\rightarrow r=0.3500$\n- $(\\Delta t=1.0\\,\\text{fs}, \\tau=5\\times 10^{-5}\\,\\text{eV}) \\rightarrow r=0.5500$\n- $(\\Delta t=1.0\\,\\text{fs}, \\tau=1\\times 10^{-4}\\,\\text{eV}) \\rightarrow r=0.8000$\n- $(\\Delta t=1.0\\,\\text{fs}, \\tau=5\\times 10^{-4}\\,\\text{eV}) \\rightarrow r=2.8000$\n- $(\\Delta t=2.0\\,\\text{fs}, \\tau=1\\times 10^{-5}\\,\\text{eV}) \\rightarrow r=1.1000$\n- $(\\Delta t=2.0\\,\\text{fs}, \\tau=5\\times 10^{-5}\\,\\text{eV}) \\rightarrow r=1.3000$\n- $(\\Delta t=2.0\\,\\text{fs}, \\tau=1\\times 10^{-4}\\,\\text{eV}) \\rightarrow r=1.5500$\n- $(\\Delta t=2.0\\,\\text{fs}, \\tau=5\\times 10^{-4}\\,\\text{eV}) \\rightarrow r=3.5500$\n\nAfter fitting $\\alpha$, $\\beta$, and $\\gamma$, quantify the energy drift for specified test $(\\Delta t,\\tau)$ pairs by evaluating $r(\\Delta t,\\tau)$. Furthermore, derive a recommendation for the maximum allowable time step $\\Delta t_{\\max}$ as a function of SCF tolerance $\\tau$ such that the drift rate remains below a target threshold $r_{\\text{thr}}=1\\,\\text{meV/atom/ns}$. Using the fitted model, this recommendation must satisfy:\n$$\n\\Delta t_{\\max}(\\tau) = \n\\begin{cases}\n\\sqrt{\\dfrac{r_{\\text{thr}} - \\beta\\,\\tau - \\gamma}{\\alpha}}, & \\text{if } r_{\\text{thr}} - \\beta\\,\\tau - \\gamma > 0,\\\\\n0, & \\text{otherwise,}\n\\end{cases}\n$$\nwith $\\Delta t_{\\max}$ expressed in fs.\n\nYour program must perform the following steps:\n1. Fit the parameters $\\alpha$, $\\beta$, and $\\gamma$ using the calibration dataset above.\n2. Compute the predicted drift rates $r(\\Delta t,\\tau)$ for the following test pairs:\n   - $\\Delta t=1.0\\,\\text{fs}$, $\\tau=1\\times 10^{-5}\\,\\text{eV}$,\n   - $\\Delta t=2.0\\,\\text{fs}$, $\\tau=1\\times 10^{-5}\\,\\text{eV}$,\n   - $\\Delta t=1.5\\,\\text{fs}$, $\\tau=1\\times 10^{-4}\\,\\text{eV}$.\n   Report each $r$ in meV/atom/ns.\n3. Compute the recommended $\\Delta t_{\\max}$ for the following SCF tolerances to keep the drift below $r_{\\text{thr}}=1\\,\\text{meV/atom/ns}$:\n   - $\\tau=1\\times 10^{-5}\\,\\text{eV}$,\n   - $\\tau=5\\times 10^{-5}\\,\\text{eV}$,\n   - $\\tau=1\\times 10^{-4}\\,\\text{eV}$,\n   - $\\tau=5\\times 10^{-4}\\,\\text{eV}$.\n   Report each $\\Delta t_{\\max}$ in fs.\n\nAll numerical answers must be floats rounded to six decimal places. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the following order: the three predicted drift rates followed by the four recommended maximum time steps, i.e., $[r_{1},r_{2},r_{3},\\Delta t_{\\max,1},\\Delta t_{\\max,2},\\Delta t_{\\max,3},\\Delta t_{\\max,4}]$.",
            "solution": "The problem requires us to determine the parameters of a linear model for energy drift in a Born-Oppenheimer Molecular Dynamics (BOMD) simulation and then use this model for prediction and to establish operational constraints. The analysis proceeds in two main stages: first, fitting the model parameters using the method of linear least squares, and second, applying the fitted model to answer the specific questions posed.\n\nThe proposed model for the energy drift rate per atom, $r$, is given by:\n$$\nr(\\Delta t, \\tau) = \\alpha (\\Delta t)^2 + \\beta \\tau + \\gamma\n$$\nwhere $\\Delta t$ is the integration time step in femtoseconds (fs), $\\tau$ is the Self-Consistent Field (SCF) energy convergence tolerance in electronvolts (eV), and $r$ is the drift rate in meV/atom/ns. The parameters to be determined are $\\alpha$, $\\beta$, and $\\gamma$. This model is linear with respect to the parameters. The term $(\\Delta t)^2$ is physically motivated by the global energy error scaling of the velocity-Verlet integrator, and the linear dependence on $\\tau$ is a reasonable first-order approximation for the influence of incomplete SCF convergence on atomic forces.\n\nWe are given $12$ calibration data points of the form $((\\Delta t)_i, \\tau_i, r_i)$, for $i=1, \\dots, 12$. To find the best-fit parameters $\\alpha$, $\\beta$, and $\\gamma$, we employ the method of linear least squares. This method minimizes the sum of the squared differences between the observed drift rates $r_i$ and the rates predicted by the model.\n\nLet us define a parameter vector $\\mathbf{p}$ and a feature vector $\\mathbf{x}_i$ for each data point:\n$$\n\\mathbf{p} = \\begin{pmatrix} \\alpha \\\\ \\beta \\\\ \\gamma \\end{pmatrix}, \\quad \\mathbf{x}_i = \\begin{pmatrix} (\\Delta t_i)^2 \\\\ \\tau_i \\\\ 1 \\end{pmatrix}\n$$\nThe model can then be expressed as $r_i \\approx \\mathbf{x}_i^T \\mathbf{p}$. We can assemble all $12$ equations into a single matrix equation:\n$$\n\\mathbf{A} \\mathbf{p} = \\mathbf{b}\n$$\nwhere $\\mathbf{A}$ is the $12 \\times 3$ design matrix whose rows are the feature vectors $\\mathbf{x}_i^T$, and $\\mathbf{b}$ is the $12 \\times 1$ vector of observed drift rates $r_i$.\n\n$$\n\\mathbf{A} = \\begin{pmatrix}\n(\\Delta t_1)^2 & \\tau_1 & 1 \\\\\n(\\Delta t_2)^2 & \\tau_2 & 1 \\\\\n\\vdots & \\vdots & \\vdots \\\\\n(\\Delta t_{12})^2 & \\tau_{12} & 1\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n(0.5)^2 & 1 \\times 10^{-5} & 1 \\\\\n(0.5)^2 & 5 \\times 10^{-5} & 1 \\\\\n(0.5)^2 & 1 \\times 10^{-4} & 1 \\\\\n(0.5)^2 & 5 \\times 10^{-4} & 1 \\\\\n(1.0)^2 & 1 \\times 10^{-5} & 1 \\\\\n(1.0)^2 & 5 \\times 10^{-5} & 1 \\\\\n(1.0)^2 & 1 \\times 10^{-4} & 1 \\\\\n(1.0)^2 & 5 \\times 10^{-4} & 1 \\\\\n(2.0)^2 & 1 \\times 10^{-5} & 1 \\\\\n(2.0)^2 & 5 \\times 10^{-5} & 1 \\\\\n(2.0)^2 & 1 \\times 10^{-4} & 1 \\\\\n(2.0)^2 & 5 \\times 10^{-4} & 1\n\\end{pmatrix},\n\\quad\n\\mathbf{b} = \\begin{pmatrix}\n0.1625 \\\\ 0.3625 \\\\ 0.6125 \\\\ 2.6125 \\\\\n0.3500 \\\\ 0.5500 \\\\ 0.8000 \\\\ 2.8000 \\\\\n1.1000 \\\\ 1.3000 \\\\ 1.5500 \\\\ 3.5500\n\\end{pmatrix}\n$$\n\nThe least squares solution $\\mathbf{p}$ minimizes the Euclidean norm of the residual vector, $||\\mathbf{A} \\mathbf{p} - \\mathbf{b}||_2$. The solution is found by solving the normal equations:\n$$\n(\\mathbf{A}^T \\mathbf{A}) \\mathbf{p} = \\mathbf{A}^T \\mathbf{b}\n$$\nSolving this system of linear equations for $\\mathbf{p}$ yields the values for $\\alpha$, $\\beta$, and $\\gamma$. Performing this calculation with the given data results in:\n$$\n\\alpha = 0.25 \\, \\frac{\\text{meV/atom/ns}}{\\text{fs}^2}\n$$\n$$\n\\beta = 5000 \\, \\frac{\\text{meV/atom/ns}}{\\text{eV}}\n$$\n$$\n\\gamma = 0.05 \\, \\text{meV/atom/ns}\n$$\nThe data provided are perfectly described by these parameters, indicating no random noise in the calibration set. The fitted model is thus:\n$$\nr(\\Delta t, \\tau) = 0.25 (\\Delta t)^2 + 5000 \\tau + 0.05\n$$\n\nWith the model parameterized, we can proceed to the required calculations.\n\n**1. Predicted Drift Rates**\n\nWe compute the drift rate $r$ for three test pairs $(\\Delta t, \\tau)$:\n- For $(\\Delta t=1.0\\,\\text{fs}, \\tau=1 \\times 10^{-5}\\,\\text{eV})$:\n$$\nr_1 = 0.25 (1.0)^2 + 5000 (1 \\times 10^{-5}) + 0.05 = 0.25 + 0.05 + 0.05 = 0.35 \\, \\text{meV/atom/ns}\n$$\n- For $(\\Delta t=2.0\\,\\text{fs}, \\tau=1 \\times 10^{-5}\\,\\text{eV})$:\n$$\nr_2 = 0.25 (2.0)^2 + 5000 (1 \\times 10^{-5}) + 0.05 = 0.25(4) + 0.05 + 0.05 = 1.0 + 0.05 + 0.05 = 1.10 \\, \\text{meV/atom/ns}\n$$\n- For $(\\Delta t=1.5\\,\\text{fs}, \\tau=1 \\times 10^{-4}\\,\\text{eV})$:\n$$\nr_3 = 0.25 (1.5)^2 + 5000 (1 \\times 10^{-4}) + 0.05 = 0.25(2.25) + 0.5 + 0.05 = 0.5625 + 0.5 + 0.05 = 1.1125 \\, \\text{meV/atom/ns}\n$$\n\n**2. Recommended Maximum Time Step**\n\nWe need to find the maximum time step $\\Delta t_{\\max}$ for a given tolerance $\\tau$ such that the drift rate does not exceed a threshold $r_{\\text{thr}} = 1.0\\,\\text{meV/atom/ns}$. We start from the model and solve for $\\Delta t$:\n$$\nr_{\\text{thr}} \\ge 0.25 (\\Delta t)^2 + 5000 \\tau + 0.05\n$$\n$$\n(\\Delta t)^2 \\le \\frac{r_{\\text{thr}} - 5000 \\tau - 0.05}{0.25}\n$$\nFor $\\Delta t$ to be real, the numerator must be non-negative. This gives the expression for $\\Delta t_{\\max}$:\n$$\n\\Delta t_{\\max}(\\tau) = \\begin{cases}\n\\sqrt{\\dfrac{1.0 - 5000 \\tau - 0.05}{0.25}} = \\sqrt{4 (0.95 - 5000 \\tau)} = 2\\sqrt{0.95 - 5000 \\tau}, & \\text{if } 0.95 - 5000 \\tau > 0 \\\\\n0, & \\text{otherwise}\n\\end{cases}\n$$\nThe condition $0.95 - 5000 \\tau > 0$ implies $\\tau < \\frac{0.95}{5000} = 1.9 \\times 10^{-4}$ eV.\n\nWe now compute $\\Delta t_{\\max}$ for the four given values of $\\tau$:\n\n- For $\\tau = 1 \\times 10^{-5}\\,\\text{eV}$: The condition is met.\n$$\n\\Delta t_{\\max,1} = 2\\sqrt{0.95 - 5000(1 \\times 10^{-5})} = 2\\sqrt{0.95 - 0.05} = 2\\sqrt{0.90} \\approx 1.897367 \\, \\text{fs}\n$$\n- For $\\tau = 5 \\times 10^{-5}\\,\\text{eV}$: The condition is met.\n$$\n\\Delta t_{\\max,2} = 2\\sqrt{0.95 - 5000(5 \\times 10^{-5})} = 2\\sqrt{0.95 - 0.25} = 2\\sqrt{0.70} \\approx 1.673320 \\, \\text{fs}\n$$\n- For $\\tau = 1 \\times 10^{-4}\\,\\text{eV}$: The condition is met.\n$$\n\\Delta t_{\\max,3} = 2\\sqrt{0.95 - 5000(1 \\times 10^{-4})} = 2\\sqrt{0.95 - 0.50} = 2\\sqrt{0.45} \\approx 1.341641 \\, \\text{fs}\n$$\n- For $\\tau = 5 \\times 10^{-4}\\,\\text{eV}$: $5000 \\tau = 2.5$, which is greater than $0.95$. The numerator is negative.\n$$\n\\Delta t_{\\max,4} = 0 \\, \\text{fs}\n$$\n\nThe final collection of results, rounded to six decimal places, is: $r_1=0.350000$, $r_2=1.100000$, $r_3=1.112500$, $\\Delta t_{\\max,1}=1.897367$, $\\Delta t_{\\max,2}=1.673320$, $\\Delta t_{\\max,3}=1.341641$, and $\\Delta t_{\\max,4}=0.000000$.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of fitting an energy drift model for BOMD simulations\n    and using it for prediction and constraint derivation.\n    \"\"\"\n    \n    # --- Step 1: Fit the model parameters using least squares ---\n    \n    # Calibration data: (delta_t, tau, r)\n    # delta_t is in fs, tau in eV, r in meV/atom/ns.\n    calibration_data = [\n        (0.5, 1e-5, 0.1625),\n        (0.5, 5e-5, 0.3625),\n        (0.5, 1e-4, 0.6125),\n        (0.5, 5e-4, 2.6125),\n        (1.0, 1e-5, 0.3500),\n        (1.0, 5e-5, 0.5500),\n        (1.0, 1e-4, 0.8000),\n        (1.0, 5e-4, 2.8000),\n        (2.0, 1e-5, 1.1000),\n        (2.0, 5e-5, 1.3000),\n        (2.0, 1e-4, 1.5500),\n        (2.0, 5e-4, 3.5500),\n    ]\n\n    # The model is r = alpha * (delta_t)^2 + beta * tau + gamma\n    # This is a linear model in the parameters (alpha, beta, gamma).\n    # We set up the linear system A * p = b, where p = [alpha, beta, gamma].\n    \n    num_points = len(calibration_data)\n    A = np.zeros((num_points, 3))\n    b = np.zeros(num_points)\n    \n    for i, (dt, tau, r) in enumerate(calibration_data):\n        A[i, 0] = dt**2\n        A[i, 1] = tau\n        A[i, 2] = 1\n        b[i] = r\n        \n    # Solve the least squares problem A*p = b for p\n    params, _, _, _ = np.linalg.lstsq(A, b, rcond=None)\n    alpha, beta, gamma = params\n\n    # --- Step 2: Compute predicted drift rates for test cases ---\n    \n    test_rates_inputs = [\n        (1.0, 1e-5),  # (delta_t, tau)\n        (2.0, 1e-5),\n        (1.5, 1e-4),\n    ]\n    \n    predicted_rates = []\n    for dt, tau in test_rates_inputs:\n        rate = alpha * dt**2 + beta * tau + gamma\n        predicted_rates.append(rate)\n\n    # --- Step 3: Compute recommended max time step ---\n\n    r_thr = 1.0  # meV/atom/ns\n    \n    test_dtmax_inputs = [\n        1e-5,  # tau in eV\n        5e-5,\n        1e-4,\n        5e-4,\n    ]\n    \n    recommended_dtmax = []\n    for tau in test_dtmax_inputs:\n        # dt_max = sqrt((r_thr - beta*tau - gamma) / alpha)\n        numerator = r_thr - beta * tau - gamma\n        if numerator > 0:\n            dt_max = np.sqrt(numerator / alpha)\n        else:\n            dt_max = 0.0\n        recommended_dtmax.append(dt_max)\n        \n    # Combine all results\n    all_results = predicted_rates + recommended_dtmax\n    \n    # Format the output as specified\n    formatted_results = [f\"{res:.6f}\" for res in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "With the ability to run robust and stable AIMD simulations, we can tackle central questions in electrochemistry, such as determining the rate of a chemical reaction. This advanced exercise demonstrates how AIMD can be used to compute rate constants by combining concepts from Transition State Theory (TST) with corrections for dynamical effects. You will learn to integrate the free energy barrier ($\\Delta G^\\ddagger$), typically obtained from enhanced sampling methods, with a transmission coefficient ($\\kappa$) calculated from short reactive trajectories. This practice provides a powerful link between first-principles simulation and the macroscopic kinetics of chemical processes like hydrogen evolution at an electrode surface .",
            "id": "4236156",
            "problem": "Consider a hydrogen evolution reaction at a model electrode studied with Ab Initio Molecular Dynamics (AIMD, Ab Initio Molecular Dynamics). Umbrella sampling along a single scalar reaction coordinate $s$ delivers a potential of mean force $G(s)$ whose barrier height $\\Delta G^\\ddagger$ defines the free-energy cost to reach the dividing surface at $s^\\ddagger$. Separately, short reactive flux trajectories initiated at the dividing surface with forward velocity produce a time-dependent transmission coefficient series $\\{\\kappa(t_i)\\}$ that encodes the effect of dynamical recrossings. Starting from classical canonical rate theory and the definition of the reactive flux plateau, derive an explicit expression for the rate constant $k$ in terms of the plateau transmission coefficient $\\kappa$ and the free-energy barrier $\\Delta G^\\ddagger$. Then, implement a program that uses this expression to compute $k$ for given test cases.\n\nFundamental base for derivation and computation:\n- The classical canonical ensemble with Hamiltonian $H(x,p) = K(p) + U(x)$ at temperature $T$.\n- The definition of the reaction coordinate $s(x)$ and dividing surface at $s^\\ddagger$, with reactant region $s < s^\\ddagger$ and product region $s > s^\\ddagger$.\n- The potential of mean force $G(s)$ along $s$ obtained by umbrella sampling, and the free energy barrier $\\Delta G^\\ddagger = G(s^\\ddagger) - G(s_{\\mathrm{r}})$ between a representative reactant value $s_{\\mathrm{r}}$ and the barrier top $s^\\ddagger$.\n- The reactive flux formulation, where time-dependent transmission $\\kappa(t)$ plateaus to a constant $\\kappa$ at intermediate times when transient recrossings have decayed.\n\nComputational task:\n1. For each provided test case, estimate the plateau transmission coefficient $\\kappa$ from the supplied time series $\\{\\kappa(t_i)\\}$ using the following algorithm:\n   - Given strictly increasing times $\\{t_i\\}$ in femtoseconds and corresponding values $\\{y_i\\} = \\{\\kappa(t_i)\\}$ in the interval $[0,1]$, define a window size $m = 5$ and tolerance $\\epsilon = 0.02$. For the smallest index $j \\ge m$ such that the window range $R_j = \\max\\{y_{j-m+1},\\dots,y_j\\} - \\min\\{y_{j-m+1},\\dots,y_j\\}$ satisfies\n     $$\\frac{R_j}{\\max\\left(\\bar{y}_j, \\delta_0\\right)} \\le \\epsilon,$$\n     where $\\bar{y}_j$ is the mean of the window and $\\delta_0 = 10^{-6}$ prevents division by zero, define the plateau estimate as\n     $$\\kappa = \\frac{1}{N-j} \\sum_{i=j}^{N-1} y_i,$$\n     with $N$ the series length and indexes $0$-based. If no such $j$ exists, define $\\kappa$ as the average over the last $m$ points.\n2. Using your derived expression for $k$ in terms of $\\kappa$ and $\\Delta G^\\ddagger$, compute $k$ for each test case. Use the Boltzmann constant $k_{\\mathrm{B}}$ and Planck’s constant $h$ with values $k_{\\mathrm{B}} = 1.380649\\times 10^{-23}\\ \\mathrm{J/K}$ and $h = 6.62607015\\times 10^{-34}\\ \\mathrm{J\\,s}$. Convert $\\Delta G^\\ddagger$ from electronvolts to joules using $1\\ \\mathrm{eV} = 1.602176634\\times 10^{-19}\\ \\mathrm{J}$. Express the final rate constant in $\\mathrm{s}^{-1}$. Round each rate to $6$ significant figures.\n3. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example, $\"[r_1,r_2,\\dots]\"$, where each $r_i$ is the rounded float in $\\mathrm{s}^{-1}$.\n\nTest suite:\n- Case $1$ (happy path): $T = 300\\ \\mathrm{K}$, $\\Delta G^\\ddagger = 0.50\\ \\mathrm{eV}$, times $\\{0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200\\}$ fs, values $\\{0.0, 0.18, 0.28, 0.33, 0.35, 0.355, 0.358, 0.360, 0.361, 0.3615, 0.362, 0.362, 0.3622, 0.3621, 0.3623, 0.3622, 0.3623, 0.3622, 0.3623, 0.3623, 0.3623\\}$.\n- Case $2$ (strong recrossing, mild noise): $T = 350\\ \\mathrm{K}$, $\\Delta G^\\ddagger = 0.35\\ \\mathrm{eV}$, times $\\{0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150\\}$ fs, values $\\{0.0, 0.05, 0.09, 0.11, 0.115, 0.118, 0.12, 0.119, 0.121, 0.120, 0.120, 0.121, 0.1205, 0.1208, 0.1207, 0.1206\\}$.\n- Case $3$ (near barrierless): $T = 300\\ \\mathrm{K}$, $\\Delta G^\\ddagger = 0.05\\ \\mathrm{eV}$, times $\\{0, 20, 40, 60, 80, 100, 120, 140, 160, 180\\}$ fs, values $\\{0.0, 0.4, 0.55, 0.64, 0.68, 0.70, 0.705, 0.707, 0.707, 0.7075\\}$.\n- Case $4$ (high barrier): $T = 298\\ \\mathrm{K}$, $\\Delta G^\\ddagger = 1.00\\ \\mathrm{eV}$, times $\\{0, 15, 30, 45, 60, 75, 90, 105, 120, 135, 150, 165\\}$ fs, values $\\{0.0, 0.2, 0.3, 0.38, 0.40, 0.405, 0.407, 0.408, 0.409, 0.4095, 0.4098, 0.4097\\}$.\n- Case $5$ (overshoot then plateau, edge case): $T = 330\\ \\mathrm{K}$, $\\Delta G^\\ddagger = 0.00\\ \\mathrm{eV}$, times $\\{0, 10, 20, 30, 40, 50, 60, 70, 80, 90\\}$ fs, values $\\{0.0, 0.6, 0.55, 0.52, 0.505, 0.5, 0.501, 0.5005, 0.5002, 0.5001\\}$.\n\nAnswer specification:\n- Compute the rate constant $k$ in $\\mathrm{s}^{-1}$ for each case, rounded to $6$ significant figures.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example, $\"[r_1,r_2,\\dots]\"$.",
            "solution": "The task is to derive an expression for the chemical reaction rate constant, $k$, within the framework of computational chemistry, specifically using concepts from Ab Initio Molecular Dynamics (AIMD), and then to implement a program to compute it. The derivation must connect the Potential of Mean Force ($G(s)$), obtained from umbrella sampling, and the transmission coefficient ($\\kappa$), obtained from reactive flux calculations.\n\nThe derivation begins with the foundational equation of Transition State Theory (TST). TST provides an upper bound for the rate constant by assuming that every system crossing a dividing surface (the transition state) from the reactant side proceeds to the product side without returning. For a reaction in the classical canonical ensemble at temperature $T$, the TST rate constant, $k_{\\mathrm{TST}}$, is given by:\n$$\nk_{\\mathrm{TST}} = \\nu \\frac{Q^\\ddagger}{Q_{\\mathrm{r}}}\n$$\nwhere $\\nu$ is a frequency factor, $Q_{\\mathrm{r}}$ is the canonical partition function of the reactants, and $Q^\\ddagger$ is the partition function of the system at the transition state, with the degree of freedom corresponding to the reaction coordinate removed. In the context of a one-dimensional reaction coordinate $s$, the frequency factor can be shown to be $\\nu = \\frac{k_{\\mathrm{B}} T}{h}$, where $k_{\\mathrm{B}}$ is the Boltzmann constant and $h$ is Planck's constant.\n\nThe ratio of partition functions is directly related to the Gibbs free energy of activation, $\\Delta G^\\ddagger$. From statistical mechanics, the Gibbs free energy $G$ is related to the total partition function $Q$ by $G = -k_{\\mathrm{B}} T \\ln Q$. The free energy of activation is the difference in free energy between the transition state ($s^\\ddagger$) and the reactant state ($s_{\\mathrm{r}}$):\n$$\n\\Delta G^\\ddagger = G(s^\\ddagger) - G(s_{\\mathrm{r}}) = -k_{\\mathrm{B}} T \\ln Q^\\ddagger - (-k_{\\mathrm{B}} T \\ln Q_{\\mathrm{r}}) = -k_{\\mathrm{B}} T \\ln\\left(\\frac{Q^\\ddagger}{Q_{\\mathrm{r}}}\\right)\n$$\nIn the problem, this quantity is provided as the barrier height of the Potential of Mean Force, $G(s)$, which is the free energy profile along the reaction coordinate. Solving for the partition function ratio yields:\n$$\n\\frac{Q^\\ddagger}{Q_{\\mathrm{r}}} = e^{-\\Delta G^\\ddagger / (k_{\\mathrm{B}} T)}\n$$\nSubstituting this and the expression for $\\nu$ into the equation for $k_{\\mathrm{TST}}$ gives the well-known Eyring equation:\n$$\nk_{\\mathrm{TST}} = \\frac{k_{\\mathrm{B}} T}{h} e^{-\\Delta G^\\ddagger / (k_{\\mathrm{B}} T)}\n$$\nThe primary deficiency of TST is its neglect of dynamical recrossings, where a trajectory crosses the dividing surface but immediately returns to the reactant region. The reactive flux formalism corrects for this. The true rate constant, $k$, is related to the TST rate by a transmission coefficient, $\\kappa$:\n$$\nk = \\kappa \\cdot k_{\\mathrm{TST}}\n$$\nThe transmission coefficient $\\kappa$ is a value between $0$ and $1$ that quantifies the fraction of forward-going trajectories at the dividing surface that successfully proceed to form products. It is determined from the long-time limit or plateau of the time-dependent transmission coefficient, $\\kappa(t)$, which is computed from an ensemble of short molecular dynamics trajectories initiated at the dividing surface. The time-dependent function $\\kappa(t)$ typically decays from an initial value of $\\kappa(t=0^+) = 1$ to a stable plateau value $\\kappa$ after a short transient period during which fast recrossing events occur.\n\nCombining the expressions for $k_{\\mathrm{TST}}$ and the dynamical correction $\\kappa$, we arrive at the final explicit expression for the rate constant:\n$$\nk = \\kappa \\frac{k_{\\mathrm{B}} T}{h} e^{-\\Delta G^\\ddagger / (k_{\\mathrm{B}} T)}\n$$\nThis equation forms the basis for the computational task. The program will first estimate the plateau transmission coefficient $\\kappa$ from the given time series data $\\{\\kappa(t_i)\\}$ using the prescribed numerical algorithm. This algorithm identifies the onset of a stable plateau by searching for a data window where the relative range of values falls below a tolerance $\\epsilon$. Once $\\kappa$ is determined, the rate constant $k$ is calculated using the derived formula. For consistency of units, the free energy barrier $\\Delta G^\\ddagger$, given in electronvolts ($eV$), must be converted to Joules ($J$) before use, as the constants $k_{\\mathrm{B}}$ and $h$ are provided in SI units. The final calculated rate $k$ will have units of $\\mathrm{s}^{-1}$.",
            "answer": "```python\nimport numpy as np\nimport math\n\ndef round_to_n_significant(number, n):\n    \"\"\"\n    Rounds a number to a specified number of significant figures.\n    \"\"\"\n    if number == 0:\n        return 0.0\n    \n    # Calculate the order of magnitude to determine the rounding scale\n    order_of_magnitude = math.floor(math.log10(abs(number)))\n    \n    # Calculate the scaling factor for rounding\n    scale = 10**(order_of_magnitude - (n - 1))\n    \n    # Round the scaled number and then scale it back\n    return round(number / scale) * scale\n\ndef estimate_kappa(values, m=5, epsilon=0.02, delta0=1e-6):\n    \"\"\"\n    Estimates the plateau transmission coefficient kappa from a time series.\n\n    Args:\n        values (list): The list of kappa(t) values.\n        m (int): The window size for plateau detection.\n        epsilon (float): The tolerance for the relative range.\n        delta0 (float): A small value to prevent division by zero.\n\n    Returns:\n        float: The estimated plateau transmission coefficient.\n    \"\"\"\n    n = len(values)\n    if n < m:\n        # If the series is shorter than the window, average what's available.\n        return np.mean(values) if n > 0 else 0.0\n\n    plateau_start_index = -1\n\n    for j in range(m, n):\n        window_indices = slice(j - m + 1, j + 1)\n        window_values = values[window_indices]\n        \n        range_j = np.max(window_values) - np.min(window_values)\n        mean_j = np.mean(window_values)\n        \n        denominator = max(mean_j, delta0)\n        \n        if denominator > 0 and (range_j / denominator) <= epsilon:\n            plateau_start_index = j\n            break\n            \n    if plateau_start_index != -1:\n        # Plateau found, average from the start of the plateau to the end\n        return np.mean(values[plateau_start_index:])\n    else:\n        # No plateau found, average over the last m points as a fallback\n        return np.mean(values[-m:])\n\ndef calculate_rate(T, dG_eV, kappa):\n    \"\"\"\n    Calculates the reaction rate constant k.\n\n    Args:\n        T (float): Temperature in Kelvin.\n        dG_eV (float): Free energy barrier in electronvolts.\n        kappa (float): The transmission coefficient.\n\n    Returns:\n        float: The rate constant k in s^-1.\n    \"\"\"\n    # Physical constants\n    K_B = 1.380649e-23   # Boltzmann constant in J/K\n    H = 6.62607015e-34    # Planck's constant in J*s\n    EV_TO_J = 1.602176634e-19 # Conversion factor from eV to Joules\n\n    # Convert dG to Joules\n    dG_J = dG_eV * EV_TO_J\n\n    # Calculate the exponent term\n    kBT = K_B * T\n    if kBT == 0:  # Avoid division by zero\n        return 0.0\n    \n    exponent = -dG_J / kBT\n\n    # Calculate Transition State Theory prefactor\n    tst_prefactor = kBT / H\n\n    # Calculate the final rate constant\n    k = kappa * tst_prefactor * np.exp(exponent)\n    \n    return k\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    \"\"\"\n    test_cases = [\n        {\n            \"T\": 300, \"dG_eV\": 0.50,\n            \"times_fs\": [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200],\n            \"kappa_t\": [0.0, 0.18, 0.28, 0.33, 0.35, 0.355, 0.358, 0.360, 0.361, 0.3615, 0.362, 0.362, 0.3622, 0.3621, 0.3623, 0.3622, 0.3623, 0.3622, 0.3623, 0.3623, 0.3623]\n        },\n        {\n            \"T\": 350, \"dG_eV\": 0.35,\n            \"times_fs\": [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150],\n            \"kappa_t\": [0.0, 0.05, 0.09, 0.11, 0.115, 0.118, 0.12, 0.119, 0.121, 0.120, 0.120, 0.121, 0.1205, 0.1208, 0.1207, 0.1206]\n        },\n        {\n            \"T\": 300, \"dG_eV\": 0.05,\n            \"times_fs\": [0, 20, 40, 60, 80, 100, 120, 140, 160, 180],\n            \"kappa_t\": [0.0, 0.4, 0.55, 0.64, 0.68, 0.70, 0.705, 0.707, 0.707, 0.7075]\n        },\n        {\n            \"T\": 298, \"dG_eV\": 1.00,\n            \"times_fs\": [0, 15, 30, 45, 60, 75, 90, 105, 120, 135, 150, 165],\n            \"kappa_t\": [0.0, 0.2, 0.3, 0.38, 0.40, 0.405, 0.407, 0.408, 0.409, 0.4095, 0.4098, 0.4097]\n        },\n        {\n            \"T\": 330, \"dG_eV\": 0.00,\n            \"times_fs\": [0, 10, 20, 30, 40, 50, 60, 70, 80, 90],\n            \"kappa_t\": [0.0, 0.6, 0.55, 0.52, 0.505, 0.5, 0.501, 0.5005, 0.5002, 0.5001]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        kappa = estimate_kappa(case[\"kappa_t\"])\n        rate_constant = calculate_rate(case[\"T\"], case[\"dG_eV\"], kappa)\n        rounded_rate = round_to_n_significant(rate_constant, 6)\n        results.append(rounded_rate)\n    \n    # Format the final output string\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}