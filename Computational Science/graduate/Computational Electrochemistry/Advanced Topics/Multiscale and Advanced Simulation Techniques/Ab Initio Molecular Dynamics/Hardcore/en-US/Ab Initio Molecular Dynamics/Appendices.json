{
    "hands_on_practices": [
        {
            "introduction": "The reliability of any Ab Initio Molecular Dynamics simulation hinges on a careful balance between computational accuracy and cost. This balance is governed by key numerical parameters, primarily the plane-wave kinetic energy cutoff ($E_{\\text{cut}}$) and the density of the $k$-point mesh for sampling the Brillouin zone. This first practice provides a structured approach to this essential setup phase, framing the convergence test as a formal optimization problem . By working through a realistic model, you will learn to select the most computationally efficient parameters that guarantee the forces and stresses in your system are converged within a desired tolerance, a foundational skill for all subsequent simulation work.",
            "id": "3728689",
            "problem": "You are asked to formalize and solve a convergence study design for Ab Initio Molecular Dynamics (AIMD) applied to a liquid High-Entropy Alloy (HEA). The objective is to determine the minimal plane-wave kinetic energy cutoff and the minimal uniform $k$-point grid per direction that bound the force and stress errors across a set of representative atomic snapshots within specified tolerances. Begin from the definitions of discretization error and computational cost, and formulate a selection rule that minimizes cost subject to error constraints. Then implement this selection rule.\n\nDefinitions and assumptions:\n- Ab Initio Molecular Dynamics (AIMD) computes interatomic forces and stress using electronic structure calculations that employ a plane-wave basis with kinetic energy cutoff and $k$-point sampling in reciprocal space. Discretization of the basis and sampling introduces errors in forces and stress.\n- Let there be $N$ representative snapshots indexed by $s \\in \\{1,\\dots,N\\}$. For a given plane-wave kinetic energy cutoff $E_{\\text{cut}}$ (in eV) and a uniform Monkhorst-Pack $k$-point grid size per direction $K$ (dimensionless integer), the force error at snapshot $s$ is modeled as\n$$\n\\mathcal{E}_f^{(s)}(E_{\\text{cut}},K) = A_s \\, E_{\\text{cut}}^{-p} + B_s \\, K^{-q}\n$$\nand the stress error at snapshot $s$ is modeled as\n$$\n\\mathcal{E}_\\sigma^{(s)}(E_{\\text{cut}},K) = C_s \\, E_{\\text{cut}}^{-p_\\sigma} + D_s \\, K^{-q_\\sigma}.\n$$\nHere $A_s$, $B_s$, $C_s$, and $D_s$ are nonnegative coefficients that encode snapshot-dependent sensitivity, and $p$, $q$, $p_\\sigma$, $q_\\sigma$ are positive exponents describing error decay with increasing $E_{\\text{cut}}$ and $K$.\n- The maximal errors across snapshots are\n$$\n\\mathcal{E}_f^{\\max}(E_{\\text{cut}},K) = \\max_{s} \\mathcal{E}_f^{(s)}(E_{\\text{cut}},K), \\quad \\mathcal{E}_\\sigma^{\\max}(E_{\\text{cut}},K) = \\max_{s} \\mathcal{E}_\\sigma^{(s)}(E_{\\text{cut}},K).\n$$\n- The target tolerances are a force error bound $T_f$ and a stress error bound $T_\\sigma$. The convergence feasibility constraints are\n$$\n\\mathcal{E}_f^{\\max}(E_{\\text{cut}},K) \\le T_f, \\quad \\mathcal{E}_\\sigma^{\\max}(E_{\\text{cut}},K) \\le T_\\sigma.\n$$\n- The computational cost model is\n$$\n\\mathcal{C}(E_{\\text{cut}},K) = \\alpha \\, E_{\\text{cut}}^{3/2} + \\beta \\, K^3,\n$$\nwhere $\\alpha$ and $\\beta$ are positive weights reflecting the scaling of the number of plane waves with $E_{\\text{cut}}$ and the number of sampled points with $K$ per direction.\n- Among candidate values $E_{\\text{cut}} \\in \\mathcal{E}$ and $K \\in \\mathcal{K}$, select the pair $(E_{\\text{cut}}^\\star,K^\\star)$ that satisfies the feasibility constraints and minimizes $\\mathcal{C}(E_{\\text{cut}},K)$. If multiple pairs have identical minimal cost, choose the one with smaller $E_{\\text{cut}}$, and if still tied, choose the one with smaller $K$. If no feasible pair exists, return a sentinel output indicating infeasibility.\n\nScientific units and output specification:\n- Express $E_{\\text{cut}}$ in eV and $K$ as an integer per direction. The force error bound $T_f$ is in meV/Å and the stress error bound $T_\\sigma$ is in GPa. There are no angle quantities in this problem.\n- Your program must compute the selection for each test case below and produce a single line of output containing a comma-separated list of per-test-case results, each result formatted as a two-element list $[E_{\\text{cut}},K]$ with $E_{\\text{cut}}$ represented as a decimal (float) and $K$ as an integer, all enclosed in square brackets. For example, the output line must look like $[[400.0,2],[300.0,1],[0.0,0]]$.\n\nTest suite:\n- Test case $1$ (happy path):\n  - $N = 3$ snapshots, coefficients:\n    - Force: $A = [1600,1400,1500]$ (units meV/Å$\\cdot$eV$^p$), $B = [4.0,6.0,5.0]$ (units meV/Å), exponents $p = 1.0$, $q = 2.0$.\n    - Stress: $C = [20.0,16.0,18.0]$ (units GPa$\\cdot$eV$^{p_\\sigma}$), $D = [0.05,0.07,0.06]$ (units GPa), exponents $p_\\sigma = 0.8$, $q_\\sigma = 1.5$.\n  - Tolerances: $T_f = 5.0$ meV/Å, $T_\\sigma = 0.2$ GPa.\n  - Candidates: $\\mathcal{E} = [300,350,400,450,500,600]$ eV, $\\mathcal{K} = [1,2,3,4,5,6]$.\n  - Cost weights: $\\alpha = 1.0$, $\\beta = 0.08$.\n- Test case $2$ (boundary and tie-possibility):\n  - $N = 2$ snapshots, coefficients:\n    - Force: $A = [1200,1200]$, $B = [0.5,0.5]$, exponents $p = 1.0$, $q = 1.0$.\n    - Stress: $C = [10.0,8.0]$, $D = [0.02,0.02]$, exponents $p_\\sigma = 1.0$, $q_\\sigma = 1.0$.\n  - Tolerances: $T_f = 5.0$ meV/Å, $T_\\sigma = 0.2$ GPa.\n  - Candidates: $\\mathcal{E} = [300,350,400,450,500,600]$ eV, $\\mathcal{K} = [1,2,3,4,5,6]$.\n  - Cost weights: $\\alpha = 1.0$, $\\beta = 0.08$.\n- Test case $3$ (edge case infeasible):\n  - $N = 2$ snapshots, coefficients:\n    - Force: $A = [8000,9000]$, $B = [10.0,10.0]$, exponents $p = 1.0$, $q = 2.0$.\n    - Stress: $C = [100.0,120.0]$, $D = [0.10,0.10]$, exponents $p_\\sigma = 1.0$, $q_\\sigma = 1.0$.\n  - Tolerances: $T_f = 5.0$ meV/Å, $T_\\sigma = 0.2$ GPa.\n  - Candidates: $\\mathcal{E} = [300,350,400,450,500,600]$ eV, $\\mathcal{K} = [1,2,3,4,5,6]$.\n  - Cost weights: $\\alpha = 1.0$, $\\beta = 0.08$.\n- Sentinel output rule: If no feasible pair exists, output $[0.0,0]$ for that test case.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each per-test-case result itself being a two-element list $[E_{\\text{cut}},K]$ as specified, for example $[[400.0,2],[300.0,1],[0.0,0]]$.",
            "solution": "The goal is to design and implement a principled selection of the plane-wave kinetic energy cutoff and $k$-point grid per direction that jointly satisfy error tolerances for forces and stress across representative snapshots, while minimizing a model of computational cost. The scientific basis is the behavior of discretization errors in plane-wave electronic structure calculations and Brillouin zone sampling. In a plane-wave basis, the number of basis functions scales with the volume of reciprocal space inside the kinetic energy sphere, which is proportional to $E_{\\text{cut}}^{3/2}$, and in uniform $k$-point sampling, the number of sampled points grows like $K^3$ for a cubic grid of size $K \\times K \\times K$. These scalings motivate the cost model $\\mathcal{C}(E_{\\text{cut}},K) = \\alpha E_{\\text{cut}}^{3/2} + \\beta K^3$. The discretization errors typically decrease monotonically with $E_{\\text{cut}}$ and $K$, and the provided parametric error model captures this decay: $\\mathcal{E}_f^{(s)} = A_s E_{\\text{cut}}^{-p} + B_s K^{-q}$ and $\\mathcal{E}_\\sigma^{(s)} = C_s E_{\\text{cut}}^{-p_\\sigma} + D_s K^{-q_\\sigma}$ with positive exponents.\n\nPrinciple-based algorithm design:\n- Start from the definitions of maximum errors across snapshots,\n$$\n\\mathcal{E}_f^{\\max}(E_{\\text{cut}},K) = \\max_{s} \\left( A_s E_{\\text{cut}}^{-p} + B_s K^{-q} \\right), \\quad\n\\mathcal{E}_\\sigma^{\\max}(E_{\\text{cut}},K) = \\max_{s} \\left( C_s E_{\\text{cut}}^{-p_\\sigma} + D_s K^{-q_\\sigma} \\right).\n$$\n- The feasibility region in $(E_{\\text{cut}},K)$ is the set where $\\mathcal{E}_f^{\\max}(E_{\\text{cut}},K) \\le T_f$ and $\\mathcal{E}_\\sigma^{\\max}(E_{\\text{cut}},K) \\le T_\\sigma$ simultaneously.\n- Among discrete candidates $E_{\\text{cut}} \\in \\mathcal{E}$ and $K \\in \\mathcal{K}$, select the feasible pair that minimizes $\\mathcal{C}(E_{\\text{cut}},K) = \\alpha E_{\\text{cut}}^{3/2} + \\beta K^3$. If ties occur, prefer smaller $E_{\\text{cut}}$, then smaller $K$.\n\nAlgorithm steps:\n- For each $E_{\\text{cut}} \\in \\mathcal{E}$ and each $K \\in \\mathcal{K}$:\n  - Compute $\\mathcal{E}_f^{\\max}(E_{\\text{cut}},K)$ and $\\mathcal{E}_\\sigma^{\\max}(E_{\\text{cut}},K)$ from the snapshot coefficients and exponents.\n  - Check feasibility: $\\mathcal{E}_f^{\\max}(E_{\\text{cut}},K) \\le T_f$ and $\\mathcal{E}_\\sigma^{\\max}(E_{\\text{cut}},K) \\le T_\\sigma$.\n  - If feasible, evaluate $\\mathcal{C}(E_{\\text{cut}},K)$ and track the minimal cost solution with the specified tie-breaks.\n- If no feasible pair exists, return the sentinel $[0.0,0]$.\n\nValidation on the test suite:\n- Test case $1$:\n  - Parameters: $A = [1600,1400,1500]$, $B = [4.0,6.0,5.0]$, $p = 1.0$, $q = 2.0$; $C = [20.0,16.0,18.0]$, $D = [0.05,0.07,0.06]$, $p_\\sigma = 0.8$, $q_\\sigma = 1.5$; $T_f = 5.0$ meV/Å, $T_\\sigma = 0.2$ GPa; $\\mathcal{E} = [300,350,400,450,500,600]$ eV; $\\mathcal{K} = [1,2,3,4,5,6]$; $\\alpha = 1.0$, $\\beta = 0.08$.\n  - Consider $E_{\\text{cut}} = 400$ eV, $K = 2$. Force errors per snapshot:\n    - Snapshot $1$: $\\mathcal{E}_f^{(1)} = 1600 \\cdot 400^{-1.0} + 4.0 \\cdot 2^{-2.0} = 4.0 + 1.0 = 5.0$ meV/Å.\n    - Snapshot $2$: $\\mathcal{E}_f^{(2)} = 1400 \\cdot 400^{-1.0} + 6.0 \\cdot 2^{-2.0} = 3.5 + 1.5 = 5.0$ meV/Å.\n    - Snapshot $3$: $\\mathcal{E}_f^{(3)} = 1500 \\cdot 400^{-1.0} + 5.0 \\cdot 2^{-2.0} = 3.75 + 1.25 = 5.0$ meV/Å.\n    - Hence $\\mathcal{E}_f^{\\max}(400,2) = 5.0$ meV/Å satisfies $T_f = 5.0$ meV/Å.\n  - Stress errors per snapshot:\n    - Compute $400^{-0.8}$. Using $400^{-0.8} \\approx \\exp(-0.8 \\ln 400) \\approx \\exp(-0.8 \\cdot 5.991) \\approx \\exp(-4.793) \\approx 0.0083$.\n    - $2^{-1.5} = 1 / 2^{1.5} = 1 / (2 \\sqrt{2}) \\approx 1 / 2.828 \\approx 0.3536$.\n    - Snapshot $1$: $\\mathcal{E}_\\sigma^{(1)} = 20.0 \\cdot 0.0083 + 0.05 \\cdot 0.3536 \\approx 0.166 + 0.0177 \\approx 0.1837$ GPa.\n    - Snapshot $2$: $\\mathcal{E}_\\sigma^{(2)} = 16.0 \\cdot 0.0083 + 0.07 \\cdot 0.3536 \\approx 0.133 + 0.0248 \\approx 0.1578$ GPa.\n    - Snapshot $3$: $\\mathcal{E}_\\sigma^{(3)} = 18.0 \\cdot 0.0083 + 0.06 \\cdot 0.3536 \\approx 0.149 + 0.0212 \\approx 0.1702$ GPa.\n    - Hence $\\mathcal{E}_\\sigma^{\\max}(400,2) \\approx 0.1837$ GPa satisfies $T_\\sigma = 0.2$ GPa.\n  - Check whether any lower-cost pair could satisfy both bounds. For $E_{\\text{cut}} = 350$ eV, $A \\cdot 350^{-1.0}$ forces are at least $4.571$ meV/Å for snapshot $1$, and with $K \\ge 2$, the added $B_s K^{-2}$ term increases the error, so the maximum force exceeds $5.0$ meV/Å. For $K = 1$, the $B_s K^{-2}$ term is larger and infeasible. Thus $(400,2)$ is the minimal feasible pair by $E_{\\text{cut}}$ and $K$ among the candidate sets. Its cost is $\\mathcal{C}(400,2) = 1.0 \\cdot 400^{3/2} + 0.08 \\cdot 2^3 = 8000.0 + 0.64 = 8000.64$, and no lower $E_{\\text{cut}}$ or $K$ choice is feasible, making $(400,2)$ the selected pair.\n- Test case $2$:\n  - Parameters: $A = [1200,1200]$, $B = [0.5,0.5]$, $p = 1.0$, $q = 1.0$; $C = [10.0,8.0]$, $D = [0.02,0.02]$, $p_\\sigma = 1.0$, $q_\\sigma = 1.0$; $T_f = 5.0$ meV/Å, $T_\\sigma = 0.2$ GPa; same candidates and cost weights as test case $1$.\n  - Evaluate $(E_{\\text{cut}},K) = (300,1)$:\n    - Force: $\\mathcal{E}_f^{(s)} = 1200 \\cdot 300^{-1.0} + 0.5 \\cdot 1^{-1.0} = 4.0 + 0.5 = 4.5$ meV/Å for both snapshots, hence $\\mathcal{E}_f^{\\max}(300,1) = 4.5 \\le 5.0$ meV/Å.\n    - Stress: snapshot $1$, $\\mathcal{E}_\\sigma^{(1)} = 10.0 \\cdot 300^{-1.0} + 0.02 \\cdot 1^{-1.0} = 0.033\\overline{3} + 0.02 \\approx 0.053\\overline{3}$ GPa; snapshot $2$, $\\mathcal{E}_\\sigma^{(2)} = 8.0 \\cdot 300^{-1.0} + 0.02 = 0.026\\overline{6} + 0.02 \\approx 0.046\\overline{6}$ GPa; thus $\\mathcal{E}_\\sigma^{\\max}(300,1) \\approx 0.053\\overline{3} \\le 0.2$ GPa.\n  - This pair is feasible and has cost $\\mathcal{C}(300,1) = 1.0 \\cdot 300^{3/2} + 0.08 \\cdot 1 = 300 \\cdot \\sqrt{300} + 0.08 \\approx 300 \\cdot 17.3205 + 0.08 \\approx 5196.15 + 0.08 \\approx 5196.23$, which is minimal among feasible pairs because it uses the smallest $E_{\\text{cut}}$ and $K$ that already satisfy the tolerances, and cost increases monotonically with either parameter. Hence $(300,1)$ is selected.\n- Test case $3$:\n  - Parameters: $A = [8000,9000]$, $B = [10.0,10.0]$, $p = 1.0$, $q = 2.0$; $C = [100.0,120.0]$, $D = [0.10,0.10]$, $p_\\sigma = 1.0$, $q_\\sigma = 1.0$; $T_f = 5.0$ meV/Å, $T_\\sigma = 0.2$ GPa; same candidates and cost weights.\n  - Evaluate the most favorable candidate $(E_{\\text{cut}},K) = (600,6)$ for forces:\n    - Snapshot $2$: $\\mathcal{E}_f^{(2)} = 9000 \\cdot 600^{-1.0} + 10.0 \\cdot 6^{-2.0} = 15.0 + 10.0/36 \\approx 15.0 + 0.277\\overline{7} \\approx 15.277\\overline{7}$ meV/Å, which far exceeds $T_f = 5.0$ meV/Å. Thus no candidate can satisfy the force bound, and feasibility fails.\n  - By the sentinel rule, the output for this test case is $[0.0,0]$.\n\nThe algorithm therefore returns the per-test-case selections $[400.0,2]$, $[300.0,1]$, and $[0.0,0]$. The implementation directly evaluates the defined functions over the candidate sets, applies the feasibility constraints, minimizes the cost under tie-break rules, and formats the output as specified.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef select_minimal_cutoff_and_kgrid(A, B, C, D, p, q, p_sigma, q_sigma,\n                                    T_f, T_sigma, E_candidates, K_candidates,\n                                    alpha, beta):\n    \"\"\"\n    Given error model parameters and candidate sets, select the minimal-cost\n    (E_cut, K) satisfying the force and stress tolerances across snapshots.\n    Tie-break by smaller E_cut, then smaller K. If none feasible, return [0.0, 0].\n    \"\"\"\n    # Convert inputs to numpy arrays for vectorized operations\n    A = np.array(A, dtype=float)\n    B = np.array(B, dtype=float)\n    C = np.array(C, dtype=float)\n    D = np.array(D, dtype=float)\n    E_candidates = np.array(E_candidates, dtype=float)\n    K_candidates = np.array(K_candidates, dtype=int)\n\n    best_pair = None\n    best_cost = np.inf\n\n    for E in E_candidates:\n        # Precompute E-dependent factors\n        E_pow_f = E ** (-p)\n        E_pow_sigma = E ** (-p_sigma)\n        for K in K_candidates:\n            # Compute K-dependent factors\n            K_pow_f = K ** (-q)\n            K_pow_sigma = K ** (-q_sigma)\n\n            # Force and stress errors per snapshot\n            force_errors = A * E_pow_f + B * K_pow_f\n            stress_errors = C * E_pow_sigma + D * K_pow_sigma\n\n            max_force_error = np.max(force_errors)\n            max_stress_error = np.max(stress_errors)\n\n            # Check tolerances\n            if (max_force_error <= T_f) and (max_stress_error <= T_sigma):\n                # Compute cost\n                cost = alpha * (E ** 1.5) + beta * (K ** 3)\n                # Update best with tie-breaks: lower cost, then lower E, then lower K\n                if (cost < best_cost) or (\n                    np.isclose(cost, best_cost) and (\n                        (best_pair is None) or (E < best_pair[0]) or (\n                            (np.isclose(E, best_pair[0])) and (K < best_pair[1])\n                        )\n                    )\n                ):\n                    best_cost = cost\n                    best_pair = (float(E), int(K))\n\n    if best_pair is None:\n        return [0.0, 0]\n    else:\n        # Ensure E is printed as float\n        return [float(best_pair[0]), int(best_pair[1])]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"A\": [1600, 1400, 1500],\n            \"B\": [4.0, 6.0, 5.0],\n            \"C\": [20.0, 16.0, 18.0],\n            \"D\": [0.05, 0.07, 0.06],\n            \"p\": 1.0,\n            \"q\": 2.0,\n            \"p_sigma\": 0.8,\n            \"q_sigma\": 1.5,\n            \"T_f\": 5.0,       # meV/Å\n            \"T_sigma\": 0.2,   # GPa\n            \"E_candidates\": [300, 350, 400, 450, 500, 600],  # eV\n            \"K_candidates\": [1, 2, 3, 4, 5, 6],              # per-direction\n            \"alpha\": 1.0,\n            \"beta\": 0.08\n        },\n        {\n            \"A\": [1200, 1200],\n            \"B\": [0.5, 0.5],\n            \"C\": [10.0, 8.0],\n            \"D\": [0.02, 0.02],\n            \"p\": 1.0,\n            \"q\": 1.0,\n            \"p_sigma\": 1.0,\n            \"q_sigma\": 1.0,\n            \"T_f\": 5.0,       # meV/Å\n            \"T_sigma\": 0.2,   # GPa\n            \"E_candidates\": [300, 350, 400, 450, 500, 600],  # eV\n            \"K_candidates\": [1, 2, 3, 4, 5, 6],              # per-direction\n            \"alpha\": 1.0,\n            \"beta\": 0.08\n        },\n        {\n            \"A\": [8000, 9000],\n            \"B\": [10.0, 10.0],\n            \"C\": [100.0, 120.0],\n            \"D\": [0.10, 0.10],\n            \"p\": 1.0,\n            \"q\": 2.0,\n            \"p_sigma\": 1.0,\n            \"q_sigma\": 1.0,\n            \"T_f\": 5.0,       # meV/Å\n            \"T_sigma\": 0.2,   # GPa\n            \"E_candidates\": [300, 350, 400, 450, 500, 600],  # eV\n            \"K_candidates\": [1, 2, 3, 4, 5, 6],              # per-direction\n            \"alpha\": 1.0,\n            \"beta\": 0.08\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = select_minimal_cutoff_and_kgrid(\n            A=case[\"A\"], B=case[\"B\"], C=case[\"C\"], D=case[\"D\"],\n            p=case[\"p\"], q=case[\"q\"], p_sigma=case[\"p_sigma\"], q_sigma=case[\"q_sigma\"],\n            T_f=case[\"T_f\"], T_sigma=case[\"T_sigma\"],\n            E_candidates=case[\"E_candidates\"], K_candidates=case[\"K_candidates\"],\n            alpha=case[\"alpha\"], beta=case[\"beta\"]\n        )\n        results.append(result)\n\n    # Format results as specified: single line, comma-separated, list of [E_cut,K] with no spaces.\n    formatted = \"[\" + \",\".join(f\"[{res[0]:.1f},{res[1]}]\" for res in results) + \"]\"\n    print(formatted)\n\nsolve()\n```"
        },
        {
            "introduction": "Once simulation parameters are converged, the next critical step is to validate the stability and physical realism of the time evolution itself. In a microcanonical (NVE) ensemble, the total energy of the system must be conserved. This exercise explores the primary sources of numerical error that lead to unphysical energy drift: the finite integration time step, $\\Delta t$, and the electronic self-consistent field (SCF) convergence tolerance, $\\tau$ . By fitting a physically-motivated model to simulation data, you will develop the practical ability to diagnose and control energy drift, thereby ensuring the long-term accuracy and trustworthiness of your AIMD trajectories.",
            "id": "3728716",
            "problem": "Consider a Born-Oppenheimer Molecular Dynamics (BOMD) simulation in the microcanonical ensemble (constant number of particles, volume, and energy; NVE) for a high-entropy alloy composed of $128$ atoms. The total energy of the system should be conserved in an ideal continuous-time evolution under exact Self-Consistent Field (SCF) convergence and exact forces. In practice, two sources of systematic numerical error contribute to energy drift: the finite time step $\\Delta t$ of the integrator and the finite SCF convergence tolerance $\\tau$ of the electronic structure solver. For sufficiently small $\\Delta t$ and tight SCF tolerance, the energy drift rate per atom can be approximated by a model that is linear in the dominant small-error contributions. Assuming a velocity-Verlet integrator (which has a local truncation error of order $\\mathcal{O}((\\Delta t)^3)$ and a global energy error scaling as $\\mathcal{O}((\\Delta t)^2)$ for well-behaved forces) and a residual force error that scales approximately linearly with the SCF energy tolerance, adopt the following linearized drift-rate model:\n$$\nr(\\Delta t,\\tau) = \\alpha\\,(\\Delta t)^2 + \\beta\\,\\tau + \\gamma,\n$$\nwhere $r$ is the energy drift rate in meV/atom/ns, $\\Delta t$ is the time step in fs (femtoseconds), $\\tau$ is the SCF energy tolerance in eV (electronvolts), and $\\alpha$, $\\beta$, $\\gamma$ are parameters to be determined.\n\nYou are provided with calibration measurements of the energy drift rate $r$ for a set of $(\\Delta t,\\tau)$ pairs obtained from short NVE BOMD runs on the $128$-atom high-entropy alloy. All listed $r$ values are per atom in meV/atom/ns. Use these calibration data to fit the linear model parameters $\\alpha$, $\\beta$, and $\\gamma$ via least squares:\n- $(\\Delta t=0.5\\,\\text{fs}, \\tau=1\\times 10^{-5}\\,\\text{eV}) \\rightarrow r=0.1625$\n- $(\\Delta t=0.5\\,\\text{fs}, \\tau=5\\times 10^{-5}\\,\\text{eV}) \\rightarrow r=0.3625$\n- $(\\Delta t=0.5\\,\\text{fs}, \\tau=1\\times 10^{-4}\\,\\text{eV}) \\rightarrow r=0.6125$\n- $(\\Delta t=0.5\\,\\text{fs}, \\tau=5\\times 10^{-4}\\,\\text{eV}) \\rightarrow r=2.6125$\n- $(\\Delta t=1.0\\,\\text{fs}, \\tau=1\\times 10^{-5}\\,\\text{eV}) \\rightarrow r=0.3500$\n- $(\\Delta t=1.0\\,\\text{fs}, \\tau=5\\times 10^{-5}\\,\\text{eV}) \\rightarrow r=0.5500$\n- $(\\Delta t=1.0\\,\\text{fs}, \\tau=1\\times 10^{-4}\\,\\text{eV}) \\rightarrow r=0.8000$\n- $(\\Delta t=1.0\\,\\text{fs}, \\tau=5\\times 10^{-4}\\,\\text{eV}) \\rightarrow r=2.8000$\n- $(\\Delta t=2.0\\,\\text{fs}, \\tau=1\\times 10^{-5}\\,\\text{eV}) \\rightarrow r=1.1000$\n- $(\\Delta t=2.0\\,\\text{fs}, \\tau=5\\times 10^{-5}\\,\\text{eV}) \\rightarrow r=1.3000$\n- $(\\Delta t=2.0\\,\\text{fs}, \\tau=1\\times 10^{-4}\\,\\text{eV}) \\rightarrow r=1.5500$\n- $(\\Delta t=2.0\\,\\text{fs}, \\tau=5\\times 10^{-4}\\,\\text{eV}) \\rightarrow r=3.5500$\n\nAfter fitting $\\alpha$, $\\beta$, and $\\gamma$, quantify the energy drift for specified test $(\\Delta t,\\tau)$ pairs by evaluating $r(\\Delta t,\\tau)$. Furthermore, derive a recommendation for the maximum allowable time step $\\Delta t_{\\max}$ as a function of SCF tolerance $\\tau$ such that the drift rate remains below a target threshold $r_{\\text{thr}}=1\\,\\text{meV/atom/ns}$. Using the fitted model, this recommendation must satisfy:\n$$\n\\Delta t_{\\max}(\\tau) = \n\\begin{cases}\n\\sqrt{\\dfrac{r_{\\text{thr}} - \\beta\\,\\tau - \\gamma}{\\alpha}}, & \\text{if } r_{\\text{thr}} - \\beta\\,\\tau - \\gamma > 0,\\\\[8pt]\n0, & \\text{otherwise,}\n\\end{cases}\n$$\nwith $\\Delta t_{\\max}$ expressed in fs.\n\nYour program must perform the following steps:\n1. Fit the parameters $\\alpha$, $\\beta$, and $\\gamma$ using the calibration dataset above.\n2. Compute the predicted drift rates $r(\\Delta t,\\tau)$ for the following test pairs:\n   - $\\Delta t=1.0\\,\\text{fs}$, $\\tau=1\\times 10^{-5}\\,\\text{eV}$,\n   - $\\Delta t=2.0\\,\\text{fs}$, $\\tau=1\\times 10^{-5}\\,\\text{eV}$,\n   - $\\Delta t=1.5\\,\\text{fs}$, $\\tau=1\\times 10^{-4}\\,\\text{eV}$.\n   Report each $r$ in meV/atom/ns.\n3. Compute the recommended $\\Delta t_{\\max}$ for the following SCF tolerances to keep the drift below $r_{\\text{thr}}=1\\,\\text{meV/atom/ns}$:\n   - $\\tau=1\\times 10^{-5}\\,\\text{eV}$,\n   - $\\tau=5\\times 10^{-5}\\,\\text{eV}$,\n   - $\\tau=1\\times 10^{-4}\\,\\text{eV}$,\n   - $\\tau=5\\times 10^{-4}\\,\\text{eV}$.\n   Report each $\\Delta t_{\\max}$ in fs.\n\nAll numerical answers must be floats rounded to six decimal places. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the following order: the three predicted drift rates followed by the four recommended maximum time steps, i.e., $[r_{1},r_{2},r_{3},\\Delta t_{\\max,1},\\Delta t_{\\max,2},\\Delta t_{\\max,3},\\Delta t_{\\max,4}]$.",
            "solution": "The problem requires us to determine the parameters of a linear model for energy drift in a Born-Oppenheimer Molecular Dynamics (BOMD) simulation and then use this model for prediction and to establish operational constraints. The analysis proceeds in two main stages: first, fitting the model parameters using the method of linear least squares, and second, applying the fitted model to answer the specific questions posed.\n\nThe proposed model for the energy drift rate per atom, $r$, is given by:\n$$\nr(\\Delta t, \\tau) = \\alpha (\\Delta t)^2 + \\beta \\tau + \\gamma\n$$\nwhere $\\Delta t$ is the integration time step in femtoseconds (fs), $\\tau$ is the Self-Consistent Field (SCF) energy convergence tolerance in electronvolts (eV), and $r$ is the drift rate in meV/atom/ns. The parameters to be determined are $\\alpha$, $\\beta$, and $\\gamma$. This model is linear with respect to the parameters. The term $(\\Delta t)^2$ is physically motivated by the global energy error scaling of the velocity-Verlet integrator, and the linear dependence on $\\tau$ is a reasonable first-order approximation for the influence of incomplete SCF convergence on atomic forces.\n\nWe are given $12$ calibration data points of the form $((\\Delta t)_i, \\tau_i, r_i)$, for $i=1, \\dots, 12$. To find the best-fit parameters $\\alpha$, $\\beta$, and $\\gamma$, we employ the method of linear least squares. This method minimizes the sum of the squared differences between the observed drift rates $r_i$ and the rates predicted by the model.\n\nLet us define a parameter vector $\\mathbf{p}$ and a feature vector $\\mathbf{x}_i$ for each data point:\n$$\n\\mathbf{p} = \\begin{pmatrix} \\alpha \\\\ \\beta \\\\ \\gamma \\end{pmatrix}, \\quad \\mathbf{x}_i = \\begin{pmatrix} (\\Delta t_i)^2 \\\\ \\tau_i \\\\ 1 \\end{pmatrix}\n$$\nThe model can then be expressed as $r_i \\approx \\mathbf{x}_i^T \\mathbf{p}$. We can assemble all $12$ equations into a single matrix equation:\n$$\n\\mathbf{A} \\mathbf{p} = \\mathbf{b}\n$$\nwhere $\\mathbf{A}$ is the $12 \\times 3$ design matrix whose rows are the feature vectors $\\mathbf{x}_i^T$, and $\\mathbf{b}$ is the $12 \\times 1$ vector of observed drift rates $r_i$.\n\n$$\n\\mathbf{A} = \\begin{pmatrix}\n(\\Delta t_1)^2 & \\tau_1 & 1 \\\\\n(\\Delta t_2)^2 & \\tau_2 & 1 \\\\\n\\vdots & \\vdots & \\vdots \\\\\n(\\Delta t_{12})^2 & \\tau_{12} & 1\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n(0.5)^2 & 1 \\times 10^{-5} & 1 \\\\\n(0.5)^2 & 5 \\times 10^{-5} & 1 \\\\\n(0.5)^2 & 1 \\times 10^{-4} & 1 \\\\\n(0.5)^2 & 5 \\times 10^{-4} & 1 \\\\\n(1.0)^2 & 1 \\times 10^{-5} & 1 \\\\\n(1.0)^2 & 5 \\times 10^{-5} & 1 \\\\\n(1.0)^2 & 1 \\times 10^{-4} & 1 \\\\\n(1.0)^2 & 5 \\times 10^{-4} & 1 \\\\\n(2.0)^2 & 1 \\times 10^{-5} & 1 \\\\\n(2.0)^2 & 5 \\times 10^{-5} & 1 \\\\\n(2.0)^2 & 1 \\times 10^{-4} & 1 \\\\\n(2.0)^2 & 5 \\times 10^{-4} & 1\n\\end{pmatrix},\n\\quad\n\\mathbf{b} = \\begin{pmatrix}\n0.1625 \\\\ 0.3625 \\\\ 0.6125 \\\\ 2.6125 \\\\\n0.3500 \\\\ 0.5500 \\\\ 0.8000 \\\\ 2.8000 \\\\\n1.1000 \\\\ 1.3000 \\\\ 1.5500 \\\\ 3.5500\n\\end{pmatrix}\n$$\n\nThe least squares solution $\\mathbf{p}$ minimizes the Euclidean norm of the residual vector, $||\\mathbf{A} \\mathbf{p} - \\mathbf{b}||_2$. The solution is found by solving the normal equations:\n$$\n(\\mathbf{A}^T \\mathbf{A}) \\mathbf{p} = \\mathbf{A}^T \\mathbf{b}\n$$\nSolving this system of linear equations for $\\mathbf{p}$ yields the values for $\\alpha$, $\\beta$, and $\\gamma$. Performing this calculation with the given data results in:\n$$\n\\alpha = 0.25 \\, \\frac{\\text{meV/atom/ns}}{\\text{fs}^2}\n$$\n$$\n\\beta = 5000 \\, \\frac{\\text{meV/atom/ns}}{\\text{eV}}\n$$\n$$\n\\gamma = 0.05 \\, \\text{meV/atom/ns}\n$$\nThe data provided are perfectly described by these parameters, indicating no random noise in the calibration set. The fitted model is thus:\n$$\nr(\\Delta t, \\tau) = 0.25 (\\Delta t)^2 + 5000 \\tau + 0.05\n$$\n\nWith the model parameterized, we can proceed to the required calculations.\n\n**1. Predicted Drift Rates**\n\nWe compute the drift rate $r$ for three test pairs $(\\Delta t, \\tau)$:\n- For $(\\Delta t=1.0\\,\\text{fs}, \\tau=1 \\times 10^{-5}\\,\\text{eV})$:\n$$\nr_1 = 0.25 (1.0)^2 + 5000 (1 \\times 10^{-5}) + 0.05 = 0.25 + 0.05 + 0.05 = 0.35 \\, \\text{meV/atom/ns}\n$$\n- For $(\\Delta t=2.0\\,\\text{fs}, \\tau=1 \\times 10^{-5}\\,\\text{eV})$:\n$$\nr_2 = 0.25 (2.0)^2 + 5000 (1 \\times 10^{-5}) + 0.05 = 0.25(4) + 0.05 + 0.05 = 1.0 + 0.05 + 0.05 = 1.10 \\, \\text{meV/atom/ns}\n$$\n- For $(\\Delta t=1.5\\,\\text{fs}, \\tau=1 \\times 10^{-4}\\,\\text{eV})$:\n$$\nr_3 = 0.25 (1.5)^2 + 5000 (1 \\times 10^{-4}) + 0.05 = 0.25(2.25) + 0.5 + 0.05 = 0.5625 + 0.5 + 0.05 = 1.1125 \\, \\text{meV/atom/ns}\n$$\n\n**2. Recommended Maximum Time Step**\n\nWe need to find the maximum time step $\\Delta t_{\\max}$ for a given tolerance $\\tau$ such that the drift rate does not exceed a threshold $r_{\\text{thr}} = 1.0\\,\\text{meV/atom/ns}$. We start from the model and solve for $\\Delta t$:\n$$\nr_{\\text{thr}} \\ge 0.25 (\\Delta t)^2 + 5000 \\tau + 0.05\n$$\n$$\n(\\Delta t)^2 \\le \\frac{r_{\\text{thr}} - 5000 \\tau - 0.05}{0.25}\n$$\nFor $\\Delta t$ to be real, the numerator must be non-negative. This gives the expression for $\\Delta t_{\\max}$:\n$$\n\\Delta t_{\\max}(\\tau) = \\begin{cases}\n\\sqrt{\\dfrac{1.0 - 5000 \\tau - 0.05}{0.25}} = \\sqrt{4 (0.95 - 5000 \\tau)} = 2\\sqrt{0.95 - 5000 \\tau}, & \\text{if } 0.95 - 5000 \\tau > 0 \\\\\n0, & \\text{otherwise}\n\\end{cases}\n$$\nThe condition $0.95 - 5000 \\tau > 0$ implies $\\tau < \\frac{0.95}{5000} = 1.9 \\times 10^{-4}$ eV.\n\nWe now compute $\\Delta t_{\\max}$ for the four given values of $\\tau$:\n\n- For $\\tau = 1 \\times 10^{-5}\\,\\text{eV}$: The condition is met.\n$$\n\\Delta t_{\\max,1} = 2\\sqrt{0.95 - 5000(1 \\times 10^{-5})} = 2\\sqrt{0.95 - 0.05} = 2\\sqrt{0.90} \\approx 1.897367 \\, \\text{fs}\n$$\n- For $\\tau = 5 \\times 10^{-5}\\,\\text{eV}$: The condition is met.\n$$\n\\Delta t_{\\max,2} = 2\\sqrt{0.95 - 5000(5 \\times 10^{-5})} = 2\\sqrt{0.95 - 0.25} = 2\\sqrt{0.70} \\approx 1.673320 \\, \\text{fs}\n$$\n- For $\\tau = 1 \\times 10^{-4}\\,\\text{eV}$: The condition is met.\n$$\n\\Delta t_{\\max,3} = 2\\sqrt{0.95 - 5000(1 \\times 10^{-4})} = 2\\sqrt{0.95 - 0.50} = 2\\sqrt{0.45} \\approx 1.341641 \\, \\text{fs}\n$$\n- For $\\tau = 5 \\times 10^{-4}\\,\\text{eV}$: $5000 \\tau = 2.5$, which is greater than $0.95$. The numerator is negative.\n$$\n\\Delta t_{\\max,4} = 0 \\, \\text{fs}\n$$\n\nThe final collection of results, rounded to six decimal places, is: $r_1=0.350000$, $r_2=1.100000$, $r_3=1.112500$, $\\Delta t_{\\max,1}=1.897367$, $\\Delta t_{\\max,2}=1.673320$, $\\Delta t_{\\max,3}=1.341641$, and $\\Delta t_{\\max,4}=0.000000$.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of fitting an energy drift model for BOMD simulations\n    and using it for prediction and constraint derivation.\n    \"\"\"\n    \n    # --- Step 1: Fit the model parameters using least squares ---\n    \n    # Calibration data: (delta_t, tau, r)\n    # delta_t is in fs, tau in eV, r in meV/atom/ns.\n    calibration_data = [\n        (0.5, 1e-5, 0.1625),\n        (0.5, 5e-5, 0.3625),\n        (0.5, 1e-4, 0.6125),\n        (0.5, 5e-4, 2.6125),\n        (1.0, 1e-5, 0.3500),\n        (1.0, 5e-5, 0.5500),\n        (1.0, 1e-4, 0.8000),\n        (1.0, 5e-4, 2.8000),\n        (2.0, 1e-5, 1.1000),\n        (2.0, 5e-5, 1.3000),\n        (2.0, 1e-4, 1.5500),\n        (2.0, 5e-4, 3.5500),\n    ]\n\n    # The model is r = alpha * (delta_t)^2 + beta * tau + gamma\n    # This is a linear model in the parameters (alpha, beta, gamma).\n    # We set up the linear system A * p = b, where p = [alpha, beta, gamma].\n    \n    num_points = len(calibration_data)\n    A = np.zeros((num_points, 3))\n    b = np.zeros(num_points)\n    \n    for i, (dt, tau, r) in enumerate(calibration_data):\n        A[i, 0] = dt**2\n        A[i, 1] = tau\n        A[i, 2] = 1\n        b[i] = r\n        \n    # Solve the least squares problem A*p = b for p\n    params, _, _, _ = np.linalg.lstsq(A, b, rcond=None)\n    alpha, beta, gamma = params\n\n    # --- Step 2: Compute predicted drift rates for test cases ---\n    \n    test_rates_inputs = [\n        (1.0, 1e-5),  # (delta_t, tau)\n        (2.0, 1e-5),\n        (1.5, 1e-4),\n    ]\n    \n    predicted_rates = []\n    for dt, tau in test_rates_inputs:\n        rate = alpha * dt**2 + beta * tau + gamma\n        predicted_rates.append(rate)\n\n    # --- Step 3: Compute recommended max time step ---\n\n    r_thr = 1.0  # meV/atom/ns\n    \n    test_dtmax_inputs = [\n        1e-5,  # tau in eV\n        5e-5,\n        1e-4,\n        5e-4,\n    ]\n    \n    recommended_dtmax = []\n    for tau in test_dtmax_inputs:\n        # dt_max = sqrt((r_thr - beta*tau - gamma) / alpha)\n        numerator = r_thr - beta * tau - gamma\n        if numerator > 0:\n            dt_max = np.sqrt(numerator / alpha)\n        else:\n            dt_max = 0.0\n        recommended_dtmax.append(dt_max)\n        \n    # Combine all results\n    all_results = predicted_rates + recommended_dtmax\n    \n    # Format the output as specified\n    formatted_results = [f\"{res:.6f}\" for res in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The power of AIMD lies in its ability to predict macroscopic material properties from the underlying quantum mechanical motion of atoms. This final practice guides you through one of the most common applications: calculating transport properties like the diffusion coefficient, $D$. Starting from the mean-squared displacement (MSD) data obtained from a trajectory, you will use the Einstein relation to compute $D$ . Crucially, this exercise also introduces the concept of finite-size effects and their correction, demonstrating how to use the Yeh–Hummer formula to extrapolate the result from a finite simulation cell to the macroscopic, thermodynamic limit, a vital step for comparing computational predictions with experimental data.",
            "id": "2448227",
            "problem": "You are given a set of synthetic but physically grounded trajectory summary data representing the motion of a single lithium ion, $\\mathrm{Li}^+$, in liquid water as would be obtained from Ab Initio Molecular Dynamics (AIMD). The motion is in three spatial dimensions under periodic boundary conditions in a cubic simulation cell of side length $L$. The goal is to estimate the diffusion coefficient in the thermodynamic (infinite-system) limit from the long-time behavior of the mean squared displacement using first principles and quantify the finite-size effect due to hydrodynamic interactions under periodic boundary conditions.\n\nDefinitions and constants:\n- The diffusion coefficient $D$ in three dimensions is defined via the Einstein relation: $D = \\lim_{t \\to \\infty} \\frac{1}{6}\\frac{\\mathrm{d}}{\\mathrm{d}t}\\langle \\Delta r(t)^2 \\rangle$, where $\\langle \\Delta r(t)^2 \\rangle$ is the mean squared displacement (MSD).\n- For a finite periodic cubic cell of side length $L$, the Yeh–Hummer hydrodynamic finite-size correction relates the finite-system diffusion coefficient $D_L$ to the infinite-system diffusion coefficient $D_{\\infty}$ by $D_{\\infty} = D_L + \\frac{k_{\\mathrm{B}} T \\,\\xi}{6\\pi \\eta L}$, where $k_{\\mathrm{B}}$ is the Boltzmann constant, $T$ is the absolute temperature, $\\eta$ is the shear viscosity, and $\\xi \\approx 2.837297$ for a cubic lattice.\n- Use $k_{\\mathrm{B}} = 1.380649\\times 10^{-23}\\ \\mathrm{J\\,K^{-1}}$ and $\\xi = 2.837297$.\n- Units: The time array $t$ is provided in picoseconds (ps), the mean squared displacement values $\\langle \\Delta r^2 \\rangle$ are provided in square nanometers ($\\mathrm{nm}^2$), the box length $L$ is provided in nanometers (nm), the viscosity $\\eta$ is provided in Pascal-second ($\\mathrm{Pa\\,s}$), and the temperature $T$ is provided in Kelvin (K). Your program must output $D_{\\infty}$ in square meters per second ($\\mathrm{m}^2\\,\\mathrm{s}^{-1}$). Angles are not involved. No percentages are involved.\n- For each case, $D_L$ must be obtained from the best-fit slope of the linear function of $\\langle \\Delta r^2 \\rangle$ versus $t$ over the specified fitting interval $[t_{\\min}, t_{\\max}]$ as implied by the Einstein relation. The conversion between units must be carried out exactly: $1\\ \\mathrm{nm}^2 / \\mathrm{ps} = 10^{-6}\\ \\mathrm{m}^2 / \\mathrm{s}$.\n\nWrite a program that, for each test case below, computes $D_L$ from the linear fit and then computes $D_{\\infty}$ using the Yeh–Hummer correction. Report the final $D_{\\infty}$ values in $\\mathrm{m}^2\\,\\mathrm{s}^{-1}$, rounded to six significant figures.\n\nTest suite (each case is independent):\n\nCase $1$:\n- $T = 300\\ \\mathrm{K}$, $\\eta = 0.00089\\ \\mathrm{Pa\\,s}$, $L = 1.5\\ \\mathrm{nm}$.\n- $t\\ \\mathrm{(ps)} = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]$.\n- $\\langle \\Delta r^2 \\rangle\\ \\mathrm{(nm^2)} = [0.0, 0.0072, 0.0144, 0.0216, 0.0288, 0.0360, 0.0432, 0.0504, 0.0576, 0.0648, 0.0720]$.\n- Fit interval: $t_{\\min} = 0\\ \\mathrm{ps}$, $t_{\\max} = 10\\ \\mathrm{ps}$.\n\nCase $2$:\n- $T = 300\\ \\mathrm{K}$, $\\eta = 0.00089\\ \\mathrm{Pa\\,s}$, $L = 1.0\\ \\mathrm{nm}$.\n- $t\\ \\mathrm{(ps)} = [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0]$.\n- $\\langle \\Delta r^2 \\rangle\\ \\mathrm{(nm^2)} = [0.0, 0.0036, 0.0072, 0.0108, 0.0144, 0.0180, 0.0216]$.\n- Fit interval: $t_{\\min} = 0.0\\ \\mathrm{ps}$, $t_{\\max} = 3.0\\ \\mathrm{ps}$.\n\nCase $3$:\n- $T = 300\\ \\mathrm{K}$, $\\eta = 0.00089\\ \\mathrm{Pa\\,s}$, $L = 6.0\\ \\mathrm{nm}$.\n- $t\\ \\mathrm{(ps)} = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]$.\n- $\\langle \\Delta r^2 \\rangle\\ \\mathrm{(nm^2)} = [0.0, 0.0072, 0.0144, 0.0216, 0.0288, 0.0360, 0.0432, 0.0504, 0.0576, 0.0648, 0.0720]$.\n- Fit interval: $t_{\\min} = 0\\ \\mathrm{ps}$, $t_{\\max} = 10\\ \\mathrm{ps}$.\n\nCase $4$:\n- $T = 320\\ \\mathrm{K}$, $\\eta = 0.00065\\ \\mathrm{Pa\\,s}$, $L = 2.0\\ \\mathrm{nm}$.\n- $t\\ \\mathrm{(ps)} = [0.0, 2.0, 4.0, 6.0, 8.0]$.\n- $\\langle \\Delta r^2 \\rangle\\ \\mathrm{(nm^2)} = [0.0, 0.0096, 0.0192, 0.0288, 0.0384]$.\n- Fit interval: $t_{\\min} = 0.0\\ \\mathrm{ps}$, $t_{\\max} = 8.0\\ \\mathrm{ps}$.\n\nRequired final output format:\n- Your program should produce a single line of output containing the results as a comma-separated list of the $D_{\\infty}$ values for Cases $1$ through $4$, in order, enclosed in square brackets and with each number rounded to six significant figures, for example, $[a,b,c,d]$ where $a$, $b$, $c$, and $d$ are floats in $\\mathrm{m}^2\\,\\mathrm{s}^{-1}$.",
            "solution": "We begin from first principles. For Brownian motion in three spatial dimensions, the diffusion coefficient $D$ is defined by the Einstein relation,\n$$\nD \\equiv \\lim_{t \\to \\infty} \\frac{1}{6}\\frac{\\mathrm{d}}{\\mathrm{d}t}\\langle \\Delta r(t)^2 \\rangle,\n$$\nwhere $\\langle \\Delta r(t)^2 \\rangle$ is the mean squared displacement (MSD) of the particle. In practice, on an interval of times where the MSD is linear in $t$ (the diffusive regime), the MSD can be modeled as a linear function,\n$$\n\\langle \\Delta r(t)^2 \\rangle \\approx s t + b,\n$$\nwith slope $s$ and intercept $b$. The finite-system diffusion coefficient $D_L$ is then\n$$\nD_L = s/6.\n$$\nBecause the provided times $t$ are given in picoseconds and the MSD values are given in square nanometers, $D_L$ computed as $s/6$ will have units of $\\mathrm{nm}^2/\\mathrm{ps}$. The exact unit conversion to obtain $D_L$ in $\\mathrm{m}^2\\,\\mathrm{s}^{-1}$ is\n$$\n1\\ \\frac{\\mathrm{nm}^2}{\\mathrm{ps}} = 10^{-6}\\ \\frac{\\mathrm{m}^2}{\\mathrm{s}},\n$$\nso\n$$\nD_L\\ \\big[\\mathrm{m}^2\\,\\mathrm{s}^{-1}\\big] = \\frac{s}{6} \\times 10^{-6}.\n$$\n\nUnder periodic boundary conditions in a cubic cell of edge length $L$, hydrodynamic interactions lead to a finite-size bias. The Yeh–Hummer correction gives the leading-order relationship between the finite-system diffusion coefficient $D_L$ and the infinite-system coefficient $D_{\\infty}$,\n$$\nD_{\\infty} = D_L + \\frac{k_{\\mathrm{B}} T \\,\\xi}{6\\pi \\eta L},\n$$\nwhere $k_{\\mathrm{B}}$ is the Boltzmann constant, $T$ is temperature, $\\eta$ is the shear viscosity, and $\\xi \\approx 2.837297$ for cubic periodic boundary conditions. In this formula, $L$ must be in meters, $\\eta$ in $\\mathrm{Pa\\,s}$, $T$ in $\\mathrm{K}$, and $k_{\\mathrm{B}}$ in $\\mathrm{J\\,K^{-1}}$, yielding a correction in $\\mathrm{m}^2\\,\\mathrm{s}^{-1}$.\n\nAlgorithmic steps derived from these principles for each case:\n1. Select the data points with times $t$ in the specified fitting interval $[t_{\\min}, t_{\\max}]$.\n2. Perform a least-squares linear fit of $\\langle \\Delta r^2 \\rangle$ versus $t$ to obtain the slope $s$ in $\\mathrm{nm}^2/\\mathrm{ps}$.\n3. Compute $D_L$ in $\\mathrm{m}^2\\,\\mathrm{s}^{-1}$ using $D_L = (s/6)\\times 10^{-6}$.\n4. Convert the box length $L$ from $\\mathrm{nm}$ to $\\mathrm{m}$ using $L_{\\mathrm{m}} = L \\times 10^{-9}$.\n5. Compute the Yeh–Hummer correction term,\n$$\n\\Delta D = \\frac{k_{\\mathrm{B}} T \\,\\xi}{6\\pi \\eta L_{\\mathrm{m}}}.\n$$\n6. Compute $D_{\\infty} = D_L + \\Delta D$.\n7. Round $D_{\\infty}$ to six significant figures and report it in $\\mathrm{m}^2\\,\\mathrm{s}^{-1}$.\n\nApplying this to the test suite:\n- In Cases $1$, $2$, and $3$, the MSD sequences are exactly linear with slope $s = 0.0072\\ \\mathrm{nm}^2/\\mathrm{ps}$, corresponding to $D_L = (0.0072/6)\\times 10^{-6} = 1.2\\times 10^{-9}\\ \\mathrm{m}^2\\,\\mathrm{s}^{-1}$. The finite-size corrections differ due to different $L$ values: smaller $L$ increases the correction, and larger $L$ reduces it. Specifically, the correction scales as $1/L$ at fixed $T$ and $\\eta$.\n- In Case $4$, the MSD is linear with slope $s = 0.0048\\ \\mathrm{nm}^2/\\mathrm{ps}$, yielding $D_L = 0.8\\times 10^{-9}\\ \\mathrm{m}^2\\,\\mathrm{s}^{-1}$ before correction. The correction increases with $T$ and decreases with $\\eta$ and $L$, per the formula.\n\nThe program will implement the linear regression using least squares, apply the exact unit conversions and constants $k_{\\mathrm{B}} = 1.380649\\times 10^{-23}\\ \\mathrm{J\\,K^{-1}}$ and $\\xi = 2.837297$, and print the four corrected diffusion coefficients $D_{\\infty}$ as a single list on one line in the format required.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_d_infinity(t_ps, msd_nm2, tmin_ps, tmax_ps, T_K, eta_Pa_s, L_nm):\n    # Select data within the fit interval [tmin_ps, tmax_ps]\n    t = np.array(t_ps, dtype=float)\n    msd = np.array(msd_nm2, dtype=float)\n    mask = (t >= tmin_ps) & (t <= tmax_ps)\n    t_fit = t[mask]\n    msd_fit = msd[mask]\n\n    # Linear least squares fit: msd = slope * t + intercept\n    # slope has units of nm^2/ps\n    slope, intercept = np.polyfit(t_fit, msd_fit, 1)\n\n    # Convert slope to D_L: D_L = (slope / 6) * 1e-6  [m^2/s]\n    D_L = (slope / 6.0) * 1e-6  # m^2/s\n\n    # Yeh–Hummer correction: D_inf = D_L + kB * T * xi / (6 * pi * eta * L)\n    kB = 1.380649e-23  # J/K\n    xi = 2.837297\n    pi = np.pi\n    L_m = L_nm * 1e-9  # convert nm to m\n\n    correction = kB * T_K * xi / (6.0 * pi * eta_Pa_s * L_m)  # m^2/s\n\n    D_inf = D_L + correction\n    return D_inf\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1\n        {\n            \"T_K\": 300.0,\n            \"eta_Pa_s\": 0.00089,\n            \"L_nm\": 1.5,\n            \"t_ps\": [0,1,2,3,4,5,6,7,8,9,10],\n            \"msd_nm2\": [0.0,0.0072,0.0144,0.0216,0.0288,0.0360,0.0432,0.0504,0.0576,0.0648,0.0720],\n            \"tmin_ps\": 0.0,\n            \"tmax_ps\": 10.0\n        },\n        # Case 2\n        {\n            \"T_K\": 300.0,\n            \"eta_Pa_s\": 0.00089,\n            \"L_nm\": 1.0,\n            \"t_ps\": [0.0,0.5,1.0,1.5,2.0,2.5,3.0],\n            \"msd_nm2\": [0.0,0.0036,0.0072,0.0108,0.0144,0.0180,0.0216],\n            \"tmin_ps\": 0.0,\n            \"tmax_ps\": 3.0\n        },\n        # Case 3\n        {\n            \"T_K\": 300.0,\n            \"eta_Pa_s\": 0.00089,\n            \"L_nm\": 6.0,\n            \"t_ps\": [0,1,2,3,4,5,6,7,8,9,10],\n            \"msd_nm2\": [0.0,0.0072,0.0144,0.0216,0.0288,0.0360,0.0432,0.0504,0.0576,0.0648,0.0720],\n            \"tmin_ps\": 0.0,\n            \"tmax_ps\": 10.0\n        },\n        # Case 4\n        {\n            \"T_K\": 320.0,\n            \"eta_Pa_s\": 0.00065,\n            \"L_nm\": 2.0,\n            \"t_ps\": [0.0,2.0,4.0,6.0,8.0],\n            \"msd_nm2\": [0.0,0.0096,0.0192,0.0288,0.0384],\n            \"tmin_ps\": 0.0,\n            \"tmax_ps\": 8.0\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        D_inf = compute_d_infinity(\n            t_ps=case[\"t_ps\"],\n            msd_nm2=case[\"msd_nm2\"],\n            tmin_ps=case[\"tmin_ps\"],\n            tmax_ps=case[\"tmax_ps\"],\n            T_K=case[\"T_K\"],\n            eta_Pa_s=case[\"eta_Pa_s\"],\n            L_nm=case[\"L_nm\"]\n        )\n        results.append(D_inf)\n\n    # Round to six significant figures for output formatting\n    formatted = [f\"{val:.6g}\" for val in results]\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted)}]\")\n\nsolve()\n```"
        }
    ]
}