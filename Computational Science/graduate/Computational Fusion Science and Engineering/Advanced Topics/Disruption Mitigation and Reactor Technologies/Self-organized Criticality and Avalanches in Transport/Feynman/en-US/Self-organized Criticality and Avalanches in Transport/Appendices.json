{
    "hands_on_practices": [
        {
            "introduction": "The concept of a critical gradient is fundamental to understanding turbulence and transport in fusion plasmas. This exercise provides practice with the analytical core of gradient-driven transport models, where avalanches are triggered in regions where the local temperature gradient exceeds a stability threshold. By solving for the marginal stability radius in a simplified, pedagogical model, you will develop the foundational skill of identifying the spatial regions prone to avalanche initiation .",
            "id": "4044333",
            "problem": "Consider a magnetically confined fusion plasma with minor radius coordinate $r \\in [0,a]$ and an equilibrium electron temperature profile $T(r)=T_{0}\\left(1-\\left(\\frac{r}{a}\\right)^{2}\\right)$, where $T_{0}>0$ and $a>0$ are constants. In self-organized criticality (SOC) models of transport, local avalanche events are triggered when the absolute value of the local drive (often taken as the magnitude of the radial temperature gradient) exceeds a critical threshold. Assume the critical threshold is encoded by a reference critical temperature profile $T_{c}(r)$ whose radial derivative is spatially constant, $\\partial_{r}T_{c}(r)=-\\frac{T_{c}}{a}$, with $T_{c}>0$ a given constant and $a$ equal to the plasma minor radius. \n\nStarting from the definitions of the radial gradient and the SOC triggering condition interpreted as a comparison of local gradients, determine the spatial region in $r$ for which $\\partial_{r}T(r)>\\partial_{r}T_{c}(r)$, and identify the marginal radius where the system first reaches this condition. Based on gradient-driven avalanche phenomenology, state where avalanches are expected to initiate relative to this marginal radius, using only the given information and first principles of gradient-driven transport. \n\nReport the marginal radius $r_{c}$ as a single closed-form expression in terms of $T_{0}$, $T_{c}$, and $a$. Express $r_{c}$ in meters. No numerical rounding is required.",
            "solution": "The problem will first be validated to ensure it is scientifically sound, self-contained, and well-posed before a solution is attempted.\n\n### Step 1: Extract Givens\n- Plasma minor radius coordinate: $r \\in [0,a]$.\n- Equilibrium electron temperature profile: $T(r)=T_{0}\\left(1-\\left(\\frac{r}{a}\\right)^{2}\\right)$.\n- Constants: $T_{0}>0$ and $a>0$. $a$ is the plasma minor radius.\n- Self-organized criticality (SOC) trigger condition is when the absolute value of the local drive (magnitude of the radial temperature gradient) exceeds a critical threshold.\n- The critical threshold is encoded by a reference critical temperature profile $T_{c}(r)$.\n- The radial derivative of the critical temperature profile is a constant: $\\partial_{r}T_{c}(r)=-\\frac{T_{c}}{a}$.\n- Constant: $T_{c}>0$.\n- Task 1: Determine the spatial region in $r$ for which $\\partial_{r}T(r)>\\partial_{r}T_{c}(r)$.\n- Task 2: Identify the marginal radius $r_{c}$ where this condition is first met (i.e., at the boundary of the region).\n- Task 3: State where avalanches are expected to initiate relative to $r_c$.\n- Final answer: $r_c$ as a closed-form expression in terms of $T_{0}$, $T_{c}$, and $a$, with units of meters.\n\n### Step 2: Validate Using Extracted Givens\nThe problem describes a simplified transport model in a fusion plasma, a common approach in theoretical and computational plasma physics. The temperature profile is a standard parabolic form. The concept of a critical temperature gradient for triggering transport events (avalanches) is a central tenet of modern transport theory, particularly in the context of ion-temperature-gradient (ITG) and electron-temperature-gradient (ETG) turbulence. Assuming a spatially constant critical gradient is a valid simplification for an analytical model.\n\nThe problem statement contains a potential ambiguity. It first describes the physical trigger for avalanches as the point where the magnitude of the temperature gradient, $|\\partial_r T|$, exceeds a critical threshold, which corresponds to $|\\partial_r T_c|$. Since both gradients are expected to be negative for a centrally peaked temperature profile, this physical condition is $- \\partial_r T(r) > - \\partial_r T_c(r)$, which simplifies to $\\partial_r T(r) < \\partial_r T_c(r)$. However, the problem then explicitly asks to determine the region where the opposite inequality holds: $\\partial_{r}T(r) > \\partial_{r}T_{c}(r)$. This is not a contradiction but a structured query. It requires solving for the region of stability (sub-critical gradient) and then identifying its boundary, the marginal radius $r_c$. The subsequent question about where avalanches initiate correctly refers back to the physical principle of gradient-driven transport.\n\nThe problem is therefore scientifically grounded within a simplified model framework, mathematically well-posed, objective, and internally consistent. All necessary information is provided to find a unique solution for $r_c$.\n\n### Step 3: Verdict and Action\nThe problem is deemed valid. A solution will be derived.\n\n### Solution Derivation\nThe electron temperature profile is given by:\n$$T(r) = T_{0}\\left(1 - \\left(\\frac{r}{a}\\right)^{2}\\right)$$\nThe radial gradient of this temperature profile, $\\partial_{r}T(r)$, is found by differentiation with respect to the minor radius coordinate $r$:\n$$\\partial_{r}T(r) = \\frac{d}{dr}\\left[T_{0}\\left(1 - \\frac{r^{2}}{a^{2}}\\right)\\right] = T_{0} \\left(0 - \\frac{2r}{a^{2}}\\right)$$\n$$\\partial_{r}T(r) = -\\frac{2T_{0}r}{a^{2}}$$\nThis gradient is negative for $r>0$, correctly representing heat flowing from the hot core to the cooler edge.\n\nThe critical temperature gradient is given as a constant:\n$$\\partial_{r}T_{c}(r) = -\\frac{T_{c}}{a}$$\n\nThe first part of the problem asks for the spatial region where $\\partial_{r}T(r) > \\partial_{r}T_{c}(r)$. We substitute the expressions for the gradients into this inequality:\n$$-\\frac{2T_{0}r}{a^{2}} > -\\frac{T_{c}}{a}$$\nTo solve for $r$, we multiply both sides by $-1$, which reverses the inequality sign:\n$$\\frac{2T_{0}r}{a^{2}} < \\frac{T_{c}}{a}$$\nSince $a > 0$, we can multiply both sides by $a^{2}$ without changing the inequality:\n$$2T_{0}r < T_{c}a$$\nGiven that $T_{0} > 0$, we can divide by $2T_{0}$:\n$$r < \\frac{T_{c}a}{2T_{0}}$$\nThis inequality defines the region where the temperature gradient is sub-critical (i.e., less steep than the critical threshold). The full region, considering the physical domain $r \\in [0,a]$, is $0 \\le r < \\frac{T_{c}a}{2T_{0}}$.\n\nThe marginal radius, $r_c$, is the location where the system is exactly at the critical threshold. This occurs at the boundary of the region found above, where the inequality becomes an equality:\n$$\\partial_{r}T(r_{c}) = \\partial_{r}T_{c}(r_{c})$$\nSubstituting the expressions:\n$$-\\frac{2T_{0}r_{c}}{a^{2}} = -\\frac{T_{c}}{a}$$\nSolving for $r_c$:\n$$r_{c} = \\left(\\frac{T_{c}}{a}\\right) \\left(\\frac{a^{2}}{2T_{0}}\\right)$$\n$$r_{c} = \\frac{T_{c}a}{2T_{0}}$$\nThis is the closed-form expression for the marginal radius. The unit of $a$ is meters, and the units of $T_0$ and $T_c$ cancel, so $r_c$ has units of meters as required.\n\nFinally, we are asked to state where avalanches are expected to initiate based on gradient-driven phenomenology. Avalanches are triggered when the system is unstable, which occurs when the magnitude of the driving gradient exceeds the critical threshold. The driving gradient magnitude is $|\\partial_{r}T(r)| = \\frac{2T_{0}r}{a^{2}}$, and the critical threshold magnitude is $|\\partial_{r}T_{c}(r)| = \\frac{T_{c}}{a}$. The avalanche condition is therefore:\n$$|\\partial_{r}T(r)| > |\\partial_{r}T_{c}(r)|$$\n$$\\frac{2T_{0}r}{a^{2}} > \\frac{T_{c}}{a}$$\nSolving for $r$ yields:\n$$r > \\frac{T_{c}a}{2T_{0}}$$\nComparing this with the expression for the marginal radius, the condition for avalanche initiation is $r > r_{c}$. Therefore, avalanches are expected to initiate in the plasma region radially outward from the marginal radius $r_{c}$, where the temperature gradient becomes super-critical. The marginal radius $r_{c}$ marks the boundary between the inner, stable region ($r < r_c$) and the outer, unstable or \"stiff\" region ($r > r_c$).",
            "answer": "$$\\boxed{\\frac{T_{c}a}{2T_{0}}}$$"
        },
        {
            "introduction": "Moving from static analysis to dynamic simulation allows us to observe complex behavior emerging from simple rules. This computational practice guides you through building a one-dimensional transport solver that incorporates a threshold-dependent transport coefficient, a key feature in many models of self-organized criticality. By numerically solving the transport equation, you will directly witness how a slow, continuous drive can lead to intermittent, avalanche-like bursts of energy, and you will learn to quantify these events .",
            "id": "4044295",
            "problem": "Consider a one-dimensional radially symmetric transport model for the normalized temperature $T(r,t)$ on the interval $r \\in [0,a]$ with time $t \\ge 0$, motivated by self-organized criticality (SOC) and avalanche-like events in magnetically confined fusion plasmas. The evolution of the temperature is governed by the nonlinear diffusion equation\n$$\n\\partial_t T(r,t) = \\partial_r\\left(\\chi\\left(T,\\partial_r T\\right)\\,\\partial_r T\\right) + S(r,t),\n$$\nwhere $\\chi$ is a thresholded transport coefficient and $S$ is a slowly varying core drive. Use dimensionless normalized units throughout; no physical units are required.\n\nYou must derive a stable and consistent numerical scheme to integrate the above partial differential equation over space and time starting from conservation principles and well-tested numerical analysis facts. The scheme must enforce symmetry at the core and a fixed temperature at the edge:\n- Core boundary condition at $r=0$: zero-gradient (Neumann) symmetry, i.e., $\\partial_r T(0,t) = 0$.\n- Edge boundary condition at $r=a$: fixed temperature (Dirichlet), i.e., $T(a,t) = T_{\\text{edge}}$.\n\nThe thresholded transport coefficient is defined by a Heaviside switching on the magnitude of the local temperature gradient at cell faces:\n$$\n\\chi\\left(T,\\partial_r T\\right) = \\chi_{\\text{low}} + \\left(\\chi_{\\text{high}} - \\chi_{\\text{low}}\\right) H\\!\\left(\\left|\\partial_r T\\right| - g_c\\right),\n$$\nwhere $H(x)$ is the Heaviside step function, $\\chi_{\\text{low}}$ is the low-transport level, $\\chi_{\\text{high}}$ is the high-transport level activated when the local gradient magnitude exceeds the threshold $g_c$, and $g_c$ is the gradient threshold. The core drive is prescribed as a time-independent, smoothly localized source:\n$$\nS(r,t) = S_0 \\exp\\!\\left(-\\left(\\frac{r}{r_s}\\right)^2\\right).\n$$\n\nTo demonstrate avalanche-like bursts, implement an avalanche detector based on the balance of globally stored thermal energy. Let the discrete global energy be\n$$\nW(t) = \\int_0^a T(r,t)\\,dr,\n$$\napproximated consistently by your chosen spatial discretization. Define the instantaneous residual\n$$\nR(t) = \\frac{dW}{dt} - \\int_0^a S(r,t)\\,dr,\n$$\nwhich measures the net loss beyond the core drive. Construct a smoothed residual $R_{\\text{sm}}(t)$ by applying a centered moving average in time with a specified window size, and define a data-driven threshold $\\theta = k \\,\\sigma_R$, where $\\sigma_R$ is the standard deviation of $R(t)$ over the simulation after discarding an initial transient. Count an avalanche-like burst whenever $R_{\\text{sm}}(t)$ drops below $-\\theta$ and remains below until it rises above again; consecutive crossings within the smoothing window must be treated as part of the same event.\n\nYour program must:\n- Use a finite-volume style discretization in $r$ with a uniform grid of $N$ cells over $[0,a]$, a time step $\\Delta t$, and evolve up to a final time $T_{\\text{end}}$.\n- Implement the thresholded $\\chi$ at cell faces using the local face gradient magnitude.\n- Enforce the boundary conditions stated above.\n- Choose an explicit time stepping scheme that satisfies a stability constraint based on the maximum value of $\\chi$ and the grid spacing to maintain numerical stability.\n- Compute the time series $W(t)$ and the residual $R(t)$ at each time step, construct $R_{\\text{sm}}(t)$ with the given window size, and count avalanche-like bursts with the stated logic.\n\nAll quantities are dimensionless. The initial condition is $T(r,0)=T_{\\text{edge}}$.\n\nTest Suite:\nUse the following four parameter sets to test your implementation. Each set specifies $(N,a,\\Delta t,T_{\\text{end}},\\chi_{\\text{low}},\\chi_{\\text{high}},g_c,S_0,r_s,T_{\\text{edge}},w,k)$ where $w$ is the moving-average window size (in time steps) and $k$ is the multiplier in the threshold definition $\\theta = k \\,\\sigma_R$.\n\n- Case $1$ (baseline slow drive):\n  - $N=64$, $a=1$, $\\Delta t=10^{-4}$, $T_{\\text{end}}=6\\times 10^{-1}$,\n  - $\\chi_{\\text{low}}=10^{-2}$, $\\chi_{\\text{high}}=5\\times 10^{-1}$, $g_c=3\\times 10^{-1}$,\n  - $S_0=8\\times 10^{-1}$, $r_s=25\\times 10^{-2}$, $T_{\\text{edge}}=0$,\n  - $w=50$, $k=3$.\n\n- Case $2$ (easier threshold, more frequent bursts expected):\n  - $N=64$, $a=1$, $\\Delta t=10^{-4}$, $T_{\\text{end}}=6\\times 10^{-1}$,\n  - $\\chi_{\\text{low}}=10^{-2}$, $\\chi_{\\text{high}}=5\\times 10^{-1}$, $g_c=2\\times 10^{-1}$,\n  - $S_0=8\\times 10^{-1}$, $r_s=25\\times 10^{-2}$, $T_{\\text{edge}}=0$,\n  - $w=50$, $k=3$.\n\n- Case $3$ (no thresholding, linear diffusion):\n  - $N=64$, $a=1$, $\\Delta t=10^{-4}$, $T_{\\text{end}}=6\\times 10^{-1}$,\n  - $\\chi_{\\text{low}}=5\\times 10^{-2}$, $\\chi_{\\text{high}}=5\\times 10^{-2}$, $g_c=10^{4}$,\n  - $S_0=8\\times 10^{-1}$, $r_s=25\\times 10^{-2}$, $T_{\\text{edge}}=0$,\n  - $w=50$, $k=3$.\n\n- Case $4$ (faster drive):\n  - $N=64$, $a=1$, $\\Delta t=10^{-4}$, $T_{\\text{end}}=6\\times 10^{-1}$,\n  - $\\chi_{\\text{low}}=10^{-2}$, $\\chi_{\\text{high}}=5\\times 10^{-1}$, $g_c=3\\times 10^{-1}$,\n  - $S_0=15\\times 10^{-1}$, $r_s=25\\times 10^{-2}$, $T_{\\text{edge}}=0$,\n  - $w=50$, $k=3$.\n\nFinal Output Specification:\n- For each case, compute the integer number of detected avalanche-like bursts as defined above.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example, [result_1,result_2,result_3,result_4] where each $\\text{result}_i$ is an integer.",
            "solution": "The user has provided a valid problem statement. The problem asks for the development and implementation of a numerical scheme to solve a one-dimensional nonlinear diffusion equation that models temperature transport in a simplified fusion plasma context. The goal is to count avalanche-like transport events, which are signatures of self-organized criticality (SOC). The problem is scientifically grounded in computational physics, is mathematically well-posed, and provides a complete set of parameters and definitions for a unique solution to be computed.\n\nThe derivation and implementation will proceed as follows:\n1.  Discretize the governing partial differential equation (PDE) using a finite-volume method on a uniform grid.\n2.  Implement the specified boundary conditions: zero-gradient (Neumann) at the core ($r=0$) and fixed-temperature (Dirichlet) at the edge ($r=a$).\n3.  Employ an explicit forward Euler a time-stepping scheme, ensuring a stability condition is met.\n4.  Develop the algorithm for detecting and counting avalanches based on the time series of the boundary heat flux.\n\n**1. Finite-Volume Discretization**\n\nThe governing PDE is a nonlinear diffusion equation in one dimension:\n$$\n\\partial_t T(r,t) = \\partial_r\\left(\\chi\\left(T,\\partial_r T\\right)\\,\\partial_r T\\right) + S(r,t)\n$$\nThis equation is in conservation form, $\\partial_t T = \\partial_r J + S$, where $J(r,t) = \\chi \\partial_r T$ is the heat flux. This form is ideal for a finite-volume discretization, which inherently conserves the transported quantity (in this case, thermal energy density $T$).\n\nWe define a uniform grid of $N$ cells covering the domain $r \\in [0, a]$. The width of each cell is $\\Delta r = a/N$. The cell centers are located at $r_i = (i + 1/2)\\Delta r$ for $i=0, 1, \\dots, N-1$. The cell boundaries, or faces, are at $r_{i+1/2} = (i+1)\\Delta r$ for $i=-1, 0, \\dots, N-1$. The physical domain is bounded by the faces at $r_{-1/2} = 0$ and $r_{N-1/2} = a$.\n\nWe integrate the PDE over the $i$-th cell, from $r_{i-1/2}$ to $r_{i+1/2}$:\n$$\n\\int_{r_{i-1/2}}^{r_{i+1/2}} \\partial_t T \\, dr = \\int_{r_{i-1/2}}^{r_{i+1/2}} \\partial_r J \\, dr + \\int_{r_{i-1/2}}^{r_{i+1/2}} S \\, dr\n$$\nAssuming $T_i(t)$ represents the average temperature in cell $i$, the left side becomes $\\Delta r \\frac{d T_i}{dt}$. The right side is evaluated using the fundamental theorem of calculus for the flux term and a midpoint rule for the source term:\n$$\n\\Delta r \\frac{d T_i}{dt} = J(r_{i+1/2}, t) - J(r_{i-1/2}, t) + S(r_i, t) \\Delta r\n$$\nDividing by $\\Delta r$, we obtain the semi-discrete equation for the evolution of the temperature in cell $i$:\n$$\n\\frac{d T_i}{dt} = \\frac{J_{i+1/2} - J_{i-1/2}}{\\Delta r} + S_i\n$$\nwhere $J_{i+1/2}$ denotes the flux at the face between cell $i$ and cell $i+1$, and $S_i = S(r_i)$.\n\nThe flux $J_{i+1/2}$ is approximated using a centered difference for the gradient across the face:\n$$\nJ_{i+1/2} = \\chi_{i+1/2} \\left( \\frac{T_{i+1} - T_i}{\\Delta r} \\right)\n$$\nThe transport coefficient $\\chi_{i+1/2}$ depends nonlinearly on the magnitude of this local gradient, $g_{i+1/2} = \\left| \\frac{T_{i+1} - T_i}{\\Delta r} \\right|$:\n$$\n\\chi_{i+1/2} = \\chi_{\\text{low}} + (\\chi_{\\text{high}} - \\chi_{\\text{low}}) H(g_{i+1/2} - g_c)\n$$\nwhere $H$ is the Heaviside step function.\n\n**2. Boundary Conditions**\n\n-   **Core Boundary ($r=0$):** The zero-gradient condition $\\partial_r T(0,t) = 0$ implies that the heat flux at the core is zero. The face at $r=0$ is $r_{-1/2}$, so we set $J_{-1/2} = 0$. The equation for the first cell ($i=0$) becomes:\n    $$\n    \\frac{d T_0}{dt} = \\frac{J_{1/2}}{\\Delta r} + S_0\n    $$\n\n-   **Edge Boundary ($r=a$):** The fixed-temperature condition is $T(a,t) = T_{\\text{edge}}$. The edge face is $r_{N-1/2} = a$. To calculate the flux $J_{N-1/2}$ into the last physical cell ($i=N-1$), we need the gradient at this face. A second-order accurate centered difference can be constructed by defining a \"ghost\" cell value $T_N$ such that the average of $T_{N-1}$ and $T_N$ gives the desired boundary temperature. However, a simpler and more common finite-volume approach is to use a one-sided difference between the last cell center $r_{N-1} = a - \\Delta r/2$ and the boundary $r=a$. The distance is $\\Delta r/2$. A more robust method that maintains the centered-difference structure for all fluxes is to define the gradient at the boundary face $r_{N-1/2}$ using the known boundary value $T_{\\text{edge}}$ and the last cell-centered value $T_{N-1}$.\n    To maintain a consistent stencil, we can imagine a ghost point $T_N$ such that linear interpolation gives the boundary value, i.e., $T(a) = (T_{N-1} + T_N)/2 = T_{\\text{edge}}$. This implies $T_N = 2T_{\\text{edge}} - T_{N-1}$. The gradient at the face $r_{N-1/2}$ is then consistently approximated as:\n    $$\n    (\\partial_r T)_{N-1/2} \\approx \\frac{T_N - T_{N-1}}{\\Delta r} = \\frac{(2T_{\\text{edge}} - T_{N-1}) - T_{N-1}}{\\Delta r} = \\frac{2(T_{\\text{edge}} - T_{N-1})}{\\Delta r}\n    $$\n    This formulation correctly determines the flux $J_{N-1/2}$ required for the update of cell $T_{N-1}$.\n\n**3. Time Integration and Stability**\n\nWe use an explicit forward Euler scheme to advance in time with a step $\\Delta t$. The fully discrete update rule for cell $i$ at time step $n$ is:\n$$\nT_i^{n+1} = T_i^n + \\frac{\\Delta t}{\\Delta r} (J_{i+1/2}^n - J_{i-1/2}^n) + \\Delta t S_i\n$$\nwhere all fluxes $J^n$ are computed using the temperature $T^n$ at the current time step. Explicit schemes are subject to a stability constraint. For a diffusion equation, this is the Courant-Friedrichs-Lewy (CFL) condition, which for our nonlinear problem is:\n$$\n\\frac{\\chi_{\\max} \\Delta t}{(\\Delta r)^2} \\le \\frac{1}{2}\n$$\nHere, $\\chi_{\\max} = \\chi_{\\text{high}}$. For all test cases provided, $\\chi_{\\text{high}} = 0.5$ (or smaller), $\\Delta t = 10^{-4}$, $\\Delta r = 1/64$, yielding $\\frac{0.5 \\cdot 10^{-4}}{(1/64)^2} \\approx 0.2048$, which is less than $0.5$. Thus, the chosen parameters ensure numerical stability.\n\n**4. Avalanche Detection Algorithm**\n\nThe total thermal energy $W(t) = \\int_0^a T(r,t) dr$ is discretized as $W^n = \\Delta r \\sum_{i=0}^{N-1} T_i^n$. The instantaneous residual is defined as $R(t) = \\frac{dW}{dt} - \\int_0^a S dr$. From the conservative form of the PDE, $\\frac{d}{dt}\\int_0^a T dr = J(a,t) - J(0,t) + \\int_0^a S dr$. With $J(0,t)=0$, this simplifies to $R(t) = J(a,t)$. In our discrete system, the residual at step $n$ is simply the flux out of the edge boundary: $R^n = J_{N-1/2}^n$.\n\nThe detection proceeds as follows:\n1.  Run the simulation up to $T_{\\text{end}}$, recording the residual $R^n$ at each time step into a history array $R_{\\text{hist}}$.\n2.  Discard an initial transient phase to focus on the statistically stationary state. We discard the first half of the simulation data. Let $n_{\\text{steps}} = T_{\\text{end}} / \\Delta t$ and $n_{\\text{transient}} = n_{\\text{steps}}/2$.\n3.  Calculate the standard deviation $\\sigma_R$ of the residual $R(t)$ for $t > t_{\\text{transient}}$.\n4.  Define the avalanche threshold as $\\theta = k \\sigma_R$.\n5.  Compute a smoothed residual, $R_{\\text{sm}}(t)$, by applying a centered moving average with window size $w$ to the full $R_{\\text{hist}}$ series. The `scipy.ndimage.uniform_filter1d` function with `mode='nearest'` is suitable for this.\n6.  Analyze the smoothed residual in the post-transient phase. An avalanche is triggered when $R_{\\text{sm}}(t)$ drops below the negative threshold $-\\theta$.\n7.  To implement the condition that \"consecutive crossings within the smoothing window must be treated as part of the same event,\" we first identify all time steps where $R_{\\text{sm}}(t)$ crosses $-\\theta$ from above (i.e., $R_{\\text{sm}}(t) < -\\theta$ and $R_{\\text{sm}}(t-\\Delta t) \\ge -\\theta$). Let these be the start times of potential avalanches.\n8.  We then merge any two potential avalanches whose start times are separated by less than or equal to the window size $w$. The total count of these merged events is the final result.\n\nThis completes the design of the numerical model and analysis pipeline. The implementation will follow this framework.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.ndimage import uniform_filter1d\n\ndef solve():\n    \"\"\"\n    Main function to run simulations for all test cases and print results.\n    \"\"\"\n    test_cases = [\n        # Case 1 (baseline slow drive)\n        (64, 1.0, 1e-4, 0.6, 1e-2, 0.5, 0.3, 0.8, 0.25, 0.0, 50, 3.0),\n        # Case 2 (easier threshold)\n        (64, 1.0, 1e-4, 0.6, 1e-2, 0.5, 0.2, 0.8, 0.25, 0.0, 50, 3.0),\n        # Case 3 (no thresholding, linear diffusion)\n        (64, 1.0, 1e-4, 0.6, 5e-2, 5e-2, 1e4, 0.8, 0.25, 0.0, 50, 3.0),\n        # Case 4 (faster drive)\n        (64, 1.0, 1e-4, 0.6, 1e-2, 0.5, 0.3, 1.5, 0.25, 0.0, 50, 3.0),\n    ]\n\n    results = []\n    for params in test_cases:\n        count = run_simulation(*params)\n        results.append(count)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef run_simulation(N, a, dt, T_end, chi_low, chi_high, g_c, S0, rs, T_edge, w, k):\n    \"\"\"\n    Performs one full simulation and avalanche analysis for a given set of parameters.\n\n    Args:\n        N (int): Number of grid cells.\n        a (float): Domain size.\n        dt (float): Time step.\n        T_end (float): Final simulation time.\n        chi_low (float): Low transport coefficient.\n        chi_high (float): High transport coefficient.\n        g_c (float): Gradient threshold for SOC.\n        S0 (float): Source amplitude.\n        rs (float): Source localization width.\n        T_edge (float): Fixed temperature at the edge.\n        w (int): Moving average window size for avalanche detection.\n        k (float): Multiplier for avalanche threshold.\n\n    Returns:\n        int: The number of detected avalanche-like bursts.\n    \"\"\"\n    # 1. Initialization\n    dr = a / N\n    r_centers = (np.arange(N) + 0.5) * dr\n\n    T = np.full(N, T_edge)\n    S = S0 * np.exp(-(r_centers / rs)**2)\n\n    n_steps = int(T_end / dt)\n    R_hist = np.zeros(n_steps)\n    \n    # Pre-calculate constants for the loop\n    c_chi = chi_high - chi_low\n    dt_dr = dt / dr\n\n    # 2. Time Evolution Loop\n    for n in range(n_steps):\n        # Array for face fluxes, J[i] corresponds to flux at face i+1/2\n        # J_faces has size N: J_faces[0]...J_faces[N-2] are interior, J_faces[N-1] is edge.\n        J_faces = np.zeros(N)\n        \n        # Interior faces (i = 0 to N-2)\n        grad_interior = (T[1:] - T[:-1]) / dr\n        chi_interior = chi_low + c_chi * (np.abs(grad_interior) > g_c)\n        J_faces[:-1] = chi_interior * grad_interior\n\n        # Edge face (i = N-1)\n        grad_edge = 2.0 * (T_edge - T[N-1]) / dr\n        chi_edge = chi_low + c_chi * (np.abs(grad_edge) > g_c)\n        J_faces[-1] = chi_edge * grad_edge\n\n        # Construct full flux array J of size N+1 (J[0] at r=0, J[N] at r=a)\n        J = np.zeros(N + 1)\n        J[1:] = J_faces\n        \n        # Update Temperature\n        T += dt_dr * (J[1:] - J[:-1]) + dt * S\n        \n        # Store residual (flux at the edge)\n        R_hist[n] = J[N]\n\n    # 3. Avalanche Detection\n    # Discard first half as transient\n    n_transient = n_steps // 2\n    R_analysis = R_hist[n_transient:]\n\n    if len(R_analysis) == 0:\n        return 0\n\n    # Calculate threshold from standard deviation of non-smoothed post-transient data\n    sigma_R = np.std(R_analysis)\n    if sigma_R == 0: # No fluctuations, no avalanches\n        return 0\n    theta = k * sigma_R\n\n    # Smooth the ENTIRE residual series to avoid edge effects at the transient boundary\n    # then analyze the post-transient part.\n    R_sm = uniform_filter1d(R_hist, size=w, mode='nearest')\n    R_sm_analysis = R_sm[n_transient:]\n\n    # Find downward crossings of the threshold -theta\n    is_below = R_sm_analysis < -theta\n    # Add a False at the beginning to catch a crossing at the very first step\n    is_below_padded = np.insert(is_below, 0, False)\n    # A crossing occurs where the state changes from False to True\n    crossings = np.where(np.diff(is_below_padded.astype(int)) == 1)[0]\n\n    if len(crossings) == 0:\n        return 0\n\n    # Merge events closer than the smoothing window 'w'\n    avalanche_count = 1\n    for i in range(1, len(crossings)):\n        if crossings[i] - crossings[i-1] > w:\n            avalanche_count += 1\n            \n    return avalanche_count\n\nsolve()\n```"
        },
        {
            "introduction": "A key signature of self-organized criticality is the presence of power-law statistics in event sizes, but rigorously identifying this signature in data requires careful statistical analysis. This practice delves into the critical task of model selection, where you will design and implement a hypothesis test to determine if simulated avalanche data is better described by a power-law distribution or by plausible alternatives like log-normal or exponential distributions. This exercise equips you with the statistical tools to move beyond simple observation and towards quantitative validation of theoretical models against data .",
            "id": "4044372",
            "problem": "You are tasked with designing, deriving, and implementing a likelihood-ratio hypothesis test to decide whether observed avalanche burst magnitudes in self-organized criticality (SOC) transport are better described by a power-law tail than by log-normal or exponential alternatives. The context is computational fusion science and engineering, where burst events associated with avalanches in magnetically confined plasmas are often argued to follow heavy-tailed statistics. Your solution must start from fundamental definitions to justify the test and produce a working program that evaluates a specified test suite of synthetic datasets.\n\nBegin with the following scientifically grounded base:\n\n- The definition of a probability density function (PDF) and the corresponding likelihood for independent and identically distributed samples.\n- The principle of Maximum Likelihood Estimation (MLE).\n- The concept of comparing models via per-sample log-likelihood differences.\n- The asymptotic normality of the average log-likelihood difference under model misspecification, leading to a standardized test statistic (the Vuong test for non-nested models).\n\nModel the burst magnitude variable $x$ as continuous and strictly bounded below by a positive scale $x_{\\min}$. Consider three candidate tail models on $x \\ge x_{\\min}$:\n\n1. A continuous power-law tail with shape parameter $\\alpha > 1$ and lower bound $x_{\\min}$.\n2. A shifted exponential tail with rate $\\lambda > 0$ and lower bound $x_{\\min}$.\n3. A log-normal distribution (with parameters $\\mu \\in \\mathbb{R}$ and $\\sigma > 0$) truncated below $x_{\\min}$.\n\nYour tasks are:\n\n- Derive the correctly normalized PDF on $x \\ge x_{\\min}$ for each model from first principles.\n- Derive the Maximum Likelihood Estimator for the power-law shape parameter and the exponential rate parameter using only the provided base principles. For the truncated log-normal parameters, derive the form of the log-likelihood and explain why a closed-form solution is generally not available, motivating numerical optimization.\n- Define the per-sample log-likelihood difference $d_i = \\ln p_{\\mathrm{PL}}(x_i \\mid \\hat{\\theta}_{\\mathrm{PL}}) - \\ln p_{\\mathrm{ALT}}(x_i \\mid \\hat{\\theta}_{\\mathrm{ALT}})$, where $p_{\\mathrm{PL}}$ is the power-law PDF with its MLE parameters, and $p_{\\mathrm{ALT}}$ is an alternative PDF (log-normal or exponential) with its MLE parameters. Using the Central Limit Theorem for independent and identically distributed variables and the properties of MLE under misspecification, derive the standardized statistic\n$$\nV = \\frac{\\sqrt{n} \\,\\bar{d}}{s},\n$$\nwhere $n$ is the sample size, $\\bar{d} = \\frac{1}{n}\\sum_{i=1}^{n} d_i$, and $s$ is the sample standard deviation of $\\{d_i\\}_{i=1}^n$, and define a two-sided $p$-value via the standard normal cumulative distribution function.\n- State a decision rule at significance level $\\alpha_{\\mathrm{test}} = 0.05$: prefer the power-law over the alternative if the two-sided $p$-value is less than $0.05$ and the total log-likelihood ratio $\\sum_{i=1}^{n} d_i$ is positive; otherwise, do not claim preference.\n\nImplement a complete, runnable program that:\n\n- Generates synthetic datasets according to the specified models and parameters.\n- Estimates parameters for each model on each dataset.\n- Computes the Vuong test statistic and $p$-values comparing the power-law model against the log-normal and exponential alternatives.\n- Applies the decision rule and outputs the final decisions for all test cases.\n\nUnits: Burst magnitudes $x$ are dimensionless positive scalars. All inputs and outputs are unitless.\n\nAngle units: Not applicable.\n\nPercentages: Not applicable.\n\nTest Suite:\nUse the following four test cases with a fixed random seed $s = 12345$ for reproducibility. In each case, draw $n$ samples above $x_{\\min}$ from the specified generating distribution.\n\n- Case 1 (power-law dominated avalanches): $n = 1000$, $x_{\\min} = 1.0$, generating distribution is power-law with shape $\\alpha = 2.3$.\n- Case 2 (log-normal dominated bursts): $n = 1000$, $x_{\\min} = 1.0$, generating distribution is log-normal with parameters $\\mu = 0.0$, $\\sigma = 0.9$, truncated below $x_{\\min}$.\n- Case 3 (exponential-limited transport): $n = 1000$, $x_{\\min} = 1.0$, generating distribution is shifted exponential with rate $\\lambda = 1.2$.\n- Case 4 (sparse sample, heavy-tail edge case): $n = 30$, $x_{\\min} = 1.0$, generating distribution is power-law with shape $\\alpha = 1.8$.\n\nAnswer format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each element corresponds to one test case and is itself a two-element list of booleans in the order $[\\text{prefer power-law vs log-normal}, \\text{prefer power-law vs exponential}]$. For example, the output format must be like\n`[[True,False],[False,False],[True,True],[False,False]]`.",
            "solution": "The supplied problem is assessed to be valid. It is scientifically grounded in statistical mechanics and inference, well-posed with a complete and consistent set of definitions and constraints, and objective in its formulation. The problem requires a rigorous derivation and implementation of a standard, albeit non-trivial, statistical procedure relevant to the specified scientific domain. We proceed with the solution.\n\nThe solution is structured in four parts: derivation of the probability density functions (PDFs) for the three candidate models, derivation of their corresponding Maximum Likelihood Estimators (MLEs), formulation of the Vuong test statistic for model comparison, and definition of the decision rule.\n\n**1. Probability Density Functions**\n\nAll models describe a continuous random variable $x$ on the domain $[x_{\\min}, \\infty)$, where $x_{\\min} > 0$. The PDF $p(x)$ for any model must be normalized such that $\\int_{x_{\\min}}^{\\infty} p(x) dx = 1$.\n\n*   **Power-Law Distribution**: The functional form is $p(x) \\propto x^{-\\alpha}$ for $x \\ge x_{\\min}$, with a shape parameter $\\alpha > 1$. The normalization constant $C$ is found from the condition $C \\int_{x_{\\min}}^{\\infty} x^{-\\alpha} dx = 1$. The integral evaluates to:\n    $$\n    \\int_{x_{\\min}}^{\\infty} x^{-\\alpha} dx = \\left[ \\frac{x^{-\\alpha+1}}{1-\\alpha} \\right]_{x_{\\min}}^{\\infty} = 0 - \\frac{x_{\\min}^{1-\\alpha}}{1-\\alpha} = \\frac{x_{\\min}^{1-\\alpha}}{\\alpha-1}\n    $$\n    The convergence requires the exponent $1-\\alpha$ to be negative, hence $\\alpha > 1$. The normalization constant is $C = (\\alpha-1)x_{\\min}^{\\alpha-1}$. The correctly normalized PDF is:\n    $$\n    p_{\\mathrm{PL}}(x | \\alpha, x_{\\min}) = (\\alpha-1)x_{\\min}^{\\alpha-1} x^{-\\alpha}\n    $$\n\n*   **Shifted Exponential Distribution**: The functional form is $p(x) \\propto e^{-\\lambda(x-x_{\\min})}$ for $x \\ge x_{\\min}$, with a rate parameter $\\lambda > 0$. The normalization constant $C$ is found from $C \\int_{x_{\\min}}^{\\infty} e^{-\\lambda(x-x_{\\min})} dx = 1$. Let $y = x-x_{\\min}$, so $dy = dx$. The integral becomes $C \\int_{0}^{\\infty} e^{-\\lambda y} dy = 1$.\n    $$\n    \\int_{0}^{\\infty} e^{-\\lambda y} dy = \\left[ -\\frac{1}{\\lambda}e^{-\\lambda y} \\right]_0^\\infty = 0 - (-\\frac{1}{\\lambda}) = \\frac{1}{\\lambda}\n    $$\n    This requires $\\lambda > 0$. The normalization constant is $C = \\lambda$. The normalized PDF is:\n    $$\n    p_{\\mathrm{EXP}}(x | \\lambda, x_{\\min}) = \\lambda e^{-\\lambda(x-x_{\\min})}\n    $$\n\n*   **Truncated Log-Normal Distribution**: This model is a standard log-normal distribution, with parameters $\\mu$ and $\\sigma$, conditioned on $x \\ge x_{\\min}$. The PDF of a standard log-normal variable $Z$ is $p_{LN}(z|\\mu, \\sigma) = \\frac{1}{z \\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{(\\ln z - \\mu)^2}{2\\sigma^2}\\right)$. The truncated PDF is given by $p_{\\mathrm{LNT}}(x) = \\frac{p_{LN}(x)}{\\mathbb{P}(Z \\ge x_{\\min})}$. The denominator is the survival function, $S \\equiv \\mathbb{P}(Z \\ge x_{\\min})$, which serves as the normalization factor.\n    $$\n    S = \\int_{x_{\\min}}^{\\infty} p_{LN}(z|\\mu, \\sigma) dz\n    $$\n    Let $u = (\\ln z - \\mu) / \\sigma$. This transforms the integral to an integral over the standard normal PDF, $\\phi(u) = (1/\\sqrt{2\\pi})e^{-u^2/2}$:\n    $$\n    S = \\int_{(\\ln x_{\\min} - \\mu)/\\sigma}^{\\infty} \\phi(u) du = 1 - \\Phi\\left(\\frac{\\ln x_{\\min} - \\mu}{\\sigma}\\right)\n    $$\n    where $\\Phi$ is the standard normal cumulative distribution function (CDF). Using the error function, $S = \\frac{1}{2}\\mathrm{erfc}\\left(\\frac{\\ln x_{\\min} - \\mu}{\\sigma\\sqrt{2}}\\right)$. The normalized PDF is:\n    $$\n    p_{\\mathrm{LNT}}(x | \\mu, \\sigma, x_{\\min}) = \\frac{1}{S \\cdot x \\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}\\right)\n    $$\n\n**2. Maximum Likelihood Estimation (MLE)**\n\nFor a set of $n$ independent and identically distributed samples $\\{x_i\\}_{i=1}^n$, the log-likelihood function is $\\mathcal{L}(\\theta) = \\sum_{i=1}^n \\ln p(x_i | \\theta)$. The MLE $\\hat{\\theta}$ is the value of the parameter vector $\\theta$ that maximizes $\\mathcal{L}(\\theta)$.\n\n*   **Power-Law Parameter $\\alpha$**: The log-likelihood is:\n    $$\n    \\mathcal{L}(\\alpha) = \\sum_{i=1}^n \\left[ \\ln(\\alpha-1) + (\\alpha-1)\\ln x_{\\min} - \\alpha \\ln x_i \\right] = n\\ln(\\alpha-1) + n(\\alpha-1)\\ln x_{\\min} - \\alpha \\sum_{i=1}^n \\ln x_i\n    $$\n    Setting the derivative with respect to $\\alpha$ to zero yields the MLE $\\hat{\\alpha}$:\n    $$\n    \\frac{\\partial\\mathcal{L}}{\\partial\\alpha} = \\frac{n}{\\alpha-1} + n\\ln x_{\\min} - \\sum_{i=1}^n \\ln x_i = 0 \\quad \\implies \\quad \\hat{\\alpha}_{\\mathrm{MLE}} = 1 + n \\left( \\sum_{i=1}^n \\ln\\frac{x_i}{x_{\\min}} \\right)^{-1}\n    $$\n*   **Exponential Parameter $\\lambda$**: The log-likelihood is:\n    $$\n    \\mathcal{L}(\\lambda) = \\sum_{i=1}^n \\left[ \\ln\\lambda - \\lambda(x_i - x_{\\min}) \\right] = n\\ln\\lambda - \\lambda \\sum_{i=1}^n (x_i - x_{\\min})\n    $$\n    Setting the derivative with respect to $\\lambda$ to zero yields the MLE $\\hat{\\lambda}$:\n    $$\n    \\frac{\\partial\\mathcal{L}}{\\partial\\lambda} = \\frac{n}{\\lambda} - \\sum_{i=1}^n (x_i - x_{\\min}) = 0 \\quad \\implies \\quad \\hat{\\lambda}_{\\mathrm{MLE}} = \\frac{n}{\\sum_{i=1}^n (x_i - x_{\\min})} = \\frac{1}{\\bar{x} - x_{\\min}}\n    $$\n*   **Truncated Log-Normal Parameters $(\\mu, \\sigma)$**: The log-likelihood is:\n    $$\n    \\mathcal{L}(\\mu, \\sigma) = \\sum_{i=1}^n \\ln p_{\\mathrm{LNT}}(x_i) = -n\\ln S(\\mu, \\sigma) - n\\ln\\sigma - \\frac{n}{2}\\ln(2\\pi) - \\sum_{i=1}^n \\ln x_i - \\frac{1}{2\\sigma^2}\\sum_{i=1}^n (\\ln x_i - \\mu)^2\n    $$\n    The dependence of the normalization factor $S$ on both $\\mu$ and $\\sigma$ leads to a system of coupled, non-linear equations when setting the partial derivatives $\\partial\\mathcal{L}/\\partial\\mu$ and $\\partial\\mathcal{L}/\\partial\\sigma$ to zero. A closed-form solution for $\\hat{\\mu}$ and $\\hat{\\sigma}$ is not available. Therefore, these parameters must be found by numerically maximizing the log-likelihood function.\n\n**3. Vuong Test for Non-Nested Models**\n\nThe Vuong test provides a formal statistical comparison of two non-nested models, such as the power-law and log-normal distributions. Let the two competing models be $p_1(x|\\theta_1)$ (power-law) and $p_2(x|\\theta_2)$ (alternative). The test is based on the per-sample log-likelihood difference, evaluated at the respective MLEs:\n$$\nd_i = \\ln p_{1}(x_i | \\hat{\\theta}_{1}) - \\ln p_{2}(x_i | \\hat{\\theta}_{2})\n$$\nThe null hypothesis, $H_0$, is that the two models are equally close (in the Kullback-Leibler sense) to the true data-generating distribution, which implies $\\mathbb{E}[d_i]=0$. Under $H_0$, the Central Limit Theorem states that the sample mean $\\bar{d} = \\frac{1}{n}\\sum_{i=1}^n d_i$ is asymptotically normal with mean $0$. The standardized test statistic is:\n$$\nV = \\frac{\\sqrt{n} \\, \\bar{d}}{s}\n$$\nwhere $s$ is the sample standard deviation of the differences $\\{d_i\\}_{i=1}^n$, defined as $s = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^n (d_i - \\bar{d})^2}$. Under $H_0$, the statistic $V$ converges in distribution to a standard normal variable, $V \\sim \\mathcal{N}(0,1)$. A two-sided $p$-value is computed as $p = \\mathbb{P}(|Z| \\ge |V_{\\text{obs}}|) = 2(1-\\Phi(|V_{\\text{obs}}|))$ where $Z \\sim \\mathcal{N}(0,1)$.\n\n**4. Decision Rule**\n\nAt a chosen significance level $\\alpha_{\\mathrm{test}} = 0.05$, we can decide whether one model is significantly preferred over the other. The decision rule to prefer the power-law model ($p_1$) over an alternative ($p_2$) is based on two conditions:\n1.  The test must show a statistically significant difference between the models, i.e., the $p$-value must be less than $\\alpha_{\\mathrm{test}}$.\n2.  The direction of the difference must favor the power-law model. This is determined by the sign of the total log-likelihood ratio, $LR = \\sum_{i=1}^n d_i = n\\bar{d}$. A positive $LR$ indicates the data is more likely under the power-law model.\n\nThus, we prefer the power-law model if and only if $p < 0.05$ and $LR > 0$. Otherwise, we cannot claim a preference for the power-law model. This includes cases where the models are statistically indistinguishable ($p \\ge 0.05$) or where the alternative model is significantly better ($p < 0.05$ and $LR < 0$).",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats, optimize, special\n\ndef solve():\n    \"\"\"\n    Main function to run the hypothesis tests on the specified test suite.\n    \"\"\"\n    SEED = 12345\n    ALPHA_TEST = 0.05\n    X_MIN = 1.0\n    rng = np.random.default_rng(SEED)\n\n    # --- Data Generation Functions ---\n    def generate_power_law(n, alpha, x_min, rng_instance):\n        u = rng_instance.uniform(low=0.0, high=1.0, size=n)\n        return x_min * (1.0 - u)**(-1.0 / (alpha - 1.0))\n\n    def generate_exponential(n, lam, x_min, rng_instance):\n        u = rng_instance.uniform(low=0.0, high=1.0, size=n)\n        return x_min - (1.0 / lam) * np.log(u)\n\n    def generate_truncated_lognormal(n, mu, sigma, x_min, rng_instance):\n        u = rng_instance.uniform(low=0.0, high=1.0, size=n)\n        # Inverse transform sampling for truncated distribution\n        p_min = stats.norm.cdf((np.log(x_min) - mu) / sigma)\n        v = p_min + u * (1.0 - p_min)\n        return np.exp(mu + sigma * stats.norm.ppf(v))\n\n    # --- Log-PDF Functions (for computing log-likelihoods) ---\n    def logpdf_power_law(x, alpha, x_min):\n        if alpha <= 1.0: return -np.inf\n        return np.log(alpha - 1.0) + (alpha - 1.0) * np.log(x_min) - alpha * np.log(x)\n\n    def logpdf_exponential(x, lam, x_min):\n        if lam <= 0.0: return -np.inf\n        return np.log(lam) - lam * (x - x_min)\n\n    def logpdf_truncated_lognormal(x, mu, sigma, x_min):\n        if sigma <= 0.0: return -np.inf\n        # Use a stable log-sum-exp trick for the normalization term log(S) if needed,\n        # but erfc is generally stable.\n        u_min = (np.log(x_min) - mu) / (sigma * np.sqrt(2.0))\n        # log(S) = log(0.5 * erfc(u_min))\n        log_s = np.log(0.5) + np.log(special.erfc(u_min))\n        if np.isinf(log_s): return -np.inf\n        \n        log_x = np.log(x)\n        log_p_unnormalized = -log_x - np.log(sigma) - 0.5 * np.log(2.0 * np.pi) - (log_x - mu)**2 / (2.0 * sigma**2)\n        return log_p_unnormalized - log_s\n\n    # --- Parameter Estimation Functions ---\n    def fit_power_law(x, x_min):\n        n = len(x)\n        # Clauset-Shalizi-Newman MLE\n        alpha = 1.0 + n / np.sum(np.log(x / x_min))\n        return alpha\n\n    def fit_exponential(x, x_min):\n        lam = 1.0 / (np.mean(x) - x_min)\n        return lam\n\n    def fit_truncated_lognormal(x, x_min):\n        def neg_loglik(params, data, x_min_val):\n            mu, sigma = params\n            log_liks = logpdf_truncated_lognormal(data, mu, sigma, x_min_val)\n            # Penalize invalid parameter ranges\n            if np.any(np.isinf(log_liks)):\n                return np.inf\n            return -np.sum(log_liks)\n\n        # Initial guess from non-truncated log-normal fit\n        log_x = np.log(x)\n        init_mu = np.mean(log_x)\n        init_sigma = np.std(log_x, ddof=1)\n        if init_sigma < 1e-6: init_sigma = 1e-6\n\n        result = optimize.minimize(\n            neg_loglik,\n            [init_mu, init_sigma],\n            args=(x, x_min),\n            method='L-BFGS-B',\n            bounds=[(None, None), (1e-9, None)]\n        )\n        return result.x\n\n    # --- Test Suite Definition ---\n    test_cases = [\n        {'name': 'Case 1: PL-Generated', 'n': 1000, 'x_min': 1.0, 'gen': 'pl', 'params': {'alpha': 2.3}},\n        {'name': 'Case 2: LNT-Generated', 'n': 1000, 'x_min': 1.0, 'gen': 'lnt', 'params': {'mu': 0.0, 'sigma': 0.9}},\n        {'name': 'Case 3: Exp-Generated', 'n': 1000, 'x_min': 1.0, 'gen': 'exp', 'params': {'lam': 1.2}},\n        {'name': 'Case 4: Sparse PL', 'n': 30, 'x_min': 1.0, 'gen': 'pl', 'params': {'alpha': 1.8}},\n    ]\n\n    all_results = []\n    for case in test_cases:\n        n, x_min = case['n'], case['x_min']\n        \n        # 1. Generate data\n        if case['gen'] == 'pl':\n            data = generate_power_law(n, case['params']['alpha'], x_min, rng)\n        elif case['gen'] == 'lnt':\n            data = generate_truncated_lognormal(n, case['params']['mu'], case['params']['sigma'], x_min, rng)\n        else: # exp\n            data = generate_exponential(n, case['params']['lam'], x_min, rng)\n        \n        # 2. Fit all models\n        alpha_hat = fit_power_law(data, x_min)\n        lam_hat = fit_exponential(data, x_min)\n        mu_hat, sigma_hat = fit_truncated_lognormal(data, x_min)\n\n        # 3. Compute per-sample log-likelihoods for each fitted model\n        ll_pl = logpdf_power_law(data, alpha_hat, x_min)\n        ll_lnt = logpdf_truncated_lognormal(data, mu_hat, sigma_hat, x_min)\n        ll_exp = logpdf_exponential(data, lam_hat, x_min)\n\n        case_results = []\n        \n        # 4. Vuong Test: Power-Law vs. Log-Normal\n        d_vs_lnt = ll_pl - ll_lnt\n        d_bar_lnt = np.mean(d_vs_lnt)\n        s_lnt = np.std(d_vs_lnt, ddof=1)\n        V_lnt = (np.sqrt(n) * d_bar_lnt / s_lnt) if s_lnt > 1e-10 else 0.0\n        p_val_lnt = 2.0 * stats.norm.sf(np.abs(V_lnt))\n        lr_lnt = np.sum(d_vs_lnt)\n        \n        prefer_pl_vs_lnt = (p_val_lnt < ALPHA_TEST) and (lr_lnt > 0)\n        case_results.append(prefer_pl_vs_lnt)\n\n        # 5. Vuong Test: Power-Law vs. Exponential\n        d_vs_exp = ll_pl - ll_exp\n        d_bar_exp = np.mean(d_vs_exp)\n        s_exp = np.std(d_vs_exp, ddof=1)\n        V_exp = (np.sqrt(n) * d_bar_exp / s_exp) if s_exp > 1e-10 else 0.0\n        p_val_exp = 2.0 * stats.norm.sf(np.abs(V_exp))\n        lr_exp = np.sum(d_vs_exp)\n        \n        prefer_pl_vs_exp = (p_val_exp < ALPHA_TEST) and (lr_exp > 0)\n        case_results.append(prefer_pl_vs_exp)\n        \n        all_results.append(case_results)\n\n    # Final print statement in the exact required format.\n    print(str(all_results).replace(\" \", \"\"))\n\nsolve()\n```"
        }
    ]
}