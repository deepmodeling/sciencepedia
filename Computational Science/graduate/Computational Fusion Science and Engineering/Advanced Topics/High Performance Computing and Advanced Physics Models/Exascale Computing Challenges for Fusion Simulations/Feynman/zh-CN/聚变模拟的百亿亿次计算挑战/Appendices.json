{
    "hands_on_practices": [
        {
            "introduction": "任何优化工作都始于理解性能瓶颈：我们是受限于原始处理能力，还是受限于为处理器提供数据的速度？本练习引入了计算强度（arithmetic intensity）$I$ 的概念，即计算量与数据移动量的比值。通过计算临界强度 $I^{\\star}$，您将学会运用屋顶线模型（Roofline model）的原理，判断一个聚变模拟核心是受限于 GPU 的计算吞吐量还是其内存带宽，这是指导所有后续优化策略的关键第一步。",
            "id": "3977177",
            "problem": "一个聚变磁流体动力学内核被实现在一个异构百亿亿次节点内，完全运行在单个图形处理单元（GPU）上。该节点包含 $2$ 个中央处理单元（CPU），每个CPU连接 $128$ GB 的双倍数据速率（DDR）内存，以及 $4$ 个GPU，每个GPU配备 $80$ GB 的高带宽内存（HBM）。每个GPU维持着 $20$ 万亿次双精度浮点运算每秒（TFLOP/s）的峰值性能和 $3$ TB每秒（TB/s）的持续HBM带宽。该内核从GPU上的HBM中流式传输其数据，除了这些流之外没有数据重用，并且在内核执行期间不使用CPU内存和互连。将算术强度 $I$ 定义为执行的浮点运算次数与从HBM移动的数据字节数之比。\n\n仅使用基本的性能和吞吐量考量，确定内核在单个GPU上达到计算受限所需的最小算术强度 $I^{\\star}$ （单位为浮点运算/字节），其中“计算受限”意味着可达性能受限于GPU的峰值浮点吞吐量，而非HBM数据移动。将最终答案表示为以浮点运算/字节为单位的最简分数。不要四舍五入。",
            "solution": "该问题要求确定一个计算内核在单个图形处理单元（GPU）上达到计算受限所需的最小算术强度，记为 $I^{\\star}$。首先必须验证问题陈述的正确性和完整性。\n\n问题验证：\n\n步骤1：提取已知条件\n- 节点组成：$2$ 个中央处理单元（CPU）和 $4$ 个 GPU。\n- CPU内存：每个CPU $128$ GB的DDR内存。\n- GPU内存：每个GPU $80$ GB的高带宽内存（HBM）。\n- 单个GPU峰值双精度性能 ($P_{peak}$)：$20$ 万亿次浮点运算每秒 (TFLOP/s)。\n- 单个GPU持续HBM带宽 ($B_{peak}$)：$3$ TB每秒 (TB/s)。\n- 内核背景：内核完全在单个GPU上执行，从其HBM流式传输数据。不使用CPU内存和互连。\n- 算术强度 ($I$) 的定义：执行的浮点运算次数与从HBM移动的数据字节数之比，单位为浮点运算/字节。\n- “计算受限”的定义：可达性能受限于GPU的峰值浮点吞吐量，而非HBM的数据移动。\n\n步骤2：使用提取的已知条件进行验证\n该问题具有科学依据，依赖于高性能计算性能建模的基本原理，特别是被称为 Roofline 模型的概念。为现代GPU提供的性能数据（$P_{peak} = 20 \\times 10^{12}$ FLOP/s）和内存带宽（$B_{peak} = 3 \\times 10^{12}$ B/s）是现实的，并且在量纲上是一致的。该问题是适定的，为所有必要术语提供了清晰的定义，并提供了足够的数据以得出唯一解。关于节点的CPU、其内存以及GPU总数的信息是背景信息，与核心问题无关，核心问题关注的是单个GPU的性能特征，但这不会造成矛盾或使问题无效。问题陈述是客观的，没有歧义。\n\n步骤3：结论与行动\n问题是有效的。将根据所提供的数据和定义来构建解决方案。\n\n解决方案构建：\n\n内核的执行时间 $T$ 受两个不同因素的限制：执行计算所需的时间 ($T_{compute}$) 和将必要数据从HBM移动到处理单元所需的时间 ($T_{memory}$)。实际执行时间将是这两者中的较大值，因为计算和数据移动通常可以重叠，但整个过程的完成速度不能快于其最慢的组成部分。\n$$T \\ge \\max(T_{compute}, T_{memory})$$\n设 $F$ 为内核执行的浮点运算总次数，设 $D$ 为从HBM移动的数据总字节数。\n\n计算所需的时间由GPU的峰值浮点性能 $P_{peak}$ 决定：\n$$T_{compute} = \\frac{F}{P_{peak}}$$\n数据移动所需的时间由HBM的持续内存带宽 $B_{peak}$ 决定：\n$$T_{memory} = \\frac{D}{B_{peak}}$$\n内核的可达性能 $P_{attainable}$ 是浮点运算总次数除以执行时间 $T$。因此，性能的上限如下：\n$$P_{attainable} = \\frac{F}{T} \\le \\frac{F}{\\max\\left(\\frac{F}{P_{peak}}, \\frac{D}{B_{peak}}\\right)}$$\n代入 $T_{compute}$ 和 $T_{memory}$ 的表达式：\n$$P_{attainable} \\le \\frac{F}{\\max\\left(\\frac{F}{P_{peak}}, \\frac{D}{B_{peak}}\\right)} = \\min\\left(\\frac{F}{F/P_{peak}}, \\frac{F}{D/B_{peak}}\\right) = \\min\\left(P_{peak}, \\frac{F}{D} \\cdot B_{peak}\\right)$$\n问题将算术强度定义为 $I = F/D$。将此定义代入性能上限表达式可得：\n$$P_{attainable} \\le \\min(P_{peak}, I \\cdot B_{peak})$$\n这个表达式在数学上描述了两种性能区域。如果 $I \\cdot B_{peak}  P_{peak}$，则内核是内存受限的，其性能受限于数据供应的速率。如果 $I \\cdot B_{peak} > P_{peak}$，则内核是计算受限的，其性能受限于硬件的峰值计算吞吐量。\n\n问题要求内核达到计算受限所需的最小算术强度 $I^{\\star}$。这个转换点发生在内存带宽施加的性能限制等于计算单元的性能限制时。在这个交叉点上，系统是完美平衡的。\n$$I^{\\star} \\cdot B_{peak} = P_{peak}$$\n求解 $I^{\\star}$ 可得：\n$$I^{\\star} = \\frac{P_{peak}}{B_{peak}}$$\n我们已知以下数值：\n$P_{peak} = 20$ TFLOP/s $= 20 \\times 10^{12}$ flops/s。\n$B_{peak} = 3$ TB/s $= 3 \\times 10^{12}$ bytes/s。\n\n将这些值代入 $I^{\\star}$ 的方程中：\n$$I^{\\star} = \\frac{20 \\times 10^{12} \\text{ flops/s}}{3 \\times 10^{12} \\text{ bytes/s}}$$\n分子和分母中的因子 $10^{12}$相互抵消：\n$$I^{\\star} = \\frac{20}{3} \\text{ flops/byte}$$\n这是确保内核性能受限于GPU计算能力而非其内存带宽所需的最小算术强度。结果已是所要求的最简分数形式。",
            "answer": "$$\\boxed{\\frac{20}{3}}$$"
        },
        {
            "introduction": "在认识到许多计算核心受限于内存带宽后，下一步自然是提高内存访问效率。在并行架构上，数据在内存中的组织方式会极大地影响性能。本实践将探讨一个关键的数据布局选择：结构体数组 (AoS) 与数组结构体 (SoA)。通过分析 GPU 基于线程束（warp）的执行模式如何与这些布局相互作用，您将量化因内存合并（memory coalescing）而产生的显著性能差异，掌握这一概念对于为基于粒子的模拟编写高效的 GPU 代码至关重要。",
            "id": "3977148",
            "problem": "在磁化聚变等离子体模拟中，一个典型的“单元内粒子”(PIC)推送内核(push kernel)在图形处理单元(GPU)上使用插值场来更新粒子的位置和速度。考虑粒子记录的两种数据布局：结构体数组(AoS)和数组结构体(SoA)。在AoS布局中，每个粒子记录为每个粒子在内存中连续存储六个双精度标量，即位置分量 $x$、$y$、$z$ 和速度分量 $v_x$、$v_y$、$v_z$。在SoA布局中，这六个相同的量存储在六个独立的数组中，每个数组包含所有粒子的相应分量。\n\n假设以下硬件和代码路径事实对于在“单指令多线程”(SIMT)模式下运行的现代GPU是标准的：\n- warp大小为 $W = 32$ 个线程。\n- 双精度宽度为 $B = 8$ 字节。\n- 全局内存事务粒度是一个大小为 $S = 128$ 字节的段(segment)，单个内存事务传输一个与 $S$ 字节边界对齐的完整段。\n- 合并规则：对于给定的加载或存储指令，内存系统为warp引用的地址所触及的每个唯一的 $S$ 字节段发出一个事务。\n- 所有粒子数组和AoS记录的基地址都是 $S$ 字节对齐的，并且每个字段的第一个元素都从一个段的起始位置开始。\n- PIC推送步骤为每个粒子发出 $6$ 个独立的加载指令以读取 $(x,y,z,v_x,v_y,v_z)$，并发出 $6$ 个独立的存储指令以写入更新后的 $(x,y,z,v_x,v_y,v_z)$。这 $12$ 个指令中的每一个都是warp范围的，每个线程操作自己的粒子。由于寄存器生命周期或缓存效应，不存在跨字段重用；假设除了每个线程的标量双精度加载和存储外，没有硬件向量化。\n\n在这些假设下：\n- 在SoA布局中，对于给定的字段（例如，$x$ 数组），该加载（或存储）的warp地址在线程间是连续的。\n- 在AoS布局中，对于给定的字段（例如，每个粒子记录内的 $x$ 成员），该加载（或存储）的warp地址被AoS记录步长(stride)分隔。设AoS记录大小为 $6B$ 字节，并假设没有填充。\n\n从以上关于warp合并和内存事务的事实出发，推导整个推送步骤中SoA相对于AoS的乘性带宽效率加速因子 $R$ 的精确解析表达式，其定义为在SoA下传输的有用字节与物理字节之比与在AoS下该比值的比率，该比率聚合了所有 $12$ 个内存指令（$6$ 个加载和 $6$ 个存储）。然后数值计算 $R$。将乘性加速比 $R$ 表示为一个精确的实数。无需四舍五入。将最终结果表示为不带单位的纯数字。",
            "solution": "问题要求计算在GPU上执行粒子推送操作时，数组结构体(SoA)数据布局相对于结构体数组(AoS)数据布局的乘性带宽效率加速因子 $R$。该因子定义为两种布局的带宽效率之比：\n$$R = \\frac{\\eta_{\\text{SoA}}}{\\eta_{\\text{AoS}}}$$\n带宽效率 $\\eta$ 是传输的有用字节与从内存传输的总物理字节之比：\n$$\\eta = \\frac{\\text{有用字节}}{\\text{物理字节}}$$\n推送步骤包括 $6$ 个加载和 $6$ 个存储指令，总共 $12$ 个内存指令。对于每个指令，一个完整的 $W$ 线程的warp进行操作，每个线程访问一个大小为 $B$ 的双精度标量。因此，对于一个warp的整个推送步骤，两种布局传输的总有用数据是相同的：\n$$\\text{总有用字节} = 12 \\times W \\times B$$\n鉴于有用字节数相同，加速因子 $R$ 简化为总物理传输字节数的反比：\n$$R = \\frac{\\frac{\\text{总有用字节}}{(\\text{总物理字节})_{\\text{SoA}}}}{\\frac{\\text{总有用字节}}{(\\text{总物理字节})_{\\text{AoS}}}} = \\frac{(\\text{总物理字节})_{\\text{AoS}}}{(\\text{总物理字节})_{\\text{SoA}}}$$\n我们的任务是计算一个warp在每种布局下执行完整推送步骤时传输的总物理字节数。物理字节数由内存事务的数量决定，其中每个事务传输一个大小为 $S$ 的段。\n\n给定参数如下：\n- Warp大小: $W = 32$\n- 双精度标量宽度: $B = 8$ 字节\n- 内存段大小: $S = 128$ 字节\n\n**1. SoA (数组结构体) 布局分析**\n\n在SoA布局中，六个粒子分量（$x, y, z, v_x, v_y, v_z$）中的每一个都存储在一个单独的、连续的数组中。考虑一个单一的warp范围指令，例如，加载 $x$ 位置。warp的 $W$ 个线程访问 $W$ 个连续的双精度值。\nwarp为一条指令访问的连续数据总量为：\n$$\\text{数据跨度} = W \\times B = 32 \\times 8 = 256 \\text{ 字节}$$\n由于每个数组的基地址都与 $S$ 字节边界对齐，这 $256$ 字节的数据将完美地占据一组连续的内存段。传输这些数据所需的内存事务数 $N_{\\text{SoA}}$ 是触及的唯一 $S$ 字节段的数量。\n$$N_{\\text{SoA}} = \\frac{W \\times B}{S} = \\frac{256}{128} = 2$$\n因此，推送步骤中的 $12$ 个内存指令（6个加载，6个存储）中的每一个都需要 $2$ 个内存事务。\n在SoA情况下，整个推送步骤传输的总物理字节数为：\n$$(\\text{总物理字节})_{\\text{SoA}} = 12 \\times N_{\\text{SoA}} \\times S = 12 \\times 2 \\times 128 = 3072 \\text{ 字节}$$\nSoA布局的带宽效率为：\n$$\\eta_{\\text{SoA}} = \\frac{12 \\times W \\times B}{(\\text{总物理字节})_{\\text{SoA}}} = \\frac{12 \\times 32 \\times 8}{3072} = \\frac{3072}{3072} = 1$$\n这表明实现了完美的内存合并和100%的带宽效率。\n\n**2. AoS (结构体数组) 布局分析**\n\n在AoS布局中，单个粒子的所有六个分量都连续存储。一个粒子记录的大小，也就是连续粒子的相同分量之间的步长(stride)，是：\n$$\\sigma = 6 \\times B = 6 \\times 8 = 48 \\text{ 字节}$$\n考虑一个单一的warp范围指令，例如加载由warp处理的所有粒子的 $x$ 分量。线程 $i$（其中 $i \\in \\{0, 1, \\dots, W-1\\}$）访问粒子 $i$ 的 $x$ 分量。warp访问的内存地址是跨步的。线程 $i$ 的地址相对于粒子数组的基地址偏移了 $i \\times \\sigma$。\n为了找出内存事务的数量，我们必须计算warp为单个指令触及的唯一 $S$ 字节段的数量。我们来分析对任意分量 $j \\in \\{0, 1, ..., 5\\}$ 的访问，其中 $j=0$ 代表 $x$，$j=1$ 代表 $y$，以此类推。分量 $j$ 在记录内的偏移量是 $j \\times B$。为简单起见，假设粒子数组的基地址为 $0$，则线程 $i$ 访问分量 $j$ 的地址是 $A(i, j) = i \\times \\sigma + j \\times B$。\n此访问的段索引为 $\\lfloor \\frac{A(i, j)}{S} \\rfloor$。对于给定的 $j$，事务数 $N_{\\text{AoS}, j}$ 是该组段索引中唯一值的数量：\n$$N_{\\text{AoS}, j} = \\left| \\left\\{ \\left\\lfloor \\frac{i \\cdot \\sigma + j \\cdot B}{S} \\right\\rfloor \\Big| i \\in \\{0, \\dots, W-1\\} \\right\\} \\right|$$\n代入给定值：\n$$N_{\\text{AoS}, j} = \\left| \\left\\{ \\left\\lfloor \\frac{i \\cdot 48 + j \\cdot 8}{128} \\right\\rfloor \\Big| i \\in \\{0, \\dots, 31\\} \\right\\} \\right| = \\left| \\left\\{ \\left\\lfloor \\frac{i \\cdot 6 + j}{16} \\right\\rfloor \\Big| i \\in \\{0, \\dots, 31\\} \\right\\} \\right|$$\n让我们对任意 $j \\in \\{0, \\dots, 5\\}$ 计算这个值。函数 $f_j(i) = \\lfloor \\frac{6i+j}{16} \\rfloor$ 是单调不减的。可以证明差值 $f_j(i+1) - f_j(i)$ 要么是 $0$ 要么是 $1$，所以函数在其最小值和最大值之间不会跳过任何整数值。因此，唯一值的数量是 $f_j(W-1) - f_j(0) + 1$。\n最小值（对于 $i=0$）是：\n$$f_j(0) = \\left\\lfloor \\frac{j}{16} \\right\\rfloor = 0 \\quad (\\text{因为 } 0 \\le j \\le 5)$$\n最大值（对于 $i = W-1=31$）是：\n$$f_j(31) = \\left\\lfloor \\frac{6 \\cdot 31 + j}{16} \\right\\rfloor = \\left\\lfloor \\frac{186 + j}{16} \\right\\rfloor$$\n对于 $j=0$，这给出 $\\lfloor 186/16 \\rfloor = \\lfloor 11.625 \\rfloor = 11$。\n对于 $j=5$，这给出 $\\lfloor 191/16 \\rfloor = \\lfloor 11.9375 \\rfloor = 11$。\n对于任意 $j \\in \\{0, \\dots, 5\\}$，最大值都是 $11$。\n因此，对于任何分量 $j$，唯一段的数量是：\n$$N_{\\text{AoS}, j} = 11 - 0 + 1 = 12$$\n这意味着对于 $12$ 个内存指令中的每一个，warp都会访问 $12$ 个不同的内存段。设 $N_{\\text{AoS}} = 12$。\n在AoS情况下，整个推送步骤传输的总物理字节数为：\n$$(\\text{总物理字节})_{\\text{AoS}} = 12 \\times N_{\\text{AoS}} \\times S = 12 \\times 12 \\times 128 = 18432 \\text{ 字节}$$\nAoS布局的带宽效率为：\n$$\\eta_{\\text{AoS}} = \\frac{12 \\times W \\times B}{(\\text{总物理字节})_{\\text{AoS}}} = \\frac{3072}{18432} = \\frac{1}{6}$$\n\n**3. 加速因子 R 的计算**\n\n现在我们可以计算加速因子 $R$：\n$$R = \\frac{(\\text{总物理字节})_{\\text{AoS}}}{(\\text{总物理字节})_{\\text{SoA}}}$$\n代入推导出的物理字节表达式：\n$$R = \\frac{12 \\times N_{\\text{AoS}} \\times S}{12 \\times N_{\\text{SoA}} \\times S} = \\frac{N_{\\text{AoS}}}{N_{\\text{SoA}}}$$\n使用计算出的每条指令的事务数：\n$$R = \\frac{12}{2} = 6$$\n或者，使用计算出的效率：\n$$R = \\frac{\\eta_{\\text{SoA}}}{\\eta_{\\text{AoS}}} = \\frac{1}{1/6} = 6$$\nSoA相对于AoS的乘性带宽效率加速因子是 $6$。",
            "answer": "$$\\boxed{6}$$"
        },
        {
            "introduction": "现代聚变模拟的规模远超单个计算节点的能力，必须在大型超级计算机上运行，这引入了新的性能瓶颈：节点间的通信。本练习将我们的关注点从单节点优化转移到大规模并行的挑战上。通过使用一个标准的区域分解模型与“光环”交换（halo exchange），您将推导出一个最优策略，以平衡冗余计算的成本与网络通信的延迟。这项实践有助于培养调优大规模分布式科学应用性能的直觉与能力。",
            "id": "3977170",
            "problem": "在用于聚变等离子体模拟的显式磁流体动力学和回旋动理学求解器中，一种广泛使用的方法是采用消息传递接口（MPI）进行结构化网格区域分解。在这种方法中，每个 MPI 进程拥有全局网格的一个局部块，并为最近邻模板维护晕（幽灵）单元。考虑每个 MPI 进程拥有一个大小为 $n_x \\times n_y \\times n_z$ 单元的三维块。每个时间步的数值更新在每个坐标方向上使用半径为 $r$ 个单元的最近邻模板，因此信息每个时间步最多传播 $r$ 个单元。为了分摊通信开销，可以交换宽度为 $w$ 个单元的更宽的晕，然后在下次交换前在本地执行多个时间步。设可调参数为每次交换的晕宽度（以时间步为单位衡量），记为 $h$，并设置 $w = r h$，这样就可以在不违反模板依赖关系的情况下，在本地精确推进 $h$ 个显式时间步。\n\n假设对于单个 MPI 进程，以下性能模型成立，该模型基于工作量和数据移动的第一性原理：\n- 每个单元更新耗时 $t_u$ 秒，与位置无关。在每个本地时间步中，进程会更新其拥有的所有内部单元和所有当前可用的晕单元，以在下次交换前保持晕数据的一致性。\n- 每个通信的单元携带 $b_c$ 字节。网络的每条消息延迟为 $\\lambda$ 秒，逆带宽为每字节 $\\beta$ 秒。每次晕交换会聚合所有 6 个面，并且每 $h$ 个本地时间步执行一次。\n- 对于较大的 $n_x$、$n_y$ 和 $n_z$，忽略边和角的幽灵单元贡献（相对于面的贡献）。在此近似下，宽度为 $w$ 的晕所交换的幽灵单元数量为 $2 w (n_y n_z + n_x n_z + n_x n_y)$。\n- 通信是块同步的：计算和通信不重叠。\n\n基于这些假设以及每个时间步和每次交换的工作量和数据移动的定义，首先推导出每个时间步的平均时间 $T(h)$ 作为 $h$ 的函数，该函数反映了增加 $h$ 会降低通信频率（特别是分摊延迟），但代价是在晕区中进行额外冗余计算的权衡。然后，以闭式解的形式确定最小化 $T(h)$ 的 $h$ 值。您的最终答案必须是关于最优 $h$ 的单个解析表达式，用 $\\lambda$、$t_u$、$r$、$n_x$、$n_y$ 和 $n_z$ 表示。将答案表示为无量纲量。无需进行数值评估。",
            "solution": "该问题是有效的，因为它在科学上基于并行计算性能建模的原理，问题本身是适定的，具有足够的信息来获得唯一解，并且使用客观、正式的语言进行陈述。因此，我们可以进行推导。\n\n目标是求出每个时间步的平均时间，记为 $T(h)$，然后找出使该时间最小化的 $h$ 值。一个包含 $h$ 个时间步的周期的总时间是总计算时间和通信时间之和，因为假设这两者不重叠。\n\n首先，我们根据问题陈述来定义关键量。\n- 每个 MPI 进程的内部单元数：$$V = n_x n_y n_z$$\n- 在忽略边和角的近似下，局部域表面上的单元数：表面积的一半为 $$A = n_y n_z + n_x n_z + n_x n_y$$\n- 模板半径为 $r$ 个单元。两次晕交换之间的时间步数为 $h$。\n- 所需的晕宽度为 $w = r h$ 个单元。\n\n一个周期的总时间 $T_{cycle}(h)$ 由一次通信事件和 $h$ 个计算步骤组成，其表达式为：\n$$T_{cycle}(h) = W_{total}(h) + C(h)$$\n其中 $W_{total}(h)$ 是 $h$ 个步骤的总计算时间，$C(h)$ 是一次晕交换的通信时间。\n\n**1. 通信成本 $C(h)$**\n晕交换每 $h$ 个时间步执行一次。对于宽度为 $w$ 的晕，需要交换的幽灵单元数 $N_{halo}$ 由 $2w(n_y n_z + n_x n_z + n_x n_y)$ 给出。\n使用我们的记法：\n$$N_{halo}(w) = 2wA$$\n代入 $w=rh$：\n$$N_{halo}(h) = 2(rh)A = 2rhA$$\n每个通信的单元大小为 $b_c$ 字节。交换的总数据量 $B(h)$ 为：\n$$B(h) = N_{halo}(h) \\times b_c = 2rhAb_c$$\n一次交换的通信成本包括延迟分量 $\\lambda$ 和带宽分量。该时间为：\n$$C(h) = \\lambda + \\beta B(h) = \\lambda + \\beta (2rhAb_c)$$\n\n**2. 计算成本 $W_{total}(h)$**\n根据问题描述，在每个本地时间步中，进程会更新其拥有的所有内部单元和所有晕单元。\n在单个本地时间步内更新的单元数 $N_{update}$ 是内部单元和晕单元之和：\n$$N_{update}(h) = V + N_{halo}(h) = V + 2rhA$$\n单个单元更新的成本为 $t_u$ 秒。因此，一个本地时间步的计算时间 $W_{step}(h)$ 为：\n$$W_{step}(h) = N_{update}(h) \\times t_u = (V + 2rhA)t_u$$\n这个计算会执行 $h$ 个本地时间步。该周期的总计算时间为：\n$$W_{total}(h) = h \\times W_{step}(h) = h(V + 2rhA)t_u = (hV + 2rh^2A)t_u$$\n\n**3. 每个时间步的平均时间 $T(h)$**\n一个包含 $h$ 个步骤的周期的总时间是总计算成本和通信成本之和：\n$$T_{cycle}(h) = W_{total}(h) + C(h) = (hV + 2rh^2A)t_u + (\\lambda + 2rhAb_c\\beta)$$\n每个时间步的平均时间 $T(h)$ 是这个总周期时间除以步数 $h$：\n$$T(h) = \\frac{T_{cycle}(h)}{h} = \\frac{(hV + 2rh^2A)t_u + \\lambda + 2rhAb_c\\beta}{h}$$\n$$T(h) = Vt_u + 2rhAt_u + \\frac{\\lambda}{h} + 2rAb_c\\beta$$\n我们可以根据各项对 $h$ 的依赖关系进行分组：\n$$T(h) = (2rAt_u)h + \\frac{\\lambda}{h} + (Vt_u + 2rAb_c\\beta)$$\n这个表达式代表了权衡关系。项 $(2rAt_u)h$ 表示晕区中冗余计算的成本，它随 $h$ 线性增长。项 $\\frac{\\lambda}{h}$ 表示分摊的延迟，它随 $h$ 的增加而减少。其余项相对于 $h$ 是常数。\n\n**4. $T(h)$ 的最小化**\n为了找到最小化 $T(h)$ 的最优 $h$ 值，我们对 $T(h)$ 关于 $h$ 求导，并令其等于零。\n$$\\frac{dT(h)}{dh} = \\frac{d}{dh} \\left( (2rAt_u)h + \\lambda h^{-1} + (Vt_u + 2rAb_c\\beta) \\right)$$\n$$\\frac{dT(h)}{dh} = 2rAt_u - \\lambda h^{-2} = 2rAt_u - \\frac{\\lambda}{h^2}$$\n将导数设为零以找到临界点：\n$$2rAt_u - \\frac{\\lambda}{h^2} = 0$$\n$$2rAt_u = \\frac{\\lambda}{h^2}$$\n解出 $h^2$：\n$$h^2 = \\frac{\\lambda}{2rAt_u}$$\n由于 $h$ 必须为正，我们取正平方根：\n$$h_{opt} = \\sqrt{\\frac{\\lambda}{2rAt_u}}$$\n为确保这是一个最小值，我们检查二阶导数：\n$$\\frac{d^2T(h)}{dh^2} = \\frac{d}{dh} \\left( 2rAt_u - \\lambda h^{-2} \\right) = -(-2)\\lambda h^{-3} = \\frac{2\\lambda}{h^3}$$\n由于 $\\lambda$（延迟）和 $h$（步数）是正的物理量，二阶导数恒为正。这证实了我们求得的 $h$ 解对应于 $T(h)$ 的一个最小值。\n\n最后，我们将 $A$ 的表达式代回到 $h_{opt}$ 的方程中：\n$$h_{opt} = \\sqrt{\\frac{\\lambda}{2rt_u(n_y n_z + n_x n_z + n_x n_y)}}$$\n这就是最小化每步平均时间的最优时间步数 $h$ 的闭式解析表达式。根据要求，该量是无量纲的。",
            "answer": "$$\\boxed{\\sqrt{\\frac{\\lambda}{2rt_u(n_y n_z + n_x n_z + n_x n_y)}}}$$"
        }
    ]
}