{
    "hands_on_practices": [
        {
            "introduction": "理解计算内核的性能瓶颈是优化的第一步。Roofline模型为此提供了一个简洁而强大的框架，通过比较内核的计算强度与硬件的理论性能，来判断其性能受限于计算能力还是内存带宽。这项练习将指导您计算关键的“计算强度”阈值，即内核从内存约束转换到计算约束的临界点，这是诊断任何高性能代码性能瓶颈的基础。",
            "id": "3977177",
            "problem": "一个聚变磁流体动力学内核被实现在一个异构百亿亿次节点内的单个图形处理单元（GPU）上完全运行。该节点包含$2$个中央处理单元（CPU），每个CPU连接$128$吉字节的双倍数据速率（DDR）内存，以及$4$个GPU，每个GPU配备$80$吉字节的高带宽内存（HBM）。每个GPU的峰值双精度性能为每秒$20$万亿次浮点运算（TFLOP/s），持续HBM带宽为每秒$3$太字节（TB/s）。该内核从GPU上的HBM流式传输数据，除了这些流之外没有重用，并且内核执行过程中不使用CPU内存和互连。将算术强度 $I$ 定义为执行的浮点运算次数与从HBM移动的数据字节数之比。\n\n仅使用基本的性能和吞吐量考虑，确定内核在单个GPU上达到计算密集（compute-bound）所需的最小算术强度 $I^{\\star}$ （单位为浮点运算/字节），其中“计算密集”意味着可达到的性能受限于GPU的峰值浮点吞吐量，而非HBM的数据移动。请将最终答案表示为以浮点运算/字节为单位的最简分数。不要四舍五入。",
            "solution": "该问题要求确定一个计算内核在单个图形处理单元（GPU）上达到计算密集所需的最小算术强度，记为 $I^{\\star}$。首先必须验证问题陈述的正确性和完整性。\n\n问题验证：\n\n步骤1：提取已知条件\n- 节点组成：$2$个中央处理单元（CPU）和$4$个GPU。\n- CPU内存：每个CPU $128$ 吉字节的DDR内存。\n- GPU内存：每个GPU $80$ 吉字节的高带宽内存（HBM）。\n- 单个GPU峰值双精度性能（$P_{peak}$）：每秒$20$万亿次浮点运算（TFLOP/s）。\n- 单个GPU持续HBM带宽（$B_{peak}$）：每秒$3$太字节（TB/s）。\n- 内核上下文：内核完全在单个GPU上执行，从其HBM流式传输数据。不使用CPU内存和互连。\n- 算术强度（$I$）的定义：执行的浮点运算次数与从HBM移动的数据字节数之比，单位为浮点运算/字节。\n- “计算密集”的定义：可达到的性能受限于GPU的峰值浮点吞吐量，而非HBM的数据移动。\n\n步骤2：使用提取的已知条件进行验证\n该问题具有科学依据，依赖于高性能计算性能建模的基本原理，特别是被称为Roofline模型的概念。为现代GPU提供的性能数据（$P_{peak} = 20 \\times 10^{12}$ FLOP/s）和内存带宽数据（$B_{peak} = 3 \\times 10^{12}$ B/s）是现实的，并且在量纲上是一致的。该问题是适定的，为所有必要术语提供了明确的定义，并提供了足够的数据以得出唯一解。关于节点的CPU、其内存以及GPU总数的信息是上下文相关的，但与核心问题无关，核心问题关注的是单个GPU的性能特征，但这不会造成矛盾或使问题无效。问题陈述是客观的，没有歧义。\n\n步骤3：结论与行动\n问题有效。将根据所提供的数据和定义制定解决方案。\n\n解决方案的制定：\n\n内核的执行时间 $T$ 受两个不同因素的限制：执行计算所需的时间（$T_{compute}$）和将必要数据从HBM移动到处理单元所需的时间（$T_{memory}$）。实际执行时间将是这两者中的较大者，因为计算和数据移动通常可以重叠进行，但整个过程的完成速度不能快于其最慢的组件。\n$$T \\ge \\max(T_{compute}, T_{memory})$$\n设 $F$ 为内核执行的浮点运算总数，设 $D$ 为从HBM移动的数据字节总数。\n\n计算所需的时间由GPU的峰值浮点性能 $P_{peak}$ 决定：\n$$T_{compute} = \\frac{F}{P_{peak}}$$\n数据移动所需的时间由HBM的持续内存带宽 $B_{peak}$ 决定：\n$$T_{memory} = \\frac{D}{B_{peak}}$$\n内核的可达到性能 $P_{attainable}$ 是浮点运算总数除以执行时间 $T$。因此，性能的上限如下：\n$$P_{attainable} = \\frac{F}{T} \\le \\frac{F}{\\max(T_{compute}, T_{memory})}$$\n代入 $T_{compute}$ 和 $T_{memory}$ 的表达式：\n$$P_{attainable} \\le \\frac{F}{\\max\\left(\\frac{F}{P_{peak}}, \\frac{D}{B_{peak}}\\right)} = \\min\\left(\\frac{F}{F/P_{peak}}, \\frac{F}{D/B_{peak}}\\right) = \\min\\left(P_{peak}, \\frac{F}{D} \\cdot B_{peak}\\right)$$\n问题将算术强度定义为 $I = F/D$。将此定义代入性能上限表达式可得：\n$$P_{attainable} \\le \\min(P_{peak}, I \\cdot B_{peak})$$\n该表达式在数学上捕捉了两种性能模式。如果 $I \\cdot B_{peak} < P_{peak}$，则内核是内存密集型（memory-bound），其性能受限于数据供应的速率。如果 $I \\cdot B_{peak} > P_{peak}$，则内核是计算密集型（compute-bound），其性能受限于硬件的峰值计算吞吐量。\n\n问题要求内核达到计算密集所需的最小算术强度 $I^{\\star}$。这个转换点发生在内存带宽施加的性能限制等于计算单元的性能限制时。在这个交叉点，系统是完美平衡的。\n$$I^{\\star} \\cdot B_{peak} = P_{peak}$$\n求解 $I^{\\star}$ 可得：\n$$I^{\\star} = \\frac{P_{peak}}{B_{peak}}$$\n我们已知以下数值：\n$P_{peak} = 20$ TFLOP/s $= 20 \\times 10^{12}$ flops/s。\n$B_{peak} = 3$ TB/s $= 3 \\times 10^{12}$ bytes/s。\n\n将这些值代入 $I^{\\star}$ 的方程中：\n$$I^{\\star} = \\frac{20 \\times 10^{12} \\text{ flops/s}}{3 \\times 10^{12} \\text{ bytes/s}}$$\n分子和分母中的因子 $10^{12}$ 相互抵消：\n$$I^{\\star} = \\frac{20}{3} \\text{ flops/byte}$$\n这是确保内核性能受限于GPU的计算能力而非其内存带宽所需的最小算术强度。结果已是所要求的最简分数。",
            "answer": "$$\\boxed{\\frac{20}{3}}$$"
        },
        {
            "introduction": "当一个内核被确定为受内存带宽限制时，下一步便是提高其数据访问效率。数据在内存中的组织方式——无论是结构体数组（AoS）还是数组结构体（SoA）——对性能有着深远的影响，尤其是在像GPU这样的单指令多线程（SIMT）架构上。本练习将通过定量分析，展示SoA布局如何通过实现GPU线程束的合并内存访问，从而显著提高内存带宽效率，这对于设计高性能的粒子模拟数据结构至关重要。",
            "id": "3977148",
            "problem": "在一个典型的磁化聚变等离子体模拟中，一个粒子云 (PIC) 推送核函数在图形处理器 (GPU) 上使用内插的场来更新粒子的位置和速度。考虑两种用于粒子记录的数据布局：结构体数组 (AoS) 和数组结构体 (SoA)。在 AoS 布局中，每个粒子记录存储六个双精度标量，即位置分量 $x$、$y$、$z$ 和速度分量 $v_x$、$v_y$、$v_z$，并且每个粒子的这些数据在内存中是连续存储的。在 SoA 布局中，这六个相同的量被存储在六个独立的数组中，每个数组包含所有粒子的相应分量。\n\n假设以下硬件和代码路径事实，这些对于在单指令多线程 (SIMT) 模式下运行的现代 GPU 是标准的：\n- 线程束 (warp) 大小为 $W = 32$ 个线程。\n- 双精度宽度为 $B = 8$ 字节。\n- 全局内存事务粒度是一个大小为 $S = 128$ 字节的段 (segment)，单次内存事务传输一个与 $S$ 字节边界对齐的完整段。\n- 合并规则：对于给定的加载或存储指令，内存系统为线程束引用的地址所触及的每个唯一的 $S$ 字节段发出一次事务。\n- 所有粒子数组和 AoS 记录的基地址都是 $S$ 字节对齐的，并且每个字段的第一个元素从一个段的起始位置开始。\n- PIC 推送步骤为每个粒子发出 $6$ 个独立的加载指令以读取 $(x,y,z,v_x,v_y,v_z)$，并发出 $6$ 个独立的存储指令以写入更新后的 $(x,y,z,v_x,v_y,v_z)$。这 $12$ 条指令中的每一条都是在整个线程束范围内发出的，每个线程操作其自己的粒子。由于寄存器生命周期或缓存效应，不存在跨字段重用；假设除了每个线程的标量双精度加载和存储之外，没有硬件向量化。\n\n在这些假设下：\n- 在 SoA 布局中，对于给定的字段（例如，$x$ 数组），该加载（或存储）操作的线程束地址在线程间是连续的。\n- 在 AoS 布局中，对于给定的字段（例如，每个粒子记录中的 $x$ 成员），该加载（或存储）操作的线程束地址由 AoS 记录的步幅 (stride) 分隔。设 AoS 记录大小为 $6B$ 字节，并假设没有填充 (padding)。\n\n从上述关于线程束合并和内存事务的事实出发，为整个推送步骤推导 SoA 相对于 AoS 的乘性带宽效率加速因子 $R$ 的精确解析表达式。$R$ 定义为 SoA 下的带宽效率（有用字节/物理传输字节）与 AoS 下的带宽效率之比，该值在所有 $12$ 条内存指令（$6$ 次加载和 $6$ 次存储）上进行聚合。然后数值计算 $R$。将乘性加速比 $R$ 表示为一个精确的实数。无需四舍五入。将最终结果表示为不带单位的纯数。",
            "solution": "问题要求计算在 GPU 上执行粒子推送操作时，数组结构体 (SoA) 数据布局相对于结构体数组 (AoS) 数据布局的乘性带宽效率加速因子 $R$。该因子定义为两种布局的带宽效率之比：\n$$R = \\frac{\\eta_{\\text{SoA}}}{\\eta_{\\text{AoS}}}$$\n带宽效率 $\\eta$ 是传输的有用字节数与从内存中传输的总物理字节数之比：\n$$\\eta = \\frac{\\text{Useful Bytes}}{\\text{Physical Bytes}}$$\n推送步骤包含 6 次加载和 6 次存储指令，总共 12 条内存指令。对于每条指令，一个完整的 $W$ 线程的线程束进行操作，每个线程访问一个大小为 $B$ 的双精度标量。因此，对于一个线程束执行整个推送步骤，两种布局传输的总有用数据是相同的：\n$$\\text{Total Useful Bytes} = 12 \\times W \\times B$$\n鉴于有用字节数相同，加速因子 $R$ 简化为总物理传输字节数的反比：\n$$R = \\frac{\\frac{\\text{Total Useful Bytes}}{(\\text{Total Physical Bytes})_{\\text{SoA}}}}{\\frac{\\text{Total Useful Bytes}}{(\\text{Total Physical Bytes})_{\\text{AoS}}}} = \\frac{(\\text{Total Physical Bytes})_{\\text{AoS}}}{(\\text{Total Physical Bytes})_{\\text{SoA}}}$$\n我们的任务是计算一个线程束在每种布局下执行完整推送步骤时传输的总物理字节数。物理字节数由内存事务的数量决定，其中每次事务传输一个大小为 $S$ 的段。\n\n给定的参数是：\n- 线程束大小：$W = 32$\n- 双精度标量宽度：$B = 8$ 字节\n- 内存段大小：$S = 128$ 字节\n\n**1. SoA (数组结构体) 布局分析**\n\n在 SoA 布局中，六个粒子分量（$x, y, z, v_x, v_y, v_z$）中的每一个都存储在一个单独的、连续的数组中。考虑一个单一的线程束范围指令，例如，加载 $x$ 位置。线程束的 $W$ 个线程访问 $W$ 个连续的双精度值。\n线程束单条指令访问的连续数据总量为：\n$$\\text{Data span} = W \\times B = 32 \\times 8 = 256 \\text{ bytes}$$\n由于每个数组的基地址与 $S$ 字节边界对齐，这 256 字节的数据将完美地占据一组连续的内存段。传输这些数据所需的内存事务数 $N_{\\text{SoA}}$ 是所触及的唯一 $S$ 字节段的数量。\n$$N_{\\text{SoA}} = \\frac{W \\times B}{S} = \\frac{256}{128} = 2$$\n因此，推送步骤中的 12 条内存指令（6 次加载，6 次存储）中的每一条都需要 2 次内存事务。\n在 SoA 情况下，整个推送步骤传输的总物理字节数为：\n$$(\\text{Total Physical Bytes})_{\\text{SoA}} = 12 \\times N_{\\text{SoA}} \\times S = 12 \\times 2 \\times 128 = 3072 \\text{ bytes}$$\nSoA 布局的带宽效率为：\n$$\\eta_{\\text{SoA}} = \\frac{12 \\times W \\times B}{(\\text{Total Physical Bytes})_{\\text{SoA}}} = \\frac{12 \\times 32 \\times 8}{3072} = \\frac{3072}{3072} = 1$$\n这表示完美的内存合并和 100% 的带宽效率。\n\n**2. AoS (结构体数组) 布局分析**\n\n在 AoS 布局中，单个粒子的所有六个分量都连续存储。一个粒子记录的大小，也就是连续粒子相同分量之间的步幅 (stride)，是：\n$$\\sigma = 6 \\times B = 6 \\times 8 = 48 \\text{ bytes}$$\n考虑一个单一的线程束范围指令，例如加载由线程束处理的所有粒子的 $x$ 分量。线程 $i$（其中 $i \\in \\{0, 1, \\dots, W-1\\}$）访问粒子 $i$ 的 $x$ 分量。线程束访问的内存地址是跨步的（strided）。线程 $i$ 的地址相对于粒子数组的基地址偏移了 $i \\times \\sigma$。\n为了找出内存事务的数量，我们必须计算单条指令中线程束所触及的唯一 $S$ 字节段的数量。让我们分析对任意分量 $j \\in \\{0, 1, ..., 5\\}$ 的访问，其中 $j=0$ 对应 $x$，$j=1$ 对应 $y$，依此类推。分量 $j$ 在记录内的偏移量是 $j \\times B$。为简单起见，假设粒子数组的基地址为 0，则线程 $i$ 访问分量 $j$ 的地址为 $A(i, j) = i \\times \\sigma + j \\times B$。\n此访问的段索引是 $\\lfloor \\frac{A(i, j)}{S} \\rfloor$。事务数 $N_{\\text{AoS}, j}$ 是给定 $j$ 的段索引集合中唯一值的数量：\n$$N_{\\text{AoS}, j} = \\left| \\left\\{ \\left\\lfloor \\frac{i \\cdot \\sigma + j \\cdot B}{S} \\right\\rfloor \\Big| i \\in \\{0, \\dots, W-1\\} \\right\\} \\right|$$\n代入给定值：\n$$N_{\\text{AoS}, j} = \\left| \\left\\{ \\left\\lfloor \\frac{i \\cdot 48 + j \\cdot 8}{128} \\right\\rfloor \\Big| i \\in \\{0, \\dots, 31\\} \\right\\} \\right| = \\left| \\left\\{ \\left\\lfloor \\frac{i \\cdot 6 + j}{16} \\right\\rfloor \\Big| i \\in \\{0, \\dots, 31\\} \\right\\} \\right|$$\n我们对任意 $j \\in \\{0, \\dots, 5\\}$ 进行求值。函数 $f_j(i) = \\lfloor \\frac{6i+j}{16} \\rfloor$ 是单调不减的。差值 $f_j(i+1) - f_j(i)$ 可以被证明为 0 或 1，因此该函数在其最小值和最大值之间不会跳过任何整数值。因此，唯一值的数量是 $f_j(W-1) - f_j(0) + 1$。\n最小值（当 $i=0$ 时）是：\n$$f_j(0) = \\left\\lfloor \\frac{j}{16} \\right\\rfloor = 0 \\quad (\\text{since } 0 \\le j \\le 5)$$\n最大值（当 $i = W-1=31$ 时）是：\n$$f_j(31) = \\left\\lfloor \\frac{6 \\cdot 31 + j}{16} \\right\\rfloor = \\left\\lfloor \\frac{186 + j}{16} \\right\\rfloor$$\n对于 $j=0$，这得到 $\\lfloor 186/16 \\rfloor = \\lfloor 11.625 \\rfloor = 11$。\n对于 $j=5$，这得到 $\\lfloor 191/16 \\rfloor = \\lfloor 11.9375 \\rfloor = 11$。\n对于任意 $j \\in \\{0, \\dots, 5\\}$，最大值都是 11。\n因此，对于任何分量 $j$，唯一段的数量是：\n$$N_{\\text{AoS}, j} = 11 - 0 + 1 = 12$$\n这意味着对于 12 条内存指令中的每一条，线程束都会访问 12 个不同的内存段。设 $N_{\\text{AoS}} = 12$。\n在 AoS 情况下，整个推送步骤传输的总物理字节数为：\n$$(\\text{Total Physical Bytes})_{\\text{AoS}} = 12 \\times N_{\\text{AoS}} \\times S = 12 \\times 12 \\times 128 = 18432 \\text{ bytes}$$\nAoS 布局的带宽效率为：\n$$\\eta_{\\text{AoS}} = \\frac{12 \\times W \\times B}{(\\text{Total Physical Bytes})_{\\text{AoS}}} = \\frac{3072}{18432} = \\frac{1}{6}$$\n\n**3. 加速因子 R 的计算**\n\n现在我们可以计算加速因子 $R$：\n$$R = \\frac{(\\text{Total Physical Bytes})_{\\text{AoS}}}{(\\text{Total Physical Bytes})_{\\text{SoA}}}$$\n代入推导出的物理字节表达式：\n$$R = \\frac{12 \\times N_{\\text{AoS}} \\times S}{12 \\times N_{\\text{SoA}} \\times S} = \\frac{N_{\\text{AoS}}}{N_{\\text{SoA}}}$$\n使用计算出的每条指令的事务数：\n$$R = \\frac{12}{2} = 6$$\n或者，使用计算出的效率：\n$$R = \\frac{\\eta_{\\text{SoA}}}{\\eta_{\\text{AoS}}} = \\frac{1}{1/6} = 6$$\nSoA 相对于 AoS 的乘性带宽效率加速因子为 $6$。",
            "answer": "$$\\boxed{6}$$"
        },
        {
            "introduction": "在超大规模的并行模拟中，处理器之间的通信往往成为主要的性能瓶颈。对于在分解域上进行模板计算的场景，优化“晕圈”或“幽灵”单元数据的交换对于实现可扩展性至关重要。通过这项实践，您将推导出一个分析模型，用以寻找在降低通信频率（通过交换更宽的晕圈）和最小化冗余计算（在晕圈区域产生的额外计算）之间的最佳平衡点，这是一个分布式科学计算中的经典优化问题。",
            "id": "3977170",
            "problem": "在用于聚变等离子体模拟的显式磁流体动力学和回旋动理学求解器中，一种广泛使用的方法是采用消息传递接口 (MPI) 的结构化网格区域分解。在这种方法中，每个 MPI 进程拥有全局网格的一个局部块，并为最近邻模板维护光环（幽灵）单元。考虑每个 MPI 进程拥有一个大小为 $n_x \\times n_y \\times n_z$ 单元的 $3$ 维块。每个时间步的数值更新在每个坐标方向上使用半径为 $r$ 个单元的最近邻模板，因此信息每个时间步最多传播 $r$ 个单元。为了分摊通信成本，可以交换宽度为 $w$ 个单元的更宽光环，然后在下一次交换前在本地执行多个时间步。设可调参数为每次交换的光环宽度，以时间步为单位度量，即 $h$，并设置 $w = r h$，这样可以在不违反模板依赖关系的情况下，在本地精确推进 $h$ 个显式时间步。\n\n对于单个 MPI 进程，假设以下基于工作量和数据移动第一性原理的性能模型：\n- 每次单元更新耗时 $t_u$ 秒，与位置无关。在每个本地时间步中，进程会更新其拥有的所有内部单元和所有当前可用的光环单元，以在下次交换前保持光环数据的一致性。\n- 每个通信的单元携带 $b_c$ 字节。网络的每条消息延迟为 $\\lambda$ 秒，逆带宽为 $\\beta$ 秒/字节。每次光环交换聚合所有 $6$ 个面，并且每 $h$ 个本地时间步执行一次。\n- 对于大的 $n_x$、$n_y$ 和 $n_z$，忽略相对于面贡献的边和角的幽灵单元贡献。在此近似下，宽度为 $w$ 的光环所交换的幽灵单元数量为 $2 w (n_y n_z + n_x n_z + n_x n_y)$。\n- 通信是块同步的：计算与通信不重叠。\n\n从这些假设以及每个时间步和每次交换的工作量与数据移动的定义出发，首先推导出每个时间步的平均时间 $T(h)$ 作为 $h$ 的函数，该函数反映了增加 $h$ 会降低通信频率（特别是分摊延迟），但代价是在光环中进行额外的冗余计算这一权衡。然后，以闭式解确定最小化 $T(h)$ 的 $h$ 值。您的最终答案必须是关于最优 $h$ 的单个解析表达式，用 $\\lambda$、$t_u$、$r$、$n_x$、$n_y$ 和 $n_z$ 表示。将答案表示为无量纲量。无需进行数值计算。",
            "solution": "该问题是有效的，因为它在科学上基于并行计算性能建模的原理，问题陈述清晰，信息充分，足以得到唯一解，并使用客观、正式的语言表述。因此，我们可以进行推导。\n\n目标是找到每个时间步的平均时间，记为 $T(h)$，然后找到最小化该时间的 $h$ 值。由于假设计算和通信不重叠，一个包含 $h$ 个时间步的周期的总时间是总计算时间和通信时间之和。\n\n首先，我们根据问题陈述定义关键量。\n- 每个 MPI 进程的内部单元数：$V = n_x n_y n_z$。\n- 在忽略边和角的近似下，局部区域表面上的单元数：一半的表面积为 $A = n_y n_z + n_x n_z + n_x n_y$。\n- 模板半径为 $r$ 个单元。光环交换之间的时间步数为 $h$。\n- 所需的光环宽度为 $w = r h$ 个单元。\n\n一个周期的总时间 $T_{cycle}(h)$，包含一次通信事件和 $h$ 个计算步骤，由下式给出：\n$$T_{cycle}(h) = W_{total}(h) + C(h)$$\n其中 $W_{total}(h)$ 是 $h$ 个步骤的总计算时间，$C(h)$ 是一次光环交换的通信时间。\n\n**1. 通信成本 $C(h)$**\n光环交换每 $h$ 个时间步执行一次。对于宽度为 $w$ 的光环，要交换的幽灵单元数 $N_{halo}$ 给出为 $2w(n_y n_z + n_x n_z + n_x n_y)$。\n使用我们的符号表示：\n$$N_{halo}(w) = 2wA$$\n代入 $w=rh$：\n$$N_{halo}(h) = 2(rh)A = 2rhA$$\n每个通信的单元大小为 $b_c$ 字节。交换的总数据量 $B(h)$ 为：\n$$B(h) = N_{halo}(h) \\times b_c = 2rhAb_c$$\n一次交换的通信成本包括延迟分量 $\\lambda$ 和带宽分量。该时间为：\n$$C(h) = \\lambda + \\beta B(h) = \\lambda + \\beta (2rhAb_c)$$\n\n**2. 计算成本 $W_{total}(h)$**\n根据问题描述，在每个本地时间步中，进程会更新其拥有的所有内部单元和所有光环单元。\n在单个本地时间步中更新的单元数 $N_{update}$ 是内部单元和光环单元的总和：\n$$N_{update}(h) = V + N_{halo}(h) = V + 2rhA$$\n单个单元更新的成本是 $t_u$ 秒。因此，一个本地时间步的计算时间 $W_{step}(h)$ 是：\n$$W_{step}(h) = N_{update}(h) \\times t_u = (V + 2rhA)t_u$$\n此计算会执行 $h$ 个本地时间步。该周期的总计算时间是：\n$$W_{total}(h) = h \\times W_{step}(h) = h(V + 2rhA)t_u = (hV + 2rh^2A)t_u$$\n\n**3. 每个时间步的平均时间 $T(h)$**\n一个包含 $h$ 个步骤的周期的总时间是总计算成本和通信成本之和：\n$$T_{cycle}(h) = W_{total}(h) + C(h) = (hV + 2rh^2A)t_u + (\\lambda + 2rhAb_c\\beta)$$\n每个时间步的平均时间 $T(h)$ 是此总周期时间除以步数 $h$：\n$$T(h) = \\frac{T_{cycle}(h)}{h} = \\frac{(hV + 2rh^2A)t_u + \\lambda + 2rhAb_c\\beta}{h}$$\n$$T(h) = Vt_u + 2rhAt_u + \\frac{\\lambda}{h} + 2rAb_c\\beta$$\n我们可以根据各项对 $h$ 的依赖关系对它们进行分组：\n$$T(h) = (2rAt_u)h + \\frac{\\lambda}{h} + (Vt_u + 2rAb_c\\beta)$$\n这个表达式代表了权衡关系。项 $(2rAt_u)h$ 表示光环中的冗余计算成本，它随 $h$ 线性增长。项 $\\frac{\\lambda}{h}$ 表示分摊的延迟，它随 $h$ 的增加而减少。其余项相对于 $h$ 是常数。\n\n**4. $T(h)$ 的最小化**\n为了找到最小化 $T(h)$ 的最优 $h$ 值，我们对 $T(h)$ 关于 $h$ 求导，并令其为零。\n$$\\frac{dT(h)}{dh} = \\frac{d}{dh} \\left( (2rAt_u)h + \\lambda h^{-1} + (Vt_u + 2rAb_c\\beta) \\right)$$\n$$\\frac{dT(h)}{dh} = 2rAt_u - \\lambda h^{-2} = 2rAt_u - \\frac{\\lambda}{h^2}$$\n将导数设为零以找到临界点：\n$$2rAt_u - \\frac{\\lambda}{h^2} = 0$$\n$$2rAt_u = \\frac{\\lambda}{h^2}$$\n求解 $h^2$：\n$$h^2 = \\frac{\\lambda}{2rAt_u}$$\n由于 $h$ 必须为正，我们取正平方根：\n$$h_{opt} = \\sqrt{\\frac{\\lambda}{2rAt_u}}$$\n为了确保这是一个最小值，我们检查二阶导数：\n$$\\frac{d^2T(h)}{dh^2} = \\frac{d}{dh} \\left( 2rAt_u - \\lambda h^{-2} \\right) = -(-2)\\lambda h^{-3} = \\frac{2\\lambda}{h^3}$$\n由于 $\\lambda$（延迟）和 $h$（步数）是正的物理量，二阶导数总是正的。这证实了我们对 $h$ 的解对应于 $T(h)$ 的一个最小值。\n\n最后，我们将 $A$ 的表达式代入 $h_{opt}$ 的方程中：\n$$h_{opt} = \\sqrt{\\frac{\\lambda}{2rt_u(n_y n_z + n_x n_z + n_x n_y)}}$$\n这就是最小化每步平均时间的最优时间步数 $h$ 的闭式解析表达式。如要求，该量是无量纲的。",
            "answer": "$$\\boxed{\\sqrt{\\frac{\\lambda}{2rt_u(n_y n_z + n_x n_z + n_x n_y)}}}$$"
        }
    ]
}