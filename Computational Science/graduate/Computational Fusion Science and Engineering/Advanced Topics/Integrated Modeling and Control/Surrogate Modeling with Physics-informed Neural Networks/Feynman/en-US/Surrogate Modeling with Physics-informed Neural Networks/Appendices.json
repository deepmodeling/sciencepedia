{
    "hands_on_practices": [
        {
            "introduction": "A crucial step in solving partial differential equations is the correct imposition of boundary conditions. This exercise () demonstrates a powerful technique for enforcing Dirichlet conditions exactly by construction, using a signed distance function to transform the neural network's output. Mastering this 'hard constraint' approach is key to developing robust and efficient physics-informed models for problems like plasma equilibrium.",
            "id": "4050755",
            "problem": "Consider a two-dimensional poloidal cross-section of an axisymmetric toroidal fusion device with a vacuum vessel boundary. The poloidal flux function $\\psi(\\mathbf{x})$ is the scalar state of interest in the Grad–Shafranov equilibrium equation, and on the vacuum vessel boundary $\\partial \\Omega$ one imposes a Dirichlet boundary condition $\\psi(\\mathbf{x}) = \\psi_{\\text{wall}}$ for all $\\mathbf{x} \\in \\partial \\Omega$. In surrogate modeling with Physics-Informed Neural Networks (PINNs), one seeks to design the network output so that the boundary condition is satisfied exactly, irrespective of training. Your task is to construct an output transform based on a signed distance function that enforces the boundary condition $\\psi = \\psi_{\\text{wall}}$ on $\\partial \\Omega$, explain why it works from first principles, and implement it for a circular vacuum vessel.\n\nStarting from the boundary value problem definition, use the concept of a signed distance function $s(\\mathbf{x})$ to derive an output transform that maps any unconstrained scalar function into one that satisfies $\\psi(\\mathbf{x}) = \\psi_{\\text{wall}}$ exactly on the boundary. The signed distance function should be defined relative to the vacuum vessel boundary, be differentiable almost everywhere, and vanish on $\\partial \\Omega$. Provide a clear reasoning path grounded in the definition of Dirichlet boundary conditions and properties of signed distance functions, without invoking shortcut formulas.\n\nThen, implement the transform for a circular vacuum vessel of radius $R$ centered at the origin. Use the signed distance function relative to the circle. Let the unconstrained surrogate output be a smooth function $\\phi(x,y)$ specified by $\\phi(x,y) = \\sin(k_{x} x)\\,\\cos(k_{y} y) + c$, where $k_{x}$ and $k_{y}$ are wavenumbers and $c$ is a constant offset. Use the following parameter values:\n- $R = 1.0\\,\\mathrm{m}$,\n- $\\psi_{\\text{wall}} = 0.8\\,\\mathrm{Wb/rad}$,\n- $k_{x} = 3.0\\,\\mathrm{rad/m}$,\n- $k_{y} = 2.0\\,\\mathrm{rad/m}$,\n- $c = 0.1$.\n\nYour program must compute the transformed output $\\tilde{\\psi}(x,y)$ in units of $\\mathrm{Wb/rad}$ at specified test locations and verify that the boundary condition is enforced on the boundary points. Use angles specified in radians. For numerical verification on the boundary, treat the condition as satisfied if the absolute difference $|\\tilde{\\psi}(x,y) - \\psi_{\\text{wall}}|$ is less than or equal to a tolerance $\\tau$, where $\\tau = 10^{-12}\\,\\mathrm{Wb/rad}$.\n\nTest Suite (provide coverage across scenarios):\n- Boundary points on the circle at angles $\\theta = 0$, $\\theta = \\pi/4$, and $\\theta = \\pi/2$, with coordinates $(x,y) = (R\\cos\\theta, R\\sin\\theta)$. Verify the boundary condition at these points and report boolean results for each (true if satisfied within the tolerance, false otherwise).\n- An interior point at polar coordinates $(r,\\theta) = (0.5R,\\pi/3)$, converted to $(x,y)$, and report the float value $\\tilde{\\psi}(x,y)$ in $\\mathrm{Wb/rad}$.\n- An exterior point at polar coordinates $(r,\\theta) = (1.5R,\\pi/6)$, converted to $(x,y)$, and report the float value $\\tilde{\\psi}(x,y)$ in $\\mathrm{Wb/rad}$.\n- The center point $(x,y) = (0,0)$, and report the float value $\\tilde{\\psi}(0,0)$ in $\\mathrm{Wb/rad}$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the following order:\n$[$boundary\\_check\\_at\\ $\\theta=0$, boundary\\_check\\_at\\ $\\theta=\\pi/4$, boundary\\_check\\_at\\ $\\theta=\\pi/2$, $\\tilde{\\psi}$ at interior point, $\\tilde{\\psi}$ at exterior point, $\\tilde{\\psi}$ at center$]$.\nThe boolean entries must be Python booleans, and the float entries must be numeric values in $\\mathrm{Wb/rad}$. Angles are in radians. No additional text should be printed.",
            "solution": "The problem of constructing a surrogate model for the poloidal flux $\\psi(\\mathbf{x})$ that exactly satisfies a Dirichlet boundary condition is a well-posed problem in computational science. We will first provide a rigorous derivation of the required output transform from first principles and then implement it for the specified scenario.\n\nThe fundamental goal is to construct a transformed function, denoted $\\tilde{\\psi}(\\mathbf{x})$, from an unconstrained function $\\phi(\\mathbf{x})$ (the raw output of a neural network) such that $\\tilde{\\psi}(\\mathbf{x})$ unconditionally satisfies the Dirichlet boundary condition $\\psi(\\mathbf{x}) = \\psi_{\\text{wall}}$ for all points $\\mathbf{x}$ on the boundary $\\partial\\Omega$. The construction will leverage a signed distance function $s(\\mathbf{x})$.\n\n**1. Derivation of the Output Transform**\n\nLet $\\phi(\\mathbf{x}): \\mathbb{R}^n \\to \\mathbb{R}$ be an arbitrary, unconstrained, and well-behaved scalar function, representing the direct output of a surrogate model. We need to find a mapping $\\tilde{\\psi}(\\mathbf{x}) = f(\\mathbf{x}, \\phi(\\mathbf{x}))$ such that $\\tilde{\\psi}(\\mathbf{x})|_{\\mathbf{x} \\in \\partial\\Omega} = \\psi_{\\text{wall}}$.\n\nThe key tool for this construction is the signed distance function (SDF), $s(\\mathbf{x})$, defined with respect to the boundary $\\partial\\Omega$. The defining property of the SDF is that $s(\\mathbf{x}) = 0$ if and only if the point $\\mathbf{x}$ lies on the boundary $\\partial\\Omega$. For points not on the boundary, $s(\\mathbf{x}) \\neq 0$.\n\nA general and effective structure for the transform is a linear combination of a term that sets the boundary value and a term that incorporates the unconstrained function $\\phi(\\mathbf{x})$. Let us propose the form:\n$$\n\\tilde{\\psi}(\\mathbf{x}) = A(\\mathbf{x}) + B(\\mathbf{x})\\phi(\\mathbf{x})\n$$\nwhere $A(\\mathbf{x})$ and $B(\\mathbf{x})$ are functions to be determined.\n\nTo satisfy the boundary condition $\\tilde{\\psi}(\\mathbf{x}) = \\psi_{\\text{wall}}$ on $\\partial\\Omega$, we evaluate the expression at an arbitrary point $\\mathbf{x}_b \\in \\partial\\Omega$:\n$$\n\\tilde{\\psi}(\\mathbf{x}_b) = A(\\mathbf{x}_b) + B(\\mathbf{x}_b)\\phi(\\mathbf{x}_b) = \\psi_{\\text{wall}}\n$$\nThis equality must hold for any function $\\phi(\\mathbf{x})$. This implies that the term involving $\\phi(\\mathbf{x})$ must vanish on the boundary. Therefore, we require $B(\\mathbf{x}_b) = 0$ for all $\\mathbf{x}_b \\in \\partial\\Omega$.\n\nThe signed distance function $s(\\mathbf{x})$ has exactly this property. By setting $B(\\mathbf{x}) = s(\\mathbf{x})$, we ensure that the term $s(\\mathbf{x})\\phi(\\mathbf{x})$ is identically zero on $\\partial\\Omega$. The proposed transform becomes:\n$$\n\\tilde{\\psi}(\\mathbf{x}) = A(\\mathbf{x}) + s(\\mathbf{x})\\phi(\\mathbf{x})\n$$\nEvaluating this on the boundary $\\partial\\Omega$ yields:\n$$\n\\tilde{\\psi}(\\mathbf{x})|_{\\mathbf{x} \\in \\partial\\Omega} = A(\\mathbf{x})|_{\\mathbf{x} \\in \\partial\\Omega} + s(\\mathbf{x})|_{\\mathbf{x} \\in \\partial\\Omega} \\cdot \\phi(\\mathbf{x})|_{\\mathbf{x} \\in \\partial\\Omega} = A(\\mathbf{x})|_{\\mathbf{x} \\in \\partial\\Omega} + 0 \\cdot \\phi(\\mathbf{x})|_{\\mathbf{x} \\in \\partial\\Omega} = A(\\mathbf{x})|_{\\mathbf{x} \\in \\partial\\Omega}\n$$\nTo satisfy the Dirichlet condition, we must have $A(\\mathbf{x})|_{\\mathbf{x} \\in \\partial\\Omega} = \\psi_{\\text{wall}}$. The simplest choice for $A(\\mathbf{x})$ that satisfies this condition for all points on the boundary is the constant function $A(\\mathbf{x}) = \\psi_{\\text{wall}}$.\n\nSubstituting these choices for $A(\\mathbf{x})$ and $B(\\mathbf{x})$ gives the final, exact output transform:\n$$\n\\tilde{\\psi}(\\mathbf{x}) = \\psi_{\\text{wall}} + s(\\mathbf{x})\\phi(\\mathbf{x})\n$$\nThis form guarantees that the boundary condition is met by construction, irrespective of the behavior of the unconstrained function $\\phi(\\mathbf{x})$.\n\n**2. Application to a Circular Vacuum Vessel**\n\nThe problem specifies a circular vacuum vessel of radius $R$ centered at the origin $(0,0)$. The boundary $\\partial\\Omega$ is the set of points $(x,y)$ such that $x^2+y^2=R^2$.\n\nThe signed distance function $s(x,y)$ for this geometry is the distance of a point $(x,y)$ from the origin minus the radius $R$. We define it as:\n$$\ns(x,y) = \\sqrt{x^2+y^2} - R\n$$\nThis function is negative inside the circle, positive outside, and zero on the circle itself, as required. It is differentiable everywhere except at the origin, fulfilling the condition of being \"differentiable almost everywhere\".\n\nThe unconstrained surrogate output is given by the smooth function:\n$$\n\\phi(x,y) = \\sin(k_{x} x)\\,\\cos(k_{y} y) + c\n$$\n\nSubstituting these specific forms into the general transform, we obtain the expression for the transformed poloidal flux:\n$$\n\\tilde{\\psi}(x,y) = \\psi_{\\text{wall}} + \\left(\\sqrt{x^2+y^2} - R\\right) \\left( \\sin(k_{x} x)\\,\\cos(k_{y} y) + c \\right)\n$$\n\n**3. Numerical Evaluation**\n\nThe problem provides the following parameter values:\n- Radius $R = 1.0\\,\\mathrm{m}$\n- Boundary value $\\psi_{\\text{wall}} = 0.8\\,\\mathrm{Wb/rad}$\n- Wavenumbers $k_{x} = 3.0\\,\\mathrm{rad/m}$, $k_{y} = 2.0\\,\\mathrm{rad/m}$\n- Offset $c = 0.1$\n- Tolerance $\\tau = 10^{-12}\\,\\mathrm{Wb/rad}$\n\nWe will now evaluate $\\tilde{\\psi}(x,y)$ at the specified test locations. For points given in polar coordinates $(r,\\theta)$, we use the conversion $x=r\\cos\\theta$ and $y=r\\sin\\theta$.\n\n- **Boundary Points**: For any point on the boundary, $r=R$, which means $\\sqrt{x^2+y^2} = R$. The term $(\\sqrt{x^2+y^2} - R)$ becomes zero. Thus, $\\tilde{\\psi}(x,y) = \\psi_{\\text{wall}} + 0 = \\psi_{\\text{wall}}$. The absolute difference $|\\tilde{\\psi}(x,y) - \\psi_{\\text{wall}}|$ is $0$, which is less than the tolerance $\\tau$. Therefore, the boundary condition is satisfied exactly, and the checks will return true.\n\n- **Interior, Exterior, and Center Points**: For points not on the boundary, we will compute the value of $\\tilde{\\psi}(x,y)$ using the full expression and the provided parameters. The implementation will carry out these computations numerically.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the transformed poloidal flux function output at specified test locations.\n    The transform enforces Dirichlet boundary conditions for a circular domain.\n    \"\"\"\n    # Define constants from the problem statement.\n    R = 1.0           # Vessel radius in meters\n    psi_wall = 0.8    # Boundary value in Wb/rad\n    kx = 3.0          # Wavenumber in x-direction in rad/m\n    ky = 2.0          # Wavenumber in y-direction in rad/m\n    c = 0.1           # Constant offset, dimensionless\n    tau = 1.0e-12     # Tolerance for boundary check in Wb/rad\n\n    def s(x, y):\n        \"\"\"Signed distance function for a circle centered at the origin.\"\"\"\n        return np.sqrt(x**2 + y**2) - R\n\n    def phi(x, y):\n        \"\"\"Unconstrained surrogate model output.\"\"\"\n        return np.sin(kx * x) * np.cos(ky * y) + c\n\n    def psi_tilde(x, y):\n        \"\"\"Transformed output function enforcing the boundary condition.\"\"\"\n        return psi_wall + s(x, y) * phi(x, y)\n\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (description, type_of_test, coordinates)\n    test_cases = [\n        # Boundary points\n        (\"Boundary at theta=0\", \"boundary_check\", (R * np.cos(0), R * np.sin(0))),\n        (\"Boundary at theta=pi/4\", \"boundary_check\", (R * np.cos(np.pi / 4), R * np.sin(np.pi / 4))),\n        (\"Boundary at theta=pi/2\", \"boundary_check\", (R * np.cos(np.pi / 2), R * np.sin(np.pi / 2))),\n        # Interior point\n        (\"Interior at (0.5R, pi/3)\", \"value\", (0.5 * R * np.cos(np.pi / 3), 0.5 * R * np.sin(np.pi / 3))),\n        # Exterior point\n        (\"Exterior at (1.5R, pi/6)\", \"value\", (1.5 * R * np.cos(np.pi / 6), 1.5 * R * np.sin(np.pi / 6))),\n        # Center point\n        (\"Center at (0,0)\", \"value\", (0.0, 0.0)),\n    ]\n\n    results = []\n    for description, test_type, coords in test_cases:\n        x, y = coords\n        val = psi_tilde(x, y)\n        \n        if test_type == \"boundary_check\":\n            # Verify if the boundary condition is satisfied within the tolerance.\n            is_satisfied = np.abs(val - psi_wall) <= tau\n            results.append(is_satisfied)\n        elif test_type == \"value\":\n            # Report the float value of psi_tilde.\n            results.append(val)\n\n    # Final print statement in the exact required format.\n    # str() on a boolean produces 'True' or 'False'.\n    # str() on a float produces its string representation.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Many physical quantities, such as plasma density and temperature, are inherently positive, a constraint that must be respected by any surrogate model. While this can be enforced using output transforms like the exponential or softplus function, these choices have profound consequences for the physics residual and its gradients. This practice () delves into the calculus of these transforms, showing how they introduce new scaling factors into the loss function that must be carefully considered for stable training.",
            "id": "4050793",
            "problem": "Consider a one-dimensional slab approximation of a magnetically confined fusion plasma, where collisional cross-field transport is modeled by diffusion for the particle density and heat conduction for the temperature. Let the particle density be $n(x,t)$ and the temperature be $T(x,t)$, both positive quantities. The particle flux is given by Fick's law $J_{n} = -D_{n} \\,\\partial_{x} n$ and the heat flux is given by Fourier's law $q = -\\chi \\,\\partial_{x} T$, where $D_{n} > 0$ and $\\chi > 0$ are constant transport coefficients. Ignoring sources and sinks at a point $(x_{0},t_{0})$, the Physics-Informed Neural Network (PINN) residuals for the diffusion operators are the second spatial derivatives weighted by transport coefficients, namely the density residual operator $R_{n} = -D_{n} \\,\\partial_{x}^{2} n$ and the temperature residual operator $R_{T} = -\\chi \\,\\partial_{x}^{2} T$ evaluated at $(x_{0},t_{0})$. To enforce positivity in a neural-network surrogate, suppose the PINN outputs two preactivation fields $u(x,t)$ and $v(x,t)$, and we define the physical outputs by the exponential map $n = \\exp(u)$ and the softplus map $T = s(v)$ with $s(v) = \\ln(1+\\exp(v))$. Starting from these definitions and the chain rule, derive the expressions for $\\partial_{x} n$, $\\partial_{x}^{2} n$, $\\partial_{x} T$, and $\\partial_{x}^{2} T$ in terms of $u$, $v$, and their spatial derivatives. Identify explicitly the coefficients multiplying $(\\partial_{x} u)^{2}$ inside $\\partial_{x}^{2} n$ and $(\\partial_{x} v)^{2}$ inside $\\partial_{x}^{2} T$. Then, at the point $(x_{0},t_{0})$, define the dimensionless ratio\n$$\n\\mathcal{R} \\equiv \\frac{\\text{coefficient of }(\\partial_{x} u)^{2}\\text{ in }R_{n}}{\\text{coefficient of }(\\partial_{x} v)^{2}\\text{ in }R_{T}} \\, ,\n$$\nwhich quantifies the relative magnitude of gradient-squared scaling induced by the positivity-preserving transforms in the PINN residuals. Compute $\\mathcal{R}$ for $D_{n} = 0.25$, $\\chi = 1.5$, $u(x_{0},t_{0}) = 0.3$, and $v(x_{0},t_{0}) = -2.0$. Round your final numerical answer for $\\mathcal{R}$ to four significant figures. The final answer must be expressed as a dimensionless number.",
            "solution": "The problem requires the derivation of the second spatial derivatives of the particle density $n$ and temperature $T$ with respect to the preactivation fields $u$ and $v$. These expressions are then used to find the coefficients of the gradient-squared terms in the respective physics residuals, and finally to compute their ratio $\\mathcal{R}$.\n\n**1. Derivatives for Particle Density ($n = \\exp(u)$)**\n\nThe particle density $n$ is defined as $n = \\exp(u)$. Applying the chain rule for the first spatial derivative gives:\n$$\n\\partial_x n = \\frac{dn}{du} \\frac{\\partial u}{\\partial x} = \\exp(u) \\, \\partial_x u\n$$\nApplying the product and chain rules for the second spatial derivative yields:\n$$\n\\partial_x^2 n = \\partial_x (\\exp(u) \\, \\partial_x u) = (\\exp(u) \\, \\partial_x u)(\\partial_x u) + \\exp(u)(\\partial_x^2 u) = \\exp(u) (\\partial_x u)^2 + \\exp(u) \\, \\partial_x^2 u\n$$\nThe coefficient of $(\\partial_x u)^2$ in $\\partial_x^2 n$ is $\\exp(u)$.\n\n**2. Derivatives for Temperature ($T = \\ln(1+\\exp(v))$)**\n\nThe temperature $T$ is given by the softplus function, $T = s(v) = \\ln(1+\\exp(v))$. The first derivative of $s(v)$ is the logistic sigmoid function, $\\sigma(v)$:\n$$\n\\frac{ds}{dv} = \\frac{\\exp(v)}{1 + \\exp(v)} = \\sigma(v)\n$$\nThe first spatial derivative of $T$ is:\n$$\n\\partial_x T = \\frac{ds}{dv} \\frac{\\partial v}{\\partial x} = \\sigma(v) \\, \\partial_x v\n$$\nFor the second derivative, we need the derivative of $\\sigma(v)$, which is $\\frac{d\\sigma}{dv} = \\sigma(v)(1-\\sigma(v)) = \\frac{\\exp(v)}{(1+\\exp(v))^2}$. Applying the product and chain rules:\n$$\n\\partial_x^2 T = \\partial_x (\\sigma(v) \\, \\partial_x v) = \\left(\\frac{d\\sigma}{dv} \\partial_x v\\right)(\\partial_x v) + \\sigma(v) \\partial_x^2 v = \\frac{\\exp(v)}{(1+\\exp(v))^2} (\\partial_x v)^2 + \\sigma(v) \\partial_x^2 v\n$$\nThe coefficient of $(\\partial_x v)^2$ in $\\partial_x^2 T$ is $\\frac{\\exp(v)}{(1+\\exp(v))^2}$.\n\n**3. Calculation of the Ratio $\\mathcal{R}$**\n\nThe PINN residuals are $R_n = -D_n \\partial_x^2 n$ and $R_T = -\\chi \\partial_x^2 T$. From the derivations above, the coefficient of $(\\partial_x u)^2$ in $R_n$ is $-D_n \\exp(u)$, and the coefficient of $(\\partial_x v)^2$ in $R_T$ is $-\\chi \\frac{\\exp(v)}{(1+\\exp(v))^2}$.\nThe ratio $\\mathcal{R}$ is therefore:\n$$\n\\mathcal{R} = \\frac{\\text{coefficient of }(\\partial_{x} u)^{2}\\text{ in }R_{n}}{\\text{coefficient of }(\\partial_{x} v)^{2}\\text{ in }R_{T}} = \\frac{-D_n \\exp(u)}{-\\chi \\frac{\\exp(v)}{(1+\\exp(v))^2}} = \\frac{D_n}{\\chi} \\frac{\\exp(u) (1+\\exp(v))^2}{\\exp(v)}\n$$\nSubstituting the given values $D_n = 0.25$, $\\chi = 1.5$, $u = 0.3$, and $v = -2.0$:\n$$\n\\mathcal{R} = \\frac{0.25}{1.5} \\frac{\\exp(0.3) (1+\\exp(-2.0))^2}{\\exp(-2.0)}\n$$\nNumerically evaluating this expression:\n$$\n\\mathcal{R} \\approx \\frac{1}{6} \\times \\frac{1.349859 \\times (1+0.135335)^2}{0.135335} \\approx \\frac{1}{6} \\times \\frac{1.349859 \\times 1.28900}{0.135335} \\approx \\frac{1}{6} \\times \\frac{1.74015}{0.135335} \\approx \\frac{1}{6} \\times 12.85725 \\approx 2.142875\n$$\nRounding to four significant figures gives $2.143$.",
            "answer": "$$\\boxed{2.143}$$"
        },
        {
            "introduction": "A reliable scientific model must not only provide accurate predictions but also quantify their uncertainty. This advanced practice () guides you through implementing an ensemble of Physics-Informed Neural Networks to estimate the predictive uncertainty in a plasma equilibrium calculation. You will build and train multiple models, then aggregate their predictions and errors to construct a statistically meaningful confidence interval for the solution.",
            "id": "4050744",
            "problem": "You are asked to design and implement an ensemble physics-informed neural network (PINN) surrogate to model the magnetostatic equilibrium poloidal flux function $\\psi(R,Z)$ in a simplified setting relevant to computational fusion science and engineering. The goal is to compute predictive uncertainty intervals for $\\psi(R,Z)$ by aggregating physics residuals and diagnostic fit errors across an ensemble. The program you produce must be a complete, runnable Python $3.12$ script that adheres to the constraints specified later. All quantities in this problem are dimensionless (normalized units), and outputs must be floats or booleans with no physical units attached.\n\nThe fundamental base of this problem begins with the axisymmetric Grad–Shafranov operator in normalized units. Consider a rectangular domain with radial coordinate $R \\in [R_{\\min},R_{\\max}]$ and vertical coordinate $Z \\in [Z_{\\min},Z_{\\max}]$, where $R_{\\min} = 1.0$, $R_{\\max} = 2.0$, $Z_{\\min} = -1.0$, and $Z_{\\max} = 1.0$. The simplified magnetostatic equilibrium operator is\n$$\n\\mathcal{L}[\\psi](R,Z) \\equiv \\frac{\\partial}{\\partial R}\\left(\\frac{1}{R}\\frac{\\partial \\psi}{\\partial R}\\right) + \\frac{\\partial^2 \\psi}{\\partial Z^2},\n$$\nand the equilibrium relation is\n$$\n\\mathcal{L}[\\psi](R,Z) = - R j(R,Z),\n$$\nwhere $j(R,Z)$ is the prescribed toroidal current density in normalized units. On the boundary of the rectangle, enforce a Dirichlet condition $\\psi = 0$.\n\nTo synthesize physically consistent training targets for the PINN, define an analytic ground-truth flux function that satisfies the boundary condition,\n$$\np(R) = (R - R_{\\min})(R_{\\max} - R), \\quad q(Z) = (Z - Z_{\\min})(Z_{\\max} - Z),\n$$\n$$\ns_R(R) = \\sin\\left(\\pi \\frac{R - R_{\\min}}{R_{\\max} - R_{\\min}}\\right), \\quad c_Z(Z) = \\cos\\left(\\pi \\frac{Z - Z_{\\min}}{Z_{\\max} - Z_{\\min}}\\right),\n$$\n$$\n\\psi_{\\text{true}}(R,Z) = p(R) \\, q(Z) \\, s_R(R) \\, c_Z(Z).\n$$\nUsing the equilibrium operator, define the current density $j(R,Z)$ from $\\psi_{\\text{true}}(R,Z)$ via\n$$\nj(R,Z) = -\\frac{1}{R}\\,\\mathcal{L}[\\psi_{\\text{true}}](R,Z).\n$$\nThe derivatives required to evaluate $\\mathcal{L}[\\psi_{\\text{true}}](R,Z)$ must be derived from first principles using the product rule and chain rule:\n- $p_R(R) = R_{\\min} + R_{\\max} - 2R$, $p_{RR}(R) = -2$,\n- $q_Z(Z) = Z_{\\min} + Z_{\\max} - 2Z$, $q_{ZZ}(Z) = -2$,\n- $s_R'(R) = \\pi \\cos\\left(\\pi \\frac{R - R_{\\min}}{R_{\\max} - R_{\\min}}\\right)$, $s_R''(R) = -\\pi^2 s_R(R)$,\n- $c_Z'(Z) = -\\frac{\\pi}{2} \\sin\\left(\\pi \\frac{Z - Z_{\\min}}{Z_{\\max} - Z_{\\min}}\\right)$, $c_Z''(Z) = -\\frac{\\pi^2}{4} c_Z(Z)$.\nThen\n$$\n\\frac{\\partial \\psi_{\\text{true}}}{\\partial R} = q(Z)c_Z(Z)\\left[p_R(R) s_R(R) + p(R) s_R'(R)\\right], \n$$\n$$\n\\frac{\\partial^2 \\psi_{\\text{true}}}{\\partial R^2} = q(Z)c_Z(Z)\\left[p_{RR}(R) s_R(R) + 2 p_R(R) s_R'(R) + p(R) s_R''(R)\\right],\n$$\n$$\n\\frac{\\partial \\psi_{\\text{true}}}{\\partial Z} = p(R) s_R(R)\\left[q_Z(Z) c_Z(Z) + q(Z) c_Z'(Z)\\right],\n$$\n$$\n\\frac{\\partial^2 \\psi_{\\text{true}}}{\\partial Z^2} = p(R)s_R(R)\\left[q_{ZZ}(Z) c_Z(Z) + 2 q_Z(Z) c_Z'(Z) + q(Z) c_Z''(Z)\\right].\n$$\nTherefore,\n$$\n\\mathcal{L}[\\psi_{\\text{true}}](R,Z) = -\\frac{1}{R^2}\\frac{\\partial \\psi_{\\text{true}}}{\\partial R} + \\frac{1}{R}\\frac{\\partial^2 \\psi_{\\text{true}}}{\\partial R^2} + \\frac{\\partial^2 \\psi_{\\text{true}}}{\\partial Z^2}.\n$$\n\nYou will construct an ensemble of physics-informed neural network surrogates using fixed random features with coefficients determined by minimizing physics residuals and fitting diagnostic data. Use a boundary-satisfying mask $B(R,Z) = p(R) q(Z)$ so that the surrogate automatically satisfies $\\psi(R,Z) = 0$ on the boundary. Define a random-feature surrogate\n$$\n\\psi_{\\text{model}}(R,Z) = B(R,Z)\\sum_{i=1}^{n_f} c_i \\,\\phi_i(R,Z),\n$$\nwhere each feature is $\\phi_i(R,Z) = \\tanh(w_i R + v_i Z + b_i)$ with fixed random parameters $(w_i,v_i,b_i)$ and trainable linear coefficients $c_i$. To enforce the physics operator, denote for any feature the operator applied to $B\\phi_i$ as\n$$\n\\mathcal{L}[B\\phi_i](R,Z) = \\frac{\\partial}{\\partial R}\\left(\\frac{1}{R}\\frac{\\partial (B\\phi_i)}{\\partial R}\\right) + \\frac{\\partial^2 (B\\phi_i)}{\\partial Z^2}.\n$$\nUsing the product rule, write\n$$\n\\frac{\\partial (B\\phi)}{\\partial R} = B_R \\phi + B \\phi_R, \\quad \\frac{\\partial^2 (B\\phi)}{\\partial R^2} = B_{RR}\\phi + 2 B_R \\phi_R + B \\phi_{RR},\n$$\n$$\n\\frac{\\partial^2 (B\\phi)}{\\partial Z^2} = B_{ZZ}\\phi + 2 B_Z \\phi_Z + B \\phi_{ZZ},\n$$\nand combine to obtain\n$$\n\\mathcal{L}[B\\phi](R,Z) = -\\frac{1}{R^2}\\left(B_R \\phi + B \\phi_R\\right) + \\frac{1}{R}\\left(B_{RR}\\phi + 2 B_R \\phi_R + B \\phi_{RR}\\right) + \\left(B_{ZZ}\\phi + 2 B_Z \\phi_Z + B \\phi_{ZZ}\\right).\n$$\nFor $\\phi(R,Z)=\\tanh(a)$ with $a=w R + v Z + b$,\n$$\n\\phi_R = \\operatorname{sech}^2(a)\\, w, \\quad \\phi_Z = \\operatorname{sech}^2(a)\\, v, \\quad \\phi_{RR} = -2 w^2 \\operatorname{sech}^2(a)\\tanh(a), \\quad \\phi_{ZZ} = -2 v^2 \\operatorname{sech}^2(a)\\tanh(a).\n$$\n\nTo train the coefficients $c_i$, assemble a linear least-squares system by stacking two types of rows:\n- Physics rows from collocation points $(R_k,Z_k)$ inside the domain enforcing $\\sum_i c_i \\,\\mathcal{L}[B\\phi_i](R_k,Z_k) \\approx - R_k j(R_k,Z_k)$,\n- Diagnostic rows from measurement points $(\\hat{R}_\\ell,\\hat{Z}_\\ell)$ enforcing $\\sum_i c_i \\, B(\\hat{R}_\\ell,\\hat{Z}_\\ell)\\,\\phi_i(\\hat{R}_\\ell,\\hat{Z}_\\ell) \\approx \\psi_{\\text{true}}(\\hat{R}_\\ell,\\hat{Z}_\\ell)$.\n\nSolve the linear least-squares problem for $c = (c_1,\\ldots,c_{n_f})$. Create an ensemble by repeating the training with independently resampled random features and independently resampled collocation and diagnostic points. For each ensemble member $m$, compute:\n- The scalar diagnostic root mean square error $e_m$ across its diagnostic points,\n- The physics residual at a test location $(R,Z)$, $\\rho_m(R,Z) = \\sum_i c_i \\,\\mathcal{L}[B\\phi_i](R,Z) + R j(R,Z)$,\n- The prediction $\\psi_m(R,Z) = B(R,Z)\\sum_i c_i \\phi_i(R,Z)$.\n\nAggregate uncertainty at $(R,Z)$ by defining the ensemble mean $\\mu(R,Z)$ and sample variance $s^2_{\\text{ens}}(R,Z)$ of $\\{\\psi_m(R,Z)\\}$ and then forming\n$$\nv(R,Z) = s^2_{\\text{ens}}(R,Z) + \\overline{\\rho(R,Z)^2} + \\overline{e^2},\n$$\nwhere $\\overline{\\rho(R,Z)^2}$ is the ensemble average of $\\rho_m(R,Z)^2$ and $\\overline{e^2}$ is the ensemble average of $e_m^2$. The predictive interval at confidence level $95\\%$ is\n$$\n\\left[\\mu(R,Z) - 1.96 \\sqrt{v(R,Z)}, \\, \\mu(R,Z) + 1.96 \\sqrt{v(R,Z)}\\right].\n$$\n\nImplement the ensemble PINN as described, with the following fixed choices to ensure reproducibility:\n- Ensemble size $M = 8$,\n- Number of random features per model $n_f = 25$,\n- Number of physics collocation points $N_c = 500$ sampled uniformly from the open interior $(R_{\\min},R_{\\max}) \\times (Z_{\\min},Z_{\\max})$,\n- Number of diagnostic points $N_d = 50$ sampled uniformly from the same interior,\n- Tiny Tikhonov regularization with parameter $\\lambda_{\\text{reg}} = 10^{-6}$ added as squared coefficient penalty in least-squares.\n\nYour program must evaluate the $95\\%$ predictive interval coverage at the following four test points (all quantities are dimensionless in normalized units):\n- Test case $1$: $(R,Z) = (1.5,0.0)$,\n- Test case $2$: $(R,Z) = (1.05,0.95)$,\n- Test case $3$ (boundary edge case): $(R,Z) = (1.0,0.0)$,\n- Test case $4$ (corner boundary edge case): $(R,Z) = (2.0,1.0)$.\n\nFor each test case, compute the ensemble predictive interval and return a boolean indicating whether the true value $\\psi_{\\text{true}}(R,Z)$ lies inside the $95\\%$ predictive interval. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $\"[True,False,True,True]\"$).\n\nThe test suite is thus the ordered list of four $(R,Z)$ pairs above, and your program must output a list of four booleans in the same order. The booleans must be the only output produced.",
            "solution": "The solution involves a multi-step computational procedure to build and evaluate an ensemble of physics-informed models. The process is grounded in the method of manufactured solutions for verification and uses a specific heuristic to quantify predictive uncertainty.\n\n**1. Ground-Truth and Source Term Definition**\n\nFirst, a set of functions is implemented to compute the analytical ground-truth solution $\\psi_{\\text{true}}(R,Z)$ and its derivatives. This manufactured solution is designed to satisfy the problem's boundary conditions by construction. The corresponding source current density $j(R,Z)$ is then derived from the governing equilibrium equation, $j(R,Z) = - \\frac{1}{R}\\mathcal{L}[\\psi_{\\text{true}}](R,Z)$, providing a self-consistent problem definition.\n\n**2. Surrogate Model Basis and Operator**\n\nSecond, the components of the surrogate model, $\\psi_{\\text{model}}(R,Z) = B(R,Z) \\sum_{i=1}^{n_f} c_i \\phi_i(R,Z)$, are defined. The boundary-satisfying mask $B(R,Z)$ ensures that $\\psi_{\\text{model}} = 0$ on the boundary, automatically satisfying the Dirichlet condition. The key computational step here is the implementation of the Grad-Shafranov operator applied to each basis function, $\\mathcal{L}[B(R,Z)\\phi_i(R,Z)]$, which requires a careful application of the product and chain rules as specified in the problem.\n\n**3. Ensemble Training via Linear Least-Squares**\n\nFor each of the $M$ members of the ensemble, a linear system $A\\mathbf{c} \\approx \\mathbf{y}$ is constructed to find the optimal coefficients $c_i$. This system combines physics constraints (enforcing the equilibrium equation at random collocation points) and data-fit constraints (matching the ground truth at random \"diagnostic\" points). The system is solved using a regularized linear least-squares algorithm to ensure stability and find a unique set of coefficients.\n\n**4. Uncertainty Quantification and Interval Evaluation**\n\nAfter training all ensemble members, the predictive uncertainty is evaluated at each test point. The total predictive variance, $v(R,Z)$, is computed by aggregating three sources of error as defined in the problem: the variance of the predictions across the ensemble ($s^2_{\\text{ens}}$), the mean squared physics residual ($\\overline{\\rho^2}$), and the mean squared diagnostic error from training ($\\overline{e^2}$). A $95\\%$ predictive interval is constructed from this total variance, using the ensemble mean prediction as the center. Finally, the implementation checks whether the known ground-truth value $\\psi_{\\text{true}}(R,Z)$ falls within this computed interval for each test case. The entire process is made reproducible by using a fixed random seed for sampling points and feature parameters.",
            "answer": "```python\nimport numpy as np\n\n# A meticulous and exacting professor in the STEM fields.\n\n# ----[ Global Constants and Domain Definition ]----\nR_min, R_max = 1.0, 2.0\nZ_min, Z_max = -1.0, 1.0\npi = np.pi\nR_w, Z_w = R_max - R_min, Z_max - Z_min\n\n# ----[ Ground Truth Functions: psi_true and its components ]----\ndef p(R):\n    return (R - R_min) * (R_max - R)\n\ndef p_R(R):\n    return R_min + R_max - 2 * R\n\ndef p_RR(R):\n    return -2.0 * np.ones_like(R)\n\ndef q(Z):\n    return (Z - Z_min) * (Z_max - Z)\n\ndef q_Z(Z):\n    return Z_min + Z_max - 2 * Z\n\ndef q_ZZ(Z):\n    return -2.0 * np.ones_like(Z)\n\ndef s_R(R):\n    return np.sin(pi * (R - R_min) / R_w)\n\ndef s_R_p(R):\n    return (pi / R_w) * np.cos(pi * (R - R_min) / R_w)\n\ndef s_R_pp(R):\n    return -(pi / R_w)**2 * s_R(R)\n\ndef c_Z(Z):\n    return np.cos(pi * (Z - Z_min) / Z_w)\n\ndef c_Z_p(Z):\n    return -(pi / Z_w) * np.sin(pi * (Z - Z_min) / Z_w)\n\ndef c_Z_pp(Z):\n    return -(pi / Z_w)**2 * c_Z(Z)\n\ndef psi_true(R, Z):\n    # Handle scalar inputs\n    R_ = np.atleast_1d(R)\n    Z_ = np.atleast_1d(Z)\n    val = p(R_) * q(Z_) * s_R(R_) * c_Z(Z_)\n    return val.item() if np.isscalar(R) else val\n\ndef L_psi_true(R, Z):\n    # Handle scalar inputs\n    R_ = np.atleast_1d(R)\n    Z_ = np.atleast_1d(Z)\n    \n    # Partial derivatives of psi_true\n    dpsi_dR = q(Z_) * c_Z(Z_) * (p_R(R_) * s_R(R_) + p(R_) * s_R_p(R_))\n    d2psi_dR2 = q(Z_) * c_Z(Z_) * (p_RR(R_) * s_R(R_) + 2 * p_R(R_) * s_R_p(R_) + p(R_) * s_R_pp(R_))\n    d2psi_dZ2 = p(R_) * s_R(R_) * (q_ZZ(Z_) * c_Z(Z_) + 2 * q_Z(Z_) * c_Z_p(Z_) + q(Z_) * c_Z_pp(Z_))\n    \n    # Grad-Shafranov operator on psi_true\n    # Suppress division by zero warnings for R=0, though R is always > 0 in this domain.\n    with np.errstate(divide='ignore', invalid='ignore'):\n        L_val = -1.0 / R_**2 * dpsi_dR + 1.0 / R_ * d2psi_dR2 + d2psi_dZ2\n    \n    return L_val.item() if np.isscalar(R) else L_val\n\ndef j_true(R, Z):\n    R_ = np.atleast_1d(R)\n    L_psi_val = L_psi_true(R, Z)\n    with np.errstate(divide='ignore', invalid='ignore'):\n        J = -1.0 / R_ * L_psi_val\n    return J.item() if np.isscalar(R) else J\n\n\n# ----[ Surrogate Model Functions: Basis, Mask, and Operator ]----\ndef B(R, Z):\n    return p(R) * q(Z)\n\ndef B_R(R, Z): return p_R(R) * q(Z)\ndef B_Z(R, Z): return p(R) * q_Z(Z)\ndef B_RR(R, Z): return p_RR(R) * q(Z)\ndef B_ZZ(R, Z): return p(R) * q_ZZ(Z)\n\ndef phi(R, Z, w, v, b):\n    a = w * R + v * Z + b\n    return np.tanh(a)\n\ndef phi_R(R, Z, w, v, b):\n    a = w * R + v * Z + b\n    return w * (1.0 / np.cosh(a))**2\n\ndef phi_Z(R, Z, w, v, b):\n    a = w * R + v * Z + b\n    return v * (1.0 / np.cosh(a))**2\n\ndef phi_RR(R, Z, w, v, b):\n    a = w * R + v * Z + b\n    return -2 * w**2 * np.tanh(a) * (1.0 / np.cosh(a))**2\n\ndef phi_ZZ(R, Z, w, v, b):\n    a = w * R + v * Z + b\n    return -2 * v**2 * np.tanh(a) * (1.0 / np.cosh(a))**2\n\ndef L_B_phi(R, Z, w, v, b):\n    R_ = np.atleast_1d(R)\n    Z_ = np.atleast_1d(Z)\n    \n    phi_val = phi(R_, Z_, w, v, b)\n    phi_R_val = phi_R(R_, Z_, w, v, b)\n    phi_Z_val = phi_Z(R_, Z_, w, v, b)\n    phi_RR_val = phi_RR(R_, Z_, w, v, b)\n    phi_ZZ_val = phi_ZZ(R_, Z_, w, v, b)\n\n    B_val = B(R_, Z_)\n    B_R_val = B_R(R_, Z_)\n    B_Z_val = B_Z(R_, Z_)\n    B_RR_val = B_RR(R_, Z_)\n    B_ZZ_val = B_ZZ(R_, Z_)\n\n    term1 = B_R_val * phi_val + B_val * phi_R_val\n    term2 = B_RR_val * phi_val + 2 * B_R_val * phi_R_val + B_val * phi_RR_val\n    term3 = B_ZZ_val * phi_val + 2 * B_Z_val * phi_Z_val + B_val * phi_ZZ_val\n\n    with np.errstate(divide='ignore', invalid='ignore'):\n      L_val = -1.0/R_**2 * term1 + 1.0/R_ * term2 + term3\n\n    return L_val.item() if np.isscalar(R) else L_val\n\n\ndef solve():\n    # ----[ Problem Configuration ]----\n    M = 8\n    n_f = 25\n    N_c = 500\n    N_d = 50\n    lambda_reg = 1e-6\n    test_cases = [\n        (1.5, 0.0),\n        (1.05, 0.95),\n        (1.0, 0.0),\n        (2.0, 1.0),\n    ]\n\n    main_seed = 42\n    rng_main = np.random.default_rng(main_seed)\n    ensemble_seeds = rng_main.integers(low=0, high=2**31 - 1, size=M)\n\n    ensemble_members = []\n    ensemble_e_sq = []\n\n    for m in range(M):\n        rng_member = np.random.default_rng(ensemble_seeds[m])\n\n        # Sample features and points\n        features = rng_member.standard_normal(size=(n_f, 3))  # (w, v, b)\n        R_c = rng_member.uniform(R_min, R_max, N_c)\n        Z_c = rng_member.uniform(Z_min, Z_max, N_c)\n        R_d = rng_member.uniform(R_min, R_max, N_d)\n        Z_d = rng_member.uniform(Z_min, Z_max, N_d)\n\n        # Build least-squares system\n        A = np.zeros((N_c + N_d, n_f))\n        y = np.zeros(N_c + N_d)\n\n        # Physics rows\n        y[:N_c] = -R_c * j_true(R_c, Z_c)\n        for i in range(n_f):\n            w_i, v_i, b_i = features[i]\n            A[:N_c, i] = L_B_phi(R_c, Z_c, w_i, v_i, b_i)\n\n        # Diagnostic rows\n        y[N_c:] = psi_true(R_d, Z_d)\n        B_vals_d = B(R_d, Z_d)\n        for i in range(n_f):\n            w_i, v_i, b_i = features[i]\n            phi_vals_d = phi(R_d, Z_d, w_i, v_i, b_i)\n            A[N_c:, i] = B_vals_d * phi_vals_d\n\n        # Solve for coefficients with Tikhonov regularization\n        A_aug = np.vstack([A, np.sqrt(lambda_reg) * np.eye(n_f)])\n        y_aug = np.concatenate([y, np.zeros(n_f)])\n        coeffs, _, _, _ = np.linalg.lstsq(A_aug, y_aug, rcond=None)\n        \n        # Calculate diagnostic error e_m\n        psi_pred_d = np.zeros(N_d)\n        B_vals_d = B(R_d, Z_d)\n        for i in range(n_f):\n            w_i, v_i, b_i = features[i]\n            psi_pred_d += coeffs[i] * B_vals_d * phi(R_d, Z_d, w_i, v_i, b_i)\n        \n        e_m_sq = np.mean((psi_pred_d - y[N_c:])**2)\n        \n        ensemble_members.append({'coeffs': coeffs, 'features': features})\n        ensemble_e_sq.append(e_m_sq)\n\n    # ----[ Uncertainty Evaluation at Test Points ]----\n    results = []\n    mean_e_sq = np.mean(ensemble_e_sq)\n\n    for R_test, Z_test in test_cases:\n        psi_m_list = []\n        rho_m_sq_list = []\n\n        is_boundary = np.isclose(R_test, R_min) or np.isclose(R_test, R_max) or \\\n                      np.isclose(Z_test, Z_min) or np.isclose(Z_test, Z_max)\n\n        for member in ensemble_members:\n            c = member['coeffs']\n            feats = member['features']\n            \n            # Prediction psi_m\n            if is_boundary:\n                psi_m = 0.0\n            else:\n                psi_m = np.sum([\n                    c[i] * B(R_test, Z_test) * phi(R_test, Z_test, *feats[i]) \n                    for i in range(n_f)]\n                )\n            \n            # Physics residual rho_m\n            L_psi_model = np.sum([\n                c[i] * L_B_phi(R_test, Z_test, *feats[i]) \n                for i in range(n_f)]\n            )\n            rho_m = L_psi_model + R_test * j_true(R_test, Z_test)\n\n            psi_m_list.append(psi_m)\n            rho_m_sq_list.append(rho_m**2)\n\n        # Aggregate uncertainties\n        psi_m_array = np.array(psi_m_list)\n        mu = np.mean(psi_m_array)\n        s2_ens = np.var(psi_m_array, ddof=1) if M > 1 else 0.0\n        mean_rho_sq = np.mean(rho_m_sq_list)\n        \n        v = s2_ens + mean_rho_sq + mean_e_sq\n\n        # Form interval and check coverage\n        half_width = 1.96 * np.sqrt(v)\n        interval_lower = mu - half_width\n        interval_upper = mu + half_width\n        \n        psi_t = psi_true(R_test, Z_test)\n        is_covered = (psi_t >= interval_lower) and (psi_t <= interval_upper)\n        results.append(is_covered)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}