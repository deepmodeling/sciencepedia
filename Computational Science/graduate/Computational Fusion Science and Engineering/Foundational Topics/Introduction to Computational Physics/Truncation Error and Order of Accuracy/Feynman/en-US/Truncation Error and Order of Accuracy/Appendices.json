{
    "hands_on_practices": [
        {
            "introduction": "The cornerstone of analyzing any finite difference scheme is the Taylor series expansion. This practice provides a foundational exercise in applying this tool to derive the leading-order truncation error for a high-order approximation of a first derivative . By meticulously tracking the cancellation of terms, you will see how the choice of stencil points and weights directly determines the scheme's formal order of accuracy.",
            "id": "4149911",
            "problem": "Consider the one-dimensional (1D) linearized acoustic system for small-amplitude waves in a homogeneous, inviscid medium with constant density $\\rho_{0}$ and sound speed $c$,\n$$\np_{t}(x,t)+\\rho_{0}c^{2}u_{x}(x,t)=0,\\qquad u_{t}(x,t)+\\frac{1}{\\rho_{0}}p_{x}(x,t)=0,\n$$\nwhere $p(x,t)$ is the acoustic pressure and $u(x,t)$ is the particle velocity. In explicit finite difference time integration schemes such as the Finite Difference Time Domain (FDTD) method, spatial derivatives like $p_{x}(x,t)$ are approximated on a uniform grid $x_{i}=x_{0}+ih$ with grid spacing $h>0$. At a fixed time $t$ (suppressed for notational simplicity), define the fourth-order centered finite difference approximation for $p_{x}(x)$ at grid point $x_{i}$ by\n$$\nD_{x}^{(4)}p_{i}:=\\frac{-p(x_{i}+2h)+8\\,p(x_{i}+h)-8\\,p(x_{i}-h)+p(x_{i}-2h)}{12\\,h}.\n$$\nAssume $p(x)$ is sufficiently smooth (at least five times continuously differentiable in a neighborhood of $x_{i}$). Starting from Taylor’s theorem and the smoothness of $p(x)$, derive the leading truncation error term of the discrete derivative $D_{x}^{(4)}p_{i}$ relative to the exact derivative $p_{x}(x_{i})$, and demonstrate that the truncation error is $O(h^{4})$ with a nonzero constant prefactor multiplying $h^{4}$. Express your final answer as a single closed-form analytic expression for the leading term of the truncation error $\\tau_{i}:=D_{x}^{(4)}p_{i}-p_{x}(x_{i})$, in terms of $h$ and the appropriate derivative of $p$ evaluated at $x_{i}$. No numerical rounding is required. The final answer must be a single analytic expression with no units.",
            "solution": "The problem is valid as it is scientifically grounded, well-posed, and objective. It consists of a standard derivation in numerical analysis applied to a common scenario in computational physics.\n\nThe objective is to derive the leading term of the truncation error $\\tau_i$ for the fourth-order centered finite difference approximation of the first derivative of a function $p(x)$ at grid point $x_i$. The truncation error is defined as the difference between the discrete approximation and the exact continuous derivative:\n$$\n\\tau_{i} := D_{x}^{(4)}p_{i} - \\frac{dp}{dx}(x_{i})\n$$\nwhere the discrete operator is given by:\n$$\nD_{x}^{(4)}p_{i} = \\frac{-p(x_{i}+2h)+8p(x_{i}+h)-8p(x_{i}-h)+p(x_{i}-2h)}{12h}\n$$\nThe problem states that $p(x)$ is at least five times continuously differentiable, which justifies the use of Taylor series expansions around the point $x_i$. We expand the terms $p(x_i \\pm h)$ and $p(x_i \\pm 2h)$ that appear in the numerator of the operator. Let $p^{(k)}(x_i)$ denote the $k$-th derivative of $p(x)$ with respect to $x$, evaluated at $x=x_i$.\n\nThe Taylor series expansion for $p(x_i + \\delta)$ around $x_i$ is:\n$$\np(x_i + \\delta) = p(x_i) + \\delta p^{(1)}(x_i) + \\frac{\\delta^2}{2!} p^{(2)}(x_i) + \\frac{\\delta^3}{3!} p^{(3)}(x_i) + \\frac{\\delta^4}{4!} p^{(4)}(x_i) + \\frac{\\delta^5}{5!} p^{(5)}(x_i) + O(\\delta^6)\n$$\nWe apply this expansion for $\\delta = h, -h, 2h, -2h$:\nFor $\\delta = h$:\n$$\np(x_{i}+h) = p(x_i) + h p^{(1)}(x_i) + \\frac{h^2}{2} p^{(2)}(x_i) + \\frac{h^3}{6} p^{(3)}(x_i) + \\frac{h^4}{24} p^{(4)}(x_i) + \\frac{h^5}{120} p^{(5)}(x_i) + O(h^6)\n$$\nFor $\\delta = -h$:\n$$\np(x_{i}-h) = p(x_i) - h p^{(1)}(x_i) + \\frac{h^2}{2} p^{(2)}(x_i) - \\frac{h^3}{6} p^{(3)}(x_i) + \\frac{h^4}{24} p^{(4)}(x_i) - \\frac{h^5}{120} p^{(5)}(x_i) + O(h^6)\n$$\nFor $\\delta = 2h$:\n$$\np(x_{i}+2h) = p(x_i) + 2h p^{(1)}(x_i) + \\frac{(2h)^2}{2} p^{(2)}(x_i) + \\frac{(2h)^3}{6} p^{(3)}(x_i) + \\frac{(2h)^4}{24} p^{(4)}(x_i) + \\frac{(2h)^5}{120} p^{(5)}(x_i) + O(h^6)\n$$\n$$\np(x_{i}+2h) = p(x_i) + 2h p^{(1)}(x_i) + 2h^2 p^{(2)}(x_i) + \\frac{4h^3}{3} p^{(3)}(x_i) + \\frac{2h^4}{3} p^{(4)}(x_i) + \\frac{4h^5}{15} p^{(5)}(x_i) + O(h^6)\n$$\nFor $\\delta = -2h$:\n$$\np(x_{i}-2h) = p(x_i) - 2h p^{(1)}(x_i) + \\frac{(-2h)^2}{2} p^{(2)}(x_i) + \\frac{(-2h)^3}{6} p^{(3)}(x_i) + \\frac{(-2h)^4}{24} p^{(4)}(x_i) + \\frac{(-2h)^5}{120} p^{(5)}(x_i) + O(h^6)\n$$\n$$\np(x_{i}-2h) = p(x_i) - 2h p^{(1)}(x_i) + 2h^2 p^{(2)}(x_i) - \\frac{4h^3}{3} p^{(3)}(x_i) + \\frac{2h^4}{3} p^{(4)}(x_i) - \\frac{4h^5}{15} p^{(5)}(x_i) + O(h^6)\n$$\nNow, we substitute these expansions into the numerator of $D_{x}^{(4)}p_{i}$:\n$$\n\\text{Numerator} = -p(x_{i}+2h)+8p(x_{i}+h)-8p(x_{i}-h)+p(x_{i}-2h)\n$$\nWe collect coefficients for each derivative of $p$ at $x_i$:\n-   Coefficient of $p(x_i)$: $-1 + 8 - 8 + 1 = 0$.\n-   Coefficient of $p^{(1)}(x_i)$: $h(-2 + 8 \\cdot 1 - 8 \\cdot (-1) + 1 \\cdot (-2)) = h(-2 + 8 + 8 - 2) = 12h$.\n-   Coefficient of $p^{(2)}(x_i)$: $h^2(-2 + 8 \\cdot \\frac{1}{2} - 8 \\cdot \\frac{1}{2} + 1 \\cdot 2) = h^2(-2 + 4 - 4 + 2) = 0$.\n-   Coefficient of $p^{(3)}(x_i)$: $h^3(-\\frac{4}{3} + 8 \\cdot \\frac{1}{6} - 8 \\cdot (-\\frac{1}{6}) + 1 \\cdot (-\\frac{4}{3})) = h^3(-\\frac{4}{3} + \\frac{4}{3} + \\frac{4}{3} - \\frac{4}{3}) = 0$.\n-   Coefficient of $p^{(4)}(x_i)$: $h^4(-\\frac{2}{3} + 8 \\cdot \\frac{1}{24} - 8 \\cdot \\frac{1}{24} + 1 \\cdot \\frac{2}{3}) = h^4(-\\frac{2}{3} + \\frac{1}{3} - \\frac{1}{3} + \\frac{2}{3}) = 0$.\n-   Coefficient of $p^{(5)}(x_i)$: $h^5(-\\frac{4}{15} + 8 \\cdot \\frac{1}{120} - 8 \\cdot (-\\frac{1}{120}) + 1 \\cdot (-\\frac{4}{15})) = h^5(-\\frac{4}{15} + \\frac{8}{120} + \\frac{8}{120} - \\frac{4}{15}) = h^5(-\\frac{8}{15} + \\frac{16}{120}) = h^5(-\\frac{64}{120} + \\frac{16}{120}) = -\\frac{48}{120}h^5 = -\\frac{2}{5}h^5$.\n\nThe coefficients for the even-order derivative terms ($p^{(2)}(x_i)$ and $p^{(4)}(x_i)$) are zero due to the symmetry of the centered stencil, as confirmed by our calculations. The specific weights of this fourth-order scheme are also constructed to cancel the term involving $p^{(3)}(x_i)$. Thus, the leading error term arises from the $p^{(5)}(x_i)$ term.\nThe numerator can thus be expressed as:\n$$\n\\text{Numerator} = 12h p^{(1)}(x_i) - \\frac{2}{5}h^5 p^{(5)}(x_i) + O(h^7)\n$$\nThe $O(h^7)$ term arises from the seventh derivative of $p(x)$, since the coefficient for the sixth derivative term also cancels out for this symmetric stencil.\n\nNow we can write the expression for the full discrete operator:\n$$\nD_{x}^{(4)}p_{i} = \\frac{12h p^{(1)}(x_i) - \\frac{2}{5}h^5 p^{(5)}(x_i) + O(h^7)}{12h}\n$$\n$$\nD_{x}^{(4)}p_{i} = p^{(1)}(x_i) - \\frac{2}{5 \\cdot 12} h^4 p^{(5)}(x_i) + O(h^6)\n$$\n$$\nD_{x}^{(4)}p_{i} = p^{(1)}(x_i) - \\frac{1}{30} h^4 p^{(5)}(x_i) + O(h^6)\n$$\nThe truncation error $\\tau_i$ is found by subtracting the exact derivative $p^{(1)}(x_i)$ (which is $p_x(x_i)$ in the problem's notation):\n$$\n\\tau_i = D_{x}^{(4)}p_{i} - p^{(1)}(x_i) = \\left( p^{(1)}(x_i) - \\frac{1}{30} h^4 p^{(5)}(x_i) + O(h^6) \\right) - p^{(1)}(x_i)\n$$\n$$\n\\tau_i = - \\frac{1}{30} h^4 p^{(5)}(x_i) + O(h^6)\n$$\nThis demonstrates that the truncation error is of order $h^4$, i.e., $\\tau_i = O(h^4)$, as the leading error term is proportional to $h^4$. The prefactor $-\\frac{1}{30}p^{(5)}(x_i)$ is non-zero for any function $p(x)$ for which the fifth derivative is non-zero, confirming the assertion.\n\nThe leading term of the truncation error is therefore the first non-zero term in the expansion, which is $-\\frac{1}{30}h^4 p^{(5)}(x_i)$.",
            "answer": "$$\n\\boxed{-\\frac{h^{4}}{30} p^{(5)}(x_i)}\n$$"
        },
        {
            "introduction": "Standard error analysis relies on the assumption that the function being approximated is sufficiently smooth. This thought-provoking exercise explores what happens when this assumption is violated, using the function $f(x)=|x|^3$ as a case study . You will discover that the *effective* order of accuracy can be lower than the formal order predicted by Taylor series analysis on smooth functions, a crucial lesson in the careful application of numerical theory.",
            "id": "2421857",
            "problem": "Let $f:\\mathbb{R}\\to\\mathbb{R}$ be defined by $f(x)=|x|^{3}$. Consider a uniform grid with spacing $h>0$ and the three-point central finite difference approximation for the second derivative of $f$ at $x=0$ given by\n$$\nD_{h}^{(2)}f(0)=\\frac{f(h)-2f(0)+f(-h)}{h^{2}}.\n$$\nDefine the effective order of accuracy $p$ of this approximation at $x=0$ as the largest real number $p$ such that the pointwise error $E(h)=\\left|D_{h}^{(2)}f(0)-f''(0)\\right|$ satisfies $E(h)=\\mathcal{O}(h^{p})$ as $h\\to 0^{+}$. It is known that $f''(0)$ exists but $f'''(0)$ is undefined.\n\nDetermine the exact value of $p$. Provide your answer as a single number with no units. No rounding is required.",
            "solution": "The problem statement presented for analysis is first subjected to a rigorous validation process.\n\nThe givens are as follows:\n- The function is $f(x) = |x|^3$ for $x \\in \\mathbb{R}$.\n- The finite difference approximation for the second derivative at $x=0$ is $D_{h}^{(2)}f(0) = \\frac{f(h) - 2f(0) + f(-h)}{h^2}$, for a grid spacing $h>0$.\n- The pointwise error is $E(h) = |D_{h}^{(2)}f(0) - f''(0)|$.\n- The effective order of accuracy, $p$, is defined as the largest real number such that $E(h) = \\mathcal{O}(h^p)$ as $h \\to 0^+$.\n- It is stated that $f''(0)$ exists and $f'''(0)$ is undefined.\n\nAn initial verification of the stated properties of the function $f(x)=|x|^3$ is required.\nFor $x \\neq 0$, the derivatives are straightforward. For $x>0$, $f(x)=x^3$, which gives $f'(x)=3x^2$ and $f''(x)=6x$. For $x<0$, $f(x)=-x^3$, which gives $f'(x)=-3x^2$ and $f''(x)=-6x$. In compact form for $x \\neq 0$, $f'(x)=3x|x|$ and $f''(x)=6|x|$.\n\nWe must check the derivatives at $x=0$ from the limit definitions.\nThe first derivative is:\n$$\nf'(0) = \\lim_{\\Delta x \\to 0} \\frac{f(0+\\Delta x) - f(0)}{\\Delta x} = \\lim_{\\Delta x \\to 0} \\frac{|\\Delta x|^3 - 0}{\\Delta x} = \\lim_{\\Delta x \\to 0} (\\Delta x)^2 \\frac{|\\Delta x|}{\\Delta x} = 0\n$$\nThe second derivative is:\n$$\nf''(0) = \\lim_{\\Delta x \\to 0} \\frac{f'(\\Delta x) - f'(0)}{\\Delta x} = \\lim_{\\Delta x \\to 0} \\frac{3(\\Delta x)|\\Delta x| - 0}{\\Delta x} = \\lim_{\\Delta x \\to 0} 3|\\Delta x| = 0\n$$\nSo, $f''(0)$ exists and is equal to $0$.\nThe third derivative is:\n$$\nf'''(0) = \\lim_{\\Delta x \\to 0} \\frac{f''(\\Delta x) - f''(0)}{\\Delta x} = \\lim_{\\Delta x \\to 0} \\frac{6|\\Delta x| - 0}{\\Delta x} = 6 \\lim_{\\Delta x \\to 0} \\frac{|\\Delta x|}{\\Delta x}\n$$\nThe right-hand limit as $\\Delta x \\to 0^+$ is $6$, while the left-hand limit as $\\Delta x \\to 0^-$ is $-6$. Since the limits are not equal, $f'''(0)$ is undefined.\nThe premises of the problem are thus verified as correct and self-consistent. The problem is well-posed and scientifically grounded in the field of numerical analysis. We may proceed with the solution.\n\nThe task is to determine the effective order of accuracy $p$. We begin by computing the finite difference approximation $D_{h}^{(2)}f(0)$ directly.\nThe formula is:\n$$\nD_{h}^{(2)}f(0) = \\frac{f(h) - 2f(0) + f(-h)}{h^2}\n$$\nWe evaluate the function $f(x) = |x|^3$ at the required points. Since $h>0$:\n- $f(h) = |h|^3 = h^3$\n- $f(0) = |0|^3 = 0$\n- $f(-h) = |-h|^3 = h^3$\n\nSubstituting these values into the formula:\n$$\nD_{h}^{(2)}f(0) = \\frac{h^3 - 2(0) + h^3}{h^2} = \\frac{2h^3}{h^2} = 2h\n$$\nNext, we evaluate the pointwise error $E(h) = |D_{h}^{(2)}f(0) - f''(0)|$. We have already established that $f''(0)=0$.\nTherefore, the error is:\n$$\nE(h) = |2h - 0| = 2h\n$$\nwhere we use the fact that $h>0$.\n\nThe standard Taylor series analysis for a sufficiently smooth function $g \\in C^4(\\mathbb{R})$ would predict that the truncation error for this central difference scheme is of order $\\mathcal{O}(h^2)$, since\n$$\n\\frac{g(x+h) - 2g(x) + g(x-h)}{h^2} - g''(x) = \\frac{g^{(4)}(\\xi)}{12}h^2\n$$\nThis result is contingent on the cancellation of the third-order derivative terms, which requires the existence and continuity of $g'''(x)$. In the present problem, $f'''(0)$ does not exist. This lack of smoothness invalidates the standard analysis and leads to a degradation of the order of accuracy. Our direct calculation confirms this.\n\nWe must find the largest real number $p$ such that $E(h) = \\mathcal{O}(h^p)$ as $h \\to 0^+$. This is equivalent to finding the largest $p$ for which the following limit is bounded:\n$$\n\\limsup_{h \\to 0^+} \\frac{E(h)}{h^p} < \\infty\n$$\nSubstituting our expression for $E(h)$:\n$$\n\\limsup_{h \\to 0^+} \\frac{2h}{h^p} = \\limsup_{h \\to 0^+} 2h^{1-p}\n$$\nFor this limit to be finite, the exponent of $h$ must be non-negative. That is, $1-p \\ge 0$, which implies $p \\le 1$.\nThe largest real number $p$ satisfying this condition is $p=1$.\nFor $p=1$, the limit is $\\lim_{h \\to 0^+} 2h^{1-1} = \\lim_{h \\to 0^+} 2 = 2$. This is a finite, non-zero constant, confirming that $E(h)$ is indeed $\\mathcal{O}(h^1)$.\nFor any $p > 1$, say $p = 1 + \\epsilon$ with $\\epsilon > 0$, the limit becomes $\\lim_{h \\to 0^+} 2h^{-\\epsilon} = \\infty$. This shows that $E(h)$ is not $\\mathcal{O}(h^p)$ for any $p>1$.\n\nThus, the largest real number $p$ for which $E(h) = \\mathcal{O}(h^p)$ is exactly $1$.\nThe effective order of accuracy is $p=1$.",
            "answer": "$$\n\\boxed{1}\n$$"
        },
        {
            "introduction": "Moving from theory to practice, this exercise demonstrates how to verify the order of accuracy of a numerical solver computationally. You will derive the formulas for a grid refinement study, a standard procedure for estimating the *observed* order of accuracy from a set of numerical results . Furthermore, you will learn to apply Richardson extrapolation, a powerful technique that uses the asymptotic error model to produce a more accurate solution.",
            "id": "4149943",
            "problem": "You are tasked with designing a mathematically rigorous grid refinement study to estimate the observed order of accuracy for an acoustic solver, using three solutions computed on successively refined spatial grids with spacings $h$, $h/2$, and $h/4$. Your goal is to derive the estimator for the observed order of accuracy and a consistent Richardson extrapolation formula for the underlying acoustic observable, and to implement these in a program that evaluates a set of test cases.\n\nThe fundamental base for this problem is the definition of truncation error and order of accuracy. For a consistent numerical method approximating a smooth acoustic observable (for example, a sample of acoustic pressure or a spatial norm) on a grid with spacing $h$, the discrete approximation $S_h$ satisfies, for sufficiently small $h$, the asymptotic error model\n$$\nS_h = S + C h^p + \\mathcal{O}\\left(h^{p+1}\\right),\n$$\nwhere $S$ is the exact observable, $C$ is a constant independent of $h$, and $p$ is the (unknown) order of accuracy. The purpose of the grid refinement study is to estimate $p$ and to compute an extrapolated approximation of $S$ using only $S_h$, $S_{h/2}$, and $S_{h/4}$.\n\nDesign requirements:\n- Starting from the asymptotic error model above, derive a formula to estimate the observed order $p$ using the three approximations $S_h$, $S_{h/2}$, and $S_{h/4}$ at refinement ratio $r = 2$.\n- Derive a Richardson extrapolation formula for $S$ using the two finest-grid approximations and your estimated order $p$.\n- The derivations must be performed without invoking any pre-derived “shortcut” formulas. You must start from the error model and reason to the final formulas.\n\nImplementation requirements:\n- Implement a program that constructs synthetic “acoustic solver” outputs consistent with the asymptotic model. For each test case, you will be given parameters $(S_\\star, p_{\\text{true}}, C, D, h)$, and you must define synthetic approximations by\n$$\nS_h = S_\\star + C h^{p_{\\text{true}}} + D h^{p_{\\text{true}} + 1}, \\quad\nS_{h/2} = S_\\star + C \\left(\\frac{h}{2}\\right)^{p_{\\text{true}}} + D \\left(\\frac{h}{2}\\right)^{p_{\\text{true}} + 1}, \\quad\nS_{h/4} = S_\\star + C \\left(\\frac{h}{4}\\right)^{p_{\\text{true}}} + D \\left(\\frac{h}{4}\\right)^{p_{\\text{true}} + 1}.\n$$\nHere $S_\\star$ represents an exact acoustic observable (dimensionless), $p_{\\text{true}}$ is the true order of the synthetic model, $C$ is the leading-order error coefficient, and $D$ is a subleading error coefficient representing higher-order contamination.\n- From these three values, compute the observed order $p_{\\text{obs}}$ and an extrapolated solution $S_{\\text{ext}}$ using your derived formulas. Use the finest pair $(h/2,h/4)$ for extrapolation to reduce higher-order contamination.\n- For numerical robustness, take absolute values inside the logarithm when estimating the order to avoid issues with sign changes in $C$; you must still ensure the ratio is positive and finite.\n\nTest suite:\nUse the following four test cases, each defined by $(S_\\star, p_{\\text{true}}, C, D, h)$.\n- Case $1$: $(0.75321, 2, 0.5, 0, 0.1)$\n- Case $2$: $(-0.132, 3, -0.3, 0, 0.12)$\n- Case $3$: $(2.5, 4, 1.0, 5.0, 0.08)$\n- Case $4$: $(0.0, 2, 1.0 \\times 10^{-4}, 0, 0.5)$\n\nProgram output specification:\n- For each test case, output two floats: the observed order $p_{\\text{obs}}$ and the extrapolated solution $S_{\\text{ext}}$, both rounded to $6$ decimal places.\n- Aggregate the results for all four test cases into a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order\n$$\n[p_{\\text{obs}}^{(1)}, S_{\\text{ext}}^{(1)}, p_{\\text{obs}}^{(2)}, S_{\\text{ext}}^{(2)}, p_{\\text{obs}}^{(3)}, S_{\\text{ext}}^{(3)}, p_{\\text{obs}}^{(4)}, S_{\\text{ext}}^{(4)}].\n$$\nNo physical units are required because all quantities are dimensionless by construction. Do not include any additional text in the output.",
            "solution": "The problem requires the derivation of an estimator for the observed order of accuracy, $p_{\\text{obs}}$, and a corresponding Richardson extrapolation formula, $S_{\\text{ext}}$, based on three numerical solutions from a grid refinement study. Following this, an implementation is required to apply these formulas to a set of synthetic test cases.\n\nThe foundation for this analysis is the asymptotic error model for a numerical approximation $S_h$ of an exact quantity $S$ on a grid with characteristic spacing $h$:\n$$\nS_h = S + C h^p + \\mathcal{O}\\left(h^{p+1}\\right)\n$$\nHere, $p$ is the formal order of accuracy of the numerical method and $C$ is the leading-order error coefficient, assumed to be constant for sufficiently small $h$.\n\nWe are provided with three solutions, $S_h$, $S_{h/2}$, and $S_{h/4}$, computed on successively refined grids with a constant refinement ratio $r=2$. To simplify the derivation, we will denote these solutions as $S_1 = S_h$, $S_2 = S_{h/2}$, and $S_3 = S_{h/4}$. By truncating the asymptotic error model and neglecting the higher-order terms $\\mathcal{O}(h^{p+1})$, we obtain a system of approximate equations. This truncation is valid in the asymptotic limit where $h \\to 0$.\n\n$$\nS_1 \\approx S + C h^p \\\\\nS_2 \\approx S + C \\left(\\frac{h}{2}\\right)^p = S + C \\frac{h^p}{2^p} \\\\\nS_3 \\approx S + C \\left(\\frac{h}{4}\\right)^p = S + C \\frac{h^p}{4^p}\n$$\n\n**Derivation of the Observed Order of Accuracy ($p_{\\text{obs}}$)**\n\nOur first goal is to estimate the order of accuracy $p$ using the three available solutions. The strategy is to eliminate the unknown quantities $S$ and $C$ from the system of equations. We can eliminate $S$ by considering the differences between successive approximations:\n\n$$\nS_1 - S_2 \\approx \\left(S + C h^p\\right) - \\left(S + C \\frac{h^p}{2^p}\\right) = C h^p \\left(1 - \\frac{1}{2^p}\\right)\n$$\n\n$$\nS_2 - S_3 \\approx \\left(S + C \\frac{h^p}{2^p}\\right) - \\left(S + C \\frac{h^p}{4^p}\\right) = C \\frac{h^p}{2^p} \\left(1 - \\frac{1}{2^p}\\right)\n$$\n\nNow, we can eliminate the term $C h^p \\left(1 - \\frac{1}{2^p}\\right)$ by taking the ratio of these two differences. This is permissible as long as the denominator is non-zero, which is generally true for a converging solution where the error does not vanish prematurely.\n\n$$\n\\frac{S_1 - S_2}{S_2 - S_3} \\approx \\frac{C h^p \\left(1 - \\frac{1}{2^p}\\right)}{C \\frac{h^p}{2^p} \\left(1 - \\frac{1}{2^p}\\right)} = 2^p\n$$\nThis relationship provides a direct way to solve for $p$. By taking the natural logarithm of both sides, we can isolate $p$:\n\n$$\n\\ln\\left(\\frac{S_1 - S_2}{S_2 - S_3}\\right) \\approx \\ln(2^p) = p \\ln(2)\n$$\n\nSolving for $p$ gives the estimator for the observed order of accuracy, which we denote $p_{\\text{obs}}$:\n\n$$\np_{\\text{obs}} = \\frac{\\ln\\left(\\frac{S_h - S_{h/2}}{S_{h/2} - S_{h/4}}\\right)}{\\ln(2)}\n$$\n\nFor numerical robustness, particularly when dealing with real solver output that may include floating-point noise or non-monotonically convergent behavior, it is prudent to take the absolute value of the ratio before applying the logarithm, as specified in the problem.\n\n$$\np_{\\text{obs}} = \\frac{\\ln\\left(\\left| \\frac{S_h - S_{h/2}}{S_{h/2} - S_{h/4}} \\right|\\right)}{\\ln(2)}\n$$\n\n**Derivation of the Richardson Extrapolation Formula ($S_{\\text{ext}}$)**\n\nOur second goal is to derive a more accurate estimate of the exact solution $S$ using the available approximations. This procedure is known as Richardson extrapolation. The problem specifies using the two finest-grid solutions, $S_2 = S_{h/2}$ and $S_3 = S_{h/4}$, along with our estimated order of accuracy, $p_{\\text{obs}}$.\n\nWe return to the truncated error equations for these two solutions, now using $p_{\\text{obs}}$ as our estimate for $p$:\n\n$$\nS_2 \\approx S + C \\left(\\frac{h}{2}\\right)^{p_{\\text{obs}}} \\\\\nS_3 \\approx S + C \\left(\\frac{h}{4}\\right)^{p_{\\text{obs}}} = S + C \\frac{(h/2)^{p_{\\text{obs}}}}{2^{p_{\\text{obs}}}}\n$$\n\nThis is a system of two linear equations in the two unknowns $S$ and the error term $E_2 = C (h/2)^{p_{\\text{obs}}}$. Our objective is to solve for $S$. Let's rewrite the system:\n\n$$\nS_2 \\approx S + E_2 \\\\\nS_3 \\approx S + \\frac{E_2}{2^{p_{\\text{obs}}}}\n$$\n\nFrom the first equation, we can express the error term $E_2$ as $E_2 \\approx S_2 - S$. Substituting this into the second equation yields:\n\n$$\nS_3 \\approx S + \\frac{S_2 - S}{2^{p_{\\text{obs}}}}\n$$\n\nWe now solve this equation for $S$. Multiply both sides by $2^{p_{\\text{obs}}}$ to clear the denominator:\n\n$$\nS_3 \\cdot 2^{p_{\\text{obs}}} \\approx S \\cdot 2^{p_{\\text{obs}}} + S_2 - S\n$$\n\nGroup the terms involving $S$:\n\n$$\nS_3 \\cdot 2^{p_{\\text{obs}}} - S_2 \\approx S \\left(2^{p_{\\text{obs}}} - 1\\right)\n$$\n\nFinally, dividing by $(2^{p_{\\text{obs}}} - 1)$ gives the formula for the Richardson-extrapolated solution, $S_{\\text{ext}}$. This formula is valid provided that $p_{\\text{obs}} \\neq 0$.\n\n$$\nS_{\\text{ext}} = \\frac{S_3 \\cdot 2^{p_{\\text{obs}}} - S_2}{2^{p_{\\text{obs}}} - 1} = \\frac{S_{h/4} \\cdot 2^{p_{\\text{obs}}} - S_{h/2}}{2^{p_{\\text{obs}}} - 1}\n$$\n\nThis extrapolated value, $S_{\\text{ext}}$, has an error that is of a higher order than the original approximations, typically $\\mathcal{O}(h^{p+1})$, assuming the asymptotic error model accurately describes the solver's behavior on the grids used.\n\nThe implementation will proceed by first generating the synthetic data points $S_h$, $S_{h/2}$, and $S_{h/4}$ for each test case. Then, it will apply the derived formula for $p_{\\text{obs}}$, followed by the formula for $S_{\\text{ext}}$, and format the results as specified.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the grid refinement study problem by deriving estimators for the\n    order of accuracy and performing Richardson extrapolation.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (S_star, p_true, C, D, h)\n    test_cases = [\n        (0.75321, 2, 0.5, 0, 0.1),\n        (-0.132, 3, -0.3, 0, 0.12),\n        (2.5, 4, 1.0, 5.0, 0.08),\n        (0.0, 2, 1.0e-4, 0, 0.5),\n    ]\n\n    results = []\n    for case in test_cases:\n        S_star, p_true, C, D, h = case\n\n        # 1. Generate synthetic \"acoustic solver\" outputs\n        # S_h = S_star + C*h^p + D*h^(p+1)\n        s_h = S_star + C * h**p_true + D * h**(p_true + 1)\n        # S_h/2\n        s_h_2 = S_star + C * (h / 2)**p_true + D * (h / 2)**(p_true + 1)\n        # S_h/4\n        s_h_4 = S_star + C * (h / 4)**p_true + D * (h / 4)**(p_true + 1)\n\n        # 2. Compute the observed order of accuracy (p_obs)\n        # p_obs = ln(|(S_h - S_h/2) / (S_h/2 - S_h/4)|) / ln(2)\n        numerator = s_h - s_h_2\n        denominator = s_h_2 - s_h_4\n\n        # The problem cases are well-behaved, so denominator won't be zero.\n        ratio = numerator / denominator\n        \n        # Taking the absolute value as per the problem's robustness requirement.\n        p_obs = np.log(np.abs(ratio)) / np.log(2)\n\n        # 3. Compute the extrapolated solution (S_ext)\n        # S_ext = (S_h/4 * 2^p_obs - S_h/2) / (2^p_obs - 1)\n        # This formula is valid for p_obs != 0.\n        power_of_2 = 2**p_obs\n        S_ext = (s_h_4 * power_of_2 - s_h_2) / (power_of_2 - 1)\n\n        # 4. Round results to 6 decimal places and append to the list\n        results.append(round(p_obs, 6))\n        results.append(round(S_ext, 6))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}