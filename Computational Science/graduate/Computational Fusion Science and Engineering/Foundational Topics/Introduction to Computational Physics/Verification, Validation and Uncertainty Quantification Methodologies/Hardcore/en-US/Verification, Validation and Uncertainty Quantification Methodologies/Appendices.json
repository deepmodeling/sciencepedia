{
    "hands_on_practices": [
        {
            "introduction": "Before we can trust a simulation's predictions, we must rigorously verify that the code correctly solves the mathematical equations it claims to. The Method of Manufactured Solutions (MMS) is a cornerstone of code verification, providing a powerful way to test a solver against a problem where the exact analytical solution is known by design . In this exercise, you will apply MMS to the Grad–Shafranov equation, which governs magnetohydrodynamic equilibrium in tokamaks, to derive a source term, implement a numerical solver, and confirm its theoretical order of accuracy by measuring the error against the manufactured solution.",
            "id": "4061811",
            "problem": "You are tasked with designing and implementing a method of manufactured solutions for the axisymmetric two-dimensional Grad–Shafranov operator to support Verification and Validation (VV) and Uncertainty Quantification (UQ) methodologies in computational fusion science and engineering. Consider the axisymmetric Grad–Shafranov operator defined for the poloidal flux function $\\psi(R,Z)$ by\n$$\n\\Delta^\\star \\psi \\equiv R \\frac{\\partial}{\\partial R} \\left( \\frac{1}{R} \\frac{\\partial \\psi}{\\partial R} \\right) + \\frac{\\partial^2 \\psi}{\\partial Z^2}.\n$$\nIn this problem, you will construct a manufactured solution and derive the corresponding source term so that the partial differential equation (PDE)\n$$\n\\Delta^\\star \\psi(R,Z) = S(R,Z)\n$$\nis exactly satisfied, where $R$ denotes the major radius and $Z$ denotes the vertical coordinate. The domain is rectangular in $(R,Z)$ space, with $R \\in [R_{\\min}, R_{\\max}]$ and $Z \\in [Z_{\\min}, Z_{\\max}]$, and you must impose Dirichlet boundary conditions consistent with the manufactured solution. All quantities are dimensionless. Any angles appearing inside trigonometric functions must be interpreted in radians.\n\nStarting from fundamental magnetohydrodynamic equilibrium considerations, the Grad–Shafranov operator $\\Delta^\\star$ arises from the balance of pressure and magnetic forces under axisymmetry, and serves as a core model for axisymmetric equilibrium. For the purposes of code verification using the method of manufactured solutions, you will specify $\\psi(R,Z)$ a priori, then derive $S(R,Z)$ and boundary conditions so that the PDE is satisfied by construction. You will solve the PDE numerically with a second-order finite-difference method on a uniform grid and compare the numerical solution to the exact manufactured solution to compute error norms and an observed order of accuracy.\n\nDefine the manufactured solution in separable form\n$$\n\\psi(R,Z) = f(R)\\, g(Z),\n$$\nwith\n$$\nf(R) = \\left(R - R_0\\right)^2 e^{-\\alpha R}, \\quad g(Z) = \\left(Z^2 + 1\\right) \\sin(\\beta Z),\n$$\nwhere $R_0$, $\\alpha$, and $\\beta$ are dimensionless parameters. Using only algebra and calculus, derive the source term $S(R,Z)$ required so that $\\psi(R,Z)$ exactly satisfies $\\Delta^\\star \\psi = S$. You must provide the source in terms of $R$, $Z$, $R_0$, $\\alpha$, and $\\beta$ without numerical approximation. Impose Dirichlet boundary conditions $\\psi(R,Z)$ on all boundaries of the rectangular domain.\n\nDiscretize the operator $\\Delta^\\star$ with a second-order accurate finite-difference method on a uniform tensor-product grid with $N_R$ points in $R$ and $N_Z$ points in $Z$. The discrete operator should be formed using a conservative flux approximation for the $R$-dependent part, i.e., let $a(R) = 1/R$ and approximate\n$$\n\\frac{\\partial}{\\partial R} \\left( a(R) \\frac{\\partial \\psi}{\\partial R} \\right)\n\\approx \\frac{1}{\\Delta R} \\left( a_{i+\\frac{1}{2}} \\frac{\\psi_{i+1,j} - \\psi_{i,j}}{\\Delta R} - a_{i-\\frac{1}{2}} \\frac{\\psi_{i,j} - \\psi_{i-1,j}}{\\Delta R} \\right),\n$$\nwith $a_{i\\pm \\frac{1}{2}} = a(R_{i\\pm \\frac{1}{2}})$, where $R_{i\\pm \\frac{1}{2}} = \\left(R_i + R_{i\\pm 1}\\right)/2$. The $Z$-second derivative should be approximated by the standard second-order central difference. Incorporate Dirichlet boundary conditions by moving boundary contributions to the right-hand side of the linear system. Solve the resulting sparse linear system for the interior unknowns and reconstruct the full solution by inserting the boundary values from the exact manufactured $\\psi(R,Z)$.\n\nCompute the following quantitative verification metrics:\n- The root-mean-square error $E_{\\mathrm{RMS}}$, defined as\n$$\nE_{\\mathrm{RMS}} = \\sqrt{\\frac{1}{N_{\\mathrm{int}}} \\sum_{(i,j)\\in \\Omega_{\\mathrm{int}}} \\left(\\psi^{\\mathrm{num}}_{i,j} - \\psi^{\\mathrm{exact}}_{i,j}\\right)^2},\n$$\nwhere $\\Omega_{\\mathrm{int}}$ indexes all interior grid points and $N_{\\mathrm{int}}$ is the number of interior points.\n- The maximum-norm error $E_{\\infty}$, defined as\n$$\nE_{\\infty} = \\max_{(i,j)\\in \\Omega_{\\mathrm{int}}} \\left| \\psi^{\\mathrm{num}}_{i,j} - \\psi^{\\mathrm{exact}}_{i,j} \\right|.\n$$\n\nAdditionally, for one refinement pair of test cases, compute the observed order of accuracy $p$ using the formula\n$$\np = \\frac{\\log\\left(E_{\\mathrm{coarse}} / E_{\\mathrm{fine}}\\right)}{\\log\\left(h_{\\mathrm{coarse}} / h_{\\mathrm{fine}}\\right)},\n$$\nwhere $E$ is the error norm (use both $E_{\\mathrm{RMS}}$ and $E_{\\infty}$ separately to compute two values of $p$) and $h$ is the maximum mesh spacing defined by $h = \\max\\{\\Delta R, \\Delta Z\\}$.\n\nYour program must implement the above and produce results for the following test suite of parameter values, which probe different numerical and physical aspects, including a general case, an edge case near the axis ($R$ small but nonzero), a more oscillatory case in $Z$, and a refinement pair for observed-order estimation. All angles inside $\\sin$ and $\\cos$ are in radians.\n\n- Test case $1$ (general case): $R_{\\min} = 1.0$, $R_{\\max} = 3.0$, $Z_{\\min} = -1.0$, $Z_{\\max} = 1.0$, $R_0 = 1.5$, $\\alpha = 0.3$, $\\beta = 4.0$, $N_R = 32$, $N_Z = 32$.\n- Test case $2$ (edge near axis): $R_{\\min} = 0.2$, $R_{\\max} = 2.0$, $Z_{\\min} = -1.0$, $Z_{\\max} = 1.0$, $R_0 = 0.9$, $\\alpha = 0.7$, $\\beta = 3.0$, $N_R = 36$, $N_Z = 36$.\n- Test case $3$ (oscillatory in $Z$): $R_{\\min} = 1.0$, $R_{\\max} = 2.5$, $Z_{\\min} = -2.0$, $Z_{\\max} = 2.0$, $R_0 = 1.2$, $\\alpha = 0.4$, $\\beta = 8.0$, $N_R = 48$, $N_Z = 64$.\n- Test case $4$ (refinement, coarse): $R_{\\min} = 1.0$, $R_{\\max} = 3.0$, $Z_{\\min} = -1.0$, $Z_{\\max} = 1.0$, $R_0 = 1.5$, $\\alpha = 0.3$, $\\beta = 4.0$, $N_R = 24$, $N_Z = 24$.\n- Test case $5$ (refinement, fine): $R_{\\min} = 1.0$, $R_{\\max} = 3.0$, $Z_{\\min} = -1.0$, $Z_{\\max} = 1.0$, $R_0 = 1.5$, $\\alpha = 0.3$, $\\beta = 4.0$, $N_R = 48$, $N_Z = 48$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must be ordered as\n$$\n\\left[ E_{\\mathrm{RMS}}^{(1)}, E_{\\infty}^{(1)}, E_{\\mathrm{RMS}}^{(2)}, E_{\\infty}^{(2)}, E_{\\mathrm{RMS}}^{(3)}, E_{\\infty}^{(3)}, E_{\\mathrm{RMS}}^{(4)}, E_{\\infty}^{(4)}, E_{\\mathrm{RMS}}^{(5)}, E_{\\infty}^{(5)}, p_{\\mathrm{RMS}}^{(4\\rightarrow 5)}, p_{\\infty}^{(4\\rightarrow 5)} \\right],\n$$\nwhere superscripts indicate the test case index and the observed orders $p_{\\mathrm{RMS}}^{(4\\rightarrow 5)}$ and $p_{\\infty}^{(4\\rightarrow 5)}$ are computed using test cases $4$ and $5$ as the coarse and fine pair, respectively. All entries must be floating-point numbers.",
            "solution": "The problem requires the design and implementation of a Method of Manufactured Solutions (MMS) for the two-dimensional axisymmetric Grad-Shafranov operator. This involves several stages: analytical derivation of a source term, numerical discretization and solution of the resulting partial differential equation (PDE), and quantitative error analysis to verify the implementation.\n\n### Step 1: Analytical Derivation of the Source Term\n\nThe Grad-Shafranov operator is given by\n$$\n\\Delta^\\star \\psi \\equiv R \\frac{\\partial}{\\partial R} \\left( \\frac{1}{R} \\frac{\\partial \\psi}{\\partial R} \\right) + \\frac{\\partial^2 \\psi}{\\partial Z^2}.\n$$\nExpanding the radial part, the operator can be rewritten as\n$$\n\\Delta^\\star \\psi = \\frac{\\partial^2 \\psi}{\\partial R^2} - \\frac{1}{R} \\frac{\\partial \\psi}{\\partial R} + \\frac{\\partial^2 \\psi}{\\partial Z^2}.\n$$\nThe manufactured solution is provided in separable form, $\\psi(R,Z) = f(R)g(Z)$, where\n$$\nf(R) = \\left(R - R_0\\right)^2 e^{-\\alpha R}\n$$\nand\n$$\ng(Z) = \\left(Z^2 + 1\\right) \\sin(\\beta Z).\n$$\nWe must find the source term $S(R,Z)$ such that $\\Delta^\\star \\psi(R,Z) = S(R,Z)$ is exactly satisfied. Applying the operator to the separable form yields\n$$\nS(R,Z) = \\Delta^\\star \\psi = g(Z) \\left( \\frac{d^2 f}{dR^2} - \\frac{1}{R} \\frac{df}{dR} \\right) + f(R) \\frac{d^2 g}{dZ^2}.\n$$\nWe proceed by computing the necessary derivatives for $f(R)$ and $g(Z)$.\n\nFor $f(R)$:\nThe first derivative is\n$$\n\\frac{df}{dR} = 2(R - R_0)e^{-\\alpha R} - \\alpha (R - R_0)^2 e^{-\\alpha R} = e^{-\\alpha R} (R - R_0) [2 - \\alpha(R - R_0)].\n$$\nThe second derivative is\n$$\n\\frac{d^2f}{dR^2} = [2 - 2\\alpha(R-R_0)]e^{-\\alpha R} - \\alpha e^{-\\alpha R} [2(R-R_0) - \\alpha(R-R_0)^2] = e^{-\\alpha R}[2 - 4\\alpha(R-R_0) + \\alpha^2(R-R_0)^2].\n$$\nLet the radial operator on $f$ be $L_R[f] = \\frac{d^2 f}{dR^2} - \\frac{1}{R} \\frac{df}{dR}$. Then,\n$$\nL_R[f] = e^{-\\alpha R} \\left( [2 - 4\\alpha(R-R_0) + \\alpha^2(R-R_0)^2] - \\frac{1}{R}(R-R_0)[2 - \\alpha(R-R_0)] \\right).\n$$\n\nFor $g(Z)$:\nThe first derivative is\n$$\n\\frac{dg}{dZ} = 2Z \\sin(\\beta Z) + \\beta(Z^2+1)\\cos(\\beta Z).\n$$\nThe second derivative is\n$$\n\\frac{d^2g}{dZ^2} = [2\\sin(\\beta Z) + 2Z\\beta\\cos(\\beta Z)] + [2Z\\beta\\cos(\\beta Z) - \\beta^2(Z^2+1)\\sin(\\beta Z)]\n$$\n$$\n\\frac{d^2g}{dZ^2} = [2 - \\beta^2(Z^2+1)]\\sin(\\beta Z) + 4Z\\beta\\cos(\\beta Z).\n$$\nThe source term $S(R,Z)$ is the sum of the two parts:\n$$\nS(R,Z) = g(Z) \\cdot L_R[f] + f(R) \\cdot \\frac{d^2g}{dZ^2}.\n$$\nThis analytical expression will be evaluated on the numerical grid to provide the right-hand side of the linear system.\n\n### Step 2: Numerical Discretization\n\nThe domain $[R_{\\min}, R_{\\max}] \\times [Z_{\\min}, Z_{\\max}]$ is discretized using a uniform tensor-product grid with $N_R$ points in $R$ and $N_Z$ points in $Z$. The grid spacings are $\\Delta R = (R_{\\max}-R_{\\min})/(N_R-1)$ and $\\Delta Z = (Z_{\\max}-Z_{\\min})/(N_Z-1)$. The grid points are denoted $(R_i, Z_j)$, where $R_i = R_{\\min} + i\\Delta R$ for $i=0, \\dots, N_R-1$ and $Z_j = Z_{\\min} + j\\Delta Z$ for $j=0, \\dots, N_Z-1$.\n\nThe PDE is discretized using a second-order finite-difference scheme. The discrete equation at an interior grid point $(i,j)$ for $i=1, \\dots, N_R-2$ and $j=1, \\dots, N_Z-2$ is $(\\Delta^\\star \\psi)_{i,j} = S_{i,j}$.\n\nThe radial part is discretized using the specified conservative flux approximation:\n$$\n\\left. R \\frac{\\partial}{\\partial R} \\left( \\frac{1}{R} \\frac{\\partial \\psi}{\\partial R} \\right) \\right|_{i,j} \\approx \\frac{R_i}{(\\Delta R)^2} \\left( a_{i+\\frac{1}{2}}(\\psi_{i+1,j} - \\psi_{i,j}) - a_{i-\\frac{1}{2}}(\\psi_{i,j} - \\psi_{i-1,j}) \\right),\n$$\nwhere $a(R)=1/R$ and $a_{i\\pm1/2} = 1/R_{i\\pm1/2}$ with $R_{i\\pm1/2} = (R_i + R_{i\\pm1})/2$.\nThe axial part is discretized using the standard second-order central difference:\n$$\n\\left. \\frac{\\partial^2 \\psi}{\\partial Z^2} \\right|_{i,j} \\approx \\frac{\\psi_{i,j+1} - 2\\psi_{i,j} + \\psi_{i,j-1}}{(\\Delta Z)^2}.\n$$\nCombining these gives a 5-point stencil for each interior point $(i,j)$:\n$$\nC_{i-1,j}\\psi_{i-1,j} + C_{i+1,j}\\psi_{i+1,j} + C_{i,j-1}\\psi_{i,j-1} + C_{i,j+1}\\psi_{i,j+1} + C_{i,j}\\psi_{i,j} = S_{i,j},\n$$\nwhere the coefficients are:\n- $C_{i,j} = -\\frac{R_i}{(\\Delta R)^2}(a_{i+\\frac{1}{2}} + a_{i-\\frac{1}{2}}) - \\frac{2}{(\\Delta Z)^2}$ (center)\n- $C_{i+1,j} = \\frac{R_i}{(\\Delta R)^2} a_{i+\\frac{1}{2}}$ (east)\n- $C_{i-1,j} = \\frac{R_i}{(\\Delta R)^2} a_{i-\\frac{1}{2}}$ (west)\n- $C_{i,j+1} = \\frac{1}{(\\Delta Z)^2}$ (north)\n- $C_{i,j-1} = \\frac{1}{(\\Delta Z)^2}$ (south)\n\n### Step 3: Linear System Formulation and Solution\n\nThe set of linear equations for all interior points forms a large, sparse linear system $A\\mathbf{x} = \\mathbf{b}$.\n- $\\mathbf{x}$ is a vector of the unknown values $\\psi_{i,j}$ at the $(N_R-2) \\times (N_Z-2)$ interior grid points, ordered lexicographically.\n- $A$ is the sparse matrix of coefficients, with a block-tridiagonal structure.\n- $\\mathbf{b}$ is the right-hand side vector, containing the source term values $S_{i,j}$ and contributions from the Dirichlet boundary conditions.\n\nThe boundary values of $\\psi$ are given by the exact manufactured solution, $\\psi^{\\mathrm{exact}}(R,Z)$, evaluated at the boundary grid points. For an interior point $(i,j)$ adjacent to a boundary, the term involving the boundary point is known and moved to the right-hand side. For example, for an interior point $(1,j)$, the term $C_{0,j}\\psi_{0,j}$ is moved, so the equation's right-hand side becomes $S_{1,j} - C_{0,j}\\psi^{\\mathrm{exact}}_{0,j}$. This procedure is applied at all interior points adjacent to any of the four boundaries.\n\nThe resulting sparse linear system is solved using a standard library routine (`scipy.sparse.linalg.spsolve`). The solution vector $\\mathbf{x}$ is then reshaped into a 2D array and placed into a full grid, whose boundary values are set from $\\psi^{\\mathrm{exact}}$, to form the complete numerical solution $\\psi^{\\mathrm{num}}$.\n\n### Step 4: Error Analysis and Verification\n\nThe numerical solution is compared to the exact manufactured solution to compute error norms. On the set of $N_{\\mathrm{int}} = (N_R-2)(N_Z-2)$ interior points $\\Omega_{\\mathrm{int}}$, we compute:\n- The root-mean-square error: $E_{\\mathrm{RMS}} = \\sqrt{\\frac{1}{N_{\\mathrm{int}}} \\sum_{(i,j)\\in \\Omega_{\\mathrm{int}}} (\\psi^{\\mathrm{num}}_{i,j} - \\psi^{\\mathrm{exact}}_{i,j})^2}$.\n- The maximum-norm error: $E_{\\infty} = \\max_{(i,j)\\in \\Omega_{\\mathrm{int}}} |\\psi^{\\mathrm{num}}_{i,j} - \\psi^{\\mathrm{exact}}_{i,j}|$.\n\nFor the refinement study using a coarse grid (test case 4) and a fine grid (test case 5), the observed order of accuracy $p$ is calculated as\n$$\np = \\frac{\\log(E_{\\mathrm{coarse}} / E_{\\mathrm{fine}})}{\\log(h_{\\mathrm{coarse}} / h_{\\mathrm{fine}})},\n$$\nwhere $E$ is either $E_{\\mathrm{RMS}}$ or $E_{\\infty}$, and $h = \\max\\{\\Delta R, \\Delta Z\\}$ is the maximum grid spacing. For the specified second-order scheme, we expect $p \\approx 2$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.sparse import lil_matrix, csc_matrix\nfrom scipy.sparse.linalg import spsolve\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n    test_cases = [\n        {'R_min': 1.0, 'R_max': 3.0, 'Z_min': -1.0, 'Z_max': 1.0, 'R_0': 1.5, 'alpha': 0.3, 'beta': 4.0, 'N_R': 32, 'N_Z': 32},\n        {'R_min': 0.2, 'R_max': 2.0, 'Z_min': -1.0, 'Z_max': 1.0, 'R_0': 0.9, 'alpha': 0.7, 'beta': 3.0, 'N_R': 36, 'N_Z': 36},\n        {'R_min': 1.0, 'R_max': 2.5, 'Z_min': -2.0, 'Z_max': 2.0, 'R_0': 1.2, 'alpha': 0.4, 'beta': 8.0, 'N_R': 48, 'N_Z': 64},\n        {'R_min': 1.0, 'R_max': 3.0, 'Z_min': -1.0, 'Z_max': 1.0, 'R_0': 1.5, 'alpha': 0.3, 'beta': 4.0, 'N_R': 24, 'N_Z': 24},\n        {'R_min': 1.0, 'R_max': 3.0, 'Z_min': -1.0, 'Z_max': 1.0, 'R_0': 1.5, 'alpha': 0.3, 'beta': 4.0, 'N_R': 48, 'N_Z': 48},\n    ]\n\n    results = []\n    errors = []\n\n    for case in test_cases:\n        e_rms, e_inf = run_case(**case)\n        results.extend([e_rms, e_inf])\n        errors.append({'rms': e_rms, 'inf': e_inf})\n\n    # Compute observed order of accuracy for cases 4 and 5\n    case4 = test_cases[3]\n    case5 = test_cases[4]\n    err4 = errors[3]\n    err5 = errors[4]\n\n    dR_c = (case4['R_max'] - case4['R_min']) / (case4['N_R'] - 1)\n    dZ_c = (case4['Z_max'] - case4['Z_min']) / (case4['N_Z'] - 1)\n    h_c = max(dR_c, dZ_c)\n\n    dR_f = (case5['R_max'] - case5['R_min']) / (case5['N_R'] - 1)\n    dZ_f = (case5['Z_max'] - case5['Z_min']) / (case5['N_Z'] - 1)\n    h_f = max(dR_f, dZ_f)\n\n    p_rms = np.log(err4['rms'] / err5['rms']) / np.log(h_c / h_f)\n    p_inf = np.log(err4['inf'] / err5['inf']) / np.log(h_c / h_f)\n\n    results.extend([p_rms, p_inf])\n\n    print(f\"[{','.join(map(str, results))}]\")\n\n\ndef run_case(R_min, R_max, Z_min, Z_max, R_0, alpha, beta, N_R, N_Z):\n    \"\"\"\n    Solves the PDE for a single test case and returns error norms.\n    \"\"\"\n    # Define manufactured solution and source term functions\n    def psi_exact_func(R, Z, R_0, alpha, beta):\n        fR = (R - R_0)**2 * np.exp(-alpha * R)\n        gZ = (Z**2 + 1) * np.sin(beta * Z)\n        return fR * gZ\n\n    def source_func(R, Z, R_0, alpha, beta):\n        # Radial part\n        R_minus_R0 = R - R_0\n        df_dR = (2 * R_minus_R0 - alpha * R_minus_R0**2) * np.exp(-alpha * R)\n        d2f_dR2 = (2 - 4 * alpha * R_minus_R0 + alpha**2 * R_minus_R0**2) * np.exp(-alpha * R)\n        L_R_f = d2f_dR2 - df_dR / R\n        gZ = (Z**2 + 1) * np.sin(beta * Z)\n        term1 = L_R_f * gZ\n\n        # Axial part\n        fR = (R - R_0)**2 * np.exp(-alpha * R)\n        Z2_plus_1 = Z**2 + 1\n        d2g_dZ2 = (2 - beta**2 * Z2_plus_1) * np.sin(beta * Z) + 4 * Z * beta * np.cos(beta * Z)\n        term2 = fR * d2g_dZ2\n\n        return term1 + term2\n\n    # Create grid\n    R_vec = np.linspace(R_min, R_max, N_R)\n    Z_vec = np.linspace(Z_min, Z_max, N_Z)\n    dR = R_vec[1] - R_vec[0]\n    dZ = Z_vec[1] - Z_vec[0]\n    R, Z = np.meshgrid(R_vec, Z_vec, indexing='ij')\n\n    # Evaluate exact solution and source term on the grid\n    psi_exact = psi_exact_func(R, Z, R_0, alpha, beta)\n    S = source_func(R, Z, R_0, alpha, beta)\n\n    # Set up the linear system Ax = b for interior points\n    Ni = N_R - 2\n    Nj = N_Z - 2\n    N_int = Ni * Nj\n    \n    A = lil_matrix((N_int, N_int))\n    b = np.zeros(N_int)\n\n    for i in range(1, N_R - 1):\n        for j in range(1, N_Z - 1):\n            k = (i - 1) * Nj + (j - 1)\n            \n            # Source term\n            b[k] = S[i, j]\n\n            # Operator coefficients\n            R_i = R_vec[i]\n            a_ip12 = 1.0 / (R_i + 0.5 * dR)\n            a_im12 = 1.0 / (R_i - 0.5 * dR)\n\n            # Center\n            A[k, k] = -R_i / dR**2 * (a_ip12 + a_im12) - 2.0 / dZ**2\n\n            # West neighbor (i-1)\n            coeff_W = R_i / dR**2 * a_im12\n            if i == 1:\n                b[k] -= coeff_W * psi_exact[0, j]\n            else:\n                A[k, k - Nj] = coeff_W\n\n            # East neighbor (i+1)\n            coeff_E = R_i / dR**2 * a_ip12\n            if i == N_R - 2:\n                b[k] -= coeff_E * psi_exact[N_R - 1, j]\n            else:\n                A[k, k + Nj] = coeff_E\n\n            # South neighbor (j-1)\n            coeff_S = 1.0 / dZ**2\n            if j == 1:\n                b[k] -= coeff_S * psi_exact[i, 0]\n            else:\n                A[k, k - 1] = coeff_S\n\n            # North neighbor (j+1)\n            coeff_N = 1.0 / dZ**2\n            if j == N_Z - 2:\n                b[k] -= coeff_N * psi_exact[i, N_Z - 1]\n            else:\n                A[k, k + 1] = coeff_N\n\n    # Solve the system\n    A = A.tocsc()\n    psi_int_flat = spsolve(A, b)\n    psi_int = psi_int_flat.reshape((Ni, Nj))\n\n    # Reconstruct full solution\n    psi_num = np.copy(psi_exact)\n    psi_num[1:N_R-1, 1:N_Z-1] = psi_int\n\n    # Calculate errors on interior points\n    diff = psi_num[1:N_R-1, 1:N_Z-1] - psi_exact[1:N_R-1, 1:N_Z-1]\n    e_rms = np.sqrt(np.mean(diff**2))\n    e_inf = np.max(np.abs(diff))\n\n    return e_rms, e_inf\n\nsolve()\n```"
        },
        {
            "introduction": "Once a code is verified, the next step is to quantify the error in a specific simulation result, which is almost always dominated by discretization error. The Grid Convergence Index (GCI) is a widely accepted, standardized procedure for estimating this error by comparing solutions on systematically refined computational meshes . This practice will guide you through the calculation of the GCI for a critical engineering parameter in a tokamak—the peak heat flux on the divertor—using a hypothetical dataset, allowing you to estimate the solution's convergence order and uncertainty.",
            "id": "4061829",
            "problem": "A high-fidelity edge plasma transport simulation for a tokamak predicts the outer divertor target peak heat flux, a scalar quantity denoted by $\\phi$. Three systematically refined meshes are used with uniform refinement ratio $r_{21} = r_{32} = r = 2$, and the corresponding computed values of $\\phi$ are $\\phi_{3} = 5.90$ megawatts per square meter on the coarse mesh, $\\phi_{2} = 5.30$ megawatts per square meter on the medium mesh, and $\\phi_{1} = 5.10$ megawatts per square meter on the fine mesh. Assume a fixed physical domain and that the numerical method yields a smooth discretization error expansion of the form $\\phi(h) = \\phi_{\\ast} + C h^{p} + \\mathcal{O}(h^{p+1})$, where $h$ is an appropriate single-parameter measure of mesh spacing, $\\phi_{\\ast}$ is the mesh-converged value, $C$ is a constant independent of $h$, and $p$ is the observed order of accuracy. Assume further that the three meshes are in the asymptotic range of convergence. The Grid Convergence Index (GCI) employs a safety factor $F_{s}$ to provide a conservative estimate of the relative discretization uncertainty. Use $F_{s} = 1.25$ for the GCI safety factor (this is the Grid Convergence Index safety factor, not the tokamak safety factor).\n\nStarting from the stated discretization error expansion and the concept of Richardson extrapolation under constant refinement ratio, derive the necessary expressions to compute the observed order $p$ from the three solutions and then the fine-to-medium Grid Convergence Index, $\\mathrm{GCI}_{21}$, defined to represent a conservative estimate of the relative error on the fine mesh with respect to mesh refinement. Then, evaluate $\\mathrm{GCI}_{21}$ numerically using the provided data and $F_{s}$.\n\nReport only the value of $\\mathrm{GCI}_{21}$ as a dimensionless decimal (not a percentage), rounded to three significant figures.",
            "solution": "The problem requires the derivation of expressions for the observed order of accuracy, $p$, and the fine-to-medium Grid Convergence Index, $\\mathrm{GCI}_{21}$, followed by a numerical evaluation of $\\mathrm{GCI}_{21}$.\n\nThe analysis begins with the provided discretization error expansion for a numerically computed scalar quantity $\\phi$ as a function of mesh spacing $h$:\n$$ \\phi(h) = \\phi_{\\ast} + C h^{p} + \\mathcal{O}(h^{p+1}) $$\nwhere $\\phi_{\\ast}$ is the exact solution (mesh-converged value), $C$ is a constant, and $p$ is the order of accuracy. Since the meshes are assumed to be in the asymptotic range, we can truncate the higher-order terms and write the solutions on the three systematically refined meshes (indexed $1$ for fine, $2$ for medium, and $3$ for coarse) as:\n$$ \\phi_1 \\approx \\phi_{\\ast} + C h_1^p $$\n$$ \\phi_2 \\approx \\phi_{\\ast} + C h_2^p $$\n$$ \\phi_3 \\approx \\phi_{\\ast} + C h_3^p $$\nHere, $h_1$, $h_2$, and $h_3$ are the characteristic mesh spacings for the fine, medium, and coarse meshes, respectively. The problem specifies a uniform refinement ratio $r = r_{21} = r_{32} = 2$. By definition, $r_{21} = h_2 / h_1$ and $r_{32} = h_3 / h_2$. Therefore, we have $h_2 = r h_1$ and $h_3 = r h_2 = r^2 h_1$. Substituting these relationships into the approximate equations gives:\n$$ \\phi_1 \\approx \\phi_{\\ast} + C h_1^p \\quad (1)$$\n$$ \\phi_2 \\approx \\phi_{\\ast} + C (r h_1)^p = \\phi_{\\ast} + C h_1^p r^p \\quad (2)$$\n$$ \\phi_3 \\approx \\phi_{\\ast} + C (r^2 h_1)^p = \\phi_{\\ast} + C h_1^p r^{2p} \\quad (3)$$\n\nFirst, we derive the expression for the observed order of accuracy, $p$. To eliminate the unknowns $\\phi_{\\ast}$ and $C h_1^p$, we consider the differences between solutions on consecutive meshes.\nSubtracting equation (1) from (2):\n$$ \\phi_2 - \\phi_1 \\approx (\\phi_{\\ast} + C h_1^p r^p) - (\\phi_{\\ast} + C h_1^p) = C h_1^p (r^p - 1) $$\nSubtracting equation (2) from (3):\n$$ \\phi_3 - \\phi_2 \\approx (\\phi_{\\ast} + C h_1^p r^{2p}) - (\\phi_{\\ast} + C h_1^p r^p) = C h_1^p (r^{2p} - r^p) = C h_1^p r^p (r^p - 1) $$\nThe ratio of these two differences eliminates the term $C h_1^p (r^p - 1)$:\n$$ \\frac{\\phi_3 - \\phi_2}{\\phi_2 - \\phi_1} \\approx \\frac{C h_1^p r^p (r^p - 1)}{C h_1^p (r^p - 1)} = r^p $$\nSolving for $p$ by taking the natural logarithm of both sides yields the expression for the observed order of accuracy:\n$$ p = \\frac{\\ln\\left(\\frac{\\phi_3 - \\phi_2}{\\phi_2 - \\phi_1}\\right)}{\\ln(r)} $$\n\nNext, we derive the expression for $\\mathrm{GCI}_{21}$. The Grid Convergence Index is based on Richardson Extrapolation, which provides a more accurate estimate of $\\phi_{\\ast}$ by canceling the leading-order error term. Using equations (1) and (2), we can eliminate the term $C h_1^p$:\nFrom (1), $C h_1^p \\approx \\phi_1 - \\phi_{\\ast}$.\nSubstituting this into (2):\n$$ \\phi_2 \\approx \\phi_{\\ast} + (\\phi_1 - \\phi_{\\ast}) r^p $$\nRearranging to solve for the extrapolated value $\\phi_{\\text{ext}}^{21}$, which is our best estimate for $\\phi_{\\ast}$:\n$$ \\phi_2 \\approx \\phi_{\\ast} + r^p \\phi_1 - r^p \\phi_{\\ast} $$\n$$ \\phi_2 - r^p \\phi_1 \\approx \\phi_{\\ast} (1 - r^p) $$\n$$ \\phi_{\\ast} \\approx \\phi_{\\text{ext}}^{21} = \\frac{r^p \\phi_1 - \\phi_2}{r^p - 1} $$\nThis expression can be rewritten to highlight the correction to the fine grid solution:\n$$ \\phi_{\\text{ext}}^{21} = \\frac{r^p \\phi_1 - \\phi_1 + \\phi_1 - \\phi_2}{r^p - 1} = \\frac{\\phi_1(r^p - 1)}{r^p - 1} + \\frac{\\phi_1 - \\phi_2}{r^p - 1} = \\phi_1 + \\frac{\\phi_1 - \\phi_2}{r^p - 1} $$\nThe approximate absolute error on the fine mesh, $E_a^{21}$, is estimated by the magnitude of this correction term:\n$$ E_a^{21} = |\\phi_1 - \\phi_{\\text{ext}}^{21}| = \\left| \\frac{\\phi_2 - \\phi_1}{r^p - 1} \\right| $$\nThe approximate relative error on the fine mesh, $e_a^{21}$, is this absolute error normalized by the fine mesh solution:\n$$ e_a^{21} = \\left| \\frac{E_a^{21}}{\\phi_1} \\right| = \\left| \\frac{\\frac{\\phi_2 - \\phi_1}{r^p - 1}}{\\phi_1} \\right| $$\nThe Grid Convergence Index $\\mathrm{GCI}_{21}$ is defined as this relative error estimate multiplied by a safety factor $F_s$ to provide a conservative error bound:\n$$ \\mathrm{GCI}_{21} = F_s e_a^{21} = F_s \\left| \\frac{\\frac{\\phi_2 - \\phi_1}{r^p - 1}}{\\phi_1} \\right| = \\frac{F_s}{|\\phi_1|} \\frac{|\\phi_2 - \\phi_1|}{r^p - 1} $$\nThis is the required expression for $\\mathrm{GCI}_{21}$.\n\nNow, we perform the numerical evaluation using the provided data:\n$\\phi_1 = 5.10$, $\\phi_2 = 5.30$, $\\phi_3 = 5.90$, $r=2$, and $F_s = 1.25$.\n\nFirst, we calculate the observed order of accuracy, $p$:\nThe ratio of solution differences is:\n$$ \\frac{\\phi_3 - \\phi_2}{\\phi_2 - \\phi_1} = \\frac{5.90 - 5.30}{5.30 - 5.10} = \\frac{0.60}{0.20} = 3 $$\nFrom our derivation, this ratio is equal to $r^p$. So, $r^p = 2^p = 3$. We can calculate $p$ explicitly, though it is not strictly necessary for the next step.\n$$ p = \\frac{\\ln(3)}{\\ln(2)} \\approx 1.58496 $$\nThe essential quantity needed for the GCI calculation is $r^p$, which we have found to be exactly $3$.\n\nNext, we calculate $\\mathrm{GCI}_{21}$:\n$$ \\mathrm{GCI}_{21} = \\frac{F_s}{|\\phi_1|} \\frac{|\\phi_2 - \\phi_1|}{r^p - 1} $$\nSubstituting the numerical values:\n$$ \\mathrm{GCI}_{21} = \\frac{1.25}{|5.10|} \\frac{|5.30 - 5.10|}{3 - 1} $$\n$$ \\mathrm{GCI}_{21} = \\frac{1.25}{5.10} \\frac{0.20}{2} $$\n$$ \\mathrm{GCI}_{21} = \\frac{1.25}{5.10} \\times 0.10 $$\n$$ \\mathrm{GCI}_{21} = \\frac{0.125}{5.10} \\approx 0.0245098039... $$\nThe problem requires the result to be reported as a dimensionless decimal rounded to three significant figures.\n$$ \\mathrm{GCI}_{21} \\approx 0.0245 $$\nThis value represents an estimated $2.45\\%$ uncertainty in the fine-grid solution $\\phi_1$ due to discretization error, including a safety factor of $1.25$.",
            "answer": "$$\n\\boxed{0.0245}\n$$"
        },
        {
            "introduction": "A key goal of VVUQ is to create models that can be credibly integrated with experimental data, accounting for uncertainties in both the model and the measurements. The Kalman filter provides a foundational framework for this process, known as data assimilation or state estimation, by optimally blending model predictions with noisy diagnostic data . In this exercise, you will derive the filter's core equations from Bayesian principles and apply them to a simplified model of a tokamak's core ion temperature, demonstrating how to update a state estimate and quantify its uncertainty.",
            "id": "4061815",
            "problem": "In computational fusion science and engineering, Verification, Validation, and Uncertainty Quantification (VVUQ) methodologies require principled state estimation grounded in statistical inference. Consider a linearized, discrete-time, core plasma state-estimation problem in which the scalar state $x_k$ represents the volume-averaged core ion temperature in kilo–electron-volts (keV) at time index $k$, driven by heating and confined with an energy confinement time. The linearized dynamics and diagnostics are modeled as a Gaussian state-space system:\n$$\nx_{k+1} = a\\,x_k + b\\,u_k + w_k, \\quad y_k = c\\,x_k + v_k,\n$$\nwhere $u_k$ is a known heating input surrogate, $w_k$ and $v_k$ are mutually independent, zero-mean, Gaussian process and measurement noise with covariances $\\mathbb{E}[w_k^2]=q$ and $\\mathbb{E}[v_k^2]=r$, respectively, and $x_0$ has a Gaussian prior with mean $x_{0|0}$ and covariance $P_{0|0}$. Assume all random variables across time are jointly Gaussian and that $w_k$ and $v_k$ are white and independent of $x_0$.\n\nTask 1 (derivation): Starting from the foundational definitions of linear Gaussian state-space models and the Minimum Mean Square Error (MMSE) estimator derived via Bayes’ rule, derive the standard discrete-time Kalman Filter (KF) prediction and update equations for the state estimate $x_{k|k}$, its prediction $x_{k+1|k}$, and their associated error covariances $P_{k|k}$ and $P_{k+1|k}$. Your derivation must start from the definitions above, construct the innovation, and determine the Kalman gain by minimizing the posterior estimation error covariance in the class of linear estimators.\n\nTask 2 (application to a toy core plasma system): Consider a toy core plasma system with sampling interval $\\Delta t = 0.01\\,\\mathrm{s}$ and energy confinement time $\\tau_E = 0.5\\,\\mathrm{s}$. A standard linearization of the core energy balance about a nominal heating trajectory yields\n$$\na = 1 - \\frac{\\Delta t}{\\tau_E},\n$$\nwith a constant diagnostic sensitivity $c = 1$ (temperature is directly measured), and scalar noise covariances $q$ and $r$ specified below. Assume the initial posterior covariance is $P_{0|0}$.\n\nUse your derived Kalman Filter equations to compute the one-step posterior covariance $P_{1|1}$ given:\n- $\\Delta t = 0.01\\,\\mathrm{s}$,\n- $\\tau_E = 0.5\\,\\mathrm{s}$,\n- $c = 1$,\n- $q = 0.08\\,\\mathrm{keV}^2$,\n- $r = 0.25\\,\\mathrm{keV}^2$,\n- $P_{0|0} = 1.0\\,\\mathrm{keV}^2$.\n\nReport the value of $P_{1|1}$ in $\\mathrm{keV}^2$, and round your answer to four significant figures.",
            "solution": "The solution is divided into two parts as requested: the derivation of the Kalman Filter equations and their application to a specific numerical problem.\n\n**Task 1: Derivation of the Discrete-Time Kalman Filter**\n\nWe are given a linear Gaussian state-space model:\n$$\nx_{k+1} = a\\,x_k + b\\,u_k + w_k, \\quad \\text{(State Equation)}\n$$\n$$\ny_k = c\\,x_k + v_k, \\quad \\text{(Measurement Equation)}\n$$\nwhere $x_k$ is the scalar state, $u_k$ is a known input, and $y_k$ is the measurement at time index $k$. The process noise $w_k$ and measurement noise $v_k$ are independent, zero-mean, white Gaussian processes with variances $\\mathbb{E}[w_k^2] = q$ and $\\mathbb{E}[v_k^2] = r$, respectively. The initial state $x_0$ is Gaussian with mean $x_{0|0}$ and variance $P_{0|0}$. We use the notation $x_{i|j} = \\mathbb{E}[x_i | y_1, ..., y_j]$ for the estimate of the state at time $i$ given measurements up to time $j$, and $P_{i|j} = \\mathbb{E}[(x_i - x_{i|j})^2]$ for the corresponding error covariance.\n\nThe Kalman filter recursively computes the posterior distribution of the state, which, in this Gaussian context, is fully described by its mean and covariance. The process consists of two steps: prediction and update.\n\n**1. Prediction Step (Time Update)**\n\nThe goal is to propagate the state estimate and its covariance from time $k$ to time $k+1$ using the system model, before incorporating the measurement at time $k+1$. We start with the posterior estimate $x_{k|k}$ and its covariance $P_{k|k}$.\n\nThe predicted state mean at time $k+1$, given measurements up to time $k$, is:\n$$\nx_{k+1|k} = \\mathbb{E}[x_{k+1} | y_1, \\dots, y_k]\n$$\nSubstituting the state equation:\n$$\nx_{k+1|k} = \\mathbb{E}[a\\,x_k + b\\,u_k + w_k | y_1, \\dots, y_k]\n$$\nBy linearity of expectation, and since $u_k$ is a known input:\n$$\nx_{k+1|k} = a\\,\\mathbb{E}[x_k | y_1, \\dots, y_k] + b\\,u_k + \\mathbb{E}[w_k | y_1, \\dots, y_k]\n$$\nBy definition, $\\mathbb{E}[x_k | y_1, \\dots, y_k] = x_{k|k}$. The process noise $w_k$ is independent of all past states and measurements, so $\\mathbb{E}[w_k | y_1, \\dots, y_k] = \\mathbb{E}[w_k] = 0$. This yields the prediction equation for the state:\n$$\nx_{k+1|k} = a\\,x_{k|k} + b\\,u_k\n$$\nThe predicted error covariance is $P_{k+1|k} = \\mathbb{E}[(x_{k+1} - x_{k+1|k})^2]$. The prediction error is:\n$$\nx_{k+1} - x_{k+1|k} = (a\\,x_k + b\\,u_k + w_k) - (a\\,x_{k|k} + b\\,u_k) = a(x_k - x_{k|k}) + w_k\n$$\nThe covariance is the expected value of the square of this error:\n$$\nP_{k+1|k} = \\mathbb{E}[(a(x_k - x_{k|k}) + w_k)^2] = \\mathbb{E}[a^2(x_k - x_{k|k})^2 + 2a(x_k - x_{k|k})w_k + w_k^2]\n$$\n$$\nP_{k+1|k} = a^2\\mathbb{E}[(x_k - x_{k|k})^2] + 2a\\mathbb{E}[(x_k - x_{k|k})w_k] + \\mathbb{E}[w_k^2]\n$$\nThe estimation error at time $k$, $(x_k - x_{k|k})$, is a function of noise terms up to time $k-1$ (i.e., $w_0, \\dots, w_{k-1}$ and $v_1, \\dots, v_k$). Since $w_k$ is white noise, it is uncorrelated with all past noise terms and thus with the error $(x_k - x_{k|k})$. Therefore, the cross-term $\\mathbb{E}[(x_k - x_{k|k})w_k] = 0$. This gives the prediction equation for the covariance:\n$$\nP_{k+1|k} = a^2 P_{k|k} + q\n$$\n\n**2. Update Step (Measurement Update)**\n\nThe goal is to update the predicted (prior) estimate $x_{k+1|k}$ and its covariance $P_{k+1|k}$ using the new measurement $y_{k+1}$ to obtain the posterior estimate $x_{k+1|k+1}$ and its covariance $P_{k+1|k+1}$.\n\nFor a linear Gaussian system, the optimal (MMSE) estimator is a linear combination of the prior estimate and the new measurement information. We seek an updated estimate of the form:\n$$\nx_{k+1|k+1} = x_{k+1|k} + K_{k+1} \\tilde{y}_{k+1}\n$$\nwhere $K_{k+1}$ is the Kalman gain and $\\tilde{y}_{k+1}$ is the innovation, which is the new information contained in the measurement $y_{k+1}$. The innovation is the difference between the actual measurement and its predicted value:\n$$\n\\tilde{y}_{k+1} = y_{k+1} - \\mathbb{E}[y_{k+1} | y_1, \\dots, y_k]\n$$\nThe predicted measurement is $\\mathbb{E}[y_{k+1} | y_1, \\dots, y_k] = \\mathbb{E}[c\\,x_{k+1} + v_{k+1} | y_1, \\dots, y_k] = c\\,\\mathbb{E}[x_{k+1} | y_1, \\dots, y_k] + \\mathbb{E}[v_{k+1} | y_1, \\dots, y_k]$. Since $v_{k+1}$ is independent of past measurements, this simplifies to $c\\,x_{k+1|k}$. Thus, the innovation is:\n$$\n\\tilde{y}_{k+1} = y_{k+1} - c\\,x_{k+1|k}\n$$\nThe Kalman gain $K_{k+1}$ is chosen to minimize the posterior error covariance $P_{k+1|k+1} = \\mathbb{E}[(x_{k+1} - x_{k+1|k+1})^2]$. The posterior estimation error is:\n$$\nx_{k+1} - x_{k+1|k+1} = x_{k+1} - [x_{k+1|k} + K_{k+1}(y_{k+1} - c\\,x_{k+1|k})]\n$$\n$$\nx_{k+1} - x_{k+1|k+1} = (x_{k+1} - x_{k+1|k}) - K_{k+1}(c\\,x_{k+1} + v_{k+1} - c\\,x_{k+1|k})\n$$\n$$\nx_{k+1} - x_{k+1|k+1} = (x_{k+1} - x_{k+1|k}) - K_{k+1}[c(x_{k+1} - x_{k+1|k}) + v_{k+1}]\n$$\n$$\nx_{k+1} - x_{k+1|k+1} = (1 - K_{k+1}c)(x_{k+1} - x_{k+1|k}) - K_{k+1}v_{k+1}\n$$\nThe posterior covariance $P_{k+1|k+1}$ is the variance of this error. The prediction error $(x_{k+1} - x_{k+1|k})$ is uncorrelated with the measurement noise $v_{k+1}$, so the cross-term in the variance calculation is zero:\n$$\nP_{k+1|k+1} = (1 - K_{k+1}c)^2 \\mathbb{E}[(x_{k+1} - x_{k+1|k})^2] + K_{k+1}^2 \\mathbb{E}[v_{k+1}^2]\n$$\n$$\nP_{k+1|k+1} = (1 - K_{k+1}c)^2 P_{k+1|k} + K_{k+1}^2 r\n$$\nTo find the optimal gain $K_{k+1}$ that minimizes $P_{k+1|k+1}$, we differentiate with respect to $K_{k+1}$ and set the result to zero:\n$$\n\\frac{d P_{k+1|k+1}}{d K_{k+1}} = 2(1 - K_{k+1}c)(-c) P_{k+1|k} + 2 K_{k+1} r = 0\n$$\n$$\n-c P_{k+1|k} + K_{k+1} c^2 P_{k+1|k} + K_{k+1} r = 0\n$$\n$$\nK_{k+1} (c^2 P_{k+1|k} + r) = c P_{k+1|k}\n$$\nThis gives the Kalman gain:\n$$\nK_{k+1} = \\frac{c P_{k+1|k}}{c^2 P_{k+1|k} + r}\n$$\nFinally, we substitute this optimal gain back into the equation for $P_{k+1|k+1}$. A more direct path is:\n$$\nP_{k+1|k+1} = P_{k+1|k} - 2 K_{k+1}c P_{k+1|k} + K_{k+1}^2 c^2 P_{k+1|k} + K_{k+1}^2 r\n$$\n$$\nP_{k+1|k+1} = P_{k+1|k} - 2 K_{k+1}c P_{k+1|k} + K_{k+1}(K_{k+1}(c^2 P_{k+1|k} + r))\n$$\nUsing $K_{k+1}(c^2 P_{k+1|k} + r) = c P_{k+1|k}$:\n$$\nP_{k+1|k+1} = P_{k+1|k} - 2 K_{k+1}c P_{k+1|k} + K_{k+1}(c P_{k+1|k})\n$$\n$$\nP_{k+1|k+1} = P_{k+1|k} - K_{k+1}c P_{k+1|k}\n$$\nThis results in the update equation for the covariance:\n$$\nP_{k+1|k+1} = (1 - K_{k+1}c) P_{k+1|k}\n$$\n\n**Task 2: Application to the Toy Core Plasma System**\n\nWe need to compute the one-step posterior covariance $P_{1|1}$. This requires a prediction step from $k=0$ to $k=1$, followed by an update step at $k=1$.\n\nThe given parameters are:\n- $\\Delta t = 0.01\\,\\mathrm{s}$\n- $\\tau_E = 0.5\\,\\mathrm{s}$\n- $c = 1$\n- $q = 0.08\\,\\mathrm{keV}^2$\n- $r = 0.25\\,\\mathrm{keV}^2$\n- $P_{0|0} = 1.0\\,\\mathrm{keV}^2$\n\nFirst, we calculate the system dynamics parameter $a$:\n$$\na = 1 - \\frac{\\Delta t}{\\tau_E} = 1 - \\frac{0.01}{0.5} = 1 - 0.02 = 0.98\n$$\n\n**1. Prediction Step ($k=0 \\to k=1$)**\n\nWe compute the predicted covariance $P_{1|0}$ using the posterior covariance at time $k=0$, which is $P_{0|0}$.\n$$\nP_{1|0} = a^2 P_{0|0} + q\n$$\nSubstituting the numerical values:\n$$\nP_{1|0} = (0.98)^2 (1.0) + 0.08\n$$\n$$\nP_{1|0} = 0.9604 \\times 1.0 + 0.08 = 0.9604 + 0.08 = 1.0404\\,\\mathrm{keV}^2\n$$\n\n**2. Update Step ($k=1$)**\n\nNext, we compute the Kalman gain $K_1$ for the update at time $k=1$:\n$$\nK_1 = \\frac{c P_{1|0}}{c^2 P_{1|0} + r}\n$$\nSubstituting the numerical values:\n$$\nK_1 = \\frac{1 \\times 1.0404}{1^2 \\times 1.0404 + 0.25} = \\frac{1.0404}{1.0404 + 0.25} = \\frac{1.0404}{1.2904}\n$$\nNow, we compute the updated posterior covariance $P_{1|1}$:\n$$\nP_{1|1} = (1 - K_1 c) P_{1|0}\n$$\nSubstituting the expressions for $K_1$, $c$, and $P_{1|0}$:\n$$\nP_{1|1} = \\left(1 - \\frac{1.0404}{1.2904} \\times 1\\right) \\times 1.0404\n$$\n$$\nP_{1|1} = \\left(\\frac{1.2904 - 1.0404}{1.2904}\\right) \\times 1.0404\n$$\n$$\nP_{1|1} = \\left(\\frac{0.25}{1.2904}\\right) \\times 1.0404\n$$\n$$\nP_{1|1} = \\frac{0.2601}{1.2904} \\approx 0.201565406...\n$$\nThe problem requires the answer to be rounded to four significant figures.\n$$\nP_{1|1} \\approx 0.2016\\,\\mathrm{keV}^2\n$$",
            "answer": "$$\\boxed{0.2016}$$"
        }
    ]
}