## 引言
在计算科学与工程，特别是像核聚变这样前沿且复杂的领域，[数值模拟](@entry_id:146043)已经成为连接理论探索与物理实验的关键桥梁。然而，模拟本身产生的数据并不天然具备可信度，其预测能力必须经过系统性的严格评估。若缺乏一套严谨的评估框架，基于模拟结果的科学发现、工程设计乃至重大决策都将面临巨大的风险。本文旨在解决这一知识鸿沟，全面介绍“验证、确认与不确定性量化”（Verification, Validation, and Uncertainty Quantification, VVUQ）这一核心方法论。

本文将引导读者深入理解如何为[计算模型](@entry_id:637456)建立起坚实的科学可信度。在“原理与机制”一章中，我们将详细剖析VVUQ的三个基本组成部分，阐明它们各自的独特角色以及如何协同工作。接着，在“应用与跨学科联系”一章中，我们将通过[聚变科学](@entry_id:182346)及其他高风险工程领域的实际案例，展示VVUQ方法论的广泛适用性与强大整合能力。最后，在“动手实践”部分，我们提供了具体问题的练习，帮助读者将理论知识转化为实践技能。通过这三个层次的深入学习，读者将掌握一套完整的、用于评估和提升[计算模型](@entry_id:637456)预测能力的科学框架。

## 原理与机制

在计算科学与工程领域，特别是对于[聚变能](@entry_id:138601)研究这样复杂且高风险的学科，[数值模拟](@entry_id:146043)已成为理论研究与实验探索之间不可或缺的桥梁。然而，仅凭[计算模型](@entry_id:637456)产生的结果本身并不具备固有的可信度。为了确保这些模型能够可靠地用于科学发现、工程设计和决策支持，我们必须采用一套系统而严谨的流程来评估和量化其可信度。这一流程的核心便是“验证、确认与[不确定性量化](@entry_id:138597)”（Verification, Validation, and Uncertainty Quantification, VVUQ）。本章将深入探讨构成VVUQ框架的基本原理与关键机制，阐明它们如何协同作用，为[计算模型](@entry_id:637456)的预测能力建立坚实的科学基础。

### [计算模型](@entry_id:637456)可信度的三位一体：验证、确认与不确定性量化

验证（Verification）、确认（Validation）与不确定性量化（UQ）是建立模型可信度的三个紧密相连且缺一不可的支柱。混淆或忽略其中任何一个环节，都将导致对模型预测能力的评估出现严重偏差。为了清晰地理解它們各自独特又互补的角色，我们可以借助一个典型的[聚变等离子体](@entry_id:1125407)计算问题——[托卡马克输运](@entry_id:756044)模拟——来进行说明 。

假设我们有一个输运求解器，它用于求解描述[电子温度](@entry_id:180280) $T_e(r,t)$ 演化的[偏微分](@entry_id:194612)方程。此模型的精确解（或称连续介质解）记为 $u$，而我们的计算机代码在特定网格上得到的数值解记为 $u_h$。同时，我们可以通过诊断设备获得关于真实托卡马克等离子体的实验测量数据 $y^{\mathrm{exp}}$。模型的预测能力最终体现在对某个关键物理量（Quantity of Interest, QoI）的预测上，例如堆芯热通量 $Q$。在此背景下，VVUQ的定义与[分工](@entry_id:190326)如下：

**验证 (Verification)** 回答的是一个纯粹的数学与程序实现问题：“我们是否正确地求解了所选的方程？” 验证的目标是评估和量化数值解 $u_h$ 与模型精确解 $u$ 之间的差异，即**数值误差**或**离散误差** $e_h = ||u_h - u||$。验证活动与物理现实无关，它只关心代码是否忠实地、精确地实现了其所声称的数学模型。例如，通过[网格加密研究](@entry_id:750067)，验证过程旨在证明当网格尺寸 $h$趋于零时，[数值误差](@entry_id:635587) $e_h$ 会以理论预期的速率收敛。一个经过充分验证的代码，是我们信任其计算结果的数学前提。

**确认 (Validation)** 回答的是一个物理问题：“我们是否求解了正确的方程？” 确认旨在评估数学模型本身在多大程度上能够准确表征我们感兴趣的物理系统。这个过程需要将模型的输出（通过一个**前向算子** $H$ 映射到可观测量 $y=H(u)$）与独立的**实验数据** $y^{\mathrm{exp}}$ 进行定量比较。一个严谨的确认过程必须同时考虑实验测量的不确定性、用于比较的数值解自身的数值误差，以及最重要的——模型自身可能存在的缺陷，即**[模型形式误差](@entry_id:274198)**（model-form error）。只有当模型在特定应用领域内通过了与真实物理世界的对比检验，我们才能相信它的物理**相关性**。

**[不确定性量化](@entry_id:138597) (Uncertainty Quantification, UQ)** 则致力于回答这样一个问题：“我们对模型的预测有多大信心？” UQ是一个贯穿始终的框架，它涉及识别、表征并传播模型中所有显著的不确定性来源。这些不确定性可能源于模型参数（例如输运系数中的未知参数 $\theta$）、[初始和边界条件](@entry_id:750648)、模型形式的简化（结构不确定性），以及实验数据的噪声。UQ的目标是将这些输入端的不确定性，通过已经过验证和确认的模型，传播到我们关心的输出量 $Q$ 上，最终得到一个概率性的预测结果（例如，$Q$ 的概率密度函数），而不仅仅是一个单一的数值。这个概率分布使我们能够给出预测的**置信区间**或**[可信区间](@entry_id:176433)**。

综上所述，验证确保了计算的正确性，确认确保了物理的准确性，而UQ则提供了对预测结果信心的量化度量。这三者共同作用，才能构建起[计算模型](@entry_id:637456)完整的**预测可信度**（predictive credibility），使其能够可靠地用于预测新场景下的物理行为 。

### 验证：确保数学正确性

验证是 VVUQ 流程的基石。一个未经验证、充满了程序错误或数值表现未知的代码，其输出结果是毫无意义的。验证过程本身可以进一步细分为两个层面：代码验证和解验证 。

#### 代码验证：发现并移除程序中的错误

**[代码验证](@entry_id:146541) (Code Verification)** 的核心目标是证明代码的实现是无误的，并且其数值算法的表现（如[收敛阶](@entry_id:146394)）符合理论预期。这项任务的主要挑战在于，对于复杂的[非线性偏微分方程](@entry_id:169481)（如磁流[体力](@entry_id:174230)学（MHD）方程组或[回旋动理学方程](@entry_id:1125856)），我们通常不知道其解析解。

为了解决这个问题，一个强大而标准的技术是**造解法 (Method of Manufactured Solutions, MMS)**。MMS 的思想是：我们首先“制造”一个我们喜欢的、足够光滑的[解析函数](@entry_id:139584)，并将其作为假定的精确解 $u_{\text{ex}}$。然后，我们将这个 $u_{\text{ex}}$代入到原始的[偏微分](@entry_id:194612)方程算子中，由此会产生一个额外的源项。接着，我们将这个源项添加到代码中，并求解这个修改后的方程。由于我们已经知道了这个修改后问题的精确解，我们就可以通过在一系列加密的网格上运行代码，直接计算[数值误差](@entry_id:635587)，并检验误差是否随着网格尺寸 $h$ 的减小，严格按照理论预期的[收敛阶](@entry_id:146394) $p$（即 $E(h) \propto h^p$）下降。成功地通过[MMS测试](@entry_id:1127983)，为代码实现的正确性提供了强有力的证据 。

#### 高级验证：物理不变量的保持

对于某些特定类型的物理问题，尤其是那些涉及长时间演化的[哈密顿系统](@entry_id:143533)（如带电粒子在磁场中的[轨道运动](@entry_id:162856)），仅仅满足某个[收敛阶](@entry_id:146394)可能还不够。一个更高层次的验证要求是，数值格式应能保持系统内在的**几何结构**和**物理不变量**。这类算法被称为**[几何积分算法](@entry_id:138085)**或[保结构算法](@entry_id:755563)。

以一个简化的回旋中心垂直动力学模型为例，其[哈密顿量](@entry_id:144286)为 $H(q,p) = \frac{1}{2}\omega(q^2 + p^2)$。这是一个简单的[谐振子](@entry_id:155622)系统。物理上，该系统的能量和相空间体积（辛二形式）在演化中是守恒的。一个理想的[数值积分方法](@entry_id:141406)应该能在离散层面上模拟这些守恒律。例如，**[隐式中点法](@entry_id:137686)**是一种典型的**辛积分方法**。当应用于此类二次哈密頓量系统时，它可以被数学证明能够精确地保持能量守恒，并且其离散演化映射的行列式严格为1（代表着相空间面积守恒）。在一个数值实验中，我们可以观测到能量误差 $\varepsilon_E$ 和行列式偏差 $\varepsilon_{\det}$ 在不考虑[浮点舍入](@entry_id:749455)误差的情况下应为零，无论时间步长 $\Delta t$ 取多大。此外，这类方法还能很好地保持系统的泊松括号结构。这种对物理不变量的精确保持，是代码正确性的一个更深刻的体现，对于确保长期模拟的保真度至关重要 。

#### 解验证：估计特定模拟中的误差

**解验证 (Solution Verification)** 的关注点则不同。它不再关心代码的普适正确性，而是要回答一个非常实际的问题：“在我这次具体的、用于科学研究的模拟中，我关心的结果 $Q$ 包含多大的[数值误差](@entry_id:635587)？”

解验证的主要工具是基于**[理查森外推法](@entry_id:137237) (Richardson Extrapolation)** 的思想。标准做法是在至少三个系统性加密的网格上（例如，网格尺寸为 $h$, $h/2$, $h/4$）进行模拟，得到 QoI 的一系列计算值。通过分析这些值随网格尺寸的变化，我们可以估计出数值解的[收敛阶](@entry_id:146394)，并外推得到一个更精确的近似值。**[网格收敛指数](@entry_id:750061) (Grid Convergence Index, GCI)** 是一个广泛使用的、基于此思想的度量，它为特定网格解的离散误差提供了一个定量的置信区间 。

然而，当模拟对象是像[等离子体湍流](@entry_id:186467)这样的[随机过程](@entry_id:268487)时，解验证会面临新的挑战。在这种情况下，任何有限时间的模拟输出 $\hat{J}_h$ 都包含两种误差：由[网格离散化](@entry_id:1125789)引起的**离散误差**，以及由有限[时间平均](@entry_id:267915)代替无限时间系综平均引起的**统计采样误差**。天真地检查 $\hat{J}_h$ 的收敛性可能会被统计噪声误导。一个严谨的[网格收敛](@entry_id:897543)判据必须能够区分这两种误差。现代方法论通过在每个网格上估计统计[标准误](@entry_id:635378) $\mathrm{SE}_h$ 来量化采样不确定性。[收敛判据](@entry_id:158093)则不再是简单地要求相邻网格结果的差异足够小，而是要求这个差异在统计上与零或某个用户设定的容差**无法**区分。例如，一个判据可以是，当观测到的差异 $|\hat{J}_{h_{k+1}} - \hat{J}_{h_k}|$ 小于由[统计不确定性](@entry_id:267672)（$\sqrt{\mathrm{SE}_{h_{k+1}}^2 + \mathrm{SE}_{h_k}^2}$）和离散化容差共同构成的阈值时，我们才认为达到了[网格无关性](@entry_id:634417)。这在贝叶斯和频率论框架下都有相应的严格表述 。

### 确认：模型与现实的对质

验证确保了我们“正确地求解了方程”，而确认则回答了更深刻的问题：“我们是否求解了正确的方程？” **确认 (Validation)** 是通过将模型预测与真实世界的物理实验数据进行定量比较，来评估模型作为现实世界代表的充分性 。一个关键原则是，用于确认的实验数据必须是**独立的**，即这些数据没有被用于模型的构建或参数的校准。

#### 确认的层次化策略

对于像[聚变模拟](@entry_id:1125419)这样极其复杂的综合性模型，试图“一站式”地确认整个模型是不现实的。一个更有效、更科学的策略是采用**层次化确认 (hierarchical validation)** 。这种自底向上的方法将复杂的确认问题分解为一系列更简单、更易于诊断的子问题：

1.  **单元物理 (Unit Physics) 层面**：在最底层，我们验证模型中最基本的物理过程。例如，我们可以将[回旋动理学代码](@entry_id:1125855)预测的线性微观[不稳定性增长率](@entry_id:265537) $\gamma(k)$ 和实频 $\omega(k)$，与来自局部涨落诊断（如束发射光谱）的实验测量结果进行比较。

2.  **组件 (Component) 层面**：在中间层，我们将多个单元物理过程耦合起来，在简化的场景中进行确认。例如，验证由微观不稳定性驱动的[非线性](@entry_id:637147)[湍流](@entry_id:151300)输运模型，在[稳态](@entry_id:139253)低约束模式等离子体中预测的热通量 $Q$ 和[粒子通量](@entry_id:753207) $\Gamma$ 是否与功率平衡分析结果一致。

3.  **集成系统 (Integrated System) 层面**：在最高层，我们确认整个模型在完全集成的、复杂的放电场景中预测[涌现现象](@entry_id:145138)的能力。例如，预测低约束模到高约束模（L-H）转换的功率阈值、台基区顶部压强 $p_{\mathrm{ped}}$ 或[边缘局域模](@entry_id:748795)（ELM）的频率 $f_{\mathrm{ELM}}$。

这种分层方法论不仅逐步建立了对模型的信心，而且当模型与数据出现偏差时，它还能帮助我们更有效地定位和诊断问题的来源。

#### 严谨的统计确认框架

定性的“看起来很像”在科学确认中是远远不够的。确认必须是定量的、客观的，并基于严谨的统计学框架。

首先，为了进行“苹果对苹果”的比较，我们需要一个**前向算子 (forward operator)** $H$。这个算子负责将模型内部的[状态变量](@entry_id:138790)（如完整的分布函数，通常无法直接测量）映射为实验中实际可观测的量（如某个谱线的亮度、探测器上的信号等）。

其次，确认过程应该被构建为一个正式的**[统计假设检验](@entry_id:274987)**。[零假设](@entry_id:265441) $H_0$ 通常设定为“模型是充分的”，即模型预测与实验测量之间的差异可以完全由两者各自的不确定性之和来解释。[备择假设](@entry_id:167270) $H_1$ 则是“模型是不充分的” 。

对于涉及多变量、多点比较的确认问题（例如，比较整个剖面上的热流密度），一个强大的统计量是**[马氏距离](@entry_id:269828) (Mahalanobis distance)**。假设模型预测向量为 $y_m$，实验测量向量为 $y_e$，它们各自的预测不确定性和测量不确定性由协方差矩阵 $S_m$ 和 $S_e$ 描述。定义[残差向量](@entry_id:165091) $d = y_e - y_m$，其总协方差为 $S = S_e + S_m$（假设不确定性来源独立）。[马氏距离](@entry_id:269828)平方构造的[检验统计量](@entry_id:897871)为：
$$
T = d^{\top} S^{-1} d
$$
这个统计量的好处在于它自然地考虑了所有数据点的不确定性大小及其之间的相关性。在零假设 $H_0$ 成立的条件下， $T$ 服从自由度为 $p$ 的**[卡方分布](@entry_id:263145)**（$\chi^2_p$），其中 $p$ 是数据点的数量。我们可以据此计算出一个 $p$-value，或者将计算出的 $T$ 值与在给定显著性水平 $\alpha$ 下的临界值 $\chi^2_{p, 1-\alpha}$进行比较。如果 $T$ 超过临界值，我们就有统计证据拒绝[零假设](@entry_id:265441)，即“证伪”该模型 。

### 不确定性量化：信心的科学

UQ是整个VVUQ拼图的粘合剂，它提供了一种量化我们对模型预测信心的语言。一个没有附带不确定性声明的预测，其科学价值是有限的。

#### 两类不确定性：[偶然不确定性与认知不确定性](@entry_id:1120923)

在UQ中，对不确定性的来源进行分类至关重要，其中最基本的分类是[偶然不确定性](@entry_id:634772)和认知不确定性 。

**[偶然不确定性](@entry_id:634772) (Aleatory Uncertainty)** 指的是系统或环境中固有的、不可避免的随机性或变异性。它源于“chance”，即使我们拥有完美的知识也无法消除它。在[聚变等离子体](@entry_id:1125407)中，由[湍流](@entry_id:151300)驱动的源项涨落 $\xi(x,t)$ 就是典型的[偶然不确定性](@entry_id:634772)。我们无法预测[湍流](@entry_id:151300)在下一时刻的具体形态，但可以通过其统计特性（如均值、方差、[相关长度](@entry_id:143364)等）来描述它。

**认知不确定性 (Epistemic Uncertainty)** 指的是由于我们缺乏知识而导致的不确定性。它源于“ignorance”，原则上可以通过收集更多的数据、进行更精确的测量或发展更完善的理论来减小。例如，一个描述等离子体与壁相互作用的模型参数 $\alpha$，如果其精确值未知，那么这种不确定性就是认知的。

区分这两种不确定性至关重要，因为它们的数学表征和处理方式截然不同。

#### 混合不确定性的处理框架

在大多数实际模型中，这两类不确定性总是同时存在。处理这种混合不确定性的标准框架是**层次化贝叶斯方法 (hierarchical Bayesian framework)** 。

该框架分为两步：

1.  **推断/校准 (Inference/Calibration)**：首先，我们利用可用的实验数据 $\mathcal{D}$ 来更新我们对认知不确定性参数的认识。在贝叶斯框架下，我们为认知参数（如 $\alpha$）设定一个**[先验分布](@entry_id:141376)** $p(\alpha)$，它代表了我们在看到数据前的知识。然后，通过[贝叶斯定理](@entry_id:897366) $p(\alpha | \mathcal{D}) \propto p(\mathcal{D} | \alpha) p(\alpha)$，结合数据的[似然](@entry_id:167119)信息 $p(\mathcal{D} | \alpha)$，得到一个**后验分布** $p(\alpha | \mathcal{D})$。这个后验分布代表了数据“教”给我们关于 $\alpha$ 的新知识，通常其不确定性范围会比[先验分布](@entry_id:141376)更窄。

2.  **[前向传播](@entry_id:193086) (Forward Propagation)**：接下来，为了得到QoI的最终预测分布，我们需要将所有剩余的不确定性传播通过模型。这通过[全概率公式](@entry_id:911633)（即[边缘化](@entry_id:264637)）实现。我们对所有不确定性参数的分布进行积分。其层次结构是，首先对于一个给定的认知参数 $\alpha$ 值，我们传播所有[偶然不确定性](@entry_id:634772)（如 $\xi$）得到一个条件预测分布 $p(\bar{n}|\alpha)$。然后，我们将这个[条件分布](@entry_id:138367)在认知参数的后验分布 $p(\alpha|\mathcal{D})$ 上进行加权平均：
    $$
    p(\bar{n} | \mathcal{D}) = \int p(\bar{n}|\alpha) p(\alpha|\mathcal{D}) d\alpha
    $$
    这样得到的最终预测分布 $p(\bar{n} | \mathcal{D})$ 便一致地包含了所有经过数据更新的认知不确定性和固有的[偶然不确定性](@entry_id:634772)。

#### 敏感性分析：识别关键不确定性驱动因素

在众多的不确定性输入中，哪些是真正影响我们预测结果的关键因素？**[敏感性分析](@entry_id:147555) (Sensitivity Analysis, SA)** 就是用来回答这个问题的工具。SA可以帮助我们合理分配研究资源，集中精力去减小那些最重要参数的认知不确定性。

**局域[敏感性分析](@entry_id:147555)**通过计算QoI关于输入参数的[偏导数](@entry_id:146280) $S_i = \partial J / \partial \theta_i$ 来衡量影响。对于具有大量参数的复杂[计算模型](@entry_id:637456)（如大型有限元或有限体积代码），如果采用有限差分法（即多次扰动运行模型）来计算这些导数，计算代价会极其高昂。

**伴随方法 (Adjoint Method)** 为此提供了一种极其高效的解决方案 。伴随方法的核心思想是，对于一个给定的QoI，我们可以构造并求解一个相应的**伴随方程**。这个伴随方程的解（称为伴随场）具有一个神奇的特性：一旦求出，QoI对于**所有**模型参数的敏感度都可以通过简单的后处理（通常是计算一个积分）得到，而无需重新运行[正向模型](@entry_id:148443)。例如，在一个一维[热传导](@entry_id:143509)问题中，为了计算热流密度 $J$ 对热导率 $\theta$ 的敏感度，我们可以推导出对应的伴随温度场 $T^*$ 的控制方程和边界条件。然后，敏感度 $S_{\theta}$ 便可以表示为正向解的梯度 $\frac{dT}{dx}$ 和伴随解的梯度 $\frac{dT^*}{dx}$ 在整个求解域上的积分，即 $S_{\theta} = - \int_0^L \frac{dT}{dx} \frac{dT^*}{dx} dx$。这意味着，无论模型有多少个参数，我们都只需要额外求解一次（线性的）伴随方程，就能获得所有的局域敏感度信息，其[计算效率](@entry_id:270255)远超传统方法。

### 综合：从VVUQ到可信的预测科学

VVUQ流程的最终目的是将一个[计算模型](@entry_id:637456)转化为一个可信的预测工具，服务于具体的科学或工程决策。这意味着我们需要理解模型的局限性，并能在决策框架下综合利用VVUQ提供的所有信息。

#### 应用域与外推风险

一个经过确认的模型并非在所有条件下都有效。我们必须定义其**确认域 (validation domain)**，即模型输入[参数空间](@entry_id:178581)中，其预测能力已经通过与实验对比得到证实的那部分区域 。

与之相关但不同的是**适用性边界 (applicability boundaries)**。这些边界是由模型底层的物理假设决定的。当工况跨越这些边界时，模型的某个核心假设可能不再成立，导致其预测能力急剧下降。这些边界通常可以通过无量纲物理参数来表征。例如，对于一个[中性束注入](@entry_id:204293)模型：
-   **引导中心近似**要求快离子的[拉莫尔半径](@entry_id:197083)远小于系统尺寸（$\rho_b/a \ll 1$）。
-   **准静态沉积**假设要求快离子的慢化时间远小于等离子体宏观演化时间（$\tau_s/\tau_E \lesssim 1$）。
-   **有效[中性束](@entry_id:752451)吸收**要求等离子体对于中性束是光学厚的（例如，[光学厚度](@entry_id:150612) $\tau_{\mathrm{opt}} \gtrsim 0.5$）。
-   **[轴对称](@entry_id:1130776)假设**要求非[轴对称磁场](@entry_id:1121293)扰动足够小（例如，磁涟漪 $\delta_B \lesssim 0.01$）。

当我们需要在一个超出确认域的新工况下进行预测时，就构成了**外推 (extrapolation)**。外推本身并非不可接受，但必须进行审慎的**外推风险评估**。评估的关键在于检查新工况点是否接近或穿越了任何适用性边界。如果一个新工况虽然在确认域之外，但仍在所有适用性边界之内，其外推风险相对较低。反之，如果新工況不仅超出了确认域，还违反了一项或多项关键的物理假设（例如，[光学厚度](@entry_id:150612)过低导致[中性束](@entry_id:752451)穿透，或者非[轴对称](@entry_id:1130776)效应变得显著），那么模型在该点的预测结果就具有很高的风险，可信度极低 。

#### 模型可信度与风险通知决策

VVUQ的最终成果服务于**风险通知决策 (risk-informed decision making)**。美国机械工程师协会（ASME）发布的 V 20 标准为此提供了一个权威的指导框架。其核心理念是，**模型的 credibility 不是一个绝对的概念，而必须与它所支持的决策后果相称** 。

让我们考虑一个实际的工程决策：评估一个[偏滤器设计](@entry_id:1123893)方案能否承受瞬态 ELM 热负荷。决策规则是：只有当预测的峰值热流 $Q$ 超过损伤阈值 $Q_{\mathrm{crit}}$ 的概率小于一个可接受的容忍度 $p_{\mathrm{tol}}$ 时（即 $\mathbb{P}(Q > Q_{\mathrm{crit}})  p_{\mathrm{tol}}$），才能批准该方案。

为了做出这个决策，我们必须综合整个VVUQ流程获得的所有信息，来构建 $Q$ 的最终预测概率分布。这个分布的均值可以取为模型的标称预测值 $\hat{Q}$，而其总不确定性则必须是所有相关不确定性分量的合成：

-   来自**[代码验证](@entry_id:146541)**的误差， $u_v$。
-   来自**解验证**的[数值离散化](@entry_id:752782)误差， $u_n$。
-   来自**确认**的[模型形式误差](@entry_id:274198)， $u_m$。当存在外推时，这个误差项必须根据外推的程度进行放大（例如，乘以一个外推因子 $r$）。
-   来自物理系统自身随机性的**[偶然不确定性](@entry_id:634772)**， $u_a$。

假设这些不确定性来源独立，总的相对标准不确定度可以通过方差合成得到：
$$
u_{\mathrm{tot}} = \sqrt{u_v^2 + u_n^2 + (r u_m)^2 + u_a^2}
$$

最终，$Q$ 的预测分布可以近似为一个正态分布 $Q \sim \mathcal{N}(\hat{Q}, (\hat{Q} u_{\mathrm{tot}})^2)$。有了这个分布，我们就可以直接计算出失效概率 $\mathbb{P}(Q > Q_{\mathrm{crit}})$，并将其与决策阈值 $p_{\mathrm{tol}}$ 进行比较。只有当计算出的概率满足决策规则时，我们才能基于该模型的可信预测，做出批准该方案的决定。这个过程完美地展示了VVUQ如何将分散的[误差分析](@entry_id:142477)和不确定性评估，汇聚成一个支持高风险决策的、量化的、可辩护的科学论证 。