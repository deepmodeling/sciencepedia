{
    "hands_on_practices": [
        {
            "introduction": "The first step in correcting magnetic error fields is accurately measuring them. This practice guides you through the process of converting raw magnetic probe data, distributed across a toroidal surface, into the specific resonant Fourier amplitudes that are known to drive plasma instabilities. By implementing estimators based on the discrete Fourier transform and Monte Carlo methods, you will gain a practical understanding of how to quantify helical field components from sensor measurements, a foundational skill for any feedback control system .",
            "id": "3976225",
            "problem": "Consider a toroidal magnetic confinement device with a rational surface at radius $r_s$ such that the safety factor $q(r_s)$ satisfies $q(r_s)=2/1$. On this surface, the radial magnetic field perturbation $b_r(\\theta,\\phi;r_s)$ is a doubly periodic function of the poloidal angle $\\theta\\in[0,2\\pi)$ and the toroidal angle $\\phi\\in[0,2\\pi)$, both specified in radians. The resonant complex Fourier amplitude associated with the $m/n=2/1$ helical symmetry, denoted $b_{21}(r_s)$, is defined in terms of the doubly periodic function $b_r(\\theta,\\phi;r_s)$ using the fundamental complex Fourier series over the poloidal-toroidal angle domain. The discrete magnetic probe measurements are uniformly distributed in $\\theta$ and $\\phi$ on that surface, and you must compute $b_{21}(r_s)$ directly from those discrete samples without any external inputs. Use a derivation that starts from the foundational definition of complex Fourier coefficients for periodic functions over a two-dimensional angular domain, and apply a scientifically sound discretization consistent with uniform sampling.\n\nYour task is to write a self-contained program that synthesizes magnetic probe data for three specified test cases, computes the complex resonant Fourier amplitude $b_{21}(r_s)$ for each case from the synthesized discrete measurements, and outputs, for each case, the magnitude $\\lvert b_{21}(r_s)\\rvert$ in Tesla and the phase $\\arg\\left(b_{21}(r_s)\\right)$ in radians. The final program must produce these results as a single line containing a comma-separated list enclosed in square brackets, with the sequence ordered as $[\\lvert b_{21}\\rvert_1,\\arg(b_{21})_1,\\lvert b_{21}\\rvert_2,\\arg(b_{21})_2,\\lvert b_{21}\\rvert_3,\\arg(b_{21})_3]$.\n\nThe synthesized data and test suite are as follows. In all cases, angles are in radians and magnetic field units are Tesla.\n\n- Test case $1$ (general case, uniform grid, single harmonic):\n  - Grid resolution: $N_\\theta=64$, $N_\\phi=64$.\n  - Field model: $b_r(\\theta,\\phi;r_s)=A_{21}\\cos\\!\\big(m\\theta-n\\phi+\\delta_{21}\\big)$ with $m=2$ and $n=1$.\n  - Amplitude and phase: $A_{21}=5\\times 10^{-5}\\,\\mathrm{T}$, $\\delta_{21}=1.2$.\n  - No other harmonics or noise are present.\n\n- Test case $2$ (mixture of harmonics with measurement noise, uniform grid):\n  - Grid resolution: $N_\\theta=48$, $N_\\phi=32$.\n  - Field model: $b_r(\\theta,\\phi;r_s)=A_{21}\\cos\\!\\big(2\\theta-\\phi+\\delta_{21}\\big)+A_{11}\\cos\\!\\big(1\\theta-1\\phi+\\delta_{11}\\big)+\\eta(\\theta,\\phi)$, where $\\eta$ is zero-mean Gaussian noise.\n  - Amplitudes and phases: $A_{21}=8\\times 10^{-6}\\,\\mathrm{T}$, $\\delta_{21}=-0.5$; $A_{11}=3\\times 10^{-5}\\,\\mathrm{T}$, $\\delta_{11}=2.0$.\n  - Noise standard deviation: $\\sigma_\\eta=1\\times 10^{-6}\\,\\mathrm{T}$.\n  - Use a fixed random seed $12345$ for generating $\\eta$.\n\n- Test case $3$ (boundary sampling case, random uniform points):\n  - Number of probes: $N=12$.\n  - Probe positions: $\\theta_k$ and $\\phi_k$ independently and uniformly distributed in $[0,2\\pi)$.\n  - Field model: $b_r(\\theta,\\phi;r_s)=A_{21}\\cos\\!\\big(2\\theta-\\phi+\\delta_{21}\\big)$ with $A_{21}=4\\times 10^{-5}\\,\\mathrm{T}$ and $\\delta_{21}=-2.3$.\n  - Use a fixed random seed $2024$ for generating the random probe angles.\n\nScientific and numerical requirements:\n- Base your computation on the fundamental complex Fourier coefficient definition for a two-dimensional periodic function on the domain $\\theta\\in[0,2\\pi)$, $\\phi\\in[0,2\\pi)$, and use a discretization consistent with uniform sampling in $\\theta$ and $\\phi$.\n- Ensure the estimator is unbiased under uniform sampling and discuss any aliasing constraints in your derivation.\n- Output the magnitude in $\\mathrm{T}$ and the phase in radians for each test case as real numbers.\n\nFinal output format specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, ordered as $[\\lvert b_{21}\\rvert_1,\\arg(b_{21})_1,\\lvert b_{21}\\rvert_2,\\arg(b_{21})_2,\\lvert b_{21}\\rvert_3,\\arg(b_{21})_3]$, where each entry is a float. No other text should be printed.",
            "solution": "The problem requires the computation of the complex resonant Fourier amplitude $b_{21}(r_s)$ of a radial magnetic field perturbation $b_r(\\theta, \\phi; r_s)$ on a rational magnetic surface in a toroidal device. The indices $(m,n)=(2,1)$ correspond to the poloidal ($m$) and toroidal ($n$) mode numbers, respectively. The computation must be derived from the fundamental definition of a complex Fourier series and applied to discrete data sets.\n\n### Theoretical Foundation: Continuous Fourier Series\n\nA doubly periodic function $f(\\theta, \\phi)$ on the domain $(\\theta, \\phi) \\in [0, 2\\pi) \\times [0, 2\\pi)$ can be represented by a complex Fourier series. In the context of helical structures in toroidal plasmas, it is conventional to use basis functions of the form $e^{i(m\\theta - n\\phi)}$. The corresponding complex Fourier coefficient, herein denoted $b_{mn}$, is defined by the projection integral:\n$$\nb_{mn} = \\frac{1}{(2\\pi)^2} \\int_0^{2\\pi} \\int_0^{2\\pi} b_r(\\theta, \\phi) e^{-i(m\\theta - n\\phi)} \\, d\\theta \\, d\\phi\n$$\nThis definition ensures the orthogonality of the basis functions over the specified domain.\n\nTo establish a ground truth for the test cases, we evaluate this integral for a single, pure helical mode given by $b_r(\\theta, \\phi) = A_{mn} \\cos(m\\theta - n\\phi + \\delta_{mn})$. Using Euler's formula, $\\cos(x) = \\frac{1}{2}(e^{ix} + e^{-ix})$, we substitute this into the integral:\n$$\nb_{mn} = \\frac{1}{(2\\pi)^2} \\int_0^{2\\pi} \\int_0^{2\\pi} \\left[ \\frac{A_{mn}}{2} \\left( e^{i(m\\theta - n\\phi + \\delta_{mn})} + e^{-i(m\\theta - n\\phi + \\delta_{mn})} \\right) \\right] e^{-i(m\\theta - n\\phi)} \\, d\\theta \\, d\\phi\n$$\n$$\nb_{mn} = \\frac{A_{mn}}{2(2\\pi)^2} \\int_0^{2\\pi} \\int_0^{2\\pi} \\left( e^{i\\delta_{mn}} + e^{-i(2(m\\theta - n\\phi) + \\delta_{mn})} \\right) \\, d\\theta \\, d\\phi\n$$\nDue to the orthogonality property of complex exponentials, the integral of the second term over the periodic domain is zero (for non-zero $m, n$). The first term is a constant, leading to:\n$$\nb_{mn} = \\frac{A_{mn}}{2(2\\pi)^2} e^{i\\delta_{mn}} \\int_0^{2\\pi} \\int_0^{2\\pi} d\\theta \\, d\\phi = \\frac{A_{mn}}{2(2\\pi)^2} e^{i\\delta_{mn}} (2\\pi)^2 = \\frac{A_{mn}}{2} e^{i\\delta_{mn}}\n$$\nThus, for a pure cosine mode of amplitude $A_{mn}$ and phase $\\delta_{mn}$, the corresponding complex Fourier coefficient has a magnitude of $|b_{mn}| = A_{mn}/2$ and a phase of $\\arg(b_{mn}) = \\delta_{mn}$. This provides the expected theoretical result.\n\n### Numerical Estimation from Discrete Data\n\nIn practice, $b_r$ is known only at a finite number of discrete points. The continuous integral must be approximated by a discrete sum. The form of this approximation depends on the sampling strategy.\n\n#### Case 1  2: Uniform Grid Sampling\n\nFor measurements taken on a uniform grid of $N_\\theta \\times N_\\phi$ points, where $\\theta_j = j \\frac{2\\pi}{N_\\theta}$ for $j \\in \\{0, \\dots, N_\\theta-1\\}$ and $\\phi_k = k \\frac{2\\pi}{N_\\phi}$ for $k \\in \\{0, \\dots, N_\\phi-1\\}$, the integral can be approximated by a Riemann sum. The differential area element $d\\theta d\\phi$ is replaced by the discrete area element $\\Delta\\theta \\Delta\\phi = \\frac{2\\pi}{N_\\theta} \\frac{2\\pi}{N_\\phi} = \\frac{(2\\pi)^2}{N_\\theta N_\\phi}$.\n\nSubstituting this into the definition of $b_{mn}$:\n$$\nb_{mn} \\approx \\frac{1}{(2\\pi)^2} \\sum_{j=0}^{N_\\theta-1} \\sum_{k=0}^{N_\\phi-1} b_r(\\theta_j, \\phi_k) e^{-i(m\\theta_j - n\\phi_k)} \\frac{(2\\pi)^2}{N_\\theta N_\\phi}\n$$\nThis expression simplifies to the formula for the 2D Discrete Fourier Transform (DFT), scaled appropriately:\n$$\nb_{mn} \\approx \\frac{1}{N_\\theta N_\\phi} \\sum_{j=0}^{N_\\theta-1} \\sum_{k=0}^{N_\\phi-1} b_r(\\theta_j, \\phi_k) e^{-i(m\\theta_j - n\\phi_k)}\n$$\nThis estimator is exact for band-limited signals if the sampling rates satisfy the Nyquist-Shannon sampling theorem, which requires $N_\\theta  2|m_{\\text{max}}|$ and $N_\\phi  2|n_{\\text{max}}|$. For Case 1, we have $(m,n)=(2,1)$ with $N_\\theta=64, N_\\phi=64$, which satisfies $64  4$ and $64  2$. For Case 2, the modes are $(2,1)$ and $(1,1)$, so $|m_{\\text{max}}|=2, |n_{\\text{max}}|=1$. The grid $N_\\theta=48, N_\\phi=32$ also satisfies the criterion ($48  4$, $32  2$), so aliasing is not an issue. The orthogonality of the discrete Fourier basis ensures that the $(1,1)$ mode does not interfere with the calculation of the $(2,1)$ coefficient. The zero-mean noise term in Case 2 will introduce a statistical error into the estimate.\n\n#### Case 3: Random Uniform Sampling\n\nFor $N$ measurements taken at positions $(\\theta_k, \\phi_k)$ drawn independently from a uniform random distribution over $[0, 2\\pi) \\times [0, 2\\pi)$, we employ a Monte Carlo integration approach. The integral defining $b_{mn}$ can be interpreted as an expectation of the function $g(\\theta, \\phi) = b_r(\\theta, \\phi) e^{-i(m\\theta - n\\phi)}$ over the domain, scaled by the domain's area, which is $(2\\pi)^2$.\n$$\nb_{mn} = \\frac{1}{(2\\pi)^2} \\int_0^{2\\pi} \\int_0^{2\\pi} g(\\theta, \\phi) \\,d\\theta d\\phi = E[g(\\theta, \\phi)]\n$$\nwhere the expectation is taken with respect to the uniform probability measure on the domain. By the law of large numbers, this expectation can be estimated by the sample mean of the function evaluated at the $N$ random points:\n$$\nb_{mn} \\approx \\frac{1}{N} \\sum_{k=1}^{N} g(\\theta_k, \\phi_k) = \\frac{1}{N} \\sum_{k=1}^{N} b_r(\\theta_k, \\phi_k) e^{-i(m\\theta_k - n\\phi_k)}\n$$\nThis Monte Carlo estimator is unbiased, meaning its expected value is the true $b_{mn}$. However, for a finite number of samples $N$, especially a small one like $N=12$, the estimate will have a significant variance, and thus a statistical error compared to the true value.\n\n### Application to Test Cases\n\nThe program will implement these estimators for $(m,n)=(2,1)$.\n- **Test Case 1:** A pure $(2,1)$ mode on a fine uniform grid. The uniform grid estimator is used. The result should be extremely close to the theoretical value $|b_{21}| = A_{21}/2 = 2.5 \\times 10^{-5}$ T and $\\arg(b_{21}) = \\delta_{21} = 1.2$ rad.\n- **Test Case 2:** A mixture of $(2,1)$ and $(1,1)$ modes with noise on a uniform grid. The uniform grid estimator is used. Due to discrete orthogonality, the $(1,1)$ mode does not contribute. The result will be close to the theoretical $(2,1)$ value ($|b_{21}| = A_{21}/2 = 4.0 \\times 10^{-6}$ T, $\\arg(b_{21}) = \\delta_{21} = -0.5$ rad), with a small deviation caused by the realization of the random noise.\n- **Test Case 3:** A pure $(2,1)$ mode sampled at a small number of random points. The random sample estimator is used. The result will approximate the theoretical value ($|b_{21}| = A_{21}/2 = 2.0 \\times 10^{-5}$ T, $\\arg(b_{21}) = \\delta_{21} = -2.3$ rad), but with a noticeable statistical error due to the small sample size $N=12$.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the complex resonant Fourier amplitude b_21 for three test cases.\n    \"\"\"\n    m, n = 2, 1\n    results = []\n\n    # --- Test Case 1: General case, uniform grid, single harmonic ---\n    N_theta_1, N_phi_1 = 64, 64\n    A_21_1, delta_21_1 = 5e-5, 1.2\n    \n    # Generate uniform angular grids\n    theta_1_vals = np.linspace(0, 2 * np.pi, N_theta_1, endpoint=False)\n    phi_1_vals = np.linspace(0, 2 * np.pi, N_phi_1, endpoint=False)\n    theta_1, phi_1 = np.meshgrid(theta_1_vals, phi_1_vals, indexing='ij')\n\n    # Synthesize magnetic field data\n    b_r_1 = A_21_1 * np.cos(m * theta_1 - n * phi_1 + delta_21_1)\n    \n    # Compute the complex Fourier coefficient b_21\n    # Estimator: (1/N_theta*N_phi) * sum(b_r * exp(-i*(m*theta - n*phi)))\n    # This is equivalent to np.mean(b_r * kernel)\n    kernel_1 = np.exp(-1j * (m * theta_1 - n * phi_1))\n    b_21_1 = np.mean(b_r_1 * kernel_1)\n\n    mag_1 = np.abs(b_21_1)\n    phase_1 = np.angle(b_21_1)\n    results.extend([mag_1, phase_1])\n    \n    # --- Test Case 2: Mixture of harmonics with noise, uniform grid ---\n    N_theta_2, N_phi_2 = 48, 32\n    A_21_2, delta_21_2 = 8e-6, -0.5\n    A_11_2, delta_11_2 = 3e-5, 2.0\n    sigma_eta_2, seed_2 = 1e-6, 12345\n    \n    # Generate uniform angular grids\n    theta_2_vals = np.linspace(0, 2 * np.pi, N_theta_2, endpoint=False)\n    phi_2_vals = np.linspace(0, 2 * np.pi, N_phi_2, endpoint=False)\n    theta_2, phi_2 = np.meshgrid(theta_2_vals, phi_2_vals, indexing='ij')\n\n    # Synthesize magnetic field data with two modes and noise\n    b_r_2_mode1 = A_21_2 * np.cos(m * theta_2 - n * phi_2 + delta_21_2)\n    b_r_2_mode2 = A_11_2 * np.cos(1 * theta_2 - 1 * phi_2 + delta_11_2)\n    \n    # Generate reproducible Gaussian noise\n    rng_2 = np.random.default_rng(seed_2)\n    noise_2 = rng_2.normal(0, sigma_eta_2, size=(N_theta_2, N_phi_2))\n    \n    b_r_2 = b_r_2_mode1 + b_r_2_mode2 + noise_2\n    \n    # Compute the complex Fourier coefficient b_21\n    kernel_2 = np.exp(-1j * (m * theta_2 - n * phi_2))\n    b_21_2 = np.mean(b_r_2 * kernel_2)\n    \n    mag_2 = np.abs(b_21_2)\n    phase_2 = np.angle(b_21_2)\n    results.extend([mag_2, phase_2])\n\n    # --- Test Case 3: Boundary sampling case, random uniform points ---\n    N_3 = 12\n    A_21_3, delta_21_3 = 4e-5, -2.3\n    seed_3 = 2024\n\n    # Generate random uniform probe positions\n    rng_3 = np.random.default_rng(seed_3)\n    theta_3 = rng_3.uniform(0, 2 * np.pi, N_3)\n    phi_3 = rng_3.uniform(0, 2 * np.pi, N_3)\n\n    # Synthesize magnetic field data at random points\n    b_r_3 = A_21_3 * np.cos(m * theta_3 - n * phi_3 + delta_21_3)\n    \n    # Compute the complex Fourier coefficient b_21 using Monte Carlo estimator\n    # Estimator: (1/N) * sum(b_r * exp(-i*(m*theta - n*phi)))\n    kernel_3 = np.exp(-1j * (m * theta_3 - n * phi_3))\n    b_21_3 = np.mean(b_r_3 * kernel_3)\n    \n    mag_3 = np.abs(b_21_3)\n    phase_3 = np.angle(b_21_3)\n    results.extend([mag_3, phase_3])\n\n    # Print the final output in the specified format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Once an error field is quantified, the next task is to apply currents to a set of correction coils to cancel it. This exercise delves into the core linear algebra of this inverse problem, using the Singular Value Decomposition (SVD) to derive the minimum-norm currents that achieve a desired correction. More importantly, this practice reveals how the SVD provides profound insight into the system's conditioning, explaining why certain corrections are \"expensive\" or highly sensitive to noise and highlighting the physical limitations of any given coil set .",
            "id": "3976165",
            "problem": "Consider a single toroidal mode number error field (EF) correction task in a toroidal magnetic confinement device, where a set of $3$ non-axisymmetric correction coils produce a measured two-component magnetic response on a dedicated pair of sensors. The linearized plasma-and-vessel response mapping at this mode is represented by a real matrix $\\mathbf{G} \\in \\mathbb{R}^{2 \\times 3}$ that maps coil currents $\\mathbf{i} \\in \\mathbb{R}^{3}$ (in Amperes) to the measured response $\\mathbf{b} \\in \\mathbb{R}^{2}$. The singular value decomposition (SVD) of $\\mathbf{G}$ is given by the orthogonal matrices $\\mathbf{U} \\in \\mathbb{R}^{2 \\times 2}$ and $\\mathbf{V} \\in \\mathbb{R}^{3 \\times 3}$ and the rectangular diagonal matrix $\\mathbf{\\Sigma} \\in \\mathbb{R}^{2 \\times 3}$ such that $\\mathbf{G}=\\mathbf{U}\\mathbf{\\Sigma}\\mathbf{V}^{\\top}$, with\n$$\n\\mathbf{U}=\\begin{pmatrix}1  0 \\\\ 0  1\\end{pmatrix},\\quad\n\\mathbf{\\Sigma}=\\begin{pmatrix}5  0  0 \\\\ 0  0.02  0\\end{pmatrix},\\quad\n\\mathbf{V}=\\begin{pmatrix}1  0  0 \\\\ 0  1  0 \\\\ 0  0  1\\end{pmatrix}.\n$$\nA target response $\\mathbf{b}_{\\mathrm{t}} \\in \\mathbb{R}^{2}$ is specified as\n$$\n\\mathbf{b}_{\\mathrm{t}}=\\begin{pmatrix}1 \\\\ 0.02\\end{pmatrix}.\n$$\nAssume the system is to be solved exactly (that is, the target is in the column space of $\\mathbf{G}$), and the operational goal is to minimize the coil Euclidean norm subject to achieving the target response. Starting from fundamental linear algebra principles and the definition of singular value decomposition (SVD), derive the minimum-Euclidean-norm solution $\\mathbf{i}^{\\star}$ that satisfies $\\mathbf{G}\\mathbf{i}=\\mathbf{b}_{\\mathrm{t}}$. Then, analyze the sensitivity of this minimum-norm solution to small singular values by considering an additive sensor noise model $\\mathbf{b}=\\mathbf{b}_{\\mathrm{t}}+\\mathbf{n}$, where $\\mathbf{n}\\in\\mathbb{R}^{2}$ has independent zero-mean components with variance $\\sigma_{n}^{2}$. Use orthogonality and the SVD structure to derive the expected squared norm of the noise-induced current component as a function of $\\sigma_{n}^{2}$ and the singular values of $\\mathbf{G}$, and identify which singular value dominates the amplification.\n\nProvide the final coil current vector $\\mathbf{i}^{\\star}$ as your final numeric answer. Express the final coil currents in Amperes and round each component to four significant figures. Do not include units in your final boxed answer.",
            "solution": "The problem requires finding the minimum-Euclidean-norm current vector $\\mathbf{i}^{\\star}$ that satisfies the linear system $\\mathbf{G}\\mathbf{i}=\\mathbf{b}_{\\mathrm{t}}$. This is a standard problem solved using the Moore-Penrose pseudoinverse of $\\mathbf{G}$, denoted $\\mathbf{G}^{+}$. The unique minimum-norm solution is given by $\\mathbf{i}^{\\star} = \\mathbf{G}^{+}\\mathbf{b}_{\\mathrm{t}}$.\n\nThe pseudoinverse $\\mathbf{G}^{+}$ can be calculated from the singular value decomposition (SVD) of $\\mathbf{G}$, which is given as $\\mathbf{G}=\\mathbf{U}\\mathbf{\\Sigma}\\mathbf{V}^{\\top}$. The formula for the pseudoinverse is $\\mathbf{G}^{+} = \\mathbf{V}\\mathbf{\\Sigma}^{+}\\mathbf{U}^{\\top}$.\n\nFirst, we construct the pseudoinverse of the singular value matrix, $\\mathbf{\\Sigma}^{+}$. Given\n$$\n\\mathbf{\\Sigma}=\\begin{pmatrix}5  0  0 \\\\ 0  0.02  0\\end{pmatrix}\n$$\n$\\mathbf{\\Sigma}^{+}$ is formed by transposing $\\mathbf{\\Sigma}$ and taking the reciprocal of the non-zero singular values ($\\sigma_1=5, \\sigma_2=0.02$):\n$$\n\\mathbf{\\Sigma}^{+}=\\begin{pmatrix}1/5  0 \\\\ 0  1/0.02 \\\\ 0  0\\end{pmatrix} = \\begin{pmatrix}0.2  0 \\\\ 0  50 \\\\ 0  0\\end{pmatrix}\n$$\nThe problem states that $\\mathbf{U}$ and $\\mathbf{V}$ are identity matrices ($\\mathbf{U}=\\mathbf{I}_{2}$, $\\mathbf{V}=\\mathbf{I}_{3}$). Substituting these into the formula for $\\mathbf{G}^{+}$ simplifies the expression:\n$$\n\\mathbf{G}^{+} = \\mathbf{I}_{3} \\mathbf{\\Sigma}^{+} \\mathbf{I}_{2}^{\\top} = \\mathbf{\\Sigma}^{+}\n$$\nNow, we can compute the minimum-norm solution $\\mathbf{i}^{\\star}$ by applying the pseudoinverse to the target response $\\mathbf{b}_{\\mathrm{t}}$:\n$$\n\\mathbf{i}^{\\star} = \\mathbf{G}^{+}\\mathbf{b}_{\\mathrm{t}} = \\mathbf{\\Sigma}^{+}\\mathbf{b}_{\\mathrm{t}} = \\begin{pmatrix}0.2  0 \\\\ 0  50 \\\\ 0  0\\end{pmatrix} \\begin{pmatrix}1 \\\\ 0.02\\end{pmatrix} = \\begin{pmatrix} (0.2)(1) + (0)(0.02) \\\\ (0)(1) + (50)(0.02) \\\\ (0)(1) + (0)(0.02) \\end{pmatrix} = \\begin{pmatrix} 0.2 \\\\ 1 \\\\ 0 \\end{pmatrix}\n$$\nTo analyze the sensitivity to sensor noise $\\mathbf{n}$, we consider the noise-induced current component $\\mathbf{i}_{\\text{noise}} = \\mathbf{G}^{+}\\mathbf{n}$. The squared norm is $\\|\\mathbf{i}_{\\text{noise}}\\|_2^2 = \\|\\mathbf{G}^{+}\\mathbf{n}\\|_2^2 = \\|\\mathbf{V}\\mathbf{\\Sigma}^{+}\\mathbf{U}^{\\top}\\mathbf{n}\\|_2^2$. Since $\\mathbf{U}$ and $\\mathbf{V}$ are orthogonal, they preserve the norm, so this simplifies to $\\|\\mathbf{\\Sigma}^{+}\\mathbf{n}\\|_2^2$.\nWith $\\tilde{\\mathbf{n}}=\\mathbf{U}^{\\top}\\mathbf{n}=\\mathbf{n}$, we have:\n$$\n\\mathbf{i}_{\\text{noise}} = \\mathbf{\\Sigma}^{+}\\mathbf{n} = \\begin{pmatrix} n_1/\\sigma_1 \\\\ n_2/\\sigma_2 \\\\ 0 \\end{pmatrix}\n$$\nThe squared norm is $\\|\\mathbf{i}_{\\text{noise}}\\|_2^2 = (n_1/\\sigma_1)^2 + (n_2/\\sigma_2)^2$. The expected value, assuming independent noise components with variance $\\sigma_n^2$, is:\n$$\nE[\\|\\mathbf{i}_{\\text{noise}}\\|_2^2] = \\frac{E[n_1^2]}{\\sigma_1^2} + \\frac{E[n_2^2]}{\\sigma_2^2} = \\sigma_{n}^{2} \\left(\\frac{1}{\\sigma_1^2} + \\frac{1}{\\sigma_2^2}\\right)\n$$\nSince $\\sigma_2=0.02$ is much smaller than $\\sigma_1=5$, the term $1/\\sigma_2^2 = 2500$ is much larger than $1/\\sigma_1^2 = 0.04$. Therefore, the noise amplification is dominated by the smallest singular value.\n\nThe final numerical solution for the current vector is $\\mathbf{i}^{\\star} = \\begin{pmatrix} 0.2 \\\\ 1 \\\\ 0 \\end{pmatrix}$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 0.2000  1.000  0 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Real-world control scenarios in fusion devices rarely involve a single objective; they require balancing competing priorities. This advanced practice moves beyond simple error field cancellation to the realm of multi-objective optimization, where the goal of minimizing core error fields may conflict with the need to apply specific resonant magnetic perturbations (RMPs) at the plasma edge for stability. By tracing a Pareto front, you will learn how to systematically map out the trade-offs between these conflicting goals and select an optimal operating point that represents a principled compromise .",
            "id": "3976162",
            "problem": "You are given a linearized, dimensionless model of coil current actuation for magnetic error fields in a toroidal device. The decision variable is the coil current vector $\\mathbf{x} \\in \\mathbb{R}^n$. The core error field residual is represented by a linear mapping $\\mathbf{C} \\in \\mathbb{R}^{m_c \\times n}$ and a desired core cancellation vector $\\mathbf{d} \\in \\mathbb{R}^{m_c}$, giving a core residual cost $J_c(\\mathbf{x}) = \\lVert \\mathbf{C}\\mathbf{x} - \\mathbf{d} \\rVert_2^2$. The edge Resonant Magnetic Perturbation (RMP) strength target is represented by a linear mapping $\\mathbf{E} \\in \\mathbb{R}^{m_e \\times n}$ with a desired RMP vector $\\mathbf{r} \\in \\mathbb{R}^{m_e}$, giving an edge tracking cost $J_e(\\mathbf{x}) = \\lVert \\mathbf{E}\\mathbf{x} - \\mathbf{r} \\rVert_2^2$. To encode engineering limits and avoid ill-conditioning, a Tikhonov regularization term $\\mu \\lVert \\mathbf{x} \\rVert_2^2$ with $\\mu  0$ is included. All quantities are dimensionless and normalized, so no physical units are required.\n\nThe Pareto optimization is performed using a weighted-sum scalarization parameter $w \\in [0,1]$ over the set $\\mathcal{W} = \\{\\, 0,\\, 0.1,\\, 0.25,\\, 0.5,\\, 0.75,\\, 0.9,\\, 1 \\,\\}$, for a fixed $\\mu$. For each $w \\in \\mathcal{W}$, consider the convex quadratic program\n$$\n\\min_{\\mathbf{x} \\in \\mathbb{R}^n} \\; F_w(\\mathbf{x}) = w \\, J_c(\\mathbf{x}) + (1-w) \\, J_e(\\mathbf{x}) + \\mu \\lVert \\mathbf{x} \\rVert_2^2,\n$$\nand denote by $\\mathbf{x}_w$ the unique minimizer. Define the realized core residual $J_c(\\mathbf{x}_w)$, the edge tracking residual $J_e(\\mathbf{x}_w)$, and the achieved edge RMP strength $S(\\mathbf{x}_w) = \\lVert \\mathbf{E} \\mathbf{x}_w \\rVert_2$.\n\nSelect the operating point by identifying the discrete “knee” of the Pareto trade-off curve using the following procedure: construct the sequence of points $\\big( \\log_{10} J_c(\\mathbf{x}_w), \\log_{10} J_e(\\mathbf{x}_w) \\big)$ in the order of increasing $w \\in \\mathcal{W}$, then for every triple of consecutive points compute the Menger curvature $\\kappa = \\dfrac{4 A}{a b c}$, where $a$, $b$, and $c$ are the side lengths of the triangle formed by the triple, and $A$ is the triangle area. Choose the $w^\\star \\in \\mathcal{W}$ corresponding to the maximum curvature over interior triples (endpoints are excluded). Return the triple $\\big[ w^\\star,\\, J_c(\\mathbf{x}_{w^\\star}),\\, S(\\mathbf{x}_{w^\\star}) \\big]$.\n\nUse the regularization $\\mu = 10^{-3}$ and solve the following three independent test cases. Each case defines $\\mathbf{C}$, $\\mathbf{d}$, $\\mathbf{E}$, and $\\mathbf{r}$ explicitly.\n\nTest case $1$:\n$$\n\\mathbf{C}_1 = \\begin{pmatrix}\n1  0.5  0 \\\\\n0  1  0.5\n\\end{pmatrix}, \\quad\n\\mathbf{d}_1 = \\begin{pmatrix} 0.1 \\\\ -0.2 \\end{pmatrix}, \\quad\n\\mathbf{E}_1 = \\begin{pmatrix}\n0.2  -0.5  1.0 \\\\\n0  0.3  0.4\n\\end{pmatrix}, \\quad\n\\mathbf{r}_1 = \\begin{pmatrix} 0.3 \\\\ 0.0 \\end{pmatrix}.\n$$\n\nTest case $2$:\n$$\n\\mathbf{C}_2 = \\begin{pmatrix}\n1.0  2.0  -1.0 \\\\\n0.0  1.0  1.0 \\\\\n1.0  -1.0  0.5\n\\end{pmatrix}, \\quad\n\\mathbf{d}_2 = \\begin{pmatrix} 0.05 \\\\ -0.1 \\\\ 0.2 \\end{pmatrix}, \\quad\n\\mathbf{E}_2 = \\begin{pmatrix}\n-0.3  1.0  0.7 \\\\\n0.6  -0.2  0.1\n\\end{pmatrix}, \\quad\n\\mathbf{r}_2 = \\begin{pmatrix} 0.4 \\\\ 0.2 \\end{pmatrix}.\n$$\n\nTest case $3$:\n$$\n\\mathbf{C}_3 = \\begin{pmatrix}\n10^{-2}  2 \\cdot 10^{-2}  -10^{-2} \\\\\n2 \\cdot 10^{-2}  4 \\cdot 10^{-2}  -2 \\cdot 10^{-2}\n\\end{pmatrix}, \\quad\n\\mathbf{d}_3 = \\begin{pmatrix} 10^{-3} \\\\ -10^{-3} \\end{pmatrix}, \\quad\n\\mathbf{E}_3 = \\begin{pmatrix}\n1.0  0.0  0.0 \\\\\n0.0  1.0  0.0\n\\end{pmatrix}, \\quad\n\\mathbf{r}_3 = \\begin{pmatrix} 0.2 \\\\ -0.1 \\end{pmatrix}.\n$$\n\nRequirements:\n- For each test case $i \\in \\{1,2,3\\}$ and each $w \\in \\mathcal{W}$, solve for $\\mathbf{x}_w$ and compute $J_c(\\mathbf{x}_w)$, $J_e(\\mathbf{x}_w)$, and $S(\\mathbf{x}_w)$ as defined above. Use $\\mu = 10^{-3}$.\n- Determine $w^\\star$ by maximizing the discrete Menger curvature on the $\\big( \\log_{10} J_c, \\log_{10} J_e \\big)$ curve over interior triples.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where the list contains three elements corresponding to the three test cases, each element being a list of the form $[w^\\star, J_c(\\mathbf{x}_{w^\\star}), S(\\mathbf{x}_{w^\\star})]$. For example, an output of the form $\\big[\\,[\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot]\\,\\big]$.\n\nAll computations are purely numerical and dimensionless; no unit conversions are required. Angles are not used. The outputs must be real numbers.",
            "solution": "This problem requires the solution of a series of regularized linear least-squares problems to trace a Pareto front, followed by a geometric analysis to identify an optimal operating point. The principles of multi-objective optimization, linear algebra, and numerical geometry are central to the solution.\n\nFirst, we address the core optimization problem for a fixed weight $w \\in [0,1]$. The objective function to minimize is\n$$\nF_w(\\mathbf{x}) = w \\lVert \\mathbf{C}\\mathbf{x} - \\mathbf{d} \\rVert_2^2 + (1-w) \\lVert \\mathbf{E}\\mathbf{x} - \\mathbf{r} \\rVert_2^2 + \\mu \\lVert \\mathbf{x} \\rVert_2^2.\n$$\nThis is a quadratic function of the decision variable $\\mathbf{x}$. We can expand the norm-squared terms:\n$J_c(\\mathbf{x}) = (\\mathbf{C}\\mathbf{x} - \\mathbf{d})^T (\\mathbf{C}\\mathbf{x} - \\mathbf{d}) = \\mathbf{x}^T \\mathbf{C}^T \\mathbf{C} \\mathbf{x} - 2\\mathbf{d}^T \\mathbf{C} \\mathbf{x} + \\mathbf{d}^T \\mathbf{d}$\n$J_e(\\mathbf{x}) = (\\mathbf{E}\\mathbf{x} - \\mathbf{r})^T (\\mathbf{E}\\mathbf{x} - \\mathbf{r}) = \\mathbf{x}^T \\mathbf{E}^T \\mathbf{E} \\mathbf{x} - 2\\mathbf{r}^T \\mathbf{E} \\mathbf{x} + \\mathbf{r}^T \\mathbf{r}$\nSubstituting these into $F_w(\\mathbf{x})$ and collecting terms based on powers of $\\mathbf{x}$ gives:\n$$\nF_w(\\mathbf{x}) = \\mathbf{x}^T \\left( w \\mathbf{C}^T \\mathbf{C} + (1-w) \\mathbf{E}^T \\mathbf{E} + \\mu \\mathbf{I} \\right) \\mathbf{x} - 2 \\left( w \\mathbf{d}^T \\mathbf{C} + (1-w) \\mathbf{r}^T \\mathbf{E} \\right) \\mathbf{x} + \\text{const}.\n$$\nThis is a convex quadratic form. The minimizer $\\mathbf{x}_w$ is found by setting the gradient with respect to $\\mathbf{x}$ to zero:\n$$\n\\nabla_{\\mathbf{x}} F_w(\\mathbf{x}) = 2 \\left( w \\mathbf{C}^T \\mathbf{C} + (1-w) \\mathbf{E}^T \\mathbf{E} + \\mu \\mathbf{I} \\right) \\mathbf{x} - 2 \\left( w \\mathbf{C}^T \\mathbf{d} + (1-w) \\mathbf{E}^T \\mathbf{r} \\right) = \\mathbf{0}.\n$$\nThis simplifies to the system of linear equations known as the normal equations:\n$$\n\\left( w \\mathbf{C}^T \\mathbf{C} + (1-w) \\mathbf{E}^T \\mathbf{E} + \\mu \\mathbf{I} \\right) \\mathbf{x}_w = w \\mathbf{C}^T \\mathbf{d} + (1-w) \\mathbf{E}^T \\mathbf{r}.\n$$\nLet us define $\\mathbf{A}_w = w \\mathbf{C}^T \\mathbf{C} + (1-w) \\mathbf{E}^T \\mathbf{E} + \\mu \\mathbf{I}$ and $\\mathbf{b}_w = w \\mathbf{C}^T \\mathbf{d} + (1-w) \\mathbf{E}^T \\mathbf{r}$. The system is $\\mathbf{A}_w \\mathbf{x}_w = \\mathbf{b}_w$. The matrix $\\mathbf{A}_w$ is guaranteed to be invertible because it is the sum of positive semi-definite matrices ($w \\mathbf{C}^T \\mathbf{C}$ and $(1-w) \\mathbf{E}^T \\mathbf{E}$ for $w \\in [0,1]$) and a positive definite matrix ($\\mu \\mathbf{I}$ for $\\mu  0$). Thus, $\\mathbf{A}_w$ is positive definite, and a unique solution $\\mathbf{x}_w = \\mathbf{A}_w^{-1} \\mathbf{b}_w$ exists for each $w$.\n\nThe overall solution procedure is as follows:\n1. For each test case, we are given matrices $\\mathbf{C}$, $\\mathbf{E}$ and vectors $\\mathbf{d}$, $\\mathbf{r}$. The regularization parameter is fixed at $\\mu = 10^{-3}$.\n2. We iterate through each weight $w$ in the specified set $\\mathcal{W} = \\{0, 0.1, 0.25, 0.5, 0.75, 0.9, 1\\}$.\n3. For each $w$, we construct the matrix $\\mathbf{A}_w$ and vector $\\mathbf{b}_w$ as defined above.\n4. We solve the linear system $\\mathbf{A}_w \\mathbf{x}_w = \\mathbf{b}_w$ to find the optimal coil current vector $\\mathbf{x}_w$.\n5. Using $\\mathbf{x}_w$, we compute the realized core and edge residuals, $J_c(\\mathbf{x}_w) = \\lVert \\mathbf{C}\\mathbf{x}_w - \\mathbf{d} \\rVert_2^2$ and $J_e(\\mathbf{x}_w) = \\lVert \\mathbf{E}\\mathbf{x}_w - \\mathbf{r} \\rVert_2^2$.\n6. We construct a sequence of points representing the Pareto trade-off curve in log-space: $P_w = \\left( \\log_{10} J_c(\\mathbf{x}_w), \\log_{10} J_e(\\mathbf{x}_w) \\right)$, ordered by increasing $w$.\n7. To find the \"knee\" of this curve, we analyze interior triples of consecutive points. For each interior point $P_i$ (corresponding to $w_i \\in \\{0.1, 0.25, 0.5, 0.75, 0.9\\}$) and its neighbors $P_{i-1}$ and $P_{i+1}$, we compute the Menger curvature $\\kappa_i$.\n8. The Menger curvature is given by $\\kappa = \\frac{4A}{abc}$, where $a$, $b$, and $c$ are the lengths of the sides of the triangle formed by the three points, and $A$ is the triangle's area. The area $A$ can be computed robustly using the vector cross product magnitude: for points $\\mathbf{p}_1, \\mathbf{p}_2, \\mathbf{p}_3$, $A = \\frac{1}{2} | (\\mathbf{p}_2 - \\mathbf{p}_1) \\times (\\mathbf{p}_3 - \\mathbf{p}_1) |$, which in $2$D is $A = \\frac{1}{2} |(x_2-x_1)(y_3-y_1) - (x_3-x_1)(y_2-y_1)|$.\n9. We identify the weight $w^\\star$ that corresponds to the triple yielding the maximum curvature. This $w^\\star$ is our selected operating point.\n10. Finally, we retrieve the corresponding core residual $J_c(\\mathbf{x}_{w^\\star})$ and calculate the achieved edge RMP strength $S(\\mathbf{x}_{w^\\star}) = \\lVert \\mathbf{E} \\mathbf{x}_{w^\\star} \\rVert_2$. The required output is the triple $[w^\\star, J_c(\\mathbf{x}_{w^\\star}), S(\\mathbf{x}_{w^\\star})]$.\n\nThis procedure is systematically applied to each of the three test cases.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the three test cases for the error field correction problem.\n    \"\"\"\n    mu = 1e-3\n    W = [0.0, 0.1, 0.25, 0.5, 0.75, 0.9, 1.0]\n\n    # Test case 1 data\n    C1 = np.array([[1.0, 0.5, 0.0],\n                   [0.0, 1.0, 0.5]])\n    d1 = np.array([0.1, -0.2])\n    E1 = np.array([[0.2, -0.5, 1.0],\n                   [0.0, 0.3, 0.4]])\n    r1 = np.array([0.3, 0.0])\n\n    # Test case 2 data\n    C2 = np.array([[1.0, 2.0, -1.0],\n                   [0.0, 1.0, 1.0],\n                   [1.0, -1.0, 0.5]])\n    d2 = np.array([0.05, -0.1, 0.2])\n    E2 = np.array([[-0.3, 1.0, 0.7],\n                   [0.6, -0.2, 0.1]])\n    r2 = np.array([0.4, 0.2])\n\n    # Test case 3 data\n    C3 = np.array([[1e-2, 2e-2, -1e-2],\n                   [2e-2, 4e-2, -2e-2]])\n    d3 = np.array([1e-3, -1e-3])\n    E3 = np.array([[1.0, 0.0, 0.0],\n                   [0.0, 1.0, 0.0]])\n    r3 = np.array([0.2, -0.1])\n    \n    test_cases = [\n        (C1, d1, E1, r1),\n        (C2, d2, E2, r2),\n        (C3, d3, E3, r3)\n    ]\n\n    results = []\n    for case in test_cases:\n        C, d, E, r = case\n        result = solve_case(C, d, E, r, mu, W)\n        results.append(result)\n\n    # Format the final output string as specified\n    print(f\"[{','.join(map(str, results))}]\")\n\n\ndef solve_case(C, d, E, r, mu, W):\n    \"\"\"\n    Solves a single test case of the optimization problem.\n\n    Args:\n        C (np.ndarray): Core error field mapping matrix.\n        d (np.ndarray): Desired core cancellation vector.\n        E (np.ndarray): Edge RMP strength mapping matrix.\n        r (np.ndarray): Desired RMP vector.\n        mu (float): Tikhonov regularization parameter.\n        W (list of float): List of weights for Pareto optimization.\n\n    Returns:\n        list: A list containing [w_star, Jc(x_w_star), S(x_w_star)].\n    \"\"\"\n    n = C.shape[1]\n    I = np.identity(n)\n    \n    pareto_points = []\n    results_for_w = {}\n\n    for w in W:\n        # Formulate and solve the linear system A_w * x_w = b_w\n        A_w = w * (C.T @ C) + (1 - w) * (E.T @ E) + mu * I\n        b_w = w * (C.T @ d) + (1 - w) * (E.T @ r)\n        x_w = np.linalg.solve(A_w, b_w)\n\n        # Calculate performance metrics\n        Jc_xw = np.linalg.norm(C @ x_w - d)**2\n        Je_xw = np.linalg.norm(E @ x_w - r)**2\n        S_xw = np.linalg.norm(E @ x_w)\n\n        # Store data for Pareto analysis\n        pareto_points.append((np.log10(Jc_xw), np.log10(Je_xw)))\n        results_for_w[w] = {\n            'Jc': Jc_xw,\n            'S': S_xw,\n        }\n    \n    # Find the knee of the Pareto curve using Menger curvature\n    curvatures = []\n    # Iterate over interior triples of points on the curve\n    for i in range(1, len(W) - 1):\n        p_prev = np.array(pareto_points[i-1])\n        p_curr = np.array(pareto_points[i])\n        p_next = np.array(pareto_points[i+1])\n\n        # Calculate side lengths of the triangle formed by the triple\n        a = np.linalg.norm(p_next - p_curr)\n        b = np.linalg.norm(p_next - p_prev)\n        c = np.linalg.norm(p_curr - p_prev)\n\n        # Check for collinearity or degenerate triangles\n        if a * b * c == 0.0 or np.isclose(a + c, b) or np.isclose(b + c, a) or np.isclose(a + b, c):\n            curvatures.append(0.0)\n            continue\n        \n        # Calculate triangle area using the 2D cross product magnitude for numerical stability\n        vec1 = p_prev - p_curr\n        vec2 = p_next - p_curr\n        area = 0.5 * np.abs(vec1[0] * vec2[1] - vec1[1] * vec2[0])\n\n        # Menger curvature formula\n        kappa = (4 * area) / (a * b * c)\n        curvatures.append(kappa)\n\n    # The curvature list corresponds to the interior weights W[1] through W[len(W)-2]\n    # Find the index of the maximum curvature\n    max_curvature_idx = np.argmax(curvatures)\n    # The index in the original weight list W is offset by 1\n    w_star_index = max_curvature_idx + 1\n    w_star = W[w_star_index]\n\n    # Retrieve the final results for the optimal weight w_star\n    final_Jc = results_for_w[w_star]['Jc']\n    final_S = results_for_w[w_star]['S']\n    \n    return [w_star, final_Jc, final_S]\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}